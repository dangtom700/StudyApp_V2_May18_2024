Quantum Mechanics in Nanoscience and Engineering
Quantum Mechanics in Nanoscience and Engineering covers both elementary and advanced quan￾tum mechanics within a coherent and self-contained framework. Undergraduate students of
physics, chemistry, and engineering will find comprehensive coverage of their introductory quan￾tum mechanics courses, and graduate students will gain an understanding of additional tools
and concepts necessary to describe real-world phenomena. Each topic presented is first moti￾vated by an experimental technique, phenomenon, or concept derived directly from the realm of
nanoscience and technology. The machinery of quantum mechanics is described and reinforced
through the perspective of nanoscale phenomena, and in this manner practical and fundamen￾tal questions are raised and answered. The main text remains fluent and accessible by leaving
technical details and mathematical proofs to guided exercises. Introductory readers may over￾look these exercises, while rigorous students can benefit from reading the guidance or solving
the exercises in full to strengthen and consolidate their understanding of the material.
Uri Peskin is Professor of Chemistry and a member of the Russell Berrie Nanotechnology Insti￾tute and the Helen Diller quantum center at Technion – Israel Institute of Technology. His
expertise lies in atomic and molecular physics and scientific computing, with emphasis on quan￾tum dynamics on the nanoscale. He was a postdoctoral fellow at the University of California at
Berkeley, and a visiting professor at Harvard and Freiburg universities. His research and teach￾ing of quantum mechanics has won him several awards, including the Yanai Prize for Excellence
in Academic Education.
Published online by Cambridge University PressMy deepest gratitude to my science teachers
Meira and Igal Peskin, Naphtali Shoham, Menachem Fisch, Avinoam Ben-Shaul, Ron￾nie Kosloff, Raphael D. Levine, Maurice Cohen, Robert B. Gerber, Nimrod Moiseyev,
Roland Lefebvre, Gabriel Kventsel, Ruben Pauncz, Jacob Katriel, Tsofar Maniv, Yitzhak
Apeloig, Itzhak Oref, Claude Leforestier, Ofir E. Alon, Nir Ben-Tal, Naomi Rom,
Rami Rom, William H. Miller, Hanna Reisler, Ron Naaman, Ilya Vorobeichick, Rob
D. Coalson, David J. Tannor, Amnon Stanger, Lorenz. S. Cederbaum, Åke Edlund,
Yoav Eichen, Soliman Khatib, Musa Abu-Hilu, Tamar Seidman, Frank A. Weinhold,
Wolfgang Domcke, Eli Pollak, Shmuel Gurvitz, Hans-Dieter Meyer, Daniel Neuhauser,
Ilan Bar-On, Michal Steinberg, Oded Godsi, Asher Schmidt, Abraham Nitzan, Michael
Galperin, Mark A. Ratner, Shammai Speiser, Joshua Jortner, Lihu Berman, Maytal Cas￾pary Toroker, Alon Malka, Daria Brisker-Klaiman, Roie Volkovich, Shachar Klaiman,
Shira Weissman, Sabre Kais, Daly Davis, Michael A. Collins, Edvardas Narevicius,
Vitali Averbukh, Michael Thoss, Rainer Härtle, Yossi Levy, Roman Vaxenburg, Tamar
Goldzak, Yoram Selzer, Tal Simon, Yehudit J. Dori, Vered Dangur, Roni Pozner, Efrat
Lifshitz, Maayan Kuperman, Ariel D. Levine, Anat Kira, Michael Iv, Lev Chuntonov,
Semion Saikin, Christoph Kreisbeck, Alán Aspuru-Guzik, Doran I. G. Bennett, Hossein
R. Sadeghpour, Yossi Paltiel, Andre Erpenbeck, Avner Fleischer, Yaling Ke, Roi Baer,
Leeor Kronik, Yonatan Dubi, Gilad Haran, Danny Porath, Ferdinand Evers, Oren Tal,
Ioan Baldea, Spiros Skourtis, Eberhard K. U. Gross, Todd Martinez, Eitan Geva, Eran
Rabani, Oded Hod, Milan Šindelka, Arik Landau, Ido Gilary, Eli Kolodney, Alon Hoff￾man, Zohar Amitay, Saar Rahav, David Gelbwaser-Klimovsky, E-Dean Fung, Latha
Venkataraman, Yoni Eshel, Yuval Agam, Nadav Amdursky, Amir Ilan, Linoy Nagar,
Yonathan Langbeheim.
To Hani, Noa and Sagi, Shiri and Ori,
I cannot thank you enough. I can only apologize for not being there as much as I should
while writing and putting this book together.
To my parents Meira and Igal, and to Noam, Niv, Yali and their families,
thank you for always being there. My special thanks to Noam Peskin for legal advice.
Published online by Cambridge University PressQuantum Mechanics
in Nanoscience
and Engineering
URI PESKIN
Technion -- Israel Institute of Technology
Published online by Cambridge University PressShaftesbury Road, Cambridge CB2 8BS, United Kingdom
One Liberty Plaza, 20th Floor, New York, NY 10006, USA
477 Williamstown Road, Port Melbourne, VIC 3207, Australia
314–321, 3rd Floor, Plot 3, Splendor Forum, Jasola District Centre, New Delhi – 110025, India
103 Penang Road, #05–06/07, Visioncrest Commercial, Singapore 238467
Cambridge University Press is part of Cambridge University Press & Assessment,
a department of the University of Cambridge.
We share the University’s mission to contribute to society through the pursuit of
education, learning and research at the highest international levels of excellence.
www.cambridge.org
Information on this title: www.cambridge.org/9781108834902
DOI: 10.1017/9781108877787
© Uri Peskin 2023
This publication is in copyright. Subject to statutory exception
and to the provisions of relevant collective licensing agreements,
no reproduction of any part may take place without the written
permission of Cambridge University Press.
First published 2023
Printed in the United Kingdom by TJ Books Limited, Padstow Cornwall
A catalogue record for this publication is available from the British Library.
ISBN 978-1-108-83490-2 Hardback
Additional resources for this publication at cambridge.org/peskin.
Cambridge University Press has no responsibility for the persistence or accuracy of
URLs for external or third-party internet websites referred to in this publication
and does not guarantee that any content on such websites is, or will remain,
accurate or appropriate.
Published online by Cambridge University PressQuantum Mechanics in Nanoscience and Engineering
Quantum Mechanics in Nanoscience and Engineering covers both elementary and advanced quan￾tum mechanics within a coherent and self-contained framework. Undergraduate students of
physics, chemistry, and engineering will find comprehensive coverage of their introductory quan￾tum mechanics courses, and graduate students will gain an understanding of additional tools
and concepts necessary to describe real-world phenomena. Each topic presented is first moti￾vated by an experimental technique, phenomenon, or concept derived directly from the realm of
nanoscience and technology. The machinery of quantum mechanics is described and reinforced
through the perspective of nanoscale phenomena, and in this manner practical and fundamen￾tal questions are raised and answered. The main text remains fluent and accessible by leaving
technical details and mathematical proofs to guided exercises. Introductory readers may over￾look these exercises, while rigorous students can benefit from reading the guidance or solving
the exercises in full to strengthen and consolidate their understanding of the material.
Uri Peskin is Professor of Chemistry and a member of the Russell Berrie Nanotechnology Insti￾tute and the Helen Diller quantum center at Technion – Israel Institute of Technology. His
expertise lies in atomic and molecular physics and scientific computing, with emphasis on quan￾tum dynamics on the nanoscale. He was a postdoctoral fellow at the University of California at
Berkeley, and a visiting professor at Harvard and Freiburg universities. His research and teach￾ing of quantum mechanics has won him several awards, including the Yanai Prize for Excellence
in Academic Education.
Published online by Cambridge University PressMy deepest gratitude to my science teachers
Meira and Igal Peskin, Naphtali Shoham, Menachem Fisch, Avinoam Ben-Shaul, Ron￾nie Kosloff, Raphael D. Levine, Maurice Cohen, Robert B. Gerber, Nimrod Moiseyev,
Roland Lefebvre, Gabriel Kventsel, Ruben Pauncz, Jacob Katriel, Tsofar Maniv, Yitzhak
Apeloig, Itzhak Oref, Claude Leforestier, Ofir E. Alon, Nir Ben-Tal, Naomi Rom,
Rami Rom, William H. Miller, Hanna Reisler, Ron Naaman, Ilya Vorobeichick, Rob
D. Coalson, David J. Tannor, Amnon Stanger, Lorenz. S. Cederbaum, Åke Edlund,
Yoav Eichen, Soliman Khatib, Musa Abu-Hilu, Tamar Seidman, Frank A. Weinhold,
Wolfgang Domcke, Eli Pollak, Shmuel Gurvitz, Hans-Dieter Meyer, Daniel Neuhauser,
Ilan Bar-On, Michal Steinberg, Oded Godsi, Asher Schmidt, Abraham Nitzan, Michael
Galperin, Mark A. Ratner, Shammai Speiser, Joshua Jortner, Lihu Berman, Maytal Cas￾pary Toroker, Alon Malka, Daria Brisker-Klaiman, Roie Volkovich, Shachar Klaiman,
Shira Weissman, Sabre Kais, Daly Davis, Michael A. Collins, Edvardas Narevicius,
Vitali Averbukh, Michael Thoss, Rainer Härtle, Yossi Levy, Roman Vaxenburg, Tamar
Goldzak, Yoram Selzer, Tal Simon, Yehudit J. Dori, Vered Dangur, Roni Pozner, Efrat
Lifshitz, Maayan Kuperman, Ariel D. Levine, Anat Kira, Michael Iv, Lev Chuntonov,
Semion Saikin, Christoph Kreisbeck, Alán Aspuru-Guzik, Doran I. G. Bennett, Hossein
R. Sadeghpour, Yossi Paltiel, Andre Erpenbeck, Avner Fleischer, Yaling Ke, Roi Baer,
Leeor Kronik, Yonatan Dubi, Gilad Haran, Danny Porath, Ferdinand Evers, Oren Tal,
Ioan Baldea, Spiros Skourtis, Eberhard K. U. Gross, Todd Martinez, Eitan Geva, Eran
Rabani, Oded Hod, Milan Šindelka, Arik Landau, Ido Gilary, Eli Kolodney, Alon Hoff￾man, Zohar Amitay, Saar Rahav, David Gelbwaser-Klimovsky, E-Dean Fung, Latha
Venkataraman, Yoni Eshel, Yuval Agam, Nadav Amdursky, Amir Ilan, Linoy Nagar,
Yonathan Langbeheim.
To Hani, Noa and Sagi, Shiri and Ori,
I cannot thank you enough. I can only apologize for not being there as much as I should
while writing and putting this book together.
To my parents Meira and Igal, and to Noam, Niv, Yali and their families,
thank you for always being there. My special thanks to Noam Peskin for legal advice.
Published online by Cambridge University PressQuantum Mechanics
in Nanoscience
and Engineering
URI PESKIN
Technion -- Israel Institute of Technology
Published online by Cambridge University PressShaftesbury Road, Cambridge CB2 8BS, United Kingdom
One Liberty Plaza, 20th Floor, New York, NY 10006, USA
477 Williamstown Road, Port Melbourne, VIC 3207, Australia
314–321, 3rd Floor, Plot 3, Splendor Forum, Jasola District Centre, New Delhi – 110025, India
103 Penang Road, #05–06/07, Visioncrest Commercial, Singapore 238467
Cambridge University Press is part of Cambridge University Press & Assessment,
a department of the University of Cambridge.
We share the University’s mission to contribute to society through the pursuit of
education, learning and research at the highest international levels of excellence.
www.cambridge.org
Information on this title: www.cambridge.org/9781108834902
DOI: 10.1017/9781108877787
© Uri Peskin 2023
This publication is in copyright. Subject to statutory exception
and to the provisions of relevant collective licensing agreements,
no reproduction of any part may take place without the written
permission of Cambridge University Press.
First published 2023
Printed in the United Kingdom by TJ Books Limited, Padstow Cornwall
A catalogue record for this publication is available from the British Library.
ISBN 978-1-108-83490-2 Hardback
Additional resources for this publication at cambridge.org/peskin.
Cambridge University Press has no responsibility for the persistence or accuracy of
URLs for external or third-party internet websites referred to in this publication
and does not guarantee that any content on such websites is, or will remain,
accurate or appropriate.
Published online by Cambridge University PressQuantum Mechanics in Nanoscience and Engineering
Quantum Mechanics in Nanoscience and Engineering covers both elementary and advanced quan￾tum mechanics within a coherent and self-contained framework. Undergraduate students of
physics, chemistry, and engineering will find comprehensive coverage of their introductory quan￾tum mechanics courses, and graduate students will gain an understanding of additional tools
and concepts necessary to describe real-world phenomena. Each topic presented is first moti￾vated by an experimental technique, phenomenon, or concept derived directly from the realm of
nanoscience and technology. The machinery of quantum mechanics is described and reinforced
through the perspective of nanoscale phenomena, and in this manner practical and fundamen￾tal questions are raised and answered. The main text remains fluent and accessible by leaving
technical details and mathematical proofs to guided exercises. Introductory readers may over￾look these exercises, while rigorous students can benefit from reading the guidance or solving
the exercises in full to strengthen and consolidate their understanding of the material.
Uri Peskin is Professor of Chemistry and a member of the Russell Berrie Nanotechnology Insti￾tute and the Helen Diller quantum center at Technion – Israel Institute of Technology. His
expertise lies in atomic and molecular physics and scientific computing, with emphasis on quan￾tum dynamics on the nanoscale. He was a postdoctoral fellow at the University of California at
Berkeley, and a visiting professor at Harvard and Freiburg universities. His research and teach￾ing of quantum mechanics has won him several awards, including the Yanai Prize for Excellence
in Academic Education.
Published online by Cambridge University PressMy deepest gratitude to my science teachers
Meira and Igal Peskin, Naphtali Shoham, Menachem Fisch, Avinoam Ben-Shaul, Ron￾nie Kosloff, Raphael D. Levine, Maurice Cohen, Robert B. Gerber, Nimrod Moiseyev,
Roland Lefebvre, Gabriel Kventsel, Ruben Pauncz, Jacob Katriel, Tsofar Maniv, Yitzhak
Apeloig, Itzhak Oref, Claude Leforestier, Ofir E. Alon, Nir Ben-Tal, Naomi Rom,
Rami Rom, William H. Miller, Hanna Reisler, Ron Naaman, Ilya Vorobeichick, Rob
D. Coalson, David J. Tannor, Amnon Stanger, Lorenz. S. Cederbaum, Åke Edlund,
Yoav Eichen, Soliman Khatib, Musa Abu-Hilu, Tamar Seidman, Frank A. Weinhold,
Wolfgang Domcke, Eli Pollak, Shmuel Gurvitz, Hans-Dieter Meyer, Daniel Neuhauser,
Ilan Bar-On, Michal Steinberg, Oded Godsi, Asher Schmidt, Abraham Nitzan, Michael
Galperin, Mark A. Ratner, Shammai Speiser, Joshua Jortner, Lihu Berman, Maytal Cas￾pary Toroker, Alon Malka, Daria Brisker-Klaiman, Roie Volkovich, Shachar Klaiman,
Shira Weissman, Sabre Kais, Daly Davis, Michael A. Collins, Edvardas Narevicius,
Vitali Averbukh, Michael Thoss, Rainer Härtle, Yossi Levy, Roman Vaxenburg, Tamar
Goldzak, Yoram Selzer, Tal Simon, Yehudit J. Dori, Vered Dangur, Roni Pozner, Efrat
Lifshitz, Maayan Kuperman, Ariel D. Levine, Anat Kira, Michael Iv, Lev Chuntonov,
Semion Saikin, Christoph Kreisbeck, Alán Aspuru-Guzik, Doran I. G. Bennett, Hossein
R. Sadeghpour, Yossi Paltiel, Andre Erpenbeck, Avner Fleischer, Yaling Ke, Roi Baer,
Leeor Kronik, Yonatan Dubi, Gilad Haran, Danny Porath, Ferdinand Evers, Oren Tal,
Ioan Baldea, Spiros Skourtis, Eberhard K. U. Gross, Todd Martinez, Eitan Geva, Eran
Rabani, Oded Hod, Milan Šindelka, Arik Landau, Ido Gilary, Eli Kolodney, Alon Hoff￾man, Zohar Amitay, Saar Rahav, David Gelbwaser-Klimovsky, E-Dean Fung, Latha
Venkataraman, Yoni Eshel, Yuval Agam, Nadav Amdursky, Amir Ilan, Linoy Nagar,
Yonathan Langbeheim.
To Hani, Noa and Sagi, Shiri and Ori,
I cannot thank you enough. I can only apologize for not being there as much as I should
while writing and putting this book together.
To my parents Meira and Igal, and to Noam, Niv, Yali and their families,
thank you for always being there. My special thanks to Noam Peskin for legal advice.
Published online by Cambridge University PressQuantum Mechanics
in Nanoscience
and Engineering
URI PESKIN
Technion -- Israel Institute of Technology
Published online by Cambridge University PressShaftesbury Road, Cambridge CB2 8BS, United Kingdom
One Liberty Plaza, 20th Floor, New York, NY 10006, USA
477 Williamstown Road, Port Melbourne, VIC 3207, Australia
314–321, 3rd Floor, Plot 3, Splendor Forum, Jasola District Centre, New Delhi – 110025, India
103 Penang Road, #05–06/07, Visioncrest Commercial, Singapore 238467
Cambridge University Press is part of Cambridge University Press & Assessment,
a department of the University of Cambridge.
We share the University’s mission to contribute to society through the pursuit of
education, learning and research at the highest international levels of excellence.
www.cambridge.org
Information on this title: www.cambridge.org/9781108834902
DOI: 10.1017/9781108877787
© Uri Peskin 2023
This publication is in copyright. Subject to statutory exception
and to the provisions of relevant collective licensing agreements,
no reproduction of any part may take place without the written
permission of Cambridge University Press.
First published 2023
Printed in the United Kingdom by TJ Books Limited, Padstow Cornwall
A catalogue record for this publication is available from the British Library.
ISBN 978-1-108-83490-2 Hardback
Additional resources for this publication at cambridge.org/peskin.
Cambridge University Press has no responsibility for the persistence or accuracy of
URLs for external or third-party internet websites referred to in this publication
and does not guarantee that any content on such websites is, or will remain,
accurate or appropriate.
Published online by Cambridge University PressQuantum Mechanics in Nanoscience and Engineering
Quantum Mechanics in Nanoscience and Engineering covers both elementary and advanced quan￾tum mechanics within a coherent and self-contained framework. Undergraduate students of
physics, chemistry, and engineering will find comprehensive coverage of their introductory quan￾tum mechanics courses, and graduate students will gain an understanding of additional tools
and concepts necessary to describe real-world phenomena. Each topic presented is first moti￾vated by an experimental technique, phenomenon, or concept derived directly from the realm of
nanoscience and technology. The machinery of quantum mechanics is described and reinforced
through the perspective of nanoscale phenomena, and in this manner practical and fundamen￾tal questions are raised and answered. The main text remains fluent and accessible by leaving
technical details and mathematical proofs to guided exercises. Introductory readers may over￾look these exercises, while rigorous students can benefit from reading the guidance or solving
the exercises in full to strengthen and consolidate their understanding of the material.
Uri Peskin is Professor of Chemistry and a member of the Russell Berrie Nanotechnology Insti￾tute and the Helen Diller quantum center at Technion – Israel Institute of Technology. His
expertise lies in atomic and molecular physics and scientific computing, with emphasis on quan￾tum dynamics on the nanoscale. He was a postdoctoral fellow at the University of California at
Berkeley, and a visiting professor at Harvard and Freiburg universities. His research and teach￾ing of quantum mechanics has won him several awards, including the Yanai Prize for Excellence
in Academic Education.
Published online by Cambridge University PressMy deepest gratitude to my science teachers
Meira and Igal Peskin, Naphtali Shoham, Menachem Fisch, Avinoam Ben-Shaul, Ron￾nie Kosloff, Raphael D. Levine, Maurice Cohen, Robert B. Gerber, Nimrod Moiseyev,
Roland Lefebvre, Gabriel Kventsel, Ruben Pauncz, Jacob Katriel, Tsofar Maniv, Yitzhak
Apeloig, Itzhak Oref, Claude Leforestier, Ofir E. Alon, Nir Ben-Tal, Naomi Rom,
Rami Rom, William H. Miller, Hanna Reisler, Ron Naaman, Ilya Vorobeichick, Rob
D. Coalson, David J. Tannor, Amnon Stanger, Lorenz. S. Cederbaum, Åke Edlund,
Yoav Eichen, Soliman Khatib, Musa Abu-Hilu, Tamar Seidman, Frank A. Weinhold,
Wolfgang Domcke, Eli Pollak, Shmuel Gurvitz, Hans-Dieter Meyer, Daniel Neuhauser,
Ilan Bar-On, Michal Steinberg, Oded Godsi, Asher Schmidt, Abraham Nitzan, Michael
Galperin, Mark A. Ratner, Shammai Speiser, Joshua Jortner, Lihu Berman, Maytal Cas￾pary Toroker, Alon Malka, Daria Brisker-Klaiman, Roie Volkovich, Shachar Klaiman,
Shira Weissman, Sabre Kais, Daly Davis, Michael A. Collins, Edvardas Narevicius,
Vitali Averbukh, Michael Thoss, Rainer Härtle, Yossi Levy, Roman Vaxenburg, Tamar
Goldzak, Yoram Selzer, Tal Simon, Yehudit J. Dori, Vered Dangur, Roni Pozner, Efrat
Lifshitz, Maayan Kuperman, Ariel D. Levine, Anat Kira, Michael Iv, Lev Chuntonov,
Semion Saikin, Christoph Kreisbeck, Alán Aspuru-Guzik, Doran I. G. Bennett, Hossein
R. Sadeghpour, Yossi Paltiel, Andre Erpenbeck, Avner Fleischer, Yaling Ke, Roi Baer,
Leeor Kronik, Yonatan Dubi, Gilad Haran, Danny Porath, Ferdinand Evers, Oren Tal,
Ioan Baldea, Spiros Skourtis, Eberhard K. U. Gross, Todd Martinez, Eitan Geva, Eran
Rabani, Oded Hod, Milan Šindelka, Arik Landau, Ido Gilary, Eli Kolodney, Alon Hoff￾man, Zohar Amitay, Saar Rahav, David Gelbwaser-Klimovsky, E-Dean Fung, Latha
Venkataraman, Yoni Eshel, Yuval Agam, Nadav Amdursky, Amir Ilan, Linoy Nagar,
Yonathan Langbeheim.
To Hani, Noa and Sagi, Shiri and Ori,
I cannot thank you enough. I can only apologize for not being there as much as I should
while writing and putting this book together.
To my parents Meira and Igal, and to Noam, Niv, Yali and their families,
thank you for always being there. My special thanks to Noam Peskin for legal advice.
Published online by Cambridge University PressQuantum Mechanics
in Nanoscience
and Engineering
URI PESKIN
Technion -- Israel Institute of Technology
Published online by Cambridge University PressShaftesbury Road, Cambridge CB2 8BS, United Kingdom
One Liberty Plaza, 20th Floor, New York, NY 10006, USA
477 Williamstown Road, Port Melbourne, VIC 3207, Australia
314–321, 3rd Floor, Plot 3, Splendor Forum, Jasola District Centre, New Delhi – 110025, India
103 Penang Road, #05–06/07, Visioncrest Commercial, Singapore 238467
Cambridge University Press is part of Cambridge University Press & Assessment,
a department of the University of Cambridge.
We share the University’s mission to contribute to society through the pursuit of
education, learning and research at the highest international levels of excellence.
www.cambridge.org
Information on this title: www.cambridge.org/9781108834902
DOI: 10.1017/9781108877787
© Uri Peskin 2023
This publication is in copyright. Subject to statutory exception
and to the provisions of relevant collective licensing agreements,
no reproduction of any part may take place without the written
permission of Cambridge University Press.
First published 2023
Printed in the United Kingdom by TJ Books Limited, Padstow Cornwall
A catalogue record for this publication is available from the British Library.
ISBN 978-1-108-83490-2 Hardback
Additional resources for this publication at cambridge.org/peskin.
Cambridge University Press has no responsibility for the persistence or accuracy of
URLs for external or third-party internet websites referred to in this publication
and does not guarantee that any content on such websites is, or will remain,
accurate or appropriate.
Published online by Cambridge University PressContents
Preface: Who Can Benefit from Reading This Book? page xi
1 Motivation 1
1.1 The Wave–Particle Duality and de Broglie Wavelength 1
1.2 Quantum Mechanics for Nanoscience and Engineering 4
2 The State of a System 5
2.1 Probability Densities 5
2.2 Proper Wave Functions 6
2.3 Normalization 8
3 Observables and Operators 10
3.1 Physical Observables and Operators 10
3.2 The Canonical Operators 11
3.3 The Angular Momentum Operators 12
3.4 Functions of Operators 13
4 The Schrödinger Equation 16
4.1 The Time-Dependent Schrödinger Equation 16
4.2 Time-Dependent Solutions 17
4.3 Stationary Solutions and the Time-Independent Schrödinger Equation 23
4.4 Interpretation of The Hamiltonian Eigenvalues 24
4.5 The Hamiltonian as a Hermitian Operator 25
4.6 Properties of the Stationary Solutions 27
5 Energy Quantization 31
5.1 The Energy Spectrum 31
5.2 The “Quantum Size Effect
“
32
5.3 Energy Quantization for a “Particle-in-a-Box
“
34
5.4 Energy Quantization for a “Particle-on-a-Ring
“
37
5.5 Particles in Three-Dimensional Boxes: Quantum Wells, Wires, and Dots 40
6 Wave Function Penetration, Tunneling,
and Quantum Wells 46
6.1 The Scanning Tunneling Microscopy 46
v
Published online by Cambridge University Pressvi Contents
6.2 A Particle in a Finite Square Well Potential and Wave Function
Penetration 48
6.3 The Schrödinger Equation for a Piecewise Constant Potential Energy 52
6.4 The Symmetric Double Well Potential and Quantum Tunneling 54
6.5 A Particle in Multiple Quantum Wells and Energy Bands 59
7 The Continuous Spectrum and Scattering States 61
7.1 The Continuity Equation and the Probability Current Density 61
7.2 Scattering in One Dimension 63
7.3 Degeneracy of Scattering States 67
7.4 Scattering from a Single Potential Barrier or Well 68
7.5 The Resonant Tunneling Phenomenon 71
8 Mechanical Vibrations and the Harmonic Oscillator Model 74
8.1 Molecular Vibrations 74
8.2 The Normal Modes of a Many-Particle System and the Harmonic
Approximation 75
8.3 The Solutions of the Schrödinger Equation for the Harmonic Oscillator 78
8.4 The Infrared Absorption Spectrum of Diatomic Molecules 82
8.5 Dirac’s Ladder Operators 85
9 Two-Body Rotation and Angular Momentum 88
9.1 The Two-Body Problem with a Central Potential 88
9.2 Angular Momentum Eigenstates 91
9.3 The Rigid Rotor Model and Rotational Spectrum of Diatomic
Molecules 97
9.4 Beyond the Rigid Rotor Model: Vibration–Rotation Coupling 100
10 The Hydrogen-Like Atom 106
10.1 Rydberg’s Formula 106
10.2 The Stationary States of a Hydrogen-Like Atom 107
10.3 Probability Density Distributions and Atomic Orbitals 116
11 The Postulates of Quantum Mechanics 122
11.1 A Summary of the Postulates 122
11.2 The Hilbert Space of Proper Quantum States and Dirac’s Notations 127
11.3 Extending the Vector Space to Include Improper States 132
11.4 Rationalizing The Postulates 135
11.5 The Continuous Position and Momentum Representations 139
11.6 The Vector Space of Multidimensional Systems 143
An Example: The Vector Space of a Particle in a Three-Dimensional
Coordinate Space 147
11.7 Ensemble Measurements and the Uncertainty Principle 151
Published online by Cambridge University Pressvii Contents
12 Approximation Methods 155
12.1 Perturbation Theory for the Time-Independent Schrödinger Equation 155
12.2 Perturbation Theory in Action 161
The Two-Level System 161
“Hybridization
“
of Atomic Orbitals 168
The Stark Effect 175
Envelope Function Approximations in Quantum Wells 177
12.3 The Variation Approach 182
The Variation Principle 184
Nonlinear Variation 185
The Method of Linear Variation 187
The Mean-Field Approximation 192
13 Many-Electron Systems 200
13.1 The Electron Spin 200
13.2 Spin and Identical Particles 206
13.3 The Electronic Structure of Many-Electron Atoms 212
Slater’s Determinant and Pauli’s Exclusion Principle 213
The Hartree--Fock Approximation 214
The Periodic Table of the Elements 222
13.4 Two-Electron Spin-Orbital Functions – Singlet and Triplet States 227
14 Many-Atom Systems 237
14.1 The “Chemical Space
“
and Many-Atom Systems 237
14.2 The Born–Oppenheimer Approximation 238
Breakdown of the Born--Oppenheimer Approximation 245
The Non-Crossing Rule and Conical Intersections 247
14.3 Covalent Bonds: the Hydrogen Molecular Ion, H
+
2
248
14.4 Linear Combinations of Atomic Orbitals (LCAO) in Molecules 256
LCAO for Atom Pairs 258
Effective LCAO: Symmetry and Energy Compatibility 262
The Simple Hückel Model for Conjugated Polyene Molecules 268
14.5 Extended Systems and Energy Band Formation 273
The Bloch Theorem 274
LCAO for Extended Systems 278
Conductors and Insulators 280
15 Quantum Dynamics 286
15.1 Time-Independent Hamiltonians 286
The Two-Level System (a “Qubit
“
) 289
15.2 Unitary Evolution 292
15.3 Time-Dependent Unitary Transformations 295
The Interaction Picture Representation 296
The Heisenberg Picture 297
Published online by Cambridge University Pressviii Contents
15.4 Quantum-Classical Correspondence 298
Gaussian Wave Packets 300
The Coherent State 305
15.5 Transition Probabilities and Transition Rates 307
15.6 Time-Dependent Perturbation Theory 310
A Constant Perturbation 313
Monochromatic Driving 316
16 Incoherent States 320
16.1 Mixed Ensembles 320
16.2 The Density Operator 322
16.3 Liouville’s Space 324
16.4 The Liouville–von Neumann Equation 326
16.5 Equilibrium States 327
The Canonical Ensemble 331
The Grand Canonical Ensemble 332
17 Quantum Rate Processes 334
17.1 Transition Rates between Pure States 334
17.2 The Emergence of a Rate Constant and Fermi’s Golden Rule 336
17.3 Thermal Rate Constants 344
18 Thermal Rates in a Bosonic Environment 350
18.1 The Spin-Boson Model 350
18.2 Charge Transfer in a Polarizable Medium 352
Nonadiabatic Charge Transfer 353
The Model Hamiltonian 355
Thermal Charge Transfer Rates 359
The “Golden Rule
“
Rate 362
The Semiclassical Limit and Marcus Formula 363
18.3 Radiation Absorption and Emission 367
The Model Hamiltonian 368
Thermal Absorption and Emission Rates 372
The “Golden Rule
“
Rates 375
The Semiclassical Limit 376
Vibronic Spectra 379
18.4 Förster Resonant Electronic-Energy (Exciton) Transfer (FRET) 382
The Model Hamiltonian 383
Thermal Energy Transfer Rates 386
19 Open Quantum Systems 391
19.1 Exact Reduced System Dynamics 391
Hilbert Space Projectors 392
Liouville Space Projectors 393
Published online by Cambridge University Pressix Contents
19.2 The Born–Markov Approximation in the System Hilbert Space 395
Irreversible Dynamics and Exponential Decay 396
19.3 The Born–Markov Approximation in Liouville Space 402
The System-Bath Hamiltonian and Nakajima--Zwanzig
Projectors 404
The Redfield Equation 406
19.4 The Stationary Born–Markov Approximation 409
Population Transfer and the Pauli Master Equation 411
Pure Dephasing 417
19.5 The Dissipative Qubit 419
Absorption, Stimulated Emission, and Spontaneous Emission 423
Coherence Transfer and the Bloch Equation 424
Diagonal Coupling and Pure Dephasing 428
20 Open Many-Fermion Systems 431
20.1 The Fock Space 431
Fock Space Operators 434
Matrix Representations 437
20.2 The Second Quantization Hamiltonian 441
20.3 Fermi–Dirac Distribution 443
20.4 Impurity Models 445
20.5 Charge Exchange with a Fermion Reservoir 450
Reduced System Dynamics 450
Master Equation 454
The Equilibrium State 456
The Case of a Single-State Impurity 457
20.6 Nonequilibrium Fermion Systems 459
An Impurity Coupled to Several Fermion Reservoirs 460
Charge Transport through Nanoscale Conductors 463
Current through a Single-State Impurity 465
Transport through a Noninteracting Impurity 469
Index 473
Published online by Cambridge University PressPublished online by Cambridge University PressPreface: Who Can Benefit from Reading This Book?
Nanoscience and nano-engineering are rapidly growing fields that break the bound￾aries between classical disciplines such as Physics, Chemistry, Biology, and Engi￾neering. The potential for utilizing nanoscale devices in very different applications,
including, for example, medicine, electronics, or information and data processing,
drives research efforts toward unraveling the way nature works on the nanoscale.
One thing that immediately becomes apparent is that the rules of Quantum Mechan￾ics (QM) are necessary for understanding nature on this scale. In fact, it was the
development of experimental techniques with nanoscale resolution that revealed the
wave–particle duality and contributed to the formulation of QM in the early twentieth
century (for example, the X-ray crystallography contributed to the discovery of the
wave nature of electrons in the Davisson–Germer experiment, discussed in Chapter 1).
Along with the potential for advancement and the growing interest in nanoscience
and nano-engineering comes the challenge of making the principles of QM accessi￾ble and useful to researchers from different fields. Scientists and engineers turning
to nanotechnology from diverse disciplines such as biology, chemical engineering, or
mechanical engineering often lack formal education in QM, and sometimes lack even
the mathematical experience or technical skills needed to learn QM from a stand￾ard introductory textbook. Moreover, the research in nanoscience and engineering is
motivated by “real-world” problems that require rather advanced topics not usually
addressed in introductory textbooks. For example, most textbooks would address the
exact solution of the Schrödinger equation for an isolated hydrogen atom, but not the
“real-world” phenomena of electron tunneling into an atom on a surface, or electron
transfer between impurities in a condensed phase environment. While the mathematics
needed to describe (at least approximately) the latter phenomenon is less cumber￾some in comparison to the analytic solution of the hydrogen atom problem, advanced
applications are excluded from introductory textbooks since they require the introduc￾tion of advanced QM topics relevant to open quantum systems (Chapters 17–19) or
nonequilibrium states (Chapter 20).
In this book we propose a pedagogical approach aimed at making advanced QM
theory accessible for readers interested in QM and its applications in general, for
researchers entering the fields of nanoscience and engineering, as well as for deep
thinkers who wish to master the field. Three features make our approach unique and
different from standard approaches to teaching QM. The first feature is the close rela￾tion to “real-world” phenomena and applications from nanoscience and technology,
which often motivate the theoretical discussions and/or summarize each topic. In many
of the chapters, the study of the theory will be motivated by problems from the realm
xi
https://doi.org/10.1017/9781108877787.001 Published online by Cambridge University Pressxii Preface: Who Can Benefit from Reading This Book?
of nanotechnology, mapping them onto fundamental questions and answering these
questions via acquaintance with the principles of QM. The manifestation of the pos￾tulates and the mathematical structure of the theory in experimental observations will
be emphasized. The second feature is the inclusion of advanced topics (commonly met
in applications to “real-world” problems) within an introductory-level textbook. The
third feature is the “layered” structure of the text, which should be appealing to both
“rigorous” and “easy” readers. For the benefit of the latter, the reading is kept rela￾tively fluent by defining the most technical details and mathematical proofs as exercises
appearing next to the main text. Some of the exercises are standard, but most of them
are guided instructions for proving equations or justifying claims made in the main
text. Just reading these guided exercises may be convincing enough for some of the
more technically oriented readers, while the most rigorous readers would probably
want to actively succeed in solving the exercises, thus gaining a complete hold on any
claim and equation mentioned in the book.
It is emphasized that the postulates and the mathematical structure of nonrelativis￾tic QM are presented at a fairly rigorous level, along with mathematical technicalities
required, for example, for solution of ordinary differential equations or dealing with
tensor product spaces. In this sense, the book can also serve the more rigorous readers
who wish to master the field, including undergraduate and graduate Physics students.
In Chapter 1 we introduce the reader to the necessity for using QM to under￾stand phenomena on the nanoscale, where the wave–particle duality naturally appears.
This chapter leads to a basic introduction to wave functions and probability densi￾ties (Chapter 2), observables as operators (Chapter 3), and the Schrödinger equation
(Chapter 4). While discussing the solutions of the stationary Schrödinger equation
for different model systems in the following chapters (Chapters 5–10), we emphasize
relations to applications in nanotechnology. For example, the ability to control the
observed color (light absorption or emission) associated with nanoparticles of different
size is relevant in numerous applications. This phenomenon motivates our fundamen￾tal discussion of energy quantization in QM in Chapter 5. Indeed, relating “color”
to energy level spacing, we provide a rigorous discussion of energy quantization and
of the “quantum size effect.” Similarly, the discussion of experimental methods for
characterization of nanoscale objects, such as Scanning Tunneling Microscopy (STM),
motivates our theoretical discussion of the quantum tunneling phenomena, first for
bound particles (quantum wells) (Chapter 6), and then for free particles (quantum bar￾riers) (Chapter 7). The latter motivates the introduction of theoretical concepts such as
probability current density and the first encounter with quantum scattering theory. The
investigation of mechanical motions in nanoscale systems by infrared and microwave
spectroscopies motivates our introduction to quantization of vibrations and rotations
in many-atom systems (molecules, solids) and to the fundamental models of the quan￾tum harmonic oscillator and the quantum rigid rotor in Chapters 8–9. In Chapter 10
we address the structure of atoms as the building blocks of matter on the nanoscale by
starting from the solution of the Schrödinger equation for the single-electron (hydrogen
like) atom. After extensive exposure to solutions of the Schrödinger equation for simple
systems in Chapters 5–10, the mathematical formulation and the postulates of QM are
https://doi.org/10.1017/9781108877787.001 Published online by Cambridge University Pressxiii Preface: Who Can Benefit from Reading This Book?
rigorously given in Chapter 11. To establish a basis for the more advanced discussions,
approximation methods based on perturbation theory and on the variation principle
are introduced in Chapter 12. The variation of electronic properties between differ￾ent elements (the periodic table) motivates our discussion of the electronic structure of
many-electron atoms in Chapter 13, within the mean-field (orbital) approximation. In
Chapter 14 the structure of many-atom systems is addressed in molecules and in peri￾odic crystals, where the nature of chemical bonds is analyzed. The relation between the
chemical composition of a material and its electric conductivity is thus also revealed.
The more advanced themes start with a rigorous introduction to quantum dynamics
in Chapter 15 and proceed to quantum thermodynamic systems (mixed ensembles)
in Chapter 16. Elementary rate processes in nanoscale systems are most relevant for
“real-world” applications such as photovoltaic cells or electro-optical devices. Their
study motivates our discussion of transport processes and quantum kinetics. In Chap￾ter 17 the emergence of unidirectional rate processes in QM is introduced within the
framework of time-dependent perturbation theory, where Fermi’s golden rule for the
rate constant is derived. Applications to processes such as light absorption and emis￾sion, charge, and energy (exciton) transfer between impurities in bulk materials and
between molecules in solution are discussed in Chapter 18. In Chapter 19 we address
the dynamics in open quantum systems, the validity of the Markovian approximation,
and the emergence of irreversible dynamics and relaxation to equilibrium. Chapter 20
provides the theoretical basis needed for the description of quantum charge transport
in nanoscale devices under nonequilibrium conditions, motivated by the applications
of molecular electronic devices.
In conclusion, this book exposes the reader to the foundations of quantum mechan￾ics, to the richness of quantum phenomena on the nanoscale, and to the theoretical
understanding of the physics underlying these phenomena. The reader gains a solid
basis in the theory of nonrelativistic QM, its fundamental postulates, and its prac￾tical implementation. The book provides the language and the concepts needed for
addressing more specified QM texts such as advanced textbooks and research arti￾cles dealing with nanoscale phenomena and their applications. Moreover, the reading
and the active learning associated with solving the many guided exercises in this book
aim to provide our readers also with skills that should enhance their own creativity in
addressing “real-world” problems encountered on the nanoscale.
https://doi.org/10.1017/9781108877787.001 Published online by Cambridge University Presshttps://doi.org/10.1017/9781108877787.001 Published online by Cambridge University Press1 Motivation
1.1 The Wave–Particle Duality and de Broglie Wavelength
It so happens that nature does not always follow the strict rules set by classical
mechanics. When attempting to describe phenomena occurring on the nanoscale, this
reality becomes most apparent, as we shall see in numerous examples throughout this
book. The structure of atoms and molecules, the organization of matter at the atom￾istic level, the dynamics of charge and energy in different materials, diffraction and
scattering of electromagnetic radiation or elementary particles from nanoscale struc￾tures, and chemical reactivity are but a few phenomena that cannot be explained within
the realm of classical mechanics.
As a concrete example of the breakdown of classical mechanics on the subnanometer
length scale, let us consider the scattering of an electron beam from a surface of a metal,
as studied by Davisson and Germer in the year 1927 [1.1]. The electron beam was
initially regarded as a flux of particles (the electrons) in classical terms. Considering
the mass and kinetic energy, E, each electron is associated with a linear momentum
p = (px, py, pz), where (neglecting relativistic corrections)
p
2 = 2mE. (1.1.1)
In the simplest terms, the metal acts as a perfect mirror when reflecting the electron
beam. In the scattering process, the momentum flips its sign in the direction perpen￾dicular to the surface (e.g., (px, py, pz) → (px, py,−pz)), and consequently, the angle
between the direction of the reflected beam and the surface plane (αout) equals the
impact angle (αin), as depicted in Fig. 1.1.1.
According to this classical interpretation, the reflected flux at αout(= αin) should
depend on the incoming particle flux, but not on the energy of each particle, E. Yet,
z e
αin αout
tFigure 1.1.1 The classical description of electron beam scattering from a metal surface.
1
https://doi.org/10.1017/9781108877787.002 Published online by Cambridge University Press2 Motivation
d
e
αin
λ
tFigure 1.1.2 The wave description of electron beam scattering from a metallic crystal. The pathway of wave scattering from the
internal atomic layer is longer by 2d sin(α)in comparison to wave scattering from the outer layer, resulting in wave
interference.
in the famous Davisson–Germer experiment a clear dependence of the reflected flux
on the energy of the incoming electrons was observed. Moreover, the intensity of the
reflected beam showed distinctive maxima at specific E values, which was reminiscent of
the result of electromagnetic wave reflection from ordered atomic crystals (X-rays, in
particular). This result couldn’t be interpreted within classical mechanics.
In wave theory, modulations in the reflected flux can be readily explained in terms
of interference of waves originating from different sources, or incoming through dif￾ferent pathways. When waves are scattered from an atomic crystal, the first and second
atomic layers can be regarded as two reflecting mirrors displaced from each other by the
interatomic distance, d. (Scattering from deeper layers may be neglected for moderate
beam energies when the penetration of the beam into the crystal is low.) For particle
scattering, the reflection from the two mirrors is additive and therefore equivalent to
an effective single mirror. In contrast, for wave scattering, the two mirrors define two
scattering pathways with remarkable consequences for the reflected flux owing to inter￾ference. In particular, when the two pathways differ in length by an integer multiplicity
of the wavelength, λ, the interference is constructive, and the reflected beam intensity
should obtain a maximum. Given the scattering angle, αout(= αin), the two pathways
differ in length by 2d sin(αin) (see Fig. 1.1.2). In this case, constructive interference
should occur for a set of discrete wavelengths, satisfying the (Bragg) condition:
λn =
2d sin(αin)
n
; n = 1,2,3,.... (1.1.2)
According to the wave theory, the reflected flux should therefore depend on the scat￾tering angle, obtaining a set of maximal values as a function of the wavelength. But how
could such a theory apply to a beam of particles? How could one relate the modulation
in the particle’s energy to modulation in some respective wavelength? The experimen￾tally observed similarities between scattering of electrons and of electromagnetic waves
by a metal crystal led Davisson and Germer to conclude that [1.1] “a description of
the occurrence and behavior of the electron diffraction beams in terms of the scatter￾ing of an equivalent wave radiation by the atoms of the crystal, and its subsequent
interference, is not only possible, but most simple and natural.” Indeed, it was already
https://doi.org/10.1017/9781108877787.002 Published online by Cambridge University Press3 1.1 The Wave–Particle Duality and de Broglie Wavelength
proposed by Louis de Brogliede-Broglie in 1924 [1.2] that a beam of particles (electrons,
included) can be associated with a wavelength, according to the following postulate:
λ ≡
h
p
, (1.1.3)
where h is Planck’s constant (already known by then, from the theory of electromag￾netic radiation [1.3]), and p is the particle’s momentum in the direction of the beam
propagation. The Davisson–Germer experiment reinforced a dual description of an elec￾tron beam in terms of both particles and waves. The maxima in the reflected beam flux as
a function of the electron energy (E) could be correlated with wave properties not only
qualitatively, but also quantitatively. By implementing the conditions for constructive
wave interference (such as Eq. (1.1.2)), the de Broglie relation between momentum and
wavelength (Eq. (1.1.3)), and the classical relation between the momentum and energy
(Eq. (1.1.1)), that is, λn = √
h
2mEn
, the maxima in the reflected flux as a function of the
kinetic energy of the electrons could be explained.
Notice that while the wave properties of the electron beam turn out to be inherent
to its nature, their manifestation in the experiment required special conditions. For
the different interference peaks in the reflected flux to be distinctively resolved, the
ratio (λn − λn+1)/λn+1 should not be too small. From Eq. (1.1.2) it follows that this
ratio equals 1/n, which means that the wave properties are most clearly pronounced
for n = 1, or in physical terms, when the de Broglie wavelength of the electrons is of
the order of the interatomic distance, λ1 = 2d sin(αin). As the de Broglie wavelength
of the electrons becomes smaller (λn/d << 1), for example, at higher kinetic energies,
n becomes too large to enable resolving specific interference peaks. Therefore, the dis￾covery of the wave nature of the electron required that the de Broglie wavelength (set by
the kinetic energy) would be of the order of the (subnanometer) interatomic distances
in the atomic crystal. Moreover, the quantitative verification of de Broglie’s relation
(Eq. (1.1.3)) was based on prior knowledge of the interatomic distance (d), which was
already inferred from X-ray diffraction measurements. Remarkably, it took more than
two centuries after the establishment of classical mechanics for the revelation of the
electron’s wave–particle duality. The characterization of the structure of matter on the
subnanometer scale was an essential precondition for this discovery.
Exercise 1.1.1 The distance between adjacent atomic layers in a nickel crystal is
d = 2.03×10−10meter. An electron beam is scattered from the face of the crystal at an
angle, αin = 45o
. Given the electron mass, m = 9 · 10−31 kg, calculate the kinetic energy
for the three most resolved maxima in the reflected flux at αout = 45o (see Figs. 1.1.1 and
1.1.2).
Exercise 1.1.2 In the “classical world,” the de Broglie wavelength is typically much
smaller than the characteristic length scale of the system under consideration. Consider,
for example, a tennis ball at a mass m = 0.058 kg, flying at a typical serve-velocity, for
example, 50 meter/sec. What is the associated de Broglie wavelength? How does it com￾pare with the length of a tennis court (24 meter), or with the diameter of the ball itself
(6.7 cm)?
https://doi.org/10.1017/9781108877787.002 Published online by Cambridge University Press4 Bibliography
1.2 Quantum Mechanics for Nanoscience and Engineering
Quantum mechanics, as detailed in the following chapters of this book, provides a
theoretical framework that accounts consistently and comprehensively for the wave–
particle duality. Indeed, any matter is associated with wave properties, which are
expressed most profoundly when the associated de Broglie wavelength is of the order
of the characteristic length scale of the system under consideration,
λ ≈ d. (1.2.1)
In the realm of nanoscience and engineering, the characteristic length scales are
associated with the typical dimensions of atoms (10−10m), molecules (10−9m), or
nanocrystals (10−8 m). The relevant masses are those of electrons (∼ 10−30 kg) and
small atoms (∼ 10−28 −10−27 kg), and the relevant kinetic energy scales are typically
∼ 10−2 −101
eV. Translating the masses and energy values to wavelength according to
de Broglie (Eq. (1.1.3)), it immediately follows that the condition for manifestation of
wave properties, Eq. (1.2.1), is often fulfilled. Quantum mechanics is therefore essential
for a proper description of phenomena associated with the nanoscale. These include,
for example, the colors of matter (absorption spectra of atoms, molecules, nanoparti￾cles, etc.), electrical conductivity, interatomic forces, the structure of matter, chemical
reactivity, heat and energy transport, and many more.
Bibliography
[1.1] C. Davisson and L. H. Germer, “Diffraction of electrons by a crystal of nickel,”
Physical Review 30, 705 (1927).
[1.2] L. de Broglie, “Recherches sur la théorie des quanta” (doctoral dissertation,
Migration-université en cours d’affectation, 1924).
[1.3] M. Planck, “Zur Theorie des Gesetzes der Energieverteilung im Normalspec￾trum,” Verhandlungen der Deutschen Physikalischen Gesellschaft 2, 237 (1900).
https://doi.org/10.1017/9781108877787.002 Published online by Cambridge University Press2 The State of a System
2.1 Probability Densities
In this chapter we shall get some informal familiarity with fundamental assumptions
(postulates) of quantum mechanics, which deal with the perception of the state of a
closed quantum system (a formal and complete presentation of the postulates is given
in Chapter 11 of this book). Imagine a collection of well-resolved particles in the sense
that to characterize their collective physical state, we only need to know the properties
of the particles themselves (e.g., position, momentum), their mutual interactions, and
any conservative external forces acting on them. These particles constitute a closed sys￾tem. According to the postulates of quantum mechanics, the state of a closed system is
associated with a proper, complex-valued wave function, ψ(t), which contains all measur￾able information on the system at time, t. The function, ψ(t) depends on time as well as
on variables that represent the system, that is, ψ(x1, x2, x3,...,t). The number of these
variables reflects the number of particles and the dimensions of the relevant physical
space.
As a concrete example, let us consider a single point particle, whose motion is
restricted to a single dimension and confined to some region in space. Denoting by
x the position of the particle in this one-dimensional space (−∞ < x < ∞), any measur￾able property of the particle is contained in a proper wave function, ψ (x,t). A property
of natural interest is the position of the particle at time t; namely, we may wish to know,
Where is the particle? However, according to another postulate of quantum mechan￾ics, this question does not have a unique answer. Instead, we can obtain an answer to
the question, What is the probability of finding the particle in a given region of space?
This information is encoded in the wave function, ψ(x,t), which defines the probabil￾ity density, ρ(x,t), for locating the particle near a point, x, at time t. According to the
postulate,
ρ(x,t) ≡ ψ
∗
(x,t)ψ(x,t) = |ψ(x,t)|
2
. (2.1.1)
Here ψ
∗ denotes the complex conjugate of the complex-valued wave function, ψ. The
wave function therefore obtains the meaning of a probability amplitude. Notice that the
probability of locating the particle at any specific point must vanish, since a point has
a zero measure. (This is true for the probability of measuring any physical quantity
with a continuous set of measurable values.) Nevertheless, the probability of locat￾ing the particle anywhere between two points is finite. In particular, the probability
5
https://doi.org/10.1017/9781108877787.003 Published online by Cambridge University Press6 The State of a System
z r
x
x = r sin(θ) cos(ϕ)
y = r sin(θ) sin(ϕ)
z = r cos(θ) y
θ
ϕ
tFigure 2.1.1 Cartesian and spherical coordinate representations of a position vector.
of locating the particle within an infinitesimal interval dx at the vicinity of the point x
equals ρ(x,t)dx. For a finite interval, one needs to integrate; namely, the probability
of locating the particle between points a and b at time t is given as
P[a,b]
(t) =
w
b
a
ρ(x,t)dx =
w
b
a
|ψ(x,t)|
2
dx. (2.1.2)
Similarly, the probability of locating the particle anywhere in space should be a unity
at any time, namely,
Ptotal =
w∞
−∞
ρ(x,t)dx =
w∞
−∞
|ψ(x,t)|
2
dx = 1. (2.1.3)
(The fact that Ptotal is indeed time-independent is assured by additional postulates, to
be discussed in the following chapters.)
Generalizations for multidimensional coordinate spaces are straightforward.
For a single particle in a three-dimensional space, the probability density for
locating the particle in an infinitesimal volume element in the vicinity of a
point in space reads |ψ(x, y,z,t)|
2 dxdydz in a Cartesian coordinate system, or
|ψ(r,θ,φ,t)|
2
r
2
sin(θ)drd θd φ in spherical coordinates (see Fig. 2.1.1). For a system
of N particles in a D-dimensional coordinate space, the wave function depends on
time t and on N × D spatial coordinates. The probability of locating simultaneously
each of the particles in the vicinity of a certain point in space reads (e.g., in Cartesian
coordinates) |ψ(x1, y1,z1; x2, y2,z2;...,t)|
2dx1dy1dz1dx2dy2dz2 ....
The association of the wave function with a probability density implies that the wave
function obtains physical dimensions, which depend on the system. For N particles in
a D-dimensional space, ψ(t) obtains the dimensions:
[ψ(t)] = [length]
−N×D/2
. (2.1.4)
2.2 Proper Wave Functions
The properties of a closed system are therefore encoded in a proper wave function. But
what does “proper” mean? The association of |ψ(t)|
2 with a probability density in the
physical space imposes strict limitations on the properties of ψ(t) itself. Particularly, to
https://doi.org/10.1017/9781108877787.003 Published online by Cambridge University Press7 2.2 Proper Wave Functions
−1.5
−4 −2 0
x
2 4
−1
−0.5
0
0.5
1
1.5 ψ (x)
|ψ (x)|
2
tFigure 2.2.1 A proper one-dimensional wave function and the respective probability density for locating the particle in space.
−3
−10 −5
x
5 10
−2
−1
0
1
2
3
ψ (x)
|ψ (x)|
2
−3
−10 −5 0
x
5 10
−2
−1
0
1
2
3
ψ (x)
|ψ (x)|
2
0
tFigure 2.2.2 Improper one-dimensional wave functions and their respective absolute squares. The left and right plots represent
periodic and diverging functions, respectively.
fulfil the condition in Eq. (2.1.3), the wave function must not be identically zero, and at
the same time, the integral of |ψ(t)|
2 over the entire space must obtain a finite positive
value. In mathematical terms, a proper wave function must be square-integrable.
For example, let us refer to a one-dimensional Cartesian space. Since the probability
density (|ψ(x,t)|
2
) is nonnegative, a proper wave function must satisfy the following
boundary conditions:
ψ(x,t) −→x→±∞
0. (2.2.1)
In Fig. 2.2.1, a specific proper one-dimensional wave function and the respective prob￾ability density are plotted for illustration. Examples of improper functions and their
respective absolute value squares are shown in Fig. 2.2.2.
Generalization of the one-dimensional condition (Eq. (2.2.1)) to multidimensional
systems is straightforward: a wave function is proper only if the corresponding
https://doi.org/10.1017/9781108877787.003 Published online by Cambridge University Press8 The State of a System
probability for locating any part of the system in an infinitesimal volume vanishes at
the boundaries of the (multidimensional) coordinate space.
Note that the boundary conditions that are necessary for “properness” are but the
first constraint on wave functions that can be associated with the state of a physical
system. In the following chapters we shall get familiar with the Schrödinger equation,
which imposes additional physical as well as mathematical constraints on ψ (t) for any
given system.
2.3 Normalization
Notice that for any proper wave function, ψ (t), the integral of |ψ (t)|
2 over the entire
space obtains a finite positive value. Nevertheless, to associate ψ (t) with a probability
density, as in Eqs. (2.1.2) and (2.1.3), the integral should equal unity. A proper wave
function that satisfies the latter condition is termed “normalized.”
Any given proper wave function can become normalized by multiplying it by a constant
number. For example, given a proper wave function, ψ(x,t), we have r∞
−∞
|ψ(x,t)|
2 dx =
N, where N is some finite positive number. The corresponding normalized wave func￾tion is given as ψ˜(x,t) = √
1
N
ψ(x,t), where the condition for probability conservation
(Eq. (2.1.3)) immediately follows: r∞
−∞
dx|ψ˜(x,t)|
2 =
r∞
−∞
dx 1
N
|ψ(x,t)|
2 =
N
N = 1.
The normalization procedure can be readily generalized for different coordinate sys￾tems and to higher dimensions. For example, for a single point particle moving on
a perfect ring, the particle’s position is defined by an angular variable, 0 ≤ φ < 2π.
s
Given any proper wave function, ψ(φ,t), the normalized wave function reads ψ˜(φ,t) =
1
2rπ
0
dφ|ψ(φ,t)|
2
ψ(φ,t). Or, for a particle moving in three dimensions, the normalized
wave function would be ψ˜(x, y,z,t) = s 1
r∞
−∞
dx
r∞
−∞
dy r∞
−∞
dz|ψ(x, y,z,t)|
2
ψ(x, y,z,t).
Exercise 2.3.1 The probability density of finding a point particle along the x-axis at a
certain time is given by ρ(x) = αe
−
(x−x0)
2
2σ2
. (a) What is the most probable position for this
particle? (Does it depend on the value of α?). (b) Determine the value of α for which the
probability density is normalized, recalling that
−r∞
−∞
e
−βy
2
dy =
qπ
β
. (c) The average posi￾tion associated with a probability density, ρ(x), is defined as hxi ≡
−r∞
−∞
xρ(x)dx. Calculate
the average position of the given point particle. (d) The corresponding standard devia￾tion in the position probability distribution is defined as ∆x ≡
p
hx
2i− hxi
2
. Calculate the
standard deviation in the position of the given point particle.
https://doi.org/10.1017/9781108877787.003 Published online by Cambridge University Press9 2.3 Normalization
Exercise 2.3.2 The state of a particle is described as a “superposition of wave functions,”
namely, ψ (x) =
∞
∑
n=1
cnϕn(x), where {cn} are given scalar expansion coefficients, and
{ϕn(x)} is a given set of “orthonormal wave functions,” namely, r∞
−∞
ϕ
∗
m(x)ϕn(x)dx =
(
0 m 6= n
1 m = n
. Normalize ψ(x). (Express the normalized wave function in terms of the
given expansion coefficients.)
Exercise 2.3.3 An isolated hydrogen-like atom is composed of a nucleus with Z protons
and a single electron. At the minimal energy state of the atom, the probability density
for finding the electron at a given position reads ρ(r)= αe
−2Zr/a0 ; r = |r|, where r is the
three-dimensional vector of the relative position between the nucleus and the electron, and
a0 = 0.0529 nm is the Bohr radius. Show that the most probable distance r between the
electron and the nucleus in this state is a0/Z. What is the probability density of finding
the electron at the most probable distance, r, in this state?
https://doi.org/10.1017/9781108877787.003 Published online by Cambridge University Press3 Observables and Operators
3.1 Physical Observables and Operators
According to quantum mechanics, the information with respect to the physical
properties of a system is contained in a mathematical object, the wave function,
ψ(t). Here we elaborate on the mathematical representation of the physical properties
themselves. Particularly, we shall start from the most elementary dynamical variables
needed to describe a system of particles, namely, the particles’ positions in space and
their momenta (or velocities, given their masses). Then, we shall move on to properties
that are derived from the particles’ positions (e.g., potential energy), momenta (e.g.,
kinetic energies), or both (e.g., angular momenta).
The postulates of quantum mechanics associate each measurable property with a
specific operator, namely, a unique mathematical operation that maps one proper func￾tion on another. For example, let us consider the operator that maps any function on
its derivative. The equation d
dx f(x) = g(x) can be written as Dˆ
x f(x) = g(x), where Dˆ
x
marks the derivative operator with respect to x. (Operators are denoted by the hat
superscript). It follows that: Dˆ
xx
2 = 2x, Dˆ
x sin(x) = cos(x), Dˆ
xc = 0, and so on. Other
common operators are multiplication operators. For example, multiplying any func￾tion f(x) by the function g(x) can be written as g(x)· f(x) = G f ˆ (x), where Gˆ is the
corresponding operator.
A critical point to notice is that operators do not necessarily commute. Namely,
the result of two successive operations on a function may lead to different results,
depending on the order in which the operators are applied. For example, consider￾ing the operators Dˆ
x and Gˆ just defined, we readily obtain Dˆ
xG f ˆ (x) = [ d
dxg(x)] f(x) +
g(x)
d
dx f(x), whereas changing the order yields GˆDˆ
x f(x) = g(x)
d
dx f(x). It follows
that GˆDˆ
x 6= Dˆ
xGˆ. This property is expressed in terms of the commutator (or
the commutation relation). For any two operators, Aˆ and Bˆ, the commutator is
defined as
[Aˆ,Bˆ] ≡ AˆBˆ −BˆAˆ. (3.1.1)
If Aˆ and Bˆ commute with each other, then [Aˆ,Bˆ] = 0, and the order of operations on
any (proper) function does not matter. Otherwise, the operators do not commute with
each other, and the order of operations must be carefully specified.
An important feature of the operators that correspond to measurable properties (we
shall often term such operators hereafter as “quantum mechanical operators”) is their
10
https://doi.org/10.1017/9781108877787.004 Published online by Cambridge University Press11 3.2 The Canonical Operators
linearity. An operator Aˆ is linear if for any two functions, f1(x) and f2(x) (in the space
of proper functions), and for any (complex valued) scalars a1,a2, we have
Aˆ [a1 f1(x) +a2 f2(x)] = a1A f ˆ
1(x) +a2A f ˆ
2(x). (3.1.2)
Exercise 3.1.1 Write explicit expressions for the following commutators: [sinx,
d
dx ],
[
1
x
,
d
dx ],[
d
dx ,
d
2
dx2
].
Exercise 3.1.2 Verify the following identities for any linear operators (Aˆ , Bˆ , Cˆ ):

Aˆ , Bˆ

= −

Bˆ , Aˆ

;

Aˆ , Bˆ +Cˆ

=

Aˆ , Bˆ

+

Aˆ , Cˆ

;

Aˆ , Bˆ Cˆ

=

Aˆ , Bˆ

Cˆ +Bˆ

Aˆ , Cˆ

.
Exercise 3.1.3 The operators: Aˆ ; Bˆ ; Cˆ ; D are defined by the results of their oper- ˆ
ation on any function f(x): Aˆ f(x) = x
n
f(x); Bˆ f(x) = d
dx f(x); Cˆ f(x) = sin(f(x));
Dˆ f(x) = p
f(x). Which ones are linear?
Exercise 3.1.4 Given that Aˆ and Bˆ are linear operators, show thatCˆ = AˆBˆ and Dˆ = Aˆ +Bˆ
are also linear operators.
Exercise 3.1.5 Dˆ is a linear differential operator, and ϕ and φ are two solutions of the
homogeneous linear equation defined by Dˆ,
Dˆ ϕ = 0 ; Dˆφ = 0.
Show that any linear combination of ϕ and φ (i.e., aϕ +bφ with constant scalars a and
b) is also a solution of the homogeneous equation (the “superposition principle”).
3.2 The Canonical Operators
The postulates of quantum mechanics identify the operators corresponding to the position
and the momentum of a particle restricted to a given Cartesian axis (x) as
xˆ = x· (3.2.1)
pˆ
x = −ih¯
d
dx
; (i =
√
−1, h¯ =
h
2π
). (3.2.2)
The position is a simple multiplication operator, namely, xˆψ(x) = xψ(x) for any
ψ(x). It is a local operator in the sense that the value of xˆψ(x) at a certain
position along the x-axis depends on ψ(x) only at that position. The momentum
involves a derivative with respect to the position and a multiplication by −ih¯, where
h = 6.62607004×10−34 m2kg/s is Planck’s constant. The momentum is a nonlocal
operator in the sense that the value of pˆxψ(x) at a point depends on the function at
the vicinity of this point. The commutator of these two canonical operators reads
[xˆ, pˆ
x
] = ih¯. (3.2.3)
https://doi.org/10.1017/9781108877787.004 Published online by Cambridge University Press12 Observables and Operators
In a three-dimensional coordinate space, the position and momentum of a particle
correspond to vector operators. In a Cartesian coordinate system,
rˆ = (xˆ, yˆ,zˆ), (3.2.4)
pˆ = (pˆx, pˆy, pˆz) = −ih¯(
∂
∂ x
,
∂
∂ y
,
∂
∂ z
) = −ih¯∇, (3.2.5)
where, for example, ∂
∂ x
is the partial derivative with respect to the coordinate x, and
∇ is the gradient vector, ∇ψ(x, y,z) = ∂ψ(x,y,z)
∂ x
i +
∂ψ(x,y,z)
∂ y
j +
∂ψ(x,y,z)
∂ z
k, (where i, j, and
k are the unit vectors defining the Cartesian system axes). Representations of these
operators in different coordinate systems are obtained straightforwardly by the proper
transformation of variables.
Exercise 3.2.1 Show that, [rˆ,pˆ] = 3ih¯.
3.3 The Angular Momentum Operators
The definitions of the canonical operators enable us to associate other dynamical vari￾ables with operators in a consistent manner, based on their relations to the position
and momentum variables as known in classical mechanics. Particularly, we can derive
an explicit form for the angular momentum operators for a single particle, using the
classical relation, L = r×p. Associating the position and momentum vectors with the
respective operators (Eqs. (3.2.4, 3.2.5)), the angular momentum vector operator reads
Lˆ = rˆ ×pˆ = (Lˆ
x,Lˆ
y,Lˆ
z), (3.3.1)
where
Lˆ
x = yˆpˆ
z −zˆpˆ
y
Lˆ
y = zˆpˆ
x −xˆpˆ
z
Lˆ
z = xˆpˆ
y −yˆpˆ
x
. (3.3.2)
Using the commutator of the canonical operators, we readily obtain the set of
commutation relations between the different angular momentum operators,
[Lˆ
x,Lˆ
y] = ih¯Lˆ
z
,
[Lˆ
y,Lˆ
z
] = ih¯Lˆ
x,
[Lˆ
z
,Lˆ
x] = ih¯Lˆ
y.
(3.3.3)
Defining the total angular momentum operator,
Lˆ
2 ≡ Lˆ
2
x +Lˆ
2
y +Lˆ
2
z
, (3.3.4)
we obtain
[Lˆ
2
,Lˆ
x] = [Lˆ
2
,Lˆ
y] = [Lˆ
2
,Lˆ
z
] = 0. (3.3.5)
Exercise 3.3.1 Prove the relations in Eqs. (3.3.3, 3.3.5).
https://doi.org/10.1017/9781108877787.004 Published online by Cambridge University Press13 3.4 Functions of Operators
3.4 Functions of Operators
Physical properties that depend on a particle’s position and/or momentum in classical
mechanics are associated with quantum mechanical operators, which are the respective
functions of the canonical operators.
A function f of an operator Aˆ is defined as its power series, f(Aˆ) ≡
∞
∑
n=0
fnAˆn
(Taylor’s
expansion, for analytic functions). { fn} are the expansion coefficients of the function
f(α), namely, f(α) ≡
∞
∑
n=0
fnα
n
, for any scalar variable α.
Exercise 3.4.1 Show that the following function of the linear momentum operator,
Mˆα = e
iα
h¯
pˆx
, is a displacement operator, namely, Mˆαψ(x) = ψ(x + α), where α is a
constant.
As an example, consider a particle of mass m moving along the x-axis. In classi￾cal mechanics, the particle’s potential energy is a function of its position in space,
V = V(x), whereas the particle’s kinetic energy is a function of its linear momentum,
Tx = p
2
x/(2m).
The corresponding quantum mechanical operator associated with the particle’s
potential energy therefore reads
Vˆ
x = V(xˆ). (3.4.1)
Using the formal power expansion of the function V, we obtain
Vˆ
xψ(x) =
∞
∑
n=0
Vnxˆ
nψ(x) =
∞
∑
n=0
Vnx
nψ(x) = V(x)ψ(x), (3.4.2)
where we have used the identification of xˆ as a multiplication operator (Eq. (3.2.1)).
Similarly, the quantum mechanical operator associated with the particle’s kinetic
energy obtains the form
Tˆ
x =
1
2m
(pˆ
x
)
2
. (3.4.3)
Here we use the identification of the momentum operator, pˆ
x
, Eq. (3.2.2), to obtain
Tˆ
xψ(x) = 1
2m
(−ih¯
d
dx
)
2ψ(x) = −h¯
2
2m
d
2
dx
2
ψ(x). (3.4.4)
As we can see, the potential energy corresponds to a local (multiplication) operator,
whereas the kinetic energy is a nonlocal (second derivative) operator, in accordance
with the properties of the canonical position and momentum operators.
In three dimensions, the position and momentum operators are vectors (Eqs. (3.2.4,
3.2.5)), and the corresponding potential and kinetic energy operators read
Vˆ
rψ(r) = V(r)ψ(r), (3.4.5)
Tˆ
rψ(r) = −h¯
2
2m
∇·∇ψ(r) = −h¯
2
2m
∆ψ(r). (3.4.6)
https://doi.org/10.1017/9781108877787.004 Published online by Cambridge University Press14 Observables and Operators
Here, ∆ is the Laplacian operator, for example, using Cartesian coordinates,
∆ψ(x, y,z) = ( ∂
2
∂ x
2 +
∂
2
∂ y
2 +
∂
2
∂ z
2
)ψ(x, y,z).
The generalization to many-particle systems is straightforward. Considering a sys￾tem of N particles with masses m1,m2,...,mN and respective coordinates r1, r2,..., rN,
the potential and kinetic energy operators read
Vˆ
r1,r2,...,rN ψ(r1, r2,..., rN) = V(r1, r2,...,rN)ψ(r1, r2,..., rN), (3.4.7)
Tˆ
r1,r2,...,rN ψ(r1, r2,..., rN) =
N
∑
i=1
−h¯
2
2mi
∆riψ(r1, r2,..., rN). (3.4.8)
Finally, we can associate the Hamilton function of classical mechanics [3.1],
H = T + V, for any system of particles, with a quantum mechanical Hamiltonian
operator,
Hˆ ≡ Tˆ +Vˆ . (3.4.9)
The Hamiltonian has a special role in quantum mechanics. In addition to the repre￾sentation of the total (kinetic and potential) energy of the system, the Hamiltonian of
a system uniquely defines the time evolution of the wave function, ψ(t), which con￾tains the entire information on the physical properties of a system. This is formulated
in terms of the time-dependent Schrödinger equation, to be discussed in the following
chapters.
It is instructive at this point to give explicit expressions for the Hamiltonians for
some systems of interest. Let us consider first a single, isolated atom, containing a
nucleus with Z protons and N electrons (for a neutral atom, N = Z). The (negative)
electron charge is denoted e, and the nucleus charge is, accordingly, Z|e|. Without loss
of generality, we consider the nucleus at rest, and we set its position to the origin of
the coordinate system, as illustrated in Fig. 3.4.1. The kinetic energy, Tˆ
e, is therefore a
sum over the kinetic energies of the electrons (each of mass me). The potential energy
is the sum of electrostatic pair interactions between all the charges. It amounts to the
attraction of each electron to the nucleus, Vˆ
en, and the repulsion between the electrons,
Vˆ
ee. The (nonrelativistic) Hamiltonian for an isolated atom, Hˆ = Tˆ
e +Vˆ
en +Vˆ
ee, therefore
reads
Hˆ =
N
∑
i=1
−h¯
2
2me
∆ri +
N
∑
i=1
−KZe2
|ri
|
+
N
∑
j>i
N
∑
i=1
Ke
2
|ri −rj
|
, (3.4.10)
where the electron rest mass is me = 9.1094×10−31 kg, and K = 9.988×109 N×m2 ×
C
−2
is the Coulomb constant. (Notice that an exact account for the physical state of an
isolated atom must also include its interaction with the vacuum state of the electromag￾netic field, as well as relativistic corrections, including spin-orbit coupling. The effect
of these corrections on the energy is comparably small with respect to the electrostatic
interactions, whose contributions are accounted for explicitly in Eq. (3.4.10)).
Now let us consider a molecule composed of n nuclei and a total number of N
electrons. Each nucleus has a mass, mα (α = 1,2,...,n), according to its number
of nucleons, and an electric charge, Zα|e|, according to the number of protons, Zα.
The total kinetic energy is a sum over the kinetic energies of the electrons (each of
mass me) and the nuclei, Tˆ = Tˆ
n + Tˆ
e. The potential energy is the sum of electrostatic
https://doi.org/10.1017/9781108877787.004 Published online by Cambridge University Press15 Bibliography
e
e
r1
r2
r3
r4
e
e
x
y
z
tFigure 3.4.1 Electrons surrounding a nucleus located at the origin. The electron position vectors are denoted ri
.
r1
r2
R2
R1
R3
r3
r4 e
e
e
Z3|e|
Z1|e|
Z2|e|
e
x
y
z
tFigure 3.4.2 Electrons and nuclei charges and positions (denoted as ri and Rα, respectively) in a generic molecule.
pair interactions between all the charges, including the repulsion between the nega￾tively charged electrons, and between the positively charged nuclei, and the attraction
between any electron and all the nuclei, Vˆ = Vˆ
ee +Vˆ
nn +Vˆ
en. Denoting the position
vectors of the ith electron and the αth nucleus in a reference coordinate system as ri
and Rα, respectively (see Fig. 3.4.2), we can write down the (nonrelativistic) quantum
Hamiltonian of any molecule as follows:
Hˆ =
n
∑
α=1
−h¯
2
2mα
∆Rα +
N
∑
i=1
−h¯
2
2me
∆ri
+
n
∑
β>α
n
∑
α=1
Ke2ZαZβ
|Rα −Rβ
|
+
n
∑
α=1
N
∑
i=1
−KZαe
2
|Rα −ri
|
+
N
∑
j>i
N
∑
i=1
Ke2
|ri −rj
|
. (3.4.11)
(As in Eq. (3.4.10), interaction with the electromagnetic vacuum and relativistic
corrections are ignored.)
Bibliography
[3.1] H. Goldstein, “Classical Mechanics,” 2nd ed. (Addison Wesley, 1981).
https://doi.org/10.1017/9781108877787.004 Published online by Cambridge University Press4 The Schrödinger Equation
4.1 The Time-Dependent Schrödinger Equation
In the previous chapters we became familiar with the association of the state of a system
with a proper wave function, ψ(t) and the identification of dynamical observables with
specific operators. Particularly, we became familiar with the Hamiltonian operator (Hˆ),
which corresponds to the total energy (the sum of kinetic and potential energy) of a
system of particles. In this chapter we shall become familiar with another postulate
of quantum mechanics, the one that states that the time-evolution of a given system is
uniquely defined by its Hamiltonian operator. This relation is formulated explicitly in
terms of the time-dependent Schrödinger equation,
ih¯
∂
∂t
ψ(t) = Hˆψ(t). (4.1.1)
Notice that the equation imposes additional constraints on proper wave functions rep￾resenting a given physical system. First, for ψ(t)to be physically relevant, the operation
of Hˆ on ψ(t) must be well defined and must yield a proper wave function, at all times.
Second, being the solution of a first-order differential equation in time, the wave func￾tion representing a system is uniquely defined at any time, given that it is known at a
certain point in time (an initial condition). From an ideal perspective, the experimen￾tal preparation of the system in a given state at a given time, t0, is associated with a
corresponding specific wave function at that time. The wave function then evolves in
time according to the Schrödinger equation, namely under the influence of the sys￾tem’s Hamiltonian, and the information regarding a measurement to be performed at
a future time, t > t0, is encoded in the time-evolving wave function. Notice that for a
given initial condition (i.e., a given state of a set of particles) there can be, in principle,
an infinite number of different Schrödinger equations, accounting for different Hamil￾tonian operators, that represent, for example, different external forces experienced by
the given set of particles.
For a given system (i.e., a given Hamiltonian) there is a unique Schrödinger equation,
but there is an infinite number of different solutions to this equation. By different, we
mean that the solutions are linearly independent, namely, they differ by more than a
multiplication by a constant (which is equivalent to the normalization of the probabil￾ity density function). Mathematically, the different solutions correspond to different
initial conditions; and physically, they correspond to different preparations of the
system, initiating different processes within the system.
16
https://doi.org/10.1017/9781108877787.005 Published online by Cambridge University Press17 4.2 Time-Dependent Solutions
The operator that maps ψ(t0) on ψ(t) is termed the time-evolution operator (or the
propagator,
ψ(t) = Uˆ(t,t0)ψ(t0). (4.1.2)
One can readily see that the Schrödinger equation (Eq. (4.1.1)) means that, Uˆ(t,t0) =
e
−i
h¯
Hˆ(t−t0)
. However, in more advanced formulation of quantum mechanics effective
Hamiltonians are introduced, which may depend explicitly on time (Hˆ 7→ ˆH˜(t)). In such
cases the expression for the time-evolution operator is more involved. (For details, see
the discussion of quantum dynamics and Dyson’s expansion in Chapter 15.) Notice
that time itself is not associated with a quantum mechanical operator, but rather with
a scalar parameter that identifies the system’s evolution. (Advanced formulations in
which time is associated with an operator were proposed, but these are beyond the
scope of the present discussion [4.1].)
4.2 Time-Dependent Solutions
In this section we discuss some examples of time-dependent solutions to Schrödinger
equations. For concreteness we shall focus on systems composed of a single point par￾ticle of mass m, moving along a one-dimensional coordinate x. The state of the particle
is associated with a proper wave function, ψ(x,t). As an initial condition we chose a
normalized “Gaussian wave packet” [4.2],
ψ(x,0) = 
1
2πσ2
1/4
e
−(x−x0
)
2
4σ2 e
ip0x/h¯
. (4.2.1)
This wave function is characterized by three parameters, σ, x0, and p0. One can readily
show (see Ex. 2.3.1) that x0 and σ correspond, respectively, to the particle’s averaged
position in space, < x >=x0, and to the standard deviation in the particle’s position
distribution, σ =
q
hx
2i−hxi
2
. The parameter p0 has no effect on the initial posi￾tion probability density, |ψ(x,0)|
2
(see Eq. (4.2.1)), but has a dramatic effect on the
wave function evolution, ψ(x,t). Indeed, this parameter corresponds to the averaged
initial momentum of the particle, as will be discussed in detail in Chapter 15. Here
we only make a brief intuitive comment in this context: for σ → ∞, one can see that
ψ(x,0) approaches the form of a periodic plane wave in any finite region of space,
ψ (x,0)∝˜ e
ip0x/h¯ ≡ e
i2πx/λ
. Using the de Broglie relation (Eq. (1.1.3)), p0, therefore
obtains the meaning of the particle’s momentum, at least in this limit.
The general Hamiltonian operator for a point particle of mass m, moving along a
one-dimensional coordinate, x, takes the form (see Eqs. (3.4.2, 3.4.4, 3.4.9))
Hˆ =
−h¯
2
2m
∂
2
∂ x
2
+V(x), (4.2.2)
https://doi.org/10.1017/9781108877787.005 Published online by Cambridge University Press18 The Schrödinger Equation
and the corresponding time-dependent Schrödinger equation therefore reads
ih¯
∂
∂t
ψ (x,t) = −h¯
2
2m
∂
2
∂ x
2
ψ(x,t) +V(x)ψ(x,t). (4.2.3)
V(x)isthe potential energy function of the particle, as known from classical mechanics.
The details with respect to a particular system, namely, the conservative forces expe￾rienced by the particle at each point in space, are derived from this function. In what
follows we consider three different choices of V(x), corresponding to different systems,
each associated with a different Schrödinger equation.
Let us consider first the case V(x) = const. This corresponds to a zero net force on
the particle anywhere in space, F(x) = −dV(x)/dx = 0 (a free particle). The time evo￾lution of the initial Gaussian wave packet for a free particle can be obtained by solving
the time-dependent Schrödinger equation analytically (see, e.g. [4.3] and also Chap￾ter 15 in this book). Here we skip the details of the quantitative analysis, focusing on
some qualitative features of the wave function evolution, as represented in Fig. 4.2.1.
In particular, the probability density (ρ(x,t) = |ψ(x,t)|
2
) and the underlying probabil￾ity amplitude (Re[ψ(x,t)]) are plotted at different times. As one can see, the average
position of the particle along the x-axis changes in time, as expected for a freely mov￾ing particle. (A quantitative analysis shows that it increases linearly with time and in
fact follows a classical trajectory for a free particle, < x(t) > =x0 + p0t/m.) In paral￾lel, the position uncertainty as expressed in the standard deviation of the probability
density function (“the width”) increases in time. This broadening effect suggests that
the particle associated with this solution of Schrödinger’s equation does not have a
well-defined momentum. Envisioning, instead, a distribution of momenta, larger and
smaller momentum values should be associated, respectively, with faster and slower
changes of the particle’s position, resulting in broadening of the position probability
density function. This dispersion effect is indeed supported by analyzing the parti￾cle’s momentum distribution (see Chapter 15). It is noticed qualitatively already in
Fig. 4.2.1, where the “local wavelength” in Re[ψ(x,t)] as a function of x becomes
shorter with increasing x, namely, toward the wave packet front along the propaga￾tion direction. (This becomes more apparent at the later times.) Invoking the de Broglie
relation (Eq. (1.1.3)), the shortening of the wavelength translates to increasing momen￾tum toward the front of the wave packet, in accord with the wave packet broadening
effect.
As a second example, we refer to the case where the particle is scattered against a
potential energy barrier,
V(x) = (
0 ; x < 0
V0 ; x ≥ 0
.
The net force on the particle vanishes anywhere in space, except for at the origin, where
it becomes infinite in the direction of decreasing x (a “reflecting” force, toward negative
x). Again, we focus on some qualitative features of the wave function evolution, as rep￾resented in Fig. 4.2.2. The Gaussian wave packet is shown to propagate initially toward
the barrier position, similarly to a free particle (compare to Fig. 4.2.1). In the vicinity
https://doi.org/10.1017/9781108877787.005 Published online by Cambridge University Press19 4.2 Time-Dependent Solutions
Probability Density
0 0
2
800
(a)
(b)
400
t [102 a.u.]
x [ a.u.]
ρ(x,t)
0 −400 −800
4
6
8
Probability Amplitude
0
0
2
800 400
t [102 a.u.]
x [ a.u.]
Re [ψ (x,t)]
0 −400 −800
4
6
8
tFigure 4.2.1 The time evolution of a free particle represented as a Gaussian wave packet. (a) the probability density, ρ(x,t). (b)
the real part of the respective probability amplitude,Re[ψ(x,t)] (the wave function normalization is arbitrary). The
particle’s mass was taken as m = 0.1, and the initial wave packet parameters are x0 = −600, σ = 40/
√
2,
and p0 = 0.1414,all in atomic units (where h¯, the Bohr radius, and the electron rest mass all equal unity).
of the potential energy step the wave is scattered, where the probability density deviates
significantly from the initial Gaussian form. The consecutive dynamics depends on the
barrier energy: for a relatively high barrier ((a) and (b) in Fig. 4.2.2), the wave packet
is scattered primarily backward, resulting in a free particle-like evolution, but in the
direction opposite to the original one. This is reminiscent of the scattering of a classi￾cal particle whose total energy is below the potential energy barrier. For a lower barrier
energy ((c) and (d) in Fig. 4.2.2), the wave packet is shown to split into two parts, one
moving forward in the barrier region, and the other reflected backward. This implies
https://doi.org/10.1017/9781108877787.005 Published online by Cambridge University Press20 The Schrödinger Equation
Probability Density
0 0
2
800 400
t [102 a.u.]
x [ a.u.]
ρ(x,t)
0 −400 −800
4
6
8
(b) Probability Amplitude
(a) Probability Density
0 0
2
800 400
x [ a.u.]
ρ(x,t)
0 −400 −800
4
6
8
(c)
0
0
2
800 400
t [102 a.u.]
x [ a.u.]
Re [ψ (x,t)]
Re [ψ (x,t)]
0 −400 −800
4
6
8
(d) Probability Amplitude
0
0
2
800 400
t [102 a.u.]
x [ a.u.]
0 −400 −800
4
6
8t [102 a.u.]
tFigure 4.2.2 The time evolution of a Gaussian wave packet scattered from a potential energy barrier. Top (a and c): the probability
density, ρ(x,t). Bottom (b and d): the real part of the respective probability amplitude, Re[ψ(x,t)] (the
normalization is arbitrary). The potential energy barriers are also marked for each snapshot. The left column (a and b)
corresponds to a relatively high energy barrier (V0 = 0.5 a.u.), where the probability density appears to be
completely reflected. The right column (c and d) corresponds to a lower energy barrier (V0 = 0.1 a.u.), where the
probability density splits into transmitted and reflected parts. The particle’s mass was taken as m = 0.1, and the
initial wave packet parameters are x0 = −600, σ = 40/
√
2, and p0 = 0.1414, all in atomic units.
that there is a significant probability for the particle to either pass the potential energy
step or be reflected backward. This result has no analogue in the classical description
of a particle’s trajectory. Again, it suggests that the particle associated with such a
solution to the relevant Schrödinger equation does not have a well-defined momen￾tum, as has already been hinted, but rather some combination of negative and positive
momenta.
Finally, let us consider the case of a particle trapped in a potential energy well.
Specifically, we consider the potential of a harmonic oscillator centered at the ori￾gin, V(x) = 1
2mω
2
x
2
, where the particle experiences a position-dependent reflecting
force, F(x) = −mω
2
x. The change in the particle’s position according to classical
mechanics is oscillatory at a frequency, ω. A thorough analysis of the solution to the
https://doi.org/10.1017/9781108877787.005 Published online by Cambridge University Press21 4.2 Time-Dependent Solutions
(a) Probability Density
(b)
0
800 400
t [102 a.u.] t [102 a.u.]
x [ a.u.]
ρ(x,t)
0 −400 −800
10
0
20
10
0
20
Probability Amplitude
0
400
x [ a.u.]
Re [ψ (x,t)]
0 −400
tFigure 4.2.3 The time evolution of a Gaussian wave packet in a harmonic potential energy trap. (a) the probability density,
ρ(x,t). (b) the real part of the respective probability amplitude, Re[ψ(x,t)] (the wave function normalization is
arbitrary). The potential energy is also marked for each snapshot. The harmonic potential frequency was set to
ω = 1/160, the particle’s mass was taken as m = 0.1, and the initial wave packet parameters are x0 = −226,
σ = 40/
√
2, and p0 = 0.1414, all in atomic units.
Schrödinger equation for Gaussian wave packets [4.2] in harmonic potentials will be
given in Chapter 15, where, as in the preceding discussion, here we are interested only
in some qualitative considerations. In Fig. 4.2.3 we present snapshots from the time
evolution of a specific initial Gaussian wave packet (Eq. (4.2.1)) in the potential energy
well. In accord with the classical results, the probability density is confined to the region
of the well. Moreover, both the probability density and the probability amplitude dem￾onstrate periodic time evolution, which are reminiscent of the classical trajectory for a
particle in a harmonic potential well.
https://doi.org/10.1017/9781108877787.005 Published online by Cambridge University Press22 The Schrödinger Equation
The same Schrödinger equation can have different solutions, depending on the
initial conditions. Let us consider again the harmonic potential well, but this time
set the parameters of the initial Gaussian wave packet, x0 and p0, to zero. The
results, as presented in Fig. 4.2.4, are remarkably different. Particularly, while the
probability amplitude keeps changing periodically in time, the probability density is
time-independent, implying that the probability of locating the particle anywhere in space
does not change in time. This is a specific example to an important set of solutions to the
Schrödinger equation, termed the stationary solutions. In the following sections, we shall
focus on the physical meaning of these stationary solutions and on their special role in
quantum mechanics.
Probability Density
0
400
t [102 a.u.]
t [102 a.u.]
x [ a.u.]
ρ(x,t)
0
−400 10
0
20
400
0
−400 10
0
20
Probability Amplitude
0
x [ a.u.]
Re [ψ (x,t)]
tFigure 4.2.4 The same as Fig.4.2.3, but for different initial wave packet parameters, with x0 = p0 = 0.
https://doi.org/10.1017/9781108877787.005 Published online by Cambridge University Press23 4.3 Stationary Solutions and the Time-Independent Schrödinger Equation
4.3 Stationary Solutions and the Time-Independent Schrödinger
Equation
The time evolution of solutions to the Schrödinger equation (ψ(t)) is not necessar￾ily associated with a change of the probability density function (|ψ(t)|
2
). Indeed, the
time-dependent Schrödinger equation has solutions for which the probability density
is time-independent. These solutions are termed “stationary solutions” and are ana￾logues to “standing wave” solutions of similar wave equations (e.g., the scalar wave
equation in electrodynamics). Let us consider a proper time-dependent wave function
in the form
ψ(t) ≡ e
−iαtψ(0), (4.3.1)
where α is any real-valued scalar. It immediately follows that although the probability
amplitude, ψ(t), depends explicitly on time, the corresponding probability density is
time-independent in this case:
ρ(t) = |ψ(t)|
2 = |ψ(0)|
2
. (4.3.2)
ψ(t) is therefore termed a stationary wave function. However, for ψ(t) to be associ￾ated with a state of a physical system, it must be a solution of the time-dependent
Schrödinger equation, Eq. (4.1.1); namely, it must satisfy Heˆ −iαtψ(0) = ih¯
∂
∂t
e
−iαtψ(0).
This imposes an implicit relation between the parameter α and the function ψ(0),
Hˆψ(0) = αh¯ψ(0). (4.3.3)
The relation is formulated as an eigenvalue equation. A function f is termed an eigen￾function of an operator, Oˆ, if O f ˆ equals a scalar times f , namely, O f ˆ = λ f . The scalar
(λ) is termed the eigenvalue of the operator, Oˆ, that corresponds to the eigenfunction,
f . Eq. (4.3.3) means that a function, ψ(t) ≡ e
−iαtψ(0), can be a (stationary) solution
to the time-dependent Schrödinger equation if and only if ψ(0) is an eigenfunction of the
system Hamiltonian.
Exercise 4.3.1 Show that if f1(x) is an eigenfunction of a linear operator Aˆ with an
eigenvalue α, so is f2(x) = c f1(x), where c is a constant scalar.
Exercise 4.3.2 (a) Determine whether the functions f1(x) = x
2
, f2(x) = e
iax, and f3(x) =
sin(ax) are (independently) eigenfunctions of the operator d
dx
. In cases where the answer
is positive, determine the respective eigenvalue. (b) Repeat the exercise for the operator
d
2
dx
2
.
Exercise 4.3.3 In Section 4.2 we encountered two different solutions to the Schrödinger
equation with a harmonic potential energy well, V(x) = 1
2mω
2
x
2
. The respective prob￾ability density was time-dependent only in one of these cases (presented in Fig. 4.2.3),
whereas the other solution (presented in Fig. 4.2.4) was stationary. These two solutions
correspond to different choices of the parameters (x0, p0) in the initial wave function (see
https://doi.org/10.1017/9781108877787.005 Published online by Cambridge University Press24 The Schrödinger Equation
Eq. (4.2.1)). Check whether ψ(x,0) is an eigenfunction of the system Hamiltonian for
these two choices and explain the observed difference between the two solutions.
Each eigenfunction of the Hamiltonian (energy) operator Hˆ is associated with an
eigenvalue, which is real-valued (see what follows). The eigenvalues are conventionally
marked by “E” (for “energy”), and the respective eigenfunctions are denoted as ψE(0).
Noticing that ψE(0) itself is time-independent, we can therefore omit the zero-time
notation and rewrite Eq. (4.3.3) as follows:
HˆψE = EψE. (4.3.4)
This equation is known as the time-independent (or the stationary) Schrödinger equa￾tion. Each solution to this equation (each Hamiltonian eigenfunction) corresponds to a
stationary solution of the time-dependent Schrödinger equation, which reads
ψE(t) = e
−iEt/h¯ψE. (4.3.5)
Exercise 4.3.4 An N-dimensional system is associated with the spatial coordinates
x1, x2,...., xN. Let us consider the case where the system Hamiltonian is separable,
namely, it can be written as a sum, Hˆ =
N
∑
j=1
Hˆ
x j
, where Hˆ
x j
is a Hamiltonian of a sys￾tem associated only with the coordinate xj
. The eigenfunctions and eigenvalues of the
jth Hamiltonians are defined by the set of eigenvalue equations, Hˆ
x jφnj
(xj) = Enjφnj
(xj).
Show that any product function, ψn1,n2,...,nN
(x1, x2,..., xN) = φn1
(x1)φn2
(x2)···φnN
(xN),
is an eigenfunction of the full Hamiltonian, Hˆ, with the corresponding eigenvalue,
En1,n2,...,nN = En1 +En2 +...+EnN
.
4.4 Interpretation of The Hamiltonian Eigenvalues
The stationary solutions encountered in the preceding discussion have a special mean￾ing. They correspond to the physical states in which the total energy of a system is
well defined. To realize this, we must become familiar with another postulate of quan￾tum mechanics. We have already learned that the state of a system is associated with
a proper wave function and that observables are associated with specific operators. As
elaborated later in Chapter 11, the postulates of quantum mechanics state additionally
that in a single measurement on a system the measured value can only be an eigenvalue of
the operator that represents the measured physical variable. Namely, if the wave func￾tion that represents the state of the system, ψ(t), happens to be an eigenfunction of an
operator Aˆ, that is, Aˆψ(t) = λψ(t), then the result of the measurement of the quantity
associated with the operator Aˆ can only be the respective eigenvalue λ. Particularly, if
the system is found in a stationary solution, that is, it is an eigenfunction of the energy
operator, HˆψE(t) = EψE(t) (see Eqs. (4.3.4, 4.3.5)), a measurement of its energy will
yield the eigenvalue, E. It follows that when a system is prepared in a state that corre￾sponds to a stationary solution of the Schrödinger equation, its energy is well defined.
https://doi.org/10.1017/9781108877787.005 Published online by Cambridge University Press25 4.5 The Hamiltonian as a Hermitian Operator
It also follows that when a system has a well-defined energy, the value of that energy
cannot obtain just any number. It must coincide with one of the eigenvalues of the
system Hamiltonian. The set of Hamiltonian eigenvalues therefore corresponds to the
energy levels of the system.
Notice that probability density associated with any stationary ψE(t) is time￾independent (for any real-valued E; see the following discussion). The “time￾independence” associated with the stationary solutions is not restricted, however, to
the probability density. When discussing the postulates of quantum mechanics in
Chapter 11 we shall see that when a system is in a state that corresponds to a sta￾tionary solution (Eq. (4.3.5)), any measurable information on the system is in fact
time-independent.
4.5 The Hamiltonian as a Hermitian Operator
The postulates of quantum mechanics associate measurable quantities with operators,
as we discovered in Chapter 3, and measured values with eigenvalues of these opera￾tors, as indicated in the previous section. The latter means that the eigenvalues of the
operators that represent measurable quantities must be real-valued. This is indeed the
case, owing to the facts that in quantum mechanics the measurable quantities are repre￾sented by Hermitian operators in the space of proper functions and that the eigenvalues
of Hermitian operators in this space are real-valued. In this section we introduce the
definition of a Hermitian operator and show that the operators that were associated
with measurable quantities in Chapter 3 are indeed Hermitian. We then discuss several
general properties of the eigenvalues and eigenfunctions of Hermitian operators.
An operator Aˆ is termed Hermitian in a space of functions if, for any two functions
in the space (e.g., f(x) and g(x) in a one-dimensional Cartesian space), the following
identity is satisfied:
w∞
−∞
f(x)Agˆ (x)dx =
"
w∞
−∞
g
∗
(x)A f ˆ
∗
(x)dx#∗
. (4.5.1)
Here z
∗ denotes the complex conjugate of the complex number z. The generalization
of this definition to operators in a multidimensional coordinate space is straightfor￾ward, replacing the one-dimensional integral by the corresponding multidimensional
integral. For simplicity, we shall stick to a one-dimensional coordinate space in the
discussion that follows.
A Hermitian operator is self-adjoint; namely, it is equal to its Hermitian conjugate.
The Hermitian conjugate of any operator Aˆ is denoted as Aˆ†
, and it must satisfy the
following identity for any proper functions, f(x) and g(x):
w∞
−∞
f(x)Aˆ
†
g(x)dx =
"
w∞
−∞
g
∗
(x)A f ˆ
∗
(x)dx#∗
. (4.5.2)
https://doi.org/10.1017/9781108877787.005 Published online by Cambridge University Press26 The Schrödinger Equation
For Aˆ, which is Hermitian, one therefore has
Aˆ
† = Aˆ. (4.5.3)
We can readily verify that the quantum mechanical operators discussed in Chapter 3
are Hermitian in the space of proper functions.
Let us start with the canonical operators, xˆ and pˆx. Considering first the position
operator (xgˆ (x) = xg(x)), one obtains for any proper f(x) and g(x)
w∞
−∞
f(x)xgˆ (x)dx =
w∞
−∞
f(x)xg(x)dx =
"
w∞
−∞
g
∗
(x)x
∗
f
∗
(x)dx#∗
=
"
w∞
−∞
g
∗
(x)x f ∗
(x)dx#∗
=
"
w∞
−∞
g
∗
(x)x f ˆ
∗
(x)dx#∗
,
(4.5.4)
where the fact that x itself is real-valued was used. For the momentum operator,
pˆxg(x) = −ih¯
dg(x)
dx
, we can use integration by parts and the asymptotic vanishing of
proper wave functions (Eq. (2.2.1)) to validate its Hermiticity:
w∞
−∞
f(x)pˆxg(x)dx = −ih¯
w∞
−∞
f(x)
dg(x)
dx
dx = −ih f ¯ (x)g(x)|
∞
−∞ +ih¯
w∞
−∞
g(x)
d f(x)
dx
dx
=
"
−ih¯
w∞
−∞
g
∗
(x)
d f ∗
(x)
dx
dx#∗
=
"
w∞
−∞
g
∗
(x)pˆx f
∗
(x)dx#∗
. (4.5.5)
Exercise 4.5.1 Given a Hermitian operators, Aˆ, prove that (a) (Aˆ)
n
is also Hermitian
(for any natural n); (b) α Aˆ is also Hermitian (for any real-valued α); (c) iAˆ is anti￾Hermitian (namely (iAˆ)
† = −(iAˆ)).
Exercise 4.5.2 Given two Hermitian operators, Aˆ and Bˆ, prove that (a) Aˆ + Bˆ is also
Hermitian; (b) if Aˆ and Bˆ commute, AˆBˆ is also Hermitian.
Exercise 4.5.3 Using the results of Exs. 4.5.1 and 4.5.2, prove, independently, that the
potential energy operator (V(xˆ)), the kinetic energy operator (pˆ
2
x/(2m)), the Hamilto￾nian, (Hˆ = pˆ
2
x/(2m) +V(xˆ)), and the angular momentum operators (Lˆ
x,Lˆ
y, and Lˆ
z
, as
defined in Eq. (3.3.2)) are all Hermitian.
As we discussed in Section 3.4, other quantum mechanical operators are derived
from the canonical operators. Using the results in Exs. 4.5.1 and 4.5.2, it follows that
these operators are also Hermitian (see Ex. 4.5.3). In particular, the components of
the angular momentum of a particle in a three-dimensional space, Lˆ
x,Lˆ
y, and Lˆ
z (Eq.
(3.3.2)), the potential energy,Vˆ =V(xˆ)(Eq. (3.4.7)), and the kinetic energy, Tˆ =
pˆ
2
x
2m
(Eq.
(3.4.8)) are Hermitian operators, and so is the Hamiltonian Hˆ = Tˆ +Vˆ , for any closed
system of particles. It is worthwhile to emphasize that non-Hermitian operators are
also useful and are commonly met in quantum mechanics (see, e.g., Ex. 4.5.4, as well
as the following chapters of this book), but these do not represent directly measurable
physical quantities.
https://doi.org/10.1017/9781108877787.005 Published online by Cambridge University Press27 4.6 Properties of the Stationary Solutions
Exercise 4.5.4 An operator Uˆ is termed unitary if its Hermitian conjugate equals its
inverse, namely, Uˆ = (Uˆ −1
)
†
, where Uˆ −1Uˆ = ˆI. Use the Hermiticity of the Hamiltonian
to prove that the time evolution operator for a time-independent Hamiltonian, e
−i(t−t0)Hˆ /h¯
(Eq. (4.1.2)), is unitary.
The eigenvalues and eigenfunctions of Hermitian operators have unique proper￾ties with important consequences. The first property has already been mentioned,
namely, the eigenvalues of a Hermitian operator in the space of proper wave func￾tions are real-valued. Let Aˆ be a Hermitian operator, and let α be any one of its
eigenvalues, associated with the eigenfunction, φα(x). Since Aˆ is Hermitian, Eq. (4.5.1)
applies for any proper functions, and particularly for the choices, f(x) ≡ φ
∗
α
(x) and
g(x) ≡ φα(x), such that r∞
−∞
φ
∗
α
(x)Aˆφα(x)dx =

r∞
−∞
φ
∗
α
(x)Aˆφα(x)dx∗
. Since Aˆφα(x) =
αφα(x), one obtains α
r∞
−∞
φ
∗
α
(x)φα(x)dx = α
∗
r∞
−∞
φ
∗
α
(x)φα(x)dx. For any proper func￾tion, r∞
−∞
φ
∗
α
(x)φα(x)dx 6= 0 (see Eq. (2.1.3)), and therefore we conclude that any
eigenvalue must be real-valued (α = α
∗
). This property is consistent with the inter￾pretation of the eigenvalues of quantum mechanical operators as directly measurable
quantities.
4.6 Properties of the Stationary Solutions
The stationary solutions of the Schrödinger equation have additional special proper￾ties. Particularly, the entire set of stationary solutions for a given system can be mapped
on a set of orthonormal functions. As we shall discuss in Chapters 11 and 15, such a set
spans the space of physically meaningful solutions to the time-dependent Schrödinger
equation for the system; namely, any time-dependent solution can be expanded as a
linear combination of the stationary solutions. In this section we focus on the orthog￾onality property of different stationary solutions, which is derived directly from their
being solutions of the time-independent Schrödinger equation (Eq. (4.3.4)), namely,
being eigenfunctions of the Hermitian (Hamiltonian) operator.
Let us start by defining the overlap integral between two normalized functions, f(x)
and g(x), as follows:
S =
w∞
−∞
f
∗
(x)g(x)dx, (4.6.1)
where r∞
−∞
| f(x)|
2dx =
r∞
−∞
|g(x)|
2dx = 1. Notice that S is generally complex-valued. How￾ever, one can show that its absolute value satisfies 0 ≤ |S|
2 ≤ 1, and it can therefore
provide a measure for the “similarity” between the two functions. (For a detailed dis￾cussion in the context of an “inner product” definition, see Chapter 11.) The maximal
value corresponds to f(x) and g(x) being equal, whereas the minimal value corresponds
https://doi.org/10.1017/9781108877787.005 Published online by Cambridge University Press28 The Schrödinger Equation
to the functions being inherently different (see Ex. 4.6.1), that is, orthogonal to each
other. Two functions, f(x) and g(x), are termed orthogonal to each other if their overlap
integral vanishes, namely,
w∞
−∞
f
∗
(x)g(x)dx = 0. (4.6.2)
It is easy to see that any two eigenfunctions of a Hermitian operator, Aˆ, that is,
φα(x) and φβ
(x), associated respectively with two different eigenvalues, α 6= β, are
orthogonal. Since Aˆ is Hermitian, Eq. (4.5.1) applies for any proper functions, and par￾ticularly for the choices, f(x) ≡ φ
∗
α
(x) and g(x) ≡ φβ
(x), such that r∞
−∞
φ
∗
α
(x)Aˆφβ
(x)dx =

r∞
−∞
φ
∗
β
(x)Aˆφα(x)dx∗
. Since Aˆφα(x) = αφα(x) and Aˆφβ
(x) = β φβ
(x), with real-valued
α and β one obtains β
r∞
−∞
φ
∗
α
(x)φβ
(x)dx = α
r∞
−∞
φ
∗
α
(x)φβ
(x)dx. Finally, since α 6= β,
one has r∞
−∞
φ
∗
α
(x)φβ
(x)dx = 0, namely, φα(x) and φβ
(x) must be orthogonal (see Eq.
(4.6.2)). Since the Hamiltonian is Hermitian, it therefore follows that any two solutions
to the time-independent Schrödinger equation, associated with different eigenvalues
(different energy values), are orthogonal. But what if two solutions are associated with
the same eigenvalue?
It often happens that two (or more) different (namely, linearly independent) eigen￾functions of an operator are associated with the same eigenvalue. Such functions
are termed degenerate. Notice that different solutions of the Schrödinger equa￾tion (Eq. (4.1.1)) correspond to different physical states of a given system. How￾ever, when two solutions are degenerate with respect to an operator, Aˆ, the corre￾sponding physical states cannot be distinguished by a measurement of the property
represented by Aˆ, since the measured value would be the same for both. In partic￾ular, an energy measurement cannot distinguish between different degenerate sta￾tionary states (Hamiltonian eigenfunctions) of a system. To do so, one needs to
perform a different measurement, associated with another operator for which the
two functions have different eigenvalues. Examples are discussed in the following
chapters.
Exercise 4.6.1 Let fe(x) and fo(x) be any even and odd functions respectively, namely,
fe(−x) = fe(x) and fo(−x) = −fo(x). Prove that fe(x) and fo(x) are orthogonal according
to the definition in Eq. (4.6.2).
Exercise 4.6.2 The parity operator is defined by its operation: P f ˆ (x) = f(−x). (a) Prove
that Pˆ is Hermitian. (b) Show that even or odd functions of x are eigenfunctions of Pˆ.
What are the corresponding eigenvalues? (c) Explain the result of Ex. 4.6.1, using (a)
and (b).
Exercise 4.6.3 Prove that if Aˆ is a linear operator, and if φ1(x),φ2(x),...,φN(x) are
degenerate eigenfunctions of Aˆ, namely, Aˆφn(x) = αφn(x), for n ∈ 1,2,...,N, then any
linear combination of these functions is an eigenfunction of Aˆ, with the eigenvalue α.
https://doi.org/10.1017/9781108877787.005 Published online by Cambridge University Press29 4.6 Properties of the Stationary Solutions
Exercise 4.6.4 Given two degenerate normalized eigenfunctions of a linear operator Aˆ,
Aˆφ1(x) = αφ1(x) and Aˆφ2(x) = αφ2(x), show that the following functions,
ψ1(x) = φ1(x) ; ψ2(x) = φ2(x)−φ1(x)
w∞
−∞
dx0φ
∗
1
(x
0
)φ2
(x
0
),
are two orthogonal eigenfunctions of Aˆ corresponding to the same eigenvalue α.
Recalling that the quantum mechanical operators are linear, it follows that any
linear combination of degenerate eigenfunctions of a quantum mechanical operator
is itself an eigenfunction of the same operator, associated with the same eigenvalue
(see Ex. 4.6.3)). When a set of N linearly independent degenerate functions spans
the subspace of degenerate functions, the corresponding eigenvalue is termed N-fold
degenerate. Clearly, degenerate eigenfunctions of an operator are not defined uniquely.
In particular, two degenerate eigenfunctions of a given Hermitian operator are not nec￾essarily orthogonal to each other. Nevertheless, for an N-fold degenerate eigenvalue of
a given operator, it is always possible to construct N orthogonal eigenfunctions to the
operator that correspond to the same eigenvalue. An example for N = 2, given explicitly
in Ex. 4.6.4, can be generalized to any N [4.4]. It therefore follows that for any (Her￾mitian and linear) quantum mechanical operator there exists a set of eigenfunctions that
are orthonormal, namely a set in which each function is normalized, and every two
functions are orthogonal to each other. Denoting the functions in the orthonormal set
as, φ1(x),φ2(x),..., one has
w∞
−∞
φ
∗
n
(x),φn
0(x)dx = δn,n
0, (4.6.3)
where the Kronecker delta is defined as
δn,n
0 =
(
0 ; n 6= n
0
1 ; n = n
0
. (4.6.4)
Notice that Eq. (4.6.3) applies in particular to the set of the Hamiltonian eigenfunc￾tions (stationary solutions), defined by Eq. (4.3.4).
Exercise 4.6.5 φ1(x), φ2(x), and φ3(x) are eigenfunctions of a Hamiltonian Hˆ
x, that is,
Hˆ
xφn(x) = Enφn(x), where E1 6= E2 = E3. Each φn(x) corresponds to a stationary solution
of the time-dependent Schrödinger equation, ψn(x,t) = φn(x)e
−iEnt
h¯ . Show that the follow￾ing linear combinations of stationary solutions (a1, a2, and a3 are non-zero scalars) are
solutions to the time-dependent Schrödinger equation. Which of these solutions is station￾ary (namely, associated with a time-independent probability density function)? What is
the conclusion?
a. Ψ(x,t) = a1ψ1(x,t) +a2ψ2(x,t)
b. Ψ(x,t) = a3ψ3(x,t) +a2ψ2(x,t)
c. Ψ(x,t) = a3ψ3(x,t) +a1ψ1(x,t)
https://doi.org/10.1017/9781108877787.005 Published online by Cambridge University Press30 The Schrödinger Equation
Exercise 4.6.6 Show that the two Hamiltonians Hˆ
x and Hˆ
x + α, where α is a scalar
constant, have the same eigenfunctions. What is the relation between the corresponding
eigenvalues?
Bibliography
[4.1] U. Peskin and N. Moiseyev, “The solution of the time-dependent Schrödinger
equation by the (t, t’) method: theory, computational algorithm and applica￾tions,” The Journal of Chemical Physics 99, 4590 (1993).
[4.2] E. J. Heller, “Time-dependent approach to semiclassical dynamics,” The Journal
of Chemical Physics 62, 1544 (1975).
[4.3] C. Cohen-Tannoudji, B. Diu and F. Laloë, “Quantum Mechanics,” vols. 1–2:
(John Wiley & Sons, 2020).
[4.4] W. E. Arnoldi, “The principle of minimized iterations in the solution of the
matrix eigenvalue problem,” Quarterly of Applied Mathematics 9, 17 (1951).
https://doi.org/10.1017/9781108877787.005 Published online by Cambridge University Press5 Energy Quantization
5.1 The Energy Spectrum
In Chapter 4 we became familiar with the existence of stationary (standing wave) solu￾tions to the time-dependent Schrödinger equation. These solutions were associated
with eigenfunctions of the Hamiltonian operator (Eq. (4.3.4)), where the correspond￾ing eigenvalues were identified with the real-valued energy levels of the system.
Typically, the Hamiltonian of a system has numerous eigenfunctions (different
standing wave solutions), which correspond to a set of energy levels. This set is termed
the energy spectrum of the system. Since the Hamiltonian eigenvalues are real-valued,
they can be ordered: En, n = 0,1,2,3,.... However, the set of energy levels of a given sys￾tem within a finite energy interval can be either discrete (“quantized”) or continuous.
For particles in extended (or “open”) systems (such as solid lattices or in free space)
the spectrum is continuous, but for particles bounded in (or confined to) a restricted
region of space, for example, within atoms, molecules, or nanoparticles, the energy
spectrum becomes discrete (see Fig. 5.1.1). To emphasize this, we rewrite Eq. (4.3.4)
for a discrete spectrum as follows:
Hˆ
xψn(x) = Enψn(x). (5.1.1)
As we discuss in detail here and also in Chapters 6–10, the discrete spectrum emerges
naturally following mathematical constraints imposed on the solutions to Eq. (5.1.1).
Energy
Energy bands
in a solid lattice
Energy levels
in an atom
tFigure 5.1.1 The emergence of energy level quantization for particles confined in space.
31
https://doi.org/10.1017/9781108877787.006 Published online by Cambridge University Press32 Energy Quantization
These constraints assure that the wave functions are proper and are therefore suitable
for representing what we can consider to be a physical reality (probability conserva￾tion, continuity in space, etc.). The mathematical constraints typically include specific
boundary conditions imposed on the wave functions (e.g., ψn(x) −−→x → ±∞
0, Eq. (2.2.1))
which can only be satisfied for a discrete set of energy values. An important manifesta￾tion of this “quantization” of the energy for particles confined in space is the “quantum
size effect” discussed in what follows.
5.2 The “Quantum Size Effect
“
Nanocrystals are relatively small crystals of semiconductors (containing typically
103–104 atoms), with a diameter of several nanometers. These crystals are useful in
numerous applications including Light Emitting Diodes (LEDs), display screens, solar
cells, medical treatment of diseases, and many others. The reason for their useful￾ness is that their electronic properties are sensitively determined by particle shape and
size, which can be relatively easily controlled during their preparation process. This is
reflected in size-controlled properties such as absorption and emission of electromag￾netic radiation in the visible spectrum (the observed “color”), interparticle charge and
energy transport, chemical catalytic activity, and so on. Consider, for example, light
emission from nanocrystals made of the same semiconductor material, but at different
particle sizes, as illustrated in Fig. 5.2.1. The red light is emitted from particles of 6 nm
in diameter, and the blue is emitted from particles of 2 nm in diameter. How can the
tFigure 5.2.1 (Greyscale) illustration of the effect of the size of colloidal nanoparticles (quantum dots) on the color of their emitted
radiation (Image by Serg Myshkovsky/Photodisc/Getty Images).
https://doi.org/10.1017/9781108877787.006 Published online by Cambridge University Press33 5.2 The “Quantum Size Effect
“
size of a particle affect so dramatically (and usefully!) the color of the emitted light? Why
is the emission shifted toward the red color as the particle diameter increases?
Why is it necessary to have particles of just a few nanometers in diameter to observe
the size-dependence of the emitted light?
A rigorous answer to these questions requires familiarity with the electronic struc￾ture of materials (and semiconductor crystals in particular), discussed in Chapter 14,
as well as with the phenomenon of radiation emission, discussed in Chapter 18. Nev￾ertheless, to explain the essence of the phenomenon we provide here some necessary
facts that will be elaborated when we address light–matter interactions in Chapters 15
and 18. Considering the colors associated with the visible spectrum of the electromag￾netic radiation, the change of color from red to blue corresponds to a change in the
wavelength (λ) of the emitted radiation from ∼700 nm to ∼400 nm, where the emitted
wavelength is inversely proportional to the radiation frequency (ν),
ν =
c
λ
. (5.2.1)
(Here c is the speed of light.) The frequency is proportional to the energy lost by
electrons in the material during the radiation emission (Planck’s formula [1.3]):
Ef −Ei = hν =
hc
λ
. (5.2.2)
Ei and Ef are respectively the “initial” and “final” electronic energy levels within the
nanoparticle. It follows that a shorter emission wavelength indicates a larger energy gap
between the relevant initial and final electronic energy levels. The observation in Fig.
5.2.1 therefore suggests that the energy gap between Ei and Ef
increases with decreasing
tFigure 5.2.2 The correlation between the size of a nanoparticle and the color of emission. The smaller (left) nanoparticle is
associated with a relatively larger spacing between the discrete energy levels, and the emission wavelength is thus
shorter. Electrons occupying the energy levels are indicated by dots. (Image by Serg Myshkovsky/Photodisc/Getty
Images.)
https://doi.org/10.1017/9781108877787.006 Published online by Cambridge University Press34 Energy Quantization
particle diameter. This phenomenon is a manifestation of “the quantum size effect,”
which means that the spectrum of a quantum system becomes less dense (namely, the
energy gap between two given states increases) as the size of the system decreases. This
is demonstrated qualitatively in Fig. 5.2.2.
The quantum size effect is ubiquitous in quantum mechanics. In what follows we
demonstrate its emergence by solving the time-independent Schrödinger equation for
the simplest textbook model of a confined particle: the “particle-in-a-box.”
5.3 Energy Quantization for a “Particle-in-a-Box
“
The model assumes a single point particle of mass m and a one-dimensional Cartesian
coordinate, x. In classical mechanics, the particle would be free to move inside a “square
box” in the range 0 ≤ x ≤ L (see Fig. 5.3.1), and its motion would be confined to this
box by the following potential energy function:
V(x) =



∞ 0 > x
0 0 ≤ x ≤ L
∞ L < x
. (5.3.1)
Moving to the quantum mechanical description, we seek the solutions to the time￾independent Schrödinger equation for this system. Outside the box, the probability
density for locating the particle must vanish on physical grounds. (This result can be
derived rigorously by considering a finite external potential energy [see Chapter 6], and
taking the limit to infinity in the resulting solutions.) This condition reads
|ψ(x)|
2 = 0; x < 0; L < x. (5.3.2)
It follows that the wave function itself must also vanish (ψ(x) = 0) anywhere outside
the box. Inside the box, the time-independent Schrödinger equation (Eq. (5.1.1)) reads
−h¯
2
2m
∂
2
∂ x
2
ψ(x) = Eψ(x). (5.3.3)
E
0
0 L X
V(x)
tFigure 5.3.1 The potential energy for a particle in an infinite one-dimensional “box.”
https://doi.org/10.1017/9781108877787.006 Published online by Cambridge University Press35 5.3 Energy Quantization for a “Particle-in-a-Box
“
Defining
k ≡
r
2mE
h¯
2
, (5.3.4)
the general solution of Eq. (5.3.3) for any k reads
ψ(x) = aeikx +be−ikx
. (5.3.5)
On physical grounds, we require that the probability density for locating the particle in
space is a continuous function of x. Particularly, since the probability density vanishes
anywhere outside the box, it must vanish also at the box boundaries, in accordance with
Eq. (5.3.2). This requirement translates to boundary conditions on the wave function
itself, namely,
ψ(0) = 0, (5.3.6a)
ψ(L) = 0. (5.3.6b)
Using Eq. (5.3.6a) in Eq. (5.3.5) imposes a dependency between a and b, and the space
of solutions is restricted accordingly:
ψ(x) = 2ia sin(kx), (5.3.7)
which holds for any value of k. However, imposing the second boundary condition,
(5.3.6b), the allowed values of k are shown to be restricted to a discrete set, kn =
nπ
L
:
ψn(x) = 2iasin(
nπ
L
x); n = 0,±1,±2,.... (5.3.8)
We note that for n = 0 the wave function (ψ0(x)) is identically zero in the entire coor￾dinate space, and therefore it is improper (see Section 2.2). Additionally, the solutions
ψ−n(x) and ψn(x) are linearly dependent. (They differ only by sign; namely, they are the
same up to a multiplication by a constant.) Normalizing the solutions in Eq. (5.3.7), we
obtain the following set of proper, linearly independent solutions to the Schrödinger
equation for the particle in a box:
ψn(x) =



0 0 > x q
2
L
sin￾
nπ
L
x

0 ≤ x ≤ L ; n = 1,2,3,....
0 L < x
(5.3.9)
We emphasize that this discrete set of solutions was “filtered” out from the full space of
solutions (Eq. (5.3.5)) by requirements that were based on our physical interpretation
of the solutions, such as the continuity and properness of the wave functions.
The energy spectrum corresponding to the physically meaningful solutions is, there￾fore, also discrete. Using kn =
nπ
L
and Eq. (5.3.4), we obtain the expression for the
discrete energy levels,
En =
h¯
2
k
2
n
2m
=
h¯
2π
2n
2
2mL2
; n = 1,2,3,... . (5.3.10)
https://doi.org/10.1017/9781108877787.006 Published online by Cambridge University Pres36 Energy Quantization
0 Position
Energy/Wavefunction
L
tFigure 5.3.2 Energy levels and stationary wave functions for the “particle-in-a-box.” The different plots correspond to different
energy levels. The plots are displaced from each other by the respective energy differences.
This result provides a first demonstration of the “quantum size effect.” We can see that
the spacing between any two levels (denoted by the indexes, n and n
0) increases, as the
box becomes smaller:
En −En
0 =
h¯
2π
2
(n
2 −n
02
)
2mL2
∝
1
L
2
. (5.3.11)
Indeed, for an infinitely large box, the energy spectrum becomes continuous. The
quantization of the spectrum emerges due to the confinement of the particle to a
finite region in coordinate space, and becomes more apparent as the confinement
becomes stronger, namely, as the box becomes smaller. Notice that this qualita￾tive result is universal for confined particles, although the quantitative dependence,
∆E ∝
1
L
2
, is specific for the one-dimensional box with an infinite external potential
energy.
Fig. 5.3.2 illustrates the energy spectrum and the corresponding wave functions for
the particle in a box model. The set of stationary solutions for this model demon￾strates some general features of stationary solutions to Schrödinger equations, which
we briefly review here. It is worthwhile to notice the following points:
I. The emergence of a “zero-point energy”: as it turns out, the lowest energy level is
above the zero of the potential energy in the system. This means that the particle
in the box has some minimal energy that cannot be “drained” out. This phenom￾enon is typical to all confining potentials. It is related to the uncertainty principle
(discussed in Chapter 11), which shows that for a proper state it is impossible to
https://doi.org/10.1017/9781108877787.006 Published online by Cambridge University Press37 5.4 Energy Quantization for a “Particle-on-a-Ring
“
simultaneously have a strictly zero momentum (zero kinetic energy) and some cer￾tainty with respect to the position of the particle (namely, its confinement to the
box region).
II. For small n values, the probability density is not uniformly distributed along the
box and the wave nature of the stationary solutions is pronounced.
III. For large n values, the probability tends to distribute uniformly over the entire
box, which is reminiscent of the classical behavior for a particle in a box at a given
energy.
IV. The number of oscillations (the number of zero values, or “nodes”) in the wave
function increases with energy. This is somewhat reminiscent of the de Broglie
wavelength formula (Eq. (1.1.3)), but notice that the particle in the box is not a free
particle since its momentum vector (the direction of motion) is not well-defined.
Exercise 5.3.1 Prove that the solutions of the time-independent Schrödinger equation for
the particle-in-a-box model (denoted as, ψn
(x)), associated with different energy levels,
are orthogonal to each other, as required by the Hermiticity of the Hamiltonian (Eq.
(4.6.3)).
5.4 Energy Quantization for a “Particle-on-a-Ring
“
Oursecond example for the emergence of quantization for spatially confined particles is
the model of a “particle on a ring,” illustrated in Fig. 5.4.1. This model has similarities
to the particle-in-a-box model, but also some important differences, that demonstrate
the effect of different boundary conditions on the energy level quantization. The model
assumes a single point particle of mass µ, restricted to a uniform ring at a constant
radius r in the (x, y) plane. The time-independent Schrödinger equation in the plane
reads
−h¯
2
2µ

∂
2
∂ x
2
+
∂
2
∂ y
2

ψ(x, y) +V(x, y)ψ(x, y) = Eψ(x, y). (5.4.1)
y
r
µ
x
ϕ
tFigure 5.4.1 The “particle-on-a-ring”
https://doi.org/10.1017/9781108877787.006 Published online by Cambridge University Press38 Energy Quantization
However, since r is restricted to a constant value, it is useful to switch from Cartesian
to polar coordinates,(x, y) → (r,φ), where
x = r cos(φ),
y = rsin(φ),
r =
p
x
2 +y
2
, (5.4.2)
φ = arccos(x/
p
x
2 +y
2) = arcsin(y/
p
x
2 +y
2).
For a given r, the only dynamical variable is the polar angle, φ, in the range 0 ≤ φ <
2π. The potential energy on the uniform ring assumes a constant value, which is taken
to be zero. Equation (5.4.1) therefore leads to a one-dimensional Schrödinger equation
for the particle on the ring,
−h¯
2
2µr
2
∂
2Φ(φ)
∂ φ2
= EΦ(φ) ; 0 ≤ φ < 2π. (5.4.3)
Exercise 5.4.1 (a) Use Eq. (5.4.2) and the chain rule to derive Eq. (5.4.3) from Eq.
(5.4.1). (b) Show that the z-component of the angular momentum reads Lˆ
z = −ih¯
∂
∂φ
.
(c) Show that the kinetic energy operator for the particle on the ring reads Hˆ =
Lˆ 2
z
2µr
2
.
The Schrödinger equation (Eq. (5.4.3)) is perfectly analogous to Eq. (5.3.3), and so are
its general solutions. Defining,
α ≡
s
2µr
2E
h¯
2
, (5.4.4)
we have (for any choice of constants, a and b)
Φ(φ) = aeiαφ +be−iαφ
. (5.4.5)
However, the condition for probability continuity reads differently for the angular var￾iable φ. Instead of vanishing at the box boundaries (as in Eq. (5.3.6)), the probability
density (and thus the wave function Φ(φ)), must satisfy periodic boundary conditions,
as φ and φ +2π correspond to the same geometry,
Φ(0) = Φ(2π). (5.4.6)
This condition imposes a restriction on the space of solutions (Eq. (5.4.5)), since α
must obtain only integer values to satisfy Eq. (5.4.6). These integer values are com￾monly denoted by a quantum number, m = 0,±1,±2,.... Without loss of generality,
we can set b in Eq. (5.4.5) to zero, and set a = √
1
2π
such that the wave functions are
normalized on the ring. The discrete set of solutions is therefore
Φm(φ) = 1
√
2π
e
imφ
; m = 0,±1,±2,±3,.... (5.4.7)
Using Eq. (5.4.4), we obtain the discrete energy spectrum for the particle on a ring,
Em ≡
h¯
2m
2
2µr
2
; m = 0,±1,±2,±3,.... (5.4.8)
https://doi.org/10.1017/9781108877787.006 Published online by Cambridge University Press39 5.4 Energy Quantization for a “Particle-on-a-Ring
“
This result is our second demonstration of the “quantum size effect.” Indeed, the energy
spacing between any two different energy levels of the particle on the ring increases as it
becomes more confined in space. In the present case, the confinement is associated with
the finite radius of the ring, where the level spacing increases as the radius of the ring
becomes smaller, Em −Em0 ∝
1
r
2
, by analogy to the case of a box.
In spite of the analogy between the box and the ring, there is an important differ￾ence between the two cases. Notice that the energy associated with the two quantum
numbers, m and −m, is the same. Nevertheless, the two wave functions, Φm(φ) and
Φ−m(φ), are generally different (except for the case, m = 0). They are linearly inde￾pendent (orthogonal, in fact (see Ex. 5.4.2)) and correspond to degenerate states of the
particle on the ring. Although corresponding to different physical states of the particle,
the two states cannot be distinguished by an energy measurement. (See Section 4.6 for
the discussion of degenerate states.)
To understand the origin of the degeneracy in the particle’s energy spectrum, we
notice that the stationary solutions Φm(φ) and Φ−m(φ), are eigenfunctions not only
of the Hamiltonian, but also of the angular momentum operator, associated with the
in-plane motion, Lˆ
z = −ih¯
∂
∂φ
(see Ex. 5.4.1):
Lˆ
zΦ±m(φ) = ±mh¯Φ±m(φ). (5.4.9)
However, the two eigenfunctions are nondegenerate with respect to Lˆ
z
, as they are
associated with two different eigenvalues of this operator, namely ±mh¯. Recalling the
quantum mechanical postulate that associates a measurement with specific eigenval￾ues of an operator (Section 4.4), the physical meaning of the last result is as follows:
measuring the angular momentum on a state Φ±m(φ) would yield different results,
depending on whether the state is associated with the “plus” or the “minus” signs.
While the absolute value of the angular momentum is the same in the two cases (which
explains why the two states are associated with the same kinetic energy), the sign of
the angular momentum, namely, the direction of the rotation, is opposite in the two
states. Indeed, the energy of rotation should be the same if the particle rotates clock￾wise or anticlockwise, but the physical states are distinguishable by a measurement of
the angular momentum vector.
Notice that Φm(φ) and Φ−m(φ) are orthogonal to each other, as expected for nonde￾generate eigenfunctions of the Hermitian operator, Lˆ
z (see Section 4.6 and Ex. 5.4.2).
Also notice that the Hamiltonian of the particle on the ring and the angular momentum
operator Lˆ
z share a common set of eigenfunctions. This implies that the quantities that
are represented by these operators can be defined simultaneously. This property does
not hold for any two operators, since to have a common set of eigenfunctions, the
operators need to commute. We shall return to this point in Chapter 11 in relation to
Heisenberg’s uncertainty principle.
Exercise 5.4.2 Prove that the solutions to the time-independent Schrödinger equation
for the particle on a ring model, defined in Eq. (5.4.7), are orthogonal to each other.
Recall that the relevant coordinate space is 0 ≤ φ < 2π.
https://doi.org/10.1017/9781108877787.006 Published online by Cambridge University Press40 Energy Quantization
5.5 Particles in Three-Dimensional Boxes: Quantum Wells, Wires,
and Dots
The solutions of the one-dimensional particle in a box model enable us to gain useful
insight into the effect of spatial confinement and the associated quantum size effect also
in higher dimensions. Particularly, it can provide estimates for the density of quantum
states for a particle at an energy E in different structures that confine the particle’s
motion in different dimensions.
Let us consider a particle in a three-dimensional square box, as defined by the
following potential energy function:
V(x, y,z) = (
0 ; 0 ≤ x ≤ Lx,0 ≤ y ≤ Ly,0 ≤ z ≤ Lz
∞ ; elsewhere
. (5.5.1)
As in the one-dimensional case, the probability for locating the particle anywhere out￾side the box must vanish, and it is sufficient to solve the time-dependent Schrödinger
equation inside the box, subject to the condition ψ(x, y,z) = 0, anywhere on the box
boundary. Inside the box, the potential energy is zero, such that the Hamiltonian
includes only the kinetic energy,
Hˆ =
−h¯
2
2m

∂
2
∂ x
2
+
∂
2
∂ y
2
+
∂
2
∂ z
2

. (5.5.2)
We notice that the box Hamiltonian is separable in the three Cartesian coordinates:
Hˆ ≡ Hˆ
x +Hˆ
y +Hˆ
z
. (5.5.3)
Therefore (using the conclusion of Ex. 4.3.4), the solutions to the corresponding three￾dimensional, time-independent Schrödinger equation can be expressed in terms of
multiplications of solutions to the respective one-dimensional boxes, namely,
ψnx,ny,nz
(x, y,z) = r
2
Lx
s
2
Ly
s
2
Lz
sin
nxπx
Lx

sin
nyπy
Ly

sin
nzπz
Lz

. (5.5.4)
The corresponding energy levels are summations,
Enx,ny,nz =
h¯
2π
2
2m
"
nx
Lx
2
+

ny
Ly
2
+

nz
Lz
2
#
, (5.5.5)
where each solution is associated with a set of three independent quantum numbers,
nx = 1,2,3,... ; ny = 1,2,3,... ; nz = 1,2,3,.... (5.5.6)
It is interesting to examine the energy spectrum of the box in several limits:
Case I : Lz = Lx = Ly = L under weak confinement (Characteristic of bulk material):
For a large L of a macroscopic size, the three-dimensional box can be regarded as a
naïve model for the available electronic states in an idealized bulk material. The model
https://doi.org/10.1017/9781108877787.006 Published online by Cambridge University Press41 5.5 Particles in Three-Dimensional Boxes: Quantum Wells, Wires, and Dots
enables us to estimate the number of quantum states per single particle of mass m,
available up to an energy, E, namely, N(E). Using Eq. (5.5.5), this translates to counting
the number of different sets of quantum numbers (nx,ny,nz), such that
h¯
2π
2
2mL2
(n
2
x +n
2
y +n
2
z
) ≤ E. (5.5.6)
In a system of macroscopic size it is justified to consider the classical limit and to
replace the quantum numbers by continuous variables x, y,z such that the problem
of counting the states is replaced by calculating a three-dimensional volume integral,
defined by x
2 +y
2 +z
2 ≤
2mL2E
h¯
2π
2
, for positive x, y, and z. This translates to a volume of a
sphere of radius R =
q
2mL2E
h¯
2π
2
, divided by 8, which yields the following estimate for the
number of states:
N(E) =
2
1/2
3
m
3/2L
3
h¯
3π
2
E
3/2
. (5.5.7)
The number of states per infinitesimal energy interval is the density of states (which
plays an important role in quantum dynamics and kinetics, to be discussed in Chap￾ters 17–20):
ρ(E) ≡
dN(E)
dE
=
m
3/2L
3
2
1/2h¯
3π
2
E
1/2
. (5.5.8)
Important qualitative results are that the density of single-particle states in a macro￾scopic three-dimensional box increases for a heavier particle (ρ(E) ∝ m
3/2
) and for a
larger spatial volume (ρ(E) ∝ L
3
), in accordance with the quantum size effect. Addi￾tionally, the density of states in three dimensions increases monotonically with the
energy and scales as ρ(E) ∝ E
1/2
.
Case II : Lz << Lx = Ly = L(a quantum well):
In this case the particle is much more strongly confined in one of the three dimensions.
Let us consider first the limit in which the energy levels in the box along the z direction
are so far apart that only levels associated with nz = 1 are relevant for describing the
lowest energy states of the system (up to some relevant energy). Therefore, within this
interval, the energy depends only on nx and ny (see Eq. (5.5.5)):
Enx,ny =
h¯
2π
2
2mL2
[n
2
x +n
2
y
]+E1. (5.5.9)
This is a typical situation for “quantum wells,” which are effective two-dimensional
systems, owing to strong confinement in the third dimension. Examples are semicon￾ductor heterostructures made of AlGaAs-GaAs-AlGaAs, as presented in Fig. 5.5.1.
Electrons are trapped in a narrow potential energy well between the layers along the z
direction, where the energy levels are quantized. In contrast, the box dimensions along
the x and y directions are of macroscopic size, with an essentially continuous energy
spectrum. Electrons in such structures are often referred to as a “two-dimensional
electron gas” [5.1].
https://doi.org/10.1017/9781108877787.006 Published online by Cambridge University Press42 Energy Quantization
E
(a)
(b)
AlGaAs
AlGaAs
GaAs
z
tFigure 5.5.1 A schematic representation of a “quantum well.” (a) A heterostructure of doped semiconductor layers
(AlGaAs-GaAs-AlGaAs). (b) The formation of an effective potential energy well (a quantum well) between the
confining layers along the direction perpendicular to the layers. A confined wave function is illustrated inside the
potential energy well.
In this case, counting the number of quantum states per particle up to energy E using
Eq. (5.5.9) translates (in the continuum limit) to calculating the area of a circle of radius
R =
q2mL2(E−E1)
h¯
2π
2
, divided by 4, which yields the following estimate for the number of
states:
N(E) =
(
0 ; E ≤ E1
mL2
(E−E1)
2h¯
2π
; E > E1
, (5.5.10)
and the corresponding density of states (for E > E1),
ρ(E) = mL2
2h¯
2π
. (5.5.11)
Interestingly, the density of states in a quantum well (a two-dimensional box) does
not depend on energy. Notice, however, that if the confinement along the z direc￾tion is weaker (Lz gets larger) such that the levels corresponding to nz = 2,3,... enter
the relevant energy interval, N(E) increases accordingly, and ρ(E) increases by steps
https://doi.org/10.1017/9781108877787.006 Published online by Cambridge University Press43 5.5 Particles in Three-Dimensional Boxes: Quantum Wells, Wires, and Dots
AlGaAs
(−)
(−)
AlGaAs
GaAs
tFigure 5.5.2 From a quantum well to a quantum wire: charging selected regions on top of a quantum well, made of a
semiconductor heterostructure, confines the motion of electrons into an effective one-dimensional wire. The charged
plates on top of the structure are marked by (-).
whose positions reflect the quantized energy levels along the z direction of the quantum
well.
Case III : Lz
,Ly << Lx = L (a quantum wire):
In this case the particle is strongly confined along two of the three dimensions. In
the limiting case, the quantum numbers that refer to the z and y directions are both
restricted to their lowest values, nz = ny = 1, resulting in the following formula for the
energy (see Eq. (5.5.5)):
Enx =
h¯
2π
2n
2
x
2mL2
+E1,1. (5.5.12)
This situation defines a “quantum wire” [5.2], where the particle is effectively restricted
to a one-dimensional system. Quantum wires are naturally obtained in nanoscale sys￾tems including atomic chains and molecules [5.3] [5.4], or they can be fabricated by
artificially confining an electron gas in a two-dimensional heterostructure into an effec￾tive one-dimensional structure (a “point contact”), by structural design [5.5], or by
using appropriate static fields (see Fig. 5.5.2).
Also here, we can count the number of quantum states per particle up to an energy,
E, by considering Eq. (5.5.12) in the continuum limit, which yields
N(E) =



0 ; E ≤ E1,1
L
√
2m(E−E11)
h¯π
; E > E1,1
, (5.5.13)
where the corresponding density of states for E > E1,1 reads
ρ(E) = L
√
m
√
2πh¯
(E −E11)
−1/2
. (5.5.14)
Notice that the density of states in a one-dimensional box decreases as a function
of energy. However, in typical realizations of quantum wires each combination of
the lateral quantum numbers (e.g., ny, nz) would contribute to the total number of
states as long as E > Eny,nz
. The result is a sharp increase in the density of state as a
function of energy, whenever E>˜ Eny,nz
, followed by the decrease characteristic of the
one-dimensional box (Eq. 5.5.14).
https://doi.org/10.1017/9781108877787.006 Published online by Cambridge University Press44 Energy Quantization
source
e
Gate
2DEG
Drain
Width of contact
0
1
2
3
4
Conductance [2e2/h]
5
6
7
tFigure 5.5.3 Conductance through a point contact. The two-dimensional electron gas is manipulated into a narrow quantum wire
with a “point contact” at its bottleneck. The electric conductance through the point contact is an integer number of
conductance quanta(G0 = 2e
2/h), which correspond to the quantum number associated with the quantization in
the lateral direction, perpendicular to the current flow. As the width of the contact increases, more such lateral states
become accessible, and the conductance increases in steps.
The jumps in the density of states in a quantum wire can be directly measured in elec￾tronic transport through quantum point contacts [5.4] (see Fig. 5.5.3). For a rigorous
derivation based on quantum scattering theory, we refer to Ref. [5.6], whereas here we
give only a brief qualitative explanation: the electric conductance is proportional to
the charge flux through the contact, which is proportional to the density of states and
to the particle velocities. Since the density of states scales as (E − Enx,ny
)
−1/2
(by Eq.
(5.5.14)), while the particle velocity scales as, (E −Enx,ny
)
1/2
, the conductance is inde￾pendent of the energy as long as the number of energetically accessible lateral states
(e.g., the number of ny and nZ values, for which E > Eny,nz
) does not change. Each set
of lateral quantum numbers therefore contributes a universal factor termed the con￾ductance quantum, G0 =
2e
2
h
, to the overall conductance. Increasing the lateral box
dimensions (Lx and/or Ly) increases the number of energetically accessible lateral states,
which leads to a stepwise increase of the conductance, characteristic of the lateral size
of the quantum point contact.
Case IV : Lz = Lx = Ly = L under strong confinement (a quantum dot):
Finally, when the particle is strongly confined in all three dimensions, the system is
often termed “a quantum dot.” In Section 5.2, we have already encountered the unique
properties of nanocrystals, which are a type of quantum dots and reveal the quan￾tum size effect. Indeed, the discrete spectrum of a quantum dot is apparent, and its
density of state is discontinuous. For the three-dimensional box model, each combi￾nation of the three quantum numbers (nx, ny, nz) contributes an isolated peak to the
density of states, ρ(E) = ∑
nx,ny,nz
δ(E − Enx,ny,nz
), where Enx,ny,nz
is given by Eq. (5.5.5),
and δ is Dirac’s delta function (discussed in detail in Chapter 11). Notice that different
combinations of quantum numbers may be associated with the same energy. Such acci￾dental degeneracies are demonstrated in Fig. 5.5.4 for a particle in a cubical box, where
Lx = Ly = Lz
.
https://doi.org/10.1017/9781108877787.006 Published online by Cambridge University Press45 Bibliography
tFigure 5.5.4 Energy levels and degeneracies in a symmetric three-dimensional box model. Each circle corresponds to a different set
of quantum numbers, (nx, ny, nz
), where the lowest energy corresponds to (1,1,1), the next level corresponds to the
three degenerate combinations, (2,1,1), (1,2,1), (1,1,2), and so on.
Bibliography
[5.1] R. L. Anderson,“Germanium-gallium arsenide heterojunctions,” IBM Journal
of Research and Development 4, 283 (1960).
[5.2] S. Datta, “Electronic Transport in Mesoscopic Systems” (Cambridge University
Press, 1997).
[5.3] C. Dekker, “Carbon nanotubes as molecular quantum wires,” Physics Today 52,
22 (1999).
[5.4] B. J. Van Wees, H. Van Houten, C. W. J. Beenakker et al., “Quantized con￾ductance of point contacts in a two-dimensional electron gas,” Physical Review
Letters 60, 848 (1988).
[5.5] R. Schuster, E. Buks, M. Heiblum et al., “Phase measurement in a quantum dot
via a double-slit interference experiment,” Nature 385, 417 (1997).
[5.6] U. Peskin, “An introduction to the formulation of steady-state transport
through molecular junctions,” Journal of Physics B: Atomic, Molecular and
Optical Physics 43, 153001 (2010).
https://doi.org/10.1017/9781108877787.006 Published online by Cambridge University Press6
Wave Function Penetration, Tunneling,
and Quantum Wells
6.1 The Scanning Tunneling Microscopy
In Chapter 1 we learned how the wave nature of the electrons was revealed for the
first time through their interaction with ordered matter on the subnanometer scale.
We start this chapter by discussing how the wave nature of electrons can be utilized for
unravelling the structure of matter on this length scale. Indeed, the Scanning Tunneling
Microscopy (STM), based on the wave phenomenon of electron tunneling, has become
one of the prominent experimental techniques for characterizing the detailed structure
of nanoscale objects on surfaces.
The STM apparatus (see Fig. 6.1.1) contains a sharp metal tip positioned above a
surface. The lateral position of the tip and its distance from the surface can be sen￾sitively controlled piezoelectrically with an atomic-scale resolution. The tip and the
surface are connected to a voltage source, which applies a controlled potential bias
between them. During operation, the tip and the surface are not in contact, and the
bias potential is insufficient for detaching an electron from the tip and/or the sur￾face. According to classical mechanics, in this situation electric current cannot flow
between the surface and the tip, since the electron’s potential energy at the spatial gap
between them is larger than the electron’s total energy (the gap region is said to be
“classically forbidden”). Nevertheless, a residual electric current does flow, which is
attributed to the quantum tunneling phenomenon. This current is exponentially sensi￾tive to the distance between the tip and the surface, which makes it a sensitive probe for
the surface structure. Structural changes on the surface, or the presence of adsorbed
atoms/molecules, affect the spatial gap and are reflected in changes in the tunneling cur￾rent. Changing the lateral position of the tip, while adjusting the height of the tip such
that the tunneling current remains constant (a constant current topography mode),
or keeping a fixed height and monitoring the changes in the current (constant height
topography mode), can be translated into detailed images of the surface plane with
atomic-scale resolution (see Fig. 6.1.2). The apparatus can also be used for Scanning
Tunneling Spectroscopy (STS). Changing the bias voltage at a fixed lateral tip posi￾tion and measuring the current at steady state, the local electrical conductivity can be
measured, and from it the local electronic density of states of the surface, or of adsor￾bates on the surface, can be inferred (see Chapter 20). Changing the bias voltage and
46
https://doi.org/10.1017/9781108877787.007 Published online by Cambridge University Press47 6.1 The Scanning Tunneling Microscopy
Tip
(a) (b)
h
Surface
Potential Energy
Tip Gap
h
Surface
Current
tFigure 6.1.1 (a) A schematic illustration of an STM apparatus. (b) A schematic representation of the effective potential energy for
electrons at the vicinity of the tunneling gap. Electrons are marked in gray.
tFigure 6.1.2 STM image of a carbon nanotube (image by Cees Dekker group at TU Delft, The Netherlands).
monitoring the transient response of the current can be used for following dynamical
processes on the surfaces [6.1], [6.2].
In Chapter 5 we discussed models of potential wells, where the external potential
was infinite, and the particle was perfectly confined to a finite region in space. How￾ever, realistic models should account for finite-valued potential energy wells and/or
barriers. As we shall see in what follows, in these cases, wave functions can pene￾trate “classically forbidden” regions, which facilitate transfer of particles “through”
(in contrast to “above”) potential energy barriers (see Fig. 6.1.1). This is the origin
of the tunneling phenomenon, and the basis for the STM operation. We emphasize
that tunneling is facilitated only for finite potential energy barriers, whereas for infinite
barriers, the wave function penetration vanishes and the phenomenon is suppressed.
In the next sections of this chapter, we shall become familiar with the solutions of the
Schrödinger equation for simple models of finite potential energy wells and barriers,
which will provide us with some knowledge about the wave function penetration, and
the quantum tunneling phenomena.
https://doi.org/10.1017/9781108877787.007 Published online by Cambridge University Press48 Wave Function Penetration, Tunneling,and Quantum Wells
6.2 A Particle in a Finite Square Well Potential and Wave Function
Penetration
The “particle in a box” model discussed in Section. 5.3 provides important insights into
the energy levels and stationary solutions of bound particles. Nevertheless, the model
is idealized in many important ways. Primarily, it assumes that the confining external
potential is infinite, resulting in perfect confinement of the particle within a finite region
in space. A more realistic description must account for a finite potential energy, where
quantum mechanics allows particles to ‘leak out’ of their potential energy wells into
regions that are ‘forbidden’ according to the laws of classical mechanics. In this section
we will become familiar with the phenomena of wave function penetration into clas￾sically forbidden regions, by solving the time-independent Schrödinger equation for a
particle trapped in a one-dimensional finite square well potential. The model potential
reads
V(x) =



V0 0 > x
0 0 ≤ x < L.
V0 L ≤ x
In classical mechanics, the particle would be free to move anywhere in space, pro￾vided that its total energy is above the threshold energy of the potential well, namely,
E ≥ V0. In this energy range the quantum system is in fact open, and the physically
meaningful solutions of the Schrödinger equation need not be proper. We shall post￾pone the discussion of free particles and improper states to Chapters 7 and 11, and
focus here on the bound states of the particle, namely, on the energy range, E < V0.
Classical mechanics implies that in this energy range the particle’s position would be
strictly limited to the “square box,” 0 ≤ x ≤ L (marked as region ‘(2)’ in Fig. 6.2.1). In
quantum mechanics the bound particle defines a closed system, where the physically
meaningful solutions of the Schrödinger equation must be proper. However, given that
V0 is finite, there is no reason to assume a priori that the probability density strictly
vanishes outside the square box. We should therefore look for proper solutions to the
time-independent Schrödinger equation in the entire coordinate space. Since the poten￾tial is piecewise constant, it is convenient to first solve the Schrödinger equation in each
segment separately, and then assure that the solutions are proper also at the boundary
points between the segments.
Numbering the three segments, n = 1,2,3, as in Fig. 6.2.1, the potential energy
obtains the respective constant values, {Vn}, and the respective Schrödinger equation
(Eq. (4.3.4)) in each segment reads
−h¯
2
2m
∂
2
∂ x
2
ψn(x) +Vnψn(x) = Eψn(x). (6.2.1)
https://doi.org/10.1017/9781108877787.007 Published online by Cambridge University Press49 6.2 A Particle in a Finite Square Well Potential and Wave Function Penetration
E
(1) (2)
0
0
x
V(x)
V0
L
(3)
tFigure 6.2.1 The potential energy for a particle in a finite one-dimensional square potential well. The regions of constant potential
energy are numbered as (1), (2), and (3).
Defining,
kn ≡
s
2m(E −Vn)
h¯
2
, (6.2.2)
a general solution for the nth segment reads
ψn(x) = ane
iknx +bne
−iknx
. (6.2.3)
On physical grounds, we must restrict ourselves to proper solutions. First, the wave
function must decay to zero at the asymptotes, x → ±∞ (see Eq. (2.2.1)). Second, as a
solution of a second-order differential equation, the proper wave function must be
continuously differentiable anywhere in space. The latter is readily satisfied within
each segment by Eq. (6.2.3), but must be imposed at the boundary points between
nearby segments; namely, both the function and its derivative must be continuous at
the boundary points (x = 0 and x = L).
Considering first the asymptote at segment (3), the following condition must be ful￾filled, ψ3(x) = a3e
ik3x + b3e
−ik3x −→x→+∞
0. For E < V0, k3 obtains an imaginary value,
k3 =
q2m(E−V0)
h¯
2 ≡
i
γ
(where i =
√
−1). It follows that the first exponent indeed con￾verges to zero as x → ∞, but the second exponent diverges. The only way to assure a
proper function ψ3(x) is therefore to set the coefficient b3 to zero. Consequently,
ψ3(x) = a3e
ik3x = a3e
−x/γ
. (6.2.4)
The result has several important characteristics. First of all, there is a finite probabil￾ity density to find the particle in a “classically forbidden” region, namely in a region
of space, where the total energy, E, is smaller than the potential energy, V0. This phe￾nomenon is referred to as the wave function penetration into a classically forbidden
region. Second, within this region, the probability is shown to decay exponentially, as
the distance from the classically allowed region (the potential well) increases, with a
“penetration length,” γ = √
h¯
2m(V0−E)
. The penetration length is shown to be larger for
lighter particles (smaller mass, m), and at higher particle energies, E, namely, as the
energy approaches the threshold, V0. Notice that this result is in line with the classical
https://doi.org/10.1017/9781108877787.007 Published online by Cambridge University Press50 Wave Function Penetration, Tunneling,and Quantum Wells
result, which states that above the threshold, the particle should not be confined to the
well region at all.
Similarly, the asymptotic condition at segment (1) reads, ψ1(x) = a1e
ik1x +
b1e
−ik1x −→x→−∞
0. Since k1 is also imaginary, k1 =
q2m(E−V0)
h¯
2 = k3, the only way to assure
a proper ψ1(x) is to set the coefficient a1 to zero. Consequently,
ψ1(x) = b1e
−ik1x = b1e
x/γ
. (6.2.5)
Also here, the wave function is shown to penetrate exponentially into the classically
forbidden region of space (in the direction of negative x).
In the intermediate segment, (2), the wave function is not restricted by the asymptotic
conditions and generally reads (Eq. (6.2.3))
ψ2(x) = a2e
ik2x +b2e
−ik2x
. (6.2.6)
However, the requirement on the solutions of the Schrödinger equation to be contin￾uously differentiable anywhere in space imposes additional constraints on the proper
solutions. Particularly, the wave function and its first derivative must be continuous
also at the boundary points between nearby segments (x = 0 and x = L):
ψ1(0) = ψ2(0)
d
dx
ψ1(x)




x=0
=
d
dx
ψ2(x)




x=0
ψ2(L) = ψ3(L)
d
dx
ψ2(x)




x=L
=
d
dx
ψ3(x)




x=L
. (6.2.7)
Any proper solution is therefore defined by a set of variables,(b1,a2,b2,a3), which must
satisfy Eq. (6.2.7). The four continuity conditions translate into a homogeneous system
of linear equations for these variables:




1 1 −1 0
ik2 −ik2 ik1 0
e
ik2L
e
−ik2L 0 −e
+ik3L
ik2e
ik2L −ik2e
−ik2L 0 −ik3e
ik3L








a2
b2
b1
a3




=




0
0
0
0




. (6.2.8)
Notice that the trivial solution to this matrix equation, b1 = a2 = b2 = a3 = 0, corre￾sponds to an improper wave function, ψ(x) = 0. Nontrivial solutions exist, for which
the determinant of the coefficient matrix vanishes. Since the determinant depends on
the energy via k1 = k3 =
q2m(E−V0)
h¯
2 and k2 =
q2mE
h¯
2
, it vanishes only for specific values
of the particle’s energy E (for a discrete set). Indeed, the energy spectrum for a bound
particle in a finite square potential well is quantized. This is demonstrated in Fig. 6.2.2
for a model of an electron bound in a 1-nm-long square potential well. The plot of
the determinant as a function of energy reveals a set of local minima that point to
https://doi.org/10.1017/9781108877787.007 Published online by Cambridge University Press51 6.2 A Particle in a Finite Square Well Potential and Wave Function Penetration
0
−15
−10
−5
1 2 3 4 5
E (eV)
log [ |det |
2]
6 7 8 9 10
tFigure 6.2.2 The emergence of energy quantization in a finite square well potential. The minima point to a discrete set of zeros,
which correspond to the energy level of the bound particle. The finite square potential well parameters are
m = 1 a.u., L = 1 nm, andV0 = 10 eV.
the energy levels of the particle in the finite potential well, for which the determinant
vanishes.
For each energy level, the corresponding stationary solution (the vector
(b1,a2,b2,a3)) can be determined. Notice that the solutions to the system of equations,
Eq. (6.2.8), are defined only up to a multiplication by a constant, which can be set by
the normalization requirement (see Section 2.3). Probability densities associated with
the stationary solutions of the bound particle in the finite potential well are plotted in
Fig. 6.2.3 (solid lines). It is instructive to compare the energy spectrum and the sta￾tionary solutions to those of a particle in the corresponding infinite box of the same
length (the dashed lines in Fig. 6.2.3). The results have apparent similarities, where
the energy levels are quantized in both cases, and the stationary solutions correspond￾ing to the same quantum number (the energy-level index) are qualitatively similar in
terms of the shape of the probability density distribution and the number of nodes.
There are, however, several important differences. In the case of a finite potential well:
first, the probability density is shown to penetrate the classically forbidden region, as
we have discussed (Eqs. (6.2.4, 6.2.5)), which becomes more pronounced as the energy
increases; and second, the density of states is larger, namely, the gap between nearby
energy levels is smaller. Notice that this is yet another manifestation of the quan￾tum size effect: the effectively lower spatial confinement of the particle in the finite
potential well (due to the wave function penetration) is correlated with a denser energy
spectrum.
Exercise 6.2.1 Derive Eq. (6.2.8).
Exercise 6.2.2 Show that, when V0 → ∞, the energy levels and the stationary solutions
of the Schrödinger equation for the symmetric finite square well potential converge to the
results for an infinite box, obtained in Chapter 5.
https://doi.org/10.1017/9781108877787.007 Published online by Cambridge University Press52 Wave Function Penetration, Tunneling,and Quantum Wells
2
4
6
8
10
−10 −5 0 5
x (Å)
V (eV)
10 15 20
12
tFigure 6.2.3 Energy levels and probability densities for a particle in a finite square well potential. The different plots correspond to
different energy levels. The plots are displaced from each other by the respective energy differences. Solid lines
correspond to the finite square well potential (see Fig.6.2.2). Dashed lines correspond to an infinite external potential
V0 → ∞, discussed in Chapter5.
6.3 The Schrödinger Equation for a Piecewise Constant Potential
Energy
The method implemented in the previous section is readily generalizable for solving the
time-independent Schrödinger equation in cases where the potential energy is piecewise
constant, as defined in Eq. (6.3.1):
V(x) =



x < x1 ; V1
x1 ≤ x < x2 ; V2
.
.
.
xN−2 ≤ x < xN−1 ; VN−1
xN−1 ≤ x ; VN
. (6.3.1)
The coordinate space is divided into N segments, in which the potential energy
obtains a constant value, Vn (see Fig. 6.3.1). The Schrödinger equation within each
https://doi.org/10.1017/9781108877787.007 Published online by Cambridge University Press53 6.3 The Schrödinger Equation for a Piecewise Constant Potential Energy
x1
V1
V2
V3
V4
VN
V(x)
x
x2 x3 . . . xN−1
tFigure 6.3.1 A schematic representation of a piecewise constant potential energy.
segment, xn−1 ≤ x < xn, obtains the form of Eq. (6.2.3), where the general solution is
given by Eqs. (6.2.2, 6.2.3):
ψ(x) =







x < x1 ; a1e
ik1x +b2e
−ik1x
x1 ≤ x < x2 ; a2e
ik2x +b2e
−ik2x
.
.
.
xN−2 ≤ x < xN−1 ; aN−1e
ikN−1x +bN−1e
−ikN−1x
xN−1 ≤ x ; aNe
ikNx +bNe
−ikNx
. (6.3.2)
A specific solution is defined by the set of 2N coefficients, (a1,a2,...,aN,b1,b2,...,bN).
Again, we shall restrict the discussion to the energy range in which a classical particle
would be trapped in a finite range in space, namely, a bound particle (free particles will
be considered in the next chapter). This means
E < min(V1,VN). (6.3.3)
In this energy range, the quantum system is closed and the physically meaningful solu￾tions to the Schrödinger equation must be proper. It follows that the wave functions
must vanish asymptotically,
ψ1(x) −−→x → −∞
0 ; ψN(x) −−→x → ∞
0, (6.3.4)
as well as be continuously differentiable at each of the N −1 boundary points between
the segments:
ψn(xn) = ψn+1(xn)
d
dx
ψn(x)




x=xn
=
d
dx
ψn+1(x)




x=xn
. (6.3.5)
The requirement for proper solutions therefore imposes 2N equations for the 2N wave
function coefficients. Eq. (6.3.4) sets two of the coefficients in the asymptotic segments
https://doi.org/10.1017/9781108877787.007 Published online by Cambridge University Press54 Wave Function Penetration, Tunneling,and Quantum Wells
to zero (see the discussion of Eqs. (6.2.4) and (6.2.5) in the previous section for the
asymptotic solutions),
a1 = 0 ; bN = 0, (6.3.6)
and Eq. (6.3.5) leads to N − 1 pairs of linear equations for the remaining 2N − 2
coefficients,
ane
iknxn +bne
−iknxn −an+1e
ikn+1xn −bn+1e
−ikn+1xn = 0
ikne
iknxn an −ikne
−iknxn bn −ikn+1e
ikn+1xn an+1 +ikn+1e
−ikn+1xn bn+1 = 0, (6.3.7)
where, n = 1,2,...,N − 1. The result is a homogeneous matrix equation for the
coefficients,
















e−ik1x1 −e
ik2x1 −e−ik2x1
−ik1e−ik1x1−ik2e
ik2x1 ik2e−ik2x1
e
ik2x2 e−ik2x2 −e
ik3x2 −e−ik3x2
ik2e
ik2x2 −ik2e−ik2x2 −ik3e
ik3x2 ik3e−ik3x2
.
.
.
e
ikN−1xN−1 e−ikN−1xN−1 −e
ikNxN−1
ikN−1e
ikN−1xN−1 −ikN−1e−ikN−1xN−1 −ikNe
ikNxN−1
































b1
a2
b2
a3
b3
.
.
.
aN−1
bN−1
aN
















=
















0
0
0
0
0
.
.
.
0
0
0
















,
(6.3.8)
which obtains a nontrivial solution only when the matrix determinant vanishes. Since
the matrix entries depend on the energy via kn =
q2m(E−Vn)
h¯
2
, the determinant vanishes
only for a set of E values, which constitute the energy levels of the particle in the general
potential well. Given E, the corresponding coefficient vector can be determined (up
to a constant). Imposing the normalization condition, a specific solution to the time￾independent Schrödinger equation (in the form of Eq. (6.3.2)) is obtained for each
energy level.
6.4 The Symmetric Double Well Potential and Quantum Tunneling
In this section we consider the Schrödinger equation for a particle bound in a symmet￾ric double well potential, whose solutions demonstrate the phenomenon of quantum
tunneling in bound systems. The potential energy for this model is defined as follows:
V(x) =



x < −(D/2+L) ; V0
−(D/2+L) ≤ x < −D/2 ; 0
−D/2 ≤ x < D/2 ; V0
D/2 ≤ x < D/2+L ; 0
D/2+L ≤ x ; V0
. (6.4.1)
https://doi.org/10.1017/9781108877787.007 Published online by Cambridge University Press55 6.4 The Symmetric Double Well Potential and Quantum Tunneling
V0
V(x)
x
L D L
0
0
tFigure 6.4.1 A symmetric double square well potential
The length of each well is set to L, and the energy “depth” is set to V0, just as for the
single square potential well discussed in Section 6.2 (see Fig. 6.2.1). In this model sys￾tem, however, there are two wells, separated by a distance D (Fig. 6.4.1). Here also,
we are interested in the bound states of the particle, namely, in the energy range where
the total energy is below the potential energy threshold, E < V0. Notice that according
to classical mechanics, a bound particle in this energy range can be confined to one,
and only one, of the two wells, since the region between the wells is classically forbid￾den. In contrast, we shall see that quantum mechanics allows for delocalization of a
bound particle between the wells, which manifests the quantum tunneling phenome￾non in bound systems. In precise terms, the bound state solutions to the Schrödinger
equation for this system correspond to probability densities that are distributed
between the two wells at the same time. As we shall see, the tunneling phenomenon
is closely related to the penetration of the wave functions into the classically forbidden
region.
Let us consider the stationary solutions for the double well system, as calculated
according to the general methodology described in Section 6.3. In Fig. 6.4.3 the solu￾tions corresponding to the two lowest energy levels are presented for different distances
(D) between the two wells. It is instructive to analyze the results in comparison to
the solutions for the respective single well potential. When the two wells are far apart
(Fig. 6.4.3a), the two lowest energy levels of the double well potential become nearly
degenerate and converge to the value of the lowest energy of the respective single well
potential (E1 = 2 eV, for the given parameters). The corresponding stationary wave
functions in each well seem to coincide (up to a sign, in each well) with the lowest energy
solutions of two isolated potential wells. This behavior is characteristic of inter-well
distances, which are much larger than the penetration length of the single well solu￾tion into the classically forbidden region, namely, D >> γ = √
h¯
2m(V0−E1)
. In the other
extreme (Fig. 6.4.3c), the distance between the wells is much smaller than the penetra￾tion length, D << γ. In this range the two lowest energy solutions of the double well
potential appear to resemble the solutions of a single well potential, whose length is
the sum of the two well lengths (∼ 2L). In the intermediate regime (Fig. 6.4.3b), the
distance between the wells is of the order of the penetration length of the single well
solution, D ∼ γ. The two lowest energy levels as well as the corresponding stationary
https://doi.org/10.1017/9781108877787.007 Published online by Cambridge University Press0
2
4
6
8
10
(a)
−15 −10 −5 0 5 10 15
x (a.u.)
V (eV)
0
2
4
6
8
10
(b)
−15 −10 −5 0 5 10 15
x (a.u.)
V (eV)
0
2
4
6
8
10
(c)
−15 −10 −5 0 5 10 15
x (a.u.)
V (eV)
tFigure 6.4.2 The two lowest energy levels and the respective wave functions for a particle in a double square well potential. The
different plots correspond to different energy levels. The plots are displaced from each other by the respective energy
difference. (a), (b), and (c) correspond to decreasing inter-well distance, where D = 10γ, γ,0.1γ, respectively. The
model parameters are m = 1 electron mass, L = 0.3 nm, andV0 = 10 eV. The lowest energy level of the isolated
single well is E1 = 2 eV, and the penetration length of the corresponding stationary state is γ = 0.069 nm.
https://doi.org/10.1017/9781108877787.007 Published online by Cambridge University Press57 6.4 The Symmetric Double Well Potential and Quantum Tunneling
solutions in this regime cannot be approximated by any single well solution, and reflect
the unique characteristics of the double well potential.
Let us reemphasize that the solutions depicted in Fig. 6.4.3 were all obtained for the
double well potential, and their analysis in terms of solutions to a single well potential
in the limits, D << γ, and D >> γ is merely a convenient interpretation. The first
apparent characteristic common to all cases is that each stationary solution in the
double well system is delocalized over the two wells. This means that there is a prob￾ability for the particle to be located at the two wells in a stationary state (namely,
“simultaneously”), in contrast to the results of classical mechanics. Moreover, the
probabilities for locating the particle in the left and right wells are equal. This is a
result of the right–left symmetry of the model Hamiltonian. Specifically, the Hamil￾tonian for the symmetric double well system commutes with the parity operator (see
Ex. 4.6.2). Consequently, the Hamiltonian eigenfunctions are also eigenfunctions of
the parity operator (see Ex. 6.4.1); namely, they are either even or odd functions of
the position, x (see Ex. 4.6.2). It follows that the absolute squares of the stationary
solutions that correspond to a bound electron are even function of x.
Exercise 6.4.1 Show that if the two linear operators, denoted Hˆ and Pˆ, commute
([Hˆ,Pˆ] = 0), and if ψ is an eigenfunction of Hˆ that corresponds to a nondegenerate
eigenvalue, then ψ is also an eigenfunction of Pˆ.
We now turn to discussing the dynamics of a bound particle in the double well
potential. Recalling that any linear combination of stationary solutions to the time￾dependent Schrödinger equation is also a solution (see Ex. 4.6.5), let us consider a
specific (normalized) linear combination of the stationary solutions corresponding to
the two lowest energy levels, E1 and E2:
ψ(x,t) = 1
√
2
ψE1
(x)e
−iE1t/h¯ +
1
√
2
ψE2
(x)e
−iE2t/h¯
. (6.4.2)
Since the solutions are nondegenerate (with E2 > E1), ψ(x,t) is not a stationary
solution, and the probability density depends on time:
ρ(x,t) = 1
2
|ψE1
(x) +ψE2
(x)e
−i(E2−E1)t/h¯
|
2
. (6.4.3)
The functions ψE1
(x) and ψE2
(x) are even and odd functions of x, respectively (see
Fig. 6.4.3 and Ex. 6.4.1), which have the same sign for x < 0, and opposite signs
for x > 0. For tn =
2nπh¯
E2−E1
(n = 0,±1,±2,...), the probability density reads ρ(x,tn) ∝
|ψE1
(x)+ψE2
(x)|
2
. At these times, ψE1
(x) and ψE2
(x) interfere constructively for x < 0,
and destructively for x > 0, such that the probability density favors the population
of the left potential well. In contrast, at different times, tn =
(2n+1)πh¯
E2−E1
, the probability
density reads ρ(x,tn) ∝ |ψE1
(x)−ψE2
(x)|
2
, and the population of the right potential is
favored. It follows that the probability for locating the bound particle in space oscillates
periodically between the two wells, with a time period,
τ =
h
E2 −E1
. (6.4.4)
https://doi.org/10.1017/9781108877787.007 Published online by Cambridge University Press58 Wave Function Penetration, Tunneling,and Quantum Wells
x [Å]
ρ(x,t)
t [a.u.]
0
5
10
−15 −5 5 15
500
400
300
200
100
0
tFigure 6.4.3 Time-dependent probability density for a particle in a symmetric double square well potential. The model parameters
are as for Fig. 6.4.2b.
This is demonstrated in Fig. 6.4.3. Notice that a bound classical particle located at
one of the wells would have zero probability to be found in the other well at any time.
Quantum mechanics allows the bound particle to tunnel through the potential barrier
between the wells and transfer to the other well. Nevertheless, the probability of finding
the particle at the barrier region remains relatively low at any time. This is the case
when the inter-well distance is similar to or larger than the penetration length of the
stationary wave functions associated with the two independent wells.
Notice that as E2 → E1, the time for transfer between the wells approaches infinity
(Eq. (6.4.4)). This is the limiting case of the situation illustrated in Fig. 6.4.3a, where
the distance between the wells is much larger than the penetration length (D >> γ).
Indeed, in this limit the two lowest-energy (even and odd) eigenfunctions of the double
well Hamiltonian become degenerate, such that their linear combinations (Eq. (6.4.2))
are also eigenfunctions of the Hamiltonian (see Ex. 4.6.3). In particular, the wave func￾tions, ψE1
(x)±ψE2
(x), which confine the probability density to only one of the wells,
become stationary solutions. This limit is in line with the classical results. However,
as the distance (D) between the wells becomes finite, the energy splitting (E2 − E1)
increases, and the time period for quantum tunneling between the wells decreases
accordingly.
We end this section by noting that while the tunneling phenomenon facilitates pow￾erful experimental analysis tools, such as STM and STS, it is a major problem in the
context of miniaturization of nanoscale electronics devices. The tendency of electrons
to delocalize between nearby quantum wells hinders their confinement into specific,
independent conductance channels, resulting in leakage currents, when the conductors
https://doi.org/10.1017/9781108877787.007 Published online by Cambridge University Press59 6.5 A Particle in Multiple Quantum Wells and Energy Bands
tFigure 6.5.1 Energy levels and probability densities for a particle (m = 1 a.u.) in several multiple square well potentials,
demonstrating the formation of energy bands and gaps with increasing number of wells. The different plots in each
frame correspond to different energy levels. The plots are displaced from each other by the respective energy
differences.
are too closely packed. This poses a physical lower bound for miniaturization of elec￾tronic devices. The quest for denser information processing devices must therefore
account for nonclassical architectures, designed to operate in the quantum tunneling
regime.
6.5 A Particle in Multiple Quantum Wells and Energy Bands
In this section we briefly discuss the solution of the Schrödinger equation for a parti￾cle in multiple (N) potential wells. The stationary solutions of the time-independent
Schrödinger equation for such systems can be readily obtained as described in Sec￾tion 6.3. In Fig. 6.5.1 we present the corresponding energy levels and probability
densities for systems of different N. Each stationary solution is shown to be delocal￾ized over all the potential wells, which implies that the bound particle is not confined
to any particular potential well.
https://doi.org/10.1017/9781108877787.007 Published online by Cambridge University Press60 Wave Function Penetration, Tunneling and Quantum Wells
The characteristics of the solutions can be rationalized by referring again to the case
of the double well potential (N = 2). In Fig. 6.4.3, we notice that when the two potential
wells are sufficiently far apart, D>˜ γ, the energy levels appear in nearby pairs, separated
by larger energy gaps, where each pair can be correlated to a single energy level of an
independent single potential well. (This becomes most apparent in the limit, D >> γ.)
A similar trend is observed also for N > 2. The energy spectrum is composed of rel￾atively dense groups of N levels, separated by larger energy gaps, where each group
can be correlated to one of the energy levels of the independent single potential well.
As N becomes larger, each group becomes denser, such that in the limit, N → ∞, the
energy spectrum consists of continuous energy bands separated by “forbidden” energy
gaps. The formation of energy bands and gaps is essential for understanding the prop￾erties of extended materials. We postpone a more rigorous discussion of the emergence
of energy bands and gaps in the spectrum of different materials and its consequences
to Chapter 14. Here we only comment that energy bands are characteristic of spatially
periodic structures, and that as the number of potential energy wells becomes large, the
system of quantum wells can be well approximated as a periodic structure [6.3]. This
is most relevant for understanding the mobility of valence electrons in perfect atomic
lattices, and the phenomenon of conductance, as will be discussed in Chapter 14.
Bibliography
[6.1] H. J. Lee and Wilson Ho. “Single-bond formation and characterization with a
scanning tunneling microscope,” Science 286, 1719 (1999).
[6.2] T. L. Cocker, D. Peller, P. Yu, J. Repp, and R. Huber, “Tracking the ultrafast
motion of a single molecule by femtosecond orbital imaging,” Nature 539, 263
(2016).
[6.3] R. de L. Kronig and W. G. Penney, “Quantum mechanics of electrons in crystal
lattices,” Proceedings of the Royal Society of London. Series A 130, 499 (1931).
https://doi.org/10.1017/9781108877787.007 Published online by Cambridge University Press7 The Continuous Spectrum and Scattering States
7.1 The Continuity Equation and the Probability Current Density
In previous chapters we focused on closed systems, in which the particles are confined
to some finite region in coordinate space. It is of interest, however, to consider also
open systems, in which particles (or energy) may leak out, of enter. Postponing a more
formal discussion of open quantum systems to Chapter 19, here we focus on a par￾ticular kind of open system, in which there is a stationary flow of particles through
the entire space. This description corresponds to scattering experiments, where a well￾defined stationary current (i.e., a flux) of particles is directed toward a target. The
resulting currents of particles scattered from the target are continuously monitored,
and their spatial distribution in space provides useful information with respect to the
target. Indeed, scattering of particles such as electrons, neutrons, and other light par￾ticles, at energies in which their de Broglie wavelength is of the order of interatomic
distances, provided most valuable information with respect to the structure of matter
on the nanoscale. In this chapter we give a modest introduction to the solutions of the
Schrödinger equation in the scattering regime, emphasizing fundamental differences
between scattering and bound states.
We already learned that particle positions in space are associated with a probability
density functions. But what is a corresponding suitable description of particle currents?
To answer this, we notice that the time-dependent Schrödinger equation can be rewrit￾ten as a universal continuity equation. Without loss of generality, let us consider a
system of N particles of masses (m1,m2,...,mN), in a three-dimensional space, where
the nth particle is associated with the Cartesian coordinates,(x1,n, x2,n, x3,n). The multi￾dimensional wave function reads ψ(x1,1, x2,1, x3,1, x1,2,..., x3,N,t) ≡ ψ(x,t). Given that
ψ(x,t) is a solution to the time-dependent Schrödinger equation (Eqs. (3.4.7, 3.4.8,
4.1.1)), it follows that (see Ex. 7.1.1)
∂
∂t
|ψ(x,t)|
2 = −∇·J(x,t), (7.1.1)
where the gradient vector reads ∇ = ( ∂
∂ x1,1
,
∂
∂ x2,1
,
∂
∂ x3,1
,
∂
∂ x1,2
,...,
∂
∂ x3,N
), and the corre￾sponding components of the vector J(x,t) read
Jj,n(x,t) ≡
h¯
mn
Im[ψ
∗
(x,t)
∂
∂ xj,n
ψ(x,t)]. (7.1.2)
61
https://doi.org/10.1017/9781108877787.008 Published online by Cambridge University Press62 The Continuous Spectrum and Scattering States
Recalling the association of |ψ(x,t)|
2 as a probability density, Eq. (7.1.1) has the
universal form of a continuity equation. The vector J(x,t) is therefore identified as the
probability current density (or “probability flux”) corresponding to the wave function
ψ(x,t). In its integral form, Eq. (7.1.1) means that the loss of probability from any
volume in the multidimensional space equals the total probability current exiting that
volume through the surface surrounding it,
−
∂
∂t
w
V
|ψ(x,t)|
2
dx =
z
S
J(x,t)·dS. (7.1.3)
Exercise 7.1.1 A system of N particles is associated with the Hamiltonian
Hˆ =
N
∑
n=1
−h¯
2
2mn

∂
2
∂ x
2
1,n
+
∂
2
∂ x
2
2,n
+
∂
2
∂ x
2
3,n

+ V(x1,1, x2,1, x3,1, x1,2,..., x3,N), where the nth par￾ticle is associated with the Cartesian coordinates, (x1,n, x2,n, x3,n). The state of the
system is represented by a solution to the time-dependent Schrödinger equation,
ψ(x1,1, x2,1, x3,1, x1,2,..., x3,N,t) ≡ ψ(x,t). Prove the following identity: ∂
∂t
|ψ(x,t)|
2 =
−
N
∑
n=1
3
∑
j=1
∂
∂ x
j,n
Jj,n(x,t), where Jj,n(x,t) ≡
h¯
mn
Im[ψ
∗
(x,t)
∂
∂ x j,n
ψ(x,t)].
We now focus specifically on the stationary solutions to the time-dependent
Schrödinger equation, which are associated with well-defined energies, E, and obtain
the form, ψ(x,t) = ψE(x)e
−iEt/h¯
. Both the probability density, |ψ(x,t)|
2 = |ψE(x)|
2
,
and the corresponding probability flux, JE(x) (see Eq. (7.1.2)), are time-independent
in this case, which means that the continuity equation (Eq. (7.1.1)) takes a simpler
form:
∇JE(x) = 0 ; z
S
JE(x)·dS = 0. (7.1.4)
The vanishing divergence ∇JE means that the probability flux exiting from the sur￾face of any volume element (infinitesimal, or finite) in coordinate space must vanish.
Expanding the volume element to the entire coordinate space, one can distinguish
between two cases: if the system is a closed one, the probability flux itself, JE(x),
vanishes at the boundary surface, and the integral in Eq. (7.1.4) is trivially satisfied.
This is consistent with ψE(x) being a proper wave function, as discussed in Chapter 2,
which vanishes at the boundary surface (see, e.g., Eq. (2.2.1) for the one-dimensional
case). If the system is open, however, where particles can flow in and out of its space,
JE(x) does not have to vanish at the boundary surface. Probability conservation, as
expressed in Eq. (7.1.4), requires only that any probability fluxes entering the entire
space must equal the probability fluxes exiting from it. Importantly, nonvanishing
fluxes at the space boundaries are associated with nonvanishing wave functions. It fol￾lows that stationary wave functions that satisfy Eq. (7.1.4) need not be proper, and that
in this case, |ψE(x)|
2
cannot be interpreted as a probability density. (Indeed, the formu￾lation of probability conservation for stationary states (Eq. (7.1.4)) does not depend
explicitly on |ψE(x)|
2
, only on JE(x).) Importantly, improper stationary solutions,
ψ(x,t) = ψE(x)e
−iEt/h¯
, satisfying Eqs. (7.1.2, 7.1.4), when they exist, are still associ￾ated with a well-defined physical meaning. These are the “scattering wave functions” of
https://doi.org/10.1017/9781108877787.008 Published online by Cambridge University Press63 7.2 Scattering in One Dimension
the system [7.1], corresponding to stationary flows of particles at a given energy. Infor￾mation on the scattering process is contained in the relative distribution of probability
fluxes at the space boundaries, where fluxes of particles can be measured by proper
experiments. As we have discussed, the boundary conditions imposed on the scattering
wave functions are less strict than the boundary conditions imposed on proper solu￾tions (as the wave function does not need to vanish asymptotically). Consequently, as
we shall see in the following section, the scattering states are not quantized, and their
energy spectrum is continuous.
7.2 Scattering in One Dimension
In this section we shall discuss in some detail scattering wave functions and their cor￾responding probability fluxes in the case of stationary scattering of a single particle of
mass m in a one-dimensional coordinate space (x). In this case the continuity equation,
Eq. (7.1.1), simplifies to
∂
∂t
|ψ(x,t)|
2 ≡ −
∂
∂ x
J(x,t), (7.2.1)
where the probability current density reads
J(x,t) ≡
h¯
m
Im[ψ
∗
(x,t)
∂
∂ x
ψ(x,t)]. (7.2.2)
For a stationary solution, ψ(x,t) = e
−iEt/h¯ψE(x), the probability flux is readily shown
to be time-independent,
JE(x) =
h¯
m
Im[ψ
∗
E
(x)
∂
∂ x
ψE
(x)], (7.2.3)
where Eq. (7.2.1) yields in this case a constant probability flux,
JE(x) = Const, (7.2.4)
which is analogous to Eq. (7.1.4) in the more general case.
Exercise 7.2.1 A single particle in a one-dimensional coordinate space (x) is associated
with a proper stationary wave function. Show that the probability flux vanishes anywhere
in space in this case.
First, let us focus on a stationary flow of free particles, in a system in which the poten￾tial energy is constant, V(x) = V0. The corresponding time-independent Schrödinger
equation reads
−h¯
2
2m
∂
2
∂ x
2
ψE(x) +V0ψE(x) = EψE(x), (7.2.5)
and the general solutions (see Eqs. (6.2.1–6.2.3)) obtain the form
https://doi.org/10.1017/9781108877787.008 Published online by Cambridge University Press64 The Continuous Spectrum and Scattering States
ψE(x) = aeikx +be−ikx ; k =
s
2m(E −V0)
h¯
2
. (7.2.6)
Specific solutions are the “plane waves” associated with E > V0, defined as
ψE±
(x) ≡ e
±ikx
. (7.2.7)
Each plane wave is an eigenfunction of the linear momentum operator, pˆx = −ih¯
∂
∂ x
,
pˆxe
±ikx = ±khe¯
±ikx
, (7.2.8)
with a real eigenvalue, px = ±kh¯. According to the postulates of quantum mechanics
(see Section 4.4, and Chapter 11), this implies that these solutions represent a flow of
particles with well-defined momentum, where the different waves, e
+ikx and e
−ikx, cor￾respond to particles moving in the left-to-right and right-to-left directions, respectively.
Substitution in Eq. (7.2.3) yields the corresponding particle fluxes:
JE±
(x) = h¯
m
Im[e
∓ikx
∂
∂ x
e
±ikx] = ±
kh¯
m
. (7.2.9)
The probability fluxes associated with the plane wave solutions can therefore be iden￾tified with the particle’s velocities, px/m. A general solution to Eq. (7.2.5) is therefore a
superposition of plane waves propagating in opposite directions, where the momentum
is not necessarily defined. (Indeed,ψE(x)in Eq. (7.2.6) is generally not an eigenfunction
of pˆx.) Nevertheless, the probability flux obtains a well-defined value for any general
solution according to Eq. (7.2.3),
JE = |a|
2
JE+ −|b|
2
JE− =
kh¯
m
(|a|
2 −|b|
2
), (7.2.10)
which is the weighted difference between the left-to-right and the right-to-left fluxes.
We now consider the scattering of particles through a one-dimensional space with an
alternating potential energy, which is piecewise constant, as defined in Eq. (6.3.1) (see
Fig. 7.2.1). The formal solution of the time-independent Schrödinger equation in this
case is given by Eq. (6.3.2). In Section 6.3 we discussed the bound states corresponding
to particles trapped in space, whose energy is smaller than the asymptotic potential
energy thresholds (V1 on the left, and VN on the right, see Fig. 7.2.1). Here we discuss
the scattering state for the same system, at particle energies for which a classical particle
could propagate to x → ∞ and/or x → −∞, namely,
E > min(V1,VN). (7.2.11)
In this energy range the quantum system is open. Consequently, the physically mean￾ingful stationary solutions must satisfy Eq. (7.2.4), but they don’t need to be proper.
Therefore, the boundary conditions imposed at the asymptotes are different from the
ones applied in the case of bound states.
Without loss of generality, let us consider a source of particles located infinitely far
on the left, (x → −∞), in the segment n = 1. The corresponding asymptotic wave func￾tion is ψ1(x) = a1e
ik1x +b1e
−ik1x
, where k1 =
q2m(E−V1)
h¯
2
. The source transmits a flux of
https://doi.org/10.1017/9781108877787.008 Published online by Cambridge University Press65 7.2 Scattering in One Dimension
V(x)
x
x1
V1
(1)
V2
V3
V4
VN
J E−
(1) J E+ (N ) J E+
x2 x3 . . . xN−1
tFigure 7.2.1 A schematic representation of a piecewise constant potential energy. The incoming probability flux (J
(1)
E+
) as well as
the transmitted (J
(N)
E+
) and reflected (J
(1)
E−
) fluxes in the asymptotic regions are marked by arrows.
free particles from left to right, which corresponds to the incoming plane wave, a1e
ik1x
.
Using Eq. (7.2.3), this flux corresponds to
J
(1)
E+
= |a1|
2
hk¯ 1
m
. (7.2.12)
It follows that a1 must obtain a finite value in this case. Since the solution to the
Schrödinger equation is defined up to a multiplication by a constant, it is conventional
to set it to unity,
a1 = 1. (7.2.13)
The same consideration applies to the asymptotic region on the right (x → +∞, in
the segment n = N), where the asymptotic wave function is ψN(x) = aNe
ikNx +bNe
−ikNx
.
Having no source of particles in that region, the incoming right-to-left flux must vanish,
which means
bN = 0. (7.2.14)
Equations (7.2.13, 7.2.14) constitute the selected scattering boundary conditions.
(Notice that similar boundary conditions would correspond to a flux source located
on the right, setting a1 = 0 and bN = 1.) In any event, these boundary conditions differ
from the asymptotic boundary conditions for bound states (which read a1 = bN = 0,
see Eq. (6.3.6)) in that one of the incoming asymptotic waves has a nonvanishing
contribution.
Recalling that a solution to the Schrödinger equation must be continuously differ￾entiable, the scattering wave function and its derivative must be continuous at each
one of the N −1 boundary points between nearby segments (Eq. (6.3.5)). The resulting
2(N −1) equations plus the two boundary conditions (Eqs. (7.2.13, 7.2.14)) can be cast
into a system of linear equations for the wave function coefficients in all segments,
https://doi.org/10.1017/9781108877787.008 Published online by Cambridge University Press66 The Continuous Spectrum and Scattering States











1
e
ik1
x1 e
−ik1
x1 −e
ik2
x1 −e
−ik2
x1
ik1e
ik1
x1 −ik1e
−ik1
x1 −ik2e
ik2
x1 ik2e
−ik2
x1
e
ik2
x2 e
−ik2
x2 −e
ik3
x2 −e
−ik3
x2
ik2e
ik2
x2 −ik2e
−ik2
x2 −ik3e
ik3
x2 ik3e
−ik3
x2
.
.
.
e
ikN−1
xN−1 e
−ikN−1
xN−1 −e
ikNxN−1
ikN−1e
ikN−1
xN−1 −ikN−1e
−ikN−1
xN−1 −ikNe
ikNxN−1











×











a1
b1
a2
b2
a3
b3
.
.
.
bN−1
aN











=











1
0
0
0
0
0
.
.
.
0
0











. (7.2.15)
This equation is similar to the one obtained for the bound states (Eq. (6.3.8)), except
for the constraint, a1 = 1, which introduces a source term, thus converting the equation
into an inhomogeneous one. The fact that the scattering wave function coefficients are
defined by an inhomogeneous equation has a remarkable consequence: a nontrivial solu￾tion exists at any energy. This is different than in the case of bound states, where the
homogeneous equation has a nontrivial solution only for specific energies. It follows
that the energy spectrum of the open system (E > min(V1,VN)) is continuous.
First, let us consider the scattering energies, which are larger than both of the asymp￾totic potential energy thresholds, namely, E >V1,VN. The information of prime interest
is the probability of scattering from the target into the different possible directions in
space. In the one-dimensional case, the asymptotic incoming flux can be either trans￾mitted forward, or reflected backward. For the piecewise constant potential energy, an
incoming particles flux from, for example, the left asymptote (segment ‘1’), J
(1)
E+
, can be
either transmitted to the Nth segment or reflected to the 1st segment. The correspond￾ing transmitted and reflected fluxes, J
(N)
E+
and J
(1)
E−
, are associated with the plane waves,
aNe
ikNx
, and b1e
−ik1x
, respectively. Using Eq. (7.2.3), one obtains
J
(N)
E+
= |aN|
2
hk¯ N
m
. (7.2.16)
J
(1)
E−
= −|b1|
2
hk¯ 1
m
. (7.2.17)
The ratios between these scattered fluxes and the incoming flux (in absolute values)
defines the transmission and reflection probabilities, T(E) and R(E),
T(E) =
|J
(N)
E+
|
|J
(1)
E+
|
=
|aN|
2
kN
|a1|
2k1
; R(E) =
|J
(1)
E−
|
|J
(1)
E+
|
=
|b1|
2
|a1|
2
. (7.2.18)
Recalling that for stationary solutions the flux must be constant anywhere in space
(Eq. (7.2.4)), namely, J
(N)
E+
= J
(1)
E+
+J
(1)
E−
, it follows that the transmission and reflection
https://doi.org/10.1017/9781108877787.008 Published online by Cambridge University Press67 7.3 Degeneracy of Scattering States
probabilities must sum to unity (this result is a manifestation of the unitarity of the
scattering matrix [7.1]):
R(E) +T(E) = 1. (7.2.19)
The reflection probability is expressed in terms of the ratio of wave function coefficients,
R(E) ≡ |r1|
2 ≡ | b1
a1
|
2
. For the piecewise constant potential (Eq. (6.3.1)) this ratio can be
calculated for any energy by reformulating Eq. (7.2.15) as a recursion relation,
rn = e
2iknxn
(kn+1 −kn)e
ikn+1xn −(kn+1 +kn)e
−ikn+1xn rn+1
−(kn+1 +kn)e
ikn+1xn +(kn+1 −kn)e
−ikn+1xn rn+1
. (7.2.20)
Starting from the Nth segment, where rN = 0, and progressing backward, one can
obtain an explicit expression for rN−1,rN−2,...,r2,r1, in terms of the potential energy
parameters (V1,V2,...,VN and (x1, x2,..., xN−1)) and the particle mass. Consequently,
R(E) = |r1|
2 and T(E) = 1−R(E) are obtained.
7.3 Degeneracy of Scattering States
Notice that for any energy in this range (E >V1,VN) there are two degenerate scattering
wave functions. The first corresponds to an incoming flux from the left, as has been
discussed in Eqs. (7.2.12–7.2.20), with the asymptotic wave functions,
ψL→R(x) =



e
ik1x +b1e
−ik1x
; x ≤ x1
.
.
.
aNe
ikNx
; x ≥ xN−1
(7.3.1)
The second corresponds to an incoming flux from the right, associated with different
asymptotic wave functions:
ψR→L(x) =



a¯1e
−ik1x
; x ≤ x1
.
.
.
e
−ikNx +b¯
Ne
ikNx
; x ≥ xN−1
(7.3.2)
Interestingly, regardless of any symmetry requirement on the potential energy, the
transmission and reflection probabilities associated with the two scattering directions
are identical, namely,
R(E)L→R = |b1|
2 = |b¯
N|
2 = R(E)R→L
T(E)L→R = |aN|
2
kN
k1
= |a¯1|
2
k1
kN
= T(E)R→L. (7.3.3)
This result means that the probability of an incoming flux from the left, associated
with an initial momentum, +hk¯ 1, to be scattered through space into a final momentum
+hk¯ N, equals the probability of an incoming flux from the right with an initial momen￾tum, −hk¯ N, to be scattered into an asymptotic state with a final momentum, −hk¯ 1. It
https://doi.org/10.1017/9781108877787.008 Published online by Cambridge University Press68 The Continuous Spectrum and Scattering States
follows directly from the time-reversal symmetry of the corresponding time-dependent
Schrödinger equation, which means that both ψ(x,t) and ψ
∗
(x,−t) are solutions to
the time-dependent Schrödinger equation, as can be readily verified. For stationary
solutions, this means that ψE(x) and ψ
∗
E
(x) are degenerate. To prove Eq.(7.3.3), we can
show that ψR→L(x) is in fact a superposition of the two degenerate solutions, ψL→R(x)
and its complex conjugate, such that scattering probabilities associated with ψR→L(x)
are expressed in terms of the parameters of ψL→R(x) (Ex. 7.3.1).
Exercise 7.3.1 Given the scattering states ψL→R
(x) and ψR→L(x) in Eqs. (7.3.1, 7.3.2),
show that ψR→L(x) can be expressed as a linear combination of ψL→R(x) and ψ
∗
L→R
(x),
and prove the result in Eq. (7.3.3).
We now consider scattering energies that are larger than one of the asymptotic
potentials but smaller than the other one, for example, without loss of generality,
V1 < E < VN. In this case, the asymptotic scattering wave functions obtain the form
ψL→R(x) =



a1e
ik1x +b1e
−ik1x
; x ≤ x1
.
.
.
0 ; x → ∞
(7.3.4)
Flux conservation (Eq. (7.2.4)) leads in this case to |a1|
2 − |b1|
2 = 0. This means
that in this energy range, an incoming particles flux from the left asymptote (seg￾ment ‘1’) must be reflected with a unit probability, namely, R(E) = |b1|
2/|a1|
2 = 1 (see
also Ex. 7.3.2). Time reversal symmetry means that the complex conjugate of ψL→R(x)
is also a solution associated with the same energy. However, since |a1|
2 = |b1|
2
, one
can readily verify that, a1
b
∗
1
ψ
∗
L→R
(x) = ψL→R
(x), namely ψ
∗
L→R
(x) and ψL→R
(x) are lin￾early dependent. It follows that in this energy range the solutions are nondegenerate.
Indeed, scattering from a right flux source is excluded since the wave function vanishes
asymptotically in the classically forbidden region.
Exercise 7.3.2 Given a single potential energy step, V(x)=(
x ≤ 0 ;V1
x > 0 ;V2
, where V2 >V1,
use Eq. (7.2.20) to show that the reflection probability equals unity in the scattering
energy range, V1 < E < V2.
7.4 Scattering from a Single Potential Barrier or Well
We now consider explicitly the case of scattering from a symmetric potential energy
barrier (or well) of a finite length, where the potential energy reads
V(x) =



V0 ; x < 0
V1 ; 0 ≤ x < L.
V0 ; L ≤ x
(7.4.1)
https://doi.org/10.1017/9781108877787.008 Published online by Cambridge University Press69 7.4 Scattering from a Single Potential Barrier or Well
0
−5 0
(a)
5
x (A)
V (eV)
10
5
10
15
20
25
30
0
−5 0
(b)
5
x (A)
V (eV)
10
5
10
15
20
25
30
tFigure 7.4.1 Potential energy and scattering wave functions for a potential energy barrier (a), and well (b). The wave functions are
represented by their real part, where the different plots correspond to different scattering energies. The plots are
displaced from each other by the respective energy differences. The particle’s mass was set to an electron mass, and
the barrier (well) width was set to L = 0.3 nm. The barrier (well) energy was shifted by +10 (−10) eV with
respect to the asymptotic potential energy.
The scattering wave functions are the stationary solutions of the time-dependent
Schrödinger equation, for E > V0. Considering an incoming flux source from the left,
the scattering states obtain the form
ψ(x) =



a1e
ik1x +b1e
−ik1x
; x < 0
a2e
ik2x +b2e
−ik2x
; 0 ≤ x < L
a3e
ik1x
; L ≤ x
, (7.4.2)
where k1 = k3 ≡
q2m(E−V0)
h¯
2 and k2 ≡
q2m(E−V1)
h¯
2
. Some of the scattering wave functions,
corresponding to selected energy values (out of the continuous energy spectrum), are
plotted in Fig. 7.4.1. Implementing the recursion relation (Eq. (7.2.20)) for this case,
one has r3 = 0, r2 = e
2ik2L k2−k1
k2+k1
, and, r1 =
k
2
1−k
2
2
k
2
2+k
2
1+2ik1k2 cot(k2L)
, which yields the following
explicit expressions for the reflection and the transmission probabilities,
R(E) = (k
2
1 −k
2
2
)
2
(k
2
2 +k
2
1
)
2 +4k
2
1
k
2
2
cot2
(k2L)
; T(E) = 1−R(E). (7.4.3)
Exercise 7.4.1 Derive the result Eq. (7.4.3) for the transmission and reflection proba￾bilities for particles scattering from a square potential energy barrier (or well).
The probability for transmission through a potential barrier (V1 > V0) in plotted in
Fig. 7.4.2. For energies smaller than the potential barrier height, E < V1, a classical
particle would not be able to penetrate a forbidden region in space to pass through
the barrier. It follows that according to classical mechanics the transmission probabil￾ity should be strictly zero. In quantum mechanics, however, as apparent in Fig. 7.4.2,
https://doi.org/10.1017/9781108877787.008 Published online by Cambridge University Press70 The Continuous Spectrum and Scattering States
0
10 20 30 40 50 60 70
E (eV)
Transmission Probability
80
0.2
0.4
0.6
0.8
1
−6
10 20 30 40 50 60 70
E (eV)
log10(T(E))
80
−5
−4
−3
−2
−1
0
tFigure 7.4.2 Transmission probability, T(E), and its logarithm, log10(T(E)), as a function of the energy for scattering from a
potential energy barrier (V1 = 20 eV; see Fig.7.4.1for all the parameters).
there is a finite transmission probability even in this low-energy regime. This phenom￾enon is attributed to the penetration of the scattering wave function into the classical
forbidden region (recall that k2 is purely imaginary in the range E < V1). See also
Fig. 7.4.1a), which allows for quantum tunneling through the potential energy barrier.
Indeed, we encountered already the possibility for quantum tunneling when discussing
bound particles in quantum wells (see Chapter 6). For energies above the potential
barrier height, E > V1, the transmission probability should be unity according to clas￾sical mechanics, since a classical particle would have sufficient kinetic energy to cross
the barrier region. Nevertheless, the corresponding quantum mechanical transmission
probability is generally less than unity (see Fig. 7.4.2). This phenomenon is familiar
from wave scattering at boundaries between different media. Equation (7.4.2) shows
that the reflection strictly vanishes (and therefore the transmission probability is unity)
only when cot2
(k2L) → ∞, namely, when,sin(k2L) = 0. This strictly happens only at spe￾cific energies, for which the barrier length equals an integer multiple of half de Broglie’s
wavelengths, λ =
2πh¯
p
,
L =
πn
k2
=
h¯πn p
2m(E −V1)
=
nλ
2
. (7.4.4)
Changing the potential energy such that V1 < V0, the barrier turns into a
potential energy well (see Fig. 7.4.1b). The transmission probability for scattering
above the potential well is plotted in Fig. 7.4.3. Again, the classical transmission
probability for E > V0 > V1 is unity, but the corresponding quantum mechani￾cal transmission probability is generally smaller. As for the case of a potential
energy barrier, the reflection strictly vanishes (and therefore the transmission prob￾ability is unity) only when sin(k2L) = 0 namely, when the length of the poten￾tial energy well equals an integer multiplication of half de Broglie’s wavelengths
(Eq. (7.4.4)).
https://doi.org/10.1017/9781108877787.008 Published online by Cambridge University Press71 7.5 The Resonant Tunneling Phenomenon
0
10 20 30 40 50 60 70
E (eV)
Transmission Probability
80
0.2
0.4
0.6
0.8
1
tFigure 7.4.3 Transmission probability, T(E), as a function of the energy for scattering above a potential energy well (V0 = 10
eV,V1 = 0; see Fig.7.4.1for the other parameter values).
7.5 The Resonant Tunneling Phenomenon
We now return to scattering through potential barriers (V1 > V0) in the quantum tun￾neling regime (E < V1). As we have seen, the transmission probability for scattering
through a single barrier increases monotonically with the scattering energy in this
regime. Here we ask: what would be the effect of a consecutive barrier, located after the
first one, along the propagation direction? In classical mechanics, as long as the second
barrier height is smaller than or equal to the first one, there should be no effect at all.
In quantum mechanics, the result turns out to be very different. Consider, for example,
the symmetric double barrier potential presented in Eq. (7.5.1) and Fig. 7.5.1,
V(x) =



V0 ; x < x1
V1 ; x1 ≤ x < x1 +L
V0 ; x1 +L ≤ x < x1 +L+d
V1 ; x1 +L+d ≤ x < x1 +2L+d
V0 ; x1 +2L+d ≤ x
. (7.5.1)
The transmission probability, calculated by implementing the general formulation pre￾sented in Eq. (7.2.20), is plotted in Fig. 7.5.2. A remarkable feature is revealed: for some
energy values within the tunneling range, E < V1, the presence of an additional con￾secutive barrier increases the transmission probability through the target. The effect
is known as the resonant tunneling phenomenon. It is known in scattering of electro￾magnetic waves through resonators, and in optics it is named after Fabry and Pérot,
the developers of the optical resonator [7.2]. In essence, the two barriers define an
effective finite potential energy well between them. If the barriers’ widths extended to
infinity (L → ∞), this potential well would support a finite number of bound states (see
https://doi.org/10.1017/9781108877787.008 Published online by Cambridge University Press72 The Continuous Spectrum and Scattering States
8
−10 −5 0 5
x (A)
V (eV)
10 15
10
12
14
16
18
20
tFigure 7.5.1 Potential energy and scattering wave functions for a symmetric double barrier potential. The wave functions are
represented by their real part, where the different plots correspond to different scattering energies. The plots are
displaced from each other by the respective energy differences. The particle’s mass was set to an electron mass, and
the double barrier parameters are L = d = 0.3 nm,V0 = 10 eV, andV1 = 20 eV.
0
10 15 20
E (eV)
Transmission Probability
25
0.2
0.4
0.6
0.8
1
tFigure 7.5.2 Transmission probability, T(E), as a function of the energy for scattering from the symmetric double barrier
potential presented in Fig. 7.5.1.The result for a single barrier is plotted for comparison (dashed line).
Section 6.2). For a finite L, however, owing to wave function penetration, there are
no bound states. Instead, for sufficiently large L, each bound state would correspond
to a “quasi-bound state” (or “resonance state”). This means that if the bound state
is selected as an initial condition for the time-dependent Schrödinger equation, the
probability for populating the intermediate potential well would decay exponentially
in time. (See Chapter 19 for a general analysis of exponential decays.) The decay rate
is denoted Γ/h¯, where Γ is termed the “resonance energy width” (formally associated
with twice the imaginary part of a complex “resonance energy”). In a scattering exper￾iment, when the energy of the incoming stationary flux matches the quasi-bound state
https://doi.org/10.1017/9781108877787.008 Published online by Cambridge University Press73 Bibliography
energy (within the energy-width Γ), the tunneling probability is significantly enhanced.
Remarkably, for a symmetric double barrier, the transmission can reach unity; namely,
the consecutive barrier turns the double barrier structure into a transparent one for
selected energies (see Ex. 7.5.1). Resonant tunneling phenomena play a crucial role
in transport through nanoscale conductors (see [5.6] and Chapter 20). The interested
reader is directed to complementary literature focusing on quantum scattering theory
in general [7.1] and resonance states in particular [7.3].
Exercise 7.5.1 Given a symmetric double barrier potential,
V(x) =



V0 ; x < −(L+d/2)
V1 ; −(L+d/2) ≤ x < −d/2
V0 ; −d/2 ≤ x < d/2
V1 ; d/2 ≤ x < d/2+L
V0 ; d/2+L ≤ x
,
obtain an equation for the scattering energies in which the transmission probability is
100%.
Bibliography
[7.1] J. R. Taylor, “Scattering Theory: The Quantum Theory of Nonrelativistic
Collisions” (Dover, 2006).
[7.2] G Hernández, “Fabry-Perot Interferometers” (Cambridge University Press,
1988).
[7.3] N. Moiseyev, “Non-Hermitian Quantum Mechanics” (Cambridge University
Press, 2011).
https://doi.org/10.1017/9781108877787.008 Published online by Cambridge University Press8
Mechanical Vibrations and the Harmonic
Oscillator Model
8.1 Molecular Vibrations
Let us consider a group of atoms composing a molecule in one of its stable geometrical
arrangements. In classical mechanics, given some finite kinetic energy, the atoms will
perform small amplitude motions, namely vibrations, around the geometry of minimal
energy. In what follows, we address the questions: What is the corresponding quan￾tum mechanical description of vibrational motion? What are the energy levels and wave
functions that account for internal molecular vibrations?
A glimpse into the nature of molecular vibrations is obtained through their
interaction with electromagnetic radiation. The relative motion of partially charged
atoms against each other is associated with dipole oscillations, which can exchange
energy with the electromagnetic field. In Fig. 8.1.1 absorption spectra of electro￾magnetic radiation are plotted for two organic molecules as a function of the
radiation wave number, 1
λ =
ν
c
, in the infrared regime. The spectrum is shown
to be sensitive to the specific molecule, which is useful as a “molecular fin￾gerprint” for identification of the molecular structure and composition. Indeed,
each molecule is characterized by a unique combination of dipole oscillations
with characteristic frequencies, which reflect the interatomic forces and the atomic
masses.
While a classical mechanical description may qualitatively explain the differences
between different molecules, a quantitative analysis of the absorption spectrum
necessitates a quantum mechanical description. As we shall see, the absorption
peak positions correspond to the quantized vibrational energy levels in the mole￾cule (which turn out to be related to the frequencies of the classical vibrations).
Moreover, the intensity of each peak is subject to quantum mechanical “selection
rules” that are derived from the corresponding wave functions, namely the station￾ary solutions to the Schrödinger equation, and the widths of the peaks are associated
with the interaction between each molecular vibration and other degrees of free￾dom within the molecule as well as with its surroundings. In this chapter we shall
focus on the relevant vibrational energy levels and the corresponding stationary
74
https://doi.org/10.1017/9781108877787.009 Published online by Cambridge University Press75 8.2 The Normal Modes of a Many-Particle System and the Harmonic Approximation
4000
0
1
3000
H
H
H
H
O
C C
Absorption
(a)
2000
[cm−1]
1500 1000 500
1
λ
4000
0
1
3000
H
H
H
H
H
O
C C
H
H
C H
Absorption
(b)
2000
[cm−1]
1500 1000 500
1
λ
C
tFigure 8.1.1 Infrared absorption spectra of two molecules: (a)C2H4O, and (b)C3H8O. The absorption is defined here as,
1−I/I0, whereI0 andI are the incoming and transmitted radiation fluxes.
wave functions. A more detailed discussion of spectral line shapes will be given in
Chapter 18.
8.2 The Normal Modes of a Many-Particle System and the Harmonic
Approximation
In the previous chapters, our solutions of the Schrödinger equation referred to sys￾tems in which a single particle (or a flux of noninteracting particles) was subject
to an “external” potential energy. In this chapter we address systems in which a
given number of particles are bounded to each other by interparticle interactions,
associated with a many-particle potential energy function of a general form. Par￾ticularly, we shall address the geometrical arrangement of the particles relative to
each other in a stable state of the system, namely near a minimum of the potential
energy function. As explained below, this scenario has a universal form, which can
https://doi.org/10.1017/9781108877787.009 Published online by Cambridge University Press76 Mechanical Vibrations and the Harmonic Oscillator Model
be approximately mapped onto a set of harmonic oscillators. Indeed, vibrations of
atoms in molecules, nanoparticles, and solid lattices are often referred to in terms of
the harmonic approximation. The energy levels and the stationary probability density
distributions of the relative atomic locations in these systems are therefore inferred
from the solution of the time-independent Schrödinger equation for the harmonic
oscillator model, as detailed in the following sections. Notice that historically, the
notion that the radiation emerging from oscillating dipoles must be quantized in energy
preceded the formulation of quantum mechanics. It was the basis for Max Planck’s suc￾cessful explanation of the “black body” radiation in the year 1900, which was a major
driving force for pursuing the origin of energy quantization.
Let us consider a system of N particles with masses, m1,m2,...,mN (e.g., atoms in
a polyatomic molecule) in a Cartesian coordinate system. The energy of the system
depends on the vector of 3N Cartesian positions of all the particles, denoted here as x,
and the corresponding momenta. We are interested in the potential energy as a function
of the coordinates at the vicinity of a minimum, x
(eq)
, which corresponds to a stable
(“equilibrium”) geometry of the particles. At a minimum point, ∂V(x)
∂ x j



x=x
(eq)
= 0, for
j = 1,2,...,3N. For small deviations around the minimum, the Taylor expansion of
the potential function can be truncated in the second order. Setting the zero of the
potential energy to, V(x
(eq)
) = 0, one therefore obtains
V(x) ≈
3N
∑
j, j
0=1
1
2
∂
2V(x)
∂ xj∂ xj
0




x=x
(eq)
(x j −x
(eq)
j
)(xj
0 −x
(eq)
j
0 ). (8.2.1)
Defining the Hessian matrix, Hj, j
0 =
∂
2V(x)
∂ x j∂ x
j
0



x=x
(eq)
, the mass matrix, Mj, j
0 = mjδ j, j
0
(where mj
is the mass of the particle associated with the coordinate xj), and the dis￾placement vector, d = x−x
(eq)
, the classical system Hamiltonian can be expressed as
follows:
H =
1
2
d
tHd+
1
2
d˙
tMd˙ . (8.2.2)
This bilinear form can be simplified by diagonalizing the (symmetric) mass-weighted
Hessian matrix, M−1/2HM−1/2
, namely, using h
M−1/2HM−1/2
i
U = UK, where K is
a diagonal matrix. Using the eigenvectors matrix U to define a new set of coordinates
(linear combinations of the particles Cartesian coordinates),
q ≡ U
tM1/2d, (8.2.3)
the Hamiltonian obtains the form
H =
1
2
q
tKq+
1
2
q˙
tq˙ =
3N
∑
j=1
1
2
(Kj, jq
2
j +q˙
2
j
) ≡
3N
∑
j=1
Hj
. (8.2.4)
The Hamiltonian is therefore expressed as sum of independent terms, each corre￾sponding to a single “global” coordinate, qj ≡
3N
∑
j
0=1
U j
0
, jM1/2
j
0
, j
0(xj
0 −x
(eq)
j
0 ). These global
coordinates are termed the “normal modes” of the system. Notice that generally only
3N −6 degrees of freedom (out of the 3N) correspond to interparticle vibrations. Three
https://doi.org/10.1017/9781108877787.009 Published online by Cambridge University Press77 8.2 The Normal Modes of a Many-Particle System and the Harmonic Approximation
out of the remaining six coordinates correspond to the position of the center of mass
of the system, and the other three correspond to the global orientation of the particles
in space as a rigid body. Indeed, when the potential energy function depends only on
the interparticle distances (namely, in the absence of external forces), there are only
3N −6 nonzero Kj values, associated with interparticle vibrations. (For a linear equi￾librium arrangement x
(eq) of the particles, the global orientation is defined by only
two variables instead of three, and the number of interparticle vibrations increases to
3N −5.)
Since the Hamiltonian, Eq. (8.2.4), is separable in the different modes (H = ∑
3N
j=1 Hj),
the analysis of the many-particle system near its stable geometry can be performed
independently for each mode (see Ex. 4.3.4). Moreover, this result is universal for any
collection of particles of different types and numbers. For example, when the particles
under consideration are atoms, the normal mode analysis applies to small molecules
(see Section 8.1), nanoparticles, quantum dots containing thousands of atoms, and
also to solid lattices, extended to include macroscopic numbers of atoms. (In the latter
case, the excitations of the normal modes is referred to as the lattice phonons.)
Each single mode is characterized by Hj
in Eq. (8.2.4). This Hamiltonian corre￾sponds to a kinetic energy of a particle of (unit) mass and a potential energy term,
which is quadratic in the respective coordinate. Before turning to the quantum mechan￾ical treatment of this Hamiltonian, let us recall the classical mechanics description of
the corresponding motion. For generality, we shall consider a particle of mass m. The
particle’s coordinate and conjugate momentum will be denoted as q and p, respectively.
The classical Hamiltonian reads
H =
1
2
p
2
m
+
1
2
Kq
2
, (8.2.5)
where the force experienced by the particle satisfies Hooke’s law,
f = −
∂H
∂q
= −Kq. (8.2.6)
Newton’s equation of motion for this model reads mq¨ = −Kq, and its general solution
for the coordinate reads
q(t) = a cos(ωt) +b sin(ωt) ; ω ≡
r
K
m
, (8.2.7)
where a and b are scalars, set by the initial conditions. It follows that the particle per￾forms a simple harmonic motion in time. The Hamiltonian in Eq. (8.2.5) is therefore
referred to as the harmonic oscillator model, where the oscillation frequency, ω, is set
by the force constant, K, and the mass m. Notice that the harmonic oscillator model
appears naturally in the normal mode analysis of atomic vibrations as we have out￾lined, but its applications extend to many areas of physics, including nuclear structure
theory, quantum electrodynamics and quantum optics, mechanical engineering, and
so forth.
https://doi.org/10.1017/9781108877787.009 Published online by Cambridge University Press78 Mechanical Vibrations and the Harmonic Oscillator Model
8.3 The Solutions of the Schrödinger Equation for the Harmonic
Oscillator
We now turn to a quantum mechanical description of a harmonic oscillator, asso￾ciated with a mass m, a force constant, K = mω
2
, a Cartesian position coordinate, q,
−∞ < q < ∞, and a corresponding classical momentum, p = mq˙. The quantum mechan￾ical Hamiltonian operator is obtained by using the quantization rule for the canonical
position and momentum operators, Eqs. (3.2.1, 3.2.2), namely, Hˆ =
−h¯
2
2m
∂
2
∂q
2 +
1
2mω
2q
2
.
The time-independent Schrödinger equation (Eq. (4.3.4)) therefore reads
−h¯
2
2m
∂
2
∂q
2
ψ(q) + 1
2
mω
2
q
2ψ(q) = Eψ(q), (8.3.1)
where we seek for its normalized solutions, for which
w∞
−∞
|ψ(q)|
2
dq = 1. (8.3.2)
It is convenient to introduce at this point dimensionless variables, y =
qmω
h¯
q and λ =
E/(h¯ω), for the oscillator’s position and energy, respectively. Defining ψ(q) = φ(y), the
Schrödinger equation Eq. (8.3.1) for φ(y) obtains the form
1
2
[y
2 −
∂
2
∂ y
2
]φ(y) = λ φ(y). (8.3.3)
Eq. (8.3.3) is an ordinary second-order differential equation, regular in the entire
space. It therefore has power series solutions for any y, namely, φ(y) =
∞
∑
k=0
aky
k
. Since
the potential energy diverges asymptotically (at y → ±∞), all the stationary solutions
correspond to bound states, and therefore must be proper; namely, they must vanish
asymptotically, φ(y) −−→y → ±∞
0 (see Eq. (2.2.1)). Focusing on the asymptotic regime, Eq.
(8.3.3) means that for any finite λ (finite energy), λ becomes negligible next to y
2
, and
therefore, ∂
2
∂ y
2 φ(y) −−→y → ±∞
y
2φ(y). One can readily verify that a power series that satis￾fies this equation must take the form φn(y) = e
±y
2/2Pn(y), where Pn(y) =
n
∑
k=0
aky
k
is a
polynomial of a finite degree, n (see Ex. 8.3.1). Excluding the asymptotically diverging
solutions associated with, e
+y
2/2
, the proper solutions obtain the form
φn(y) = e
−y
2/2Pn(y). (8.3.4)
The lowest-degree polynomial corresponds to n = 0. The solution to Eq. (8.3.3), subject
to normalization (Eq. (8.3.2)), and the respective eigenvalue, read in this case
φ0(y) = mω
h¯π
1/4
e
−y
2/2
; λ0 =
1
2
. (8.3.5)
Exercise 8.3.1 Show that the function χ(y) = e
±y
2/2
y
n
satisfies the asymptotic equation
for the harmonic oscillator; namely, ∂
2
∂ y
2 φ(y) −−→y → ±∞
y
2φ(y), for any finite n.
https://doi.org/10.1017/9781108877787.009 Published online by Cambridge University Press79 8.3 The Solutions of the Schrödinger Equation for the Harmonic Oscillator
H0(y) = 1
H1(y) = 2y
H2(y) = 4y
2 −2
H3(y) = 8y
3 −12y
H4(y) = 16y
4 −48y
2 +12
H5(y) = 32y
5 −160y
3 +120y
H6(y) = 64y
6 −480y
4 +720y
2 −120
.
.
.
tFigure 8.3.1 A list of the first seven Hermit polynomials
Exercise 8.3.2 Verify that φ0(y) and λ0, as defined in Eq. (8.3.5), are indeed an
eigenfunction and its corresponding eigenvalue of Eq. (8.3.3).
To obtain the polynomials of higher degrees we can make use of the observation
that if φn(y) is an eigenfunction of Eq. (8.3.3), associated with the eigenvalue, λn,
then h
y−
∂
∂ y
i
φn(y) is also an eigenfunction of the same equation, associated with
the eigenvalue, λn + 1 (see Ex. 8.3.3). Using λ0 =
1
2
and φ0(y) ∝ e
−y
2/2
, it follows
that the eigenfunctions obtain the form φn(y) = h
y−
∂
∂ y
in
e
−y
2/2
, which is indeed
of the form of Eq. (8.3.4), hy−
∂
∂ y
in
e
−y
2/2 ≡ e
−y
2/2Pn(y)

, where the polynomial
degree is n = 0,1,2,..., and the corresponding eigenvalues are λn = n +
1
2
. Further￾more, if φn(y) = e
−y
2/2Pn(y) is normalized, so is φn+1(y) = √
1
2(n+1)
h
y−
∂
∂ y
i
φn(y)
(see Ex. 8.3.4). Using Eq. (8.3.5), it follows that the normalized eigenfunctions are
φn(y) = ￾
mω
h¯π
1/4
q
1
2
nn!
[y−
∂
∂ y
]
n
e
−y
2/2
. Introducing the definition of the known Hermit
polynomials [8.1], Hn(y) ≡ e
y
2/2
(y−
∂
∂ y
)
n
e
−y
2/2
, we therefore obtain
φn(y) = mω
h¯π
1/4
r
1
2
nn!
e
−y
2/2Hn(y). (8.3.6)
A few of the lower-order Hermit polynomials are presented in Fig. 8.3.1.
Exercise 8.3.3 Show that if φn(y) is a solution to the eigenvalue equation for a harmonic
oscillator, that is, 1
2
[y
2 −
∂
2
∂ y
2
]φn(y) = λnφn(y), then:
(a) [y−
∂
∂ y
]φn(y) is also an eigenstate solution, with the respective eigenvalue, (λn +1),
and
(b) [y+
∂
∂ y
]φn(y) is also an eigenstate solution, with the respective eigenvalue, (λn −1).
You can use the commutators, [(y
2 −
∂
2
∂ y
2
),(y∓
∂
∂ y
)] = ±2(y∓
∂
∂ y
).
Exercise 8.3.4 Let φn(y) be a normalized solution to the Schrödinger equation for the
harmonic oscillator: 1
2
[y
2 −
∂
2
∂ y
2
]φn(y) = (n+
1
2
)φn(y). Show that:
https://doi.org/10.1017/9781108877787.009 Published online by Cambridge University Pres80 Mechanical Vibrations and the Harmonic Oscillator Model
0
−0.05 0 0.05
q [nm]
V (eV)
0.5
1
1.5
2
2.5
3
3.5
4
4.5
tFigure 8.3.2 Energy levels and probability densities (|ψn(q)|
2
) for the harmonic oscillator model. The different plots correspond
to different energy levels. The plots are displaced from each other by the respective energy differences. The model
parameters are m = 1789 a.u., and h¯ω = 0.358 eV, corresponding to the harmonic approximation for the
vibration in the H
35Cl molecule.
(a) φn+1(y) = √
1
2(n+1)
h
y−
∂
∂ y
i
φn(y) is also normalized.
(b) φn−1(y) = √
1
2n
h
y+
∂
∂ y
i
φn(y) is also normalized.
Returning to the original variables, En = h¯ωλn and q =
q
h¯
mω
y, the energy levels and
stationary wave functions of the harmonic oscillator read
En = h¯ ω

n+
1
2

; n = 0,1,2,... (8.3.7)
ψn(q) = mω
h¯π
1/4
r
1
n!2n
Hn
r
mω
h¯
q

e
−mω
2h¯
q
2
. (8.3.8)
Probability densities corresponding to the lowest-energy solutions are plotted in
Fig. 8.3.2. The stationary solutions of the harmonic oscillator reveal several impor￾tant characteristics. Some of these are generic to solutions of the one-dimensional
Schrödinger equation, as discussed in the previous chapters (Chapters 5–7), and others
are unique for the harmonic oscillator model:
I. Energy quantization: the energy spectrum is discrete (which is general for a bound
system), with a uniform spacing between nearest levels (this uniformity is spe￾cific to this model), En+1 −En = h¯ ω = h¯
p
K/m. The level spacing decreases with
increasing mass (the classical limit).
https://doi.org/10.1017/9781108877787.009 Published online by Cambridge University Press81 8.3 The Solutions of the Schrödinger Equation for the Harmonic Oscillator
II. The number of oscillations in the stationary wave functions, namely, the number
of zero values (“nodes”) in the respective probability density functions, increases
with increasing energy.
III. The probability densities are shown to penetrate the classically forbidden regions,
for which q 2En
mω2 < |q| (namely, En <
1
2mω
2q
2
).
IV. For small n values, the probability density is distributed nonuniformly in space
and the wavelike nature of the stationary solutions is pronounced.
V. For large n values, the probability density tends to peak near the classical turning
points, qn, in which the total energy equals the potential energy, En =
1
2mω
2q
2
n
.
This observation is in accord with the motion of a classical oscillator, which
spends longer times at the classical turning points, where the kinetic energy
vanishes.
VI. The quantum size effect: Comparing between oscillators with different force con￾stants, the level spacing near a given energy, En, decreases when the distance
between the classical turning points increases (namely, when the oscillator wave
function is less localized); see Ex. 8.3.5.
VII. The “zero-point energy”: as in other examples of bound systems that we encoun￾tered before, the energy of the oscillator at its lowest energy state does not vanish,
and equals
E0 =
1
2
h¯ ω =
1
2
h¯
r
K
m
. (8.3.9)
This phenomenon is related to the uncertainty principle (to be discussed in Chap￾ter 11), which prohibits simultaneous determination of a strictly zero momentum
(zero kinetic energy) and a strict position at the minimum of the potential energy
function. Let us emphasize that the zero-point energy associated with a chemical
bond within a molecule has a remarkable effect on the bond mechanical stability:
the lower is the zero point energy, the more energy is needed to dissociate the bond
(see the next section). Since the zero-point energy decreases with increasing oscil￾lator mass (see Eq. (8.3.9)), replacing an atom with its heavier isotope increases
the bond stability and therefore slows down chemical reactions involving the rel￾evant bond. (Notice that the bond force-constant does not change upon isotope
substitution, since the electric charges are unchanged.) The effect is especially
pronounced for bonds involving light atoms, such as hydrogen. Indeed, replac￾ing hydrogen by deuterium can lead to a remarkable reduction in reaction rates
and serves as a standard tool in chemical kinetics investigations.
Exercise 8.3.5 Let us denote the classical amplitude of motion for a harmonic oscillator
at energy En as ∆n. Show that the level spacing near En, namely, En+1 − En, is inversely
proportional to ∆n, namely, a larger amplitude of motion corresponds to a more dense
energy spectrum (the quantum size effect).
https://doi.org/10.1017/9781108877787.009 Published online by Cambridge University Press82 Mechanical Vibrations and the Harmonic Oscillator Model
0
−0.05 0 0.05 0.1
q [nm]
V [eV]
0.15 0.2 0.25
1
2
3
4
tFigure 8.4.1 Solid: potential energy function for a diatomic molecule at its electronic ground state, as a function of the deviation
from the classical equilibrium geometry. Dashed: the harmonic approximation for the potential energy function. The
plots correspond to the H
35Cl molecule with a dissociation energy,V(∞)−V(R0) = 4.47 eV [8.2]. The
harmonic frequency is 8.66 · 1013 Hz, and the equilibrium distance is, R0 = 0.127 nm.
8.4 The Infrared Absorption Spectrum of Diatomic Molecules
In Section 8.2 we discussed the normal modes of a polyatomic system. Here we focus on
an isolated diatomic molecule (e.g., in the gas phase), in which two atoms with masses
m1 and m2 are connected via a chemical bond. The positions of the two atom centers
in space are defined by six degrees of freedom, for example, the Cartesian coordinates
of each atom (denoted by the vectors R1 and R2). It is useful to transform into linear
combinations of these coordinates, separating the motion of the molecular center of
mass, associated with the coordinates, Rcm =
m1
m1+m2
R1 +
m2
m1+m2
R2, and the total mass,
M = m1 +m2, from the relative motion of the atoms, associated with the coordinates,
R = R1 −R2 ≡ (R,θ,φ), and a reduced mass, m =
m1m2
m1+m2
(see Chapter 9 for a detailed
discussion). Since the interaction between the atoms is due to the electrically charged
electrons and atomic nuclei (see Chapter 14 for a detailed account for the nature of the
chemical bond), the potential energy depends only on the absolute relative distance
between the atom centers, namely, V(R) = V(R) where the rotation of the vector R
induces an additional centrifugal force that depends on the distance, R. However, for
discussing the vibrations, this force can be neglected to a good approximation for typi￾cal molecules and rotational energies (see Chapter 9), such that the vibrational motion
can be approximated as being one-dimensional, in the coordinate R.
A typical potential energy function, V(R), is plotted in Fig. 8.4.1. For a large intera￾tomic distance, the potential energy obtains an asymptotic constant value, implying
that the interatomic forces (potential energy derivatives) vanish at large distances.
https://doi.org/10.1017/9781108877787.009 Published online by Cambridge University Press83 8.4 The Infrared Absorption Spectrum of Diatomic Molecules
Indeed, for sufficiently high vibrational energy, the chemical bond can dissociate, and
the two atoms detach from each other and behave as nearly free particles. In contrast,
for small interatomic distances the potential energy keeps increasing as the distance
gets shorter. This manifests the increased repulsion between the nuclear charges, as well
as the quantum mechanical exclusion principle (see Chapter 13), which are opposing
the fusion of the two atoms into the same point in space. At some finite interatomic dis￾tance, R0, the potential energy obtains a minimum. This is the classical “bond-length”
or the “equilibrium distance” of the molecule. For small deviations around the mini￾mum, |R−R0| << |R0|, one can replace R by a Cartesian variable (see Section 9.4 for
a more detailed discussion), q ≡ R−R0, and write an approximated one-dimensional
quantum mechanical Hamiltonian for the molecular vibration,
Hˆ =
−h¯
2
2m
∂
2
∂q
2
+V(R0 +q). (8.4.1)
Additionally, for small deviations from R0 the potential energy function can be approx￾imated to second order in a Taylor series. Setting the zero of potential energy to
V(R0) = 0, one obtains in the harmonic approximation,
V(R0 +q) ∼=
1
2
∂
2V(R0 +q)
∂q
2




q=0
q
2 ≡
1
2
Kq
2
. (8.4.2)
Clearly, this approximation breaks down for large deviations from the equilibrium dis￾tance (see Fig. 8.4.1). Nevertheless, for a stable molecule at its lowest energy state the
approximation becomes accurate. An example is given in Fig. 8.4.2 for the diatomic
molecule, H
35Cl, where the energy levels and the respective stationary probability den￾sities are plotted. The results obtained with the anharmonic potential are compared
to those obtained using its quadratic (harmonic) approximation (see Eq. (8.4.2)). At
the lowest quantum numbers, the energy levels and stationary wave functions are well
approximated by the harmonic model; in particular, the value of the zero-point energy,
E0 =
1
2
h¯ω, and the first excitation energy, E1 −E0 = h¯ω.
As it turns out, for most chemical bonds at standard experimental conditions the
low-energy vibrational states are the most relevant ones. This holds due to the fact
that the typical excitation energies (h¯ω ≈ 0.1−0.5 eV) are much larger than the ther￾mal energy, which for standard room temperature equals kBT ≈ 0.026 eV. Thermal
ensembles will be dealt with only in Chapters 16–20; but let us mention already here
that in thermal equilibrium the condition, kBT << h¯ ω, implies that the bond oscillator
is found primarily at its ground state, where the probability of populating higher lying
vibrational states decays exponentially with the excitation number. It follows that the
harmonic approximation provides a qualitatively correct description for most of the stable
chemical bonds in equilibrium conditions.
An important consequence of the validity of the harmonic approximation for low
vibrational energies is the observed infrared absorption spectrum of molecules inter￾acting with electromagnetic field (see Section 8.1). Indeed, excitation of a harmonic
oscillator from its ground state to higher vibrational levels is subject to a selection rule
https://doi.org/10.1017/9781108877787.009 Published online by Cambridge University Press84 Mechanical Vibrations and the Harmonic Oscillator Model
0
0.08 0.1 0.12 0.14 0.16 0.18 0.2
r [nm]
V [eV]
0.2
0.4
0.6
0.8
1
1.2
1.4
tFigure 8.4.2 Energy levels and probability densities as functions of the interatomic distance in the H
35Cl molecule. The plots are
displaced from each other by the respective energy differences. The solid and dashed lines correspond to solutions
obtained for the anharmonic potential (see Fig.8.4.1) and its harmonic approximation (see Fig.8.3.2), respectively.
derived from the symmetry of the stationary wave functions. Particularly, excitation
from the n = 0 level via a (weak) electromagnetic field is restricted to the first energy
level, n = 1 (see Ex. 8.5.3). This rule applies approximately also for real bond oscilla￾tors, since they are typically found at their ground vibrational state, and therefore, they
are well approximated by the harmonic model. It follows that a specific bond vibration
is associated with a distinctive transition energy, E1−E0 = h¯ ω. Using Planck’s formula
(Eq. (5.2.2), and see Chapter 18 for discussion of radiation absorption and emission),
the transition is associated with a distinctive radiation wavelength,
hc
λ
= E1 −E0 = h¯ ω = h¯
r
K
m
. (8.4.3)
First, we notice that given the typical vibrational excitation energies in chemical
bonds (h¯ ω ≈ 0.1 − 0.5 eV), the corresponding absorption spectra are indeed in the
infrared regime ( 1
λ ∼ 1000−4000cm−1
). Second, each bond is associated with a spe￾cific wavelength, determined by the force constant, and the reduced mass of the atoms.
Finally, let us recall that in a polyatomic molecule, the infrared absorption spectrum
(see Fig. 8.1.1) corresponds to the normal modes of the molecule rather than to local
https://doi.org/10.1017/9781108877787.009 Published online by Cambridge University Press85 8.5 Dirac’s Ladder Operators
chemical bonds between neighboring atoms. The specific (global) normal mode fre￾quencies are a unique characteristic of the molecule, which can be inferred from its
infrared absorption spectrum.
8.5 Dirac’s Ladder Operators
As we saw (Exs. 8.3.3, 8.3.4), the normalized nth and (n±1)th stationary solutions of
the Schrödinger equation for the harmonic oscillator are related as follows:
p
(n+1)φn+1(y) = 1
√
2

y−
∂
∂ y

φn(y), (8.5.1)
√
nφn−1(y) = 1
√
2

y+
∂
∂ y

φn(y). (8.5.2)
Following Dirac, it is useful to identify ladder operators, which map the nth solution
onto the (n±1)th ones. Since the corresponding change in the oscillator energy is ±h¯ω
(see Eq. (8.3.7)), which corresponds to a creation or annihilation of a single energy
quantum, the operators are termed the creation (bˆ†
) and annihilation (bˆ) operators,
bˆφn(y) = √
nφn−1(y), (8.5.3)
bˆ†φn(y) = √
n+1φn+1(y). (8.5.4)
The operators are defined according to Eqs. (8.5.1, 8.5.2):
bˆ ≡
1
√
2

y+
∂
∂ y

, (8.5.5)
bˆ† ≡
1
√
2

y−
∂
∂ y

. (8.5.6)
These operators are non-Hermitian, where bˆ†
is the Hermitian conjugate of bˆ (see
Ex. 8.5.1), and they satisfy the commutation relation (Ex. 8.5.2),
[bˆ,bˆ†
] = 1. (8.5.7)
Using the relations,
y =
1
√
2
(bˆ +bˆ†
) (8.5.8)
∂
∂ y
=
1
√
2
(bˆ −bˆ†
), (8.5.9)
and recalling that y =
qmω
h¯
q, the oscillator position and momentum operators are
related to the ladder operators as follows:
qˆ =
r
h¯
2mω
(bˆ +bˆ†
) ; bˆ =
r
mω
2h¯
qˆ+i
r
1
2mω h¯
pˆ (8.5.10)
https://doi.org/10.1017/9781108877787.009 Published online by Cambridge University Press86 Mechanical Vibrations and the Harmonic Oscillator Model
pˆ = −i
r
mω h¯
2
(bˆ −bˆ†
) ; bˆ† =
r
mω
2h¯
qˆ−i
r
1
2mω h¯
pˆ. (8.5.11)
Finally, the Hamiltonian of the harmonic oscillator can be expressed in terms of the
ladder operators:
Hˆ =
1
2m
pˆ
2 +
1
2
mω
2
qˆ
2 = h¯ω

bˆ†
bˆ +
1
2

. (8.5.12)
Exercise 8.5.1 Use the definition of a Hermitian conjugate, Eq. (4.5.2), and show that
bˆ†
is the Hermitian conjugate of bˆ, using their definitions in Eqs. (8.5.5, 8.5.6).
Exercise 8.5.2 Use the definition of the creation and annihilation operators (Eqs. (8.5.5,
8.5.6)), and show that [bˆ,bˆ†
] = 1.
Exercise 8.5.3 The rate of transitions between stationary states of a system via a “weak”
external perturbation is proportional to the “perturbation matrix element” squared (see
Chapters 17–20). In the case of a molecular vibration interacting with an electromag￾netic field, the perturbation operator is the molecular dipole, which is proportional to the
interatomic distance, y, and the stationary states are approximated as the harmonic oscil￾lator eigenfunctions. The transition rate between two stationary states, φn(y) and φn
0(y),
is therefore given by kn→n
0 ∝




r∞
−∞
φ
∗
n
0(y)yφn
(y)dy




2
. (a) Use Eqs. (8.5.3, 8.5.4, 8.5.8) and
the orthonormality of the stationary states to show that the transition is subject to a
“selection rule”: kn→n
0 ∝

nδn
0
,n−1 + (n+1)δn
0
,n+1

. (b) Use this result to show that the
transition from the ground state is restricted to the first excited state.
Exercise 8.5.4 Prove Eq. (8.5.12) using Eqs. (8.5.7, 8.5.10, 8.5.11).
Since the stationary solutions are eigenfunctions of the Hamiltonian, Hˆψn(q) =
λnψn(q), with the eigenvalues, λn = h¯ω(n+
1
2
) (see Eqs. (8.3.7, 8.3.8)) it follows that
bˆ†
bˆψn(q) = nψn(q) ; n = 0,1,2,.... (8.5.13)
The stationary solutions are therefore eigenfunctions of the operator bˆ†bˆ, with integer
eigenvalues that count the corresponding number of energy quanta. This operator is
therefore termed the number operator,
bˆ†
bˆ = Nˆ , (8.5.14)
where Hˆ = h¯ω[Nˆ +
1
2
]. In applications of the harmonic oscillator model to quantum
field theory the single excitation quantum of the oscillator is regarded as an energy￾carrying particle (a boson). Examples are phonons representing solid lattice vibrations,
or photons corresponding to elementary excitations of the electromagnetic radiation
field. We shall return to the discussion of boson fields in Chapter 18.
https://doi.org/10.1017/9781108877787.009 Published online by Cambridge University Press87 Bibliography
Bibliography
[8.1] M. Abramowitz and A. S. Irene, eds., “Handbook of Mathematical Functions
with Formulas, Graphs, and Mathematical Tables.” National Bureau of Stan￾dards Applied Mathematics Series, vol. 55. (US Government Printing Office,
1964).
[8.2] J. D. D. Martin and J. W. Hepburn, “Determination of bond dissociation ener￾gies by threshold ion-pair production spectroscopy: An improved D0 (HCl).”
The Journal of Chemical Physics 109, 8139 (1998).
https://doi.org/10.1017/9781108877787.009 Published online by Cambridge University Press9 Two-Body Rotation and Angular Momentum
9.1 The Two-Body Problem with a Central Potential
In this chapter we discuss some universal aspects of interparticle interactions, focus￾ing on an interacting pair of particles (“the two-body problem”). For this purpose, let
us consider a closed system composed of two point-particles, associated with masses,
m1,m2, and the position vectors, r1 = (x1, y1,z1) and r2 = (x2, y2,z2), in a Cartesian
coordinates system. In the most general case, the potential energy depends on the abso￾lute positions of the particles, namely, V(r1, r2); but we shall limit the discussion to
the absence of external fields, where the potential energy depends only on the relative
position between the particles, namely, V(r1, r2) = V(r2 −r1). It is therefore useful to
introduce a new set of coordinates, corresponding to the relative position, r, and to the
center-of-mass position, rcm (see Fig. 9.1.1):
r ≡ r2 −r1
rcm ≡
m1
m1+m2
r1 +
m2
m1+m2
r2
. (9.1.1)
rcm
m1
m2
r
x
x
y
y
θ
ϕ
z
z
tFigure 9.1.1 Representation of two particle positions using their center-of-mass coordinates (rcm) and the relative position
coordinates (r = (r,θ,φ)).
88
https://doi.org/10.1017/9781108877787.010 Published online by Cambridge University Press89 9.1 The Two-Body Problem with a Central Potential
Using these variables, the classical Hamiltonian for the “two-body problem” obtains
the form
H =
m1r˙
2
1
2
+
m2r˙
2
2
2
+V(r2 −r1) =
(m1 +m2)r˙
2
cm
2
+
m1m2r˙
2
2(m1 +m2)
+V(r). (9.1.2)
The apparent advantage of changing the coordinates from r1 and r2 to r and rcm is that
the system Hamiltonian becomes separable in the latter, Hrcm,r ≡ Hrcm +Hr. It immedi￾ately follows that the Schrödinger equation can be solved independently for the relative
and for the center-of-mass motions (see Ex. 4.3.4). The quantum mechanical Hamil￾tonian for the center-of-mass motion is trivial (see Eq. 3.4.6), Hˆ
rcm =
−h¯
2
2(m1+m2)
∆ˆ
rcm , and
corresponds to the motion of a single free particle, whose mass is the sum of the two
particle masses. Our focus will naturally be on Hˆ
r, which accounts for the interparticle
interaction,
Hˆ
r =
−h¯
2
2µ
∆ˆ
r +V(rˆ). (9.1.3)
This Hamiltonian corresponds to an effective single particle with a mass, µ ≡
m1m2
m1+m2
(the “reduced mass” of the two particles), in the presence of the interaction.
We now restrict the discussion further, focusing on an important class of pair interac￾tions, associated with “a central potential.” In this case the potential energy is invariant
to the relative orientation between the particles and depends only on the absolute dis￾tance between them, namely on r ≡ |r|. It is therefore most natural to represent the
three-dimensional vector of relative distance in spherical coordinates (see Fig. 2.1.1),
using r = (r,θ,φ), where
V(rˆ) = V(rˆ). (9.1.4)
In spherical coordinates the kinetic energy operator takes the form (see Ex. 9.1.1)
−h¯
2
2µ
∆ˆ
r =
−h¯
2
2µ

∂
2
∂ r
2
+
2
r
∂
∂ r

+
−h¯
2
2µr
2

∂
2
∂ θ
2
+
1
tg(θ)
∂
∂θ
+
1
sin2
(θ)
∂
2
∂ φ2

. (9.1.5)
Exercise 9.1.1 Use the transformation from Cartesian to spherical coordinates,
x = rsin(θ) cos(φ); y = rsin(θ)sin(φ);z = r cos(θ), to derive Eq. (9.1.5) from the kinetic
energy in Cartesian coordinates, −h¯
2
2µ
∆ˆ
r =
−h¯
2
2µ

∂
2
∂ x
2 +
∂
2
∂ y
2 +
∂
2
∂ z
2

.
The term containing derivatives with respect to r is associated with the radial kinetic
energy. In classical mechanics, it would correspond to dynamical changes in the abso￾lute interparticle distance. The term containing derivatives with respect to the angles
is associated with a rotational kinetic energy; namely, in classical mechanics, it would
correspond to a motion in which the orientation of the particle in space (θ and/or φ)
changes in time. Recalling the kinetic energy of a classical rotor, that is, |L|
2
2µr
2
, where L
is the vector of angular momentum, the rotational kinetic energy can be expressed in
terms of the angular momentum operator |Lˆ |
2 ≡ Lˆ 2
:
Lˆ
2 = −h¯
2

∂
2
∂ θ
2
+
1
tg(θ)
∂
∂θ
+
1
sin2
(θ)
∂
2
∂ φ2

. (9.1.6)
https://doi.org/10.1017/9781108877787.010 Published online by Cambridge University Press90 Two-Body Rotation and Angular Momentum
Indeed, recalling the definitions of the three components of the angular momentum
vector operator in Cartesian coordinates (Eq. (3.3.2)), and transforming to spherical
coordinates (Ex. 9.1.2), we obtain
Lˆ
x = ih¯

sin(φ)
∂
∂θ
+cot(θ) cos(φ)
∂
∂φ

Lˆ
y = −ih¯

cos(φ)
∂
∂θ
−cot(θ)sin(φ)
∂
∂φ

Lˆ
z = −ih¯
∂
∂φ
Lˆ
2 = Lˆ
2
x +Lˆ
2
y +Lˆ
2
z
(9.1.7)
where the expression for the total angular momentum (Eq. (9.1.6)) is reproduced.
Exercise 9.1.2 Using the transformation from Cartesian to spherical coordinates, x =
rsin(θ) cos(φ); y = rsin(θ)sin(φ); z = r cos(θ), derive (a) the explicit expressions for
Lˆ
x, Lˆ
y, Lˆ
z
in Eq. (9.1.7); (b) Eq. (9.1.6) by summing over the component of the angular
momentum vector, Lˆ 2 = Lˆ 2
x +Lˆ 2
y +Lˆ 2
z
.
The information regarding the interaction within the pair of particles is contained in
the solutions to the time-independent Schrödinger equation for their relative position.
For any central potential, V(r), this equation obtains the form (Eqs. (9.1.3–9.1.6))

−h¯
2
2µ

∂
2
∂ r
2
+
2
r
∂
∂ r

+
Lˆ 2
2µr
2
+V(r)

ψ(r,θ,φ) = Eψ(r,θ,φ). (9.1.9)
The equation has solutions that are products of functions of the radial and angu￾lar variables, namely, ψ(r,θ,φ) ≡ Y(θ,φ)R(r). It can be readily verified (Ex. 9.1.3)
that these solutions (based on separation of variables) must simultaneously satisfy an
angular equation,
Lˆ
2Y(θ,φ) = λY(θ,φ), (9.1.10)
and a radial equation,
−h¯
2
2µ

∂
2
∂ r
2
+
2
r
∂
∂ r

R(r) + [V(r) + λ
2µr
2
]R(r) = ER(r). (9.1.11)
The angular equation (Eq. (9.1.10)) is the eigenvalue equation for the angular momen￾tum operator, Lˆ 2
(as defined in Eq. (9.1.6)). Its solutions constitute the angular part
of the stationary solutions of the Schrödinger equation with any central potential and
are discussed in the following section (Section 9.2). The radial equation depends on
the specific interaction term, V(r). In Chapter 10 we discuss in detail an important
example of the radial equation, which corresponds to the hydrogen atom.
Exercise 9.1.3 Show that any product function ψ(r,θ,φ) ≡Y(θ,φ)R(r), where Y(θ,φ)
and R(r) are defined solutions to Eq. (9.1.10) and Eq. (9.1.11), respectively, is a solution
to Eq. (9.1.9).
https://doi.org/10.1017/9781108877787.010 Published online by Cambridge University Press91 9.2 Angular Momentum Eigenstates
9.2 Angular Momentum Eigenstates
Focusing on the angular dependence of the solutions to the time-independent
Schrödinger equation, we seek for proper solutions to the angular equation,
Lˆ 2Y(θ,φ) = λY(θ,φ) (Eq. (9.1.10)). We can readily identify this equation as the eigen￾value equation for the angular momentum operator, Lˆ 2
; namely, we seek for the
eigenfunctions of this operator, and their corresponding eigenvalues, denoted here
by λ.
We first notice that the operators Lˆ 2 and Lˆ
z commute, that is, [Lˆ 2
,Lˆ
z
] = 0 (see
Eq. (3.3.5)). It follows (see Ex. 6.4.1) that the eigenfunctions of Lˆ
z are also eigenfunc￾tions of Lˆ 2
. Recalling the explicit form of the Lˆ
z-eigenfunctions (encountered already
in Chapter 5 in the context of the “particle on a ring”; see Eqs. (5.4.7–5.4.9)),
Lˆ
z
1
√
2π
e
imφ = mh¯
1
√
2π
e
imφ
; m = 0,±1,±2,±3,..., (9.2.1)
we can conclude that Lˆ
z and Lˆ 2 have a common set of eigenfunctions, each associated
with a quantum number m, which we denote as Yλ,m(θ,φ). The quantum number m
defines the eigenvalue of Lˆ
z
, and λ is the respective Lˆ 2
-eigenvalue, namely,
Lˆ
zYλ,m(θ,φ) = mhY¯ λ,m(θ,φ), (9.2.2)
Lˆ
2Yλ,m(θ,φ) = λYλ,m(θ,φ). (9.2.3)
Eqs. (9.2.1, 9.2.2) imply that Yλ,m(θ,φ) must obtain the following form:
Yλ,m(θ,φ) ≡ Θλ,m(θ)
1
√
2π
e
imφ
. (9.2.4)
Seeking for the unknown function, Θλ,m(θ), we can substitute Yλ,m(θ,φ) in the Lˆ 2
-
eigenvalue equation (Eq. (9.1.10)). Using Eq. (9.1.6), we have
−h¯
2

∂
2
∂ θ
2
+
1
tg(θ)
∂
∂θ
+
1
sin2
(θ)
∂
2
∂ φ2

Yλ,m(θ,φ) = λYλ,m(θ,φ), (9.2.5)
which yields an explicit equation for Θλ,m(θ):
−h¯
2

∂
2
∂ θ
2
+
1
tg(θ)
∂
∂θ
+
−m
2
sin2
(θ)

Θλ,m(θ) = λΘλ,m(θ). (9.2.6)
Notice that the quantum number m, which determines the dependence of Yλ,m(θ,φ) on
the azimuthal angle, φ, determines also the dependence ofYλ,m(θ,φ) on the polar angle
θ, through the function Θλ,m(θ). This correlation between the two angular dependen￾cies is due to the nonseparable form of the operator Lˆ 2
in the two angular variables
(see Eq. (9.2.5)).
To identify the proper solutions to Eq. (9.2.6), we recall that the polar angle is
defined on the finite interval, 0 ≤ θ ≤ π, where the wave function normalization
https://doi.org/10.1017/9781108877787.010 Published online by Cambridge University Press92 Two-Body Rotation and Angular Momentum
condition reads rπ
0
|Θλ,m(θ)|
2
sin(θ)dθ = 1. It is convenient to define a new variable
and a corresponding function:
ξ = cos(θ) ; Θλ,m(θ) = fλ,m(ξ ). (9.2.7)
The normalization condition translates to r 1
−1
| fλ,m(ξ )|
2dξ = 1, and Eq. (9.2.6) turns
into the following equation for fλ,m(ξ ) on the interval −1 ≤ ξ ≤ 1:

(ξ
2 −1)
d
2
dξ
2
+2ξ
d
dξ
+
m
2
1−ξ
2

fλ,m(ξ ) = λ
h¯
2
fλ,m(ξ ). (9.2.8)
Let us consider first the case, m = 0. In this case [9.1] the corresponding ordinary
differential equation is guaranteed to have solutions that are polynomials of a finite
degree in ξ :
fλ,0
(ξ ) = ∑
l
k=0
a
(λ,0)
k
ξ
k
. (9.2.9)
Indeed, substituting fλ,0
(ξ ) in Eq. (9.2.8) for m = 0 and shifting the series index,
we obtain the following closed equation for the coefficient of the finite (lth) degree
polynomials:
l−2
∑
k=0
(k +1)(k +2)a
(λ,0)
k+2
ξ
k =
l
∑
k=0

k(k +1)−
λ
h¯
2

a
(λ,0)
k
ξ
k
. (9.2.10)
Comparing the coefficients of ξ
k
in both sides of the equation for any k, we have
[l(l +1)−
λ
h¯
2
]a
(λ,0)
l = 0 ; k = l
[l(l −1)−
λ
h¯
2
]a
(λ,0)
l−1 = 0 ; k = l −1
a
(λ,0)
k+2 =
k(k+1)−λ/h¯
2
(k+1)(k+2)
a
(λ,0)
k
; 0 ≤ k ≤ l −2.
(9.2.11)
Since a
(λ,0)
l
6= 0 for an lth-degree polynomial it follows that h
l(l +1)−
λ
h¯
2
i
= 0. We can
therefore identify a set of discrete values for λ, namely for the eigenvalues of Lˆ 2
:
λl = h¯
2
l(l +1) ; l = 0,1,2,.... (9.2.12)
According to Eqs. (9.2.11, 9.2.12), the coefficient a
(λ,0)
l−1 must vanish, and the rest of the
coefficients for the lth-degree polynomial can be obtained recursively. Notice that the
nonzero coefficients in each polynomial correspond to either even or odd powers of ξ
(see also Ex. 9.2.1).
Exercise 9.2.1 Recalling the definition of the parity operator: P f ˆ (ξ ) = f(−ξ ), do the
following. (a) Prove that Pˆ commutes with the differential operator on the left-hand
side of Eq. (9.2.8). (b) Use the result of Ex. 6.4.1 and Eq. (9.2.12) to show that the
eigenfunctions of Eq. (9.2.8) must be either even or odd functions of ξ .
The polynomials satisfying Eq. (9.2.11) can be readily identified as the associated
Legendre polynomials of zero order, {P
0
l
(ξ )} (also termed the lth-degree Legendre
https://doi.org/10.1017/9781108877787.010 Published online by Cambridge University Press93 9.2 Angular Momentum Eigenstates
polynomials [8.1]). These polynomials are defined by the function, P
0
l
(ξ ) = 1
2
l
l!
d
l
dξ
l
(ξ
2 − 1)
l
, and they satisfy an orthogonality relation, r 1
−1
P
0
l
0(ξ )P
0
l
(ξ ) = 2
2l+1
δl,l
0 . It
follows that the normalized proper solutions to Eqs. (9.2.6, 9.2.7) with m = 0 are
fλ,0
(ξ ) ≡
r
2l +1
2
P
0
l
(ξ ). (9.2.13)
Using Eqs. (9.2.4, 9.2.7), the corresponding Lˆ 2
-eigenfunctions read
Yλ,0
(θ,φ) = r
2l +1
4π
P
0
l
(cos(θ)). (9.2.14)
To obtain the eigenfunctions associated with m 6= 0, we can solve an ordinary dif￾ferential equation (Eq. (9.2.8)) directly for fλ,m(ξ ). Alternatively, we can make use of
angular momentum “ladder operators,” defined as
Lˆ+ ≡ Lˆ
x +iLˆ
y
Lˆ− ≡ Lˆ
x −iLˆ
y. (9.2.15)
These operators are Hermitian conjugates of each other, Lˆ− = Lˆ
†
+, and satisfy the
following commutation relations (Ex. 9.2.2):
[Lˆ
z
,Lˆ±] = ±h¯Lˆ±, (9.2.16)
[Lˆ
2
,Lˆ±] = 0. (9.2.17)
Exercise 9.2.2 The angular momentum ladder operators, Lˆ+ and Lˆ−, are defined in
Eq. (9.2.15). Show the following:
(a) Lˆ+ and Lˆ− are Hermitian conjugates of each other.
(b) [Lˆ+,Lˆ−] = 2h¯Lˆ
z
, [Lˆ
z
,Lˆ±] = ±h¯Lˆ±, and [Lˆ 2
,Lˆ±] = 0.
(c) Lˆ 2 −Lˆ 2
z =
1
2
(Lˆ+Lˆ− +Lˆ−Lˆ+).
We can readily verify that if Yλ,m(θ,φ) is a simultaneous eigenfunction of Lˆ 2 and
Lˆ
z (associated with the eigenvalues λ and hm¯ , respectively), so are the functions
Lˆ±Yλ,m(θ,φ). Indeed, using the commutation relations in Eqs. (9.2.16, 9.2.17) we have
Lˆ
z
[Lˆ±Yλ,m(θ,φ)] = ([Lˆ
z
,Lˆ±] +Lˆ±Lˆ
z)Yλ,m(θ,φ) = (m±1)h¯[Lˆ±Yλ,m(θ,φ)]. (9.2.18)
Lˆ
2
[Lˆ±Yλ,m(θ,φ)] = Lˆ±Lˆ
2Yλ,m(θ,φ) = λ[Lˆ±Yλ,m(θ,φ)]. (9.2.19)
Consequently, we can identify
Yλ,m±1
(θ,φ) ∝ Lˆ±Yλ,m(θ,φ). (9.2.20)
It follows that any common eigenfunction of Lˆ 2and Lˆ
z
, namely any Yλ,m(θ,φ), can be
related to Yλ,0
(θ,φ) as follows:
https://doi.org/10.1017/9781108877787.010 Published online by Cambridge University Press94 Two-Body Rotation and Angular Momentum
Yλ,±|m|
(θ,φ) ∝ (Lˆ±)
|m|Yλ,0
(θ,φ), (9.2.21)
where the Lˆ 2
-eigenvalues, {λ}, are independent on m. These eigenvalues were already
obtained explicitly for the case m = 0 (see Eq. (9.2.12)), that is, λl = h¯
2
l(l + 1). Since
λl
is uniquely defined by the quantum number l, we shall hereafter denote the common
eigenfunctions of Lˆ 2and Lˆ
z by two quantum numbers, l and m:
Yλ,m(θ,φ) ≡ Yl,m(θ,φ). (9.2.22)
The explicit expressions for any Yl,m(θ,φ) can be derived, recalling that Yl,0(θ,φ) ∝
P
0
l
(cos(θ)) (see Eq. (9.2.14)) and that the ladder operators take the explicit form (see
Ex. 9.2.3):
Lˆ± = he¯
±iφ
[±
∂
∂θ
+i cot(θ)
∂
∂φ
]. (9.2.23)
Using Eq. (9.2.21), it follows that Yl,m(θ,φ) is identified as
Yl,m(θ,φ) ∝ P
|m|
l
(cos(θ))e
imφ
, (9.2.24)
where {P
|m|
l
(ξ )} are the associated Legendre polynomials, defined as (for m ≥ 0)
P
m
l
(ξ ) ≡ (−1)
m
(1−ξ )
m
2
d
m
dξ
m
P
0
l
(ξ ) ; m ≥ 0. (9.2.25)
Indeed, using this definition, we can readily see (Ex. 9.2.4) that
m ≥ 0 ; Lˆ+P
m
l
(ξ )e
imφ = hP¯
m+1
l
(ξ )e
i(m+1)φ
m ≤ 0 ; Lˆ−P
|m|
l
(ξ )e
imφ = −hP¯
|m|+1
l
(ξ )e
i(m−1)φ
, (9.2.26)
where it follows that the function P
|m|
l
(cos(θ))e
imφ
is obtained for any m (up to nor￾malization) by |m| successive operations of the ladder operators on P
0
l
(ξ ), as required
for Yl,m(θ,φ) in Eq. (9.2.21). Notice, however, that for |m| > l, P
|m|
l
(ξ ) must vanish
identically, since P
0
l
(ξ ) is a polynomial of degree l in ξ . A proper (i.e., a nontrivial)
eigenfunction Yl,m(θ,φ) is therefore limited to
|m| ≤ l, (9.2.27)
where it follows that for any eigenvalue of Lˆ 2
(namely, for any value of the quan￾tum number, l = 0,1,2,....), there are 2l + 1 degenerate eigenfuctions, Yl,m(θ,φ),
corresponding to the values m = −l,−l +1,...,0,...,l −1,l.
Exercise 9.2.3 (a) Derive Eq. (9.2.23) using Eqs. (9.1.7, 9.2.15). (b) Changing
variable, ξ = cos(θ), show that Lˆ± = he¯
±iφ

∓
p
1−ξ
2 d
dξ +i√
ξ
1−ξ
2
∂
∂φ

.
Exercise 9.2.4 The associated Legendre polynomials are defined in Eq. (9.2.25). (a)
Show that (for nonnegative m) we have P
m+1
l
(ξ ) = (−1)
p
1−ξ
2 d
dξ + √mξ
1−ξ
2

P
m
l
(ξ ).
(b) Derive the relations in Eq. (9.2.26).
https://doi.org/10.1017/9781108877787.010 Published online by Cambridge University Press95 9.2 Angular Momentum Eigenstates
Finally, we address the eigenfunctions normalization. We start by recalling the nor￾malized function for m = 0, namely, Yl,0(θ,φ) = q
2l+1
4π
P
0
l
(cos(θ)) (see Eq. (9.2.14)).
Then, we identify the following relations between the normalized functions, Yl,m(θ,φ)
and Yl,m±1(θ,φ) for |m| < l (see Ex. 9.2.5):
Yl,m+1(θ,φ) = 1
h¯
√
(l−m)(l+m+1)
Lˆ+Yl,m(θ,φ)
Yl,m−1(θ,φ) = 1
h¯
√
(l+m)(l−m+1)
Lˆ−Yl,m(θ,φ).
(9.2.28)
It follows that any normalized Yl,m(θ,φ) is obtained by |m| successive operations of Lˆ+,
or Lˆ− (for positive or negative m, respectively) on Yl,0(θ,φ). Together with Eq. (9.2.26),
this yields (Ex. 9.2.6)
Yl,m(θ,φ) = (−1)
m
r
2l +1
4π
s
(l −|m|)!
(l +|m|)!
P
|m|
l
(cos(θ))e
imφ
, (9.2.29)
where the (−1)
m is conventional.
Exercise 9.2.5 Let Yl,m(θ,φ) and Yl,m±1(θ,φ) be normalized functions:
2
rπ
0
dφ
rπ
0
sin(θ)
dθY
∗
l,m
(θ,φ)Yl,m(θ,φ) =
2
rπ
0
dφ
rπ
0
sin(θ)dθY
∗
l,m±1
(θ,φ)Yl,m±1(θ,φ) = 1, and let Yl,m±1
(θ,φ) = c±Lˆ±Yl,m(θ,φ). Use the results of Ex. 9.2.2 to show that (for |m| < l) c± =
1
h¯
√
(l±m+1)(l∓m)]
.
Exercise 9.2.6 Use Eqs. (9.2.26, 9.2.28) and Yl,0(θ,φ) = q
2l+1
4π
P
0
l
(cos(θ)) to derive
Eq. (9.2.29).
The normalized functions, Yl,m(θ,φ), are known in the literature as the spherical
harmonics [9.2]. Some examples, corresponding to the angular quantum numbers,
l = 0,1,2, are presented explicitly in Fig. 9.2.1. A summary of important properties
of the spherical harmonics follows:
I. The set {Yl,m(θ,φ)} consists of proper simultaneous solutions to the following
eigenvalue equations:
Lˆ
2Yl,m(θ,φ) = h¯
2
l(l +1)Yl,m(θ,φ) ; l = 0,1,2,..., (9.2.30)
Lˆ
zYl,m(θ,φ) = mhY¯ l,m(θ,φ) ; |m| ≤ l. (9.2.31)
II. The set {Yl,m(θ,φ)} is an orthonormal set of angular functions in the spherical
coordinate space (0 ≤ θ ≤ π, and 0 ≤ φ < 2π):
w
2π
0
dφ
wπ
0
sin(θ)dθY
∗
l,m(θ,φ)Yl
0
,m0(θ,φ) = δl,l
0δm,m0. (9.2.32)
https://doi.org/10.1017/9781108877787.010 Published online by Cambridge University Press96 Two-Body Rotation and Angular Momentum
Y0,0(θ,ϕ) = 4π
1
Y1,0(θ,ϕ) = cos(θ) 4π
3
sin(θ)eiϕ Y1,1(θ,ϕ) = 8π
3
(3 cos2 Y (θ)−1) 2,0(θ,ϕ) = 16π
5
Y 3 cos (θ) sin(θ)eiϕ 2,1(θ,ϕ) = 24π
5
Y 3 cos (θ) sin(θ)e−iϕ 2,−1(θ,ϕ) = 24π
5
3 sin2 Y (θ)e2iϕ 2,2(θ,ϕ) = 96π
5
3 sin2 Y (θ)e−2iϕ 2,−2(θ,ϕ) = 96π
5
Y sin(θ)e−iϕ 1,−1(θ,ϕ) = 8π
3 −
tFigure 9.2.1 A list of the spherical harmonics associated with the angular quantum numbers, l = 0,1,2.
III. For any quantum number, l, there is a set of 2l+1 degenerate orthogonal functions,
corresponding to m = −l,...,0,...,l. In atomic physics and chemistry (see Chapter
10), it is customary to replace the set of spherical harmonics associated with a given
l by a set of real-valued linear combinations of spherical harmonics (see Ex. 4.6.3).
For example, the set {Y1,−1(θ,φ),Y1,0(θ,φ),Y1,1(θ,φ)} is replaced by
Y1,0(θ,φ),
√
1
2
[Y1,1(θ,φ) +Y1,−1(θ,φ)],
√
1
2
[Y1,1(θ,φ)−Y1,−1(θ,φ)],
and the set {Y2,−2(θ,φ),Y2,−1(θ,φ),Y2,0(θ,φ),Y2,1(θ,φ),Y2,2(θ,φ)} is replaced by
Y2,0(θ,φ)
√
1
2
[Y2,1(θ,φ) +Y2,−1(θ,φ)]
√
1
2
[Y2,1(θ,φ)−Y2,−1(θ,φ)]
√
1
2
[Y2,2(θ,φ) +Y2,−2(θ,φ)]
√
1
2
[Y2,2(θ,φ)−Y2,−2(θ,φ)].
IV. The spherical harmonics (or linear combinations of degenerate spherical harmonics)
constitute the angular part of the stationary states of the Schrödinger equation in any
central potential problem (see Eq. (9.1.9)).
https://doi.org/10.1017/9781108877787.010 Published online by Cambridge University Press97 9.3 The Rigid Rotor Model and Rotational Spectrum of Diatomic Molecules
9.3 The Rigid Rotor Model and Rotational Spectrum of Diatomic
Molecules
When the radial motion is highly constrained or suppressed, a model of a “rigid rotor”
becomes instrumental. Referring to the time-independent Schrödinger equation for a
general central potential (Eq. (9.1.9)), the rigid rotor corresponds to the case where
the radial distance obtains a fixed value, r = r0. The Schrödinger equation therefore
obtains the form
Lˆ 2
2µr
2
0
ψ(r0,θ,φ) = Eψ(r0,θ,φ), (9.3.1)
where the Hamiltonian reduces to the angular kinetic energy operator, with the relative
distance coordinate, r, replaced by a parameter, r0:
Hˆ =
Lˆ 2
2µr
2
0
. (9.3.2)
Since the Hamiltonian is proportional to the angular momentum operator, Lˆ 2
, the
stationary solutions to the Schrödinger equation coincide with the Lˆ 2
-eigenfunctions
(see Eqs. (9.2.29–9.2.31)), and the corresponding energy levels are proportional to the
Lˆ 2
-eigenvalues, namely,
HYˆ
l,m(θ,φ) = ElYl,m(θ,φ) (9.3.3)
El =
h¯
2
l(l +1)
2µr
2
0
; l = 0,1,2,.... (9.3.4)
The rigid-rotor model can be successfully applied in the analysis of the relative
rotational motion of atoms in molecules. Particularly, let us consider here a diatomic
molecule, as discussed in Section 8.4, where two atoms with masses, m1 and m2, are con￾nected via a chemical bond. The relative motion of the two atoms is associated with
the relative position vector, r = r1 −r2 ≡ (r,θ,φ), and a reduced mass, m =
m1m2
m1+m2
(see
Fig. 9.1.1). Since the interaction between the atoms is due to the electrically charged
electrons and atomic nuclei (see Chapter 14), the potential energy depends only on
the absolute relative distance between the atom centers, namely, V(r) = V(r). Conse￾quently, the relative motion is associated with a Schrödinger equation for a central
potential (Eq. (9.1.9)). In Section 8.4, we focused on the radial part, associated with
the interatomic vibrations, where the coupling between the radial and the angular
motions via the centrifugal term, Lˆ 2
2µr
2
, was neglected. Indeed, for typical rotational
and vibrational energies in diatomic molecules, rotations can be ignored to a good
approximation for the purpose of describing the vibrations. Similarly, for an approx￾imate qualitative discussion of the rotational motion, the vibrational motion can be
ignored. In classical mechanical terms, the justification for the separate treatment is
derived from a timescale separation, where rotational motion is typically much slower
https://doi.org/10.1017/9781108877787.010 Published online by Cambridge University Press98 Two-Body Rotation and Angular Momentum
than the vibrations in molecules. This implies that the rotation is nearly frozen on
the vibration timescale, while the fast vibrational motion can be averaged in time on
the rotational timescale. In quantum mechanical terms (see an extended discussion of
quantum dynamics in Chapter 15), the timescale separation corresponds to the fact
that a slower (rotational, in this case) motion is associated with a denser spectrum of
energy levels. Indeed, rotational excitation energies are typically much smaller than
vibrational excitation energies, such that the rotational dynamics can be well approx￾imated by assuming a constant vibrational quantum number. (This argument is often
referred to as “an adiabatic approximation,” to be discussed in more detail in Chapter
14 in the context of separating the treatment of the “fast” electrons from the “slow”
nuclei in molecules.) The timescale separation argument implies that the diatomic mol￾ecule can be regarded approximately as a rigid rotor, with a constant moment of inertia,
I = µr
2
0
, set by the reduced mass and by the typical (e.g., averaged) interatomic dis￾tance, associated with its vibrational ground state (see Section 8.4). In Section 9.4, the
validity of this approximation is discussed in quantitative terms.
The relevance of the rigid rotor model to the rotational energy spectrum of a dia￾tomic molecule can be revealed in experiments when the molecule interacts with an
electromagnetic radiation. Specifically, molecules having a finite permanent electric
dipole moment (namely, molecules composed of two different atoms) change their
energy upon interaction with the external electric field. This change is given as, −µ·E,
where µ is the molecular dipole, and E is the electric field vector. Since the projection
µ·E = |µ||E| cos(χ) depends on an angle (χ) between the molecular dipole (directed
along the axis connecting the two atomic centers) and the electric field vector, the
energy of the molecule in the field changes upon rotation. The molecular rotational
energy can therefore increase (via radiation absorption) or decrease (via radiation
emission) in the presence of the field.
Transitions between stationary states, induced by a weak interaction with the field,
are subject to selection rules derived from the properties of the respective stationary
wave functions (see Chapter 18 for a detailed discussion of field induced transi￾tions). For a perfectly rigid rotor, the stationary states are the spherical harmonics
(Eq. (9.3.3)), and the corresponding selection rules imply that transitions are restricted
to changes of the angular momentum quantum number, l, by ±1 (see Ex. 9.3.1). Focus￾ing on absorption of rotational energy (namely, l → l +1) and using Planck’s formula
(Eq. (5.2.2)), it follows that each transition is associated with a distinctive radiation
wavelength, λ
(ab)
l
, given by hc
λ
(ab)
l
= El+1−El
. Using Eq. (9.3.4) for the rotational energy
levels and defining a rotational constant, B, the set of absorption wavelengths for any
specific molecule is given as
1
λl
= 2B(l +1) ; B ≡
h¯
4πcµr
2
0
; l = 0,1,2,.... (9.3.5)
As we can readily perceive (see also Fig. 9.4.2), the inverse wavelengths are evenly
spaced, 1
λ
∈ 2B,4B,6B,....,. Notice that while the sequence is formally infinite, in prac￾tice, transitions corresponding to large l values are not observed in experiments at
https://doi.org/10.1017/9781108877787.010 Published online by Cambridge University Press99 9.3 The Rigid Rotor Model and Rotational Spectrum of Diatomic Molecules
typical thermal equilibrium conditions (see, e.g., [9.3]). The main reason is that rota￾tional energies that exceed the thermal energy El >> KBT are rarely found at thermal
equilibrium (see Chapter 16 for a detailed discussion of thermal ensembles), and rare
events are missed at a finite detection resolution.
Exercise 9.3.1 The rate of transitions between stationary states of a system via a “weak”
external perturbation is proportional to the “perturbation matrix element” squared (see
Chapters 17–20). In the case of rotation of a diatomic molecule interacting with an elec￾tromagnetic field, the perturbation operator is the projection of the molecular dipole on
the electric field vector (−µ·E). When the direction of the electric field vector is fixed in
the lab reference frame, it is convenient to identify it with the z-axis direction of the molec￾ular reference frame. The perturbation operator is then proportional to cos(θ), where θ
is the polar angle of the spherical coordinate system. The rate of field-induced transi￾tions between two rotational eigenfunctions, Yl,m(θ,φ) and Yl
0
,m0(θ,φ), reads kl,m→l
0
,m0 ∝





2
rπ
0
dφ
rπ
0
sin(θ)dθY
∗
l
0
,m0(θ,φ) cos(θ)Yl,m
(θ,φ)





2
. Use the relation of the spherical harmon￾ics to the associated Legendre polynomials (Eq. (9.2.29)), a known recursive relation for
associated Legendre polynomials, (2l + 1) cos(θ)P
m
l
(cos(θ)) = (l − m + 1)P
m
l+1
(cos(θ))
+(l + m)P
m
l−1
(cos(θ))[9.4], and the orthonormality of the spherical harmonics, (Eq.
(9.2.32)) to derive the “selection rule” for rotational transitions induced by a (weak)
electromagnetic field, kl,m→l
0
,m0 ∝ δm0
,mδl
0
,l±1
.
The interpretation of the rotational absorption spectra of diatonic molecules in
terms of the rigid rotor model immediately leads to several practical conclusions.
First, the typical absorption wave lengths are within the microwave regime (defined
as 1
λ ∼ 0.01 − 10 cm−1
). Second, knowing the atomic masses, one can extract the
interatomic distance, r
0
, with remarkable precision. Let us consider, for example, the
molecule H
35Cl (discussed in Section 8.4), where the measured rotational constant cor￾responds to B ∼= 10.6 cm−1
. Considering the reduced mass, µ = 1.6 × 10−27 kg, this
readily yields the interatomic distance, r0 ≡
q h¯
4πcµB ≈ 0.128 nm. In other cases, the
interatomic distance, r0, is already known, and the reduced mass can be deduced by
measuring the rotational constant. Particularly, while different isotopes of the same
chemical element are associated with different masses, they have the same electronic
structure. Therefore, diatomic molecules containing different isotopes experience the
same interatomic forces and have nearly the same interatomic distance r
0
(strictly the
same, within the harmonic approximation for the vibrations), but a different reduced
mass, µ. Consequently, diatomic molecules containing different isotopes have different
rotational constants. For example, the rotational constant of H
35Cl is larger by 0.15%
than that of H
37Cl, and by 95% than that of D
35Cl (see Ex. 9.3.2). These differences
are readily detectable in experiments.
Exercise 9.3.2 Use the definition of the rotational constant to show that the rotational
constant of H
35Cl is larger by 0.15% than that of H
37Cl, and by 95% than that of D
35Cl.
https://doi.org/10.1017/9781108877787.010 Published online by Cambridge University Press100 Two-Body Rotation and Angular Momentum
9.4 Beyond the Rigid Rotor Model: Vibration–Rotation Coupling
In this section we address the coupling between vibration and rotation, beyond the
rigid rotor approximation. Specifically, we shall analyze the manifestation of this
coupling in the spectrum of diatomic molecules, and the validity of the timescale sepa￾ration argument, which justifies the separate treatment of vibration and rotation. Our
discussion would be restricted to small deviations of the interatomic distance from r0,
and to the lowest vibrational state, where the potential energy can be approximated
within the harmonic approximation (see Section 8.4):
V(r) = 1
2
µω
2
(r −r0)
2
. (9.4.1)
The stationary Schrödinger equation for the coupled vibration and rotation degrees of
freedom of a diatomic molecule therefore reads

−h¯
2
2µ

∂
2
∂ r
2
+
2
r
∂
∂ r

+
Lˆ 2
2µr
2
+
1
2
µω
2
(r −r0)
2

ψ(r,θ,φ) = Eψ(r,θ,φ). (9.4.2)
As for any central potential problem, the corresponding stationary solutions are
of the form ψ(r,θ,φ) = Yl,m(θ,φ)R(r), where Yl,m(θ,φ) are the angular momen￾tum eigenfunctions (see Eqs. (9.1.9–9.1.11)). Substitution in Eq. (9.4.2) leads to the
corresponding radial equation for the function R(r),
−h¯
2
2µ

∂
2
∂ r
2
+
2
r
∂
∂ r

R(r) +
µω
2
2
(r −r0)
2 +
h¯
2
l(l +1)
2µr
2

R(r) = ER(r), (9.4.3)
where an l-dependent centrifugal potential energy term, h¯
2
l(l+1)
2µr
2
, is added to the radial
potential energy. The equation can be simplified by defining χ(r) ≡ rR(r). Substitution
in Eq. (9.4.3) yields (see Ex. 9.4.1)
−
h¯
2
2µ
∂
2
∂ r
2
χ(r) +
µω
2
2
(r −r0)
2 +
h¯
2
l(l +1)
2µr
2

χ(r) = Eχ(r). (9.4.4)
Exercise 9.4.1 Use the definition χ(r) ≡ rR(r), and derive Eq. (9.4.4) from Eq. (9.4.3).
Focusing on the deviations from r0, we define a vibration coordinate, q ≡ r − r0, and
change variables, χ(r) = ϕ(q). The equation for ϕ(q) (in the range, q ≥ −r0) reads
−
h¯
2
2µ
∂
2
∂q
2
ϕ(q) +
µω
2
2
q
2 +
h¯
2
l(l +1)
2µ(r0 +q)
2

ϕ(q) = Eϕ(q), (9.4.5)
where the vibrational coordinate is coupled to the angular momentum, h¯
2
l(l +1), via
the q-dependent moment of inertia. It is instructive to associate the centrifugal poten￾tial energy with a “rotational frequency.” Motivated by the classical relation between
the rotation frequency, the angular momentum, and the moment of inertia, ωrot =
L
I
,
we define
https://doi.org/10.1017/9781108877787.010 Published online by Cambridge University Press101 9.4 Beyond the Rigid Rotor Model: Vibration–Rotation Coupling
ωl ≡
q
h¯
2
l(l +1)
µr
2
0
, (9.4.6)
and rewrite Eq. (9.4.5) as follows:
−
h¯
2
2µ
∂
2
∂q
2
ϕ(q) +
µω
2
2
q
2 +
µω
2
l
2
r
2
0
1
(1+q/r0)
2

ϕ(q) = Eϕ(q). (9.4.7)
This equation can be solved analytically in a most important parameter regime, which
corresponds to small vibrational amplitudes. Indeed, in typical diatomic molecules, the
distribution of interatomic distances is much narrower than the average bond length,
namely,
|q/r0|  1. (9.4.8)
In this regime it is useful to expand, 1
(1+q/r0)
2 = (1−2q/r0+3(q/r0)
2+···), and to keep
only the linear term in q. Notice, however, that terms of order o(q
2
) in the centrifu￾gal potential can be neglected in Eq. (9.4.7) only if they are small with respect to the
harmonic potential energy, µω
2
2
q
2
, which amounts to
ωl
ω
 1. (9.4.9)
This condition limits the validity of the linear approximation to small rotational quan￾tum numbers, for which the rotational frequency is small with respect to the bond
harmonic frequency. Under the restrictions of Eqs. (9.4.8, 9.4.9), the equation for
the vibrational functions becomes a Schrödinger equation for a linearly displaced
harmonic oscillator,
−
h¯
2
2µ
∂
2
∂q
2
ϕ(q) +
µω
2
2
q
2 − µω
2
l
r0q+
µω
2
l
r
2
0
2

ϕ(q) = Eϕ(q). (9.4.10)
Defining a displaced coordinate, ql
, and a corresponding energy, εl
, Eq. (9.4.10)
transforms into (see Ex. 9.4.2)
−
h¯
2
2µ
∂
2
∂q
2
l
ϕ˜(ql) + µω
2
2
q
2
l ϕ˜(ql) = (E −εl)ϕ˜(ql), (9.4.11)
where ϕ˜(ql) = ϕ(q), and
ql = q−r0
ω
2
l
ω2
= r −r0

1+
ω
2
l
ω2

, (9.4.12)
εl =
µω
2
l
r
2
0
2

1−
ω
2
l
ω2

. (9.4.13)
Exercise 9.4.2 Use Eqs. (9.4.12–9.4.13) to derive Eq. (9.4.11) from Eq.(9.4.10).
https://doi.org/10.1017/9781108877787.010 Published online by Cambridge University Press102 Two-Body Rotation and Angular Momentum
Eq. (9.4.11) is the time-independent Schrödinger equation for a harmonic oscillator
(Eq. (8.3.1)). For the standard boundary conditions, ϕ˜(ql) −−−→ ql → ±∞
0, the exact eigen￾values and eigenfunctions are given by Eqs. (8.3.7, 8.3.8). Notice that the variable ql
is related to the radial variable, r ≥ 0 (Eq. (9.4.12)), and therefore obtains physically
meaningful values only for ql ≥ −r0(1+
ω
2
l
ω2
). From a mathematical point of view, how￾ever, extending ql to the range, −∞ ≤ ql ≤ ∞, has a negligible effect on eigenfunctions
for which

ϕ˜(ql)


2
is confined in a narrow range, |ql
| << r0(1 +
ω
2
l
ω2
). Since the latter
condition holds within our restriction to small amplitude vibrations (see Eqs. (9.4.8,
9.4.12)), the relevant vibration eigenfunctions are well approximated by the stand￾ard harmonic oscillator model. Using these solutions in the full Schrödinger equation
(Eq. (9.4.2)) for the nonrigid diatomic molecule (for ωl  ω), the eigenvalues are given
as
En,l = h¯ω

n+
1
2

+
h¯
2
l(l +1)
2µr
2
0

1−
ω
2
l
ω2

. (9.4.14)
The corresponding eigenfunctions are, ψn,l,m(r,θ,φ) = Yl,m(θ,φ)Rn,l(r), where the
radial functions, confined in a range |r −r0|  r0, obtain the form (Ex. 9.4.3)
Rn,l(r) =
1
r
µω
h¯π
1/4
r
1
n!2n
Hn
r
µω
h¯

r −r0(1+
ω
2
l
ω2
)
e
−µω
2h¯
(r−r0(1+
ω
2
l
ω2
))2
.
(9.4.15)
The coupling between vibration and rotation is apparent from the dependence of
the radial functions (Eq. (9.4.15)) on the angular quantum number. In particular, the
typical interatomic distance is shown to shift to larger values with increasing angular
momentum, r0 → r0(1 +
ω
2
l
ω2
) (see Ex. 9.4.4), which means that the interatomic bond
distance “stretches” with increasing angular momentum. This is indeed expected, owing
to the centrifugal force.
Exercise 9.4.3 Use the solutions of the Schrödinger equation for the harmonic oscillator
(Eqs. (8.3.1, 8.3.7, 8.3.8)), and change variables, to obtain Eqs. (9.4.14, 9.4.15).
Exercise 9.4.4 A nonrigid diatomic molecule is associated with a (normalized) sta￾tionary state, ψn,l,m(r,θ,φ) = Yl,m(θ,φ)Rn,l(r), where Rn,l(r) is given by Eq. (9.4.15).
Show that the average interatomic distance becomes larger with increasing angular
momentum quantum number, < rn,l >=
rπ
0
dθ
2
rπ
0
dφ
r∞
0
dr·r·r
2
sin(θ)|ψn,l,m(r,θ,φ)|
2 = r0
(1 +
ω
2
l
ω2
).(Notice that when the probability density is confined to a range where |r| <<
r0(1+
ω
2
l
ω2
), the boundaries of the radial integral can be changed: r∞
0
dr →
r∞
−∞
dr.)
Another remarkable effect of the vibration–rotation coupling is on the rotational
absorption spectrum. From Eq. (9.4.14) it follows that for l > 0, the energy level for
the nonrigid rotor is lower than the energy level for a rigid rotor, corresponding to the
same quantum number. Moreover, the decrease in energy is larger for a larger l (see
Fig. 9.4.1). This means that the energy spectrum of a nonrigid rotor is denser than
https://doi.org/10.1017/9781108877787.010 Published online by Cambridge University Press103 9.4 Beyond the Rigid Rotor Model: Vibration–Rotation Coupling
0
0
1
2
3
4
×104
10 20
I
EI [cm−1]
30 40 50 60
tFigure 9.4.1 Calculated rotational energy (El = E0,l −h¯ω/2) as a function of the rotation quantum number, l. The solid and
dashed lines correspond to a nonrigid and rigid rotor models, respectively. The parameters correspond to the diatomic
molecule H
35Cl (µ = 1.6×10−27 kg,r0 = 0.128 nm,ω = 5.4412×1014 rad/sec. The maximal
quantum number in the plot, l = 60, corresponds toω
2
l
/ω
2 = 0.2).
that of a rigid rotor, which is closely related to the effect of “bond stretching” (yet
another manifestation of a “quantum size effect”). Indeed, a larger radius means a
larger moment of inertia, and therefore a lower rotational excitation energy. In quanti￾tative terms, using Eq. (9.4.14) for the energy levels, the absorption wavelengths change
from that of a rigid rotor, Eq. (9.3.5), into (see Fig. 9.4.2)
1
λl
= 2B(1−
ω
2
l
ω2
)(l +1) ; l = 0,1,2,.... (9.4.16)
It follows that unlike for a rigid rotor, where the peaks are evenly spaced, for a nonrigid
rotor the distance between two successive absorption peaks decreases with increasing
l (see Ex. 9.4.5 and Fig. 9.4.2),
1
λl+1
−
1
λl
= 2B(1−
ω
2
l +2ω
2
l+1
ω2
). (9.4.17)
Exercise 9.4.5 Use the definition of the rotational frequency (Eq. (9.4.6)) and Eq.
(9.4.16) to derive Eq. (9.4.17).
The manifestations of the vibration–rotation coupling are shown to depend on the
ratio between the rotational frequency, ωl (defined in Eq. (9.4.6)) and the vibrational
frequency, ω. As ω
2
l
ω2 → 0, these manifestations are expected to vanish. First, the rota￾tional energy spectrum coincides with that of a rigid rotor, h¯
2
l(l+1)
2µr
2
0
(1−
ω
2
l
ω2
) → h¯
2
l(l+1)
2µr
2
0
https://doi.org/10.1017/9781108877787.010 Published online by Cambridge University Press104 Two-Body Rotation and Angular Momentum
0 100 200
1/λ [cm−1]
300 400
tFigure 9.4.2 Calculated rotational absorption wavelengths for the diatomic molecule, H
35Cl (see Fig.9.4.1for parameters). The
solid and dashed lines correspond to nonrigid and rigid rotor models, respectively.
(see Eq. (9.4.14). Second, Rn,l(r) becomes independent of the angular quantum num￾ber, as r0(1 +
ω
2
l
ω2
) → r0 (see Eq. (9.4.15)), which justifies a separable treatment of the
vibration and rotation degrees of freedom, as in the rigid rotor model (Section 9.3).
Notice that in the classical mechanical sense, ω
2
l
ω2 << 1 corresponds to a timescale
separation between the (slow) rotation and the (fast) vibration, where the rotation time
period (2π/ωl) exceeds by far the vibration time period (2π/ω). Using the definitions
of the rotational frequency (Eq. (9.4.6)), this condition corresponds to h¯
√
l(l+1)
µr
2
0
<< ω.
Recalling the definition of the typical vibrational absorption wave number, 1
λvib
=
ω
2πc
(see Eq. (8.4.3)), and the definition of a rotational constant, B ≡
h¯
4πcµr
2
0
(Eq. (9.3.5)),
this translates to
2B
p
l(l +1) <<
1
λvib
. (9.4.18)
Considering that for typical diatomic molecules the values of 1
λvib
are in the range of
∼ 1000 − 4000 cm−1
(see Section 8.4), whereas the values for B are in the range of
∼ 1 − 10 cm−1
(see Section 9.3), the limit in Eq. (9.4.18) is a reasonable approxima￾tion as long as the rotational quantum number l is not too large. This is also apparent
in Figs. 9.4.1 and 9.4.2. As already mentioned, the observed values of l are typically
limited by the thermal energy, such that the condition (Eq. (9.4.18)) is relevant for
most diatomic molecules in typical thermal conditions. While the rigid rotor model
provides a good approximation, effects of vibration–rotation coupling are also appar￾ent in experiments. These include, for example, the deviations from equally spaced
absorption spectral lines, as we have discussed, as well as other effects associated with
the anharmonicity of the interatomic potential energy function in real molecules. These
are left for further reading elsewhere.
https://doi.org/10.1017/9781108877787.010 Published online by Cambridge University Press105 Bibliography
Bibliography
[9.1] V. I. Arnold, “Ordinary Differential Equations” (Springer-Verlag, 2006).
[9.2] G. B. Arfken, H. J. Weber and F. E. Harris “Mathematical Methods for
Physicists” (Elsevier, 2013).
[9.3] J. M. Hollas, “Modern Spectroscopy,” 4th ed. (John Wiley & Sons, 2004).
[9.4] E. W. Weisstein, “Associated Legendre Polynomial.” From MathWorld –
A Wolfram Web Resource. Accessed at https://mathworld.wolfram.com/
AssociatedLegendrePolynomial.html
https://doi.org/10.1017/9781108877787.010 Published online by Cambridge University Press10 The Hydrogen-Like Atom
10.1 Rydberg’s Formula
Atoms, as originally conceived by the atomistic philosophers in ancient Greece, are the
“indivisible” building blocks of any known material. At the center of each atom there
is a positively charged nucleus, composed of protons and neutrons, where the number
of protons in the nucleus defines the chemical identity of each element. The nucleus is
surrounded by electrons, whose number (for an electrically neutral atom) equals the
number of protons. Recalling that the typical length scale (e.g., an effective radius) of
a single atom is of the order of 1 Å (0.1 nanometer), atomic resolution is necessary for
a full description of the structure and properties of matter on the nanoscale. Indeed,
a detailed account of the internal structure of atoms is essential for understanding
interatomic forces as well as binding between atoms to form molecules and extended
lattices, which further influence structure and reactivity of materials on the macro￾scopic length scale. In this chapter we start our discussion of the internal structure of
atoms, and particularly of the binding of electrons to the nucleus.
It turns out that the way electrons are bounded to atomic nuclei is strongly influenced
by the laws of quantum mechanics. The mere existence of an atom as a stable entity and
of its most basic properties, such as size (volume) and internal particle arrangement,
contradicts the laws of classical mechanics. In fact, the accumulation of experimental
evidence with respect to the internal structure of atoms was a cornerstone for formu￾lating quantum mechanics at the beginning of the twentieth century. Particularly, let
us focus here on a remarkable observation associated with the emission of electro￾magnetic radiation by atoms in a gas tube, following their electronic excitation by an
electric discharge. For hydrogen, for example, the emitted radiation appears in a set
of specific wavelengths (see Fig. 10.1.1), which fits an empirical formula proposed by
Johannes Rydberg [10.1]:
hc
λ
= RH

1
n
2
1
−
1
n
2
2

; n1 = 1,2,3,... ; n2 = n1 +1,n1 +2,.... (10.1.1)
This formula, with the constant (named after Rydberg) RH = 13.6 eV, strictly applies
to hydrogen atoms, but similar patterns emerge in the emission spectra of other excited
atoms [10.1].
The quest for the origin of these empirical findings in the late nineteenth century led
to an important breakthrough toward the formulation of quantum mechanics in the
106
https://doi.org/10.1017/9781108877787.011 Published online by Cambridge University Press107 10.2 The Stationary States of a Hydrogen-Like Atom
Ftigure 10.1.1 The emission spectral lines for hydrogen atoms according to the Rydberg formula.
year 1913, when Niels Bohr proposed his model for the atom. While the Bohr model
relied on classical mechanical equations of motion for the electron, emission of electro￾magnetic radiation by an accelerated charged particle was ignored, and additionally,
discretization (quantization) of angular momentum (resulting in energy quantization)
was assumed. The success of these additional assumptions in reproducing Rydberg’s
formula for the emission spectrum of hydrogen indeed accelerated the formulation
of quantum mechanics. The interested reader may learn more about Bohr’s model
elsewhere; here, we turn to the fully quantum mechanical treatment.
10.2 The Stationary States of a Hydrogen-Like Atom
The hydrogen-like atom is a two-particle system, composed of a single electron and a
nucleus containing Z protons. This strictly holds for the series of single-electron atoms
(or ions) H,He+,Li2+,... and so on. However, many-electron atoms and molecules can
sometimes be approximated (especially in electronically excited states) as hydrogen-like
atoms, when one of the electrons is located far from a positively charged core contain￾ing the nucleus (or nuclei), and from the rest of the electrons. Atoms or molecules of
the latter type are often referred to as “Rydberg atoms” or “Rydberg molecules” [10.2].
The electron and nucleus are associated with point charges −|e| and Z|e|, respec￾tively, where the two oppositely charged particles are coupled via the classical elec￾trostatic (Coulomb) force. Denoting the nucleus and the electron position vectors
as Rn and re, respectively, the potential energy is given by Coulomb’s law (where
K = 8.99×109 N·m2
·C
−2
is Coulomb’s constant in a vacuum):
V(Rn,re) = −KZe2
|Rn − re|
. (10.2.1)
Notice that relativistic spin-orbit coupling as well as the interaction of the electric
dipole with the vacuum state of the electromagnetic field (the Lamb shift [10.3], [10.4])
are ignored here. Inclusion of these effects would indeed lead to deviations from Ryd￾berg’s formula for the emission spectrum. Nevertheless, the latter are typically small on
the energy scale set by the electrostatic interactions and therefore observed only at high
https://doi.org/10.1017/9781108877787.011 Published online by Cambridge University Press108 The Hydrogen-Like Atom
resolution. Accordingly, a theory that accounts only for the electrostatic interactions
is sufficient for reproducing the emission spectra as captured by the simple Rydberg
formula.
Since the potential energy in Eq. (10.2.1) depends only on the absolute distance
between the two particles and not on their relative orientation, the hydrogen-like atom
is a two-body problem with a central potential, as discussed in Chapter 9 (see Fig. 9.1.1).
As in any two-body problem, we can focus on the relative electron–nucleus Hamilto￾nian independently from the atom center-of-mass Hamiltonian. The relative distance
and the center-of-mass coordinates are defined as
r ≡ re −Rn
R ≡
me
me +mn
re +
mn
me +mn
Rn
, (10.2.2)
with the corresponding reduced mass and total mass,
µ ≡
memn
me +mn
.
M ≡ me +mn.
(10.2.3)
Notice that the ratio between the nucleus and electron masses is considerably large.
Indeed, even for the smallest possible nucleus (corresponding to a single proton, in the
case of the hydrogen atom) this ratio is mn/me ≈ 1.8×103
. This means that the reduced
mass associated with the relative electron–nucleus Hamiltonian approximately equals
the (light) electron mass, µ ≈ me, whereas the center-of-mass Hamiltonian corresponds
to the (heavy) nucleus mass, M ≈ mn. It follows that the relative motion can be identified
(approximately) with the motion of the electron around a fixed nucleus.
Using spherical coordinates for the relative position vector, r = (r,θ,φ), the quantum
Hamiltonian that corresponds to the relative electron–nucleus system in a hydrogen￾like atom reads (see Eqs. (9.1.3–9.1.6) for any central potential)
Hˆ =
−h¯
2
2µ

∂
2
∂ r
2
+
2
r
∂
∂ r

+
−KZe2
r
+
Lˆ 2
2µr
2
, (10.2.4)
where Lˆ 2
is the angular momentum operator. The properties of the atom are captured
in the set of energy levels and corresponding stationary solutions to the Schrödinger
equation
Hˆψ(r,θ,φ) = Eψ(r,θ,φ). (10.2.5)
As for any central potential, the solutions (ψ(r,θ,φ)) obtain a universal angular
dependence, corresponding to the spherical harmonics (Yl,m(θ,φ); see Eq. (9.2.29)):
ψ(r,θ,φ) = R(r)Yl,m(θ,φ). (10.2.6)
The quantum numbers l and m are associated, respectively, with the relative angular
momentum (Lˆ 2
) and its projection of the z-axis, (Lˆ
z), and are subject to the following
constraints (see Eqs. (9.2.30, 9.2.31)):
l = 0,1,2,.... ; m = −l,−l +1,...,0,...,l −1,l. (10.2.7)
https://doi.org/10.1017/9781108877787.011 Published online by Cambridge University Press109 10.2 The Stationary States of a Hydrogen-Like Atom
The radial equation for R(r) (Eq. (9.1.11)) is obtained from the full Schrödinger equa￾tion (Eq. (10.2.5)) by using explicitly Eq. (10.2.4) for the Hamiltonian, and Eq. (10.2.6)
for the wave functions. This yields for any angular quantum number, l, the following
radial equation:

−h¯
2
2µ

∂
2
∂ r
2
+
2
r
∂
∂ r

+
−KZe2
r
+
h¯
2
l(l +1)
2µr
2

R(r) = ER(r), (10.2.8)
where the angular quantum number appears in the differential operator through the
radial centrifugal potential, h¯
2
l(l+1)
2µr
2
. The radial equation can be simplified by defining
χ(r) ≡ rR(r). (10.2.9)
Substitution in Eq. (10.2.8) readily yields an equation for χ(r) (see Ex. 9.4.1 for a
similar transformation):
−h¯
2
2µ
∂
2
∂ r
2
χ(r) +
−KZe2
r
+
h¯
2
l(l +1)
2µr
2

χ(r) = Eχ(r). (10.2.10)
It is convenient at this point to change variables, χ(r) = Φ(ρ), where ρ is a dimension￾less position variable,
ρ =
µe
2K
h¯
2
r. (10.2.11)
(Approximating the reduced electron–nucleus mass by the electron mass, Eq. (10.2.11)
reads ρ = r/a0, where a0 =
h¯
2
mee
2K
= 0.05292 nm is the known Bohr radius). In the new
variable, the radial equation reads (see Ex. 10.2.1)
∂
2
∂ ρ
2
Φ(ρ) + [2Z
ρ
−
l(l +1)
ρ
2
]Φ(ρ) = λ
2Φ(ρ), (10.2.12)
where the energy is associated with a dimensionless variable,
−λ
2 ≡
2h¯
2
µe
4K2
E. (10.2.13)
Notice that by associating the energy, E, with a negative value (−λ
2
) we restrict the
discussion below to the bound states of the electron–nucleus system. These states are
associated with a total energy smaller than the asymptotic potential energy, such that
the distribution of the relative electron–nucleus distances is confined to finite values.
Since the Coulomb potential energy vanishes asymptotically, V(Rn, re) → 0 as r → ∞
(see Eq. (10.2.1)); the bound states are therefore associated with negative energy levels.
Exercise 10.2.1 Use the definitions of the dimensionless variables (Eqs. (10.2.11,
10.2.13)) to derive Eq. (10.2.12) from Eq. (10.2.10).
We seek proper eigenfunctions of Eq. (10.2.12) and their corresponding eigenvalues.
The proper solutions are subject to a normalization condition,
w
2π
0
dφ
wπ
0
dθ
w∞
0
drr2
sin(θ)|ψ(r,θ,φ)|
2 = 1. (10.2.14)
https://doi.org/10.1017/9781108877787.011 Published online by Cambridge University Press110 The Hydrogen-Like Atom
Using Eqs. (10.2.6, 10.2.9, 10.2.11), this translates to the following condition on the
radial function, Φ(ρ):
w∞
0
dρ|Φ(ρ)|
2 =
1
a0
, (10.2.15)
which means that Φ(ρ) must vanish asymptotically,
Φ(ρ) −−→ρ → ∞
0. (10.2.16)
At the origin it is sufficient that Φ(ρ) does not diverge, fulfilling the normalization
condition, Eq. (10.2.15). However, a more stringent restriction is needed to assure con￾tinuity of the radial probability density function (namely, |R(r)|
2
r
2
) toward vanishing
in the nonphysical coordinate regime, ρ < 0 (namely, r < 0). We therefore seek for
solutions that vanish also at the origin,
Φ(ρ) −→ρ → 0
0. (10.2.17)
We now notice that Eq. (10.2.12) is an ordinary second-order differential equation [9.1]
with a regular singular point at the origin. Therefore, it has power series solutions in
the form Φ(ρ) = ρ
s
∞
∑
k=0
akρ
k
, where Eq. (10.2.17) holds only for s > 0. The solution
must also satisfy the asymptotic condition at ρ → ∞, where Eq. (10.2.12) takes the
form ∂
2
∂ ρ
2 Φ(ρ) → λ
2Φ(ρ). It can be readily verified that this restricts the power series
solutions to the form Φ(ρ) = ρ
s
e
±λ ρ Pq(ρ), where s is finite, and Pq(ρ) =
q
∑
k=0
a
(q)
k
ρ
k
is a
polynomial of a finite degree, q (see Ex. 10.2.2). Excluding the asymptotically diverging
solutions associated with e
+λ ρ
, the proper solutions, which satisfy the two boundary
conditions (Eqs. (10.2.16, 10.2.17)), are of the form
Φ(ρ) = e
−λ ρ ρ
s
q
∑
k=0
a
(q)
k
ρ
k
. (10.2.18)
Substituting Eq. (10.2.18) in Eq. (10.2.12) and shifting the series index, we obtain
closed equations for the coefficients {a
(q)
k
} of each q-degree polynomial (Ex. 10.2.3),
q
∑
k=0
[(s+k)(s+k −1)−l(l +1)]a
(q)
k
ρ
s+k−2 =
q+1
∑
k=1
2[λ(s+k −1)−Z]a
(q)
k−1
ρ
s+k−2
.
(10.2.19)
Exercise 10.2.2 Show that the functions χ(y) = e
±λ ρ ρ
p
satisfy the asymptotic radial
equation for the hydrogen-like atom, namely, ∂
2
∂ ρ
2 Φ(ρ) −−→ρ → ∞
λ
2Φ(ρ), for any nonnegative
finite power, p, and use it to show that Φ(ρ), defined in Eq. (10.2.18), is a solution to this
equation.
Exercise 10.2.3 Derive Eq. (10.2.19), using Eqs. (10.2.12, 10.2.18).
Comparing the coefficients of ρ
k
for any k in Eq. (10.2.19), we obtain
https://doi.org/10.1017/9781108877787.011 Published online by Cambridge University Press111 10.2 The Stationary States of a Hydrogen-Like Atom
[s(s−1)−l(l +1)]a
(q)
0 = 0 ; k = 0,
a
(q)
k =
2[λ(s+k−1)−Z]
(s+k)(s+k−1)−l(l+1)
a
(q)
k−1
; 1 ≤ k ≤ q,
[λ(s+q)−z]a
(q)
q = 0 ; k = q+1.
(10.2.20)
Notice that a proper solution, Φ(ρ), must be associated with a
(q)
0
6= 0. (Otherwise, the
recursion relation means that all the coefficients, a
(q)
0
,a
(q)
1
,a
(q)
2
,...,a
(q)
q , vanish, and
Φq(ρ) = 0.) It therefore follows from the first condition that s(s − 1) = l(l + 1). The
(only) positive value of s (that assures consistency with Eq. (10.2.17)) is
s = l +1. (10.2.21)
Additionally, a
(q)
q 6= 0 for a qth-degree polynomial. Therefore, the third condition in
Eq. (10.2.20) means that λ(q + s) = Z. Recalling that q = 0,1,2,... stands for the
polynomial degree, and using Eq. (10.2.21), it is useful to define a new integer index,
n ≡ q+s = q+l +1, (10.2.22)
where
Z = λn. (10.2.23)
Using the relation of λ to the energy (Eq. (10.2.13)), we can readily identify the set of
eigenvalues of the Hamiltonian Eq. (10.2.4) for the hydrogen-like atom:
En = −
µe
4K
2
2h¯
2
Z
2
n
2
; n = l +1,l +2,.... (10.2.24)
Approximating the reduced electron–nucleus mass by the electron mass me (see
Eq. (10.2.3)), the energy levels of a hydrogen-like atom are given as En = −RH
Z
2
n
2
, where
the constant
RH =
mee
4K
2
2h¯
2 = 13.6 eV (10.2.25)
is identified as the experimentally known Rydberg’s constant.
According to this quantum mechanical result, the specific lines (wavelengths) appear￾ing in the emission spectrum of a hydrogen-like atom (Eq. (10.1.1)) are associated
with transitions between stationary states of the atom, induced by (weak) coupling to
the radiation field. Using Planck’s formula (Eq. (5.2.2); also, see Chapters 18 for a
detailed discussion of field-induced transitions), each transition ni → nf corresponds
to a particular radiation wavelength,
hc
λni
,nf
= Eni −Enf = −RHZ
2
 
1
n
2
i
−
1
n
2
f
!
; nf < ni
; nf = 1,2,.... (10.2.26)
In Fig. 10.2.1, two series of emission spectral lines, corresponding to transitions from
excited electronic states into the ground (nf = 1) and into the first excited (nf = 2)
states, are illustrated.
https://doi.org/10.1017/9781108877787.011 Published online by Cambridge University Press112 The Hydrogen-Like Atom
E (eV)
−14
−12
−10
−8
−6
−4
−2
0
Ftigure 10.2.1 Emission spectral lines for a hydrogen-like atom, according to the quantum model.
The two quantum numbers, n and l, therefore define a proper solution to the radial
equation. Using Eqs. (10.2.21–10.2.23) in Eq. (10.2.18), the solutions obtain the form
Φn,l(ρ) = e
−Zρ/n
ρ
l+1
n−l−1
∑
k=0
a
(n,l)
k
ρ
k
, (10.2.27)
where the polynomial coefficients, {a
(n,l)
k
}, defined by the recursion relation, Eq.
(10.2.20), can be calculated explicitly using Eqs. (10.2.21–10.2.23) (see Ex. 10.2.4):
a
(n,l)
k =

−
2Z
n
k
(n−l −1)!(2l +1)!
(n−l −1−k)!(2l +1+k)!k!
a
(n,l)
0
. (10.2.28)
The radial solutions can be expressed compactly in terms of the known associated
Laguerre polynomials [10.5], defined as
L
p
q
(ξ ) ≡
q
∑
k=0
(−1)
k
(p+q)!
(q−k)!(p+k)!k!
ξ
k
. (10.2.29)
Identifying q = n − l − 1 and p = 2l + 1 in Eqs. (10.2.27, 10.2.28), it follows that (see
Ex. 10.2.5)
Φn,l(ρ) = cn,le
−Zρ/n
ρ
l+1L
2l+1
n−l−1

2Z
n
ρ

, (10.2.30)
where cn,l = a
(n,l)
0
(n − l − 1)!(2l + 1)!/(l + n)!. Notice that the constant a
(n,l)
0
can be
selected to assure the normalization condition, Eq. (10.2.15). Using the property of the
associated Laguerre polynomials [10.5], r ∞
0
e
−x
x
p+1
[L
p
q (x)]2dx = (2q+ p+1)(q+ p)!/q!,
https://doi.org/10.1017/9781108877787.011 Published online by Cambridge University Press113 10.2 The Stationary States of a Hydrogen-Like Atom
ψ1,0,0(r,θ,φ) = s
Z
3
πa
3
0
e
−Zr/a0
ψ2,0,0(r,θ,φ) = 1
8
s
2Z
3
πa
3
0
(2−
Z
a0
r)e
−rZ/2a0
ψ2,1,0(r,θ,φ) = 1
8
s
2Z
5
πa
5
0
re−rZ/2a0 cos(θ)
ψ2,1,1(r,θ,φ) = 1
8
s
Z
5
πa
5
0
re−rZ/2a0
sin(θ)e
iφ
ψ2,1,−1(r,θ,φ) = 1
8
s
Z
5
πa
5
0
re−rZ/2a0
sin(θ)e
−iφ
ψ3,0,0(r,θ,φ) = 1
81s
Z
3
3πa
3
0
(27−18
Z
a0
r +2
Z
2
a
2
0
r
2
)e
−Zr/3a0
ψ3,1,0(r,θ,φ) = 1
81s
2Z
5
πa
5
0
r(6−
Z
a0
r)e
−Zr/3a0 cos(θ)
ψ3,1,1(r,θ,φ) = 1
81s
Z
5
πa
5
0
r(6−
Z
a0
r)e
−Zr/3a0
sin(θ)e
iφ
ψ3,1,−1(r,θ,φ) = 1
81s
Z
5
πa
5
0
r(6−
Z
a0
r)e
−Zr/3a0
sin(θ)e
−iφ
ψ3,2,0(r,θ,φ) = 1
81s
Z
7
6πa
7
0
r
2
e
−Zr/3a0
(3 cos2
(θ)−1)
ψ3,2,1(r,θ,φ) = 1
81s
Z
7
πa
7
0
r
2
e
−Zr/3a0
sin(θ) cos(θ)e
iφ
ψ3,2,−1(r,θ,φ) = 1
81s
Z
7
πa
7
0
r
2
e
−Zr/3a0
sin(θ) cos(θ)e
−iφ
ψ3,2,2(r,θ,φ) = 1
162s
Z
7
πa
7
0
r
2
e
−Zr/3a0
sin2
(θ)e
2iφ
ψ3,2,−2(r,θ,φ) = 1
162s
Z
7
πa
7
0
r
2
e
−Zr/3a0
sin2
(θ)e
−2iφ
Ftigure 10.2.2 A list of some low-energy eigenfunctions of the hydrogen-like atom Hamiltonian
this yields cn,l =
qZ(n−l−1)!
a0n
2(n+l)!
￾
2Z
n
l+1
. Returning to the original radial-coordinate vari￾able, Φn,l(ρ) = χn,l(r) = rRn,l(r), we obtain (Ex. 10.2.6)
Rn,l(r) =
s
4Z
3(n−l −1)!
a
3
0
n
4(n+l)!

2Zr
na0
l
e
−Zr
na0 L
2l+1
n−l−1

2Zr
na0

. (10.2.31)
https://doi.org/10.1017/9781108877787.011 Published online by Cambridge University Pres114 The Hydrogen-Like Atom
Exercise 10.2.4 The radial wave functions for a hydrogen-like atom are of the form
Φn,l(ρ) = e
−Zρ/nρ
l+1
n−l−1
∑
k=0
a
(n,l)
k
ρ
k
. The polynomial coefficients, {a
(n,l)
k
}, are defined by
the recursion relation, Eq. (10.2.20). Use Eqs. (10.2.21–10.2.23) and derive the explicit
expression for these coefficients, Eq. (10.2.28).
Exercise 10.2.5 Use Eqs. (10.2.27, 10.2.28) for the radial wave functions of the
hydrogen-like atom, and Eq. (10.2.29) for the associated Laguerre polynomials, to derive
Eq. (10.2.30).
Exercise 10.2.6 Use the normalization condition (Eq. (10.2.15)) to normalize the
radial function given by Eq. (10.2.30), and change variables to obtain Rn,l(r) in Eq.
(10.2.31).
Finally, the three-dimensional stationary wave functions corresponding to the
hydrogen-like atom, as defined in Eqs. (10.2.5, 10.2.6), are given as
ψn,l,m(r,θ,φ) = Rn,l(r)Yl,m(θ,φ). (10.2.32)
In Fig. 10.2.2, the wave functions corresponding to some of the smallest quantum
numbers are given explicitly, and in Fig. 10.2.3 some functions are plotted for illus￾tration along a one-dimensional cut through the three-dimensional space, on top of
the underlying coulomb potential energy.
Let us highlight here some general properties of the set of hydrogen-like atom
eigenfunctions { ψn,l,m}:
Ftigure 10.2.3 Stationary wave functions,ψn,l,m(x, y,z), for the hydrogen-like atom (for Z = 1), represented along a
one-dimensional cut through the three-dimensional space,ψn,l,m(x,0,0). The four functions associated with the
lowest energy levels are displaced from each other by the respective energy differences. The corresponding Coulomb
potential energy curve,V(x,0,0), is plotted (thick line) for reference.
https://doi.org/10.1017/9781108877787.011 Published online by Cambridge University Press115 10.2 The Stationary States of a Hydrogen-Like Atom
I. Each function,ψn,l,m(r,θ,φ), is characterized by three different quantum numbers.
These quantum numbers are subject to the following restrictions (see Eqs. (9.2.27,
10.2.22, 10.2.24)), derived from the requirement for proper wave functions:
n = 1,2,3...,
l = 0,1,2,...,n−1,
m = −l,−l +1,...,0,...,l −1,l.
(10.2.33)
II. Each function, ψn,l,m(r,θ,φ), is a common eigenfunction of three commuting
operators (Ex. 10.2.7),
Hˆψn,l,m(r,θ,φ) = −RHZ
2
n
2
ψn,l,m(r,θ,φ),
Lˆ
2ψn,l,m(r,θ,φ) = h¯
2
l(l +1)ψn,l,m(r,θ,φ),
Lˆ
zψn,l,m(r,θ,φ) = mh¯ψn,l,m(r,θ,φ),
(10.2.34)
where Hˆ = [
−h¯
2
2µ
(
∂
2
∂ r
2 +
2
r
∂
∂ r
)+ −KZe2
r +
Lˆ 2
2µr
2
] is the hydrogen-like atom Hamiltonian,
and Lˆ 2
, Lˆ
z are the corresponding angular momentum operators. The quantum
numbers n, l, and m define uniquely the eigenvalues of Hˆ, Lˆ 2
, and Lˆ
z
, namely,
−RHZ
2/n
2
, h¯
2
l(l + 1), and mh¯, respectively. They are commonly referred to as
the main (or principal) quantum number (n), the angular momentum quantum
number (l), and the magnetic quantum number (m).
III. The set of functions {ψn,l,m(r,θ,φ)} is an orthonormal set:
w
2π
0
dφ
wπ
0
sin(θ)dθ
w∞
0
r
2
drψ
∗
n
0
,l
0
,m0(r,θ,φ)ψn,l,m(r,θ,φ) = δn,n
0δl,l
0δm,m0. (10.2.35)
IV. Degeneracy: For any quantum number, n, there are n
2 degenerate eigenfunctions
of Hˆ, corresponding to the same eigenvalue, En = −RHZ
2/n
2
. The different func￾tions correspond to all the different combinations of the quantum numbers, l and
m, associated with the given n, where l takes on the values, 0,1,...,n−1, and the
number of m-values for each l is 2l +1 (see Ex. 10.2.8).
V. In atomic physics and chemistry, the set {ψn,l,m} is often replaced by an alterna￾tive orthonormal set of real-valued functions, which are linear combinations of
degenerate ψn,l,m, associated with the same n and l (see Figs. 10.2.4, 10.3.2). Each
real-valued function is denoted by the principal quantum number, n, followed by
a letter that corresponds to the angular quantum number (s, p,d, f,g,h,... mark,
respectively, l = 0,1,2,3,4,5,....), and a function in Cartesian variables that rep￾resents the angular dependence of the function. For example, ψ3dxz
corresponds to
n = 3, l = 2, and an angular function, proportional to x ·z = cos(θ)sin(θ) cos(φ).
The letters, s, p,d are reminiscent of the historical names given to the spectral lines
for the corresponding electronic transitions: Sharp, Principal, and Diffused.
Exercise 10.2.7 Show that the three operators, Lˆ
z
, Lˆ 2
, and the hydrogen-like atom Ham￾iltonian commute with each other. Prove that these three operators have a set of joint
eigenfunctions (use Eq. (10.2.32)).
https://doi.org/10.1017/9781108877787.011 Published online by Cambridge University Press116 The Hydrogen-Like Atom
ψ1s ψ1,0,0 R1,0(r)Y0,0 ≡ = (θ,ϕ)
ψ2s ψ2,0,0 R2,0(r)Y0,0 ≡ = (θ,ϕ)
ψ2pz
ψ2,1,0 R2,1(r)Y1,0 ≡ = (θ,ϕ)
ψ3s ψ3,0,0 R3,0(r)Y0,0 ≡ = (θ,ϕ)
ψ3pz
ψ2,1,0 R2,1(r)Y1,0 ≡ = (θ,ϕ)
ψ3dz 2
ψ3,2,0 R3,2(r)Y2,0 = = (θ,ϕ)
ψ2px
1 (ψ2,1,1+ψ2,1,−1) R2,1(r)[Y1,1(θ,ϕ)+Y1,−1 ≡ = (θ,ϕ)] √2
1
√2
ψ2py
1 (ψ2,1,1−ψ2,1,−1) R2,1(r)[Y1,1(θ,ϕ)−Y1,−1 ≡ = (θ,ϕ)] √2
1
√2
ψ3px
1 (ψ3,1,1+ψ3,1,−1) R3,1(r)[Y1,1(θ,ϕ)+Y1,−1 ≡ = (θ,ϕ)] √2
1
√2
ψ3dxz
1 (ψ3,2,1+ψ3,2,−1) R3,2(r)[Y2,1(θ,ϕ)+Y2,−1 = = (θ,ϕ)] √2
1
√2
ψ3py
1 (ψ3,1,1−ψ3,1,−1) R3,1(r)[Y1,1(θ,ϕ)−Y1,−1 ≡ = (θ,ϕ)] √2
1
√2
ψ3dyz
1 (ψ3,2,1−ψ3,2,−1) R3,2(r)[Y2,1(θ,ϕ)−Y2,−1 = = (θ,ϕ)] √2
1
√2
ψ3dx 2−y 2
1 (ψ3,2,2+ψ3,2,−2) R3,2(r)[Y2,2(θ,ϕ)+Y2,−2 = = (θ,ϕ)] √2
1
√2
ψ3dxy
1 (ψ3,2,2−ψ3,2,−2) R3,2(r)[Y2,2(θ,ϕ)−Y2,−2 = = (θ,ϕ)] √2
1
√2
Figure 10.2.4 t A list of real-valued eigenfunctions of the hydrogen-like atom Hamiltonian
Exercise 10.2.8 Show that the energy levels of a hydrogen-like atom, En = −RHZ
2/n
2
,
are n
2
-fold degenerate. (Notice that,
n−1
∑
l=0
(2l +1) = n
2
.)
The probability distribution functions for the vector of relative position between the
electron and the nucleus in a hydrogen-like atom in its stationary states are discussed
in the following section.
10.3 Probability Density Distributions and Atomic Orbitals
The stationary solutions to the Schrödinger equation for a hydrogen-like atom ena￾ble us to address directly a fundamental question relating to atoms in general and to
hydrogen-like atoms in particular: What is the size (volume) of an atom? This ques￾tion does not have a unique answer, to the best of our current knowledge, since the
laws of quantum mechanics state that the relative positions of the electron and the
nucleus cannot be defined deterministically. Nevertheless, a closely related question
can be answered quite accurately (at least for a hydrogen-like atom) on the basis of
solutions to the Schrödinger equation: Given an atom in a stationary state, what is the
https://doi.org/10.1017/9781108877787.011 Published online by Cambridge University Press117 10.3 Probability Density Distributions and Atomic Orbitals
g(θ,ϕ)
z
x
y
θ
ϕ
Ftigure 10.3.1 Representing an angular distribution function, g(θ,φ), by a vector of length, g(θ,φ), pointing in the direction set
by the angles, θ and φ.
probability density for finding the electron and the nucleus at a relative position vector r
= (r,θ,φ)?It is customary to represent a probability density function, ρ(r) = ρ(r,θ,φ),
by considering separately its angular and radial dependencies.
Angular Distributions
For representation of an angular probability density distribution, each pair of angles
(θ,φ) is associated with a vector in the direction defined by θ and φ (see Fig. 10.3.1),
whose length is proportional to ρ(r,θ,φ) for some fixed value of the radial coordi￾nate, r = r0. Notice that the stationary atomic wave functions discussed in Section
10.2 are products of radial and angular functions (see Fig. 10.2.4), ρ(r0,θ,φ) =
|Rn,l(r0)|
2gl(θ,φ), such that the choices of r0 as well as the quantum number n affect
only the prefactor, |Rn,l(r0)|
2
, which does not bear any information regarding the angu￾lar distribution. The shape of the angular distribution function is therefore encoded in
the function, gl(θ,φ). Each angular quantum number, l, corresponds to 2l +1 differ￾ent angular distributions, corresponding to degenerate spherical harmonics, gl(θ,φ) =
|Yl,m(θ,φ)|
2
, or their linear combinations, gl(θ,φ) = |∑
l
m=−l
cmYl,m(θ,φ)|
2
.
In Fig. 10.3.2 angular distributions (gl(θ,φ)) are plotted for some real-valued sta￾tionary solutions, associated with l = 0,1,2 (see Fig. 10.2.4). As we can see, the shape
of the angular distribution function changes with the angular quantum number, l.
Particularly, as l increases, the number of nodal surfaces in the angular distribution
increases. The orbitals of type s, p, and d are associated, respectively, with zero, one,
and two nodal surfaces on which the probability density vanishes, as reflected in the
changes of the sign of the wave function.
Radial Distributions
We now change focus and discuss the radial probability distributions. Specifically,
we wish to answer the following question: Given an atom in a stationary state,
what is the probability density for finding the electron and the nucleus at a relative
https://doi.org/10.1017/9781108877787.011 Published online by Cambridge University Press118 The Hydrogen-Like Atom
Ftigure 10.3.2 Angular distribution functions for a hydrogen-like atom, corresponding tol = 0,1,2. The different shades in each
plot add information corresponding to changes in the sign of the wave function, for which the probability density is
presented.
distance, r, regardless of their relative spatial orientation (θ,φ)? The answer is given
by recalling the normalization condition for any proper solutions, Eq. (10.2.14),
r∞
0
dr
2
rπ
0
dφ
rπ
0
dθr
2
sin(θ)|ψ(r,θ,φ)|
2 = 1. We can readily rewrite this equation as
w∞
0
ρ(r)dr = 1, (10.3.1)
where the radial distribution function, ρ(r), is defined as
ρ(r) ≡ r
2
w
2π
0
dφ
wπ
0
dθ sin(θ)|ψ(r,θ,φ)|
2
. (10.3.2)
Since the stationary atomic wave functions of a hydrogen-like atom are prod￾ucts of (normalized) angular and radial functions (see Fig. 10.2.4), |ψ(r,θ,φ)|
2 =
|Rn,l(r)|
2gl(θ,φ), the radial probability distribution depends only on the principal and
angular quantum numbers (n and l) and is of the form
https://doi.org/10.1017/9781108877787.011 Published online by Cambridge University Press119 10.3 Probability Density Distributions and Atomic Orbitals
ρn,l(r) = r
2
|Rn,l(r)|
2
. (10.3.3)
In Fig. 10.3.3 radial distributions are plotted for different stationary states, {ψn,l,m}.
The different functions correspond to different values of the principal quantum num￾ber, n = 1,2,3, where the angular and magnetic numbers, l = 0 and m = 0, are the same.
The most apparent observation is that the radial probability density spreads toward
larger values of the electron–nucleus relative distance as n increases (and accordingly
the energy, En = −RHZ
2/n
2
, increases). Another observation is that the number of
nodes in the radial probability density increases with increasing quantum number,
n, and therefore with increasing energy, En. This behavior is reminiscent of the trend
observed in solutions of the Schrödinger equation for one-dimensional model Hamil￾tonians (see Chapters 5 and 8). Here the number of nodes equals n−1, which reflects
the degree of the associated Laguerre polynomial, L
1
n−1
(
2Zr
na0
) (see Eq. 10.2.31).
The correlation between increasing energy and increasing electron–nucleus distance
is expected on classical mechanics grounds, where the Coulomb law associates a larger
relative distance between the oppositely charged electron and nucleus with a higher
energy. This correlation was also the basis for the historical Bohr model for the hydro￾gen atom. In that model the set of discrete energy levels of the electron in the atom,
En = −RHZ
2/n
2
, were associated with circulating orbits of the electron around the
nucleus, each having a radius, rn = a0n
2/Z. Remarkably, the same qualitative trend
is obtained in quantum mechanics for the average electron–nucleus distance, which
reads hrin =
3a0n
2
2Z
(for zero angular momentum); but the important difference is that
in Bohr’s model each energy level corresponds to a deterministic electron–nucleus dis￾tance, which is the radius of a circular orbit, whereas in quantum mechanics, the
distance is defined only probabilistically. The state of the electron is associated with
an “orbital” rather than with a classical orbit. An orbital in the hydrogen-like atom is
the quantum mechanical wave function, which defines the probability density for finding
the electron and nucleus in any relative distance. In general, the term orbital is often used
in atomic, molecular, and solid-state physics for describing any single-electron quantum
mechanical wave function (see Chapters 13 and 14).
Ftigure 10.3.3 Radial distribution functions, ρn,l(r), for a hydrogen-like atom (Z = 1), corresponding tol = 0 and n = 1,2,3.
https://doi.org/10.1017/9781108877787.011 Published online by Cambridge University Press120 The Hydrogen-Like Atom
Exercise 10.3.1 Use Eqs. (10.3.3) and (10.2.31) for the radial probability distribution
to show that (a) the most probable relative distance between the electron and the nucleus
in the ground state of a hydrogen-like atom is r = a0/Z; (b) the probability for finding
the electron and the nucleus at any distance in the range, 0 < r < γ
a0
Z
, equals P(γ) =
1−e
−2γ
(2γ
2 +2γ +1) (you can use the identity r∞
x
dyy2
e
−αy =
d
2
dα2
r∞
x
dye−αy).
The “effective volume” of the hydrogen-like atom can be estimated by considering
the radial probability density associated with the ground state, ψ1,0,0(r,θ,φ). The most
probable distance between the electron and the nucleus in this state is r = a0/Z (see
Ex. 10.3.1), which defines a sphere with a volume, V = 4πa
3
0
/(3Z
3
). For Z = 1, which
corresponds, for example, to the hydrogen atom itself, r = 0.5292 Å, and the corre￾sponding volume equals 0.62 cubic Å. Notice, however, that this sphere is too small to
account for the volume of the atom, since there is a substantial probability of finding
the relative electron–nucleus distance outside this sphere. It turns out that this sphere
accounts only for ∼ 32% of all possible electron–nucleus distances (see Ex. 10.3.1).
Clearly, the sphere volume needs to be extended to infinity to include any accessible
relative distance. However, a substantial portion of the possible distances (∼ 94%)
is contained in a sphere of a radius that is three times larger, r = 3a0 ≈ 1.6 Å (see
Ex. 10.3.1), defining an effective volume of 16.8 cubic Å.
Let us turn now to discussing the effect of the angular quantum number, l, on the
radial distributions. Figure 10.3.4 demonstrates that the probability density distribu￾tion of the relative electron–nucleus distances does depend on l; but the changes in
the distribution are mild in comparison to the changes associated with the principal
quantum number, n. In particular, the changes in the most probable electron–nucleus
distance as l changes are relatively mild (compare to Fig. 10.3.3). Nevertheless, an
important effect is the decrease in the number of nodes in the radial distribution
with increasing angular quantum number, l. Notice that the number of nodes equals
n−l −1, whereas the number of angular nodal surfaces is equal to l. Since each node
Ftigure 10.3.4 Radial distribution functions, ρn,l(r), for a hydrogen-like atom (Z = 1), corresponding to n = 3 andl = 0,1,2.
https://doi.org/10.1017/9781108877787.011 Published online by Cambridge University Press121 Bibliography
in the radial distribution defines a surfaces of a sphere on which the wave function
vanishes (and changes sign), the overall number of nodal surfaces equals n−1 and is
therefore correlated with the energy, En, as we have already mentioned in discussing
other quantum systems (see Chapters 5 and 8).
Bibliography
[10.1] J. R. Rydberg, “On the structure of the line-spectra of the chemical elements,”
The London, Edinburgh, and Dublin Philosophical Magazine and Journal of
Science 29, 331 (1890).
[10.2] C. H. Greene, A. S. Dickinson and H. R. Sadeghpour, “Creation of polar and
nonpolar ultra-long-range Rydberg molecules,” Physical Review Letters 85,
2458 (2000).
[10.3] W. E. Lamb, Jr and R. C. Retherford, “Fine structure of the hydrogen atom by
a microwave method,” Physical Review 72, 241 (1947).
[10.4] H. A. Bethe, “The electromagnetic shift of energy levels,” Physical Review 72,
339 (1947).
[10.5] E. W. Weisstein, “Associated Laguerre Polynomial.” From MathWorld –
A Wolfram Web Resource. Accessed at https://mathworld.wolfram.com/
AssociatedLaguerrePolynomial.html
https://doi.org/10.1017/9781108877787.011 Published online by Cambridge University Press11 The Postulates of Quantum Mechanics
11.1 A Summary of the Postulates
In the previous chapters we already encountered some of the postulates of quantum
mechanics. These postulates provide the needed guidelines for associating physically
measurable quantities of interest with mathematical objects. In Chapter 2, the state
of a closed physical system was associated with a proper, complex-valued, wave func￾tion, which contains all measurable information on the system, where the extension
of the wave functions description to open systems was given in Chapter 7. In Chap￾ter 3 we discussed the representation of measurable quantities in terms of mathematical
operators that are linear and Hermitian, and we saw how relations between physi￾cally measurable quantities (energy, angular momentum, position, momentum, etc.)
are associated with mathematical relations between the corresponding operators. In
Chapter 4 we discussed the Schrödinger equation, which associates the Hamiltonian
operator of a system with the time evolution of any physical state within this system.
We learned that the measured values in a single measurement on a single system can
only be eigenvalues of the operator that represents the measured physical quantity, and
therefore, when two operators share a common set of eigenfunctions (e.g., commut￾ing operators), the quantities that are represented by these operators can be defined
simultaneously.
In Chapters 6–10 we discussed solutions to the Schrödinger equation for simple
and yet most informative model Hamiltonians, which enable us to understand some
basic phenomena on the nanoscale. Many other phenomena, however, are beyond
the scope of exact solutions of the Schrödinger equation. To address these, the full
mathematical structure of quantum mechanics theory must be exploited. The pres￾ent chapter will be devoted to a rigorous formulation of the postulates of quantum
mechanics, and in the next chapter we will introduce some of the basic approximation
methods in quantum mechanics that are necessary for treating complex, many-particle
systems.
For the sake of continuity with the previous chapters, we shall first introduce the
postulates in the realm of wave functions, namely focusing on the position repre￾sentation. Then we shall generalize the formulation to the abstract Hilbert space of
quantum states, introducing Dirac’s notations. We chose to group the postulates into
four groups and to introduce them according to the following order: Postulate 1 deals
122
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press123 11.1 A Summary of the Postulates
with the mathematical representation of the physical state of a system in terms of a wave
function, and postulate 2 deals with the representation of measurable quantities in
terms of operators. Postulate 3 deals with the dynamics of the physical states, and pos￾tulate 4 deals with the consequences of a measurement of an observable (represented
by an operator) on a system (represented by a wave function).
Postulate 1: The state of a physical system is associated with a complex-valued wave
function, which contains all the measurable information on the system. This func￾tion depends on the coordinates of all the particles composing the system. Denoting
here the vector of all the particle-coordinates as r ≡ r1, r2, r3,..., the wave function is
denoted, ψ(r).
In a closed system, namely, where all the particles are bound within a finite region
in space, the wave function must be proper (square integrable), and its absolute square
value has the meaning of a probability density in the position space:
ψ
∗
(r)ψ(r) = |ψ(r)|
2 ≡ ρ(r). (11.1.1)
Here ρ(r)dr is the probability for locating the particles in the system in the spatial
arrangement defined by the position vector r, within an infinitesimal volume, dr. For a
proper wave function, the probability of finding the particles in any position in space can
be normalized to unity, such that
w
Vps
ρ(r)dr = 1. (11.1.2)
Here Vps is the volume of the entire physical space. The association of ρ(r) with
a probability density means that the wave function itself is interpreted as a prob￾ability amplitude and obtains physical dimensions, [ψ] = [r]
−1/2
. The information
content in the wave function with respect to the physical state of the system (e.g.,
the ratio between probabilities of finding the system at different spatial configura￾tions) is unchanged when ψ(r) is multiplied by a finite (complex) number. This means
that any proper wave function with a finite (nonzero) integral, r
Vps
ρ(r)dr ≡ c, can be
normalized by its multiplication with 1/
√
c. Detailed discussions as well as exercises
concerning the definition of probability densities, proper wave functions, and wave
function normalization in spaces of different dimensions can be found in Sections 2.1,
2.2, and 2.3.
When the system is open, for example, when particles are scattered through (enter
and / or leave)the physical space, the state of the physical system is still associated with a
wave function, ψ(r), but the latter is not necessarily proper. When the system is associ￾ated with an improper scattering wave function, probability conservation is formulated
in terms of probability fluxes, J(r), rather than densities, and reads
z
Sps
J(r)·dS = 0. (11.1.3)
Here, Sps is a surface surrounding the boundaries of the entire relevant physical space
(e.g., the interaction region in a scattering experiment [7.1]). The improper wave func￾https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press124 The Postulates of Quantum Mechanics
tions are conventionally normalized either to a specified incoming flux (see Chapter 7)
or to Dirac’s delta function, as discussed in Section 11.5. Examples of scattering wave
functions and their implementations were discussed in Chapter 7 of this book.
Notice that while the probabilistic interpretation of the wave function imposes some
necessary condition, such as Eqs. (11.1.2, 11.1.3), on ψ(r), these conditions are not suf￾ficient. The full set of constraints on “physically meaningful” wave functions accounts
also for their being solutions of the Schrödinger equation, to be discussed in what
follows.
Postulate 2: Dynamical variables are associated with operators. In particular, the posi￾tion (x) the momentum (px) of a particle along a given Cartesian axis are associated with
the operators, xˆ and pˆx, where
xˆψ ≡ xψ(x)
pˆxψ ≡ −ih¯
d
dx
ψ(x). (11.1.4)
In the three-dimensional space, the position and momentum are associated with the
vector operators,
rˆ ≡ (xˆ, yˆ,zˆ)
pˆ ≡ (pˆx, pˆy, pˆz). (11.1.5)
The position operator, rˆ, is a local operator in the position representation, namely,
its operation is well defined at each point in the coordinate space, rˆψ ≡ (x · ψ(r), y ·
ψ(r),z·ψ(r)). The momentum operator, pˆ, is a nonlocal (differential) operator in the
position representation. Its operation requires knowledge of the wave function also at
the vicinity of each point, pˆψ = −ih¯

∂ψ(r)
∂ x
,
∂ψ(r)
∂ y
,
∂ψ(r)
∂ z

= −ih¯∇ψ(r).
Other observables are represented as operators according to their relations to the
canonical position and momentum operators, as known from classical mechanics. Exam￾ples are:
The angular momentum of a particle, which is a vector operator,
Lˆ = rˆ ×pˆ = (yˆpˆz −zˆpˆy,zˆpˆx −xˆpˆz
, xˆpˆy −yˆpˆx). (11.1.6)
Scalar or vector potentials are represented in terms of the corresponding functions
of the canonical operators. For example, the operator that corresponds to the scalar
potential energy function of a particle,V(r), is a function of the local position operator,
Vˆ = V(xˆ, yˆ,zˆ). (11.1.7)
The kinetic energy of a particle of mass m is a scalar function of its momentum, T =
|p|
2
2m
, represented in terms of the nonlocal momentum operator,
Tˆ =
1
2m
pˆ ·pˆ =
1
2m
(pˆ
2
x + pˆ
2
y + pˆ
2
z
), (11.1.8)
where Tˆψ =
−h¯
2
2m

∂
2ψ(r)
∂ x
2 +
∂
2ψ(r)
∂ y
2 +
∂
2ψ(r)
∂ z
2

=
−h¯
2
2m
∆ψ(r).
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press125 11.1 A Summary of the Postulates
The Hamiltonian of classical mechanics [3.1], H = T +V, is represented as the sum of
the corresponding quantum mechanical operators,
Hˆ ≡ Tˆ +Vˆ . (11.1.9)
The generalization to many-particle systems is straightforward. Considering
a system of N particles with masses, m1,m2,...,mN, and respective coordi￾nates, r1, r2,..., rN, the potential and kinetic energy operators read Vˆ
r1,r2,...,rNψ =
V(r1, r2,..., rN)ψ(r1, r2,..., rN) and Tˆ
r1,r2,...,rNψ =
N
∑
i=1
−h¯
2
2mi
∆riψ(r1, r2,..., rN), respec￾tively. Detailed discussions as well as exercises concerning the definition of quantum
mechanical operators, functions of operators, and their properties can be found in
Chapter 3.
The operators representing dynamical variables share common properties. The two
of the most important ones are:
The operators are linear in the space of wave functions (see Section 3.1 for relevant
exercises). An operator Aˆ is linear in the space {ψ(r)}, if the following identity holds
for any two functions in the space, ψ1(r) and ψ2(r), and for any scalars, a1 and a2,
Aˆ(a1ψ1(r) +a2ψ2(r)) = a1Aˆψ1(r) +a2Aˆψ2(r). (11.1.10)
The operators are Hermitian (self-adjoint) in the space of wave functions (see Sec￾tions 4.5, 4.6 for relevant exercises). An operator Aˆ is Hermitian in the space {ψ(r)},
if the following identity holds for any two functions in the space, ψ1(r) and ψ2(r):
w
Vps
ψ
∗
1
(r)Aˆψ2(r)dr =


w
Vps
ψ
∗
2
(r)Aˆψ1(r)dr


∗
(11.1.11)
Hermitian operators are characterized by a set of real eigenvalues, and orthonormal
eigenfunctions. (See Section 4.6 for a detailed discussion.)
Postulate 3: The time evolution of a system is uniquely defined by its initial state and
its Hamiltonian operator. The equation of motion for the state of a system is the time￾dependent Schrödinger equation. Let ψ(r,t) represent the state of a system at any time,
t; then,
ih¯
∂
∂t
ψ(r,t) = Hˆψ(r,t). (11.1.12)
The time-dependent Schrödinger equation is a first-order differential equation in t,
which means that the wave function representing a system is uniquely defined at all times,
given that it is known at a certain point in time (i.e., an initial time, ψ(r,t)|t=0 = ψ0(r)).
The time-dependent Schrödinger equation is a homogeneous linear differential equa￾tion, h
Hˆ −ih¯
∂
∂t
i
ψ(r,t) = 0, from which follows the superposition principle: Any linear
combination of solutions is also a solution. Specifically, a solution to the Schrödinger
equation is defined only up to multiplication by a scalar constant. The constant
is conventionally chosen to impose normalization on the solution (Eq. (11.1.2) or
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press126 The Postulates of Quantum Mechanics
Eq. (11.1.3)). Since the Hamiltonian is a Hermitian operator, the normalization is
conserved at all times. (See Chapter 15 for a general proof.):
w
Vps
ψ
∗
(r,t)ψ(r,t)dr = 1 or z
Sps
J(r,t)·dS = 0. (11.1.13)
Notice that the Schrödinger equation imposes mathematical constraints on ψ(r, t),
in addition to the ones associated with its interpretation as a probability amplitude
(e.g., the normalization requirements, Eqs. (11.1.2, 11.1.3)). Specifically, the wave
function ψ(r,t) must be continuously differentiable with respect to any of the system
position variables. The time-dependent Schrödinger equation was already discussed in
Chapter 4 of this book. An extended discussion of quantum dynamics is given also in
Chapter 15.
Postulate 4: In a single measurement of an observable on a single system, the measured
value can only be an eigenvalue of the operator that represents the observable. The proba￾bility for measuring a specific eigenvalue is defined by the wave function representing the
system and by the operator representing the observable.
Let a system be in a state associated with the wave function, ψ(r,t), prior to a mea￾surement at time t
0
, namely at t ≤ t
0
, and let the measured observable be represented
by the operator, Aˆ. If ψ(r,t
0
) is an eigenfunction of Aˆ, namely, if Aˆψ(r,t
0
) = αψ(r,t
0
),
with an eigenvalue, α, then the result of the measurement would yield the value α,
with perfect certainty. Notice that α is real-valued, since observables are represented
by Hermitian operators (postulate 2).
In the more general case, where ψ(r,t
0
) is not necessarily an eigenfunction of Aˆ, the
following holds:
I. The result of a single measurement of the observable associated with Aˆ can only be
one of the eigenvalues of Aˆ, as defined by its eigenvalue equation,
Aˆφn(r) = αnφn(r). (11.1.14)
II. For a proper wave function, ψ(r,t
0
), the probability of measuring an isolated
eigenvalue (from a discrete spectrum) at the measurement time, P(αn,t
0
), is given
by the overlap integral between the (normalized) wave function at the time of
measurement, ψ(r,t
0
), and the corresponding (normalized) eigenfunction, φn(r),
namely
P(αn,t
0
) ≡ | w
Vps
φ
∗
n
(r)ψ(r,t
0
)dr|
2
, (11.1.15)
where r
Vps
|ψ(r,t
0
)|
2dr = 1 and r
Vps
|φn(r)|
2dr = 1. If the eigenvalue, αn, is N-fold
degenerate, namely Aˆφk(r) = αnφk(r), where φ1,φ2,...,φN are a subset of ortho￾normal functions, r
Vps
φ
∗
k
0(r)φk(r)dr = δk,k
0 , the probability for measuring αn is given
by the summation, P(αn,t
0
) ≡
N
∑
k=1
|
r
Vps
φ
∗
k
(r)ψ(r,t
0
)dr|
2
.
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press127 11.2 The Hilbert Space of Proper Quantum States and Dirac’s Notations
When the operator Aˆ has a continuous spectrum, namely Aˆφα(r) = αφα(r), with α
being a continuous variable, the probability for measuring the eigenvalue α, within
an interval dα, is ρ(α,t
0
)dα, where the probability density reads
ρ(α,t
0
) ≡ | w
Vps
φ
∗
α
(r)ψ(r,t
0
)dr|
2
. (11.1.16)
Also in this case, if α is a degenerate eigenvalue, the right-hand side must be
extended to include the sum over all degenerate states.
Notice that if the entire eigenvalue spectrum of Aˆ is discrete, probability conserva￾tion means that
∑n
P(αn,t
0
) = 1, (11.1.17)
where the sum is over the entire set of eigenvalues of the operator (which can
also be infinite). If the entire eigenvalue spectrum of Aˆ is continuous, probability
conservation means that
w
ρ(α,t
0
)dα = 1. (11.1.18)
As we shall discuss in Section 11.4, Eqs. (11.1.17, 11.1.18) indeed hold from a math￾ematical point of view, since the corresponding set of eigenfunctions of any linear
Hermitian operator is a complete orthonormal system that spans the space of wave
functions.
III. Given a measurement on the system at time t
0
, which yields a specific eigenvalue of
Aˆ, for example, αn, the state of the system collapses to the respective eigenfunction
of Aˆ,
ψ(r,t ≤ t
0
) 7→ φn(r,t
0
). (11.1.19)
Notice that the Schrödinger equation dictates the evolution of the physical state of
the system before the measurement (ψ(r,t ≤ t
0
)) and also after the measurement
time (where φn(r,t
0
) is an initial condition for the future evolution at t > t
0
), but not
during the measurement. Notice also that this postulate refers to a full collapse of
the wave function, which refers to a perfect precision in the determination of the
measured eigenvalue. This is an idealized limit, and in practice the finite precision
of the measurement also needs to be accounted for [11.1].
11.2 The Hilbert Space of Proper Quantum States and Dirac’s
Notations
In this section we turn to an abstract formulation of the postulates of quantum mechan￾ics, which is fully consistent with, but not limited to wave functions in the position
space, as introduced so far. We start by noticing that the solutions to the Schrödinger
equation for a given system define a vector space over the field of complex numbers.
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press128 The Postulates of Quantum Mechanics
Particularly, this space is closed with respect to addition of functions and to their
multiplications by scalar complex numbers (i.e., a sum of wave functions and/or a
wave function multiplied by a complex number is a wave function), where the fol￾lowing set of properties, defining a vector space, hold trivially. Indeed, addition of
wave function satisfies commutativity (for any wave functions, ψ1(r) and ψ2(r), we have
ψ1(r)+ψ2(r) = ψ2(r)+ψ1(r)), associativity (for any wave functions ψ1(r), ψ2(r), and
ψ3(r), we have ψ1(r) + [ψ2(r) + ψ3(r)] = [ψ1(r) + ψ2(r)] + ψ3(r)), the existence of an
additive identity (namely the trivial solution, ψ (r) = ψ (r)+0), and the existence of an
additive inverse for any ψ (r) (namely ψ (r)−ψ (r) = 0). Additionally, multiplication of
a wave function by a complex valued scalar satisfies distributivity (for any scalars a and
b, and any wave functions, ψ1(r) and ψ2(r), we have a[ψ1(r)+ψ2(r)] = aψ1(r)+aψ2(r)
and (a+b)ψ1(r) = aψ1(r)+bψ1(r)), associativity (for any scalars a and b,(ab)ψ(r) =
a[bψ(r)]), and the existence of an identity (1 · ψ(r) = ψ(r)). We can accordingly asso￾ciate the physical states of a given system with abstract vectors, each corresponding to
a realization in terms of a wave function, ψ(r). Following Dirac [11.2], an abstract vec￾tor representing a physical state is termed a “ket,” where (as elaborated in Section 11.5)
there is a unique correspondence between a ket, denoted as |ψi, and its realization in
terms of a wave function,
ψ(r) ↔ |ψi. (11.2.1)
Let us consider first the vector space of all proper (square-integrable) complex￾valued wave functions representing the possible physical states of a given closed system.
According to the postulates (Eqs. (11.1.1, 11.1.2)) the information with respect to any
measurable quantity in a system characterized by a ket vector, |ψi, is contained in this
vector. This information is expressed in terms of probabilities (or probability densi￾ties), which must be real-valued and nonnegative. In particular, the state vector, |ψi,
must be normalizable, namely, must have a unique norm, expressed in terms of a real￾valued (orderable), positive scalar. Moreover, the definition of the norm must account
for the fact that the vector space is defined over the field of complex numbers. A nat￾ural choice is to associate the norm of a vector with its “length,” namely the positive
square root of its inner product with itself (a Euclidian norm). For this purpose, a
suitable inner product between vectors in the space needs to be defined. Following
Dirac, the inner product between the vectors |ψi and |ϕi is termed a “braket,” and is
denoted as
hφ(r),ψ(r)i ↔ hφ|ψi, (11.2.2)
where, in order for hψ|ψi to be real-valued, the following must hold:
hφ|ψi = hψ|φi
∗
. (11.2.3)
Notice that the inner product between two different ket vectors can be complex in
general. Nevertheless, the condition, Eq. (11.2.3), assures that each physically mean￾ingful (nonzero) solution can be associated with a positive norm, p
hψ|ψi > 0. It is
customary to multiply the vector |ψi by a scalar in order to obtain the normalized ket,
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press129 11.2 The Hilbert Space of Proper Quantum States and Dirac’s Notations
|ψ˜i = √
1
hψ|ψi
|ψi, which corresponds to a normalized wave function (see Eqs. (11.1.1,
11.1.2)):
w
Vps
ψ˜
∗
(r)ψ˜(r)dr = 1 ↔ hψ˜ |ψ˜i = 1. (11.2.4)
The vector appearing in the left place within the bracket is termed the “bra.”
Eq. (11.2.3) implies that a bra, denoted as hφ|, is related uniquely to a ket vector,
|φi, in terms of Hermitian conjugation. Namely, for any |χi in the vector space, the
scalars, hφ|χi and hχ|φi, are complex conjugates. In linear algebra terms (namely,
in finite-dimensional spaces), a ket would be analogous to a column vector of N
complex-valued entries, and the corresponding bra would be associated with its Her￾mitian conjugate (complex-transposed) vector, namely the row vector consisting of the
complex conjugates of these entries. The bra-ket inner product is therefore analogous
to the scalar (dot) product between two vectors of a finite dimension. Nevertheless,
the dimension of the ket space can be infinite, in general, that is, N → ∞. This can
be readily seen by inspecting, for example, Eq.(11.2.4). Replacing the normalization
integral by a Riemann sum over finite volume elements, the inner product can be
approximately associated with the dot product of a complex vector with itself, namely
hψ˜ |ψ˜i ↔ limdr→0 dr
Vps/dr
∑
n=1
ψ˜
∗
n
(r)ψ˜n(r), where the nth vector element is ψ˜n(r)
√
dr. Nev￾ertheless, the exact result of the normalization integral would be reproduced only when
the volume element becomes infinitesimally small, and the vector dimension therefore
becomes infinite, asVps/dr → ∞. The infinite dimension of the ket space reflects the infin￾ity of the physical space. Indeed, even for a closed system composed of a fixed number
of particles, the idea that the particle’s position changes continuously in space (with
resolution limited only by the measurement precision) implies that the position can
obtain an infinite number of entries, and a similar argument is true for other physi￾cal properties such as momentum, energy, and so on. Notice in this context that even
when the spectrum of an observable is discrete (rather than continuous) the number
of eigenvalues, and therefore the different outcomes of a measurement, can still be
infinite. We already encountered this when discussing the discrete energy spectrum of
several bound systems, including the one-dimensional harmonic oscillator, a particle
in a one-dimensional infinite box, or the hydrogen atom.
It is therefore natural that the postulates of quantum mechanics associate the space
of proper physical states of a system with a Hilbert space. The Hilbert space is an infi￾nite vector space over the field of complex numbers, which admits an inner product (e.g.,
Eq. (11.2.3)) and a finite norm (e.g. Eq. (11.2.4)) for any nonzero vector. Moreover,
a Hilbert space is the span of an infinite (countable) set of orthonormal vectors (a com￾plete orthonormal set). The latter property extends the existence of a finite orthonormal
basis for finite-dimensional inner-product vector spaces to infinite dimensions. While a
mathematical proof of existence is beyond the scope of this book, in the following sec￾tion we shall show how such sets can be constructed, and we shall discuss their essential
role in the interpretation of the postulates of quantum mechanics.
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press130 The Postulates of Quantum Mechanics
Given a complete orthonormal set for spanning a Hilbert space of proper physical
states, each vector within the set, denoted as |φni, can be associated with a natu￾ral index, n = 1,2,3,.... The orthonormality of the set is expressed in terms of the
Kronecker delta (Eq. (4.6.4)),
hφn
0|φni = δn
0
,n
(11.2.5)
where any ket |ψi in the Hilbert space can be expanded as
|ψi =
∞
∑
n=1
an|φni. (11.2.6)
The series of scalars {an} are the elements of the “vector representation” of the state in
the selected set. These can be readily identified by taking the inner product of |ψi with
any specific ket, hφn
0|ψi. Using the orthogonality condition (Eq. (11.2.5)), this yields
an = hφn|ψi, (11.2.7)
where the expansion, Eq. (11.2.6), obtains the form,
|ψi =
∞
∑
n=1
|φnihφn|ψi. (11.2.8)
Since for any two kets, |ψi and |χi, we have hψ|χi = hχ|ψi
∗
, and since hχ|ψi
∗ =
∞
∑
n=1
hχ|φni
∗
hφn|ψi
∗ =
∞
∑
n=1
hψ|φnihφn|χi, it follows that the bra state, hψ|, can be
expanded similarly as follows:
hψ| =
∞
∑
n=1
hψ|φnihφn|. (11.2.9)
In analogy with a finite-dimensional space, the ket corresponds to a column vector, ψ,
whose entries, [ψ]n = hφn|ψi, are the representation of the vector|ψiin the selected ortho￾normal set. The corresponding bra is the complex conjugate transposed vector, namely
ψ†
.
Since the expansions (Eqs. (11.2.8, 11.2.9)) hold for any |ψi, we can identify an
expression of the identity operator in the Hilbert space, which reads
∞
∑
n=1
|φnihφn| = ˆI. (11.2.10)
The “ket-bra” structure, |ψ1ihψ2|, associated with any two states, |ψ1i and |ψ2i, indeed
defines an operator, since it maps any ket on a ket within the space, that is, |ψ1ihψ2| ·
|ψi = hψ2|ψi|ψ1i. In a finite-dimensional space this structure is analogous to a matrix,
formed by an outer product of two vectors, ψ1 ⊗ ψ
†
2
, where the ket corresponds to
a column vector, ψ1, and the bra corresponds to the complex conjugate transposed
vector, ψ
†
2
.
The identity operator is shown to be a sum over all outer products of the basis vec￾tors with themselves, which manifests the completeness of the set. Moreover, any linear
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press131 11.2 The Hilbert Space of Proper Quantum States and Dirac’s Notations
operator in the Hilbert space can be represented using a complete orthonormal set.
Indeed, for any linear operator, Aˆ, we obtain
Aˆ = ˆIAˆ ˆI =
∞
∑
n=1
|φnihφn|Aˆ
∞
∑
n
0=1
|φn
0ihφn
0| =
∞
∑
n,n
0=1
An,n
0|φnihφn
0|. (11.2.11)
In analogy with finite vector spaces, the scalar An,n
0 ≡ hφn|Aˆ|φn
0i is termed “the matrix
element” of the operator Aˆ, between the n and n
0 basis vectors, where the indexes, n
and n
0
, can be associated, respectively, with the row and column index of an infinite
“matrix representation” of the operator Aˆ in the selected basis,
An,n
0,≡ [A]n,n
0. (11.2.12)
Notice that a matrix representation of an operator Aˆ depends on the choice of
basis, and therefore it is not unique. Let A and A˜ be the matrix representations
of Aˆ obtained using two different orthonormal sets, {|φni}, and {|χmi}, respec￾tively, as defined according to Eqs. (11.2.11, 11.2.12). It then follows that A˜
m,m0 =
∞
∑
n,n
0=1
hχm|φniAn,n
0hφn
0|χm0i. Associating the inner products between the different basis
vectors with the elements of a matrix, [S]m,n = hχm|φni, the last equation can be formally
written as
A˜ = SAS†
, (11.2.13)
where the Hermitian conjugate matrix, S
†
, is defined by [S
†
]n,m = [S]
∗
m,n = hφn|χmi.
Since each of the two sets {|φni} and {|χmi} spans the space, it immediately follows
(see Ex. 11.2.1), that the matrix S is unitary, namely
SS† = S
†S = I. (11.2.14)
Changing the matrix representation of an operator, Aˆ, from one complete orthonormal
set to another is therefore associated with a unitary transformation, Eq. (11.2.13).
Similarly, the vector representation of a state |ψi depends on the choice of basis.
Expanding the ket |ψi in two different orthonormal basis sets, |ψi =
∞
∑
n=1
|φnihφn|ψi =
∞
∑
m=1
|χmihχm|ψi, we readily obtain hχm|ψi =
∞
∑
n=1
hχm|φnihφn|ψi. Denoting the elements
of the two different vector representations as ψn = hφn|ψi and, ψ˜
m = hχm|ψi, we
formally obtain
ψ˜ = Sψ. (11.2.15)
Changing the vector representation of a state |ψi from one complete orthonormal set to
another is therefore formally equivalent to a unitary matrix operation.
Exercise 11.2.1 (a) S is a matrix whose elements are given as [S]m,n = hχm|φni, where
the sets {|φ1i,|φ2i,|φ3i...} and {|χ1i,|χ2i,|χ3i,...} are two different complete ortho￾normal sets of vectors, which span the Hilbert space. Use Eq. (11.2.10) to show that the
matrix S is unitary, namely [S
†S] = I (or, [S
†S]m,n = δm,n).
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press132 The Postulates of Quantum Mechanics
It is instructive to define a Hermitian conjugate to a linear operator Aˆ as Aˆ†
, whose
matrix representation in any complete orthonormal set is identified with the complex
conjugate transposed matrix representation of Aˆ, namely
[A
†
]n,n
0 ≡ [A]
∗
n
0
,n
. (11.2.16)
Using the definition of the matrix elements and the completeness relation
(Eq. (11.2.11)), the following identity holds for any states, |ψi and |χi, in the Hilbert
space (see Ex. 11.2.2):
hψ|Aˆ
†
|χi = hχ|Aˆ|ψi
∗
. (11.2.17)
Exercise 11.2.2 Use Eqs. (11.2.11, 11.2.12, 11.2.16) and show that Eq. (11.2.17) holds
for any states, |ψi and |χi, in the Hilbert space.
The Hermitian conjugate operator is instrumental for defining the bra associated with
Aˆ|ψi ≡ |Aˆψi. Since for any |χi in the Hilbert space we have hχ|Aˆψi = hAˆψ|χi
∗
, and
using Eq. (11.2.17), it follows that
hAˆψ| = hψ|Aˆ
†
. (11.2.18)
Exercise 11.2.3 The Schrödinger equation for a ket reads ∂
∂t
|ψ(t)i =
1
ih¯
Hˆ|ψ(t)i, where
Hˆ is the Hamiltonian operator. Use Eq. (11.2.18) and show that the equation of motion
for the corresponding bra reads ∂
∂t
hψ(t)| =
−1
ih¯
hψ(t)|Hˆ.
Notice that for a Hermitian operator (Aˆ = Aˆ†
), the matrix representation is Hermitian
(see Eq. (11.2.16)),
Aˆ = Aˆ
† ⇔ A = A
†
, (11.2.19)
where
Aˆ = Aˆ
† ⇔ hχ|Aˆ|ψi = hψ|Aˆ|χi
∗
. (11.2.20)
As discussed in Section 11.5, when the state vectors and the operators are presented in
the continuous position representation, Eq. (11.2.20) coincides with the definition of
Hermiticity in terms of integrals over the coordinate space for proper wave functions,
as introduced in Section 4.5 (Eq. (4.5.1)).
11.3 Extending the Vector Space to Include Improper States
We now turn to consider improper states, which are outside the Hilbert space of square
integrable functions. Following Dirac [11.2], it is most useful to extend the vector space
of physical states beyond that Hilbert space, such that certain improper states can be
included. We have already encountered improper solutions to the Schrödinger equa￾tion, which are not subject to the normalization requirement, Eqs. (11.1.1, 11.1.2), and
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press133 11.3 Extending the Vector Space to Include Improper States
yet conserve probability fluxes (Eq. (11.1.3)). These states obtain their physical mean￾ing as stationary scattering states in open systems (see Chapter 7). Moreover, although
scattering wave functions are not square integrable, a continuous set of scattering wave
functions can replace a complete orthonormal set for expanding square integrable
functions. A well-known example (to be discussed in detail in what follows) is the
representation of square integrable functions as Fourier transforms, which are inte￾gral expansions in terms of a continuous set of non–square-integrable plane waves
(encountered in Chapter 7). Such integral expansions exist also for other continuous
sets of improper functions, as discussed in what follows.
In order to treat (physically meaningful) sets of improper functions within an
extended ket space, we utilize the existence of integral transforms, namely represen￾tations of proper states within the Hilbert space in terms of a specified uncountable
set of improper states. Denoting the set of improper functions as ket vectors, {|φαi},
each vector is marked by the continuous index, α (which can be a scalar or a vector,
depending on dimensions of the physical system). The existence of an integral transform
implies that each ket in the Hilbert space can be expanded as follows,
|ψi ≡ w
dαψ(α)|φαi, (11.3.1)
where the expansion coefficients {ψ(α)} are the inner products between the proper
ket, |ψi, and the improper kets, |φαi (subject to Eq. (11.2.3)),
hφα|ψi ≡ ψ(α). (11.3.2)
The function, ψ(α), is often termed “the continuous vector representation” of the
state vector |ψi. Substitution of Eq. (11.3.2) into Eq. (11.3.1), we obtain |ψi = r
dα|φαihφα|ψi, which implies that the identity operator in the Hilbert space can be
expressed in terms of the specified set of improper states,
ˆI =
w
dα|φαihφα|. (11.3.3)
Using the normalization condition for any proper state, hψ|ψi = 1, and the identity
operator representation, it follows that
w
dαhψ|φaihφα|ψi =
w
dα|ψ(α)|
2 = 1, (11.3.4)
which reassures that ψ(α) is a square integrable function of α.
Eqs. (11.3.1–11.3.3) can be regarded as continuous analogues to Eqs. (11.2.6, 11.2.7,
11.2.10), which refer to spanning the Hilbert space of proper states by a complete
orthonormal set of proper vectors. However, let us reemphasize that the orthonor￾mality condition, Eq. (11.2.5), does not apply to the set {|φai}. In particular, the
improper states are, by definition, not normalizable, namely, hφa|φai does not strictly
exist. Nevertheless, the existence of the expansions, Eqs. (11.3.1, 11.3.2), enables us
to extend the definition of the orthonormality condition beyond Eq. (11.2.5) and to
provide a formal basis for an analogy between the expansion of proper states in terms
of a complete orthonormal system of proper states within the Hilbert space and in
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press134 The Postulates of Quantum Mechanics
terms of a specified set of improper states. Using Eqs. (11.3.1, 11.3.2), we readily
obtain
ψ(α) = w
dα
0
hφα|φα0iψ(α
0
). (11.3.5)
This can hold for any α, only if the inner product between |φαi and |φα0i is identified
with “Dirac’s delta function” [11.2],
hφα|φα0i = δ(α
0 −α), (11.3.6)
which (for a one-dimensionl Cartesian variable) is defined as follows,
w∞
−∞
δ(α
0 −α)dα = 1 ; δ(α
0 −α) = (
0 ; α 6= α
0
∞ ; α = α
0
, (11.3.7)
such that
ψ(α) = w∞
−∞
δ(α
0 −α)ψ(α
0
)dα
0
. (11.3.8)
Strictly speaking, Dirac’s delta is not a well-defined function of its arguments. Never￾theless, it is a limit of well-defined functions, where Eqs. (11.3.7, 11.3.8) strictly hold
under a limit (see, e.g., Ex. 11.3.1). Moreover, Eq. (11.3.8) is an integral transform,
which expresses a square integrable function, ψ(α), in terms of a set of (improper) delta
functions. As we shall discuss in Section 11.5, sets of Dirac’s delta functions not only
are useful for conveniently representing square integrable functions, but also obtain
important physical meaning.
Exercise 11.3.1 One of the definitions of Dirac’s delta is the limit of an infinitely nar￾row normalized Gaussian distribution, δ(α) = limε→0
q
1
4πε
e
−α
2
4ε . Calculate the integral
explicitly and show that indeed limε→0
r∞
−∞
q
1
4πε
e
−(α−α
0
)
2
4ε ψ(α)dα = ψ(α
0
), where ψ(α)
is a Gaussian distribution of a fimite width, ψ(α) = q 1
2πσ2 e
−(α−α0
)
2
2σ2
.
Eqs. (11.3.3, 11.3.6) are the analogues to Eqs. (11.2.10, 11.2.5), which enable one to
extend the vector space of physical states beyond the Hilbert space of square-integrable
functions. Thereby, proper and improper states can be regarded as kets (and bras) using
the same formal terms. For this purpose, it is instructive to review the expressions of
the inner product between the different types of vectors in the extended space, in terms
of an uncountable set of improper states, {|φαi}.
I. The inner product between two proper states, |ψi and |χi, can be expanded as
hχ|ψi =
w
dαhχ|φαihφα|ψi (11.3.9)
where both χ(α) ≡ hφa|χi and ψ(α) ≡ hφα|ψi are proper functions of α.
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press135 11.4 Rationalizing The Postulates
II. The inner product between a proper vector, |ψi, and an improper vector, |χβ
i, can
be expanded as
hχβ
|ψi =
w
dαhχβ
|φαihφα|ψi, (11.3.10)
where ψ(β) ≡ hχβ
|ψi and ψ(α) ≡ hφα|ψi are proper function of α, and hχβ
|φαi
is an improper function of α and β.
III. The inner product between two improper vectors, |ψγ i, and |χβ
i, can be expanded
as
hχβ
|ψγ i =
w
dαhχβ
|φαihφα|ψγ i, (11.3.11)
where hχβ
|ψγ i, hχβ
|φαi, and hφα|ψγ i are improper functions of their respective
arguments (α, β and γ).
For the completeness of the discussion, we notice that the expansion of an improper
state, for example, |φαi, in terms of a complete set of proper orthonormal functions
does not strictly hold, namely |φαi 6=
∞
∑
n=0
|φnihφn|φαi. Nevertheless, an improper func￾tion that is a limit of a proper functions can be expanded using proper states. An
important example is the formal representation of Dirac’s delta in term of a complete
orthogonal set, which reads
δ(α −α
0
) =
∞
∑
n=0
hφα0|φnihφn|φαi =
∞
∑
n=0
φn(α
0
)φ
∗
n
(α). (11.3.12)
Thereby, proper and improper states can be regarded as kets and bras using the same
formal terms.
11.4 Rationalizing The Postulates
According to the postulates of quantum mechanics: (i) The measurable information on
a system in a given state is entirely contained in a wave function (Section 11.1), where,
as discussed in Section 11.2, the wave function is associated with an abstract vector in
the space of physical states, (ii) measurable quantities are represented by linear opera￾tors in that vector space, and (iii) the results of a single measurement are expressed in
terms of the eigenvalues and eigenvectors of these operators. In this section we discuss
again these seemingly unrelated postulates in the context of the abstract vector space,
attempting to unravel the rationale that links them.
So far, we used the fact that the vector space of physical states is spanned by a
complete orthonormal set of vectors, but we did not attempt to specify how such
orthonormal sets can be identified or constructed. For this purpose, we first recall that
observables are represented by operators that are linear and Hermitian in the space
of wave functions. We already noticed that the eigenvalues of Hermitian operators in
the space of proper (square integrable) functions are real-valued, and therefore there
is no fundamental problem in associating them with results of physical measurements
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press136 The Postulates of Quantum Mechanics
(see Section 4.5). We also noticed that the eigenvalue spectrum of a linear Hermitian
operator can be associated with an orthonormal set of eigenfunctions in the position
representation (see Section 4.6). In what follows we reformulate these results within the
abstract vector space of physical states, as introduced in Sections 11.2 and 11.3.
Using Dirac’s notations, the eigenvalue equation for a linear Hermitian operator, Aˆ,
reads
Aˆ|φαi = α|φαi. (11.4.1)
Here |φαi is the eigenvector, and α is the respective scalar eigenvalue. Since Aˆ is Her￾mitian, the following identity holds for any two vectors in the space (Eq. (11.2.20)),
and particularly for any two eigenvectors of Aˆ, |φαi, and |φβ
i,
hφβ
|Aˆ|φαi = hφα|Aˆ|φβ
i
∗
. (11.4.2)
Using Eq. (11.4.1) in Eq. (11.4.2), we have
(α −β
∗
)hφβ
|φαi = 0. (11.4.3)
Setting |φβ
i = |φαi and noticing that hφα|φαi 6= 0 (whether |φαi is proper or improper,
where, in the latter case, hφα0|φαi = δ(α −α
0
); see Eqs. (11.3.6, 11.3.7)), Eq. (11.4.3) is
shown to hold only if the eigenvalue is real-valued,
α = α
∗
. (11.4.4)
Considering now two different eigenvalues, α 6= β, Eq. (11.4.3) can hold only if the
inner product between the two corresponding eigenvectors vanishes; namely the two
vectors corresponding to different eigenvalues, must be orthogonal:
hφβ
|φαi|β6=a = 0. (11.4.5)
Notice that this result holds regardless of whether the two eigenvectors are proper or
not. Also notice that when |φαi and |φβ
i are degenerate vectors (associated with the
same eigenvalue), their orthogonality is not imposed by Eq. (11.4.5). Nevertheless,
it is always possible to construct linear combinations of degenerate eigenvectors that
are mutually orthonormal by using a Gram Schmidt orthonormalization process (see,
e.g., Exs. 4.6.3, 4.6.4, for proper functions) [4.4]. Consequently, the set of eigenvectors
of any linear Hermitian operator Aˆ can be mapped onto an orthogonal set. Hereaf￾ter we denote this set as {|φγ ,i}, where γ is a parameter that identifies uniquely each
vector within the set. (For example, γ can denote the eigenvalue itself, and/or an iden￾tifying index within a degenerate subspace, or a quantum number, etc.) Notice that
in manyparticle and/or multidimensional systems, a unique definition of the eigen￾vector requires a group of parameters (e.g., a vector, γ = (γ1, γ2,...)). Without loss
of generality, and for simplicity of notations, we shall restrict the discussion to a sin￾gle parameter, where the generalization is straightforward. The eigenvalue equation
therefore reads
Aˆ|φγ i = αγ |φγ i, (11.4.6)
where αγ is the eigenvalue associated with |φγ i. Eigenvectors corresponding to proper
states (as, e.g., the Hamiltonian eigenstates in bound physical systems) are associated
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press137 11.4 Rationalizing The Postulates
with a discrete spectrum, which means that γ is countable and can be denoted γn, with
n = 1,2,3.... In this case, the orthonormality condition reads
hφγ
n
0
|φγn
i = δn,n
0 (11.4.7)
Eigenvectors corresponding to improper states (as, e.g., scattering states in open sys￾tems, as discussed in Chapter 7, or position eigenstates, as discussed in what follows),
are associated with a continuous spectrum, which means that γ is uncountable. In this
case (see Eq. (11.3.6)), the orthonormality condition corresponds to
hφγ
0|φγ i = δ(γ −γ
0
). (11.4.8)
In many cases, the spectrum of a linear Hermitian operator contains both continuous
and discrete parts, which correspond, respectively to improper and proper wave func￾tions (see, e.g., the discussion of the Hamiltonian eigenstates for a particle in a finite
square well potential in Chapter 7). Eq. (11.4.5) means that eigenvectors associated
with different parts of the spectrum are necessarily orthogonal, and therefore when
the set of eigenvectors includes both countable {|φγn
i} and uncountable {|φγ i} parts
we have
hφγn
|φγ i = 0. (11.4.9)
In finite, N-dimensional inner product vector spaces, a linear Hermitian operator
(namely a Hermitian matrix) defines a series of N orthonormal eigenvectors (a basis),
which spans the N-dimensional vector space [11.3]. In analogy, an infinite set of ortho￾normal eigenvectors of a linear Hermitian operator is a complete orthonormal system,
which spans the vector space of physical states, in the sense that the only vector in the
space that is orthogonal to the entire system is the zero vector. A rigorous proof of
this statement in beyond our scope here, and the reader is directed to complementary
literature on functional analysis.
As discussed in the previous section, the identity operator in the vector space can be
expanded in terms of a complete orthonormal system. Choosing an orthonormal set
of eigenvectors of a linear Hermitian operator, Aˆ, we have (in the most general case)
ˆI = ∑n
|φγn
ihφγn
|+
w
dγ|φγ ihφγ |, (11.4.10)
where we recall that γn and γ correspond, respectively, to the discrete (proper) and con￾tinuous (improper) parts of the spectrum of Aˆ. In many cases of interest the spectrum
is either discrete (finite or infinite) or continuous, such that the identity is expanded in
either the countable summation or the integral, in Eq. (11.4.10).
Since the postulates of quantum mechanics associate each observable with a linear
Hermitian operator, and since a set of eigenvectors of such an operator spans the space
of physical states, it is natural to analyze the results of the measurement of a particu￾lar observable in terms of the eigenvectors of the corresponding operator. Notice that
the state of the system at the measurement time (e.g., |ψi) can be expanded as a lin￾ear combination of any complete orthonormal system. Nevertheless, the postulates
associate the results of a measurement represented by Aˆ, with the expansion of |ψi in
a specific orthonormal system, corresponding to the set of Aˆ eigenvectors, as defined by
Aˆ|φγ i = αγ |φγ i.
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press138 The Postulates of Quantum Mechanics
Let us consider first the case where the eigenvectors of Aˆ correspond to proper states,
and the eigenvalues are countable. The vector that represents the state of the system,
|ψi, can then be expanded as follows:
|ψi =
∞
∑
n=0
|φγn
ihφγn
|ψi =
∞
∑
n=0
ψn|φγn
i. (11.4.11)
The scalar expansion coefficients are the inner products, ψn ≡ hφγn
|ψi (see Eqs. (11.2.6,
11.2.7)). Invoking again the analogy to a finite-dimensional (Euclidian) vector space,
these inner products can be regarded as projections of the state vector |ψi onto the
different basis vectors, |φγn
i, just like the elements of the column vector, [ψ]n, are pro￾jections (dot products) of the vector ψ on the elementary basis vectors, en, namely
[ψ]n = en ·ψ. In Euclidian geometrical terms, a larger absolute value of the inner prod￾uct, implies a smaller angle between the vectors, namely a closer similarity between the
vector directions. Moreover, for a normalized |ψi, Eq. (11.4.11) readily means
∞
∑
n=0
|hφγn
|ψi|2 =
∞
∑
n=0
|ψn|
2 = 1. (11.4.12)
As we can see, a larger |hφγn
|ψi|2
implies a larger contribution of the basis vector, |φγn
i,
to the norm of the state vector, |ψi, suggesting, again, that the “similarity” between
|ψi and the vector, |φγn
i, is larger in some sense.
A similar argument holds also when the observable represented by Aˆ is associated
with a continuous eigenvalue spectrum. In this case, |ψi can be expanded as an integral,
|ψi =
w
dγhφγ |ψi|φγ i =
w
dγψ(γ)|φγ i. (11.4.13)
For a normalized |ψi, we have
w
dγ|hφγ |ψi|2 =
w
dγ|ψ(γ)|
2 = 1, (11.4.14)
where ψ(γ) is a square integrable function of γ (see Eq. (11.3.4)).
According to the postulates, the results of a single measurement represented by an
operator Aˆ on a single system represented by |ψi are restricted to the eigenvalues of the
operator Aˆ, where the occurrence of any specific eigenvalue is inherently probabilistic.
Given this framework, it is only natural to expect that the probability of measuring a
particular eigenvalue, αγn
(or αγ ), and of collapsing the system into the correspond￾ing eigenvector, |φγn
i (or |φγ i), should be larger with increasing similarity between the
state vector |ψi and that eigenvector. It is also natural to associate this similarity with
the projection of |ψi onto that eigenvector, namely, with the inner product, hφγn
|ψi
(or hφγ |ψi) (see Ex. 11.4.1). The postulates indeed identify the probability for meas￾uring αγ with the nonnegative, bounded value, |hφγn
|ψi|2
(or |ψ(γ)|
2dγ), where the
completeness relations, Eqs. (11.4.12, 11.4.14), imply that the probability of obtaining
any eigenvalue of Aˆ in a measurement of the observable represented by Aˆ is unity. Using
Dirac’s notations, the probability of measuring a specific eigenvalue in the case of a
discrete spectrum is given as
P(αγn
) = |hφγn
|ψi|2
, (11.4.15)
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press139 11.5 The Continuous Position and Momentum Representations
where, in the case of a continuous spectrum, the probability density for measuring an
eigenvalue αγ , within an interval dγ, is expressed in terms of a probability density,
ρ(γ)dγ, where
ρ(γ) ≡ |

φγ |ψ

|
2
. (11.4.16)
Notice that in the original formulation of the postulates in terms of wave functions,
the probabilities expressed in Eqs. (11.4.15, 11.4.16) were associated with overlap
integrals. In the following section we shall show that an overlap integral is merely a
particular representation of the inner product between two state vectors in their (con￾tinuous) position representation. Eqs. (11.1.15 and 11.1.16) therefore coincide with the
“natural,” more general definition of the probability of measurement as expressed in
Eqs. (11.4.15, 11.4.16).
Exercise 11.4.1 Let S = hχ|ψi be the inner product between two normalized proper
vectors, hψ|ψi = 1 and hχ|χi = 1. Show that the inner product satisfies the Cauchy￾Schwarz inequality, namely |S|
2 ≤ 1, which is consistent with the interpretation of |S|
2 as
a probability. (You can use the identity, r
dγ
r
dγ
0
|ψ(γ)χ(γ
0
) − χ(γ)ψ(γ
0
)|
2 ≥ 0, which
holds for any proper functions ψ(γ) and χ(γ).)
In summary, when attempting to measure a specific observable, the postulates
restrict the outcome to a specific “ruler,” composed of the set of all possible eigenvalues
of the Hermitian linear operator that represents that observable. The probabili￾ties for realization of a specific eigenvalue in the measurement process depend on
the state of the system at the time of measurement. These probabilities are deter￾mined by expanding the corresponding state vector in a complete orthonormal system
composed of the eigenvectors of the operator representing the observable. A larger
expansion coefficient (in absolute value squared) of a specific eigenvector means that
the probability of measuring the corresponding eigenvalue is larger. The expansion
of the state vector is analogous to the representation of a vector in a Euclidian
space in terms of its projections on a selected axis system, namely an orthonor￾mal set of basis vectors. Indeed, each observable defines a unique, generally infinite,
“axis system,” associated with the eigenvectors of the corresponding operator. Each
axis corresponds to a specific eigenvalue, and the magnitude of the projection of
the state vector on any particular axis determines the probability of measuring that
eigenvalue.
11.5 The Continuous Position and Momentum Representations
Let us return now to the postulates as formulated in Section 11.1. Postulate 1 associates
the state of a system with a wave function, namely an explicit function of the parti￾cle positions, which (for a closed system) defines the probability density of measuring
the particles in a specific position, ρ(r) = |ψ(r)|
2
(Eq. (11.1.1)). For simplicity, let us
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press140 The Postulates of Quantum Mechanics
consider a single particle in a one-dimensional coordinate space, where this identity
takes the form
ρ(x) = |ψ(x)|
2
, (11.5.1)
and the particle’s position is denoted by the real variable, x. According to postulate
3, each measurable particle position is associated with one of the eigenvalues of the
(linear and Hermitian, Eq. (4.5.4)) position operator, xˆ, as defined by the following
eigenvalue equation:
xˆ|φxi = x|φxi (11.5.2)
First, we notice that the spectrum of xˆ is continuous. Second, since the spectrum cov￾ers uniformly the entire axis, −∞ < x < ∞, the corresponding position eigenfunctions
cannot be square integrable (proper) functions. Indeed, the position eigenvectors are
extemal to the Hilbert space of square integrable functions (see the detailed discussion
in Section 11.3). Nevertheless, as eigenvectors of a Hermitian operator, they constitute
a set of vectors for expanding any physical state vector. Expressing the orthonormality
condition for the improper position eigenvectors in terms of Dirac’s delta (Eq. 11.3.6)),
hφx
0|φxi = δ(x−x
0
), (11.5.3)
and using the expansion of the identity in terms of the complete set (Eq. (11.3.3)),
ˆI =
w
dx|φxihφx|, (11.5.4)
any physical state vector, |ψi, can be expanded as an integral transform,
|ψi =
w∞
−∞
dx|φxihφx|ψi. (11.5.5)
Similarly, any inner product between two state vectors, |ψi and |χi, can be expanded
as
hχ|ψi =
w∞
−∞
dxhχ|φxihφx|ψi (11.5.6)
where hφx|ψi is the continuous representation of the state vector |ψi in the set of posi￾tion eigenstates. Therefore, according to postulate 3 (Eq. (11.4.16)), |hφx|ψi|2
is the
probability density for measuring the corresponding eigenvalue. Using the relation
between the probability density and the wave function (Eq. (11.5.1)), we can identify
the wave function with the “position representation” of the abstract state, |ψi,
ψ(x) = hφx|ψi, (11.5.7)
where the inner product between |ψi and |χi (Eq. (11.5.6) is identified with the overlap
integral between the respective wave functions,
hχ|ψi =
w∞
∞
dxχ
∗
(x)ψ(x). (11.5.8)
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press141 11.5 The Continuous Position and Momentum Representations
Particularly, projecting |ψi on a specific position eigenstate, |φx
0i, we obtain
hφx
0|ψi =
w∞
−∞
dxhφx
0 |φxihφx|ψi, (11.5.9)
where, using Eq. (11.5.3), the integral transform of ψ(x) obtains the familiar form,
ψ(x
0
) = w∞
−∞
dxδ(x−x
0
)ψ(x). (11.5.10)
Eq. (11.5.10) can be regarded as an expansion of the wave function in terms of the
complete orthonormal system of position eigenstates,
ψ(x
0
) = w∞
−∞
dxψ(x)φx(x
0
), (11.5.11)
where φx(x
0
) = δ(x − x
0
) = hφx
0|φxi is the “position representation” of the abstract
position eigenstate, |φxi. Indeed, considering an idealized measurement in absolute
precision, in which the particle’s position is determined to be, for example, x, the
postulates imply that right after the measurement the wave function collapses to a
delta-localized distribution at the position x.
Exercise 11.5.1 A local operator is a function of the position operator (e.g., the sca￾lar potential energy, Vˆ
x = V(xˆ), Eq. (3.4.1)). Show that the matrix representation of a
local operator in the position eigenstates is a diagonal matrix, namely hφx
0|Vˆ |φxi =V(x)δ
(x−x
0
).
Similar considerations apply to the particle’s momentum. The measurable momen￾tum values are the eigenvalues of the momentum operator, pˆx (linear and Hermitian,
Eq. (4.5.5)), as defined by the following eigenvalue equation:
pˆx|φpx
i = px|φpx
i. (11.5.12)
As in the case of the position, the spectrum of pˆx is continuous, and the eigenvalues
cover uniformly the entire momentum axis, −∞ < px < ∞. The corresponding momen￾tum eigenfunctions are improper and external to the Hilbert space of square integrable
functions. Indeed, when discussing scattering processes in Chapter 7, we encountered
the momentum eigenstates, as the improper “plane wave” solutions to the Schrödinger
equation (see Eq. (7.2.8)). It is worthwhile to recall that this association of particles
having a definite momentum with a plane wave by de Broglie (see Chapter 1) preceded
the introduction of quantum mechanics, and later guided the elaborate formulation
of its postulates. Associating the plane wave with the position representation of an
abstract momentum eigenstate (see Eq. (11.5.7)), we have
hφx|φpx
i = ce
ipxx
h¯ , (11.5.13)
where c is a complex-valued normalization constant. We recall that the improper plane
waves are not normalizable in the sense of square integrable function. Nevertheless,
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press142 The Postulates of Quantum Mechanics
as eigenvectors of a Hermitian linear operator, the momentum eigenstates consti￾tute an orthonormal set. Expressing the orthonormality condition as Dirac’s delta
(Eq. 11.3.6),
hφp
0
x
|φpx
i = δ(px − p
0
x
), (11.5.14)
and introducing the identity operator in the position representation (Eq. (11.5.4)), we
obtain
δ(px − p
0
x
) = w
dxhφp
0
x
|φxihφx|φpx
i = |c|
2
w∞
−∞
e
−i(p
0
x−px)x
h¯ dx. (11.5.15)
Using one of the standard representations of Dirac’s delta, δ(k) = 1
2π
r∞
−∞
e
ikxdx, the
normalization constant can be determined to be c = 1/
√
2πh¯, and the normalized
momentum eigenstate in the position representation reads
φpx
(x) = hφx|φpx
i =
1
√
2πh¯
e
ipx x
h¯ . (11.5.16)
Expanding the identity in terms of a complete set of momentum eigenstates,
ˆI =
w
d px|φpx
ihφpx
|, (11.5.17)
any physical state vector, |ψi, can be expanded as an integral transform,
|ψi =
w∞
−∞
d px|φpx
ihφpx
|ψi, (11.5.18)
where hφpx
|ψi is the continuous representation of the state vector in the set of
momentum eigenstates (the “momentum representation” of |ψi),
ψ(px) = hφpx
|ψi. (11.5.19)
Projecting |ψi on a specific position eigenstate, |φxi, Eq. (11.5.18) reads
hφx|ψi =
w∞
−∞
d pxhφx|φpx
ihφpx
|ψi. (11.5.20)
Similarly (Ex. 11.5.1),
hφpx
|ψi =
w∞
−∞
dxhφpx
|φxihφx|ψi. (11.5.21)
Using Eqs. (11.5.7, 11.5.16, 11.5.19), the last two equations can be written as
follows:
ψ(x) = 1
√
2πh¯
w∞
−∞
e
ipxx
h¯ ψ(px)d px, (11.5.22)
ψ(px) = 1
√
2πh¯
w∞
−∞
e
−ipxx
h¯ ψ(x)dx. (11.5.23)
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press143 11.6 The Vector Space of Multidimensional Systems
The momentum and position representations of any state vector are shown to be
related by the Fourier transforms.
Exercise 11.5.2 Given a state vector, |ψi, use Eq. (11.5.4) to derive Eq. (11.5.21).
Exercise 11.5.3 The kinetic energy of a particle is a function of the momentum operator,
Tˆ
x =
1
2m
(pˆx)
2
(Eq. (3.4.3)). Show that the matrix representation of the kinetic energy in
the momentum eigenstates is a diagonal matrix, namely hφp
0
x
|Tˆ
x|φpx
i =
p
2
x
2m
δ(px − p
0
x
).
Exercise 11.5.4 Formulating the postulates in terms of wave functions, the linear
momentum operator is defined as pˆx = −ih¯
d
dx
. Use the expansions of the identity in
terms of the position and momentum eigenstates, Eqs. (11.5.4 and 11.5.17), to show
that hφx|pˆx|ψi = −ih¯
d
dx
ψ(x) and hφx|
pˆ
2
x
2m
|ψi =
−h¯
2
2m
d
2
dx
2ψ(x).
Exercise 11.5.5 Use Eqs. (11.5.12, 11.2.3, 11.5.17) to show that the momentum
operator is Hermitian, namely hχ|pˆx|ψi = hψ|pˆx|χi
∗
.
Using the expansion of the identity in terms of eigenstates of an operator with a con￾tinuous spectrum, any operator can be formally associated with a “continuous matrix
representation.” For example, invoking the position representation (Eq. (11.5.4)), any
operator takes the form
Aˆ =
w
dxw
dx0
|φxihφx|Aˆ|φx
0ihφx
0| =
w
dxw
dx0A(x, x
0
)|φxihφx
0|, (11.5.24)
whereas in the momentum representation (Eq. (11.5.17)),
Aˆ =
w
d px
w
d p0
x
|φpx
ihφpx
|Aˆ|φp
0
x
ihφp
0
x
| =
w
d px
w
d p0
x A(px, p
0
x
)|φpx
ihφp
0
x
|. (11.5.25)
The functions A(x, x
0
) and A(px, p
0
x
) are different continuous (matrix) representations
of the operator Â. In an appropriate basis, the matrix representation of an operator
becomes diagonal. In the case of a continuous spectrum, the diagonal matrix cor￾responds to a function of the eigenvalues. For example, the scalar potential energy
operator is diagonal in the coordinate representation (Ex. 11.5.1); hence, V(x, x
0
) =
V(x)δ(x − x
0
), whereas the kinetic energy operator is diagonal in the momentum
representation (Ex. 11.5.3), hence T(px, p
0
x
) = p
2
x
2m
δ(px − p
0
x
).
11.6 The Vector Space of Multidimensional Systems
Let us consider, as examples, physical systems composed of single or groups of particles
in a three-dimensional coordinate space. According to the first postulate, such systems
are associated with a wave function of several independent variables, corresponding to
the spatial coordinates of each particle composing the system. For concreteness, let us
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press144 The Postulates of Quantum Mechanics
consider a system characterized by N independent Cartesian coordinate variables, x1,
x2,..., xN. In this case the system position is an N -dimensional vector,
x = (x1, x2,..., xN). (11.6.1)
According to postulate 3, each specific N -dimensional position vector x is associ￾ated with one of the eigenvalues of the corresponding position vector operator (see
Eq. (11.5.2) for the one-dimensional case),
xˆ|ϕxi = x|ϕxi, (11.6.2)
where this form of writing means that the position eigenstate, |ϕxi, is a simultaneous
eigenvector of the N independent components of the position operator, namely
xˆj
|ϕxi = xj
|ϕxi ; j = 1,2,...,N. (11.6.3)
Defining the eigenstates of each one-dimensional position operator as (see Eq. (11.5.2))
xˆj
|φx j
i = x j
|φx j
i ; j = 1,2,...,N, (11.6.4)
the multidimensional position eigenstate (|ϕxi, as defined in Eqs. (11.6.2, 11.6.3)) must
therefore be proportional to each |φx j
i, namely |ϕxi ∝ |φx j
i for every j. This means that
|ϕxi must obtain a product form, that is, |ϕxi ∝ |φx1
i|φx2
i···|φxN
i, where the ordering
is insignificant. Notice that each vector |φx j
i is associated with a different (extended)
Hilbert space, corresponding to functions of the independent variable, xj
. The vector
|ϕxi therefore belongs to a larger (extended) Hilbert space that corresponds to all the
different combinations of products of the vectors {|φx j
i}. The multiplication of vectors
from different spaces is a tensor product (also known as a Kronecker product [11.4]),
denoted as
|ϕxi ≡ |φx1
i ⊗|φx2
i ⊗··· ⊗|φxN
i. (11.6.5)
(Please see the examples that follow of realizations of tensor products in standard linear
algebra terms).
Notice that each complete set of position eigenvectors {|φx j
i} defines an identity
operator in the space associated with functions of xj only (see Eq. (11.5.4)), namely ˆIj ≡ r
dx j
|φx j
ihφx j
|. The corresponding identity in the space of multidimensional functions
reads, accordingly,
ˆI =
w
dx|ϕxihϕx|
=
w
dx1
w
dx2 ...w
dxN|φx1
i ⊗|φx2
i ⊗··· ⊗|φxN
ihφx1
| ⊗ hφx2
| ⊗··· ⊗ hφxN
|, (11.6.6)
=
w
dx1
w
dx2 ...w
dxN|φx1
ihφx1
| ⊗|φx2
ihφx2
| ⊗··· ⊗ |φxN
ihφxN
|
and the inner product between two multidimensional states reads
hφ|ψi =
w
dxhφ|ϕxihϕx|ψi =
w
dx1
w
dx2 ...w
dxNφ
∗
(x1, x2,..., xN)ψ(x1, x2,..., xN),
(11.6.7)
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press145 11.6 The Vector Space of Multidimensional Systems
where the multidimensional wave functions are identified as the projections (see
Eq. (11.5.7)) of the state vector in the multidimensional space onto the multidimen￾sional position eigenstate, |ϕxi:
ψ(x1, x2,..., xN) = hϕx|ψi
φ
∗
(x1, x2,..., xN) = hφ|ϕxi. (11.6.8)
Importantly, any ψ(x1, x2,..., xN) is generally not a product function, namely
ψ(x1, x2,..., xN) 6= ψ1(x2)ψ2(x2)...ψN(xN). (11.6.9)
However, it can be expanded in a complete orthonormal set of products, for example,
using Eq. (11.6.6),
ψ(x1, x2,..., xN) = w
dx0
1
w
dx0
2
...w
dx0
N
hφx1
|φx
0
1
ihφx2
|φx
0
2
i··· hφxN
|φx
0
N
iψ(x
0
1
, x
0
2
,..., x
0
N
).
(11.6.10)
Notice that the multidimensional identity operator, Eq. (11.6.6), can be readily
reordered as a tensor product of identity operators (see the following examples for
the definition in linear algebra terms) in the spaces of single coordinate functions,
ˆI =
hw
dx1|φx1
ihφx1
|
i
⊗
hw
dx2|φx2
ihφx2
|
i
⊗··· ⊗hw
dxN|φxN
ihφxN
|
i
= ˆI1 ⊗ ˆI2 ⊗··· ⊗ ˆIN.
(11.6.11)
Since ˆIj can be expanded using any complete orthonormal set of eigenvectors of a
Hermitian linear operator in the respective one-dimensional coordinate space, for
example, ˆIj = ∑
nj
|φnj
ihφnj
|, where Aˆ
j
|φnj
i = αnj
|φnj
i, any multidimensional state vec￾tor, for example, |ψi, can be expanded in terms of tensor product states, which is the
generalization of the expansion, Eq. (11.4.11), into the multidimensional coordinate
space,
|ψi = ∑n1,n2...nN
ψn1,n2,...,nN
|φn1
i ⊗|φn2
i ⊗··· ⊗|φnN
i, (11.6.12)
and in the coordinate representation,
ψ(x1, x2,..., xN) = ∑n1n2,...,nN
ψn1,n2,...,nN φn1
(x1)φn2
(x2)···φnN
(xN). (11.6.13)
Similarly, any operator in the multidimensional space can be expanded as a sum of
tensor products of operators in the one-dimensional coordinate spaces,
Aˆ = ∑
n1,n2,...,nN,n
0
1
,n
0
2
,...,nN0
A(n1,n2,...,nN),(n
0
1
,n
0
2
,...,n
0
N
)|φn1
ihφn
0
1
| ⊗|φn2
ihφn
0
2
| ⊗··· ⊗ |φnN
ihφn
0
N
|.
(11.6.14)
It is instructive to discuss at this point tensor products of vector and operators in
linear algebra terms, using the close analogy between the Hilbert space of physical
states and finite-dimensional vector spaces, where each ket corresponds to a column
vector, and a linear operator corresponds to a finite matrix. Let a and b be two vectors
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press146 The Postulates of Quantum Mechanics
whose dimensions are M and N, respectively. The tensor product between these vectors
is an M ×N dimensional vector, defined as
a⊗b =





a1
a2
.
.
.
aM





⊗





b1
b2
.
.
.
bN





≡




























a1





b1
b2
.
.
.
bN





a2





b1
b2
.
.
.
bN





.
.
.
aM





b1
b2
.
.
.
bN

































=




























a1b1
a1b2
.
.
.
a1bN
a2b1
a2b2
.
.
.
a2bN
.
.
.
aMb1
aMb2
.
.
.
aMbN




























. (11.6.15)
Notice that each element in a⊗b is associated with two indexes,
[a⊗b]k,l ≡ akbl
. (11.6.16)
Similarly, let A and B be two matrices whose dimensions are M2 and N
2
, respectively.
The tensor product between these matrices is an (MN)
2
-dimensional matrix, defined
as (e.g., for M = 2 and N = 3):
A⊗B =

a1,1 a1,2
a2,1 a2,2

⊗


b1,1 b1,2 b1,3
b2,1 b2,2 b2,3
b3,1 b3,2 b3,3


≡









a1,1


b1,1 b1,2 b1,3
b2,1 b2,2 b2,3
b3,1 b3,2 b3,3

 a1,2


b1,1 b1,2 b1,3
b2,1 b2,2 b2,3
b3,1 b3,2 b3,3


a2,1


b1,1 b1,2 b1,3
b2,1 b2,2 b2,3
b3,1 b3,2 b3,3

 a2,2


b1,1 b1,2 b1,3
b2,1 b2,2 b2,3
b3,1 b3,2 b3,3











=









a1,1b1,1 a1,1b1,2 a1,1b1,3 a1,2b1,1 a1,2b1,2 a1,2b1,3
a1,1b2,1 a1,1b2,2 a1,1b2,3 a1,2b2,1 a1,2b2,2 a1,2b2,3
a1,1b3,1 a1,1b3,2 a1,1b3,3 a1,2b3,1 a1,2b3,2 a1,2b3,3
a2,1b1,1 a2,1b1,2 a2,1b1,3 a2,2b1,1 a2,2b1,2 a2,2b1,3
a2,1b2,1 a2,1b2,2 a2,1b2,3 a2,2b2,1 a2,2b2,2 a2,2b2,3
a2,1b3,1 a2,1b3,2 a2,1b3,3 a2,2b3,1 a2,2b3,2 a2,2b3,3









(11.6.17)
Each element in the matrix is associated with four indexes,
[A⊗B](k,l),(k
0
,l
0) ≡ ak,k
0bl,l
0. (11.6.18)
Notice that any operator in a specific subspace can be mapped onto the multidimen￾sional space by a suitable tensor product with an identity operator. Consider, for
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press147 11.6 The Vector Space of Multidimensional Systems
example, the space defined by A⊗B (see, e.g., Eq. (11.6.17)). In this space the matrices
A and B are mapped onto A⊗I and I⊗B, respectively. Similarly, any vector in a specific
subspace can be mapped onto the multidimensional space, where the representations
of the two vectors, a and b, in the space of A⊗B correspond to rectangular matrices,
a⊗I and I⊗b, respectively, where
[a⊗I](k,l),l
0 ≡ akδl,l
0 ; [I⊗b](k,l),k
0 ≡ blδk,k
0. (11.6.19)
For example:
I⊗b =
h
1 0
0 1 i
⊗

b1
b2
b3

≡




b1 0
b2 0
b3 0
0 b1
0 b2
0 b3




a⊗I =
h
a1
a2
i
⊗

1 0 0
0 1 0
0 0 1 
≡










a1 0 0
0 a1 0
0 0 a1
a2 0 0
0 a2 0
0 0 a2










(11.6.20)
The following are useful identities associated with tensor products (see Ex. 11.6.1). Let
the matrices A and C be linear operators in a given vector space, where the matrices B
and D are linear operators in another vector space. We have
(A⊗B)(C⊗D) = AC⊗BD. (11.6.21)
Let c and d be vectors in these two different vector spaces, respectively. We have
(A⊗B)(c⊗d) = Ac⊗Bd (11.6.22)
(A⊗B)(I⊗d) = A⊗Bd ; (A⊗B)(c⊗I) = Ac⊗B. (11.6.23)
Let the vectors u and v be eigenvectors of the matrices A and B, associated with the
eigenvalues λu and λv, respectively; then,
(A⊗I+I⊗B)u⊗v = (λu +λv)u⊗v. (11.6.24)
It follows that an eigenvector of an operator, which is a sum over different operators
restricted to different subspaces, is a tensor product of the corresponding eigenvectors
of the subspace operators, where the eigenvalue is a sum over the eigenvalues associated
with the eigenvectors composing the tensor product. Notice that this is a generalization
of the property of separable Hamiltonians discussed in Ex. 4.3.4.
Exercise 11.6.1 Use the definitions in Eqs. (11.6.15–11.6.20) to prove the identities
given in Eqs. (11.6.21–11.6.24).
An Example: The Vector Space of a Particle in a
Three-Dimensional Coordinate Space
Let us consider a single point-particle of mass m in a three-dimensional physical space.
In classical mechanics the particle’s position is defined by the three Cartesian coordi￾nates r = (x, y,z) (a specific case of Eq. (11.6.1)), where in quantum mechanics the
particle’s position operator corresponds to
rˆ = (xˆ, yˆ,zˆ). (11.6.25)
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press148 The Postulates of Quantum Mechanics
Each of the position operators has a complete orthonormal system of eigenstates,
defined by the independent eigenvalue equations (a specific case of Eq. (11.6.4)),
xˆ|φxi = x|φxi ; ˆy|φyi = y|φyi ; ˆz|φzi = z|φzi. (11.6.26)
A unique particle position in the three-dimensional space corresponds, therefore, to a
tensor product state (a specific case of Eq. (11.6.5)),
|ϕri ≡ |φxi ⊗|φyi ⊗|φzi, (11.6.27)
where the particle’s state vector in the coordinate representation corresponds to the
wave function of the three position variables (a specific case of Eq. (11.6.8)),
ψ(x, y,z) = ψ(r) = hϕr|ψi. (11.6.28)
Introducing the identity operator in the three-dimensional coordinate space (a specific
case of Eq. (11.6.11)),
ˆI =
w
dr|ϕrihϕr| =
"
w∞
−∞
dx|φxihφx|
#
⊗
"
w∞
−∞
dy|φyihφy|
#
⊗
"
w∞
−∞
dz|φzihφz
|
#
, (11.6.29)
each state vector can be expanded as (see Ex. 11.6.2)
|ψi =
w
drψ(r)|ϕri =
w∞
−∞
dx w∞
−∞
dy w∞
−∞
dzψ(x, y,z)|φxi ⊗|φyi ⊗|φzi. (11.6.30)
Exercise 11.6.2 Use Eqs. (11.6.27–11.6.29) to derive Eq. (11.6.30).
Similar considerations apply to the particle’s momentum. In particular, the particle’s
momentum operator corresponds to
pˆ = (pˆx, pˆy, pˆz). (11.6.31)
Each component of the momentum operator defines a complete orthonormal system
of eigenstates,
pˆx|φpx
i = px|φpx
i ; ˆpy|φpy
i = py|φpy
i ; ˆpz
|φpz
i = pz
|φpz
i, (11.6.32)
where a unique particle momentum in the three-dimensional space corresponds to a
product of momentum eigenstates,
|ϕpi ≡ |φpx
i ⊗|φpy
i ⊗|φpz
i. (11.6.33)
The particle’s state vector in the momentum representation therefore corresponds to
the wave function of the three momentum variables,
ψ(px, py, pz) = ψ(p) = hϕp|ψi. (11.6.34)
Introducing the identity operator in the three-dimensional momentum space,
ˆI =
w
dp|ϕpihϕp| =
"
w∞
−∞
d px|φpx
ihφpx
|
#
⊗
"
w∞
−∞
d py|φpy
ihφpy
|
#
⊗
"
w∞
−∞
d pz
|φpz
ihφpz
|
#
,
(11.6.35)
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press149 11.6 The Vector Space of Multidimensional Systems
any state vector can be expanded in terms of the momentum eigenstates,
|ψi =
w
dpψ(p)|ϕpi =
w∞
−∞
d px
w∞
−∞
d py
w∞
−∞
d pzψ(px, py, pz)|φpx
i⊗|φpy
i⊗|φpz
i. (11.6.36)
Notice that the position (Eq. (11.6.30)) and momentum (Eq. (11.6.36)) representations
of the particle’s state in the three-dimensional coordinate space can be transformed to
any other representation by a resolution of the identity operator in terms of a complete
orthonormal system of any Hermitian operator eigenstates (Eq. (11.6.12)).
Exercise 11.6.3 Use the position and momentum representations of |ψi in the three￾dimensional space(Eqs. (11.6.30, 11.6.36)) and the explicit position representation of
the momentum eigenstates (Eq. (11.5.16)) to show that the functions ψ(r) = ψ(x, y,z)
and ψ(p) = ψ(px, py, pz) are related to each other by the three-dimensional Fourier
transforms,
ψ(p) = w
drψ(r)

1
√
2πh¯
3
e
−ipr/h¯
ψ(r) = w
dpψ(p)

1
√
2πh¯
3
e
ipr/h¯
(Compare to the one-dimensional case, Eqs. (11.5.22, 11.5.23)).
We now consider the representation of general operators in the three-dimensional
coordinate space. Formally, any resolution of the identity can be invoked, and any
operator can be represented according to Eq. (11.6.14). For example, in the coordinate
representation,
Aˆ =
w
dr
w
dr
0
|ϕrihϕr|Aˆ|ϕr
0ihϕr
0| =
w
dr
w
dr
0A(r, r
0
)|ϕrihϕr
0|, (11.6.37)
and in the momentum representation,
Aˆ =
w
dp
w
dp
0
|ϕpihϕp|Aˆ|ϕp
0ihϕp
0| =
w
dp
w
dp
0 A(p,p
0
)|ϕpihϕp
0|, (11.6.38)
where A(r, r
0
) = hϕr|Aˆ|ϕr
0i and A(p, p
0
) = hϕp|Aˆ|ϕp
0i are continuous (matrix) represen￾tations of the operator Â (see Eqs. (11.5.24, 11.5.25)).
Let us focus on local operators, such as the scalar potential energy:
Vˆ = V(rˆ) = V(xˆ, yˆ,zˆ) (11.6.39)
When discussing a one-dimensional coordinate space, we noticed that the matrix rep￾resentation of the potential energy is diagonal in the position representation (see
Ex. (11.5.1)). To show that this holds also in the three-dimensional space, we restrict
the discussion to analytic functions, where the classical potential energy function can
be expanded in a power series, y(x, y,z) = ∑
i, j,k
vi, j,kx
i
y
j
z
k
. Since each product x
i
, y
j
,z
k
translates to a tensor product of independent quantum mechanical operators, each
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press150 The Postulates of Quantum Mechanics
associated with a different one-dimensional coordinate space, the potential energy
operator obtains the form
Vˆ =
∞
∑
i, j,k=0
vi, j,k(xˆ)
i ⊗(yˆ)
j ⊗(zˆ)
k
. (11.6.40)
Using this expansion and Eq. (11.6.37), we can readily see that the potential energy
remains diagonal in the coordinate representation in the three-dimensional coordinate
space as well (the generalization to higher dimensions is straightforward):
hϕr|Vˆ |ϕr
0i = hφx| ⊗ hφy| ⊗ hφz
| ∑
i, j,k
vi, j,k(xˆ)
i ⊗(yˆ)
j ⊗(zˆ)
k
|φx
0i ⊗|φy
0i ⊗|φz
0i
= ∑
i, j,k
vi, j,khφx|(xˆ)
i
|φx
0ihφy|(yˆ)
j
|φy
0ihφz
|(zˆ)
k
|φz
0i
= ∑
i, j,k
vi, j,kx
i
y
j
z
k
δ(x−x
0
)δ(y−y
0
)δ(z−z
0
)
= V(x, y,z)δ(x−x
0
)δ(y−y
0
)δ(z−z
0
)
= V(r)δ(r−r
0
). (11.6.41)
Consequently, in the coordinate representation, the potential energy operation on any
state vector in the three-dimensional coordinate space translates into a multiplication,
hϕr|Vˆ |ψi =
w
dr
0
hϕr|Vˆ |ϕr
0ihϕr
0|ψi =
w
dp
0V(r)δ(r−r
0
)ψ(r
0
) = V(r)ψ(r). (11.6.42)
A parallel argument holds with respect to the nonlocal kinetic energy operator, when
the momentum representation is considered:
Tˆ = T(pˆ) = T(pˆx, pˆy, pˆz). (11.6.43)
In this case, the classical kinetic energy function reads T(px, py, pz) = 1
2m
(p
2
x + p
2
y + p
2
z
),
and the corresponding quantum mechanical operator in the three-dimensional coor￾dinate space is a sum of tensor products of operators in the different one-dimensional
coordinate spaces:
Tˆ =
1
2m

(pˆx)
2 ⊗ ˆIy ⊗ ˆIz + ˆIx ⊗(pˆy)
2 ⊗ ˆIz + ˆIx ⊗ ˆIy ⊗(pˆz)
2

. (11.6.44)
Using this expansion and Eq. (11.6.38), we can readily see that the kinetic energy is
diagonal in the momentum representation, namely
hϕp|Tˆ|ϕp
0i =
1
2m
.
hφpx
| ⊗ hφpy
| ⊗ hφpz
|((pˆx)
2 ⊗ ˆIy ⊗ ˆIz + ˆIx ⊗(pˆy)
2 ⊗ ˆIz + ˆIx ⊗ ˆIy ⊗(pˆz)
2
)|φp
0
x
i ⊗|φp
0
y
i ⊗|φp
0
z
i
=
1
2m
(p
2
x + p
2
y + p
2
z
)δ(px − p
0
x
)δ(py − p
0
y
)δ(pz − p
0
z
). (11.6.45)
Consequently, in the momentum representation, the kinetic energy operation on any
state vector in the three-dimensional coordinate space translates into a multiplication:
hϕp|Tˆ|ψi =
w
dp
0
hϕp|Tˆ|ϕp
0ihϕp
0|ψi =
w
dp
0 p
2
2m
δ(p−p
0
)ψ(p
0
) = p
2
2m
ψ(p). (11.6.46)
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press151 11.7 Ensemble Measurements and the Uncertainty Principle
Finally, in the coordinate representation, the kinetic energy operation in the three￾dimensional coordinate space obtains the familiar form,
hϕr|Tˆ|ψi =
−h¯
2
2m
∆ˆ
rψ(r), (11.6.47)
where ∆ˆ
r =

∂
2
∂ x
2 +
∂
2
∂ y
2 +
∂
2
∂ z
2

is the Laplacian (see Ex. (11.6.5)).
Exercise 11.6.4 Given that Vˆ = V(rˆ), and T = T(pˆ), rederive Eqs. (11.6.42) and
(11.6.46) by using the Hermiticity of the corresponding operators.
Exercise 11.6.5 (a) Use Eq. (11.6.46) and the explicit position representation of the
momentum eigenstates (Eq. ( 11.5.16)) to show that hϕr|Tˆ|ψi =
r
dp
p
2
2m
e
ipr/h¯
(
√
2πh¯)
3ψ(p).
(b) Show that p
2
e
ipr/h¯ = −h¯
2

∂
2
∂ x
2 +
∂
2
∂ y
2 +
∂
2
∂ z
2

e
ipr/h¯
.
(c) Use the results of (a) and (b), as well as the Fourier expansion of ψ(r) in Ex. 11.6.3,
to obtain Eq. (11.6.47).
11.7 Ensemble Measurements and the Uncertainty Principle
The postulates as previously formulated refer to idealized measurements in which a
single measurement is performed on a single system, characterized by a single solu￾tion to the Schrödinger equation. In the vast majority of experiments, the situation
in more involved. Typically, the limited accuracy, the large size, and the experimen￾tal noise associated with a measuring device exclude the isolation of a single system.
Instead, the measurement records the result of a simultaneous measurement on a large
number of systems. When the systems are identical and independent of each other, this
is equivalent to a repeated experiment on a set of identically prepared systems. Either
way, the outcome of the measurement corresponds to an ensemble of systems. In Chap￾ter 16 we shall address the most general case in which different systems in the ensemble
can be associated with different solutions to the Schrödinger equation. Here we focus
on a pure ensemble, where all the systems prior to the measurement are identical and
correspond to the same solution of the Schrödinger equation. Given the probabilis￾tic nature of any single measurement on a single system, the outcome of an ensemble
measurement is associated with a statistical distribution of measured values. It is cus￾tomary to represent the distribution in terms of its first and second moments, namely
the averaged measured value, and the measurement uncertainty, which is commonly
associated with the standard deviation of the distribution about the average.
For an infinitely large number of identical systems, each associated with the same
state, |ψ(t)i, the ensemble averaged value of an observable represented by the operator
Aˆ, measured at time t, reads
hA(t)i = hψ(t)|Aˆ|ψ(t)i. (11.7.1)
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press152 The Postulates of Quantum Mechanics
hA(t)i is often termed the “expectation value” (or “expected value”) of Aˆ in the state
|ψ(t)i.
Exercise 11.7.1 Prove that the expectation value of a Hermitian operator is real-valued.
Exercise 11.7.2 A system is found in a stationary state, |ψE(t)i = e
−iEt
h¯ |φEi
(Eq. (4.3.5)). Show that the expectation value of any operator is time-independent.
Exercise 11.7.3 Show that the expectation value of a local operator V(xˆ) (see
Ex. 11.5.1) in a system associated with the wave function ψ(x,t) reads hV(t)i =
r∞
−∞
ψ
∗
(x,t)V(x)ψ(x,t)dx.
Exercise 11.7.4 Prove that the expectation value of the momentum operator, pˆx,
vanishes for a system in a bound stationary state, ψE(x,t) = φE(x)e
−iEt/h¯
, where
Im[φ
∗
E
(x)
d
dx
φE(x)] = 0.
Exercise 11.7.5 Use the time-dependent Schrödinger equation, ih¯
∂
∂t
|ψ(t)i =
h
pˆ
2
x
2m +V(xˆ)
i
|ψ(t)i, and prove the Ehrenfest theorem for a particle of mass m, in the presence of a
one-dimensional potential energy, V(x) :
∂
∂t
hx(t)i =
hpx(t)i
m
and ∂
∂t
hpx(t)i = −


dV
dx
(t)

.
Show that for a quadratic potential energy V(x) = α +βx+γx
2
, the quantum mechanical
expectation values follow the Hamilton equations of classical mechanics.
Notice that Eq. (11.7.1) is not a new postulate, but rather a compact representation
of the expectation value, which is consistent with the postulates. This can be readily
verified by expanding the state vector of the system in the complete orthogonal set
of eigenvectors of Aˆ, the operator that represents the measured observable, Aˆ|φni =
γn|φni. (For simplicity, and without loss of generality, here Â is assumed to have a
discrete, nondegenerate spectrum.) Using |ψ(t)i = ∑
n
an(t)|φni and hψ(t)| = ∑
n
a
∗
n
(t)hφn|,
we obtain (Ex. 11.7.6)
hA(t)i = ∑n
|an(t)|
2
γn. (11.7.2)
Exercise 11.7.6 Derive Eq. (11.7.2).
According to the postulates, each single measurement yields one of Aˆ’s eigenvalues,
γn, at a probability, Pγn
(t) = |an(t)|
2 = |hφn|ψ(t)i|2 Therefore, the expectation value
as defined in Eq. (11.7.1) consistently equals the weighted average value over the
distribution of single measurements.
Given the definition of the averaged measured value of any operator (Eq. (11.7.1)),
the expression of the standard deviation in terms of the averaged square of the
deviation from the average follows naturally,
∆A(t) = q
hψ(t)|(Aˆ − hA(t)i)
2
|ψ(t)i =
q
hA2(t)i− hA(t)i
2
. (11.7.2)
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press153 11.7 Ensemble Measurements and the Uncertainty Principle
Exercise 11.7.7 A system is found in a stationary state, |ψE(t)i = e
−iEt
h¯ |φEi (Eqs. (4.3.4,
4.3.5)). Show that: (a) The probability of measuring the energy E is 1. (b) The standard
deviation in energy measurement, as defined in Eq. (11.7.2), vanishes.
Notice that when the state of the system happens to be an eigenstate of the opera￾tor representing the observable (i.e., |ψ(t)i = a(t)|φni), the uncertainty vanishes (see
Ex. 11.7.7). This means that the observable associated with Aˆ can be measured, in
principle (excluding the limitations of the measuring device), with absolute precision.
However, even if the system was prepared to be in one of the eigenstates of Aˆ at the mea￾surement time, such that the observable associated with Aˆ can be measured with absolute
precision, other observables are likely to exhibit measurement uncertainties. This holds
since, in general, the eigenstate of Aˆ would not be an eigenstate of another opera￾tor. Specifically, if the state of the system, |ψ(t)i, is an eigenstate of Aˆ, but not of Bˆ,
the observable associated with Bˆ cannot be measured with absolute certainty. Only if
|ψ(t)i is a common eigenstate of both Aˆ and Bˆ can the two measurements, in principle,
be performed with absolute certainty. Moreover, the results would not depend on the
order of measurements, since in each measurement (of either Aˆ or Bˆ) the state of the
system would be unaltered (|ψ(t)i would “collapse to itself ”).
Situations in which two operators share common eigenstates are not uncommon. In
Ex. 6.4.1 we concluded that a nondegenerate eigenfunction of an operator Â is also
an eigenfunction of any operator Bˆ that commutes with Â ([Aˆ,Bˆ] = 0). This claim can
be readily generalized to show that any commuting operators have a common set of
eigenvectors [4.3]. Indeed, we already encountered examples of differential operators
commuting with symmetry operators and having a common set of eigenfunctions (see,
e.g., Ex. 9.2.1). For example, in Chapter 10, we saw that the hydrogen-like atomic
orbitals, ψn,l,m(r,θ,φ), are common eigenfunctions of the commuting Hamiltonian
and angular momentum operators, Hˆ, Lˆ 2
, and Lˆ
z
.
In general, however, measurements are associated with uncertainties that reflect an
inherent probabilistic nature of the outcome of single measurements. When two observ￾ables are associated with noncommuting operators, simultaneous certainty in their
measurement is excluded. Even for commuting operators, the possibility for simultane￾ous certainty depends on the specific system state vector. The fundamental limitation
on the certainty in the simultaneous measurement of two observables is commonly
referred to as “Heisenberg’s uncertainty principle.” Formally, expressing the uncer￾tainty as the standard deviation (Eq. (11.7.2)), the following inequality holds (see
Ex. 11.7.8 for the proof) for any linear Hermitian operators, Â and Bˆ, and any
normalizable (proper or improper) state vector |ψ(t)i:
[∆A(t)]2
[∆B(t)]2 ≥
−hψ(t)|[Aˆ,Bˆ]|ψ(t)i
2
4
(11.7.3)
Exercise 11.7.8 In order to prove Eq. (11.7.3): (a) Show that for any operator, Oˆ, and
its Hermitian conjugate, Oˆ †
, and for any state vector, the expectation value of Oˆ †Oˆ is
nonnegative, namely hψ|Oˆ †Oˆ|ψi ≥ 0. (b) Given two Hermitian linear operators, Xˆ and
Yˆ, and a real-valued scalar, α, use (a) and the definition, Oˆ ≡ Xˆ − iαYˆ, to show that
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press154 The Postulates of Quantum Mechanics
hψ|Xˆ 2
|ψi+α
2
hψ|Yˆ 2
|ψi −iαhψ|[Xˆ,Yˆ]|ψi ≥ 0. (c) Since (b) holds for any real α, show
that −hψ|[Xˆ,Yˆ]|ψi
2
4 ≤ hψ|Xˆ 2
|ψihψ|Yˆ 2
|ψi. (d) Let Xˆ ≡ Aˆ − hψ|Aˆ|ψi, and Yˆ ≡ Bˆ− hψ|Bˆ|ψi,
where Aˆ and Bˆ are any linear Hermitian operators. Use (c) and the definition of the
standard deviation (Eq. (11.7.2)) to obtain the uncertainty inequality, Eq.(11.7.3).
In line with the preceding discussion, simultaneous absolute precision in the mea￾surement of two observables can only be reached, in principle, if the corresponding
operators commute, and therefore [∆A(t)]2
[∆B(t)]2 ≥ 0, where the equality corresponds
to the case of |ψ(t)i being a common eigenfunction of both Aˆ and Bˆ, which means
∆A(t) = ∆B(t) = 0. When [Aˆ,Bˆ] 6= 0, Eq. (11.7.3) means that [∆A(t)]2
[∆B(t)]2 > 0 for
any nontrivial |ψ(t)i (Ex. 11.7.9). Namely, there is an intrinsic bound for simultane￾ous certainty. A well-known example is the Heisenberg relation between the position
and the linear momentum uncertainties for a particle moving along a given direction
(x). Using [xˆ, pˆx] = ih¯, Eq. (11.7.3) yields
∆x(t)·∆p(t) ≥
h¯
2
. (11.7.4)
Exercise 11.7.9 Show that −hψ(t)|[Aˆ,Bˆ]|ψ(t)i
2 > 0 for any noncommuting Hermi￾tian operators, Aˆ and Bˆ, [Aˆ,Bˆ] 6= 0, and |ψ(t)i 6= 0. (Show that hψ(t)|[Aˆ,Bˆ]|ψ(t)i is an
imaginary number.)
Exercise 11.7.10 A particle is associated at a certain time with a normalized Gauss￾ian wave function, ψ(x) = 
1
2πσ2
1/4
e
−x
2
4σ2
. (a) Calculate the position and momentum
standard deviations as defined by Eq. (11.7.2) and verify that their multiplication satis￾fies Eq. (11.7.4). (You can use the following integrals: r∞
−∞
e
−βx
2
dx =
qπ
β
;
r∞
−∞
x
2
e
−βx
2
=
√
π
2
β
−3/2
.) (b) The Gaussian wave function is sometimes referred to as the minimal
uncertainty state for the particle. Explain this term in view of the result of (a).
Bibliography
[11.1] Y. Aharonov, D. Z. Albert, and L. Vaidman, “How the result of a measure￾ment of a component of the spin of a spin-1/2 particle can turn out to be 100,”
Physical Review Letters 60, 1351 (1988).
[11.2] P. A. M. Dirac, “The Principles of Quantum Mechanics” (Oxford University
Press, 1958).
[11.3] L. Mirsky, “An Introduction to Linear Algebra” (Dover, 1990).
[11.4] C. F. Van Loan, “The ubiquitous Kronecker product,” Journal of Computa￾tional and Applied Mathematics 123, 85 (2000).
https://doi.org/10.1017/9781108877787.012 Published online by Cambridge University Press12 Approximation Methods
12.1 Perturbation Theory for the Time-Independent Schrödinger
Equation
So far, we have used the tools of quantum mechanics for explaining phenomena on the
nanoscale, by associating different systems with simple model Hamiltonians and learn￾ing about them from the analytic solutions of the corresponding Schrödinger equation.
This strategy of mapping a complex problem onto a simple, tractable model Hamil￾tonian is indeed essential for understanding the physics. Yet, in most cases, analytic
solutions of the Schrödinger equation are not known even when the underlying model
Hamiltonian is relatively simple, and numerical solutions to the Schrödinger equa￾tion are commonly practiced. In other cases, the complexity of the system is so large
that minimal models are searched for, which capture only the essential ingredients of
the system’s Hamiltonian. In all these cases, approximation methods must be invoked
for solving the relevant Schrödinger equation. The time-dependent Schrödinger equa￾tion will be discussed in this context in Chapters 15–20, while here we focus on the
time-independent Schrödinger equation. One of the most important approximation
methods is perturbation theory. The basic idea is to utilize the known solutions of
a presumably simpler problem to approximate the solutions of a more complex one,
which is too hard to solve “directly.”
The perturbation theory due to Rayleigh and Schrödinger provides a formal frame￾work for expressing the eigenvalues and eigenfunctions of the time-independent
Schrödinger equation for a given Hamiltonian, Hˆ, in terms of the known solutions of
the equation for another (“zero-order”) Hamiltonian, Hˆ
0, in the same space. The two
Hamiltonians can be formally connected via a continuous parameter, λ, which obtains
the values 0 and 1 for Hˆ
0 and Hˆ, respectively. When the eigenvalues and eigenfunctions
are analytic functions of λ on a contour, 0 ≤ λ ≤ 1, they can be expanded as a power
series in λ around zero. While, in general, the expansion may be infinite, perturbation
theory becomes useful when the expansion converges at the lowest orders. In this case,
Hˆ
0 and Hˆ are sufficiently close in some sense (to be discussed in what follows), where
Hˆ
1 = Hˆ −Hˆ
0 is referred to as a “perturbation” to Hˆ
0.
For the zero-order Hamiltonian, Hˆ
0 = Hˆ(λ)|λ=0
, the stationary solutions to the
Schrödinger equation are assumed to be known,
Hˆ
0


ψ
(0)
n
E
= E
(0)
n


ψ
(0)
n
E
, (12.1.1)
155
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press156 Approximation Methods
Ftigure 12.1.1 A schematic representation of the (known) energy levels of a zero-order Hamiltonian and the corresponding
(unknown) energy levels of a full Hamiltonian. Roughly, perturbation theory is accurate when there is a one-to-one
correspondence between the two ladders, and when the change at each of the energy levels is small in comparison to
the energy spacing between nearby levels.
where
D
ψ
(0)
m


ψ
(0)
n
E
= δm,n. (12.1.2)
We seek for the corresponding solutions to the Schrödinger equation with the full
Hamiltonian, Hˆ = Hˆ(λ)|λ=1
(see Fig. 12.1.1),
Hˆ|ψn
E
= En|ψni. (12.1.3)
By introducing explicitly a linear dependence in the parameter λ,
Hˆ(λ) = Hˆ
0 +λHˆ
1, (12.1.4)
Eq. (12.1.3) can be written as
[Hˆ
0 +λHˆ
1]|ψn(λ)i = En(λ)|ψn(λ)i, (12.1.5)
where the solutions are expanded (up to normalization) in powers of λ,
En(λ) =
∞
∑
l=0
λ
lE
(l)
n (12.1.6)
|ψn(λ)i =
∞
∑
l=0
λ
l


ψ
(l)
n
E
. (12.1.7)
The terms with l > 0 are corrections to E
(0)
n and


ψ
(0)
n
E
, where E
(l)
n and


ψ
(l)
n
E
are referred to as the lth-order corrections to the energy and the wave function,
respectively. Substitution of the expansions Eq. (12.1.6) and (12.1.7) in the Schrödinger
equation, Eq. (12.1.5), and changing the summation index, we obtain (Ex. 12.1.1)
∞
∑
l=0
h
Hˆ
0


ψ
(l)
n
E
+ (1−δl,0)Hˆ
1


ψ
(l−1)
n
E
−
l
∑
l
0=0
E
(l
0
)
n


ψ
(l−l
0
)
n
Eiλ
l = 0 (12.1.8)
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press157 12.1 Perturbation Theory for the Time-Independent Schrödinger Equation
Since this result must hold for any 0 ≤ λ ≤ 1, the coefficients of the different pow￾ers, λ
l
(for l = 0,1,2,...), should all vanish independently. For l = 0, Eq. (12.1.1) is
reproduced, and for the higher powers, Eq. (12.1.8) yields
Hˆ
0


ψ
(l)
n
E
=
l
∑
l
0=0
(E
(l
0
)
n −δl
0
,1Hˆ
1)


ψ
(l−l
0
)
n
E
; l > 0. (12.1.9)
Exercise 12.1.1 Derive Eq. (12.1.8).
Let us consider first the corrections to a nondegenerate eigenvalue of Hˆ
0, correspond￾ing to the energy, E
(0)
n , where the zero-order vector,


ψ
(0)
n
E
, is defined uniquely (up to a
constant multiplication). Noticing that the eigenstates of Hˆ
0 are a complete orthonor￾mal set (Eq. (12.1.2)), we can use them for expanding the (unnormalized) eigenfunc￾tions of Hˆ, that is, |ψn(λ)i =


ψ
(0)
n
E
+ ∑
m6=n
bm(λ)


ψ
(0)
m
E
. Comparing to Eq. (12.1.7), it
follows that
∞
∑
l>0
λ
l


ψ
(l)
n
E
∝ ∑
m6=n
bm(λ)


ψ
(0)
m
E
, which means that for l > 0, the lth-order
corrections to the wave function |ψn(λ)i are orthogonal to


ψ
(0)
n
E
, namely
D
ψ
(0)
n


ψ
(l)
n
E
= δl,0. (12.1.10)
Projecting Eq. (12.1.9) onto


ψ
(0)
n
E
, using Eq. (12.1.10) and the hermiticity of Hˆ
0, we
obtain (Ex. 12.1.2)
E
(l)
n =
D
ψ
(0)
n



Hˆ
1


ψ
(l−1)
n
E
. (12.1.11)
The lth-order correction to the energy, is shown to depend on the wave function,
corrected up to the order l −1. The corrections, n

ψ
(l)
n
Eo, can be obtained by a recur￾sive solution of Eq. (12.1.9). Using an orthonormal set of Hˆ
0 eigenstates (excluding


ψ
(0)
n
E
, in accordance with Eq. (12.1.10)), each correction can be expanded as a linear
combination,


ψ
(l)
n
E
=
∞
∑
n
06=n=0
a
(l)
n
0


ψ
(0)
n
0
E
; a
(l)
n
0 =
D
ψ
(0)
n
0


ψ
(l)
n
E
. (12.1.12)
An explicit equation for the coefficients n
a
(l)
n
0
o
is obtained by substituting the expan￾sion in Eq. (12.1.9) and projecting the two sides of the equation onto the corresponding
eigenstates of Hˆ
0,


ψ
(0)
n
0
E
, with n 6= n
0
. Since E
(0)
n is nondegenerate, E
(0)
n 6= E
(0)
n
0 for any
n
0
, and the result reads (Ex. 12.1.3)
a
(l)
n
0 =
D
ψ
(0)
n
0



Hˆ
1


ψ
(l−1)
n
E
E
(0)
n −E
(0)
n
0
−
l
∑
l
0=1
D
ψ
(0)
n
0


ψ
(l−l
0
)
n
E
E
(l
0
)
n
E
(0)
n −E
(0)
n
0
. (12.1.13)
Substitution of Eq. (12.1.12) in Eq. (12.1.13) yields explicit expressions for the correc￾tions to the wave function. The results for the first and second orders read (Ex. 12.1.4)
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press158 Approximation Methods


ψ
(1)
n
E
= ∑
n
06=n
D
ψ
(0)
n
0



Hˆ
1


ψ
(0)
n
E
E
(0)
n −E
(0)
n
0


ψ
(0)
n
0
E
(12.1.14)


ψ
(2)
n
E
= ∑
n
006=n
∑
n
06=n
D
ψ
(0)
n
00 |Hˆ
1 −E
(1)
n


ψ
(0)
n
0 i
E
(0)
n −E
(0)
n
00
D
ψ
(0)
n
0



Hˆ
1|ψ
(0)
n
E
E
(0)
n −E
(0)
n
0


ψ
(0)
n
00 E
. (12.1.15)
Using Eq. (12.1.11), the corresponding corrections for the energy read
E
(1)
n =
D
ψ
(0)
n



Hˆ
1


ψ
(0)
n
E
(12.1.16)
E
(2)
n = ∑
n
06=n



D
ψ
(0)
n
0



Hˆ
1


ψ
(0)
n
E
|
2
E
(0)
n −E
(0)
n
0
(12.1.17)
E
(3)
n = ∑
n
006=n
∑
n
06=n
D
ψ
(0)
n



Hˆ
1


ψ
(0)
n
00 EDψ
(0)
n
00



Hˆ
1 −E
(1)
n


ψ
(0)
n
0
EDψ
(0)
n
0



Hˆ
1


ψ
(0)
n
E

E
(0)
n −E
(0)
n
0
E
(0)
n −E
(0)
n
00  . (12.1.18)
Exercise 12.1.2 (a) The projection of the vector Hˆ
0


ψ
(l)
n
E
, appearing in the left-hand
side of Eq. (12.1.9), on the vector


ψ
(0)
n
E
is the inner product, D
ψ
(0)
n



Hˆ
0


ψ
(l)
n
E
. Use the
Hermiticity of Hˆ
0 and Eqs. (12.1.1, 12.1.10) to show that this projection is zero. (b) Use
the result obtained in (a) to show that projection of


ψ
(0)
n
E
on the vector appearing in the
right-hand side of Eq. (12.1.9) leads to Eq. (12.1.11).
Exercise 12.1.3 Substitute the expansion of


ψ
(l)
n
E
(Eq. (12.1.12)) into Eq. (12.1.9),
and project the two sides of the resulting equation on


ψ
(0)
n
0
E
with n 6= n
0
. Derive
Eq. (12.1.13) for the expansion coefficients, considering that E
(0)
n is a nondegenerate
eigenvalue of Hˆ
0.
Exercise 12.1.4 (a) Use Eqs. (12.1.12, 12.1.13) to derive Eq. (12.1.14, 12.1.15). (b)
Use the results of (a) and Eq. (12.1.11) to obtain Eqs. (12.1.16–12.1.18).
The case where the eigenvalue of Hˆ
0 is degenerate (N-fold, with N > 1), requires a
special consideration (see the discussions of degenerate states in Sections 4.6 and 5.4).
In this case, the zero-order wave functions corresponding to the energy E
(0)
n are not
uniquely defined in the sense that they can be taken as any linear combination of a
finite set of N orthogonal vectors (a basis) in the degenerate subspace (see Ex. 4.6.3).
Choosing such a basis, n

ψ
(0)
k
Eo, where
Hˆ
0


ψ
(0)
k
E
= E
(0)
n


ψ
(0)
k
E
;
D
ψ
(0)
k
0


ψ
(0)
k
E
= δk
0
,k
; k, k
0 ∈ 1,2,...,N, (12.1.19)
a general set of N orthonormal zero-order wave functions is therefore expressed as
linear combinations:


ψ
(0)
j
E
=
N
∑
k=1
a
(0)
k, j


ψ
(0)
k
E
. (12.1.20)
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press159 12.1 Perturbation Theory for the Time-Independent Schrödinger Equation
Our task is to derive equations for the corresponding lth-order corrections that
approximate the eigenvalues and eigenfunctions of the full Hamiltonian, Hˆ. Using a
derivation identical to the one outlined in Eqs. (12.1.1–12.1.9), where E
(l)
n and


ψ
(l)
n
E
are replaced by, E
(l)
j
and


ψ
(l)
j
E
, respectively, we obtain the following equations for E
(l)
j
and


ψ
(l)
j
E
:
Hˆ
0


ψ
(l)
j
E
=
l
∑
l
0=0
(E
(l
0
)
j −δl
0
,1Hˆ
1)


ψ
(l−l
0
)
j
E
; l > 0. (12.1.21)
Recalling again that the eigenstates of Hˆ
0 are a complete orthonormal set in the rel￾evant space, any (unnormalized) eigenfunction of Hˆ,


ψj
E
can be formally expanded
as a linear combination,


ψj(λ)
E
=
N
∑
k=1
a
(0)
k, j
|ψ
(0)
k
E
+ ∑
k
06={1,2,...,N}
bk
0(λ)|ψ
(0)
k
0
E
. The set
n

ψ
(0)
k
Eo with k = 1,2,...,N spans the degenerate subspace, whereas n

ψ
(0)
k
0
Eo with
k
0 6= 1,2,...,N is the set of Hˆ
0 eigenstates that are orthogonal to that space. Compar￾ing this to the power expansion,


ψj(λ)
E
=
∞
∑
l=0
λ
l


ψ
(l)
j
E
, it follows that
∞
∑
l>0
λ
l


ψ
(l)
j
E
∝
∑
k
06={1,2,...,N}
bk
0(λ)


ψ
(0)
k
0
E
, which means that for l > 0, the lth-order corrections to the
wave function


ψj(λ)
E
are orthogonal to the degenerate subspace, namely
D
ψ
(0)
k


ψ
(l)
j
E
= a
(0)
k, j
δl,0 ; k ∈ 1,2,...,N. (12.1.22)
Substitution of the expansion (Eq. 12.1.20) in Eq. (12.1.21) for l = 1, and project￾ing the two sides of the equation on the set which spans the degenerate subspace,
n

ψ
(0)
k
Eo, we obtain the following set of equations (Ex. 12.1.5) for the expansion
coefficients:
N
∑
k
0=1
D
ψ
(0)
k



Hˆ
1


ψ
(0)
k
0
E
a
(0)
k
0
, j = E
(1)
j
a
(0)
k, j
; k ∈ 1,2,...,N (12.1.23)
Defining a square matrix, [H1]k,k
0 ≡
D
ψ
(0)
k



Hˆ
1


ψ
(0)
k
0
E
, and a vector, h
a
(0)
j
i
k
= a
(0)
k, j
in the
N-dimensional degenerate subspace, Eq. (12.1.21) translates to an algebraic eigenvalue
equation,
H1a
(0)
j = E
(1)
j
a
(0)
j
, (12.1.24)
where H1 is the matrix representation of the perturbation operator in a selected
orthonormal basis for the degenerate subspace.
It follows that the first-order corrections to the energy are the eigenvalues of H1:
E
(1)
1
,E
(1)
2
,...E
(1)
N
. The corresponding eigenvectors, a
(0)
1
,a
(0)
2
,a
(0)
N
, are specific sets of
coefficients, definingspecific zero-order states,
E
(1)
j ↔


ψ
(0)
j
E
=
N
∑
k=1
h
a
(0)
j
i
k


ψ
(0)
k
E
. (12.1.25)
Notice that any linear combination of n

ψ
(0)
k
Eo with k = 1,2,...,N is an eigenvector
of Hˆ
0, but only specific linear combinations, satisfying Eq. (12.1.25), are consistent with
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press160 Approximation Methods
the expansions of the eigenvalues and eigenvectors of Hˆ, in powers of λ. While these
specific zero-order states are degenerate with respect to Hˆ
0, they are generally associ￾ated with different first-order corrections to the energy. In such a case the perturbation
is said to “remove the degeneracy” between these states (see Fig. 12.1.1). Importantly,
the degeneracy is not necessarily removed. It may happen (see some of the following
examples) that some of the eigenvalues of H1 are zeros, which implies that the first￾order corrections vanish, or it may happen that H1 has nonzero but still degenerate
eigenvalues.
Exercise 12.1.5 (a) Show that projecting Eq. (12.1.21) with l = 1 on the orthonormal
set of degenerate vectors, defined in Eq. (12.1.19), yields hψ
(0)
k
|(E
(1)
j − Hˆ
1)|ψ
(0)
j
i = 0.
(b) Use the expansion, Eq. (12.1.20), to derive Eq. (12.1.23).
Exercise 12.1.6 (a) Use the orthonormality of the basis states (Eq. (12.1.19)) and
recall that the eigenvectors of any Hermitian matrix (e.g.,H1) can be chosen orthonormal,
(a
(0)
j
, a
(0)
j
0 ) =
N
∑
k=1
[a
(0)
j
]
∗
k
· [a
(0)
j
0
]k = δ j, j
0 , to prove that the vectors defined in Eq. (12.1.25)
can be chosen orthonormal, namely hψ
(0)
j
|ψ
(0)
j
0 i = δ j, j
0 . (b) Show that for a normalized
vector defined in Eq. (12.1.25), the first-order correction to the energy can be expressed
as for a nondegenerate state (Eq. (12.1.16)), namely E
(1)
j = hψ
(0)
j
|Hˆ
1|ψ
(0)
j
i.
The higher-order corrections, namely |ψ
(l)
j
i for l > 0 and E
(l)
j
for l > 1, can be obtained
as in the case of nondegenerate zero-order states. Projecting the two sides of Eq. (12.1.21)
on any of the zero-order solutions {|ψ
(0)
j
i} defined in Eq. (12.1.25), we obtain the
equation for the corrections to the energy (analogous to Eq. (12.1.11)),
E
(l)
j = hψ
(0)
j
|Hˆ
1|ψ
(l−1)
j
i. (12.1.26)
The corrections to the wave functions for l > 0 can be obtained by expanding them in
the set of Hˆ
0 eigenstates, excluding the degenerate subspace, namely
|ψ
(l)
j
i = ∑
k
06={1,2,...,N}
a
(l)
k
0
, j
|ψ
(0)
k
0 i ; a
(l)
k
0
, j = hψ
(0)
k
0
|ψ
(l)
j
i. (12.1.27)
Substituting the expansions in Eq. (12.1.21) and projecting the two sides of the equa￾tion on the set {|ψ
(0)
k
0 i} with k
0 6= 1,2,...,N, we obtain the following expression
(analogous to Eq. (12.1.13)) for the expansion coefficients (see Ex. 12.1.3), recalling
that E
(0)
n 6= E
(0)
k
0
, since all {|ψ
(0)
k
0 i} are external to the degenerate subspace:
a
(l)
k
0
, j =
hψ
(0)
k
0
|Hˆ
1|ψ
(l−1)
j
i
E
(0)
n −E
(0)
k
0
−
l
∑
l
0=1
hψ
(0)
k
0
|ψ
(l−l
0
)
j
iE
(l
0
)
n
E
(0)
n −E
(0)
k
0
. (12.1.28)
Before turning to some practical examples of how perturbation theory is used,
let us discuss the meaning of its “working equations,” focusing on the lowest-order
corrections. The first-order correction to the energy turns out to be the average of
the perturbation (see Eq. (12.1.16) and Ex. 12.1.6). Indeed, given a system Hamil￾tonian, Hˆ = Hˆ
0 + λHˆ
1, an energy can be associated with any state vector by means
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press161 12.2 Perturbation Theory in Action
of the Hamiltonian expectation value (see Eq. (11.7.1)). Considering specifically the
normalized zero-order state, |ψ
(0)
n i, the associated energy reads
En ≈ hψ
(0)
n |Hˆ|ψ
(0)
n i = hψ
(0)
n |Hˆ
0 +λHˆ
1|ψ
(0)
n i = E
(0)
n +λhψ
(0)
n |Hˆ
1|ψ
(0)
n i, (12.1.29)
where the coefficient of λ is naturally associated with the expectation value of the
perturbation. The first-order correction to the wave function, Eq. (12.1.14) extends
beyond the space of the zero-order states associated with E
(0)
n . The relative contribu￾tion of each of the different eigenstates,


ψ
(0)
n
0
E
, is weighted by (in absolute magnitude)



D
ψ
(0)
n
0



Hˆ
1


ψ
(0)
n
E





E
(0)
n −E
(0)
n
0



. As we can see, as the energy gap between each eigenstate, E
h0)
n
0
, and E
(0)
n
increases, the contribution of the n
0
state becomes smaller. Moreover, when the energy
gap, |E
(0)
n − E
(0)
n
0
|, is much larger than the corresponding matrix element of the per￾turbation, |hψ
(0)
n
0
|Hˆ
1|ψ
(0)
n i|, the contribution weight becomes much smaller than unity.
Notice that the perturbation can indeed be regarded as “small,” and the low-order
corrections are indeed meaningful in the regime where
|hψ
(0)
n
0
|Hˆ
1|ψ
(0)
n i|
|E
(0)
n −E
(0)
n
0
|
<< 1 (12.1.29)
for all the eigenstates with n
0 6= n. Setting λ = 1 to comply with the definition of
the full Hamiltonian, the corrected vector, |ψ
(0)
n i + |ψ
(1)
n i, is dominated by |ψ
(0)
n i in
this regime. In geometrical terms, the corrected vector still points (approximately)
to the direction set by |ψ
(0)
n i, in the space spanned by the set of all Hˆ
0 eigenstates.
A similar consideration applies to the next terms. Considering, for example, |ψ
(2)
n i
(Eq. (12.1.15)), it is again expanded in the set of Hˆ
0-eigenstates, beyond the space of
|ψ
(0)
n i. This time, however, the relative contributions of the different eigenstates are
weighted by multiplications of the ratio between Hˆ
1 matrix elements and correspond￾ing Hˆ
0 eigenvalue differences. Provided that all the ratios are smaller than unity, the
second-order correction is small with respect to the previous terms, and so forth.
12.2 Perturbation Theory in Action
The Two-Level System
A commonly used model maps the physical space of a system onto a two-dimensional
Hilbert space. In some cases, this description is exact, as, for example, the description of
a single isolated spin in nonrelativistic quantum mechanics (see Chapter 13). In most
cases, however, a two-level system (TLS) is a reduced approximate description of a
multilevel system in some limit, useful for idealized descriptions of quantum systems
with two distinctive states. In Chapters 17–20 we shall encounter several applications
involving the generic TLS Hamiltonian.
Within a two-state model, any solution to the Schrödinger equation is a
superposition of two orthonormal basis vectors,
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press162 Approximation Methods
|ψi = a1|χ1i+a2|χ2i ; hχn|χmi = δn,m, (12.2.1)
where the corresponding Hamiltonian operator takes the generic form (Eq. (11.2.11)),
Hˆ = H1,1|χ1ihχ1|+H2,2|χ2ihχ2|+H1,2|χ1ihχ2|+H2,1|χ2ihχ1|, (12.2.2)
or in a matrix representation,
H =

H1,1 H1,2
H2,1 H2,2

≡

ε1 γ
γ
∗
ε2

(12.2.3)
The basis states, |χ1i and |χ2i, can be identified as the Hamiltonian eigenstates, for
γ = 0. The entries, ε1 and ε2, therefore obtain the meaning of the energy levels associ￾ated with these states, The off-diagonal terms correspond to the interaction between
the two basis states, which is expressed in terms of a single complex-valued parameter,
γ = H1,2 = H
∗
2,1
, owing to the Hermiticity of Hˆ.
The TLS model enables us to demonstrate fundamental aspects of perturbation
theory, where exact solutions, readily available, enable us to test the accuracy of
the approximation in the different parameter regimes. The exact time-independent
Schrödinger equation for the TLS Hamiltonian (Eqs. (12.2.2, 12.2.3)) reads
Hˆ|ψni = En|ψni. (12.2.4)
It is convenient to define the average and the difference between the energies, ε1 and
ε2, as ε and 2∆, respectively:
ε =
ε1 +ε2
2
; ∆ =
ε1 −ε2
2
. (12.2.5)
The exact eigenvalues of the TLS Hamiltonian are then readily obtained (see
Ex. 12.2.1),
E1 = ε +
q
∆2 +|γ|
2
; E2 = ε −
q
∆2 +|γ|
2
. (12.2.6)
As for the eigenvectors, let us consider first the “nonsymmetric” case, ∆ 6= 0, introduc￾ing a dimensionless parameter,
α ≡
r
∆2 +|γ|
2
∆2
. (12.2.7)
Without loss of generality and for concreteness, we consider the case, γ = −|γ|, which
yields the following expression for the orthonormal eigenvectors corresponding to E1
and E2 (see Ex. 12.2.1 for the general case),
|ψ1i =
r
α +1
2α
|χ1i −r
α −1
2α
|χ2i ; |ψ2i =
r
α −1
2α
|χ1i+
r
α +1
2α
|χ2i, (12.2.8)
where we notice that this expression applies also in the symmetric case (∆ = 0), where
(α ±1)/α −−−→
∆→0
1.
Exercise 12.2.1 Derive the expressions for the eigenvalues (Eq. (12.2.6)) and the eigen￾vectors (Eq. (12.2.8)) of the TLS Hamiltonian, as defined in Eqs. (12.2.2, 12.2.3). In
order to do this, express the eigenvectors as linear combinations of the basis vectors,
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press163 12.2 Perturbation Theory in Action
|ψi = a1|χ1i + a2|χ2i, project the corresponding eigenvalue equation Hˆ|ψi = E|ψi
onto the basis vectors, |χ1i and |χ2i, and obtain the algebraic eigenvalue equation,

ε1 γ
γ
∗
ε2
  a1
a2

= E

a1
a2

. Then solve the equation: obtain the two eigenvalues,
E± = ε ±
p
∆2 +|γ|
2
, and the corresponding eigenvector coefficients, a
(±)
1 =
q
α±1
2α
,
a
(±)
2 = ±
|γ|
γ
q
α∓1
2α
, where ε = (ε1 +ε2)/2,∆ = (ε1 −ε2)/2, and α ≡
p
1+|γ|
2/∆2
.
We now turn to the implementation of the Rayleigh–Schrödinger perturbation the￾ory for the TLS. Notice that the partitioning of the full Hamiltonian into zero-order
and perturbation terms is not unique. Indeed, different partitions may be useful in dif￾ferent parameter regimes, where the more “correct” selection is the one yielding more
accurate approximation to the exact solutions to Schrödinger’s equation in a given
parameter regime. Let us express the general TLS Hamiltonian (Eqs. (12.2.2, 12.2.3))
in terms of its three independent parameters, ε, ∆, and γ:
H = ε¯

1 0
0 1 
+∆

1 0
0 −1

+γ

0 1
0 0 
+γ
∗

0 0
1 0 
(12.2.9)
The first term amounts to an addition of a constant to the eigenvalues of H and has
no effect on its eigenvectors (see Ex. 4.6.6). It can therefore be trivially included as
part of the zero-order Hamiltonian. The effect of the other terms on the eigenvalues
and eigenvectors depends on the ratio between the interstate interaction (|γ|) and the
spacing (∆) between the energy levels.
In Fig. 12.2.1, the two eigenvalues of the TLS (Eq. (12.2.6)) are plotted as functions
of the ratio |γ|/∆. The dotted and dashed lines correspond to their approximations,
based on second-order perturbation theory (derived in what follows) with different
partitioning of the full Hamiltonian into zero-order and perturbation terms. As we
can see, the exact values are remarkably well approximated by one (and only one) of
these approximations, as long as |γ|/∆ >> 1 or |γ|/∆ << 1.
When |γ| is smaller than |∆|, a natural choice is to associate the perturbation operator
with the interstate interaction term, proportional to |γ|. The zero-order Hamiltonian
Hˆ
0 takes the form
Hˆ
0 = (ε +∆)|χ1ihχ1|+ (ε −∆)|χ2ihχ2|, (12.2.10)
where its “preknown” eigenvalues and eigenvectors (Eq. (12.1.1)) are readily identified
as
E
(0)
1 = ε +∆ ; |ψ
(0)
1
i = |χ1i
E
(0)
2 = ε −∆ ; |ψ
(0)
2
i = |χ2i (12.2.11)
The perturbation Hˆ
1 is identified with the interstate interaction, where the full (λ￾dependent) Hamiltonian obtains the form
Hˆ(λ) = Hˆ
0 +λHˆ
1 ; Hˆ
1 = γ|χ1ihχ2|+γ
∗
|χ2ihχ1|. (12.2.12)
Expanding the energy levels of Hˆ to the lowest powers in λ, using perturbation theory
(Eqs. (12.1.16, 12.1.17)), we readily obtain (Ex. 12.2.2)
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press164 Approximation Methods
E1
∼= E
(0)
1 +λE
(1)
1 +λ
2E
(2)
1 = ε +∆+λ
2
|γ|
2
2∆
E2
∼= E
(0)
2 +λE
(1)
2 +λ
2E
(2)
2 = ε −∆−λ
2
|γ|
2
2∆
. (12.2.13)
Notice that the exact energy levels can also be expressed as analytic functions of λ
(replacing γ by λ γ (λ ∈ R) in Eq. (12.2.6)),
E1,2 = ε ±∆
r
1+
λ
2
|γ|
2
∆2
. (12.2.14)
Expanding the square root function in a Taylor series, √
1+x = 1+x/2+···, we can
readily identify the perturbation expansions (Eq. (12.2.13)) with the lowest-order terms
in the corresponding expression of the exact energy levels (Eq. (12.2.14)). Indeed,
for λ
2
|γ|
2
∆2 << 1, the truncated expansion is an accurate approximation to the exact
eigenvalues (see the dashed lines in Fig. 12.2.1). Recalling that the “physical” TLS
Hamiltonian is associated with λ = 1, the condition for validity of this low-order
approximation reads
|γ| << |∆|. (12.2.15)
This result is consistent with our association of the interstate interaction with a “per￾turbation,” when |γ|/|∆| < 1. Notice, however, that the accuracy of the low-order
perturbation expansion depends on the interstate coupling energy, |γ|, and improves
as it gets smaller in comparison to |∆|. Moreover, the result is accurate only when the
resulting induced change to the level spacing is small.
Ftigure 12.2.1 Solid lines: The exact two eigenvalues of a TLS defined by the diagonal matrix elements ∆ and −∆ (ε was set to
zero), and the off-diagonal, γ. The dashed and dotted lines represent approximated eigenvalues, calculated by
second-order perturbation theory with different selections of the zero-order Hamiltonians: Dashed for diagonal and
dotted for off-diagonal.
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press165 12.2 Perturbation Theory in Action
Exercise 12.2.2 Implement perturbation theory (Eqs. (12.1.16, 12.1.17)) for the
Hamiltonian defined in Eqs. (12.2.10–12.2.12). (a) Show that the first-order cor￾rections to the energy vanish. (b) Calculate the second-order corrections to obtain
Eq. (12.2.13).
A similar consideration applies to the TLS eigenvectors. Using Eq. (12.1.14), the
perturbation theory expansion yields the following (for concreteness, we set again, γ =
−|γ|) (see Ex. 12.2.3):
|ψ1i ∼= |ψ
(0)
1
i+λ|ψ
(1)
1
i = |χ1i −λ
|γ|
2∆
|χ2i
|ψ2i ∼= |ψ
(0)
2
i+λ|ψ
(1)
2
i = |χ2i+λ
|γ|
2∆
|χ1i. (12.2.16)
Renormalizing the exact eigenstates for (Eq. (12.2.7)) and replacing γ in Eq. (12.2.6)
by λ γ(λ ∈ R), the exact (unnormalized) TLS eigenvectors can be expressed as analytic
functions of λ (Ex. 12.2.4):
|ψ1i ∝
"
|χ1i+
∆
λ|γ|
 
1−
r
1+
λ
2
|γ|
2
∆2
!
|χ2i
#
|ψ2i ∝
"
|χ2i+
∆
λ|γ|
 r
1+
λ
2
|γ|
2
∆2
−1
!
|χ1i
#
. (12.2.17)
Again, the first-order approximations obtained using the perturbation expansion,
Eq. (12.2.16), are shown to correspond to the first-order Taylor expansion of the square
root function in Eq. (12.2.17). For λ = 1, the perturbation expansion (Eq. (12.2.16))
is shown to coincide with the exact wave function, as long as |γ| << |∆|, in line with
Eq. (12.2.15). Notice that the exact eigenstates are dominated by the two eigenstates of
Hˆ
0 in this parameter regime, |ψ1(2)
i ≈ |χ1(2)
i, where the corrections are proportional
to the small ratio, |γ|/|∆|.
Exercise 12.2.3 Implement perturbation theory (Eq. (12.1.14)) for the Hamiltonian
defined in Eqs. (12.2.10–12.2.12) to obtain the first-order corrections to the eigenstates,
as given in Eq. (12.2.16).
Exercise 12.2.4 (a) Derive the expressions in Eq. (12.2.17) for the exact TLS
eigenstates. (b) Show that the result obtained by first-order perturbation theory
(Eq. (12.2.16)) is obtained by expanding the square root function in a first-order Taylor
expansion.
The identification of the perturbation with the interstate interaction (Eq. (12.2.12))
was shown to be useful only for |γ| << |∆| (see Eq. (12.2.15)). However, perturba￾tion theory is still applicable when the system parameters are in the complementary
regime, namely, when |γ| > |∆|. In this case, however, the partition of Hˆ into zero-order
and perturbation terms needs to be changed accordingly. Let us set the zero-order
Hamiltonian to
Hˆ
0 = ε(|χ1ihχ1|+|χ2ihχ2|) +γ|χ1ihχ2|+γ
∗
|χ2ihχ1|, (12.2.18)
where its “preknown” eigenvalues and eigenvectors (Eq. (12.1.1)) are readily identified
as (again, we set γ = −|γ| for concreteness)
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press166 Approximation Methods
E
(0)
1 = ε +|γ| ; |ψ
(0)
1
i =
r
1
2
|χ1i −r
1
2
|χ2i
E
(0)
2 = ε −|γ| ; |ψ
(0)
2
i =
r
1
2
|χ1i+
r
1
2
|χ2i. (12.2.19)
The perturbation Hˆ
1 is now associated with the interaction-free Hamiltonian, where
the full (λ-dependent) Hamiltonian obtains the form
Hˆ(λ) = Hˆ
0 +λHˆ
1 ; Hˆ
1 = ∆|χ1ihχ1| −∆|χ2ihχ2| (12.2.20)
The approximations to the energy levels of Hˆ, using perturbation theory (Eqs. (12.1.16,
12.1.17)), read in this case (Ex. 12.2.5)
E1 ' E
0
1 +λE
(1)
1 +λ
2E
(2)
1 = ε +|γ|+
λ
2∆
2
2|γ|
E2 ' E
0
2 +λE
(1)
2 +λ
2E
(2)
2 = ε −|γ| − λ
2∆
2
2|γ|
(12.2.21)
Expressing the exact energy levels as analytic functions of λ (replacing ∆ by λ∆(where
λ ∈ R) in Eq. (12.2.6)), we obtain
E1,2 = ε ±|γ|
s
1+
λ
2∆2
|γ|
2
, (12.2.22)
where the perturbation expansions (Eq. (12.2.21)) are identified with the lowest-order
expansion of the square root function, √
1+x = 1+x/2+... Setting λ = 1, as in the full
Hamiltonian, we conclude that the truncated expansion is an accurate approximation
to the exact eigenvalues (see the dotted lines in Fig. 12.2.1), as long as
|γ| >> |∆|, (12.2.23)
which is consistent with our choice of the interstate interaction as the zero-order
Hamiltonian in the case, where |γ|/|∆| > 1. Again, the TLS eigenvectors can be
approximated using perturbation theory (Ex. 12.2.6),
|ψ1i ∼= |ψ
(0)
1
i+
λ∆
2|γ|
|ψ
(0)
2
i
|ψ2i = |ψ
(0)
2
i − λ∆
2|γ|
|ψ
(0)
1
i. (12.2.24)
Renormalizing the exact eigenstates for γ = −|γ| (Eq. (12.2.7)) and replacing ∆ in
Eq. (12.2.7) by λ∆(whereλ ∈ R), the exact (unnormalized) TLS eigenvectors can be
expressed as analytic functions of λ (Ex. 12.2.7),
|ψ1i ∝


vuut
s
1+λ
2
∆2
|γ|
2
+λ
∆
|γ|
r
1
2
|χ1i −
vuut
s
1+λ
2
∆2
|γ|
2
−λ
∆
|γ|
r
1
2
|χ2i


|ψ2i ∝


vuut
s
1+λ
2
∆2
|γ|
2
−λ
∆
|γ|
r
1
2
|χ1i+
vuut
s
1+λ
2
∆2
|γ|
2
+λ
∆
|γ|
r
1
2
|χ2i

.
(12.2.25)
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press167 12.2 Perturbation Theory in Action
Again, the approximations obtained using perturbation theory, Eq. (12.2.24), are
shown to correspond to the first-order Taylor expansion of the square root functions in
the exact expressions (Eq. (12.2.25)), which is valid for |∆| << |γ|. As we can see, in this
regime the eigenstates of the full Hamiltonian are dominated by the two eigenstates of
Hˆ
0, |ψ1(2)
i ≈ |ψ
(0)
1(2)
i, where the corrections are proportional to the small ratio, |∆|/|γ|
(see Eqs. (12.2.19, 12.2.24)).
Exercise 12.2.5 Implement perturbation theory (Eqs. (12.1.16, 12.1.17)) for the Ham￾iltonian defined in Eqs. (12.2.18–12.2.20). (a) Show that the first-order corrections to
the energy vanish. (b) Calculate the second-order corrections to obtain Eq. (12.2.21).
Exercise 12.2.6 Implement perturbation theory (Eq. (12.1.14)) for the Hamiltonian
defined in Eqs. (12.2.18–12.2.20) to obtain the first-order corrections to the eigenstates,
as given in Eq. (12.2.24).
Exercise 12.2.7 (a) Derive the expressions in Eq. (12.2.25) for the exact TLS
eigenstates. (b) Show that the result obtained by first-order perturbation theory
(Eq. (12.2.24)) is obtained by expanding the square root function in a first-order Taylor
expansion.
Let us dwell on the specific case where the energy level spacing between the nonin￾teracting states |χ1i and |χ2i strictly vanishes (∆ = 0). On one hand, this is a limiting
case of |∆| << |γ|, where the perturbation operator Hˆ
1 = ∆|χ1ihχ1| − ∆|χ2ihχ2| van￾ishes, and the result of perturbation theory with the proper partitioning, Eq. (12.2.20),
trivially coincides with the exact results:
E1,2|∆=0 = ε ±|γ| ; |ψ1,2i|∆=0 =
r
1
2
|χ1i ∓r
1
2
|χ2i. (12.2.26)
On the other hand, we may choose a partitioning of the Hamiltonian according to
Eq. (12.2.12), and attempt to refer to the interaction operator as the perturbation and
to the noninteracting states |χ1i and |χ2i as degenerate eigenstates of Hˆ
0, associated
with the interaction-free TLS Hamiltonian, Eq. (12.2.10). Recalling the procedure of
implementing perturbation theory for degenerate states (Eq. (12.1.24)), our first task is
to diagonalize the matrix representation of the perturbation operator in the degenerate
subspace, which reads in this case
H1 =

0 γ
γ
∗ 0

. (12.2.27)
Since, for ∆ = 0, H1 differs from the full TLS Hamiltonian only by an addition of a
constant ε,
H|∆=0 =

ε γ ¯
γ
∗
ε¯

= H1 +ε¯

1 0
0 1 
, (12.2.28)
the eigenvectors of the perturbation operator H1 coincide with the exact Hamilto￾nian eigenstates in this case, and the respective eigenvalues are the same up to the
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press168 Approximation Methods
additional ε (Eq. (12.2.26)). Indeed, implementing perturbation theory for degenerate
states is equivalent to a full solution of the Schrödinger equation, projected onto the
degenerate subspace. In the case of the TLS model (as well as for other models, in which
the degenerate space coincides with the full space), this is equivalent to a full solution
of the Schrödinger equation, and therefore is generally not practical. In most cases of
interest, however, the degenerate space is only a part of the full space, and perturba￾tion theory for degenerate states is therefore useful as a first step for approximating the
exact solutions to the Schrödinger equation in the entire space.
“Hybridization
“
of Atomic Orbitals
In Chapter 10 we became familiar with the states of an electron in an isolated hydrogen￾like atom model. Here we use perturbation theory in order to study the effect of a small
perturbation, associated with the presence of another point charge, on the energy lev￾els and orbitals of the electron. As we shall see, even a remote, small charge can induce
substantial changes to the electronic energy levels and stationary wave functions. Such
changes are indeed meaningful in understanding the formation of much more compli￾cated systems, including molecules and solid lattices (discussed in Chapter 14), where
electrons are shared among several nuclei. Particularly, we shall see that the presence
of external charges can induce a “hybridization” of atomic orbitals, which lowers the
ground state energy.
Our zero-order model Hamiltonian would correspond to an isolated hydrogen-like
atom where the nucleus is positioned at the origin, R = (0,0,0), and the electron
coordinate is r = (x, y,z) (see Eq. (10.2.4), using Cartesian coordinates):
Hˆ
0 =
−h¯
2
2µ

∂
2
∂ x
2
+
∂
2
∂ y
2
+
∂
2
∂ z
2

+
−KZe2
p
x
2 +y
2 +z
2
. (12.2.29)
The perturbation corresponds to the interaction of the atom with a remote point￾charge, q|e|, located at a fixed position, Rq = (xq, yq,zq), at a distance Rq = |Rq| from
the origin. The addition to the Hamiltonian accounts for the electrostatic interaction
of the remote charge with the electron and the nucleus,
Hˆ
1 =
KZqe2
|Rq|
+
−Kqe2
|r−Rq|
(12.2.30)
We shall focus here on perturbations whose effect on the ground state of the system
becomes null as Rq → ∞. This excludes, for example, cases in which q = |Z|, where the
Hamiltonian Hˆ
0 +Hˆ
1 becomes symmetric with respect to exchanging the nucleus and
the remote charge resulting in delocalization of the electronic wave functions between
the two positive charges. Let us emphasize that orbital delocalization between atoms is
considered as the “driving force” for chemical bond formation and for atomic orbital
hybridizations, which is the basis for the valence bond theory [12.1]). Here we focus
only on atomic orbital hybridization driven by weak electrostatic perturbations, where
a detailed discussion of delocalization of atomic orbitals between different atoms and
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press169 12.2 Perturbation Theory in Action
chemical bond formation will be given in Chapter 14. Cases in which q > |Z| are also
excluded here, since in that case the ground states of Hˆ
0 + Hˆ
1 will be associated with
charge transfer to the remote point charge, whereas our focus here is on changes to the
atomic orbitals near the atomic nucleus.
Restricting the following discussion to perturbations associated with q < |Z|, we shall
focus on the first-order corrections to the ground and first excited energy states of Hˆ
0.
The zero-order atomic ground state is nondegenerate (see Fig. 10.2.2 and Eq. (10.2.32))
and corresponds to the wave function and energy level,
hr|ψ
(0)
1s
i = ψ1s(x, y,z) = s
Z
3
πa
3
0
e
−Z
√
x
2+y
2+z
2/a0
; E
(0)
1 = −RH
Z
2
1
2
(12.2.31)
The first-order correction to the ground state energy is therefore the matrix element
of the perturbation operator (see Eq. (12.1.16)). For convenience, the line connecting
the atomic nucleus (the origin) and the remote charge is identified here as the z-axis,
namely Rq ≡ (0,0,Rq), which yields in this case (see Ex. 12.2.8)
E
(1)
1 = hψ
(0)
1s
|Hˆ
1|ψ
(0)
1s
i =
KZqe2
Rq
−Ke
2
q
w
dr
|ψ1s(r)|
2
|r−Rq|
=
Kqe2
Rq

Z −1+

ZRq
a0
+1

e
−2ZRq
a0

. (12.2.32)
Notice that at asymptotic distances (Rq >> a0
Z
) we obtain
E
(1)
1 −−−→
Rq→∞
Ke2q(Z −1)
Rq
, (12.2.33)
which has a clear physical meaning of the Coulomb interaction energy between the
remote point charge (q|e|) and the net atomic charge, obtained by subtracting the neg￾ative electron charge from the positive nucleus charge,(Z−1)|e|, as if the remote charge
“sees” the atom as a point charge. Indeed, when the external charge is positioned far
from the atom ￾
a0
Z << Rq

, its interaction energy with the electron is insensitive to
the details of the electron’s probability density distribution. The latter is confined to
some radius of the order ∼
a0
Z
around the atomic nucleus, and therefore when inte￾grating over the entire space in Eq. (12.2.32), the interaction energy −Ke2q
|r−Rq|
is projected
into this (relatively small) region. Consequently, we can approximate the perturbation
operator by its first-order Taylor expansion as a function of r near the origin,
Hˆ
1 =
Ke2Zq
|Rq|
+
−Ke
2q
|r−Rq|
∼=
Ke
2Zq
Rq
+
−Ke
2q
Rq
 
1+
xqx
R2
q
+
yqy
R2
q
+
zqz
R2
q
!
. (12.2.34)
Since the probability density, |ψ1s(r)|
2
, is an even function of r, the integral over the lin￾ear terms in r vanishes, and the remaining result (see Ex. 12.2.9) amounts to Ke2q(Z−1)
Rq
,
multiplied by the normalization integral of ψ1s(r), which indeed coincides with the
asymptotic value of E
(1)
1
in Eq. (12.2.33).
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Pres170 Approximation Methods
Exercise 12.2.8 To calculate the integral −Ke2q
r
dr
|ψ1s
(r)|
2
|r−Rq|
, it is convenient to change
variables to the elliptical coordinates, (λ,µ,φ), defined as
λ ≡
r +rq
Rq
; 1 < λ < ∞
µ ≡
rq −r
Rq
; −1 < µ < 1,
where rq ≡ |r−Rq|, Rq ≡ |Rq|,r ≡ |r|, and Rq ≡ (0,0,Rq).
(a) Show that these definitions yield the following results: x = rsin(θ) cos(φ) =
Rq
2
p
λ
2 + µ
2 −1− µ
2λ
2 cos(φ), y = rsin(θ)sin(φ) = Rq
2
p
λ
2 + µ
2 −1− µ
2λ
2
sin(φ) and z = r cos(θ) = Rq
2
(1− µλ).
(b) Let g(λ,µ,φ) = f(x, y,z). Calculate the corresponding Jacobian,







∂ x
∂ λ
∂ x
∂ µ
∂ x
∂ φ
∂ y
∂ λ
∂ y
∂ µ
∂ y
∂ φ
∂ z
∂ λ
∂ z
∂ µ
∂ z
∂ φ







,
and show that r∞
−∞
dx
r∞
−∞
dy r∞
−∞
dz f(x, y,z) =
2
rπ
0
dφ
r∞
1
dλ
r
1
−1
dµ
R
3
q
8
(λ
2 − µ
2
)g(λ,µ,φ).
(c) Let f(x, y,z) = −Ke2q
|ψ1s
(r)|
2
|r−Rq|
, with ψ1s(r) as defined in Eq. (12.2.31) and Rq ≡
(0,0,Rq). Derive the result for E
(1)
1
in Eq. (12.2.32).
(d) Show that as the distance to the point charge goes to infinity, the first-order correction
to the energy approaches the Coulomb interaction energy between the remote charge
and an effective point charge, in which the electron charge is subtracted from the
nucleus charge, namely E
(1)
1 −−−→
Rq→∞
Ke2q
Rq
(Z −1).
Exercise 12.2.9 Calculate the first-order correction to the ground-state energy
(Eq. (12.1.16)), owing to a remote point charge, using the approximation for the pertur￾bation, Eq. (12.2.34). Compare the result to the exact calculation, Eq. (12.2.32), in the
limit, Rq >> a0
Z
.
We now turn to the effect of a remote point charge on the first excited state
of the hydrogen-like atom. In this case the energy level of Hˆ
0 is 4-fold degener￾ate. For convenience, we shall choose the orthonormal set of real-valued functions
{ψ2s
, ψ2px
,ψ2py
,ψ2pz
} (see Fig. 10.2.4) as a basis for the degenerate subspace (see
Eq. (12.1.19)). The zero-order solutions therefore read
E
(0)
2 = −RH
Z
2
2
2
,
hr|ψ
(0)
2s
i = ψ2s(x, y,z) = 1
8
s
2Z
3
πa
3
0

2−
Z
a0
p
x
2 +y
2 +z
2

e
−
√
x
2+y
2+z
2 Z
2a0 ,
hr|ψ
(0)
2pz
i = ψ2pz
(x, y,z) = 1
8
s
2Z
5
πa
5
0
ze
−
√
x
2+y
2+z
2 Z
2a0 ,
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press171 12.2 Perturbation Theory in Action
hr|ψ
(0)
2py
i = ψ2py
(x, y,z) = 1
8
s
2Z
5
πa
5
0
ye
−
√
x
2+y
2+z
2 Z
2a0 ,
hr|ψ
(0)
2px
i = ψ2px
(x, y,z) = 1
8
s
2Z
5
πa
5
0
xe
−
√
x
2+y
2+z
2 Z
2a0 . (12.2.35)
The first-order corrections to the energy in this case are the eigenvalues of the matrix
representation of the perturbation operator in the degenerate subspace (Eq. (12.1.24)).
In the present case (Eq. (12.2.30), when Rq ≡ (0,0,Rq) in Cartesian coordinates), the
matrix representation of the perturbation operator obtains the form
H1 =









D
ψ
(0)
2s

Hˆ
1

ψ
(0)
2s
E Dψ
(0)
2s

Hˆ
1

ψ
(0)
2pz
E Dψ
(0)
2s

Hˆ
1

ψ
(0)
2py
E Dψ
(0)
2s

Hˆ
1

ψ
(0)
2px
E
D
ψ
(0)
2pz

Hˆ
1

ψ
(0)
2s
E Dψ
(0)
2pz

Hˆ
1

ψ
(0)
2pz
E Dψ
(0)
2pz

Hˆ
1

ψ
(0)
2py
E Dψ
(0)
2pz

Hˆ
1

ψ
(0)
2px
E
D
ψ
(0)
2py

Hˆ
1

ψ
(0)
2s
E Dψ
(0)
2py

Hˆ
1

ψ
(0)
2pz
E Dψ
(0)
2py

Hˆ
1

ψ
(0)
2py
E Dψ
(0)
2py

Hˆ
1

ψ
(0)
2px
E
D
ψ
(0)
2px

Hˆ
1

ψ
(0)
2s
E Dψ
(0)
2px

Hˆ
1

ψ
(0)
2pz
E Dψ
(0)
2px

Hˆ
1

ψ
(0)
2py
E Dψ
(0)
2px

Hˆ
1

ψ
(0)
2px
E









=




f2s(β) fs,pz
(β) 0 0
fs,pz
(β) f2pz
(β) 0 0
0 0 f2py
(β) 0
0 0 0 f2px
(β)




, (12.2.36)
where the nonvanishing integrals are functions of the dimensionless distance parame￾ter, β ≡ ZRq/(2a0) (see Ex. 12.2.10 for the full calculation using elliptical coordinates):
f2s(β) = Ke2Z
2q
2a0β
+
−ZKe2q
4a0β
3
[2β
2 −(2β
5 +2β
4 +3β
3 +2β
2
)e
−2β
],
f2pz
(β) = Ke2Z
2q
2a0β
+
−ZKe2q
4a0β
3
[2β
2 +6−(2β
5 +6β
4 +11β
3 +14β
2 +12β +6)e
−2β
],
f2px
(β) = f2py
(β) = Ke2Z
2q
2a0β
+
−ZKe2q
4a0β
3
[2β
2 −3+ (β
3 +4β
2 +6β +3)e
−2β
],
fs,pz
(β) = −ZKe2q
4a0β
3
[−3β + (2β
5 +4β
4 +6β
3 +6β
2 +3β)e
−2β
]. (12.2.37)
Exercise 12.2.10 Using the explicit set of degenerate wave functions (Eq. (12.2.35)),
calculate the matrix elements of the operator −Ke2q
|r−Rq|
, for Rq ≡ (0,0,Rq), and verify the
results given in Eqs. (12.2.36, 12.2.37) (including the vanishing entries). For this purpose,
it is recommended to change variables to the elliptical coordinates,(λ,µ,φ), following the
practice of Ex. 12.2.8.
The eigenvalues of H1({E
(1)
2
}), are the roots of the following determinant,









f2s(β)−E
(1)
2
fs,pz
(β) 0 0
fs,pz
(β) f2pz
(β)−E
(1)
2
0 0
0 0 f2py
(β)−E
(1)
2
0
0 0 0 f2px
(β)−E
(1)
2









= 0, (12.2.38)
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press172 Approximation Methods
where each root (E
(1)
2, j
, j = 1,2,3,4) corresponds to a specific eigenvector,



f2s(β)−E
(1)
2, j
fs,pz
(β) 0 0
fs,pz
(β) f2pz
(β)−E
(1)
2, j
0 0
0 0 f2py
(β)−E
(1)
2, j
0
0 0 0 f2px
(β)−E
(1)
2, j







a
(0)
2s, j
a
(0)
2pz, j
a
(0)
2py, j
a
(0)
2px, j




=


0
0
0
0

. (12.2.39)
Each coefficient vector, a
(0)
2s, j
,a
(0)
2pz, j
,a
(0)
2py, j
,a
(0)
2px, j
, corresponds to a zero-order eigenstate
of Hˆ
0,
E
(1)
2, j ↔ |ψ
(0)
2, j
i = a
(0)
2s, j
|ψ
(0)
2s
i+a
(0)
2pz, j
|ψ
(0)
2pz
i+a
(0)
2py, j
|ψ
(0)
2py
i+a
(0)
2px, j
|ψ
(0)
2px
i, (12.2.40)
which is consistent with the perturbation to the Hamiltonian (see Eq. (12.1.25)).
The corrections to the excited-state energy are readily obtained from Eq.
(12.2.38),
E
(1)
2,1 =
1
2
(f2s(β) + f2pz
(β) +q
[ f2s(β)− f2pz
(β)]2 +4[ fs,pz
(β)]2)
E
(1)
2,2 =
1
2
(f2s(β) + f2pz
(β)−
q
[ f2s(β)− f2pz
(β)]2 +4[ fs,pz
(β)]2),
E
(1)
2,3 = f2py
(β)
E
(1)
2,4 = E
(1)
2,3
(12.2.41)
As we can see, the degeneracy of the excited state orbitals is only partially removed in
the presence of the remote point charge, where one of the corrected eigenvalues remains
doubly degenerate. The block diagonal structure of Eq. (12.2.39) reveals that the two
degenerate eigenvalues are (any) linear combinations of |ψ
(0)
2px
i and |ψ
(0)
2py
i, whereas the
nondegenerate states are specific linear combinations of |ψ
(0)
2s
i and |ψ
(0)
2pz
i. The remain￾ing degeneracy is intuitive, considering that the point charge is positioned along the
z-axis, and its interaction with the charge densities associated with the orbitals |ψ
(0)
2px
i
and |ψ
(0)
2py
i is therefore invariant to a 90◦
rotation around the z-axis, which would map
these two densities one on the other.
While an explicit calculation of the new orbitals obtained by mixing |ψ
(0)
2s
i with
|ψ
(0)
2pz
i is straightforward for any position of the point charge (solving explicitly
Eq. (12.2.39)), it is insightful to consider again the asymptotic limit, in which the
extra point charge is positioned far from the electronic density surrounding the atomic
nucleus, namely at Rq >> a0/Z. The matrix representation of the perturbation obtains
a simple form in this case (see Eq. (12.2.34)),
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press173 12.2 Perturbation Theory in Action
H1 =
Ke
2Zq
Rq




1 0 0 0
0 1 0 0
0 0 1 0
0 0 0 1




+
−Ke2q
Rq





1
−3a0
ZRq
0 0
−3a0
ZRq
1 0 0
0 0 1 0
0 0 0 1





, (12.2.42)
with the following eigenvalues and eigenvectors,
E
(1)
2,2 =
Ke2q
Rq

Z −1+
3a0
ZRq

; |ψ
(0)
2,1
i =
1
√
2

|ψ
(0)
2s
i+|ψ
(0)
2pz
i

E
(1)
2,2 =
Ke2q
Rq

Z −1−
3a0
ZRq

; |ψ
(0)
2,2
i =
1
√
2

|ψ
(0)
2s
i − |ψ
(0)
2pz
i

E
(1)
2,3 =
Ke2q
Rq
(Z −1) ; |ψ
(0)
2,3
i = |ψ
(0)
2py
i
E
(1)
2,4 =
Ke2q
Rq
(Z −1) ; |ψ
(0)
2,4
i = |ψ
(0)
2px
i. (12.2.43)
As we can see, the presence of the remote point charge removes the degeneracy of the
orbitals of the isolated atom, |ψ
(0)
2s
i and |ψ
(0)
2pz
i, while inducing their “mixing” into so￾called “sp” hybrid orbitals, |ψ
(0)
2sp,±
i = √
1
2
(|ψ
(0)
2s
i ± |ψ
(0)
2pz
i), associated with polarized
probability densities, either toward or away from the point charge (see Fig. 12.2.2).
Notice that the different energies attributed to each hybrid orbital are in accord with
Ftigure 12.2.2 Angular distribution functions for degenerate|ψ
(0)
2s
iand|ψ
(0)
2pz
istates of an isolated hydrogen-like atom (a) and
“sp” hybridization orbitals (b) obtained by introducing a remote point charge+q. The angular distribution functions
are as defined in Fig.10.3.1, where the different shades in each plot add information corresponding to changes in the
sign of the wave function, for which the probability density is presented.
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press174 Approximation Methods
the electrostatic interaction between the point charge and the polarized electronic
charge distribution. For example, when the remote charge located at zq > 0 is posi￾tive, q > 0, the lower energy state corresponds to ||ψ
(0)
2s
i − |ψ
(0)
2pz
i|2
. Since |ψ
(0)
2s
i and
|ψ
(0)
2pz
i interfere constructively (destructively) at large positive (negative) z, the (neg￾atively charged) electronic probability density is polarized toward the positive point
charge (see Ex. 12.2.11), which reduces the electrostatic energy. Similarly, the higher
energy state corresponds to ||ψ
(0)
2s
i + |ψ
(0)
2pz
i|2
, where the interference between |ψ
(0)
2s
i
and |ψ
(0)
2pz
i polarizes the (negatively charged) electronic probability density away from
the remote positive charge.
Notice that the hybridized “sp” function is asymmetric with respect to reflection
through the (x, y) plane, which reflects the reduced symmetry of the Hamiltonian in
the presence of the point charge. Importantly, while the energy difference between the
hybridized orbitals, ∆E =
Ke2q
R2
q
6a0
Z
, decays to zero as 1/R
2
q with increasing distance to the
point charge, the shape of the corresponding orbitals is invariant to changes in Rq in this
asymptotic regime and reflects the broken symmetry of the Hamiltonian. Indeed, any
distribution of charges along the z-axis that breaks the symmetry of reflection through
the (x, y) plane would result in a non-diagonal matrix H1 with the same hybridized
orbitals as its eigenvectors. (In contrast, for example, two identical charges positioned
at +zq and −zq that maintain the reflection symmetry would correspond to a diagonal
matrix H1, and consequently |ψ
(0)
2s
i and |ψ
(0)
2pZ
i would remain degenerate, where the
hybridized orbitals would have no particular meaning).
Exercise 12.2.11 Use the explicit form of |ψ
(0)
2s
i and |ψ
(0)
2pz
i in Eq. (12.2.35), and show
that far from the nucleus (r > 2a0/Z) the probability density associated with |ψ
(0)
2s
i −
|ψ
(0)
2pz
i is larger above the (x, y) plane, namely p(x, y,|z|) ≥ ρ(x, y,−|z|), and the result is
reversed for |ψ
(0)
2s
i+|ψ
(0)
2pz
i.
Different hybridizations are obtained when several point charges are distributed at dif￾ferent points in space, where the atomic orbitals are mixed differently according to
the geometrical arrangement of the charges (more generally, according to the sym￾metry group of the perturbed system Hamiltonian). Consider, for example, two point
charges, the first positioned at a fixed distance Rq from the origin along the (positive) z￾axis, R1 = (0,0,Rq), and the second positioned at a fixed distance αRq along the positive
x-axis, R2 = (αRq,0,0). For simplicity, we shall consider in this case only the asymp￾totic limit, αRq,Rq >> a0/Z, where the distances between the point charges and the
atom are sufficiently large that the perturbation operator can be well approximated by
its first-order Taylor expansion as a function of r near the origin (Eq. (12.2.34)). In the
present case, the perturbation operator obtains the form
Hˆ
1 = C(R1,R2) + −Ke2q
Rq

1+
1
α

+
−Ke2q
R2
q
z+
−Ke
2q
α2R2
q
x, (12.2.44)
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press175 12.2 Perturbation Theory in Action
where C(R1,R2) ≡
Ke2Zq
|R1| +
Ke
2Zq
|R2| +
Ke
2q
2
|R1−R2|
is the electrostatic energy associated with
the clamped nucleus and point charges, which is independent of the electron coordi￾nates. As discussed in the previous example, the terms linear in r do not contribute
to the first-order correction for the ground-state energy, which therefore reads E
(1)
1 =
hψ
(0)
1s
|Hˆ
1|ψ
(0)
1s
i = C(R1,R2) + −Ke2q
Rq
￾
1+
1
α

. These terms do contribute, however, to
the first-order corrections to the degenerate excited-state energy. Particularly, using
the integrals, hψ
(0)
2s
|zˆ|ψ
(0)
2pz
i = hψ
(0)
2s
|xˆ|ψ
(0)
2px
i = −3a0/Z (see Ex. 12.2.12), the matrix
representation of Hˆ
1 in the basis for the degenerate excited states, Eq. (12.2.35), reads
H1 = C(R1,R2)




1 0 0 0
0 1 0 0
0 0 1 0
0 0 0 1




+
−Ke2q
Rq






1+
1
α −
3a0
ZRq
0 −
3a0
α2ZRq
−
3a0
ZRq
1+
1
α
0 0
0 0 1+
1
α
0
−
3a0
α2ZRq
0 0 1+
1
α






.
(12.2.45)
Two of the corresponding eigenvalues of H1 are associated with the same correction
to the energy, C(R1,R2) + −Ke2q
Rq
￾
1+
1
α

, which corresponds to two degenerate eigen￾states, where the other two are different, C(R1,R2) + −Ke2q
Rq

1+
1
α ±
3a0
ZRq
p
1+1/α4

.
Setting, for example, α = 1/3
1/4
(see Ex. 12.2.12), the two degenerate eigenstates
are |ψ
(0)
2py
i and q
3
4
|ψ
(0)
2pz
i − 1
2
|ψ
(0)
2px
i, where the other two are √
1
2
|ψ
(0)
2s
i ± √
1
8
|ψ
(0)
2pz
i ±
q
3
8
|ψ
(0)
2px
i.
Exercise 12.2.12 (a) Use the explicit form of the hydrogen-like orbitals (Eq. (12.2.35))
to show that hψ
(0)
2s
|zˆ|ψ
(0)
2pz
i = hψ
(0)
2s
|xˆ|ψ
(0)
2px
i = hψ
(0)
2s
|yˆ|ψ
(0)
2py
i = −3a0/Z. (b) Diagonalize
the matrix H1 for α = 1/3
1/4
to show that the eigenvalues are C(R1,R2) + −Ke2q
Rq
(1 +
3
1/4
);C(R1,R2)+
−Ke2q
Rq

1+3
1/4 ±
6a0
ZRq

. (c) Obtain the corresponding first-order cor￾rected atomic orbitals.
The Stark Effect
Another example for electrostatically induced hybridization of atomic orbitals is the
Stark effect [12.2]. Consider a hydrogen-like atom centered at the origin of coordinate
space, subject to a static electric field along the z-axis. The Hamiltonian takes the form
Hˆ = Hˆ
0 +Hˆ
1, where Hˆ
0 is the hydrogen-like atom Hamiltonian (Eq. (12.2.29)), and Hˆ
1
accounts for the interaction of the atomic dipole with the electric field, Hˆ
1 = −µˆ ·E.
Identifying the z-axis with the direction of the electric field, E = (0,0,Ez), and using
the atom’s dipole operator, µˆ = −|e|rˆ, the atom-field interaction reads Hˆ
1 = Ez
|e|zˆ. For
weak fields, perturbation theory can be applied for calculating the energy levels and
stationary wave functions for the atom in the presence of the field. Before implementing
the theory, we note that in general we need to be careful when considering a perturba￾tion operator that diverges asymptotically. Indeed, for Ez 6= 0, the local operator, Ez
|e|zˆ,
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Pre176 Approximation Methods
diverges in the position representation as z → ±∞, which implies that sufficiently far
from the origin, it dominates over Hˆ
0, and a different partitioning of the Hamiltonian
needs to be invoked for using perturbation theory. Moreover, since Hˆ
1 = Ez
|e|zˆ does
not support bound states, its eigenstates are very different from the bound states of the
atom. We must therefore restrict the linear dependence of the field to a finite coordi￾nate space (e.g., the interior of a finite range capacitor) and to small field intensities,
for which the expected corrections to the eigenvalues of the full Hamiltonian remain
small in comparison to their level spacings (see Fig. 12.1.1).
Starting from the ground state of the atom, |ψ
(0)
1s
i, the first-order correction to
the energy takes the following form (see Eq. (12.2.35) for the Cartesian coordinate
representation):
E
(1)
1 = hψ
(0)
1s
|Hˆ
1|ψ
(0)
1s
i = Ez
|e|
w
|ψ1s(r)|
2
zdr = 0. (12.2.46)
Since |ψ1s(r)|
2 and z are, respectively, even and odd functions of z, the integral van￾ishes, and so does the first-order correction to the energy. Moreover, the second-order
correction to the energy, as defined in Eq. (12.1.17), depends on the squares of matrix
elements of the perturbation operator, and therefore we can conclude that the depend￾ence of the ground state energy on the field intensity (Ez) will be at least quadratic,
which is indeed the case (the quadratic Stark effect).
Turning to the first excited state of the atom, we encounter a 4-fold degener￾acy. Again, it is convenient to choose the orthonormal set of real-valued functions,
{ψ2s
,ψ2px
,ψ2py
,ψ2pz
} (see Eq. (12.2.35)), as a basis for the degenerate subspace, where
the matrix representation of the perturbation operator reads
H1 =









D
ψ
(0)
2s

Hˆ
1

ψ
(0)
2s
E Dψ
(0)
2s

Hˆ
1

ψ
(0)
2pz
E Dψ
(0)
2s

Hˆ
1

ψ
(0)
2py
E Dψ
(0)
2s

Hˆ
1

ψ
(0)
2px
E
D
ψ
(0)
2pz

Hˆ
1

ψ
(0)
2s
E Dψ
(0)
2pz

Hˆ
1

ψ
(0)
2pz
E Dψ
(0)
2pz

Hˆ
1

ψ
(0)
2py
E Dψ
(0)
2pz

Hˆ
1

ψ
(0)
2px
E
D
ψ
(0)
2py

Hˆ
1

ψ
(0)
2s
E Dψ
(0)
2py

Hˆ
1

ψ
(0)
2pz
E Dψ
(0)
2py

Hˆ
1

ψ
(0)
2py
E Dψ
(0)
2py

Hˆ
1

ψ
(0)
2px
E
D
ψ
(0)
2px

Hˆ
1

ψ
(0)
2s
E Dψ
(0)
2px

Hˆ
1

ψ
(0)
2pz
E Dψ
(0)
2px

Hˆ
1

ψ
(0)
2py
E Dψ
(0)
2px

Hˆ
1

ψ
(0)
2px
E









=




0 γ 0 0
γ 0 0 0
0 0 0 0
0 0 0 0




, (12.2.47)
where γ = −3a0/Z (see Ex. 12.2.12 for the relevant integrals). The first-order correc￾tions to the excited state energy in the presence of the field are the eigenvalues of
this matrix, E
(1)
2 = 0,0, γ,−γ, where the corresponding eigenvectors define corrected
zero-order atomic orbitals. The zero eigenvalue remains doubly degenerate, and the
corresponding orbitals are any linear combination of the orthonormal states, |ψ
(0)
2px
i
and |ψ
(0)
2py
i. The two other eigenvalues, E
(1)
2 = ±γ, correspond to hybrid “sp” orbitals,
√
1
2
(|ψ
(0)
2s
i ± |ψ
(0)
2pz
i), as illustrated in Fig. 12.2.3. Notice that the electron densities are
pointing toward opposite directions, parallel and antiparallel to the field direction, in
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press177 12.2 Perturbation Theory in Action
Ftigure 12.2.3 Angular distribution functions for “sp” hybridization orbitals obtained by introducing a hydrogen-like atom into a
constant electric field along thezdirection. The angular distribution functions are as defined in Fig.10.3.1, where the
different shades in each plot add information corresponding to changes in the sign of the wave function, for which the
probability density is presented.
consistency with the corresponding changes in the orbital energies. As we can see, the
corrections to the excited state energy in the presence of the field are linear in the field
intensity (the linear stark effect).
Envelope Function Approximations in Quantum Wells
In Chapters 5 and 6 we discussed energy quantization in quantum wells. These struc￾tures were idealized in several aspects, one being ignorance of the detailed atomistic
structure of the underlying material composing the structure. Indeed, the typical
length of quantum wells (∼ 10–1000 nm) is large in comparison to the typical unit
cell of most lattices (∼ 0.1–1 nm), and therefore, for a qualitative understanding
of the electron energy quantization phenomenon (the quantum size effect), models
neglecting the atomistic structure are sufficient. A quantitative treatment of the “multi￾scale” Schrödinger equation, should account consistently for the boundary conditions
derived from the size, shape, and environment of the quantum well (or the nanopar￾ticle), as well as for the short-range potential energy alternations on the atomic scale.
The inherent length-scale separation enables the implementation of approximate and
yet accurate solutions to the full Schrödinger equation for the quantum structure. The
most common approaches, such as the k · p perturbation theory, relate specifically
to the basis (Bloch) functions associated with the infinitely periodic lattice structure.
The interested reader is directed to more advanced discussions of this approach in
other textbooks [12.3]. Here the atomistic details of the structure are regarded as a
small perturbation. As we have already seen, perturbation theory provides accurate
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press178 Approximation Methods
approximation, as long as the matrix elements of the perturbation operator are small
in magnitude in comparison to the energy level spacings of the zero-order Hamilto￾nian. In a typical nanostructure, the quantum size effect means that the level spacings,
derived from the confining potential energy function at the boundaries, increase with
reducing structure size, to a point where the level spacing is sufficiently large to invoke
a perturbative treatment of the underlying lattice structure.
Let our zero-order Hamiltonian for an idealized quantum well correspond to the
“particlein-a-box” model studied in Section 5.3, with the zero-order eigenfunctions
and eigenvalues:
hx|ψni =
r
2
L
sinnπ
L
x

; En =
h¯
2π
2n
2
2mL2
; n = 1,2,3..., (12.2.48)
where m and L are the particle’s mass and the box length, respectively.
The perturbation operator corresponds to an alternating potential energy with a
lattice period (a unit cell), which we set to L/k, where k is an integer (of the order of
10–103
, for typical nanostructure). For simplicity, we consider a harmonic modulation
function,
Hˆ
1 = α cos
kxˆ
2π
L

, (12.2.49)
where α is the amplitude of the potential energy modulation.
We can readily see that the first-order correction to the energy vanishes for any n 6= k
(Ex. 12.2.13),
E
(1)
n6=k = hψn|Hˆ
1|ψni = 0, (12.2.50)
whereas the second-order correction reads
E
(2)
n =
∞
∑
n
0=1
n
06=n



D
ψ
(0)
n
0

Hˆ
1

ψ
(0)
n
E


2
E
(0)
n −E
(0)
n
0
=
−α
2
16k
2mL2
h¯
2π
2
 1
k+n +
1
k−n
; n 6= k,2k
1
k+n
; n = k,2k
. (12.2.51)
Similarly, we can obtain the first-order correction to the full Hamiltonian eigenfunc￾tions (See Eq. (12.1.14) and Ex. 12.2.13),


ψ
(1)
n
E
=
∞
∑
n
0=1
n
06=n
D
ψ
(0)
n
0

Hˆ
1

ψ
(0)
n
E
E
(0)
n −E
(0)
n
0

ψ
0
n
0

ψ
(1)
n (x) = α
8k
r
2
L

2mL2
h¯
2π
2




−1
n+k
sin
(n+2k)πx
L

; n = k,2k
−1
n+k
sin
(n+2k)πx
L

+
1
n−k
sin
(n−2k)πx
L

; n 6= k,2k.
(12.2.52)
Exercise 12.2.13 Use the explicit form of the particle-in-a-box eigenstates (Eq. (12.2.48))
and the perturbation operator, Eq. (12.2.49), to show the following: (a) For any n,n
0 > 0,
hψn
0|Hˆ
1|ψni =
α
2

δn
0
,n+2k −δn
0
,2k−n
; 2k > n
δn
0
,n+2k +δn
0
,n−2k
; 2k ≤ n
. (b) The first-order corrections to the
energy vanish unless n=k (Eq. (12.2.50)). (c) The second-order correction to the energy
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press179 12.2 Perturbation Theory in Action
is given in terms of Eq. (12.2.51). (d) The first-order correction to the function is given
in terms of Eq. (12.2.52).
It is instructive to discuss the effect of the alternating lattice potential on the lowest
eigenstates of the confining quantum well potential, n ∼ 1 − 10, which should corre￾spond to the energy levels accessible by charge carriers in a typical material. For typical
quantum wells (or nanoparticles) the atomic lattice period is about two to three orders
of magnitude smaller than the confining potential length, which means that we are
interested in the regime where n << k. In this limit, the de Broglie wavelength associ￾ated with the quantum number n, namely λn = 2L/n (see Eq. (1.1.3)), is much larger
than the unit cell length, L/k. In Fig. 12.2.4 the exact eigenfunctions in the presence
of the perturbation are compared to the zero-order particle-in-a-box functions. As we
can see, two length scales are apparent. A slowly varying envelope corresponding to the
zero-order function, and rapid oscillations at a wavelength set by the rapidly changing
(lattice) potential. This form is captured already using the first-order correction to the
wave function, based on Eq. (12.2.52), which yields in the limit n << k (Ex. 12.2.14),
ψ
(0)
n (x) +ψ
(1)
n (x) ≈
r
2
L
sinnπx
L

"
1−
α
E
(0)
2k
cos
2kπx
L
#
. (12.2.53)
As we can see, a measure for the perturbation effect is the ratio between the oscillat￾ing potential energy amplitude, α, and the corresponding kinetic energy for a particle
in the box with a de Broglie wavelength at the same oscillation period (a quantum
Ftigure 12.2.4 Stationary wave functions(ψn(x), n = 1,2,3,4, displaced from each other according to their respective energy
levels) for a “particle-in-a-box” in the presence of an oscillating potential energy,α cos(2kπx/L). The box
contains 30 oscillation periods(k = 30), and the potential amplitude is ,α = 0.2E
(0)
2k
. The thin line corresponds
to the perturbation-free box, and the thick line represents the exact wave function in the presence of the perturbation
(calculated numerically) and/or the first-order approximation by perturbation theory (Eq. (12.2.53)), which are
indistinguishable in the given plot resolution. Notice that while the perturbation induces a significant reduction of the
energy levels, the effect on the level spacings and on the wavefunctions is relatively minor.
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press180 Approximation Methods
number 2k). For α  E
(0)
2k
the explicit expression for the wave function indeed reveals
a slowly varying envelope function (q
2
L
sin￾
nπx
L

, in the present case) multiplied by a
rapidly oscillating function at the lattice periodicity. The similarity between the solu￾tions in the perturbed and unperturbed systems in this limit is also apparent from the
corrections to the energy, which approaches a nearly constant value in this limit (see
Eq. (12.2.51)), E
(2)
n −−→nk
−α
2
2E
(0)
2k
, with a negligible effect on the energy level spacings in
the perturbed system (see Ex. 4.6.6).
Exercise 12.2.14 Derive Eq. (12.2.53) from Eq. (12.2.52) in the limit n << k.
In the opposite limit, n >> k, the de Broglie wavelength associated with the quan￾tum number n, becomes short in comparison to the unit cell length, L/k. As the kinetic
energy of the particle-in-a-box increases with n, the perturbation associated with
the potential energy oscillations becomes negligible (for any finite α). This is indeed
reflected in the vanishing perturbative corrections to the energy levels, Eq. (12.2.51),
and wave functions, Eq. (12.2.52), E
(2)
n −−−→n→∞
0,|ψ
(1)
n i −−−→n→∞
0.
A most interesting regime is associated with the intermediate quantum numbers, n ≈
k, where the length scale separation breaks down (i.e., the half de Broglie wavelength
is of the order of the unit cell length, λn/2 ∼ L/k). The perturbative correction to the
energy (Eq. (12.2.51)) is dominated in this regime by the term E
(2)
n ≈
−α
2
16k
2mL2
h¯
2π
2
1
k−n
and
therefore changes its sign from negative to positive, as the quantum number changes
from n < k to n > k, respectively. This discontinuity in the corrections to the energy is
a signature of the emergence of an energy gap formation in the exact spectrum of the
full Hamiltonian. The gap is characteristic of the Schrödinger equation for an infinitely
periodic lattice, as will be discussed in Chapter 14.
We now turn to a similar study of a two-dimensional potential energy well. The zero￾order Hamiltonian corresponds to a particle in an infinite two-dimensional box (see
Section 5.5),
Hˆ
0 =
1
2m
(pˆ
2
x + pˆ
2
y
)+V(xˆ, yˆ), (12.2.53)
where V(x, y) = 
0 ; 0 ≤ x ≤ Lx,0 ≤ y ≤ Ly
∞; elsewhere . The corresponding zero-order
eigenvalues and eigenfunctions are identified by two quantum numbers in this case,
nx,ny = 1,2,... :
E
(0)
nx,ny =
h¯
2π
2
2m
"
nx
Lx
2
+

ny
Ly
2
#
;
ψ
(0)
nx,ny
(x, y) = r
2
Lx
s
2
Ly
sin
nxπx
Lx

sin
nyπy
Ly

. (12.2.54)
The two-dimensional lattice corresponds to an alternating potential energy with a two￾dimensional unit cell of dimensions (Lx/kx,Ly/ky). In the simplest case, the potential
energy function obtains a product form,
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Pres181 12.2 Perturbation Theory in Action
Hˆ
1 = α cos
kxxˆ
2π
Lx

cos
kyyˆ
2π
Ly

. (12.2.55)
Consequently, the matrix elements of the perturbation operator in the basis of Hˆ
0
eigenstates become products of one-dimensional integrals,
hψnX ,ny
|Hˆ
1|ψn
0
x
,n
0
y
i
= α
 
2
Lx
w
Lx
0
sin
nxπx
Lx

cos
kx2πx
Lx

sin
n
0
xπx
Lx

dx
!


2
Ly
w
Ly
0
sin
nyπy
Ly

cos
ky2πy
Ly

sin
n
0
yπy
Ly

dy

 (12.2.56)
where each one-dimensional integral obtains the form (see Ex. 12.2.13)
2
L
w
L
0
dx sin
n
0πx
L

cos
2kπx
L

sinnπx
L

=

2k > n ; (δn
0
,n+2k −δn
0
,2k−n
)/2
2k ≤ n ; (δn
0
,n+2k +δn
0
,n−2k
)/2.
While calculating the corrections to the energy levels and wave functions we must notice
that, unlike in the one-dimensional case, some eigenvalues of the zero-order Hamilto￾nian can be degenerate and should be treated accordingly. However, here we restrict
the discussion to the low-lying energy levels, where both nx  kx and ny << ky. In
this regime, both diagonal and non-diagonal matrix elements of the perturbation van￾ish, hψnx,ny
|Hˆ
1|ψn
0
x
,n
0
y
i|nx,n
0
x<<kx;ny,n
0
y<<ky = 0, such that the first-order corrections to the
energy vanish for any zero-order eigenstate,
E
(1)
nx,ny = 0. (12.2.57)
The second-order corrections to the energy include contributions also from high
quantum numbers, and therefore do not vanish:
E
(1)
nx,ny =
∞
∑
n
0
x
,=1
n
0
x
6=nx
∞
∑
n
0
y
,=1
n
0
y
6=ny



D
ψnx,ny

Hˆ
1

ψn
0
x
,n
0
y
E


2
E
(0)
nx,ny −E
(0)
n
0
x
,n
0
y
. (12.2.58)
Restricting the discussion again to the typical parameter regime, where nx  kx and
ny << ky, we obtain (Ex. 12.2.15)
E
(2)
nx,ny ≈ −
α
2
4
2m
h¯
2π
2
 
k
2
x
L
2
x
+
k
2
y
L
2
y
!−1
= −
α
2
E
(0)
2kx,2ky
(12.2.59)
Similarly, the first-order corrections to the eigenfunctions read
|ψ
(1)
nx,ny
i =
∞
∑
n
0
x
,=1
n
0
x
6=nx
∞
∑
n
0
y
,=1
n
0
y
6=ny
hψn
0
x
,n
0
y
|Hˆ
1|ψnx,ny
i
E
(0)
nx,ny −E
(0)
n
0
x
,n
0
y
|ψn
0
x
,n
0
y
i, (12.2.60)
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press182 Approximation Methods
where for both nx  kx and ny << ky (see Ex. (12.2.15)) we obtain
ψ
(0)
nx,ny
(x, y) +ψ
(1)
nx,ny
(x, y) ≈
r
2
Lx
s
2
Ly
sin
nxπx
Lx

sin
nyπy
Ly


1−
2α
E
(0)
2kx,2ky
cos
2kxπx
Lx

cos
2kyπy
Ly


. (12.2.61)
As in the one-dimensional case, the two-dimensional wave functions reflect two length
scales. Each wave is composed of a slowly varying envelope function, multiplied by a
rapidly oscillating function reflecting the underlying unit cell structure.
Exercise 12.2.15 Use the explicit form of the zero-order solutions (Eq.(12.2.54))and
the perturbation matrix elements, Eq. (12.2.56), to derive the results of Eqs. (12.2.59,
12.2.61).
12.3 The Variation Approach
As we saw in the previous section, a successful implementation of perturbation theory
requires an identification of a suitable zero-order approximation to the full Hamil￾tonian, which is sufficiently close to it in some sense, and yet significantly easier to
handle. When applicable, perturbation theory is the method of choice, providing accu￾rate energy levels and wave functions, as well as physical insight. However, approximate
solutions to the Schrödinger equation are needed also when perturbation theory as
previously outlined becomes too cumbersome to be applicable. In this chapter we intro￾duce the variation approach to the solution of the Schrödinger equation. The approach
is robust and it provides numerous algorithms and numerical procedures for calcu￾lating energy levels and wave functions in complex, many-particle, nanoscale systems
(atoms, molecules, etc).
The most important concept behind the different variation methods is that of trial
wave functions. The latter are subject to constraints imposed by the nature of the phys￾ical system (variables, dimensions, boundary conditions, etc.), as well as to artificial
constraints, which reduce the space of wave functions to a smaller subspace within the
full Hilbert space. The trial functions are then optimized within the reduced subspace
in order to obtain an approximation as close as possible to the exact full-space solution.
Consider, for example, a bounded particle in a one-dimensional coordinate space
(x). All the proper functions having a specific analytic form can be the trial functions.
Introducing a dependence of these functions on a parameter, σ, for example, f(x,σ),
the variation of σ can yield an optimal solution in the sense of being closest to an
exact solution. A different example of a space of trial functions corresponds to linear
combinations of a known set of functions, for example, f(x,a1,a2) = a1φ1(x)+a2φ2(x).
Here, the expansion coefficients, a1 and a2, can be varied for optimizing the solution.
When considering multidimensional (or many-particle) coordinate systems, the trial
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press183 12.3 The Variation Approach
space can be associated with additional constraints. For example, it can include all
possible products of normalized one-coordinate functions, and so on. In what follows
we shall discuss such examples in detail. First, we introduce the general guidelines for
optimizing the trial function for a given system, characterized by the Hamiltonian, Hˆ.
For convenience, we shall use Dirac’s notations, referring to the corresponding state
vectors.
We wish to approximate the solutions of the time-independent Schrödinger equa￾tion, Hˆ|ψi = E|ψi, by introducing a trial solution, denoted as a vector, |ψ˜i. The energy
associated with the trial vector is termed the variational energy, and it is defined as the
expectation value of the Hamiltonian,
ε˜ ≡
hψ˜ |Hˆ|ψ˜i
hψ˜ |ψ˜i
. (12.3.1)
We now define an “error vector” associated with the trial function,
|ϕi ≡ Hˆ|ψ˜i −ε˜|ψ˜i. (12.3.2)
If the trial function coincides with an exact Hamiltonian eigenstate, the error is shown
to strictly vanish. Otherwise, the error vector can be used to assess the deviation of
|ψ˜i from an exact solution, where an optimal |ψ˜i is associated with a minimal error.
Invoking a Galerkin approach [12.4], an optimal state in the space of trial functions
(the variation space) is reached when the corresponding error vector, |ϕi value becomes
orthogonal to any infinitesimal change in the trial function, |δψ˜i. Namely, within the
constraints associated with the variation space, the error cannot be further minimized
by any infinitesimal change in |ψ˜i,
hδψ˜ |ϕi|ψ˜opt = 0, for any δψ˜ (12.3.3)
Using Eq. (12.3.2), the condition for an optimal trial function reads
hδψ˜ |Hˆ −ε˜|ψ˜i|ψ˜opt = 0, for any δψ˜ (12.3.4)
As a concrete example, let us consider a space of trial functions that depend on a
continuous parameter, σ, where variation in |ψ˜i is associated with variation of this
parameter. Particularly, an infinitesimal change is defined as
|δψ˜i ≡





∂
∂σ
ψ˜
+
dσ . (12.3.5)
In this case, the general optimization condition, Eq. (12.3.4), amounts to (see
Ex. 12.3.1)
∂ ε˜
∂σ




σopt
= 0. (12.3.6)
Namely, the optimal value of σ corresponds to a stationary point of the expectation value,
ε˜(σ).
Exercise 12.3.1 (a) Show that for |δψ˜i ≡



∂
∂σ
ψ˜
E
dσ, the general condition for the
optimal trial function (Eq. (12.3.4)) obtains the form D
∂
∂σ
ψ˜



Hˆ − ε˜|ψ˜i = 0. (b) Use
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press184 Approximation Methods
the Hermiticity of Hˆ to show that this condition leads to ∂
∂σ
hψ˜ |Hˆ|ψ˜i = ε˜
∂
∂σ
hψ˜ |ψ˜i. (c)
Use the result of(b) and the definition of the variational energy (Eq. (12.3.1)) to obtain
Eq. (12.3.6).
The Variation Principle
A critical aspect of the variation approach is the fundamental relation between the
optimal variational energy ε˜, associated with a given variation space, |ψ˜i, and the exact
energy levels of a given system. Recalling that the system Hamiltonian eigenstates con￾stitute a complete orthogonal system of vectors that span the full Hilbert space, any
trial function in that space can be expanded using the complete set,
Hˆ|φni = En|φni ; |ψ˜i =
∞
∑
n=0
an|φni, (12.3.7)
where n = 0 denotes here the ground (minimal energy) state of the system. Conse￾quently, the variational energy is a weighted average of the exact Hamiltonian eigen￾values (see Eq. (11.7.2)), and as such, it is larger or equal to the ground state energy,
ε˜ =
hψ˜ |Hˆ|ψ˜i
hψ˜ |ψ˜i
=
∞
∑
n=0
|an|
2En
∞
∑
n=0
|an|
2
≥
∞
∑
n=0
|an|
2E0
∞
∑
n=0
|an|
2
= E0. (12.3.8)
It follows that the variational energy ε˜ is an upper bound to the exact ground-state energy.
Therefore, the optimal trial function with respect to the ground state of a system is the
one that minimizes ε˜. Referring again to the concrete example defined in Eq. (12.3.5),
the optimization condition derived from a Galerkin condition, Eq. (12.3.6), is indeed
a necessary condition for a minimum of the variational energy as a function of the
variation parameter, that is, a minimum of ε˜(σ).
Given a variation space, the variation principle as expressed in Eq. (12.3.8) pro￾vides a guideline for searching the optimal approximation to the ground state of a
given system. Indeed, any variation leading to a decrease in ε˜ improves on the trial
function.Additionally, re-minimization of ε˜ within an extended variation space (by
removing constraints) cannot increase the optimal value, and will typically reduce it,
yielding an improved approximation. This is the main idea beyond powerful algo￾rithms (as, e.g., the linear variation method, to be discussed in what follows), which
can converge efficiently toward the exact ground-state solution.
The variation principle is not restricted to approximating the ground state of a sys￾tem. If the ground state |ψ0i is known exactly, it is instructive to use trial functions
that are orthogonal to it, namely |ψ˜i = |φ˜i − |ψ0ihψ0|φ˜i. In this case we can read￾ily see (Ex. 12.3.2) that ε˜ is an upper bound to the first excited-state energy, ε˜ ≥ E1,
and similarly, a trial function |ψ˜i = |φ˜i −
N
∑
n=0
|ψnihψn|φ˜i (where the counting index
n = 1,2,...,N covers the set of all the eigenstates associated with an energy smaller
than EN+1) yields a variation energy that is an upper bound to the exact energy level,
EN+1.
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press185 12.3 The Variation Approach
Exercise 12.3.2 A trial function is defined as |ψ˜i = |φ˜i −
N
∑
n=0
|ψnihψn|φ˜i, where
|ψni are all the orthonormal eigenstates of the corresponding system Hamiltonian,
Hˆ|ψni = En|ψni, with energy smaller than EN+1.(a) Show that |ψ˜i is orthogonal to
{|ψni}, for n = 0,1,...,N. (b) Use the definition of the variational energy (Eq. (12.3.1))
and follow Eq. (12.3.8) to show that ε˜ ≥ EN+1.
Nonlinear Variation
To demonstrate a concrete implementation of the variation principle, we chose an
example of a particle in an effective semi-infinite one-dimensional quantum well, as
described in Fig. 12.3.1 and Eq. (12.3.9). The exact bound states for this model can
be readily obtained by solving the Schrödinger equation, which translates to solving a
homogeneous linear equation. (See the discussion of a similar problem in Sections 6.2,
6.3.) Here, however, we demonstrate a variation approach to the same problem.
V(x) =



x < 0 ; ∞
0 ≤ x ≤ L ; 0
x > L ; V0
(12.3.9)
Motivated by the known analytic solution for the ground state of a similar prob￾lem, that is, a particle in an infinite box, ψ1(x) = q
2
L
sin￾
πx
L

, and yet realizing that
when the external potential, V0, is finite, the wave function should penetrate the clas￾sically forbidden region extending beyond the box dimensions, x > L, we can attempt
to use trial functions that are normalized particle-in-a-box functions, associated with
a variable “box-length,” L → L+∆:
ψ˜(∆; x) =



x < 0 ; 0
0 ≤ x ≤ L+∆ ;
q
2
L+∆
sin￾
πx
L+∆

.
x > L+∆ ; 0
(12.3.10)
0
0
V0
V(x)
x
L
ψ (x ) ∼
L+∆
Ftigure 12.3.1 A semi-infinite quantum well potential (thick line) and a trial functionψ˜(x)(thin line) chosen for approximating the
ground-state energy. The trial function is taken to be the exact ground state of an infinite box potential in which the
box length varies to account approximately for the wave function penetration in the region to the right of the
semi-infinite quantum well.
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Pre186 Approximation Methods
The box extension parameter, ∆ ≥ 0, is regarded here as the variation parameter. To
find the optimal effective box length, we seek to minimize the variational energy by
satisfying the stationarity condition (Eq. (12.3.6)),
dε˜(∆)
d∆





∆opt
= 0. (12.3.11)
The variational energy (Eq. (12.3.1)) is the expectation value of the system Hamilto￾nian, which reads in the present case
ε˜(∆) = 2
L+∆
L
w
+∆
0
dx sin
πx
L+∆

−h
2
2m
∂
2
∂ x
2
+V(x)

sin
πx
L+∆

. (12.3.12)
The explicit expression for ε˜(∆) simplifies by assuming that the ground state energy
is lying “deep” inside the potential energy well; namely, it is much smaller than V0.
Consequently, the required extension of the box length is expected to be small with
respect to the box length itself, namely ∆ << L+∆. In this case (see Ex. (12.3.3)),
ε˜(∆) ∼=
h¯
2π
2
2m(L+∆)
2
+V0
2π
2
3
∆
3
(L+∆)
3
. (12.3.13)
According to the optimization condition, Eq. (12.3.11), the optimal box extension
length reads (Ex. (12.3.4))
∆opt =
L
2α
(1+
√
1+4α) ; α ≡ V0/(h¯
2
/2mL2
). (12.3.14)
When the ground-state energy is much smaller than V0, the parameter α is much larger
than 1, and the optimal box extension can be approximated as ∆opt ≈ √
L
α
, where, as
can be anticipated, ∆opt becomes smaller for larger V0 values. In particular, ∆opt → 0 as
V0 → ∞, and the corresponding variational energy approaches the exact value of the
ground-state energy of an infinite potential well, ε˜(∆) −−−→
V0→∞
h¯
2π
2
2mL2
.
Exercise 12.3.3 (a) Show that the exact expression for the variational energy, as defined
in Eq. (12.3.12), reads ε˜(∆) = h¯
2π
2
2m(L+∆)
2 +
V0∆
L+∆ +
V0
2π
sin
2π
￾
1−
∆
L+∆
. (b) Obtain the
approximation, Eq. (12.3.13), by expanding the result for ∆ << L+∆.
Exercise 12.3.4 Obtain the optimal value of the box extension parameter, ∆opt
(Eq. (12.3.14)), according to the variation principle. (Recall that ∆ ≥ 0.)
Exercise 12.3.5 Recall the definition of the penetration length, Eq. (6.2.4), for a particle
in a finite potential well, γ = √
h¯
2m(V0−E)
, and show that when the ground-state energy is
much smaller than V0, the optimal value, ∆opt, increases with the penetration length (as
might be expected).
Exercise 12.3.6 Calculate numerically the exact ground-state energies for a particle
in a semi-infinite potential energy well, corresponding to V0/E
(∞)
1 = 10,100,1000,10000
(Eq. (12.3.9)), using the approach described in Section 6.3. Show that the respective
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Pres187 12.3 The Variation Approach
Ftigure 12.3.2 Variational calculations of the ground-state energies for a set of semi-infinite quantum well potentials (see
Eq. (12.3.9)) withV0/E
(∞)
1 =10,100, 1000, 10000 (corresponding to solid, dotted, dot-dashed, and dashed lines,
respectively). The curved lines are the variational energies plotted as functions of the box extension parameter, ∆. For
each quantum well, the optimal variational approximation (marked by a circle) is shown to be greater than the exact
ground-state energy (marked by the horizontal lines; see Ex.12.3.6). The optimal variational approximations follow
the correct qualitative trend of increasing ground-state energy with increasingV0, and approach the value E
(∞)
1
,
which corresponds to an infinite box potential. Moreover, owing to the specific choice of the trial function, the relative
error in the variational approximation decreases with increasingV0, as the trial function approaches the exact
ground-state wave function.
ground-state energies are 0.823310, 0.939163, 0.980165, 0.993664, in units of E
(∞)
1 =
h¯
2π
2/(2mL2
).
For any finite value of V0, the optimal variational energy is only an upper bound for
the exact ground-state energy of the particle in the finite potential well, as illustrated in
Fig. 12.3.2. It is interesting to notice that the exact ground-state energy for any finite
V0 must be smaller than the ground-state energy for an infinite potential well of the
same length, namely smaller than E
(∞)
1 =
h¯
2π
2
2mL2
. This result holds, since the variation
principle means that E
(V0)
1 ≤ ε˜(∆) for any ∆. Since ε˜(0) = E
(∞)
1
, we have E
(V0)
1 ≤ E
(∞)
1
.
The equality corresponds to V0 → ∞, and we can therefore conclude that for any finite
V0, we have E
(V0)
1 < E
(∞)
1
.
The Method of Linear Variation
It is most useful to extend the variation space by considering trial functions of several
parameters, for example, |ψ˜(c1, c2,..., cN)i. Infinitesimal changes in these parameters
correspond to infinitesimal changes in |ψ˜i or hψ˜ |,
|δψ˜i =
N
∑
n=1




∂
∂ cn
ψ˜

dcn ; hδψ˜ | =
N
∑
n=1
dcn

∂
∂ cn
ψ˜




, (12.3.15)
which generalizes Eq. (12.3.5). The equations for the optimal parameter values are
derived from the general optimization condition, hδψ˜ |Hˆ −ε˜|ψ˜i|ψ˜opt = 0, for any |δψ˜i
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press188 Approximation Methods
(see Eq. (12.3.4)), which reads in this case
N
∑
n=1
dcn
D
∂
∂ cn
ψ˜



Hˆ −ε˜|ψ˜i



ψ˜opt
= 0 for any dCn
.
This yields the following set of N equations,

∂
∂ cn
ψ˜




Hˆ −ε˜|ψ˜i





c
(opt)
= 0 ; n = 1,2,...,N, (12.3.16)
where the optimal trial function is associated with the optimal parameter set, c
(opt) =
(c
(opt)
1
, c
(opt)
2
,..., c
(opt)
N
). Extending the derivation in Ex. 12.3.1 to several variables, the
optimization conditions (Eq. (12.3.16)) lead to a set of equations (see Ex. 12.3.7),
∂ ε˜
∂ cn




c
(opt)
= 0 ; n = 1,2,...,N. (12.3.17)
Exercise 12.3.7 Generalize the derivation of the optimization condition for a single var￾iation parameter, Ex. 12.3.1, to the case of several variation parameters and show that
Eq. (12.3.17) is obtained from Eq. (12.3.16).
A most powerful approach to variation in a multiple-parameter space is the method
of linear variation. The idea is to expand the trial functions as linear combination of
a known set of functions within the relevant space of physical states and to regard the
expansion coefficients as variation parameters. In this case the trial function takes the
generic form,
|ψ˜i =
N
∑
n
0=1
cn
0|φn
0i, (12.3.18)
where the functions, {|φ1i,|φ2i,...,|φNi}, are termed the basis set for the variation
space. Taking the partial derivatives with respect to the expansion coefficients, we
obtain




∂
∂ cn
ψ˜

= |φni ; n = 1,2,...,N. (12.3.19)
The corresponding bra reads D
∂
∂ cn
ψ˜


 = hφn|, where the set of equations for the optimal
coefficients (Eq. (12.3.16)) take a particularly simple form,
hφn|Hˆ −ε˜|ψ˜i|c
(opt) = 0 ; n = 1,2,...,N. (12.3.20)
Substitution of the trial function, Eq. (12.3.18), we obtain a system of N linear
equations for the N optimal expansion coefficients,
N
∑
n
0=1
hφn|Hˆ −ε˜|φn
0ic
(opt)
n
0 = 0 ; n = 1,2,...,N. (12.3.21)
By defining two matrices, H and S, of dimension, N ×N, whose elements are
Hn,n
0 = hφn|Hˆ|φn
0i
Sn,n
0 = hφn|φn
0i
, (12.3.22)
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press189 12.3 The Variation Approach
the system of linear equations can be identified as a generalized eigenvalue equation,
N
∑
n
0=1
[Hn,n
0 −ε˜Sn,n
0]c
(opt)
n
0 = 0 ; n = 1,2,...,N, (12.3.23)
or, in matrix notations, it is often termed the secular equation,
[H−ε˜S]c
(opt) = 0. (12.3.24)
The matrix H is the representation of the Hamiltonian within (namely, its projec￾tion onto) the finite-dimensional variation space. The matrix S is often referred to
as the overlap matrix, since its entries are the overlap integrals (Eq. (4.6.1)) between
the different basis functions. Notice that the algebraic equation has generally multiple
eigenvalues. According to the variation principle, Eq. (12.3.8), the lowest eigen￾value, ε˜0 = min(ε˜1, ε˜2,..., ε˜N), is the best approximation (from above) to the exact
ground-state energy of the system,
ε˜0 ≥ E0. (12.3.25)
The eigenvector corresponding to ε˜0, namely c
(opt)
0 = (c
(opt)
1,0
, c
(opt)
2,0
,..., c
(opt)
N,0
), defines
the optimal approximation to the ground-state wave function within the variation
space,
|ψ˜0i =
N
∑
n
0=1
c
(opt)
n
0
,0
|φn
0i. (12.3.26)
When the set of basis functions is orthonormal, S becomes an identity matrix, and
consequently, the secular equation, Eq. (12.3.24), simplifies to
S = I ; Hc(opt) = ε˜c
(opt)
(12.3.27)
In this case, the expansion coefficients can be interpreted as the projections of |ψ˜i
on the basis functions, namely cn = hφn|ψ˜i. It is instructive to define a projection
operator onto the variation space, PˆN ≡
N
∑
n
0=1
|φn
0ihφn
0|, where hφn
0|φn
00i = δn
0
,n
00 . Using
the identity, Pˆ2
N = PˆN, we can rewrite Eq. (12.3.27) for the optimal trial function as
[PˆNHˆ PˆN]PˆN|ψ˜i = ε˜PˆN|ψ˜i, which means that the optimal approximations for the trial
function and the variational energy in a given linear variation space are obtained by
solving the eigenvalue equation for the projection of the full Hamiltonian (PˆNHˆ PˆN)
onto that space. Extending the variation space by increasing N toward the entire space,
pˆN −−−→
N→∞
ˆI this eigenvalue equation coincides with the exact Schrödinger equation,
Hˆ|ψ˜i = ε˜|ψ˜ , which means that |ψ˜i −−−→N→∞
|ψi, and ε˜ −−−→
N→∞
E, where E is the exact eigen￾value of Hˆ. Indeed, optimizing the expansion coefficients within an increasingly larger
variation space, the eigenvalues and eigenvectors of PˆNHˆ PˆN converge to the exact ones,
limN→∞|ψ˜i|c
(opt) =
∞
∑
n
0=1
c
(opt)
n
0
|φn
0i = |ψi ; hφn
0|φn
00i = δn
0
,n
00
limN→∞ε˜(c
(opt)
) = limN→∞
hψ˜ |Hˆ|ψ˜i
hψ˜ |ψ˜i




c
(opt)
= E. (12.3.28)
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press190 Approximation Methods
Importantly, Eq. (12.3.28) is not restricted to the ground state of the system, and
applies to any of the eigenvectors of Eq. (12.3.27) in the N → ∞ limit. Therefore, the
set of eigenvectors of Eq. (12.3.27) provides a set of approximations to the energy
levels {ε˜m} and corresponding wave functions, |ψ˜mi =
N
∑
n
0=1
c
(opt)
n
0
,m
|φn
0i, which converge,
respectively, to the exact energy levels and eigenfunctions of the Hamiltonian as N → ∞.
The eigenvalues and expansion coefficients can be obtained by efficient numeri￾cal matrix diagonalization techniques [12.5], which make the linear variation a most
powerful approach for obtaining approximate solutions to the Schrödinger equation.
Notice that the matrix representation of the Hamiltonian operator for any N is Hermi￾tian, that is, H∗t = H. Consequently, its eigenvectors are an orthonormal basis set for
the corresponding N-dimensional vector space, which means that the set of approxi￾mated functions, |ψ˜mi, is therefore also orthonormal: hψ˜m|ψ˜m0i = δm,m0 . (See Ex. 12.1.6
for a similar consideration.)
To demonstrate a concrete implementation of the linear variation principle, we chose
the analytically solvable model of a one-dimensional harmonic oscillator,
Hˆ =
h¯Ω
2
[yˆ
2 + pˆ
2
y
], (12.3.29)
where yˆ and pˆy are the corresponding dimensionless position and momentum oper￾ators (see Eqs. (8.5.8–8.5.11)), and Ω is the classical oscillator frequency. The energy
levels for this system are analytically known, namely En = h¯Ω
￾
n+
1
2

, for n = 0,1,2... .
For demonstrating the linear variation method, we ignore our knowledge of the exact
solutions and follow the procedure set by Eqs. (12.3.18, 12.3.22, 12.3.27, 12.3.28) to
obtain optimal approximated solutions.
Let us start by choosing a basis set for expanding the eigenfunctions. In the present
example we chose a finite set of particle-in-a-box wave functions (see Eq. (5.3.9)),
hy|φni =



0
q
; −L/2 > y
2
L
sin
nπ
L
(y+L/2)

; −L/2 ≤ y ≤ L/2 ; n = 1,2,3,...,N
0 ; L/2 < y
.
(12.3.30)
Notice that the functions are displaced such that they are centered at the minimum of
the potential energy well at y = 0 and are confined to the region −L/2 ≤ y ≤ L/2, where
L is the box length in dimensionless units. (Also notice that the boundary conditions
on the basis functions, hy|φni −−−−−→
y→±L/2
0 are only adequate for expanding functions
that are confined to the same region, and therefore, accurate approximations to the
eigenfunctions of the harmonic oscillator Hamiltonian, associated with increasingly
large quantum numbers, can only be obtained by increasing L accordingly.) The next
step is to construct the N-dimensional matrices H and S, whose elements are given as
Hn,n
0(L) = h¯Ω
L
L/2
w
−L/2
dy sinh
nπ
L
(y+L/2)
i

y
2 −
d
2
dy
2

sin
n
0π
L
(y+L/2)

Sn,n
0(L) =
2
L
L/2
w
−L/2
dy sinh
nπ
L
(y+L/2)
i
sin
n
0π
L
(y+L/2)

= δn,n
0
n,n
0 ∈ 1,2,3,...,N. (12.3.31)
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Pres191 12.3 The Variation Approach
Ftigure 12.3.3 Linear variation calculations of the lowest energy levels of a harmonic oscillator, using particle-in-a-box basis
functions, with box lengths L = 20 and L = 40 in the left and right plots, by matrix diagonalization are marked as
circles, and the exact eigenvalues are marked as dashed horizontal lines.
Ftigure 12.3.4 The variational ground-state energy of a harmonic oscillator, optimized using the linear variation method with
N = 4,6,8 particle-in-a-box basis functions. By regarding the box length (L)as a nonlinear variation parameter,
the variational energy can be minimized to obtain an optimal approximation to the exact ground-state energy
(E = 0.5h¯Ω) within each variation space.
Since the basis functions are orthonormal, the variational approximations for
the eigenvalues and eigenvectors are obtained by solving the corresponding secular
equation, Eq. (12.3.27), namely finding the roots of the corresponding determinant,
|H−ε˜I| = 0. (12.3.32)
In Fig. 12.3.3 the eigenvalues of H, as obtained by numerical matrix diagonalization,
are plotted as functions of the size of the variation space (N) for two choices of the
box length, L. As N increases, the spectrum of the finite size matrices converges (from
above) toward the exact spectrum of the Hamiltonian (Eq. (12.3.28)). Notice that the
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press192 Approximation Methods
variational approximations for the energy levels for a given N depend on the box length,
L. Indeed, for any (fixed) N, the trial function depends on L, which can be optimized
as an additional nonlinear variation parameter. This is demonstrated in Fig. 12.3.4 for
the oscillator ground state energy.
The applications of the linear variation approach are far-reaching. Apart from being
a powerful computational tool, enabling us to map the solution of multidimensional
differential eigenvalue equations onto matrix algebra problems, the representation of
quantum states in terms of finite-dimensional vectors is intuitive and conceptually
useful. Associating a basis set with physically meaningful states, where the system
eigenstates are associated with linear combinations of these states, assigns physical
meaning to the expansion coefficients and helps to obtain insight into the system under
study. As we shall see in the coming chapters, fundamental concepts such as molecu￾lar orbitals are based on linear combinations of atomic orbitals, which are remarkably
useful for describing charge delocalization between different atoms to form chemi￾cal bonds in molecules. Similar concepts are used for the description of delocalized
band states in solid crystals as linear combinations of localized atomic orbitals. These
concepts are useful for understanding macroscopic bulk properties of different solid
materials on the basis of their microscopic unit cell structure.
The Mean-Field Approximation
In the examples discussed so far, the space of trial functions was characterized by a
set of parameters, optimized according to the variation principle. Here we consider
a somewhat broader definition of the variation space, especially tailored to systems
of multidimensional coordinates (e.g., many-particle systems), in which the physical
states are defined in tensor product spaces (see Section 11.6). The resulting “mean￾field approximation” is a powerful approach to multidimensional quantum mechanical
systems. In many-electron systems it provides the foundation for the concept of elec￾tronic orbitals, a most successful tool for interpreting the structure of many-electron
atoms and of the periodic table of the elements (see Chapter 13). Electronic orbitals are
most useful also in the description of molecular and crystalline materials (see Chap￾ter 14), as well as in approximate descriptions of processes on the nanoscale, involving
electron transfer, electron energy transfer, light–matter interactions, and more (see
Chapters 18–20). In other many-particle systems, involving bosons, the mean-field
approximation yields the Gross–Pitaevskii equation, often used to describe the phe￾nomenon of Bose–Einstein condensation [12.6]. In all cases, when valid, the mean-field
approximation enables us to discuss a many-body system, whose complexity increases
exponentially with the number of particles, in terms of a set of coupled single-particle
systems, which are much more tractable. Moreover, this approximation provides intu￾itive interpretation of the underlying physics from a single-particle perspective. For
systems with effectively strong interparticle coupling, the mean-field approximation
breaks down and cannot account for all aspects of the correlated many particles. Nev￾ertheless, it is still useful as a starting point for corrections by perturbation theory or
for generating basis sets for extended linear variation treatments.
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press193 12.3 The Variation Approach
For simplicity, we start our discussion with the case of a two-dimensional coor￾dinate space, corresponding, for example, to two particles in a one-dimensional
space or to a single-particle in a two-dimensional space. The generalization to the
multidimensional/many-particle cases follows. Specifically, let us consider a Hamil￾tonian of the generic form,
Hˆ ≡ Hˆ
1 +Hˆ
2 +Vˆ
1,2, (12.3.33)
where x1 and x2 are two Cartesian coordinates. Hˆ
1 and Hˆ
2 are operators in the respec￾tive single-coordinate subspaces, where their representations in the two-coordinate
space are Hˆ
1 ⊗ ˆI2 and ˆI1 ⊗ Hˆ
2, respectively, and Vˆ
1,2 is a coupling operator within the
two spaces. In the absence of such a coupling (setting Vˆ
1,2 to zero), the eigenstates
of Hˆ are product states, namely (Hˆ
1 ⊗ ˆI + ˆI ⊗ Hˆ
2)|φi ⊗ |χi = (λφ + λχ)|φi ⊗ |χi (see
Eq. (11.6.24)). In general, however, when Vˆ
1,2 6= 0, the exact eigenstates of the Hamil￾tonian cannot be expressed as single products, |ψi 6= |φi ⊗ |χi. If the two coordinates
correspond to different particles, the particles are said to be entangled in this case, which
means that their properties cannot be determined independently (the particles are corre￾lated). Instead, the general expression for the Hamiltonian eigenstates in the presence
of a finite interaction (Vˆ
1,2 6= 0) involves a sum of products (see Eqs. (11.6.8–11.6.12)),
[Hˆ
1 +Hˆ
1 +Vˆ
1,2]|ψi = E|ψi ; |ψi = ∑n1,n2
ψn1,n2
|αn1
i ⊗|βn2
i, (12.3.34)
where the sets {|αn1
i} and {|βn2
i} span the single-coordinate spaces, ˆI1 = ∑
n1
|αn1
ihαn1
|,
and ˆI2 = ∑
n2
|βn2
ihβn2
|.
In spite of the inherent correlation between the two coordinates within each Hamil￾tonian eigenstate forVˆ
1,2 6= 0, in many applications the coupling operator is sufficiently
small in some sense, where it is useful to seek for approximations in the form of a single
products to the Hamiltonian eigenstates. For this purpose, we may refer to the space
of all possible products of normalized proper states as the variation space. Each trial
state is therefore formulated as
|ψ˜i ≡ |φ˜i ⊗ |χ˜i, (12.3.35)
where
hφ˜|φ˜i = 1 ; hχ˜|χ˜i = 1. (12.3.36)
Any infinitesimal variation in |ψ˜i, subject to the constrained product form, amounts
to either |δ χ˜i or |δφ˜i, namely
|δψ˜i = |δφ˜i ⊗ |χ˜i+|φ˜i ⊗ |δ χ˜i ; hδψ˜ | = hδφ˜| ⊗ hχ˜|+hφ˜| ⊗ hδ χ˜|. (12.3.37)
Invoking the general variation optimization condition,hδψ˜ |[Hˆ −ε˜]|ψ˜i = 0 for any hδψ˜ |
(Eq. (12.3.4)), and using Eq. (12.3.37), two coupled equations are obtained,
hδφ˜| ⊗ hχ˜|[Hˆ −ε˜]|φ˜i ⊗ |χ˜i = 0 ; hφ˜| ⊗ hδ χ˜|[Hˆ −ε˜]|φ˜i ⊗ |χ˜i = 0, (12.3.38)
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press194 Approximation Methods
where the optimal product states, |φ˜i and |χ˜i, must satisfy these equations for any
infinitesimal changes, hδφ˜| and hδ χ˜|. This means that (see Ex. 12.3.8, for an explicit
derivation)
hχ˜opt|Hˆ|χ˜opti|φ˜opti = ε˜|φ˜opti ; hφ˜opt|Hˆ|φ˜opti|χ˜opti = ε˜|χ˜opti. (12.3.39)
The optimal states, |φ˜opti and |χ˜opti, turn out to be eigenvectors of effective Ham￾iltonian operators in their respective single-coordinate spaces, associated with the
eigenvalue, ε˜. These effective Hamiltonians, hχ˜opt|Hˆ|χ˜opti ≡ Hˆ
(χ˜)
1
and hφ˜opt|Hˆ|φ˜opti ≡
Hˆ
(φ˜)
2
, are obtained by partial averaging over vectors (|φ˜opti or|χ˜opti) in the complemen￾tary vector space (see Ex. 12.3.8). Considering the generic form of the full Hamiltonian,
Eq. (12.3.33), we obtain
hχ˜opt|Hˆ|χ˜opti = Hˆ
1 +hχ˜opt|Vˆ
1,2|χ˜opti+hχ˜opt|Hˆ
2|χ˜opti
hφ˜opt|Hˆ|φ˜opti = Hˆ
2 +hφ˜opt|Vˆ
1,2|φ˜opti+hφ˜opt|Hˆ
1|φ˜opti
. (12.3.40)
The terms hχ˜opt|Hˆ
2|χ˜opti and hφ˜opt|Hˆ
1|φ˜opti are scalars corresponding to expectation
values in the one-dimensional coordinate spaces. Therefore, they merely shift the
eigenvalues in Eq. (12.3.39), which can be reformulated as
[Hˆ
1 +hχ˜opt|Vˆ
1,2|χ˜opti]|φ˜opti = ε˜φ˜opt |φ˜opti
[Hˆ
2 +hφ˜opt|Vˆ
1,2|φ˜opti]|χ˜opti = ε˜χ˜opt |χ˜opti
, (12.3.41)
where
ε˜φ˜opt ≡ ε˜ − hχ˜opt|Hˆ
2|χ˜opti
ε˜χ˜opt ≡ ε˜ − hφ˜opt|Hˆ
1|φ˜opti
. (12.3.42)
The coupled eigenvalue equations, Eq. (12.3.41), are termed the mean-field equations.
The “mean-field” in this context refers to the way in which the coupling between the
two coordinate subspaces is accounted for. Instead of the fully detailed Vˆ
1,2, which
appears in the full multidimensional Schrödinger equation, the mean-field equations
associate each single coordinate space with an reduced effective equation, in which
the coupling to the complementary space is represented as an effective field. These
fields are derived by partially averaging over the complementary space, hence the
operators hχ˜opt|Vˆ
1,2|χ˜opti and hφ˜opt|Vˆ
1,2|φ˜opti are termed the “mean-field operators.”
Notice that the two equations are coupled, in the sense that the field appearing in
one of them depends on the solution of the other equation. In practice, such non￾linear coupled equations are often solved by guessing an initial form of |φ˜opti and/or
|χ˜opti and improving iteratively, until a self-consistent solution for the two equations
is reached. The converged mean-fields are therefore sometimes referred to as the self￾consistent-field (SCF), and the solutions to Eq. (12.3.41) are referred to as the SCF
solutions.
Exercise 12.3.8 A two-dimensional coordinate system is associated with an iden￾tity operator, ˆI = ˆI1 ⊗ ˆI2 = ∑
n1
|αn1
ihαn1
| ⊗ ∑
n2
|βn2
ihβn2
|, where {|αn1
i} and {|βn2
i} are
complete orthonormal systems in the respective spaces. A general operator in the full
space reads (see Eq. (11.6.14)) Aˆ = ∑
n1,n
0
1
∑
n2,n
0
2
An1,n
0
1
,n2,n
0
2
|αn1
ihαn
0
1
| ⊗ |βn2
ihβn
0
2
|. Given
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press195 12.3 The Variation Approach
two vectors in the respective one-dimensional coordinated spaces, |φ˜i = ∑
n1
φ˜n1
|αn1
i and
|χ˜i = ∑
n2
χ˜n2
|βn2
i, show that:
(a) hχ˜|Aˆ|φ˜i ⊗ |χ˜i = Aˆ
(χ˜)
1
|φ˜i, where
Aˆ
(χ˜)
1 = ∑
n1,n
0
1
,n2,n
0
2
An1,n
0
1
,n2,n
0
2
hχ˜|βn2
ihβn
0
2
|χ˜i|αn1
ihαn
0
1
| = hχ˜|Aˆ|χ˜i.
(b) hφ˜|Aˆ|φ˜i ⊗ |χ˜i = Aˆ
(φ˜)
2
|χ˜i, where
Aˆ
(φ˜)
2 = ∑
n1,n
0
1
,n2,n
0
2
An1,n
0
1
,n2,n
0
2
hφ˜|αn1
ihαn
0
1
|φ˜i|βn2
ihβn
0
2
| = hφ˜|Aˆ|φ˜i.
(c) Use the results of (a) and (b) to show thathχ˜|[Hˆ −ε˜]|φ˜i⊗|χ˜i = 0 ⇒ Hˆ
(χ˜)
1
|φ˜i = ε˜|φ˜i
and hφ˜|[Hˆ −ε˜]|φ˜i ⊗ |χ˜i = 0 ⇒ Hˆ
(φ˜)
2
|χ˜i = ε˜|χ˜i.
The solution to the mean-field (or the SCF) equations provides the variation￾ally optimal product state approximations to the eigenstates of the two-dimensional
Hamiltonian,
|ψi ≈ |ψ˜opti ≡ |φ˜opti ⊗ |χ˜opti, (12.3.43)
where the corresponding variational energy reads (see Ex. 12.3.9)
ε˜ = hψ˜ |Hˆ|ψ˜i = ε˜φ˜opt +ε˜χ˜opt − hψ˜ |Vˆ
1,2|ψ˜i. (12.3.44)
Exercise 12.3.9 Use Eq. (12.3.41) to derive the relation in Eq. (12.3.44).
The generalization of the product state approximation to N-dimensional Hamilto￾nians is straightforward. Considering the Hamiltonian,
Hˆ =
"
N
∑
n=1
Hˆ
n
#
+Vˆ
1,2,...,N, (12.3.45)
the mean-field product trial state reads
|ψ˜i ≡ |φ˜opt,1i ⊗ |φ˜opt,2i ⊗ ··· ⊗|φ˜opt,Ni, (12.3.46)
where the set {|φ˜opt,ni} is the solutions of the following coupled SCF equations,
[Hˆ
n +Hˆ
(φ˜opt,1,φ˜opt,2,...φ˜opt,n−1,...φ˜opt,n+1,...,φ˜opt,N)
n |φ˜opt,ni = ε˜φ˜opt,n
|φ˜opt,ni ; n = 1,2,...,N,
(12.3.47)
where
ε˜φ˜opt,n = ε˜ −
N
∑
n
0=1
n
06=n
hφ˜opt,n
0|Hˆ
n
0|φ˜opt,n
0i. (12.3.48)
Hˆ
(φ˜opt,1,φ˜opt,2,...φ˜opt,n−1,φ˜opt,n+1,...,φ˜opt.N)
n = hφ˜opt,1| ⊗...hφ˜opt,n−1| ⊗ hφ˜opt,n+1|...⊗
hφ˜opt,N|Vˆ
1,2,...,N|φ˜opt,1i ⊗...|φ˜opt,n−1i ⊗|φ˜opt,n+1i...⊗|φ˜opt,Ni,
(12.3.49)
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press196 Approximation Methods
and the variational energy reads
ε˜ =
N
∑
n=1
ε˜φ˜opt ,n −[N −1]hψ˜ |Vˆ
1,2,...,N|ψ˜i. (12.3.50)
Notice that the variational energy is different from the sum of eigenvalues as obtained
from the different SCF equations. Indeed, the expectation value of the coupling oper￾ator (times N −1) must be subtracted from the sum of SCF eigenvalues to obtain the
total state energy. This is attributed to overcounting of the interaction operator within
the SCF equations, in which this operator appears N times. (This does not apply in the
absence of interaction; see Ex. 12.3.10.)
Exercise 12.3.10 Show that in the absence of coupling, namely when Vˆ
1,2,...,N = 0,
the variational energy equals the sum of independent variational energies in the one￾dimensional coordinate subspaces, namely ε˜ =
N
∑
n=1
ε˜φ˜opt ,n =
N
∑
n=1
hφ˜opt,n|Hˆ
n|φ˜opt,ni.
According to the variation principle, the energy associated with the ground-state
solutions of the coupled SCF equations is an upper bound for the exact ground￾state energy of the system. Denoting the ground-state eigenvalue and eigenstate of
each equation (Eq. (12.3.47)) as ε˜
(0)
opt,n and |φ˜
(0)
opt,n
i, respectively, the optimal approx￾imation for the system’s ground state by the mean field approximation is |ψ˜0i ≡
|φ˜
(0)
opt,1
i ⊗ |φ˜
(0)
opt,2
i ⊗ ··· ⊗|φ˜
(0)
opt,N
i, where the corresponding energy reads
ε˜ 0 =
N
∑
n=1
ε˜
(0)
opt,n −[N −1]hψ˜0|Vˆ
1,2,...,N|ψ˜0i ≥ E0. (12.3.51)
As a concrete implementation of the mean-field approximation, let us consider a
system of two electrons bound to a positive nucleus in an isolated He atom. Setting the
nucleus at rest, the Hamiltonian for the two electrons obtains the form (Eq. (3.4.10))
Hˆ =
−h¯
2
2me
∆r1 +
−h¯
2
2me
∆r2 +
−KZe2
|r1|
+
−KZe2
|r2|
+
Ke
2
|r1 −r2|
. (12.3.52)
r1 and r2 are the two electron position vectors, K is Coulomb’s constant, me and e are
the electron mass and charge, and Z = 2 is the number of protons in the atomic nucleus.
Defining Hˆ
n =
−h¯
2
2me
∆rn +
−KZe2
|rn|
and Vˆ
1,2 =
Ke
2
|r1−r2|
, the Hamiltonian, Eq. (12.3.52), is of
the generic form, Eqs. (12.3.33, 12.3.45).
A mean-field approximation for the two-electron function constrains the variational
space of trial functions to products of single-electron functions,
ψ˜(r1, r2) = φ˜(r1)χ˜(r2). (12.3.53)
In analogy to the single-electron (hydrogen-like) atom, each single-electron function
within a many-electron Hamiltonian is termed “an atomic orbital.” The approximation
of the many-electron function as a product of orbitals is referred to as the Hartree
product [12.7].
The optimal single-particle states are obtained by solving the self-consistent mean￾field eigenvalue equations (Eq. (12.3.41)). Using the position representation, the vari￾ationally optimized single-particle wave functions are denoted as φ˜opt(r1) = hϕr1
|φ˜opti
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press197 12.3 The Variation Approach
and χ˜opt(r2) = hϕr2
|χ˜opti, and the mean-field equations take the explicit form (see
Ex. 12.3.11)
h
−h¯
2
2me
∆r1 +
−KZe2
|r1| +
r
dr2|χ˜opt(r2)|
2 Ke2
|r1−r2|
i
φ˜opt(r1) = ε˜φ˜optφ˜opt(r1)
h
−h¯
2
2me
∆r2 +
−KZe2
|r2| +
r
dr1|φ˜opt(r1)|
2 Ke2
|r1−r2|
i
χ˜opt(r2) = ε˜χ˜opt χ˜opt(r2)
. (12.3.54)
Each orbital is therefore an eigenfunction of an effective single-particle Hamiltonian.
The latter is a sum of a “hydrogen-like” term, which corresponds to the interac￾tion between an electron and the bare atomic nucleus, and an additional potential
energy term, which corresponds to the mean field interaction with the other elec￾tron in the atom. For example, the interaction experienced by electron 1, Ve f f(r1) ≡
r
dr2|χ˜opt(r2)|
2 Ke2
|r1−r2|
, corresponds to the averaged interaction between that electron,
positioned at r1, and electron 2, which is distributed over the entire space according
to a probability density function, |χ˜opt(r2)|
2
. In other words, the two-electron interac￾tion energy, Ke2
|r1−r2|
, is replaced by an effective single-electron electrostatic potential at
r1, obtained by averaging over the charge distribution associated with the other elec￾tron. A similar description holds also for the second electron, where the two effective
potentials experienced by the two electrons depend on the orbitals that define the spa￾tial electronic charge distributions, and, in turn, the shape and energy of each orbital
depends on the effective mean-field potentials that modify the single-electron Hamil￾tonians with respect to the hydrogen like-model. Consequently, the orbitals of He are
different from the hydrogen-like orbitals. Qualitatively, the presence of an additional
electron within the atom, which corresponds to a distribution of a negative charge,
screens to some extent the positive charge of the nucleus. This effect results in higher
single-electron energies and more diffused orbitals in comparison to the orbitals of a
hydrogen-like atom with the same nuclear charge.
Exercise 12.3.11 (a) Use the identity operator in the full space, r
dr
0
1
r
dr
0
2
|ϕr
0
1
ihϕr
0
1
| ⊗
|ϕr
0
2
ihϕr
0
2
|, and the definition of Vˆ
1,2 according to Eq. (12.3.52) to show that
hϕr1
| ⊗ hχ˜opt|Hˆ
1,2|φ˜opti ⊗ |χ˜opti =
w
dr2|χ˜opt(r2)|
2 Ke2
|r1 −r2|
φ˜opt(r1)
hφ˜opt| ⊗ hϕr2
|Hˆ
1,2|φ˜opti ⊗ |χ˜opti =
w
dr1|φ˜opt(r1)|
2 Ke2
|r1 −r2|
χ˜opt(r2).
(b) Use the definitions of Hˆ
1 and Hˆ
2 according to Eq. (12.3.52), and the coordinate
representation of the kinetic energy operator (hϕr|Tˆ
r|ψi =
−h¯
2
2m
∆ψ(r); see Ex. 11.5.4) to
show that
hϕr1
|Hˆ
1|φ˜opti =

−h¯
2
2me
∆r1 +
−KZe2
|r1|

φ˜opt(r1)
hϕr2
|Hˆ
2|χ˜opti =

−h
2
2me
∆r2 +
−KZe2
|r2|

χ˜opt(r2).
(c) Use the results of(a) and (b) to show that the generic mean-field equations translate
to Eq. (12.3.54) in the case of the He atom Hamiltonian (Eq. (12.3.52)).
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press198 Approximation Methods
So far, our discussion has ignored the fact that the two electrons are identical par￾ticles. The full consequences of this fact are quite remarkable, as will be discussed in
detail in the next chapter. Here, we only point out that the identity of the two electrons
is reflected in the symmetry of the Hamiltonian for permutation between r1 and r2 (see
Eq. (12.3.52)); namely, the Hamiltonian commutes with the particle permutation oper￾ator, and the two-particle probability density must be invariant to their permutation,
namely |ψ(r2, r1)|
2 = |ψ(r1, r2)|
2
. It follows that the exact Hamiltonian eigenstates are
subject to a symmetry constraint, ψ(r2, r1) ∝ ψ(r1, r2). Imposing this requirement on
the space of single product trial functions, we conclude that the two optimal orbitals
must be identical, namely (see Ex. 12.3.12)
φ˜opt(r) ∝ χ˜opt(r). (12.3.55)
Consequently, the two seemingly different coupled self-consistent equations are in
fact identical in the present case and amount to a single nonlinear equation for the
electronic orbital, denoted as φ˜opt(r):

−h¯
2
2me
∆r +
−KZe2
|r|
+
w
dr
0
|φ˜opt(r
0
)|
2 Ke2
|r−r
0
|

φ˜opt(r) = ε˜φ˜optφ˜opt(r). (12.3.56)
The lowest-energy solution of this nonlinear eigenvalue equation corresponds to an
orbital, φ˜opt,0(r), and its corresponding orbital energy, ε˜φ˜opt ,0. The Hartree (orbital)
approximation for the ground state of the He atom therefore reads
ψ˜0(r1, r2) = φ˜opt,0(r1)φ˜opt,0(r2), (12.3.57)
where the corresponding variational energy is (see Eq. (12.3.44))
ε˜ = 2ε˜φ˜opt ,0 −Ke2
w
dr
w
dr
0 |φ˜opt,0(r
0
)|
2
|φ˜opt,0(r)|
2
|r−r
0
|
(12.3.58)
The variational energy as obtained by a numerical solution of Eq. (12.3.56) is −77.9 eV
[12.8]. As can be expected in view of the screening effect previously discussed, this value
is significantly higher than the energy of two noninteracting electrons in a hydrogen￾like atom with Z = 2, which amounts to −108.8 eV (see Ex. 12.3.13). Moreover, the
mean-field ground state energy is reasonably close to the exact energy, which can be
measured by ionization experiments and equals −79 eV. While being reasonably suc￾cessful in calculation of the ground state for He, the Hartree product fails to predict
the properties of atoms with more than two electrons. Indeed, the Hartree product
ignores a crucial effect on many-electron systems, which is derived from electron spin.
The existence of spin and its consequences in many-electron systems will be addressed
in Chapter 13.
Exercise 12.3.12 Let us define a permutation operator, Pˆ
1,2 f(r1, r2) = f(r2, r1). (a)
Show that any eigenfunction of this operator must satisfy ψ(r2, r1) = αψ(r1, r2), where
α is a scalar. (b) Show that if an eigenfunction of Pˆ
1,2 is a product, ψ(r1, r2) = g(r1)h(r2),
then g(r) ∝ h(r).
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press199 Bibliography
Exercise 12.3.13 Calculate the exact ground state energy of the Hamiltonian,
Hˆ =
−h¯
2
2me
∆r1 +
−h¯
2
2me
∆r2 +
−KZe2
|r1|
+
−KZe2
|r2|
,
which corresponds to the He atom, when the electron–electron interaction is completely
ignored. Refer as needed to Ex. 4.3.4 and to the known solution for a hydrogen-like atom
(see Chapter 10).
Bibliography
[12.1] S. S. Shaik and P. C. Hiberty, “A Chemist’s Guide to Valence Bond Theory”
(John Wiley & Sons, 2007).
[12.2] P. S. Epstein, “The Stark effect from the point of view of Schrödinger’s
quantum theory,” Physical Review 28, 695 (1926).
[12.3] C. Kittel, “Quantum Theory of Solids” (John Wiley & Sons, New York, 1987).
[12.4] Y. Saad, “Iterative Methods for Sparse Linear Systems,” 2nd ed. (SIAM, 2003).
[12.5] G. H. Golub and C.F. Van Loan, “Matrix Computations” (The John Hopkins
University Press, 1989).
[12.6] A. I. Streltsov, O. E. Alon, and L. S. Cederbaum, “General variational many￾body theory with complete self-consistency for trapped bosonic systems,”
Physical Review A 73, 063626 (2006).
[12.7] D. R. Hartree, “The Calculation of Atomic Structures” (John Wiley & Sons,
1957).
[12.8] I. N. Levine, “Quantum Chemistry” (Pearson, 2014).
https://doi.org/10.1017/9781108877787.013 Published online by Cambridge University Press13 Many-Electron Systems
13.1 The Electron Spin
So far, we have discussed nonrelativistic quantum mechanics, its postulates, and some
of its applications in nano- and subnanoscale physics. As it turns out, this is not
enough for understanding important phenomena, including the structure of many￾electron systems, which is the topic of the present chapter. Indeed, the explanation of
observations regarding the nature of atoms, such as periodical-like changes in the prop￾erties of atoms of different elements (the periodic table), requires additional accounting
for the relativistic nature of physical reality. Remarkably, however, in the weak rela￾tivistic regime (namely, when a classical treatment would involve particle velocities
significantly smaller than the speed of light) a fairly accurate description of reality is
obtained by extending the nonrelativistic framework of quantum mechanics (repre￾senting the states of physical systems, the observables, and measurement outcomes as
outlined in the previous chapters) with an additional postulate, which associates “spin”
to the elementary particles. By the end of this chapter, we shall see that the existence
of the electron spin is indeed crucial for understanding the structure of many-electron
atoms, and particularly the periodic-like alternation of physical properties and chemi￾cal reactivity of atoms depending on their atomic number (the number of protons in the
atomic nucleus). Here we start by becoming familiar with the existence of the electron
spin. This property is most directly manifested in the presence of an external magnetic
field.
We start by recalling that in classical mechanics, a particle of mass µ and charge q,
rotating in a circle, induces a magnetic moment perpendicular to the rotation plane.
This moment, µ, is proportional to the particle’s angular momentum,
µ =
q
2µ
L. (13.1.1)
In the presence of an external magnetic filed, B, the particle’s energy changes according
to the projection of its magnetic moment on the external field,
HB = −µ ·B =
−q
2µ
L·B. (13.1.2)
For an electron of charge −e and a magnetic field directed along the z-axis, B =
(0,0,Bz), the change of energy amounts to HB =
e
2me
LzBz
. Replacing the classical
200
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press201 13.1 The Electron Spin
angular momentum with its corresponding quantum mechanical operator, the Ham￾iltonian for an electron in the magnetic field obtains an additional term,
Hˆ
Bz =
e
2me
BzLˆ
z
. (13.1.3)
Let us focus, for example, on an electron in a hydrogen-like atom. In the absence
of a magnetic field, the energy eigenstates associated with a given angular momen￾tum (and a given principal quantum number, n) are degenerate (i.e., ψn,l,m, with m =
−l,...,0,...l; see Chapters 9 and 10). The introduction of a magnetic field, Eq. (13.1.3),
removes this degeneracy, where the energy levels are split according to their magnetic
quantum number, m, Hˆ
Bz
|ψn,l,mi =
eBZ
2me
mh¯|ψn,l,mi = mµBBz
|ψn,l,mi. The magnitude of
the effect is set by µB ≡
he¯
2me
, named “the Bohr magneton” after Niels Bohr. The split￾ting of the energy levels in the magnetic field is manifested in the well-known Zeeman
effect, observed also in many-electron hydrogen-like atoms. Indeed, multiple splitting
of atomic spectral lines has been observed in experiments since the end of the nine￾teenth century [13.1]. However, it became clear that magnetic fields induce splitting of
atomic energy levels beyond what could be attributed to the quantization of the elec￾tron’s angular momentum. This “anomalous” Zeeman effect was the first indication
that the magnetic moments of electrons are not simply determined by their orbital
angular momentum. The most compelling evidence for the nature of the magnetic
moment of electrons was first revealed in the Stem–Gerlach experiment from 1922,
which demonstrated for the first time that, even when its orbital angular momentum
is zero, the electron still has a magnetic moment. In that experiment [13.2], neutral
silver atoms were scattered through an inhomogeneous magnetic field. Unexpectedly,
the single atomic beam split into two parts while passing through the field, indicating
two remarkable facts: (i) Although electrically neutral, the silver atoms experienced
magnetic forces when passing through a magnetic field. (ii) The magnetic forces were
of two different signs, as indicated by the splitting into two beams.
The first observation is attributed to the existence of a net magnetic moment in a
neutral silver atom, which exerts a force on the atomic center of mass as it passes
through an inhomogeneous magnetic field. A more detailed analysis of the struc￾ture of silver atoms later related the net magnetic moment to that of an (unpaired)
electron in the atom. Notably, within the orbital approximation (to be discussed in
Section 13.3), the unpaired electron in the ground state of a silver atom is associated
with a 4s-type orbital, hence with a zero orbital angular momentum. Since a magnetic
moment of a charged particle is expected to be proportional to its angular momentum
(see Eq. (13.1.1)), the orbital angular momentum cannot account for the magnetic
moment, where another source for angular momentum must be present, unrelated to
the particle’s orbital. This additional angular momentum of particles is referred to as
an “intrinsic particle spin.” In nonrelativistic quantum mechanics, where particle posi￾tions are associated with a three-dimensional coordinate space, the existence of spin
is an additional postulate. (It is worthwhile to mention, however, that spin is inherent
in Dirac’s equation for an electron [13.3], which extends the Schrödinger equation to
include relativistic corrections.)
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press202 Many-Electron Systems
A no less remarkable observation in the Stern–Gerlach experiment was the splitting
of the particle’s energy was into two distinctive states. Attributing the splitting to the
quantum Zeeman effect, via Eq. (13.1.3), the number of split states in a magnetic field
should reflect the number of different values of the magnetic quantum number, m. Fol￾lowing the arguments outlined in Section 9.2 for orbital angular momenta, this number
must be 2l +1, where l = 0,1,... is the angular quantum number (to comply with the
boundary conditions for proper stationary solutions of the Schrödinger equation in the
three-dimensional coordinate space). Consequently, for any orbital angular momen￾tum, 2l +1 must be an odd number. An even number of m values points to half-integer
angular quantum numbers, which, again, cannot be attributed to an orbital angular
momentum. In particular, the splitting into two beams in the Stern–Gerlach exper￾iment, namely, 2l + 1 = 2, is consistent with an angular quantum number, l = 1/2,
where m = −l,...,l amounts to m = −1/2,1/2. (Remarkably, mathematical consid￾erations based solely on the Hermiticity and commutation relations of the angular
momentum operators, irrespective of any coordinate representation, suggest that nor￾malizable angular momentum eigenvectors can indeed be associated with either even
or odd angular quantum numbers [4.3].) Finally, a quantitative analysis reveals that
the magnitude of the energy splitting attributed to the intrinsic electron spin is differ￾ent from what can be expected for an orbital angular momentum: instead of the Bohr
magneton, µB , the splitting was associated with gµB, where g = 2.0034 (the electron’s
gyromagnetic factor) is characteristic to the electron spin.
It is therefore necessary to introduce another postulate to nonrelativistic quantum
mechanics that assumes the existence of an intrinsic spin for each particle. This measura￾ble property is associated with angular momentum operators, analogues to the orbital
angular momentum operators. To distinguish from the orbital angular momentum
operator, Lˆ = (Lˆ
x,Lˆ
y,Lˆ
z), the spin operator is denoted as
Sˆ = (Sˆ
x,Sˆ
y,Sˆ
z). (13.1.4)
Notice that although the spin operates in a “spin-space” different form the coordinate
space, it is a vector in the coordinate space, with spatial components satisfying angular
momentum commutation relations (see Eqs. (3.3.3, 3.3.5)) namely
[Sˆ
x,Sˆ
y] = ih¯Sˆ
z
[Sˆ
y,Sˆ
z
] = ih¯Sˆ
x
[Sˆ
z
,Sˆ
x] = ih¯Sˆ
y
[Sˆ
2
,Sˆ
x] = [Sˆ
2
,Sˆ
y] = [Sˆ
2
,Sˆ
z
] = 0. (13.1.5)
Defining spin ladder operators,
Sˆ+ ≡ Sˆ
x +iSˆ
y ; Sˆ− ≡ Sˆ
x −iSˆ
y (13.1.6)
and using the commutation relations, Eq. (13.1.5), we can readily verify that the
following equations hold (see Ex. 9.2.2):
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press203 13.1 The Electron Spin
[Sˆ+,Sˆ−] = 2h¯Sˆ
z
; [Sˆ
z
, Sˆ±] = ±h¯Sˆ± ; [Sˆ
2
,Sˆ±] = 0
Sˆ
2 −Sˆ
2
z =
1
2
(Sˆ+Sˆ− +Sˆ−Sˆ+). (13.1.7)
According to the standard quantum mechanical postulates (see Chapter 11), the
spin-state of a particle is associated with an abstract vector, namely, a Dirac ket. Con￾sidering, for example, a single electron, the Stern–Gerlach experiment indicates that
its spin quantum number (denoted traditionally as s instead of l) is s = 1/2, with two
possible projections on a selected axis, corresponding to the magnetic quantum num￾bers (denoted ms
instead of m), ms = ±1/2. It is conventional to denote these two spin
states |σ1/2
i = |αi and |σ−1/2
i = |βi, where, by their definition, these states are proper
simultaneous eigenstates of Sˆ2 and Sˆ
z
,
Sˆ2
|αi = h¯
2
s(s+1)|αi = h¯
2 3
4
|αi ; Sˆ2
|βi = h¯
2
s(s+1)|βi = h¯
2 3
4
|βi
Sˆ
z
|αi = hm¯ s
|αi = h¯
1
2
|αi Sˆ
z
|βi = hm¯ s
|βi = −h¯
1
2
|βi
. (13.1.8)
Since the Hermitian operator, Sˆ
z
, has only two eigenvalues, the corresponding eigen￾states (|αi and |βi) are a complete orthonormal system, which spans the space of spin
states of a single electron:
hα|αi = hβ|βi = 1 ; hα|βi = 0. (13.1.9)
Using the perfect analogy to normalized angular momentum eigenvectors (see Sec￾tion 9.2), the spin states satisfy the following relations (Ex. 13.1.1):
Sˆ+|βi = h¯|αi ; Sˆ+|αi = 0
Sˆ−|αi = h¯|βi ; Sˆ−|βi = 0
Sˆ
x|αi =
h¯
2
|βi ; Sˆ
x|βi =
h¯
2
|αi
Sˆ
y|αi = i
h¯
2
|βi ; Sˆ
y|βi = −i
h¯
2
|αi. (13.1.10)
Using |αi and |βi as a basis for the single-electron spin space, any electronic spin state
can be expressed as
|σi = cα|αi+cβ
|βi. (13.1.11)
It is useful to represent the spin states and the spin operators as vectors and matrices
in the two-dimensional vector space. Projecting Eq. (13.1.11) onto the basis vectors,
we obtain cα = hα|σi, cβ = hβ|σi, where the vector representation reads

hα|σi
hβ|σi

=

cα
cβ

. (13.1.12)
Introducing the identity,
ˆI = |αihα|+|βihβ|, (13.1.13)
any operator in the single-electron spin space obtains the form
Aˆ = Aα,α|αihα|+Aα,β
|αihβ|+Aβ,α|βihα|+Aβ,β
|βihβ|, (13.1.14)
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press204 Many-Electron Systems
which corresponds to the matrix representation,

Aα,α Aα,β
Aβ,α Aβ,β

=

hα|Aˆ|αi hα|Aˆ|βi
hβ|Aˆ|αi hβ|Aˆ|βi

. (13.1.15)
Specifically, the matrix representations of the three components of the single-electron
spin vector operator read (see Ex. 13.1.2)
Sz =
h¯
2
"
1 0
0 −1
#
; Sx =
h¯
2
"
0 1
1 0 #
; Sy =
h¯
2
"
0 −i
i 0
#
. (13.1.16)
These matrices are related to the Pauli matrices, named after Wolfgang Pauli (who also
introduced the spin-related exclusion principle, to be discussed in Section 13.3):
σ z =
"
1 0
0 −1
#
; σ x =
"
0 1
1 0 #
; σ y =
"
0 −i
i 0
#
σ + =

0 1
0 0 
; σ − =

0 0
1 0 
. (13.1.17)
Since the representation of the identity is exact, the relations between the spin operators
(Eqs. (13.1.5–13.1.7)) as well as their operations on spin states (Eqs. (13.1.8, 13.1.10))
are reproduced by the corresponding matrix–matrix and matrix–vector multiplications
(see Ex. 13.1.3).
Exercise 13.1.1 The spin states |αi and |βi are common eigenstates of Sˆ2 and Sˆ
z (see
Eq. (13.1.8)). Denoting the common eigenstates by the respective quantum numbers,
|s,msi, one can identify | αi =




1
2
,
1
2

and




β

=




1
2
,
−1
2

.
(a) Use the definition of the spin ladder operators (Sˆ±, Eq. (13.1.6)) and their com￾mutation relations (Eq. (1.3.7)) to show that Sˆ±|s,msi ∝ |s,ms ± 1i. Particularly,
show that Sˆ+|βi ∝ |αi and Sˆ−|αi ∝ |βi.
(b) Use the commutation relation (Eq. (13.1.7)) to show that Sˆ+|αi = 0 and Sˆ−|βi = 0.
(Show that hα|Sˆ−Sˆ+|αi = hβ|Sˆ+Sˆ−|βi = 0.)
(c) Normalize the vectors Sˆ+|βi and Sˆ−|αi, and show that the normalized vectors satisfy
the relations Sˆ+|βi = h¯|αi and Sˆ−|ai = h¯|βi.
Exercise 13.1.2 Use the properties of the spin eigenstates in Eqs. (13.1.8, 13.1.10) and
derive the matrix representations of the spin operators in Eq. (13.1.16).
Exercise 13.1.3 (a) Verify that the commutation relations between the spin operators
(Eqs. (13.1.5–13.1.7)) are satisfied by the spin matrices (Eqs. (13.1.16–13.1.17)). (b)
Verify that the results in Eqs. (13.1.8, 13.1.10) are obtained by matrix–vector multipli￾cations of the appropriate spin matrices (Eqs. (13.1.16–13.1.17)) on the basis vectors

1
0

and 
0
1

, corresponding to the states |αi and |βi, respectively.
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press205 13.1 The Electron Spin
A full description of the physical state of an electron (within nonrelativistic quantum
mechanics) corresponds to a vector in an extended space, which is a tensor product of
the coordinate and spin spaces. This means that the vectors are spanned by a complete
orthonormal set of product states (see Section 11.6),
|Φi ≡ ∑
σ∈α,β
∞
∑
n=1
cσ,n|φni ⊗|σi. (13.1.18)
Here {|αi, |βi} and {|φni} are complete orthonormal systems of state vectors in the
spin and coordinate spaces, respectively. The two spaces are in fact coupled by spin–
orbit coupling operators, derived from relativistic corrections (Dirac’s equation). In
atoms, this coupling manifests in additional splitting of atomic energy levels, even in
the absence of an external magnetic field, due to the magnetic interaction between
the orbital electronic degrees of freedom and the intrinsic magnetic moments of elec￾trons and the nuclei (the fine and hyperfine structures, respectively). When the relevant
classical velocities are far below the speed of light, spin–orbit couplings induce small
corrections to the energy level spacings associated with the electrostatic interaction
terms, which enables us to treat them, when required, using perturbation theory. In
“heayy” atoms, however, the internal electrons are associated with high effective veloc￾ities, and spin–orbit coupling becomes important. (The interested reader may want to
address other textbooks for a comprehensive coverage of this issue [4.3].)
When spin–orbit coupling is completely neglected, the electron spin is revealed only
in the presence of an external magnetic field. The electromagnetic field enters the
single-electron Hamiltonian in terms of the scalar and vector potentials, Φ(r) and
A(r), respectively [13.4], where the magnetic field is the curl of the vector potential,
B = ∇ × A(r). Introducing the corresponding quantum mechanical operators, the
“Pauli Hamiltonian” is obtained for an electron in the field:
Hˆ =
1
2me
[pˆ −eA(rˆ)]2 −eΦ(rˆ)+
e
me
B(rˆ)·Sˆ. (13.1.19)
The Zeeman effect associated with the interaction of the orbital angular momentum
with the magnetic field (Eqs. 13.1.2, 13.1.3) is derived from the kinetic energy term,
1
2me
[pˆ −eA(rˆ)]2
, where the spin interaction with the magnetic field appears as a separate
term, e
me
B(rˆ)·Sˆ. Notice that the latter interaction has a twice larger pre-factor in com￾parison to the interaction of the orbital angular momentum with the field (compare
to Eq. (13.1.3).) According to the Pauli Hamiltonian, the Zeeman splitting associated
with the spin is proportional to a scaled Bohr magneton, geµB, where ge = 2. This
value for the electron’s “gyromagnetic factor” is indeed close to the measured one,
ge = 2.0034.
By setting the static potential energy to −eΦ =
−KZe2
r
, the Pauli Hamiltonian
(Eq. (13.1.10)) corresponds to an electron in a hydrogen-like atom and a magnetic
field. Identifying the magnetic field direction with the z-axis, e
me
B(rˆ)· Sˆ =
e
me
Bz(rˆ)· Sˆ
z
,
the eigenstates of the Pauli Hamiltonian are readily seen to be products of spin and
orbital states, characterized by four quantum numbers,
|Φn,l,m,ms
i ≡ |ψn,l,mi ⊗ |σms
i, (13.1.20)
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press206 Many-Electron Systems
where |σ1/2
i ≡ |αi, and |σ−1/2
i ≡ |βi. In atomic physics and chemistry, the vector
|Φn,l,m,ms
i is often termed a “spin-orbital,” associated with a well-defined informa￾tion on both the orbital and the spin state of the electron. As we shall discuss, the
concept of spin-orbitals is very useful also when approximating the state of many￾electron systems, and many-electron atoms in particular. Notice that in the absence
of a magnetic field, the two spin states for an electron are degenerate. In that case
the Hamiltonian eigenstates can be any superposition of the two spin states, |Φi ≡
|ψn,l,mi ⊗ (cα|αi + cβ
|βi). A measurement process, such as a Stern–Gerlach experi￾ment, can induce collapse of the superposition state, |Φi, into either an |αi or a |βispin
state. Indeed, considering a beam of particles entering an inhomogeneous magnetic
field along the z-axis, the center of mass of each particle experiences a force depend￾ing on the projection of its magnetic moment on that axis, which is different for the
|αi and |βi spin states. The result is splitting of the particles into two distinguishable
beams, according to their spin state.
13.2 Spin and Identical Particles
The existence of spin at the single-particle level has a profound effect on systems com￾posed of many identical particles. In the following sections, we shall see how this
manifests itself in the electronic structure of different materials, starting from the elec￾tronic structure of many-electron atoms, and its reflection in the periodic table of the
elements. We start this section by discussing some general properties of systems of
identical particles in quantum mechanics, and then we introduce another postulate of
nonrelativistic quantum mechanics, which imposes additional limitations on proper
wave functions (or, generally, the physical state) of systems of many identical particles
according to their spins.
Let us consider first two particles, marked as “1” and “2.” If the particles are phys￾ically identical, exchanging their identities (namely, replacing their marks) does not
affect any measurable property of the system. As we shall see, in quantum mechanics
this fact is associated with remarkable consequences. Let us associate the two-particle
system with a wave function, ψ(x1, x2). Since the particles are identical, the probability
density for locating the first particle at the position x1 and the second at position x2
must be equal to the probability of locating the first particle at x2 and the second at x1,
which means
|ψ(x1, x2)|
2 = |ψ(x2, x1)|
2
. (13.2.1)
An immediate consequence of Eq. (13.2.1) is that a physically proper two-particle
function must fulfill the condition
ψ(x1, x2) = e
iφ ψ(x2, x1), (13.2.2)
where φ is a real-valued parameter. Namely, a permutation of the particle indexes,
1 ↔ 2, changes the two-particle wave function by up to a multiplication by a complex
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press207 13.2 Spin and Identical Particles
number of a unit norm. Since physical states (e.g., solutions to the Schrödinger equa￾tion) are invariant to a multiplication by a constant, both ψ(x2, x1) and ψ(x1, x2) are
equivalent descriptions of the same state of the two identical particles. Nevertheless, as
discussed in the following sections, nature teaches us that the constant associated with
a permutation of identical particles (φ in Eq. (13.2.1)) cannot be chosen arbitrarily.
We now turn to the formal definition of the two-particle permutation operator. In
the abstract two-particle vector space, each physical sate is associated with a linear
combination of tensor products (see Eq. (11.6.12)),
|ψi = ∑n1,n2
ψn1,n2
|φn1
i ⊗|φn2
i, (13.2.3)
where |φni
i is a single-particle basis state in the subspace corresponding to the ith par￾ticle. Since the particles are identical, so are their respective single-particle subspaces,
which means that identical basis sets can be invoked for the two subspaces,
{|φn1
i} = {|φn2
i}. (13.2.4)
The permutation operator, Pˆ
1,2, exchanges the basis states in any given product state,
Pˆ
1,2|φn1
i ⊗|φn2
i ≡ |φn2
i ⊗|φn1
i. (13.2.5)
where, as we can readily verify (Ex. 13.2.1), Pˆ
1,2 is Hermitian, namely, for any |ψi and
|χi,
hχ|Pˆ
1,2|ψi = hψ|Pˆ
1,2|χi
∗
, (13.2.6)
as well as unitary,
(Pˆ
1,2)
†Pˆ
1,2 = (Pˆ
1,2)
2 = ˆI. (13.2.7)
Generalizing the condition in Eq. (13.2.1) to any representation means that in a system
of identical particles the probability of finding particle “1” in a state |φn1
i and particle
“2” in a state |φn2
i must be equal to the probability of finding particle “1” in a state
|φn2
i and particle “2” in a state |φn1
i. Consequently, any physical state, |ψi, of a system
of identical particles must satisfy the condition
|(hφn2
| ⊗ hφn1
|)|ψi|2 = |(hφn1
| ⊗ hφn2
|)|ψi|2
, (13.2.8)
from which follows
(hφn1
| ⊗ hφn2
|)Pˆ
1,2|ψi = e
iφ
(hφn1
| ⊗ hφn2
|)|ψi, (13.2.9)
where φ is real-valued. Since the latter holds for any |φn1
i and |φn2
i, it means that the
state |ψi must be an eigenstate of the permutation operator, Pˆ
1,2|ψi = e
iφ
|ψi. However,
considering that Pˆ
1,2 is Hermitian (Eq. (13.2.6)), its eigenvalues in the space of proper
states must be real. Consequently,
Pˆ
1,2|ψi = ±|ψi. (13.2.10)
Returning to the coordinate representation, Eq. (13.2.2) is refined as follows:
ψ(x1, x2) = hx1, x2|ψi = ±hx1, x2|Pˆ
1,2|ψi = ±hx2, x1|ψi = ±ψ(x2, x1), (13.2.11)
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press208 Many-Electron Systems
which means that the wave function of a system of two identical particles must be either
symmetric or antisymmetric for permutation of the particle indexes.
The generalization to the case of many (N) particles is straightforward. Defining a
basis of products of identical single-particle basis sets, the state vector of a system of
identical particles obtains the form
|ψi = ∑ n1,n2,...,nN
ψn1,n2,...,nN
|φn1
i ⊗|φn2
i ⊗··· ⊗|φnN
i. (13.2.12)
A pair permutation (transposition) i ↔ j between the ith and jth particles is repre￾sented here by an operator, Pˆ
i, j
, defined by its operation on any product state,
Pˆ
i, j
|φn1
i··· ⊗ |φni
i ⊗ ··· ⊗|φnj
i ⊗···|φnN
i = |φn1
i··· ⊗ |φnj
i ⊗··· ⊗|φni
i ⊗ ···|φnN
i.
(13.2.13)
The general condition for any pair permutation on a system of identical particles
(Eq. (13.2.8)) obtains the form
|(hφn1
| ⊗ hφn2
| ⊗··· ⊗ hφnN
|)Pˆ
i, j
|ψi|2 = |(hφn1
| ⊗ hφn2
| ⊗··· ⊗ hφnN
|)|ψi|2
, (13.2.14)
which means that the state of a system of identical particles must be an eigenvector of
any pair permutation operator, with an eigenvalue, ±1,
Pˆ
i, j
|ψi = ±|ψi. (13.2.15)
Moreover, as we shall discuss, nature tells us that the two different eigenvalues corre￾spond to two different types of particles. Depending on the particle’s type, the state |ψi
is associated with only one eigenvalue of Pˆ
i, j
, which is either +1 or −1 , and is the same
for all (i, j) pairs.
Exercise 13.2.1 Consider a system of three identical particles. The three-particle space
is spanned by the complete set of products of single-particle states, |φn1
i ⊗ |φn2
i ⊗ |φn3
i,
associated with the quantum numbers n1,n2,n3, respectively for the particle indexes 1,
2, and 3. The permutation between particles 1 and 2 is associated with the operator Pˆ
1,2,
defined as Pˆ
1,2|φn1
i ⊗|φn2
i ⊗|φn3
i = |φn2
i ⊗|φn1
i ⊗|φn3
i. Show that:
(a) The operator Pˆ
1,2 is Hermitian, namely hχ|Pˆ
1,2|ψi = hψ|Pˆ
1,2|χi
∗
, for any three parti￾cle states, |ψi = ∑
n1,n2,n3
ψn1,n2,n3
|φn1
i⊗|φn2
i⊗|φn3
i, and |χi = ∑
n1,n2,n3
χn1,n2,n3
|φn1
i⊗
|φn2
i ⊗|φn3
i.
(b) The operator Pˆ
1,2 is unitary, namely (Pˆ
1,2)
†Pˆ
1,2 = ˆI.
Exercise 13.2.2 The following symmetry property of a many-particle observable, Oˆ,
to exchange of particle indexes, Oˆ
1,...i,..., j,...,N = Oˆ
1,... j,...,i,...,N, means that the following
identity holds for any two tensor product basis states:
hφn1
0|··· ⊗ hφni
0| ⊗··· ⊗ hφnj
0| ⊗··· hφnN
0|Oˆ|φn1
i··· ⊗ |φni
i ⊗ ··· ⊗|φnj
i ⊗···|φnN
i
= hφn1
0|··· ⊗ hφnj
0| ⊗··· ⊗ hφni
0| ⊗··· hφnN
0|Oˆ|φn1
i··· ⊗ |φnj
i ⊗··· ⊗|φni
i ⊗ ···|φnN
i
.
Use the definition of the permutation operator, Eq. (13.2.13), to show that such an
observable commutes with any permutation operator, namely [Pˆ
i, j
,Oˆ
1,...i,..., j,...,N] = 0.
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press209 13.2 Spin and Identical Particles
The discussion so far has referred to any state of a system of many identical particles.
Here we focus on properties of the Hamiltonian eigenstates of such systems. Notice
that when particles are physically identical, any system observable is invariant to their
index permutations. Without loss of generality, we consider the system Hamiltonian;
but the discussion based on Eq. (13.2.16) applies in fact to any observable in a system
of identical particles. Denoting the Hamiltonian of an N-particle system as Hˆ
1,2,...,N,
the identity of the ith and jth particles is expressed in the symmetry property,
Hˆ
1,...i,..., j,...,N = Hˆ
1,... j,...,i,...,N, (13.2.16)
which means that the Hamiltonian commutes with the pair permutation operators (see
Ex. 13.2.2),
[Pˆ
i, j
,Hˆ
1,...i,..., j,...,N] = 0. (13.2.17)
It immediately follows that if |ψi is a Hamiltonian eigenstate,
Hˆ
1,...i,..., j,...,N|ψi = E|ψi, (13.2.18)
then Pˆ
i, j
|ψi is also a Hamiltonian eigenstate, corresponding to the same eigenvalue,
Hˆ
1,...i,..., j,...,N(Pˆ
i, j
|ψi) = E(Pˆ
i, j
|ψi), (13.2.19)
where |ψi and Pˆ
i, j
|ψi are degenerate states. Since this argument can be repeated for
all possible permutations (including general permutations, namely sequences of pair
permutations), there is a set of N! degenerate states associated with any eigenvalue,
E, which corresponds to all the different arrangements of the N particle indexes.
Therefore, any Hamiltonian eigenstate can be written as a linear combination,
Hˆ
1,2,...,N
 
N!
∑
n=1
anRˆ
n|ψi
!
= E
 
N!
∑
n=1
anRˆ
n|ψi
!
. (13.2.20)
(Here, Rˆ
n =
N
∏
i, j>i=1
(Pˆ
i, j)
p
(n)
i, j creates the nth unique order of the N indexes. It is an ordered
sequence of operations over all pairs of indexes (i, j), where each p
(n)
i, j
obtains the
value zero or one.) Importantly, while the general superposition, |Ψi =
N!
∑
n=1
anRˆ
n|ψi,
is an eigenstate of the identical particles Hamiltonian, it does not necessarily meet
the condition Eq. (13.2.15) on the identical particles state. (This is sometimes referred
to as the “exchange degeneracy” problem [4.3].) Indeed, any physical eigenstate |Ψi
of the many-particle Hamiltonian must also be an eigenstate of all the permutation
operators corresponding to two identical particles, with the same eigenvalue, either
+1 or −1. In order to properly fulfil these requirements on |Ψi, the expansion coef￾ficients {an} must be properly selected: we can readily see (Ex. 13.2.3) that setting all
the coefficients identical to each other and normalizing, namely, a
(S)
n = √
1
N!
, results
in a symmetric many-particle state, |Ψsi, associated with the eigenvalue +1 for any
pair permutation. Similarly, an antisymmetric many-particle state, |ΨAi, associated
with the eigenvalue −1 for any pair permutation, can be obtained by setting a
(A)
n =
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press210 Many-Electron Systems
(−1)
N
∑
i=1
N
∑
j>i
P
(n)
i, j
√
1
N!
, which means that the expansion coefficients of all the different index
arrangements are identical in magnitude, but may differ in sign. Particularly, when
the index arrangement is associated with an odd number of pair permutations (with
respect to a common reference order), the respective expansion coefficient obtains a
minus sign. The two systematic choices of expansion coefficients can be cast in the
form of two operators,
Sˆ ≡ √
1
N!
N!
∑
n=1
N
∏
i, j>i=1
(Pˆ
i, j)
p
(n)
j, j
Aˆ ≡ √
1
N!
N!
∑
n=1
(−1)
N
∑
i=1
N
∑
j>i
p
(n)
i, j N
∏
i, j>i=1
(Pˆ
i, j)
p
(n)
i, j
. (13.2.21)
Sˆ and Aˆ are termed, respectively, the symmetrizer and the antisymmetrizer. As we have
detailed, the states obtained by applying these operators on a state |ψi, namely,
|Ψsi = Sˆ|ψi
|ΨAi = Aˆ|ψi, (13.2.22)
are symmetric or antisymmetric, respectively, under any pair permutation (see
Exs. 13.2.3, 13.2.4, 13.2.5),
Pˆ
i, j
|ΨSi = |ΨSi
Pˆ
i, j
|ΨAi = −|ΨAi. (13.2.23)
Notice that while our discussion was motivated by the search for Hamiltonian eigen￾states that additionally satisfy Eq. (13.2.15) (or Eq. (13.2.23)), the result is not restricted
to Hamiltonian eigenstate; namely, the operators Sˆ or Aˆ map any state of a system of
many identical particles onto a state that is symmetric or antisymmetric under permuta￾tions. Also notice that the states|ΨSi and |ΨAi are associated with different eigenvalues
of the same Hermitian operator (see Ex. 13.2.1), which means that the subspaces of
symmetric and antisymmetric states with respect to permutation of identical particles
are orthogonal subspaces. Finally, our definition of the operators Sˆ or Aˆ assures that
they preserve the norm of the state to which they are applied (unless the result is a
trivial improper state). Alternative normalizations of these operators that differ by a
constant multiplication (e.g., to fulfil the properties of projection operators) are also
commonly used [4.3].
Exercise 13.2.3 The operator Rˆ
n =
N
∏
i, j>i=1
(Pˆ
i, j)
p
(n)
i, j
is a sequence of permutation oper￾ators, defined by a specific vector of scalars (p
(n)
1,2
, p
(n)
1,3
, p
(n)
2,3
,...) with entries 0 or 1.
Each Rˆ
n corresponds to one of the N! unique arrangements of the particle indexes.
The symmetrizer and the antisymmetrizer operators are defined as sums over all pos￾sible arrangements with appropriate coefficients, as follows: Sˆ|ψi ≡ √
1
N!
N!
∑
n=1
Rˆ
n|ψi,
and, Aˆ|ψi ≡ √
1
N!
N!
∑
n=1
(−1)
N
∑
i=1
N
∑
j>i
p
(n)
i, j
Rˆ
n|ψi, respectively. Show that Pˆ
i, jSˆ|ψi ≡ Sˆ|ψi and
Pˆ
i, jAˆ|ψi ≡ −Aˆ|ψi by showing that the following holds for any tensor product basis vector:
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press211 13.2 Spin and Identical Particles
hφn1
| ⊗ hφn2
| ⊗··· ⊗ hφnN
|Pˆ
i, jSˆ|ψi = hφn1
| ⊗ hφn2
| ⊗··· ⊗ hφnN
|Sˆ|ψi
hφn1
| ⊗ hφn2
| ⊗··· ⊗ hφnN
|Pˆ
i, jAˆ|ψi = −hφn1
| ⊗ hφn2
| ⊗··· ⊗ hφnN
|Aˆ|ψi.
Exercise 13.2.4 The symmetrizer and antisymmetrizer operators applied to a generic
two-particle state, |ψi = ∑
n1,n2
ψn1,n2
|φn1
i ⊗|φn2
i, yield
|ψSi = Sˆ|ψi =
1
√
2
∑n1,n2
ψn1,n2
|φn1
i ⊗|φn2
i+
1
√
2
Pˆ
1,2 ∑n1,n2
ψn1,n2
|φn1
i ⊗|φn2
i
=
1
√
2
∑n1,n2
ψn1,n2
(|φn1
i ⊗|φn2
i+|φn2
i ⊗|φn1
i)
and
|ψAi = Aˆ|ψi =
1
√
2
∑n1,n2
ψn1,n2
|φn1
i ⊗|φn2
i − 1
√
2
Pˆ
1,2 ∑n1,n2
ψn1,n2
|φn1
i ⊗|φn2
i
=
1
√
2
∑n1,n2
ψn1,n2
(|φn1
i ⊗|φn2
i −|φn2
i ⊗|φn1
i).
Show that Sˆ|ψi and Aˆ|ψi are indeed eigenstates of the permutation operator, Pˆ
1,2
(Eq. (13.2.23)). What are the corresponding eigenvalues?
Exercise 13.2.5 The symmetrizer and antisymmetrizer operators applied to a generic
three-particle state, |ψi = ∑
n1,n2,n3
ψn1,n2,n3
|φn1
i ⊗|φn2
i ⊗|φn3
i, yield
Sˆ|ψi =
1
√
6
∑n1,n2,n3
ψn1,n2,n3
(|φn1
i ⊗|φn2
i ⊗|φn3
i+|φn2
i ⊗|φn1
i ⊗|φn3
i+|φn1
i ⊗|φn3
i⊗
|φn2
i+|φn3
i ⊗|φn2
i ⊗|φn1
i+|φn2
i ⊗|φn3
i ⊗|φn1
i+|φn3
i ⊗|φn1
i ⊗|φn2
i)
Aˆ|ψi =
1
√
6
∑n1,n2,n3
ψn1,n2,n3
(|φn1
i ⊗|φn2
i ⊗|φn3
i −|φn2
i ⊗|φn1
i ⊗|φn3
i −|φn1
i ⊗|φn3
i⊗
|φn2
i −|φn3
i ⊗|φn2
i ⊗|φn1
i+|φn2
i ⊗|φn3
i ⊗|φn1
i+|φn3
i ⊗|φn1
i ⊗|φn2
i).
Show that Sˆ|ψi and Aˆ|ψi are indeed eigenstates of the two particle permutation operators,
Pˆ
1,2,Pˆ
2,3, and Pˆ
1,3 (Eq. (13.2.23)). What are the corresponding eigenvalues?
The general considerations so far allow for either symmetric or antisymmetric
proper states under permutation of identical particle pairs. Evidence from experiments
show, however, that nature distinguishes between these two options, where particles
are divided into two distinctive groups, bosons, and fermions. Particles whose many￾particle states are symmetric with respect to pair permutation of identical particles
are termed bosons, whereas particles whose many-particle states are antisymmetric
with respect to pair permutation are termed fermions. Moreover, what seems to dis￾tinguish bosons from fermions relates to the nature of their intrinsic spin. At the level
of elementary particles, bosons (such as photons, mesons, phonons, etc.) are asso￾ciated with an integer spin quantum number, s = 0,1,2,..., whereas fermions (such
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press212 Many-Electron Systems
as electrons, protons, neutrons, etc.) are associated with a half-integral spin quantum
number, s = 1/2,3/2,.... Larger particles, composed out of elementary ones, can be
classified into bosons and fermions according to their net intrinsic spin, defined by the
addition of the spin vectors of their elementary particles. Consequently, for example,
the hydrogen nucleus, 1H, is a proton, hence a fermion associated with s = 1/2, while
the deuterium nucleus, 2H, is a boson owing to the addition of the proton and neutron
spins (s = 1). Similarly, the nucleus 3He is a fermion, while 4He is a boson, and so on.
In summary, physically proper state vectors for systems composed of identical parti￾cles are subject to additional requirements, derived in part from general consideration
with respect to their information content (Eqs. (13.2.1, 13.2.8, 13.2.14)) and in part
from experimental observations on many-particle systems. These requirements were
not included in our discussion of the postulates of quantum mechanics in Chapter 11.
They can be summarized as an additional postulate:
A proper physical state (or a wave function) of a system composed of identical par￾ticles must be either symmetric (unchanged) or antisymmetric (flip sign) with respect
to any permutation of two identical particle indexes. The symmetric and antisymmet￾ric cases correspond to permutation of identical bosons (associated with integer spin
quantum number) and fermions (associated with a half-integral spin quantum number),
respectively.
13.3 The Electronic Structure of Many-Electron Atoms
A direct consequence of the existence of the electron spin is the electronic structure of
many-electron atoms. Indeed, electrons are fermions, and the many-electron state of
any atom must be antisymmetric to any pair permutation (transposition) of electron
indexes. In Chapter 10 we became familiar with hydrogen-like atoms, composed of a
nucleus and a single electron. The quantized energy levels for the electron and the spa￾tial distribution of its charge around the nucleus were associated with single-electron
wave functions, namely orbitals. In a nonrelativistic framework, the electron spin is
independent of its spatial orbital (see Section 13.1), and it should be undetectable in
the absence of an external magnetic field. Consequently, the (orthonormal) Hamilto￾nian eigenstates in a single-electron atom can be associated with a spin-orbital product
state, |Φn,l,m,ms
i ≡ |ψn,l,mi⊗|σms
i, where n,l,m are the principal, angular, and magnetic
quantum numbers, and ms = ±1/2 is the spin quantum number (see Eq. (13.1.20)).
Turning to many-electron atoms, one would have liked to make use of the knowledge
acquired by solving the Schrödinger equation for a single-electron atom by maintain￾ing the concept of orbitals and associating each electron with its own spin-orbital. If
this was indeed possible, an N-electron state would have been a single tensor prod￾uct over the single-electron spaces, for example, |Ψi=|Φn1,l1,m1,ms1
i ⊗ |Φn2,l2,m2,ms2
i ⊗
··· ⊗ |ΦnN,lN,mN,msN
i. However, there are two issues that exclude such single products
from being a correct description of many-electron atoms. First, since electrons are
fermions, the many-electron state must be antisymmetric to any permutation of two
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press213 13.3 The Electronic Structure of Many-Electron Atoms
electron indexes. If all the electrons would be associated with identical spin-orbitals, the
many-electron product state would be symmetric (invariant) under index permutation,
whereas if two electrons would be associated with different spin-orbitals, the product
state would be asymmetric, namely neither symmetric nor antisymmetric, with respect
to their index permutation. Therefore, a single product state violates the antisymmetry
requirement for fermions. The second issue is that electrons interact with each other.
Therefore, even if the consequences of their being identical particles are ignored, their
many-body Hamiltonian is non-separable (see Eq. (3.4.10) for the explicit form of an
atomic Hamiltonian in the nucleus reference frame, which is not a sum over single￾electron terms), which means that the exact Hamiltonian eigenstates are not single
products.
In spite of these difficulties, spin-orbitals are very often used within theoretical
approximations to many-electron systems, including atoms, molecules, and extended
materials. The concept of orbitals is indeed useful to obtain a tractable description
of such complex systems. The widespread usage of orbitals is based on the follow￾ing solutions to the two issues just discussed: First, by applying the antisymmetrizer
(see Section 13.2) to a single product state, a proper state can be generated, which is
a superposition of products, fulfilling the requirement of antisymmetry with respect
to pair permutations (a Slater determinant). Second, the variational principle (see
Section 12.3) enables us to optimize the spatial orbitals used for approximating the
many-electron state, while accounting for the electron–electron interactions. This is
carried out within a self-consistent (mean-field) approximation (the Hartree–Fock
equations), as discussed in what follows.
Slater's Determinant and Pauli's Exclusion Principle
An elegant way to maintain the concept of single-particle states in many-electron
atoms, while maintaining the antisymmetry of the many-electron state with respect
to pair permutations, was proposed by Slater [13.5].
The electrons are distributed among spin-orbitals, which account for both the spatial
and spin state of each electron. Invoking the coordinate representation for the spatial
orbitals, assigning the ith electron to the jth spin-orbital is denoted as
hi|Φji ≡ φj(ri)·σj(i). (13.3.1)
Assuming an effective centro-symmetric field (an effective central potential) for each
electron in the nucleus reference frame, each spatial orbital obtains the form φj(r) ∝
R
(Z,N)
n,l
(r)Yl,m(θ,φ), where the radial functions {R
(Z,N)
n,l
(r)} are different from those of
the hydrogen-like atom and change from one atom to another (see what follows). σj(i)
is the spin state, which can be either σms=1/2
(i) or σms=−1/2
(i). The index j therefore
stands for a set of four quantum numbers, j ↔ (n,l,m,ms).
The N-electron state is expressed in terms of the spin orbitals, as a determinant rather
than as a single product. The columns and rows correspond, respectively, to the spin
orbital and electron indexes:
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press214 Many-Electron Systems
h1,2,...,N | Ψi ≡ 1
√
N!











h1 | Φ1i h1 | Φ2i h1 | Φ3i ··· h1 | ΦNi
h2 | Φ1i h2 | Φ2i h2 | Φ3i ··· h2 | ΦNi
h3 | Φ1i h3 | Φ2i h3 | Φ3i ··· h3 | ΦNi
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
hN | Φ1i hN | Φ2i hN | Φ3i ··· hN | ΦNi











. (13.3.2)
Notice that the determinant is an explicit linear combination of all possible permuta￾tions of the N electrons in the different N spin-orbitals, with alternating signs. Clearly,
the determinant is anti-symmetric to a permutation of two electron indexes, since the lat￾ter amounts to exchanging two rows, which changes the sign of the determinant. One can
readily verify that the slater determinant is equivalent to the antisymmetrizer operation
on a direct product of spin orbital states, namely
h1,2,...,N|Ψi = h1,2,...,N|Aˆ(|Φ1i ⊗ |Φ2i ⊗··· ⊗|ΦNi), (13.3.3)
where, Aˆ is defined in Eq. (13.2.21).
A remarkable property of this many-electron state is that it becomes improper
when two (or more) of the spin orbitals are identical. Indeed, setting |Φji = |Φj
0i in
Eq. (13.3.2), the determinant has two identical columns and therefore vanishes iden￾tically, meaning that the state is improper. This restriction is the grounds for Pauli’s
exclusion principle (named after Wolfgang Pauli): In a many-electron atom, any spin
orbital can occupy up to a single electron, or, any spatial orbital can occupy up to two
electrons, associated with a different spin quantum number. Alternatively, two electrons
cannot be associated with the same set of four quantum numbers.
The description of many-electron systems in terms of determinants composed out of
single-particle states extends beyond the realm of atoms. It is useful also in molecules
and extended many-atom systems, to be discussed in the following chapters. Particu￾larly, Pauli’s exclusion principle sets the foundations for the Fermi–Dirac distribution
of fermions (electrons, in particular) over the single-particle energy states, which
determines macroscopic optical and electronic properties of different materials, to be
discussed in Chapter 20.
The Hartree--Fock Approximation
In Chapter 12 we became familiar with the mean-field approach for the description of
many-particle systems. The idea is to approximate the many particle states in terms
of single products of single-particle states and to use the variation principle for opti￾mizing the latter. In the context of an N-electron atom, a naive implementation of this
approach would correspond to a product of orthonormal atomic spin orbitals as a
variational trial state (a Hartree product, as discussed in Section 12.3 for the case of
He),
|Ψ˜ Hi = |Φ˜
1i ⊗|Φ˜
2i ⊗··· ⊗|Φ˜ Ni (13.3.4)
hΦ˜
k
|Φ˜
k
0i = δk,k
0, (13.3.5)
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press215 13.3 The Electronic Structure of Many-Electron Atoms
where |Φki ≡ |φki⊗|σki are specific spin orbitals, corresponding to a set of four quan￾tum numbers, k ↔ (n,l,m,ms). However, such a Hartree product is incompatible with
the requirement for antisymmetry with respect to any pair permutation. A proper
trial state would be, instead, the corresponding antisymmetrized state, namely the
determinant,
|Ψ˜ i = Aˆ|Ψ˜ Hi, (13.3.6)
where Aˆ is the antisymmetrizer (Eq. (13.2.21)).
The task is therefore to optimize the trial state, |Ψ˜ i. According to the variational
principle, the optimal trial function is obtained when (Eq. (12.3.4))
hδΨ˜ |(Hˆ −ε)|Ψ˜ i = 0 (13.3.7)
for any infinitesimal change, |δΨ˜ i. ε is the variational energy, ε = hΨ˜ |Hˆ|Ψ˜ i, and Hˆ is
the many-electron Hamiltonian, which has the generic form (see Eq. (3.4.10))
Hˆ =
N
∑
j=1
hˆ
j +
N
∑
j
0>j=1
wˆ j, j
0. (13.3.8)
hˆ
j
is the single-electron (hydrogen-like) operator in the jth particle subspace (Within
each subspace, the operation is identical for all the electrons, hˆ =
−h¯
2
2me
∆r+
−KZe2
|rˆ|
), where
wˆ j, j
0 is the electron–electron interaction operator, in the subspace of the jth and j
0
th
electrons. (Within each subspace, the operation is identical for all the electron pairs,
wˆ =
Ke2
|rˆ−rˆ
0
|
).
The targets for optimization are the spin-orbitals {|Φ˜
ki}. We therefore restrict the
changes in the trial state to changes in the orbitals. (In fact, we shall constrain the spins
such that only the spatial parts are changed; see what follows),




δΨ˜

= Aˆ




δΨ˜ H

=
N
∑
k=1
Aˆ




Φ˜
1

⊗··· ⊗




δΦ˜
k

⊗··· ⊗




Φ˜ N

. (13.3.9)
Consequently, the optimization condition, Eq. (13.3.7), readshδΨ˜ H|Aˆ(Hˆ −ε)Aˆ|Ψ˜ Hi=0.
Using the facts that (see Ex. 13.3.1) the antisymmetrizer is Hermitian, it commutes with
the system Hamiltonian (Eq. (13.3.8)),
[Aˆ,Hˆ] = 0, (13.3.10)
and it satisfies the identity, Aˆ2 =
√
N!Aˆ, the optimization condition (Eq. (13.3.7))
simplifies to
hδΨ˜ H|(Hˆ −ε)Aˆ|Ψ˜ Hi = 0. (13.3.11)
Using Eq. (13.3.9) for |δΨ˜ i and requiring the condition in Eq. (13.3.11) to hold inde￾pendently for any |δΦ˜
ki, we obtain the following set of N coupled equations (for
k = 1,2,...,N),
(hΦ˜
1|⊗··· ⊗ hδΦ˜
k
| ⊗··· ⊗ hΦ˜ N|)(Hˆ −ε)Aˆ(|Φ˜
1i ⊗|Φ˜
2i ⊗ ··· ⊗|Φ˜ Ni) = 0, (13.3.12)
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press216 Many-Electron Systems
where, the orthogonality of the single-particle states (Eq. (13.3.5)) is constrained by
requiring
hδΦ˜
k
|Φ˜
k
0i|k6=k
0 = 0. (13.3.13)
Substitution of the Hamiltonian, Eq. (13.3.8), in Eq. (13.3.12), utilizing its structure in
the many-electron tensor product space, the optimal set of normalized single-particle
states {|Φ˜
ki} satisfies the following condition, for any infinitesimal change, |δΦ˜
ki,
hδΦ˜
k
|hˆ
k −εk
|Φ˜
ki+
N
∑
j=1
[hδΦ˜
k
| ⊗ hΦ˜
j
|wˆ k, j

|Φ˜
ki ⊗ |Φ˜
ji −|Φ˜
ji ⊗|Φ˜
ki

= 0, (13.3.14)
where εk
is a scalar (see Ex. 13.3.2).
Exercise 13.3.1 The antisymmetrizer Aˆ is defined in Eq. (13.2.21). (a) Show that
Aˆ = Aˆ†
. (b) Given the symmetry of the many-electron Hamiltonian to permutations
(Eqs. 13.2.16, 13.2.17), show that the antisymmetrizer commutes with the Hamiltonian,
[Aˆ,Hˆ
1,...i,..., j,...,N] = 0. (c) Show that Aˆ2 =
√
N!Aˆ.
Exercise 13.3.2 Given the antisymmetrizer, Aˆ, the single-particle operators in the jth
particle subspaces, {hˆ
j}, and the pair interactions {wˆ j, j
0} in the subspace of the jth and
j
0
th particles, prove the following identities:
(a) (hΦ˜
1| ⊗··· ⊗ hδΦ˜
k
| ⊗··· ⊗ hΦ˜ N|)Aˆ(|Φ˜
1i ⊗ |Φ˜
2i ⊗ ··· ⊗|Φ˜ Ni) = √
1
N!
hδΦ˜
k
|Φ˜
ki
(b) (hΦ˜
1|⊗··· ⊗ hδΦ˜
j
| ⊗··· ⊗ hΦ˜ N|)
N
∑
j
0=1
hˆ
j
0Aˆ(|Φ˜
1i ⊗ |Φ˜
2i ⊗··· ⊗|Φ˜ Ni)
= √
1
N!



N
∑
j
0=1
(j
06=j)
hΦ˜
j
0|hˆ
j
0|Φ˜
j
0i


hδΦ˜
j
|Φ˜
ji+ √
1
N!
hδΦ˜
j
|hˆ
j
|Φ˜
ji
(c) (hΦ˜
1|⊗··· ⊗ hδΦ˜
j
| ⊗··· ⊗ hΦ˜ N|)
N
∑
j
0>j
00=1
wˆ j
0
, j
00Aˆ(|Φ˜
1i ⊗|Φ˜
2i ⊗ ··· ⊗|Φ˜ Ni)
= √
1
N!
hδΦ˜
j
|Φ˜
ji



N
∑
j
0>j
00=1
j
0
, j
006=j
hΦ˜
j
0| ⊗ hΦ˜
j
00|wˆ j
0
, j
00|Φ˜
j
0i ⊗ |Φ˜
j
00i
−hΦ˜
j
0|⊗ hΦ˜
j
00|wˆ j
0
, j
00|Φ˜
j
00i ⊗ |Φ˜
j
0i
#
+ √
1
N!
N
∑
j
06=j=1
"
hδΦ˜
j
| ⊗ hΦ˜
j
0|wˆ j, j
0|Φ˜
ji ⊗ |Φ˜
j
0i
− hδΦ˜
j
| ⊗ hΦ˜
j
0|wˆ j, j
0|Φ˜
j
0i ⊗ |Φ˜
ji
#
.
Use the identities, (a), (b), and (c), and Eqs. (13.3.8, 13.3.12) to show that
hδΦ˜
k
|hˆ
k
|Φ˜
ki+
N
∑
j=1
[hδΦ˜
k
|⊗hΦ˜
j
|wˆ k, j
[|Φ˜
ki⊗|Φ˜
ji−|Φ˜
ji⊗|Φ˜
ki] = εkhδΦ˜
k
|Φ˜
ki,where,
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press217 13.3 The Electronic Structure of Many-Electron Atoms
εk=ε −
N
∑
j
06=k=1
hΦ˜
j
0|hˆ
j
0|Φ˜
j
0i
−
N
∑
j
0>j
00=1
j
0
, j
006=k
[hΦ˜
j
0| ⊗ hΦ˜
j
00|wˆ j, j
00|Φ˜
j
0i ⊗ |Φ˜
j
00i − hΦ˜
j
0| ⊗ hΦ˜
j
00|wˆ j
0
, j
00|Φ˜
j
00i ⊗ |Φ˜
j
0i].
Each pair interaction, wˆ k, j
, corresponds to an operator in a two-particle Hilbert
space. To obtain reduced representations of these operators in a single-particle space,
we make use of the following tensor product identities:
hδΦ˜
k
| ⊗ hΦ˜
j
| = hδΦ˜
k
|[
ˆI ⊗ hΦ˜
j
|]
|Φ˜
ki ⊗ |Φ˜
ji = [ˆI ⊗|Φ˜
ji]|Φ˜
ki
|Φ˜
ji ⊗ |Φ˜
ki = [|Φ˜
ji ⊗ ˆI]|Φ˜
ki.
Notice that each term in square brackets is a vector in one of the single-particle
spaces and an operator in the other single-particle space. Therefore, objects of the
form, [···]wˆ k, j
[···], are operators in a single-particle space. Using these identities in
Eq. (13.3.14), we obtain
hδΦ˜
k
|{hˆ
k −εk +
N
∑
j=1
[
ˆI ⊗ hΦ˜
j
|]wˆ k, j
[
ˆI ⊗|Φ˜
ji]−[
ˆI ⊗ hΦ˜
j
|]wˆ k, j
[|Φ˜
ji⊗ ˆI]}|Φ˜
ki = 0. (13.3.15)
We now recall that the single-particle states are spin-orbitals, namely, products of the
type
|Φ˜
ji = |φ˜ji ⊗ |σms, j
i, (13.3.16)
where the spin states (|σms, j
i) are fixed to either |σ1/2
i or |σ−1/2
i for each j, such that
the optimization targets are only the spatial orbitals, hr|φ˜ji. Utilizing the fact that hˆ
k
and wˆ k, j operate only on the spatial orbitals, Eq. (13.3.14) leads to (see Ex. 13.3.3.)
hδφ˜k
|
(
hˆ
k −εk +
N
∑
j=1
[
ˆI ⊗ hφ˜j
|]wˆ k, j
[
ˆI ⊗|φ˜ji]−δms, j
,ms,k
[
ˆI ⊗ hφ˜j
|]wˆ k, j
[|φ˜ji ⊗ ˆI]
)
|φ˜ki = 0.
(13.3.17)
Since this condition must hold for any hδφ˜k
|, the optimal set, {|φ˜ki}, are solutions of
the following nonlinear equations, known as the canonical Hartree–Fock equations
[13.6], [13.7],
[hˆ
k +Jˆ
k −Kˆ
k
]|φ˜ki = εk
|φ˜ki. (13.3.18)
The operator hˆ
k + Jˆ
k − Kˆ
k
is known as the Fock operator, where the operators Jˆ
k
and Kˆ
k are the “mean-field” operators that capture the electron–electron interactions
within the single-particle subspaces,
Jˆ
k =
N
∑
j=1
[
ˆI ⊗ hφ˜j
|]wˆ k, j
[
ˆI ⊗|φ˜ji] (13.3.19)
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press218 Many-Electron Systems
Kˆ
k =
N
∑
j=1
δms, j
,ms,k
[
ˆI ⊗ hφ˜j
|]wˆ k, j
[|φ˜ji ⊗ ˆI]. (13.3.20)
Notice that Kˆ
k depends explicitly on the spin states (ms,k) associated with the kth
orbital, |φ˜ki. Therefore, the Fock operator is in principle different for orbitals asso￾ciated with the two different spin states, ms,k = 1/2 and ms,k = −1/2. (Things are
simplified, e.g., in cases where the number of electrons is even, and each spatial orbital
is populated twice, with two different spin states. In this case, the Fock operator is
identical for the two spin states of each spatial orbital.)
Introducing the identity operator in the single-particle space, using the coordinate
representation, ˆI =
r
dr|ϕrihϕr| (see Eq. (11.6.6)), the Coulomb interaction in the two￾particle spaces obtains a diagonal form (Ex. 13.3.4),
wˆ k, j =
w
dr
w
dr
0 Ke2
|r−r
0
|
[|ϕrihϕr|]k ⊗[|ϕr
0ihϕr
0|] j
, (13.3.21)
where the square brackets are added to specify products between different single￾particle spaces. The operators Jˆ
k and Kˆ
k therefore obtain the explicit forms (Ex. 13.3.5)
Jˆ
k =
w
dr
0 Ke2
|rˆ −r
0
|
N
∑
j=1
|φ˜j(r
0
)|
2
(13.3.22)
Kˆ
k =
w
dr
w
dr
0
N
∑
j=1
δms, j
,ms,k
φ˜
∗
j
(r
0
)φ˜j(r)
Ke2
|r−r
0
|
|ϕrihϕr
0|. (13.3.23)
Exercise 13.3.3 Use the product form of each spin-orbital (Eq. (13.3.16)) to obtain
Eq. (13.3.17) from Eq. (13.3.15).
Exercise 13.3.4 The operator wˆ k, j
is a two-particle operator confined to the subspace of
the kth and jth particles, which is diagonal in the two-particle coordinate representation,
namely
[hϕr|]k ⊗[hϕr
0|] j
·wˆ k, j
· [|ϕr
00i]k ⊗[|ϕr
000i] j =
Ke2
|r−r
0
|
δ(r−r
00)δ(r
0 −r
000).
Introducing identity operators in the corresponding single-particle subspaces, [
ˆIr]k ⊗[
ˆIr] j
·
wˆ k, j
· [
ˆIr]k ⊗[
ˆIr] j
, derive Eq. (13.3.21) for wˆ k, j
.
Exercise 13.3.5 The single-particle operators, Jˆ
k and Kˆ
k
, are defined in Eq. (13.3.19)
and Eq. (13.3.20), respectively. Use Eq. (13.3.21) to derive the explicit coordinate
representations of these operators, (Eq. (13.3.22) and Eq. (13.3.23)), respectively.
The operator Jˆ
k
is the Coulomb operator, encountered already within the Hartree
product approximation (See Eq. (12.3.54)). As one can see, this operator corresponds
to a mean-field obtained by averaging the repulsive interaction between the kth elec￾tron and the probability density function, ρ(r
0
) =
N
∑
j=1
|φ˜j(r
0
)|
2
, derived from the spatial
orbitals of all the electrons in the system. One can notice that the kth electron is
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press219 13.3 The Electronic Structure of Many-Electron Atoms
included in the sum over j, where a so-called “self-interaction” of an electron with
itself appears to be overcounted. Nevertheless, in Eq. (13.3.18) the contribution to Jˆ
k
associated with j = k is canceled out by an identical contribution, but at opposite sign,
to the operator Kˆ
k (see Eq. (13.3.24)). Hence, the Hartree–Fock equations are free of
the self-interaction.
The operator Kˆ
k
is the electronic exchange operator. As we can see, it operates on
single-particle states, but transfers states from all the jth spaces into the kth space.
Moreover, as a single-particle operator, it is nonlocal, that is, non-diagonal in the coor￾dinate representation, hence its operation on an orbital induces delocalization in the
coordinate space (which is reminiscent of the effect of a kinetic energy operator). While
there is no classical analog for the exchange operator, it can be associated with a posi￾tion uncertainty induced by the fact that each electron is simultaneously “shared” by
all the populated orbitals.
We now return to Eq. (13.3.18), invoking the coordinate representation. Recalling
the explicit form of the single-electron operators, hϕr|hˆ
k
|φ˜ki =
h
−h¯
2
2me
∆r +
−KZe2
|r|
i
φ˜k(r)
(see Eqs. (11.6.42, 11.6.47)), we substitute Eqs. (13.3.22, 13.3.23) in Eq. (13.3.18) to
obtain the Hartree–Fock equations in the coordinate representation,
h
−h¯
2
2me
∆r +
−KZe2
|r|
i
φ˜k(r) +
N
∑
j=1
r
dr
0 Ke2
|r−r
0
|
|φ˜j(r
0
)|
2φ˜k(r)
−
N
∑
j=1
δms, j
,ms,k
r
dr
0φ˜
∗
j
(r
0
)φ˜j(r)
Ke2
|r−r
0
|
φ˜k(r
0
) = εkφ˜k(r)
. (13.3.24)
The optimal spatial orbitals, {φ˜k(r)}, are shown to be the eigenfunctions of an integro￾differential operator (the Fock operator in the coordinate representation), where each
spin orbital is associated with a corresponding orbital energy, εk
. Importantly, the
equation is nonlinear, where, by its definition, the Fock operator requires knowledge
of the set of N spin-orbitals populated by N electrons of the system. The solution of the
Hartree–Fock equations is therefore carried out iteratively. An initial guess is invoked
for the set of orbitals, and a new set is obtained by solving the integro-differential
equations. This process is repeated until the orbitals, orbital energies, and mean-field
operator are self-consistently reproduced.
In practice, there are several different implementations of the Hartree–Fock method
for calculating the optimal orbitals. The interested reader is directed to an exten￾sive complementary literature on this subject. Here we briefly mention that on top
of the orthogonality condition, Eq. (13.3.5), additional constraints are imposed while
solving Eq. (13.3.24). Spherical averaging of the mean-field operators results in a cen￾trally symmetric Fock operator, which means that the angular parts of the atomic
orbitals in the many-electron atom are eigenvalues of the electron’s angular momentum
operator, Lˆ 2
, as in any Schrödinger equation with a central potential (see Section
9.1). Consequently, the angular dependence of the spatial atomic orbitals in a many￾electron atom is the same as in a hydrogen-like atom. Additionally, the angular momen￾tum quantum numbers are affecting also the radial dependence of the orbitals, via the
centrifugal single-electron potential (Eq. (10.2.8)). The index “j,” which characterizes
each spin-orbital, stands for a set of four quantum numbers, j ↔ (n,l,m,ms), where
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press220 Many-Electron Systems
|Φ˜
ji = |φ˜n,l,mi ⊗ |σms
i ; hr|φ˜n,l,mi = R
(Z,N)
n,l
(r)Yl,m(θ,φ). (13.3.25)
The radial part, R
(Z,N)
n,l
(r), depends on the identity of the atom, namely the num￾ber of protons in the nucleus, Z, and the number of electrons, N. Usually, only the
radial part is variationally optimized. While optimizing the orbitals, we can impose
that each spatial orbital is populated twice with two different spin states (for an even
N, in a so-called, “closed shell” atom). In this case, the method is referred to as
“Restricted Hartree–Fock” [13.7]. Alternatively, this restriction can be relaxed. For
practical purposes, the trial radial orbitals are often expanded in a set of “primi￾tive” basis functions. The orbital optimization amounts to optimizing the expansion
coefficients, via the method of linear variation (see Section 12.3), namely by solving
iteratively an algebraic generalized eigenvalue problem in which the Fock operator
replaces the Hamiltonian.
The iterative procedure for solving the Hartree–Fock equations seems similar in
nature to the SCF solution of the Hartree equation (Eq. (12.3.54)). However, the lat￾ter ignores the requirement on the many-electron wave function to be antisymmetric
with respect to pair permutation and therefore, does not constrain the number of elec￾trons populating each spin-orbital. In contrast, when the Hartree–Fock equations are
solved, the N electrons are populated in N different (orthogonal) spin orbitals, such
that the many-electron wave function (the slater determinant, Eq. (13.3.2)) remains
proper and does not vanish identically. Notice that in principle, the Hermitian Fock
operator has an infinite number of eigenstates. The selection of specific eigenstates of
the Fock operator to be populated by the electrons in the many-electron ground state
is guided by the criterion of minimizing the variational energy (Eq. (12.3.8)),
ε = hΨ˜ |Hˆ|Ψ˜ i, (13.3.26)
where |Ψ˜ iis the normalized slater determinant associated with N selected spin-orbitals,
|Ψ˜ i = Aˆ|Φ˜
1i ⊗ |Φ˜
2i ⊗··· ⊗|Φ˜ Ni. (13.3.27)
Substituting the Hamiltonian, Eq. (13.3.8), one can readily express the variational
energy (or, the “Hartree–Fock energy”) in terms of the optimal orbitals (see Ex. 13.3.6),
ε =
N
∑
k=1
hφ˜k
|hˆ
k
|φ˜ki+
1
2
N
∑
k=1
N
∑
j=1
hφ˜k
|⊗ hφ˜j
|wˆ k, j
[|φ˜ki⊗|φ˜ji−δms, j
,ms,k
|φ˜ji⊗|φ˜ki]. (13.3.28)
Exercise 13.3.6 Using the properties of the antisymmetrizer (Eq. (13.3.10), and Aˆ2 = √
N!Aˆ), derive Eq. (13.3.28).
Importantly, the Hartree–Fock energy is different from a sum of the populated
orbital energies. The latter are obtained by taking the expectation value of the Fock
operator (Eq. (13.3.18)), with respect to each specific orbital,
εk = hφ˜k
|[hˆ
k +Jˆ
k −Kˆ
k
]|φ˜ki
= hφ˜k
|hˆ
k
|φ˜ki+
N
∑
j=1
hφ˜k
| ⊗ hφ˜j
|wˆ k, j
[|φ˜ki ⊗ |φ˜ji −δms, j
,ms,k
|φ˜ji ⊗ |φ˜ki]
, (13.3.29)
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press221 13.3 The Electronic Structure of Many-Electron Atoms
where the sum of the occupied orbital energies reads
N
∑
k=1
εk =
N
∑
k=1
hφ˜k
|hˆ
k
|φ˜ki+
N
∑
k=1
N
∑
j=1
hφ˜k
| ⊗ hφ˜j
|wˆ k, j
[|φ˜ki ⊗ |φ˜ji −δms, j
,ms,k
|φ˜ji ⊗ |φ˜ki].
(13.3.30)
Subtracting Eq. (13.3.28) from Eq. (13.3.30), the difference between the variational
energy and the sum over orbital energies reads
N
∑
k=1
εk −ε =
1
2
N
∑
k=1
N
∑
j=1
hφ˜k
| ⊗ hφ˜j
|wˆ k, j
[|φ˜ki ⊗ |φ˜ji −δms, j
,ms,k
|φ˜ji ⊗ |φ˜ki]. (13.3.31)
Indeed, the kth orbital energy (Eq. (13.3.18)) includes the Coulomb and exchange
pair interactions between this orbital and any other orbital. When summing up all
the orbital energies, each specific pair interaction appears twice, since it appears in
the calculation of two of the orbital energies. Therefore, the overcounted interaction
energy needs to be subtracted from the sum of orbital energies, to relate correctly to
the variational energy. Remarkably, however, when it comes to selecting the N orbitals
(eigenstates of the Fock operator) for which the Hartree–Fock energy is minimal, it
is usually sufficient to minimize the corresponding sum over orbital energies. This is
known as the “Aufbau principle”: in the ground state of an atom, the N electrons usually
occupy the N spin orbitals corresponding to the lowest possible sum of orbital energies.
Put differently, the orbitals are “filled” from the lowest orbital energy and upwards,
subject to the Pauli’s exclusion principle, namely, up to two electrons of different spin
states per each spatial orbital. The success of the orbital energies in predicting the
electronic population in the ground state relies on the fact that the energy differences
between nearby orbital energies are typically large in magnitude in comparison to the
overcounted interaction energy (Eq. (13.3.31)), such that the sum of orbital energies
dominates the Hartree–Fock energy. Indeed, in cases where the orbital energies get
close to each other (examples are discussed in what follows), the overcounted interac￾tion energy may become dominant. Orbital populations then deviate from the Aufbau
principle, and only a careful calculation of the ground state energy can determine the
set of spin orbitals to be populated.
As it turns out, the mean-field approximation that leads to the Hartree–Fock approx￾imation seems to provide a reliable picture with respect to the electronic structure of
many-electron atoms at their ground state. Other mean-field approaches, such as the
Thomas–Fermi (TF) model [13.8] and the density functional theory [13.9], provide
similar qualitative trends, but much of the understanding of the electronic structure,
and particularly the orbital approximation, is naturally related to the Hartree–Fock
approximation. A rigorous quantitative description of the ground-state energy and
the many-electron wave function requires, however, “post mean-field” treatments. The
latter are based either on perturbation theory, where the difference between the full
Hamiltonian and the Fock operator is regarded as a perturbation, or on the linear
variation approach, where the exact wave function is approximated as a linear com￾bination of different determinants, each corresponding to a different selection of N
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press222 Many-Electron Systems
spin-orbitals in which the N electrons are populated (configuration-interaction and
coupled cluster approaches [13.10]).
The Periodic Table of the Elements
We are now ready for a comparative review of the structure of different many￾electron atoms, within the realm of the orbital (Hartree–Fock) approximation, the
Pauli exclusion principle, and the Aufbau principle as introduced in the preceding
discussion. We recall that this idealized picture ignores relativistic corrections, which
become important for the “heavier” atoms, associated with large atomic numbers
(>∼ 100). Let us discuss several principles that apply to all the atoms within this
framework.
I. The many-electron wave function at the atomic ground state is approximated as a
Slater-determinant, where the N electrons are populated in N spin-orbitals that
minimize the Hartree–Fock energy.
II. Each spin-orbital is a product φ(r,θ,φ)⊗|σms
i, where φ(r,θ,φ)is the spatial orbital
and |σms
i is the electronic spin state, associated with the quantum number, ms
,
which obtains one of the two values, ms = −1/2,1/2.
III. The spatial orbitals obtain the form φ(r,θ,φ) = Yl,m(θ,φ)R
(Z,N)
n,l
(r). The quan￾tum numbers (l,m) are constrained, as in the case of the hydrogen-like atom,
namely m = −l,−l + 1,...,0...,l − 1,l. Given the quantum numbers, l and m, the
orbital’s angular dependence is “universal” for all the atoms. (In case of degeneracy
with respect to l, a set of degenerate functions {Yl,m(θ,φ)} can be replaced by an
orthonormal set of their linear combinations.)
IV. The radial wave functions depend on the angular quantum, l, and on a “main”
quantum number, n, as in the hydrogen-like atom, where n = l + 1,l + 2, These
radial functions are not “universal”: Different atoms, associated with different
numbers of protons (Z) and/or electrons (N), would be associated with different
radial functions, R
(Z,N)
n,l
(r), for the same n and l.
V. Each orbital corresponds to an orbital-energy, ε
(Z,N)
n,l
. While for a hydrogen-like
atom the orbitals associated with different angular quantum numbers (l) are
degenerate, in a many-electron atom the orbital energies depend on both n and l.
Indeed, solutions to the radial Schrödinger equation, which correspond to differ￾ent l values, are degenerate when the electron is subject to the bare atomic nucleus
(see Eq. (10.2.8)). This degeneracy is removed when the hydrogen-like Hamilto￾nian is replaced by the Fock operator (Eq. (13.3.24)), in which the presence of
many electrons is taken into account in terms of additional mean-field operators.
This effect is schematically represented in Fig. 13.3.1, where the energy levels asso￾ciated with a quantum number n in the hydrogen-like atom are shown to split into
groups of energy levels (often termed energy shells) in a many-electron atom. The
values of the orbital energies {ε
(Z,N)
n,l
} change from one atom to another, as illus￾trated schematically in Fig. 13.3.2. As the atomic number (Z) increases, the orbital
energy, ε
(Z,N)
n,l
, tends to decrease in response to the increasing attractive positive
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press223 13.3 The Electronic Structure of Many-Electron Atoms
nucleus charge (which is not fully compensated for by the corresponding addition
of electrons). Importantly, the effect is different for different orbitals, since the
increase in the number of electrons changes the repulsive mean-field in a nontriv￾ial way. Notice particularly that even the order of the atomic orbitals according to
their energy may differ between different atoms. (For example, the 4s(n = 4, l = 0)
and 3d (n = 3, l = 2) orbital energies cross each other, as Z is changed.) Never￾theless, for a fixed quantum number, n (namely, within a given energy shell), the
orbital energy increases with increasing angular quantum number, l. This observed
trend can be qualitatively explained by combining classical electrostatic arguments
with our earlier acquaintance with the model of the hydrogen-like atom. First, we
recall that as in classical electrostatics, the typical distance between the electron
and the nucleus in a hydrogen-like atom increases with increasing orbital energy
(see Fig. 10.3.3). Assuming this trend to hold also for many-electron atoms, we can
conclude that electrons associated with internal energy shells (smaller n values) are
closer to the nucleus (in a probabilistic, quantum mechanical, sense) than electrons
associated with external energy shells. Consequently, electrons in orbitals asso￾ciated with a given quantum number n experience the positive nucleus charge as
well as a mean-field owing to the electrons in the inner shell orbitals. This repulsive
mean-field effectively screens the positive nucleus charge, resulting in a less positive
“effective core charge.” Comparing now hydrogen-like orbitals associated with the
same quantum number n, but with different quantum numbers l (Fig. 10.3.4), we
notice that in the hydrogen-like atom, lower l values are associated with a larger
probability density at distances in the vicinity of the nucleus. If this is the case
also in a many-electron atom, it means that electrons associated with lower l val￾ues have increasing probability of “penetrating” beyond the “screen” of the inner
shell electrons, into the vicinity of the nucleus. Consequently, electrons in orbitals
of lower l values experience a more positive (attractive) effective core charge, and
the corresponding orbital energy is accordingly lower. For example, in Fig. 13.3.2,
one can see that in an atom like Ca, the energy of the 4s orbital (l = 0) drops below
that of the 3d orbital (l = 2), although in terms of the main quantum number (n)
4s belongs to a higher energy shell. The relatively low energy of the 4s orbital can
be attributed to the “penetration” of this orbital to the vicinity of the nucleus.
VI. The ground state of each neutral atom is approximated by an “electronic configura￾tion,” which represents a single Slater determinant that minimizes the many-electron
energy. Examples of the electronic configuration for some elements and their cor￾respondence to a Slater determinant are presented in Figs. 13.3.3 and 13.3.4.
Usually, the orbitals are populated from lower to higher orbital energy (the Auf￾bau principle), where each spatial orbital can be populated by up to two electrons
(Pauli’s principle). In some exceptional cases (see, e.g., the example of scandium
(Sc), with Z = 21), the requirement of minimizing the many-electron energy does
not comply with the Aufbau principle, as the difference between nearby orbital
energies becomes small with respect to the overcounted interaction energy (see
Eq. (13.3.31)). When an orbital energy is degenerate, namely, when there is more
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press224 Many-Electron Systems
Orbital energy
n = 3 n = 3
l = 2
l = 1
l = 0
l = 1
l = 0
l = 0
n = 2 ε n = 2
n = 1 n = 1
Hydrogen-like atom Many-electron atom
Ftigure 13.3.1 A schematic representation of the orbital energies and their degeneracies in a hydrogen-like atom and in
many-electron atoms. Each dark horizontal line represents an orbital. In a hydrogen-like atom, all the orbitals
associated with a given n are degenerate. The degeneracy is removed by electron–electron interactions in
many-electron atoms, where the orbital energy depends on both quantum numbers, n andl.
4s
3s 3p 3d
2s 2p
H (Z = 1) Li (Z = 3) C (Z = 6) Ca (Z = 20) Sc (Z = 21)
1s
4s
4s
3p 3d 3d
3s
2p
2s
3d 4s
3p
3p
3s
3s
2p
2s
2p
2s
4s
3d
3p
3s
2p
2s
1s
1s
1s 1s
log(E)
Ftigure 13.3.2 A schematic representation of the changes in the orbital energies for the lowest-energy orbitals:
1s,2s,2p,3s,3p,3d, 4s, and in their order, for a few selected atoms corresponding to the atomic numbers 1, 3,
6, 20, 21.
than one spatial orbital to be populated at the same orbital energy, the low￾est energy state would correspond to population of one electron at each spatial
orbital, at the same electronic spin state. An example for the case of carbon is
illustrated in Fig. 13.3.5. This principle (Hund’s rule, after Friedrich Hund) is
attributed to the exchange interaction between electrons of the same spin, which
lowers the many-particle energy, when the electrons are delocalized among the
degenerate orbitals. This effect will be discussed in the next section.
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press225 13.3 The Electronic Structure of Many-Electron Atoms
Z
1 H 1s1
He 1s2
Li 1s2 2s1
Be 1s2 2s2
1s2 2s2 2p1
1s2 2s2 2p2
1s2 2s2 2p3
1s2 2s2 2p4
1s2 2s2 2p5
1s2 2s2 2p6
1s2 2s2 2p6 3s1
B
C
N
O
F
Ne
Na
1s Ca 2 2s2 2p6 3s2 3p6 4s2
Sc 1s2 2s2 2p6 3s2 3p6 4d1 4s2
2
3
4
5
6
7
8
9
10
11
20
21
Symbol Electronic Configuration
Ftigure 13.3.3 The electronic configuration of some selected neutral atoms of different elements.
When it comes to chemical reactivity of atoms, their tendency to form chemical
bonds (see Chapter 14) or to exchange electrons with their surroundings, the populated
atomic orbitals at the outer shell are the most relevant. According to the previously out￾lined principles of electronic population of the atomic orbitals, which apply to all atoms
in their ground electronic state, each energy shell can accommodate a finite number of
electrons (2 for n = 1, 8 for n = 2,18 for n = 3, etc.). As the atomic number increases
from one atom to another, fully occupied shells get “closed” and new shells “open”.
Consequently, different atoms are associated with similar electronic population in their
outer shell orbitals. Remarkably, atoms of elements associated with similar outer shell
electronic configuration show similarity in their properties. This is the basis for the
observed “periodic” trends observed in the properties of different elements along the
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press226 Many-Electron Systems
E
ψ(1,2,3) =
l = 1
l = 0
l = 0
n = 2
2s1
1s 2 n = 1
Y0,0(θ1,ϕ1)R1,0 (r1)α(1)
(3,3)
Y0,0(θ2,ϕ2)R1,0 (r2)α(2)
(3,3)
Y0,0(θ3,ϕ3)R1,0 (r3)α(3)
(3,3)
Y0,0(θ1,ϕ1)R1,0 (r1)β(1)
(3,3)
Y0,0(θ2,ϕ2)R1,0 (r2)β(2)
(3,3)
Y0,0(θ3,ϕ3)R1,0 (r3)β(3)
(3,3)
Y0,0(θ1,ϕ1)R2,0 (r1)α(1)
(3,3)
Y0,0(θ2,ϕ2)R2,0 (r2)α(2)
(3,3)
Y0,0(θ3,ϕ3)R2,0 (r3)α(3)
(3,3)
1
√3!
Figure 13.3.4 t A detailed view of the electronic configuration of Li(Z = N = 3),1s
22s
1
, and the Slater determinant it
corresponds to. The different spin states are denoted ashi|σ1/2
i = α(i)andhi|σ−1/2
i = β(i), and are
conventionally marked by half arrows up and down, respectively.
E
l = 1
l = 0
l = 0
n = 2
n = 1
Figure 13.3.5 t A detailed view of the electronic configuration of a carbon atom (C, Z = N = 6), namely, 1s
22s
22p
2
. The
higher occupied atomic orbitals are degenerate p-type orbitals, where the minimal energy determinant corresponds
to two electrons with the same spin state, singly occupying two different orbitals. Notice that different determinants
corresponding to different choices of occupying two out of the three p orbitals are all associated with the same
variational (Hartree–Fock) energy.
periodic table of the elements. Consider, for example, the group of elements known as
the alkali metals. They are all highly reactive metals, associated with relatively low first
ionization potential and relatively small atomic radii. Inspecting their electronic config￾uration reveals that all neutral alkali atoms have a single electron at their external shell
s-type orbital, for example, Li: [1s2
]2s1
, Na: [1s22s22p6
]3s1
,K : [1s22s22p63s23p6
]4s1
,
and so on. Similarly, the group of alkaline earth metals (Be, Mg, Ca, Sr, etc.) are all
associated with an outer shell electronic configuration of ns2
. The halogens group (F,
Cl, Br, I, etc.) are nonmetals, associated with the outer shell configuration, ns2np5 The
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press227 13.4 Two-Electron Spin-Orbital Functions – Singlet and Triplet States
1
H
3
Li
11
Na
19
K
37
Rb
55
Cs
87
Fr
57
La
89
Ac
6
C
14
Si
32
Ge
50
Sn
82
Pb
114
Uuq
7
N
15
P
33
As
51
Sb
83
Bi
115
Uup
8
O
16
S
34
Se
52
Te
84
Po
116
Uuh
9
F
17
Ci
35
Br
53
I
85
At
117
Uus
10
Ne
2
He
18
Ar
36
Kr
54
Xe
86
Rn
118
Uuo
5
B
13
Ai
31
Ga
49
In
81
Ti
113
Uut
70
Yb
102
No
4
Be
12
Mg
20
Ca
38
Sr
56
Ba - -
- - 88
Ra
58
Ce
90
Th
21
Sc
39
Y
71
Lu
103
Lr
60
Nd
92
U
22
Ti
40
Zr
72
Hf
104
Rf
61
Pm
93
Np
23
V
41
Nb
73
Ta
105
Db
62
Sm
94
Pu
24
Cr
42
Mo
74
W
106
Sg
63
Eu
95
Am
25
Mn
43
Tc
75
Re
107
Bh
64
Gd
96
Cm
26
Fe
44
Ru
76
Os
108
Hs
65
Tb
97
Bk
27
Co
45
Rh
77
Ir
109
Mt
66
Dy
98
Cf
28
Ni
46
Pd
78
Pt
110
Ds
67
Ho
99
Es
29
Cu
47
Ag
79
Au
111
Rg
68
Er
100
Fm
30
Zn
48
Cd
80
Hg
112
Cn
69
Tm
101
Md
59
Pr
91
Pa
Ftigure 13.3.6 The periodic table of the elements
noble gas atoms (He, Ne, Ar, Kr, etc.) are all associated with the outer shell configu￾ration, ns2 np6
, and so on. Each such group (or “family”) of elements corresponds to a
column in the periodic table of the elements. The members within each family have the
same outer shell electronic configuration in their neutral state, but they differ in the
number of filled energy shells. Consequently, their atomic numbers (and the numbers
of electrons) differ by electron numbers corresponding to occupation of an entire shell.
These numbers can take the values, 2n2 = 2,8,18,32,..., which indeed correspond to
the observed “period lengths” in the periodic table of the elements (Fig. 13.3.6). It is
remarkable that these numbers are related to the constraints set on the angular and
magnetic quantum numbers to obtain proper solutions to the Schrödinger equation
for a single-electron atom.
13.4 Two-Electron Spin-Orbital Functions – Singlet and Triplet
States
When discussing the spin of a single electron, it was emphasized that in nonrelativis￾tic quantum mechanics, the space of physical states is a tensor product of the spin
and coordinate spaces. This idea was adopted within the concept of spin-orbitals for
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press228 Many-Electron Systems
many-electron system, in the sense that each spin-orbital is a product of spatial and spin
states. Nevertheless, while a Hartree product of spin orbitals can always be factorized
into a single product of a many-electron spatial function (wave function) and a many￾electron spin function, the antisymmetrizer operation on a Hartree product generates
a superposition of such products, in which the many-electron spin and orbital states
may become entangled; namely, the many-electron state cannot be factorized into a
single product of spin and spatial states. Such determinants do comply with being
antisymmetric under permutation of electrons between spin-orbitals, but they include
“artificial correlation” (at least within nonrelativistic quantum mechanics) between
the spin and spatial coordinates. Even an approximate nonrelativistic description of
the physical states of many-electron systems must therefore extend beyond the realm
of single determinants. In this section we focus on systems of two electrons, introduc￾ing the corresponding product states between two-electron “spin functions” (known
as the singlet and triplet states) and spatial two-electron functions, while emphasizing
their relation to Slater determinants. Generalization to systems of N electrons will be
discussed only qualitatively. A quantitative analysis of many-electron spin functions
can be found elsewhere [13.11].
Let us consider a system of two electrons (a “helium-like” atom). The single-electron
states are spin orbitals, |Φji = |φji ⊗ |σji, where in the coordinate representation
(Eq. (13.3.1)), each spin orbital has the form
hi|Φji ≡ φj(ri)·σj(i). (13.4.1)
We now focus on a minimal variational space, in which the number of spatial orbitals
is limited to two. These spatial-orbitals are denoted as φ1(ri) and φ2(ri), where the spin
state per electron is either α(i) or β(i), such that there are four different spin-orbitals
in total:
φ1(ri)α(i)
φ2(ri)α(i)
φ1(ri)β(i)
φ2(ri)β(i).
Since only two out of the four spin-orbitals are populated in a two-electron system, six
(

4
2

) different two-electron determinants can be defined (see also Fig. 13.4.1):
Ψ1α,1β = √
1
2
φ1(r1)φ1(r2)[α(1)β(2)−β(1)α(2)]
Ψ2α,2β = √
1
2
φ2(r1)φ2(r2)[α(1)β(2)−β(1)α(2)]
Ψ1α,2α = √
1
2
[φ1(r1)φ2(r2)−φ2(r1)φ1(r2)]α(1)α(2)
Ψ1β,2β = √
1
2
[φ1(r1)φ2(r2)−φ2(r1)φ1(r2)]β(1)β(2)
Ψ1α,2β = √
1
2
[φ1(r1)φ2(r2)α(1)β(2)−φ2(r1)φ1(r2)β(1)α(2)]
Ψ1β,2α = √
1
2
[φ1(r1)φ2(r2)β(1)α(2)−φ2(r1)φ1(r2)α(1)β(2)].
(13.4.2)
We recall that the Hamiltonian for the two-electron atom reads (Eq. (13.3.8))
Hˆ = hˆ
1 +hˆ
2 +wˆ1,2. (13.4.3)
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press229 13.4 Two-Electron Spin-Orbital Functions – Singlet and Triplet States
Ftigure 13.4.1 Six possible Slater determinants for two electrons in a space of two spatial orbitals (φ1 and φ2). The electronic spin
states are marked by half arrows up and down, forα and β, respectively.
In an atom, hˆ
1 and hˆ
2 are the single-electron (hydrogen-like) Hamiltonians, which read
in the coordinate representation: hˆ
j ≡ hˆ
r j =
−h¯
2
2me
∆r j +
−KZe2
|r j
|
, where wˆ1,2 =
Ke2
|r1−r2|
is the
electron–electron interaction. The variational energy associated with each determinant
is given as ε = hΨ|Hˆ|Ψi, which can be readily expressed as (see Ex. 13.4.1)
ε1α,1β = 2E1 +J1,1
ε2α,2β = 2E2 +J2,2
ε1α,2α = ε1β,2β = E1 +E2 +J1,2 −K1,2
ε1α,2β = ε1β,2α = E1 +E2 +J1,2.
(13.4.4)
Here E1 and E2 are integrals corresponding to the single-particle Hamiltonians,
E1 =
w
drφ
∗
1
(r)hˆ
rφ1(r)
E2 =
w
drφ
∗
2
(r)hˆ
rφ2(r)
, (13.4.5)
{Ji, j} correspond to the Coulomb integrals,
Ji, j = Ke2
w
dr
w
dr
0
|φi(r)|
2
|φj(r
0
)|
2
|r−r
0
|
, (13.4.6)
and K1,2 corresponds to the exchange integrals,
K1,2 = Ke2
w
dr
w
dr
0 φ
∗
1
(r)φ
∗
2
(r
0
)φ2(r)φ1(r
0
)
|r−r
0
|
. (13.4.7)
Exercise 13.4.1 For each determinant in Eq. (13.4.2), (a) Calculate the appropri￾ate energy ε = hΨ|Hˆ|Ψi in Eq. (13.4.4) by expressing it in terms of the integrals
given in Eqs. (13.4.5–13.4.7). (b) Calculate the orbital energy for each of the rele￾vant spin orbitals, φ1(ri)α(i), φ2(ri)α(i) φ1(ri)β(i), or φ2(ri)β(i), using Eq. (13.3.29).
(c) Verify that the relation between the total energy and the sum over orbital energies
(Eq. (13.3.31)) holds.
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press230 Many-Electron Systems
In the first two determinants, Ψ1α,1β and Ψ2α,2β
(Eq. (13.4.2)), the two electrons
occupy the same spatial orbital with different spin states. Each two-electron determi￾nant is naturally factorized in these cases into a product of two-electron spatial and spin
functions, where the spatial function is symmetric and the spin function is antisymmet￾ric to permutation of the electron indexes. One can readily yerify that the two-electron
spin state, [α(1)β(2) − β(1)α(2)], is an eigenstate of the two-electron spin operators,
Sˆ
z = Sˆ
z1 + Sˆ
z2
and Sˆ2 =
￾
Sˆ
x1 +Sˆ
x2
2
+
￾
Sˆ
y1 +Sˆ
y2
2
+
￾
Sˆ
z1 +Sˆ
z2
2
, associated with the
quantum numbers ms = 0 and s = 0, respectively (see Ex. 13.4.2). Such a spin state is
termed a singlet state, owing to the single possible projection of the total spin on the
z-axis.
When the energy difference between the single-particle energies is large with respect
to all the Coulomb and exchange integrals, namely |E2 − E1| >> J1,1, J2,2, J1,2,K1,2,
it is easy to see (Eq. (13.4.4)) that double occupation of the orbital with the lowest
single-particle energy, that is, the determinant, Ψ1α,1β
, is the lowest-energy state of the
two-particle system in the two-orbital space (see Fig. 13.4.2). Indeed, considering a
two-electron atom (He, or He-like atom), the ground state configuration corresponds
to 1s
2
, where the orbital of lowest single-particle energy is identified as a 1s-type func￾tion. Notice that the spatial state of the two electrons in the variational ground state of
the He atom (a product of two identical orbitals) coincides with the Hartree solution,
Eq. (12.3.57), which indeed gives a reasonable approximation of the atom’s ground￾state energy (see Section 12.3). The spin state of the two electrons, which is missing in
the Hartree approximation, has no effect on the ground-state energy. Nevertheless, the
antisymmetry of the singlet spin state with respect to permutation of the two electrons
is essential. The double occupation of the two electrons in the same (lowest-energy)
orbital means that the spatial two-electron state is symmetric with respect to permu￾tation, and the entire state is antisymmetric only due to the spin state. In a broader
context, the case of He-like atoms is indicative with respect to the ground state of any
atom according to the Aufbau principle: whenever the energy gap to the next orbital
energy is large with respect to all the Coulomb and exchange integrals, the electrons
will first be paired with different spins in the orbital with the lowest available orbital
energy.
Given that the ground state of the system corresponds to Ψ1α,1β
, the next two deter￾minants, Ψ1α,2a and Ψ1β,2β
(see Eq. (13.4.2)), correspond to the first excited electronic
state (Fig. 13.4.2). As before, the total energy corresponds to the sum of single-particle
energies and the Coulomb interaction term between the two orbitals, but the iden￾tical electronic spins in these configurations allow for an additional contribution to
the energy, in terms of an exchange interaction term (see Eq. (13.4.4)). Notice that
exchange interaction lowers the state energy, owing to its nonlocal nature (see the dis￾cussion of the exchange operator, Kˆ
k
, in Section 13.3). Like in Ψ1α,1β and Ψ2α,2β
, the
determinants Ψ1α,2α and Ψ1β,2β are, in fact, products of two-electron spatial and spin
functions, but in this case, the spin function is symmetric and the spatial function is
antisymmetric to permutation of the electrons’ indexes. The two-electron spin states,
[α(1)α(2)] or [β(1)β(2)], are eigenstates of the two-electron spin operators, Sˆ
z and
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Pr231 13.4 Two-Electron Spin-Orbital Functions – Singlet and Triplet States
Sˆ2
, corresponding to the total spin quantum numbers, s = 1 and ms = 1 or ms = −1,
respectively (see Ex. 13.4.2). These spin states are termed triplet states, since the total
spin associated with s = 1 has three possible projections on the z-axis, ms = 0,±1 (the
two-electron spin state associated with ms = 0 is discussed in what follows).
The next two determinants, Ψ1α,2β and Ψ1β,2α, are associated with yet higher ener￾gies (see Eq. (13.4.4) and Fig. 13.4.2). Since each spatial orbital is paired with a
different electronic spin state in each spin-orbital, the exchange interaction vanishes,
and the two-electron energy is consequently higher. Importantly, unlike in the case
of the other determinants, Ψ1α,2β and Ψ1β,2α are not single products of two-electron
spatial and spin functions, namely, the spin and spatial states are entangled. Moreo￾ver, these two determinants are eigenstates of Sˆ
z
, corresponding to ms = 0, but they
are not eigenstates of the total spin operator, Sˆ2
, which implies that the two-electron
spin is not well-defined. Indeed, while both Ψ1α,2β and Ψ1β,2α satisfy the require￾ment for antisymmetry with respect to electron pair permutation, each of them is
an incomplete description of the physical state. Given that the two electrons have
different spins, there is no way to distinguish which spin is correlated with each
one of the orbitals, as suggested by the construction of Ψ1α,2β or Ψ1β,2α. A com￾plete description would give an equal probability to the two possible configurations,
namely, it would be a superposition of the two determinants with equal probability
weights,
Ψ± =
1
√
2
[Ψ1α,2β ±Ψ1β,2α]. (13.4.8)
(We skip here a detailed explanation for the restriction of the coefficients to ±1 rather
than to any phase. It follows from the Hermiticity of the spin permutation operator,
and arguments similar to ones used in the derivation of Eqs. (13.2.5–13.2.11), but for
the spin permutation only.)
A proper description of two-electron states for electrons of different spins extends,
therefore, beyond the space of single determinants. In this sense, the states Ψ+ and
Ψ− are “post-Hartree Fock,” that is, configuration-interaction approximations to the
exact two electron states. We can readily see that the states Ψ+ and Ψ− are products of
two-electron spatial and spin functions (Ex. 13.4.3),
Ψ± =
1
√
4
[φ1(r1)φ2(r2)∓φ2(r1)φ1(r2)][α(1)β(2)±β(1)α(2)], (13.4.9)
where in Ψ+ the spin function is symmetric and the spatial function is antisymmetric
with respect to permutation of the electron indexes, and vice versa in Ψ−. Also here, the
two-electron spin states, [α(1)β(2) +β(1)α(2)] and [α(1)β(2)−β(1)α(2)], are eigen￾states of the two-electron spin operators, Sˆ
z and Sˆ2
, corresponding to the total spin
quantum numbers, ms = 0, s = 1, and ms = 0, s = 0, respectively (see Ex.13.4.2). Ψ+
and Ψ− therefore correspond to triplet and singlet spin states, respectively. The total
energy, ε = hΨ|Hˆ|Ψi, associated with these two-electron states reads (see Ex. 13.4.4
and Fig. 13.4.2)
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press232 Many-Electron Systems
ε+ = E1 +E2 +J1,2 −K1,2
ε− = E1 +E2 +J1,2 +K1,2
. (13.4.10)
Ψ+ has the same energy as the other two triplet states, Ψ1α,2α and Ψ1β,2β
, which
corresponds to the same antisymmetric spatial two-electron function. Ψ− is asso￾ciated with a higher energy, which corresponds to the symmetric spatial function,
√
1
2
[φ1(r1)φ2(r2) + φ2(r1)φ1(r2)]. A qualitative argument attributes the increase in
energy to increasing electrostatic repulsion between the electrons, which diverges when
the two electrons are positioned at the same location in coordinate space. The proba￾bility density for this to occur depends on the spatial wave function, where it is finite
in Ψ− (the singlet state), |φ1 (r1)φ2 (r2) +φ2 (r1)φ1 (r2)|
2 −→r2→r1
4|φ2 (r1)φ1 (r1)|
2
, but
vanishes in the triplet state, |φ1 (r1)φ2 (r2)−φ2 (r1)φ1 (r2)|
2 −→r2→r1
0.
In summary, the four different spin-functions for two electrons are the singlet state,
1
√
2
[α(1)β(2)−β(1)α(2)],
and the triplet states,
[α(1)α(2)]
1
√
2
[α(1)β(2) +β(1)α(2)]
[β(1)β(2)].
The singlet and triplet spin functions are common eigenfunctions of the total two￾electron spin operators, Sˆ2 and Sˆ
z
, associated with the quantum numbers, s = ms = 0
for the singlet, and s = 1, ms = 1,0,−1 for the triplet (Ex. 13.4.2):
Sˆ
2
[α(1)β(2)−β(1)α(2)] = 0h¯
2
[α(1)β(2)−β(1)α(2)] (13.4.11)
Sˆ
2



α(1)α(2)
α(1)β(2) +β(1)α(2)
β(1)β(2)



= 2h¯
2



α(1)α(2)
α(1)β(2) +β(1)α(2)
β(1)β(2)



(13.4.12)
Sˆ
z
[α(1)β(2)−β(1)α(2)] = 0h¯[α(1)β(2)−β(1)α(2)] (13.4.13)
Sˆ
zα(1)α(2) = h¯α(1)α(2)
Sˆ
z
[α(1)β(2) +β(1)α(2)] = 0
Sˆ
zβ(1)β(2) = −h¯β(1)β(2).
(13.4.14)
When two electrons occupy a single spatial orbital, the spin state is a singlet, and the
two-electron state corresponds to Ψ1α,1β
(or Ψ2α,2β
), see Eq. (13.4.2) and Fig. 13.4.1.
The antisymmetry to permutation is attributed to the spin function in this case.
When two electrons occupy two different spatial orbitals, there are four proper two￾electron states. The three lower-energy states correspond to triplet states, associated
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press233 13.4 Two-Electron Spin-Orbital Functions – Singlet and Triplet States
with an antisymmetric spatial function and a symmetric spin function with respect
to permutation of the electron indexes,



Ψ1α,2α
Ψ+
Ψ1β,2β



=
1
√
2
[φ1(r1)φ2(r2)−φ2(r1)φ1(r2)]



α(1)α(2)
√
1
2
[α(1)β(2) +β(1)α(2)]
β(1)β(2)



.
(13.4.15)
The higher-energy state corresponds to a singlet state, associated with an antisymmetric
spin function and a symmetric spatial function, with respect to permutation of the
electron indexes:
Ψ− =
1
√
4
[φ1(r1)φ2(r2) +φ2(r1)φ1(r2)][α(1)β(2)−β(1)α(2)]. (13.4.16)
Exercise 13.4.2 Show that the following four spin states of two electrons,
α(1)α(2)
β(1)β(2)
α(1)β(2) +β(1)α(2)
α(1)β(2)−β(1)α(2),
are eigenfunctions of the two-electron spin operators:
Sˆ
z = Sˆ
z1 +Sˆ
z2
Sˆ
2 = (Sˆ
x1 +Sˆ
x2
)
2 + (Sˆ
y1 +Sˆ
y2
)
2 + (Sˆ
z1 +Sˆ
z2
)
2
.
What are the respective eigenvalues and spin quantum numbers for each of the spin states?
Exercise 13.4.3 Substitute the relevant determinants, defined in Eq. (13.4.2), in
Eq. (13.4.8) to derive Eq. (13.4.9).
Exercise 13.4.4 Express the energy ε = hΨ|Hˆ|Ψi of Ψ+ and Ψ−, as defined
in Eq. (13.4.9), in terms of the integrals defined in Eq. (13.4.5–13.4.7) (obtain
Eq. (13.4.10)).
When the two single-particle energies associated with the two orbitals E1 =
hφ1|hˆ
1|φ1i and E2 = hφ2|hˆ
2|φ2i are well separated, namely E2−E1 >> J1,1, J2,2, J1,2,K1,2,
the situation corresponds to a He-like atom, where φ1 and φ2 can be identified with
the 1s and 2s type orbitals. A summary of the different two-electron states for a He￾like atom is presented in Fig. 13.4.2. The singlet and triplet spin stats are marked
by (S) and (T) respectively and are sorted according to their energy, for E2 − E1 >>
J1,1, J2,2, J1,2,K1,2. The ground state is a singlet spin state, the first excited state is
a triplet (threefold degenerate in the absence of a magnetic field), where the next
two excitations are again singlet states. Let us emphasize that while we considered
explicitly only a He-like atom, similar considerations apply to the ground and first
excited states of many-electron “closed shell” atoms (or molecules, in fact), where
the ground state corresponds to an even number of paired electrons, and the first
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press234 Many-Electron Systems
Figure 13.4.2 t A schematic representation of the ground and first excited states of a “helium-like” atom within the manifold of the
two lowest-energy orbitals. The proper states that correspond to uncorrelated products of spin and orbital functions
are marked in black. (Slater determinants that artificially correlate spin and orbitals are marked in gray.) The different
states are sorted according to the two-electron energy.
excitations involve single- or two-electron transitions to the next empty orbital (accord￾ing to its single-particle energy). In particular, the ground state of such systems is
a singlet, where the first excitations are associated with a triplet and a singlet state,
with the triplet being lower in energy due to the stabilizing effect of the exchange
interaction.
We now turn to the case where two electrons are populated in two degenerate spa￾tial orbitals. In this case, E1 = E2 ≡ E, and consequently, |E2 − E1| << J1,1, J2,2, J1,2,
K1,2. For simplicity we shall additionally assume that the different Coulomb integrals
are identical in the degenerate manifold, namely J1,1 = J2,2 = J1,2 ≡ J. In this case (see
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press235 Bibliography
Ftigure 13.4.3 A schematic representation of the single determinant as well as proper uncorrelated products of spin and orbital
functions, for two degenerate orbitals. The different states are sorted according to the two-electron energy,
demonstrating Hund’s rule, where the triplet state corresponds to the lowest two-electron energy. (Slater
determinants that artificially correlate spin and orbitals are marked in gray.)
Fig. 13.4.3) the lowest two-electron energy is associated with the triplet spin states,
where the two electrons are associated with the same spin, and therefore with a sta￾bilizing exchange interaction. Also in this case, a similar consideration applies to the
many-electron atoms and leads to Hund’s rule: in a many-electron atom where several
electrons occupy several degenerate orbitals at a given single-particle energy, the ground
state corresponds to a maximal number of unpaired electrons occupying the degenerate
orbitals, with the same electronic spin. Considering, for example, the configuration of
carbon in its ground state (see Fig. (13.3.5)), two electrons occupy two of the three
degenerate carbon orbitals associated with n = 2,l = 1. In the space of these two spatial
orbitals, the ground state corresponds to the triplet state (as in Fig. 13.4.3).
Bibliography
[13.1] P. Zeeman, “The Effect of Magnetisation on the Nature of Light Emitted by a
Substance”, Nature 55, 347 (1897).
[13.2] W. Gerlach and O. Stem, “Der experimentelle Nachweis der Richtungsquan￾telung im Magnetfeld,” Zeitschrift für Physik 9, 349 (1922).
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press236 Bibliography
[13.3] B. Thaller, “The Dirac Equation” (Springer Science Berlin Heidelberg, 1992).
[13.4] J. D. Jackson, “Classical Electrodynamics,” 3rd ed. (Wiley, 1999).
[13.5] J. C. Slater, “The theory of complex spectra,” Phys. Rev. 34, 1293 (1929).
[13.6] V. Fock, “Naherungsmethode zur Losung des quantenmechanischen Mehrko￾rperproblems,” Zeitschrift für Physik 61, 126 (1930).
[13.7] A. Szabo and N. S. Ostlund, “Modern Quantum Chemistry: Introduction to
Advanced Electronic Structure Theory” (Dover, 1996).
[13.8] R. Latter, “Atomic energy levels for the Thomas-Fermi and Thomas-Fermi￾Dirac potential,” Physical Review 99, 510 (1955).
[13.9] R. G. Parr and W. Yang, “Density Functional Theory of Atoms and
Molecules” (Oxford University Press, 1989).
[13.10] R. J. Bartlett and M. Musiał, “Coupled-cluster theory in quantum chemistry,”
Reviews of Modern Physics 79, 291 (2007).
[13.11] R. Pauncz, “Spin Eigenfunctions: Construction and Use” (Springer, 1979).
https://doi.org/10.1017/9781108877787.014 Published online by Cambridge University Press14 Many-Atom Systems
14.1 The “Chemical Space
“
andMany-Atom Systems
The most relevant systems in nanoscale science extend beyond the realm of isolated
atoms. The interaction between atoms and the possibility to form chemical bonds
give rise to a variety of chemical compounds, ranging from metals to nonmetals, from
molecular materials to crystals and to periodic lattices. The so-called “chemical space”
of possible combinations of small organic molecules was estimated to exceed an astro￾nomic number of 1060 [14.1]. Remarkably, the versatility of the different “allowed”
forms of stable compounds can be fairly understood within the postulates and con￾cepts of quantum mechanics. Moreover, macroscopic properties of different materials,
such as chemical and mechanical stability, electric conductivity, observed color, and
more, are directly related to the interaction between the atoms on the nanoscale, which
is well described by quantum mechanics.
In this chapter we invoke a “bottom-up” approach for extending the treatment of
many-electron atoms into many-atom systems. Based on their electronic structure,
detailed quantitative information can be obtained about the properties of different
materials, using elaborate atomistic-level electronic structure calculations. Our focus
here will be on a qualitative description of quantum mechanical concepts and princi￾ples. First, we shall introduce concepts that explain the formation of a “chemical bond”
between two atoms. These concepts will then be invoked for understanding the prin￾ciples underlying the structure and the properties of extended many-atomic systems
(solid lattices). In Chapter 13 we saw that the properties of many-electron systems have
remarkable consequences when several electrons are bound to a nucleus within a sin￾gle atom. In particular, Pauli’s exclusion “forces” electrons to populate single-particle
states of increasing single-particle energy, such that high-energy electrons are partially
“shielded” from the bare nucleus. As it turns out, when atoms are brought to proxim￾ity, the external electrons of one atom are attracted to the atomic cores of other atoms,
which tends to “spontaneously” delocalize the electron over several atoms. In other
words, the stationary solutions of the Schrödinger equation become delocalized (this
phenomenon is reminiscent of the spatial delocalization observed in quantum wells in
Sections 6.4 and 6.5). Just how much these electrons tend to delocalize, or be shared
among different atoms, differs from one element to another, and from one chemi￾cal compound to another. However, the same principles that determine the electronic
configuration of a single atom are applicable also to groups of atoms coupled to each
237
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press238 Many-Atom Systems
other, as happens in molecules or in extended atomic lattices. In particular, the orbital
approximation can be extended to account for single-particle functions (orbitals) that
are delocalized among different atoms. These orbitals are filled by paired electrons of
different spins, typically from low to high orbital energy, up to some highest occupied
orbitals. Just as the properties of a single atom are determined to a large extent by
the electrons’ occupancy at the external energy shell, the properties of more-complex
materials, such as molecules or lattices, can be correlated with the properties of the
highest occupied (or lowest unoccupied) orbitals (sometimes referred to as the frontier
orbitals).
As a concrete example, consider the property of electrical conductivity, which turns
out to be dramatically different between metals and ionic lattices. Why does a metallic
lattice (e.g., Na) conduct electric current, whereas an ionic compound of the same metal
(e.g., NaCl) insulates? Macroscopic conductivity depends on the mobility of charge
carriers, namely their ability to accelerate (gain kinetic energy) in response to an electric
potential bias. As discussed in the following sections, this ability depends on the elec￾tronic configuration within the many-atom material. Materials that conduct are those
in which the energy gap between the highest occupied orbitals and the lowest unoccu￾pied orbitals is small (in comparison to the available thermal energy) or nonexisting (as
the in the case of a partially filled energy band). Therefore, electrons in these materi￾als can accelerate in response to any potential bias. In contrast, materials in which the
energy gap to an unoccupied orbital exceeds by far the thermal energy will be insulating
and will start conducting only at some finite bias or at increasing temperatures.
14.2 The Born–Oppenheimer Approximation
We start from the definition of a many-atom system as a system composed of n
nuclei and N electrons. The nuclei are denoted by α = 1,2,...,n, where each nucleus
has an electric charge, Zα|e|(Za is the atomic number of the element, namely the
number of protons in the nucleus), and a mass, mα (the sum of proton and neu￾tron masses). Denoting the position vector of the ith electron and the αth nucleus
in a three-dimensional Cartesian coordinate reference system as ri = (xi
, yi
,zi) and
Rα = (xα, yα,zα), respectively, the quantum Hamiltonian of a general many-atom
system in the position representation is given by Eq. (3.4.11) (see also Fig. 3.4.2).
The complexity of solving the Schrödinger equation with this many-body Hamil￾tonian can be reduced by noticing that the mass of a typical nucleus is three to five
orders of magnitude larger than the mass of an electron. Using classical mechanics
terms, since the forces between the particles are electrostatic and do not depend on
the particle masses, the lighter electrons are expected to move much faster than the
heavier nuclei, in response to their mutual interaction. Consequently, a timescale sep￾aration argument is expected to hold in this case. Namely, on the relevant timescale for
electronic dynamics, the forces on the electrons owing to the presence of the nuclei can
be approximated as emerging from static nuclei at some fixed positions. On the relevant
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press239 14.2 The Born–Oppenheimer Approximation
timescale for nuclear dynamics, the forces on the nuclei can be approximated as emerg￾ing from a static field, attributed to the averaged position of the electrons in the system.
In quantum mechanical terms, “fast” and “slow” dynamics correspond, respectively,
to “large” and “small” energy gaps between energy eigenvalues of the underlying Ham￾iltonian (see Chapter 15). Analogy with classical mechanics suggests that the spectrum
of the Hamiltonian should involve densely packed eigenstates that differ mostly by the
state of the nuclei, whereas eigenstates that differ significantly in the state of the elec￾trons will be farther apart in energy. While not always correct (see the discussion at
the end of this section), these time and energy scale separation arguments suggest that
when solving the full Schrödinger equation, the electrons and nuclei could be treated
differently. This is the essence of the adiabatic treatment of the electronic structure of
many-atom systems, attributed to Born and Oppenheimer [14.2].
Let us start by collecting all the electronic and nuclear coordinates into two respec￾tive “super vectors,” defined as
r ≡ (r1, r2,..., rN)
R ≡ (R1,R2,...,Rn)
. (14.2.1)
We would have liked to be able to solve the full stationary Schrödinger equation for
the system. Invoking the position representation this equation reads
HˆR,rΨ(R, r) = EΨ(R, r). (14.2.2)
The full (nonrelativistic) Hamiltonian for a many-atom system (see Eq. (3.4.11)) can
be written in a compact form,
HˆR,r = TˆR +Tˆ
r +VˆR +VˆR,r +Vˆ
r, (14.2.3)
where
TˆR =
n
∑
α=1
−h¯
2
2mα
∇Rα
·∇Rα
Tˆ
r =
N
∑
i=1
−h¯
2
2me
∆ri
VˆR =
n
∑
β>α
n
∑
α=1
Ke2ZαZβ
|Rα −Rβ
|
Vˆ
r =
N
∑
j>i
N
∑
i=1
Ke
2
|ri −rj
|
VˆR,r = −
n
∑
α=1
N
∑
i=1
KZαe
2
|Rα −ri
|
.
(14.2.4)
TˆR and Tˆ
r, are the kinetic energy operators, corresponding, respectively, to the nuclei
and the electrons.VˆR andVˆ
r are the electrostatic repulsion terms corresponding, respec￾tively, to all nucleus pairs and all electron pairs, and VˆR,r is the potential energy of
electrostatic attraction between all electrons and nuclei.
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press240 Many-Atom Systems
The first step in the Born–Oppenheimer (BO) treatment of this equation is to define
the “electronic Hamiltonian,”
Hˆ
elec(R) = HˆR,r −TˆR, (14.2.5)
in which the kinetic energy of the nuclei is subtracted from the full Hamiltonian. The
electronic Hamiltonian can be regarded as a differential operator in the space of the
electron coordinates, which depends on the nuclei positions, R, only parametrically.
(Notice that the term VˆR, which corresponds to the interaction between the nuclei, is
conventionally included within the electronic Hamiltonian, although in the electronic
space, it corresponds to an identity operator multiplied by a function of R.) The elec￾tronic Hamiltonian can be rightly viewed as a straightforward generalization of an
atomic Hamiltonian, where there are many electrons, and instead of a single nucleus,
the system contains several (or many) nuclei, distributed in coordinate space at some
fixed geometry, defined by the parameter R.
The electronic Hamiltonian is a Hermitian operator in the electronic coordinate
space, for any given positions of the nuclei, R. Therefore, the eigenstates of this opera￾tor span the space of the electronic physical states (see Section 11.4). Considering the
R-dependent eigenvalue equation (conventionally termed, “the electronic Schrödinger
equation”),
Hˆ
elec(R)ϕl(R, r) = εl(R)ϕl(R, r), (14.2.6)
there exists a set {ϕl(R, r)} of orthonormal functions with respect to integration over
the multidimensional electronic space (termed “the electronic functions”), where for
any R,
w
ϕ
∗
l
(R, r)ϕl
0(R, r)dr = δl,l
0. (14.2.7)
Any proper function of r can be therefore expanded as a linear combination of
{ϕl(R, r)}. Since this holds for any R, it follows that any proper function of both R and
r can be expanded using the sets {ϕl(R, r)} with appropriate expansion coefficients. In
particular, this holds for the exact eigenstates of the full Hamiltonian, HˆR,r, namely,
for the exact solutions to the Schrödinger equation, Eq.(14.2.2), which can therefore
be expanded as (the “BO expansion”)
Ψ(R, r) = ∑
l
χl(R)ϕl(R, r). (14.2.8)
The linear expansion coefficients are a vector of functions (χ1(R),χ2(R),...) in the
nuclear coordinate space, conventionally termed “the nuclear functions.” The exact
solution is formally expressed as an infinite (truncated, in practice) sum of products of
“electronic functions” and “nuclear functions.”
An exact solution to the full Schrödinger equation can therefore, in principle, be
obtained in two steps. In the first step, complete orthogonal sets of electronic functions,
{ϕl(R, r)}, should be calculated for each and every (relevant) nuclei positions vector,
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press241 14.2 The Born–Oppenheimer Approximation
R. In the subsequent step, the expansion coefficients, {χl(R)}, should be obtained for
each solution, Ψ(R, r). An equation for the proper expansion coefficients is obtained by
substitution of the expansion, Eq. (14.2.2), in the Schrödinger equation, Eq. (14.2.2),
with the full Hamiltonian, HˆR,r = Hˆ
elec(R) +TˆR:

Hˆ
elec(R) +TˆR

∑
l
χl(R)ϕl(R, r) = E∑
l
χl(R)ϕl(R, r). (14.2.9)
Projecting the equation on every specific electronic wave function, ϕm(R, r), by inte￾grating over the electronic coordinate space, using Eqs. (14.2.6, 14.2.7), we obtain the
following coupled linear equations for the components of the vector, {χm(R)},
∑
l

HˆR

m,l
χl(R) = Eχm(R). (14.2.10)
[HˆR]m,l
is an operator in the nuclear coordinate space, obtained by integrating over the
electronic coordinates,

HˆR

m,l ≡
w
drϕ
∗
m(R, r)

Hˆ
elec(R) +TˆR

ϕl(R, r) = εm(R)δm,l +

TˆR

m,l
, (14.2.11)
where we used the fact that the set {ϕl(R, r)} is an orthonormal set of eigenstates of
the electronic Hamiltonian (Eqs. (14.2.6, 14.2.7), see Ex. 14.2.1).
Exercise 14.2.1 Obtain Eqs. (4.2.10, 4.2.11) from Eq. (4.2.9) by multiplying from the
left by ϕ
∗
m(R, r) and integrating over the electronic coordinates. Use the fact that the elec￾tronic functions, {ϕl(R, r)}, are the orthonormal (Eq. (14.2.7)) eigenfunctions of the
electronic Hamiltonian (Eq. (14.2.6)).
A closer look into the matrix representation of the nuclear kinetic energy operator in
the basis of the electronic wave functions, denoted as[TˆR]m,l
, is essential for defining the
BO approximation. First, for simplicity of notation, we define mass-scaled coordinates
for each nucleus, R˜
α =
q2mα
h¯
2 Rα, and an extended gradient vector in the entire nuclear
coordinate space,
∇R˜ ≡

∂
∂ x˜1
,
∂
∂ y˜1
,
∂
∂ z˜1
,...,
∂
∂ x˜α
,
∂
∂ y˜α
,
∂
∂ z˜α
,...,
∂
∂ x˜n
,
∂
∂ y˜n
,
∂
∂ z˜n
t
,
such that the nuclear kinetic energy (see Eq. (14.2.4)) obtains the form
TˆR =
n
∑
α=1
−h¯
2
2mα
∇Rα
·∇Rα ≡ −∇R˜ ·∇R˜ . (14.2.12)
The matrix elements of the kinetic energy in the basis of electronic functions therefore
reads (see Ex. 14.2.2)
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press242 Many-Atom Systems
[TˆR]m,l = −
w
drϕ
∗
m(R, r)∇R˜ ·∇R˜ ϕl(R, r)
= δm,lTˆR −2
w
drϕ
∗
m(R, r)∇R˜ ϕl(R, r)

·∇R˜ −
w
drϕ
∗
m(R, r)∇R˜ ·∇R˜ ϕl(R, r)

(14.2.13)
≡ δm,lTˆR −2hϕm(R)|∇R˜ ϕ(R)i·∇R˜ − hϕm(R)|∇R˜ ·∇R˜ ϕl(R)i,
where in the last step we introduced Dirac’s notations for the states in the electronic
coordinate space, which depend parametrically on R. Using Eq. (14.2.13) for [TˆR]m,l
,
we rewrite Eqs. (14.2.10, 14.2.11) as
∑
l
h
Hˆ
(0)
R +Hˆ
(1)
R
i
m,l
χl(R) = Eχm(R), (14.2.14)
where
h
Hˆ
(0)
R
i
m,l
= δm,l

εm(R) +TˆR

, (14.2.15)
and
h
Hˆ
(1)
R
i
m,l
= −2hϕm(R)|∇R˜ ϕl(R)i·∇R˜ − hϕm(R)|∇R˜ ·∇R˜ ϕl(R)i. (14.2.16)
The “zero-order” Hamiltonian, Hˆ
(0)
R
, is purely diagonal in the electronic state repre￾sentation, where Hˆ
(1)
R
is non-diagonal (see Fig. 14.2.1).
Exercise 14.2.2 (a) Use the definition of the gradient operator, ∇Rα ≡

∂
∂ xα
,
∂
∂ yα
,
∂
∂ zα
t
,
to show that ∇Rα
· ∇Rα
[ϕl(R, r)χl(R)] = 2[∇Rα
ϕl(R, r)] · ∇Rα χl(R) + ϕl(R, r)∇Rα
·
∇Rα χl(R) +[∇Rα
·∇Rα
ϕl(R, r)]χl(R).
(b) Use the definition of the nuclear kinetic energy operator in Eq. (14.2.4), the result
of (a), and the orthonormality of the electronic functions (Eq. (14.2.7)) to show
that

TˆR

m,l
χl(R) =
n
∑
α=1
−h¯
2
mα
hw
drϕ
∗
m(R, r)∇Rα
ϕl(R, r)
i
·∇Rα χl(R)
+
n
∑
α=1
−h¯
2
2mα
hw
drϕ
∗
m(R, r)∇Rα
·∇Rα
ϕl(R, r)
i
χl(R)
+δm,l
n
∑
α=1
−h¯
2
2mα
∇Rα
·∇Rα χl(R).
(c) Use the result of (b) and the definition of ∇R˜ to obtain Eq. (14.2.13).
While exact, Eqs. (14.2.14–14.2.16) are not particularly useful. Firstly, their imple￾mentation requires preknowledge of all the electronic functions {ϕm(R, r)} (an infinite
set of multidimensional functions, in principle), and secondly, due to the non-diagonal
terms, the nuclear functions associated with different electronic functions are all cou￾pled to each other, such that a solution to the Schrödinger equation (Eq. (14.2.9)),
means a simultaneous calculation of the entire set, {χm(R)}.
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press243 14.2 The Born–Oppenheimer Approximation
Ftigure 14.2.1 The matrix representation of the full Hamiltonian in the basis of the electronic functions (see Eq.14.2.11). The “partial”
integration (over the electronic space) associates each matrix element, 
HˆR

m,l =
h
Hˆ
(0)
R
i
m,l
+
h
Hˆ
(1)
R
i
m,l
, with
an operator in the nuclear coordinate space.
A remarkable simplification is obtained by invoking the BO approximation (or the
“adiabatic approximation”), assuming that Hˆ
(1)
R
can be neglected next to Hˆ
(0)
R
. Namely,
matrix elements involving first and second derivatives of the electronic functions,
{ϕm(R, r)}, with respect to the nuclear coordinates {R} are assumed to be null:
w
drϕ
∗
m(R, r)TˆRϕl(R, r)χl(R) ≈ δm,lTˆRχl(R). (14.2.17)
In fact, it is sufficient to assume that the vector of nonadiabatic couplings,
hϕm(R)|∇R˜ ϕl(R)i, vanishes for any m and l (see Ex. 14.2.3). Setting h
Hˆ
(1)
R
i
m,l
= 0,
Eq. (14.2.14) is replaced by
∑
l
h
Hˆ
(0)
R
i
m,l
χl(R) = Eχm(R). (14.2.18)
Since Hˆ
(0)
R
is diagonal (see Eq. (14.2.15) and Fig. 14.2.1), the equations for different
electronic states become decoupled, where a “nuclear equation” is obtained for each
m, independently of all the other electronic states:

TˆR +εm(R)

χm(R) = Eχm(R). (14.2.19)
The result is cast in a form of an effective stationary Schrödinger equation for χm(R),
where the role of the effective potential energy in the coordinate space of the nuclei is
played by the corresponding eigenvalue of the electronic Hamiltonian (Eq. (14.2.6)),
εm(R). Each such equation has multiple solutions, which we denote here by an addi￾tional index, “k.” Therefore, each eigenstate of Hˆ
(0)
R
(as defined by Eq. (14.2.18))
is associated with two indexes: Em,k
, where m accounts for the electronic function,
ϕm(R, r), and the combination (m, k) specifies a nuclear function, χ
(m,k)
m (R). The latter
is an eigenstate of Eq. (14.2.19), which corresponds to the energy Em,k
,

TˆR +εm(R)−Em,k

χ
(m,k)
m (R) = 0. (14.2.20)
The block-diagonal form of Hˆ
(0)
R
(Eq. (14.2.18)), means that its eigenvector, which
corresponds to the eigenvalue, Em,k
, can be chosen as
χ
(m,k)
l
(R) = δm,lχ
(m,k)
m (R). (14.2.21)
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press244 Many-Atom Systems
(This form is obligatory, in fact, if the spectrum of Hˆ
(0)
R
is nondegenerate.) Conse￾quently, the exact BO expansion, Eq. (14.2.8), of the solution to the full Schrödinger
equation (Eq. (14.2.2)) is approximated by a single product,
Ψ(R, r) ∼= Ψm,k(R, r) = ϕm(R, r)χ
(m,k)
m (R), (14.2.22)
which corresponds to the approximated eigenvalue,
E ∼= Em,k
. (14.2.23)
Eq. (14.2.22) is conventionally referred to as the “Born–Oppenheimer Ansatz” for the
solution of the Schrödinger equation for the many-atom system.
In summary, the BO approximation associates each energy level of the many￾atom system, Em,k
, with a product state, Ψm,k(R, r) = ϕm(R, r)χ
(m,k)
m (R). The index m
accounts for an electronic function, ϕm(R, r), which is one of the eigenfunctions of
the electronic Hamiltonian (Eq. (14.2.6)). The combination of indexes (m, k) accounts
for a nuclear function, χ
(m,k)
m (R), which is one of the eigenfunctions of the nuclear
Schrödinger equation, Eq. (14.2.20), in which the electronic energy, εm(R) plays the
role of a potential energy in the nuclear coordinate space. A consecutive solution of
the electronic and nuclear equations thus provides approximations for the stationary
states of the Shroedinger equation for the entire system.
The emerging physical picture is that the states of the nuclei are dictated by the states
of the electrons, where each electronic state defines a different potential energy “land￾scape” for the nuclei. In general, the number of nuclear degrees of freedom can be very
large (3n for an n-atom system), and the potential energy landscape is a function of a
multidimensional vector R. Each electronic state index, m, therefore defines a multidi￾mensional “adiabatic Potential Energy Surface” (PES), εm(R). Derivatives of the PES
with respect to the nuclear coordinates define the forces on the nuclei, where the min￾ima in the PES correspond to stable nuclear geometries and the maxima correspond
to unstable geometries (transition states between stable nuclear configurations).
An illustrative example is given for the case of two atoms (n = 2) in Fig. 14.2.2.
Notice that the electronic Hamiltonian (Eq. (14.2.5)) is invariant in this case to trans￾lation of the diatomic center of mass (three degrees of freedom) and to rotations in the
center-of-mass frame (two degrees of freedom). Therefore, out of six nuclear degrees of
freedom, only one, corresponding to the interatomic distance R, affects the electronic
energy. Each adiabatic PES is therefore a potential energy curve in this case, εm(R).
The lower energy curve in Fig. 14.2.2 corresponds to a typical electronic ground state
of a diatomic molecule, ε0(R), as discussed in Chapters 8 and 9 (see Fig. 8.4.1), in the
context of molecular vibrations. There, we assumed the existence of a potential energy
function, V(R), which obtains an asymptotic constant value at large interatomic dis￾tances, increases in the opposite limit, where the interatomic distance gets shorter, and
in between, obtains a minimum at some finite interatomic distance. Within the BO
approximation, this potential energy curve is identified with the dependence of the
electronic ground state energy on the interatomic distance, V(R) = ε0(R). In the next
section we shall discuss this curve quantitatively. However, we have already acquired
tools to understand it qualitatively. At large interatomic distances the electrons will
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press245 14.2 The Born–Oppenheimer Approximation
E
R
ε2 (R )
ε1 (R )
ε0 (R )
Ftigure 14.2.2 A schematic representation of electronic energies for a diatomic system. Each electronic energy is an adiabatic
potential energy curve for the nuclei, as a function of the interatomic distance. When the potential energy curve has a
minimum at the electronic ground state, the two atoms can form a stable molecule.
be exposed primarily to one of the nuclei or the other, such that their energy will
depend only weakly on the internuclear distance. In contrast, as the internuclear dis￾tance approaches zero, the electronic energy must increase, not only because of the
internuclear repulsion (recall that the latter is conventionally counted as a part of the
electronic energy), but primarily since attempting to “fuse” the electrons from two
atoms into one “united atom” necessitates the occupation of orbitals associated with
higher single-particle energies, according to the Aufbau principle, as a consequence of
Pauli’s exclusion principle (see Chapter 13). The existence of a minimum of ε0(R) at
some finite inter-atomic distance is not “universal.” In fact, it depends on the identity
of the two atoms, which determine whether the diatomic molecule is a stable entity
or not. Only when such a minimum exists can a stable “chemically bonded” diatomic
molecule be identified. The factors that govern the shape of the potential energy curve
at the electronic ground state or different diatomic molecules, and therefore determine
their stability with respect to decomposition into isolated atoms, will be analyzed in
the next section. Importantly, even when the electronic ground state energy has a min￾imum at some nuclear configuration, R0, corresponding to a stable molecule, higher
potential energy curves, corresponding to excited electronic states, may not have a min￾imum, as illustrated in Fig. 14.2.2. When the electrons are excited to such a repulsive
potential energy curve, the internuclear force, −dεm(R)/dR, is always in the direction
of increasing R, resulting in bond cleavage, or molecular dissociation. Such electronic
excitations are associated, for example, with collisions with other particles or with an
interaction with electromagnetic radiation (see Section 18.3). It is emphasized that the
principles described here are not limited to diatomic molecules. They often apply to
chemical bonds in many-atom systems as well. Examples are photochemical reactions,
induced by UV radiation [14.3] or by electronscattering (e.g., damages to molecular
DNA following collisions with low-energy electrons [14.4]).
Breakdown of the Born--Oppenheimer Approximation
Within the BO approximation, the electronic state of the system determines the poten￾tial energy and therefore the forces experienced by the nuclei. The effect of the nuclei
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press246 Many-Atom Systems
on the electrons is restricted to the parametric dependence of the electronic energy on
the nuclear configuration in space. Therefore, changes in the nuclear geometry cannot
induce transitions between different electronic states (“nonadiabatic” transitions), and
the electronic quantum numbers are “adiabatically” conserved. An exact treatment
should account also for the effect of the nuclear kinetic energy (the nuclear position
uncertainty in the stationary states, or, otherwise, the nuclear “motion”) on the elec￾tronic state, which should correspond to superpositions of the different eigenstates
of the electronic equation, {ϕm(R, r)}. Formally, the coupling between these states is
an immediate consequence of the non-diagonal operator, Hˆ
(1)
R
, in Eq. (14.2.14), which
was neglected in the BO approximation. The neglected terms (see Eq. (14.2.16)) depend
(directly, or indirectly; see Ex. 14.2.3) on the magnitude of the nonadiabatic coupling
vectors, which corresponds to the derivatives of the electronic wave functions with
respect to the different nuclear coordinates,
Dm,l(R) ≡ hϕm(R)|∇R˜ ϕl(R)i. (14.2.24)
Exercise 14.2.3 The nonadiabatic terms in the nuclear Hamiltonian are given by
h
Hˆ
(1)
R
i
m,l
in Eq. (14.2.16). Follow (a–d) to show that a sufficient condition for the van￾ishing of h
Hˆ
(1)
R
i
m,l
is the vanishing of the nonadiabatic coupling vector, Di, j(R) =
hϕi(R)|∇R˜ ϕ j(R)i, for any i and j.
(a) Show that hϕm(R)|∇R˜ ·∇R˜ ϕl(R)i = [∇R˜ ·Dm,l(R)]− h∇R˜ ϕm(R)|·|∇R˜ ϕl(R)i.
(b) For any R, introduce a complete orthonormal system of electronic functions and
show that
h∇R˜ ϕm(R)|·|∇R˜ ϕl(R)i = ∑
k
h∇R˜ ϕm(R)|ϕk(R)i·Dk,l(R).
(c) Use Eq. (14.2.7) to prove that h∇R˜ ϕm(R)|ϕk(R)i = −Dm,k(R).
(d) Show that h
Hˆ
(1)
R
i
m,l
= −2Dm,l(R)·∇R˜ −[∇R˜ ·Dm,l(R)]−∑
k
Dm,k(R)·Dk,l(R).
Recalling the definition of ∇R˜ (see Eq. (14.2.12)), the derivative couplings should
decrease as the nuclear masses increase, namely Dm,l(R) ∝ {1/
√
mα }. One might have
expected that the large mass ratio between the nuclei and the electrons would be suf￾ficient for justifying the neglection of the derivative coupling [14.2], but this is not
the case. One can see (Ex. 14.2.4) that the off-diagonal derivative couplings can be
expressed as
Dm,l(R) = hϕm(R)|(∇R˜ Hˆ
elec(R))|ϕl(R)i
εl(R)−εm(R)
; l 6= m. (14.2.25)
The numerator contains the matrix element of the vector operator, ∇R˜ Hˆ
elec(R), which
is proportional to the forces on the nuclear degrees of freedom due to the electron–
nucleus and nucleus–nucleus interactions. These matrix elements are finite (except for
pathological cases). The denominator is the difference between the two adiabatic PES,
corresponding to the m and l electronic states. Therefore, the derivative coupling,
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press247 14.2 The Born–Oppenheimer Approximation
Dm,l(R), diverges whenever the two PES cross each other; namely, when εl(R) → εm(R),
and consequently the BO approximation is no longer valid.
Exercise 14.2.4 Derive Eq. (14.2.25) by calculating ∇R˜hϕm(R)|Hˆ
elec(R)|ϕl(R)i, using
the properties of the electronic functions, Eqs. (14.2.6, 14.2.7).
The Non-Crossing Rule and Conical Intersections
It is important to zoom into the properties of the electronic Hamiltonian as two
electronic energies (or two adiabatic PES) come close together. As the energy gap
between two PES becomes much smaller than the gaps between them to any other
PES, one can attempt to approximate the exact electronic Hamiltonian in a reduced
electronic Hilbert space, spanned by two orthonormal basis states (e.g., ϕl(R0, r) and
ϕm(R0, r) at some R0 for which the respective PES are close). When this approximation
holds, the electronic Hamiltonian is mapped on a two-level system model (see Sec￾tion 12.2), with the matrix elements, Hl,m(R) = hϕl(R0)|Hˆ
elec(R)|ϕm(R0)i. The energy
gap between the electronic energies, namely the eigenvalues of this matrix, reads (see
Eqs. (12.2.3–12.2.6)) |εl(R) − εm(R)| =
p
(Hl,l(R)−Hm,m(R))2 +4|Hl,m(R)|
2
. A strict
crossing, namely |εl(R)−εm(R)| = 0, means that two independent conditions should
hold at the same point, R : Hl,l(R)−Hm,m(R) = 0 and |Hl,m(R)| = 0. Two cases should
be distinguished. In the first case, Hl,m(R) vanishes identically, irrespective of R. This
happens when ϕl(R, r) and ϕm(R, r) are nondegenerate eigenfunctions of a symmetry
operator that commutes with Hˆ
elec(R). In this case surface crossing requires fulfilment
of a single equation, Hl,l(R) − Hm,m(R) = 0, which can be met by a proper choice of
a single parameter. Consequently, given an f-dimensional PES, only f − 1 nuclear
degrees of freedom can be chosen freely while meeting the condition for crossing
another PES; namely, the crossing is limited to a surface of dimension f − 1. In the
second case, ϕl(R, r) and ϕm(R, r) are degenerate with respect to all the symmetry oper￾ators. Therefore, Hl,m(R) is not guaranteed to vanish, and the fulfilment of the two
independent conditions, Hl,l(R) − Hm,m(R) = 0 and |Hl,m(R)| = 0, requires a proper
choice of two independent parameters. Consequently, only f − 2 nuclear positions
can be chosen freely to meet the crossing condition; namely, the crossing of two f￾dimensional PES, is limited to a surface of dimension f − 2 in this case. Considering
the example of a diatom (n = 2), illustrated in Fig. 14.2.2, the electronic Hamiltonian is
invariant to translation of the center of mass, and to rotation about the line connecting
the two centers of the atoms, and therefore the PES depends on a single nuclear coor￾dinate, namely the interatomic distance. Since f = 1 in this case, different potential
energy curves (one-dimensional surfaces) corresponding to different rotational quan￾tum numbers (with respect to rotation around the molecular axis) can cross only at a
single point (a zero-dimensional space corresponding to f −1 = 0). Remarkably, when
the two curves correspond to the same rotational quantum number, two independent
parameters are needed to assure crossing; and for f = 1, one has f − 2 < 0, which
means that crossing cannot occur. This result is known as the “non-crossing rule” due
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press248 Many-Atom Systems
to von Neumann and Wigner [14.5]. Extending the same argument for polyatomic sys￾tems, two PES associated with the same symmetry eigenstates can only cross at a single
point when f = 2 (or, f −2 = 0, which corresponds to “a conical intersection” [14.6]),
or along a line, when f = 3 (or, f −2 = 1), and so forth. Overall, intersections between
two (or more) different PES become ubiquitous as the number of atoms in the system
increases. Notice that although the crossing dimensions are always smaller than the
dimensions of the full nuclear coordinate space (f), and the probability for finding the
nuclei strictly at crossing points is therefore of zero measure in the nuclear coordinate
space, the nonadiabatic coupling vector (Dm,l(R), Eq. (14.2.25)) can obtain arbitrarily
large values also at the vicinity of the crossing points. Therefore, the BO approximation
is valid only when the relevant electronic energies (or the nuclear PES) are sufficiently
far in energy from each other, at the relevant nuclear positions, namely at nuclear posi￾tions associated with a substantial probability density. This situation is not always met
in practice.
From the point of view of perturbation theory, the BO approximation should hold
strictly only when the following condition is met (see Eq. (12.1.29)):
|
w
dRχ
∗
m,k
(R)
h
Hˆ
(1)
R
i
m,l
χl,k
0(R)| << |Em,k −El,k
0|, (14.2.26)
where Em,k =
r
dRχ
∗
m,k
(R)
h
Hˆ
(0)
R
i
m,m
χm,k(R). Namely, the matrix elements of Hˆ
(1)
R
need
to be negligible in comparison to the difference between the energy levels associated
with Hˆ
(0)
R
(see the related discussion in Section 12.1). While the condition, Eq. (14.2.26),
is not so transparent, it is still clear that the right-hand side increases as the energy
difference between the nuclear PES, εl(R) and εm(R), increases, which is in agreement
with the conclusion derived from Eq. (14.2.25). As we shall see in Chapter 15, “larger”
energy gaps between stationary solutions of the Schrödinger equation are translated
to “faster” dynamics in the system (higher underlying frequencies). We may therefore
argue that the validity of the BO approximation relies on the electrons being much
faster than the nuclei. A quantitative analysis of this argument is found, for example,
in the Landau–Zenner model for nonadiabatic transitions [14.7].
14.3 Covalent Bonds: the Hydrogen Molecular Ion, H
+
2
Perhaps the most interesting phenomenon associated with many-atom systems is the
spontaneous tendency of atoms to form chemical bonds, namely, stable geometrical
arrangements in which the distances between neighboring atoms are of the order of
atomic radii. Chemical bonds range from molecules to solid crystals and metals. We
start by considering the simplest example for chemical bonding, which is the formation
of the hydrogen molecular ion, composed of two atomic hydrogen nuclei (two protons)
and a single electron. Being a single-electron system, the discussion of many-electron
aspects can be avoided, and the concept of orbital (single-electron wave functions)
becomes exact. As we shall see, however, the concepts derived for this single-electron
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press249 14.3 Covalent Bonds: the Hydrogen Molecular Ion, H
+
2
system are most useful when discussing the general case of many-electron molecules,
which we postpone to the next section. This is similar to the role played by atomic
orbitals of a hydrogen-like atom, in analyzing many-electron atoms within the orbital
approximation.
Following the Born–Oppenheimer framework (see Section 14.2), we first freeze the
position of the nuclei in space and attempt to solve the stationary Schrödinger equation
for the electronic Hamiltonian. Setting the number of nuclei to n = 2, with Zα = Zβ = 1,
and the number of electrons to N = 1, the electronic Hamiltonian (Eqs. (14.2.3–14.2.5))
reads in this case
Hˆ
elec(Rα,Rβ
) = −h¯
2
2me
∆r +
Ke
2
|Rα −Rβ
|
−
Ke2
|Rα −r|
−
Ke2
|Rβ −r|
. (14.3.1)
Denoting the fixed distance between the two nuclei as |Rα −Rβ
| ≡ R, it is most conven￾ient to set the origin of the frame of reference at the center of mass and to position the
two nuclei along the z-axis, where Rα = (0,0,−R/2) = −R
2
k, and Rβ = (0,0,R/2) = R
2
k.
Within these definitions one can readily see that the electronic Hamiltonian depends
only on a single nuclear parameter, which is the internuclear distance, R (see Fig.
14.3.1):
Hˆ
elec(R) = −h¯
2
2me
∆r +
Ke
2
R
−
Ke
2
|r+kR/2|
−
Ke
2
|r−kR/2|
. (14.3.2)
The cylindrical symmetry of the diatomic molecule is reflected in the independence of
its electronic Hamiltonian on the angle φ, which means that
[Hˆ
elec(R),Lˆ
z
] = 0, (14.3.3)
where Lˆ
z = −ih¯
∂
∂φ
is the corresponding angular momentum operator. Additionally, the
identity of the two nuclei means that the Hamiltonian commutes with the inversion
operator,
e
Z
r − Rα
Rβ = (0,0,R / 2)
ϕ
Rα = (0,0,−R / 2)
r − Rβ
Ftigure 14.3.1 The coordinate system for the electronic Hamiltonian in the hydrogen molecular ion.
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press250 Many-Atom Systems
[Hˆ
elec(R),Pˆ
x,y,z
] = 0, (14.3.4)
where Pˆ
x,y,z
f(x, y,z) = f(−x,−y,−z).
We are interested in the ground state of the electronic Hamiltonian. Rather than
following analytic solutions to the electronic Schrödinger equation for H
+
2
, as a specific
case of a “two-center problem” [14.8], we follow a generic approach, readily extendable
to more-complex molecules. The approach is based on the method of linear variation
(see Section 12.3), where the wave functions are approximated as linear combinations
of known basis functions, and the coefficients are variationally optimized. A natural
choice is to expand the single-electron wave functions of the many-atom system in a
basis of atomic orbitals of the single (isolated) atoms. This approach is therefore termed
Molecular Orbitals as Linear Combinations of Atomic Orbitals (or MO-LCAO).
Focusing on H
+
2
, a minimal basis for expanding the electronic ground state of the
molecule at a finite internuclear distance, R, would correspond to the atomic orbitals
of the independent atoms at their ground state, namely two 1s atomic orbitals (ψ1,0,0),
centered at the positions of the two nuclei:
φα(R, r) ≡ ψ1,0,0(r+kR/2)
φβ
(R, r) ≡ ψ1,0,0(r−kR/2)
. (14.3.5)
The ansatz for the variational trial functions (Eq. (12.3.18)) therefore reads
ϕ˜(R, r) = cα(R)φα(R, r) +cβ
(R)φβ
(R, r). (14.3.6)
The optimal coefficients and the corresponding energy levels are obtained accord￾ing to the linear variation method by solving the corresponding secular equation
(Eq. (12.3.24)),
[H(R)−ε˜(R)S(R)] = 0

Hα,α(R)−ε˜(R)Sα,α(R) Hα,β
(R)−ε˜(R)Sα,β
(R)
Hβ,α(R)−ε˜(R)Sβ,α(R) Hβ,β
(R)−ε˜(R)Sβ,β
(R)
  cα(R)
cβ
(R)

=

0
0

.
(14.3.7)
The matrices H(R) and S(R) are, respectively, the Hamiltonian and overlap matrices
(see Eq. (12.3.22)). Due to the symmetry of the electronic Hamiltonian (Eq. (14.3.4) in
particular) and its Hermiticity, the following relations hold:
Hα,α(R) = hφα(R)|Hˆ
elec(R)|φα(R)i = Hβ,β
(R)
Hβ,α(R) = hφβ
(R)|Hˆ
elec(R)|φα(R)i = Hα,β
(R)
. (14.3.8)
The diagonal matrix elements of S(R) are the normalization integrals of the atomic
orbitals, where
Sβ,β
(R) = Sα,α(R) = 1
Sβ,α(R) = hφβ
(R)|φα(R)i = Sα,β
(R) ≡ S(R)
, (14.3.9)
and we used the fact that the atomic orbitals are real. The two variational energy levels
are obtained by solving the secular equation, Eq. (14.3.7),
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press251 14.3 Covalent Bonds: the Hydrogen Molecular Ion, H
+
2
ε˜±(R) =
Hα,α(R)±Hβ,α(R)
1±S(R)
, (14.3.10)
where the corresponding eigenvectors obey the conditions (Ex. 14.3.1),
c
±
β
(R)
c
±
α (R)
= ±1. (14.3.11)
The normalized variational approximations to the electronic wave functions that
correspond to ε˜±(R) are therefore (Ex. 14.3.2)
ϕ˜±(R,r) = 1
p
2(1±S(R))
[φα(R, r)±φβ
(R, r)]. (14.3.12)
Exercise 14.3.1 Solve the secular equation, Eq. (14.3.7): (a) Express the eigenvalues as
functions of Hα,α(R),Hβ,α(R),S(R) (use Eqs. (14.3.8, 14.3.9)) by calculating the roots
of the determinant,




Hα,α(R)−ε˜(R)Sα,α(R) Hα,β
(R)−ε˜(R)Sα,β
(R)
Hβ,α(R)−ε˜(R)Sβ,α(R) Hβ,β
(R)−ε˜(R)Sβ,β
(R)



 = 0.
(b) For each eigenvalue obtain the ratio between the elements cβ
(R) and cα(R) of the
respective eigenvector (Eq. (14. 3. 11)).
Exercise 14.3.2 The variational approximations for the two lowest eigenfunctions of the
electronic Hamiltonian are expressed as linear combinations of atomic orbitals, according
to Eq. (14.3.6). Using the result, Eq. (14.3.11), for the corresponding relations between
the expansion coefficients, show that the normalized wave functions, ϕ˜±(R,r), are given
by Eq. (14.3.12).
Clearly, the (variational) solutions to the electronic Schrödinger equation depend
on the interatomic distance. To analyze this dependence, we turn to explicit evaluation
of the matrix elements, Hα,α(R),Hβ,α(R) and S(R). Using Eq. (14.3.5) for the atomic
orbitals and Eq. (14.3.2) for the electronic Hamiltonian, we obtain (see Ex. 14.3.3)
Hα,α(R) = Ke2
R
+E1s +C(R) ; Hβ,α(R) = 
Ke2
R
+E1s

S(R)+A(R), (14.3.13)
where
E1s =
w
drψ1,0,0(r)

−h¯
2
2me
∆r −
Ke
2
|r|

ψ1,0,0(r)
C(R) = −Ke2
w
dr
|ψ1,0,0(r)|
2
|r−kR|
A(R) = −Ke2
w
dr
ψ1,0,0(r−kR)ψ1,0,0(r)
|r−kR|
S(R) =
w
drψ1,0,0(r−kR)ψ1,0,0(r)
. (14.3.14)
E1s
is simply the ground state energy of a hydrogen atom, E1s = −RH (see Section 10.2).
The terms C(R) and A(R) are known as the single-electron “Coulomb integral” and
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press252 Many-Atom Systems
“exchange integral,” respectively (to be distinguished from the two-electron Coulomb
and exchange integrals, Eqs. (13.4.6, 13.4.7)), and S(R) is simply the overlap integral
between two atomic 1s orbitals centered at the two nuclei. The explicit dependence of
these terms on R can be readily obtained by integrating over the electronic coordinates.
We already encountered the Coulomb integral when discussing the effect of a remote
point of charge q|e| on the stationary states of a hydrogen atom, using perturbation
theory (see Section 12.2). To carry out these integrals, it is convenient to follow the
same practice, namely, to change variables to elliptical coordinates, which yields (see
Ex. 14.3.4)
S(R) = e
−R/a0

R
2
3a
2
0
+
R
a0
+1

, (14.3.15)
C(R) =
−Ke2
R

1−

R
a0
+1

e
−2R
a0

, (14.3.16)
A(R) =
−Ke2
a0

e
−R/a0

R
a0
+1
, (14.3.17)
where a0 is Bohr’s radius.
Exercise 14.3.3 Obtain the expressions in Eqs. (14.3.13, 14.3.14) for the integrals,
Hα,α(R) and Hβ,α(R), as defined in Eq. (14.3.8). Use Eq. (14.3.5) and Fig. 10.2.2
for the explicit form of the atomic orbitals, and Eq. (14.3.2) for the electronic Ham￾iltonian. Change integration variables to comply with the definitions of the integrals in
Eq. (14.3.14).
Exercise 14.3.4 To derive the results, Eqs. (14.3.15–14.3.17), for the integrals defined
in Eq. (14.3.14), first follow steps (a) and (b) of Ex. 12.2.8. Then:
(a) Set f(x, y,z) = −Ke2
|ψ1,0,0(r)|
2
|r−kR|
and obtain the result forC(R) in Eq. (14.3.16). (This
amounts to setting the charge to q = 1 in the result of Ex. 12.2.8.)
(b) Set f(x, y,z) = −Ke2 ψ1,0,0(r−kR)ψ1,0,0(r)
|r−kR|
and obtain the result for A(R) in
Eq. (14.3.17).
(c) Set f(x, y,z) = ψ1,0,0(r−kR)ψ1,0,0(r) and obtain the result for S(R)in Eq. (14.3.15).
(d) Show that Hα,α(R) = −RH +2RH
￾
1+
a0
R

e
−2R/a0 and Hα,β
(R) = RH

2a0
R −1−
7R
3a0
−
R
2
3a
2
0

e
−R/a0 .
(e) Show that as the interatomic distance exceeds the size of a single atom, that is, for
R > a0, the coupling matrix element is negative, namely Hα,β
(R) = −|Hα,β
(R)|.
It is important to notice that the Coulomb integral,C(R), has a clear classical mean￾ing. It describes the attraction of an electron density corresponding to the ground state
of a hydrogen atom to another positive charge associated with a second nucleus (a pro￾ton in this case). Indeed, as the interatomic distance increases far beyond the size of
the atom, namely R >> a0, and the second nucleus becomes external to the electronic
density (which decays as ∝ e
−2R/a0 ), the Coulomb integral reads C(R) → −Ke2
R
, which
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Pres253 14.3 Covalent Bonds: the Hydrogen Molecular Ion, H
+
2
is the classical attraction energy between a proton and an electron. In contrast, the
exchange integral, A(R), has no classical analogue, since it appears as if the electron
is delocalized between the two atomic orbitals, while interacting explicitly with only
one of the two nuclei. This integral decays to zero as R >> a0, similarly to the over￾lap integral (S(R)) between two atomic orbitals, each centered at another nucleus (see
Eqs. (14.3.15, 14.3.17)).
The calculated variational electronic energies, ε˜+(R) and ε˜−(R), according to
Eqs. (14.3.10, 14.3.13, 14.3.15–14.3.17), are plotted in Fig. 14.3.2 as functions of
the internuclear distance. Remarkably, while approximate, the qualitative results of
this treatment are correct. The electronic ground state energy, ε˜+(R), has a point of
minimum at a finite internuclear distance, R0, suggesting the existence of a stable
chemical bond, at a corresponding “bond-length,” R0. Within the BO approxima￾tion, a minimum along the electronic energy curve corresponds to a “potential energy
well,” which confines the nuclear motion and supports bound vibrational states (see
Chapter 8). For interatomic distances smaller than R0 the electronic energy increases
and diverges asymptotically, ε˜+(R) −−−→
R→0
Ke2/R (Ex. 14.3.5), owing to the electro￾static repulsion between the two positively charged nuclei (protons). For interatomic
distances larger than R0, the electronic energy increases, but up to a constant asymp￾totic value, ε˜+(R) −−−→
R→∞
−RH, which is Rydberg’s constant (Ex. 14.3.5). This limit
corresponds to a “dissociated” H
+
2 molecule, H
+
2 → H + H
+, composed of a neutral
hydrogen atom in its ground state, and a nucleus (proton) at an infinite distance. The
“dissociation energy” is the difference between the asymptotic energy (−RH) and the
ground state energy, E+,0, of the bound molecular ion (see Fig. 14.3.2). Within the
BO approximation, E+,0 corresponds to the zero-point energy of the nuclei (see Sec￾tions 8.3 and 8.4) at the nuclear potential energy well, set by ε˜+(R). The corresponding
ground state wave function (Eq. (14.2.22)) reads Ψ˜ +,0(R, r) = ϕ˜+(R,r)χ˜
(0)
+ (R), where
ϕ˜+(R,r) is the electronic function corresponding to ε˜+(R), and χ˜
(0)
+ (R) is the nuclear
wave function of minimal energy.
Exercise 14.3.5 (a) Use Eqs. (14.3.13, 14.3.15–14.3.17) to show that as the intera￾tomic distance goes to zero, the electronic energies reflect the classical electrostatic repul￾sion between the nuclei, ε˜±(R) −−−→
R→0
Ke2
R
. (Show that Hα,α(R) = RH

−3+
2a0
R +o(R
2
)

,
Hβ,α(R) = RH

−3+
2a0
R −
R
3a0
+o(R
2
)

, and S(R) = 1−
R
2
6a
2
0
+o(R
3
)). (b) Show that as
the interatomic distance becomes infinite, the electronic energies converge to the ground
state energy of an isolated hydrogen atom, ε˜±(R) −−−→
R→∞
−RH.
Exercise 14.3.6 (a) Use Eqs. (14.3.10, 14.3.13) to show that the difference between
the two electronic energies reads ε˜+(R)−ε˜−(R) = 2
A(R)−S(R)C(R)
1−S(R)
2
. (b) Use Eqs. (14.3.15–
14.3.17) to show that as the internuclear distance becomes large in comparison to atomic
sizes, R >> a0, the energy splitting between the electronic states, ε˜+(R)−ε˜−(R), decays
exponentially, as ∝
R
a0
e
−R/a0 , and becomes proportional to the exchange integral, A(R).
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press254 Many-Atom Systems
−1.1
2 4 6 8 10
−1
−0.9
−0.8
Dissociation energy
E/RH
R/a0
R0
−0.7
−0.6
F(R )
ε−(R ) ∼
ε+(R ) ∼
χ+(R )
(0) ∼
Ftigure 14.3.2 The two lowest electronic energies, ε˜+(R)and ε˜−(R), obtained by the linear variation approach within the BO
approximation for the H
+
2
molecular ion, are presented as solid curves. The electronic ground state has a minimum at
R0 = 2.49a0, where ε˜+(R0) = −1.13RH, suggesting the existence of a stable molecular ion. The
corresponding vibrational ground state wave function, χ˜
(0)
+ (R), and the corresponding nuclear zero-point energy,
E+,0, are presented by the dotted line. The bond dissociation energy in the electronic ground state is represented by
the double arrow. The electronic excitation energy at R0 is represented by the vertical arrow, and the repulsive force
between the nuclei on the excited electronic states is represented schematically by the horizontal arrow.
In the excited electronic state, the electronic energy, ε˜−(R) does not have a minimum.
Consequently, the nuclear potential energy curve is repulsive for any R. This means that
the force on the nuclei, F(R) = −dε˜−(R)/dR, is always in the direction of increasing R.
An electronic excitation of H
+
2
into its first excited state would therefore correspond to
a dissociation of the chemical bond.
The energy gap between the two electronic energies closes as R >> a0, where the
two states approach their asymptotic value, −RH. As already discussed, this limit cor￾responds to a dissociated molecule, where the electron seems to “pick” one of the nuclei
to form a hydrogen atom, and the interaction of this neutral atom with a remote point
charge decays asymptotically to zero. This description is qualitatively correct, but it
is somewhat naïve, since, as discussed in what follows, at any finite R the symme￾try of the system (e.g., Eq. (14.3.4)) implies that the electronic stationary states are
associated with equal probability density for the electron to be located near the two
identical nuclei. The situation is reminiscent of a particle in a symmetric double well
potential, discussed in Section 6.4, where the two nuclei define two potential energy
wells for the electron. The “tunneling splitting” between the two lowest energy levels
in this double well system indeed corresponds to these delocalized states. A quan￾titative calculation of ε˜+(R) − ε˜−(R) shows that for R  a0; the energy splitting is
proportional to the single-electron exchange integral, A(R) (see Ex. 14.3.6)), which
is attributed to the nonclassical delocalization of the electronic wave function between
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press255 14.3 Covalent Bonds: the Hydrogen Molecular Ion, H
+
2
0
−3 −2 −1
|φ+|
2 ∼
0
z/a0
1 2 3
0.05
0.1
0.15
0
−3 −2 −1
|φ−|
2 ∼
0
z/a0
1 2 3
0.1
0.2
0.3
Ftigure 14.3.3 Solid lines: Probability densities for the bonding(|ϕ˜+(R0, r)|
2
)and antibonding (|ϕ˜−(R0, r)|
2
) molecular
orbitals for H
+
2
, plotted as functions of the electronic coordinate r = (0,0,z), for the internuclear distance,
R0 = 2.49a0. Dotted lines: Probability densities for a 1satomic orbital, evenly split (“classically delocalized”)
between the two nuclei.
the two nuclei. Importantly, this exchange (delocalization) effect is the main source for
the relative stabilization (lower energy) of the molecule in comparison to its dissociated
components. This principle generalizes to more-complex many-atom systems as well.
We now turn to discussing the correlation between the properties of the different
electronic energy levels, ε˜+(R) and ε˜−(R), and the corresponding molecular orbitals,
ϕ˜±(R,r), as given in Eq. (14.3.12) and presented in Fig. 14.3.3. The two probabil￾ity densities, |ϕ˜±(R,r)|
2
, are even functions of z; namely, they are evenly delocalized
between the two nuclei (see Fig. 14.3.3). Nevertheless, they differ from each other
in a way that reflects the different molecular orbitals (see Eq. (14.3.12)). In ϕ˜+(R,r)
the two atomic orbitals appear with the same sign, whereas they have opposite signs
in ϕ˜−(R,r). Put differently, in accordance with the inversion symmetry of the Ham￾iltonian (Eq. (14.3.4)), both molecular orbitals are eigenfunctions of the inversion
symmetry operator, but they correspond to different eigenvalues; namely, ϕ˜±(R,r)
correspond to the eigenvalues ±1 (even and odd functions of z ).
The origin of the energy splitting between the two states, and the fact that ϕ˜+(R,r)
is associated with the lower energy can be qualitatively explained by considering the
difference between the orbitals and its influence on the electrostatic energy of the sys￾tem. What destabilizes the “chemical bond” is the repulsion between the two positively
charged nuclei. The presence of a negatively charged electron may compensate for that
by its mutual attraction to the two nuclei, as long as it is positioned between the nuclei
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press256 Many-Atom Systems
(a screening effect). In H
+
2
, optimal stabilization is obtained when the electron is right
in the middle between the two positive nuclei. Inspecting the probability densities,
|ϕ˜+(R,r)|
2 and |ϕ˜−(R,r)|
2
, in the region between the nuclei, namely, in the plane per￾pendicular to the bond axis (z = 0), we can readily see that they are different. While
in |ϕ˜+(R,r)|
2
the two atomic orbitals interfere constructively, building up finite prob￾ability density in that plane between the nuclei, the destructive interference between
the atomic orbitals in |ϕ˜−(R,r)|
2 yields zero probability density in that plane (z = 0
is a “nodal plane” in this case). The effect is emphasized in Fig. 14.3.3 by comparing
|ϕ˜+(R,r)|
2 and |ϕ˜−(R,r)|
2
to the probability density of an atomic orbital, evenly split
between the two nuclei (a “classically delocalized” orbital, 1
2
|φα(R, r)|
2 +
1
2
|φβ
(R, r)|
2
).
As we can see, the probability density near the z = 0 plane is enhanced in |ϕ˜+(R,r)|
2 and
suppressed in |ϕ˜−(R,r)|
2
in comparison to the “classically delocalized” atomic orbital.
Since the electrostatic energy decreases in correlation to the increase of the probability
density in this plane, and vice versa, the energy associated with ϕ˜+(R,r) decreases, and
the energy associated with ϕ˜−(R,r)increases in comparison to an atomic orbital energy
(see Fig. 14.3.2). As we have highlighted, this energy difference is attributed primarily
to the quantum mechanical single-electron exchange integral.
The decrease/increase in molecular orbital energies in which the two atomic orbitals
appear in the same/opposite sign is universal and applies in general. Consequently,
molecular orbitals that do not have any nodal plane (do not change their sign) perpendic￾ular to the line connecting the two nuclei are termed “bonding orbitals,” while molecular
orbitals that have such a nodal plane are termed “antibonding orbitals.”
14.4 Linear Combinations of Atomic Orbitals (LCAO) in Molecules
As we saw in the previous section, insight was gained on the nature of the chemical
bond in the single-electron molecule, H
+
2
, by invoking the BO approximation and the
linear variation approach. The idea of MO-LCAO can be readily extended to different
molecules as well as to extended many-atom systems, including atomic lattices. In the
discussion of H
+
2
, the variational calculation was limited to a “minimal basis” com￾posed of the two 1s orbitals associated with the two hydrogen nuclei. However, even
for this simple molecule the variational space must be extended (see Section 12.3, and
Eq. (12.3.28) in particular) to approach the exact ground state energy (as a function
of the internuclear distance) and to obtain higher electronically excited states. When it
comes to many-electron molecules, extending the linear variation space becomes neces￾sary. Recalling that electrons are fermions, Pauli’s exclusion principle (see Section 13.3)
limits the occupation of each spin orbital to a single electron. Consequently, the num￾ber of (linearly independent) spin-orbitals needed for approximating the ground state
of a many-electron molecule must be larger than (or at least equal to) the number of
electrons, and the space of linear variation must increase accordingly.
A natural way to increase the number of calculated molecular orbitals within a lin￾ear variation approximation is to increase the basis by adding more atomic orbitals
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press257 14.4 Linear Combinations of Atomic Orbitals (LCAO) in Molecules
of the atoms composing the molecule. Denoting the different atoms by their indexes,
α = 1,2,...,n, a set of Nα atomic orbitals associated with the αth atom is denoted
as {φα,1(r − Rα),φa,2(r − Rα),...,φa,Nα
(r − Rα)}, where φa,nα
(r − Rα) is an “atomic
orbital” centered around the nucleus position, Rα. The atomic orbitals are asso￾ciated with the known atomic angular function (of types s, p,d, etc.; see Chap￾ter 13) and a fixed radial function (e.g., an exponent or a Gaussian, multiplied by
a polynomial [13.6]). The linear variation approximations for the molecular orbitals,
ϕ˜MO
1
(r),ϕ˜MO
2
(r),ϕ˜MO
3
(r),..., therefore read
ϕ˜MO
k
(r) =
n
∑
α=1
Nα
∑
nα=1
c
(k)
α,nα φa,nα
(r−Rα), (14.4.1)
where the variational parameters to be optimized are the expansion coefficients,
{c
(k)
α,nα
}. The ground state of the electronic Hamiltonian corresponds to a Slater
determinant, namely an antisymmetrized product of molecular orbitals (Eqs. (13.3.2,
13.3.3)), where the optimal orbitals are self-consistent solutions to the nonlinear
Hartree–Fock equations (Eq. (13.3.24)),
"
−h¯
2
2me
∆r +
n
∑
α=1
−KZe2
|r−Rα|
#
ϕ˜MO
k
(r) +
N
∑
j=1
w
dr
0 Ke2
|r−r
0
|
|ϕ˜MO
j
(r
0
)|
2
ϕ˜MO
k
(r)
−
N
∑
j=1
δms, j
,ms,k
w
dr
0
￾
ϕ˜MO
j
(r
0
)
∗
ϕ˜MO
j
(r)
Ke2
|r−r
0
|
ϕ˜MO
k
(r
0
) = εkϕ˜MO
k
(r)
. (14.4.2)
The iterative solution of these equations corresponds to calculations of the eigen￾states of the Fock operator (readjusted in each iteration) instead of the Hamiltonian.
This is done by representing the Fock operator as a matrix in the variational space
of the selected atomic orbital. Since atomic orbitals corresponding to different atoms
are generally non-orthogonal (unless for specific symmetry considerations; see the
following discussion), their overlap must be accounted for, such that the secular equa￾tion obtained by the linear variation principle is a generalized eigenvalue problem
(Eq. (12.3.24)) for the molecular orbitals’ coefficients {c
(k)
α,nα
} and the corresponding
orbital energies, {εk} (the Roothaan equations [13.6]).
The number of molecular orbitals obtained as solutions to the Hartree–Fock equa￾tions is limited by the number of basis functions. This number typically exceeds the
number of spatial orbitals (N/2 or (N +1)/2) needed to construct a single Slater deter￾minant for the N electrons in the molecule. The choice of the orbitals to be occupied
in the electronic ground state is guided by minimizing the variational (Hartree–Fock)
many-electron energy (see Eq. (13.3.28)). As in the case of atoms, for a rough estimate
it is sufficient to minimize the sum over molecular orbital energies. This means that in
the ground state the orbitals are “filled” from the lowest orbital energy and upward,
subject to the Pauli’s exclusion principle, namely, up to two electrons of different spin
states per spatial orbital (the Aufbau principle). As in the case of atoms, however, there
are exceptions to this general rule when the energy differences between nearby molec￾ular orbital energies are small in comparison to the overcounted interaction energy
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Pres258 Many-Atom Systems
(see Eq. (13.3.31), and the related discussion). In the case of degeneracy of molecu￾lar orbitals, Hund’s rule applies, namely the ground state corresponds to a maximal
number of unpaired electrons occupying the degenerate orbitals (see the discussion in
Section 13.4).
LCAO for Atom Pairs
Calculations based on the BO and the Hartree–Fock approximations as just outlined
often provide a qualitatively correct account for the electronic energy of molecules in
their ground state, at near-equilibrium geometries. Focusing first on atom pairs, the
orbital energy levels and their ground state occupation are presented schematically
in Fig. 14.4.1 for some homonuclear pairs. Graphical representations of some of the
molecular orbitals are presented in Fig. 14.4.2. The orbitals are classified into “bond￾ing” and “antibonding” (marked by a star), where an antibonding orbital corresponds
to the existence of a nodal plane between the nuclei, perpendicular to the bond axis.
Other classifications correspond to the symmetry properties of the molecular orbitals.
Identifying the z-axis as the line connecting the two atomic centers, the electronic
Hamiltonian, and hence the Fock operator, commute with the angular momentum
operator, Lˆ
z
, for any diatomic. When the atoms are identical, this also holds for the
inversion operator, Pˆ
x,y,z (as in the case of H
+
2
; see Eqs. (14.3.3, 14.3.4)). Consequently,
the molecular orbitals (eigenfunctions of the Fock operator) can be identified with
Ftigure 14.4.1 The order of the molecular orbitals and their occupation by electrons at the ground state of three homonuclear atom
pairs, B2,N2 and F2. The different orbitals are marked according to their rotational quantum number(σ,π)and
their symmetry with respect to inversion (g,u), and according to the atomic orbital types dominating their LCAO
expansions (namelysor p type). A star corresponds to an antibonding orbital (see Fig.14.4.2).The bond order (BO),
which corresponds to the excess of electrons in bonding orbitals, is marked for each atom pair.
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press259 14.4 Linear Combinations of Atomic Orbitals (LCAO) in Molecules
πg(p) ∗
πu(p)
px px
σu(p) ∗
σg(p)
pz pz
pz s
σu(s) ∗
σg(s)
s s
σ (s−p) ∗
σ (s−p)
Ftigure 14.4.2 Schematic illustrations of molecular orbitals (middle) and the atomic orbitals (sides) dominating their LCAO
expansions. The plots represent the electron probability densities, where the different colors refer to changes in the
sign of the underlying functions. The vertical dotted lines mark nodal planes between the nuclei (small black dots),
which correspond to antibonding orbitals. The different molecular orbitals are marked according to their rotational
quantum number(σ,π)and their symmetry with respect to inversion (g,u, when relevant), and according to the
atomic orbital types dominating their LCAO expansions.
eigenfunctions of the operators Lˆ
z and Pˆ
x,y,z
, and can be classified according to the
respective eigenvalues of these operators. The Greek letters σ,π,δ,... correspond to
the angular momentum quantum numbers, |m| = 0,1,2,... respectively, whereas g and
u stand for the eigenvalues of the inversion operator, +1 and −1, which correspond,
respectively, to its even (”gerade”) and odd (“ungerade”) eigenfunctions.
As we can see in Fig. 14.4.1, the same orbital types (e.g., σ
∗
g
, or πu, and so forth) are
common to the different homonuclear atom pairs, which reflect their common sym￾metry properties. The spatial distribution of the electronic probability density in each
of the molecular orbitals as well as the orbital energies depend, as expected, on the
specific atoms involved (see, e.g., Fig. 5.7 in Ref. [14.9] for the relative energies of the
different molecular orbitals in different homonuclear atom pairs). The general trend is
that the orbital energies decrease with increasing atomic number, which correlates with
the decrease in the corresponding atomic orbital energies (see, e.g., Fig. 13.3.2). The
order of the orbital energies (and therefore their corresponding electronic population)
may change, however, between different atomic pairs. For example, the πu orbitals in
B2 are lower in energy then the σg orbital (which means that the total spin state of the
molecule in its ground state is a triplet, via Hund’s rule), whereas in F2 their order is
reversed.
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press260 Many-Atom Systems
The set of occupied molecular orbitals in each atomic pair (and at each interatomic
distance), is determined by minimizing the variational (Hartree–Fock) energy. The
prospects for the formation of a “chemical bond” between the atoms can be extracted
from the dependence of the electronic ground-state energy on the nuclear positions.
When a minimum exists at some finite interatomic distance, a stable chemical bond
between the atoms can be formed around that distance (see the discussion of H
+
2
in
the previous section). A rough indicator for the existence of a chemical bond can be
gained by a simple inspection of the occupation numbers of electrons in bonding versus
antibonding orbitals. Referring to the discussion of H
+
2
(Fig. 14.3.3), bonding orbitals
are associated with lower energy in comparison to the “classically delocalized” atomic
orbitals, and therefore, electronic population in these orbitals contributes to stabili￾zation of the chemical bond, while antibonding orbitals are associated with higher
energies, and their population destabilizes the chemical bond. The “bond order” is
defined as the sum of electron pairs populating bonding orbitals minus the sum of
pairs populating antibonding orbitals. Whenever the bond order is larger than zero, the
rough prediction is for the existence of a stable chemical bond. For example, according
to this prediction, the diatomic pairs, N2,O2,F2, would be stable molecules (associated
with bond orders, 3, 2,1, respectively), whereas the noble gas dimer Ne2 has a zero
bond order and would not exist as a stable molecule at any interatomic distance. This
is indeed the case.
Further insight into the nature of the chemical bond in different molecules can be
gained by inspecting the contribution of the different atomic orbitals to each molec￾ular orbital. Given a molecular orbital, ϕ˜MO
k
(r), this information is encoded in the
2p
σ ∗
σ ∗
σ ∗
σ
σ
σ
π ∗
π
2s
1s
o o2
(a) (b) (c)
o H HF F Li LiF F
σ ∗
1s
2s 2s
2s
σ
2p 2p
1s
1s
1s
2s
2p 2p 2p
2s 2s
1s 1s
2s
1s
1s
Ftigure 14.4.3 Orbital energy levels are presented in the middle of each plot (a, b, and c), between the corresponding atomic orbital
energy levels. The orbital populations in the electronic ground state are presented by the half arrows. (a), (b), and (c)
represent typical cases of “purely covalent,” “polar,” and “ionic” chemical bonds, according to the degree of localization
of the orbitals in which the bonding electrons are populated. The schemes are not in scale, to emphasize qualitative
differences.
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press261 14.4 Linear Combinations of Atomic Orbitals (LCAO) in Molecules
expansion coefficients vector, n
c
(k)
α,nα
o
(see Eq. (14.4.1)). Analysis of differentdiatomic
molecules reveals that each molecular orbital is primarily dominated by only a few
atomic orbitals, typically two, one from each atom, which correspond to the same
quantum number for rotation around the molecular (z) axis (|m|), and the same (or
nearly the same) atomic orbital energy. Before analyzing the origin for these two con￾ditions, let us discuss a few examples, illustrated in Fig. 14.4.3. The molecular and
atomic orbitals are presented according to their (relative) orbital energies, where each
molecular orbital is correlated to the atomic orbitals, which dominate its expansion
(Eq. (14.4.1)).
In a homonuclear molecule, such as O2 (Fig. 14.4.3 (a)), each molecular orbital is
shown to be dominated by a pair of atomic orbitals (one from each atom) of the same
orbital energy and the same rotational quantum number, |m|. Notice that both s-type
and pz-type atomic orbitals correspond to |m| = 0, and therefore the corresponding
molecular orbitals are of σ-type. The two degenerate pairs of px and py atomic orbitals
both correspond to |m| = 1, which correspond to the two degenerate pairs of π-type
molecular orbitals (see Fig. 14.4.2 for graphical illustrations of these orbitals).
In a heteronuclear molecule, such as HF (Fig. 14.4.3 (b)), the two sets of atomic
orbitals corresponding to H and F do not match in energy. Nevertheless, the atomic
orbital energies of 1s (H) and 2p(F) are sufficiently close (in the sense that will be elab￾orated in what follows). Out of the three degenerate 2p atomic orbitals of F, only the
2pz orbital is associated with the same rotational quantum number (|m| = 0) as the
1s of H, such that two σ-type orbitals (bonding and antibonding) are formed, where
only the bonding orbital turns out to be occupied at the molecular electronic ground
state. Each of the other “molecular orbitals” of HF that are occupied turns out to be
dominated by a single atomic orbital, whose association as molecular orbitals is essen￾tially only formal. (These orbitals are often termed “nonbonding” molecular orbitals.)
According to this MO analysis, what stabilizes the chemical bond in the molecule HF
is the single electron pair populated in the single bonding molecular orbital, which
corresponds to a bond of order 1.
A qualitatively different picture emerges for the pair LiF (Fig. 14.4.3 (c)). In this
case, the two sets of atomic orbitals do not even nearly match in any of their relevant
orbital energies. It turns out that all the populated “molecular orbitals” in the elec￾tronic ground state of LiF are dominated by single atomic orbitals, associated with
either Li or F (formally, “nonbonding” molecular orbitals). The population of these
orbitals at the ground electronic state should correspond to the minimal variational
(Hartree–Fock) energy (roughly, to the Aufbau principle). This leads to a remarka￾ble result when the two atoms are close to each other. The electronic ground state
corresponds to a “transfer” of an electron from a high-lying 2s orbital of Li into an
atomic orbital 2p of F, which is unpopulated in an isolated F atom. What stabilizes
the “chemical bond” in LiF is therefore the Coulomb attraction between the positively
charged Li+ (which lost an electron) and the negatively charged F
− (which gained an
electron). In contrast to the chemical bonds in O2 or HF, which are often referred to
as molecular, or covalent bonds, the chemical bond in LiF is termed “ionic.”
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press262 Many-Atom Systems
Ionic bonds are commonly formed between an atom with a relatively high energy
of its highest occupied atomic orbital (a low “ionization potential”), which is typical
for metal atoms, and an atom with a relatively low energy of its lowest unoccupied
atomic orbital (a high “electron affinity”), which is typical for nonmetal atoms. Ionic
materials are indeed formed when electrons are transferred from metal to nonmetal
atoms, resulting in bond formation between oppositely charged ions. The attraction
between oppositely charged atoms stabilizes the formation of extended lattices (beyond
atomic pairs).
In pure nonmetal materials, ionic bonds cannot be formed. When all the atomic
ionization potentials are relatively high, the required energy for charge transfer from
one atom to another can be provided only at interatomic distances, which are small
in comparison to the typical size of each atom, and therefore, are typically inaccessi￾ble. In this absence of “full charging,” bonds between nonmetal atoms are covalent,
where the bond stabilization is attributed to charge delocalization between the nuclei
(as discussed in Section 14.3, for H
+
2
).
In pure metals, the stabilization energy attributed to electronic delocalization among
the different atoms increases to the extent that it typically exceeds the gain in energy
attributed to charging the atoms. Charge delocalization among many atoms further
stabilizes the formation of extended atomic lattices, in which atoms are bounded by
“metallic bonds” based on electron delocalization over the many-atom system.
The difference between ionic, molecular, and metallic bonds leads to dramatic effects
on the properties of the respective materials. One example is electrical conductance,
which will be addressed in Section 14.5. Specifically, ionic materials are typically insu￾lators, and metals are conductors. Semiconductors are chemical compounds of atoms
on the borderline between metals and nonmetals (such as silicon).
Effective LCAO: Symmetry and Energy Compatibility
The examples presented in Fig. 14.4.3 are representative for diatomic pairs in general,
in the sense that each molecular orbital is primarily dominated by two atomic orbitals,
one from each atom (in the case of bonding and antibonding molecular orbitals), or by
a single atomic orbital (in the case of nonbonding orbitals). This may seem surprising
at first, since each molecular orbital is formally expanded in a linear variation space,
which includes numerous atomic orbitals from the two atoms (Eq. (14.4.1)). Why then
are most of the atomic orbitals “filtered out” in each molecular orbital? The reason is
that for the atomic orbitals to be effectively coupled within a molecular orbital, they
must fit in their symmetry and their orbital energy, as explained in what follows.
The symmetry requirement is straightforward. Considering first the single-electron
Hamiltonian of any diatomic, its cylindrical symmetry means that it is invariant to
rotation around the bond (z) axis (see Fig. 14.3.1)), and therefore it commutes with
the electron’s rotation operator, Lˆ
z (Eq. (14.3.3)). Since by construction each atomic
orbital can be chosen as an eigenfunction of Lˆ
z (notice that while the two atom centers
are displaced from each other along the z-axis, the angular coordinate φ is iden￾tical in the two atoms; see Fig. 14.3.1), the Hamiltonian matrix elements between
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press263 14.4 Linear Combinations of Atomic Orbitals (LCAO) in Molecules
atomic orbitals associated with different eigenvalues of Lˆ
z must vanish identically (see
Ex. 14.4.1). Since this rule applies to all the atomic orbitals, the matrix representation
of the Hamiltonian in the linear variational space spanned by such atomic orbitals is
block-diagonal, where each block corresponds to a specific eigenvalue of Lˆ
z
, associ￾ated with m = 0, +/–1, +/–2, .... Consequently, each molecular orbital (defined by an
eigenvector of this block-diagonal matrix, c
(k)
α,nα
) is associated with a specific eigenvalue
of Lˆ
z
, where atomic orbitals associated with different m values “don’t mix.”(Notice that
when the atomic orbitals are selected as linear combinations of eigenfunction associ￾ated with m and -m, each block corresponds to |m|.) The same argument holds in the
many-electron system, where the method of linear variation is applied to the nonlin￾ear Fock operator. The matrix representation of this operator in the basis of atomic
orbitals is also a block diagonal, as long as the cylindrical symmetry is imposed on the
mean-field operators at each step of the self-consistent solution of the Hartree–Fock
equations.
Similar considerations apply beyond diatomic molecules, namely in complex poly￾atomic systems. When the electronic Hamiltonian commutes with a set of symmetry
operators, the atomic orbitals can be chosen to comply with specific eigenvalues of
these symmetry operators. Such “symmetry-adopted” atomic orbitals lead to block￾diagonal representations of the polyatomic molecular Hamiltonian (or Fock operator)
in the variational basis, which divides the variational calculation of molecular orbitals
into subspaces associated with specific eigenvalues of the different symmetry oper￾ators. (In group theory terms, each such subgroup of orbitals corresponds to an
irreducible representation of the symmetry group defined by the symmetry operators
[14.9].) This has important practical implementation, as it helps to reduce the compu￾tational effort associated with the variational solution by diagonalizing the different
blocks independently.
Exercise 14.4.1 Let the operator Hˆ commute with the Hermitian operator Aˆ, and
let |φ1i and |φ2i be two eigenvectors of Aˆ, associated with two different eigenvalues,
Aˆ|φ1i = α1|φ1i, Aˆ|φ2i = α2|φ2i, α1 6= α2. (a) Show that the vectors Hˆ|φ1i and Hˆ|φ2i
are eigenvectors of Aˆ, corresponding to the eigenvalue, α1 and α2, respectively. (b) Use
the Hermiticity of Aˆ to prove that H1,2 = hφ2|Hˆ|φ1i = 0.
A second requirement for the creation of bonding and antibonding molecular
orbitals as linear combinations of atomic orbitals is that the atomic orbitals must be
sufficiently close in their orbital energies. Just how close the atomic orbitals need to be
is not easy to define in the most general case. Nevertheless, it is possible to justify the
requirement for energy matching and even to quantify it in terms of the molecular
parameters in most cases.
For simplicity we start from a “tight-binding” model for a single electron in a system
of two positively charged atomic cores at a fixed interatomic distance. The Hamiltonian
obtains the generic form,
Hˆ = Tˆ
r +Vˆα +Vˆ
β
, (14.4.3)
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press264 Many-Atom Systems
where Vˆα ≡ V(r − Rα) and Vˆ
β ≡ V(r − Rβ
) are potential energy operators (potential
energy wells), corresponding to the attraction of the electron to two atomic cores,
denoted by the indexes α and β, and Tˆ
r is the kinetic energy operator. We wish to
obtain molecular orbitals for this system, within a linear variation space of two specific
atomic orbitals,
|ϕki = c
(k)
α |φai+c
(k)
β
|φβ
i, (14.4.4)
where |φαi and |φβ
i, are approximations to bound states of the “isolated”
atoms,
[Tˆ +Vˆα]|φαi ≈ εα|φαi
[Tˆ +Vˆ
β
]|φβ
i ≈ εβ
|φβ
i
. (14.4.5)
We now restrict the discussion to cases in which the spatial probability densities associ￾ated with |φαi and |φβ
i are localized in the respective potential energy wells, such that
the distance between the wells exceeds significantly the widths of these probability den￾sity distributions (see Fig. 14.4.4). In this case, one can invoke an approximation that
states that the amplitude of |φαi vanishes in the region where Vˆ
β 6= 0, and similarly,
the amplitude of |φβ
i vanishes in the region where Vˆα 6= 0. Additionally, the spatial
overlap between |φαi and |φβ
i is approximated as null. While this set of assumptions
is never strictly met or any given Hamiltonian, it leads to insightful and useful discrete
models for binding between the atoms, often referred to as “tight-binding” models.
Formally, the following set of conditions is assumed to hold simultaneously:
hφα|Vˆ
β
|φαi = hφβ
|Vˆα|φβ
i = hφβ
|Vˆα|φαi = hφβ
|Vˆ
β
|φαi = 0, (14.4.6)
hφβ
|φαi = 0. (14.4.7)
According to the method of linear variation, the optimal expansion coefficients for the
variational trial function, Eq. (14.4.4), are obtained by solving the secular equation
(see Eq. (12.3.24)),
Ftigure 14.4.4 A schematic illustration of probability density distributions confined in two remote potential energy wells. The tight
binding model assumptions become relevant when the distance between the two potential well minima is much
larger than the standard deviations of the probability density distributions in each potential well.
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press265 14.4 Linear Combinations of Atomic Orbitals (LCAO) in Molecules
"
Hα,α −εk Hα,β
H
∗
α,β Hβ,β −εk
#" c
(k)
α
c
(k)
β
#
=

0
0

, (14.4.8)
where Hα,α = hφα|Hˆ|φαi,Hβ,β = hφβ
|Hˆ|φβ
i, and Hα,β = hφα|Hˆ|φβ
i = hφβ
|Hˆ|φαi
∗
.
Solving this equation amounts to finding the eigenvalues and eigenvectors of atwo￾level system Hamiltonian (see Eqs. (12.2.3–12.2.8)).The two eigenvalues,corresponding
to the molecular orbital energies, therefore read
ε1 =
Hα,α +Hβ,β
2
+
Hα,α −Hβ,β
2
s
1+
4|Hα,β
|
2
(Hα,α −Hβ,β
)
2
ε2 =
Hα,α +Hβ,β
2
−
Hα,α −Hβ,β
2
s
1+
4|Hα,β
|
2
(Hα,α −Hβ,β
)
2
. (14.4.9)
The respective eigenvectors, which correspond to the molecular orbitals, are
|ϕ1i =
s
ξ +1
2ξ
|φαi−s
ξ −1
2ξ
|φβ
i ; |ϕ2i =
s
ξ −1
2ξ
|φαi+
s
ξ +1
2ξ
|φβ
i, (14.4.10)
where ξ ≡
q
1+4|Hα,β
|
2/(Hα,α −Hβ,β
)
2
, and where, without loss of generality, these
solutions correspond to the typical case (see, e.g., the example of H
+
2
(Ex. 14.3.4e)) in
which the coupling matrix element is real and negative, namely Hα,β = −|Hα,β
|.
The eigenvalues and eigenvectors depend critically on the ratio between the inter￾atomic coupling matrix element and the difference between the two “local” matrix
elements at the two atoms, 2|Hα,β
|/|Hα,α − Hβ,β
|. Recalling that |φαi and |φβ
i are
approximated eigenstates of the “isolated” atoms (see Eq. (14.4.5)), |Hα,α −Hβ,β
| can
be regarded as the energy difference between the two atomic orbital energies, and the
critical parameter reads
2|Hα,β
|/|Hα,α −Hβ,β
| ≈ 2|Hα,β
|/|εα −εβ
|. (14.4.11)
It is instructive to examine the two limiting cases:
Case I: The atomic orbitals match in energy, εα ≈ εβ
, where |εα −εβ
| << 2|Hα,β
|.
In this case (see Fig. 14.4.5 (a)) we can set 4|Hα,β
|
2/(Hα,α −Hβ,β
)
2 >> 1 in Eqs. (14.4.9,
14.4.10), such that the approximated molecular orbital energies (Eq. (14.4.9)) read (see
Ex. 14.4.2)
ε1 ≈
Hα,α +Hβ,β
2
+|Hα,β
| ; ε2 ≈
Hα,α +Hβ,β
2
−|Hα,β
|, (14.4.12)
where the corresponding eigenvectors are
|ϕ1i ∼=
r
1
2
|φαi −r
1
2
|φβ
i ; |ϕ2i ∼=
r
1
2
|φαi+
r
1
2
|φβ
i. (14.4.13)
As we can see, each molecular orbital is shown to be delocalized over the space of
the two atoms, and therefore the molecular orbitals are significantly different from
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press266 Many-Atom Systems
|φ1〉 = |φ1〉 = |ϕα 〉
|ϕα 〉 −
|ϕα 〉
εα
∼
εβ
|ϕβ 〉
|ϕβ 〉
|ϕα 〉
εα
|ϕα 〉
εα
εβ
|ϕβ 〉
εβ
|ϕβ 〉
1
(a) (b) (c)
2
1
2
|φ 2〉 = |φ 2〉 = |ϕβ 〉 |ϕα 〉 +
∼
∼ |ϕβ 〉
1
2
1
2
∼
Ftigure 14.4.5 A schematic illustration of the effect of energy matching between atomic orbitals, on the LCAO in an atom pair.
(a) Perfect energy matching resulting in perfect orbital delocalization between the two atoms. (b) The intermediate
case, where the mismatch in energy is of the order of the coupling energy. (c) The limit where the energy mismatch
exceeds by far the coupling energy, resulting in localized pair orbitals.
the localized atomic orbitals. Considering the sign of the atomic orbital coefficients
within each molecular orbital, the linear combinations, |ϕ2i and |ϕ1i, correspond to
bonding and antibonding molecular orbitals, respectively. This difference is expressed
also in the molecular orbital energies, ε2 and ε1, which are substantially different from
the atomic orbital energies, where ε2 << εα ≈ εβ and ε1 >> εα ≈ εβ
, as illustrated in
Fig. 14.4.5 (a). Notice the similarity of this result to the case of H
+
2
that was studied in
Section 14.3, where ε1,2 and |ϕ1,2i are reminiscent of ε˜−,+ and |ϕ˜−,+i, respectively.
Exercise 14.4.2 Use the condition for “energy matching,” 2|Hα,β
| >> |Hα,α − Hβ,β
|,
in Eqs. (14.4.9, 14.4.10) to obtain the approximations for the orbital energies and
coefficients in Eqs. (14.4.12, 14.4.13).
Case II: The atomic orbitals mismatch in energy, εα 6= εβ
, where |εα −εβ
| >> 2|Hα,β
|.
Setting 4|Hα,β
|
2/(Hα,α −Hβ,β
)
2 << 1 in Eqs. (14.4.9, 14.4.10) leads in this case to the
following approximations for the molecular orbital energies (Ex. 14.4.3),
ε1 ≈ Hα,α +
|Hα,β
|
2
Hα,α −Hβ,β
; ε2 ≈ Hβ,β −
|Hα,β
|
2
Hα,α −Hβ,β
, (14.4.14)
and to the corresponding molecular orbitals (Eq. (14.4.10)),
|ϕ1i ∼= |φαi −
|Hα,β
|
Hα,α −Hβ,β
|φβ
i ∼= |φαi ; |ϕ2i ∼=
|Hα,β
|
2
Hα,α −Hβ,β
|φαi+|φβ
i ∼= |φβ
i.
(14.4.15)
In this case each “molecular orbital” remains nearly localized at one of the two atoms
and essentially identifies with the corresponding atomic orbital (see Fig. 14.4.5(c)).
This localization is expressed also in the molecular orbital energies, which are nearly
equal to the atomic orbital energies. The orbitals|ϕ2i and |ϕ1i correspond in this case to
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press267 14.4 Linear Combinations of Atomic Orbitals (LCAO) in Molecules
nonbonding orbitals, which do not induce electronic localization and therefore hardly
affect the stability of the chemical bond between the atoms.
Exercise 14.4.3 Use the condition for “energy mismatching,” 2|Hα,β
| << |Hα,α −Hβ,β
|,
in Eqs. (14.4.9, 14.4.10) to obtain the approximations for the orbital energies and
coefficients in Eqs. (14.4.14, 14.4.15).
Within the tight-binding model, the condition for effective mixing of two atomic
orbitals to give delocalized (bonding, or antibonding) molecular orbitals is indeed
unambiguous. It can be cast into a single requirement, namely, the difference between
the atomic orbital energies, |εα − εβ
|, must be small in comparison to the coupling
energy, |Hα,β
|. In realistic many-atom systems the tight-binding model assumptions
(Eqs. (14.4.6, 14.4.7)) do not hold strictly, and additional care must also be taken
to many-electron interactions. Nevertheless, by properly redefining the parameters,
|Hα,β
|, and |εα −εβ
|, the energy-matching criterion is useful also beyond the realm of
elementary tight-binding models.
Relaxing the assumptions outlined in Eqs. (14.4.6, 14.4.7), still within the single￾electron framework, leads to a generalized eigenvalue equation instead of Eq. (14.4.8).
The equation for the optimal variational expansion coefficients reads in this case

Hα,α −εk Hα,β −εks
Hα,β −εks Hβ,β −εk

"
c
(k)
α
c
(k)
β
#
=

0
0

. (14.4.16)
Here, s = hφβ
|φαi is the overlap between the two atomic orbitals, and
Hα,α = εα +hφα|Vˆ
β
|φαi
Hβ,β = εβ +hφβ
|Vˆα|φβ
i (14.4.17)
Hα,β = εαs+hφα|Vˆ
β
|φβ
i.
To extract the proper conditions for obtaining effective linear combinations that corre￾spond to bonding and antibonding orbitals (as in case I), we enforce the two expansion
coefficients to be equal in magnitude (which corresponds to “perfect delocalization”),
c
(k)
α = ±c
(k)
β
. (14.4.18)
Along with Eq. (14.4.16), this condition leads to the following equations for the
molecular orbital energies (Ex. 14.4.4),
ε± =
Hα,α ±Hα,β
1±s
=
Hβ,β ±Hα,β
1±s
, (14.4.19)
from which one immediately obtains the condition Hα,α −Hβ,β = 0, namely
εα −εβ +hφα|Vˆ
β
|φαi − hφβ
|Vˆα|φβ
i = 0. (14.4.20)
This condition generalizes the condition for matching atomic orbital energies, as dis￾cussed for the tight-binding model (|εα − εβ
| << 2|Hα,β
|), since in order to have
Hα,α − Hβ,β ≈ 0, in addition to εα − εβ ≈ 0, the term hφα|Vˆ
β
|φαi − hφβ
|Vˆα|φβ
i,
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press268 Many-Atom Systems
which is completely ignored in the tight-binding approximation, must also be suffi￾ciently small. Another apparent difference from the tight-binding model is that the
orbital energies in Eq. (14.4.19) are not equally displaced in energy with respect to
Hα,α(Hβ,β
). Referring again to the typical case where Hα,β = −|Hα,β
| (e.g., Ex. 14.3.4e),
the stabilization (energy decrease) of the bonding molecular orbital, ε+, is shown to
be less in absolute magnitude than the destabilization (energy increase) of the anti￾bonding molecular orbital, ε− (see Ex. 14.4.4). In spite of these refinements beyond
the tight-binding assumptions, we can see that as long as the overlap between the
atomic orbitals remains substantially smaller than 1, and consistently, the integrals
hφα|Vˆ
β
|φαi,hφβ
|Vˆα|φβ
i,hφα|Vˆ
β
|φβ
i remain small in comparison to hφα|Hˆ|φβ
i, the
condition for delocalized molecular orbitals requires proximity in the atomic orbital
energies.
Exercise 14.4.4 (a) Show that solutions to the secular equation, Eq. (14.4.16), which
are perfectly delocalized (defined in Eq. (14.4.18)), correspond to the orbital energies,
ε±, as given in Eq. (14.4.19). (b) Show that the orbital energies in Eq. (14.4.19) are not
equally displaced in energy with respect to Hα,α(Hβ,β
), namely |ε+ −Hα,α| < |ε− −Hα,α|.
Similar considerations apply also when many-electron interactions are accounted
for, within the Hartree–Fock approximation. The atomic and molecular orbitals are
eigenstates of the corresponding Fock operator, which includes the mean-field terms
in addition to the single-electron terms in the Hamiltonian. The secular equation for
the optimal variation coefficients consequently involves the matrix elements of the
nonlinear molecular Fock operator. In this case, the condition for effective linear com￾bination of atomic orbitals into delocalized molecular orbitals accounts also for matrix
elements of the mean-field operators; hence, it is more cumbersome. Nevertheless, the
requirements for proximity in energy of the atomic orbitals applies similarly.
The Simple Hückel Model for Conjugated Polyene Molecules
The preceding tight-binding analysis suggests that given a proper symmetry, degener￾ate atomic orbitals from different atoms should form delocalized molecular orbitals
even in the presence of the smallest interatomic coupling. This observation is indeed
useful for qualitative understanding of the electronic structure of certain types of pol￾yatomic molecules. A remarkable example is the class of organic molecules, termed
conjugated polyenes (see Fig. 14.4.6). These molecules contain chains of carbon atoms
bonded to each other (and to hydrogen atoms) by σ-type bonds in a molecular plane.
Each carbon atom has an additional electron that, in the absence of coupling to other
atoms, would be occupied in a p-type atomic orbital, polarized in the perpendicular
direction to the molecular plane. When the carbon atomic nuclei are clumped (within
the BO approximation) at equal interatomic distances between neighboring atoms,
each of the (degenerate) p-type atomic orbitals is coupled to its neighbors. Conse￾https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press269 14.4 Linear Combinations of Atomic Orbitals (LCAO) in Molecules
quently, instead of (π-type) molecular orbitals, shared by distinctive pairs of atoms, the
molecular orbitals tend to delocalize over the entire atomic chain. These orbitals are
often referred to as “conjugated π orbitals,” and the molecule is termed a conjugated
polyene.
A simple single-electron model Hamiltonian that accounts for the molecular orbitals
in such conjugated polyenes was proposed by Hückel [14.10]. This model can be
derived from an effective single-electron Schrödinger equation (or the Hartree–Fock
equations) by invoking a set of assumptions. Each molecular orbital is approximated as
a linear combination of the p-type atomic orbitals, {|φni}, associated with the different
carbon atoms in the system. For a conjugated system of N carbon atoms, n = 1,2,...,N,
this reads
|ϕ
MO
k
i =
N
∑
n=1
c
(k)
n |φni. (14.4.21)
The optimal expansion coefficients and the corresponding molecular orbital energies
are obtained as the eigenvectors and eigenvalues of a model Hamiltonian, subject to
tight-binding assumptions. Namely, the overlap between the atomic orbitals is assumed
to be null,
Sn,m = hφn|φmi = δn,m, (14.4.22)
the diagonal (“on-site”) matrix elements of the single-particle Hamiltonian are
assumed to depend locally on the carbon atom, independently of its position along
the chain, and obtain the same value for all carbon atoms,
Hn,n = εα, (14.4.23)
and the electronic coupling between different sites is restricted to the nearest neigh￾boring atoms and denoted β, where β = −|β|, in line with the common interatomic
electronic interaction (see, e.g., Ex. 14.3.4e). Again, the nearest-neighbor couplings
between any two carbon atoms are assumed to be uniform,
Hn,m =

β ; n and m are nearest neighbors
0 ; otherwise . (14.4.24)
In Fig. 14.4.7, the secular equations for the molecular orbitals energy levels and expan￾sion coefficients are presented for two conjugated molecules of six carbon atoms,
hexatriene and benzene. The different carbon atoms are indexed according to their
position in each molecule. The apparent difference between these two molecules is
that hexatriene is linear, whereas benzene is cyclic. This difference is reflected also
in the electronic properties of these molecules, where, for example, in the electronic
ground states, benzene absorbs electromagnetic radiation at shorter wavelengths in
comparison to hexatriene, suggesting a difference in the electronic structure of the
two molecules. This difference and its relation to the molecular geometry can indeed
be revealed already at the level of Hückel’s tight-binding model, as discussed in what
follows.
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press270 Many-Atom Systems
Ftigure 14.4.6 (a) A schematic representation of a linear conjugated polyene molecule with “ π-type bonds” between carbon atoms.
(b) The underlying “p-type” atomic orbitals with electronic density polarized perpendicularly to the plane defined by
the atom nuclei. (c) Illustration of two equivalent arrangements of “ π bonds” between neighbouring carbon atoms in
a uniform infinite chain.
The molecular geometry is reflected in different “boundary conditions” at the ter￾minal atoms in each chain. In the linear case, each terminal atom (corresponding to
index 1 or 6) has only one neighbor (“reflecting” boundary conditions), whereas in the
cyclic case, these atoms are not different from any other atom along the chain (peri￾odic boundary conditions), where each of them has two neighbors. Within the Hückel
model, the periodic boundary conditions are included in the Hamiltonian matrix in
terms of two additional nonzero entries, H1,6 = H6,1 = β (see Fig. 14.4.7). The conse￾quences with respect to the orbitals and the orbital energy levels are readily revealed
from the solutions to the secular equations (see Ex. 14.4.5):
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press271 14.4 Linear Combinations of Atomic Orbitals (LCAO) in Molecules
Figure 14.4.7 t Two six-membered polyene molecules and the corresponding secular equations for the atomic orbital coefficients
within the π-system. Notice the difference in connectivity: atoms 1 and 6 are neighbors in benzene, but not in
hexatriene, which corresponds to additional entries in the respective Hamiltonian matrix.
For a uniform linear chain of N sites, the orbital energy levels obtain the form
ε
(k) = εα +2β cos
πk
(N +1)

; k = 1,2,...,N, (14.4.25)
and the corresponding normalized expansion coefficients are
c
(k)
n =
r
2
N +1
sin
nπk
(N +1)

. (14.4.26)
For a cyclic uniform chain of N sites (N > 2), the orbital energy levels obtain the form
ε
(k) = εα +2β cos
2πk
N

; k = 1,2,...,N, (14.4.27)
and the corresponding normalized expansion coefficients are
c
(k)
n =
1
√
N
e
−i
2πkn
N , (14.4.28)
where c
(k)
n = c
(k)
n+N
.
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press272 Many-Atom Systems
−2β cos(—) 7
π −2β
2β
−β
β
ε − εα ε − εα
−2β cos( 7
2π )
−2β cos( 7
3π )
2β cos( 7
3π )
2β cos( 7
2π )
2β cos( 7
π )
Ftigure 14.4.8 Illustration of delocalized molecular orbitals for the π electrons in hexatriene and benzene according to the simple
Hückel model, at the corresponding orbital energies, expressed in terms of the atomic (on-site) orbital energies εα
and the interatomic, nearest-neighbor coupling matrix element, β. The area of the circle around each atom center is
proportional to the squared coefficient of the respective atomic orbital in the expansion of each molecular orbital. The
different shades correspond to sign alternations in each molecular orbital.
Exercise 14.4.5
(a) The secular equation for the Hückel model for a uniform linear chain reads (see
Fig. 14.4.7)



(εα −εk)c
(k)
1 +βc
(k)
2 = 0 ; n = 1
βc
(k)
n−1 + (εα −εk)c
(k)
n +βc
(k)
n+1 = 0 ; 1 < n < N.
βc
(k)
N−1 + (εα −εk)c
(k)
N = 0 ; n = N
Show that the orbital energies (Eq. (14.4.25)) and coefficients (Eq. (14.4.26))
satisfy these secular equations. Show that
N
∑
n=1
(c
(k)
n )
2 = 1.
(b) The secular equation for the Hückel model for a uniform cyclic chain reads (see
Fig. 14.4.7)



(εα −εk)c
(k)
1 +βc
(k)
2 +βc
(k)
N = 0 ; n = 1
βc
(k)
n−1 + (εα −εk)c
(k)
n +βc
(k)
n+1 = 0 ; 1 < n < N.
βc
(k)
1 +βc
(k)
N−1 + (εα −εk)c
(k)
N = 0 ; n = N
Show that the orbital energies (Eq. (14.4.27)) and coefficients (Eq. (14.4.28))
satisfy these secular equations. Show that
N
∑
n=1
(c
(k)
n )
2 = 1.
The results of the Hückel model for the conjugated π orbitals in hexatriene and
benzene are illustrated in Fig. 14.4.8. The orbital energies are calculated according to
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press273 14.5 Extended Systems and Energy Band Formation
Eqs. (14.4.25, 14.4.27) by setting N = 6. As we can see, the differences in the molecu￾lar geometry are reflected in the orbital energies. Particularly, degenerate π orbitals
appear only in the cyclic system (benzene), which is reminiscent of the degeneracy
encountered for a particle-on-a-ring energy, discussed in Section 5.4. Another appar￾ent difference between the two systems is the energy gap between the Highest Occupied
Molecular Orbital (HOMO) and the Lowest Unoccupied Molecular Orbital (LUMO).
The HOMO and LUMO can be identified in each case by populating the molecular
orbitals of the conjugate π system according to the Pauli exclusion and the Aufbau
principles (see Chapter 13), recalling that each carbon atom contributes a single elec￾tron to the system. The Pauli exclusion principle means that at the electronic ground
state only half of the orbitals will be populated by electrons. Inspecting the results of
the Hückel model, the gap between the HOMO and LUMO energies is indeed larger
for the cyclic molecule. Since this gap defines the minimal electronic excitation energy,
the model prediction is that the excitation energy in benzene should be larger than
the excitation energy in hexatriene. This is in qualitative agreement with the meas￾ured absorption spectra of the two molecules (in the UV regime of the electromagnetic
radiation), where benzene absorbs at shorter wavelengths.
The results of the Hückel model (Eqs. (14.4.25, 14.4.27)) reveal another important
aspect of conjugated π systems, which characterizes also extended solid-state systems
(to be discussed in the next section): The spacing between neighboring orbital energies
decreases as the number of sites in the system increases. This is another manifestation
of the quantum size effect, introduced in Chapter 5, where the “size” of the system
is correlated here with the number of coupled atomic sites. For a linear chain, this
principle reads (see Ex. 14.4.6)
ε
(k+1) −ε
(k) = 2β

cos
(k +1)π
(N +1)

−cos
kπ
(N +1)
 −−−→
N→∞
0, (14.4.29)
whereas for a cyclic chain we have
ε
(k+1) −ε
(k) = 2β

cos
2(k +1)π
N

−cos
2kπ
N
 −−−→
N→∞
0. (14.4.30)
Exercise 14.4.6 Prove the asymptotic results in Eqs. (14.4.29, 14.4.30).
14.5 Extended Systems and Energy Band Formation
The perception of chemical bonding within the BO and the orbital approximations is
extendable also to solid crystals, composed of different materials (insulators, conduc￾tors, or semiconductors) with different types of chemical bonds (ionic, molecular, or
metallic). The number of atoms in such systems can be astronomically large, and yet
the principles outlined so far are useful for analyzing the physical properties (e.g., elec￾tric conductivity, interaction with radiation) as well as chemical properties (stability,
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press274 Many-Atom Systems
reactivity) of such extended systems. An important characteristic of crystalline materi￾als is their periodic structure at their ground (minimal energy) state. The invariance of
the electron-pair interaction to translation implies that the periodicity is attributed to
the underlying single-electron potential energy. Consequently, the entire crystal can be
mapped by discrete translations of a unit-cell Hamiltonian, containing a finite num￾ber of atoms (or order 1–100, typically). This simplifies considerably the theoretical
description within the orbital approximation by restricting each orbital to satisfy the
same periodic boundary conditions. Notice, however, that at the crystal boundaries
(surfaces), the translational symmetry is broken, and the finite dimensions of the crys￾tal must be accounted for, giving rise to quantum size effects on top of the effect of
the underlying crystal unit cell. This boundary effect is particularly important for
nanocrystals (see the discussion of envelope functions in Section 12.2). In this sec￾tion we focus on extended, infinitely periodic crystals, representing bulk materials. For
simplicity, our introduction to the subject will be restricted to one spatial dimension,
where the generalization to a three-dimensional lattice will be mentioned only briefly.
Let us envision an infinitely periodic linear chain of atoms as appear in an ordered
crystal (see Fig. 14.5.1). Each atom is associated with a single positive nucleus (clumped
at its minimal energy position, within a BO framework) and several (many) electrons.
If the electron–electron interaction is neglected, each electron in the system can be
regarded separately as a particle in a system of identical multiple potential wells. As
we shall see, the single-particle states (orbitals) in such a system are delocalized over the
entire lattice (see also Section 6.5). The same picture holds if electron–electron inter￾actions are accounted or within a mean-field (orbital) approximation, where the Fock
operator (Eqs. (13.3.18–13.3.20)) obtains the lattice periodicity. In what follows we first
analyze the exact solutions to the Schrödinger equation for a single particle in a contin￾uous, infinitely periodic, one-dimensional potential, introducing Bloch’s theorem, and
then we apply a variational LCAO approach within the tight-binding approximation
to the same problem.
The Bloch Theorem
The Schrödinger equation for a particle of mass m in a periodic one-dimensional
potential, with a lattice period, a, along the x coordinate, −∞ < x < ∞, reads

−h¯
2
2m
∂
2
∂ x
2
+V(x)−E

ψ(x) = 0 ; V(x) = V(x+a), (14.5.1)
where the periodic potential energy can be expanded as a Fourier series,
V(x) =
∞
∑n=−∞
Vne
i2πn
a
x
. (14.5.2)
It is useful in this case to expand the proper solutions to the Schrödinger equa￾tion as (Fourier) integrals over an orthonormal set of one-dimensional plane waves
(Eq. (11.5.22)),
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press275 14.5 Extended Systems and Energy Band Formation
n−1
V(x)
x
(n−2)a (n−1)a na (n+1)a
n n+1
Ftigure 14.5.1 Illustration of an infinitely periodic atomic lattice (three periods are presented), and a corresponding effective
single-particle potential with the lattice period(a).
ψ(x) = 1
√
2π
w∞
−∞
e
ikxψ(k)dk ; ψ(k) = 1
√
2π
w∞
−∞
e
−ikxψ(x)dx, (14.5.3)
where k = px/h¯ is the wave vector that corresponds to the momentum, px. Substituting
the expansionψ(x)in the Schrödinger equation (Eq. (14.5.1)) and projecting on a plane
wave, e
ikx, we obtain (see Ex. 14.5.1)
∞
∑n=−∞

Vn +δn,0

h¯
2
k
2
2m
−E
Ψ

k −
2π
a
n

= 0. (14.5.4)
The differential equation in the coordinate representation therefore translates into an
algebraic equation in the wave vector representation, where, according to Eq. (14.5.4),
the value of ψ(k) at each point in k-space depends on its value at a discrete (infinite)
set of points, k −
2π
a
n, where n is an integer (−∞ < n < ∞). To obtain these values, the
Schrödinger equation can be projected on the corresponding full set of plane waves,
{e
i(k−
2π
a
n)x
}, which yields a closed (infinite) set of coupled equations for ψ(k) at the set
of points (see Ex. 14.5.1):
∞
∑
n
0=−∞
"
Vn
0−n +δn,n
0
 
h¯
2
2m

k −
2π
a
n
2
−E
!#ψ

k −
2π
a
n
0

= 0 ; −∞ < n < ∞.
(14.5.5)
Recalling the integral definition of ψ(k) (Eq. (14.5.3)) and changing the integration
variable, we can readily see that the functions, ψ(x) and e
−ikaψ(x + a), correspond
precisely to the same set of values, {ψ
￾
k −
2πn
a

,−∞ < n < ∞}, where
ψ

k −
2πn
a

=
1
√
2π
w∞
−∞
e
i
2π
a
nxe
−ikxψ(x)dx =
1
√
2π
w∞
−∞
e
i
2π
a
nxe
−ikx
e
−ikaψ(x+a)dx,
(14.5.6)
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Pres276 Many-Atom Systems
which means that the corresponding solutions to the Schrödinger equation are
indistinguishable; namely, each solution to the Schrödinger equation with a periodic
potential energy (Eqs. (14.5.1–14.5.2) satisfies an identity,
ψ(x+a) = e
ikaψ(x). (14.5.7)
This result is referred to as the Bloch theorem [14.11]. It means that the single-particle
wave functions (the orbitals) are delocalized over the entire coordinate space and are
“periodic up to a phase.” The phase, e
ika, is defined by a “Bloch wave vector,” k, and
it accumulates from one unit cell to another along the lattice. Each solution to the
Schrödinger equation is therefore denoted by its corresponding wave vector, namely
ψk(x).
Formulating equivalently the Bloch theorem, the function uk(x) ≡ e
−ikxψk(x) is
periodic in the coordinate space with the lattice period, a:
ψk(x) = e
ikxuk(x) ; uk(x) = uk(x+a). (14.5.8)
Expanding the periodic function in a Fourier series,
uk(x) =
∞
∑n=−∞
u
(k)
n e
i
2π
a
nx
, (14.5.9)
the expansion coefficients {u
(k)} are identified as (see Ex. 14.5.1)
u
(k)
n =
1
√
2π
ψ

k +
2πn
a

, (14.5.10)
which can be obtained explicitly by solving the Bloch equations, Eq. (14.5.5), where,
in practice, a finite truncation of the infinite summation is often sufficiently accu￾rate. Notice that the same derivation applies to a three-dimensional periodic lattice,
where the wave functions ψk(x) and uk(x) become three-dimensional, and k is replaced
by the three-dimensional wave vector (e.g., k = (kx, ky, kz)) defined according to the
parameters of the three-dimensional unit cell.
An important consequence of Eqs. (14.5.8–14.5.10) is that solutions to the
Schrödinger equation associated with the Bloch wave vectors, k and k +
2π
a
n, are
identical (see Ex. 14.5.1):
ψk(x) = ψk+2πn/a
(x). (14.5.11)
This means that all the physically distinguishable values of the Bloch wave vector,
namely the set of k values that correspond to linearly independent solutions of the
Schrödinger equation, are confined within a finite interval (termed the first Brillouin
zone [12.3]):
−
π
a
< k ≤
π
a
. (14.5.12)
For each value of k, explicit solutions to the Schrödinger equation depend on the peri￾odic functions uk(x), namely on the corresponding sets of Fourier coefficients, {u
(k)
n }.
The latter can be calculated using the relation, Eq. (14.5.10). Rearranging Eq. (14.5.5),
the sets {u
(k)
n } comprise the eigenvectors of an algebraic eigenvalue equation,
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press277 14.5 Extended Systems and Energy Band Formation
∞
∑
n
0=−∞
Hn,n
0u
(k)
n
0 = Eu
(k)
n ; −∞ < n < ∞, (14.5.13)
where
Hn,n
0 =
"
Vn−n
0 +δn,n
0
h¯
2
2m

k +
2πn
a
2
#
. (14.5.14)
Assigning an additional quantum number to the different solutions of this eigenvalue
equation, l = 0,1,... (a nonnegative integer, for simplicity and without loss of gen￾erality), each eigenvalue and a corresponding eigenfunction of the one-dimensional
Schrödinger equation for the particle in an infinitely periodic potential is associated
with two quantum numbers (clearly, more quantum numbers are needed at higher
dimensions):
ψk,l(x) = e
ikxuk,l(x) ↔ Ek,l
; l = 0,1,... ; −
π
a
< k ≤
π
a
, (14.5.15)
where uk,l(x) =
∞
∑
n=−∞
u
(k,l)
n e
i
2π
a
nx
. The spectrum of the periodic Hamiltonian can thus be
divided into energy bands. Each band is characterized by a specific value of the quantum
number l and a continuum of states associated with the quantum number k. When the
lattice potential is associated with “well-separated” and “deep” potential energy wells,
each of the low energy bands can be correlated with a specific bound state of a single
isolated potential well, mapped into a continuous band, as the potential is periodi￾cally continued. An example for the onset of such energy bands in a system of multiple
potential energy wells was given in Section 6.5; see Fig. 6.5.1. Notice that this simple
picture breaks down when the distance between neighboring wells becomes compara￾ble to the “width” of the particle’s probability density distribution within an isolated
well. In that case the energy width of the relevant bands broadens to the extent that
different bands may overlap. Notice also that there are no “bound states” within an
infinitely periodic lattice potential, in the sense that the wave function does not vanish
(except for at isolated points) in the entire coordinate space.
Exercise 14.5.1
(a) Derive Eq. (14.5.4) by substituting the plane wave expansion of ψ(x) in the
Schrödinger equation with a periodic potential, Eqs. (14.5.1, 14.5.2), projecting the
result on the plane wave, e
ikx, and using the representation of the delta function,
δ(k) = 1
2π
r∞
−∞
e
ikxdx.
(b) Derive Eq. (14.5.5) by substituting the plane wave expansion of ψ(x) in the
Schrödinger equation with a periodic potential, Eqs. (14.5.1, 14.5.2), projecting
the result on the plane wave, e
i(k−
2π
a
n)x
, and using the representation of the delta
function, δ(k) = 1
2π
r∞
−∞
e
ikxdx.
(c) Use the definition, uk(x) ≡ e
−ikxψk(x), and Eq. (14.5.7) to derive Eq. (14.5.8).
(d) Obtain Eq. (14.5.10) by substituting Eqs. (14.5.8, 14.5.9) in Eq. (14.5.6).
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press278 Many-Atom Systems
(e) Use the general form of the solutions to the Schrödinger equation for a periodic
potential (Eq. (14.5.7)) to prove Eq. (14.5.11).
LCAO for Extended Systems
We now turn to an approximate LCAO description of a periodic one-dimensional lat￾tice composed of a repeating unit cell of several (different, in general) atoms (see Fig.
14.5.1). The periodicity assures that the same atoms appear in neighboring cells, which
means that their atomic orbitals perfectly match in their energy as well as in their sym￾metry properties. Therefore, effective linear combinations of the atomic orbitals are
expected between different cells, and since all the cells are coupled, the orbitals in
this structure are expected to extend over the entire lattice, in accordance with the
Bloch theorem. Models based on extended “lattice orbitals,” approximated as linear
combinations of atomic orbitals, are often adequate for qualitative description of the
different electronic properties of different types of materials, as we demonstrate in the
following discussion.
Assuming that the effective potential energy well attributed to each atomic core con￾fines the electronic density associated with the atomic orbitals, such that its standard
deviation is much smaller than the interatomic distance between neighboring atoms,
a tight-binding model Hamiltonian can be invoked for the chain (see Fig. 14.4.4 and
Eqs. (14.4.3–14.4.7)). Importantly, the model assumes that the interatomic interac￾tions are “short-ranged” in the sense that the atoms within each unit cell interact only
with the two nearest-neighboring cells (otherwise, the “cell” size must be extended until
the relevant interactions are confined within the nearest-neighbors range). For simplic￾ity, and without loss of generality, our examples will invoke a stronger assumption,
namely that interatomic interactions are restricted to nearest neighbors both between
and within the cells (as in the Hückel model for finite chains, discussed in Section 14.4
(Eqs. (14.4.21–14.4.24)). Additionally, we shall consider a minimal basis of a single
atomic orbital from each atom along the chain. This is justified when the selected
atomic orbitals are well separated in energy from the other atomic orbitals within each
atom (in comparison to the interatomic interaction matrix elements).
Denoting each unit cell by an integer, −∞ < n < ∞, and the atoms within the unit cell
by another integer, m = 1,2,...,M (see Fig. 14.5.1), each atom, and hence each atomic
orbital, |φm,ni, is identified by these two indexes. The lattice orbitals are introduced as
linear combinations of the atomic orbitals,
|ϕli =
∞
∑n=−∞
M
∑
m=1
c
(l)
m,n|φm,ni, (14.5.16)
where the expansion coefficients and the corresponding lattice orbital energies, εl
, are
obtained according to the linear variation method as the eigenvectors and eigenvalues
of the (infinite-dimensional) secular equation (Eq. 12.3.24):
Hc(l) =εlSc(l)
. (14.5.17)
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press279 14.5 Extended Systems and Energy Band Formation
The matrix representation of the system Hamiltonian and the overlap matrix are sub￾ject to the tight-binding model assumptions (Eqs. (14.4.5–14.4.7)), which take the
explicit form,
S(n
0
,m0),(n,m) ≡ hφn
0
,m0|φn,mi = δn,n
0δm,m0, (14.5.18)
H(n
0
,m0),(n,m) ≡



αm ; n = n
0
,m = m
0
βm0
,m ; (n
0
,m
0
) and (n,m) correspond to nearest neighbors
0 ; otherwise.
(14.5.19)
Notice that the lattice periodicity means that the entries of H depend only on the
internal indexes within each cell, and not on the cell index,
H =


















.
.
. βM−1,M
βM−1,M αM βM,1
βM,1 α1 β1,2
β1,2 α2 β2,3
β2,3
.
.
.
βM−1,M
βM−1,M αM βM,1
βM,1 α1 β1,2
β1,2
.
.
.


















.
(14.5.20)
The Hamiltonian matrix can therefore be conveniently represented as a block matrix,
H =








.
.
. β
β
t α β
β
t α β
β
t α β
β
t
.
.
.








, (14.5.21)
where the matrices α and β are defined in the space of a single unit cell,
α =







α1 β1,2
β1,2 α2 β2,3
β2,3
.
.
.
αM−1 βM−1,M
βM−1,M αM







; β =







0 0 0 0 0
0 0 0 0 0
0 0
.
.
.
0 0 0 0
βM,1 0 0 0







.
(14.5.22)
Information attributed to the chemical composition of the material is encoded here
in the on-site atomic orbital energies, α1,α2,...,αM, and in the intersite couplings,
β1,2,β2,3,...,βM−1,M,βM,1.
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press280 Many-Atom Systems
One can readily verify (Ex. 14.5.2) that the eigenvector elements that satisfy the
secular equation (Eq. (14.5.17)) are of a product form,
c
(l)
m,n = u
(l,
˜k)
m e
i
˜kn ; u
(l,
˜k)
m = u
(l,
˜k)
m+M, (14.5.23)
where the vector (u
(l,
˜k)
1
,u
(l,
˜k)
2
,...,u
(l,
˜k)
M ) ≡ u
(l,
˜k)
is the solution of a reduced eigenvalue
equation within the space of a single unit cell,
h
α+β
t
e
−i
˜k +βe
i,
˜k
i
u
(l,
˜k) = εl(
˜k)u
(l,
˜k)
; l = 1,2,...,M. (14.5.24)
The result is nothing but a discrete version of Bloch’s theorem, Eq. (14.5.8). The eigen￾vectors to the secular equation, Eq. (14.5.17), are products of a phase factor, e
i
˜kn, which
depends only on the “external” unit cell index, n, and a vector u
(l,
˜k)
, which is independ￾ent of the cell index; namely, its elements are replicated periodically along the entire
lattice with the unit cell periodicity (M). Notice that the dimensionless parameter ˜k
is continuous. However, the solutions to the secular equation are invariant to changes
˜k → ˜k+2πn, which means that the independent solutions are confined to a finite range,
−π < ˜k < π. Moreover, dividing by the unit cell length, k = ˜k/a and associating each
cell with a position along the real coordinate axis, xn = na, we can identify e
i
˜kn with the
continuous Bloch wave, e
ikx:
e
i
˜kn = e
ikna = e
ikxn
; −π/a < k ≤ π/a. (14.5.25)
Each eigenvalue and eigenvector of the infinite chain Hamiltonian are therefore
defined by two indexes, ˜k and l. The spectrum of the lattice Hamiltonian is composed
of continuous energy bands, where each of the M eigenvalues of the effective unit cell
Hamiltonian, that is, ε1(
˜k), ε1(
˜k),..., εM(
˜k) (see Eq. (14.5.24)), is a continuous function
of the Bloch wave vector ˜k. The corresponding eigenvectors are Bloch waves, extend￾ing through the entire lattice, multiplied by a periodic vector, with the unit cell period,
which depends on both ˜k and l.
Exercise 14.5.2
(a) Defining the “unit cell” coefficient vector, c
(l)
n = (c
(l)
1,n
, c
(l)
2,n
,..., c
(l)
M,n
) and using
Eq. (14.5.18) for the matrix S and Eq. (14.5.21) for the Hamiltonian, H, show
that the secular equation (Eq. (14.5.17)) reads β
t
c
(l)
n−1 +[α−εlI]c
l
n +βc
(l)
n+1 = 0.
(b) Use the ansatz c
(l)
n = u
(l,
˜k)
e
i
˜kn, where u
(l,
˜k) ≡ (u
(l,
˜k)
1
,u
(l,
˜k)
2
,...,u
(l,
˜k)
M ), to show that
the unit cell vectors, {u
(l,
˜k)}, are the eigenvectors of a finite-dimensional Hermitian
matrix, [α +β
t
e
−i
˜k +βe
i
˜k
]u
(l,
˜k) = εl(
˜k)u
(l,
˜k)
, f orl = 1,2,...,M.
Conductors and Insulators
Let us consider a specific example, in which there are only two atoms in the unit cell
of a periodic lattice (M = 2). We shall denote the corresponding two atomic orbital
energies of the neighboring atoms as α1,α2 = ∆,−∆, and the coupling matrix element
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press281 14.5 Extended Systems and Energy Band Formation
Ftigure 14.5.2 Band energies for different periodic lattices with two atoms per unit cell (M = 2). (a) The two atomic orbitals are
identical(∆ = 0), yielding a single band with a bandwidth, 4|β|. (b) The difference in the atomic orbital energies is
of the order of the interatomic coupling matrix element, yielding two bands, separated by 2∆. (c) The difference in
atomic energies is much larger than the interatomic coupling matrix element, resulting in much narrower bands,
separated by 2∆.
between them as β. The corresponding α and β matrices composing the infinite lattice
Hamiltonian (Eqs. (14.5.21, 14.5.22)) are
α =

∆ β
β −∆

; β =

0 0
β 0

, (14.5.26)
and accordingly, the reduced (single-cell) eigenvalue equation for the band energies and
eigenfunctions (Eq. (14.5.24)) obtains the form


∆−εl(
˜k) β

1+e
i
˜k

β

1+e
−i
˜k

−∆−εl(
˜k)


"
u
(l,
˜k)
1
u
(l,
˜k)
2
#
=

0
0

. (14.5.27)
The two eigenvalues for each wave vector ˜k therefore read (Ex. 14.5.3)
ε±(
˜k) = ±
q
∆2 +4β
2 cos2(
˜k/2) ; −π < ˜k ≤ π. (14.5.28)
The spectrum of the periodic lattice with M = 2 is shown to be grouped into two con￾tinuous bands. Since the function cos2
(
˜k/2) is bounded between 0 and 1, each band
has a finite energy range,
|∆| < ε+(
˜k) <
p
∆2 +4β
2
−
p
∆2 +4β
2 < ε−(
˜k) < −|∆|
; −π < ˜k ≤ π. (14.5.29)
As we can see, the bands are separated by an energy gap between −|∆| and |∆|
(see Fig. 14.5.2).
Exercise 14.5.3 Calculate the eigenvalues, εl(
˜k), of the secular equation, Eq. (14.5.27),
and obtain the results in Eq. (14.5.28).
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press282 Many-Atom Systems
The population of the lattice orbitals by electrons at the ground state depends on
the number of electrons populating the corresponding atomic orbitals. As an exam￾ple, let us consider a case in which the relevant atomic orbital is “half field” in the
ground state of each single atom (this would be the case, e.g., for the highest occupied
(valence) orbitals of alkali metal atoms); namely, each atomic orbital contributes a
single electron to the system of lattice orbitals. Since the number of independent eigen￾vectors of the secular equation (lattice orbitals) equals the number of atomic orbitals,
and since the Aufbau principle means that the orbitals are doubly occupied from the
lowest energy and upward, only half of the lattice orbitals would be populated at the
electronic ground state. In the present model, this implies that only the lowest of the
two energy bands would be populated with electrons.
Now let us consider the possibility of electric conductance in the different cases. Net
flow of charges through the lattice necessitates their acceleration, namely an increase in
their kinetic energy. In the example of a fully occupied lower energy band, this would
require overcoming the energy “band gap” to the higher unoccupied energy levels. In
cases where this gap is much larger than the thermal energy or the applied bias voltage,
electric conductance would be blocked, and the material would behave as an insula￾tor. If, on the other hand, the energy gap is relatively small (or vanishes), the material
would behave as a conductor. The presence of an “energy gap” in the spectrum near the
highest occupied lattice orbital therefore has dramatic consequences with respect to the
electric conductance of the material. In what follows we discuss the relation between
the formation of an energy gap and the chemical composition of the underlying mate￾rial (e.g., ionic vs. metallic), using the theoretical model of a one-dimensional atomic
lattice at equal interatomic distances, with half-filled orbitals. Two extreme cases are
analyzed in detail, corresponding to a conductor and an insulator.
Case I: A uniform unit cell (a conductor model)
In the first case we consider a hypothetical chain of clamped identical atoms, in
which all the interatomic distances and nearest-neighbor coupling matrix elements are
the same along the entire chain. The identity of the atoms is imposed by setting to
zero the difference in their atomic orbital energies, namely, ∆ = 0 in Eq. (14.5.26). As
one can readily see from Eqs. (14.5.28, 14.5.29), the two bands merge in this case into
a single continuous band (see Fig. 14.5.2(a)). Defining ˜k/2 =
˜˜k, the entire spectrum
depends on a single quantum number, where Eq. (14.5.28) compactly reduces to
ε(
˜˜k) = 2β cos(
˜˜k) ; −π <
˜˜k ≤ π, (14.5.30)
where the bandwidth equals 4|β|. Each ˜˜k defines an eigenvector of the 2 × 2 unit-cell
Hamiltonian (see Eq. (14.5.27)), where, in this case, the coefficients of the two atomic
orbitals within the unit cell relate to each other as (see Ex. 14.5.4)
u
(
˜˜k)
2
/u
(
˜˜k)
1 = e
−i
˜˜k
. (14.5.31)
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press283 14.5 Extended Systems and Energy Band Formation
The identity of the two atoms within the unit cell, therefore, has two consequences.
First, all the lattice orbitals are evenly distributed (perfectly delocalized) among the
two atoms in each unit cell, in the sense that
|u
(
˜˜k)
1
|
2 = |u
(
˜˜k)
2
|
2
. (14.5.32)
Second, there is no energy gap between the highest occupied lattice orbital and the
lowest unoccupied lattice orbital, which implies that this model system corresponds to
a conductor.
Notice that, as expected, this model resembles that of a uniform chain of N identical
sites, subject to periodic boundary conditions, in the limit N → ∞. Setting the on-site
energy to zero, the eigenvalues read (Eq. (14.4.27)) εl = 2β cos￾
2πl
N

, with l = 1,2,...,N.
As N → ∞, the argument 2πl/N covers continuously a single period of the cosine func￾tion, which coincides with Eq. (14.5.30). The corresponding eigenvectors of a uniform
chain under periodic boundary conditions (Eq. (14.4.28)) also satisfy a similar relation
to Eq. (14.5.31), c
(l)
m+1
/c
(l)
m = e
−i
2πl
N .
Case II: A nonuniform unit cell (an insulator model)
In the second limiting case we consider the two atoms within each unit cell to be
“very different” from each other, in the sense that the difference in their on-site atomic
orbital energies exceeds by far the interatomic coupling matrix element. Choosing
∆ > 0, we assume
∆ >> |β|. (14.5.33)
The two bands (Eq. (14.5.28)) are separated in this case by an energy gap (see Figs.
14.5.2 (b), 14.5.2 (c)), and we obtain the form
ε±(
˜k) ≈ ±∆

1+
2β
2
∆2
cos2
(
˜k/2)

; −π < ˜k ≤ π, (14.5.34)
where each bandwidth is ∼ 2β
2/∆.
Substitution of the band energies in the secular equation for the lattice orbitals
(Eq. (14.5.27)) reveals a remarkable difference between the orbitals in the different
bands. Particularly, the ratio between the coefficients associated with the two atomic
orbitals within the unit cell differs in the two bands, where (see Ex. 14.5.4))
u
(+,
˜k)
2
u
(+,
˜k)
1
=
β
∆
e
−i
˜k/2
cos(
˜k/2) ;
u
(−,
˜k)
1
u
(−,
˜k)
2
= −
β
∆
e
i
˜k/2
cos(
˜k/2). (14.5.35)
Since |∆| >> |β|, this means that
|u
(+,
˜k)
1
|
2 >> |u
(+,
˜k)
2
|
2
; |u
(−,
˜k)
1
|
2 << |u
(−,
˜k)
2
|
2
(14.5.36)
In the upper energy band, ε+(
˜k), the orbitals are primarily localized on the first site in
each cell, corresponding to the atomic orbital energy, ∆, whereas in the lower energy
band, ε−(
˜k), the orbitals are primarily localized on the second site in each cell, cor￾responding to the atomic orbital energy, −∆. The result is not surprising, considering
that effective linear combinations of atomic orbitals require matching in their energies.
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Pres284 Many-Atom Systems
Regarding each unit cell as an atom pair, a difference in the two atomic orbital ener￾gies that exceeds the coupling matrix element between them means that the “molecular
orbitals” within the pair would remain localized on the respective atoms (as in an
ionic material; see Fig. 14.4.5(c), and the related discussion). Notice, however, that
in the lattice, identical atoms belonging to neighboring unit cells are still coupled indi￾rectly through the other atom in the unit cell. The effective coupling matrix element
between the identical atoms is relatively small, and in this case equals βe f f ≈ β
2/(2∆)
(see Ex. 14.5.5). Yet, since the respective orbitals are degenerate in energy, this cou￾pling results in delocalized lattice orbitals along the entire lattice. Each kind of atom
is therefore associated with a relatively narrow band, whose width is ∼ 4βe f f = 2β
2/∆,
where the two bands are separated by an energy gap, 2∆. From a chemical point of
view, the situation depicted in this model (∆ >> |β|) is typical to cases in which the
valence orbitals of the different atoms within the unit cell are far in energy from each
other, which is commonly the case in ionic crystals (see, e.g., Fig. 14.4.3c). In the half￾filling model previously discussed, the lower of the two bands is fully occupied at the
electronic ground state, and when the energy gap to the next (conductance) band is
much larger than the thermal energy and/or an applied bias voltage, these materials
are insulators.
Exercise 14.5.4 (a) Use Eq. (14.5.30) for the band energies (corresponding to ∆ = 0)
in the secular equation for the unit cell coefficients (Eq. (14.5.27)) to obtain the rela￾tion between the coefficients as given in Eq. (14.5.31) (recall that ˜k/2 =
˜˜k). (b) Use
Eq. (14.5.34) for the two band energies (corresponding to ∆ >> |β|) in the secular
equation for the unit cell coefficients (Eq. (14.5.27)) to obtain the relations between
the coefficients, as given in Eq. (14.5.35).
Exercise 14.5.5 Consider a tight-binding model Hamiltonian for two degenerate atomic
orbitals coupled indirectly through a third, nondegenerate atomic orbital,
H =


∆ β 0
β −∆ β
0 β ∆

.
In the case ∆ >> |β| the corrections to the energy of the two degenerate states can be
calculated using perturbation theory, where H = H0 +V:
H0 =


∆ 0 0
0 −∆ 0
0 0 ∆

 ; V =


0 β 0
β 0 β
0 β 0

.
Denoting the local atomic orbitals as {|φni, n = 1,2,3}, we chose a symmetric and an
antisymmetric linear combination as two degenerate zero-order vectors, |ψ
(0)
s i = (|φ1i+
|φ3i)/
√
2, |ψ
(0)
a i = (|φ1i −|φ3i)/
√
2, and a third, localized eigenvector, |ψ
(0)
2
i = |φ2i.
(a) Show that the first-order corrections to the two degenerate state energies vanish.
(b) Show that the second-order correction to the antisymmetric state energy vanishes.
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press285 Bibliography
(c) Show that the second-order correction to the symmetric state energy reads
E
(2)
s =
β
2
∆
.
(d) Show that the resulting energy splitting between |ψ
(0)
s i and |ψ
(0)
a i, induced by
the coupling to |ψ
(0)
2
i, is equivalent to the splitting induced by a direct cou￾pling matrix element, βe f f =
β
2
2∆
, within an effective two-state Hamiltonian,
He f f =

0 βe f f
βe f f 0

.
Bibliography
[14.1] P. Kirkpatrick and C. Ellis, “Chemical space,” Nature 432, 823 (2004).
[14.2] M. Born and R. Oppenheimer, “Zur Quantentheorie der Molekeln,” Annals
der Physik 389, 457 (1927).
[14.3] N. J. Turro, “Modern Molecular Photochemistry” (University Science Books,
1991).
[14.4] J. Simons, “How do low-energy (0.1–2 eV) electrons cause DNA-strand
breaks?,” Accounts of Chemical Research 39, 772 (2006).
[14.5] J. von Neumann and E. P. Wigner, “Über das Verhalten von Eigenwerten bei
adiabatischen Prozessen,” Physikalische Zeitschrift 30, 467 (1929).
[14.6] G. A. Worth and L. S. Cederbaum, “Beyond Born-Oppenheimer: Molec￾ular dynamics through a conical intersection,” Annual Review of Physical
Chemistry 55, 127 (2004).
[14.7] C. Zenner, “Non-adiabatic crossing of energy levels,” Proceedings of the Royal
Society of London A 137, 696 (1932).
[14.8] C. A. Coulson and P. D. Robinson, “Wave functions for the hydrogen atom
in spheroidal coordinates I: The derivation and properties of the functions,”
Proceedings of the Physical Society 71, 815 (1958).
[14.9] G. L. Miessler, P. J. Fischer and D. A. Tarr, “Inorganic Chemistry” (Pearson,
2014).
[14.10] E. Hückel, “Quantentheoretische Beiträge zum Benzolproblem,” Zeitschrift
für Physik 70, 204 (1931).
[14.11] F. Bloch, ”Über die Quantenmechanik der Elektronen in Kristallgittern,”
Zeitschrift für Physik 52, 555 (1929).
https://doi.org/10.1017/9781108877787.015 Published online by Cambridge University Press15 Quantum Dynamics
15.1 Time-Independent Hamiltonians
So far, our attention has almost entirely been dedicated to solutions of the time￾independent Schrödinger equation, Hˆ|ψi = E|ψi. There are two good reasons for that.
First, the information needed to describe the properties of a system at equilibrium
is fully contained in its stationary states, namely the eigenstates of its Hamiltonian.
In previous chapters we often focused on the state of minimal energy, referred to as
the ground state; however, as we shall discuss in Chapter 16, this statement holds
also for any equilibrium state. A second motivation for focusing on the eigenstates
of the system Hamiltonian relates to systems out of equilibrium, when dynamical pro￾cesses are of interest. This is the case when inherent processes within the system need
to be analyzed, or when the transient response of an equilibrated system to external
perturbations is under study. In these cases, the system is prepared (namely, driven
to) a nonstationary state, and dynamics is induced. The time-dependent Schrödinger
equation (see Eq. (4.1.1) and postulate 3, Eq. (11.1.12)) determines that infinitesi￾mal changes to the state of the system in time are attributed directly to the system
Hamiltonian, which is identified as the “generator of motion,”
ih¯
∂
∂t
|ψ(t)i = Hˆ|ψ(t)i. (15.1.1)
Restricting ourselves first to a time-independent Hamiltonian, its eigenstates are a
complete orthonormal system for expanding the physical state vector of the system,
at any point in time:
|ψ(t)i = ∑n
an(t)|φni ; {Hˆ|φni = εn|φni}. (15.1.2)
(Without loss of generality, we consider here a discrete set of nondegenerate eigen￾states.) The information with respect to the dynamics in the system is therefore encoded
in the Hamiltonian eigenstates and in the expansion coefficients. These coefficients are
obtained by substitution of the expansion in the Schrödinger equation, Eq. (15.1.1).
Projecting on the bra states, {hφm|}, yields for any m
ih¯
∂
∂t
am(t) = ∑n
an(t)hφm|Hˆ|φni = εmam(t). (15.1.3)
The coefficients are the solutions of this differential equation, which read
286
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press287 15.1 Time-Independent Hamiltonians
am(t) = am(0)e
−iεmt
h¯ , (15.1.4)
and the state of the system at any time (Eq. (15.1.2)) reads
|ψ(t)i = ∑n
an(0)e
−iεnt
h¯ |φni. (15.1.5)
Any solution to the time-dependent Schrödinger equation with a time-independent Ham￾iltonian is therefore a linear combination of the stationary solutions to this equation (see
Ex. 15.1.1 and Sections 4.3–4.6 for an introduction to stationary solutions):
|ψ(t)i = ∑n
an(0)|ψn(t)i ; |ψn(t)i = e
−iεnt
h¯ |φni. (15.1.6)
Projecting the expansion at t = 0 on the bra states, {hφm|}, yields for any m
am(0) = hφm|ψ(0)i. (15.1.7)
As we can see, the expansion coefficients are fully defined by the initial state of the
system (its “preparation”). Any dynamical process in a system with a time-independent
Hamiltonian therefore corresponds to a superposition of time-dependent stationary
waves, often termed a “coherent wave packet” (see also Section 4.2). Time evolution
of a state of a system can hence be regarded as a time-dependent interference between its
Hamiltonian eigenstates.
Exercise 15.1.1 A stationary solution to the time-dependent Schrödinger equation is
defined as |ψn(t)i = e
−iεnt
h¯ |φni, where |φni, is an eigenstate of the system Hamilto￾nian, Hˆ|φni = εn|φni (see Section 4.3). Show that any linear combination of stationary
solutions is also a solution to the time-dependent Schrödinger equation with the same
time-independent Hamiltonian, ih¯
∂
∂t
|ψ(t)i = Hˆ|ψ(t).
We now turn to evaluation of the time-dependence of the results of measurements
performed on a system undergoing time evolution. We first recall that the state |ψ(t)i
corresponds to a statistical ensemble of different realizations of the system, and that
the statistical distribution of any measurable quantity at time t can be expressed in terms
of an expectation value of a suitable Hermitian operator,
hψ(t)|Oˆ|ψ(t)i ≡ O(t). (15.1.8)
For example, the probability of measuring a specific (nondegenerate) eigenvalue χ of
an operator Aˆ is obtained by defining a projection operator into the corresponding
eigenstate, Oˆ
χ ≡ |χihχ|, where the time-dependence of the probability measurement
reads (see Section 11.1, postulate 4)
Pχ(t) = |hχ|ψ(t)i|2 = hψ(t)|χihχ|ψ(t)i ≡ hψ(t)|Oˆ
χ|ψ(t)i = Oχ(t). (15.1.9)
Similarly, the probability of measuring any eigenvalue χ of an operator Aˆ within a
specified part of its spectrum (e.g., the set {χ}) is obtained by a projector into the
subspace of specified corresponding eigenstates, Oˆ
{χ} ≡ ∑
χ∈{χ}
|χihχ|, where
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press288 Quantum Dynamics
P{χ}
(t) = ∑
χ∈{χ}
|hχ|ψ(t)i|2 = ∑
χ∈{χ}
hψ(t)|χihχ|ψ(t)i ≡ hψ(t)|Oˆ
{χ}
|ψ(t)i = O{χ}
(t).
(15.1.10)
Eq. (15.1.8) clearly holds also for a measurement of the statistical average of any
dynamical variable represented by an operator Aˆ (see Eq. (11.7.1)),
hA(t)i = hψ(t)|Aˆ|ψ(t)i ≡ A(t), (15.1.11)
where we recall (Eq. (11.7.2)) that any (Hermitian) Aˆ can be formally expressed as a
weighted sum of projection operators into its eigenstates, Aˆ = ∑
χ
χ|χihχ| = ∑
χ
χOˆ
χ.
Since any Hermitian operator (Oˆ, Eq. (15.1.8)), can be represented in terms of the
Hamiltonian eigenstates (Section 11.2) as defined in Eq. (15.1.2),
Oˆ = ∑n,m
0m,n|φmihφn|, (15.1.12)
the time-dependence of the statistical distribution of any measurable quantity on the
system can be expressed in terms of the stationary states of the system, namely, as a
superposition of oscillatory waves, whose frequencies are defined by the energy differences
between the Hamiltonian eigenvalues,
ωn,m ≡
εn −εm
h¯
. (15.1.13)
This can be readily verified by explicit calculation of the expectation value of Oˆ, using
the expansion of |ψ(t)i in the Hamiltonian eigenstates, Eq. (15.1.5) (see Ex. 15.1.2),
O(t) = ∑n,m
γn,me
−iωn,mt
. (15.1.14)
The set of coefficients {γn,m } depends on the initial preparation of the system, namely,
on the set of initial expansion coefficients {an(0)} (see Eq. (15.1.7)) and on the selected
observable to be measured (via the matrix elements of the corresponding operator,
{om,n}),
γn,m = a
∗
m(0)an(0)om,n. (15.1.15)
Notice that in the case of a stationary state, an(0) = δn,m and consequently γn,m ∝ δn,m,
where any observable is time-independent (see Eq. (15.1.14) and Sections 4.3, 4.4).
Also notice that in the general (nonstationary) case, system observables corresponding
to operators that commute with the system Hamiltonian are constants of motion. This
can be readily seen from Eqs. (15.1.1, 15.1.8),
d
dt
hψ(t)|Oˆ|ψ(t)i = hψ(t)|
i
h¯
[Hˆ,Oˆ]|ψ(t)i. (15.1.16)
We can therefore summarize that dynamical processes in a system, characterized by
a time-independent Hamiltonian, are fully described in terms of the Hamiltonian
eigenstates, and particularly, on their projections on the initial state. Nonstationary
solutions to the time-dependent Schrödinger equations are merely specific super￾positions of stationary ones. Notice, however, that although formally correct, the
representation of the system dynamics in terms of the Hamiltonian eigenstates in
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press289 15.1 Time-Independent Hamiltonians
not always practical or useful. In many cases of interest, the entire spectrum of
the Hamiltonian is too difficult to compute and moreover, not necessarily needed,
since the initial state often “filters” only a relevant subspace of Hamiltonian eigen￾states (see Eq. (15.1.7)). It is therefore useful to relate directly to the time-dependent
Schrödinger equation without going through the solution of the time-independent
equation.
Exercise 15.1.2 Given a complete orthonormal system of the Hamiltonian eigenstates,
Hˆ|φni = εn|φni, any operator in the system’s Hilbert space can be represented according
to Eq. (15.1.12), and any state of the system, |ψ(t)i, can be expanded as in Eq. (15.1.6).
(a) Show that the time-dependence of any observable obtains the form of Eq. (15.1.14)
with γn,m as defined in Eq. (15.1.15). (b) Show that γn,m = γ
∗
m,n
.
The Two-Level System (a “Qubit
“
)
As the simplest example, let us consider here the dynamics of a quantum two-level sys￾tem, often referred to as a single quantum bit (a qubit). In Chapter 12 we encountered
the TLS Hamiltonian, its eigenvalues, and its eigenvectors. We recall that in this case
the Hilbert space of physical states is spanned by two orthonormal states, |χ1i and |χ2i
(Eq. (12.2.1)), and the matrix representation of the (Hermitian) Hamiltonian operator
in this basis obtains the generic form (Eq. (12.2.3))
 

χ1|Hˆ|χ1
 
χ1|Hˆ|χ2



χ2|Hˆ|χ1
 
χ2|Hˆ|χ2


=

ε1 γ
γ
∗
ε2

. (15.1.17)
Defining ε ≡ (ε1 +ε2)/2, ∆ ≡ (ε1 −ε2)/2, and α ≡
p
1+|γ|
2/∆2
, the eigenvalues and
eigenvectors of the TLS Hamiltonian, Hˆ|φ±i = E±|φ±i, read (See Ex. 12.2.1)
E± = ε ±
q
∆2 +|γ|
2
; |φ±i = a
(±)
1
|χ1i+a
(±)
2
|χ2i, (15.1.18)
where
a
(±)
1 =
r
α ±1
2α
; a
(±)
2 = ±
|γ|
γ
r
α ∓1
2α
. (15.1.19)
Without loss of generality, let us identify an “initial” state with one of the two
orthonormal basis states,
|ψ(0)i = |χ1i. (15.1.20)
Following the general derivation (Eqs. 15.1.1–15.1.5), the state of the system at any
other time can be represented as a superposition of the stationary solutions to the
time-dependent Schrödinger equation (Eqs. (15.1.6, 15.1.7)),
|ψ(t)i = hφ+|χ1ie
−iE+t
h¯ |φ+i+hφ−|χ1ie
−iE−t
h¯ |φ−i. (15.1.21)
Alternatively, the time-dependent state can be expanded in terms of the two basis states,
|ψ(t)i = c1(t)|χ1i+c2(t)|χ2i, (15.1.22)
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press290 Quantum Dynamics
where (Ex. 15.1.3)
c1(t) = |hφ+|χ1i|2
e
−iE+t
h¯ +|hφ−|χ1i|2
e
−iE−t
h¯
c2(t) = hφ+|χ1ihχ2|φ+ie
−iE+t
h¯ +hφ−|χ1ihχ2|φ−ie
−iE−t
h¯ . (15.1.23)
Using the explicit expressions, Eqs. (15.1.18, 15.1.19), and the orthonormality of the
basis states, we obtain
hφ±|χ1i =
r
α ±1
2α
; hφ±|χ2i = ±
γ
|γ|
r
α ∓1
2α
(15.1.24)
and therefore (Ex. 15.1.3)
c1(t) = e
−iE+t
h¯

α +1
2α
+
α −1
2α
e
i(E+−E−)t
h¯

c2(t) =
|γ|
γ
e
−iE+t
h¯
√
α2 −1
2α

1−e
i(E+−E−)t
h¯

. (15.1.25)
Exercise 15.1.3 (a) Given the expansion of the state of a TLS, |ψ(t)i in terms of its
stationary states (Eq. (15.1.21)) and the expansion of the stationary states in terms
of the basis states (Eq. 15.1.18), derive Eqs. (15.1.22, 15.1.23). (b) Use the explicit
expressions for the projections of the TLS stationary states on the basis states in terms
of the TLS Hamiltonian parameters (Eqs. (15.1.18, 15.1.19)) to derive Eq. (15.1.25).
Any operator in the Hilbert space of the TLS obtains the form
Oˆ = o1,1|χ1ihχ1|+o1,2|χ1ihχ2|+o2,1|χ2ihχ1|+o2,2|χ2ihχ2| (15.1.26)
The corresponding observable,hψ(t)|Oˆ|ψ(t), can therefore be expressed in terms of the
time-dependent expansion coefficients of the state of the system (Eq. (15.1.22)),
O(t) = o1,1|c1(t)|
2 +o2,2|c2(t)|
2 +2Re[o1,2c
∗
1
(t)c2(t)]. (15.1.27)
Using Eq. (15.1.25) in Eq. (15.1.27), we can see that any TLS observable is either
constant in time or oscillates at a single frequency (Ex. 15.1.4), corresponding to the
difference between the two Hamiltonian eigenvalues,
ω =
E+ −E−
h¯
=
p
(ε1 −ε2)
2 +4|γ|
2
h¯
. (15.1.28)
Notice that this is a specific case of the general expansion of any observable,
Eq. (15.1.14).
Exercise 15.1.4 Given the time-dependent expansion coefficients for the TLS state,
Eqs. (15.1.22, 15.1.25), and the general expansion of a TLS observable, Eq.(15.1.27),
show that the TLS observables are either time-independent, or oscillating at a single
frequency, ω =
E+−E−
h¯
.
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press291 15.1 Time-Independent Hamiltonians
An important observable is the “survival probability” of an initial state, which is the
probability of finding a system at its initial state as a function of time,
P(t) = |hψ(0)|ψ(t)i|2 = hψ(0)|ψ(t)ihψ(t)|ψ(0)i. (15.1.29)
Recalling that the initial state can be identified with one of the basis states, for example,
|ψ(0)i = |χ1i, the survival probability can be expressed explicitly in terms of the TLS
Hamiltonian parameters (Ex. 15.1.5):
P(t) = |c1(t)|
2 = 1−
4|γ|
2
(ε1 −ε2)
2 +4|γ|
2
sin2
 
t
p
(ε1 −ε2)
2 +4|γ|
2
2h¯
!
. (15.1.30)
P(t) is uniquely determined by two parameters, |γ| and |ε1 − ε2|. In applications of
the TLS model, |γ| is often referred to as the interaction strength between the two
eigenstates of the “unperturbed” diagonal TLS Hamiltonian, |χ1i and |χ2i, whose
energy difference is |ε1 − ε2|. The survival probability of the state |χ1i is shown to
oscillate between unity and 1−
4|γ|
2
(ε1−ε2)
2+4|γ|
2 at a frequency ω =
p
(ε1 −ε2)
2 +4|γ|
2/h¯
(Eq. (15.1.28)). The dependence of the oscillation frequency and amplitude on |γ| and
|ε1 −ε2| is demonstrated in Fig. 15.1.1.
It is instructive to analyze in detail two limiting cases. First, when |γ| >> ε1 − ε2|,
the two eigenstates of the TLS Hamiltonian are nearly equally delocalized over the two
basis states, namely |φ±i ≈ √
1
2
|χ1i± |γ|
γ
√
1
2
|χ2i(see Ex. 15.1.6). The survival probability
in this limit (see Eq. (15.1.30)) is approximated as
Ftigure 15.1.1 The survival probability as a unction of time for a TLS (a single qubit). The interaction strength parameter is fixed at
γ = 0.1 eV, where the level spacing changes, |ε1 −ε2| = 0.01,0.1,1 eV, as indicated on the plot. For
|ε1 −ε2| << γ the probability oscillates between zero and one, whereas for |ε1 −ε2|  γ, the state is nearly
stationary, and the survival probability remains close to unity at all times.
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press292 Quantum Dynamics
P|γ|>>|ε1−ε2|
(t) ≈ 1−sin2
(t|γ|/h¯); (15.1.31)
namely, it oscillates between zero and one. Indeed, the initial state is “far from station￾ary” in the sense that it has similar projections on two nondegenerate stationary states,
resulting in “beating” of the state |ψ(t)i between the two states |χ1i and |χ2i. This
is reminiscent, for example, of the beating of the probability density in a symmetric
double quantum well, as discussed in Chapter 6 (see Fig. 6.4.3).
In the opposite limit, |γ| << |ε1 − ε2|, the TLS Hamiltonian is “nearly diagonal,”
where the two eigenstates are well approximated as |φ+i ≈ |χ1i, and |φ−i ≈ |χ2i
(see Ex. 15.1.7). In this case, the approximation for the survival probability (see
Eq. (15.1.30)) reads
P|γ|<<|ε1−ε2|
(t) ≈ 1−
4|γ|
2
(ε1 −ε2)
2
sin2

t(ε1 −ε2)
2h¯

. (15.1.32)
Also in this case, the probability is oscillatory in time, but the oscillation amplitude is
much smaller than unity (P(t) ≈ 1 at all times), which means “localization” of |ψ(t)i at
its initial state |χ1i(see Fig. 15.1.1).Indeed, in this limit the initial state nearly coincides
with one of the Hamiltonian eigenstates (|χ1i ≈ |φ+i), and therefore the system is in a
nearly stationary state.
Exercise 15.1.5 Use Eq. (15.1.25) for c1(t), and the definition α ≡
p
1+|γ|
2/∆2
to
derive Eq. (15.1.30).
Exercise 15.1.6 Use Eqs. (15.1.18, 15.1.19) for the stationary states of the TLS to
show that in the strong interaction limit, |γ| >> |ε1 −ε2|, the states are approximated as
|φ±i ≈ √
1
2
|χ1i ± |γ|
γ
√
1
2
|χ2i (recall the definition, α ≡
p
1+4|γ|
2/(ε1 −ε2)
2).
Exercise 15.1.7 Use Eqs. (15.1.18, 15.1.19) for the stationary states of the TLS and
show that in the weak interaction limit, |γ| << ε1 − ε2|, the states are approximated as
|φ+i ≈ |χ1i and |φ−i ≈ |χ2i (recall the definition, α ≡
p
1+4|γ|
2/(ε1 −ε2)
2).
15.2 Unitary Evolution
An additional motivation for solving the time-dependent equation directly is that we
often encounter Hamiltonians that are explicitly time-dependent. Since the Hamil￾tonian eigenvalues and eigenstates are also time-dependent in this case, stationary
solutions to the full Schrödinger equation cannot be defined in general. Importantly,
in the Schrödinger representation of quantum mechanics, the full Hamiltonian of an
energy-conserving system is strictly time-independent, and any time-dependence is
attributed only to the physical states. Nevertheless, the Schrödinger equation formally
holds also for Hamiltonians that depend explicitly on time, Hˆ 7→ Hˆ(t):
ih¯
∂
∂t
|ψ(t)i = Hˆ(t)|ψ(t)i. (15.2.1)
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press293 15.2 Unitary Evolution
Time-dependent Hamiltonians can be derived exactly, by applying unitary time￾dependent transformations to the Schrödinger equation (see the discussion of the
interaction and the Heisenberg picture representations in Section 15.3), or as effective
field operators within solvers of the time-dependent schroedinger equation [15.1] [15.2]
[15.3], or in approximate mean-field and mixed quantum–classical [15.4] approaches.
In the latter, the Hamiltonian corresponds to a reduced system, where “external”
degrees of freedom, not accounted for explicitly within the system, appear as time￾dependent fields, namely, time-dependent parameters in the system Hamiltonian.
Solutions to the time-dependent Schrödinger equation are often formulated in terms
of a “time-evolution operator.” Without loss of generality, if the “initial” time is t’,
the solution at any time t is related to |ψ(t
0
)i by a time-evolution operator (or the
“propagator”), Uˆ(t,t
0
), and vice versa:
|ψ(t)i = Uˆ(t,t
0
)|ψ(t
0
)i, (15.2.2a)
|ψ(t
0
)i = Uˆ(t
0
,t)|ψ(t)i = Uˆ −1
(t,t
0
)|ψ(t)i. (15.2.2b)
The Schrödinger equation relates Uˆ(t,t
0
) to the system Hamiltonian. Substitution of
|ψ(t)i (Eq. (15.2.2a) in the Schrödinger equation, Eq. (15.2.1), yields
ih¯
∂
∂t
Uˆ(t,t
0
)|ψ(t
0
)i = Hˆ(t)Uˆ(t,t
0
)|ψ(t
0
)i. (15.2.3)
Since this identity holds for any initial state, |ψ(t
0
)i, in the Hilbert space of the system,
an equation of motion is obtained for the time-evolution operator itself:
∂
∂t
Uˆ(t,t
0
) = −i
h¯
Hˆ(t)Uˆ(t,t
0
). (15.2.4)
A fundamental property of the time-evolution operator is its unitarity,
Uˆ
†
(t,t
0
) = Uˆ −1
(t,t
0
). (15.2.5)
This is trivially satisfied when t = t
0
, since according to Eq. (15.2.2)
Uˆ(t
0
,t
0
) = ˆI. (15.2.6)
For t 6= t
0
, the unitarity of the time-evolution operator is attributed to the Hermiticity
of the system Hamiltonian. Taking the Hermitian conjugate of Eq. (15.2.4) (see also
Ex. 11.2.3), we have
∂
∂t
Uˆ
†
(t,t
0
) = i
h¯
Uˆ
†
(t,t
0
)Hˆ(t). (15.2.7)
Using Eqs. (15.2.4, 15.2.7), we can readily conclude that Uˆ †
(t,t
0
)Uˆ(t,t
0
) is a constant
of motion (see Ex. 15.2.1),
∂
∂t
Uˆ
†
(t,t
0
)Uˆ(t,t
0
) = 0. (15.2.8)
Given the initial condition, Eq. (15.2.6), the unitarity is hence proved for any t:
Uˆ
†
(t,t
0
)Uˆ(t,t
0
) = ˆI ⇔ Uˆ
†
(t,t
0
) = Uˆ −1
(t,t
0
). (15.2.9)
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press294 Quantum Dynamics
An immediate reflection of the unitarity of the time-evolution operator is the con￾servation of the initial norm for any solution to the time-dependent Schrödinger
equation,
hψ(t)|ψ(t)) = hψ(t
0
)|Uˆ
†
(t,t
0
)Uˆ(t,t
0
)|ψ(t
0
)i = hψ(t
0
)|ψ(t
0
)i. (15.2.10)
Exercise 15.2.1 Use Eqs. (15.2.4, 15.2.7) for the time-derivative of the time-evolution
operator to show that ∂
∂tUˆ †
(t,t
0
)Uˆ(t,t
0
) = 0.
The explicit expression for the time-evolution operator depends on the system Ham￾iltonian. For a time-independent Hamiltonian, one can readily see that Eqs. (15.2.4,
15.2.6) for the time-evolution operator are consistent with an exponential function of
Hˆ (see Section 3.4 for the definition of functions of operators):
Uˆ(t,t
0
) = e
−i
h¯
Hˆ(t−t
0
)
. (15.2.11)
When the Hamiltonian depends explicitly on time, Hˆ 7→ Hˆ(t), the time-evolution
operator, Uˆ(t,t
0
), can be expressed by integrating the Schrödinger equation
(Eq. (15.2.4)) from t
0
to any other time:
Uˆ(t,t
0
) = Uˆ(t
0
,t
0
) +wt
t
0
dτ
−i
h¯
Hˆ(τ)Uˆ(τ,t
0
). (15.2.12)
Iterative substitutions of Uˆ(τ,t
0
) under the time integral, using the initial condi￾tion, Uˆ(t
0
,t
0
) = ˆI (Eq. (15.2.6)), yields the infinite Dyson series expansion for the
time-evolution operator [15.5]:
Uˆ(t,t
0
) = ˆI +
−i
h¯
wt
t
0
dτ
0Hˆ(τ
0
) +
−i
h¯
2
wt
t
0
dτ
0Hˆ(τ
0
)
τ
0
w
t
0
dτ
00Hˆ(τ
00)
+

−i
h¯
3
wt
t
0
dτ
0Hˆ(τ
0
)
τ
0
w
t
0
dτ
00Hˆ(τ
00)
τ
00
w
t
0
dτ
000Hˆ(τ
000) +....
(15.2.13)
Notice that in each term the product of the Hamiltonians at different times is ordered;
for example, for forward propagation, t > t
0
, we have t > τ
0 > τ
00 > τ
000 ... > t
0
. This
is important since, in general, the time-dependent Hamiltonian evaluated at one time
does not commute with the Hamiltonian evaluated at another time.
In specific cases, where the Hamiltonians at different times Hˆ(t) and Hˆ(t
0
) commute
(for any t and t
0
), the integrals can be reordered and recollected as a Taylor expansion
of an exponential function. In this case, the time-evolution operator obtains the form
[Hˆ(τ),Hˆ(τ
0
)] = 0 ⇒ Uˆ(t,t
0
) = e
−i
h¯
rt
t
0
Hˆ(τ)dτ
. (15.2.14)
Other formulations of the time-evolution operator as an exponential operator exist
also in the general case of time-dependent Hamiltonians by extending the Hilbert space
of the system artificially to include an additional “time-coordinate.” In this case the
time-evolution operator is an exponential operator of a time-dependent Hamiltonian
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press295 15.3 Time-Dependent Unitary Transformations
in the extended space, exp
−
it
h¯
h
Hˆ(t
0
)−ih¯
∂
∂t
0
i, and the solutions to the Schrödinger
equation in the physical space are obtained by a proper projection of an initial state at
t = 0 onto the extended space, and back projection of the final states (at t 6= 0) onto the
physical space [15.6].
15.3 Time-Dependent Unitary Transformations
The representation of the state of the system depends on the selected basis set, where
a change of representation is equivalent to a unitary operation on the state (see
Eq. (11.2.15)). It is often convenient to choose a unitary transformation that changes
in time, namely, to invoke a time-dependent reference frame for representing the phys￾ical state of a time-evolving system. Denoting an abstract state of a system as |ψ(t)i,
the corresponding unitarily transformed state then reads
|ψ˜(t)i = Sˆ(t)|ψ(t)i ; Sˆ(t)Sˆ
†
(t) = ˆI (15.3.1)
Using the Schrödinger equation, Eq. (15.2.1), for |ψ(t)i, we can readily obtain a
corresponding equation of motion (a transformed Schrödinger equation) for |ψ˜(t)i:
ih¯
∂
∂t
|ψ˜(t)i = ˆH˜(t)|ψ˜(t)i ;
ˆH˜(t) = Sˆ(t)Hˆ(t)Sˆ
†
(t)−ih¯Sˆ(t)

∂
∂t
Sˆ
†
(t)

, (15.3.2)
where ˆH˜(t) is the transformed Hamiltonian (see Ex. 15.3.1).
Exercise 15.3.1 The state of the system, |ψ(t)i, is associated with a solution to the time￾dependent Schrödinger equation, ih¯
∂
∂t
|ψ(t)i = Hˆ(t)|ψ(t)i. A transformed state, |ψ˜(t)i,
is related to |ψ(t)i via a unitary transformation, as defined in Eq. (15.3.1). Express
the time-derivative of |ψ˜(t)i in terms of the operation of a transformed Hamiltonian on
|ψ˜(t)i, as defined in Eq. (15.3.2).
In calculations of measurable quantities, the same unitary transformation must
apply consistently to the operator representing the measurement (see Eq. (11.2.13)).
For generality we consider here system operators that can depend inherently on time,
namely Oˆ 7→ Oˆ(t). The result of any time-dependent measurement on the system can
therefore be formulated as (see Eqs. (15.1.8–15.1.11)) O(t) = hψˆ(t)|Oˆ(t)|ψˆ(t)i. This
expression is invariant to the introduction of unitary operators,
O(t) = hψ(t)|Oˆ(t)|ψ(t)i = hψ(t)|Sˆ
†
(t)Sˆ(t)Oˆ(t)Sˆ
†
(t)Sˆ(t)|ψ(t)i = hψ˜(t)|
ˆO˜(t)|ψ˜(t)i,
(15.3.3)
where the transformed operator that corresponds to the unitarily transformed state,
|ψ˜(t)i, can therefore be identified as
ˆO˜(t) = Sˆ(t)Oˆ(t)Sˆ
†
(t). (15.3.4)
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press296 Quantum Dynamics
The Interaction Picture Representation
A commonly practiced unitary transformation leads to the “interaction picture rep￾resentation” of the system dynamics. Consider a Hamiltonian that is a sum of a
time-independent term (Hˆ
0) and an “interaction” term, which, generally, can depend
inherently on time:
Hˆ(t) = Hˆ
0 +Vˆ(t). (15.3.5)
It is convenient in this case to choose an inverse propagator that corresponds to the
time-independent Hˆ
0 as a unitary transformation, namely
Sˆ(t) ≡ Uˆ
†
0
(t,0) = e
i
h¯
Hˆ
0t
. (15.3.6)
The transformed state, denoted as |ψI(t)i, is referred to as the interaction picture
representation of the state of the system,
|ψI(t)i ≡ e
i
h¯
Hˆ
0t
|ψ(t)i. (15.3.7)
The corresponding equation of motion for |ψI(t)i obtains the form (see Ex. 15.3.2)
ih¯
∂
∂t
|ψI(t)i = Vˆ
I(t)|ψI(t)i ; Vˆ
I(t) = e
i
h¯
Hˆ
0tVˆ(t)e
−i
h¯
Hˆ
0t
, (15.3.8)
where Vˆ
I(t) is the interaction picture representation of the interaction operator.
The transformation of the Schrödinger equation into the interaction picture is
equivalent to replacing the original Hamiltonian by an effective time-dependent
Hamiltonian, Hˆ (I)
(t) ≡ Vˆ
I(t) = e
i
h¯
Hˆ
0tVˆ(t)e
−i
h¯
Hˆ
0t
, which holds regardless of any time￾dependence of the original interaction term, Vˆ(t). Consequently, the effective time￾evolution operator in the interaction picture, to be denoted as Uˆ (I)
(t,0), is not a simple
exponential operator, but rather a Dyson series expansion in powers of Hˆ (I)
(t) (see
Eq. (15.2.13)):
|ψI(t)i ≡ Uˆ
(I)
(t,0)|ψI(0)i
∂
∂t
Uˆ
(I)
(t,0) = 1
ih¯
Hˆ
(I)
(t)Uˆ
(I)
(t,0) ; Hˆ
(I)
(t) ≡ e
i
h¯
Hˆ
0tVˆ(t)e
−i
h¯
Hˆ
0t
Uˆ
(I)
(t,0) = ˆI +
−i
h¯
wt
0
dt
0Hˆ
(I)
(t
0
) +
−i
h¯
2
wt
0
dt
0Hˆ
(I)
(t
0
)
t
0
w
0
dt00Hˆ
(I)
(t
00) +.... (15.3.9)
As we shall discuss, the interaction representation is particularly useful when the inter￾action operator can be regarded as a small perturbation, and consequently the Dyson
expansion can be truncated at a low order.
Given any system observable, Oˆ(t), and the definition of the transformed state
(Eqs. (15.3.6, 15.3.7)), the time evolution of the corresponding observable in the
interaction picture is given by Eq. (15.3.3):
O(t) = hψI(t)|Oˆ
I(t)|ψI(t)i. (15.3.10)
The corresponding interaction picture representation of the operator reads
Oˆ
I(t) ≡ e
i
h¯
Hˆ
0tOˆ(t)e
−i
h¯
Hˆ
0t
, (15.3.11)
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press297 15.3 Time-Dependent Unitary Transformations
and the equation of motion for Oˆ
I(t) is therefore
∂
∂t
Oˆ
I(t) = i
h¯

Hˆ
0,Oˆ
I(t)

+

∂
∂t
Oˆ(t)

I
. (15.3.12)
Notice that the transformed operator Oˆ
I(t) depends on time even when the system
operator is inherently time-independent, Oˆ(t) 7→ Oˆ.
Exercise 15.3.2 The state of the system, |ψ(t)i, is associated with a solution to the
time-dependent Schrödinger equation, ih¯
∂
∂t
|ψ(t)i = Hˆ(t)|ψ(t)i, where Hˆ(t) = Hˆ
0 +Vˆ(t).
A transformed state, |ψI(t)i, is related to |ψ(t)i via a unitary transformation, as defined
in Eq. (15.3.7). Express the time derivative of |ψI(t)i in terms of the operation of the
transformed interaction operator, as defined in Eq. (15.3.8).
The Heisenberg Picture
Another commonly practiced time-dependent unitary transformation of the state leads
to the “Heisenberg picture representation” of the system dynamics. Let Hˆ(t) be the
system Hamiltonian, and let Uˆ(t,0) be the corresponding time-evolution operator
(propagator) associated with Hˆ(t). One can then choose the inverse of the full system’s
propagator as a time-dependent unitary transformation, namely
Sˆ(t) ≡ Uˆ
†
(t,0). (15.3.13)
The transformed state obtained in this case is referred to as the Heisenberg picture
representation of the state, which reads
|ψHi ≡ Uˆ
†
(t,0)|ψ(t)i = Uˆ
†
(t,0)Uˆ(t,0)|ψ(0)i = |ψ(0)i. (15.3.14)
As we can see, in the Heisenberg picture the state vectors are time-independent, which
can be readily verified using Eq. (15.2.8) (see Ex. 15.2.1).
Concerning system observables, Eq. (15.3.3) together with the definitions in
Eqs. (15.3.13, 15.3.14)) means that the time-dependence of any observable is given as
O(t) = hψ(t)|Oˆ(t)|ψ(t)i = hψ(0)|OˆH(t)|ψ(0)i, (15.3.15)
where the Heisenberg picture representation of any system operator, OˆH(t), reads
OˆH(t) ≡ Uˆ
†
(t,0)Oˆ(t)Uˆ(t,0), (15.3.16)
and specifically for a time-independent Hamiltonian, we obtain OˆH(t) ≡ e
i
h¯
HˆtOˆ(t)e
−i
h¯
Hˆt
.
The corresponding equation of motion for OˆH(t) is readily obtained from the
Schrödinger equation for Uˆ(t,0) (see Ex. 15.3.3):
∂
∂t
OˆH(t) = i
h¯
[HˆH(t),OˆH(t)]+

∂
∂t
Oˆ(t)

H
. (15.3.17)
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press298 Quantum Dynamics
Notice that (as in the interaction picture) the transformed operator OˆH(t) depends on
time even when the system operator is inherently time-independent, Oˆ(t) 7→ Oˆ. In the
latter case, the Heisenberg equation simplifies:
Oˆ(t) 7→ Oˆ ⇒
∂
∂t
OˆH(t) = i
h¯
[HˆH(t),OˆH(t)]. (15.3.18)
Namely, the generator of motion for an operator in the Heisenberg picture is its
commutator with the system Hamiltonian. Any observable represented by an oper￾ator that commutes with the Hamiltonian is therefore a constant of motion, namely
time-independent. When the system Hamiltonian itself does not depend explicitly on
time, we can readily see that its Heisenberg picture representation is equal to the
Hamiltonian itself, namely
Hˆ(t) 7→ Hˆ ⇒ HˆH(t) = Hˆ. (15.3.19)
Exercise 15.3.3 Use Eqs. (15.2.4,15.2.7) to derive Eq. (15.3.17) from Eq. (15.3.16).
15.4 Quantum-Classical Correspondence
The Heisenberg picture associates the dynamics of a system with time-dependent
observables rather than with time-dependent state vectors. This concept is similar
to the picture invoked in classical mechanics, and therefore it provides a convenient
framework for analyzing the differences as well as the correspondence between quan￾tum and classical mechanics. Consider, for example, a point particle of mass m, in
a one-dimensional coordinate system, associated with the generic (time-independent)
Hamiltonian
Hˆ =
pˆ
2
2m
+V(xˆ) ; V(xˆ) =
∞
∑
n=0
anxˆ
n
, (15.4.1)
where pˆ and xˆ are the canonical momentum and position operators (Eqs. (3.2.1,
3.2.2)). Transforming to the Heisenberg picture representation (Eq. (15.3.16)), the
corresponding operators are time-dependent,
pˆH(t) ≡ e
i
h¯
Hˆt
peˆ
−i
h¯
Hˆt
; ˆxH(t) ≡ e
i
h¯
Hˆt
xeˆ
−i
h¯
Hˆt
(15.4.2)
and the corresponding equations of motion for pˆH(t) and xˆH(t), according to
Eq. (15.3.18), read (see Ex. 15.4.1)
∂
∂t
xˆH(t) = i
h¯
[Hˆ, xˆH(t)] =
i
h¯
[Hˆ, xˆ]H(t) =
1
m
pˆH(t)
∂
∂t
pˆH(t) = i
h¯
[Hˆ, pˆH(t)] =
i
h¯
[Hˆ, pˆ]H(t) = −V
0
(xˆH(t)), (15.4.3)
where V
0
(α) = d
dα
V(α).
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press299 15.4 Quantum-Classical Correspondence
Exercise 15.4.1 (a) Given the commutation relation, h
xˆ,
∂
∂ x
i
= −1, prove that,
h
xˆ
n
,
∂
∂ x
i
= −nxˆ
n−1
. (b) Given the definitions of the canonical position and momen￾tum operators, Eqs. (3.2.1, 3.2.2), and using the solution to (a), derive the results in
Eq. (15.4.3).
As we can see, the equations of motion for the Heisenberg operators are identical
to Hamilton’s equations of classical mechanics [3.1] for the corresponding classical
observables, namely, x˙ = p/m, p˙ = −V
0
(x). However, while in classical mechanics
the solutions x(t) and p(t) correspond to directly measurable quantities, in quantum
mechanics the latter can be obtained only by a statistical average over an ensemble of
systems represented by the quantum state (namely expectation values; see Chapter 11).
To derive equations for the quantum mechanical measurable quantities, we must first
introduce the (time-independent) state of the system in the Heisenberg picture, |ψHi,
where the Heisenberg equations of motion, Eq. (15.4.3), lead to
∂
∂t
hψH|xˆH(t)|ψHi =
1
m
hψH|pˆH(t)|ψHi (15.4.4)
∂
∂t
hψH|pˆH(t)|ψHi = −hψH|V
0
[xˆH(t)]|ψHi. (15.4.5)
This result is the Heisenberg picture representation of the Ehrenfest theorem (see
Ex. (11.7.5)). Taking the derivative of the potential energy with respect to xˆH(t),
[V
0
[xˆH(t)] =
∞
∑
n=1
annxˆ
n−1
H
(t), (15.4.6)
and recalling the identification of measurable quantities with expectation values
(Eq. (15.3.3)), and particularly
p(t) ≡ hψH|pˆH(t)|ψHi ; x
n
(t) ≡ hψH|xˆ
n
H(t)|ψHi, (15.4.7)
we obtain the following equations of motion for the quantum mechanical expectation
values:
∂
∂t
x(t) = 1
m
p(t)
∂
∂t
p(t) = −
∞
∑
n=1
annxn−1
(t). (15.4.8)
Notice that, in general, x
n
(t) = hψH|xˆ
n
H
(t)|ψH i6= [hψH|xˆH(t)|ψHi]
n = [x(t)]n
. Therefore,
the term
∞
∑
n=1
annxn−1
(t) cannot be replaced in general by d
dx(t)
V(x(t)). This is the essence
of the difference between the quantum and classical equations of motion. Indeed, in
classical mechanics the observable x
n
(t) identifies with [x(t)]n
, such that the second
equation in Eq. (15.4.8) can be written as ∂
∂t
p(t) = −
d
dx(t)
V(x(t)). Consequently, in
classical mechanics, given that x(0) and p(0) are known at an initial time (t = 0), the
measurables x(t) and p(t) are uniquely defined at any time. In contrast, in quantum
mechanics the equations for the expectation values x(t) and p(t) depend also on the
higher moments, {xˆ
n
(t) = hψH|xˆ
n
H
(t)|ψHi}. In the general case, the additional equations
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press300 Quantum Dynamics
of motion for these higher moments result in an infinite hierarchy of coupled equations,
whose formal solution requires an infinite set of corresponding initial conditions. (This
is reminiscent of the information contained in the continuous wave function, ψH(x).)
The time evolution of the position and momentum observables is therefore different
in quantum and classical mechanics. Notice, however, that the classical and quantum
expressions may coincide. This is the case for quadratic potential energy functions in the
particle’s position,
V(xˆ) = a0 +a1xˆ+a2xˆ
2
; V
0
(xˆ) = a1 +2a2xˆ, (15.4.9)
where the Heisenberg equations of motion (Eqs. (15.4.3)) and the corresponding Ham￾ilton’s equations become linear in the position and momentum variables. The quantum
equations for the observables (Eqs. (15.4.7, 15.4.8)) read in this case
∂
∂t
x(t) = 1
m
p(t)
∂
∂t
p(t) = −a1 −2a2x(t), (15.4.10)
which are identical to the classical Hamilton equations. Two important cases fall
into this category. The first is the motion of a free particle, which corresponds to
a2 = 0, and the second is the harmonic oscillator. Owing to the universality of the
harmonic approximation in quantum systems (also in the multidimensional case [see
Section 8.2]), the quantum–classical correspondence in the harmonic oscillator model
is the basis for semiclassical approaches for approximate treatments of quantum
dynamics in multidimensional systems. In what follows we consider the dynamics of a
free particle and of the harmonic oscillator in some detail.
Gaussian Wave Packets
The quantum–classical correspondence is interesting, since it provides a rigorous
framework for associating wave function dynamics in quantum mechanics with the
motion of particles in classical mechanics. Returning to a point particle of mass m in
a one-dimensional coordinate space, an intuitive (as well as optimal, as will be dis￾cussed in what follows) mapping of the particle’s properties onto a wave function is
in terms of a normalized Gaussian wave packet. In Chapter 4 we discussed qualita￾tively the dynamics of a Gaussian wave packet, whereas here we add the quantitative
analysis. In the position representation, the initial wave function obtains the form (see
Eq. (4.2.1))
ψ(x,0) = hx|ψ0i =

1
2πσ2
1/4
e
−(x−x0
)
2
4σ2 e
ip0x/h¯
, (15.4.11)
where we can readily verify that the parameters x0 and σ correspond to the expec￾tation value of the particle’s position, hψ0|xˆ|ψ0i = x0, and to the position uncertainty,
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press301 15.4 Quantum-Classical Correspondence
p
hψ0|xˆ
2
|ψ0i − hψ0|xˆ|ψ0i
2 = σ (see Ex. 2.3.1). Using the transformation to the momen￾tum representation,
hp|ψ0i =
1
√
2πh¯
w
dxhx|ψ0ie
−ipx/h¯
; hx|ψ0i =
1
√
2πh¯
w
d php|ψ0ie
ipx/h¯
, (15.4.12)
the initial Gaussian wave packet obtains the form
ψ(p,0) = hp|ψ0i =

2σ
2
πh¯
2
1/4
e
−(p−p0
)
2
(h¯/σ)
2
e
−i(p−p0)x0/h¯
, (15.4.13)
where one can readily verify that the parameter p0 corresponds to the expectation value
of the particle’s momentum,
p
hψ0|pˆ|ψ0i = p0, and the momentum uncertainty reads
hψ0|pˆ
2
|ψ0i − hψ0|pˆ|ψ0i
2 =
h¯
2σ
. Consequently, the Gaussian wave packet |ψ0i is a
state of minimum uncertainty,
q
hψ0|pˆ
2
|ψ0i − hψ0|pˆ|ψ0i
2
q
hψ0|xˆ
2
|ψ0i − hψ0|xˆ|ψ0i
2

=
h¯
2
, (15.4.14)
(see Eq. (11.7.4), Ex. 11.7.10). Thereby, this state provides an optimal mapping of a
classical particle onto a quantum state. We are interested in the dynamics of the quan￾tum system from an initial state |ψ0i. The time evolution depends, of course, on the
underlying system’s Hamiltonian, where we focus on the cases of a free particle and a
harmonic oscillator.
Case I: The “free particle”
The free-particle Hamiltonian reads
Hˆ =
pˆ
2
2m
+a0. (15.4.15)
The corresponding Heisenberg equations, Eqs. (15.4.3), therefore obtain the form
∂
∂t
xˆH(t) = 1
m
pˆH(t) ;
∂
∂t
pˆH(t) = 0. (15.4.16)
Integrating these equations from t = 0, for the initial conditions, pˆH(0)= pˆ and
xˆH(0)=xˆ, we obtain the Heisenberg operators,
pˆH(t) = pˆ ; ˆxH(t) = xˆ+
pˆ
m
t. (15.4.17)
For the Gaussian wave packet, |ψ0i (Eqs. (15.4.11–15.4.13)), the corresponding evolu￾tion of the expectation values, x(t) = hψ0|xˆH(t)|ψ0i and p(t) = hψ0|pˆH(t)|ψ0i, is readily
obtained:
p(t) = p0 ; x(t) = x0 +
p0
m
t. (15.4.18)
Indeed, the quantum mechanical result for the position and momentum expectation values
coincides in this case with the classical trajectory of a free particle (see also Fig. 4.2.1).
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press302 Quantum Dynamics
It is instructive to also follow the standard deviations of the position and momentum
distributions for the Gaussian wave packet. For this purpose, we consider the time
evolution of the second moments. Using Eq. (15.4.17), we obtain
xˆ
2
H(t) = 
xˆ+
pˆ
m
t
2
= xˆ
2 +
pˆ
2
m2
t
2 +
xˆpˆ + pˆxˆ
m
t
pˆ
2
H(t) = pˆ
2
(15.4.19)
Taking the expectation values with respect to |ψ0i, we obtain the corresponding
quantum observables (Ex. 15.4.2),
x
2
(t) = σ
2 +x
2
0 +
t
2
m2
h¯
2
4σ2
+
t
2
m2
p
2
0 +
2t
m
x0 p0
p
2
(t) = p
2
0 +
h
2
4σ2
, (15.4.20)
which amount to the following standard deviations in the momentum and position
distributions (Ex. 15.4.3):
q
x
2(t)−[x(t)]2 = σ
s
1+
t
2
m2
h¯
2
4σ4
q
p
2(t)−[p(t)]2 =
h
2σ
. (15.4.21)
While the momentum uncertainly is fixed in time, which corresponds to the absence of
a net force on the free particle, the position uncertainty is shown to grow in time. This is
expected on account of the initial distribution of momenta, leading to dispersion and
hence broadening of the distribution in the position representation. The dispersion
rate is shown to decrease with decreasing width of the momentum distribution and
with increasing particle mass. The broadening of the position distribution for a fixed
momentum distribution means that the uncertainty product grows in time:
q
x
2(t)−[x(t)]2
q
p
2(t)−[p(t)]2 =
h¯
2
s
1+
t
2
m2
h¯
2
4σ4
≥
h¯
2
. (15.4.22)
The minimal uncertainty state is therefore only transient for the free particle (see also
Fig. 4.2.1).
Exercise 15.4.2 In Eq. (15.4.19) the time-dependent Heisenberg operators, xˆH(t) and
pˆH(t), are expressed in terms of the operators, xˆ
2
, pˆ
2
, xˆpˆ, and pˆxˆ. (a) Express the expec￾tation values of xˆ
2
, pˆ
2
, xˆpˆ, and pˆxˆ in terms of the parameters x0, p0, σ of the Gaussian
wave packet (Eq. (15.4.11)). (b) Obtain the expressions for the quantum mechanical
expectation values, x
2
(t) = hψ0|xˆ
2
H
(t)|ψ0i and p
2
(t) = hψ0|pˆ
2
H
(t)|ψ0i, in Eq. (15.4.20).
Exercise 15.4.3 Use Eqs. (15.4.18, 15.4.20) to derive Eq. (15.4.21).
For completeness, we turn to the time evolution of the initial Gaussian wave packet,
Eq. (15.4.11), in the Schrödinger picture for a free particle. First, we notice that the
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press303 15.4 Quantum-Classical Correspondence
time-evolution operator (Eq. (15.2.11)) is most conveniently applied in this case, in the
momentum representation,
ψ(p,t) = hp|e
−it pˆ
2
2mh¯ |ψ0i =

2σ
2
πh¯
2
1/4
e
−(p−p0
)
2
(h¯/σ)
2
e
−i(p−p0)x0/h¯
e
−ip2t
2mh¯ . (15.4.23)
The time-dependence of the state in the position representation is obtained by expand￾ing in the momentum eigenstates basis, using the relation, Eq. (15.4.12),
ψ(x,t) = 1
√
2π
h¯
w∞
−∞
d pψ(p,t)e
ipx/h¯
=
1
√
2πh¯

2σ
2
πh¯
2
1/4
w∞
−∞
d pe
−(p−p0
)
2
(h¯/σ)
2
e
−i(p−p0)x0/h¯
e
ipx/h¯
e
−ip2t
2mh¯ , (15.4.24)
Notice that this expression can be regarded as a superposition of the set of stationary
states for a free particle 
√
1
2πh¯
e
ipx/h¯
e
−ip2t
2mh¯

, with hp|ψ0i as the expansion coeffi￾cients (see Eq. (15.1.5)). Evaluating the integral in Eq. (15.4.24), the time-dependent
probability density is shown to remain a Gaussian function (see Ex. 15.4.4),
|ψ(x,t)|
2 =
vuut
1
2π
h
σ2 +
h¯
2
t
2
4σ2m2
i e
−

x−x0−
p0
t
m
2
2

σ2+
h¯
2t
2
4σ2m2

. (15.4.25)
The center of the position space distribution (corresponding to the position expecta￾tion value) is indeed shown to follow the classical trajectory (Eq. (15.4.18)), and the
distribution width (corresponding to the position uncertainty) indeed increases in time
according to Eq. (15.4.21).
Exercise 15.4.4 Use the momentum space representation of the time-dependent Gauss￾ian wave packet, Eq. (15.4.24), change the integration variable, p
0 = p − p0, and use
the identity, r∞
−∞
d p0
e
−zp02
e
ip0
x =
qπ
z
e
−x
2
4z for a complex-valued z to obtain an explicit
expression for the time-evolution of the Gaussian wave packet for a free particle,
hx|ψ(t)i =

e
−ip0
2t
2mh¯ e
ip0x/h¯
q
h¯
2π

2σ
2
πh¯
2
1/4q π
[σ2+
iht¯
2m ]
e
−

x−x0−
p0
t
m
2
4[σ2+
iht¯
2m ]
, and the correspond￾ing probability density, Eq. (15.4.25).
Case II: The Harmonic oscillator
The Hamiltonian of a one-dimensional harmonic oscillator reads (see Chapter 8)
Hˆ =
pˆ
2
2m
+
mω
2
xˆ
2
2
, (15.4.26)
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press304 Quantum Dynamics
and the corresponding Heisenberg equations, Eq. (15.4.3), for this Hamiltonian obtain
the form
∂
∂t
xˆH(t) = 1
m
pˆH(t) ;
∂
∂t
pˆH = −mω
2
xˆH. (15.4.27)
The explicit expressions for the position and momentum operators in the Heisenberg
picture are readily obtained by integrating these equations from t = 0 (see Ex. 15.4.5),
with the initial conditions, pˆH(0) = pˆ and xˆH(0) = xˆ:
xˆH(t) = xˆcos(ωt) + pˆ
mω
sin(ωt) ; ˆpH(t) = −mωxˆsin(ωt) + pˆ cos(ωt). (15.4.28)
Using the relations, x0 = hψ0|xˆ|ψ0i and p0 = hψ0|pˆ|ψ0i, for the Gaussian wave packet
(|ψ0i, as defined in Eqs. (15.4.11–15.4.13)), the time evolution of the expectation values,
x(t) = hψ0|xˆH(t)|ψ0i and p(t) = hψ0|pˆH(t)|ψ0i reads
x(t) = x0 cos(ωt) + P0
mω
sin(ωt) ; p(t) = −mωx0 sin(ωt) + p0 cos(ωt). (15.4.29)
As we can see, the quantum mechanical result for the position and momentum expectation
values coincides with the classical trajectory of a particle in a harmonic potential energy
well (Eqs. (15.4.9, 15.4.10); see also Fig. 4.2.3).
To follow the standard deviations of the position and momentum distributions for
the Gaussian wave packet in the harmonic oscillator model, we consider the time evo￾lution of the corresponding second moments. Using Eq. (15.4.28), we immediately
obtain
xˆ
2
H(t) = xˆ
2
cos2
(ωt) + pˆ
2
m2ω2
sin2
(ωt) + xˆpˆ + pˆxˆ
mω
cos(ωt)sin(ωt)
pˆ
2
H(t) = m
2ω
2
xˆ
2
sin2
(ωt) + pˆ
2
cos2
(ωt)−mω(xˆpˆ + pˆxˆ) cos(ωt)sin(ωt). (15.4.30)
Taking the expectation values with respect to the wave packet, |ψ0i, we obtain
(Ex. 15.4.6)
x
2
(t) = (x
2
0 +σ
2
) cos2
(ωt) + 1
m2ω2

p
2
0 +
h¯
2
4σ2

sin2
(ωt) + 2x0 p0
mω
cos(ωt)sin(ωt)
p
2
(t) = m
2ω
2
(x
2
0 +σ
2
)sin2
(ωt) +
p
2
0 +
h¯
2
4σ2

cos2
(ωt)−2mωx0 p0 sin(ωt) cos(ωt),
(15.4.31)
and finally, using Eqs. (15.4.29, 15.4.31), the standard deviations are given as
(Ex. 15.4.6)
q
x
2(t)−[x(t)]2 =
s
σ2 cos2(ωt) + h¯
2
4σ2m2ω2
sin2
(ωt)
q
p
2(t)−[p(t)]2 =
s
m2ω2σ2 sin2
(ωt) +
h¯
2
4σ2

cos2(ωt). (15.4.32)
In general, the momentum and position uncertainties are shown to oscillate in time at
the oscillator frequency.
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press305 15.4 Quantum-Classical Correspondence
Exercise 15.4.5 Obtain the time-dependent Heisenberg operators for the harmonic
oscillator (Eq. (15.4.28)) by solving Eq. (15.4.27) for the initial conditions, xˆH(0) =
xˆ, pˆH(0) = pˆ.
Exercise 15.4.6 Use the results of Ex. 15.4.2(a) for the expectation values of xˆ
2
, pˆ
2
, xˆpˆ,
and pˆxˆ as functions of the parameters x0, p0, σ of the Gaussian wave packet to obtain the
expressions for the quantum mechanical expectation values, x
2
(t) = hψ0|xˆ
2
H
(t)|ψ0i and
p
2
(t) = hψ0|pˆ
2
H
(t)|ψ0i, in Eq. (15.4.31). (b) Obtain the expressions for the standard
deviations of the momentum and position distributions in Eq. (15.4.32).
The Coherent State
A particularly interesting case of a Gaussian wave packet dynamics under the Har￾monic oscillator Hamiltonian corresponds to the parameter σ =
q
h¯
2mω
. In this case,
the standard deviations are constant in time (see Eq. (15.4.32)), such that the minimal
uncertainty product is maintained at any time:
σ =
r
h¯
2mω
⇒
q
x
2(t)−[x(t)]2
q
p
2(t)−[p(t)]2 =
h¯
2
. (15.4.33)
The solution of the Schrödinger equation for a harmonic oscillator corresponding to
a minimal uncertainty Gaussian wave packet is referred to as a coherent state. Since
the position and momentum expectation values follow a classical trajectory, while the
standard deviations in the position and momentum do not change in time, the corre￾spondence between quantum and classical mechanics is maximized in this case. Indeed,
coherent states are the basis for semiclassical approximations in atomic and molecu￾lar physics as well as in quantum field theory [15.7]. Recalling the definition of the
annihilation operator for the harmonic oscillator (Eq. (8.5.10)),
aˆ ≡
r
mω
2h¯
xˆ+i
r
1
2mωh¯
pˆ, (15.4.34)
we can readily see that the initial Gaussian wave packet, Eq. (15.4.11), is an eigenfunc￾tion of the creation operator (Ex. 15.4.7),
aˆ|ψ0i =
r
mω
2h¯

x0 +
ip0
mω

|ψ0i. (15.4.35)
The real and imaginary parts of the eigenvalue correspond, respectively, to the (dimen￾sionless) initial position and momentum expectation values of the Gaussian wave
packet. A coherent state can therefore be uniquely defined by a complex eigenvalue
of aˆ, denoted as α:
|ψ0i ≡ |αi ; α ≡
r
1
2
r
mω
h¯
x0 +i
p0
√
hm¯ ω

. (15.4.36)
Again, for completeness, we turn to evaluation of the time evolution of the
coherent state (defined in terms of the Gaussian wave packet, Eq. (15.4.11)) in
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press306 Quantum Dynamics
the Schrödinger picture. This is most conveniently done by expanding the state in
the basis of the harmonic oscillator Hamiltonian eigenstates, defined by the equa￾tion h¯ω
￾
aˆ
†aˆ+
1
2

|φni = h¯ω
￾
n+
1
2

|φni,n = 0,1,2,... (see Eqs. (8.5.12, 8.5.13)). This
expansion reads (Ex. 15.4.8)
|αi = e
iΦe
−|α
2|
2
∞
∑
n=0
α
n
√
n!
|φni, (15.4.37)
where Φ is an arbitrary phase. The time-dependence of the state is obtained by applying
the time-evolution operator,
|ψ(t)i = e
−it
h¯
h¯ω(aˆ
†aˆ+1/2)
|αi = e
iΦe
−|α
2|
2
∞
∑
n=0
α
n
√
n!
e
−it
h¯
h¯ω(n+1/2)
|φni. (15.4.38)
Identifying, α(t) ≡ αe
−iωt
, and using the relation, Eq. (15.4.37), the result can be cast
as (Ex. 15.4.9)
|ψ(t)i = e
−iωt
2 e
iΦ(t)
|α(t)i = e
−iωt
2 e
iΦ(t)
|αe
−iωt
i. (15.4.39)
Consequently, up to a global phase, the time evolution of the coherent state amounts
to a time-periodic change in the parameter, α 7→ α(t). Using Eq. (15.4.36), the real and
imaginary parts of α are related to position and momentum expectation values of the
Gaussian wave packet, namely
x(t) =
q
2h¯
mω
Re[α(t)]
p(t) =
√
2mωh¯ Im[α(t)]
. (15.4.40)
These values are shown to coincide with the classical trajectory, as obtained in the Hei￾senberg picture (Eq. (15.4.29); see Ex. 15.4.10). The value of the phase, Φ(t), is uniquely
determined by the Schrödinger equation (Ex. 15.4.11), where the corresponding
position representation of the coherent state at any time reads
ψ(x,t) = ￾
mω
πh¯
1/4
e
−mω(x−x(t))2
2h¯ e
ip(t)x/h¯
e
iΦ¯ (t)
Φ¯ (t) = mω
4h¯

x
2
0 −(
p0
mω
)
2

sin(2ωt)−
x0 p0
2h¯
cos(2ωt)−
ωt
2
. (15.4.41)
Exercise 15.4.7 Use the position representation of the annihilation operator, aˆ = qmω
2h¯
x+
q
h¯
2mω
∂
∂ x
, and of the coherent state, ψ(x,0) = ￾
mω
πh¯
1/4
e
−mω(x−x0
)
2
2h¯ e
ip0x/h¯
, to show
that the coherent state is an eigenstate of the annihilation operator, Eq. (15.4.35).
Exercise 15.4.8 Derive the expansion of the coherent state in terms of the harmonic
oscillator eigenstates, Eq. (15.4.37). Apply the annihilation operator to the formal
expansion, aˆ|αi =
∞
∑
n=0
γnaˆ|φni, recalling that aˆ|φni =
√
n|φn−1i (Eq. (8.5.3)). Then
show that γm+1
√
m+1 = αγm. Use the normalization condition hα|αi = 1 to show that
|hφ0|αi|2 = e
−|α|
2
, and prove the identity, Eq. (15.4.37).
Exercise 15.4.9 Using the identity e
−iωnt = (e
−iωt
)
n
, rewrite Eq. (15.4.38) as
Eq. (15.4.39).
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University P307 15.5 Transition Probabilities and Transition Rates
Exercise 15.4.10 Use Eqs. (15.4.36, 15.4.40) to derive the quantum mechanical position
and momentum expectation values for the coherent state. Show that these results identify
with a classical trajectory of a corresponding particle.
Exercise 15.4.11 Show that ψ(x,t), as defined in Eq. (15.4.41), is a solution of
the time-dependent Schrödinger equation for the harmonic oscillator, ih¯
∂
∂t
ψ(x,t) =
h¯ω

aˆ
†aˆ+
1
2

ψ(x,t), where aˆ =
qmω
2h¯
x+
q
h¯
2mω
∂
∂ x
.
15.5 Transition Probabilities and Transition Rates
The values of measurable quantities in any experiment depend on the initial prepara￾tion of the system. In this sense the initial preparation at time t’ is somewhat equivalent
to the final measurement at time t. Experiments and their interpretations are often for￾mulated in terms of transition probabilities, which consider both the initial and the
final states of the system. In this section we shall account for transition probabilities
associated with a single solution of the time-dependent Schrödinger equation (a coher￾ent ensemble of systems), and in Chapter 17 we shall extend the discussion to mixed
states (to be introduced in Chapter 16). Without loss of generality, we shall associate
the preparation time with t
0 = 0.
Let the state of a system at the initial time (t
0 = 0) be
|ψ(0)i = |χii. (15.5.1)
According to the postulates of quantum mechanics, the probability amplitude for the
system to be in a state |χfi at any time t is the projection of the state of the system on
|χfi(“the Green’s function,” gf,i
,(t,0) ≡ hχf
|Uˆ(t,0)|χii). The corresponding transition
probability is the absolute square of this projection,
Pi→f(t) = |hχf
|Uˆ(t,0)|χii|2
. (15.5.2)
Here, Uˆ(t,0) is the unitary time-evolution operator of the system (see Section 15.2).
It is often convenient to reformulate the transition probability in terms of the cor￾relator between two projection operators, referring to the initial and final states. For
this purpose, let us start by defining the trace of an operator. Let {|φni} be a complete
orthonormal system of vectors in the system Hilbert space, where ˆI = ∑
n
|φnihφn| is the
identity operator. (For simplicity we refer here to a discrete set, but the same applies
also in the continuous case (see Section 11.3).) The trace of an operator Oˆ in that space
is defined as (see Ex. 15.5.1)
tr{Oˆ} ≡ ∑n
hφn|Oˆ|φni. (15.5.3)
Using this definition, the transition probability (Eq. 15.5.2) can be formulated as
(Ex. 15.5.2)
Pi→f(t) = tr{Uˆ
†
(t,0)|χfihχf
|Uˆ(t,0)|χiihχi
|}. (15.5.4)
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press308 Quantum Dynamics
Defining projection operators into the initial and final states,
Pˆ
(i) ≡ |χiihχi
| ; Pˆ
(f) ≡ |χfihχf
|, (15.5.5)
and recalling the definition (Eq. (15.3.16)) of the time-dependent operators in the Hei￾senberg picture, AˆH(t) = Uˆ †
(t,0)AˆUˆ(t,0), the transition probability corresponds to the
trace of a correlator between Pˆ
(i)
H
(0) and Pˆ
(f)
H
(t):
Pi→f(t) = tr{Pˆ
(f)
H
(t)Pˆ
(i)
H
(0)}. (15.5.6)
Exercise 15.5.1 Using the definition of the trace of an operator, Eq. (15.5.3), (a)
prove the following identities: tr{AˆBˆ} = tr{BˆAˆ}, tr{Aˆ†} = tr{Aˆ}
∗
,tr{[Aˆ,Bˆ]} = 0. (b)
Show that the trace of an operator is invariant to a similarity transformation of the
operator, tr{Sˆ−1AˆSˆ} = tr{Aˆ}. (c) Show that the trace of an operator is invariant to a
unitary transformation of the operator, tr{Uˆ †AˆUˆ } = tr{Aˆ}. (d) Show that the trace of
an operator is independent of the basis in which the operator is represented, tr{Aˆ} ≡
∑
n
hφn|Aˆ|φni = ∑
m
hχm|Aˆ|χmi, where {|φni} and {|χmi} are complete orthonormal systems
in the relevant Hilbert space, ˆI = ∑
n
|φnihφn| = ∑
m
|χmihχm|. (e) Show that the trace of a
tensor product of operators in a multidimensional space, Aˆ
1 ⊗Aˆ
2 ⊗··· ⊗Aˆ
N, is a product
of traces over the subspaces, tr{Aˆ
1 ⊗ Aˆ
2 ⊗ ··· ⊗ Aˆ
N} = tr{Aˆ
1} ·tr{Aˆ
2}···tr{Aˆ
N} (recall
that the multidimensional space is spanned by a complete set of tensor product states
(Eq. (11.6.12)).
Exercise 15.5.2 Use Eqs. (15.5.2, 15.5.3) and the identity operator ˆI = ∑
n
|φnihφn| to
derive Eq. (15.5.4).
In many cases of interest (see, e.g., Chapter 18) the change of the transition probabil￾ity in time is the quantity that is being measured directly. The corresponding theoretical
quantity of interest is the transition rate, namely the time-derivative of the transition
probability,
ki→f(t) ≡
d
dt
Pi→f(t). (15.5.7)
Using the explicit expressions for the transition probability (Eqs. (15.5.4, 15.5.6)), the
transition rate reads (Ex. 15.5.3)
d
dt
Pi→f(t) = 2 Retr{Uˆ
†
(t,0)|χfihχf
|
d
dt
Uˆ(t,0)|χiihχi
|}, (15.5.8)
or, in the Heisenberg picture representation,
d
dt
Pi→f(t) = tr
d
dt
Pˆ
(f)
H
(t)Pˆ
(i)
H
(0)

. (15.5.9)
Exercise 15.5.3 Use Eqs. (15.5.4, 15.5.6) to derive Eqs. (15.5.8, 15.5.9).
The formally exact and general expressions for the transition probability and the
transition rate rely on the exact time-evolution operator for the system. In practice,
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press309 15.5 Transition Probabilities and Transition Rates
the time-evolution operator associated with the full-system Hamiltonian is usually
too complicated to evaluate. Moreover, in many cases of interest its evaluation can
be avoided. This is the case where the full Hamiltonian can be decomposed into a
zero-order Hamiltonian (Hˆ
0) whose propagator is simple to evaluate, and an inter￾action (time-dependent, in principle) that is “small” in some specified sense, namely
Hˆ = Hˆ
0 +Vˆ(t). In this case it is useful to evaluate the transition probabilities and tran￾sition rates between eigenstates of the zero-order Hamiltonian using the approximated
(but practical) time-dependent perturbation theory, as will be discussed in the next
section.
Here we still focus on the exact expressions for transition probabilities and transi￾tion rates for Hamiltonians of the generic form, Hˆ = Hˆ
0 +Vˆ(t). It is most convenient
in this case to transform the states and operators into the interaction picture (see Sec￾tion 15.3), where the time-dependent states are transformed according to Eq. (15.3.7),
and the corresponding propagator, Uˆ (I)
(t,0), is defined in Eq. (15.3.9). Using the rela￾tion between Uˆ(t,0) and Uˆ (l)
(t,0), the exact transition probability from the state |χii
at t = 0 to the state |χfi at time t reads (see Eq. (15.5.2) and Ex. 15.5.4)
Pi→f(t) = |hχf
|e
−it
h¯
Hˆ
0Uˆ
(I)
(t,0)|χii|2
. (15.5.10)
It is often the case that the final state of interest is an eigenstate of Hˆ
0 (see Chapter 17).
In this case the expression for the transition probability simplifies to (see Ex. (15.5.4))
Pi→f(t) = |hχf
|Uˆ
(I)
(t,0)|χii|2
; Hˆ
0|χfi = ε f
|χfi. (15.5.11)
Alternatively, defining the projection operators, Pˆ
i = |χiihχi
| and Pˆ
f = |χfihχf
|, and
using the trace definition, the transition probability reads (see Ex. 15.5.4)
Pi→f(t) = tr{Uˆ
†(I)
(t,0)Pˆ
fUˆ
(I)
(t,0)Pˆ
i} ; Hˆ
0|χfi = ε f
|χfi. (15.5.12)
Exercise 15.5.4 Let the time-dependent state of a system be |ψ(t)i ≡ Uˆ(t,0)|χii. (a)
Use the transformation of the state to the interaction picture, |ψI(t)i ≡ e
i
h¯
Hˆ
0t
|ψ(t)i
(Eq. (15.3.7)), and the definition of the interaction picture propagator, |ψI(t)i ≡
Uˆ (I)
(t,0)|χii, (Eq. (15.3.9)), to show that |hχf
|Uˆ(t,0)|χii|2 = |hχf
|e
−it
h¯
Hˆ
0Uˆ (I)
(t,0)|χii|2
.
(b) Given that |χfi is an eigenvector of Hˆ
0, show that

hχf
|Uˆ(t,0)|χii


2 =
|hχf
|Uˆ (I)
(t,0)|χii|2
. (c) Given the definitions Pˆ
i = |χiihχi
| and Pˆ
f = |χfihχf
|, and using
the trace definition (Eq. (15.5.3)), derive Eq. (15.5.12) from Eq. (15.5.11).
Taking the time-derivative of the transition probability, Eq. (15.5.11), using the
expression for the time-derivative of Uˆ (I)
(t,0) (Eq. (15.3.9)), the exact transition rate
from |χii at t = 0 to an Hˆ
0 eigenstate, |χfi at time t reads (Ex. 15.5.5)
ki→f(t) =
1
h¯
2Imhχi
|Uˆ
†(I)
(t,0)|χfihχf
|Vˆ
I(t)Uˆ
(I)
(t,0)|χii, (15.5.13)
where Vˆ
I(t) = e
it
h¯
Hˆ
0Vˆ(t)e
−it
h¯
Hˆ
0
. This result can also be expressed as
ki→f(t) = 1
h¯
2Im tr{Pˆ
iUˆ
†(I)
(t,0)Pˆ
fVˆ
I(t)Uˆ
(I)
(t,0)}. (15.5.14)
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press310 Quantum Dynamics
Exercise 15.5.5 (a) Take the time-derivative of the transition probability, Eq. (15.5.11),
Pi→f(t) = hχi
|Uˆ †(I)
(t,0)|χfihχf
|Uˆ (I)
(t,0)|χii, using Eq. (15.3.9) for the time deriv￾ative of Uˆ (I)
(t,0), to show that
∂
∂t
Pi→f(t) = −1
ih¯
hχi
|Uˆ
†(I)
(t,0)e
it
h¯
Hˆ
0Vˆ(t)e
−it
h¯
Hˆ
0
|χfihχf
|Uˆ
(I)
(t,0)|χii
+
1
ih¯
hχi
|Uˆ
†(I)
(t,0)|χfihχf
|e
it
h¯
Hˆ
0Vˆ(t)e
−it
h¯
Hˆ
0Uˆ
(I)
(t,0)|χii.
(b) Recall that hχi
|Aˆ|χii = hχi
|Aˆ†
|χii
∗ and show that
∂
∂t
Pi→f(t) = 2
h¯
Imhχi
|Uˆ
†(I)
(t,0)|χfihχf
|e
it
h¯
Hˆ
0Vˆ(t)e
−it
h¯
Hˆ
0Uˆ
(I)
(t,0)|χii.
15.6 Time-Dependent Perturbation Theory
In most experiments the preparation and the measurement of the state of a system are
carried out in an asymptotic regime (in space and/or in time), where the full-system
Hamiltonian coincides with some zero-order Hamiltonian, denoted Hˆ
0. Of prime inter￾est is therefore to evaluate transition probabilities between different eigenstates of Hˆ
0,
owing to the presence of an interaction term in the full Hamiltonian, which obtains the
general form
Hˆ(λ,t) = Hˆ
0 +λVˆ(t). (15.6.1)
The parameter 0 ≤ λ ≤ 1 is introduced as a continuous scalar pre-factor where λ = 0
and λ = 1 correspond, respectively, to the zero-order and full Hamiltonians. Notice
that in some cases the time-dependent interaction corresponds, for example, to the
effect of an external (semiclassical) time-dependent field on the system. In other cases,
the time-dependence can be introduced formally by “turning on” an otherwise time￾independent interaction at some time, Vˆ(t) = h(t −t
0
)Vˆ(t
0
), where h(τ) is the Heaviside
step function. While formally relevant for any Hˆ
0 andVˆ(t), the interest in the transition
probability between eigenstates of Hˆ
0 is primarily in cases where the interaction that
drives the transition is a small perturbation to Hˆ
0. It is most convenient in this case
to invoke the interaction picture, where the full time-evolution operator is given as
the Dyson series (Eq. (15.3.9)). First, the interaction picture involves the “interaction￾free” propagator, Uˆ
0(t,t
0
) = exp(−i(t −t
0
)Hˆ
0/h¯), which yields only trivial phase factors
(see what follows) when applied to eigenstates of Hˆ
0. Second, when the interaction is
sufficiently small and/or for sufficiently short times, the Dyson series can be truncated
at low orders and still provide accurate results.
We are interested in evaluating the transition probability between two different
(orthogonal) eigenstates of the zero-order Hamiltonian, namely
Hˆ
0|χii = εi
|χii ; Hˆ
0|χfi = ε f
|χfi (15.6.2)
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press311 15.6 Time-Dependent Perturbation Theory
hχf
|χii = 0. (15.6.3)
Without loss of generality, we shall set the initial (system preparation) time to t = 0.
The transition amplitude from the state |χii at time t = 0 to the state |χfi at time t can
be readily formulated in terms of the interaction picture propagator (see Eq. (15.5.11)):
Pi→f(t) = |gf,i(λ,t)|
2
; gf,i(λ,t) ≡ hχf
|Uˆ
(I)
(t,0)|χii. (15.6.4)
Using the Dyson expansion (Eq. (15.3.9)) for the time-evolution operator in the
interaction picture, we obtain
gf,i(λ,t) =hχf
|χii+
−i
h¯
wt
0
dt
0
hχf
|Hˆ
(I)
(t
0
)|χii
+

−i
h¯
2
wt
0
dt
0
hχf
|Hˆ
(I)
(t
0
)
t
0
w
0
dt00Hˆ
(I)
(t
00)|χii+..., (15.6.5)
where
Hˆ
(I)
(τ) ≡ λVˆ
I(τ) = λe
i
h¯
Hˆ
0τVˆ(τ)e
−i
h¯
Hˆ
0τ
. (15.6.6)
Regarding the transition amplitude as a function of λ, Eqs. (15.6.5, 15.6.6) can be
identified as its series expansion in powers of λ,
gf,i(λ,t) =
∞
∑
n=0
λ
n
g
(n)
f,i
(t), (15.6.7)
where for n > 0,
g
(1)
f,i
(t) = −i
h¯
wt
0
dt0hχf
|Vˆ
I(t0)|χii
g
(2)
f,i
(t) = 
−i
h¯
2
wt
0
dt1hχf
|Vˆ
I(t1)
wt1
0
dt0Vˆ
I(t0)|χii
.
.
.
g
(n)
f,i
(t) = 
−i
h¯
n wt
0
dtn−1hχf
|Vˆ
I(tn−1)
twn−1
0
dtn−2Vˆ
I(tn−2)···wt1
0
dt0Vˆ
I(t0)|χii. (15.6.8)
Approximating the expansion of the transition amplitude up to the nth-order
is referred to as the nth-order time-dependent perturbation theory. The first-order
approximation for the transition probability therefore reads
P
(1)
i→f
(t) ∼=


hχf
|χii+λg
(1)
f,i
(t)



2
. (15.6.9)
We shall restrict the discussion to this first order, where the transition amplitude is lin￾ear in the interaction strength parameter; hence, observables depend quadratically on
the interaction strength. This is sufficient for treating a wealth of phenomena attributed
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press312 Quantum Dynamics
to linear response of the system to time-dependent perturbations (see Chapters 17–20).
For the description of nonlinear response, attributed to higher orders in the Dyson
expansion, the reader is directed to a complementary literature [15.8], [15.9]. The
explicit expression for the first-order transition probability between two orthogonal eigen￾states of the zero-order Hamiltonian, Hˆ
0 (Eqs. (15.6.2, 15.6.3)), due to the interaction
term, λVˆ(t), obtains the form (see Ex. 15.6.1, 15.6.2 and 15.6.3)
P
(1)
i→f
(t) =
λ
2
h¯
2





wt
0
dt
0
e
i
h¯
(ε f −εi)t
0
hχf
|Vˆ(t
0
)|χii





2
. (15.6.10)
Exercise 15.6.1 Use the definition of the first-order propagator in the interaction repre￾sentation, g
(1)
f,i
(t) = −i
h¯
rt
0
dt0hχf
|Vˆ
I(t0)|χii (Eqs. (15.6.6, 15.6.8)), and Eq. (15.6.2) for
the states |χii and |χfi, to show that g
(1)
f,i
(t) = −i
h¯
rt
0
dτhχf
|e
i
h¯
ε f τVˆ(τ)e
−i
h¯
εiτ
|χii.
Exercise 15.6.2 Use the orthogonality of the initial and final states (Eq. (15.6.3))
and the result of Ex. 15.6.1 to derive the first-order transition probability, P
(1)
i→f
(t)
(Eq. 15.6.10), from Eq. (15.6.9).
Exercise 15.6.3 Follow the steps given here as an alternative derivation of the expression
for the first-order transition probability, Eq. (15.6.10): Any solution to the time￾dependent Schrödinger equation can be expanded at any time in the basis of the eigen￾states of the zero-order Hamiltonian, {Hˆ
0|φni = εn|φni}, namely |ψ(t)i = ∑
n
bn(t)|φni ≡
∑
n
an(t)e
−iεnt
h¯ |φni, where the projection of the system state on any eigenstate, |φmi, is given
as Pm(t) = |hφm|ψ(t)i|2 = |bm(t)|
2 = |am(t)|
2
. Show that substitution of this expansion in
the time-dependent Schrödinger equation, ih¯
∂
∂t
|ψ(t)i = Hˆ|ψ(t)i, yields coupled equations
for the expansion coefficients, {an(t)} : ih¯ ∑
n
a˙n(t)e
−iεnt
h¯ |φni = λ ∑
n
Vˆ(t)an(t)e
−iεnt
h¯ |φni.
Project this equation on the bra state hφm|, multiply by e
iεmt
h¯ , and integrate over time from
0 to t to obtain am(t) = am(0) + λ
ih¯ ∑
n
rt
0
dt
0
hφm|Vˆ(t
0
)|φnie
−i(εn−εm)t
0
h¯ an(t
0
). Since this result
means that an(t
0
) = an(0) +o(λ), the expression for the probability amplitude, am(t), to
first order in λ, reads am(t) ∼= am(0)+ λ
ih¯ ∑
n
rt
0
dt
0
hφm|Vˆ(t
0
)|φnie
−i(εn−εm)t
0
h¯ an(0). Choose the
initial state as the ith eigenstate of Hˆ
0, namely am(0) = δm,i
. Substitute this condition in
the approximated expression for the probability amplitude and show that the probability
to find the system in any other eigenstate (m 6= i) at time t reads Pi→m(t) = |am(t)|
2 ∼=
λ
2
h¯
2



rt
0
dt
0
hφm|Vˆ(t
0
)|φiie
−i(εi−εm)t
0
h¯



2
, which reproduces the result, Eq. (15.6.10).
It is important to assess the validity of the first-order approximation. First, we notice
that this approximation coincides with the exact transition probability in the short time
limit. This can be readily verified by expanding the integrands in the infinite Dyson
series to their lowest order in powers of t (see Ex. 15.6.4), which yields
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press313 15.6 Time-Dependent Perturbation Theory
limt→0P
(1)
i→f
(t) = limt→0Pi→f(t) = λ
2
h¯
2
|hχf
|Vˆ(0)|χii|2
t
2
. (15.6.11)
However, the maximal time in which the first-order approximation is valid depends
on the Hamiltonian parameters. An upper bound for the validity can be obtained by
recalling that the exact transition probability is bounded at all times, 0 ≤ Pi→f(λ,t) ≤ 1
(which follows immediately from the unitarity of the time evolution operator). Impos￾ing this condition on the first-order approximation, at any time,



P
(1)
i→f
(t)


 < 1, we
obtain a necessary condition for the validity of Eq. (15.6.10):
λ <
h¯




rt
0
dt
0e
i
h¯
(ε f −εi)t
0
hχf
|Vˆ(t
0)|χii




. (15.6.12)
This general limitation translates to more transparent conditions on the Hamiltonian
parameters (the interaction strength, in particular) when the interaction is constant in
time (for t ≥ 0 ), as discussed in what follows.
Exercise 15.6.4 Prove that in the short time limit(t → 0), the exact transition probability
increases quadratically in time: Start from the Dyson expansion (15.6.5, 15.6.6) of the
probability amplitude for |χii 6= |χfi (where, Vm,n(τ) ≡ hχm|Vˆ(τ)|χni),
gf,i(λ,t) = −iλ
h¯
wt
0
dt
0
e
i(ε f −εi
)t
0
h¯ Vf,i(t
0
)
+∑
j

−iλ
h¯
2
wt
0
dt
0
t
0
w
0
dt00e
i(ε f −ε j
)t
0
h¯ Vf, j(t
0
)e
i(ε j−εi
)t
00
h¯ Vj,i(t
00)+....
Expand the exponential functions and the interaction to their lowest order in
time, for example, e
i(ε f −εi
)t
0
h¯ ≈
h
1+
i(ε f −εi)t
0
h¯
i
and Vf,i(t
0
) ≈
h
Vf,i(0)+t
0V
0
f,i
,(0)
i
, and
show that lim t→0[gf,i(λ,t)] = −iλ
h¯
Vf,i(0)t + o(t
2
) and therefore lim t→0Pi→f(t) =
λ
2
h¯
2
|hχf
|Vˆ(0)|χii|2
t
2
.
A Constant Perturbation
Let us focus now on cases in which the interaction is time-independent, except for its
“turning on” at t = 0. The Hamiltonian is formally defined as in Eq. (15.6.1), where
Vˆ(t) = (
0 ; t < 0
λVˆ ; t ≥ 0
·
. (15.6.13)
Since the interaction is constant during the system propagation time (t ≥ 0), the general
expression, Eq. (15.6.10), simplifies in this case (Ex. 15.6.5):
P
(1)
i→f
(t) = 4λ
2
|hχf
|Vˆ |χii|2
|ε f −εi
|
2
sin2

(ε f −εi)t
2h¯

, (15.6.14)
where the transition probability is shown to oscillate in time at a frequency,
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press314 Quantum Dynamics
ωf,i ≡
ε f −εi
h¯
. (15.6.15)
The oscillation amplitude prefactor is shown to depend on the ratio between the cou￾pling matrix element, |hχf
|Vˆ |χii|, and the energy gap between the two corresponding
Hˆ
0 eigenstates, |ε f −εi
|.
In the “strong interaction” limit, 2λ|hχf
|Vˆ |χii| >> |ε f − εi
|, the prefactor is
much larger than unity. Consequently, the requirement of probability conservation,
|P
(1)
i→f
(t)| ≤ 1, necessitates that sin2

(ε f −εi)t
2h¯

<< 1, which means that sin
(ε f −εi)t
2h¯

≈
(ε f −εi)t
2h¯
, and therefore
2λ|hχf
|Vˆ |χii| >> |ε f −εi
| ⇒ t ≤
h¯
λ|hχf
|Vˆ |χii|
. (15.6.16)
Indeed, in this parameter regime the validity of the first-order approximation is limited
to the short time limit (Eq. (15.6.11)), in which the probability increases quadratically
on time, irrespective of |ε f −εi
|.
In contrast, the condition for probability conservation is less strict in the “weak
interaction limit,” 2λ|hχf
|Vˆ |χii| << |ε f −εi
|, where the oscillation amplitude of P
(1)
i→f
(t)
is much smaller than unity. This result is reminiscent of the condition for validity of the
low-order time-independent perturbation theory (Eq. (12.1.29)), where the low-order
expansion in powers of the interaction operator holds as long as the coupling matrix
element between the eigenstates of Hˆ
0 is small in comparison to the difference between
the corresponding energy levels. Indeed, the first-order time-dependent perturbation
theory can generally be valid for times much longer than the trivial short time limit
(Eq. (15.6.11)). In the simplest case of a two-level system (to be discussed shortly), the
validity of the approximation extends to a number of oscillation periods, which is as
large as |ε1 −ε2|
2/|2λhχ2|Vˆ |χ1i|2
.
Exercise 15.6.5 Obtain Eq. (15.6.14) for the transition probability amplitude from the
general expression, Eq. (15.6.10), in the case where the interaction operator is constant
through the propagation time, Vˆ(t)|t≥0 7→ Vˆ .
It is instructive to test the results of the time-dependent perturbation theory by
comparing them to exact results for the TLS model, introduced in Eq. (15.1.17). The
zero-order Hamiltonian and the interaction correspond, respectively, to the diagonal
and non-diagonal parts of the Hamiltonian, where the matrix representations of these
operators in the basis of the two orthonormal states, |χ1i and |χ2i, read
H0 =

ε1 0
0 ε2

; V =

0 γ
γ
∗ 0

. (15.6.17)
Let us identify the initial and final states with the two basis states (Hˆ
0-eigenstates),
|χii = |χ1i ; |χfi = |χ2i, (15.6.18)
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press315 15.6 Time-Dependent Perturbation Theory
where the interaction term is “switched on” at t ≥ 0, with λ = 1. Since the two states
span the Hilbert space of the TLS, the transition probability, P1→2(t), is complementary
to the survival probability, P(t) ≡ P1→1(t), that was discussed in Section 15.1, namely
P1→2(t) +P1→1(t) = 1. Using Eq. (15.1.30), the exact transition probability (for λ = 1)
is given as
P1→2(t) =
4|γ|
2
(ε1 −ε2)
2 +4|γ|
2
sin2
 
t
p
(ε1 −ε2)
2 +4|γ|
2
2h¯
!
. (15.6.19)
Implementing the first-order perturbation theory expression, Eq. (15.6.14), for the case
of the TLS, the approximated transition probability reads
P
(1)
1→2
(t) = 4|γ|
2
|ε2 −ε1|
2
sin2

(ε2 −ε1)t
2h¯

. (15.6.20)
First, we notice that (as in the general case, Eq. (15.6.11)) the first-order approximation
coincides with the exact transition probability in the short time limit,
limt→0P
(1)
1→2
(t) = limt→0P1→2(t) = |γ|
2
t
2
h¯
2
. (15.6.21)
This holds, importantly, regardless of the energy difference between the two eigenstates
of Hˆ
0 (Ex. 15.6.6). In the strong interaction limit, |γ| >> |ε1 −ε2|, the exact transition
probability oscillates at a frequency ∼ 2|γ|/h¯ (Eq. (15.1.31)), where the short time limit
(Eq. (15.6.21)) is valid for times much shorter than the corresponding time period, t <<
h/(2|γ|). In the weak interaction limit, |γ| << |ε1 −ε2|, the exact transition probability
oscillates at a frequency ∼ |ε2 −ε1|/h¯ (Eq. (15.1.32)), where in this case the short time
limit (Eq. (15.6.21)) is strictly valid only for t << h/|ε2 −ε1| << h/|γ|.
Second, we notice that in the weak interaction limit, |ε1 −ε2|  2|γ|, the first-order
approximation for the transition probability coincides with the exact result also beyond
the short time limit. Indeed, Eq. (15.6.20) is readily obtained from the exact result,
Eq. (15.6.19), when |ε1 −ε2| >> 2|γ| (see also Eq. (15.1.32)). Notice that the transition
probability is much smaller than unity in this case, at any time, which is in line with the
necessary condition for the validity of the first-order approximation (Eq. (15.6.16)).
It is important to notice, however, that even in the weak interaction limit, the accu￾racy of the first-order approximation is limited to finite times. The difference between
the oscillation frequency in the exact and the approximate expressions (
p
ωexact =
(ε1 −ε2)
2 +4|γ|
2/h¯ vs. ω = |ε1 − ε2|/h¯, respectively, see Eqs. (15.6.19, 15.6.20))
meansthat an error accumulates in the approximation. The error becomes critical when
the numbers of completed oscillation periods in the exact and the approximated solu￾tions differ by the order of a single period. This critical time, tc = 2π/(ωexact −ω) (see
Ex. 15.6.7), sets an upper bound on the times in which the first-order approximation
is valid. In the weak interaction limit, this leads to the following validity condition:
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press316 Quantum Dynamics
Figur t e 15.6.1 Comparison between the exact result (Eq. (15.6.19), solid) and the first-order approximation (Eq. (15.6.20), dotted) for
the transition probability, in the different parameter regimes of the TLS model. The interaction strength parameter is
fixed at γ = 0.1 eV, where the level spacing changes, |ε1 −ε2| = 20γ,4γ, γ (left, middle, and right plots,
respectively). The accuracy of the perturbative expression is shown to be limited to the parameter regime,
|ε1 −ε2| >> γ.
|ε1 −ε2|  2|γ| ; t <<
h|ε1 −ε2|
2|γ|
2
=

2π
ω

|ε1 −ε2|
2
2|γ|
2
. (15.6.22)
Notice that in this limit, the number of oscillation periods (2π/ω)) for which the
first-order approximation is valid can still be very large, n ∼ |ε1 − ε2|
2/(2|γ|
2
), which
demonstrates the relevance of the first-order perturbation treatment to relatively “long
time” dynamics in this case (see Fig. 15.6.1).
Exercise 15.6.6 Show that for times much shorter than the oscillation period, both the
exact and the approximate expressions for the TLS transition probability (Eq. (15.6.19),
and Eq. (15.6.20), respectively) converge to quadratic time-dependence of Eq. (15.6.21).
Exercise 15.6.7 The approximate and exact expressions for the TLS transition proba￾bility are given by Eqs. (15.6.20) and (15.6.19), respectively. (a) Show that P
(1)
1→2
(t) =
1
2
(α
2 − 1)[1 − cos(ωt)] and P1→2(t) = α
2−1
2α2
[1 − cos(ωαt)], where ω =
|ε1−ε2|
h¯
and α ≡ p
1+4|γ|
2/(ε1 −ε2)
2
. (b) The oscillation frequencies of the approximate and the exact
expressions are ω and ωα, respectively. At a certain time, tc, the approximate solution
completes n oscillation periods, whereas the exact solution completes n+1 periods. Show
that tc =
2π
ωα−ω
.
Monochromatic Driving
An important class of time-dependent perturbations is associated with the interaction
of electromagnetic radiation with matter. When the radiation field can be regarded
semiclassically, its effect on the system corresponds to a time-dependent interaction
term in the system Hamiltonian, and when the field intensity is sufficiently low, this
interaction can be treated in the linear response regime, namely, using first-order per￾turbation theory. More specifically, a coherent laser field is often represented by a
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press317 15.6 Time-Dependent Perturbation Theory
single wavelength (monochromatic radiation), where in the long wavelength limit, the
system–field interaction amounts a time-periodic driving of the system’s electric dipole.
Motivated by this class of applications (to be discussed in more detail in Chapter 18),
let us consider here a generic Hamiltonian,
Hˆ(t) = Hˆ
0 +λ µˆ sin(Ωt). (15.6.23)
The field-free Hamiltonian is Hˆ
0, where Ω and λ are, respectively, the frequency and
intensity of the driving field, and µˆ is the system dipole operator that interacts with the
field.
As before, we are interested in the transition probability between two eigenstates of
the zero-order Hamiltonian, namely from |χii (corresponding to the initial state of the
system at t = 0) to a final state, |χfi, at time t, where hχf
|χii = 0. The energy difference
between the initial and the final states defines a frequency, ωf,i ≡
ε f −εi
h¯
. Implementing
the general formula of first-order perturbation theory, Eq. (15.6.10), we obtain in this
case (Ex. 15.6.8)
P
(1)
i→f
(t) = λ
2
|hχf
|µˆ |χii|2
4h¯
2





e
i(ωf,i+Ω)t −1
ωf,i +Ω
−
e
i(ωf,i−Ω)t −1
ωf,i −Ω





2
. (15.6.24)
The denominators in the right-hand side already suggest that the transition probability
obtains maximal values when the driving field frequency (times h¯ ) matches the energy
difference between the initial and final Hˆ
0 eigenstates, Ω ≈ ±ε f −εi
h¯
. This is known as
the “resonance condition” for energy exchange between the system and the field,
ε f
∼= εi ±h¯Ω, (15.6.25)
where the plus and minus signs correspond, respectively, to energy absorption and
emission by the system. Near the resonance, it is useful to define the detuning
parameter, ∆ ≡ Ω − |ωf,i
|. In the limit of “small detuning”, namely |∆| << Ω, the
expression for the transition probability simplifies, since only one of the terms cor￾responding to either emission 
e
i(ω f,i+Ω)t−1
ωf,i+Ω

or absorption 
e
i(ω f,i−Ω)t−1
ωf,i−Ω

is dominant,
and the relative contribution of the other term can be neglected. This approxi￾mation is often referred to as the rotating wave approximation, where the time￾dependent function, sin(Ωt) = (e
iΩt − e
−iΩt
)/(2i), is replaced by a single rotating
wave, namely either e
iΩt/(2i) or e
−iΩt/(2i), neglecting the other (counterrotating)
wave. Within the rotating wave approximation, the transition probability simplifies to
(Ex. 15.6.9)
P
(1)
i→f
(t) ∼=
λ
2
|hχf
|µˆ |χii|2
t
2
4h¯
2

sin[∆t/2]
∆t/2
2
(15.6.26)
∆ =

Ω−ωf,i
; εi < ε f
Ω+ωf,i
; εi > ε f
. (15.6.27)
Strictly on resonance, namely for ∆ = 0, the transition probability is shown to
increase quadratically in time, P
(1)
i→f
(t) ∼=
λ
2
|hχ f
|µˆ |χii|2
t
2
4h¯
2
, which means that the transition
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press318 Bibliography
rate, k
(1)
i→f
(t) = ∂
∂t
Pi→f(t)
(1)
(t), increases linearly in time. (We recall, however, that prob￾ability conservation imposes an upper bound, P
(1)
i→f
(t) ≤ 1, which limits the validity of
the approximation to t << 2h¯
|λ||hχ f
|µˆ |χii| .)
Off-resonance, where 0 < |∆| << Ω, the quadratic increase of the transition probabil￾ity at short times, t << 1/|∆|, is modulated by the squared sinc function. The transition
rate reads (Ex. 15.6.10)
k
(1)
i→f
(t) = λ
2
|hχf
|µˆ |χii|2
2h¯
2
sin[∆t]
∆
. (15.6.28)
For t >> 1/|∆|, we can approximate the result by considering the limit, t → ∞, where
sin[∆t]
∆ −−→t→∞
πδ (∆), such that the rate expression converges to
k
(1)
i→f
(t) −−−−→ t>>1|∆|
πλ
2
2h¯
2
|hχf
|µˆ |χii|2
δ(∆) ; |∆| 6= 0. (15.6.29)
Recalling the definition of Dirac’s delta, this result means that in the long time limit the
transition rate vanishes for off-resonant frequencies; namely, field-induced transitions
between Hˆ
0 eigenstates are restricted by the resonance conditions, ε f = εi ±h¯Ω.
Exercise 15.6.8 Show that for an interaction term, Vˆ = µˆ sin(Ωt), the transition
probability to first order in λ (Eq. (15.6.10)) reads as Eq. (15.6.24).
Exercise 15.6.9 Derive Eq. (15.6.26) from Eq. (15.6.24) for |∆| << Ω.
Exercise 15.6.10 Derive Eq. (15.6.28) for the transition rate by taking the time￾derivative of the transition probability as given in Eq. (15.6.26).
Bibliography
[15.1] H.-D. Meyer, U. Manthe, and L. S. Cederbaum, “The multi-configurational
time-dependent Hartree approach,” Chemical Physics Letters 165, 73 (1990).
[15.2] H. Wang and M. Thoss, “Multilayer formulation of the multiconfiguration
time-dependent Hartree theory,” The Journal of Chemical Physics 119, 1289
(2003).
[15.3] O. E. Alon, A. I. Streltsov, and L. S. Cederbaum, “Multiconfigurational
time-dependent Hartree method for bosons: Many-body dynamics of bosonic
systems,” Physical Review A 77, 033613 (2008).
[15.4] R. Car and M. Parrinello, “Unified approach for molecular dynamics and
density-functional theory,” Physical Review Letters 55, 2471 (1985).
[15.5] J. J. Sakurai and J. Napolitano, “Modern Quantum Mechanics,” 2nd ed.
(Addison Wesley, 2011).
[15.6] U. Peskin and Nimrod Moiseyev, “The solution of the time-dependent
Schrödinger equation by the (t, t
0
) method: Theory, computational algorithm
and applications,” The Journal of Chemical Physics 99, 4590 (1993).
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press319 Bibliography
[15.7] J. R. Klauder and B.-S. Skagerstam, “Coherent states: applications in physics
and mathematical physics” (World Scientific, 1985).
[15.8] S. Mukamel, “Principles of nonlinear optical spectroscopy” (Oxford Univer￾sity Press, 1999).
[15.9] D. J. Tannor, “Introduction to quantum mechanics: A time-dependent per￾spective” (University Science Books, 2007).
https://doi.org/10.1017/9781108877787.016 Published online by Cambridge University Press16 IncoherentStates
16.1 Mixed Ensembles
According to the postulates of quantum mechanics (see Chapter 11), the outcome of
a single measurement on a given system is inherently nondeterministic, even when the
physical state of the system is well defined. The state corresponds to a statistical ensem￾ble, and each measurement samples a possible realization of that state. So far, we
discussed physical states associated with a single wave function (a single solution to the
Schrödinger equation, or a single vector in the Hilbert space of the system). The ensem￾ble that corresponds to such a state is termed “coherent” or “pure.” Given the state
vector, |ψ(t)i, the statistical distribution of any measurable quantity can be expressed
in terms of an expectation value of a corresponding operator (see Eq. (15.1.8)):
O{|ψi}(t) = hψ(t)|Oˆ|ψ(t)i. (16.1.1)
In many cases, however, the experimental apparatus (at the preparation and/or the
measurement stage) cannot resolve pure physical states. Instead, the states that are
measured correspond to a “mixed” or an “incoherent” statistical ensemble, where dif￾ferent parts of the ensemble are associated with different vectors in the system Hilbert
space, for example, |ψ1(t)i, |ψ2(t)i, |ψ3(t)i,..., with well-defined relative statistical
weights, w1, w2, w3,..., where
∑
i
wi = 1 ; wi ≥ 0 ; hψi(t)|ψi(t)i = 1. (16.1.2)
The statistical distribution of any measurable quantity depends on the relative weights
of the different coherent states within the ensemble, in addition to the inherent statis￾tical distribution attributed to each coherent state. The expectation value for a mixed
ensemble is therefore a weighted average [15.5],
O{|ψ1i,|ψ2i,|ψ3i,...}
(t) = ∑
i
wihψi(t)|Oˆ|ψi(t)i. (16.1.3)
It is important to notice that the mixed ensemble (which refers to a “mixed state”)
cannot be associated with a single state vector in the Hilbert space of the system. A
naïve attempt to associate a mixed state with a linear combination of the pure states
composing the ensemble, namely |Ψ(t)i ≡ ∑
i
ai
|ψi(t)i, would generally not yield the
correct expectation values for system observables, as defined by Eq. (16.1.3). Indeed,
320
https://doi.org/10.1017/9781108877787.017 Published online by Cambridge University Press321 16.1 Mixed Ensembles
the expectation values for the state |Ψ(t)i, O{∑n an|ψni}(t) = hΨ(t)|Oˆ|Ψ(t)i, cannot
coincide with O{|ψ1i,|ψ2i,|ψ3i,...}
(t) for any system operator Oˆ. It is sufficient to notice
that O{∑n an|ψni}(t) = ∑
i
|ai
|
2
hψi(t)|Oˆ|ψi(t)i+ ∑
i>j
2 Re[a
∗
j
aihψj(t)|Oˆ|ψi(t)i], where the off￾diagonal contributions (associated with j 6= i) are always absent in O{|ψ1i,|ψ2i,|ψ3i,...}
(t).
Indeed, the off-diagonals are “coherences” (or “phase relations”) between the differ￾ent coherent states, introduced artificially in this case by construction of the linear
combination state, |Ψ(t)i (an elaborate definition of coherences is discussed in what
follows).
As a concrete example for the inherent difference between a mixed and a pure state,
let us consider a system of noninteracting spin-half particles in a mixed ensemble, in
which half of the particles are in a spin state |αi, and the other half in a spin |βi. Recall￾ing that Sˆ
z
|αi =
h¯
2
|αi and Sˆ
z
|βi =
−h¯
2
|βi(Eq. (13.1.10)), we can readily see that the spin
polarization in the z-direction (the expectation value of Sˆ
z) vanishes for this ensemble.
Implementing Eq. (16.1.3) with Oˆ = Sˆ
z
, |ψ1(t)i = |αi, |ψ2(t)i = |βi, w1 = w2 = 0.5,
we indeed obtain Sz = 0.5hα|Sˆ
z
|αi+0.5hβ|Sˆ
z
|βi = 0.5
h¯
2 +0.5
−h¯
2 = 0. Interestingly, the
same result is obtained for an ensemble in which all the particles are associated with
a pure superposition state, |Ψi = √
1
2
|αi+ √
1
2
|βi, where Sz = hΨ|Sˆ
z
|Ψi = 0. Indeed, in
both the mixed {0.5|αi,0.5|βi} and the pure { √
1
2
|αi+ √
1
2
|βi} states, the same prob￾ability (50%) is obtained for measuring the particle spin in the positive or negative
direction along the z-axis. Nevertheless, these states are in fact different and can be
distinguished by a different experiment. Let us consider, for example, a measurement
of the spin polarization along the x-direction, namely the expectation value of Sˆ
x. Using
Sˆ
x|αi =
h¯
2
|βi, and Sˆ
x|βi =
h¯
2
|αi(Eq. (13.1.10)), we obtain different results for the mixed
and the pure states, namely Sx = 0 and Sx =
h¯
2
, respectively (see Ex. 16.1.1). Indeed, in
the pure state, each particle is associated with a specific coherent superposition of the
different spin states |αi and |βi, which happens to be an eigenstate of Sˆ
x, whereas in
the mixed state, each particle is either at a state |αi or |βi, and therefore, none of the
particles is in an eigenstate of Sˆ
x. (In fact, each particle is in some coherent superpo￾sition of the two Sˆ
x eigenstates.) We can therefore conclude that a superposition state
such as √
1
2
|αi + √
1
2
|βi is indeed different from the mixed ensemble {0.5|αi,0.5|βi},
although for some measurements the pure and mixed states would give the same result.
In the pure (superposition) state, there are coherence relations between the different
spin states that are nonexisting within the mixed state. Moreover, these coherences
depend on the superposition coefficients, where different coefficients affect the values
of different observables (see Ex. 16.1.1).
Exercise 16.1.1 (a) A mixed state corresponds to an ensemble of noninteracting spin￾half particles, of which half are in a spin state |αi, and the other half in a spin state
|βi, where wα = wβ = 0.5. Use Eqs. (13.1.9, 13.1.10) to compute the expectation
value of the three different components of the single particle spin vector in this state,
Si = wαhα|Sˆ
i
|αi + wβ
hβ|Sˆ
i
|βi(i ∈ x, y, z), and show that the spin vector orientation in
this state is random, Sx = Sy = Sz = 0. (b) Repeat the calculation of the spin vector com￾ponents for a pure state in which all the particles are associated with a superposition state,
https://doi.org/10.1017/9781108877787.017 Published online by Cambridge University Press322 Incoherent States
|Ψi = √
1
2
|αi+ √
1
2
|βi. Show that in this case Sy = Sz = 0, Sx = h¯/2, namely, the spin is
polarized along the x-axis. (c) Repeat the calculation of the spin vector components for
a pure state in which all the particles are associated with another superposition state,
|Ψi = √
1
2
|αi+i √
1
2
|βi. Show that in this case Sx = Sz = 0, Sy = h¯/2, namely, the spin is
polarized along the y-axis.
16.2 The Density Operator
In the previous section we introduced mixed states of a physical system, which cannot
be represented in terms of a single vector in the system’s Hilbert space. It is desirable
to find a general state representation that captures the statistical distributions of any
measured property, and yet has the same formal structure for both mixed and pure
states. For this purpose, it is convenient to express the expectation value of any operator
in terms of a trace. Using the trace definition (Eq. (15.5.3) and Ex. 16.2.1), Eq. (16.1.1)
for the expectation value of a pure state can be rewritten as
O(t) = hψ(t)|Oˆ|ψ(t)i = tr{Oˆ|ψ(t)ihψ(t)|}, (16.2.1)
where, for the case of a mixed state, Eq. (16.1.3) leads to
O(t) = ∑
i
wihψi(t)|Oˆ|ψi(t)i = tr{Oˆ ∑
i
wi
|ψi(t)ihψi(t)|}. (16.2.2)
In both cases the expectation value of Oˆ is a trace of a product of Oˆ and another oper￾ator that contains the information with respect to the state of the system. Defining the
system’s density operator,
ρˆ(t) ≡ ∑
i
wi
|ψi(t)ihψi(t)|, (16.2.3)
a general expression for the expectation value, applicable for all states, is revealed:
O(t) = tr{ρˆ(t)Oˆ}, (16.2.4)
where a pure state is a specific case in which the statistical weights vanish except for
one, for example, wi = δi,i0
, where ρˆ(t) = |ψi0
(t)ihψi0
(t)|.
Some important properties of the density operator are immediately apparent. First,
since the relative weights of the different states in the ensemble sum to unity,
Eq. (16.1.2), the trace of ρˆ(t) is unity:
tr{ρˆ(t)} = 1. (16.2.5)
Second, as an operator in the system Hilbert space, ρˆ(t) is Hermitian; namely, for any
state vectors, |φi and |χi, we have
hχ|ρˆ(t)|φi = hφ|ρˆ(t)|χi
∗
. (16.2.6)
https://doi.org/10.1017/9781108877787.017 Published online by Cambridge University Press323 16.2 The Density Operator
The eigenvalues of the density operator are therefore real. Moreover, according to the
definition of the density operator, its eigenvalues are nonnegative (Ex. 16.2.2)):
ρˆ(t)|χn(t)i = λn(t)|χn(t)i ; 0 ≤ λn(t) ≤ 1. (16.2.7)
Exercise 16.2.1 Introduce the identity operator, ˆI = ∑
n
|φnihφn|, into the general def￾inition of a measurable quantity (Eq. (16.1.3)), and use the definition of the trace of
an operator, Eq. (15.5.3), to show that ∑
i
wihψi(t)|Oˆ|ψi(t)i = tr{∑
i
wi
|ψi(t)ihψi(t)|Oˆ} =
tr{ρˆ(t)Oˆ}.
Exercise 16.2.2 Use the generic structure of the density operator, Eq. (16.2.3), to show
that its eigenvalues are nonnegative; namely, if ρˆ(t)|ϕi = η|ϕi(wherehϕ|ϕi = 1), then
η ≥ 0.
The matrix representation of the density operator in any set of vectors spanning
the system’s Hilbert space is referred to as the density matrix, for example, using,
ˆI = ∑
n
|φnihφn|, we have
ρˆ = ∑n,m
|φnihφn|ρˆ|φmihφm| = ∑n,m
ρn,m|φnihφm|, (16.2.8)
where ρn,m are the matrix elements of the density matrix in the selected basis,
ρn,m = [ρ]n,m. (16.2.9)
The diagonal elements, {ρn,n}, are referred to as the “relative populations” of the basis
states, namely, ρn,n is the probability for measuring the system in the state, |φni. Using
the definition, ρn,n = hφn|ρˆ|φni = ∑
i
wihφn|ψi(t)ihψi(t)|φni = ∑
i
wi
|hφn|ψi(t)i|2
, we can
readily see that the relative populations are nonnegative, 0 ≤ ρn,n ≤ 1, where, according
to Eq. (16.2.5),
∑n
ρn,n = 1. (16.2.10)
The off-diagonal elements of the density matrix, ρn,m,where m 6= n, are referred to as
the “coherences” between the basis states, ρn,m = hφn|ρˆ|φmi=∑
i
wihφn|ψi(t)ihψi(t)|φmi =
∑
i
wihφn|ψi(t)ihφm|ψi(t)i
∗
. These entries are shown to depend on the projections of the
states composing the ensemble on the basis states, {hφn|ψii}, including the phases of
these complex-valued projections. As we can readily see, the populations and coherences
of the density matrix are basis-dependent and in general vary upon basis set transforma￾tions (see Ex. 16.2.3). Particularly, since the density operator is Hermitian, it can be
diagonalized, and therefore any density operator can be represented in a basis in which
the coherences between the basis states are null.
Exercise 16.2.3 In Ex. 16.1.1 we discussed the difference between two ensembles of spin￾half particles. The first corresponded to a random spin orientation, where half of the parti￾cles are found in a spin state |αi, and the other half in a spin state |βi. The other ensemble
https://doi.org/10.1017/9781108877787.017 Published online by Cambridge University Press324 Incoherent States
corresponded to spin polarization along the x direction, where all the particles are in a
superposition state, |Ψi = √
1
2
|αi + √
1
2
|βi. The density operators corresponding to the
two ensembles are ρˆR = 0.5|αihα|+0.5|βihβ| and ρˆP = |ΨihΨ|. (a) Show that the den￾sity matrices corresponding to these two ensembles in the basis of the two spin states are
ρR =

0.5 0
0 0.5

and ρP =

0.5 0.5
0.5 0.5

, respectively. (b) Change the basis from
|αi and |βi (Sˆ
z-eigenstates) into the two eigenstates of Sˆ
x, namely, √
1
2
|αi+ √
1
2
|βi and
√
1
2
|αi − √
1
2
|βi. Show that the matrix representation of the random ensemble is invari￾ant to the transformation, whereas the matrix representation of the pure state becomes
diagonal in this basis, ρP =

1 0
0 0 
.
16.3 Liouville’s Space
By its definition, a density operator does not correspond to any specific system observ￾able but rather to a state of the system. Yet, this state representation is an operator,
not a vector, in the standard Hilbert space of the system. It is instructive, however, to
associate density operators with elements in a vector space, named Liouville’s space.
We can readily verify that system operators are indeed vectors in a space over the field
of complex numbers, which is closed with respect to addition of operators and to their
multiplications by scalar complex numbers, and where the set of properties defining a
vector space are fulfilled. Defining an inner product between two operators Aˆ and Bˆ in
this space,
(Aˆ,Bˆ) ≡ tr{Aˆ
†Bˆ}, (16.3.1)
the norm of a vector is also defined,
||Aˆ|| = tr{Aˆ
†Aˆ}, (16.3.2)
and the vector space (the Liouville space) can be identified as a Hilbert space. The
mapping of an operator in the standard system Hilbert space onto a vector in Liou￾ville’s space is straightforward. Given any complete orthonormal system of vectors
in the standard Hilbert space, for example, {|φni}, the set of all linearly independent
outer products between these vectors, {|φnihφm|}, is a complete orthonormal system
of operators that spans the Liouville space (see Exs. 16.3.1 and 16.3.2).
The “matrix representation” of any operator in the standard Hilbert space of the
system (e.g., Eq. (16.2.8)) is also its “vector representation” in the Liouville space;
namely, any system operator can be expanded as a linear combination of the set
{|φnihφm|}:
Aˆ = ∑m,n
An,mφˆn,m ; φˆn,m ≡ |φnihφm|. (16.3.3)
https://doi.org/10.1017/9781108877787.017 Published online by Cambridge University Press325 16.3 Liouville’s Space
Under the inner product, Eq. (16.3.1), the set {φˆn,m} is orthonormal, and An,m is the
projection of Aˆ on the basis vector φˆn,m:
tr{φˆ
†
n,mφˆn
0
,m0} = δn,n
0δm,m0 ; An,m = tr{φˆ
†
n,m,Aˆ}. (16.3.4)
Exercise 16.3.1 Let the set of vectors {|φni} be a complete orthonormal system spanning
a Hilbert pace, where hφm|φni = δm,n. The outer products between these vectors, {φˆm,n =
|φmihφn|}, are operators in that space. (a) Associating each operator, φˆm,n, with a vector
in a (Liouville) vector space with an inner product, (Aˆ,Bˆ) = tr{Aˆ†Bˆ}, show that {φˆm,n}
is an orthonormal set, namely (φˆm,n,φˆm0
,n
0) = δm,m0δn,n
0 . (b) Show that any operator in
the original Hilbert space can be expanded as a linear combination of the set {φˆm,n}, Aˆ =
∑
m,n
Am,nφˆm,n, where Am,n is the inner product of Aˆ with φˆm,n, Am,n = (φˆm,n,Aˆ) = tr{φˆ
†
m,nAˆ}.
Exercise 16.3.2 Consider the space of two-dimensional matrices, 
x y
z w 
, where
x, y, z and w are complex-valued numbers. (a) Show that the set of Pauli matrices
(Eq. (13.1.17)) and the identity matrix,
σ z =

1 0
0 −1

; σ x =

0 1
1 0 
; σ y =

0 −i
i 0

; I =

1 0
0 1 
,
compose an orthogonal set of vectors in this space, under the inner product,
(A,B) = tr{A
†B}. (b) Show that the corresponding normalized basis vectors under this
inner product read
σ z =
1
√
2

1 0
0 −1

; σ x =
1
√
2

0 1
1 0 
; σ y =
1
√
2

0 −i
i 0

; I =
1
√
2

1 0
0 1 
.
(c) Show that any two-by-two matrix 
x y
z w 
can be written as a linear combination
of these matrices, with expansion coefficients given by its inner product with the basis
vectors in (b).
Operations on a Hilbert space operator can be represented in terms of Liouville’s
space “super operators.” Consider the ordered sequence of operations Bˆ and Aˆ. Using
a complete orthonormal set {|φni} in the standard Hilbert space, the matrix elements
of BˆAˆ read
hφn
0 |BˆAˆ|φm0i = ∑n
hφn
0|Bˆ|φnihφn|Aˆ|φm
0i = ∑m,n
hφn
0|Bˆ|φniδm0
,mhφn|Aˆ|φmi. (16.3.5)
Regarding the result as a linear map from the Liouville space vector whose elements are
An,m to another vector whose elements are [BˆAˆ]n
0
,m0 , we can readily identify the matrix
representation of the corresponding Liouville space “super-operator,” B
(L)
(n
0
,m0),(n,m)
:
[BˆAˆ]n
0
,m0 = ∑m,n
B
(L)
(n
0
,m0),(n,m)
An,m ; B
(L)
(n
0
,m0),(n,m) = Bn
0
,nδm0
,m. (16.3.6)
https://doi.org/10.1017/9781108877787.017 Published online by Cambridge University Press326 Incoherent States
Similarly, the alternative sequence of Hilbert space operators AˆBˆ can also be formulated
as a Liouville space super operator on Aˆ:
hφn
0|AˆBˆ|φm0i = ∑m
hφn
0|Aˆ|φmihφm|Bˆ|φm0i = ∑m,n
hφm|Bˆ|φm0iδn
0
,n
hφn|Aˆ|φmi (16.3.7)
[AˆBˆ]n
0
,m0 = ∑m,n
B
(R)
(n
0
,m0),(n,m)
An,m ; B
(R)
(n
0
,m0),(n,m) = δn
0
,nBm,m0. (16.3.8)
Notice that each vector element (corresponding to the projection on basis operator,
|φnihφm|; see Ex. (16.3.1)) in Liouville’s space is characterized by two indexes, and each
super-matrix element is characterized by four indexes. The dimensions of Liouville’s
space vectors and super-matrices are therefore the squares of the dimensions of the
corresponding Hilbert space objects. Particularly, the matrix representations of the
Liouville super operators in Eqs. (16.3.6, 16.3.8) can be formally expressed as tensor
products, B
(L) = B⊗I and B
(R) = I⊗B
t
(see Eq. (11.6.18)).
16.4 The Liouville–von Neumann Equation
We now turn to the time evolution of density operators in Liouville’s space. Each of
the pure states defining a mixed ensemble (see Eq. (16.2.3)) is a physical state-vector
in the system’s Hilbert space, whose time evolution is given by the time-dependent
Schrödinger equation. Using ih¯
∂
∂t
|ψi(t)i = Hˆ(t)|ψi(t)i, we readily obtain an equation
of motion for the density operator, in terms of the underlying system Hamiltonian
(Ex. 16.4.1),
∂
∂t
ρˆ(t) = −i
h¯
[Hˆ(t),ρˆ(t)]. (16.4.1)
The result is known as the Liouville–von Neumann equation for the density operator.
Notice that in spite of some structural resemblance (up to the sign of the commutator),
there is no relation between this equation and the Heisenberg equation of motion.
Indeed, the Heisenberg picture representation of the density operator is ρˆH(t) = ρˆH(0),
where ∂
∂t
ρˆH(t) = 0 (see Ex. 16.4.2).
Exercise 16.4.1 Use the Schrödinger equation for the coherent states,
ih¯
∂
∂t
|ψi(t)i = Hˆ(t)|ψi(t)i, and the Hermitian conjugated equation to show that the time
derivative of the density operator (Eq. (16.2.3)) is given by Eq. (16.4.1).
Exercise 16.4.2 (a) Show that by its definition, the density operator (Eq. (16.2.3)) can
be formulated using the time-evolution operator (Eq. (15.2.2)), ρˆ(t)=Uˆ(t,0)ρˆ(0)Uˆ †
(t,0).
(b) Show that the Heisenberg picture representation (Eq. (15.3.16)) of the density oper￾ator, ρˆH(t), is time-independent. (c) Use Eq. (15.3.17) to show that the time derivative
of ρˆH(t) vanishes at all times.
Notice the analogy of Liouville’s equation for the density operator ρˆ(t), Eq. (16.4.1),
to the time-dependent Schrödinger equation for a pure state, ih¯
∂
∂t
|ψ(t)i = Hˆ(t)|ψ(t)i.
https://doi.org/10.1017/9781108877787.017 Published online by Cambridge University Press327 16.5 Equilibrium States
In both cases the time-derivative of the state vector is identified with an operation of
a suitable operator (generator of motion) in the relevant vector space. In the case of
the Schrödinger equation, the space is the standard system’s Hilbert space, and the
generator of motion in that space is the Hamiltonian. In the Liouville equation for the
density operator, the vector space is Liouville’s space, where the generator of motion is
the commutator with the Hamiltonian. The latter is often denoted as the Liouvillian
“super-operator,” Lˆ(t):
Lˆ(t)ρˆ(t) ≡ [Hˆ(t),ρˆ(t)], (16.4.2)
where the Liouville–von Neumann equation reads
ih¯
∂
∂t
ρˆ(t) = Lˆ(t)ρˆ(t). (16.4.3)
Exercise 16.4.3 Given a finite basis for the system’s Hilbert space, where operators are
represented as N ×N matrices, use Eqs. (16.3.6, 16.3.8) to show that the Liouville super￾operator can be represented as a matrix of dimensions N
2 × N
2
, L = H ⊗ I − I ⊗ Ht
,
where H and I are, respectively, the matrix representation of the Hamiltonian and the
identity (use the matrix tensor product definition, Eqs. (11.6.17, 11.6.18), to show that
[Hˆ ρˆ −ρˆHˆ]n
0
,m0 = ∑
m,n
(H⊗I−I⊗Ht
)(n
0
,m0),(n,m)ρn,m).
16.5 Equilibrium States
We now focus on the equilibrium state of a system. When the external constraints ena￾ble a system to reach a stationary state, with no net flow of particles or energy inside
the system or at any of its boundaries, the system is said to reach equilibrium. Unless
specified differently (see Chapter 20 for the discussion of steady states in nonequilib￾rium), we shall assume that the boundary conditions are uniform such that stationary
net flow through the boundaries is excluded, and we shall identify the equilibrium state
with a stationary state, in which the probability distribution of any measurable prop￾erty is time-independent. Since any measurable property is expressed in terms of the
system’s density operator, ρˆ(t), Eq. (16.2.4), the requirement of time-independence for
any measurable property, Oˆ, reads
∂
∂t
tr{ρˆ(t)Oˆ} = tr ∂
∂t
ρˆ(t)

Oˆ

= 0. (16.5.1)
The equilibrium state is therefore associated with a time-independent system density
operator, ρˆ
(eq)
, namely
∂
∂t
ρˆ
(eq) = 0. (16.5.2)
According to the Liouville–von Neumann equation (Eq. (16.4.1)), the time derivative
of a density operator is proportional to its commutator with the system Hamiltonian,
which means
https://doi.org/10.1017/9781108877787.017 Published online by Cambridge University Press328 Incoherent States
[Hˆ,ρˆ
(eq)
] = 0. (16.5.3)
Notice that to comply with the definition of the equilibrium density operator
(Eq. (16.5.2)), the commutator must vanish at all times. This means that a strict equilib￾rium state is limited to time independent Hamiltonians. Indeed, the equilibrium density
operator for a mixed state can be regarded as a generalization of the stationary pure
states in systems with time-independent Hamiltonians.
An important consequence of Eq. (16.5.3) is that the matrix representation of ρˆ
(eq)
in the basis of the Hamiltonian eigenstates can be diagonal. In fact, off-diagonal matrix
elements of ρˆ
(eq)
, attributed to coherences between nondegenerate Hamiltonian eigen￾states, must vanish (see Ex. 16.5.1). Vanishing is not mandatory for coherences between
degenerate eigenstates of the system Hamiltonian. However, since ρˆ
(eq) and Hˆ com￾mute, they share a common set of eigenstates, in which their matrix representations
are both diagonal (Section 11.7). Denoting this common set as {|φ1i,|φ2i,|φ3i,...},
the equilibrium density operator obtains the form
ρˆ
(eq) = ∑n
wn|φnihφn|, (16.5.4)
where (Ex. 16.5.1)
Hˆ|φni = εn|φni ; ρˆ
(eq)
|φni = wn|φni. (16.5.5)
For simplicity, we refer to systems with a discrete energy spectrum, where the gener￾alization to the case of continuous spectrum involves replacing summations by proper
integrals (see Chapter 11), but otherwise it is conceptually similar.
The corresponding matrix representation of the density operator in the general case of
a mixed equilibrium state therefore reads
ρ
(eq) =





w1
w2 0
0
.
.
.
wN





. (16.5.6)
Since tr{ρ
(eq)} = 1 (see Eq. (16.2.5)), the information with respect to the underlying
equilibrium state of the system is fully encoded in the normalized distribution of the
diagonal matrix elements, which reflects the relative weights of the system’s stationary
states. It is instructive to consider two limiting cases.
Exercise 16.5.1 Given a time-independent system Hamiltonian, any pure state can be
expanded in terms of the stationary solutions (Eq. (15.1.5)), |ψi(t)i = ∑
n
a
(i)
n e
−it
h¯
εn
|φni,
where |φni are the Hamiltonian eigenstates, Hˆ|φni = εn|φni. (a) Use this expansion and
the definition of the system’s density operator, Eq. (16.2.3), to show that the matrix
representation of the density operator in the basis of the Hamiltonian eigenstates reads
hφm0|ρˆ(t)|φmi = ∑
i
wia
(i)
m0

a
(i)
m
∗
e
−it
h¯
(εm0−εm)
. (b) Show that the equilibrium requirement,
https://doi.org/10.1017/9781108877787.017 Published online by Cambridge University Press329 16.5 Equilibrium States
∂
∂t
hφm0|ρˆ(t)|φmi = 0, means that off-diagonal matrix elements between nondegenerate
Hamiltonian eigenstates (εm 6= εm0) must vanish identically. (c) Show that any density
matrix that is diagonal in the basis of stationary states, hφm0|ρˆ(t)|φmi ∝ δm0
,m, must be
time-independent. (d) Given the diagonal representation of the equilibrium density oper￾ator in the basis of Hamiltonian eigenstates {|φni} (Eq. (16.5.4)), show that ρˆ
(eq)
|φni =
wn|φni.
When the equilibrium state corresponds to a delta distribution of weights, namely
wn = δn,m, the density operator takes the form ρˆ
(eq) = |φmihφm|, or
ρ
(eq) =







.
.
.
.
.
.
1
.
.
.







. (16.5.7)
This is the case of a stationary pure state, where the system at equilibrium is associated
with a single Hamiltonian eigenstate, namely a single stationary state.
In contrast, when the equilibrium state corresponds to a uniform distribution of
weights, namely wn = 1/N, the density operator takes the form ρˆ
(eq) =
1
N
N
∑
m=1
|φmihφm|,
or
ρ
(eq) =
1
N





1
1
1
.
.
.





. (16.5.8)
In this case, the equilibrium density operator is proportional to the identity operator,
where all the Hamiltonian eigenstates are equally populated. Remarkably, since the
identity operator is invariant to unitary transformations, including basis set transfor￾mations (see Eq. (11.2.13)), a system in this state is associated with equal populations of
the eigenstates of any operator. Consequently, the statistical distribution of any measura￾ble quantity is a random distribution, and the state is referred to as the random state, or the
zero-information state. The random state is unique in that the coherences (off-diagonal
elements) of the density matrix vanish regardless of the selected basis (see Ex. 16.1.1 and
Ex. 16.2.3).
A convenient measure for the “purity” (or the “information content”) of the state of
the system is the norm of the corresponding density operator. Recalling the definition,
Eq. (16.3.2), and considering the Hermiticity of the density operator (Eq. (16.2.6)), the
norm reads
kρˆk = tr{ρˆ
2
}. (16.5.9)
As we can see, 0 ≤ tr{ρˆ
2} ≤ 1, where the upper limit, tr{ρˆ
2} → 1, corresponds
to maximum purity (a delta distribution of weights, Eq. (16.5.7)), and the lower
limit, tr{ρˆ
2} → 0, corresponds to a random state, Eq. (16.5.8), in the limit of an
infinite-dimensional Hilbert space (N → ∞).
https://doi.org/10.1017/9781108877787.017 Published online by Cambridge University Press330 Incoherent States
It is instructive to associate the loss of purity in the state of a system with a mono￾tonically increasing entropy function. von Neumann introduced the following entropy
measure which accounts for the “randomness” of mixed quantum ensembles:
S ≡ −tr{ρˆ ln(ρˆ)}. (16.5.10)
For an equilibrium state (Eqs. (16.5.4, 16.5.5)), the von Neumann entropy therefore
reads
S
(eq) = −∑n
wn ln(wn). (16.5.11)
Indeed, for a pure state the entropy vanishes, S
(eq) = 0 (Ex. 16.5.2), whereas for a ran￾dom ensemble, S
(eq) obtains a maximal value (subject to the normalization condition),
S
(eq) = −∑
n
1
N
ln(
1
N
) = ln(N); see Ex. 16.5.3.
Exercise 16.5.2 Show that the von Neumann equilibrium entropy, Eq. (16.5.11)
vanishes for a pure state, namely when the weights are either wn → 0 or wn → 1.
Exercise 16.5.3 The statistical weights at equilibrium are obtained by maximizing the
von Neumann entropy, subject to constraints. For a random ensemble the only constraint
is the normalization,
N
∑
n=1
wn = 1, which can be imposed in terms of a Lagrange multi￾plier λ. The function to be maximized in this case is F(w1,w2,...) = S
(eq)
(w1,w2,...)−
λ

N
∑
n=1
wn −1

. Apply the necessary condition for a maximum, { ∂
∂wn
F(w1, w2,...) = 0},
and show that the maximum is obtained when the weight is uniform for all the stationary
states, namely, wn = e
−(1+λ)
. Determine the value of λ by the normalization constraint
to show that the equilibrium weights in this case read wn =
1
N
.
According to the standard postulates of statistical mechanics, an equilibrium state of
a system is a state of maximum entropy, within a given set of constraints. As practiced
in quantum mechanics, a system is characterized by its Hamiltonian; but the state of
the system (its equilibrium state, in particular) depends on the amount of energy and
the number of particles available to the system. (Hamiltonians that correspond to sys￾tem with varying numbers of particles will be discussed in Chapter 20.) The ability of
the system to exchange particles and/or energy with its surroundings (the rest of the
universe, or the “reservoir”), can be constrained in different ways. The precise form of
the equilibrium density matrix, namely the distribution of the weights between the dif￾ferent stationary states (w1,w2,...,wN), depends therefore on the imposed constraints.
We can readily verify (Ex. 16.5.3) that the random state distribution (Eq. (16.5.8)) is
obtained by maximizing the von Neumann entropy, S
(eq)
, where the only constraint is
the trivial normalization of the weights. Additional constraints lead to different results
for the weights distribution. Two standard cases corresponding to the canonical and
the grand canonical statistical ensembles are discussed in detail in what follows.
https://doi.org/10.1017/9781108877787.017 Published online by Cambridge University Press331 16.5 Equilibrium States
The Canonical Ensemble
A typical constraint on a system that exchanges energy with its surroundings at
equilibrium refers to the amount of energy contained in the system. This constraint
characterizes systems in contact with a thermal reservoir (a thermal bath) at a fixed
temperature (in the thermodynamic limit, where the system–bath interaction strength
is assumed to be weak). The constraint means that the energy, averaged over the
statistical ensemble representing the state of the system, obtains a constant value,
tr{Hˆ ρˆ
(eq)} = U. Expressing the density matrix in terms of the statistical weights of
the stationary states of the system, we obtain
tr{Hˆ ρˆ
(eq)
} =
N
∑
n=1
wnεn = U. (16.5.12)
The equilibrium weights are obtained by maximizing the von Neumann entropy,
subject to this constraint, as well as to the normalization constraint,
N
∑
n=1
wn = 1.
Introducing corresponding Lagrange multipliers [15.5], β and λ, the functional to be
maximized in this case reads
F(w1,w2,...) = S
(eq)
(w1,w2,...)−λ
" N
∑
n=1
wn
!
−1
#
−β
" N
∑
n=1
wnεn
!
−U
#
.
(16.5.13)
Using Eq. (16.5.11) and imposing the necessary conditions for a maximum,
∂
∂wn
F(w1,w2,...) = 0, for n = 1,2,...,N, we obtain
−ln(wn)−1−λ −β εn = 0, (16.5.14)
which means wn = e
−(1+λ+β εn)
. The value of λ is set by the normalization constraint,
which yields (Ex. 16.5.4)
wn =
e
−β εn
N
∑
n
0=1
e
−β ε
n
0
. (16.5.15)
The value of the other Lagrange multiplier, β, can be determined by writing the explicit
expression for the ensemble-averaged energy,
U =
N
∑
n=1
εne
−β εn
N
∑
n
0=1
e
−β ε
n
0
= −
∂
∂β
ln 
N
∑
n=1
e
−β εn
!
. (16.5.16)
This expression coincides with the familiar results for a canonical thermodynamic
ensemble, U = −kB
∂ ln(Z)
∂ (1/T)
, where kB is Boltzmann’s constant, Z is the canonical par￾tition function, and T is the absolute temperature. Using this relation to identify the
expressions for the partition function and the temperature, the equilibrium weights for
a canonical (thermal) ensemble are given as
wn =
1
Z
e
−εn
kBT
; Z =
N
∑
n=1
e
−εn
kBT
(16.5.17)
https://doi.org/10.1017/9781108877787.017 Published online by Cambridge University Press332 Incoherent States
Recalling the definition of the equilibrium density matrix in the representation of the
Hamiltonian eigenstates, Eqs. (16.5.4, 16.5.5), the canonical density operator itself
reads (see Ex. 16.5.5)
ρˆ
(eq) =
e
−Hˆ /(kBT)
tr{e
−Hˆ /(kBT)}
. (16.5.18)
Notice that in the infinite temperature limit, the equilibrium state of the canonical
ensemble approaches that of a random ensemble.
Exercise 16.5.4 For a canonical ensemble, the weights of the stationary states are con￾strained, such that
N
∑
n=1
wn = 1 and
N
∑
n=1
wnεn =U. (a) Derive Eq. (16.5.14) by maximizing
the von Neumann entropy subject to these constraints. Determine the value of λ by the
normalization constraint to show that the equilibrium weights are given in this case by
Eq. (16.5.15).
Exercise 16.5.5 Derive Eq. (16.5.18) by substitution of the result, Eq. (16.5.17), for
the canonical ensemble in the general expression for the density matrix, Eq. (16.5.4), and
by using Eq. (16.5.5).
The Grand Canonical Ensemble
When the system can exchange particles (in addition to energy) with its surroundings,
not only the energy but also the particle content in the system are constrained by the
surroundings. This is the typical situation for systems in contact with particle reser￾voirs at fixed temperature and chemical potentials. For simplicity we shall restrict our
discussion to systems with a single type of particle. The additional constraint means in
this case that the number of particles per state of the system, averaged over the statisti￾cal ensemble, obtains a constant value, namely tr{Nˆ ρˆ
(eq)} = N0. The particle number
operator, Nˆ , as well as Hamiltonians of systems with an indefinite number of particles
will be introduced and discussed in Chapter 20 (in relation to “second quantization”
for fermions). For the present discussion, all we need to know is that such operators
exist and that any stationary state of the system is associated with a well-defined num￾ber of particles; namely, the Hamiltonian eigenstates {|φni} are also eigenstates of the
system particle number operator (see also Eq. 16.5.5):
Nˆ |φni = Nn|φni. (16.5.19)
Expressing the density matrix in this basis, the additional constraint on the number of
particles reads
tr{Nˆ ρˆ
(eq)
} =
N
∑
n=1
wnNn = N0. (16.5.20)
To obtain the equilibrium weights {wn} in this equilibrium state, the von Neu￾mann entropy is maximized subject to the constraints, Eqs. (16.5.12, 16.5.20), and
https://doi.org/10.1017/9781108877787.017 Published online by Cambridge University Press333 16.5 Equilibrium States
the normalization constraint,
N
∑
n=1
wn = 1. Introducing the corresponding Lagrange
multipliers, β,η, and λ, the functional to be maximized in this case reads
F(w1,w2,...) = S
(eq)
(w1,w2,...)−λ
" N
∑
n=1
wn
!
−1
#
−β
" N
∑
n=1
wnεn
!
−U
#
−η
" N
∑
n=1
wnNn
!
−N0
#
. (16.5.21)
Imposing the necessary conditions for a maximum, ∂
∂wn
F(w1,w2,...) = 0, we obtain
in this case wn = e
−(1+λ+β εn+ηNn)
, where the value of λ is set by the normalization
condition (Ex. 16.5.6)
wn =
e
−β εn−ηNn
∑
n
0
e
−β ε
n
0−ηNn
0
. (16.5.22)
Using Eq. (16.5.22) and defining Z = ∑
n
0
e
−β ε
n
0−ηNn
0
, the ensemble-averaged energy
(Eq. (16.5.12)) and particle number (Eq. (16.5.20)) can be rewritten as
U = −
∂
∂β
ln(Z) ; N0 = −
∂
∂η
ln(Z). (16.5.23)
Comparing the expressions to standard thermodynamic definitions of these quantities
in a grand canonical ensemble, U = −kB
∂ ln(Z)
∂ (1/T)
, and N0 = kBT
∂ ln(Z)
∂ µ
, where Z is the
partition function, T is the absolute temperature, and µ is the chemical potential, the
Lagrange multipliers can be identified with thermodynamics quantities β = 1/(kBT)
and η = −µβ. Consequently, the statistical weights (Eq. (16.5.22)) for an equilibrium
state corresponding to a grand canonical ensemble obtain the form
wn =
1
Z
e
−1
kBT
(εn−µNn)
; Z =
N
∑
n=1
e
−1
kBT
(εn−µNn)
, (16.5.24)
where the corresponding equilibrium density operator reads (see Ex. 16.5.7)
ρˆ
(eq) =
e
−1
kBT
(Hˆ−µNˆ)
tr

e
−1
kBT
(Hˆ−µNˆ)
 (16.5.25)
Exercise 16.5.6 For a grand canonical ensemble, the weights of the stationary states are
constrained, such that
N
∑
n=1
wn = 1,
N
∑
n=1
wnεn =U, and
N
∑
n=1
wnNn = N0. Derive Eq. (16.5.22)
by maximizing the von Neumann entropy subject to these constraints.
Exercise 16.5.7 Derive Eq. (16.5.25) by substitution of the result, Eq. (16.5.24), for the
grand canonical ensemble in the general expression for the density matrix, Eq. (16.5.4),
and by using Eqs. (16.5.5, 16.5.19).
https://doi.org/10.1017/9781108877787.017 Published online by Cambridge University Press17 Quantum Rate Processes
In many applications to “real-life” problems, the rates of specific elementary processes
are of interest. It may be the rate of charge hopping between impurities in a disordered
material or between molecules in solution, the rate of electronic energy (exciton) trans￾fer between chromophores in biological photosynthetic systems, or the rate of light
absorption/emission by a nanocrystal; rates are of the essence. And yet, the emergence
of a seemingly unidirectional process associated with a single rate constant (a single
characteristic timescale) is a nontrivial consequence from the rigorous perspective of
quantum mechanics. Indeed, such a description involves several approximations that
are valid only in the limit of weak interaction and extensive averaging, which eventu￾ally lead to Markovian-like quantum dynamics. In this chapter we draw the connection
between exact quantum dynamics and rate constants. Implementations of the gen￾eral formulation (e.g., of Fermi’s golden rule) to specific processes will be discussed in
Chapter 18, and the connection to Markovian dynamics in open quantum systems will
be discussed in Chapters 19 and 20.
17.1 Transition Rates between Pure States
We start by recalling that as far as the evolution of a single nonstationary solu￾tion to the Schrödinger equation is concerned, transition probabilities are inherently
time-dependent. This is trivially true for systems in which the Hamiltonian depends
explicitly on time, but even when the underlying Hamiltonian is time-independent (see
Section 15.1), the transition probability from an initial state, |χii, to another specific
final state, |χfi, namely Pi→f(t) = |hχf
|ψ(t)i|2 = |hχf
|Uˆ(t,0)|χii|2
, is a superposition of
oscillatory waves in time (see Eqs. (15.1.9, 15.1.14)). Consequently, any (nonzero) tran￾sition rate between |χii, and |χfi, defined as the time-derivative of the corresponding
transition probability, ki→f(t) = ∂Pi→f
(t)
∂t
, also is time-dependent.
We now focus on the most relevant context in which transition rates are of interest,
that is, when the initial and final states are associated with some zero-order Hamilto￾nian, Hˆ
0. In a typical scenario, the experimental characterization of the initial and final
states (namely, the preparation and the measurement) is defined in the framework of
Hˆ
0, where the experiment selects either a pure eigenstate, or a coherent superposition
of eigenstates, or a mixed state of Hˆ
0 eigenstates. The system Hamiltonian includes
334
https://doi.org/10.1017/9781108877787.018 Published online by Cambridge University Press335 17.1 Transition Rates between Pure States
an additional interaction term, Hˆ(t) = Hˆ
0 +Vˆ(t), which induces transitions of popu￾lations and/or coherences between Hˆ
0 eigenstates whose rates are of interest (several
examples will be encountered in the following chapters). The interaction may be local
in space (as in a scattering experiment) or in time (as in a pulsed laser excitation), and
it is often sufficiently weak such that the characterization of the initial and final states
in terms of Hˆ
0 remains relevant. Moreover, the weak interaction (in a sense that will be
elaborated below) merits the use of time-dependent perturbation theory for assessing
the transition rates.
The exact rate of transition from an initial coherent state, |χii, to a final eigenstate
of the zero-order Hamiltonian, Hˆ
0|χfi = ε f
|χfi, reads (see Eq. (15.5.13)) ki→f(t) =
2
h¯
Imhχi
|Uˆ †(I)
(t,0)|χfihχf
|Vˆ
I(t)Uˆ (I)
(t,0)|χii. Here Uˆ (I)
(t,0) is the interaction picture
propagator (Eq. (15.3.9)), and Vˆ
I(t) = e
it
h¯
Hˆ
0Vˆ(t)e
−it
h¯
Hˆ
0
. A first-order approximation for
the rate is obtained by expanding the propagator up to first order in the Dyson series,
Uˆ (I)
(t, 0) ∼= ˆI +
−i
h¯
rt
0
dt
0VI(t
0
). Restricting to final states that are orthogonal to the ini￾tial state and keeping the nonvanishing terms to lowest order in the interaction (see
Ex. 17.1.1), we obtain
k
(1)
i→f
(t) = 2
h¯
2 Re
wt
0
dt0
hχi
|VI(t
0
)|χfihχf
|Vˆ
I(t)|χii ; hχf
|χii = 0. (17.1.1)
In the case where both the initial and the final states are Hˆ
0-eigenstates, namely,
Hˆ
0|χii = εi
|χii and Hˆ
0|χfi = ε f
|χfi, the rate reads (Ex. 17.1.1)
k
(1)
i→f
(t) =
2
h¯
2 Re
wt
0
dτe
i
h¯
(ε f −εi)τ
hχi
|Vˆ(t −τ)|χfihχf
|Vˆ(t)|χii. (17.1.2)
Notice that this result for the first-order transition rate can be derived directly as
well, by taking the time-derivative of the first-order perturbation expression for the
transition probability (Eq. 15.6.10); see Ex. 17.1.2.
As we can see, the first-order transition rate, Eq. (17.1.2), is time-dependent for
two reasons. First, the interaction may depend on time explicitly, which appears as
hχf
|Vˆ(t)|χii, and second, the time integrand is a function of τ, resulting in a time￾dependent integral. The latter is inherent for transitions between any two orthogonal
Hˆ
0-eigenstates and applies also when the interaction is constant for τ ≥ 0, namely, for
Vˆ(τ) 7→ Vˆ , where
k
(1)
i→f
(t) =
2|hχf
|Vˆ |χii|2
h¯
2 Re
wt
0
e
i
h¯
(ε f −εi)τ
dτ =
2|hχf
|Vˆ |χii|2
h¯(ε f −εi)
sin
(ε f −εi)t
h¯

. (17.1.3)
The state-to-state transition rate is shown to be time periodic in this case (Ex. 17.1.3).
Exercise 17.1.1 (a) Use the first-order Dyson expansion, Uˆ (I)
(t,0) ∼= ˆI +
−i
h¯
rt
0
dt
0VI(t
0
),
in the exact expression for the transition rate (Eq. (15.5.13)) to obtain the first-order
https://doi.org/10.1017/9781108877787.018 Published online by Cambridge University Press336 Quantum Rate Processes
approximation for the rate, Eq. (17.1.1). (b) Show that when the initial and final states
are eigenstates of Hˆ
0 the first-order approximation for the rate is given by Eq. (17.1.2).
Exercise 17.1.2 The first-order approximation for the transition probability is given by
Eq. (15.6.10). Show that the rate expression, Eq. (17.1.2), is indeed the time derivative
of the transition probability.
Exercise 17.1.3 Derive the expression for the time-dependent transition rate,
Eq. (17.1.3), from Eq. (17.1.2) for a time-independent interaction operator, Vˆ(τ) 7→ Vˆ .
17.2 The Emergence of a Rate Constant and Fermi’s Golden Rule
In spite of the intrinsic time-dependence of transition rates between pure states, in
applications of quantum theory we often encounter the notion of time-independent
“rate constants” for transitions between different states of a system. Typical exam￾ples are absorption or emission of radiation, charge and/or energy transfer between
molecules or chromophores, chemical reactions, and so forth. How do rate constants
come about in quantum mechanics? To answer this question, we first need a proper def￾inition of rate constants in the context in which they are used, namely within kinetic
equations.
Let us consider the simplest kinetic equation for a transition between two comple￾mentary states of a given system, the initial state “i” and the final state “ f ”:
P˙
i(t) = −ki, f Pi(t) +kf,iPf(t),
P˙
f(t) = −kf,iPf(t) +ki, f Pi(t)
(17.2.1)
where Pi(t) and Pf(t) are probabilities for populating the state “i” and the state “ f ”
respectively, subject to probability conservation, Pi(t) + Pf(t) = 1. A practical way to
experimentally measure the rate constant ki, f
in Eq. (17.2.1) is to prepare the system in
the initial state “i,” where Pi(0) = 1 and Pf(0) = 0, and to follow the rate of change in
the populations at short times where the populations have not changed much. Approx￾imating Pi(t) ≈ 1 and Pf(0) ≈ 0, Eq. (17.2.1) yields the following practical definition
for the rate constant:
ki, f ≡ P˙
f(t)|t1/ki, f
. (17.2.2)
Indeed, within the realm of the kinetic equations, Eq. (17.2.1), the time-derivative of
the transition probability is effectively constant for times much shorter than 1/ki, f
, and
therefore it can be identified with the rate constant.
The emergence of a constant transition rate at short times is a characteristic of the
kinetic equations, which seems to be in apparent contrast with the quantum mechan￾ical state-to-state transition rate, as given in Eq. (17.1.3). Indeed, in the short time
limit the latter is shown to be linear in time, k
(1)
i→f
(t)−−→t→0
2|hχ f
|Vˆ |χii|2
h¯
2
t (which is also true
https://doi.org/10.1017/9781108877787.018 Published online by Cambridge University Press337 17.2 The Emergence of a Rate Constant and Fermi’s Golden Rule
|χi〉
ωi , f
|χf〉 |χi〉 {|χf〉}
k i→{f }
Ftigure 17.2.1 The change from an oscillatory transition probability in a two-level system (left) into a “unidirectional” decay in the
case of an ensemble of final states (right).
for the exact result (Eq. (15.6.11)). At longer times, the solution of the kinetic equa￾tions, Eq. (17.2.1), that is, Pi(t) = Pi(0)e
−(ki, f +k f,i
)t +
k f,i
ki, f +k f,i
(1 − e
−(ki, f +k f,i
)t
), predicts
an exponential decay of the state populations, again, in contrast with the apparent
time-periodic oscillations in Eq. (17.1.3). In fact, it is only in the infinite time limit,
that k
(1)
i→f
(t) approaches a constant, namely, limt→∞ k
(1)
i→f
(t) = 2π
h¯
|hχf
|Vˆ |χii|2δ(ε f −εi).
However, the validity of the first-order approximation at long times (t >> h/|ε f −εi
|)
is limited to, |hχf
|Vˆ |χii| << |ε f − εi
| (see Eq. (15.6.16)), for which δ(ε f − εi) = 0.
The conclusion is that within its regime of validity, Eq. (17.1.3) associates a constant
state-to-state rate with a vanishing rate.
Indeed, transitions between two pure orthogonal states as expressed in Eqs. (17.1.2,
17.1.3) cannot be associated with a rate constant. This, however, does not exclude the
emergence of rate constants in other cases. In fact, transitions between two pure states
can be rarely addressed in actual experiments, since the preparation of the “initial
state” and the measurement of the “final state” can rarely address specific eigenstates
of an underlying Hamiltonian. In the more common situation, transitions occur between
mixed ensembles of quantum states. For example, consider an electron transfer event
between two impurities in a solid or between two molecules in a solution. The mea￾surement concerns the initial and final electronic states, but the change in electronic
state involves a manifold of different states which depend, for example, on the posi￾tions of atoms in the environment (phonons in the solid, or the molecular dipoles in a
solvent). These additional degrees of freedom affect the transfer rate, but they are not
measured directly, since only the electronic state is concerned. The effect of specific
states in the environment is therefore averaged by the measurement in an incoherent
fashion, which merits a mixed state description (see Chapter 16).
To see how a rate constant may come about when a transition into a mixed ensem￾ble of states is concerned, let us analyze the rate of transition from a single eigenstate
(|χii) of Hˆ
0 into a finite discrete set of eigenstates of Hˆ
0,({|χfi}), orthogonal to |χii.
We seek the rate of transition to the entire final ensemble, regardless of the iden￾tity of specific final states (see Fig. 17.2.1). According to the postulates of quantum
mechanics, the transition probability is additive in this case, Pi→{ f }
(t) = ∑
f∈{ f }
Pi→f(t) =
∑
f∈{ f }
|hχf
|ψ(t)i|2
(see Section 11.1, postulate 4), and consequently the transition rate
to the ensemble is the sum of the individual state-to-state transition rates. In this sec￾tion we shall focus on interaction operators, which remain constant in time after the
https://doi.org/10.1017/9781108877787.018 Published online by Cambridge University Press338 Quantum Rate Processes
initial time, namely, Vˆ(τ) 7→ Vˆ for τ ≥ 0. Extension of the conclusions to the general
case of a time-dependent interaction will be addressed in Section 17.3.
In the absence of an exact solution, we invoke the general result of first-order per￾turbation theory, k
(1)
i→f
(t), remembering to keep track of the conditions for its validity.
Using Eq. (17.1.3), the rate of transition to the entire final ensemble obtains the form
k
(1)
i→{ f }
(t) = ∑
f∈{ f }
k
(1)
i→f
(t) = 2
h¯
2
wt
0
∑
f∈{ f }
|hχf
|Vˆ |χii|2
cos(ωf,iτ)dτ, (17.2.3)
where ωf,i ≡
ε f −εi
h¯
. We recall that when the coupling to a specific final state is large
in comparison to the corresponding energy difference, namely |hχf
|Vˆ |χii| >> |h¯ωf,i
|,
the approximation, k
(1)
i→f
(t), is valid only in the short time limit, t ≤ h¯/|hχf
|Vˆ |χii| (see
Eq. (15.6.16)), where the transition probability is quadratic in time (see Eq. (15.6.11)),
and the transition rate is linear in time, k
(1)
i→f
(t) ∼=
2
h¯
2
|hχf
|Vˆ(0)|χii|2
t. The validity of
Eq. (17.2.3) is therefore limited in time by the largest of the coupling matrix elements:
t ≤ tmax =
h¯
max(|hχf
|Vˆ |χii|)
. (17.2.4)
The transition rate, k
(1)
i→{ f }
(t), is expressed as a time integral (Eq. (17.2.3)) over a sum
of cosine functions, weighted by the squared coupling matrix elements, |hχf
|Vˆ |χii|2
.
Within its validity time-window (t ≤ tmax), the contributions of “strongly interact￾ing” states (|hχf
|Vˆ |χii| >> |h¯ωf,i
|) to the integrand are nearly constants (which would
amount to a rate that is linear in time). However, the contributions of “weakly inter￾acting” states (|hχf
|Vˆ |χii| << |h¯ωf,i
|) are oscillatory, where we recall that k
(1)
i→f
(t) can
be valid for a large number of oscillation periods, as long as |hχf
|Vˆ |χii| << |h¯ωf,i
| (see
Section 15.6).
At short times, τ → 0, all the contributions to the summation in Eq. (17.2.3) interfere
constructively. At longer times, however, dephasing of the different oscillations leads
to cancellation of terms with opposite signs and to a decay of the integrand toward
zero, as demonstrated in Fig. 17.2.2 for a specific model. The characteristic time in
which the integrand decays to zero is set roughly by the highest oscillation frequency
and corresponds roughly to half of its time period,
td ≈
π
max(|ωf,i
|)
. (17.2.5)
For times much longer than the decay time, td << t, the integrand nearly vanishes, and
the time integral converges approximately to a constant value as a function of time.
Hence, a “rate constant” emerges in this “long time” limit:
k
(1)
i→{ f }
(t)|t>>td ≡ ki→{ f }
. (17.2.6)
We can attempt to make a step forward at this point, claiming that since at long times
the result of the integral, Eq. (17.2.3), does not depend on time, we can replace it by its
infinite time limit to obtain
https://doi.org/10.1017/9781108877787.018 Published online by Cambridge University Press339 17.2 The Emergence of a Rate Constant and Fermi’s Golden Rule
Ftigure 17.2.2 Numerical illustration of Eq. (17.2.3) for a concrete model. The initial state energy is set to zero, εi = 0, and the final
ensemble includesN states in the energy range, −ε0 < ε f < ε0, with a constant coupling matrix element,
|hχf
|Vˆ |χii| ≡ V, and a constant nearest level spacing, ∆ = 0.1V. Using dimensionless parameters,
∆˜ = ∆/V, ε˜0 = ε0/V,ω˜ f,i = h¯ωf,i/V, τ˜ = τV/h¯, and ˜k(τ˜) = hk¯ (t)/V, Eq. (17.2.3) for this model
obtains the form ˜k
(1)
i→{ f }
(t˜) = 2
t˜r
0
N
∑
f=1
cos(ω˜ f,iτ˜)dτ˜. The upper graph depicts the normalized time integrand,
2
N
N
∑
f=1
cos(ω˜ f,iτ˜)as a function of τ˜ in the range, 0 ≤ τ˜ ≤ 1 (where perturbation theory may be valid). The
integrand is shown to decay within a time period that shortens, as the bandwidth (2ε˜0)increases. (as N increases
from 1 to 100 and to 10000 at a constant ∆˜.) This is emphasized in the middle graph using a logarithmic timescale,
where the characteristic decay times, π/max(ω˜ f,i) = π/ε˜0, are marked by arrows. In the lower graph, the
corresponding time integrals, ˜k
(1)
i→{ f }
(t˜), are plotted, demonstrating that a rate constant is obtained only as the
bandwidth increases, ε˜0  1. Notice that the rate constant converges with increasing bandwidth,
˜k
(1)
i→{ f }
(t˜)−−−→ N→∞
2π/∆˜, and hence, k
(1)
i→{ f }
−−−→ N→∞
2πV
2/(h¯∆). This coincides with the result for a continuous
spectrum (see Ex.17.2.4).
ki→{ f }
∼=
2
h¯
2
w∞
0
dτ ∑
f∈{ f }
|hχf
|Vˆ |χii|2
cos(ωf,iτ)
=
1
h¯
2 Re
w∞
−∞
dτ ∑
f∈{ f }
|hχf
|Vˆ |χii|2
e
−iωf.iτ
,
=
2π
h¯ ∑
f∈{ f }
|hχf
|Vˆ |χii|2
δ(εi −ε f) (17.2.7)
where in the last step we used the representation of Dirac’s delta, 2πh¯δ(εi −
ε f)= r∞
−∞
exp
−i(ε f −εi)τ
h¯

dτ. This formal expression for the rate is referred to as “Fermi’s
golden rule.” Dirac’s delta attributes the transition to one of the final states, whose
energy strictly matches the initial state energy. Recalling, however, that the infinite
https://doi.org/10.1017/9781108877787.018 Published online by Cambridge University Press340 Quantum Rate Processes
time limit is merely an idealization, where in fact there are restrictions on the times
in which Eq. (17.2.3) is valid, as discussed in some detail in what follows, the Dirac
delta should be thought of as an idealized limit of a broader distribution over the dif￾ferent final states. Nevertheless, Fermi’s golden rule emphasizes that while at short
times the initial state population is transferred to the entire ensemble of final states,
on a longer timescale, where a constant rate emerges, the transition is restricted by
energy conservation to final states whose energy matches the initial state energy. (This
will be elaborated in the context of the Markovian approximation, to be discussed in
Chapter 19; see, e.g., Ex. 19.2.8.) In what follows we discuss the limitations on the rate
calculation by Eq. (17.2.3) and express these limitations in terms of restrictions on the
parameters of the ensemble of final states, for which Fermi’s golden rule is applicable.
First, we recall that by its definition, a rate constant is equal to the rate of probabil￾ity transfer only in a short time limit, in which the initial probability hardly changes
(t << 1/ki→{ f }
, Eq. (17.2.2)). To comply with the result that k
(1)
i→{ f }
(t) reaches a con￾stant value only in the long time limit, td << t, a timescale separation is needed: Fast
relaxation of the oscillations within ∼ td owing to multiple final states, followed by
slow kinetics. The calculation of the “rate constant” by Eq. (17.2.3) is then relevant
only within a given time window, td << t << 1/ki→{ f }
. For this time window to exist,
we must have td << 1/ki→{ f }
, namely
td =
π
max(|ωf,i
|)
<<
1
ki→{ f }
. (17.2.8)
This means that the rate of population transfer should be much smaller than the maxi￾mal transition frequency into the manifold of final states, ki→{ f } << max|ωf,i
|/π. This
condition on the final ensemble is often referred to as a “wide-band” condition. It means
that the maximal energy gap from the initial to a final state, max(ε f −εi) = max(h¯ωf,i),
must be significantly larger than h¯/ki→{ f }
. As we shall discuss in Chapter 19, this wide￾band condition also marks the emergence of Markovian dynamics within quantum
mechanics.
Another time limit that restricts the validity of Fermi’s golden rule is related to its
derivation within first-order perturbation theory. Indeed, Eq. (17.2.4) sets an upper
bound on the validity of Eq. (17.2.3). To converge to a rate constant within this validity
window, we must have td << tmax, which means
td =
π
max(|ωf,i
|)
<<
h¯
max(|hχf
|Vˆ |χii|)
. (17.2.9)
This additional limitation restricts the coupling matrix elements between the initial
state and each of the states within the final ensemble. The condition is often referred to
as the weak coupling limit, which means that the coupling matrix elements must be small
in comparison to the energy bandwidth of the manifold of final states.
Finally, there is another limit that may restrict the applicability of Eq. (17.2.3) to
long times. The summation over cosine functions may revive its initial value (in full, or
in part) owing to rephasing after the time period of the slowest oscillation, namely
tr ≈
2π
min(|ωf,i
|)
. The precise conditions for the emergence of revivals depend on the
https://doi.org/10.1017/9781108877787.018 Published online by Cambridge University Press341 17.2 The Emergence of a Rate Constant and Fermi’s Golden Rule
specifics of the frequency spectrum and will not be addressed here. Nevertheless,
the integral over the sum of cosines can generally be approximated as a constant
only up to some time, tr
. Notice that this is not a limitation if min(|ωf,i
|) → 0 and
tr → ∞. This condition is readily fulfilled if the band of final state energies is contin￾uous, and if the initial state energy is included within this band. Nevertheless, for a
discrete ensemble of final states, a finite tr may restrict the applicability of Eq. (17.2.3).
(Notice that this restriction is irrelevant when tr >> min(1/ki→{ f }
,tmax), namely, when
min(|ωf,i
|) << max({|hχf
|Vˆ |χii|/h¯}, ki→{ f }
), which means that εi coincides with {ε f }
within a finite tolerance.)
We now consider explicitly a dense ensemble of final states, associated with a contin￾uous spectrum of Hˆ
0. Indeed, as discussed in the next chapter, “real-life” applications
of Fermi’s golden rule typically involve ensembles with “macroscopic” numbers of
bound degrees of freedom, and/or open systems associated with continuous spec￾tra. Formally, the discrete summation over the coupling matrix elements to the final
states is replaced by an integral over a (positive) coupling function, λ
2
i,{ f }
(ε f) ≡
|hχf(ε f)|Vˆ |χii|2
, which is a continuous function of the energy, multiplied by the energy￾dependent density of final states, ρ{ f }
(ε) ≡
dn{ f }
(ε)
dε
(see Eq. (5.5.8)). Defining a spectral
density function,
Ji,{ f }
(ε) ≡ 2πλ
2
i,{ f }
(ε)ρ{ f }
(ε), (17.2.10)
Eq. (17.2.3) for the transition rate obtains the form
k
(1)
i→{ f }
(t) = 1
πh¯
2
wt
0
dτ
w
dεJi,{ f }
(ε) cos((ε −εi)τ/h¯). (17.2.11)
The properties of the coupling between the initial state and the final ensemble are there￾fore fully encoded in the “spectral density” function. In particular, the time integrand
in the rate expression, Re e
−iεiτ/h¯
r
dεJi,{ f }
(ε)e
iετ/h¯
, can be identified with the Fou￾rier transform of the spectral density. Within the limitations of perturbation theory
(namely when the interaction is sufficiently weak, Eq. (17.2.9)), and when the spectral
density is a sufficiently smooth and broad function of the energy (a wide band of final
states, Eq. (17.2.8)), the time integrand decays sufficiently fast on the kinetics timescale
and the upper limit of the time integral can be taken to infinity, leading to (Ex. 17.2.1):
ki→{ f }
∼= limt→∞k
(1)
i→{ f }
(t) = 1
h¯
Ji,{ f }
(εi) = 2π
h¯
λ
2
i,{ f }
(εi)ρ{ f }
(εi). (17.2.12)
This is a central result, as it expresses the rate constant, when it exists, in terms of the
properties of the final ensemble to which the initial state is coupled. In particular, the
rate increases linearly with the density of states and with the squared coupling matrix
elements to the final states that match the initial state energy. The latter can often be
estimated to a good precision or obtained directly from experiments. In Chapter 18 we
shall review some applications of Fermi’s golden rule, demonstrating its usefulness and
widespread usage in the context of nanoscale phenomena.
Notice that the result for a discrete ensemble, Eq. (17.2.7), is readily regained from
Eq. (17.2.12) in the limit where the density of final states reveals the underlying discrete
https://doi.org/10.1017/9781108877787.018 Published online by Cambridge University Press342 Quantum Rate Processes
level structure. Setting the density of states to ρ{ f }
(ε) = ∑
f
δ(ε −ε f), the spectral density
reads Ji,{ f }
(ε) ≡ ∑
f
2πλ
2
i,{ f }
(ε f)δ(ε −ε f), which yields for the overall rate (Ex. 17.2.2)
ki→{ f } =
2π
h¯ ∑
f
λ
2
i,{ f }
(ε f)δ(εi −ε f). (17.2.13)
Exercise 17.2.1 One of the representations of Dirac’s delta reads δ(εi − ε f) =
1
2πh¯
r∞
−∞
dτ exp
−i(ε f −εi)τ
h¯

dτ. Use this representation to calculate the infinite time limit
of the first-order rate, Eq. (17.2.11), as given in Eq. (17.2.12) (notice that the integrand
in Eq. (17.2.11) is an even function of time).
Exercise 17.2.2 The spectral density for a discretely resolved density of states reads
Ji,{ f }
(ε) ≡ ∑
f
2πλ
2
i,{ f }
(ε f)δ(ε −ε f). (a) Show that Eq. (17.2.13) is obtained directly from
Eq. (17.2.12) in this case. (b) Derive Eq. (17.2.13) by substituting the given spectral
density in Eq. (17.2.11) and taking the infinite time limit of the integral.
Now let us consider an idealized model in which the spectral density is continuous
and uniform over a finite energy band:
Ji,{ f }
(ε) = 
J0 ; |ε| ≤ ε0.
0 ; |ε| > ε0
(17.2.14)
Assuming the conditions for validity of the golden rule formula hold, Eq. (17.2.12)
immediately yields in this case
ki→{ f } =

J0/h¯ ; εi ≤ ε0,
0 ; εi > ε0
(17.2.15)
which means that the decay rate is constant if the initial state energy overlaps with the
energy band of the final states, and vanishes otherwise.
It is instructive (and straightforward, in this case) to return to the formulation of
the rate as a time integral (Eq. (17.2.11)) and to inspect the validity of the infinite time
limit leading to Eq. (17.2.12). Substitution of Eq. (17.2.14) in Eq. (17.2.11) yields
ki→{ f } =
J0
πh¯
2
wt
0
dτ
wε0
−ε0
dε cos((ε −εi)τ/h¯). (17.2.16)
Performing first the energy integral, we obtain (Ex. 17.2.3)
ki→{ f } =
2J0ε0
πh¯
2
wt
0
dτ cos(εiτ/h¯)
sin(ε0τ/h¯)
(ε0τ/h¯)
. (17.2.17)
As we can see, the time integrand is a decaying function (sinc (ε0τ/h¯) −−−→
ε0τ/h¯→∞
0), mul￾tiplied by an oscillatory function of time, whose frequency is set by the initial state
energy, εi
. If the initial state energy is well outside the band of final states, |εi
| >> |ε0|,
the oscillations are rapid on the decay timescale, which will lead to a vanishingly
https://doi.org/10.1017/9781108877787.018 Published online by Cambridge University Press343 17.2 The Emergence of a Rate Constant and Fermi’s Golden Rule
small rate constant. If, however, the initial state energy is at the center of the band,
|εi
| << |ε0|, the oscillations are suppressed, and the rate is maximized. Let us analyze
this regime by setting εi = 0, in which case the time integrand is just the sinc function.
The first zero of sinc (ε0τ/h¯) is reached at time τ = πh¯/ε0, which coincides with half a
time period of the largest frequency in this model, namely max(ωf,i) = ε0/h¯. This decay
time is in line with our qualitative discussion of the decay of a discrete sum of cosine
functions (see Eqs. (17.2.3, 17.2.5)), and with the numerical results demonstrated in
Fig. 17.2.2. As the bandwidth of final state energy (namely, ε0) increases, the decay
time shortens. If the bandwidth becomes infinite (“the wide band limit”), the decay￾ing function approaches δ(τ), and therefore the integral converges to J0
h¯
, namely to
the golden rule result, Eqs. (17.2.12, 17.2.14), already at finite times (see Ex. 17.2.4).
Notice that when bandwidth of the final ensemble is “infinite,” the other conditions
for the validity of the golden rule expression (Eqs. (17.2.8, 17.2.9)) are guaranteed to
hold, namely max(|ωf,i
|) >> max({|hχf
|Vˆ |χii|/h¯}, ki→{ f }
).
Exercise 17.2.3 The energy integral in Eq. (17.2.11) is related to the Fourier transform
of the spectral density, r
dεJi,{ f }
(ε) cos((ε − εi)τ/h¯) = Re e
−iεiτ/h¯
r
dεJi,{ f }
(ε)e
iετ/h¯
.
Show that for the “square window” spectral density function, given in Eq. (17.2.14),
the energy integral reads 2J0ε0Re e
−iεi
τ
h¯
sin(ε0τ/h¯)
ε0τ/h¯
.
Exercise 17.2.4 (a) One of the representations of Dirac’s delta reads δ(x) =
limα→∞
sin(αx)
πx
. Use it to show that the infinite bandwidth limit of the transition rate in
Eq. (17.2.17) is ki→{ f } =
J0
h¯
. (b) In Fig. 17.2.2 numerical results are presented for a dis￾crete model, in which the initial state energy is set to zero, εi = 0, and the final ensemble
includes N states in the energy range, −ε0 < ε f < ε0, with a constant coupling matrix
element, |hχf
|Vˆ |χii| ≡ V and a constant nearest level spacing, ∆. As N increases (at a
constant level spacing), the rates calculated by Eq. (17.2.3) are shown to converge to
k
(1)
i→{ f }−−→
N→∞
2πV
2/(h¯∆). Obtain this result analytically by replacing the discrete summa￾tion over final states by an integral with a constant density of states, ρ = 1/∆. Show that
the discrete model coincides with the result of the continuous model (a) by identifying the
spectral density, J0 = 2πV
2/∆.
We can therefore conclude that a rate constant for transition from an initial to a
final state does emerge in quantum mechanics, as long as the final state is not a finely
resolved pure state, but rather an ensemble of states that is dense and wide in energy
(see Fig. 17.2.1). Moreover, the rate constant does not appear instantaneously, but
only after a transient time of relaxation of the quantum oscillations between the ini￾tial state and individual final states at different energies. When the bandwidth of the
final state energies is sufficiently large, this fast relaxation precedes population trans￾fer between the initial and the final states, at a constant rate. The preceding derivation
of the rate expression was based on perturbation theory, which restricted its applica￾bility to the limit of weak coupling between the initial and final states, and to short
times on the population transfer timescale, where transfer rate can be identified with
the “rate constant.” In Chapter 19 we shall follow an alternative derivation leading to
https://doi.org/10.1017/9781108877787.018 Published online by Cambridge University Press344 Quantum Rate Processes
the emergence of rate constants over the entire kinetics timescale, including the infi￾nite time limit of relaxation to equilibrium. That derivation is based on a Markovian
approximation, which is closely related to the “weak coupling” and “wide band” limits
encountered in this chapter.
17.3 Thermal Rate Constants
In Section 17.2 we analyzed the rate of transition from a single pure state, typically an
eigenstate of some meaningful zero-order Hamiltonian, into a group of other (final)
eigenstates of the same Hamiltonian. Here we emphasize that in many cases of inter￾est, the experimental preparation of an initial state does not select a single eigenstate,
but rather a group of eigenstates. In some cases, the experiment prepares a coherent
superposition of states of a relevant zero-order Hamiltonian, resulting in dynamics of
both populations and coherences (see Chapter 16). In the most common case, however,
the initial state corresponds to an incoherent (mixed) ensemble, in which the relative
weights of different eigenstates are associated with a “quasi-equilibrium” state char￾acterized by macroscopic parameters such as temperature, chemical potential, and so
forth.
In this section we focus on the formulation of “thermal rates,” where the initial
ensemble corresponds to a quasi-equilibrium state, associated with a zero-order Ham￾iltonian, Hˆ
0, and a temperature, T (see Eq. (16.5.18)). Particularly, we are interested in
the rate of transition between two subsets of (orthonormal) Hˆ
0-eigenstates, {i} ≡ {|χii}
and { f } ≡ {|χfi}, where Hˆ
0|χii = εi
|χii and, Hˆ
0|χfi = ε f
|χfi. Without loss of gener￾ality, we shall assume now that every transition from {i} is only to { f } and vice versa,
either since these sets complete each other to a unity, or since the interaction oper￾ator, Vˆ , couples {i} only to the states in { f }. The two sets are associated with the
corresponding orthogonal projection operators,
Pˆ
{i} = ∑
i∈{i}
|χiihχi
| ; Pˆ
{ f } = ∑
f∈{ f }
|χfihχf
|, (17.3.1)
where
Pˆ
{i}
2 = Pˆ
{i}
; Pˆ
{i}Pˆ
{ f } = 0 ; Pˆ
{ f }
2 = Pˆ
{ f }
(17.3.2)
and
[Pˆ
{i}
,Hˆ
0] = [Pˆ
{ f }
,Hˆ
0] = 0. (17.3.3)
Denoting the probability of populating the two ensembles at time t as P{i}
(t) and
P{ f }
(t), we chose an initial state in which only the ensemble {i} is populated, namely
P{i}
(0) = 1 ; P{ f }
(0) = 0. (17.3.4)
The definition of a “thermal” rate constant depends on the assumption that quasi￾equilibrium is maintained within the initial ensemble. This is justified when the
https://doi.org/10.1017/9781108877787.018 Published online by Cambridge University Press345 17.3 Thermal Rate Constants
relaxation to equilibrium within the ensemble induced by the environment is fast on the
kinetics timescale, and when the ensemble is sufficiently large, such that the statistical
weight of nonequilibrium populations (fluctuations) is negligibly small. Without loss
of generality (see Chapter 20), we restrict ourselves here to a canonical initial ensem￾ble. The relative populations of the different Hˆ
0-eigenstates corresponds to a density
operator, ρˆ0 = e
−Hˆ
0/(kBT)/Z0, where Z0 = tr{e
−Hˆ
0/(kBT)} (see Eq. (16.5.18)). The relative
population of each specific state within the initial ensemble therefore reads
Pi(0)
P{i}
(0)
=
e
−εi/(kBT)
Z{i}
; Z{i} ≡ ∑
i∈{i}
e
−εi/(kBT)
, (17.3.5)
where Z{i}
is the partition function corresponding to the sub-ensemble of initial states.
For the selected initial condition (Eq. (17.3.4)), the initial state populations are given
as
Pi(0) = e
−εi/(kBT)
Z{i}
. (17.3.6)
In the short time limit, in which the initial populations do not change much, the transi￾tion rate from {i} to { f } is expressed in terms of a weighted average over state-specific
rates:
k{i}→{ f }
(t) ∼= ∑
i∈{i}
Pi(0) ∑
f∈{ f }
∂
∂t
Pi→f(t) = ∑
i∈{i}
Pi(0) ∑
f∈{ f }
ki→f(t). (17.3.7)
These rates can be formulated exactly (Ex. 17.3.1) in terms of the time-evolution
operator with the full Hamiltonian, Uˆ(t,0):
ki→f(t) = d
dt
tr{|χfihχf
|Uˆ(t,0)|χiihχi
|Uˆ
†
(t, 0)}. (17.3.8)
Substituting Eqs. (17.3.6, 17.3.8) in Eq. (17.3.7), we obtain formally exact expressions
for the initial probability transfer rate between the ensembles (Ex. 17.3.2),
k{i}→{ f }
(t) = d
dt
tr{Pˆ
{ f }Uˆ(t,0)ρˆ{i}
(0)Uˆ
†
(t,0)}
=
d
dt
tr{Pˆ
{ f }ρˆ{i}
(t)}, (17.3.9)
= tr

i
h¯
[Hˆ,Pˆ
{ f }
H
(t)]ρˆ{i}
(0)

where ρˆ{i}
(0) is the thermal density operator, projected onto the initial state,
ρˆ{i}
(0) ≡
e
−Hˆ
0/(kBT)Pˆ
{i}
tr{e
−Hˆ
0/(kBT)P{i}}
, (17.3.10)
and Pˆ
{ f }
H
(t) is the Heisenberg picture representation of Pˆ
{ f }
(Eq. (15.3.16)).
Exercise 17.3.1 Use Eq. (15.5.8) for the exact state-to-state transition rate, ki→f(t),
and derive Eq. (17.3.8).
https://doi.org/10.1017/9781108877787.018 Published online by Cambridge University Press346 Quantum Rate Processes
Exercise 17.3.2 (a) Substitute Eqs. (17.3.6, 17.3.8) in Eq. (17.3.7), and use the defini￾tion of the projection operators to the initial and final ensembles, Pˆ
{i} and Pˆ
{ f } (use Eqs.
(17.3.1–17.3.3), and recall that ∑
i∈{i}
hχi
|Aˆ|χii = tr{AˆPˆ
{i}}) to derive the result for the
transition rate between the two ensembles, k{i}→{ f }
(t) = d
dt
tr{Pˆ
{ f }Uˆ(t,0)ρˆ{i}
(0)Uˆ †
(t,0)}.
(b) Use this result and the definition of the time-dependent density operator (Ex. 16.4.2)
to show that k{i}→{ f }
(t) = d
dt
tr{Pˆ
{ f }ρˆ{i}
(t)}. (c) Use the result of (a) and the defi￾nition of the Heisenberg picture representation of Pˆ
{ f } (Eq. (15.3.16)) to show that
k{i}→{ f }
(t) = tr{
i
h¯
[Hˆ, Pˆ
{ f }
H
(t)]ρˆ{i}
(0)}.
Exact expressions for thermal rates are often used for the evaluation of chemical
reaction rates or transport rates in condensed phases [17.1] [17.2]. Nevertheless, in
many cases the description of the initial state in terms of an equilibrium density oper￾ator, attributed to a zero-order Hamiltonian, is experimentally relevant only when
the interaction (that induces population transfer between Hˆ
0-eigenstates) is sufficiently
weak. Since this is a common case indeed, approximated expressions for thermal rates,
based on perturbation theory, are also valid and commonly implemented.
Here we generalize the perturbative result obtained for the transition rate from a
pure state to the case of an initial thermal ensemble. Starting from Eq. (17.3.7) for the
“short-time” transition rate between the two ensembles, we replace the exact state-to￾state transition rate by its first-order approximation,
k{i}→{ f }
(t) ∼= ∑
i∈{i}
Pi(0)k
(1)
i→{ f }
(t). (17.3.11)
Using Eq. (17.2.3) for k
(1)
i→{ f }
(t), and Eq. (17.3.6) for the thermal weights ({Pi(0)}), we
obtain the first-order approximation for the thermal rate (see Ex. 17.3.3):
k
(1)
{i}→{ f }
(t) ∼=
2
h¯
2 Re
wt
0
tr
ρˆ{i}
(0)Pˆ
{i}Vˆ Pˆ
{ f }e
iHˆ
0
τ
h¯ Vˆ e
−iHˆ
0
τ
h¯

dτ. (17.3.12)
Defining the projected interaction operator, Vˆ
{i},{ f } ≡ Pˆ
{ f }Vˆ Pˆ
{i}
, the result can be com￾pactly expressed as an integral over the interaction correlation function (Ex. 17.3.4),
k
(1)
{i}→{ f }
(t) = 2
h¯
2 Re
wt
0
trn
ρˆ{i}
(0)
h
Vˆ
†
{i},{ f }
(0)
i
I
h
Vˆ
{i},{ f }
(τ)
i
I
o
dτ, (17.3.13)
where 
Vˆ
{i},{ f }
(τ)

I
= e
iHˆ
0
τ
h¯ Vˆ
{i},{ f }e
−iHˆ
0
τ
h¯ .
Exercise 17.3.3 Use Eq. (17.2.3) for k
(1)
i→{ f }
(t), and Eq. (17.3.6) for the thermal weights
({Pi(0)}), to derive Eq. (17.3.12).
Exercise 17.3.4 Use the definition Vˆ
{i},{ f } ≡ Pˆ
{ f }Vˆ Pˆ
{i} and the properties of the pro￾jection operators, Pˆ
{i} and Pˆ
{ f } (Eqs. (17.3.1–17.3.3)), to derive Eq. (17.3.13) from
Eq. (17.3.12).
https://doi.org/10.1017/9781108877787.018 Published online by Cambridge University Press347 17.3 Thermal Rate Constants
The convergence of the time integral depends on the cumulative convergence of
the state-to-state rates, {k
(1)
i→{ f }
(t)}, associated with the populated states in the ini￾tial ensemble. When the conditions leading to Fermi’s golden rule expression (see
Section 17.2) apply to each of these rates, the upper time limit of the integral in
Eq. (17.3.12) can be taken to infinity. The thermal rate constant can be readily obtained
by calculating the time integral,
k{i}→{ f }
(T) = ∑
i∈{i}
e
−εi/(kBT)
Z{i}
ki→{ f } =
2π
h¯ ∑
i∈{i}, f∈{ f }
e
−εi/(kBT)
Z{i}
|hχf
|Vˆ |χii|2
δ(ε f −εi).
(17.3.14)
The result is equivalent to substitution of the infinite time limit of k
(1)
i→{ f }
(t) (see
Eq. (17.2.7)) in Eq. (17.3.11), and using Eq. (17.3.6) for the thermal weights. The rate
constant to transfer from any state in the initial ensemble {|χii} to any state in the final
ensemble is therefore given by the state-to-state rates, summed over the final states, and
averaged over the thermal distribution within the initial ensemble.
Golden rule expressions for thermal rates are at the center of numerous theories
of quantum transport. A few important examples include the Marcus formula for
charge transfer in molecular systems, the Förster formula for electronic energy transfer
between chromophores, the theory of linear absorption and emission spectroscopies,
and Redfield’s theory for relaxation in open quantum systems. These will be addressed
in some detail in the following chapters.
Notice that a thermal rate constant may also apply even when the interaction oper￾ator depends explicitly on time. To see this, we return to the most general definition
of the first-order approximation for a state-to-state transition rate, Eq. (17.1.1). Using
this expression and Eq. (17.3.6) for the thermal weights in Eq. (17.3.11), Eq. (17.3.13)
generalizes to (Ex. 17.3.5)
k
(1)
{i}→{ f } = limt→∞
2
h¯
2 Re
wt
0
trn
ρˆ{i}
(0)
h
Vˆ
†
{i},{ f }
(t
0
)
i
I
h
Vˆ
{i},{ f }
(t)
i
I
o
dt
0
, (17.3.15)
where [Vˆ
{i},{ f }
(t)]I = e
iHˆ
0t
h¯ Vˆ
{i},{ f }
(t)e
−iHˆ
0t
h¯ = e
iHˆ
0t
h¯ Pˆ
{ f }Vˆ(t)Pˆ
{i}e
−iHˆ
0t
h¯ . Whether the infinite
time limit exists in this case depends on the system; but in many cases, the explicit time￾dependence of the interaction does not contradict a convergence of the time integral
(although Eq. (17.3.13) does not apply). In the next chapter we shall deal explicitly
with time-dependent interactions when discussing the interaction of a molecule with
electromagnetic radiation.
Exercise 17.3.5 Use Eq. (17.1.1) for k
(1)
i→f
(t), and Eq. (17.3.6) for the thermal weights
({Pi(0)}), to derive Eq. (17.3.15) from Eq. (17.3.11).
We now turn to consider a typical case in which both the initial and the final ensem￾bles of Hˆ
0-eigenstates are associated with continuous energy spectra. Formally, the
discrete summation over the initial and final states in Eq. (17.3.14) are is replaced
by integrals over a (positive) continuous function of the initial and final energies,
λ
2
{i},{ f }
(ε f
, εi) ≡ |hχf(ε f)|Vˆ |χi(εi)i|2
, multiplied by the densities of the initial and final
https://doi.org/10.1017/9781108877787.018 Published online by Cambridge University Press348 Quantum Rate Processes
states, ρ{i}
(ε) ≡
dn{i}
(ε)
dε
and ρ{ f }
(ε) ≡
dn{ f }
(ε)
dε
. Eq. (17.3.14) for the thermal rate
therefore obtains the form
k{i}→{ f }
(T) = 2π
h
w
dεi
w
dε f
e
−εi/(kBT)
Z{i}
λ
2
{i},{ f }
(ε f
, εi)ρ{i}
(εi)ρ{ f }
(ε f)δ(ε f −εi).
(17.3.16)
Using the definition of the ensemble spectral density (Eq. (17.2.10)) and noticing that,
by definition, λ
2
i,{ f }
(ε f) = λ
2
{i},{ f }
(ε f
, εi), the last equation can be rewritten as
k{i}→{ f }
(T) =
1
h¯
w
dεi
e
−εi/(kBT)
Z{i}
Ji,{ f }
(εi)ρ{i}
(εi). (17.3.17)
The thermal rate is shown to be a Boltzmann-weighted spectral “overlap integral” between
the initial ensemble density of states and the spectral density of the final ensemble.
Finally, we consider the relation between the forward and backward rates for tran￾sitions between two thermal ensembles. The same arguments applied in deriving
k{i}→{ f }
(T) are applicable also for evaluating the rate of a transition from the ensemble
{ f }, initially populated at thermal quasi-equilibrium, into the ensemble {i}. The result
readily follows:
k{ f }→{i}
(T) = 2π
h¯
w
dε f
w
dεi
e
−ε f /(kBT)
Z{ f }
λ
2
{ f },{i}
(εi
, ε f)ρ{ f }
(ε f)ρ{i}
(εi)δ(εi −ε f).
(17.3.18)
Using the symmetry of the coupling function (derived from the Hermiticity of the
interaction),
λ
2
{ f },{i}
(εi
, ε f) = |hχi(εi)|Vˆ |χf(ε f)i


2 =

hχf(ε f)|Vˆ |χi(εi)i|2 = λ
2
{i},{ f }
(ε f
, εi), (17.3.19)
we readily obtain (Ex. 17.3.6)
k{i}→{ f }
(T)
k{ f }→{i}
(T)
=
Z{ f }
Z{i}
. (17.3.20)
Notice that at thermal equilibrium in the entire system associated with the zero-order
Hamiltonian, the state populations within both {i} and { f } must be Boltzmann￾distributed (see Eq. (16.5.17)). This means that the ratio between the two ensemble
populations equals the ratio of their reduced partition functions (see Eq. (17.3.5)),
namely P
(eq)
{ f }
/P
(eq)
{i} = Z{ f }/Z{i}
. Using Eq. (17.3.20), this means that
P
(eq)
{i}
k{i}→{ f }
(T) = P
(eq)
{ f }
k{ f }→{i}
(T). (17.3.21)
The result can be readily identified as the infinite time limit of the kinetic equations
(Eq. (17.2.1); see Ex. 17.3.7), in which the rate constants correspond to k{i}→{ f }
(T)
and k{ f }→{i}
(T). It means that at equilibrium the forward (P
(eq)
{i}
k{i}→{ f }
(T)) and the
backward (P
(eq)
{ f }
k{ f }→{i}
(T)) rates of population transfer between the two ensembles
must be equal (the “detailed balance” condition). We may conclude that Fermi’s golden
rule rates describe the kinetic evolution of the ensemble all the way from its initial state
(at which the rates are calculated) toward equilibrium (the infinite time limit). This will
https://doi.org/10.1017/9781108877787.018 Published online by Cambridge University Press349 Bibliography
become apparent in Chapter 19, where the Markovian approximation and quantum
master equations are introduced.
Exercise 17.3.6 Replacing the role of the initial and final states, the rate of transition
from the thermal ensemble { f } to the ensemble {i} is given by Eq. (17.3.18). Use the
symmetry of the coupling function (Eq. (17.3.19)) to derive Eq. (17.3.20).
Exercise 17.3.7 Let us associate the relative populations of two ensembles, P{i}
(t) and
P{ f }
(t), with generic probability-conserving kinetic equations (see Eq. (17.2.1)),
P˙
{i}
(t) = −k{i}→{ f }P{i}
(t) +k{ f }→{i}P{ f }
(t)
P˙
{ f }
(t) = −k{ f }→{i}P{ f }
(t) +k{i}→{ f }P{i}
(t),
where P{i}
(t)+P{ f }
(t) = 1. Show that P{i}
(t) = P{i}
(0)e
−(k{i}→{ f }+k{ f }→{i}
)t +
k{ f }→{i}
k{i}→{ f }+k{ f }→{i}
(1−e
−(k{i}→{ f }+k{ f }→{i}
)t
), where limt→∞
P{i}
(t)
P{ f }
(t) =
k{ f }→{i}
k{i}→{ f }
.
Bibliography
[17.1] W. H. Miller, S. D. Schwartz, and J. W. Tromp, “Quantum mechanical rate
constants for bimolecular reactions,” The Journal of Chemical Physics 79, 4889
(1983).
[17.2] I. R. Craig, M. Thoss, and H. Wang, “Proton transfer reactions in
model condensed-phase environments: Accurate quantum dynamics using the
multilayer multiconfiguration time-dependent Hartree approach,” The Journal
of Chemical Physics 127, 144503 (2007).
https://doi.org/10.1017/9781108877787.018 Published online by Cambridge University Press18 Thermal Rates in a Bosonic Environment
18.1 The Spin-Boson Model
In this chapter we discuss a few implementations of Fermi’s golden rule for ele￾mentary kinetic processes in molecular and nanoscale systems. We shall focus on
processes involving charge and energy transfer that are essential to applications in
electro-optics, photovoltaics, and nanoelectronics. Particularly, we shall discuss charge
transfer between a donor and an acceptor (so-called redox centers), absorption and
emission of electromagnetic radiation by electronic dipoles, and electronic energy
transfer (exciton transfer). In all these cases the process is characterized by a measura￾ble change in the electronic state populations within the underlying system (a molecule,
a quantum dot, a defect in a lattice, and so forth). However, this change is coupled to
mechanical degrees of freedom, attributed to the atomic nuclei. These nuclear degrees
of freedom affect the electronic transition and sometimes provide the driving force
for its occurrence. Therefore, they are an essential part of the system and must be
accounted for in the relevant system Hamiltonian.
Being much lighter particles, the electrons are typically much faster than the atomic
nuclei. This is also reflected in the differences in energy between electronic states (when
the nuclei are clumped), which are typically much larger than differences in energy
between nuclear (vibrational) states (when the electronic state is fixed), as discussed in
Section 14.2. In the examples addressed here, two electronic states (e.g., “donor” and
“acceptor” or “ground” and “excited”) are assumed to be well separated in energy from
other electronic states for all the relevant nuclear configurations. This implies that the
electronic degree of freedom can be effectively associated with a (nuclear coordinate–
dependent) two-level system Hamiltonian. Formally, since the space of 2×2 matrices
is spanned by Pauli’s spin matrices (see Eq. (13.1.17)), the electronic degree of freedom
is mapped on a spin-half system.
The energy at each electronic state depends on the configuration of the relevant
nuclei. Near the minimal energy configuration, the harmonic approximation can be
invoked (see Chapter 8), such that the corresponding potential energy surface is
approximated as a sum of harmonic oscillators (Eq. (8.2.4)). Anharmonic corrections
are essential for the detailed nuclear dynamics. Nevertheless, for the purpose of charac￾terizing the effect of the multidimensional nuclear system on electronic transitions, the
harmonic approximation provides a reasonable starting point, where analytical results
can be derived (see what follows). Within the harmonic model, nuclear excitations and
350
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press351 18.1 The Spin-Boson Model
de-excitations are associated with creation and annihilation of bosonic particles (see
Dirac’s ladder operators, Eqs. (8.5.3, 8.5.4)), where the corresponding operators satisfy
the bosonic commutation relations (Eq. (8.5.7)).
The Hilbert space of the system composed of the electronic states and the nuclear
coordinates is therefore a tensor product of the respective subspaces. Using the spin
operators, σˆx, σˆz
, and ˆI (Eq. (13.1.17)), and the dimensionless position and momentum
operators, {Qˆ
j} and {Pˆ
j}, corresponding to harmonic oscillators at frequencies {ωj},
the generic system is mapped on a “spin-boson” model Hamiltonian [18.1],
Hˆ = ˆI ⊗
Nω
∑
j=1
h¯ωj
2
(Pˆ
2
j +Qˆ
2
j
)+σx ⊗γ ˆIQ +σz ⊗∆E
ˆIQ +σz ⊗
Nω
∑
j=1
h¯ωj∆jQˆ
j
. (18.1.1)
Using Pauli’s matrix representations of the spin operators (Eq. (13.1.17)), this Hamil￾tonian can be expressed as a 2×2 matrix of nuclear space operators,
Hˆ =

Hˆ
1,Q γ ˆIQ
γ ˆIQ Hˆ
2,Q

. (18.1.2)
The diagonal terms are nuclear space operators associated with each one of the elec￾tronic states. Each electronic state defines a multidimensional potential energy surface
(PES), which is a sum over harmonic potential wells, where the equilibrium configu￾ration of the jth oscillator is either Qj = −∆j or Qj = +∆j
, depending on whether the
electronic state is “1” or “2” (see Ex. 18.1.1):
Hˆ
1,Q = ∆E +
Nω
∑
j=1
h¯ωj
2
(Pˆ
2
j +Qˆ
2
j
)+h¯ωj∆jQˆ
j
Hˆ
2,Q = −∆E +
Nω
∑
j=1
h¯ωj
2
(Pˆ
2
j +Qˆ
2
j
)−h¯ωj∆jQˆ
j
. (18.1.3)
At each electronic state, the minimal energy is obtained when all the oscillator coor￾dinates are set to their equilibrium configurations. Without loss of generality, those
minimal energies are set to ∆E and −∆E for the electronic states “1” and “2,” respec￾tively. The off-diagonal terms in Eq. (18.1.2) are the interstate electronic coupling
operators. Within this model, the couplings are characterized by a single parameter,
γ, and are assumed to be independent of the nuclear coordinates (proportional to an
identity operator in the nuclear space).
In the following sections, the spin-boson model Hamiltonian is implemented for
analyzing different scenarios. In each case, the physical meanings of the different model
parameters and their relation to a realistic description of the underlying system are
outlined.
Exercise 18.1.1 Use the matrix representations of the spin operators (Eq.( 13.1.17))
to identify the explicit form of the nuclear space Hamiltonians (Eq. (18.1.3)), as the
diagonal elements of the spin-boson model Hamiltonian (Eq. (18.1.1)).
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press352 Thermal Rates in a Bosonic Environment
18.2 Charge Transfer in a Polarizable Medium
Charge transfer is one of the most central elementary processes taking place on the
nanoscale. It may be between two local defects in a solid, an interface and an adsorb￾ate, two molecules in a solvent, or two chromophores embedded inside a protein.
Charge transfer plays an essential role in the microscopic description of electric con￾ductivity, chemical reactivity, and biological activities such as vision, respiration, and
photosynthesis.
Without loss of generality, we shall focus on a generic electron transfer event between
two electron binding sites, a “donor” and an “acceptor,”
D
− +A → D+A
−. (18.2.1)
Each “site” is typically an interacting many-electron system in its own right, such
that the charge transfer is in fact between two many-electron states, where an “extra
electron” is localized either at the donor or at the acceptor site. If these two elec￾tronic states are well separated in energy from all the other electronic states in the
donor–acceptor system, one may attempt to describe the electron transfer process in
terms of a two-level system. However, as we saw in Chapter 15, transition probabil￾ity between two states in a two-level system is either zero or oscillatory in time. The
emergence of an electron transfer “rate constant” is attributed in this case to the cou￾pling of the electronic change of state to other degrees of freedom, associated with the
surroundings.
As a concrete example, let us consider an electron transfer process occurring within
a polarizable medium, where the environment degrees of freedom are identified with
surrounding electric dipoles, as illustrated schematically in Fig. 18.2.1. The electric
dipoles at the vicinity of the donor and/or acceptor sites respond to changes in the
location of the extra charge by changing their favorable orientation (the orientation
of minimal potential energy). Importantly, our interest is only in the location of the
extra charge within the donor–acceptor system, and not in the specific orientations of
each and every dipole in the environment. Nevertheless, as we shall see, the polarizable
Donor
e−
Acceptor Donor
e−
Acceptor
Ftigure 18.2.1 Electron transfer from a “donor” to an “acceptor” within a polarizable medium. The minimal energy orientations of the
surrounding electric dipoles (marked as arrows) change in response to the change in the position of the electron
charge.
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press353 18.2 Charge Transfer in a Polarizable Medium
medium plays a critical underlying role in determining the rate at which the electronic
state (namely the location of the extra charge) changes.
Nonadiabatic Charge Transfer
Prior to formulating a microscopic model that accounts explicitly for both the elec￾tronic and the medium degrees of freedom, let us obtain some qualitative insight into
the generic system as visualized in Fig. 18.2.1. In any “frozen” configuration of the sur￾rounding dipoles, the extra electron is subject to two centers of attractive forces and
hence can be qualitatively considered as a particle in some effective double well poten￾tial (see Section 6.4). The characteristics of this potential depend on the nature of the
donor and acceptor, and also on the surrounding dipole orientations. This is illustrated
in Fig. 18.2.2 for a single rotating dipole, positioned at the vicinity of the two positively
charged centers. The dipole orientation is associated with a coordinate, q, where with￾out loss of generality, the symmetric double well corresponds to the dipole vector being
perpendicular to the line connecting the two centers of attraction (q = 0). Regarding
the extra charge as a quantum particle in a double well potential, this symmetric config￾uration implies that the two lowest energy states are delocalized over the two potential
energy wells (see Section 6.4). We shall denote the energy splitting between these cor￾responding energies as VD,A. When the dipole rotates toward the right potential well
(“the acceptor,” see top panel), reflection symmetry is broken, and the two electronic
states become localized in space: a state of lower energy in the right well and a state
of higher energy in the left one. This trend continues as q increases until some opti￾mal dipole orientation (q = qA) is reached, in which the electronic energy at the right
(acceptor) potential well reaches a minimum. From there on, namely, for q > qA, the
lower state energy also increases with increasing q. The same consideration applies to
rotation of the dipole toward the left well (“the donor”; see bottom panel). The quali￾tative dependence of the two lowest energy levels on the dipole orientation is illustrated
in Fig. 18.2.3.
Let us consider two limiting cases. When the energy splitting is large in comparison
to the dipole-induced stabilization energy (VD,A > Ea as in Fig. 18.2.3 (a)), the elec￾tronic ground state is well separated in energy from the excited state for all the relevant
dipole orientations. This implies that changes in the dipole orientation cannot provide
sufficient energy for electronic excitation from the ground to the excited state; hence
charge transfer between the potential wells is restricted to the ground electronic state,
namely, it is “adiabatic” (limited to a single PES in the framework of the BO approxi￾mation). In the other limit, the tunneling splitting is small (VD,A  Ea as in Fig. 18.2.3
(b)), such that changes in the dipole orientation can transfer sufficient energy to elec￾tronic excitation. Hence charge transfer is nonadiabatic in this case and involves both
the ground and the excited electronic states.
Our focus in what follows is on nonadiabatic charge transfer. This limit is consistent
with a typical situation in which the donor and acceptor centers are spatially remote
from each other, and the tunneling matrix element, VD,A, falls exponentially with the
donor–acceptor distance (see the discussion of the long-range single-electron exchange
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press354 Thermal Rates in a Bosonic Environment
Ftigure 18.2.2 Changes to the effective “double well potential” for an electron in the presence of two fixed centers of positive charges,
and a rotating electric dipole. In each plot the potential energy is plotted (solid line) as a function of the electronic
coordinate,re, for a different dipole orientation. The dotted lines refer to a reference orientation in which the dipole is
perpendicular to the line connecting the two fixed charge centers(q = 0). The top and bottom panels correspond,
respectively, to rotation of the dipole to the right(q > 0)and to the left(q < 0).
integral in Section 14.3). It is instructive in these cases to analyze the charge transfer
process in terms of localized “donor” and “acceptor” electronic eigenstates associated
with the eigenstates of the two separated potential energy wells (often referred to as
“diabatic states”). For most dipole orientations, these two localized states approximate
well the ground and excited states of the double well potential (see, e.g., the asymmetric
double well potentials in Fig. 18.2.2). However, near the “crossing point” (the sym￾metric configuration (q = 0) in Figs. 18.2.2 and 18.2.3), where the energydifference
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press355 18.2 Charge Transfer in a Polarizable Medium
Energy
(a) (b)
Adiabatic
qD qA
Ea
ε1(q )
εD (q )
ε0(q )
ε0(q ) ≈ ε εA(q ) 0(q ) ≈
ε εA(q ) 1(q ) ≈ ε εD(q ) 1(q ) ≈
q qD qA q
VDA
Energy
Non-adiabatic
Ftigure 18.2.3 The two lowest energy levels of the effective electronic double well potential (see Fig.18.2.2) as functions of the
orientation of a nearby dipole (denoted by a coordinate q). The (a)/(b) plot corresponds to the adiabatic/nonadiabatic
limit, at which the electronic coupling between the two potential wells is much larger/smaller than changes in the
potential energy attributed to changes in the surrounding medium.
between the eigenstates of the separated donor and acceptor potential energy wells
becomes smaller than the tunneling splitting VD,A associated with the corresponding
double well potential, the exact electronic eigenstates are delocalized over the two wells
and can be approximated in terms of effective linear combinations of the two localized
states.
The Model Hamiltonian
A convenient framework for analyzing the charge transfer in the nonadiabatic limit
is to use two localized electronic donor and acceptor states as a basis in which the
full Hamiltonian can be represented. Denoting the electronic coordinates (of the
many-electron donor–acceptor system) by r = r1, r2,..., and the coordinates of the
environment (assuming the existence of multiple dipoles in the microscopic environ￾ment) by q ≡ q1,q2,..., the two basis states are the localized electronic states in the
donor and acceptor potential wells, ψD(r,q) and ψA(r,q). The full system Hamil￾tonian can be decomposed as Hˆ = Hˆ
e + Tˆ
q, where Hˆ
e is the electronic Hamiltonian
(see Section 14.2), which depends parametrically on the coordinates of the polariza￾ble medium, q, and Tˆ
q is the respective kinetic energy. The matrix representation of
the electronic Hamiltonian in the basis of localized electronic states is additionally
assumed to be of a tight binding form (see Section 14.4), which means that the elec￾tronic Hamiltonian couples between ψD(r,q) and ψA(r,q), while their overlap integral
vanishes. Again, this assumption is consistent with the nonadiabatic limit VD,A  Ea
(see Fig. 18.2.3), where the two donor and acceptor centers are spatially remote from
each other. The matrix elements of Hˆ
e are therefore denoted as
w
drψ
∗
D(r,q)Hˆ
eψD(r,q) = εD(q) ;
w
drψ
∗
A
(r,q)Hˆ
eψA(r,q) = εA(q) (18.2.2)
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press356 Thermal Rates in a Bosonic Environment
w
drψ
∗
D(r,q)Hˆ
eψA(r,q) = w
drψ
∗
A
(r,q)Hˆ
eψD(r,q) = VDA(q), (18.2.3)
where
w
drψ
∗
D(r,q)ψA(r,q) = 0. (18.2.4)
An additional simplifying assumption is that the dependence of the localized elec￾tronic basis states, ψD(r,q) and ψA(r,q), on the dipole orientations can be disregarded,
which is referred to as “the Condon approximation” [18.2]. Notice that the exact elec￾tronic eigenfunctions of the separated donor and acceptor Hamiltonians do depend
on the dipole orientation. However, for sufficiently “deep” and “narrow” wells (that
is, when the range of the potential well is much smaller than the inter-well separation),
local perturbations to the potential wells may induce significant changes to the local
energies (changes in the diagonal matrix elements of the electronic Hamiltonian, εD(q)
and εA(q)), but only negligible changes to the inter-well coupling, which depends on
the remote “tails” of the electronic eigenfunctions. Consequently, the dependence of
the inter-well coupling matrix element, VD,A(q), on q may be neglected:
VD,A(q) ≈ VD,A. (18.2.5)
Moreover, neglecting the dependence of the basis states on q and using Eq. (18.2.4),
the representation of the dipoles’ kinetic energy simplifies to
w
drψ
∗
D(r,q)Tˆ
qψD(r,q) ≈ Tˆ
q ;
w
drψ
∗
A
(r,q)Tˆ
qψA(r,q) ≈ Tˆ
q (18.2.6)
and
w
drψ
∗
D(r,q))Tˆ
qψA(r,q) = w
drψ
∗
A
(r,q)Tˆ
qψD(r,q) ≈ 0. (18.2.7)
It is convenient to introduce Dirac’s notations for the q-independent localized
electronic basis states,
ψD(r) ≡ hr|Di ; ψA(r) ≡ hr|Ai. (18.2.8)
Using Eqs. (18.2.2–18.2.8)), the matrix elements of the model Hamiltonian in the
electronic basis read
HˆD,q = hD|[Tˆ
q +Hˆ
e(q)]|Di = Tˆ
q +εD(q)
Hˆ
A,q = hA|[Tˆ
q +Hˆ
e(q)]|Ai = Tˆ
q +εA(q)
HˆD,A = Hˆ
A,D = hA|[Tˆ
q +Hˆ
e(q)]|Di = VDA ˆIq. (18.2.9)
Notice that each electronic matrix element is an operator in the multidimensional
dipole coordinates space. In matrix form, the model Hamiltonian reads
Hˆ =

HˆD,q VD,A
ˆIq
VD,A
ˆIq Hˆ
A,q

. (18.2.10)
We now turn to formulating a concrete microscopic model for the polarizable
medium. Considering a collection of independent dipole modes, q = q1,q2,q3,...,
the preferred orientation of each dipole changes as the electronic state changes (see
Fig. 18.2.1). For small-amplitude motion around the preferred orientations at each of
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press357 18.2 Charge Transfer in a Polarizable Medium
the two localized electronic states, the corresponding potential energy as a function of
q can be described within a harmonic approximation (Eq. (8.2.4)). Attributing effec￾tive mass and frequency to each dipole mode coordinate, the multidimensional donor
and acceptor Hamiltonians (Eq. (18.2.9)) obtain an explicit form,
HˆD,q = ε
0
D +∑
j
pˆ
2
j
2mj
+
1
2
mjω
2
j
(qˆj −qj,D)
2
Hˆ
A,q = ε
0
A +∑
j
pˆ
2
j
2mj
+
1
2
mjω
2
j
(qˆj −qj,A)
2
, (18.2.11)
where {qj,D} and {qj,A} are the dipoles’ orientations corresponding to the potential
energy minima, ε
0
D
and ε
0
A
, at the donor and acceptor states, respectively. It is con￾venient to set the origin for each dipole coordinate to the average of the donor and
acceptor minimal energy configurations, namely (qj,D +qj,A)/2, and to transform into
dimensionless position and momentum variables,
Qˆ
j ≡
r
mjωj
h¯

qˆj −
qj,D +qj,A
2

; Pˆ
j ≡
s
1
mjh¯ωj
pˆj
. (18.2.12)
The energy gap between the donor and acceptor potential energy minima is often
referred to as the “driving force” for charge transfer, which is marked as
ε
0
D −ε
0
A ≡ 2∆E. (18.2.13)
Using Eqs. (18.2.12, 18.2.13), the donor and acceptor Hamiltonians in Eq. (18.2.11)
can be replaced by
HˆD,Q = ∑
j
h¯ωj
2
Pˆ
2
j +ED(Qˆ ) ; ED(Qˆ ) = ∆E +∑
j
h¯ωj
2
Qˆ
2
j +h¯ωj∆jQˆ
j
Hˆ
A,Q = ∑
j
h¯ωj
2
Pˆ
2
j +EA(Qˆ ) ; EA(Qˆ ) = −∆E +∑
j
h¯ωj
2
Qˆ
2
j −h¯ωj∆jQˆ
j
, (18.2.14)
where HˆD,Q and Hˆ
A,Q are identical to HˆD,q and Hˆ
A,q up to an addition of a common
constant (see Ex. (18.2.1)). The distance between the optimal dipole orientations at
the donor and acceptor electronic states is a dimensionless measure for the coupling
strength of each mode to the electronic degrees of freedom:
∆j ≡
r
mjωj
h¯

qj,A −qj,D
2

=
Qj,A −Qj,D
2
. (18.2.15)
As one can readily see, the model for an “extra charge” in a donor–acceptor system
coupled to a polarizable medium (Eqs. (18.2.10, 18.2.14)) is mapped on a spin-boson
model Hamiltonian (Eqs. (18.1.1, 18.1.2)). Notice that this model is introduced under
a set of approximations that overlook some of the complexities present in any realistic
system. Specifically, the spin-boson model relies on the projection of the many-electron
system onto only two electronic basis states, on the Condon approximation, and on
the harmonic approximation, where the same set of modes at the same frequencies is
assumed for the two electronic states. These simplifying assumptions clearly do not
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press358 Thermal Rates in a Bosonic Environment
allow for quantitative predictions. Nevertheless, as demonstrated in what follows, the
simple microscopic model reproduces the most important characteristics of charge
transfer kinetics, and particularly the Marcus rate expression [18.2].
Exercise 18.2.1 (a) Use Eqs. (18.2.12, 18.2.13, 18.2.15) to rewrite Eq. (18.2.11) as
HˆD,q = ∆E +
ε
0
D +ε
0
A
2
+∑
j
h¯ωj
2
∆
2
j +∑
j

h¯ωj
2
Pˆ
2
j +
h¯ωj
2
Qˆ
2
j +h¯ωj∆jQˆ
j

Hˆ
A,q = −∆E +
ε
0
D +ε
0
A
2
+∑
j
h¯ωj
2
∆
2
j +∑
j

h¯ωj
2
Pˆ
2
j +
h¯ωj
2
Qˆ
2
j −h¯ωj∆jQˆ
j

.
(b) Show that Eq. (18.2.14) is obtained by setting the zero of energy to ε
0
D+ε
0
A
2 +
∑
j
h¯ωj
2
∆
2
j
.
The spin-boson model Hamiltonian for the donor–acceptor system (Eq.18.2.10) can
be conveniently decomposed into a zero-order Hamiltonian and an interaction,
Hˆ = Hˆ
0 +Vˆ
Hˆ
0 = HˆD,Q|DihD|+Hˆ
A,Q|AihA| ; Vˆ = VD,A(|DihA|+|AihD|). (18.2.16)
Each eigenstate of the zero-order Hamiltonian is a product state in the space of the
electronic and the medium degrees of freedom (Ex. 18.2.2),
Hˆ
0|Di ⊗ |χD,ni = εD,n|Di ⊗ |χD,ni
Hˆ
0|Ai ⊗ |χA,mi = εA,m|Ai ⊗ |χA,mi, (18.2.17)
where, |Di or |Ai denote the electronic state, and |χD,ni and |χA,mi are eigenstates of
the donor and acceptor Q-space Hamiltonians,
HˆD,Q|χD,ni = εD,n|χD,ni ; Hˆ
A,Q|χA,mi = εA,m|χA,mi. (18.2.18)
The vectors of quantum numbers, n = (n1,n2,n3,...) and m = (m1,m2,m3,...), corre￾spond to multidimensional products of single harmonic oscillator eigenfunctions,
hQ|χD,ni = φn1
(Q1 +∆1)·φn2
(Q2 +∆2)·φn3
(Q3 +∆3)...
hQ|χA,mi = φm1
(Q1 −∆1)·φm2
(Q2 −∆2)·φm3
(Q3 −∆3)...
, (18.2.19)
where φn(Q) is an eigenfunction of the one-dimensional harmonic oscillator Hamilto￾nian (Eqs. (8.3.7, 8.3.8)),
h¯ω
2
(Pˆ
2 +Qˆ
2
)φn(Q) = h¯ω

n+
1
2

φn(Q) ; n = 0,1,2.... (18.2.20)
The eigenvalues of the zero-order Hamiltonian therefore read (Ex. 18.2.2)
εD,n = ∆E −∑
j
h¯ωj
2
∆
2
j +∑
j
h¯ωj(nj +
1
2
)
εA,m = −∆E −∑
j
h¯ωj
2
∆
2
j +∑
j
h¯ωj(mj +
1
2
). (18.2.21)
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press359 18.2 Charge Transfer in a Polarizable Medium
Exercise 18.2.2 For the zero-order Hamiltonian, Hˆ
0, as defined in Eqs. (18.2.14,
18.2.16), show that the eigenvectors and eigenvalues are given by Eqs. (18.2.17–18.2.21).
Thermal Charge Transfer Rates
We are interested in the thermal rate of charge transfer between the “donor” and the
“acceptor” states in a system characterized by the full Hamiltonian, Eq. (18.2.16).
Without loss of generality, we shall associate the initial state with the donor, and
the final state with the acceptor, where the same considerations apply to the reverse
process. More specifically, the initial and final states are identified with Hˆ
0-eigenstates
projected onto the donor and acceptor subspaces, respectively. The corresponding
projection operators read (see Eq. (17.3.1))
PˆD = |DihD| ; Pˆ
A = |AihA|, (18.2.22)
where Pˆ2
D = PˆD, PˆDPˆ
A = 0, Pˆ2
A = Pˆ
A, and [PˆD,Hˆ
0] = [Pˆ
A, Hˆ
0] = 0 (see Eqs. (17.3.2, 17.3.3)).
The definition of a thermal rate assumes an initial “quasi-equilibrium” donor state in
which the relative weights of the different Hˆ
0-eigenstates attributed to the donor cor￾respond to a canonical statistical ensemble. Consequently, the occupation probability
of any initial donor eigenstate is given by a Boltzmann distribution (Eq. (17.3.6)):
PD,n(0) = e
−εD,n/(kBT)
ZD
; ZD = ∑n
e
−εD,n/(kBT)
. (18.2.23)
Alternatively, the initial density operator obtains the form (see Eq. (17.3.10))
ρˆD(0) = e
−Hˆ
0/(kBT)PˆD
tr{e
−Hˆ
0,(kBT)PˆD}
. (18.2.24)
In the absence of interaction between the donor and acceptor manifolds of Hˆ
0-
eigenstates, this initial state would be stationary. The interaction couples, in principle,
any donor state to the entire manifold of acceptor states, resulting in charge transfer
from the donor to the acceptor. Provided that the state-to-state coupling is sufficiently
small (see what follows), the overall transfer rate from the donor to the acceptor can be
calculated by first-order perturbation theory. Using the general expression for the rate
in terms of the interaction correlation function (Eqs. (17.3.12, 17.3.13)), we obtain in
this case
k
(1)
D→A
(t) ∼=
2
h¯
2 Re
wt
0
tr{ρˆD(0)PˆDVˆ Pˆ
Ae
iHˆ
0 τ
h¯ Vˆ e
−iHˆ
0τ
h¯ }dτ. (18.2.25)
Introducing explicitly the zero-order Hamiltonian and the interaction (Eq. (18.2.16)),
and taking the (partial) trace over the electronic degrees of freedom, a compact
expression is obtained in terms of the medium correlation function (Ex. 18.2.3):
k
(1)
D→A
(t) = 2Rewt
0
cD,Q(τ)dτ ; cD,Q(τ) = |VD,A|
2
h¯
2
trQ
(
e
−HˆD,Q/(kBT)
ZD
e
−iHˆ
D,Qτ
h¯ e
iHˆ
A,Qτ
h¯
)
.
(18.2.26)
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press360 Thermal Rates in a Bosonic Environment
Evaluating the trace using a complete orthonormal system of multidimensional har￾monic oscillator eigenfunctions, we obtain (Ex. 18.2.4)
k
(1)
D→A
(t) = 2
h¯
2 ∑n,m
e
−εD,n/(kBT)
ZD
Re
wt
0
e
−i(εD,n−εA,m)τ
h¯ |VD,AhχD,n|χA,mi|2
dτ. (18.2.27)
As discussed for the general case (Eqs. (17.2.3, 17.2.4)), this perturbative expression is
valid only for times much shorter than the resonant state-to-state transition time,
t  h¯/max(|VD,AhχD,n|χA,mi|). (18.2.28)
Here hχD,n|χA,mi are multidimensional overlap integrals over the medium degrees of
freedom (the “Franck–Condon (FC) factors”). Importantly, this condition is satisfied
in typical cases of charge transfer within a polar medium over nanoscale distances,
owing to the exponential decay of the electronic tunneling matrix element, VD,A, with
the donor–acceptor distance, and the fact that the products of FC factors are smaller
than (or equal to) unity.
Exercise 18.2.3 (a) Use the explicit expressions for the zero-order Hamiltonian
(Eq. (18.2.16)) to show that f(Hˆ
0)|Di = f(HˆD,Q)|Di and f(H0)|Ai = f(HA,Q)|Ai, where
f is an analytic function of its argument. (b) Use the results of (a), the interaction opera￾tor (Eq. (18.2.16)), and the definitions of the initial and final ensembles (Eqs. (18.2.22,
18.2.24)) to derive Eq. (18.2.26) from Eq. (18.2.25). Notice that the trace over the full
electronic and nuclear space can be expressed as tr{Oˆ} = trQ{hD|Oˆ|Di+hA|Oˆ|Ai}.
Exercise 18.2.4 Derive Eq. (18.2.27) from Eq. (18.2.26) by evaluating the trace
over the nuclear space using a complete set of eigenstates of the multidimensional
Hamiltonian, HˆD,Q, and an identity operator, expressed in terms of Hˆ
A,Q-eigenstates
(Eq. (18.2.18)).
An explicit expression for the rate in terms of the microscopic model Hamiltonian
can be derived directly from Eq. (18.2.26) by using the separability of the donor and
acceptor Hamiltonians in the harmonic mode coordinates (see Eq. (18.2.14)). First,
we make use of the fact that the multi-dimensional trace in the medium correlation
function can be conveniently replaced by a product of traces over single-mode spaces
(see Ex. 18.2.5), namely
k
(1)
D→A
(t) = 2|VD,A|
2
h¯
2 Re
wt
0
e
−iτ
h¯
2∆E ∏
j
CD, j(τ)dτ ;
CD, j(τ) ≡ trQj
(
e
−1
kBT
hˆD, j
ZD, j
e
−iτ
h¯
hˆD, j e
iτ
h¯
hˆ
A, j
)
. (18.2.29)
Here we defined the single-mode Hamiltonians at the donor and acceptor spaces,
hˆD, j =
h¯ωj
2
(Pˆ
2
j +(Qˆ
j +∆j)
2
) ; hˆ
A, j =
h¯ωj
2
(Pˆ
2
j +(Qˆ
j −∆j)
2
), (18.2.30)
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press361 18.2 Charge Transfer in a Polarizable Medium
where ZD, j = trQj
{e
−hˆD, j/(kBT)} is the partition function for the jth mode in the initial
donor space. Using some algebra, the single-mode traces can be evaluated analytically
(Ex. 18.2.6),
cD, j(τ) = e
2i∆
2
j
sin(ωjτ)
e
−2∆
2
j
(1−cos(ωjτ))(1+2n(ωj))
, (18.2.31)
where n(ωj) is the thermal occupation number of the jth mode (Ex. 18.2.7),
n(ωj) = 1
e
h¯ωj/(kBT) −1
. (18.2.32)
Substitution in Eq. (18.2.29) yields the following explicit expression for the transfer
rate,
k
(1)
D→A
(t) = 2|VD,A|
2
h¯
2 Re
wt
0
e
−iτ
h¯
2∆E e
2i∑
j
∆
2
j
sin(ωjτ)
e
−2∑
j
∆
2
j
(1−cos(ωjτ))(1+2n(ωj))
dτ. (18.2.33)
Exercise 18.2.5 (a) The donor partition function is defined as ZD = ∑
n
e
−εD,n/(kBT)
.
Use the definition of HˆD,Q (Eq. (18.2.14)) to show that ZD = e
−∆E /(kBT)
e
∑
j
h¯ω j
2
∆
2
j
/(kBT)
ZD,1ZD,2ZD,3 ..., where the jth mode partition function reads ZD, j ≡ ∑
nj
e
−h¯ω j
kBT
(nj+
1
2
) =
e
−h¯ω j
2kBT
1−e
−h¯ω j
kBT
. (b) Show that e
−iHˆ
D,Qτ
h¯ = e
−iτ
h¯
∆E e
iτ
h¯ ∑
j
h¯ωj
2
∆
2
j
∏
j
e
−iτ
h¯
h¯ω j
2
(Pˆ2
j +(Qˆ
j+∆j)
2
)
; e
iHˆ
A,Qτ
h¯ =
e
−iτ
h¯
∆E e
−iτ
h¯ ∑
j
h¯ωj
2
∆
2
j
∏
j
e
iτ
h¯
h¯ωj
2
(Pˆ2
j +(Qˆ
j−∆j)
2
)
. (c) Use the results of (a) and (b), and the defini￾tions in Eq. (18.2.30) to derive Eq. (18.2.29) from Eq. (18.2.26). Recall that the trace
of a tensor product of operators in a multidimensional space, Aˆ
1 ⊗ Aˆ
2 ⊗ ··· ⊗ Aˆ
N, is a
product, tr{Aˆ
1 ⊗Aˆ
2 ⊗··· ⊗Aˆ
N} = tr{Aˆ
1}·tr{Aˆ
2}···tr{Aˆ
N} (Ex. 15.5.1).
Exercise 18.2.6 To prove the identity in Eq. (18.2.31), you can follow these steps: (a)
Let f(x) be an analytic function of x. Prove the identity: e
−λ
∂
∂ x f(x)e
λ
∂
∂ x = f(x − λ).
(b) Use the result of (a) to show that the single-mode Hamiltonians at the donor and
acceptor states, as defined by Eq. (18.2.30), are transformations of a reference Ham￾iltonian, hˆ
j =
h¯ωj
2
(Pˆ2
j + Qˆ 2
j
), that is, hˆD, j = e
i∆jPˆ
jhˆ
je
−i∆jPˆ
j
, and hˆ
A, j = e
−i∆jPˆ
jhˆ
je
i∆jPˆ
j
.
(c) Let f(x) be an analytic function of x. Show that f(hˆD, j) = e
i∆jPˆ
j
f(hˆ
j)e
−i∆jPˆ
j and
f(hˆ
A, j) = e
−i4jPˆ
j
f(hˆ
j)e
i∆jPˆ
j
. (d) Expressing the dimensionless momentum operator in
terms of Dirac’s ladder operator, Pˆ
j = √−i
2
(bˆ
j − bˆ
†
j
), and defining, bˆ
j(τ) = e
iτ
h¯
hˆ
jbˆ
je
−iτ
h¯
hˆ
j
,
show that bˆ
j(τ) = e
−iτωjbˆ
j
. (e) Use the results of (c) and (d) to show that cD,j(τ) =
trQj
(
e
−1
kBT
hˆ
D, j
ZD, j
e
−iτ
h¯
hˆD, j e
iτ
h¯
hˆ
A, j
)
= trQj
(
e
−1
kBT
hˆ
D, j
ZD, j
e
−
√
2∆j
[bˆ
j−bˆ
†
j
]
e
−
√
2∆j
[e
−iτω j bˆ
j−bˆ
†
j
e
iτω j
]
)
. (f)
The Baker–Campbell–Hausdorff formula for two operators, Aˆ and Bˆ, that commute with
their commutator ([Aˆ,[Aˆ,Bˆ]] = [Bˆ,[Aˆ,Bˆ]] = 0) reads e
Aˆ+Bˆ = e
Aˆ
e
Bˆ
e
−[Aˆ,Bˆ]/2
. Use it and the
commutator, [bˆ,bˆ†
] = 1, to show that cD, j(τ) = e
−2∆
2
j
(1−e
iτω j)
trQj
(
e
−1
kBT
hˆ
j
ZD, j
e
√
2∆jb
†
j
(1−e
iτω j )
×e
−
√
2∆jbˆ
j(1−e
−iτω j )
)
(g) To evaluate the trace over the single-mode space, use a complete
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press362 Thermal Rates in a Bosonic Environment
set of hˆ
j-eigenstates, hˆ
j
|φmi = h¯ωj(m + 1/2)|φmi. Recalling that bˆ
j
|φmi =
√
m|φm−1i,
show that cD, j(τ) = e
−2∆
2
j
(1−e
iτω j
)
ZD, j
∑
m=0
e
−h¯ω j
kBT
(m+1/2)
m
∑
n=0
[−2∆
2
j
|(1−e
iτωj)|
2
]
n m!
(n!)
2(m−n)!
. (h)
The Laguerre polynomials of order m are defined as Lm(x) =
m
∑
k=0

m
k

(−1)
k
k!
x
k
, and
their generating function reads
∞
∑
m=0
t
mLm(x) = 1
1−t
e
−tx/(1−t)
. Use it to show that cD, j(τ) =
e
2i∆
2
j
sin(ωjτ)
e
−2∆
2
j
(1−cos(ωjτ))(1+2n(ωj)), where n(ωj) = 1
e
h¯ω j
/(kBT)−1
.
Exercise 18.2.7 The averaged occupation number of a harmonic mode at a fre￾quency, ωj
, and a temperature, T, is defined as n(ωj) = 1
Z
∞
∑
n=0
ne−h¯ωjn/(kBT)
, where Z =
∞
∑
n
0=0
e
−hωjn
0/(kBT)
. Show that n(ωj) = e
−hω j
/(kBT)
1−e
−hω j
/(kBT)
.
The “Golden Rule
“
Rate
Let us return to the expression for the transition rate as a time-dependent integral, Eq.
(18.2.27), in which the time integrand is a sum over multiple oscillatory terms at fre￾quencies corresponding to the energy differences between Hˆ
0-eigenstates in the donor
and acceptor manifolds. As discussed in the general case (Eq. (17.2.3)), de-phasing of
the oscillating terms may lead to their mutual cancelations after some characteristic
time, and to a decay of the integrand to zero. When the decay time is within the valid￾ity window of perturbation theory (Eq. (17.2.9)) and much shorter than the “charge
transfer time” (Eq. (17.2.8)), and when each initial state is embedded in a dense mani￾fold of final states (where revivals of the initial state are suppressed), the rate converges
to a constant value after the fast decay of the integrand. These conditions are typ￾ically met when the (nonvanishing) state-to-state coupling matrix elements are much
smaller than the bandwidth of the corresponding energy differences, {εD,n −εA,m}, and
when the frequency spectrum of the multidimensional surroundings medium includes
the limit ωj → 0, such that the energy spectrum of the initial and final states can be
approximated as continuous. Given a rapid decay of the integrand, the upper time limit
in Eq. (18.2.27) can be replaced by infinity, leading to Fermi’s golden rule expression
for the charge transfer “rate constant” (Ex. 18.2.8),
kD→A
∼=
2π
h¯ ∑n,m
e
−εD,n/(kBT)
ZD
|VD,A|
2
|hχD,n|χA,mi|2
δ(εD,n −εA,m). (18.2.34)
Within these conditions, the charge transfer rate is a weighted average over the ther￾mal distribution of initial (donor) states and a sum over all final (acceptor) states. The
dominant contributions to the rate are due to donor and acceptor states with matching
energy (as imposed by Dirac’s delta) and with nonvanishing FC factors. Notice that
the amplitude of harmonic oscillator eigenfunctions at a given energy usually increases
near the corresponding classical turning points (see Section 8.3). Consequently, the
overlap integrals between the eigenfunctions of the donor and acceptor Hamiltonians
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press363 18.2 Charge Transfer in a Polarizable Medium
are maximized when the classical turning points of the two potential energy surfaces
coincide, namely, when the surfaces cross each other, ED(Q) ≈ EA(Q) (see Fig. 18.2.4).
The crossing surface is multidimensional and covers a wide energy range. Nevertheless,
the thermal weights limit the number of initial states whose energy reaches the cross￾ing surface. Hence, the charge transfer is a thermally activated process. The “activation
energy” can be identified by further analysis, outlined in what follows.
Exercise 18.2.8 Derive Eq. (18.2.34) by taking the upper limit of the time integral in
Eq. (18.2.27) to infinity and using a suitable definition of Dirac’s delta. Use the fact that
the real part of the integrand is an even function of time.
The Semiclassical Limit and Marcus Formula
In a typical scenario often met in charge transfer processes on the nanoscale, the polar￾izable medium is characterized by low-frequency modes. When their corresponding
vibration quanta are much smaller than the thermal energy, a full account of the energy
quantization of the surrounding modes is no longer critical, and semiclassical approxi￾mations can be justified. Here we shall refer to the high-temperature and low-frequency
limits by deriving approximation for the general quantum mechanical charge transfer
Ftigure 18.2.4 The role of Franck–Condon factors in controlling the charge transfer rate is illustrated for a single active environment
mode. The two parabolic potential energy curves (solid lines) correspond to the donor and acceptor electronic states
(ED(Qj)and EA(Qj); see Fig.18.2.3). The nuclear probability densities (dotted lines), corresponding to the
vibrational eigenfunctions, plotted at the respective energy levels, illustrate that the FC overlap between different
states at the same energy is maximized at the vicinity of the crossing point between the two curves.
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press364 Thermal Rates in a Bosonic Environment
rate, Eq. (18.2.33). As we shall see, the result coincides with the celebrated semiclassical
expression derived by Marcus [18.3].
First, let us consider the high-temperature limit, which implies that the thermal
energy is much larger than the vibrational quantum for any mode of the polarizable
medium, namely,
kBT  h¯ωj for any j. (18.2.35)
Within this limit, the thermal occupation number of the jth mode can be approximated
as (see Eq. (18.2.32))
n(ωj) ≈
kBT
hωj
 1. (18.2.36)
Second, and in line with the high-temperature limit, we restrict ourselves to low fre￾quencies of the surrounding modes in the sense that their corresponding time periods
are much larger than the decay time of the integrand in Eq. (18.2.33),
td 
2π
ωj
for any j. (18.2.37)
Let us recall that the decay of the time integrand requires the fulfilment of several
conditions (weak state-to-state coupling to a dense and wide band of final states), in
which Fermi’s golden rule (Eq. (18.2.34)) is valid. When this holds, the trigonometric
functions in Eq. (18.2.33) can be approximated by their lowest-order expansion in ωjτ,
sin(ωjτ) ≈ ωjτ ; cos(ωjτ) ≈ 1−ω
2
j
τ
2
/2. (18.2.38)
Substituting Eqs. (18.2.36, 18.2.38) in Eq. (18.2.33) yields (Ex. 18.2.9)
k
(1)
D→A
(t) = 2|VD,A|
2
h¯
2 Re
wt
0
e
−iτ
h¯
(2∆E−Eλ
)
e
−Eλ
kBTτ
2
h¯
2 dτ. (18.2.39)
Here the medium “reorganization energy” was introduced,
Eλ ≡ ∑
j
2∆
2
jωjh¯ = ∑
j
h¯ωj
2
(2∆j)
2
, (18.2.40)
as a global measure for the coupling between the electronic and the medium degrees
of freedom (a measure for the polarizability of the surrounding medium). As we can
see, the reorganization energy corresponds to the potential energy gained by changing
the dipole orientations from their minimal energy orientation on a given (donor or
acceptor) potential energy surface, to the orientation that would correspond to the
minimal energy on the other (acceptor or donor) surface, namely (see Ex. 18.2.10 and
Fig. 18.2.5)
Eλ = ED(Q = ∆)−ED(Q = −∆) = EA(Q = −∆)−EA(Q = ∆). (18.2.41)
The time integrand in Eq. (18.2.39) is shown to be an oscillatory function,
e
−iτ
h¯
(2∆E−Eλ
)
, multiplied by a Gaussian envelope, e
−Eλ
kBTτ
2
h¯
2
, where the decay time can
be identified as its standard deviation,
td ≡
h¯ √
2Eλ kBT
. (18.2.42)
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press365 18.2 Charge Transfer in a Polarizable Medium
ED(Qj
)
EA(Qj
)
Eλ
Eλ
−∆j ∆j Qj
E
Ftigure 18.2.5 The reorganization energy, Eλ ≡ 2∆
2
jωjh¯, attributed to a single environment mode. The two potential energy
curves (solid lines) correspond to the donor and acceptor electronic states(ED(Qj)and EA(Qj); see Fig.18.2.3).
Given that the time integral converges for t  td, the upper time-limit can be taken to
infinity, which yields a compact expression for the thermal charge transfer rate constant
(Ex. 18.2.11),
kD→A = |VD,A|
2
r π
h¯
2
kBTEλ
e
−(Eλ
−2∆E )
2
4kBTEλ . (18.2.43)
The regime of validity of the semiclassical approximation to Fermi’s golden rule rate
can be readily identified using Eqs. (18.2.37, 18.2.42), which yield
(h¯ωj)
2
kBTEλ
 8π
2
for any j. (18.2.44)
This means that the approximation holds when the vibration quanta of the surrounding
medium are small in comparison to both the thermal and the reorganization energies.
Additionally, using Eq. (18.2.42) and the validity condition for first-order perturbation
theory (Eq. (18.2.28)), similar restrictions are obtained with respect to the electronic
coupling matrix element (Ex. 18.2.12),
|VD,A|
2
2kBTEλ
 1. (18.2.45)
Exercise 18.2.9 Use Eqs. (18.2.36, 18.2.38) in Eq. (18.2.33) to express the rate,
Eq. (18.2.39), in terms of the reorganization energy, defined in Eq. (18.2.40).
Exercise 18.2.10 Show that Eq. (18.2.41) reproduces the reorganization energy as
defined in Eq. (18.2.40), where ED(Qˆ ) and EA(Qˆ ) are the donor and acceptor potential
energy surfaces, defined in Eq. (18.2.14).
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press366 Thermal Rates in a Bosonic Environment
ED(Qj
)
EA(Qj
)
2∆E < Eλ
2∆E = Eλ
2∆E > Eλ
−∆j ∆j Qj
E
Ftigure 18.2.6 Illustration of the non-monotonic effect of the driving forces on the charge transfer rate. The solid line corresponds to a
representative harmonic potential at the donor electronic state, where the three dotted lines represent different
possibilities for the corresponding potential at the acceptor state, associated with different “driving forces,” 2∆E.
When 2∆E < Eλ
, the energy at the crossing between the donor (solid) and the acceptor (dotted) potential energy
surfaces is greater than the minimum energy at the donor state, and the charge transfer is thermally activated. When
2∆E = Eλ
, the crossing identifies with the minimum at the donor potential energy, and the process is
activation-less. When 2∆E > Eλ
, the crossing is again higher in energy, and the charge transfer is again thermally
activated (the inverted region).
Exercise 18.2.11 Change the time limit in Eq. (18.2.39) to infinity (notice that the real
part of the integrand is an even function of time) to obtain the result in Eq. (18.2.43).
Use the identity, r∞
−∞
dke−zk2
e
ikx =
qπ
z
e
−x
2
4z .
Exercise 18.2.12 (a) Show that the maximal state-to-state coupling matrix element
between the donor and acceptor eigenstates is |VDA|, and use Eqs. (18.2.28, 18.2.42) to
obtain the validity condition, Eq. (18.2.45). (b) Show that this condition also assures
that td  1
kD→A
(the wide band limit, Eq. (17.2.8)).
Eq. (18.2.43) can be readily identified as the Marcus formula for the charge trans￾fer rate [18.3], which depends on the electronic tunneling matrix element, VD,A, the
temperature, T, the reorganization energy, Eλ
, and the driving force, 2∆E. The expo￾nential factor is characteristic of a thermally activated process, where k ∝ e
−Ea
kBT
. The
corresponding activation energy can be readily identified as Ea =
(Eλ−2∆E )
2
4Eλ
. The
maximal rate is obtained when the activation energy vanishes, that is, Eλ = 2∆E (the
activation-less regime). This means that the rate changes non-monotonically as a func￾tion of the driving force (for a given reorganization energy), and as a function of the
reorganization energy (for a given driving force), as illustrated in Fig. 18.2.6.
Notice that while the reorganization energy has a dramatic effect on the charge trans￾fer kinetics, it does not affect the ratio between the forward and backward transfer rates
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press367 18.3 Radiation Absorption and Emission
(Ex. 18.2.13), which is solely determined by the temperature and the “driving force”
for charge transfer (2∆E),
kA→D
kD→A
= e
−2∆E
kBT . (18.2.46)
Indeed, since the direct sum of the donor and acceptor spaces is the entire Hilbert
space, the ratio of the transition rates between them is uniquely related to their relative
populations at equilibrium (the detailed balance condition, Eq. (17.3.21)), kA→D
kD→A
=
P
(eq)
D
P
(eq)
A
.
At equilibrium this ratio merely reflects the ratio between the reduced donor and accep￾tor partition functions (Eq. (17.3.20)), which is independent of the reorganization
energy.
Exercise 18.2.13 According to Eq. (18.2.43), the thermal rates, kD→A and kA→D, differ
only by the sign of the driving force. Use this to derive their ratio, Eq. (18.2.46).
18.3 Radiation Absorption and Emission
The interaction of electromagnetic radiation with matter is fundamentally important
from both basic and applicative science points of view. This interaction enables us
to measure transitions between energy eigenstates of nanoscale materials (including
atoms, molecules, quantum dots, and bulk), unraveling both the energy quantization
and the underlying particle arrangement in the material (e.g., spatial and temporal
probability densities and interference between probability amplitudes). Absorption
and emission of electromagnetic radiation is an important mechanism of energy
transfer to and from molecular and nanoscale systems. A remarkable example is
photosynthesis, in which the energy absorbed from the sun light is channeled into a
nanoscale reaction center and finally transformed into “energy-rich” chemical bonds.
Applications engineered for energy storage and conversion (e.g. photovoltaic cells) or
electro-optical devices are based on similar ideas in which electromagnetic radiation
is converted into excitations (and thus triggers charge currents, chemical reactions,
reorganization processes), or vice versa.
In this section we consider the elementary process in which an electronic transi￾tion within a given material (a molecule, as a specific example) is coupled to external
electromagnetic radiation. Restricting ourselves to the weak coupling (linear response)
regime, we shall use perturbation theory to describe the rate of electronic excitation
(radiation absorption) or de-excitation (radiation emission), induced by coupling of
the system to the radiation field. We shall reveal the dependence of these rates on
the field parameters (intensity and frequency) as well as on the system parameters.
In Section 15.6 we studied the effect of a monochromatic driving on state-to-state
transitions within a generic system. Here this treatment is generalized to account or
the case in which an electronic transition within a chromophore (typically, an atom,
molecule, or a nanoparticle) is coupled to internal molecular vibrations as well as to
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press368 Thermal Rates in a Bosonic Environment
Ftigure 18.3.1 A schematic illustration of radiation-induced transitions. The groups of states correspond to the electronic ground and
excited states of the system, where specific states within each group correspond to different nuclear states (in the
system or in its surroundings) at a given electronic state.
a multidimensional environment at a finite temperature. In the presence of this cou￾pling, measurements of radiation absorption and emission involve transitions between
incoherent ensembles of states (see Fig. 18.3.1). As discussed in Chapter 17, this sce￾nario is associated with the emergence of “rate constants” for these processes on their
relevant timescale. As we shall see, these rates are smooth functions of the field fre￾quency, unlike the delta peaks, which characterize transitions between pure states (see
Eq. (15.6.28)).
The Model Hamiltonian
The zero-order Hamiltonian corresponds to the field-free system. Typically, the elec￾tronic transition involves the many-electron ground state and one of the excited elec￾tronic states. When these states are well separated in energy from all the other electronic
states for the relevant nuclear configurations, one may attempt to describe the many￾electron degrees of freedom in terms of a two-level model system. Moreover, when
the two states are well separated from each other, the adiabatic (Born–Oppenheimer)
approximation is justified (see Section 14.2). The system Hamiltonian can therefore be
decomposed as
Hˆ
0 = Hˆ
e(q) +Tˆ
q, (18.3.1)
where Hˆ
e(q) is the electronic Hamiltonian (see Section 14.2), which depends paramet￾rically on the nuclear coordinates, and Tˆ
q is the respective kinetic energy. Denoting the
electronic coordinates by r = r1, r2,... and the nuclear coordinates by q ≡ q1,q2,...,
the ground and excited states, denoted as ψgr(r,q) and ψex(r,q), are eigenstates of the
electronic Hamiltonian,
Hˆ
e(q)ψgr(r,q) = εgr(q)ψgr(r,q)
Hˆ
e(q)ψex(r,q) = εex(q)ψex(r,q). (18.3.2)
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press369 18.3 Radiation Absorption and Emission
These states are an orthonormal set, which spans the electronic space for any nuclear
configuration:
w
dr|ψgr(r,q)|
2 =
w
dr|ψex(r,q)|
2 = 1 ; w
drψ
∗
gr(r,q)ψex(r,q) = 0. (18.3.3)
Within the BO approximation, the q-dependence of the electronic functions (namely,
the derivative coupling) is assumed negligible, resulting in a diagonal representation of
the nuclear kinetic energy operator (see Eq. (14.2.17)):
w
drψ
∗
gr(r,q)Tˆ
qψgr(r,q) ≈ Tˆ
q ;
w
drψ
∗
ex(r,q)Tˆ
qψex(r,q) ≈ Tˆ
q, (18.3.4)
where
w
drψ
∗
gr(r,q)Tˆ
qψex(r,q) = w
drψ
∗
ex(r,q)Tˆ
qψgr(r,q) ≈ 0. (18.3.5)
Invoking Dirac’s notations for the q-independent electronic states,
ψgr(r) ≡ hr|gri ; ψex(r) ≡ hr|exi, (18.3.6)
the matrix representation of the field-free Hamiltonian obtains the form
Hˆ
0 = Hˆ
gr,q|grihgr|+Hˆ
ex,q|exihex|, (18.3.7)
where
hgr|[Tˆ
q +Hˆ
e(q)]|gri = Tˆ
q +εgr(q) = Hˆ
gr,q
hex|[Tˆ
q +Hˆ
e(q)]|exi = Tˆ
q +εex(q) = Hˆ
ex,q
hex|[Tˆ
q +Hˆ
e(q)]|gri = hgr|[Tˆ
q +Hˆ
e(q)]|exi = 0. (18.3.8)
For small-amplitude motion around the minimal energy configuration, the multidi￾mensional nuclear potential energy surfaces, εgr(q) and εex(q), can be approximated
as harmonic (Eq. (8.2.4)). Transforming to a set of independent coordinates (normal
modes; see Section 8.2), of masses, {mj}, and frequencies, {ωj}, an explicit model for
the multidimensional ground and excited state Hamiltonians (Eq. (18.3.7)) reads
Hˆ
gr,q = ε
0
gr +∑
j
pˆ
2
j
2mj
+
1
2
mjω
2
j
(qˆj −qj,gr)
2
Hˆ
ex,q = ε
0
ex +∑
j
pˆ
2
j
2mj
+
1
2
mjω
2
j
(qˆj −qj,ex)
2
. (18.3.9)
Here, {qj,gr} and {qj,ex} are the nuclear configurations corresponding to the poten￾tial energy minima values, ε
0
gr and ε
0
ex, at the ground and the excited electronic states,
respectively. (Notice that this simplified model assumes the same mode frequencies for
the two potential energy surfaces.) It is convenient to set the origin for each coordinate
to the average of the two minimal energy configurations, namely (qj,gr +qj,ex)/2, and
to transform to dimensionless position and momentum variables,
Qˆ
j ≡
r
mjωj
h¯

qˆj −
qj,gr +qj,ex
2

; Pˆ
j ≡
s
1
mjh¯ωj
pˆj
. (18.3.10)
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press370 Thermal Rates in a Bosonic Environment
The gap between the minima of the ground and excited potential energy surfaces is
often referred to as the “adiabatic excitation energy.” Here we denote it as
ε
0
gr −ε
0
ex ≡ 2∆E. (18.3.11)
(Notice that by definition, ε
0
gr < ε
0
ex, and therefore ∆E is chosen to be negative.) The
distance between the minimal energy configurations at the donor and acceptor elec￾tronic states is a dimensionless measure for the coupling strength of each mode to the
electronic degrees of freedom,
∆j ≡
r
mjωj
h¯

qj,ex −qj,gr
2

=
Qj,ex −Qj,gr
2
. (18.3.12)
Using Eqs. (18.3.9–18.3.12), the ground and excited state Hamiltonians obtain the
form (see Ex. 18.2.1 for an analogous derivation)
Hˆ
ex,Q = ∑
j
h¯ωj
2
Pˆ
2
j +Eex(Qˆ ) ; Eex(Qˆ ) = −∆E +∑
j
h¯ωj
2
Qˆ
2
j −h¯ωj∆jQˆ
j
Hˆ
gr,Q = ∑
j
h¯ωj
2
Pˆ
2
j +Egr(Qˆ ) ; Egr(Qˆ ) = ∆E +∑
j
h¯ωj
2
Qˆ
2
j +h¯ωj∆jQˆ
j
. (18.3.13)
Consequently, the field-free molecular Hamiltonian obtains the form of a generic spin￾boson model (see Eqs. (18.1.1–18.1.3)),
Hˆ
0 = Hˆ
gr,Q|grihgr|+Hˆ
ex,Q|exihex|. (18.3.14)
We now turn to modeling the interaction of the system with the radiation field.
A rigorous derivation based on quantum electrodynamics is beyond our scope here,
but in the high photon-density (semiclassical) limit and within the long wavelength
approximation (where the radiation wavelength is much larger than the spatial dimen￾sions of the nanoscale emitter/absorber system) the presence of the radiation amounts
to a time-dependent electric field, interacting with the system’s dipole. Without loss
of generality, we shall consider a monochromatic driving field, characterized by a
frequency, Ω,
E(t) = E0 sin(Ωt), (18.3.15)
where the interaction term reads
Vˆ(t) = −E(t)·dˆ. (18.3.16)
The dipole, dˆ, is a vector operator, defined as a sum over all the charged particles in
the system,
dˆ = ∑n
Rˆ
nZn|e| −∑
i
rˆi
|e| ≡ dˆ
q +dˆ
r, (18.3.17)
where Rn and Zn are the position vector and the proton number of the nth nucleus.
Defining the scalar operator,
µˆ = −E0 ·dˆ ≡ µˆq + µˆ r, (18.3.18)
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press371 18.3 Radiation Absorption and Emission
the matrix representation of the interaction operator in the basis of the ground and
excited electronic states reads
Vˆ(t) = sin(Ωt)[hgr|µˆ |gri|grihgr|+hgr|µˆ |exi|grihex|+hex|µˆ |gri|exihgr|
+hex|µˆ |exi|exihex|]. (18.3.19)
Recalling that the dependence of the electronic wave functions on the nuclear coordi￾nates is neglected within the framework of the Born–Oppenheimer approximation, the
matrix elements of the electronic dipole between the electronic wave functions are also
assumed to be independent of the nuclear coordinates (the Condon approximation
[18.4]),
hex|µˆ r|exi = µex ; hgr|µˆ r|gri = µgr
hgr|µˆ r|exi = hex|µˆ r|gri
∗ = µgr,ex. (18.3.20)
Making use of Eq. (18.3.3), the matrix elements of the nuclear dipole operator read
hex|µˆq|exi = hgr|µˆq|gri = µˆq
hgr|µˆq|exi = hex|µˆq|gri = 0.
(18.3.21)
Notice that the transitions between the electronic ground and the excited states are
attributed only to the off-diagonal elements (see what follows), referred to as the “tran￾sition dipoles.” Indeed, when these matrix elements vanish, for example, due to specific
symmetry properties of the electronic states, the system is transparent to the radiation.
The full Hamiltonian is the sum of the field-free system Hamiltonian (Eq. (18.3.14))
and the interaction term (Eq. (18.3.19)),
Hˆ = Hˆ
0 +Vˆ(t). (18.3.22)
Notice that the zero-order Hamiltonian is analogous to Hˆ
0 discussed in detail in Sec￾tion 18.2 for the charge transfer scenario (Eqs. (18.2.17–18.2.21)). Using this analogy
and replacing the donor and acceptor states, |Di and |Ai, by the ground and excited
states, |gri and |exi, each eigenstate of the zero-order Hamiltonian is a product of an
electronic state and a nuclear state,
Hˆ
0|gri ⊗|χgr,ni = εgr,n|gri ⊗ |χgr,ni
Hˆ
0|exi ⊗ |χex,mi = εex,m|exi ⊗|χex,mi. (18.3.23)
The nuclear states, |χgr,ni and |χex,mi, are eigenstates of the nuclear Hamiltonians,
Hˆ
gr,Q and Hˆ
ex,Q, respectively. These states are products of displaced harmonic oscillator
eigenfunctions,
hQ|χgr,ni = φn1
(Q1 +∆1)·φn2
(Q2 +∆2)·φn3
(Q3 +∆3)···
hQ|χex,mi = φm1
(Q1 −∆1)·φm2
(Q2 −∆2)·φm3
(Q3 −∆3)···
, (18.3.24)
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press372 Thermal Rates in a Bosonic Environment
where the corresponding eigenvalues are
εgr,n = ∆E −∑
j
h¯ωj
2
∆
2
j +∑
j
h¯ωj

nj +
1
2

εex,m = −∆E −∑
j
h¯ωj
2
∆
2
j +∑
j
h¯ωj

mj +
1
2

.
(18.3.25)
Thermal Absorption and Emission Rates
We are interested in the rate of field-induced transitions between the ground and the
excited electronic states. Considering that the state-to-state interaction matrix ele￾ments, hχgr,n|hgr|Vˆ(t)|χex,mi|exi = hχgr,n|χex,miµgr,ex sin(Ωt), are proportional to the
field intensity, |E0| (see Eq. (18.3.18)) and to Franck–Condon factors (which are
smaller than or equal to unity), first-order perturbation theory can become valid for
sufficiently weak field intensities (see Eq. (15.6.12)). Using the general expression for
thermal rates induced by explicitly time-dependent interactions (Eq. (17.3.15)), we
obtain in this case (Ex. 18.3.1)
k
(1)
gr→ex(t) ∼=
2
h¯
2 Re
wt
0
tr{ρˆgr(0)Pˆ
gre
iHˆ
0t
0
h¯ Vˆ(t
0
)e
−iHˆ
0t
0
h¯ Pˆ
exe
iHˆ
0t
h¯ Vˆ(t)e
−iHˆ
0t
h¯ }dt
0
k
(1)
ex→gr(t) ∼=
2
h¯
2 Re
wt
0
tr{ρˆex(0)Pˆ
exe
iHˆ
0t
0
h¯ Vˆ(t
0
)e
−iHˆ
0t
0
h¯ Pˆ
gre
iHˆ
0t
h¯ Vˆ(t)e
−iHˆ
0t
h¯ }dt
0
, (18.3.26)
where the initial and final states are associated with the electronic projection operators
(see Eq. (17.3.1)),
Pˆ
gr = |grihgr| ; Pˆ
ex = |exihex|, (18.3.27)
and, Pˆ2
gr = Pˆ
gr, Pˆ
grPˆ
ex = 0, Pˆ2
ex = Pˆ
ex, [Pˆ
gr, Hˆ
0] = [Pˆ
ex, Hˆ
0] = 0 (see Eqs. (17.3.2, 17.3.3)).
An initial “quasi-equilibrium” state is assumed, in which the relative weights of the dif￾ferent Hˆ
0-eigenstates correspond to a canonical statistical ensemble (see Section 17.3).
The respective initial density operators for absorption and emission processes therefore
read
ρˆgr(0) = 1
Zgr
e
−Hˆ
0 /(kBT)Pˆ
gr ; ρˆex(0) = 1
Zex
e
−Hˆ
0/(kBT)Pˆ
ex, (18.3.28)
where Zgr = tr{e
−Hˆ
0/(kBT)Pˆ
gr} and Zex = tr{e
−Hˆ
0 /(kBT)Pˆ
ex}.
Exercise 18.3.1 According to first-order perturbation theory, the rate of population
transfer between an initial thermal ensemble and a final ensemble due to an explicitly time￾dependent interaction is given by Eq. (17.3.15). Replace the generic projection operators
as defined in Eqs. (17.3.1–17.3.4) by the relevant projection operators into the ground
and excited electronic states in a chromophore (Eq. (18.3.27)) to obtain the absorption
and emission rates in Eq. (18.3.26).
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press373 18.3 Radiation Absorption and Emission
Introducing explicitly the interaction (Eqs. (18.3.15–18.3.21)), the absorption and
emission rates (Eq. (18.3.26)) obtain the more explicit form (Ex. 18.3.2),
k
(1)
gr→ex(t) ∼= 2 Re"
(1−e
−2iΩt
)
wt
0
e
iΩτ
cgr(τ)dτ + (1−e
2iΩt
)
wt
0
e
−iΩτ
cgr(τ)dτ
#
k
(1)
ex→gr(t) ∼= 2 Re"
(1−e
−2iΩt
)
wt
0
e
iΩτ
cex(τ)dτ + (1−e
2iΩt
)
wt
0
e
−iΩτ
cex(τ)dτ
#
,
(18.3.29)
where cgr(τ) and cex(τ) are dipole–dipole correlation functions,
Cgr(τ) ≡
1
4h¯
2
tr{ρˆgr(0)µ
†
ex,gr(0)µˆ ex,gr(τ)}
Cex(τ) ≡
1
4h¯
2
tr{ρˆex(0)µˆ ex,gr(0)µ
†
ex,gr(τ)}
(18.3.30)
µˆ ex,gr(τ) = e
iHˆ
0τ
h¯ Pˆ
exµˆ Pˆ
gre
−iHˆ
0τ
h¯ . (18.3.31)
Considering the explicit form of the zero-order Hamiltonian (Eq. (18.3.14)), and tak￾ing the trace over the electronic degrees of freedom, these correlation functions are
expressed in terms of the nuclear Hamiltonians (Ex. 18.3.3),
cgr(τ) = |µgr,ex|
2
4h¯
2
trQ
(
e
−Hˆ
gr,Q/(kBT)
Zgr
e
iHˆ
ex,Qτ
h¯ e
−iHˆgr,Qτ
h¯
)
cex(τ) = |µgr,ex|
2
4h¯
2
trQ
(
e
−Hˆ
ex,Q/(kBT)
Zex
e
iHˆgr,Qτ
h¯ e
−iHˆ
ex,Qτ
h¯
)
. (18.3.32)
The trace over the nuclear degrees of freedom can be evaluated explicitly by introducing
a complete orthonormal system of harmonic oscillator eigenfunctions. This leads to
an expansion of the correlation functions (Eq. (18.3.32)) in terms of Franck–Condon
overlap integrals (Ex. 18.3.4),
Cgr(τ) = |µgr,ex|
2
4h¯
2 ∑n,m
e
−εgr,n/(kBT)
Zgr
|hχgr,n|χex,mi|2
e
−i(εgr,n−εex,m)τ
h¯
Cex(τ) = |µgr,ex|
2
4h¯
2 ∑n,m
e
−εex,m/(kBT)
Zex
|hχgr,n|χex,mi|2
e
i(εgr,n−εex,m)τ
h¯
. (18.3.33)
Exercise 18.3.2 The absorption and emission rates of a field-driven chromophore are
given in Eq. (18.3.26). Use the explicit form of the interaction, Eqs. (18.3.15–18.3.18),
the projection operators to the ground and excited states, Eq. (18.3.27), and the decompo￾sition of the field amplitude into rotating waves, sin(Ωt) = (e
iΩt −e
−iΩt
)/(2i), to express
the rates in terms of the dipole correlation functions (Eqs. (18.3.29–18.3.31)).
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press374 Thermal Rates in a Bosonic Environment
Exercise 18.3.3 (a) Given the explicit form of the zero-order Hamiltonian,
Eq. (18.3.14), show that
hex|e
±iHˆ
0 τ
h¯ |exi = e
±iHˆ
ex,Qτ
h¯ ; hgr|e
±iHˆ
0 τ
h¯ |gri = e
±iHˆ
gr,Qτ
h¯
hgr|e
−Hˆ
0 /(kBT)
|gri = e
−Hˆ
gr,Q/(kBT)
; hex|e
−Hˆ
0/(kBT)
|exi = e
−Hˆ
ex,Q/(kBT)
(b) Use the definition of the projection operators to the ground and excited electronic
states (Eq. (18.3.27)), the result (a), and Eqs. (18.3.18, 18.3.20, 18.3.21) for the inter￾action matrix elements, to derive Eq. (18.3.32) from Eqs. (18.3.28, 18.3.30). Recall
that the trace over the full electronic and nuclear space can be expressed as tr{Oˆ} =
trQ{hgr|Oˆ|gri+hex|Oˆ|exi}.
Exercise 18.3.4 Derive Eq. (18.3.33) from Eq. (18.3.32) by evaluating the trace over
the nuclear space using a complete set of eigenstates of the multidimensional Hamilto￾nian, Hˆ
gr,Q, and an identity operator, expressed in terms of Hˆ
ex,Q-eigenstates (as defined
in Eqs. (18.3.23, 18.3.24)).
As apparent from Eq. (18.3.33) for the dipole correlation functions, the absorp￾tion and emission rates (Eq. (18.3.29)) are sums over time integrals of the form
rt
0
e
±i(εgr,n−εex,m±h¯Ω)τ/h¯ dτ. The dominant contributions to these sums are attributed to
the smallest exponents, corresponding to resonances between the field frequency and
the state-to-state transition frequency,(εex,m −εgr,n)/h¯ ≈ Ω. Taking this into considera￾tion, each transition rate is dominated by only one of the rotating waves, e
±iΩτ
. Keeping
only the dominant one is often referred to as the “Rotating Wave Approximation”
(RWA) for the absorption and emission rates,
k
(1)
gr→ex(t) ∼= 2 Re"
(1−e
2iΩt
)
wt
0
e
−iΩτ
cgr(τ)dτ
#
k
(1)
ex→gr(t) ∼= 2 Re"
(1−e
−2iΩt
)
wt
0
e
iΩτ
cex(τ)dτ
#
. (18.3.34)
Notice that the time-dependence of the transition rates arises from the time integral as
well as the pre-factor, 1−e
±2iΩt
. The latter oscillates around unity at twice the driving
field frequency, which is typically much higher than the rate of change of the domi￾nant contributions to the time integral, and in the weak coupling limit, much higher
than the transition rate itself. Therefore, the contribution of the rapid oscillations aver￾ages to zero on the relevant timescales, and the RWA expressions for the measurable
absorption and emission rates read (Ex. 18.3.5)
k
(1)
gr→ex(t) ∼= 2 Rewt
0
e
−iΩτ
cgr(τ)dτ
k
(1)
ex→gr(t) ∼= 2 Rewt
0
e
iΩτ
cex(τ)dτ
. (18.3.35)
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press375 18.3 Radiation Absorption and Emission
Exercise 18.3.5 Within the rotating wave approximation, the interaction term in
the Hamiltonian (Eq. (18.3.19)) can be replaced by Vˆ(t) = e
iΩt
2
µgr,ex|grihex| +
e
−iΩt
2
µex,gr|exihgr|. Use this interaction term in the rate expressions (Eq. (18.3.26)) to
derive Eq. (18.3.35) directly.
The “Golden Rule
“
Rates
The rate expressions (Eqs. (18.3.35, 18.3.32)) are analogous to those in Eq. (18.2.26)
for charge transfer within the spin-boson model. Apart from the pre-factor in which the
electronic tunneling matrix element is replaced by the transition dipole interaction, the
harmonic correlation functions have precisely the same structure of sums over oscilla￾tory functions (Eqs. (18.2.27, 18.3.33)). The remarkable difference, however, is that in
the case of charge transfer the oscillation frequencies correspond directly to the energy
differences between Hˆ
0-eigenstates, whereas in the case of absorption/emission of radi￾ation, these differences are displaced by the field frequency, ±Ω. As discussed in the
general case (Eqs. (17.2.3, 17.2.8, 17.2.9)), as well as in the context of a multidimen￾sional harmonic model (Eq. (18.2.34)), in the limits of weak state-to-state coupling
between an initial thermal state and a dense and wide manifold of final states, the
integrands in Eq. (18.3.35) decay within a time that is much shorter than the character￾istic time of population transitions between the electronic states. Therefore, the upper
time-limit in the expressions for the absorption and emission rates can be replaced by
infinity, and these rates become constants, expressed in terms of Fermi’s golden rule
(Ex. 18.3.6),
kgr→ex(Ω) = 2π
h¯




µgr,ex
2




2
∑n,m
e
−εgr,n/(kBT)
Zgr
|hχgr,n|χex,mi|2
δ(εgr,n −εex,m +h¯Ω)
kex→gr(Ω) = 2π
h¯




µgr,ex
2




2
∑n,m
e
−εex,m/(kBT)
Zex
|hχgr,n|χex,mi|2
δ(εgr,n −εex,m +h¯Ω)
. (18.3.36)
Exercise 18.3.6 Derive Eq. (18.3.36) by taking the upper limit of the time integral in
Eqs. (18.3.33, 18.3.35) to infinity and by using a suitable definition of Dirac’s delta. Use
the fact that the real part of the integrand is an even function of time.
Notice that the transition rates can be reformulated alternatively, in terms of
the dipole–dipole correlation functions (Eq. (18.3.30)). Taking the time integral in
Eq. (18.3.35) to infinity (in accordance with the validity of Fermi’s golden rule), the
rates are shown to be Fourier transforms of the dipole–dipole correlation functions
(Ex. 18.3.7),
kgr→ex(Ω) = w∞
−∞
e
−iΩτ
cgr(τ)dτ =
1
4h¯
2
w∞
−∞
e
−iΩτ
tr{ρˆgr(0)µˆ
†
ex,gr(0)µˆ ex,gr(τ)}dτ
kex→gr(Ω) = w∞
−∞
e
iΩτ
cex(τ)dτ =
1
4h¯
2
w∞
−∞
e
iΩτ
tr{ρˆex(0)µˆ ex,gr(0)µˆ
†
ex, gr(τ)}dτ, (18.3.37)
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press376 Thermal Rates in a Bosonic Environment
which reproduces the expression for the spectral line shapes of linear response theory
(see [18.7]).
Exercise 18.3.7 The dipole correlation functions are defined in Eq. (18.3.30). (a)
Show that c
∗
gr(τ) = cgr(−τ) and c
∗
ex(τ) = cex(−τ). (b) Use the result (a) to show that
Re[e
−iΩτ
cgr(τ)] and Re[e
iΩτ
cex(τ)] are even functions of time, and that Im[e
−iΩτ
cgr(τ)]
and Im[e
iΩτ
cex(τ)] are odd functions of time. Use this result to derive Eq. (18.3.37) from
Eq. (18.3.35), in the limit t → ∞.
According to Fermi’s golden rule (Eq. (18.3.36)) the thermal absorption and emis￾sion rates are weighted averages over the initial thermal distributions of the initial
nuclear states and a sum over all the final nuclear states. In analogy to the result
for charge transfer (Eq. (18.2.34)), the energy delta selects state-to-state transitions
in which the initial and final energies match each other. However, unlike in the case
of charge transfer, where the matching condition is strict (εA,m = εD,n), the matching
condition for radiation emission and absorption depends on the radiation frequency,
εex,m = εgr,n +hΩ. Of all transitions satisfying this condition, the dominating ones are
those associated with maximal FC factors. While in the case of charge transfer the FC
factors are maximal near crossings between the donor and acceptor potential energy
surfaces (see Fig. 18.2.4), in the present case, the FC factors at a given field frequency
are maximal near crossings between the ground and excited potential energy surfaces,
displaced by h¯Ω, namely, Eex(Q) ≈ Egr(Q) +h¯Ω, as illustrated in Fig. 18.3.2.
We now turn to deriving explicit expressions for the absorption and emission rates
in terms of the microscopic model Hamiltonian parameters. For this purpose, we refer
again to the close analogy between charge transfer (Eq. (18.2.26)) and field-driven
transitions (Eqs. (18.3.35, 18.3.32)) within the spin-boson model. Using this analogy
(Eqs. (18.2.29–18.2.33)), the nuclear correlation functions, cgr(τ) and cex(τ), can be
expressed explicitly in terms of the oscillator frequencies {ωj} and coupling strengths,
{∆j}. The first-order approximations for the time-dependent thermal absorption and
emission rates therefore read
k
(1)
gr→ex(t) ∼=
|µgr,ex|
2
2h¯
2 Re
wt
0
e
−iτ
h¯
(2∆E+h¯Ω)
e
2i∑
j
∆
2
j
sin(ωjτ)
e
−2∑
j
∆
2
j
(1−cos(ωjτ))(1+2n(ωj))
dτ
k
(1)
ex→gr(t) ∼=
|µgr,ex|
2
2h¯
2 Re
wt
0
e
iτ
h¯
(2∆E+h¯Ω)
e
2i∑
j
∆
2
j
sin(ωjτ)
e
−2∑
j
∆
2
j
(1−cos(ωjτ))(1+2n(ωj))
dτ.
(18.3.38)
The Semiclassical Limit
It is often the case that transitions between the ground and excited states involve cou￾pling to low-frequency nuclear modes. This characterizes, for example, the coupling of
an intramolecular electronic (or vibronic; see what follows) transition to surrounding
dipoles in a polar solvent, or the coupling of a transition within an atomic or molec￾ular impurity to phonon modes in a lattice. The influence of low-frequency modes on
the field-induced transition rates can be readily accounted for by referring again to the
close analogy to electron transfer processes, as analyzed in Section 18.2. Assuming first
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press377 18.3 Radiation Absorption and Emission
that all the nuclear modes addressed in Eq. (18.3.38) are associated with low frequen￾cies (in comparison to the thermal energy (Eq. (18.2.35)), as well as to the relaxation
rate of the relevant time integrand (Eq. (18.2.37)), the absorption and emission rates
are approximated as (compare to Eq. (18.2.39))
k
(1)
gr→ex(t) ∼=
|µgr,ex|
2
2h¯
2 Re
wt
0
e
−iτ
h¯
(2∆E+h¯Ω−Eλ
)
e
−Eλ
kBTτ
2
h¯
2 dτ
k
(1)
ex→gr(t) ∼=
|µgr,ex|
2
2h¯
2 Re
wt
0
e
−iτ
h¯
(−2∆E−h¯Ω−Eλ
)
e
−Eλ
kBTτ
2
h¯
2 dτ. (18.3.39)
Here Eλ
is the nuclear reorganization energy, as defined in Eq. (18.2.40). When
the reorganization energy is sufficiently large with respect to the vibrational quanta
(
(h¯ωj)
2
kBTEλ
 8π
2
; see Eq. (18.2.44)), and with respect to the driven transition dipole
(
|µgr,ex|
2
8kBTEλ
 1; see Eq. (18.2.45)), the time integral can be taken to infinity to obtain
the Fermi’s golden rule rates in the low-frequencies limit,
kgr→ex(Ω) = |µgr,ex|
2
4
r π
h¯
2
kBTEλ
e
−(Eλ
−2∆E −h¯Ω)
2
4kBTEλ
kex→gr(Ω) = |µgr,ex|
2
4
r π
h¯
2
kBTEλ
e
−(Eλ
+2∆E +h¯Ω)
2
4kBTEλ . (18.3.40)
Eex (Qj
)
Egr (Qj
)
Eex (Qj)
Qj,gr Qj,ex Qj
E
hΩ Egr (Qj
)
Qj,gr Qj,ex Qj
E
hΩ
Ftigure 18.3.2 The role of Franck–Condon factors in controlling the absorption and emission rates is illustrated for a single active
nuclear mode. In each plot, the two parabolic potential energy curves (thick solid lines) correspond to the ground and
excited electronic states (Egr(Qj)and Eex (Qj); see Fig.18.3.1). The nuclear probability densities (thin solid lines)
associated with the vibrational eigenfunctions at each electronic state are plotted at the respective energy levels. For a
given field frequency, Ω, the FC overlap between different states at the same energy is maximized near crossing
points between two curves: in the case of absorption (let plot), the crossing between Eex(Qj)and
Egr(Qj) +h¯Ω, and in the case of emission (right plot), the crossing between Egr(Qj)and Eex(Qj)−h¯Ω.
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press378 Thermal Rates in a Bosonic Environment
The absorption and emission rates as functions of the driving field frequency are
proportional to the spectral lines, derived in linear response theory [18.7]. The sem￾iclassical result (Eq. (18.3.40)) amounts to a Gaussian broadening of the transition
lines, due to their coupling to the low-frequency vibrations. The line width (the
standard deviation, √
2kBTEλ
) is shown to increase with increasing temperature and
coupling strength (nuclear reorganization energy). The absorption and emission rates
are peaked at different frequencies, Ω = (−2∆E + Eλ
)/h¯ and Ω = (−2∆E − Eλ
)/h¯,
respectively, which deviate from resonance with the “adiabatic transition energy,”
Ω = −2∆E/h¯ (see Eq. (18.3.11) and recall that ∆E < 0). Indeed, the resonant frequen￾cies are higher (blue-shifted) for absorption and lower (red-shifted) for emission, due
to the nuclear reorganization energy associated with each transition (see Fig. 18.3.3).
This result (termed “the Stokes shift”) has remarkable practical consequences in the
context of electrooptical and photovoltaic devices, as it means that driving the sys￾tem “upwards” in energy from the thermal ground electronic state to the excited state
requires more energy than can be gained by the corresponding “downwards” transi￾tion. This is attributed to the fact that in both cases, regaining a quasi-equilibrium
thermal state of the nuclei after the electronic transition involves a nonradiative
transition in which heat is emitted to the surroundings.
Notice that, in the absence of coupling to the surrounding low-frequency modes,
the absorption and emission line shapes converge to a single delta peak, centered
emission
(a) (b)
absorption
Transition rate
= 2|∆E hΩ | −Eλ
= 2|∆E hΩ |−Eλ
E
−∆E +Eλ
∆E +Eλ
∆E
Qj,gr Qj,ex Qj
−∆E
= 2|∆E hΩ |+Eλ
2 |∆E | hΩ
= 2|∆E hΩ |+Eλ
Ftigure 18.3.3 (a) The effect of nuclear reorganization on the absorption and emission rates for the field-driven spin-boson model, in
the semiclassical limit. The rates are Gaussian functions of the field frequency, peaked at h¯Ω = |2∆E|+Eλ
for
absorption, and h¯Ω = 2|∆E| −Eλ
for emission. The peaks are Stokes-shifted by the nuclear reorganization
energy, Eλ
, with respect to the “adiabatic” transition energy, |2∆E|. The solid and dashed curves correspond to Eλ
being equal to 10% and 30% of |2∆E|, respectively. (b) Potential energy curves for a single low frequency mode at
the ground and excited electronic states. The maximal absorption (emission) rate is obtained when the transition is
“activation-less,” namely, when the minimum of the h¯Ω-shifted ground (excited) state potential crosses the excited
(ground) state potential. The “adiabatic” transition energy, |2∆E|, is marked by the dashed diagonal line.
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press379 18.3 Radiation Absorption and Emission
at the “adiabatic excitation energy,” Ω = −2∆E/h¯. This can be readily realized by tak￾ing the limit, Eλ → 0 (Ex. 18.3.8), which also reproduces the perturbative calculation
of the transition rate between pure initial and final states (see the discussion of periodic
driving in Section 15.6, Eq. (15.6.28), and Ex. 15.6.10). “Pure electronic transitions”
are characteristics of atoms in the gas phase, but rarely observed in nanoscale many￾atom systems. In a condensed-phase environment (and even in polyatomic molecules
in the gas phase), line broadening and the Stokes shift between the absorption and
emission lines are commonly observed. Characteristic examples are the absorption
and fluorescence spectra of molecular chromophores in solid matrices, lattices, and
solutions, or exciton formation and relaxation in quantum dots and bulk materi￾als. Notice that when the surrounding mode frequencies are much smaller than the
absorption/emission transition rates, their averaged effect on the transition rate can
be rightly treated as an ensemble average over a distribution of different static micro￾scopic environments to which the electronic transition is coupled [18.5]. The Gaussian
broadening of the absorption/emission lines due to coupling to low-frequency modes
is therefore closely related to “inhomogeneous broadening.” (See Chapter 19 for a dis￾cussion of inhomogeneous broadening in the limit of weak coupling to the bosonic
environment.)
Exercise 18.3.8 One of the representations of Dirac’s delta is δ(x) = limε→+0
q
1
4πε
e
−x
2
4ε .
Use it to show that in the limit of vanishing coupling to the nuclear modes, both the absorp￾tion and the emission rates are peaked at the “adiabatic” energy gap, −2∆E, namely
limEλ→0 kgr→ex(Ω) = 2π
h¯
|µgr,ex|
2
4
δ(−2∆E − h¯Ω), limEλ→0 kex→gr(Ω) = 2π
h¯
|µgr,ex|
2
4
δ(2∆E +
h¯Ω). Compare the result with the direct calculation of transition rate between pure states
in Eq. (15.6.29).
Vibronic Spectra
In many cases the electronic transition is coupled to “high-frequency” nuclear modes.
This is a common situation in molecules, where electronic excitations affect chemi￾cal bonds. For example, electronic population transfer from bonding to antibonding
molecular orbitals (see Section 14.3) would result in changes in bond distances,
frequencies, dissociation energies, and so forth. The vibrational frequencies associated
with chemical bonds near their stable configuration are typically much larger than the
thermal energy (see Section 8.4), and the “low-frequency” (semiclassical) approxima￾tion just exercised does not apply to such vibrations. Yet, high-frequency modes are
apparent in absorption and emission line shapes, and in many cases can be resolved
experimentally, providing valuable information on the molecular structure and inter￾nuclear forces. The manifestation of high-frequency modes in absorption and emission
spectral line shapes can be inferred directly from the general perturbative expression,
Eq. (18.3.38), for the transition rates within the spin-boson model. For concreteness,
let us consider a scenario in which the electronic transition is coupled to a dense set
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press380 Thermal Rates in a Bosonic Environment
of low-frequency modes as well as to a single high-frequency mode. We shall denote
the mode frequency as ω0, and its displacement parameter (its effective coupling to the
electronic transition) as ∆0. Invoking the low-frequency approximation (Eq. (18.3.39))
only for the low-frequency modes, Eq. (18.3.38) obtains the form (Ex. 18.3.9)
k
(1)
gr→ex(t)∼=
|µgr,ex|
2
2h¯
2 Re
wt
0
e
−iτ
h¯
(2∆E+h¯Ω−Eλ
)
e
−Eλ
kBTτ
2
h¯
2
e
2i∆
2
0
sin(ω0τ)
e
−2∆
2
0
(1−cos(ω0τ))(1+2n(ω0))dτ
k
(1)
ex→gr(t)∼=
|µgr,ex|
2
2h¯
2 Re
wt
0
e
−iτ
h¯
(−2∆E−h¯Ω−Eλ
)
e
−Eλ
kBTτ
2
h¯
2
e
2i∆
2
0
sin(ω0τ)
e
−2∆
2
0
(1−cos(ω0τ))(1+2n(ω0))dτ.
(18.3.41)
For the high-frequency mode, the condition h¯ω0  kBT typically holds. Conse￾quently, and for simplicity, we consider here the limit in which the thermal occupation
number (Eq. (18.2.32)) can be approximated as zero, n(ω0) ≈ 0, leading to
k
(1)
gr→ex(t) ∼=
|µgr,ex|
2
2h¯
2
e
−2∆
2
0 Re
wt
0
e
−iτ
h¯
(2∆E+h¯Ω−Eλ
)
e
−Eλ
kBTτ
2
h¯
2 e
2∆
2
0
e
iω0τ
dτ
k
(1)
ex→gr(t) ∼=
|µgr,ex|
2
2h¯
2
e
−2∆
2
0 Re
wt
0
e
−iτ
h¯
(−2∆E−h¯Ω−Eλ
)
e
−Eλ
kBTτ
2
h¯
2 e
2∆
2
0
e
iω0 τ
dτ
. (18.3.42)
Using the Taylor expansion, e
2∆
2
0
e
iω0
τ
=
∞
∑
n=0
(
√
2∆0)
2n
n!
e
inω0τ
, and taking the upper limit in
the time integral to infinity (in accordance with the validity of Fermi’s golden rule), we
obtain explicit expressions for the spectral line shapes (Ex. 18.3.10),
kgr→ex(Ω) =
∞
∑
n=0
(
√
2∆0)
2n
n!
e
−2∆
2
0
|µgr,ex|
2
4
s
T
h¯
2kBTEλ
e
−(h¯ω 0 n+Eλ−2∆E−h¯Ω)
2
4kBTEλ
kex→gr(Ω) =
∞
∑
n=0
(
√
2∆0)
2n
n!
e
−2∆
2
0
|µgr,ex|
2
4
r π
h¯
2kBTEλ
e
−(h¯ω 0 n+Eλ+2∆E+hΩ)
2
4kBTEλ . (18.3.43)
The spectral lines are shown to be sums of Gaussian peaks, centered at h¯Ω = −2∆E +
h¯ω 0n + Eλ and hΩ = −2∆E − h¯ω 0n − Eλ
, for absorption and emission, respectively.
These peaks correspond to “vibronic transitions,” in which the molecule gains (or
loses) energy that equals the “adiabatic excitation energy,” −2∆E (recall that ∆E < 0 by
our convention), plus an integer number of vibration quanta, h¯ω0n (see Fig. 18.3.4).
Each vibronic peak is broadened and displaced by the reorganization energy, Eλ
,
attributed to the coupling to low-frequency modes. The peak heights are proportional
to the square of the transition dipole and the field intensity, |µgr,ex|
2
(see Eqs. (18.3.18,
18.3.20)), where the pre-factors, (
√
2∆0)
2n
e
−2∆
2
0 /n!, depend on the number of vibra￾tion quanta involved in the transition. These pre-factors can be readily identified as
the squares of Franck–Condon overlap integrals between the ground vibrational state
at the initial electronic state and the nth vibrational state at the final electronic state
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press381 18.3 Radiation Absorption and Emission
(see Ex. 8.3.11 and Fig. 18.3.4). The ability to resolve individual vibrational line-shapes
depends on the coupling of the vibronic transitions to low-frequency modes, and par￾ticularly on the ratio between the vibration quantum and the reorganization energy,
h¯ω 0/Eλ
. In a polar solvent, the reorganization energy is typically large due to efficient
coupling to the polarizable medium, and the corresponding line broadening obscures
the vibronic peaks. In the gas phase, however, and even in nonpolar solvents, the
vibronic structure can be clearly resolved.
Exercise 18.3.9 (a) Show that the time integrals in Eq. (18.3.38) can be rewritten as
rt
0
e
±iτ
h¯
(2∆E+h¯Ω)
c0(τ)
N
∏
j=1
cj(τ)dτ, where the single-mode correlation functions are defined
as cj(τ) = e
2i∆
2
j
sin(ωjτ)
e
−2∆
2
j
(1−cos(ωjτ))(1+2n(ωj)). (b) Show that c0(τ) can be rewrit￾ten as c0(τ) = e
−2∆
2
0
(2n(ω0)+1)
e
2∆
2
0
[(n(ω0)+1)e
iω0
τ +n(ω0)e
−iω0
τ
]
. (c) Follow the low-frequency
approximation, Eqs. (18.2.35–18.2.39), to show that
N
∏
j=1
cj(τ) = e
iτ
h¯
Eλ e
−Eλ
kBTτ
2
h¯
2
, and
derive Eq. (18.3.41).
Ftigure 18.3.4 (a) Vibronic absorption and emission spectra calculated by Eq. (18.3.43) for the field-driven spin-boson model with a
single high-frequency vibrational mode. Within the harmonic approximation, the absorption and emission peaks are
symmetrically distributed with respect to the “adiabatic” transition energy, |2∆E|. The different peaks (separated by
the vibration quantum, h¯ω0 = 0.1|2∆E|) correspond to different changes in the vibration quantum number
during radiation absorption/emission. The ambient temperature corresponds to kBT = 0.25h¯ω 0, which implies
that in the initial thermal states, only the vibrational ground state of the high-frequency mode is significantly
populated. Each peak is broadened due to additional coupling of the electronic transition to multiple low-frequency
modes, characterized by the reorganization energy Eλ = 0.01|2∆E|. (b) Underlying potential energy curves and
corresponding vibrational eigenstates probability densities for the high-frequency vibration. The vibronic transitions
associated with the peaks in the spectra are marked by vertical arrows, where the Franck–Condon overlap integrals
between the corresponding vibrational eigenstates determine the heights of the corresponding spectral peaks.
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press382 Thermal Rates in a Bosonic Environment
Exercise 18.3.10 Introduce the Taylor expansion of e
2∆
2
0
e
iω 0
τ
into Eq. (18.3.42) and
then carry out the time integration to infinity. Notice that the time integrand is an even
function of time, and use the identity, r∞
−∞
dke−zk2
e
ikx =
qπ
z
e
−x
2
4z , to obtain Eq. (18.3.43).
Exercise 18.3.11 Using dimensionless position and momentum variables, Qˆ and Pˆ, a
coherent state of a one-dimensional harmonic oscillator, |αi, is defined as hQ|αi =
(
1
π
)
1/4
e
−(Q−
√
2Re(α))2
2 e
i
√
2Im(α)Q, where α ≡
q
1
2
(Q0 +iP0) (see Eqs. (15.4.11, 15.4.36)).
The projections of the coherent state on the eigenstates of the harmonic oscilla￾tor Hamiltonian, h¯ω
2
(Qˆ 2 + Pˆ2
)|φni = h¯ω(n + 1/2)|φni, read |hφn|αi|2 = e
aα
2
|
|α|
2n
n!
(see Eq. (15.4.37)). Use this to show that the pre-factors multiplying the Gaus￾sians in Eq. (18.3.43) are related to Franck–Condon overlap integrals, namely,
given the harmonic oscillator ground state function, φ0(Q) = ( 1
π
)
1/4
e
−Q
2
2 , show that




r∞
−∞
φn(Q+∆0)φ0(Q−∆0)dQ




2
= e
−2∆
2
0
(
√
2∆0)
2n
n!
.
18.4 Förster Resonant Electronic-Energy (Exciton) Transfer (FRET)
A most important elementary process in nanoscale systems is electronic energy transfer
between chromophores, often referred to as Fluorescence Resonance Energy Transfer
(FRET) or Förster Resonance Energy Transfer, after Theodor Förster who explained
the physics underlying this phenomenon [18.6]. In Section 18.3 we learned that elec￾tronic energy can be gained or lost by an isolated chromophore due to the interaction
between its electric dipole and a time-periodic electric field. In a multichromophore
system, however, the interaction between the electric dipoles of nearby chromophores
can lead to direct energy transfer between them. Consider, for example, a chromo￾phore in an excited electronic state (an energy “donor”). Instead of emitting its extra
energy as electro-magnetic radiation (fluorescence), the energy can be transferred to
a nearby chromophore (the energy “acceptor”) via dipole–dipole interaction, result￾ing in an excitation of the latter, in a process termed FRET (see Fig. 18.4.1). When
the interchromophore interaction is weak, this process can be readily associated with a
rate constant, and when this rate is larger than the fluorescence rate, FRET dominates.
In what follows we shall analyze the dependence of FRET on the parameters charac￾terizing the chromophores in their microscopic environments. As we shall see, the rate
of FRET increases with increasing spectral overlap between the emission line of the
energy donor and the absorption line of the energy acceptor. If the donor and accep￾tor are of the same type, their emission and absorption lines are Stokes-shifted (see
Section 18.3), and the overlap is relatively small. When the donor and acceptor are
of a different type, the spectral overlap can become optimal, and the rate of FRET
increases. The difference between the fluorescence of the originally excited chromo￾phore (donor) and that of the acceptor enables us to measure the rate of FRET. Since
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press383 18.4 Förster Resonant Electronic-Energy (Exciton) Transfer (FRET)
Ftigure 18.4.1 A schematic illustration of the states involved in FRET between two chromophores. Each chromophore is characterized
by its ground and first excited electronic states, coupled to internal as well as external nuclear degrees of freedom in its
local surroundings (marked symbolically by arrows). The left and right plots represent the two excited states of the
bichromophoric system, where the excitation resides either on the donor (left) or on the acceptor (right).
this rate depends on the square of a dipole–dipole interaction matrix element (see what
follows), it falls like R
−6
, where R is the interchromophore distance. This dependence
on R makes FRET a sensitive probe or interchromophore distances (as well as relative
orientations) on the nanoscale.
The Model Hamiltonian
The zero-order Hamiltonian for the bi-chromophore system corresponds to two
noninteracting chromophores, denoted arbitrarily as a donor (D) and an acceptor (A),
Hˆ
0 = Hˆ
(D)
0 ⊗ ˆI
(A) + ˆI
(D) ⊗Hˆ
(A)
0
. (18.4.1)
Each chromophore Hamiltonian is projected onto the basis of its ground and first
excited electronic states, which are orthonormal eigenstates of the respective electronic
Hamiltonian within the Born–Oppenheimer approximation (see Eqs. (18.3.2, 18.3.3)),
hgr(D)
|gr(D)
i = hex(D)
|ex(D)
i = 1 ; hgr(D)
|ex(D)
i = 0
hgr(A)
|gr(A)
i = hex(A)
|ex(A)
i = 1 ; hgr(A)
|ex(A)
i = 0. (18.4.2)
The single-chromophore Hamiltonians therefore read (see Eq. (18.3.7))
Hˆ
(A)
0 = Hˆ
(A)
gr,QA
|gr(A)
ihgr(A)
|+Hˆ
(A)
ex,QA
|ex(A)
ihex(A)
|
Hˆ
(D)
0 = Hˆ
(D)
gr,QD
|gr(D)
ihgr(D)
|+Hˆ
(D)
ex,QD
|ex(D)
ihex(D)
|. (18.4.3)
Here, QD and QA stand for the (dimensionless) nuclear coordinates within the space of
each chromophore (internal, or in the local surroundings). The corresponding nuclear
Hamiltonians are modeled in terms of additive contributions of harmonic modes (Eqs.
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press384 Thermal Rates in a Bosonic Environment
(18.3.9–18.3.13)), where the nuclear equilibrium positions change upon a change in the
electronic state of the relevant chromophore,
Hˆ
(A)
gr,QA
= ∆
(A)
E +∑
jA
h¯ωjA
2
(Pˆ
2
jA
+Qˆ
2
jA
)+h¯ωjA∆jAQˆ
jA
Hˆ
(A)
ex,QA
= −∆
(A)
E +∑
jA
h¯ωjA
2
(Pˆ
2
jA
+Qˆ
2
jA
)−h¯ωjA∆jAQˆ
jA
Hˆ
(D)
gr,QD
= ∆
(D)
E +∑
jD
h¯ωjD
2
(Pˆ
2
jD +Qˆ
2
jD
)+h¯ωjD ∆jD Qˆ
jD
Hˆ
(D)
ex,QD
= −∆
(D)
E +∑
jD
h¯ωjD
2
(Pˆ
2
jD +Qˆ
2
jD
)−h¯ωjD ∆jD Qˆ
jD
. (18.4.4)
The energy gap between the multidimensional potential energy surface minima at the
ground and the excited states in each chromophore (the adiabatic excitation energy) is
denoted as
2∆
(A)
E = ε
(A)
gr −ε
(A)
ex ,
2∆
(D)
E = ε
(D)
gr −ε
(D)
ex (18.4.5)
where, by our convention, ∆
(D)
E
,∆
(A)
E < 0 (see Eq. (18.3.11)).
Focusing on electronic energy transfer between the two chromophores, we now
restrict the discussion to the space of a single excitation within the bi-chromophore sys￾tem. Namely, we further project the zero-order Hamiltonian onto the space in which
one (and only one) chromophore is electronically excited (the single exciton mani￾fold). The two relevant electronic states of the bi-chromophore system are products
of single-chromophore states,
|D
∗
i = |ex(D)
i ⊗ |gr(A)
i ; |A
∗
i = |gr(D)
i ⊗ |ex(A)
i, (18.4.6)
where |D
∗
i and |A
∗
i correspond to the exciton residing on the donor and the accep￾tor, respectively (see Fig. 18.4.1). The zero-order Hamiltonian in the single exciton
manifold thus reads (Ex. 18.4.1)
Hˆ
0 = HˆD∗,QD,QA
|D
∗
ihD
∗
|+Hˆ
A∗,QD,QA
|A
∗
ihA
∗
| (18.4.7)
HˆD∗,QD,QA = Hˆ
(D)
ex,QD
+Hˆ
(A)
gr,QA
; Hˆ
A∗,QD,QA = Hˆ
(D)
gr,QD
+Hˆ
(A)
ex,QA
. (18.4.8)
Exercise 18.4.1 The Hamiltonian of the bichromophoric system in the absence of inter￾chromophore interaction (Hˆ
0) is given by Eq. (18.4.1), where the single-chromophore
Hamiltonians are given by Eq. (18.4.3). Calculate the matrix elements of Hˆ
0 in the basis
of the bi-chromophore states, |D
∗
i = |ex(D)
i ⊗ |gr(A)
i and |A
∗
i = |gr(D)
i ⊗ |ex(A)
i, and
derive Eq. (18.4.7).
We now turn to modeling the interaction between the two chromophores. Again,
a rigorous derivation based on quantum electrodynamics is beyond our scope.
We restrict the discussion to a typical scenario in which the chromophore size
(typically < 1 nm) is smaller than the interchromophore distance, R, and each
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press385 18.4 Förster Resonant Electronic-Energy (Exciton) Transfer (FRET)
chromophore is neutral. Expanding in powers of R the Coulomb interaction energy
between the charge distributions at the two chromophores, the dominant term is the
dipole–dipole interaction,
Jˆ=
dˆ D ·dˆ
A
R3
−3
(dˆ D ·R/R)(dˆ
A ·R/R)
R3
. (18.4.9)
Here, dˆ D and dˆ
A are the donor and acceptor dipole operators in the respective reference
frames (see Eq. (18.3.17)), the vector connecting the centers of mass of the two chro￾mophores is R, where R = |R|. The dipole–dipole interaction facilitates energy transfer
between the donor and the acceptor. Notice that the interaction energy depends on the
magnitude, as well as on the relative orientation of the two dipoles, and decays with the
interchromophore distance as R
3
. This long range nature of the interaction typically
enables energy transfer at a substantial rate, even when the chromophores are a few
nanometers apart. Indeed, electronic energy transfer is enabled over interchromophore
distances in which charge transfer between the chromophores is excluded, owing to
the exponential decay of the corresponding electronic tunneling matrix element (see
Section 18.2).
Representing the dipole–dipole interaction in the basis of single exciton states, we
obtain
Vˆ = JD∗ (QD, QA)|D
∗
ihD
∗
|+JA∗ (QD, QA)|A
∗
ihA
∗
|+JD∗,A∗ |D
∗
ihA
∗
|+JA∗,D∗ |A
∗
ihD
∗
|
(18.4.10)
where JD∗ (QD,QA) = hD
∗
|Jˆ|D
∗
i, JA∗ (QD,QA) = hA
∗
|Jˆ|A
∗
i, JD∗,A∗ = hD
∗
|Jˆ|A
∗
i and
JA∗,D∗ = hA
∗
|Jˆ|D
∗
i. Notice that within the Born–Oppenheimer approximation (see Eqs.
(18.3.20, 18.3.21)) the off-diagonal matrix elements of the dipole–dipole interaction do
not depend on the nuclear coordinates (the Condon approximation).
The full Hamiltonian is the sum of the zero-order (Eqs. (18.4.4, 18.4.7, 18.4.8)) and
the dipole–dipole interaction (Eq. (18.4.10)) terms, Hˆ = Hˆ
0 +Vˆ . The zero-order Ham￾iltonian has the same structure as the corresponding Hamiltonian for charge transfer
(18.2.14, 18.2.16)). The apparent difference is that in the case of energy transfer,
the donor and acceptor states are defined in a bi-chromophore space, and accord￾ingly the nuclear Hamiltonians are sums over modes from the two chromophores
(Eq. (18.4.8)). The eigenstates of Hˆ
0 are products of an electronic and a nuclear states,
in the bi-chromophore system,
Hˆ
0|D
∗
i ⊗|χD∗,ni = εD∗,n|D
∗
i ⊗ |χD∗,ni
Hˆ
0|A
∗
i ⊗ |χA∗,mi = εA∗,m|A
∗
i ⊗ |χA∗,mi. (18.4.11)
The nuclear states are products of single-chromophore states,
hQD, QA|χD∗,ni = hQD|χex,nihQA|χgr,ni
hQD, QA|χA∗,mi = hQD|χgr,mihQA|χex,mi (18.4.12)
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press386 Thermal Rates in a Bosonic Environment
which are products of displaced harmonic oscillator eigenfunctions,
hQD|χex,ni = φn1
(Q1 −∆1)·φn2
(Q2 −∆2)·φn3
(Q3 −∆3)···
hQD|χgr,mi = φm1
(Q1 +∆1)·φm2
(Q2 +∆2)·φm3
(Q3 +∆3)···
hQA|χex,mi = φm1
(Q1 −∆1)·φm2
(Q2 −∆2)·φm3
(Q3 −∆3)···
hQA|χgr,ni = φn1
(Q1 +∆1)·φn2
(Q2 +∆2)·φn3
(Q3 +∆3)···
. (18.4.13)
The corresponding Hˆ
0-eigenstates are
εD∗,n = ∆
(A)
E −∆
(D)
E − ∑
j∈{ jA, jD}
h¯ωj
2
∆
2
j +∑
j
h¯ωj(nj +
1
2
)
εA∗,m = ∆
(D)
E −∆
(A)
E − ∑
j∈{ jA, jD}
h¯ωj
2
∆
2
j +∑
j
h¯ωj(mj +
1
2
) (18.4.14)
Thermal Energy Transfer Rates
We are interested in the rate of electronic energy transfer between the chromophores.
As discussed in Chapter 17, perturbation theory is valid when the state-to-state cou￾pling matrix elements are sufficiently small. In the present case, these matrix elements
obtain the form hχD∗,n|χA∗,mihD
∗
|Jˆ|A
∗
i. Since hD
∗
|Jˆ|A
∗
i ∝ R
−3
, and since the multidi￾mensional Franck–Condon factors, hχD∗,n|χA∗,mi, are smaller than or equal to unity,
perturbation theory becomes valid for sufficiently large interchromophore distances.
Without loss of generality, we shall consider explicitly the transition from the donor
to the acceptor (where similar considerations apply to the reverse process). The donor
and acceptor manifolds of Hˆ
0-eigenstates are associated with the projection operators
(see Eq. (17.3.1)),
PˆD∗ = |D
∗
ihD
∗
| ; Pˆ
A∗ = |A
∗
ihA
∗
|, (18.4.15)
where Pˆ2
D∗ = PˆD∗ ,PˆD∗Pˆ
A∗ = 0,Pˆ2
A∗ = Pˆ
A∗ and [PˆD∗ ,Hˆ
0] = [Pˆ
A∗ ,Hˆ
0] = 0 (see Eqs. (17.3.2,
17.3.3)). The definition of a thermal energy transfer rate (see Section 17.3) assumes an
initial state of the bi-chromophore system, in which all nuclei are at quasi equilibrium.
The corresponding density operator reads (Eq. (17.3.10))
ρˆD∗ (0) = e
−Hˆ
0/(kBT)PˆD∗
ZD∗
; ZD∗ = tr{e
−Hˆ
0/(kBT)PˆD∗ }. (18.4.16)
Notice that the thermal state of each nuclear mode is determined by the electronic
state of the chromophore to which the mode is coupled. Implementing the general
expression for the thermal rate to the present case, we obtain (Eq. (17.3.12))
k
(1)
D∗→A∗ (t) ∼=
2
h¯
2 Re
wt
0
tr{ρˆD∗ (0)PˆD∗Vˆ Pˆ
A∗ e
iHˆ
0
τ
h¯ Vˆ e
−iHˆ
0
τ
h¯ }dτ. (18.4.17)
Introducing explicitly the zero-order Hamiltonian (Eq. (18.4.7)) and the interaction
(Eq. (18.4.10)), and taking the trace over the electronic degrees of freedom, the rate is
expressed as a time integral over a nuclear correlation function (Ex. 18.4.2),
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press387 18.4 Förster Resonant Electronic-Energy (Exciton) Transfer (FRET)
k
(1)
D∗→A∗ (t) = 2 Rewt
0
cD∗,QD,QA
(τ)dτ
cD∗,QD,QA
(τ) = |JD∗,A∗ |
2
h¯
2
trQD,QA
{
e
−Hˆ
D∗,QD,QA
/(kBT)
ZD∗
e
−iHˆ
D∗,QD,QA
τ
h¯ e
iHˆ
A∗,QD,QA
τ
h¯ }. (18.4.18)
A formal expression for the “rate constant” of energy transfer can be obtained
by evaluating the trace using a complete orthonormal system of multidimensional
harmonic oscillator eigenfunctions. This yields (Ex. 18.4.3)
k
(1)
D∗→A∗ (t) = 2|JD∗,A∗ |
2
h¯
2 ∑n,m
e
−εD∗,n
/(kBT)
ZD∗
Re
wt
0
e
−i(εD∗,n
−εA∗,m)τ
h¯ |hχD∗,n|χA∗,mi|2
dτ.
(18.4.19)
In the limits of weak state-to-state coupling between an initial thermal state and a dense
and wide manifold of final states, the integral over oscillating terms in Eq. (18.4.19)
converges within a time that is much shorter than the characteristic time of energy
transfer between the donor and the acceptor. (This is in close analogy to our detailed
discussion of charge transfer (Section 18.2) and radiation absorption/emission (Sec￾tion 18.3)). Therefore, the upper time-limit can be replaced by infinity, leading to
Fermi’s golden rule rate,
kD∗→A∗ ∼=
2π
h¯ ∑n,m
e
−εD∗,n
/(kBT)
ZD∗
|JD∗,A∗ |
2
|hχD∗,n|χA∗,mi|2
δ(εD∗,n −εA∗,m). (18.4.20)
A more informative expression is obtained by invoking the infinite time limit
already in Eq. (18.4.18), and using the symmetry of the nuclear correlation function,
[cD∗,QD,QA
(τ)]∗ = cD∗,QD,QA
(−τ) (Ex. 18.4.4), which leads to
kD∗→A∗ =
w∞
−∞
cD∗,QD,QA
(τ)dτ. (18.4.21)
We then notice that the nuclear function in Eq. (18.4.18) factorizes into a product
of two independent dipole correlation functions (Eqs. (18.3.30–18.3.32)) of the two
chromophores (see Ex. 18.4.5),
cD∗,QD,QA
(τ) = 16|JD∗,A∗ |
2h¯
2
|µ
(D)
gr,ex|
2
|µ
(A)
gr,ex|
2
c
(D)
ex (τ)· c
(A)
g (τ). (18.4.22)
Substitution of this result in Eq. (18.4.21), one obtains the following expression for the
energy transfer rate (see Ex. 18.4.6):
kD∗→A∗ =
8|JD∗,A∗ |
2h¯
2
π|µ
(D)
gr,ex|
2
|µ
(A)
gr,ex|
2
w∞
−∞
dΩk
(D)
ex→gr(Ω)k
(A)
gr→ex(Ω), (18.4.23)
where k
(D)
ex→gr(Ω) and k
(A)
gr→ex(Ω) are, respectively, the rate expressions obtained in
Eq. (18.3.37) for radiation emission from the donor, and radiation absorption by the
acceptor. The rate of electronic energy transfer is shown to be proportional to the
spectral overlap between the donor emission and the acceptor absorption spectral
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press388 Thermal Rates in a Bosonic Environment
lines, namely an integral of the rate of emission by the donor multiplied by the rate
of absorption by the acceptor, over all possible frequencies [18.6].
The Förster energy transfer rate is therefore maximized when the emission peak
of the donor coincides with the absorption peak of the acceptor. Recalling that for
any given chromophore the emission peak is (red-)shifted to lower frequencies with
respect to the absorption peak (due to coupling of the electronic transitions to nuclear
modes), the energy transfer rate is optimized when the donor and acceptor are differ￾ent, where the acceptor’s adiabatic excitation energy is smaller than that of the donor
(see Fig. 18.4.2). As we can see, optimal energy transfer rate requires that the excited
donor energy is not fully converted into the electronic excitation of the acceptor, where
the difference is lost into heat production.
Exercise 18.4.2 (This exercise is completely analogous to Ex. 18.2.4 for charge trans￾fer): (a) Use the explicit expressions for the zero-order Hamiltonian (Eq. (18.4.7))
and show that f(Hˆ
0)|D
∗
i = f(HˆD,QD,QA
)|D
∗
i and f(Hˆ
0)|A
∗
i = f(Hˆ
A∗,QD,QA
)|A
∗
i, where
f(Hˆ
0) is an analytic function of the respective operator. (b) Use the results of (a),
the interaction operator (Eq. (18.4.10)), and the definitions of the initial and final
ensembles (Eqs. (18.4.15, 18.4.16)) to derive Eq. (18.4.18) from Eq. (18.4.17). Recall
that the trace over the full electronic and nuclear space can be expressed as tr{Oˆ} =
trQD,QA
{hD
∗
|Oˆ|D
∗
i+hA
∗
|Oˆ|A
∗
i}.
Exercise 18.4.3 (This exercise is completely analogous to Ex. 18.2.4 for charge trans￾fer). Derive Eq. (18.4.19) from Eq. (18.4.18) by evaluating the trace over the nuclear
space using a complete set of eigenstates of the multidimensional Hamiltonian, HˆD∗,QD,QA
,
and an identity operator, expressed in terms of Hˆ
A∗,QD,QA
-eigenstates (Eqs. (18.4.11,
18.4.12)).
Exercise 18.4.4 The dipole–dipole correlation function is defined in Eq. (18.4.18).
Show that c
∗
D∗,QD,QA
(τ) = cD∗,QD,QA
(−τ). Use this result to derive Eq. (18.4.21) from
Eq. (18.4.18), in the limit t → ∞.
Exercise 18.4.5 The dipole–dipole correlation function, cD∗,QD,QA
(τ), is defined in
Eq. (18.4.18). Use the decomposition of HˆD∗,QD,QA
and Hˆ
A∗,QD,QA
in terms of “local”
donor and acceptor modes (Eq. (18.4.8)), and the commutativity of donor-space and
acceptor space operators, namely, [Hˆ
(D)
gr,QD
,Hˆ
(A)
gr,QA
] = [Hˆ
(D)
gr,QD
,Hˆ
(A)
ex,QA
] = [Hˆ
(D)
ex,QD
,Hˆ
(A)
gr,QA
] =
[Hˆ
(D)
ex,QD
,Hˆ
(A)
ex,QA
] = 0, to express cD∗,QD,QA
(τ) in terms of the local dipole correlation
functions, as defined in Eqs. (18.3.30–18.3.32).
Exercise 18.4.6 (a) Use the identity
w∞
−∞
dt f(t)g(t) = w∞
−∞
dΩ
1
√
2π
w∞
−∞
dteiΩt
f(t)
1
√
2π
w∞
−∞
dt0
e
−iΩt
0
g(t
0
)
to express the time-integral over the nuclear correlation function in Eq. (18.4.22) as
an integral over Ω. (b) Derive Eq. (18.4.23) by substitution of the result (a) in
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press389 18.4 Förster Resonant Electronic-Energy (Exciton) Transfer (FRET)
Eq. (18.4.21) and identifying the donor emission rate and the acceptor absorption rate,
as defined in Eq. (18.3.37).
It is instructive to express the energy transfer rate in terms of the spin-boson
model parameters. Using the analogy between charge transfer (Eq. (18.2.26)) and
electronic energy transfer (Eq. (18.4.18)), we obtain the following expression for the
time-dependent energy transfer rate (the analogue of Eq. (18.2.33)):
k
(1)
D∗→A∗ (t) = 2|JD∗,A∗ |
2
h¯
2 Re
wt
0
e
−iτ
h¯
(2∆
(A)
E −2∆
(D)
E
)
e
2i ∑
j∈{ jD, jA}
∆
2
j
sin(ωjτ)
e
−2 ∑
j∈{ jD, jA}
∆
2
j
(1−cos(ωjτ))(1+2n(ωj))
dτ. (18.4.24)
In the limits of low nuclear frequencies, (h¯ωj)
2
kBTEλ
 8π
2
, and weak dipole–dipole inter￾action |JD∗,A∗ |
2
2kBTEλ
 1 (see Eqs. (18.2.44, 18.2.45)), the transfer rate can be approxi￾mated as a constant (Fermi’s golden rule), given by a particularly simple expression
(Ex. 18.4.7),
kD∗→A∗ = |JD∗,A∗ |
2
r π
h
2kBTEλ
e
−(Eλ
−(2∆
(A)
E
−2∆
(D)
E
))2
4kBTEλ . (18.4.25)
The result is perfectly analogous to the Marcus formula for charge transfer
(Eq. (18.2.43)). In the case of energy transfer, the nuclear reorganization energy
includes the contributions from both the donor and acceptor modes (internal as well as
in their local surroundings), Eλ ≡ ∑
j∈{ jD, jA}
2∆
2
jωjh¯ = ∑
j∈{ jD, jA}
h¯ωj
2
(2∆j)
2
, and the “driv￾ing force” is the difference between the adiabatic excitation energies of the donor and
acceptor chromophores, |2∆
(D)
E
| − |2∆
(A)
E
| = (ε
(D)
ex −ε
(D)
gr )−(ε
(A)
ex −ε
(A)
gr ) (recall that by
our convention, ∆
(D)
E
,∆
(A)
E < 0; see Eq. (18.3.11)).
Notice that the Marcus-like formula for the Förster transfer rate (Eq. (18.4.25))
can be derived alternatively by using the low-frequency limit of the donor emission
and acceptor absorption spectral lines (Eq. (18.3.40)) and by calculating the spectral
overlap between them, according to Eq. (18.4.23) (see Ex. 18.4.8). Denoting the local
chromophore reorganization energies E
(D)
λ ≡ ∑
jD
2∆
2
jD
ωjD
h¯ and E
(A)
λ ≡ ∑
jA
2∆
2
jA
ωjA
h¯, and
the adiabatic excitation energies |2∆
(D)
E
| and |2∆
(A)
E
|, the energy transfer rate is maximal
when the overlap between the donor emission and acceptor absorption lines is optimal,
namely, when |2∆
(D)
E
| −E
(D)
λ
∼= |2∆
(A)
E
|+E
(A)
λ
(see Fig. 18.4.2).
Exercise 18.4.7 The golden rule expression for the time-dependent charge trans￾fer rate within the spin-boson model is given by Eq. (18.2.33). Invoking additional
approximations, one obtains the semiclassical golden rule rate (Marcus formula),
Eq. (18.2.43). Use the analogy between Eq. (18.2.33) and Eq. (18.4.24) to derive
Eq. (18.4.25) for the electronic energy transfer rate, within the same set of approxima￾tions.
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press390 Bibliography
Donor
Transition rate
emission
emission
absorption
absorption
Acceptor
(A) (A) (A) (A)
(D) (D) (D) (D)
| 2∆E | −Eλ | 2∆E | +Eλ
| 2∆E | −Eλ | 2∆E | +Eλ
hΩ
Ftigure 18.4.2 Illustration of the spectral lines of two chromophores. The donor emission and the acceptor absorption are presented
as solid lines (the donor absorption and acceptor emission are plotted as dashed lines for completeness). The energy
transfer rate is maximal for a pair of donor and acceptor that are different from each other, with maximal overlap
between the donor emission and the acceptor absorption lines.
Exercise 18.4.8 Use the semiclassical golden rule expressions for the absorption and
emission spectral lines (Eq. (18.3.40)), with the local chromophore reorganization ener￾gies, E
(D)
λ ≡ ∑
jD
2∆
2
jD
ωjD
h¯ and E
(A)
λ ≡ ∑
jA
2∆
2
jA
ωjA
h¯, to derive the Marcus-like formula
for the electronic energy transfer rate (Eq. (18.4.25)) as the spectral overlap integral,
Eq. (18.4.23). Notice that the total reorganization energy includes all the modes of the
donor and the acceptor chromophores, Eλ = E
(D)
λ +E
(A)
λ
.
Bibliography
[18.1] A. J. Leggett, S. Chakravarty, A. T. Dorsey, M. P. A. Fisher, A. Garg, and W.
Zwerger, “Dynamics of the dissipative two-state system,” Reviews of Modern
Physics 59, 1 (1987).
[18.2] V. May and O. Kühn, “Charge and Energy Transfer Dynamics in Molecular
Systems,” 3rd ed. (Wiley, 2011).
[18.3] R. A. Marcus and N. Sutin, “Electron transfers in chemistry and biology,”
Biochimica et Biophysica Acta (BBA)-Reviews on Bioenergetics 811, 265
(1985).
[18.4] E. U. Condon, “Nuclear motions associated with electron transitions in
diatomic molecules,” Physical Review 32, 858 (1928).
[18.5] U. Peskin, Quantum mechanical averaging over fluctuating rates,” Molecular
Physics 110, 729 (2012).
[18.6] T. Förster, “Intermolecular energy migration and fluorescence,” Annals of
Physics 437, 55 (1948).
https://doi.org/10.1017/9781108877787.019 Published online by Cambridge University Press19 Open Quantum Systems
19.1 Exact Reduced System Dynamics
In many cases of interest, measurements performed on a large macroscopic system
are aimed at some well-defined part of it. The relevant part of the full system is often
referred to as “the reduced system.” Imagine, for example, a distinguishable set of
particles of interest embedded in a system of many other particles. The presence of
interaction between the particles of interest and the other particles means that the
system Hamiltonian is nonseparable, hence the particles of interest are generally entan￾gled with the rest, and their exact dynamics is associated with the full (many-particle)
system’s wave function (in the case of a pure state) or a density matrix (in the general
case). However, the measurement aims only at the reduced system, which, in quan￾tum mechanical terms, means that the measurement operator is a trivial identity in the
space of the other particles. Consequently, expectation values of system observables
involve simple averaging with respect to the (accessible) states of the other particles.
Such averaging has a remarkable effect on observables within the reduced system, and
on phenomena such as exchange of energy between the reduced system and its envi￾ronment (including relaxation, effective friction forces, and so forth), and de-coherence
between the system Hamiltonian eigenstates, including disentanglement between par￾ticles. These phenomena are essential to the emergence of classical-like dynamics and
irreversible processes in the system of interest.
Reduced dynamics can be of interest even for noninteracting particles when the mea￾surement involves projection from the full single-particle Hilbert space into a part of it.
For example, local measurements project onto a certain region in the particle’s coor￾dinate space. In such a case, the number of particles within the reduced system (the
projected region of interest) does not need to be conserved, and the reduced system
dynamics can exhibit a wealth of phenomena, such as transport of particles and/or
energy, probability gain or loss, and resonant decay [7.3]. In Chapters 17 and 18 we
already encountered examples of transfer of particles between two quantum states
(e.g., a “donor” and an “acceptor”) within a macroscopic system. These states were
characterized by different subgroups of states projected out of the full system Hilbert
space, where each subgroup corresponded to a reduced system.
Since reduced quantum systems can exchange particles and/or energy with the rest of
“the universe,” they are referred to as open quantum systems. The rest of the universe
is referred to as their environment, or the surrounding. Formally exact equations of
391
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press392 Open Quantum Systems
motion for the open system dynamics can be readily derived, using appropriate projection
operators, as discussed in what follows. It is emphasized that these formal equations
become cumbersome to implement, as they strictly involve the “dynamics of the uni￾verse.” However, in many cases, valid approximations lead to relatively simple closed
equations for the reduced system dynamics. Most relevant in this context is the Marko￾vian approximation, which essentially assumes a timescale separation between the (slow)
environment-induced dynamics within the system, and the (fast) system-induced dynam￾ics within its surroundings. In this section we start from the exact expressions for the
reduced dynamics, and the Markovian approximation is derived in the next sections.
Hilbert Space Projectors
Let us start by considering a generic system Hamiltonian, Hˆ(t), and two projection
operators, Pˆ, and Qˆ, whose sum composes the identity operator in the system’s Hilbert
space:
Pˆ +Qˆ = ˆI ; Pˆ
2 = Pˆ ; Qˆ
2 = Qˆ ; PˆQˆ = 0. (19.1.1)
We are interested in the projection of the exact wave function onto the Pˆ-space, namely
Pˆψ(t), where ψ(t) is an exact solution of the Schrödinger equation,
∂
∂t
|ψ(t)i = −
i
h¯
Hˆ(t)|ψ(t)i. (19.1.2)
Substitution of the projection operators readily yields
∂
∂t
|Pˆψ(t)i = −
i
h¯
PˆHˆ(t)|Pˆψ(t)i − i
h¯
PˆHˆ(t)|Qˆψ(t)i
∂
∂t
|Qˆψ(t)i = −
i
h¯
QˆHˆ(t)|Pˆψ(t)i − i
h¯
QˆHˆ(t)|Qˆψ(t)i
. (19.1.3)
A formal solution to the second equation reads (see Ex. 19.1.1)
|Qˆψ(t)i ≡ UˆQ(t,0)|ψ(0)i − i
h¯
wt
0
dτUˆQ(t, τ)Hˆ(τ)|Pˆψ(τ)i, (19.1.4)
where a Q-space propagator, UˆQ(t, τ), is defined here by the differential equation
∂
∂t
UˆQ(t, τ) = −
i
h¯
QˆHˆ(t)QˆUˆQ(t, τ) ; UˆQ(t,t) ≡ Qˆ. (19.1.5)
When the initial state is confined to the Pˆ space, we have |Qˆψ(0)i = 0, and therefore,
∂
∂t
|Pˆψ(t)i = −
i
h¯
PˆHˆ(t)|Pˆψ(t)i − 1
h¯
2
wt
0
dτPˆHˆ(t)UˆQ(t, τ)Hˆ(τ)|Pˆψ(τ)i. (19.1.6)
For a time-independent Hamiltonian, the time-evolution operator, UˆQ(t, τ), obtains
the standard exponential form, UˆQ(t, τ) = Qeˆ
−i(t−τ)
h¯
QˆHˆ Qˆ
(see Eq. (15.2.11)), which leads
to the explicit equation for the reduced space wave function, |Pˆψ(t)i:
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press393 19.1 Exact Reduced System Dynamics
∂
∂t
|Pˆψ(t)i = −
i
h¯
PˆHˆ Pˆ|Pˆψ(t)i − 1
h¯
2
wt
0
dτPˆHˆ Qeˆ
−i(t−τ)
h¯
QˆHˆ Qˆ
QˆHˆ Pˆ|Pˆψ(τ)i. (19.1.7)
Transforming the Pˆ-space wave function to the interaction picture representation
(Eq. 15.3.7),
|PˆψI(t)i ≡ e
it
h¯
PˆHˆ Pˆ
|Pˆψ(t)i, (19.1.8)
the transformed equation reads
∂
∂t
|PˆψI(t)i = −
1
h¯
2
wt
0
dτe
it
h¯
PˆHˆ Pˆ
PˆHˆ Qeˆ
−i(t−τ)
h¯
QˆHˆ Qˆ
QˆHˆ Peˆ
−iτ
h¯
PˆHˆ Pˆ
|PˆψI(τ)i. (19.1.9)
As we can see, the projection of the full system wave function onto a part of the Hilbert
space (|PˆψI(t)i) is a solution of a homogeneous integrodifferential equation. When
the initial state is not confined to the Pˆ space, the equation obtains an additional
inhomogeneous term (Ex. 19.1.2),
∂
∂t
|PˆψI(t)i+
1
h¯
2
wt
0
dτe
it
h¯
PˆHˆ Pˆ
PˆHˆ Qeˆ
−i(t−τ)
h¯
QˆHˆ Qˆ
QˆHˆ Peˆ
−iτ
h¯
PˆHˆ Pˆ
|PˆψI(τ)i
= −
i
h¯
e
it
h¯
PˆHˆ Pˆ
PˆHˆ Qeˆ
−it
h¯
QˆHˆ Qˆ
|Qˆψ(0)i. (19.1.10)
Eqs. (19.1.9, 19.1.10) are exact reformulations of the Schrödinger equation, but
generally are not particularly useful. The need to follow the evolution of each past
state (|PˆψI(τ)i ; 0 ≤ τ ≤ t) under the Qˆ space Hamiltonian at any time, t, is usually
highly involved and does not have a particular advantage in comparison to solving the
Schrödinger equation in the full space and projecting the final result onto the Pˆ-space.
Exercise 19.1.1 Use the identity ∂
∂t
rt
0
f(t,t
0
)dt0 =
rt
0
∂
∂t
f(t,t
0
)dt0 + f(t,t) to show that the
expression in Eq. (19.1.4) for the Q-space projection, |Qˆψ(t)i, is indeed a solution to its
defining equation, Eq. (19.1.3).
Exercise 19.1.2 Show that in the general case, where |Qˆψ(0)i 6= 0, substitution of
Eq. (19.1.4) in Eq. (19.1.3) results in an additional inhomogeneous term in the equa￾tion for the P-space projection. Show that for a time-independent Hamiltonian, the
corresponding inhomogeneous equation in the interaction picture is Eq. (19.1.10).
Liouville Space Projectors
The derivation of an equation for a reduced system dynamics in terms of projection
operators is readily applicable also within Liouville’s space. Recalling the Liouville–von
Neumann equation (Eq. (16.4.3)) for the full density operator,
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press394 Open Quantum Systems
∂
∂t
ρˆ(t) = −
i
h¯
Lˆ(t)ρˆ(t) ; Lˆ(t)ρˆ(t) = [Hˆ(t),ρˆ(t)], (19.1.11)
and defining generic projection operators in Liouville’s space, Pˆ
L and Qˆ
L,
Pˆ
L +Qˆ
L = ˆIL ; Pˆ
2
L = Pˆ
L ; Qˆ
2
L = Qˆ
L ; Qˆ
LPˆ
L = 0, (19.1.12)
we are interested in following the dynamics of the reduced system density operator,
defined as ρˆP(t) ≡ Pˆ
Lρˆ(t). Since Liouville’s space is also a Hilbert space (see Sec￾tion 16.3), an exact equation for ρˆP(t) is obtained by following the steps outlined in
Eqs. (19.1.3–19.1.7).Indeed, replacing the system Hilbert space vector, |ψ(t)i, by Liou￾ville’s space vector, ρˆ(t), the system Hamiltonian, Hˆ, by the Liouville operator, Lˆ, and
the Hilbert space projectors by the Liouville space projectors, the exact result (for a
time-independent Hamiltonian) reads (Ex. 19.1.3)
∂
∂t
Pˆ
Lρˆ(t) = −
i
h¯
Pˆ
LLˆPˆ
Lρˆ(t)−
1
h¯
2
wt
0
dτPˆ
LLˆQˆ
Le
−iτ
h¯
Qˆ
LLˆQˆ
LQˆ
LLˆPˆ
Lρˆ(t −τ), (19.1.13)
which is analogous to Eq. (19.1.7) for a time-independent Hamiltonian. Transforming
to an interaction picture,
ρˆ
(I)
P
(t) ≡ e
it
h¯
Pˆ
LLˆPˆ
LPˆ
Lρˆ(t), (19.1.14)
we readily obtain (Ex. 19.1.3)
∂
∂t
ρˆ
(I)
P
(t) = −
1
h¯
2
wt
0
dτe
it
h¯
Pˆ
LLˆPˆ
LPˆ
LLˆQˆ
Le
−i(t−τ)
h¯
Qˆ
LLˆQˆ
LQˆ
LLˆPˆ
Le
−iτ
h¯
Pˆ
LLˆPˆ
L ρˆ
(I)
P
(τ), (19.1.15)
which is the Liouville space analogue of Eq. (19.1.9). The result is a homogeneous
integrodifferential equation, where the time derivative of the reduced density operator
ρˆ
(I)
P
(t) depends on its past evolution starting at earlier times, ρˆ
(I)
P
(τ), which is generally
too cumbersome to follow. Notice that when the initial state is not confined to the Pˆ
L
space, the equation obtains an additional inhomogeneous term [19.1], by analogy to
Eq. (19.1.10) (Ex. 19.1.3):
∂
∂t
ρˆ
(I)
P
(t) + 1
h¯
2
wt
0
dτe
it
h¯
Pˆ
LLˆPˆ
LPˆ
LLˆQˆ
Le
−i(t−τ)
h¯
Qˆ
LLˆQˆ
LQˆ
LLˆPˆ
Le
−iτ
h¯
Pˆ
LLˆPˆ
L ρˆ
(I)
P
(τ)
= −
i
h¯
e
it
h¯
Pˆ
LLˆPˆ
LPˆ
LLˆQˆ
Le
−it
h¯
Qˆ
LLˆQˆ
LQˆ
Lρˆ(0). (19.1.16)
Exercise 19.1.3 (a) Start from the defining equations for the projected density oper￾ator, ∂
∂t
Pˆ
Lρˆ(t) = −
i
h¯
Pˆ
LLˆ(t)Pˆ
Lρˆ(t) −
i
h¯
Pˆ
LLˆ(t)Qˆ
Lρˆ(t);
∂
∂t Qˆ
Lρˆ(t) = −
i
h¯
Qˆ
LLˆ(t)Qˆ
Lρˆ(t) −
i
h¯
Qˆ
LLˆ(t)Pˆ
Lρˆ(t), and use the analogy to the derivation of Eq. (19.1.7), to derive
Eq. (19.1.13) for time-independent Hamiltonians, when Qˆ
Lρˆ(0) = 0. (b) Use
Eq. (19.1.14) to derive Eq. (19.1.15) from Eq. (19.1.13). (c) Show that in the general
case, where Qˆ
Lρˆ(0) 6= 0, the inhomogeneous equation for the P-space projected density
operator in the interaction picture is Eq. (19.1.16) (follow the analogy to Ex. 19.1.2).
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press395 19.2 The Born–Markov Approximation in the System Hilbert Space
19.2 The Born–Markov Approximation in the System Hilbert Space
To follow exactly the system dynamics in a reduced Hilbert space, we must account
continuously for the evolution of the reduced system states at past times, {|PˆψI(τ)i},
under the Qˆ-space Hamiltonian (see Eqs. (19.1.9, 19.1.10)). The equation of motion
for the reduced system wave function can be simplified significantly, if “past states” are
replaced by the “present state,” namely |PˆψI(τ)i is replaced by |PˆψI(t)i, for any past
time, 0 ≤ τ ≤ t. Implementing this in Eq. (19.1.9) (restricting hereafter to |Qˆψ(0)i = 0)
leads to the approximation
∂
∂t
|PˆψI(t)i ∼= −
1
h¯
2
wt
0
dτe
it
h¯
PˆHˆ Pˆ
PˆHˆ Qeˆ
−i(t−τ)
h¯
QˆHˆ Qˆ
QˆHˆ Peˆ
−iτ
h¯
PˆHˆ Pˆ
|PˆψI(t)i. (19.2.1)
The “loss of memory” associated with this approximation characterizes Markov pro￾cesses in which the future evolution of a system does depend on its past history. Notice
that Eq. (19.2.1) still requires the backward time evolution of |PˆψI(t)i within the Qˆ￾space, owing to the interaction between the Pˆ and Qˆ subspaces, QˆHˆ Pˆ. However, unlike
in the exact expression, this operation is carried out independently, and only once per
each time t, as in a reset process. As one can suspect, this simplicity is valid only when
the coupling between the Pˆ and Qˆ subspaces is sufficiently weak. Indeed, returning to
the exact formulation (Eq. (19.1.9)) and using repeatedly the trivial relation between
|PˆψI(τ)i and |PˆψI(t)i, namely |PˆψI(τ)i = |PˆψI(t)i − rt
τ
dt0 ∂
∂t
0
|PˆψI(t
0
)i, the approxima￾tion, Eq. (19.2.1), is shown to be the lowest-order term of an infinite series expansion of
the exact equation in powers of the coupling operators, QˆHˆ Pˆ and PˆHˆ Qˆ (Ex. 19.2.1):
∂
∂t
|PˆψI(t)i = −


wt
0
dτKˆ(t, τ)

ˆI +
wt
τ
dτ
0
τ
0
w
0
dτ
00Kˆ(τ
0
, τ
00)
×

ˆI +
wt
τ
00
dτ
000
τ
000
w
0
dτ
0000
Kˆ(τ
000
, τ
0000)[ˆI +···]





|PˆψI(t)i
Kˆ(t, τ) ≡
1
h¯
2
e
it
h¯
PˆHˆ Pˆ
PˆHˆ Qeˆ
−i(t−τ)
h¯
QˆHˆ Qˆ
QˆHˆ Peˆ
−iτ
h¯
PˆHˆ Pˆ
. (19.2.2)
The truncation of the infinite series at the first order in Kˆ(t, τ) (namely, second order
in the coupling between the Pˆ and Qˆ subspaces) is reminiscent of the Born approxima￾tion in quantum scattering theory [7.1], and the first-order result (Eq. (19.2.1)) is often
referred to as the Born–Markov approximation.
Exercise 19.2.1 (a) Given the definition of the Kernel Kˆ(t, τ) in Eq. (19.2.2), show
that the exact equation for the projected state |PˆψI(t)i, Eq. (19.1.9), reads ∂
∂t
|PˆψI(t)i =
−
rt
0
dτKˆ(t, τ)|PˆψI(τ)i. (b) Derive the infinite series expansion in Eq. (19.2.2) by recur￾sive application of the formal relation, PˆψI(τ) = PˆψI(t)−
rt
τ
dt0 ∂
∂t
0 PˆψI(t
0
).
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press396 Open Quantum Systems
Irreversible Dynamics and Exponential Decay
As an example of reduced Hilbert space dynamics, and for assessing the validity of the
Markovian approximation within an exactly solvable model, let us consider the dynam￾ics of a single state within a system of finite dimensions. When the state of interest is an
eigenstate of some zero-order Hamiltonian, following its dynamics is closely related to
following the probability amplitudes of transition to the other eigenstates. The latter
was discussed extensively in Chapter 17, where we analyzed the conditions in which the
total transition probability is associated with a well-defined rate constant, for exam￾ple, ∂
∂t
Pi(t)|t<<1/ki→{ f }
≈ −ki→{ f }
. Here we adopt a complementary view, by following
the survival probability of a single state coupled to a manifold of other orthonormal
states. As we shall see, when the Markovian approximation becomes valid, the survival
probability follows an exponential decay in time, ∂
∂t
Pi(t) = −ki→{ f }Pi(t), at a rate which
reproduces Fermi’s Golden rule. Indeed, the result is consistent with Eq. (17.2.2), which
identifies the decay rate constant with the initial time derivative of Pi(t), and moreover,
it implies that under certain conditions a quantum transition can become “irreversible”
or “unidirectional” also in the long time-limit of the kinetics.
We start from the most general form of a discrete Hermitian model Hamiltonian,
Hˆ ≡
N
∑
j=0
Hj, j
|φjihφj
|+
N
∑
j>j
0=0
{Hj, j
0|φjihφj
0|+h.c.}, (19.2.3)
where {|φji}, j = 0,1,2,...,N, are orthonormal basis vectors, hφj
0|φji = δ j, j
0 ,
corresponding to the eigenstates of some zero-order Hamiltonian (notice that
{Aˆ +h.c.} ≡ {Aˆ +Aˆ†}). We are interested in the time evolution under Hˆ, of one of these
basis states, denoted as |φ0i. For this purpose, let us introduce a projection operator
into the space of the initial state |φ0i, Pˆ = |φ0ihφ0|, and a complementary projector,
Qˆ = ˆI − Pˆ =
N
∑
j=1
|φjihφj
|. We can then rewrite the full Hamiltonian as Hˆ = Hˆ
0 +Vˆ ,
where Hˆ
0 ≡ PˆHˆ Pˆ +QˆHˆ Qˆ and Vˆ ≡ {QˆHˆ Pˆ +h.c.}. Denoting the eigenstates of this Hˆ
0 as
{|χ0i,|χ1i,|χ2i,...,|χNi} and using them as an alternative basis, the full Hamiltonian
is rewritten in the form (see Fig. 19.2.1 and Ex. 19.2.2),
Hˆ = Hˆ
0 +Vˆ
Hˆ
0 = ε0|χ0ihχ0|+
N
∑
f=1
ε f
|χfihχf
|
Vˆ =
N
∑
f=1
(V0, f
|χ0ihχf
|+h.c.). (19.2.4)
Notice that Hˆ
0 is in general different than the original zero-order Hamiltonian, whose
eigenvectors are {|φ0i,|φ1i,...,|φNi}. However, the selected initial state, |φ0i is, by
construction, an eigenvector also of Hˆ
0, namely
|χ0i = |φ0i. (19.2.5)
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press397 19.2 The Born–Markov Approximation in the System Hilbert Space
ϕ0
ϕ1
ϕ2
ϕ3
ϕ4
χ0
χ1
χ2
χ3
χ4
H0,0 H0,1 H0,2 H0,3 H0,N
H1,1 H1,2 H1,3 H1,N
H2,1 H2,2 H2,3 H2,N
H3,1 H3,2 H3,3 H3,N
HN,1 HN,2 HN,3 HN,N
H1,0
H2,0
H3,0
.
.
.
HN,0
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
V0,1
V1,0
V2,0
V3,0
VN,0
ε 0
ε 1 0
(a) (b)
0 0
0 ε 2 0 0
0 0 ε 3 0
0 0 0 ε N
V0,2 V0,3 V0,N
Ftigure 19.2.1 A schematic representation of the model Hamiltonian in an arbitrary orthonormal basis (a), and in a basis in which the
zero-order Hamiltonian (Hˆ
0 ≡ PˆHˆ Pˆ +QˆHˆ Qˆ)is diagonal (b). (For a concrete example, see Section 20.4,
Fig.20.4.1.)
The other eigenstates of Hˆ
0,{|χfi}, f = 1,2,...,N are the eigenstates of QˆHˆ Qˆ (see
Ex. 19.2.2), which are orthogonal to each other as well as to the initial state, |χ0i.
Exercise 19.2.2 Use the decomposition of the Hamiltonian in Eq. (19.2.3) in terms
of the projection operators, Hˆ = PˆHˆ Pˆ + QˆHˆ Qˆ + PˆHˆ Qˆ + QˆHˆ Pˆ, where Pˆ = |φ0ihφ0|, and
Qˆ = ˆI − Pˆ =
N
∑
j=1
|φjihφj
|. Denote the eigenstates of PˆHˆ Pˆ and QˆHˆ Qˆ as |χ0i and {|χfi},
respectively, to derive Eq. (19.2.4).
The exact time evolution of the system under the full Hamiltonian, Eq. (19.2.4), is
given by the Schrödinger equation, ih¯
∂
∂t
|ψ(t)i = Hˆ|ψ(t)i. It is convenient to transform
to the interaction picture representation (Eqs. (15.3.7, 15.3.8)), where
|ψI(t)i = e
iHˆ
0t
h¯ |ψ(t)i ; ih¯
∂
∂t
|ψI(t)i = e
iHˆ
0t
h¯ Vˆ e
−iHˆ
0t
h¯ |ψI(t)i. (19.2.6)
We are interested in the reduced Pˆ-space dynamics, which in the present example
amounts to |χ0ihχ0|ψI(t)i ≡ c0(t)|χ0i. An exact equation for ∂
∂t
c0(t) can be obtained
directly by implementing the general result, Eq. (19.1.9), for the Hamiltonian in
Eq. (19.2.4), with the projection operators, Pˆ = |χ0ihχ0| and Qˆ =
N
∑
f=1
|χfihχf
| (see
Ex. 19.2.3). Alternatively, we can use the complete basis of Hˆ
0 eigenvectors to expand
the state of the system at any time:
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press398 Open Quantum Systems
|ψI(t)i ≡ c0(t)|χ0i+
N
∑
f=1
cf(t)|χfi. (19.2.7)
Substitution of this expansion in Eq. (19.2.6) and projecting onto the different basis
vectors yields (see Ex. 19.2.4)
∂
∂t
c0(t) = 1
ih¯
N
∑
f=1
V0, f e
−i(ε f −ε0
)t
h¯ cf(t) ;
∂
∂t
c f(t) = 1
ih¯
V
∗
0, f
e
i(ε f −ε0
)t
h¯ c0(t) (19.2.8)
For the selected initial condition, |ψI(0)i ≡ |χ0i, we have, c0(0) = 1, and cf(0) = 0.
Integrating the equation for cf(t), we obtain (Ex. 19.2.4)
∂
∂t
c0(t) = −
1
h¯
2
N
∑
f=1
|V0, f
|
2
wt
0
dτe
−i(ε f −ε0
)(t−τ)
h¯ c0(τ). (19.2.9)
Exercise 19.2.3 Derive Eq. (19.2.9) by implementing Eq. (19.1.9) for the Pˆ-space pro￾jection, |PˆψI(t)i, with the Hamiltonian in Eq. (19.2.4), and the projection operators,
Pˆ = |χ0ihχ0| and Qˆ =
N
∑
f=1
|χfihχf
|.
Exercise 19.2.4 (a) Substitute the expansion of |ψI(t)i (Eq. (19.2.7)) in the
Schrödinger equation (Eq. (19.2.6)), and project on the eigenstates of Hˆ
0, to obtain the
coupled equations for the expansion coefficients, Eq. (19.2.8). ( b) lntegrate Eq. (19.2.8)
over time for the initial condition, c0(0) = 1 and {cf(0) = 0}, to obtain Eq. (19.2.9).
The survival probability at time t is the probability of occupying the initial state (see
Eq. (15.1.29)),
P0(t) = |hχ0|ψ(t)i|2 = |hχ0|ψI(t)i|2 = |c0(t)|
2
. (19.2.10)
The rate of change of the survival probability reads
∂
∂t
P0(t) = 2 Re[c
∗
0
(t)
∂
∂t
c0(t)], (19.2.11)
which can be expressed exactly, using Eq. (19.2.9):
∂
∂t
P0(t) = −
2
h¯
2
Re"
wt
0
dτ
N
∑
f=1
|V0, f
|
2
e
−i(ε f −ε0
)(t−τ)
h¯ c
∗
0
(t)c0(τ)
#
. (19.2.12)
As we can see, in the absence of coupling between the initial state and the other
Hˆ
0-eigenstates ({V0, f } = 0), the survival probability remains unity at all times. This
case corresponds to |χ0i being a stationary state of the system (an eigenvector of
the full Hamiltonian). In any other case, however, P0(t) changes in time, where the
rate of change at time t depends explicitly on the “history” of the survival probability
amplitude, c0(τ), at 0 ≤ τ ≤ t.
We now invoke a Markovian approximation (see Eq. (19.2.1) for the general
case). Ignoring the “history,” c0(τ) is replaced by c0(t) under the time integral in
Eq. (19.2.12), which yields a simple kinetic equation:
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press399 19.2 The Born–Markov Approximation in the System Hilbert Space
∂
∂t
P0(t) ∼= −k0→{ f }
(t)P0(t). (19.2.13)
The time-dependent rate coefficient reads
k0→{ f }
(t) = 2
h¯
2
Re"
wt
0
dτη(t, τ)
#
; η(t, τ) ≡
N
∑
f=1
|V0, f
|
2
e
−i(ε f −ε0
)(t−τ)
h¯ , (19.2.14)
where η(t, τ) can be identified (Ex. 19.2.5) as the time correlation function of the
interaction, η(t, τ) = tr{e
iHˆ
0(t−τ)
h¯ PˆVˆ Qeˆ
−iHˆ
0(t−τ)
h¯ QˆVˆ Pˆ}.
Exercise 19.2.5 Use the definition of the operators Hˆ
0 and Vˆ in Eq. (19.2.4), and the
projection operators, Pˆ = |χ0ihχ0|,Qˆ =
N
∑
f=1
|χfihχf
|, to show that the kernel, η(t, τ), as
defined in Eq. (19.2.14) can be written as tr{e
iHˆ
0(t−τ)
h¯ PˆVˆ Qeˆ
−iHˆ
0(t−τ)
h¯ QˆVˆ Pˆ}.
The validity of this Markovian approximation clearly depends on the properties of
the exact time integral in Eq. (19.2.12). More precisely, the approximation is justified
as long as η(t, τ) is strongly peaked around τ ≈ t and decays to zero as a function
of τ much faster than changes in the amplitude, c0(τ) . Moreover, a rapid decay of
the integrand justifies replacement of the upper limit of the time integral by infinity,
which implies that (except for an initial transient) a time-independent “rate constant”
is obtained. Eq. (19.2.14) is then replaced by
k0→{ f }
∼=
2
h¯
2
Re"
w∞
0
dτ
N
∑
f=1
|V0, f
|
2
e
−i(ε f −ε0
)τ
h¯
#
, (19.2.15)
where the survival probability decays exponentially (see Eq. (19.2.13)),
∂
∂t
P0(t) ∼= −k0→{ f }P0(t) ; P0(t) ∼= e
−k0→{ f }
t
. (19.2.16)
The expression for the decay rate constant (Eq. (19.2.15)) coincides with Fermi’s golden
rule result (see Eq. (17.2.7)) for the short-time rate of probability transfer from a pure
state to an ensemble of final states (see Eq. (17.2.7)):
k0→{ f } =
2π
h¯
N
∑
f=1
|V0, f
|
2
δ(ε0 −ε f). (19.2.17)
This is naturally expected, since the short-time decay rate of the initial state population
is identical to the rate of transition into all possible final states, as calculated by Fermi’s
golden rule (see Section 17.2). Importantly, the coincidence of these two approximated
calculations suggests that the validity of the Markovian approximation (Eqs. (19.2.15–
19.2.17)) is subject to the same limitations on the validity of Fermi’s golden rule. The
time integrand in the exact equation for the survival probability (Eq. (19.2.12)), is
a multiplication of η(t, τ) by c0(τ)c
∗
0
(t). The real part of similar functions to η(t, τ)
was already analyzed in detail in Section 17.2. We recall that the oscillating contribu￾tions interfere constructively as τ → t; but in the weak coupling and wide band limits,
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press400 Open Quantum Systems
dephasing at longer times (τ) leads to cancellation of contributions with opposite signs
and to a decay toward zero. Notice that similar considerations apply here, although
η(t, τ) in Eq. (19.2.12) is multiplied by the complex factor, c0(τ)c
∗
0
(t) . Roughly, as long
as the amplitude, c0(τ), deviates significantly from c0(t) only after Re[η(t, τ)] decays to
zero, c0(τ)c
∗
0
(t) can be replaced by the real-valued probability, |c0(t)|
2
, which justifies
the result, Eq. (19.2.13).
We can readily verify that the Markovian approximation for the survival probability
is consistent with a weak coupling limit by considering the exact expansion of ∂
∂t
c0(t)in
powers of the interaction matrix elements {|V0, f
|
2}. Implementing the general formula,
Eq. (19.2.2), for the model Hamiltonian defined by Eq. (19.2.4), with the projectors,
Pˆ = |χ0ihχ0| and Qˆ =
N
∑
f=1
|χfihχf
|, the exact equation is reformulated as (Ex. 19.2.6)
∂
∂t
c0(t) = −


wt
0
dτη(t, τ)

ˆI +
wt
τ
dτ
0
τ
0
w
0
dτ
00η(τ
0
, τ
00)
×

ˆI +
wt
τ
00
dτ
000
τ
000
w
0
dτ
0000
η(τ
000
, τ
0000)[ˆI +···]





c0(t). (19.2.18)
The Markovian approximation, Eqs. (19.2.13, 19.2.14), therefore corresponds to
the first-order term in powers of the interaction correlation function, η(t, τ) =
∑f
|V0, f
|
2
e
−i(t−τ)
h¯
(ε f −ε0)
, namely in powers of the squared coupling matrix elements (a
Born–Markov approximation).
Exercise 19.2.6 Derive Eq. (19.2.18) by implementing the general kernel formula
(Eq. (19.2.2)) for the model Hamiltonian defined by Eq. (19.2.4), with the projectors,
Pˆ = |χ0ihχ0| and Qˆ =
N
∑
f=1
|χfihχf
|.
When the manifold of Hˆ
0 eigenstates coupled to the initial state is sufficiently dense
on the energy scale of the coupling matrix elements, the latter can be associated with a
continuous function of the final state energy, |V0, f
|
2 = λ
2
0, f
(ε f), and with a respective
spectral density function (see Eq. 17.2.10), J0, f(ε) ≡ 2πλ
2
0, f
(ε)ρf(ε). The interaction
correlation function η(t, τ) is then related to the Fourier transform of the spectral
density,
η(t, τ) = 1
2π
w
dεJ0, f(ε)e
−i(ε−ε0
)(t−τ)
h¯ . (19.2.19)
Invoking, for example, a finite and uniform band model, where J0, f(ε) ≡ Jb in the range
|ε| ≤ εb, and zero otherwise (see Eq. (17.2.14)), the time-dependent derivative of the
survival probability (Eq. (19.2.12)) reads (Ex. 19.2.7)
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press401 19.2 The Born–Markov Approximation in the System Hilbert Space
∂
∂t
P0(t) = −2Jbεb
πh¯
2
Rewt
0
dτe
iε0τ
h¯
sin(εbτ/h¯)
εbτ/h¯
c
∗
0
(t)c0(t −τ). (19.2.20)
As we can see, when the bandwidth is taken to infinity, εb → ∞, the conditions for validity
of the Markovian approximation are automatically satisfied. Indeed, performing the
time integral, we obtain the Markovian result with no approximation in this infinite
wide band limit (Ex. 19.2.7),
∂
∂t
Pi(t) = −
Jb
h¯
Pi(t), (19.2.21)
where the decay rate is identified as the (constant) spectral density, divided by h¯.
Exercise 19.2.7 (a) In the continuous band limit, we have
N
∑
f=1
|V0, f
|
2
e
−i(ε f −ε0
)(t−τ)
h¯ →
1
2π
r
dεJ0, f(ε)e
−i(ε−ε0
)(t−τ)
h¯ . Show that for J0, f(ε) ≡ Jb in the range |ε| ≤ εb, and J0, f(ε) ≡
0 otherwise, the exact equation for the survival probability, Eq. (19.2.12), yields
Eq. (19.2.20). (b) Show that in the limit εb → ∞, the decay of the survival probability
becomes exponential (Eq. (19.2.21)).
Having established the conditions for an exponential decay of the initial survival
probability, it is instructive to consider also the “fate” of the decaying state within the
manifold of Hˆ
0 eigenstates. Using Eq. (19.2.8) with the initial condition, {c f(0) = 0},
ci(0) = 1, the probability amplitude for populating the fth eigenstate (|χfi) reads
cf(t) =
V
∗
0, f
ih¯
wt
0
dt
0
e
i(ε f −ε0
)t
0
h¯ c0(t
0
). (19.2.22)
Assuming that the validity conditions for the Markovian approximation hold, the exact
equation for c0(t) (Eq. (19.2.9)) can be approximated as
∂
∂t
c0(t) ∼= −
w∞
0
dτ
N
∑
f=1
|V0, f
|
2
h¯
2
e
−i(ε f −ε0 )τ
h¯ c0(t). (19.2.23)
Noticing that the real part of r∞
0
dτ
N
∑
f=1
|V0, f
|
2
h¯
2 e
−i(ε f −ε0
)τ
h¯ equals half the exponential decay
rate, k0→{ f }
(see Eq. (19.2.15)), and denoting the corresponding imaginary part as
Imr∞
0
dτ
N
∑
f=1
|V0, f
|
2
h¯
2 e
−i(ε f −ε0
)τ
h¯ ≡
∆
h¯
, we obtain ∂
∂t
c0(t) ∼= −

k0→{ f }
2 +i
∆
h¯

c0(t), and therefore
c0(t) ∼= e
−k
0→{ f }
t
2 e
−i
∆t
h¯ . (19.2.24)
Substitution in Eq. (19.2.22) yields (Ex. 19.2.8)
|cf(t)|
2 −−−−−−−−→ t>>1/k0→{ f }
|V0, f
|
2
(ε f −(ε0 +∆))2 + (hk¯ 0→{ f }
)
2/4
. (19.2.25)
As we can see, when the decay of the initial state is complete, t>e1/k0→{ f }
, the other
Hˆ
0 eigenstates are populated according to their energy in a Lorenzian-like distribution
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press402 Open Quantum Systems
(assuming weak dependence of the state-to-state coupling on the final state), whose
width and center correspond, respectively, to the decay rate (∆ε f ∼ hk¯ 0→{ f }
) and a dis￾placed initial state energy, ε f ≈ ε0 + ∆. It is interesting to notice that the distribution
of the population over a finite range of final state energies is in apparent contradic￾tion with Fermi’s golden rule rate expression, Eq. (19.2.17), which seems to impose
strict energy conservation between the initial and final states. Indeed, the strict energy
conservation and the finite lifetime of the initial population (τi = 1/ki→{ f }
) seem to
violate a “time–energy uncertainty” relation. This uncertainty is encoded, however,
in the broadening of the final state distribution, Eq. (19.2.25), where ∆ε f τi ∼ h¯. The
effect of this broadening on the decay process itself is indeed missing in the Markovian
approximation (in the second order in the coupling). It is accounted for in the higher
orders of the expansion, Eq. (19.2.18).
Exercise 19.2.8 Use Eqs. (19.2.22, 19.2.24) to show that |c f(t)|
2 ∼=
|V0, f
|
2
(ε f −(ε0+∆))2+(hk¯ 0→{ f })
2/4
(1−2e
−k0→{ f }
t/2
cos[(ε f −(ε0 +∆))t/h¯] +e
−k0→{ f }
t
).
We end this section by noting that an exponential decay of the survival probabil￾ity means that the decay process continues irreversibly. This is strictly true only in the
absence of revivals of the interaction correlation function (η(t, τ)), which characterize
idealized models of decay into continuous wide bands. Nevertheless, exponential decay
phenomena are commonly encountered in the real world in processes such as spontane￾ous emission of radiation (see Section 19.5), radioactive decay, atomic autoionization,
and many more. A practical observation of exponential decay implies that revivals
may occur only at times much longer than the relevant kinetics timescale, namely at
t >> 1/ki→{ f }
. This condition can be met in principle when the reduced system of
interest (defined by the projector Pˆ) is much “smaller” than the rest of the “universe,”
associated with the projector Qˆ (in its phase space volume, in classical terms). In other
cases, when the Pˆ and the Qˆ spaces are of “comparable size,” revivals become ubiq￾uitous. Even in such cases, rapid relaxation of coherences within each space may still
justify a Markovian approximation, which leads to kinetic equations for population
transfer (master equations) instead of a unidirectional exponential decay.
19.3 The Born–Markov Approximation in Liouville Space
Reduced system dynamics is of interest in many cases. Consider the generic situation
in which a “small” quantum system, typically associated with a finite number of par￾ticles and/or a finite number of degrees of freedom, interacts with a macroscopically
large environment. In the context of nanoscale phenomena, such a system can be, for
example, an atom, molecule, nanocrystal, or a defect (impurity), embedded in and
interacting with a condensed phase environment, such as a solution, a solid crystal, a
surface, and so on. Being interested in the small system, the detailed information with
respect to the surroundings is in most cases not of prime interest and/or accessible to
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press403 19.3 The Born–Markov Approximation in Liouville Space
the measurement. Nevertheless, the interaction between the small system and its envi￾ronment may have remarkable effects on the dynamics within the small system and
hence on system observables. We are therefore often interested in the reduced system
dynamics, in the presence of coupling to the environment. Since the latter is typically
“thermodynamically large,” it can be regarded as a reservoir (or a “bath”) of energy
and/or particles, characterized by its intensive (ensemble-averaged) properties, such
as temperature, chemical potentials, and so on. Since the macroscopic environment
is then associated with an incoherent ensemble, the most suitable framework for fol￾lowing the dynamics is Liouville’s equation (see Section 16.4), where the state of the
system in its environment is characterized by a density operator.
The exact dynamics of the reduced system of interest involves time evolution of past
states of the reduced system under the complementary Hamiltonian (see Eq. (19.1.15)).
Since the latter is typically associated with a macroscopically large number of
degrees of freedom, it is practically intractable. Therefore, it is desirable to identify
instead an effective Markovian Liouville equation, which corresponds to a time￾local dynamical map within the space of reduced system density operators, namely
∂
∂t
Pˆ
Lρˆ(t) = −
i
h¯
Lˆ
e f f(t)Pˆ
Lρˆ(t). Such an equation indeed exists, where the effective
(reduced space) Liouville operator obtains a generic Lindblad form, which guarantees
that the dynamical map from Pˆ
Lρˆ(0) to Pˆ
Lρˆ(t) preserves nonnegativity of the system
Hamiltonian eigenstate populations (complete positivity), and their accumulation to
unity (trace preservation). The interested reader is referred to more specialized text￾books for the derivation of the general Lindblad form of the reduced Liouville operator
(“the dissipator”) [19.2]. Importantly, evaluating the exact reduced Liouville operator
for a given Hamiltonian is a highly involved task, in general, unrealistic in most cases.
Nevertheless, effective Markovian dissipators, cast into a generic Lindblad form, are
often introduced phenomenologically to model reduced system dynamics. Moreover,
as discussed in what follows, approximated Markovian dissipators can be rigorously
derived from full Hamiltonian (Liouville space) dynamics by invoking several assump￾tions on the system–bath coupling. These approximations correspond essentially to
scenarios in which there is a timescale separation between “fast” relaxation of system￾induced perturbations to the bath, and “slow” bath-induced dynamics within the
system.
Let us start from the exact equation for the dynamics of the reduced density operator
(Eqs. (19.1.14, 19.1.15), where we shall restrict the discussion to Qˆ
Lρˆ(0) = 0). Replacing
the “past” reduced density operator ρˆ
(I)
P
(τ) by its “present” form, ρˆ
(I)
P
(t), for any time,
0 ≤ τ ≤ t, we obtain a Born–Markov approximation:
∂
∂t
ρˆ
(I)
P
(t) ∼= −
1
h¯
2
wt
0
dτe
it
h¯
Pˆ
LLˆPˆ
LPˆ
LLˆQˆ
Le
−i(t−τ)
h¯
Qˆ
LLˆQˆ
LQˆ
LLˆPˆ
Le
−iτ
h¯
Pˆ
LLˆPˆ
L ρˆ
(I)
P
(t). (19.3.1)
We can readily verify that this approximation becomes formally valid in the limit of
small coupling between the subspaces defined by the Liouville space projectors, Pˆ
L and
Qˆ
L. Following the analogous derivation for Hilbert space projectors (see Ex. 19.2.1),
the exact equation can be reformulated as
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press404 Open Quantum Systems
∂
∂t
ρˆ
(I)
P
(t) = −


wt
0
dτKˆ
L(t, τ)

ˆI +
wt
τ
dτ
0
τ
0
w
0
dτ
00
Kˆ
L(τ
0
, τ
00)
×

ˆI +
wt
τ
00
dτ
000
τ
000
w
0
dτ
0000
Kˆ
L(τ
000
, τ
0000)[ˆI +···]





ρˆ
(I)
P
(t)
Kˆ
L(t, τ) ≡
1
h¯
2
e
it
h¯
Pˆ
LLˆPˆ
LPˆ
LLˆQˆ
Le
−i(t−τ)
h¯
Qˆ
LLˆQˆ
LQˆ
LLˆPˆ
Le
−iτ
h¯
Pˆ
LLˆPˆ
L
, (19.3.2)
where the approximation, Eq. (19.3.1), is readily identified as the lowest-order term of
an infinite series expansion in powers of the interaction between the projected subspaces,
Pˆ
LLˆQˆ
L and Qˆ
LLˆPˆ
L. The result, Eq. (19.3.1), is therefore often referred to as a Born–
Markov approximation.
The System-Bath Hamiltonian and Nakajima--Zwanzig
Projectors
We now distinguish the degrees of freedom of the system of interest from the rest by
rewriting the full Hamiltonian in a generic form:
Hˆ = Hˆ
S +Hˆ
B +Hˆ
SB ; [Hˆ
S,Hˆ
B] = 0. (19.3.3)
Here, Hˆ
S and Hˆ
B denote the “system” and the “bath” Hamiltonians, respectively, where
the system–bath coupling terms are included in Hˆ
SB. Considering the decomposition
of the system–bath Hamiltonian (Eq. (19.3.3)), the full Liouville operator can also be
decomposed into additive contributions from the system, the bath, and their coupling:
Lˆ = Lˆ
S +Lˆ
B +Lˆ
SB ; [Lˆ
S,Lˆ
B] = 0, (19.3.4)
where
Lˆ
SOˆ ≡ [Hˆ
S,Oˆ] ; Lˆ
BOˆ ≡ [Hˆ
B,Oˆ] ; Lˆ
SBOˆ ≡ [Hˆ
SB,Oˆ]. (19.3.5)
While focusing on the reduced system dynamics and reduced system observables,
in many cases it is justified to expect that the state of the environment remains essen￾tially constant on the timescale of the bath-induced system dynamics. Notice that this
does not imply that the bath is not influenced by the interaction with the system, but
rather that system-induced perturbations to the bath relax much faster than the bath￾induced dynamics within the system. As one can suspect, and as we shall indeed see in
what follows, this simplified picture of timescale separation emerges when the coupling
between the system and the bath is weak, and when the bath Hamiltonian is associated
with a dense and wide band of eigenstates.
The idea of fast bath relaxation is naturally cast into useful projection operators
in the Liouville space, as were introduced by Nakajima and Zwanzig. The projectors
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press405 19.3 The Born–Markov Approximation in Liouville Space
assume a reference stationary density operator, ρˆB (typically, the equilibrium density
of the uncoupled reservoir (Section 16.5)), for the bath degrees of freedom, where
[ρˆB,Hˆ
B] = 0 ; trB{ρˆB} = 1. (19.3.6)
A projector from the full space into a reduced (product) space in which the system is
disentangled from the bath is defined as
Pˆ
Lρˆ(t) ≡ ρˆBtrB{ρˆ(t)} ≡ ρˆBρˆS(t), (19.3.7)
where the notation trB{...} corresponds to a partial trace (Ex. 19.3.1) over the bath
degrees of freedom. Hence, the complementary projector, Qˆ
L, accounts for the system–
bath correlations,
Qˆ
Lρˆ(t) ≡ ρˆ(t)−Pˆ
Lρˆ(t). (19.3.8)
We can readily verify that these projectors satisfy the standard properties for two
complementary projectors as defined in Eq. (19.1.12). Additionally (Ex. 19.3.2),
[Pˆ
L,Lˆ
S] = [Qˆ
L,Lˆ
S] = [Pˆ
L,Lˆ
B] = [Qˆ
L,Lˆ
B] = 0. (19.3.9)
An important quantity of interest is the reduced system density,
ρˆS(t) = trB{ρˆ(t)}. (19.3.10)
The trace over the space of the bath variables projects the full density operator onto
the reduced system space. ρˆS(t) therefore contains the entire measurable information
about the system, averaged over the bath degrees of freedom. Particularly, any system
observable, OS(t) (see Eq. (16.2.4)), can be expressed in terms of the reduced density
operator:
OS(t) = tr{Oˆ
Sρˆ(t)} = trS{trB{Oˆ
Sρˆ(t)}} = trS{Oˆ
StrB{ρˆ(t)}} = trS{Oˆ
SρˆS(t)}.
(19.3.11)
Exercise 19.3.1 Let Aˆ be an operator in a Hilbert space that is a tensor product of
two Hilbert subspaces, spanned by the orthonormal vector sets, {|si} and {|bi} (with￾out loss of generality, |si and |bi can correspond to states of “a system” and “a bath,”
respectively). Expanding the operator in the product basis, {|si ⊗ |bi}, we have (see
also Eq. (11.6.14)) Aˆ = ∑
s,b,s
0
,b
0
As,b,s
0
,b
0|sihs
0
| ⊗ |bihb
0
|, where the elements, As,b,s
0
,b
0 , are
the matrix representation of Aˆ. The partial traces of Aˆ with respect to each of the sub￾spaces are defined astrB{Aˆ} ≡ ∑b
00hb
00|Aˆ|b
00i and trS{Aˆ} ≡ ∑s
00hs
00|Aˆ|s
00i (see Eq. (15.5.3)
and Ex. 15.5.1 for the definition of a trace). (a) Show that the partial trace of Â
with respect to one of the subspaces is an operator in the other subspace, for example,
trB{Aˆ} = ∑
s,s
0
αs,s
0|sihs
0
|, where αs,s
0 = ∑
b
00
As,b
00
,s
0
,b
00 . (b) Let Sˆ and Bˆ be operators in the sub￾spaces spanned by {|si} and {|bi}, respectively. Show that trB{Sˆ ⊗ Bˆ} = trB{Bˆ ⊗ Sˆ} =
trB{Bˆ}Sˆ. (c) Let Sˆ be an operator in the subspace spanned by {|si}, and let Aˆ be an
operator in the full (product) space. Show that tr{SˆAˆ} = trS{Str ˆ
B{Aˆ}}. (d) Let Bˆ be an
operator in the subspace spanned by {|bi}, and let Aˆ be an operator in the full (product)
space. Show that trB{BˆAˆ} = trB{AˆBˆ}.
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press406 Open Quantum Systems
Exercise 19.3.2 (a) Show that Pˆ
L and Qˆ
L, as defined in Eqs. (19.3.7, 19.3.8), satisfy
the relations Qˆ 2
L = Qˆ
L, Pˆ2
L = Pˆ
L and Qˆ
LPˆ
L = Pˆ
LQˆ
L = 0. (b) Show that [Pˆ
L,Lˆ
S] = 0 and
[Pˆ
L,Lˆ
B] = 0.
The Redfield Equation
It is convenient to expand the system–bath coupling as a sum over products of sys￾tem and bath operators, denoted hereafter as {Vˆ
(S)
1
,Vˆ
(S)
2
,....} and {Uˆ
(B)
1
,Uˆ
(B)
2
,....},
respectively:
Hˆ
SB ≡ ∑α
Vˆ
(S)
α Uˆ
(B)
α . (19.3.12)
This expansion is rather general, as this form of Hˆ
SB corresponds to any analytic func￾tion in the system and bath operators. (Notice that each term in the sum need not be
Hermitian, as long as the sum contains its Hermitian conjugate.) The NZ projection
becomes especially useful, however, in the common case in which the bath coupling
operators are orthogonal to the stationary bath density (in the sense of a Liouville’s
space inner product, Eq. (16.3.1)),
trB{Uˆ
(B)
α ρˆB} = trB{Uˆ
(B)†
α ρˆB} = 0, (19.3.13)
which means that observables associated with these operators vanish in the stationary
state of the bath. In this case, the following identities hold for the projectors defned in
Eqs. (19.3.7, 19.3.8) (see Ex. 19.3.3):
Pˆ
LLˆPˆ
L = Pˆ
LLˆ
SPˆ
L ; Pˆ
LLˆQˆ
L = Pˆ
LLˆ
SB ; Qˆ
LLˆPˆ
L = Lˆ
SBPˆ
L. (19.3.14)
Replacing Qˆ
LLˆPˆ
L by Lˆ
SBPˆ
L in the exact equation for the reduced system dynamics
(Eq. (19.3.2)), the infinite-order expansion is explicitly expressed in terms of powers of
Lˆ
SB, and hence of the system–bath coupling operator, Hˆ
SB. The Born–Markov approx￾imation, Eq. (19.3.1), can then be identified as a weak coupling approximation, valid
to second order in the system–bath interaction, Hˆ
SB. Consistent with the neglect of
higher orders in Hˆ
SB, the Qˆ
L-space propagator in Eq. (19.3.1) can be approximated to
the zeroth order in Lˆ
SB:
e
−i(t−τ)
h¯
Qˆ
LLˆQˆ
L ≈ e
−i(t−τ)
h¯
Qˆ
L(Lˆ
S+Lˆ
B)Qˆ
L
. (19.3.15)
Using Eqs. (19.3.9, 19.3.14, 19.3.15) as well as the equality, Pˆ
Le
αLˆ
B = Pˆ
L (see Ex. 19.3.4),
the Born–Markov approximation (Eq. (19.3.1)) reads
∂
∂t
ρˆ
(I)
P
(t) ∼= −
1
h¯
2
wt
0
dτPˆ
Le
it
h¯
(Lˆ
S+Lˆ
B)Lˆ
SBe
−i(t−τ)
h¯
(Lˆ
S+Lˆ
B)Lˆ
SBe
−iτ
h¯
(Lˆ
S+Lˆ
B)
ρˆ
(I)
P
(t), (19.3.16)
or, recalling the definition of the interaction picture representation of the system–bath
coupling, e
it
h¯
(Lˆ
S+Lˆ
B)Hˆ
SB = e
it
h¯
(Hˆ
S+Hˆ
B)Hˆ
SBe
−it
h¯
(Hˆ
S+Hˆ
B) ≡ Hˆ
(I)
SB
(t), we obtain (Ex. 19.3.5)
∂
∂t
ρˆ
(I)
P
(t) ∼= −
1
h¯
2
ρˆB
wt
0
dτtrB{[Hˆ
(I)
SB (t),[Hˆ
(I)
SB (τ),ρˆ
(I)
P
(t)]}. (19.3.17)
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press407 19.3 The Born–Markov Approximation in Liouville Space
Noticing that ρˆ
(I)
P
(t) = e
it
h¯
Lˆ
sPˆ
Lρˆ(t) = ρˆBe
it
h¯
Lˆ
sρˆS(t) (see Eqs. (19.1.14, 19.3.7)), we obtain
the equation of motion for the reduced system density operator, ρˆS(t) (Ex. 19.3.6):
∂
∂t
ρˆS(t) ∼= −
i
h¯
Lˆ
SρˆS(t)−
1
h¯
2
wt
0
dτtrB{Lˆ
SBe
−iτ
h¯
(Lˆ
S+Lˆ
B)Lˆ
SBe
iτ
h¯
(Lˆ
S+Lˆ
B)
ρˆB}ρˆS(t), (19.3.18)
or, equivalently (Ex. 19.3.7)
∂
∂t
ρˆS(t) ∼= −
i
h¯
[Hˆ
S, ρˆS(t)]−
1
h¯
2
wt
0
dτtrB
nhHˆ
SB,
h
e
−iτ
h¯
(Hˆ
S+Hˆ
B)Hˆ
SBe
iτ
h¯
(Hˆ
S+Hˆ
B)
,ρˆBρˆS(t)
iio.
(19.3.19)
This result is known as the Redfield equation [19.3]. Notice that it can be derived
directly by tracing the full Liouville equation over the bath degrees of freedom, keeping
only terms up to second order in the system–bath coupling (see Ex. 19.3.8). Also notice
that for initial states, in which the system and the bath are correlated, Qˆ
Lρˆ(0) 6= 0,
the exact equation obtains an additional inhomogeneous term (see Eq. (19.1.16)).
Approximating this term up to second order in the system–bath coupling, the Redfield
equation obtains a corresponding inhomogeneous term (see Ex. 19.3.9).
In the absence of initial system–bath correlation, the effect of the coupling of the
system to the bath is introduced by a dissipator,
Dˆ ρˆS(t) ≡ −
1
h¯
2
wt
0
dτtrB{[Hˆ
SB, [e
−iτ
h¯
(Hˆ
S+Hˆ
B)Hˆ
SBe
iτ
h¯
(Hˆ
S+Hˆ
B)
,ρˆBρˆS(t)]]}. (19.3.20)
Using the expansion of the system–bath coupling in multiplications of system and bath
operators (Hˆ
SB ≡ ∑
α
Vˆ
(S)
α Uˆ
(B)
α ; see Eq. (19.3.12)), the influence of the bath is captured in
the correlation functions of the corresponding bath operators,
cα,α0(τ) ≡ trB{Uˆ
(B)
α e
−iτ
h¯
Hˆ
BUˆ
(B)
α0 e
iτ
h¯
Hˆ
B ρˆB} ; cα,α0(τ) = cα,α0(−τ), (19.3.21)
where the dissipator obtains the form (see Ex. 19.3.10)
Dˆ ρˆS(t) =−
1
h¯
2 ∑
α,α0
wt
0
dτ{cα,α0(τ)[Vˆ
(S)
α , e
−iτ
h¯
Hˆ
SVˆ
(S)
α0 e
iτ
h¯
Hˆ
SρˆS(t)]
+cα0
,α(τ)[ρˆS(t)e
−iτ
h¯
Hˆ
SVˆ
(S)
α0 e
iτ
h¯
Hˆ
S
,Vˆ
(S)
α ]}. (19.3.22)
Introducing a complete orthonormal system of the reduced system Hamiltonian eigen￾states, Hˆ
S|φni = En|φni (for simplicity, only a discrete spectrum is considered explicitly)
and representing the system operators in this basis, ρn
0
,n
(t) = hφn
0|ρˆS(t)|φni and
V
(α)
n
0
,n = hφn
0|Vˆ
(S)
α |φni, the Redfield equation (Eq. (19.3.19)) obtains the form
∂
∂t
ρn
0
,n
(t) ∼= −
i
h¯
(En
0 −En)ρn
0
,n
(t)− ∑
m0
,m
Rn
0
,n,m0
,m(t)ρm0
,m(t), (19.3.23)
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press408 Open Quantum Systems
where the dissipator is represented in terms of the Redfield tensor (super-operator; see
Ex. 19.3.11),
Rn
0
,n,m0
,m (t) = ∑
α,α0
(
∑
l
[g
(α,α
0
)
l,m0 (t)V
(α)
n
0
,l
V
(α
0
)
l,m0 δm,n +g
(α
0
,α)
m,l
(t)V
(α
0
)
m,l
V
(α)
l,n
δm0
,n
0]
−[g
(α,α
0
)
n
0
,m0 (t)V
(α
0
)
n
0
,m0V
(α)
m,n +g
(α
0
,α)
m,n (t)V
(α)
n
0
,m0V
(α
0
)
m,n ]
)
,
(19.3.24)
and we introduced the Fourier integrals over the bath correlation functions,
g
(α,α
0
)
n,n
0 (t) ≡
1
h¯
2
wt
0
cα,α0(τ)e
−iτ
h¯
(En−En
0)
dτ ; g
(α,α
0
)
n,n
0 (t) ≡
1
h¯
2
wt
0
cα,α0(τ)e
−iτ
h¯
(En−En
0)
dτ.
(19.3.25)
Exercise 19.3.3 For the system–bath operators as defined in Eqs. (19.3.3–19.3.6,
19.3.12–19.3.13), show that the projection operators Pˆ
L and Qˆ
L, as defined in Eqs.
(19.3.7, 19.3.8), satisfy the relations in Eq. (19.3.14).
Exercise 19.3.4 (a) Use Eqs. (19.1.12, 19.3.9, 19.3.14, 19.3.15) in Eq. (19.3.1) to
show that ∂
∂t
ρˆ
(I)
P
(t) =∼ −
1
h¯
2
rt
0
dτPˆ
Le
it
h¯
Lˆ
SLˆ
SBe
−i(t−τ)
h¯
(Lˆ
S+Lˆ
B)Lˆ
SBPˆ
Le
−iτ
h¯
Lˆ
Sρˆ
(I)
P
(t). (b) Show that
according to the definition of Pˆ
L (Eq. (19.3.7)), for any scalar α one has, Pˆ
Le
αLˆ
B = Pˆ
L.
Use this identity and the definition, ρˆ
(I)
P
(t) ≡ e
it
h¯
Pˆ
LLˆPˆ
LPˆ
Lρˆ(t) (Eq. (19.1.14)), to derive
Eq. (19.3.16).
Exercise 19.3.5 (a) Use the identities for any scalar α, e
αLˆ
sρˆ ≡ e
αHˆ
sρˆ e
−αHˆ
s
, and e
αLˆ
B ρˆ
≡ e
αHˆ
B ρˆ e
−αHˆ
B , to derive Eq. (19.3.17) from Eq. (19.3.16).
Exercise 19.3.6 Use the identities, ρˆ
(I)
P
(t) = e
it
h¯
Lˆ
SPˆ
Lρˆ(t) = ρˆBe
it
h¯
Lˆ
SρˆS(t), and Eq.
(19.3.16) to derive Eq. (19.3.18).
Exercise 19.3.7 Use the identity, e
it
h¯
(Lˆ
S+Lˆ
B)Aˆ = e
it
h¯
(Hˆ
S+Hˆ
B)Aeˆ
−it
h¯
(Hˆ
S+Hˆ
B)
to derive
Eq. (19.3.19) from Eq. (19.3.18).
Exercise 19.3.8 Follow the alternative derivation given here to obtain the Redfield
equation directly: (a) Transform the full Liouville equation, ∂
∂t
ρˆ(t) = −i
h¯
[Hˆ ,ρˆ(t)],
with Hˆ = Hˆ
S + Hˆ
B + Hˆ
SB, into the interaction picture representation, ∂
∂t
ρˆ
(I)
(t) =
−i
h¯
[Hˆ
(I)
SB
(t),ρˆ
(I)
(t)], where Oˆ(I)
(t) ≡ e
i
h¯
[Hˆ
S+Hˆ
B]tOˆ(t)e
−i
h¯
[Hˆ
S+Hˆ
B]t
. (b) Integrate the equation
over time and show that it can be rearranged exactly as ∂
∂t
ρˆ
(I)
(t) = −i
h¯
[Hˆ
(I)
SB
(t),ρˆ
(I)
(0)]−
1
h¯
2
rt
0
dt
0
[Hˆ
(I)
SB(t),[Hˆ
(I)
SB(t
0
),ρˆ
(I)
(t)]] −
i
h¯
3
rt
0
dt
0
rt
t
0
dt00[Hˆ
(I)
SB(t),[Hˆ
(I)
SB(t
0
),[Hˆ
(I)
SB(t
00),ρˆ
(I)
(t
00)]. (c)
Neglect the terms of third order and higher in the system–bath coupling and obtain
an approximate Markovian equation for ρˆ
(I)
(t),
∂
∂t
ρˆ
(I)
(t) ∼=
−i
h¯
[Hˆ
(I)
SB
(t),ρˆ
(I)
(0)] −
1
h¯
2
rt
0
dt
0
[Hˆ
(I)
SB(t),[Hˆ
(I)
SB(t
0
),ρˆ
(I)
(t)]]. (d) Defining the reduced system density operator
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press409 19.4 The Stationary Born–Markov Approximation
as ρˆ
(I)
S
(t) ≡ trB[ρˆ
(I)
(t)], and assuming an initial product density:, ρˆ
(I)
(0) = ρˆ(0) =
ρˆBρˆS(0), show that for trB{ρˆBHˆ
SB} = 0 (Eqs. (19.3.12, 19.3.13)), we obtain ∂
∂t
ρˆ
(I)
S
(t) =
−
1
h¯
2
rt
0
dt
0
trB[Hˆ
(I)
SB(t),[Hˆ
(I)
SB(t
0
),ρˆ
(I)
(t)]]. (e) Without loss of accuracy to second order in
the system–bath coupling, replace ρˆ
(I)
(t) ∼= ρˆB ⊗ρˆ
(I)
S
(t) under the latter time integral and
show that this leads to Eq. (19.3.17), and hence to the Redfιeld equation, Eq. (19.3.19).
Exercise 19.3.9 When the system and bath are initially correlated, Qˆ
Lρˆ(0) 6= 0,
the exact equation for the Pˆ
L-space density operator obtains an inhomogeneous
term (Eq. (19.1.16)). Expanding this term up to first-order in the system–
bath coupling, show that Eq. (19.3.19) is generalized to ∂
∂t
ρˆS(t) ∼= −
i
h¯
[Hˆ
S,ρˆS(t)]
−
1
h¯
2
rt
0
dτtrB{[Hˆ
SB,[e
−iτ
h¯
(Hˆ
S+Hˆ
B)Hˆ
SBe
iτ
h¯
(Hˆ
S+Hˆ
B)
,ρˆBρˆS(t)]]}
−
i
h¯
ρˆBtrB{[e
it
h¯
(Hˆ
S+Hˆ
B)Hˆ
SBe
−it
h¯
(Hˆ
S+Hˆ
B)
,ρˆ(0)]}.
Exercise 19.3.10 Using the expansion of the system–bath coupling operator,
Hˆ
SB ≡ ∑
α
Vˆ
(S)
α Uˆ
(B)
α (Eq.(19.3.12)), we obtain e
−iτ
h¯
(Hˆ
S+Hˆ
B)Hˆ
SBe
iτ
h¯
(Hˆ
S+Hˆ
B) ≡ ∑
α
Vˆ
(S)
α (τ)Uˆ
(B)
α (τ),
whereVˆ
(S)
α (τ) ≡ e
−iτ
h¯
Hˆ
SVˆ
(S)
α e
iτ
h¯
Hˆ
S andUˆ
(B)
α (τ) ≡ e
−iτ
h¯
Hˆ
BUˆ
(B)
α e
iτ
h¯
Hˆ
B . Using these expressions,
show that Dˆ ρˆS(t), as defined in Eq. (19.3.20), can be expressed in terms of the bath
coupling correlation functions cα,α0(τ) and cα,α0(τ) (Eqs. (19.3.21, 19.3.22)).
Exercise 19.3.11 The Redfield equation for the reduced density operator (Eq. (19.3.19))
can be written as ∂
∂t
ρˆS(t) ∼= −
i
h¯
[Hˆ
S,ρˆS(t)] + Dˆ ρˆS(t), with Dˆ ρˆS(t) defined according to
Eq. (19.3.22). Defining ρn
0
,n
(t) ≡ hφn
0|ρˆS(t)|φni and V
(α)
n
0
,n ≡ hφn
0|Vˆ
(S)
α |φni, where {|φni}
are a complete orthonormal system of Hˆ
S eigenstates with the corresponding energies,
{En}, derive Eq. (19.3.23), using the definitions in Eqs. (19.3.24, 19.3.25).
Notice that the time-dependent Redfield equation (Eq. (19.3.23)) is valid as long
as the weak coupling assumption holds (namely, the equation is derived by replacing
Eq. (19.3.2) by the Born–Markov approximation, Eq. (19.3.1)). The latter is limited
to times that are short on the system–bath coupling period (h¯ over the largest of the
system–bath coupling matrix elements; see, e.g., Eq. (17.2.4)). In many cases of inter￾est, however, these times are sufficiently long on the timescale of the reduced system
dynamics, such that the latter is well approximated by the Redfield equation. More￾over, as discussed in what follows, the equation can be further simplified when the
timescale for bath-induced dynamics in the system is well separated from the bath
relaxation time (leading to the stationary Redfield equation) and from the periods of
internal (bath-free) system dynamics (leading to the Pauli master equation).
19.4 The Stationary Born–Markov Approximation
Within the Born–Markov approximation, the dissipator (Eq. (19.3.24)) is time￾dependent, owing to the Fourier integrals over the bath correlation functions (see
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press410 Open Quantum Systems
Eq. (19.3.25)). However, when the relaxation of these correlations is much faster
than the bath-induced dynamics in the system, the upper time-limit in the Fourier
integrals can be taken to infinity with no significant effect on the solution of the equa￾tion. In this case, the Redfield tensor (Eq. (19.3.24)) can be approximated as being
time-independent:
Rn
0
,n,m0
,m(t) ≈ R
(St)
n
0
,n,m0
,m = ∑
α,α0
{−[G
(α,α
0
)
n
0
,m0 V
(α
0
)
n
0
,m0V
(α)
m,n +G
(α
0
,α)
m,n V
(α)
n
0
,m0V
(α
0
)
m,n ]
+∑
l
[G
(α,α
0
)
l,m0 V
(α)
n
0
,l
V
(α
0
)
l,m0 δm,n +G
(α
0
,α)
m,l V
(α
0
)
m,l
V
(α)
l,n
δm0
,n
0]},
(19.4.1)
where the coefficients G
(α,α
0
)
n,n
0 and G
(α,α
0
)
n,n
0 are the “half Fourier transforms” of the bath
correlation functions,
G
(α,α
0
)
n,n
0 ≡
1
h¯
2
w∞
0
cα,α0(τ)e
−iτ
h¯
(En−En
0)
dτ ; G
(α,α
0
)
n,n
0 ≡
1
h¯
2
w∞
0
cα,α0(τ)e
−iτ
h¯
(En−En
0)
dτ.
(19.4.2)
The corresponding equation of motion for the reduced system dynamics under time￾scale separation between the “fast” bath relaxation and the “slow” bath induced
dynamics is sometimes referred to as the stationary Born–Markov (stationary Red￾field) approximation [19.4],
∂
∂t
ρn
0
,n
(t) = i
h¯
(En −En
0)ρn
0
,n
(t)− ∑
m0
,m
R
(St)
n
0
,n,m0
,m
ρm0
,m(t). (19.4.3)
The conditions for the validity of this approximation can be readily identified by con￾sidering the explicit form of the bath correlation functions (Eq. (19.3.21)). Denoting
the bath Hamiltonian eigenstates, Hˆ
B|bi = Eb|bi, and recalling that [ρˆB,Hˆ
B] = 0, we
have
cα,α0(τ) = ∑
b,b
0
hb|Uˆ
(B)
α |b
0
ihb
0
|Uˆ
(B)
α0
|biρbe
−iτ
h¯
(Eb
0−Eb
)
cα,α0(τ) = ∑
b,b
0
hb|Uˆ
(B)
α |b
0
ihb
0
|Uˆ
(B)
α0
|biρbe
−iτ
h¯
(Eb−Eb
0)
.
(19.4.4)
These functions have the generic form of a sum of oscillating terms at the bath frequen￾cies, {ωb
0
,b = (Eb
0 − Eb)/h¯}. Recalling that the relaxation time of a sum of oscillating
terms decreases with increasing bandwidth (see the discussion of Fermi’s golden rule
in Section 17.2, and Fig. 17.2.2), the assumption of rapid decay of the bath correla￾tion function, and hence the validity of the stationary Redfield approximation, become
valid as the bandwidth increases. This implies that the matrix representations of the
bath coupling operators {hb|Uˆ
(B)
α |b
0
i} are broad-banded, and/or that the distribution
of the bath eigenstate populations, {ρb = hb|ρˆ|bi}, is sufficiently broad. The latter typ￾ically depends on the bath temperature, where the distribution width increases with
increasing temperature (e.g., for a canonical ensemble, ρb = e
−Eb/(kBT)/Z). Conse￾quently, the validity of the stationary Redfield approximation typically increases with
increasing bath temperature. (Notice that the validity of the time-dependent Redfield
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press411 19.4 The Stationary Born–Markov Approximation
equation (Eqs. (19.3.23)) is not restricted by the bath temperature, as long as the weak
coupling (Born–Markov) assumption holds, as we have discussed.)
Population Transfer and the Pauli Master Equation
Now let us recall that, in the absence of system–bath coupling, the system eigenstate
populations are constant in time, and the dynamics is restricted to the oscillating coher￾ences between pairs of system eigenstates (see Section 15.1). While this dynamics may
be rich and interesting in its own right, here we wish to focus on the bath-induced
dynamics within the system under the influence of the system–bath coupling. For this pur￾pose, it is useful to transform Eq. (19.4.3) into the interaction picture representation
(see Section 15.3), where in the absence of system–bath coupling the density operator
is stationary, such that any system dynamics is solely attributed to the system–bath
coupling. The transformed density matrix reads
ρ
(I)
n
0
,n
(t) = e
iωn
0
,n
t
ρn
0
,n
(t) ; ωn
0
,n =
En
0 −En
h¯
, (19.4.5)
where
∂
∂t
ρ
(I)
n
0
,n
(t) = − ∑
m0
,m
R
(I)
n
0
,n,m0
,m
(t)ρ
(I)
m0
,m
(t). (19.4.6)
In this representation the coupling-free dynamics is encoded into the transformed
dissipator (see Ex. 19.4.1):
R
(I)
n
0
,n,m0
,m
(t) = [R
(St)
n
0
,n,m0
,m
]e
i(ωn
0
,n−ωm0
,m
)t
. (19.4.7)
The equation of motion for the reduced system density in the interaction pic￾ture (Eq. (19.4.6)) simplifies tremendously when the coupling-free system dynamics
is much faster than the bath-induced dynamics. This scenario applies whenever the
level spacings between (nondegenerate) eigenvalues of the bare system Hamiltonian
are large in comparison to the system–bath coupling energy. In these cases, coherences
between the system eigenstates are oscillating rapidly (at frequencies {ωn
0
,n}) on the
timescale of the bath-induced dynamics. Consequently, the corresponding elements of
R
(I)
n
0
,n,m0
,m
(t), average to near zero on the timescale of the bath-induced dynamics and
can be approximately neglected with respect to its stationary elements. This is known
as “the secular approximation,” which is closely related to “the rotating wave approx￾imation” (as encountered already in Section 18.3). To formally justify the resulting
equation, let us assume first that the system coherences share a common oscillation
period, Tc = 2π/ω, such that ωn
0
,n
∼= ω · ln
0
,n
, where ln
0
,n
is an integer. This assumption
is not guaranteed to hold in general, but it is often fulfilled (exactly or approxi￾mately) for “small” (e.g., few-level) quantum systems (it is trivially correct for any
two-level system). Second, let us assume that the common period Tc is still considera￾bly short on the bath-induced dynamics timescale (while still being much longer than
the relaxation time of the bath correlation functions (see Fig. 19.4.1), which should
hold when the characteristic energy level spacings in the system are large in compari￾son to the bath spectral density (see Section 17.2)). Since changes in ρ
(I)
n
0
,n
(t) within the
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press412 Open Quantum Systems
period Tc are assumed negligible, we have ∂
∂t
ρ
(I)
n
0
,n
(t) ≈
1
Tc
t+Tc/2
r
t−Tc/2
dt
0 ∂
∂t
0 ρ
(I)
n
0
,n
(t
0
) as well as
1
Tc
t+Tc/2
r
t−Tc/2
dt
0 ∑
m0
,m
R
(I)
n
0
,n,m0
,m
(t
0
)ρ
(I)
m0
,m
(t
0
) ∼=
1
Tc
t+Tc/2
r
t−Tc/2
dt
0 ∑
m0
,m
R
(I)
n
0
,n,m0
,m
(t
0
)ρ
(I)
m0
,m
(t). Using these
approximations in Eqs. (19.4.6, 19.4.7), we obtain (Ex. 19.4.2)
∂
∂t
ρ
(I)
n
0
,n
(t) ∼= − ∑
m0
,m
Rn
0
,n,m0
,mρ
(I)
m0
,m
(t), (19.4.8)
Rn
0
,n,m0
,m =
1
Tc
t+Tc/2
w
t−Tc/2
dt
0 ∑
m0
,m
R
(I)
n
0
,n,m0
,m
(t
0
) = δl
n
0
,n
,lm0
,m
R
(St)
n
0
,n,m0
,m
. (19.4.9)
Exercise 19.4.1 Given Eq. (19.4.3) for the dynamics of the reduced system den￾sity matrix elements, ∂
∂t
ρn
0
,n
(t) = i
h¯
(En − En
0)ρn
0
,n
(t) − ∑
m0
,m
R
(St)
n
0
,n,m0
,m
ρm0
,m(t), and the
transformation, ρ
(I)
n
0
,n
(t) = e
iωn
0
,n
t
ρn
0
,n
(t) (Eq. (19.4.5)), derive Eq. (19.4.6) with the
time-dependent tensor, R
(I)
n
0
,n,m0
,m
(t), as defined in Eq. (19.4.7).
Exercise 19.4.2 Show that time averaging of Eq. (19.4.6) over the short oscillation
period, Tc, leads to Eqs. (19.4.8, 19.4.9).
The result is an effective equation for the reduced system density operator, ρˆ
(I)
S
(t),
where the bath-induced dynamics is captured in the time-independent super-operator
R (Eq. (19.4.9)). It can be shown that this operator is of a generic Lindblad form
(a generator of a dynamical semigroup), which assures that the sum as well as the
nonnegativity of the system eigenstate populations are preserved over time. We direct
the interested reader to complementary literature (e.g., [19.2]) with respect to the math￾ematical proofs of these properties. Here we address some practical consequences that
can be readily deduced from Eqs. (19.4.8, 19.4.9).
First, we notice that since the off-diagonal elements of ρˆ
(I)
S
(t) (coherences) between
two nondegenerate eigenstates of the bath-free system Hamiltonian are associated with
ln
0
,n 6= 0, the bath-induced changes in these coherences depend only on non-diagonal
elements of ρˆ
(I)
S
(t) . This means that the dynamics of coherences between nondegenerate
eigenstates is decoupled from the dynamics of populations (associated with ln
0
,n = 0).
Second, in cases where the spectrum of the coupling-free system Hamiltonian is
nondegenerate, bath-induced changes in the populations (the diagonal matrix elements
of ρˆ
(I)
S
(t), corresponding to ln
0
,n = 0) are independent of any coherences (non-diagonal
elements, which correspond to ln
0
,n 6= 0 in these cases). Denoting the populations of
the system eigenstates as
Pn(t) = ρn,n(t) = ρ
(I)
n,n(t), (19.4.10)
the corresponding equation for the bath-induced population changes reads (using
Eqs. (19.4.8, 19.4.9))
∂
∂t
Pn(t) ∼= −∑m
R
(St)
n,n,m,mPm(t), (19.4.11)
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press413 19.4 The Stationary Born–Markov Approximation
Ftigure 19.4.1 Illustrative representation of timescale separation underlying the weak coupling (Born–Markov) and the secular
approximations. (a) The decay of bath correlation functions (Eq. (19.3.21)), determined by the bandwidth of the
system bath coupling,td ∼ 1/ωmax. (b) Oscillating coherences at the bath-free system frequencies,
tc ∼ 1/|ωn,n
0|. (c) Bath-induced kinetics in the system (population transfer and/or decay of coherences),
determined by the bath spectral density and temperature,tk ∼ 1/k. The characteristic timescales are indicated on
each plot. The Born–Markov approximation is valid when the decay of bath correlations is much faster than both the
bath-induced system dynamics,td  fk
(the wide-band limit), and the bath-free system dynamics,td << tc. The
secular approximation becomes valid when, on top of these conditions, the bath-free system dynamics is much faster
than the bath-induced system dynamics,tc << tk
.
where (using Eq. (19.4.1))
R
(St)
n,n,m,m = ∑
α,α0
{−[G
(α,α
0
)
n,m V
(α
0
)
n,m V
(α)
m,n +G
(α
0
,α)
m,n V
(α)
n,m V
(α
0
)
m,n ]
+∑
l
[G
(α,α
0
)
l,m
V
(α)
n,l
V
(α
0
)
l,m
δm,n +G
(α
0
,α)
m,l V
(α
0
)
m,l
V
(α)
l,n
δm,n]}
. (19.4.12)
Defining, km,n ≡ ∑
α,α0
{G
(α,α
0
)
n,m V
(α
0
)
n,m V
(α)
m,n + G
(α
0
,α)
m,n V
(α)
n,m V
(α
0
)
m,n }, and noticing that km,n ≥
0 (see the following), Eqs. (19.4.11, 19.4.12) obtain the form of a set kinetic
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press414 Open Quantum Systems
equations for the state populations, often referred to as Pauli’s master equation
(Ex. 19.4.3),
∂
∂t
Pn(t) = ∑m
km→nPm(t)−∑m
kn→mPn(t), (19.4.13)
where the state-to-state rates can be identified as
km,n = km→n = ∑
α,α0
{G
(α,α
0
)
n,m V
(α
0
)
n,m V
(α)
m,n +G
(α
0
,α)
m,n V
(α)
n,m V
(α
0
)
m,n }. (19.4.14)
As we can see, the time evolution of the reduced system populations is subject to
probability conservation, namely (see Ex. 19.4.4)
∂
∂t ∑n
Pn(t) = 0. (19.4.15)
Reformulating the master equation in matrix form,
∂
∂t
P(t) = KP(t), (19.4.16)
the matrix elements of K read
[K]n,m = (1−δm,n)km→n −δm,n ∑
n
06=n
kn→n
0. (19.4.17)
We can also see (Ex. 19.4.5) that the linear system of equations has a stationary (“steady
state”) solution, which we denote as PS:
∂
∂t
PS = KPS = 0. (19.4.18)
Exercise 19.4.3 Substitute Eq. (19.4.12) in Eq. (19.4.11) to derive the Pauli master
equation (Eq. (19.4.13)), with the population transition rates given in Eq. (19.4.14).
Exercise 19.4.4 Use the Pauli master equation (Eq. (19.4.13)) for ∂
∂t
Pn(t), to show
that ∂
∂t ∑
n
Pn(t) = 0. (Recall that each summation is over the entire spectrum of Hˆ
S￾eigenstates.)
Exercise 19.4.5 Use the structure of the matrix K, as expressed in Eq. (19.4.17), to
show that its rows are linearly dependent, and hence there exists a nontrivial solution, P,
to the homogeneous equation, KP = 0.
We now turn to the explicit evaluation of the state-to-state population transfer rates
in terms of the Hamiltonian parameters. The Hermiticity of the sum of system–bath
coupling operators, Hˆ
SB ≡
N
∑
α=1
Vˆ
(S)
α Uˆ
(B)
α , means that the sum contains either Hermitian
terms or sums of pairs of non-Hermitian terms and their conjugates. Consequently,
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press415 19.4 The Stationary Born–Markov Approximation
we can show (Ex. 19.4.6) that ∑
α,α0
G
(α
0
,α)
m,n V
(α)
n,m V
(α
0
)
m,n =
"
∑
α,α0
G
(α,α
0
)
n,m V
(α
0
)
n,m V
(α)
m,n
#∗
, which
means that the population transfer rates read
km→n = ∑
α,α0
2 Re{G
(α,α
0
)
n,m V
(α
0
)
n,m V
(α)
m,n }, (19.4.19)
or explicitly, using Eqs. (19.4.2, 19.4.4) and some algebra (see Ex. 19.4.7), we obtain
km→n = 2 Re
1
h¯
2
w∞
0
tr{ρˆB|φmihφm|Hˆ
SB|φnihφn|e
iτ
h¯
(Hˆ
B+Hˆ
S)Hˆ
SBe
−iτ
h¯
(Hˆ
B+Hˆ
S)
}dτ. (19.4.20)
Let us identify the uncoupled system and bath with a zero-order Hamiltonian
defined as Hˆ
0 = Hˆ
B +Hˆ
S, and the system–bath coupling with a perturbation operator,
Vˆ = Hˆ
SB. We can now associate the initial and final states of the system with ensembles
of Hˆ
0-eigenstates, characterized by product states of the uncoupled bath eigenstates
(defined by Hˆ
B|bi = Eb|bi), and the respective eigenstates of the system Hamiltonian
(Hˆ
S|φmi = Em|φmi) . Defining projectors into these ensembles, Pˆ
{i} = |φmihφm| ⊗
∑
b
|bihb|, and Pˆ
{ f } = |φnihφn| ⊗ ∑
b
|bihb|, for the initial and final ensembles, respec￾tively, and associating the initial state with the density operator, ρˆ{i} = |φmihφm| ⊗ρˆB,
Eq. (19.4.20) can be written as
km→n = 2 Re
1
h¯
2
w∞
0
tr
n
ρˆ{i}Pˆ
{i}Vˆ Pˆ
{ f }e
iτ
h¯
Hˆ
0Vˆ e
−iτ
h¯
Hˆ
0
o
dτ. (19.4.21)
We can readily see that the population transfer rate is the infinite time limit of
Eq. (17.3.12), derived in Chapter 17 for the transition rate between the two ensem￾bles, which leads to Fermi’s golden rule (Ex. 19.4.8). The rates or population transfer
therefore obtain the standard FGR form,
km→n =
2π
h¯ ∑
b,b
0
ρb|hb
0
|hφn|Vˆ |φmi|bi|2
δ(En −Em −[Eb −Eb
0]), (19.4.22)
where ρˆB|bi = ρb|bi. It is apparent from the result that the population transfer rates
are nonnegative. This means that for a given distribution of initial state populations,
not only does the sum of probabilities remain constant in time (Eq. (19.4.15)), but also
each population remains nonnegative at all times (Ex. 19.4.9), namely
Pn(0) ≥ 0 ⇒ Pn(t) ≥ 0 ; t > 0. (19.4.23)
Hence, the Pauli master equation (Eqs. (19.4.13, 19.4.16)) is consistent with the Lind￾blad requirements on the Markovian dynamical map from P(0)to P(t), which preserves
nonnegativity of the system Hamiltonian eigenstate populations (complete positivity),
and their accumulation to unity (trace preservation).
We can also see that the transition rate is subject to energy conservation, in the sense
that the energy difference between the initial and final eigenstates of the system Ham￾iltonian (En − Em) must be compensated for by similar transitions between the bath
Hamiltonian eigenstates, associated with Eb − Eb
0 = En − Em. In the case of coupling
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press416 Open Quantum Systems
to a thermal bath at equilibrium, where ρb =
1
Z
e
−Eb/(kBT)
(Eqs. (16.5.16–16.5.18)), the
rates for bath-induced transitions in the forward and backward directions are shown
to obey the detailed balance condition (see Ex. 19.4.10):
km→n = kn→me
−(En−Em)/(kBT)
. (19.4.24)
Using this condition in Eqs. (19.4.17, 19.4.18), we can readily verify the existence of a
steady-state solution, in which the populations of the system Hamiltonian eigenstates
are given by the Boltzmann distribution (see Ex. 19.4.11):
[PS]n =
1
∑
n
0
e
−En
0 /(kBT)
e
−En/(kBT)
. (19.4.25)
As we can see, under the assumptions of the Born–Markov and secular approxima￾tions, the steady state of the system (equilibrium in this case) “adopts” the constraint
imposed by the coupling to the thermal bath, where the approximated reduced system
density operator reads ρˆS
∼= e
−Hˆ
S/(kBT)/tr{e
−Hˆ
S/(kBT)}.
To summarize the discussion of Pauli’s master equation, we briefly review the con￾ditions for its validity, as we have just outlined. First, the system–bath coupling energy
must be sufficiently small, such that bath-induced dynamics in the system is fast on
the timescale of coherent oscillations between the system and the bath (set by the
inverse system–bath coupling energy). This justifies the time-dependent Born–Markov
(Redfield) approximation. Then, for a wide and continuous bath spectral density, the
relaxation of bath correlation functions should be sufficiently fast on the timescale of
the bath-induced system dynamics, justifying the stationary Born–Markov (Redfield)
approximation. Finally, when the bath-free system dynamics is much faster than the
bath-induced dynamics (and yet slower than the relaxation of bath correlations) the
secular (rotating wave) approximation is justified, leading to a probability-conserving
quantum master equation. When the bath-free system Hamiltonian is nondegenerate,
the kinetics of its eigenstate populations is decoupled from coherences between them,
which justifies the Pauli master equation. Notice that in the discussion of population
transfer between ensembles in Chapter 17, the presence of an initial “incoherent” state
of a system was assumed, with coherences completely ignored. Here we see that the
ignorance of coherences while following state populations can be rigorously justified
when the assumptions underlying the Pauli master equation hold.
Exercise 19.4.6 Show that for a Hermitian operator, Hˆ
SB ≡
N
∑
α=1
Vˆ
(S)
α Uˆ
(B)
α , and using
the definitions of G
(α,α
0
)
n,n
0
, G
(α,α
0
)
n,n
0 (Eq. (19.4.2)) and V
(α)
n
0
,n = hφn
0|Vˆ
(S)
α |φni, we have
∑
α,α0
G
(α
0
,α)
m,n V
(α)
n,m V
(α
0
)
m,n =
"
∑
α,α0
G
(α,α
0
)
n,m V
(α
0
)
n,m V
(α)
m,n
#∗
, and therefore the population transition
rates defined in Eq. (19.4.14) are real-valued (Eq. (19.4.19)).
Exercise 19.4.7 Use Eqs. (19.4.2, 19.4.4) in Eq. (19.4.19) to derive Eq. (19.4.20).
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press417 19.4 The Stationary Born–Markov Approximation
Exercise 19.4.8 Use the definitions Hˆ
0 = Hˆ
B + Hˆ
S, Hˆ
B|bi = Eb|bi, ρˆB|bi = ρb|bi,
Hˆ
S|φmi = Em|φmi,Pˆ
{i} = |φmihφm| ⊗ ∑
b
|bihb|, Pˆ
{ f } = |φnihφn| ⊗ ∑
b
|bihb|, and ρˆ{i} =
|φmihφm| ⊗ρˆB to derive Eq. (19.4.22) from Eq. (19.4.21).
Exercise 19.4.9 Let us denote the probability of populating the nth eigenstate of Hˆ
S as
Pn(t). (a) Given Pn(t) ≥ 0 for any n, and recalling that population transfer rates are non￾negative (km→n ≥ 0), use Eq. (19.4.13) to show that when a certain probability vanishes,
Pn(t) = 0, it means that ∂
∂t
Pn(t) ≥ 0. (b) Use the result of (a) to show that if all the prob￾abilities are nonnegative at t = 0 (namely Pn(0) ≥ 0 for any n), they remain so at any
later times, namely Pn(t) ≥ 0 for t > 0.
Exercise 19.4.10 (a) For a canonical density operator, ρˆB =
e
−Hˆ
B/(kBT)
ZB
, use Eq. (19.4.22)
to show that km→n =
2π
h¯ ∑
b,b
0
e
−Eb
/(kBT)
ZB
|hb|hφm|Vˆ |φni|b
0
i|2δ(Em −En −[Eb
0 −Eb]) and
kn→m =
2π
h¯ ∑
b,b
0
e
−E
b
0 /(kBT)
ZB
|hb|hφm|Vˆ |φni|b
0
i|2δ(Em −En −[Eb
0 −Eb]).
(b) Replacing the discrete summations over the bath Hamiltonian eigenstates by
energy integrals, where |hb|hφm|Vˆ |φni|b
0
i|2 → λ(Eb
0,Eb), and introducing the bath
density of states, ρ(Eb), show that km→n =
2π
h¯
r
dEb
r
dEb
0ρ(Eb
0)ρ(Eb)
e
−Eb
/(kBT)
ZB
λ(Eb
0,Eb)δ(Em − En − Eb
0 + Eb) and kn→m =
2π
h¯
r
dEb
r
dEb
0ρ(Eb
0)ρ(Eb)
e
−E
b
0 /(kBT)
ZB
λ(Eb
0, Eb)δ(Em −En −Eb
0 +Eb).
(c) Changing integration variables and defining the transition frequency, h¯ωn,m = En −
Em, show that km→n =
e
−h¯ωn,m
2
/(kBT)
ZB
2π
h¯
r
dEρ

E −
h¯ωn,m
2

ρ

E +
h¯ωn,m
2

e
−E/(kBT)
ZB
λ(E −
h¯ωn,m
2
,E +
h¯ωn,m
2
) and kn→m =
e
h¯ωn,m
2
/(kBT)
ZB
2π
h¯
r
dEρ

E −
h¯ωn,m
2

ρ

E +
h¯ωn,m
2

e
−E/(kBT)
ZB
λ(E −
h¯ωn,m
2
,E +
h¯ωn,m
2
), where km→n = kn→me
−(En−Em)/(kBT)
.
Exercise 19.4.11 Use the detailed balance condition, Eq. (19.4.24), to show that the
Boltzmann probability distribution, Pn(t) = const · e
−En/(kBT)
, is a stationary solution of
the Pauli master equation (Eq. (19.4.13)).
Pure Dephasing
Let us emphasize that population transfer between nondegenerate system Hamiltonian
eigenstates vanishes if the system–bath coupling operators are all diagonal in the sys￾tem eigenstate basis representation. This is apparent from the golden rule expression,
Eq. (19.4.22), where km→n ∝ |hb
0
|hφn|Vˆ |φmi|bi|2
. Recalling the explicit expansion of the
coupling operator, Vˆ = Hˆ
SB = ∑
α
Vˆ
(S)
α Uˆ
(B)
α , population transfer depends on the existence
of nonzero off-diagonal coupling matrix elements, Vˆ
(α)
n,m = hφn|Vˆ
(S)
α |φmi 6= 0, which
means that the coupling operators do not commute with the system Hamiltonian,
[Hˆ
SB,Hˆ
S] 6= 0 (see Ex. 6.4.1).
In contrast, even when [Hˆ
SB, Hˆ
S] = 0, the system–bath coupling can still induce
changes in the coherences between nondegenerate system Hamiltonian eigenstates.
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press418 Open Quantum Systems
This effect is often referred to as “pure dephasing.” It can be readily verified by con￾sidering the reduced Liouville equation (Eqs. (19.4.8, 19.4.9)) under the constraint of
“diagonal coupling”:
{V
(α)
n,m } = {V
(α)
n,n δn,m} ⇒ hφn|Hˆ
SB|φmi ∝ δn,m. (19.4.26)
In this case, the Redfield tensor (Eq. (19.4.1)) obtains a diagonal form,
R
(St)
n
0
,n,m0
,m
∝ δm,nδm0
,n
0 , (see Ex. 19.4.12), which means that
∂
∂t
ρ
(I)
n
0
,n
(t) = −kn
0
,nρ
(I)
n
0
,n
(t) ; n 6= n
0
, (19.4.27)
Each coherence is shown to change independently of other coherences and popula￾tions, where the bath-induced changes are introduced by
kn
0
,n = ∑
α,α0
[G
(α,α
0
)
n
0
,n
0 V
(α
0
)
n
0
,n
0 −G
(α
0
,α)
n,n V
(α
0
)
n,n ](V
(α)
n
0
,n
0 −V
(α)
n,n ). (19.4.28)
Using Eq. (19.4.5), we obtain in the Schrödinger picture
∂
∂t
ρn
0
,n
(t) = −{Re(kn
0
,n
) +i[ωn
0
,n +Im(kn
0
,n
)]}ρn
0
,n
(t). (19.4.29)
As we can see, the bath influence vanishes when hφn
0|Hˆ
SB|φn
0i = hφn|Hˆ
SB|φni, namely,
when the diagonal bath coupling (Eq. (19.4.26)) is identical for two system Hamil￾tonian eigenstates, the coherence between them is invariant to this coupling. Another
necessary condition for the bath influence in this case is that the bath coupling corre￾lation functions (see Eqs. (19.4.2, 19.4.4)) have a nonvanishing zero-frequency Fourier
component, namely
G
(α,α
0
)
n,n =
1
h¯
2
w∞
0
cα,α0(τ)dτ 6= 0 ; G
(α,α
0
)
n,n ≡
1
h¯
2
w∞
0
cα,α0(τ)dτ 6= 0. (19.4.30)
Notice that the real part of kn
0
,n
is nonnegative. Using Eqs. (19.4.2, 19.4.4), we obtain
(Ex. 19.4.13)
Re[kn
0
,n
] = 2π
h¯ ∑
b,b
0
ρb
1
2
|hb|hφn
0|Hˆ
SB|φn
0i|b
0
i − hb|hφn|Hˆ
SB|φni|b
0
i|2
δ(Eb
0 −Eb) ≥ 0.
(19.4.31)
Therefore, when the coupling to the bath is diagonal (as defined by Eq. (19.4.26)),
the magnitude of coherences between the system Hamiltonian eigenstates can only
decrease during forward time evolution. This decay, which is decoupled from popula￾tion transfer, is the “pure dephasing”:
|ρn
0
,n
(t)| = e
−Re[k
n
0
,n
]t
|ρn
0
,n
(0)|. (19.4.32)
A remarkable consequence of pure dephasing is that in the infinite time limit the matrix
representation of the reduced density matrix in the basis of Hˆ
S eigenstates approaches
a diagonal form; namely, it becomes stationary regardless of its initial preparation.
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press419 19.5 The Dissipative Qubit
Exercise 19.4.12 (a) Show that under the constraint of “diagonal coupling”
(Eq. (19.4.26)) the stationary Redfield tensor (Eq. (19.4.1)) obtains the form
R
(St)
n
0
,n,m0
,m = kn
0
,nδm,nδm0
,n
0 , where kn
0
,n = ∑
α,α0
[G
(α,α
0
)
n
0
,n
0 V
(α
0
)
n
0
,n
0 − G
(α
0
,α)
n,n V
(α
0
)
n,n ](V
(α)
n
0
,n
0 − V
(α)
n,n )
(Eq. (19.4.28)). (b) Use this result and Eqs. (19.4.8, 19.4.9) to derive Eq. (19.4.27).
(c) Use Eq. (19.4.5) to derive Eq. (19.4.29).
Exercise 19.4.13 Use Eqs. (19.4.2, 19.4.4) and the definition of kn
0
,n (Eq. (19.4.28)) to
show that Re[kn
0
,n
] = 1
h¯
2 ∑
b,b
0
r∞
0
ρb cos[(Eb
0 − Eb)τ/h¯]|hb|hφn
0|Hˆ
SB|φn
0i|b
0
i − hb|hφn|Hˆ
SB|φni
|b
0
i|2dτ and to derive Eq. (19.4.31).
19.5 The Dissipative Qubit
As a concrete example, let us analyze in some detail the interaction of a two-level sys￾tem (a TLS, or a qubit) with a bosonic environment, as captured in the spin-boson
model. (Extensions to Fermionic environment will be addressed in the next chapter.)
In Chapter 18 the corresponding TLS dynamics was analyzed in a local basis repre￾sentation of the TLS (a “donor” state and an “acceptor” state), where the coupling to
the bosonic environment was assumed diagonal in the local basis representation and
“strong,” whereas the off-diagonal coupling between the local states was regarded as
a weak perturbation. In what follows, we consider a complementary scenario, where
the off-diagonal coupling within the TLS is not necessarily weak, and the interaction
between the TLS and the bosonic environment is diagonal in the system eigenstate
representation and regarded as being in the weak-coupling limit.
The scenario of weak coupling of a few-level system (TLS in particular) to a bosonic
bath is a generic one, with relevance to elementary processes encountered in atomic,
molecular, optical, and material sciences on the nanoscale, as well as to quantum
information processing, involving qubits in an inevitably dissipative environment. One
example is spin relaxation in a condensed phase environment (in the harmonic approx￾imation), which is the basis for magnetic resonance imaging techniques. Another
example is the interactions of quantized dipoles in atoms, molecules, or nanoparticles
with the quantum electromagnetic radiation field (photons), which underlies the phe￾nomena of photon absorption and stimulated and spontaneous emission. (Notice that
in Chapters 10, 13, and 14 we addressed single atoms or molecules as isolated quan￾tum systems, but this holds only on timescales much shorter than the time for energy
exchange with the electromagnetic radiation field.) Other examples include the cou￾pling of spatially confined charge carriers or charge excitations to lattice vibrations
(phonons) in solids, which underlies charge and energy transport in electronic and
optoelectronic devices. These physical contexts are indeed very different, and a careful
implementation of the spin-boson model to each specific system requires deep specific
knowledge of the relevant context and consequently of the model parameters. Here we
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press420 Open Quantum Systems
give an introductory level understanding of the generic aspects and some common features
of the reduced dynamics of a TLS (weakly) coupled to a bosonic bath. The expert reader
can identify some of the results with well-known concepts in different fields, such as
Einstein coefficient in optics, spin relaxation times in nuclear magnetic imaging, or
electron–phonon scattering rates in solid-state physics.
Focusing on the weak system–bath coupling limit, it is instructive to pre-diagonalize
the “bath-free,” two-level system Hamiltonian and to represent the spin-boson model
(introduced in Chapter 18, Eq. (18.1.1)) in the basis of the TLS eigenstates, |φgi and
|φei for the ground and excited states, respectively. Without loss of generality, the aver￾age of the corresponding system eigenvalues is set to zero, such that the spin-boson
model Hamiltonian obtains the form
Hˆ = Hˆ
S +Hˆ
B +Hˆ
SB
Hˆ
S = ∆Eσˆz
Hˆ
B =
Nω
∑
j=1
h¯ωj
2
(Pˆ
2
j +Qˆ
2
j
) =
Nω
∑
j=1
h¯ωj

bˆ
†
j
bˆ
j +
1
2

Hˆ
SB = Vˆ
SUˆ
B +Vˆ
†
S Uˆ
†
B
; Uˆ
B =
Nω
∑
j=1
λjbˆ
j
. (19.5.1)
Here σˆz = |φeihφe| − |φgihφg| (corresponding to the two-by-two Pauli matrix, σz (see
Eq. (13.1.17))), ∆E > 0, Vˆ
S is any coupling operator in the space of the TLS, and Uˆ
B
is the bath coupling operator, where bˆ
†
j
and bˆ
j are, respectively, creation and annihi￾lation operators for a bath excitation at a frequency ωj
. Notice that the coupling is
linear in the bosonic bath operators, which means that bath response is limited to the
linear regime. This is consistent with the “weak coupling” limit, where the system–bath
interaction can be formally expanded in a Taylor series, keeping only the linear terms.
More specific justifications for the linear coupling arise in different contexts in different
fields, for example, the harmonic (normal modes) approximation in disordered molec￾ular systems, weak electron–phonon coupling in solids, or the dipole approximation
in matter–radiation interaction.
We are interested in following the reduced TLS dynamics in its eigenstate repre￾sentation under weak coupling to the bath. In the spirit of Nakajima and Zwanzig
projection, it is natural to associate the initial state with an uncorrelated product of
system and bath densities,
ρˆ(0) = ρˆB ⊗ρˆS(0), (19.5.2)
where the bath density operator is stationary. In the case of a thermal (canonical)
ensemble,
ρˆB =
e
−Hˆ
B/(kBT)
trB{e
−Hˆ
B/(kBT)}
. (19.5.3)
As we can readily see, the bath density fulfils the conditions (Eq. (19.3.6)),
[ρˆB,Hˆ
B]=0,trB{ρˆB} = 1, and the system bath coupling is consistent with the generic
form of Eq. (19.3.12), Hˆ
SB ≡ ∑
α
Vˆ
(S)
α Uˆ
(B)
α , where trB{Uˆ
(B)
α ρˆB} = trB{Uˆ
(B)†
a ρˆB} = 0
(Eq. (19.3.13), see Ex. 19.5.1). Consequently, the reduced system density in the
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press421 19.5 The Dissipative Qubit
weak coupling limit follows the time-dependent Born–Markov (Redfield) equation
(Eqs. (19.3.19, 19.3.20)),
∂
∂t
ρˆS(t) ∼= −
i
h¯
[Hˆ
S,ρˆS(t)] +Dˆ ρˆS(t), (19.5.4)
where the dissipator reads in this case (see Eqs. (19.3.21, 19.3.22) and Ex. 19.5.2)
Dˆ ρˆS(t) = −
1
h¯
2
wt
0
dτ{ce(τ)[Vˆ
S, e
−iτ
h¯
Hˆ
SVˆ
†
S
e
iτ
h¯
Hˆ
SρˆS(t)]+ca(τ)[Vˆ
†
S
, e
−iτ
h¯
Hˆ
SVˆ
Se
iτ
h¯
Hˆ
SρˆS(t)]+h.c.}.
(19.5.5)
The influence of the bosonic bath is shown to be captured in its correlation
functions,
ca(τ) = trB{Uˆ
†
B
e
−iτ
h¯
Hˆ
BUˆ
Be
iτ
h¯
Hˆ
B ρˆB} =
Nω
∑
j=1
|λj
|
2
e
iτωjn(ωj)
ce(τ) = trB{Uˆ
Be
−iτ
h¯
Hˆ
BUˆ
†
B
e
iτ
h¯
Hˆ
B ρˆB} =
Nω
∑
j=1
|λj
|
2
e
−iτωj
[1+n(ωj)], (19.5.6)
where n(ωj) = 1
e
h¯ω j
/(kBT)−1
is the boson occupation number of the jth bath mode
(see Ex. 18.2.7). Considering a continuous spectrum of bath frequencies, the
correlation functions can be expressed in terms of the bath spectral density,
J(h¯ω) ≡ 2πλ
2
(h¯ω)ρ(h¯ω), where the system–bath coupling function, λ
2
(h¯ω), and the
bath density of states, ρ(h¯ω), are related to the discrete frequency distribution as
λ
2
(h¯ωj) = |λj
|
2 and ρ(h¯ω) = ∑
j
δ(h¯ω −h¯ωj):
ca(τ) = h¯
2π
w∞
0
dωe
iτω
J(h¯ω)n(ω)
ce(τ) = h¯
2π
w∞
0
dωe
−iτω
J(h¯ω)(n(ω) +1)
. (19.5.7)
When the multiplicity of the spectral density function and the boson occupation num￾ber (J(ω)n(ω)) is a sufficiently broad function of the bath frequencies (namely, in the
wide band and high temperature limits), the relaxation time of the bath correlations
can become faster than any significant change in the reduced density matrix. Conse￾quently, the upper time limit in Eq. (19.5.5) can be taken to infinity (see a detailed
analysis in Section 17.2 as well as Eqs. (19.4.1–19.4.3)), which yields the stationary
Born–Markov approximation,
Dˆ ρˆ S(t) ∼= −
1
h¯
2
w∞
0
dτ{ce(τ)[Vˆ
S, e
−iτ
h¯
Hˆ
SVˆ
†
S
e
iτ
h¯
Hˆ
SρˆS(t)]+ca(τ)[Vˆ
†
S
, e
−iτ
h¯
Hˆ
SVˆ
Se
iτ
h¯
Hˆ
SρˆS(t)]+h.c.}.
(19.5.8)
Exercise 19.5.1 (a) Use the commutation relation between the bosonic annihilation
and creation operators (Eqs. (8.5.5–8.5.7)), [bˆ
j
0,bˆ
†
j
] = δ j, j
0 , to show that the traces over
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press422 Open Quantum Systems
the single-mode subspace, trj{bˆ
j
f(bˆ
†
j
bˆ
j)} and trj{bˆ
†
j
f(bˆ
†
j
bˆ
j)}, vanish for any analytic
function (f(Aˆ) = ∑
∞
n=0
fnAˆn
). (b) Given the definition of the bosonic bath Hamiltonian
and coupling operators (Eq. (19.5.1) with Uˆ
B =
Nω
∑
j=1
λjbˆ
j), and the bath density opera￾tor (Eq. (19.5.3)), ρˆB = e
−Hˆ
B/(kBT)/trB{e
−Hˆ
B/(kBT)}, use the result of (a) to show that
trB{Uˆ
BρˆB} = trB{Uˆ
†
B
ρˆB} = 0.
Exercise 19.5.2 (a) Use the explicit expressions (Eqs.(19.5.1, 19.5.3)),Uˆ
B=
Nω
∑
j=1
λjbˆ
j
,
Hˆ
B =
Nω
∑
j=1
h¯ωj(bˆ
†
j
bˆ
j +
1
2
),ρˆB =
e
−Hˆ
B/(kBT)
trB{e
−Hˆ
B/(kBT)}
, to show that the bath correlation
functions, ce(τ) = trB{Uˆ
Be
−iτ
h¯
Hˆ
BUˆ
†
B
e
iτ
h¯
Hˆ
B ρˆB} and ca(τ) = trB{Uˆ
†
B
e
−iτ
h¯
Hˆ
BUˆ
Be
iτ
h¯
Hˆ
B ρˆB},
read ce(τ) =
Nω
∑
j=1
|λj
|
2
e
−iτωj
[1+n(ωj)] and ca(τ) =
Nω
∑
j=1
|λj
|
2
e
iτωjn(ωj).
(b) For a general system–bath coupling operator, Hˆ
SB ≡ ∑
α
Vˆ
(S)
α Uˆ
(B)
α (Eq. (19.3.12)),
the Redfield (Born–Markov) dissipator obtains the form of Eqs. (19.3.21, 19.3.22),
Dˆ ρˆS(t) = −
1
h¯
2 ∑
α,α0
rt
0
dτ{cα,α0(τ)[Vˆ
(S)
α , e
−iτ
h¯
Hˆ
SVˆ
(S)
α0 e
iτ
h¯
Hˆ
SρˆS(t)]+cα0
,α(τ)[ρˆS(t)e
−iτ
h¯
Hˆ
sVˆ
(S)
α0
e
iτ
h¯
Hˆ
s
,Vˆ
(S)
α ]}, where cα,α0(τ) ≡trB{Uˆ
(B)
α e
−iτ
h¯
Hˆ
BUˆ
(B)
α0 e
iτ
h¯
Hˆ
B ρˆB} and cα,α0(τ)=cα,α0(−τ).
Map the coupling operator defined in Eq. (19.5.1), Hˆ
SB ≡Vˆ
SUˆ
B +Vˆ
†
S Uˆ
†
B
, on this gen￾eral form by identifying, Vˆ
S ≡Vˆ
(S)
1
, Uˆ
B ≡Uˆ
(B)
1
, Vˆ
†
S ≡Vˆ
(S)
2
, Uˆ
†
B ≡ Uˆ
(B)
2
, to show that
Dˆ ρˆS(t) = −
1
h¯
2
rt
0
dτ{c1,2(τ)[Vˆ
S, e
−iτ
h¯
Hˆ
SVˆ
†
S
e
iτ
h¯
Hˆ
SρˆS(t)]+c
∗
2,1
(τ)[ρˆS(t)e
−iτ
h¯
Hˆ
SVˆ
†
S
e
iτ
h¯
Hˆ
S
,Vˆ
S]}
−
1
h¯
2
rt
0
dτ{c2,1(τ)[Vˆ
†
S
, e
−iτ
h¯
Hˆ
SVˆ
Se
iτ
h¯
Hˆ
SρˆS(t)]+c
∗
1,2
(τ)[ρˆS(t)e
−iτ
h¯
Hˆ
SVˆ
Se
iτ
h¯
Hˆ
S
,Vˆ
†
S
]}.
(c) Use the identities c1,2(τ) = ce(τ) and c2,1(τ) = ca(τ) to derive Eq. (19.5.5).
Recalling (Eq. (19.5.1)) of the bath-free TLS Hamiltonian eigenstates,
Hˆ
S|φgi = −∆E|φgi ; Hˆ
S|φei = ∆E|φei. (19.5.9)
The reduced system density operator can be represented as
ρˆS(t) = ρg,g(t)|φgihφg|+ρe,e(t)|φeihφe|+ρg,e(t)|φgihφe|+ρe,g(t)|φeihφg|, (19.5.10)
where ρg,g(t) = hφg|ρˆS(t)|φgi and ρe,e(t) = hφe|ρˆS(t)|φei) are the ground and excited
state populations, and the coherences between these states are ρe,g(t) = hφe|ρˆS(t)|φgi
and ρg,e(t) = hφg|ρˆS(t)|φei.
The bath influence on the system depends on the nature of the coupling operators.
Let us consider first the case of off-diagonal coupling between the T LS and the bosonic
bath, setting
Vˆ
S ≡ µ|φeihφg| ; Vˆ
†
S = µ
∗
|φgihφe|, (19.5.11)
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press423 19.5 The Dissipative Qubit
or, in terms of the Pauli spin operators, σˆ+ = |φeihφg|, and σˆ− = |φgihφe|,
Hˆ
SB =
Nω
∑
j=1
µλjbˆ
jσˆ+ + µ
∗
λ
∗
j bˆ
†
jσˆ−. (19.5.12)
This version of the spin-boson model is often used, for example, to describe the inter￾action of the quantum electromagnetic field with an electric dipole (corresponding to
transition between two selected electronic states in an atom, molecule, impurity, and
so forth), within the dipole and rotating wave approximations. (See Ex. 18.3.5 for the
semiclassical version of the rotating wave approximation, and Ex. 19.5.6.)
Absorption, Stimulated Emission, and Spontaneous Emission
The dynamics of the different matrix elements of the reduced density operator within
the stationary Born–Markov (Redfield) approximation can be obtained directly from
Eqs. (19.5.4, 19.5.8). For the populations, Pauli’s master equation is readily obtained
(Ex. 19.5.3):
∂
∂t
ρg,g(t) = k
em
e→gρe,e(t)−k
ab
g→e pg,g(t)
∂
∂t
ρe,e(t) = k
ab
g→eρg,g(t)−k
em
e→gρe,e(t)
, (19.5.13)
where the population transfer rates read
k
em
e→g = 2|µ|
2Re
1
h¯
2
w∞
0
dτce(τ)e
iτ
h¯
2∆E =
2π
h¯
Nω
∑
j=1
|µ|
2
|λj
|
2
[1+n(ωj)]δ(h¯ωj −2∆E)
k
ab
g→e = 2|µ|
2Re
1
h¯
2
w∞
0
dτca(τ)e
−iτ
h¯
2∆E =
2π
h¯
Nω
∑
j=1
|µ|
2
|λj
|
2
n(ωj)δ(h¯ωj −2∆E),
(19.5.14)
or, in the case of a continuous bath spectral density,
k
em
e→g =
|µ|
2
h¯
J(2∆E)

n

2∆E
h¯

+1

k
ab
g→e =
|µ|
2
h¯
J(2∆E)n

2∆E
h¯

.
(19.5.15)
As we can see, the rate of energy emission (k
em
e→g
) into the bosonic bath has two
contributions:
k
em
e→g = k
st
e→g +k
se
e→g
. (19.5.16)
The rate of stimulated emission (k
st
e→g
) depends on the thermal occupation number of the
bath mode at the TLS transition frequency and is equal to the rate of energy absorption
from the field,
k
st
e→g = k
ab
g→e =
|µ|
2
h¯
J(2∆E)n

2∆E
h¯

. (19.5.17)
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press424 Open Quantum Systems
The spontaneous emission rate is independent on the bath temperature and corresponds
to the interaction of the TLS with the vacuum (unoccupied) state of the bosonic field,
k
se
e→g =
|µ|
2
h¯
J(2∆E). (19.5.18)
We can readily see that regardless of the initial state of the TLS, in the asymptotic
time limit the relative populations of the ground and excited states are set by the bath
temperature (see Ex. 17.3.7):
ρe,e(∞)
ρg,g(∞)
=
k
ab
g→e
k
em
e→g
= e
−2∆E /(kBT)
. (19.5.19)
This result is a specific case of the detailed balance condition (Eq. (19.4.24)).
Exercise 19.5.3 (a) Given Eqs. (19.5.4, 19.5.8), and defining the TLS eigenstate
populations, ρg,g(t) = hφg|ρˆS(t)|φgi, and ρe,e(t) = hφe|ρˆS(t)|φei, show that
∂
∂t
ρg,g(t)∼= −
1
h¯
2 2Re r∞
0
dτ{ce(τ)hg|[Vˆ
S, e
−iτ
h¯
Hˆ
SVˆ
†
S
e
iτ
h¯
Hˆ
sρˆS(t)]|gi+ca(τ)hg|[Vˆ
†
S
, e
−iτ
h¯
Hˆ
s
Vˆ
Se
iτ
h¯
Hˆ
sρˆS(t)]|gi}.
(b) lntroduce the identity operator in the space of the TLS, ˆI = |φgihφg| + |φeihφe|,
to show that for off-diagonal TLS coupling operators, Vˆ
S ≡ µ|φeihφg| and Vˆ
†
S =
µ
∗
|φgihφe|, this result reads ∂
∂t
ρg,g(t) = k
em
e→gρe,e(t) − k
ab
g→eρg,g(t), where k
em
e→g =
2|µ|
2Re 1
h¯
2
r∞
0
dτce(τ)e
iτ
h¯
2∆E and k
ab
g→e = 2|µ|
2Re 1
h¯
2
r∞
0
dτca(τ)e
−iτ
h¯
2∆E .
(c) Show similarly that ∂
∂t
ρe,e(t) = k
ab
g→eρg,g(t)−k
em
e→gρe,e(t).
(d) Use the explicit expressions for the correlation functions (Eq. (19.5.6)) to derive
Eq. (19.5.14).
(e) Use the expressions for the correlation functions for a continuous bath
(Eq. (19.5.7)) to derive Eq. (19.5.15).
Coherence Transfer and the Bloch Equation
The off-diagonal matrix elements of the reduced TLS density operator correspond to
coherences between the TLS eigenstates. Using the stationary Born–Markov (Red￾field) approximation (Eqs. (19.5.4, 19.5.8)), the time evolution of the coherences reads
(Ex. 19.5.4)
∂
∂t
ρe,g(t) = −i
h¯
(2∆E −h¯δ)ρe,g(t)−k
decρe,g(t)
∂
∂t
ρg,e(t) = i
h¯
(2∆E −h¯δ)ρg,e(t)−k
decρg,e(t). (19.5.20)
As we can see, the Hermiticity of the density operator (Eq. (16.2.6)) is preserved in time,
where ρg,e(0) = ρ
∗
e,g
(0) ⇒ ρg,e(t) = ρ
∗
e,g
(t) . In the absence of coupling to the bath, the
coherences oscillate at the bath-free (field-free) TLS frequency, 2∆E/h¯. The off-diagonal
coupling to the bosonic field is shown to induce a shift in the frequency of the coherence
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press425 19.5 The Dissipative Qubit
oscillations, as well as decay of the coherences in time. The frequency shift corresponds
to renormalization of the TLS energy gap by
h¯δ = Im
|µ|
2
2π
w∞
0
dτ
w∞
0
dωJ(h¯ω)[2n(ω) +1]e
−iτ
h¯
(2∆E−h¯ω)
. (19.5.21)
Notice that this energy shift is present even at zero bath temperatures (n(ω) → 0),
which reflects the effect of coupling between the TLS and the vacuum field (the Lamb
shift [10.3][10.4]). The decay of the coherences to zero (referred to as decoherence, or
dephasing), |ρg,e(t)| ∝ e
−k
dect
, is shown to be governed by a rate constant that is equal to
the average of the energy absorption and emission rates (Eqs. (19.5.14, 19.5.15)),
k
dec =
1
2
(k
ab
g→e +k
em
e→g
). (19.5.22)
Notice that in the infinite time limit, the Born–Markov and secular approximations
predict that the matrix representation of the reduced TLS density matrix becomes
diagonal in the basis of the bath-free TLS eigenstates, where the state populations
are Boltzmann-distributed. Hence, the system–bath coupling drives the system into
an equilibrium-like stationary state, which reflects the bath temperature.
The TLS state populations and coherences are closely related to three components
of the TLS dimensionless “spin” vector, defined as
hσz(t)i ≡ tr{σˆzρˆ(t)}
hσx(t)i ≡ tr{σˆxρˆ(t)}
hσy(t)i ≡ tr{σˆyρˆ(t)},
(19.5.23)
where σˆx, σˆy, and σˆz are the Pauli spin operators corresponding to the Pauli matrices
in the TLS eigenstate representation (Eq. (13.1.17)). Using Eqs. (19.5.13 and 19.5.20),
we can readily obtain an equation of motion for the “spin” vector (Ex. 19.5.5),
∂
∂t
hσz(t)i = −(k
ab
g→e +k
em
e→g
)hσz(t)i −k
se
e→g
∂
∂t
hσx(t)i = −k
dechσx(t)i − 1
h¯
(2∆E −h¯δ)hσy(t)i
∂
∂t
hσy(t)i = −k
dechσy(t)i+
1
h¯
(2∆E −h¯δ)hσx(t)i.
(19.5.24)
The result is well known as the Bloch equation in the context of magnetic reso￾nance imaging. Indeed, associating the free TLS with a spin-half particle in a constant
magnetic field along the z direction, namely ∆Eσˆz = BzµBSˆ
z =
BzµBh¯
2
σˆz
, where the
bosonic field represents lattice modes to which the spins are coupled, Eq. (19.5.24)
describes the dynamics of the spin magnetization vector. The decay of the magnet￾ization is characterized by the “spin-lattice relaxation” time, T1 =
1
k
ab
g→e+k
em
e→g
, and
the “spin-spin” relaxation time, T2 = 2T1, which identifies with the decoherence rate
(Eq. (19.5.22)). Neglecting the TLS gap renormalization, hδ << 2∆E, and defining the
Larmor frequency, ω0 = BzµB, the Bloch equations are expressed as
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press426 Open Quantum Systems
∂
∂t
hσz(t)i = −
1
T1
hσz(t)i −k
se
e→g
∂
∂t
hσx(t)i = −
1
T2
hσx(t)i −ω0hσy(t)i
∂
∂t
hσy(t)i = −
1
T2
hσy(t)i+ω0hσx(t)i.
(19.5.25)
Exercise 19.5.4 (a) The coherences between the TLS eigenstates are defined as
ρg,e(t) = hφg|ρˆS(t)|φei and ρe,g(t) = hφe|ρˆS(t)|φgi. Introduce the identity operator in
the space of the TLS, ˆI = |φgihφg| + |φeihφe|, into the stationary Redfield Equa￾tion (Eqs. (19.5.4, 19.5.8)), and show that for off-diagonal TLS coupling operators,
Vˆ
S ≡ µ|φeihφg| and Vˆ
†
S = µ
∗
|φgihφe|, the coherences follow the equations ∂ ρg,e(t)
∂t
∼=
i
h¯
2∆Eρg,e(t) −
|µ|
2
h¯
2
r∞
0
dτ{[ca(τ) + c
∗
e
(τ)]e
−iτ
h¯
2∆E }ρg,e(t), and ∂ ρe,g(t)
∂t
∼= −
i
h¯
2∆Eρe,g(t) −
|µ|
2
h¯
2
r∞
0
dτ[ce(τ) + c
∗
a
(τ)]e
iτ
h¯
2∆E ρe,g(t). (b) Use the definition of the absorption and emis￾sion rates (Eq. (19.5.14)) and the definitions, δ ≡ Im |µ|
2
h¯
2
r∞
0
dτ{[ca(τ) + c
∗
e
(τ)]e
−iτ
h¯
2∆E }
and, k
dec ≡
1
2
(k
ab
g→e +k
em
e→g
), to derive Eq. (19.5.20). (c) Use the explicit expressions for
the correlation functions for a continuous bath (Eq. (19.5.7)) to derive Eq. (19.5.21).
Exercise 19.5.5 (a) Use Eq. (19.5.23), the Pauli spin matrices σ x =

0 1
1 0 
, σ y =

0 −i
i 0

,σ z =

1 0
0 −1

and the TLS density matrix ρ(t) = 
ρe,e(t) ρe,g(t)
ρg,e(t) ρg,g(t)

to show that hσz(t)i = ρe,e(t) − ρg,g(t),hσx(t)i = ρg,e(t) + ρe,g(t), hσy(t)i = −iρg,e(t) +
iρe,g(t). (b) Use Eqs. (19.5.13, 19.5.20) for the time evolution of the density matrix
elements to derive Eq. (19.5.24).
Exercise 19.5.6 The reduced dynamics of the TLS density operator (Eqs. (19.5.13,
19.5.20)), under the system–bath coupling, Hˆ
SB = µUˆ
Bσˆ+ + µ
∗Uˆ
†
Bσˆ−, was derived from
the stationary Redfield equation (Eqs. (19.5.4, 19.5.8)), allegedly with no farther
approximations. This simplicity is attributed to the fact that the excitation (σˆ+) and de￾excitation (σˆ−) TLS operators are coupled independently to Uˆ
B and to Uˆ
†
B
, respectively.
In a more general case, however, both σˆ+ and σˆ− may couple to the same system–bath
operators. As shown in what follows, the time evolution of the reduced density matrix is
different in this case. Nevertheless, within the secular and rotating wave approximations,
this difference is neglected and Eqs. (19.5.13, 19.5.20) are regained. Let us consider
a system–bath coupling operator, Hˆ
SB = µ(σˆ+ + σˆ−)(Uˆ
B +Uˆ
†
B
) ≡ Vˆ
S(Uˆ
B +Uˆ
†
B
), where
Vˆ
S = µ(σˆ+ +σˆ−) is Hermitian and Uˆ
B =
Nω
∑
j=1
λjbˆ
j
.
(a) Show that in this case the Redfield dissipator (Eqs. (19.5.4, 19.5.8)) reads Dˆ ρˆS(t) =
−
1
h¯
2
r∞
0
dτ{c(τ)[Vˆ
S, e
−iτ
h¯
Hˆ
SVˆ
Se
iτ
h¯
Hˆ
SρˆS(t)] +h.c.}, where c(τ) = ce(τ) +ca(τ).
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press427 19.5 The Dissipative Qubit
(b) Defining C ≡
|µ|
2
h¯
2
r∞
0
dτc(τ)e
−iτ
h¯
2∆E and C ≡
|µ|
2
h¯
2
r∞
0
dτc(τ)e
iτ
h¯
2∆E , show that the corre￾sponding time evolution of the reduced TLS density matrix is given by
∂
∂t
ρg,g(t) = −[C +C
∗
]ρg,g(t) + [C +C
∗
]ρe,e(t)
∂
∂t
ρe,e(t) = −[C +C
∗
]ρe,e(t) +[C +C
∗
]ρg,g(t)
∂
∂t
ρg,e(t) = i
h¯
2∆Eρg,e(t)−[C +C
∗
]ρg,e(t) + [C
∗ +C]ρe,g(t)
∂
∂t
ρe,g(t) = −i
h¯
2∆Eρe,g(t)−[C
∗ +C]ρe,g(t) + [C +C
∗
]ρg,e(t).
(c) Recalling the explicit form of the bosonic bath correlation functions (Eq. (19.5.6)),
we obtain
C =
|µ|
2
h¯
2
Nω
∑
j=1
|λj
|
2
w∞
0
dτ
h
e
iτωj e
−iτ
h¯
2∆E n(ωj) +e
−iτωj e
−iτ
h¯
2∆E
[1+n(ωj)]i
C =
|µ|
2
h¯
2
Nω
∑
j=1
|λj
|
2
w∞
0
dτ
h
e
iτωj e
iτ
h¯
2∆E n(ωj) +e
−iτωj e
iτ
h¯
2∆E
[1+n(ωj)]i
.
The rotating wave approximation implies that rapidly oscillating terms can be
neglected next to slowly oscillating terms under the time integrals. Considering that
both ∆E and the bath frequencies are positive, show that this approximation means
that C ∼=
|µ|
2
h¯
2
r∞
0
dτe
−iτ
h¯
2∆E ca(τ) and C ∼=
|µ|
2
h¯
2
r∞
0
dτe
iτ
h¯
2∆E ce(τ).
(d) Recalling the definitions of the absorption and emission rates (Eq. (19.5.14)) and of
δ ≡ Im|µ|
2
h¯
2
r∞
0
dτ[ca(τ) + c
∗
e
(τ)]e
−iτ
h¯
2∆E , show that Re[C] ∼= k
em
e→g/2, Re[C] ∼= k
ab
g→e/2,
and Im[C +C
∗
] ∼= δ, and therefore
∂
∂t
ρg,g(t) = −k
ab
g→eρg,g(t) +k
em
e→gρe,e(t)
∂
∂t
ρe,e(t) = −k
em
e→gρe,e(t) +k
ab
g→eρg,g(t)
∂
∂t
ρg,e(t) = i
h¯
2∆Eρg,e(t)−

k
ab
g→e +k
em
e→g
2
+iδ

ρg,e(t) +
k
ab
g→e +k
em
e→g
2
−iδ

ρe,g(t)
∂
∂t
ρe,g(t) = −i
h¯
2∆Eρe,g(t)−

k
ab
g→e +k
em
e→g
2
−iδ

ρe,g(t) +
k
ab
g→e +k
em
e→g
2
+iδ

ρg,e(t).
(e) Transforming to the interaction picture representation, ρ
I
g,e
(t) = e
−i2∆Et/h¯ρg,e(t),
ρ
I
e,g
(t) = e
i2∆Et/h¯ρe,g(t), the equations for the coherences obtain the form
∂
∂t
ρ
I
g,e
(t) = −

k
ab
g→e +k
em
e→g
2
+iδ

ρ
I
g,e
(t) +
k
ab
g→e +k
em
e→g
2
−iδ

e
−i4∆Et/h¯ρ
I
e,g
(t)
∂
∂t
ρ
I
e,g
(t) = −

k
ab
g→e +k
em
e→g
2
−iδ

ρ
I
e,g
(t) +
k
ab
g→e +k
em
e→g
2
+iδ

e
i4∆Et/h¯ρ
I
g,e
(t).
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press428 Open Quantum Systems
The secular approximation (see Eqs. (19.4.8, 19.4.9)) implies that the rapidly oscil￾lating coefficients are negligible with respect to the stationary coefficients. Invoke
this approximation and transform back the equations to the Schrodinger picture
to regain the equations of motion for Hˆ
SB = µUˆ
Bσˆ+ + µ
∗Uˆ
†
Bσˆ− (Eqs. (19.5.13,
19.5.20)).
Diagonal Coupling and Pure Dephasing
We now focus on system–bath coupling that is diagonal in the system eigenstate basis.
Physically, this type of coupling amounts to bath-induced variations in the TLS energy
gap. As analyzed in the general case (see Section 19.4), diagonal coupling cannot induce
population transfer between the TLS eigenstates. Nevertheless, it is an important source
of decoherence (dephasing) that is independent of the population transfer dynamics.
Without loss of generality, here the system–bath coupling is projected onto the excited
state of the TLS, setting
Vˆ
S ≡ η|φeihφe| = ησˆ+σˆ−, (19.5.26)
where η is real-valued. Since Vˆ
s
is Hermitian, the system–bath coupling (see
Eq. (19.5.1)) becomes a single product of system and bath operators,
Hˆ
SB = Vˆ
SUˆ
B +Vˆ
†
S Uˆ
†
B = Vˆ
S(Uˆ
B +Uˆ
†
B
) ; Uˆ
B =
Nω
∑
j=1
λjbˆ
j
, (19.5.27)
and the dissipator obtains a simple form (compare to Eq. (19.5.5)),
Dˆ ρˆS(t) = −
1
h¯
2
wt
0
dτ{[ce(τ) +ca(τ)][Vˆ
S, e
−iτ
h¯
Hˆ
sVˆ
Se
iτ
h¯
Hˆ
sρˆS(t)] +h.c.}, (19.5.28)
with the bath correlation functions as given in Eqs. (19.5.6, 19.5.7). Invoking the sta￾tionary Born–Markov approximation (Eq. (19.5.8)), the time evolution of the state
populations and coherences in the reduced TLS obtain the explicit form (Ex. 19.5.7),
∂
∂t
ρg,g(t) = 0
∂
∂t
ρe,e(t) = 0
∂
∂t
ρe,g(t) = −[Re{k}+
i
h¯
(2∆E +h¯ Im{k})]ρe,g(t)
∂
∂t
ρg,e(t) = −[Re{k} − i
h¯
(2∆E +h¯ Im{k})]ρg,e(t),
(19.5.29)
where (Ex. 19.5.8)
k =
η
2
2πh¯
w∞
0
dτ
w∞
0
dωJ(h¯ω)[cos(τω)2n(ω) +e
−iτω
]. (19.5.30)
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press429 Bibliography
The diagonal coupling is shown to induce a real-valued shift to the TLS energy gap by
h¯ Im{k} (and therefore to the oscillation frequency of the coherences), as well as a decay
of the coherences to zero in the infinite time limit:
|ρe,g(t)| = |ρe,g(0)|e
−k
pdt
; k
pd = Re{k} ≥ 0. (19.5.31)
The (pure) dephasing rate, k
pd is shown to depend on the spectral density of the
bosonic bath in the zero-frequency limit (see Ex. 19.5.8 and Eq. (19.4.30)). For any
finite temperature, the rate is approximated as
k
pd ≈ limω→0
kBTη
2
2h¯
J(h¯ω)
h¯ω
(19.5.32)
Notice that a finite spectral density at the zero-frequency limit corresponds to a “static
noise” (or static disorder), where the diagonal coupling to the bath merely changes the
TLS energy gap. Considering a low-frequency mode, Qˆ
0 = (bˆ
†
0 + bˆ
0)/
√
2, at a finite
temperature, where the classical limit applies, Eqs. (19.5.26, 19.5.27) imply that the
effective energy gap depends on the bath displacement, namely 2∆E +
√
2ηλ0Q0. The
broadening of the distribution of static TLS energy gaps in an ensemble of otherwise
identical quantum systems (“inhomogeneous broadening”) can therefore be regarded
as the physical origin of pure dephasing. In the context of magnetic resonance imag￾ing, for example, inhomogeneity in the local magnetic field within a sample is a major
source of dephasing, typically much faster than the decoherence due to population
transfer between the TLS states (owing to off-diagonal system–bath coupling; see the
preceding discussion). The effective decoherence rate (often referred to as 1/T
∗
2
) is
therefore much larger than 1/T2, as appears in Eq. (19.5.25).
Exercise 19.5.7 Use Eqs. (19.5.26–19.5.28) and the definition, k =
η
2
h¯
2
r∞
0
dτ [ce(τ) +
ca(τ)], to derive Eq. (19.5.29) for the reduced density matrix elements.
Exercise 19.5.8 (a) Use the explicit expressions for the correlation functions in the case
of a continuous boson bath (Eq. (19.5.7)) to show that k =
η
2
h¯
2
r∞
0
dτ [ce(τ) + ca(τ)] =
η
2
2πh¯
r∞
0
dτ
r∞
0
dωJ(h¯ω)[cos(τω)2n(ω) + e
−iτω ]. (b) The bath-induced decay of the coher￾ences is associated with the rate, k
pd = Re{k} ≥ 0 (Eq. (19.5.31)). Show that k
pd =
limω→0
η
2
4h
J(h¯ω)[2n(ω) +1], where for a finite temperature, k
pd ≈ limω→0
kBTη
2
2h¯
J(h¯ω)
h¯ω
.
Bibliography
[19.1] C. Meier and D. J. Tannor, “Non-Markovian evolution of the density operator
in the presence of strong laser fields,” The Journal of Chemical Physics 111,
3365 (1999).
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press430 Bibliography
[19.2] H.-P. Breuer and F. Petruccione, “The Theory of Open Quantum Systems”
(Oxford, 2002).
[19.3] A. G. Redfield, “The theory of relaxation processes,” Advances in Magnetic
and Optical Resonance 1, 1 (1965).
[19.4] D. Egorova, M. Thoss, W. Domcke, and H. Wang, “Modeling of ultra￾fast electron-transfer processes: Validity of multilevel Redfield theory,” The
Journal of Chemical Physics, 119, 2761 (2003).
https://doi.org/10.1017/9781108877787.020 Published online by Cambridge University Press20 Open Many-Fermion Systems
20.1 The Fock Space
In Chapters 13 and 14 we discussed in some detail the electronic structure of atoms,
molecules, and periodic lattices, which are the “building blocks” of matter on the
nanoscale. In these discussions the many-electron systems were closed, in the sense
that the number of electrons was fixed. However, many of the relevant phenomena for
nanoscience and technology involve transport of electrons between open systems, in
which the number of electrons can repeatedly change. For example, when an atom or
a molecule is adsorbed on a surface, it can exchange charge with the surface, lead￾ing to remarkable changes in electronic structure, nuclear configuration, chemical
stability, and so forth. To fully characterize the dynamics associated with such charg￾ing/discharging processes, different charging states of the system of interest need to be
accounted for simultaneously.
In this chapter we extend the treatment of many-electron systems to account for a
variable number of electrons within the system, introducing the “second quantization”
formulation. The state of a many-particle system is formulated in “Fock space,” which
is an extended Hilbert space, that relates to all possible particle numbers within the
system. We shall focus here only on fermions, where the complementary discussion of
second quantization for bosons, can be found elsewhere.
We start by recalling the generic form of the Hamiltonian for a system of N elec￾trons. Considering, for example, an atom (Eq. (3.4.10)) or a molecule (Eq. (3.4.11))
with clamped nuclei, in the absence of external fields, the Hamiltonian (up to a trivial
addition of a constant) can be cast as,
Hˆ
(N) =
N
∑
i=1
hˆ
i +
N
∑
j>i=1
wˆi, j
. (20.1.1)
The first term is a sum over N single-particle Hamiltonians, accounting for each
of the electrons, in the absence of the others. In terms of the electron coordinates,
hˆ ≡
−h¯
2
2me
∆r +V(rˆ), where V(rˆ) is the “external single-particle potential,” which is the
Coulomb energy attributed to the electron owing to the spatial distribution of the
nuclear charges. The second term is a sum over all electron-pair interactions. In terms
of the electron coordinates, wˆ ≡
Ke2
|rˆ−rˆ
0
|
is the Coulomb repulsion energy between the
431
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press432 Open Many-Fermion Systems
two electrons positioned at rˆ and rˆ
0
. This term is universal, namely independent of any
particular external potential.
Each single-particle state can be expanded in terms of a complete orthonormal sys￾tem of state vectors, denoted as {|Φki}. Here k is a set of quantum numbers, needed
to uniquely define a single-particle state (e.g., its spatial orbital in the coordinates
representation, as well as its spin state). The orthonormal set can be composed of,
for example, the eigenstates of the single-particle Hamiltonian, hˆ|Φki = εk
|Φki, or the
eigenstates of the Fock operator (Eq. (13.3.18)). In general, the single-particle Hilbert
space is spanned by an infinite set (see section 11.2), but for simplicity, and without
loss of generality, we restrict the following discussion to finite dimensions, M, denot￾ing the set of single-particle states (e.g., the number of orthonormal spin-orbitals) as
{|Φ1i,|Φ2i,...,|ΦMi}, where
hΦk
0|Φki = δk,k
0. (20.1.2)
An N-particle vector space is a tensor product of N single-particle spaces (see Sec￾tion 11.6). Consequently, in general, each N-particle state can be expanded as a linear
combination of products of N single-particle states, where the number of linearly￾independent products is MN Recalling, however, that for N identical fermions a proper
state must be antisymmetric with respect to any particle index permutation (see Sec￾tion 13.3), the dimensions of the “physical” vector space for N electrons is much
smaller. The antisymmetry property is guaranteed to hold when the product states
are grouped into determinants (see Section 13.3). Each determinant is defined by an
ordered selected set of N “populated” single-particle states out of the total number
of M, namely a set of selected indexes, l1 < l2 < ... < lN, where {lj} ∈ 1,2,...M (see
Eq. (13.3.2)):
D
1,2,...,N|Ψ
(N)
{11,l2,...,lN}
E
≡
1
√
N!











h1|Φl1
i h1|Φl2
i h1|Φl3
i ··· h1|ΦlN
i
h2|Φl1
i h2|Φl2
i h2|Φl3
i ··· h2|ΦlN
i
h3|Φl1
i h3|Φl2
i h3|Φl3
i ··· h3|ΦlN
i
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
hN|Φl1
i hN|Φl2
i hN|Φl3
i ··· hN|ΦlN
i











.
(20.1.3)
Using the orthonormality of the single-particle states (Eq. (20.1.2)), we can readily
verify that different N-particle determinants, corresponding to different selected sets
({l1,l2,...,lN}), are orthonormal:
D
Ψ
(N)
{l1,l2,...,lN}



Ψ
(N)
{l1
0
,l2
0
,...,lN
0
}
E
= δ{l1,l2,...,lN},{l1
0
l2
0
...,lN
0
}. (20.1.4)
Since the number of different selected sets is M!
N!(M−N)! =

M
N

, the corresponding
determinants are a basis for an 
M
N

-dimensional vector space, {|Ψ(N)
i}, where the
proper states of an N-electron system are the span of {|Ψ(N)
i}:
|Ψ
(N)
i = ∑
{l1,l2,...lN}
a{l1,l2,...,lN}
|Ψ
(N)
{l1,l2,...,lN}
i. (20.1.5)
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press433 20.1 The Fock Space
Now let us notice that a formal representation of an N-particle state within the space
of N
0 particles, with N
0 6= N, corresponds to an improper (un-normalizable) state. Con￾sidering an extended vector space that is the direct sum of all the N-particle vector
spaces, the inner product between vectors associated with different particle numbers
within this space must therefore vanish:
D
Ψ
(N)
{l1,l2,...,lN}



Ψ
(N
0
)
{l1
0
,l2
0
...,lN0
0
}
E
= δN,N0δ{l1,l2,...,lN},{l1
0
,l2
0
,...,lN
0
}
. (20.1.6)
Particularly, any N-particle state is orthogonal to the state of “no particles,” cor￾responding to N = 0. This state is termed “the vacuum state,” which we denote
as |Ψ(0)
i. The extended vector space, which is the span of the extended basis,
|Ψ(0)
i,{|Ψ(1)
i},{|Ψ(2)
i},...,{|Ψ(M−1)
i},|Ψ(M)
i, is termed the Fock space. Each basis
vector corresponds to a specific selection of single-particle states to be “occupied,”
out of the total number of M. Since in each basis vector, each single-particle state is
either occupied or not (only two possibilities, in line with Pauli’s exclusion principle,
discussed in Section 13.3), the total number of possibilities of occupying the M single￾particle states is 2
M, which is the dimension of the Fock space,
M
∑
N=0

M
N

= 2
M. It is
convenient to represent each basis vector in terms of a binary string, |n1,n2,n3,...,nMi,
corresponding to the “occupation number” of each of the M single-particle states,
{|Φ1i,|Φ2i,...,|ΦMi}, where “occupied” and “unoccupied” states are associated with
nl = 1 and nl = 0, respectively:



Ψ
(N)
{l1,l2,l3,...,lN}
E
=

n1,n2,n3,...,nM

; nl =
(
1 ; l ∈ {l1,l2,...,lN}
0 ; otherwise
.
(20.1.7)
(For example, if the total number of single-particle states is M = 6, and the indexes
of the occupied states are {l1,l2,l3} = {2,3,5}, the corresponding basis state would
be denoted as |Ψ
(3)
{2,3,5}
i = |0,1,1,0,1,0i). Using this notation, the representation of
the vacuum state would be |Ψ(0)
i = |0,0,0,...,0i, the M basis states associated with a
single particle in the system would be represented as
{|Ψ
(1)
i} =



|Ψ
(1)
{1}
i = |1,0,0,...,0i
|Ψ
(1)
{2}
i = |0,1,0,...,0i
|Ψ
(1)
{3}
i = |0,0,1,...,0i
.
.
.
|Ψ
(1)
{M}
i = |0,0,0,...,1i



,
the M(M − 1)/2 basis states associated with two particles in the system would be
represented as
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press434 Open Many-Fermion Systems
{|Ψ
(2)
i} =



|Ψ
(2)
{1,2}
i = |1,1,0,...,0i
|Ψ
(2)
{2,3}
i = |0,1,1,...,0i
|Ψ
(2)
{1,3}
i = |1,0,1,...,0i
.
.
.



,
and so forth, where the representation of the fully occupied state would be |Ψ(M)
i =
|1,1,1,...,1i. Recalling that (except for the vacuum state) each basis state is identified
with a determinant (see Eq. (20.1.3)), the sign of each state depends on the order of
the occupied single-particle state indexes, where for a fixed order, l1 < l2 < ... < lN,
{lj} ∈ 1,2,...,M, the signs of all basis states are uniquely defined.
Exercise 20.1.1 Write the binary strings for the 16 basis vectors defined by four single￾particle states, {|Φ1i,|Φ2i,|Φ3i,|Φ4i}.
Fock Space Operators
We now define operators in Fock space. Of particular importance are the operators
that couple between the subspaces of different particle numbers. The electron creation
operator in the lth single-particle state is denoted aˆ
†
l
and can be defined by its operation
on the vacuum state,
aˆ
†
l
|Ψ
(0)
i ≡ |Ψ
(1)
{l}
i. (20.1.8)
The Hermitian conjugate of aˆ
†
l
is denoted aˆl
, and defined as usual (see Eq. (11.2.18)),
hΨ(0)
|aˆl = hΨ
(1)
{l}
|. Using the normalization conditions (Eq. (20.1.6)), we obtain
(Ex. 20.1.2)
aˆl
|Ψ
(1)
{l}
i = |Ψ
(0)
i, (20.1.9)
which associates the operator aˆl with electron annihilation at the lth single-particle
state.
Exercise 20.1.2 Use the normalization conditions (Eq. (20.1.6)), D
Ψ
(1)
{l}



Ψ
(1)
{l}
E
= 1,
and hΨ(0)
|Ψ(0)
i = 1, and the definition of the creation operator (Eq. (20.1.8)) to derive
Eq. (20.1.9).
Since an attempt to occupy the same single-particle state twice would correspond
to a vanishing determinant (see Eq. (20.1.3)), we have aˆ
†
l
|Ψ
(1)
{l}
i = (aˆ
†
l
)
2
|Ψ
(0)
{l}
i = 0. Sim￾ilarly, the number of particles in a given single-particle state cannot be smaller than
zero, which means that aˆl
|Ψ(0)
i must be orthogonal to any state in the Fock space, and
therefore, aˆl
|Ψ(0)
i = (aˆl)
2
|Ψ
(1)
{l}
i = 0. These requirements can be summarized as
(aˆ
†
l
)
2 = (aˆl)
2 = 0. (20.1.10)
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press435 20.1 The Fock Space
We can readily verify that aˆl and aˆ
†
l
are non-Hermitian operators (Ex. 20.1.3). Their
product, aˆ
†
l
aˆl
, is Hermitian, where
aˆ
†
l
aˆl
|Ψ
(0)
i = 0|Ψ
(0)
i
aˆ
†
l
aˆl
|Ψ
(1)
{l}
i = 1|Ψ
(1)
{l}
i
. (20.1.11)
Both the unoccupied (|Ψ(0)
i) and singly occupied (|Ψ
(1)
{l}
i)states are eigenstates of aˆ
†
l
aˆl
,
with eigenvalues corresponding to the number of electrons occupying the l
th single￾particle state, Nl ∈ 0,1. The operator aˆ
†
l
aˆl can therefore be identified as a physical
observable corresponding to the electron number,
aˆ
†
l
aˆl ≡ Nˆ
l
. (20.1.12)
Similarly,
aˆlaˆ
†
l
|Ψ
(0)
i = 1|Ψ
(0)
i
aˆl aˆ
†
l
|Ψ
(1)
{l}
i = 0|Ψ
(1)
{l}
i
, (20.1.13)
the eigenvalues of aˆlaˆ
†
l
correspond to complementary numbers of “electron vacancies”
or “holes” associated with the occupied and the empty states of the lth single-particle
state. The operator aˆlaˆ
†
l
can therefore be identified as an observable corresponding to
the hole number,
aˆlaˆ
†
l ≡ 1−Nˆ
l
. (20.1.14)
Combining Eqs. (20.1.12, 20.1.14), the operators aˆl and aˆ
†
l
are shown to satisfy an
“anti-commutation” relation,
{aˆ
†
l
,aˆl} ≡ aˆ
†
l
aˆl +aˆlaˆ
†
l = 1. (20.1.15)
The proper two-electron basis states can be obtained by selecting two single-particle
states out of the ordered list, {|Φ1i,|Φ2i,...,|ΦMi}. Selecting the states|Φl
0i, and |Φl
0i,
where, l < l
0
, the corresponding two-particle state is the determinant, |Ψ
(2)
{l,l
0}
i (see
Eq. (20.1.3)). This basis state is obtained from the vacuum by two successive operations
of the relevant creation operators, namely,
|Ψ
(2)
{l,l
0}
i ≡ aˆ
†
l
|Ψ
(1)
{l
0}
i = aˆ
†
l
aˆ
†
l
0
|Ψ
(0)
i, (20.1.16)
and similarly (see Ex. 20.1.4),
|Ψ
(0)
i = aˆl
0|Ψ
(1)
{l
0}
i = aˆl
0aˆl
|Ψ
(2)
{l,l
0}
i. (20.1.17)
Recalling that exchanging two columns in a determinant is associated with a sign flip,
|Ψ
(2)
{l,l
0}
i = −|Ψ
(2)
{l
0
,l}
i, (20.1.18)
it follows that changing the order of the two creation operators corresponds to a change
of sign, which, together with Eq. (20.1.10), leads to the anti-commutation relations (see
Ex. 20.1.5),
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press436 Open Many-Fermion Systems
{aˆ
†
l
,aˆ
†
l
0} = 0 ; {aˆl
,aˆl
0} = 0. (20.1.19)
Additionally, using Eqs. (20.1.16, 20.1.17), we obtain,



Ψ
(1)
{l
0}
E
= −aˆl



Ψ
(2)
{l
0
,l}
E
=
−aˆ
l
aˆ
†
l
0aˆ
†
l
|Ψ(0)
i, and



Ψ
(1)
{l
0}
E
= aˆ
†
l
0
|Ψ(0)
i = aˆ
†
l
0aˆlaˆ
†
l
|Ψ(0)
i, and therefore aˆ
†
l
0aˆl = −aˆlaˆ
†
l
0
.
Recalling Eq. (20.1.15), the result reads
{aˆl
,aˆ
†
l
0} = δl,l
0. (20.1.20)
Exercise 20.1.3 Recalling the definition of a Hermitian operator (Eq. (11.2.20)), use
the matrix elements of the operators, aˆ
†
l
and aˆl
, between the states,



Ψ(0)
E
and



Ψ
(1)
{l}
E
, to
show that these operators are non-Hermitian.
Exercise 20.1.4 Use the normalization conditions (Eq. (20.1.6)), hΨ(0)
|Ψ(0)
i = 1, D
Ψ
(1)
{l}



Ψ
(1)
{l}
E
= 1,
D
Ψ
(2)
{l,l
0}



Ψ
(2)
{l,l
0}
E
= 1, and Eq. (20.1.16), to derive Eq. (20.1.17).
Exercise 20.1.5 Use Eqs. (20.1.16, 20.1.18) to derive Eq. (20.1.19).
The canonical anti-commutation relations for the fermionic creation and annihila￾tion operators (Eqs. (20.1.19, 20.1.20)) apply to all the single-particle states. Indeed,
any many electron basis vector can be represented in terms of the set of operators,
{aˆ
†
l
}, where, for an ordered sequence, {|Φ1i,|Φ2i,...,|ΦMi}, and for l1 < l2 < ... < lN,



Ψ
(N)
{l1,l2,...,lN}
E
≡ aˆ
†
l1



Ψ{l2,...,lN}
E
= aˆ
†
l
aˆ
†
l2
aˆ
†
l3
···aˆ
†
lN
|Ψ
(0)
i. (20.1.21)
Notice that since |Ψ
(N)
{l
0
,l
00
,...}
i corresponds to a determinant (Eq. (20.1.3)), the opera￾tor aˆ
†
l
|Ψ
(N)
{l
0
,l
00
,...}
i (with l < l
0
,l
00
,...) corresponds to an extended determinant in which
a (first) row and a column are added. In binary string representation (Eq. (20.1.7)),
Eq. (20.1.21) can also be written as
|n1,n2,n3,...,nMi = (aˆ
†
1
)
n1 (aˆ
†
2
)
n2
···(aˆ
†
M)
nM |Ψ
(0)
i ; nl =
(
1 ; l ∈ {l1,l2,...,lN}
0 ; otherwise
,
(20.1.22)
where, (aˆ
†
l
)
0 = 1 and (aˆ
†
l
)
1 = aˆ
†
l
. Considering an N-electron system in a state,
|n1,n2,...,nMi, an electron creation in the kth single-particle state can therefore be
represented as
aˆ
†
k
|n1,n2,...,nMi =



0 ; nk = 1
(−1)
k−1
∑
j=1
nj
|n1,...,nk +1,...,nMi ; nk = 0
. (20.1.23)
Notice that the state of the N + 1-electron system is a standard determinant (as
defined by Eqs. (20.1.3, 20.1.7)), multiplied by an appropriate (Jordan–Wigner) phase,
(−1)
∑
k−1
j=1
nj
(see Ex. 20.1.6).
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press437 20.1 The Fock Space
Similarly, an electron annihilation from the kth single-particle state is represented as
aˆk
|n1,n2,...,nMi =



0 ; nk = 0
(−1)
k−1
∑
j=1
nj
|n1,...,nk −1,...,nMi ; nk = 1
. (20.1.24)
Notice that the occupation number of the kth single-particle state in the N-electron
system is an eigenvalue of the number operator, Nˆ
k ≡ aˆ
†
k
aˆk (see Eq. (20.1.12)),
aˆ
†
k
aˆk
|n1,n2,...,nMi = nk
|n1,n2,...,nMi. (20.1.25)
Associating the total number of electrons in the state |n1,n2,...,nMi with the total
number operator,
Nˆ ≡
M
∑
k=1
Nˆ
k =
M
∑
k=1
aˆ
†
k
aˆk
, (20.1.26)
any basis vector is an eigenvector of Nˆ ,
Nˆ |n1,n2,...,nMi = N|n1,n2,...,nMi ; N =
M
∑
k=1
nk
, (20.1.27)
where the total number of electrons is the corresponding eigenvalue.
Exercise 20.1.6 Use the anti-commutation relations for the fermion operators
(Eqs. (20.1.19, 20.1.20)), and Eqs. (20.1.21, 20.1.22) to derive Eqs. (20.1.23, 20.1.24).
Matrix Representations
For one single-particle state (M = 1), the dimension of the Fock space is 2
1 = 2, where
the space is the span of two basis vectors corresponding to the occupied and unoc￾cupied single-particle states, |1i and |0i, respectively. Given a general state, |ψi =
ψ1|1i+ψ0|0i, the corresponding vector representation reads (Eq. (11.2.7))
ψ =

ψ1
ψ0

=

h1|ψi
h0|ψi

, (20.1.28a)
where the two basis vectors are unit vectors,
e1 =

1
0

; e0 =

0
1

. (20.1.28b)
The creation and annihilation operators for an electron are defined by the equations,
aˆ
†
|0i = |1i, aˆ
†
|1i = 0, and aˆ|1i = |0i, aˆ
†
|1i = 0, respectively (Eqs. (20.1.8, 20.1.9)).
Consequently, the matrix representations of these operators in the basis {|1i |0i} read
(Eqs. (11.2.11, 11.2.12))
a =

0 0
1 0 
; a
† =

0 1
0 0 
. (20.1.29)
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press438 Open Many-Fermion Systems
Similarly, the matrix representations of the electron and hole number operators,
Eqs. (20.1.12, 20.1.14), read (Ex. 20.1.7)
a
†
a =

1 0
0 0 
; aa† =

0 0
0 1 
. (20.1.30)
We can readily verify that the matrix representations satisfy the anti-commutation
relations, Eqs. (20.1.19, 20.1.20):
{a
†
,a
†
} = 0 ; {a,a} = 0 ; {a
†
,a} = I ; I =

1 0
0 1 
(20.1.31)
Exercise 20.1.7 Use the definitions aˆ
†
|0i=|1i, aˆ
†
|1i=0, aˆ|1i=|0i, and aˆ
†
|1i = 0
to derive the (two-by-two) matrix representations of the operators, aˆ
†
, aˆ, aˆ
†aˆ, and
aˆaˆ
†
in the complete orthonormal basis {|0i,|1i}. Show that these matrices satisfy the
anti-commutation relation, Eq. (20.1.31).
For a system with many single-particle states (M > 1), the dimension of the Fock
space is 2
M. This space is an ordered tensor product of M subspaces, corresponding to
the the different single-particle states. Therefore, each basis vector of the Fock space
is a tensor product of M basis vectors, each associated with one of the single-particle
occupation states
|n1,n2,n3,....nMi = |n1i ⊗ |n2i ⊗ ··· ⊗|nMi ; nj ∈ {0,1}. (20.1.32)
For example, a basis vector, |0,1,...,1,0i, corresponds to a tensor product,
|0,1,...,1,0i ⇔
1

0
1

⊗
2

1
0

⊗···⊗
M −1

1
0

⊗
M

0
1

. (20.1.33)
Using the vector representations, Eq. (20.1.28b), the basis vector is represented as a
2
M-dimensional unit vector,
e0,1,...,1,0 = e0 ⊗e1 ⊗··· ⊗e1 ⊗e0. (20.1.34)
Electron creation and annihilation operators in the 2
M-dimensional Fock space are
tensor products of operators in the M subspaces of the single-particle states. Accord￾ing to Eq. (20.1.23), the operator aˆ
†
k
, which creates an electron in the kth single-particle
state, maintains the occupation numbers in all the other single-particle states, and mul￾tiplies the many-particle state by −1, for each occupied single-particle state whose
index is smaller than k (the Jordan–Wigner phase). The matrix representation of aˆ
†
k
,
denoted as a
†
k
, must therefore satisfy the equation
a
†
k
· en1,n2,...,nk
,...,nM =



0 ; nk = 1
(−1)
k−1
∑
j=1
nj
en1,n2,...,1,...,nM
; nk = 0
. (20.1.35)
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press439 20.1 The Fock Space
We can readily verify that the matrix a
†
k
reads
a
†
k =
1

−1 0
0 1 
⊗
2

−1 0
0 1 
⊗···⊗
k −1

−1 0
0 1 
⊗
k

0 1
0 0 
⊗
k −1

1 0
0 1 
⊗···⊗
M −1

1 0
0 1 
⊗
M

1 0
0 1 
, (20.1.36)
where, for any j < k, the identity matrix is replaced by 
−1 0
0 1 
= −1

1 0
0 0 
+
1

0 0
0 1 
. This means that the result accumulates a phase “1” if the jth state is empty,
and a phase “−1” if the jth state is occupied.
Similarly, the matrix representation of the annihilation operator, aˆk
, which complies
with Eq. (20.1.24), reads
ak =
1

−1 0
0 1 
⊗
2

−1 0
0 1 
⊗···⊗
k −1

−1 0
0 1 
⊗
k

0 0
1 0 
⊗
k +1

1 0
0 1 
⊗···⊗
M −1

1 0
0 1 
⊗
M

1 0
0 1 
.
(20.1.37)
We can verify (Ex. 20.1.8) that these matrix representations of the creation
and annihilation operators satisfy the canonical anti-commutation relations,
Eqs. (20.1.19, 20.1.20).
Exercise 20.1.8 Show that the matrix representations of the creation and annihilation
operators (Eqs. (20.1.36, 20.1.37)) satisfy the canonical anti-commutation relations for
fermions, Eqs. (20.1.19, 20.1.20). (You can use the rules of tensor products multiplica￾tion, Eq. (11.6.21).)
For concreteness, let us consider the Fock space for M = 2, which is the span of four
(2
2
) basis vectors, corresponding to the single-particle state occupation vectors, |1,1i,
|1,0i,|0,1i, |0,0i,
e1,1 =

1
0

⊗

1
0

=


1
0
0
0


e1,0 =

1
0

⊗

0
1

=


0
1
0
0


https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press440 Open Many-Fermion Systems
e0,1 =

0
1

⊗

1
0

=


0
0
1
0


(20.1.38)
e0,0 =

0
1

⊗

0
1

=


0
0
0
1

.
Using Eqs. (20.1.36, 20.1.37), the creation and annihilation operators are represented
as
aˆ
†
1 ≡

0 1
0 0 
⊗

1 0
0 1 
=


0 0 1 0
0 0 0 1
0 0 0 0
0 0 0 0


;
aˆ1 ≡

0 0
1 0 
⊗

1 0
0 1 
=


0 0 0 0
0 0 0 0
1 0 0 0
0 1 0 0


aˆ
†
2 ≡

−1 0
0 1 
⊗

0 1
0 0 
=


0 −1 0 0
0 0 0 0
0 0 0 1
0 0 0 0


;
aˆ2 ≡

−1 0
0 1 
⊗

0 0
1 0 
=


0 0 0 0
−1 0 0 0
0 0 0 0
0 0 1 0

. (20.1.39)
It is easy to test explicitly (Ex. 20.1.9) that these matrix representations satisfy the
canonical anti-commutation relations, Eqs. (20.1.19, 20.1.20), as well as Eqs. (20.1.23,
20.1.24).
Exercise 20.1.9 Let us consider the Fock space corresponding to the two single￾particle states, {|Φ1i,|Φ2i}, with the basis vectors, |1,1i,|1,0i,|0,1i,|0,0i. (a) Use
Eqs. (20.1.23, 20.1.24) to show that
aˆ
†
1
|0,0i = |1,0i ; ˆa
†
1
|0,1i = |1,1i ; ˆa
†
1
|1,0i = aˆ
†
1
|1,1i = 0
aˆ1|1,0i = |0,0i ; ˆa1|1,1i = |0,1i ; ˆa1|0,0i = aˆ1|0,1i = 0
aˆ
†
2
|0,0i = |0,1i ; ˆa
†
2
|1,0i = −|1,1i; ˆa
†
2
|0,1i = aˆ
†
2
|1,1i = 0
aˆ2|1,1i = −|1,0i; ˆa2|0,1i = |0,0i ; ˆa2|1,0i = aˆ2|0,0i = 0.
(b) Obtain the matrix representations of the creation and annihilation operators in the
basis {|1,1i, |1,0i, |0,1i, |0,0i}, and compare the results to Eq. (20.1.39). (c) Check
that the four matrices satisfiy the anti-commutation relations for fermions, Eqs. (20.1.19,
20.1.20).
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press441 20.2 The Second Quantization Hamiltonian
20.2 The Second Quantization Hamiltonian
We now turn to the representation of the Hamiltonian of a system of an indefinite
number of electrons in the Fock space of M single-particle states. Since, by construc￾tion, the Fock space is a direct sum of N-particle subspaces, |Ψ(0)
i,{|Ψ(1)
i},{|Ψ(2)
i},
{|Ψ(M−1)
i},|Ψ(M)
i, the projection of the Fock space Hamiltonian, Hˆ, onto each N￾particle subspace spanned by ({|Ψ(N)
i}) must coincide with the corresponding N￾particle Hamiltonian, Hˆ (N)
(Eq. (20.1.1)). Using a projection into the N-particle sub￾space, PˆN = ∑{l1,l2,l3,...,1N}



Ψ
(N)
{11,l2,l3,...,lN}
EDΨ
(N)
{l1,l2,l3,...,lN}


, this condition formally reads
∑
{l1,l2,l3,...,lN},{l
0
1
,l
0
2
,l
0
3
,...,l
0
N
}
D
Ψ
(N)
{l1,l2,l3,...,lN}



Hˆ
(N)



Ψ
(N)
{l
0
1
,l
0
2
,l
0
3
,...,l
0
N
}
E



Ψ
(N)
{l1,l2,l3,...,lN}
EDΨ{l
0
1
,l
0
2
,l
0
3
,...,l
0
N
}


 = Hˆ
(N)
, (20.2.1)
or, considering any matrix element of Hˆ (N)
,
D
Ψ
(N)
{l
0
1
,l
0
2
,l
0
3
,...,l
0
N
}



Hˆ



Ψ
(N)
{l1,l2,l3,...,lN}
E
=
D
Ψ
(N)
{l
0
1
,l
0
2
,l
0
3
,...,l
0
N
}



Hˆ
(N)



Ψ
(N)
{l1,l2,l3,...,lN}
E
. (20.2.2)
We can verify that the Fock space Hamiltonian that complies with this identity for any
fixed number of electrons (N ≤ M) reads
Hˆ =
M
∑
i, j=1
hi, jaˆ
†
i
aˆj +
1
2
M
∑
i, j,k,l=1
wi, j,k,laˆ
†
i
aˆ
†
j
aˆlaˆk
, (20.2.3)
where the scalar parameters correspond to spin orbitals (|Φji ≡ |φji ⊗ |σms, j
i, see Eq.
(13.3.16)),
hi, j ≡ hΦi
|hˆ|Φji = δms,i
,ms, j
w
drφ
∗
i
(r)
"
−h¯
2
2me
4r +V ˆ(r)
#
φj(r)
wi, j,k,l ≡ hΦi
| ⊗ hΦj
|wˆ|Φki ⊗|Φli = δms,i
,ms,k
δms, j
,ms,lKe2
w
dr
w
dr
0
φ
∗
i
(r)φ
∗
j
(r
0
)φk(r)φl(r
0
)
|r−r
0
|
(20.2.4)
Particularly, the diagonal matrix elements of Hˆ read (see Ex. 20.2.1)
D
Ψ
(N)
{l1,l2,...,lN}



Hˆ



Ψ
(N)
{l1,l2,...,lN}
E
= E{l1,l2,...,lN} =
N
∑
j∈{l1,l2,...,lN}=1
hj, j +
1
2
N
∑
i, j∈{l1,l2,...,lN}=1
(wi, j,i, j −wi, j, j,i)
. (20.2.5)
As we can see, this result identifies with the expectation value of the N-electron Ham￾iltonian, with a single determinant state, as derived in Chapter 13 in the context of the
Hartree–Fock approximation (see Eqs. (13.3.26–13.3.28) and Ex. 13.3.6). Notice that
wi, j,i, j and wi, j, j,i are the Coulomb and exchange integrals, respectively.
Exercise 20.2.1 (a) Using the binary string representation of a single determinant state
(Eq. (20.1.7)), show that the expectation value of the second quantization Hamiltonian,
Eqs. (20.2.3, 20.2.4), is given by Eq. (20.2.5). Compare the result to Ex. 13.3.6 for the
energy expectation value of a single N-electron determinant. (b) Generalize the result of
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press442 Open Many-Fermion Systems
Ex. 13.3.6 for off-diagonal Hamiltonian matrix elements between different determinants,
D
Ψ
(N)
{l
0
1
,l
0
2
,l
0
3
,...,l
0
N
}



Hˆ (N)



Ψ
(N)
{l1,l2,l3,...,lN}
E
, and show that the result coincides with the second
quantization Hamiltonian matrix elements, D
Ψ
(N)
{l
0
1
,l
0
2
,...,l
0
N
}



Hˆ



Ψ
(N)
{l1,l2,l3,...,lN}
E
.
In closed many-electron systems both the interaction wˆi, j and the external poten￾tial (associated with hˆ
i) conserve the number of particles. Therefore, the Fock space
Hamiltonian must not couple between subspaces corresponding to different particle
numbers. To see that the Hamiltonian Hˆ in Eq. (20.2.3) complies with this require￾ment, we first notice that it commutes with the total electron number operator (see
Eq. (20.1.26) and Ex. 20.2.2),
[Hˆ,Nˆ ] = 0. (20.2.6)
Recalling that the basis vectors are eigenstates of the Hermitian number oper￾ator (Eq. (20.1.27)), we have D
Ψ
(N
0
)
{l
0
1
,l
0
2
,...,l
0
N0
}



HˆNˆ



Ψ
(N)
{l1,l2,...,lN}
E
= N
D
Ψ
(N
0
)
{l
0
1
,l
0
2
,...,l
0
N0
}



Hˆ



Ψ
(N)
{l1,l2,...,lN}
E
, and, D
Ψ
(N
0
)
{l
0
1
,l
0
2
,...,l
0
N0
}



Nˆ Hˆ



Ψ
(N)
{l1,l2,...,lN}
E
= N
0
D
Ψ
(N
0
)
{l
0
1
,l
0
2
,...,l
0
N0
}



Hˆ



Ψ
(N)
{l1,l2,...,lN}
E
.
Eq. (20.2.6) therefore means that
D
Ψ
(N
0
)
{l
0
1
,l
0
2
,...,l
0
N0
}



Hˆ



Ψ
(N)
{l1,l2,...,lN}
E
=
D
Ψ
(N
0
)
{l
0
1
,l
0
2
...,l
0
N0
}



Hˆ
(N)



Ψ
(N)
{l1,l2,...,lN}
E
δN,N0. (20.2.7)
The conservation of particle number is therefore reflected in a block-diagonal structure
of the Fock space Hamiltonian.
Exercise 20.2.2 (a) Use the anti-commutation relations for fermion creation and anni￾hilation operators (Eqs. (20.1.19, 20.1.20)) and the definition of the electron number
operator (Eq. (20.1.26)) to show that [aˆ
†
j
,Nˆ ] = −aˆ
†
j
, and [aˆj
, Nˆ ] = aˆj
. (b) Use the
general operator identity, [AˆBˆ,Cˆ] = Aˆ[Bˆ,Cˆ] + [Aˆ,Cˆ]Bˆ, and the result of(a) to show that
[aˆ
†
i
aˆj
,Nˆ ] = 0. (c) Use the results of (a) and (b) to show that the second quantization
Hamiltonian (Eq. (20.2.3)) commutes with the total electron number operator.
Exercise 20.2.3 Show that the second quantization Hamiltonian (Eq. (20.2.3)) for a
system of two orthonormal single-particle states (|Φ1i and |Φ2i, selected as the eigen￾states of the single-particle Hamiltonian, hi, j = ε jδi, j) reads Hˆ = ε1aˆ
†
1
aˆ1 + ε2aˆ
†
2
aˆ2 +
Uaˆ
†
1
aˆ1aˆ
†
2
aˆ2, where U = (w1,2,1,2 −w1,2,2,1).
Notice that by selecting an infinite set of single-particle states, the Fock space
becomes a Hilbert space of infinite dimensions (see Section 11.2). Moreover, it is
often convenient to extend the Fock space by selecting a continuous, improper (see
Section 11.3) set of single-particle states. A commonly used choice associates the
single-particle states with “spin orbitals” (see Chapter 13), which are products of
eigenstates of the position and spin operators, {|φri ⊗ |σi}(σ ∈ (1/2,−1/2)), with
the orthonormalization condition, hφr
0| ⊗ hσ
0
| · |φri ⊗ |σi = δσ,σ0δ(r − r
0
). Consider￾ing a generic orthonormal system of single electron states (spin orbitals) as discussed
above, {|Φki} ≡ {|φki ⊗ |σki}, and recalling the definition of a wave function in the
position representation, φk(r) = hφr|φki (Eq. (11.6.28)), we can use the expansion,
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press443 20.3 Fermi–Dirac Distribution
|φri ⊗ |σi =
∞
∑
k=1
δσk
,σφ
∗
k
(r)|Φki. Since an electron at a spin state |σi in a position, r,
is represented as a linear combination of the generic set {|Φki}, the corresponding
electron creation operator is a linear combination of the creation operators within the
set,
ψˆ
†
r,σ =
∞
∑
k=1
δσk
,σφ
∗
k
(r)aˆ
†
k
, (20.2.8)
where it is emphasized that the index “k” corresponds to a specific spin-orbital. Simi￾larly, the annihilation of an electron at spin state |σi in a position, r, is given by taking
the Hermitian conjugate,
ψˆ r,σ =
∞
∑
k=1
δσk
,σφk(r)aˆk
. (20.2.9)
The operators ψˆ
†
r,σ and ψˆ r,σ are referred to as “field operators,” which satisfy the
following anti-commutation relations (Ex. 20.2.4):
{ψˆ
†
r,σ
,ψˆ r
0
,σ0} = δσ,σ0δ(r−r
0
)
{ψˆ
†
r,σ
,ψˆ
†
r
0
,σ0} = 0 (20.2.10)
{ψˆ r,σ,ψˆ r
0
,σ0} = 0
The expression of the many-electron Hamiltonian in terms of the field operators reads
(see Eq. (20.2.4) and Ex. 20.2.5)
Hˆ = ∑σ
w
drψˆ
†
r,σhˆψˆ r,σ +
1
2 ∑
σ,σ0
w
dr
w
dr
0ψ
†
r,σψˆ
†
r
0
,σ0wˆψˆ r
0
,σ0ψˆ r,σ. (20.2.11)
Exercise 20.2.4 Use the anti-commutation relations for fermion creation and anni￾hilation operators (Eqs. (20.1.19, 20.1.20)), and the definition of the field operators
(Eqs. (20.2.8, 20.2.9)) to derive Eq. (20.2.10). Recall the formal definition of Dirac’s
delta in terms of a complete orthonormal set, Eq. (11.3.12).
Exercise 20.2.5 Accounting explicitly for the spin, σk
, associated with each kth sin￾gle particle state, the second quantization Hamiltonian (Eq. (20.2.3)) reads Hˆ =
∞
∑
k,k
0=1
δσ
0
k
,σk
hk,k
0aˆ
†
k
aˆk
0 +
1
2
∞
∑
i, j,k,l=1
δσl
,σi
δσk
,σ jwi, j,k,laˆ
†
i
aˆ
†
j
aˆlaˆk
. Use the definitions of the field
operators to derive this result from Eq. (20.2.11).
20.3 Fermi–Dirac Distribution
Of special interest are open systems of many identical fermions, in the absence of inter￾particle interaction (a “Fermi gas”). This is a commonly used idealized (mean-field
based) model that approximates to some extent single-electron observables in bulk met￾als. Therefore, it is useful for modeling an “electron reservoir.” Here we focus on the
equilibrium state for such a reservoir, and in the following sections we shall discuss
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press444 Open Many-Fermion Systems
exchange of charge carriers between a macroscopic fermion reservoir (e.g., an elec￾trode surface) and a smaller system of interest coupled to it (e.g., an impurity such as
an atom, molecule, or a quantum dot, adsorbed on that surface).
Let us choose an orthonormal set of single-particle states, as the eigenstates of the
underlying singe-particle Hamiltonian, defined by the equation
hˆ|Φki = εk
|Φki. (20.3.1)
Each |Φki corresponds to some spatial wave function and a spin state. The correspond￾ing fermion number operator reads in this case
Nˆ = ∑
k
aˆ
†
k
aˆk
, (20.3.2)
and, in the absence of interactions, the Fock space Hamiltonian reads (Eqs. (20.2.3,
20.2.4))
Hˆ = ∑
k
εkaˆ
†
k
aˆk
. (20.3.3)
In Chapter 16 we encountered the generic form of the equilibrium density operator
for a grand canonical ensemble, namely for an open many-particle system, with fixed
averages of energy and particle number per state (Eq. (16.5.25)). Using Eqs. (20.3.2,
20.3.3), the equilibrium density operator for a system of noninteracting fermions reads
ρˆ
(eq) =
e
−1
kBT ∑k
(εk−µ)aˆ
†
k
aˆk
tr{e
−1
kBT ∑
k
(εk−µ)aˆ
†
k
aˆk
}
, (20.3.4)
0
µ
0.2
0.4
0.6
Occupation probability
0.8
Energy
1
1.2
Ftigure 20.3.1 The Fermi–Dirac distribution function, representing the occupation probability per single-particle state in a system of
noninteracting fermions at thermal equilibrium, as a function of energy. The sharp step marks the position of the
chemical potential and corresponds to the zero-temperature limit. The distribution is broadened at a finite
temperature, as shown by the dotted curve.
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press445 20.4 Impurity Models
where kB is Boltzmann’s constant, T is the absolute temperature, and µ is the chemical
potential. Of particular importance is the average occupation number of each single￾particle state at equilibrium, defined as Nl = tr{Nˆ
lρˆ
(eq)} = tr{aˆ
†
l
aˆlρˆ
(eq)}. Using the
explicit expression for ρˆ
(eq)
, we obtain (see Ex. 20.3.1)
Nl =
1
1+e
(εl−µ)/(kBT)
. (20.3.5)
This result is known as the Fermi–Dirac distribution (see Fig. 20.3.1). It defines occu￾pation at each single-particle state (e.g., each spin orbital), according to the state energy
(εl), and the macroscopic parameters corresponding to the reservoir temperature (T)
and its chemical potential (µ). At zero temperature, all the single-particle states whose
energy is less than µ are fully occupied, whereas states at energy greater than µ are
empty. (This reproduces Pauli’s exclusion principle and the Aufbau principle, discussed
in Section 13.3 in the context of the electronic ground state of N-electron systems.) At
finite temperatures, the equilibrium distribution broadens, where there is a finite proba￾bility to find electrons at energies greater than the chemical potential, as well as electron
vacancies (holes) at energies less than µ. Referring to the limit of a continuous (and
nondegenerate) spectrum of the reservoir, the Fermi–Dirac distribution translates into
continuous functions of the energy
fe(ε) = 1
1+e
(ε−µ)/(kBT)
; fh(ε) = 1− fe(ε), (20.3.6)
where fe(ε) and fh(ε) are the probability densities of finding an electron or a hole,
respectively, at the energy ε within the reservoir.
Exercise 20.3.1 (a) Recalling that the trace of a tensor product of operators is a product
of their traces, tr{Aˆ
1 ⊗Aˆ
2 ⊗ ··· ⊗Aˆ
N} = tr{Aˆ
1} ·tr{Aˆ
2}...tr{Aˆ
N} (Ex. 15.5.1), use the
commutativity of the number operators associated with the single-particle states to show
that tr{Nˆ
lρˆ
(eq)} = trl{aˆ
†
l
aˆle
−1
kBT
(εl−µ)aˆ
†
l
aˆl
}/trl{e
−1
kBT
(εl−µ)aˆ
†
l
aˆl
}. (b) Calculate explicitly
the trace in the subspace of the lth single-particle state to derive Eq. (20.3.5).
20.4 Impurity Models
In many cases our focus of interest is a “small” system of fermions, which can exchange
particles with a “large” fermion reservoir. A typical example is a molecule, adsorbed
on the surface of a single crystal of bulk material. The interaction with the surface may
lead to charging/discharging of the molecule, and consequently, to affecting its stable
conformation, its binding energy to the surface, and even its chemical stability, induc￾ing a chemical reaction. (This is the underlying principle of heterogeneous catalysis.)
The system and the reservoir are different in many ways. For starters, while the sys￾tem length scale is on the order of a nanometer, the bulk to which it is coupled may
be macroscopically large. Additionally, the system is associated with a unique compo￾sition (e.g., specific atoms), whereas the bulk contains numerous replicas of identical
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press446 Open Many-Fermion Systems
unit cells. Finally, we are naturally interested in the effect of the reservoir on the small
system observables, where the system needs to be modeled in some detail. The comple￾mentary effect of the system on the reservoir is often negligible, and in these cases, the
fine details of the reservoir model are of less importance. The convenient partitioning
of the entire system into a “small system of interest” and a reservoir is particularly
instrumental when the coupling between these two subsystems is sufficiently weak, as
discussed extensively in Chapter 19.
Focusing on exchange of particles between the system and the reservoir, it is natural
to invoke some local basis for the single-particle Hilbert space, in which each basis state
corresponds to a particle being either “inside” or “outside” the system. A commonly
invoked approach relies on the tight-binding approximation in which the basis for the
single-particle space is assumed to be both orthonormal and local (see Sections 14.4
and 14.5).
As a concrete example, let us consider an adsorbate on top of a bulk conductor
(an “electrode”). A minimal tight binding model for the single-particle Hamilto￾nian [5.6] associates the adsorbate with a single terminal site, and the electrode
with a semi-infinite uniform linear chain of sites (see Section 14.5 and Fig. 20.4.1).
Invoking a basis of orthonormal localized states, hφn|φn
0i = δn,n
0 , where |φ0i and
{|φ1i,|φ2i,|φ3i...,|φME
i} correspond to the adsorbate and conductor sites, respec￾tively, the matrix representation of the single-particle Hamiltonian reads
h =








ε0 γ 0
γ µ β
β
.
.
.
.
.
.
.
.
.
.
.
. β
0 β µ








. (20.4.1)
Here ε0 = hφ0|hˆ|φ0i is the adsorbate on-site energy, γ = hφ0|hˆ|φ1i is the nearest￾neighbor adsorbate–electrode coupling matrix element, β = hφn|hˆ|φn±1iis the coupling
matrix element between neighboring electrode sites, and µ = hφn|hˆ|φniis the (constant)
on-site energy at the electrode. (Notice that for a “half-filling model,” in which the
number of electrons present in the electrode is identical to the number of local sites,
the on-site energy identifies with the chemical potential (see Ex. 20.4.1).)
The localized basis states enable us to conveniently divide the single-particle Hil￾bert space into the “adsorbate” and “electrode” subspaces, where the single-particle
Hamiltonian, hˆ, is written as
hˆ ≡ hˆ
A +hˆ
E +hˆ
A,E. (20.4.2)
Furthermore, it is convenient to transform into an orthonormal basis, in which hˆ
A +
hˆ
E is diagonal (see Fig. 20.4.1). Denoting this basis as |χ0i,|χ1i,|χ2i...,|χME
i, where
hχn|χn
0i = δn,n
0 , the different parts of the Hamiltonian are expressed as
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press447 20.4 Impurity Models
Ftigure 20.4.1 A schematic representation of a simple adsorbate–electrode model. The adsorbate is modeled as a single site at
energy ε0, coupled to the first site of a semi-infinite uniform chain (left plot), representing an “electrode.” The chain is
characterized by the on-site energy, µ, and the nearest-neighbor tunneling matrix element, β. (For a half filling
model of noninteracting fermions in the electrode, the on-site energy coincides with the chemical potential.) The plot
on the right represents the same model after block diagonalization of the electrode Hamiltonian, where the adsorbate
is coupled to the band of delocalized electrode eigenstates, where the coupling is scaled by the projection of each
delocalized eigenstate on the first (“surface”) electrode site.
hˆ
E =
ME
∑
n,n
0=1
hφn|hˆ|φn
0i|φnihφn
0| =
ME
∑
n=1
εn|χnihχn|
hˆ
A = hφ0|hˆ|φ0i|φ0ihφ0| = ε0|χ0ihχ0| (20.4.3)
hˆ
A,E = |φ0iγhφ1|+h.c. =
ME
∑
n=1
γn|χ0ihχn|+h.c. ; γn = γhφ1|χni.
The eigenvalues and eigenvectors corresponding to the linear uniform chain model
(n = 1,2,...) are (see Eqs. (14.4.25, 14.4.26))
εn = µ +2β cos
nπ
ME +1

; |χni =
ME
∑
j=1
r
2
ME +1
sin
nπ j
ME +1

|φji, (20.4.4)
where each eigenvector is a linear combination of the localized conductor states.
Notice that while these eigenvectors are delocalized over the electrode sites, the ortho￾normal basis |χ0i,|χ1i,|χ2i...,|χME
i is still “local” in the sense that a part of it (|χ0i) is
associated with the adsorbate site, and the other part (|χ1i,|χ2i...,|χME
i) is associated
with the electrode (conductor) sites. (This locality reflects the underlying tight-binding
model assumptions.)
Exercise 20.4.1 The “electrode” part in the model depicted in Eq. (20.4.1) consists
of a uniform linear tight-binding chain of ME sites at the on-site energy, µ, with the
nearest-neighbor coupling matrix elements, β = −|β|. The eigenvalues and eigenvec￾tors of the corresponding model Hamiltonian were first introduced in Eqs. (14.4.25,
14.4.26) and are quoted in Eq. (20.4.4). Let us consider a “half-filling model” where
the system is populated by noninteracting electrons whose number equals the number
of electrode sites, ME. (a) Considering the Pauli exclusion and the Aufbau principles
(Chapter 13), show that for an even ME, the energies of the highest occupied and lowest
unoccupied eigenvectors of the chain Hamiltonian at zero temperature are, respectively,
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press448 Open Many-Fermion Systems
ε = µ +2β cosh
π
2

1−
1
ME+1
i and ε = µ +2β cosh
π
2

1+
1
ME+1
i. (b) Show that for
an infinite chain length, ME → ∞, these two energies coincide to the same value (the chem￾ical potential of the many-electron system), which is equal to the on-site energy, µ. (c)
Show that the energies of the highest occupied and lowest unoccupied eigenvectors of the
chain Hamiltonian have the same value also for an odd ME.
To account for many electrons in the adsorbate–electrode system, we can pair each
spatial state with a spin state, |χni ⊗ |σi, σ ∈ (1/2,−1/2), and construct a Fock space
based on the orthonormal set of single-particle states. The many-electron Hamiltonian
in this space reads (Eq. (20.2.3))
Hˆ =
1/2
∑
σ=−1/2
ME
∑
i, j=0
hi, jaˆ
†
i,σ
aˆj,σ +
1
2
1/2
∑
σ,σ0=−1/2
ME
∑
i, j,k,l=0
wi, j,k,laˆ
†
i,σ
aˆ
†
j,σ0aˆl,σ0aˆk,σ, (20.4.5)
where, hi, j = hχi
|hˆ|χji is the single-particle matrix element, and the electron-pair
interactions are encoded in the scalars, {wi, j,k,l}. It is customary to invoke a model
of noninteracting fermions for the conductor, which means that the interaction is
restricted to the adsorbate subspace; namely, wi, j,k,l
is assumed to vanish unless i = j =
k = l = 0. Denoting the “on-site” Coulomb repulsion at the adsorbate (often referred
to as the Hubbard interaction parameter [20.1]) as
w0,0,0,0 = hχ0| ⊗ hχ0|wˆ|χ0i ⊗|χ0i = Ke2
w
dr
w
dr
0
|χ0(r)|
2
|χ0(r
0
)|
2
|r−r
0
|
≡ U, (20.4.6)
and using the explicit form of the single-particle Hamiltonian (Eqs. (20.4.2, 20.4.3)),
the many-particle Hamiltonian, Eq. (20.4.5), reads (Ex. 20.4.2)
Hˆ = ε0aˆ
†
0,1/2
aˆ0,1/2 +ε0aˆ
†
0,−1/2
aˆ0,−1/2 +Uaˆ
†
0,1/2
aˆ0,1/2aˆ
†
0,−1/2
aˆ0,−1/2
+
1/2
∑
σ=−1/2
ME
∑
i=1
[εiaˆ
†
i,σ
aˆi,σ + (γiaˆ
†
0,σ
aˆi,σ +h.c.)]
. (20.4.7)
Exercise 20.4.2 Using the explicit form of the single-particle Hamiltonian, Eqs. (20.4.2,
20.4.3), in Eq. (20.4.5) and restricting the electron–electron interaction to the adsorbate
space (Eq. (20.4.6)), derive Eq. (20.4.7).
The many-particle adsorbate–electrode model (Eq. (20.4.7)) is identical in its struc￾ture to the Anderson impurity model [20.2] that was introduced for treating a mag￾netic impurity in a metal. Indeed, in both cases, a localized impurity state that can
accommodate two electrons at opposite spin states is coupled to a reservoir of non￾interacting electrons. This model can be readily generalized to account for impurities
with many single-particle states by replacing the single-particle adsorbate Hamiltonian
(hˆ
A in Eqs. (20.4.2, 20.4.3)) with a tight binding model Hamiltonian for MA-coupled
adsorbate sites, that is,
hˆ
A ≡
MA
∑
mA,m0
A=1
hmA,m0
A
|φmA
ihφm0
A
| =
MA
∑
mA=1
εmA
|χmA
ihχmA
|. (20.4.8)
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press449 20.4 Impurity Models
Invoking the electrode model, hˆ
E (see Eq. (20.4.3)), and introducing nearest-neighbor
coupling between the terminal site of the impurity (e.g., |φ1A
i) and the terminal site
of the electrode (e.g., |φ1E
i), the generalized adsorbate–electrode model Hamiltonian
reads
hˆ ≡ hˆ
A +hˆ
E +hˆ
A,E
hˆ
E =
ME
∑
mE ,m0
E=1
hφmE
|hˆ|φm0
E
i|φmE
ihφm0
E
| =
ME
∑
mE=1
εmE
|χmE
ihχmE
|. (20.4.9)
hˆ
A,E = |φ1A
iγhφ1E
|+h.c. =
ME
∑
mE=1
MA
∑
mA=1
γhχmA
|φ1A
ihφ1E
|χmE
i|χmA
ihχmE
|+h.c.
Within the tight binding assumptions, the eigenstates of the uncoupled adsorbate and
electrode Hamiltonians ({|χmA
i} and {|χmE
i}, respectively, are an orthonormal basis
for the spatial single-particle Hilbert space, hχm|χm0i = δm,m0 . As in the previous sec￾tion, we invoke a composite index to account also for the spin degree of freedom,
{|Φmi} = {|χmi ⊗ |σmi}. Using the orthonormal basis of the single-particle states
(spin orbitals), hΦm|Φm0i = δm,m0 , the corresponding many-particle impurity model
Hamiltonian obtains the generic form
Hˆ = Hˆ
A +Hˆ
E +Hˆ
A,E, (20.4.10)
Hˆ
A =
MA
∑
mA=1
εmA
aˆ
†
mA
aˆmA + ∑
i, j,k,l∈{mA}
wi, j,k,laˆ
†
i
aˆ
†
j
aˆlaˆk
Hˆ
E =
ME
∑
mE=1
εmE
aˆ
†
mE
aˆmE
Hˆ
A,E =
MA
∑
mA=1
ME
∑
mE=1
νmA
γmE
aˆ
†
mA
aˆmE +h.c.,
(20.4.11)
where we denoted νmA = hχmA
|φ1A
i and γmE = γhφ1E
|χmE
i.
Notice that the many-particle Hamiltonian, Hˆ, is naturally cast in a “system–
bath” form (see Eq. (19.3.3)). The impurity (Hˆ
A) corresponds to the “small system
of interest,” which can accommodate a finite number of electrons, whereas the Ham￾iltonian Hˆ
E corresponds to a “bath,” or an electron reservoir, which, for ME → ∞, can
accommodate an infinite number of electrons. The system–bath interaction operator,
Hˆ
A,E, corresponds to electron transitions between the system and the bath subspaces,
namely, annihilating an electron in a state confined within the system and creat￾ing an electron at a reservoir state, or vice versa. Within the tight binding model,
the system–bath interaction depends on the intersite coupling matrix elements at
the impurity–reservoir interface (e.g., the parameters γmE
and νmA
depend on the
projections of the reservoir and impurity Hamiltonian eigenstates on the terminal
sites). When these coupling matrix elements are significantly smaller than the inter￾site coupling matrix elements within each subspace, the system–bath interaction can
be treated perturbatively. The reduced system dynamics, and particularly the exchange
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press450 Open Many-Fermion Systems
of electrons between the impurity and the reservoir can then be described within the
Born–Markov approximation, as introduced in Chapter 19.
20.5 Charge Exchange with a Fermion Reservoir
Reduced System Dynamics
Let us start by identifying the adsorbate with the system, and the electrode with a bath,
rewriting the generalized impurity Hamiltonian, Eqs. (20.4.10, 20.4.11), as a standard
system–bath Hamiltonian (see Eqs. (19.3.3, 19.3.12)):
Hˆ = Hˆ
S +Hˆ
B +Hˆ
SB ; [Hˆ
S, Hˆ
B] = 0
Hˆ
S =
MA
∑
m=1
εmaˆ
†
maˆm + ∑
i, j,k,l∈{m}
wi, j,k,laˆ
†
i
aˆ
†
j
aˆlaˆk
Hˆ
B =
ME
∑
k=1
εkaˆ
†
k
aˆk
Hˆ
SB = Vˆ
SUˆ
B +Vˆ
†
S Uˆ
†
B
; Vˆ
S ≡
MA
∑
m=1
νmaˆ
†
m ; Uˆ
B ≡
ME
∑
k=1
γkaˆk
. (20.5.1)
Our prime interest is in the system dynamics in the presence of its coupling to the
bath. For this purpose, it is sufficient to follow the time evolution of the reduced
system density operator under the full Hamiltonian. In the limit of weak coupling
to the bath, the Nakajima and Zwanzig projection scheme and the Born–Markov
approximation can provide a reliable description of the reduced dynamics, as detailed
in Sections 19.3 and 19.4 for the generic system–bath Hamiltonian. We can there￾fore implement this general formulation to the adsorbate–electrode Hamiltonian,
emphasizing some special characteristics of fermion reservoirs.
The initial density operator is taken to be a product state, where the system density
operator depends on its transient preparation, and the state of the macroscopi￾cally large reservoir is assumed to be at near equilibrium, corresponding to a grand
canonical ensemble (Eq. (20.3.4)), namely
ρˆ(0) = ρˆB ⊗ρˆS(0) ; ρˆB =
e
−1
kBT ∑
k
(εk−µ)aˆ
†
k
aˆk
tr{e
−1
kBT ∑
k
(εk−µ)aˆ
†
k
aˆk
}
. (20.5.2)
As we can readily verify, the bath density fulfils the conditions, trB{ρˆB} = 1 and
[ρˆB,Hˆ
B] = 0 (Eq. (19.3.6)). Additionally, the system–bath coupling is of the generic
form of a sum of products of system and bath operators, namely Hˆ
SB ≡ ∑
α
Vˆ
(S)
α Uˆ
(B)
α
(Eq. (19.3.12)), where the bath coupling operators are orthogonal to the bath equilib￾rium density (Eq. (19.3.13)), trB{Uˆ
BρˆB} = trB{Uˆ
†
B
ρˆB} = 0 (see Ex. 20.5.1). Therefore,
in the weak system–bath coupling limit, the reduced system density, ρˆS(t) = trB{ρˆ(t)},
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press451 20.5 Charge Exchange with a Fermion Reservoir
satisfies the general Born–Markov (Redfield) equation (Eqs. (19.3.19–19.3.22)), where
the influence of the bath is captured in terms of its coupling correlation functions
(Eq. (19.3.21)). For the present system–bath model Hamiltonian (Eq. (20.5.1)), the
Redfield equation obtains the form (see Ex. 20.5.2)
∂
∂t
ρˆS(t) ∼= −
i
h¯
[Hˆ
S,ρˆS(t)]
−
1
h¯
2
wt
0
dτ{ce(τ)
h
Vˆ
S, e
−iτ
h¯
Hˆ
SVˆ
†
S
e
iτ
h¯
Hˆ
SρˆS(t)
i
+ca(τ)[Vˆ
†
S
, e
−iτ
h¯
Hˆ
SVˆ
Se
iτ
h¯
Hˆ
SρˆS(t)] +h.c.}, (20.5.3)
where ca(τ) and ce(τ) are the fermionic coupling correlation functions. These are
related to the equilibrium Fermi distribution functions (Eq. (20.3.6)) for electrons and
holes in the reservoir (see Ex. 20.5.2):
ca(τ) = trB{Uˆ
†
B
e
−iτ
h¯
Hˆ
BUˆ
Be
iτ
h¯
Hˆ
B ρˆB} =
ME
∑
k=1
|γk
|
2
e
iτ
h¯
εk
fe(εk)
ce(τ) = trB{Uˆ
Be
−iτ
h¯
Hˆ
BUˆ
†
B
e
iτ
h¯
Hˆ
B ρˆB} =
ME
∑
k=1
|γk
|
2
e
−iτ
h¯
εk
fh(εk)
. (20.5.4)
Exercise 20.5.1 (a) Use the anti-commutation relation between the fermionic annihi￾lation and creation operators, {aˆ
†
l
,aˆ
†
l
0} = 0, {aˆl
,aˆl
0} = 0, {aˆl
,aˆ
†
l
0} = δl,l
0 , (Eqs. (20.1.19,
20.1.20)), to show that the traces over a single-orbital Fock space, trk{aˆk
f(aˆ
†
k
aˆk)} and
trk{aˆ
†
k
f(aˆ
†
k
aˆk)}, vanish for any analytic function, f(Aˆ) =
∞
∑
n=0
fnAˆn
. (b) Given the def￾inition of the fermion bath Hamiltonian and coupling operators (Eq. (20.5.1) with
Uˆ
B ≡
ME
∑
k=1
γkaˆk), and the bath density operator (Eq. (20.5.2)), use the result of (a) to
show that trB{Uˆ
BρˆB} = trB{Uˆ
†
B
ρˆB} = 0.
Exercise 20.5.2 (a) Use the explicit expressions, Uˆ
B ≡
ME
∑
k=1
γkaˆk
, Hˆ
B =
ME
∑
k=1
εkaˆ
†
k
aˆk
,ρˆB =
e
−1
kBT ∑
k
(εk−µ)aˆ
†
k
aˆk
/tr (
e
−1
kBT ∑
k
(εk−µ)aˆ
†
k
aˆk
)
, and the fermionic anti-commutation relations to
show that the bath correlation functions, ce(τ) = trB{Uˆ
Be
−iτ
h¯
Hˆ
BUˆ
†
B
e
iτ
h¯
Hˆ
B ρˆB} and ca(τ) =
trB{Uˆ
†
B
e
−iτ
h¯
Hˆ
BUˆ
Be
iτ
h¯
Hˆ
B ρˆB}, read ce(τ) =
ME
∑
k=1
|γk
|
2
e
−iτ
h¯
εk

1−
1
1+e
1
kBT
(ε
k−µ)

and ca(τ) =
ME
∑
k=1
|γk
|
2
e
iτ
h¯
εk 1
1+e
1
kBT
(ε
k−µ)
.
(b) For a general system–bath coupling operator, Hˆ
SB ≡ ∑
α
Vˆ
(S)
α Uˆ
(B)
α (Eq. (19.3.12)),
the Redfield (Born–Markov) dissipator obtains the form of Eqs. (19.3.21, 19.3.22),
Dˆ ρˆS(t) = −
1
h¯
2 ∑
α,α0
rt
0
dτ
n
cα,α0(τ)
h
Vˆ
(S)
α , e
−iτ
h¯
Hˆ
SVˆ
(S)
α0 e
iτ
h¯
Hˆ
SρˆS(t)
i
+cα0
,α(τ)
h
ρˆS(t)e
−iτ
h¯
Hˆ
SVˆ
(S)
α0
e
iτ
h¯
Hˆ
S
,Vˆ
(S)
α
io, where cα,α0(τ) ≡ trB{Uˆ
(B)
α e
−iτ
h¯
Hˆ
BUˆ
(B)
α0 e
iτ
h¯
Hˆ
B ρˆB} and cα,α0(τ) = cα,α0(−τ).
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press452 Open Many-Fermion Systems
Map the coupling operator defined in Eq. (20.5.1), Hˆ
SB ≡ Vˆ
SUˆ
B +Vˆ
†
S Uˆ
†
B
, on this general
form by identifying Vˆ
S ≡ Vˆ
(S)
1
, Uˆ
B ≡ Uˆ
(B)
1
, Vˆ
†
S ≡ Vˆ
(S)
2
, Uˆ
†
B ≡ Uˆ
(B)
2
to show that
Dˆ ρˆS(t) = −
1
h¯
2
wt
0
dτ
n
c1,2(τ)
h
Vˆ
S, e
−iτ
h¯
Hˆ
SVˆ
†
S
e
iτ
h¯
Hˆ
SρˆS(t)
i
+c
∗
2,1
(τ)
h
ρˆS(t)e
−iτ
h¯
Hˆ
SVˆ
†
S
e
iτ
h¯
Hˆ
S
,Vˆ
S
io
−
1
h¯
2
wt
0
dτ
n
c2,1(τ)
h
Vˆ
†
S
, e
−iτ
h¯
Hˆ
SVˆ
Se
iτ
h¯
Hˆ
SρˆS(t)
i
+c
∗
1,2
(τ)
h
ρˆS(t)e
−iτ
h¯
Hˆ
SVˆ
Se
iτ
h¯
Hˆ
S
, Vˆ
†
S
io.
(c) Use the identifications, c1,2(τ) = ce(τ), c2,1(τ) = ca(τ), to derive Eq. (20.5.3).
For “macroscopically” large reservoirs, the spectrum of the single particle is dense;
namely, the energy spacings between nearest levels are much smaller than the system–
bath coupling matrix elements. It is instructive to replace the discrete model (e.g.,
Eq. (20.4.4)) by a continuous band (see Section 14.5). The summation over the system–
bath coupling matrix elements squared {|γk
|
2} can then be replaced by an integral
over a continuous function of the energy, γ
2
(ε), weighted by the electrode’s density of
states (see Section 5.5), where |γk
|
2 = γ
2
(εk). Introducing the respective spectral density
function (see also Eq. (17.2.10)),
J(ε) ≡ 2πγ
2
(ε)ρ(ε), (20.5.5)
the bath correlation functions are shown to be
ca(τ) = 1
2π
w
dεe
iτε/h¯
J(ε)fe(ε)
ce(τ) = 1
2π
w
dεe
−iτε/h¯
J(ε)fh(ε)
, (20.5.6)
where the integral is over the electrode band energies. The discrete summations
(Eq. (20.5.4)) are readily recovered for ρ(ε) = ∑
k
δ(ε −εk).
As an example, let us consider the electrode model of a uniform linear chain with
ME sites (Eqs. (20.4.3, 20.4.4) or Eq. (20.4.11)), in which the coupling of the chain to
the system is restricted to its terminal site via a tunneling matrix element, γ. In this
case, we obtain |γk
|
2 = 2|γ|
2
h
1−
(εk−µ)
2
4β
2
i
/(ME +1), where for ME >> 1, the density of
states can be approximated as, ρ(εk) ≈ (ME +1)/(π
p
4β
2 −(εk − µ)
2) (see Ex. 20.5.3).
Consequently, in the limit of a semi-infinite linear chain (ME → ∞), the spectral density
(Eq. (20.5.5)) corresponds to a semielliptical band model [20.3] (see Ex. 20.5.3),
J(ε) = |γ|
2
β
2
q
4β
2 −(ε − µ)
2
. (20.5.7)
In the case of “half-filling” of the chain, the on-site single-particle energy, µ, identifies
with the chemical potential of the many-electron system (Ex. 20.4.1), which means that
the spectral density obtains its maximal value at the chemical potential.
Exercise 20.5.3 Consider the adsorbate–electrode model, characterized by the single￾particle Hamiltonian in Eqs. (20.4.2, 20.4.3). The eigenvalues and eigenvectors of the
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press453 20.5 Charge Exchange with a Fermion Reservoir
single-particle electrode Hamiltonian ( corresponding to a linear uniform chain) are given
by Eq. (20.4.4) (see also Eqs. (14.4.25, 14.4.26)) where the adsorbate–electrode cou￾pling is restricted to the terminal electrode site and depends on the projections of the chain
eigenvectors ({|χki}) on the first electrode site, namely γk = γhφ1|χki (see Eq. (20.4.3)).
Show that: (a) |γk
|
2 = 2|γ|
2
h
1−
(εk−µ)
2
4β
2
i
/(ME + 1). (b) The density of states for the
linear chain model reads ρ(εk) ≡
∂n(ε)
∂ ε



ε=εk
≈ (ME +1)/(π
p
4β
2 −(εk − µ)
2). (c) The
respective spectral density of the adsorbate–electrode interaction (Eq. (20.5.5)) is given
by Eq. (20.5.7).
The bath correlation functions have the generic form of sums, Eq. (20.5.4) (or inte￾grals, Eq. (20.5.6)), over oscillating waves in time, at frequencies corresponding to the
single-particle energy levels at the electrode band {(εk/h¯)}, weighted by the pre-factors,
|γk
|
2
fe/h
(εk). For a dense and wide frequency band the net result is a decaying function
in time (see, e.g., the discussion of the generic Fermi’s golden rule in Section 17.2, and
Fig. 17.2.2), where the time decay becomes more rapid as the bandwidth increases.
The effective bandwidth is determined by the width of the spectral density function,
J(ε) (or the distribution of the system–bath tunneling matrix elements, {|γk
|
2}), as well
as by the effective energy width of the relevant Fermi function (fe(ε) or fh(ε)). The
width of the spectral density increases as the fastest time period of the bath dynam￾ics increases (e.g., for the semi-infinite linear chain model, Eq. (20.4.4), the bandwidth
equals |4β|, which corresponds to the tunneling frequency between neighboring sites,
2|β|/h¯). The width of the Fermi distribution increases with increasing bath tempera￾ture (see Fig. 20.3.1). When the multiplicity, J(ε)fe/h
(ε), is a sufficiently broad function
of the energy, the relaxation time of the bath correlations can become faster than any
significant change in the reduced density matrix according to Eq. (20.5.3). When this
holds, the upper limit in the time integral in Eq. (20.5.3) can be taken to infinity, which
yields the stationary Born–Markov approximation. (See a detailed analysis in Sec￾tion 17.2 as well as Eqs. (19.4.1–19.4.3), and a similar consideration for a bosonic
bath, Eqs. (19.5.6–19.5.8)):
∂
∂t
ρˆS(t) ∼= −
i
h¯
[Hˆ
S,ρˆS(t)]
−
1
h¯
2
w∞
0
dτ{ce(τ)
h
Vˆ
S, e
−iτ
h¯
Hˆ
SVˆ
†
S
e
iτ
h¯
Hˆ
SρˆS(t)
i
+ca(τ)
h
Vˆ
†
S
, e
−iτ
h¯
Hˆ
SVˆ
Se
iτ
h¯
Hˆ
SρˆS(t)
i
+h.c.}. (20.5.8)
The state of the adsorbate system is fully captured in the reduced density matrix in
the basis of eigenstates of the reduced system Hamiltonian, defined as
Hˆ
S|Ψmi = Em|Ψmi. (20.5.9)
In the presence of electron–electron interaction, each eigenstate is a specific superposi￾tion of many-electron occupation vectors (determinants). Nevertheless, recalling that
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press454 Open Many-Fermion Systems
the Hamiltonian commutes with the electron number operator, the matrix represen￾tation of the Hamiltonian in Fock space is block diagonal (see Eqs. (20.2.6, 20.2.7)),
and each eigenstate of Hˆ
S is also an eigenstate of the corresponding electron number
operator,
Nˆ
S|Ψmi = Nm|Ψmi. (20.5.10)
Introducing the eigenstates of Hˆ
S as a complete orthonormal basis for the space of
the reduced system, where 
Oˆ
S

m,m0 = hΨm|Oˆ
S|Ψm0i, Eq. (20.5.8) can be written as
∂
∂t
[ρˆs(t)]n
0
,n
∼= −
i
h¯
(En
0 −En)[ρˆs(t)]n
0
,n − ∑
m,m0
R
(St)
n
0
,n,m0
,m
[ρˆs(t)]m0
,m, (20.5.11)
where the stationary Redfield tensor (Eq. (19.4.1)) obtains the form (Ex. 20.5.4)
R
(St)
n
0
,n,m0
,m = An
0
,n,m0
,m +A
∗
n,n
0
,m,m0
An
0
,n,m0
,m = δm,n∑
k
1
h¯
2
w∞
0
dτe
−iτ
h¯
(Ek−Em0)
{ce(τ)[Vˆ
S]n
0
,k
[Vˆ
†
S
]k,m0 +ca(τ)[Vˆ
†
S
]n
0
,k
[Vˆ
S]k,m0}
−
1
h¯
2
w∞
0
dτe
−iτ
h¯
(En
0−Em0)
{ce(τ)[Vˆ
†
S
]n
0
,m0[Vˆ
S]m,n +ca(τ)[Vˆ
S]n
0
,m0 [Vˆ
†
S
]m,n}.
(20.5.12)
Exercise 20.5.4 Show that the matrix representation of Eq. (20.5.8) in the basis of the
system Hamiltonian eigenstates (Eq. (20.5.9)) is given by Eqs. (20.5.11, 20.5.12).
Master Equation
When the energy level spacings within the spectrum of the adsorbate Hamiltonian
(Hˆ
S, in the absence of coupling to the electrode) are much larger than the spectral
density of the adsorbate–electrode coupling, the bath-free dynamics is much faster
than the bath-induced dynamics within the adsorbate. In this limit, and when the
spectrum of Hˆ
S is nondegenerate, the secular approximation is valid (Eqs. (19.4.8–
19.4.11)). The dynamics of the populations of Hˆ
S-eigenstates, Pn(t) ≡ [ρˆ]n,n(t), is then
effectively decoupled from the dynamics of the coherences between them, which means
that the equation for the population can be derived by setting to zero off-diagonal
matrix elements of the reduced density matrix, [ρˆ]n
0
,n
(t), in Eq. (20.5.11). Noticing
that R
(St)
n,n,m,m = 2Re[An,n,m,m], we obtain Pauli’s master equation (Eq. (19.4.13)) for the
eigenstate population kinetics (Ex. 20.5.5):
∂
∂t
Pn(t) ∼= ∑
n
0
kn
0→nPn
0(t)−∑
n
0
kn→n
0Pn(t)
kn→n
0 ≡




Vˆ
S

n,n
0



2 J(En −En
0)
h¯
fh(En −En
0)+




Vˆ
S

n
0
,n



2 J(En
0 −En)
h¯
fe(En
0 −En).
(20.5.13)
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press455 20.5 Charge Exchange with a Fermion Reservoir
As in the general case discussed in Section 19.4, the rate coefficients {kn→n
0} are shown
to be nonnegative, and consequently, the nonnegativity of each state population (as
well as the sum of state populations) is conserved by the master equation. Additionally,
the structure of the rate equation guarantees the existence of a stationary (steady-state)
solution, where ∂
∂t
Pn(t) = 0 (see Eqs. (19.4.13–19.4.23)).
Exercise 20.5.5 Show that setting the coherences of the reduced density matrix to zero
in Eqs. (20.5.11, 20.5.12) leads to Eq. (20.5.13).
The physical processes underlying the state-to-state population transfer become
apparent by considering the explicit form of the system bath coupling operators within
the system (Eq. (20.5.1)), Vˆ
S ≡
MA
∑
m=1
νmaˆ
†
m,
[Vˆ
S]n,n
0 = hΨn|Vˆ
S|Ψn
0i =
MA
∑
m=1
νmhΨn|aˆ
†
m|Ψn
0i. (20.5.14)
Since the operator aˆ
†
m creates an electron at the mth single-particle state in the system,
and since eigenstates associated with different numbers of electrons in the system are
orthogonal to each other (Eq. (20.5.10)), the coupling matrix element, [Vˆ
s
]n,n
0 , vanishes
unless the system in the state |Ψn
0i contains one electron less than the system in the state
|Ψni, namely [Vˆ
S]n,n
0 ∝ δNn
0Nn−1. Consequently, the state-to-state rates can be expressed
as
kn→n
0 =







Vˆ
S

n,n
0



2
J(En−En
0)
h¯
fh(En −En
0) ; Nn
0 = Nn −1




Vˆ
S

n
0
,n



2
J(En
0−En)
h¯
fe(En
0 −En) ; Nn
0 = Nn +1
0 ; otherwise.
(20.5.15)
The nonzero transition rates in the master equation therefore correspond to either
a single electron emission from the system to the reservoir, or a single electron absorp￾tion by the system from the reservoir. We can readily verify (see Ex. 20.5.6) that the rate
expressions in the master equation coincide with the results of Fermi’s golden rule for
transitions between different manifolds of the uncoupled adsorbate–electrode Hamil￾tonian eigenstates. Notice that if electron–electron interactions within the system can
be neglected (Hˆ
S ≈ ∑
MA
m=1
εmaˆ
†
maˆm in Eq. (20.5.1)), each electron emission or absorption
involves one of the single-particle (spin-orbital) states (see Ex. 20.5.7).
Exercise 20.5.6 The adsorbate–electrode Hamiltonian can be conveniently split into
zero order and perturbation Hamiltonians, Hˆ = Hˆ
0+Vˆ , where Hˆ
0 = Hˆ
S +Hˆ
B andVˆ = Hˆ
SB
(see Eq. (20.5.1)). Using Eq. (20.5.9), the eigenvectors of Hˆ
0 are defined by the equation,
Hˆ
0|Ψni ⊗ |n1,n2,...,nME
i = (En +
ME
∑
k=1
nkεk)|Ψni ⊗ |n1,n2,...,nME
i. A charge transfer
event between the electrode and the adsorbate can be formulated as a transition between
incoherent ensembles of (orthogonal) Hˆ
0 eigenstates, where the initial and final states
are defined, respectively, by projection operators to the initial and final system Hamilto￾nian eigenstates, Pˆ
{i} = |ΨnihΨn|, and Pˆ
{ f } = |Ψn
0ihΨn
0|. In the weak molecule–electrode
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press456 Open Many-Fermion Systems
coupling limit, the charge transfer rate can be evaluated by Fermi’s golden rule (see
Chapter 17), where the electrode is initially in a thermal state, ρˆ{i}
(0) = |ΨnihΨn| ⊗ρˆB.
Starting from the generic perturbative rate expression (Eq. (17.3.12)), k
(1)
{i}→{ f }
(t) ∼=
2
h¯
2 Re rt
0
tr{ρˆ{i}
(0)Pˆ
{i}Vˆ Pˆ
{ f }e
iHˆ
0 τ
h¯ Vˆ e
−iHˆ
0 τ
h¯ }dτ, and using Eq. (20.5.4) for the bath corre￾lation functions, show that the transition rates appearing in the master equation are
reproduced at the infinite time limit (under the fast bath relaxation assumption), namely
kn→n
0 = limt→∞ k
(1)
{i}→{ f }
(t).
Exercise 20.5.7 In the absence of electron–electron interaction, the system Hamil￾tonian in Eq. (20.5.1) reads Hˆ
S =
MA
∑
m=1
εmaˆ
†
maˆm. (a) Show that the eigenvectors of
Hˆ
S in this case are the MA-particle determinants, {|n1,n2,n3,...,nMA
i} (defined in
Eqs. (20.1.3, 20.1.7)), with the corresponding eigenvalues, (
MA
∑
m=1
εmnm
)
, where 
εm
	
are the single-particle Hamiltonian eigenstates. (b) Denoting each eigenstate by the vec￾tor of occupation numbers, |n1,n2,n3,...,nMA
i ⇔ n and using the system–bath coupling
(Vˆ
S) in Eq. (20.5.1), show that the transition rate between nondegenerate Hˆ
S eigenvectors
(Eq. (20.5.13)) reads in this case kn→n
0 = ∑
MA
m=1
[δn−n
0
,em
ke,m +δn
0−n,em
ka,m], where em is
a unit vector of length MA with elements [em]m0 = δm,m0 . Here ke,m ≡ |νm|
2 J(εm)
h¯
fh(εm) and
ka,m ≡ |νm|
2 J(εm)
h¯
fe(εm) are rates of single-electron emission to the reservoir, or absorp￾tion from the reservoir. Notice that the rate vanishes unless the two occupation vectors
are identical except for a flip between zero and one at the mth entry, which corresponds
to either absorption or emission of a single electron at the mth single-particle state.
Notice that each transition rate is proportional to the spectral density (J(E)) at the
charging (or discharging) energy, as well as to the Fermi distributions, namely to the
availability of a hole (for emission) or an electron (for absorption) at the electrode, at
the appropriate transitions. The dependence of the Fermi distribution function on the
temperature and chemical potential imposes a detained balance relation on the forward
and backward transitions between the same many-electron states. Let us consider the
many-electron states, |Ψn
0i and |Ψni, whose total electron occupation numbers differ
by one, where Nn
0 = Nn −1. Using Eq. (20.5.15), the ratio between the rates of electron
emission (kem = kn→n
0) and electron absorption (kab = kn
0→n
) between these states reads
(Ex. 20.5.8)
kem
kab
=
kn→n
0
kn
0→n
= e
En−E
n
0 −µ
kBT
. (20.5.16)
The Equilibrium State
Using the condition, Eq. (20.5.16), in the Pauli master equation (Eq. (20.5.13)), we
can readily identify the existence of a stationary (steady-state) solution 
∂
∂t
Pn(t) = 0

,
in which the populations of the system Hamiltonian eigenstates are given by the
distribution (see Ex. 20.5.9),
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press457 20.5 Charge Exchange with a Fermion Reservoir
Pn =
e
−(En−µNn)
kBT
∑
n
0
e
−(E
0
n−µN
0
n
)
kBT
. (20.5.17)
As we can see, under the assumptions of the Born–Markov and secular approxima￾tions, the steady state of the system (equilibrium in this case) “adopts” the constraint
imposed on the (grand canonical) fermion reservoir, where the approximated reduced sys￾tem density operator reads, ρˆS
∼= e
−(Hˆ
S−µNˆ
S
)
kBT /tr

e
−(Hˆ
S−µNˆ
S
)
kBT

(compare to Eq. (19.4.25)
for the canonical case).
Exercise 20.5.8 Use the explicit rate expressions (Eq. (20.5.15)) to derive the ratio in
Eq. (20.5.16).
Exercise 20.5.9 Recalling that each system eigenstate is associated with a well-defined
number of electrons (see Eqs. (20.5.9, 20.5.10)) and restricting to Nn
0 = Nn − 1,
Eq. (20.5.16) can be written as k
n→n
0
k
n
0→n
= e
(En−µNn)−(E
n
0 −µNn
0
)
kBT
. Use this to show that the
probability distribution in Eq. (20.5.17) is a stationary solution to the master equation,
Eq. (20.5.13).
The Case of a Single-State Impurity
As a concrete simple example, let us return to the case of a single-state adsorbate, as
depicted in the model Hamiltonian described in Eqs. (20.4.1–20.4.7). For extra sim￾plicity, the electronic interaction on the adsorbate (impurity) site is assumed to be
sufficiently weak (settingU → 0)to allow the many-electron Hamiltonian (Eq. (20.4.7))
to become effectively separable in the two spin states. In this case, for either of the two
spin states, the adsorbate–electrode Hamiltonian reads
Hˆ = ε0aˆ
†
0
aˆ0 +
ME
∑
k=1
εkaˆ
†
k
aˆk +
"
ME
∑
k=1
γkaˆ
†
0
aˆk +h.c.
#
, (20.5.18)
where the system–bath Hamiltonian, Eq. (20.5.1), obtains the form Hˆ
S = ε0aˆ
†
0
aˆ0, Hˆ
B =
ME
∑
k=1
εkaˆ
†
k
aˆk
, and Hˆ
SB = Vˆ
SUˆ
B +Vˆ
†
S Uˆ
†
B
, where Vˆ
S ≡ aˆ
†
0
and Uˆ
B ≡
ME
∑
k=1
γkaˆk
. The space of
the adsorbate states is spanned by the “empty” (|Ψ0i = |0i) and “occupied” (|Ψ1i =
|1i) states of the single adsorbate orbital. Therefore, the adsorbate in this model
corresponds to a two-level system (TLS). Using the identities,
Hˆ
S|0i = 0|0i ; Hˆ
S|1i = ε0|1i
Vˆ
S|0i = |1i ; Vˆ
S|1i = 0, (20.5.19)
the representations of the TLS operators in the occupation basis read
Hˆ
S = ε0|1ih1| ; Vˆ
S = |1ih0| ; Vˆ
†
S = |0ih1|. (20.5.20)
In Section 19.5 we analyzed bath-induced dynamics in a TLS coupled to a boson bath,
which exchanges energy with the system. Here, the analogous treatment corresponds to
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press458 Open Many-Fermion Systems
particles exchanged between the TLS and the fermion reservoir. The general derivation
of the quantum master equation (Eqs. (20.5.1–20.5.13)) clearly applies also for the
present model (Eqs. (20.5.19, 20.5.20)). Let us emphasize that since the two eigenstates
of Hˆ
S are nondegenerate, and since the matrix representation of the coupling opera￾tor Vˆ
S in the basis of Hˆ
S-eigenstates is off diagonal, the secular approximation is not
needed, and Pauli’s master equation is obtained directly from Eqs. (20.5.11, 20.5.12)
with no additional assumptions (see Ex. 20.5.10).
Denoting the four elements of the density matrix in the basis of the adsorbate
occupation numbers,
ρ0,0(t) = h0|ρˆS(t)|0i ; ρ1,1(t) = h1|ρˆS(t)|1i
ρ1,0(t) = h1|ρˆS(t)|0i ; ρ0,1(t) = h0|ρˆS(t)|1i, (20.5.21)
the diagonal matrix elements, ρ1,1(t) and ρ0,0(t), correspond, respectively, to the occu￾pied and unoccupied states of the adsorbate site. Within the stationary Born–Markov
approximation, the population dynamics is decoupled from the coherences (ρ0,1(t) and
ρ1,0(t)), and Pauli’s master equation for the adsorbate population is obtained,
∂
∂t
ρ0,0(t) = k
em
1→0
p1,1(t)−k
ab
0→1ρ0,0(t)
∂
∂t
ρ1,1(t) = k
ab
0→1ρ0,0(t)−k
em
1→0ρ1,1(t).
(20.5.22)
The transfer rates k
ab
0→1
and k
em
1→0
correspond, respectively, to electron absorption and
emission by the adsorbate. These rates are Fourier transforms of the bath correlation
functions (Eq. (20.5.4)),
k
em
1→0 = 2Re
1
h¯
2
w∞
0
dτce(τ)e
iτ
h¯
ε0 =
2π
h¯
ME
∑
k=1
|γk
|
2
δ(εk −ε0)fh(εk)
k
ab
0→1 = 2Re
1
h¯
2
w∞
0
dτca(τ)e
−iτ
h¯
ε0 =
2π
h¯
ME
∑
k=1
|γk
|
2
δ(εk −ε0)fe(εk),
(20.5.23)
or, in the case of a continuous electrode spectral density (Eq. (20.5.6)),
k
em
1→0 =
1
h¯
J(ε0)fh(ε0)
k
ab
0→1 =
1
h¯
J(ε0)fe(ε0)
. (20.5.24)
We can readily see that regardless of the initial population of the adsorbate, the asymp￾totic time limit of the ratio between the two occupation states reaches a constant value
(see Ex. 20.5.11), where
ρ1,1(∞)
ρ0,0(∞)
=
k
ab
0→1
k
em
1→0
= e
−(ε0−µ)
kBT
. (20.5.25)
Therefore, at equilibrium the adsorbate population adopts the Fermi distribution:
ρ1,1(∞) = 1
1+e
ε0−µ
kBT
= fe(ε0). (20.5.26)
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press459 20.6 Nonequilibrium Fermion Systems
This is a manifestation of the general results (Eqs. (20.5.16, 20.5.17)) for the present
model.
Exercise 20.5.10 (a) Given Eq. (20.5.8), and defining the TLS eigenstate popula￾tions, ρ0,0(t) = h0|ρˆS(t)|0i, and ρ1,1(t) = h1|ρˆS(t)|1i, show that ∂
∂t
ρ0,0(t) ∼= −
1
h¯
2 2Re r∞
0
dτ
{ce(τ)h0|[Vˆ
S, e
−iτ
h¯
Hˆ
SVˆ
†
S
e
iτ
h¯
Hˆ
SρˆS(t)]|0i+ca(τ)h0|[Vˆ
†
S
, e
−iτ
h¯
Hˆ
SVˆ
Se
iτ
h¯
Hˆ
SρˆS(t)]|0i}.
(b) Introduce the identity operator in the Fock space of the adsorbate, ˆI = |0ih0| +
|1ih1|, to show that for the off-diagonal TLS coupling operators (Eq. (20.5.20)), Vˆ
S =
|1ih0| and Vˆ
†
S = |0ih1|, this result reads ∂
∂t
ρ0,0(t) = k
em
1→0
ρ1,1(t) − k
ab
0→1
ρ0,0(t), where
k
em
1→0 = 2Re 1
h¯
2
r∞
0
dτce(τ)e
iτ
h¯
ε0 and k
ab
0→1 = 2Re 1
h¯
2
r∞
0
dτca(τ)e
−iτ
h¯
ε0 (c) Show similarly that
∂
∂t
ρ1,1(t) = k
ab
0→1
ρ0,0(t) − k
em
1→0
ρ1,1(t). (d) Use the explicit expressions for the correla￾tion functions (Eq. (20.5.4)) to derive Eq. (20.5.23). (e) Use the expressions for the
correlation functions for a continuous bath (Eq. (20.5.6)) to derive Eq. (20.5.24).
Exercise 20.5.11 Use Eq. (20.5.24) and the definition of the Fermi–Dirac distribution
function (Eq. (20.3.6)) to derive Eq. (20.5.25).
20.6 Nonequilibrium Fermion Systems
So far, we discussed “small” quantum systems that are either isolated from their sur￾roundings or weakly coupled to a large reservoir at a near equilibrium state. In a more
general case, an open quantum system can be coupled to several reservoirs, each at
its own near equilibrium state. In this case the system is driven into a nonequilibrium
state. Nevertheless, when the coupling to different reservoirs is weak, the open sys￾tem can reach a “steady state” at asymptotic times, analogous to an equilibrium state
in the sense that system observables become time-independent. Yet, this state is dif￾ferent, since stationary fluxes (currents) of energy and/or particles can pass through
the boundaries between the small system and the different reservoirs at a constant,
nonzero rate. This scenario characterizes elementary processes on the nanoscale, such
as charge, spin, and energy transport, which are microscopic events underlying macro￾scopic transport phenomena such as electrical conductivity and heat transport, and are
at the heart of numerous technological applications, including nanoscale electronics
and spintronics, thermoelectric power, and optoelectric devices.
As we saw in Section 20.5, within the realm of the Born–Markov and the sec￾ular approximations, coupling of a small fermionic system to a single reservoir of
noninteracting fermions drives the system into an equilibrium distribution, in which
the system eigenstate populations reflect the constraints imposed on the external res￾ervoir. In this section we elaborate on the effect of coupling the small system of
interest to several reservoirs, each maintained in a different near equilibrium state,
at different temperatures and/or chemical potentials. As we shall see, the system can
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press460 Open Many-Fermion Systems
reach a nonequilibrium steady state, in which energy and/or particles continuously
flow between the reservoirs (namely, in a directed manner) through the system. An
example of charge transport through a nanoscale conductor (e.g., a single mole￾cule) between two macroscopic leads under a bias potential will be analyzed in what
follows.
An Impurity Coupled to Several Fermion Reservoirs
The formal treatment of an impurity coupled to several fermion reservoirs turns out
to be a rather straightforward extension of the case of a single reservoir, at least when
the system–bath coupling is restricted to the single-particle level (electron exchange
between the impurity and reservoirs of noninteracting particles), and within the valid￾ity of the Born–Markov approximation. In this case, the effect of multiple reservoirs
on the system evolution is shown to be a sum of contributions of each reservoir. The
theoretical formulation can therefore rely to a large extent on the one derived in the
previous section for a single reservoir.
We start by generalizing the adsorbate–electrode model Hamiltonian, Eq. (20.5.1),
to the case of several reservoirs.
Hˆ = Hˆ
S +Hˆ
B +Hˆ
SB ; [Hˆ
S,Hˆ
B] = 0
Hˆ
S =
MA
∑
m=1
εmaˆ
†
maˆm + ∑
i, j,k,l∈{m}
wi, j,k,laˆ
†
i
aˆ
†
j
aˆlaˆk
Hˆ
B = ∑
K
HˆK
Hˆ
SB = ∑
K
(Vˆ
S,KUˆ
B,K +Vˆ
†
S,KUˆ
†
B,K
).
(20.6.1)
The impurity Hamiltonian, Hˆ
S, is unchanged, where the single reservoir model is
replaced by a sum of reservoir Hamiltonians, HˆK = ∑
kK
εkK
aˆ
†
kK
aˆkK
. Here K = 1,2,... is
the reservoir index, and the operator aˆ
†
kK
creates an electron in the kKth single-particle
state at the Kth reservoir. The corresponding system–reservoir coupling operators read
Uˆ
B,K ≡ ∑
kK
γkK
aˆkK
and Vˆ
S,K ≡
MA
∑
m=1
νm,Kaˆ
†
m, where aˆ
†
m creates an electron in the mth single￾particle state at the system, and νm,K is the projection of that mth state on a local
coupling site to the Kth reservoir.
The full Fock space is a tensor product of the system and all the independent
reservoir spaces. An initially uncorrelated density operator in this space therefore reads
ρˆ(0) = ρˆS(0)⊗ρˆB ; ρˆB = ρˆ1 ⊗ρˆ2 ⊗ρˆ3 ... = ∏
K
ρˆK, (20.6.2)
where each reservoir density operator (ρˆK) obtains the equilibrium form for a grand
canonical ensemble, characterized by its own temperature, TK, and chemical potential,
µK:
ρˆK = e
−1
kBTK
∑
kK
(εkK
−µK)aˆ
†
kK
aˆkK
/ZK ; ZK = trK{e
−1
kBTK
∑
kK
(εkK
−µK)aˆ
†
kK
aˆkK
}. (20.6.3)
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press461 20.6 Nonequilibrium Fermion Systems
Our prime interest is the time evolution of the reduced system density operator,
ρˆS(t) = trB{ρˆ(t)}. When the second-order Born–Markov approximation applies, this
equation obtains the generic Redfield form of Eqs. (19.3.19–19.3.22). Introducing the
system–bath coupling operator, Hˆ
SB = ∑K(Vˆ
S,KUˆ
B,K +Vˆ
†
S,KUˆ
†
B,K
), into these equations,
the influence of the dissipator on the system dynamics is shown to be a sum over
independent contributions from the different reservoirs (Ex. 20.6.1):
∂
∂t
ρˆS(t) ∼= −
i
h¯
[Hˆ
S,ρˆS(t)]
−∑
K
1
h¯
2
wt
0
dτ{ce,K(τ)
h
Vˆ
S,K, e
−iτ
h¯
Hˆ
SVˆ
†
S,K
e
iτ
h¯
Hˆ
SρˆS(t)
i
+ca,K(τ)[Vˆ
†
S,K
, e
−iτ
h¯
Hˆ
SVˆ
S,Ke
iτ
h¯
Hˆ
SρˆS(t)] +h.c.} (20.6.4)
Each Kth reservoir is represented in this equation by its specific coupling operator
in the system, Vˆ
S,K, and the corresponding correlation functions, ce,K(τ) and ca,K(τ),
which read (compare to Eq. (20.5.4) for the case of a single reservoir)
ce,K(τ) = trK{Uˆ
B,Ke
−iτ
h¯
HˆKUˆ
†
B,K
e
iτ
h¯
HˆK ρˆK} =
ME
∑
kK=1
|γkK
|
2
e
−iτ
h¯
εkK fh(εkK
)
ca,K(τ) = trK{Uˆ
†
B,K
e
−iτ
h¯
HˆKUˆ
B,Ke
iτ
h¯
HˆK ρˆK} =
ME
∑
kK=1
|γkK
|
2
e
iτ
h¯
εkK fe(εkK
)
. (20.6.5)
Or, associating each reservoir with a continuous spectral density, JK(ε) (see
Eq. (20.5.6)),
ce,K(τ) = 1
2π
w
dεe
−iτε/h¯
JK(ε)fh,K(ε)
ca,K(τ) = 1
2π
w
dεe
iτε/h¯
JK(ε)fe,K(ε)
. (20.6.6)
The additivity of the contributions from the different reservoirs is a seemingly
straightforward generalization of Eq. (20.5.3). Indeed, it is derived from the addi￾tive contributions of the different reservoirs to the single-particle Hamiltonian, from
the lack of direct inter-reservoir coupling (the inherent locality associated with the
tight binding model assumptions), and from the restriction of the system–bath cou￾pling to the single-particle level. Notice, however, that even within this structure of the
system–bath coupling, the interaction of each reservoir with the system may induce
inter-reservoir correlations. Such correlations are missed within the Born–Markov
approximation, as they appear beyond the second order in the system–bath coupling
operator.
Exercise 20.6.1 For a generic system–bath coupling term, Hˆ
SB ≡ ∑α Vˆ
(S)
α Uˆ
(B)
α , the dis￾sipator in the Born–Markov approximation obtains the form shown in Eqs. (19.3.21,
19.3.22). To bring to this form the coupling operator, Hˆ
SB = ∑
K
(Vˆ
S,KUˆ
B,K +Vˆ
†
S,KUˆ
†
B,K
),
let us define Hˆ
SB ≡ ∑α∈K,nVˆ
(S)
α Uˆ
(B)
α = ∑K ∑
2
n=1Vˆ
(S)
K,nUˆ
(B)
K,n
, where Vˆ
(S)
K,1 = Vˆ
S,K, Vˆ
(S)
K,2 =
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press462 Open Many-Fermion Systems
Vˆ
†
S,K
, Uˆ
(B)
K,1 = Uˆ
B,K = ∑
kK
γkK
aˆkK
, Uˆ
(B)
K,2 = Uˆ
†
B,K = ∑
kK
γ
∗
kK
aˆ
†
kK
, such that the dissipa￾tor (Eq. (19.3.22)) obtains the form Dˆ ρˆS(t) = −
1
h¯
2 ∑
K,K0
∑
n,n
0∈1,2
rt
0
dτ{cK,n,K0
.n
0(τ)[Vˆ
(S)
K,n
,
e
−iτ
h¯
Hˆ
SVˆ
(S)
K0
,n
0e
iτ
h¯
Hˆ
SρˆS(t)]+cK0
,n
0
,K,n
(τ)[ρˆS(t)e
−iτ
h¯
Hˆ
SVˆ
(S)
K0
,n
0e
iτ
h¯
Hˆ
S
,Vˆ
(S)
K,n
]}, with the bath correla￾tion functions, cK,n,K0
,n
0(τ) = trB{Uˆ
(B)
K,n
e
−iτ
h¯
Hˆ
BUˆ
(B)
K0
,n
0e
iτ
h¯
Hˆ
B ρˆB}, cK,n,K0
,n
0(τ) = cK,n,K0
,n
0(−τ),
where Hˆ
B = ∑
K
HˆK, ρˆB = ∏
K
ρˆK. (a) Use the results of Ex. 20.5.1 to show that the correla￾tion functions involving different reservoirs vanish, namely cK,n,K0
,n
0(τ) = δK,K0c
(K)
n,n
0(τ),
where c
(K)
n,n
0(τ) = trK{Uˆ
(B)
K,n
e
−iτ
h¯
HˆKUˆ
(B)
K,n
0e
iτ
h¯
HˆK ρˆK}. (b) Using this result, show that the
dissipator reads
Dˆ ρˆS(t) = −
1
h¯
2 ∑
K
∑
n,n
0∈1,2
wt
0
dτ{c
(K)
n,n
0(τ)[Vˆ
(S)
K,n
, e
−iτ
h¯
Hˆ
SVˆ
(S)
K,n
0e
iτ
h¯
Hˆ
SρˆS(t)]
+c
(K)
n
0
,n
(τ)[ρˆS(t)e
−iτ
h¯
Hˆ
SVˆ
(S)
K,n
0e
iτ
h¯
Hˆ
S
,Vˆ
(S)
K,n
]}.
(c) Apply the treatment in Ex. (20.5.2) to the dissipator in (b) to derive Eq. (20.6.4),
where the absorption and emission correlation functions are defined in Eq. (20.6.5).
Assuming that fast bath relaxation (the stationary Redfield approximation) and the
secular approximation hold independently for each of the reservoirs, and using the
additivity of the dissipators associated with the different reservoirs, we can readily gen￾eralize the derivation leading from Eq. (20.5.8) to Eq. (20.5.15) to multiple reservoirs.
The kinetics of population transfer between any two eigenstates, |Ψn
0i and |Ψni, of the
many-particle system Hamiltonian ( Hˆ
S) is then given by the general master equation,
∂
∂t
Pn(t) ∼= ∑
n
0
"
∑
K
k
(K)
n
0→n
#
Pn
0(t)−∑
n
0
"
∑
K
k
(K)
n→n
0
#
Pn(t). (20.6.7)
Here Pn(t) is the transient population of the nth eigenstate, and k
(K)
n→n
0
is the contri￾bution of the Kth reservoir to the overall state-to-state transition rate, which depends
on the specific reservoir spectral density, temperature, and chemical potential (via the
respective Fermi distribution functions):
k
(K)
n→n
0 =




Vˆ
S,K

n,n
0



2 JK(En −En
0)
h¯
fh,K(En −En
0)
+




Vˆ
S,K

n
0
,n



2 JK(En
0 −En)
h¯
fe,K(En
0 −En). (20.6.8)
Recalling that within the master equation, bath-induced transition rates are restricted
to an exchange of a single electron (Eqs. (20.5.14, 20.5.15)), we have
k
(K)
n→n
0 =







Vˆ
S,K

n,n
0



2
JK(En−En
0)
h¯
fh,K(En −En
0) ; Nn
0 = Nn −1




Vˆ
S,K

n
0
,n



2
JK(En
0−En)
h¯
fe,K(En
0 −En) ; Nn
0 = Nn +1
0 ; otherwise
. (20.6.9)
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press463 20.6 Nonequilibrium Fermion Systems
Notice that the transition rates are nonnegative. Hence, by its structure (see Eqs.
(19.4.13-19.4.18)) Eq. (20.6.7) has a stationary solution, ∂
∂t
Pn(t) = 0. Nevertheless,
unlike in the case of coupling to a single reservoir (Eqs. (20.5.16, 20.5.17)), if the dif￾ferent reservoirs are associated with different chemical potentials and/or temperatures,
the stationary solution will not reflect the equilibrium distribution in any of the reser￾voirs. Instead, the reduced system density will adopt an “intermediate” steady state
that does not comply with the constraints imposed on any of the reservoirs. This state
will involve a constant flow of charge and/or energy between the reservoirs through the
system.
Charge Transport through Nanoscale Conductors
Molecular conductance junctions are devices in which a single molecule is connected
to two macroscopic electrodes [20.4]. The coupling between the molecule and the elec￾trodes can be via chemical bonds of the molecule to atoms at the contact interface
(metals, typically), or remote, as, for example, in a scanning tunneling microscope,
discussed in Section 6.1. When a bias potential is applied, charge flows through the
molecular conductor. The dependence of the current on the bias voltage can reveal
the detailed electronic structure of the molecule and the contacts. Additionally, elec￾tronically inelastic charging and discharging events at the electrode interfaces drive
the molecule far from equilibrium, possibly changing its conformational state and/or
chemical composition. These processes affect the mechanical stability of the junction,
as well as its response to changes in the bias potential. The latter reveals phenom￾ena such as nonlinear current–voltage relations, negative differential resistance, and
kinetic hysteresis, which are of fundamental interest as well as of potential relevance
to nanoelectronics applications.
From a formal point of view, a single molecule junction can be modeled as an
impurity, coupled to two reservoirs, where the bias potential is associated with a
difference between the chemical potentials at the two reservoirs. Inelastic processes
and mechanical conformational changes in response to the bias are critical for the
description of realistic single molecule junctions [20.5]. Here, for pedagogical pur￾poses, we shall ignore the mechanical degrees of freedom, discussing a hypothetical
system (corresponding to “clamping” the atomic nuclei) with a “purely electronic”
model Hamiltonian, namely a specific realization of Eq. (20.6.1). Only two reservoirs
will be considered, corresponding to “right” and “left” electrodes, with K ∈ R,L. The
respective chemical potentials would be denoted µR and µL, where we shall allow for
µR 6= µL. Without loss of generality, we shall consider here only cases in which the same
temperature applies to the two reservoirs.
We are interested in charge flow into and out of the impurity. The averaged total
number of electrons on the impurity at a given time is given by the expectation value
of the electron number operator, Nˆ
S =
MA
∑
m=1
aˆ
†
maˆm, namely
NS(t) = trS[ρˆS(t)Nˆ
S]. (20.6.10)
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press464 Open Many-Fermion Systems
Recalling that the number operator is diagonal in the system Hamiltonian eigen￾state representation (Eq. (20.5.10)), it is convenient to evaluate the trace in this basis,
where only the eigenstate populations (diagonal elements of the reduced system density
matrix) are needed, Pn(t) = [ρˆS(t)]n,n,
NS(t) = ∑n
Pn(t)Nn. (20.6.11)
Within the Born–Markov and secular approximations, the populations of the system
Hamiltonian eigenstates follow the master equation, Eq. (20.6.7), which reads in this
case
∂
∂t
Pn(t) ∼= ∑
n
0
k
(R)
n
0→n
Pn
0(t)−∑
n
0
k
(R)
n→n
0Pn(t)+∑
n
0
k
(L)
n
0→n
Pn
0(t)−∑
n
0
k
(L)
n→n
0Pn(t). (20.6.12)
The change in the averaged total electron number within the system therefore reads
∂
∂t
NS(t) = ∑
n,n
0
k
(R)
n
0→n
Pn
0(t)Nn − ∑
n,n
0
k
(R)
n→n
0Pn(t)Nn + ∑
n,n
0
k
(L)
n
0→n
Pn
0(t)Nn − ∑
n,n
0
k
(L)
n→n
0Pn(t)Nn.
(20.6.13)
Since the contributions from the two reservoirs to ∂
∂t
NS(t) are additive, it is instructive
to identify the transient particle fluxes into the system from each of the reservoirs,
JR(t) ≡ ∑
n,n
0
k
(R)
n
0→n
Pn
0(t)Nn − ∑
n,n
0
k
(R)
n→n
0Pn(t)Nn
JL(t) ≡ ∑
n,n
0
k
(L)
n
0→n
Pn
0(t)Nn − ∑
n,n
0
k
(L)
n→n
0Pn(t)Nn,
(20.6.14)
where
∂
∂t
NS(t) = JL(t) +JR(t). (20.6.15)
The structure of the master equation, Eq. (20.6.12), guarantees the existence of a
stationary solution (Eqs. (19.4.15–19.4.18)), in which the eigenstate populations are
fixed in time, {P
(st)
n }. Setting ∂
∂t
P
(st)
n = 0, these populations satisfy the equation:
∑
n
0
k
(R)
n
0→n
P
(st)
n
0 −∑
n
0
k
(R)
n→n
0P
(st)
n +∑
n
0
k
(L)
n
0→n
P
(st)
n
0 −∑
n
0
k
(L)
n→n
0P
(st)
n = 0. (20.6.16)
Using the matrix notations of Eqs. (19.4.16, 19.4.17), this equation can be written as a
homogeneous system of linear equations,
(KR +KL)P
(st) = 0, (20.6.17)
where
[KR]n,m = (1−δm,n)k
(R)
m→n −δm,n ∑
n
06=n
k
(R)
n→n
0
[KL]n,m = (1−δm,n)k
(L)
m→n −δm,n ∑
n
06=n
k
(L)
n→n
0
.
(20.6.18)
Since the total averaged electron number in the system is also constant in time
(
∂
∂t
NS(t) = 0, by Eq. (20.6.11)), the net particle flux into the system vanishes. However,
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press465 20.6 Nonequilibrium Fermion Systems
unlike in an equilibrium state (obtained by coupling the system to a single reservoir),
the average fluxes at the two system–reservoir interfaces, J
(st)
L
and J
(st)
R
, do not nec￾essarily vanish. Instead, the only restriction imposed by the stationarity condition
(Eq. (20.6.16)) reads
J
(st)
L = −J
(st)
R
. (20.6.19)
This restriction implies that any increase in the number of particles coming from the left
reservoir, is compensated by an equivalent decrease in the number of particles leaving
to the right reservoir (and vice versa). This steady state is characterized by a constant
charge current through the system, given by the probability flux, multiplied by the
electron charge. Without loss of generality, defining the current direction from left to
right, the steady-state current reads
I
(st)
L→R = e∑
n,n
0
k
(L)
n
0→n
P
(st)
n
0 Nn −e∑
n,n
0
k
(L)
n→n
0P
(st)
n Nn = e∑
n,n
0
k
(L)
n
0→n
P
(st)
n
0 (Nn −Nn
0), (20.6.20)
or I
(st)
L→R = e∑
n
[KLP
(st)
]nNn.
Current through a Single-State Impurity
The solution of the homogeneous equation, Eq. (20.6.17), to obtain the steady￾state populations, {P
(st)
n } is generally straightforward. It may become cumbersome,
however, when the number of many-particle states within the system is large. It is
instructive, therefore, to relate to an analytically solvable model, which captures some
qualitative essence. For this purpose, we refer to the single-state impurity model dis￾cussed in Section 20.5. The model Hamiltonian, Eq. (20.5.18), is extended to account
for two (“right” and “left”) reservoirs,
Hˆ = ε0aˆ
†
0
aˆ0 +
ML
∑
kL=1
εkL
aˆ
†
kL
aˆkL +
MR
∑
kR=1
εkR
aˆ
†
kR
aˆkR +
"
ML
∑
kL=1
γkL
aˆ
†
0
aˆkL +
MR
∑
kR=1
γkR
aˆ
†
0
aˆkR +h.c.
#
.
(20.6.21)
The eigenstates of the system Hamiltonian in this case correspond to the unoccupied
(|0i) and occupied (|1i) single-particle states. There are two transition rates between
these states at each of the reservoirs, as illustrated in Fig. 20.6.1. Setting n,n
0 ∈ (0,1),
the master equation for the corresponding eigenstate populations, P0(t) = ρ0,0(t) and
P1(t) = ρ1,1(t), reads (see Eq. (20.6.12))
∂
∂t
P0(t) = (k
(R)
1→0 +k
(L)
1→0
)P1(t)−(k
(R)
0→1 +k
(L)
0→1
)P0(t)
∂
∂t
P1(t) = (k
(R)
0→1 +k
(L)
0→1
)P0(t)−(k
(R)
1→0 +k
(L)
1→0
)P1(t),
(20.6.22)
and the corresponding transient probability fluxes read (Eq. (20.6.14))
JL(t) = ek(L)
0→1
P0(t)−ek(L)
1→0
P1(t)
JR(t) = ek(R)
0→1
P0(t)−ek(R)
1→0
P1(t)
. (20.6.23)
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press466 Open Many-Fermion Systems
k1→0
(L)
k0→1
(L)
k0→1
ε0
(R)
k1→0
(R)
µL
µR
Ftigure 20.6.1 A schematic representation of the kinetics of charge transport through a single-state impurity. The electron reservoirs
are characterized by the conductance bands, filled up to the respective chemical potentials. (Black and gray areas
correspond to electronically filled and empty reservoir states at zero temperature.) The master equations are
characterized by four rate constants, corresponding to electron absorption or emission at each electrode interface.
At steady state, the populations satisfy the stationarity condition, ∂
∂t
P0(t) = ∂
∂t
P1(t) = 0
(Ex. 20.6.2), which yields
P
(st)
0 =
k
(R)
1→0 +k
(L)
1→0
k
(R)
1→0 +k
(L)
1→0 +k
(R)
0→1 +k
(L)
0→1
; P
(st)
1 =
k
(R)
0→1 +k
(L)
0→1
k
(R)
1→0 +k
(L)
1→0 +k
(R)
0→1 +k
(L)
0→1
, (20.6.24)
and the steady-state charge current therefore reads (Eq. (20.6.20))
I
(st)
L→R = ek(L)
0→1
P
(st)
0 −ek(L)
1→0
P
(st)
1
. (20.6.25)
The total charge on the impurity at steady state, and the charge current through it
depend on the microscopic model parameters, as well as on the constraints imposed
on the reservoirs. To analyze these dependencies, we use the expression of the state￾to-state transition rates at the Kth electrode in terms of the corresponding spectral
densities and Fermi distribution functions (see Eq. (20.5.24)):
k
(K)
1→0 =
1
h¯
JK(ε0)fh,K(ε0) ; k
(K)
0→1 =
1
h¯
JK(ε0)fe,K(ε0). (20.6.26)
Eq. (20.6.24) therefore yields (Ex. 20.6.3)
P
(st)
1 =
JR(ε0)
JR(ε0) +JL(ε0)
fe,R(ε0) + JL(ε0)
JR(ε0) +JL(ε0)
fe,L(ε0). (20.6.27)
The result is an average of the two Fermi distribution functions at the two reservoirs,
weighted by their respective spectral densities. Notice that when the two reservoirs have
the same chemical potential and temperature, the system reaches an equilibrium state
in which the impurity population reflects a single Fermi distribution, just as in the
case of coupling to a single reservoir (see Eq. (20.5.26)). When the reservoirs differ in
their chemical potentials, a nonequilibrium steady state is reached, in which the relative
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press467 20.6 Nonequilibrium Fermion Systems
fe,L (ε) − fe,R(ε) fe,L (ε) − fe,R(ε)
µR µL
Energy
0
1
(a)
(b)
µR µL
Energy
0
1
Ftigure 20.6.2 Fermi’s conductance window for a finite bias potential between “left” and “right” reservoirs. Only charging energies
that are “inside the conductance window” contribute to the left-to-right current, where the sign of the current is set
by the sign of the window function, which is positive for µL > µR (a) and negative for µR > µL (b). The solid and
dotted lines correspond to zero and finite temperatures, respectively.
dominance of each reservoir is determined according to its spectral density, namely,
according to the relative system–bath coupling.
The steady-state current is obtained by using Eqs. (20.6.26, 20.6.27) in Eq. (20.6.25)
(see Ex. 20.6.4):
I
(st)
L→R =
e
h¯
JL(ε0)JR(ε0)
JR(ε0) +JL(ε0)
[ fe,L(ε0)− fe,R(ε0)]. (20.6.28)
The steady-state current is shown to be proportional to a “reduced spectral density,”
J(ε0) = JL(ε0)JR(ε0)
JR(ε0)+JL(ε0)
, and to “Fermi’s conductance window,” which is the difference
between the Fermi distributions at the two leads, fe,L(ε0) − fe,R(ε0), at the impurity
charging energy, ε0 (see Fig. 20.6.2). Notice that when the spectral densities at the
two reservoirs are the same, JL(ε0) = JR(ε0) = J(ε0), the reduced spectral density reads
J(ε0) = J(ε0)/2. When the spectral densities differ significantly, the current is nearly
proportional to the smaller of the two, J(ε0) ≈ min(JL(ε0), JR(ε0)). Hence, the cur￾rent is limited by the rate of charging/discharging at the electrode interface to which
the coupling of the impurity is weaker. The Fermi conductance window can obtain,
by definition, any value between −1 and 1, where positive and negative values of
fe,L(ε0)− fe,R(ε0) are associated with µL > µR and µR > µL, respectively. The sign of the
Fermi conductance window points to the direction of the net current at steady state,
where currents in the “left-to-right” direction are positive, and vice versa. Notice that
in any case, the current direction is from the higher to the lower chemical potential.
However, when ε0 << min{µL,µR} or ε0 >> max{µL,µR}, the charging energy is said
to be outside the “conductance window” and the current vanishes (see Fig. 20.6.3).
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press468 Open Many-Fermion Systems
ε0 ε0 ε0
µL µR
I I
< µL µR = µL µR >
Φ
−2ε0 2ε0
−1
−0.5
0
0.5
1
I / [ ] e JL(ε 0) JR (ε 0)
JR (ε 0) + JL(ε 0) h
Ftigure 20.6.3 Current–voltage curve for the single-state impurity model. The Fermi energy at equilibrium is set to zero, and the
impurity charging energy is taken to be positive, ε0 > 0. The current is plotted in units of its maximal value, as a
function of the bias potential between the two reservoirs, Φ ≡ (µL − µR)/e, assuming a symmetric drop on the
two contacts, µL = eΦ/2 = −µR. The steps in the current correspond to the entrance of the charging energy into
Fermi’s conductance window, where the current direction is from the higher to the lower electrode chemical potential.
The current depends on the applied bias voltage between the left and right electrodes,
Φ ≡ (µL −µR)/e, as well as on the impurity charging energy, ε0; namely, on the energy
difference between the charged impurity and the Fermi energy of the electrodes at equi￾librium. The current–voltage curves can therefore reveal the impurity charging energy,
where for a symmetric voltage drop, namely µL = eΦ/2 = −µR, a step in the current
is revealed at Φ = 2ε0 (see Fig. 20.6.3). According to Eq. (20.6.28), the step-height
equals eJ(ε0)/h¯, which depends on the coupling strength to the two reservoirs, and the
step width increases with the temperature, which reflects the broadening as the Fermi
conductance window as the reservoir’s temperature increases.
Within the Born–Markov approximation, as the reservoirs’ temperature goes to
zero, so does the step-width in the current-voltage curve (Fig. 20.6.3). Moreover,
as the coupling to the reservoirs (via the spectral densities) increases, the current
seems to increase indefinitely. These two effects reflect an inaccuracy of the Born–
Markov approximation, in which the state-to-state rate calculation is subject to strict
energy conservation. We can readily see (for a detailed discussion, see Section 19.2 and
Eq. (19.2.25)) that the distribution over final state energies per charging/discharging
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press469 20.6 Nonequilibrium Fermion Systems
event is effectively Lorentzian-broadened (where the width corresponds to the transi￾tion rate, which is of the order of the spectral densities, divided by Plank’s constant).
This “intrinsic” (or “time-energy uncertainty”) broadening implies that the steps in
the current–voltage curve should have a finite width, and that with increasing spectral
densities the current through the impurity cannot increase indefinitely, since the corre￾sponding energy broadening of the impurity state energy may exceed the conductance
window. These effects are accounted for in higher-order treatments of the system–bath
coupling beyond the Born–Markov approximation [20.6] [20.7], including treatments
based on quantum scattering theory [5.6], or Green’s functions [20.8].
Exercise 20.6.2 Use Eq. (20.6.22) for calculating the system eigenstate populations at
steady state, P
(st)
0
and P
(st)
1
, and show that the normalized populations (P
(st)
0 +P
(st)
1 = 1)
are given by Eq. (20.6.24).
Exercise 20.6.3 Use Eqs. (20.6.24, 20.6.26) to derive Eq. (20.6.27).
Exercise 20.6.4 Use Eqs. (20.6.26, 20.6.27) in Eq. (20.6.25) to derive Eq. (20.6.28).
Transport through a Noninteracting Impurity
In the case of a multistate impurity, there are multiple charging/discharging energies,
each corresponding to the addition/substruction of a single electron to the small many￾particle system. Within the Born–Markov and secular approximations (assuming weak
coupling to the reservoirs and non-degenerate impurity Hamiltonian), the contribu￾tions of the different charging/discharging events to the current are additive, resulting
in a multistep current–voltage curve. In general, even in this case the nonequilibrium
state in a multistate conductor is too cumbersome to follow analytically. Nevertheless,
for a noninteracting system (when both electron–electron and vibronic interactions
are negligible) the expressions for the nonequilibrium eigenstate populations and the
steady-state current through the impurity are rather transparent and intuitive.
First, let us recall (see Ex. 20.5.7) that in the absence of interactions within the sys￾tem (i.e., Hˆ
s = ∑
MA
m=1
εmaˆ
†
maˆm in Eq. (20.6.1)) the eigenvectors of the system Hamiltonian
are determinants, denoted as {|n1,n2,n3,...,nMA
i}. Each determinant is fully charac￾terized by the MA-dimensional vector of occupation numbers, n = (n1,n2,n3,...,nMA
),
where nm = 1 and nm = 0 correspond, respectively, to occupied and unoccupied
single-particle states. The state-to-state transitions are restricted in this case to either
absorption or emission of a single electron at the mth single-particle state, character￾ized by state specific absorption (ka,m) or emission (ke,m) rates. The transition rates
between many-particle states therefore obtain the form (see Ex. 20.5.7),
kn→n
0 = ∑
MA
m=1
[δn−n
0
,em
ke,m +δn
0−n,em
ka,m], (20.6.29)
where em is a unit vector of length MA, with elements [em]m0 = δm,m0 . We can ver￾ify (Ex. 20.6.5) that in this case there is a steady-state solution 
∂P
(st)
n
∂t = 0

to the
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press470 Open Many-Fermion Systems
master equation, Eq. (20.6.12), in which the population of the many-particle system
eigenstates are products of occupation probabilities of the single-particle states, namely
P
(st)
n =
MA
∏m=1
(P
(st)
m,[n]m
). (20.6.30)
The probability attributed to the mth single particle state depends on whether this state
is populated or not, within each nth many-particle state; namely, whether [n]m equals
‘one’ or ‘zero,’
P
(st)
m,1 =
JR,m(εm)
JR,m(εm) +JL,m(εm)
fe,R(εm) + JL,m(εm)
JR,m(εm) +JL,m(εm)
fe,L(εm)
P
(st)
m,0 =
JR,m(εm)
JR,m(εm) +JL,m(εm)
fh,R(εm) + JL,m(εm)
JR,m(εm) +JL,m(εm)
fh,L(εm)
. (20.6.31)
This result is a natural generalization of the result for a single-state impurity,
Eq. (20.6.27), where the charging energy ε0 is replaced by the respective single-particle
state (orbital) energy, εm, and the spectral density at each reservoir is scaled by an
m-dependent factor,
JK,m(εm) ≡ |νm,K|
2
JK(εm). (20.6.32)
Here, |νm,K|
2
is the probability of occupying the (local) system site that is coupled
to the Kth reservoir, at the mth single-particle state. According to Eq. (20.6.31), the
steady-state probability of occupying the mth single-particle state by an electron/hole
is a weighted average of the Fermi distributions of electrons/holes at the two reservoirs.
The relative weights are determined independently per orbital, by its relative coupling
to the two reservoirs.
Given the steady-state population of the eigenstates of the system Hamiltonian, an
analytic expression for the steady-state current can also be derived (Ex. 20.6.6):
I
(st)
L→R =
e
h¯ ∑
MA
m=1
JR,m(εm) JL,m(εm)
JR,m(εm) +JL,m(εm)

fe,L(εm)− fe,R(εm)

. (20.6.33)
Thisresult generalizes the expression derived for the single-state impurity (Eq. (20.6.28))
to the case of multiple-state impurity. As expected, the current through the different
single-particle states is additive in this case. Each single-particle state (orbital) con￾tributes independently to the current, where this contribution is proportional to a
“reduced spectral density,” J(εm) = JL,m(εm)JR,m(εm)
JR,m(εm)+JL,m(εm)
, and to the Fermi conductance win￾dow, evaluated at the single-particle state energy, fe,L(εm)− fe,R(εm). This implies that
the current–voltage plot (see Fig. 20.6.4) can reveal the single-particle energies of the
impurity. Each such energy corresponds to a step, whose position is at a specific volt￾age Φm = 2εm (assuming a symmetric voltage drop on the contacts), and whose height
depends on the coupling strength to the two reservoirs. An important aspect appar￾ent from Eqs. (20.6.32, 20.6.33) is that the contribution of each single-particle state to
the current increases with increasing projections of the corresponding orbital on the
local sites to which the two electrodes are coupled (|νm,L|
2 and |νm,R|
2
). In the con￾text of molecular electronics, for example, this means that molecules with delocalized
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press471 20.6 Nonequilibrium Fermion Systems
ε1
−2ε3 −2ε2 −2ε1 2ε1 2ε2 2ε3
I
Φ
ε2
ε3
Ftigure 20.6.4 Current–voltage curve for a multistate noninteracting impurity model. The Fermi energy at equilibrium is set to zero,
and the charging energies of the impurity single-particle states are taken to be positive, ε1, ε2, ε3,... > 0. The
current is plotted as a function of the bias potential between the two reservoirs, Φ ≡ (µL − µR)/e, assuming a
symmetric drop on the two contacts, µL = eΦ/2 = −µR. The steps in the current correspond to the entrance of
the different orbital energies into Fermi’s conductance window.
orbitals (which have simultaneous nonvanishing probability amplitudes at the contact
sites to the two electrodes) are better conductors in a single molecule junction, which
is indeed the case. Such molecules are typically associated with conjugated systems of
π-electrons, as discussed in Section 14.4.
Notice that the current formula, Eqs. (20.6.32, 20.6.33), is accurate (apart from
the missing broadening) only within the limitations of the Born–Markov and secular
approximations; namely, when the single-particle states are well separated in energy
(in the sense that the level spacings are large in comparison to the spectral densi￾ties) and the many-particle Hamiltonian is nondegenerate. When this is not the case,
coherences between system eigenstates become important, and interference between
different transport pathways leads to a rich behavior (e.g., [20.9]), which is beyond the
expected step-like current–voltage curves predicted by the Born–Markov and secular
approximations.
Exercise 20.6.5 (a) Use the results of Ex. 20.5.7 to show that for a system of nonin￾teracting fermions, the equation for the steady-state population of the nth many-particle
state (P
(st)
n , Eq. (20.6.16)) reads ∑
MA
m=1
[δn
0−n,em
ke,m +δn−n
0
,em
ka,m]P
(st)
n
0 −[δn−n
0
,em
ke,m +
δn
0−n, em ka,m]P
(st)
n = 0, where ke,m =
1
h¯
JR,m(εm)fh,R(εm) + 1
h¯
JL,m(εm)fh,L(εm), ka,m =
1
h¯
JR,m(εm)fe,R(εm)+ 1
h¯
JL,m(εm)fe,L(εm), and JK,m(ε) = |νm,K|
2
JK(ε). (b) Show that P
(st)
n =
MA
∏
m=1
(P
(st)
m,[n]m
), with P
(st)
m,[n]m
=
ka,m
ke,m+ka,m
δ[n]m,1 +
ke,m
ke,m+ka,m
δ[n]m,0
, satisfies the equation for the
steady-state population of the nth many-particle state in (a). (c) Show that P
(st)
m,1 +P
(st)
m,0 =
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University Press472 Bibliography
1, and therefore the sum over all the eigenstate populations reads ∑n P
(st)
n =1. (d) Use the
explicit expressions for the absorption and emission rates in (a) to derive Eq. (20.6.31)
for the occupation probabilities of the single-particle states, at steady state.
Exercise 20.6.6 For a system of noninteracting fermions, the equation for the steady￾state current (Eq. (20.6.20)) can be written as I
(st)
L→R = e ∑
n,n
0
k
(L)
n
0→n
P
(st)
n
0
[Nn − Nn
0],
where n is an occupation vector, n = (n1,n2,n3,...,nMA
). (a) Using Eq. (20.6.29)
for the state-to-state transition rates, and the results of Ex. 20.6.5 for the corre￾sponding steady-state populations in this case, P
(st)
n =
MA
∏
m=1
(P
(st)
m,[n]m
), with P
(st)
m,[n]m
=
ka,m
ke,m + ka,m
δ[n]m,1+
ke,m
ke,m + ka,m
δ[n]m,0
, show that I
(st)
L→R = e∑
MA
m=1
[−P
(st)
m,1
k
(L)
e,m + P
(st)
m,0
k
(L)
a,m]. (b)
Use the explicit expressions for the emission and absorption rates (see Ex. 20.6.5), ke,m =
1
h¯
JR,m(εm)fh,R(εm)+ 1
h¯
JL,m(εm)fh,L(εm), ka,m =
1
h¯
JR,m(εm)fe,R(εm)+ 1
h¯
JL,m(εm)fe,L(εm), to
derive Eq. (20.6.33) for the steady-state current.
Bibliography
[20.1] J. Hubbard, “Electron correlations in narrow energy bands,” Proceedings of
the Royal Society of London. Series A, Mathematical and Physical Sciences
277, 238 (1963).
[20.2] P. W. Anderson, “Localized magnetic states in metals,” Physical Review 124,
41 (1961).
[20.3] M-C. Desjonqueres and D. Spanjaard, “Concepts in Surface Physics”
(Springer, 1996).
[20.4] J. C. Cuevas and E. Scheer, “Molecular Electronics: An Introduction to Theory
and Experiment” (World Scientific, 2nd Edition 2017).
[20.5] M. Galperin, M. A. Ratner and A. Nitzan. “Molecular transport junctions:
Vibrational effects,” Journal of Physics: Condensed Matter 19, 103201 (2007).
[20.6] L. Mühlbacher and E. Rabani, “Real-time path integral approach to nonequi￾librium many-body quantum systems,” Physical Review Letters 100, 176403
(2008).
[20.7] C. Schinabeck, A. Erpenbeck, R. Härtle and M. Thoss, “Hierarchical quan￾tum master equation approach to electronic-vibrational coupling in nonequi￾librium transport through nanosystems,” Physical Review B 94, 201407 (2016).
[20.8] Y. Meir and N. S. Wingreen, “Landauer formula for the current through an
interacting electron region,” Physical Review Letters 68, 2512 (1992).
[20.9] R. Härtle, G. Cohen, D. R. Reichman and A. J. Millis, “Decoherence and lead￾induced interdot coupling in nonequilibrium electron transport through inter￾acting quantum dots: A hierarchical quantum master equation approach,”
Physical Review B 88, 235426 (2013).
https://doi.org/10.1017/9781108877787.021 Published online by Cambridge University PressIndex
adiabatic excitation energy, 370, 379, 384, 388
angular distributions, 117, 118
angular momentum operators, 12, 39, 89–91, 97,
202, 219, 249
angular quantum number, 102, 104, 202, 223
annihilation operator, 305, 306, 440
antibonding orbitals, 256, 259, 260
antisymmetrizer, 210, 211, 213–216, 220, 228
associated Legendre polynomials, 94, 99
atomic orbitals, 153, 168, 169, 174, 175, 177, 219,
223, 225, 226, 249–253, 255–257, 259–270,
278, 281–284
Aufbau principle, 221–223, 230, 245, 257, 261, 282,
446
Bloch equations (coherence transfer), 427
Bloch theorem, 276, 278, 280
bonding orbitals, 256, 260, 262, 267
Born–Markov approximation, 396, 401, 403–405,
407, 410, 414, 422, 429, 451, 454, 459,
461–463, 470
Born–Oppenheimer approximation, 239, 240, 244,
249, 285, 368, 371, 383, 385
bosons, 193, 211, 212, 318, 351, 432
bound states, 55, 72
boundary conditions, 7, 8, 32, 35, 37, 38, 63–65,
102, 177, 182, 190, 202, 270, 274, 283, 327
bra, 129, 130, 132, 189, 286, 287, 312
canonical ensemble, 331–333, 411, 445, 451, 462
canonical operators, 11–13, 26, 124
center of mass, 77, 82, 88, 89, 201, 206, 244, 247,
249
central potential, 89, 90, 96, 97, 100, 213, 219
centrifugal potential, 100, 101
chemical bond, 81, 82, 97, 169, 192, 237, 253–256,
260, 261, 267
classical mechanics, 1–3, 12–14, 18, 20, 34, 46, 48,
55, 57, 69, 71, 74, 77, 89, 102, 124, 125, 147,
152, 200, 238, 298–300, 305
coherences, 323
coherent state, 305–307, 382
commutation relations, commutator, 10–12, 85,
204, 298, 299, 326–328, 361, 423, 452
Condon approximation, 356, 371, 385
conductor, 282, 283, 447, 449, 461, 464, 470
continuity equation, 61–63
continuous representation, 140, 142
Coulomb potential, 109, 114, 119
covalent bond, 260–262
creation operator, 305, 435, 444
current density, 62, 63
Davisson–Germer experiment, 1–4
de Broglie, 3, 4, 37, 61, 70, 179, 180
degeneracy, degenerate states, 39, 127, 158, 160,
167, 168, 172, 173, 176, 201, 209, 222, 224,
258, 273, 284
density matrix, 323, 328–333, 392, 412, 413,
426–428, 454, 459, 465
density of states, 41–44, 46, 51, 341, 342, 348, 418,
453, 454
diffraction, 1–3
Dirac’s delta, 44, 124, 134, 135, 140, 142, 318, 339,
342, 343, 362, 363, 375, 444
Dirac’s notations, 122, 136, 138, 183, 242, 356, 369
dissipator, 404, 408–410, 412, 422, 423, 427, 429,
452, 462, 463
double well potential, 54, 55, 57, 60, 254, 353–355
Dyson series, 294, 296, 310–313, 335
effective linear combination of atomic orbitals,
267, 268, 278, 355
Ehrenfest theorem, 152, 299
eigenvalue equations, 23, 79, 90, 91, 126, 136, 141,
159, 163, 189, 190, 198, 240, 267, 276, 277,
280, 281
electron spin, 199, 200, 202–205, 212, 228, 230–232
electron transfer, 352
electronic configuration, 223, 225, 226, 237, 238
emission spectra, 106–108, 111, 112
energy bands, 59, 60, 277, 280, 282
473
https://doi.org/10.1017/9781108877787.022 Published online by Cambridge University Press474 Index
energy quantization, 51, 76, 177, 364, 367
energy spectrum, 31, 35, 36, 38–41, 50, 51, 60, 63,
66, 69, 80, 81, 98, 102, 103, 129, 328, 362
entanglement, 228, 231, 392, 406
envelope function, 179, 182
exchange interaction, 224, 230, 231, 234, 235
expectation value, 152, 153, 161, 184, 186, 196, 220,
287, 288, 300, 301, 303, 320–322, 442, 465
Fermi’s golden rule, 334, 339–341, 347, 348, 350,
362, 364, 365, 375, 376, 378, 380, 387, 400,
403, 411, 416, 454, 456, 457
Fermi–Dirac distribution, 214, 445, 446, 460
Fermion anti-commutation relations, 438–441,
443, 444
fermion reservoir, 445, 446, 458, 459
fermions, 211, 212, 214, 256, 332, 432, 433, 440,
441, 444–446, 448, 449, 460, 473
field operators, 444
final ensemble, 337–341, 343, 347, 348, 373
finite square well potential, 48, 51, 52, 137
Fock space, 432, 434, 435, 438–443, 445, 449, 452,
455, 460, 461
Förster Resonant Energy Transfer (FRET), 382,
383
Fourier integral, 409, 410
Fourier transform, 341, 343, 401
Franck–Condon integrals, 360, 363, 372, 373, 377,
381, 382, 386
Gaussian wave packet, 17–22, 300–306
grand canonical ensemble, 330, 332, 333, 445, 451,
458, 462
Hückel model, 270, 272, 278
harmonic approximation, 76, 80, 82–84, 99, 100,
300, 350, 357, 381, 420
harmonic oscillator, 20, 76–81, 83, 85, 86, 101, 102,
129, 190–192, 300, 301, 303–307, 358, 362,
372, 373, 382, 386, 387
Hartree–Fock, 213, 214, 217, 219–222, 226, 257,
258, 260, 261, 263, 268, 442
Heisenberg equation, 298, 326
Heisenberg picture, 293, 297–299, 304, 306, 308,
326, 345, 346
Heisenberg’s uncertainty principle, 39, 153
Hermit polynomials, 79
Hermitian operators, 25–29, 39, 126, 127, 132, 136,
137, 140, 149, 152, 203, 210, 240, 263, 287,
288, 417, 437
Hilbert space, 122, 129–134, 141, 144, 145, 161,
183, 184, 217, 247, 289, 290, 293, 294, 307,
308, 315, 320, 322–327, 329, 351, 366,
392–397, 404, 406, 432, 433, 443, 447, 450
Huckel model, 272, 273
Hund’s rule, 224, 235, 258, 259
hydrogen-like atom, 9, 168, 170, 175, 197, 199, 201,
213, 219, 222, 224, 249
improper states, functions, 7, 35, 48, 50, 62, 123,
132–137, 140, 141, 153, 214, 434, 443
impurity models, 449, 450, 466, 469, 472
infrared absorption, 75
inhomogeneous equation, 66, 394, 395
initial ensemble, 344, 347, 348
inner product, 27, 128–130, 134–140, 144, 158, 324,
325, 407, 434
insulator, 262, 273, 282–284
interaction picture, 296–298, 309–311, 335, 394,
395, 398, 407, 409, 412, 428
interference, 2, 3, 45, 173, 256, 287, 367, 472
ionic bonds, 238, 260–262, 273, 282, 284
irreversible processes, 392, 397
ket, 128–133, 145, 203
Kronecker delta, 29, 130
Kronecker product, 144, 154
ladder operators, 85, 86, 93, 94, 202, 204, 351
Laguerre polynomials, 362
Legendre polynomials, 93, 99
linear combinations of atomic orbitals, 192, 250,
251, 256, 258, 259, 263, 266, 274, 278, 283
linear operators, 28, 29, 131, 132, 139, 142, 145
linear response, 312, 316, 368, 376, 378
linear variation, 185, 188, 190–193, 220, 221, 250,
254, 256, 257, 262–264, 278
Liouville space, 324–326, 395, 404, 405
Liouville–von Neumann equation, 327, 404, 408,
409, 419
local operators, 11, 124, 141, 152, 176
magnetic quantum number, 201, 202
Marcus formula, 366, 390
matrix representation, 131, 132, 143, 149, 159, 162,
168, 171, 173, 175, 176, 190, 204, 241, 243,
263, 279, 289, 323–325, 327, 328, 355, 369,
371, 406, 419, 426, 439, 440, 447, 455, 459
mean-field approximation, 192, 196, 197, 221
measurements, 16, 24, 28, 39, 45, 122, 123, 126, 127,
129, 135, 137–139, 141, 151–154, 200, 206, 287,
288, 295, 307, 310, 320, 321, 334, 337, 392, 404
metals, 226, 237, 238, 248, 262, 444, 464, 473
microwave radiation, 99
mixed states, ensembles, 320–322, 326, 328, 334,
337
molecular electronics, 472
molecular orbitals, 192, 255–269, 272, 273, 284, 379
Nakajima–Zwanzig projection, 405, 421, 451
nanoparticles, 33, 177
nonadiabatic charge transfer, 353
nonadiabatic coupling, 246, 248
https://doi.org/10.1017/9781108877787.022 Published online by Cambridge University Press475 Index
noncommuting operators, 153
non-crossing rule, 247
nonequilibrium, 345, 460, 461, 468, 470
nonlocal operators, 13, 124, 150, 219, 230
normal modes, 76, 77, 82, 84, 369, 421
normalization, 8, 16, 19–21, 51, 54, 78, 91, 92, 94,
95, 123, 126, 129, 132, 133, 141, 142, 156, 170,
250, 306, 330–333, 435, 437
number operator, 86, 332, 436, 438, 443, 445, 455,
465
observables, 16, 24, 123, 124, 126, 129, 135,
137–139, 151–154, 200, 208, 209, 288–291,
296–300, 302, 311, 320, 321, 324, 392,
404–407, 436, 444, 447, 460
orbital hybridization, 169
orthonormal functions, 27, 126, 135, 240
orthonormal set, 29, 95, 129–133, 135, 137, 139,
142, 145, 157, 159, 160, 170, 176, 205, 222,
241, 275, 325, 369, 444, 445, 449
overlap integral, 27, 28, 126, 139, 140, 252, 253,
355, 390
particle in a box, 35, 37, 40, 48
particle on a ring, 37, 38, 91
Pauli Hamiltonian, 205
Pauli master equation, 410, 415–418, 457
Pauli matrices, 204, 325, 426
Pauli’s exclusion principle, 213, 214, 221, 245, 256,
257, 434, 446
periodic table, 192, 200, 206, 222, 226, 227
point contact, 43, 44
polarizable medium, 352, 355, 356, 363, 364, 381
populations, 323
postulates of quantum mechanics, 5, 10, 11, 24, 25,
64, 122, 127, 129, 135, 137, 212, 307, 320, 337
potential energy barrier, 18–20, 68–70
potential energy surfaces, 244, 245, 247
potential energy well, 20, 23, 41, 42, 70, 71, 180,
186, 187, 190, 253, 278, 304
principal quantum number, 201
probability amplitude, 5, 18–23, 123, 126, 307,
312–314, 399, 402
probability conservation, 8, 32, 62, 123, 127, 314,
318, 336, 415
probability density, 5–7
probability flux, 62–65, 466
projection operators, 189, 287, 397
propagator, 17, 293, 296, 297, 309–312, 335, 393,
407
proper states, wave functions, 5–8, 16, 17, 24, 26,
27, 36, 49, 62, 123, 126, 132–138, 193, 207,
211–213, 234, 433
pure dephasing, 419, 429, 430
pure state, 321, 322, 324, 326, 328, 330, 343, 344,
346, 392, 400
quantum beats, 292, 343
quantum dots, 32, 44, 77, 367, 379
quantum size effect, 32, 34, 36, 39–41, 44, 51, 81,
103, 177, 273
quantum wells, 41, 58, 60, 70, 177, 179, 237
quantum wires, 43
quantum–classical correspondence, 300
qubit, 289, 291, 420
radial distributions, 119, 120
radial equation, 90, 100
random ensemble, 324, 330, 332
rate constant, 336, 337, 339–341, 343, 344, 347,
362, 368, 400
Rayleigh–Schrödinger perturbation theory, 163
Redfield equation, 407–410, 412, 427, 452
reduced density matrix, 419, 422, 454, 455
reduced dynamics, 392, 393
reduced mass, 82, 84, 89, 97, 99
reflection probabilities, 66–69
reorganization energy, 364–366, 378, 381, 389, 390
resonance states, 73
resonant tunneling, 71, 73
rigid rotor, 97–100, 102–104
rotating wave approximation, 317, 375, 412, 424,
428
Rydberg atom, 107
Rydberg formula, 107, 108
Scanning Tunneling Microscopy, 46
scattering states, wave functions, 1, 2, 19, 44, 61–73,
123, 124, 133, 137, 141, 245, 335, 396, 421, 470
second quantization Hamiltonian, 442
secular approximation, 412, 414, 429, 455, 459, 463
selection rules, 83, 86, 99
semiclassical limit, 300, 305, 365, 370, 377, 378,
380, 390
semiconductor, 32, 41
singlet, 228, 230–233
Slater determinant, 213, 223, 226, 257
spectral density, 341–343, 348, 401, 402, 412, 414,
417, 422, 424, 430, 453–455, 457, 459, 462,
463, 468, 471, 472
spectral line, 380, 388, 390
spherical coordinates, 6, 89, 90
spherical harmonics, 95, 96, 98, 99
spin operators, 202–204, 230–233, 351, 424, 426,
443
spin-boson model, 351, 357, 358, 370, 375, 376,
380, 381, 389, 390, 420, 421, 424
spin-orbit coupling, 14, 205
spin-orbital, 206, 212–214, 218–220, 222, 228, 231,
256, 444, 446, 456
spontaneous emission, 403, 420, 424, 425
standing wave, 23, 31
Stark effect, 175
https://doi.org/10.1017/9781108877787.022 Published online by Cambridge University Press476 Index
state vectors, 128, 133, 138–140, 142, 143, 145,
148–150, 152, 153, 161, 208, 286, 320, 327
stationary solutions, stationary states, 24, 25, 29,
51, 56, 57, 59, 63, 102, 152, 153, 286–288, 292,
327, 329, 332, 334, 399, 407, 418, 426, 458,
464, 465
steady state, 46, 327, 415, 417, 457, 458, 460, 461,
464, 466–468, 470, 471, 473
Stern–Gerlach experiment, 201–203, 206, 235
stimulated emission, 424
symmetrizer, 210, 211, 216
system–bath Hamiltonian, 405, 451, 458
tensor product, 144–146, 148, 149, 192, 205, 208,
210, 212, 216, 217, 227, 308, 327, 351, 361,
406, 433, 439, 446, 461
thermal rate, 346–348, 359, 387
tight binding, 264, 267, 269, 274, 278, 279, 284,
355, 447, 449, 450, 462
time-dependent perturbation theory, 309, 311, 314,
335
time-dependent Schrödinger equation, 14, 16, 23,
24, 29, 62, 68, 72, 152, 289, 294, 295, 297, 312
time-evolution operator, 17, 27, 293, 294, 296, 297,
303, 306–311, 313, 326, 345, 393
time-independent Schrödinger equation, 27, 28, 34,
37, 39, 40, 48, 52, 54, 59, 63, 64, 69, 76, 78, 90,
97, 102, 155, 162, 183, 286
transition probabilities, 307–318, 334–338, 397
transition rates, 86, 308, 309, 318, 334–338, 341,
343, 345–347, 362, 366, 374, 375, 377, 379, 380,
415–417, 456, 457, 463, 464, 466, 467, 471, 473
transmission probabilities, 69–72
trial functions, 183–191, 215, 264
triplet, 228, 231–233, 235, 259
tunneling, 46, 47, 54, 55, 58, 70, 71, 254, 353, 360,
366, 375, 385, 448, 453, 454, 464
tunneling splitting, 355
two-dimensional electron gas, 41, 44, 45
two-level system, 161, 247, 265, 289, 314, 337, 352,
412, 420, 421, 458
unidirectional processes, 334, 337, 397, 403
unitary transformation, 131, 295–297, 308
variation method, 185, 190, 192, 250, 278
variation principle, 184, 185, 187–190, 192, 196,
214, 257
variation space, 183, 184, 188, 189, 191–193, 197,
228, 256, 262–264
vector representation, 130, 131, 133, 203, 275, 324,
438
vibration quanta, 365, 381
vibration–rotation coupling, 102–104
vibronic spectra, 381
Von Neumann entropy, 330
wave function penetration, 47–49, 51, 72, 186
weak coupling limit, 340, 374, 401, 420, 422
wide band, 340, 343, 344, 364, 366, 400, 402, 405,
422
zero-order Hamiltonian, 155, 156, 163, 166, 178,
180, 309, 310, 312, 317, 335, 344, 346, 358–360,
368, 371, 373, 374, 384, 385, 387, 388, 397, 398
zero-point energy, 36, 81, 83, 253, 254
https://doi.org/10.1017/9781108877787.022 Published online by Cambridge University Press
