SECOND EDITION •
CONTROL
SYSTEM THEORY
AND
APPLICATION
Stanley M. Shinnersl3>. J.
MODERN
CONTROL
SYSTEM THEORY
AND
APPLICATION
SECOND EDITIONStanley M. Shinners
The Sperry Division
Division of Sperry Rand Corporation
and
New York Institute of Technology
MODERN
CONTROL
SYSTEM THEORY
AND
APPLICATION
SECOND EDITION
ADDISON-WESLEY PUBLISHING COMPANY
Reading, Massachusetts • Menlo Park, California
Amsterdam • London • Manila • Singapore • Sydney • TokyoWORLD STUDENT SERIES
SECOND PRINTING, 1980
A complete and unabridged reprint of the original American textbook, this World Student
Series edition may be sold only in those countries to which it is consigned by Addison￾Wesley or its authorized trade distributors. It may not be re-exported from the country
to which it has been consigned, and it may not be sold in the United States of America
or its possessions.
Consulting Editors
David K. Cheng, Leonard A. Gould, Fred K. Manasse
Copyright © 1978,1972 by Addison-Wesley Publishing Company, Inc.
Philippines copyright 1978,1972 by Addison-Wesley Publishing Company, Inc.
All rights reserved. No part of this publication may be reproduced, stored in a retrieval
system, or transmitted, in any form or by any means, electronic, mechanical, photocopying,
recording, or otherwise, without the prior written permission of the publisher. Original
edition published in the United States of America. Published simultaneously in Canada.
Library of Congress Catalog Card No. 78-52497.
ISBN 0-201-07059-6To my wife
Doris
and to my children
Sharon, Walter, and DanielPREFACE
The goal of Modern Control System Theory and Application is to bridge the gap
existing between classical and modern control theory. My main objective in writing
this volume has been to offer an easily understandable book from the reader’s
viewpoint. It is written in an integrated manner in order that one can proceed from
the first to the last chapter clearly.
This book aims at an audience consisting of the senior undergraduate student, the
first-year graduate student, and the practicing control-system engineer. The text, in its
first edition, has been used at over one hundred colleges and universities. Its contents
correspond to approximately three semester credit hours and are based on courses that
I have taught at universities (New York Institute of Technology, The Cooper Union and
the Polytechnic Institute of Brooklyn) and in industry (Sperry Rand Corporation).
Modern Control System Theory and Application is distinguished by the following
desirable features.
1. A unified blending of the classical and modem approaches. It uses the transfer
function and state-space methods in parallel throughout the book, and then introduces
modem optimal control theory including such important topics as dynamic programming
and the maximum principle.
2. Presentation of working digital-computer programs.
3 . The development of theoretical topics is coupled with clear applications of the theory
in engineering design. Recognizing that control theory is interdisciplinary and cuts across
all specialized engineering fields, I have presented modem illustrations and practical
problems from the fields of ecology, sociology, servomechanisms, space-vehicle systems,
aircraft, submarines, hydrofoils, economics, management, biomedical engineering, and
nuclear reactor control systems. This has been further emphasized in the second edition
and should prove to be of interest to electrical, mechanical, aerospace, system, chemical,
nuclear, biomedical, and industrial engineers.
4. A coverage of a variety of topics of recent importance. In addition to dynamic
programming and the maximum principle, the presentation includes Liapunov’s stability
criterion, Popov’s method, the generalized circle criterion, and linear-state-variable
feedback.
viiviii Preface
5. An in-depth coverage of linear and nonlinear control systems. This is a flexible book
designed for a one-term course that can be easily adapted to the student s training and
ability and to various curricula.
6. A set of problems, which has been greatly expanded for the second edition, with
answers to one third of them contained in the book. This is a helpful feature of the book
for the student, and also for the practicing control-system engineer who desires to use
the book for self-study.
7. An accompanying Instructor’s Guide and Solutions Manual containing detailed
solutions to the remaining problems This manual also presents several possible course
outlines that are based on the students’ level of learning, background, and proficiency.
By means of these features, Modern Control System Theory and Application is unique
and fills a rather large gap in the existing literature on feedback control-system design
Chapter 1 introduces the concept of open-loop and closed-loop control systems,
and defines the terminology and nomenclature used throughout the book. Chapter 2
reviews Fourier methods, the Laplace transform, and the transfer-function method.
In addition, it introduces the signal-flow diagram and the state-variable concept.
The transfer-function and state-variable representations of several common devices
found in control systems are derived in Chapter 3. The concepts of conservation and
analogy are also Introduced in this chapter. Chapter 4 focuses attention on second￾order systems since they occur so frequently and since many higher-order systems can
be approximated as second-order systems. Chapter 5 considers various performance
criteria including the IAE, ISE, ITAE, ITSE, and 1STAE methods. A comprehensive
treatment of techniques for determining stability, together with several useful and
practical examples, is given in Chapter 6. The techniques presented include the
state-space, the Routh-Hurwitz, Nyquist, Bode-diagram, Nichols-chart, and root￾locus methods. In addition, digital-computer programs are illustrated which can be
used for the routine calculations associated with several of these methods. The
concepts of stability, presented in Chapter 6, are applied in great detail to the design
of linear control systems in Chapter 7. Chapter 8 discusses the theory of design of
nonlinear systems along with practical examples. Included are linearizing approxi￾mations, the describing function, piecewise-linear approximations, the state-space
analysis technique (the phase plane), Liapunov’s stability criterion, Popov’s stability
criterion, and the generalized circle criterion. The use of analog and digital com￾puters as an aid in several of these methods is illustrated together with working
programs. Chapter 9 introduces optimal control theory and concludes the presenta￾tion. The following material is covered at an introductory level in this final chapter:
controllability, observability, calculus of variations, Bellman’s dvnamic programming,
and Pontryagin's maximum principle
The flexibility of Modern Control System Theory and Application for adapting to
the course level, the various curricula and the students’ training and ability is quitePreface ix
evident from this content summary. For example, if the book is being used in a
course where the students have only a limited familiarity with feedback, have not had
the Laplace transform previously, and if computers are not available to the students
for solving problems, it is recommended that the instructor cover Chapters 1 through
8 in detail deleting the material on computer-aided design. In addition, Sections 9.1
through 9.4 should be covered. However, if the class has good familiarity with
feedback and the Laplace transform and computers are available to the students for
solving problems, then it is recommended that the instructor should start with
Section 2.12 and cover all of the material through Chapter 9. Variations to these
general guidelines are contained in the course outlines listed in the Instructor’s Guide
and Solutions Manual.
Sampled-data and stochastic-control theories have not been included in this book
since they are usually not included in an introductory course. It is hoped, however,
that the reader will be motivated to continue his study of these and other topics of
current interest in the control literature.
I wish to express my sincere appreciation to Dr. Leonard A. Gould of the Massa￾chusetts Institute of Technology for his detailed review of the manuscript and for his
valuable comments. A debt of gratitude is also owed to Dr. John G. Truxal of the
SUNY at Stony Brook for his thorough review of the manuscript and for
his useful suggestions. Thanks- are due also to Mr. Gerald Grushow of Sperry and Dr.
Walt White of Texas Tech University for their helpful comments.
I am most grateful to my wife Doris and daughter Sharon Rose for their encour￾agement, understanding, patience, and typing assistance throughout. In addition, I
wish to express thanks and appreciation to my parents for their efforts, encourage￾ment, and inspiration.
Jericho, New York S. M. S.
January 1978CONTENTS
CHAPTER 1 THE GENERAL CONCEPT OF CONTROL-SYSTEM DESIGN
1.1 Introduction 1
1.2 Open-lbop control systems 1
1.3 Closed-loop control systems 3
1.4 Human control systems 5
1.5 Modern control-system applications 7
1.6 Definition of nomenclature and symbols 15
CHAPTER 2 MATHEMATICAL TECHNIQUES FOR
THE CONTROL ENGINEER
2.1 Introduction 22
2.2 Complex variables and the s-plane 22
2.3 Fourier series and the Fourier transform 27
2.4 The Laplace transform 34
2.5 Useful Laplace transforms 34
2.6 Important properties of the Laplace transform 36
2.7 Inversion by partial fraction expansion 37
2.8 Solution of differential equations using the Laplace transform 39
2.9 The transfer-function concept 42
2.10 Transfer functions of common networks 43
2.11 Transfer functions of systems 46
2.12 The signal-flow diagram and Mason’s theorems 51
2.13 Reduction of the signal-flow diagram 52
2.14 Application of Mason’s theorems and the signal-flow diagram to multiple
feedback systems 55
2.15 Review of matrix algebra 56
2.16 State-space concepts 63
2.17 The state-variable diagram 70
2.18 Digital-computer evaluation of the time response 74
2.19 The transition matrix 75
2.20 Application of the state-space method 79
2.21 Digital-computer evaluation of the transition matrix 81
2.22 Summary 84
xixii Contents
CHAPTER 3 STATE EQUATIONS AND TRANSFER-FUNCTION REPRESENTATION
OF PHYSICAL LINEAR CONTROL-SYSTEM ELEMENTS
3.1 Introduction 101
3.2 State equations of electrical networks 101
3.3 Transfer-function and state-space representation of typical mechanical
control-system devices 104
3.4 Transfer-function and state-space representation of typical electrical
control-system devices 109
3.5 Transfer-function and state-space representation of typicalhydraulic
devices 126
3.6 Transfer-function representation of thermal systems 132
3.7 A generalized approach for modeling—the principle of conservation and
analogy 134
CHAPTER 4 SECOND-ORDER SYSTEMS
4.1 Introduction 146
4.2 Characteristic responses of typical feedback control systems 146
4.3 State-variable signal-flow diagram of a second-order system 154
CHAPTER 5 PERFORMANCE CRITERIA
5.1 Introduction 163
5.2 Stability 163
5.3 Sensitivity 164
5.4 Static accuracy 167
5.5 Transient response 178
5.6 Performance indices 180
5.7 Zero-error systems 182
5.8 The 1TAE performance criterion for optimizing the transient response 183
5.9 Other practical considerations 184
CHAPTER 6 TECHNIQUES FOR DETERMINING CONTROL-SYSTEM STABILITY
6.1 Introduction 198
6.2 State-space determination of the characteristic equation 199
6.3 Routh-Hurwitz stability criterion 203
6.4 Nyquist stability criterion 206
6.5 Bode diagram approach 213
6.6 Digital computertechniquesfor obtaining the open-loop and closed-loop
frequency response, and the time-domain response 226
6.7 The Nichols chart 240
6.8 Relationship between closed-loop frequency response and the time￾domain response 246
6.9 The root-locus method for negative-feedback systems 249Contents xiii
6.10 The root-locus method for positive-feedback systems 265
6.11 Computer techniques for plotting the root locus 268
CHAPTER 7 LINEAR FEEDBACK SYSTEM DESIGN
7.1 Introduction 295
7.2 Cascade-compensation techniques 296
7.3 Minor-loop feedback-compensation techniques 303
7.4 An example of the design of a linear feedback control system 306
7.5 Design utilizing the Bode-diagram approach 309
7 6 Approximate methods for preliminary compensation design utilizing the
Bode diagram 320
7.7 Design utilizing the Nichols chart 327
7.8 Design utilizing the root locus 328
7.9 The concept of linear-state-variable feedback 342
7.10 Control-system design with linear-state-variable feedback 347
CHAPTER 8 NONLINEAR FEEDBACK CONTROL-SYSTEM DESIGN
8.1 Introduction 369
8.2 Nonlinear differential equations 370
8.3 Properties of linear systems that are not valid for nonlinear systems 371
8.4 Unusual characteristics that are peculiar to nonlinear systems 372
8.5 Methods available for analyzing nonlinear systems 373
8.6 Linearizing approximations 374
8.7 The describing-function concept 379
8.8 Derivation of describing functions for common nonlinearities 380
8.9 Use of the describing function to predict oscillations 396
8.10 Design of nonlinear feedback control systems using describing functions 401
8.11 Digital computer computation of the describing function 404
8.12 Piecewise-linear approximations 411
8.13 State-space analysis: the phase plane 413
8.14 Construction of the phase portrait 414
8.15 Characteristics of the phase portrait 423
8.16 Design of nonlinear feedback control systems using the phase-plane
method 431
8 17 Liapunov’s stability criterion 437
8.18 Popov’s method 446
8.19 The generalized circle criterion 453
CHAPTER 9 OPTIMAL CONTROL THEORY AND APPLICATIONS
9.1 Introduction ^75
9.2 Characteristics of the optimal control problem 473xiv Contents
9.3 Controllability 475
9.4 Observability 478
9.5 Calculus of variations 480
9.6 Dynamic programming 485
9.7 Pontryagin’s maximum principle 490
9.8 Application of the maximum principleto the space attitude control
problem 493
APPENDIX A LAPLACE TRANSFORM TABLE 513
APPENDIX B PROOF OF THE NYQUIST STABILITY CRITERION 515
ANSWERS TO SELECTED PROBLEMS 519
INDEX 535THE GENERAL CONCEPT OF
CONTROL-SYSTEM DESIGN
1.1 INTRODUCTION
The desire of man to control nature’s forces successfully has been the catalyst for
progress throughout history. His goal has been to control these forces in order to
help him perform physical tasks which were beyond his own capabilities. During
the dynamic and highly motivated twentieth century, the control-system engineer
has transformed many of man's hopes and dreams into reality.
The control ofsystems is an interdisciplinary subject and cuts across all specialized
engineering fields. This book recognizes this fact and presents illustrations of control
systems from the fields of electrical, mechanical, aeronautical, chemical, nuclear,
economics, management, bioengineering, and other related fields. The versatile
subject of automatic control ranks today as one of the most promising fields, and its
growth potential appears unlimited.
Control systems can be defined as devices which regulate the flow of energy,
matter or other resources. Their arrangement, complexity, and appearance vary with
their purpose and function. In general, control systems can be categorized as being
either open loop or closed loop. The distinguishing feature between these two types
of control system is the use of feedback comparison for closed-loop operation.
Properties characteristic of open-loop and closed-loop control systems are
discussed in this chapter. We shall give several examples of each type so that the
reader may gain a thorough understanding and a good foundation for further studies
in this book. Included will be a qualitative, philosophical comparison between the
behavior of closed-loop control systems and that of living creatures. The feedback
concept can also be applied to model our economic system. A discussion of modern
control-system applications, and definitions of nomenclature and symbols used, will
conclude the presentation of this chapter.
1.2 OPEN-LOOP CONTROL SYSTEMS
Open-loop control systems represent the simplest and least complex form of con￾trolling devices. Their concept and functioning are illustrated by several simple
examples in this section.
Figure 1.1 illustrates a simple tank level control system. We wish to hold the tank
level, h, within reasonable acceptable limits even though the outlet flow through valve
12 The General Concept of Control-System Design 1.2
Fig. 1.1 Tank level control system.
Vt is varied. This can be achieved by irregular manual adjustment of the inlet flow
rate by valve V2. This system is not a precision system since it does not have the
capability of accurately measuring the output flow rate through valve V1, the input
flow rate through valve K2, or the tank level. Figure 1.2 shows the simple relationship
which exists in this system between the input (the desired tank level) and the output
(the actual tank level). This signal-flow representation of the physical system is called
a block diagram. Arrows are used to show the input entering and the output leaving
the control system. This control system does not have any feedback comparison, and
the term open loop is used to describe its absence.
Input
(desired tank
level) Control system
-> (valve kj and
operator)
Output
(actual tank
level)
Fig. 1.2 Tank level control system block diagram.
The angular position of a missile launcher being controlled from a remote source
is illustrated in Fig. 1.3. Commands from a potentiometer located at a remote
location activate the positioning of the missile launcher. The control signal is ampli￾fied and drives a motor which is geared to the launcher. The block diagram in Fig. 1.2
is also applicable to this system. The input would be the desired angular position, the
output would be the actual angular position, and the control system would consist of
the amplifier and motor. For accurate positioning the missile launcher should be
Fig. 1.3 Controlling the position of a missile launcher from a remote location.1.3 Closed-loop Control Systems 3
Fig. 1.4 Field-controlled de motor.
precisely calibrated with reference to the angular position of the potentiometer, and
the characteristics ofthe potentiometer, amplifier, and motor should remain constant.
Except for the potentiometer, the components that comprise this open-loop control
system are not precision devices. Their characteristics can easily change and result
in false calibration and poor accuracies. In practice, simple open-loop control
systems are never used for the accurate positioning of fire control systems due to the
inherent possibility of inaccuracies and the stakes involved.
Disturbing torque
Fig. 1.5 Field-controlled de motor having a disturbance torque.
Figure 1.4 illustrates a field-controlled de motor turning a cutting wheel at a
constant speed. When a piece of wood is applied to the surface of the cutting wheel,
it acts as a disturbing torque to the driving torque of the motor and results in a
reduction of the speed of the cutting wheel, assuming that the control signal remains
constant. This situation can be represented as shown in Fig. 1.5. The symbol
appearing between the motor and the load represents a subtractor.
The effect of disturbance torques, or other secondary inputs, is detrimental to the
accurate functioning of an open-loop control system. It has no way of automatically
correcting its output since there is no feedback comparison. We must resort to
changing the input manually in order to compensate for secondary inputs.
1.3 CLOSED-LOOP CONTROL SYSTEMS
Closed-loop control systems derive their valuable accurate reproduction of the input
from feedback comparison. An error detector derives a signal proportional to the
differences between the input and output. The closed-loop control system drives
the output until it equals the input and the error is zero. Any differences between
the actual and desired output will be automatically corrected in a closed-loop control
system. Through proper design, the system can be made relatively independent of
secondary inputs and changes in component characteristics. This section illustrates4 ■ The General Concept of Control-System Design 1.3
Fig. 1.6 Automatic tank level control system.
the closed-loop control system versions of the open-loop control systems considered
in Section 1.2.
Figure 1.6 illustrates an automatic tank level control version of the system shown
in Fig. 1.1. It can maintain the desired tank level h within quite accurate tolerances
even though the output flow rate through valve Kj is varied. If the tank level is not
correct, an error voltage, e, is developed. This is amplified and applied to a motor
drive which adjusts valve V2 in order to restore the desired tank level by adjusting the
inlet flow rate. A block diagram analogous to this system is shown in Fig. 1.7.
Because feedback comparison is present, the term dosed loop is used to describe the
system's operation.
Figure 1.8 illustrates an automatic missile launcher position control version of the
system shown in Fig. 1.3. This feedback system can position the missile launcher
quite accurately on commands from potentiometer Potentiometer R2 feeds a
signal back to the difference amplifier, which functions as an error detector. Should
an error exist, it is amplified and applied to a motor drive which adjusts the output￾shaft position until it agrees with the input shaft position, and the error is zero. The
block diagram shown in Fig. 1.7 is also applicable to this system. The input would be
the desired angular position, the output would be the actual angular position, and the
control system would consist of the amplifier and the motor.
An automatic speed control version of the field-controlled de motor, which was
shown in Fig. 1.4. is illustrated in Fig. 1.9. This feedback system has the capability of
maintaining the output speed relatively constant even though disturbing torques may
Input
(desired
tank level)
Fig. 1.7 Block diagram of a closed-loop system.
Output
(actual
tank level)
-------------->1.4 Human Control Systems 5
occur. A tachometer, which functions as a transducer that transforms speed to
voltage, is the feedback element for this control system. Should the output speed
differ from the desired speed, the difference amplifier develops an error signal which
adjusts the field current of the motor in order to restore the desired output speed.
Feedback control systems used to control position, velocity, and acceleration are
very common in industrial and military applications. They have been given the special
Disturbing torque
Fig. 1.9 Automatic speed control for a field-controlled de motor.
name of servomechanisms. With all their many advantages, feedback systems have a
very serious disadvantage since the closed-loop system may inadvertently act as an
oscillator. Through proper design, however, all the advantages of feedback can be
utilized without having an unstable system. A major task ofthis book is to determine
how this may be accomplished for several kinds of systems.
1.4 HUMAN CONTROL SYSTEMS
The relation between the behavior of living creatures and the functioning of feedback
control systems has recently gained wide attention. Norbert Wiener in his book6 The General Concept of Control-System Design 1.4
Cybernetics [8] implied that all systems, living and mechanical, are both information
and feedback control systems. He suggested that the most promising techniques for
studying both systems are information theory and feedback control theory.
Several characteristics of feedback control systems can be linked to human
behavior. Feedback control systems can “think” in the sense that they can replace,
to some extent, human operations. These devices do not have the privilege offreedom
in their thinking process and are constrained by the designer to some predetermined
function. Adaptive feedback control systems, which are capable of modifying their
Error
detector
(eyes)
Fig. 1.10 Steering of an automobile—a feedback control system involving a human transfer
function.
functioning in order to achieve optimum performance in a varying environment, have
recently gained wide attention. These systems are a step closer to the adaptive capa￾bility of human behavior [14],
The human body is, indeed, a very complex and highly perfected adaptive feed￾back control system. Consider, for example, the human actions required to steer an
automobile. The driver’s object is to keep the automobile traveling in the center of a
chosen lane on the road. Changes in the direction of the road are compensated for by
the driver turning the steering wheel. His object is to keep the difference between the
output (the actual path of the car) and the input (the desired path of the car) as close
to zero as is possible.
Figure 1.10 illustrates the block diagram of the feedback control system involved
in steering an automobile. The error detector in this case is the driver's eyes. This in
turn activates the brain’s sensing elements. Signals are then transmitted from the
brain to the driver's muscles which control the steering wheel. Power amplification
is provided by the automobile’s steering mechanism, which controls the position ofthe
front wheels. Of course, this description is very crude—any attempt to construct a
mathematical model of the process should somehow account for the adaptability of
the human being and the effects of learning, fatigue, motivation, and familiarity with
the road.1.5 Modern Control-system Applications 7
1.5 MODERN CONTROL-SYSTEM APPLICATIONS
Feedback control systems are to be found in almost every aspect of our daily environ￾ment. In the home, the refrigerator utilizes a temperature-control system. The
desired temperature is set and a thermostat measures the actual temperature and the
error. A compressor motor is utilized for power amplification. Other applications of
control in the home are the hot-water heater (see Problem 1.3), the central heating
system, and the oven, which all work on a similar principle.
In industry, the term automation is very common. Modern industrial plants
utilize temperature controls, pressure controls, speed controls, position controls, etc.
The chemical process control field is an area where automation has played an impor￾tant role [1]. Here, the control engineer is interested in controlling temperature,
pressure, humidity, thickness, volume, quality, and many other variables. Areas of
additional interest include automatic warehousing [2] and inventory control [3] and
automation of farming [4],
Modern control concepts are being utilized in an ever increasing degree to help
solve various problems. In the transportation field, for example, automatic control
systems have been devised to regulate automobile traffic and control high-speed train
systems. A very widely acclaimed high-speed rail transportation system is in operation
in Japan [5, 6], This latest innovation to the system of the Japanese National Rail￾ways is the Tokyo-to-Osaka super-express train, which is illustrated in Fig. 1.11. The
high-speed railroad link between Tokyo and Osaka is commonly called the Tokaido
line. It travels over a 320-mile route in 3 hours and 10 minutes. The train can travel
at 130 miles per hour over most of the route. The system utilizes a control computer
to control the trains in an optimum manner. Figure 1.12 illustratesthe general position
control concepts of such a high-speed automated train system. Observe from the
diagram that it contains a position-measuring loop and a velocity-measuring loop.
Position can be measured from the rotation of the train’s wheels. Speed can be
measured by using velocity-sensing devices such as tachometers. The control com￾puter system monitors the positions and speeds of all trains in the system and issues
control signals via a high-speed communication system.
Automatic control systems have been applied to a large degree by the aerospace
industry. Modern high-speed aircraft, such as the F-4 long-range all-weather inter￾ceptor and attack bomber, illustrated in Fig. 1.13(a), are controlled almost entirely
automatically during their missions. Figure 1.13(b) illustrates the cockpit instrumenta￾tion needed to control this modern aircraft. Figure 1.14 illustrates one axis of the
autopilot for a typical aircraft. The feedback-loop concept is quite evident. The
desired heading is compared with the actual heading. An error signal is produced
which drives the aircraft’s control elements in order to reduce the heading error to
zero. Automatic control concepts have also been applied to the problem ofstabilizing
the attitude of space vehicles. Figure 1.15 illustrates the Apollo space vehicle. A
typical block diagram for one axis of a space attitude control system is illustrated in
Fig. 1.16. A computer is utilized to close the loop and compare the desired and actual00
Fig. 1.11 Tokyo-to-Osaka super-express train. (Courtesy of Japanese National Railways)
The General Concept of Control-System Design1.5 Modern Control-system Applications 9
Fig. 1.12 Automatic position control system.
attitude. Observe from this figure that the overall action can be viewed in terms of a
simple feedback loop.
The Polaris/Poseidon Fleet Ballistic Missile (FBM) Weapon System is a good
example of the application of automatic control to a complex naval weapon system
[9], Figure 1.17 illustrates the underwater launching of the Polaris A-3 strategic
ballistic missile. Let us go through the process of launching and guiding this missile
in order to illustrate the multitude of automatic control systems involved in the
operation. Polaris missiles are launched from the submarine by means of an air or a
gas/steam generator ejection system. The missile is propelled from the launch tube,
through the water and to the surface. At this point, a control system automatically
ignites the missile’s first-stage rocket motor and sends the missile on its mission. Two
positions must be known very accurately for successfully controlling a missile: that
of the target and launcher. In addition, the initial velocity of the launcher must be
known very accurately. Since the position and velocity of the ship (launcher) is
continuously changing in the FBM system, great emphasis must be placed on the
design of the navigation system. The FBM navigation system, managed by the
Sperry Systems Management Division, Sperry Rand Corporation, Great Neck, New
York, utilizes several methods that complement each other in order to provide a very
high order of accuracy in determining the ship's position and velocity. The heart of
the system is the Ship's Inertial Navigation System (SINS), a complex system of
gyroscopes, accelerometers, and computers, which relate movement and speed of the
ship in all directions to true north in order to give a continuous report ofship position
and velocity. The missile’s guidance package consists of an inertia) platform and a
digital computer. The inertial platform is a gyro-stabilized set of three accelerom￾eters. Once launch has occurred, the missile computer is in complete control of the
missile. During flight, missile accelerations are measured by the inertial platform and
integrated into velocities which are continuously fed to the computer. The computer10 The General Concept of Control-System Design 1.5
(a)
(b)
Fig. 1.13 (a) The F-4 aircraft, (b) Cockpit of the F-4. (Official USAF photos)Fig. 1.14 A typical autopilot system.12 The General Concept of Control-System Design 1.5
Fig. 1.16 The attitude control system of a typical space vehicle.
Fig. 1.17 Underwater firing of the Polaris A-3 missile. (Official U.S. Navy photo)1.5 Modern Control-system Applications 13
Fig. 1.18 The Boston Arm. The EMG signals (A) are processed by a small computer (B)
which compares muscle effort with load on the terminal device and controls motor (C) to
achieve lift or lowering of forearm at desired speed or force. Motion of forearm is per￾formed by changing length of bail screw (D) via gear train from motor. Power for motor is
stored in small battery pack on belt (E). (Courtesy of the Liberty Mutual Insurance
Company)
continuously compares the attained velocity information with that reference velocity
which will permit the payload to continue on to the target on a ballistic trajectory.
When this desired velocity is attained, the computer automatically issues a signal which
commands separation from the second stage motor and the payload continues on a
ballistic trajectory to the target.
There have been many applications of feedback control system concepts in the
field of bioengineering for prosthetic purposes [10, II]. As an example of the
application of feedback control system concepts to aid amputees, let us consider a
recent advance in motor prosthesis. Figure 1.18 illustrates an artificial elbow, known
as the Boston Arm, that was developed by the Massachusetts Institute ofTechnology,14 The General Concept of Control-System Design 1.5
Liberty Mutual Insurance Companies, Massachusetts General Hospital, and Harvard
Medical School [12, 13]. This device depends on an electrical signal of about one
millivolt, known as the electromyographic (EMG) signal, which is generated by a
biochemical reaction whenever a muscle tissue contracts. Even in an above-elbow
amputation, some muscle tissue usually remains in the stump which the amputee
can contract and thus generate an EMG signal. EMG signals, controlled by the
efferent nervous system that transmits information from the brain to the limb, are
Fig. 1.19 Economic feedback relationship model concerning national income, government
policy on spending, private business investment, business production, taxes, and consumer
spending.
picked up by electrodes taped to the skin over the muscle. They are then amplified
and used to control a battery-powered motor inside the forearm of the prosthesis.
The signals from the biceps muscles control the device in flexion, while the triceps
muscles control extension. Afferent reflexive feedback to the human nervous system
of force-sensing information is achieved by means of a strain-gauge element whose
electrical output opposes the EMG signal in this negative-feedback control system.
Thus, an amputee can judge the force exerted by the elbow. The angular position of
the elbow is also fed back to the control nervous system by means of a tactile display.
In one application, this was found to aid an amputee in determining the position of
his elbow by supplementing the usual visual and aural cues.1.6 Definition of Nomenclature and Symbols 15
Automatic control theory has also been applied for modeling the feedback
processes of our economic system in order to understand it better. Our economic
system contains many feedback systems and regulatory agencies. Figure 1.19
illustrates a crude model of the economics concerned with national income, govern￾ment policy on spending, private business investment, business production, taxes, and
consumer spending. This type of feedback model assists the analyst in understanding
the overall effects of government policy and private business investment on the
national income.
Feedback control systems have a very bright and unlimited potential. This
important field is one in which the engineer should become knowledgeable and
proficient for solving problems found in this modern technological age. Before we
begin our discussion of analyzing and synthesizing feedback control systems, let us
define the nomenclature which is standard in the field and which we will use.
1.6 DEFINITION OF NOMENCLATURE AND SYMBOLS
The nomenclature and symbols described in this section are based on the standards
issued by the American National Standards Institute Committee C85, Terminology
for Automatic Control, under the sponsorship of the American Society of Mechanical
Engineers [7, 15], Figure 1.20 represents a general feedback control system, using
standard symbols and notations. It would be well worth the reader’s time to memorize
the nomenclature and symbols and the definitions of these terms, since they are
employed universally by the practicing control system engineer.
The command, v, is an input which is developed externally and is independent of the
feedback control system.
The reference input elements, a, produce a signal proportional to the command.
The reference input, r, is the signal input which is proportional to the command.
The primaryfeedback, b, is a signal that is a function of the controlled variable and is
compared with the reference input in order to obtain the actuating signal.
The actuating signal, e, equals the difference between the reference input and the
primary feedback.
The control elements, Glt develop the manipulated variable from the actuating signal.
The manipulated variable, m, is the quantity obtained from the control elements and
applied to the controlled system.
The disturbance, u, represents undesired signals that attempt to affect the value of the
controlled variable c.
The controlled system, G2, is the device to be controlled.Fig. 1.20 Block diagram of a general feedback control system illustrating notations and terminology.
The General Concept of Control-System DesignProblems 17
The controlled variable, c, is the quantity of the feedback system that is controlled.
The indirectly controlled system, z, is outside the feedback loop and relates the
indirectly controlled variables to the controlled variable.
The indirectly controlled variable, q, is related to the controlled variable through the
indirectly controlled system. It is outside the feedback system and is not directly
measured for control.
Thefeedback elements, H, produce the primary feedback from the controlled variable.
The idealized system, Gt, is a system whose performance results in a response with an
ideal value from the command.
The ideal value, i, is the value of the indirectly controlled variable which would result
from an idealized system operating from the same command as the actual system.
The system error, ye, is the difference between the ideal value and the indirectly con￾trolled variable.
The dashed-line portion of the block diagram represents an idealized system. It
is used to compare the indirectly controlled variable of the system with the ideal, or
desired, value. The system error is the difference between these two values. For
systems that have unity feedback the ideal system would also equal unity.
The reference input elements and feedback elements usually consist of devices
known as transducers. These devices convert various types of input signals into other
forms ofsignals. Many examples oftransducers are used in industry. The potentiom￾eter is probably the simplest form. Its prime function is to convert a shaft position
into a proportional electrical signal. Transducers that convert velocity and accelera￾tion into proportional electrical signals are tachometers and accelerometers, respec￾tively. Pressure and temperature transducers convert pressure and temperature
changes, respectively, into proportional electrical signals.
The primary functions of the control elements are to provide amplification to the
actuating signals and to modify the frequency characteristics of the signal in order to
insure stability. Electronic, electromechanical, magnetic, hydraulic, fluidic [16], and
pneumatic devices are used for this purpose.
The controlled system is the portion of the system that responds to the manip￾ulated variable and develops the controlled variable. The controlled system may
represent a missile launcher, an aircraft's frame, or a chemical process, for example.
PROBLEMS
1.1 Figure Pl. 1 illustrates the control system for controlling the angular position of a ship's
heading. The desired heading, which is determined by the gyroscope setting, is the reference.
An electrical signal proportional to the reference is obtained from a resistor that is fixed to the18 The General Concept of Control-System Design
Figure Pl.l
ship’s frame. Qualitatively explain how this control system operates in following a command
for a southbound direction.
1.2 Explain how the rudder positioning system discussed in Problem 1.1 can be modified
to become a closed-loop control system.
1.3 An electric hot-water heater is illustrated in Fig. Pl.3. The heating element is turned
on and off by a thermostatic switch in order to maintain a desired temperature. Any demand
for hot water results in hot water leaving the tank and cold water entering. Draw the simple 
functional block diagram for this closed-loop control system and qualitatively explain how it
operates if the reference temperature of the thermostat is changed.
Figure Pl.3
1.4 Explain how the system discussed in Problem 1.3 operates if the ambient temperature
surrounding the tank suddenly changes. Refer to the block diagram.
1.5 Figure Pl.5 illustrates a control system using a human operator as part of the closed￾loop control system. Draw the block diagram of this liquid volume rate control system.Problems 19
Figure Pl.5
Valve
Liquid
flow output
1.6 Devise a system that can control the speed of an internal-combustion engine in accor￾dance with a command in the form of a voltage. Explain the operation of your system.
1.7 Devise a system that can control the position, rate, and acceleration of an elevator used
in an apartment house. What specifications or limits would you place on the position,
velocity, and acceleration capabilities of the system?
1.8 For the control system devised in Problem 1.7, describe what happens when a man
weighing 200 lb enters the elevator that has stopped at one of the floors of the apartment
building. Utilize a functional block diagram.
1.9 The economic model illustrated in Fig. Pl .9 illustrates the relationship between wages,
prices, and cost of living. Note that an automatic cost of living increase results in a positive
feedback loop. Indicate how additional feedback loops in the form of legislative control can
stabilize the economic system.
Figure Pl.9
1.10 Explain what happens to the automatic position control system illustrated in Fig. 1.12
if the speed-measuring device fails. Can the system still operate?
1.11 Determine what happens in the autopilot system illustrated in Fig. 1 14 if the aircraft
suddenly enters a turbulent atmosphere.20 The General Concept of Control-System Design
1.12 Modify the block diagram of the altitude control system of the space vehicle illustrated
in Fig. 1.16, to allow for sudden failure of the computer and manual control of the vehicle.
1.13 The pH factor of a liquid is a very important factor to be controlled in chemical
process control systems. Figure Pl. 13 illustrates an example of a system which controls
the pH factor of a liquid flowing through a tank. The pH probe measures the actual pH
level and compares it with the desired pH level. If the liquid in the tank does not have the
required acidic level, then the motor adjusts the valve which permits additional acid to 
enter the tank. The limitation of the system shown is that it does not have any provisions
for adding a base solution in the event that the liquid in the tank is too acidic. Modify this
control system so that it could add an acid or a base to the liquid in the tank, and achieve
the desired pH factor for all kinds of liquid pH factors.
Figure Pl. 13
1.14 The actual sales price of a commodity in a free economic market is governed by the
law of supply and demand that states that the market demand for the item increases as its
price decreases. In addition, this concept states that an equilibrium sales price is achieved
when the supply is equal to the demand. The control engineer can represent this concept
as a feedback system with the actual sales price being represented as the output, and the
desired market sales price change as the command input. Draw the block diagram for this
economic system which includes the supplier , demander, prices, and market. Under which
conditions is an equilibrium operation of supply and demand achieved?
1.15 The level of a liquid in a chemical process control system must be maintained
constant within a narrow range. In order to achieve this, a float-operated device is used
to sense the level of the liquid and control the valve opening which determines the flow
of liquid into the tank to replace that which is consumed in the process. Show how this
float-valve control system can be operated in a closed-loop control system.References 21
1.16 Repeat Problem 1.15 if the level of the liquid is controlled by a float switch which
opens the valve whenever the level of the liquid reaches a certain predetermined level.
The valve is automatically closed by a timer switch four minutes after it is opened by the
float switch, even though the liquid may be more or less than the desired level. Is this an
open-loop or closed-loop control system?
REFERENCES
1. S. C. Lyman, “Computer directs process control at textile plant,” Control Eng. 13, 20-21
(October 1966).
2. J. C. Keebler, “Warehouse automation,” Automation 13, 64 (December 1966).
3. S. Hearne, “In-plant data collection tracks material,” Control Eng. 14, 100 (May 1967).
4. S. W. R. Cox, “Automation in agriculture,” Control 9, 247-52 (May 1965).
5. I. Nakamura and S. Yamazaki, “On the centralized system for train operation and
traffic control—Including signaling and routing information,” Railway Technical Re￾search Institute, 5, No. 1 (1964).
6. Technical Aspects on the New Tokaido Line, Japanese National Railways, Tokyo
(October 1966).
7. ASA-C85.1, Terminologyfor Automatic Control, American National Standards Institute,
New York (1963).
8. N. Wiener, Cybernetics or Control and Communication in the Animal and the Machine
(2nd Edn.), The MIT Press and Wiley, New York (1961).
9. Polaris/Poseidon Fleet Ballistic Missile Weapon System, Fact Sheet, U.S. Navy Special
Projects Office, Washington, D.C. (September 1967).
10. N. A. Coulter, Jr., and O. L. Updike, Jr., “Biomedical control developments,” in
Proceedings ofthe 1965 Joint Automatic Control Conference, pp. 258-72.
11. R. W. Mann, “Efferent and afferent control of an electromyographic, proportional￾rate, force sensing artificial elbow with cutaneous display of joint angle,” Proc. Inst.
Meeh. Engrs. 183, 86-91 (1968-69).
12. The Boston Arm, Liberty Mutual Insurance Company, Research Center, 175 Berkeley
Street, Boston.
13. “Designers still grope for efficient ‘limbs’,” Electronic Design 18, U92-U93 (March
1970).
14. S. M. Shinners, Techniques of System Engineering, McGraw-Hill, New York (1967).
15. USAS-C85.1a, Supplement to Terminology for Automatic Control, American National
Standards Institute, New York (1966).
16. S M. Shinners, “Fluidics,” Electro-Technology 79, 81-94 (March 1967).2
MATHEMATICAL TECHNIQUES FOR
THE CONTROL ENGINEER
2.1 INTRODUCTION
The design of linear, continuous, feedback control systems is dependent on mathe￾matical techniques such as the Laplace transformation, the signal-flow diagram, and
the state-space concept. In addition to these techniques, the design of linear,
sampled-data, feedback control systems requires a knowledge of the z-transform
and some aspects of information theory. The design of nonlinear, continuous,
feedback control systems is dependent on mathematical techniques such as the Fourier
transform, the signal-flow diagram, and the state-space concept. The design of
systems having random inputs requires a knowledge of probability theory and
statistical theory. The scope of this book does not permit a detailed discussion of all
of these mathematical devices. The philosophy followed here is to review the theory
of those techniques necessary for understanding the design of linear and nonlinear
continuous systems, and to focus attention on the specific application of these
mathematical tools to these classes of control systems.
This chapter reviews the theory and application of complex-variable theory, the
Fourier transform, the Laplace transformation, the signal-flow diagram, and matrix
techniques. In addition, it introduces the state-space concept.
2.2 COMPLEX VARIABLES AND THE s-PLANE
The design of control systems depends greatly on the application of complex-variable
theory. In what follows, the complex variable 5 is composed of a real part <s and an
imaginary part co. In the complex s-plane, a is usually plotted horizontally and co
vertically. An arbitrary function F(s) is considered to be a function of the complex
variable s if there is at least one value of F(.v) for every value of 5. If there is only one
value of F{s) for every value of s, the function F(s) is called a single-valuedfunction.
However, if there is more than one point in the F(s)-plane for every value of 5, then
F(s) is a multivaluedfunction. Figure 2.1 illustrates the mapping of a single-valued
function from the s-plane to the F(i)-plane. Figure 2.2 illustrates the corresponding
mapping for a multivalued function.
A. Key Notions Four notions of complex-variable theory which are important to
the control systems engineer are those of analytic functions, singularities, poles, and
222.2 Complex Variables and the s-plane 23
s-plane
F(s) - plane
.f(s„)
Re F
• F(sb)
Fig. 2. 1 Mapping of a single-valued function.
zeros of a function. A complex-variable function FIs') is analytic in a region if the
function and all of its derivatives exist at every point in that region. As an example,
the function
F(S) = —1—
s + 4
(2.1)
is analytic at every point in the s-plane except at the point s = —4. Singularities are
defined as points in the s-plane where the function, or its derivatives, do not exist.
An important example of a singularity is a pole. If a function F(s) is analytic in the
region ofs3, except at the poles ofs3-, then F(s) has a pole of order q (where q is finite)
at s — Sj if
lim [F(s)(s - s3)9] (2.2)
is finite. Therefore, the denominator of F(s) must contain the factor (s — s3)9, and
the function becomes infinite when s = s3. In Eq. (2.1), the function has a simple
Ju
s- plane
Im F
/qsl-plane
•F(sa)}
Re /
•F(.sa)4 • F(sa)}
Fig. 2. 2 Mapping of a multivalued function.24 Mathematical Techniques for the Control Engineer 2.2
pole (i.e., a pole of order one) at 5 = —4. As a more complex example, consider
the function
100(s + l)(s + 8)2
F(s) = --------------------------------—, ■ (2.3)
s(s + 4)(s + 10)(s + 20)3
This function has simple poles at s = 0, —4, and —10. In addition, it has a pole of
order three at s = —20.
Finally, we consider the concept of zeros. If a function F(s) is analytic at 5 = s,,
then F(s) has a zero of order q (where q is finite) at s = Sj, if
lim [F(s)(s - s,.)-4] (2.4)
S~>Sj
is finite. Therefore, the numerator of F(s) must contain the factor (s — Sj)", and the
function becomes zero where s — s}-. For example, in Eq. (2.3), there is a simple zero
(i.e., a zero of order one) at s = — 1 and a zero of order two at 5 = —8.
B The Residue Theorem An important aspect of complex-variable theory is the
residue theorem. This will be used later to prove Nyquist’s theorem—a very important
relationship for determining the stability of linear systems.
Fig. 2.3 A contour C around an analytic function containing a pole of order n at a.
In order to develop this theorem, consider a functionf(s) which is analytic on and
within a closed contour C, where a pole exists of order n at a [16], This is illustrated
in Fig. 2.3. For this situation the expression for is modified to the following
form:
A (s - ay (s - ay (2.5)
The new function F(s) is analytic on and within the closed contour including the point
a. Since the function F(s) is analytic at point a (and thus all of its derivatives at point2.2 Complex Variables and the s-plane 25
a exist), it can be expanded about point a in a Taylor series as follows:
F(s) = F(a) + F'(a)(s - a) + ® (s - a)2+ • • •
FM(a) + -----^(5-ar + ---.
n!
Substituting Eq. (2.6) into Eq. (2.5), we obtain the following series:
f(s) = F(a>> . f'(a) , F"(a) , . . .
(s - a)n (s - a)”-1 2! (s - a)”"2
F<n-i>(a) F<n>(a) Fn+1(a)
+ („ - 1)! (, - a) + ~+ <^H>! < " ’ +
(2-6)
(2-7)
Equation (2.7) is the Laurent expansion off(s) at a. Let us now consider the integra￾tion of/($), in its Laurent-expansion form, around a closed contour which encloses
the point a and on and within which there are no other singularities.
+^<1;- ds ,+■
2-rrj J 2-rrj J (s — a)n 2-rrj J (s — a)" 1
(n — 1)! 2Try J (s — a) n! 2-rrj J
(2.8)
The notation is used to denote an integration around a closed curve; the arrow
indicates that the integration is positive in the counterclockwise direction. In Eq.
(2.8), it can be shown [16] that all integrals on the right-hand side of the equation are
zero except for
2-rrj J (s — a)
Therefore, Eq. (2.8) reduces to
7~. <£/(s)«/s =
2-rrj J
F{n~1\a)
(n - 1)! ‘
(2.10)
The rkht-hand side of Eq. (2.10) represents the only coefficient of the Laurent
expansion which affects the value of the integral ofj\s) around the closed contour,
and is denoted as the residue RM off(s) in the pole at 5 = a. Hence we have
— /(s) ds = F<n 1-(g) = Rm. (2.11)
2njJJ (n — 1)1
For cases where there are more than one pole on or within the contour, the path of
integration can be deformed as illustrated in Fig. 2.4 and the results just obtained can26 Mathematical Techniques for the Control Engineer 2.2
Fig. 2.4 A contour C around an analytic function containing four poles.
be applied. Since the contour excludes the poles, with circles of radii approaching
zero, Cauchy’s theorem can be applied. This theorem states that the line integral
around a closed contour is zero if the function f(s) is analytic within and upon the
contour [16]. Therefore, the following expression can be written:
— f(s) ds = 0 = — /(.s') ds----- — f(s) ds
2ttj J 2irj Jo 2nj JC1
- 7- <£ /(*) ds - — /(s) ds - — <£ f(s) ds. (2.12)
2rrJ Jos 2~J •'cs 2jtJ Jet
Therefore, the integral around the outer contour C is given by
— 4) f(s) ds — Rj + R2 + R3 + R4. (2.13)
2ttj Jc
It can thus be concluded that if/(5) is analytic except at the poles, the integral around
the closed path equals the sum of the residues in the poles inside the contour:
/(«) ds = 2 Ri￾2-ttJ Jc 1=i
From Eqs. (2.5) and (2.11), the residue of a pole of order n is given by
= = Hm d"-x r/(s)(s - q)"-|
(n — 1)1 s-a dsn~x L (n — 1)! J
(2-14)
(2.15)
As an example of applying the residue theorem', consider the evaluation of the follow￾ing integral around a closed contour C which encloses the point s — — 1:
2
-Utt/ Jc s—+ 1
(2.16)2.3 Fourier Series and the Fourier Transform 27
In this example, the function f(s) being considered is given by
2
S
s + 1 ’
= (2-17)
which has a single pole at s = —1. From Eq. (2.15), the residue at 5 = —1 is given by
R(1) = lim —^-±1 = 1.
s-* —i s + 1 0!
(2.18)
Therefore, from Eq. (2.16), the integral around any closed contour enclosing the pole
at 5 = — 1 is given by
•£ 7Y7ds = 2nJ' (219)
2.3 FOURIER SERIES AND THE FOURIER TRANSFORM
In the analysis of the behavior of systems evolving in time, it is often convenient
to introduce mathematical transformations that take us from the time domain to a
new domain called the frequency domain. Such transformations are called trans￾forms. Here we will focus on the Fourier series, which is used to analyze periodic
functions of time, and the Fourier transform, which is used to examine aperiodic
time functions of a restricted class. Section 2.4 introduces the Laplace transform,
which is of great value in the analysis of time functions which vanish for negative
time.
A. The Fourier Series Given a periodic function,/(t), whose period is T, then
/(')=/(' + T). (2.20)
Functions which satisfy Eq. (2.20) can be represented by a Fourier series provided
the function is bounded and contains only a finite number of discontinuities in a finite
interval. The classical Fourier series is given by
where
/(0 =
-ff=0°
— + 2 Ak cosKmt
2 zc=i
K=x
+ &K sin Kwt,
K=1
ak = 2-
K tJ
pr/2
/(t) cos Kent dt,
— T/2
K = 0, 1, 2, 3, . CoII
H |ro
<___
CT/2
f(f) sin Kat dt,
-T/2
K = 1,2, 3,. . .
(2.21)
(2.22)
(2.23)
Ify(/) = then the function is odd and AK = 0; Fig. 2.5(a) illustrates an odd
function. If/(z) =/(—t), then the function is even and BK = 0; Fig. 2.5(b) illustrates
an even function. The two terms in the series whose frequency is Km when added
comprise the Ath harmonic of/(Z). The amplitude of the harmonic is given by
+ B2k,
(2.24)28 Mathematical Techniques for the Control Engineer 2.3
(a)
Fig. 2.5 (a) An odd function, (b) An even function.
and the phase is given by
tan-1 (-BK/AK).
i r
Ak = —— (-1) COS K0)ct dt
17/(l>c L.V —
/*jt/2coc ~|
+ (1) cos K(0ct dt + (-1) cos Kwctdt (2.27)
J-n-/2<oc Jr/2<of J
, 2 sin (Ktt/2)
K ~ Ktt/2 ’ (2,
(2-25)
As an example of the application of the Fourier series, consider the periodic
waveshape illustrated in Fig. 2.6(a). This function represents a periodic switching
function whose period is 2ttIwc. In addition, it is an even function sincef(t) =
so that the BK terms are zero. The evaluation of Ao and A K follows from Eq. (2.22):
1 r f-'r/2o'c f>r/2u>c fir/coc -]
=-— (-l)dt+ (l)dt + (-l)dt = 0 (2.26)
J—r/2a>f |2.3 Fourier Series and the Fourier Transform 29
Fig. 2.6 (a) A periodic function, (b) Envelope of the function
Ak _ sin Xw/2
~2 Krr/2
showing the (sin x)/x pattern.30 Mathematical Techniques for the Control Engineer 2.3
Therefore,
/(0 = Sin cos Kcot. (2.29)
A=i Ktt/2
A plot of the envelope of the function AK, which follows the familiar (sin x/x) wave
pattern, is illustrated in Fig. 2.6(b).
B. Complex Form of the Fourier Series The Fourier series given by Eqs. (2.21)
through (2.23) can be converted to a complex form by means of the following sub￾stitutions:
sin KoA = - - e~iK(Ot), (2.30)
2/
cos Ka)t = \(eiKa>t + e-iKo,t). (2.31)
Therefore,
A 00 A 00 R
. XT / jKat — iKaytx . 5T dK z iKot —iKcotx f(S) = —+ 2— 0 + e )+> — (e - e )•
2 a-i 2 A'=i 2/
This can also be written as
A 1 00 i °°
/(0 = T + ; 5 -jBK)eiKlot + -y (Ak + jBK)e~iK(al. (2.32)
2 2 a=i 2 a=i
Note that from Eqs. (2.22) and (2.23),
2 CT/2
(AK-jBK) = - dt
1 J-T/2
and
t‘T/2
(Ak + jBK) = ± /(t)e,K"f dt.
T J-T/2
Therefore, Eq. (2.32) becomes
A co iKcot [T/2 co a-iKo>t f'T/2
= ~ + f(j)e~iKa)t dt + ~------- f(t)e’K<atdt. (2.33)
2 A'=l T J-T/2 A=1 T J-T/2
Since the second and third terms on the right side of Eq. (2.33) differ by a sign, the
complex form of the Fourier series can be written as
K=00 iKat [>T/2
f^= 2 — f{t}e~iKe>tdt. (2.34)
qo T J—T/2
This equation is usually written in the following form:
/(O = i .5 CKeiKwt, (2.35)
1 K~—<x)2.3 Fourier Series and the Fourier Transform 31
where
fT/2
J-T/Z
(2-36)
Equation (2.35) gives the complex Fourier series of/(/), and Eq. (2.36) defines the
complex Fourier coefficient, CK.
As an example of the application of the complex form of the Fourier series,
consider the periodic pulse train illustrated in Fig. 2.7(a). The complex Fourier
(a)
(b)
Fig. 2.7 (a) Periodic pulse train, (b) Complex Fourier coefficient CK for the pulse train of
Fig. 2.7(a).
coefficient of this periodic pulse train is given by
fr/2 r -iKu>t-iTl2
CK = Me~iKa>t dt = ------- = — sin ojKt/2. (2.37)
J-r/2 L J-r/2 Ko)
Equation (2.37) can also be written as
sin icoKr
C = Mr------------ .
%o)Kt
A plot of CK for all values of frequency is illustrated in Fig. 2.7(b). The envelope of
CK follows a (sin x/x) function and the spacing between lines is given by AcoAT =
2tt/T.32 Mathematical Techniques for the Control Engineer 2.3
Fig. 2.8 (a) A nonperiodic pulse train, (b) Fourier transform for the pulse illustrated in
Fig. 2.8(a).
C. The Fourier Integral The control-system engineer finds many functions ofinterest
which are not periodic. For these functions, the Fourier series cannot be applied.
However, the Fourier integral can be used to analyze a wide class of aperiodic func￾tions.
Let us assume that instead of the periodic pulse train in Fig. 2.7(a), we have only
one nonperiodic pulse as illustrated in Fig. 2.8(a). By considering this single pulse as
the fundamental function during a period and assuming that its period is infinity, this
function can be represented by the Fourier integral. Basically, the approach is to
obtain the Fourier series of the function of Fig. 2.8a assuming that it is periodic with
a period of infinity. Let us write Eq. (2.35) as
i K=oo /(0 = — s CKeiK<ot^Ka)
2tt k=-oo
by letting T = 2ttI&Ko>. As T approaches infinity, AA7o approaches zero and we
have the following relationships:
i X=oo
lim/(t)= lim — £ CA-e’A'"‘AKw, (2.38)
T-oo T- *oo 2tt K=-co
A w-* 0 A Kco -»0
lim /(t) = j CKeia< da). (2.39)
T-»oo Z7T J—co
A Ka>-»02.3 Fourier Series and the Fourier Transform 33
Therefore, the discrete lines of CK in Fig. 2.7(b) merge into a continuous frequency
spectrum as illustrated in Fig. 2.8(b). As the period T approaches infinity, Eq. (2.36)
can be written as:
CK = F(ct>) =J°° dt. (2.40)
This is the definition of the Fourier transform of a nonperiodic function f(t), and
is commonly denoted as F(co). It is important to note here that the function must
satisfy the following condition of absolute convergence before the Fourier transform
of a function is taken:
f \f(t)\dt < oo. (2.41)
J—CO
As an example of the calculation of a Fourier integral, consider the following
exponential time function, where 9 < 0.
f(t) = eet for t > 0 (2.42)
/(t) = 0 for t < 0. (2.43)
Let us first check on the convergence of the function. From Eq. (2.41),
f dt < oo, since 9 < 0. (2.44)
J—co
Therefore, this exponential function is absolutely integrable and its Fourier transform
can be obtained from Eq. (2.40), with the lower limit replaced by zero, as follows:
F(co) = pe9te~M dt. (2.45)
Integrating, we obtain
[
f
t(0—ie>) -| oo
, (2.46)
6 — jcujo
F(oj) =—' (2.47)
ja> — u
The Fourier transform is a very powerful mathematical tool that is used to a great
extent in engineering. However, the limitation defined by Eq. (2.41) restricts its use
in important situations. For example, the control engineer is usually interested in the
response of a control system to unit step, ramp, and parabolic time functions denoted
by {/(/), tU(t), and t2U(t), respectively. Unfortunately the Fourier transforms ofthese
functions do not exist. For these types of function, the engineer modifies the Fourier
transform by adding a convergence factor e~at where cr is a real number that is large
enough to maintain absolute convergence. Therefore, the new transform is given by
F((T, w) = [/(t)^-’*0' dt. (2.48)
Jo34 Mathematical Techniques for the Control Engineer 2.5
Notice that the lower limit is defined as zero rather than minus infinity, so that the
new transform only applies to time functions that vanish for negative time. However,
this is not a serious limitation in control problems since the time reference is usually
chosen to be t = 0. By defining
(2.49)
Eq. (2.48) can be written as
(2.50)
where F(s) is defined as the Laplace transform of the function f(f).
2.4 THE LAPLACE TRANSFORM
The Laplace transform [1, 2] is helpful in the solution ofordinary differential equations
describing the behavior of systems. When the transform operates on a differential
equation, a “transformed” equation results. It is expressed in terms of an arbitrary
complex variable, 5. The resulting transformed equation is in purely algebraic terms
which can be easily manipulated to obtain a solution for the desired quantity as an
explicit function of the complex variable. In order to obtain a solution in terms of the
original variable, it is necessary to carry out an inversion process to determine the
desired time function. The inverse Laplace transform is given by
1
2ttj
fW = F(s)est ds, (2-51)
where <r is a real constant greater than the real part of any singularity of F(s). The
evaluation of this integral is usually difficult, and the inverse transformations are
usually obtained by utilizing a table of Laplace transforms. The Laplace transform
F(s) of a certain function of time/(t) is conventionally written as
F(s) ± (2.52)
From the definition of the Laplace transform given by Eq. (2.50), the integral exists
if
(2.53)
2.5 USEFUL LAPLACE TRANSFORMS
The Laplace transforms for various time functions will now be considered. These are
readily obtainable through a direct application of Eq. (2.50).2.5 Useful Laplace Transforms 35
A. The Laplace Transform of a Unit Step For the unit step function defined by
(0 for t < 0,
/(') = U(t), f(t) =
(1 for t > 0,
the Laplace transform is
W0)l = = [--s
Therefore,
^[U(r)] = 1/5, Re [s] > 0. (2.54)
From here on we assume that /(r) = 0 for z < 0.
B. The Laplace Transform of an Exponential Decay For the function
/(') =
we have the Laplace transform
^[/(t)] = f°°e-(s+*H dt = F- —
Jo L 5 + « Jo
Therefore,
^(e~at) = —— Re [s] > -a. (2.55)
s + a
C. The Laplace Transform of a Unit Ramp For the function /(0 =
t,
the Laplace transform is
^[f(t)] =^te~stdt. (2.56)
Integrating by parts,
Ju dv = uv — Jt> du, (2.57)
with u — t, do = e~st dt, the following is obtained:
foo r _-st-| 00 foo -st
te-st dt = Z — - — dt.
jo L —sjo Jo —s
Therefore,
J5f(t) = -,, Re [s] > 0. (2.58)
r
D. The Laplace Transform of a Sinusoidal Function For the function
/(f) = sin cot,
the Laplace transform is
Poo
^[/(t)] = J^(sin cof) = sin cot e~st dt. (2.59)36 Mathematical Techniques for the Control Engineer 2.6
The solution to Eq. (2.59) is simplified by using the exponential form of sin cot,
Therefore,
Therefore,
_ e-’“f
sin cot = --------------- .
y
/'oo ("x pia>t __ p—int
sin cot e~st dt = --------------- e~st dt
Jo Jo 2J
(s+;co)f
_ j_ / 1_________1
2j \s — jco s + jcO
^(sin cot) = —2 > Re [s] > 0 .
s2 + co2
(2.60)
(2.61)
Once the Laplace transform for any function f(t) is obtained and tabulated, it
. need not be derived again. The foregoing results and other important transform pairs
useful to the control engineer appear in Table 2.1 on page 40. An extended table is
shown in Appendix A. In addition, the location of the poles of the transformed
function in the complex plane is listed.
2.6 IMPORTANT PROPERTIES OF THE LAPLACE TRANSFORM
The Laplace transform has been introduced in order to simplify several mathematical
operations. These operations center upon the solution of linear differential equations.
Several basic properties of the Laplace transform are given here.
A. Addition and Subtraction If the Laplace transforms offx(t) and /2(t) are Fx(s)
and F2(j), respectively, then
WrW ± .4(0] = F\(s) ± f2(.s).
B. Multiplication by a Constant If the Laplace transform of/(z)is F(s), then multi￾plication of the function f(t) by a constant K results in a Laplace transform KF(s).
C. Direct Transforms of Derivatives If the Laplace transform of f(t) is F(s), the
transform of the time derivative/(t) of/'(/) is given by
W(0] = sF(s) -/(0+), (2.62)
where/(0+) is the initial value off(t), evaluated as t->0 from the positive region.
The Laplace transform of the nth derivative of a function is given by
^\dF\ = S"F(5) “ S"’1/(0+) ~ S"“V(°+)------------ /(n-u(0+), (2.63)2.7 Inversion by Partial Fraction Expansion 37
where/(0+) is the first derivative of/(z) evaluated at t = 0+. The notation/('*- 1’(0+)
represents the (n — l)th derivative offwith respect to time evaluated at t = 0+.
D. Direct Transforms of Integrals If the Laplace transform of/(Z) is F(s'), the trans￾form of the time integral off(t) is given by
17(0 dt] = i [ (7(t) dt] . (2.64)
LJ J s s LJ Jt=o
where [f/(z) r/z](=o+ signifies that the integral is evaluated as t 0 from the positive
region. In general, for nth-order integration,
+ [>0 "'I..+■ ■ ■+; [Jf • ■ >> (265)
E. Shifting Theorem The Laplace transform of a time function /(z) delayed in time
by T equals the Laplace transform of/(z) multiplied by esT\
^[f{t - T)t/(Z - T)] = e~sTF(s), T > 0. (2.66)
F. The Initial-Value Theorem If the Laplace transform of /(z) is F(s), and if
lims. SF(S) exists, then the initial value of the time function is given by
lim /(Z) = lim sF(s). (2.67)
i-»0 s-»oo
G. The Final-Value Theorem If the Laplace transform of/(z) is F(s), and if sF(s) is
analytic on the imaginary axis and in the right half-plane, then the final value of the
time function is given by
lim/(z) = lim sF(s). (2.68)
f-*co S“*o
2.7 INVERSION BY PARTIAL FRACTION EXPANSION
The time response is the quantity of ultimate interest to the control-system designer.
The process of inversion of a function F(s) to find the corresponding time function
/(Z) is denoted symbolically by
^-iF(j) =/(/). (2.69)
In applications, F(s) is usually a rational function of the form
4y5a + 4v_iS'y-1 + • ■ • + Ays + Ae
F(s) = —----------- —---------------------------------- ■ (2.70)
sr + By-xs1'-1 + ■ • ■ + B.s + Bo
In practical systems, the order of the polynomial in the denominator is equal to, or
greater than, that of the numerator. For the cases where Y > X, partial fraction38 Mathematical Techniques for the Control Engineer 2.7
expansion is directly applicable. When Y = X, it is necessary to reduce F(s) to a
proper fraction by long division.
The simplest method for obtaining inverse transformations is to use a table of
transforms. Unfortunately, many forms of F(s) are not found in the usual table of
Laplace transform pairs. When the form of the solution cannot be readily reduced to
a form available in a table, we must use the technique known as partial fraction
expansion. This method permits the expansion of the algebraic equation into a series
of simpler terms whose transforms are available from a table. It is then possible to
obtain the inverse transformation of the original algebraic expression by adding
together the inverse transformations of the terms in the expansion. Equation (2.71)
expresses this operation symbolically. The function F(s) represents the original
algebraic expression and F^s), F2(s), F3(s), . . . , Fn(s) are terms ofthe partial fraction
expansion: '
^-W)] = -^[W] + + • ■ • + ^[^)L (2.71)
As an example of the method, consider the transform
F(s) = ----- As + -6----- . (2.72)
(s + C)(s + D) V ’
In this equation A, B, C, and D are constants. This function can be expanded into
partial fractions:
As + B Kj K,
--------------------- = -----1----- 1------- — . (2.73)
(s + C)(s + D) s + C s + D v
To determine A\, both sides of Eq. (2.73) are multiplied by s + C, yielding
As + B K2(s + C)
— /v 1 1 s + D s + D
(2-74)
By substituting s = — C, the last term vanishes and a numerical value for Kv can be
obtained. An analogous procedure leads to the value for K2. One finds
„ B - AC B - AD
Al -- , l\.n - •» D - C C - D
(2.75)
(2.76)
An expression for the expanded form of F(s) can now be obtained by substituting this
result into Eq. (2.73):
, B - AC 1 , B - AD 1 F(s) ------------------------|--------------------------
D - C s + C C - D s + D
It is now a simple process to obtain the inverse Laplace transform from this last
equation. The corresponding time function can be obtained by merely inspecting the
terms and comparing them with transform pairs listed in Table 2.1:
f(t) = &------- e-Ct + AP -Dt
D - C C - D ‘
(2-77)2.8 Solution of Differential Equations Using the Laplace Transform 3*)
Transforms with multiple poles are occasionally encountered. For example,
consider the transform
(2.78) F(s) = - 745 + 5------
(s + C)2(s + £>)
In this equation A, B, C, and D are constants. The partial fraction expansion is
written as
As ~F B _ Kx K2 K3
(s + C)2(s + D) “ (s + C)2 s + C s + D '
To find Kx, both sides of Eq. (2.79) are multiplied by (5 + C)2:
di±J=K1+K,(s+c)+&M
s + D s + D
The constant can now be evaluated by simply substituting s = —C.
(2.79)
(2.80)
„ B - AC —
D - C
In order to determine the constant K3, both sides of Eq. (2.80) must be differentiated
with respect to s, and s is then set equal to — C:
'd (s + C)2'
ds s+D
d As + B
\_ds s + D
The resulting numerical value for K2 is given by
(2.81)
2 (2.82)
d As + B
.ds s + D
_ AP - B
-c~ (D - C)2 ’
The constant K3 can be obtained by the same procedure used in evaluating the
expression given by Eq. (2.72). Its value is
(2.83)
3 —
B — AD
(C - D)2 '
(2-84)
2.8 SOLUTION OF DIFFERENTIAL
EQUATIONS USING THE LAPLACE TRANSFORM
Now that the physical relationship of a linear system has been described by means of
its integrodifferential equation, the analysis of the system’s dynamic behavior can be
carried out by solving the equations and incorporating the initial conditions into the
solution. Two examples are given in this section to illustrate the application of
the Laplace transform to solve a linear differential equation. In general, we take the
Laplace transform of each term in the differential equation. This step eliminates time40 Mathematical Techniques for the Control Engineer 2.8
and all of the time derivatives from the original equation and results in an algebraic
equation in s. The resulting equation is then solved for the transform of the desired
time function. The final step involves obtaining the inverse Laplace transform which
yields the solution directly.
Example 1 Consider the following linear differential equation:
d2y
dt2
+ 5 — + = 6.
dt
(2.85)
Assume the initial conditions are
y(0+) = 2, y(0+) = 2.
By taking the Laplace transform of both sides of Eq. (2.85), the following equation is
obtained (using Eqs. (2.62) and (2.63)):
^2T(5) - sy(0+) - y(0+) + 5.vT(s) - 5y(0+) + 6Y(s) = 6/s. (2.86)
Substituting the values of the initial conditions, and solving for
following equation:
T(s), yields rhe
(2.87) w . 2s2 + 12s + 6 2s2 + 12s + 6
Y(s) = —---------------- = ----------------------
s(s + 5s + 6) s(s + 3)(s + 2)
If Eq. (2.87) is expanded by means of partial fractions as discussed previously, the
following expansion is obtained:
y(s) = -
s
---------- 1----------.
s + 3 s + 2
(2.88)
The inverse Laplace transform of Eq. (2.88) is given, using Table 2.1, by
y(r) = 1 - 4e~3t + 5e~2‘, t > 0. (2.89)
This solution is composed of two portions: the steady-state solution given by 1,
and the transient solution given by — 4e3' + 5e~2<. As a check of the steady-state
solution, we can apply the final-value theorem given by Eq. (2.68):
lim y(t) = lim sT(s) = lim ^——35 + 6 = 1. (2.90)
i-co s~o s-+o (s + 3)(s + 2)
Example 2 As a second example, the following differential equation is considered
and the inapplicability of the final-value theorem when the function is not analytic
in the right half-plane is illustrated:
dt2 dt
The initial conditions are assumed to be
y(0+) = 2, j(0+) = 0.
(2-91)
(2.92)2.8 Solution of Differential Equations Using the Laplace Transform 41
Table 2.1 Important Laplace transform pairs
Name of function
Time function,
/(')
Laplace transform,
HO
Location of poles
in s-plane
1. Unit impulse at t = 0
2, Unit step
3. Unit ramp
4. Parabolic
5. wth order ramp
6. Exponential decay
7. Sine wave
8. Cosine wave
9. Exponentially
decaying sine wave
<5(0
U(r)
t
t2
tn
e~3t
sin Mt
cos cat
e~at sin cot
1
1
5
1
S2
2
m!
Sn+1
1
s + a
M
s2 4- co2
5
s2 4- a>2
co
(s + a)2 + co2
None
One pole at the origin
Double pole at the origin
Triple pole at the origin
Pole of multiplicity
(« + 1) at the origin
One pole on the real axis
at —a
Two poles on the
imaginary axis at ±jco
Two poles on the
imaginary axis at ±jca
Two complex poles
located at — a ± jco
Taking the Laplace transform of both sides of Eq. (2.91), the following equation is
obtained:
[s2r(s) - sy(0+) - j(0+)] + sT(s) - y(0+) = • (2-93)
s — 4
By substituting the values of the initial conditions, and solving for T(s), the following
equation is obtained:
2s2 _ 6s — 7
Y(s) = ---------- -- ----- -- . (2.94)
s(s + l)(s - 4)
Expansion of Eq. (2.94) by means of partial fractions, as discussed previously, gives
T(s) = - 4- -i- + • (2.95)
s s + 1 (s — 4)
From Table 2.1, the inverse Laplace transform of Eq. (2.95) is given by
y(t) = 1.15 + je-( + (2.96)
It is obvious from Eq. (2.96) that the final value of this function is infinite. However,
if one were to apply the final-value theorem to Eq. (2.94), the incorrect final value of42 Mathematical Techniques for the Control Engineer 2.9
1.75 would be obtained. This example, therefore, illustrates very clearly that Eq.
(2.68) cannot be applied when the function F(s) is not analytic in the right half-plane.
2.9 THE TRANSFER-FUNCTION CONCEPT
For analysis and design, control systems are usually described by a set of differential
equations. A block diagram is a device for displaying the interrelationships of the
equations pictorially. Each component is described by its transferfunction. This is
defined as the ratio of the transform of the output of the component to the transform
Input. R(s) System
(7(5)
Output.C(s)
Fig. 2.9 Block diagram of a simple linear system.
of the input. The component is assumed to be at rest prior to excitation, and all
initial values are assumed to be zero when determining the transfer function.
Consider the block diagram of the simple system shown in Fig. 2.9. The only
assumption made concerning this system is that the input and output are related by a
linear differential equation whose coefficients are constant and can be written in the
form
dnc de dmr dr An— + • ■ ■ + Al — + Aoc = B —— + • • • + Bj- + Bor. (2.97) dtn dt m dtm 1 dt V
The Laplace transform of Eq. (2.97), assuming zero initial conditions, can be written
as
(Ansn + • • • + As + A)C(s) = (Bm5™ + • • • + B1S + B0)B(s). (2.98)
The ratio C(s)/B(s) is called the transfer function of the element and completely
characterizes its performance. Designating the transfer function of the element as
G(s), we obtain
_ Cfs) _ + ■ ■ ■ + .
R(s) A.s’ + ■ ■■ + A,s + A,
Therefore, assuming that the initial conditions are zero, the Laplace transform of the
output is
C(s) = G(s)B(s). (2.100)
In general, the function G(s) is the ratio of two polynomials in s:
G(s) = P(s)/2(s). (2.101)2.10 Transfer Functions of Common Networks 43
The transfer function G(s) is a property of the system elements only, and is not
dependent on the excitation and initial conditions. In addition, transfer functions
can be used to represent closed-loop as well as open-loop systems.
2.10 TRANSFER FUNCTIONS OF COMMON NETWORKS
The control engineer depends heavily on simple passive networks to modify the trans￾fer function of the feedback control system in order to promote stability, improve
closed-loop performance, and minimize the effects of noise and other undesirable
signals.
Figure 2.10(a) represents an electrical network which is used for integration or to
provide a phase lag. This circuit obtains its integrating property from the fact that
Fig. 2.10 (a) An integrating or phase-lag network, (b) An integrating network with fixed
high-frequency attenuation.
the voltage across the capacitor is proportional to the integral of the current through
it. To determine the behavior of this network we must determine the transfer function
relating input and output signals. The integrodifferential equations describing the
behavior of this network are given by
= Ri + fi dt,
C J
(2.102)
(2.103)
These differential equations can be solved for the relation between e0 and et by means
of the Laplace transform; e„(0+) is assumed equal to zero. 1 hus one finds
E^s) = RI(s) + Z(s)/C.y, (2.104)
E0(s) = I(s)lCs. (2.105)Table 2.2 Transfer functions of common networksTransfer function £
RCs
RCs + 1
1
RCs + 1
/?2 1 +
Mathematical Techniques for the Control Engineer
RiC2s + 1
(/?! + R2)C2s + 1
_________ (1 + /?iC^)(l + R^s)________
RyR.CyC^2 + {RyC^ + 7?2C2 + R^s + 12.10 Transfer Functions of Common Networks 45 + ^ y C j C j S 2 (^ 1 ^ 1 + ^ 2 ^ 2 + ^ 3 ^ 1 )5 + 1 (RlR2 4- R2R2 + RiR3)ClC2st + (7?1C\ + R2C2 + R\C2 + /?3Cj)s + 146 Mathematical Techniques for the Control Engineer 2.11
Eliminating 7(.s) results in the transfer function
^2 = ----- 1----- (2.106)
£/s) RCs + 1
Notice from Eq. (2.106) that integration is possibly only for those frequencies where
|£C.s| » 1. It is important to note that this same transfer function can be obtained
quite simply by determining the impedance of each circuit element and using the
voltage divider rule. Thus
E0(s) = l/(Cs) = 1 (2 ]07)
£,(s) l/(Cs) + R RCs + 1'
The impedance of the capacitance approaches a short circuit at very high fre￾quencies, and ultimately it will have no output. This circuit is basically a low-pass
filter whose high-frequency response is attenuated to a very large degree. Very often
it is undesirable to have such a large attenuation at high frequencies. The circuit of
Fig. 2.10(b) limits this attenuation to a value of R2/(Ri + Rz)- The transfer function
of the network is obtained directly by using the voltage divider rule. Thus,
£0(s) R2 + (I/C,s) R.2C2s + 1
----- — — . (z.lvo)
£((s)----------+ R2 + (1/C2s) (/?! + £2)C2s + 1
A tabulation of the foregoing results, together with other useful transfer functions
which the control engineer will most likely encounter, is shown in Table 2.2. Network
1 is known as a differentiating or phase-lead network. Notice that it is basically a
high-pass filter possessing very large attenuation at low frequencies. This attenuation
can be limited to a finite value of 7?2/(/?1 + R2) by network 3. A lag-lead network,
which provides a phase lag at low frequencies and a phase lead at high frequencies, is
shown as network 5. Networks 6 and 7 are slight modifications of network 5. Net￾work 8 is used for eliminating unwanted frequency bands. Network 9 is used for
passing signals in a narrow band of frequencies.
2 il TRANSFER FUNCTIONS OF SYSTEMS
In order to determine the transfer function of complex systems, it is necessary to
eliminate intermediate variables of the elements that comprise the system. This will
enable the designer to obtain a relation between the input and output of the overall
system. This section will consider the transfer functions of cascaded elements, single￾loop feedback systems, and multiple-loop feedback systems.2.11 Transfer Functions of Systems 47
Fig. 2.11 A cascaded system.
A cascaded system is shown in Fig. 2.11. The transfer function of the overall
system can be obtained by solving the following set of equations:
£2(y) = G1(5)£1(5), (2.109)
£3(j) = G2(s)£2(s), (2.110)
E-l(s) = G3(s)E3(s), (2.111)
E&(s) = G4(s)£4(s). (2.112)
By inspection, it can be seen that the transfer function of the cascaded system is the
product of the transfer functions of the individual elements:
£5(y) = G1(j)G2(5)G3(5)G4(5)£1(j). (2.113)
Consider the elementary linear feedback system in Fig. 2.12. G(s) and H(s)
represent the transfer functions of the direct-transmission and feedback portions of
the loop, respectively. They may be individually composed of cascaded elements and
minor feedback loops.
The following three equations are required in order to compute the overall system
transfer function:
B(s) = H(s)C(s), (2.114)
£(5) = R(s) - B(s), (2.115)
C(s) = G(s)E(s). (2.116)
Solution of these three equations results in the following transfer function relating
R(s) and C(s):
C(s)_ _____G(s)____ (2
R(s) “ 1 + G(s)H(s)'
Fig. 2.12 General block diagram of a single-loop feedback system.48 Mathematical Techniques for the Control Engineer 2.11
For cases where |G(.t)/f(s)| » 1, the closed-loop transfer function can be approxi￾mated by
~ _ (2.H8)
K(s) H(s)
This implies that the closed-loop transfer function is independent of the direct trans￾mission transfer function G(s), and only depends on the feedback transfer function
H(s). Use is made ofthis characteristic in feedback amplifier design in order that the
overall amplifier gain may be insensitive to tube, transistor, and/or integrated circuit
parameter variations. Note also that the approximate transfer function is the inverse
ofthe feedback transfer function. This property is used for producing behavior which
may be difficult to achieve directly.
The characteristic equation for the system can be obtained by setting the
denominator of the system transfer function equal to zero:
1 + G(s)H(s) = 0. (2.119)
This equation determines system stability, and it will receive much attention in later
chapters.
Another useful relationship is the transfer function Els^R^s) when H(s) = 1.
Then E(s) represents the error R(s) — C(s). One finds
£(s)
£(s) H(s)=l
1___
1 + G(s)
(2.120)
When |G(s)| » 1, this can be approximated by
£(s)
K(S)
1
G(s)
(2.121)
Thus the error is small when the magnitude ofthe open-loop transfer function is large.
Practical feedback systems usually contain multiple feedback loops and several
inputs. Ail multiple-loop systems can be reduced to the basic form shown in Fig. 2.12
by means of step-by-step feedback loop reduction or by means ofsignal-flow diagrams
which are considered in later sections of this chapter. Multiple inputs, which are
present in all control systems because unwanted inputs (such as noise and drift) are
present, can occur anywhere in the feedback system. Successive block diagram
reduction techniques permit the designer to determine their effect on overall perform￾ance. Table 2.3 illustrates several transformations that can be used to simplify the
reduction of a multiple feedback system. The technique of multiple feedback loop
reduction can best be understood by means of an example.
Figure 2.13 illustrates a multiple-loop feedback system containing three feedback
loops. The original feedback system is illustrated in Fig. 2.13(a). Figure 2.13(b)
through (e) shows successive steps in reducing this system using the transformations2.11 Transfer Functions of Systems 49
Table 2.3 Block diagram transformations
illustrated in Table 2.3. Figure 2.13(f) shows the closed-loop transfer function of the
system.
Block diagram reduction techniques get very tedious and time consuming as the
number of feedback paths increases, as is illustrated in Fig. 2.13. In order to solve
complex problems, it is much simpler to make use of the theorems and properties of
signal-flow graphs, which permit a solution almost by inspection.(D
Fig. 2.13 Reducing a multiple-loop system containing complex paths, (a) The original
system, (b) Rearrangement of the summing points of the intermediate and minor loops,
(c) Reduction of the equivalent intermediate loop, (d) Reduction of the equivalent minor
loop, (c) The equivalent feedback system, (f) The system transfer function.
502.12 The Signal-flow Diagram and Mason’s Theorems 51
2.12 THE SIGNAL-FLOW DIAGRAM AND MASON’S THEOREMS
Signal-flow graphs and Mason’s theorems [3,4] enable the control engineer to
determine the response of a complicated linear, multiloop system to any input much
more rapidly than do block diagram reduction techniques.
A signal-flow graph is a topological representation of a set of linear equations
having the form
yi=iai}yj, i = 1, 2,. . . , n. (2.122)
3=1
This equation expresses each of the n variables in terms ofthe others and themselves.
A signal-flow graph represents a set of equations of this type by means of branches
and nodes. A node is assigned to each variable of interest in the system. For
e
Fig. 2.14 Signal-flow diagram.
example, node i represents variable yt. Branches are used to relate the different
variables. For example, branch ijrelates variable y, toy,, where the branch originates
at node i and terminates at node j. Consider the following set of linear equations
y2 = ayi 4- by2 + cyt (2.123)
y3 = dy2 (2.124)
yt = eyi + fy$ (2.125)
y& = gy3 + hyy (2.126)
The signal-flow graph which represents this set of equations is shown in Fig. 2.14.
Here yx can be interpreted as the input to the system and y5 as its output. Usually we
would be interested in obtaining the ratio ofy5/yx.
Before proceeding further, several terms used in signal-flow diagrams must be
defined.
a) A source is a node having only outgoing branches, such as yx in the preceding
. illustration.
b) A sink is a node having only incoming branches, such as y5.
c) A path is a group of connected branches having the same sense of direction. In
Fig. 2.14, eh, adfh, and b are paths.
d) Forwardpaths are paths which originate from a source and terminate at a sink and
along which no node is encountered more than once, as eh, ecdg, adg, and adfh.52 Mathematical Techniques for the Control Engineer 2.13
e) Path gain is the product of the coefficients associated with the branches along the
path.
f) Feedback loop is a path originating from a node and terminating at the same node.
In addition, a node cannot be encountered more than once. In the preceding
example b and dfc are feedback loops.
g) Loop gain is the product of the coefficients associated with the branches forming
a feedback loop.
2.13 REDUCTION OF THE SIGNAL-FLOW DIAGRAM
Several preliminary simplifications can be made to the complex signal-flow graphs of
a system by means of the following signal-flow graph algebra.
a) Addition
1. The signal-flow diagram in Fig. 2.15(a) represents the linear equation
y3 = ayj. + by2. (2.127)
2. The signal-flow diagram in Fig. 2.15(b) represents the linear equation
T2 = (« + b)yi. (2.128)
b) Multiplication. The signal-flow diagram in Fig. 2.15(c) represents the linear equa￾tion
Fig. 2.15 Signal-flow graph algebra.2.13 Reduction of the Signal-flow Diagram 53
c) Feedback loops
1. The signal-flow diagram in Fig. 2.15(d) represents the linear equation
2. The signal-flow diagram in Fig. 2.15(e) represents the linear equation
l + o
It is possible to apply the preceding signal-flow diagram algebra to a complicated
graph and reduce it to one containing only a source and a sink. This process requires
repeated applications until the final desired form is obtainable. An interesting prop￾erty of network and system topology, based on Mason’s theorems [3, 4] permits the
writing of the desired answer almost by inspection. The general expression for signal￾flow graph gain is given by
G = Gk , (2.132)
A
where A = 1 — £ Tx 4- 2 Lz — ' + (~ O’" 2 L>n
Lr = gain of each closed loop in the graph
L2 = product of the loop gains of any two nontouching closed loops (loops
are considered nontouching if they have no node in common)
Lm = product of the loop gains of any m nontouching loops
GA- = gain of the A"th forward path
AK = the value of A for that part of the graph not touching the Xth forward
path (value of A remaining when the path producing GK is removed).
A is known as the determinant of the graph and A/r is the cofactor of the forward
path K. Basically, A consists ofthe sum ofthe products ofloop gains taken none at a
time (1), one at a time (with a minus sign), two at a time (with a plus sign), etc.;
A7< contains the products of the nontouching loops. The proof of this general gain
expression is contained in Reference 4. A few examples follow in order to show how
this expression may be used.
Example 1 For Fig. 2.16(a),
A = 1 - bd,
Gx = abc,
Ax = 1.
Therefore.
abc (j = ----------- ,
1 - bd54 Mathematical Techniques for the Control Engineer 2.13
(c)
(d)
Fig. 2.16 Signal-flow diagram examples: (a) Example 1, (b) Example 2, (c) Example 3,
(d) Example 4.2.14 Application of Mason’s Theorems and Signal-flow Diagram to Multiple Feedback Systems 55
Example 2 For Fig. 2.16(b),
A = 1 — eg — bedf,
Gj = abede,
Therefore,
= 1,
&______ abede
i — eg — bedf
Example 3 For Fig. 2 16c,
A = 1 — (i + cdh),
G4 = abedef,
G2 = agdef,
G3 = agjf,
G4 = abejf,
A, = 1, A3 = 1 - i,
A2 = 1 - i, A4 = 1.
Therefore,
abedef + agdef(i — i) + agjf(l — i) + abejf G — - - ■ ■ 1 - (i + cdh)
Example 4 For Fig. 2.16d,
A = 1 — (bi + dj + fk + bcdefgm) + (bidj + bifk + djfk) — bidjfk,
Gj = abcdefgh,
A, = 1.
Therefore,
abcdefgh Cj — ----------------------------------------------------------------------------------------------,
1 — (bi + dj + fk + bcdefgm) + (bidj + bifk + djfk) — bidjfk
2.14 APPLICATION OF MASON’S THEOREMS AND
THE SIGNAL-FLOW DIAGRAM TO MULTIPLE FEEDBACK SYSTEMS
It is important at this point to differentiate between signal-flow diagrams and block
diagrams. Basically, the signal-flow diagram represents a detailed picture of a
system’s topological structure, whereas the block diagram focuses on the transfer
functions that comprise the various elements of the system. The signal-flow diagram
is useful in analyzing multiple-loop feedback systems and in determining the effect of
a particular element or parameter in an overall feedback system, whereas the block
diagram is useful in the design and analysis of sections of a feedback system.56 Mathematical Techniques for the Control Engineer 2.15
Essentially both present the same information in different ways, and Mason’s
theorems can be applied to both. However, Mason’s theorems are conventionally
used with the signal-flow diagram since the topology is more clearly depicted by the
signal-flow diagram.
The signal-flow diagram for Fig. 2.13(a) is shown in Fig. 2.17. By inspection,
the overall system transfer function is
A = 1 + G1(s)G2(s)G3(s)G4(s)H1(s) + G2(s)G3(s)H2(s) 4- G3(s)G4(s)H3(s),
Ga = G1(s)G2(s)G3(s)G4(S),
A.4 = I￾Figure 2.17
Therefore,
C(s) = G =_____________________ G1(s)G2(s)G3(s)G4(s)_____________________
7?(s) 1 + Gl(s)G2(s)G3(s)G4(s)H1(s) + G2(s)G3(s)H2(s) + G3(S)G4(S)H3(S) ’
This result agrees with the transfer function shown in Fig. 2.13(f).
The foregoing examples illustrate the simplifications made possible by use of
Mason’s theorems in conjunction with the signal-flow diagrams. It will be extended
to the state-space concept in this chapter and, in the remaining chapters, the signal￾flow diagram approach will be used to simplify the solutions of problems. In addi￾tion, further properties and applications of this powerful tool will be demonstrated.
2.15 REVIEW OF MATRIX ALGEBRA
The classical methods of describing a linear system by means of transfer functions,
block diagrams, and signal-flow diagrams have thus far been presented in this chapter.
An inherent characteristic of this type of representation is that the system dynamics
are described by definable input-output relationships. Disadvantages of these tech￾niques, however, are that the initial conditions have been neglected and intermediate
variables lost. The methods cannot be used for nonlinear, or time-varying systems.
Furthermore, working in the frequency domain is not convenient for applying
modern optimal control theory, discussed in Chapter 9, which is based on the time
domain. The use of digital computers also serves to focus on time-domain methods.2.15 Review of Matrix Algebra 57
Therefore, a different set of tools for describing the system in the time domain is
needed and is provided by state-space methods. As a necessary preliminary, matrix
algebra is reviewed in this section [15].
A matrix A is a rectangular array of elements defined by
■«n
a12 ^ln
a21 a22
A =
am2 ‘
(2.133)
A matrix having m rows and n columns is referred to as an m x n matrix. A square
matrix is one for which m = n. A column matrix, or vector, is one for which n = 1,
and is represented in the following manner:
a (2.134)
Capital letters are used to denote matrices and lower-case letters to denote vectors.
Matrix A equals matrix B if element ai3 equals element Z>i3- for each i and each j,
where the subscripts refer to elements in row i and columnj ofthe respective matrices.
In order to present the basic types and properties of matrices, matrix A will be
considered in the following discussion where the representative element is ai3.
A. Identity Matrix The identity matrix, or unit matrix, is a square matrix whose
principal diagonal elements are unity, all other elements being zero. This matrix,
which is denoted by I, is given by
T 0
0 1
O’
0
(2.135)
0 0 1
An interesting property of the identity matrix is that multiplication of any matrix A
by an identity matrix I results in the original matrix A:
Al = A, (2.136)
where matrix multiplication is defined later on.58 Mathematical Techniques for the Control Engineer 2.15
B. Diagonal Matrix A diagonal matrix, which is denoted by diag x,-, is given by
X
0
0 •
x2 •
• O'
• 0
diag xf =
•
_0 0 • • xn_
(2.137)
C. Transpose of a Matrix A matrix is transposed by interchanging its rows and
columns. To form the transpose of a matrix, element atj, which is the element of row
i and column j, is interchanged with element aSi, which is the element of row j and
column i, for all i and j. For example, the transpose of A, where
is written as A' where
#11 #12 #13
#21 #22 #23
#31 a32 #33
#11 #21 #31
#12 #22 #32
_#13 #23 #33.
(2.138)
(2.139)
Note that the transpose of A7’ is (AT)r = A.
D. Symmetric Matrix A symmetric matrix is defined by the condition
#;i‘ (2.140)
This matrix, which is denoted by As, is represented by
#u #12 #ln
#12 #22 ' #2n
As =
#2n #nn_
(2.141)
Notice that it is symmetrical about the principal diagonal, and that a symmetric
matrix and its transpose are identical.
E. Skew-Symmetric Matrix A skew-symmetric matrix is defined by the condition
aa = ati = 0. (2.142)2.15 Review of Matrix Algebra 59
This matrix, which is denoted by Aa, is represented by
Aa =
1
1
• • ft 0
N
ai2 ‘
0 •
&ln
‘ a2n
—a2n ' • 0
(2.143)
Note that a skew-symmetric matrix is equal to the negative of its transpose.
F. Zero Matrix The zero matrix or null matrix, denoted by 0, is defined as the
matrix whose elements are all zero. It has the property that
A + 0 = A, (2.144)
where addition of matrices is defined later on.
G. Adjoint Matrix The adjoint of a square matrix is formed by replacing each ele￾ment of the matrix by its corresponding cofactor, and then transposing the result.
For example, if a matrix A is given by
°11 °12 a13
®21 ^22 ^23 >
a31 a33_
(2.145)
then the cofactors of the elements an, a21 are given respectively by the determinants
21
a22 a23
O32 G33 — ^22^33 ^23^32 >
fl12 fl13
°32 a33 — &32a13 '312°33-
(2.146)
A (2.147)
The element ai3- has for its cofactor Ti3 with the proper algebraic sign, (—l)i+>,
prefixed. The new matrix formed by replacing the original elements in the matrix
with their corresponding cofactors is given by
^11 ^12 ^13
•^21 A22 A23
T31 T32 A3a
(2.148)
The transpose ofthis matrix results in the expression for the adjoint (adj) of matrix A:
adj A = /1i2
.^13
^21 ^31
^22 ^32
•^23 ^33.
(2.149)60 Mathematical Techniques for the Control Engineer 2.15
In order to present the basic operations of matrix analysis, three matrices A, B,
and C will be considered in the following discussion where the representative elements
are denoted by al}, bi}, ctj.
A. Addition or Subtraction The sum (or difference) oftwo matrices A and B with the
same numbers of rows and columns is obtained by adding (or subtracting) corre￾sponding elements. The result is a new matrix C, where
C = A + B, (2.150)
and
Ca - + bi}. (2.151)
For example, if matrices A and B are given by
an °12 " ' ’ aln bn b12 • • • bln
a2l a22 ' ' ' a2n b21 b22 • ■ • b2n
A =
then the sum of matrix A £
C — A 4- B =
, B = ,
bn2 * * bnn
md matrix B is given by
(all + ^11) (a12 + ^12) ’ ’ ' (flln + ^in)
(a2l + ^21) (fl22 + ^22) ■ ■ ' (a2n + ^2n)
_(^nl "b bni) (on2 4” bn^) • • • (ann 4- £nn)_
(2.152)
. (2.153)
B. Multiplication of a Matrix by a Scalar Multiplication of a matrix A by a scalar
d is equivalent to multiplying each element of the matrix by d. The result is a new
matrix C, where
C = rfA (2.154)
and
Ca,• = daiS. (2.155)
For example, if matrix A is given by
Xi
°21
fl12
fl22
«ln'
°2n
(2.156)
J^nl &n2 ’ O,2.15 Review of Matrix Algebra 61
then the multiplication of matrix A by scalar d is given by
^#21 dct22
dain
da^n
C = dA = (2.157)
_danl dan2 • • • dannj
C. Multiplication of Two Matrices Postmultiplication * of matrix A by matrix B
results in a new matrix C, where
* The terms post- or premultiplication are used to indicate whether the matrix is multiplied
from the right or the left, respectively.
and
C = AB (2.158)
%=2#iA/- t=i (2.159)
These equations state that the result of postmultiplication of matrix A by matrix B is
a matrix C whose element located in row i and column j is obtained by multiplying
each element in row i ofmatrix A by the corresponding element in column j of matrix
B and then adding the results. It is important to note that the number of columns in
matrix A must equal the number ofrows in matrix B so that matrices A and B may be
multiplied together. For example, if matrices A and B are given by
#11 #12 #13
#21 #22 #23
_#31 #32 #33_
^11
^21
_^31
^12
^22
^32.
B = (2.160)
then the product of matrices A and B is given by
C = AB =
(#11^11
(#21^11
.(#31^11
+ #12^21
+ #22^21
+ #32^21
+ #13^31)
+ #23^31)
+ #33^31)
(#11^12 4" #12^22 + #13^32)
(#21^12 + #22^22 + #23^32) I •
(#31^12 4- #32^22 + #33^32).]
(2.161)
Matrix multiplication is associative and distributive with respect to addition, but in
general not commutative:
A(BC) = (AB)C (associative), (2.162)
A(B + C) = AB + AC (distributive), (2.163)
AB # BA (commutative). (2.164)
D. Inverse of a Square Matrix The inverse of a square matrix B is denoted by
B-1 and has the property
BB1 = BB = I (2.165)62 Mathematical Techniques for the Control Engineer 2.15
It can be shown that the product of an adjoint matrix with the matrix itself has the
property that it is equal to the product of an identity matrix and the determinant of
the matrix:
B adj B = I |B|. (2.166)
Using these two relationships, we can derive the expression for the inverse matrix
B-1. By solving for I from Eq (2.166), the following relationship is obtained:
I = Bad-i_B |B| # 0. (2.167)
|B|
Using Eqs. (2.165) and (2.167), we obtain
BB = BB1 = B B, |B[ # 0. (2.168)
Solving for the inverse matrix B~1 in terms of the adjoint matrix and the determinant
of the matrix, we obtain the following expression:
or
B 1 =
adj B
|B| ’
|B| # 0, (2.169)
Bn I?21 • Bn;
^12 ^22 ■ BnZ
B1 = —
|B|
-Bln Bin Bnn-
, |B|#0 (2.170)
Note that B1 does not exist if | B[ = 0, although Eq. (2.166) still holds.
E. Differentiation of a Matrix The usual concepts regarding the differentiation of
scalar variables carry over to the differentiation of a matrix. Let A be an m x n
matrix whose elements o,7(0 are differentiable functions of the scalar variable t. The
derivative of A with respect to the variable t is given by
~dan(t) da12(t) daln(t)~
dt dt dt
da21(t) da22(t) da2n(t)
J dt dt- dt
7 [A] = A -
dt
dam2{t) damn(t)
L dt dt dt _
(2.171)2.16 State-space Concepts 63
In addition, the derivative of the sum of two matrices is the sum of the derivatives of
the matrices:
j- [A + B] = A + B. (2.172)
at
F. Integration of a Matrix The usual concepts regarding the integration of scalar
variables also carry over to the integration of a matrix. Again, let A be an m x n
matrix whose elements a„(t) are integrable functions of the scalar variable t. The
integration of A with respect to the variable t is given by
(2.173)
«m2<0 dt dt
2.16 STATE-SPACE CONCEPTS
In the analysis of a system via the state-space approach, the system is characterized by
a set of first-order differential or difference [2] equations that describe its “state”
variables. System analysis and design can be accomplished by solving a set of first￾order equations rather than a single, higher-order equation. This approach simplifies
the problem and has several advantages when utilizing a digital computer for solution.
What is meant by the state of a system? It is defined as the minimum set of
variables, denoted by xx,. . . , xn and specified at time t = t0, which together with
the given inputs ux, . . . , um. determine the state at any future time t > t0 [6-9, 10, 22].
Physically, this means that a set of state variables Xj(/0), *2(/0), • • • > XA) define
the initial state of the system based on past history. In addition, the set of state
variables x2, x3,... ,xn characterize the future behavior of the system once the
inputs for t t0 are specified, together with the knowledge of the initial states. We
can view the state of a system, therefore, as describing the past, present, and future
behavior of the system. It is important to emphasize that state variables are not
necessarily system outputs and may not always be accessible, measurable, observable,
or controllable.
The state-space approach has the following advantages.
1. The solution to a set of first-order differential or difference equations is much
easier to determine on a digital computer than the solution of the equivalent
higher-order differential or difference equation.64 Mathematical Techniques for th? Control Engineer 2.16
2. The state-space concept greatly simplifies the mathematical notation by utilizing
vector matrix notation for the set of first-order equations.
3. The inclusion of the initial conditions of a system in the analysis of control
systems, which is difficult using conventional techniques, can be accounted for
readily in the state-space approach.
4. The state-space approach can be applied to the solution of most nonlinear, time￾varying, stochastic, and sampled-data system configurations.
5. The state-space representation lends itself to system synthesis using modern
control techniques that are discussed in later chapters.
Fig. 2.18 The optimal control problem.
Let us consider the block diagram of Fig. 2.18 in order to define the nomenclature
utilized in the state-space approach [10, 22], This open-loop system is used to
introduce the characteristics of the basic optimal control problem in Chapter 9.
Briefly, the optimal control problem is concerned with the determination ofthe control
elements C so that the controlled process P performs optimally with respect to a
selected performance S for the anticipated inputs r15 r2, r3, • • • , rit subject to limita￾tions on the controlled processes inputs u1; u2, u3, . . . , m,„. Initially, attention will be
focused on the controlled process.
It is assumed that u and c are time functions, and that u((t) and c;(r) are used to
represent the values of ut and c, at time t. It is convenient to represent the inputs
«i, i/2, w3, . . . , Mm by an input vector u, where
m2
(2.174)
Lw»n.J
and the outputs c1; c2, c3,. . . , cn by an output vector c, where
(2.175)2.16 State-space Concepts 65
The inputfunction space ofP refers to the set of all possible input functions u that can
be applied to P. The input space of P refers to the set of all possible values that the
vector u can have at some time T. The initial state ofP refers to its initial conditions
at the starting time r0.
The output ofP, which is denoted by c, is a function ofthe input u and the initial
conditions of P. For example, if it is assumed that the input u is applied to P from
t0 to T (where T t0), then the segments of the time functions u and c over the
observation interval (t0, T) are denoted by u(r0, T) and c(t0, T). In addition, the
initial state of P is denoted by p(t0). Therefore, the value of c(t0, T) depends on
u(r0, T) and p(/0).
How can a state vector be associated with a controlled process, and then the
state-equations found for P? Firstly, by associating with P a vector x(t0), a set of
equations which are satisfied by x, u, and c can then be determined. Ifthe resulting set
of equations have the property that x and c are uniquely determined by x(r0) and
u(r0, T), then x qualifies as a state vector of P.
Consider the state equations for the system illustrated in Fig. 2.18. It is assumed
in this derivation that P is a linear, time-invariant system characterized by the
following differential equation:
+ + + = (2.176)
where all the coefficients are constant and An # 0. Here c(n) refers to the «th deriva￾tive of c with respect to time, c(,t-1) is the (n — l)th derivative, etc. It is further
assumed that the initial time, t0, is zero. Taking the Laplace transform of Eq. (2.176)
results in
(Ansn + A^s"-1 + • • • + A0)C(s) = U(s) + Anc{n~1}(0)
+ (Ans + An-Jc^fO) + • • • + (Ansn~' + • • • + A)c(0), (2.177)
where c{lll}(0) represents the initial value of c*"' at t0 = 0. Rearranging Eq. (2.177),
the following relationship is obtained:
C(s) =-----
£(s)
/j„c("-1>(0) + (Ans + /fw_1k(”-2)(0) + • • • + (A^-1 + • • • + Ak(Q)
E(s) ’
(2.178)
where
£(s) = Ansn + + ■ • • + 7f0. (2.179)
This equation states that the Laplace transform of the output C(s), and thus the out￾put in the time domain c(t) [for t > 0], is determined by the input u (for t > 0) and
the values of the output c and all its derivatives up to and including order n — 1 at66 Mathematical Techniques for the Control Engineer 2.16
t = 0. The initial state x(0) can be represented by the following n vector:
x(0) = (c(0), . . . , (2.180)
In addition, the vector x(r) can be represented by
x(t) = (c(t),. . . , c<n-1>(t)). (2.181)
It will be demonstrated that Eq. (2.181) determines a state vector for P.
A mathematical description of the dynamic relationships between the inputs and
outputs of the controlled process can be derived from Eq. (2.181). This vector
equation can be rewritten as the following set of linear equations:
= c, x2 = c,. . . , xn — c("-1’. (2.182)
In addition, Eq. (2.182) can be written in the following form:
Xj = x2,. . . , x„ = cM = -y- (u - Aoxr - • • • - A^xJ. (2.183)
This set of first-order differential equations can be represented in vector form by
x = Px 4- Bu (2.184)
where
(2.185)
x =
x2
P =
2
B =
71 —
0
0
1
0
0
1
0
0
(2.186)
0 0
-o~
0
1
A_
0
A,
1
A
J
= [1,0,...,0],
The representation given in Eq. (2.186) is known as the phase-variable canonical
form and the matrix P is called the companion matrix. The solution to Eq. (2.184),
x(t), is uniquely determined by x(0) and u(0, T). Reference 7 shows that this is a
necessary and sufficient condition to qualify x(r) as a state vector for P. Note that P
can have infinitely many different state-vector representations.2.16 State-space Concepts 67
Equations (2.184) and (2.185) are the state and output equations for linear
time-invariant systems only. The state and output equations of general nonlinear
and/or time-varying systems are given by
X = f(x, u, /),
c = g(x, u,r).
(2.187)
(2.188)
In these equations, u is an m-vector, x is an n-vector, and c is a />-vector.
A time description of the controlled process can be obtained by solving the
differential equations (2.184) or (2.187). The solution is represented as
x(0 = *o, '<>)• (2.189)
The above equation is interpreted as the value of x at time t after starting at time r0,
in state x0, and governed by the control input u. defined for the interval t0 < t < T.
In the remainder of this section, several examples are given for converting the
dynamics of a system (given in any of several forms) into the state-space forms given
by [6]
*i = /i( *i, • • • Wn • • • >«w),
(2.190)
Xn = fn(xv, ... ,Xn', Ulf ... , Um),
or in the vector state-space form given by
x = f(x, u, t). (2.191)
The linear, time-invariant forms ofEqs. (2.190) and (2.191) are represented as follows:
— -^11-^1 “I" ’ * ’ “F AinXn "F
(2.192)
Xn = ~F ’ * * “F ^nn^n “F ~F * “F
and
X = Px + Bu. (2.193)
In Eq. (2 193), x is a column matrix (vector) whose components arexj, . . . , xn; u
is a column matrix whose components are w15. . . , um; P is an n x n matrix with
entries AiS, and B is an n X m matrix with entries Bti.
In the first example used to illustrate the representation of the dynamics of a
system in state-space form, consider the problem of rocket flight in two dimensions.
Representing the vertical and horizontal axes by v and r, respectively, the describing
equations are given by
r = F cos 0,
v = F sin 6 — g,
(2.194)
(2.195)68 Mathematical Techniques for the Control Engineer 2.16
where F is thrust force per unit mass, 0 is thrust direction, and g is the gravitational
force. The control inputs are considered to be F and 0. Defining
xt = r,
x3 = v,
Ui = F,
x2 = r,
x4 = v,
u2 = 0,
we find that the dynamics are described by
X2 = Mj cos m2,
■ x4 = sin w2 — g.
This system can also be described in vector form by
where
X = Px + Bu, (2.196)
(2.197)
B
c = Lx,
1 0
0 0
c =
0 0
1 0
For the second example, consider a system whose transfer function is given by
The differential equation corresponding to this system is given by
+ 8^ + 9y + 2c = 5u. (2.199)
dt3 dt3 dt
Defining the state variables as
= c, x2 = c, x3 = c, (2.200)
the system can now be described by the following three first-order differential equa￾tions:
= x2 = c, (2.201)
x2 = x3 = c, (2.202)
x3 = -2xj - 9x, - 8x3 + 5m. (2.203)2.16 State-space Concepts 69
Therefore, the system can be described in vector form by
x = Px + Bu,
c = Lx,
(2.204)
(2.205)
where
L = [1 0 0],
Fig. 2.19 A feedback control system.
As a third example concerned with obtaining the state-space equation of a system,
consider the closed-loop system shown in Fig. 2.19. The closed-loop transfer function
of this system is given by
Ci's) 2
R(s) s2 + s + 2 ’
(2.206)
The corresponding differential equation is given by
— + - + 2c = 2r.
dt2 dt
(2.207)
By defining the state variables as
Xj = c, x2 = c. (2.208)
the system can be described by the following two first-ofder differential equations:
jq = x2 = c
x2 = — 2xj — x2 + 2r. (2.209)70 Mathematical Techniques for the Control Engineer 2.17
Therefore, the entire system can be described in vector form by
x = Px + Br,
c = Lx,
where
P =
0 rl -2 -1J’
(2.210)
(2.21 I)
B x x = L=[l 0],
At this point, it is important to re-emphasize that the state variables are not neces￾sarily the outputs of a system. The system output can be measured or observed, but
a state variable may not always be measurable or observable Sometimes, a state
variable can be viewed as an output if it is measurable or observable. The concept
of observability is discussed in Chapter 9 when optimal control theory is presented.
2.17 THE STATE-VARIABLE DIAGRAM
The state-variable diagram provides a physical picture that is useful in understanding
the state-space concept. In addition, the differential equations relating the state
variables are easily obtained by inspection of the diagram. A state-variable diagram
consists of integrators, summing devices, and amplifiers. Outputs from the integrators
denote the state variables. It should be noted that the state-variable diagram is the
same as an analog computer simulation diagram [23].
As an example ofdetermining the state-variable diagram, consider a system whose
transfer function is given by
Dividing top and bottom by s3, we obtain the following
x C(s) s2 + 4s + 1
P(s) = — = ------------------. (2.212)
l/(s) s3 + 9s2 + 8s
Eq. (2.213) may be rewritten as follows:
C(s) s 1 + 4s 2 + s 3
P(s) = — =----- - . (2.213)
t/(s) 1 + 9s"1 + 8s-2
Defining
£(s) = --------~;, (2.214)
1 + 9s”1 + 8s-2
C(s) = (s-1 + 4s~2 + 5-3)E($).
From Eq. (2.215) and the relation
E(s) = U(s) - 9s~lE(s) - 8s2E(s),
(2.215)
(2.216)2.17 The State-variable Diagram 71
the state-variable diagram can easily be obtained as indicated in Fig. 2.20. * The
state-variables are indicated in the diagrams as xn x2, and x3. Also, the differential
equations relating the state variables are easily obtained from Fig. 2.20 by inspection.
From the state-variable diagram, the differential equations relating the state variables
are as follows:
* This analog computer simulation diagram contains more inverters than are actually
required to implement Eqs. (2.215) and (2.216). It has been presented in this manner to
indicate the proper phase relationships existing among the various states, as indicated in
Eq. (2.217). From now on, all state-variable diagrams will also contain a sufficient number
of inverters to indicate the proper phase relationships among the various states. It is left as an 
exercise to show how an analog computer simulation of Eqs. (2.215) and (2.216) can be
performed using the same number of integrators and summers as shown in Fig. 2.20, but
with only one inverter.
(2.217)
Fig. 2.20 State-variable diagram for system where
= / + 45 + 1
n ’ s3 - 9i2 + 85 •
Therefore, the entire system can be described in vector form by
x = Px + Bm, (2.218)
c = Lx, (2.219)72 Mathematical Techniques for the Control Engineer 2.17
where
'0 1 O’
P = 0 0 1
0 -8 -9
"O’
0
1
x L = [1 4 1],
B =
;iven by
C(s) . 2
U(s) s2(s2 + s + 1) ’
C(s) 2s-“
(2.222)
I7(s) 1 + s-1 + s-2
The output c(t) can be obtained by a linear combination of the three state variables as
follows:
c(t) = xx(t) + 4x2(t) + x3(t). (2.220)
As a second example for determining the state-variable diagram, consider a
system whose transfer function is g
P(s) =
Dividing through by s4 we obtain
P(s) =
Defining
£(s)
Eq. (2.222) may be rewritten as
C(s) = s~4£(s). (2.223)
From Eq. (2.223) and the relation
E(s) = 2U(s) — s^Efs) — s~2E(s), (2.224)
2U(s)
1 + s’1 + s-2 ’
the state variable diagram for this system can easily be obtained (see Fig. 2.21). The
state-variables are referred to as xx, x2, x3, and x4. They are defined as:
x4 = c, x2 = c, x3 = c, x4 = "c. (2.225)
The differential equations relating the state variables are as follows:
Xi = x2 = c,
x2 = x3 = c, (2.226)
*3 = *4 = C,
x4 = 2u — x3 — x4.2.17 The State-variable Diagram 73
s-l£ (s)
s *2 E (s)
Fig. 2.21 State-variable diagram for system where
2
The corresponding vector form is given by
(2.227)
(2.228)
From this discussion it can be seen that it is possible to apply the signal-flow
diagram technique to state-space analysis. Mason’s theorems can be applied to the
signal-flow diagram which is obtained directly by inspection of the state-variable
P(-0 = 2z 2 , ---—n
r(r + 5 + 1)
where
x = Px + Bu,
c = Lx,
Fig. 2.22 Signal-flow diagram corresponding to the state-variable diagram of Fig. 2.20.74 Mathematical Techniques for the Control Engineer 2.18
Fig. 2 23 Signal-flow diagram corresponding to the state-variable diagram of Fig. 2.21.
diagram. The signal-flow diagram also provides a physical interpretation ofthe state￾rpace concept since its nodes actually represent the different states of the system.
For example, the signal-flow diagrams corresponding to the state-variable dia￾grams of Figs. 2.20 and 2.21 are given in Figs. 2.22 and 2.23, respectively. The
physical meaning of system state is quite clear from these diagrams.
2.18 DIGITAL-COMPUTER EVALUATION OF THE TIME RESPONSE
The state-space representation of a system's dynamics easily lends itself to analysis by
means of a digital computer. The technique involves the division of the time axis into
sufficiently small increments t = 0, T, 2T, IT, 4T, . . . , where T is the incremental
time of evaluation At. This time increment must be made small enough for accurate
results. Round-off errors in the computer, however, limit how small the time incre￾ment can be.
To illustrate the procedure, let us consider the equation
x(t) = Px(t) + Bu(t). (2.229)
By definition of a derivative,
(2.231)
Utilizing this definition, the value of x(t) when t is subdivided into the increments At
can be determined. Since At = T, we can say (approximately) that
. x(t + T) - x(t)
x = ------------------------- .
T
Substituting Eq. (2.231) into Eq. (2.229), we obtain
. >(> + - X(,) - PXO) + BUG).
Equation (2.232) may be solved for x(r + T) as follows:
(2.232)
x(t + T) = TPx(t) + x(/) 4- TBu(t). (2.233)2.19 The Transition Matrix 75
This equation can be rewritten as
x(r + T) = (TP + l)x(t) + TBu(l). (2.234)
To generalize this expression for the intervals mT, let
t = mT, (2.235)
where m = 0,1,2, 3,4, . . . . Therefore, Eq. (2.234) can be rewritten as the recurrence
relation
*[(m + 1)T] = (TP + l)x(mT) + TBu(wT). (2.236)
Equation (2.236) states that the value ofthe state vector at time (m + 1)T is based on
the values of x and u at time mT. This resulting recurrence relation is a sequential
series of calculations that is very suitable for digital-computer operation. Note that
this is a very crude scheme—more sophisticated schemes involve more refined
approximations to x [24, 25, 26].
2.19 THE TRANSITION MATRIX
The transition matrix relates the state of a system at t — t0 to its state at some subse￾quent time t, when the input u = 0. In order to define the transition matrix of a
system, let us consider the general form of the state-space equation (see Eq. 2.193):
x = Px + Bu. (2.237)
The Laplace transform of Eq. (2.237) is given by
sX(s) - x(0+) = PX(i) + BU(s), . (2.238)
where X(s) is the Laplace transform of x(r) and U(s) is the Laplace transform of
u(r). Solving for X(s), we obtain
X(s) = [si - P]-^^) + [si - P]-1BU(s). (2.239)
The inverse Laplace transform of Eq. (2.239) is given by
x(t) = <t»(t)x(0+) + I «>(r - t)Bu(t) dr, (2.240)
Jo
where
4»(t) = ^{[sl - P?1}, (2.241)
and the second term on the right-hand side of Eq. (2.240) is the convolution integral.
Equation (2.240) is known as the state-transition equation of the system. When the
input u = 0, Eq. (2.240) reduces to
x(t) = 4>(t)x(0+). (2.242)76 Mathematical Techniques for the Control Engineer 2.19
The matrix 4»(r) is defined as the transition matrix since it relates the transition of the
system state at time t0 = 0, to the state at some subsequent time t. It has the following
properties:
4>(0) = I, (2.243)
- U = *('2 ~O*('i ~ fo)» (2.244)
*(t + T) = 4>(0 *(r), (2.245)
4>-J(t) = 4>(-t). (2.246)
Very often it is desired to use a more general initial time, t0. Equation (2.240)
can be modified by letting t = r0. Solving for x(0+), we obtain the following expression:
x(0+) = 4>’4(r0)x(to) - f 4»(t0 - t)Bu(t)dr.
Jo
Using Eq. (2.246), this equation can be rewritten as
x(0+) = *(-t o)x(to) - ♦(“*<>) r*(fo - t)Bu(t) dr. (2.247)
Jo
Substituting Eq. (2.247) into Eq. (2.240), the following expression is obtained:
x(t) = «>(t)«>(-to)x(to) - ^(t)4»(-t0) f °4»(t0 - t)Bu(t) dr
Jo
+ [♦(, - t)Bu(t) dr. (2.248)
Jo
Using Eq. (2.244), Eq. (2.248) can be reduced to
x(t) = *(t - t0)x(t0) + f<I»(t - t)Bu(t) dr. (2.249)
Jto
Equation (2.249) is the state-transition equation of the system for z > r0.
As an example of determining the transition matrix, consider the system where
the transfer function of the controlled process is given by
p(s) = TTTy = • (2.256)
U(s) s
Its corresponding differential equation is given by c = u. Defining the state variables
as
Xj = c, x2 = c, (2.251)
the system can be described by the following two first-order differential equations:
*! = x2 = c, ,x2 — u. (2.252)
Therefore, the entire system can be described by the equation
x = Px + Bu, (2.253)2.19 The Transition Matrix 77
where
The transition matrix, which is defined by
(2.254)
4»(t) = ^-i{[5| - P]-i} (2.255)
can be obtained from Eq. (2.254). We find
[sl - p' - [o °] -
From Eq. (2.169), we know that
B1 =
Therefore
[si _ pj-i = a- pi _
|sl - P|
r° r
L° °.
adj B
|B| '
Fs 11
LO sj
Fs —
L°
s 1
_0 s.
/]• (2.256)
(2.257)
pl 1_~
s
-= . (2.258)
0 -
_ s_
s
0
-1
s
s2
The transition matrix defined by Eq. (2.241) is the inverse transform of this matrix.
It is given by
*(0 = ^{[sl - P]-i) = (2.259)
The transition matrix may also be derived directly from the state-variable dia￾gram. As an example of the technique, consider a system described by the differential
equation
c + 4c + 3c = r. (2.260)
The Laplace transform of Eq. (2.260) yields
and dividing top and bottom by s2, we obtain
C(s)________ s~2
R(s) ~ 1 + 4s"1 4- 3s-2 ‘
(2.262)
Defining
(2.263)
1 + 4s-1 + 3s-2 ’
Eq. (2.262) may be rewritten as
C(s) = s-2£(s).
From Eq. (2.264) and the relation
' (2.264)
E(s) = R(s) - 4s~'E(s) - 3s~2E(s), (2.265)78 Mathematical Techniques for the Control Engineer 2.19
xi C(s)
Fig. 2.24 State-variable diagram for system where
C(s) = 1
R(s) s2 + 4s + 3 ’
the state-variable diagram for this system is obtained as illustrated in Fig. 2.24. In
addition, for generality, it is assumed that the states ofthe system, Xj and x2, have the
initial conditions x^O) and x2(0), respectively. The corresponding signal-flow diagram
is given by Fig. 2.25. The transformed state-transition equations of the system are
obtained from this state-variable signal-flow diagram using Mason's formula (Eq.
2.132):
where
X/s) -
-!(! + 4s~1)x1(0) s
A
~2x2(0) s~2R(s)
A ’ A
(2.266)
X2(s) -
-3s~2Xi(0) s^x^O)
A A
s~1R(s)
A
(2.267)
A = 1 - (-4s-1 - 3s-2) = 1 + 4s-1 + 3s-2. (2.268)
Fig 2.25 State-variable signal-flow diagram corresponding to the state-variable diagram of
Fig. 2.24.2.20 Application of the State-space Method 79
Simplifying Eqs. (2.266), (2.267), and (2.268), we obtain the following pair of equa￾tions:
Xx(s) s + 4
s2 + 4s + 3
-v/0) +
1
s2 + 4s + 3
x2(0) +
R(s)
s2 + 4s + 3 ’
(2.269)
X2(s) =
-3
s2 + 4s + 3
*t(0) +
s
s2 + 4s 4- 3
x2(0) +
sR(s)
s2 + 4s + 3 ’
(2.270)
These two equations can be put into the following form:
X2(s)J
1
(s + l)(s + 3)
HRo)-!
sj Lx2(0)J
(s + l)(s + 3)
s
R(s). (2.271)
s + 4
. -3
L(s + l)(s + 3)J
From Eq. (2.271), we can easily obtain the transition matrix by taking the inverse
Laplace transform. It is assumed in the following solution that r(t) = U(t) and
7?(s) = 1/s:
rx1(f)'l = I" 1.5e-' - 0.5e-3< 0.5e~‘ - 0.5e~3‘ 1pc1(0)'l
|x2(0J 1.5e_< + L5^3( -0.5e-‘ + 1.5e-32J Lx2(O)J
ro.33f/(r) - 0.5e~z + 0.167e-3rl
+ 0.5e-' - 0.5e-3( (2.272)
Therefore, the transition matrix is given by
*(0 =
1.5e-‘ - 0.5e-3‘
-1.5e-‘ + 1.5e-3(
0.5e_( — 0.5e-3( "I
-0.5e-( + 1.5e-3/J
(2.273)
Once the transition matrix is obtained, the evaluation of the time response is easily
obtained.
This technique unfortunately shows that the use of the state-variable diagram and
signal-flow graph method for determining the transition matrix is extremely inefficient
compared with calculating it directly from Eq. (2.241). However, the method
utilizing the state-variable diagram in conjunction with the signal-flow graph does
have advantages in certain situations since it offers other choices ofstate variables and
permits application of Mason’s theorems for determining the relationships among the
various states required in the transition matrix.
2.20 APPLICATION OF THE STATE-SPACE METHOD
The purpose of this section is to illustrate how one may obtain the complete solution
for the output in the time domain of a control system utilizing the stale-space method.
In this example, we will want to determine the complete solution by evaluating
Eq. (2.240).80 Mathematical Techniques for the Control Engineer 2.20
Consider a system described by the following differential equation:
c + 2c + c = r + r. (2.274)
It is desired to determine the output c(t), given that the input r(t) is given by
r(t) = sin t (2.275)
and the initial conditions are Xj(0) = 1 and x2(0) = 0. The technique employed is to
determine the transition matrix from Eq. (2.241) and then evaluate Eq. (2.240) for
x(f). The output c(r) is then evaluated from
c(r) = Lx(r). (2.276)
If the state variables are defined by
Xj = c, x2 = c, (2.277)
and w by
u = r + r,
then the system can be described by the following two first-order differential equations:
*1 = X2,
x2 = — 2x2 — Xj + u.
(2.278)
Therefore, the system can be described by
x = Px + Bu, (2.279)
where
J]. ■=["]• *-[]. (2.280)
The transition matrix, which is defined by Eq. (2.241), can be obtained from Eq.
(2.280)1 We find
r W ~m = |_° 01J~ LT-10 -2J
11 = LTs1 5—+
112J’ (2.281)
From Eq. (2.169), we know that
= (2.282)
Therefore,
[si - p]->‘ = =
|sl - P|
's + 2 1"
- — 1 s_
- s + 2 1__ -
(s + I)2 (s + I)2
_____ 1 5
L (s +I)2 (s 4- 1)2J
. (2.283) (S + I)22.21 Digital-computer Evaluation of the Transition Matrix 81
The transition matrix defined by Eq. (2.241) is the inverse transform of this matrix.
It is given by
0(1) = ^{[sl - P]-1} = e_t^_ J. (2.284)
The full solution for the output can be obtained from Eqs. (2.240) and (2.276) as
follows:
ft
x(t) = O(0x(0+) + O(t - t)Bu(t) dr, (2.285)
Jo
c(0 = Lx(0- (2.286)
Substituting Eq. (2.285) into Eq. (2.286), we obtain the following relationship for the
output in terms of the transition matrix:
c(0 = LO(0x(0+) + [*1.0(1 - t)Bu(t) dr. (2.287)
Jo
We know O(r) from Eq. (2.284). We have looked at many similar systems in this
chapter, and should know by inspection now that
L = [1 0], x(0+) = (2.288)
For this system, the input function u(r) is obtained as follows:
u(t) = r(r) + r(r) — sin r + cos r. (2.289)
Substituting all of these values into Eq. (2.287), we obtain the following expression:
+£[l e-'-'V- "+’J[?](sinT + C0ST),/T'
(2.290)
On simplifying, the result becomes
c(t) = e~f(t + 1) +J [(t — r)e~((~,',][sin r + cost] dr. (2.291)
Integrating and simplifying, we finally obtain the output as
c(t) = 4e~( + te~f + |sin t — | cos /. (2.292)
2.21 DIGITAL-COMPUTER EVALUATION OF THE TRANSITION MATRIX
The transition matrix may be readily evaluated by means of digital-computer tech￾niques. Several methods have been proposed for its numerical evaluation. References
11 and 12 discuss one type of computational algorithm developed by Fadeev for82 Martcmatical Techniques for the Cootrot Engineer
accomplishing this. However. this approach requires the LapJece-tMesferm inversion
of 4>(s). Unfortunately this approach is very tedious for matrices o’ any siat This
section presents a straightforward method which evaluates the transition matnx based
on its infinite matrix series definition [13]. Direct application of the series definition
gives a ven efficient and fast method that depends only on matrix m If'p’.carion.
In order to derive the series definition of the transition matrix [14], let us consider
the following equation:
4>(f) = P4>(r). (2.293)
where
<$(0) = I.
The transition matrix. <$(r). represents a solution to this equation. and let us assume
that it is given bv
«»(r) = ep . (2.2 *4)
where
.. P¥ F*f
t-F- = I 4- Pf q- ---- q- •••+-- 4- - - •. (2 295)
2' Jt!
We shall now work backwards and pro\e that Eq. (2.294) is indeed the correct solution
to Eq. (2.293). Following this procedure, the value of 4>(:'' is given bv
J .. PA;
-[e«] = P + P-; + — 4- • - - + r_ + . . . . (2.296)
dr 2! x!
A comparison of Eqs p.295) and (2 2%) indicates that
-[Z- *] = p/ (2.297)
at
Therefore. from the definition of Eq. (2.294), we find that
4>(f) = P4>(ri, (2.29$)
so that
<>(f) = er’ = — (2.299)
s—ti k *
is indeed a correct solution to Eq. (2.293).
From this derivation, we can now extend our original definition of the transi.ion
matrix (see Eq. 2.241) to the following:
*(’> = - P]-1} = cF = V — • C.300)
k!
Since the matrix series is uniformly convergent for any finite interval, the transition
matrix can be determined within prescribed accuracy using onlv a fim e number of
terms [15].2 21 KsaJaaiito ©f tte InamMtK MWix »3
As :‘e<at, ?e sfoeedufe for ewftsadsg, fyst-eAon the definition of Eq, (2 299), is
ttow pmestod aed fc read y adapted for d gitel eor'p.jter computation [13], Let
e* ‘ be ntja^erTe^ ac
f = M - P |2,S61)
where M » toe appreswrattog matrix for,^',
5 P'-jT *
»-» = 2 r-(T^ 0, (2.302)
i'"^ ,
R is the reminder matrix
? PT
R = 2 -~7 ■ (2 M3)
k:
Pat eac' atomwit hi the matrix e'' h mqwtired to witfein m aacrwracy of at
l0£#t b ®g?5?a£3HS C>'t$, tbe?A • ,
(2,304)
hhere r r«ps«tsst jfejwits o-Ttte m^r w R srd M
Let tfe norm of matrix P be gives by
P = 2 fM- (2.305)
ffees it be %- ffwn
r < P/.. k f2.y>6)
rterefore, each efes^st of the matrix P’- m thas or equal to P z. ft follows that
kd < S -/1^. (2.307)
lx f>t
£>et fefire the rsttio of the ?ec0«d ter». to t-W terr * of the prwiow, wm
o be « ac toUe%$:
a -T
€ = -^-—, (2.JOS)
K ^2
'herefore.
i P! 7
-■2 <<, fe>K + 2. (2.309)
«Witoii«g Eq. (2.?/h) into Eq, (2,307), we ofctais the toltowisg Mpramim:
p 5 'Y’’ t
r^<- -----~ € -b "-). (2.310)
(K -b rj!
qmttos (7 3i0; cwb fee re#/ntte« in dzytec ferm %,x84 Mathematical Techniques for the Control Engineer 2.22
Let us summarize the steps of this iterative procedure for evaluating cp before
applying it to a problem:
a) An initial value of K is chosen arbitrarily.
b) The value of is evaluated by means of Eq. (2.302).
c) The value of e is determined by means of Eq. (2.308).
d) The upper bound of |ri3| is calculated from Eq. (2.311).
e) Each element of M, obtained from Eq. (2.302), is compared with the upper bound
of |ri3| obtained from Eq. (2.311).
f) Ifthe inequality ofEq. (2.304) is not satisfied, the value ofKis increased, and steps
(a) through (e) are repeated; otherwise, the procedure is ended.
As an example of applying this procedure, let us evaluate 4»(r) numerically for the
following example [13]:
T = 0.1.
Let us assume that each element in the matrix efT is required to within an accuracy of
at least four significant digits and each number carries six significant digits. The
transition matrix is obtained approximately, using the procedure indicated:
epT M =
’ 0.999884
-0.339385 x 10~2
-0.644972 x 10-1
0.995717 X 10-1 0.452513 X IO-3'
0.987440 0.859963 x 10-1
-0.239884 0.729451
In this example, b — 4. When K = 9, the upper bound of |ri3| from Eq. (2.311) is
0.587945 X 10-’. Therefore, 10” |rl7| = 0.587945 X 10~3 < |WJ (/,; = 1,2,...),
where are the elements of M given in the example. This illustrative example
indicates the simplicity and accuracy of the procedure for obtaining the transition
matrix utilizing its series definition in conjunction with a digital computer.
2.22 SUMMARY
Many mathematical techniques have been presented in this chapter for use by the
control-system engineer. Starting with complex-variable theory, we then developed
the Fourier transform and Laplace transform. The transfer function, block diagram,
and signal-flow diagrams were then presented. It was pointed out that these concepts
were not applicable to the more general, nonlinear, time-varying system. For this
class of systems, the state-space concept was then presented. Matrix algebra was
reviewed, and the state-variable diagram and the transition matrix were presented.
It is reasonable for the reader at this point to ask which methods he should use.Problems 85
There are no hard and fast guidelines but reasonable rules of thumb can be out￾lined. In general, if the problem is one of analysis, if the system has one input and
one output, and if its differential equation can be described by a linear differential
equation having constant coefficients, then the engineer can use the simple transfer￾function/block-diagram approach or the state-space method, each technique comple￾menting the other. On the other hand, if the analysis problem involves nonlinearities,
time-varying characteristics and multi variable inputs and outputs, then the state￾space approach should be used. If the problem is one of synthesis involving optimal
control theory, then again the state-space approach should be used.
Since the main purpose of this book is pedagogical, both the transfer function/
block diagram and state-space concept will be used wherever possible. For example,
in the following chapter, where it is desired to represent mathematically various linear
physical components, both approaches are used. The reader should also develop this
dual capability and be able to handle a problem from either point of view.
PROBLEMS
2.1 Prove that the Laplace transform of an exponentially decaying sine wave, e xt sin cor,
This
is given
transform
by
is shown as item 9 in Table (i+
2.1.a)CO2+ co2
2.2 Obtain the direct Laplace transform for the following differential and integral equations:
di(t) 1 f
a) L —----1- Ri(t) + - z(r) dt = e(r),
err C J
d2x(t) dx(t)
b) M + B-— + Kx(t) = 3r, dr dt
d26(t) d6(t) .
c) J —7^- + B —— + A?0(r) = 10 sin cor.
dt2 dt
2.3 Obtain the inverse Laplace transform for the following expressions:
20
a) Fa{s) = + 2)2(s2 + i25 + 16) ’
z s 10(5 + 2)
b) Fb(s) = (i2 _ 16)(5 + ,
. 2(5 + 1)
c) f-c(s) = j(52 + 85 + 4) •86 Mathematical Techniques for the Control Engineer
2.4 Prove that the transfer function for the network illustrated in Table 2.2, item 3, is
given by the expression shown.
2.5 Prove that the transfer function for the network illustrated in Table 2.2, item 6, is given
by the expression shown.
2.6 Prove that the transfer function for the network illustrated in Table 2.2, item 9, is
given by the expression shown.
2.7 By means of block-diagram reduction techniques, find the transfer function of the
system C(s)/R(s) for the configuration illustrated in Fig. P2.7.
Figure P2.7
2.8 For the system illustrated in Fig. P2.7, what is the effect on the system transfer function
of inserting a sign reverser in series with W3(y)?
2.9 Determine the transfer function of the system shown in Fig. P2.7 relating error E(s)
and input R(s).
2.10 Repeat Problem 2.9 with a sign reverser inserted in series with H3(s). What is the
significance of this result as compared to that obtained in Problem 2.9?
2.11 Repeat Problem 2.7 using the signal-flow diagram method.
2.12 Repeat Problem 2.8 using the signal-flow diagram method.
2.13 .Repeat Problem 2.9 using the signal-flow diagram method.
2.14 Repeat Problem 2.10 using the signal-flow diagram method.
2.15 Determine the transfer function of the overall system shown in Fig. P2.15, C(s)lR(s),
using the signal-flow diagram.Problems 87
Figure P2.15
2.16 Repeat Problem 2.15 with the feedback path containing element Hs(s) removed.
2.17 Determine the transfer function of the system shown in Fig. P2.15 relating error E(s)
and input R(s).
2.18 Repeat Problem 2.17 with the feedback path containing element Hb(s) removed.
2.19 Determine the transfer function of the <?verall system shown in Fig. P2.19, C(s)lR(s),
using the signal-flow diagram.
Figure P2.19
2.20 Determine the transfer function of the system shown in Fig. P2.19 relating error E^s)
and input R(s).
2.21 Repeat Problem 2.19, with the feedback path containing element H^s) removed.88 Mathematical Techniques for the Control Engineer
2.22 Repeat Problem 2.20, with the feedback path containing element TTjfs) removed.
2.23 Determine the system transmission T — C/R for the signal-flow diagram shown in
Fig. P2.23.
e
Figure P2.23
2.24 Synthesize a signal-flow diagram for the following source-to-sink transmission T, such
that each branch transmission in the graph is a different letter.
, C ah{\ — cf — dg)
T = R= (1 - M(1 - dg) - cf
2.25 Synthesize a flow graph for the following source-to-sink transmission expression, such
that each branch transmission in the graph is a different letter.
_ C (ag 4- adi 4- e)(f + bh + bcj) 4- z/(l — abed)
R 1 — abed
2.26 The signal-flow diagram of a control system is illustrated in Fig. P2.26.
a) Determine the overall transmission T = C/7?.
b) If the K' branch were made zero, the same overall transmission could be obtained by
appropriately modifying the G branch. Determine the required modification.
2.27 Determine the vector equations for the systems characterized by the following differ￾ential equations:
d2c
di2
d2c
di2
d3c
dt3
d3c
di3
a)
b)
c)
d)
de
2dt +
de
2- +
dt
d2c
3 -tv dt2
d2c
3 di2
= 0,
= A,
de
4-2— 4- 2c = 0, dt
de
+ 2— 4- 2c = A. dtProblems 89
2.28 The approximate linear equations for a spherical satellite are given by
7 + WqI 63 = Z1(
Z02 =L2,
I $3 — ^3>
where 0u 02, 63 represent angular deviations of the satellite from a set of axes with fixed
orientation, Zj, Z2, Z3 represent applied torques, /represents the moment ofinertia, and w0
represents the angular frequency of the oriented axis. Determine the vector form of the
system’s dynamics.
2.29 The signal-flow diagram of Fig. P2.29 illustrates the process of interest accrual in a
savings account. The initial deposit is represented as r(f) and the total savings is represented
as c(t). The interest is assumed to be a constant of K% per year. It is interesting to note
from this representation that it represents a. positive feedback process.
a) Write the state equation of this system and determine the total savings as a function of
deposit(s) and the interest rate.
b) Compare the total savings at the end of a ten year period for the following two conditions:
1. An initial deposit of $10,000 held in a savings account over a ten-year period.
2. A yearly deposit of $1,000, totaling $10,000 over a ten-year period, in a savings
account.
In each case assume that the interest rate K is 5 % per year.
c) How do each of these cases compare with the case of savings without interest.
Figure P2.29
2.30 The voltage build-up of a simple vacuum-tube oscillator is given by the Van der Pol
equation as follows:
v — u(l — v2)v + v = 0.
Determine the plant dynamics.
2.31 The APOLLO 11 mission, in which Astronauts Neil Armstrong and Edwin Aldrin
successfully soft landed the Lunar Excursion Module (LEM) on the lunar surface, was a
historic event. Figure P2.31(a) is a photograph of the LEM vehicle taken by Astronaut
Michael Collins from the Apollo Command Module window after they separated. In order
to obtain the state-space vector equations ofthe LEM during the terminal soft-landing phase,
let us consider the basic physics involved [17]. Figure P2.31(b) illustrates the forces acting on
the LEM, assuming that the vehicle is vertical and subject to the following conditions:
a) The only forces acting on the vehicle are its own weight and the thrust which acts as a
braking force.
b) The moon is flat in the vicinity of the desired landing point.
c) The propulsion system is capable of producing a mass flow rate, m.(a)
Vehicle
descent
trajectory
(b)
Fig. P2.31 (a) Apollo 11 Astronauts Neil Armstrong and Edwin Aldrin are inside the
lunar module separated from the Apollo command module. (Official NASA photo) (b)
Forces acting on LEM.
90Problems 91
Based on these assumptions, the motion of the vehicle is governed by the following relation:
Km
x =--------+ g,
m °
where
x = altitude
m = total mass
m = mass flow rate < 0
g = acceleration of gravity at the surface
K = velocity of exhaust gases = constant > 0.
Defining the state variables as
X = X15 X? = Xj,
x3 = m, zq = m,
determine the vector equation of the system during the terminal soft-landing phase of the
mission.
2.32 Determine the vector equation for the system shown in Fig. P2.32.
Figure P2.32
2.33 The landing of an aircraft consists of several phases [18], First, the aircraft is guided
toward the airport with approximately the correct heading by radio direction-finding equip￾ment. Within a few miles of the airport, radio contact is made with the radio beam of the
instrument landing system (ILS). In following this beam, the pilot guides the aircraft along a
glide path angle of approximately 3° toward the runway. Finally, at an altitude of approxi￾mately 100 ft, the flare-out phase of the landing begins. During this final phase of the
landing, the ILS radio beam is no longer effective, nor is the —3° glide path angle desirable
from the viewpoint of safety and comfort. Therefore, the pilot must guide the aircraft along
the desired flare path by making visual contact with the ground. Let us consider, in this
problem, the states of the aircraft during the final phase of the landing (the last 100 ft of the
aircraft’s descent). Figure P2.33(a) defines the aircraft’s coordinates and angles. Figure
P2.33(b) illustrates the aircraft’s block diagram in terms of measurable state signals from the
elevator deflection angle to the altitude h(t). The state signals being fed back are all
measurable. For example, the altitude h(t) can be measured with a radar altimeter, and the
rate of ascent h(t) can be measured with a barometric ratemeter. In addition, the pitch
angle, 0(r), and the pitch rate, Kt), can be easily measured using gyros. Defining the states
of the aircraft-landing system as
x/o = Kt), xjf) = Kt),
x3(r) = A(r), x4(0 = h(t), U1(t) = K(t),
determine the vector equation of this system.Drag
(b)
, 1 _ 1 2£<». _ 1
^11 ““ ^13 '— “------ » -------- ' ' > ^33 — “*—
Ts VT,1 VTS jz Ts
, _ 2<COS 2 1 _ V
^12------ -- — Ms ~2 ’ ^32 ~ Z7 CH M’
* S *8 *3
where
Ks = short period gain of the aircraft,
Ts = path time constant,
m, = short period resonant frequency of the aircraft,
t, = short period damping factor of the aircraft.
Figure P2.33
Figure P2.34
92Problems 93
2.34 Determine the vector equation for the system shown in Fig. P2.34.
2.35 A finless torpedo is directionally unstable without control. However, its controlled
performance is usually made better than that of a torpedo with fins by utilizing optimal
control theory. It is possible to synthesize an intercept trajectory that overcomesthe problems
associated with random disturbances, measurement noise, and drift [19]. Figure P2.35
illustrates the motion of such a torpedo in the yaw axis. If it is assumed that the optimal
Figure P2.35
intercept trajectory is a straight line, then the usual small-angle assumptions are reasonably
accurate and the problem can be treated by linear techniques. The following equations
describe yaw acceleration, 6, side-slip effects, </>, and the command input, <5C, for the finless
torpedo:
Mj> + Y^ + (Yr- + Ys6 = 0,
~ - Nr6 - N6d = 0,
t'd = -6 + <5C.
The value t' is a normalized time parameter. Since the problem has been presented on the
assumption that only small perturbations are being considered, no bounds need to be placed
on Sc. Determine the vector equation for this system with the coefficients, normalized with,4 Mathematical Techniques for the Control Engineer
respect to ship length, defined as follows:
Afj = longitudinal virtual mass coefficient = 1.56
M2 = lateral virtual mass coefficient = 2.92
Z2 = virtual moment of inertia coefficient = 0.138
= static side force rate coefficient = 0.60
= static yaw moment rate coefficient = 0.99
Yr = damping force rate coefficient = 0.20
Nt = damping moment rate coefficient = —0.08
Ys = rudder force rate coefficient =0.10
Ns = rudder moment rate coefficient = Yscr = —0.50
eR = dimensionless coordinate of rudder side force = —0.50.
2.36 Given
2 4"
1 1
2 2-
and B
"2 4 2'
2 1 1
-4 2 4-
determine AB1.
2.37 How can the characteristic equation of the control system illustrated in Fig. P2.37 be
determined utilizing matrix techniques?
Figure P2.37
2.38 Determine the vector equation for an open-loop system where
C(s) 1
R(s) s2(s + 10) ‘
2.39 Repeat Problem 2.38 with
C(s) 1
R(s) s(s + l)(s + 8) ‘
2.40 Repeat Problem 2.38 with
C(s) 5
R(s) s(s2 + 4s + 2) ’
2.41 Determine the state-variable diagram and the vector equation for the following open￾loop system:
P(J) = = * + 1
t/(s) s(s2 + 7s + 1) ’
2.42 The automatic depth control of a submarine is an interesting control problem. Figure
P2.42(a) illustrates a representative problem, where the actual depth of the submarine isProblems 95
denoted as C. In practice, the actual depth of a submarine is measured by a pressure trans￾ducer. This measurement is then compared with the desired depth, R. Any differences are
amplified in a control system which appropriately adjusts the stem plane actuator angle 0.
An equivalent block diagram of such a system is illustrated in Fig. P2.42(b). Determine
the state-variable signal-flow diagram and the vector equation for this system.
(b)
Figure P2.42
2.43 Determine analytically the transition matrix of the system considered in Problem 2.41.
2.44 Determine the transition matrix ofthe following open-loop control system analytically:
P(j) =
Cfr) 1
U(s) s(s + 2)(s + 5) '
2.45 Repeat Problem 2.44 with
P(s) =
C(s) _ 1
U(s) s2(s 4- 6)(s -4-10)"
2.46 A nuclear reactor has been operating in equilibrium for a long period of time at a
high thermal-neutron flux level, and is suddenly shut down. At shut-down, the density of96 Mathematical Techniques for the Control Engineer
iodine 135 (I) is 5 x 1016 atoms per unit volume and that of xenon 135 (X) is 2 x 1015 atoms
per unit volume. The equations of decay are given by the following state equations:
I = -0.11, X = —I — 0.05X.
a) Determine the transition matrix.
b) Determine the system response equations, I(/) and X(t).
c) Determine the half-life time of I 135. The unit of time for I and X is hours.
2.47 Control-system concepts have recently been applied in attempts to solve some problems
ofsociology and ofeconomics. Let us consider one such example concerned with the problem
of underdeveloped countries [20, 21], Representing the number of underdeveloped countries
by Cu, and developed countries by Cd, the state variable xt is defined as
*i = cjcd.
The state variable is an indication of the development of the countries in the world. A
second state variable x2 is used to represent the tendency towards underdevelopment. In
writing a set of dynamical equations for these state variables, it is important to recognize that
the tendency towards underdevelopment can be reduced by means of technical-assistance
programs, education, etc. However, it is interesting to note that studies indicate that the
gap between the developed and underdeveloped nations is growing, since the underdeveloped
nations tend to remain in their present state relative to the developed area [21]. It has been 
proposed that the following set ofstate equations may be used to represent this process [20]:
= —Axx — Bx2,
x2 = Cx1 — Dx2.
a) Determine the transition matrix of this system when A = 4, B = C = 1, and D = 2.
b) Determine the response of this system when xx(0) = 2 and x2(0) = 1.
2.48 Determine the transition matrix of the following open-loop control system analytically:
v 7 U{s) s\s + I)2 ’
2.49 The effectiveness of a mass-marketing campaign to sell a product can be predicted
by analyzing its state-equation representation using control techniques. Consider the
promotion of a new automobile in a city by the mass media including television, radio,
newspapers, and periodicals. Consider the population under study to be made up of the
following three groups:
X, represents the group who might be receptive to the automobile;
x2 represents the group who buys the automobile;
x3 represents the group removed from groups and ,r2 due to death or other factors
that cause them to be isolated or removed from the groups x, and x2.
The rate at which new receptives are added to the population is equal to ut, and the rate
at which new buyers are added to the population is equal to u2. The model of this systemProblems 97
can be represented by the following set of equations:
X! = -mXi - nx2 + W],
x2 — nxy — px2 + u2,
x3 = mx, + px2.
Assume a closed population model (tq = u2 = 0).
a) Determine the transition matrix of this system when m = 4, n = 2, and p = 1.
b) Forecast how well the automobile will sell and whether the marketing campaign will
be successful by determining the response ofx2(r) ofthis system for the following initial
conditions: X](0) = 100,000; x2(0) = 20,000; x3(0) = 2,000. What conclusions can you
reach from your results?
2.50 Control techniques are being utilized to solve problems in the aquatic systems field.
These ecological problems require a mathematical model to provide an understanding of
the characteristics within the system. An aquatic ecosystem model [27] for Lago Pond, a
Georgia farm pond, has been developed. This pond is a man-made pond created by an 
earth-fill dam and is used for sport fishing. The pond is fertilized in the spring and
periodically throughout the summer in order to cause algal blooms; this increase in primary
productivity travels up the food chain and causes an increase in the fish population. A
constant coefficient model of Lago Pond, which assumes a constant temperature environ￾ment, is given by the following set of equations:
x, = —3O.8xi + 616 + 200 sin 0.524/
x2 = 2.13xi _ 17.4x2 + 0.0458x9 .
x3 = 1.67x( — 8.66x3 + 0.0553x9
x, = 0.457x2 + 0.553x3 — 0.94 lx( -I- 0.148r6
x5 = 0.0925x3 + 0.0814x4 - 0.349x5 + 0.00224x6
x6 = 5.97x2 - 1.94x6
x7 = 0.346x2 + 2.73x3 + 0.0193x6 - 0.314x7 -I- 0.23
Xg = 0.0898x4 + 0.0166x3 + 0.0166r7 - 0.104x8
x9 = 13.5x, + 5.45x2 + 4.23x3 + 0.213x4 + 0.0703x5 + 0.382x6 + 0.0628x7 + 0.0207x8
— 0.816x9
The states x4, x5, x6, and x7 represent the levels of redbreast, warmouth, chaoborus,
and bluegill sunfish in the lake; the state x8 represents the level of bass in the lake. States
x,, x>, and x3 represent nutrient factors for the fish as a result of pond fertilization, and
state x9 represents detritus (rocks and other small material worn or broken away from a
mass due to the action of water).
a) Determine the companion matrix P, and Bu, for the vector equation of the system:
x = Px + Bu.98 Mathematical Techniques for the Control Engineer
b) (optional) Simulate this constant coefficient model of Lago Pond on a digital computer,
and determine the time responses of the states for 12 months using the algorithm given
in Section 2.18 (see Eq. 2.236). Assume the following initial conditions for the nine
states (units are in Kcal/m2): x, = 20; x, = 3.5; x3 = 6.4; x4 = 7.16; x5 = 3.44; x6 =
10.8; x7 = 61; xB = 16.5; x9 = 400. What conclusions can you reach from your results?
2.51 A very interesting ecological problem is that of rabbits and foxes in a controlled
environment. If the number of rabbits were left alone, they would grow indefinitely until
the food supply was exhausted. Representing the number of rabbits by xt, their growth
rate is given by
x, = Axt.
However, rabbit-eating foxes in the environment change this relationship to the following:
x, = Ax — Bx>
where x2 represents the fox population. In addition, if foxes must have rabbits to exist,
then their growth rate is given by
x2 = -Cx, + £>x,
a) Assume that A = 1, B = 2, C = 2, and D = 4. Determine the transition matrix for this
ecological model.
b) From the transition matrix, determine the response of this ecological model when
x,(0) = 100 and x2(0) = 50. Explain your results.
2.52 (28] A very important ecological control problem is the treatment of wastes in water.
Control engineers are attempting to solve this problem by adding bacteria, which grow by
using the pollutant as a nutrient, to the waste flow. In this manner, wastes in sewage
treatment plants can be eliminated by this natural biological process. Microbial growth
models currently being used to analyze this kind of problem are based on differential
equations. Defining x as the bacteria concentration required for pollutant removal, s as
the pollutant serving as the nutrient substance for the bacteria, and D as the rate of
flow/volume (dilution rate), the normalized material balance equations can be approxi￾mated by the following two state equations:
x = ux - Dx,
s = — ux — Ds.
a) Assuming that the specific growth rate u is a constant, determine the transition matrix
of this ecological control system.
b) Analyze the meaning of the transition matrix obtained for this problem. Under what
conditions does a balance exist in this ecological control system?
REFERENCES
1. R. V. Churchill, Modern Operational Mathematics in Engineering McGraw-Hill New
York (1944).References 99
2. M. F. Gardner and J. L. Barnes, Transients in Linear Systems, Vol. 1, Wiley, New York
(1942).
3. S. J. Mason, “Feedback theory: Some properties ofsignal flow graphs,” Proc. IRE 41,
1144 (1953).
4. S. J. Mason, “Feedback theory: Further properties of signal flow graphs,” Proc. IRE44,
920 (1956).
5. F. E. Horn, Elementary Matrix Algebra (2nd Edn.) Macmillan, New York (1964).
6. C. A. Desoer, “An introduction to state space techniquesin linearsystems,” in Proceedings
ofthe 1962 Joint Automatic Control Conference, New York, pp. 10-2-1 to 10-2-5.
7. L. A. Zadeh, “An introduction to state-space techniques,” in Proceedings of the 1962
Joint Automatic Control Conference, New York, pp. 10-1-1 to 10-1-5.
8. G. Leitmann (Ed.), Optimization Techniques, Academic, New York (1962).
9. P. DeRusso, R. J. Roy, and C. M. Close, State Variablesfor Engineers, Wiley, New York
(1967).
10. B. C. Kuo, “State transition flow graphs of continuous and sampled dynamic systems,”
in Proceedings ofthe 1962 Western Electronic Show and Convention, August 21-24, 1962,
Los Angeles.
11. D. K. Faddeev and V. N. Faddeeva, Computational Methods ofLinear Algebra, Freeman,
San Francisco (1963).
12. B. S. Morgan, Jr., “Sensitivity analysis and synthesis of multivariable systems,” IEEE
Trans. Automatic Control 11, 506-12 (1966). ,
13. M. I. Liou, “A novel method of evaluating transient response,” Proc. IEEE 54, 20-23
(1966).
14. B. O. Watkins, Introduction to ControlSystems, Macmillan, New York (1969), pp. 258-9.
15. R. Bellman, Stability Theory ofDifferential Equations, McGraw-Hill, New York (1953),
pp. 12-13.
16. W. T. Thomson, Laplace Transformation, Theory andEngineering Applications, Prentice￾Hall, Englewood Cliffs, N.J. (1950).
17. J. S. Meditch, “On the problem of optimal thrust programming for a lunarsoft landing,”
IEEE Trans. Automatic Control AC-9, 477-84 (1964).
18. F. J. Ellert and C. W. Merriam, III, “Synthesis offeedback controls using optimization
theory—An example,” in Proceedings of the 1962 Joint Automatic Control Conference,
p. 19-1.
19. N. W. Rees, “An application of optimal control theory to the guided torpedo problem,”
in Proceedings ofthe 1968 Joint Automatic Control Conference, pp. 820-25.
20. R. C. Dorf, Modern Control Systems, Addison-Wesley Publishing Company, Reading,
Mass. (1967), pp. 292-94.
21. D. Rockefeller, “The population problem and economic progress,” Vital Speeches 32,
366-70 (1966).
22. L. A. Zadeh and C. A. Desoer, Linear System Theory—The State Space Approach,
McGraw-Hill, New York (1963).
23. G. A. Korn and T. M. Korn, Electronic Analog and Hybrid Computers, McGraw-Hill,
New York (1964).
24. R. W. Hamming, Numerical Methodsfor Scientists and Engineers, McGraw-Hill, New
York (1962).
25. D. D. McCracken and W. S. Dorn, Numerical Methods and FQRTRAN Programming,
Wiley, New York (1964).100 Mathematical Techniques for the Control Engineer
26. H. H. Rosenbrick and C. Storey, Computational Techniques for Chemical Engineers,
Pergamon, Oxford (1966).
27. W. R. Emanuel and R. J. Mulholland, “Energy Based Dynamic Model for Lago
Pond, Georgia,” in Proceedings ofthe 1974 Joint Automatic Control Conference, pp.
354-62.
28. G. D’Ans, P. W. Kotovic, and D. Gottlieb, “A Nonlinear Regulator Problem for a
Model of Biological Water Treatment,” IEEE Trans. Automatic Control AC-16,
341-47 (1971).3
STATE EQUATIONS AND
TRANSFER-FUNCTION
REPRESENTATION OF PHYSICAL
LINEAR CONTROL-SYSTEM
ELEMENTS
3.1 INTRODUCTION
The purpose of this chapter is to illustrate the procedures used for deriving the state
equations and transfer-function representation for several common linear control￾system elements. This is a very important step that must be mastered before consider￾ing the determination of performance and stability ofvarious kinds ofcontrol systems.
In general, the devices that are encountered can be classified as being electrical,
mechanical, electromechanical, hydraulic, thermal, etc. The emphasis here will be
to describe the state equations and transfer functions for linear control system
elements that are representative of these classes. Nonlinear devices are discussed in
Chapter 8 on Nonlinear Feedback Control-System Design.
3.2 STATE EQUATIONS OF ELECTRICAL NETWORKS
Before introducing the techniques for formulating the state equations and transfer￾function representation of some common linear control-system devices, the subject
of electrical networks is considered [1]. Specifically, it is the purpose of this section
to illustrate how the engineer can represent the state equations of electrical networks
[2]. The very same method is applicable to the analysis of control-system devices.
Network equations of electrical circuits can be formulated from the basic laws of
Kirchhoff. It is assumed that the reader is familiar with the corresponding loop and
nodal techniques for analyzing electrical networks [1],
The loop equation of the basic RLC circuit illustrated in Fig. 3.1 is given by
e(t) = 7?i(t) + + - fi(t) dt.
dt C j
(3-1)
Fig. 3.1 An RLC circuit.
101102 State Equations and Transfer-function Representations 3.2
The current in the inductor and the voltage across the capacitor are usually considered
to be the state variables of a network. Then the resulting state equations for this
circuit can be formulated by relating the voltage across the inductor L and the Current
in the capacitor C as follows:
= e(t) - ec(t) - Ri(t), (3-2)
dt
i(,) = cfeW. (33)
v dt
Defining the state variables as
= ec(t), (3-4)
x2 = i(t), (3-5)
the following state equations of the circuit are obtained:
Xj =
These equations can be written in vector form as
x = Px + Br,
where
x =
1_ _ R
L L.
(3.6)
(3-7)
(3.8)
B = r = e(0.
0
£
L
As a second example, consider the electrical network of Fig. 3.2. The state
equations are obtained by writing the equation for the currents in the capacitors and
/?, L,
Fig. 3.2 An electrical network.3.2 State Equations cf Electrical Networks 103
the voltage across the inductors as follows:
h(t) - i2(t) = Cd-^,
dt
L1 = ~ Rli1^ ~ Sc^’
at
L
T 2 —— = ec(t).
dt
If the state variables are defined as
Xi = ec(t),
x2
= f/O,
X3 = i2(t),
the following state equations for this electrical network are obtained:
1 1 — x, — —
c 2 c 3
1 R1 , 1 / X “ — - — x2 + — e(t), M Li Lt
T2
These equations can be written in vector form as
x = Px + Br,
where
0
x2
-X3-
P =
■3-1 1
T2
1_
c
__Ri
0
c
0
0
B =
0
1
~Li
0
(3.9)
(3.10)
(3-11)
(3.12)
(3.13)
(3.14)
(3.15)
(3.16)
(3.17)
(3.18)
r = e(t).
These simple examples illustrate the general method for analyzing electrical
networks utilizing the state-space technique. The reader is referred to Reference 2
for a more detailed discussion of this particular subject. The same general method is
illustrated next for the analysis of commonly used linear control-system devices.104 State Equations and Transfer-function Representations 3.3
3.3 TRANSFER-FUNCTION AND STATE-SPACE
REPRESENTATION OF TYPICAL MECHANICAL CONTROL-SYSTEM DEVICES
Mechanical control-system devices can generally be classified as being either transla￾tional or rotational. The major difference between the two is that we talk of forces
and translational units in the former, and torque and angular units in the latter.
Newton’s three laws of motion [3] govern the action of both types of mechanical
system. Basically, these laws state that the sum ofthe applied forces, or torques, must
equal the sum ofthe reactive forces, or torques, for a body whose acceleration is zero.
Another way ofstating this is that the sum of the forces must equal zero for a body at
rest or moving at a constant velocity. We shall consider some representative transla￾tional systems and then some rotational systems. The basic concepts illustrated and
developed here should be sufficient to enable the reader to handle more complex
systems.
1. Mechanical Translation Systems The three basic characteristics of a mechanical
translational system are mass, stiffness, and damping. Mass represents an element
having inertia. Stiffness represents the restoring force action such as that of a spring.
Damping, or viscous friction, represents a characteristic of an element that absorbs
energy. We use the English system of units as our standard. The symbols for the
various quantities together with their respective units are shown in Table 3.1.
Table 3.1 Mechanical translation symbols and
units
Quantity Symbol English units
Distance y ft
Velocity V ft/sec
Acceleration a ft/sec2
Force f
lb
Mass M slugs
Damping factor B lb/(ft/sec)
Stiffness factor K Ib/ft
a) Force Applied to a Mechanical System Containing a Mass, Spring, and Damper.
The case of a force f(t) applied to a mass, spring, and damper is shown in Fig. 3.3.
The system produces a displacement of the mass, y(t), measured from a reference
terminal, j0, which is assumed to be stationary. The application of Newton’s law to
this system yields
+ + Ky =
dt dt (3-19)3.3 Transfer-function Representation of Typical Mechanical Control-system Devices 105
This second-order differential equation can be written as two first-order differential
equations by defining
*1 = y (3.20)
and
x2 = y (3.21)
The resulting state equations are given by
Xj = x2, (3.22)
x2 = - “ *1 - t; x2 + 7-/(1). (3.23)
Fig. 3.3 Force applied to a system containing a spring, a mass, and a damper.
In vector form, these equations become
x = Px + Br,
y = Lx,
(3.24)
(3.25)
where
'2
r
M.
’0"
r = /(l), L = [1 0],
Assuming the system is initially at rest, the transfer function of this mechanical
translation system, defined as the ratio of the output T(s) divided by the input £(5).
x P =
0
M
B =106 State Equations and Transfer-function Representations 3.3
is readily found to be
y(s) =___________i/M__________
F(s) ~ s2 + + K/M ’
(3.26)
and its simple block diagram appears in Fig. 3.4.
Fig. 3.4 Block diagram for the spring-mass-damper system.
b) Force Applied to a Complex Mechanical System. Consider next the complex
mechanical system illustrated in Fig. 3.5. A force/(/)is applied to a mass, spring, and
damper which in turn applies a force to another mass, spring, and damper. Mass M2
is displaced a distance y2(t), and mass is displaced a distance y^t). In order to
apply Newton’s laws to this system, it is advantageous to first separate the mechanical
system into a set of free-body diagrams as illustrated in Fig. 3.6. Newton’s equations
for this resulting system are given by
n0=Br2~—-
^i(0l , „ r . . ... — + ^2[f2(0 ~ Tl(0] L dt dt J
Fig. 3.5 A mechanical system.3.3 Transfer-function Representation of Typical Mechanical Control-system Devices 107
Fig. 3.6 Free-body diagram for the system illustrated in Fig. 3.5.
These two second-order differential equations can be transformed into four first-order
differential equations by defining
* i = >’1(0,
* 2 = >2(0,
_ <h(0
* 3 — .
dt
A'2(0
dt
(3.29)
(3.30)
(3.31)
(3.32)
The resulting state equations are given by
A — *3> (3.33)
A = x4, (3.34)
A = - — (Kx + k2)X1 + — x, 3 M/1 Mi
- 77 (Bl + B2)x3 + x4, Mj Mj
(3.35)
k2 k2 B2 B2 f(t)
m2 m2 m2 m2 m2
(3.36)
In vector form, these equations become
x = Px + Br, (3.37)
y = Lx, (3.38)108 State Equations and Transfer-function Representations 3.3
where
0 0 1 0
0 0 0 1
1 k2
1 b2
p = - — (Ki + K2)
Mi Mj Mi
_K^ b2 b2 ■ ' m2 m2 m2 m2_
0
0
0
1_
M2
Pl 0 0 0"|
[0 1 0 oj’ r =/(0,
2. Mechanical Rotational Systems The three basic characteristics of a mechanical
rotational system are moment of inertia, stiffness, and damping. Rotational systems
are quite similar to translational systems except that torque equations are used to
describe system equilibrium instead of force equations, and we use angular displace￾ment, velocity, and acceleration quantities. The symbols for the various quantities
and their respective units are shown in Table 3.2.
Table 3.2 Mechanical rotation symbols and units
Quantity Symbol English units
Angle e radians (rad)
Angular velocity CO rad/sec
Angular acceleration a rad/sec2
Torque T lb ft
Moment of inertia J lb ft sec2
Damping factor B lb ft/(rad/sec)
Stiffness factor K lb ft/rad
a) Torque Applied to a Body Having a Moment of Inertia, a Twisting Shaft, and a
Damping Device. The configuration of a torque T(f) applied to a body having a
moment of inertia J, a twisting shaft having a stiffness factor K, and a damper having3.4 Transfer-function Representation of Typical Electrical Control-system Devices 109
a damping factor B, is shown in Fig. 3.7.
measured from an equilibrium position 0O,
end of the damping device is assumed to
this system yields
The system produces a displacement, 0(r),
which is assumed to be zero. The reference
be stationary. Applying Newton’s law to
Td2e(t)
dt2
+ + K0(t) = T(f).
dt
(3.39)
This second-order differential equation can be written as two first-order differential
equations by defining
x. = 6(f), (3.40)
x2 = 6(f). (3.41)
Fig. 3.7 Torque applied to a moment of inertia, a twisting shaft, and a damping device.
3.4 TRANSFER-FUNCTION AND STATE-SPACE
REPRESENTATION OF TYPICAL ELECTRICAL CONTROL-SYSTEM DEVICES
The resulting state equations are given by
A = x2,
K B > 1 tva
x2 = - — Xi - J x2 4- J T(t).
(3-42)
(3.43)
In vector form, these equations become
x = Px + Br,
0 = Lx,
where
r -1 r-1 r0 1 1 r° X = X1 , i = X1 , P = K B , B = 1
(3.44)
(3.45)
W W j jJ
L = [1 0], r = T(t).
This section illustrates the procedure used for deriving the transfer function and
state-space representation of some commonly used electrical devices from their basic110 State Equations and Transfer-function Representations 3.4
differential equations. We specifically analyze a de generator, armature-controlled
de servomotor, Ward-Leonard system, field-controlled de servomotor, and a two￾phase ac induction servomotor. The analysis is limited to the linear operating range
of these devices.
1. DC Generator A de generator [4, 5] is commonly used in control systems for
power amplification. The armature, which is driven at a constant speed n, is capable
of producing a relatively large controllable current, ia, as the field current if is varied.
Fig. 3.8 DC generator schematic diagram.
The exact value of ia is dependent on the load circuit impedance, ZL. A schematic
diagram of the configuration is shown in Fig. 3.8. The symbols Rf, Lf and Rg and Lg
represent the resistive and inductive components of the field and armature circuits,
respectively.
The voltage induced in the armature, eg(t), is a function of the speed ofrotation n
and the flux developed by the field, </>. It can be expressed as
eg(t) = K^. (3.46)
The flux depends on the field current and the characteristics of the iron used in the
field. This is a linear relationship up to a certain saturation point and can be expressed
as
= K2i,. (3.47)
By substituting Eq. (3.47) into Eq. (3.46), and assuming that the armature rotation
speed is constant, the relation between the induced armature voltage eg(t) and the
field current if can be expressed as
eg(t) = Kgif, (3.48)
where Kg = KxK2n = generator constant having units of V/A. The equation relating
the field voltage ez(t), and field current zz(f), is
MO = Rfif + Lf^-. (3.49)
at3.4 Transfer-function Representation of Typical Electrical Control-system Devices 111
The held current can be eliminated between Eqs. (3.48) and (3.49) and an expression
relating ef(t) and the induced armature voltage eg(t) can be obtained.
. . Rf Lf de„(f) ~ -f2
Kg Kg dt
By transforming, there results
(3.50)
E/s) = ±(Rf + M£b(s).
A g
The transfer function of this device, defined as the ratio of the output Eu(a) to the
input Ef(s), is given by
(3.51)
Eg(s) = KglLf
Ef(s) s + Rf/Lf
and its simple block diagram is shown in Fig. 3.9.
Ef(s) Kt/Lt
s + Rj /Lf
(3-52)
Ek(s) - >
Fig. 3.9 Block diagram of a DC generator.
Ifit is desired to obtain the transfer function Ea(s)/Ef(s), we must first determine the
nature of the actual load connected to the armature. For example, assume that the
load impedance is ZL(s). Then the transfer function Ea(s)/Eg(s) becomes
Ea(s) = ZL(s)
Ea(s) Rg + Lgs + ZJs)
and the overall transfer function of the de generator, Ea(s)/Ef(s), is
Ea(s) = Eg(s)x Ea(s) = Kg/Lf ZL(s)
Ef(s) Ef(s) Eg(s) s + Rf/Lf Rg + Lgs + ZL(s) ‘
2. Armature-Controlled DC Servomotor Armature-controlled de servomotors [6] are
quite commonly used in control systems. As a matter of fact, a de generator driving
an armature-controlled de servomotor is known as the Ward-Leonard system. We
will study this configuration in the next section drawing on the relations derived for
the de generator and armature-controlled de servomotor.
A schematic diagram of the armature-controlled de servomotor is shown in
Fig. 3.10(a). The symbols Rm and Lm represent the resistive and inductive com￾ponents of the armature circuit. The field excitation is constant, being supplied from
a de source. The motor is shown driving a load having an inertia J and damping B.112 State Equations and Transfer-function Representations 3.4
(b)
(O
Fig. 3.10 (a) Armature-controlled de servomotor schematic diagram, (b) Block diagram of
an armature-controlled de motor, (c) Signal-flow diagram representation for the armature￾controlled de servomotor.
As the armature rotates, it develops an induced voltage em which is in a direction
opposite to ea(t). The induced voltage is proportional to the speed of rotation n and
the flux created by the field current. Since we are assuming that the field current is
held constant, the flux must be constant. Therefore, the induced armature voltage is
only dependent on the speed of rotation and can
_ _
Ltbe17 n expressed as
em = Ken = Ke-^ , (3.55)
where Ke — voltage constant of the motor having units of V/(rad/sec). The voltage
equation of the armature circuit is
ea(0 — 7?mia + Lm —- + em.
at
(3.56)3.4 Transfer-function Representation of Typical Electrical Control-system Devices 113
£0(s)
O—
0o(s)
—O
(d)
Fig. 3.10 (d) Modification of the signal-flow diagram to a more compact form, (e) Analog
computer circuit simulation for an armature-controlled de servomotor.
Substituting Eq. (3.55) into Eq. (3.56) and taking the Laplace transform, we obtain
Eo(y) = (Rm + Lms)Ia(s) + Kes0o(s). (3.57)
The developed torque of the motor, TD, is a function of the flux developed by the
field current, the armature current, and the length and number of the conductors.
Since we are assuming that the field current is held constant, the developed torque
TD can be expressed as
Td = KTia (3.58)
where KT = torque constant of the motor having units of lb ft/A. * The developed
torque drives the mechanical load and the torque equation is
* The torque constant is a very important characteristic of de motors.
Tn = J^ + B^. (3.59)
Substituting Eq. (3.58) into Eq. (3.59) and taking the Laplace transform, we obtain
KTIa(s) = (Js2 + Bs)0o(s). (3.60)114 State Equations and Transfer-function Representations 3.4
The overall system transfer function O0(s)/Ea(s) obtained by eliminating Ia(s) between
Eqs. (3.57) and (3.60) is
= ------------------------------Lz----------------------------- . (3.61)
Ea(s) JLms3 + (RmJ + LmB)s2 + (RmB + KeKT)s
Equation (3.61) can be defined in terms of an armature time constant Ta, a motor
time constant Tm, and a damping factor y, as follows:
where
e0(s) =_______________i/Ke______________
Ea(s) . s[TaTms2 + (Tm + yT„)s + (y + 1)]
T = La T = JRm = RmB
a Rm ’ m KeKT ’ 7 KeKT ‘
(3.62)
(3.63)
The simple block diagram of this system is illustrated in Fig. 3.10(b).
The state-space model can be derived directly for the armature-controlled de
servomotor from the original set of defining scalar equations, (3.55), (3.56),
(3.58), and (3.59). Defining the state variables as
Xi = 0O, (3.64)
' x2 = 0O, (3.65)
x3 = ia, (3.66)
the resulting state equations are given by
X'l = x2, (3-67)
N
II
1
1to
to*"
4*
w
(3.68)
II
1 r i *
to
+ r i ­
a
(3-69)
In vector form, these equations become
x = Px + Br,
C = Lx,
(3.70)
(3.71)
where
C =
B -=3.4 Transfer-function Representation of Typical Electrical Control-system Devices 115
It is usually quite interesting and revealing to study the signal-flow diagram for such
a device, especially for purposes of analog-computer simulation. The governing
equations from which the signal-flow diagram can be drawn for the armature￾controlled de servomotor are given by
s (Js 4- B)
= Kes60(s) [from Eq. (3.55)] (3-72)
_ Ea(s) - Em(s)
[from Eq. (3.56)] ' (3.73)
Td(s) = KTIa(s) [from Eq. (3.58)] (3-74)
0o(s) = - ; Td(S\ .
[from Eq. (3.59)] (3.75)
The signal-flow diagram is illustrated in Fig. 3.10(c). It clearly illustrates the inherent
feedback (back electromotive force) ofthis device. This property is sometimes used to
stabilize a feedback control system (see Problem 3.8). It is left as an exercise to the
reader to prove that the transfer function of this system, as derived from the signal￾flow diagram, agrees with Eqs. (3.62) and (3.63), and that the state equations derived
from the state-variable diagram agree with Eqs. (3.70) and (3.71) (see Problem 3.21).
Since the signal-flow graphs represent the mathematical structure of a system,
they represent a type of basic analog. Likewise, an analog computer may be thought
of as the physical realization of a signal-flow graph. However, any arbitrary signal￾flow graph is not necessarily a suitable representation as the program for an analog
computer. This is usually due to the fact that the control engineer avoids simulating
differentiations which have wide bandwidths and associated noise problems. For the
case of the armature-controlled de servomotor, the signal-flow diagram of Fig. 3.10(c)
is modified to a more compact form in Fig. 3.10(d) which is more appropriate for
analog simulation. The analog-computer simulation circuitry is shown in Fig.
3.10(e) [16, 17].
3. The Ward-Leonard System A configuration having a de generator driving
an armature-controlled de motor is known as a Ward-Leonard system [7, 8]. The
de generator acts as a rotating power amplifier that supplies the power which, in turn,
drives the servomotor. Variations of the conventional Ward-Leonard system are
known as the Amplidyne, the Metadyne, the Rotorol, and the Regulex. The reader
is referred to more authoritative books on de machinery [7] for a description of these
devices.
A schematic diagram of the basic Ward-Leonard system is shown in Fig. 3.11.
The notations used are the same as those of Figs. 3.8 and 3.10. Many sophisticated
variations of this basic configuration, using compensating windings, exist [8].
To enable us to combine the transfer-function relationships derived previously
for the de generator and armature-controlled de motor, we assume that the generator
voltage e„(t) is applied directly to the armature of the motor. Therefore, we are116 State Equations and Transfer-function Representations 3.4
Fig. 3.11 Ward-Leonard system schematic diagram.
interested in applying the generator Eq. (3.52) rather than (3.54). In order to apply
the motor transfer function (3.62), we must first combine the resistive and inductive
components ofthe generator’s and motor’s armatures. This will result in a set of new,
modified motor constants as follows:
, (Rg + Rm)B Lg + Lm J(Rg + Rm)
V — ---------------- > J a =------------ , m = ------------------ • (3.76) KeKT a Rg + Rm m KeKT
Therefore, Eq. (3.62) may be written as follows in this case:
=----------- ;------------. (3.77) sinn? + (r; + r'T^ + (?■ + ») ' ’
It is now relatively simple to obtain the transfer-function representation of the
configuration shown in Fig. 3.11. Defining ey(f) as the input and 0o(t) as the output of
the system, we need merely to combine the transfer functions given by Eqs. (3.52) and
(3.77). Therefore, the system transfer function is given by
W = KaILf__________________ 1/Ke________________
Ef(s) s + Rf/Lf s[T„T'ms2 + (T'm + y'T^s + (/ + 1)] k ’
and its simple block diagram is illustrated in Fig. 3.12. .
z., Ke
s(s+^-)[TaTmS2+(Tm+YT')s+(y+l)]
»o(s) —>
Fig. 3.12 Block diagram of the Ward-Leonard system.3.4 Transfer-function Representation of Typical Electrical Control-system Devices 117
4. Field-Controlled DC Servomotor A de servomotor [9] can also be controlled by
varying the field current and maintaining a constant armature current. The schematic
diagram of such a configuration, known as the field-controlled de servomotor, is
shown in Figure 3.13. The notations are the same as those of Fig. 3.10.
Fig. 3.13 Field-controlled de servomotor schematic diagram.
The developed torque of the motor, TD, is a function of the flux developed by the
armature current, the field current, and the length of the conductors. Since we are
assuming that the armature current is held constant, the developed torque TD can
be expressed as
Td = KTif (3.79)
where KT = torque constant of the motor having units of lb ft/A. The developed
torque is used to drive the mechanical load with inertia J and damping B. The torque
equation is
TD = + Bp (3-80)
dt2 dt
Substituting Eq. (3.79) into Eq. (3.80), we obtain a differential equation relating the
field current and the output shaft position:
J d20o + _B_d6o
Kt dt2 Kt dt
(3.81)
An expression for the value ofthe field current i} can be obtained from the voltage
equation of the field circuit.
ez(t) = Rfif + Lf—j .
dt
(3-82)118 State Equations and Transfer-function Representations 3.4
Substituting Eq. (3.81) into Eq. (3.82) and taking the Laplace transform, we obtain
(3.83)
The transfer function of the device, defined as the output 60(s) divided by the input
Ef(s), is given by
where
W = KT/RfB
E,(s) 5(1 4- T/S)(l + Tms) ’
(3.84)
T, = — = field time constant,
Tm = — = motor time constant.
and its simple block diagram is illustrated in Fig. 3.14(a).
The governing equations from which the signal-flow diagram can be drawn for
the field-controlled de servomotor are given by
s Js -f- B
/,( *) = -------
Rf + Lfs
[from Eq. (3.82)] (3-85)
TD(s) = KTIf(s) [from Eq. (3.79)] (3.86)
1 Td(s)
^o(s) — „ [from Eq. (3.80)] (3.87)
o------------- >-------------o--- -
(b)
Fig. 3.14 (a) Block diagram of a field-controlled de servomotor, (b) Signal-flow diagram
representation for the field-controlled de servomotor.
The simple signal-flow diagram ofthis device, useful for analog computer simulations,
is illustrated in Fig. 3.14(b).
E/(s) KT/R,B
s (i + t, 5) (i + r,„s)
1
E,{s) (R,+ L,s) f,(s)
2
5 «O(S)
---------- -o
1
(Js + B) s»0(s)
----- >-------------- o
A T TD( S )
->--------------o3.4 Transfer-function Representation of Typical Electrical Control-system Devices 119
The state-space representation of the field-controlled de servomotor can be
obtained either by starting from the defining scalar equations, (3.81) and (3.82), or
by utilizing the resultant transfer function derived in Eq. (3.84). The first method is
usually preferable. However, since the first method was utilized in the case of the
armature-controlled de servomotor, the second method is utilized here for the field￾controlled de servomotor to permit comparison of the two approaches.
Equation (3.84) can be written in differential-equation form as follows:
where
d30o(O T . ^o(D ^o(D kt
T,T„ +(T, I TJ R Be,W. (3.88)
This third-order differential equation can be written as three first-order differential
equations by defining
*i = eo(')> (3.89)
x2 = 60(t), (3.90)
x3 = 6*o(O- (3.91)
The resulting state equations are given by
A = x2, (3-92)
x2 = x3, (3.93)
1 (T, + Tm) Kt
A
(3.94) q ■—
TfTm
-^2 " '
TfTm *^3 I
RfBTfTm
In vector form, these equations become
x = Px + Br, (3.95)
e0 = Lx, (3.96)
*i
x2
-X3.
X1
x2
-X3-
ro 1 0 ' 0 ‘
o 0 1 0
P =
0
1 (T, + Tm)
, B =
kt
TfTm
TfTm J
-R/BTfTm￾L = [1 0 0], r =
Notice that the resultant vector equation has eliminated the field current. This is a
measurable state and it is preferable to retain it in the state-space model. If the state￾space representation had proceeded from the defining scalar equations, (3.81) and
(3.82), then the field current would have been retained—just as the armature current
was retained as a state in the case of the armature-controlled de servomotor (see
Eq. 3.66).120 State Equations and Transfer-function Representations 3.4
5. Two-Phase AC Servomotor The two-phase ac servomotor [10-12] is probably
the most commonly used type of servomotor. Its popularity stems from the fact that
many error-sensing devices are carrier-frequency (ac) devices. By using two-phase ac
servomotors, demodulation need not be performed and ac amplification can be used
throughout the electrical portion of the system.
Fig. 3.15 Two-phase ac servomotor schematic diagram.
The ac servomotor is a two-phase induction motor having its two stator coils
separated by 90 electrical degrees with a high resistance rotor. A control signal is
applied to one phase (the control winding) while the other phase (the reference
winding) is supplied with a fixed signal that is phase-shifted by 90° relative to the
control signal. The motor is used primarily for relatively low-power applications.
A schematic diagram of an ac servomotor driving a load of inertia J and damping B
is shown in Fig. 3.15. The reference field voltage is denoted as eT(t) and the control
field voltage is denoted as ec(f). The developed torque ofthis motor is proportional to
cr(r), ec(z), and the sine of the angle between er(t) and ec(t).
As the control voltage is varied, the torque TD and speed n vary. A set of
torque-speed curves for various values of control voltage are shown in Fig. 3.16.
Notice that these curves show a very large torque for zero speed which is desirable in 
developing a very rapid acceleration.
Unfortunately, the torque-speed curves are not straight lines. Therefore we
cannot write a linear differential equation to represent them. However, by linearizing
these characteristics, reasonable accuracy can be achieved. * Since the developed
torque TD is a function of the speed n and the control voltage ec(t), we use a Taylor
* The subject of linearizing approximations is discussed from a more general viewpoint in
Section 8.6.3.4 Transfer-function Representation of Typical Electrical Control-system Devices 121
Fig. 3.16 Two-phase ac servomotor torque-speed characteristics.
series expansion of the nonlinear function TD — TD(n, ec) to get an approximate
linear function:
~ec(t) = TD(n, ec). (3.97)
on oec
By defining
= Ke, = K„ (where Kn is a negative number)
dec dn
and substituting n = d0o/dt, we can rewrite Eq. (3.97) as
(3.98)
(3.99)
K dG< Knlt
The developed torque is used to drive the mechanical load and the torque equation is
d2Q0 d9e
T» = J -T + 3 -T dr dt
Substituting Eq. (3.99) into Eq. (3.98) and taking the Laplace transform, we obtain
Kns0o(s) + KeEc(s) = Js20o(s) + Bse0(s). (3.100)
The transfer function of the device, defined as the output 0o(s) divided by the input
Ec(s), is given by
0<)(S) =
Ec(s) s(Tms + 1)’
(3.101)122 State Equations and Transfer-function Representations 3.4
where
K,„ =------ -— = motor constant,
B - K„
T,„ = —----- = motor time constant,
B - Kn
and its simple block diagram is illustrated in Fig. 3.17. Although the torque-speed
characteristics are nonlinear, as illustrated in Fig. 3.16, the value of Kn is usually
obtained graphically by drawing a straight line through the two end points. The
s ( T,„s + 1)
90(s>
----->
Fig. 3.17 Block diagram of a two-phase ac servomotor.
accuracy of this approach, compared with drawing a line tangent to the curve at
various other points, is analyzed further in Section 8.6 (see Problem 8.1).
Equation (3.101) can be written in differential-equation form as follows:
, d2on(t) de0(t)
m , , + ~— — KM!)- dr dt (3.102)
This second-order differential equation can be written as two first-order differential .
equations by defining
--= 90('). (3.103)
x2= (3.104)
The resulting state equations are given by
■Vi = x2, (3.105)
X2 = ~ ~~ ec(t). (3.106)
* m •" m
In vector form, these equations become
x = Px + B/, (3.107)
eo = Lx, (3.108)
where
L = [1 0], r = ec(t).3.4 Transfer-function Representation of Typical Electrical Control-system Devices 123
It is left as an exercise to the reader to prove that the state equations derived from
the state-variable diagram agree with Eqs. (3.107) and (3.108) (see Problem 3.23).
6. Servomotors with Gear Reducers The two-phase ac servomotor is inherently a
high-speed, low-torque device. In control-system practice, however, what is usually
needed is a low-speed, high-torque device. Therefore, a gear reduction is usually
required between the high-speed, low-torque servomotor and the load to obtain speed
reduction and torque magnification.
Fig. 3.18 Servomotor geared to load.
In order to analyze the modifications necessary to the transfer function derived
in Eq. (3.101), let us consider the configuration illustrated in Fig. 3.18. The sub￾subscripts m and I are used to denote motor and load shafts, respectively. It is
assumed initially that the inertias of the gears are negligible, the efficiency of trans￾mission is perfect, and there is only one gear mesh between the load and the motor.
It is also assumed that a servomotor and gear train have been selected which will
provide the required torque to obtain the desired acceleration, and to drive the load
at the maximum required speed. Basically what is desired is a set of relationships to
include the effect of the gear reduction and the load inertia.
There are basically two approaches to the problem. In one method, the
parameters Kn , KCm, and Jm are reflected to the output shaft, 0(. Another manner
ofsolving the problem is to reflect the load inertia to the motor shaft. Both methods
will be illustrated here, and it will be shown that they are equivalent.
Let us first consider the reflection of the parameters K„n, Kem, and Jm to the
output shaft, K„m is the ratio of motor torque to motor speed and the value of
A'„m is given by
Kn = (3.109)
nm dn124 State Equations and Transfer-function Representations 3.4
Since the driving torque at the load is multiplied by the gear reduction factor N, and
the motor speed is reduced by this factor at the load shaft, the following relationship
is obtained:
Kni = — = N2K , (3.110)
1 1//V dn
where Kn denotes Kn referred to the load shaft.
The parameter K is the ratio of motor torque to control voltage. Since the
driving torque ofthe load is multiplied by the gear reduction factor N, and the control
voltage ec is independent of N,
Kei = NKem, (3.111)
where Ke indicates the value of Ke at the motor shaft and Ke denotes its value
referred to the load shaft. The effect of the motor inertia at the load shaft can be
obtained by considering the conservation of energy equation:
= (3.112)
where Jmr denotes the value of the motor inertia referred to the output shaft.
On substitution, the following is obtained:
Therefore,
J,nr=JmN2. (3.114)
This relationship indicates that the motor inertia referred to the output shaft is
amplified by a factor of TV2. This factor must be added to the load inertia, JL, in
order to obtain the total output inertia:
Ztota^ — + JL￾Based on these relationships, the values of Km and Tm for the overall combination of
servomotor, gear train and load inertia can now be obtained. To do this, it is
assumed that the damping factor B in Eq. (3.101) is zero (it is usually negligible
compared with the motor damping Kn):
„ 1
w'“ -N2K„m “ N m’ (3H5)
where /^denotes the value of Km referred to the output shaft. This indicates that
the system gain is reduced by a factor of TV. Furthermore,
JmA/2 T Jt J r
mtotai _ N2K m N2K * (3.116)
nm nm
This indicates an increase in the servomotor time constant due to the added load
inertia. Therefore, the net effect of the gear reduction and the load inertia has been3.4 Transfer-function Representation of Typical Electrical Control-system Devices 125
to reduce Km by a factor of N, and to increase the time constant by the added term
Now let us attack the problem by referring all quantities to the motor shaft and
check the result. For this case, the only two factors that have to be considered are the
effect of the gear reduction N and the load inertia JL. As we have just observed, the
effect of the gear reduction N is basically a loss in system gain N. Therefore, it must
be treated as a box having a transfer function 1/A. What about the load inertia JL1
Let us reconsider Eq. (3.112) and reflect the load inertia to the servomotor:
Pir(NW;)2 =
where JL is the load inertia referred to the motor shaft. Therefore,
and
rp _ Jm . JL
'"total “ _K_ -N2K
This indicates that the load inertia at the motor shaft is reduced by a factor of N2.
We are now ready to determine the values of Km and Tm of the servomotor and gear
reduction combination. As before, B is assumed to be zero. Therefore,
= (3-117)
- = Tm- J^L , K <0. (3.118)
m N2K„ ’ v '
m "tn
Observe the agreement between Eqs. (3.115) and (3.117) and between Eqs. (3.116) and
(3.118).
The results derived here can easily be extended to multimesh gear trains as
illustrated in Fig. 3.19. In this figure, a two-mesh system is illustrated, and the inertia
of the respective shafts and gearing combinations are indicated as Jr, J2, and J3.
It is left as an exercise to the reader to show that the equivalent inertia reflected to the
input (motor) shaft is
Input torque
T,(r)
Output torque
■ w
Fig. 3.19 A multimesh gear train.126 State Equations and Transfer-function Representations 3.5
and the equivalent inertia reflected to the output shaft is given by
Je% = WW + J.Nl + J3.
Before leaving the subject of gear ratios, the question is posed as to what is the
optimum gear ratio for a given motor and load configuration ? This problem can be
answered by reconsidering the servomotor, gear train, and load configuration illus￾trated in Fig. 3.18. The torque developed by the motor in accelerating its own inertia,
Jm, and the load inertia, JL, through the gear ratio N, is given by
Td = (aM (3.119)
where a( represents the maximum required acceleration of the load. Equation (3.119)
represents the developed torque at the motor shaft with the load inertia component
appropriately reflected to it. In order to find the optimum gear ratio N which will
minimize the required motor torque and therefore the size of the motor, Eq. (3.119)
is differentiated with respect to N and is set equal to zero:
= °- <3i2°> L N2J
Therefore, the gear ratio required to minimize the motor torque is given by
N=J^’ (3-121)
where the gear ratio is the geometric mean of the ratio of the load to motor inertias.
Equation (3.121) may also be interpreted from the viewpoint that the value of motor
inertia for minimum motor torque required is given by
= 0-122)
Therefore, Eq. (3.122) states that the motor torque is minimized when the motor and
load inertias are equal when referred to a common shaft.
Note that this result assumes that the only effect that is important is acceleration
of the load. If a maximum load velocity is specified and the motor can only reach a
given maximum velocity, the choice ofoptimum gear ratio is a more complex problem.
3.5 TRANSFER-FUNCTION AND STATE-SPACE
REPRESENTATION OF TYPICAL HYDRAULIC DEVICES
Hydraulic components are commonly found in control systems that are either all
hydraulic or a combination of electromechanical and hydraulic devices [6, 13],
The procedures used for deriving the transfer function representation of some
commonly used hydraulic control system devices from their basic differential equations3.5 Transfer-function and State-space Representation of Typical Hydraulic Devices 127
are illustrated in this section. We specifically consider hydraulic motors, pumps, and
valves.
1. Hydraulic Motor and Pump There is no essential difference between a hydraulic
pump and motor, just as there is no essential difference between a de generator and a
de motor. Basically, the hydraulic device is classified as a motor if the input is
hydraulic flow or pressure and the output is mechanical position; or a pump if the
input is mechanical torque and the output is hydraulic flow or pressure.
Fig. 3.20 Hydraulic power transmission system.
Figure 3.20 illustrates a commonly used hydraulic power transmission system.
This device, which is capable of controlling large torques, consists of a variable
displacement pump that is driven at a constant speed. A control stroke, which
determines the quantity of oil pumped, also controls the direction of fluid flow.
The angular velocity of the hydraulic motor is proportional to the volumetric flow
and is in the same direction as the oil flow from the pump. A functional diagram ofthe
hydraulic transmission is illustrated in Fig. 3.21.
Fig. 3.21 Functional block diagram of a hydraulic power transmission system.
The amount of oil displaced per revolution of the hydraulic pump is a function
of the tilt angle 0p. When 0v = 0°, there is no flow in the oil lines. As Qv is increased
in the positive direction, more oil flows in the lines with the direction shown. W hen
0v is negative, the direction of oil flow reverses.128 State Equations and Transfer-function Representations 3.5
In order to derive the differential equation relating and 0c(t), we must define
certain hydraulic quantities. The volume of oil flowing from the pump, Qv, is
composed of flow of oil through the motor, Qm, leakage flow around the motor,
Qi, and compressibility flow, Qc, that is,
Qv = Qm + Qt + Qc- (3.123)
It can be shown that
Q„ = KJ)V, (3.124)
where
Kv — volumetric pump flow per second per angular displacement of Oj,
6P = displacement of the pump stroke;
Qm = ym^c, (3.125)
where
Vm = volumetric motor displacement
coe = angular velocity of motor shaft;
Qi = LPl, (3.126)
where
£ — leakage coefficient of complete system (ft3/sec)/(lb/ft2),
PL = load-induced pressure drop across motor (lb/ft2); and
where
V — total volume of liquid under compression (ft3),
KB — bulk modulus of oil, (lb/ft2).
Substituting Eqs. (3.124) to (3.127) into Eq. (3.123), we obtain the relationship
KA = Vm<oc + LPl + ^.
Kb dt
The torque available to drive the motor inertia is
torque = VmPL = J~ .
dt2
Substituting Eq. (3.129) into (3.128), we obtain
kb v, <«’ '
The Laplace transform of Eq. (3.130) is given by
W) = K„A(s) + ^-s2oc(s) + -^-S3ec(s).
KBvm
(3.128)
(3.129)
(3.130)
(3.131)3.5 Transfer-function and State-space Representation of Typical Hydraulic Devices 129
The transfer function of this device, defined as the ratio of the output 0c(s) to the
input tipis), is given by
9c(s) = ____________ Kp/Vm____________
6p(s) s[iVJIKBV2m)s2 + (LJlV2n)s + 1] ’ ’
and its simple block diagram is illustrated in Fig. 3.22. It is important to emphasize,
however, that even a relatively small amount of air in the oil lines would lower KB.
This would cause the resonant frequency of the system to decrease sharply and reduce
its capabilities. In addition, a large volume of oil in the lines between the hydraulic
pump and motor has a similar effect. Therefore, these lines should be as short and
narrow as possible.
Fig. 3.22 Block diagram of a pump-controlled hydraulic transmission system.
Equation (3.132) can be written in differential-equation form as follows:
vj d3ecjt) lj d2ec(t) . docjt) Kp e
KBV2m dt3 V2m dt2 dt Vm '
This third-order differential equation can be written as three first-order differential
equations by defining
= Ocit), (3.134)
x2 = 6cit), (3.135)
x3 = (3-136)
The resulting state equations are given by
xr =x2, (3-137)
it =x„ (3.13S)
x, - - x, - x. + 0 (,). (3.139)
3 VJ V VJ
In vector form, these equations become
i = Px + Br, (3.140)
0C = Lx, (3.141)130 State Equations and Transfer-function Representations 3.5
where
0
0
KBKvVm
l_ VJ _
L = [1 0 0],
1 0
0 1
K/M kbl
VJ V _
r = 0p(t).
2. Hydraulic Valve-Controlled Motor Another method of controlling a hydraulic
motor is with a constant-pressure source and a valve that controls the flow of oil
through it. A valve-controlled hydraulic system is usually smaller than a pump￾controlled system and less efficient. Due to the increased losses, the time constants
are greatly reduced, and the speed of response is relatively greater. Valve-controlled
systems do, however, have the disadvantages associated with devices whose charac￾teristics are nonlinear.
Figure 3.23 illustrates a valve-controlled hydraulic system. A fluid source, at
constant pressure, is provided at the center of the control valve. Fluid-return lines
are located on each side of this pressure source. When the control valve is moved to
the right, hydraulic fluid flows through line A into the hydraulic motor. This results
in a pressure differential across the piston of the motor which causes it also to move
to the right. This action causes fluid to be pushed back into the valve through line
B which returns it to the sump through line E. Similar operation occurs when the
control valve is moved to the left. Observe that all fluid flows are blocked when the
control valve is in the neutral position, as shown in Fig. 3.23.
pressure
source
Fig. 3.23 A valve-controlled hydraulic system.3.5 Transfer-function and State-space Representation of Typical Hydraulic Devices 131
Figure 3.24 represents the characteristics for the valve-controlled hydraulic
motor. The pressure between lines going to the motor is denoted by P, the flow
through these lines is denoted by Q, and r denotes the displacement ofthe valve from
its neutral position. Although these characteristics are nonlinear, it will be assumed
that they are linear for small input displacements. This is basically an application of
small-signal theory, used so frequently by circuit designers. For small excursions
from a given quiescent operating point,
Ag = |^AP + |^Ar. (3.142)
dP dr
At any given quiescent operating point, it will be assumed that dQ/dP and dQ/dr
are constants.
Fig. 3.24 Valve characteristics.
The transfer function relating the input r and output c can be obtained by
comparing the valve-controlled hydraulic system with the pump-controlled hydraulic
system. Studying these two systems carefully, it is observed that AQ is analogous to
QP, M is analogous to J, AP is analogous to PL, and Ar is analogous to 0„. Using
these analogies, the transfer function can easily be found to be given by
C(s) = _______________ (l/FJ(gg/ar)_______________
K(s) s[(VM/KBVPl)s2 + (M/V^L - dQ/dP)s + 1] ‘
The term L — dQ/dP in the denominator of this equation is always positive since
Fig. 3.24 indicates that dQ/dP is always negative. The simple block diagram for this132 State Equations and Transfer-function Representations 3.6
Fig. 3.25 Block diagram of a valve-controlled hydraulic transmission system.
system is illustrated in Fig. 3.25. It is left as an exercise to the reader to determine
what the transfer function ofthe system is if a spring and damper are attached to the
control rod (see Problem 3.11), and to determine the state-space vector form of Eq.
(3.143).
3.6 TRANSFER-FUNCTION REPRESENTATION OF THERMAL SYSTEMS
If the assumption is made that the temperature of a body is uniform, then a number
of thermal systems can be represented by linear ordinary differential equations [14].
This approximation is reasonably correct for relatively small configurations. This
section specifically considers a hot-water heating system as an example of a typical
thermal system.
Figure 3.26 illustrates an electric hot-water heating system. The object of this
system may be, typically, to supply hot water in a home. Any demand for hot water
in the home causes hot water to leave and cold water to enter the tank. In order to
reduce heat loss to the surrounding air, the tank is insulated. A thermostatic switch
turns an electrical heating element on or off in order to maintain a desired reference
temperature.
Fig. 3.26 Electric hot-water heating system.3.6 Transfer-function Representation of Thermal Systems 133
The law of conservation of energy requires that the heat added to the system
equals the heat stored plus the heat lost. This can be expressed by the relationship
Qk = Qc + Qo - Qi + Qi, (3.144)
where
Qh = heat flow supplied by heating element
Qc = heat flow into storage in the water in the tank
Qo = heat flow lost by hot water leaving tank
Qi = heat flow carried in by cold water entering tank
Qi = heat flow through insulation.
It can be shown that
Qc = (3.145)
at
where
C = thermal capacity of water in tank
Tt = temperature of water in tank;
Qo = VHTt, (3.146)
where
V = water flow from tank
H = specific heat of water;
Qt = VHTi, (3.147)
where
Ti = temperature of water entering tank; and
where
Te = temperature of air surrounding tank
R = thermal resistance of insulation, stagnant air film, and stagnant liquid film.
Substitution of Eqs. (3.145) through (3.148) into Eq. (3.144) yields the expression
Qh = C + VH(Tt - • (3.149)
at K
The thermal model presented, so far, has considered Tt, Tit Te, and V as variables.
For the specific condition where V is a constant and Te = Tt, Eq. (3.149) reduces to
the expression
Qn = Cd-^+ (/H +
at \
(3.150)
IV
where Tt = temperature ofthe water in the tank above the reference Te. The Laplace
transform of Eq. (3.150) is given by
eA(s) Cs + VH + -1
R/
(3.151) =134 State Equations and Transfer-function Representations 3.7
The transfer function of this system, defined as the ratio of the output Tr(s) to the
input is given by
W- = ----------------------- (3.152)
Qh(s) Cs+VH + 11R
and its simple block diagram is illustrated in Fig. 3.27.
0/,(5) 1 T,(s)
Cs + VH + l/R
Fig. 3.27 Block diagram for the system shown in Fig. 3.26.
3.7 A GENERALIZED APPROACH FOR MODELING—
THE PRINCIPLES OF CONSERVATION AND ANALOGY
Due to the large variety of control system components that occur in practice, a
generalized approach is useful for obtaining their mathematical model. Therefore,
rather than pursue the presentation of further specific control system components,
this section will provide a generalized approach to deriving mathematical models.
There are several general principles that can be useful in serving as guides.
The most important are the principle of conservation and the concept of analogous
circuits.
1. Principle of Conservation The principle of conservation is a very important
guideline for the derivation of a mathematical model. A statement of this concept is
that
accumulation = inflow — outflow. (3.153)
In terms of rates, the principle of conservation is stated as follows:
rate of increase (of storage) = rate of inflow — rate of outflow. (3.154)
Exactly what is being conserved depends on the application. However, this principle
is usually used to establish a balance or inventory of mass, energy, momentum or
charge.
The principle of conservation has been used several times throughout this
chapter. For example, let us reconsider the hydraulic motor and pump power
transmission system illustrated in Fig. 3.20 and the electric hot-water heating system
of Fig. 3.26. In the case ofthe hydraulic motor and pump power transmission system,
Eq. 3.123 was derived. It related the volume of oil flowing from the pump Qv to its
distribution in flow through the motor, Qm, leakage around the motor, Qlt and
compressibility flow (accumulation), Qc. Therefore, this equation was an application3.7 A Generalized Approach for Modeling—The Principles of Conservation and Analogy 135
of the principle of conservation where Eq. (3.153) was modified to the form
inflow = outflow + leakage + accumulation. (3.155)
Similarly, in the electric hot-water heating system problem, Eq. (3.144) was derived.
Let us rearrange it into the following form in order to demonstrate the principle of
conservation:
Qn + Qi = Qc + Qo + Qi. (3.156)
This equation states that the heat flow supplied by the heating element, Qh, plus the
heat flow carried in by cold water entering the tank, Qt, is distributed as heat flow
into storage in the water in the tank, Qe, heat flow lost by hot water leaving the tank,
Qo, an(i heat flow through the insulation, Qt. Therefore, the principle of conservation
was applied, and the form of the principle applied was the same as Eq. (3.155).
2. The Circuit Concept and Analogy An alternative viewpoint to the principle of
conservation is the concept of an analogous circuit. The basis for applying the
principle of analogy is that two different physical systems can be described by the
same mathematical model. This permits a generalization of ideas specific to a
particular field in order that a broader understanding of a variety of apparently
unrelated situations can be achieved.
Table 3.3 Analogous quantities
Electrical Mechanical
(linear motion)
Mechanical
(rotation) Thermal Hydraulic
Current Force Torque Heat flow Flow
Voltage Linear Angular Temperature Pressure
velocity velocity
Inductance Spring Spring — Inertia
Capacitance Mass Inertia Capacitance Compression
Resistance Dashpot Dashpot Resistance Resistance
The analogy concept can best be understood by focusing attention on some of the
devices that have been covered in this chapter. For example, let us look at the
electrical circuit of the armature-controlled de servomotor illustrated in Fig. 3.10(a)
and the hydraulic motor and pump illustrated in Fig. 3.20. Equations (3.61) and
(3.132) described their respective mathematical models. The direct analogy between
Eqs. (3.61) and (3.132) is self-evident. Furthermore, the development of these two
models follows a very similar process. It is important to note how their respective
relations in both cases enabled one to relate the two coupled sets of physical variables:
electrical and mechanical for the armature-controlled de servomotor, and hydraulic
and mechanical for the hydraulic motor and pump transmission system.
This concept of analogy can be extended to relate electrical, mechanical (linear
motion), mechanical (rotational), thermal, and hydraulic systems. For purposes of
comparison, Table 3.3 illustrates a brief table of analogous quantities in different136 State Equations and Transfer-function Representations 3.7
physical systems. It is important to note that there are two possible analogies between
mechanical and electrical systems, If torque (or force) is chosen to be analogous to
current, then the mechanical circuit and electrical circuits look alike with inertia being
analogous to capacitance and a spring being analogous to inductance. This is the
system illustrated in Table 3.3. Another approach could be to choose torque (or
force) to be analogous to voltage. Then the mechanical and electrical circuits will be
analogous, with inertia being analogous to inductance and a spring being analogous
to capacitance: it makes no difference which viewpoint is taken.
Ri
Fig. 3.28 Electrical analog of Fig. 3.5.
By using the method of analogs, complex mechanical (or hydraulic, etc.) systems
can be drawn as equivalent circuit diagrams, for which Kirchhoff’s voltage and
current laws can be utilized to obtain the mathematical model of the system. As an
example ofthis approach, let us reconsider the complex mechanical system of Fig. 3.5,
using Kirchhoff’s voltage and current laws. By using the analogs of Table 3.3, the
mechanical network of Fig. 3.5 is redrawn as an equivalent electrical circuit in Fig.
3.28. The node equations for Fig. 3.28 are written by inspection as
Qs + -^ + -M r2(s) - + tM K(s) = /(*), (3.157)
“(I + /-W) + (c1S
\/x2 \
+ —
L,s + «, + ± +tLVi(s) = 0,
k2 L2s/
(3.158)
where
Lj = 1/ *, c2 = m2,
r2 = l/2?2, Vl = >1(0,
L2 = 1//C2, r2 = >2(0, C, = M,.
Equations (3.157) and (3.158) are analogous to Eqs. (3.27) and (3.28), respectively.
Substituting the analogous quantities into Eqs. (3.157) and (3.158), and taking theProblems 137
inverse Laplace transforms we obtain the following set of equations:
/(0 = + KMt) - (3.159)
at L at at J
n p pWO „ r ,A. 0 = B2 —— - —— + K2[y2(t) — y/t)]
L at at J
d2yi(0 R dy^t)
~ ------—— - K^ySt). (3.160)
at at
Observe that Eqs. (3 159) and (3.160) are identical to Eqs. (3.27) and (3.28),
respectively.
Electrical analogies have the advantage that they can be set up very easily in the
laboratory. For example, a change in a particular parameter can be accomplished
very easily in the electric circuit to determine its overall effects and the electric circuit
can be approximately adjusted for the desired response. Afterwards, the parameters
in the mechanical (or hydraulic, or thermal, etc.) system can be adjusted by an
analogous amount to obtain the same desired response.
PROBLEMS
3.1 a) For the mechanical translational system illustrated in Fig. P3.1, write the differential
equation relating the position y(t) and the applied force/(/).
Figure P3.1138 State Equations and Transfer-function Representations
b) Determine the transfer function Y(s)/F(s).
c) Determine the state-space vector form of this system.
3.2 a) For the mechanical translational system illustrated in Fig. P3.2, write the differential
equation relating the position j(r) and the applied force/(?).
b) Determine the transfer function Y(s)lF(s).
c) Determine the state-space vector form of this system.
Figure P3.2
3.3 a) For the mechanical rotational system illustrated in Fig. P3.3, write the differential
equation relating T(f) and 0(t).
b) Determine the transfer function 6(s)/T(s).
Equilibrium
position
Figure P3.3
3.4 Figure P3.4 represents the diagram of a gyroscope which is used quite frequently in
autopilots, stabilized fire control systems, and so on. Assume that the rotorspeed is constant,
that the total developed torque about the output axis is given by
Figure P3.4Problems 139
where K is a constant, and that the inner gimbal’s moment of inertia about the output axis
is J.
a) Write the differential equation relating 0j(r) and 0o(r).
b) Determine the transfer function
c) Determine the vector differential equation of this system.
3.5 The Ward-Leonard system shown in Fig. 3.11 has the constants and characteristics
shown in Table P3.5. Derive the transfer function for the system, G0(s)/Ef(s).
Table P3.5
Generator Motor
Rf = 1.1 12
Lf = 0.25 H
R, = 0.20 12
Ls = 0.01 H
Kg = 1 V/A
Rm = 2 £2
Lm = 0.05 H
Ke =0.1 V/(rad/sec)
Kt = 2 ft Ib/A
J = 0.1 slug ft2
B = negligible
3.6 Repeat Problem 3.5 for the constants and characteristics shown in Table P3.6.
Table P3.6
Generator Motor
Rf = 1 12
Lf = 0.1 H
R„ =0.1 12
Lg = 0.1 H
Krj = 10 V/A
= 1 £2
Lm = 0.01 H
Ke = 10 V/(rad/sec)
KT = 10 ft Ib/A
J = 1 slug ft2
B = negligible
3.7 The time constant for highly inductive devices such as the armature circuit ofthe Ward￾Leonard system shown in Fig. 3.11 is usually too long for high-performance control systems.
A simple technique for decreasing the time constant of such a system uses feedback, which
controls the current ofthe inductive device. Figure P3.7 illustrates how this can be practically
accomplished for a Ward-Leonard system by inserting a resistor R in series with the armature
circuit. Other notations used in this diagram are the same as those used in Section 3.4.
Assume that the armature current is much greater than the field current.
a) Write the differential equation relating ef(t) and 0o(O￾b) Determine the transfer function G0(s)/Ef(s).
c) Compare the answer to part (b) with Eq. (3.78) and show that the armature time constant
has been reduced by means of feedback.140 State Equations and Transfer-function Representations
Figure P3.7
3.8 Since it is proportional to velocity, the back emf of a motor is sometimes directly used
as a stabilizing voltage. Figure P3.8 illustrates a practical bridge-type circuit which can be
used for this purpose. The resistors and R2, which have very high resistance relative to
the armature circuit resistance, are adjustable in order to obtain the desired value of eb(J).
Rac represents the resistance of the armature and commutator voltage drop; RCF and
Lcf represent the resistance and inductance of the commutating fields, respectively.
Ke, K?, J, and B have the same significance as in the text of this chapter. For the armature￾Figure P3.8
controlled de servomotor illustrated in Fig. P3.8, assume that the field current If remains
constant.
a) Write the differential equation relating ea(t) and eb(t).
b) Determine the transfer function Eb(s)lEa(s).
3.9 If the armature current of the field-controlled de servomotor is not held constant, the
developed torque is proportional to both the field and the armature currents (see Fig. 3.13).Problems 141
This essentially results in a nonlinear device because of the multiplication effect of field and
armature current.
a) Draw the signal-flow diagram for the system.
b) What approximations can be made to linearize the operation?
3.10 Draw the signal-flow diagram and analog-computersimulation circuitry for the following
devices:
a) de generator
b) the Ward-Leonard system
c) two-phase ac servomotor
3.11 Derive the transfer function C(s)[R(s) for the valve-controlled hydraulic transmission
system shown in Fig. 3.23 if a spring in parallel with a viscous damper is attached between
the right end of the valve control rod and some stationary reference point. Assume that the
spring stiffness factor is K Ib/ft and the viscous damping factor is B lb(ft/sec).
3.12 The control of paper color is a very interesting and important problem in the paper
processing industry. Figure P3.12(a) illustrates a functional diagram of the problem [15].
This color-control method depends on the availability of a precise, reliable, on-line colorim￾eter. As indicated in the diagram, dyestuff concentrations are added at various stages of the
process. In this diagram, the following nomenclature is used:
f — water flow rate, in liters/min
a = consistencies (weight of dry fiber/weight of stock)
Vt = header tank volume
Kv — constant at the dry end
VP = pipe volume
Vs = stirred tank volume
c = dyestuff concentration, in gm/liter
v = machine speed, in m/min
m — dyestuff flow rate, in liters/min
Figure P3.12(a)Figure P3.12(b)
142 State Equations and Transfer-function RepresentationsProblems 143
Figure P3.12(A) illustrates an equivalent block diagram of the color control process [15].
The factor Pr, indicated at several stages of the block diagram, is the retention factor of the
dye. It varies with the concentration, with the time allowed for dyeing, and with such factors
as pH, alum, resin, temperature and dye interaction. Determine the transfer function of
this system, C(s)/7?(.s), where
R(s) = dye concentration ratio = percent of dye/weight of fiber
C(s) = weight concentration of dye in the sheet at the output.
3.13 A two-phase ac servomotor has the following specifications: 115/115 V; 60 Hz; 2
phases; 4 poles; rotor moment of inertia, 0.09 oz in2, rated stalled torque, 6 oz in; no-load
speed, 2500 rev/min; load inertia and coefficient of viscous friction are negligible. Calculate
the transfer function for this servomotor, 60(s)/Ec(s).
3.14 It is common practice to place a gear reduction between a servomotor and the load in
order to convert the high-speed, low-torque motor characteristics to a low-speed, high￾torque device. Assuming a gear reduction of N: 1 and a load inertia ofJ2, derive the transfer
function O0(s)/Ec(s) for thissystem and compare it with Eq. (3.101). Use the same terminology
and motor characteristics as in Section 3.4, part 5. Assume B is finite.
3.15 Based on the derivation of Problem 3.14, repeat Problem 3.13 if the load has an inertia
of 0.40 oz in2, and a gear ratio of 36:1 is used.
3.16 Repeat Problem 3.15 with the load inertia doubled. What conclusions can you draw
from your results?
3.17 A two-phase ac servomotor has the following specifications: 115/115 V; 400 Hz;
2 phases; 4 poles; rotor moment of inertia, 0.04 oz in2, rated stall torque, 2 oz in; no-load
speed, 5000 rev/min; load inertia, 4 oz in2 geared to the motor through a gear reduction of
9:1. Determine the transfer function for the overall servomotor and load. Assume the
inertia of the gears is negligible.
3.18 Repeat Problem 3.17 without assuming that the gearing inertia can be neglected.
Assume that the gear reduction of 9:1 is achieved in one gear pass and each gear has an
inertia of 0.01 oz in2. What conclusions can you reach from your results?
3.19 Repeat Problem 3.17 without assuming that the gearing inertia can be neglected.
Assume that the gear reduction of 9:1 is achieved in two gear passes of 3:1 each, and that
each gear has an inertia of 0.01 oz in2. What conclusions can you draw from your results?
3.20 Derive the transfer function of the armature-controlled de servomotor from its signal￾flow diagram.
3.21 Starting with Eq. (3.62), derive the state equations of the armature-controlled de 
servomotor from its state-variable diagram.
3.22 Starting with Eq. (3.78), derive the state equations of the Ward-Leonard system from
the state-variable diagram.
3.23 Starting with Eq. (3.101), derive the state equations of the two-phase ac servomotor
from the state-variable diagram.144 State Equations and Transfer-function Representations
Figure P3.24
3.24 For the mechanical system illustrated in Fig. P3.24, draw an analogous electric circuit
and determine the differential equation relating the forcef(t) and the position x(t).
3.25 For the mechanical system illustrated in Fig. P3.25, draw an analogous electric circuit
and determine the differential equation relating v^i), v2(f), andf(t).
Figure P3.25References 145
3.26 With the advent of modern man-machine control systems utilizing humans to 
perform various manual tasks, the knowledge of the human transfer function is very
important in order to enable the prediction of the system's performance. Many researchers
have attempted to determine the human transfer function. For manual control at relatively
low frequency, the human characteristics indicate a gain K. an anticipation time constant
T’.i, an operator’s error-smoothing lag time constant TL, an operator’s short neuromuscular
delay time constant 7\, and an operator's time-delay factor D. Write the form of the
human transfer function. What is the meaning of the time-delay factor D?
REFERENCES
1. M. E. Van Valkenberg, Network Analysis (2nd Edn.), Prentice-Hall, Englewood Cliffs,
N.J. (1964).
2. R. J. Schwarz and B. Friedland, Linear Systems, McGraw-Hill, New York (1965).
3. A. Higdon and W. B. Stiles, Engineering Mechanics, Prentice-Hall, Englewood Cliffs, N.J.
(1949), Chapter 9.
4. R. M. Saunders, “The dynamo electric amplifier—Class A operation,” Trans. AIEE 68,
1368-73 (1949).
5. B. Litman, "An analysis of rotating amplifiers,” Trans. AIEE 68, Pt. 2, 111 (1949).
6. H. Chestnut and R. W. Mayer, Servomechanisms and Regulating System Design (2nd
Edn.), Vol. 1, Wiley, New York (1959).
7. R. C. Kloeffler, R. M. Kerchner, and J. L. Brenneman, Direct-Current Machinery,
Macmillan, New York (1950).
8. J. C. Gille, N. J. Pelegrin, and P. Decaulne, Feedback Control Systems, McGraw-Hill,
New York (1959), Chapter 33.
9. H. Chestnut and R. W. Mayer, Servomechanisms and Regulating System Design, Vol. 2,
Wiley, New York (1955), Chapter 7.
10. R. J. W. Koopman, “Operating characteristics of two-phase servomotors,” Trans. AIEE
68, Pt. 1, 319 (1949).
11. A. M. Hopkin, “Transient response of small two-phase servomotors,” Trans. AIEE 70, 
Pt. 1, 881 (1951).
12. M. Liwschitz-Garik and C. C. Whipple, Electric Machinery, Vol. 2, A-C Machines,
Van Nostrand, Princeton, N.J., (1946), Chapter 7.
13. G. J. Brown and D. P. Campbell, Principles of Servomechanisms, Wiley, New York
(1948).
14. J. D. Trimmer, Response ofPhysical Systems, Wiley, New York (1950).
15. P. R. Belanger, “Sensitivity design of a paper color control system,” in Proceedings ofthe
1969 Joint Automatic Control Conference, pp. 99-106.
16. G. A. Korn and T. M. Korn, Electronic Analog and Hybrid Computers, McGraw-Hill,
New York (1964).
17. S. M. Shinners, “Which computer—Analog, digital, or hybrid?” Machine Design 43,
104-111 (January 21, 1971).4
SECOND-ORDER SYSTEMS
4.1 INTRODUCTION
From the frequency domain viewpoint, system order refers to the highest power ofs
in the denominator of the closed-loop transfer function of a system. In the time
domain, system order refers to the highest derivative ofthe controlled quantity in the
equation describing the control system’s dynamics. System order is a very significant
parameter for characterizing a system.
Second-order systems are very important to the control-system engineer. This
type of system characterizes the dynamics of many control-system applications
found in the fields of servomechanisms, space-vehicle control, chemical process
control, bioengineering, aircraft control systems, ship controls, etc. It is interesting
to note that most control system designs are based on second-order system analysis.
Even if the system is of higher order, as it usually is, the system may be approximated
by a second-order system in order to obtain a first approximation for preliminary
design purposes with reasonable accuracy. A more exact solution can then be obtained
in terms of departures from the performance of a second-order system.
Due to the importance of second-order systems, this chapter is devoted to
presenting its characteristic response in the time domain, and analyzing its state￾variable signal-flow diagram. In addition, several important control system definitions
are presented. The closed-loop frequency response of second-order systems is pre￾sented in Chapter 6 where techniquesfor obtaining the closed-loop frequency character￾istics are derived.
4.2 CHARACTERISTIC RESPONSES
OF TYPICAL FEEDBACK CONTROL SYSTEMS
The purpose of this section is to describe the transient response of a typical feedback
control system. We consider a very common configuration in which a two-phase ac
servomotor, whose transfer function is given by Eq. (3.101) is enclosed by a simple
unity feedback loop. Figure 4.1 illustrates the block diagram of this second-order
system. For purposes of simplicity, the reference input elements, control elements,
feedback elements, and the indirectly controlled system are assumed to have unity
transfer functions.
1464.2 Characteristic Responses of Typical Feedback Control Systems 147
R(s)
Fig. 4.1 Second-order feedback system containing a two-phase ac induction motor.
The closed-loop transfer function of this system is given by
C(s) = Km/Tm
R(s) s2 + (1/Tm)s + KJTm ‘
By defining the undamped natural frequency a>n and the damping factor £ as
co2 = and £ = —— ,
Tm 2(onTm
Eq. (4.1) can be rewritten as
C(s) = a)2„
R(s) s2 + 2£co„s + co2
(4-2)
(43)
The parameters co„ and £ are very important for characterizing a system’s response.
Note from Eq. (4.3) that a>„ turns out to be the radian frequency of oscillation when
£ = 0. As £ increases in value from 0, the oscillation decays and becomes more
damped. When £ > 1, an oscillation does not occur.
We assume that the initial conditions are zero and the input is a unit step. There￾fore, R(s) = I/s, and the Laplace transform of the output can be written as
2
C(s) =
s(s2 + 2£co„s + co2)
(4.4)
Factoring the denominator, we obtain
C(5) = -------------------------- (4.5)
s(s + £co„ — O)n￾The exact solution for the output in the time domain is dependent on the value of £.
When £ > 1, the second-order system has poles which lie along the negative real axis
of the complex plane. When £ < 1, however, a pair of complex conjugate poles
result. We shall determine the output response to a step input for the three cases:
where the damping factor equals unity, is greater than unity, and is less than unity.
Case A. Damping Factor Equals Unity When £ = 1, Eq. (4.5) reduces to
co2
C(«) = , ~2 •
s(s + coj
(4-6)148 Second-order Systems 4.2
The time-domain response can be obtained by utilizing the solution obtained for
Eq. (2.78). The partial-fraction expansion of Eq. (4.6) is given by
K, K, K3
C(s) — + + ■ (s + (Ony s + w„ s
(4.7)
Using Eqs. (2.81), (2.83), and (2.84) we find that
Ki = —con, (4.8)
K2 = -1, (4.9)
K3 = 1. (4.10)
Substituting these constants into Eq. (4.7), we obtain
■. — a>n 1 1
-— •— “r (4.H)
(s + s + co„ s
The time-domain response of the output, c(t), may be obtained by utilizing the table
of Laplace transforms given in Appendix A:
c(t) = - e-^ + 1. (4-12)
Figure 4.2(a) illustrates the output response together .with the unit step input.
Notice that the output response exhibits no overshoots when £ = 1. This response is
described as being critically damped.
Case B. Damping Factor Greater than Unity When £ > 1, the time-domain response
can be obtained quite simply from its partial-fraction expansion. This can be
expressed as
C(s) = -7-f=’ <4J 3>
s s 4- £w„ - wnV£ — 1 s + K + "„V£ — 1
where £ton — co„\/£2 — 1 and £con + £2 - 1 are positive real numbers.
The constants Kx, K2, and K3 can be evaluated quite simply by the methods
described in Chapter 2. Their values are
= 1,
*2 = [2(£2 - £\Z£2 - 1 - l)]-1, (4.14)
K3 = [2(£2 + £x/£2 - 1 - I)]-1.
Therefore Eq. (4.13) can be written as
C(y) = 5-1 + [2(£2 - £>/£2 - 1 - 1)]-J(5 + £a»w - conV£2 - I)-1
+ [2(£2 + £V£2 - 1 - l)]-!(5 + £con + conx/£2 - I)-1. (4.15)4.2 Characteristic Responses of Typical Feedback Control Systems 149
Fig. 4.2 (a) Input and output response for a critically damped second-order system; (b)
Input and output response for an overdamped second-order system; (c) Input and output
response for an underdamped second-order system (£ = 0.3).150 Second-order Systems 4.2
The time-domain response of the output, c(t), may be obtained by utilizing the table
of Laplace transforms given in Appendix A. It can be expressed as
. c(t) = 1 + [2(£2 - 1?J? - 1 -
+ [2(1? + £>/£2 - 1 - (4.16)
Figure 4.2(b) illustrates the output response together with the unit step input. Notice
that when £ > 1, the output response exhibits no overshoots and takes longer to
reach its final value than when £ = 1. This response is described as being overdamped.
Fig. 4.3 Location of the conjugate complex poles in the complex plane.
Case C. Damping Factor Less than Unity When £ < 1, the time-domain response
can be obtained in an analogous manner. The solution is slightly more complex,
however, since we now have a pair of complex conjugate poles. The partial-fraction
expansion of Eq. (4.5) can be written as
C(s) = -1 + --------------=+ ------------------------K* .-------- - (4.17)
s « + £«„- 1 - £2 s + £w„ + 1 - £2
The constants Kt, K2, and K3 can be evaluated in an analogous manner by the method
described in Chapter 2, but the algebra becomes a little complicated. In order to
simplify this situation somewhat, use is made of the relationship between the location
of the conjugate complex poles in the complex plane and the damping factor £. The
geometry of the configuration is illustrated in Fig. 4.3. Notice that the distance from
the origin to either pole equals con. In addition, the angle a has the following
trigonometric properties:
cos a = — £, (4.18)
sin a = Vl — £2. (4.19)4.2 Characteristic Responses of Typical Feedback Control Systems 151
Utilizing the relations given by Eqs. (4.18) and (4.19), the constants Klt K2, and K3
can be expressed as
K, = 1,
e~lx K2 = , (4.20)
2j sin a
eix
2j sin a
Therefore Eq. (4.17) can be written as
c(S) = 3- + (s + -jcoji - er1
s 2j sin a
- (s + &>n + - C2)-1. (4.21)
2j sin a
The time-domain response of the output, c(t), may be obtained by utilizing Appendix
A. It can be expressed as
e Vi - C1 - a). (4.24) c(t) =
2j sin a
_ e e-(<<on+j«nv/i-t2)t (4-22)
2j sin a
This can be simplified to
Qa>nt 42-«)__ o
c(t) = 1 + -, (4.23)
Vi - e 2j
or
. sin (a>„
Figure 4.2(c) illustrates the output response for a value of £ approximately equal to
0.3, together with the unit step input. Notice that the output response exhibits
several overshoots before finally settling out. This response, which is characteristic of
an exponentially damped sinusoid, is described as being underdamped.
The time to the first overshoot and the value of the first overshoot are two
interesting identifying characteristics for this type of response. We shall next derive
these values in terms of the undamped natural frequency, a>n, and the damping
factor £.
Equation (4.24) indicates that the radian frequency of oscillation of the system,
is ______
0Jm = coJi - (4.25)152 Second-order Systems 4.2
(4.26)
(4.27)
The cyclic frequency of oscillation of the system,fm, is
f _ — C
Jn~ ~ _
2ir 2tt
The period of oscillation of the system, tm, is
_ 1 _ 2tt
tm=7m = ^T^‘
The time at which the peak overshoot occurs, can be found by differentiating
c(t), given by Eq. (4.24), with respect to time and setting the derivative equal to zero:
- £2) 1 sin (co„Vl - C21 - a)
dt
+ to„e-Ja>n< cos (<wnV1 — £21 — a) = 0.
This derivative is zero when
<z>„x/1 — £2 t = 0, it, 2tt, ....
The peak overshoot occurs at the first value after zero, provided there are zero initial
conditions. Therefore,
ointv = . (4.29)
Vi - £2
For the case illustrated in Fig. 4.2(c), where £ = 0.3, the time to the first overshoot is
approximately 3.3/ct>„.
Substituting Eq. (4.29) into Eq. (4.24) yields the value for the maximum instan￾taneous value of the output, c(t):
<(<) - 1 + exP(-:j±<r^?)si„ („ _ a)
V1 - £2
This can be simplified by substituting
sin (?r — a) == sin a and sin a = VI — £2.
Therefore,
/ 'Ctt \
c(0maX = 1 + exp----- - (4.31)
v4.2 Characteristic Responses of Typical Feedback Control Systems 153
Fig. 4.4 Transient response curves of a second-order system to a step input.
This is usually expressed as a percentage of the input. Therefore, for a unit step input,
Maximum percent overshoot = exp , .3 x too.
%/l -
(4-32)
For the case illustrated in Fig. 4.2(c), where £ = 0.3, the maximum percent overshoot
is approximately 38 %.
The second-order system is a very common and popular one. In order for the
reader to become more familiar with its typical characteristic responses, Figs. 4.4
and 4.5 are shown to illustrate the resulting transient responses, and percent maximum
overshoots, respectively, for several values of damping factor.154 Second-order Systems 4.3
Fig. 4.5 Per cent maximum overshoot versus damping factor for a second-order system.
It is interesting to compare the sketches of Fig. 4.2(a), (b), and (c). The critically
damped system appears to be a compromise among the three systems shown. Although
it does take a longer time to reach the desired value of unity than the underdamped
system, it does not exhibit overshoots. The underdamped system, however, oscillates
several times around the desired value before it finally settles to its steady-state value.
Depending on the value of the damping factor, the underdamped system may reach
its final value faster than the critically damped system. Overdamped systems are
hardly ever used in practice. As a matter of interest, practical systems are usually
designed to be somewhat underdamped. Chapter 5 will discuss this in greater detail
in terms of the various performance criteria.
4.3 STATE-VARIABLE SIGNAL-FLOW
DIAGRAM OF A SECOND-ORDER SYSTEM
In the previous section, the derivation of the time response of the second-order system
was based on the transfer-function derivation. Therefore, an implicit assumption
was made that the initial conditions were zero. This section illustrates how the4.3 State-variable Signal-flow Diagram cf a Second-order System 155
Fig. 4.6 (a) State-variable diagram of a second-order system, (b) Signal-flow diagram for a
second-order system.
state-variable signal-flow diagram method of the underdamped case yields a more
versatile and complete solution in the time domain including the initial condition
terms.
The state-variable diagram for this system can be derived from Eq. (4.3) as follows:
C(s) = «>2
R(s) s2 + 2£<z)„s + co2
Dividing through by s2, we obtain
C(s) = co2s-2
R(s) 1 + 2^„s-1 + w2s-2 ’
Defining
F(.__________ W)
1 + 2^ns~1 + co2s-2 ’
(4.33)
(4-34)
(4.35)156 Second-order Systems 4.3
we may rewrite Eq. (4.34) as
C(s) = co2s~2£(s). (4.36)
From Eq. (4.36) and
E(s) = R(s) - 2£cons~1£(s) - co2S-2£(8), (4.37)
the state-variable diagram of this system can easily be obtained as illustrated in Fig.
4.6(a). The corresponding signal-flow diagram of the system is illustrated in Fig.
4.6(b). The initial conditions are assumed to occur at t = t0. Application of Mason’s
theorem (Eq. 2.132) to this diagram permits us to write the state transition equation
directly as follows:
Simplifying Eqs. (4.38), (4.39), and (4.40), we obtain the following set of equations:
Xl(8) =
8 \1 + 2£cO„S x) 8 2x2(to)
A X1( o) 1 A +
8 2R(S)
A ’
(4.38)
X2(s) =
-(t)2nS~2 S~1X2(t0) S^Rjs)
. ^l(to) + A + A ’ A A A
(4-39)
where
A = 1 + 2£co„s-1 + co2s-2. (4.40)
y z \ _ $ ~b z x , ______ *2(^0) ______
1 s2 + 2£wns + a>2 1 ° s2 + 2£a>ns + co2
+ -L 2* (S)’ s + 2c,ojns 4- co„
— co2 s
^2(5) = 2,9? T 2 xi(*o) 4 2,9/ T 2 *2^0)
s + 2i,cons + (on s + 2£co„s + con
s2 4- 2£co„s + co2 ( )
(4-41)
(4-42)
These two equations can be put into the following vector form:
W]
X2(s)J
' s + 2£a>w
s2 + 2^„8 + co2
s2 + 2£o>ns + co2
_______ 1_______ '
8 + 2£ft>ns + CO„ rx1(to)”l
S LX2(^o)J
s2 + 2£co„s + co2.
£(8). (4-43)4.3 State-variable Signal-flow Diagram of a Second-order System 157
The inverse Laplace transform of Eq. (4.43) is given by the following expression (it
is assumed that 7?(s) = 1/s and that £ < 1):
*iW|
x2(t)J
where
[co Ji - £2(t - t0) + fa
— U>n ,----------
-y==e-C“"('- *o) sinWnVl - £2(t - t0)
Ksin - £2(t - t0)
wBVl — £
- sin [wnx/l — C ~ *o) + ^2]
I _ x*
Xi(to)1
,^2(to)J
411 + v=^e“W'“/0>sin ~ £2(' ~ M ~ fa
I VI ~ £2
----- 1 - e-5ob.«-to> sin ft> _ £2 (j _ /())
"nVl - C2
A_te„-.A^L!,
^ = tan-A^T.
I V -I
(4.44)
The corresponding output response of this second-order system having a unit step
input is given by the following expression:
c(t) = CO2X!(t)
sjn - C2(t - to) + ^l]x](t0)
-
1 + —------e- Vi - c2
> icOnit /o) sin [<o„V1 - C2 (t - to)]x2(*o)
, fo)sin [ftj^j _ £2(t _ to) - fa\. (4.45)
Equation (4.45) is a much more complete solution to the classical second-order
system than that previously derived in Eq. (4.24), since the initial conditions are now
accounted for. Observe from Eq. (4.45) that the solution, when the initial con￾ditions are zero, reduces to that of Eq. (4.24) with a = <f>2.158 Second-order Systems
PROBLEMS
4.1 The two-phase ac induction motor of Problem 3.13 is used in a simple positioning
system as shown in Fig. P4.1. Assume that a difference amplifier, whose gain is 10, is used
as the error detector and also supplies power to the control field.
a) What are the undamped natural frequency a>n and the damping factor ??
b) What are the percent overshoot and time to peak resulting from the application of a unit
step input?
c) Plot the error as a function of time on the application of a unit step input.
Figure P4.1
4.2 Repeat Problem 4.1 with the gain of the difference amplifier increased to 20. What
conclusions can you draw from your result?
4.3 The two-phase ac induction motor and load, in conjunction with the gear train specified
in Problem 3.19, is used in a simple positioning system as shown in Fig. P4.1. Assume that a
difference amplifier, whose gain is 20, is used as the error detector and also supplies power
to the control field.
a) What are the undamped natural frequency and damping factor £?
b) What are the percent overshoot and time to peak resulting from the application of a
unit step input?
c) Plot the error as a function of time on the application of a unit step input.
4.4 Repeat Problem 4.3 with the gain of the difference amplifier increased to 40. What
conclusions can you draw from your results?
4.5 Repeat Problem 4.3 with the gain of the difference amplifier decreased to 10. What
conclusions can you draw from your result?
4.6 A typical aerodynamically controlled missile control system is synthesized by means of
the appropriate application of moments to the airframe. These moments are generated by
the deflection of control surfaces placed at large distances from the center of gravity. The
result is that large moments are created with relatively small surface loads. The design of
this type of control system requires a sufficiently high control loop gain in order to minimize
the response time to input commands. In addition, it must not be so high as to cause high￾frequency instabilities. Figure P4.6 illustrates an acceleration-control steering system of a
missile. The command acceleration is compared with the output of an accelerometer to
develop the basic error signal which drives the control system. The output of a rate gyro is
utilized for damping [I],
a) Determine the transfer function, C(s)/R(s), of this system.
b) Determine the undamped natural frequency mn of this system and the damping factor I,Problems 159
Airframe dynamics
Figure P4.6
for the following set of parameters:
Amplifier gain = KA = 16, Aircraft gain factor = q = 4, KR = 4.
c) Determine the percent overshoot and time to peak resulting from an input command of a
unit step of acceleration.
4.7 Figure P4.7 illustrates the control system of a map drive system used to display a
portion of the map of an area to the commander of a task force. A main requirement of this
control system is that a constant tension be maintained on the continuous sheet of paper
between the wind-up and wind-off rolls in order that the paper does not tear. The system
illustrated contains four rollers, and a spring which provides a restoring angular torque of
K^t). As the radius R of the rollers varies, the tension changes and an adjustment in the
wind-up motor speed is required. The map leaving the wind-off roll is assumed to have a
velocity vr(t) and a tension T2(t); that approaching the wind-up roil is assumed to have a
velocity v2(t) and a tension T^t). A synchro-type sensing device, whose transfer function is
Ke, is mounted on the pivot point of the tension arm and is used to sense angular deviations
from 0 = 0. This error signal is amplified by a factor Ka by an amplifier. In addition,
assume that the relationship for motor control voltage Ec(t) caused by tension variations
T(t) is given by
Ec(t) = K2T(t).
The two-phase ac servomotor is assumed to have a transfer function given by Eq.
(3.101). It also contains a gear reduction of A: 1.
a) Determine the transfer function relating the change in tension T(s) due to an input
change velocity tq(s) of the wind-off roll in terms of the system parameters.
b) Determine the undamped natural frequency a>n and the damping factor £ in terms of the
system parameters.160 Second-order Systems
c) Calculate the damping factor for the case of a fully loaded wind-up roll, with the
following parameters:
Inertia of wind-up roller = 0.101 oz in sec2
Gear ratio = TV = 10.4:1
Radius of wind-up roller = R = 1.5 in
Motor inertia = Jm = 4.43 x 10“4 oz in sec2
Motor constant = Km — 0.417 in oz/(rad/sec)
Synchro sensitivity = Ke = 0.4 V/degree
Amplifier gain = Ka = 1000
Kr = 10.5 V/oz tension
K2 = 0.04 in oz/degree
d) How can the damping factor be increased ?
4.8 The Viking Mission conducted by the National Aeronautics and Space Administra￾tion included two launches in 1975 of a Viking Spacecraft by a Titan-Centaur launch
vehicle consisting of an Orbiter and a Lander. The Orbiter had the capability of orbiting
the planet Mars and of separating the Lander capsule, an automated laboratory in the
search of signs of life, that entered the Martian atmosphere for soft landing on the surfaceProblems 161
Actual position 
---------------- >
of claw
Fig. P4.8 (a) Lander capsule, Viking Project. (Official NASA photo) (b) Block diagram
of the second-order control system for positioning the retractable claw.
of Mars. Looking over Mars from orbit, Viking cameras and other instruments aided in
the confirmation of a suitable landing site. After this confirmation, the Lander separated
from the Orbiter and began its descent to the Martian surface. The descent occurred when
Mars was about 225 million miles from Earth and nearly on the other side of the sun.
Therefore, this required a completely automated deorbit and landing operation because
two-way communication at that distance was almost 45 minutes. Viking featured a series
of scientific experiments in the areas of biology, geology, and meteorology. In order to
collect material for these experiments, the Lander had a retractable claw with a 10-foot
reach as shown in Fig. P4.8(a). It was used for scooping out soil samples and placing162 Second-order Systems
them in its automated chemical laboratory for analysis. For purposes of this example,
assume that the control system which positions the retractable claw can be represented
by the second-order control system shown in Fig. P4.8(b).
a) Determine the undamped natural frequency and the damping factor of this control
system.
b) Determine the maximum percent overshoot and time to peak resulting from the appli￾cation of a unit command signal.
4.9 A two-phase ac induction motor is used to position a device in a feedback configu￾ration represented by Fig. P4.1. The time constant of the motor and load, Tm, is 0.5
seconds.
a) Determine the combined amplifier and motor constant gain, Km, which will result in a
damping factor of 0.5.
b) What is the resulting undamped, natural resonant frequency for the value of gain 
determined in part (a)?
REFERENCE
1. W. K. Waymeyer and R. W. Sporing, “Closed loop adaptation applied to missile control,”
in Proceedings ofthe 1962 Joint Automatic Control Conference, p. 18-3.5
PERFORMANCE CRITERIA
5.1 INTRODUCTION
In the early days of control-system theory, engineers were generally less rigid in
defining performance criteria. They were more apt to look on the feedback control
system rather qualitatively and center attention primarily on stability and static
accuracy. However, modern complex control systems have demanded the develop￾ment of accurate criteria of performance.
The performance of a feedback control system is generally described in terms of
stability, sensitivity, accuracy, transient response, and residual noise jitter. The exact
specifications are usually dictated by the required system performance. Certain
characteristics are more important in some systems than in others.
The great amount of literature that has appeared on the subject in recent years is
evidence of the increasing importance that performance criteria have been given in
feedback control system design. In order to keep pace with the requirements ofmodern
feedback control systems, several new criteria of performance have been developed
[1]. It is the purpose ofthis chapter to review and study several classical performance
criteria together with more recent and sophisticated approaches. The control
literature of the past decade abounds in various criteria of performance. Most
significant are several performance criteria that have been postulated which are
functions of time and error. After examining the literature, we find that the integral
oftime and error (ITAE) criterion for optimizing the transient response stands out as
being useful, although somewhat limited; the integral square error (ISE) criterion is
also quite popular. The concept of performance criteria, as presented in this chapter,
is extended in Chapter 9, where optimal control theory is discussed.
5.2 STABILITY
A feedback control system must be stable even when the system is subjected to
command signals, extraneous inputs anywhere within the loop, power supply vari￾ations, and changes in parameters of the feedback loop.
The qualitative statement that a system is stable, is meaningless. The question of
how stable the system is must also be determined. In order to answer this question
adequately, we must return to Eq. (2.117), which is repeated below:
G^-. (5.1)
R(s) 1 + G(s)H(s)
163164 Performance Criteria 5.3
As shown in Chapter 6, stability is determined by evaluating the denominator of this
equation for s = jo. If G(j(o)H(j(») = — 1, the denominator would vanish and the
system would oscillate indefinitely or the response would grow linearly with time.
The margin by which G(ja>)H(ja>) is shy of unity magnitude when its phase is 180° is
known as the gain margin, and the phase by which it is shy of 180° when its magnitude
is unity is known as the phase margin. These quantities indicate the degree to which
the system is stable. They are used by the control engineer to determine how stable
the feedback system is. Useful, qualitative, desirable design values are 3O°-6O°
for the phase margin and 4-12 decibels for the gain margin. These numbers indicate
that when G{ja>)H(jai) equals unity, its phase is 120°-150°, and when G(s)H(s) has 180°
phase shift, its magnitude is 0.25-0.63. In addition, the magnitude of the closed￾loop resonant peak, Mv, is also a measure of the degree of stability. As shown in
Chapter 6, a desirable value is between 1.0 and 1.4.
5.3 SENSITIVITY
Sensitivity is a measure of the dependence of a system’s characteristics on those of a
particular element. The differential sensitivity of a system’s closed-loop transfer
function T with respect to the characteristics of a given element K is defined as
T _ d In T
K ~ d In K ’
(5-2)
where
(5-3)
T = C(s')/R(s).
A more meaningful definition can be obtained by rewriting Eq. (5.2) as:
r _ dT/T
K dK/K ’
Equation (5.3) states that the differential sensitivity of T with respect to K is the per￾centage change in T divided by that percentage change in K which has caused the
change in T to occur. This definition is valid only for small changes. It is important
to note that sensitivity is a function of frequency and an ideal system has zero
sensitivity with respect to any parameter.
In order to illustrate the concept ofsensitivity, consider the typical control system
shown in Fig. 5.1 (a). Here represents the transfer function of the input transducer,
K2 represents the transfer function of the feedback transducer, and G represents the
combined transfer function of an amplifier, stabilizing network, motor, and geartrain
in the forward part of the feedback loop.
The overall system transfer function T is given by
K.G
T = -
R 1 + K2G
(5-4)5.3 Sensitivity 165
(b)
Fig. 5.1 (a) A representative control system, (b) An automatic positioning system for a
missile launcher.
Let us now determine the sensitivity ofthe overall system transfer function with respect
to changes in K2, and G.
A. Sensitivity of T with respect to Kr This is
sT = dT/T = K±dT_
K1 dKjKt T dKt ’
where
dT _ G _ T_
dK.~ 1 + K2G “ ’
Therefore,
= (5.5)
T Kx
B. Sensitivity of T with respect to K2 This is
T __ dT/T K2 dT
Ks ~ dK2/K2 ~ T dK2’166 Performance Criteria 5.3
where
dT _ 0 - KjG2 _ -KfG2
dK2 ~ (1 + K2G)2 “ Kj(l + K2G)2 '
Therefore,
T _ K, -K2G2 _ -K2 T2 = -K,G
sk2 - T + KaG)2 ~ T Ki i + k2G '
For cases where K2G »1, this reduces to
(5.6)
C. Sensitivity of T with respect to G
T _ dT/T _ G dT
G ~ dG/G ~ TdG ’
where
dT _ (1 + K2G)Kt- K,GK2 _
dG~ (1 + K2G)2 “ (1 + K2G)2 ’
Therefore,
r G Kr 1 S7 —________1------ — ------------ (5 7)
G T (1 + K2G)2 1 + K.fi '
The results obtained in Eqs. (5.5), (5.6), and (5.7) are quite interesting. The
symbols Kx and K2 represent input and feedback transducers, respectively, and Eqs.
(5.5) and (5.6) illustrate that they are very critical. Any changes in their characteristics
are directly reflected in an overall system transfer function change. Elements used
for and K2 must, therefore, possess precise and stable characteristics with tem￾perature and time. Equation (5.7) shows that the sensitivity of the overall system
transfer function with respect to G is divided by 1 + K2G. From a sensitivity view￾point, it appears desirable to design K2G to have as large a value as possible. However,
it need not be very precise.
It is also important to recognize that since sensitivity is a function of frequency,
we should think of systems as being sensitive or insensitive only over certain frequency
bands. In this example, K>G is a function of frequency and will be large over only a
limited range of frequencies. Therefore, T is insensitive to G only over a certain
range of frequencies. This point is further illustrated in Problems 5.1 through 5.5.
Let us now try to extend the results derived in this section in order to determine
qualitatively the requirements of the various elements shown in the simple missile
launcher positioning device of Fig. 5.1(b). In this system R1, R2, ± V, and the
difference capability ofthe difference amplifier must all be precise. The gain character￾istics of the difference amplifier, voltage amplifier, stabilizing network, power
amplifier, and motor need not be precise. Any changes in the characteristics of these
elements will be divided by 1 + K2G. Let us now consider the gear train, which is
composed of three gears n2, n3. It is assumed that gears n2 and n3 have the same5.4 Static Accuracy 167
number of teeth and each has 10 times as many teeth as gear The oiXput is taken
off gear n2. The prime purpose of gear n3 is to enable the output transducer to be
coupled off another shaft. Gear meshes can result in system errors because the tooth
space exceeds the thickness of an engaging tooth. This phenomenon is commonly
referred to as backlash. It can be measured by holding one gear fast and observing
the amount of motion in the other gear. Figure 5.1(b) denotes the backlash between
gears Wj and n2 as e15 and that between n2 and n3 as e2. A sensitivity analysis shows
that the error produced by backlash ex is reduced by 1 + K2G, while the error
produced by backlash e2 is added practically directly into the overall system transfer
function. Therefore, there is a need for precision gearing for n2 and n3 but not for nx.
Chapter 8 illustrates that backlashes at ex and e2, however, are very important from a
stability viewpoint. From a sensitivity viewpoint, however, the backlash at ex is not
as critical as that at e2.
5.4 STATIC ACCURACY
Accuracy probably ranks as the next most important characteristic of a feedback
control system. The designer always strives to design the system to minimize error
for a certain anticipated class of inputs. This section considers techniques which are
available for determining the system accuracy.
Fig. 5.2 A unity feedback system.
Theoretically, it is desirable for a control system to have the capability of
responding to changes in position, velocity, acceleration, and changes in higher-order
derivatives with zero error. Such a specification is very impractical and unrealistic.
Fortunately, the requirements of practical systems are much less stringent. For
example, let us consider the automatic positioning system of a missile launcher which
is illustrated in Fig. 5.1(b). Its functioning is similar to the missile launcher positioning
system in Fig. 1.8. Realistically, it would be desirable for this system to respond well
to inputs of position and velocity, but not necessarily to those of acceleration. In
addition, it probably would be desirable for this system to respond with zero error for
positional-type inputs. However, a finite tracking error could probably be tolerated
for inputs of velocity. In contrast to this system, where the stakes are quite high, let
us consider a simpler positioning system which perhaps is only required to reproduce
the angular position of a dial at some remote location. Such a control system would168 Performance Criteria 5.4
probably be only required to reproduce any positional inputs, but not any higher￾order inputs such as those of velocity and acceleration.
A method for determining the steady-state performance of any control system is
to apply the final-value theorem ofthe Laplace transform as given by Eq. 2.68.’ Let us
consider the unity feedback system shown in Fig. 5.2. The relation between the result￾ing system error, E(s), for a given input R(s~) is given by
£(s) = 1
R(s) 1 + G(s) ‘
The steady-state error can be expressed as
sR(s)
ess = lim e(t) = lim
i-*oo s-»0 1 4-
(5-8)
(5-9)
The control engineer is usually interested in inputs of position, velocity, and acceler￾ation. A step, ramp, and paraboloid are simple mathematical expressions which
represent these physical quantities, respectively. They are defined in Eqs. (5.10)
through (5.12), where the notation U(t) means a unit step for t > 0.
Position input: r(z) = U(t),
Ramp input: r(Z) =
Acceleration input: r(f) = |r2(7(z),
£(s) = 1/J,
R(s) = 1/s2,
R(s) = 1/s3.
(5.10)
(5.11)
(5-12)
We next determine the steady-state error of several types of systems for each of
these three inputs: the unit step, unit ramp, and unit paraboloid. It is assumed that
the loop transfer function G(s) has the general form
Cfs) = K(1 + T1S)(1 + +
s”[(T3s)2 + 2^ns + 1](1 + T4s)(l + T5s) •••(! + Tvs) ’ ( ‘ '
where
sn = a multiple pole at the origin of the complex plane,
K = gain factor of the expression.
1. Unit Step Input The steady-state error can be obtained by substituting R(s) = 1/s
into Eq. (5.9):
.. s(l/s) 1
ess = lim------ '-----= ------------------- . (5.14)
s-o 1 + G(s) 1 + lim G(s)
s-*0
The quantity limw0 G(s) is defined as the position constant and is denoted by Kv~.
Ku = lim G(s).
s-*0 (5-15)5.4 Static Accuracy 169
Therefore the steady-state error in terms of the position constant is given by
Equation (5.16) states that the steady-state tracking error of a feedback control
system having a unit step input equals 1/(1 + the position constant). Table 5.1
summarizes the value of Kp as a function of the number of pure integrations of the
open-loop transfer function G(s).
Table 5.1
Pure integrations of G(s) K9
0 K
1 CO
2 oo
n, where n > 0 00
Table 5.1 indicates that the position constant is infinite for all systems which
contain one or more pure integration(s) in the open-loop transfer function G(s).
Therefore, Eq. (5.16) implies that all systems containing at least one pure integration
result in a theoretical steady-state positional response error of zero. Table 5.1 indicates
that the position constant is finite for a system containing no pure integrations and,
therefore, the response error for a position input is nonzero.
2. Unit Ramp Input The steady-state error can be obtained by substituting Rfs) =
1/s2 into Eq. (5.9):
,. s(l/s)2 1 i~i\
ess = hm —— = ---------- . (5.17)
»-o 1 + G(s) iim sG(s)
3->0
The quantity lims^0 sG(s) is defined as the velocity constant and is denoted by Kv ;
Kv = lim sG(s). (5.18)
s- *0
Therefore, the steady-state error in terms of the velocity constant is given by
e„ = 1/KV. (5.19)
Equation (5.19) states that the steady-state response error of a feedback control system
having a unit ramp equals the reciprocal of the velocity constant. Table 5.2 summar￾izes the value of Kv as a function ofthe number of pure integrations of the open-loop
transfer function G(s).170 Performance Criteria 5.4
Table 5.2
Pure integrations of G(s) Kv
0 0
1 K
2 00
n, where n > 1 oo
Table 5.2 indicates that the velocity constant is infinite for all systems which
contain more than one pure integration in the open-loop transfer function G(s).
Therefore, Eq. (5.19) implies that all systems containing at least two pure integrations
have a theoretical steady-state velocity response error of zero. Table 5.2 indicates that
a system containing no pure integrations cannot follow a velocity input. Table 5.2
also indicates that a system containing one pure integration has a nonzero response
error for a velocity input.
3. Unit Parabolic Input An expression for the steady-state error can be obtained
by substituting R(s) = 1/s3 into Eq. (5.9):
C O C 1 11 11 1 • I ^7 • f
s-0 1 -I- G(s) lim s2G(s)
8- *0
The quantity lims_>0 s2G(s) is defined as the acceleration constant and is denoted by
Ka'.
Ka = lim s2G(s). (5-21)
s- *0
Therefore, the steady-state error in terms of the acceleration constant is
ess = \/Ka. (5.22)
Equation (5.22) states that the steady-state response error of a feedback control system
having a unit parabolic input equals the reciprocal ofthe acceleration constant. Table
5.3 summarizes the value ofKa as a function of the number of pure integrations ofthe
open-loop transfer function G(s). Table 5.3 indicates that the acceleration constant
is infinite for all systems which contain three or more pure integrations in the open￾loop transfer function G(s). Therefore, Eq. (5.22) implies that all systems containing
at least three pure integrations have a theoretical steady-state acceleration response
error of zero. Table 5.3 indicates that systems containing less than two pure integra￾tions cannot follow an acceleration input. Table 5.3 also indicates that a system
containing two pure integrations has a nonzero response error for an acceleration
input.5.4 Static Accuracy 171
Table 5.3
Pure integrations of G(s) Ka
0 0
1 0
2 K
3 oo
n, where n > 2 oo
A summary of the results derived appears in Table 5.4. It is quite general and
enables the reader to compare the capabilities of various types of systems. Notice
from this table that the steady-state constants are zero, finite, or infinite. It is
important to emphasize at this time that if the inputs are other than unit quantities
the steady-state errors are proportionally increased. For example, should the input
to a system containing one pure integration’ be a ramp whose value is B
position units (ft/sec, yd/sec, etc.), then the steady-state error as given by Eq. (5.19)
would be modified to read
ess = B/Kv .
It should be noted that the unit of the velocity constant is 1 /sec and that ofthe acceler￾ation constant is 1/sec2. The position constant Kv has no dimensions.
Let us now consider an input composed of position, velocity, and acceleration
which equal A ft, B ft/sec, and C/2 ft/sec2, respectively. The form of the input can
be represented as:
r(r) = A + Bt + <Cz2.
The steady-state response of the system may be obtained by considering each com￾ponent ofthe input separately, and then adding the results by means ofsuperposition.
Table 5.4 Summary of steady state constants for various types
of input
Number of pure
integrations
Type of input
Unit step Unit ramp Unit paraboloid
0 Kv 0 0
1 co 0
2 co 00
3 00 00 CO172 Performance Criteria 5.4
The resulting steady-state error is of the following form:
= A J- A . .2 Css 1 + Kv Kv Ka ‘
It is interesting to see how the various types of systems summarized in Table 5.4
would respond to this input.
Fig. 5.3 Response of a system containing no pure integrations to a step input.
a) System Containing No Pure Integration. The steady-state error is
A
& SS ---
The result indicates that a system containing no pure integration will be able to
follow the position input component of A ft, but not the velocity or acceleration
inputs of B ft/sec and C/2 ft/sec2, respectively. Figure 5.3 illustrates a typical step
response for this system (when there are no velocity or acceleration components of
the input).
b) System Containing One Pure Integration. The steady-state error is
es« — 0 + B/Kv + oo.5.4 Static Accuracy 173
The result indicates that a system containing one pure integration will follow the
position input component with zero error and the velocity input component with a
finite error of B/Kv. This system will not, however, be able to follow the acceleration
input component. Note that the units of B/Kv are feet. This should be interpreted to
mean that there is a fixed positional error due to the constant velocity input com￾ponent. Figure 5.4 illustrates typical step and ramp responses of this system.
Fig. 5.4 Response of a system containing one pure integration to (a) step and (b) ramp
inputs.
c) System Containing Two Pure Integrations. The steady-state error is
ess = 0 + 0 + C/Ka.
The result indicates that a system containing two pure integrations will follow the
position and velocity input components with zero error and the acceleration input
component with a finite error of CfKa. Note that the units of C[Ka are feet. This
should be interpreted to mean that there is a fixed positional error due to the constant
acceleration input component. Figure 5.5 illustrates typical step and ramp responses
of this system.
4. Relationships of Static Error Constants to Closed-Loop Poles and Zeros It is often
important to relate the position, velocity, and acceleration constants to the closed-loop
poles and zeros. Let us consider a general single-loop, unity-feedback system having a174 Performance Criteria 5.4 e ft) r ( r) and eft)
Fig. 5,5 Response of a system containing two pure integrations to (a) step and (b) ramp
inputs.
forward transfer function, G(s), where the closed-loop transfer function is given by
C(s) _ G(s)
R(s) 1 + G(s) ’
and the relationship between input and error is given by
£(s) = 1
R(s) 1 + G(s) ’
Since E(s) = R(s) — C(s), it is evident that
C(s) _ t £(s)
R(s) R(s) ’
It is assumed that C(s)lR(s) can be represented by the rational function
c(s) = K(s + ?i)(s 4- z2) • • • (s 4- zJ = K i (* 4- z3)
R(s) (s + pj)(s 4- p2) • • • (s 4- p„) ILn=i (s 4- Pj)
(5.23)
(5-24)
(5.25)
(5.26a)
In addition, if 1/[1 4- G(s)] in Eq. (5.24) is expanded as a power series in s, the error5.4 Static Accuracy 175
constants are defined in terms of the successive coefficients:
E(s) 1 1 11,
R(S) = i + 0(S)-1 + K; + K/ + K.?+- <526b>
Now the relationships between Kp, Kv, Ka and the closed-loop poles and zeros can be
determined.
a) Position Constant. Letting s approach zero in Eq. (5.24), we have
— = lim----- ------. (5.27) K(0) s-*o 1 + G(s) v 7
Based on the definition of Kp in Eq. (5.15), we can rewrite Eq. (5.27) as
® = ----------. (5.28)
K(0) 1 + Kp
Substituting Eq. (5.28) irta Eq. (5.25) with y set at zero, we obtain the following:
C(0) _ Kp
R(0) 1 + KP ‘
Solving for Kp in terms of C(0)/l?(0), we have
P 1 - C(0)//?(0)
Using Eq. (5.26a) to represent C(s)/7?(y) and letting s approach zero in Eq. (5.26a),
we have
where
C(o)=Ml£ii M)
K(0) ITU P,
m
JI z} = product of zeros,
7?
U p} = product of poles.
Substituting Eq. (5.30) into (5.29), the following expression for KP in terms of the
closed-loop poles and zeros is obtained:
b) Velocity Constant. In order to derive the velocity constant in terms of the closed￾loop poles and zeros, let us substitute Eq. (5.26b) into Eq. (5.25).
C(s) = J _ _ _L s _ J- s2--------
7?(s) 1 + Kj>176 Performance Criteria 5.4
Taking the derivative ofthis expression with respect to s, and then letting 5 equal zero,
we obtain
In addition, we make use of the property that
r^1 = = i (5.33)
LR(s)Js=0 i?(0)
in unity feedback systems containing one or more pure integrations. Equation (5.33)
says that a closed-loop unity feedback system behaves with an ideal closed-loop
transfer function of one at zero frequency. Dividing Eq. (5.32) by (5.33),
1_____ Lds \R(s)/Js=o _ _ r*Lj n C(s)~l
Kv~ [C(s)/K(s)]s=0 Us K(s)_U
Substituting Eq. (5.26a) into this equation, we have the following:
~ [In K + In (s 4- zj + • • ■ + In (s + zm)
Kv [as
- In (s + P1) - ’ ’ ’ - In (s + p„)] .
Js=O
This can also be written as
— ~ -(—— + • • • +---- !— - —— - • ■ • - ——) , (5.34)
Kv \S + Zj S + s + Pl S + P„/s=O
or
1 "1 '"1
7 = (5-35)
2 —1 Pj j—L ~ j
Therefore, l/Kv equals the sum of the reciprocals of the closed-loop poles minus the
sum of the reciprocals of the closed-loop zeros.
c) Acceleration Constant. The acceleration constant in terms of the closed-loop
poles and zeros can be derived in a similar manner. We know from Eq. 5.26(b) that
£(s) 1 , 1 , 1 , , — + s 4- s 4- • ■ • .
R(s) 1 + K„ Kv K„
From Eq. (5.25), this can be rewritten as
C(s) . 1 1 1 ,
------ = 1 — ----------- — --- 5 —----5“ — ■ < •
*(s) I 4- Kp Kc Ka5.4 Static Accuracy 177
It is obvious from this equation that — 2/Ka equals the zero-frequency value of the
second derivative of C(s)/R(s). Writing this in terms of the logarithmic derivative:
d!rlnWl = (C/R)" _ IKM
ds2L K(s)J C/R L CIR J ’
Setting C(0)/7?(0) equal to one, then
_a = (^rlnwn ,_l
Ka U2L K(s)Jjs=o K*'
Differentiating the right-hand side of Eq. (5.34) and letting s equal zero yields the
following expression:
where Kv is defined by Eq. (5.35).
d) An Example. As an example, let us consider the second-order system illustrated
in Fig. 4.1 whose characteristics are defined by Eqs. (4.1), (4.2), and (4.3):
C(s) _ KJTm
R(s) s2 + (1/Tm)s + Km/Tm ’
or
C(s) _ co2
7?(s) s2 + 2£cons + co2’
where
co2 = KjTm and I = l/2co„Tm.
This is representative of a wide class of control systems that was thoroughly analyzed
in Section 4.2. The problem is to determine Kv in terms of the parameters £ and co„.
Km is the system gain and Tm is the time constant of the open-loop transfer function.
The velocity constant of the simple system illustrated in Fig. 4.1 is
= Km
by inspection. Let us relate this velocity constant to £ and co„ from the basic definitions
of Km and Tm in terms of £ and co„:
The fact that
Kv = co„/2£ (5.37)
is very important to rememberfor all second-order control systemsthat are characterized
by a pair of complex-conjugate poles.178 Performance Criteria 5.5
5.5 TRANSIENT RESPONSE
In addition to stability, sensitivity, and accuracy, we are always concerned with the
transient response of a feedback system. Transient response characteristics are
usually defined on the basis of a step input. The response of a second-order system,
containing one pure integration, to a step input is quite useful for purposes of defining
the various transient parameters. Should a problem arise where the system is higher
than second order, a reasonably good approximation can be made by assuming that
the system is second order if one pair of complex-conjugate roots dominate. This
point is amplified during the discussion of the root locus in Chapters 6 and 7. For
purposes of illustration, let us consider the second-order system analyzed in Section
4.2. There we had a unity feedback system whose closed-loop transfer function
C(s)/R(s) was given by
£0) = . M38)
R(s) s2 + 2£to„s + co2
Its response to a unit step input, for the case of £ < 1, was given by
Fig. 5.6 Response of a second-order system to a unit step.5.5 Transient Response 179
The time for the feedback system to reach its first overshoot is commonly referred
to as the time to the first peak, tv. As was derived in Section 4.2 (see Eq. 4.29) and is
illustrated in Fig 5.6,
77
(t>nh ,--------- ,
Vi - r
or
time to first peak = tp =----- — . (5.40)
1 —
The time required for the system to damp out all transients is commonly called
the settling time, ts. Theoretically, for a second-order system this is infinity. In
practice, however, the transient is assumed to be over when the error is reduced
below some minimum value. Typically, the minimum level is set at 2% of the final
value. The settling time, which is approximately equal to four time constants of
the envelope of the damped sinusoidal oscillation, is illustrated in Fig. 5.6 and is
given by
t, = 4/^„. (5.41)
The rise time tr is defined as the time required for the response to rise from 10% to
90% of its final value. Figure 5.6 illustrates the rise time for the response shown.
Upon the application of a step input, the output of a feedback system will usually
exceed the input. As is illustrated in Fig. 5.6, a second-order system may oscillate
several times around the steady-state output, depending on the value of the damping
ratio £. The first overshoot is of particular interest; the ratio of this overshoot’s
peak value to the steady-state settling value of the system is usually expressed as a
percentage. The amount of overshoot allowable depends entirely on the particular
problem. An overshoot of 10% is reasonable. Notice that the percentage overshoot
of the system illustrated in Fig. 5.6 is exp (—£tt/x/1 — C2) X 100%. A 10% over￾shoot corresponds to a damping ratio of approximately 0.6 for this system.
Even though suitable and reasonable values for rise time, settling time, and the
peak overshoot have been chosen, one is not sure whether a good system has been
designed. For example, ifthe rise time is very small, invariably the peak value of the
overshoot increases and so does the settling time. On the other hand, if the design is
for minimum overshoot, the rise time increases. In order to resolve the conflict that
exists between rise time, peak overshoot, and settling time, criteria have been proposed
for synthesizing optimum transient performance. Most of these criteria consider that
the error and/or the time at which the error has occurred during the transient is
important [1,2]. Several of these criteria are presented in the remainder of this
chapter.180 Performance Criteria 5.6
5.6 PERFORMANCE INDICES
Modern complex control systems usually require more sophisticated performance
criteria than those presented so far. As seen in the previous section, error and the
time at which it occurs are very important factors which usually must be considered
simultaneously. A performance index is a single measure of a system’s performance
which emphasizes those characteristics of the response that are deemed to be
important. The notion of a performance index is very important in optimal control
theory where the system is designed to optimize this performance index given certain
constraints. This subject will be discussed fully in Chapter 9.
References 1 and 2 discuss an entire class of performance indices which are
various functions of error and/or time. This section reviews those which seem useful
in the design of practical control systems.
A fairly useful performance index is the integral of the absolute magnitude of the
error (IAE) criterion which is
| l*(0l dt. o
(5-42)
By utilizing the magnitude of the error, this integral expression increases for either
positive or negative error, and results in a fairly good underdamped system. For a
second-order system, has a minimum for a damping factor of approximately 0.7.
The simplicity ofthis performance index makes it very applicable to analog-computer
simulation.
Another useful performance index is the integral of the square of the error (ISE)
criterion which is
S2 (5-43)
By focusing on the square ofthe error function, it penalizes both positive and negative
values of the error. For a second-order system, S2 has a minimum for a damping
factor of approximately 0.5.
A very useful criterion which penalizes long-duration transients is known as the
integral of time multiplied by the absolute value of error (ITAE). It is given by
S3 = | t |e| dt.
Jo
(5-44)
This performance index is much more selective than the IAE or the ISE: the minimum
value ofits integral is much more definable as the system parameters are varied. For
a second-order system, S3 has a minimum for a damping factor of 0.707.
Other figures of merit which have been proposed are the integral oftime multiplied
by the squared error (ITSE), the integral ofsquared time multiplied by the absolute
value of error (ISTAE), and the integral ofsquared time multiplied by square error5.6 Performance Indices 181
(ISTSE). These performance indices are
'o
ITSE: S4 =j te2 dt, (5.45)
'o
P 00
ISTAE: s5 =J l2 |e| dt,
0
(5.46)
ISTSE: s6 = |Rt2e2 dt.
(5-47)
The performance indices S4, S5, and Sc have not been applied to any great extent in
practice due to the increased difficulty in handling them.
Note that all of the integrals proposed in Eqs. (5.42) through (5.47) converge only
if e(t) —► 0 as t -> co.
A comparison of this array of performance indices is very interesting. The ISE
criterion is not very sensitive to parameter variations since the minimum is usually
broad [11]. In addition, the ISE criterion has the advantage of being easy to deal with
mathematically. The IAE criterion gives a slightly better sensitivity than the ISE
criterion. The ITAE criterion generally produces smaller overshoots and oscillations
than the IAE and ISE criteria. In addition, it is the most sensitive of the three, and
sometimes too sensitive—slight parameter variation degrades system performance
[1,2].
In practice, a relatively insensitive criterion may be more useful in those systems
where the parameters may not be known very accurately. In addition, even though
one tries to optimize a performance criterion, one may also have other performance
characteristics in mind. Therefore, it is desirable in some applications to permit
moderate deviation from the “optimum” setting of the parameters in order that these
other performance characteristics can be achieved without appreciably increasing
the performance index. Based on this logic, the ISE criterion may be the most
desirable performance index in some practical applications and is considered further
in Chapter 9 when optimal control theory is discussed. In addition, the reader is
referred to Chapter 2 of Reference 11 for additional considerations of the ISE
criterion.
The ITSE criterion has not been studied in great detail [1]. However, available
data indicate that it will probably result in being a valuable performance criterion.
Very limited information is available on the ISTAE performance criterion, and a
judgment cannot be made here [1]. Data available on the ISTSE criterion indicate
that it does result in good responses for systems containing one integration in the
open-loop transfer function [1], Information on the resulting response with more
than one integration in the open-loop transfer function is not available.
A paper by Graham and Lathrop [2] created a great deal of interest in the ITAE
criterion. An important aspect of this paper was the detailed discussion and presen￾tation of results of a comparison for various performance criterion with the ITAE.
It is more sensitive than the IAE and ISE criteria, and is useful in those practical182 Performance Criteria 5.7
applications which require a very sensitive criterion. Since the ITAE criterion has
practical value and is interesting academically, this performance criterion is studied
further. First, however, we are interested in determining the form of the closed-loop
system transfer function in order that zero error results for various kinds of inputs.
This is necessary in order to determine the relationship of the various coefficients in
the numerator and denominator of the closed-loop system transfer function.
5.7 ZERO-ERROR SYSTEMS
The transfer function of the general feedback system, containing a forward transfer
function G(s) and a feedback transfer function H(s), is given by the general expression
C(s) G(s) Axsl + A2s' 1 + A3sl '+••• + AjS + A,^
= ----- --- ---------- 1 = — . (j.4o)
R(s) 1 + G(s)H(s) B1Sm + B2sm-1 + B3s™-2 + ’ ’ ' + Bms + Bm+1
From Eq. (5.26b) of Section 5.4, the error for this system can be expressed as*
* It is assumed that the input and all of its derivatives do not have any discontinuities in the
interval of interest.
r(0 r(0 r(t)
1 + K„ Ka
(5-49)
It can be shown [2] that 1 + Kp is a function of Bm+1 — Al+1. Therefore, it is
necessary that Bm+1 = Ai+1 for zero steady-state error when the input is a step function.
In addition, this implies that the forward transfer function contains at least one pure
integrator as discussed previously in Section 5.4. From the general system transfer
function of Eq. (5.48), it can be seen that there are many possible forms of C(s)lR(s)
which will yield zero steady-state error with a step input. When the numerator consists
ofthe constant Bm+1, the system is called a zero steady-state step error system [2]:
C(s) = ________________ B,„+1________________
B(s) B,sm + B2s"'-1 + B3sm~2 + ■■■ + Bm+1 ’
(5.50)
It can also be shown [2] that Kv is a function of Bm+1 — Ti+1 and Bm — Av
Therefore, for zero steady-state error with a ramp input, Bm = At and Bm+l = Al+1.
In addition, this implies that the forward transfer function contains two or more pure
integrators as discussed previously in Section 5.4. A zero steady-state ramp input
system occurs when the system transfer function is given by
c(s) =________________ Bms + B,n+l________________
R(.s) B1S’n + B2sm~l + B3sm~2 + ■■■ + Bms + Bm+l '5.8 The ITAE Performance Criterion 183
5.8 THE ITAE PERFORMANCE CRITERION
FOR OPTIMIZING THE TRANSIENT RESPONSE
The ITAE performance index, as defined by Eq. (5.44), is considered further in this
section. As discussed in Section 5.6, this performance index does not penalize large
initial errors which are unavoidable. However, it does penalize long duration
transients. We now consider the form that the system transfer function should take,
for various order systems, in order to achieve zero steady-state step and ramp error
systems and minimize the ITAE.
In the case of the zero steady-state step error system, Eq. (5.50) shows that the
form of the system transfer function is given by
^•'(s) _ ________________$m+l______________
R(s) “ B1Sm + B2sm~x + B3sm-2 + • • • + Bm+l ‘
The procedure used to produce a table of standard system transfer functions of the
form C(s)/R(s) was to vary each coefficient in Eq, (5.52) separately until the integral
of time multiplied by the absolute value of error became a minimum. Then the
successive coefficients were varied in sequence to minimize the ITAE value.
If this criterion is applied to the second-order system described by Eq. (5.38),
the optimum damping ratio is approximately 0.707. A table of system transfer
functions, C(s)/R(s), has been prepared by Graham and Lathrop [2]. They show the
optimum form of the denominator, for systems whose transfer functions are of the
form given by Eq. (5.52), which will minimize the integral of Eq. (5.44). For example,
the optimum form for a second-order system is given by
C($) _ fJ)n 53)
R(s) s2 + 1.414wns co2
where £ = 1.414/2 = 0.707. The optimum form for a third-order system is given by
________________ _______________ (5-54)
R(s) s3 + 1.75co„s2 + 2.15co2s + co3
Table 5.5 The minimum ITAE standard forms for a zero-error-displacement system [2]
s + co„
S2 + 1.4lO„S + CO2
s3 + 1.75co„s2 + 2.15co’s + co’
s4 + 2.1co„j3 + 3.4co’s2 + 2.7a>3s + co4
+ 2.8co„s4 + 5.0co>3 + 5.5<o3.v2 + 3.4co4s + co3
se + 3.25co„s6 + 6.60co>4 + 8.60co3s3 + 7.45w>2 + 3.95co’s + co3
+ 4.475cd„56 + 10.42co2s6 + 15.08co’s4 + 15.54co4s3 + 10.64co’s2 + 4.58co“s + co’
+ 5.20cons7 + 12.80co2s6 + 21.60co3? + 25.75co4? + 22.20<? + 13.30co’s2 + 5.15co^ + co31S4 Performance Criteria 59
Table 5.5, which has been obtained from Reference 2, shows the optimum
denominator transfer function tor svstems through the eighth order which will
minimize the integral of Eq. (5.44). These standard forms provide 3 quick and simple
method for synthesizing an optimum dynamic response.
In the case of the zero steady-state ramp error systems, the system transfer
function was shown in Eq. (5.51) to be given by.
C(s) _ ________________ 4- Ba,_}______________________
R(s) ~ Bp” + B^s ** -1 + Bp' *' 2 + - - ■ + Bks + b\-t
The objecme here also is to obtain a set ofstandard forms for the denominators ofthe
svstem transfer functions given bv Eq. 5.55 Table 5.6, obtained from Reference 2,
w as similarly obtained as Table 5.5.
Table 5.6 The minimum ITAE standard forms for a zero-error ramp system [2],
s2 + 3.2rap- + roj
ss + ITOWhS2 -r 3 25<u~.c — to2
s* + 2.41 ei.s3 4- 4.93a>;s2 -t- 5.I4ra®S +
s® + 2.19<u-.c + 6.50e>2ss + 6.3Qo|s2 + 5,24e>t-S +
s® + G.IZcOrS5 + 13.42«u;s4 + 17.1 6ro8.A + 14.14«il? + 6.76ro|s + ra®
The ITAE criterion is applied to several problems in the problem section of this
chapter (see Problems 5.17 through 5.21).
The ITAE criterion is a straightforward method for optimizing the transient
response of a system when the transfer function is known. Generally, it produces
smaller overshoots and oscillations than the other criteria presented It should be
emphasized, however, that the ITAE solution is very sensitive and mav not be useful
tor certain systems where most of the svstem poles and zeros and gains may be
specified initially. For the latter case, the designer does not have the flexibility for
selecting as many of the parameters as he might wish.
5.9 OTHER PRACTICAL CONSIDERATIONS
The control engineer must concern himself w ith several other practical aspects before
becoming able to state intelligently and completely the expected system performance.
The concluding section of this chapter qualitativelx discusses considerations of feed￾back system bandwidth, nonlinearities, size, weight, power consumption, and
economics. Hopefully, this will aid in giving the reader a complete overall view ofthe
problem.Problems 185
Feedback system bandwidth is usually defined as the frequency at which the
closed-loop magnitude equals unity. The bandwidth of a system is indicated by its
particular application. Usually, the control engineer is interested in designing the
system to respond to a certain spectrum of input signal frequencies and to suppress all
inputs above a certain frequency. It is important to emphasize that we should not
arbitrarily design for a large bandwidth. Although large bandwidths usually result in
large error constants, with small resulting system error, they also result in a system
that responds to extraneous noise inputs and has considerable jitter due to the noise.
The desirable approach is to design the feedback system bandwidth to be just large
enough to pass the desired input-signal frequency spectrum and then attenuate all
higher frequency signals [3], Feedback system bandwidth considerations are dis￾cussed in detail in Chapters 6 and 7, where methods for obtaining the frequency
response are presented.
Nonlinearities are other factors which affect the performance of a control system.
Primary concern is with backlash, stiction, and coulomb friction. Backlash, which
was described in Section 5.3, is the amount offree motion of one gear while its mating
gear is held fast. Stiction is the frictional force which prevents motion until the driving
force exceeds some minimum value. Coulomb friction is a constant frictional drag
which opposes motion, but has a magnitude that is independent of velocity. Each of
these nonlinearities has an effect on the performance offeedback systems. More will be 
said regarding nonlinearities in Chapter 8.
Other factors of concern are size, weight, power consumption, and economics.
The system must conform to certain specifications of size and weight. These are very
important factors which usually dictate the design of the system. For example, these
specifications may decide the type of power drive to be used. Power is another very
important consideration. The system must usually perform within a certain allowable
power limitation. Size, weight, and power consumption are usually very critical items
for airborne and space applications. Last, but not least, is the question of economics.
A basic fact of life is that most engineers work for organizations whose primary
purpose is to make profit. Systems must therefore be designed as inexpensively as
possible within the framework of good performance. A generally useful rule ofthumb
is that minimum bandwidth systems will consume the least power and be the most
economical.
PROBLEMS
5.1 Assume that the system shown in Fig. P5.1 has the following characteristics:
= 10 V/rad,
K2 = 10 V/rad,
100186 Performance Criteria
Figure P5.1
a) Determine the sensitivity of the system’s transfer function T with respect to the input
transducer, Kt.
b) Determine the sensitivity of the system’s transfer function T with respect to the output
transducer, K2.
c) Determine the sensitivity of the system’s transfer function T with respect to G.
d) Indicate qualitatively the frequency dependency of S@.
5.2 For the system in Fig. P5.2, assume the following characteristics:
10
^ = 10V/rad,
20
K2 = 10 V/rad, G2 = ------- — ,
2 2 s(s + 2)
K3 = 2 V/rad, H = 4s.
a) Determine the sensitivity of the system’s transfer function T with respect to Gj at co = 1
rad/sec.
b) Determine the sensitivity of the system’s transfer function Twith respect to G2 at co = 1
rad/sec.
c) Determine the sensitivity of the system’s transfer function Twith respect to H at co = 1
rad/sec.Problems 187
d) Determine the sensitivity of the system’s transfer function T with respect to K3 at co =1
rad/sec.
e) List the answers of parts (a) through (d) in tabular form with the lowest value first and the
largest value last in the vicinity of co =1. Normalize your table with respect to the
lowest sensitivity found. How could this table change for a different choice offrequency?
5. 3 Figure P5.3(a) illustrates the block diagram of a computer-controlled machine tool
which utilizes a position loop and a correction loop [4]. A practical problem in machine-tool
(a)
Sensor and
computer
correction
(b)
Figure P5.3188 Performance Criteria
application is the fact that the desired tool position is ordinarily fed back by the position loop
as shown, but this is not indicative ofthe condition and shape ofthe finished part. In reality,
the finished part is ordinarily removed from the feedback effect due to the tool-work inter￾face. Since these effects are complex and difficult to predict, the process output will not
conform precisely to that desired by the programmer. By means of the correction loop,
information is obtained from the process output by means of sensors coupled as closely as
possible to the tool-work interface. These sensor signals, which represent variables such as
torque, vibration, and temperature, are fed back to improve the performance of the machine
tool control system. Figure P5.3(b) illustrates an equivalent block-diagram representation,
a) With switch open and the correction loop inoperative, determine the sensitivity of the
system’s transfer function T to variations of Km, Tm, and Kv
b) Repeat part (a) with switch Sx closed and the correction loop operative.
c) What conclusions can you draw from your results?
5.4 For the system illustrated in Fig. P5.4 assume the transfer functions indicated.
Figure P5.4
a) Determine the sensitivity of the system’s transfer function with respect toGx(j).
b) Determine thesensitivity of the system’s transfer function with respect to G3(s).
c) Determine thesensitivity of the system’s transfer function with respect toH3(s).
d) Determine thesensitivity of the system’s transfer function with respect toH^s).
e) List the answers of parts (a) through (d) in tabular form with the lowest value of sen￾sitivity first and the largest value last at a frequency of 1 rad/sec. Normalize your table
with respect to the lowest sensitivity found. How could this table change for a different
choice of frequency ?
5.5 Automatic control theory can also be applied to automatic warehousing and inventory
control systems [5]. Of particular importance in these systems is the smooth flow of material.
Fig. P5.5 illustrates a block diagram that is representative of this class of control systems,
a) Determine the sensitivity of the system’s transfer function C(s)/R(s) with respect to pro￾duction planning, G^s).
b) Determine the sensitivity of the system’s transfer function with respect to production,
G2(s)Figure P5.5Warehouse functions
Problems 189190 Performance Criteria
c) Determine the sensitivity of the system’s transfer function with respect to the various
warehouse functions, G3(i).
d) Determine the sensitivity of the system’s transfer function with respect to incoming
orders, G^s).
e) Determine the sensitivity of the system’s transfer function with respect to the inventory
policy, K2.
f) For which two parameters is the system most sensitive, and what conclusions can you
reach from your results?
g) Indicate qualitatively the frequency dependency of the sensitivity functions.
5.6 The block diagram of a simple instrument servomechanism is shown in Fig. P5.6.
a) Determine the steady-state error resulting from the input of a ramp which may be 
represented by
r(t) = lOt.
b) Determine the steady-state error resulting from the following input:
r(0 = 4 + 6t + 3r2.
5.7 Repeat Problem 5.6 with the transfer function of the system given by
10
G(s) = ------------------------.
V 5(1 + J)(l + 105)
5.8 For the system shown in Fig. P5.8, determine the following:
a) Steady-state error resulting from an input
r(f) = 10t.
b) Steady-state error resulting from an input
r(r) = 4 + 6t + 3?
Figure P5.8Problems 191
c) Steady-state error resulting from an input
r(r) = 4 + 6r + 3r2 + 1.8r3.
5.9 Repeat Problem 5.8 with the transfer function of the system given by
10
s2(l + s)(l + 10s) '
5.10 A common problem in the television industry is that of picture wobbling or jumping
due to movement of the TV camera while a picture is being taken. The effect of this problem
is easily understood by examining Figs. P5.10(a) and (b). When the camera is at rest (as
illustrated in Fig. P5.10(a) a light-ray entering the camera lens impinges on point A within
the camera. However, if the camera isjolted upward through an angle <5 (as in Fig. P5.10b),
the light ray is displaced from its original location at point A to point B. This can be corrected
by means of the system illustrated in Fig. P5.10(b). The concept utilizes a device which
changes the shape of a fluid lens such that the ray’s impinging point does not move [6], The
front transparent plate is rotated in the vertical plane by a torque motor. The rear plate is
rotated in the horizontal plane. Two rate gyros are mounted in the camera to detect any
disturbances. Their output is fed to a servo amplifier which adjusts the driving current to the
Bellows
Zoom lens
Light ray
Transparent plates
Camera Vertical axis
torque motor
Horizontal axis
torque motor
Light ray
Fluid lens formed into
prism by torque motor
(b)
Camera Bellows
Motor parameters
K„=0.4
Tm =0.2
(c)
Fig. P5.10 (From Control Engineering published by The Reuben H. Donnelley Corp.
Reproduced by permission.)192 Performance Criteria
torque motors. Tachometers close the rate feedback loops. The equivalent block diagram of
one such axis is illustrated in Fig. P5.10(c). Observe that the feedback loop uses speed from
the rate gyro as the reference input and speed from the tachometer to indicate speed of the
bellows.
a) Determine the required value of amplifier gain K in order that the steady-state error
resulting from a camera scanning speed of 50°/sec is only l°/sec.
b) What is the steady-state error of this system resulting from camera accelerations of any
magnitude ?
5.11 A servomechanism, shown in Fig. P5.ll, is used to drive an inertia load through
gearing of negligible inertia.
Figure P5.ll
1. AC motor characteristics: Torque-speed slope = 4.5 x 10~6 lb ft/(rad/sec). Stall torque
constant =8.5 x IO-6 (lb ft)/V.
2. Load inertia = = 40 x 108 lb ft sec2 (Assume JmN2 « Jl)
3. Amplifier gain = 10
4. Gear ratio =9:1 (steps motor speed down)
a) What is the transfer function G(s) relating C(s) and E(s) of the system?
b) What are the undamped natural frequency a>n and the damping factor £?
c) What is the percent overshoot and time to peak resulting from the application of a
unit step input?
d) Whatis the steady-state error resulting from application of a unit step input?
e) Whatis the steady-state error resulting from application of a unit ramp input?
f) Whatis the steady-state error resulting from application of a parabolic input?
5.12 Repeat Problem 5.11 with the assumption that the motor inertia, Jm, is 1.11 x 10-6
lb ft sec2.
5.13 Repeat Problem 5.11 with a motor inertia of 1.11 x 10 6 lb ft sec2 and the amplifier’s
gain increased to 100.
5.14 Automatically controlled machine tools form an important aspect of control-system
application. The major trend has been towards the use of automatic numerically controlled
machine tools using tape inputs. The justification of using tape has been the elimination
of costly contour templates and the reduction of the machine set-up procedure required.
In addition, it eliminates the tediumof repetitive operations required of human operators, and
the possibility of human error. Figure P5.14 illustrates the block diagram of an automatic
numerically controlled machine-tool position control system, using a punched tape reader,
to supply the reference signal.
a) What are the undamped natural frequency con and damping factor
b) What are the percent overshoot and time to peak resulting from the application of a
unit step input?Problems 193
Figure P5.14
c) What is the steady-state error resulting from the application of a unit step input?
d) What is the steady-state error resulting from the application of a unit ramp input?
5.15 Modern ocean-going ships utilize stabilization techniques in order to minimize the
effects of oscillations due to waves. By utilizing hydrofoils or fins, stabilizing torques can be
generated in order to stabilize the ship [7]. Figure P5.15(a) illustrates this concept employing
stabilizing fins. An equivalent block diagram of the system is illustrated in Fig. P5.15(b).
Figure P5.15 (b)194 Performance Criteria
Tachometer (a)
J=1 K] = 5
(b) 6 = 0.1 K2 = 0.5
Figure P5.16Problems 195
The reference input signal, 6de8ired, is normally set equal to zero. A vertical gyro, which
senses deviationsfrom 0=0, feeds back a correction signal which activatesthe fins in order to
drive the error signal to zero. The disturbance signal, CZ(^), represents the disturbance
torque due to the waves.
a) Determine the effect of the disturbance torque U(s~) on system error E(s) if it is assumed
that K^G^s) » 1. What conclusions can you draw from your result?
b) Based on the approximation of part (a), what should Kr be set at in order to reduce a
disturbance torque input at U(s) of 10° to an equivalent system error of 0.1° ?
5. 16 As digital computers become more common in every phase ofindustry and the scientific
communities, there is an ever increasing demand for the storage and speedy retrieval of data.
The resulting control-system requirements imposed are usually quite stringent and usually
require new techniques. Figure P5.16(a) illustrates a system used to control the position of
the read/write heads in a random-access magnetic-drum memory system [8]. The particular
application had 64 data heads mounted in vertical pairs at 2-inch intervals along a “headbar.”
Although the controlling action is obtained by utilizing digital components, an equivalent
representation of the control system is given in Fig. P5.16(b).
The headbar is free to move longitudinally. It is located between two magnetic drums
whose axes of rotation are parallel with the longitudinal axis of the headbar. Each of the
data heads in this system has access to a total of 200 tracks. The track accessed depends on the
placement ofthe headbar within the limits ofits 2-inch travel. A fine and a coarse positioning
loop are used to obtain the desired accuracy. An electronic switch Sj switches the system so
that it has a large amount of gain for large errors so that the system responds rapidly. For
this condition, a large amount of overshoot is tolerated in order to achieve a fast rise time.
For small errors, the fine system is activated which has a larger damping factor, smaller
overshoot, and a somewhat longer response time. Assume that the system switches when
e(t) = 0.1 unit.
a) Determine the undamped natural frequency, damping factor, overshoot, and time to
peak for the “coarse” loop.
b) Repeat part (a) for the “fine” loop.
c) Determine the error of the “coarse” and “fine” loops to a unit step input,
d) Determine the error of the “coarse” and “fine” loops to a unit ramp input,
e) Determine the error of the “coarse” and “fine” loops to a unit paraboloid input.
Figure P5.17196 Performance Criteria
5.17 A fourth-order feedback system containing three feedback paths is illustrated in Fig. 
P5.17. In order to satisfy the ITAE criterion, determine the values of K19 and 02.
5.18 Utilizing an analog computer, determine the overshoot and rise time of the transient
response for the system considered in Problem 5.17 to a step input as Klt and />2 are each
varied ±100% [9, 10, 12].
5.19 Determine the values ofKlt K2, and b, in the feedback system illustrated in Fig. P5.19,
which will satisfy the ITAE criterion.
Figure P5.19
5.20 Repeat Problem 5.19 with the acceleration feedback element attenuated by a factor of
0.5. What conclusions can you draw from your result?
5.21 Repeat Problem 5.19 if the gain ofthe acceleration feedback element is doubled. What
conclusions can you draw from your result?
5.22 Figure P5.22 illustrates an electronic pacemaker used to regulate the speed of the
human heart. Assume that the transfer function of the pacemaker is given by Gv(s) =
K/(0.05.v + 1) and assume that the heart acts as a pure integrater.
a) For optimum response, a closed-loop damping factor of 0.5 is desired. Determine the
required gain, K, of the pacemaker in order to achieve this.
b) What is the sensitivity of the system transfer function, C(.s)//?(s), to small changes in
K'l
c) Determine this sensitivity at DC.
d) Find the magnitude of this sensitivity at the normal heart rate of 60 beats/minute.
Figure P5.22References 197
5.23 A control system used to position a load is shown in Fig. P5.23.
a) Determine the steady-state error for a step input of 10 units.
b) How should G(s) be modified in order to reduce this steady-state error to zero?
Figure P5.23
5.24 Repeat Problem 5.6 for
G(s) =
10(5 + 1)
s2(0.1s + l)(s + 5)’
REFERENCES
1. W.C. Schultz and C. V. Rideout, “Control system performance measures: Past, present,
and future,” IRE Trans. Automatic Control AC-6, 22 (1961).
2. D. Graham and R. C. Lathrop, “The synthesis of optimum transient response: Criteria
and standard forms,” AIEE Trans. 72, 273 (1953).
3. S. M. Shinners, “Minimizing servo load resonance error with frequency selective feed￾back,” Control Eng. 51, 51-56 (January 1962).
4. R. M. Centner and J. M. Idelsohn, “Adaptive controller for a metal cutting process,” in 
Proceedings ofthe 1963 Joint Automatic Control Conference, pp. 262-71.
5. R. Dallimonti, “Developments in automatic warehousing and inventory control,” in
Proceedings ofthe 1965 Joint Automatic Control Conference, pp. 281-5.
6. J. de la Cierva, “Rate servo keeps TV picture clear,” Control Eng. 12, 112 (May 1965).
7. J. Bell, “Control for ship stabilization,” in Proceedings ofthe 1st InternationalFederation
ofAutomatic Control Congress, Butterworth, London, (1960), pp. 208-17.
8. R. Tickell, “A high performance position control,” in Proceedings of the 1966 Joint
Automatic Control Conference, pp. 230-42.
9. G. A. Korn and T. M. Korn, Electronic Analog and Hybrid Computers, McGraw-Hill,
New York (1964).
10. J. R. Ashley, Introduction to Analog Computation, Wiley, New York (1963).
11. G. C. Newton, Jr., L. A. Gould, and J. F. Kaiser, Analytical Design ofLinear Feedback
Controls, Wiley, New York (1961).
12. S. M. Shinners, “Which computer-Analog, digital, or hybrid?” Machine Design 43,
104-111 (January 21, 1971).6
TECHNIQUES FOR DETERMINING
CONTROL-SYSTEM STABILITY
6.1 INTRODUCTION
For proper controlling action, a feedback system must be stable. Previous chapters
have indicated that feedback systems have the serious disadvantage that they may
inadvertently act as oscillators. A feedback control system must maintain stability
when the system is subjected to commands at its input, extraneous inputs anywhere
within the feedback loop, power supply variations, and changes in the parameters of
the elements comprising the feedback loop.
In the ensuing discussion, if, for every bounded input, the output is bounded, then
the system is stable. In this chapter, analysis is limited to linear time-invariant
systems, that is, systems for which the principle of superposition is valid and which
may be described by an ordinary linear differential equation with constant coefficients.
The analysis of nonlinear systems is presented in Chapter 8.
This chapter focuses attention on the stability of the general feedback system
which was illustrated in Fig. 2.12. The closed-loop transfer function of this system,
given by Eq. (2.117), is repeated below:
a)=ga
K(s) 1 + G(s)H(s)
The characteristic equation for this generalized system can be obtained by setting the
denominator of the system transfer function equal to zero:
1 + G($)H(s) = 0. (6.2)
In linear systems, stability is independent of the input excitation, and this is the
equation that determines system stability. All the methods of stability analysis
investigate this equation in some manner. One can show that ifthe roots of Eq. (6.2)
lie in the left half-plane, the system is stable. However, the system is considered
unstable if any of the roots of this equation have positive real parts or lie on the
imaginary axis.
In general, the following two approaches exist for determining stability:
1. Calculating the exact roots of Eq. (6.2)
2. Determination ofthe region of system parameters which guarantees that the roots
of Eq. (6.2) have negative real parts.
1986.2 State-space Determination of the Characteristic Equation 199
Using the first approach, the control engineer has at his disposal the following two
methods:
a) Direct solution utilizing the classical approach
b) Root-locus method
Using the second approach, the control engineer has at his disposal the following
criteria:
a) Routh-Hurwitz criterion
b) Nyquist criterion.
Clearly, calculation of the exact roots using the classical approach can be extremely
tedious. Usually, the designer is interested in the root-locus method and the criteria
of the second approach. This chapter presents each of these methods, except the
classical approach, together with theirrelativemerits. Additional graphical approaches
based on the Nyquist criterion are also discussed. These include the use of the Bode
diagram and Nichols chart. Application of these methods to actual design is deferred
to Chapter 7.
6.2 STATE-SPACE DETERMINATION OF THE CHARACTERISTIC EQUATION
The characteristic equation can also be defined in terms of the state-space equation
of the control system. We have stated in the previous section that stability is in￾dependent of the input. Therefore, the condition x(r) = 0, where x(z) is the state
vector, can be viewed as the equilibrium state of the system. Let us assume that a
linear system is subjected to a disturbance at t = 0 resulting in an initial state, x(0),
that is finite. If it returns to its equilibrium state as t approaches infinity, the system
is considered to be stable. If it does not, in terms of our definition, it is considered
to be unstable. These concepts of stability can be generalized. In the state-space
approach [1, 2], a linear system is considered to be stable if, for a finite initial state
x(0), there is a positive number A, that depends on x(0), where
||x(f)|] < A for t >0, (6.3)
lim ||x(0ll = 0. (6.4)
t-> 00
The value ||x(t)|| denotes the norm of the state vector x(t). It is defined as
r n -|l/2
I|X(OII = Xx3.(t)2 • (6.5)
b=i J
Equation (6.3) can be interpreted to mean that the transition of state for positive
time, as represented by the norm of the vector x(t)‘ is bounded. Equation (6.4) can
be interpreted to mean that the system must reach its equilibrium point as t approaches
infinity. Figure 6.1 illustrates the state-space stability criterion for a second-order
system having states and x2. Observe from this figure that a cylinder, whose
radius is A, forms the bound for the trajectory as time increases. As time approaches
infinity, the linear system reaches the equilibrium point x(t) = 0. Note that, strictly200 Techniques for Determining Control-system Stability 6.2
Fig. 6.1 State-space stability concept.
speaking, the above definition corresponds to asymptotic stability.* For simplicity,
we will call the system stable if Eqs. (6.3) and (6.4) hold.
* According to Liapunov, this is asymptotic stability—the type of stability preferred by
control system engineers. This is defined and discussed in detail in Section 8.17 on Liapunov's
stability criterion.
Let us next develop analytically, and apply, the state-space approach for
determining the stability of a linear system. It will be shown that this method
determines the location of the roots of the characteristic equation, and restricts the
roots of the characteristic equation to the left half-plane for stability.
Consider the general differential equation of a linear system in scalar form:
+ ■■■ + Aoc(t) = r(t), (6.6)
dt dt 1
where all the coefficients are constants, An 0, r(/) represents the input to the
system, and c(r) represents the system output. Since the input does not affect stability,
it is assumed to be zero. The Laplace transform of Eq. (6.6) is given by
C(s)[/M" + A^s”-1 + • • • + Jo] = 0. (6.7)
Stability can be determined from the characteristic equation of this system:
Ansn + + • • • + Ao = 0. (6.8)
It remains now to determine the roots of this equation.
The nth-order differential equation, given by Eq. (6.6), may also be specified by
n first-order differential equations. By defining
*1 = c(t),
dnc(t)6.2 State-space Determination of the Charactistic Equation 201
the linear system can be specified by the following set of first-order differential
equations:
*1 = 4uxx + • • • + Alnxn + B11r1,
(6.10)
AniX^ 4" ’ ’ ’ 4" AnnXn 4“ ^nl^l ’
which is equivalent to Eq. (6.6).
The set of equations (6.10) is solved for the case where the input r(f) equals zero;
assume an exponential solution of the form
xi=fest, (6.11)
whereis an unknown constant. To check the form of the assumed solution, Eq.
(6.11) is differentiated and the result is substituted into the set of equations (6.10).
Differentiating (6.11), we obtain
xi=fi(se’t). (6.12)
Substitution of Eqs. (6.11) and (6.12) into (6.10) results in
fisest = + ■■■ + AXnfnest,
(6.13)
fnsesl = Anifxest 4- • • • 4- Annfnest.
Equating coefficients of est and rearranging, we obtain the following:
(4ii — s)fi 4- • • • 4- Alnfn = 0,
(6.14)
4ni/i 4- • ■ • 4- (Ann — s)fn = 0.
This set of equations can be rewritten in the following matrix algebra form:
[A - il]f = 0 (6.15)
where f = column matrix, or vector, and I = identity matrix. Equation (6.15) will
have a nontrivial solution only if
|A - il| = 0. (6.16)
By expanding the determinant |A — il| and solving for the roots of the equation
| A — il| = 0, the eigenvalues of the matrix A are obtained. Expanding the
determinant
|A - il| = 0 (6.17)
results in the following expression:
i« + B1sri~}- 4- ' • • 4- Bn = 0. (6.18)
Notice that the Bi terms in Eq. (6.18) are equivalent to the AjAn terms in Eq. (6.8).
Therefore, the two equations are equivalent. The n values of 5 that satisfy Eqs. (6.17)
are called the characteristic values, or eigenvalues, of the matrix.202 Techniques for Determining Control-system Stability 6.2
As an example for comparing the stability determination of a system utilizing
conventional Laplace transform and state-space techniques, consider the unity feed￾back system shown in Fig. 6.2. Using the Laplace transform, we could easily obtain
the closed-loop transfer function of the system as
C(s) = G(s) =_____________ K_____________
R(s) 1 + G(s) TjV + (Tj + T2)s2 + s + K ’
The characteristic equation of this simple linear system is given by
T^s3 + (Tj + T2)s2 + 5 + ^=0. (6.20)
System stability can be determined by locating the roots ofthis equation ifthe classical
approach is to be used The same problem will next be analyzed from the state-space
viewpoint.
Fig. 6.2 Third-order feedback control system considered in Section 6.2.
From Eq. (6.19), we obtain
+ (7\ + T2)s2 + 5 + K]C(s) = KR(s). (6.21)
The time-domain expression equivalent to Eq. (6.21) is given by
+ (Tx + T,)c(/) + c(t) + Kc(t) = Kr(t). (6.22)
As discussed previously, this third-order differential equation may be written as three
first-order differential equations as follows:
c(/) = Xj
c(t) = = x2
c(t) = x2 = x3 (6.23)6.3 Routh-Hurwitz Stability Criterion 203
Using vector notation, the above equation becomes
x = Ax + Br(r),
where
X =
'Xi *
*2 , x =
■<
*2 • A =
' 0
0
— K
i
0
-i
0
1
-(t; + t2)
, B =
' 0 ’
0
K . (6.25)
La3_] _-
*3. TXT2 7^ J
In order to obtain the characteristic equation, the input will be set equal to zero and
the solution will be assumed equal to ftest. As outlined previously (see Eq. 6.17),
this procedure results in
1A - = 0. (6.26)
The resulting determinant is given by
—s 1 0
0 —s 1
— K -1 + r2) = °- (6.27)
— . — — 5
t;t2 tx t2 TxT2
Expansion of the determinant by means of minors along the first row gives
TxT2s3 + (Tx + T2)s2 + s + K = 0.
—s 1 0 1
—s -i -(rt + t.)
Tx r2 TxT2
-1 —K
TxT2
— (7j + T2) —• s
TxT2
= 0, (6.28)
(6.29)
which reduces to
Equation (6.29), obtained utilizing the state-space approach, is the same character￾istic equation as (6.20), which was obtained by using conventional Laplace transform
techniques. Although the mathematics involved in obtaining Eq. (6.29) was more
laborious than for Eq. (6.20) for this simple problem, many important features and
characteristics of the state-space approach have been presented and applied. It is
important to emphasize that for more complex problems involving multiple inputs
and outputs, the state-space approach greatly simplifies the solution. In addition, it
greatly facilitates automatic computation utilizing digital computers.
6.3 ROUTH-HURWITZ STABILITY CRITERION
The Routh-Hurwitz stability criterion is an algebraic procedure for determining
whether a polynomial has any zeros in the right half-plane. It involves examining the
signs and magnitudes of the coefficients of the characteristic equation without204 Techniques for Determining Control-system Stability 6.3
actually having to determine its roots. Although this method overcomes one of the
disadvantages of the classical approach, it still does not indicate the relative degree of
stability or instability.
Routh [3] and Hurwitz [4] independently determined the necessary and sufficient
conditions for stability from the signs and magnitudes of the coefficients of the
characteristic equation. Although their criteria differ somewhat, both furnish the
same information. A useful form of their approach is described below.
Let us represent the general form of the characteristic equation by
BlS"‘ + + • • • + Bm+1 = 0. (6.30)
The coefficients of this equation are arranged in two rows as follows:
s’" B, B3 Bs B7-- (6.31)
sm 1 B2 Bt B$ Ba •
All the coefficients are assumed to be real and, in addition, B7 is assumed to be posi￾tive. Additional rows of coefficients are derived from these two in the following
manner:
where
=
U2 =
K =
c: q to
c; cc ,to
w
Cj 1 1 .S® 1 «o to 6, Co to c,
r- 1 - . ° . . . 3 3 S S 3 =
r - to to 1 1 1 1 1
W bD »-*
L ? 1“ - “ N . . . C: C! to to
to H• to H*
b3
B,
u3
Bs
B,
u3
[73 —
U4 =
V3 =
b7---
b8 • ■ •
u7--
v7- ■ •
y... y 8
B3B5 —
B-i
u7b6 - b,u5 \ ’ (6.33)
LW5 ~ UtU6
(72
This pattern will continue until all the terms in a row are zero. The rows are indexed
downwards, the first row being numbered m, the degree of the original polynomial;
the last row being numbered 0. The number of rows obtained will be m + 1, where m6.3 Routh-Hurwitz Stability Criterion 205
is the order of the characteristic equation. Note that there is one exceptional case
where this will not be so and this is discussed later on. The criterion ofstability is to
check that all the terms in the left-hand column (B15 B2, U1, U2, V2, V2,. . .) have the
same sign. Ifso, there are no roots in the right half-plane. If there are A'changes of
sign, then X roots exist in the right half-plane.
Let us illustrate the approach with a simple example. Consider the characteristic
equation
1 + G(s)7/(s) = 53 + 4s2 + 100s + 500 = 0. (6.34)
Using the procedure described, the resulting array is
s3 1 100
s2 4 500
s — 25 0
s° 500 0
(6.35)
There are two changes ofsign in the first column: 4 to —25 and —25 to 500; there￾fore, there are two roots in the right half-plane.
If the first term in any row is zero, and the other terms of the row are not zero,
the array of Eq. (6.32) may be continued by replacing the first column zero by an
arbitrary small positive constant e. The process is then continued in the usual manner.
Let us illustrate the procedure for this particular case with a simple example Consider
the following characteristic equation:
1 + G(s)H(s) = y5 + s4 + 4y3 + 4y2 + 2s + 1 = 0. (6.36)
Using the procedure described, the resulting array is
1 4 2
1 4 1
Replace this row -> (0 10)
with -> e 1 0
(6.37)
0 0
4e - 1
1 0 0
As e goes to zero, the limiting value of the term in the left-hand column, fourth row,
is negative. The limiting value of the term in the left-hand column, fifth row, is
positive. Therefore there are two changes of sign, and two roots must lie m the
right half-plane.
The exceptional case referred to above occurs when all the terms in a rou are
zero before the (m + l)th row is reached. This means that there are pairs ot real206 Techniques for Determining Control-system Stability 6.4
roots existing which are negatives of each other located on the real axis, pairs of
conjugate roots on the imaginary axis, or quadruples of roots symmetrically located
with respect to the origin. For this special case, the array of Eq. (6.32) can be com￾pleted by obtaining a subsidiary polynomial from the preceding row. The subsidiary
polynomial is formed by constructing an odd or even polynomial whose coefficients
are the coefficients of the last nonzero row. To determine the degree of the subsidiary
polynomial, the rows are indexed downwards, the first row being numbered m,
the degree of the original polynomial. Then the index of the last nonzero row is the
degree of the subsidiary polynomial. This polynomial is then differentiated and the
resulting coefficients are used to complete the array. The zeros of the subsidiary
polynomial are actual roots ofthe characteristic equation. This procedure is illustrated
with a simple example. Consider the following characteristic equation:
1 + G(s)H(s) = 53 + 10j2 + 16s + 160 = 0. (6.38)
Using the procedure described, the resulting array is
s3 1 16
s2 10 160 (6.39)
s 0 0
The presence of zeros in the third row indicates the exceptional case. Using the
coefficients of the second row for the subsidiary equation, we obtain
F(s) = 10s2 + 160 = 0. (6.40)
In order to complete the array, Eq. (6.40) is differentiated and the resulting coefficients
are then inserted into the array as follows:
s3 1 16
s2 10 160
s 20 0(6.41)
s° 160 0
No roots lie in the right half-plane since there are no changes of sign in the left-hand
column. The roots which are negatives of each other can be obtained from Eq. (6.40)
as ±j'4, indicating a pair ofimaginary roots.
Although the Routh-Hurwitz criterion gives a relatively quick determination of
absolute stability, it does not show how to improve the design. In addition, it does
not give an indication of relative system performance. Its main attribute is to serve
as a check of other design, criteria. The greatest difficulty with using the Routh￾Hurwitz criterion, however, is that it assumes that the characteristic polynomial is
known.
6.4 NYQUIST STABILITY CRITERION
The Nyquist stability criterion [5] is a very valuable tool which determines the degree
ofstability, or instability, of a feedback control system. In addition, it is the basis for
other methods which are used to improve both the steady-state and the transient6.4 Nyquist Stability Criterion 207
response of a feedback control system. Application of the Nyquist stability criterion
requires a polar plot of the open-loop transfer function, G(j(o)H(j(i)), which is usually
referred to as the Nyquist diagram.
The Nyquist criterion determines the number ofroots ofthe characteristic equation
which have positive real parts from a polar plot of the open-loop transfer function,
G(/co)ET(y<v), in the complex plane. Let us consider the characteristic equation,
F(y) = 1 + G(y)H(y) = 0. (6.42)
System stability can be determined from Eq. (6.42) by locating its roots in the complex
plane. Assuming that G(s) and H(s), in their general form, are functions ofs which
are given by
G(S) “ (6 43)
£>a(s)
and
h(s) = TTTv (644)
then we can say that
^b(5)
G(s)H& = 7~~- (6-45)
DA(s) db(s)
Substituting Eq. (6.45) into Eq. (6.42), we obtain the following equivalent expression
for F(s):
1 . zv A 1 □_ N^)NB(s) Da(s)Db(s) + NA(s)NB(s) F(s) = 1 + G(s)H(s) = 1 + --------------- =-----------------------—----------. (6.46)
Da(s)Db(s) Da(s)Db(s)
In terms of factors, we may rewrite Eq. (6.46) as
F(s) = ---------------------------------------- . (6.4/)
(s + sj(s + sB)(s + sc) • • •
The factors s + y1; s + s2, . . . are called the zero factors of F(s). This terminology
is due to the fact that F(s) vanishes when s = —5i, —s2, and so on. The factors
s 4- sA, s + sB, . . . are called the pole factors ofF(s). This terminology is due to the
fact that F(s) is infinite when s = —sA, —sB, and so on.
Since F(s) is the denominator of the closed-loop system transfer function given
by Eq. (6.1), we see that the zeros of F(s) are the poles of Eq. (6.1). Therefore, for a
stable system, it is necessary that the zeros y15 5a, «3,. . . have negative real parts.
The roots sA, sB, sc, have no real restrictions on them. As we shall shortly see,
however, if we try to determine stability based on G(s)H(s) above, then a knowledge
of the roots sA, sB, sc,... is also required. The only limitations of the Nyquist
criterion are that the system be describable by a linear differential equation having
constant coefficients.208 Techniques for Determining Control-system Stability 6.4
The Nyquist diagram is a polar plot in the complex plane of G(s)H(s) as s follows
the contour shown in Fig. 6.3. Notice that the locus of s avoids poles of G(s)H(s)
which lie anywhere on the imaginary axis by small semicircular paths passing to the
right. These semicircular paths are assumed to have radii of infinitesimal magnitude.
Any roots of the characteristic equation having positive real parts will lie within the
contour shown in Fig. 6.3.
Fig. 6.3 Locus of r in the complex plane for determining the Nyquist diagram.
Use is made of Cauchy’s [6] principle of the argument, which states that if a
function F(s) is analytic on and within a closed contour, except for a finite number of
poles and zeros within the contour, then the number of times the origin of F(s) in the
F-plane is encircled as s traverses the closed contour once is equal to the number of
zeros minus the number of poles of F(s), the poles and zeros being counted according
to their multiplicity. In our particular case, the function F(s) equals 1 + G(s)7/(s).
Observe that for this case the origin of 1 + G(s)H(s) is given by
G(s)//(s) = -1. (6.48)
Therefore, if G(s)H(s) is sketched for the contour defined by Fig. 6.3, the number of
times that G(s)H(s) encircles the point —1 + jQ equals the number of zeros minus
the number of poles of 1 + G(s)H(s) for s in the right half-plane.
Figure 6.4 illustrates a polar plot, corresponding to the contour defined by s in
the complex plane, for a system whose characteristic equation is
1 + G(s)H(s) = 1 +
________K________
s(l + T1S)(1 + T2s)
(6.49)6.4 Nyquist Stability Criterion 209
To obtain the direct polar plot of this function, we substitute 5 = joj into Eq. (6.49)
as follows:
1 + = 1 + ■ K-- . . (6.50)
jco(l + Ti/coXl + T2ja>)
Figure 6.4 represents the polar plot of 1 + G(s)H(s) for values ofs along the imaginary
axis where —jco < ja> < jco. * The dotted portion of the curve denotes the negative￾frequency portion. Notice that the polar plot for negative frequencies is the conjugate
of the positive portion. Figure 6.5 illustrates the same polar plot with the origin
shifted to the point — 1 + /0. This simplifies the drawing of the polar plot of
1 + G(s)H(s), since we need now only sketch G(s)H(s). The resulting curve will
correspond to 1 4- G(s)H(s) as is indicated on the new set of coordinates. In practice,
this is very advantageous since G(s)H(s) is a function which is much more readily
available than 1 + G(s)H(s).
* The path along the imaginary axis in the vicinity of co = 0 is modified to be a semicircle of
infinitesimal radius <5 in the positive half-plane in order to avoid passing through this pole
on the imaginary axis at the origin (see Fig. 6.3). For this semicircular portion of the path,
from j0~ to j0+, s =8e‘e where <5 -> 0 and —nil < 6 < tt/2. Therefore, for j 0, Eq.
(6.49) becomes
1 + G(s)H(s) = 1 + K/s = K/6ei9 = (K/6)e-’e = (KlW'.
Observe that the magnitude of K/S oo as <3 -> 0, and a = -6 goes from w/2 to —rr/2 as
the directed segment 5 goes from <5/ -n/2 to <5/tt/2. This implies that the end points from
co —> 0" and co —> (F in the polar plot are joined by a semicircle of infinite radius in the first 
and fourth quadrants as indicated. Numerals 1-5 are used for clarity in correlating the
locus ofs in the complex plane and the polar plot.
Fig. 6.4 Locus ofs in the complex plane and polar plot of 1 + G(s)H(s).210 Techniques for Determining Control-system Stability 6.4
Fig. 6.5 Polar plot of 1 + G(s)H(s~) with change of origin.
With the Nyquist diagram sketched on a set of axes where the origin is shifted to
the —1 4- jO point, the Nyquist stability criterion can be stated algebraically as*
* The proof of the Nyquist stability criterion is contained in Appendix B.
N = Z - P (6.51)
where N is the number of clockwise encirclements of the —1 + j’O point by the
Nyquist locus, P is the number of poles of the open-loop transfer function G(s)H(s)
having positive real parts, and Z is the number of roots of the characteristic equation
having positive real parts (Z must equal zero for stability). In most practical cases, the
open-loop transfer function is in itself stable and P would equal zero. Since Z must
equal zero for stability, N must equal zero for these practical systems.
Figure 6.6 illustrates several examples of application of the Nyquist stability
criterion using the relationship given by Eq. (6.51). In all cases, the values of the
open-loop transfer function G(s)H(s) are shown together with the values ofN, P, and
Z. Notice that those systems whose Nyquist diagrams are illustrated in parts (a)
through (d) are open-loop stable while those in parts (e) and (f) are open-loop
unstable. The systems illustrated in parts (a), (d), and (e) are closed-loop stable, while
the systems illustrated in parts (b), (c), and (f) are closed-loop unstable.
It is quite clear that a good picture of a system’s margin of stability can be
obtained from the Nyquist diagram. The proximity of the G(s)H(s) locus to the
— 1 + y’0 point is an indication of relative stability. The farther away the locus is
from this point, the greater the margin of stability. One conventional measure of
the relative degree of stability is the distance two points on the G(s)H(s) locus are
from the point —1 + JO. This is illustrated in Fig. 6.7 by the points A and B.Kc
(c> G(s)H(s) = Gixt~\ (1 + Z,s) (1 + T2s) (1 + T}s)
N = 2
P= 0
Z= 2; therefore unstable
(d) G(s) /~Hs) =--------------------------------------- -
(1 + r, s)(l + T2s)(l + T}s)
7V=0
P=0
Z=0; therefore stable
(e)G(.)//(s)= (=T^-s)
^=-1
P= 1
Z= 0; therefore stable
N= 0
P= 1
Z= 1; therefore unstable
Fig. 6.6 Examples of typical Nyquist diagrams.
211212 Techniques for Determining Control-system Stability 6.4
Fig. 6.7 Definition of phase and gain margin.
The point A is defined by the intersection of the G(s)H(s) locus and the unit circle.
Obviously, the magnitude of G(s)H(s) at point A is unity and is denoted by
[G’( /,->)//(yT»)]i in Fig. 6.7. The angle of [G(yto)77(ja>)]1 with respect to the positive
real axis is defined as being positive in the counterclockwise sense and is designated as
0. The phase margin y is defined as the angle which [GQa^HQco^ makes with
respect to the negative real axis. It is related to 0 by the equation
y = 180° + e. (6.52)
A positive value of phase margin tends to indicate stability and a negative value of
phase margin tends to indicate instability although there are exceptions. * A zero
value of phase margin indicates that the G(s)H(s~) locus passes through the — 1 + y0
point. The magnitude of +y indicates the relative degree of stability. Usually, a
desirable value of y is between 30° and 60°.
* The exceptions refer to conditionally stable systems which are considered shortly.
The point B is defined by the intersection of the G(s)H(s) locus and the negative
real axis. The gain margin is defined as the reciprocal of the magnitude of the
G(s)H(s) locus at point B. For the configuration illustrated in Fig. 6.7, the gain
margin equals 1/a. The significance of the gain margin is that the system gain could
be increased by a factor of 1/a before the G(s)H(s) locus would intersect the — 1 + j’O
point. A value of gain margin greater than unity tends to indicate stability; a gain
margin smaller than unity tends to indicate instability. The magnitude of the gain6.5 Bode-Diagram Approach 213
margin indicates the relative degree of stability. Gain margin is usually expressed in
decibels as follows:
gain margin in db = 20 log10 (1/a). (6.53)
Usually, a desirable value of gain margin is between 4 and 12 db.
Fig. 6.8 A conditionally stable system.
One important issue to be considered is that of conditionally stable systems. If
Fig. 6.7 is examined, the erroneous impression can be obtained that an increase in
gain will always cause a system to become unstable. This is not always true, as
illustrated in Fig. 6.8. Here, if the gain is increased, then the point A will move to
enclose the — 1 + jO point and the system will become unstable. However, ifthe gain
is decreased, point B will move to enclose the —1 + /0 point and the system will
become unstable. Although they do occur in practice, conditionally stable systems
should be avoided if possible.
6.5 BODE-DIAGRAM APPROACH
The Bode-diagram approach [8] is one of the most commonly used methods for the
analysis and synthesis of linear feedback control systems. This method, which is
basically an extension of the Nyquist stability criterion, has the same limitations and
uses as the Nyquist diagram. The presentation of information in the Bode-diagram
approach, however, is modified to permit relatively quick determinations ofthe effects
of changes in system response without the laborious calculations associated with
the Nyquist diagram.
The Nyquist diagram gives the amplitude and phase of the open-loop transfer
function G(s)H(s) as 5 traverses a contour that encloses the right half-plane. As 5
traverses the positive imaginary axis, it has the value of real frequency co, and the
plot corresponds to We can illustrate the same amount ofinformation
by means of two diagrams which have co as a common axis. These two diagrams,214 Techniques for Determining Control-system Stability 6.5
Fig. 6.9 Typical pair of Bode diagrams.
illustrated in Fig. 6.9, are usually referred to as Bode diagrams. It is important to
emphasize that the Bode diagrams provide information only ofs corresponding to the
imaginary axis and therefore represent the frequency response.
Let us consider the system illustrated in Fig. 6.10. It is assumed that the input,
r(t), is a sinusoidal waveform of frequency co and unity amplitude given by
r(t) = sin cot. (6.54)
Assuming a linear system, the output would have the general form
c(r) = a sin (cot — <f>), (6.55)
where a = gain of system, and </> = phase shift of the system. Let us represent the
system transfer function as
T(» = = a(jco)e-^M. (6.56)
Fig. 6.10 Representative feedback control system.6.5 Bode-Diagram Approach 215
Here T(jm) is a complex function which can be represented by an amplitude
and a phase shift of </>(/co). In the Bode-diagram approach, the amplitude is expressed
in decibels and is plotted versus frequency on semilogarithmic graph paper. The
amplitude, in decibels, is given by
amplitude in db = 20 log10 a(Jo>). (6.57)
The phase shift is conventionally expressed in degrees.
By introducing the logarithm concept, the tedious process of multiplying two
complex numbers is simplified to one of addition. For example, let us consider two
complex numbers: Ga(jo>) and Gb(jco). The logarithm of the product of two complex
quantities
GM = (6.58)
and
G6(» = aMe-^^ (6.59)
is given by
logic Ga(J( *>)G b(Ja>) = log10 aa(Jco) + log10 ab(jw)
+ 0.434M(» + (6.60)
Equation (6.60) illustrates that the logarithm of the product of two complex
numbers is the sum of the logarithms of the magnitude components plus 0.434/ times
the sum of the phase-angle components. In addition, Eq. (6.60) shows that the
logarithm of the magnitude and phase components, respectively, are separate
functions of the common parameter oj and can be sketched separately as was shown in 
Fig. 6.9. By convention, the factor 0.434 is not considered, and only the phase angle
itself is used.
Bode’s theorems are presented in Chapter 7 when we discuss the Bode-diagram
approach for the design of feedback control systems in order to meet certain specifi￾cations. In this chapter, however, it is important to emphasize the fact that the Bode
diagram approach applies primarily only to minimum-phase networks. The basic
definition of a minimum-phase network [7] is a network whose phase shift is the
minimum possible for the number of energy storage elements in the network. This
definition restricts the zeros of minimum-phase networks to the left half of the
complex plane. A little thought indicates that when we specify either the amplitude
or phase of a minimum-phase network, we have also automatically specified the other.
This concept is the basis ofone ofBode’s theorems. However, the Bode diagram can be
applied to nonminimum phase systems if we know where the nonminimum phase
characteristics come from.
Understanding the basic concepts of the Bode diagram, let us now gain the
facility for constructing them. The laborious procedure of plotting the amplitude
and phase ofG(ja))H(J<o) by means ofsubstituting several values ofja> is not necessary
when drawing the Bode diagram, because we can use several short cuts. These short
cuts are based on simplifying approximations which allow us to represent the exact,
smooth plots with straight-line asymptotes. The difference between actual amplitude216 Techniques for Determining Control-system Stability 6.5
characteristics and the asymptotic approximations is only a few decibels. Now we
shall demonstrate the application of this approximating technique to seven common,
representative transfer functions: a constant, a pure integration, a pure differentiation,
a simple phase-lag network, a simple phase-lead network, a quadratic phase-lag
network, and a time-delay factor. The basic concepts illustrated are then used to draw
the Bode diagram of the transfer function for representative systems.
A. Bode Diagram of a Constant Using the definition of Eq. (6-57), the logarithm of
a constant K, or 1/A, where K > 1, is given by
(K)db = 20 log10 K, (6.61)
= -201og10K. (6.62)
\K/db
The corresponding phase angle of a constant is 0° or 180°, depending on whether the
constant is positive or negative, respectively. Figure 6.11 illustrates the Bode diagram
of a constant.
(i/xr )< i
O 20log10K
< -20 log10K
D
5 0
K (positive number)
K (negative number)
Fig. 6.11 Bode diagram of a constant.
B. Bode Diagram of a Pure Integration The Bode diagram of a pure integration
G(yco) = 1/yco (6.63)
can be obtained by taking the logarithm, yielding
1 TT 20 log10 — = -20 log10 co -j- . (6.64)
jco 2
Figure 6.12 illustrates the Bode diagram of a pure integration. Notice that the
resulting amplitude curve is linear when the amplitude is plotted on a linear scale and
the frequency is plotted on a logarithmic scale. The slope ofthe amplitude character￾istic is a constant and equals —20 db/decade. A slope of —20 db/decade also corre￾sponds to a slope of —6 db/octave. The phase characteristic for the pure integration
is constant and equals —90°.6.5 Bode-Diagram Approach 217
Bode Diagram of a Pure Differentiation The Bode diagram of a pure differentiation
G(Ja>) = ja> (6.65)
can be obtained in a manner similar to that used for the pure integration. The major
differences are that the amplitude characteristics now have a positive slope and the
phase characteristic is positive. Figure 6.13 illustrates the Bode diagram of a pure
differentiation.
u (rad/sec)
Fig. 6.13 Bode diagram of a pure differentiation.
D. Bode Diagram of a Simple Phase-lag Network A phase-lag network produces a
phase lag which is a function of frequency. The transfer function of such a network
is given by
G(» =—= (j- + 1V. (6.66)
ja> + a \ a /218 Techniques for Determining Control-system Stability 6.5
The Bode diagram for this transfer function can be obtained as follows:
20 log10(j — + 1
\ a (
2 \l/2
+ 1 | —j tan-1 -.
a J a
(6.67)
Figure 6.14 illustrates the Bode diagram of a simple phase-lag network. The dashed
portion of the amplitude characteristic represents the exact plot, and the heavy line
segments represent the straight-line asymptotic approximation. They differ by a
maximum of 3 db at co/a = 1.
Fig. 6.14 Bode diagram of a simple phase-lag network.
The asymptotic approximations can be drawn quite easily. For example, when
co/a is much less than unity, the imaginary component is very much smaller than the
real component (unity), and the imaginary component can be neglected. Therefore,
201og10 1 = 0 db for — « 1. (6.68)
a
When co/cz is much greater than unity, the imaginary component is much greater than
the real component (unity) and the real component may be neglected. Therefore
201og10(j-V= —201og10 —db for -» 1. (6.69)
\ a) a a
Equation (6.69) is very similar to the amplitude characteristic of a pure integrator,
given by Eq. (6.64), and has a slope of —20 db/decade. At co/a = 1, the two asymp￾totes join each other. This frequency (co = a) is referred to as the break frequency.
Ordinarily, the straight-line asymptotic approximation is accurate for most appli￾cations. If further correction is needed, the exact curve can be obtained from the6.5 Bode-Diagram Approach 219
approximate curve by using the following corrections: — 1 db at wja = 0.5 and 2;
—3 db at a>/a = 1.
The phase shift produced by the simple phase-lag network can be obtained from
the expression
phase lag = —tan-1 —. (6.70)
a
The phase shift at the break frequency is —45°; at co = 0 it is 0°; at co = oo it is
—90°. Notice that this phase-lag network is a minimum-phase network since it has
the minimum phase shift possible for the number of energy storage elements in the
network (one).
Fig. 6.15 Bode diagram of a simple phase-lead network.
E. Bode Diagram of a Simple Phase-lead Network The Bode diagram of a simple
phase-lead network
G(jco)=j- + 1 (6.71)
a
can be obtained in a manner similar to that used for the simple phase-lag network.
The major differences are that the amplitude characteristic has a positive slope, and
the phase characteristic has a positive (phase lead) value. Figure 6.15 illustrates the
Bode diagram of a simple phase-lead network.
F. Bode Diagram ofa Quadratic Phase-lag Network Let us consider the second-order
quadratic, phase-lag transfer function given by
2
G(ico) =--------------- --- , (6-72) {J } (»2 + 2^„(» + cof V220 Techniques for Determining Control-system Stability 6.5
or
G(» = (6.73)
The Bode diagram for this transfer function can be obtained as follows:
201og10|7j —Y +2c(j—)+l
L\ co„/ \ wnJ
1/2
— j'0.434 tan 1
2 2 ’ O)n — CD
(6-74)
Figures 6.16 and 6.17 illustrate the Bode diagram of the quadratic phase-lag network
for various values of damping factor, £. In Fig. 6.16, the dashed portion of the
amplitude characteristic represents the straight-line asymptotic approximation and
the heavy-line portions represent the exact plot. For £ = 1, the two curves differ by a
maximum of 6.2 db at co/co„ equal to unity.
The asymptotic approximations can be drawn quite simply. For example, when
a>la>n is much less than unity, the imaginary component is very much smaller than the
real component, and the imaginary component can be neglected. Therefore,
20 log10 y/1. = 0 db/decade for -«1. (6.75)
Fig. 6.16 Amplitude portion of Bode diagram for a quadratic phase-lag network.6.5 Bode-Diagram Approach 221
When co/w„ is much greater than unity, the dominant term is
(6.76)
This indicates that the slope of the straight-line asymptotic approximation for
w/a>n » 1 is twice that of a phase-lag network. The difference between the approxi￾mate curve and the exact curve depends on the damping factor, Similar analysis
indicates the phase shift possible is twice that of the simple phase-lag network.
G. Bode Diagram of a Time-delay Factor The time-delay factor [9] occurs in systems
which are characterized by the movement of mass that requires a finite time to pass
from one point to another. The transfer function of a pure time-delay factor, without
attenuation, is given by
G(» = e~i<oT. (6.77)
The delay factor e~,u>T results in a phase shift
</>(<u) = — a>T rad, (6.78)
which has to be added to the phase shift resulting from the rest ofthe system. Observe
that the magnitude of the time-delay factor is always unity and, therefore, does not
affect the magnitude characteristics. Figure 6.18 illustrates the Bode diagram of the
pure time-delay factor on a logarithmic scale.222 Techniques for Determining Control-system Stability 6.5
Fig. 6.18 Bode diagram of a pure time-delay factor.
H. Bode Diagram of a Composite Transfer Function—Example 1 Let us next apply
the basic notions developed in this section for the transfer function of a representative
system. Consider a unity feedback system whose open-loop transfer function is given
by
G(j(D) = 775 + + 1
ja> O.5jco + 1 ja> + 1
x [0.655 x 10~4(jco)2 + 6.55 x 10-3jco + l]-1. (6.79)
This transfer function contains a pure integration, two phase lags, two phase leads,
and a quadratic phase-lag network. Each ofthese characteristics has previously been
considered individually. The simplest procedure for plotting the amplitude character￾istic for the entire transfer function is to start by locating one point, say to = 1,
Using the straight-line asymptotic approximation technique, the assumption is made
that either the real or the imaginary component (whichever is larger at co = 1)
predominates. (Ifthey are both equal, either component may be used for the straight￾line asymptote.) At the same time, the slope at co = 1 is determined. For the problem
at hand, at co = 1,
Equation (6.80) indicates that the gain of the straight-line asymptotic curve is 775
(57.5 db) and the slope is changing from —20 db/decade to —40 db/decade at co = 1.6.5 Bode-Diagram Approach 223
The next step is to locate all the break frequencies (frequencies at which the slopes
change because a real or imaginary component starts or stops dominating). The
break frequencies for this transfer function are at co = 1 (—20 db/decade to —40 db/
decade); co = 2 (—40 db/decade to —60 db/decade); co = 5 (—60 db/decade to
-40 db/decade); co = 10 (-40 db/decade to-20 db/decade); co = 123.8 (-20 db/
decade to —60 db/decade). The corresponding phase characteristics can most easily
be determined using superposition of the individual phase characteristics of each
component and utilizing the scale shown in Fig. 6.19. This scale, which can be easily
derived from the tangent relationship of Eq. (6.70), illustrates the effect on the
resultant phase shift occurring at frequency co for a first-order factor, due to a break
frequency occurring at co = co0. For example, at ci>/co0 = 5, the phase shift contributed
by the break occurring at co[co0 — 1 is 78.7°, while at <o/co0 = 0.2 the phase shift
contributed by this break is only 11.3°
Figure 6.20 illustrates the composite Bode diagram for the transfer function
given by Eq. (6.79). Notice that the peaking due to the quadratic phase-lag component
occurs at con =• 123.8, and corresponds to £ = 0.405.
I. Relationship Between Bode and Nyquist Diagrams At this point in the development
of the Bode diagram, it seems appropriate to relate the Nyquist stability criterion to
the Bode amplitude and phase diagrams. When we discussed the Nyquist diagram,
the degree ofstability was defined in terms of the phase and gain margins present (see
Fig. 6.7). This can easily be related to the Bode diagrams by making use of the
following two facts.
1. The unit circle ofthe Nyquist diagram transforms into the unity or 0 db line ofthe
amplitude plot for all frequencies.
2. The negative real axis ofthe Nyquist diagram transforms into a negative 180° phase
line for all frequencies.
Therefore, the phase margin can be determined on the Bode diagram by determining
the phase shift present when G(jco)H(jco) crosses the 0 db line (this is commonly
referred to as the crossover frequency). For the example illustrated in Fig. 6.20, the
phase shift is —126° (this corresponds to the 0 of Fig. 6.7) and the resulting phase
margin, y, is 54°. The gain margin can be obtained on the Bode diagram by determin￾ing the gain present when G(jco)H(jco) crosses the —180° line. For the example
Phase shift (degrees) 1Q 20 3Q 40 5Q 6Q 7Q gQ g6
0.01 0.02 0.05 0.1 0.2 0.5 1.0 2 5 10 20 50 100
"/“0
Fig. 6.19 Phase-shift scale.224 Techniques for Determining Control-system Stability 6.5
Fig. 6.20 Composite Bode diagram for a unity feedback system where
G(ju>) = + 1 0,2^C° + 1 [0.655 x lO-fyw)2 + 6.55 x 10-3yw + I]-1.
jco 0.5/co + 1 JW + 1 J J
illustrated in Fig. 6.20, the gain is —12 db when the phase shift is —180° (this
corresponds to 20 log10 a of Fig. 6.7) and the resulting gain margin, 20 log10 (1/a), is
12 db.
J. Bode Diagram of a Composite Transfer Function—Example 2 As a second example
of a Bode diagram, let us consider a unity feedback system whose open-loop transfer
function is given by
G(» = +
Ml + 0.5» (6.81)
This transfer function contains a pure integration, one phase lag, one phase lead,
and a time-delay factor. This represents the transfer function in a steel mill and the
time-delay factor is caused by the finite time it takes the steel to move from one point6.5 Bode-Diagram Approach 225
Fig. 6.21 Composite Bode diagram for a unity feedback system where
. 20(1 + 0.2»
G(/«0 = ■ /. , n /• ;e ■ J ja>(l + 0.5yw)
Phase (degrees)
to another. In this system, a motor adjusts the separation, /, of two rolls so that the
thickness error of the steel is minimized. If the steel is traveling at a velocity v of
lOft/sec, and the nominal separation / is 1 ft, then the time delay between the roll
thickness measurement and thickness adjustment is given.by
T = - =—= 0.1 sec.
v lOft/sec
The overall transfer function G{jco), given by Eq. (6.81), relates the transfer function
of the system error, defined as system error = desired thickness — actual thickness
and the output which represents the actual thickness.
Each of the other characteristics in Eq. (6.81) has been previously considered
separately. Again, our procedure for plotting the amplitude characteristics is to
start locating the point for co = 1. For this problem, the amplitude of G at co = 1 is
crc • m 20 1 1
[G(jw)L=i = 77 7 k
jl 1
(6.82)226 Techniques for Determining Control-system Stability 6.6
Equation (6.82) indicates that the gain is 20 (26 db) and the slope is —20 db/decade
at w = 1. The break frequencies occur at co = 2 where the slope changes from —20
db/decade to —40 db/decade, and co = 5 when the slope changes from —40 db/
decade to —20 db/decade. The corresponding phase characteristic can be readily
determined using superposition of the individual phase characteristics of each
component and utilizing the scale of Fig. 6.19. Figure 6.21 illustrates the composite
Bode diagram for the transfer function given by Eq. (6.81). For interest, the phase
characteristic is illustrated with and without the time-delay factor. Observe from this
curve that the crossover frequency is 8 rad/sec and the phase margin of the system
without the time-delay factor is 'll0. However, with the time-delay factor in the
system, the phase margin drops to 26°, the gain margin becomes 5 db, and the system
has a smaller margin of stability than before. The control system engineer should
always give particular attention to time-delay factors and avoid them if possible since
they produce a phase lag and decrease the phase margin.
The Bode-diagram method has the very practical virtue that the amplitude and
phase frequency responses can easily be measured in the laboratory. The relative
ease of synthesizing feedback control systems with the Bode-diagram approach is
further demonstrated in Chapter 7.
6.6 DIGITAL COMPUTER TECHNIQUES FOR OBTAINING THE OPEN-LOOP
AND CLOSED-LOOP FREQUENCY RESPONSE, AND THE TIME-DOMAIN
RESPONSE *
* The reader should consult Refs. 34 and 35 for a review of digital computer techniques.
As well as making possible computations and analyses which are not practicable by
other means, the digital computer provides valuable assistance in obtaining solutions
to relatively common, “standard” problems. It is a very valuable tool for computing
the gain and phase characteristics as a function of frequency. Several program
languages can be used to perform this computation. Perhaps the simplest lan￾guages are BASIC (.Beginner’s ylll-purpose Symbolic instruction Code) [22, 23, 26]
and FORTRAN (FORmula TRANslator) [24, 26, 27], Several problems are solved
in this chapter and in Chapter 8 utilizing these languages.
Consider a unity feedback control system where
G(s) =
_________99(1 + 0.1s)_________ 
(1 + 0.01s)2(l + 0.2s)(l + 1.5s)’
(6.83)
It is desired to determine the phase and gain margins of this linear control system,
and a BASIC program will be utilized in this problem [22, 23, 26]. The coding6.6 Digital Computer Techniques 227
Fig. 6.22 Logic flow diagram for Bode-diagram analysis.228 Techniques for Determining Control-system Stability 6.6
symbols used are as follows:
W = co
G2 = |G(s)|8
P = phase of G(s)
PM = phase margin
GOSUB —► Compute G2, P
Figure 6.22 illustrates the logic flow diagram for developing the program that
determines the phase and gain margins. Table 6.1 illustrates the actual program.
Figure 6.22 and Table 6.1 should be compared in order to obtain a thorough under￾standing of the method. Table 6.2 illustrates the computer’s answer for phase and
gain margin. It indicates that unity gain occurs at co = 31.2 rad/sec where the phase
shift is 132.1°. Therefore, the phase margin is 180 — 132.1 = 47.9°. It also indicates
that at co = 96.1 rad/sec, the phase shift is 180°, and the gain margin is 14.9 db. To
Table 6.1 Computer program for Bode-diagram analysis (BASIC program)
LIST
1 GEN PHASE AND GAIN MARGIN COMPUTATION FOR GENERAL
RESPONSE
10 LET W = 0.01
20 GOSUB 170
30 IF G2 < = 1 THEN 90
40 IF G2 < = 100 THEN 70
50 LET W = 2*W
60 GO TO 20
70 LET W = 1.01 * W
80 GO TO 20
90 IF P > = 180 THEN 210
100 PRINT "UNITY GAIN," "W=" W, "P=" P
110 LET W = 1.01 *W
120 GOSUB 170
130 IF P > = 180 THEN 150
140 GOTO 110
150 PRINT "W=" W, "GAIN MARGIN =" 4.3429448 *LOG(1/G2)
160 GO TO 900
170 LET P=57.29578 *(2ATN(O.O1 W)+ATN(O.2 W)+ATN(1.5 W)-ATN(O.1 W))
180 LET X = W*
190 LET G2 = 99*(1 +0.01 *X)/((l +0.0001 *X)f2 (l +0.04 *X) (l +2.25 *X))
200 RETURN
210 PRINT "W =" W, "SYSTEM UNSTABLE"
900 END6.6 Digital Computer Techniques 229
Table 6.2 Results of computer analysis for G(s)
99(1 + 0.15)
(1 + 0.01j)2(l + 0.2j)(1 + 1.5s)
RUN
UNITY GAIN W= 31.21 P = 132.107
W = 96.0747 GAIN MARGIN = 14.9268
RUNNING TIME: 01.4 SECS
READY
BYE
utilize the conventional asymptotic Bode-diagram technique as a check, Fig. 6.23 is
drawn. It indicates a phase margin of 48° at a crossover of 31 rad/sec, which is in
good agreement. The frequency where 180° phase shift occurs is at 97 rad/sec
(compared with 96.1 in the computer run). The gain margin using the straight-line
asymptotic curve is only 10 db and is quite far from the computer run (approximately
15 db) since a double break occurs at 100 rad/sec. However, if we correct each of
these breaks by the 3 db error factor, we should obtain a gain margin ofapproximately
16 db which is fairly close to the computer solution of 14.9 db.
Notice the preciseness and simplicity of the digital computer’s solution. In
addition, the speed ofthe computer’s solution is most interesting. Its usefulness as an
aid to the control system engineer is quite evident.
Fig. 6.23 Bode-diagram analysis of
99(1 +0.15)
G(i) ~ (1 + 0.015)2(l + 0.25)(l + 1.55) *230 Techniques for Determining Control-system Stability 6.6
Let us next extend the digital computer as a tool for also determining the closed￾loop frequency response, and the time-domain response to a number of standard
input signals. Consider a unity feedback control system where
Mum,
s(l + 5s)
A FORTRAN [24, 26, 27] program will be utilized in this example in order to
determine the open- and closed-loop frequency response, and the BASIC [22, 23, 26]
program will be utilized to determine the time-domain response.
Figure 6.24 shows the logic flow chart of a FORTRAN program, called FRECOM,
which computes the following relations for various frequencies:
a) 20 log |G(s)H(s)| ] , . _ ,
1 for open-loop Bode diagram b) Phase of G(s)H(s)J F 6
c) 20 log =)
R(s) 1 + G(sW(s) I , , , . r
) for closed-loop frequency response
d) Phase ofR(s) >
The FORTRAN program for computing these quantities is shown in Table 6.3 and
should be compared with the flow chart of Fig. 6.24 to obtain a thorough understand￾ing of the technique. The program utilizes statements available from the Rapidata
FORTRAN IV language [23]. Note how simple the complex specification statements
become in this language. One should also observe the use of complex function sub￾programs G(s) and H(s). Once written, the programs can now be revised for different
systems merely by replacing the two lines containing the arithmetic statements for
G(jco) and H(jai).
The actual use of the program is extremely simple. During program execution,
one enters the starting frequency value and the number of decades of frequency range
required. Table 6.4 shows the computer run for the open and closed-loop frequency
response of this system. Figure 6.25 is a plot of these results. It indicates a phase
margin of 74.5° at a crossover frequency of 6.4 rad/sec and a closed-loop peaking of
1.8 db at 2.5 rad/sec. It is immediately evident from examination of the open-loop
frequency characteristics that the system is always stable since the phase shift never
exceeds —144.87°.
In order to obtain the time-domain response, the differential equations which
describe the system must be derived from the given frequency-domain description.
Since, in the running example,
60(1 + 0.5s)
G(s) =-----------------
s(l + 5s)
and
H(s) = 16.6 Digital Computer Techniques 231
Table 63 Computer program FRECOM
FRECOM
PROGRAM FRECOM
1SNDM
100
101
102
105
106
108
110
120
125
221
222
231
240
241
250
260
270
280
290
300
310
320
330
340
350
360
370
380
390
400
410
500
510
520
530
540
550
560
570
580
590
COMPLEX S,TFRFCT,LOOPG
COMPLEX G,H
EXTERNAL G,H
COMPLEX TEMP
PRINT, "INPUT INITIAL FREQUENCY AND # OF DECADES,"
READ, WMIN,JM
PRINT, "FREQUENCY LOOP GAIN RESPONSE"
PRINT, "RAD/SEC DB DEGREES DB DEGREES"
PRINT, "---------------------- --------------------------- --------------------------- "
FACI=20./ALOG(10.)
FAC2 =180./FPI(l.)
WINC=WMIN
DO 1 J =1,JM
IF(J.GT.l) WINC=WMIN *(10.*J —1))
DO 1 K =l,9
W=K *INC
S=CMPLX(O.,W)
TEMP=G(S)
LOOPG =TEMP *H(S)
TFRFCT =TEMP/(1. +LOOPG)
LOOPG =CLOG(LOOPG)
TFRFCT=CLOG(TFRFCT)
V I =REAL(LOOPG) FAC1 *
V 2 =AIMAG(LOOPG) FAC2 *
V 3 =REAL(TFRFCT) FAC1 *
V 4 =AIMAG(TFRFCT) FAC2 *
PRINT 900,W,Vl,V2,V3,V4
900 FORMAT(F7.2,2X,2F10.2,1X,2F10.2)
1 CONTINUE
STOP
END
COMPLEX FUNCTION G(S)
COMPLEX S
G = 6O. *(1.+O.5 S)/(S (1.+5. S))
RETURN
END
COMPLEX FUNCTION H(S)
COMPLEX S
H =l.
RETURN
END232 Techniques for Determining Control-system Stability 6.6
Fig. 6.24 Flow diagram FRECOM for computing open and closed-loop frequency
responses.6.6 Digital Computer Techniques 213
Table 6.4 Open and closed-loop frequency response of G(s)
_ 60(1 + 0.5s)
s(l + 5s)
READY
RUNNH
INPUT INITIAL FREQUENCY AND # OF DECADES 0.1, 4
FREQUENCY LOOP GAIN RESPONSE
RAD/SEC DB DEGREES DB DEGREES
0.10 54.60 -113.70 0.01 -0.10
0.20 46.58 -129.29 0.03 -0.21
0.30 41.00 -137.78 0.06 -0.35
0.40 36.70 -142.13 0.10 -0.52
0.50 33.24 -144.16 0.15 -0.74
0.60 30.37 -144.87 0.22 -1.02
0.70 27.94 -144.76 0.29 -1.37
0.80 25.84 -144.16 0.36 -1.79
0.90 24.01 -143.24 0.44 -2.28
1.00 22.38 -142.13 0.53 -2.84
2.00 12.51 -129.29 1.21 -12.17
3.00 7.60 -119.88 1.20 -24.53
4.00 4.48 -113.70 0.57 -35.73
5.00 2.22 -109.51 -0.34 -44.55
6.00 0.45 -106.53 -1.34 -51.26
7.00 -1.00 -104.31 -2.32 -56.39
8.00 -2.24 -102.60 -3.24 -60.39
9.00 -3.31 -101.26 -4.11 -63.57
10.00 -4.27 -100.16 -4.91 -66.14
20.00 -10.41 -95.14 -10.57 -77.99
30.00 -13.96 -93.43 -14.03 -81.98
40.00 -16.47 -92.58 -16.51 -83.99
50.00 -18.41 -92.06 -18.43 -85.19
60.00 -20.00 -91.72 -20.01 -85.99
70.00 -21.34 -91.47 -21.35 -86.56
80 00 -22.50 -91.29 -22.51 -86.99
90.00 -23.52 -91.15 -23.53 -87.33
100.00 -24.44 -91.03 — 24,44 -87.59
200.00 -30.46 -90.52 -30.46 -88.80
300.00 -33.98 -90.34 -33.98 -89.20
400.00 -36.48 -90.26 -36.48 -89.40
500.00 -38.42 -90.21 -38.42 -89.52
600.00 -40.00 -90.17 -40.00 -89.60
700.00 -41.34 -90.15 -41.34 -89.66
800.00 -42.50 -90.13 -42.50 -89.70
900.00
STOP
USED: CPU 2.3 1/0
READY
-43.52
3.8
-90.11 -43.52 -89.73234 Techniques for Determining Control-system Stability 6.6
then
C(s) _ G(s)
R(s) 1 + G(s) '
Upon substitution of G(s) into the expression for C(s)/R(s), the following is obtained:
C(s) _ 30s + 60
R(s) “ 5s2 + 31s + 60
or
C(s)[5s2 + 31s + 60] = 7?(s)[30s + 60].
This is equivalent to the following differential equation:
5^} + 31 + 60c(t) = 60r(r) + 30^. (6.85)
dr2 dr dr
In order to obtain the first-order dynamic equations, let
Xi(r) = c(t),
Fig. 6.25 Open and closed-loop frequency response of
G(s) =
60(1 4- 0.5s)
s(l + 5s) ‘6.6 Digital Computer Techniques 235
Table 6.5 Coding of a BASIC program for solving two simultaneous differential equations
STEP 1 Read in x^tq), x2(t0), t0, At, rf
Set n = 0, Amax =
STEP 2 Compute
f X2(rn), t„)
S rn)
STEP 3 Compute
xj. = Xj(Tn) +/ * At
4 = X2(tJ + g* At
Tn+1 = Tn At
STEP 4 Compute
f = /(x[,X2, t')
g' = g( *l, x'z, r')
STEP 5 Compute
*(’’n+i) = (X + xi)/2 + At*/'/2
y^n+l) = (x'2 + X2)/2 + Sr*g'l2
STEP 6 If the final time has not yet been reached, set n — n 4- 1 and go back to
Step 2. Otherwise stop.
Therefore, Eq. (6.85) is equivalent to the following two first-order differential
equations:
- dxi(r) . . ,, . —— = x2(r), (6.86)
dr
= -12x/t) - -V-x2(r) + y(r). (6.87)
dr
Table 6.5 illustrates the coding of a BASIC program called INTER 2, which applies
a second-order Runge-Kutta numerical integration method to the solution of two
simultaneous differential equations [24, 25, 32, 33]:
= f(x1,x2,-r)
x2 = g( *l> X2> T)-
Table 6.5 shows how the values of x^r) and x2(r) are obtained for r = r0 + n Ar,
for n = 1,2, . . . . A flow chart of the program is shown in Fig. 6.26, and the
BASIC language program is shown in Table 6.6.
In order to use this program, one must define the specific functions/(xls x2, t),
g(x1; x2, t), and y(r) on the specified lines. One must then enter the initial values of
t0, x1(r0), x2(r0), and the time increment Ar. The tabulation step size is a multiple of
Ar for which a print out of results is required (this cuts down on a voluminous
output).Table 6.6 Computer program INTER 2
INTER 2
READY
LISTNH
1 REM THIS ROUTINE APPLIES THE RUNGE-KUTTA METHOD WITH
2 REM SECOND-ORDER ACCURACY TO THE SOLUTION OF THE
3 REM SYSTEM OF DIFFERENTIAL EQUATIONS X' = F(X,Y,T), Y' =
4 REM G(X,Y,T) WITH THE INITIAL CONDITIONS X(T0) = X0,Y(T0) = Y0.
5 REM THE INTEGRATION STEP IS H AND THE SOLUTIONS X(T) AND
6 REM Y(T) ARE TABULATED ON THE INTERVAL TO < = T < = B IN
7 REM STEPS OF SIZE L.
8 REM THE FUNCTIONS F(X,Y,T), G(X,Y,T) ARE ENTERED IN LINES
9 REM 509 AND 510 RESPECTIVELY AS FOLLOWS:
10 REM 509 LET F = F(X,Y,T)
11 REM 510 LET G = G(X,Y,T)
12 REM THE NUMBERS TO, X0, Y0, B, L, and H ARE ENTERED AS
13 REM DATA IN LINE 900.
14 REM
15 REM
100 READ T,X,Y,B,L,H
110 LET M = INT(L/H)
120 LET N = INT((B—T)/L)
130 PRINT "VALUE OF T,"
"VALUE OF X," "VALUE OF Y"
140 PRINT
150 PRINT
160 PRINT T,X,Y
170 FOR J = 1 TO N
180 FOR I = 1 TO M
190 LET XI = X •
200 LET Y1 = Y
210 GOSUB 500
220 LETX=X+H *F
230 LETY=Y+H *G
240 LET T = T +H
250 GOSUB 500
260 LET X = (XI +X)/2 4- 0.5 *HF
270 LET Y = (Y1 +Y)/2 + 0.5 *HG
280 NEXT I
290 PRINT, T,X,Y
300 NEXT J
310 STOP
500 LET Y9 = 12
509 LET F = Y
510 LETG = —(31/5) *Y —12*X+Y9
520 RETURN
900 DATA 0,0,1,10,1,0.01
999 END
2366.6 Digital Computer Techniques 237
Fig. 6.26 Flow diagram INTER 2 for computing the time-domain response.238 Techniques for Determining Control-system Stability 6.6
Fig. 6.27 Unit step response of unity feedback system where
G(s) =
60(1 + 0.5^)
5(1 + 5s)
The solution for a unit step input is shown in Table 6.7. Similarly, the solution
for a unit ramp input is shown in Table 6.8. For both cases, the initial input parameters
were:
To = 0
xi(To) = 0
X2(to) — 1
(initial time)
(initial value of xx(t))
(initial value of x2(r))
T/= 10
At = 0.01
At' = 0.5
(final time)
(time increment)
(tabulation step size)
Figures 6.27 and 6.28 plot the results of the tabulation in Tables 6.7 and 6.8.
Fig. 6.28 Unit ramp response of unity feedback system where
G(s) =
60(1 + 0.55)
5(1 + 55)6.6 Digital Computer Techniques 239
Table 6.7 60(1 + 0.5s)
s(l + 5s)
Unit step response of unity feedback system where G(s)
11 USERS
510 LET G =
RUNNH
10:30
—(31/5) *Y —12*X+Y9
VALUE OF T VALUE OF X VALUE OF Y
0 0 l
1. 0.937669 0.260442
2. 1.00189 -1.43078E-3
3. 1 00013 -5.31968E-4
4. 0.999996 1.68H8E-6
5. 1. 1.084HE-6
6. 1. —4.45157E-10
7. 1. — 1.49581E-9
8. 1. 3.54907E-10
9. 1 3.56945E-1O
10. I. 3.56945E-10
USED: CPU 3.2 1/0 1.2
Table 6.8 Unit ramp response of unity feedback system where G(s)
60(1 + 0.5s)
s(l + 5s)
READY
500 LET Y9 = 12*T+6
RUNNH
VALUE OF T VALUE OF X VALUE OF Y
0 0 1
I. 0.984858 0.994173
2. 1.9833 0.999987
3. 2.98333 1.00001
4. 3.98333 1.
5. 4.98333 1.
6. 5.98333 1
7. 6.98333 1.
8. 7.98333 1.
9. 8.98333 1.
10. 9.98333 1.
USED: CPU 3.0 1/0 1.2240 Techniques for Determining Control-system Stability 6.7
6.7 THE NICHOLS CHART
The Nichols chart [8, 10] is a very useful technique for determining stability and the
closed-loop frequency response of a feedback system. Stability is determined from a
plot of the open-loop gain versus phase characteristics. At the same time, the closed￾loop frequency response of the system is determined by utilizing contours of constant
closed-loop amplitude and phase shift which are overlaid on the gain-phase plot.
c(j<Q
Fig. 6.29 General block diagram of a simple feedback control system.
In order to derive the basic Nichols-chart relationships, let us consider the unity
feedback system illustrated in Fig. 6.29. The closed-loop transfer function is given by
C(ja>) = G(jgj)
R(jai) 1 + G(Ja>)’
or
C(jco)
(6.88)
= M(o))eix(ca), (6.89)
where M(a>) represents the amplitude component of the transfer function and a(co)
represents the phase component of the transfer function. The radian frequency at
which the maximum value of C(jco)lR(Jw) occurs is called the resonant frequency of
the system, and the maximum value of is denoted by Mv. For the
system illustrated in Fig. 6.29, we would expect a typical closed-loop frequency
response to have the general form shown in Figure 6.30.
From Section 4.2 we know that a small margin ofstability would mean a relatively
small value for £ and a relatively large value for M„. This can be further clarified ifwe
Fig. 6.30 A typical closed-loop frequency-response curve for the system shown in Fig. 6.29.6.7 The Nichols Chart 241
Fig. 6.31 Qualitative stability comparison of two systems illustrating corresponding values
of Af(to). (a) Stable system with large degree of stability:
|C(»[ = I G(j<o) I
|A(ya>)| |i + G(yco)|
(b) Stable system with very small degree of stability: M(co) » 1.
= M(a>) « 1.
examine the Nyquist diagrams illustrated in Fig. 6.31. Notice that Af(co) is much
less than unity for the case of a system having a large degree ofstability, as shown in
part (a) of the figure. This situation would correspond to £ » 1. In contrast, Af(<o)
is much greater than unity for the case of a system having a very small degree of
stability, as shown in part (b) of the figure. This situation would correspond to
£ « 1. We next develop the Nichols-chart contours in the complex plane in order to
be able to determine Mp and co„ quantitatively for a feedback control system.
Reconsidering the basic relationships of the unity feedback control system
illustrated in Fig. 6.29, let us represent the complex vector G(jw) by an amplitude and
phase as follows:
G(» = |G(y<u)|e38. (6.90)
Substituting Eq. (6.90) into the system transfer function, as given by Eq. (6.88), we
obtain
G(jm) _ G(joj)
R(jm) 1 + G(jrn)
|G(jco)| eie
1 + |G(y<u)| '
Dividing through by \G(Ja>)\e39, we obtain
C(» = r e-’e + t
R(ym) L|G(ym)|
(6-91)
(6-92)242 Techniques for Determining Control-system Stability 6.7 Loop gain G (db)
Open-loop phase angle (degrees)
Fig. 6.32 Nichols chart,6.7 The Nichols Chart 243
Using the trigonometric relationship for the exponential term, we obtain the
expression
C(ja>)
RM
cos 6
\G(Jco)\
J sin 0 1
|G(»|
(6-93)
The expression ofEq. (6.93) has a magnitude M and a phase angle a which are given by
M(a>) = { 1 +
1 2 cos 0 ~11/2) 1
|G(»|2 |G(»|J / ’ (6.94)
a(<z>) — —tan 1
_____sin 0
cos 0 + |G(ja»)|
(6-95)
A detailed plot of G in decibels versus 0, with M and a as parameters, is illustrated in
Fig. 6.32. Notice the symmetry of these curves about the —180° line.
The stability criterion for the Nichols chart is quite simple since the —1 + jO
point ofthe complex plane corresponds to the 0 db, —180° point of Fig. 6.32. There￾fore, for minimum-phase systems, the phase margin can be determined and the
feedback control system is stable if a plot of G(J(o)H(ja)) on the Nichols chart lies to
the right of the —180° line when crossing the 0 db line.
The Nichols chart can be used for the analysis and/or synthesis of a feedback
control system. For analysis, we can use the Nichols chart to obtain the closed-loop
frequency response from the Bode diagram and determine the maximum value of
peaking, Mv, and the frequency at which it occurs, a>p. From a synthesis viewpoint,
we can use the Nichols chart to meet certain requirements as to the values of Mp and
cop. We demonstrate the use of this method as a tool for analysis in this section. Its
value as a tool for synthesis is illustrated in Chapter 7.
Let us determine the closed-loop frequency response for the third-order feedback
control system which is illustrated in Fig. 6.33. Specifically, we are now interested in
obtaining the values of Mp and a>p using the Nichols chart. They can be obtained by
first drawing the Bode diagram as shown in Fig. 6.34. Then, for each value of co, the
magnitude and phase of G(Ja>) are then plotted onto a Nichols chart as shown in
Fig. 6.35. This figure indicates a phase margin of 30° which agrees with the value
Fig. 6.33 A third-order feedback system.244 Techniques for Determining Control-system Stability 6.7 Phase (degrees) Amplitude (db)
Fig. 6.34 Bode diagram for the system shown in Fig. 6.33 where
11 7
G(.r)H(s) = ------------—------------.
5(1 + 0.05s)(l + 0.1s)6.7 The Nichols Chart 245
Open-loop phase angle (degrees)
Fig. 6.35 Nichols chart for the system shown in Fig. 6.33.246 Techniques for Determining Control-system Stability 6.8
Fig. 6.36 Closed-loop frequency response of the system shown in Fig. 6.33 from the Nichols
chart of Fig. 6.35.
obtained from the Bode diagram (using the corrected curve of Fig. 6.34). The inter￾sections of G(juj) with on the Nichols chart give the closed-loop response from
which Mp and can be obtained. The resulting response, shown in Fig. 6.36,
indicates a value of Mv = 6.8 db (2.2) and <ov = 10 rad/sec.
In practice, a value of Mv = 2.2 is a little too high. Usually, is chosen some￾where between 1.0 and 1.4 (see Section 6.8). The technique of compensation of this
system utilizing the Nichols chart is illustrated in Chapter 7. Let us here, however,
indicate how the constant M loci on the Nichols chart may be used to limit Mv to
some maximum value, say 2.2 db (1.3). Since the interior of the M = 2.2 db locus
consists entirely of constant-magnitude loci which represent M greater than 2.2 db,
we must confine the Nichols locus to the exterior of the M = 2.2 db locus. The
system illustrated in Fig. 6.33 is compensated, to meet certain maximum requirements
of Mj,, in Chapter 7 utilizing the Nichols chart.
6.8 RELATIONSHIP BETWEEN CLOSED-LOOP
FREQUENCY RESPONSE AND THE TIME-DOMAIN RESPONSE
Section 6.7 has illustrated how the closed-loop frequency-domain response may be
obtained from the open-loop transfer function. The next logical question to ask is6.8 Relationship Between Closed-Ioop Frequency Response and the Time-domain Response 247
how to determine the relationship between Mp and the peak overshoot one obtains
in the time domain. In Chapter 4, we defined the time at which the peak overshoot
occurs as tp in terms of £ and (see Eq. 4.28). For example, does an MP of 1.3
mean a 30% transient overshoot in the time domain?
This problem has been analyzed for the general, unity-feedback system of Fig.
6.29 [21], After determining the Fourier transform of the input, 7?(co), and that of
the output, C(w), the value of C(co) was then related to the transient response in the
time domain. The resulting approximate general relationship between MP and the
peak overshoot ofthe transient in the time domain has been shown [21] to be given by
c(t)max < 1.18M,. (6.96)
Therefore, the overshoot in the time domain is, in general, related to MP by some
factor equal to or less than 18%. This approximation is extremely important since it
permits the control-system engineer to correlate peak overshoots in the frequency
and time domains.
For second-order systems, exact relationships can be obtained for Mp and cop in
terms ofthe damping factor £. In order to derive this expression, let us reconsider the
closed-loop transfer function of a second-order system in the following form:
^22 = ———---------= M(w)e)a(“’. (6.97)
K(» (1 - w2/o>2) + j’2£(<o/co„)
Therefore, the magnitude of the closed-loop response is given by
M(co) =------------------------------------------ - • (6.98)
[(i-w2M)2+4^>2jr
In order to find the maximum value Mp of M, and the frequency at which it occurs,
(Op, Eq. (6.98) is differentiated with respect to frequency and set equal to zero. The
frequency (op at which Mp occurs is found to be given by
<op = ronVl - 2£2. (6.99)
Ifthis value of(op is substituted into Eq. (6.98), the value of Mp is found to be given by
1
2^1 - C '
Mp (6.100)
A plot cf Mp versus t, is illustrated in Fig. 6.37. Observe from this figure that Mp
increases very rapidly for £ < 0.4. The resulting transient oscillatory response is
excessively large in this region and is undesirable from practical considerations.
Therefore, systems having a £ < 0.4 are not normally desired. In mechanical
systems, values of Mp in the range of
1 < Mp < 1.4248 Techniques for Determining Control-system Stability 6.8
Fig. 6.37 Af„ versus the damping ratio.
are usually specified, which requires £ > 0.4 if the system is a pure second-order
system. In industrial process control, values of Mp up to 2.0 are often used.
Let us carry the analysis ofthe second-order system one step further by correlating
its frequency and time-domain response. In Section 4.2, we found that the peak
value of c(t) for the step response of a second-order system is given by
cWmax = 1 + (6.101)
To check the correspondence between Mp (from Eq. 6.100) and c(t)max (from Eq.
6.101), consider the case where £ = 0.4. Substituting into Eqs. (6.100) and (6.101),
we find that
Mp = 1.364, (6.102)
<(')max = 1-254, (6.103)
and they are within 18 % of each other as stated in Eq. (6.96). Actually, the difference
is only 8.76 %. As the damping factor £ increases, the correspondence gets better. For
example, if £ = 0.6, then Mp = 1.04 and c(0TOax = 1.09; a difference of only 4.8%.
In general, when £ > 0.4, there is a close correspondence between Mp and c(0max￾For values of £ < 0.4, the correspondence between Mp and c(0max is only qualitative.
For example, for the second-order system and at £ = 0, we find that M„ = oo and
c(0mnx = 2. However, since practical second-order systems usually do not use a
£ < 0.4, the 18% relationship given in Eq. 6.96 is quite accurate for systems of
interest.6.9 The Root-locus Method for Negative-feedback Systems 249
6.9 THE ROOT-LOCUS METHOD FOR NEGATIVE-FEEDBACK SYSTEMS
The root-locus method is a graphical technique for determining the roots of the
closed-loop characteristic equation of a system as a function of the static gain. This
method is based on the relationship which exists between the poles of the closed￾loop transfer function and the poles and zeros of the open-loop transfer function.
The root-locus method, which was conceived by Evans [11-13], has several distinct
advantages. A complete, detailed, and very accurate transient and steady-state
solution can be obtained since the closed-loop poles can be obtained directly from the
root loci. Alternatively, approximate solutions may be obtained, with a considerable
reduction oflabor, ifvery accurate solutions are not required. This and the following
sections present the methods of constructing the root locus and of interpreting the
results for negative and positive feedback systems, respectively. The technique for
synthesizing a system utilizing the root-locus method is discussed in Chapter 7. The
method is a useful one and should be part of the designer’s bag of tricks.
Let us consider the general feedback control system illustrated in Fig. 6.38. In
order to find the poles of the closed-loop transfer function, we require that
1 + G(s)H(s) = 0 (6.104)
G(s)H(s) = -1 = l/(2n + 1)tt (6.105)
where n = 0, ± 1, ±2, .... Equation (6.105) specifies two conditions which must be
satisfied for the existence of a closed-loop pole.
1. The angle of G(s)H(s) must be an odd multiple of it:
angle of G(s)H(s) = (2n + 1)tt (6.106)
where n = 0, ±1, ±2,. •. . .
2. The magnitude of G(s)H(s) must be unity:
|G(5)//(s)| = 1. (6.107)
The construction of the root locus for a particular system can start by locating
the *open-loop poles and zeros in the complex plane. Other points on the locus can be
obtained by choosing various test points and determining whether they satisfy
Fig. 6.38 A nonunity feedback control system.250 Techniques for Determining Control-system Stability 6.9
Fig. 6.39 Vector representation of
\ K(Se + S^)(SE + sc) G(sE)H(sE) = —------ ------- ----- -------
se(se + sb)(sE + sd)
at the exploratory point, sE.
Eq. (6.106). The angle of G(s)H(s} can be easily determined at any test point in the
complex plane by measuring the angles contributed to it by the various poles and zeros.
For example, consider a feedback control system where
G(S)H(S) = ^_+_2^L+ . (6108)
s(s + ss)(s + sD )
At some exploratory point sE, G(s)H(s) has the value
The angle of G(sE)H(sE) is the sum of the angles 0H 02, 03, 0^, and 0S, determined by
the vectors a, (3, y, 8, and e, respectively:
G(Se)H(se) = + Sc) .
SE\SE + SE)(SE + Sp)
(6.109)
Pictorially, Eq. (6.109) can be represented by Fig. 6.39, where the vectors
a = sE + sA (6.110)
0 = se + Sj; (6.111)
y = sE + sc (6.112)
8 = sE + sD (6.113)
£ = Spj, (6.114)
Angle of G(se)H(s^ = £ angles of vectors a, 0, y, 8, and e to point sE
= 0t - 02 + 03 - 04 - 05. (6.115)
Ifthis angle equals (In + 1> where n = 0, ± 1, . . . , then sE lies on the root locus.
If it does not, the point sE does not lie on the locus and a new point must be tried.6.9 The Root-locus Method for Negative-feedback Systems 251
When a point is found which does satisfy Eq. (6.106), the vector magnitudes are
determined and are substituted into Eq. (6.107) in order to find the value of the gain
constant K at the exploratory point sB:
|G(S/;)H(Se)| = ,--'(?+^)'l,<,^ + 5C>', = I- (6.116)
lS7?l l(S£ + SZ?)I l(SJE + SZ>)I
Fortunately, the actual construction of a root locus does not entail an infinite
search through the complex plane. Since the zeros of the characteristic equation are
continuous functions of the coefficients, the root locus is a continuous curve. There￾fore, the root locus must have certain general patterns which are governed by the
location and number of open-loop zeros and poles. Once these governing rules are
established, the drawing of a root locus is not a tedious and lengthy trial-and-error
procedure. We next present eleven basic rules which aid in determining the approxi￾mate location of the root locus.
Rule 1 The number of branches of the locus equals the order of the characteristic
equation. This is true since there are as many roots (and branches) of the root locus
as the order of the characteristic equation. Each segment, or branch, of the root
locus describes the motion of a particular pole of the closed-loop system as the gain is
varied.
Rule 2 The open-loop poles define the start of the root locus (K = 0), and the
open-loop zeros define the termination of the root locus (K = oo). This can easily
be shown by considering Eq. (6.116). At open-loop zeros, K must equal infinity since
there is a zero in the expression due to either sA or sc. However, K must equal zero
when open-loop poles occur since there is a zero in the expression due to sB or sD.
When the order ofthe denominator ofG(s)H(s) is greater than the numerator, the root
locus ends at infinity, whereas if the order of the numerator is greater than the de￾nominator, the root locus starts at infinity.
Rule 3 Complex portions of the root locus always occur as complex-conjugate
pairs if the characteristic equation is a rational function of s having real coefficients.
Rule 4 Sections of the real axis are part of the root locus if the number of poles and
zeros to the right of an exploratory point along the real axis is odd. This is easily
demonstrated from Eq. (6.115). Since the angular contribution along the real axis
due to complex-conjugate poles cancels, the total angle of G(s)H(s) is due only to the
contributions of the real poles and zeros. Therefore, at any exploratory point along
the real axis, the angular contribution due to a pole or zero to its right is 180°, while
that due to a pole or zero to its left is zero.
Rule 5 Angles of asymptotes to the root locus am are given by
a„, = ± (2w + 1)ff , (6.117)
p - z252 Techniques for Determining Control-system Stability 6.9
where
p = number of open-loop poles,
z = number of open-loop zeros,
m = 0, 1,2, . . ., up to m = p — z (exclusively).
This can be shown by considering the root locus as it is mapped far away from the
group of open-loop poles and zeros. In this area, all the poles and zeros contribute
about the same angular component. Since the total angular component must add
up to ± 180° or some odd multiple, Eq. (6.117) follows. Figure 6.40 illustrates the6.9 The Root-locus Method for Negative-feedback Systems 253
asymptotes of a third-order system where
G(s)H(s) =
K
s(s + 4)(s + 5)
(6.118)
The asymptotic angles for the root locus illustrated in Fig. 6.40 are
<Xq = -4-tt/3 = ±60°,
04 = ±3tt/3 = ±180°.
Rule 6 The intersection of the asymptotes and the real axis occurs along the real
axis at sr, where
Sr = ---------------- Snoles ~ Xeros---------------- (6.119)
no. of finite poles — no. of finite zeros
The value of sr is the centroid of the open-loop pole and zero configuration. The
intersection of the asymptotes for the root locus illustrated in Fig. 6.40 is given by
_ (-4 - 5) - 0
3-0
K=0
-^1
Fig. 6.41 Loci for two consecutive poles and zeros on the real axis and the corresponding
relation of |X| versus a.254 Techniques for Determining Control-system Stability 6.9
Rule 7 Consider the simple case where the locus has a branch on the real axis between
two poles as shown in Fig. 6.41 (a). A point must exist where the two branches break￾away from the real axis and enter the complex region of the s-plane in order to
approach zeros which are finite or are located at infinity. Since K has a value of zero
at the two poles and increases in value as the locus moves along the real axis away
from the poles, the X’s for the two branches simultaneously reach a maximum value at
the breakaway point. A plot of |KJ versus a is shown in Fig. 6.41(b). For the case
where the locus has branches on the real axis between the two zeros as illustrated in
Fig. 6.41(c), branches come from poles in the complex region and break-in onto the
real axis. The variation in value of |K'| along the real-axis locus between these two
zeros is shown in Fig. 6.41(d). The two poles that enter the real axis and then move
to zeros on the real axis will enter simultaneously with a value of K which is a mini￾mum since the gain is increasing continuously as the loci approach the zeros. Thus
the breakaway and break-in points can be evaluated from the magnitude condition
for Re y = a and solving for A'(ct). This can be accomplished graphically or by
utilizing
= 0 (6.120)
to find all the maxima and minima of K(o) and their locations. The most straight￾forward method for isolating the factor K is to rearrange the characteristic equation.
An example will illustrate the procedure.
For the system analyzed in Fig. 6.40,
G(s)H(s) =--------- ------------
s(s + 4)(s + 5)
The characteristic equation of this system is given by
1 + G(s)H(s) = 1 +---------------------= 0.
s(s + 4)(s + 5)
Alternatively, this can be written as
K = -s(s + 4)(s + 5).
For the case of Re s = a, we obtain
A^(<t) = — a(a + 4)(ct + 5).
Multiplying the factors together, we have
K(a) = —ct3 — 9ct2 — 20ct.
Taking the derivative ofthis function and setting it equal to zero, we can determine the
breakaway point:
—— = —3u2 — 18ct — 20 = 0.
do￾The roots are
cy = -1.47,
<r2 = -4.53.6.9 The Root-locus Method for Negative-feedback Systems 255
The breakaway point of cq is indicated in Fig. 6.40; the value cr2 is not a possible
solution in this negative feedback example since the root locus does not exist on the
real axis at this point. It is interesting to note that the point —4.53 is a breakaway
point for this system when there is positive feedback present (see Section 6.10).
Points of breakaway of the root locus from the real axis can also be obtained by
considering the transition from the real axis to a point 5t which is a small distance d
off the axis. The basis ofthis method is that the transition from the real axis to sy must
result in a zero net change of the angle of G(s)H(s). This is illustrated for the root
locus considered in Fig. 6.40. For this example,
— (& + ft + &) — (2/i + 1)tt- (6.121)
The very small angles we are considering are equal to their tangents, in radians, as
follows:
Canceling <5, and simplifying, results in the equation
1
4
1
1
1
1 0
Q
<5 — — — 77.
5 — O’!
This can be rewritten as
5 0 _ q_
<T1 4 - (Tj
— u.
5 -
(6.122)
(6.123)
__ 1
4 - ffj
1
5 — <q
= 0. (6.124)
Solution of Eq. (6.124) yields values of a1 equal to 1.47 and 4.53. As indicated before,
the value of 4.53 is impossible for negative feedback. •
Both techniques presented for determining the breakaway and break-in points
are utilized in this book. They are referred to as the maximization (or minimization)
ofK(a) and the transition from the real-axis to the complex-plane methods.
Rule 8 The intersection of the root locus and the imaginary axis can be determined
by applying the Routh-Hurwitz stability criterion to the characteristic equation.
The characteristic equation for the system illustrated in Fig. 6.40 is given by
53 + 952 + 205 + K = 0.
The resulting Routh-Hurwitz array is given by
1 20
9 K
9
K256 Techniques for Determining Control-system Stability 6.9
For this simple array, a zero in the third row indicates a pair of complex-conjugate
poles crossing the imaginary axis. The corresponding value of gain and the value ofs
at which this occurs can be obtained as follows: For the third row to equal zero,
180 - K = 0
9
or
K = 180. (6.125)
Therefore, this system is stable for all gains up to a value of 180. The corresponding
value of 5 occurring at the crossing of the imaginary axis can be obtained from the
expression
9s2 4- 180 = 0,
or
5 = ±j\?20 = ±y'4.48. (6.126)
These values are illustrated in Fig. 6.40.
Rule 9 The angles made by the root locus leaving a complex pole can be evaluated
by applying the principle of Eq. (6.106). This is illustrated by considering the system
shown in Fig. 6.42. Let us calculate the angle that the root locus makes with the
complex pole located at —2 + 2j. An exploratory point, sE, will be assumed slightly
displaced from this pole. The angle made by the root locus leaving the pole at —2 +
2j to the point sE is assumed to be —6 as illustrated in Fig. 6.42. The angles con￾tributed to the point sE, due to various open-loop poles of the system, are given
by (see Fig. 6.42)
-135° - 90° 4- 0 = -180°,
or
e = 45°.
Therefore, the angle contributed by the branch of the root locus leaving the pole at
—2 4- 2y must be sufficient to satisfy the basic relationship given by Eq. (6.106).
The negative sign appears before each of the angles in this angular equation, since
they are in the denominator of the expression given by Eq. (6.106). If zeros were
present, however, they would contribute positive angles since they are in the numerator
of the expression given by Eq. (6.106).
Rule 10 In order to derive a useful relation between the poles of the open-loop
transfer function and the roots of the characteristic equation, consider the following
form of the open-loop transfer function for the system illustrated in Fig. 6 38, where
z, represents the open-loop zeros and pa represents the open-loop poles excluding
those at the origin:
G(s)W(s) =
S" II“=1 (« - Pa)
(6.127)6.9 The Root-locus Method for Negative-feedback Systems 257
Fig. 6.42 Root locus of system where
G(s)H(s) =
s(s2 + 4s + 8) ’
K
In practical physical systems
n + y > x
and the denominator of C(s)jR(s) is of the form
1 + G(s)H(s) = , (6.128)
« TTL1 (« ~ Pa)
where
m = n + y,
= roots described by the root locus.
Substituting Eq. (6.127) into Eq (6.128), and equating the expressions on each side of
the resulting equation, results in the following:
y x m
s" n <s - Pa) + & n(s - z«) = n(«- ri)-
a=l i—1 /«=!
Expanding the product terms of this equation yields
m
= sm - 2 ^s”-1 + • • •. (6.129)258 Techniques for Determining Control-system Stability 6.9
For those open-loop transfer functions where the denominator of <7(s)/7(y) is at least
of degree two higher than that of the numerator (which is often the case in practice),
x < m — 2
and the following is obtained by equating the coefficients ofs’" 1 in Eq. (6.129):
?/ in
1p« = 2 rj.
a=l 7=1
By defining to represent all of the open-loop poles, including those at the origin,
this equation can be written as
in. in
= 1 rj. (6.130)
j=i j=i
Equation (6.130), known as Grant’s rule, indicates that the sum ofthe system roots is a
constant as the gain is varied from zero to infinity. Therefore, the sum of the system
roots is conserved and is independent of gain. This rule, sometimes also referred to
as the conservation of the sum of the roots, aids in drawing the root locus, since it
implies that as certain loci turn to the right, others must turn to the left in order that
the sum of the closed-loop poles may be constant. In addition, this rule, as described
by Eq. (6.130), aids in determining the gain along the root locus. For interest, we
can determine the location of the third root of the system illustrated in Fig. 6.40 when
the root locus crosses the imaginary axis as follows:
1 (-4 - 5) = 2 (+74.48 - y'4.48 + r).
Therefore, at r = —9, the gain is also 180.
Rule 11 The gain along the root locus can be determined in a number of ways.
One of the most fundamental rules of the root locus, Eq. (6.107), can be used to
determine this as indicated previously in Fig. 6.39 and Eq. (6.116). Basically, for any
point along the root locus, the control-system engineer can substitute the distance
of the various poles and zeros to the point into Eq. (6.107) and solve for K. As an
example, let us reconsider the root locus illustrated in Fig. 6.40. We have already
determined that the gain when the root locus intersects the imaginary axis is 180
(using rule 8). Now, let us determine the value of gain at point A. To do this, we
need to solve the following equation:
Measuring the distances |y.t|, |y4 + 4|, and |su + 5| to be 2.2, 3.5, and 4.3,
respectively, and substituting these values into Eq. (6.131), we obtain
------------------ = 1, (2.2)(3.5)(4.3) (6.132)
K = 33.1.
Gains along the rest of the root locus can be similarly determined.6.9 The Root-locus Method for Negative-feedback Systems 259
After the root locus has been sketched by using the eleven rules presented, the
graphical accuracy may be improved by determining the exact location of a few
points. This can easily be performed by applying the relationship of Eq. (6.106).
In general, constructing a detailed root locus is a very tedious, time-consuming
method. Several mechanical construction aids are available. The most commonly
used device is known as the Spirule, shown in Fig. 6.43 [14], This clear-plasticdevice,
which consists of a disk and arm, functions as an angle summer and locus calibrator.
A logarithmic spiral curve on the arm portion enables the logarithm of a length to be
calibrated as an angle. Therefore, the addition of angles reduces to a process of
adding logarithms. Analog and digital computers are other very important tools
used in plotting the root locus. These approaches are discussed in detail in Section
6.11.
Fig. 6.43 A Spirule.
This section will conclude with illustrative examples of the root-locus procedure.
The technique ofstabilizing systems utilizing the root-locus method are illustrated in
Chapter 7.
As the first example, consider a unity negative feedback system whose open-loop
transfer function is given by
K
G(s) =
(s + l)(s — l)(s + 4)2
(6.133)
This system has four poles: three on the negative real axis and one on the positive
real axis. In addition, it has four zeros at infinity. The root locus of this system,
illustrated in Fig. 6.44, can be drawn on the basis of the eleven rules, as follows.
Rule 1 There are four separate loci since the characteristic equation, 1 + G(s)H(s),
is a fourth-order equation.
Rule 2 The root locus starts (K = 0) from the poles located at 1, —1, and a double
pole at —4. All loci terminate (K = co) at zeros which are located at infinity for this
problem.260 Techniques for Determining Control-system Stability 6.9
Rule 3 Complex portions of the root locus occur in complex-conjugate pairs.
Rule 4 The portions of the real axis between — I and 1 are part of the root locus.
Rule 5 The four loci approach infinity as K becomes large at angles given by
«o = ±^/4 = ±45°
and
ai = ±377/4 = ±135°.
Rule 6 The intersections of the asymptotic lines and real axis occur at
Rule 7 The point of breakaway from the real axis is determined using the two
techniques presented: maximization of K(c) and the transition from the real-axis to
the complex-plane methods.6.9 The Root-locus Method for Negative-feedback Systems 261
Maximization ofK(p) Method. From the equation
we obtain
The roots are
1 + G(s)H(s) = 1 +
_________ K_________
(s + l)(s - l)(s + 4)2
= 0,
K= ~(s + l)(s - l)(s + 4)2,
K(a) = -(ct2 - ])(ct + 4)2,
= —2(cr + 4)(2ct2 + 4ct - 1) = 0.
do
CTj = 0.22, ct2 = —2.22, ct3 = —4.
Of these, ot represents the breakaway point from the positive real axis, ct3 represents
the breakaway from the double pole at —4, 0, and ct2 represents the breakaway point
for positive feedback (see Problem 6.33).
Transitionfrom the Real-axis to the Complex-plane Method. The point of breakaway
from the real axis occurring between —1 and 1 will be assumed to lie along the
positive real axis at oY. The angles contributed from the various poles to a point sr
that lies a small distance 8 off the positive real axis are
-d
1 “ ^1
—(& + & + 2/?3) = (2n + 1)tt
8 _ 28 = _
1 + CTX 4 + CTi
or
8 + 28
1 + CTj 4 + CTj
= 0.
Solving, we obtain roots at 0.22 and —2.22. The interpretation of these roots is the
same as with the first method.
Rule 8 This particular root locus intersects the imaginary axis only at the origin.
Rule 9 This rule does not apply to this problem.
Rule 10 This rule shows that as certain of the loci turn to the right, others turn to
the left to ensure that the sum of the roots is a constant.
Rule 11 This rule does not apply to this problem since the problem does not require
the calculation of gains along the locus.
It is interesting to observe from the root locus illustrated in Fig. 6.44 that the
system is always unstable since at least one root of the characteristic equation always
lies in the right half-plane. We illustrate in Chapter 7 the stabilization of this system
by means of a lead network.262 Techniques for Determining Control-system Stability 6.9
Fig. 6.45 Root locus of negative-feedback system where
1.6K(s + 10) G(s)H(s) = -—■ s(s + l)(s + 4)'
As a second example, consider a unity negative-feedback system where
G = K(1 + 0.1s) = 1.6K(s + 10)
s(l + s)(l + 0.25s)2 s(s + l)(s + 4)2
(6.134)
This system has four poles (two being a double pole) and one zero, all on the negative
real axis. In addition, it has three zeros at infinity. The root locus of this system,
illustrated in Fig. 6.45, can be drawn on the basis of the eleven rules presented as
follows:
Rule 1 There are four separate loci since the characteristic equation, 1 + G(s)H(s),
is a fourth-order equation.6.9 The Root-locus Method for Negative-feedback Systems 263
Rule 2 The root locus starts (K — 0) from the poles located at zero, —1, and a
double pole located at —4. One pole terminates (K = oo) at the zera located at —10
and three loci terminate at zeros which are located at infinity.
Rule 3 Complex portions of the root locus occur in complex-conjugate pairs.
Rule 4 The portions of the real axis between the origin and —1, the double poles
at —4, and between —10 and — oo are part of the root locus.
Rule 5 The loci approach infinity as K becomes large at angles given by
«o = ± —= ±60°
4—1
and
a, = ± = ±180°.
4 - 1
Rule 6 The intersection of the asymptotic lines and the real axis occur at
= -9-(-10) _ 0 „
4 - 1
Rule 7 The point of breakaway from the real axis is determined using the maxi￾mization of K(a) and the transition from the real-axis to the complex-plane method.
Maximization ofK(a) Method. From the relation
1 + G(s)H(s) = 1 + = 0.
s(s + l)(s -I- 4)
we have
x = _ s^s + PC5 + 4>2
1.6(s + 10) ’
K(J) = _ + 1>(.q + y
1.6(<r + 10)
Taking the derivative ofX(cr) with respect to a and solving, we obtain roots at —0.45,
—2.25, and —12.5. The root at —2.25 is impossible for the negative-feedback case,
since the root locus doesn’t lie here. In the following section we shall find that —2.25
is the breakaway point for a positive-feedback system. As mentioned previously, the
third breakaway point occurs at the location of the double pole at —4.
Transitionfrom the Real-axis to the Complex-plane Method. The points of breakaway
from the real axis occurring between the origin and —1, and —10 and —co, are
evaluated by summing the angles contributed from the various poles and zero to a
point s1# located a small distance <5 off the negative real axis. In addition, there must
be a breakaway point at the double pole at -4 since sections of the negative real
axis on both sides ofthis double pole are not part ofthe root locus. The point chosen,264 Techniques for Determining Control-system Stability 6.9
as illustrated in Fig. 6.45, is to the left of —10, 0. Actually, it doesn’t matter if the
point is chosen on this segment of the root locus or between the —1,0 point and the
origin. The resulting equation, in either case, will result in the other points of
breakaway:
[ft - 2/j2 - & - M = (2n 4- Dvr,
Solving, we obtain values of ol at 0.45, 2.25, and 12.5. The interpretation of these
roots is the same as with the first method.
Rule 8 The intersection of the root locus and the imaginary axis can be determined
by applying the Routh-Hurwitz stability criterion to the characteristic equation:
54 4- 9s3 + 24s2 + (16 + 1.60 4- 16/C = 0.
A simpler technique in this problem, since the characteristic equation is a fourth￾order equation, is first to solve for the frequencies where the locus intersects the
imaginary axis, and then obtain the maximum values of gain from this expression.
Letting s = Jo, the characteristic equation becomes
The frequencies where the locus crosses the imaginary axis can be calculated from
co4 - J9oj3 - 24co2 + >(16 4- 1.6/0 4- 16/C = 0. (6.135)
Substituting this value into Eq. (6.136), we obtain
or
co4 - 24<y2 4- 16/C = 0 (6.136)
/16 4- 1.6K .. 9 . (6.137)
/I6+L6K? _ 24/!l+L6K\ + ,6K _ „
\ 9 / \ 9 /
Therefore,
Alllllx = 3.2
and the system is stable for 0 < K < 3.2. Substituting /Cluax = 3.2 into Eq. 6.137,
we obtain
/16 4- 1.6(3.2) , ..
co — j — 1.53 rad/sec
as the frequency of crossover.
Rule 9 This rule does not apply to this problem.
Rule 10 This rule shows that as certain of the loci turn to the right, others turn to
the left to ensure that the sum of the roots is a constant.6.10 The Root-locus Method for Positive-feedback Systems 265
Rule 11 This rule does not apply to this problem since the problem does not require
the calculation of gains along the locus.
6.10 THE ROOT-LOCUS METHOD FOR POSITIVE-FEEDBACK SYSTEMS
The rules presented in the previous section for constructing the root locus were
directed towards negative feedback systems. For positive feedback systems, several
of these rules must be modified. The purpose of this section is to indicate the changes
to the rules and apply it to the last problem considered in Section 6.9 for positive,
instead of negative, feedback.
For positive feedback, Eq. (6.104) becomes:
1 - G(s)H(s) = 0 (6.138)
or
G(s)H(s) = 1 = 1/2/177 (6.139)
where n — 0, ±1, ±2, ±3,.... Equation (6.139) specifies two conditions which
must be satisfied for the existence of a closed-loop pole in positive-feedback systems.
1. The angle of G(s)H(s) must be an even multiple of tt:
angle of G(s)H(s) = 2nn, (6.140)
where n = 0, ± 1, ±2, ±3, ....
2. The magnitude of G(s)H(s) must be unity:
|<7(y)//(y)| = 1. (6.141)
Based on Eqs. (6.140) and (6.141), it is necessary to modify Rules 4, 5, 7, and 9 given
in Section 6.9 for construction of the root locus with negative feedback as follows:
Rule 4 This rule is modified for positive feedback so that sections of the real axis
are part ofthe root locus ifthe number of poles and zeros to the right of an exploratory
point along the real axis is even.
Rule 5 For positive feedback, the numerator in Eq. (6.117) is changed to 2mir.
Rules 7 and 9 The transition from the real-axis to the complex-plane method of
Rules 7 and 9 is modified in both cases so that the sum ofthe angles in the calculations
is 2/7tt instead of (2n -F 1)?7. The procedure of Rule 7 using the maximization of K(a)
method is exactly the same for negative- and positive-feedback systems.
These changes will now be considered in view of the last example presented in
Section 6.9 with positive instead of negative feedback. The open-loop transfer266 Techniques for Determining Control-system Stability 6.10
Fig. 6.46 Root locus of a positive-feedback system where
1.6ff(s + 10)
s(s + l)(s + 4)2'
function of the unity feedback linear system with positive feedback is given by (see
Eq. (6.134))
G(s) _ ■ + 10)
s(s + l)(s + 4)2
(6.142)
Let us construct the root locus for this system by reconsidering the changes required
to Rules 4, 5, 7, and 9.
Rule 4 The portions of the real axis between +oo and the origin, and between — 1
and —10, are part of the root locus as indicated in Fig. 6.46.
Rule 5
and
The loci approach infinity as K becomes large at angles given by
a0 = 0
a, = ± - — = ±120°.
4 — 16.10 The Root-locus Method for Positive-feedback Systems 267
Rule 7 The point of breakaway from the real axis is determined using the
maximization of and the transition from the real-axis to the complex-plane
methods.
Maximization ofK(cr) Method. The procedure and resulting equations are exactly the
same as for the negative-feedback case presented in Section 6.9. The only difference
is in the interpretation of the resulting roots. For the positive-feedback case only the
root at —2.25 is possible; the roots at —0.45 and —12.5 are impossible.
Fig. 6.47 Root locus of a feedback system where
G(« =
1.67f(v + 10)
5(5 + 1)0 + 4)2'
for — co < K < 00.268 Techniques for Determining Control-system Stability 6.11
Transitionfrom the Real-axis to the Complex-plane Method. The point of breakaway
from the real axis can be computed from the following equation:
r 8 _ 28
L10 — <71 4 — <7i _
[& - 2& - & - PJ = (6.143)
= _27r. (6.144)
<71—1/ \ Oj J
This equation is similar to the one obtained for the negative-feedback system case.
Solving, we obtain the values of ox as before: 0.45, 2.25, and 12.5. In this case,
however, only the root at —2.25 is possible. The other solutions are impossible since
the root locus doesn’t exist along the real axis there.
Rule 9 This rule does not apply to this problem.
The complete root locus for this system is illustrated in Fig. 6.46. It is interesting to
observe from this figure that the system is unstable for all values of gain, as compared
to the negative feedback case (see Fig. 6.45), where we found that the system was
stable for 0 < K < 3.2.
A useful interpretation is possible if we combine the analyses of Figs. (6.45) and
(6.46) and study the behavior of the feedback system where
G(s)H(s) =
1.6K(s + 10)
s(s + !)($ + 4)2
for
— oo < K < oo.
Figure 6.47 illustrates this combination of negative- and positive-feedback behavior.
Note that the root locus is a continuous curve in going from negative to positive
feedback.
6.11 COMPUTER TECHNIQUES FOR PLOTTING THE ROOT LOCUS
The root locus can be plotted automatically using a variety of methods [2]. A
special-purpose analog computer which satisfies the necessary angle condition of
Eq. (6.106) (or (6.140)) as s is varied can be constructed using servo multipliers [15]. 
Another special-purpose analog computer method utilizes two-dimensional electric
potential distribution techniques in order to plot the complex variables which satisfy
Eqs. (6.106) and (6.107) (or Eqs. 6.140 and 6.141) [16, 17]. In addition the root locus
can be determined utilizing a digital computer [18-20]. Since the analog computer
techniques are less satisfactory and not as commonly used today as the digital
computer method, we will focus our attention on the digital computer technique.6.11 Computer Techniques for Plotting the Root Locus 269
In our discussions, we will only consider the case ofnegative feedback. The procedures
are similar for positive feedback.
The digital computer is a very versatile and flexible tool that is easily adaptable
for automatically determining the roots in the complex plane. The method presented,
based on the material of References 18, 19, and 20, starts at the poles of the control
system and searches for the overall root locus in a segmented manner.
Reference 18 discusses this conceptual algorithm for obtaining the root locus using
a digital computer. It presents the logic that can be used to code a digital computer
in order to determine the locus of points which satisfy Eqs. (6.106), (6.107), and (6.120).
The techniques presented are conceptual and are not designed for a particular machine
or computer language. In addition, specific problems associated with computer
coding are not presented in the following discussion, but must be considered when
determining the root locus of a specific system utilizing a specific digital computer.
The computer logic flow diagrams ofthis technique are illustrated in Fig. 6.48(a)
through (d), and (f). The basis of the conceptual algorithm is a convergent trial￾and-error procedure for progressing from a known point on the root locus to a
Phase 1.
Input and initialization
(a)
Fig. 6.48 (a) Digital computer logic flow chart, phases 1 and 2.270 Tecnniques for Determining Control-system Stability 6.11
succeeding point. Initial points for the algorithm can be determined by realizing that
the locus begins at the poles where the loop gain equals zero. For poles located on the
real axis, the locus will remain on it until some breakaway point is reached. For
these loci, it will be necessary to determine the breakaway points and begin a search
in the complex plane from these points. Terminating points of the root locus are zeros
that are located at some finite value or at infinity. Therefore, it is necessary to test
and determine if a locus point is near a zero or if it appears to be heading away from
the origin of the complex plane.
The procedure determines the root locus in segments which are ultimately joined
together. The process is composed of the following phases:
a) Input and initialization—Fig. 6.48(a).
b) Determine locus segments on real axis—Fig. 6.48(a).
Phase III.
Determination of breakaway and break-in
points of the root locus from the real axis in
the positive half of the complex plane
Fig. 6.48 (b) Digital computer logic flow chart, phase 3.6.11 Computer Techniques for Plotting the Root Locus 271
Fig. 6.48 (c) Digital computer logic flow chart, phase 4.272 Techniques for Determining Control-system Stability 6.11
c) Determine breakaway and break-in points ofroot locus from real axis in positive
(upper) half of complex plane—Fig. 6.48(b).
d) Search for root loci which begin at poles in positive (upper) half of complex
plane—Fig. 6.48(c).
e) Search for root loci which begin at poles on real axis and subsequently enter the
positive (upper) half of complex plane—Fig. 6.48(f).6.11 Computer Techniques for Plotting the Root Locus 273
Fig. 6.48 (e) Estimated root locus point.
f) Reflect the root-locus segments of the positive (upper) half-plane into the negative
(lower) half-plane—Fig. 6.48(f).
g) Produce remaining root loci from unassigned segments—Fig. 6.48(f).
Figure 6.48(d) illustrates a computer subroutine associated with Fig. 6.48(c) and de￾noted as “next point.” Let us next consider some of the details associated with each
of these computer steps.
The input and initialization phase, illustrated in Fig. 6.48(a), is concerned with
reading in poles and zeros of the open-loop gain.
The second phase of the procedure, denoted as the determination ofthe locus on
the real axis in Fig. 6.48(a), consists of three sequences. Poles and zeros with imag￾inary parts equal to zero are determined and are then sequenced in order of decreasing
magnitude. Portions of the locus are then defined for an odd number of real-axis
poles and zeros which exist to the right of a test point.
The third phase, illustrated in Fig. 6.48(b), is concerned with the determination of
breakaway and break-in points of the root locusfrom the real axis in the positive half
ofthe complex plane. The procedure involves determining the location ofthe maxima
and minima of the function K(p) as discussed in Rule 7 for construction of the root
locus.
Search for root loci which begin at poles in the positive half ofthe complex plane.
the fourth phase, is illustrated in Fig. 6.48(c). Successive points of the root locus are
determined and the search for additional points are terminated if the following274 Techniques for Determining Control-system Stability 6.11
conditions occur:
a) A zero is recognized as the termination of the current locus;
b) The termination of the current locus occurs at infinity;
c) The current locus intercepts the real axis.
If the last condition occurs, then it is necessary to determine the succeeding behavior
of the root locus. In general, the following three situations can occur:
Phase V.
Search for root loci which begin at poles on the real axis and
subsequently enter the positive-half of the complex plane
Fig. 6.48 (f) Digital computer logic flow chart, phases 5, 6, and 7 [18],6.11 Computer Techniques for Plotting the Root Locus 275
d) The locus continues onto the real axis and terminates at a zero on the real axis
which is located at a finite value or at infinity;
e) The locus continues on the real axis until a breakaway point occurs and it then
reenters the full complex plane;
f) The locus immediately reenters the imaginary portion of the complex plane.
As each new locus point is obtained, it is examined to determine whether conditions
(a), (b), or (c) occur.
Each real-axis intercept is tested to determine if it lies between the bounds of
real-axis root-locus segments determined in the second phase. If it does not, an
error flag is set, the search for the current root locus is discontinued, and the search
for a new root locus is started. Similarly, the real-axis intercepts are compared with
the breakaway points determined in the third phase. Ifthe intercept is not within some
small error, then an error condition is recognized. If more than one break-in point
exists at the breakaway point, tests are made to determine which ofthem has the same
slope as the current root locus. If no correspondence is obtained, then an error
condition is recognized.
The root-locus continuation is examined next. A test is made to determine
whether the current root locus can be ended at a nearby zero or a zero located at
infinity. If it can, the full locus from start to completion is recorded and displayed.
If the root locus reenters the imaginary portion ofthe complex plane, it will occur at
the nearest unassigned breakaway point. The repeated use of “call next point”
is then applied as indicated.
The “next point” flow diagram is illustrated in Fig. 6.48(d). The real and
imaginary parts ofthe point in the complex plane are treated in a real two-dimensional
space. An estimate is made of the continuation of the root locus. The initial trial
locus point is obtained by computing the intersection of the estimated root-locus
continuation with a circle having a small radius rA, that is centered at the last known
locus point as illustrated in Fig. 6.48(e). There will be two intersecting points and the
computer logic must be able to differentiate between them. The net angle contri￾bution for all poles and zeros is computed at the trial locus point. The difference
A0 is computed and compared with the maximum permissible angular deviation of
GH from iir, ee. If A0 < e8, then the angle criterion is satisfied and the value of K
required to obtain |GH| = 1 is determined. However, if A6 > ea, a new trial locus
point must be found. The procedure used is to search for an acceptable solution
which falls on the previously defined circle illustrated in Fig. 6.48(e). In the figure, a
test point <58 is chosen. The difference of the angular contribution of the poles and
zeros from /tt, evaluated at the new test point, is denoted as A'0 in Fig. 6.48(e). The
change in the angular error is used to determine a new trial locus point on the circle.
After the location of the point and the value of gain are determined, the computer
returns to the main routine.276 Techniques for Determining Control-system Stability
The fifth phase, illustrated in Fig. 6.48(f), is to search for root loci which begin at
poles on the real axis and subsequently enter the positive halfofthe complex plane. Only
those, as yet unassigned, breakaway points in the same segments as the poles which
lead into the right half-plane and which are also unassigned, are examined. If an
assignment can be made, the continuation of the current root locus is determined.
The coding in the box labeled “determine root-locus continuation from pole to zero”
is exactly the same as that used in the fourth phase (see Fig. 6.48(c)) which exists
outside the dotted lines.
The sixth phase, illustrated in Fig. 6.48(f), is concerned with reflecting the root￾locus segments of the positive half-plane into the negative half-plane. The fourth and
fifth phases of the computer routine are sufficient to have determined all of the root￾locus segments in the positive half-plane. Similar segments are also part of the root
locus in the negative half-plane.
Producing the remaining root locifrom the unassigned segments, the seventh and
final computer phase, is illustrated in Fig. 6.48(f). The complete root loci in the
negative half-plane is not completely symmetrical with the root loci previously
determined. It is the function ofthis phase to join all unconnected segments remaining
in the negative half-plane and on the origin to form a complete root locus. This
process can be accomplished by successively accessing unassigned poles, and then
adjoining unassigned segments which are continuous and end in the unassigned zeros.
PROBLEMS
6.1 The differential equation expressing the output r(r) of a second-order system in terms
of its input x(ji is given by
^
d2y(t) dy(t) + B~+Cy(^x(t).
a) Find the ratio of K(/cu)/%(/w) for a sinusoidal input motion in terms of A, B, and C.
b) Plot the ratio y(/a>)/%(/«>) in the complex plane when A = 1, B = 4, C = 16.
6.2 The field of fluidics is a relatively new field with a great potential [2]. The use of fluids
as a power source is not new, but the discovery that this energy can be manipulated and
utilized in much the same way as electricity, and without the need for moving parts, has
sparked the new technology of fluidics. The term fluidics refers to the field of technology
which is concerned with the use of either liquid or gaseous fluids in motion to perform
functions such as amplification, sensing, switching, computation, and control. These systems
have the advantages of high reliability, operation under extreme environmental conditions,
resistance to radiation, and low cost. Fluidic control systems are especially applicable to
fluid-flow systems, such as those using a turbine. Figure P6.2 illustrates the equivalent blockProblems 277
diagram of a fluidic speed control system. Actual speed, derived from a tuning-fork device,
is compared with the desired speed. Any difference is amplified by a fluidic amplifier which
then activates a valve used to control the turbine’s speed.
Figure P6.2
a) Determine the state-variable signal-flow diagram and the vector differential equation of
this system when Ka = 10 and T = 100.
b) Determine the characteristic equation of this system from the relation |P — 5I] =0.
c) Utilizing the Routh-Hurwitz criterion, determine whether the system is stable.
Figure P6.3
6.3 Using the Routh-Hurwitz stability criterion, determine if the feedback control system
shown in Fig. P6.3 is stable for the following transfer functions:
100
a) G(s) = s(s2 + 8s + 24)
,, x 3^ + 1
b) = 52(300.s2 + 6005 + 50)
24
C) G(S) = 5(5 + 2)(5 + 4)
0.2(5 + 2) .
d) G^ = 5(5 + 0.5)(5 + 0.8)(5 + 3)
6.4 Figure P6.4(a) illustrates the submarine depth control problem. The object is to adjust
the actual depth C to equal a desired depth'/?. The control system depends on a pressure
transducer which is used to measure the actual depth. Any difference between the actual
and desired depths is amplified and is used to drive the stern plane actuator through an 
appropriate angle 6 until the actual depth equals the desired depth. An equivalent block
diagram ofsuch a system is illustrated in Fig. P6.4(b). Utilizing the Routh-Hurwitz criterion,
determine whether this system is stable for the parameters indicated.278 Techniques for Determining Control-system Stability
(b)
Figure P6.4
6.5 Using the Routh-Hurwitz stability criterion, determine if the feedback control system
illustrated in Fig. P6.5 is stable.
Figure P6.5
6.6 Automatic control systems are being used to an ever-increasing degree in the railroad
transportation field [28], A very widely acclaimed high-speed rail transportation system is in
operation in Japan [29]. Figure P6.6(a) is a photograph of the Tokyo-to-Osaka railroad
which is commonly referred to as the Tokaido line. Figure P6.6(b) illustrates an equivalent
block diagram for the automatic braking system used to regulate this class of high-speed
trains.
a) Determine the signal-flow diagram and the characteristic equation of this system.
b) Using the Routh-Hurwitz criterion, determine the allowable values of amplifier gain KaFig. P6.6 (a) Tokaido Line. (Courtesy of Japanese National Railways)
P r o b le m s 2 7 9280 Techniques for Determining Control-system Stability
(b)
Figure P6.6 (b)
for system stability. Assume the following parameters:
K-l = 1, K2 = 1000, K3 = 0.001;
a = 0.1, b = 0.1.
6.7 Using the Routh-Hurwitz stability criterion, determine if the feedback control system
illustrated in Fig. P6.7 is stable.
Figure P6.7
6.8 The tool of mathematical modeling can be used to study economic problems of a much
larger scope than that found in a single business organization. The economics concerned
with national income, government policy on spending, private business investment, business
production, taxes, and consumer spending may be represented [2] by the block diagram ofProblems 281
Fig. P6.8. Although business production lags available funds according to a pure time
delay, the representation of G2(s) by the lag factor 1/(1 + Ts), is adequate. Assuming that
E(s) and U(s) are related by
t/(s) = -(A 4-
and government policy is represented by
G^s) = C + Ds,
determine the requirements on C and D in terms of A and B for system stability.
Figure P6.8
6.9 By means of complex-plane plots, determine whether feedback systems represented by
the following values of G(j<ji)H(ja>) are stable.
. . 10
a) G(ja>)H(Ja>) = (1 + yw)(1 + y^ + 3;-w)
10
b) G(ja>)H(Ja>) = ——j)(1 +wyw-)
......... 10
c) G{j(o)H{j<a) = + o.ljco)(l + 0.2jco)
, . . 2
d) G(J(»)H(J<O) = + 01yco)(1 + lOya,) •282 Techniques for Determining Control-system Stability
Do not attempt to plot the exact values of G( Hjw) (jw) for all values of frequency. It should
only be necessary to determine a few values of frequency exactly.
6.10 By means of a complex-plane plot, determine whether the system illustrated in Fig.
P6.10 is stable.
Figure P6.10
6.11 Determine whether the system illustrated in Fig. P6.ll is stable by means of a complex￾plane plot.
Figure P6.ll
6.12 The positive-frequency portions of the complex-plane plots for several transfer
functions are shown in Fig. P6.12. Complete the Nyquist diagram and determine stability,
assuming that G(/a>) has no poles in the right half-plane.
Figure P6.12
6.13 The design of automatic control systems for electronic activation of human limb
movements is an interesting example of the application of control theory [30]. By means of
electrical pulses, a paralyzed limb can be made to contract, with the result that functional
movements of the extremity are performed. Figure P6.13(a) illustrates the concept imple￾mented using conventional control-system techniques. The electronic controller G(s) feeds
electrical signals to the contracting muscle (agonists) which stretch the opposing musclesProblems 283
(b)
Figure P6.13
(antagonists). Figure P6.13(b) illustrates the equivalent block diagram where the following
transfer functions can be assumed :
G(s) = A,
^(s) K'e~T°s
H(s) = 7^) = s(Js + C) ’
Typical values of the parameters are as follows:
J = 1, C = 20, r0 = 0.1, K' = 1.
a) Utilizing the Nyquist diagram, determine the phase margin when the electronic gain, A,
is set at 2.
b) Repeat part (a) when the electronic gain is set at 100.
6.14 Draw the straight-line attenuation diagrams, showing the magnitude in decibels, and
the phase characteristics, showing the phase angle in degrees, as a function of frequency,
for the following transfer functions:
20
a) Ga = 5(1 + 0.5s)(l + 0.1s) ’
2s2
b) Gb = (1 + 0.4s)(l + 0.04s) ’
50(0.6s + 1)
C) Gc = s2(4s 4- 1) ’
_ 7.5(0.2s + l)(s + 1)
Gd s(s2 4- 16s 4- 100)284 Techniques for Determining Control-system Stability
Assuming that GA and Gc represent the open-loop transfer functions of unity-gain feedback
systems, determine the phase and gain margins in parts (a) and (c).
6.15 A feedback control system has the configuration shown in Fig. P6.15.
a) Draw the Nyquist diagram of the loop gain function.
b) Draw the Bode diagram showing the magnitude, in decibels, and phase angle, in degrees,
as a function of frequency.
c) Find the phase margin and gain margin ofthe system. Illustrate these points on the graphs
for parts (a) and (b).
d) Find the values of Kp, Kv, and Ka.
e) What is the steady-state velocity-lag error for a velocity input of 5 rad/sec?
Figure P6.15
6.16 Repeat Problem 6.15 for the transfer function
v ’ j(1 + 0.1 j)(l + 0.0D)'
6.17 A feedback control system has the configuration shown in Fig. P6.17.
a) Plot the Bode diagram for this system.
b) What is the gain crossover frequency? What is the phase margin at gain crossover?
Is the system stable?
c) Find the values of KP, Kv, Ka.
d) What is the steady-state velocity-lag error for a velocity input of 40 rad/sec?
Figure P6.17
6.18 Repeat Problem 6.17 for the transfer function
s(l + 0.55)(l + 0.0015) '
6.19 A tank level control is shown in Fig. P6.19. It is desired to hold the tank level C within
limits even though the outlet flow rate V is varied. If the level is not correct, an error voltage
En is developed which is amplified and applied to a servomotor. This in turn adjusts a valve
through appropriate gearing N and thereby restores balance by adjusting the inlet rate, M2.Problems 285
Figure P6.19
The following relations are valid from this figure:
En = R — C = error in level (in),
Eo = KaEn = voltage applied to motor (volts),
Afj = GjEq = valve position (rad),
M2 = KVMX = tank feed flow (ft3/sec),
C = G2M2 = tank level (in).
The pertinent constants and transfer functions are as follows:
1
G, = ——------ — radians of valve motion per volt, 5(0.1 J + 1) r
G2 = 0.5/5 inches of level per ft3/sec,
Kv =0.1 ft3/sec per radian of valve motion,
Ka = amplifier gain to be set,
Error detector = 1 volt per inch of error.
a) Draw the system block diagram showing all transfer functions.
b) Using a Bode diagram for the solution, determine the amplifier gain Ka required to meet
a required gain crossover frequency of 1.5 rad/sec.
c) With the gain set at the value determined in part (b), what are the resulting phase and
gain margins?
6.20 Repeat Problem 6.19 with an error-detector sensitivity of 10 volts per inch of error.
6.21 By utilizing automatic ship steering systems, a ship can maintain a desired heading
much more accurately than ifit depended on a helmsman correcting the heading at infrequent
intervals. Accurate ship heading is a particularly crucial problem for minesweepers who must
sweep desired, prescribed, straight paths with very little allowable deviations. Figure P6-21
illustrates the overall control problem where <3 represents the deviation of the mine sweeper
from the desired heading and 9 represents the angle of deflection of the steering rudder.
The transfer function relating 0(5) and <5(5) for a 180-ft minesweeper moving at 13 ft/sec is
given by [31]
d(s) 0.164(5 + 0.2)(-5 + 32)
0(7) ~ 52(5 + 0.25)(5 - 0.009) ‘
Determine the Bode diagram for this transfer function.286 Techniques for Determining Control-system Stability
Figure P6.21
6.22 A feedback control system has the configuration shown in Fig. P6.22, where U(s)
represents an extraneous signal appearing at the input to the plant.
a) Assuming that G^s) = 1, plot the decibel-log frequency diagram for this system.
b) It is desired that the steady-state error resulting from an extraneous unit step input sig￾nal at U(s) shall be 0.1 unit. Assuming G/5) — K, determine K to meet this specification.
c) Determine the crossover frequency and phase margin resulting from part (b).
6.23 Repeat Problem 6.22 with the transfer function of G2(s) given by
2
C2(i) “ 5(1 -i- J)(l + 0.1s) '
6.24 A second-order servomechanism has a forward transfer function given by
G(s) =
16
5(2 + s)-
The feedback function is unity.
a) Draw the Bode diagram showing the magnitude and the phase characteristics as a function
of frequency.
b) Using the Nichols chart, plot a curve of frequency response of the closed loop system.
c) What are and
d) Can this system ever be unstable no matter how large the forward gain is made? Explain.
6.25 Repeat Problem 6.24 for
60(1 + 0.55)
5(1 + 55)
G(5) =Problems 287
6.26 Repeat Problem 6.24 for
G(s) =
60(1 + s)
s2(l + 0.1s)'
6.27 A feedback control system has a block diagram as shown in Fig. P6.27.
a) Determine the required gain K for a steady-state velocity-lag error of 30° with an input
velocity of 10 rad/sec.
b) What are the values of Mp and «„?
Figure P6.27
6.28 A unity feedback control system has a forward transfer function given by
10
G(S> “ s(l + 0.1s)(l + 0.05s) ‘
a) Plot G( ja>) on the Nichols chart.
b) What are the values of Mp and wp?
6.29 Repeat Problem 6.28 for
2
C(J) “ s(l + s)(l + 10s) '
6.30 A unity negative feedback control system has a forward transfer function given by
K
= s(l + 0.1s)(l + s) ’
a) Sketch the root locus giving all pertinent characteristics of the locus.
b) At what value of gain does the system become unstable?
6.31 Repeat Problem 6.30 for the following transfer functions:
K
a) G(s) = -2 ,
si
K(\ +s)
b) C(i) ~ s2(l + 0.1s) ’
K(s + 1)
c) G(s) - s(s2 + 8;f + 16) >
K(s + 0.1)2
d) = s2(s2 + 9s + 20) '288 Techniques for Determining Control-system Stability
6.32 Sketch the root locus for a feedback control system having the following forward and
feedback transfer functions:
G(s) = J(^+o°oij ’ H(s) = 1 + 06j￾6.33 Sketch the root locus of a unity, positive, feedback system whose transfer function is
given by
v ’ (s + 1)(5 - 1)( * + 4)2 '
6.34 Sketch the root locus for a negative feedback control system having the following
forward and feedback transfer functions:
K(s + 1) GW = ■>; ' ' , H(s) = 1.
si(s + 2)(s 4- 4)
6.35 Repeat Problem 6.34 for positive feedback. What conclusions can you draw from your
result ?
6.36 Draw the root locus of a positive feedback system where
c<” - - L
6.37 Determine the root locus for a feedback-system whose open-loop transfer function is
given by
K(s + 2)
G(s)H(s) + 4)(5 + + 2s q. 5)
for —1» < K < oo. Indicate all pertinent values on the root locus.
6.38 A negative feedback-system has an open-loop transfer function given by
C(j)H(r) =
K(s + 4)0 + 40)
s30 4- 200)(5 + 900) ‘
a) Draw the root locus and label all pertinent values on the root locus.
b) For what range of values of gain is the system stable?
c) Draw the Bode diagram of the system and correlate the region of stability and instability
with the root-locus results.
6.39 Repeat Problem 6.36 for the case of negative feedback.
6.40 Reconsider the ecological model of rabbits and rabbit-eating foxes presented in
Problem 2.51. The state equations of the process were given by
ii = Ax, — Bxi,
x2 = -Cx2 4- Dxt,
where x, represented the number of rabbits andx2 represented the fox population. Deter￾mine the requirements on A, B, C, and D for a stable ecological system. What occurs if
A is greater than C?Problems 289
6.41 Sketch the root locus for the following negative feedback control system, and de￾termine the range of K for which the system is stable:
c« ’ «« - '■
6.42 Reconsider the model depicting the development of unindustrialized nations dis￾cussed previously in Problem 2.47. For the coefficients listed in part (a) of Problem 2.47,
determine whether the system is stable. Stability in this problem means that the states
xt(f) and x2(f) decrease to zero as time increases.
6.43 The stability ofthe feedback control system shown in Fig. P6.43 is to be determined.
a) Using the Routh-Hurwitz stability criterion, determine whether the system is stable for
the following transfer functions:
r 45
g*(5) = 7T2’
z , 2
Gb(j) “ (5 + 3(5 + 5)’
//(5) = 1.
b) Repeat part (a) for the following transfer functions:
z , 45
G*(s) = TT2’
c) What conclusions concerning stability can you draw from your results in parts (a) and
(b)?
d) Will the outputs, c(t), in parts (a) and (b), differ in response to the same input? Discuss
your results.
Figure P6.43290 Techniques for Determining Control-system Stability
6.44 Determine the range of positive real gain K that will result in a stable system for the
system shown in Fig. P6.44 for the following conditions:
a) The system has negative feedback.
b) The system has positive feedback.
Figure P6.44
6.45 The transfer function of an unknown element in a control system can be determined
by measuring its frequency response using a sinusoidal input. For a particular element,
the frequency and amplitude data shown in Table P6.45 was obtained.
Table P6.45 Experimental data
G) G (jcn) in db
0.1 66
0.2 60
0.4 54
0.7 51
1.0 49
2.0 47
4.0 46
7.0 45
10.0 43
20.0 39
40.0 34
70.0 28
100.0 23
200.0 13
400.0 2
700.0 -8
1000.0 -14
The form of the transfer function is given by
G(s\ = *[1 + (-y/cog)]
y[l + (s/«>(,)][ 1 + (y/wc)]’
Determine the values of K, w„, a>b, and coc.
6.46 The transfer function of an element used in a feedback system is not known explic￾itly, but its frequency response has been measured experimentally and is given in Fig.Problems 291
P6.46. Based on your knowledge of Bode diagram characteristics, determine the transfer
function of this element.
6 47 Electromechanical nose-wheel steering systems have been developed that can supply
general aviation short-haul aircraft with needed maneuverability and durability [36], These
intermediate-sized aircraft must be able to utilize small airfields, many of which do not
have elaborate service and maintenance facilities. During takeoff from such landing strips,
the task of keeping the aircraft on the proper heading is achieved by utilizing nose-wheel
power steering provided by this device. The block diagram of a nose-wheel steering
system is illustrated in Fig. P6.47. Pilot command signals are compared with a feedback
signal representing the nose-wheel’s heading. The resulting error signal is amplified and
applied to a magnetic particle clutch which activates the rotation of the wheel heading
Assuming that LIR = 0.1, Kc = 1, J = 1, Cv = 9, and Ke = 9, utilize the Bode diagram
to determine the gain required to achieve a phase margin of 40°.
Nose wheel
Figure P6.47292 Techniques for Determining Control-system Stability
6.48 The proper design of man-machine control systems requires as much knowledge ot
the human element as that of the machine. Therefore, the determination of the human
transfer function is very essential in order that the performance of man-machine systems
can be evaluated. This problem can be better understood by referring to Fig. P6.48, which
depicts the classical compensatory manual tracking problem. In this configuration, an
operator attempts to maintain a moveable follower coincident with a stationary reference
point that represents the target. A very general and useful form of the human transfer
function, GH(s), which can be applied to manual tracking problems, was provided in
Problem 3.26. It is given by
r f , = K(1 + TAs) e~D>
h( ’ (1 + TLs)(\ + Tns)’
where D represents the operator’s transportation lag, TA represents the operator’s antic￾ipation time constant, TL represents the operator’s error-smoothing lag time constant, and
Tn represents the operator’s short neuromuscular delay. Representative values for the
elements are as follows:
D = 0.2 sec ± 20%,
Ta = 0 to 2.5 sec (variable),
Tl = 0 to 20 sec (variable),
TN = 0.1 sec ± 20%,
K = 1 to 100 (variable).
The gain K and the time constants TA and TL are considered to be variable according to
the control task being performed. This transfer function has met with reasonable success
for predicting manual tracking control system response where the bandwidth is relatively
low. For this problem, assume that the human transfer function is given by the following
expression:
= 10(1 +5) e~°-2s
’ (1 + 10s)(l + 0.1s)’
Assume that the controlled system has a transfer function given by
2
Gs(s) =-.
s
Draw the Bode diagram and determine the phase and gain margin of the resulting system.
Figure P6.48References 293
6.49 The pitch attitude control system for a booster rocket containing attitude and rate
gyros is shown in Fig. P6.49. Sketch the root locus and determine the maximum value of
K that would permit stable operation.
Figure P6.49
6.50 A unity feedback control system has the following forward transfer function-
’ s(s + l)(s + 5)'
a) If the gain is set at 1.1 and one of the closed-loop poles is known to be located at
Sj = -0.5, is the system stable?
b) If the gain is increased to 30 and one of the closed-loop poles is known to be located
at Sj = -6, is the system stable?
REFERENCES
1. R. J. Schwarz and B. Friedland, Linear Systems, McGraw-Hill, New York (1965).
2. S. M. Shinners, Techniques ofSystem Engineering, McGraw-Hill, New York (1967).
3. E. Routh, Advanced Dynamics ofa System ofRigid Bodies, Macmillan, London (1905).
4. A. Hurwitz, “Uber die Bedingungen, unter welchen eine Gleichung nur Wurzeln mit
negativen realen Theilen besitzt,” Math. Ann. 46, 273 (1895).
5. H. Nyquist, “Regeneration theory,” Bell System Tech. J. 11, 126 (1932).
6. W. T. Thompson, Laplace Transformation, Prentice-Hall, Englewood Cliffs, N.J. (1950).
7. S. M. Shinners, “Minimizing servo load resonance error with frequency selective feed￾back,” Control Eng. 51, 51-56 (January 1962).
8. H. Chestnut and R. W. Mayer, Servomechanisms and Regulating System Design, (2nd
Edn.), Vol. I, Wiley, New York (1959).
9. R. C. Dorf, Modern Control Systems, Addison-Wesley, Reading, Mass. (1967).
10. H. M. James, N. B. Nichols, and R. S. Phillips, Theory of Servomechanisms, McGraw￾Hill, New York (1947).
11. W. R. Evans, “Graphical analysis of control systems,” Trans. AIEEC1, 547 (1948).
12. W. R. Evans, “Control system synthesis by root locus method,” Trans. AIEE 69, 66
(1950).294 Techniques for Determining Control-system Stability
13 W. R. Evans, Control System Dynamics, McGraw-Hill, New York (1954).
14. The Spirule, available from'the Spirule Co., Whittier, Calif.
15. F. E. Liethen, An Automatic Root Locus Plotter Using an Electronic Analog Computer,
M.S. Thesis, Air Force Institute of Technology, Wright-Patterson AFB, Ohio, August
1959.
16. M. L. Morgan, “Algebraic function calculation using potential analog pairs,” Proc.
[RE 49, 276-82 (1961).
17. Information supplied by Electro Scientific Industries, Inc., 13900 N.W. Science Park
Drive, Portland, Oregon.
18. J. Lipow, A Computer Algorithmfor Obtaining the Root Locus, National Biscuit Co., New
York (1962).
19. M. J. Remec, “Saddle-points of a complete root locus and an algorithm for their easy
location on the complex frequency plane,” Proc. Natl. Electronics Conf. 21, 605-8
(1965).
20. H. M. Paskin, Automatic Computation of Root Loci Using a Digital Computer, M.S.
Thesis, Air Force Institute of Technology, Dayton, Ohio (March 1962).
21. A. Papoulis, The Fourier Integral and Its Application, McGraw-Hill, New York (1962).
22. ‘"BASIC" Language, Reference Manual, General Electric Co., Information Systems
Division, Pheonix, Arizona (June 1965, Rev. January 1967).
23. Information supplied by Rapidata, The Empire State Building, 350 Fifth Avenue, New
York, N.Y. 10001.
24 D D. McCracken and W. J. Dorn, Numerical Methods and FORTRAN Programming:
With Applications in Engineering and Science, Wiley, New York (1964).
25. S. Gill, “A process for the step-by-step integration of differential equations in an auto￾matic digital computing machine,” Proc. Roy. Soc. (London) A193, 407-33 (1948).
26. S. A. Hovanessian and L. A. Pipes, Digital Computer Methods in Engineering, McGraw￾Hill, New York (1969).
27. E. I. Organick, A FORTRAN IF Primer, Addison-Wesley, Reading, Mass. (1966).
28. B. Blake, “Four views on train control,” Control Eng. 11, 62-68 (December 1964).
29. I. Nakamura and S. Yamazaki, “On the centralized system for train operation and
traffic control—Including signaling and routing information,” Railway Technical Re￾search Institute 5, 9-11 (1964).
30 W. Crochetiere, L. Vovovnik, and J. B. Resnick, “The design of control systems for
electronic activation of human limb movements,” in Proceedings of the 1967 Joint
Automatic Control Conference, pp. 51-57.
31 J. Goclowski and A. Gelb, “Dynamics of an automatic ship steering system,” in Pro￾ceedings ofthe 1966 Joint Automatic Control Conference, pp. 294-304.
32. H. H. Rosenbrick and C. Storey, Computational Techniques for Chemical Engineers,
Pergamon, Oxford (1966).
33. R. W. Hamming, Numerical Methodsfor Scientists and Engineers, McGraw-Hill New
York (1962).
34. T. C. Bartee, Digital Computer Fundamentals (2nd Edn.), McGraw-Hill, New York
(1966).
35. S. M. Shinners, “Which computer—Analog, digital or hybrid?” Machine Design 43,
104-111 (January 21, 1971).
36. J. Camp and M. J. Campbell, “Aircraft Power Steering,” Sperry Rand Engineering
Review 24, 37-40 (1971).7
LINEAR FEEDBACK SYSTEM DESIGN
7.1 INTRODUCTION
After the stability of a feedback control system has been analyzed, by using any of the
tools presented in Chapter 6, it will often be found that system performance is not
satisfactory and needs to be modified. It is necessary to ensure that the open-loop
gain is adequate for accuracy, and that the transient response is desirable for the
particular application. In order for the system to meet the requirements of stability,
accuracy, and transient response, certain types of equipment must be added to the
basic feedback control system. We use the term design to encompass the entire
process of basic system modification in order to meet the specifications of stability,
accuracy, and transient response. The term stabilization is usually used to indicate the
process of achieving the requirements of stability alone; the term compensation is
usually used to indicate the process of increasing accuracy and speeding up the
response.
The compensating (or stabilizing) device may be inserted into the system either
in cascade with the forward portion of the loop (cascade compensation) as shown in
Fig. 7.1, or as part of a minor feedback loop (feedback compensation) as shown in
Fig. 7.2 [1-2]. The cascade-compensation technique is usually concerned with the
addition of phase-lag, phase-lead, and phase-lag-lead devices. The feedback￾compensation technique is primarily concerned with the addition of rate or accelera￾tion feedback. The type of compensation chosen usually depends on the nonlinearities
and the location of the noises in the loop.
Fig. 7.1 Illustration of cascade compensation.
This chapter focuses attention on the tools presented in Chapter 6 which are of
practical and useful interest to the control engineer. Since not all the stability criteria
presented are useful with both cascade and feedback compensation, we will focus our
attention only on the application ofthe techniques to those particular design problems
295296 Linear Feedback System Design 7.2
Fig. 7.2 Illustration of minor-loop feedback compensation.
they are most suited to solve. Chapter 9 discusses the design of linear feedback
control systems from the point of view of modern optimal control theory.
7.2 CASCADE-COMPENSATION TECHNIQUES
Let us consider the system of Fig. 7.1 as our basic starting point in order to analyze
the effects of cascade compensation. The compensating transfer function, Gc(s), is
designed in order to provide additional phase lag, phase lead, or a combination of
both, in order to achieve certain specifications regarding stability and accuracy. We
will illustrate and derive the transfer functions for representative compensating
networks [1-6].
A phase-lag network is a device which shifts the phase of the control signal in
order that the phase of the output lags the phase of the input. An electrical network
Fig. 7.3 A complex-plane plot for a phase-lag network.7.2 Cascade-Compensation Techniques 297
20 log l0
-20 log 10 «
Phase
^u.
£,n(s)
-+f— where “T>T
l + «7s
|£inG")|
Fig. 7.4 Bode diagram of a phase-lag network.
performing this function was illustrated in Table 2.2 as item 4. Its transfer function
was
£out(s) _ I + K2C2s
Ein(s) 1 + (R, + R2)C2s ’ 1 ‘
This can be written in the following more useful form:
£out(s) = 1 + Ts
Ein(s) 1 + aTs ’
where
T = R2C2, a = 1 + Ri/R2.
Observe that a.T > T. A cdmplex-plane plot of this network as a function of
frequency is shown in Fig. 7.3. Notice that the output voltage lags the input in phase
angle for all positive frequencies. In addition, observe that the magnitude of Eout/Ein
decreases from unity at co = 0 to 1/a at co = co. A corresponding Bode diagram for
the phase-lag network is illustrated in Fig. 7.4. The frequency at which the maximum
phase lag occurs, comax, and the maximum phase lag, </>max, can be easily derived.
The results are
COmax = l/(rVa) (7.3)
and
Sin (7.4)298 Linear Feedback System Design 7.2
Values of <^mRX for certain values of a, which are useful for design purposes, are listed
in Table 7.1.
Table 7.1 <Amax as a function of a
a (degrees)
1 0
2 -19.4
4 -36.9
8 -51.0
10 -55.0
20 -64.8
A phase-lead network is a device which shifts the phase of the control signal in
order that the phase of the output leads the phase of the input. An electrical network
performing this function was illustrated in Table 2.2, as item 3. Its transfer function
was as follows:
£ont(s) = R2 1 + R^S______
£in(s) /?! + R2 1 + [R2KR1 + }
This can be written in the following more useful form:
Eout(s)
Ein(s)
1 /I + a7s\
a \ 1 + Ts /
(7.6)
where
R1R2
Rt + R%
Fig. 7.5 A complex-plane plot for a phase-lead network7.2 Cascade-Compensation Techniques 299
Fig. 7.6 Bode diagram of a phase-lead network.
Observe that al > T. A complex-plane plot of this network as a function of
frequency is shown in Fig. 7.5. Notice that the output voltage leads the input in phase
angle for all positive frequencies. In addition, notice that the magnitude of EontlEin
increases from 1/a at a> — 0 to unity at w = co. A corresponding Bode diagram for
the phase-lead network is illustrated in Fig. 7.6. The corresponding values of romax
and </>niax for the phase-lead network are
«„lax = l/(?Va) (7.7)
and
^max = sin”1 —~~ . (7.8)
a + 1
The values shown in Table 7.1 are also true for the phase-lead case except for the sign.
An important practical point to emphasize is that the control engineer would never
in practice use any ratio of a > 10 since the lead network acts as an approximate
differentiator and emphasizes high-frequency noise, which leads to saturation. In
addition, the 1/a term acts as an attenuation which must be made up for somewhere
in the feedback control system, with an amplification whose ratio is a.
A phase-lag-lead network is a device which shifts the phase of a control signal in
order that the phase ofthe output lags at low frequencies and leads at high frequencies
relative to the input. An electrical network performing this function was illustrated300 Linear Feedback System Design 7.2
in Table 2.2 as item 5. Its transfer function was as follows:
£out(s) = ________(1 + KAsXl + K2C2s)_________ (7 9)
£in(s) K1R2C1C2s2 + (R.Cy + R2C2 + R1C2)s + 1 ’
Defining
Tj = R.C., T2 = R2C2, T21 = R,C2
we can rewrite Eq. (7.9) as
E0l,t(s) = 7\T2s2 + (7] + TJs + 1
£in(s) T^s2 + (7; + t2 + T21)s + I ’
A complex-plane plot of this network as a function of frequency is shown in Fig. 7.7.
Notice that the output voltage lags the input in phase angle for low frequencies and
leads in phase angle for high frequencies. In addition, notice that the magnitude of
■Eout/Fin decreases at an intermediate range of frequencies and increases to unity as co
approaches 0 and oo. A corresponding Bode diagram for the phase-lag-lead network
is illustrated in Fig. 7.8.
The stabilizing effect of cascaded, phase-shifting networks can easily be demon￾strated for a simple second-order system. For example, let us consider the configura￾tion illustrated in Fig. 7.1, where the original forward transfer function, G0(s), is
given by
If this system were uncompensated (Gc(s) = 1), then the transfer function G0(s)
would result in the familiar second-order system response which was discussed at
great length in Section 4.2. The resulting damping factor ofthe system would be given
Fig. 7.7 A complex-plane plot for a phase-lag lead network.7.2 Cascade-Compensation Techniques 301
Fig. 7.8 Bode diagram of a phase-lag-lead network.
by £ and its natural frequency by w„. Let us now assume that we add a lead network
to this system whose transfer function is given by
Gc(.s) = 1 -~t~ — . (7.11)
I 4- Ts
It is assumed that the attenuation factor of 1/oc is negated with an amplification
increase of a, and the system will maintain the same static error. Let us consider the
case where T « a.T and, therefore, Gc(s) can be approximated by a zero factor:
Gc(s) 1 + aTs. (7.12)
The form of Eq. (7.12) suggests that this lead network is equivalent to a proportional
plus derivative controller. The resulting system transfer function with the lead
network is given by
C{s)_________ m2(l + aTs)
R(s) s2 + (2£<z>„ + aTw2)s + <o2
Comparing the denominators of Eqs. (7.13) and (4.3), we observe that it is still of
second order and co„ remains the same, but £ is greater due to the increase in the
coefficient of 5 in the denominator. The equivalent damping factor with Gc(s) can be
obtained as follows:
2£co„ + aTw2 = 2£cq<o„ (7-14)
where
£ = an equivalent damping factor with phase-lead compensation.
Solving for £ei., we obtain
£cq = £ + ar<0„/2. (7.15)302 Linear Feedback System Design 7.2
Therefore, we can conclude that the addition of a zero factor in Gc(s) has increased
the damping factor from £ to £eq by an amount equal to a.Ta>n/2. This assumes that
T is positive, or the zero of the factor (1 + a. 7s) is in the left half of the s-plane.
The next question is what is the steady-state error resulting from cascade compen￾sation? To answer this, we must find the steady-state errors resulting from the
application of a unit ramp input for the cases of no compensation and compare them
with those resulting from cascade compensation. We choose a unit ramp as our input
since it is the only input which results in a finite response error for a system with a pole
at the origin. The transfer function relating error to input for the system shown in
Applying the final-value theorem to Eq. (7.17), we find the steady-state error to be
Fig. 7.1 is given by
£(s) 1
(7-16)
R(s) 1 + Gc(s)G0(s) ’
Assuming that
Gc(s) = I (no cascade compensation),
2
c, fA U>n
and
> s(s + 2^„)
we find that
R(s) = 1/s2 (a unit ramp input);
r/A s “I" XS ( 5 ) — (7-17)
s(s2 + 2&)ns + co2)
ess(ramp input) = lim sE(s) = . (7.18)
s-»0 COn COn
For the case with cascade compensation, a similar analysis yields the following
result:
r ( s 1 + aTs Gc 5) - ,
1 + Ts
Therefore,
G0(s) = ---------, R(s) = •
s(s + 2£w„) s2
£(s) = 1 —— (s + 2£to„)(l + Ts)
s [s(s + 2£<o„)(l + Ts) + co2(l + aTs)]
Applying the final-value theorem to Eq. (7.19), the steady-state error is found to be
OX OX
^ssframp input) ~ lim sE($) — ~ . (7.20)
s-o a>n a>n
Comparing the results of Eqs. (7.18) and (7.20), we conclude that the addition of the
cascade lead network as given by Eq. (7.11) does not increase or decrease the steady￾state response error of the system.7.3 Minor-loop Feedback Compensation Techniques 303
It is important to emphasize that the relationships derived in this analysis apply
only to the simple system considered. For example, if a zero factor were contained in 
the numerator of Eq. (7.10), then these relationships are modified (see Problems 7.5
and 7.6).
If we attempt to extend this analysis of a second-order system to the case of
phase-lag compensation, the characteristic equation becomes third order and
difficult to factor. For example, if GC(J) were only to represent the pole factor of the
phase-lag network, then
In a similar manner, the closed-loop system transfer function can be found to be
given by
---------------------- . (7.22)
7?(s) a.Ts3 + (2£ti>„aT + l)s2 + 2£co„s + <y2
The factorization ofthis characteristic equation is not trivial and a similar analysis to
that performed for the lead-network case is not possible.
7.3 MINOR-LOOP FEEDBACK COMPENSATION TECHNIQUES
Let us next consider the general system illustrated in Fig. 7.2. The compensating
element in this case is the transfer function B(s). In order to have a basis of com￾parison, we will follow an analysis for minor-loop feedback compensation similar to
that performed for the case of lead-network cascade compensation.
The minor-loop feedback element 5(s) usually represents rate feedback or accelera￾tion feedback. In general, phase-lag, lead, and/or lag-lead networks may also be
cascaded with 5(5).
The stabilizing effect of minor-loop feedback compensation can easily be 
demonstrated for a simple second-order system. We assume that the system illustrated
in Fig. 7.2 consists of simple rate feedback. The specific transfer functions for the
system are
6/5) = !, (7.23)
w2
s(s + 2(wJ
(7.24)
5(s) = bs. (7-25)
Without any rate feedback, the configuration represents a simple second-order system
whose damping factor is and natural frequency is wn. The resulting system transfer
function with rate-feedback compensation is given by
9^) = . (7.26)
R(s) s2 + (2£<w„ + w2b)s + w2304 Linear. Feedback System Design 7.3
Comparing the denominator of Eq. (7.26) with that of Eq. (4.3), we observe that
it is still ofsecond order and ojn remains the same, but £ is greater due to the increase
in the coefficient of s in the denominator. The equivalent damping factor with rate
feedback added can be obtained by setting the coefficients ofthe s terms equal to each
other, as follows:
2£co„ + c»2b = 2£eqcon, (7.27)
where £cq = an equivalent damping factor with rate feedback added. Solving for
£cq, we obtain
+ (7.28)
Therefore, we can conclude that the addition of the minor-loop using rate feedback
has increased the damping factor from £ to £eq by an amount equal to con6/2. This
assumes that b is positive (negative feedback).
It is important at this point to compare Eqs. (7.15) and (7.28). Note that they
are very similar, and they imply that
a.T,= b. (7.29)
Fig. 7.9 The stabilizing effects of the systems illustrated are equivalent, (a) Cascade
compensation—proportional plus derivative controller, (b) Feedback compensation.7.3 Minor-loop Feedback Compensation Techniques 305
The fact that rate feedback behaves as the approximated lead network, as defined by
Eq. (7.12) (proportional plus derivative controller), can be easily demonstrated from
Figs. 7.9(a) and (b). Let us assume that there is zero input to both systems, since we
are concerned only with the system poles. Clearly, in both cases, there are two
negative feedback paths in parallel around G0(s). In the cascade-compensation case,
the total feedback around G0(s) is 1 F a7s; in the rate-feedback-compensation
case, the total feedback around G0(s) is 1 + bs. Therefore, the stabilizing effects of
a.T and b are equivalent.
Let us next determine the steady-state error resulting from the use of minor-loop
rate-feedback compensation. We assume that the input to this system is a unit ramp
in order to have a finite steady-state response error and a basis for comparison. From
our discussion of cascade compensation in Section 7.2 we know from Eq. (7.18) that
the resulting steady-state error of this system without any compensation (b = 0) is
2^1a>„- For the case of minor-loop rate-feedback compensation, the resulting expres￾sion for E(s) is given by
t-z \ If” 5 F 2^(i)n F bcon "1
£(s) = " 7 "ITr-----L L 2 • (7.30)
sLs(s F 2c,0)ri F £><o') F«„J
Applying the final-value theorem, the steady-state error is found to be
^ssframp input) sE($) , F b. (7.31)
s^o a>n a>n
Therefore, the steady-state response error of the system with minor-loop rate-feedback
compensation has increased by a factor of b. This unfavorable result can easily be
remedied by placing a high-pass filter in cascade with the rate signal. Such a filter
would block the steady-state value of the rate output. This technique is illustrated in
Fig. 7.10.
Fig. 7.10 Illustration of minor-loop feedback compensation using a rate device in cascade
with a high-pass filter.306 Linear Feedback System Design 7.4
As in the preceding section, it is important to emphasize that the relationships
derived apply only to the simple system considered. Problems 7.5 and 7.6 illustrate
how these relationships change if a zero factor is added to the basic system transfer
function considered.
7.4 AN EXAMPLE OF THE DESIGN OF A LINEAR FEEDBACK CONTROL SYSTEM
In this section we consider the design and resulting performance of the second-order
system by means of cascade and minor-loop rate-feedback techniques. This problem
is useful in unifying concepts which were introduced in Chapters 4, 5, and 6, together
with the design techniques to be illustrated later in this chapter.
(a)
(b)
Fig. 7.11 Design of a second-order system.
Let us consider the second-order system illustrated in Fig. 7.11(a). We will
assume that the original forward-loop transfer function G0(s) is given by
G0(s) 14.4
s(0.1s + 1) '
(7.32)
The closed-loop transfer function, C(s)/R(s), is given by
C(s) = G„(s) = 14 4/[s(0 Is + 1)]
R(s) 1 + G0(s) 1 + 14.4/[s(0.1s + 1)J
or
C(s) = 144
R(s) s2 + 10s + 1447.4 An Example of the Design of a Linear Feedback Control System 307
Comparing Eqs. (4.3) and (7.34), we observe that the natural frequency con and
damping factor £ of the system are given by
cjn = 12 rad/sec (7.35)
and
I = 0.417. (7.36)
Ifthe system is subjected to a unit step input, the transient response will have the form
shown in Fig. 4.4 (interpolate between £ = 0.4 and £ = 0.6). The maximum percent
overshoot can be obtained from Eq. (4.32) and is found to be 23.5 %.
Let us assume, for this application, that it is desired to have a critically damped
system (£ = 1). We will demonstrate how this can be achieved using a cascaded
network and minor-loop rate feedback.
Figure 7.11(b) illustrates the form that the system illustrated in Figure 7.11(a)
would have if a cascaded network were used. We attempt to achieve a damping factor
equal to 1 using a lead network, where
G.(s) =
1 + Ts
As was assumed previously, in Section 7.2, we assume that 7'« aT', and therefore
Gc(s) can be approximated by
Gc(s) & 1 + aTs. (7.38)
The closed-loop system transfer function for this case was derived in Section 7.2 (see
Eq. 7.13) as
C(s) raw + <x.T(otls 39)
R(s) s2 + (2£w„ + aTcu2)s 4- to2
The equivalent damping factor for this situation was derived in Section 7.2 (see
Eq. 7.15) as
U = I + ■ (7.40)
The object in this problem is to design £C(1 = 1 for the case where
£ = 0.417 and a>n = 12.
Substituting the values into Eq. (7.40), we find that
aT = 0.0972.
We know that the resulting system will be stable and critically damped, and will
have a steady-state response error for a unit step input of zero. The steady-state
response error of the system to a unit ramp input was derived (see Eq. 7.18) as
2£ 2(0.417)
^(ramp input) = ~ = 0 0695 UnltS>
a>„ 12
(7.41)308 Linear Feedback System Design
Fig. 7.12 Minor-loop feedback added to the system shown in Fig. 7.11(a).
Let us next attempt to achieve the same type of performance using minor-loop
rate feedback. Figure 7.12 illustrates the form that the system illustrated in Fig.
7.11(a) would have if minor loop feedback were used. Our goal is to achieve a
damping factor of £ = 1. The closed-loop system transfer function for this case was
derived, previously, in Section 7.2 (see Eq. 7.26) as
= -------------------- ^2------------------- . (7.42)
R(s) s2 + (2£co„ + w2b)s + co2
The equivalent damping factor for this configuration was derived in Section 7.2 (see
Eq. 7.28) as
U = £ + <onb/2. (7.43)
The object in this problem is to design £cq = 1 for the case where
£ = 0.417 (7.44)
and
= 12. (7.45)
Substituting these values into Eq. (7.43), we find that
b =■- 0.0972. (7.46)
We know that the resulting system will be stable and critically damped, and will
have a steady-state response error of zero for a unit step input. The steady-state
response error of the system to a unit ramp input was derived (see Eq. 7.31) as
2£
ess(ramP input) = — + 6 = 0.0695 + 0.0972 = 0.1667 units. (7.47)
<*>n
This increase has been accounted for in Section 7.3; by using a high-pass filter in the
feedback path to block a steady-state output from the rate feedback, the steady-state
error can be reduced to 0.0695.7.5 Design Utilizing the Bode-Diagrarti Approach 309
7.5 DESIGN UTILIZING THE BODE-DIAGRAM APPROACH
The techniques necessary to construct and analyze the open-loop frequency response
of a feedback control system utilizing the Bode-diagram approach were presented in
Section 6.5. This section illustrates how the Bode diagram can be used for designing
a feedback control system in order to meet certain specifications regarding relative
stability, transient response, and accuracy. It is important to emphasize that the
Bode-diagram approach is used very frequently by the practicing control engineer.
Its use is due to the fact that the anticipated theoretical results may be relatively
simply checked with actual performance in the laboratory just by opening the
feedback loop and obtaining an open-loop frequency response of the system.
Bode’s primary contribution to the control art is summarized in two theorems [7].
We introduce the concepts embodied in these theorems first in a qualitative manner,
and then the mathematical statements are given.
A. Bode’s Theorems Bode's first theorem essentially states that the slopes of the
asymptotic amplitude-log frequency curve implies a certain corresponding phase
shift. For example, in Section 6.5 it was shown that a slope of 20h db/decade (or
6n db/octave) corresponded to a phase shift of 90n° for n = 0, ±1, ±2, . . . .
Furthermore, this theorem states that the slope at crossover (where the attenuation￾log frequency curve crosses the 0 db line) is weighted more heavily towards determin￾ing system stability than a slope further removed from this frequency. This results in
a rather complex weighting factor which is a measure of relative importance toward
determining system stability.
From what has been presented so far, this theorem is intuitively seen to be valid.
The crossover frequency is one of the two points that is checked to determine the
degree of stability when using the Bode diagram. Specifically, the phase shift is
measured at this particular frequency in order to determine the phase margin. A
feedback control system whose slope at crossover is —20 db/decade, and whose other
slope sections are relatively far away from crossover in accordance with the relative
weighting function, implies a phase shift of approximately —90° in the vicinity of
crossover and a corresponding phase margin of about 90°. This value of phase
margin certainly implies a stable system. A system, however, whose slope at crossover
is —40 db/decade, and whose other slope sections are relatively far away from
crossover in accordance with the relative weighting function, implies a phase shift of
approximately —180° and a corresponding phase margin of about 0°. This value of
phase margin implies a system which is on the verge of being unstable and would
probably be so when actually tested. Steeper slopes would indicate negative phase
margins and definitely unstable systems. Therefore, one strives to maintain the slope
of the amplitude-log frequency curve in the vicinity of crossover at a slope of —20
db/decade. Notice that the system, illustrated in Fig. 6.20, has slopes of — 60 db/
decade that are relatively far removed from the crossover frequency. Therefore, this
system has a fairly respectable phase margin of 54° by maintaining the —20 db/decade
slope for about an octave below, and about 2 octaves above crossover.310 Linear Feedback System Design 7.5
Bodes second theorem essentially states that the amplitude and phase charac￾teristics oflinear, minimum-phase shift systems are uniquely related. When we specify
the slope of the amplitude-log frequency curve over a certain frequency interval, we
have also specified the corresponding phase shift characteristics over that frequency
interval. Conversely, if we specify the phase shift over a certain frequency interval,
we have also specified the corresponding amplitude-log frequency characteristic over
that frequency interval. The theorem emphasizes the fact that we can specify the
amplitude-log frequency characteristic over a certain interval of frequencies together
with the phase shift-log frequency characteristics over the remaining frequencies.
It should be emphasized that these conclusions apply only if the transfer function is
minimum phase.
The second theorem may appear quite trivial at first glance. Its implications
however, are quite important. We will make further use ofthis theorem when design￾ing feedback control systems using the Bode-diagram approach.
The formal mathematicalstatement ofBode'sfirst theorem is given by the following
expression
dC
dn
In coth dn, (7 48)
n
2
where </>(cod) represents the phase shift ofthe system in radians at the desired frequency
cod, G represents the gain in nepers (1 neper = In |e|), n = In (w/wd), \dGjdn\
represents the slope of the amplitude-log frequency curve in nepers per unit change of
n (note that 1 neper/unit change ofn is equivalent to 20 db/decade), |dG/dn\d represents
the slope of the amplitude-log frequency curve at the reference frequency a>d, and
In coth |«/2| represents the weighting function which is plotted in Fig. 7.13. The first
Fig. 7.13 Plot of the weighting function used in Bode’s first theorem.7.5 Design Utilizing the Bode-Diagram Approach 311
term of Eq. (7.48) represents the phase shift contributed by the slope ofthe amplitude￾log frequency curve at the reference frequency wd. For example, it yields a phase shift
of 90° for every neper per unit of n (20 db/decade). The second term of Eq. (7.48) is
proportional to the integral ofthe product of the weighting function and the difference
in slope of the amplitude-log frequency curve at a frequency w as compared to its
value at the reference frequency, cod. Attention is drawn to the fact that it is the
weighting function that determines the phase shift contribution at cod due to the
amplitude-log frequency curve which exists at some frequency co. Since the second
term of Eq. (7.48) is zero for large values of n and where n = 0, the value of the
integral will be relatively small compared with the first term if the slope of dG[dn is
constant over a relatively wide range of frequencies about <od. Therefore, under these
conditions, the phase shift would be determined primarily by the first term of Eq.
(7.48). Following this line of reasoning, the slope of the amplitude-log frequency
curve should be less than —2 nepers per unit of n (—40 db/decade) over a relatively
wide range of frequencies at crossover in order to ensure stability.
The formal mathematical statement of Bode's second
following expression:
p____ G do\ f°°____ <f>doj_______
-'o a/co2 — co2 (co2 — co2) J“’a/co2 — co2 (co2 — co2)
I
TT <Kwg)
2 CO^V w2 ~
2 codVw2 - «2
where cos represents the frequency in radians per second below which the amplitude￾log frequency characteristic is specified and above which the phase characteristic is
specified. This theorem emphasizes the interdependence of amplitude and phase shift
over the entire range of positive frequencies. In addition, notice that although it is
possible to specify amplitude or phase in one range of frequencies, and the other
quantity in the remaining frequencies, these quantities reflect their presence back into
the other range of frequencies. Therefore the integration with respect to frequency is
performed over the entire range of positive frequencies.
The design of several systems using the Bode-diagram approach is considered
next. We shall illustrate a method that determines steady-state accuracy from the
Bode diagram as well as meeting relative stability requirements.
B. Example of Lead and Lag Compensation Let us first consider the third-order
system illustrated in Fig. 7.14. Its open-loop transfer function, G0(s), is given by
theorem is given by the
(for cod < coj
(7.49)
(for cod > cod
s(l + 0.02s)(l + 0.05s) ‘312 Linear Feedback System Design 7.S
Fig. 7.14 A third-order system which is to be compensated.
The Bode diagram for the uncompensated system (Gc(s) = 1) is illustrated in Fig.
7.15. It indicates a crossover frequency <wc of 38 rad/sec, a phase margin y of —17°,
and a gain margin of —6 db. These results indicate that the uncompensated system is
unstable. Let us next attempt to compensate this system with a simple lag and then a
lead network. To achieve an acceptable transient response for the specific application
of this system, the phase margin should be approximately 30° and the gain margin
about 7 db (see Section 6.4). Also, it is assumed that a sinusoidal disturbance at 1 rad/
sec is present, and a gain of 38 db is required at this frequency to nullify its effect.
Phase (degrees) Amplitude (db)
Fig. 7 15 Compensation of a third-order system where
5(1 + 0.025)(l + 0.055) ‘7.5 Design Utilizing the Bode-Diagram Approach 313
Let us first consider the lag-network compensation case. Applying Bode’s
theorems in order to achieve the specified phase and gain margins, we would expect
that the — 20db/decade slope in the vicinity of the new crossover frequency should
not extend over too wide a range of frequencies since the relative stability that is
desired is rather moderate. The lag network is of the form:
1 4- Ts Gc(s) = - f J 5 , (7.51)
1 + a.Ts
where a.T > T. In Section 7.2 we studied the characteristics of the phase-lag network.
In particular, Fig. 7.4 illustrated the Bode diagram of a general phase-lag network.
Notice that this type of network is of such a nature that it attenuated all high
frequency components above a> = 1/T by a factor of 1/a. From the Bode diagram
viewpoint, this attenuating characteristic can be used for stabilization purposes by
reshaping the uncompensated amplitude characteristics, so that the initial —20
db/decade is made to cross over the 0 db line rather than the —40 db/decade segment.
In other words, one would attempt to stabilize this system with a phase-lag
network by placing the frequencies 1/aT and 1/T in the range of frequencies below
about lOrad/sec. It would be desirable that the —20 db/decade segment start at
least around lOrad/sec and cross over the Odb line before 20 rad/sec where the
amplitude-log frequency characteristic changes to a slope of —40 db/decade. In
addition, we would not want 1/aT to occur at less than 1 rad/sec, since an open-loop
gain of 38 db has been specified at co = 1 rad/sec. The final phase of the solution is
by means of iteration. However, the procedure converges quite rapidly. Usually,
two or three iterations should prove sufficient. For the requirements specified, a
phase-lag network given by
Gc(s) = 1 + °-1-4-35- (7-52)
1 + s
results in a phase margin of 30° and a gain margin of 7 db.
Let us next consider the lead-network compensation case. The lead network has
the form
Gc(s) = U1 +-<XT.S\ (7.53)
a\ 1 4- Ts)
where aT > T. In Section 7.2 we studied the characteristics of the phase-lead
network. We assume that any low-frequency attenuation, which is due to the value of
1/a, is made up for by increasing the gain of the feedback control system by a like
amount. The Bode diagram of a general phase-lead network was shown in Fig. 7.6.
From the Bode-diagram viewpoint, this type of characteristic can be used for stabiliza￾tion purposes by reshaping the uncompensated amplitude characteristics so that a
—40 db/decade slope is made to cross over the Odb line along a synthesized -20
db/decade slope rather than the -40 db/decade segment. The range of frequencies
where one can place the frequencies 1/aT and l/T is quite limited in this particular314 Linear Feedback System Design 7.5
problem. The value of 1/a.Tcan be placed between 20 and 38 rad/sec. The closer it
is to 20 rad/sec, the greater will be its stabilizing effect. The further away the break at
1/7” is from 38 rad/sec, the greater will be the stabilizing effect of the lead network.
It can be seen that this particular solution does not modify the open-loop charac￾teristics in the vicinity of 1 rad/sec and the accuracy specification of 38 db at 1 rad/sec
will easily be achieved. After some trial and error, a phase-lead network given by
G = 1 + 0.04s (7 54)
1 + 0.005s
results in a phase margin of 27° and a gain margin of 8 db- This is close enough to the
desired result for all practical purposes. Observe the fact that although we are actually
crossing the 0 db line at an asymptotic slope of —40 db/decade, the system is still
stable. This can clearly be understood from Bode’s first theorem and the weighting
diagram shown in Fig. 7.13. Notice that the resulting lead network has a low￾frequency attenuation of 0 005/0.04 which must be made up by increasing the gain by
a factor of 0.04/0.005.
If we have a choice of using the phase-lag or phase-lead network, the phase-lag
network solution would be preferable since it meets the required specifications with a
narrower bandwidth than the lead network case (<uc = 12 for the former; a>c = 54
for the latter). A feedback control system having a narrower bandwidth will reject a
greater amount of noise than one having a wider bandwidth, as well as requiring less
power and cost. In addition, the phase-lead network has the disadvantage ofrequiring
a greater amount of amplification within the control system than the lag network.
C. Obtaining Steady-State Error Coefficients from the Bode Diagram The steady-state
error coefficients can be determined from the Bode diagram. The definition and
importance of these error coefficients have been discussed in Section 5.4. For a
system having one pure integration, the velocity constant Kv can be obtained by extend￾ing the initial —20 db/decade slope until it intersects the 0 db line. The frequency at
which it intersects this line is equal to the velocity constant. We recall from our
discussion in Section 5.4 that K„ was obtained by letting s approach zero when
utilizing the final-value theorem (see Eq. 5.18). Therefore, the time-constant factor
terms having the form (1 + 7s) or [(7s)2 + 2£7s + 1] all approach unity. This
permits one to obtain A'(1 directly by considering only the initial slope of the Bode
diagram. For the Bode diagram shown in Fig. 7.15, the value Kv obtained graphically
is 80. As a check, using the definition given by Eq. (5.18), we obtain
Kv = lim sG(s)H(s). (7.55)
Since
, 80 G(s) ----------------------------------- ’ (7 56)
5(1 + 0.02s)(l + 0.05s) V 7
H(s)=l, (7.57)7.5 Design Utilizing the Bode-Diagram Approach 315
then,
s(80) Kv = lim-------------—------------- = 80.
s(l + 0.02s)(1 + 0.05s)
(7-58)
It is also interesting to note that the velocity constant is the same for the uncom￾pensated and compensated systems.
For a system which has a double pole at the origin, the acceleration constant Ka
can be obtained in a similar manner. The initial —40db/decade slope is extended
until it intersects the 0 db line. The square of the frequency at which it intersects this
line is equal to the acceleration constant.
(7-59)
D. Application of Bode Diagram to a System Containing a Disturbance The next
system we consider is illustrated in Fig. 7.16. This consists of a third-order system
which has an unwanted external input U(s). The open-loop transfer function for the
uncompensated system, G0(s), is given by
2 2
G0(s) = -------------------—-------------------
(1 + 0.1s)(l + 0.4s)(l 4- 1.2s)
It is desired that the steady-state error resulting from an unwanted, external step
input signal at U(s), should not exceed 0.1 unit. The compensation device, Gc(s),
is to contain amplification which will meet this accuracy requirement together with a
phase-lead or phase-lag network which will provide a phase margin of about 30° and
a gain margin of 5 db.
Fig. 7.16 A third-order system having an unwanted external input.
The value of gain required for Gc(s) will be computed first. For this calculation,
U(s) is assumed to be the input and E(s) is assumed to be the output. The transfer
function between these two points is given by
£(5) _ ___________________2.2(1 4- T2s)_____________________ 60)
U(s) (14- T2s)(l 4- 0.1s)(l 4- 0.4s)(l 4- 1.2s) 4- 2.2K(1 4- 7\s)'
Setting U(s) = 1/s, we obtain the expression for the Laplace transform of the error,
£(s), as
2.2(1 4- T2s)
£(s) = --------------------------------- T x- --------------------------------- • (7-61)
s[(l 4- r2s)(l + 0.1s)(l 4- 0.4s)(l 4- 1.2s) 4- 2.2K(1 4- ^s)]316 Linear Feedback System Design 7.5
21 . 1+0.167$ o(j) (1 + 0.1s)(l + 0.4$)(l +1.2$) an c(i) 1 +0.05$ ‘
The required value of K can be obtained by applying the final-value theorem to E(s)
and setting the result equal to 0.1 unit. We find
K = 9.55. (7.62)
Let us next determine the compensating network required to achieve a phase
margin of 30° and a gain margin of 5 db. The transfer function ofthe uncompensated
system, with K = 9.55, is given by
KG0(s) =------------------- —--------------------.
(1 + 0.1s)(l + 0.4s)(l + 1.2$) . (7.63)
Its Bode diagram, which is drawn in Fig. 7.17, indicates a phase margin of 2° and a
gain margin of 1.7 db. We wish to increase the phase margin by about 30°. From
Table 7.1, it can be seen that a time-constant ratio of 4 will result in a phase shift of
approximately 37° at a frequency which was given by Eq. (7.7):
wmax — V(7\/<x). (7.64)7.5 Design Utilizing the Bode-Diagram Approach 317
We must be careful when using this approach, since we actually desire to have this
phase shift occur at the crossover frequency in order to achieve the specified phase
margin. However, specifying a, T, and comax does not ensure that comax will occur at
the crossover frequency. Therefore, a trial-and-error procedure is followed. A
phase-lead network corresponding to
results in a phase margin of 29° and a gain margin of 4.3 db. This is close enough to
the desired result for all practical purposes. It is interesting to note that this lead
network gives its maximum phase lead of about 32° at a frequency of 11 rad/sec.
This accounts for the fact that we only achieved a phase margin of 29° at a crossover
frequency of 7.5 rad/sec.
E. Application of the Bode Diagram to a Two-Loop System The concluding problem
we consider using the Bode-diagram approach consists of designing the feedback
control system illustrated in Fig. 7.18(a). For this particular system, we desire that
the steady-state error resulting from a velocity input of 110 rad/sec be equal to 0.25
rad. The uncompensated open-loop transfer function G0(s) is given by
G0(s) = K,/(s(l + Tms)), (7.66)
where
Kv = velocity constant,
Tm = motor time constant = 0.025 sec.
K(s)
(b)
Fig. 7.18 (a) Use of rate feedback in cascade with a high-pass filter in order to compensate
a feedback control system, (b) Equivalent block diagram for the system shown in Fig. 7.18(a).318 Linear Feedback System Design 7.5
This transfer function consists of an amplifier, positioning motor, gear train, and load.
In order to achieve the required accuracy, Kr must equal
Kv = = 110rad/s£-c = 440/sec. (7.67)
error 0.25 rad
We want a phase margin of approximately 55° for this system. This will be achieved
by means of minor-loop rate feedback compensation which is cascaded with a simple
RC high-pass filter (lead network) in order not to increase the steady-state response
error for velocity inputs.
The open-loop frequency response we must plot on the Bode diagram is that
obtained with the minor rate loop closed and the outer position loop opened. There￾fore, we are interested in obtaining the equivalent transfer function between £($) and
C(s). This is easily found to be
C(s) K/l + Ts)
----- — . (/.68)
£(s) s[(l + Tms)(l + Ts) + KvbTs]
Expanding the denominator of Eq. (7.68), we obtain the expression
s[TmTs^ + (£„, + T + KvbT)s + 1], (7.69)
This expression can be put into the form
s[(l + T'iS)(l + T1S)]. (7.70)
by defining the time constants T'n and Tx as
T’m = ~T (7.71)
Tj
and
7] = -T',„ + Tn + (\ + Kvb)T. (7.72)
Therefore, we may redraw Fig. 7.18(a) as shown in Fig. 7.18(b). For any set of
values for Tm, T, Kv, and b, we can derive T'm and Tx by solving the simultaneous
equations (7.71) and (7.72). Another approach is to choose Tand Tx from the Bode
diagram which meets the specified phase margin and solve for the required rate
feedback constant b.
The procedure we follow when compensating this system is to draw the Bode
diagram for the uncompensated system in accordance with Eq. (7.66) and then fit the
characteristics of the compensated system in accordance with
C(s) = K„(l + Ts)
E(s) s(l + T',s)(l + Trs) (7-73)7.5 Design Utilizing the Bode-Diagram Approach 319
Fig. 7.19 Compensation of the system shown in Fig. 7.18(b) where
r . . _ 440 440(1 + 0.0335)
C'°(v) - 5(i + 0.0257) cW 5(1 +0.33j)(1 + 0.0025s)'
until a phase margin of 55° is achieved. The compensated characteristics will then
determine T and 7\, from which T'm and the rate feedback constant b can be deter￾mined. Figure 7.19 illustrates the Bode diagram of the uncompensated and com￾pensated systems. Values of
7) = 0.33, (7.74)
T = 0.033, (7.75)
and
T'm = Tz T = 0.0025 [from Eq. (7.71)] (7.76)
results in a phase margin of 55°. From Eq. (7.72), the corresponding value of rate
feedback constant b is 0.0186.
The type of compensation just illustrated is used quite frequently in practice.
In order to really understand what is actually happening, it is important to examine
the Bode diagram of Fig. 7.19 closely. The net effect of the minor-loop rate feedback
has been to move the equivalent motor break frequency from 1/Tm to 1/77, by the
ratio given in Eq. (7.71). This technique is used quite frequently to compensate power
servos. The net effect of the phase-lead network, in the minor-loop feedback path, is320 Linear Feedback System Design 7.6
to appear as a phase lag, for the equivalent open-loop characteristics of Fig. 7.18(b).
This can be easily understood since we effectively see the reciprocal of the feedback
element when looking into a closed-loop system which has an open-loop gain much
greater than unity. This is a very important fact that can be utilized to approximate
the Bode diagram in preliminary designs. This point is now expanded upon in the
following section.
7.6 APPROXIMATE METHODS FOR PRELIMINARY
COMPENSATION DESIGN UTILIZING THE BODE DIAGRAM
Having presented detailed compensation methods, let us next focus our attention on
approximate methods for obtaining a first cut at compensation utilizing the Bode
diagram [9-11]. Although the procedures presented in this section are approximate,
it is generally adequate for the preliminary stage of design. Before the system design
is completed, however, the exact attenuation and phase curves should be drawn as
indicated previously. The practice of utilizing approximate methods for preliminary
design is generally employed as a convenience in obtaining significant time constants,
gains, and phase characteristics required for a design.
A. Approximate Closed-Loop Response from the Bode Diagram In order to develop
the concept of this approach, let us consider the feedback system illustrated in Fig.
7.20. The closed-loop transfer function of this system is given by
C(s) _ G(s)
R(s) 1 + G(s)//(s)'
Let us modify this equation into the following more convenient form:
C(£) = _J_r G(5)H(s) I
R(s) + G(s)H(s)J 1 }
As shown previously, the magnitude (in db) of G(s)H (s') can be approximated by
straight lines of constant slope when plotted against frequency on a log scale. There￾fore, it appears reasonable that the term 1 + G(s)H(s) in Eq. (7.78) may also be
Fig. 7.20 A feedback system.7.6 Approximate Methods for Preliminary Compensation Design 321
dealt with in a similar approximate manner as follows:
1 + G(s)H(s) 1 for |G(s)H(s)| < 1, (7.79)
1 + G(s)H(s) ~ G(s)tt(s) for |G(5)/f(y)| > 1. (7.80)
Substituting these approximations into Eq. (7.78), we find that
C(s) .
R(s)~* G(s) for |C(s)H(s)| <: i, (7-81)
C(s) _
£($)
1
*H(s) for IG(s)H(s)| >> i. (7.82)
The approximations of Eqs. (7.81) and (7.82) are very useful as a first cut in the
preliminary design of a control system. However, it is important to point out that
they are approximate relationships, and are subject to error particularly at those
frequencies where G(s)H(s) = 1. However, the amount by which the approximations
are in error can be calculated, and this correction can then be applied to correct the
approximate value. The resultant corrected value is then an exact solution.
The technique of applying the approximation of Eqs. (7.81) and (7.82) can best
be illustrated through an example. Consider the feedback system of Fig. 7.20, where
G(5) =—(7-83)
1 + Ts
and
H(s) = 1. (7.84)
This example will illustrate how feedback, around an element containing a time
constant, reduces the time constant of that element. Substituting Eqs. (7.83) and
(7.84) into Eq. (7.77), the resultant system transfer function is given by
C(s) = K/(l + Ts) . = K__________ 1
R(s) ~ 1 + K/(l + Ts) 1 + K 1 + Ts/(1 + K) ‘
For purposes of illustration, it is assumed that
K = 10,
T = 1
in this example. For these values, Fig. 7.21 illustrates the straight-line approximations
to the equations for C(s)/A(s), G(s), and G(s)H(s). The dotted curve representing
G(s) (and G(s)H(s) since H(s) = 1) has a gain of 10 (20 db) for frequencies lower
than co = 1/T = 1 rad/sec. At frequencies higher than co = 1 rad/sec, G(s) and
G(s)H(s) have an attenuation of 20 db/decade. At co = co„ = K/T = = 10,
G(s) and G(s)H(s) approximately equal Odb. Equation (7.82) indicates that for
frequencies lower than con = 10, the system transfer function C(s)/R(s) equals
(7.85)
(7.86)322 Linear Feedback System Design 7.6
Fig. 7.21 Open- and closed-loop gain and phase characteristics for the system of Fig. 7.20
where G(s) = 10/(1 + s') and H(s) = 1.
Phase (degrees)
= 1 and is shown by the solid line at 0 db. For frequencies greater than co„,
Eq. (7.81) indicates that C(s')/R(s) is equal to G(s) as shown. Figure 7.21 illustrates
very clearly that the use of unity gain feedback around a single time-constant element
results in a reduction in its time constant. This admirable characteristic is achieved at
the expense of a loss of gain.
It is important to recognize that the results obtained for the closed-loop transfer
function are approximate. For example, Eq. (7.85) indicates that the gain is actually
K/(\ + K) = 10/(1 4- 10) = 0.909 instead of 1 for co < con> and the closed-loop
time constant is T/(l + K) = 1/(1 4- 10) = 0.0909 instead of T/K = ^ = 0.1.
Note that these errors decrease as the gain K increases. Generally, K is quite large
and the error between the approximate and exact curves is very small.
The form of Eq. (7.78) is very well suited for determining the value of C(s)/R(s)
when \G(s)H(s)\ > 1, with the bracketed term representing the difference between the
approximate and exact curves. In order to determine a general analytic expression for
finding the difference between the approximate and exact curves when |G| < 1,
let us reconsider Eq. (7.77) and rewrite it as follows:
C(s) r( . 1
----- = G(s)--------------------
R(s) 14- G(s)H(s)
(7.88)7.6 Approximate Methods for Preliminary Compensation Design 323
Therefore,
sa=c(s)r_w«)L-|. (7.89)
R(0 Ll + l/[G(s)H(s)]J
For those frequencies where |G(s)//(.s)| <1, the bracketed term of Eq. (7.89)
represents the error between the approximate solution
C(s}
TTT G(s) for |G(s)H(s)| < 1 (7.90)
K(s)
and the exact solution. Another way of looking at this is that the bracketed term
represents a correction factor which can be used to correct the results of the approxi￾mation given by Eq. (7.81).
B. The Straight-Line Phase-Shift Approximation For preliminary design purposes,
it is usually sufficient to obtain quantitative information regarding phase shift without
resorting to the exact but tedious method of Bode’s phase integral. We have found it
convenient to represent the amplitude characteristics by a straight-line approximation,
and can utilize a similar technique for the phase-shift function. In order to introduce
the method, let us consider the phase shift due to the transfer function given by
G(jco') = 1 +j(-\ (7.91)
Xc-Jj/
Figure 7.22(a) illustrates the straight-line amplitude approximation and Fig. 7.22(b)
illustrates the exact phase shift and its straight-line approximation. The straight-line
approximate phase shift has been constructed by drawing a straight line tangent to the
actual curve at a> = coP
In order to construct these straight-line phase-shift approximations by inspection,
the dependence of a>A and a>B on must be known. This can be obtained by first
considering the slope of the actual curve at co = cox as follows:
<f> = tan"1 — . (7.92) OJi
The slope at co — can be obtained by differentiating this expression:
"1 drf> do "1 _ (d/(Oi ~| _ 1 93)
d(ln co)J®=®i dw d(ln co)J<o=<oi 1 + (w/wj 2
Knowing the slope at co = co1? the intercepts at coA and a>B can be obtained from
------------------ = -, (7.94)
In coj — In ma 2
which gives
- = i In — . (7.95)
4 wA324 Linear Feedback System Design 7.6
(b)
Fig. 7.22 Straight-line, approximate, phase-shift method for a lead term.
Therefore,
— = — = e!2 = 4.81. (7-96)
U>.( (Oj
It is interesting to note that if a number other than e were chosen for the logarithmic
base, the slope in Eq. (7.93) would change, but the frequency ratio given by Eq. (7.96)
would remain the same.
Based on this result, complicated approximate straight-line phase-shift curves can
be obtained. Figure 7.23 illustrates the application of this approach for a transfer
function given by
(7.97) = (1 + 10s)(l + 0.01s)2
S (1 + s)2(l + 0.001s)
and compares the approximate straight-line phase-shift curve with the exact phase￾shift curve. Observe that the errors obtained by using the approximate phase curve
are relatively larger than the corresponding errors of the amplitude approximation.
However, the use of this approximation greatly aids the control-system engineer in
obtaining a first cut at preliminary design.1.6 Approximate Methods for Preliminary Compensation Design 325
Fig. 7.23 Approximate straight-line phase-shift (----- ) and exact phase-shift (-------- )
characteristics of
, (1 + 10s)(l + 0.01s)2
W (1 4- s)2(l + 0.001s) ’
The example just presented contained roots that were all real. What happens if
the transfer function contains underdamped quadratic factors? In order to analyze
this situation, let us consider the following normalized quadratic term:
G(jw) ____________1____________
(jto/toJ2 + 2£(jto/to„) + 1
(7.98)
It was shown in Section 6.5 that the amplitude and phase-shift terms were given
respectively by (see Eq. 6.74):
-201og10
2£to„to -
Z 2 ’
to* - to
(7.99)
<f> = —tan (7.100)326 Linear Feedback System Design 7.6
(7.101)
(7.102)
(7.103)
Let us focus attention on the phase-shift term. Differentiation of Eq. (7.100) results
in the slope at co = wn being given by
d</> 1
slope = --------- = - -
c/(ln co)
As before, the two intercepts co4 and wB can be found as follows:
tt/2£
In con — In co ( £
Therefore,
= em = 4.81?.
co 4 co„
Exact phase characteristics corresponding to Eq. (7.102) and its straight-line approxi￾mation, based on the relationship of Eq. (7.103), are illustrated in Fig. 7.24. In
addition, the exact amplitude characteristics of Eq. (7.99) and its straight-line
approximation are also illustrated. Observe from Eq. (7.103) that as 5 approaches
zero, the two frequency ratios decrease and approach unity in the limits. This
Fig. 7.24 Straight-line, approximate, phase shift method for a quadratic lag factor (£ < 1).7.7 Design Utilizing the Nichols Chart 327
certainly agrees with the exact phase characteristics of a quadratic phase lag illustrated
in Fig. 6.17. On the other hand, when £ = 1, the roots become real and Eq. (7.103)
reduces to Eq. (7.96).
The reader is again reminded that the straight-line phase-shift approximation is
not exact. It should only be used in order to obtain a first cut for preliminary design
work. It should also be noted that the errors of the straight-line phase shift approxi￾mation are generally larger than the corresponding errors of the amplitude approxi￾mation. For this reason, the phase-shift approximation is not too widely used.
In the final design, the actual phase-shift characteristics must be employed as
previously illustrated.
7.7 DESIGN UTILIZING THE NICHOLS CHART
The Nichols chart method has been developed in Section 6.7. We demonstrated in
that section how one could obtain the closed-loop frequency response of a feedback
control system by superimposing the open-loop gain-phase characteristics onto the
Nichols chart. Specifically, we obtained the closed-loop frequency response of the
system shown in Fig. 6.33. The intersections of the open-loop gain-phase charac￾teristics and the Nichols closed-loop gain characteristics were shown in Fig. 6.35.
The resulting closed-loop frequency response was illustrated in Fig. 6.36. It indicated
a maximum value of peaking, Mp, of 6.8 db (2.2) and the frequency at which it
occurred, mv, was lOrad/sec. We indicated in Sections 6.7 and 6.8 that a value of
M„ = 6.8 db (2.2) does not represent a good design. This section demonstrates how
the control engineer may use the Nichols chart in order to achieve a specified perfor￾mance.
Let us assume for this problem that an acceptable value of Mp is 1.3 (2.3 db).
This may be achieved by adding a phase-lag or phase-lead network in cascade with
the forward-loop transfer function G(s). A phase-lag network is used for this problem
although a solution can be found as easily using a phase-lead network. We shall
demonstrate that for an Mv of 2.3 db the object is to modify the gain-phase charac￾teristics on the Nichols chart so that it isjust tangent to the 2.3 db locus and does not
enter it. By restricting the gain-phase characteristics to areas external to the M = 2.3
db locus, we will have limited Af;) to 2.3 db, since the interior of this locus represents
values of M greater than 2.3 db.
Studying the characteristics of Fig. 6.35, we see that relatively large magnitudes
of G(Jm) exist for co < 3 rad/sec. Therefore, it is not desirable to shift these
magnitudes inside the = 2.3 db curve. In addition, it is desirable to attenuate
G(ja>) by a factor of about 3 in the range of frequencies of m = 5 to 12 rad/sec.
A phase-lag network, (1 + Ts)/(\ + a Ta), whose factor a equals 3 will achieve this
if "max — l/(T\/a) is chosen at about 1 rad/sec. Solving for aT and T, we get
aT = 1.74 and T = 0.58.
In order to obtain the gain-phase characteristics of the open-loop system, the
Bode diagram is first drawn as indicated in Fig. 7.25. Then for each value of to the328 Linear Feedback System Design 7.8
Fig. 7.25 Bode diagram for the compensated system of Fig. 6.33 where
_____ 11.7(1 + 0.58s)
(s) f(s) (.s) + 005j)(1 +01y)(1 +i.74i)-
magnitude and phase of the open-loop compensated characteristics are plotted onto a
Nichols chart as shown in Figure 7.26. Since the open-loop gain-phase characteristics
are just tangent to the constant-magnitude locus corresponding to M = 2.3 db
(1.3), we have achieved our goal. Notice that we have shifted a> = 1 rad/sec by
about —35°, but this does not increase Mp.
7.8 DESIGN UTILIZING THE ROOT LOCUS
The root-locus technique has been developed previously in Sections 6.9 and 6.10.
It is a very helpful tool which the control engineer can use in order to study the
variation of gain, system parameters, and effect of compensation. We demonstrated
in Section 6.9 the migration of poles in the complex plane as the gain of the system
was varied from zero to infinity. Specifically, we obtained the root locus for a7.8 Design Utilizing the Root Locus 329 Loop gain G (db)
Open-loop phase angle (degrees)
Fig. 7.26 Compensation of the system shown in Fig. 6.33 for M - 2.3 db (1.3).330 Linear Feedback System Design 7.8
feedback system where
G(s)W(s) =
_________K________
(S + 1)(S - 1)(5 + 4)2‘
(7.104)
This was illustrated in Fig. 6.44. An analysis of the root locus for this system
indicated that it was always unstable, since at least one of the roots of the charac￾teristic equation always occurred in the right half-plane. This section demonstrates
how this system may be compensated by means of a lead network. This problem is
followed by considering lag-network compensation for the system illustrated in Fig.
6.40. In addition, we shall demonstrate how the control engineer may determine the
transient response of the compensated systems in order to meet certain specifications.
A. Lead Network Compensation Let us attempt to stabilize the system of Fig. 6.44
by means of a phase-lead network in cascade with the forward-loop transfer function.
The form of its transfer function is given by
c 4- a
Gc(s) = S~f-. (7.105)
s + p
We assume that the effect of the pole introduced by the phase-lead network has a
negligible effect compared with its zero. Therefore, we assume that the transfer
function of the cascaded phase-lead network can be approximated by the simple
expression:
Gc(s) ph s + of.. (7.106)
The resulting value of Gc(s)G(s)H(s), which is to be examined on the root locus, is
given by
G.(j)G(5)H(S) = — -K(’ + . (7.107)
(s + l)(s — l)(s + 4)-
We wish to investigate the effect on stability of a variation in a as follows:
Case A: a = 0.5 Case D: a = 4
Case B: a = 1 Case E: a = 6
Case C: a = 2
The resulting root loci for all these cases are presented next. It is important to
emphasize at this point that, although we make use of most of the analytic tools
developed in Section 6.9, we do not use all of them. This omission is due to the fact
that some ofthe analytic techniques developed are too complex to use for higher-order
systems. For example, it is very tedious to determine the value of the gain K along
the root loci utilizing the relationship given by Eq. (6.107). Fortunately, this can be
obtained much more easily with the Spirule. The approach we take in presenting the
resulting root loci for this problem is to outline the results ofthe eleven rules developed
previously in Section 6.9 and use the Spirule wherever it is helpful. In addition, the7.8 Design Utilizing the Root Locus 331
values of gain obtained using the Spirule which are pertinent for an intelligent evalua￾tion of the problem will be indicated. It is our feeling that this dual approach is the
best procedure when using the root-locus method.
Case A. a = 0.5. See Fig. 7.27 for the root-locus sketch.
Rule 1. There are four separate loci since the characteristic equation,
1 + Gc(5)G(5)H(5) = 0,
is a fourth-order equation.
Rule 2. The root locus starts (K — 0) from the poles located at 1, — 1, and a double
pole at —4. One branch terminates (K = oo) at the zero located at —a and three
branches terminate at zeros located at infinity.
Rule 3. Complex portions of the root locus occur in complex-conjugate pairs.
Rule 4. The portions of the real axis between 1 to —a; —1 to —4; and — 4 to oo
are part of the root locus.
Rule 5. The branches approach infinity as K becomes large at angles given by
«o = ± - = ±60°,
3
and
3 7T
ax = ± — = ±180°.
3
Rule 6. The intersection of the asymptotic lines and the real axis occur at
_ _8 - (—0.5) _ _2 5
4 - 1
Rule 7. Using the Spirule, we found the point of breakaway from the real axis to
occur at approximately —1.75.
Rule 8. Using the Spirule, we found the intersection of the root locus and the
imaginary axis to occur at approximately 5 = ±j3.3, where the gain is 104, and at the
origin, where the gain is 32.
Rule 9. 1 his rule does not apply here.
Rule 10. This rule shows that as certain ofthe loci turn to the right, others turn to the
left to ensure that the sum of the roots are a constant.
Rule 11. A Spirule was used to obtain the gains along the root locus.
I he resulting root locus indicates that the system is stable when 32 < K < 104.
Case B* a = 1. See Fig. 7.27 for the root-locus sketch. A zero at a — —1 cancels
* Only the results of applying the eleven rules for constructing the root locus are indicated
for Cases B-E.332 Linear Feedback System Design 7.8
Fig. 7.27 Compensation of the root locus shown in Fig 6.44 using a cascaded phase-lead
network where Gc(s) = (s + a).7.8 Design Utilizing the Root Locus 333
the poie at —1. The resulting root-locus sketch indicates that this system is stable
when 16 < K < 72.
Case C. a = 2. See Fig. 7.27 for the root-locus sketch. The resulting root-locus
sketch indicates that the system is always unstable since at least one of the roots of
the characteristic equation always occurs in the right half-plane except for the condition
where two poles exist at the origin.
Case D. v. = 4. See Fig. 7.27 for the root-locus sketch. A zero at a = 4 cancels one
of the poles located at —4. The resulting root-locus sketch indicates that the system
is always unstable since at least one of the roots of the characteristic equation always
occurs in the right half-plane.
Case E. a = 6. See Fig. 7.27 for the root-locus sketch. The resulting root-locus
sketch indicates that the system is always unstable since at least one of the roots ofthe
characteristic equation always occurs in the right half-plane.
The interpretation of Fig. 7.27 is quite interesting and revealing. It indicates that
the exact location of the zero is very important from a stability viewpoint. Cases A
and B were the only configurations which had regions of stability. As a matter of
fact, the closer the zero lies to the imaginary axis, the greater is its stabilizing effect.
This point is very important. Since Case A resulted in larger values of gain, it would
result in a more accurate system and is, therefore, preferred to Case B.
B. Determination of the Transient Response The transient response of the system can
also be obtained by reasoning along these lines: The transient performance is often
dominated by the pair of complex-conjugate poles located closest to the origin.
This occurs when the other poles are far to the left of the dominant poles, or the other
poles are near a zero. The resulting transient components due to these other poles are
small under these conditions and diminish rapidly. For this case, the poles closest to
the origin are conventionally referred to as the dominant poles. From the discussion
of Section 4.2, the expression associated with these complex poles can be given by
the following expression (see Eq. 4.3).:
C(s)
R(s) s2 + 2£a)„s + a;
(7.108)
where £ = damping factor, and (on = natural resonant frequency. We found in
Section 4.2 that the transient response to a unit step input, for £ < 1, is given by the
following expression (see Eq. 4.24):
c(t) = 1 + -
- Vi - e
where
a = cos-1 (— £).
sin (wnX/l - l2t ~ a)> (7.109)
Figure 4.3 illustrated the complex-plane location of these dominant poles. The
values derived for the time to the first peak (see Eq. 4.28) and maximum percent334 Linear Feedback System Design 7.8
overshoot (see Eq. 4.32) are specifically for a second-order system whose closed-loop
transfer function is given by Eq. (7.108). These quantities change if other closed￾loop poles and zeros exist in addition to the dominant complex pair. However, ifthe
other poles and zeros are at least twice as far from the origin as the dominant pair, the
approximation gives reasonable results. Expressions for time to the first peak and
percent overshoot, which consider other poles and zeros and give more accurate
results, can be derived [6]. These expressions assume that
a) Other poles are far to the left of the dominant poles, so that the amplitude of
transients due to these other poles is small.
b) Poles which are not far to the left of the dominant poles are near a zero so that
the transient amplitude due to such poles is small.
The approximate expressions, for unity feedback systems, are given by
[tp]modified = —rJ - 2 + 2 (7-110)
V1 - £2 L2 J
where
2 4>z — sum °f angles from the zeros of C/R to one of the dominant poles,
2 </>» = sum °f th6 angles from the poles of C/R to one of the dominant poles,
and maximum percent overshoot
The expression for maximum percent overshoot can be stated symbolically as
'product of distances from all'
poles of C/R to origin,
excluding distances of two
_ dominant poles from origin
'product of distances from'
all zeros of C/R to
dominant pole Po
x 100% 'product of distances from all’
other poles of C/R to
dominant pole Po excluding
distance between dominant
poles
'product of distances from'
all zeros of C/R to
origin
max. % overshoot = i------- 1-----1 i------------ ) I-------- 2-----j
L\|7’1 - P0|/\|P2 - P0|/\|P3 - P0P J
x r/|Z, - Po|\ /|Z, - P„|\ Z|Z, - P,|\ ... 1
L\ z, /\ z2 /\ z, / J
where the first set of brackets represents the product of the ratios of the values ofs at
which poles occur to their absolute distances from the dominant pole. The second set
of brackets represents the product of the ratios of the absolute distances of the zeros7.8 Design Utilizing the Root Locus 335
from the dominant pole and the values ofs at which the zeros occur. Let us next apply
these expressions in the following design problem.
C. Lag Network Compensation and Overall System Performance The concluding
design problem we consider using the root locus consists of employing cascaded
phase-lag compensation in order to improve the steady-state performance of a
feedback control system. The object is to increase its gain while maintaining a good
dynamic response. Specifically, we consider the system whose root locus was
illustrated in Fig. 6.40. For this system
G(s)H(s) =
K
s(s + 4)(s + 5)
(7.112)
The root locus of Fig. 6.40 indicated that the system was stable when 0 < K < 180.
Let us assume that a damping factor of 0.707 achieves a desirable dynamic response
for this system. In addition, we must maintain a velocity constant Kv of 30 in order
to meet specified accuracy requirements. Analyzing this problem, by means of the
root locus, we can find the value of K which will give the required damping factor.
For example, the redrawn version of Fig. 6.40 shown in Fig. 7.28 indicates that a
K = 23.6 will result in a damping factor of 0.707. This value of gain, obtained using
the Spirule, does not maintain the required velocity constant of 30. The actual value
of Kv resulting from K = 23.6 is
Kv = lim sG(s)H(s) = lim--------------------- — 1. ] 8/sec.
s-*o s—*0 s(s T 4)(s T 5)
(7.113)
It is therefore clear that we cannotjust increase the gain K to a value that produces the
required velocity constant, since this would decrease the damping factor and adversely
affect the transient response or cause the system to become unstable. Using the root
locus for a solution, we show how these two conflicting factors can be resolved.
Let us assume that the phase-lag compensator is of the form
gc(s) = £j3T^’ <7-114)
s + a
where n = ratio of the break frequencies. Equation (7.114) indicates that this
compensator provides a low-frequency gain in addition to the phase lag. The open￾loop transfer function of the compensated system is given by
Gc(s)G(s)H(s)
K
s(s + 4)(s + 5)
s 4- na
. 5 + .
(7.115)
In general, the distances of not. and a from the origin in the 5-plane are chosen to be
small compared with the distances of the other zeros and poles of the uncompensated
open-loop transfer function, so that the added pole and zero of the compensator will
not contribute significant phase lag in the vicinity of the closed-loop bandwidth
(crossover frequency). This result is quite clear from a study of the Bode diagram.336 Linear Feedback System Design 7.8
Fig. 7.28 Compensation of the root locus shown in Fig. 6.40 using a cascaded phase-lag
network.
Certainly we do not wish to add the phase-lag contribution in the vicinity of the
crossover frequency. Therefore, the combination of pole and zero will appear quite
close together on the root locus and very close to the origin. This combination is
usually called a dipole.
In order to complete the design, a will be chosen as 0.01 and n will be chosen,
using the following derivation, which will achieve a Kc = 30:
Kr = 30 = lim sG(,(s)G(s)H(.s). (7.1 16)
s-07.8 Design Utilizing the Root Locus 337
Substituting Eq. (7.115) into Eq. (7.116), we obtain
on !■ / K \/s + na\ 30 = lim sI--------------------- 11 —1-------|, (7.117)
s-*o \s(s + 4)(s + 5)/ \ s + a /
or
30 = -------. (7.118)
(4)(5)
Since we desire that K = 23.6 from a transient viewpoint, we must have
n = 30(4)(5)
23.6
= 25.4. (7.119)
The completed root locus for the compensated system whose open-loop transfer
function is given by
Gc(s)G(s)H(s) K
s(s + 4)(s + 5)
s + 0.254X
. s + 0.01 /
must now be determined. Since the dipole is added near the origin, the original root
locus is not changed significantly, because the two poles and the zero near the origin
tend to merge into a single pole.
Let us next determine the new resulting root locus and analyze the effect of the
dipole on it. Specifically, we wish to know whether the new root locus will indeed
have a Kv = 30. In addition, we would like to determine the transient response ofthe
compensated system. Each of the eleven rules for constructing the root locus will be
considered.
Rule 1. There are four separate branches since the characteristic equation,
1 + G(s)/f(s) = 0,
is a fourth-order equation.
Rule 2. The root locus starts (K = 0) from the poles located at the origin, —0.01,
—4, and —5. One branch terminates (K = oo) at the zero located at —0.254 and
the other three branches terminate at zeros which are located at infinity.
Rule 3. Complex portions of the root locus occur in complex-conjugate pairs.
Rule 4. The portions of the real axis between the origin and —0.01, —0.254 and —4,
and —5 to — oo are part of the root locus.
Rule 5. The four branches approach infinity as K becomes large at angles given by
a0 = ± = ±60°,
a. = ± = ±180°.
4-1338 Linear Feedback System Design 7.8
Rule 6 The intersection of the asymptotic lines and the real axis occurs at
-9.01 - (-0.254) -8.756
sr =-------------------------- = ----------= —z.yz.
4-1 3
Rule 7. The point of breakaway from the real axis can be computed from the follow￾ing equation:
(Vi - Pt - & - Pt - PJ = (2« + 1>,
where
= angle from the zero at —0.254 to the point that is located a
small distance <5 off the positive real axis,
/S2 = angle fromthe pole atthe origin to the point
= angle fromthe pole at—0.01 to the point s15
Pt = angle fromthe pole at—4 to the point
/?5 = angle fromthe pole at—5 to the point sv
The equation of the transition of the root locus from the real axis to a point which is
a small distance d off the axis is given by
Solving, we obtain = 1.19, which compares with a value of 1.47 obtained from Eq.
(6.122) for the uncompensated system.
Rule 8. The intersection ofthe root locus and the imaginary axis can be determined by
applying the Routh-Hurwitz stability criterion to the characteristic equation
j(s + 0.01)(s + 4)(s + 5) + K(s + 0.254) = 0,
which becomes
s4 + 9.01 y3 + 20.09y2 + (K + 0.2)y + 0.254K = 0.
The resulting Routh-Hurwitz array is given by
s4 1 20.09 0.254K
s3 9.01 K + 0.2
s1 20.068 - 0.111K 0.254K
-0.11 IK2 + 17.8K + 4
20.068 - 0.11 IK
s° 0.254K7.8 Design Utilizing the Root Locus 339
An interesting situation occurs in this Routh-Hurwitz array, since the first terms of
the third and fourth rows can go to zero for certain values of gain, K. When the
equation
20.068 - 0.111A' = 0
is satisfied, then a possible solution is
= 186.3.
When the equation
-0.11 IK2 + 17.8K + 4 _
20.068 - 0.111K ~
is satisfied, then a possible solution is
= 160.75.
Therefore, in order to find which is (or are) valid, let us substitute 5 = ja> into the
characteristic equation and find out where the root locus crosses the imaginary axis.
The result can be separated into a real and imaginary part and written in the following
form:
> - 20.09o2 + 0.254AT + >[-9.01w2 + K + 0.2] = 0. (7.120)
For K to be real, the imaginary part ofthis equation must equal zero. Therefore,
>[-9.01 co2 + K + 0.2] = 0,
Now, to find the value of K which corresponds to this value of crossing of the
imaginary axis, let us substitute this value of into the real part of Eq. (7.120).
The result is the following equation:
K2 - 160.5 AT - 36.1 = 0.
Therefore, we find that
K = 160.75
is the only possible real value of gain when the root locus crosses the imaginary
axis. This analysis indicates that the maximum value of gain, before the system
becomes unstable, is 160.75. In Eq. (6.125), we found that the uncompensated
system had a maximum allowable gain of 180. Therefore, this result indicates that the
dipole has an effect on the maximum allowed gain. The corresponding value of 5
occurring at the crossing of the imaginary axis is found to be ±/4.22 by substituting
>iax into the equation for <o. This compares with a value of s — obtained
previously for the uncompensated case (see Eq. 6.126).
Rule 9. This rule does not apply to this problem.340 Linear Feedback System Design 7.8
Rule 10. This rule shows that as certain of the loci turn to the right, others turn to
the left to ensure that the sum of the roots is a constant.
Rule 11. This rule is quite important to us in this case since we want to determine the
value of gain when £ = 0.707 (the intersection of a line making an angle of +45° with
the negative real axis and the dashed curve). For the uncompensated case, we found
that K = 23.6. The new value can be obtained from the following expression:
K(s + 0-254) _
s(s + 4)(s + 5)(s 4- 0.01)
Measuring the distance from the various poles and zero to the point of interest, we
obtain
K(l-45) =J
(1.7)(3)(3.85)(1.65) ’
K = 23.2.
Therefore, the gain has decreased slightly from 23.6 to 23.2. This will result in a
slight reduction of Kv from 30 to 29.5. For this reason, the value of n calculated in
Eq. (7.119) should always be increased by about 5 percent to allow for a margin of
safety for the inherent reduction in gain due to the addition of the dipole. In this
problem, an n of 25.9 will achieve a Kv of 30.
To conclude this problem, we can calculate the value ofthe time to the first peak
and the maximum per cent overshoot from Eqs. (7.110) and (7.111), respectively.
These results can then be compared with the values obtained from Eqs. (4.28) and
(4.32), which assume that the transient response is completely controlled only by the
pair of complex-conjugate poles located closest to the imaginary axis. The time to
the first peak of the compensated system can be calculated from Eq. (7.110). In order
to use this equation, the location of the other two roots must be determined. Using
a Spirule, these were found to be located at —6.45 and —0.26. Therefore, .
'. = 77=—(j-+
(V1-£2<U2 i
where
£ = 0.707,
co„ = 1.63 (distance from the origin of the complex plane to the two
dominant poles located at 1.15 ± j\. 15—dashed curve of Fig. 7.28),
2<k = 141° = 2.47 rad,
2 &> = 136° + 90° 4- 14° = 240° = 4.19 rad.
Substituting these values into the equation for /;), we obtain
tP = -- 1 -------(1.57 - 2.47 4- 4.19) = 2.86 sec.
(Vl - 0.7072 1.63)7.8 Design Utilizing the Root Locus 341
Therefore, the time to the first peak is 2.86 sec. If one simply assumes that the
transient response is governed by the pair of complex-conjugate poles located at
1.15 ±y 1.15 and uses Eq. (4.28) to determine the time to the first peak, then the
following is obtained:
<o„71 - C
[from Eq. (4.28)],
_________ 77__________
1.6371 _ 0.7072
3.14
1.15
= 2.73 sec.
Therefore, we see the improved accuracy obtained using Eq. (7.110).
A similar analysis of the uncompensated system, utilizing Eq. (7.110), results in a
time to the first peak of 2.81 sec. For this case, the two complex-conjugate poles are
located at —1.2 ± jl.2. The third root can be determined analytically from rule 10:
-4 - 5 = -1.2 + yl.2 - 1.2 -yl.2 + r,
r = —6.6.
Therefore,
where
£ = 0.707,
a)n = 1.7 (distance from the origin of the complex plane to the two
dominant poles—solid curve of Fig. 7.28),
1^ = 0,
= 90° + 13° = 103° = 1.8 rad.
Hence,
t =-------------—-------(1.57 4- 1.8) = 2.81 sec.
71 - 0.7072 (1.7)
Observe that the dipole compensation increases the time to the first peak.
The maximum percent overshoot of the compensated system can be obtained
from Eq. (7.111). To use this equation, we have to determine the location ofthe other
two roots. As mentioned previously, these were found to be at —6.45 and —0.26.
Therefore,
, . P1P2 |Zi ~ y inn0/
maximum percent overshoot = —------ - — -----~----- e * lw/o
(I “1 — ■< 0|) (|r2 — r0|)
_ (0.26)(6.45) (1.46) ^-0.707(1.63)2.86 * 100%
~ (1.45)(4.9) (0.254)
= 4.95%.342 Linear Feedback System Design 7.9
Therefore, the resulting.maximum percent overshoot is only 4.95%. If one simply
assumes that the transient response is governed by the pair of complex-conjugate
poles located at 1.15 ± yl .15 and uses Eq. (4.32) to determine the maximum percent
overshoot, then the following is obtained:
maximum percent overshoot = x 100%
= x 1(X)o/ = 4 3%
Therefore, we see the increased accuracy obtained using Eq. (7.111).
A similar analysis of the uncompensated system utilizing Eq. (7.111) results in a
maximum percent overshoot of 4.48%; for this case, the third root is located at
— 6.6 as illustrated before:
P maximum percent overshoot = ------ 1---- e-’'0"'" x 100%
I Eo|
= y e-«-707(1.7)(2.31) x 1000/ = 4 48%
Observe that the dipole compensation increases the maximum percent overshoot.
The results of the transient analysis indicate that the effect of the dipole is to
increase the time to the first peak slightly and to increase the maximum overshoot
slightly. Of most importance, the dipole increases the velocity constant greatly,
from 1.18 to 30.
One should note that the dominant pole concept is very useful here, the results
coming quite close to the more accurate calculation. In fact, due to the ever-present
uncertainty of the parameters of the actual system, it is rarely, if ever, necessary to
carry out the detailed calculations indicated.
7.9 THE CONCEPT OF LINEAR-STATE-VARIABLE FEEDBACK
Having presented methods for designing linear control systems using classical
techniques, let us now look at the problem from the viewpoint of state-variable
feedback [8], In order to do this, let us first look at the basic feedback problem
illustrated in Fig. 7.29. This figure illustrates the concept of feeding back the states of
Fig. 7.29 General feedback system problem illustrating feedback of the output and the
states of the process.7.9 The Concept of Linear-State-Variable Feedback 343
the process in addition to that of the output. Since a linear process can be charac￾terized by the equations
x = Px + bu, (7.121)
c = Lx, (7.122)
let us consider the configuration of Fig. 7.30. It is important to observe from this
figure that the control signal is generated from a knowledge of the reference input r
and the state variables x. Note that r, u, and c represent scalars.
Fig. 7.30 General feedback system with state-variable feedback.
u = K[r — hx],
where
h = [/ij h2 h3 • • • A„],
x2
*3
In general, the control input u can be represented as
M=/(x,r). (7.123)
Rather than considering the controller in such a broad sense, let us consider the
specific condition of linear state-variable feedback where the controller weights the
sum of the state variables in a linear manner. In addition, it is assumed that
the controller provides a linear gain K which multiplies the difference between the
reference input and the linear weighted sum of state variables fed back. 1 herefore, u
can be represented as
u = K[r — (/zjXj + h2x2 + h3x3 + • • • + hnx„)], (7.124)
where is defined as the (th feedback coefficient. In matrix form, u can be represented
as:
(7.125)
(7.126)
(7.127)344 Linear Feedback System Design 7.9
Fig. 7.31 Linear-state-variable feedback representation.
Figure 7.31 presents a matrix representation of the concept of linear-state-variable
feedback, and Fig. 7.32 is a physical representation of a typical system as implied by
Fig. 7.31. In the following discussion, it is assumed that all state variables are directly
available for measurement and control. In practice, this is not always possible, and
techniques for modifying and extending the design procedure presented, to the case
where all the state variables are not available, are also discussed.
How does linear feedback of the state variables affect the behavior of the process
given by Eqs. (7.121) and (7.122)? This can easily be determined by substituting Eq.
(7.125) into Eq. (7.121):
x = Px + b[/C(r - hx)]. (7.128)
Fig. 7.32 Example of a linear-state-variable feedback system.7.9 The Concept of Linear-State-Variable Feedback 345
Simplifying Eq. (7.128), and incorporating Eq. (7.122), we obtain the closed￾loop equations
x = P,x + Kbr, (7.129)
c = Lx, (7.130)
where
P& = P - Kbh (7.131)
is the closed-loop-system matrix. Comparing Eqs. (7.121) and (7.122) with (7.129)
and (7.130), we observe that they are identical except that the P-matrix has been
replaced by PA and u becomes Kr.
How can we relate the closed-loop-system matrix, P/(, to the closed-loop transfer
function, C(s)/R(_s)? This can be accomplished by taking the Laplace transform of
Eqs. (7.129) and (7.130). Since the results will be used to find a transfer function, all
initial conditions are assumed to be zero:
sX(s) = P,,X(s) + KbR(s), (7.132)
C(s) = LX(s). (7.133)
Solving for X(s) from Eq. (7.132), we get
X(s) = K[sl - PJ-’bm (7.134)
The inverse matrix [si — PA]-1 is defined as the closed-loop resolvent matrix,
where
H - M-1- (7-135)
Therefore, Eq. (7.134) may be rewritten as
X(s) = K4>h(s)bR(s). (7.136)
Substituting Eq. (7.136) into Eq. (7.133), we obtain a relation between C(s) and R(s):
C(s) = KL^h(s)bR(s). (7.137)
Therefore, the closed-loop transfer function in terms of the closed-loop resolvent
matrix is given by
KL4>/(s)b. (7.138)
R(s)
In addition, the characteristic equation in terms ofthe closed-loop system matrix can
also easily be determined, simply by substituting the numerator and denominator
portions of the inverse matrix, 4>/((s):
C(s) = KL[adj (si - P„)]b (7J39)
A(s) det (si — Pj
The corresponding characteristic equation of the closed-loop system in terms of the
closed-loop system matrix is given by
det (si - P„) = 0. (7.140)346 Linear Feedback System De 7.9
Fig. 7.33 An equivalent model of Fig. 7.31.
Since we are concerned with synthesizing confrol systems in terms of linear-state￾variable feedback concepts, we would like to force the system illustrated in Fig. 7.31
into the generalized form illustrated in Fig. 7.33, and study its properties. Let us first
consider the derivation of From Fig. 7.33, we observe that
H(s) =
hX(s)
(7-141)
Substituting Eq. (7.133) into Eq. (7.141), we obtain
H(s) =
hX(s)
LX(s)’
(7.142)
After substitution of Eq. (7.136) for X(s), Eq. (7.142) becomes
H(s)
h<>ft(5)b
L4\(s)b ’
(7.143)
The term G(s) can also be derived in terms of<**($). The closed-loop transfer function
of the system illustrated in Fig. 7.33 is given by
C(s) _ KG(s)___
R(s) ~ 1 + KG(s)H(s)' (7-144)
Substituting Eqs. (7.138) and (7.143) into Eq. (7.144), we obtain the expression
_ L^(s)b
S 1-Kh<(s)b‘ (7.145)
Combining Eqs. (7.143) and (7.145), the open-loop transfer function is found to be
given by
Kh<I»,,(s)b
*G(s)H(s) = - - . (7.146)
1 - Kh4>A(s)b
Let us compare Eqs. (7.138), (7.143)—(7.145), and (7.146) in order to draw con￾clusions regarding G(s), H(s), the open-loop transfer function KG(s)H(s), and
the closed-loop transfer function C(s)/A(.s). These characteristics will be important7.10 Control-System Design with Linear-State-Variable Feedback 347
for designing systems with linear-state-variable feedback techniques in the following
section. Based on these five equations, we can state the following properties:
1. The poles of KG(s)H(s) are the poles of G(s).
2. The zeros of C(s~)/R(s) are the zeros of G(s).
3. The pole-zero excess of C(s)/R(s) must be equal to the pole-zero excess of <j(s).
With these properties as a basis, we consider in the following section the design of
control systems from the viewpoint of linear-state-variable feedback.
7.10 CONTROL-SYSTEM DESIGN WITH LINEAR-STATE-VARIABLE FEEDBACK
The preceding section has indicated several important relationships between open￾loop and closed-loop transfer functions. This is very important in the design of
control systems for the case where the closed-loop transfer function is specified and it
is desired to determine the open-loop transfer function. A typical problem might
specify the desired velocity constant; then use is made of Eq. (5.35) in Section 5.4
which gave the velocity constant in terms of the closed-loop poles and zeros. The
problem is to determine the resulting linear-state-variable feedback system.
Let us illustrate the procedure by considering the following problem. It is desired
that the closed-loop characteristics of a unity feedback control system be given by the
following parameters:
a>n = 50 rad/sec, Kv - 35/sec, £ — 0.707.
What form of closed-loop transfer function will satisfy these requirements? Let us
first try a simple quadratic control system having a pair of complex-conjugate poles.
From Eq. (5.37), such a system has a velocity constant given by
Therefore, a simple quadratic control system having a pair of complex-conjugate
poles will satisfy these specifications. From Eq. (4.18),
cos a = — £. (7.147)
For a damping factor of 0.707, a = 45° and the relations among the complex￾conjugate poles, a>n and t, are illustrated in Fig. 7.34. Therefore, the closed-loop
control system is given by
. (7.148)
K(s) s2 + 2£wns + w2348 Linear Feedback System Design 7.10
Fig 7.34 Closed-loop poles.
By substituting I = 0.707 and a>n = 50 into Eq. (7.148), we obtain the following
desired closed-loop transfer function:
C(s)_ 2500
R(s) ~ s2 + 70\7s 4- 2500 '
(7.149)
Let us assume that the open-loop process that is being controlled is illustrated in
Fig. 7.35. The corresponding state-variable representation is readily found to be
where
c = [1 0]x,
(7.150)
(7-151)
Fig. 7.35 Open-loop process to be controlled.7.10 Control-System Design with Linear-State-Variable Feedback 349
Fig. 7.36 State-variable feedback representation of system.
The resulting linear-state-variable feedback representation is illustrated in Fig. 7.36.
This feedback representation can be simplified by the configuration illustrated in Fig.
7.37. The resulting closed-loop transfer function is given by
C(s) = K/[s(s + 70)] J
R(s) 1 + (/tj +/t2s)K/[s(s + 70)]’ ’
which can be reduced to the following expression:
= ---------------- ------------------ . (7.153)
(Rs) s2 + (70 + h2K)s + Khl
The values ofKJi^, and h2 can be found from Eqs. (7.149) and (7.153). The following
set of simultaneous equations result:
= 2500, (7.154)
70 4-/12^= 70.7, (7.155)
Khr = 2500. (7.156)
We have three equations and three unknowns. Solving, we find that hx = 1, K —
2500, and h2 = 2.8 x 10~4. The final step is to draw the root locus and examine the
relative stability, and the sensitivity as a function of slight gain variations. For this
simple system, the final step is not necessary.
Fig. 7.37 Equivalent configuration of Fig. 7.36.350 Linear Feedback System Design 7.10
Although this example has been solved using block diagrams and transfer
functions, it could also have been solved using the matrix-algebra approach. For
example, using Eq. (7.138), we could have also found C(s)/R(s) from Eq. (7.153) as
follows.
From Eq. (7.138), we have
®= KL^(s)b. (7.157)
K(s)
From Eq. (7.151), L is given by
L = [1 0], (7.158)
From Eq. (7.150), b is given by
b = pl (7.159)
We can evaluate &k(s) from Eq. (7.135), and it is given by
*Js) = [si - P.r1 = a;dJ.(S| ~ pl (7-160)
det (si - Pft)
and the value of Pft can be evaluated from Eq. (7.131), using the value of P from Eq.
<7J50): ' P = roP _7nJj- (7.161)
In this simple example, h is given by (this is needed in Eq. (7.131))
h = [/?! h2]. (7.162)
From these matrix equations, we can determine C(s)/R(s). The matrix approach is
generally preferable, but in this simple example, the block diagram/transfer function
method is adequate.
With this fundamental example as a basis, the general design procedure can be
formulated as follows:
1. Determine the desired closed-loop transfer function based on the discussion of
Section 5.4.
2. Determine the representation of the process to be controlled.
3. Represent the closed-loop system in terms of an equivalent linear-state-variable￾feedback configuration.
4. Determine the closed-loop transfer function C(5)/R(j) from the equivalent model
in terms of K and h.
5. Equate the C(s)/R(s) expressions from Steps 1 and 4 and determine K and h. *
6. Plot the resulting root locus of KG(s)H(s) and evaluate the relative stability and
sensitivity as a function of gain variations.
* This assumes that all of the states are measurable.7.10 Control-System Design with Linear-State-Variable Feedback 351
Let us apply this procedure next to the following more complex example. The
problem concerns the control of a process in a unity feedback closed-loop system
whose transfer function is given by
G(s) = -----------------------.
s(s + l)(s + 10)
(7.163)
It is assumed that the transient response of the system is governed by a pair of
dominant complex-conjugate poles, and that the following parameters are desired:
K,. = 0.93,
£ = 0.707,
(•>,, = 1 rad/sec.
What should the closed-loop transfer function be ? From Eq. (5.37), a pair of complex￾conjugate poles in the denominator would only,have a velocity constant given by
K, = — = 0.707. (7.164)
Therefore, a simple pair of complex-conjugate poles is inadequate to meet the velocity
constant requirement of 0.93. By examining Eq. (5.35), we conclude that a zero Z must
be added to the closed-loop transfer function. How many poles should the closed￾loop system have? Since
- NZr)cll! = (NPo - (7.165)
where
Nj, = number of closed-loop poles = ?
Nz = number of closed-loop zeros = 1
Np — number of open-loop poles = 3
jVZo = number of open-loop zeros = 0.
Therefore,
(NPc - 1) = (3 - 0), (7.166)
and
NP = 4. (7.167)
Since the resulting unity-feedback, closed-loop transfer has to have one zero and 4
poles, it has the following general form:
C(s) = <o *P 3P4 (* + Z)_____________
R(s) Z (s2 + 2C<o„s + «2)(s + P3)(s + P4) '
The value of the zero Z can be found from Eq. (5.35) as follows:
± = + l +
K,. v)„ P3 P4 Z
(7.168)352 Linear Feedback System Design 7.10
Due to external, overall system, factors in which this feedback system is to operate,
it is assumed that the poles at P3 and P4 are specified to occur at 9 and 16, respectively.
Therefore,
_l____ 2(0.707) 1 _1_ _ 1
0.93 “ 1 9 16 Z •
so that Z = 2, and the desired closed-loop transfer function is given by
C(s) _ 72(s -j- 2) 169)
R(s) (s2 + 1.414s + l)(s + 9)(s + 16)
or
<*> = . (7.170)
R(s) s4 + 26.4s3 + 180.4s2 + 229s + 144
Comparing Eqs. (7.163) and (7.170), we notice that G(s) has a denominator of only
third order while C(s)/P(s) has a denominator of fourth order. Therefore, we must
add another pole factor, s + a, to the denominator of G(s). In addition, since the
numerator of the open-loop transfer function must be the same as that of the closed￾loop transfer function, we must also add the factor
(s + 2)
to the numerator of G(s). The resulting compensating network to be added to G(s) is
given by
s + 2 Gc(s) = ^±, (7.171)
s + a
Fig. 7.38 State-variable feedback representation of system.7.10 Control-System Design with Linear-State-Variable Feedback 353
Fig. 7.39 Equivalent block diagram for system illustrated in Fig. 7.38.
where a is a pole of the open-loop transfer function which is to be determined. The
resulting linear-statervariable feedback system is illustrated in Fig. 7.38. The problem
remaining is to select the values of K, a, and h.
An equivalent block diagram of this system is illustrated in Fig. 7.39. The
resulting closed-loop transfer function from this equivalent model is given by
C(s) = __________________K(s + 2)___________________
R(s) {(K7;4 + l)s4 + [K.(h3 + 13/i4) + (11 + a)]s3
+ [K(/j2 + 12/i3 + 32/i4) + (10 + 1 la)]s2
+ [K(/ij + 2/i2 + 20/i3 + 20/i4) + lOaJs + 2K/1J. (7.172)
Equating the two forms of C(s)[R(s) given by Eqs. (7.170) and (7.172), the following
set of equations is obtained:
AT =72, (7.173)
K/u + 1 =1, (7.174)
K(h3 +13/i4) + (11 + a) =26.4, (7.175)
K(h2 + 12/?3 + 32/i4)+ (10 + Ila) =180.4, (7.176)
K(hr + 2/i2 4- 20/13 + 20/i4) + 10a = 229, (7.177)
2Khx = 144. (7.178)
Notice that we have six simultaneous equations with six unknowns (JK, hlt h2, /?3, A4,
and a). Solving these equations, we obtain the following expressions:
K = 72, Aj = 1, h2 = 0.0134,
h3 = 0.0014, A4 = 0, a = 15.3.
From Eq. (7.171), the resulting compensation network, Gc(s), is given by
which is a lead network.
It is important to emphasize that a could have turned out to be negative for a
different set of specifications. This could be undesirable since it might make the354 Linear Feedback System Design
plant open-loop unstable, depending on the value of the gain K. If it turns out to be
open-loop unstable, we would put feedback around G(s) in order to modify it to a
new open-loop function G'(s) which is open-loop stable, and then solve the problem
with the new value of G’(s).
Our results can be evaluated most conveniently on a root-locus plot. It is left as
an exercise to the reader to determine the root-locus plot of the compensated system.
(See Problem 7.32.)
Notice in this example, as in the first one, that it was not necessary to utilize
the matrix relationships previously derived: the block-diagram/transfer-function
representation was adequate. The reader is again reminded that the matrix represen￾tation should be utilized if there is a large amount of interrelation among the state
variables. In addition, if a computer is being used for solution, the matrix represen￾tation should be utilized since it is usually easier for a computer to work directly with
the matrices.
It is important to emphasize again that the discussion of linear-state-variable
feedback in this and the preceding section has assumed that all of the state variables
are accessible. This is not always the case. In general, if all of the state variables are
not measurable, one could proceed in one of two directions:
1. Measure the state variables that can be measured and use them for control.
However, the feedback of the available state variable is not through constant,
frequency-insensitive elements, as before. Instead, feedback is through frequency￾sensitive transfer functions. For example, if x2 in Fig. 7.38 were not accessible, we
still could feed back x2 by differentiating state and then connecting it to h2.
2. Use estimating filters as a Kalman filter [20- 22].
The concepts of measurable and accessible state variables are discussed further in
Chapter 9, when the concepts of controllability and observability are discussed.
PROBLEMS
7.1 Determine the circuit structure, the values of resistance and capacitance, the gains
of any amplifiers required, and the complex-plane plot for first-order networks having the
following characteristics:
a) Phase lead of 60° at to = 4 rad/sec, a minimum input impedance of 50,000 O, and an
attenuation of 10 db at de.
b) Phase lag of 60° at m = 4, a minimum input impedance of 50,000 D, and a high-frequency
attenuation of — lOdb.
c) A lag-lead network having an attenuation of 10 db for a frequency range of w = 1 to 
co = 10 rad/sec and an input impedance of 50,000 Q.
In all cases, limit the maximum values of resistance to 1 Mil and capacitance to 10 /iF.
Furthermore, assume that the loads on the networks have essentially infinite impedance.Problems 355
Figure P7.2
7.2 The system illustrated in Fig. P7.2 consists of a unity feedback loop containing a minor
rate feedback loop.
a) Without any rate feedback (b = 0), determine the damping factor, natural frequency,
peak overshoot ofthe system to a unit step input, and the steady-state error resulting from
a unit ramp input.
b) Determine the rate feedback constant b which will increase the equivalent damping factor
of the system to 0.8.
c) With rate feedback and a damping factor of 0.8, determine the peak overshoot of the
system to a unit step input and the steady-state error resulting from a unit ramp input.
d) Illustrate how the resulting steady-state error of the system with rate feedback to ramp
inputs can be reduced to the same level, if rate feedback were not used, and still maintain
a damping factor of 0.8.
7.3 Repeat Problem 7.2 for the forward transfer function ofthe system given by 20/s(l + 5).
7.4 Figure P7.4 illustrates the block diagram of a roll control system used to limit the roll
rate excursions of a missile by providing sufficient dynamic reaction to disturbing moments
[12], The disturbance moments result from changes in bank angle and steering control
deflections. The basic limitation which determines the effectiveness of the roil control system
is the response of the aileron servo.
a) Determine the transfer function, C(s)/R(s), of the system illustrated in Fig. P7.4.
b) Since the transient response is governed by a pair of dominant complex-conjugate poles,
specify the requirements of the aileron servo parameters in order that the equivalent
damping factor of the system is approximately 0.5, and the equivalent natural frequency
of the system is approximately 4 rad/sec.
Airframe
Aileron servo dynamics
Figure P7.4356 Linear Feedback System Design
7.5 A unity feedback system has a forward transfer function given by
28(1 + 0.05s)
- ,(■ +» ■
It is desired to compensate this system so that the resulting damping factor is unity (critically
damped).
a) Using the classical approach, determine the time constant of a cascaded lead network,
containing a zero factor only, that can achieve this.
b) Using the classical approach, determine the rate feedback constant of a minor rate
feedback loop which can achieve critical damping.
7.6 Repeat Problem 7.5 for the forward transfer function of the system given by
100(1 + 0.1s)
s(l + 10s) ’
7.7 It is desired that the system considered in Problem 6.17 have a phase margin of 65°
and a gain margin of 6 db. Cascade compensation is to be employed.
a) Specify the time constant of a lead network (or networks) that can achieve this.
b) Repeat part (a) for a lag network.
7.8 It is desired that the system considered in Problem 6.18 have a phase margin of 65° and
a gain margin of 34 db. Cascade compensation is to be employed. Determine the time
constant of a lag network (or networks) that can achieve this.
Desired
temperature.
Actual temperature
measured
Figure P7.9Problems 357
7.9 The temperature control loop of a nuclear power plant is illustrated in Fig. P7.9. The
transfer function of the nuclear reactor can be adequately represented by
e~0 2s
Ctj(j) = ———- ■ 0.4s + 1
A time delay is included in this transfer function to account for the time required to transport
the fluid from the reactor to the measurement point. Using the Bode diagram, determine the
values of Kx and K2 in order to achieve a phase margin of 30°.
7.10 It is desired that the system considered in Problem 6.19 have a phase margin of 45°
at the crossover frequency. Determine the stabilizing element required to achieve this.
7.11 It is desired that the system considered in Problem 6.20 have a phase margin of 45° at
the crossover frequency. Determine the stabilizing element required to achieve this.
7.12 The H.S. Denison, shown in Fig. P7.12(a), is the first large hydrofoil seacraft built and
operated in the United States [13], The craft was designed and built by the Grumman
Aerospace Corporation for the Maritime Administration of the U.S. Department of Com￾merce. The 80-ton hydrofoil is capable of operating at speeds of 60 knots in seas containing
waves 9 feet high. A simplified schematic of the automatic control system of the H.S.
Denison is illustrated in Fig. P7.12(b). It consists of transducers for sensing craft motions
and a computer for transmitting commands to the electrohydraulic actuators [13], Heave
rate is fed symmetrically to the forward flaps, roll and roll rate are fed differentially to the
forward flaps; pitch rate is fed to the stern foil. The stabilization control system maintains
level flight by means of two main surface piercing foils located ahead of the center of gravity
and an all-movable submerged foil aft. An equivalent block diagram of the pitch control
system is illustrated in Fig. P7.12(c). It is desired that the craft maintain a constant level of
travel despite a wave disturbance U(s) whose energy is concentrated at 1 rad/sec. Assume
that the specifications require that the pitch loop maintain a gain of 40 db at 1 rad/sec in
order to minimize the wave disturbance, and a crossover of 10 rad/sec for adequate response
time. In addition, it is desired to have a phase margin of at least 45° at the gain crossover
frequency of 10 rad/sec. Select the amplifier gain Ka and compensation network Gc(s) in
order to achieve these requirements.
7.13 - It is desired that the system considered in Problem 6.22 have a phase margin of 45° at
the crossover frequency. In order to achieve this, one or more phase-lead networks are
introduced into the controller. Determine the compensation required and the resulting new
crossover frequency to meet this specification.
7.14 Space vehicles using wings to maneuver while reentering the earth’s atmosphere present
an interesting control problem. Figure P7.14(a) illustrates a conceptual design of such a
system and Fig. P7.14(b) indicates the block diagram ofthe pitch-rate control system of such
a system [14]
a) Draw the Bode diagram of this system with Kx = 1 and K2 = 0. What are the resulting
gain and phase margins?
b) Select the values of A, and K2 which will result in a gain crossover frequency of 1 rad/sec,
a phase margin of at least 40° and a gain margin of at least 45 db.358 Linear Feedback System Design
(b)
(c)
Fig. P7.12 (a) Photograph of H. S. Denison. (Courtesy of Grumman Aerospace Corpora￾tion) (b) The automatic control system, (c) Block diagram of the pitch control system.Problems 359
(b)
Figure P7.14
7.15 It is desired that the system considered in Problem 6.23 have a phase margin of 65°
at the crossover frequency. In order to achieve this, two phase-lead networks are introduced
into the controller. This results in the controller having a transfer function given by
^(5) = K
1 + T\s 1 + T3s
1 + r2s 1 + 7\s ’
where K is the value of gain found in part (b) of Problem 6.23. Determine Tj, T2, T3, T4,
and the resulting new crossover frequehcy to meet this specification.
7.16 The design of the Lunar Excursion Module (LEM) shown in Fig. P7.16(a), is an 
extremely interesting problem [15], The control, guidance, and navigation for the LEM
are provided by an all-digital system from the sensors to the gas-jet propulsion units. For
purposes ofthis analysis, the vehicle dynamics can be approximated by a double integration,
as indicated in Fig. P7.16(b), which illustrates one axis of the attitude control system. In
addition, the torque T(s) is assumed to be proportional to the control signal U(s). Assume
that J = 0.25 and
T(s) = 2(7(5).
Utilizing the Bode diagram for solution, determine a lead-compensation network, Gc(s),
which will result in a crossover frequency of 6 rad/sec and a phase margin of 60°.360 Linear Feedback System Design
(a)
(b)
Fig. P7.16 (a) Apollo 11 Astronauts Neil Armstrong and Edwin Aldrin are inside the
lunar module separated from the Apollo command module. (Official NASA photo) (b)
One axis of the attitude control system.Problems 361
7.17 It is desired to add cascade compensation to the system considered in Problem 6.25 in
order that the peak overshoot to a step input be approximately 10%.
a) Using the Nichols chart, design a phase-lead network which can achieve this.
b) Repeat part (a) using a phase-lag network.
c) With the compensation networks chosen in parts (a) and (b), determine the closed-loop
amplitude and phase-frequency response for each part.
d) What conclusions can you draw from part (c) ?
7 18 It is desired to add cascade compensation to the system considered in Problem 6.27 in
order that Mv = 1.2 while the same steady-state error is maintained.
a) Design a phase-lag network to achieve this.
b) Repeat part (a) for a phase-lead network.
c) With the compensation networks chosen in parts (a) and (b), determine the closed-loop
amplitude and phase frequency responses for each part.
d) What conclusions can you draw from part (c)?
7.19 It is desired that the system considered in Problem 7.18 have a peak overshoot of
approximately 15% to a step input.
a) Utilizing a minor rate feedback loop, specify the tachometer constant which can achieve
this.
b) What will be the resulting system steady-state error to a unit ramp input with the minor
rate feedback loop added ?
c) Utilizing a simple, high-pass, RC filter in cascade with the tachometer, determine the time
constant of the network and the tachometer constant which will result in a 15% over￾shoot to a step input.
d) What will be the steady-state error to a unit ramp when the high-pass filter is cascaded
with the tachometer ?
7.20 It is desired that the system considered in Problem 6.30 have a damping factor of 0.75
for the dominant complex roots. Using the root-locus method,
a) Determine the lag network (s + «a)/(j + a) which can achieve this. Assume Kv = 15.
b) Determine the lead network (s + na.)/(s + a) which can achieve Kv = 4.15.
7.21 The signal-flow graph of the temperature control loop for a xylene chemical process
[16] is shown in Fig. P7.21. The temperature of the process, C(s), is related to the heat
k(S2 +s+0.1)
Gf(s)= -----------------
r, < \ 0.67 Cs(s)= s+03
_ , . 0 03 (s) -
s2+O.25s +0.01
Figure P7.21362 Linear Feedback System Design
supplied to the process by the quadratic transfer function Gv(s). Temperature is measured
by a sensor having a pole at s = —0.3, and the output ofthe sensor in the form of air pressure
is compared with the desired value of temperature as indicated by the reference pressure R(s).
The pressure difference (a measure of temperature error) actuates a pneumatic controller
which provides as its output a pneumatic actuating signal applied to a steam valve. The valve,
in turn, controls the flow of heat to the xylene column in order to minimize the error.
a) Draw the root locus for this system.
b) Determine the required gain K for a damping factor of 0.5.
7.22 It is desired that the system considered in Problem 6.31(b) have a damping factor of
0.75 for the dominant complex roots. Using the root-locus method,
a) Determine the lag network (s + na.)l(s + a) which can achieve this. Assume Ka = 15.
b) Determine the lead network (s + n<t)](s + a) which can achieve this. Assume Ka = 15.
c) Determine the steady-state error coefficients, cop and Mp for parts (a) and (b).
7.23 A turbine speed control system is illustrated in Fig. P7.23. Assume that the transfer
function of the control valve, turbine, and speed converter are as follows:
= rnn’
0.5
G2(j) ~ s2 + 3s + 2 ’
H(s) = 1 .
Assuming that the transient response is governed by a pair of dominant complex-conjugate
poles, determine the value of the controller gain K in order that the system having a damping
factor of 0.5
Figure P7.23
7.24 It is desired that the system considered in Problem 6.31(c) have a damping factor of
0.75 for the dominant complex roots. Using the root-locus method,
a) Determine the lag network (s + na)l(s + a) which can achieve this. Assume Kv = 15.
b) Determine the lead network (s + na.)l(s + a) which can achieve this. Assume Kv = 15.
c) Determine the steady-state error coefficients, a>p and Mp for parts (a) and (b).Figure P7.26P r o b le m s 3 6 3364 Linear Feedback System Design
7.25 Repeat Problem 7.22 for the system considered in Problem 6.31(d).
7.26 Unlike fixed-wing aircraft which possess a moderate degree of inherent stability, the
helicopter is very unstable and requires the use of feedback loops for stabilization. A typical
control system involves the use of an inner automatic stabilization loop, and an outer loop
which is controlled by the pilot, who inserts commands into it based on attitude errors dis￾played to the pilot. Figure P7.26 illustrates the pitch control system used on the S-55 heli￾copter [17]. When the pilot is not utilizing the control stick, the switch is open which
disengages the pilot control loop. The model of the pilot’s transfer function, G^s), includes a
gain factor, an anticipation time constant of 1 sec, and an error-smoothing time constant
of 10 sec [18].
a) With the pilot control loop open, plot the root locus for the automatic stabilization loop
and determine the gain K2 which results in a damping factor of 0.5 for the dominant
complex roots
b) Draw the root locus ofthe pilot control loop with K2 set at the value determined in part (a).
Determine the value of the pilot’s gain compensation factor in order that the pilot
control loop have a damping factor of 0.5.
7.27 Many modern control systems are designed to be adaptive, in order that they can
achieve a desired response in the presence of extreme changes in the system parameters and
major external disturbances. Adaptive control systems are usually characterized by devices 
which automatically measure the dynamics of the controlled system and by other devices 
which automatically adjust the characteristics of the controlled elements based on a com￾parison ofthe measurements with some optimum figure of merit. Figure P7.27 illustrates an 
adaptive pitch flight control system proposed by the Sperry Gyroscope Company for
adaptive flight control [19]. It attempts to measure the exact location of a pair of dominant,
variable, servo actuator poles which move in the complex plane, as a function of the flight
conditions. The adaptive feature overcomes this problem by adjusting the gain in order to
keep the location of these sensitive poles fixed in the complex plane. A test impulse train is
injected into the system when the error is small. The performance computer determines the
transient response of the system and compares it with an optimum desired response that is
set at 2 half-cycles of a transient response over a 3-sec interval of time. The performance
computer is designed so that a count less than 2 over a 3-sec period will cause the adaptor
motor to increase K, while a count greater than 2 over a 3-sec period will cause the adaptor
motor to decrease K. Assume that the poles and zeros ofthe system are located in the complex
plane as follows:
Poles Zeros Gain
Aircraft
aerodynamics
Pa = -4 ±/2
Pb = -1 ±/l
m <s|
1 1
II II
r* M
3 3
Ka = 0 5
Servo
actuator Pc = -3 ±76 — —
Autopilot
computer — coc = — 6 —Figure P7.27P r o b le m s 3 6 5366 Linear Feedback System Design
a) Draw the root locus of this system.
b) Determine the variable gain K that will result in a damping factor of 0.3, assuming that
the transient response is governed by a pair of dominant complex-conjugate poles.
7.28 A unity feedback control system has a forward transfer function given by
K(s + 1)
G{S) s(s2 + 6s + 9) ’
It is desired that the system have a velocity constant of 15 and a damping factor of 0.75.
Using the root-locus method, determine the lag network (s + na)/(s + a) which can achieve
this, assuming that the transient response is governed by a pair of dominant complex-con￾jugate poles.
7.29 Synthesize a system utilizing linear-state-variable feedback which has closed loop
poles existing at —9, 0 and —16, 0 and can satisfy the following specifications:
Kv = 1, C = 0.707, = 1.
It is assumed that the process to be controlled has a transfer function given by G(s) =
20/[s(s + l)(s + 10)], and that the transient response is governed by a pair of dominant
complex-conjugate poles.
7.30 Repeat Problem 7.29 for the following specifications:
C(s) 72(s + 2)
R[s) “ (72 + 1.4145 + 1)(5 + 9)(s + 16) ’
10
“ j(1 + 5s)(l + 0.5s) ’
7.31 Repeat Problem 7.29 for the following specifications:
C(s) = 8
R(s) s'3 + 6s2 + 10s + 8
cw - aTH)'
7.32 Draw the root locus and analyze the stability of the resulting system of Fig. 7.38 with
the system parameters determined.
7.33 The system shown in Fig. P7.33 contains a proportional plus integral controller.
a) Determine the steady-state error of this system to a unit step input.
h) Determine the steady-state error of this system to a unit ramp input.
c) Determine the range of gain K for which this system is stable.
Figure P7.33References 367
7.34 A negative feedback system containing unity feedback has a forward transfer func￾tion given by
G(s) = —+ —
5(5 + 2)(.v + 4)’
The zero factor (5 + A) in the numerator of this transfer function is to be used to
compensate the system. Utilizing the root locus, analyze the effects on system stability
of the following values of A:
a) A = I, b) A = 2, c) A = 3,
d) A = 4, e) A = 6.
What conclusions can you draw from your results on the best value ofA for compensating
this system?
7.35 The transfer functions of a negative feedback system are given by the following:
K
G(s} = sis2 + 6s + 10)’
H(s) = 1.
a) Sketch the root locus.
b) Determine C(s)/R(s), with denominator in factored form, if a damping factor of 0.5 is
required for the dominant roots.
7.36 Determine the lag network compensation required to stabilize a unity feedback
system whose forward transfer function is given by
= 5(5 + 3)(s + 4)'
The requirements for the system damping factor is 0.707, and the velocity constant is
100/sec.
7.37 Repeat Problem 7.28 for
REFERENCES
1. W. R. Ahrendt, Servomechanism Practice, McGraw-Hill, New York (1954).
2. J. G. Truxal, Automatic Feedback Control System Synthesis, McGraw-Hill, New York
(1955).
3. A. D. Groner, “AC stabilizing networks,” Control Eng. 55, 55-57 (September 1954).
4. G. E. Valley, Jr., and H. Wallman, Vacuum Tube Amplifiers, McGraw-Hill, New York
(1948).
5. H. Lauer, R. N. Lesnick, and L. E. Matson, Servomechanism Fundamentals, McGraw￾Hill, New York (1960).
6 J. G. Truxal (Ed.), Control Engineer's Handbook, McGraw-Hill, New York (1955).
7. H. W. Bode, Network Analysis and Feedback Amplifier Design, Van Nostrand New
York (1945).368 Linear Feedback System Design
8. J. L. Melsa and D. G. Schultz, Linear Control Systems, McGraw-Hill, New York (1969).
9. L. A. Gould, Chemical Process Control: Theory and Applications, Addison-Wesley,
Reading, Mass. (1969).
10. H. Chestnut and R. W. Mayer, Servomechanisms and Regulating System Design (2nd
Edn.), Vol. 1, Wiley, New York (1959).
II. J. L. Bower and P. M. Schultheiss, Introduction to the Design of Servomechanisms,
Wiley, New York (1958).
12. W. K. Waymeyer and R. W. Sporing, “Closed Loop Adaptation Applied to Missile
Control,” in Proceedings ofthe 1962 Joint Automatic Control Conference, p. 18-3.
13. R. M. Rose, The Rough Water Performance ofthe H. S. Denison, American Institute of
Aeronautics and Astronautics, Paper no. 64-197 (May 1964).
14. R. P. Kotfile and S. S. Oseder, “Stabilization and control of maneuvering reentry
vehicle,” Sperry Engineering Review 18, 2-10 (1965).
15. F. Doennebrink and J. Russel, “LEM stabilization and control system,” AIAAJION
Guidance and Control Conference, August 16-18, 1965, pp. 430—41.
16. W. A. Lynch and J. G. Truxal, Principles of Electronic Instrumentation, McGraw-Hill,
New York, (1962), p. 686.
17. L. Kaufman, “Helicopter control stick steering,” Sperry Engineering Review 11, 41-48
(1958).
18. S. M. Shinners, Techniques ofSystem Engineering, McGraw-Hill, New York (1967).
19. F. C. Gregory (Ed.), Proceedings ofthe Self-Adaptive Flight Control Systems Symposium,
WADC Technical Report 59-49, ASTIA Document No. AD 209389 (March 1959).
20. R. E. Kalman and R. W. Koepcke, “Optimal synthesis of linear sampling control
systems using generalized performance indices,” ASME Trans. 80, 1820 (1958).
21. R. E. Kalman, “A new approach to linear filtering and prediction problems,” ASME
Trans., Series D, J. Basic Eng. 82, 35 (1960).
22. R. S. Bucy and R. E. Kalman, “New results in linear filtering and prediction problems,”
ASME Trans., Series D., J. Basic Eng. 83, 95 (1961).B
NONLINEAR FEEDBACK
CONTROL-SYSTEM DESIGN
8.1 INTRODUCTION
The feedback control-system design methods presented in previous chapters were
restricted to linear constant systems, that is, systems that can be represented by linear
differential equations with constant coefficients. In practice, linear systems possess
the property of linearity only over a certain range of operation; all physical systems
are nonlinear to some degree. Therefore it is important that one acquire a facility
for analyzing feedback control systems with varying degrees of nonlinearity.
Any attempt to restrict attention strictly to linear systems can only result in 
severe complications in system design. To operate linearly over a wide range of
variation of signal amplitude and frequency would require components of an ex￾tremely high quality; such a system would probably be impractical from the view￾points of cost, space, and weight. In addition, the restriction of linearity severely
limits the system characteristics that can be realized.
In practice, linear operation is required only for small deviations about a quiescent
operating point. The saturation of amplifying devices having large deviations about
the quiescent operating point is usually acceptable. The presence of nonlinearities in
the form of dead zones for small deviations about the quiescent operating point is
also usually acceptable. In both cases one attempts to limit the effects of non￾linearities to acceptable tolerances, since it is impractical to eliminate the problem
entirely.
It is worth noting that nonlinearities may be intentionally introduced into a
system in order to compensate for the effects of other undesirable nonlinearities, or to
obtain better performance than could be achieved using linear elements only. A
simple example of an intentional nonlinearity is the use of a nonlinear damped
system to optimize response in accordance with the magnitude of the error [1]. The
on-off contactor (relay) servo, where full torque is applied as soon as the error
exceeds a specified value, is another case of an intentionally nonlinear system.
The purpose of this chapter is to examine the broad aspects of nonlinear systems.
We first study the characteristics of nonlinearities and then present several methods
for analyzing unintentional nonlinear feedback control systems. We follow in
Chapter 9 with several illustrations ofsynthesis of nonlinearsystems having intentional
nonlinearities utilizing optimal control theory.
We should emphasize here that methods of analyzing nonlinear systems have not
progressed as rapidly as have techniques for analyzing linear systems. Comparatively
369370 Nonlinear Feedback Control-system Design 8.2
speaking, at the present time we are still in the developmental stage. However, the
various methods presented in this chapter will enable one to analyze and synthesize
nonlinear feedback control systems quantitatively.
8.2 NONLINEAR DIFFERENTIAL EQUATIONS
A linear differential equation of the //th order, with constant coefficients, is written
AndF + A”~1 dt^ + ’ ’ ’ + y4°-v =
where x(t) represents the input to the system, t represents time and is the independent
variable, j>(r) represents the dependent variable, or the output of the system, and
An, An_±, . . . , Ao are constants.
This equation is of the form derived for several representative mechanical and
electrical systems in Chapter 3. For example, Eq. (3.19), which is repeated below,
gave the differential equation of motion for a mechanical system which consists of
a force f(t) applied to a mass, damper, and spring:
M + B + Ky = f(t).
dt2 dt
The mass of the system is represented by the constant M, the damping factor by the
constant B, and the spring constant by K.
Detailed solutions for the class of differential equations having the form shown in
Eq. (8.1) are available. They have been studied extensively, and several powerful
techniques, such as the Laplace transformation, exist for their solution. All the
analytical methods discussed in Chapters 6 and 7 are based on systems which can be
represented by simple differential equations having this general form.
If any of the coefficients An, An_x, . . . , Ao are functions of the independent
variable time, then the linear differential equation is said to have variable coefficients.
In this case, the differential equation takes the following form:
dn v An{t} de + de^ + ’' ’ + <8-2)
where An, An_lt . . . , Ao are all functions of time. Except in special cases (such as
when the coefficients are polynomials), the solution of linear time-variable equations
is quite difficult and one usually has to resort to a computer.
If the coefficients of the differential equation are functions of the dependent
variable y, then a nonlinear differential equation results. Its general form is
d"~'y
dt"~l
dy
dt
dn~1y
= *(0,
(8.3)
’ ’ ’ dt"-18.3 Properties of Linear Systems That Are Not Valid for Nonlinear Systems 371
where x(t) represents the input to the system, t represents time and is the independent
variable, y(t) represents the dependent variable and the output of a system,
^n-i> • • • > are constants, e is a constant indicating the degree of nonlinearity
present, and f(y, dyjdt, . . . , dn~1yldtn~r) is a nonlinear function.
Notice that if € = 0, Eq. (8.3) reduces to Eq. (8.1), which represents a linear
differential equation having constant coefficients. This leads us to the qualitative
rule, that a small amount of nonlinearity in a system means that e is small in compari￾son with the coefficients An, An_t, . . . , Ao. In addition, a large amount of non￾linearity means that e is large compared with An, An_v, . . . , Ao.
8.3 PROPERTIES OF LINEAR SYSTEMS
THAT ARE NOT VALID FOR NONLINEAR SYSTEMS
Several inherent properties of linear systems, which greatly simplify the solution for
this class of systems, are not valid for nonlinear systems. The fact that nonlinear
systems do not have these properties further complicates their analysis.
Superposition is a fundamental property of linear systems. As a matter of fact,
this property can be considered to be a definition of a linear system. The principle of
superposition states that if <?i(t) is the response of a system to r^t) and c2(0 is its
response to r2(t), then the system’s response to a1r1(r) -I- a2r2(t) is a1c1(t) + a2c2(t).
Unfortunately, the superposition principle does not apply to nonlinear systems.
Therefore several mathematical procedures used in the design of linear systems
cannot be used for nonlinear systems.
Stability of linear systems has been shown (in Chapter 6) to depend only on the
system’s parameters. The stability of nonlinear systems, however, depends on the
initial conditions and the nature of the input signal as well as the system parameters.
One cannot expect a nonlinear system that exhibits a stable response to one type of
input to have a stable response to other types of input. We shall shortly illustrate
nonlinear systems that are stable for very small or very large signals, but not for both.
We normally expect the output of a linear system, excited by a sinusoidal signal,
to have the same frequency as the input, although its amplitude and phase may differ.
However, the output of nonlinear systems usually contains additional frequency
components and may, in fact, not contain the input frequency.
For linear systems, interchanging two elements in cascade does not affect
behavior. This is not true if one of the elements is nonlinear.
The question of stability is clearly defined for linear constant systems: A system
is either stable or unstable. An unstable linear constant system has an output that
grows without bound, either exponentially or in an oscillatory mode with the envelope
of the oscillations increasing exponentially. In nonlinear systems, system instability
may mean a constant-amplitude output having an arbitrary waveform. It is important
to emphasize that an oscillator is stable according to Liapunov. The exponentially372 Nonlinear Feedback Control-system Design 8.4
decaying system, which we have referred to in this book as being stable, is described
by Liapunov as being asymptotically stable. *
* Asymptotic stability and nonlinear system stability classified in terms of a regional basis is
discussed in Section 8.17 where Liapunov's stability criterion is presented.
t As far as control-system design is concerned, a steady oscillation is treated as being unstable.
Another important difference concerns the amplitude of oscillation in linear and
nonlinear systems. A linear oscillator oscillates at an amplitude which is determined
by the initial conditions, whereas a nonlinear oscillator exhibits an amplitude which is
usually independent of the initial conditions.
8.4 UNUSUAL CHARACTERISTIC’S
THAT ARE PECULIAR TO NONLINEAR SYSTEMS
This section describes in detail some of the unusual characteristics that are peculiar
to nonlinear systems. These phenomena, which do not occur in linear systems, may
be desirable or undesirable depending on the application. We discuss specifically the
following behavior: limit cycle, soft and hard self-excitation, hysteresis, jump
resonance, and subharmonic generation.
Limit cycles are oscillations offixed amplitude and period that occur in nonlinear
systems. Depending on whether the oscillation converges or diverges from the
conditions represented, limit cycles can be either stable or unstable. It is possible that
conditionally stable systems may contain both a stable and an unstable limit cycle.
The occurrence of limit cycles in nonlinear systems makes it necessary to define
instability! in terms of acceptable magnitudes of oscillation, since a very small
nonlinear oscillation may not be detrimental to the performance of a system.
Self-excited oscillations occurring in systems that are unstable in the presence of
very small signals are called soft self-excitation. Self-excited oscillations occurring in 
systems that are unstable in the presence of very large signals are called hard self￾excitation. Since soft and hard types of oscillation can occur, the control engineer
must specify the dynamic range of operation completely when designing a nonlinear
system. A feedback control system containing an element having saturation charac￾teristics, such as illustrated in Fig. 8.1 (a), could exhibit soft self-excitation. A feedback
control system containing an element having dead-zone characteristics, such as
illustrated in Fig. 8.1(b), could exhibit hard self-excitation.
Hysteresis is a nonlinear phenomenon which is most usually associated with
magnetization curves or backlash of gear trains. A conventional magnetization curve
whose path depends on whether the magnetizing force H is increasing or decreasing
is shown in Fig. 8.1(c).
Jump Resonance [2], another form of hysteresis, is of considerable interest. It
exhibits itself in the closed-loop frequency response of certain nonlinear systems, as
illustrated in Fig. 8.1(d). As the frequency w is increased and the input amplitude R
is held constant, the response follows the curve AFB. At point B, a small change8.5 Methods Available for Analyzing Nonlinear Systems 373
Fig. 8.1 (a) Saturation characteristics, (b) Dead zone characteristics, (c) Conventional
hysteresis loop, (d) Closed-loop response of a system with jump resonance.
in frequency .results in a discontinousjump to point C. The response then follows the
curve to point D upon further increase in frequency. As the frequency is decreased
from point D, the response follows the curve to points C and E. At point E, a small
change in frequency results in a discontinuousjump to point F. The response follows
the curve to point A for further decreases in frequency. Observe from this description
that the response never actually follows the segment BE. This portion of the curve
represents a condition of unstable equilibrium. The system must be of the second
order, or higher, for the phenomenon ofjump resonance to occur.
Subharmonic generation [3] refers to nonlinear systems whose output contains
subharmonics of the input’s sinusoidal excitation frequency. The transition from
normal harmonic operation to subharmonic operation is usually quite sudden. Once
the subharmonic operation is established, however, it is usually quite stable. In
general, if sinusoidal signals and f2 are added and their sum is applied to a non￾linear device, the output contains frequency components aft ± bf2, where a and b
assume all possible integers including zero.
8.5 METHODS AVAILABLE FOR ANALYZING NONLINEAR SYSTEMS
Several tools are available for the analysis of nonlinear systems. All these techniques
depend on the severity of the nonlinearity and/or the order of the system under
consideration. We consider most ofthe useful and popular techniques in this chapter
and illustrate their practical application.374 Nonlinear Feedback Control-system Design 8.6
The analysis of nonlinear systems is concerned with the existence and effects of
limit cycles, soft and hard self-excitation, hysteresis, jump resonance, and subhar￾monic generation. In addition, the response to specific input functions must be
determined. The major difficulty of analyzing nonlinear systems is that no single
technique is generally applicable to all problems.
Quasilinear systems, where the deviation from linearity is not too large, permit
the use of certain linearizing approximations [12]. The describing-function approach,
which is applicable to nonlinear systems of any order and is concerned with dis￾covering limit cycles, simplifies the problem by assuming that the input to the
nonlinear system is sinusoidal and the only significant frequency component of the
output is that component having the same frequency as the input [4-7],
Nonlinear systems can often be approximated by several linear regions. The
piecewise-linear approach permits the segmented linearization of any nonlinearity for
any order of system. The phase-plane method is a very useful technique for analyzing
the response of a second-order nonlinear system [7, 17-19]. Liapunov's stability
methods are very powerful techniques for determining the steady-state stability of
nonlinear systems based on generalizations of energy notions [20-21], Popov's
method is very useful for determining the stability of time-variable, nonlinear systems
[22-29]. The generalized circle criterion is applicable to time-variable, nonlinear
systems whose linear portion is not necessarily open-loop stable [25-26].
Systems of very high order having several nonlinearities have hardly been dealt
with in general analytical terms. This problem usually requires the use of numerical
methods utilizing digital computers for a solution. It is worth emphasizing at this
point that any nonlinear differential equation can be solved by these techniques pro￾vided many small increments are used [32, 33, 36-38], However, the resulting solu￾tion is valid only for the specific problem being considered. It is very difficult to
extend the result and obtain a general solution which can be used for other problems.
8.6 LINEARIZING APPROXIMATIONS
In quasilinear systems, where the deviation from linearity is not too great, linear
approximations may permit the extension of ordinary linear concepts. This approach
acknowledges that certain system characteristics change from operating point to
operating point, but it assumes linearity in the neighborhood of a specific operating
point. The technique oflinearizing approximations is universally used by the engineer
and may be more familiar to the reader under the names small-signal theorv and/or
theory ofsmall perturbations.
Linearizing approximations were utilized when we discussed the two-phase ac
servomotor in Section 3.4. For this device, Fig. 3.16 illustrated the quasilinear
characteristics relating developed torque and speed. However, by approximating the
torque-speed curves with straight lines, the linear differential equation (3.98) was
formulated. We then obtained the transfer function of the two-phase ac servomotor,8.6 Linearizing Approximations 375
assuming that it was a linear device. It is left as an exercise to the reader in Problem
8.1 to determine the effect of various linearizing approximations.
The effects of a small amount of nonlinearity can be studied analytically by
considering small perturbations or changes in the variables about some average value
of the variables This can be represented analytically by
dy a dn~1y
dtn + dV'-1
dy-+
. dy A„y + <f(y,- dn~y
’dr-1,
= x(t).
An expansion of the solution to this differential equation, for small nonlinearities,
can be written as a power series in e as
j(z) = J(0)(Z) + eT(i)(0 + e2T(2)(?) + e3T<3)(0 + • • • •
From this equation, j(z) may be interpreted as composed of a linear component
JtoiO) and several deviation factors: ey(1)(z) 4- e2T<2)(0 + '' ’ ■ Assuming that e is
very small, the nonlinear components will not seriously affect the system’s behavior if
a linear approximation is assumed. Therefore, within the realm of reasonable eng￾ineering approximations, the control engineer may be able to extend linear theory for
certain feedback control systems which exhibit a small amount of nonlinearity. It is
very interesting that this is just the reason why linear theory has had such good results
even though practical systems are never purely linear.
Linearization techniques can also be applied to those problems where it is desired
to linearize nonlinear equations by limiting attention to small perturbations about a
reference state [12], This technique is often used in the design of space navigation
and control systems where it is desired to maintain a space vehicle along a specified
reference trajectory. It will now be shown how the corrective control forces required
to keep the vehicle on the desired flight trajectory can be synthesized from a set of
linear differential equations, although the basic differential equations describing the
reference flight trajectory are nonlinear.
To illustrate this, let us assume that the equation of the system is given by
x = f(x, u),
where the function f is nonlinear. Figure 8.2 illustrates the reference trajectory of the
space vehicle (solid line) which satisfies the equation
x° = f(x°, u°), (8.4a)
where the superscript zero refers to parameters occurring along the reference tra￾jectory. * These reference parameters are related to the parameters of the actual
trajectory (dashed line) as follows:
* It is important to emphasize that both x° and u° may be functions of time. Therefore, it
would have been more general to use the symbols x°(r) and u°(z). However, the abbreviated
symbols x° and u° will be used for simplicity.
x = x° + <5x,
u = u° + <5u.376 Nonlinear Feedback Control-system Design 8.6
Figure 8.2 illustrates the reference and actual trajectories, where the actual state x is
perturbed from the reference state x° by dx. Physically, this means that the actual
trajectory of the space vehicle is perturbed, or slightly different, from that of the
desired reference trajectory. The vector du represents the deviation of the control
input from the desired reference input u° which would result in the desired system
response x°.
Fig. 8.2 Reference and perturbed trajectories of a space vehicle [12].
What kind of relationship can we derive between x°, dx, u°, and du? The basic
nonlinear equation of the system,
X = f(x, u)
can be expressed as follows:
— (x° + <5x) — x° + dx = f(x° + dx, u° + du).
dt
Since we are assuming that the actual perturbations of the system are small, we can
expand the yth component of this equation in a Taylor series about the reference
trajectory as follows:
+ dx, //x0, u°) + dxj + • • • + ^- dx„, + du, + ■ • • + ^dun.
oxl dxM dur du„
(8.4b)
Using Eq. (8.4a), we can rewrite Eq. (8.4b) as follows:
dxj + • • • + dxm 4- <5U q- • • • + (3m (8.5)
wxb/. \dxj \duj \duj
where j — 1, 2, 3, . . . , m.8.6 Linearizing Approximations 377
Equation (8.5)
defined as follows:
can be simplified by utilizing the Jacobian matrices * that are
9A
3«i
9/2
dut
du2
df2
du2
Qfi
dun
9/2
dun
A =
3/i
dxr
dft
a/
3x2
9/2
9x2
9/i
9xm
9A
3xm
B =
9/n 9/„ | x = x» dfn 9/„ |x = x°
_3xi dx2 dxm_
| U = M° -diii du2 9«n- 1 u = u°
It is important to einphasize that all ofthe partial derivatives in the Jacobian matrices
are evaluated along the reference trajectory ofthe space vehicle. Based on the Jacobian
matrices, Eq. (8.5) can be rewritten in the following simplified form
dx sw A <)x + B du.
This resulting equation is very important. It states that the differential equation
describing the perturbations about the reference trajectory are approximately linear,
although the basic system differential equations describing the reference flight
trajectory are nonlinear. Therefore, we have succeeded in linearizing the problem.
We can also linearize a system if we can adapt it to behave like a linear system.
In order to demonstrate this, let us consider a two-position relay that controls the
rotation of a motor in either direction. It is assumed that the control voltage applied
by the relay to the motor, ec, is given by
ec = E sin a>t
and the resulting motor torque developed, T, would be a square wave due to the
switching action. Both ec and T are illustrated in Fig. 8.3. Observe from this figure
that the average, or mean, value of both functions is zero.
* Note that when linearizing along a trajectory, the matrices A and B will be functions of
time.378 Nonlinear Feedback Control-system Design 8.6
Let us next assume that the control voltage has a finite mean value Eo where
ec = Eo + E sin cot.
For this case, the torque is a periodic function whose mean value is some nonzero
value To, since the time intervals where ec is positive or negative are not equal, as
indicated in Fig. 8.4. Note that Eo is also a function of time, but it is assumed that it
is very slowly varying compared with co. Assuming, in addition, that Eo « E, it can
easily be shown that the mean value of To is given by the linear relationship
Therefore, the mean value of the torque, To, is proportional to the mean value of the
controlling voltage.
Fig. 8.4 Relay-controlled motor characteristics—Case 2.
This is a very important result. It shows that by means of a nonlinear element
like a relay, a linear relationship can be obtained between the mean value of the
controlling voltage and the mean value of the motor torque developed. The basic
linearization technique utilized has taken the mean value of the applied voltage to the
relay as the input, and superimposed on it a sinusoidal function of time whose
amplitude and frequency are very high relative to that of the input.
In the following section, we extend our linearization concepts and attempt to
apply them to nonlinear systems. Although the notion of a transfer function is
inapplicable for nonlinear systems, an equivalent approximate transfer characteristic
for a nonlinear device can be derived which can be manipulated as a transfer function
under certain circumstances. We define this approximate transfer characteristic as the
describing function. It is a very useful notion and is frequently employed in practice.8.7 The Describing-function Concept 379
8.7 THE DESCRIBING-FUNCTION CONCEPT
The use of describing functions is an attempt to extend the very powerful transfer
function approach of linear systems to nonlinear systems [4, 5, 7]. A describing
function is defined as the ratio of the fundamental component of the output of a
nonlinear device to the amplitude of a sinusoidal input signal. In general, the
describing function depends on the input signal’s amplitude and frequency and is
complex because phase shift may occur between the input and the fundamental
component of the output. We study the describing-function method of analysis and
compare it with the transfer-function concept for linear systems.
If the input to a nonlinear element is a sinusoidal signal, the describing-function
analysis assumes that the output is a periodic signal having the same fundamental
period as that of the input signal. Therefore, the analysis is concerned only with the
fundamental component of the output waveform. All harmonics, subharmonics,
and any de component are neglected. This assumption is reasonable since the
harmonic terms are often small when compared with the fundamental term. In
addition, a feedback control system usually provides additional attenuation of the
harmonic terms because of its inherent filtering action. Many nonlinear elements do
not generate a de term since they are symmetrical, nor do they generate any sub￾harmonic terms [3], Therefore, in many (but not all) situations the fundamental
term is the only significant component of the output of the nonlinear element. In
addition, it is assumed that there is only one nonlinear element in the feedback control
system and that it is not time varying. Ifa system contains more than one nonlinearity,
we must lump all the nonlinearities together and obtain an overall describing function.
An examination of these limitations indicates that the describing function is based
on a restricted mathematical foundation. The technique does give, however, reason￾able results and does have an advantage that it can be used for systems of any order
and is fairly simple to apply. It is recommended that the results always be checked
with a computer simulation.
Given its limitations, the describing-function technique is still a very useful tool
for analyzing and designing nonlinear systems. The describing function should be
thought of as a generalized transfer function for nonlinear systems. Linear criteria
of stability, for example, the Nyquist diagram, the Nichols chart, and the root locus,
can be used to interpret system stability, with the added constraint that stability must
be analyzed as a function of signal level and frequency of the input signal.
In order to derive a mathematical expression for the describing function, let us
consider the nonlinear system illustrated in Fig. 8.5. In accordance with the definition
of the describing function, let us assume that the input to the nonlinear element N is
given by
m(cof) = M sin cot. (8.6)
In general, the steady-state output of the nonlinear device can be represented by the
series
n(cot) = M sin (cot + <£j) + N2 sin (2cot + </>2) + N3 sin (3cot + <f>3) + • • • . (8.7)380 Nonlinear Feedback Control-system Design 8.8
By definition, the describing function is
N(M, to) = — e^1. (8.8)
M
Notice that the describing function depends on the amplitude and frequency of the
input signal. The nonlinear element is thus considered to have a gain and phase
shift varying with the amplitude and frequency of the input signal.
Fig. 8.5 General nonlinear system.
8.8 DERIVATION OF DESCRIBING
FUNCTIONS FOR COMMON NONLINEARITIES
The describing functions for several common nonlinearities are derived in this section
[5, 6, 7], The procedure most commonly used is to determine the Fourier series of
the output waveshape from the nonlinear device and consider only the fundamental
component. Let us consider the nonlinear element N in an overall feedback control
system, as shown in Fig. 8.5. Assuming that the input m is given by a sinusoidal
signal where
m(o)t) = M sin mt, (8.9)
we can represent the output waveshape by a Fourier series given by the expression
where
K=oo ' K—cc
n(o)t) = — + 2 Ak cos Kcot + y Ba- sin Kcot,
2 K=1 A=1
2 ct/2
Ak = — n(cot) cos Kcot d(cot), K = 0, 1,2, . . .
T J-T/2
2 CT/2
Bk = — n(a>t) sin Kcot d(cof), K = 1,2,3,....
T J-T/2
(8.10)
(8.11)
(8.12)
In general, if n(cot) = —n( — <ot), then the function is odd and AK = 0. In addition,
if n(cot) = n(—a>t), then the function is even and BK — 0.
Since we are only concerned with the fundamental component of the output, it is
necessary to determine only A± and Br. For m(cot) = M sin cot, the describing
function can then be obtained from the expression
N(M, co) = + j
M M
(8.13)8.8 Derivation of Describing Functions for Common Nonlinearities 381
The control engineer is usually concerned with the nonlinearities due to dead
zones, saturation, backlash, on-off relay control systems, coulomb friction, and
stiction. We specifically derive and catalog their describing functions so that a handy
reference for some common describing functions will be available. In addition, the
procedure illustrated should enable one to develop the facility for calculating the
describing function of any nonlinearity encountered.
1. Describing Function of a Dead Zone Figure 8.6 illustrates the dead-zone character￾istic. The relationships between input and output ofthis nonlinearity can be expressed
by the equations
n(cot) = 0
n(cot) = KxM(sin cot — sin cotj)
n(cot) = KyM(sin cot + sin coty)
for —D < m < D,
for m > D,
for m < — D.
(8.14)
(8.15)
(8.16)
Fig. 8.6 Nonlinear characteristics of a dead zone.
Figure 8.7 illustrates typical input and output waveshapes. Notice that the output
is an odd function, and therefore AK = 0. The symmetry over the four quarters of
the period allows us to evaluate the expression for the Fourier coefficient, By, by
taking four times the integral over one quarter of a cycle, as follows:
a
By — - n(cot) sin cot d(cot). (8-17)
77 Jo
Substituting Eqs. (8.14) and (8.15) into Eq. (8.17), we obtain
By (0) sin cot d(cot) +
• zr/2
KjM(sin cot — sin wtj) sin cot d(cof)
(oil
(8.18)
where
coty = sin-1382 Nonlinear Feedback Control-system Design 8.8
Fig. 8.7 Input and general form of the output waveshape from a nonlinear device having
dead-zone characteristics.
Evaluation of Eq. (8.18) results in the expression
2K.M
— --------
TT
— cos sin
M
—
D -i — sin (819)
M
From Eq. (8.19), since the describing function is the ratio of the amplitude of the
fundamental component of the output to M, it can be expressed as
Ndz(M) =
2K 'rr D . _x D . _i D\ —------ cos sin------- sin — .
,2 M M MJ
(8.20)
Notice that the describing function for a dead zone is only a function of the
amplitude of the input and not of frequency. Figure 8.8, obtained from Eq. (8.20),
is a sketch ofthe normalized value ofthe describing function N/K1 as a function ofthe
ratio D/M. For very small values of D/M the normalized describing function
approaches unity. For values of D/M 1 it equals zero, which implies that the
input must be greater than the dead-zone magnitude in order to obtain an output.
Notice that the describing function for a dead zone does not have any phase shift.
2. Describing Function of Saturation Figure 8.9 illustrates the saturation character￾istic. The relationship between input and output of this nonlinearity can be expressed8.8 Derivation of Describing Functions for Common Nonlinearities 383
Fig. 8.8 Normalized describing function for a dead zone.
by the following equations
n(cof) = KyM sin cot
n = K.S
n = -KiS
for —5 < m < S,
for m > S,
for m < — 5.
(8.21)
(8.22)
Figure 8.10 illustrates typical input and output waveshapes.
Notice that the output waveshape is an odd function for the case of saturation
just as it was for the case of a dead zone. Therefore, the expression for the Fourier
coefficient Br of the output waveshape is
2 f272
Bi = — I n(cot) sin cot d(cot).
T J-T/2
(8.23)
As was true for dead zone, the expression for the Fourier coefficient Bt can be obtained
by taking four times the integral over one quarter of a cycle because of the symmetry
Fig. 8.9 Nonlinear characteristics of saturation.384 Nonlinear Feedback Control-system Design 8.8
Fig. 8.10 Input and general form of the output waveshape from a nonlinear device having
saturation characteristics.
over the four quarters of the period. This results in the expression
4 f17/2
= — n(cot) sin cot d(cot). (8-24)
IT JO
Substituting Eqs. (8.21) and (8.22) into Eq. (8.24), we obtain
4 r pir/2 -i
Bi = - KyM sin cot sin cot d(wt) + K±M sin cot1 sin cot d(wt) , (8.25)
7T |_v 0 Jcoti J
where
■ -i s
cot, = sin — • M
Evaluation of Eq. (8.25) results in the expression
D 2K.MJS . S . , S\ Bi =-------- —cos sin 1 — + sin 1 — |. (8.26)
77 \M M Mj
Since the describing function is defined as the ratio of the amplitude of the funda￾mental component of the output, Bt, to M, the describing function can be expressed
as
.. Br 2KJS . S . ,S\
Nsat(M) = — = ----- —cos sin — 4-sin — 1. (8.27) M 7T \M M MJ V }8.8 Derivation of Describing Functions for Common Nonlinearities 385
Fig. 8.11 Normalized describing function for saturation.
Notice that the describing function for saturation is only a function of the
amplitude of the input and not of frequency. Figure 8.11, obtained from Eq. (8.27),
is a sketch of the normalized value of the describing function NlKr as a function of
the ratio SfM. For very small values of S/M, the normalized describing function
approaches zero. For values of S/M 1 it equals unity, which implies that the
output is unaffected by the saturation level if 5 > Af. Notice that the describing
function for saturation does not introduce any phase shift.
It is important to emphasize that the describing functions for dead zone and
saturation could have been obtained from one nonlinear characteristic containing
m(wt) = input
displacement
n(«z) = output
displacement
Fig. 8.12 Physical model of backlash.386 Nonlinear Feedback Control-system Design 8.8
both types of nonlinearities. Then, the resulting describing function could be reduced
to the describing function of dead zone (Eq. 8.20) by letting the saturation level
approach infinity, or it could be reduced to the describing function of saturation
(Eq. 8.27) by letting the dead-zone width approach zero. It is recommended that the
reader derive Eqs. (8.20) and (8.27) using this approach (see Problem 8.2).
3. Describing Function of Backlash Backlash or mechanical hysteresis is due to the
difference in motion between an increasing and a decreasing output. Figure 8.12
illustrates a model of backlash, and Fig. 8.13 illustrates its characteristics. The source
of backlash that usually receives the most attention is the “looseness” inherent in
mechanical gearing. Although attempts have been made to design gears and other
mechanical transmission devices so as to fit their mating members very tightly, it is
practically impossible to eliminate backlash entirely.
Fig. 8.13 Characteristics of backlash.
From Fig. 8.14, the relationship between input and output for this nonlinearity
can be expressed by the following equations:
Notice that the output waveshape is neither an odd nor an even function. This
means that the Fourier series of the output waveshape has AK and BK components.
n(mt) = — (M — D) for 0 4C cot < mtj, (8.28)
n(a>t) = M sin cot - D for cotj «C mt <
77
2 ’
(8.29)
n(cot) = M — D for — «
2
% ml < mt2, (8.30)
n(cot) = M sin cot + D for cot2 4C mt <
3 77
2 ’
(8.31)
n(cot) = — (M — D) r 3ir for — <
2
% mt < 277. (8.32)8.8 Derivation of Describing Functions for Common Nonlinearities 387
Fig. 8.14 Backlash characteristics where D <M < ID.
Since the describing function is concerned only with the fundamental component of
the output, however, we are interested only in Ar and B±. From Eqs. (8.28) through
(8.32), we can express Ar as
9 p fioti Ft/2
At = — — (M — D) cos cot d(cot) + (M sin cot — D) cos col d(cot)
2ttLJo
p<oti /*3ff/2
+ (M — D) cos cot d(cot) + (M sin cot + D) cos cot d(cot)
Jr/2
— (M — D) cos cot ci(cot)
cotx = sin 1
(8.33)
where
(8.34)
and
COt2 = COtj + 77, (8.35)388 Nonlinear Feedback Control-system Design 8.8
and Bl can be expressed as
2 r fwii l'ir/2
Br = — — (M - D) sin <ot d(mt) + (M sin cot — D) sin cot d(cot)
27tL«/O dati
f*ot2 f*3ir/2
+ (M — D) sin cot d(cot) + (M sin cot + D) sin cot d(cot)
Jtr/2 Jot2
P2v “I
+ — (M — D) sin cot d(cof) . (8.36)
J31/2 J
Integrating Eqs. (8.33) and (8.36), we obtain the following results:
A 2D /2D , ZQ At = ----- — — 2 \M, (8.37)
ttM\M /
_ ITtt . -tl2D \ [2D .\ . [2D .X-!.- ZQ B, = - ------- sin I--------- 11 — I--------- 11 cos sin--------- II \M. (8.38)
7rL2 \M J \M J \M /J
Therefore, the describing function for backlash is given by
Nbackia.Sh(M) = 7; VX + B? /tan'1 (A/BQ. (8.39)
M
This expression is valid only when the positive slope of the backlash characteristic as
shown in Fig. 8.14 is unity. If it is any other value, such as Klf then Eq. (8.39) is
modified, since the right-hand sides of the defining equations (8.29) and (8.31) would
have to be multiplied by Kx.
Notice that the describing function for backlash is only a function of the ampli￾tude of the input and not of the frequency. Figures 8.15 and 8.16, which have been
obtained from Eqs. (8.37) through (8.39), are sketches of the amplitude and phase
Fig. 8.15 Amplitude characteristics for the describing function of backlash.8.8 Derivation of Describing Functions for Common Nonlinearities 389
Fig. 8.16 Phase characteristics for the describing function of backlash.
characteristics, respectively, of the describing function as a function of the ratio D[M.
Notice that a phase lag occurs at low amplitudes. This phase lag may introduce
problems of stability in a feedback system.
4. Describing Function of an On-Off Element Having Hysteresis A class ofsystems of
great practical importance is that of “on-off” control systems. In these systems, as
soon as the error signal exceeds a certain level, a relay switches on full corrective
torque having proper polarity. When the error falls below a certain level, all the
corrective torque is removed. These simple and relatively inexpensive devices find
many practical uses in thermostatic control of heat, in automobile voltage regulators,
in aircraft and space-vehicle control applications where space and weight limitations
are very critical, and so on.
The heart of an on-off control system, the relay or contactor, has a variety of
characteristics. For the purpose of deriving a describing function, we consider a
three-position contactor exhibiting hysteresis characteristics; this includes the two￾position contactor as a limiting case. Figure 8.17 illustrates the input-output charac￾teristic and the waveshapes for such a device. The hysteresis effect occurs because of
the different values of control signal required for corrective torque application and its
removal. Torque is applied when the control signal reaches ±(D + A), but it is not
removed until the control signal equals ±Z>. The relationship between input and
output for this nonlinearity can be expressed by the following equations:
«(cot) — 0 for wit < cot < coti, (8.40)
n(cot) = Kr for cotj < cot < cot2, (8.41)
n(cot) = 0 for cot2 < cot < co/3, (8.42)
«(wt) = — A'j for cot3 < cot < cotf (8.43)390 Nonlinear Feedback Control-system Design 8.8
Fig. 8.17 On-off characteristics for a three-position contactor having hysteresis.
Notice that the output waveshape is neither an odd nor an even function. The
Fourier series ofthe output waveshape, therefore, contains AK and BK components.
From Eqs. (8.40) through (8.43), we can express Ar as
2 r
A = ~ (0) cos cot d(cot) + (Kx) cos cot d(cot)
27r[_ */aj/ 4 Jcuti
-I
+ (0) cos cot cZ(cot) + (—KJ cos cot d(cot) , (8.44)
J Jcois
where
(Oh = sin'1 ——, (8.45)
M
■ -i D
(ot2 — it — sin 1 — , (8.46)
M
cot3 = cotx + TT, (8.47)
cot4 = cot2 + 77, . (8.48)8.8 Derivation of Describing Functions for Common Nonlinearities 391
and Bx as
2 r f"' *
By = — I (0) sin cot d(cot) 4- (KJ sin cot d(<ot)
27r|_J«t« J<u«i
4- I (0) sin cot d(cot) 4- I (—KJ sin cot d(cot) . (8.49)
J<otz J
Integrating Eqs. (8.44) and (8 49), we obtain the expressions
= (8-5O)
7T \MJ
= ^iFcossin-1-^-^—- — cos (n — sin-1—)1. (8.51)
7T L M \ Af/J
The describing function is given by the expression
DNon^tt(M) = y/Al + Bj /tan"1 £ . (8.52)
Az / B,
Notice that the describing function for this device is a function only ofthe amplitude
of the input and not of frequency. Figures 8.18 and 8.19, which have been obtained
from Eqs. (8.50) and (8.51), are sketches of the normalized amplitude and phase
characteristics ofthe describing function as a function of the ratio MID, respectively.
Notice that the phase lag is zero when hysteresis is not present and grows progressively
worse as the hysteresis increases.
Fig. 8.18 Amplitude characteristics for the describing function of an on-off device having
hysteresis.392 Nonlinear Feedback Control-system Design 8.8
Fig. 8.19 Phase characteristics for the describing function of an on-off device having
hysteresis.
5. Describing Function of Coulomb Friction and Stiction In Chapter 3 we considered
the effect of damping in linear systems. Damping, a form of friction, is known as
viscous friction. Its characteristic is that its magnitude is always proportional to
velocity, as illustrated in Fig. 8.20(a). The damping factor B is the slope of this
characteristic. Another type of frictional force commonly found in control systems
is known as coulombfriction. Unlike viscous friction, it is not proportional to velocity
but is a constant force that always opposes the velocity. This nonlinear phenomenon
is illustrated in Fig. 8.20(b), where the coulomb friction force is denoted by ±FC.
Another nonlinear form of frictional force, known as static friction or stiction, is the
value of the frictional force at zero velocity. It is usually denoted by ±FS. Figure
8.20(c) illustrates the composite frictional-force characteristics generally encountered
when controlling some load.
To determine the describing function of coulomb friction, we can express the
relationship between the input and output as
n(a>t) = m(cot) ± Fc
Fig. 8.20 (a) Viscous friction characteristics, (b) Coulomb friction characteristics, (c)
Composite friction characteristics illustrating viscous, coulomb, and static friction (stiction).
Velocity8.8 Derivation of Describing Functions for Common Nonlinearities 393
Fig. 8.21 Coulomb friction characteristics.
where
/n(ojt) = applied force,
. Fc = force necessary to overcome coulomb friction,
n(rot) = output force.
The corresponding steady-state waveforms are given by Fig. 8.21. It should be noted
that the discontinuities of the output waveform correspond to zero velocity since the
force required to overcome coulomb friction changes sign at these instants. The
relationship between the input and output forces is
n(ct>r) = A/sin cot + Fc for —coty < cot < cot2, (8.53)
= M sin cot — Fc for cot2 < cot <. tt, (8.54)
where
coty = sin-1 y, cot2 = cos-1 (rry/2), y = FJM.
The fundamental components of the output Ay and By are
2 = — I Af(sin cot + y) cos cot d(cot)
7T J—(Dti
2 ^v—cati
-|- - M(sin cot — y) cos cot d(cot), (8.55)
7T Jcofg
2 fcoia
B1 = — M(sin cot + y) sin cot d(cot)
77 (oti
fir—ofi
+ — M(sin cot — y) sin cot d(cot). (8.56)
77 Jw/2
Integrating Eqs. (8.55) and (8.56), we obtain the following expressions:
/ 4 \1/2
Ay = 2My\-2 - y2 I , (8-57)
\77 /
By = M[1 - 2y2]. (8.58)394 Nonlinear Feedback Control-system Design 8.8
The resulting expression for coulomb friction is
T / 4\ »"l1/2/ , 2v(4/7t2 - y2)1/3 Ne(y) = P ~ ~ /tan"1 t 2^2 for 7 < °’536 <8'59)
7Vc(y) = — {[vr — (wtj — cot2) — sin «Z1(cos o>tl + cos Mt2)
TT
— cos n>t2(sin cotj + sin cot2)]2 + [sin Mtv + sin cot2]}1/2
. sin Mt, + sin Mt2
x /tan 1-----------------------------—--------- ----------------------
[
/ {tT — (Mtt — Mt2) — sin Mtjfcos MtT + cos wt2)
— cos mt2(sin Mtl + sin cot2)}
for y > 0.536. (8.60)
Observe that the describing function for coulomb friction depends only on the
amplitude of the input and not on its frequency. The gain-phase relationship of the
describing function for coulomb friction is illustrated in Fig. 8.22.
Fig. 8.22 Gain-phase characteristics for the describing function of coulomb friction.8.8 Derivation of Describing Functions for Common Nonlinearities 395
Fig. 8.23 Coulomb friction and stiction characteristics.
The describing function for the simultaneous occurrence of both coulomb friction
and stiction is considered next. Waveform relationships between the applied force
nz(a>t), the output force n(cot), and the forces necessary to overcome coulomb friction
and stiction Fc and Fs are given in Fig. 8.23. The expressions for the fundamental
components of the Fourier coefficients are
2
zlj = — I Af(sin a>t — y) cos cut d(a)t),
TT Jcofg
= - I M(sin cut — y) sin a>t d(a>t),
TT £0^2
(8.61)
(8.62)
where
a)t1 = sin-1 y,
ot2 = sin-1 (FS[M),
wt3 = cos-1 (n-y/2),
y = FJM.
The describing function for the combined case of coulomb friction and stiction is
obtained by integrating Eqs. (8.61) and (8.62). The resultant expression is
yV(y) = - {[tt — (cut2 — cot3) — cos co/2(2 sin cot. — sin tut2)
— cos &>t3(2 sin cutj + sin cot3)]2
+ [sin cot3(2 sin cotj + sin cot3) + sin cot2(2 sin cotj — sin cot2)]2}1/2
sin cot3(2 sin cotj + sin cot3) + sin cot2(2 sin cot1 — sin tt>t2)
tan —-------------------- ----------------—~ ;
tt — (cot2 — cot3) — cos cot2(2 sin <x>tx — sin cot2)
— cos cot3(2 sin cotj + sin o.'t3)
x
(8.63)396 Nonlinear Feedback Control-system Design 8.9
Fig. 8.24 Gain-phase characteristics for the describing function of coulomb friction and
stiction.
Observe from this expression that the describing function for the combined case of
coulomb friction and stiction is a function of the amplitude of the input and the
relative magnitudes of friction but not of frequency. Figure 8.24 illustrates the gain￾phase relationship of the describing function for the combined case of coulomb
friction and stiction.
8.9 USE OF THE DESCRIBING FUNCTION TO PREDICT OSCILLATIONS
The describing function of a nonlinear element can be utilized to determine the
existence of a limit cycle in a nonlinear feedback control system in an approximating
manner [8], Let us consider the system illustrated in Fig. 8.5. If we assume that8.9 Use of the Describing Function to Predict Oscillations 397
the describing function ofthe nonlinearity is N(M, co) and R(jco) = 0, let us determine
the conditions under which an assumed oscillation m(cot) can be sustained, where
m(cot) = M cos cot, (8.64)
The fundamental component of n(cot) is given by
»i(<ot) = w)| M cos [cot + ^(Af, co)]. (8.65)
Expressing Eqs. (8.64) and (8.65) as the real part of a complex exponential, we obtain
the following expressions:
m(cot) = Re [Me3mt],
n^cot) = Re [fN/Af, co)| Af?(o,,+*,)].
The output of the linear elements is given by
Re [IM(Af, co)| M |G(»[ (8.66)
where
G(jco) = G1(jco)G2(yco),
a = phase shift due to G(jco).
Equation (8.66) must equal — m(cot) if the initial assumption is to hold. Thus,
dropping the real-part notation, we obtain the following expression:
-Meiat = \Nr(M, w)| M \G(jco)\ eit<at+4,1+x>.
This can be rewritten as
[|MO, w)| \G(jco)\ ei(<t,l+x) + l]Meiat = 0. (8.67)
For a sustained oscillation, the bracketed term in Eq. (8.67) must vanish, since
M/0. Therefore,
1 + MA/, co)G(jco) = 0 (8.68)
and any combination of values of input amplitude M and frequency co which satisfy
the equation
G(» = - v (8-69)
N(M, co)
are capable of providing a limit cycle. If a combination of amplitude and frequency
can be found which satisfies Eq. (8.69), the feedback control system can have a
sustained oscillation.
From experience, I have found the Nyquist diagram and the Nichols chart
(gain-phase plot) to be the most revealing techniques for stability analysis when
utilizing the describing-function method. Two separate sets of loci, corresponding to
G(jco) and — co) of Eq. (8.69), are sketched on the same graph for either of
these methods. Generally, the sketch of co) will be a family of curves for398 Nonlinear Feedback Control-system Design 9.9
Fig. 8.25 (a) Gain-phase diagram stability analysis of nonlinear system containing a dead
zone where
2
G(.ja>)H{j^ =———————
(b) Gain-phase diagram stability analysis of nonlinear system containing a dead zone where
17
J J jco(l 4- O.5y'co)(l + O.ly'oj)
different input magnitudes M and frequencies a>. Intersections of the two loci
indicate possible solutions to Eq. (8.69) and yield information as to the magnitude
and frequency co of sustained oscillation. If no intersections result, an oscillation is
unlikely. The distance to a possible intersection can be used as a criterion of closeness
to oscillation. This is next illustrated on the gain-phase diagram for several represen￾tative systems.
Figure 8.25(a) illustrates an analysis via the gain-phase diagram for a nonlinear
system containing a dead zone where KY = 1. The figure illustrates a stable system8.9 Use of the Describing Function to Predict Oscillations 399
where a dead zone is present and
2 G(»H(» =
>(1 4- 0.5»(l + 0.1»
Figure 8.25(b) illustrates a system where a dead zone is present and
17
jco(l + 0.5jco)(l + 0.1/co)
(8.70)
(8.71)
An intersection occurs at a frequency of approximately 4.4 and a value of D/M of
0.09. This is to be interpreted as the frequency and amplitude which satisfy Eq. (8.69)
and which result in a limit cycle. Notice that the system is unstable from a linear
viewpoint since the — 1,0 point is enclosed.
The interpretation of this situation is quite illuminating. Since the normalized
describing function of a dead zone is less than one, its effect is to reduce the overall
system gain. When multiplied by the transfer,function given by Eq. (8.70), which
would produce a stable feedback system by itself, its effect is to make the system even
more stable. Therefore, in order to illustrate a limit cycle in this nonlinear system
containing a dead zone, it is necessary to illustrate a system that produces an unstable
feedback system from a linear viewpoint as well. The frequency function of Eq.
(8.71) satisfies this requirement, as indicated in Fig. 8.25(b).
Figure 8.26 illustrates the gain-phase diagram analysis for a nonlinear system
containing backlash, where
G(»H(» =
1.5
ja>(l + /co)2
(8.72)
Gain (db)‘
30 -
20
10
-IOI I I I 1 1__ I__ 1__ 1__ I__ 1-- 1------
-200 -180 -160 -140 -120 Phase (degrees)
0
Fig. 8.26 Gain-phase diagram analysis of nonlinear system containing backlash.400 Nonlinear Feedback Control-system Design 8.9
Notice that the system has two points of intersection corresponding to a pair of
limit cycles. They occur at co = 0.84, D[M = 0.16 and co = 0.3, DIM = 0.82.
These two limit cycles must now be examined to determine whether they are stable
or unstable.
A generalized rule can be established for determining whether aflimit cycle is
stable or unstable [39], If the two loci are assigned a sense of direction so that the
linear locus G(jco) is pointing in the direction of increasing frequency and the non￾linear locus — 1/jV is pointing in the direction of increasing amplitude M (decreasing
D/M in our example), then a stable limit cycle occurs when the nonlinear locus
appears to an observer, stationed on the linear locus and facing in the direction of
increasing frequency, to cross from left to right in the direction of increasing ampli￾tude M. If the opposite occurs, then the limit cycle is unstable and the state of the
system is divergent. As an example of applying this rule, consider the gain-phase
plot of Fig. 8.27. Here, we see that there are two unstable limit cycles (divergent
states) and three stable limit cycles (convergent states). The unstable limit cycles
cannot maintain themselves in the presence of minute disturbances; the stable limit
cycles will always maintain themselves in the presence of disturbances.
Applying this generalized rule for determining whether the limit cycles in Fig.
8.26 are stable or unstable, we find that co = 0.84, D/M = 0.16 corresponds to a
stable limit cycle and the other intersection corresponds to an unstable limit cycle.
The stable limit cycle corresponds to a convergent point because disturbances at
either side tend to converge to these conditions. This is contrasted with the unstable
limit cycle at co — 0.3, DIM = 0.82, which is a divergent point, since disturbances
which are not large enough to reach this intersection will decay, and disturbances8.10 Design of Nonlinear Feedback Control Systems Using Describing Functions 401
which are larger will result in oscillations which tend to increase in amplitude until
the stable limit cycle is reached.
8.10 DESIGN OF NONLINEAR FEEDBACK
CONTROL SYSTEMS USING DESCRIBING FUNCTIONS
The purpose of this section is to illustrate the procedure for compensating for unde￾sirable nonlinearities in a system. As an example, we consider the nonlinearity te be
backlash. The gain-phase plot will be used for analysis, although we could use the
Nyquist diagram just as well.
Oscillating input signals, having frequencies very much greater in magnitude than
the system bandwidth, can be used to maintain the output of a system containing
backlash at its correct average value. This technique is known as dither. It is effective
in reducing the influence of very small amplitude nonlinearities. However, the
resultant increased wear on the system is a serious disadvantage of this simple
approach to the problem. The effect of dither on the describing function is analyzed
in References 9 through 14 where the “dual input describing function” is discussed.*
For systems which are to operate continuously for long periods of time, it is necessary
to utilize other approaches which will eliminate backlash. Reducing the system gain,
addition of phase-lead networks, and introducing rate feedback are all relatively simple
methods which can be used to minimize the effects of backlash. We next demonstrate
the theoretical effects of these techniques on backlash [1, 8].
___ KN(M.,to)
* The dual-input describing function is a modified describing function which is dependent on
two frequency components: the intelligence signal and the dither signal.
Let us reconsider the nonlinear system analysis of Fig. 8.26. This sketch illus￾trated that a nonlinear system having the form shown in Fig. 8.5, where
G(» = Gi(jtt>)G2(» = 7 ;1'”|5TT2 >
ja>(l + ja>)
and having a backlash element, was indeed oscillatory. We demonstrate how this
system can be stabilized by each of the following electrical methods:
a) Reducing the system gain.
b) Adding a phase-lead network.
c) Introducing rate feedback.
1. Reducing the System Gain In order to consider the effects of gain changes, let
us rewrite G(jcd) of Eq. (8.68) as
G(ja>) = KG'(Ja>),
where K represents the system gain and G'(j(d) represents only the poles and zeros
of the linear part of the system. Therefore, Eq. (8.69) can be rewritten as
u < VJ) — —402 Nonlinear Feedback Control-system Design 8.10
By reducing the gain K, the limit cycle is eliminated because the curve of — \JKN is
moved upward. Figure 8.28 illustrates how the oscillation can be eliminated by reduc￾ing the system gain from 1.5 to unity. At a gain setting of approximately 1.3, the
curves of G'(ja>) and — 1/KNjust clear each other. A gain setting of unity was chosen
in order to maintain some margin ofsafety.
Fig. 8.28 Compensation of a nonlinear system containing backlash, by reduction of the
system gain.
2. Addition of a Phase-Lead Network A passive phase-lead network can also be
used to eliminate the oscillation. The transfer function of this network is given by
G0’w)lead =
1 + aTQ'co)
1 + T(ja>)
(8.73)
where <x.T > T. (The attenuation 1/a is nullified by increasing the system gain by a.)
The compensated value of G(ja>), G(/co)comp, is given by
G(j<o)comp — . 2 X
jw(l + jmy
1 + «TQ>)
I + T(» ’
(8.74)
For the system under consideration, a value of aT = 0.8 and T = 0.4 will eliminate
the limit cycle, as is illustrated in Fig. 8.29. This is not the only lead network which
could be used for compensation; it is one of many possible solutions, as can be noted
from studying the gain-phase diagram.8.10 Design of Nonlinear Feedback Control Systems Using Describing Functions 403
Fig. 8.29 Compensation of a nonlinear system containing backlash, by addition of a
phase-lead network.
3. Introduction of Rate Feedback Addition of rate feedback can also be a very
effective method for eliminating the oscillation. For this configuration, which is
illustrated in Fig. 8.30, the value of the system feedback element is 1 + bja>.
Therefore, the oscillation criterion for this configuration must be modified from that
given by Eq. (8.69) to the following expression:
G(»H(» = - 1 . (8.75)
N(M, a>)
With rate feedback, the value of for the system being considered is given
by 15
G(jw)H(» = . - (1 + bjco). (8.76)
co(l + jmY
Fig. 8.30 Nonlinear system containing rate and position feedback.404 Nonlinear Feedback Control-system Design 8.11
Fig. 8.31 Compensation of a nonlinear system containing backlash, by the introduction of
rate feedback.
A value of b = 0.4 will eliminate the limit cycle, as is illustrated in Fig. 8.31, and a
relatively safe margin is achieved. At a value of b approximately equal to 0.25, the
curves of (7(/co)7f(jw) and — 1/A just clear each other.
Since the describing-function analysis is an amplitude-sensitive method applicable
to nonlinear systems, and since superposition ofsignals is not valid for these systems,
we cannot extend this method and obtain data on low-amplitude transient responses.
Our main concern has been the elimination of limit cycles.
8.11 DIGITAL COMPUTER
COMPUTATION OF THE DESCRIBING FUNCTION
The digital computer is very useful for the construction of the describing function
[40, 42], The computer can compute — 1/A and, as indicated in Chapter 6, G(Jco).
This section illustrates the procedure used to analyze and compensate a practical non￾linear system containing backlash with the aid of a digital computer. It is based on the
analytic method illustrated in Sections 8.7 through 8.10. The BASIC language will be
used for the program [34, 35].
Let us consider the system illustrated in Fig. 8.5, where
GO) = t (8.77) jw(i + 2jc»y
and N corresponds to backlash. We know from Eq. (8.39) that
^baekiasb(M) = j + B2 /tan-1 (A/B), (8.78)8.11 Digital Computer Computation of the Describing Function 405
Fig. 8.32 (a) Logic flow diagram for determination of — 1/M.
where
„ 1 [7T . _J2D \ (2D \ . _x (2D B = — — sin I---------11 — I---------11 cos sin I-------- 11 Al.
77 L2 \M / \M J \M /J
Note that the subscripts have been dropped from the A- and B-terms for simplicity.
The coding symbols used are as follows:
X = DIM, S = sin-1 C = tan-1 ( . C—), P = -tt - tan-1 (A/B),
Wi - C2/
C = 2X - 1, G = 201og10—.
N406 Nonlinear Feedback Control-system Design 8.11
Fig. 8.32 (b) Logic flow diagram for determination of G(ja>).
Figure 8.32(a) illustrates the logic flow diagram for developing the program for
computing — 1/iV. Table 8.1 illustrates the actual program for computing — 1/7V.
The reader should compare these two in order fully to understand the digital com￾puter’s program. Table 8.2 illustrates the computer run for calculating — l/N.
Notice that it was necessary to compute additional values of 0.9 < D/M < 0.99 at
the end of the computer run since it was found that a limit cycle existed in this region.
Figure 8.32(b) illustrates the logic flow diagram for determining G(joS). In the coding,
G represents the gain of G(yco), P represents its phase and W represents a>. Table 8.3 
illustrates the actual program for computing G(jco) and Table 8.4 illustrates the
computer run for calculating G(jw).
The values for — 1/N and G(Ja>) are illustrated on the gain-phase diagram in Fig.
8.33. It indicates limit cycles at co = 1.36, D/M = 0.41 (stable) and co = 0.27,
DIM = 0.945 (unstable). As illustrated previously in Section 8.10, this nonlinear
system can be compensated by lowering the gain, adding a phase-lead network
or rate feedback. A similar analysis indicates that at K = 1.65, a lead network
given by
G(jco) =
1 4- 1.2yco
1 + 0.4/co8.11 Digital Computer Computation of the Describing Function 407
Table 8.1 Computer program for computing — \/N (BASIC program).
1 REM DESCRIBING FUNCTION FOR BACKLASH
10 PRINT "D/M", "GAIN(DB)", "PHASE(DEGREES)", "N"
20 READ X1,X2,D
30 FOR X =X1 TO X2 STEP D
40 LETC=2 *X —1
50 LET S=ATN(C/SQR(1 —C|2))
60 LET A =1.27324 *X(X —1)
70 LET B=O.31831 *(1. 570796—S—C*OS(S))
80 LET N =SQR(Af2+BT2)
90 LET G=20 *0.43429448 LOG(1/N)
100 LET P= —180—57.29578 *ATN(A/B)
110 PRINT X,G,P,N
120 NEXT X
130 DATA 0.05, 0.95, 0.05
140 END
RUN408 Nonlinear Feedback Control-system Design 8.11
Table 8.2 Results of computer analysis for —1/N
Balash
D/M Gain(DB)(-l/A) Phase(Degrees) N
0.05 0.147435 -176.473 0.983169
0.1 0.401232 -173.107 0.954857
0.15 0.720751 -169.841 0.92037
0.2 1.0957 -166.638 0.881485
0.25 1.52297 -163.472 0.839173
0.3 2.00298 -160.322 0.794056
0.35 2.53864 -157.17 0.746565
0.4 3.13505 -153.998 0.697024
0.45 3.79968 -150.787 0.645678
0.5 4.54295 -147.518 0.592724
0.55 5.37919 -144.17 0.53832
0.6 6.32826 -140.714 0.4826
0.65 7.41848 -137.119 0.425673
0.7 8.69166 -133.34 0.367635
0.75 10.213 -129.314 0.308567
0.8 12.092 -124.95 0.248541
0.85 14.5345 -120.088 0.187619
0.9 18.0025 -114.426 0.125856
0.95 23.9717 -107.175 6.33018 E-2
Time: 1 Secs
KEY •
READY.
130 DATA 0.9, 0.99, 0.01 (Modification to Address 130 of Computer Program shown in 
Table 8.1)
RUN
Balash
D/M Gain(DB)( — 1/2V) Phase(Degrees) N
0.9 18.0025 -114.426 0.125856
0.91 18.9072 -113.146 0.113407
0.92 19.9199 -111.798 0.100927
0.93 21.0694 -110.367 8.84157 E-2
0.94 22.3982 -108.836 7.58739 E-2
0.95 23.9717 -107.175 6.33018 E-2
0.96 25.8999 -105.345 5.06999 E-2
0.97 28.3887 -103.275 3.80685 E-2
0.98 31.9007 -100.827 2.54078 E-2
0.99 37.9115 -97.6472 1.27182 E-2
Time: 1 Secs8.11 Digital Computer Computation of the Describing Function 409
Table 83 Computer program for computing G(jco) (BASIC program).
RESPG
10 PRINT "OMEGA”, "GAIN(DB)", "PHASE(DEG)”
20 READK
30 READW1.W2, D
40 FOR W =W1 TO W2 STEP D
50 LET G = 4.3429448 *LOG(K K(1 +9*W)/(W (1 +4*W)f2))
60 LET P= -90 + 57.29578 *(ATN(3 W)-2 ATN(2 W))
70 PRINT W, G, P
80 NEXTW
90 DATA 4, 0.1, 2.0, 0.05
200 END
r.- G{ju> ~ Ju(l + 2ju)l
N = backlash
Fig. 8.33 Describing-function analysis based on computer results.410 Nonlinear Feedback Control-system Design 8.11
Table 8.4 Results of computer analysis for G(j<o)
RESPG
Omega Gain(DB) Phase(Deg)
0.1 32.0748 -95.9206
0.15 28.5717 -99.1707
0.2 26.0668 -102.639
0.25 24.0824 -106.26
0.3 22.4048 -109.94
0.35 20.9235 -113.587
0.4 19.577 -117.125
0.45 18.3297 -120.503
0.5 17.16 -123.69
0.55 16.0544 -126.671
0.6 15.004 -129.443
0.65 14.0026 -132.012
0.7 13.0454 -134.388
0.75 12.1288 -136.582
0.8 11.2499 -138.609
0.85 10.4059 -140.482
0.9 9.59458 -142.214
0.95 8.81385 -143.818
1. 8.0618 -145.305
1.05 7.33669 -146.686
1.1 6.63691 -147.97
1.15 5.96097 -149.167
1.2 5.3075 -150.284
1.25 4.67521 -151.329
1.3 4.06293 -152.306
1.35 3.46955 -153.223
1.4 2.89405 -154.085
1.45 2.33549 -154.895
1.5 1.79296 -155.659
1.55 1.26566 -156.379
1.6 0.752819 -157.06
1.65 0.253712 -157.704
1.7 -0.232325 -158.315
1.75 -0.705916 -158.894
1.8 -1.16765 . -159.443
1.85 -1.61806 -159.966
1.9 -2.05767 -160.464
1.95 -2.48695 -160.938
2. -2.90636 -161.39
Time: 2 Secs.8.12 Piecewise-linear Approximations 411
and rate feedback having a constant of 0.47 result in a 3 db margin of safety. The
system compensated with a lead network and rate feedback is illustrated in Fig. 8.33.
8.12 PIECEWISE-LINEAR APPROXIMATIONS
Approximating any nonlinearity by means of piecewise-linear segmentation is a very
useful tool for analysis. Each segment leads to a relatively simple linear differential
equation which can be solved by conventional linear techniques. This method, which
is not limited to quasilinear systems, has the advantage of yielding an exact solution
for nonlinearities of any order, if the nonlinearity is itself piecewise linear or can be
approximated by piecewise-linear segments. We illustrate its application by means of
an example.
Let us consider saturation. Figure 8.34 illustrates a simple feedback control
system containing an integrator and an amplifier which saturates. The amplifier
gain is 5 over an input voltage range of ± 1 volt. For input voltages greater than this,
the amplifier saturates. It is quite evident that two distinct linear operating regions for
the amplifier exist. Each of these linear regions can be considered separately in a
piecewise-linear manner in order to obtain the composite response of the system.
For the unsaturated region, the relationships depicting the system operation are
e(t) = r(t) - c(t),
/(0 =
c(j) = f/(0 dt.
(8.79)
(8.80)
(8.81)412 Nonlinear Feedback Control-system Design 8.12
During saturation, Eqs. (8.79) and (8.81) are still valid. However, (8.80) changes
to
f(t) = 5 for e(t) > 1 (8.82)
f(t) = —5 for e(t) < — 1. (8.83)
Assuming zero initial conditions and a step input of 10 V, the expression for the
output during the saturated region of operation c8at(l) is given by
csat(0= fsrfr = 5/. (8.84)
Jo
The expression for the output during the unsaturated region is given by
cU8(0 = 5 f (10 - c) dt, or ^-s4-5c = 50. (8.85)
Jti dt
The time lx is the time at which the amplifier becomes unsaturated. When c = 9,
e — 1, and tl is 1.8 sec. Using conventional techniques, the solution to Eq. (8.85) is
cu8(t) = 10 - e-5*'- 18>. (8.86)
The initial value for this region, cU8(0), is the same as the final value of the saturated
region, cgat(1.8) = 9; this continuity of the output is imposed by the integrator.
Therefore, the composite solution for this problem, obtained by a piecewise-linear
analysis, is
csat(l) = 51 for 0 < 1 < 1.8, (8.87)
cU8(l) = 10 - e-5«-i-s) for t > 1.8. (8.88)
The response of this system to a step input of 10 V is sketched in Fig. 8.35.
The piecewise-linear approach illustrated in the preceding problem can be
extended to very complex nonlinearities. It is important to emphasize that the
boundary conditions between linear regions are continuous whenever the transfer
Fig. 8.35 Step response of saturating system obtained from piecewise-linear analysis.8.13 State-Space Analysis: The Phase Plane 413
function following the nonlinearity is a proper rational function. The resulting
differential equation for each segmented region is linear and can be easily solved by
conventional linear techniques.
8.13 STATE-SPACE ANALYSIS: THE PHASE PLANE
A useful technique of applying the state-space approach to nonlinear systems is the
phase-plane method [7,17-19], It is a technique for analyzing the transient response of
a nonlinear feedback control system to a step input or for solving an initial-condition
problem. The phase-plane method is limited to second-order systems. The variation
of the displacement is plotted against velocity on a graph known as the phase plane.
A curve for a specific step input is known as a trajectory. A set of curves of displace￾ment versus velocity ofa specific system, which are repeated forseveral step amplitudes
and are plotted on the same phase plane, is called a phase portrait.
The starting point of a trajectory is the initial displacement, x(0), and velocity,
(dx[dt)(O). The future path of the trajectory after it leaves its initial starting point
represents the behavior ofthe system for some step-input excitation. Ifthe trajectory
approaches infinity on the phase plane, the system is unstable. If the phase trajec￾tory approaches the vicinity of the origin, however, the system is stable. If the tra￾jectory circles the origin continuously in a closed curve after excitation, a sustained
oscillation known as a limit cycle exists.
The phase-plane method is specifically concerned with the solution of second￾order, nonlinear differential equations having the following general form:
d2x , . / dx\ dx . / dx\ _ (Q — + Adx,-I — + As x,— x = 0. (8.89)
dt2 \ dt / dt \ dt/
The initial conditions, x(0) and (dx/dt)(O), represents the input to the system. Equa￾tion (8.89) immediately emphasizes some serious limitations of the phase-plane
method. It is only useful for analyzing second-order systems. Since the right-hand
side of Eq. (8.89) is zero, the analysis is further limited to initial value problems, or
to step inputs where appropriate transformations can be made to produce a zero
right-hand side. It is interesting to compare the limitations ofthe phase-plane method
with those ofthe describing-function analysis, where the response to sinusoidal inputs
of systems having any order could be determined. The phase-plane method could be
extended to higher-order systems, but it is too impractical. *
The following section discusses the techniques which can be used for constructing
the phase portrait from the differential equation of a system. Then we examine the
* A system described by an nth-order differential equation requires an n-dimensional phase
space with a knowledge of n initial conditions. It is, indeed, an arduous task to visualize this
for third- and higher-order systems, and is rarely used.414 Nonlinear Feedback Control-system Design 8.14
properties and interpretation of the phase portrait. The procedure to be followed for
applying the phase-plane approach to some representative design problems is then
presented.
8.14 CONSTRUCTION OF THE PHASE PORTRAIT
Three procedures that can be used to construct the phase portrait of a system are
1. direct solution of the differential equation,
2. transformation of the second-order differential equation to a first-order equation,
3. the method of isoclines.
The first two methods are analytical techniques; the last is graphical. We shall
describe these methods next, together with some simple illustrative examples.
1. Direct Solution of The Differential Equation This is the most straightforward
method for obtaining the phase portrait. It is usually the most useless method from
a practical viewpoint since we do not have to resort to the phase-plane representation
for a solution ifthe differential equation is integrable. However, this method does give
a physical “feel” for the situation.
The procedure is to solve the differential equation for the dependent variable x.
The solution for x is then differentiated in order to obtain the derivative of the
dependent variable, dxjdt. The independent variable, time, is then eliminated between
the two resulting equations. A single equation that relates x and dx/dt results, and
can be used to plot the phase portrait directly. However, the approach has the
disadvantage that it requires the solution of a nonlinear, second-order, differential
equation.
Let us illustrate the procedure in detail by first considering the simple linear
system illustrated in Fig. 3.7. That configuration illustrated a system where a torque
T(t) was applied to a body having a moment of inertia J, a twisting shaft having a
stiffness factor K, and a damper having a damping factor B. Applying Newton’s
second law of motion to this system resulted in the following relationship:
r d20(O d0(O
J + B + K0(t) = T(t), (8.90) dr dt
where 0(0 is the displacement. The differential equation is second order, and the
phase-plane method is certainly applicable. Assuming that the system is unexcited,
the resulting differential equation is given by
d20(Q , Bd0(Q 0(t)
J 9 r 1 *" (8.91)8.14 Construction of the Phase Portrait 415
Equation (8.91) can be written in terms of damping factor £ and natural frequency
co„, as follows.
+ = (8,2)
at at
where
B/J = 2^n,
KIJ =
Before sketching the phase portrait, let us consider the simpler case of an un￾damped system where £ = 0. For this situation, Eq. (8.92) reduces to
+ W2„0(t) = 0. (8.93)
dt'
From elementary calculus, the solution to Eq. (8.93) is that of simple harmonic
motion:
9(t) = R sin (a>nt + </>). (8.94)
In order to obtain a relationship between 6(f) and dO(f)/dt, we differentiate Eq. (8.94)
and then eliminate time between the resulting equations, as follows:
= Rojn cos (<y„t + <£). (8.95)
dt
Eliminating time between Eqs. (8.94) and (8.95), we obtain the expression
F— W+ [0(0]2 = R2. (8.96)
Lw,, dt J
The phase portrait for this system can be drawn directly from Eq. (8.96). Observe
that Eq. (8.96) describes a family of concentric circles in the (\la)n)(d6(f)/df) versus
0(f) plane having a radius of R. Therefore, the phase portrait for this system (shown
in Fig. 8.36) is a family of concentric circles if a normalized ordinate axis is used. If
the ordinate axis is not normalized, a family of ellipses results. Any set of initial
conditions, such as points Rly R2, R3, and Rt, specifies a particular circle. For
t > 0, the motion is in the indicated direction.
Let us next sketch the phase portrait for the case where the damping factor ofthis
system is finite. The general solution for Eq. (8.92), when it is excited by a step input
and has a set of initial conditions, was derived in Chapter 4 (see Eq. 4.45). The form
of the solution for this system when it is unexcited by a step input and only has a set
of initial conditions, 0(/o) and 6(t0), present is given by
2 ________
6(t) = , [coJI - £2(t - /») +
V1 -e
+ sin [roJl - ? (t ~ ^(Q. (8.97)
V1 -£2416 Nonlinear Feedback Control-system Design 8.14
Fig. 8.36 Phase portrait for a second-order linear system having no damping.
Proceeding as in the previous example, the derivative of Eq. (8.97) is obtained:
6(t) = ^-^'-‘-’cos [rojl - c2 (t - t0) + ^]0(1O)
- -M= e-^'-^sin [WnVl - £2(t - U + &M'o)
V1 -r
+ cos [<o„Vl - f(t - to)]0(to)
_ faL e-^-^ sin (/ _ /o)]^o) (8 98)
Vi -
The complexity of Eqs. (8.97) and (8.98) makes it quite difficult to eliminate time
between them. Therefore we use an alternative approach. Equations (8.97) and
(8.98) will be evaluated for several values of time to obtain the corresponding co￾ordinates in a normalized phase plane The result is plotted in Fig. 8.37 for a damping
factor of 0.7. Notice that the phase portrait is a collection of noncrossing paths
describing system behavior for all possible initial conditions. Since all the trajectories
approach the origin, the system is stable as we would expect it to be.
The projection of a specific trajectory onto the abscissa gives the variation of
6(t) with time, and its projection onto the ordinate gives the variation of dO(t)ldt
with time. Time appears in the portrait implicitly as a parameter along all phase
trajectories. We discuss its computation later in the chapter.8.14 Construction of the Phase Portrait 417
Fig. 8.37 Phase portrait of a stable node.
Let us next illustrate the application ofthis method to a relatively simple nonlinear
differential equation. We consider the problem of nonlinear friction which was
discussed previously in Section 8.8. We first determine the phase portrait for coulomb
friction and then extend it to the case of stiction. Consider a system containing
coulomb friction ±FC, the moment of inertia of the system being J and the spring
constant K. The differential equation of the motion of the system is given by
Defining
J~+ Kc(t) ± Fc = 0.
at~
(o = (K/J)1/2,
_ (c — y when c < 0,
~ lc + V when c > 0.
the normalized equation of motion is
a + co2oc = 0-
(8.99)
(8.100)
(8.101)
(8.102)
(8.103)
The phase portrait for Eq. (8.103) in the a versus a plane is the same as that for
the linear, second-order system considered previously (see Fig. 8.36). However, in
the c/ro versus c plane, the phase portrait for Eq. (8.103) is quite different, and can be
obtained by considering Eq. (8.103) in two parts: one for the upper half-plane where
c/m > 0, and the other for the lower half-plane where c/w < 0. A little thought418 Nonlinear Feedback Control-system Design 8.14
shows that the phase portrait in the upper half-plane is a family of semicircles,
centered about c = —y, since c is related to a merely by a simple translation. In a
similar manner, the phase portrait for the lower half-plane is a family of semicircles
centered about c = y. Figure 8.38 illustrates the phase portrait.
Fig. 8.38 Phase portrait for a system containing coulomb friction.
It is interesting to observe from Fig. 8.38 that as soon as the displacement has a
value within the interval on the c(l)-axis given by
—y < c < y, (8.104)
all motion stops. This gives rise to the possibility of large, steady-state errors. For
example, if the initial conditions are at point 1, the trajectory will be 1 —2—3—4 and the
system will not have any steady-state error. If the initial conditions are at point 5,
however, the trajectory followed will be 5-6-7-8 and the system will have a steady￾state error equal to y.
We have already seen that dither is useful for eliminating the steady-state error
due to coulomb friction. Its effect on the steady-state error can easily be understood
by studying the phase plane. For example, let us assume that a finite steady-state
error exists corresponding to point 9 on Fig. 8.38. With dither, the effect of a negative
disturbance, segment 9-10, results in the system returning to point 11 on the c(t)-axis,
while a positive disturbance, segment 9—12, results in the system returning to point
13 on the c(t)-axis. Since the projection 11-9 is greater than the projection 9-13, the
system will tend to move towards the origin.8.14 Construction of the Phase Portrait 419
Before leaving this system, let us consider the required modification to the phase
portrait in Fig. 8.38 for stiction. Since stiction occurs only for zero velocity and is
greater than coulomb friction, its effect is to extend the termination line: to ±ys.
These extended terminations are illustrated in Fig. 8.38.
2. Transformation of the Second-Order Differential Equation to a First-Order Equation
Ifthe differential equation ofthe system cannot be easily integrated, a new differential
equation in terms ofthe phase variables may be formed, from which the phase portrait
can be obtained directly. This method can best be illustrated by considering the linear,
second-order, undamped system discussed previously, namely,
+ co20(O = 0. (8.105)
at
Using the dot notation, we have
6 + a, 29 = o. (8.106)
Defining the state variables as
xx = 0, (8.107)
x2 = 6, (8.108)
we have
xL = x2, (8.109)
x2 = (8.110)
Dividing Eq. (8.110) by Eq. (8.109), the following is obtained:
dx2 conXi 111)
dxj x2
Equation (8.111) can be rewritten as
x2 dx2 + cu^Xi dXi = 0.
Integrating, /e obtain
x2 + a>£x? = C,
where C is an arbitrary constant easily determined from the initial conditions. Solving
for x2, we obtain
x2 = ±VC — co2x?.
In terms of the phase variable, this equation can be written as
0(0 = ±VC - cu202(O (8.112)
The result of sketching various phase trajectories from Eq. (8.112) will be the phase
portrait illustrated in Fig. 8.36, where a normalized ordinate axis is used. The initial
conditions determine the particular trajectory followed.
This technique can be easily extended to the systems whose phase portraits are
illustrated in Figs. 8.37 and 8.38. This method is by far the most useful analytic
technique for obtaining the phase portrait of a system.420 Nonlinear Feedback Control-system Design 8.14
3. Method of Isoclines The method of isoclines is a graphical procedure for deter￾mining the phase portrait. It can be used even if the differential equation cannot be
solved analytically. In practice, it is a very powerful method to use.
Isoclines are lines in the phase plane corresponding to constant slopes of the
phase portrait. One starts with the differential equation in the form shown by Eq.
(8.111). Here, dxjdxi, or dO/dO, corresponds to the slope ofthe trajectories that form
the phase portrait. Numerical values are assigned for the slopes dO/dd, and Eq.
(8.111) is used to find the corresponding points in the phase plane having those slopes.
Once a set of isoclines is drawn, a trajectory may be drawn by starting at some point
on an isocline and then proceeding to the next isocline along a straight line whose
slope is the average of the slopes corresponding to the two isoclines. Since the pro￾cedure is a numerical approximation, closer spacing of the isoclines increases the
accuracy of the resulting trajectory.
Let us illustrate the application ofthe isocline method to the linear, second-order,
undamped and damped systems whose portraits are given in Figs. 8.36 and 8.37,
respectively. For the undamped case, the family of isoclines can be drawn from Eq.
(8.111). However, in order to plot the phase portrait on a normalized plane
[(l/<y„)0(t) versus 0(01, let
6(t) = 0(O/w„. (8.113)
So we have
d&(t) _ 6(t)
dO(t) 6(0 (8.114)
where m represents the slope of the trajectory.
Isoclines associated with slopes corresponding to Eq. (8.114) constitute a family
of straight lines passing through the origin and are illustrated in Fig. 8.39. Also
shown is the construction ofthe phase trajectory starting with a point that lies on the
isocline corresponding to a slope of —1.5. The motion of the trajectory drawn from
point A on the —1.5 isocline, to the isocline whose slope is —2, has a slope in the
phase plane that is the average of these two isoclines, or —1.75. This is indicated on
Fig. 8.39 as line segment AB. In addition, the following line segment, BC, whose
slope is —2.5, is illustrated. The complete trajectory is shown dotted. It is obvious
from this simple example that the accuracy of the isocline method depends on the
number of isoclines drawn.
Let us next construct the phase portrait for the linear, second-order, damped
system considered previously. From Eq. (8.92), the differential equation ofthe system
is
®+ co2„6(t) = 0. (8.115)
Setting £ = 0.5 and using the dot notation, we have
0 + co„0 + <o20 = 0. (8.116)8.14 Construction of the Phase Portrait 421
Fig. 8.39 Construction of a phase trajectory for a linear, second-order, undamped system
using the method of isoclines.
Defining the state variables as
Xi =0,(8.117)
x2 = 0, (8.118)
then we have
= x2, (8.119)
x2 = —w^Xi — co„x2. (8.120)
Dividing Eq. (8.120) by Eq. (8.119), we obtain the following:
(8.121)
axj x2
Defining a normalized state variable
x3 = = 6(0,
0)„
we can write Eq. (8.121) as follows:
dx3 _ t Xj
dXj x3
or
d&(t) _ 0(0
dO(t) 6(0 ’422 Nonlinear Feedback Control-system Design 8.14
From this equation, the slope of the trajectories in the 0(t) versus 0(t) plane is given
by
trajectory slope = — 1 — (8.122)
Isoclines associated with slopes corresponding to Eq. (8.122) constitute a family of
straight lines passing through the origin in the phase plane. This is illustrated in Fig.
8.40. The construction ofthe trajectory starting with a point which lies on the isocline
corresponding to a slope of 2 is illustrated. The segment ofthe trajectory drawn from
point A on the isocline whose slope is 2 to that whose slope is 1 would be a straight
line whose slope is the average of 2 and 1, or 1.5. This is indicated in Fig. 8.40 as line
segment AB. In addition, the following line segment SC, whose slope is 0.5, is
illustrated. The remaining trajectory is shown dashed. As for the undamped system,
the accuracy depends greatly on the number of isoclines drawn.
Fig. 8.40 Construction of a phase trajectory for a linear, second-order, damped system using
the method of isoclines.
Before leaving this discussion, it should be mentioned that there are several other
methods available for obtaining a phase portrait. Most notable ofthese other methods
are the method of tangents and Lienard’s construction. The former technique is very
similar to the method of isoclines. It consists of deriving the tangent to a trajectory
at many points in the phase plane. The phase trajectory is then drawn tangent to8.15 Characteristics of the Phase Portrait 423
these lines. This technique is usually a little more tedious than the method of iso￾clines. The reader should consult Ref. 17 for a further discussion of the method of
tangents. The latter technique, Lienard’s construction, is useful if the second-order
differential equation has the following special form:
^4) + Kx = 0 (8.123)
where f(dxjdt) represents nonlinear damping. The reader should consult Ref. 18
for a further discussion of this specialized construction.
8.15 CHARACTERISTICS OF THE PHASE PORTRAIT
Several properties of the phase portrait need to be singled out; their correct interpre￾tation is important for the intelligent analysis of feedback control systems. We begin
by defining and illustrating the notion of singular points. Then we illustrate limit
cycles and follow this by showing how to determine time from the phase portrait. The
section concludes with examples of several interesting and representative phase
portraits.
d12x
1. Singular Points Singular points are points of the phase plane where the system is
in a state of equilibrium. At these points both velocity and acceleration of the system
are zero. The origin is the only singular point in the phase portrait of the linear
system illustrated in Fig. 8.37.
Consider the general second-order, nonlinear differential equation (8.89)
dt2
dx
’ dt. t + a-‘ dt
x = 0.
If this equation is written in the state-space form, the singular points are defined as
the points that make the quantities in Eqs. (8.124) and (8.125) equal to zero:
— = P(x, y), (8.124)
dt
— — Q(x, y). (8.125)
dt
Here x and y are the state variables. The characteristics of singular points may vary
greatly depending on the variations of the coefficients of the first-order differential
equations given by Eqs. (8.124) and (8.125). The type ofsingular point may be found
by means of a Taylor-series expansion of Eqs. (8.124) and (8.125) in the vicinity ofthe
singular point. Assuming that the singularity occurs at x = A and y = B, the result424 Nonlinear Feedback Control-system Design 8.15
of expanding P(x, y) and Q(x, y) about these points is
= A(x - A) + A2(y -B) + A2(x - A)3
dt
+ At(x - A)(y - B) + A,(y - B)2 + • ■ • . (8.126)
= Bt(x - A) + B2(y — B) + B3(x - A)3
dt
+ B4(x - A)(y - B) + B5(y - B)2 + • • • . (8.127)
We assume that the character of the singular points is determined entirely by the
coefficients of the linear terms only: Au A2, Blt and B2. This is certainly reasonable
if a sufficiently small region is chosen in the vicinity of the singularity. What we have
done is to characterize the system by its linear part in the vicinity ofthe singular point.
Therefore, Eqs. (8.126) and (8.127) reduce to
V = A(x - A) + /i2(y - B), (8.128)
dt
~ = Bx(x - A) + B2(y - B). (8.129)
dt
We further simplify the problem by assuming that the singularity occurs at the origin.
Therefore A and B are both zero. Equations (8.128) and (8.129) reduce to the form
Y = Axx + A2y,
dt
dy
— = Bjx + B2y.
(8.130)
(8.131)
We have not lost any generality in using this assumption, since the same result can
always be obtained merely by changing the variables as follows:
x — A = p, y — B — q. (8.132)
The characteristics of the singular point can be determined by eliminating one of the
two variables of Eqs. (8.130) and (8.131) and studying the resulting characteristic
equation. The result is
X(s) = --------------------------------------------- ,
s2 -(A + B2)s + (AB2 -J2Bx)
and the characteristic equation is given by
s2 - (Ar + B2)s + (ArB2 - A2BJ = 0.
(s - B2)x(0) + A2y(0)
(8.133)
(8.134)
Assuming real coefficients, six different characteristic sets of roots of Eq. (8.134) are
possible. These sets of roots result in singular points which can be classified as be￾longing to one of four types.8.15 Characteristics of the Phase Portrait 425
Fig. 8.41 Phase portrait of an unstable node.
a) Node A node is a point in the phase plane consisting of a family of trajectories
which directly converge and approach it (stable node) or radiate from it (unstable
node). A stable node occurs when the roots are both real and both in the left half
of the 5-plane. An unstable node occurs when the roots are both real and both lie
in the right half of the s-plane Figure 8.37 illustrates a stable node and Fig. 8.41
an unstable node.
Fig. 8.42 Phase portrait of a stable focus.426 Nonlinear Feedback Control-system Design 8.15
b) Focus. A focus is a point in the phase plane consisting of a family of spiral
trajectories which either converge on the point (stable focus) or diverge from it
(unstable focus). A stable focus occurs when the roots are complex conjugate and lie
in the left half of the s-plane. An unstable focus occurs when the roots are complex
conjugate and lie in the right half-plane. The origin of the phase portrait in Fig.
8.42 is a stable focus. Figure 8.43 illustrates an unstable focus.
Fig. 8.43 Phase portrait of an unstable focus.
c) Center. A center is a point in the phase plane consisting of a family of closed
curves encircling it. This occurs when the roots are complex conjugate and lie on the
joj-axis. The origin of the phase portrait in Fig. 8.36 is a center.
d) Saddle point. A saddle point is a point in the phase plane that is characterized by
the phase portrait illustrated in Fig. 8.44. This occurs when the roots are real, with
one in the right half-plane and the other in the left half-plane. Except for the case
where the numerator of Eq. (8.133) contains a zero which exactly cancels the zero of
the denominator lying in the right half-plane, this type ofsingularity always represents
an unstable situation.
2. Limit Cycles Limit cycles are defined as isolated closed paths of the phase portrait.
The location and determination of the type of limit cycle, together with the singular
points which exist in the phase plane, offer a complete description of the behavior of
a nonlinear second-order system.
A limit cycle can be stable or unstable, depending on whether the paths in the
neighborhood ofthe limit cycle converge toward it or diverge away from it. They can
result from either soft or hard self-excitation. These situations can be portrayed on
the phase plane. Figure 8.45 illustrates a system with a soft self-excitation. Physically,
this phase portrait may represent a system which has excessive gain for small signals8.15 Characteristics of the Phase Portrait 427
Fig. 8.44 Phase portrait of a saddle point.
and the output builds up in an unstable manner. With large signals the output also
approaches the stable limit cycle from the outside as shown in Fig. 8.45. A stable
limit cycle exists between these two conditions and a sustained oscillation occurs.
Figure 8.46 illustrates a system where a hard self-excitation exists. The generation of
an oscillation depends on the initial conditions. For example, let us assume that the
Fig. 8.45 Phase portrait of soft self-excitation.428 Nonlinear Feedback Control-system Design 8.15
Fig. 8.46 Phase portrait of hard self-excitation.
initial state is at the stable focus. For hard self-excitation to occur, a very large
disturbance is required to change the state of the system to a region outside the
unstable limit cycle. If this disturbance is sufficient for the operating point of the
system to reach the stable limit cycle, a steady oscillation occurs.
3. Determination of Time from the Phase Plane Although we cannot solve for x
and dx/dt as functions of time directly, it is possible to obtain time from the phase
portrait. The variation of time can be easily found from the equation
y = dx/dt. (8.135)
Solving for t, we obtain the relationship
1
t= - dx. (8.136)
Ja y
Equation (8.136) shows that if the phase portrait is replotted with 1/y or (dx/dt)-1 as
the ordinate and x as the abscissa, the area under the resulting curve represents time.
This area can be evaluated with a planimeter or by approximation using a series of
rectangles. Let us use the phase trajectory labeled ABCDEF on the phase portrait
of Fig. 8.42 to illustrate the determination of time. We assume that <o„ = 1. Our
first problem is to determine the time it takes for the motion to go from A to C.
Figure 8.47 represents a plot of [dG(t)/dt]-1 versus 6(t) for the interval ABC. Using a
series of rectangles for area summation, we find that the time is approximately equal
to 1.12 sec. If we attempt to find the time it takes for the trajectory to pass from C to
E, we run into a problem since dd(t)/dt equals zero at point D and the reciprocal8.15 Characteristics of the Phase Portrait 429
Fig. 8.48 Approximating time from a reciprocal phase-plane plot when velocity passes
through zero.430 Nonlinear Feedback Control-system Design 8.15
phase-plane plot goes to infinity. This certainly is not the true situation, and we must
resort to an approximation in the vicinity of point D. The most practical approxi￾mation is to find the time it takes to go from point C to a small finite distance on the
phase trajectory before point D, £>(—), and then the time it takes to go from a small
finite distance past point D, Z>(+), to point E. This technique is illustrated in Fig.
8.48. Using the rectangular area summation technique, we find that it takes approxi￾mately 2.18 sec to go from point C to point E. Therefore, the total time it takes to
traverse the segment ABODE is approximately 3.3 sec.
Ordinarily, the reciprocal phase-plane plot is sufficient for obtaining time. For
academic completeness, several other methods also exist for obtaining time from the
phase plane. References 7 and 18 deal with these approaches thoroughly.
4. Representative Phase Portraits In order to develop a greater facility for intel￾ligently interpreting phase portraits, we next present additional representative phase
portraits. These, with the portraits already discussed, should provide a good facility
for interpreting phase portraits. Specifically, we consider the phase portraits of
undamped, second-order control systems that have the nonlinear characteristics of
rate and position limiting. We compare the results with the portrait illustrated in
Fig. 8.39.
a) Rate Limiting of an Undamped, Second-Order System. Consider the linear,
undamped, second-order system whose phase trajectory was illustrated in Fig. 8.39,
We shall change this linear system to a nonlinear one by adding a governor to the
servomotor driving the load so that the maximum rate is limited. The resulting phase
portrait is illustrated in Fig. 8.49. If the initial conditions are such that the resulting
phase trajectory lies anywhere within the dashed trajectory, the system will oscillate
as the undamped linear system did, as shown in Fig. 8.39. However, if the initial
Fig. 8.49 Phase portrait of a second-order, undamped system having rate limiting.8.16 Design of Nonlinear Feedback Control Systems Using the Phase-plane Method 4.31
conditions are such that they lie outside the dashed trajectory, the output rate is
limited to the maximum value allowed by the governor, as shown in Fig. 8.49 by the
dashed trajectory. Thereafter the system will oscillate indefinitely following the dashed
trajectory.
b) Position Limiting ofan Undamped, Second-Order System. Next consider the linear,
undamped, second-order system that is made nonlinear by adding limit stops to the
output shaft, so that the maximum and minimum positions are limited. The resulting
phase portrait is given in Fig. 8.50. The interpretation of this phase portrait is analo￾gous to that of Fig. 8.49, except that it is shifted by 90°.
Fig. 8.50 Phase portrait of a second-order, undamped system having position limiting.
8.16 DESIGN OF NONLINEAR FEEDBACK
CONTROL SYSTEMS USING THE PHASE-PLANE METHOD
This section illustrates the design of a nonlinear feedback control system using the
phase-plane method [19]. We use the analytic tools developed in Sections 8.13 to
8.15 to demonstrate the procedure to follow when designing a nonlinear system.
Specifically, we consider an on-off control system. The primary function of this
example is to use the transient response of the system as a guide for choosing the
parameters. One of our main objectives will be to determine the existence of limit
cycles as the parameters are varied. We will not, however, be able to obtain the margin
of stability for the system from the phase plane. The following analysis should be
compared with that obtained from the describing function in Section 8.10.432 Nonlinear Feedback Control-system Design 8.16
Fig. 8.51 On-off control system having variable position and velocity feedback.
Let us consider the on-off control system illustrated in Fig. 8.51. It has a two￾position contactor which applies a corrective signal having the proper phase for control
action. The problem is to determine a good polarity combination of the variable
position-feedback constant, a, and the variable velocity feedback constant, b, for
acceptable transient performance. We assume that the input r is zero and that the
forcing function generated by the contactor is unity; therefore the general form of
the differential equation for this system is given by
y^ + 2£wn y + <onc = sgn (ac + b y), (8.137)
at at \ at/
where 0 < £ < 1. The sign of the unit forcing function is given by the sign of
ac + b(dcldt). Assuming that £ = 0.5 and cun = 1, the equation reduces to
d2c , de , ~2 + y + c = sgn
dt2 dt
. k dC\
ac + b — 1.
dt/
(8.138)
Specifically, we shall determine the transient response of this system for the following
polarity combinations of a and b‘.
(A) a > 0, b > 0,
(B) a > 0, b < 0,
(C) a < 0, b > 0,
(D) a < 0, b < 0.
(8.139)8.16 Design of Nonlinear Feedback Control Systems Using the Phase-plane Method 433
In general the phase portrait for any of these cases may be obtained in a similar
manner. We draw heavily on the results of our studies of singular points in drawing
the various phase portraits. The basic relation analyzed in our discussion of singular
points was Eq. (8.89):
~ + ^2(c, = 0. (8.140)
dt \ dt] dt \ dtj
If we are considering an underdamped, linear second-order system, we know that the
differential equation (8.92) results in a phase portrait similar to that in Fig. 8.37, where
the origin acts as a stable node. In the case of an on-offsystem, however, we find that
it is represented by a differential equation which is given by Eq. (8.138). The right￾hand side ofthis equation can be thought of as either a unit positive or negative forcing
function. The phase portrait of a system having a unit positive forcing function will
have spirals that converge towards a stable focus at c = 1, dcjdt = 0. The phase
portrait of a system having a unit negative forcing function will have spirals that
converge towards a stable focus at c = —1, dc/dt = 0. The on-off system we are
considering actually has two stable foci because of the action of the two-position
contactor. A switching line, defined by
de
ac + b— = 0 (8.141)
dt
separates the regions where the phase trajectory spirals towards c = 1, dejdt — 0 or
c = — 1, defdt = 0. Using this general approach, which is valid for all four cases,
the transient response can be readily determined.
Case A. a > 0, b > 0. The switching line is a straight line given by the following
relationship:
— = - - c. (8.142)
dt b
It passes through the origin and lies in the second and fourth quadrants. The sign of
ac + b(dcldt) is positive in the region to the right of it and negative to the left of it.
The phase portrait for this system, which is given in Fig. 8.52, can be constructed
using the method ofisoclines or by transforming the second-order differential equation
to a first-order equation. Observe that three trajectories are possible, depending on
the initial conditions. Two represent convergent motion where the phase portrait
terminates on the foci at —1 or 1, depending on the final switching input. The third
possible trajectory represents a limit cycle.
Any initial condition occurring beyond the limit cycle or very close to it in the
enclosed area will eventually result in the trajectory reaching some part of the limit
cycle, ABCDA. For a limit cycle to occur, the distance DE from the switching line
to the corresponding focus must be greater than the distance BE, which represents the
distance from the subsequent crossing of the line to the focus. This must be true with
respect to the other focus as well.
Trajectories that start sufficiently inside the limit cycle will spiral into one of the
foci. However, there is no chance of these trajectories ultimately reaching the origin.434 Nonlinear Feedback Control-system Design 8.16
Fig. 8.52 Phase portrait for an on-off control system where a > 0 and b > 0.
Case B. a > 0, 6 < 0. The switching line is a straight line given by
de a — = - c.
dt b
(8.143)
It passes through the origin and lies in the first and third quadrants. In a manner
similar to the first case, we can show the phase portrait to be as shown in Fig. 8.53.
Observe that any set of initial conditions which results in a trajectory intersecting the
switching line inside the interval AB results in a motion spiraling towards one of
the two stable foci. However, if the intersection occurs outside the interval AB, the
trajectory theoretically ends on the switching line. Figure 8.53 indicates these points
by C and D. Points E and F represent points of tangency with the switching lines for
limiting trajectories. In reality, however, the system cannot just end at these points.
This inconsistency is resolved by the fact that switching action of a contactor always
has a certain time lag due to its dynamics. Therefore, when a solution reaches the
switching line it actually proceeds for some small distance past it, before there is a
change of sign in the forcing function. This results in a zigzag action along the
switching line. Eventually, the trajectory spirals into one of the foci as shown in Fig.
8.53. Physically, this is audible as a “chattering” of the contactor.
Cose C. a < 0, b > 0. The switching line has the same form as that of case B. The
phase portrait is given in Fig. 8.54. For this case a stable limit cycle always prevails.
Regardless of the initial conditions, the final solution always winds up as a stable
limit cycle.8.16 Design of Nonlinear Feedback Control Systems Using the Phase-plane Method 435
Fig. 8.53 Phase portrait for an on-off control system where a > 0, b < 0.
Fig. 8.54 Phase portrait for an on-off control system where a < 0, b > 0.436 Nonlinear Feedback Control-system Design 8.16
Case D. a < Q,b < 0. The switching line has the same form as that of case A. The
phase portrait, given in Fig. 8.55, shows that no periodic solution exists. The solu￾tions tend to end on the switching line. Because of the time lag of the relay, however,
the trajectory zigzags towards the origin of the phase plane. The system finally
oscillates at very high frequency and small amplitude around the origin.
Fig 8.55 Phase portrait for an on-off control system where a < 0, b < 0.
It is interesting to observe that of the four cases considered, the control-system
engineer would prefer the phase portrait of case D, the only configuration which
resulted in a stable equilibrium state occurring around the origin. However, we would
have to tolerate some chattering around the origin with this linear switching system.
To eliminate the chattering, one would have to use nonlinear switching techniques
[19].
An analog computer is very useful for studying the phase portraits of nonlinear
systems as certain parameters are varied. * Figure 8.56 illustrates the analog computer
circuitry required for simulating the system whose block diagram was shown in Fig.
8.51. Switch Sj permits choices of a > 0 or a < 0, and switch S2 permits choices of
b > 0, or b < 0. By connecting the points x and y to the horizontal and vertical
deflection plates of an oscilloscope, respectively, the phase portraits shown in Figs.
8.52 through 8.55 can be obtained as switches and S2- are varied. The reader should
try this useful exercise.
* The reader should consult References 41 and 42 for a discussion of analog computers.8.17 Liapunov’s Stability Criteria 437
Fig. 8.56 Analog computer circuit for simulating system shown in Fig. 8.51.
8.17 LIAPUNOV’S STABILITY CRITERION
A. M. Liapunov [20] developed a fundamental method of determining the stability
of a dynamic system based on generalization of energy considerations. This section
presents the first and second methods of Liapunov and illustrates their application
to nonlinear feedback control systems [21],
A. Liapunov’s First Method Liapunov divided the general problem of analyzing the
stability of nonlinear systems into two classes. The first class consists of all those
methods in which the differential equation of the system can be solved. System
stability or instability is determined from this solution. This approach, which is
known as Liapunov'sfirst method, does not say anything of particular importance
concerning the solution of the nonlinear differential equations. However, Liapunov
did point out in his first method that the solution may be obtained in the form of a
series from which stability can be determined using his second method. In addition,
he proved that approximate solutions of nonlinear differential equations often yield
useful stability information.
In order to illustrate Liapunov’s first method, let us assume that the non￾linearity is single valued (has no hysteresis present) and has derivatives of every .order
in the vicinity of a point A. Then the nonlinear function,^' = f(x), can be expanded438 Nonlinear Feedback Control-system Design 8.17
into a Taylor series as follows:
y = f(x) = y(A) + (x - + ;“(*-
\ax/A .2! \ax Ja
+ (x - A)3(^\ + • • • + ±(x - Ay + • • • . (8.144)
3! \dx Ja n! \dxn/A
Note that the first two terms ofthe series represent the linear approximation about the
operating point of the actual nonlinearity. Liapunov proved that if the real parts of
the roots of the characteristic equation corresponding to the differential equation of
the linear approximation are different from zero, the equations of the linear approxi￾mation always give a correct answer to the question of stability of a nonlinear system
[21], This theorem means that we can use a linear approximation of the nonlinear
equation and determine stability from it. If the roots of the linearized characteristic
equation are negative, the motion is stable about the point in question. However,
if any ofthe real parts ofthe roots ofthe characteristic equation ofthe linear approxi￾mation are positive, the motion is unstable about the operating point. In the special
case of roots of the linearized characteristic equation having zero real parts, no
conclusion may be drawn.
To illustrate the application of Liapunov’s first method, consider the Van der Pol
equation which describes the voltage build-up of an oscillator,
v + u(i>2 - l)i> + Kv = Q, (8.145)
where
u < 0, K > 0.
The equilibrium point of this system is determined when the velocity and acceleration
are zero. Then,
Kv = Q, (8.146)
or
v = — — V= equilibrium point. (8.147)
K
In order to determine behavior in the area of the equilibrium point, V, let
v = V + vt, (8.148)
, where
V = V = 0.
Substituting Eq. (8.148) into Eq. (8.145) we obtain the following expression:
i;i + utfV'2 + 2VVi + i>*) - 1]^. + K(V + d,.) = Q. (8.149)
The linear approximation to this equation is given by
j;. + w[p - l]i)(. + KVi = 0. (8.150)8.17 Liapunov’s Stability Criterion 439
The characteristic equation is given by
s2 + t/[F2 - l]s + K = 0. (8.151)
Applying the Routh-Hurwitz stability criterion, we find that, for stability,
u[V2 - 1] > 0. (8.152)
Equation (8.152) states that when u < 0, the system is stable for all V < 1. Lia￾punov’s first method is not applicable when V = 1, since this condition results in
zero real parts for the roots of the characteristic equation.
It is important to emphasize that Liapunov’s first method determines stability
in the immediate vicinity of the equilibrium point.
B.- Liapunov’s Second Method This determines stability without actually having to
solve the differential equation. In this method a function of the state variables
having special properties is formed, that can be compared to the sum of the kinetic
and potential energy, and the derivative of the function with respect to time is taken.
If this derivative is negative along the trajectories of the system, it can be shown that
the system is asymptotically stable. The remainder of this section is devoted to the
details and application of the method.
We introduce Liapunov’s second method by first considering a linear system.
Reconsider the simple mass-spring-damper mechanical system illustrated in Fig.
3.3. It was shown there that this system can be represented by the following differ￾ential equation:
M + B^r + = /(0- (8.153)
dt2 dt
Assume that M = B = K = 1 and that/(/) = 0. Then we have
y + y + y = 0. (8.154)
Defining the state variables as
Xl=y, (8.155)
x2 = y, (8.156)
the system can be described by the following two first-order differential equations:
xx = x2 = y,(8.157)
x2 = — Xj — x2. (8.158)
This simple linear .system can easily be solved. Assuming the initial conditions are
xx(0) = 1,(8.159)
x2(0) = 0, (8.160)
then we obtain the following solutions:
xx = 1.15e~i/2sin (0.866/ + tt/3), (8.161)
x2 = — 1.15e“</2 sin (0.866/). (8.162)440 Nonlinear Feedback Control-system Design 8.17
Fig. 8.57 Time-domain response of a simple mechanical system.
Equations (8.161) and (8.162) are plotted in the time domain in Fig. 8.57, and in the
phase plane in Fig. 8.58. These two figures completely determine the dynamics and
stability of this simple mechanical system. The system is stable and the states and
x2 behave as indicated.
Now, let us look at this simple system from the viewpoint of energy. The total
stored energy is given by
V = JKxi + iMx^. (8.163)
Since K = M = 1 in our simple example,
V = + 14 (8.164)
This total energy is dissipated as heat in the damper at the rate of
V = -Bxrx2 = -Bxl (8.165)
Since B — 1, we obtain
V = -4 (8 166)
Fig. 8.58 Phase plane of a simple mechanical system.8.17 Liapunov’s Stability Criterion 441
Fig. 8.59 Constant-energy loci on the phase plane illustrating a decrease of energy with
time.
Equation (8.164) determines the loci of constant stored energy in the XjXg-plane.
Clearly they are circular for this simple example. Another important observation
from Eq. (8.166) is that the energy rate is always negative and, therefore, these circles
must get smaller and smaller with time. Figure 8.59 illustrates this characteristic in
the phase plane. For this simple example, we can determine the time variation of
V and V explicitly by substituting Eqs. (8.161) and (8.162) into Eqs. (8.164) and
(8.165). The results are as follows:
V = 0.667e-‘[sin2 (0.866/) + sin2 (0.866/ + tt/3)], (8.167)
F = —1.333c-* sin2 (0.866/). (8.168)
Figure 8.60 illustrates the time variation of V and V. Comparing Figs. 8.59 and 8.60,
we conclude that the total stored energy approaches zero as time approaches infinity.
This implies that the system is asymptotically stable. By this is meant that the state
will return to the origin from any point x within a region R enclosing the origin.
Asymptotic stability is the type of stability preferred by control engineers.
The stability of nonlinear systems depends on the particular state space in which
the state vector ranges in addition to the type and magnitude of the input. Therefore,
the stability of nonlinear systems can also be classified on a regional basis as follows
[12,24]:
a) local stability, or stability in the small,
b) finite stability,
c) global stability, or stability in the large.442 Nonlinear Feedback Control-system Design 8.17
Fig. 8.60 Variation of energy and energy rate with time.
A nonlinear control system is denoted as being locally stable if it remains within an
infinitesimal region about a singular point when subjected to a small perturbation.
Finite stability refers to a system which returns to a singular point from any point
x within a region R of finite dimensions surrounding it. The system is said to be
globally stable if the region R includes the entire finite state space. Stability of either
the local, finite, or global variety does not exclude limit cycles, but rather only
excludes the possibility of the state point tending to travel to infinity. If the state
point approaches the singularity as time approaches infinity, for any initial condi￾tions within the region under consideration, then the system is described as being
asymptotically stable. Asymptotic stability excludes a stable limit cycle as a possible
dynamic equilibrium condition. The strongest possible condition that can be placed
on a nonlinear control system, with parameters that do not vary with time, is global
asymptotic stability. *
* There are about 30 different classes ofstability currently in use. However, the types defined
in this book are the important ones most frequently used by the control-system engineer.
A major factor in this analysis has been the choice of the energy function V,
V = + |x2. (8.169)
This function has two very interesting properties. First it is positive for all nonzero
values of xx and x2. Secondly, it equals zero when = x2 = 0. A scalar function
having these properties is called a positive-definite function. By adding V as a third
dimension to the xrx2-plane, the positive-definite function V(xlt x2) appears as a
cup-shaped three-dimensional surface as illustrated in Fig. 8.61.
Liapunov’s stability theorem can now be summarized for n-dimensional state
space. A dynamic system of nth order is asymptotically stable if a positive-definite
function V can be found whose derivative with respect to time is negative along the
trajectories of the system. In practice, it is fairly easy to find a function which is
positive definite, but usually it is very hard to find a function where, in addition,
K < 0 along the trajectories.
A justification of Liapunov’s second method can best be presented by considering
the phase plane of Fig. 8.62. Contours of constant V are shown by the curves of C158.17 Liapunov’s Stability Criteria 443
Fig. 8.61 A positive-definite function.
C2, and C3. Assume that the phase trajectory of this second-order system, whose
initial state is the pointp, is described by the following state equations:
= Jj(x15 x2), (8.170)
x2 = F2(x1, x2). (8.171)
The positive-definite function, V, is assumed to be given by
V = a2x[ + b2xi (8.172)
where a and b are unknown coefficients. The quantity V is permitted to take on
successively larger constant values,
V = 0, Clf C2, C3,... , where 0 < Q < C2 < C3 < • • •. (8.173)
Fig. 8.62 Justification of Liapunov’s stability criterion.444 Nonlinear Feedback Control-system Design 8.17
Therefore, Eq. (8.172) results in a set of equations:
a2x2 + b2x% = 0
a2x2 + b2xl = Cx
a2x2 + b2x% = C2
(8.174)
When V = 0, Eq. (8.174) describes the origin ofthe state space; for other values, the
resulting equations describe ellipses in the state space. As shown in Fig. 8.62, each
succeeding ellipse contains within itself all of the preceding ellipses. The time deriva￾tive of the V function is given by
dV dV dx} dV dx2
dt dxr dt dx2 dt
(8.175)
or
dV dV . dV . — = — x, + — x2.
dt dx} dx2
(8 176)
Substituting Eqs. (8.170) and (8.171) into Eq. (8.176), we obtain
dV dV , dV / — = — x2) + — F2(x15 x2).
dt
(8.177)
Taking the partial derivatives of Eq. (8.172) as indicated, Eq. (8.177) can be rewritten
as
— = 2a2x1F1(x1, Xa) + 2b2x2F,(x1, x2).
at
(8.178)
If dV/dt is negative, then the state must move, from its initial state point p, in the
direction of smaller values of V and toward the origin. This system would then be
asymptotically stable. This illustration can be extended, analogously, to higher-order
systems.
To illustrate the application of Liapunov’s second method we consider the
second-order differential equation
dx
— = y, dt (8.179)
y; = -K±y - K2y3 — x,
dt (8.180)
where Kx and K2 are not both zero. Depending on the values of A'1 and K2, stability
or instability can result. For example, if > 0 and K2 > 0, and V is given by
(8.181)8.17 Liapunov’s Stability Criteria 445
this system is stable, since the derivative of lz with respect to time t, dY/dt, is negative,
since
dE _/ dx dy\ , ,
“T = 2 X T. + ■>’ TJ = + W) < 0. (8.182)
at \ dt at/
Equilibrium occurs at the singularity located at the origin, and the equilibrium point
is asymptotically stable.
It is left as an exercise for the reader to prove that the condition A) < 0 and
^2 < Q corresponds to an unstable equilibrium; the condition KY > 0 and K2 < 0
corresponds to a stable equilibrium only if 0 < y2 < KJK2.
As an additional example, let us consider the following nonlinear problem:
= x2 (8.183)
x2 — —ax2 — bx2 — x15 (8.184)
where a > 0 and > 0 and are not both zero. Let us try the following energy
function:
V = xl + xf. (8.185)
This function satisfies the Liapunov criterion since it is positive for all nonzero values
of Xj and x2, and K(0, 0) = 0. Now let us examine V. Differentiating the E-function,
we obtain
E = 2fx1^ + x2^. (8.186)
\ dt dt /
Substituting Eqs. (8.183) and (8.184) into Eq. (8.186), we obtain
V — 2[xjX2 + x2(— ax2 — bx2 — xx)], (8.187)
V = - 2[ax2 + bx4,]. (8.188)
Therefore, V is negative everywhere except at the origin, and the equilibrium is
asymptotically stable. Notice that if a < 0 and b < 0, then we have a case of an
unstable equilibrium as all trajectories move away from the origin. In the case where
a > 0 and b < 0, K is negative only if 0 < x2 < alb. This means that stability
occurs only for initial disturbances that do not cause the (x15 x2)-point to lie outside
a horizontal strip in the phase plane.
It is important to recognize that the stability conditions obtained from a particular
E-function are usually sufficient, but not necessary. In addition, a Liapunov function
for any particular system is not unique. Therefore, if a particular K-function should
fail to demonstrate whether a particular system is stable or not, there is no assurance
that another function could not be found that does determine stability or instability.
There is also no assurance that exceeding the limits based on a particular F-function
will actually cause the equilibrium to be unstable. The Liapunov stability criterion
is a conservative one.446 Nonlinear Feedback Control-system Design 8.18
As can be seen from this presentation, the primary use of Liapunov’s second
method is not the determination of stability where the answer may be found by other
means, but is rather in the study of problems of stability which are not readily deter￾mined by other methods. For example, the determination of stability of high-order
nonlinear control systems is such a problem.
It is important to emphasize that we have not specified any guidelines for selecting
the K-functions. Actually, the choice of the K-function is the main problem in wider
application of Liapunov’s method in practice. Methods for constructing the V￾function is of current research interest [14, 21].
8.18 POPOV’S METHOD
An interesting and very powerful stability, criterion for nonlinear systems that are
time invariant was introduced in 1959 by V. M. Popov who obtained a frequency￾domain criterion as a sufficient condition for asymptotic stability of single-loop
control systems [22-29], The method, as originally developed by Popov, is
applicable to single-loop feedback systems containing time-invariant linear elements
and time-invariant nonlinearities. An important feature of Popov’s approach is
that it is applicable to systems of high order. Once the frequency response ofthe linear
element is known, very little additional calculation is required for determining stability
of the nonlinear control system.
This section presents Popov’s stability criterion in terms of inequality constraints
on the nonlinear element in conjunction with a modified frequency plot of the linear
element. It will be shown that the most important and appealing feature of the
Popov criterion is that it shares all of the desirable characteristics of the Nyquist
method.
Fig. 8.63 Nonlinear feedback control system considered by Popov [22],
In order to introduce Popov’s method, let us consider the nonlinear system
illustrated in Fig. 8.63. It is composed of a linear, time-invariant process G(s) and a
nonlinear, time-invariant element jV[<?(t)]. The reference input r(t) is assumed to be
zero. Therefore, the response of this system can be expressed as
where
e(0 = eo(O — g(t — t)m(t) dr,
Jo
(8.189)
g(t) = 1[G(j)] = unit impulse response
—e0(t) = initial condition response.8.18 Popov’s Method 447
Fig. 8.64 Restricted region of nonlinearity.
In this analysis, special restrictions are placed on the nonlinear and linear ele￾ments. For the nonlinear element 7V[e(t)], it is assumed that the input-output
relationship is restricted to lie within a sector bounded by two straight lines that pass
through the origin as illustrated in Fig. 8.64. Thus
A < 2V[e(7)] < B, (8.190)
where
u(t) = N[e(t)]e(t). (8.191)
Furthermore, it is assumed that for all t, and for every finite value em, there is a finite
value um such that
l«(0l < Um < co if |e(z)| < em. (8.192)
The only assumption concerning the linear element G(s) is that it is output stable of
degree n for some value of n. By this we mean that if n < 0, the output response to
an initial condition or an impulse may diverge, but when the output is multiplied by
eni it will converge towards zero. For the case of n > 0, output stable means that the
output response to an initial condition or an impulse will converge towards zero
faster than the function e~nt. In general, a linear element will be output stable of
degree n if its transfer function G(s) and initial condition response function E0(s) are
rational functions of s and its poles all satisfy
Re 5 < —n.
Therefore, n actually represents the settling rate of the linear element.
Popov’s method is concerned with the asymptotic behavior of the control signal
u(f) and output — e(t) of the linear element. Therefore, in addition to the definitions
of asymptotic stability, local stability, finite stability, and global stability that were
introduced in Section 8.17 in connection with the Liapunov stability criterion, we are448 Nonlinear Feedback Control-system Design 8.18
concerned here with control asymptoticity and output asymptoticity. Control
asymptoticity ofdegree n exists if a real value n can be found such that for every set of
initial conditions
(*[e ntu(t)]2 dt < oo. (8.193)
Jo
Output asymptoticity ofdegree n exists if a real value n can be found such that for every
set of initial conditions
poo
[enie(tf? dt < oo. (8.194)
Jo
These stability definitions can be clarified by considering the following lemma.
If the linear element G(s) of Fig. 8.63 is output stable of degree n, the input and
output ofthe nonlinear element are bounded and satisfy Eq. (8.192), and the feedback
system is control asymptotic of degree n, then
. hm ente(t) = 0. (8.195)
co
Therefore, if this lemma is satisfied, e(t) converges towards zero faster than e~nt for
n > 0.
How can we relate control asymptoticity and output asymptoticity? Obviously,
there should be some relationship based on the properties of the linear element G(s).
Let us assume that the linear element is output stable of degree n. It can be shown that
ifthe linear element is control asymptotic of degree n, then it is also output asymptotic
of degree n. In addition, if for each set of initial conditions a number Qo exists such
that
ko(OI <
then there exists a number Q that is dependent on Qq such that
|e(t)| < Qe~nt
for all values of t. This appears reasonable since a decaying control signal u(f), that
satisfies Eq. (8.193), when it is fed into the linear element whose unit-impulse response
decays like u(t), will produce an output — e(t) that also decays in a similar manner.
Popov’s fundamental theorem is based on the basic feedback control system
illustrated in Fig. 8.63. It is assumed that the linear system is output stable. The
theorem states that for the feedback system to be absolutely control and output
asymptotic for
0 < 2V[e(t)] <
it is sufficient that a real number q exists such that for all real co > 0 and an arbitrarily
small <5 > 0, the following condition is satisfied:
Re [(1 + >^)G(»] + 1/A: > <5 > 0. (8.196)
The relation (8.196) is the Popov criterion. Depending on the type of nonlinearity8.18 Popov’s Method 449
Fig. 8.65 Passive hysteresis nonlinear characteristics.
present, the following restrictions on q and K are imposed:
A. For a single-valued, time-invariant, nonlinearity:
— oo < ^ < oo if 0<A'<oo,
0 < q < oo if K = co.
B. For a nonlinearity having passive hysteresis (see Fig. 8.65):
— oo < q < 0 and 0 < K < oo.
C. For a nonlinearity having active hysteresis (see Fig. 8.66):
0 < q < oo and 0 < K < oo.
Examination of these three possible types of nonlinearities shows that the theorem
allows for a trade-off between the requirements on the nonlinear and linear elements.
Let us rewrite (8.196) as follows:
Re G(jTt'j) > — — + a>q Im G(jco). (8.197)
Fig. 8.66 Active hysteresis nonlinear characteristics.450 Nonlinear Feedback Control-system Design 8.18
Relation (8.197) states that for each frequency co, the Nyquist plot of G(jco) must lie
to the right of a straight line given by
Re G(jco) = — — 4- coq Im G(jco). (8.198)
K
This line is called the Popov line and is illustrated in Fig. 8.67. The angles a and are
a = tan-1 coq, (8.199)
3 = tan"1 — , (8.200)
coq
and it is clear that the slope of this line depends on the product coq.
Fig. 8.67 Popov’s method when q is finite.
Stability depends on choosing a value of q such that, for each frequency co, G(jco)
lies to the right of the Popov line. It is important to recognize from Eqs. (8.199) and
(8.200) that the slope of this line is frequency dependent. A Popov line whose slope
is not frequency dependent can be found in a modified frequency plane. In order to
find the particular frequency-insensitive Popov line, a simple transformation is used.
The modified frequency response function G*(s) is defined as
G*(Jco) = Re G(jco) 4- jco Im G(jco). (8.201)
Therefore, Eq. (8.197) can be rewritten as
Re G*(jco) > - — 4- q Im G*(». (8.202)
K
In the G*(yw)-plane, the Popov line is defined by
Re G*(» = - - 4- q Im G*(»,8.18 Popov’s Method 451
Fig. 8.68 Popov line in the G*(yw)-plane for the case where 9 > 0.
and is frequency insensitive. The Popov line in the G*(yw)-plane is illustrated in Figs.
8.68 and 8.69. The angle y is defined as
y = tan'1 q.
Notice from Figs. 8.68 and 8.69 that the G*(y'w)-locus passes to the right of a tangent
to the locus at the point where intersects the negative real axis. These points
are labeled —\/K. Therefore, K represents the maximum permissible gain for the
system. For the case where q = 0, the Popov line expression reduces to
Re (7*jw) = — —K
and the system is stable if it lies to the right of a vertical line passing through the point
— 1 /A'i as is illustrated in Fig. 8.68.
Fig. 8.69 Popov line in the G*(yw)-plane for the case where q < 0.452 Nonlinear Feedback Control-system Design 8.18
Fig. 8.70 Nonlinear control system example.
As an example of applying Popov’s method, consider the system illustrated in
Fig. 8.70. For the linear element, the initial condition response e0(t) is given by
<?o(O = + <?2oe~2' + e30c-3(,
where e10, e20, and e30 depend on the initial conditions. The unit impulse response
g(t) is given by
g(t) = [0.5e^ - e~2' + 0.5e-3/]C/(t) (8.203)
where U(t) is a unit step function. Equation (8.203) indicates that the linear element
is output stable and satisfies one of the necessary constraints in order to use Popov’s
method. The corresponding G*(yco)-locus is illustrated in Fig. 8.71. From this dia￾gram, we can conclude that if the nonlinear element corresponds to a single-valued
nonlinear element, and ifq = 0.5, the Popov condition is satisfied when 0 < K < 60.
Fig. 8.71 The G*(yco)-locus for system illustrated in Fig. 8.70.8.19 The Generalized Circle Criterion 453
In conclusion, we see that the Popov method gives an exact and sufficient con￾dition for determining the absolute stability of feedback systems having the configura￾tion illustrated in Fig. 8.63, with certain restrictions imposed. The inequality
(8.196), which was given in terms of G(ja>) and a real constant q, is the key element of
the technique. The importance of Popov’s method is due to the fact that Popov’s
condition is given in terms of G(Ja>) which makes the technique easily applicable to
systems having high-order processes which are to be controlled. In addition, the
method shares all of the desirable characteristics of the Nyquist method. In the
following section, Popov’s method is extended to other types of systems which are
not necessarily restricted to systems in which the linear portion is output stable, and
the nonlinearity is time invariant.
8.19 THE GENERALIZED CIRCLE CRITERION
The generalized circle criterion [25, 26] enables one to investigate the asymptotic
behavior of a much wider class of systems than that for which Popov’s theorem was
originally intended. For example, this technique can be applied to systems having
unstable or nonasymptotically stable plants, and time-variable nonlinearities. The
generalized circle criterion presented in this section consists of modifying Popov’s
basic theorem in such a manner that the Popov condition can be applied directly to
the original transfer function.
Let us reconsider the basic nonlinear feedback control system illustrated in Fig.
8.63, and allow the nonlinearity to be time variable. It is assumed that the linear
element of this system is obtained by applying negative feedback through a constant
feedback gain A to the original linear element, and is output stable. The generalized
circle criterion is as follows: for the system of Fig. 8.63 to be absolutely control and
output asymptotic for
A < zV[e>(/), t] < B
then it is sufficient that a real number q exists such that for all real c>, the following
conditions are satisfied:
(B + A) — jcoq(B — A) “ /B — , 2 2\ \ s x. n
GG“) +--------------- -----------------------------
for IM > 1/B (8.204)
«w +(B + X) ~ <-«<«•
for IM < 1/B. (8.205)
The quantities B - A and q are restricted as K and q were in Popov’s method,
discussed previously in Section 8.18.454 Nonlinear Feedback Control-system Design 8.19
Fig. 8.72 The generalized circle criterion for the case 1/X > 1/7?.
Figure 8.72 illustrates the physical interpretation of relation (8.204) where it is
assumed that 1/X > 1/B. For each value of co > 0, the Nyquist plot of G(yco) must
lie outside the circle centered at *
* The circle criterion was originally developed only for the case of q = 0 [26], However, the
generalized circle criterion presented here is an extension which is valid for all values of q
including zero [25].
, 1 . /I + 2JKa~
I ■
A B.r
(8.206)
which crosses the real axis at the points — 1 /A and — 1/B. It is interesting to note that
if 1/B > 1/X. then the Nyquist plot must lie inside the circle that is centered at the
point given by Eq. (8.206).
Analysis of the generalized circle criterion is quite interesting. For example, if
we let X -> 0 and B -> K, then relations (8.204) and (8.205) reduce to (8.197), which
corresponds to the Popov condition (8.196). On the other hand, if we let X -> C and
B C, then we have a linear time-invariant system with gain C. For this case, the
critical circle reduces to a point —(1/C) in the G(y'co)-plane, which is of course the
critical point of the Nyquist diagram.
The generalized critical circle illustrated in Fig. 8.72 and defined by (8.204) and
(8.205) is a function of frequency. Although all of the circles pass through the points
— 1/X and — 1/jB, their centers move up with increasing values of qa>. However, for
the general nonlinearity case where the nonlinearity may contain hysteresis and is
time variable, q = 0 and a set of circles result that are symmetrical about the real
axis. Notice also from Fig. 8.72 that trade-offs can be made between the requirements8.19 The Generalized Circle Criterion 455
on the linear and nonlinear elements. For example, by narrowing the sector
A < A[e(t), /] < B (8.207)
the critical circles will be reduced and this will increase the permissible range of G(jw).
Let us consider the application of the generalized circle criterion Unlike the
situation for the Popov line of Section 8.18, it is not advantageous to transform the
critical circles from the G(/ft>)-plane into the <j *(yco)-plane, since this will only result
in a family of curves that are not circles and whose shapes depend on both co and q.
However, it can easily be shown that if a tangent is drawn on the critical circle at the
point — l/B, its angle a is given by
a = tan"1 — . (8.208)
a>q
Figure 8.72 illustrates this angle and also the angle which is given by
= tan-1 coq. (8.209)
Comparing Figs. 8.67 and 8.72, we observe that the tangent line on the critical circle
has the same slope as the Popov line when A — 0. In addition, if
B = K
and
0 < A < B,
then the tangent line on the critical circle becomes identical to the Popov line shown
in Fig. 8.67. We also showed in Section 8.18 that the Popov line could be trans￾formed into a frequency-independent line on the G*(/co)-plane as was shown in Figs.
8.68 and 8.69. Therefore, if lies to the right of the Popov line of Figs. 8.68
and 8.69, then G{jw) lies outside the critical circle illustrated in Fig. 8.72 for all co.
As an example of the generalized circle criterion, let us consider a nonlinear
system with the configuration illustrated in Fig. 8.63, where the transfer function of
the linear element is given by
1
C(s) =
(s - l)(s + 2)(s + 3)
(8.210)
and the initial-condition response is
e0(l) = 21 + V 3‘> (8.211)
where c?10, e20, and ^30 are related to the initial conditions for a particular set of state
variables. It is important to recognize that we are dealing with a nonlinear element
that is time variable and a linear element that is not output stable; a problem which
could not be solved using Popov’s basic method. It is assumed that the nonlinear456 Nonlinear Feedback Control-system Design 8.19
element corresponds to the general nonlinearity A[e(t), /], and therefore q must be
chosen equal to zero. The solution consists of plotting the frequency locus G(jco) as
illustrated in Fig. 8.73. The generalized circle criterion results in Popov sectors
A < N\e(j), t]< B (8.212)
such that for each of these Popov sectors the G(yro)-Iocus lies on or outside a circle
symmetrical about the real axis and passing through the points —A/A and — 1/5.
For this particular example, the possible Popov sectors (illustrated in Fig. 8.73)
which result in stable systems are given by the following conditions:
12.6 < N[e(t), r] < 15.2,
19.6 < N[e(t), t] < 34.5,
41.7 < 7V[e(r), t] < 167.0.
(8.213)
Notice from Fig. 8.73 that the size of the Popov sector, B — A, i.e.. the difference
between the lower bound A and upper bound B, depends on the size of the critical
circle.
(s - l)(j + 2)(j + 3)
and the nonlinearity corresponds to the general nonlinearity case where q = 0.
Therefore, we see that Popov’s method can be extended to systems with unstable
or nonasymptotically stable plants and time-varying nonlinearities by utilizing the
generalized circle criterion. As shown in this section, the method permits the design
of nonlinear systems whose linear elements are not output stable and whose nonlinear￾ity can be time variable and correspond to any general nonlinearity. There are many
practical situations where this is the very case involved, and the generalized circle
criterion provides a very powerful method for solving this class of problems.Problems 457
PROBLEMS
8.1 The torque-speed characteristics of a two-phase, ac instrument servomotor are
illustrated in Fig. P8.1. Assume that the inertia of the rotor is 0.1 oz in2 and that the load
inertia and coefficient of viscous friction are negligible.
Figure P8.1
a) Derive the transfer function of the motor, relating output position to control voltage,
using linearizing approximations. Approximate the characteristics by one straight line
that is tangent to the exact characteristics at 1000 rev/min, and by one straight line that
goes through the two endpoints. Compare your results.
b) How do the time constants derived in (a) change if the torque-speed characteristics are
approximated by two other straight lines: one at low speed that is tangent to the exact
characteristics at 250 rev/min, and one at high speed that is tangent to the exact charac￾teristics at 1750 rev/min?
c) Comparing your answers to (a) and (b), what conclusions can you reach?
8.2 Derive the describing function corresponding to the combined nonlinear character￾istics of saturation S and dead zone D.
8.3 Derive the describing function of a 2-position contactor which does not exhibit any
hysteresis affect.
8.4 An amplifying device in a feedback loop has the following nonlinear characteristics:
1. No output signal for all inputs whose magnitude is less than Er V.
e0(0 = 0 when |et(0l < l^il￾2. Input signals whose magnitude is greater than Ex V but less than E2 V are amplified
according to the relation
eg(t) = K[eM - EJ,
where
< le/r)] < |£2|.
3. For all input signals whose magnitude is greater than E., V, the output is given by
*©(0 = ke2,
when
> JE|2.
Sketch the input-output characteristics and derive the describing function.458 Nonlinear Feedback Control-system Design
Figure P8.5
8.5 Derive the describing function for an amplifying device which has the nonlinear
characteristics illustrated in Fig. P8.5.
8.6 A unity feedback system consists of cascaded elements which include a relay, pure
integration, an amplifier which saturates, a two-phase, ac servomotor, and a gear train con￾taining backlash.
a) Draw the block diagram and show the linear transfer functions and the describing
functions for the nonlinear elements, symbolically.
b) Qualitatively illustrate how you would predict the presence of an oscillation on a gain￾phase diagram.
8.7 A unity feedback instrument servo with a spring-loaded shaft has a dead zone of 2°.
Assume that K1 in Fig. 8.6 equals 1. The transfer function for the linear portion of the
system is given by
20
G(ia>) = --------------------------------. V 7 ycoQco + 0.05)(yw +0.1)
Utilizing the describing-function method on a gain-phase diagram, determine the conditions
necessary for the existence of a limit cycle.
8.8 Repeat Problem 8.7 with the transfer function for the linear portion of the system
given by
2
8.9 A unity feedback instrument servo is driven by an amplifier which saturates at 70% of
rated voltage of the motor. Assume that the gain of the unsaturated amplifier is 40. The
transfer function of the linear portion of the system, excluding the amplifier, is given by
0.25 (7(/co) = -------------- ,
J ju)(jco + 2)' Problems 459
(a)
(b)
Fig. P8.12 (a) An artist’s conception of NASA’s OAO. (Official NASA photo)
(b) Equivalent block diagram of the roll coarse solar orientation control loop.460 Nonlinear Feedback Control-system Design
Utilizing the describing function method on a gain-phase diagram, determine whether a
limit cycle exists.
8.10 An instrument servo contains a three-position contactor which has a pull-in point and
a drop-out point at errors of 0.03 rad and 0.01 rad respectively. The transfer function of the
linear portion is given by
10
G^^ ja>{ja> -t- 4) ’
Determine whether a limit cycle exists utilizing the describing-function analysis on a gain￾phase diagram. Assume in Fig. 8.17 equals 1.
8.11 Repeat Problem 8.10 with the transfer function of the linear portion given by
2.5
G^m^ + 4) '
8.12 The Orbiting Astronomical Observatory (OAO), shown in Fig. P8.12(a), is designed
to provide astronomers with a standardized stable platform in space readily adaptable to a
variety of experiments [15], Orbiting at 500 miles altitude, the OAO permits scientists to
examine any point in the heavens, unimpeded by the earth’s atmosphere. In addition, it has
a precision and stability unsurpassed even by a stationary observatory. After injection into
orbit and separation of the satellite from the second booster stage, the high-thrust gas jets
stop any tumbling or rolling sensed by rate gyros and align the OAO’s optical axis with the
earth-sun line to ±|°. The OAO utilizes coarse and fine solar orientation control systems.
The coarse loop depends on gas jets firing and is a nonlinear control system. The fine loop
depends on a momentum-exchange wheel and is a linear control system. Let us consider
the nonlinear characteristics of the coarse solar orientation control system in this problem.
Figure P8.12(b) illustrates an equivalent block diagram of the roll coarse solar orientation
control loop. Basically, it consists of a switching amplifier which has very similar charac￾teristics to the nonlinear on-off element having hysteresis that has been analyzed previously
and which controls a solenoid valve and jet. As indicated in Fig. P8.12(b), the jet fires when
the error reaches ±3 V and stops firing when the error is reduced to ±2.9 V. Assume that
the resultant corrective torque produced by the jet is ±0.3 lb ft, and the inertia in the roll
axis is 1000 lb ft sec2. The rate gyro, which closes this rate loop, has a sensitivity of 10 V/
(degree/sec). Using the describing function analysis on a gain-phase diagram, determine the
existence of any limit cycles.
8.13 An instrument servo system used for positioning a load may be adequately represented
by the block diagram shown in Fig. P8.13.
Figure P8.13Problems 461
(b)
Fig. P8.15 (a) Conceptual design of spinning space station. (Courtesy of the Sperry Rand
Corporation) (b) Equivalent block diagram of the spin speed control system.462 Nonlinear Feedback Control-system Design
a) Using the gain-phase diagram, prove that if K = 4 the system exhibits a limit cycle(s).
Determine the range of frequencies and D/M ratios for which the limit cycle(s) exist.
Are they stable or unstable?
b) It is desired to stabilize this configuration by reducing the system gain. Determine the
maximum value of gain K which will allow a minimum stability margin of 3 db.
c) It is desired to stabilize this configuration by adding a lead network in cascade with
G(jw). Determine the time constants of the lead network
1 + j<oa.T
1 +Ja>T
which will permit a minimum stability margin of 3 db.
d) It is desired to stabilize this configuration by the introduction of rate feedback as shown
in Fig. 8.30. Determine the rate feedback constant b which will permit a minimum stability
margin of 3 db.
8.14 Repeat Problem 8.13 for
r(. , _ W + 3»
j«>(1 + 2.1yw)2 '
8.15 It is questionable whether man can tolerate prolonged periods of weightlessness and it
may, therefore, be necessary to provide an artificial gravity environment in future space
stations. This can be accomplished by spinning the space station to obtain a centripetal
acceleration equivalent to 0.2 to 0.5 of the earth’s surface gravity. Various studies have been
performed on this problem [16], Figure P8.15(a) illustrates a conceptual design of what such
a space configuration might look like. Basically, it consists of a small laboratory that is
connected to a counterweight with a cable, and the entire configuration is spun about its 
composite mass center. From a practical viewpoint, this configuration is launched as a
retracted, unmanned vehicle. Crew members arrive later in escape vehicles and dock with
the orbiting, nonspinning space station. After entering the laboratory, a transition maneuver
is performed to deploy the stations. After this maneuver, the station is spun at 4 rev/min in
order to obtain an acceleration of 0.25 g in the laboratory portion. This configuration re￾quires many control systems which include pitch, roll, yaw, and spin control. Let us focus
our attention in this problem on the spin control system. The spin speed must be held fairly
constant in order to maintain a fixed artificial gravity. Since the space station will be operating
at altitudes between 100 to 150 miles, however, residual atmosphere can cause significant
reductions in the spin speed. Figure P8.15(b) illustrates a proposed spin speed control system
[30], An accelerometer gives a direct measure of the gravity level and spin jets are activated
through the switching amplifier and solenoid valve to correct the errors. As indicated in 
Fig. P8.15(b), a torque of ±25 lb ft is produced when errors exceeding ±0.006g are en￾countered. This torque remains until the error is reduced to ±0.0005 g. Assume the inertia
of the configuration is 50,000 lb ft sec2. Using the describing function analysis on a gain￾phase diagram, determine the existence of any limit cycles.
8.16 A positioning system consists of a major feedback path and three minor feedback paths
as shown in Fig. P8.16. Utilizing the signal-flow diagram approach, determine whether any
limit cycles exist if the nonlinearity corresponds to backlash and the system parametersProblems
£464 Nonlinear Feedback Control-system Design
correspond to the following values:
2(1 ± 10s)
G,(s) H4($) = 1.2,
$(1 + $)
100(0.1$ + l)(0.2$ + 1)
G2($) —— //.,($) = 0.0282$, ------------------------------
($ ± l)(0.5$ ± 1)
200(0.04$ ± 1)
C3($) /f3($) = 10$. $(0.02$ ±1) ’
G4($)
4
- (0.1$ + 1) ’
5
G^s) = - ,
8.17 Repeat Problem 8.16 with the nonlinearity corresponding to coulomb friction.
8.18 In 1965 the Ranger unmanned space vehicle, shown in Fig. P8.18(a), investigated the
surface of the moon by means of a TV camera and instruments. From a control-system
viewpoint, the Ranger attitude control system must stabilize the vehicle from second-stage .
separation until lunar encounter [31], The accuracy requirements are especially high since
the Ranger vehicle is an unmanned vehicle and its solar panels must point accurately at the
sun in order to obtain energy. In addition, the Ranger vehicle transmits data back to earth
by means of a narrow-beam antenna which requires very accurate pointing. The equivalent
block diagram of the Ranger attitude control system for the pitch axis is illustrated in Fig.
P8.18(b). Error signals in position, generated by a sun sensor, are added to velocity error
signals generated by a rate gyro. A switching amplifier, which has very similar characteristics
to the nonlinear on-off element having hysteresis that has been analyzed previously, controls
a solenoid valve and jet. As indicated in Fig. P8.18(b), the jet fires when the dead zone error
is equivalent to ±1 mrad and stops firing when the error decreases to ±0.96 mrad. Assume
that the corrective torque produced by the jet is ±0.02 lb ft, and the inertia of Ranger in 
the pitch axis is 110 lb ft sec2. Utilizing the describing function method, determine the
sensitivity ofthe rate gyro, b, in order to obtain a stability margin of at least 40° for M/D <6.
8.19 The control system of Fig. P8.19 illustrates an undamped servo, where the motor
torque is proportional to the error e and is not affected by velocity. Consider the composite
gain of the forward part of the loop to be 800 dyne cm per radian of error.
a) Draw the phase trajectory for the following set of initial conditions:
0O = initial output displacement (in rad) = 1 rad
0o = initial output velocity (in rad/sec) = 0.
b) What conclusions can you reach from the phase trajectory?Problems 465
. ’V «x,. •Ts-V.-
f- .• u. ' V»%K!
(b)
Fig. P8.18 (a) An artist’s conception of a Ranger spacecraft photographing the moon before 
impact. (Official NASA photo.) (b) Equivalent block diagram of the Ranger attitude
control system for the pitch axis.466 Nonlinear Feedback Control-system Design
Figure P8.19
8.20 The control system shown in Fig. P8.20 illustrates a positioning servo system,
a) Draw the phase trajectory for the following set of initial conditions:
f)0 = 2.5 rad, >’ (50 = 0.
b) What conclusions can you reach from the phase portrait ?
Figure P8.20
8.21 Draw the phase portrait of a linear, unity, feedback control system whose transfer
function is given by
10
~ j(l + 0.1s) ’
8.22 RepeatProblem 8.20 with rate limiters at 4 rad/sec added to the system.
8.23 RepeatProblem 8.20 with position limiters at 1 rad added to the system.
8.24 RepeatProblem 8.21 with the rate limiters at 1 rad/sec added to the system.
8.25 RepeatProblem 8.21 with position limiters at 1 rad added to the system.
8.26 Determine the time it takes for the phase trajectory illustrated in Fig. P8.26 to traverse
the following segments:
a) AB, b) BC, c) CD,
d) DE, e) AE.
8.27 Manipulate the following equations into the 'form
-/(».<):
a) dt2 dt
+ C6(t) = D,
bj
d20(t) d6(t) d6(t)
dt2 + dt dt + C0(t) = D,Problems 467
Figure P8.26
A +B— |0(0| + C0(t) = D,
d20(t)
d) A~di *
dO(t)
+ c(w = D- at
8.28 Derive the isocline equation for each of the following differential ct]nations and draw
the isoclines together with their slope markers:
d20(t) d0(t) n
a) + 0.8 + 0.40(f) = 0,
</20(O ~ o dO(t)
b) -^ + 0.8 —— + 0.40(0 — 0.6, dt
d26(t) zs o dd(t) de(t) nAa/x n
c) -^-+0.8 dt d< + 0.4«(,) - 0,
d20(t) z. z> J0(O W)
d) -^-+0.8 —— ——- 4- 0.40(r) = 0.6.
dt dt
8.29 Construct the phase portraits for each of the differential equations a Problem 8.28
using the method of isoclines.468 Nonlinear Feedback Control-system Design
8.30 The differential equation of a typical second-order system containing both viscous and
coulomb friction is given by
d2y dy — + 0.8 — + 0.4v + A sin dx2 dx J
= 0.
Determine and construct the phase portraits for A = 0.2, 0.4, and 0.8.
8.31 Determine and construct the phase trajectory for a second-order system containing rate
limiting where 0(0) = 0.7. The differential equation for the system is given by
d26(t) d6(t)
__ + 0.8 — + 0.40(0 = 0
and
d&{t)
dt = 0.3.
max
8.32 Determine and construct the phase trajectory
describing equations are given by
of a nonlinear system for which the
and
d20(t) d3(t)
+ 0.8 + 0(0 = 0.5 dt2 dt where 0(0 > 0
d—
26(t) d0(j)
+ 0.8 + 0(0 = -0.5 dt2 dt where e(t) < o.
Assume that the initial conditions are 0(0) = 0.5 and (t/0/t/r)(O) = 0.
8.33 Utilizing Liapunov’s second method, determine the stability of the nonlinear differen￾tial equation
x + Krx + X2(x)5 + x = 0
if
a) K{ >0, K2> 0; b) K± <0, K2 < 0;
c) Xj >0, K2 < 0.
8.34 Repeat Problem 8.33 for the nonlinear differential equation
x + [A\ + A'2(x)4]x 4- x = 0.
8.35 A unity-feedback control system contains a linear and nonlinear element. The transfer
function of the linear element is given by
= + 3)
W s(j + 2)2(s + 1.5) ‘
The initial-condition response of the linear element is given by
^n(0 = <ho +
where e10, e20, e30, and ei0 are related to the initial conditions and the unit-impulse response is
given by
£•(/) = [0.5 + 3.5e~2( + te~2t — 4e~1,5t]U(t)Problems 469
where U(t) is the unit step input. Using Popov’s method, determine the values of K which
will result in a stable system, assuming that the nonlinear element is single-valued with
q = 1.0.
8.36 Repeat Problem 8.35 with q = 0.75 and the transfer function of the linear element
given by
5(5 + 1.5)(j + 2)2 ’
8.37 Repeat Problem 8.35 with q = 1.11 and the transfer function of the linear element
given by
w 5(5 + 2)2(5 + 1.5)’
8.38 A unity-feedback control system contains a linear and nonlinear element. The transfer
function of the linear element is given by
V ’ (5 - 1)(5 + 3)(5 + 4)'
The initial condition response is
eo(O = <hoef + + e30e-4t,
where e10, e20. and e3o arise from the initial conditions. Using the generalized circle criterion,
determine possible values of r] which will result in a stable system if the nonlinear
element corresponds to the general nonlinearity case (q = 0).
8.39 Repeat Problem 8.38 with the transfer function of the linear element given by
1
G{S) = (5 - 1)(5 + 3)(5 + 4) ‘
8.40 Repeat Problem 8.38 with the transfer function of the linear element given by
(5 + 6)
G(6) = (5 - 1)(5 + 3)(5 + 4)'
8.41 An instrument servo system used for positioning a load may be adequately repre￾sented by the block diagram shown in Fig. P8.41, which indicates that the system contains
backlash.
a) Using the gain-phase diagram, determine the existence of any limit cycles if K = 25.
b) What is the maximum gain that can be tolerated in G'Q'w) before a limit cycle occurs?
Figure P8.41470 Nonlinear Feedback Control-system Design
8.42 In contrast to the on-off element having dead-zone and hysteresis characteristics
present, as analyzed in Fig. 8.17, an ideal relay has no dead-zone or hysteresis
characteristics.
a) For the ideal relay characteristics shown in Fig. P8.42, determine its describing function
analytically, assuming that the input to the nonlinear element is a sinusoid of M sin cot.
b) Check your answer by reducing Eq. 8.51 for the conditions of zero dead zone and
hysteresis (Ai of Eq. 8.50 now becomes zero).
Figure P8.42
8.43 Utilizing the result of your derivation of the describing function for the ideal relay
characteristics in Problem 8.42, consider the stability of the control system shown in Fig.
P8.43. For the value of G(jcu) indicated, determine the existence of any limit cycles and
whether they are stable or unstable.
Figure P8.43
8.44 Assume that the block diagram of a load-positioning control system, which contains
backlash, is represented as in Fig. P8.41 and that the linear portion’s transfer function is
given by
r.. . .20
J<o(l -I- 0.5/w)2'
a) Using the gain-phase diagram, determine the existence of any limit cycles.
b) Determine the gain which can permit a stability margin of 3 db.
8.45 Repeat Problem 8.44 for
/w(! 4 0.3 ,’a>)(References 471
REFERENCES
1. P. M. Lowitt and S. M. Shinners, “Type N—Integral space tracking configuration,”
IEEE Trans. Military Electronics MIL-9, 88-98 (1965).
2. E. Levinson, “Some saturation phenomena in servomechanisms,” Trans. AIEE 72, 1
(1953).
3. C. A. Ludeke, “The generation and extinction of subharmonics,” in Proceedings of the
Symposium on Nonlinear Circuit Analysis, Polytechnic Institute of Brooklyn, New York
(April 1953).
4. R. J. Kochenburger, “A frequency response method for analyzing and synthesizing
contactor servo-mechanisms,” Trans. AIEE 69, 270 (1950).
5. E. C. Johnson, “Sinusoidal analysis of feedback-control systems containing nonlinear
elements,” Trans. AIEE1\, 169 (1952).
6. H. D. Grief, “Describing function method of servomechanism analysis applied to most
commonly encountered nonlinearities,” Trans. AIEE 72, 253 (1953).
7. J. G. Truxal, Automatic Feedback Control System Synthesis, McGraw-Hill, New York
(1955).
8. P. M. Lowitt and S. M. Shinners," Integrated optimal synthesis for a radar tracker,” in
Proceedings ofthe Seventh National Military Electronics Convention, Washington, D.C.
(September 1963).
9. R. Oldenburgerand R. C. Boyer, “Effects ofextra sinusoidal inputsto nonlinearsystems,”
in Proceedings ofthe ASME Winter Annual Meeting, New York (1961).
10. S. M. Shinners, “Dual-input describing function,” Control Eng. 18, 53-55 (February
1971).
11. O. I. Elgerd, “Continuous control by high frequency signal injection,” Instrum. Control
Systems 37, 12 (1964).
12. O. 1. Elgerd, Control Systems Theory, McGraw-Hill, New York (1967).
13. R. C. Boyer, Sinusoidal Signal Stabilization, M.S. Thesis, Purdue University, Lafayette,
Ind. (1960).
14. J. E. Gibson, Nonlinear Automatic Control, McGraw-Hill, New York (1963).
15. O. Romaine, "OAO: NASA’s biggest satellite yet,” Space/Aeronautics 40, 54-58 (1962).
16. 1. N. Hutchinson, and J. L. Keller, “A flexibly coupled spinning space station—Its
stabilization and control,” Sperry Engineering Review, 18, 23-32 (1965).
17. I. Ritow, “Designing servos by the phase-plane method,” Elec. Mfg. 62, 98 (1956).
18. E. Levinson, “Phase-plane analysis,” Electro-Technology 69, 118 (1962)
19. H. S. Tsien, Engineering Cybernetics, McGraw-Hill, New York (1954).
20. A. M. Liapunov, On the General Problem ofStability ofMotion, Ph.D. Ihesis, Kharkov
1892; reprinted (in French) in Annals of Mathematics Studies, Vol. 17, Princeton Univer￾sity Press, Princeton, N.J. (1949).
21. N. Minorsky, Introduction to Non-linear Mechanics, J. W. Edwards, Ann Arbor,
Michigan, p. 52 (1967).
22. V. M. Popov, “Absolute stability of nonlinear systems of automatic control,” Auto￾mation Remote Control 22, 857-75 (1961).
23. V. A. Jakubovic, “Frequency conditions for the absolute stability and dissipativity
of control systems with a single differentiable nonlinearity,” Soviet Math. 6, 98-101
(1965).
24. S. Lefschetz, Stability of Nonlinear Control Systems, Academic, New York (196 Y472 Nonlinear Feedback Control-system Design
25. J. C. Hsu and A. U. Meyer, Modern Control Principles and Applications, McGraw-Hill,
New York (1968).
26. G. Zames, “On the input-output stability of time-varying nonlinear feedback systems—
Part II: Condition involving circles in the frequency plane and sector nonlinearities,”
IEEE Trans. Automatic Control AC-11, 465-76 (1966).
27. C. A. Desoer, “A generalization of the Popov criterion,” IEEE Trans. Automatic Control
AC-10, 182-85 (1965).
28. V. M. Popov and A. Halanay, “On the stability of nonlinear automatic control systems
with lagging argument,” Automation Remote Control 23, 783 86 (1963).
29. A. V. Michailov, “Harmonic analysis in the theory of automatic control,” A.T. Moscow,
No. 3, p. 27 (1938).
30. I. N. Hutchinson, R. F. Morrison, and J. L. Keller, “Stabilization and control of a cable￾connected spinning space station,” in Proceedings of the 1965 Joint Automatic Control
Conference, pp. 520-30.
31. W. Turk, Ranger Block III attitude control system, Jet Propulsion Laboratory Technical
Report, No. 32-663, Pasadena, California (November 1964).
32. B. O. Watkins, Introduction to Control Systems, Macmillan, New York (1969).
33. E. M. Grabbe, S. Ramo, and D. E. Wooldridge, Handbook ofAutomation, Computation,
and Control, Vol. 1, Wiley, New York (1958).
34. “BASIC” Language, Reference Manual, General Electric Co., Information Systems
Division, Phoenix, Arizona (June 1965; rev. January 1967).
35. S. A. Hovanessian and L. A. Pipes, Digital Computer Methods in Engineering, McGraw￾Hill, New York (1969).
36. H. H. Rosenbrick and C. Storey, Computational Techniques for Chemical Engineers,
Pergamon, Oxford (1966).
37. D. D. McCracken and W. S. Dorn, Numerical Methods and FORTRAN Programming,
Wiley, New York (1964).
38. R. W. Hamming, Numerical Methodsfor Scientists and Engineers, McGraw-Hill, New
York (1962).
39. D. Graham and D. McRuer, Analysis ofNonlinear Control Systems, Wiley, New York
(1961).
40. T. C. Bartee, Digital Computer Fundamentals (2nd Edn.), McGraw->Hill, New York
(1966).
41. G. A. Korn and T. M. Korn, Electronic Analog and Hybrid Computers, McGraw-Hill,
New York (1964).
42. S. M. Shinners, “Which computer—Analog, digital or hybrid?” Machine Design 43,
104-111 (January 21, 1971).9
OPTIMAL CONTROL THEORY AND
APPLICATIONS
9.1 INTRODUCTION
From the presentation of linear and nonlinear systems in Chapters 7 and 8, we
recognize that the conventional design of feedback control systems has several
disadvantages. The most serious disadvantage is that the design techniques presented
depended heavily on trial-and-error procedures. In contrast, optimal control theory
is concerned with obtaining a system which is the best possible with respect to a
standard against which we can measure real performance. We denote this standard as
the performance criterion (see Chapter 5 for a discussion of performance criteria).
The task of designing control systems which are optimal, in some sense, is one of the
most important and complex problems facing control engineers today.
Wiener [30], in the late 1940’s, developed the concept of optimum design that was
based on optimizing a performance criterion. McDonald [1] first applied the concept
of optimization to control systems in 1950. His objective was to minimize the
transient response time of a relay-type feedback control system to step inputs. In
1957, Draper and Li [2] wrote a booklet discussing the theoretical concepts of optimal
control for an internal combustion engine. Their system attempted to minimize (or
optimize) the consumption of fuel. Since that time many papers have been written
on optimal control systems both in this country and abroad. Most important is the
work of Bellman [12, 13], who developed the concept of dynamic programming, and
Pontryagin, Boltyanskii, and Gamkrelidge [15, 16], who developed the maximum
principle. The purpose of this chapter is to present the principles of this theory and
some examples of its application.
9,2 CHARACTERISTICS OF THE OPTIMAL CONTROL PROBLEM
In this section, we consider the basic problem of optimal control theory [8]. It
consists of choosing the input u to a control system so that the performance of the
system is optimum with respect to some performance criterion. The basic goal of
optimal control theory is to design control elements which meet a wide variety of
requirements in the best possible manner. The structure of the optimal control
problem can be described in the following way. One has
1. A,controlled process whose dynamics have the following form:
x = /(x, u, 0- (9-l)
473474 Optimal Control Theory and Applications 9.2
2. Restrictions on the input u and/or the plant state x.
3. A reference signal r which signifies the desired output response.
4. A performance criterion having the following general form:
5 = f G(c(t), u(t), r(t), t)dt. (9.2)
J/o
In Eq. (9.2), the integrand G is referred to as the loss function and represents a measure
of instantaneous change from ideal performance [3]. Therefore, the performance
criterion is interpreted as the cumulative loss. The optimal control problem consists of
the determination of the control input u that minimizes the performance criterion S
subject to certain constraints on u and x.
The problem of a unity feedback servo positioning system can be readily
formulated using optimal control theory [4], The objective is to determine the input
u that causes the output c to follow a given reference signal r within a certain accuracy.
Typically, the loss function could be the squared norm of the magnitude of the error
e = |(c - r)|:
G = |(c - r)| *. (9.3)
Thus from Eq. (9.2), the performance is given by
S = fr|(c- r)|2dt (9.4)
to
The limits of the optimization interval are usually specified and can be finite or
infinite. (See Problem 9.21 for an application of this performance criterion.)
Generally, it is desirable to revise the performance criterion, as defined by Eq.
(9.4), in order to include the effects of excessive control effort. By revising Eq. (9.4)
to
$ = f2 [|(<= - r)|2 + A(u)2] dt, (9.5)
J to
a compromise between small and large error and control amplitudes can be obtained
by a proper selection of X.
The choice of an input u, over the operating interval from t0 = 0 to t = Tsec, is
denoted as the control law [5]. If the input u minimizes the performance criterion S,
then it is optimal. Under these conditions, the optimal control is denoted by u° and
the optimal performance is denoted by S°.
The optimal policy can be either an open-loop policy or a feedback (closed-loop)
policy. The designation open-loop is used if the controlled input is specified as a
function of time. The optimal policy is designated feedback if the controlled input is
specified as a function of the current state of the plant. The nature of the policy is
extremely important since it indicates how u° is to be generated from r and c.
1 he representation of optimal control systems having open-loop and feedback
policies is illustrated in Fig. 9.1.9.3 Controllability 475
HO)
(a)
(b)
Fig. 9.1 Open-Ioop and feedback optimal control systems: (a) open-loop optimal control
system, (b) feedback optimal control system.
As the preceding chapters have shown, feedback has a great many advantages
and, therefore, a feedback policy is preferred for optimal control. For example,
feedback operation, in general, tends to make the system less sensitive to variations.
In addition, feedback operation makes use of the most recent information on the state
of the plant. As a result, if a disturbance within the system occurs in the feedback
case, the system operates optimally on the latest measurement of c. In an open-loop
system, however, the entire input is preprogrammed only on the basis of the initial￾state value. In this case, any disturbances within the system destroy the optimality of
operation.
9.3 CONTROLLABILITY
The concepts of controllability [6, 7, 9] and observability play a very important role
in optimal control theory. Before we can design a system to be optimal, we must
first determine whether it is controllable and its states are observable, since the
conditions on controllability and observability often govern the existence of a
solution to an optimal control system. Kalman [6, 7] first introduced the concepts of
controllability and observability in 1960. These concepts are basic in modern optimal
control theory. This section develops the controllability concept and the following
section presents observability.
in order to introduce the concept of controllability, let us consider the simple
open-loop system illustrated in Fig. 9.2. A system is completely controllable if there
exists a control which transfers every initial state at t = t0 to any final state at t = T
for all t0 and T. Qualitatively, this means that the system G is controllable if every
state variable ofG can be affected by the input signal u. However, if one (or several) of476 Optimal Control Theory and Applications 9.3
Fig. 9.2 Open-Ioop system containing several inputs and outputs.
the state variables is (or are) not affected by u, then this (or these) state variable(s)
cannot be controlled in a finite amount of time by it and the system is not completely
controllable.
As an example of a system which is not completely controllable, let us consider
the signal-flow diagram illustrated in Fig. 9.3. This system contains four states,
only two of which are affected by u(t). This input only affects the states x1 and x2.
It has no affect on x3 and x4. Therefore, x3 and x4 are uncontrollable. This means
that it is impossible for w(Z) to change x3 from an initial state x3(0) to final state x3(T)
in a finite time interval T and the system is not completely controllable.
Let us now consider this problem more precisely and establish a criterion for
determining whether a system is controllable. We limit our discussion to linear
constant systems. Assume that the system is described by
x = Px + Bu, (9.6)
c = Lx. (9.7)
The solution of Eq. (9.6) can be expressed as Eq. (2.249):
Ci
x(t) = «I>(t - t0)x(t0) + 4>(t - t)Bu(t) dr where t t0. (9.8)
J fo
Let us assume that the desired final state of our system at t = tf is zero:
*('/) = 0. (9.9)
Using Eqs. (2.244) and (2.246), we can write Eq. (9.8) as
fit
x(t0) = - 4>(f0 - t)Bu(t) dr. (9.10)
J f0
Fig. 9.3 Signal-flow diagram of a system that is not completely controllable.9.3 Controllability 477
The state-transition matrix can be expressed from Eq. (2.294) as
nt—1
4>(?) = ep' = J ara(t)P". n=0 (9.11)
Here, x is an m x 1 vector, P is an m x m matrix, u is an r x 1 vector, B is an
m x r matrix, and a„(r) is a scalar function of t. (This form results from application
of the Cayley-Hamilton theorem.) Substituting Eq. (9.11) into Eq. (9.10), we obtain
the following expression for x(t0):
x(t0) =
if 772 -1
1 a„(t0 - t)P''Bu(t) Jr.
o n=Q
(9-12)
Since the matrices P and B are not functions of r, we can rewrite Eq. (9.12) as
m—1 rtf - X(U = -2 P"B an(t0 - r)u(r) dr.
n~0 J to
Equation (9.13) can be rewritten as
x(/0)=—[B PB P2B P3B . . . pm—1g
Ax
a2
where
If we define
rtf
*n = a«('o - t)u(t) dr.
Jto
D = [B PB P2B P3B • • • P™~iB]
A = [Ao Ax A2 • • • Am l] ,
(9.13)
(9-14)
(9.15)
(9-16)
(9-17)
where D is a m x mr matrix and A is a mr x 1 vector, then Eq. (9.14) becomes
x(t0) -DA. (9.18)
For a given initial state x(r0), the input u can be found to drive the state to x(tz) = 0
for a finite time interval tf — t0 if Eq. (9.18) has a solution. A unique solution occurs
only if there is a set of m linearly independent column vectors in the matrix D. If u
is a scalar, then D is an m x m square matrix, and Eq. (9.18) represents a set of m
linear independent equations which have a solution if D is nonsingular, or the
determinant of D is not zero. The controllability criterion thus states that the system
of Eqs. (9.6) and (9.7) is completely controllable if D (see Eq. 9.6) contains m linearly
independent column vectors or, if u is a scalar, D is nonsingular.478 Optimal Control Theory and Applications 9.4
In order to illustrate this mathematical controllability concept, consider a second￾order system where
and
Then, from Eq. (9.16),
(9.19)
The resulting matrix D is singular (its determinant is zero) and the system is therefore
not completely controllable.
As a second example, consider a second-order system where
and
Then, from Eq. (9.16)
The resulting matrix D is nonsingular and the system, therefore, is completely
controllable.
9.4 OBSERVABILITY
In order to introduce the concept of observability [6, 7, 9], let us again consider the
simple open-loop system illustrated in Fig. 9.2. A system is completely observable if,
given the control and the output over the interval t0 < t < T, one can determine the
initial state x(t0). Qualitatively, the system G is observable if every state variable of
G affects some of the outputs in c. It is very often desirable to determine information
regarding the system states based on measurements of c. However, if we cannot
observe one or more of the states from the measurements of c, then the system is not
completely observable.
As an example of a system which is not completely obse able, let us consider the
signal-flow diagram illustrated in Fig. 9.4. This system contains four states, only two
of which are observable. The states x3 and x4 are not connected to the output c in any
manner. Therefore, x3 and x4 are not observable and the system is not completely
observable.9.4 Observability 479
Fig. 9.4 Signal-flow diagram of a system that is not completely observable.
Let us now consider this problem more precisely and establish a criterion for
determining whether a system is completely observable. Again, we limit our discus￾sion to linear constant systems of the form
x = Px + Bu, (9.20)
c = Lx (9.21)
where xis an nt X 1 vector, Pis an m x m matrix, u is an r x 1 vector,B is an m x r
matrix, c is a p x 1 vector,and L is a p x r matrix. Thesolutionof Eq.(9.20) is
given by (see Eq. 2.249)
x(t) = <E>(r - t0)x(t0) + f 4»(t - t)Bu(t) dr. (9.22)
It will now be shown that observability depends on the matrices P and L. Substituting
Eq. (9.22) into Eq. (9.21), we obtain
c(t) = L4>(t - t0)x(r0) + L ['4>(t - t)Bu(t) dr. (9.23)
J to
From the definition of observability we can see that the observability of x(t0) depends
on the term L4»(t — r0)x(/0). Therefore, the output c(t) when u = 0 is given by
c(t) = L<$(/ - r0)x(r0). (9.24)
Substituting Eq. (9.11) into Eq. (9.24), we obtain the following expression for the
output c:
m—1
C(O = 2 «„( * - to)LP”x(t0). (9.25)
M=0
Equation (9.25) indicates that if the output c(t) is known over the time interval
ta < ? < T, then x(r0) is uniquely determined from this equation if x(/0) is a linear
combination of (L?P',)r for n = 0, 1, 2, . .. , m — 1, and j = 1, 2, 3, . .. , r. The
matrix L, is the 1 x m matrix formed by the elements of the /th row of L. Since
(L^P")r = (Pr)’‘Ljr, we let U be the m x ntr matrix defined by
U = [Lr PrLT (Pr)2LT (Pr)3Lr • • • (Pr)m-1LT]. (9.26)
The observability criterion states that the system is completely observable if there is a
set of m linearly independent column vectors in U.480 Optimal Control Theory and Applications 9.5
In order to illustrate the observability concept mathematically, consider a second￾order system where
p = r-4 °i L 0 ~2J
and
L = [1 0].
Therefore,
and
Substituting these values into Eq. (9.26), we obtain
U = [Lr P2’LT] = 4J.
Since U is singular, the system is not completely observable.
As a second example, consider the second-order system where
and
Therefore,
and
L = [1 1].
Substituting these values into Eq. (9.26), we obtain
U = [LT PIV] = 81 -4j’
1
Since U has two independent columns, the system is completely observable.
9.5 CALCULUS OF VARIATIONS
The calculus of variations [3, 5, 10, 11] is concerned with obtaining the maxima and
minima of entire functional expressions. It can be applied to a great many problems
in the fields of classical mechanics, aerodynamics, optics, and control theory. We
shall consider the calculus of variations only in the context of control theory. Three9.5 Calculus of Variations 481
of its central problems are as follows:
1. The Lagrange problem is concerned with determining a function u which
minimizes a certain performance criterion S. Thus, for the given set of equations
x = f(x, u, f), (9.27)
c = Lx,
a set of initial conditions given by
x(0) = p,
and a performance criterion given by
rr
G(c(t),u(t), t) dt, (9.28)
Jo
this problem is concerned with determining the function u(t) which minimizes S'.
2. The Mayer problem is concerned with determining a function u which
minimizes a certain performance criterion S evaluated at the endpoint and containing
some variables whose final values are unspecified in advance. Thus, for the given set
of equations
x = f(x, u, r), (9.29a)
c = Lx, (9.29b)
a set of initial conditions given by
x(0) = p, (9.30)
a set of final conditions given by
x(T) = q, (9.31)
and a performance criterion given by
pT
S = G(c(t), u(t), t) dt, (9.32)
Jo
this problem is concerned with determining the function u(t) which minimizes S.
3. The Bolzaproblem is concerned with determining a function u, which contains
some variables that are unspecified in advance, and minimizing a certain performance
criterion at the endpoint. Thus, for the given set of equations
x = f(x, u, t), (9.33)
c = Lx,
a set of initial conditions given by
x(0) = P.
a set of final conditions given by
«(r) = q,482 Optimal Control Theory and Applications 9.5
and a performance criterion given by
S = F[(c(0, u(t), r)]or + Fg(c(0, u(t), t) dt, (9.34)
Jo
the problem is concerned with determining the function u(r) which minimizes S'.
The Bolza problem is the most general case of variational calculus. Most optimal
control problems can be formulated as one of these three fundamental problems, and
it is usually possible to introduce a mathematical substitution which can transform a
Lagrange or Mayer problem into a Bolza problem.
In order to solve for u° in a scalar problem using the calculus of variations, we
must first solve the Euler-Lagrange equation. The derivation of this differential
equation and demonstration of its computational difficulty can be shown by consider￾ing the Mayer scalar problem It is assumed that c — x, and that Eq. (9.32) has been
optimized and the optimum values x° and u° have been determined. For example, if
x° and u° are substituted back into Eq. (9.32), then S° is optimized (let us assume that
it is a minimum value).
What is the effect on S° if we now allow x° and u° to be perturbed by small
arbitrary amounts Ax and Am, respectively? If S° is indeed optimum, then AS must
be zero if we deviate slightly from it. We limit these perturbations, however, to
Ax(0) = Ax(T) = 0, in order to meet the constraints given by Eqs. (9.30) and
(9.31). The resulting effect on S° in Eq. (9,32) can be determined by substituting
x = x° + Ax (9.35)
m = u° + Am (9.36)
into Eq. (9.29a) as follows:
Using a Taylor series expansion around the optimum values, we obtain
y (x° + Ax) = /(x° + Ax, u° 4- Au, t). (9.37)
dt
,du/o
x° + Ax =/(x°, u°, t) + Ax + Au. (9.38)
\dx/o \ouJo
Since
x° = /(x°, u°, /), (9.39)
we have
Ax = Ax -|- Au (9.40)
\oxjo \dujo
or
Ax - Ax
Au =---------—■ .Q.,.
/Sf\ <9-41)9.5 Calculus of Variations 483
Equations (9.40) and (9.41) indicate that if Ax is arbitrarily chosen, then Au is
restricted to values which obey this equation. Now, knowing the relationship
between x, Ax, m and Au, can we say what effect Ax and Au have on S°? We can say
that
AS = S(x° + Ax, u° + Au, t) - S(x°, u°, t). (9.42)
Therefore,
pT fT
AS = G(x° + Ax, u° 4- Au, t) dt — G(x°, u°, t) dt. (9.43)
Jo Jo
Combining terms under the integral sign, we obtain
AS =J [G(x° + Ax, u° + Au, t) — G(x°, u°, t)] dt. (9.44)
By means of the Taylor series, we can show that
dt. (9.45)
Substituting Eq. (9.41) into Eq. (9.45), we obtain the following expression:
rTr/3G\ + /SG\ Ax - (3//5x)0 Ax'
o Lwx/o \3u/o (dfldu)^ (9.46)
Equation (9.46) can be simplified to
AS = r((9W2A. + rm_
Jo i(df/du)0 L\3x/o
/3G'
\2u,
1 Ax| A. 'o(a//au)oJ 1
Integrating the first term of the integral by parts, we obtain
(9-47)
r (5G/gu)0dt = r(dGidu)0^r d (dGldu\dt
Jo (df/du)0 L(3//3m)0 Jo Jo dt (df/du)0
(9.48)
Since Ax(0) = Ax(T) — 0, the first term on the right-hand side of Eq. (9.48) is
zero. Therefore, returning to Eq. (9.47), and substituting Eq. (9.48) into it, we obtain
the following:
(g//^)o _ d (dG/du)oi dt
o L\3x/o \Su'o(df/du)o dt (df/du)0]
Equation (9.49) states the resulting effect on S for a perturbation of Ax and Au.
However, if x° and u° do indeed result in an optimum S°, then AS must be zero for a
perturbation of Ax. Therefore, it is necessary that, during the interval 0 < t < T,
/dG\ _ /5G\ (df/dx)„ __ d (dG/du)0 _
\dx /o \du Jo (df/du)0 dt (df/du)0
this is the well-known Euler-Lagrange differential equation.
(9.50)484 Optimal Control Theory and Applications 9.S
The results of this exercise indicate that we have to solve the Euler-Lagrange
differential equation which cannot, in general, be integrated analytically. In addition,
if numerical techniques are used, one finds that the Euler-Lagrange equations are
unstable.
Let us illustrate the application of the calculus of variations to a simple problem
that is easily solvable [11]. Consider the open-loop system illustrated in Fig. 9.5.
It is desired to control the state between x(0) and x(T) in order that the performance
criterion, which penalizes (in ISE sense) u and the deviation from the reference x = 0,
S =JJ(x2 + u2) dt (9.51)
is minimized. For this simple system, the state equation is given by
x — f(x, u, t) = u. (9.52)
In addition, to obtain the Euler-Lagrange equation, we need to determine the follow￾ing:
= 2x, (9.53)
wX /o
= 2u, (9.54)
/0
ay
r- = 0, (9.55)
ox
df .
= 1. (9.56)
ou
Substituting Eqs. (9.53) through (9.56) into Eq. (9.50), we obtain the following
Euler-Lagrange equation:
x - u = 0. (9.57)
For this simple system, since Eqs. (9.52) and (9.57) are linear, the Laplace transforma￾tion can be used. We have
sX(s) - x(0) = U(s), (9.58)
X(y) - [sU(s) - »(0)] = 0. (9.59)
Observe from Eqs. (9.58) and (9.59) that we must obey the constraints given by x(0)
and m(0). Since we know x(0) and x(T) but not w(0), we will proceed by using only the
one initial condition we know, x(0). The value of u(0) will be eliminated later on by
Fig. 9.5 A simple integrating system.9.6 Dynamic Programming 485
attempting to meet the final condition x(T’). Solving for Y(s) from Eqs. (9.58) and
(9.59), we obtain the expression
sx(0) + t/(0)
*(«) = ■ • (9.60)
s' — 1
Taking the inverse transform, we have
x(t)° — x(0) cosh t + w(0) sinh t. (9.61)
The value of w(0) must now be obtained in order that the state x(T) is reached.
Therefore,
x(T) = x(0) cosh T + t/(0) sinh T. (9.62)
Solving for u(0), we obtain
tt(0)gxm-.v(0)eoshT (963)
sinh T
Substituting Eq. (9.63) into Eq. (9.61), we obtain the final expression for x(t)°:
= x(0) cosh , + r*< r>- *< 0>‘;°sh7~| sinh (9.M)
L sinh T J
In addition, we can determine the corresponding optimal control from Eq. (9.52):
u(t)° = x(0° = x(0)sinh t + ----- x(0) cosh T~l f (9.65)
L sinh T J
In this example, notice that the Euler-Lagrange equation turned out to be linear
because the state dynamic equations were linear and the performance was quadratic.
In addition, the Euler-Lagrange equation resulted in an open-loop optimal control
solution and is based on a priori knowledge of the final state and the control interval.
In general, design of control systems by means of the calculus of variations
usually leads to the solution of a two-point boundary-value problem. Usually, one is
faced with a numerical trial-and-error solution to a resulting nonlinear differential
equation. The calculus of variations is not commonly used by the control system
engineer for designing optimal control systems since it cannot easily handle “hard”
constraints such as |m| < wmnx. Its use is limited to control systems that are linear,
have no constraints on x and u, and have a quadratic performance criterion.
9.6 DYNAMIC PROGRAMMING
The concept of dynamic programming [4, 8, 12, 13], as originally developed by
Bellman, is based on the principle of optimality and the imbedding approach. The
principle of optimality states that regardless of the initial state and the initial decision,
the remaining decision must form an optimal control policy with respect to the state486 Optimal Control Theory and Applications 9.6
resulting from the first decision. The imbedding approach is one in which an optimal
decision problem is imbedded in a series of smaller problems that are easier to solve.
A multistage decision process is an example of a problem that can be simplified
considerably by applying the principle of dynamic programming. Utilizing the
imbedding approach and the principle of optimality, the total return of an A-stage
decision process is reduced to the problem of solving a sequence of N single-stage
decision processes. This permits a simple, systematic solution to the problem.
In practice, dynamic programming is basically an optimization procedure that
proceeds backwards in time. The solution is computed first over the last stage of the
process, and successive solutions are computed for the remaining stages until the
entire solution is obtained.
The principle of optimality results in a partial differential equation, known as the
Hamilton-Jacobi equation, whose solution results in the optimum control policy.
The Hamilton-Jacobi equation can be derived from the definition of the performance
criterion defined by Eq. (9.2):
T
G(c(t), u(z), r(t), t) dt. (9.66)
Let us assume that the optimal control input u°(t) has been determined fora reference
signal r(t) and a final time 7. Therefore, the minimum value of this performance
criterion .8’° is a function only of the initial state c(/0) and the initial time t0. From
Eq. (9.66), we obtain S° as follows:
S° = S°(c(t0), t0) = min
u(i)
r f G(c(t), u(t), r(t), t) dt
Iv to .
(9.67)
Applying the imbedding approach and assuming that the last stage of the process
occurs between t' and T, Eq. (9.67) may be rewritten as
5",(c(to)ffo) = min
u(Z)
[£c(‘w, u(t), r(t), t) dt + (9.68)
Applying the principle of optimality over the last stage which occurs from t' to T,
Eq. (9.68) can be rewritten as
S°(dJo), to) = min
u(t)
I" f G(c(0, u(t), r(t), t) dt + S°(c(t'), t'
L-' (o (9.69)
The first term of Eq. (9.69) may be approximated as
u(t), r(0, t)dt [G(c(t), u(r), r(t), t)](=<o At, (9.70)
by defining
t — to + &t. (9.71)9.6 Dynamic Programming 487
Expanding the second term of Eq. (9.69) by means of a Taylor series about the point
c(r0), t0 yields
S°(c(t'), t') = S°(c(t0), t0) + Ac, + • • • + Acn + At. (9.72)
de, dcn dt0
Substituting Eqs. (9.70) and (9.72) into (9.69), we obtain the following relationship:
S°(c(t0), = min [G(c(t0), u(t0), r(t0), t0) At + S°(c(t0), t0)
as0. as0. as0. ~i
+ — Ac, + ■ • ■ + kcn + — At . (9.73)
Taking S°(c(t0), r0) outside the minimization operation (since it is not a function of
u(t0)), dividing both sides of Eq. (9.73) by At, and letting At -> 0, we obtain
min fG(c(t0), u(t0), r(t0), t0) + c\ + • • • + |^- c„ + ^-1 = 0. (9.74)
u(f0) L de, ocn ot0 J
Assuming that u°(t0) minimizes the bracketed term, Eq. (9.74) can be rewritten as
as0 " as,° T- + 2 T- Q + G«'o), u°(t0), r(t0), to) = 0. (9.75)
OtQ 1=1 oct
Since is a function of c and u°, we may write this relationship as
q=Z(c,u°). (9.76)
Substituting Eq. (9.76) into (9.75), we obtain the Hamilton-Jacobi equation:
a <s° ” a
+ 2 u°) + G(c, u°, r, to) = 0. (9.77)
Ot0 i=l OCi
The Hamilton-Jacobi equation is a partial differential equation whose boundary
conditions can be obtained from the definition of the performance criterion (see Eq.
9.66) and from the relationship
S°(c(f0), t0) = [TG(c, u°, r, t) dt. (9.78)
If c(T) does not contain an impulse function at t — T, then the boundary condition
is given by
lim S°(c(t0), t0) = 0. (9.79)
If c(T) contains an impulse function at t = T, then the boundary condition is given by
lim S°(c(t0), to) = [G(c, u°, r, t)](=r. (9.80)
t(j~*’1'
The solution to the Hamilton-Jacobi equation, with appropriate boundary conditions,
results in the optimal control policy. However, since the Hamilton-Jacobi equation488 Optimal Control Theory and Applications 9.6
was derived from the imbedding approach and the principle of optimality, it represents
only a necessary condition for optimality. For example, if there are constraints on the
inputs or outputs to the system, these constraints must also be considered as necessary
conditions for optimality.
As an example of solving an optimal control problem by means of dynamic
programming, a simple regulator problem will be considered [14], The objective in
the regulator problem is to maintain the output at a fixed value. Therefore, the input
r = 0. For this problem:
1. The controlled process is a first-order linear plant whose dynamics are given by
c = Ac + Bu. (9.81)
2. The performance criterion is given by
S = f c2 dt. (9.82)
Jo
3. The controlled input satisfies the following relationship:
-1 < u < 1. (9.83)
From Eq. (9.77), the scalar Hamilton-Jacobi equation is
—
a c" a c°
+ ^-/(c, u°) + G(c, u°, r, t0) = 0. (9.84)
Gtg t/C
From the statement of the problem, the terms of this equation are:
as0
7- = 0, (9.85)
f(c, u°) = c = Ac + Bu, (9.86)
G(c, u°, r, tQ) = c2. (9.87)
Substituting these equations into Eq. (9.84), we obtain
dS° — (Ac + Bu) + c2 = 0. (9.88)
de
In order to minimize this expression with respect to u, the constraint
-1 < u < 1 (9.89)
must be incorporated into the solution. Therefore,
3 raeo
—— (Ac + Bu) + c2 = min —- Bu
oc J u(i> L de
(9.90)9.6 Dynamic Programming 489
Clearly, the optimal control must satisfy
ac0
u° = 1 for — B < 0.
de
u° = -1 for —- B > 0,
de
or
I
u° = - sgn IB—).
\ de '
Substituting Eq. (9.92) into (9.88), we obtain
— Ac — B sgn B —) + c' = 0.
de L \ de / J
Simplifying this equation, we obtain
A 5S° Ac--------
de
B™
de
+ c- = 0,
or
2 A dS°
c + Ac—------
de de
= 0.
(9.91)
(9.92)
(9.93)
(9.94)
(9.95) B^
Equation (9.95) is a nonlinear partial differential equation. Except for some simple
cases, the solution for S° requires the aid of a digital computer. The resulting solution
for S° is then substituted into Eq. (9.92) in order to obtain the optimum u°.
As a second example ofsolving an optimal control problem by means of dynamic
programming, consider the following problem:
1. The controlled process is a second-order linear plant whose dynamics are given by
c + 4c + c = u. (9.96)
2. It is desired to minimize the response time so that the performance criterion is
given by
S = f00 dt. (9.97)
Jo
3. The controlled input satisfies
-1<M<1. (9.98)
By defining the states
= c, x2 = c, (9.99)
the state equations for this system are given by:
xt = x2, x2 = —— 4x2 + u. (9.100)490 Optimal Control Theory and Applications 9.7
The terms of the Hamilton-Jacobi equation (see Eq. 9.75) for this problem are
p<?'> — = 0,
at0
* . dS° . , dS°. .
2— G = — c + — (-c - 4c + u),
t=l OCi oc oc
G(x, u° r, t0) = 1.
(9.101)
Substituting these equations into the Hamilton-Jacobi equation, Eq. (9.75), we obtain
3s°. , as0. . . , , , . A —— c + —— ( — c — 4c + u) + 1 = 0.
oc oc
(9.102)
In order to minimize this expression with respect to u, the constraint
must be incorporated into the solution. Therefore,
min uU)
as0. as0. .. . — c + — (-c — 4c + u) + 1
. OC OC
min
u(f)
Clearly, the optimal control satisfies
(9.103)
Substituting this equation into Eq. (9.102), we obtain
(9.104)
— 1 < u < 1
Equation (9.104) is a nonlinear partial differential equation which requires a digital
computer to find S°. The resulting solution for S° is then substituted into Eq. (9.103)
in order to obtain the optimum it0.
9.7 PONTRYAGIN’S MAXIMUM PRINCIPLE
In 1956, the Russian mathematicians, Pontryagin, Boltyanskii, and Gamkrelidge
developed the maximum principle [6, 8, 12, 15, 16], According to Pontryagin, the
maximum principle was derived originally from the calculus of variations (see
Section 9.5). Pontryagin’s maximum principle is very similar to the calculus of varia￾tions, and is very closely related to dynamic programming. It is possible to obtain the
maximum principle from dynamic programming by a simple change of variables.9.7 Pontryagin’s Maximum Principle 491
In this section, Pontryagin's maximum principle and an illustrative example of its
application are presented. In the following section, it is applied to the space atti￾tude control problem.
Let us assume that we have a process whose dynamics are given by
c,=/,(c, u), z = l,2, ...,m (9.105)
and a performance index
fT
S= G(c, u, r, t) dt (9.106)
Jo
which is to be minimized. The maximum principle requires that the optimal control
input u° which minimizes 5 will maximize the scalar
H = Pif^c, u) - G.(c, u, r, t0), (9.107) i=l
where the function pt is defined as
□ H
Pi=-~, i = l,2,...,n. (9.108)
Sc,-
The scalar H is called the Hamiltonian function; the vector p is known as the co-state.
From Eqs. (9.105) and (9.107), ct can also be expressed in terms of H and pit as
follows:
Ci = —, i = 1,2, ...,n. (9.109)
dpi
The necessary conditions of the maximum principle can be obtained from the
dynamic programming equations by a simple change of variables. Let us reconsider
the Hamilton-Jacobi equation (see Eq. 9.77):
OrO n o0
7^ + 2~f^ u) + 'o) = (9-110)
dt0 i=i de,
Let us define
dS°
Pi=~T~ (9I11)
Sc,
and
0^0
H = —. (9.112)
Sto
Substituting Eqs. (9.111) and (9.112) into (9.110), we obtain the following relation￾ship:
H = J a/Xc, u) - G(c, u, r, t0), (9.113)492 Optimal Control Theory and Applications 9.7
which is the basic Hamiltonian function defined in Eq. (9.107). In addition, the
relationship of Eq. (9.108) can be obtained from Eqs. (9.111) and (9.112) as follows:
pi = dh = ±i^\ = = (9.U4)
' dt0 dt0\ dcj dtodCi dcf
Therefore, the basic maximum-principle relationships, as defined by Eqs. (9.107) and
(9.108), have been derived from the dynamic programming relationship (the
Hamilton-Jacobi equation) by a simple change of variables. However, it is important
to note that this is not a proof ofthe maximum principle since this derivation assumed
the existence of the derivatives dS°ldci and dS°/dt0. On the contrary, there are many
cases where they do not exist.
As an example of an optimal control problem which can be solved by means of
the maximum principle, let us reconsider the first-order problem in Section 9.6
which was solved by applying dynamic programming. The problem involves
1. A process whose dynamics are described by
c = Ac + Bu. (9.115)
2. A performance criterion given by
S = \c2dt. (9.116)
Jo
3. A control input constrained by the relationship
-1 < u < 1. (9.117)
From the above, the valuesofu) and G(c, u, r, t0) in the Hamiltonian equation are
given by
f<S, u) = Ac + Bu, (9.118)
G(c, u, r, Zo) = c2. (9.119)
Substituting Eqs. (9.118) and (9.119) into the Hamiltonian equation (see Eq. 9.107),
we obtain the relationship
H = p(Ac + Bu) - c2. (9.120)
Applying the fundamental relationship of the maximum principle (see Eq. 9.108)
dH
Pi= ~T~ (9.121) dc4-
to Eq. (9.120), we obtain the first equation to be solved:
• SH A „
P = - — = —pA + 2c. (9.122)
oc
A second equation can be obtained from the fact that the Hamiltonian is maximized
when the performance criterion is minimized. It. was shown in our discussion of9.8 Application of the Maximum Principle to the Space Attitude Control Problem 493
dynamic programming (Section 9.6) that the performance criterion was minimized in
this problem when (see Eq. 9.92).
/ 8 S°\ w° = — sgn IB— (9.123)
\ de 1
From the definition ofpt in Eq. (9.111), we may rewrite Eq. (9.123) as
m° = sgn (Bp). (9.124)
Substituting Eq. (9.124) into (9.115), we obtain the second necessary condition
c = Ac + Bsgn (Bp). (9.125)
The solution to this optimal control problem, utilizing the maximum principle, has
Deen reduced to the solution of the nonlinear ordinary differential equations given by
Eqs. (9.122) and (9.125). In order to solve these equations, the boundary conditions
must be utilized. Note that they define a two-point boundary-value problem.
It is interesting to compare the dynamic-programming solution with that obtained
with the maximum principle. The dynamic-programming solution was reduced to the
solution of one nonlinear partial differential equation (see Eq. 9.104). The maximum￾principle solution of the same problem was reduced to the solution of two, nonlinear,
ordinary differential equations (see Eqs. 9.122 and 9.125). Although both techniques
result in equations which require digital computers for solution, the two, nonlinear,
first-order ordinary differential equations (obtained using the maximum principle) are
easier to solve than the nonlinear partial differential equation, which is a function of
two variables (obtained using dynamic programming). In practice, however, the
choice between these approaches will depend to a great extent on the particular
problem. The application of Pontryagin’s maximum principle to the synthesis of
optimum attitude controllers for space vehicles is discussed in the following section.
9.8 APPLICATION OF THE MAXIMUM PRINCIPLE
TO THE SPACE ATTITUDE CONTROL PROBLEM
Optimal control theory has been applied to a wide variety of important problems
[8, 12, 15, 17-29]. It has been used to solve problems concerning the attitude control
of space vehicles, control of traffic flow, the orbit transfer problem for interplanetary
space vehicles, chemical process control problems, and problems concerned with
communication systems. In this section, the use ofthe maximum principle for solving
the attitude control problem of various space vehicles is illustrated. The objective is
to synthesize the optimum strategy for controlling the space vehicle to satisfy a given
performance criterion.
Attitude contrql of a space vehicle encompasses a vfery wide variety of problems.
During powered flight, the attitude control system receives commands from a
guidance system and controls the attitude of the vehicle. This causes the vehicle to
pitch or yaw and results in changes in attitude and/or direction ofthe flight path. After494 Optimal Control Theory and Applications 9,8
Fig. 9.6 Attitude control via horizon scanners to establish the local vertical.
the vehicle has attained the desired orbit, it is attitude-stabilized with respect to some
reference such as the earth, sun, or the stars. During reentry into the earth’s
atmosphere, the vehicle is pitched over to the proper angle from the reference attitude
by signals from a reference gyroscope. Then the firing of a retrorocket places the
vehicle on a transfer orbit into the earth’s atmosphere. The attitude control problem
is even more complicated for manned space stations where orbit rendezvous is
required for purposes of orbital refueling, crew changes and/or satellite inspection.
This section is concerned with the attitude stabilization of a manned or unmanned
vehicle in orbit about the earth. It is to be stabilized perpendicular to the earth’s local
vertical as shown in Fig. 9.6. Consider one plane of such a space vehicle orbiting the
earth which is slaved to the local vertical via horizon sensors and gyros. A physical
model of the problem is illustrated in Fig. 9.7 and a block diagram of a typical
Vehicle inertia = J
Fig. 9.7 Attitude control problem for one plane.9.8 Application of the Maximum Principle to the Space Attitude Control Problem 495
attitude control system is shown in Fig. 9.8. The reference input position to the
horizon tracker is denoted by J? and the resultant output position of the attitude
control system is denoted by C. The rate of change ofthe local vertical with respect to
the earth is denoted by coj and the rate of the vehicle relative to the local vertical is
denoted by co2. The vehicle inertial rate, which is the sum of co1 and w2, is denoted
by cor.
Fig. 9.8 One axis of an attitude control system.
Assuming that friction and disturbing forces are negligible, the motion ofthe space
vehicle is given by the following simple second-order differential equation.
c =
By defining
u(t) = where |u(t)| < 1,
Eq. (9.126) can be rewritten as
c(z) = w(r).
(9.126)
(9.127)
(9.128)
Utilizing state-space notation, this second-order differential equation can be rewritten
as two first-order differential equations. Let
= c, c2 = c; q = c2 c2 = u. (9.129)
Then
where
c = Pc + Bu, (9.130)
p = r° n b = p fl, u = r°i. (9.130
L° °J L° d W496 Optimal Control Theory and Applications 9.8
The basic attitude control problem is to maintain the vehicle at a referenced
attitude. The desired equilibrium state for this problem is assumed to be the stable
node at the origin of the Ci<?2-plane.
In the following analysis the synthesis of the optimal attitude control system for
several practical attitude control problems is considered. For example, due to a
disturbance torque or the command of a new reference attitude, what is the best
strategy to minimize the response time of the vehicle? Other considerations may
dictate that the amount of fuel or energy be minimized. These possibilities lead to the
following problems:
1. the minimum-time problem,
2. the minimum fuel-consumption problem,
3. the minimum energy problem.
In all cases, it will be assumed that u is constrained to be 1 < u < — 1.
1. The Minimum-Time Problem Although the minimum-time problem can be solved
with conventional techniques [28], it is synthesized here, utilizing Pontryagin’s
maximum principle as an introduction to the application of optimal control concepts.
In addition, its solution is useful for comparison with the other problems which are
subsequently considered.
Since it is desired to minimize the response time of the space vehicle, the
performance Ciiterion for the minimum-time problem is given by
(9.132)
Here the loss function is unity: that is,
G(c, u, r, t) = 1. (9.133)
Substituting Eqs. (9.129) and (9.133) into the expression for the Hamiltonian, Eq.
(9.107), the following expression is obtained:
H = PiC2 + p2u - 1. (9.134)
The values ofplt p2, and c2 can be evaluated by applying Eqs. (9.108) and (9.109) to
Eq. (9.134). The results are as follows:
A = - — = o, P1 = Klt (9.135)
SH
dc2
-Pi, P2 — K2 Pit — K2 — Kit, (9.136)9.8 Application of the Maximum Principle to the Space Attitude Control Prob'em 497
where K± and K2 represent constants of integration; and
cH
cj = — = c2, (9.137)
dPi
ary
c2 = = u. (9.138)
Since the term pxc2 — 1 in Eq. (9.134) is independent ofthe input u, the maximization
of the Hamiltonian function is concerned only with
max H[p2u], (9.139)
It is seen from Eq. (9.139) that the Hamiltonian function is maximized by choosing
m° = sgn [p2]. (9.140)
Substituting Eq. (9.136) into Eq. (9.140), we obtain
= sgn [K2 - Kp]. (9.141)
The following conclusions can be drawn from this result:
1. The optimum input for minimization of the response time is piecewise constant.
2. The optimum input for minimum-time operation takes on only the values ±1.
3. The sign of the optimum input for minimum-time operation can change its value
only once
These conclusions clearly imply that the attitude control system for the space
vehicle should be bang-bang (on-off) when minimization of response time is the
performance criterion. Physically this means that accelerating and then decelerating
is the best that can be done in order to minimize the response time. The period of each
action depends on the initial conditions of position and velocity.
The phase-plane representation and optimal switching curve can be formulated
from consideration of Eqs. (9.128) and (9.129) when u■= ±1. When u = 1, the
following expressions are obtained:
c2 = 1 (9.142)
\= t +A. (9.143)
c, = t +A (9.144)
C1 = it2 + Art + A2 (9.145)
where AY and A2 are constants of integration. By completing the square, Eq. (9.145)
can be rearranged as follows:
= >(/ + A,)2 + (/12 - iAl). (9.146)498 Optimal Control Theory and Applications 9.8
Substituting Eq. (9.144) into (9.146), we obtain the following relationship:
Cl = ^1 + A3, (9.147)
where
A3 = A2 - Mt (9.148)
Equation (9.147) defines the switching curve when u = 1. Similarly, the switching
curve when u = — 1 can be obtained as
C1 = —|cf+ 46, (9.149)
where
A = A + (9.150)
The switching curves defined by Eqs. (9.147) and (9.149) define parabolas in the
CjCj-plane. The corresponding phase portrait and optimal switching line for the
minimum time system is illustrated in Fig. 9.9. The phase trajectory travels from its
initial conditions to the switching line defined by Eq. (9.147) or Eq. (9.149). At the
instant the state arrives at the switching curve, the system switches its control to the
opposite phase and remains at this value until the state reaches the stable node at
the origin. If the initial conditions are above the curve AOB, the system is under the
control of u = —1 until it reaches the arc BO. Then it switches over to the control
u — 1, where it remains until the equilibrium state is reached. When the initial
conditions are below AOB, the system is under the control of u = 1 until the state
reaches arc AO. At the instant that it arrives, the system switches to the control
u = — 1 and remains at this value until the equilibrium state is reached.
Figure 9.10 shows the block diagram ofthe optimum control system just designed.
The basic control element required has ideal relay characteristics which can easily be
implemented. The control system will accelerate and then decelerate in order to
minimize the response time ofthe attitude control system. It should be noted that the
Fig. 9.9 Phase-plane representation for the minimum-time problem.9.8 Application of the Maximum Principle to the Space Attitude Control Problem 499
Fig. 9.10 Synthesized system to minimize response time.
exact period of each phase is dependent upon the initial conditions relative to the
switching curves.
2. The Minimum Fuel-consumption Problem In this problem it is assumed that the
attitude control system is powered by a reaction jet. It is desired to minimize the fuel
consumption of the space vehicle. It is also assumed that a pure minimum fuel
consumption problem is inadequate from a practical viewpoint since it may result in
an excessive response time. Therefore, the actual practical problem considered here
is that of minimizing fuel consumption over a certain period of time.
Although response time is of secondary importance in this problem, it must be
considered. It is theoretically possible to bring the state of the system to the stable
node with an arbitrarily small amount of fuel if the response time were not bounded.
However, the response time must be considered fixed for practical systems. Therefore,
it is assumed that the total response time is limited to T seconds.
In synthesizing a meaningful optimal control system, the reaction jet system must
be understood. An important parameter used to characterize the performance of a
reaction jet engine is its specific impulse Zgp. It is defined as the ratio of the thrust F
of a hypothetical engine to a propellant flow rate d> of one pound of propellant per
second:
4P =
Fl *-
The units ofJ from this relationship are pounds of thrust per pounds of propellant
per second and are usually expressed in seconds. The specific impulse of an engine is
indicative of how effectively each pound of propellant is utilized in producing a
thrust force to the vehicle.
Since it is desired to minimize fuel consumption of the space vehicle over a
period of T seconds, the performance criterion for this problem is given by
$ = |m| dt, (9.151)
where u is defined as the propellant rate of flow and is constrained in magnitude by
Eq. (9.127). For this problem, the loss function represents a measure of the total fuel
flow rate:
G(c, u, r, t) = |m|. (9.152)500 Optimal Control Theory and Applications 9.8
Its time integral, as given by Eq. (9.151), represents a measure of the total fuel
consumed in T seconds.
Substituting Eqs. (9.129) and (9.152) into the expression for the Hamiltonian
function, Eq. (9.107), the following expression is obtained:
H = Picz + P2»2 — M- (9.153)
The values ofpx,p2, and c2 can be evaluated by applying Eqs. (9.108) and (9.109) to
Eq. (9.153). The results are the same as Eqs. (9.136) and (9.138). Since the term prc2
in Eq. (9.153) is independent of the input u, the maximization of the Hamiltonian
function is concerned only with
max H[p2u — |u|]. (9.154) u(t)
It is obvious from Eq. (9.154) that the Hamiltonian function is maximized by choosing
u as follows:
u° = sgn [p2]
u° = 0
for
for
lp2| > 1,
lp2l < 1-
(9.155)
Substituting Eq. (9.136) into Eq. (9.155), the following optimal control inputs are
obtained:
u° = sgn [JC2 - for |p2| > 1,
u° = 0 for |p2| <1. ( J
The following conclusions can be drawn from this result:
1. The optimum input is piecewise constant;
2. The optimum input can have values of only ±1 and 0.
Although Ky and K2 are not known exactly, the fact that p2(t) is a linear function
oftime (see Eq. 9.136) means that u must proceed in time as a nonrepeating sequence
of values having the form (±1,0, ±1). These conclusions imply that the attitude
control system should be bang-bang and incorporate a dead zone. This function can
be easily implemented. Physically, this means that in order to minimize the fuel
consumption over a bounded period of time, the best one can do is to accelerate,
coast at a constant velocity, and then decelerate. The periods for each action depend
on the initial conditions of position and velocity.
The phase-plane representation and optimal switching curves can be formulated
from considerations of Eqs. (9.128) and (9.129) when u = ±1 and 0. When u = ± 1,
results analogous to Eqs. (9.147) and (9.149) are obtained for the minimum-time
problem. When u = 0,
c2 = 0, (9.157)
c2 = constant, (9.158)Application of the Maximum Principle to the Space Attitude Control Problem 501
and the switching curve is a horizontal line parallel to the Cj-axis. Typical phase
trajectories for the minimum fuel-consumption problem when the response time is
bounded are illustrated in Fig. 9.11 as curves Imno and I'm'n'o. These results lead to
the conclusion that if reaction jets are used for attitude control, then a nozzle which
simply opens or closes without any intermediate settings provides the optimal system.
Fig. 9.11 Typical phase trajectories for the minimum fuel problem.
It is interesting to compare the phase trajectories of a pure minimum-fuel
problem where the response time is not bounded and that of a minimum-fuel system
where the response time is bounded. Typical phase trajectories for the pure minimum
fuel optimal problem are curves lo and I'o in Fig. 9.11. The corresponding time
response of curves Imno and lo can be obtained from an examination of the phase
trajectories. It was shown in Section 8.15 that the variation of time along a phase
trajectory can be obtained from (see Eq. 8.136)
(9.159)
The integral represents the area under the reciprocal phase-plane trajectory. A
corresponding reciprocal plot for the phase trajectories Imno and lo are illustrated in
Fig. 9.12. The points I and o are assumed to lie at infinity; this has a negligible effect
on the area under curve Imno since the area under these points approaches zero.
However, the area under the rectangular curve lo is infinity. This illustrates that a
pure minimum-fuel problem, where the response time is not bounded, results in an
infinite response time and is not very practical.
Figure 9.13 shows the block diagram of the optimal control system. The basic
control element required has the characteristics of a relay with a dead zone.502 Optimal Control Theory and Applications 9.8
Fig. 9.12 Reciprocal phase-plane plot.
3. The MinimuHb-energy Problem In this problem it is assumed that the energy
utilized in the attitude control system of a space vehicle is to be minimized. This is a
very practical problem for space vehicles utilizing momentum-exchanging devices
such as control-moment gyros, inertia wheels, fluid flywheels, and magnetic moment
devices in their attitude control systems. All of these systems utilize electrical energy
derived from such sources as batteries, fuel cells, and/or solar cells.
It is assumed that the input to the attitude control system is an electrical signal u.
In addition, it is desired to utilize a minimum amount of electrical energy over a
bounded period of time in order to accomplish a desired control. We know that the
square of the voltage utilized is proportional to power, and the time integral of power
is energy. Since the square of the control signal is proportional to the integral power
required for control, and the energy is proportional to the integral ofthe square ofthe
control signal, the minimum-energy problem can be formulated as a problem of
Fig. 9.13 Synthesized system to minimize fuel consumption over a specified period oftime.9.8 Application of the Maximum Principle to the Space Attitude Control Problem 503
minimum integral square control. The performance criterion is thus given by
CT
S= u2 dt- (9.160)
Jo
Here the loss function represents power
G(c, u, r, t) = u2 (9.161)
and its time integral, as given by Eq. (9.160), represents a measure of energy.
Substituting Eqs. (9.129) and (9.161) into the expression for the Hamiltonian function,
Eq. (9.107), we obtain
H = pxc2 + p2u — u2. (9.162)
The values ofpi,p2, and c2, can be evaluated by applying Eqs. (9.108) and (9.109) to
Eq. (9.162). Since the term prc2 in Eq. (9.162) is independent of the input u, the
maximization of the Hamiltonian function is only concerned with the expression
max H [p2u — u2]. (9.163)
It is obvious from Eq. (9.163) that two cases exist for the Hamiltonian function to be
maximized. To find the optimal value of u°, differentiation of Eq. (9.163) yields
-[p2« - m2] = 0, (9.164)
u° = p2/2.
Therefore, if |/>2| < 2, u° = p2/2. When |p2| > 2, then
u° = sgn [p2] (9.165)
results in a maximum value of the Hamiltonian function. Substituting Eq. (9.136)
into Eqs. (9.164) and (9.165), we obtain
= for |p,l < 2, (9J66)
u° = sgn [p2] = sgn [K2 - Kp] 1 for |p2| > 2.
These results indicate that the control is linear over a fixed range and saturates
whenever |p2| > 2. These conclusions imply that the attitude control system for the
space vehicle should contain a limiter whose output is linear for small signals and
saturates for large signals in order to minimize energy.
Figure 9.14 shows the block diagram of the control system. The basic control
element required is a limiter which will operate linearly until saturation is reached.
The attitude control problem has been used as a convenient illustration of the
application of Pontryagin’s maximum principle. The results of this analysis indicated504 Optimal Control Theory and Applications
Fig. 9.14 Synthesized system to minimize energy over a specified period of time.
that the resulting structure of the control element was in the form of a relay to
minimize the response time, a relay with a dead zone to minimize the fuel consumption
over a bounded period of time, and a limited linear amplifier to minimize energy over
a bounded period of time.
PROBLEMS
9.1 Determine whether the control system illustrated in Fig. P9.1 is controllable and
observable.
Figure P9.1
9.2 Repeat Problem 9.1 for the control system illustrated in Fig. P9.2.
Figure P9.2Problems 505
9.3 Repeat Problem 9.1 for the control system illustrated in Fig. P9.3.
Figure P9.3
9.4 Repeat Problem 9.1 for the control system illustrated in Fig. P9.4.
Figure P9.4
9.5 Consider a simple open-loop system that consists of an integration and an amplifier
having a gain of 2. It is desired to control the state of this system between x(0) and x(T) in
order that the performance criterion
S = (4x2 + 2w2) dt
Jo
is minimized. Using the calculus of variations, determine the optimal control w°(r) which
can achieve this.
9.6 Repeat Problem 9.5 with the performance criterion changed to
[T
S = (2x2 + 4m2) dt.
Jo
What conclusions can you draw from your results? y
9.7 Using dynamic programming, determine the optimal control policy for a second-order
system where
c + 4c + c = u,
s - r *■
Assume the magnitude of the controlled input must be less than or equal td unity.506 Optimal Control Theory and Applications
9.8 Repeat Problem 9.7 using the maximum principle.
9.9 Using dynamic programming, determine the optimal control policy for a third-order
system where — 1 < « < 1 and
"c + 2c + 6c = 4 + it,
f*<x>
S = dt.
Jo
9.10 Repeat Problem 9.9 with the dynamics given by
c + 2c + 6c + 4c = u.
9.11 Using the maximum principle, determine the optimal control policy for a third-order
system where — 1 < u < 1 and
"c + 2c + 6c = 4 + u,
9.12 Repeat Problem 9.11 with the dynamics given by
"c + 2c + 6c + 4c = u.
9.13 The APOLLO 11 mission, in which Astronauts Neil Armstrong and Edwin Aldrin
successfully soft-landed the Lunar Excursion Module (LEM) on the lunar surface, was a
historic event. Figure P9.13(a) is a photograph of the LEM vehicle, taken by Astronaut
Michael Collins from the Apollo Command Module window, after they separated. The
problem of synthesizing an optimal control policy for minimal fuel thrust, during the
terminal phase of a lunar soft-landing mission, is one that can best be solved using modern
optimal control theory [31], Let us first look at this problem from the basic physics involved
in a lunar soft landing as shown in Fig. P9.13(6). It is assumed in this problem that the motion
of the vehicle is vertical and subject to the following conditions:
a) The only forces acting on the vehicle are its own weight and the thrust which acts as a
braking force.
b) The moon is flat in the vicinity of the desired landing point.
c) The propulsion system is capable of a mass-flow rate, m, between zero and an upper fixed
limit of a:
— a < < 0.
On these assumptions, the motion of the vehicle is governed by the relation
Km
x ---------------g,
m s’
where
x — altitude,
m = total mass,
m = mass flow rate < 0,
g = acceleration of gravity at the surface of the moon,
K = velocity of exhaust gases = constant > 0.Problems 507
(a)
(b)
Fig. P9.13 (a) Apollo II: Astronauts Neil Armstrong and Edwin Aldrin are inside the
lunar module separated from the Apollo command module. (Official NASA Photo)
(b) Forces acting on vehicle.508 Optimal Control Theory and Applications
In addition, system performance is based on the following criterion:
rr
S = w(t) dt.
Jo
Utilizing the maximum principle, determine the form of the optimal control policy.
9.14 Utilizing dynamic programming, determine the optimal control policy for a control
system where
poo
S = I (Ac2 + u2) dt,
assuming that the plant dynamics are given by
c = Ku.
and that there are no constraints on the input.
9.15 A second-order space attitude control system is characterized by the following state
equations:
A = x2,
x2 = -x2 - xx + u.
Determine the control signal u such that the system is taken from the initial state c(t0) to the
equilibrium state c(rz) = 0 in the shortest possible time. Assume that
l«WI < u.
9 16 Repeat Problem 9.15 with the state equations given by
XX = x2,
x2 = —2x2 — 4xr + u.
9.17 Repeat Problem 9.15 with the state equations given by
Xi = x2,
x2 = —4x2 + 4xj 4- u.
9.18 Determine the optimal control policy for a control system whose performance criterion
is given by
CT
S = (u + c2) dt,
Jo
and whose plant dynamics are given by
c = —c + 4«.
Assume that the magnitude of the input < 10. Solve using the maximum principle.
9.19 Aquaculture, the science of farming and husbandry of fresh water and marine or￾ganisms, is a field where optimal control theory has recently been applied for optimizing
its operation [32], An optimal policy for the raising of Maine lobsters has been developed.
Experimental results indicate that Maine lobsters take from five to eight years to reach
maturity when raised in their natural environment, while lobsters raised in water held at
70° F can reach maturity in two years. It has been shown that lobster growth is a functionProblems 509
of temperature and lobster weight. When the costs of heating the water and maintaining
the lobsters are included, the total expense for raising lobsters can be treated as an optimal
control problem. The differential equations describing growth and cost of raising lobsters
are given by the following:
W = K0W°(U - Uor for l/0 U « (7max,
W = O for all other temperatures,
L = K,W(U - Uo) + K2W + K3,
where
W = weight of the lobster (state variable),
[7 = water temperature for the lobster,
C/o = empirically determined zero growth temperature,
t^max = maximum practical temperature for growing lobsters,
L - cost of raising lobsters (loss function).
The values Ko, a, and m are constants and Kx, K2, and K3 represent estimates of cost.
a) Write the expressions for the Hamiltonian function and for the co-state vector for this
aquaculture temperature control system.
b) Assuming that m is greater than unity, determine the optimal control temperature, U°.
What kind of temperature control system results?
9.20 Almost all agricultural crops suffer damage caused by certain prey (insects) that eat
or otherwise destroy the crop. Nature keeps these pests in check by subjecting them to 
the role of prey, with respect to other insects that act as their predators. Predators usually
cause little crop damage. Man, however, has tried to control pests by utilizing insecticides
that are lethal not only to the prey but to their predators as well. The unfortunate side
effects of such control programs over the past are now being realized and analyzed by
those concerned with the environment. Control engineers are entering the ecological
domain in order to guide future pest-control programs. Any control attempt should start
first with a model of the biological control system. By utilizing a biological model of the
ecological environment, the effects of human control can be examined. Most prey-predator
systems can be modeled by the following Lotka-Volterra equations [33]:
= AN, - BN,N2,
= -CN2 + DN,N2l at
where N, and N2 are the instantaneous populations ofthe prey and predators, respectively,
and A, B, C and D are all positive constants. This model can be simplified by nondimen￾sionalizing all the variables and eliminating all constants except one:510 Optimal Control Theory and Applications
jy, = A
1 2r B’
1
Z' = A’
The resulting equations are as follows:
- X2),
= x2(x, - K).
ar
The result of human control on this biological control system is to decrease the growth
rates of both prey and predators. Representing the human control effort as u, which has
the physical significance of using traps and chemical spray (insecticides), then
dxx ,
-j- = x,(l - x2) - uxXt
= x2(x, - K) - eux2, dr
where e is a constant proportional to the relative effectiveness of the control used on the
predators as compared with that used on the prey. In order to determine an optimal
control strategy, the following loss function has been proposed:
G = (ar, 4- u).
Its significance is that it assumes the two factors associated with the cost of the con￾trol program are those associated with the presence of the pests and those associated
with using control—social and economic. Utilizing the Maximum Principle, determine
the optimal control law for this biological system. Explain your result. Assume that
0 U Wmax *
9.21 Optimal control systems based on a quadratic performance criterion, which were
discussed in Section 9.2 (see Eqs. 9.3, 9.4, and 9.5), are very frequently used in practice
by the control system engineer. Consider a system with an initial displacement
x = Px, x(0) = c,
in which it is desired to minimize the quadratic performance criterion
5 = xTQx dt,
Jo
where Q is a positive-definite (or positive-semidefinite) real matrix. If the eigenvalues of
the companion matrix P have negative real parts (P is stable), then it can be shown that
a matrix A exists which can be found from the following relationship that it satisfies:
PTA + AP = -Q.References 511
In addition, since all ofthe eigenvalues of P have real parts, then x(°°) -> 0 and it can also
be shown that the performance criterion can be obtained in terms of the initial condition
x(0):
5 = xr(0)Ax(0)
It is desired to adjust the damping factor, for the control system shown in Fig. P9.21
in order that the integral of the square of the error (ISE) performance criterion is mini￾mized. Using this approach, determine the value of £ for this second-order system in order
that the following performance criterion is minimized when the control system is subjected
to a unit step input:
J
1*00 poo
erQe dt = e2(t) dt,
o Jo
where
Assume that the system is initially at rest. Compare your results with the value obtained
using classical techniques and discussed in Section 5.6.
Figure P9.21
REFERENCES
1. D. McDonald, “Nonlinear techniques for improving servo performance,” in Proceedings
ofthe National Electronics Conference, Vol. 6, pp. 400-21 (1950).
2. C. S. Draper and V. T. Li, Principles ofoptimizing controlsystems and an application to
the internal combusion engine, Am. Soc. Meeh. Engrs., New York (September 1951).
3. G. Leitman (Ed.), Optimization Techniques, Academic, New York (1962).
4. L. A. Zadeh and C. A. Desoer, Linear System Theory—The State Space Approach,
McGraw-Hill, New York (1963).
5. R. E. Kalman, The Theory of Optimal Control and the Calculus of Variations, RIAS
Technical Report 6-13, Baltimore, Maryland (1961).
6. R. E. Kalman, “On the general theory of control systems,” in Proceedings of the First
International Congress ofAutomatic Control, Moscow (1960).
7. R. E. Kalman, Y. C. Ho, and K. S. Navendra, “Controllability of linear dynamical sys￾tems,” Contribution to Differential Equations 1, 189-213 (1961).
8. S. M. Shinners, Techniques ofSystem Engineering, McGraw-Hill, New York (1967).
9. E. G. Gilbert, “Controllability and observability in multivariable control systems,” J.
Control, Series A 1, Society for Industrial and Applied Mathematics, 128-51 (1963).512 Optimal Control Theory and Applications
10 J. T Tou, Modern Control Theory, McGraw-Hill, New York (1964).
11. O. I. Elgerd, Control Systems Theory, McGraw-Hill, New York (1967).
12. R. E. Bellman, Dynamic Programming, Princeton University Press, Princeton, N.J. (1959).
13. R. E. Bellman, Applied Dynamic Programming, Princeton University Press, Princeton,
N.J. (1962).
14. P. H. Dosik, “Synthesis ofoptimal control systems,” Electro-TechnologyTS, 36-43 (1965).
15. V. G. Boltyanskii, R. V. Gamkrelidge, and L. J. Pontryagin,” The theory of optimal proc￾esses, I. The maximum principle,” Izvestiya Akad. Nauk SSR., Ser. Mat. 24, 3 (1960).
16. L. J. Pontryagin, “Optimal control processes,” USP Mat. Nauk 14, 3 (1959).
17. E. L. Peterson, Statistical Analysis and Optimization ofSystems, Wiley, New York (1961).
18. B. Friedland, “The structure of optimum control systems,” ASME Trans., Series E,
J. ofBasic Eng. 84, 1-11 (1962).
19. E. B. Lee, “Mathematical aspects of the synthesis of linear minimum response time
controllers,” IRE Trans. Automatic Control AC-5, 283-90 (1960).
20. M. Athanassiades and O. J. Smith, “Theory and design of high order bang-bang control
systems,” IRE Trans. Automatic Control AC-6, 125-34 (1961).
21. L. W. Neustadt, “Time-optimal synthesis with position and integral limits,” J. Math.
Analysis Applications 3, 406-27 (1961).
22. I. Flugge-Lotz and H. Marback, “The optimal control of some attitude control systems
for different performance criteria,” in Proceedings of the 1962 Joint Automatic Control
Conference, pp. 12-1-1 to 12-1-12.
23. B. Friedland, “The design of optimum controllers for linear processes with energy
limitations,” in Proceedings ofthe 1962 Joint Automatic Control Conference, pp. 12-4-1 to
12-4-12.
24. A. B. Pearson, “Synthesis of a minimum energy controller subject to an average power
constraint,” in Proceedings ofthe 1962 Joint Automatic Control Conference, pp. 19-4-1 to
19-4-6.
25 M. Athanassiades, “Optimal control for linear time invariant plants with time, fuel, and
energy constraints,” Trans. AIEE 81, 321-25 (1962).
26. M. Athans, P. L. Falb, and R. I. Lacoss, “Time-, fuel-, and energy-optimal control of
nonlinear norm-invariant systems,” IRE Trans. Automatic Control AC-8,196-202 (1963).
27. S. M. Shinners, “Optimal and adaptive control systems,” Electro-Technology 74, 63-80
(1964).
28. T. M. Stout, “Effects of friction in an optimum relay servomechanism,” Trans. AIEE
72, 329-335 (1953).
29. M. Athans, “The status of optimal control theory and applications for deterministic
systems,” IEEE Trans. Automatic Control AC-11, 580-96 (1966).
30. N. Wiener, The Extrapolation, Interpolation, and Smoothing of Stationary Time Series,
MIT Technology Press, Cambridge, Mass. (1949).
31. J. S. Meditch, “On the problem of optimal thrust programming for a lunar soft landing,”
IEEE Trans. Automatic Control AC-9, 477-84 (1964).
32. L. W. Botsford, H. E. Rauch, and R. A. Shiesser, IEEE Trans. Automatic Control
AC-19, 541-43 (1974).
33. T. L. Vincent, “Pest Management Programs via Optimal Control Theory,” in Pro￾ceedings of the 1972 Joint Automatic Control Conference, pp. 658-63.APPENDIX A
LAPLACE TRANSFORM TABLE
Laplace transform, F(s) Time function,/(r), t > 0
1 <5(t0), unit impulse at t = t0
1
U(t), unit step function
s
1
72
t
2
73
t2
n\
sn+l I
1_ e~at
5 + a
1 e~at — e~bt
(s + a)(s + b) b — a
1
(s + a)n (»-1)1
s + a
-7T--—7 [(a - a)e-at - (a - b)e~bt}
(s + a)(s + b) (b - a)
1 —at q & t
4. J_______________
(j + a){s + b)(s + c) (b — a)(c — a) (c — b)(a — b) (a — c)(b — c)
CD sin mt
s2 4- a>2
5
cos cot
J2 + a>2
CD a>te~'°l
(s + to)2
1
(1 + Ts)n
_____________________Tn(n - 1)!___________________
513514 Appendix A
Laplace transform, F(s) Time function,/(r), t > 0
1
5(1 + Ts)
1
5(1 + Ts)2
1 - e~t/T
sin cot
co
(5 4- a)2 + co2
(5 + a)
(s 4- a)2 + co2
__________________
5(52 4- 2£con5 4- co2)
________ __________
s2(52 + 2£co„j + co2)
e at cos <ot
1 4- sin (co„V 1 — £21 — a)
where cos a = — £
t — — 4--------e ^0>nt sin (conV1 — £2 t — 0)
“>n ~ I2
Vl _
where 0=2 tan-1-------—
Vl - ?
s
(1 + 75)(52 + CO2)
5
(52 + CO2)2
__________ 1__________
(5 4- b)[(5 + a)2 + co2]
H 4- + COS ~ 6)
(1 4" 2 u>n) V1 4" T2a>2
n
where 0 = tan-1 <onT
1
-— t sin ant
2wn
e~bt j e~at sin (cor — 0)
{b - a)2 + co2 + co[(/> - a)2 + co2]1'2
co
where 0 = tan-1 --------
b — a
2abs
[52 4- (a 4- ft)2][52 4- (a - Z>)2]
1 4- as 4- bs2
52(1 4- T^Xl + T25)
sin at sin bt
t 4- (a - Tx - T2) 4-
b - aT1 4- Tf
7\ ~ T2
b -aT2 + T2
T. - T2
-t/T2APPENDIX B
PROOF OF THE NYQUIST STABILITY CRITERION
The Nyquist stability criterion can be derived from Cauchy’s residue theorem,
which states that
—- I g(s) ds = residues of g(s) at the poles enclosed by
2nj Jc
the closed contour C. (B.l)
Let us replace g(s) by/'(5)//(5) where f(s) is a function of 5 which is single valued on
and within the closed contour C and analytic on C. Observe that the singularities of
f'(s)/f(s) occur only at the zeros and poles off(s). The residue may be found at each
singularity with multiplicity of the order of zeros and poles taken into account.
The residues in the zeros off(s) are positive and the residues in the poles off(s) are
negative. Therefore, iff(s) is not equal to zero along C, and if there are at most a
finite number of singular points that are all poles within the contour C, then
1
2tt7
ds = Z - P, (B.2)
where
Z = number of zeros of/(s) within C, with due regard for their multiplicity of order,
P = number of poles off(s) within C, with due regard for their multiplicity of order.
The left-hand side of Eq. (B.2) may be written as
-i- f = ±; f d[ln/(s)].
2.irj J cf(s) 2ttjJc
(B.3)
In general,/(s) will have both real and imaginary parts along the contour C. There￾fore, its logarithm can be rewritten as
ln/(5) = in |/(5)| +j/f(s). (B.4)
If we assume that/(s) is not zero anywhere on the contour C, the integration of Eq.
(B.3) results in the expression
— f d[In/(s)] = [In |/(s)[ + j/fW, (B.5)
2-nj Jc 2ttj si
where and s2 denote the arbitrary beginning and end of the closed contour C as it
515516 Appendix B
is followed. Since |/(5)| returns to its initial value in completing the closed curve,
— f d[ln/(s)] = [//(sg) - //(sQ]. (B.6)
2irj Jc 2tt ----
Therefore, Eq. (B.6) can be rewritten as ■
1 f f'(s)’ 1 .
-— — ds = — X net change in angle of/(s) as s is
27TjJcf(s') 2tt
varied over the contour C. (B.7)
By equating Eqs. (B.2) ard (B.7), we obtain
Z — P = — X net change in anele of/(.$) as s is varied
2tt
over the contour C. (B.8)
Equation (B.8) states that the excess of zeros over poles of/(s) within the contour C
equals 1/2-zr times the net change in angle (i.e., equals the number of net encirclements
of the origin) of/(s) as s is varied over the contour C. Let A'be this number. Then
Eq. (B.8) can be written as
Z — P = N, (B.9)
where the contour C is traversed in a clockwise direction, and where an encirclement
is defined as being positive if it also is in a clockwise direction. The number Z must
be zero for the system to be stable.
This relationship, which is known as Cauchy’s principle of the argument, is the
basis of Nyquist’s stability criterion. To make use of this principle in applying
Nyquist’s stability criterion, let us consider the feedback control system of Fig. B.l.
Let
/(5) = 1 + G(s)H(s)
and examine the number of timesf(s) encircles the origin as 5 traverses the contour of
Fig. B.2. (It is assumed that there are no poles on the imaginary axis, except at the
origin.) Observe that the origin of/(s) corresponds to G(s)H(s) = —1. Therefore, if
G(s)H(s) is plotted for the contour of Fig. (B.2), the number of times that G(s)H(s)
encircles the point —1 + jO equals the number of zeros minus the number of poles of
1 + G(.s)77 (5) for 5 in the right half-plane.
H(s) <■
C(s)
Figure B.lAppendix B 517
Figure B.2
Let us examine the contour of Fig. B.2 in detail. Since
iim |G(s)H(s)| = 0 (B.10)
J—*00
for all physical systems, the points along the infinite arc ABC contract to the origin
co = 0. Along the small semicircle about the origin, let
s = reie = c + jco. (B.ll)
Since G(s)H(s) is usually a rational function with a denominator of higher power than
that of the numerator, then
G(s)H(s) = lira G(re>6)H\(re’9) (B. 12)
r—*0
will map into a segment of an infinite circle. Along the imaginary axis, 5 = jco, so
that we are concerned with G(Jco)H(jco). Since G(—jco)H(—jco) is a conjugate of
G(jco)H(jco), the two functions are symmetric about the real axis and G(—jco)H(—jco)
is a reflection of G(jco)H(jco) about the real axis. Therefore, it is only necessary to
plot G(ja>)H(jco) from co = 0 to co.
Therefore, N can be determined by plotting G(joo)H(jco) and observing the
number of encirclements of the —1 + jO point; P can be determined by inspection
of the G(s)H(s) expression; and Z can be found by using Eq. (B.9).ANSWERS TO SELECTED PROBLEMS
CHAPTER 1
1.1 An electrical signal proportional to the difference between the desired heading (gyro￾scopic setting) and original heading is amplified by the power amplifier. The amplified
signal drives the motor which turns the rudder until the desired heading and actual heading
of the ship are in agreement, and the corresponding electrical signal that is proportional to
the difference between these two headings is zero.
1.2 The rudder’s positioning can be made into a closed-loop control system by fastening a
resistor in a similar manner as the resistor that is fixed to the ship’s frame. An electrical
feedback signal can then be obtained of the actual position, which can be appropriately
compared with that of the desired, or reference, position.
1.3 If the reference temperature of the thermostat is changed, the reference input to the
control system changes, and an electrical error signal results. The electric hot-water heater
will then change the temperature of the water until the difference between the reference input
and actual temperatures is zero.
1.4 A change in the ambient temperature surrounding the tank manifests itself as a disturb￾ance input within the heating control system. The explanation of the system’s resulting
control action is similar to that discussed in the book for a disturbance occurring in an
automatic speed control system (see Fig. 1.9).
1.6 The speed of an internal combustion engine can be varied by adjusting the spark
setting and fuel-air mixture. By utilizing a tachometer to feed back an electrical signal
proportional to the internal combustion engine's speed and comparing it with a reference
voltage that is proportional to the desired speed, the spark setting and fuel-air mixture can
be theoretically adjusted to control the speed of the engine.
1.7 a) The basic system would require that the elevator’s actuating signal be proportional
to position, velocity, and acceleration. Theoretically, this could be obtained by feeding back
electrical signals proportional to position, velocity, and acceleration, and comparing these
signals with reference signals representing the desired values. In practice, this can be simpli￾fied by placing integrators properly within the control system in order that only electrical
signals proportional to position, and perhaps velocity, need be sensed.
b) Specifications must be placed on the velocity and acceleration capabilities in order
that they be limited to safe values from the passenger’s viewpoint.
1.8 Assuming that safety brakes are not utilized in the feedback control system devised,
the man entering the elevator acts as a disturbance force in the feedback control system.
The functioning of the control system’s resulting action is similar to that discussed in
Chapter 1 for a disturbance torque occurring in an automatic speed control system (see
Fig. 1.9).
519520 Answers to Selected Problems
CHAPTER 2
r 11 z<-)(o+)
2.2 a) /(s) LS + R + — - Li(0+) + — = E(s), S J
ci where/(-'(0+) = lim iff) dt
r>o+ Jo
I” dx(j) ~| 3
b) A(s)[Ms2 + Bs + K] - M\ sx{Q+) + -j-(0+) - Bx(G+) = ~2
T df){t) ~1 10a>
c) 0(s)[Js2 + Bs + A] - J S0(O+) + — (0+) - B0(O+) =
2.3 a) fA(t) = -5te~2t - 10e“2s - 0.0315e~10-48( + 10.0315e?-i 52t
b) /b(0 =
c) fc(t) = 0.5 - 0.25e-’-47( - 0.250?-° 53<
C(£) = __________________ G1(5)G2(5)G3(^)G4(5)___________________
■7 R(j) [1 + G2(s)G3(s)H3(s) + G^G^H^s) + G^s)G2(s)G3(s)ff2(s)
-G1(5)G2(s)G3(5)G4(5)H1(5)J
„ o C(s) G4(j)G2(j)G3(5)G4(s)
R(s) [1 - G2(s)G3(s)H3(s) + G3(s)G4(s)//4(s) + G1(J)G2(5)G3(j)H2(j)
-G1(5)G2(5)G3(j)G4(5)H1(5)]
__________ 1 + G2(5)G3Q)ff3(5) + G3(.s)G4(.s)H4(5)
A(s) [1 + G2(s)Gs(s)H3(s) + G3(5)G4U)H4(^) + G1(^)G2(j)G3(^)//2(j)
-G1^)G2(5)G3(5)G4(5)//1(^)]
£(s) 1 - G2(s)G3(s)Hs(s) + G3(s)G4(i)/f4(5)
2.10 ----- =--------------------------------------------- -------------------- -——---------- R(s) [1 - G20)G3(5)^3(5) + G3^)G4(^)W4(j) + G1(5)G2(5)G3W/f9(5)
-G1(5)G2(5)G3(5)G4(i)H1(j)]
, n C(s) G^G^G^G^s)
" R(s) [1 + G2(5)G3(5)H3a) + G3(5)G4(^)//4(5) + G^s)G.2(s)G3(s)H.As)
-G1(i)G2(y)G3(^)G4^)//1(,0]
C(s) G1(5)G2(5)G3(5)G4M 2.12 ----- =----- ----------------------------------------------------------------------------
R(s) [1 — G2(s)G3(s')Hs(s) + G3(i)G4(i')//4(^) + G1(s)G.i(s)G3(s)H2(s')
-G^G^G^G^H^]
, ,, E(s) 1 + G2(s)G3(5)H3(s) + G3(5)G4W/74(5) 2.1 a ----- --------------------------------------------------------------- ------------ -—-—.— /?(5) [1 + G2(s)G3(s)H3(s) + G3(s)G4(s)H4(s) + G1(.r)G2(y)G3(5)H.,(5)
-G^G^G^G^H^s)]
, , A E(s) 1 - G2(5)G3(5)H3(^ + G3(5)G4(5)//4(5)
2 14 —— ~----------------------------------------------------- ——-—-———____ __ R(s) [1 - G2WG3(j)H3(5) + G3(s)G4(5)W4(5) + G1(5)G2(5)G3(j)//9(5)
-G1(5)G2(5)G3(5)G4(5)W1(^)]Answers to Selected Problems 521
Figure A2.24
2.24 One possible solution to this problem is shown in Fig. A2.24.
2.27 a) Defining Xj = c and x2 = c, the plant dynamics become
xy ~~ x2, x2 == 2x2 X￾or in vector form
x = Px + Bu, c = Lx,
where
LoJ’
b) With Xj = c and x, = c, the plant dynamics become
Xj = x2, x2 = —2x2 — xx + A,
or in vector form
x = Px + Bu, c = Lx,
where
c) With Xj = c, x2 = c, and x3-= c, the plant dynamics become
r°i W’
= x2,
= X3>
= —2xx — 2x2 — 3x3,
or in vector form
x = Px + Bu, c = Lx,522 Answers to Selected Problems
where
B =
x =
0
0
-2
1
0
-2
0
1
-3
[1 0 0].
d) With x4 — c, x2 = c, and x3 = c, the plant dynamics become
==
*3>x2,
or in vector form
where
B
0
u = 0 L = [1 0 0],
"0 0 o'
0 0 0
0 0 1 A
2.28 With x4 - 01; x2 - x3 = 02, x4 = 62, x5 = 03, and x8 = 03, the plant dynamics
become
A = x2,
x2 = -cooXg + LX\I,
x3 = x4,
x
*54 == *6, L2jl,
. x6 = WgXa + £3//,
or in vector form
where
x = Px 4- Be1, 01000 o’
0 0 0 0 0 -w0
P =
00010 0
00000 0
00000 1
0 w0 0 0 0 0
0 0 0 0 0 0 ' '0'
0 1/Z 0 0 0 0 £4
6 = 000000
0 0 0 1/700 , U =
0
Z,2
000000 0
0 0 0 0 0 1/Z ^3Answers to Selected Problems 523
2.30 With Xj = v and x2 — v, the plant dynamics become
A = x2,
A = —Xj + «(1 — Xi)x2.
2.32 The differential equation of the system is given by
c + 4c + c = r(f).
With Xj = c and x2 = c, the plant dynamics become
or in vector form
A = x2, x2 = —Xj - 4x2 + r(r),
where
2.43
0
-1
x = Px + Br(t)
"1 7 + 0.00305c-6-86' - 7.3e-014'
0(?) = 0 -0.0209c-6-86' + 1.02c-014'
0 0.149c-6-86' - 0.149c-014‘
1 + 0.0217e-6-86' - 1.065c-014'"
—0.149c-6-86' + 0.149c-014'
1.02c-6-86' - 0.0208c-014'
P =
1
-4 ’ M
L^J
JHAPTER 3
3.1 a) /(0 =
B1M2
:2 + k3
M2K}3. +A dy{t)
+ Kiy(t)
b)
y(s)
F(s) B1M2
----------- s +
k2 + k3 1
MAfj “I + K2 + X3J
s2 + 3}$ +
3.2 b) F(s)
Y(s) _ ___________________________________________________________
[ABCD - AB(B
(B
3s
1S
+
+
K
KJ(B
a)2 -
2s
AD(B
+ *
2
2s
)(B+35X2+)2 ^3) -
CD^s + KJ1 ’
where
+ (B,s + K^Btf
+ *3)21
3.3 b)
= Mrs2 + B^
= m2s2 + (A
= M3s2 + (B2
= Mts2 + B3s
(K2 + B2s)2 - X(s)Y(s)
+ B^s
+
(K. + K2),
{K2
+ ^3), T(5) f>(s) _ ______________________________________________
W(s)[(K2
+B2)2 -X(s)r(j)]+
Y(s)(K1 + B.s)2 ’
where
lY(s) = J1S2 + B1S + Klt
A
B
D 3
X(s) = J2s2 + (A + B2)s + (Kr + A'.).
y(s) = J3s2 + (B, + B3~)s + (K2 + X3).524
3.4
3.5
3.7
3.8
3.1]
3.13
3.14
3.15
Answers to Selected Problems
d20o0 BdO^t) K K'de^t)
a) dt2 + J dt + J 0o(Z) J dt
W = (K'lJ)s
e^s) s2 + (Ms + KIJ '
OqW =_______________9.43______________
a) Ef(s) 5(1.115 + l)(0.2275 + l)(0.0285 + 1)
Defining the following terms
Tf — LfjRf, y" = B(Rg 4- Rm + R)Rf]KTKe,
T'' = (Lg + Lm)/(Re + Rm + /?), r ym = BKgR[KTKe,
To = JK„RlKTKe, K = J(Rg + Rm + R)RflKTKe,
„ „ d^(f) „ „ „ „ d3e0(t) a) TmTaTf-^ + [Tm(Ta + Tf) + y"TaTf]~^
„ „ ,, d2e0(t) „ d0o(t) K.,
+ VK + /(r" + Tf) + To + Lf] + [y" + y'" + /?,] = -3 ef(t)
W =___________________________KIK______________________________
J Ef(s) {StKKTfss + \T'm(K + Tf) + y"KTf]s2
+ [K + y”(K + Tf) + To + Lf]s + y” + y'" + /?,]}
- y'
(Ri + -TaTms2 - (K + yTa)s + a_!_
■^2
TaTms2 + (T" + yTa)s + (/ + 1
ejs) + J?.2I b) =-----------
Ea(s)
where
Ta = LCF/RCF, Tm = JRCF/KeKT, y = ,
T> _ — (R1IR2)Rac] , _ J[RCf +
w IZ"
, _ — (Ri/R'itRjp] /> E^R-cf + R.-tc^
V ~ Mt ’ " = Mt '
Cis) =_________________________ (MVmWQ/dr)________________________ _
/?(5) [Vsl(K;iVI„)](Ms'i + Bs + K) + (1/V;„)(Z, — dQ/dP)(Ms2 + Bs + K) + s '
= 2.29
£c(5) 5(0.01025 + 1) ’
0o(s) = K'm
Eds) s(Tms + 1) ’
where ,
K'e=NKe,
T, = Aotal K = N2Kn
R R-n Aotal = JmotorN2 + J.,.
0o(s) 0.0636
M) “ 5(0.01025 + 1) ’Answers to Selected Problems 525
CHAPTER 4
4.1 a) = 47.3 rad/sec, £ = 1.028
b) percent overshoot = 0, time to peak = oo
c) The error as a function of time can be plotted from the following expression:
e(t) = 2.62e-37 2i - 1.63e~6O-2{.
46 a) CC?) =
d R(s) s2 + Vq Krs + qKA
b) wn = 8 rad/sec, £ — 0.5
c) maximum percent overshoot = 16.4%, time to peak = 0.452 sec.
CHAPTER 5
5.1 a) = 1
rr 1
b) Sk* ~ ~ 10-3s2 + 10 -3.s- + 1
T s2 + s
c) Sg = s2 4- s 4- 1000 ’
s3 4- 182s2 4- 8200s
5.2 a) SOi = ^3 + )82i,2 + g20(k + 2000
s3 4- 102s2 4- 200s
b) = s3 4- 182s2 + 8200s + 2000
-(80s2 4- 8000s)
C) Sh = s3 4- 182s2 4- 8200s 4- 2000
d) stKz = 1
e) In the vicinity of a> = 1: Sq^, SR,
5.6 a) 4, b) infinity.
5.8 a) zero b) 2.4 c) infinity.
5.11 a) On the assumption that JL » JmN2,
C(s) 2.1
~ E(7) ” s(0.11s + 1)
b) wn = 4.31 rad/sec; £ = 1.03
c) 0%; oo sec d) zero e) 0.476 f) infinity.
5.17 JCj = 0.112, ^i=0.77, £j=4.36.526 Answers to Selected Problems
CHAPTER 6
y(» i
6-1 a) X(jw) “ /1(»2 + B(Ja>) + c
6.3 a) stable b) unstable with 2 poles in right half-plane c) stable d) stable.
6.8 C + 0.3 — A > 0, T - B + D > 0.
6.9 a) unstable with 2 poles in right half-plane
b) unstable with 2 poles in right half-plane
c) unstable with 2 poles in right half-plane
d) unstable with 2 poles in right half-plane
6.12 a) unstable with 2 poles in right half-plane
b) unstable with 2 poles in right half-plane
c) stable.
6.14 a) Pertinent characteristics of the Bode diagram are as follows:
1. Crossover frequency = 6.3 rad/sec
2. Phase margin = —13°
3. Gain margin — —5.3 db.
c) Pertinent characteristics of the Bode diagram are as follows:
1. Crossover frequency = 2.7 rad/sec
2. Phase margin = —26°
3. Gain margin = — oo.
6.15 a) phase margin = 42°, gain margin = 14 db
b) phase margin = 43°, gain margin = 14 db
c) The difference in phase margin obtained in (a) and (b) is due to the straight-line
asymptotic approximation used to find it in (b)
d) K„ = oo, Kv = 2,Ka = 0
e) 2.5 rad.
6.17 b) crossover frequency = 3.8 rad/sec, phase margin = —10°, system is unstable
c) Kp = co , Kv = 10, Ka = 0
d) 4 rad.
6 19 b) Ka = 45 c) System is unstable.
6.22 b) K = 9.9
c) crossover frequency = 15 rad/sec, phase margin = —32°.
6.24 c) cop = 3.9 rad/sec, Mp = 7.0 db d) No.
6.25 c) = 2.5 rad/sec, Mp = 1.25 db d) No.
6.26 a) The Bode diagram indicates a crossover frequency of 23.5 rad/sec and a phase
margin of 21°
c) = 23 rad/sec, = 9 db
d) No.
6.27 a) K = 1.91 b) System is unstable.
6.28 b) Mv = 1.8, = 7.2 rad/sec.
6.29 b) System is unstable.Answers to Selected Problems 527
6.30 a) Pertinent characteristics of the root locus are as follows:
1. Root locus occurs along the real axis between the origin and —1, and between 
— 10 and — oo.
2. The asymptotes intersect the real axis at —3.67 with angles of ±60°.
3. The point of breakaway of the root locus from the real axis occurs at —0.49.
b) K = 11.
6.31 a) The root locus lies along the imaginary axis.
b) Pertinent characteristics of the root locus are as follows:
1. Root locus occurs along the real axis at the origin and between —1 and —10.
2. The asymptotes intersect the real axis at —4.5 with angles of ±90°.
3. The points of breakaway of the root locus from the real axis occur at 0, —2.5,
and —4.
4. The root locus indicates that the system is stable.
c) Pertinent characteristics of the root locus are as follows:
1. Root locus occurs along the real axis between the origin and —1, and at —4.
2. The asymptotes intersect the real axis at —3.5 with angles of ±90°.
3. The root locus indicates that the system is stable for all values of gain.
d) Pertinent characteristics of the root locus are as follows:
1. Root locus occurs along the real axis at the origin, —0.1, and between —4 and
-5.
2. The asymptotes intersect the real axis at —4.4 with angles of ±90°.
3. The points of breakaway of the root locus from the real axis occur at 0, —0.1,
and —4.5.
4. The root locus indicates that the system is stable.
6.32 Pertinent characteristics of the root locus are as follows:
1. Root locus occurs along the real axis at the origin, between —0.01 and —0.1, and
between —1.67 and — co.
2. The point of breakaway of the root locus from the real axis occurs at 0 and —3.4.
3. The root locus crosses the imaginary axis at ±j0.386.
4. The root locus indicates that the system is stable for 0.14 < K < co.
CHAPTER 7
7.1 a) The electrical network illustrated in Table 2.2, item 3, with
7?! = 690 kQ, R2 = 51 ktt, Q = 1.38 pF
and cascaded with an amplifier whose gain is 4.6 will satisfy the specifications.
b) The electrical network illustrated in Table 2.2, item 4, with
/?! = 690 kQ, R2 = 51 kQ, Cx = 1.38 pF
and cascaded with an amplifier whose gain is 4.6 will satisfy the specifications,
c) The electrical network illustrated in Table 2.2, item 5, with
Rx = 595 kll, R2 = 25 kQ, Q = 1.68 pF, C2 = 4 pF
will satisfy the specifications.528 Answers to Selected Problems
7.2 a) £ = 0.5; a>n = 4 rad/sec; maximum percent overshoot = 16.4%; steady-state
error = 0.25
b) b = 0.15
c) maximum percent overshoot = 1.5%; steady-state error =0.4
d) Add a high-pass filter in cascade with the tachometer as illustrated in Fig. 7.10.
7.5 a) Gc(s) = 1 + O.382i b) b = 0.382
0.5s -I- 1 0.05s + 1
7.7 a) Gc(s) = 0 014i + 1 Q—+ } the attenuation of 1/178.6 due to the two lead net￾works is assumed to be compensated for by increasing the gain of the amplifier by 178.6.
b) Gc(s) =
12.5s + 1
250s + 1 ‘
7.10 A lead network whose transfer function is
1 1 + s
15 1 + 03367s
results in a phase margin of approximately 45°, assuming that its attenuation of is com￾pensated for by boosting the gain of the amplifier by a factor of 15.
7.11 Same answer as for Problem 7.10.
7.13 Two cascaded lead networks are required to meet these specifications. Their transfer
function, together with the gain found in Problem 6.22, is given by
1 + 0.2s 1 + 0.1s
G.(s) = 9.9---------------------------.
1 1 + 0.01s 1 + 0.005s
The constant attenuation of 400 due to the characteristics of these two lead networks must be 
made up by an amplification of 400.
7.17 a) Gc(s) =
I -f 0.416s
1 + 0.384s
The constant attenuation of 1.08 due to the characteristics of this lead network must be made
up by an amplification of 1.08.
1 + 100s .
b) Gc(s) = j + 10,000j.
c) For part (a), a>p = 2.5 rad/sec
For part (b), cop = 0.025 rad/sec
d) The phase-lag network compensated system will be less susceptible to noise problems,
as well as requiring less power and cost. However, the phase-lag network compensated
system has a relatively very small bandwidth which may be unacceptable in some applica￾tions.
7.18 a) Gc(s)
20s + 1
1000s + 1
0.5s + 1 0.05s + 1
b) Gc(s) = ———— ———— ; the attenuation due to the lead network is 0.001s + 1 0.001s 4- 1
assumed to be compensated for by increasing the gain of the amplifiersAnswers to Selected Problems 529
c) I or the phase-lag network case, Mp = 1.2, Wj, = 0.25 rad/sec
1 or the phase-lead network case, Mp = 1.2, a>p = 7 rad/sec
d) The phase-lag compensated system with its narrower bandwidth is desirable from noise
considerations, as well as requiring less power and cost, if the reduced gain at low fre￾quencies is acceptable.
7.19 a) b = 0.25 b) ess = 0.3024
c) The transfer function of the rate feedback path is given by
d) ess = 0.0524.
5s
------ -- 0.255
1 + 35
7.20 a) The lag network is given by
5 + 0.0357
5 + 0.001
b) The lead network is given by
5 + 1
s + 100
7.22 a) The lag network is given by
s + 0.0649
5 + 0.01
b) The lead network is given by
.y 8
5+48
c) For part (a)
Kp = oo, Kv = oo, K, = 15,
a)p as 3.58 rad/sec, Mv as 1.0285
For part (b)
K = co, K„ = oo, Ka = 15,
a>p 19.9 rad/sec, Mv as 1.0285.
7.24 a) The lag network is given by
s + 0.201
5 + 0.01
b) The lead network is given by
s + 4
5 + 140
c) For part (a)
Kp = oo, Kv = 15, Ka = 0,
3.18 rad/sec, Mv as 1.0285
Kp = °o, Kv = 15, Ka = 0,
Wj, ab 65 rad/sec, MP 1.0285.
For part (b)530 Answers to Selected Problems
7.25 a) The lag network is given by
s + 0.1890
a + 0.0001
b) The lead network is given by
5+4
j + 16,800
c) For part (a)
Kj> = co, Kv = co, Ka - 15,
a)p 3.92 rad/sec, MP & 1.0285
For part (b)
Kv = oo, Kv = oo, Ka = 15,
cuj, 7,420 rad/sec, MP rm 1.0285.
7.31 The synthesized system is illustrated in Fig. A7.31 where
5 — a
K = 8, hr = 1, h2 = f, h3 = —-— .
o
A root locus analysis indicates that a good choice of a is approximately 2.5. Therefore,
fi3 becomes
Figure A7.31Answers to Selected Problems 531
CHAPTER 8
8.1 a) Transfer function of the motor with one straight line tangent to the exact char￾acteristics at 1000 rev/min is
0(5) 2.36
Ve(s) ~ 5(0.00835 + 1) ’
Transfer function of the motor with one straight line going through the two endpoints is
0(5) 1.79
^(5) ~ 5(0.00685 + 1) ’
b) Transfer function of the motor with one straight line tangent to the characteristics at
250 rev/min is
0(5) 6.12
Zc(5) “ 5(0.02275 + 1) ■
Transfer function of the motor with one straight line tangent to the characteristics at
1750 rev/min is
OQ) 2
Vc(s) 5(0.003345 + 1) ’
2KJ D D D S S S\
8.2 N(M) =---1 — — cos sin-1 — — sin-1 — + — cos sin"1 — +sin-1 — I.
tt \ M M MM M MJ
4K, I /D\2
8.3 7V(M) = —M 1 - .
ttM \MJ
2KT E> . Ey . ^2 , ^i"l 8.4 N(M) = — sin-1 — - sin-1 — + I — + — cos sin'1 — - — cos sin 1 — .
rr[_ M M \M MJ MM M]
8.7 A limit cycle occurs at DIM = 0.99 and a> = 0.075 rad/sec.
8.9 System is stable and exhibits no limit cycle.
8.10 System is stable and exhibits no limit cycle.
8.11 Limit cycle occurs at MfD = 3.15 and a> = 7.68 rad/sec.
8.13 a) Limit cycles occur at D/M = 0.82, a> = 0.39 rad/sec; D/M = 0.3, co = 1 rad/sec.
The former limit cycle is unstable, the latter is stable.
b) K = 2.75
c) aT = 0.9 sec, T = 0.4 sec (assume increase in original gain by a factor of ®)
d) b = 0.26.
8.16 A stable limit cycle exists at co = 30 rad/sec and DjM = 0.62. An unstable limit
cycle exists at co = 3 rad/sec and D/M = 0.92.
8.17 The describing function analysis of the gain-phase diagram indicates that limit cycles
do not exist for this system if the nonlinearity corresponds to coulomb friction.
8.19 a) The phase trajectory is a circle going through the point 1, 0 and whose center is
the origin.
b) The system is unstable, since no viscous damping is present.532 Answers to Selected Problems
8.27 a)
d6(t) B D - C6(f)
d6(t) “
A + A0{t)
b)
dO(t) _ B |0(Q|
A
D - C0(t)
+ Ad(t)
d6(t) B\9(t)\ D - C0(t)
C) d6(t) A
1 A0(t)
d)
dO(f) _
d6(t)
B D
A +
- C0(O |0(Q|
A6(f)
8.28 a) The isocline equation is given by
dQdt) _ _ 0(f)
dG(t) 0(f) '
where
0(0 — 0(0 = —= , s' = ' 0.4
<0.4
b) The isocline equation is given by
where
di-dt) = e(f)
dO(t) ~ 0(0 ’
0(f)
0(0 = —= , I = Vo.4
Vo.4
c) The isocline equation is given by
where
</©(0 eW dQ(t) 2S 10(01 0(f)
0(0 __
®(,) ' £ “ Vm
d) The isocline equation is given by
where
^©(0 . 0(0
dQ{t} ? 10(01 ©(f)’
6(f) _
0(0 = V6^ ’ = Vo-4 •
8.30 Using Lienard’s construction and defining v = —, we find the fundamental curve is
given by (for A =0.2)
y = —2v — 0.5 sin v.
8.32 Defining
6i(0 = 6(0 ~ 0.5 for 0(f) > 0
and
0x(f) = 0(f) + 0.5 for 0(f) < 0,Answers to Selected Problems 533
the isocline equation is given by
^0i(O W)
dO^t) ’ 0!(r)’
where
and
% = L
8.35 Popov condition satisfied if 0 < K < 5.5.
8.39 Possible Popov sectors which result in stable systems are given by the following
conditions:
6 < jVteft), t] < 18.9, 8.34 < N[e(f), t] < 47.6, 33.3 < N\e(t), z] < 100.
CHAPTER 9
9.1 uncontrollable, unobservable.
9.2 controllable, observable.
9.7 The optimal input is given by
and the nonlinear partial differential equation to be solved for S° is given by
9.8
u° = sgn [Xe2< cos V3f + ^],
where K and 0 are determined from the boundary conditions of the system.
9.14 The optimal control policy is given by
KdS°
2~dc
and the nonlinear partial differential equation to be solved for .8'° is given by
-K2/dS°^
' 4 '
+ Ac2 = 0.
9.15 «°(Z) = U sgn [Ket/2 sin (0.866/ + 0)], where K and 0 are determined from the
boundary conditions of the system.
9.16 w°(z) = U sgn [JCe sin (1.732/ + 0)], where Kand 0 are determined from the boundary
conditions of the system.
*
9.17 z/°(r) = U sgn [K^e + K2te‘], where Klt K2, and 0 are determined from the boundary
conditions of the system.
*INDEX
Acceleration constant, definition of, 170
graphical determination, 315
relation to closed-loop poles and zeros,
176-177
Accuracy, 167-177
Actuating signal, definition of, 15
Adaptive control systems, 364-365
concept of human, 6
flight control, 364-365
Adjoint matrix, definition of, 59-60
Aircraft, autopilots for, 364-365
F-4, 7, 10
landing system for, 91-92
nose wheel steering system for, 291-292
Aldrin, Astronaut Edwin, 506-508
Amplidyne, 115
Analog computer techniques, application
of, 268, 431-432
Analogy circuit concept, 134-137
Analytic, definition of, 23
Answers to selected problems, 519-533
Apollo, command module of, 89-91, 506-
508
eleven, 89-91, 506-508
seven, 7, 11
Aquaculture control system, 508-509
Armature-controlled de servomotor, 111-
115
Armstrong, Astronaut Neil, 89-91, 506-508
Asymptotic stability, 200, 372
definition of, 441-442
Attitude control, aircraft, 7, 10-11, 364-365
space vehicle, 7, 10, 12, 20, 293, 493-504
Autopilots, 7, 10-12, 19, 20, 364-365, 493-
504
Backlash, definition of, 179
describing function of, 386-389
eliminating effects of, 401-404
Bandwidth, control system, 184-185
Bang-bang control systems, definition of,
497
examples of, 431-437, 496-499
BASIC programming language, 226, 404
Bellman, R. E., 473, 485
Bioengineering, 1, 13-14, 282-283
Biological control system, 509-510
Block diagram, nomenclature for, 15-17
reduction techniques, 48-50
transformation, 48-50
Bode diagram, approach, 213-248
approximate closed-loop response from,
320-323
approximate preliminary compensation
using, 320-327
design utilizing the, 309-320
examples of, 216-234, 311-320
relationship of Nyquist diagram to the,
223-224
Bode’s theorems, 215, 309-311
first, 309-310
second, 310-311
Boltyanskii, V. G., 473, 490
Bolza problem, 481-482
Boston arm, the, 13-14
Branches of the signal-flow diagram, defi￾nition of, 51
Break-in point, definition of, 254-255
Breakaway point, definition of, 254-255
Bulk modulus of oil, definition of, 128
Calculus of variations, 480-485
Bolza problem in, 481-482
examples of, 484-485
Lagrange problem in, 481
Mayer problem in, 481-485
Cascade compensation, methods of, 295-
303
535536 Index
Cauchy, principle of the argument of, 208,
515-516
residue theorem of, 515
Cayley-Hamilton theorem, 477
Center of phase plane, definition of, 426
Characteristic equation, definition of, 198
state-space method for determining the,
199-203
Characteristic response of second-order
systems, 146-157
Chemical process control, 7, 20, 242, 361—
362
Circle criterion, 374, 453-456
Classical approach, 199, 300-306
Closed-loop frequency response, digital
computer program for determining,
226-239
time-domain response relation to, 246-
248
Closed-loop policy, definition of, 474-475
Closed-loop resolvent matrix, definition of,
345
Closed-loop system matrix, definition of,
345
Cofactors of matrices, definition of, 59
Cofactors of a signal-flow diagram, defini￾tion of, 53
Collins, Astronaut Michael, 506-507
Command, definition of, 15
Companion matrix, definition of, 66
Compensation, cascade, 295-303
linear system, 295-354
minor feedback loop, 303-306
nonlinear system, 401-411, 431-437
Complex variable, definition of, 22
theory of, 22-27
Computer techniques, Bode-diagram plot 
utilizing, 226-239
closed-loop frequency plot utilizing.
226-239
describing-function plot utilizing, 404-411
phase-plane plot utilizing, 431-437
Constant, Bode diagram of a, 216
Contactor characteristics, 389-390
Control elements, definition of, 15
Control policy, optimal, 474-475
Control stroke, hydraulic system, 127
Control winding of servomotor, 120
Controllability, 475-478
definition of, 475-476
example of. 478
Controlled system, definition of, 15
Controlled variable, definition of, 17
Convolution integral, definition of, 75
Coulomb friction, definition of, 185, 392
describing function of, 392-396
Critical damping, definition of, 148
Cybernetics, 6
Cyclic frequency of oscillation, definition
of, 152
Damping, critical, 148
Damping factor, definition of, 147
DC armature-controlled servomotor, 111-
115
DC field-controlled servomotor, 117-119
DC generator, 110-111
DC Ward-Leonard system, 115-116
Dead zone, definition of, 381
describing function of, 381-382
Decibel, definition of, 213
Denison, H. S., 357-358
Describing function, 379-411
backlash, 386-389
coulomb friction, 392-396
dead zone, 381-383
definition of, 379-380
derivation of, 380-396
design examples, 401-404
digital computer computation of, 404-411
hysteresis, 389-392
ideal relay, 470
prediction of oscillation from, 396-401
saturation, 382-385
stiction, 395-396
Determinant, signal-flow diagram, 53
Diagonal matrix, definition of, 58
Differential equation transformation, 419
Differentiation, Bode diagram of, 217
Differentiation network, 44
Digital computer, automatic storage and re￾trieval system for, 194-195
closed-loop frequency response evalua￾tion utilizing, 226-239
describing function evaluation utilizing,
404-411Index 537
nonlinear system evaluation utilizing, 374
open-loop frequency response utilizing,
226-238
root locus plot utilizing, 268-276
transition matrix evaluation utilizing,
81-84
Disturbance, definition of, 15
examples of, 315-316
torque, 3
Dither, definition, 401
Dominant poles, 333
Draper, C. S., 473
Dual-input describing function, 401
Dynamic programming, 485-490
examples of, 488-490
relation of Pontryagin’s maximum prin￾ciple to, 491
Ecological control systems, 97-98, 288,
509-510
Economics, considerations of, 1, 20, 184—
185
models of, 14-15, 19, 96, 280-281
Eigenvalues, definition of, 201
Electric hot water heater control system, 18
Electrical devices, state-space representa￾tion of, 114-120
transfer function of, 110-126
Electrical networks, state-space represen￾tation of, 101-103
transfer function of, 43-46
Electromygraphic signal, definition of, 14
Elevator, control of, 19
Energy, considerations of, 1
Energy function, definition of, 440
Error, definition of system, 168
Error constants, definition of, 168-177
Euler-Lagrange equation, definition of,
482-483
Evans, W. R., 249
F-4 aircraft, 7, 10
Farming, automatic, 7
Feedback compensation techniques, 295-
296, 303-306
Feedback elements, definition of, 17
Feedback loop, definition of, 52
Field-controlled de servomotor, 3, 117-119
Final-value theorem, 37
Finite stability, definition of, 441-442
Fluidic control systems, 276-277
Focus, definition of, 426
FORTRAN computer program, 226
Forward path, definition of, 51
Fourier integral, definition of, 32-34
Fourier series, complex form of, 30-32
definition of, 27-32
Fourier transform, definition of, 32-34
Friction,
coulomb, 392
stiction, 185, 392
viscous, 392
Fuel cells, 502
Functions, analytic, 22-23
Gain margin, definition of, 164, 212, 223
Gamkrelidge, R. V., 473, 490
Gear trains, 123-126, 165-167, 372, 386
Generalized circle criterion, 374, 453-456
example of, 455-456
Global stability, definition of, 441-442
Graham, D., 181
Grant’s rule, definition of, 258
Grumman Aerospace Corporation, 358
Gyroscope, 17, 138-139,494
Hamiltonian function, definition of, 491
Hamilton-Jacobi equation, derivation of,
486-487
Hard self-excitation, 372
Harvard medical school, 14
Helicopter control system, 363-364
Horizon sensors, 494
Human control system. 5-6, 18-19
Hurwitz, A., 204
Hydraulic devices, 126-132
motor and pump, 127-130
state-space representation of, 129-130
transfer function representation of, 126-
132
valve-controlled motor, 130-132
Hydrofoil, 357-358
Hysteresis, characteristics of, 372, 374,
389-390
describing function of, 389-392538 Index
Ideal value, definition of, 17
Idealized system, definition of, 17
Identity matrix, definition of, 57
Imbedding principle in dynamic program￾ming, 485-486
Indirectly controlled system, definition of,
17
Indirectly controlled variable, definition of,
17
Initial-value theorem, 37
Instrument landing system, 91-92
Integral of square error performance crite￾rion, 163, 484
Integral of the absolute magnitude of the
error performance criterion, 184
Integral of the square of the error perform￾ance criterion, 184, 484, 511
Integral of the squared time multiplied by
the absolute value of error performance
criterion, 181
Integral of the squared time multiplied by
square error (ISTSE) performance cri￾terion, 185
Integral of time and error performance cri￾terion, 163
Integral of time multiplied by the absolute
value of error (ITAE) performance cri￾terion, 180-185
optimum coefficients for, 183-184
Integral of time multiplied by the squared
error performance criterion, 181
Integration, Bode diagram of, 216-217
Integration network, 43-44 
Intentional nonlinearities, 369, 493-504
Internal combustion engine, 19
Inverse Laplace transform, 37-39 
Inventory control systems, 7, 188-190
Iodine-135, 96
Isocline method, 420-423
Jacobian matrices, definition of, 77
Japan, 7, 8, 272
Japanese National Railways, 7-9, 278
Jump resonance, 372-373
Kalman, R. E., 475
Kalman filtering, 354
Kirchhoffs equations, 101
Lag networks, 296-298
Lag-lead network, 299-300
Lago Pond, 97
Lagrange problem, 481
Laplace transform, application of, .34-36,
39-42
definition of, 34
derivation of, 34
inverse, 37-39
properties of, 36-37
tables of, 41, 513-514
Lathrop, R. C., 181
Laurent expansion, definition of, 25
Lead network, 298-299
Li, V. T., 473
Liapunov, A. M., 200
first method of, 437-439
second method of, 439-446
design examples utilizing, 444-446
justification of, 442-444
stability criterion of, 437-446
Liberty Mutual Insurance Company, 14
Lienard’s construction, 422-423
Limit cycles, 374
definition of, 372, 413
illustration of, 426-428
Linear systems, compensation of, 295-354
stability of, 198-276
Linearizing approximations, 120-123, 374
378
Linear-state-variable feedback, 342-354
concept of, 342-347
design utilizing, 347-354
general design procedure for, 347-354
Local stability, definition of, 441-442
Logarithm, definition of, 215
Loop gain, definition of, 52
Loss function, definition of, 474
Lotka-Volterra equations, 509
Lunar Excursion Module, 89-91, 359-360,
506-508
McDonald, D., 473
Machine tool control systems, 187-188,
192-193
Magnitude of closed-loop resonant peak,
definition of, 150-154, 320-323Index 539
Manipulated variable, definition of, 15
Man-machine control system, 145, 292
Manual tracking, compensatory, 292
Map drive control system, 155-156
Mars, 160-161
Mason’s theorems, application of, 53-55
definition of, 53
Massachusetts General Hospital, 14
Massachusetts Institute of Technology, 13
Matrix,
addition, 60
adjoint, 59-60
algebra, 56-63
analysis, 60-63
closed-loop resolvent, 345
closed-loop system, 345
companion, 66
diagonal, 58
differentiation, 62-63
identity, 57
integration, 63
inverse of a square, 62
Jacobian, 377
multiplication, 61
skew-symmetric, 57-58 
subtraction, 60
symmetric, 58-59
transition, 75-79
transpose, 58
zero, 59
Maximization of K(a) method, 253-255
Maximum percent overshoot, definition of,
153
root-locus determination of, 333-335
Maximum principle, 490-504
examples of, 492-504
solution of minimum-energy problem us￾ing the, 502-504
solution of minimum fuel-consumption
problem using the, 499-502
solution of minimum-time problem using
the,496-499
Maximum value of peaking, Nichols chart
determination of, 240-246
Mayer problem, 481
Mechanical devices, state-space represen￾tation of, 104-109
transfer function of, 104-109
tables of symbols and units, 104, 108
Metadyne, 115
Method of isoclines, 420-423
Method of tangents, 422-423
Minimization of K(cr) method, 253-255
Minimum-energy problem, 502-504
Minimum fuel-consumption problem, 499-
502
Minimum-phase networks, definition of,
215
Minimum-time problem, 496-499
Minor feedback loop compensation, 303-
306
Missile,
controi system, 158-159
roll control system, 355
launcher control system, 2-4, 165-166
Model of,
aquaculture control system, 508-509
aquatic systems, 97-98
armature-controlled de servomotor, 111-
115
automatic warehousing system, 188-190
bang-bang systems, 431-437, 496-499
biological processes, 509-510
ecological control systems, 97-98, 288,
509-510
economic systems, 14-15, 19, 20, 96,
280-281
field-controlled de servomotor, 117-119
generator, 110-111
human control system, 5-6, 145, 292
hydraulic pump-controlled transmission.
127-130
hydraulic valve-controlled motor, BO￾132
inventory control system, 188-190
mass-marketing campaign, 96-97
pacemaker, electronic, 196
population, 96-97
savings account, 89
sociological problems, 96, 289
thermal systems, 132-134
Ward-Leonard system, 115-116
Modeling, principle of conservation and
analogy applied to, 134-137
Motor constant, definition of, 122540 Index
Motor time constant, definition of, 122
Multivariable systems. 63-70
National Aeronautics and Space Adminis￾tration, 160-161
Navigation, space, 448-454, 493-504
Networks, compensating, 295-303
differentiating, 44
integrating, 43-44
phase lag, 43-44, 296-298
phase lag-lead, 299-300
phase lead. 44-45, 298-299
table of transfer functions for, 44-45
Newton's laws of motion, 104, 413
Nichols chart, 199, 240-246
application to nonlinear systems utilizing
the, 396-401
design of linear systems utilizing the,
327-328
Node of phase plane, definition of, 425
Node of signal-flow diagram, 51
Nomenclature, definitions of, 15-17
Nonlinear control systems, 369-456
characteristics of, 371-373
methods available for analyzing stability
of. 373-374
properties of, 371-372
Nonlinear differential equations, 370-371
Nonlinear system stability, describing func￾tion method for determining, 379-411
generalized circle criterion for determin￾ing, 453-456
Liapunov's method for determining,
437-446
linearizing approximations method for
determining, 374-378
phase plane method for determining,
413-437
piecewise-linear method for determining.
411-413
Popov's method for determining, 446-453
state-space analysis of, 413-437
Nonlinearities, 178-179
intentional, 369, 493-504
unintentional, 369
Nonminimum phase-shift transfer func￾tions, 215
Norm of the state vector, definition of, 199
Nuclear control systems, 1. 356-357
reactor for, 95-96
Numerical methods. 374
Runge-Kutta. 235
Nyquist criterion. 199. 206-213
Nyquist diagram, application to nonlinear
system stability utilizing the. 397
proof of. 513-514
relationship to Bode diagram. 223-224
Observability, criterion of. 478-480
definition of. 478
examples of. 479-480
Open-loop control systems. 1-3. 64
Open-loop frequency response, digital com￾puter technique for determining. 226-
234
Open-loop policy, definition of. 474-475
Optimal control theory. 473-504
application of. 493-504
characteristics of. 473-475
policy in. 474-475
Orbiting Astronomical Observatory. 459-
460
Osaka. 7-8
Overdamped response, definition of. 148-
149
Overshoot, curves of, 153-154
definition of. 153
Pacemaker, electronic. 196
Paper color processing control system.
141-143
Parabolic input. 170
Partial-fraction expansion. 37-39
Path, definition of. 51
gain. 52
Performance criteria. 64, 163-185. 474
integral of square error. 163. 485
integral of the absolute magnitude of the
error, 180
integral of the square of the error, 180.
485. 510-511
integral of the squared time multiplied by
the absolute value of error. 180-181
integral of the squared time multiplied by
square error. 180-181
in egral of time and error, 163Index 541
integral of time multiplied by the absolute
value of error, 180-184
optimum coefficients for, 183-184
optimum control, 474
quadratic, 510-511
Phase-lag networks, 43-44, 296-298
Bode diagram of, 217-218
characteristics of, 296-298
Phase-lag-lead networks, Bode diagram of,
301
characteristics of, 300-301
Phase-lead networks, 44-45, 298-299
Bode diagram of, 298-299
characteristics of, 298-299
Phase margin, definition of, 163, 212
Phase-plane method, 413-437
analysis of space vehicle attitude control
system utilizing the, 493-504
characteristics of, 423-431
construction of, 414-423
design examples utilizing the, 431-437
energy determination from, 439-446
representative phase portraits on the,
430-431
time determination from, 428-430, 501
Phase-shift approximation, straight-line,
323-327
Phase-shift scale, 223
Phase-shift table, 298
Phase-variable canonical form, definition
of, 66
Piecewise-linear approximations, 411-413
Polaris/Poseidon Fleet Ballistic Missile
Weapon System, 9, 12-13
Poles, definition of, 23
Policy, closed-loop, 474-475
open loop, 474-475
optimal, 474-475
Pontryagin, L. J., 473, 490
Pontryagin’s maximum principle, 490-504
examples of, 492-504
relation to dynamic programming, 491
solution of minimum-energy problem us￾ing the, 502-504
solution of minimum fuel-consumption
problem using the, 499-502
solution of minimum-time problem using
the, 496-499
Popov line, definition of, 450
Popov's method, 374, 446-453
example of, 452
limitations of, 447-448
Position constant, definition of, 168-175
Position limiting, 431
Positive-definite function, definition of, 442
Power considerations, 184-185
Practical considerations of performance,
184-185
Primary feedback, definition of, 15
Principle of conservation, definition of,
134-135
Programs, computer, 226-239, 404-411
Prosthetics, 13-14, 282-283
Quadratic performance criterion, 510-511
Quadratic phase-lag network, Bode dia￾gram of, 219-221
Quasilinear systems, definition of, 374
Radian frequency of oscillation of system,
definition of, 152
Ramp input, 169-170
Ranger space vehicle, 464-465
Rate limiting, 430
Reduction of multiple loop systems, block
diagram, 48-50
signal-flow diagram, 51-55
Reference input, definition of, 15
elements, definition of, 15
Reguiex, 115
Relative stability, by the Bode diagram,
223-228
by the describing function, 398, 402
by the Nyquist criterion, 212-213
Relay characteristics, 389-391, 470
Relay servo, 431-437, 470
Residue theorem, 24-27
Resonant frequency, 151
Rise time, definition of, 179
Rocket flight, example of, 67-68
Root-locus method, 199, 249-276, 328-342
design utilizing the, 328-342
maximum percent overshoot from the,
333-334
rules for construction of negative feed￾back systems from the, 251-258542 Index
rules for construction of positive feed￾back systems from the, 265-268
time to the first peak from the, 334
Roots of equation, determination of, 201
Rotating mechanical components, 108-109
Rotorol, 115
Routh, E., 204
Routh-Hurwitz criterion, 199, 203-206
Rudder control system, 17-18
Runge-Kutta numerical integration method,
235
Saddle point, definition of, 426-427
Satellite, spherical, 89
Saturation, describing function of, 382-385
Savings account, model of, 89
Second-order systems, characteristics of,
146-157
transient response of, 178-179, 333-335
Sensitivity of control systems, 164-167
definition of, 164
Servomechanisms, definition of, 5
examples of, 120-126, 192
Servomotor, 120-126, 374-375
Settling time, definition of, 179
Shifting theorem, 37
Ship stabilization system, 193, 195
Ship Inertial Navigation System, 9
Signal-flow diagram, 51-56
application of, 53-56
branches of, 51
description of, 51-52
determinant of, 53
feedback loops of, 52
loop gain of, 52
nodes of, 51
path gain of, 52
reduction techniques of, 52-55
relationship to state-space approach, 73-
74
sinks of, 51
sources of, 51
Singular points, phase plane, 423-426
Singularity, definition of, 23
Sink, definition of, 51
Size of equipment considerations, 184-185
Skew-symmetric matrix, definition of, 58-
59
Small-signal theory, 374
Sociological model, 96, 289
Soft self-excitation, 372-373
Solar cells, 502
Source, definition of, 51.
Space-attitude control system, design of,
493-504
Space navigation control system,
448-454
Space station, spinning. 460-461
Space vehicle, 7, 11-12
attitude control of, 20, 493-504
control of, 493-494
Orbiting Astronomical Observatory,
460-461
Ranger, 464-466
winged, 357-359
Viking, 160-162
Specific heat of water, definition of, 133
Specific impulse, definition of, 499
Speed control, 4-5, 7
Sperry Gyroscope Company, 364
Sperry Rand Corporation, 9
Sperry Systems Management Division, 9
Spinning space station, 460-461
Spirule, 259, 330
Stability, characteristics of, 163-164 , 441-
442
Bode diagram approach for determining,
213-248
definition of linear system, 198
Liapunov, 437-446
linear system, 198-354, 371
Nichols chart method for determining,
240-246
nonlinear system, 379-456
Nyquist criterion for determining, 206-
213
Popov, 446-453
root locus method for determining, 249-
276
Routh-Hurwitz method for determining,
203-206
Stabilization, linear system, 295-354
nonlinear system, 401-411, 431-437
Stable focus, definition of, 426
Stable node, definition of, 425
State, definition of, 65Index 543
State equations, derivation of, 65-66
electrical networks, 101-103
State input function space, definition of, 65
State input vector, definition of, 64
State output vector, definition of, 64
State-space, concepts of, 63-85
linear system analysis using the, 67-75,
114-115, 119, 122, 129-130
nonlinear system analysis using the,
413-437
State-space method, advantages of, 63-64
application of, 79-81
State-transition equation, definition of, 75
State variable, definition of, 63
State-variable diagram, characteristics of,
70-74
examples of, 73-74
State-variable signal-flow diagram, 73-74
second-order system, 154-157
State-vector form, characteristics of, 66
Static accuracy, 167-177
Steady state error constants, 168-177
from Bode diagram, 314-315
Steel mill control system, 224-225
Stiction, definition of, 185, 392
describing function of, 395-396
Subharmonic generation, 373
Submarine, automatic depth control prob￾lem of, 94-95, 277-278
Superposition, principle of, 370
Switching line, definition of, 433
Symmetric matrix, definition of, 58-59
System error, definition of, 17
Table, analogous quantities, 135
block-diagram transformations, 49
ITAE criterion standard forms, 183-184
Laplace transforms, 41, 513-514
maximum phase shift, 298
mechanical rotational symbols and units,
108
mechanical translation symbols and
units, 104
steady-state error constants, 171
transfer functions of networks, 44-45
Tank-level control systems, 1-2, 20-21,
278-279
Television camera control system, 191-192
Temperature control systems, 7, 356-357,
361-362, 508-509
Theory of small perturbations, 374
Thermal control systems, transfer function
of, 132-135
Time delay factor, 221-222
Time-domain response, digital computer
technique for determining, 230-236
relation of closed-loop frequency re￾sponse to, 246-248
Time to first peak, definition of, 152, 179
root-locus determination of, 334
Tokaido line, 7-9, 278-279
Tokyo, 7-8
Tokyo-to-Osaka railroad system, 278-279
Tokyo-to-Osaka super-express train, 7-9
Torpedo, Unless, 93-94
Torque constant, definition of, 113, 117
Train control systems, 7-9, 19
Trajectory on the phase plane, definition of,
413
Transducers, 17
Transfer function, 41
armature-controlled servomotor, 111-114
de generator, 110-111
electrical device’s, 109-126
fieid-controlled de servomotor, 117-118
hydraulic device’s, 126-132
mechanical device’s, 104-109
network’s, 43-44
system’s, 44, 47-49
table of, 44-45
thermal system’s, 132-135
two-phase ac servomotor, 120-122
Ward-Leonard system's, 115-116
Transient response, 178-179
root-locus determination of, 333-335
second-order system, 146-157
Transition from the real axis to the complex
plane method, 255, 261, 263-264
Transition matrix, 75-79
definition of, 75, 82
derivation from the state-variable dia￾gram, 77-79
digital computer evaluation of, 81-84
examples of, 76-79
properties of, 76
Transportation systems, 7-9544 Index
Transpose of a matrix, 58
Two-phase ac servomotor, 120-126
nonlinear characteristics of, 374-375
state-space representation of, 122-123
transfer function of, 120-122
Undamped natural frequency, definition of,
147
Underdamped response, 150-155
United States Department of Commerce,
357
Units, 104, 108
Unstable focus, definition of, 426
Unstable node, definition of, 425
Van der Pol equation, 438
Vector matrix form, 64
Velocity constant, definition of, 169
graphical determination, 314-315
relation of closed-loop poles and zeros
to, 175-176
Viking Mission, 160-162
Viscous friction, definition of, 392
Ward-Leonard system, 115-116
modified form of, 139-140
Warehousing, automatic, 7, 188-190
Weight considerations, 184-185, 369, 389
Wiener, N., 5, 473
Xenon-135, 96
Xylene chemical process control, 361-362
Zero, definition of, 24
Zero-error systems, definition of, 182
Zero matrix, definition of, 59
Zero steady-state error system, definition
of, 182
Printed in Hong Kong by Carrie Printing Co.ISBN 0—201—07059-6
