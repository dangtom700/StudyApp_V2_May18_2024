Probability Theory
This book introduces Probability Theory with R software and explains abstract 
concepts in a simple and easy-to-understand way by combining theory and com￾putation. It discusses conceptual and computational examples in detail to provide 
a thorough understanding of basic techniques and develop an enjoyable read for 
students seeking suitable material for self-study. It illustrates fundamental con￾cepts including fields, sigma-fields, random variables and their expectations, 
various modes of convergence of a sequence of random variables, laws of large 
numbers and the central limit theorem.
• Computational exercises based on R software are included in each Chapter
• Includes a brief introduction to the basic functions of R software for beginners
in R and serves as a ready reference
• Includes numerical computations, simulation studies, and visualizations using
R software as easy tools to explain abstract concepts
• Provides multiple-choice questions for practice
• Incorporates self-explanatory R codes in every chapter
This textbook is for advanced students, professionals, and academic researchers 
of Statistics, Biostatistics, Economics and Mathematics.Probability Theory
An Introduction Using R
Shailaja R. Deshmukh
and
Akanksha S. KashikarDesigned Cover Image: Shailaja R. Deshmukh, and Akanksha S. Kashikar
First edition published 2025 
by CRC Press
2385 NW Executive Center Drive, Suite 320, Boca Raton FL 33431
and by CRC Press
4 Park Square, Milton Park, Abingdon, Oxon, OX14 4RN
CRC Press is an imprint of Taylor & Francis Group, LLC
© 2025 Shailaja R. Deshmukh and Akanksha S. Kashikar
Reasonable efforts have been made to publish reliable data and information, but the author and publisher cannot as￾sume responsibility for the validity of all materials or the consequences of their use. The authors and publishers have 
attempted to trace the copyright holders of all material reproduced in this publication and apologize to copyright 
holders if permission to publish in this form has not been obtained. If any copyright material has not been acknowl￾edged, please write and let us know so we may rectify in any future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, transmitted, 
or utilized in any form by any electronic, mechanical, or other means, now known or hereafter invented, includ￾ing photocopying, microfilming, and recording, or in any information storage or retrieval system, without written 
permission from the publishers.
For permission to photocopy or use material electronically from this work, access www.copyright.com or contact the 
Copyright Clearance Center, Inc. (CCC), 222 Rosewood Drive, Danvers, MA 01923, 978-750-8400. For works that are 
not available on CCC please contact mpkbookspermissions@tandf.co.uk
Trademark notice: Product or corporate names may be trademarks or registered trademarks and are used only for 
identification and explanation without intent to infringe.
Library of Congress Cataloging-in-Publication Data
Names: Deshmukh, Shailaja R., author. | Kashikar, Akanksha S., author. 
Title: Probability theory : an introduction using R / Shailaja R. Deshmukh 
and Akanksha S. Kashikar. 
Description: First edition. | Boca Raton : C&H/CRC Press, 2024. | Includes bibliographical references and index. | 
Summary: “This book introduces Probability Theory with R software and explains abstract concepts in a 
simple and easy-to-understand way by combining theory and computation”-- Provided by publisher. 
Identifiers: LCCN 2024010470 (print) | LCCN 2024010471 (ebook) | ISBN 
9781032617978 (hbk) | ISBN 9781032619033 (pbk) | ISBN 9781032619057 
(ebk) 
Subjects: LCSH: Probabilities--Data processing--Textbooks. | R (Computer 
program language)--Textbooks. 
Classification: LCC QA273.19.E4 D47 2024 (print) | LCC QA273.19.E4 
(ebook) | DDC 519.20285/5133--dc23/eng/20240509 
LC record available at https://lccn.loc.gov/2024010470
LC ebook record available at https://lccn.loc.gov/2024010471
ISBN: 978-1-032-61797-8 (hbk)
ISBN: 978-1-032-61903-3 (pbk)
ISBN: 978-1-032-61905-7 (ebk)
DOI: 10.1201/9781032619057
Typeset in SFRM1000 font
by KnowledgeWorks Global Ltd.Dedicated to
Respected Teachers who made us Better Students,
Beloved Students who made us Better Teachers
&
Dear Friends who effortlessly switched between
these two roles !Contents
List of Tables xi
List of Figures xiii
Preface xv
Author Biographies xix
1 Sigma Field, Borel Field and Probability Measure 1
1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.2 Introduction to R Software and Language . . . . . . . . . . 2
1.3 Limit of a Sequence of Sets . . . . . . . . . . . . . . . . . . 9
1.4 Borel Field . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
1.5 Probability Space . . . . . . . . . . . . . . . . . . . . . . . . 48
1.6 Conceptual Exercises . . . . . . . . . . . . . . . . . . . . . . 58
1.7 Computational Exercises . . . . . . . . . . . . . . . . . . . . 62
1.8 Multiple Choice Questions . . . . . . . . . . . . . . . . . . . 62
2 Random Variables and Random Vectors 67
2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
2.2 Random Variables . . . . . . . . . . . . . . . . . . . . . . . 68
2.3 Random Vectors . . . . . . . . . . . . . . . . . . . . . . . . 84
2.4 Simple Random Variable . . . . . . . . . . . . . . . . . . . . 106
2.5 Probability Distribution of a Random Variable . . . . . . . 121
2.6 Conceptual Exercises . . . . . . . . . . . . . . . . . . . . . . 127
2.7 Computational Exercises . . . . . . . . . . . . . . . . . . . . 129
2.8 Multiple Choice Questions . . . . . . . . . . . . . . . . . . . 130
3 Distribution Function 135
3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
3.2 Properties of a Distribution Function . . . . . . . . . . . . . 136
3.3 Decomposition of a Distribution Function . . . . . . . . . . 145
3.4 Distribution Function of a Random Vector . . . . . . . . . . 158
3.5 Conceptual Exercises . . . . . . . . . . . . . . . . . . . . . . 160
3.6 Computational Exercises . . . . . . . . . . . . . . . . . . . . 162
3.7 Multiple Choice Questions . . . . . . . . . . . . . . . . . . . 162
viiviii Contents
4 Expectation and Characteristic Function 165
4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
4.2 Expectation of a Simple Random Variable . . . . . . . . . . 167
4.3 Expectation of Non-Negative and Arbitrary
Random Variables . . . . . . . . . . . . . . . . . . . . . . . 171
4.4 Characteristic Function . . . . . . . . . . . . . . . . . . . . 185
4.5 Moment Inequalities . . . . . . . . . . . . . . . . . . . . . . 203
4.6 Conceptual Exercises . . . . . . . . . . . . . . . . . . . . . . 214
4.7 Multiple Choice Questions . . . . . . . . . . . . . . . . . . 217
5 Independence 221
5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 221
5.2 Independence of Events and Classes of Events . . . . . . . . 222
5.3 Independence of Random Variables . . . . . . . . . . . . . . 227
5.4 Kolmogorov Zero-One Law . . . . . . . . . . . . . . . . . . 242
5.5 Conceptual Exercises . . . . . . . . . . . . . . . . . . . . . . 246
5.6 Multiple Choice Questions . . . . . . . . . . . . . . . . . . . 248
6 Almost Sure Convergence and Borel Zero-One Law 252
6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 252
6.2 Definitions of Various Modes of Convergence . . . . . . . . 253
6.3 Almost Sure Convergence . . . . . . . . . . . . . . . . . . . 257
6.4 Borel Zero-One Law . . . . . . . . . . . . . . . . . . . . . . 270
6.5 Conceptual Exercises . . . . . . . . . . . . . . . . . . . . . . 284
6.6 Computational Exercises . . . . . . . . . . . . . . . . . . . . 286
6.7 Multiple Choice Questions . . . . . . . . . . . . . . . . . . . 286
7 Convergence in Probability, in Law and in r-th Mean 288
7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 288
7.2 Convergence in Probability . . . . . . . . . . . . . . . . . . 288
7.3 Convergence in Law . . . . . . . . . . . . . . . . . . . . . . 316
7.4 Convergence in r-th Mean . . . . . . . . . . . . . . . . . . . 353
7.5 Conceptual Exercises . . . . . . . . . . . . . . . . . . . . . . 371
7.6 Computational Exercises . . . . . . . . . . . . . . . . . . . . 375
7.7 Multiple Choice Questions . . . . . . . . . . . . . . . . . . . 376
8 Convergence of a Sequence of Expectations 386
8.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 386
8.2 Monotone Convergence Theorem . . . . . . . . . . . . . . . 387
8.3 Lebesgue Dominated Probability Convergence Theorem 398
8.4 Conceptual Exercises . . . . . . . . . . . . . . . . . . . . . . 403
8.5 Computational Exercises . . . . . . . . . . . . . . . . . . . . 403
8.6 Multiple Choice Questions . . . . . . . . . . . . . . . . . . . 403Contents ix
9 Laws of Large Numbers 406
9.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 406
9.2 Weak Law of Large Numbers . . . . . . . . . . . . . . . . . 407
9.3 Strong Law of Large Numbers . . . . . . . . . . . . . . . . . 419
9.4 Conceptual Exercises . . . . . . . . . . . . . . . . . . . . . . 426
9.5 Computational Exercises . . . . . . . . . . . . . . . . . . . . 427
9.6 Multiple Choice Questions . . . . . . . . . . . . . . . . . . . 427
10 Central Limit Theorem 430
10.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 430
10.2 Lindeberg-Levy CLT . . . . . . . . . . . . . . . . . . . . . . 431
10.3 CLT for Independent Random Variables . . . . . . . . . . . 451
10.4 Conceptual Exercises . . . . . . . . . . . . . . . . . . . . . . 473
10.5 Computational Exercises . . . . . . . . . . . . . . . . . . . . 474
10.6 Multiple Choice Questions . . . . . . . . . . . . . . . . . . . 475
11 Solutions to Conceptual Exercises 479
11.1 Chapter 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 479
11.2 Chapter 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 496
11.3 Chapter 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 503
11.4 Chapter 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 508
11.5 Chapter 5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 519
11.6 Chapter 6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 526
11.7 Chapter 7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 532
11.8 Chapter 8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 553
11.9 Chapter 9 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 556
11.10 Chapter 10 . . . . . . . . . . . . . . . . . . . . . . . . . . . 561
Bibliography 571
Index 573List of Tables
4.1 Characteristic Functions of Standard Distributions . . . . . 186
6.1 Almost Sure Convergence: n0(ϵ, ω) . . . . . . . . . . . . . . 261
6.2 MLE of θ for N(θ, 1) Distribution, θ ∈ I . . . . . . . . . . . 283
6.3 P
N
n=1
Pθ[
ˆθn ̸= θ] . . . . . . . . . . . . . . . . . . . . . . . . . . 283
7.1 P[|Xn − X| < ϵ] for Given n and ϵ . . . . . . . . . . . . . . 290
7.2 Verification of Theorem 7.2.3 for U(0, 1) Distribution . . . . 298
7.3 U(0,1) Distribution: Convergence in Probability . . . . . . . 305
7.4 Values of rfn for Sample Mean and Sample Median . . . . . 308
7.5 Gamma Distribution: Convergence in Probability and in
Quadratic Mean . . . . . . . . . . . . . . . . . . . . . . . . . 348
7.6 Convergence in Probability, in Quadratic Mean and Conver￾gence of Moments . . . . . . . . . . . . . . . . . . . . . . . . 364
7.7 Values of Tn . . . . . . . . . . . . . . . . . . . . . . . . . . . 365
8.1 Verification of LDCT for N(θ, 1) Distribution, θ ∈ [a, b] . . . 401
9.1 Verification of WLLN: Exponential, Geometric and Poisson
Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . 418
9.2 Verification of WLLN: Binomial Distribution . . . . . . . . . 419
10.1 p-values: Exponential, Poisson and Geometric Distributions 436
10.2 p-values: CLT for Binomial Distribution . . . . . . . . . . . 439
10.3 P[Xn ≤ µ] → 1/2: Exponential, Poisson and Geometric
Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . 444
10.4 P[Xn ≤ x] : x < µ, x = µ, x > µ . . . . . . . . . . . . . . . . 446
10.5 Verification of Lindeberg-Feller CLT: Xk ∼ U(−k, k) . . . . 464
10.6 Hypoexponential Distribution: p-values . . . . . . . . . . . . 470
10.7 Lindeberg-Feller CLT: Hypoexponential Distribution . . . . 471
11.1 Answer Key to MCQs in Chapter 1 . . . . . . . . . . . . . . 496
11.2 Answer Key to MCQs in Chapter 2 . . . . . . . . . . . . . . 502
11.3 Answer Key to MCQs in Chapter 3 . . . . . . . . . . . . . . 508
11.4 Answer Key to MCQs in Chapter 4 . . . . . . . . . . . . . . 518
11.5 Answer Key to MCQs in Chapter 5 . . . . . . . . . . . . . . 526
xixii List of Tables
11.6 Answer Key to MCQs in Chapter 6 . . . . . . . . . . . . . . 532
11.7 Answer Key to MCQs in Chapter 7 . . . . . . . . . . . . . . 553
11.8 Answer Key to MCQs in Chapter 8 . . . . . . . . . . . . . . 556
11.9 Answer Key to MCQs in Chapter 9 . . . . . . . . . . . . . . 561
11.10 Answer Key to MCQs in Chapter 10 . . . . . . . . . . . . . 570List of Figures
1.1 Exponential Distribution with Mean 1: Observed and Ex￾pected Distributions . . . . . . . . . . . . . . . . . . . . . . . 8
1.2 Limit of a Non-decreasing Sequence . . . . . . . . . . . . . . 14
1.3 Limit of a Non-increasing Sequence . . . . . . . . . . . . . . 19
1.4 Non-monotone Convergent Sequence . . . . . . . . . . . . . 21
1.5 Non-convergent Sequence . . . . . . . . . . . . . . . . . . . . 23
1.6 Limit Supremum and Limit Infimum . . . . . . . . . . . . . 24
1.7 Limit Supremum . . . . . . . . . . . . . . . . . . . . . . . . 28
1.8 Limit Infimum . . . . . . . . . . . . . . . . . . . . . . . . . . 29
2.1 Point-wise Convergence . . . . . . . . . . . . . . . . . . . . . 102
2.2 Visual Illustration of Theorem 2.4.2 . . . . . . . . . . . . . . 112
2.3 Visual Illustration of Theorem 2.4.3 . . . . . . . . . . . . . . 116
3.1 Distribution Functions . . . . . . . . . . . . . . . . . . . . . 152
3.2 Distribution Functions of X, X+, X− and |X| . . . . . . . 157
6.1 Almost Sure Convergence . . . . . . . . . . . . . . . . . . . . 259
6.2 Almost Sure Convergence: n0 . . . . . . . . . . . . . . . . . 261
7.1 Convergence in Probability of Xn = e
ω + ω
n to X = e
ω . . . 291
7.2 U(0,1) Distribution: Convergence in Probability of X(n)
, X(1),
Xn and Sample Median . . . . . . . . . . . . . . . . . . . . . 306
7.3 Rate of Convergence of Sample Mean and Sample Median . 309
7.4 Convergence in law of Yn . . . . . . . . . . . . . . . . . . . . 319
7.5 U(0, θ) Distribution: Convergence in Law of n(θ − X(n))/θ . 321
7.6 Poisson Distribution Approximation to Binomial Distribution 324
7.7 Convergence in Law of Yn =
√
n(Xn − 1): Histograms . . . . 349
7.8 Convergence in Law of Yn =
√
n(Xn − 1) . . . . . . . . . . . 350
7.9 Xn ∼ G(n, n): Convergence in Law to 1 . . . . . . . . . . . . 351
7.10 Distribution Functions Fn and F . . . . . . . . . . . . . . . 366
7.11 Box Plots of |Fn(x) − F(x)| and Values of Tn . . . . . . . . 367
7.12 Convergence in Law of Xn to Y . . . . . . . . . . . . . . . . 368
10.1 CLT: Exponential, Poisson and Geometric Distributions . . 437
10.2 Verification of CLT for Binomial Distribution . . . . . . . . 440
xiiiPreface
The most important questions of life... are indeed for the most
part only problems of probability.
– Pierre-Simon Laplace
In his Philosophical essay on Probabilities, Laplace talks about how the theory
of probabilities is basically just common sense reduced to calculus and hence
has applications in almost every aspect of human knowledge. In today’s data￾driven world, the importance of probability theory has grown immensely. We
have evolved from using conditional probabilities to predict whether an email
is spam to creating large language models which are apparently doing a decent
job as teachers, diagnosticians and what not! Hence, it is always essential that
we don’t lose touch with the fundamentals! Probability theory has always
served as a foundation of inferential aspect of statistics. In fact, the knowledge
of probability theory is what differentiates statisticians from record keepers
or accountants. For example, a cricket historian may be able to tell you all
about the wins and losses of a particular team. Before a match, he/she may
also be able to present you with nice visual displays of the performances of a
player in older similar matches. However, a statistician trained in probability
theory will be able to account for the variety of factors at play to arrive at a win
probability. Similarly using past data, a statistical model based on probability
theory can predict whether a recently initiated transaction is a fraud. It can
also tell us whether we are in a danger of contracting some disease based on our
genetic makeup! Probability theory thus plays the role of a bridge between the
exploratory (tabulation, visualization of the given data) and the confirmatory
(hypothesis testing for generalizing from samples to populations, predictions,
forecasts using sophisticated models) data analysis. The theory of probability
is the foundation of statistics as a science.
In the present book, we introduce some basic concepts of the probability
theory. We have adopted a rigorous mathematical approach towards the the￾oretical concepts. To absorb the notions easily, it is simultaneously supported
by numerical computations, simulation studies and visualizations, with R soft￾ware. The book begins with a brief introduction to the basic concepts in Chap￾ter 1, such as sequences of sets, their limit, sigma field, Borel field, measurable
space, probability measure and probability space. Chapter 2 is devoted to a
study of random variables as measurable functions, random vectors, sequence
of random variables, induced sigma fields and induced probability measure.
In Chapter 3, we discuss the notion of a distribution function and study its
properties. Chapter 4 is concerned with the concept of an expectation of a
xvxvi Preface
random variable as an integral with respect to the probability measure and
related results. A distinguishing and fundamental feature of probability the￾ory is the notion of independence, which has no parallel in measure theory. It
is one of the most central concepts of probability theory and a large part of
the theory explores the consequences of the presence of this property and the
lack of it. Chapter 5 presents the fundamentals of the theory of independence
of random variables and some relevant ideas.
Chapters 6 and 7 investigate in detail the various modes of the conver￾gence of a sequence of random variables and the interrelations among these.
In probability theory we study limit theorems of two types: (i) strong limit
theorems which deal with the almost sure convergence of a sequence of ran￾dom variables and (ii) weak limit theorems which deal with the convergence in
probability of a sequence of random variables as well as the convergence of a
sequence of distribution functions. Chapter 8 discusses the convergence of the
sequences of expectations of random variables. It includes the monotone con￾vergence theorem, Fatou’s lemma and the Lebesgue-dominated convergence
theorem. Chapter 9 is concerned with the laws of large numbers which are
related with the limiting behaviour of the sequence of partial sums of a se￾quence of random variables. These state conditions under which the sequence
of partial sums converges almost surely and in probability. The weak law of
large numbers refers to convergence in probability, whereas the strong law of
large numbers refers to the almost sure convergence.
Chapter 10 is devoted to the most important and frequently applied tool
in probability theory and it is the central limit theorem. It is concerned with
the convergence in distribution of appropriately normed sequence of partial
sums. Central limit theorem is one of the oldest and the most useful results
in probability theory. It states that the mean of a large number of random
variables, no matter what their distribution is, with the only condition on
the variance of the random variables, is approximately normally distributed.
Empirical findings in applied sciences, dating back to the seventeenth century,
showed that the averages of laboratory measurements on various physical
quantities tend to have a bell-shaped distribution. The central limit theorem
provides a theoretical justification for this observation. Chapters 6 to 10 are
the most important chapters and the concerned theory is heavily applied in
large sample statistical inference to study the asymptotic optimality properties
of the estimators and to derive the asymptotic null distribution of the test
statistic.
Chapter 11 presents the solutions of almost all of the conceptual exercises.
Solutions to the exercises are important for students who initially do not have
the skill in solving these exercises completely. It is expected that students
should not be completely driven by the solutions. They should try each exer￾cise first without referring to its solution. Numerous illustrative examples of
different difficulty levels are incorporated throughout each chapter to clarify
the concepts. These illustrations and several remarks reveal the depth of the
incorporated theory. Exercises form an important part of any textbook. ForPreface xvii
better assimilation of the material, three types of exercises, such as conceptual,
computational and MCQs are given at the end of each chapter.
The book has evolved out of the instructional material prepared for teach￾ing a course “Probability Theory” for several years at Savitribai Phule Pune
University, formerly known as the University of Pune. To some extent, the
topics coincide with what we used to cover in the course. The material cov￾ered in the present book is influenced by several standard textbooks, such
as Athreya and Lahiri (2006), Bhat B.R. (1999), Billingsley (1986), A. Gut
(2005) and Loeve (1978). The novelty and unique feature of our book is aug￾menting the theory with R software as a tool for simulation and computation.
Over the years, we have noted that the concepts from probability are difficult
for the students to grasp due to their abstract nature. To overcome this dif￾ficulty, it is essential that the theory and computations go hand in hand.
Hence, in the present book, we have adopted an approach to explain theory
along with the computations. The books mentioned above do not address the
computational aspect.
We are convinced that the development of computational methods, along
with the theory, will greatly contribute to a better understanding of the theory.
Hopefully, a better understanding can provide more insights and help students
to appreciate the beauty of the subject. We will be deeply rewarded, if the
present book helps students to enhance their understanding and to enjoy the
subject. The main motive is to provide fairly thorough treatment of basic
techniques, theoretically and computationally using R, so that the book will
be suitable for self-study, particularly in the present era of online education.
The style of the book is purposely kept conversational. One more reason to
keep the style conversational is to help the students develop an intuition for
the subject. In the present era, where students are becoming increasingly
reliant on technology for solving their problems, texts which can help develop
rigorous mathematical thinking abilities have become a necessity. Thus, we try
to explain the thinking behind each and every argument made in a proof, so
as to ensure that the students develop the art of problem-solving and logical
thinking.
Nowadays R is a leading computational tool for statistics and data analysis.
It is free and platform-independent and hence can be used on any operating
system. Keeping up with the recent trend of using R software for statistical
computations, we too have used it extensively in this book for illustrating the
concepts. Another advantage of using a free software is that a lot of com￾munity support is available online for fixing errors in the codes and finding
out new commands. Using R, we illustrate the concept of limit infimum and
limit supremum of the sequence of sets, limits of monotone and non-monotone
sequences of sets, various modes of convergence of a sequence of random vari￾ables, Lebesgue dominated convergence theorem, laws of large numbers and
the central limit theorem. R codes are provided in the respective chapters.
Computational exercises based on R software are included so as to provide a
hands-on experience to students.xviii Preface
The mathematical pre-requisites for this book are elementary probability,
basic convergence concepts for a sequence of real numbers, familiarity with
the properties of standard discrete and continuous distributions. Some back￾ground of the measure theory would also be beneficial but is not necessary.
In addition, some basic knowledge of R software is desirable. In Chapter 1
for ready reference, we have added a section on R software, which gives a
brief introduction to the basic functions. The intended target audience of the
present book is mainly postgraduate students in Statistics, Bio-statistics or
Mathematics. It will also provide sufficient background information for study￾ing advanced courses in probability theory and stochastic processes. The book
is designed primarily to serve as a textbook for a one-semester introductory
course on probability theory in any post-graduate statistics program.
We wish to express our special thanks to all our teachers, who have laid
the strong foundation of probability theory and influenced our understanding,
appreciation and taste for the subject. The book is essentially based on our
class notes when we were students in this course and the notes we prepared
as the instructor of this course. We would like to express our sincere thanks
to Prof. S. R. Adke and Prof. G. B. Marathe, who taught this course when
we were students.
We express our deep gratitude to the R core development team and the
authors of contributed packages, who have invested a lot of time and effort
in creating R as it is today. With the help of such a wonderful computa￾tional tool, it is possible to showcase the beauty of the theory. We thank Prof.
T.V. Ramanathan, Head of the Department of Statistics, Savitribai Phule
Pune University, for providing the necessary facilities. We take this opportu￾nity to acknowledge Rajesh Dey, Senior Commissioning Editor (Mathematics,
Physics, Statistics and Computer Science), Taylor & Francis India Pvt. Ltd.
CRC Press and his team, for providing help from time to time and subsequent
processing of the text to its present form. We are deeply grateful to our fam￾ily members for their constant support and encouragement. We owe profound
thanks to all our students whom we have taught during the last several years
and who have been the driving force to take up this immense task. Their reac￾tions, positive as well as negative, doubts in the class, and their responses in
the answer books urged us to make the theory crystal clear to them, thereby
compelling us to pursue this activity and to prepare a variety of illustrations
and exercises.
All mistakes and ambiguities in the book are exclusively our responsibil￾ity. We would love to know any mistakes that a reader comes across in the
book. Feedback in the form of suggestions and comments from colleagues and
readers is the most welcome.
December 2023 Shailaja Deshmukh and Akanksha Kashikar
Pune, India
Email Addresses: Shailaja Deshmukh – deshshailaja@gmail.com
Akanksha Kashikar – akanksha.kashikar@gmail.comAuthor Biographies
Shailaja Deshmukh is a visiting faculty at the Department of Statistics,
Savitribai Phule Pune University, formerly known as University of Pune, In￾dia. She retired as a Professor of Statistics from the Savitribai Phule Pune
University. She has taught around twenty five different theoretical and applied
courses. She worked as a visiting professor at the Department of Statistics,
University of Michigan, Ann Arbor, Michigan, during 2009-10 academic year.
She has served as an executive editor and as a chief editor of the Journal of
Indian Statistical Association. She is an elected member of the International
Statistical Institute.
Her areas of interest are inference in stochastic processes, applied probability
and analysis of microarray data. She has a number of research publications
in various peer-reviewed journals, such as Biometrika, Journal of Multivariate
Analysis, J. R. Statist. Society, Australian and New Zealand Journal of Statis￾tics, Journal of Applied Statistics , Environmetrics, J. of Statistical Planning
and Inference, Naval Research Logistics, Journal of Translational Medicine,
Annals of Institute of Statistical Mathematics. She has published the follow￾ing six books. (i) Microarray Data: Statistical Analysis Using R, published by
Narosa in 2007, (ii) Statistics Using R, published by Narosa in 2008, (iii) Ac￾tuarial Statistics: An Introduction Using R, published by Universities Press in
2009, (iv) Multiple Decrement Models in Insurance: An Introduction Using R,
published by Springer in 2012 and (v) Asymptotic Statistical Inference: An In￾troduction Using R, published by Springer in 2021. (vi) Stochastic Processes:
An Introduction Using R”, published by Springer in 2023.
Akanksha Kashikar is an Assistant Professor at Savitribai Phule Pune
University (formerly known as the University of Pune) since 2012, specializing
in Statistics. She obtained her masters and PhD in Statistics from the same
university. Her research interests include Branching Processes, Count Data
Time Series, and Applied Statistics. She has taught around fifteen different
theoretical and applied courses. She has published papers in various Sci/Sco￾pus listed journals including the Journal of Statistical Planning and Inference,
Statistics and Probability Letters, Annals of the Institute of Statistical Math￾ematics, Communication in Statistics, Environmental Science and Pollution
Research, Proteome Science, Journal of Astrophysics and Astronomy etc. She
has developed an R Package “Outlier Detection” which has been downloaded
more than 15000 times. She is an executive editor for the Journal of Indian
Statistical Association. She has received several awards, including the Young
xixxx Author Biographies
Statistician Award and the Young Scientist Award from Indian statistical so￾cieties, and the Best Paper Award from the Indian Society for Medical Statis￾tics. She was granted a research fellowship through the Indo-Japanese Young
Researcher Fellowship Programme. She is passionate about science popular￾ization and has written articles in Marathi publications. She has also been
recognized for her innovative teaching methods. (Award by SPPU)1
Sigma Field, Borel Field and Probability
Measure
1.1 Introduction
Statistics as a subject comprises the art and science of the collection, interpre￾tation and analysis of data, which enables to draw logical generalities related
to the phenomenon under investigation. In view of such essential stages of any
scientific method, statistics extensively enters the domain of all scientific in￾vestigations. Theory of probability is the foundation of statistics as a science.
It forms a strong base for Mathematical statistics. In the present book, we
elaborate on some aspects of probability theory.
The main objective of probability theory is to investigate mathematical
models of random phenomena from a theoretical point of view. The basis
of probability theory is a probability space. To explain this concept prop￾erly, we need some definitions and results from measure theory. This chapter
provides some principal concepts of probability theory and some important
results which form a sound foundation of the theory in subsequent chapters.
As the title of the book conveys, R software is used throughout the book
to illustrate the concepts with numerical examples and figures. The novel fea￾ture of the present book is augmentation of the theory with R software (see R
[18]) as a tool for simulation, computation and visual presentation. For the
last two decades, R has been a leading computational tool for statistics and
data analysis. It is free and platform-independent and hence can be used on
any operating system. Keeping up with the recent trend of using R software
for statistical computations, we too have used it extensively in this book for
illustrating the concepts. In order to facilitate understanding of R codes pro￾vided in all the chapters, a preliminary introduction to the R software is given
in Section 2 of this chapter. In Section 3, we review some topics from measure
theory, such as set theory, sequence of sets and its convergence. We use R to
illustrate the concepts of limit supremum, limit infimum and convergence of
sequence of sets. R codes used in these illustrations are provided.
Borel field plays a major role in the definition of a random variable and a
random vector. Hence, in Section 4, we elaborate on the concept of a sigma
field of subsets of a non-empty set and study some of its properties. We then
define a Borel field and prove various equivalent ways to generate the Borel
DOI: 10.1201/9781032619057-1 12 Sigma Field, Borel Field and Probability Measure
field. Section 5 is concerned with the probability measure and some related
results. This background material is essential for the solid treatment of the
probability theory presented in this book.
One may refer to some standard textbooks on probability theory, such as
Ash [2], Athreya and Lahiri [3], Bhat [4], Billingsley [5], Chung [8] and
Loeve [16] for more details.
Some readers may be familiar with R software as it has been introduced in
the curriculum of many undergraduate and post-graduate statistics programs.
In the following section, we give a brief introduction to R, which will be useful
to beginners. We have also tried to make the codes given in all the chapters
to be self-explanatory.
1.2 Introduction to R Software and Language
In statistical analysis, one needs a good statistical software to carry out com￾putations and draw different types of graphs. There is a variety of software
available for the computation such as Excel, Minitab, Matlab, SAS, etc. In
the last two decades, R software has been strongly advocated and a large pro￾portion of the world’s leading statisticians use it for statistical analysis. It is
a high-level language and an environment for data analysis and graphics, cre￾ated by Ross Ihaka and Robert Gentleman in 1996. It is both a software and
a programming language considered as a dialect of the S language developed
by AT & T Bell Laboratories.
The current R software is the result of a collaborative effort with contri￾butions from all over the world. It has become very popular in academics and
also in the corporate world for a variety of reasons such as its good computing
performance, excellent built-in help system, flexibility in graphical environ￾ment, its vast coverage, availability of new, cutting-edge applications in many
fields and scripting and interfacing facilities. The most important advantage
is that in spite of being the finest integrated software, it is freely available
software from the site known as CRAN (Comprehensive R Archive Network)
with the address http://cran.r-project.org/. From this site one needs to
“Download and Install R” by running the appropriate pre-compiled binary
distributions. When R is installed properly, the R icon is displayed on the
desktop/laptop. To start R, one has to click on the R icon. The data analy￾sis in R proceeds as an interactive dialogue with the interpreter. As soon as
we type a command at the prompt (>) and press the enter key, the inter￾preter responds by executing the command. The session is ended by typing
q(). The latest version of R is 4.3.1 released on June 16, 2023. One can type R
codes in an editor file with “·R” extension and save the file for repeated use. A
more user-friendly interface for R is provided by another software named “R”Introduction to R Software and Language 3
Studio. It is also available freely for personal use. The latest version available
is 2023.06.2 + 561.
With this non-statistical part of the introduction to R, we now proceed to
discuss how it is used for statistical analysis. The discussion is not exhaustive,
but we restrict to the functions which are repeatedly used in this book. Like
any other programming language, R contains data structures. Vectors are the
basic data structures in R. The standard arithmetic functions and operators
apply to vectors on an element-wise basis, with usual hierarchy. We specify
below some such basic functions which we need to write R codes for under￾standing the concepts studied in this book. The most useful R command for
entering small data sets is the c (“combine”) function. This function combines
or concatenates terms together. One can use any variable name, but care is
to be taken as R is case sensitive. It may be noted that anything that appears
after the symbol # is ignored by R. It is only for understanding the code.
Code 1.2.1. This code presents some basic functions.
# To input vectors and matrices
x=c(14, 28, 35, 43, 56, 67) # c function to construct a vector
# with given elements
x # displays x, print(x) also displays the object x
length(x) # specifies a number of elements in x
y=1:7; y # constructs a vector with consecutive elements 1 to
# 7 and prints it.
# Two commands can be given on the same line with separator ";"
u=seq(100,250,50); u # sequence function to create a vector
# with first element 100, last element 250 and increment 50
v=c(rep(1,3),rep(2,2),rep(3,5));v # rep function to create a
vector
# where 1 is repeated thrice, 2 twice and 3 five times
m=matrix(c(22,28,33,41,54,67),nrow=2,ncol=3); m # matrix
# with 2 rows and 3 columns, with first two elements
# forming first column, next two second column, output is
> [,1] [,2] [,3]
[1,] 22 33 54
[2,] 28 41 67
m1=matrix(c(22,28,33,41,54,67),nrow=2,ncol=3,byrow=T); m1
# Now elements are row-wise. The output is
[,1] [,2] [,3]
[1,] 22 28 33
[2,] 41 54 67
# with additional argument byrow=T, we get matrix with 24 Sigma Field, Borel Field and Probability Measure
# rows and 3 columns, with first three elements forming
# first row and next three forming second row.
# By default byrow=F, see m matrix defined above
t(m) # function to obtain transpose of matrix m
□
R has excellent facility to find the values of probability mass function,
probability density function and distribution function for specified values, to
find quantiles and to draw random samples from some standard discrete and
continuous probability distributions. These can be obtained by the functions
d, p, q, r described below.
(i) The d function returns the probability density or probability mass func￾tion of the distribution.
(ii) The p function gives the value of a distribution function.
(iii) The q function gives the quantiles.
(iv) The r function returns a random sample from a distribution.
Each family has a name and some parameters. The function name is obtained
by combining either d, p, q or r with the name for the family. The parameter
names vary from family to family but are consistent within the family. Func￾tions d, p, q and r are illustrated in the following code for the binomial
B(10, 0.6) distribution.
Code 1.2.2. pr=dbinom(c(3,4,5),10,.6); pr1=round(pr,4); pr1
# values in pr rounded to four digits after the decimal point
# 0.0425, 0.1115, 0.2007: probability mass function at 3,4,5
df=pbinom(c(3,4,5),10,.6); df1=round(df,4); df1
# 0.0548, 0.1662, 0.3669: distribution function at 3,4,5
qbinom(c(.25,.5,.75),10,.6)
# 5,6,7: first,second and third quartiles
r=rbinom(8,10,.6); r # random sample of size 8
# 3 6 9 6 5 5 6 6
□
If we run the function rbinom(8,10,.6) again, we may get a different
sample. If we wish to generate the same sample again, we have to use a
function set.seed. It is used and explained in Code 1.2.4.
We use functions rexp and rnorm to draw random samples from an ex￾ponential distribution and a normal distribution respectively. Thus, we need
to change the family name and add appropriate parameters. We can get the
names for all probability distributions by following the path on R console as
help → manuals (in pdf) → An Introduction to R → Probability distributions.Introduction to R Software and Language 5
The function round(pr,4) prints the values of pr, rounded to four digits
after the decimal point. It is to be noted that rounding is mainly for printing
purpose, original unrounded values of pr are stored in the object pr and used
in computations.
There are some useful built-in functions. Apart from many built-in func￾tions, one can write a suitable function as required in a specific situation. In
subsequent chapters, you will find many such functions written to serve the
specific purpose.
Code 1.2.3. This code illustrates some commonly used functions with a data
set stored in variable x.
x=rnorm(25,3,2) # random sample of size n=25 from normal
# distribution with mean 3 and standard deviation 2
mean(x); median(x); max(x); min(x); sum(x)
cumsum(x)# cumulative sum
var(x)# returns variance, divisor is (n-1) and not n
quantile(x,c(.25,.5,.75)) # three quartiles
summary(x) # gives minimum, maximum, three quartiles and mean
shapiro.test(x) # Shapiro-Wilk test for normality
# gives value of statistic and p-value
# Partial output
> summary(x)
Min. 1st Qu. Median Mean 3rd Qu. Max.
-1.387 2.250 3.426 3.356 4.360 7.978
> shapiro.test(x)
W = 0.97969, p-value = 0.8789
□
It is to be noted that we have drawn a random sample from the normal
distribution and from the p-value of Shapiro-Wilk test for normality; normality
is accepted, as is expected. We can carry out number of test procedures on
similar lines; manual from help menu lists some of these. We illustrate one
more test procedure after discussing graphical tools of R.
Graphical features of R software have a remarkable variety. Each graphical
function has a large number of options making production of graphics very
flexible. Graphical device is a graphical window or a file. There are two kinds
of graphical functions – the high-level plotting functions, which create a new
graph, and the low-level plotting functions, which add elements to an already
existing graph. The standard high-level plotting functions are plot() function
for scatter plot, hist() function for histogram and boxplot() function for
box plot, etc. The lower-level plotting functions are lines() to impose curves
on the existing plot, abline() to add a line with a given intercept and slope,6 Sigma Field, Borel Field and Probability Measure
points() to add points at appropriate places, etc. These functions take extra
arguments that control the graphic. The graphs are produced with respect to
graphical parameters, which are defined by default and can be modified with
the function “par”. If we type ?par on R console, we get the description on num￾ber of arguments for graphical functions, as documented in R. We explain one
among these which is frequently used in the book. It is par(mfrow=c(2,2))
or par(mfcol=c(2,2)). This function divides the graphical window invisibly
in 2 rows and 2 columns to accommodate 4 graphs. A function legend() is usu￾ally added in plots to specify a list of symbols or colours used in the graphs.
Following code illustrates one test procedure and hist and lines functions.
Suppose {X1, X2, · · · , Xn} is a random sample from an exponential distri￾bution, with location parameter θ ∈ R and scale parameter 1. It is known that
for each n, the distribution of Tn = n(X(1)−θ) is exponential with mean 1. We
verify this result by simulations using the following procedure. Every sample
gives us one value of Tn. Hence to study the given distribution of Tn, we gen￾erate m samples from exponential distribution, with location parameter θ ∈ R
and scale parameter 1 and compute the value of Tn for each of these samples.
Thus, we get a sample of size m on Tn. We then examine the distribution of
these m values graphically. We draw the histogram of these m values using
hist function, with relative frequencies on y-axis. Then we impose on it, the
graph of the probability density function of the exponential distribution with
mean 1, using lines function. We observe the closeness between the observed
and the expected distributions visually from the graph.
We confirm the visual impression with Karl Pearson’s test procedure for
testing goodness of fit. Karl Pearson’s test statistic is T =
Pk
i=1(oi − ei)
2/ei
,
where k denotes the number of classes and oi and ei respectively denote the
observed frequency and the expected frequency, expected under the expo￾nential distribution with mean 1, of the i-th class. Under the null hypothe￾sis that the observed data are from the exponential distribution with mean
1, T follows chi-square distribution. Using it we find the cut-off point and
the p-value to arrive at a decision. In the computation of T, we have not
pooled the frequencies which are less than 5. We also use the built-in func￾tion chisq.test(O1,p=ep1) for goodness of fit test. We note that the two
approaches give the same results.
Following code incorporates all these features. In the code we use the
function set.seed, so that every time we run the code, we get the same
sample. In the code the vector “ep” presents the difference between the values
of distribution function of the exponential distribution with mean 1 at break
points, that is, at class boundaries. Another function data.frame is used to
create an array-like structure by joining multiple vectors of the same length.
Code 1.2.4. th=1.5; n=60; nsim=2000; t=c()
for(i in 1:nsim)
{
set.seed(i)Introduction to R Software and Language 7
x=th+rexp(n,rate=1)
t[i]=min(x)
}
tn=n*(t-th); summary(tn); v=var(tn)*(nsim-1)/nsim; v
hist(tn,freq=FALSE,main=expression(paste("Histogram of T"[n])),
ylim=c(0,1),xlab=expression(paste("T"[n])),col="light blue")
O=hist(tn,plot=FALSE)$counts; sum(O)
bk=hist(tn,plot=FALSE)$breaks; bk
M=max(bk); u=seq(0,M,.1); y=dexp(u,rate=1)
lines(u,y,"o",pch=20,col="dark blue",lty=1)
legend("topright",pch=20,col="dark blue",lty=1,cex=.7,
legend="pdf of exponential distribution with mean 1")
ep=c()
for(i in 1:(length(bk)-1))
{
ep[i]=exp(-bk[i])-exp(-bk[i+1])
}
a=1-sum(ep); a; ep1=c(ep,a); ef=sum(O)*ep1; O1=c(O,0)
d=data.frame(O1,round(ef,2)); d
ts=sum((O1-ef)^2/ef);ts
df=length(ef)-1; df; b=qchisq(.95,df); b; p1=1-pchisq(ts,df); p1
chisq.test(O1,p=ep1) # pooling of frequencies less than
#5 is ignored
Without pooling the frequencies which are less than 5, T = 11.956. The
null distribution of the test statistic is χ
2
10. The cut-off and p-value are 18.3070
and 0.288 respectively. The built-in function also gives the same value of T
and the same p-value. Thus, with both approaches, we arrive at the conclu￾sion that the data may be from an exponential distribution with mean 1.
Figure 1.1 also leads to the same conclusion.
Code 1.2.4 illustrates d,r functions and a variety of graphical functions.
We use ylim, xlab and col arguments in hist function to set the limits
on y-axis using ylim=range(c(0,1)), label the x-axis as required and to set
colour of the histogram. Note that from hist function, we can extract the
observed frequencies and the cut-off points, with the help of $ operator. All
these features are used in a variety of graphs drawn in the subsequent chapters.
There are some other functions such as arrow, axis or many other argu￾ments to the usual functions like plot, which may be new to the reader. In
such cases, help from R or a simple Google search would give us idea about
the usage. Another simple way to learn these functions is to experiment by
changing the values of these arguments.8 Sigma Field, Borel Field and Probability Measure
FIGURE 1.1
Exponential Distribution with Mean 1: Observed and Expected Distributions
There are many books on introduction to statistics using R, such as Crawley
[9], Dalgaard [10], Purohit et al. [17] and Verzani [25]. There is a tremendous
amount of information about R on the web at http://cran.r-project.org/
with a variety of R manuals. Following are some links useful for beginners to
learn R software.
1. https://www.datacamp.com/courses/free-introduction-to-r
2. http://www.listendata.com/p/r-programming-tutorials.html
3. http://www.r-tutor.com/r-introduction
4. https://www.r-bloggers.com/list-of-free-online-r-tutorials/
5. https://www.tutorialspoint.com/r/
6. https://www.codeschool.com/courses/try-rLimit of a Sequence of Sets 9
As for any software or programming language, best way to learn R is to
use it for understanding the concepts and solving problems. We hope that this
brief introduction will definitely be useful to a reader to be comfortable with
R and follow the codes written in this and the subsequent chapters.
In the next section, we define a sequence of sets and discuss the concepts
related to its convergence.
1.3 Limit of a Sequence of Sets
Suppose Ω is a universal set, which we assume to be non-empty. We begin
with the basic concepts from set theory and define union and intersection of
two sets, countable and uncountable collections of sets. A countable collection
of sets refers to a finite or a countably infinite collection of sets.
Definition 1.3.1. Union and intersection of two sets: Suppose A1, A2 ⊆ Ω.
Then union of A1 and A2, denoted by A1 ∪A2 and intersection of A1 and A2,
denoted by A1 ∩ A2 are defined as,
A1 ∪ A2 = {ω | ω ∈ Ai
, for at least one i = 1, 2}
& A1 ∩ A2 = {ω | ω ∈ Ai
, for all i = 1, 2}.
Definition 1.3.2. Finite union and intersection: Suppose Ai ⊆ Ω, i =
1, 2, . . . , k. Then union and intersection of Ai
, i = 1, 2, . . . , k are respectively
defined as,
[
k
i=1
Ai = {ω | ω ∈ Ai
, for at least one i = 1, 2, . . . , k}
&
\
k
i=1
Ai = {ω | ω ∈ Ai
, for all i = 1, 2, . . . , k}.
Definition 1.3.3. Countable union and intersection: Suppose {An, n ≥ 1}
is a countably infinite collection of subsets of Ω. In this case, {An, n ≥ 1} is
always referred to as a sequence of subsets of Ω. Then the countable union and
countable intersection are respectively defined as,
[
n≥1
An = {ω | ω ∈ An, for at least one n ≥ 1}
&
\
n≥1
An = {ω | ω ∈ An, for all n ≥ 1}.
Definition 1.3.4. Uncountable union and intersection: Suppose {At, t ∈ T}
is a collection of subsets of Ω, where T, known as an index set, is uncountable.10 Sigma Field, Borel Field and Probability Measure
Then uncountable union and uncountable intersection are respectively defined
as,
[
t∈T
At = {ω | ω ∈ At, for at least one t ∈ T}
&
\
t∈T
At = {ω | ω ∈ At, for all t ∈ T}.
Remark 1.3.1. (i) These four types of unions and intersections can be sum￾marized as S
t∈T At and T
t∈T At, where T = {1, 2} or T = {1, 2, . . . , k} or
T = N = {1, 2, . . . , }, a set of natural numbers or T is any uncountable set,
such as T = (0, 1) or R or R
+. (ii) If {At, t ∈ T} is a collection of disjoint sets
in Ω, then S
t∈T At is denoted by P
t∈T At.
Following examples illustrate countable union and countable intersection
of a sequence of sets.
Example 1.3.1. Suppose Ω = (0, 1) and An = (0, 1/n), n ≥ 1. Then
S
n≥1 An = (0, 1) and T
n≥1 An = ∅. If Ω = [0, 1] and Bn = [0, 1/n], n ≥ 1,
then S
n≥1 Bn = [0, 1] and T
n≥1 Bn = {0}. □
Example 1.3.2. Suppose Ω = R. If An = (a − 1/n, a + 1/n), n ≥ 1, a ∈ R,
then S
n≥1 An = (a − 1, a + 1) and T
n≥1 An = {a}. □
Remark 1.3.2. De Morgan’s law related to complement of union/intersec￾tion is valid for finite, countable and uncountable unions and intersections. In
general,
 [
t∈T
At
c
=
\
t∈T
A
c
t and  \
t∈T
At
c
=
[
t∈T
A
c
t
,
where T = {1, 2} or T = {1, 2, . . . , k} or T = N = {1, 2, . . . , } or any uncount￾able set.
As in the setup of a sequence of real numbers, we now discuss the monotone
nature of a sequence of sets.
Definition 1.3.5. Non-decreasing sequence of sets: Suppose {An, n ≥ 1} is a
sequence of subsets of Ω. If An ⊆ An+1, ∀ n ≥ 1, then {An, n ≥ 1} is called
as a non-decreasing sequence of sets.
Definition 1.3.6. Non-increasing sequence of sets: Suppose {An, n ≥ 1} is a
sequence of subsets of Ω. If An ⊇ An+1, ∀ n ≥ 1, then {An, n ≥ 1} is called
as a non-increasing sequence of sets.
In Example 1.3.1 and Example 1.3.2, {An, n ≥ 1} is a non-increasing
sequence of sets. If {An, n ≥ 1} is defined by An = (0, n) or An = (0, 2
n), n ≥
1, then it is a non-decreasing sequence of sets. If a sequence of sets is either
non-decreasing or non-increasing, then it is referred to as a monotone sequence
of sets. If An = (0, 1/n) if n is odd and An = (−1/n, 1/n) if n is even, thenLimit of a Sequence of Sets 11
the sequence {An, n ≥ 1} is neither increasing nor decreasing and hence is not
a monotone sequence.
Once we have defined a sequence of sets, the next natural step is to define
a limit of a sequence of sets. However, not every sequence of sets has a limit, as
in the case of a sequence of real numbers. The concept of a limit of a sequence
of sets is parallel to that for a sequence of real numbers and is defined via
a limit supremum and a limit infimum. The limit supremum and the limit
infimum for a sequence {an, n ≥ 1} of real numbers is defined as follows.
lim sup an = inf
n≥1
sup
k≥n
ak and lim inf an = sup
n≥1
inf
k≥n
ak.
If lim sup an = lim inf an, then we say that limn→∞ an exists and its value
is the common value of lim sup an and lim inf an. If {an, n ≥ 1} is a conver￾gent sequence, then limn→∞ an measures roughly the size of an for large n.
lim sup an is a measure of how large an can be when n is large and lim inf an
is a measure of how small an can be when n is large.
For a sequence of sets, limit supremum and limit infimum are defined
analogously.
Definition 1.3.7. Limit supremum and limit infimum of a sequence of sets:
Suppose {An, n ≥ 1} is a sequence of subsets of Ω. Then the limit supre￾mum and the limit infimum of a sequence of sets, denoted by lim sup An and
lim inf An respectively are defined as,
lim sup An =
\
n≥1
[
k≥n
Ak & lim inf An =
[
n≥1
\
k≥n
Ak.
Limit supremum and limit infimum of a sequence of sets are also known
as a limit superior and a limit inferior respectively of a sequence of sets and
are also denoted by limAn and limAn respectively.
Definition 1.3.8. Limit of a sequence of sets: Suppose {An, n ≥ 1} is a
sequence of subsets of Ω. If lim sup An = lim inf An, then we say that limit of
a sequence of sets exists and it is the common set. Thus,
limn→∞
An = lim sup An = lim inf An.
Following example illustrates these concepts of a limit of a sequence for a
non-decreasing sequence.
Example 1.3.3. We find the limit of the sequence {An, n ≥ 1} where
An = (a + 1/n, b − 1/n). If a and b are such that a + 1/n > b − 1/n, then such
An sets will be ∅. Observe that An ⊆ An+1 ∀ n ≥ 1, thus {An, n ≥ 1} is a
non-decreasing sequence. Further ∀ n ≥ 1
A1 ⊆ A2 ⊆ A3 ⊆ · · · ⊆ An
⇒ A1 ∪ A2 ∪ · · · ∪ An = An & A1 ∩ A2 ∩ · · · ∩ An = A1.12 Sigma Field, Borel Field and Probability Measure
By the definition of the limit supremum,
lim sup An =
\
n≥1
[
k≥n
Ak =
\
n≥1
Cn, where Cn =
[
k≥n
Ak.
It is to be noted that
C1 =
[
k≥1
Ak = (a, b) C2 =
[
k≥2
Ak =
[
k≥1
Ak = (a, b)
In general, Cn =
[
k≥n
Ak =
[
k≥1
Ak = (a, b) ⇒ lim sup An =
\
n≥1
Cn = (a, b).
Now, by the definition of the limit infimum,
lim inf An =
[
n≥1
\
k≥n
Ak =
[
n≥1
Bn where Bn =
\
k≥n
Ak.
With An = (a + 1/n, b − 1/n), ∀ n ≥ 1
Bn =
\
k≥n
Ak = (a + 1/n, b − 1/n) ∩ (a + 1/(n + 1), b − 1/(n + 1)) ∩ · · ·
= (a + 1/n, b − 1/n) = An
⇒ lim inf An =
[
n≥1
Bn =
[
n≥1
An = (a, b)
⇒ lim sup An = lim inf An = (a, b) ⇒ lim An exists and is (a, b).
If An = [a+ 1/n, b−1/n] or An = (a+ 1/n, b−1/n] or An = [a+ 1/n, b−1/n),
then we proceed on similar lines and in all the three cases lim An exists and
is (a, b). □
Following theorem proves that the limit of a non-decreasing sequence of
sets exists and is a countable union. The proof is similar to the solution of
Example 1.3.3.
Theorem 1.3.1. Suppose {An, n ≥ 1} is a non-decreasing sequence of subsets
of Ω. Then limn→∞ An exists and is S
n≥1 An.
Proof. By the definition of a limit supremum,
lim sup An =
\
n≥1
[
k≥n
Ak =
\
n≥1
Cn, where Cn =
[
k≥n
Ak.
It is given that {An, n ≥ 1} is a non-decreasing sequence, hence An ⊆ An+1,
for all n ≥ 1. In particular, A1 ⊆ A2 ⇒ A1 ∪ A2 = A2. Further, A1 ⊆ A2 ⊆Limit of a Sequence of Sets 13
A3 ⊆ · · · ⊆ An implies A1 ∪ A2 ∪ · · · ∪ An = An. As a consequence,
C2 =
[
k≥2
Ak = A2 ∪ A3 ∪ · · · = A1 ∪ A2 ∪ A3 ∪ · · · = C1
Cn = An
[ [
k≥n+1
Ak

=
 [
k≤n
Ak
[ [
k≥n+1
Ak

= C1, ∀ n ≥ 1
⇒ lim sup An =
\
n≥1
Cn = C1 =
[
n≥1
An .
Now, by the definition of a limit infimum,
lim inf An =
[
n≥1
\
k≥n
Ak =
[
n≥1
Bn where Bn =
\
k≥n
Ak.
Again, in view of the non-decreasing nature of the sequence {An, n ≥ 1} we
have,
An ⊆ An+1 ⊆ An+2 ⊆ · · · ⇒ Bn =
\
k≥n
Ak = An, ∀ n ≥ 1
⇒ lim inf An =
[
n≥1
Bn =
[
n≥1
An
⇒ lim sup An = lim inf An =
[
n≥1
An
⇒ limn→∞
An exists and is [
n≥1
An.
The concepts of limit supremum, limit infimum and limit of a sequence
of sets are difficult to grasp due to their abstract nature. To overcome this
difficulty, it is essential that the theory and computations go hand in hand.
Hence, in the present book we have adopted an approach to explain theory
along with the computations and visual presentation of the concepts, wherever
possible. In the next example, we demonstrate the limit of a non-decreasing
sequence of sets, using R.
Example 1.3.4. In Example 1.3.3, we studied the limit of a non-decreasing
sequence {An, n ≥ 1}, where An = (a + 1/n, b − 1/n). In particular, suppose
a = 2 and b = 3. Note that A1 = A2 = ∅. The limit exists and it is A = (2, 3).
We use Code 1.3.1 to demonstrate the limit of a sequence {(2 + 1/n, 3 −
1/n), n ≥ 1} graphically.
Code 1.3.1. a=2; b=3
nvec=c(10,25,50,75,100,500,750,1000,2500,5000,10000)
colvec=rainbow(length(nvec),start=0.7,end=0.1)14 Sigma Field, Borel Field and Probability Measure
nlab=paste("n",nvec,sep="=")
plot(c(a-0.3, b+0.3),c(0,2),type="n",xlab="", ylab="",
ylim=c(0,11),
main="Limiting Behaviour of (2+1/n, 3-1/n)",yaxt="n")
for(i in 1:length(nvec))
{n=nvec[i]
text(x=b+0.2,y=i+0.1,labels=nlab[i])
rect(a+1/n,i,b-1/n,i+0.2,col=colvec[i] )
}
abline(v=c(2,3),col=1)
# function "rect" constructs a rectangle
Figure 1.2 clearly depicts the non-decreasing nature of the sequence
{An, n ≥ 1} and we note that for n ≥ 500, An is close to A = (2, 3). □
In the next example, we find the limit of a non-increasing sequence of sets.
Example 1.3.5. We find the limit of the sequence {An, n ≥ 1} where,
(i) An = (a−1/n, a+ 1/n), (ii) An = [a−1/n, a+ 1/n], (iii)An = (a−1/n, a+
FIGURE 1.2
Limit of a Non-decreasing SequenceLimit of a Sequence of Sets 15
1/n] and (iv) An = [a−1/n, a+1/n). By the definition of the limit supremum,
lim sup An =
\
n≥1
[
k≥n
Ak =
\
n≥1
Cn, where Cn =
[
k≥n
Ak.
With An = (a−1/n, a+1/n), C1 = (a−1, a+1) = A1, C2 = (a−1/2, a+1/2) =
A2 and continuing in this manner Cn = An, ∀ n ≥ 1. Hence,
lim sup An =
T
n≥1 An = {a}. Now, by the definition of the limit infimum,
lim inf An =
[
n≥1
\
k≥n
Ak =
[
n≥1
Bn where Bn =
\
k≥n
Ak.
With An = (a − 1/n, a + 1/n), ∀ n ≥ 1,
Bn =
\
k≥n
Ak = (a − 1/n, a + 1/n) ∩ (a − 1/(n + 1), a + 1/(n + 1)) ∩ · · · = {a}.
Hence, lim inf An =
[
n≥1
Bn = {a} ⇒ lim sup An = lim inf An = {a}
⇒ lim An exists and is {a}.
For the remaining three sequences, we proceed on similar lines and in all the
three cases lim An exists and is {a}. □
Example 1.3.6. Suppose Ω = (0, 1) and An = (0, 1/n), n ≥ 1. By the
definition of the limit supremum,
lim sup An =
\
n≥1
[
k≥n
Ak =
\
n≥1
Cn, where Cn =
[
k≥n
Ak.
With An = (0, 1/n), C1 = (0, 1) = A1, C2 = (0, 1/2) = A2 and continuing in
this manner Cn = (0, 1/n) = An, ∀ n ≥ 1. Hence, lim sup An =
T
n≥1
An = ∅.
Now, by the definition of limit infimum,
lim inf An =
[
n≥1
\
k≥n
Ak =
[
n≥1
Bn where Bn =
\
k≥n
Ak.
With An = (0, 1/n), B1 = ∅, B2 = ∅, similarly Bn = ∅, ∀ n ≥ 1 and hence
lim inf An =
S
n≥1 Bn = ∅. Thus, lim sup An = lim inf An = ∅ hence lim An
exists and is ∅. □
Example 1.3.7. Suppose Ω = [0, 1] and Dn = [0, 1/n], n ≥ 1. By the defini￾tion of the limit supremum,
lim sup Dn =
\
n≥1
[
k≥n
Dk =
\
n≥1
Cn, where Cn =
[
k≥n
Dk.16 Sigma Field, Borel Field and Probability Measure
On similar lines as in the previous example, we get Cn = Dn and
lim sup Dn =
T
n≥1
Dn = {0}. Further, Bn = {0}, ∀ n ≥ 1. Hence,
lim inf An =
[
n≥1
Bn = {0} ⇒ lim sup Dn = lim inf Dn = {0}
and hence lim Dn exists and is {0}. □
It is to be noted that in all the above three examples, we have non￾increasing sequence of subsets of Ω and their limit is the countable inter￾section. It is true in general for a non-increasing sequence. We prove it in the
next theorem.
Theorem 1.3.2. Suppose {An, n ≥ 1} is a non-increasing sequence of subsets
of Ω. Then limn→∞ An exists and is T
n≥1 An.
Proof. By the definition of a limit supremum,
lim sup An =
\
n≥1
[
k≥n
Ak =
\
n≥1
Cn, where Cn =
[
k≥n
Ak.
It is given that {An, n ≥ 1} is a non-increasing sequence, hence An ⊇ An+1,
for all n ≥ 1, that is, A1 ⊇ A2 ⊇ A3 ⊇ · · · . As a consequence,
C1 = A1 ∪ A2 ∪ A3 ∪ · · · = A1, C2 = A2 & Cn = An, ∀ n ≥ 1
⇒ lim sup An =
\
n≥1
Cn =
\
n≥1
An.
Now, by the definition of a limit infimum,
lim inf An =
[
n≥1
\
k≥n
Ak =
[
n≥1
Bn where Bn =
\
k≥n
Ak.
Since {An, n ≥ 1} is a non-increasing sequence, we get A1 ⊇ A2 ⊇ A3 ⊇ · · · ⊇
An which implies T
k≤n Ak = An, ∀ n ≥ 1. Hence,
Bn = An
\ \
k≥n+1
Ak

=
 \
k≤n
Ak
\ \
k≥n+1
Ak

=
\
n≥1
An = B1, ⇒ Bn = B1, ∀ n ≥ 1
⇒ lim inf An =
[
n≥1
Bn = B1 =
\
n≥1
An
⇒ lim sup An = lim inf An =
\
n≥1
An ⇒ limn→∞
An exists and is \
n≥1
An.Limit of a Sequence of Sets 17
Example 1.3.8. Suppose {An, n ≥ 1} is a sequence of sets where,
An = [a, b + 1/n], where a and b are such that a < b + 1/n ∀ n. Then
{An, n ≥ 1} is a decreasing sequence of sets and hence limit exists and it is
T
n≥1 An = [a, b]. □
Theorem 1.3.2 can be proved in a different way. It uses Theorem 1.3.1 and
the relation among lim sup An, lim sup Ac
n
, lim inf An and lim inf Ac
n
. To dis￾cuss this approach, we first derive the relations among lim sup An, lim sup Ac
n
,
lim inf An and lim inf Ac
n
.
Theorem 1.3.3. Suppose {An, n ≥ 1} is a sequence of subsets of Ω. Then
lim sup A
c
n = (lim inf An)
c & lim inf A
c
n = (lim sup An)
c
.
Proof. By the definition of a limit supremum and a limit infimum we have,
lim sup A
c
n =
\
n≥1
[
k≥n
A
c
k =
\
n≥1
 \
k≥n
Ak
c
=
 [
n≥1
\
k≥n
Ak
c
=

lim inf An
c
.
Similarly,
lim inf A
c
n =
[
n≥1
\
k≥n
A
c
k =
[
n≥1
 [
k≥n
Ak
c
=
 \
n≥1
[
k≥n
Ak
c
=

lim sup An
c
.
Following theorem is the same as Theorem 1.3.2, but the proof is given in
a different way.
Theorem 1.3.4. Suppose {An, n ≥ 1} is a non-increasing sequence of subsets
of Ω. Then limn→∞ An exists and is T
n≥1 An.
Proof. It is given that {An, n ≥ 1} is a non-increasing sequence of sets, hence
An ⊇ An+1, ∀ n ≥ 1 ⇒ A
c
n ⊆ A
c
n+1, ∀ n ≥ 1.
Thus, {Ac
n
, n ≥ 1} is a non-decreasing sequence. Hence by Theorem 1.3.1,
limn→∞ Ac
n
exists and it is S
n≥1 Ac
n = (T
n≥1 An)
c
. Since, limn→∞ Ac
n
exists,
we have
lim sup A
c
n = lim inf A
c
n = ( \
n≥1
An)
c
⇐⇒ (lim inf An)
c = (lim sup An)
c = ( \
n≥1
An)
c
⇐⇒ lim inf An = lim sup An =
\
n≥1
An.
Thus, limn→∞ An exists and is T
n≥1 An.18 Sigma Field, Borel Field and Probability Measure
Using the relations among lim sup An, lim sup Ac
n
, lim inf An and
lim inf Ac
n
, the next theorem proves that if a sequence {An, n ≥ 1} is a con￾vergent, then so is {Ac
n
, n ≥ 1}.
Theorem 1.3.5. Suppose {An, n ≥ 1} is a convergent sequence of subsets of
Ω with limit A. Then {Ac
n
, n ≥ 1} is also a convergent sequence with limit Ac
.
Proof. Since {An, n ≥ 1} is a convergent sequence with limit A, we have,
lim sup An = lim inf An = lim An = A
⇒ (lim sup An)
c = (lim inf An)
c = (lim An)
c = A
c
⇒ lim inf A
c
n = lim sup A
c
n = A
c by Theorem 1.3.3
⇒ lim A
c
n
exists and is A
c
.
Hence, if An → A then Ac
n → Ac
.
Example 1.3.9. In Example 1.3.5, we discussed the limit of a non-increasing
sequence {An, n ≥ 1}, where An = (a − 1/n, a + 1/n). We have noted that
the limit exists and it is A = {a}. In particular, suppose a = 2. We use Code
1.3.2 to present visually the limit of a sequence {(2 − 1/n, 2 + 1/n), n ≥ 1}.
Code 1.3.2. a=2; colvec=rainbow(11,start=0.7, end=0.1)
nvec=c(10,25,50,75,100,500,750,1000,2500,5000,10000)
nlab=paste("n",nvec,sep="=")
for(i in 1:length(nvec))
{
n=nvec[i]
if(i==1) plot(c(a-0.15, a+0.15),c(0, 2),type="n",xlab="",
ylab="",
ylim=c(0,11),main="Limiting Behaviour of (2-1/n,2+1/n)",yaxt="n")
text(x=a+0.12,y=i+0.1,labels=nlab[i])
rect(a-1/n,i,a+1/n,i+0.2,col=colvec[i])
}
From Figure 1.3, we observe that {An, n ≥ 1} is a non-increasing sequence
and for n = 10000, An is almost A = {2}. □
From Theorem 1.3.1 and Theorem 1.3.2, we note that a monotone sequence
of sets is convergent. However, the converse is not true, that is, every conver￾gent sequence need not be monotone, as is clear from the following example.
Example 1.3.10. Suppose {An, n ≥ 1} is a sequence of sets such that An ̸= ∅
for at least one n ≥ 1 and An ∩ Am = ∅, ∀ n ̸= m. We examine whether the
sequence is monotone and convergent. In the given sequence {An, n ≥ 1} allLimit of a Sequence of Sets 19
FIGURE 1.3
Limit of a Non-increasing Sequence
the sets are disjoint and hence it is not a monotone sequence. To examine if
it is convergent, note that lim inf An =
S
n≥1
T
k≥n
Ak =
S
n≥1
∅ = ∅. Further,
lim sup An =
\
n≥1
[
k≥n
Ak =
\
n≥1
Cn, where Cn =
[
k≥n
Ak.
Since {An, n ≥ 1} is a sequence of disjoint sets, ω ∈ Ω is only in one of the
sets of the sequence. Suppose ω ∈ Ak0
and ω /∈ Ak for k ̸= k0. Hence,
ω ∈ C1 =
[
k≥1
Ak, ω ∈ C2 =
[
k≥2
Ak, . . . , ω ∈ Ck0 =
[
k≥k0
Ak
but ω /∈ Ck0+1 =
[
k≥k0+1
Ak
⇒ ω ∈ Cn, ∀ n ≤ k0 but ω /∈ Cn, ∀ n > k0
⇒ lim sup An =
\
n≥1
Cn = ∅ = lim inf An
⇒ limn→∞
An exists and is ∅.
□
Example 1.3.11. Suppose {An, n ≥ 1} is a sequence of sets such that for
n ≥ 1, An = (a − 1/n, b − 1/n), a < b. We examine whether the sequence is20 Sigma Field, Borel Field and Probability Measure
monotone and convergent. Observe that A1 = (a − 1, b − 1) and
A2 = (a − 1/2, b − 1/2), neither A1 ⊆ A2 nor A2 ⊆ A1, which implies that
{An, n ≥ 1} is not a monotone sequence. To examine whether it is convergent,
we find lim sup An and lim inf An. Note that
Cn =
[
k≥n
Ak = (a − 1/n, b) ⇒ lim sup An =
\
n≥1
Cn = (a, b).
Similarly, Bn =
\
k≥n
Ak = (a, b − 1/n) ⇒ lim inf An =
[
n≥1
Cn = (a, b)
⇒ lim sup An = lim inf An = (a, b) ⇒ lim An = (a, b).
Thus, {An, n ≥ 1} is a non-monotone sequence, but it is convergent. □
In the next example using R, we plot a non-monotone convergent sequence.
Example 1.3.12. Suppose {An, n ≥ 1} is a sequence of sets where
An = (2 − 1/n, 3 − 1/n). From Example 1.3.11, it is clear that it is not a
monotone sequence but is convergent with limit A = (2, 3). We use Code 1.3.3
to plot the limit of this sequence.
Code 1.3.3. a=2; b=3
nvec=c(10,25,50,75,100,500,750,1000,2500,5000,10000)
colvec=rainbow(length(nvec),start=0.7,end=0.1)
nlab=paste("n",nvec,sep="=")
plot(c(a-0.5, b+0.5),c(0,2),type="n",xlab="",ylab="",
ylim=c(0,11),main="Limiting Behaviour of(2-1/n,3-1/n)",yaxt="n")
for(i in 1:length(nvec))
{n=nvec[i]
text(x=b+0.2,y=i+0.1,labels=nlab[i])
rect(a-1/n,i,b-1/n,i+0.2, col=colvec[i] )
}
abline(v=c(2,3),col=1)
From Figure 1.4, we note that the sequence {An, n ≥ 1} is non-monotone,
but for n ≥ 500, An is close to A = (2, 3). □
We now discuss some more examples to illustrate the concept of limit of a
non-monotone sequence of sets.
Example 1.3.13. Suppose {An, n ≥ 1} is a sequence of sets where,
An =

(3 − 1/n, 3 + 1/n), if n is odd ,
∅, if n is even.Limit of a Sequence of Sets 21
FIGURE 1.4
Non-monotone Convergent Sequence
With An = ∅ for even value of n we have,
lim sup An =
\
n≥1
[
k≥n
Ak =
\
n≥1
(3 − 1/n, 3 + 1/n) ⇒ lim sup An = {3}
Now, lim inf An =
[
n≥1
\
k≥n
Ak =
[
n≥1
Bn = ∅ ⇒ lim inf An = ∅
⇒ lim An does not exist.
If we define An = (3 − 1/n, 3) if n is odd and An = ∅, if n is even, then
Cn = An and lim sup An =
T
n≥1 Cn = ∅. Thus limit exists in this case and it
is an empty set. □
Example 1.3.14. Suppose {An, n ≥ 1} is a sequence of sets where
A2n = (0, 1/2n), n ≥ 1, A2n+1 = [−1, 1/(2n + 1)], n ≥ 0.22 Sigma Field, Borel Field and Probability Measure
We examine whether lim An exists. By the definition,
lim sup An =
\
n≥1
[
k≥n
Ak =
\
n≥1
Cn where Cn =
[
k≥n
Ak
For n = 2m, C2m =
[
k≥2m
Ak
= (0, 1/(2m)) ∪ [−1, 1/(2m + 1)] ∪ (0, 1/(2m + 2))· · ·
= [−1, 1/(2m))
For n = 2m − 1, C2m−1 =
[
k≥2m−1
Ak = [−1, 1/(2m − 1)] ∪ (0, 1/(2m))· · ·
= [−1, 1/(2m − 1)]
⇒ lim sup An =
\
n≥1
Cn = [−1, 1] ∩ [−1, 1/2) ∩ [−1, 1/3] · · · = [−1, 0].
Now, lim inf An =
[
n≥1
\
k≥n
Ak =
[
n≥1
Bn where Bn =
\
k≥n
Ak
For n = 2m, B2m =
\
k≥2m
Ak
= (0, 1/(2m)) ∩ [−1, 1/(2m + 1)] ∩ (0, 1/(2m + 2))· · ·
= ∅
For n = 2m − 1, B2m−1 =
\
k≥2m−1
Ak = [−1, 1/(2m − 1)] ∩ (0, 1/(2m))· · ·
= ∅
⇒ lim inf An = ∅ ⇒ lim An does not exist. □
Example 1.3.15. In this example we consider a sequence {An, n ≥ 1}, where
An =

(1 + 1/n, 3 − 1/n), if n is odd ,
(2 + 1/n, 4 − 1/n), if n is even.
Proceeding as in Example 1.3.14, it follows that lim sup An = (1, 4) and
lim inf An = (2, 3) and hence it is not a convergent sequence. Using Code
1.3.4, we plot sets An for some odd and even values of n, which demonstrates
the limiting behaviour of the sequence.
Code 1.3.4. a=1; b=3; c=2; d=4
nvec=c(10,25,50,75,100,505,750,1005,2500,5005,10000)
colvec=rainbow(length(nvec),start=0.7,end=0.1)
nlab=paste("n",nvec,sep="=")
plot(c(a-0.5, d+0.8),c(0,2),type="n", xlab="", ylab="",Limit of a Sequence of Sets 23
ylim=c(0,11),main="Limiting Behaviour of An",yaxt="n")
for(i in 1:length(nvec))
{
n=nvec[i]
text(x=d+0.5,y=i+0.1,labels=nlab[i])
if(n%%2!=0) rect(a+1/n,i,b-1/n,i+0.2,col=colvec[i])
if(n%%2==0) rect(c+1/n,i,d-1/n,i+0.2,col=colvec[i])
}
abline(v=c(2,3),col=1); abline(v=c(1,4),col=2)
From Figure 1.5, it is clear that the sequence is not convergent since for
odd and even values of n, sets An are different even for large n. With the
Code 1.3.5, we plot An for n = 10, 000 to n = 15, 005.
Code 1.3.5. n=10000; a=1;b=3;c=2;d=4
nvec=n+c(0,10,25,50,75,100,505,750,1005,2500,5005)
colvec=rainbow(length(nvec),start=0.7,end=0.1)
nlab=paste("n",nvec,sep="=")
plot(c(a-0.5, d+1),c(0,2),type="n", xlab="",
FIGURE 1.5
Non-convergent Sequence24 Sigma Field, Borel Field and Probability Measure
ylab="",ylim=c(0,11),
xlim=c(0,5),main="Limsup and Liminf An",yaxt="n")
for(i in 1:length(nvec))
{
n=nvec[i]
text(x=d+0.6,y=i+0.1,labels=nlab[i])
if(n%%2!=0) rect(a+1/n,i,b-1/n,i+0.2,col=colvec[i])
if(n%%2==0) rect(c+1/n,i,d-1/n,i+0.2,col=colvec[i])
}
abline(v=c(2,3),col=1); abline(v=c(1,4),col=2)
From Figure 1.6, note that if we take the union of all An sets after some n0,
say n0 = 10000, then Cn = (1, 4) for all n ≥ n0. The countable intersection
of Cn is then (1, 4) and hence lim sup An = (1, 4). Similarly, if we take the
intersection of all An sets after some n0, then Bn = (2, 3) for all n ≥ n0. The
countable union of Bn is then (2, 3) and hence lim inf An = (2, 3). □
We now investigate the concepts of lim sup An and lim inf An in more detail
and discuss their interpretation. We have defined lim sup An as
lim sup An =
\
n≥1
[
k≥n
Ak =
\
n≥1
Cn, where Cn =
[
k≥n
Ak.
FIGURE 1.6
Limit Supremum and Limit InfimumLimit of a Sequence of Sets 25
Cn is known as supk≥n Ak. Now observe that
Cn =
[
k≥n
Ak = An
[
Cn+1 ⇒ Cn ⊇ Cn+1,
that is, {Cn, n ≥ 1} is a non-increasing sequence of sets and hence by Theorem
1.3.2 is convergent with limit T
n≥1 Cn. Thus,
lim sup An =
\
n≥1
Cn = limn→∞
Cn = limn→∞
sup
k≥n
Ak.
Further, lim sup An =
T
n≥1
Cn can be interpreted as follows.
ω ∈ lim sup An ⇒ ω ∈
\
n≥1
Cn ⇒ ω ∈ Cn ∀ n ≥ 1
⇒ ω ∈
[
k≥n
Ak, ∀ n ≥ 1
⇒ ω ∈ Ak, for at least one k ≥ n and ∀ n ≥ 1
⇒ ω ∈ An for infinitely many values of n ≥ 1.
Thus, lim sup An is a set of points which belong to infinitely many sets of the
sequence {An, n ≥ 1}. lim inf An can also be expressed and interpreted in a
similar way. We have defined lim inf An as
lim inf An =
[
n≥1
\
k≥n
Ak =
[
n≥1
Bn where Bn =
\
k≥n
Ak.
Bn is known as infk≥n Ak. Now,
Bn =
\
k≥n
Ak = An
\
Bn+1 ⇒ Bn ⊆ Bn+1,
that is, {Bn, n ≥ 1} is a non-decreasing sequence of sets and hence by Theorem
1.3.1 is convergent with limit S
n≥1 Bn. Thus,
lim inf An =
[
n≥1
Bn = limn→∞
Bn = limn→∞
inf
k≥n
Ak.
Now,
ω ∈ lim inf An ⇒ ω ∈ limn→∞
Bn =
[
n≥1
Bn ⇒ ω ∈ Bn for at least one n≥1
⇒ ω ∈
\
k≥n
Ak, for at least one n ≥ 1
⇒ ω ∈ Ak, ∀ k ≥ n and for at least one n ≥ 1
⇒ ω ∈ An for all but finitely many values of n ≥ 1.26 Sigma Field, Borel Field and Probability Measure
Thus, lim inf An is a set of points which belong to all but finitely many sets
of the sequence {An, n ≥ 1}. Note that,
lim sup An = inf
n≥1
sup
k≥n
Ak & lim inf An = sup
n≥1
inf
k≥n
Ak.
Thus, the definitions of limit supremum and the limit infimum for a sequence
of sets is similar to those for a sequence of real numbers.
As discussed above, lim sup An is a set of points which belong to infinitely
many sets of the sequence {An, n ≥ 1} and lim inf An is a set of points which
belong to all but finitely many sets of the sequence {An, n ≥ 1}. It indicates
that lim inf An ⊆ lim sup An. We prove it in the following theorem.
Theorem 1.3.6. Suppose {An, n ≥ 1} is a sequence of subsets of Ω. Then
lim inf An ⊆ lim sup An .
Proof. By the definitions of lim sup An and lim inf An we have,
ω ∈ lim inf An ⇒ ω ∈
[
n≥1
\
k≥n
Ak
⇒ ω ∈
\
k≥n
Ak, for at least one n ≥ 1, say n0
⇒ ω ∈
\
k≥n0
Ak ⇒ ω ∈ Ak, ∀ k ≥ n0
⇒ ω ∈
[
k≥n0
Ak ⇒ ω ∈
[
k≥n
Ak ∀ n ≥ 1
⇒ ω ∈
\
n≥1
[
k≥n
Ak ⇒ ω ∈ lim sup An.
Thus, lim inf An ⊆ lim sup An.
We have discussed the interpretation of lim sup An and lim inf An. We il￾lustrate it using R code. A set lim sup An contains those points which occur in
infinitely many An sets. Hence, to check whether, say x belongs to lim sup An,
we adopt the following approach. As per the definition of lim sup, we know
that lim sup is a collection of those elements of x which occur in infinitely many
An sets. Hence, for any x in lim sup An, if we define a set T(x) as follows,
T(x) = {n ∈ N|x ∈ An},
T(x) would be a countably infinite subset of N and hence an unbounded set.
Therefore, any natural number n0 cannot be an upper bound for T(x). That is,
for any natural number n0, we would find some other natural number n > n0
such that n ∈ T(x). Therefore, to conclude that x belongs to infinitely may
Ans, given any natural number n0, we should be able to find at least one
n > n0 such that x ∈ An. In the next example, we find n for given values of
n0 and x using R. One may try different values of x between (1, 4) and n0.Limit of a Sequence of Sets 27
Example 1.3.16. In Example 1.3.15, if we consider two separate subse￾quences corresponding to odd and even values of n respectively, we can see that
both these subsequences are increasing. Hence, to prove that x is in infinitely
many Ans, it is enough to find one An containing x. It would automatically
be in every alternate An beyond this n. To find one such n we first locate
whether x is closer to 1 or 4. If x is closer to 1, let ϵ = x − 1. Then, we need
to find odd n such that 1/n < ϵ, so that 1 + 1/n < x and hence, x ∈ An for
that n. However, in general, we also want to make sure that this n is larger
than n0. Hence we take maximum over the two numbers. If x is closer to 4,
we let ϵ = 4 − x, we find even value of n such that 4− x > 1/n and again take
max{n, n0}. We use Code 1.3.6.
Code 1.3.6. x=3.1; n0=20000; z=min(c(x-1,4-x)); a=1;b=3;c=2;d=4
{
n1=ifelse(ceiling(1/z)%%2==1,ceiling(1/z),ceiling(1/z)+1)
n2=ifelse(n0%%2==1,n0,n0+1)
n=max(n1,n2)
}
n
nvec=n+c(0,10,25,50,75,100,505,750,1005,2500,5005,10000)
colvec=rainbow(length(nvec),start=0.7,end=0.1)
nlab=paste("n",nvec,sep="=")
plot(c(a-0.5, d+0.5),c(0,2),type="n",xlab="",ylab="",
ylim=c(0,11),xlim=c(0,5),main="Limsup An",yaxt="n")
for(i in 1:length(nvec))
{
n=nvec[i]
text(x=d+0.8,y=i+0.1,labels=nlab[i])
if(n%%2!=0) rect(a+1/n,i,b-1/n,i+0.2,col=colvec[i])
if(n%%2==0) rect(c+1/n,i,d-1/n,i+0.2,col=colvec[i])
}
abline(v=x,col=1,lty=3,lwd=2); axis(1,at=x,labels="x")
We observe from Figure 1.7 that x = 3.1 is present in all An with even
values of n > 20000. Thus x ∈ An for infinitely many n.
By the definition, lim inf An contains those points which occur in all but
finitely many Ans. From the graph in Figure 1.6, it seems that (2, 3) is the
lim inf. Hence, to check whether, say x belongs to lim inf An, we need the
following approach. Given x, we should be able to find n0 such that, x ∈ An
for every n ≥ n0. Hence, if x is closer to 3 than 2, we need to find n such that
x < 3 − 1/n, i.e., n > 1/(3 − x). Similarly, if x is closer to 2, we will choose
n > 1/(x − 2). We use Code 1.3.7 to find such n0 and draw Figure 1.8.28 Sigma Field, Borel Field and Probability Measure
FIGURE 1.7
Limit Supremum
Code 1.3.7. x=2.3; z=min(c(x-2,3-x)); nt=ceiling(1/z); n=nt; n
a=1;b=3;c=2;d=4
nvec=n+c(0,10,25,50,75,100,505,750,1005,2500,5005,10000)
colvec=rainbow(length(nvec),start=0.7,end=0.1)
nlab=paste("n",nvec,sep="=")
plot(c(a-0.5, d+0.5), c(0,2),type="n", xlab="",ylab="",
ylim=c(0,11),xlim=c(0,5),main="Liminf An",yaxt="n")
for(i in 1:length(nvec))
{n=nvec[i]
text(x=d+0.8,y=i+0.1,labels=nlab[i])
if(n%%2!=0) rect(a+1/n,i,b-1/n,i+0.2,col=colvec[i])
if(n%%2==0) rect(c+1/n,i,d-1/n,i+0.2,col=colvec[i])
}
abline(v=x,col=1,lty=3,lwd=2); axis(1,at=x,labels="x")
From Figure 1.8, note that the point x = 2.3 ∈ lim inf is in all the sets after
n = 4. Thus, the number of sets not containing points in lim inf An is finite.Limit of a Sequence of Sets 29
FIGURE 1.8
Limit Infimum
However, in the case of lim sup An, even though the points occur in infinitely
many Ans, the number of An’s which do not contain that x is also infinite.
For example, in this example x = 3.1 does not belong to any An where n is
odd. Note that x = 3.1 ∈/ lim inf An, but all points in lim inf An are also in
lim sup An. □
In the next two examples, we examine whether limit supremum and limit
infimum are distributive over union and intersection.
Example 1.3.17. In this example we examine whether
(i) lim sup(An
S
Bn) = (lim sup An)
S
(lim sup Bn) and
(ii) lim inf(An
T
Bn) = (lim inf An)
T
(lim inf Bn).
By the definition of limit supremum of a sequence of sets we have,
lim sup(An ∪ Bn) = \
n≥1
[
k≥n
(Ak ∪ Bk) = \
n≥1
h [
k≥n
Ak
[ [
k≥n
Bk
i
=
\
n≥1
h
Mn
[
Nn
i
,
where Mn =
[
k≥n
Ak & Nn =
[
k≥n
Bk.30 Sigma Field, Borel Field and Probability Measure
Now, (lim sup An)
S
(lim sup Bn) can be expressed as,
(lim sup An) ∪ (lim sup Bn) =  \
n≥1
[
k≥n
Ak
[ \
n≥1
[
k≥n
Bk

=
 \
n≥1
Mn
[ \
n≥1
Nn

⇒ lim sup(An
[
Bn) = (lim sup An)
[
(lim sup Bn)
if \
n≥1

Mn
[
Nn

=
 \
n≥1
Mn
[ \
n≥1
Nn

,
that is, if the distributive law is valid for countable union and countable in￾tersection. In general, it is not true, but we now show that it is true in this
setup, in view of the non-increasing nature of the sequences {Mn, n ≥ 1} and
{Nn, n ≥ 1}. Observe that,
Mn =
[
k≥n
Ak = An
[
Mn+1 ⇒ Mn ⊇ Mn+1
Nn =
[
k≥n
Bk = Bn
[
Nn+1 ⇒ Nn ⊇ Nn+1,
that is, both {Mn, n ≥ 1} and {Nn, n ≥ 1} are non-increasing sequences of
sets. We first prove that
\
n≥1

Mn
[
Nn

⊆
 \
n≥1
Mn
[ \
n≥1
Nn

⇐⇒ x ∈
\
n≥1

Mn
[
Nn

⇒ x ∈
 \
n≥1
Mn
[ \
n≥1
Nn

⇐⇒ x /∈
 \
n≥1
Mn
[ \
n≥1
Nn

⇒ x /∈
\
n≥1

Mn
[
Nn

.
Observe that
x /∈
 \
n≥1
Mn
[ \
n≥1
Nn

⇒ x /∈
 \
n≥1
Mn

& x /∈
 \
n≥1
Nn

⇒ ∃ n1 ∈ N such that x /∈ Mn1 & ∃ n2 ∈ N such that x /∈ Nn2
⇒ x /∈ Mn0 & x /∈ Nn0 where n0 = max{n1, n2}
⇒ x /∈ Mn0 ∪ Nn0 ⇒ x /∈
\
n≥1

Mn
[
Nn

.
In the third step, we use the non-increasing pattern of the sequences {Mn, n ≥
1} and {Nn, n ≥ 1}. Thus, T
n≥1

Mn
S
Nn

⊆
 T
n≥1
Mn
 S  T
n≥1
Nn

. NowLimit of a Sequence of Sets 31
we prove the inclusion in the reverse direction. Note that
x ∈
 \
n≥1
Mn
[ \
n≥1
Nn

⇒ x ∈
 \
n≥1
Mn

and/or x ∈
 \
n≥1
Nn

⇒ x ∈ Mn ∀ n ≥ 1 and/or x ∈ Nn ∀ n≥1
⇒ x ∈ Mn
[
Nn ∀ n ≥ 1
⇒ x ∈
\
n≥1

Mn
[
Nn

.
Thus we have proved that,
\
n≥1

Mn
[
Nn

=
 \
n≥1
Mn
[ \
n≥1
Nn

⇒ lim sup(An ∪ Bn) = (lim sup An) ∪ (lim sup Bn).
Now from (i) we have,
lim sup(A
c
n ∪ B
c
n
) = (lim sup A
c
n
) ∪ (lim sup B
c
n
)
⇐⇒ (lim sup(A
c
n ∪ B
c
n
))c = ((lim sup A
c
n
) ∪ (lim sup B
c
n
))c
⇐⇒ lim inf(A
c
n ∪ B
c
n
)
c = (lim sup A
c
n
)
c ∩ (lim sup B
c
n
)
c
⇐⇒ lim inf(An ∩ Bn) = (lim inf An) ∩ (lim inf Bn). □
Example 1.3.18. In this example we examine whether
(i) lim sup(An
T
Bn) = (lim sup An)
T
(lim sup Bn) and
(ii) lim inf(An
S
Bn) = (lim inf An)
S
(lim inf Bn).
We define sequences {An, n ≥ 1} and {Bn, n ≥ 1} as follows.
A2n+1 = {2n + 1}, n ≥ 0 A2n = {1, 2, . . . , 2n}, n ≥ 1
B2n+1 = {1, 2, . . . , 2n + 1}, n ≥ 0 & B2n = {2n}, n ≥ 1.
Now by the definition,
lim sup An =
\
n≥1
[
k≥n
Ak =
\
n≥1
Cn, where Cn =
[
k≥n
Ak.
For the given sequence {An, n ≥ 1}, observe that,
Cn = N, ∀ n ≥ 1 ⇒ lim sup An = N
Similarly, lim sup Bn = N ⇒ lim sup An
\
lim sup Bn = N.
Now, A1 ∩ B1 = {1}, A2 ∩ B2 = {2} and in general Mn = An ∩ Bn = {n}.
Hence, lim sup Mn =
\
n≥1
[
k≥n
Mk =
\
n≥1
Nn, where Nn =
[
k≥n
Mk.32 Sigma Field, Borel Field and Probability Measure
For the given sequence,
Nn =
[
k≥n
{k} = {n, n + 1, n + 2, . . .} ⇒ lim sup Mn =
\
n≥1
Nn = ∅
⇒ lim sup(An
\
Bn) ̸= (lim sup An)
\
(lim sup Bn),
for the sequences {An, n ≥ 1} and {Bn, n ≥ 1} as defined above. Thus in gen￾eral, lim sup(An
T
Bn) need not be equal to (lim sup An)
T
(lim sup Bn). We
use this result to examine whether (ii) is true. We prove (ii) by contradiction.
Thus we assume that lim inf(An ∪ Bn) = (lim inf An) ∪ (lim inf Bn) always.
Observe that
lim inf(An ∪ Bn) = (lim inf An) ∪ (lim inf Bn)
⇒ lim inf(A
c
n ∪ B
c
n
) = (lim inf A
c
n
) ∪ (lim inf B
c
n
)
⇒ (lim inf(A
c
n ∪ B
c
n
))c = ((lim inf A
c
n
) ∪ (lim inf B
c
n
))c
⇒ lim sup(A
c
n ∪ B
c
n
)
c = (lim inf A
c
n
)
c ∩ (lim inf B
c
n
)
c
⇒ lim sup(An ∩ Bn) = (lim sup An) ∩ (lim sup Bn),
but we have proved in (i) that this need not be true. Hence, limit infimum of
a sequence of union of two sets need not be equal to union of limit infimums
of individual sequences of sets. □
Example 1.3.19. Suppose {An, n ≥ 1} and {Bn, n ≥ 1} are sequences of sets.
If An → A and Bn → B as n → ∞. We examine whether An ∪ Bn → A ∪ B
and An ∩ Bn → A ∩ B as n → ∞. By the definition of a limit of a sequence
of sets, An → A and Bn → B implies that
lim sup An = lim inf An = A and lim sup Bn = lim inf Bn = B.
We have proved in Example 1.3.17 that lim sup(An ∪ Bn) = (lim sup An) ∪
(lim sup Bn). Using this result we have,
lim sup(An ∪ Bn) = lim sup An ∪ lim sup Bn = A ∪ B.
Now to find lim inf(An ∪ Bn) observe that,
ω ∈ lim inf(An ∪ Bn) ⇒ ω ∈ Ak ∪ Bk, ∀ k ≥ n1 ∈ N.
We make the following three cases.
Case(i): Suppose ω ∈ Ak ∀ k ≥ n1. Note that
ω ∈ Ak ∀ k ≥ n1 ⇒ ω ∈ lim inf An = A ⇒ ω ∈ A ∪ B.
Case(ii): Suppose ω ∈ Bk ∀ k ≥ n1. As in Case(i), observe that
ω ∈ Bk ∀ k ≥ n1 ⇒ ω ∈ lim inf Bn = B ⇒ ω ∈ A ∪ B.Limit of a Sequence of Sets 33
Case(iii) Suppose ω ∈ Ak for some k ≥ n1 and ω ∈ Bk for the remaining
k ≥ n1. Suppose
NA = {n ∈ N|n ≥ n1 & ω ∈ An} & NB = {n ∈ N|n ≥ n1 & ω ∈ Bn}.
We know that NA ∪ NB = {n1, n1 + 1, n1 + 2, . . . , }. Hence at least one of the
two sets must be countably infinite. Suppose NA is infinite. Then
ω ∈ An for infinitely many n’s
⇒ ω ∈ lim sup An = A ⇒ ω ∈ A ∪ B.
If NB is infinite, then using similar arguments we have ω ∈ A ∪ B. Thus from
these three cases, we conclude that lim inf(An ∪ Bn) ⊆ A ∪ B. To prove the
inclusion in other direction we proceed on similar lines. Observe that
ω ∈ A ∪ B ⇒ ω ∈ at least one of A & B
Now, ω ∈ A = lim inf An ⇒ ω ∈ Ak ∀ k ≥ n2 ∈ N
& or ω ∈ B = lim inf Bn ⇒ ω ∈ Bk ∀ k ≥ n3 ∈ N
⇒ ω ∈ Ak & or ω ∈ Bk ∀ k ≥ n4 = max{n2, n3}
⇒ ω ∈ Ak ∪ Bk ∀ k ≥ n4
⇒ ω ∈ lim inf(An ∪ Bn)
⇒ A ∪ B ⊆ lim inf(An ∪ Bn).
Consequently,
lim inf(An ∪ Bn) = A ∪ B = lim sup(An ∪ Bn) ⇒ An ∪ Bn → A ∪ B.
To examine whether An ∩ Bn → A ∩ B, note that by the result in Example
1.3.17, we have
lim inf(An ∩ Bn) = (lim inf An) ∩ (lim inf Bn) = A ∩ B.
Now to find lim sup(An ∩ Bn) observe that
ω ∈ A ∩ B ⇒ ω ∈ lim inf An ∩ lim inf Bn
⇒ ω ∈ lim inf An and ω ∈ lim inf Bn
⇒ ω ∈ An ∀ n ≥ n5 ∈ N & ω ∈ Bn ∀ n ≥ n6 ∈ N
⇒ ω ∈ An ∩ Bn ∀ n ≥ n7 = max{n5, n6}
⇒ ω ∈ lim inf(An ∩ Bn) ⇒ ω ∈ lim sup(An ∩ Bn)
⇒ A ∩ B ⊆ lim sup(An ∩ Bn).
Now to prove that lim sup(An ∩ Bn) ⊆ A ∩ B, suppose An ∩ Bn = Dn. By the34 Sigma Field, Borel Field and Probability Measure
definition of limit supremum, observe that
ω ∈ lim sup Dn ⇒ ω ∈
\
n≥1
[
k≥n
Dk
⇒ ω ∈
[
k≥n
Dk ∀ n ≥ 1
⇒ ω ∈ Dk for at least one k ≥ n & ∀ n ≥ 1
⇒ ω ∈ Ak ∩ Bk for at least one k ≥ n & ∀ n ≥ 1
⇒ ω ∈ Ak for at least one k ≥ n & ∀ n ≥ 1
& ω ∈ Bk for at least one k ≥ n & ∀ n ≥ 1
⇒ ω ∈ lim sup An = A & ω ∈ lim sup Bn = B
⇒ ω ∈ A ∩ B
⇒ lim sup(An ∩ Bn) ⊆ A ∩ B.
Thus, lim sup(An ∩Bn) = A∩B = lim inf(An ∩Bn) ⇒ An ∩Bn → A∩B.□
The next section is devoted to an important concept of a sigma field of
subsets of Ω and a particular sigma field, known as a Borel field.
1.4 Borel Field
Suppose Ω is a non-empty universal set. We now define different classes or
collections of subsets of Ω. These classes of sets have certain structures as
defined by a set of rules. Different rules yield different types of collections. We
begin with two types of collections: a field and a sigma field.
Definition 1.4.1. Field: A non-empty class A of subsets of Ω is called a field
or an algebra if it is closed under complementation and union of two sets, that
is, A is a field if (i) A ∈ A ⇒ Ac ∈ A and (ii) A1, A2 ∈ A ⇒ A1 ∪ A2 ∈ A.
Following theorem specifies some properties of a field.
Theorem 1.4.1. (i) The empty set and the universal set are members of a
field. (ii) A field is closed under finite unions and finite intersections.
Proof. (i) Suppose A is a field. Observe that,
A ∈ A ⇒ A
c ∈ A ⇒ A ∪ A
c = Ω ∈ A ⇒ Ω
c = ∅ ∈ A.
(ii) Suppose A1, A2, . . . Ak ∈ A. By the definition, B = A1 ∪ A2 ∈ A, hence,
B ∪A3 = A1 ∪A2 ∪A3 ∈ A. Continuing in this manner, we get that A1 ∪A2 ∪Borel Field 35
· · · ∪ Ak ∈ A. Now,
A1, A2, . . . Ak ∈ A ⇒ A
c
1
, Ac
2
, . . . Ac
k ∈ A
⇒ A
c
1 ∪ A
c
2 ∪ · · · ∪ A
c
k ∈ A
⇒ (A
c
1 ∪ A
c
2 ∪ · · · ∪ A
c
k
)
c ∈ A
⇒ A1 ∩ A2 ∩ · · · ∩ Ak ∈ A.
Thus, a field is closed under finite unions and finite intersections.
Example 1.4.1. Suppose we want to construct a field containing a subset A
of Ω. If a set A is in a field, then, by the definition of a field, Ac has to be in
A, union of A and Ac
is Ω and its complement is ∅, thus a field containing the
set A or generated by a collection {A} is given by, A = {Ω, A, Ac
, ∅}. □
Example 1.4.2. Suppose P = {A1, A2, A3} is a partition of Ω and we want
to find a field generated by the partition P. P is a partition of Ω implies
that A1, A2, A3 are disjoint sets and their union is Ω. If A denotes the field
generated by P, then the empty set and the universal set and A1, A2, A3 are
members of A. Further if A1 ∈ A, then its complement A2 + A3 ∈ A, note
that it is also the union of A2 and A3. Continuing in this way we have,
A =
n
Ω, ∅, A1, A2, A3, A1 + A2, A1 + A3, A2 + A3
o
. □
Remark 1.4.1. It is to be noted that there are ￾
3
0

+
￾
3
1

+
￾
3
2

+
￾
3
3

=
2
3 = 8 sets in the field. ￾
3
0

means selecting no set from the partition, which
corresponds to an empty set, ￾
3
1

means there are three ways of selecting 1 set
from the partition, which correspond to A1, A2, A3,
￾
3
2

gives the number of
ways in which two sets can be selected from the partition, which correspond to
A1+A2, A1+A3, A2+A3 and finally ￾
3
3

corresponds to A1+A2+A3 = Ω. Thus
if there are k sets in the partition then the field generated by the partition will
consists of 2
k
sets corresponding all possible sums of the sets of the partition.
Thus, the field A is given by,
A =
n
A | A =
X
t∈T
At where T is the powerset of {1, 2, . . . , k}
o
,
where summation over empty set is taken as the empty set.
Example 1.4.3. Suppose Ω = [0, ∞) and A is a class of all intervals of the
type [a, b). It is clear that [a, b) ∈ A, but [a, b)
c = [0, a) ∪ [b, ∞) is not in A.
Thus, A is not closed under complementation and hence it is not a field. □
We now extend the concept of a field of subsets of Ω to a sigma field which
is closed under countable unions.
Definition 1.4.2. Sigma field: A non-empty class A of subsets of Ω is called
a sigma field or a sigma algebra (also written as σ field, or σ algebra), if it is
closed under complementation and countable union, that is, A is a sigma field
if (i) A ∈ A ⇒ Ac ∈ A, and (ii) An ∈ A, n ≥ 1 ⇒
S
n≥1 An ∈ A.
Some properties of a sigma field are proved in the following 36 Sigma Field, Borel Field and Probability Measure
Theorem 1.4.2. (i) A sigma field is a field.
(ii) The empty set and the universal set are members of a sigma field.
(iii) A sigma field is closed under countable intersection.
(iv) A sigma field is closed under limits of monotone sequences.
(v) A sigma field is closed under limit supremum and limit infimum and
limit of a sequence of sets, if it exists.
Proof. (i) Suppose A is a σ field. Then it is closed under complementation.
Suppose An ∈ A are such that An = A2 ∀ n ≥ 2, then S
n≥1 An =
A1 ∪ A2 ∈ A. Thus, A is closed under complementation and finite union,
hence it is a field.
(ii) In (i) we have proved that a sigma field is a field, and the empty set
and universal set are members of a field and hence of a sigma field.
Alternatively, suppose An ∈ A, n ≥ 1 are such that An = Ac
1 ∀ n ≥ 2.
Then
[
n≥1
An ∈ A ⇒ A1 ∪ A
c
1 = Ω ∈ A ⇒ Ω
c = ∅ ∈ A .
Hence, the empty set and the universal set are members of a sigma field.
(iii) Suppose An ∈ A, n ≥ 1. Then
A
c
n ∈ A, n ≥ 1 ⇒
[
n≥1
A
c
n ∈ A ⇒
 [
n≥1
A
c
n
c
=
\
n≥1
An ∈ A.
Thus, a sigma field is closed under countable intersection.
(iv) It is proved in Theorem 1.3.1 and Theorem 1.3.2 that limit of a monotone
sequence is either a countable union or a countable intersection and hence
a sigma field is closed under limits of monotone sequences.
(v) A sigma field is closed under countable union and countable intersection
and hence lim sup An and lim inf An are members of a sigma field. If
a limit of a sequence {An, n ≥ 1} exists, then lim An = lim sup An =
lim inf An. lim sup An and lim inf An are members of a sigma field and
hence a sigma field is closed under limit of a sequence of sets, if it exists.
Example 1.4.4. In this example we examine whether the given classes are
fields and/or sigma fields.Borel Field 37
(i) Suppose A1 = {Ω, ∅}. It is obvious that A1 is a field as Ω
c = ∅ ∈ A1 and
∅
c = Ω ∈ A1. Further, Ω ∪ ∅ = Ω ∈ A1. Hence, A1 is a field. A sequence
of sets in A1 will have each set to be either Ω or ∅. Thus, the countable
union will be Ω if all An’s are not ∅ and it will be ∅ if all of An’s are ∅.
Thus, A1 is closed under complementation and countable union. Hence,
it is a sigma field.
(ii) Suppose A2 = {Ω, ∅, A, Ac}, where A ⊆ Ω. As in (i) we see that A2 is
closed under union and complementation. Again, if we define a sequence
of sets in A2, then the distinct sets are only four, and hence the countable
union is just a finite union. Hence, A2 is a field as well as a sigma field.
(iii) Suppose A3 = A2 ∪ B2, where A ⊆ Ω and B2 = {Ω, ∅, B, Bc} where
B ⊆ Ω. Observe that A, B ∈ A3, but A ∪ B is not in A3, hence A3 is
neither a field nor a sigma field.
(iv) Suppose A4 = A2 ∩ A3. Then A4 = A2, hence it is a field as well as a
sigma field. □
Remark 1.4.2. (i) We have verified that A1 = {Ω, ∅} is a sigma field. It
is known as a degenerate or a trivial sigma field. Similarly, a powerset P(Ω)
of Ω is also a sigma field. If A is any other sigma field of subsets of Ω, then
A1 ⊂ A ⊂ P(Ω). Thus, for any given Ω, there are always two sigma fields. The
first one is A1 = {Ω, ∅}, this is the smallest possible sigma field of subsets of
Ω. The second one is a powerset P(Ω) and is the largest sigma field of subsets
of Ω. (ii) It is to be noted that if a class of subsets of Ω is a field and it
contains finite number of sets then it is also a sigma field, as countable union
essentially reduces to a finite union. A class A of subsets of Ω is said to be a
finite field, if A is a finite set and is a field. Thus, a finite field is a sigma field.
From (iii) and (iv) of Example 1.4.4, we note that union of two sigma
fields may not be a sigma field but intersection of two sigma fields is a sigma
field. In the following theorem, we prove that intersection of two sigma fields
is always a sigma field.
Theorem 1.4.3. Intersection of two sigma fields is a sigma field.
Proof. Suppose A1 and A2 are two sigma fields and A = A1 ∩A2. Being sigma
fields, {Ω, ∅} ⊆ A1 and {Ω, ∅} ⊆ A2, thus, {Ω, ∅} ⊆ A implying that A is a
non-empty class of subsets of Ω. Now
A ∈ A ⇒ A ∈ A1 & A ∈ A2
⇒ A
c ∈ A1 & A
c ∈ A2 since Ai are sigma fields i = 1, 2
⇒ A
c ∈ A1 ∩ A2 = A.
Now consider a sequence {An, n ≥ 1} of sets in A. Observe that,
∀ n ≥ 1, An ∈ A ⇒ An ∈ Ai
, i = 1, 2
⇒
[
n≥1
An ∈ Ai
, i = 1, 2 ⇒
[
n≥1
An ∈ A.38 Sigma Field, Borel Field and Probability Measure
Thus, A is closed under complementation and countable union and hence is a
sigma field.
Remark 1.4.3. Using similar arguments as in the proof of Theorem 1.4.3,
it can be proved that finite intersection and even countable intersection of
sigma fields is a sigma field. In the next theorem, we extend it to uncountable
intersection.
Theorem 1.4.4. Suppose {At, t ∈ T} is a collection of sigma fields, then
A =
T
t∈T At is a sigma field.
Proof. Proof is exactly on similar lines as those of Theorem 1.4.3.
Example 1.4.5. Suppose Ω = R and Fn is the sigma field generated by
subsets {A1, A2, . . . , An} of Ω where Ak = [k − 1, k), k = 1, 2, . . . , n. We list
the sets in F2. By the definition
F2 = σ({A1, A2}) = σ({[0, 1), [1, 2)}) = n
Ω, ∅, [0, 1), [1, 2),
(−∞, 0) ∪ [1, ∞),(−∞, 1) ∪ [2, ∞), [0, 2),(−∞, 0) ∪ [2, ∞)
o
.
We examine whether there is any relation between Fn and Fn+1, such as
whether Fn ⊂ Fn+1. It is to be noted that {A1, A2, . . . , An} is a collection of
disjoint sets. Hence,
Fn = σ({A1, A2, . . . , An})
=
(
Ω, ∅, A1, A2, · · · , An, Ac
1
, Ac
2
, · · · , Ac
n
,
X
T
Ai
,
X
T
Ai
c
)
,
where T denotes all possible subsets of {1, 2, . . . , n} except singletons and the
empty set. Similarly,
Fn+1 = σ({A1, A2, . . . , An+1})
=
(
Ω, ∅, A1, A2, · · · , An+1, Ac
1
, Ac
2
, · · · , Ac
n+1,
X
T
Ai
,
X
T
Ai
c
)
,
where T denotes all possible subsets of {1, 2, · · · , n+ 1} except singletons and
the empty set. It is clear that Fn ⊂ Fn+1 for all n ≥ 1. From F2 and the
sets listed in Fn, it is to be noted that each Fn consists of finite intervals,
finite sums of finite intervals, and sets of the type (−∞, a) ∪ [b, ∞). Hence,
S
n≥1 Fn also consists of finite intervals, finite sums of finite intervals, and
sets of the type (−∞, a) ∪ [b, ∞). Thus a set An = [n − 1, n) ∈
S
n≥1 Fn but
S
n≥1 An = [0, ∞) ∈/
S
n≥1 Fn ⇒
S
n≥1 Fn is not a sigma field. □
Definition 1.4.3. Co-finite set: A subset A of Ω is said to be co-finite if its
complement is finite.Borel Field 39
For example, suppose Ω = N, A = {4, 5, · · · , } then Ac = {1, 2, 3} is finite,
hence set A is co-finite.
Example 1.4.6. Suppose Ω is countably infinite and F is a class of all finite
and co-finite subsets of Ω. Suppose A ∈ F is finite, that is, A = (Ac
)
c
is finite,
hence Ac
is co-finite and hence is in F. Suppose A ∈ F is co-finite, then Ac
is
finite and hence is in F. Thus, F is closed under complementation. To check
whether it is closed under union, we make four cases depending on the nature
of the sets.
Case (i): Suppose A1, A2 ∈ F are both finite, then A1 ∪ A2 is also finite and
hence is in F.
Case (ii): Suppose A1, A2 ∈ F are such that A1 is co-finite and A2 is finite,
then Ac
1 ∩ Ac
2 = (A1 ∪ A2)
c ⊆ Ac
1
is finite, that is (A1 ∪ A2) is
co-finite and hence is in F.
Case (iii): Suppose A1, A2 ∈ F are such that A1 is finite and A2 is co-finite,
then proceeding as in case (ii) we get that (A1 ∪ A2) is co-finite
and hence is in F.
Case (iv): Suppose A1, A2 ∈ F are both co-finite, that is, both Ac
1
, Ac
2 ∈ F are
finite, then Ac
1 ∩ Ac
2 = (A1 ∪ A2)
c
is finite, that is (A1 ∪ A2) is co￾finite and hence is in F. Thus, F is closed under complementation
and finite union, hence it is a field. It will be a sigma field if it
is closed under countable union as well. Suppose Ω = I
+, An =
{2n} ∈ F, since it is a finite set ∀ n ≥ 1. However,
S
n≥1 An = {2, 4, 6, · · · } is not in F as it is neither finite nor co￾finite. Thus F is not a sigma field. □
Remark 1.4.4. In the above example, the universal set Ω is not finite. If it
is finite then all the sets and their complements are finite.
Example 1.4.7. Suppose Ω is an uncountable set and F is a class of all
countable subsets of Ω. A set is said to be countable if it is either finite or
countably infinite. We examine whether it is a sigma field. Suppose A is a
countable set, then A ∈ F. Since Ω is uncountable, Ac must be uncountable.
Hence, Ac ∈/ F and hence F is not a sigma field. For example, suppose Ω = R
and A is a set of all rational numbers, which is a countable set and hence
A ∈ F. However, Ac ∈/ F as it is a set of irrational numbers and is not
countable. Thus, F is not a sigma field. □
In the above example, if F is a class of all countable and co-countable
subsets of Ω, then it is a sigma field as shown in the following example. We
first define a co-countable set, it is similar to that of a co-finite set.
Definition 1.4.4. Co-countable set: A subset A of Ω is said to be co-countable
if its complement is countable.40 Sigma Field, Borel Field and Probability Measure
Example 1.4.8. Suppose Ω is uncountable and F is a class of all countable
and co-countable subsets of Ω. Suppose A ∈ F is countable, that is, A = (Ac
)
c
is countable, hence Ac
is co-countable and hence is in F. Suppose A ∈ F is
co-countable, then Ac
is countable and hence is in F. Thus, F is closed under
complementation. To check whether it is closed under union, we make three
cases depending on the nature of the sets.
Case (i): Suppose An ∀ n ≥ 1 are countable, then the fact that countable
union of countable sets is countable implies that S
n≥1 An is also
countable and hence is in F.
Case (ii): Suppose An ∀ n ≥ 1 are co-countable, then Ac
n
for all n ≥ 1 are
countable. Then T
n≥1 Ac
n
is atmost countable which implies that
(
T
n≥1 Ac
n
)
c =
S
n≥1 An is co-countable and hence in F.
Case (iii): Suppose some An’s are countable and remaining in the sequence
{An, n ≥ 1} are co-countable. Suppose n1 ∈ N is such that An1
is co-countable. Note that, An1
is co-countable and hence Ac
n1
is
countable. Further,
\
n≥1
A
c
n ⊆ A
c
n1
is countable ⇒
\
n≥1
A
c
n ∈ F
⇒ (
\
n≥1
A
c
n
)
c =
[
n≥1
An ∈ F.
Thus, F is closed under countable union. From these three cases we conclude
that F is a sigma field. □
Remark 1.4.5.
(i) In the above example, if the universal set Ω is countably infinite, then
all the sets and their complements are countably infinite and thus F is a
powerset of Ω. Hence, we have assumed that Ω is uncountable.
(ii) Suppose Ω = R and A = (−∞, 0], which is uncountable. Then Ac =
(0, ∞) is also uncountable. Thus neither A nor Ac are in F defined in
Example 1.4.8. It shows that in general, not all subsets of Ω = R are
members of F.
Suppose Ω is a non-empty universal set and A ⊆ Ω. A sigma field gener￾ated by a collection consisting of single set A, is given by A = {Ω, ∅, A, Ac}.
Similarly, a sigma field AB generated by a collection {A, B} of subsets of Ω,
is given by,
AB =
n
Ω, ∅, A, Ac
, B, Bc
, A ∪ B, A ∪ Bc
, Ac ∪ B, Ac ∪ Bc
, A ∩ B, A ∩ Bc
,
Ac ∩ B, Ac ∩ Bc
, A∆B,(A∆B)
c
o
, where A∆B is known as a symmetric dif￾ference and is defined as A∆B = (Ac ∩ B) ∪ (A ∩ Bc
). AB can also describedBorel Field 41
as a sigma field generated by {A}, but note that A ⊂ AB. The power set
P(Ω) of Ω is a sigma field generated by any class of subsets of Ω. In general,
for a given collection of subsets of Ω, there exist many sigma fields covering
the collection, so naturally there is a problem of choice and uniqueness. The
concept of minimal sigma field, as defined below, provides the solution.
Definition 1.4.5. Minimal sigma field: Suppose C is a non-empty class of
subsets of Ω. The minimal sigma field covering the class C, or generated by
the class C is denoted by σ(C). It is defined as the minimal sigma field if it
satisfies the following conditions. (i) σ(C) is a sigma field. (ii) C ⊆ σ(C).
(iii) If σ
∗
(C) is any sigma field generated by C, then σ
∗
(C) ⊇ σ(C).
Following theorem establishes the existence and the uniqueness of the min￾imal sigma field.
Theorem 1.4.5. There exists a unique minimal sigma field generated by a
non-empty class C of subsets of Ω.
Proof. Suppose {σt(C), t ∈ T} is a collection of sigma fields generated by C.
It is known that the powerset P(Ω) of Ω is a sigma field generated by any class
of subsets of Ω and thus, {σt(C), t ∈ T} is a non-empty collection. We define,
σ(C) = \
t∈T
σt(C).
From Theorem 1.4.4 it follows that σ(C) is a sigma field. Further, {σt(C), t ∈
T} is a collection of sigma fields generated by C, hence
C ⊆ σt(C) ∀ t ∈ T ⇒ C ⊆
\
t∈T
σt(C) = σ(C).
It is to be noted that by the definition of σ(C), for all t ∈ T σt(C) ⊇ σ(C) and
hence, σ(C) is a minimal sigma field, which establishes the existence of the
minimal sigma field. To prove uniqueness, suppose if possible, σ
∗
(C) is another
minimal sigma field generated by C. Then by the definition of minimal sigma
field,
σ
∗
(C) ⊆ σ(C) and σ(C) ⊆ σ
∗
(C) ⇐⇒ σ
∗
(C) = σ(C).
Thus, for any non-empty class of subsets of Ω, there exists a unique minimal
sigma field generated by the class.
Following are some results about the minimal sigma field.
Theorem 1.4.6. (i) If any non-empty class C of subsets of Ω, is a sigma
field, then σ(C) = C. (ii) Suppose C1 and C2 are two classes of sets such that
C1 ⊆ C2. Then σ(C1) ⊆ σ(C2).42 Sigma Field, Borel Field and Probability Measure
Proof.
(i) Suppose σ(C) is not C, but F. Then by the definition of the minimal
sigma field (i) F is a sigma field. (ii) C ⊆ F and (iii) If σ
∗
(C) is any
sigma field generated by C, then σ
∗
(C) ⊇ F. In particular, C is a sigma
field generated by C and hence C ⊇ F. Thus,
C ⊆ F & C ⊇ F ⇒ F = C.
(ii) Observe that C1 ⊂ C2 ⊂ σ(C2). Thus, σ(C2) is a sigma field covering
C1. Hence, by the definition of the minimal sigma field σ(C1) ⊂ σ(C2).
We now proceed to define the most exclusively used minimal sigma field in
probability theory and it is the minimal sigma field generated by a collection
of any type of intervals of the real line R. Suppose the universal set Ω is the
set R of real numbers. Then an interval of R can be any one of the following 8
types: (i) (a, b), (ii) (a, b], (iii) [a, b), (iv) [a, b], (v) (−∞, a), (vi) (−∞, a],
(vii) (a, ∞), (viii) [a, ∞), where a < b ∈ R.
Definition 1.4.6. Borel field: Suppose Ci is the class of intervals of type
i, i = 1, 2, · · · , 8. Then the minimal sigma field generated by any one of Ci,
denoted by B, is known as a Borel field.
Definition 1.4.7. Borel set: A set in the Borel field is known as a Borel set.
Example 1.4.9. This example shows that almost all the subsets of the real
line are Borel sets.
1. A set of real numbers R is a Borel set, since by the definition, Borel field
is the minimal sigma field of subsets of R. Thus, Ω = R and hence R ∈ B.
2. All eight types of intervals are Borel sets, since by the definition, Borel
field is the minimal sigma field generated by classes of any one type of
intervals.
3. A singleton set {a} can be expressed as {a} =
T
n≥1
(a − 1/n, a + 1/n).
Thus it is a countable intersection of intervals and hence is in the Borel
field. Thus, a singleton set {a} is a Borel set.
4. Any finite set can be expressed as a finite union of singleton sets and hence
it is a Borel set.
5. Any countable set can be expressed as a countable union of singleton sets
and hence it is a Borel set.
6. A set of rational numbers being countable is a Borel set. Similarly a set
irrational numbers, being complement of a set of rational numbers is a
Borel set.Borel Field 43
7. Suppose An = [0, n). Then S
n≥1 An = [0, ∞) and hence R
+ is a Borel set.
Further, R
− = (−∞, 0), being its complement is a Borel set.
8. Any open set can be expressed as a countable union of open intervals and
hence it is a Borel set.
9. Any open set is a Borel set and hence a countable union of open sets is a
Borel set. Similarly, countable intersection of open sets is a Borel set.
10. Suppose A is a closed set, then Ac
is an open set. Since Ac
is a Borel set,
A = (Ac
)
c
is also a Borel set. Hence any closed set is a Borel set. Borel
field being a sigma field, any countable union of closed sets is in the Borel
field and hence is a Borel set. Similarly, countable intersection of closed
sets is a Borel set.
11. A set A =
S
t∈T
{at}, where T is an uncountable set, may not be a Borel
set. □
From Definition 1.4.6, we note that there are 8 types of intervals but the
minimal sigma field generated by a class of any type of intervals is the same
and it is the Borel field. It can be proved that all of these classes of intervals
generate the same minimal sigma field. While proving such results, we note
that any type of class interval can be expressed in terms of intervals of other
types either by countable union or countable intersection or both. Following
are some such relations.
1. (a, b) = S
n≥1
[a + 1/n, b) = S
n≥1
(a, b − 1/n] = S
n≥1
[a + 1/n, b − 1/n]
2. [a, b] = T
n≥1
[a, b + 1/n) = T
n≥1
(a − 1/n, b] = T
n≥1
(a − 1/n, b + 1/n)
3. [a, b) = T
n≥1
(a − 1/n, b) = S
n≥1
[a, b − 1/n] = T
n≥1
S
m≥1
(a − 1/n, b − 1/m]
4. (a, b] = T
n≥1
(a, b + 1/n) = S
n≥1
[a + 1/n, b] = S
n≥1
T
m≥1
[a + 1/n, b + 1/m)
5. (−∞, a] = T
n≥1
(−∞, a + 1/n)
6. (−∞, a) = S
n≥1
(−n, a)
7. {a} = (−∞, a] ∩ [a, ∞)
In the following theorem, we demonstrate that the minimal sigma field
generated by classes of some type of intervals is the same. In the proof, we
use some of the relations listed above.44 Sigma Field, Borel Field and Probability Measure
Theorem 1.4.7. Suppose C1 is a class of intervals of the type (a, b), a <
b ∈ R, C2 is a class of intervals of the type (a, b], a < b ∈ R, C5 is a
class of intervals of the type (−∞, a), a ∈ R and C6 is a class of intervals
of the type (−∞, a], a ∈ R. Then (i) σ(C1) = σ(C2), (ii) σ(C1) = σ(C5),
(iii) σ(C1) = σ(C6) and hence σ(C1) = σ(C2) = σ(C5) = σ(C6).
Proof. (i) Since σ(C1) is the minimal sigma field generated by C1,
∀ n ≥ 1, (a, b + 1/n) ∈ C1 ⇒ ∀ n ≥ 1, (a, b + 1/n) ∈ σ(C1)
⇒
\
n≥1
(a, b + 1/n) = (a, b] ∈ σ(C1)
⇒ C2 ⊂ σ(C1) ⇒ σ(C2) ⊆ σ(C1).
The last step follows from the following arguments. C2 ⊆ σ(C1) im￾plies that σ(C1) is a sigma field generated by C2. Hence, the minimal
sigma field generated by C2 must be included in σ(C1). We use similar
arguments below. Now by the definition of C2,
∀ n ≥ 1, (a, b − 1/n] ∈ C2 ⇒ ∀ n ≥ 1, (a, b − 1/n] ∈ σ(C2)
⇒
[
n≥1
(a, b − 1/n] = (a, b) ∈ σ(C2)
⇒ C1 ⊆ σ(C2) ⇒ σ(C1) ⊆ σ(C2).
Thus, σ(C1) = σ(C2).
(ii) Since σ(C1) is the minimal sigma field generated by C1,
∀ n ≥ 1, (−n, a) ∈ C1 ⇒ ∀ n ≥ 1, (−n, a) ∈ σ(C1)
⇒
[
n≥1
(−n, a) = (−∞, a) ∈ σ(C1)
⇒ C5 ⊆ σ(C1) ⇒ σ(C5) ⊆ σ(C1).
Now by the definition of C5, (−∞, b) ∈ C5 ⇒ (−∞, b) ∈ σ(C5).
Further,
∀ n ≥ 1, (−∞, a + 1/n) ∈ C5 ⇒ ∀ n ≥ 1,(−∞, a + 1/n) ∈ σ(C5)
⇒
\
n≥1
(−∞, a + 1/n) = (−∞, a] ∈ σ(C5)
⇒ (−∞, a]
c = (a, ∞) ∈ σ(C5)
⇒ for b > a, (−∞, b) ∩ (a, ∞)
= (a, b) ∈ σ(C5)
⇒ C1 ⊆ σ(C5) ⇒ σ(C1) ⊆ σ(C5).
Thus, σ(C1) = σ(C5)Borel Field 45
(iii) Now σ(C6) is the minimal sigma field generated by C6. Hence,
∀ n ≥ 1, (−∞, b − 1/n] ∈ C6 ⇒ ∀ n ≥ 1, (−∞, b − 1/n] ∈ σ(C6)
⇒
[
n≥1
(−∞, b − 1/n]= (−∞, b) ∈ σ(C6) .
Now, (−∞, a] ∈ C6 ⇒ (−∞, a] ∈ σ(C6) ⇒ (a, ∞) ∈ σ(C6) .
Thus, (−∞, b) & (a, ∞) ∈ σ(C6) ⇒ (−∞, b) ∩ (a, ∞) = (a, b) ∈ σ(C6)
⇒ C1 ⊆ σ(C6) ⇒ σ(C1) ⊆ σ(C6).
Further, ∀ n ≥ 1, (a, n) ∈ C1 ⇒ ∀ n ≥ 1, (a, n) ∈ σ(C1)
⇒
[
n≥1
(a, n) = (a, ∞) ∈ σ(C1)
⇒ (a, ∞)
c = (−∞, a] ∈ σ(C1)
⇒ C6 ⊆ σ(C1) ⇒ σ(C6) ⊆ σ(C1) .
Hence, σ(C6) = σ(C1). We have thus shown that
σ(C1) = σ(C2) = σ(C5) = σ(C6) .
On similar lines one can show that minimal sigma fields generated by a
class of any type of intervals coincide and the common sigma field is labeled
as the Borel field.
In the following theorem, we show that a sigma field generated by the
collection of all open sets is also the Borel-field.
Theorem 1.4.8. Suppose O is a class of open sets in R. Then the minimal
sigma field generated by O is the same as the Borel field.
Proof. By the definition of the Borel field, σ(C1) = B, where C1 is a class
of intervals of the type (a, b), a, b ∈ R. Thus, the Borel field B contains all
open intervals. Since any open set can be written as a countable union of
open intervals, it follows that O ⊆ σ(C1) = B which further implies that
σ(O) ⊆ B. It is known that any open interval is an open set. Hence,
C1 ⊆ O ⇒ C1 ⊆ σ(O) ⇒ σ(C1) ⊆ σ(O) ⇒ B ⊆ σ(O).
Thus, we have σ(O) = B.
Borel field in k dimensions is defined on similar lines as those for one
dimension.46 Sigma Field, Borel Field and Probability Measure
Definition 1.4.8. Borel field in k dimensions: Suppose
Ik = {(x1, x2, · · · , xk)|ai ≤ xi ≤ bi
, ai
, bi
, xi ∈ R, i = 1, 2, · · · , k}
is a k-dimensional rectangle and Ck is a collection of rectangles of the type
Ik. The minimal sigma field generated by Ck, denoted by B
k
, is known as the
Borel field in k dimensions.
As in Theorem 1.4.7, it can be shown that the minimal sigma field gener￾ated by rectangles of any type in R
k
coincide and each one is the Borel field
in k dimensions. Further, the minimal sigma field generated by a class of open
sets in k dimensions is also the Borel field in k dimensions.
Definition 1.4.9. Measurable space: Suppose Ω is a non-empty universal set
and A is a sigma field of subsets of Ω. Then the set Ω along with associated
sigma field A, that is, a pair (Ω, A) is known as a measurable space.
For example, (R, B) is a measurable space, also (R
k
, B
k
) is a measurable
space.
Definition 1.4.10. Event: Suppose (Ω, A) is a measurable space. A set in A
is known as an event.
We have studied two types of classes of subsets of Ω of which sigma field is
the most important for theory as well as applications. There are other types
of classes also, we define these below.
Definition 1.4.11. Ring: A non-empty class F of subsets of Ω is said to be
a ring, if it is closed under finite unions and differences, that is, F is said
to be a ring, if A, B ∈ F implies that A ∪ B ∈ F and A − B ∈ F, where
A − B = A ∩ Bc
.
A class of all finite subsets of Ω is a ring. It is closed under finite intersec￾tions and symmetric differences, but not under countable unions.
Definition 1.4.12. Sigma ring: A non-empty class F of subsets of Ω is said
to be a sigma ring, if it is closed under countable unions and differences.
Thus, sigma ring is a ring closed under countable unions. Further, every
finite ring is a sigma ring. A class of all countable subsets of Ω is a sigma ring.
Definition 1.4.13. π-class: A non-empty class L of subsets of Ω is said to
be a π-class or a π-system, if it is closed under finite intersections, that is, L
is a π-class if A, B ∈ L ⇒ A ∩ B ∈ L.
From the definition it follows that a field and a sigma field are π-systems.
Further, a class of all intervals in R is also a π-system, the empty set being
taken as (a, a).Borel Field 47
Definition 1.4.14. λ-class: A non-empty class D of subsets of Ω is said to
be a λ-class or a λ system, if Ω ∈ D and if it is closed under complements and
countable unions of pairwise disjoint sets. Thus, D is a λ-class if, (i) Ω ∈ D,
(ii) A ∈ D ⇒ Ac ∈ D and (iii) An ∈ D such that Ai∩Aj = ∅ ⇒ S∞
n=1 An ∈
D.
Equivalently, a λ-class D is also defined as a non-empty class of subsets of
Ω that satisfies the following conditions. (i) Ω ∈ D, (ii) A, B ∈ D,
B ⊆ A ⇒ A − B ∈ D and (iii) An ∈ D ∀ n ≥ 1, An ↑ ⇒ S∞
n=1 An ∈ D.
A λ-class is also called as a Dynkin system. In the first set of conditions of
λ system, in view of disjointness of sets in condition (iii), λ system is weaker
than the sigma field. From the same set, condition (i) and (ii), together imply
that ∅ is a member of λ system. Since ∅ is a member of λ system, countable
union in condition (iii) can be reduced to finite union. Further, λ-class is also
a π-class.
Definition 1.4.15. Monotone class: A non-empty class M of subsets of Ω is
said to be a monotone class, if it is closed under limits of monotone sequences
of sets. Thus, M is a monotone class if, (i) An ∈ M ∀ n ≥ 1, An ↑ implies
S∞
n=1 An ∈ M and (ii) An ∈ M ∀ n ≥ 1, An ↓ ⇒ T∞
n=1 An ∈ M.
Definition 1.4.16. Monotone field: A field which is a monotone class is
known as a monotone field.
The following relations between different collections of sets are obtained
by the different properties of set operations, together with De Morgan’s rule.
1. Every field is a π-class.
2. Every sigma field is a field.
3. A field is a sigma field if and only if it is a monotone class, that is, a sigma
field is a monotone field and monotone field is a sigma field.
4. Every sigma field is a λ-class.
5. A λ-class is a sigma field if and only if it is π-class.
6. Every λ-class is a monotone class.
7. Every sigma field is a monotone class.
8. The power set of any subclass of Ω is a sigma field on that subclass.
9. If A is a sigma field and B ⊆ Ω, then B ∩ A = {B ∩ A|A ∈ A} is a sigma
field of subsets of B.
10. A ring is a sigma ring if and only if it is a monotone class, that is, a sigma
ring is a monotone class and a monotone ring is a sigma ring.48 Sigma Field, Borel Field and Probability Measure
11. Every sigma field is a λ-class. However, the converse is not true. For
counter example refer to page 5 of Stoyanov [23].
We state below a theorem related to a π-system and a λ-system, which is
known as Dynkin’s π-λ theorem. It is technical but extremely useful.
Theorem 1.4.9. Dynkin’s π − λ Theorem: If P is a π-system and L is a
λ-system, then P ⊆ L ⇒ σ(P) ⊆ L.
For proof refer to page 37 of Billingsley [5]. In Chapter 5 while discussing
independence of random variables, we discuss one more result about a π￾system and a λ-system.
In the next section, we discuss the important concept of a probability
measure.
1.5 Probability Space
The basis of probability theory is the probability space. In this section, we
discuss the axiomatic theory of probability. Although games of chance have
been performed for thousands of years, a mathematically rigorous treatment
of the theory of probability was given by the Russian mathematician A.N.
Kolmogorov in his fundamental monograph, which appeared in 1933. If a set
function P satisfies the three Kolmogorov axioms, as defined below, then P is
a probability measure.
Definition 1.5.1. Probability measure: Suppose (Ω, A) is a measurable space.
A set function P defined on (Ω, A) is known as a probability measure, if the
following conditions are satisfied.
(i) P(A) ≥ 0, ∀ A ∈ A, (non-negativity)
(ii) P(Ω) = 1, (normed measure)
(iii) If {An, n ≥ 1} is a sequence of disjoint sets in A, then P(
S
n≥1 An) =
P(
P
n≥1 An) = P
n≥1 P(An), (σ- additivity).
Definition 1.5.2. Probability space: A triplet (Ω, A, P) is known as a prob￾ability space, where Ω is a non-empty set, A is a sigma field of subsets of Ω
and P is a probability measure on the measurable space (Ω, A).
Some important properties of a probability measure are proved in the
following theorem.
Theorem 1.5.1. (i) P(∅) = 0. (ii) Probability measure is finitely additive,
that is, if {A1, A2, · · · , Ak} are disjoint sets from A, then P(
Sk
i=1 Ai) =
Pk
i=1 P(Ai). (iii) P(Ac
) = 1 − P(A). (iv) If A and B in A are such that
A ⊆ B, then P(A) ≤ P(B). (v) P(A) ≤ 1.Probability Space 49
Proof.
(i) From σ- additivity of the probability measure, if {An, n ≥ 1} is a se￾quence of disjoint sets in A, then P(
S
n≥1 An) = P
n≥1 P(An). In par￾ticular, suppose An = ∅, ∀ n ≥ 2, then S
n≥1 An = A1. Suppose
P(∅) = p ≥ 0. From σ- additivity,
P(
[
n≥1
An) = X
n≥1
P(An) ⇒ P(A1) = P(A1) + X
n≥2
P(∅)
⇒
X
n≥2
p = 0 ⇒ p = P(∅) = 0.
(ii) Suppose {An, n ≥ 1} is a sequence of disjoint sets in A, such that An = ∅,
∀ n ≥ k + 1. Then using the sigma additivity and the property P(∅) =
0, the identity P(
S
n≥1 An) = P
n≥1 P(An) reduces to P(
Sk
i=1 Ai) =
Pk
i=1 P(Ai).
(iii) By finite additivity, 1 = P(Ω) = P(A ∪ Ac
) = P(A) + P(Ac
), hence
P(Ac
) = 1 − P(A).
(iv) Observe that since A ⊆ B, B = (A ∩ B) ∪ (Ac ∩ B) = A ∪ (Ac ∩ B).
Hence, by finite additivity and non-negativity of probability measure
P(B) = P(A ∪ (A
c ∩ B)) = P(A) + P(A
c ∩ B) ≥ P(A).
(v) Note that, ∀ A ∈ A, A ⊆ Ω ⇒ P(A) ≤ P(Ω) = 1, by property (iv).
Remark 1.5.1. From Definition 1.5.2 and Theorem 1.5.1, it is to be noted
that A is a collection of all those subsets of Ω, whose probability can be
uniquely determined via relationships for complementation, union and inter￾section. Hence, A is a collection of all those subsets of Ω for which probability
measure can be assigned. Hence, (Ω, A) is known as a measurable space.
Example 1.5.1. Suppose (Ω, A) is a measurable space and a set function P is
defined on (Ω, A) such that the events A, B, C satisfy the following conditions:
P(A) = 0.6, P(B) = 0.8, P(C) = 0.7, P(A ∩ B) = 0.5, P(A ∩ C) = 0.4,
P(B ∩ C) = 0.4 and P(A ∩ B ∩ C) = 0.1. We examine whether P can be a
probability measure. Suppose P is a probability measure then
P(B ∪ C) = P(B) + P(C) − P(B ∩ C) = 1.5 − 0.4 = 1.1 > 1,
which is a contradiction. Hence P cannot be a probability measure.
Example 1.5.2. Suppose Ω = W, a set of whole numbers, A = P(Ω), power￾set of Ω, and a set function P on (Ω, P(Ω)) is defined as P(A) = P
i∈A e
−λλ
i/i!50 Sigma Field, Borel Field and Probability Measure
for A ∈ P(Ω) and λ is a positive real number. We examine whether P is
a probability measure on (Ω, P(Ω)). By the definition P(A) ≥ 0. Further,
P(Ω) = P
i∈W e
−λλ
i/i! = 1. To examine the third condition of sigma additiv￾ity, suppose {An, n ≥ 1} is a sequence of disjoint events. Then
P
 [
n≥1
An

=
X
i∈
S
n≥1
An
e
−λλ
i
i!
=
X
n≥1
 X
i∈An
e
−λλ
i
i!

=
X
n≥1
P(An).
Thus, the set function P satisfies all the conditions of a probability measure
and hence it is a probability measure on (Ω, P(Ω)). □
If Ω is countable then one can usually consider the sigma field as a power
set of Ω and a probability measure that assigns a value to every subset of
Ω. When Ω is uncountable, it may not be possible to define a reasonable
probability measure for every subset of Ω. In view of such a limitation, it is
necessary to introduce appropriate sigma fields and assign probability measure
for the sets in the sigma field
One of the basic questions is to what extent limits of sets carry over to
limits of probabilities of sets, that is, whether probabilities of converging sets
converge. We now discuss a continuity theorem for a probability measure,
which answers this question. As a pre-requisite, we prove a lemma, known as
a disjointification lemma.
Lemma 1.5.1. Suppose {An, n ≥ 1} is a sequence of sets in A. Then there
exists a sequence {Bn, n ≥ 1} of disjoint sets in A such that for m ∈ N,
(i)
[m
n=1
Bn =
[m
n=1
An & (ii)
[
n≥1
Bn =
[
n≥1
An .
Proof. For a given sequence {An, n ≥ 1} of sets in A, we define another
sequence {Bn, n ≥ 1} as follows.
B1 = A1 and for n ≥ 2, Bn = A
c
1 ∩ A
c
2 ∩ · · · A
c
n−1 ∩ An.
Thus ∀ n ≥ 1, Bn ∈ A. For n < m,
Bn = A
c
1 ∩ A
c
2 ∩ · · · A
c
n−1 ∩ An and Bm = A
c
1 ∩ · · · A
c
n ∩ · · · ∩ A
c
m−1 ∩ Am.
Observe that, for n < m, ω ∈ Bn ⇒ ω ∈ An ⇒ ω /∈ Ac
n ⇒ ω /∈ Bm.
Thus, for n < m, Bn ∩ Bm = ∅. Similarly we can prove that for n > m, Bn ∩
Bm = ∅, that is {Bn, n ≥ 1} is a sequence of disjoint sets in A. Further note
that,
ω ∈
[m
n=1
An ⇒ ω ∈ An for at least one n, say n0, which is first such n ≤ m
⇒ ω ∈ A
c
1 ∩ A
c
2 ∩ · · · A
c
n0−1 ∩ An0 = Bn0 ⇒ ω ∈
[m
n=1
Bn.Probability Space 51
Hence, Sm
n=1 An ⊆
Sm
n=1 Bn. Now suppose,
ω ∈
[m
n=1
Bn ⇒ ω ∈ Bn, for only one n, say n0, 1 ≤ n0 ≤ m
⇒ ω ∈ Bn0 = A
c
1 ∩ A
c
2 ∩ · · · A
c
n0−1 ∩ An0
⇒ ω ∈ An0 ⇒ ω ∈
[m
n=1
An.
Thus, Sm
n=1 Bn ⊆
Sm
n=1 An and hence Sm
n=1 Bn =
Sm
n=1 An. We now
prove that the relation is true for countable union as well.
ω ∈
[
n≥1
An ⇒ ω ∈ An for at least one n, say n0, which is first such n
⇒ ω ∈ A
c
1 ∩ A
c
2 ∩ · · · A
c
n0−1 ∩ An0 = Bn0 ⇒ ω ∈
[
n≥1
Bn.
Hence, S
n≥1 An ⊆
S
n≥1 Bn. Now suppose,
ω ∈
[
n≥1
Bn ⇒ ω ∈ Bn, for only one n, say n0
⇒ ω ∈ Bn0 = A
c
1 ∩ A
c
2 ∩ · · · A
c
n0−1 ∩ An0
⇒ ω ∈ An0 ⇒ ω ∈
[
n≥1
An .
Thus, S
n≥1 Bn ⊆
S
n≥1 An and hence S
n≥1 Bn =
S
n≥1 An .
Theorem 1.5.2. Continuity theorem for probability measure: Suppose
(Ω, A, P) is a probability space.
(i) If {An, n ≥ 1} is a non-decreasing sequence of sets in A, then
P(An) → P(A), as n → ∞ where A = limn→∞ An =
S
n≥1 An.
(ii) If {An, n ≥ 1} is a non-increasing sequence of sets in A, then
P(An) → P(A), as n → ∞ where A = limn→∞ An =
T
n≥1 An.
(iii) If {An, n ≥ 1} is a convergent sequence of sets in A, such that
limn→∞ An = A, then
limn→∞
P(An) = P(A) ⇐⇒ limn→∞
P(An) = P( limn→∞
An).
Proof.
(i) By Theorem 1.3.1, if {An, n ≥ 1} is a non-decreasing sequence of sets
in A, then limn→∞ An =
S
n≥1 An = A. Hence by Lemma 1.5.1 and
σ-additivity,52 Sigma Field, Borel Field and Probability Measure
P(A) = P

limn→∞
An

= P
 [
m≥1
Am

= P
 X
m≥1
Bm

=
X
m≥1
P(Bm)
= limn→∞
Xn
m=1
P(Bm) = limn→∞
P
 Xn
m=1
Bm

by finite additivity
= limn→∞
P
 [n
m=1
Am

by Lemma 1.5.1
= limn→∞
P(An), as [n
m=1
Am = An,
since {An, n ≥ 1} is a non-decreasing sequence.
(ii) Now {An, n ≥ 1} is a non-increasing sequence of sets in A, hence as
proved in Theorem 1.3.2, {Ac
n
, n ≥ 1} is a non-decreasing sequence of
sets in A and it is convergent with limit as Ac =
S
n≥1 Ac
n = (T
n≥1 An)
c
.
Thus by part (i),
limn→∞
P(A
c
n
) = P(A
c
) ⇐⇒ limn→∞
(1 − P(An)) = 1 − P(A)
⇐⇒ limn→∞
P(An) = P(A).
(iii) Since {An, n ≥ 1} is a convergent sequence with limit A, we have
lim sup An = lim inf An = lim An = A,
where, lim sup An and lim inf An are defined as,
lim sup An =
\
n≥1
[
k≥n
Ak =
\
n≥1
Cn, where Cn =
[
k≥n
Ak
& lim inf An =
[
n≥1
\
k≥n
Ak =
[
n≥1
Bn, where Bn =
\
k≥n
Ak.
As shown in Section 1.3, {Cn, n ≥ 1} is a non-increasing sequence of sets
and hence is convergent with
limn→∞
Cn =
\
n≥1
Cn = lim sup An = A
⇒ limn→∞
P(Cn) = P( limn→∞
Cn) = P(lim sup An) = P(A),
by part(ii). Similarly, {Bn, n ≥ 1} is a non-decreasing sequence of sets
and hence is convergent with
limn→∞
Bn =
[
n≥1
Bn = lim inf An = A
⇒ limn→∞
P(Bn) = P( limn→∞
Bn) = P(lim inf An) = P(A),Probability Space 53
by part (i). Now,
\
k≥n
Ak ⊂ An ⊂
[
k≥n
Ak ⇐⇒ Bn ⊂ An ⊂ Cn
⇒ P(Bn) ≤ P(An) ≤ P(Cn)
⇒ limn→∞
P(Bn) ≤ limn→∞
P(An) ≤ limn→∞
P(Cn)
⇒ P(lim inf An) ≤ limn→∞
P(An) ≤ P(lim sup An)
⇒ P(A) ≤ limn→∞
P(An) ≤ P(A)
⇒ limn→∞
P(An) = P(A) = P( limn→∞
An).
Remark 1.5.2. (i) Theorem 1.5.2 is labeled as a continuity theorem for prob￾ability measures in view of its similarity with the property of a real valued
continuous function. If {xn, n ≥ 1} is a sequence of real numbers and if g is
a continuous function then xn → x implies g(xn) → g(x). On similar lines,
if An → A then P(An) → P(A). (ii) The sigma additivity condition of the
probability measure is sometimes referred to as the continuity condition of a
probability measure, Bhat [4].
Theorem 1.5.3. Suppose (Ω, A, P) is a probability space. If {An, n ≥ 1} is a
sequence of sets in A, then P
 S
n≥1 An

≤
P
n≥1 P(An).
Proof. As in Lemma 1.5.1, for a given sequence {An, n ≥ 1} of sets in A, we
have another sequence of sets {Bn, n ≥ 1} as,
B1 = A1 and for n ≥ 2, Bn = A
c
1 ∩ A
c
2 ∩ · · · A
c
n−1 ∩ An.
It is proved in Lemma 1.5.1 that {Bn, n ≥ 1} is a sequence of disjoint sets in
A and S
n≥1 An =
P
n≥1 Bn. By the definition of Bn, Bn ⊆ An, hence
P(Bn) ≤ P(An). Thus,
P
 [
n≥1
An

= P
X
n≥1
Bn

=
X
n≥1
P(Bn) ≤
X
n≥1
P(An).
Remark 1.5.3. The inequality proved in Theorem 1.5.3 is known as Boole’s
inequality and this property of probability measure is known as sub sigma
additivity.
Theorem 1.5.4. Suppose (Ω, A, P) is a probability space. If {An, n ≥ 1} is a
sequence of sets in A, then54 Sigma Field, Borel Field and Probability Measure
(i) P(lim inf An) ≤ lim inf P(An) ≤ lim sup P(An) ≤ P(lim sup An).
(ii) If {An, n ≥ 1} is a convergent sequence of sets in A, such that
limn→∞ An = A, then limn→∞ P(An) = P(A).
Proof.
(i) By the definition,
lim inf An =
[
n≥1
\
k≥n
Ak =
[
n≥1
Bn where Bn =
\
k≥n
Ak.
Observe that by the definition of Bn, Bn ⊆ An ⇒ P(Bn) ≤ P(An).
Further, it is known that {Bn, n ≥ 1} is a non-decreasing sequence of
sets and hence is convergent with limn→∞ Bn =
S
n≥1 Bn = lim inf An.
Hence, by continuity theorem for probability measure,
limn→∞
Bn = lim inf An ⇒ limn→∞
P(Bn) = P( limn→∞
Bn) = P(lim inf An).
Further, limn→∞ P(Bn) exists and hence limn→∞ P(Bn) = lim inf P(Bn).
Thus, we have
P(lim inf An) = P( limn→∞
Bn) = limn→∞
P(Bn) = lim inf P(Bn)
= lim( inf
k≥n
P(Bk))
≤ lim( inf
k≥n
P(Ak)), as Bk ⊆ Ak, ∀ k ≥ n
= lim inf P(An). (1.1)
Now using the result (lim sup An)
c = lim inf Ac
n
, we have
P(lim sup An) = 1 − P((lim sup An)
c
) = 1 − P(lim inf A
c
n
)
≥ 1 − lim inf P(A
c
n
), by (1.1)
= 1 − lim inf(1 − P(An)) = 1 − sup
n≥1
( inf
k≥n
(1 − P(Ak)))
= 1 − sup
n≥1
((1 − sup
k≥n
P(Ak))) = 1 − (1 − inf
n≥1
sup
k≥n
P(Ak))
= inf
n≥1
sup
k≥n
P(Ak) = lim sup P(An) (1.2)
It is well known that for a sequence of real numbers {an, n ≥ 1},
lim inf an ≤ lim sup an. Hence using this result and combining (1.1) and
(1.2), we have
P(lim inf An) ≤ lim inf P(An) ≤ lim sup P(An) ≤ P(lim sup An).
(ii) Since {An, n ≥ 1} is a convergent sequence with limit A, we have
lim sup An = lim inf An = lim An = A. Hence by (i) we get
P(A) = P(lim inf An) ≤ lim inf P(An) ≤ lim sup P(An)
≤ P(lim sup An) = P(A).
Thus, lim inf P(An) = P(A) and lim sup P(An) = P(A), hence
lim P(An) exists and is equal to P(A).Probability Space 55
Remark 1.5.4. Result (ii) of Theorem 1.5.4 is the same as result (iii) of
Theorem 1.5.2.
Example 1.5.3. Suppose (Ω, A, P) is a probability space, where
Ω = {ω1, ω2, ω3, ω4}, A is a powerset of Ω and probability measure is defined
by
P({ω1}) = 2/9, P({ω2}) = 1/9, P({ω3}) = 4/9, P({ω4}) = 2/9.
A set An ∈ A is defined as An = {ω1, ω2} if n is odd and An = {ω2, ω3} if n is
even. We find P(lim inf An), P(lim sup An) and lim inf P(An), lim sup P(An)
and examine the relation established in Theorem 1.5.4. By the definition,
lim inf An =
[
n≥1
\
k≥n
Ak =
[
n≥1
{An ∩ An+1 ∩ · · · }
=
[
n≥1
{{ω1, ω2} ∩ {ω2, ω3} ∩ {ω1, ω2} · · · } if n is odd
=
[
n≥1
{{ω2, ω3} ∩ {ω1, ω2} ∩ {ω1, ω2} · · · } if n is even
=
[
n≥1
{ω2} = {ω2}.
Similarly by the definition,
lim sup An =
\
n≥1
[
k≥n
Ak =
[
n≥1
{An ∪ An+1 ∪ · · · }
=
\
n≥1
{{ω1, ω2} ∪ {ω2, ω3} ∪ {ω1, ω2} · · · }
=
\
n≥1
{ω1, ω2, ω3} = {ω1, ω2, ω3}.
Note that lim inf An ⊂ lim sup An, the two sets are not the same and hence
lim An does not exist. Further, P(lim inf An) = 1/9 and P(lim sup An) = 7/9.
For the given probability measure, P(An) = 3/9 if n is odd and 5/9 if n is
even. It is then clear that
lim inf P(An) = sup
n≥1
inf
k≥n
P(Ak) = sup
n≥1
3/9 = 3/9
& lim sup P(An) = inf
n≥1
sup
k≥n
P(Ak) = inf
n≥1
5/9 = 5/9.
Thus, lim inf P(An) ̸= lim sup P(An) hence lim P(An) does not exist. Further,
1
9
= P(limAn) < limP(An) = 3
9
< limP(An) = 5
9
< P(limAn) = 7
9
.
Thus, the relation established in Theorem 1.5.4 is verified. □56 Sigma Field, Borel Field and Probability Measure
Example 1.5.4. Suppose (Ω, A, P) is a probability space and {An, n ≥ 1} is
a sequence of disjoint sets from A. We find limn→∞ P(An). By the definition,
lim inf An =
[
n≥1
\
k≥n
Ak =
[
n≥1
∅ = ∅
& lim sup An =
\
n≥1
[
k≥n
Ak =
\
n≥1
Cn, where Cn =
[
k≥n
Ak = An∪An+1∪· · · .
Observe that,
ω ∈ A1 ⇒ ω /∈ An for any n ̸= 1 ⇒ ω /∈ Cn for any n = 1 ̸
⇒ ω /∈
\
n≥1
Cn = lim sup An.
On similar lines if ω is in any one of the sets of the sequence {An, n ≥ 1}, then
it cannot be in all Cn sets and hence in lim sup An. It is true for all ω ∈ Ω
and hence lim sup An = ∅. Thus limn→∞ An exists and it is ∅. Hence, by the
continuity theorem for a probability measure
limn→∞
P(An) = P( limn→∞
An) = P(∅) = 0. □
Example 1.5.5. Suppose (Ω, A, P) is a probability space and An ∈ A is
defined as An = (−∞, a + 1/n], n ≥ 1. Note that
An ⊃ An+1 ∀ n ≥ 1 ⇒ {An, n ≥ 1} is a non-increasing sequence
⇒ limn→∞
An =
\
n≥1
An = (−∞, a] = A, say
⇒ limn→∞
P(An) = P(A) by the continuity theorem.
In general, suppose {hn, n ≥ 1} is a non-increasing sequence of positive ratio￾nal numbers tending to 0 as n → ∞ and An is defined as An = (−∞, a + hn],
n ≥ 1. Then again {An, n ≥ 1} is a non-increasing sequence of sets with limit
as T
n≥1 An = (−∞, a] = A and P(An) ↓ P(A). Now suppose Bn is defined
as Bn = (−∞, a − hn], n ≥ 1. Observe that,
Bn ⊂ Bn+1 ∀ n ≥ 1 ⇒ {Bn, n ≥ 1} is a non-decreasing sequence
⇒ limn→∞
Bn =
[
n≥1
Bn = (−∞, a) = B, say
⇒ limn→∞
P(Bn) = P(B) by the continuity theorem. □
We will come across sequences of events similar to this example in Chapter
3, while discussing the right continuity and left continuity of a distribution
function.
A quick recap of the results discussed in this chapter is given below.Probability Space 57
Summary
1. Suppose {An, n ≥ 1} is a sequence of subsets of Ω. Then limit supremum
and limit infimum of a sequence of sets are defined as,
lim sup An =
\
n≥1
[
k≥n
Ak & lim inf An =
[
n≥1
\
k≥n
Ak.
2. lim inf An ⊆ lim sup An.
3. If {An, n ≥ 1} is a monotone sequence of subsets of Ω, then limn→∞ An
exists. If it is non-decreasing sequence, then limn→∞ An =
S
n≥1 An. If it
is a non-increasing sequence, then limn→∞ An =
T
n≥1 An.
4. If {An, n ≥ 1} is a non-monotone sequence of subsets of Ω, then
limn→∞ An exists if lim sup An = lim inf An.
5. A non-empty class A of subsets of Ω is called a field or an algebra if it is
closed under complementation and union of two sets.
6. The empty set and the universal set are members of a field and a field is
closed under finite unions and finite intersections.
7. A non-empty class A of subsets of Ω is called a sigma field or a sigma
algebra, if it is closed under complementation and countable union.
8. Properties of a sigma field: (i) A sigma field is a field. (ii) The empty set
and the universal set are members of a sigma field. (iii) A sigma field is
closed under countable intersection, limits of monotone sequences, limit
supremum and limit infimum of sets and limit of a sequence, if it exists.
(iv) Any arbitrary intersection of sigma fields is a sigma field.
9. Suppose C is a non-empty class of subsets of Ω. Then the minimal sigma
field σ(C) covering the class C, or generated by the class C, satisfies the
following conditions: (i) σ(C) is a sigma field, (ii) C ⊆ σ(C) and (iii) if
σ
∗
(C) is any sigma field generated by C, then σ
∗
(C) ⊇ σ(C).
10. There exists a unique minimal sigma field generated by a non-empty class
C of subsets of Ω.
11. The minimal sigma field generated by a class of any type of intervals of
real line is known as a Borel field. A set in the Borel field is known as a
Borel set.
12. If Ik = {(x1, x2, · · · , xk)|ai ≤ xi ≤ bi
, ai
, bi
, xi ∈ R, i = 1, 2, · · · , k} is a k
dimensional rectangle and Ck is the collection of rectangles of the type Ik,
then the minimal sigma field generated by Ck, denoted by B
k
, is known
as the Borel field in k dimensions.58 Sigma Field, Borel Field and Probability Measure
13. Suppose Ω is a non-empty universal set and A is a sigma field of subsets
of Ω. Then a pair (Ω, A) is known as a measurable space.
14. A set function P defined on (Ω, A) is known as a probability measure, if
the following conditions are satisfied.
(i) P(A) ≥ 0, ∀ A ∈ A, (non-negativity)
(ii) P(Ω) = 1, (normed measure)
(iii) If {An, n ≥ 1} is a sequence of disjoint sets in A, then
P(
S
n≥1 An) = P
n≥1 P(An), (σ- additivity).
15. Properties of a probability measure: (i) P(∅) = 0. (ii) Probability measure
is finitely additive. (iii) P(Ac
) = 1 − P(A). (iv) If A ⊆ B, then
P(A) ≤ P(B). (v) P(A) ≤ 1.
16. Continuity theorem for probability measures: Suppose (Ω, A, P) is a prob￾ability space. Then
(i) If {An, n ≥ 1} is a non-decreasing sequence of sets in A, then
P(An) → P(A), as n → ∞ where A = limn→∞ An =
S
n≥1 An.
(ii) If {An, n ≥ 1} is a non-increasing sequence of sets in A, then
P(An) → P(A), as n → ∞ where A = limn→∞ An =
T
n≥1 An.
(iii) If {An, n ≥ 1} is a convergent sequence of sets in A, such that
limn→∞ An = A, then limn→∞ P(An) = P(A).
17. Suppose (Ω, A, P) is a probability space. If {An, n ≥ 1} is a sequence of
sets in A, then
P(lim inf An) ≤ lim inf P(An) ≤ lim sup P(An) ≤ P(lim sup An).
1.6 Conceptual Exercises
1.6.1 Verify whether the following sequences of the sets are monotone.
(i) {(a −
1
n
, b +
1
n
), n ≥ 1}. (ii) {(a +
1
n
, b −
1
n
), n ≥ 1}.
(iii) {(a +
1
n
, b +
1
n
), n ≥ 1}. (iv) Suppose {An, n ≥ 1} is a sequence of
the sets, where An = {(x, y)|0 ≤ x ≤ n, 0 ≤ y ≤ 1/n}.
1.6.2 For the following sequences {An, n ≥ 1} of sets examine whether it has
a limit. If yes, find it.
(i) An = (a − 1/n, a + 1/n), (ii)An = [a − 1/n, a + 1/n],
(iii) An = (a − 1/n, a + 1/n], (iv) An = [a − 1/n, a + 1/n),
(v) An = (a − 1/n, a], (vi) An = (a, b + 1/n), (vii) An = (a, b + 1/n],
(viii) An = [a, b + 1/n), (ix) An = [a, b + 1/n], (x) An = (a, b − 1/n),
(xi) An = (a, b − 1/n], (xii) An = [a, b − 1/n), (xiii) An = [a, b − 1/n],
(xiv) An = (a − 1/n, b + 1/n), (xv) An = [a − 1/n, b + 1/n],
(xvi) An = (a − 1/n, b + 1/n], (xvii) An = [a − 1/n, b + 1/n).Conceptual Exercises 59
1.6.3 For the following sequences {An, n ≥ 1} of sets, examine whether it has
a limit. If yes, find it.
(i) An =

(0, 1/n), if n is odd
(−1/n, 1/n), if n is even.
(ii) An =

(0, 1/n), if n is odd
(1 − 1/n, 1), if n is even.
(iii) An =

(0, 1 − 1/n), if n is odd
(1/n, 1), if n is even.
(iv) An =
 ￾
2 −
1
n
, 2 + 1
n

, if n is odd
∅, if n is even.
(v) An =
 ￾
2 −
1
n
, 2

, if n is odd
∅, if n is even.
(vi) An = {0, 1/n, 2/n, · · · , 1 − 1/n, 1}.
(vii) An : set of rationals in 
1 −
1
n+1 , 1 + 1
n
i
,
(viii) A2n =
￾
0,
1
2n

, A2n+1 =
h
−1,
1
2n+1 i
, A1 = [−1, 1],
(ix) An: set of rationals in (1 −
1
n
, 1 + 1
n
).
1.6.4 Suppose a sequence {An, n ≥ 1} is defined as follows.
An =

B, if n is even
C, if n is odd.
Examine whether the sequence {An, n ≥ 1} converges. If yes find the
limit. If not, impose a condition on B and C so that it is a convergent
sequence.
1.6.5 Examine the limiting behaviour of the following sequence.
An =
￾
− ∞, 0

∪ (1/n, ∞), ∀ n ∈ N.
1.6.6 Give an example of a sequence of sets {An, n ≥ 1} where
lim sup An ̸= lim inf An.
1.6.7 Give an example to show that lim inf An ∪lim inf Bn ̸= lim inf(An ∪Bn).
1.6.8 Examine whether (i) lim sup(An
T
Bn) = lim sup An
T
lim sup Bn and
(ii) lim inf(An
S
Bn) = lim inf An
S
lim inf Bn if sequences {An, n ≥ 1}
and {Bn, n ≥ 1} are defined as follows. A1 = {1}, A2n = {2n}, A2n+1 =
[1, 2n + 1] and B1 = {1}, B2n = [1, 2n], B2n+1 = {2n +60 Sigma Field, Borel Field and Probability Measure
1.6.9 Examine whether
(i) lim inf An ∪ lim inf Bn ⊆ lim inf(An ∪ Bn)
⊆ lim sup(An ∪ Bn)
= lim sup An ∪ lim sup Bn
& (ii) lim inf An ∩ lim inf Bn = lim inf(An ∩ Bn)
⊆ lim sup(An ∩ Bn)
⊆ lim sup An ∩ lim sup Bn.
1.6.10 Give an example where the sequences {An, n ≥ 1} and {Bn, n ≥ 1} do
not converge, but {An ∩ Bn, n ≥ 1} and {An ∪ Bn, n ≥ 1} converge.
1.6.11 Suppose A = lim sup An and B = lim inf An. Then show that
M −A = lim inf(M −An) and M −B = lim sup(M −An) for any M ∈ Ω.
1.6.12 Suppose Ω is a finite set. Examine whether (i) a collection of all finite
subsets of Ω is a field and (ii) a collection of all singleton subsets of Ω
is a field.
1.6.13 Examine whether the following classes of subsets of Ω are field and /
or sigma field, where Ω is an uncountable set. Suppose A ⊆ Ω
(i) {Ω, ∅} (ii) {Ω, ∅, A}, (iii) {Ω, ∅, A, Ac}, (iv) P(Ω), (v) the class of all
finite subsets of Ω and (vi) the class of all countable subsets of Ω.
1.6.14 Suppose F is a sigma field of subsets of Ω. Suppose E ∈ F and E ̸= ∅.
Show that FE = {A ∩ E|A ∈ F} is the sigma field of subsets of E.
1.6.15 Suppose C2 is a class of intervals of the type (a, b], a < b ∈ R and C6
is a class of intervals of the type (−∞, a], a ∈ R. Then show that the
minimal sigma field generated by C2 is the same as that by C6.
1.6.16 Give an example of a class of events, which is closed under finite unions
and finite intersections but not under complementation.
1.6.17 Suppose Ω is a finite set and A is a field of subsets of Ω. Show that it
is a sigma field.
1.6.18 Suppose {Fn, n ≥ 1} is a sequence of fields of subsets of Ω, such that
Fn ⊆ Fn+1, ∀ n ≥ 1. Prove that S∞
n=1 Fn is a field. What can one say
if
{Fn, n ≥ 1} is a sequence of sigma fields?
1.6.19 Suppose Ω = N, the set of all natural numbers and An = {1, 2, . . . , n},
n ≥ 1. If An = σ({An}), verify whether {An, n ≥ 1}is an increasing
sequence.
1.6.20 Suppose P = {A1, A2, . . . , } is a countable partition of Ω and
A = {E|E = ∅ or E is a union of sets in P}. Show that A is the
minimal sigma field containing P.Conceptual Exercises 61
1.6.21 Suppose P1 = {Ai
, i = 1, 2, · · · , m} and P2 = {Bj , j = 1, 2, · · · , n} are
two partitions of Ω. Show that σ(σ(P1) ∪ σ(P2)) = σ(P), where
P = {Ai ∩ Bj , i = 1, 2, · · · , m, j = 1, 2, · · · , n} is a partition of Ω.
1.6.22 Suppose (Ω, A, P) is a probability space. Prove that for{A1, A2, · · · , An}
in A, P(
Tn
i=1 Ai) ≥
Pn
i=1 P(Ai) − (n − 1).
1.6.23 Suppose (Ω, A, P) is a probability space. Suppose {A1, A2, A3} ∈ A are
such that P(A1 ∩ A2 ∩ A3) = P(Ac
1 ∩ Ac
2 ∩ Ac
3
). Then show that each is
equal to
(1/2)[1−(P(A1)+P(A2)+P(A3))+P(A1 ∩A2)+P(A1 ∩A3)+P(A2 ∩
A3)].
1.6.24 Show that if P
n≥1 P(An) < ∞, then P(lim sup An) = 0. Examine if
P(lim inf An) = 0.
1.6.25 Suppose Ω = W, a set of whole numbers and A = P(Ω) and a set
function P on (Ω, P(Ω)) is defined as P(A) = P
i∈A p(1 − p)
i
for A ∈
P(Ω) and p ∈ (0, 1). Examine whether P is a probability measure on
(Ω, P(Ω).
1.6.26 Suppose (Ω, P(Ω), P) is a probability space, where P({ω}) = p ∈ (0, 1).
Show that Ω must be finite. If Ω consists of k elements, then p must be
1/k.
1.6.27 Suppose Ω = N, a set of natural numbers and P is a set function
defined on (Ω, P(Ω)) such that
P(A) = 
0, if A is finite
1, if A is infinite.
Is P a probability measure on (Ω, P(Ω))?
1.6.28 Suppose Ω = W, a set of whole numbers, A is a power set of Ω. Examine
whether set functions P defined below in (i), (ii) and (iii) are probability
measures on (Ω, A). (i) P(A) = number of points in A, (ii) for a non￾empty set A ∈ A, P(A) = P
x∈A µ({x}), where µ({x}) = 1/2
x
, x =
1, 2, · · · , µ({0}) = 1/2 and µ(∅) = 0 and (iii) µ({x}) = 1/2
x+1, x ∈ Ω.
1.6.29 Suppose (Ω, A, P) is a probability space and {An, n ≥ 1} and
{Bn, n ≥ 1} are sequences of sets from A. Suppose P(lim sup An) =
P(lim sup Bn) = 1. Examine whether (i) P(lim sup An ∩lim sup Bn) = 1
and (ii) P(lim sup An ∩ Bn) = 1.
1.6.30 Suppose (Ω, A) is a measurable space and B ∈ A is any non empty
subset of Ω. Suppose a class is defined as B ∩ A = {B ∩ A|A ∈ A} =
AB say. Show that AB is a sigma field of subsets of B. A function
PB : (B, AB) → [0, 1] is defined as PB(A) = P(B ∩ A)/P(B) ∀ A ∈ A.
Show that PB is a probability measure on (B, AB).62 Sigma Field, Borel Field and Probability Measure
1.6.31 Suppose {Bn, n ≥ 1} is a sequence of sets from A such that
P(Bn) = 1, ∀ n ≥ 1. Then show that P(
T
n≥1 Bn) = 1.
1.7 Computational Exercises
1.7.1 For any non-decreasing sequence {An, n ≥ 1}, find its limit and demon￾strate the limit of a sequence graphically.
1.7.2 For any non-increasing sequence {An, n ≥ 1}, find its limit and demon￾strate the limit of a sequence graphically.
1.7.3 Give an example of a non-monotone but convergent sequence of sets.
Demonstrate graphically that it is non-monotone but convergent.
1.7.4 Give an example of a non-convergent sequence {An, n ≥ 1} of sets and
graphically show that lim inf An ⊆ lim sup An. Further show that the
number of sets not containing points from lim inf An is finite whereas
for lim sup An this number is infinite.
1.8 Multiple Choice Questions
Note: In each question, multiple options may be correct. Unless specified
otherwise, identify which of the statement(s) is/are correct. Answers are given
in Chapter 11, after the solutions of conceptual exercises of Chapter 1.
1.8.1 Which of the following sequences is monotone decreasing?
(a) An = [a + 1/n, b − 1/n]
(b) An = {k ∈ N|k ≥ n}
(c) An = {a}
(d) An = [a − 1/n, b − 1/n]
1.8.2 Which of the following sequences {An, n ≥ 1} does/do NOT converge?
(a) A2n = C, A2n−1 = D, C ̸= D
(b) An = {k ∈ N|k ≤ n}
(c) An = {n} ∀ n ≥ 1
(d) An = A
1.8.3 Which of the following set operations are commutative?
(a) UnionMultiple Choice Questions 63
(b) Intersection
(c) Difference
(d) Symmetric Difference
1.8.4 Which of the following sequences converge to (a, b)?
(a) [a + 1/n, b)
(b) (a, b − 1/n]
(c) (a − 1/n, b − 1/n)
(d) [a + 1/n, b − 1/n]
1.8.5 Following are two statements: (I) Monotone sequences of sets are con￾vergent. (II) Convergent sequences of sets are monotone. Then which of
the following is correct?
(a) Both (I) and (II) are true
(b) (I) is true but (II) is false
(c) (II) is true but (I) is false.
(d) Both (I) and (II) are false.
1.8.6 Which of the following statements is/are true?
(a) lim sup is distributive over union
(b) lim inf is distributive over union
(c) lim sup is distributive over intersection
(d) lim inf is distributive over intersection
1.8.7 Following are four statements related to a sequence of sets.
(I) lim sup is distributive over union.
(II) lim inf is distributive over union.
(III) lim sup is distributive over intersection.
(IV) lim inf is distributive over intersection
Which of the following statements is true?
(a) Only (I) and (II) are true
(b) Only (I) and (III) are true
(c) Only (I) and (IV) are true
(d) Only (II) and (IV) are true
1.8.8 Which of the following statements is/are false?
(a) lim sup(An ∪ Bn) = (lim sup An) ∪ (lim sup Bn)
(b) lim inf(An ∩ Bn) = (lim inf An) ∩ (lim inf Bn)
(c) lim sup(An ∩ Bn) = (lim sup An) ∩ (lim sup Bn)
(d) lim inf(An ∪ Bn) = (lim inf An) ∪ (lim inf Bn).
1.8.9 F is a field. Ai ∈ F, ∀i. Which of the following belong to F?
(a) Ac
i
(b) S∞
i=1 Ai
(c) T∞
i=1 Ai
(d) Tk
i=1 Ai
.64 Sigma Field, Borel Field and Probability Measure
1.8.10 F1 and F2 are two σ-fields. Which of the following is/are σ-field(s)?
(a) F1
S
F2
(b) F1
T
F2
(c) σ(F1
S
F2)
(d) σ(F1
T
F2)
1.8.11 F1 and F2 are two σ-fields with F1 ⊇ F2. Which of the following is/are
σ-field(s)?
(a) F1
S
F2
(b) F1
T
F2
(c) σ(F1
S
F2)
(d) σ(F1
T
F2)
1.8.12 Suppose Ω = [0, ∞). Which of the following is/are field(s)?
(a) F1 = {I|I = [a, b) or I = [a, ∞), a, b ∈ Ω, a < b}
(b) F2= Class of all finite unions of intervals in F1
(c) F3 = {[0, 3),(3, ∞), Ω, ϕ}
(d) F4 = {(0, 4],(4, ∞), Ω, ϕ}
1.8.13 Which of the following sets are measurable with respect to A, if
A = σ({A
S
B})?
(a) A
(b) Bc
(c) Ac ∩ Bc
(d) A ∩ B
1.8.14 Which of the following statements is/are true?
(a) A finite field is a σ-field
(b) Every σ-field is a field
(c) A σ-field is closed under a limit of a sequence of sets in it, if it exists
(d) Power set is a σ-field
1.8.15 E = {E1, E2, . . . , En} is a partition of Ω. Which of the following is/are
field/s?
(a) G1 = {A|A is a union of sets in E}, individual Ei ∈/ G1
(b) G2 = Power set of E
(c) G3 = {Ω, ϕ, Sn
i=2 Ei
, E1}
(d) G4 = E
1.8.16 E = {E1, E2, . . . , En} is a partition of Ω. Which of the following is/are
sigma field/s?
(a) G1 = {A|A is a union of sets in E}, individual Ei ∈/ G1
(b) G2 = Power set of E
(c) G3 = {Ω, ϕ, Sn
i=3 Ei
, E1}
(d) G4 = EMultiple Choice Questions 65
1.8.17 E = {E1, E2, . . . , En} is a partition of Ω. Which of the following is/are
sigma field/s?
(a) G1 = {A|A is a union of sets in E}, individual Ei ∈/ G1
(b) G2 = Power set of E
(c) G3 = {Ω, ϕ, Sn
i=1 Ei
, E1}
(d) G4 = E
1.8.18 If {An, n ≥ 1} is a monotone increasing sequence of sets, which of the
following is/are true?
(a) An →
S
An
(b) Ac
n →
S
Ac
n
(c) P(An) → P(
S
An)
(d) P(Ac
n
) → P(
T
Ac
n
)
1.8.19 Suppose (Ω, A, P) is a probability space. Which of the following state￾ments is/are false?
(a) P(A) ≥ 0, ∀ A ∈ A
(b) P(Ω) = 1
(c) If {A1, A2, · · · , Ak} ∈ A, then P(
Sk
i=1 Ai) = Pk
i=1 P(Ai)
(d) If {An, n ≥ 1} is a sequence of disjoint sets in A, then
P(
S
n≥1 An) = P
n≥1 P(An)
1.8.20 Which of the following statements is/are not true?
(a) P(lim inf An) ≤ lim sup P(An)
(b) P(lim inf An) ≥ lim inf P(An)
(c) P(lim sup An) ≥ lim sup P(An)
(d) P(lim sup An) ≥ lim inf P(An)
1.8.21 Suppose {An, n ≥ 1} is a sequence of sets such that
An =

(2 − 1/n, 4 + 1/n), if n is odd
(1 − 1/n, 3 + 1/n), if n is even.
Which of the following points can be in lim sup An?
(a) 2
(b) 3
(c) 1
(d) 4
1.8.22 Suppose {An, n ≥ 1} is a sequence of sets such that
An =

(2 − 1/n, 4 + 1/n), if n is odd
(1 − 1/n, 3 + 1/n), if n is even.66 Sigma Field, Borel Field and Probability Measure
Which of the following points can be in lim inf An?
(a) 2
(b) 3
(c) 1
(d) 4
1.8.23 Suppose An → A ̸= ∅. For x ∈ A, a set Nx is defined as
Nx = {n ∈ N|x ∈ An}. Which of the following statements is/are true?
(a) Nx is a countably infinite set
(b) Nc
x = {n ∈ N|x /∈ An} is a finite set
(c) Nx can be empty set
(d) Nx = N always2
Random Variables and Random Vectors
2.1 Introduction
Any realistic model of a real-world phenomenon has to take into account the
possibility of randomness. It is usually achieved by allowing the model to be
probabilistic in nature. A starting point in the development of the theory of
probability is the concept of a random experiment. An experiment is a system￾atic method to collect data. Since it is a systematic method, an experiment
can be repeated any number of times. Conducting an experiment once is called
a trial. An experiment in which a set of possible outcomes of the experiment is
known, but an outcome of a given performance of the experiment is not known
in advance, is defined as a random experiment. In a random experiment, the
outcome is not known at any trial unless the experiment is conducted.
As an illustration, the annual premium of the vehicle insurance is based on
the estimate of claims, the vehicle owners will make in a period. The vehicle
may or may not meet with an accident. It is a random experiment with two
possible outcomes - accident occurs in a given year or accident does not occur
in a given period. In case there is no accident, there is no claim. If an accident
occurs, it is known before hand that the damage will be between two limits
say a and b. However, the actual value of the damage and hence of the claim
amount is not known in advance. In the determination of a premium, insurer
has to take into account the output of many such repeated cases of accidents
and claims, to model the distribution of the number of occurrences of accidents
and of the claim amount.
A fundamental concept in probability theory is to model the uncertainty
of a random experiment. With each such experiment, we associate a set Ω,
a set of all possible outcomes of the experiment. It is known as a sample
space associated with the experiment. It is assumed that the sample space
is known. Obviously, it is a non-empty set. If it is a singleton set, then the
random experiment is said to be deterministic. Thus, for an experiment to
be truly a random experiment, Ω must have at least two elements. A sample
space plays the role of a universal set as defined in Chapter 1. In modelling a
random phenomenon, usually some functions defined on Ω are of more interest
than the outcomes of the experiment. In many situations, one is interested in
only some aspects of the random experiment. For example, in an experiment
of tossing 3 unbiased coins, one is only interested in number of ‘heads’ turned
DOI: 10.1201/9781032619057-2 6768 Random Variables and Random Vectors
up. So our interest is only on certain functions on the sample space. These
functions are called random variables, if the image space is the real line. If the
image space is k dimensional Euclidean space, these functions are labeled as
random vectors and more generally if the image space is any abstract space,
then the functions on Ω are labeled as random elements.
In the present chapter, we make these concepts more precise, in which we
require the functions to be measurable with respect to a sigma field of subsets
of Ω. Towards it, we need to explore the concept of an inverse image of a
set and an inverse image of a collection of sets. In Section 2, we define these
concepts and study their properties. The main result we prove is that the
inverse image of the minimal sigma field covering C is the minimal sigma field
covering the inverse image of C and it is heavily used in subsequent sections.
We define the concept of “random variable” as a measurable function, using
two approaches. These lead to descriptive and economical definitions of a
random variable. We further elaborate on the concept of sigma field induced
by a random variable. We define a Borel function and prove that a Borel
function of a random variable is again a random variable, measurable with
respect to the same sigma field.
In Section 3, we extend all the results related to random variables, to
finite and infinite dimensional random vectors. Using the results about the
induced sigma fields, we prove that an infinite dimensional random vector can
be labeled as a sequence of random variables. Section 4 is devoted to the study
of a simple random variable and two important theorems concerned with a
sequence of simple random variables. These are useful in demonstrating that a
continuous function is a Borel function and in the definition of expectation of
a random variable, discussed in Section 4. Section 5 discusses the probability
measure induced by a random variable and a random vector and its connection
with the probability measure defined in Chapter 1.
2.2 Random Variables
To define the term “random variable” precisely, we begin with the concept of
an inverse image of a set.
Definition 2.2.1. Inverse image of a set: Suppose Ω1 and Ω2 are non empty
sets and X : Ω1 → Ω2 is a function. Suppose S ⊆ Ω2. Then the inverse image,
also known as inverse mapping, of a set S under the function X, denoted by
X−1
(S), is defined as,
X−1
(S) = {ω ∈ Ω1|X(ω) ∈ S}.
Thus, the inverse image of a set S is a set of all arguments whose images are
in S. It is to be noted that X−1
(S) ⊆ Ω1. Hence, the argument as well as the
image of the inverse function are sets.Random Variables 69
Example 2.2.1. Suppose Ω1 = {a, b, c, d, e, f} and Ω2 is a set of all alphabets.
A function X is defined on Ω1 → Ω2 as
X(ω) = 
z, if ω = a, b, c
y, if ω = d, e, f.
To find the inverse image of any subset S of Ω2, we divide the class of subsets
of Ω2 in four groups depending on whether y and z are in the set. Suppose
A = {a, b, c}. The inverse image of any subset S is then given by,
X−1
(S) =



∅, if y, z /∈ S
Ω1, if y, z ∈ S
A, if z ∈ S, y /∈ S
Ac
, if y ∈ S, z /∈ S.
Note that X−1
(S) ⊆ Ω1. □
In the definition of “random variable”, we assume Ω1 = Ω, which is a
sample space associated with the given random experiment. Further, instead
of having the domain of a function simply as Ω, it is taken as a measurable
space (Ω, A). Similarly, the co-domain is taken as a measurable space (R, B),
where B is the Borel field defined in Chapter 1.
Definition 2.2.2. Random variable: Suppose X : (Ω, A) → (R, B) is a func￾tion defined on a measurable space (Ω, A) to a measurable space (R, B). A
function X is a random variable or a measurable function, measurable with
respect to the sigma field A, if
∀ S ∈ B, X−1
(S) ∈ A.
The above definition of a random variable is known as a descriptive defini￾tion. If X : (Ω, A) → ([−∞, ∞], B
∗
), where B
∗
is the Borel field generated by
a class of any type of intervals of [−∞, ∞], is a A measurable function, then
we call X an extended valued random variable.
In the following examples, we examine whether the given function X is a
random variable with respect to some sigma field.
Example 2.2.2. Suppose Ω = {1, 2, 3, 4, 5, 6}, A = {1, 3, 5} and a function
X is defined on (Ω, A) as
X(ω) = 
0, if ω = 1, 3, 5
1, if ω = 2, 4, 6.
Then the inverse image of any Borel set S is given by,
X−1
(S) =



∅, if 0, 1 ∈/ S
Ω, if 0, 1 ∈ S
A, if 0 ∈ S, 1 ∈/ S
Ac
, if 1 ∈ S, 0 ∈/ S.70 Random Variables and Random Vectors
If we define A = {Ω, ∅, A, Ac}, then it has been verified in Section 1.3, that it
is a sigma field. Now ∀ S ∈ B, X−1
(S) ∈ A. Hence, X is measurable with
respect to A and is a random variable with respect to A. Further, observe that
∀ S ∈ B, X−1
(S) ∈ P(Ω), the powerset of Ω. Thus, X is a random variable
with respect to P(Ω) also. It is to be noted that A ⊂ P(Ω). □
Remark 2.2.1. If Ω is finite or countably infinite then the powerset of Ω, is
a sigma field and any function X : (Ω, A) → (R, B) is a measurable function
with respect to P(Ω) and hence is a random variable with respect to P(Ω).
Example 2.2.3. Suppose (Ω, A) is a measurable space. Suppose A ∈ A. The
indicator function X ≡ IA is defined as,
IA(ω) = 
1, if ω ∈ A
0, if ω ∈ Ac
Suppose S ∈ B. Then
X−1
(S) =



∅, if 0, 1 ∈/ S
Ω, if 0, 1 ∈ S
A, if 1 ∈ S, 0 ∈/ S
Ac
, if 0 ∈ S, 1 ∈/ S.
Observe that if A ∈ A then Ac ∈ A, it being a sigma field. Further Ω and ∅
are always members of any sigma field. Thus, ∀ S ∈ B, X−1
(S) ∈ A and IA
is a random variable with respect to A if A ∈ A. □
Example 2.2.4. Suppose Ω = {a, b, c, d} and A = {Ω, ∅, A, Ac}, where A =
{a, b}. A function X is defined on (Ω, A) as X(a) = X(b) = −1, X(c) = 1 and
X(d) = 2. Suppose S = {2}, then X−1
(S) = {d} ∈/ A, similarly if S = {1},
then X−1
(S) = {c} ∈/ A and hence X is not a random variable with respect
to A. □
Example 2.2.5. Suppose we want to identify a function on (Ω, A) which is
measurable with respect to A, where A = {Ω, ∅}. Since there are only two
sets in A, the collection of all Borel sets is partitioned into two classes such
that inverse images of Borel sets are either Ω or ∅. Suppose X ≡ c, that is
X(ω) = c ∀ ω ∈ Ω. Then
X−1
(S) = 
∅, if c /∈ S
Ω, if c ∈ S.
Hence, X is a random variable with respect to the sigma field A = {Ω, ∅}. We
label X as a degenerate random variable, measurable with respect to A. The
sigma field A = {Ω, ∅} is known as the trivial sigma field. □Random Variables 71
Example 2.2.6. Suppose Ω = {−1, 0, 1} and a function X is defined on
(Ω, A) as X(ω) = ω. Suppose A = P(Ω). To examine if X is A measurable
random variable, we first find X−1
(S) for S ∈ B. These are given by,
X−1
(S) =



∅, if −1 ∈/ S, 0 ∈/ S, 1 ∈/ S
{−1}, if −1 ∈ S, 0 ∈/ S, 1 ∈/ S
{0}, if −1 ∈/ S, 0 ∈ S, 1 ∈/ S
{1}, if −1 ∈/ S, 0 ∈/ S, 1 ∈ S
{−1, 0}, if −1 ∈ S, 0 ∈ S, 1 ∈/ S
{−1, 1}, if −1 ∈ S, 0 ∈/ S, 1 ∈ S
{0, 1}, if −1 ∈/ S, 0 ∈ S, 1 ∈ S
Ω, if −1 ∈ S, 0 ∈ S, 1 ∈ S.
Thus, ∀ S ∈ B, X−1
(S) ∈ A = P(Ω) and X is a random variable with
respect to A. □
It is to be noted that for a function X defined on (Ω, A) to be a random
variable, we have to examine if the inverse image of every Borel set is in the
sigma field A. It becomes tedious when the number of elements in Ω and in
the set of images of X is large. There is an alternative simpler way to examine
whether X is a random variable. In this approach, it is not necessary to verify
whether inverse image of every Borel set is in the sigma field A, but it is
sufficient to examine that inverse image of a set in class C, which generates
the Borel field, is in A. Thus, one may restrict to a class of intervals of any
one of the eight types as described in Chapter 1, which generates a Borel field.
To establish such an equivalence, we need some properties of inverse image
of a set and also the properties of inverse image of a collection of sets. We
investigate these in the following lemma. It is of interest to note that the
inverse mapping preserves all the set operations.
Lemma 2.2.1. Suppose X is a function defined from Ω1 to Ω2.
(i) Inverse image of a complement is a complement of the inverse image,
that is, for S ⊆ Ω2, X−1
(S
c
) = (X−1
(S))c
.
(ii) Inverse image of a union of two sets is a union of inverse images of the
sets, that is, if S1 and S2 are two subsets of Ω2, then
X−1
(S1 ∪ S2) = X−1
(S1) ∪ X−1
(S2).
(iii) Inverse image of a countable union is a countable union of inverse im￾ages, that is, if {Sn, n ≥ 1} is a sequence of subsets of Ω2, then
X−1
(
S
n≥1 Sn) = S
n≥1 X−1
(Sn).
(iv) Inverse image of a countable intersection is a countable intersection of
inverse images, that is, if {Sn, n ≥ 1} is a sequence of subsets of Ω2,
then X−1
(
T
n≥1 Sn) = T
n≥1 X−1
(Sn).
(v) Inverse images of disjoint sets are disjoint sets, that is, if S1 and S2 are
two disjoint subsets of Ω2, then X−1
(S1) and X−1
(S2) are also disjoint
subsets of Ω1.72 Random Variables and Random Vectors
(vi) If S1 ⊆ S2 ⊆ Ω2, then X−1
(S1) ⊆ X−1
(S2) ⊆ Ω1.
(vii) If X−1
(S1) ⊆ X−1
(S2), then S1 ⊆ S2.
Proof.
(i) By the definition of the inverse image of a set,
ω ∈ X−1
(S
c
) ⇐⇒ X(ω) ∈ S
c ⇐⇒ X(ω) ∈/ S
⇐⇒ ω /∈ X−1
(S) ⇐⇒ ω ∈ (X−1
(S))c
.
Hence, X−1
(S
c
) = (X−1
(S))c
.
(ii) Suppose S1 and S2 are two subsets of Ω2.
ω ∈ X−1
(S1 ∪ S2) ⇐⇒ X(ω) ∈ S1 ∪ S2
⇐⇒ X(ω) ∈ Si for at least one i = 1, 2
⇐⇒ ω ∈ X−1
(Si) for at least one i = 1, 2
⇐⇒ ω ∈ X−1
(S1) ∪ X−1
(S2).
Hence, X−1
(S1 ∪S2) = X−1
(S1)∪ X−1
(S2). Result (ii) can be extended
to a countable union as shown below.
(iii) As in the proof of Result (ii),
ω ∈ X−1
 [
n≥1
Sn

⇐⇒ X(ω) ∈
[
n≥1
Sn
⇐⇒ X(ω) ∈ Sn for at least one n ≥ 1
⇐⇒ ω ∈ X−1
(Sn) for at least one n ≥ 1
⇐⇒ ω ∈
[
n≥1
X−1
(Sn).
Hence, X−1
(
S
n≥1 Sn) = S
n≥1 X−1
(Sn).
(iv) By the definition of the inverse image of a set,
ω ∈ X−1
 \
n≥1
Sn

⇐⇒ X(ω) ∈
\
n≥1
Sn
⇐⇒ X(ω) ∈ Sn, ∀ n ≥ 1
⇐⇒ ω ∈ X−1
(Sn) ∀ n ≥ 1
⇐⇒ ω ∈
\
n≥1
X−1
(Sn).
Hence, X−1
(
T
n≥1 Sn) = T
n≥1 X−1
(Sn).Random Variables 73
(v) We assume the contrary, that is, X−1
(S1) and X−1
(S2) are not disjoint
sets. Then
X−1
(S1) ∩ X−1
(S2) ̸= ∅ ⇒ ∃ ω ∈ Ω such that ω ∈ X−1
(S1) ∩ X−1
(S2)
⇒ ω ∈ X−1
(S1) and ω ∈ X−1
(S2)
⇒ X(ω) ∈ S1 and X(ω) ∈ S2
⇒ X(ω) ∈ S1 ∩ S2 ⇒ S1 ∩ S2 ̸= ∅,
which is a contradiction to the given statement that S1 and S2 are two
disjoint sets. Thus, if S1 and S2 are two disjoint sets, then X−1
(S1) and
X−1
(S2) are also disjoint sets.
(vi) Observe that
ω ∈ X−1
(S1) ⇒ X(ω) ∈ S1 ⇒ X(ω) ∈ S2 as S1 ⊆ S2
⇒ ω ∈ X−1
(S2) ⇒ X−1
(S1) ⊂ X−1
(S2) .
(vii) To prove that if X−1
(S1) ⊆ X−1
(S2), then S1 ⊆ S2, we assume the
contrary, that is, S1 is not a subset of S2. Then
∃ ω ∈ Ω1 such that X(ω) ∈ S1 but X(ω) ∈/ S2
⇒ ∃ ω ∈ Ω1 such that ω ∈ X−1
(S1) but ω /∈ X−1
(S2)
⇒ X−1
(S1) not a subset of X−1
(S2),
which is a contradiction. Hence, X−1
(S1) ⊆ X−1
(S2) ⇒ S1 ⊆ S2.
We now extend the concept of an inverse image of a set to an inverse
image of a collection of sets. We define it below and then prove some results
regarding it in subsequent lemmas.
Definition 2.2.3. Inverse image of a collection: Suppose C is a collection of
subsets of Ω2. Then the inverse image of a collection C under the function X,
denoted by X−1
(C), is defined as,
X−1
(C) = {X−1
(S)|S ∈ C}.
Thus, an inverse image of a collection is basically a collection of inverse
images of sets from that collection.
Lemma 2.2.2. Suppose X : Ω1 → Ω2 is a function. Suppose C1 and C2 are
classes of subsets of Ω2. Then
C1 ⊆ C2 ⇒ X−1
(C1) ⊆ X−1
(C2) & σ[X−1
(C1)] ⊆ σ[X−1
(C2)].74 Random Variables and Random Vectors
Proof. Suppose C1 ⊆ C2. To prove that X−1
(C1) ⊆ X−1
(C2), note that
A ∈ X−1
(C1) ⇒ ∃ S ∈ C1 such that X−1
(S) = A
⇒ ∃ S ∈ C2 such that X−1
(S) = A as C1 ⊆ C2
⇒ X−1
(S) ∈ X−1
(C2) such that X−1
(S) = A
⇒ A ∈ X−1
(C2) ⇒ X−1
(C1) ⊆ X−1
(C2).
Now, X−1
(C1) ⊆ X−1
(C2) ⊆ σ[X−1
(C2)]. Thus, σ[X−1
(C2)] is a sigma field
covering X−1
(C1), and hence by the definition of the minimal sigma field
σ[X−1
(C1)] ⊆ σ[X−1
(C2)]. If C1 = C2, then σ[X−1
(C1)] = σ[X−1
(C2)].
Lemma 2.2.3. Suppose X : Ω1 → Ω2 is a function. If F is a sigma field of
subsets of Ω2, then X−1
(F) is a sigma field of subsets of Ω1, that is, inverse
image of a sigma field is a sigma field.
Proof. By the definition of an inverse image of a collection of sets, we have
X−1
(F) = {X−1
(S)|S ∈ F},
which we want to show to be a sigma field. Now,
A ∈ X−1
(F) ⇒ ∃ S ∈ F such that A = X−1
(S)
⇒ S
c ∈ F as F is a sigma field
⇒ X−1
(S
c
) ∈ X−1
(F) by Definition 2.2.3
⇒ (X−1
(S))c ∈ X−1
(F) by (i) of Lemma 2.2.1
⇒ A
c ∈ X−1
(F). (2.1)
Thus, X−1
(F) is closed under complementation. Further, consider a sequence
{An, n ≥ 1} of sets in X−1
(F). Now,
∀ n ≥ 1, An ∈ X−1
(F) ⇒ ∃ Sn ∈ F such that An = X−1
(Sn)
⇒
[
n≥1
Sn ∈ F as F is a sigma field
⇒ X−1
(
[
n≥1
Sn) ∈ X−1
(F) by Definition 2.2.3
⇒
[
n≥1
X−1
(Sn) ∈ X−1
(F) by (iii) of Lemma 2.2.1
⇒
[
n≥1
An ∈ X−1
(F) . (2.2)
Thus, X−1
(F) is closed under countable union. Hence by Equation (2.1) and
Equation (2.2), it is a sigma field.
Lemma 2.2.4. Suppose X : Ω1 → Ω2 is a function. Suppose A is a sigma
field of subsets of Ω1. Then, there exists a sigma field F of subsets of Ω2 such
that X−1
(F) ⊆ A.Random Variables 75
Proof. Suppose a class F of subsets of Ω2 is defined as
F = {S ⊂ Ω2|X−1
(S) ∈ A}.
We examine whether F is a sigma field. Observe that,
S ∈ F ⇒ X−1
(S) ∈ A by definition of F
⇒ (X−1
(S))c ∈ A as A is a sigma field
⇒ X−1
(S
c
) ∈ A by (i) of Lemma 2.2.1
⇒ S
c ∈ F by definition of F. (2.3)
Thus, F is closed under complementation. Suppose {Sn, n ≥ 1} is a sequence
of sets in F. Note that,
∀ n ≥ 1, Sn ∈ F ⇒ X−1
(Sn) ∈ A, n ≥ 1, by definition of F
⇒
[
n≥1
X−1
(Sn) ∈ A as A is a sigma field
⇒ X−1
(
[
n≥1
Sn) ∈ A by (iii) of Lemma 2.2.1
⇒
[
n≥1
Sn ∈ F by definition of F. (2.4)
Thus, F is closed under countable union. Hence by Equation (2.3) and Equa￾tion (2.4), it is a sigma field.
To examine whether X−1
(F) ⊆ A, note that
A ∈ X−1
(F) = {X−1
(S)|S ∈ F} ⇒ ∃ S ∈ F such that A = X−1
(S).
Now by the definition of F,
S ∈ F ⇒ X−1
(S) ∈ A ⇒ A ∈ A.
Thus, A ∈ X−1
(F) ⇒ A ∈ A. Hence, X−1
(F) ⊆ A.
Remark 2.2.2. Note that X−1
(F) need not be equal to A. A can have some
additional sets which are not inverse images of any subsets of Ω2.
Theorem 2.2.1. Suppose X : Ω1 → Ω2 is a function. If C is a class of
subsets of Ω2, then the inverse image of the minimal sigma field covering C
is the minimal sigma field covering the inverse image of C, that is, if σ(C) is
the minimal sigma field generated by class C of subsets of Ω2 then
X−1
[σ(C)] = σ[X−1
(C)].
Proof. Note that
C ⊆ σ(C) ⇒ X−1
(C) ⊆ X−1
[σ(C)] by Lemma 2.2.2.76 Random Variables and Random Vectors
Observe that σ(C) is a sigma field and hence by Lemma 2.2.3, X−1
[σ(C)] is
also a sigma field. Thus, X−1
[σ(C)] is a sigma field covering the class X−1
(C).
Hence, the minimal sigma field generated by X−1
(C) is included in X−1
[σ(C)]
by the definition of the minimal sigma field, that is,
σ[X−1
(C)] ⊆ X−1
[σ(C)]. (2.5)
To prove that X−1
[σ(C)] ⊆ σ[X−1
(C)], suppose a collection F of subsets of
Ω2 is defined as F = {S ⊆ Ω2|X−1
(S) ∈ σ[X−1
(C)]}. Note that σ[X−1
(C)]
is a sigma field of subsets of Ω1. Hence by Lemma 2.2.4, F is sigma field of
subsets of Ω2 and X−1
(F) ⊆ σ[X−1
(C)] . Now by the definition, X−1
(C) =
{X−1
(S)|S ∈ C}. Note that
S ∈ C ⇒ X−1
(S) ∈ X−1
(C) ⊆ σ[X−1
(C)] ⇒ X−1
(S) ∈ σ[X−1
(C)] ⇒ S ∈ F,
by definition of F. Thus, C ⊆ F. Now by the definition of the minimal sigma
field,
C ⊆ F ⇒ σ(C) ⊆ F
⇒ X−1
[σ(C)] ⊆ X−1
(F) ⊆ σ[X−1
(C)]. (2.6)
From Equation (2.5) and Equation (2.6), we conclude that
X−1
[σ(C)] = σ[X−1
(C)].
Remark 2.2.3. Lemma 2.2.2 conveys that C1 ⊆ C2 ⇒ X−1
(C1) ⊆
X−1
(C2). However, its converse is not true, that is, if X−1
(C1) ⊆ X−1
(C2),
then C1 may not be included in C2 as illustrated in the following example
Example 2.2.7. Suppose X : Ω1 → Ω2 where Ω1 = {HH, HT, T H, T T},
Ω2 = R
+ and X(HH) = 2, X(T H) = X(HT) = 1 and X(T T) = 0. Observe
that,
C1 = {{1}, {2}} ⇒ X−1
(C1) = {{HT, T H}, {HH}}
C2 = {{0},(0.5, 1.5), {2}} ⇒ X−1
(C2) = {{HT, T H}, {HH}, {T T}}.
Thus, X−1
(C1) ⊂ X−1
(C2). However, C1 is not included in C2. □
The next example shows that if a class C is such that σ(X−1
(C)) =
X−1
(F), then C may or may not be included in F.
Example 2.2.8. Suppose X : Ω1 → Ω2 where Ω1 = {HH, HT, TH, T T},
Ω2 = R
+ = [0, ∞), X(HH) = 2, X(T H) = X(HT) = 1 & X(T T) = 0.
Suppose C = {{1}, {2}}. Then X−1
(C) = {{HT, T H}, {HH}}. Hence,
σ(X−1
(C)) = n
Ω1, ∅, {HT, T H}, {HH}, {T T, HH}, {HT, T H, HH}, {TT},
{HT, T H, T T}
o
. We now find two different F such thatRandom Variables 77
σ(X−1
(C)) = X−1
(F). However, C is included in one but not in the other.
Suppose
F1 =
n
Ω2, ∅, {1}, {2}, {1}
c
, {2}
c
, {1, 2}, {1, 2}
c
o
=
n
Ω2, ∅, {1}, {2}, [0, 1) ∪ (1, ∞), [0, 2) ∪ (2, ∞), {1, 2},
[0, 1) ∪ (1, 2) ∪ (2, ∞)
o
.
F2 =
n
Ω2, ∅, {2},(0.5, 1.5), {2}
c
,(0.5, 1.5)c
,(0.5, 1.5) ∪ {2},
(0.5, 1.5)c ∩ {2}
c
o
=
n
Ω2, ∅, {2},(0.5, 1.5), [0, 2) ∪ (2, ∞), [0, 0.5) ∪ (1.5, ∞),
(0.5, 1.5) ∪ {2},(0.5, 1.5)c ∩ {2}
c
o
.
Note that X−1
(F1) = X−1
(F2) = σ(X−1
(C)) and C = {{1}, {2}} ⊂ F1.
However C = {{1}, {2}} is not included in F2. □
It is to be noted that Lemma 2.2.1, Lemma 2.2.2, Lemma 2.2.3 and Lemma
2.2.4 are mainly to prove Theorem 2.2.1. All these results are also valid for a
function X from any measurable space to any other measurable space. When
we deal with a random variable, we take (Ω, A) as a domain and (R, B) as
a co-domain. When we deal with a Borel function, both the domain space
and the co-domain space are (R, B) (see Theorem 2.2.3). In the definition of
a random vector, the co-domain space is (R
k
, B
k
).
Using Theorem 2.2.1, we prove an important result in the following theo￾rem which leads to a simpler way to verify that a given function is a random
variable.
Theorem 2.2.2. Suppose X : (Ω, A) → (R, B) is a function. Suppose C is a
class of subsets of R such that σ(C) = B. Then
∀ S ∈ B, X−1
(S) ∈ A ⇐⇒ ∀ S ∈ C, X−1
(S) ∈ A.
Proof. Part(i) - Suppose ∀ S ∈ B, X−1
(S) ∈ A. Now B = σ(C) is the minimal
sigma field generated by the class C and hence by the definition of minimal
sigma field, C ⊆ σ(C) = B. Suppose S ∈ C. Then,
S ∈ C ⇒ S ∈ B ⇒ X−1
(S) ∈ A
Part(ii) - Suppose ∀ S ∈ C, X−1
(S) ∈ A. Now
∀ S ∈ C, X−1
(S) ∈ A ⇒ X−1
(C) ⊆ A, (A covers X−1
(C))
⇒ σ[X−1
(C)] ⊆ A
⇒ X−1
[σ(C)] ⊆ A by Theorem 2.2.1
⇒ X−1
(B) ⊆ A
⇒ ∀ S ∈ B, X−1
(S) ∈ A.
The second step follows by the definition of minimal sigma field.78 Random Variables and Random Vectors
From Theorem 2.2.2, we note that
∀ S ∈ C, X−1
(S) ∈ A ⇒ ∀ S ∈ B, X−1
(S) ∈ A.
Hence we have the following another definition of a random variable.
Definition 2.2.4. Random variable: Suppose X : (Ω, A) → (R, B) is a func￾tion. Suppose C is a class of subsets of R such that σ(C) = B. Then X is a
random variable measurable with respect to A if ∀ S ∈ C, X−1
(S) ∈ A.
Definition 2.2.4 is referred to as an economical definition of a random
variable, while Definition 2.2.2 is referred to as a descriptive definition of
a random variable. Theorem 2.2.2 proves the equivalence of descriptive and
economical definitions of a random variable. With the economical definition,
it is simpler to verify that a function defined on the measurable space is a
random variable. It is clear from the following examples.
Example 2.2.9. Suppose Ω = {a, b, c, d, e, f} and A is given by,
A = {Ω, ∅, {a, b}, {c, d}, {a, b, c, d}, {e, f}, {c, d, e, f}, {a, b, e, f}}. A function
X is defined on (Ω, A) as follows.
X(ω) =



10, if ω = a
1010
, if ω = b, c
1020
, if ω = d
1030
, if ω = e, f.
We use Definition 2.2.4 to examine if X is A measurable random variable.
Suppose C = {(−∞, x]|x ∈ R}. Now,
X−1
((−∞, x]) = 
∅, if −∞ < x < 10
{a}, if 10 ≤ x < 1010
.
But {a} ∈/ A, hence X is not A measurable random variable. □
Example 2.2.10. Suppose Ω = {−1, 0, 1} and a function X is defined on
(Ω, A) as X(ω) = ω and A = P(Ω). As in the previous example we use
Definition 2.2.4 to examine if X is A measurable random variable. Suppose
C = {(−∞, x]|x ∈ R}. Now,
X−1
((−∞, x]) =



∅, if −∞ < x < −1
{−1}, if −1 ≤ x < 0
{−1, 0}, if 0 ≤ x < 1
Ω, if x ≥ 1.
Thus, X−1
((−∞, x]) ∈ P(Ω), ∀ x ∈ R and hence X is a random variable
with respect to P(Ω). □
Comparison of the solutions of Examples 2.2.6 and 2.2.10 clarifies why
Definition 2.2.4 is labeled as the economical definition of a random variable.
Note that B is a sigma field and hence by Lemma 2.2.3, X−1
(B) is also
a sigma field. It is referred to by a special term as given in the following
definition.Random Variables 79
Definition 2.2.5. Sigma field induced by a random variable X: Suppose X
is a random variable defined on (Ω, A) to (R, B). Then
X−1
(B) = {X−1
(S)|S ∈ B},
also denoted by σ(X), is known as a sigma field induced by or generated by a
random variable X.
In the following example, we obtain the induced sigma field and also verify
Theorem 2.2.1.
Example 2.2.11. Suppose X is a function defined on (Ω, A) to (R, B) as
X(ω) =



−1, if ω ∈ A1
0, if ω ∈ (A1 ∪ A2)
c
1, if ω ∈ Ac
1 ∩ A2,
where A1 and A2 are measurable sets, that is, they are in A. We examine
whether X is a random variable with respect to A. Suppose
C = {(−∞, x]|x ∈ R}. Now,
X−1
((−∞, x]) =



∅, if −∞ < x < −1
A1, if −1 ≤ x < 0
A1 ∪ (A1 ∪ A2)
c = A1 ∪ Ac
2
, if 0 ≤ x < 1
Ω, if x ≥ 1.
It is given that A1, A2 ∈ A, hence A1 ∪ Ac
2 ∈ A, it being a sigma field. Thus,
X−1
((−∞, x]) ∈ A, ∀ x ∈ R and hence X is a random variable with respect
to A. Note that
X−1
(C) = {Ω, ∅, A1, A1 ∪ A
c
2}
& σ(X−1
(C)) = {Ω, ∅, A1, A1 ∪ A
c
2
, Ac
1
, Ac
1 ∩ A2, A1 ∪ A2, Ac
1 ∩ A
c
2} .
We now find the sigma field induced by X. Thus we need to find
X−1
(S) ∀ S ∈ B. We have for S ∈ B,
X−1
(S) =



∅, if −1 ∈/ S, 0 ∈/ S, 1 ∈/ S
A1, if −1 ∈ S, 0 ∈/ S, 1 ∈/ S
Ac
1 ∩ A2, if −1 ∈/ S, 0 ∈/ S, 1 ∈ S
Ac
1 ∩ Ac
2
, if −1 ∈/ S, 0 ∈ S, 1 ∈/ S
A1 ∪ A2, if −1 ∈ S, 0 ∈/ S, 1 ∈ S
A1 ∪ Ac
2
, if −1 ∈ S, 0 ∈ S, 1 ∈/ S
Ac
1
, if −1 ∈/ S, 0 ∈ S, 1 ∈ S
Ω, if −1 ∈ S, 0 ∈ S, 1 ∈ S.
Thus, the sigma field induced by X is given by,
X−1
(B) = {Ω, ∅, A1, Ac
1 ∩ A2, Ac
1 ∩ A
c
2
, A1 ∪ A2, A1 ∪ A
c
2
, Ac
1} .
Note that X−1
(B) = X−1
(σ(C)) = σ(X−1
(C)). □80 Random Variables and Random Vectors
Remark 2.2.4. Observe that in the above example X−1
(B) ⊆ A and hence
it is a random variable with respect to A. Note that a function X defined
on (Ω, A) to (R, B) is always a random variable with respect to its induced
sigma field. Further note that X−1
(B) is a much smaller sigma field than the
original sigma field A, which is not even specified in the above example. Often
the sigma field A, which may be a powerset, contains too many subsets and
we are interested in only some of them. One can then define a random variable
X measurable with respect to the induced sigma field containing subsets that
are of interest. In general, X−1
(B) is between the trivial sigma field and A. In
fact, the induced sigma field is the smallest sigma field with respect to which
a random variable is measurable.
Example 2.2.12. Suppose X is a function defined on (Ω, A) to (R, B) as
X(ω) = ω, where Ω = {−1, 0, 1}. We obtain the sigma fields induced by X,
Y = X2 and Z = e
X and examine the relation between the sigma fields
induced by X and Y as well as between the sigma fields induced by X and Z.
To find the sigma field induced by X, for S ∈ B,
X−1
(S) =



∅, if −1 ∈/ S, 0 ∈/ S, 1 ∈/ S
{−1}, if −1 ∈ S, 0 ∈/ S, 1 ∈/ S
{0}, if −1 ∈/ S, 0 ∈ S, 1 ∈/ S
{1}, if −1 ∈/ S, 0 ∈/ S, 1 ∈ S
{−1, 0}, if −1 ∈ S, 0 ∈ S, 1 ∈/ S
{−1, 1}, if −1 ∈ S, 0 ∈/ S, 1 ∈ S
{0, 1}, if −1 ∈/ S, 0 ∈ S, 1 ∈ S
Ω, if −1 ∈ S, 0 ∈ S, 1 ∈ S.
Thus, the sigma field induced by X is given by,
X−1
(B) = {Ω, ∅, {−1}, {0}, {1}, {−1, 0}, {−1, 1}, {0, 1}}
and X is a random variable measurable with respect to the induced sigma
field. Now Y = X2
, hence Y (−1) = Y (1) = 1 and Y (0) = 0. To find the sigma
field induced by Y , we have for S ∈ B,
Y
−1
(S) =



∅, if 0 ∈/ S, 1 ∈/ S
{0}, if 0 ∈ S, 1 ∈/ S
{−1, 1}, if 0 ∈/ S, 1 ∈ S
Ω, if 0 ∈ S, 1 ∈ S.
Thus, the sigma field induced by Y is given by,
Y
−1
(B) = {Ω, ∅, {0}, {−1, 1}} and Y
−1
(B) ⊂ X−1
(B).
It is to be noted that Y is a random variable measurable with respect to
Y
−1
(B) as well as X−1
(B), but Y
−1
(B) is the minimal sigma field with respectRandom Variables 81
to which Y is measurable. To find the sigma field induced by Z, for S ∈ B,
Z
−1
(S) =



∅, if e
−1 ∈/ S, e0 ∈/ S, e1 ∈/ S
{−1}, if e
−1 ∈ S, e0 ∈/ S, e1 ∈/ S
{0}, if e
−1 ∈/ S, e0 ∈ S, e1 ∈/ S
{1}, if e
−1 ∈/ S, e0 ∈/ S, e1 ∈ S
{−1, 0}, if e
−1 ∈ S, e0 ∈ S, e1 ∈/ S
{−1, 1}, if e
−1 ∈ S, e0 ∈/ S, e1 ∈ S
{0, 1}, if e
−1 ∈/ S, e0 ∈ S, e1 ∈ S
Ω, if e
−1 ∈ S, e0 ∈ S, e1 ∈ S.
Thus, the sigma field induced by Z is the same as that of X and Z is a random
variable measurable with respect to the induced sigma field. It is to be noted
that Y is a many-to-one function of X and Z is a one-to-one function of X.
In general, all one-to-one functions of X induce the same sigma fields as that
of X and the sigma field induced by many-to-one functions of X are included
in the sigma field induced by X. Thus, the values of random variables are not
important but the partition of the sample space that it induces is important.
□
To formalize the results obtained in Example 2.2.12, we define a term
“Borel function”.
Definition 2.2.6. Borel function: Suppose g : (R, B) → (R, B) is a function.
If
∀ S ∈ B, g−1
(S) = {x ∈ R|g(x) ∈ S} ∈ B
then g is measurable with respect to the Borel field and is known as a Borel
function.
Just as we have an economical definition of a random variable, we have a
following theorem which states that to examine if g is a Borel function, it is
enough to examine that inverse images of sets in a class C, which generates
B.
Theorem 2.2.3. Suppose g : (R, B) → (R, B) is a function. Suppose C is a
class of subsets of R such that σ(C) = B. Then g is a Borel function if and
only if ∀ S ∈ C, g−1
(S) ∈ B.
Proof.
(i) Suppose g : (R, B) → (R, B) is a Borel function, that is, ∀ S ∈ B,
g
−1
(S) ∈ B. Now B = σ(C) is the minimal sigma field generated by the
class C and hence by the definition of minimal sigma field, C ⊂ σ(C) = B.
Thus,
S ∈ C ⇒ S ∈ B ⇒ g
−1
(S) ∈ B.82 Random Variables and Random Vectors
(ii) Suppose that
∀ S ∈ C, g−1
(S) ∈ B ⇒ g
−1
(C) ⊆ B (B covers g
−1
(C))
⇒ σ[g
−1
(C)] ⊆ B by definition of minimal σ field
⇒ g
−1
[σ(C)] ⊆ B by Theorem 2.2.1
⇒ g
−1
(B) ⊆ B ⇒ ∀ S ∈ B, g−1
(S) ∈ B.
Hence g is B measurable function, that is, it is a Borel function.
Example 2.2.13. Using the economical definition of a Borel function we
examine whether (i) g(x) = a0 + a1x + a2x
2 + · · · + anx
n, x ∈ R is a Borel
function. Suppose C is a class of all open intervals of R, then the minimal
sigma field generated by C is the Borel field B. Suppose S = (a, b) ∈ C, then
g
−1
(S) = {x|g(x) = a0 +a1x+a2x
2 +· · ·+anx
n ∈ S} will be an open interval
or union of open intervals and hence belongs to B. It follows since the inverse
image of an open set under a continuous function is again an open set. Hence
g is a Borel function.
(ii) Suppose g(x) = sin x, the range is (−1, 1), hence for any S = (a, b) ⊆
(−1, 1), g
−1
(S) will be again an union of open intervals in R and hence a
Borel set. For any Borel set S, which is not included in (−1, 1), g
−1
(S) = ∅.
Thus g(x) = sin x is a Borel function.
(iii) If g(x) = exp(x), then inverse image of any open interval of R
+ = [0, ∞)
will be an open interval of R. For any Borel set S, which is included in R
−,
g
−1
(S) = ∅. For an interval of the type (−a, a), where a > 0, g
−1
((−a, a)) =
g
−1
((0, a)). It is again an open interval. Hence exp(x) is a Borel function. □
Having defined the Borel function, we now prove an important result that
measurability of X remains invariant under Borel transformations. The fol￾lowing theorem plays a central role in Statistics.
Theorem 2.2.4. Suppose X : (Ω, A) → (R, B) is a random variable measur￾able with respect to a sigma field A and g : (R, B) → (R, B) is a Borel function,
then
(i) Y = g(X) is a random variable, measurable with respect to the sigma
field A.
(ii) The sigma field induced by Y is included in a sigma field induced by X.
Proof.
(i) For a Borel set S,
Y
−1
(S) = (g(X))−1
(S) = {ω|Y (ω) ∈ S} = {ω|g(X)(ω) ∈ S}
= {ω|g(X(ω)) ∈ S} = {ω|X(ω) ∈ g
−1
(S)}
= X−1
(g
−1
(S)) . (2.7)Random Variables 83
Thus, for a Borel set S, g(X)
−1
(S) = X−1
(g
−1
(S)). Now, ∀ S ∈ B,
S ∈ B ⇒ g
−1
(S) ∈ B, g being a Borel function
⇒ X−1
(g
−1
(S)) ∈ A, X being A measurable
⇒ Y
−1
(S) = X−1
(g
−1
(S)) ∈ A.
Hence, Y = g(X) is a random variable, measurable with respect to the
sigma field A.
(ii) To prove that Y
−1
(B) ⊆ X−1
(B), observe that
A ∈ Y
−1
(B) ⇒ ∃ S ∈ B such that A = Y
−1
(S)
⇒ A = Y
−1
(S) = X−1
(g
−1
(S)) by (2.7)
⇒ A = X−1
(g
−1
(S)) ∈ X−1
(B) as g
−1
(S) ∈ B.
Thus, A ∈ Y
−1
(B) ⇒ A ∈ X−1
(B) and hence Y
−1
(B) ⊆ X−1
(B).
Remark 2.2.5. The result g(X)
−1
(S) = X−1
(g
−1
(S)) is similar to
(AB)
−1 = B−1A−1
, where A and B are matrices of appropriate order so
that matrix product AB is defined.
We prove in Section 4 that every continuous function is a Borel function.
Thus, almost any function of a A measurable random variable X, such as a
polynomial function, exponential function, logarithmic function and all trig￾nometric functions, is again a random variable with respect to the same sigma
field A. We have verified in Example 2.2.12 that the sigma field induced by a
Borel function of X is included in the sigma field induced by X.
Example 2.2.14. In this example, we examine whether |X| is a random
variable with respect to A implies X is a random variable with respect to A.
Suppose Ω = {−1, 0, 1} and X be defined on (Ω, A) as an identity function,
that is as X(i) = i. Now Y = |X|, hence Y (−1) = Y (1) = 1 and Y (0) = 0.
To find the sigma field induced by Y , we have for S ∈ B,
Y
−1
(S) =



∅, if 0 ∈/ S, 1 ∈/ S
{0}, if 0 ∈ S, 1 ∈/ S
{−1, 1}, if 0 ∈/ S, 1 ∈ S
Ω, if 0 ∈ S, 1 ∈ S.
Thus, the sigma field induced by Y is given by,
Y
−1
(B) = {Ω, ∅, {0}, {−1, 1}} = A, say
and then Y = |X| is a random variable with respect to A. It is to be noted
that the sigma field induced by |X| and X2
is the same. Now for a Borel set
S such that −1 ∈ S, 0 ∈/ S, 1 ∈/ S, X−1
(S) = {−1} ∈/ A, hence X is not a
random variable with respect to A. It is to be noted that the correspondence
from |X| to X is not a function, it being a one-many correspondence. □84 Random Variables and Random Vectors
Once we have defined a random variable as a measurable function from
(Ω, A) to (R, B), we interpret Ω as a set of all possible outcomes of a random
experiment and it is known as a sample space and each element in Ω is known
as a sample point. Often, we are interested in the occurrence of some outcomes
of interest. It is a subset of Ω. If it belongs to A, then it is known as an event.
Thus we have a following formal definition.
Definition 2.2.7. Sample space, sample point and event: Suppose (Ω, A) is a
measurable space. Then the set Ω is a set of all possible outcomes of a random
experiment and is known as a sample space. Each element in Ω is known as
a sample point and a set in A is known as an event.
It should be noted that every subset of Ω may not be an event. An event
A is said to occur at a trial of a random experiment, if the outcome ω ∈ A at
that trial. Otherwise, we say that the event A has not occurred at that trial.
In such case, ω ∈ Ac and hence Ac has occurred. It may be noted that, Ω is
an event that always occurs and the event ∅ never happens. For this reason Ω
is known as a sure event and ∅ as an impossible event.
In this section, the image space of the function X is the real line and if
it is measurable, we have labeled it as a random variable. The image space
of the function can be k dimensional Euclidean space or even a sequence of
real numbers. In the next section, we extend the theory of univariate random
variables, that is random variables with image space as the real line, to multi￾variate random variable, when image space is k dimensional Euclidean space,
also known as random vector and then to a countably infinite collection of
random variables, known as a sequence of random variables.
2.3 Random Vectors
Definition of a random vector is similar to that of a random variable.
Definition 2.3.1. k-Variate random vector: Suppose Z = (X1, X2, · · · , Xk)
′
is a function defined on the measurable space (Ω, A) to (R
k
, B
k
), where B
k
is
the Borel field of subsets of R
k
. If
∀ S ∈ B
k
, Z−1
(S) = {ω| Z(ω) = (X1(ω), X2(ω), · · · , Xk(ω))′ ∈ S} ∈ A,
then Z is a random vector measurable with respect to A.
By Lemma 2.2.3, Z
−1
(B
k
) = {Z
−1
(S)|S ∈ B
k} is a sigma field and it is
known as a sigma field induced by the random vector Z. It is also denoted by
σ(Z). Thus, if the induced sigma field is included in A, then Z is a random
vector with respect to A. Following example illustrates the concept of a random
vector.Random Vectors 85
Example 2.3.1. Suppose X1 and X2 are two functions defined on (Ω, A) as
follows, where Ω = {a, b, c} and A = P(Ω).
X1(ω) = 
0, if ω = a
1, if ω = b, c & X2(ω) = 
2, if ω = b
3, if ω = a, c.
A vector Z = (X1, X2)
′
is given by,
Z(ω) =



(0, 3)′
, if ω = a,
(1, 2)′
, if ω = b,
(1, 3)′
, if ω = c.
(i) We first examine whether X1 and X2 are random variables on (Ω, A).
Suppose S ∈ B, then
X
−1
1
(S) =



∅, if 0 ∈/ S & 1 ∈/ S,
{a}, if 0 ∈ S & 1 ∈/ S,
{b, c}, if 0 ∈/ S & 1 ∈ S,
Ω, if 0 ∈ S & 1 ∈ S.
and
X
−1
2
(S) =



∅, if 2 ∈/ S & 3 ∈/ S,
{b}, if 2 ∈ S & 3 ∈/ S,
{a, c}, if 2 ∈/ S & 3 ∈ S,
Ω, if 2 ∈ S & 3 ∈ S.
It is clear that X
−1
1
(S) ∈ A, ∀ S ∈ B and X
−1
2
(S) ∈ A, ∀ S ∈ B and
hence X1 and X2 and are random variables on (Ω, A).
(ii) Now using Definition 2.3.1 of a random vector, we examine whether
Z = (X1, X2)
′
is a random vector on (Ω, A). Suppose we denote the
images (0, 3),(1, 2) and (1, 3) as points as P1, P2 and P3 respectively. For
S ∈ B
2
,
Z
−1
(S) =



∅, if P1 ∈/ S, P2 ∈/ S, P3 ∈/ S, ,
{a}, if P1 ∈ S, Pi ∈/ S, i = 2, 3,
{b}, if P2 ∈ S, Pi ∈/ S, i = 1, 3,
{c}, if P3 ∈ S, Pi ∈/ S, i = 1, 2,
{a, b}, if P1 ∈ S, P2 ∈ S, P3 ∈/ S,
{a, c}, if P1 ∈ S, P3 ∈ S, P2 ∈/ S,
{b, c}, if P1 ∈/ S, P2 ∈ S, P3 ∈ S,
Ω, if P1 ∈ S, P2 ∈ S, P3 ∈ S.
Again it is to be noted that Z
−1
(S) ∈ A, ∀ S ∈ B
2
, hence Z = (X1, X2)
is a random vector on (Ω, A).86 Random Variables and Random Vectors
(iii) From the inverse images of Borel sets as obtained above, we have
X
−1
1
(B) = {Ω, ∅, {a}, {b, c}} , X−1
2
(B) = {Ω, ∅, {b}, {a, c}}
and Z
−1
(B
2
) = {Ω, ∅, {a}, {b}, {c}, {a, b}, {b, c}, {a, c}} .
Further,
X
−1
1
(B) ∪ X
−1
2
(B) = {Ω, ∅, {a}, {b}, {b, c}, {a, c}} .
Observe that Z
−1
(B
2
) ≠ X
−1
1
(B) ∪ X
−1
2
(B). Further X
−1
1
(B) ∪ X
−1
2
(B)
is not a sigma field as {a} ∪ {b} = {a, b} ∈/ X
−1
1
(B) ∪ X
−1
2
(B). We
have noted in Chapter 1 that in general union of two sigma fields is
not a sigma field. Also note that {b, c}, {a, c} ∈ X
−1
1
(B) ∪ X
−1
2
(B), but
{b, c} ∩ {a, c} = {c} ∈/ X
−1
1
(B) ∪ X
−1
2
(B). Now the minimal sigma field
generated by X
−1
1
(B) ∪ X
−1
2
(B) is given by
σ(X
−1
1
(B) ∪ X
−1
2
(B)) = {Ω, ∅, {a}, {b}, {c}, {a, b}, {b, c}, {a, c}}
= Z
−1
(B
2
).
(iv) Note that X1 and X2 are random variables, with respect to A. Thus,
X
−1
1
(B) ⊆ A & X
−1
2
(B) ⊆ A ⇒ X
−1
1
(B) ∪ X
−1
2
(B) ⊆ A
⇒ σ(X
−1
1
(B) ∪ X
−1
2
(B)) ⊆ A
⇒ Z
−1
(B
2
) ⊆ A,
as in (iii) it is verified that σ(X
−1
1
(B) ∪ X
−1
2
(B)) = Z
−1
(B
2
). Thus this
example shows that if components are random variables, then vector of
these components is also a random vector. We prove this result in general
in this section. □
In general, if Z = (X1, X2, · · · , Xk)
′
is a k-dimensional random vector,
then the sigma field induced by Z is the same as the minimal sigma field
generated by the union of sigma fields, induced by {X1, X2, · · · , Xk}. Thus,
σ(Z) = σ ({X1, X2, · · · , Xk}) = Z
−1
(B
k
) = σ
 [
k
i=1
X
−1
i
(B)

.
It is proved below. Towards it, we need some more results. As in the univariate
setup, we have the following theorem which leads to a simpler way to verify
that a given function is a random vector.
Theorem 2.3.1. Suppose C
k
is a class of subsets of R
k which generates the
Borel field B
k
. A function Z = (X1, X2, · · · , Xk)
′
is defined on the measurable
space (Ω, A) to (R
k
, B
k
). Then
∀ S ∈ B
k
, Z−1
(S) ∈ A ⇐⇒ ∀ S ∈ C
k
, Z−1
(S) ∈ A.Random Vectors 87
Proof.
(i) Suppose ∀ S ∈ B
k
, Z−1
(S) ∈ A. By the definition of the minimal sigma
field, C
k ⊆ σ(C
k
) = B
k
. Hence,
S ∈ C
k ⇒ S ∈ B
k ⇒ Z
−1
(S) ∈ A.
(ii) Now suppose that ∀ S ∈ C
k
, Z−1
(S) ∈ A, thus Z
−1
(C
k
) ⊆ A implying
that A is a sigma field covering Z
−1
(C
k
). Thus,
Z
−1
(C
k
) ⊆ A ⇒ σ(Z
−1
(C
k
)) ⊆ A by definition of minimal sigma field
⇒ Z
−1
(σ(C
k
)) ⊆ A by Theorem 2.2.1
⇒ Z
−1
(B
k
) ⊆ A by definition of Borel field
⇒ ∀ S ∈ B
k
, Z−1
(S) ∈ A
In view of Theorem 2.3.1, we have one more definition for a random vector
as given below.
Definition 2.3.2. k-Variate random vector: Suppose Z = (X1, X2, · · · , Xk)
′
is a function defined on the measurable space (Ω, A) to (R
k
, B
k
). Suppose C
k
is a class of subsets of R
k which generates the Borel field B
k
. If
∀ S ∈ C
k
, Z−1
(S) = {ω | Z(ω) = (X1(ω), X2(ω), · · · , Xk(ω))′ ∈ S} ∈ A,
then Z is a random vector measurable with respect to A.
Definition 2.3.2 is known as an economical definition of a random vector
while Definition 2.3.1 is known as a descriptive definition of a random vector.
Equivalence of the two definitions is established in Theorem 2.3.1. In the
following example, we use the descriptive definition as well as the economical
definition of a random vector to verify whether Z = (IA, IB)
′
is a random
vector.
Example 2.3.2. Suppose Z = (IA, IB) where A, B ∈ A. (i) We show that Z
is a random vector on (Ω, A) by showing that σ(Z) ⊆ A. By definition of Z
we have,
Z(ω) =



(1, 1), if ω ∈ A & ω ∈ B ⇐⇒ ω ∈ A ∩ B,
(1, 0), if ω ∈ A & ω /∈ B ⇐⇒ ω ∈ A ∩ Bc
,
(0, 1), if ω /∈ A & ω ∈ B ⇐⇒ ω ∈ Ac ∩ B,
(0, 0), if ω /∈ A & ω /∈ B ⇐⇒ ω ∈ Ac ∩ Bc
.
To find the sigma field induced by Z, we denote the images as P1 = (0, 0),88 Random Variables and Random Vectors
P2 = (0, 1), P3 = (1, 0) and P4 = (1, 1). For S ∈ B
2
,
Z
−1
(S) =



∅, if Pi ∈/ S, i = 1, 2, 3, 4
Ac ∩ Bc
, if P1 ∈ S, Pi ∈/ S, i = 1, 2, 3,
Ac ∩ B, if P2 ∈ S, Pi ∈/ S, i = 1, 3, 4,
A ∩ Bc
, if P3 ∈ S, Pi ∈/ S, i = 1, 2, 4,
A ∩ B, if P4 ∈ S, Pi ∈/ S, i = 1, 2, 3,
Ac
, if P1 ∈ S, P2 ∈ S, Pi ∈/ S, i = 3, 4,
Bc
, if P1 ∈ S, P3 ∈ S, Pi ∈/ S, i = 2, 4,
(A∆B)
c
, if P1 ∈ S, P4 ∈ S, Pi ∈/ S, i = 2, 3,
A∆B, if P2 ∈ S, P3 ∈ S, Pi ∈/ S, i = 1, 4,
B, if P2 ∈ S, P4 ∈ S, Pi ∈/ S, i = 1, 3,
A, if P3 ∈ S, P4 ∈ S, Pi ∈/ S, i = 1, 2,
(A ∩ B)
c
, if P1 ∈ S, P2 ∈ S, P3 ∈ S, P4 ∈/ S,
(A ∩ Bc
)
c
, if P1 ∈ S, P2 ∈ S, P3 ∈/ S, P4 ∈ S,
(Ac ∩ B)
c
, if P1 ∈ S, P2 ∈/ S, P3 ∈ S, P4 ∈ S,
A ∪ B, if P1 ∈/ S, P2 ∈ S, P3 ∈ S, P4 ∈ S,
Ω, if P1 ∈ S, P2 ∈ S, P3 ∈ S, P4 ∈ S.
Thus, Z
−1
(B
2
) = {Ω, ∅, A, B, Ac
, Bc
, A ∩ B, Ac ∩ B, A ∩ Bc
,
Ac∩Bc
,(A∆B)
c
, A∆B,(A∩B)
c
,(A∩Bc
)
c
,(Ac∩B)
c
, A∪B}. It is clear that if
A, B ∈ A, then all sets in Z
−1
(B
2
) are included in A and hence Z is a random
vector measurable with respect to A.
(ii) We now examine whether Z = (IA, IB) is a random vector, using the
economical definition, as given in Definition 2.3.2. Suppose for a, b ∈ R,
C
2 = {(x, y)| − ∞ < x ≤ a, −∞ < y ≤ b} = {S|S = (−∞, a] × (−∞, b]}.
Note that with S = (−∞, a] × (−∞, b],
Z
−1
(S) =



∅, if a < 0 & b < 0,
∅, if a < 0 & b ≥ 0,
∅, if a ≥ 0 & b < 0,
Ac ∩ Bc
, if 0 ≤ a < 1 & 0 ≤ b < 1,
Ac
, if 0 ≤ a < 1 & 0 ≤ b ≤ 1,
Bc
, if 0 ≤ a ≤ 1 & 0 ≤ b < 1,
Ω, if a ≥ 1 & b ≥ 1.
It is given that A, B ∈ A hence Ac
, Bc
, Ac ∩ Bc ∈ A, it being a sigma field.
Thus, Z
−1
(S) ∈ A ∀ S ∈ C
2 and hence Z is a A measurable random vector.
□
In Example 2.3.1, we have noted that Z
−1
(B
2
) = σ(X
−1
1
(B)∪ X
−1
2
(B)). It
is in general true and we prove this important result below. In the proof, we
need the following lemma.
Lemma 2.3.1. (i) Suppose C1 and C2 are two classes of sets such that C1 ⊆
C2. Then σ(C1) ⊆ σ(C2). (ii) Suppose σ(C) ⊆ A where A is a sigma field,
then C ⊆ A.Random Vectors 89
Proof.
(i) As proved in Section 1.4, note that C1 ⊆ C2 ⊆ σ(C2). Thus, σ(C2) is a
sigma field covering C1. Hence, by the definition of the minimal sigma
field σ(C1) ⊆ σ(C2).
(ii) Note that
S ∈ C ⇒ S ∈ σ(C) ⇒ S ∈ A as σ(C) ⊆ A.
Thus, C ⊆ A. Note that Result(ii) is valid if A is any collection of sets,
not necessarily a sigma field.
Theorem 2.3.2. Suppose Z = (X1, X2)
′
is a random vector defined on a
measurable space (Ω, A) to (R
2
, B
2
). Then
σ(Z) = σ ((X1, X2)
′
) = Z
−1
(B
2
) = σ
￾
X
−1
1
(B) ∪ X
−1
2
(B)

.
Proof. Suppose a1, b1, a2 and b2 are real numbers and
S = {(x1, x2) ∈ R
2
| a1 < x1 < b1, a2 < x2 < b2}
is a rectangle in R
2
. Suppose C
1
is a class of open intervals of R and C
2
is a
class of rectangles of the type S. Then σ(C
1
) = B and σ(C
2
) = B
2
.
(i) Observe that
Z
−1
(S) = {ω | a1 < X1(ω) < b1, a2 < X2(ω) < b2}
= {ω | a1 < X1(ω) < b1} ∩ {ω | a2 < X2(ω) < b2}
= X
−1
1
((a1, b1)) ∩ X
−1
2
((a2, b2)).
In particular, (a2, b2) = R ⇒ Z
−1
(S) = X
−1
1
((a1, b1)) ∩ Ω =
X
−1
1
((a1, b1)). Thus, X
−1
1
((a1, b1)) can be written as Z
−1
(S) for some
S. Hence,
{Z
−1
(S) | S is a rectangle} ⊇ {X
−1
1
((a1, b1)) | a1, b1 ∈ R}
⇒ Z
−1
(C
2
) ⊇ X
−1
1
(C
1
)
⇒ σ(Z
−1
(C
2
)) ⊇ σ(X
−1
1
(C
1
)), by Lemma 2.3.1
⇒ Z
−1
(σ(C
2
)) ⊇ X
−1
1
(σ(C
1
))
⇒ Z
−1
(B
2
) ⊇ X
−1
1
(B).
Similarly, we have Z
−1
(B
2
) ⊇ X
−1
2
(B). Hence,
X
−1
1
(B) ∪ X
−1
2
(B) ⊆ Z
−1
(B
2
) ⇒ σ
￾
X
−1
1
(B) ∪ X
−1
2
(B)

⊆ Z
−1
(B
2
).
(2.90 Random Variables and Random Vectors
(ii) Note that X
−1
1
((a1, b1)) ∈ X
−1
1
(B) and X
−1
2
((a2, b2)) ∈ X
−1
2
(B), how￾ever, X
−1
1
(a1, b1)∩X
−1
2
(a2, b2) may not be in X
−1
1
(B)∪X
−1
2
(B). On the
other hand, it is in σ
￾
X
−1
1
(B) ∪ X
−1
2
(B)

. Thus, ∀ S ∈ C
2
Z
−1
(S) = X
−1
1
((a1, b1)) ∩ X
−1
2
((a2, b2)) ∈ σ
￾
X
−1
1
(B) ∪ X
−1
2
(B)

⇒ Z
−1
(C
2
) ⊆ σ
￾
X
−1
1
(B) ∪ X
−1
2
(B)

⇒ σ(Z
−1
(C
2
)) ⊆ σ
￾
X
−1
1
(B) ∪ X
−1
2
(B)

⇒ Z
−1
(σ(C
2
)) ⊆ σ
￾
X
−1
1
(B) ∪ X
−1
2
(B)

⇒ Z
−1
(B
2
) ⊆ σ
￾
X
−1
1
(B) ∪ X
−1
2
(B)

. (2.9)
Thus, from (2.8) and (2.9), we have Z
−1
(B
2
) = σ(X
−1
1
(B) ∪ X
−1
2
(B)).
In Example 2.3.1 we have verified that if the components of Z are random
variables with respect to A, then Z is a random vector with respect to A. It
is in general true and we prove this important result below. Theorem 2.3.2 is
heavily used in the proof.
Theorem 2.3.3. Suppose Z = (X1, X2)
′
is defined on the measurable space
(Ω, A) to (R
2
, B
2
). Then Z is a random vector measurable with respect to A
if and only if X1 and X2 are random variables measurable with respect to A.
Proof. In Theorem 2.3.2, it is proved that Z
−1
(B
2
) = σ(X
−1
1
(B) ∪ X
−1
2
(B)).
(i) Suppose Z is a random vector measurable with respect to A. Then
Z
−1
(B
2
) ⊆ A ⇒ σ(X
−1
1
(B) ∪ X
−1
2
(B)) ⊆ A
⇒ X
−1
1
(B) ∪ X
−1
2
(B) ⊆ A
by (ii) of Lemma 2.3.1
Hence, A ∈ X
−1
1
(B) ⇒ A ∈ X
−1
1
(B) ∪ X
−1
2
(B) ⊆ A
⇒ A ∈ A ⇒ X
−1
1
(B) ⊆ A
Similarly, A ∈ X
−1
2
(B) ⇒ A ∈ A ⇒ X
−1
2
(B) ⊆ A.
Hence, X1 and X2 are random variables measurable with respect to A.
(ii) Suppose X1 and X2 are random variables measurable with respect to A.
Then
X
−1
1
(B) ⊆ A & X
−1
2
(B) ⊆ A ⇒ X
−1
1
(B) ∪ X
−1
2
(B) ⊆ A
⇒ σ
￾
X
−1
1
(B) ∪ X
−1
2
(B)

⊆ A
⇒ Z
−1
(B
2
) ⊆ A.
Hence, Z is a random vector measurable with respecRandom Vectors 91
Remark 2.3.1. Theorem 2.3.2 and Theorem 2.3.3 can be extended to a k
dimensional random vector, that is, if Z = (X1, X2, · · · , Xk)
′
, then
Z
−1
(B
k
) = σ
 [
k
i=1
X
−1
i
(B)

.
Further, Z is a random vector measurable with respect to A if and only if
each of Xi
, i = 1, 2, · · · , k is a random variable measurable with respect to
A. It is the most useful result to verify whether Z is a random vector, as one
can simply proceed marginally and verify whether components are random
variables using the economical definition of a random variable.
We apply Theorem 2.3.3 in the next example.
Example 2.3.3. Suppose Z = (IA, IB) where A, B ∈ A. In Example 5.3.8, us￾ing economical and descriptive definitions of a random vector, it is shown that
Z is a random vector on (Ω, A). We now use Theorem 2.3.3. In Example 2.2.3,
we have noted that the sigma field induced by IA is I
−1
A (B) = {Ω, ∅, A, Ac}
and that of IB is given by I
−1
B (B) = {Ω, ∅, B, Bc}. Both are included in A
which implies that IA and IB both are random variables with respect to A
and hence by Theorem 2.3.3, Z = (IA, IB) is A measurable random vector. It
is clear that instead of using the definitions, it is simpler to verify that IA and
IB are random variables and hence Z = (IA, IB)
′
is a random vector. Note
that I
−1
A (B) ∪ I
−1
B (B) = {Ω, ∅, A, Ac
, B, Bc} which is not a sigma field but it
is included in Z
−1
(B
2
). If we go on adding sets to I
−1
A (B) ∪ I
−1
B (B) so that it
becomes closed under complementation and countable union and hence will
be a sigma field, then σ(I
−1
A (B) ∪ I
−1
B (B)) = Z
−1
(B
2
). □
In Theorem 2.2.4 we have proved that measurability of a random variable
X remains invariant under Borel transformations and the sigma field induced
by any Borel function of X is included in the sigma field induced by X.
We prove similar result for a Borel transformation of a random vector in the
following Theorem 2.3.5. We first define a Borel function in higher dimensions.
The definition is similar to that in one dimension.
Definition 2.3.3. Borel function: Suppose g : (R
k
, B
k
) → (R
l
, B
l
) l ≤ k
is a function where g = (g1, g2, · · · , gl). g is a Borel function if ∀ S ∈ B
l
,
g
−1
(S) ∈ B
k
.
Following theorem gives a necessary and sufficient condition for a function
to be a Borel function in higher dimensions.
Theorem 2.3.4. Suppose g : (R
k
, B
k
) → (R
l
, B
l
) l ≤ k is a function where
g = (g1, g2, · · · , gl). g is a Borel function if and only if each of gi is a Borel
function from (R
k
, B
k
) → (R, B), i = 1, 2, · · · , l.
Proof. Proof follows on similar lines as in Theorem 2.3.3, with (Ω, A) replaced
by (R
k
, B
k
).92 Random Variables and Random Vectors
Theorem 2.3.5. Suppose Z : (Ω, A) → (R
k
, B
k
) is a random vector, measur￾able with respect to A.
(i) Suppose g : (R
k
, B
k
) → (R, B) is a Borel function, then Y = g(Z) is a
random variable, measurable with respect to A.
(ii) σ(Y ) ⊆ σ(Z).
(iii) Suppose g : (R
k
, B
k
) → (R
l
, B
l
), l ≤ k is a Borel function, then Y = g(Z)
is a random vector, measurable with respect to the sigma field A.
(iv) σ(Y ) ⊆ σ(Z).
Proof.
(i) For a Borel set S ∈ B,
(g(Z))−1
(S) = Y
−1
(S) = {ω|Y (ω) ∈ S} = {ω|g(Z)(ω) ∈ S}
= {ω|g(Z(ω)) ∈ S} = {ω|Z(ω) ∈ g
−1
(S)}
= Z
−1
(g
−1
(S)) . (2.10)
Thus, for a Borel set S ∈ B, (g(Z))−1
(S) = Z
−1
(g
−1
(S)). Now, ∀ S ∈ B,
S ∈ B ⇒ g
−1
(S) ∈ B, g being a Borel function
⇒ Z
−1
(g
−1
(S)) ∈ A, Z being A measurable
⇒ (g(Z))−1
(S) = Y
−1
(S) ∈ A.
Hence, Y = g(Z) is a random variable, measurable with respect to A.
(ii) To prove that Y
−1
(B) ⊆ Z
−1
(B
k
), observe that
A ∈ Y
−1
(B) ⇒ ∃ S ∈ B such that A = Y
−1
(S)
⇒ A = Y
−1
(S) = Z
−1
(g
−1
(S)) by (2.10)
⇒ A = Z
−1
(g
−1
(S)) ∈ Z
−1
(B
k
) as g
−1
(S) ∈ B
k
Thus, A ∈ Y
−1
(B) ⇒ A ∈ Z
−1
(B
k
) ⇒ Y
−1
(B) ⊆ Z
−1
(B
k
).
(iii) Proof of this part is on similar lines as that of (i). For a Borel set S ∈ B
l
,
(g(Z))−1
(S) = Y
−1
(S) = {ω|Y (ω) ∈ S} = {ω|g(Z)(ω) ∈ S}
= {ω|g(Z(ω)) ∈ S} = {ω|Z(ω) ∈ g
−1
(S)}
= Z
−1
(g
−1
(S)). (2.11)
Thus, for a Borel set S ∈ B
l
, g(Z)
−1
(S) = Z
−1
(g
−1
(S)). Now, ∀ S ∈ B
l
,
S ∈ B
l ⇒ g
−1
(S) ∈ B
k
, g being a Borel function
⇒ Z
−1
(g
−1
(S)) = (g(Z))−1
(S) = Y
−1
(S) ∈ A,Random Vectors 93
Z being A measurable. Hence, Y = g(Z) is a random vector, measurable
with respect to A. Another approach to prove this result is as follows.
g : (R
k
, B
k
) → (R
l
, B
l
), l ≤ k is a Borel function implies that each of
gi
, i = 1, 2, · · · , l is a Borel function from (R
k
, B
k
) → (R, B). It then
follows by part(i) that Yi = gi(Z) is a random variable, measurable with
respect to A. Hence, by Theorem 2.3.3, Y = (Y1, Y2, · · · , Yl) = g(Z) is a
random vector, measurable with respect to A.
(iv) To prove that Y
−1
(B
l
) ⊆ Z
−1
(B
k
), observe that
A ∈ Y
−1
(B
l
) ⇒ ∃ S ∈ B
l
such that A = Y
−1
(S)
⇒ A = Y
−1
(S) = Z
−1
(g
−1
(S)) by (2.11)
⇒ A = Z
−1
(g
−1
(S)) ∈ Z
−1
(B
k
) as g
−1
(S) ∈ B
k
Thus, A ∈ Y
−1
(B
l
) ⇒ A ∈ Z
−1
(B
k
) ⇒ Y
−1
(B
l
) ⊆ Z
−1
(B
k
).
Remark 2.3.2. As a consequence of Theorem 2.3.5, the addition, the sub￾traction and the product of k random variables is again a random vari￾able. Further Y = exp(t1X1 + t2X2 + · · · + tkXk), where t1, t2, · · · , tk are
real numbers is also a random variable. Such a result is proved with a dif￾ferent approach in Section 4. Part (iii) and (iv) of Theorem 2.3.5 indicate
that results for real valued Borel function can be easily extended to a Borel
function g : (R
k
, B
k
) → (R
l
, B
l
), l ≤ k. Thus, if Z = (X1, X2, X3)
′
is a
random vector, measurable with respect to A, then random vectors such as
U = (X1/X3, X2/X3)
′ or V = (X1 + X3, X2 + X3)
′ are also A measurable
random vectors.
Example 2.3.4. Suppose Z = (X1, X2, · · · , X5)
′
is a random vector on
(Ω, A). Suppose Y =
P4
i=1 liXi
, where l1, l2, · · · , l4 are any real numbers.
Then Y can be expressed as Y = g(Z) where g : R
5 → R is defined
as g(x1, x2, · · · , x5) = P5
i=1 lixi with l5 = 0. It is a Borel function and
hence by Theorem 2.3.5, Y is a random variable on (Ω, A, P). Suppose
U = (sin X1, X2
2
, X3
3
, eX4
, |X5|). It is to be noted that sin X1 is a Borel function
of X1, similarly, each of X2
2
, X3
3
, eX4
, |X5| are Borel functions of X2, X3, X4, X5
respectively. Thus, each component of U is a random variable on (Ω, A) and
hence by Theorem 2.3.3, U is a random vector on (Ω, A). □
Remark 2.3.3. It is known that there is a one-to-one correspondence between
all points in R
2 and a set of all complex numbers. Analogously, if (X1, X2)
′
is a random vector, then Z = X1 + iX2 is a complex valued random variable,
where i =
√
−1.
From one dimensional random variable, we proceeded to define a k￾dimensional random vector. We now extend it to a countably infinite collection94 Random Variables and Random Vectors
of random variables and define what we mean by a sequence of random vari￾ables. Towards it, we need a concept of the Borel field in infinite dimensions.
Suppose x = (x1, x2, · · · ,) is a sequence of real numbers and R∞ denotes the
collection of all such sequences of real numbers. Thus,
R
∞ = {x = (x1, x2, · · · ,) | xi ∈ R, ∀ i ≥ 1}.
We consider a collection of particular types of subsets of R∞ defined as follows.
Definition 2.3.4. Cylinder set with a finite dimensional base: A subset S of
R∞ is known as a cylinder set with a finite dimensional base if it is defined
as,
S = {x | aij ≤ xij ≤ bij
, j = 1, 2, · · · , k, xij ∈ R, j = k + 1, k + 2, · · · },
where i1, i2, · · ·ik is any permutation of positive integers and k is finite.
Definition 2.3.5. Borel field in infinite dimensions: Suppose C∞ is a collec￾tion of all cylinder sets with a finite dimensional base, as defined in Definition
2.3.4. Then the minimal sigma field induced by C∞ is said to be a Borel field
in infinite dimensions and is denoted by B∞.
Having defined the Borel field in infinite dimensions, we now define an
infinite dimensional random vector.
Definition 2.3.6. Infinite dimensional random vector: A function
Z = (X1, X2, · · · ,) defined on (Ω, A) to (R∞, B∞) is an infinite dimensional
random vector if ∀ S ∈ B∞, Z
−1
(S) ∈ A.
To prove that Z = (X1, X2, · · · ,) is an infinite dimensional random vector
on (Ω, A), if and only if each component of Z is a random variable on (Ω, A),
we derive a relation between the sigma field induced by Z and the sigma fields
induced by each of {Xn, n ≥ 1}. We define
An = σ{X1, X2, · · · , Xn} = σ
 [n
i=1
(X
−1
i
(B))
,
which is the minimal sigma field induced by {X1, X2, · · · , Xn}. Note that
n[
+1
i=1
(X
−1
i
(B)) ⊇
[n
i=1
(X
−1
i
(B))
⇒ σ
 n[
+1
i=1
(X
−1
i
(B))
⊇ σ
 [n
i=1
(X
−1
i
(B))
⇒ An+1 ⊇ An ∀ n ≥ 1 .
Hence, {An, n ≥ 1} is a monotone increasing sequence of sigma fields and
therefore has a limit given by S
n≥1 An, which may not be a sigma field.Random Vectors 95
Then we find the minimal sigma field generated by S
n≥1 An, denoted by
σ(
S
n≥1 An). In the following Theorem 2.3.6, we prove that a sigma field
Z
−1
(B∞) induced by a sequence Z = (X1, X2, · · · ,) of random variables is
σ(
S
n≥1 An). Thus, if
Z
−1
(B
∞) = σ
 [
n≥1
An

= σ({Xn, n ≥ 1}) ⊆ A
then {Xn, n ≥ 1} is an infinite dimensional random vector, measurable with
respect to A.
Theorem 2.3.6. Suppose an infinite dimensional random vector
Z = (X1, X2, · · · ,) is defined on (Ω, A) to (R∞, B∞). Then
Z
−1
(B
∞) = σ

(X1, X2, · · · ,)

= σ
 [
n≥1
An

.
Proof. Suppose S = {x | aij ≤ xij ≤ bij
, j = 1, 2, · · · , k, xij ∈ R, j =
k + 1, k + 2, · · · } is a cylinder set, the collection of which generates B∞. Then
for S ∈ B∞,
Z
−1
(S) = {ω|Z(ω) ∈ S} =
\
k
j=1
X
−1
ij
((aij
, bij
)), for any i1, i2, · · · , ik ∈ N.
Then as in Theorem 2.3.2, observe that, for any j = 1, 2, · · · , k and
i1, i2, · · · , ik ∈ N,
X
−1
ij
((aij
, bij
)) ∈ X
−1
ij
(B) ⇒
\
k
j=1
X
−1
ij
((aij
, bij
)) ∈ σ
 [
k
j=1
(X
−1
ij
(B)

⇒ Z
−1
(S) ∈ σ
 [
k
j=1
(X
−1
ij
(B)

⇒ Z
−1
(S) ∈ σ
 [
k
i=1
(X
−1
i
(B)

= Ak,
for some k ≥ 1
It further implies that
Z
−1
(S) ∈
[
k≥1
Ak ⇒ Z
−1
(C
∞) ⊂
[
k≥1
Ak
⇒ σ

Z
−1
(C
∞)

⊆ σ
 [
k≥1
Ak

⇒ Z
−1
(B
∞) ⊆ σ
 [
k≥1
Ak

. (2.12)96 Random Variables and Random Vectors
Now to establish the inclusion in the reverse direction, in Z
−1
(S) if we take
(aij
, bij
) = R for j = 2, · · · , k, then Z
−1
(S) = X
−1
i1
((ai1
, bi1
)), hence
Z
−1
(C∞) ⊇ X
−1
i1
(B). On similar lines we have, X
−1
ij
(B) ⊂ Z
−1
(C∞) for
j = 2, · · · , k and any permutation of i1, i2, · · · , ik ∈ N. In particular, suppose
ij = j, j = 1, 2, · · · , k, then for i = 1, 2, · · · , k
X
−1
i
(B) ⊆ Z
−1
(C
∞) ⇒
[
k
i=1
X
−1
i
(B) ⊆ Z
−1
(C
∞)
⇒ σ
 [
k
i=1
X
−1
i
(B)

⊆ σ

Z
−1
(C
∞)

⇒ Ak ⊆ Z
−1
(B
∞), for any k ≥ 1
⇒
[
k≥1
Ak ⊆ Z
−1
(B
∞)
⇒ σ(
[
k≥1
Ak) ⊆ Z
−1
(B
∞). (2.13)
From (2.12) and (2.13) we have, Z
−1
(B∞) = σ(
S
n≥1
An).
Theorem 2.3.3 states that Z = (X1, X2, · · · , Xk)
′
is a k-dimensional ran￾dom vector, measurable with respect to A, if and only if each of the compo￾nents X1, X2, · · · , Xk are random variables, measurable with respect to A. On
similar lines in the following theorem we prove that Z = (X1, X2, · · · ,) de￾fined on (Ω, A) is an infinite dimensional random vector, if and only if for every
n ≥ 1, Xn is a random variable on (Ω, A). The proof is based on Theorem
2.3.6.
Theorem 2.3.7. Suppose Z = (X1, X2, · · · ,) is defined on the measurable
space (Ω, A) to (R∞, B∞). Then Z is an infinite dimensional random vector
if and only if for every n ≥ 1, Xn is a random variable on a measurable space
(Ω, A).
Proof. In Theorem 2.3.6, we have proved that Z
−1
(B∞) = σ
 S
n≥1
An

.
Suppose for every i ≥ 1, Xi
is a random variable on (Ω, A). Hence,
X
−1
i
(B) ⊆ A, ∀ i ≥ 1 ⇒
[n
i=1
X
−1
i
(B) ⊆ A ⇒ σ
 [n
i=1
X
−1
i
(B)

⊆ A
⇒ An ⊆ A, ∀ n ≥ 1
⇒
[
n≥1
An ⊆ A ⇒ σ
 [
n≥1
An

⊆ A
⇒ Z
−1
(B
∞) ⊆ A (2.14)Random Vectors 97
Thus, if for each i ≥ 1, Xi
is a random variable, measurable with respect to A,
then Z is an infinite dimensional random vector, measurable with respect to
A. Now suppose Z = (X1, X2, · · · ,) is an infinite dimensional random vector,
measurable with respect to A. Then
Z
−1
(B
∞) ⊆ A ⇒ σ
 [
n≥1
An

⊆ A
⇒
[
n≥1
An ⊆ A ⇒ An ⊆ A, ∀ n ≥ 1
⇒ σ
 [n
i=1
X
−1
i
(B)

⊆ A, ∀ n ≥ 1
⇒
[n
i=1
X
−1
i
(B) ⊆ A, ∀ n ≥ 1
⇒ X
−1
i
(B) ⊆ A, ∀ i ≥ 1 (2.15)
Thus for each i ≥ 1, Xi
is a random variable, measurable with respect to A.
From (2.14) and (2.15) we conclude that Z = (X1, X2, · · · ,) defined on (Ω, A)
is an infinite dimensional random vector, if and only if for every n ≥ 1, Xn is
a random variable on (Ω, A).
As a consequence of this theorem, an infinite dimensional random vector
Z will now be referred to as a sequence {Xn, n ≥ 1} of random variables.
Once we have defined a sequence of random variables, the subsequent
natural questions are, how to define its limit, how to find it, whether it is
unique and whether it is a random variable. In the following lemmas and
theorems and in Chapter 6, we discuss all these issues.
Suppose {Xn, n ≥ 1} is a sequence of random variables defined on a prob￾ability space (Ω, A, P). Thus, for every n ≥ 1, Xn is a measurable function
on a measurable space (Ω, A) with range space as the real line, that is, for
fixed ω ∈ Ω, Xn(ω) = an, a real number. As a consequence, for each fixed
ω ∈ Ω, {Xn(ω), n ≥ 1} ≡ {an, n ≥ 1}, a sequence of real numbers and hence
all techniques of convergence of a sequence of real numbers can be used to
study the convergence of a sequence of random variables. However, note that
a sequence {Xn, n ≥ 1} of random variables is equivalent to a collection of
sequences of real numbers, {{Xn(w) = an, n ≥ 1}, ω ∈ Ω}. This collection is
finite, countably infinite or uncountable depending on whether Ω is finite,
countably infinite or uncountable respectively. Thus, to discuss convergence
of a sequence of random variables, one has to deal with convergence of a col￾lection of sequences of real numbers. There are various modes of convergence
of a sequence of random variables, which we will discuss in detail in Chapters
6 and 7. In two approaches, we proceed exactly on the lines of convergence
of the sequence of real numbers {an, n ≥ 1}, with images Xn(ω) = an. Other
modes of convergence depend on different approaches to reduce a sequence of
random variables to a sequence of real numbers.98 Random Variables and Random Vectors
We now discuss one mode of convergence of a sequence of random variables,
where a sequence of random variables is reduced to a collection of sequences
of real numbers corresponding to the images. For a sequence of real numbers,
we say that the limit exists, if its limit supremum and limit infimum coincide
and value of the limit is the common value of the limit supremum and limit
infimum.
We proceed to define a limit supremum and a limit infimum of the sequence
of random variables. These are defined on similar lines as for a sequence of
real numbers. Suppose
Yn(ω) = inf
k≥n
Xk(ω) & Zn(ω) = sup
k≥n
Xk(ω).
From the theory of real numbers, it is known that as n → ∞, ∀ ω ∈ Ω,
Yn(ω) ↑ sup
n≥1
Yn(ω) = sup
n≥1
{ inf
k≥n
Xk(ω)} = lim inf Xn(ω)
& Zn(ω) ↓ inf
n≥1
Zn(ω) = inf
n≥1
{sup
k≥n
Xk(ω)} = lim sup Xn(ω).
Thus, for a sequence {Xn, n ≥ 1} of random variables defined on (Ω, A),
lim inf Xn and lim sup Xn are defined as
lim inf
n→∞
Xn = sup
n≥1
inf
k≥n
Xk & lim sup
n→∞
Xn = inf
n≥1
sup
k≥n
Xk .
As in the setup of real numbers, lim inf Xn(ω) and lim sup Xn(ω) always exist,
it may happen that for some ω ∈ Ω, lim inf Xn(ω) = −∞ and lim sup Xn(ω) =
∞. A limit of a sequence of random variables, denoted by limn→∞ Xn, is
defined similar to that for a sequence of real numbers.
Definition 2.3.7. Limit of a sequence of random variables: Suppose
{Xn, n ≥ 1} is a sequence of A measurable random variables. If ∀ ω ∈ Ω,
lim inf Xn(ω) = lim sup Xn(ω), then we say that limn→∞ Xn exists. Further,
if lim inf Xn(ω) = lim sup Xn(ω) = X(ω), ∀ ω ∈ Ω, then we say that
limn→∞ Xn = X on Ω. If X(ω) < ∞, ∀ ω ∈ Ω, then we say that Xn
converges to X and write it as Xn → X on Ω.
The type of convergence of a sequence of random variables defined above is
known as a point-wise convergence or convergence everywhere. If Xn → X on
A ⊆ Ω, then A is said to be a set of convergence of the sequence {Xn, n ≥ 1}.
Definition of a point-wise convergence of the sequence {Xn, n ≥ 1} can also
be given as follows.
Definition 2.3.8. Point-wise convergence of a sequence of random variables:
A sequence {Xn, n ≥ 1} of random variables is said to converge to a random
variable X < ∞ on A ⊆ Ω if ∀ ω ∈ A & ∀ ϵ > 0, ∃ n0(ϵ, ω) such that
∀ n ≥ n0(ϵ, ω), |Xn(ω) − X(ω)| < ϵ. If A = Ω then we have the point-wise
convergence on Ω.Random Vectors 99
Remark 2.3.4. If n0(ϵ, ω) is the same for all ω ∈ A, then we say that the
convergence is uniform on A.
Remark 2.3.5. Since the point-wise convergence of a sequence of random
variables is defined in terms of the convergence of a sequence of images, that
is real numbers, the limit, whenever exists, is uniquely defined.
Definition 2.3.9. Almost sure convergence of a sequence of random variables:
If a sequence {Xn, n ≥ 1} of random variables converges to a random variable
X < ∞ on A ⊆ Ω such that P(A) = 1, then we say that {Xn, n ≥ 1}
converges to X almost surely.
A set N such that P(N) = 0 is known as a P-null set or P-null event. Thus
point-wise convergence on Nc
is the almost sure convergence. In Chapters 6
and 7, we study in detail various properties of almost sure convergence.
We now investigate whether the limit of a sequence of random variables
is a random variable. In the following theorem, we prove that if {Xn, n ≥ 1}
is a sequence of random variables on a measurable space (Ω, A), lim inf Xn
and lim sup Xn and lim Xn, whenever exists, are random variables, measur￾able with respect to A. In some cases these may be extended valued random
variables.
Theorem 2.3.8. Suppose {Xn, n ≥ 1} is a sequence of random variables on
a measurable space (Ω, A). Suppose
(i) Y1 = max{X1, X2} and Y2 = min{X1, X2}
(ii) Z1 = supn≥1 Xn and Z2 = infn≥1 Xn
(iii) U1 = lim inf Xn and U2 = lim sup Xn and
(iv) X = lim Xn, if it exists
Then Y1, Y2, Z1, Z2, U1, U2 and X are random variables, measurable with
respect to A.
Proof. Since {Xn, n ≥ 1} is a sequence of random variables on a measurable
space (Ω, A), for each n ≥ 1, Xn is a random variable on a measurable space
(Ω, A), that is, ∀ S ∈ B, X−1
n
(S) ∈ A.
(i) Note that for any x ∈ R,
Y
−1
1
((−∞, x]) = {ω | Y1(ω) ≤ x} = {ω | max{X1, X2}(ω) ≤ x}
= {ω | max{X1(ω), X2(ω)} ≤ x}
= {ω | X1(ω) ≤ x} ∩ {ω | X2(ω) ≤ x}
= X
−1
1
((−∞, x]) ∩ X
−1
2
((−∞, x]) ∈ A,
sigma field being closed under intersection. Hence by the economical def￾inition of the random variable, Y1 = max{X1, X2} is a random variable100 Random Variables and Random Vectors
measurable with respect to A. To prove that Y2 is a random variable,
using arguments similar to those for Y1 = max{X1, X2}, we get for any
x ∈ R,
Y
−1
2
((−∞, x]) = {ω | min{X1(ω), X2(ω)} ≤ x}
= {ω | X1(ω) ≤ x} ∪ {ω | X2(ω) ≤ x}
= X
−1
1
((−∞, x]) ∪ X
−1
2
((−∞, x]) ∈ A.
Thus, Y2 = min{X1, X2} is a A measurable random variable.
(ii) As in (i), for any x ∈ R,
Z
−1
1
((−∞, x]) = {ω | sup
n≥1
Xn ≤ x} = {ω | Xn(ω) ≤ x, ∀ n ≥ 1}
=
\
n≥1
{ω | Xn(ω) ≤ x} =
\
n≥1
X−1
n
((−∞, x]) ∈ A,
as sigma field is closed under countable intersection. Thus, Z1 =
supn≥1 Xn is a A measurable random variable. Now, for any x ∈ R,
Z
−1
2
((−∞, x]) = {ω | inf
n≥1
Xn ≤ x}
= {ω | Xn(ω) ≤ x, for at least one n ≥ 1}
=
[
n≥1
{ω | Xn(ω) ≤ x} =
[
n≥1
X−1
n
((−∞, x]) ∈ A,
as sigma field is closed under countable union. Thus, Z2 = infn≥1 Xn is
a A measurable random variable.
(iii) To prove that lim inf Xn and lim sup Xn are A measurable random vari￾ables, from the definition of lim inf Xn we note that,
lim inf Xn = sup
n≥1
Yn, where Yn = inf
k≥n
Xk.
It is proved in (ii) that infimum of A measurable random variables is
again a random variable, measurable with respect to A. Hence, Yn is a A
measurable random variable. Further, it is also proved that supremum
of random variables is again a random variable. Hence, lim inf Xn =
supn≥1 Yn is a A measurable random variable. By the definition,
lim sup Xn = inf
n≥1
Zn, where Zn = sup
k≥n
Xk.
Note that Zn, being supremum of A measurable random variables is a
A measurable random variable and lim sup Xn being infimum of Zn ran￾dom variables is a A measurable random variable.Random Vectors 101
(iv) If limn→∞ Xn exists, then lim inf Xn = lim sup Xn = lim Xn. Further,
lim inf Xn and lim sup Xn are A measurable random variables, hence
limn→∞ Xn is a A measurable random variable.
Following example illustrates the point-wise convergence of a sequence of
random variables.
Example 2.3.5. Suppose a measurable space (Ω, A) is defined as Ω = (0, 1]
and A is a sigma field of subsets of Ω. Suppose a sequence {Xn, n ≥ 1} of
A measurable random variables and a A measurable random variable X are
defined as follows. Xn(ω) = sin(ω) + ω
n, n ≥ 1 & X(ω) = sin(ω). It is
clear that, Xn(ω) = sin(ω) + ω
n → sin(ω) = X(ω), ∀ ω ∈ (0, 1). But at
ω = 1, Xn(ω) = sin(1) + 1 ∀ n ≥ 1 hence converges to sin(1) + 1 ̸= X(ω) =
sin(1). Thus the sequence of random variables {Xn, n ≥ 1} does not converge
point-wise to X. However, note that Xn(ω) → X(ω), except for ω = 1. Thus,
if A = (0, 1), then, Xn → X on A. To grasp and appreciate the abstract
concept of point-wise convergence, we verify the results graphically, using the
following R code.
Code 2.3.1. Verification of point-wise convergence:
Xnw=function(n,w){return(sin(w)+w^n)}
Xw=function(w){return(sin(w))}
omegavec=seq(0,1,length=100)
nvec=c(1,10,100); nlab=paste("n=",nvec,sep="")
XnMat=matrix(nrow=length(omegavec),ncol=length(nvec))
for(i in 1:nrow(XnMat))
{
omega=omegavec[i]
for(j in 1:ncol(XnMat))
{
n=nvec[j]
XnMat[i,j]=Xnw(n,omega)
}
}
XVec=c()
for(i in 1:length(omegavec))
{
omega=omegavec[i]
XVec[i]=Xw(omega)
}
plot(omegavec,XVec,ylim=c(0,max(XnMat)+0.1),type="l",col=2,102 Random Variables and Random Vectors
lty=1,lwd=2,xlim=c(0,1.3),xaxt="n", xlab=expression(omega),
ylab=(expression(Xn(omega)~or~X(omega))),
main=(expression(Xn(omega)~"="~sin(omega)+ omega^n)))
axis(1,at=seq(0,1,by=0.1),labels=seq(0,1,by=0.1))
for(i in 1:ncol(XnMat))
{
lines(omegavec,XnMat[,i],col=1,lty=i+1,type="l",lwd=2)
}
legend("bottomright",legend=c(nlab,expression(X(omega))),
lty=c(2:(ncol(XnMat)+1),1),col=c(rep(1,3),2),lwd=2)
In Figure 2.1, the red curve displays values of X(ω), whereas the black
curves give values of Xn(ω) for different choices of n as indicated in the legend.
It can be seen that the black curves approach the red curve as n increases
except for the rightmost endpoint, that is, ω = 1. Thus, Xn ↛ X point-wise,
but Xn → X on A = (0, 1). □
The next theorem illustrates the point-wise convergence of a sequence of
random variables. In Example 2.2.3, we have noted that if A ∈ A, then the
indicator function IA is a random variable measurable with respect to A.
Thus, if {An, n ≥ 1} is a sequence of sets in A, then IAn
is a random variable
FIGURE 2.1
Point-wise ConvergenceRandom Vectors 103
measurable with respect to A ∀ n ≥ 1. Hence by Theorem 2.3.7, {IAn
, n ≥
1} is a sequence of random variable measurable with respect to A. Suppose
{An, n ≥ 1} is a convergent sequence of sets in A, then limn→∞ An ∈ A.
Suppose limn→∞ An = A. In the next theorem, we prove that An → A if and
only if IAn → IA on Ω. The proof is heavily based on the following lemma.
Lemma 2.3.2. Suppose {An, n ≥ 1} is a sequence of sets in A, then
Ilim inf An = lim inf IAn & Ilim sup An = lim sup IAn
.
Proof. By the definition of the indicator function,
Ilim inf An = 1 ⇐⇒ ω ∈ lim inf An =
[
n≥1
\
k≥n
Ak
⇐⇒ ω ∈
[
n≥1
Bn, where Bn =
\
k≥n
Ak
⇐⇒ ω ∈
\
k≥n
Ak, for at least one n ≥ 1
⇐⇒ ω ∈ Ak, ∀ k ≥ n and for at least one n ≥ 1
⇐⇒ IAk = 1, ∀ k ≥ n and for at least one n ≥ 1
⇐⇒ inf
k≥n
IAk = 1, for at least one n ≥ 1
⇐⇒ sup
n≥1
inf
k≥n
IAk = 1 ⇐⇒ lim inf IAn = 1 .
On similar lines we have Ilim inf An = 0 ⇐⇒ lim inf IAn = 0. Thus,
Ilim inf An = lim inf IAn
. Using similar arguments we examine whether
Ilim sup An = lim sup IAn
. Observe that
Ilim sup An = 1 ⇐⇒ ω ∈ lim sup An =
\
n≥1
[
k≥n
Ak
⇐⇒ ω ∈
\
n≥1
Cn, where Cn =
[
k≥n
Ak
⇐⇒ ω ∈
[
k≥n
Ak, ∀ n ≥ 1
⇐⇒ ω ∈ Ak, for at least one k ≥ n & ∀ n ≥ 1
⇐⇒ IAk = 1, for at least one k ≥ n & ∀ n ≥ 1
⇐⇒ sup
k≥n
IAk = 1, ∀ n ≥ 1
⇐⇒ inf
n≥1
sup
k≥n
IAk = 1 ⇐⇒ lim sup IAn = 1 .
Thus, we have Ilim sup An = lim sup IAn
.
Theorem 2.3.9. Suppose {An, n ≥ 1} is a sequence of sets in A, then
An → A ∈ A ⇐⇒ IAn → IA on Ω.104 Random Variables and Random Vectors
Proof. By the definition of convergence of sequence of sets and point-wise
convergence of sequence of random variables we have,
An → A ⇐⇒ lim sup An = lim inf An = A
⇐⇒ Ilim sup An = Ilim inf An = IA on Ω
⇐⇒ lim sup IAn = lim inf IAn = IA on Ω, by Lemma 2.3.2
⇐⇒ lim IAn = IA on Ω .
Remark 2.3.6. (i) Observe that in Theorem 2.3.9, IA = limn→∞ IAn
is A
measurable random variable, when IAn
is A measurable random variable for
each n ≥ 1. (ii) Note that using Theorem 2.3.9, the convergence of sequence
of sets can be defined in terms of the convergence of sequence of indicator
functions of sets.
We now define one more sigma field related to a sequence of random vari￾ables. It is known as a tail sigma field. Suppose {Xn, n ≥ 1} is a sequence of
random variables. Suppose Cn = σ{Xn, Xn+1, · · · }. We have proved that
σ({Xn, n ≥ 1}) = σ
 [
n≥1
An

where An = σ({X1, X2, · · · , Xn}).
Hence by definition,
Cn = σ{Xn, Xn+1, · · · } = σ
 [
k≥n
Ak

& Cn+1 = σ
 [
k≥n+1
Ak

.
Observe that,
[
k≥n
Ak ⊇
[
k≥n+1
Ak ⇒ σ
 [
k≥n
Ak

⊇ σ
 [
k≥n+1
Ak

⇒ Cn ⊇ Cn+1 ∀ n ≥ 1.
Thus, {Cn, n ≥ 1} is a non-increasing sequence of sigma fields with limit as
T =
T
n≥1 Cn. T being intersection of sigma fields, is again a sigma field.
Definition 2.3.10. Tail sigma field and tail event: Suppose {Xn, n ≥ 1} is a
sequence of random variables and Cn = σ{Xn, Xn+1, · · · }. Then T =
T
n≥1 Cn
is known as a tail sigma field of the sequence {Xn, n ≥ 1} and sets in T are
known as tail events.
If n is interpreted as time, then Cn contains the information beyond time n
and T contains the information “beyond time n ∀ n”, that is, loosely speaking,
the information at infinity. Another name for the tail sigma field is the sigma
algebra of remote events. A random variable X such that σ(X) ⊆ T, that is,
a random variable which is measurable with respect to a tail sigma field TRandom Vectors 105
is known as a tail random variable. Intuitively, a function measurable with
respect to T, does not depend on any finite segment of the sequence {Xn, n ≥
1}, in a sense that its value is not affected if finitely many Xi
’s are changed in
the sequence {Xn, n ≥ 1}. Similarly, for the tail event, the probability remains
unaltered if finitely many Xi
’s are changed in the sequence. It is thus expected
that lim inf Xn, lim sup Xn and lim Xn, if it exists, should be measurable with
respect to a tail sigma field T. In the following theorem, we prove that it is
indeed true.
Theorem 2.3.10. Suppose {Xn, n ≥ 1} is a sequence of random variables
on a measurable space (Ω, A). Then lim inf Xn, lim sup Xn and lim Xn, if it
exists, are measurable with respect to a tail sigma field T.
Proof.
(i) By definition,
lim sup Xn = inf
n≥1
sup
k≥n
Xk = inf
n≥1
Wn, where Wn = sup
k≥n
Xk.
Note that if A ⊆ B, then sup(A) ≤ sup(B). Hence ∀ n ≥ 1,
Wn = sup{Xn, Xn+1, Xn+2, · · · , } ≥ sup{Xn+1, Xn+2, · · · , } = Wn+1
⇒ {Wn, n ≥ 1} is a non-increasing sequence.
Observe that Wn is a function of {Xn, Xn+1, · · · , } and hence it is mea￾surable with respect to Cn = σ{Xn, Xn+1, · · · }. Further, {Cn, n ≥ 1}
is a non-increasing sequence of sigma fields. Now, W1 is C1 measurable
and W2 is C2 measurable. However, C2 ⊆ C1 and hence W2 is C1 mea￾surable. Using such arguments, we claim that Wn, which is measurable
with respect to Cn, is also measurable with respect to Ck, ∀ k ≤ n. As
a consequence, infn≥1 Wn is measurable with respect to C1, since each
Wn is measurable with respect to C1. Similarly, infn≥k Wn is measur￾able with respect to Ck, since each Wn is measurable with respect to
Ck. Note that since {Wn, n ≥ 1} is a non-increasing sequence, ∀ k ∈ N,
infn≥1 Wn = infn≥k Wn. Thus, infn≥1 Wn is measurable with respect to
Ck, ∀ k ∈ N implies that infn≥1 Wn = lim sup Xn is measurable with
respect to T
k≥1 Ck = T.
(ii) We use arguments similar to those in (i) to prove that lim inf Xn is
measurable with respect to a tail sigma field T. By definition,
lim inf Xn = sup
n≥1
inf
k≥n
Xk = inf
n≥1
Vn, where Vn = inf
k≥n
Xk.
Note that if A ⊆ B, then inf(A) ≥ inf(B). Hence ∀ n ≥ 1
Vn = inf{Xn, Xn+1, Xn+2, · · · , } ≤ inf{Xn+1, Xn+2, · · · , } = Vn+1
⇒ {Vn, n ≥ 1} is a non-decreasing sequence.106 Random Variables and Random Vectors
Observe that Vn is a function of {Xn, Xn+1, · · · , } and hence it is mea￾surable with respect to Cn = σ{Xn, Xn+1, · · · }. Further, {Cn, n ≥ 1} is
a non-increasing sequence of sigma fields, hence Vn which is measurable
with respect to Cn is also measurable with respect to Ck, ∀ k ≤ n.
As a consequence, supn≥1 Vn is measurable with respect to C1, since
each Vn is measurable with respect to C1. Similarly, supn≥k Vn is mea￾surable with respect to Ck, since each Vn is measurable with respect
to Ck. Since {Vn, n ≥ 1} is a non-decreasing sequence, ∀ k ∈ N,
supn≥1 Vn = supn≥k Wn. Thus, supn≥1 Vn is measurable with respect
to Ck, ∀ k ∈ N implies that supn≥1 Vn = lim inf Xn is measurable with
respect to T
k≥1 Ck = T.
(iii) If lim Xn exists, then lim Xn = lim inf Xn = lim sup Xn and hence by (i)
and (ii) it follows that lim Xn is measurable with respect to T.
Remark 2.3.7. If {Xn, n ≥ 1} is a sequence of random variables on a mea￾surable space (Ω, A), then in Theorem 2.3.8, it is proved that lim inf Xn,
lim sup Xn and lim Xn, if it exists, are measurable with respect to A. In the
above Theorem 2.3.10, it is proved that these are measurable with respect to
a tail sigma field T. It suggests that there has to be a relation between the two
sigma fields A and T. Observe that the minimal sigma field σ({Xn, n ≥ 1}) in￾duced by the sequence {Xn, n ≥ 1} is such that σ({Xn, n ≥ 1}) ⊆ A. From the
definition of tail sigma field C1 = σ({Xn, n ≥ 1}). Thus, T ⊆ C1 ⊆ A. Thus,
Theorem 2.3.10 specifically conveys that lim inf Xn, lim sup Xn and lim Xn, if
it exists, are measurable with respect to a tail sigma field which is included
in A.
In Chapter 5 we study one important result related to the tail sigma field.
It is known as the Kolmogorov zero-one law, which states that if {Xn, n ≥ 1}
is a sequence of independent random variables then events in the tail sigma
field have probabilities either 0 or 1.
The last result in Theorem 2.3.8 which states that lim Xn, if it exists, is a
random variable plays important role, along with the results related to a simple
random variable in proving many results in probability theory. It will be clear
in the next section. As the nomenclature conveys, a simple random variable
is simple in its definition but is extremely useful in establishing number of
significant results which play key role in probability theory. The next section
is devoted to the theory concerned with a simple random variable.
2.4 Simple Random Variable
The class of simple random variables is obtained by taking linear combinations
of indicators of measurable sets. The definition of a simple random variable is
based on the concept of a measurable partition of Ω, as defined below.Simple Random Variable 107
Definition 2.4.1. Measurable partition: Suppose (Ω, A) is a measurable space
and P = {A1, A2, · · · , Ak} is a partition of Ω, that is, Sk
i=1 Ai = Ω and
Ai ∩ Aj = ∅ ∀ i ̸= j = 1, 2, · · · , k. P is said to be a measurable finite
partition of Ω, if Ai ∈ A, ∀ i = 1, 2, · · · , k. If P = {A1, A2, · · · , } is a
countably infinite partition of Ω such that Ai ∈ A, ∀ i ≥ 1, then P is said to
be a measurable countably infinite partition of Ω.
Definition 2.4.2. Simple random variable: Suppose a random variable X on
a measurable space (Ω, A) is defined as follows.
X(ω) = X
k
i=1
aiIAi
(ω) ⇐⇒ X(ω) = ai if ω ∈ Ai
, ai ∈ R, i = 1, 2, · · · , k,
where P = {A1, A2, · · · , Ak} is a measurable partition of Ω. Then X is known
as a simple random variable, measurable with respect to A.
If X is a simple random variable, then the sigma field X−1
(B) induced by
X is the sigma field generated by the partition P = {A1, A2, · · · , Ak} ⊂ A, as
illustrated in Example 1.4.2.
Definition 2.4.3. Elementary random variable: Suppose a random variable
X on a measurable space (Ω, A) is defined as follows.
X(ω) = X∞
i=1
aiIAi
(ω) ⇐⇒ X(ω) = ai if ω ∈ Ai
, ai ∈ R, i ≥ 1,
where P = {A1, A2, · · · , } is a measurable countably infinite partition of Ω.
Then X is known as an elementary random variable, measurable with respect
to A.
Example 2.4.1. Suppose Ω is defined as,
Ω = {ω = (ω1, ω2, · · · , ωn)| ωj = 0 or 1, j = 1, 2, · · · , n},
which is a sample space corresponding to a random experiment of tossing a
coin n times, where 1 corresponds to head and 0 corresponds to tail. If we are
interested in number of ones in each sample point ω, we define
Ai = {ω = (ω1, ω2, · · · , ωn)

Xn
j=1
ωj = i}, i = 0, 1, 2, · · · , n.
Suppose A = P(Ω), then Ai ∈ P(Ω), i = 0, 1, 2, · · · , n. Further, Ai ∩ Aj = ∅,
∀ i ̸= j, i, j = 0, 1, 2, · · · , n and Sn
i=0 Ai = Ω. Thus, {A0, A1, A2, · · · , An} is
a measurable partition of Ω. The number of sample points in Ai
is ￾n
i

,
i = 1, 2, · · · , n, since Ai a collection of outcomes corresponding to i heads in
n tosses. We define a random variable X on (Ω, A) as follows.
X(ω) = Xn
i=0
iIAi
(ω) ⇐⇒ X(ω) = i if ω ∈ Ai
, i = 0, 1, 2, · · · , n.
Thus, X is a simple random variable on (Ω, A). 108 Random Variables and Random Vectors
In the following theorem, we prove that a class of simple random variables
is closed under arithmetic operations.
Theorem 2.4.1. Suppose X1 and X2 are A measurable simple random vari￾ables defined on a measurable space (Ω, A) to (R, B). Then
(i) X1 + X2, X1 − X2, X1 × X2 and X1/X2, provided it is defined, are A
measurable simple random variables on the measurable space (Ω, A).
(ii) aX1 is a simple random variable on (Ω, A) to (R, B), where a ∈ R.
(iii) Suppose g : R → R is a function. Then g(X1) is a simple random variable
on (Ω, A) to (R, B).
(iv) Z = (X1, X2)
′
is a simple random vector on (Ω, A) to (R
2
, B
2
).
Proof. Suppose P1 = {A1, A2, · · · , Ak} and P2 = {B1, B2, · · · , Bl} are mea￾surable partitions of Ω and simple random variables X1 and X2 are defined
as,
X1(ω) = X
k
i=1
aiIAi
(ω) & X2(ω) = X
l
j=1
bj IBj
(ω)
Further, we define Cij = Ai ∩Bj , i = 1, 2, · · · , k and j = 1, 2, · · · , l. Then for
i ̸= r & j ̸= s Cij ∩ Crs = (Ai ∩ Bj ) ∩ (Ar ∩ Bs) = (Ai ∩ Ar) ∩ (Bj ∩ Bs) = ∅.
Similarly, even if i = r and j ̸= s or i ̸= r and j = s, then Cij ∩ Crs = ∅.
Thus,
Cij = Ai ∩ Bj , i = 1, 2, · · · , k and j = 1, 2, · · · , l are all disjoint sets. Further,
[
k
i=1
[
l
j=1
Cij =
[
k
i=1
[
l
j=1
(Ai ∩ Bj ) = [
k
i=1
 [
l
j=1
(Ai ∩ Bj )

=
[
k
i=1
(Ai ∩ Ω) = Ω.
Note that, Ai ∈ A and Bj ∈ A, hence Cij = Ai ∩ Bj ∈ A, i = 1, 2, · · · , k and
j = 1, 2, · · · , l. Thus, {Cij , i = 1, 2, · · · , k, j = 1, 2, · · · , l} forms a measurable
partition of Ω. Observe that,
ω ∈ Cij ⇒ ω ∈ Ai & ω ∈ Bj ⇒ X1(ω) = ai
, & X2(ω) = bj
⇒ X1(ω) ± X2(ω) = ai ± bi
, X1(ω) × X2(ω) = ai × bj
&X1(ω)/X2(ω) = ai/bj
⇒ X1 ± X2 =
X
k
i=1
X
l
j=1
(ai ± bj )ICij , X1 × X2 =
X
k
i=1
X
l
j=1
(ai × bj )ICij
X1/X2 =
X
k
i=1
X
l
j=1
(ai/bj )ICij & Z(ω) = (X1(ω), X2(ω))′ = (ai
, bj )
′
.
Note that X1/X2 is defined if bj ̸= 0 for any j. Hence, X1 + X2, X1 − X2,
X1 × X2 and X1/X2, provided it is defined, are A measurable simple random
variables on the measurable space (Ω, A).Simple Random Variable 109
(ii) aX1 is a simple random variable follows from the fact that X1 × X2 is
a simple random variable in a particular case of X2 ≡ a.
(iii) Note that
X1(ω) = X
k
i=1
aiIAi
(ω) ⇒ g(X1)(ω) = g(X1(ω)) = X
k
i=1
g(ai)IAi
(ω),
that is, g(X1)(ω) = g(ai) if ai ∈ Ai
, i = 1, 2, · · · , k. Hence, g(X) is a simple
random variable on (Ω, A) to (R, B).
(iv) Observe that Z can be expressed as Z =
Pk
i=1
Pl
j=1(ai
, bj )
′
ICij and
hence it is a A measurable simple random vector. Thus, if the components
of a random vector are simple random variables, then the random vector is a
simple random vector.
Following theorem is related to an important result which states that any
random variable can be represented as a limit of a sequence of simple random
variables. The idea of the proof is similar to the idea of Riemann sum for
approximating a Riemann integral. It involves the following steps. (i) We use
the fact that a sequence of intervals {(−n, n], n ≥ 1} converges to R as n → ∞.
Hence it is enough to worry about the values of Xn and X being close to each
other when X(ω) ∈ (−n, n]. As n → ∞, they will be close to each other on
almost entire R. (ii) We partition the interval (−n, n] into intervals of length
1/2
n or in general 1/δn for any δ = 2, 3, 4, · · · . If X(ω) belongs to one of
these intervals, then Xn(ω) is defined as upper end point of that interval.
Thus, the distance between Xn(ω) and X(ω) is less than 1/2
n. Consequently
as n → ∞, the intervals become smaller and the distance between Xn(ω) and
X(ω) decreases to 0 leading to convergence.
Theorem 2.4.2. Suppose X is a A measurable random variable defined on a
measurable space (Ω, A) to (R, B). Then there exists a sequence {Xn, n ≥ 1}
of A measurable simple random variables on a measurable space (Ω, A) such
that Xn → X on Ω as n → ∞.
Proof. It is given that X is a A measurable random variable on (Ω, A) to
(R, B), hence ∀ S ∈ B, X−1
(S) ∈ A. In particular,
T1 = (−∞, −n], T2 = (n, ∞) & Sk = (k/2
n
,(k + 1)/2
n
],
⇒ B1 = X−1
(T1), B2 = X−1
(T2) & Ak = X−1
(Sk) ∈ A,
k = −n2
n, −n2
n+1, · · · , n2
n−1. Note that T1, T2 and Sk, k = −n2
n, −n2
n+
1, · · · , n2
n−1 are disjoint subsets of R, hence by Lemma 2.2.1, B1 = X−1
(T1),110 Random Variables and Random Vectors
B2 = X−1
(T2) and Ak = X−1
(Sk) for all k are also disjoint sets in A. Further,
T1
[ n2
[
n−1
k=−n2n
Sk
[
T2 = R
⇒ X−1

T1
[
(
n2
[
n−1
k=−n2n
Sk)
[
T2

= X−1
(R)
⇒ X−1
(T1)
[
X−1
 n2
[
n−1
k=−n2n
Sk
![
X−1
(T2) = Ω
⇒ B1
[ n2
[
n−1
k=−n2n
Ak
[
B2 = Ω.
Thus, P = {B1, B2, Ak, k = −n2
n, −n2
n + 1, · · · , n2
n − 1} is a measurable
partition of Ω. Suppose a function Xn(ω) on (Ω, A) is defined as follows.
Xn(ω) = −n IB1
(ω) +
n2
Xn−1
k=−n2n
((k + 1)/2
n
) IAk
(ω) + n IB2
(ω) (2.16)
that is,
Xn(ω) =



−n, if X(ω) ∈ (−∞, −n] ⇐⇒ ω ∈ B1,
(k + 1)/2
n, if X(ω) ∈ (k/2
n,(k + 1)/2
n] ⇐⇒ ω ∈ Ak,
k = −n2
n, −n2
n + 1, · · · , n2
n − 1,
n, if X(ω) ∈ (n, ∞) ⇐⇒ ω ∈ B2.
By Definition 2.4.2, it is clear that Xn as defined in Equation (2.16) is a simple
random variable on a measurable space (Ω, A). To prove that Xn → X on Ω,
observe that ∀ ω ∈ Ω, X(ω) ∈ R ⇒ ∃ n1(ω) such that ∀ n ≥ n1(ω),
|X(ω)| < n. Further, given ϵ > 0, ∃ n2(ϵ) such that ∀ n ≥ n2(ϵ), 1/2
n < ϵ.
If N(ω, ϵ) is defined as N(ω, ϵ) = max{n1(ω), n2(ϵ)}, then
∀ n ≥ N(ω, ϵ), |X(ω)| < n and 1/2
n < ϵ, ∀ ω ∈ Ω.
Since |X(ω)| < n, X(ω) is in one of the intervals of the type
(k/2
n,(k + 1)/2
n], each having length 1/2
n, thus if X(ω) ∈ (k/2
n,(k+1)/2
n],
then Xn(ω) = (k + 1)/2
n, and the difference |Xn(ω) − X(ω)| < 1/2
n. Thus,
∀ ω ∈ Ω, given ϵ > 0, ∃ N(ω, ϵ) such that ∀ n ≥ N(ω, ϵ), |Xn(ω)−X(ω)| <
1/2
n < ϵ. Hence, Xn → X on Ω.
We illustrate below Theorem 2.4.2 for X(ω) = ω
3
for ω ∈ [−2, 2]. Note that
X(ω) ∈ [−8, 8]. We define a simple random variable Xn as defined in Theorem
2.4.2. For example, X2(ω) = −2 if X(ω) ≤ −2 ⇐⇒ ω ≤ (−2)(1/3) = −0.7937Simple Random Variable 111
and X2(ω) = 2 if X(ω) > 2 ⇐⇒ ω > 2
(1/3) = 0.7937. When X(ω) ∈
(−2, 2] ⇐⇒ ω ∈ (−0.7937, 0.7937], we partition the interval (−2, 2] into 16
intervals, each of length (1/4) and define Xn as the upper boundary of the
interval. We use Code 2.4.1 to draw the graph of X and impose on it graphs
of Xn for n = 1, 2, 3, 5, 10.
Code 2.4.1. a=-2; b=2; omega=seq(from=a,to=b,length=1000)
Xom=omega^3; nvec=c(1,2,3,5,10)
Xnom=matrix(nrow=length(omega),ncol=length(nvec))
for(j in 1:length(nvec))
{
n=nvec[j]
for(i in 1:length(omega))
{
if(Xom[i]<= -n) Xnom[i,j]=-n
if(Xom[i]> n) Xnom[i,j]=n
if(abs(Xom[i])<n)
{
k1=ceiling(Xom[i]*(2^n))
Xnom[i,j]=k1/(2^n)
}
}
}
plot(omega,Xom,lwd=3,type="l",xlab=expression(omega),
ylab=expression(X(omega)),ylim=c(-8,8),xaxt="n",
main=expression(X(omega)==omega^3))
omlab1=-round((seq(2,0,by=-0.25))^(1/3),2)
omlab2=round((seq(0,2,by=0.25))^(1/3),2)
omlab=c(omlab1,omlab2)
axis(1,at=omlab,labels=omlab,las=2,cex.axis=0.7)
for(i in 1:length(nvec))
{
lines(omega,Xnom[,i],lwd=2,lty=i+1,col=i+1)
}
fomlab=(omlab)^3
arrows(x0=omlab,y0=-10,x1=omlab,y1=fomlab,col="black",lty=3,
length=0);T=paste("n",nvec,sep="=")
legend("topleft",legend=T,col=2:(length(nvec)+1),
lty=2:(length(nvec)+1),lwd=2,cex=1.2)112 Random Variables and Random Vectors
FIGURE 2.2
Visual Illustration of Theorem 2.4.2
From Figure 2.2, we note that as n increases, the graph of Xn approximates
graph of X. Note that for n = 10, graphs of X and Xn almost coincide, thus
the approximation is quite good even for n = 10. It is to be noted that the
support of X is a bounded interval and hence even for large n, while defining
Xn, one has to restrict to a set {ω|X(ω) ∈ [−a, a]}, where a = min{n, 8}. As
n increases, the partitions of the intervals become finer and finer and it leads
to the better approximation of X by Xn.
The next theorem is similar to Theorem 2.4.2, but we restrict to a non￾negative random variable X. As a consequence, the sequence of simple random
variables, whose limit is X, is non-decreasing and the simple random variables
are non-negative.
Theorem 2.4.3. Suppose X is a A measurable non-negative random vari￾able defined on a measurable space (Ω, A) to (R, B). Then there exists a non￾decreasing sequence {Xn, n ≥ 1} of A measurable non-negative simple random
variables on a measurable space (Ω, A) such that Xn → X on Ω.
Proof. It is given that X is a non-negative random variable on a measurable
space (Ω, A) to (R, B), hence ∀ ω ∈ Ω, X(ω) ≥ 0. Since X is A measurable,Simple Random Variable 113
∀ S ∈ B, X−1
(S) ∈ A. In particular, if Sk = [k/2
n,(k + 1)/2
n), k =
0, 1, · · · , n2
n−1 and S = [n, ∞) then Ak = X−1
(Sk), k = 0, 1, · · · , n2
n−1 and
A = X−1
(S) are in A. Note that Sk, k = 0, 1, · · · , n2
n − 1 and S are disjoint
subsets of R
+, hence by Lemma 2.2.1, Ak = X−1
(Sk), k = 0, 1, · · · , n2
n − 1
and A = X−1
(S) are also disjoint sets in A. As in Theorem 2.4.2,
 n2
[
n−1
k=0
Sk
![
S = R
+ ⇒ X−1
 
(
n2
[
n−1
k=0
Sk)
[
S
!
= X−1
(R
+)
⇒
 n2
[
n−1
k=0
Ak
![
A = Ω.
Thus, P = {A, Ak, k = 0, 1, · · · , n2
n − 1} is a measurable partition of Ω.
Suppose a function Xn(ω) on (Ω, A) is defined as follows.
Xn(ω) =
n2
Xn−1
k=0
(k/2
n
)IAk
(ω) + nIA(ω) (2.17)
that is,
Xn(ω) =



(k/2
n), if ω ∈ Ak, ⇐⇒ X(ω) ∈ [k/2
n,(k + 1)/2
n),
k = 0, 1, · · · , n2
n − 1,
n, if ω ∈ A ⇐⇒ X(ω) ≥ n.
Then Xn as defined in Equation (2.17) is a non-negative simple random vari￾able on (Ω, A). To prove that Xn → X on Ω, observe that, ∀ ω ∈ Ω, X(ω) ∈
R
+ implies that ∃ n1(ω) such that ∀ n ≥ n1(ω), X(ω) < n. Further, given
ϵ > 0, ∃ n2(ϵ) such that ∀ n ≥ n2(ϵ), 1/2
n < ϵ. If N(ω, ϵ) is defined as
N(ω, ϵ) = max{n1(ω), n2(ϵ)}, then
∀ n ≥ N(ω, ϵ), X(ω) < n ∀ ω ∈ Ω and 1/2
n < ϵ.
Since, X(ω) < n, X(ω) is in one of the intervals of the type h
k/2
n,(k+1)/2
n

,
each having length 1/2
n, thus if X(ω) ∈ [k/2
n,(k + 1)/2
n), then Xn(ω) =
k/2
n, and the difference |Xn(ω) − X(ω)| < 1/2
n. Thus, ∀ ω ∈ Ω, given
ϵ > 0, ∃ N(ω, ϵ) such that ∀ n ≥ N(ω, ϵ), |Xn(ω) − X(ω)| < 1/2
n < ϵ.
Hence, Xn → X on Ω. Now to prove that {Xn, n ≥ 1} is a non-decreasing
sequence, we have to show that Xn(ω) ≤ Xn+1(ω), ∀ n ≥ 1 and ∀ ω ∈ Ω.
We partition Ω in three sets, as [X ≥ n + 1], [n ≤ X < n + 1) and [X < n],
as the definitions of Xn+1(ω) and Xn(ω) differ on these three sets. We have,
Xn+1(ω) =



k/2
n+1
, if X(ω) ∈

k/2
n+1
,(k + 1)/2
n+1
,
k = 0, 1, · · · ,(n + 1)2n+1 − 1,
n + 1, if X(ω) ∈ [n + 1, ∞).114 Random Variables and Random Vectors
Case(i) [X ≥ n+1]: On this partition set, by definition of Xn(ω) and Xn+1(ω),
Xn+1(ω) = n + 1 > n = Xn(ω) ⇒ Xn(ω) < Xn+1(ω), ∀ n ≥ 1.
Case(ii) [n ≤ X < n + 1]: On this partition set, by definition Xn(ω) = n. To
find the values of Xn+1(ω), we divide the interval [n, n + 1) in 2
n+1 intervals,
each of length 1/2
n+1. By definition of Xn+1(ω), on this partition set, for
k = n2
n+1, n2
n+1 + 1, · · · ,(n + 1)2n+1 − 1 we have,
Xn+1(ω) = k/2
n+1
, if X(ω) ∈

k/2
n+1
,(k + 1)/2
n+1
.
Thus, values of Xn+1(ω) are 
n, n + 1/2
n+1, n + 2/2
n+1
, · · · , n + 1 − 1/2
n+1	
and hence on the partition set [n ≤ X < n+ 1], Xn(ω) ≤ Xn+1(ω), ∀ n ≥ 1.
Case(iii) [X < n]: In this case, Xn(ω) = k/2
n if ω ∈ Ak, k = 0, · · · , n2
n−1. To
find the values of Xn+1(ω), for each k we divide the interval [k/2
n,(k + 1)/2
n)
in two equal parts as,
[k/2
n
,(k + 1)/2
n
) = 
2k/2
n+1
, 2k/2
n+1 + 1/2
n+1
∪

2k/2
n+1 + 1/2
n+1
, 2k/2
n+1 + 2/2
n+1
= I1 ∪ I2.
Note that if X(ω) ∈ [k/2
n,(k + 1)/2
n), then X(ω) ∈ I1 or X(ω) ∈ I2. Further,
X(ω) ∈ I1 ⇒ Xn+1(ω) = k/2
n & X(ω) ∈ I2 ⇒ Xn+1(ω) = k/2
n+1/2
n+1
.
Thus, on the set [X < n], Xn(ω) = k/2
n ≤ Xn+1(ω), ∀ n ≥ 1. Hence, it is
proved that {Xn, n ≥ 1} is a non-decreasing sequence of non-negative simple
random variables.
Theorem 2.4.3 is visually demonstrated below for X(ω) = log(ω) for ω ∈
[1, 8]. Note that X(ω) ∈ [0, 2.0794] and it is a non-negative random variable.
We define a simple random variable Xn as defined in Theorem 2.4.3. For
example, X2(ω) = 2 if X(ω) ≥ 2 ⇐⇒ ω ≥ exp(2) = 7.39. When X(ω) ∈
[0, 2) ⇐⇒ ω ∈ [1, 7.39), then we partition the interval [0, 2) into 16 intervals,
each of length (1/4) and define Xn as the lower boundary of the interval. We
use Code 2.4.2 to draw the graph of X and impose on it graphs of Xn for
n = 1, 2, 3, 5, 10.
Code 2.4.2. a=1; b=8; omega=seq(from=a,to=b,length=1000)
Xom=log(omega); nvec=c(1,2,3,5,10)
Xnom=matrix(nrow=length(omega),ncol=length(nvec))
for(j in 1:length(nvec))
{
n=nvec[j]
for(i in 1:length(omega))
{Simple Random Variable 115
if(Xom[i]> n) Xnom[i,j]=n
if(abs(Xom[i])<n)
{
k1=floor(Xom[i]*(2^n))
Xnom[i,j]=k1/(2^n)
}
}
}
plot(omega,Xom,lwd=3,type="l",xlab=expression(omega),xaxt="n",
ylab=expression(X(omega)),main=expression(X(omega)==log(omega)))
omlab=round(exp(seq(0,2,by=0.25)),2)
axis(1,at=omlab,labels=omlab,las=2,cex.axis=0.7)
for(i in 1:length(nvec))
{
lines(omega,Xnom[,i],lwd=2,lty=i+1,col=i+1)
}
fomlab=log(omlab)
arrows(x0=omlab,y0=0,x1=omlab,y1=fomlab,col="black",lty=3,
length=0); T=paste("n",nvec,sep="=")
legend("topleft",legend=T,col=2:(length(nvec)+1),
lty=2:(length(nvec)+1),lwd=2,cex=1.2)
From Figure 2.3, we note that as n increases, the graph of Xn approxi￾mates graph of X, with good approximation for n = 10. Further observe that
X1(ω) ≤ X2(ω) ≤ X3(ω) ≤ X5(ω) ≤ X10(ω) displaying the non-decreasing
nature of {Xn, n ≥ 1} as proved in Theorem 2.4.3. In Figure 2.2, {Xn, n ≥ 1}
is not non-decreasing. As noted in illustration of Theorem 2.4.2, in this case
also the support of X is a bounded interval and hence for large n, while defin￾ing Xn, one has to restrict to a set {ω|X(ω) ∈ [0, a]}, where a = min{n, 2}.
As n increases, the partitions of the intervals become finer and finer which
leads to the better approximation of X by Xn.
Theorem 2.4.2 and Theorem 2.4.3 are two widely used results in probability
theory. Both the theorems convey that a random variable can be constructed
as a limit of a sequence of simple random variables, hence these two theorems
are referred to as constructive definitions of a random variable. Theorem 2.4.2
is useful to prove that a continuous function of a random variable is again a
random variable and secondly the class of random variables is closed under
arithmetic operations. Theorem 2.4.3 plays a fundamental role in the definition
of expectation of a random variable as a Lebesgue integral. We first define the
expectation of a simple random variable, then use Theorem 2.4.3 to define it
for the non-negative random variable. and then extend the definition for an
arbitrary random variable. It is discussed in Chapter 4.116 Random Variables and Random Vectors
FIGURE 2.3
Visual Illustration of Theorem 2.4.3
Remark 2.4.1. Theorem 2.4.3 states that if X is non-negative A measurable
function on the measurable space (Ω, A), then there exists a non-decreasing
sequence {Xn, n ≥ 1} of non-negative simple A measurable functions on a
measurable space (Ω, A), such that Xn → X on Ω. Using similar arguments it
can be proved that if g is non-negative Borel function on the measurable space
(R, B), then there exists a non-decreasing sequence {gn, n ≥ 1} of non-negative
simple Borel functions on a measurable space (R, B), such that gn → g on R.
We need the result in Chapter 4 to derive a formula for E(g(X)), as an integral
with respect to the induced probability measure.
From Theorem 2.3.5, it follows that the class of random variables is closed
under arithmetic operations. We prove the same result below, using a different
method. It is based on Theorem 2.4.1 and Theorem 2.4.2.
Theorem 2.4.4. Suppose X1 and X2 are random variables defined on a mea￾surable space (Ω, A) to (R, B). Then
(i) X1 + X2, X1 − X2, X1 × X2 and X1/X2, provided it is defined, are
random variables on the measurable space (Ω, A).Simple Random Variable 117
(ii) aX1 is random variable on (Ω, A) to (R, B), where a is any real number.
Proof. If X1 and X2 are arbitrary random variables, then by Theorem 2.4.2,
there exist sequences {X1n, n ≥ 1} and {X2n, n ≥ 1} of simple random vari￾ables on a measurable space (Ω, A), such that X1n → X1 and X2n → X2 on
Ω. Since ∀ n ≥ 1, X1n and X2n are simple random variables, by Theorem
2.4.1 X1n ± X2n, X1n × X2n and X1n/X2n are also simple random variables.
Since X1n → X1 and X2n → X2 on Ω,
X1 ± X2 = lim(X1n ± X2n), X1 × X2 = lim(X1n × X2n)
and X1/X2 = lim(X1n/X2n).
We have proved in Theorem 2.3.8, that limit of a sequence of random variables
is also a random variable. Hence, X1 + X2, X1 − X2, X1 × X2 and X1/X2 are
random variables on the measurable space (Ω, A). (ii) aX1 is a random variable
follows from the fact that X1 × X2 is a random variable when X2 ≡ a.
With any random variable X defined on (Ω, A) to (R, B), we associate
two non-negative random variables, known as a positive part and a negative
part. A positive part X+ and a negative part X− of a random variable X are
defined as,
X+ = X I[X≥0] = max{X, 0} & X− = −X I[X<0] = max{−X, 0}.
Thus, X+ =

X, if X ≥ 0
0, if X < 0
& X− =

−X, if X ≤ 0
0, if X > 0.
Note that X−, although known as a negative part, is a non-negative ran￾dom variable. An arbitrary random variable X can be expressed as X =
X+ − X−. Using Theorem 2.4.4, we prove that X+ and X− are random
variables.
Theorem 2.4.5. Suppose X is a random variable defined on a measurable
space (Ω, A) to (R, B). Then X+, X− and |X| are random variables on a
measurable space (Ω, A).
Proof. Note that for X defined on (Ω, A), [X ≥ 0] = X−1
([0, ∞)) ∈ A
and [X < 0] = X−1
((−∞, 0)) ∈ A. Hence, as shown in Example 2.2.3,
I[X≥0] and I[X<0] are random variables on (Ω, A). Thus, by Theorem 2.4.4,
X+ = X I[X≥0] and X− = −X I[X<0] are random variables on (Ω, A), being
product of two random variables. If we use the definition of X+ and X− as
X+ = max{X, 0} and X− = max{−X, 0}, then we have one more ap￾proach to prove that X+ and X− are random variables. In Theorem 2.3.8, it
is proved that maximum of two random variables is again a random variable.
Further, Y ≡ 0 is a random variable with respect to any sigma field, hence,
X+ = max{X, 0} & X− = max{−X, 0}118 Random Variables and Random Vectors
are random variables on the same space on which X is defined. Observe that
|X| can be expressed as |X| = X+ + X− and hence again by Theorem 2.4.4,
it is a random variable on (Ω, A), being addition of two random variables.
In the next three theorems, we prove that a continuous function of a ran￾dom variable is a random variable and a continuous function is a Borel func￾tion. Theorem 2.4.2 is used heavily.
Following theorem proves that measurability remains invariant under con￾tinuous transformations.
Theorem 2.4.6. Suppose X is a A measurable random variable defined on a
measurable space (Ω, A) to (R, B). Suppose g : R → R is a continuous function.
Then g(X) is a A measurable random variable on (Ω, A) to (R, B).
Proof. Suppose {an, n ≥ 1} is a sequence of real numbers such that an → a as
n → ∞. Then continuity of g implies that g(an) → g(a) as n → ∞. Since X
is a random variable on a measurable space (Ω, A), by Theorem 2.4.2, there
exists a sequence {Xn, n ≥ 1} of simple random variables on a measurable
space (Ω, A) such that Xn(ω) → X(ω) ∀ ω ∈ Ω. Hence, by continuity of g,
g(Xn(ω)) → g(X(ω)) ⇐⇒ g(Xn)(ω) → g(X)(ω) ∀ ω ∈ Ω.
By (iii) of Theorem 2.4.1, {g(Xn), n ≥ 1} is a sequence of simple random
variable with pointwise limit g(X). Hence, by Theorem 2.3.8 which states
that a limit of a sequence of random variables is again a random variable, we
claim that g(X) is a random variable on (Ω, A).
Remark 2.4.2. In Theorem 2.2.3, it is proved that a Borel function of a
random variable is a random variable. Theorem 2.4.6, proved above, states
that a continuous function of a random variable is a random variable. Both
these results indicate that there has to be some connection between a Borel
function and a continuous function. It is indeed true and it is proved in the
following theorem that a continuous function is a Borel function.
Theorem 2.4.7. Suppose g : (R, B) → (R, B) is a continuous function. Then
g is a Borel function, that is, g is measurable with respect to B.
Proof. Theorem 2.4.6 states that a continuous function of a random vari￾able is again a random variable with respect to the same measurable space.
In particular, suppose X is defined on a measurable space (R, B) such that
X(ω) = ω, that is, X is an identity function. For the identity function, the
inverse image of any Borel set is the set itself, thus the identity function is a
Borel measurable function. Since g is a continuous function, by Theorem 2.4.6,
g(X)(ω) = g(X(ω)) = g(ω) is a Borel measurable function. Thus a continuous
function g on (R, B) is a Borel function.
Converse of Theorem 2.4.7 is not true, that is every Borel function need
not be continuous. Following are two illustrations.Simple Random Variable 119
Example 2.4.2. Suppose Q is a set of rational numbers and A = (−∞, 10).
Suppose functions g & h : (R, B) → (R, B) are defined as follows.
g(x) = 
0, if x ∈ A
1, if x ∈ Ac & h(x) = 
0, if x ∈ Qc
1, if x ∈ Q
The function h is known as the Dirichlet function. Note that for any Borel set
S, inverse images of S under g and h are given by,
g
−1
(S) =



∅, if 0, 1 ∈/ S
Ω, if 0, 1 ∈ S
A, if 0 ∈ S, 1 ∈/ S
Ac
, if 1 ∈ S, 0 ∈/ S,
& h
−1
(S) =



∅, if 0, 1 ∈/ S
Ω, if 0, 1 ∈ S
Qc
, if 0 ∈ S, 1 ∈/ S
Q, if 1 ∈ S, 0 ∈/ S,
Thus, g
−1
(S) & h
−1
(S) ∈ B, ∀ S ∈ B. Hence both are Borel functions, but
g is not continuous, x = 10 being a point of discontinuity and the Dirichlet
function h is nowhere continuous, refer to page 64 of Kumar and Kumaresan
[15]. □
Theorem 2.4.6 and 2.4.7 can be extended to a function g from R
k
to R
and a function g from R
k
to R
l
, l ≤ k and a random vector Z. It is proved in
the next theorem. The proof is on similar lines as that of Theorem 2.4.6 and
Theorem 2.4.7.
Theorem 2.4.8. Suppose Z = (X1, X2, · · · , Xk)
′
is a random vector defined
on a measurable space (Ω, A) to (R
k
, B
k
).
(i) Suppose g : R
k → R is a continuous function. Then g(Z) is a random
variable on (Ω, A) to (R, B) and g is a Borel function.
(ii) Suppose g : R
k → R
l
, l ≤ k is a continuous function. Then g(Z) is a
random vector on (Ω, A) to (R
l
, B
l
) and g is a Borel function.
Proof.
(i) Since Z = (X1, X2, · · · , Xk)
′
is a random vector on (Ω, A), each of
X1, X2, · · · , Xk are random variables on (Ω, A). Hence, by Theorem
2.4.2, there exists sequences {Xin, n ≥ 1} of simple random variables
on a measurable space (Ω, A) such that Xin(ω) → Xi(ω) ∀ ω ∈ Ω as
n → ∞, ∀ i = 1, 2, · · · , k. Suppose Zn = (X1n, X2n, · · · , Xkn)
′
, then
Zn → Z on Ω which further implies that g(Zn
) → g(Z) on Ω, in view
of continuity of g. In Theorem 2.4.1, it is proved that if components are
simple random variables, then the corresponding vector is also a simple
random vector. Suppose the simple random variable Xin is expressed as
Xin =
Xm
j=1
ainj
IAnj , i = 1, 2, · · · , k
⇒ Zn = (a1nj
, a2nj
, · · · , aknj
)
′
on Anj , j = 1, 2, · · · , m
⇒ g(Zn
) = g((a1nj
, a2nj
, · · · , aknj
)
′
) on Anj , j = 1, 2, · · · , m
⇒ ∀ n ≥ 1, g(Zn
) is a simple random variable,120 Random Variables and Random Vectors
measurable with respect to A. Thus, g(Z) is a limit of a sequence of A
measurable random variables and hence the required result that g(Z) is
a random variable on (Ω, A) follows from the fact that limit of A measur￾able random variable is again A measurable random variable. The result
that g is a Borel function follows by taking Z as an identity function on
(R
k
, B
k
) to (R
k
, B
k
) and using similar arguments as in Theorem 2.4.7.
(ii) g : R
k → R
l
is a continuous function hence, if g is expressed as
g(x1, · · · , xk) = (g1(x1, · · · , xk), g2(x1, · · · , xk), · · · , gl(x1, · · · , xk)),
then each of g1, g2, · · · , gl are continuous functions from R
k → R. Thus,
by (i) each of gi(Z), i = 1, 2, · · · , l is a random variable on (Ω, A) to
(R, B) and
g(Z) = (g1(Z), g2(Z), · · · , gl(Z))
is a random vector on (Ω, A) to (R
l
, B
l
) in view of the fact that compo￾nents are random variables on (Ω, A). g is a Borel function also follows
from the fact that each of g1, g2, · · · , gl
is a Borel function.
Remark 2.4.3. If Z = (X1, X2, · · · , Xk)
′
is a random vector on (Ω, A), then
as a consequence of the Theorem 2.4.8, U = a1X1 + a2X2 + · · · + akXk or
V = a1X1 ∗ a2X2 ∗ · · · ∗ akXk, where a1, a2, · · · , ak are any real numbers, are
random variables on (Ω, A), since U = g(Z) where g(x) = a1x1 + a2x2 + · · · +
akxk is a continuous function from R
k → R and V = g(Z) where g(x) =
a1x1 ∗ a2x2 ∗ · · · ∗ akxk is a continuous function from R
k → R.
Theorem 2.4.5 can be proved using Theorem 2.4.8, as shown below. Sup￾pose functions g
+ and g
− on (R, B) are defined as follows.
g
+(x) = 
x, if x ≥ 0
0, if x < 0
& g
−(x) = 
−x, if x ≤ 0
0, if x > 0.
It is clear that g
+ and g
− are continuous functions on R and hence are Borel
functions. Thus, X+ = g
+(X) and X− = g
−(X) are Borel functions of A
measurable random variable X and hence are A measurable random variables.
Similarly, |X| = X+ + X− = g(X+, X−), where g(x1, x2) = x1 + x2 is a
continuous and hence Borel function from R
2
to R and hence is a A measurable
random variable.
Having defined a random variable, a random vector and a sequence of
random variables, we now proceed in the next section to define a probability
measure associated with these.Probability Distribution of a Random Variable 121
2.5 Probability Distribution of a Random Variable
In Section 1.5, we have defined a probability measure on the measurable space
(Ω, A). We now discuss the probability measure associated with a random
variable X defined on the measurable space (Ω, A) to (R, B), measurable with
respect to A. Thus, ∀ S ∈ B, X−1
(S) = A ∈ A. Suppose (Ω, A, P) is a proba￾bility space. Then,
P(A) = P(X−1
(S)) = P{ω | X(ω) ∈ S} = P[X ∈ S] = PX(S), say.
The set function PX(S), related to P(A) in this way, is defined for every Borel
set S. Thus, PX(S) is defined on the measurable space (R, B). In the following
theorem, we verify that a set function PX(S) defined on (R, B) satisfies Kol￾mogorov’s three axioms and hence is a probability measure on the measurable
space (R, B).
Theorem 2.5.1. Suppose X is a random variable defined on a probability
space (Ω, A, P) to (R, B). A set function PX(S) defined on (R, B) as
PX(S) = P(X−1
(S)), for S ∈ B is a probability measure on the measurable
space (R, B).
Proof. A set function PX(S) = P(X−1
(S)) is a probability measure, if it
satisfies Kolmogorov’s three axioms as given in Definition 1.5.1. Suppose S ∈ B
is such that X−1
(S) = A ∈ A. Then
(i) PX(S) = P(X−1
(S)) = P(A) ≥ 0.
(ii) PX(R) = P(X−1
(R)) = P(Ω) = 1.
(iii) Suppose {Sn, n ≥ 1} is a sequence of disjoint Borel sets. Then
{X−1
(Sn), n ≥ 1} is also a sequence of disjoint sets in A, by Lemma
2.2.1. Now,
PX
X
n≥1
Sn

= P

X−1
(
X
n≥1
Sn)

= P
X
n≥1
X−1
(Sn)

,
by Lemma 2.2.1
. =
X
n≥1
P
￾
X−1
(Sn)

,
by σ-additivity of probability measure P
=
X
n≥1
PX(Sn).
Hence, PX(S) = P(X−1
(S)) is a probability measure on the measurable
space (R, B).
As a consequence of this theorem, we have the following definitions122 Random Variables and Random Vectors
Definition 2.5.1. Induced probability measure: A probability measure
PX(S) = P(X−1
(S)) on the measurable space (R, B) is known as an induced
probability measure, induced by a random variable X on (Ω, A, P).
Definition 2.5.2. Induced probability space: Suppose PX(S) = P(X−1
(S))
is a probability measure on the measurable space (R, B). Then the probability
space (R, B, PX) is known as an induced probability space, induced by a random
variable X.
Definition 2.5.3. Probability distribution of X: Suppose (R, B, PX) is an
induced probability space, induced by a random variable X. Then the collection
{PX(S), S ∈ B} is knows as a probability distribution of X.
Suppose X is a random variable defined on a probability space (Ω, A, P)
to (R, B, PX) and g is a Borel function. Then g(X) is also a random variable
on the probability space (Ω, A, P). The probability measure induced by g(X)
is given by,
Pg(X)(S) = P(g(X)
−1
(S)) = P((X−1
(g
−1
(S)))) = P((X−1
(Sg)))
= PX(Sg) = PX(g
−1
(S)), where Sg = g
−1
(S) ∈ B.
Thus, the probability distribution of any Borel function of X is determined
by that of X, which in turn is determined by the probability measure P on
(Ω, A). In summary, the knowledge of P is enough to find out the distribution
of any random variable defined on (Ω, A, P) and also of any Borel function of
X. Hence, (Ω, A, P) is known as a parent probability space or a fundamental
probability space.
Example 2.5.1. Suppose Ω corresponds to the outcome of a random exper￾iment of tossing an unbiased coin twice. Then the sample space Ω is given by
Ω = {HH, HT, T H, T T}. Suppose A = P(Ω). Since it is given that the coin is
unbiased, the probability of getting head is the same as that of tail and it is
1/2. Thus, for any A ∈ A, P(A) = m/4, where m is the number of elements
in A. Suppose a random variable X is defined as the number of heads in the
outcome. Thus,
X(ω) =



0, if ω = T T
1, if ω = T H, HT
2, if ω = HH.
Hence, for a Borel set S,
PX(S) =



0, if 0 ∈/ S, 1 ∈/ S, 2 ∈/ S
P({T T}) = 1/4, if 0 ∈ S, 1 ∈/ S, 2 ∈/ S
P({T H, HT}) = 2/4, if 0 ∈/ S, 1 ∈ S, 2 ∈/ S
P({HH}) = 1/4, if 0 ∈/ S, 1 ∈/ S, 2 ∈ S
P({T T, T H, HT} = 3/4, if 0 ∈ S, 1 ∈ S, 2 ∈/ S
P({T T, HH}) = 2/4, if 0 ∈ S, 1 ∈/ S, 2 ∈ S
P({T H, HT, HH}) = 3/4, if 0 ∈/ S, 1 ∈ S, 2 ∈ S
P(Ω) = 1, if 0 ∈ S, 1 ∈ S, 2 ∈ S.Probability Distribution of a Random Variable 123
This gives us the probability distribution {PX(S), S ∈ B} of X. It is usually
presented as follows.
P[X = 0] = 1/4, P[X = 1] = 1/2 & P[X = 2] = 1/4. □
Example 2.5.2. Suppose Ω is a sample space corresponding to a random
experiment of tossing a coin n times, independently of each other. For the
given random experiment the sample space Ω is given by,
{ω = (ω1, ω2, · · · , ωn)| ωj = 0 or 1, j = 1, 2, · · · , n} and suppose A = P(Ω).
A simple random variable X on (Ω, A) is defined as follows.
X(ω) = Xn
i=0
iIAi
(ω) ⇐⇒ X(ω) = i if ω ∈ Ai
, i = 0, 1, 2, · · · , n,
where Ai = {ω = (ω1, ω2, · · · , ωn)

Pn
j=1 ωj = i}, i = 0, 1, 2, · · · , n. It is given
that probability of a head is p and remains the same ∀ n. By the definition,
the probability distribution of X is given by {PX(S), S ∈ B}, however it is to
be noted that by the sigma additivity of the probability measure PX(.), it is
enough to specify the probability assigned to Ai ≡ [X = i] ∀ i = 1, 2, · · · , n.
Observe that there are ￾n
i

sample points in Ai and for each sample point in
Ai there are i heads and n − i tails. Hence
P(Ai) = P{ω|ω ∈ Ai} = P{ω|X(ω) = i} = P[X = i] = 
n
i

p
i
(i − p)
n−i
,
i = 0, 1, 2, · · · , n. Thus, the probability distribution {PX(S), S ∈ B} can be
specified as {P(Ai) = P[X = i] = ￾n
i

p
i
(i − p)
n−i}, i = 0, 1, 2, · · · , n. Note
that it is the well known binomial distribution. □
Probability distribution of a random vector Z is also defined on similar
lines as the collection {PZ(S), S ∈ B
k}, where PZ(S) = P(Z
−1
(S)).
Remark 2.5.1. In most of the practical situations, we are usually given the
induced probability space. Once it is given, it is not always necessary to have
the knowledge of the fundamental probability space (Ω, A, P), when we are
interested in studying the properties of the given random variables and their
Borel functions. However, in order to study the calculus of random variables
by introducing new random variables, such as limits of random variables,
it is necessary to have the knowledge of the fundamental probability space
(Ω, A, P).
A quick recap of the results discussed in the present chapter is given below.
Summary
1. Inverse image of a set: Suppose X : Ω1 → Ω2 is a function and S is a
subset of Ω2. Then the inverse image of a set S under the function X is
defined as X−1
(S) = {ω ∈ Ω1|X(ω) ∈ S124 Random Variables and Random Vectors
2. Properties of the inverse image of a set: (i) Inverse image of a complement is
a complement of the inverse image. (ii) Inverse image of a countable union
is a countable union of inverse images. (iii) Inverse image of a countable
intersection is a countable intersection of inverse images.
(iv) Inverse images of disjoint sets are also disjoint sets. (v) If S1 ⊆ S2,
then X−1
(S1) ⊆ X−1
(S2). If X−1
(S1) ⊆ X−1
(S2), then S1 ⊂ S2.
3. The inverse image of a collection C of subsets of Ω2 under the function X
is defined as, X−1
(C) = {X−1
(S)|S ∈ C}.
4. Suppose A is a sigma field of subsets of Ω1, then the class F of all sets
whose inverse images belong to A is also a sigma field.
5. Inverse image of a sigma field is a sigma field.
6. C1 ⊆ C2 ⇒ X−1
(C1) ⊆ X−1
(C2) and σ(X−1
(C1)) ⊆ σ(X−1
(C2)).
7. Inverse image of the minimal sigma field generated by a class is the minimal
sigma field of inverse image of the class, that is, X−1
(σ(C)) = σ(X−1
(C)).
8. Descriptive definition of a random variable: A function X : (Ω, A) → (R, B)
is said to a random variable or a measurable function with respect to A if
∀ S ∈ B, X−1
(S) ∈ A.
9. Economical definition of a random variable: Suppose X : (Ω, A) → (R, B)
is a function and C is a class of subsets of R such that the minimal sigma
field generated by C is the Borel field B. Then X is a random variable
measurable with respect to A if ∀ S ∈ C, X−1
(S) ∈ A.
10. Suppose X is a random variable defined on (Ω, A) to (R, B). Then
X−1
(B) = {X−1
(S)|S ∈ B} is a sigma field, being inverse image of a sigma
field. It is known as a sigma field induced by or generated by a random
variable X.
11. Borel function: Suppose g : (R, B) → (R, B) is a function. If ∀ S ∈ B,
g
−1
(S) = {x ∈ R|g(x) ∈ S} ∈ B, then g is measurable with respect to the
Borel field and is known as a Borel function.
12. Suppose g : (R, B) → (R, B) is a function. Suppose C is a class of subsets
of R such that the minimal sigma field generated by C is the Borel field
B. Then g is a Borel function if and only if ∀ S ∈ C, g−1
(S) ∈ B.
13. Suppose X : (Ω, A) → (R, B) is a random variable measurable with respect
to a sigma field A and g : (R, B) → (R, B) is a Borel function, then Y =
g(X) is a random variable measurable with respect to A and σ(Y ) ⊆ σ(X).
14. Descriptive definition of a k-variate random vector: Suppose
Z = (X1, X2, · · · , Xk)
′
is a function defined on the measurable space
(Ω, A) to (R
k
, B
k
), where B
k
is the Borel field of subsets of R
k
. If
∀ S ∈ B
k
, Z−1
(S) = {ω | Z(ω) = (X1(ω), X2(ω), · · · , Xk(ω))′ ∈ S} ∈ A,
then Z is a random vector measurable with respect to A.Probability Distribution of a Random Variable 125
15. Economical definition of a k-variate random vector: Suppose
Z = (X1, X2, · · · , Xk)
′
is a function defined on the measurable space
(Ω, A) to (R
k
, B
k
). Suppose C
k
is a class of subsets of R
k which gener￾ates the Borel field B
k
. If
∀ S ∈ C
k
, Z−1
(S) = {ω | Z(ω) = (X1(ω), X2(ω), · · · , Xk(ω))′ ∈ S} ∈ A,
then Z is a random vector measurable with respect to A.
16. Suppose Z = (X1, X2, · · · , Xk)
′
is a random vector defined on a measur￾able space (Ω, A) to (R
k
, B
k
). Then σ(Z) = Z
−1
(B
k
) = σ
 Sk
i=1 X
−1
i
(B)

.
17. Z = (X1, X2, · · · , Xk)
′
is a random vector measurable with respect to A
if and only if each of Xi
, i = 1, 2, · · · , k is random variable measurable
with respect to A.
18. Suppose g : (R
k
, B
k
) → (R
l
, B
l
) l ≤ k is a function where g =
(g1, g2, · · · , gl). g is a Borel function if ∀ S ∈ B
l
, g−1
(S) ∈ B
k
.
19. Suppose g : (R
k
, B
k
) → (R
l
, B
l
) l ≤ k is a function where g =
(g1, g2, · · · , gl). g is a Borel function if and only if each of gi
is a Borel
function from (R
k
, B
k
) → (R, B), i = 1, 2, · · · , l.
20. Suppose Z : (Ω, A) → (R
k
, B
k
) is a random vector measurable with re￾spect to the sigma field A. (i) Suppose g : (R
k
, B
k
) → (R, B) is a Borel func￾tion, then Y = g(Z) is a random variable measurable with respect to the
sigma field A and σ(Y ) ⊆ σ(X). (ii) Suppose g : (R
k
, B
k
) → (R
l
, B
l
), l ≤ k
is a Borel function, then Y = g(Z) is a random vector measurable with
respect to the sigma field A and σ(Y ) ⊆ σ(Z).
21. Borel field in infinite dimensions: Suppose C∞ is a collection of cylinder
sets S defined as
S ={x = (x1, x2, · · · ,)|aij ≤ xij ≤ bij
, j = 1, · · · , k, xij ∈ R, j = k+1, · · · },
where i1, i2, · · ·ik is any permutation of positive integers and k is finite.
Then the minimal sigma field induced by C∞ is the Borel field in infinite
dimensions and is denoted by B∞.
22. Infinite dimensional random vector: A function Z = (X1, X2, · · · ,) de￾fined on (Ω, A) to (R∞, B∞) is an infinite dimensional random vector if
∀ S ∈ B∞, Z
−1
(S) ∈ A.
23. For an infinite dimensional random vector Z = (X1, X2, · · · ,),
Z
−1
(B
∞) = σ

{Xn, n ≥ 1}

= σ(
[
n≥1
An)
where An = σ{X1, · · · , Xn} = σ
 Sn
i=1(X
−1
i
(B))
.126 Random Variables and Random Vectors
24. Suppose Z = (X1, X2, · · · ,) is defined on the measurable space (Ω, A) to
(R∞, B∞). Then Z is an infinite dimensional random vector if and only if
for every n ≥ 1, Xn is a random variable with respect to A.
25. For a sequence {Xn, n ≥ 1} of random variables
lim inf Xn = sup
n≥1
inf
k≥n
Xk & lim sup Xn = inf
n≥1
sup
k≥n
Xk .
If lim inf Xn(ω) = lim sup Xn(ω) = X(ω), ∀ ω ∈ Ω, then limn→∞ Xn,
exists and limn→∞ Xn = X. This mode of convergence of a sequence of
random variables is known as a point-wise convergence or convergence
everywhere.
26. If for each n ≥ 1, Xn is a random variable measurable with respect to A,
then lim inf Xn and lim sup Xn, and lim Xn, whenever exists, are random
variables measurable with respect to A.
27. Suppose {Xn, n ≥ 1} is a sequence of random variables and
Cn = σ{Xn, Xn+1, · · · }. Then T =
T
n≥1 Cn is known as a tail sigma field
of the sequence {Xn, n ≥ 1} and sets in T are known as tail events.
28. Suppose a random variable X on a measurable space (Ω, A) is defined as
follows.
X(ω) = X
k
i=1
aiIAi
(ω) ⇐⇒ X(ω) = ai
if ω ∈ Ai
, ai ∈ R, i = 1, 2, · · · , k
where P = {A1, A2, · · · , Ak} is a measurable partition of Ω. Then X is
known as a simple random variable.
29. Suppose X is a random variable defined on a measurable space (Ω, A)
to (R, B). Then there exists a sequence {Xn, n ≥ 1} of simple random
variables on a measurable space (Ω, A) such that Xn → X on Ω as n → ∞.
30. Suppose X is a non-negative random variable defined on a measurable
space (Ω, A) to (R, B). Then there exists a non-decreasing sequence
{Xn, n ≥ 1} of non-negative simple random variables on a measurable
space (Ω, A) such that Xn → X on Ω.
31. Suppose X is a simple random variable defined on a measurable space
(Ω, A) to (R, B). Suppose g : R → R is a function. Then g(X) is a simple
random variable on (Ω, A) to (R, B).
32. Suppose X is a random variable defined on a measurable space (Ω, A)
to (R, B). Suppose g : R → R is a continuous function. Then g(X) is a
random variable on (Ω, A) to (R, B).
33. Suppose g : (R, B) → (R, B) is a continuous function. Then g is a Borel
function.Conceptual Exercises 127
34. Suppose Z = (X1, X2, · · · , Xk)
′
is a random vector defined on a measur￾able space (Ω, A) to (R
k
, B
k
). (i) Suppose g : R
k → R is a continuous
function. Then g(Z) is a random variable on (Ω, A) to (R, B) and g is a
Borel function. (ii) Suppose g : R
k → R
l
, l ≤ k is a continuous func￾tion. Then g(Z) is a random vector on (Ω, A) to (R
l
, B
l
) and g is a Borel
function.
35. Suppose X1 and X2 are random variables defined on a measurable space
(Ω, A) to (R, B). Then (i) X1 + X2, X1 − X2, X1X2 and X1/X2, provided
it is defined, are random variables on the measurable space (Ω, A).
(ii) aX1 is random variable on (Ω, A) to (R, B), where a is any real number.
36. Suppose X is a random variable defined on a measurable space (Ω, A)
to (R, B). Then X+, X− and |X| are random variables on a measurable
space (Ω, A).
37. Suppose X is a random variable defined on a probability space (Ω, A, P)
to (R, B). A set function PX(S) defined on (R, B) as PX(S) = P(X−1
(S)),
for S ∈ B is a probability measure on the measurable space (R, B). It is
known as an induced probability measure, induced by X.
38. The probability space (R, B, PX) is known as an induced probability space.
39. {PX(S), S ∈ B} is known as a probability distribution of X.
2.6 Conceptual Exercises
2.6.1 Suppose Ω is a sample space corresponding to the experiment of rolling
a die once. Suppose A = {Ω, ∅, {1, 3, 5}, {2, 4, 6}}. Define two functions
on (Ω, A) such that one is a random variable on (Ω, A) and the other is
not a random variable on (Ω, A).
2.6.2 Suppose Ω = (0, 1] and A is a minimal sigma field consisting of all
Borel sets which are subsets of Ω. Examine whether a function X(ω) =
6ω + 2 is a random variable on (Ω, A). (i) Use the economical definition.
(ii) Use the result that a Borel function of a random variable is a random
variable.
2.6.3 Suppose X is a random variable, measurable with respect to A. Examine
whether (i) Y1 = e
X and Y2 = e
X + X3 + 5X are random variables,
measurable with respect to A. (ii) If X is a positive random variable
measurable with respect to A, examine whether Y3 = log X is a random
variable. Is Z = (Y1, Y2, Y3)
′ a random vector measurable with respect
to A? Justify.128 Random Variables and Random Vectors
2.6.4 (i) Suppose A and B are mutually exclusive events. Find the minimal
sigma field induced by IA + IB. (ii) Suppose A and B are not mutually
exclusive events. Find the minimal sigma field induced by IA + IB.
2.6.5 Suppose Ω = {a, b, c} and A = {Ω, ∅, {a}, {b, c}}. Examine whether A is
a sigma field. If yes, specify any non-constant function on (Ω, A) which
is measurable with respect to A.
2.6.6 Suppose X and Y are random variables on (Ω, A, P) such that σ(X) =
σ(Y ). Show that σ(X + Y ) ⊆ σ(Y ).
2.6.7 Suppose X is a random variable. Show that σ(X2
) ⊆ σ(X).
2.6.8 Give an example of a random variable such that σ(X2
) ̸= σ(X).
2.6.9 Give an example of a random variable such that σ(X2
) = σ(X).
2.6.10 Suppose Ω = {1, 2, 3, 4}, A = {1, 2} and A = {Ω, ∅, A, Ac}. Functions
X, Y and Z on (Ω, A) are defined as follows. X(ω) = 4 ∀ ω ∈ Ω,
Y (ω) = 1 if ω ∈ A and 0 otherwise and Z(ω) = ω ∀ ω ∈ Ω. Examine
whether Z = (X, Y, Z) is random vector on (Ω, A). If not, modify A,
so that Z = (X, Y, W) is random vector on (Ω, A). Find the sigma field
induced by Z.
2.6.11 Suppose Ω = N, the set of natural numbers, and A = P(N), power
set of N. Construct one finite and one countably infinite measurable
partition of Ω. Give an example of one simple random variable and one
elementary random variable defined on (N, P(N)).
2.6.12 Prove or disprove: X−1
(lim Sn) = lim X−1
(Sn), where Sn is a Borel
set.
2.6.13 Show that a necessary and sufficient condition for a function to be
measurable is that its positive and negative parts are measurable.
2.6.14 Suppose f and g are Borel functions on (R, B). For A ∈ B, a function
h is defined as h = f on A and h = g on Ac
. Show that h is a Borel
function.
2.6.15 Suppose |X| is A measurable. Examine whether X+ and X− are also
A) measurable.
2.6.16 Suppose (X1, X2, · · · , Xn) is a random vector on (Ω, A, P). Show that
(i) Pn
i=1 liXi
is real valued random variable where l1, l2, · · · , ln are any
real numbers, (ii) (sin X1, X2, X3, · · · , eXn−1
, |Xn|) is a random vector
and (iii) (X2, X3, · · · , Xn−1) is a random vector, all defined on the same
probability space (Ω, A, P).Computational Exercises 129
2.6.17 Suppose a measurable space (Ω, A) is defined as Ω = [0, ∞) and A is
a sigma field of subsets of Ω. Suppose a sequence {Xn, n ≥ 1} of A
measurable random variables and a A measurable random variable X
are defined as follows.
Xn(ω) = exp(−nω), n ≥ 1 & X(ω) = 0 ∀ ω ∈ Ω.
(i) Examine if Xn → X on Ω or any subset of Ω. (ii) If not, identify
another X such that Xn → X on Ω.
2.6.18 Suppose a random variable X is defined on (Ω, A, P) and X ∼ N(0, 1)
distribution. Suppose An = [X ≤ 1/n]. Find limn→∞ P(An).
2.6.19 Suppose a random variable X is defined on (Ω, A, P) and X ∼ χ
2
5 and
An = [X ≤ 1/n]. Find limn→∞ P(An).
2.6.20 Suppose a random variable X is defined on (Ω, A, P) and X has expo￾nential distribution with mean 1 and An = [1−1/n ≤ X ≤ 2+1/n]. Find
limn→∞ P(An). Suppose Bn = [n < X ≤ n + 1]. Find limn→∞ P(Bn).
2.6.21 Suppose a random variable X is defined on (Ω, A, P) and P[X = n] =
an, n ∈ N, an ≥ 0 and P
n∈N
an = 1. Find limn→∞ P[X = n].
2.7 Computational Exercises
2.7.1 Suppose a measurable space (Ω, A) is defined as Ω = [0, ∞) and A is
a sigma field of subsets of Ω. Suppose a sequence {Xn, n ≥ 1} of A
measurable random variables and a A measurable random variable X
are defined as follows.
Xn(ω) = exp(−nω), n ≥ 1 & X(ω) = 0 ∀ ω ∈ Ω.
Examine graphically if Xn → X on Ω or any subset of Ω.
2.7.2 Verify Theorem 2.4.2 graphically.
2.7.3 Verify Theorem 2.4.3 graphically.
2.7.4 Suppose X ∼ N(0, 1) and An = [X ≤ 1/n]. Find limn→∞ P(An) on the
basis of data simulated from the distribution of X.
2.7.5 Suppose X ∼ χ
2
5 and An = [X ≤ 1/n]. Using simulation find
limn→∞ P(An).
2.7.6 Suppose X has exponential distribution with mean 1 and
An = [1−1/n ≤ X ≤ 2 + 1/n]. Find limn→∞ P(An) based on simulated
data.130 Random Variables and Random Vectors
2.8 Multiple Choice Questions
Note: In each question, multiple options may be correct. Answers are given
in Chapter 11, after the solutions of conceptual exercises of Chapter 2.
2.8.1 Suppose X : Ω1 → Ω2 is a function and S1 and S2 are subsets of Ω2.
Following are two statements: (I) If S1 ⊆ S2, then X−1
(S1) ⊆ X−1
(S2).
(II) If X−1
(S1) ⊂ X−1
(S2), then S1 ⊂ S2. Then which of the following
statements is true?
(a) Both (I) and (II) are true
(b) (I) is true but (II) is false
(c) (II) is true but (I) is false
(d) Both (I) and (II) are false
2.8.2 Suppose X : Ω1 → Ω2 is a function and C1 and C2 are classes of subsets
of Ω2. Following are two statements: (I) C1 ⊆ C2 ⇒ X−1
(C1) ⊆
X−1
(C2). (II) X−1
(C1) ⊆ X−1
(C2) ⇒ C1 ⊂ C2. Then which of the
following statements is true?
(a) Both (I) and (II) are true
(b) (I) is true but (II) is false
(c) (II) is true but (I) is false
(d) Both (I) and (II) are false
2.8.3 Suppose X : Ω1 → Ω2 is a function and C1 and C2 are classes of subsets
of Ω2. Following are two statements: (I) C1 ⊆ C2 ⇒ σ[X−1
(C1)] ⊆
σ[X−1
(C2)]. (II) σ[X−1
(C1)] ⊆ σ[X−1
(C2)] ⇒ C1 ⊆ C2. Then which
of the following statements is true?
(a) Both (I) and (II) are true
(b) (I) is true but (II) is false
(c) (II) is true but (I) is false
(d) Both (I) and (II) are false
2.8.4 Suppose X : Ω1 → Ω2 is a function and C is a sigma field of subsets of
Ω2, then which of the following statements is/are true
(a) X−1
(C) = σ[X−1
(C)]
(b) X−1
[σ(C)] = σ[X−1
(C)]
(c) X−1
(C) ⊆ σ[X−1
(C)]
(d) X−1
[σ(C)] ⊇ σ[X−1
(C)]
2.8.5 Which of the following statements is/are true for a random variable X?
(a) X is A measurable ⇒ |X| is A measurable
(b) X is A measurable ⇒ X2
is A measurable
(c) |X| is A measurable ⇒ X is A measurable
(d) X2
is A measurable ⇒ X is A measurableMultiple Choice Questions 131
2.8.6 Which of the following is/are simple random variables with respect to
(Ω, A), if Ω = set of natural numbers and A= powerset of Ω.
(a) X(ω) = 0 ∀ ω ∈ Ω
(b) X(ω) = 0 if ω is odd and X(ω) = 1 if ω is even
(c) X(ω) = ω ∀ ω ∈ Ω
(d) X(ω) = 2ω ∀ ω ∈ Ω
2.8.7 Suppose (Ω, A) is a measurable space where Ω = set of natural numbers
and A= powerset of Ω. Following are two statements:
(I) X(ω) = 0 ∀ ω ∈ Ω is a simple random variable with respect to
(Ω, A). (II) X(ω) = ω ∀ ω ∈ Ω is a simple random variable with respect
to (Ω, A). Then which of the following statements is true?
(a) Both (I) and (II) are true
(b) (I) is true but (II) is false
(c) (II) is true but (I) is false
(d) Both (I) and (II) are false
2.8.8 Which of the following statements is/are NOT true for a random variable
X?
(a) X is A measurable ⇒ |X| is A measurable
(b) X is A measurable ⇒ X2
is A measurable
(c) |X| is A measurable ⇒ log(|X|) is A measurable
(d) X2
is A measurable ⇒ X is A measurable
2.8.9 Suppose Z = (X1, X2)
′
is a random vector defined on a measurable
space (Ω, A) to (R
2
, B
2
). Then the sigma field Z
−1
(B
2
) induced by Z is
given by
(a) X
−1
1
(B) ∪ X
−1
2
(B)
(b) σ(X
−1
1
(B) ∪ X
−1
2
(B))
(c) σ(X
−1
1
(B) ∩ X
−1
2
(B))
(d) X
−1
1
(B) ∩ X
−1
2
(B)
2.8.10 Suppose an infinite dimensional random vector Z = (X1, X2, · · · ,) is
defined on (Ω, A) to (R∞, B∞). Suppose An is a sigma field induced by
{X1, X2, · · · , Xn}. Then the sigma field Z
−1
(B∞) induced by Z is given
by
(a) σ(
T
n≥1 An)
(b) σ(
S
n≥1 An)
(c) S
n≥1 An
(d) T
n≥1 An
2.8.11 Suppose Z = (X1, X2)
′
is defined on the measurable space (Ω, A) to
(R
2
, B
2
). Following are two statements: (I) Z is a random vector measur￾able with respect to A implies X1 and X2 are random variables measur￾able with respect to A. (II) X1 and X2 are random variables measurable132 Random Variables and Random Vectors
with respect to A, but Z = (X1, X2)
′
is not measurable with respect to
A. Then which of the following is true?
(a) Both (I) and (II) are true
(b) (I) is true but (II) is false
(c) (II) is true but (I) is false
(d) Both (I) and (II) are false
2.8.12 Suppose (sin X1, eX2 )
′
is a random vector measurable with respect to
A. Then which of the following is/are NOT always true?
(a) sin X1 measurable with respect to A
(b) cos2 X1 measurable with respect to A
(c) cos X1 measurable with respect to A
(d) cos2 X1e
7X2+5 measurable with respect to A
2.8.13 Following are two statements: (I) Every continuous function on R is
a Borel function on (R, B). (II) Every Borel function on (R, B) is a
continuous function on R. Then which of the following is true?
(a) Both (I) and (II) are true
(b) (I) is true but (II) is false
(c) (II) is true but (I) is false
(d) Both (I) and (II) are false
2.8.14 Suppose {Xn, n ≥ 1} is a sequence of random variables on a measurable
space (Ω, A). Then which of the following is/are NOT true?
(a) Y1 = max{X1, X2} is a A measurable random variable
(b) Z1 = supn≥1 Xn is a A measurable random variable
(c) U1 = lim sup Xn is a A measurable random variable
(d) Y1, Z1, U1 are not measurable with respect to A.
2.8.15 Suppose Z = (X1, X2, · · · ,) is defined on the measurable space (Ω, A)
to (R∞, B∞). Following are two statements.
(I) Z is measurable with respect to A implies that for every n ≥ 1, Xn
is measurable with respect to A.
(II) For every n ≥ 1, Xn is measurable with respect to A does not imply
that Z is measurable with respect to A.
Then which of the following is true?
(a) Both (I) and (II) are true
(b) (I) is true but (II) is false
(c) (II) is true but (I) is false
(d) Both (I) and (II) are false
2.8.16 Suppose {Xn, n ≥ 1} is a sequence of random variables on a measurable
space (Ω, A). Then which of the following is/are true?
(a) Y1 = max{X1, X2} is a A measurable random variable
(b) Z1 = supn≥1 Xn is a A measurable random variableMultiple Choice Questions 133
(c) U1 = lim sup Xn is a A measurable random variable
(d) U2 = lim inf Xn is a A measurable random variable
2.8.17 Suppose {An, n ≥ 1} is a sequence of sets in A, then which of the
following is/are true?
(a) Ilim inf An = lim sup IAc
n
(b) Ilim inf An = lim inf IAn
(c) Ilim sup An = lim inf IAc
n
(d) Ilim sup An = lim inf IAn
2.8.18 Which of the following is true?
Suppose {Xn, n ≥ 1} is a sequence of random variables and
Cn = σ{Xn, Xn+1, · · · }. Then the tail sigma field of the sequence
{Xn, n ≥ 1} is defined as
(a) T =
S
n≥1 Cn
(b) T =
S
n≥k Cn
(c) T =
T
n≥k Cn
(d) T =
T
n≥1 Cn
2.8.19 Suppose X is a non-negative random variable defined on a measurable
space (Ω, A) to (R, B). Then which of the following is always true?
(a) There exists a sequence {Xn, n ≥ 1} of non-negative simple random
variables on a measurable space (Ω, A) such that Xn → X on Ω
(b) There exists a non-decreasing sequence {Xn, n ≥ 1} of elementary
random variables on a measurable space (Ω, A) such that Xn → X
on Ω
(c) There exists a non-decreasing sequence {Xn, n ≥ 1} of non-negative
simple random variables on a measurable space (Ω, A) such that
Xn → X on Ω
(d) There exists a non-increasing sequence {Xn, n ≥ 1} of non-negative
random variables on a measurable space (Ω, A) such that Xn → X
on Ω
2.8.20 Following are two statements.
(I) A class of random variables is closed under arithmetic operations.
(II) A class of simple random variables is closed under arithmetic oper￾ations.
Then which of the following is true?
(a) Both (I) and (II) are true
(b) (I) is true but (II) is false
(c) (II) is true but (I) is false
(d) Both (I) and (II) are false
2.8.21 Which of the following is/are Borel function(s), if f(x) = √
x?
(a) f : R → R134 Random Variables and Random Vectors
(b) f : R
+ → R
(c) f : R
+ → R
+
(d) f : R → R
+
2.8.22 What is the value of limn→∞ exp(−λ)λ
n/n! for λ > 0 and n ∈ N ?
(a) 0
(b) 1
(c) 0.5
(d) λ
2.8.23 What is the value of limn→∞[exp(−n) − exp(−(n + 1)] ?
(a) 0
(b) 1
(c) exp(−1)
(d) −∞
2.8.24 For non-decreasing sequence {Xn, n ≥ 1}, which of the following
statements is/are true? (I) supn≥1 Xn = supn≥k Xn, ∀ k ∈ N. (II)
infn≥1 Xn = infn≥k Xn, ∀ k ∈ N.
(a) Both (I) and (II) are true
(b) Only (I) is true
(c) Only (II) is true
(d) Both (I) and (II) are false
2.8.25 For non-increasing sequence {Xn, n ≥ 1}, which of the following
statements is/are true? (I) supn≥1 Xn = supn≥k Xn, ∀ k ∈ N. (II)
infn≥1 Xn = infn≥k Xn, ∀ k ∈ N.
(a) Both (I) and (II) are true
(b) Only (I) is true
(c) Only (II) is true
(d) Both (I) and (II) are false3
Distribution Function
3.1 Introduction
In Chapter 2 we introduced the probability distribution of a random variable
X defined on the probability space (Ω, A, P) to (R, B, PX). It is a collection
{PX(S), S ∈ B}, where PX(S) is the induced probability measure, induced
by the random variable X. Thus, to specify the probability distribution of X,
we require the knowledge of PX(S) for all S ∈ B. We have a simpler way to
specify the probability distribution of X, as we have a simpler way to verify
that a function on (Ω, A) is a random variable via the economical definition.
Once again such a simpler approach is based on the fact that a collection of
intervals of the type (−∞, x], x ∈ R, generates the Borel field and it is enough
to specify PX(S) for S = (−∞, x], x ∈ R. It is manifested by introducing the
concept of a distribution function in the present chapter.
By definition, the induced probability measure PX(S) is a set function
defined on (R, B). Using a distribution function, we can specify the probability
distribution of a random variable X by a point function defined on R. It is
usually easier to work with a point function than a set function and hence in
practice the distribution of a random variable is always specified in terms of
its distribution function. We define below a distribution function of a random
variable and study its properties.
Definition 3.1.1. Distribution function: Suppose X is a random variable
defined on the probability space (Ω, A, P). Then the distribution function FX(.)
of X is defined on R as
FX(x) = P
￾
X−1
((−∞, x])
= P{ω | X(ω) ≤ x} = P[X ≤ x], x ∈ R.
Suppose S = (−∞, x], x ∈ R, then PX(S) = P
￾
X−1
((−∞, x]

= FX(x).
Thus, probability distribution of X completely specifies the distribution func￾tion of X. The converse is also true and can be proved using the Caratheodory
extension theorem. For proof, see Ash [2] or Athreya and Lahiri [3]. Thus,
there is a one to one correspondence between the probability distribution of
X and the distribution function of X as stated in the following theorem.
Theorem 3.1.1. Correspondence theorem: Every probability measure P
∗ on
(R, B) uniquely determines a distribution function through the correspondence
DOI: 10.1201/9781032619057-3 1136 Distribution Function
F(x) = P
∗
((−∞, x]), x ∈ R with F(−∞) = 0 and F(∞) = 1. Conversely, if
F(x) is specified for each x ∈ R, then the probability measure P
∗ on (R, B) is
determined uniquely through the relation P
∗
((−∞, x]) = F(x).
In view of the correspondence theorem, the terms probability distribution
and distribution function of a random variable are used interchangeably. In
the next section, we discuss some properties of a distribution function.
3.2 Properties of a Distribution Function
Four important properties of a distribution function are proved in the following
theorem. The continuity theorem for probability measure is heavily used in
the proof. We also use one property of a dense set, defined below.
Definition 3.2.1. A set A is said to be dense in R, if every point of R is
either in A or is a limit point of A.
For example, the set of rational numbers as well as the set of irrational
numbers is dense in R.
Theorem 3.2.1. Suppose FX(x) is a distribution function of a random vari￾able X defined on the probability space (Ω, A, P). Then
(i) 0 ≤ FX(x) ≤ 1.
(ii) FX(x) is a non-decreasing function on R.
(iii) FX(x) is a right continuous function on R.
(iv) limx→∞ FX(x) = 1 and limx→−∞ FX(x) = 0.
Proof.
(i) By definition, FX(x) = P[X ≤ x], x ∈ R. Hence, 0 ≤ FX(x) ≤ 1.
(ii) Suppose x1 and x2 in R are such that x1 ≤ x2.
x1 ≤ x2 ⇒ (−∞, x1] ⊆ (−∞, x2] ⇒ X−1
((−∞, x1]) ⊆ X−1
((−∞, x2])
⇒ P(X−1
((−∞, x1])) ≤ P(X−1
((−∞, x2]))⇒FX(x1)≤FX(x2).
Thus, FX(x) is a non-decreasing function on R.
(iii) FX(x) is a right continuous function on R if lim
h→0
FX(x+h) = FX(x). To
establish this assertion, suppose an event An, n ≥ 1 is defined as
An = [X ≤ x+hn], where {hn, n ≥ 1} is a monotone decreasing sequence
of positive numbers tending to 0 as n → ∞. Following arguments assureProperties of a Distribution Function 137
that such a sequence exists. Observe that 0 is a limit point of [0, ∞), since
every neighborhood of 0 contains infinitely many points from [0, ∞).
Hence by the properties of limit points, there ∃ at least one sequence
{gn, n ≥ 1} from [0, ∞), which converges to 0. Further, every sequence
of real numbers has a monotone subsequence (page 55 of Kumar and
Kumaresan [15] and if the original sequence is convergent then this
subsequence is also converges to the same limit as that of the original
sequence. Thus, ∃ a monotone subsequence {hn, n ≥ 1} of {gn, n ≥ 1}
such that hn → 0. Since hn ≥ 0 ∀ n ≥ 1, it must be a monotone
decreasing sequence. Note that ∀ n ≥ 1
An ⊃ An+1 ⇒ {An, n ≥ 1} is a non-increasing sequence of events
⇒ limn→∞
An =
\
n≥1
An = [X ≤ x] = A, say
⇒ limn→∞
P(An) = P(A)
by continuity theorem for probability measure
⇒ limn→∞
P[X ≤ x + hn] = P[X ≤ x] = FX(x)
⇒ lim
h→0
FX(x + h) = FX(x) ⇒ FX(x) is right continuous on R.
(iv) Suppose {an, n ≥ 1} is a non-decreasing sequence of numbers such that
an → ∞ as n → ∞, for example an = n. The existence of such a
sequence follows using similar arguments as in (iii). Suppose the event
An is defined as An = [X ≤ an]. Observe that ∀ ω ∈ Ω,
X(ω) ≤ an ⇒ X(ω) ≤ an+1 ⇒ An ⊂ An+1 ∀ n ≥ 1
⇒ {An, n ≥ 1} is a non-decreasing sequence of events
⇒ limn→∞
An =
[
n≥1
An = Ω, since an → ∞ as n → ∞.
Again by the continuity theorem for probability measures, if An ↑ Ω
then P(An) ↑ P(Ω) = 1. Thus,
1 = P(Ω) = P( limn→∞
An) = limn→∞
P(An)= limn→∞
FX(an)⇒ limx→∞
FX(x) = 1.
To prove limx→−∞ FX(x) = 0, an event Bn is defined as Bn = [X ≤
−an]. Then {Bn, n ≥ 1} is a non-increasing sequence of events with limit
T
n≥1 Bn = ∅. Again by the continuity theorem for probability measures,
if Bn ↓ ∅ then P(Bn) ↓ P(∅) = 0. Thus,
0 = P(∅) = P( limn→∞
Bn) = limn→∞
P(Bn) = limn→∞
FX(−an)
⇒ lim x→−∞
FX(x) = 0.
Converse of Theorem 3.2.1 is true and is proved in the following theorem.138 Distribution Function
Theorem 3.2.2. Suppose a function g : R → R satisfies the following four
properties.
(i) 0 ≤ g(x) ≤ 1.
(ii) g(x) is a non-decreasing function on R.
(iii) g(x) is a right continuous function on R.
(iv) limx→∞ g(x) = 1 and limx→−∞ g(x) = 0. Then there exists a probability
space on which one can define a random variable, whose distribution
function is the given function g.
Proof. Suppose a function X is defined on a measurable space (R, B) as
X(y) = y ∀ y ∈ R, that is X is an identity function. Note that
∀ S ∈ B, X−1
(S) = {y|X(y) ∈ S} = {y|y ∈ S} = S ∈ B.
Thus, X is measurable with respect to B. Suppose C denotes a collection of all
intervals of the form (a, b], a < b ∈ R. Then the minimal sigma field σ(C) = B.
We now define an increment function F((a, b]) as F((a, b]) = g(b) − g(a), a ≤
b ∈ R. Since g is non-decreasing, it follows that F((a, b]) ≥ 0. Using the
increment function, we define a measure P on F(C), a field generated by C,
such that
P((−∞, a]) = F((−∞, a]) = g(a)−g(−∞) = g(a) ∀ a ∈ R as lim x→−∞
g(x) = 0.
By the Caratheodory extension theorem, P is further extended to the minimal
sigma field σ(C) = B, the Borel field. Note that limx→∞ g(x) = 1 implies that
P(R) = 1 and the right continuity of g assures that P is a continuous set
function. Thus P is a probability measure on (R, B) and hence there exists a
probability space (R, B, P). Note that X is a measurable function (R, B, P)
such that
P[X ≤ x] = P((−∞, x]) = g(x) ∀ x ∈ R.
Thus, if a function g : R → R satisfies the four properties of a distribution
function, then there exists a probability space on which one can define a
random variable whose distribution function is the given function g.
In general, many random variables can have the same distribution function.
In such a case we say that the random variables are identically distributed.
Definition 3.2.2. Identically distributed random variables: Random variables
X and Y are said to be identically distributed if FX(x) = FY (x) ∀ x ∈ R.
If two random variables X and Y are identical in the sense that
X(ω) = Y (ω) ∀ ω ∈ Ω, then X and Y have the same distribution function
and the two are identically distributed. However, the converse is not true. Two
identically distributed random variables need not be identical as is clear from
the following example.Properties of a Distribution Function 139
Example 3.2.1. Suppose a probability distribution of a random variable X
is given by P[X = 0] = P[X = 1] = 1/2. Hence its distribution function is,
F(x) =



0, if x ≤ 0
1/2, if 0 ≤ x < 1
1, if x ≥ 1.
If a random variable Y is defined as Y = 1 − X, then the probability dis￾tribution of Y is given by, P[Y = 0] = P[Y = 1] = 1/2 and its distribution
function is the same as that of X. Hence, X and Y are identically distributed
random variables taking values 0 and 1 each with probability 1/2 but observe
that if X(ω) = 0 then Y (ω) = 1 and if X(ω) = 1 then Y (ω) = 0. Thus,
X(ω) ̸= Y (ω) ∀ ω ∈ Ω which implies that X and Y are not identical random
variables. □
As proved in Theorem 3.2.1, the distribution function is always right con￾tinuous. To study the left hand limit limh→0 FX(x − h) at x, as in the setup
of right continuity, suppose {hn, n ≥ 1} is a non-increasing sequence of pos￾itive numbers tending to 0 as n → ∞. Suppose an event An is defined as
An = [X ≤ x − hn], n ≥ 1. Observe that An ⊂ An+1, ∀ n ≥ 1 and hence
{An, n ≥ 1} is a non-decreasing sequence of events. Further, the sequence
{(−∞, x − hn], n ≥ 1} → (−∞, x). Hence,
limn→∞
An =
[
n≥1
An = [X < x]
⇒ limn→∞
P(An) = P[X < x] ⇒ lim
hn→0
FX(x − hn) = P[X < x]
⇒ lim
h→0
FX(x − h) = P[X < x] = FX(x−), say.
The second step follows by the continuity theorem of probability measure.
Hence, F is continuous from left at x, if FX(x−) = FX(x). It may or may
not be left continuous at all points in the domain R. We denote the left hand
limit lim
h→0
FX(x − h) by either FX(x−) or FX(x − 0).
Definition 3.2.3. Point of discontinuity of a distribution Function: If F is
not continuous from left at x ∈ R, that is, if limh→0 FX(x − h) = FX(x−) ̸=
FX(x), then x is said to be a point of discontinuity of a distribution function
F.
Definition 3.2.4. Size of discontinuity: Suppose x is a point of discontinuity
of F. Then, px = FX(x) − FX(x−) is known as the size of discontinuity of F
at x or the magnitude of the jump at x.
It is to be noted that in view of the non-decreasing nature of the distribu￾tion function, FX(x) > FX(x−) and hence px > 0 for a point x of discontinuity
of F. Further,
px = FX(x) − FX(x−) = P[X = x] = P{ω | X(ω) = x}.140 Distribution Function
If x is not a point of discontinuity of F, then px = FX(x) − FX(x−) = 0, that
is, P[X = x] = 0. Following theorem proves an important result related to
the set of points of discontinuity of F.
Theorem 3.2.3. Suppose F is a distribution function of a random variable
X defined on a probability space (Ω, A, P). Then the set D of points of dis￾continuity of F is at most countable set.
Proof. Suppose x is a point of discontinuity of F, with px > 0 as the size of
the discontinuity. Suppose Dn is a set of points x of discontinuity of F, such
that the size of discontinuity px ≥ 1/n. Thus, Dn = {x ∈ R|px ≥ 1/n}. Now,
x ∈ D ⇐⇒ px > 0 ⇐⇒ px ≥ 1/n, for at least one n ≥ 1
⇐⇒ x ∈ Dn, for at least one n ≥ 1
⇐⇒ x ∈
[
n≥1
Dn.
Thus, D =
S
n≥1 Dn. Suppose Dn contains more than n points. In particular,
suppose x1, x2, · · · , xn+k, k ≥ 1 are n + k distinct points in Dn. Hence, the
singleton sets {xi}, i = 1, 2, · · · , n + k are disjoint Borel sets, which further
implies that the inverse images
X−1
({xi}) = {ω | X(ω) = xi} = [X = xi
], i = 1, 2, · · · , n + k
are also disjoint subsets of A. Further, size of discontinuity pxi ≥ 1/n at xi
,
i = 1, 2, · · · , n + k. Hence, by finite additivity of the probability measure P,
P
h nX
+k
i=1
[X = xi
]
i
=
nX
+k
i=1
P[X = xi
] =
nX
+k
i=1
pxi ≥
1
n
(n + k) = 1 + k
n
> 1,
which is a contradiction. Thus the assumption that Dn contains more than n
points is not correct and we conclude that the number of points in Dn is ≤ n,
that is, the set Dn is finite for all n ≥ 1. Now D is a countable union of finite
sets Dn and hence D is at most countable.
Suppose C denotes a set of points of continuities of a distribution function
F, then C = Dc
. Since D is at most countable, it follows that C is either R or
an uncountable subset of R. In the following lemma, we prove that C is dense
in R.
Lemma 3.2.1. The set C of points of continuity of F is dense in R.
Proof. We prove the result by contradiction. Suppose C = Dc
is not dense
in R. Hence ∃ x ∈ R such that x /∈ Dc and x is not a limit point of Dc
. It
implies that ∃ ϵ > 0 such that Nϵ(x) = (x − ϵ, x + ϵ) does not contain any
point from Dc
, which further implies that Nϵ(x) ⊆ D. It is a contradiction,
since Nϵ(x) is an uncountable set while D is at most countable.Properties of a Distribution Function 141
Using this property and the right continuity of F, it is proved in the
following theorem that F is completely determined by its values at all the
points of continuity.
Theorem 3.2.4. Suppose F and G are two distribution functions with C(F)
and C(G) as the sets of points of continuity respectively. Then
(i) C(F) ∩ C(G) ̸= ∅.
(ii) C(F) ∩ C(G) is dense in R.
(iii) If F(x) = G(x) ∀ x ∈ C(F) ∩ C(G), then F(x) = G(x) ∀ x ∈ R.
Proof.
(i) To prove that C(F)∩C(G) ̸= ∅, we assume the contrary. Suppose C(F)∩
C(G) = ∅. Then,
(C(F) ∩ C(G))c = D(F) ∪ D(G) = ∅
c = R,
where D(F) and D(G) are sets of points of discontinuity of F and G
respectively. In Theorem 3.2.3, it is proved that the set of points of
discontinuity of a distribution function is at most countable. Further
the union of two at most countable sets is at most countable. Hence,
(D(F) ∪ D(G)) is at most countable and it cannot be equal to R. Thus,
our assumption that C(F) ∩ C(G) = ∅ is wrong and C(F) ∩ C(F) ̸= ∅.
(ii) As in Lemma 3.2.1, we assume the contrary that C(F) ∩ C(G) is not
dense in R. Hence ∃ x ∈ R such that x /∈ C(F) ∩ C(G) and x is
not a limit point of C(F) ∩ C(G). It implies that ∃ ϵ > 0 such that
Nϵ(x) = (x − ϵ, x + ϵ) does not contain any point from C(F) ∩ C(G),
which further implies that Nϵ(x) ⊆ (C(F) ∩ C(G))c = D(F) ∪ D(G). It
is a cotradiction, since Nϵ(x) is an uncountable set while D(F) ∪ D(G)
is atmost countable.
(iii) Suppose x ∈ (C(F) ∩ C(G))c
. It is proved in (ii) that C(F) ∩ C(G)
is dense in R. As a consequence, for any real number x, there exists a
sequence {x+rn, n ≥ 1} of points in C(F)∩C(G) such that x+rn → x,
as rn ↓ 0. It is given that F(x) = G(x) ∀ x ∈ C(F) ∩ C(G). Hence,
F(x + rn) = G(x + rn). Note that being distribution functions, F and G
are right continuous. Hence, for x ∈ (C(F) ∩ C(G))c
,
F(x) = lim
h↓0
F(x + h) = lim
rn↓0
F(x + rn) = lim
rn↓0
G(x + rn)
= lim
h↓0
G(x + h) = G(x) ⇒ F(x) = G(x) ∀ x ∈ R.142 Distribution Function
We use Theorem 3.2.4 in Section 7.3, to prove that limit random variables
in convergence in distribution are identically distributed. In fact, if two dis￾tribution functions agree on a dense subset of R, then these agree on R, the
result is stated below. For proof refer to Gut [13].
Theorem 3.2.5. Suppose F and G are two distribution functions. If F = G
on a dense subset of R, then F = G on R.
The next example illustrates how to identify the points of discontinuity
and their respective sizes.
Example 3.2.2. Suppose Ω = {1, 2, 3}, A = P(Ω) and the probability mea￾sure P is specified by P({1}) = 1/4, P({2}) = 1/2, P({3}) = 1/4. Suppose
a random variable X on (Ω, A) is defined as X(i) = i. Then the distribution
function FX(x) = P{ω | X(ω) ≤ x} = P[X ≤ x], for x ∈ R is given by,
FX(x) =



0, if x < 1,
1/4, if 1 ≤ x < 2,
3/4, if 2 ≤ x < 3,
1, if x ≥ 3.
To find the points of discontinuities of F, observe that ∀ x < 1, FX(x) = 0,
thus it is a constant function and hence a continuous function on (−∞, 1),
hence all points in this interval are points of continuity. At x = 1,
FX(1) = 1/4 ̸= 0 = FX(1−) = lim
h→0
FX(1−h) & p1 = FX(1)−FX(1−) = 1/4.
Hence x = 1 is a point of discontinuity with size of discontinuity 1/4. Further,
∀ x ∈ (1, 2), FX(x) = 1/4 is a constant function and hence a continuous
function on (1, 2), hence all points in this interval are points of continuity. At
x = 2,
FX(2) = 3/4 ̸= 1/4 = FX(2−) = lim
h→0
FX(2−h) & p2 = FX(2)−FX(2−) = 1/2.
Hence x = 2 is a point of discontinuity with size of discontinuity 1/2. Note
that, ∀ x ∈ (2, 3), FX(x) = 3/4, thus it is again a constant function and hence
a continuous function on (2, 3), hence all points in this interval are points of
continuity. At x = 3,
FX(3) = 1 = 3 ̸ /4 = FX(3−) = lim
h→0
FX(3−h) & p3 = FX(3)−FX(3−) = 1/4.
Hence x = 3 is a point of discontinuity with size of discontinuity 1/4. Now,
∀ x ≥ 3, FX(x) = 1 is a constant function and hence a continuous function
on [3, ∞), hence all points in (3, ∞) are points of continuity. Thus, the set D
of points of discontinuity of FX(x) is {1, 2, 3}, with size of jump at point of
discontinuity being p1 = 1/4, p2 = 1/2 and p3 = 1/4. It is to be noted that
sum of sizes of jump at points of discontinuity is 1. □Properties of a Distribution Function 143
Having defined a distribution function, the next natural question is to
determine how many different types of distribution functions exist. To define
these types, we now introduce a concept of a point of increase of a distribution
function. It is useful to define a discrete and a continuous type distribution
function.
Definition 3.2.5. Point of increase of a distribution function: A point x ∈ R
is said to be a point of increase of a distribution function F if
∀ ϵ > 0, FX(x + ϵ) − FX(x − ϵ) > 0.
Example 3.2.3. We find the points of increase for the distribution function
derived in Example 3.2.2. Note that
∀ x < 1 , ∀ ϵ ∈ (0, 1 − x) FX(x + ϵ) − FX(x − ϵ) = 0.
Hence, no point in this interval is a point of increase. At
x = 1, ∀ ϵ > 0, FX(x + ϵ) − FX(x − ϵ) = 1/4 or 3/4 or 1,
depending on the values of ϵ, thus, x = 1 is a point of increase. For x ∈ (1, 2),
if
ϵ = (1/2) min{2 − x, x − 1}, then for all such ϵ, FX(x + ϵ) − FX(x − ϵ) = 0
but for other ϵ, FX(x + ϵ) − FX(x − ϵ) > 0 and hence no x ∈ (1, 2) is a point
of increase. At
x = 2, ∀ ϵ > 0, FX(x + ϵ) − FX(x − ϵ) > 0,
thus, x = 2 is a point of increase. For x ∈ (2, 3), using similar arguments as
for the case x ∈ (1, 2), no point is a point of increase. For
x = 3, ∀ ϵ > 0, FX(x + ϵ) − FX(x − ϵ) > 0,
thus, x = 3 is a point of increase. For all x ≥ 3, FX(x + ϵ) − FX(x − ϵ) = 0.
Hence, no point in this interval is a point of increase. Thus, a set E of points
of increase of FX(·) is E = {1, 2, 3}. □
Remark 3.2.1. From Example 3.2.2 and Example 3.2.3, we note that the set
of points of discontinuities of F is the same as the set of points of increase of
F. From the definitions of point of discontinuity and of point of increase, it
is clear that a point of discontinuity of F is always a point of increase of F.
But the converse is not true. Suppose a distribution function F is continuous
and strictly increasing on R, thus the set of points of discontinuities of F is
the empty set, but
∀ x ∈ R and ∀ ϵ > 0, FX(x + ϵ) − FX(x − ϵ) > 0
implying that all x ∈ R are points of increase. This observation leads to the
following definitions of a discrete and a continuous random variable.144 Distribution Function
Definition 3.2.6. Discrete random variable or discrete distribution function:
A random variable X or its distribution function F is said to be discrete if
all points of increase of F are its points of discontinuities. Alternatively, X
or its distribution function F is said to be discrete, if for some countable set
of real numbers {xj} and {pxj ∈ (0, 1)}, FX(x) = P
xj≤x
pxj
, ∀ x ∈ R.
Definition 3.2.7. Continuous and absolutely continuous random variable or
continuous and absolutely continuous distribution function: A random variable
X or its distribution function F is said to be continuous if the set of points
of discontinuity of F is an empty set, that is, if the distribution function F is
continuous on R. A continuous random variable X or its distribution function
F is said to be absolutely continuous, if there exists a non-negative function
f such that FX(b) − FX(a) = R b
a
f(x)dx, for all a < b.
Definition 3.2.8. Singular distribution function: A distribution function F
is said to be singular if F ̸= 0, but d
dx FX(x) exists and is 0 almost everywhere.
Definition 3.2.9. Support of a distribution function: A set of values of x ∈ R
for which F(x) increases is known as a support of a distribution function.
If F is a discrete distribution function, then its support is the set D of
points of discontinuity of F, which is the same as the set of points of increase
of F. If F is a continuous distribution function, then its support is the set of
points of increase of F.
Definition 3.2.10. Probability mass function of a discrete random variable:
Suppose D is a set of points of discontinuity of F and px, x ∈ D is the size
of discontinuity at x. Then the set {(x, px) | x ∈ D} is a probability mass
function of a discrete random variable X.
Definition 3.2.11. Probability density function of an absolutely continuous
random variable: Suppose a random variable X is absolutely continuous with
distribution function F. Hence, there exists a non-negative function f such
that FX(b) − FX(a) = R b
a
f(x)dx, for all a < b. The function f is known as
a probability density function of an absolutely continuous random variable X.
If F is differentiable on R, then f(x) = d
dx FX(x).
Remark 3.2.2. Probability mass function of a discrete random variable X
completely specifies the probability distribution of X, because when the set
{(x, px) | x ∈ D} is known, then by the finite additivity or sigma additivity
of the probability measure P, P[X ∈ S] is known for every Borel set S and
P[X ∈ S] = P
x∈S
px . Similarly, probability density function of an absolutely
continuous random variable X completely specifies the probability distribu￾tion of X as P[X ∈ S] is given by P[X ∈ S] = R
x∈S
f(x) dx. In particular,
FX(x) = P[X ≤ x] = R x
−∞ f(x)dx. Thus, there is one to one correspon￾dence between the probability density function and the distribution function.
Note that the probability density function of an absolutely continuous ran￾dom variable or the probability mass function of a discrete random variableDecomposition of a Distribution Function 145
are completely determined by the probability measure P of the probability
space (Ω, A, P).
A distribution function can be neither discrete nor continuous. It may be a
mixture of discrete and continuous distribution functions. In the next section,
we discuss how such a distribution function can be decomposed.
3.3 Decomposition of a Distribution Function
Suppose X denotes the waiting time at a traffic signal. It is 0, if the signal
light is green upon arrival. If the signal light is red, then waiting time is a
continuous random variable. We have a similar scenario, if X denotes the
waiting time at a bill counter at the mall. It is 0, if there is no customer
at the counter, otherwise it is a continuous random variable. In such cases
the distribution function is a mixture of discrete and continuous distribution
functions. Every distribution function can always be decomposed in terms of
discrete and continuous distribution functions. The following theorem, known
as the Jordan decomposition theorem, conveys this concept more precisely.
Theorem 3.3.1. Jordan decomposition theorem: Every distribution function
F can be uniquely expressed as,
F = l1F1 + l2F2, where l1, l2 ≥ 0 and l1 + l2 = 1,
where F1 is a discrete distribution function and F2 is a continuous distribution
function.
Proof. It is proved in Theorem 3.2.3 that the set of points of discontinuity of
F is at most countable. Suppose {xn, n ≥ 1} is a sequence of points of dis￾continuity of F. Thus, the sequence {xn, n ≥ 1} consists of finite or countably
infinite number of points or no points at all. The size of discontinuity defined
as pxn = F(xn) − F(xn−) > 0 ∀ n ≥ 1. Suppose a function G on R is defined
as
G(x) = X
xn≤x
pxn
, x ∈ R.
By the definition of G it is clear that it satisfies the following properties.
(i) 0 ≤ G(x) ≤ 1 for all x ∈ R, (ii) G is non-decreasing and right continuous
on R and (iii) G(−∞) = 0, G(∞) ≤ 1. Another function H(x) based on F
and G is defined as H(x) = F(x) − G(x), x ∈ R and it satisfies the following
properties. (i) G(x) ≤ F(x) ⇒ H(x) ≥ 0. (ii) Since F(x) ≤ 1 and G(x)146 Distribution Function
may be 0 for some or all x, H(x) ≤ 1. (iii) H(−∞) = 0. (iv) Observe that for
x < y, H(y) − H(x) = F(y) − F(x) −
X
xn≤y
pxn +
X
xn≤x
pxn
= P[x < X ≤ y] −
X
x<xn≤y
pxn ≥ 0
and hence H is non-decreasing on R. (v) Since F and G are right continuous,
H is also right continuous on R. To examine the left continuity, observe that
if x is a point of continuity of F, then for h > 0
H(x) − H(x − h) = F(x) − F(x − h) −
X
x−h<xn≤x
pxn → 0 as h → 0.
Further, if x is a point of discontinuity of F, then for h > 0
H(x)−H(x−h) = F(x)−F(x−h)−
X
x−h<xn≤x
pxn → px−px = 0 as h → 0.
It thus follows that H is continuous on R. Suppose l1 = G(∞) < 1. Since for
all x ∈ R, F(x) = H(x) + G(x), H(∞) = 1 − G(∞) = l2 say. Suppose F1 and
F2 are defined as
F1 = (1/l1)G & F2 = (1/l2)H ⇒ F1(∞) = 1 & F2(∞) = 1.
From the properties of G and H and the fact that F1(∞) = F2(∞) = 1, it is
clear that F1 and F2 are distribution functions. Thus,
F(x) = G(x) + H(x) = l1F1(x) + l2F2(x),
where F1 is of discrete type while F2 is continuous. Note that the decomposi￾tion remains valid even if either l1 or l2 is 0. To establish the uniqueness, sup￾pose if possible, F = G+H = G∗ +H∗ which implies G−G∗ = H −H∗
, how￾ever G and G∗ are discrete distribution functions and G−G∗
is not a continu￾ous function, but H −H∗
is a continuous function. Hence G−G∗ = H −H∗
is
possible if and only if each is 0, that is, if and only if G = G∗ and H = H∗
.
Remark 3.3.1. In the decomposition F = l1F1 + l2F2, if l1 = 0, then F is a
continuous distribution function and if l2 = 0, then F is a discrete distribution
function. If both l1 and l2 are positive then F is neither discrete nor contin￾uous. A discrete distribution function is always a step function while graph
of a continuous distribution function is a non-decreasing continuous function,
tending to 0 as x → −∞ and tending to 1 as x → ∞.
In Jordan decomposition theorem, F is decomposed as F = l1F1 + l2F2.
The continuous distribution function F2 can be further decomposed into ab￾solutely continuous and singular components. Thus, F can be decomposed in
three components. We state this result in the following theorem. For proof
one may refer to Athreya and Lahiri [3].Decomposition of a Distribution Function 147
Theorem 3.3.2. Decomposition theorem: Every distribution function can be
uniquely expressed as,
F = l1F1 + l2F2 + l3F3, where l1, l2, l3 ≥ 0 and l1 + l2 + l3 = 1,
where F1 is a discrete distribution function, F2 is an absolutely continuous
distribution function and F3 is a singular distribution function.
In the following example, we adopt the procedure outlined in Theorem
3.3.1 to decompose a distribution function F into discrete and continuous
components.
Example 3.3.1. Suppose a distribution function F : R → [0, 1] is defined as
follows.
F(x) =



0, if x < −2,
1/3, if −2 ≤ x < 0,
1/2, if 0 ≤ x < 5,
1/2 + (x − 5)2/2, if 5 ≤ x < 6,
1, if x ≥ 6.
We first find a set of points of discontinuity and corresponding size of the
discontinuity. Observe that at F(−2−) = 0 ̸= 1/3 = F(−2), implying that −2
is a point of discontinuity with size of discontinuity 1/3. Similarly,
F(0−) = 1/3 ̸= 1/2 = F(0), hence 0 is a point of discontinuity with size of
discontinuity 1/2−1/3 = 1/6. No other point is a point of discontinuity. Hence,
as in Theorem 3.3.1, we have G(x) = P
xn≤x
pxn
and H(x) = F(x) − G(x),
x ∈ R. These are given by,
G(x)=



0, if x < −2,
1/3, if −2 ≤ x < 0,
1/2, if x ≥ 0
& H(x)=



0, if x < 5,
(x − 5)2/2, if 5 ≤ x < 6,
1/2, if x ≥ 6.
Note that l1 = G(∞) = 1/2 < 1 and H(∞) = 1 − G(∞) = l2 = 1/2. Suppose
F1 and F2 are defined as F1 = (1/l1)G and F2 = (1/l2)H. Hence, F1(∞) = 1
and F2(∞) = 1. Thus, F1 and F2 are given by,
F1(x) =



0, if x < −2,
2/3, if −2 ≤ x < 0,
1, if x ≥ 0
& F2(x) =



0, if x < 5,
(x − 5)2
, if 5 ≤ x < 6,
1, if x ≥ 6.
It is easy to verify that F(x) = l1F1(x) + l2F2(x) for all x ∈ R. F1 is a
discrete distribution function and corresponding probability mass function
is given by, P[X = −2] = 2/3 and P[X = 0] = 1/3. F1 is a continuous
distribution function and it is differentiable with corresponding probability
density function f(x) = 2(x − 5) if 5 ≤ x < 6 and 0 otherwise. □
In some cases it is possible to decompose F into discrete and continuous
components by observing the given F. We adopt this approach in the following
example.148 Distribution Function
Example 3.3.2. Suppose a function F : R → [0, 1] is defined as follows.
F(x) =



0, if x < 0,
1/4, if 0 ≤ x < 1,
1/2, if 1 ≤ x < 2,
1/2 + (x − 2)/2, if 2 ≤ x < 3,
1, if x ≥ 3.
We first examine whether F is a distribution function. It will be a distribution
function, if it satisfies the four conditions given in Theorem 3.2.1. By the
definition of F, (i) it is clear that 0 ≤ F(x) ≤ 1 ∀ x ∈ R. (ii) F is non￾decreasing on R, if ∀ x1, x2 ∈ R, x1 ≤ x2 implies F(x1) ≤ F(x2). Suppose
x1 < x2 are in (−∞, 0). For all x ∈ (−∞, 0), F(x) = 0, hence x1 ≤ x2 ⇒
F(x1) ≤ F(x2). For x1 < 0, F(x1) = 0, and for x2 ∈ [0, 1), F(x2) = 1/4, for
x2 ∈ [1, 2), F(x2) = 1/2, for x2 ∈ [2, 3), F(x2) = 1/2 + (x2 − 2)/2 and for x2 ∈
[3, ∞), F(x2) = 1. Thus, for all such x1 and x2, F(x1) ≤ F(x2). Now suppose
both x1, x2 ∈ [0, 1), then F(x1) = F(x2) = 1/4. For x2 ∈ [1, 2), F(x2) = 1/2,
for x2 ∈ [2, 3), F(x2) = 1/2 + (x2 − 2)/2, for x2 ∈ [3, ∞), F(x2) = 1. Thus,
for all such x1 and x2, F(x1) ≤ F(x2). For both x1, x2 ∈ [1, 2), F(x1) =
F(x2) = 1/2. For x2 ∈ [2, 3), F(x2) = 1/2 + (x2 − 2)/2 and for x2 ∈ [3, ∞),
F(x2) = 1.Thus, for all such x1 and x2, F(x1) ≤ F(x2). Further, assume that
both x1 < x2 ∈ [2, 3), then F(x1) = 1/2+(x1−2)/2 ≤ 1/2+(x2−2)/2 = F(x2)
and for x2 ∈ [3, ∞), F(x2) = 1. Thus, for all such x1 and x2, F(x1) ≤ F(x2).
Now suppose both x1, x2 ∈ [3, ∞), then F(x1) = F(x2) = 1. Hence, we have
noted that ∀ x1, x2 ∈ R, x1 ≤ x2 implies that F(x1) ≤ F(x2). (iii) Note
that for x ∈ (−∞, 0), x ∈ (0, 1), x ∈ (1, 2) and x ∈ (3, ∞), F(x) is a constant
function, hence continuous and hence right continuous function on all these
intervals of the domain. For x ∈ (2, 3), F(x) = 1/2 + (x−2)/2 is a polynomial
of degree 1 and hence is continuous and hence right continuous function. We
now have to check right continuity at x = 0, 1, 2, 3. Observe that,
lim
h→0
F(0 + h) = 1/4 = F(0), lim
h→0
F(1 + h) = 1/2 = F(1),
lim
h→0
F(2+h) = lim
h→0
(1/2+(2+h−2)/2) = 1/2 = F(2), lim
h→0
F(3+h) = 1 = F(3).
Thus F is right continuous at x = 0, 1, 2, 3. (iv) Note that
∀ x < 0, F(x) = 0 ⇒ lim x→−∞
F(x) = 0 & ∀ x > 3, F(x) = 1 ⇒ limx→∞
F(x) = 1.
Thus, the function F satisfies the four conditions for it to qualify as a distri￾bution function. Observe that F can be expressed as,
F(x) =



0, if x < 0,
1
4 =
1
2
∗
1
2
, if 0 ≤ x < 1,
1
2 =
1
2
∗ 1, if 1 ≤ x < 2,
1
2 +
(x−2)
2 =
1
2
∗ 1 + 1
2
(x − 2), if 2 ≤ x < 3,
1 = 1
2
∗ 1 + 1
2
∗ 1, if x ≥ 3.Decomposition of a Distribution Function 149
This expression of F suggests that F can be decomposed as F = l1F1 + l2F2,
where l1 = 1/2, l2 = 1/2 and F1 and F2 are
F1(x) =



0, if x < 0,
1/2, if 0 ≤ x < 1,
1, if x ≥ 1
& F2(x) =



0, if x < 2,
x − 2, if 2 ≤ x < 3,
1, if x ≥ 3.
Observe that F1 is a discrete distribution function with set D = {0, 1} as
a set of points of discontinuity, with jump size 1/2 at each jump. It is the
same as the set of points of increase. Thus, F1 is a distribution function of
a discrete random variable X1 with probability mass function P[X1 = 0] =
P[X1 = 1] = 1/2. Further, F2 is a continuous distribution function and it is a
distribution function of an absolutely continuous random variable X2 having
uniform U(2, 3) distribution with probability density function f(x) given by,
f(x) = 
1, if 2 ≤ x ≤ 3,
0, otherwise.
□
Example 3.3.3. In this example we draw four graphs corresponding to dif￾ferent types of distribution functions. We use Code 3.3.1 to draw these graphs.
Figure 3.1 displays these graphs.
Code 3.3.1. Graphs of distribution functions:
par(mfrow=c(2,2),mai=c(0.5,0.5,0.5,0.1)); n=1000
#Part I: Discrete uniform on {0,1,2,3}
x=seq(from=-1,to=4,length=n)
F3=function(z)
{
if(z<0) Fz=0
if(z>=0 && z<1) Fz=1/4
if(z>=1 && z<2) Fz=1/2
if(z>=2 && z<3) Fz=3/4
if(z>=3) Fz=1
return(Fz)
}
y=c()
for(i in 1:n)
{
y[i]=F3(x[i])
}
plot(x,y,type="l",col="dark blue",lwd=2,xlab="x",ylab="F3(x)",150 Distribution Function
main="Discrete Uniform on {0,1,2,3}")
lines(x=c(0,1,2,3),y=c(F3(0),F3(1),F3(2),F3(3)),type="p",pch=16,
col=2,cex=2)
#Part II: Uniform distribution on (0,3)
a=0; b=3
F2=function(z)
{
if(z<a) Fz=0
if(z>=a && z<b) Fz=(z-a)/(b-a)
if(z>b) Fz=1
return(Fz)
}
y=c()
for(i in 1:n)
{
y[i]=F2(x[i])
}
plot(x,y,type="l",col="dark blue",lwd=2,xlab="x",ylab="F2(x)",
main="Uniform Distribution on (0,3)")
#Part III: Mixture distribution from Ex 3.3.1
x=seq(from=-3,to=7,length=n)
F1=function(z)
{
Fz=c()
if(z< -2) Fz=0
if(z>=-2 && z<0) Fz=1/3
if(z>=0 && z<5) Fz=0.5
if(z>=5 && z<6) Fz=0.5+(z-5)^2/2
if(z>=6) Fz=1
return(Fz)
}
y=c()
for(i in 1:n)
{
y[i]=F1(x[i])
}
plot(x,y,type="l",col="dark blue",lwd=2,xlab="x",ylab="F1(x)",
main="DF: Ex 3.3.1")
lines(x=c(-2,0),y=c(F1(-2),F1(0)),type="p",pch=16,col=2,cex=2)Decomposition of a Distribution Function 151
#Part IV: Mixture distribution from Ex 3.3.2 and its components
x=seq(from=-1,to=4,length=n)
F1=function(z)
{
Fz=c()
if(z<0) Fz=0
if(z>=0 && z<1) Fz=0.25
if(z>=1 && z<2) Fz=0.5
if(z>=2 && z<3) Fz=0.5+(z-2)/2
if(z>=3) Fz=1
return(Fz)
}
F2=function(z)
{
Fz=c()
if(z<0) Fz=0
if(z>=0 && z<1) Fz=0.5
if(z>=1 ) Fz=1
return(Fz)
}
F3=function(z)
{
Fz=c()
if(z<2) Fz=0
if(z>=2 && z<3) Fz=z-2
if(z>=3 ) Fz=1
return(Fz)
}
y1=y2=y3=c()
for(i in 1:n)
{
y1[i]=F1(x[i])
y2[i]=F2(x[i])
y3[i]=F3(x[i])
}
plot(x,y1,type="l",col="dark blue",lwd=2,xlab="x",ylab="F1(x)",
main="DF & its components:Ex 3.3.2")
lines(x,y2,type="l",col="dark red",lwd=2,lty=2)
lines(x,y3,type="l",col="dark green",lwd=2,lty=3)152 Distribution Function
lines(x=c(0,1),y=c(F1(0),F1(1)),type="p",pch=16,col=2,cex=2)
legend("topleft",legend=c("Mixture","Discrete","Continuous"),
col=c("dark blue","dark red", "dark green"),lty=1:3,
lwd=c(1.5,2,2),bty="n")
From Figure 3.1, we note the nature of the following different types of
distribution functions. (i) The upper left panel of Figure 3.1 shows the graph
of a distribution function of the discrete uniform distribution with support
{0, 1, 2, 3}. Observe that it is a step function with jump of the same size 1/4
at each of the four points of discontinuity. (ii) The upper right panel shows the
graph of a distribution function of the continuous uniform distribution with
support (0, 3). On the support, the graph is a straight line with slope 1/3.
(iii) The lower left panel shows the graph of a distribution function discussed
in Example 3.3.1, which is neither discrete nor continuous. (iv) The lower
right panel shows the graph of a distribution function discussed in Example
3.3.2, which is also neither discrete nor continuous. In Example 3.3.2, we have
decomposed it into discrete and continuous components. In this panel, the
graphs of discrete and continuous components are imposed on the graph of
the distribution function.
FIGURE 3.1
Distribution FunctionsDecomposition of a Distribution Function 153
□
Example 3.3.4. Suppose F is a distribution function of a random variable
X. In this example we express the distribution functions of (i) X+, (ii) X−,
(iii) |X| and (iv) −X in terms of F. Suppose P[X > 0] = p ≥ 0 and
P[X ≤ 0] = 1 − p = q = F(0) ≥ 0.
(i) By the definition of X+, it is a non-negative random variable defined as,
X+ =

X, if X > 0,
0, if X ≤ 0.
For x < 0, FX+ (x) = P[X+ ≤ x] = 0, for x = 0, FX+ (0) = P[X+ = 0] =
P[X ≤ 0] = q = F(0) and for x > 0
FX+ (x) = P[X+ ≤ x] = P[X+ = 0] + P[0 < X+ ≤ x]
= P[X ≤ 0] + P[0 < X+ ≤ x, X > 0] + P[0 < X+ ≤ x, X ≤ 0]
= q + P[0 < X ≤ x] + 0 = q + (F(x) − F(0)) = F(x).
Thus, FX+ (x) is given by,
FX+ (x) =



0, if x < 0,
q = F(0), if x = 0,
q + (F(x) − F(0)) = F(x), if x > 0.
That is,
FX+ (x) = 
0, if x < 0,
F(x), if x ≥ 0.
Observe that when q > 0, 0 is a point of discontinuity, with size of discontinuity
to be q. Further, right hand limit at 0 is q, since F is right continuous at 0.
Further, limx→∞ FX+ (x) = 1. Thus, if q > 0, then the distribution function
of X+ is neither discrete nor continuous. If q = 0, then X+ distributed as X.
(ii) By the definition of X−,
X− =

−X, if X ≤ 0,
0, if X > 0.
Note that X− is a non-negative random variable. Hence, for x < 0, FX− (x) =
0. For x = 0, FX− (0) = P[X− = 0] = P[X ≥ 0] = 1 − F(0−) . Now for x > 0,
FX− (x) = P[X− ≤ x] = P[X− ≤ 0] + P[0 < X− ≤ x]
= 1 − F(0−) + P[0 < X− ≤ x, X ≤ 0] + P[0 < X− ≤ x, X > 0]
= 1 − F(0−) + P[0 < −X ≤ x] + 0
= 1 − F(0−) + P[−x ≤ X < 0]
= 1 − F(0−) + P[X < 0] − P[X < −x]
= 1 − F(0−) + F(0−) − F(−x−) = 1 − F(−x−)154 Distribution Function
Thus, FX− (x) is given by,
FX− (x) = 
0, if x < 0,
1 − F(−x−), if x ≥ 0.
Observe that 0 is a point of discontinuity with size 1 − F(0−), that is,
1 − P[X < 0] = P[X ≥ 0]. Further, right hand limit at 0 is 1 − F(0−). Note
that, limx→∞ FX− (x) = 1. Thus, if 1 − F(0−) > 0, then the distribution
function of X− is neither discrete nor continuous.
(iii) Since |X| is a non-negative random variable, for x < 0, F|X|(x) = 0. If
x = 0, then F|X|(0) = P[|X| ≤ 0] = P[X = 0]. For x > 0,
F|X|(x) = P[|X| ≤ x] = P[−x ≤ X ≤ x] = F(x) − F(−x−).
(iv) It is clear that for x ∈ R,
F−X(x) = P[−X ≤ x] = P[X ≥ −x] = 1 − P[X < −x] = 1 − F(−x−). □
Example 3.3.5. Suppose a random variable X follows either a Cauchy
C(0, 1) distribution or the Laplace distribution with location parameter 0 and
scale parameter 1, or the standard normal distribution. All the three distribu￾tions are symmetric around 0 and for each, the value of p and q as defined in
Example 3.3.4, is 1/2. Thus, the distribution functions of X+ and of X− are
neither discrete nor continuous. In all the cases 0 is a point of discontinuity
with size 1/2 and the distributions of X+ and of X− are the same. In the
next example, we demonstrate it for the Cauchy distribution. □
Example 3.3.6. In this example we plot the distribution functions of X, X+,
X− and |X| in two cases: (i) when X follows the Cauchy C(0, 1) distribution,
which is symmetric around 0 and (ii) when X is discrete random variable with
finite support and asymmetric probability distribution.
(i) When X ∼ C(0, 1), its distribution function F is F(x) = 1/2 +
tan−1
(x)/π,
x ∈ R. For x < 0, the values of the distribution function of X+ and X−
are 0, there is a discontinuity at x = 0 with size 1/2, while for x > 0,
these are respectively given by F(x) and 1 − F(−x) = F(x), due to
symmetry. Thus, for x > 0, the values of the distribution function of X,
X+ and X− are the same. Again it is a consequence of the symmetry of
the Cauchy C(0, 1) distribution around 0. The values of the distribution
function of |X| are 0 for x < 0 and F(x) − F(−x) for x ≥ 0. At x = 0 it
is 0. Thus, the distribution function of |X| is a continuous function. We
note these features in the graph in the left panel of Figure 3.2.
(ii) Suppose X is a discrete random variable with support {−2, −1, 0, 1, 2, 3}
with respective probabilities {0.2, 0.3, 0.1, 0.1, 0.2, 0.1}. Note that the
distribution of X is not symmetric. Further, X+ is a discrete ran￾dom variable with support {0, 1, 2, 3} with respective probabilitiesDecomposition of a Distribution Function 155
{0.6, 0.1, 0.2, 0.1}, X− is a discrete random variable with support {0, 1, 2}
with respective probabilities {0.5, 0.3, 0.2}. Observe that the distri￾butions of X+ and X− are different. Note that |X| is a discrete
random variable with support {0, 1, 2, 3} with respective probabilities
{0.1, 0.4, 0.4, 0.1} and its distribution is different from that of X+. The
right panel of Figure 3.2 displays the distribution functions correspond￾ing to these four random variables. We use the following code to draw
these graphs.
Code 3.3.2. Graphs of distribution functions of X, X+, X− and |X|:
par(mfrow=c(1,2),mai=c(0.5,0.5,0.5,0.1)); n=1000
x=seq(from=-5,to=5,length=n)
y=pcauchy(x) # DF of X
x1=seq(from=-5,to=0,length=n/2); y1=rep(0,n/2)
x2=seq(from=0,to=5,length=n/2)
y2=pcauchy(x2); x3=c(x1,x2);y3=c(y1,y2) #DF of X+
y4=1-pcauchy(-x2);y5=c(y1,y4) # DF of X￾y6=pcauchy(x2)-pcauchy(-x2); y7=c(y1,y6) # Df of |X|
plot(x,y,type="l",col="black",xlab="x",lty=1,ylim=c(0,1),
main="Symmetric Distribution",lwd=2)
lines(x3,y3,type="l",col="blue",xlab="x",lty=2,lwd=2)
lines(x,y5,type="l",col="dark red",xlab="x",lty=5,lwd=2)
lines(x,y7,type="l",col="dark green",xlab="x",lty=6,lwd=2)
y8=rep(0.5,n/2); lines(x1,y8)
xp=expression(paste(X^"+")); xm=expression(paste(X^"-"))
legend("topleft",legend=c("X",xp,xm,"|X|"),lty=c(1,2,5,6),
lwd=2,
col=c("black","blue","dark red","dark green"))
## Discrete random variable
Fx=function(z)
{
if(z< -2) Fz=0
if(z>=-2 && z< -1) Fz=0.2
if(z>=-1 && z<0) Fz=0.5
if(z>=0 && z<1) Fz=0.6
if(z>=1 && z<2) Fz=0.7
if(z>=2 && z<3) Fz=0.9
if(z>=3) Fz=1
return(Fz)
}
Fxp=function(z)156 Distribution Function
{
if(z<0) Fz=0
if(z>=0&& z< 1) Fz=0.6
if(z>=1 && z<2) Fz=0.7
if(z>=2 && z<3) Fz=0.9
if(z>=3) Fz=1
return(Fz)
}
Fxm=function(z)
{
if(z<0) Fz=0
if(z>=0&& z< 1) Fz=0.5
if(z>=1 && z<2) Fz=0.8
if(z>=2) Fz=1
return(Fz)
}
Fmodx=function(z)
{
if(z<0) Fz=0
if(z>=0&& z< 1) Fz=0.1
if(z>=1 && z<2) Fz=0.5
if(z>=2 && z<3) Fz=0.9
if(z>=3) Fz=1
return(Fz)
}
a=-3; b=4; n=1000; y1=y2=y3=y4=c()
x=seq(from=a,to=b,length=n)
for(i in 1:n)
{
y1[i]=Fx(x[i])
y2[i]=Fxp(x[i])
y3[i]=Fxm(x[i])
y4[i]=Fmodx(x[i])
}
plot(x,y1,type="l",col="black",lwd=2,xlab="x",lty=1,
main="Asymmetric Distribution")
points(x=c(-2,-1,0,1,2,3),y=c(.2,.5,.6,.7,.9,1),type="p",
pch=20,col="black",cex=2)
lines(x,y2,type="l",col="blue",lty=2,lwd=2)Decomposition of a Distribution Function 157
points(x=c(0,1,2,3),y=c(.6,.7,.9,1),type="p",pch=20,
col="blue",cex=2)
lines(x,y3,type="l",col="dark red",lty=5,lwd=2)
points(x=c(0,1,2),y=c(.5,.8,1),type="p",pch=20,
col="dark red",cex=2)
lines(x,y4,type="l",col="dark green",lty=6,lwd=2)
points(x=c(0,1,2,3),y=c(.1,.5,.9,1),type="p",pch=20,
col="dark green",cex=2)
legend("topleft",legend=c("X",xp,xm,"|X|"),lty=c(1,2,5,6),
lwd=2,col=c("black","blue","dark red","dark green"))
Observe that in the left panel of the Figure 3.2, there is a discontinuity
at x = 0 with size 1/2 in the graphs corresponding to the distribution
functions of X+ and X−. Further for x > 0, the graphs of the distribution
function of X, X+ and X− coincide. The right panel of the Figure 3.2
displays the graphs of four discrete distribution functions. These are
step functions with size of the jump at discontinuity points to be the
probability attached with the discontinuity point. □
FIGURE 3.2
Distribution Functions of X, X+, X− and |X|158 Distribution Function
In the next section, we now extend the concept of distribution function of
a random variable to a distribution function of a random vector.
3.4 Distribution Function of a Random Vector
We begin with a bivariate random vector.
Definition 3.4.1. Distribution function of a bivariate random vector: Sup￾pose a random vector Z = (X1, X2)
′
is defined on a probability space (Ω, A, P)
to a probability space (R
2
, B
2
, PZ). Then the distribution function FZ(.) of Z
is defined on R
2 as follows. Suppose z = (x1, x2)
′ ∈ R
2
.
FZ(z) = P{ω | X1(ω) ≤ x1, X2(ω) ≤ x2}
= P

X
−1
1
((−∞, x1)) ∩ X
−1
2
((−∞, x2))
.
As in the setup of a random variable, FZ(z) is a point function with
domain as R
2 and range [0, 1]. Observe that if x2 → ∞ in FZ(z), then
X
−1
2
((−∞, ∞)) = Ω and hence
lim x2→∞
FZ(x1, x2) = P

X
−1
1
((−∞, x1)) ∩ Ω

= P{ω | X1(ω) ≤ x1} = FX1
(x1).
Similarly, if x1 → ∞ in FZ(z), we get
lim x1→∞
FZ(x1, x2) = P

Ω ∩ X
−1
2
((−∞, x2))
= P{ω | X2(ω) ≤ x2} = FX2
(x2).
We state below the properties of FZ(z).
(i) lim x1→∞
FZ(x1, x2) = FX2
(x2).
(ii) lim x2→∞
FZ(x1, x2) = FX1
(x1).
(iii) lim x1→−∞
FZ(x1, x2) = lim x2→−∞
FZ(x1, x2) = 0.
(iv) lim x1,x2→∞
FZ(x1, x2) = 1.
(v) If a1, a2, b1, b2 are real numbers such that a1 ≤ a2 and b1 ≤ b2, then
FZ(a2, b2) − FZ(a1, b2) − FZ(a2, b1) + FZ(a1, b1) ≥ 0.
The function FZ(.) is known as a joint distribution function of (X1, X2)
′
,
while FX1
(.) and FX2
(.) are known as the marginal distribution functions
to emphasize that it is a distribution function of a component variable in a
bivariate setup. The property (v) is analogous to the non-decreasing property
of univariate distribution function. This expression gives P[a1 < X1 ≤ a2, b1 <
X2 ≤ b2] and hence it must be non-negative. Distribution function of a k￾variate random vector is defined analogously.Distribution Function of a Random Vector 159
Definition 3.4.2. Distribution function of a k-variate random vector: Sup￾pose a random vector Z = (X1, X2, · · · , Xk)
′
is defined on a probability space
(Ω, A, P) to a probability space (R
k
, B
k
, PZ). Then the distribution function,
FZ(.) of Z is defined on R
k as follows. Suppose z = (x1, x2, · · · , xk)
′ ∈ R
k
.
FZ(z) = P{ω | Xi(ω) ≤ xi
, i = 1, 2, · · · , k} = P
h \
k
i=1
X
−1
i
((−∞, xi
])i
.
Properties of a Distribution Function of a Random Vector
(i) lim x1→∞
FZ(x1, x2, · · · , xk) = FX2,X3,··· ,Xk
(x2, x3, · · · , xk).
If further we allow x2 → ∞, then we get the distribution function of
(X3, X4, · · · , Xk)
′
. In this manner distribution function of a random vec￾tor of lower dimensions can be derived.
(ii) lim xi→−∞
FZ(x1, x2, · · · , xk) = 0, for any i = 1, 2, · · · , k.
(iii) lim
xi→∞ ∀ i
FZ(x1, x2, · · · , xk) = 1.
The quick recap of the results discussed in this chapter is given below.
Summary
1. Suppose X is a random variable defined on the probability space (Ω, A, P).
Then the distribution function FX(.) of X is defined on R as
FX(x) = P
￾
X−1
((−∞, x]

= P{ω | X(ω) ≤ x} = P[X ≤ x], x ∈ R.
2. Correspondence theorem: Every probability measure P
∗ on (R, B)
uniquely determines a distribution function through the correspondence
F(x) = P
∗
((−∞, x]), x ∈ R with F(−∞) = 0 and F(∞) = 1. Conversely,
if F(x) is specified for each x ∈ R, then the probability measure P
∗ on
(R, B) is determined uniquely through the relation P
∗
((−∞, x]) = F(x).
3. A distribution function FX(x) of a random variable X satisfies the follow￾ing properties. (i) 0 ≤ FX(x) ≤ 1. (ii) FX(x) is a non-decreasing function
on R. (iii) FX(x) is a right continuous function on R and
(iv) limx→∞ FX(x) = 1 and limx→−∞ FX(x) = 0. Conversely, if a function
g : R → R satisfies these four properties, then there exists a probability
space on which one can define a random variable whose distribution func￾tion is the given function g.
4. A set of values of x ∈ R for which F(x) increases is known as a support
of a distribution function160 Distribution Function
5. If F(x) is not continuous from left at x ∈ R, that is, if limh→0 FX(x−h) =
F(x−) ̸= F(x), then x is said to be a point of discontinuity of F(x) and
px = F(x) − F(x−) is the size of discontinuity of F at x or the magnitude
of the jump at x.
6. A set of points of discontinuity of F is at most countable.
7. A point x ∈ R is said to be a point of increase of FX(x) if ∀ ϵ > 0,
FX(x + ϵ) − FX(x − ϵ) > 0.
8. A random variable X or its distribution function F is said to be discrete, if
all points of increase of F are its points of discontinuities. Suppose D is a
set of points of discontinuity of F and px, x ∈ D is the size of discontinuity
at x. Then the set {(x, px) | x ∈ D} is a probability mass function of a
discrete random variable X.
9. A random variable X or its distribution function F is said to be continuous,
if the set of points of discontinuity of F is an empty set, that is, if the
distribution function F is continuous on R. A continuous random variable
X or its distribution function F is said to be absolutely continuous, if there
exists a non-negative function f such that FX(b) − FX(a) = R b
a
f(x)dx,
for all a < b. The function f is known as a probability density function of
an absolutely continuous random variable X. If F is differentiable on R,
then f(x) = d
dx FX(x).
10. Every distribution function can be uniquely expressed as,
F = l1F1 + l2F2, where l1, l2 ≥ 0 and l1 + l2 = 1,
where F1 is a discrete distribution function and F2 is a continuous distri￾bution function.
11. Suppose a random vector Z = (X1, X2, · · · , Xk)
′
is defined on a prob￾ability space (Ω, A, P) to a probability space (R
k
, B
k
, PZ). Then the
distribution function, FZ(.) of Z is defined on R
k as follows. Suppose
z = (x1, x2, · · · , xk)
′ ∈ R
k
.
FZ(z) = P{ω | Xi(ω) ≤ xi
, i = 1, 2, · · · , k} = P
h \
k
i=1
X
−1
i
((−∞, xi
])i
.
3.5 Conceptual Exercises
3.5.1 Suppose functions F are defined as follows. In each case examine whether
F is a distribution function. If yes, find the set of points of discontinuitiesConceptual Exercises 161
and points of increase. Decompose the distribution function and decide
the type of distribution function F.
(i) F(x) =



0, if x < 0,
x
2
/4, if 0 ≤ x < 2,
1, if x ≥ 2.
(ii) F(x) =



0, if x < 0,
x
2
, if 0 ≤ x ≤
2
3
,
1, if x > 2
3
.
(iii)F(x) = 
0, if x ≤ 1,
1 −
1
x2 , if x > 1.
(iv)F(x) = 
0, if x ≤ 0,
1
2 +
1
2
e
−x
, if x > 0.
(v)F(x) = 
0, if x < 0,
1 −
1
2
e
−x
, if x ≥ 0.
(vi)F(x) =



0, if x < 0,
sin x, if 0 ≤ x < π
2
,
1, if x ≥
π
2
.
(vii) F(x) = sin x, 0 < x < π/2.
(viii) F(x) = sin x, x ∈ R.
(ix)F(x) =



0, if x < 0,
x/2, if 0 ≤ x < 1,
1, if x ≥ 1.
(x) F(x) =



0, if x < 2,
x/3, if 2 ≤ x < 3,
1, if x ≥ 3.
3.5.2 If D is a set of points of discontinuity of a distribution function, give an
example of each of the following types of distribution functions.
(i) D is empty. (ii) D is singleton. (iii) D is finite, but not singleton.
(iv) D is countably infinite. Write the distribution function or the prob￾ability density function or the probability mass function.
3.5.3 A function F : R → R is defined as F(x) = 0 if x ≤ 0 and
F(x) = α + ke−x
2/2
if x > 0. Determine values of α and k so that F is
a distribution function.
3.5.4 Examine whether a convex combination of k distribution functions is a
distribution function.
3.5.5 Does there exist a distribution function F such that ∀ x, y ∈ R
F(x + y) = F(x) + F(y)? Justify your answer.
3.5.6 Suppose F and G are distribution functions of X and Y respectively. If
X > Y on Ω, show that F(x) ≤ G(x) ∀ x ∈ R. Show that the converse
is not true.
3.5.7 Suppose a distribution function F : R → [0, 1] is defined as follows.
F(x) =



0, if x < −2,
0.2, if −2 ≤ x < 1,
0.2 + x
2/10, if 1 ≤ x < 2,
0.6 + x/10, if 2 ≤ x < 3,
1, if x ≥ 3.
Decompose F into discrete and continuous components. Identify the
distributions in the decomposition.162 Distribution Function
3.5.8 Suppose a distribution function F : R → [0, 1] is defined as follows.
F(x) =



0, if x < 0,
(pr + (1 − p)x)/5, if r ≤ x < r + 1, r = 0, 1, · · · , 4,
1, if x ≥ 5,
0 < p < 1. Examine whether F is a distribution function. If yes, decom￾pose F into discrete and continuous components. Identify the distribu￾tions in the decomposition.
3.6 Computational Exercises
3.6.1 Suppose a distribution function F : R → [0, 1] is defined as follows.
F(x) =



0, if x < −2,
0.2, if −2 ≤ x < 1,
0.2 + x
2/10, if 1 ≤ x < 2,
0.6 + x/10, if 2 ≤ x < 3,
1, if x ≥ 3.
Draw the graph of the distribution function. On the same graph impose
the graphs of discrete and continuous components.
3.6.2 Suppose X ∼ N(0, 1) Plot the distribution functions of X, X+, X− and
|X|.
3.6.3 Suppose X follows a discrete distribution with with support
{−3, −2, −1, 0, 1, 2, 3, 4} with respective probabilities {0.1, 0.1, 0.2, 0.1,
0.1, 0.2, 0.1, 0.1}. Plot the distribution functions of X, X+, X− and |X|.
3.7 Multiple Choice Questions
Note: In each question, multiple options may be correct. Answers are given
in Chapter 11, after the solutions of conceptual exercises of Chapter 3.
3.7.1 Suppose FX(x) is a distribution function of a random variable X. Then
which of the following is NOT always true?
(a) FX(x) is a non-decreasing function on R
(b) FX(x) is a right continuous function on R
(c) FX(x) is a continuous function on R
(d) 0 ≤ FX(x) ≤ 1Multiple Choice Questions 163
3.7.2 Following are two statements.
(I) X and Y are identically distributed random variables implies X and
Y are identical random variables.
(II) X and Y are identical random variables implies X and Y are iden￾tically distributed random variables.
Then which of the following is true?
(a) Both (I) and (II) are true
(b) (I) is true but (II) is false
(c) (II) is true but (I) is false
(d) Both (I) and (II) are false
3.7.3 For a distribution function, which of the following is NOT true?
(a) Every point of discontinuity is a point of increase
(b) A set of points of discontinuity is at most countable
(c) A set of points of increase is at most countable
(d) Every point of increase is need not be a point of discontinuity
3.7.4 For a distribution function, which of the following need NOT be true?
(a) Every point of discontinuity is a point of increase
(b) A set of points of discontinuity is at most countable
(c) A set of points of increase can be uncountable
(d) Every point of increase is a point of discontinuity
3.7.5 For a distribution function, which of the following is/are always true?
(a) Every point of discontinuity is a point of increase
(b) A set of points of discontinuity is at most countable
(c) A set of points of increase is always uncountable
(d) Every point of increase need not be a point of discontinuity
3.7.6 Which of the following sets can not be a set of discontinuity points of a
distribution function?
(a) D = ∅
(b) D = N
(c) D = {0, 1, 2, 3}
(d) D = (0, ∞)
3.7.7 Which of the following statements is/are always true?
(a) Set of points of increase of a distribution function is dense in R
(b) Set of points of continuity of a distribution function is dense in R
(c) Set of points of discontinuity of a distribution function is dense in
R
(d) None of the above164 Distribution Function
3.7.8 If F1(x) and F2(x) are distribution functions, which of the following
is/are distribution functions?
(a) F(x) = (F1(x) + F2(x))/2
(b) F(x) = F1(x) + F2(x)
(c) F(x) = F1(x) − F2(x)
(d) None of the above
3.7.9 Which of the following functions is/are distribution functions?
(a)
F(x) =



0, x < 0
x/2, 0 ≤ x ≤
2
3
1, x > 2
3
(b)
F(x) =



0, x < 0
sin x, 0 ≤ x < π
2
1, x ≥
π
2
(c)
F(x) = 
0, x ≤ 1
1 − 1/x2
, x > 1
(d)
F(x) = 
0, x ≤ 0
1/2 + e
−x/2, x > 0
3.7.10 If X ∼ B(1, 0.5), which of the following random variables is/are NOT
distributed as X?
(a) Y1 = 1 − X
(b) Y2 = No. of heads in a single toss of a fair coin
(c) Y3 = X2
(d) e
X4
Expectation and Characteristic Function
4.1 Introduction
In Chapter 2 we defined a random variable and its probability distribution.
Probability distribution of a random variable can also be specified in terms
of its distribution function, as noted in Chapter 3. It is of interest to find
some characteristics of a random variable which will summarize its probabil￾ity distribution. Many such characteristics are based on an expectation of a
random variable or expectation of a particular Borel function of a random
variable. We discuss the notion of expectation in this chapter. Mathemati￾cally, expectations are integrals with respect to an arbitrary finite measure in
measure theory, with respect to a probability measure in probability theory
or Riemann Stieltjes integral with respect to the distribution function.
Suppose a random variable X is defined on a probability space (Ω, A, P)
to (R, B, PX). Expectation of a random variable X, denoted by, E(X) or
R
Ω XdP is defined as an integral of X with respect to the probability measure
P. Expectation of a random variable is also known as a mean of a random
variable. Expected value of a random variable is a probabilistic version of the
centre of gravity of a physical body.
Differentiation and integration are two main components of calculus. It is
also true in measure theory or probability theory. We briefly introduce the
concept of an integral with respect to a measure and the theory of Lebesgue
integration. The classical integral is the Riemann integral, which is generalized
to the Riemann-Stieltjes integral. However, it has certain deficiencies which
are overcome by the Lebesgue integral. The Lebesgue integral is an integral
with respect to a Lebesgue measure which is defined below.
Definition 4.1.1. Lebesgue measure: The Lebesgue measure λ is a measure
on the measurable space (R, B) defined as
λ((a, b]) = b − a ∀ a < b ∈ R.
The Lebesgue integral of a Borel function is defined in three steps, first
for a simple Borel function, then for a non-negative Borel function and for
an arbitrary Borel function. Analogous to a simple random variable, a simple
Borel function is defined as follows.
DOI: 10.1201/9781032619057-4 165166 Expectation and Characteristic Function
Definition 4.1.2. Simple Borel function: A function g on a measurable space
(R, B) to (R, B) defined as g(x) = Pk
i=1 xiISi
(x) where xi ∈ R, i = 1, 2, · · · , k
and {S1, S2, · · · , Sk} is a measurable partition of R, is known as a simple Borel
function.
We also have an analogue of Theorem 2.4.3 for a non-negative Borel func￾tion. It is stated in the following theorem.
Theorem 4.1.1. Suppose g is a non-negative Borel function defined on a
measurable space (R, B) to (R, B). Then there exists a non-decreasing sequence
{gn, n ≥ 1} of non-negative simple Borel functions on a measurable space
(R, B) such that gn → g on R.
We now define the Lebesgue integral R
R
g dλ of a Borel function with re￾spect to a Lebesgue measure. The definition proceeds in three steps as follows.
Definition 4.1.3. Lebesgue integral: Suppose g is a Borel function on a mea￾surable space (R, B) and λ is a Lebesgue measure.
i For a simple Borel function given by g =
Pk
i=1 xiISi
, the Lebesgue integral
R
R
g dλ is defined as R
R
g dλ =
Pk
i=1 xiλ(Si).
ii If g is a non-negative Borel function, then R
R
g dλ = limn→∞ R
R
gn dλ
where {gn, n ≥ 1} is a non-decreasing sequence of non-negative simple
Borel functions such that gn → g on R.
iii For arbitrary Borel function g,
R
R
g dλ =
R
R
g
+ dλ −
R
R
g
− dλ provided at
least one of the integrals on the right hand side is finite.
Remark 4.1.1. If g is a Borel function defined on a measurable space (R, B)
to (R, B), then its integral with respect to any measure µ on (R, B) is defined
on similar lines. In Section 3, we come across with the integral of g with respect
to the induced probability measure.
Observe that an integral of a simple function is a weighted average of
xi
’s with weights as λ(Si), i = 1, 2, · · · , k. The Lebesgue integral and the
Riemann-Stieltjes integral are related to each other in the sense that if the
Riemann-Stieltjes integral of a function exists, then the Lebesgue integral also
exists and both are the same.
Using this concept of Lebesgue integration we now define the expectation
of a random variable as an integral with respect to a probability measure.
We proceed exactly on the same three steps, first we define it for a simple
random variable in Section 2, then for a non-negative random variable and for
an arbitrary random variable in Section 3. We discuss a variety of properties
of the expectation of a random variable. Some of these seem to be obvious or
are already known. However, we have now defined expectation as an integral
with respect to a probability measure and hence we have a different approach
to prove these properties. Section 4 is devoted to the important concept of aExpectation of a Simple Random Variable 167
characteristic function and some related results, including inversion theorem,
its versions and uniqueness theorem. Section 5 presents some inequalities con￾cerning moments, which are the expectations of Borel functions of a random
variable. These inequalities are heavily used in the study of convergence of a
sequence of random variables discussed in Chapters 6 and 7.
4.2 Expectation of a Simple Random Variable
We have defined a simple random variable in Section 2.4. Its expectation is
defined as follows.
Definition 4.2.1. Expectation of a simple random variable: Suppose a simple
random variable X on a probability space (Ω, A, P) to (R, B, PX) is defined as,
X =
Pk
i=1 aiIAi
, where {A1, A2, · · · , Ak} is a measurable partition of Ω and
a1, a2, · · · , ak are real numbers. Then E(X) is defined as,
E(X) = Z
Ω
XdP =
X
k
i=1
aiP(Ai).
Note that expectation of a simple random variable may be viewed as a
weighted average of the possible values of X, where weight attached to ai
is
P(Ai). It is also a centre of gravity of the values of X with mass associated with
ai as P(Ai). If P(Ai) = 1/k, then E(X) = (1/k)
Pk
i=1 ai
is the arithmetic
mean of a1, a2, · · · , ak. E(X) gives us an idea of the central value around
which the values of X are spread. Hence, it is known as the measure of central
tendency of X and is termed as the location parameter of the probability
distribution of X.
In the following theorem, we discuss the properties of expectation of a sim￾ple random variable, some of these are required in the definition of expectation
of a non-negative random variable.
Theorem 4.2.1. Suppose X1 and X2 are simple random variables defined on
a probability space (Ω, A, P). Then
(i) E(X1 ± X2) = E(X1) ± E(X2).
(ii) E(aX1) = aE(X1), where a is any real number.
(iii) E(aX1+bX2) = aE(X1)+bE(X2), where a and b are any real numbers.
(iv) If X1 = X2 a.s., then E(X1) = E(X2) (Equivalence).
(v) If X1 ≥ X2 on Ω, then E(X1) ≥ E(X2) (Dominance).
(vi) If X1 ≥ 0 a.s., then E(X1) ≥ 0.168 Expectation and Characteristic Function
(vii) If X1 ≥ X2 a.s. then E(X1) ≥ E(X2) (Dominance).
Proof.
(i) Suppose P1 = {A1, A2, · · · , Ak} and P2 = {B1, B2, · · · , Bl} are measur￾able partitions of Ω and simple random variables X1 and X2 on (Ω, A, P)
are defined as follows.
X1(ω) = X
k
i=1
aiIAi
(ω) & X2(ω) = X
l
j=1
bj IBj
(ω),
where a1, a2, · · · , ak and b1, b2, · · · , bl are any real numbers. Suppose
Cij = Ai ∩ Bj , i = 1, 2, · · · , k and j = 1, 2, · · · , l. In Theorem 2.4.7 it
is proved that {Cij , i = 1, 2, · · · , k, j = 1, 2, · · · , l} forms a measurable
partition of Ω and X1 ± X2 is again a simple random variable given by,
X1 ± X2 =
X
k
i=1
X
l
j=1
(ai ± bj )ICij .
Further, note that for any i = 1, 2, · · · , k,
Ai = Ai ∩ Ω = Ai ∩
X
l
j=1
Bj

=
X
l
j=1
(Ai ∩ Bj )
⇒ P(Ai) = P
X
l
j=1
(Ai ∩ Bj )

=
X
l
j=1
P(Ai ∩ Bj ),
the last equality follows from the finite additivity of the probability mea￾sure P. Similarly, for any j = 1, 2, · · · , l,
Bj =
X
k
i=1
(Ai ∩ Bj ) ⇒ P(Bj ) = X
k
i=1
P(Ai ∩ Bj ).
Now by the definition of expectation of a simple random variable, we
have
E(X1 ± X2) = X
k
i=1
X
l
j=1
(ai ± bj )P(Ai ∩ Bj )
=
X
k
i=1
X
l
j=1
aiP(Ai ∩ Bj ) ±
X
k
i=1
X
l
j=1
bjP(Ai ∩ Bj )
=
X
k
i=1
ai
X
l
j=1
P(Ai ∩ Bj )

±
X
l
j=1
bj
X
k
i=1
P(Ai ∩ Bj )

=
X
k
i=1
aiP(Ai) ±
X
l
j=1
bjP(Bj ) = E(X1) ± E(X2).Expectation of a Simple Random Variable 169
(ii) Since X1 is a simple random variable,
X1(ω) = X
k
i=1
aiIAi
(ω) ⇒ aX1(ω) = X
k
i=1
aaiIAi
(ω),
for any real number a. Thus, aX1 is also a simple random variable.
Hence,
E(aX1) = X
k
i=1
aaiP(Ai) = a
X
k
i=1
aiP(Ai) = aE(X1).
(iii) Observe that
E(aX1 + bX2) = E(aX1) + E(bX2) by (i)
= aE(X1) + bE(X2) by (ii).
(iv) As stated in (i), X1 − X2 =
Pk
i=1
Pl
j=1(ai − bj )ICij is a simple random
variable. Note that X1 = X2 a.s. implies that X1(ω) = X2(ω) ∀ ω ∈ Nc
such that P(N) = 0. Thus, ai − bj = 0 on some partition sets Cij and
union of such sets is Nc
. We define sets A and B as A = {(i, j)|ai −bj =
0} and
B = {(i, j)|ai − bj ̸= 0}, where the number of elements in B is r <
kl. Suppose events Cij are labeled as D1D2, · · · , Dr corresponding to
(i, j) ∈ B. Similarly, ai − bj such that (i, j) ∈ B, are labeled as dm, m =
1, 2, · · · , r. Suppose N =
Sr
m=1 Dm. Since P(N) = 0, P(Dm) = 0 ∀ m =
1, · · · , r. Hence,
E(X1 − X2) = X
k
i=1
X
l
j=1
(ai − bj )P(Cij )
=
X
(i,j)∈A
(ai − bj )P(Cij ) + X
(i,j)∈B
(ai − bj )P(Cij )
=
Xr
m=1
dmP(Dm) = 0 ⇒ E(X1) = E(X2).
(v) As shown in (i) X1 − X2 =
Pk
i=1
Pl
j=1(ai − bj )ICij is a simple random
variable, with (ai − bj ) ≥ 0 ∀ i & j since it is given that X1 ≥ X2 on
Ω. By definition of expectation,
E(X1 − X2) = X
k
i=1
X
l
j=1
(ai − bj )P(Cij )
≥ 0 since (ai − bj ) & P(Cij ) ≥ 0 ∀ i & j
⇒ E(X1) ≥ E(X2).170 Expectation and Characteristic Function
(vi) X1 ≥ 0 a.s. ⇒ X1(ω) ≥ 0, ∀ ω ∈ Nc
such that P(N) = 0. Thus
if, X1(ω) = Pk
i=1 aiIAi
(ω), some a
′
i
s may be negative on some partition
sets Ai
, i = 1, 2, · · · , k, but for such sets P(Ai) = 0. Hence,
E(X1) = X
k
i=1
aiP(Ai) = X
i:ai≥0
aiP(Ai) + X
i:ai<0
aiP(Ai),
where the first summation is over i for which ai ≥ 0 and the second
summation is over i for which ai < 0. Hence, E(X1) ≥ 0, the first term
being non-negative and the second term being 0.
(vii) Note that
X1 ≥ X2 a.s.⇒X1−X2 ≥ 0 a.s.⇒E(X1−X2) ≥ 0 ⇒ E(X1) ≥ E(X2).
We use these properties and Theorem 2.4.3 to define the expectation of a
non-negative and an arbitrary random variable in the next section.
Suppose X is a non-negative simple random variable. Then we have some
more results related to E(X). These are proved in the following theorem.
Theorem 4.2.2. Suppose X is a non-negative simple random variable defined
on a probability space (Ω, A, P).
(i) If X = 0 a.s., then E(X) = 0.
(ii) If E(X) > 0, then P[X > 0] > 0.
(iii) If E(X) = 0, then X = 0 a.s.
(iv) E(XI[X>0]) = E(X).
Proof. X is a non-negative simple random variable. Hence, X can be expressed
as X(ω) = Pk
i=1 aiIAi
(ω), where P1 = {A1, A2, · · · , Ak} is a measurable
partition of Ω and ai ≥ 0 are real numbers.
(i) X = 0 a.s. ⇒ X(ω) = 0, ∀ ω ∈ Nc
such that P(N) = 0. Thus
in X(ω) = Pk
i=1 aiIAi
(ω), some a
′
i
s may be positive on some partition sets
Ai
, i = 1, 2, · · · , k, but for such sets P(Ai) = 0. Hence,
E(X) = X
k
i=1
aiP(Ai) = X
i:ai=0
aiP(Ai) + X
i:ai>0
aiP(Ai),
where the first summation is over i for which ai = 0 and the second summation
is over i for which ai > 0. Hence, E(X1) = 0, the first term being 0 since ai = 0Expectation of Non-Negative and Arbitrary Random Variables 171
and the second term being 0 since P(Ai) = 0.
(ii) Since X ≥ 0, E(X) ≥ 0. From (i)
X = 0 a.s. ⇒ E(X) = 0
Hence, E(X) > 0 ⇒ X ̸= 0 a.s.
⇒ P[X = 0] ̸= 1 ⇒ P[X > 0] > 0.
(iii) We prove X = 0 a.s. by contradiction. Suppose X takes non-zero values
with positive probability, that is, ∃ j ∈ {1, 2, · · · , k} such that aj > 0 and
P(Aj ) > 0. Hence E(X) = Pk
i=1 aiP(Ai) > ajP(Aj ) > 0, which is a contra￾diction to the fact that E(X) = 0. Hence X = 0 a.s.
(iv) Observe that X = XI[X>0] + XI[X=0]. Hence by (i) of Theorem 4.2.1,
E(X) = E(XI[X>0]) + E(XI[X=0]) = E(XI[X>0]) + 0 = E(XI[X>0]).
4.3 Expectation of Non-Negative and Arbitrary
Random Variables
Suppose X is a non-negative random variable defined on a probability space
(Ω, A, P) to (R, B, PX). Then by Theorem 2.4.3 there exists a non-decreasing
sequence {Xn, n ≥ 1} of non-negative simple random variables such that
Xn → X on Ω. Since {Xn, n ≥ 1} is a non-decreasing sequence of simple ran￾dom variables, it follows from result (v) of Theorem 4.2.1, that {E(Xn), n ≥ 1}
is also a non-decreasing sequence of non-negative real numbers and therefore
its limit exists, it may be ∞. Hence, expectation of a non-negative random
variable X is defined as follows.
Definition 4.3.1. Expectation of a non-negative random variable: Suppose
X is a non-negative random variable, then
E(X) = Z
Ω
XdP = limn→∞
E(Xn),
where {Xn, n ≥ 1} is a non-decreasing sequence of non-negative simple ran￾dom variables such that Xn → X on Ω and E(Xn) is as in Definition 4.2.1.
Remark 4.3.1. It is possible that there exist more than one non-decreasing
sequences {Xn, n ≥ 1} of non-negative simple random variables converging to
X on Ω. However, it has been proved in Bhat [4] that for all such sequences,
limn→∞ E(Xn) is the same and hence E(X) is uniquely defined,172 Expectation and Characteristic Function
Suppose X is an arbitrary random variable with X+and X− as its positive
and negative parts respectively. Then X can be expressed as X = X+ −
X−. By definition, X+ and X− are non-negative random variables and their
expectations can be defined as in Definition 4.3.1. Hence, expectation of an
arbitrary random variable X is defined as follows.
Definition 4.3.2. Expectation of an arbitrary random variable: Suppose X is
an arbitrary random variable with X+and X− as its positive and negative parts
respectively. Then E(X) is defined as E(X) = R
Ω XdP = E(X+) − E(X−),
provided at least one of the two E(X+) and E(X−) is finite.
If both E(X+) and E(X−) are infinite then E(X) does not exist as it is of
the form ∞ − ∞. If both E(X+) and E(X−) are finite then E(X) is finite. If
E(X+) is infinite then E(X) exists and is ∞. If E(X−) is infinite then E(X)
exists and is −∞.
Definition 4.3.3. Integrable random variable: A random variable X is said
to be an integrable random variable if E(X) is finite.
Theorem 4.3.1. An arbitrary random variable X is integrable if and only if
both X+and X− are integrable.
Proof. Observe that
X is integrable ⇒ E(X) < ∞ ⇒ E(X+) < ∞ & E(X−) < ∞
⇒ X+ & X−are integrable, conversely,
X+ & X−are integrable ⇒ E(X+) < ∞ & E(X−) < ∞
⇒ E(X) = E(X+) − E(X−) < ∞
⇒ X is integrable.
In the following theorem, we prove some properties of expectation of non￾negative and arbitrary random variables.
Theorem 4.3.2. Suppose X1 and X2 are random variables defined on a prob￾ability space (Ω, A, P) such that E(X1), E(X2) and E(X1) + E(X2) exist.
(i) If X1 ≥ 0 a.s., then E(X1) ≥ 0 (Non-negativity).
(ii) E(cX1) = cE(X1), where c is any real number.
(iii) If X1 = 0 a.s., then E(X1) = 0.
(iv) E(X1 + X2) = E(X1) + E(X2) (Linearity).
(v) E(aX1 + bX2) = aE(X1) + bE(X2), where a, b ∈ R.
(vi) If X1 ≥ X2 a.s., then E(X1) ≥ E(X2).Expectation of Non-Negative and Arbitrary Random Variables 173
(vii) X1 is integrable if and only if |X1| is integrable.
(viii) If |X1| ≤ Y , where Y is an integrable random variable then X1 is inte￾grable.
Proof. (i) X1 ≥ 0 a.s. implies that X1(ω) ≥ 0, ∀ ω ∈ Nc where P(N) = 0.
Further, by Theorem 2.4.3, there exists a non-decreasing sequence {X1n, n ≥
1} of almost surely non-negative simple random variables such that X1n → X1
on Nc
. It is proved in Theorem 4.2.1 that if X1n ≥ 0 a.s. then E(X1n) ≥ 0.
Hence,
E(X1) = limn→∞
E(X1n) ≥ 0.
(ii) Suppose X1 ≥ 0 and c ≥ 0. Since X1 is a non-negative random variable,
there exists a non-decreasing sequence {X1n, n ≥ 1} of non-negative simple
random variables such that X1n → X1 on Ω. For c ≥ 0, cX1n is a non-negative
simple random variable for all n ≥ 1. Thus, {cX1n, n ≥ 1} is a non-decreasing
sequence of non-negative simple random variables such that cX1n → cX1 on
Ω. Hence,
E(cX1) = limn→∞
E(cX1n) = limn→∞
cE(X1n) = c limn→∞
E(X1n) = cE(X1), (4.1)
by result (ii) of Theorem 4.2.1. For arbitrary X1 and c ≥ 0,
cX1 = (cX1)
+ − (cX1)
−. Since c > 0, Observe that
(cX1)
+ =

cX1, if cX1 ≥ 0 ⇐⇒ X1 ≥ 0
0, if cX1 < 0 ⇐⇒ X1 < 0
Hence, (cX1)
+ = cX+
1
. Similarly, it can be shown that (cX1)
− = cX−
1
. Thus,
by definition
E(cX1) = E(cX1)
+ − E(cX1)
− = cE(X
+
1
) − cE(X
−
1
)
= c(E(X
+
1
) − E(X
−
1
)) = cE(X1).
To establish such a relation for non-negative and arbitrary X and for c < 0,
we first prove that E(−X) = −E(X). By definition of a positive part and a
negative part of a random variable, it is noted that,
(−X)
+ = (−X)I[−X≥0] = −XI[X≤0] = X−
and (−X)
− = −(−X)I[−X<0] = XI[X>0] = X+,
which is logically true. Now, by definition of the expectation of an arbitrary
random variable, we have,
E(−X) = Z
Ω
(−X)
+dP −
Z
Ω
(−X)
−dP =
Z
Ω
X−dP −
Z
Ω
X+dP
= −
 Z
Ω
X+dP −
Z
Ω
X−dP
= −E(X). (4.2)174 Expectation and Characteristic Function
Thus, for any random variable X, E(−X) = −E(X). Now suppose X1 ≥ 0
and c < 0. To show that E(cX1) = cE(X1), suppose c = −a, where a > 0 and
Y = aX1. Then
E(cX1) = E(−aX1) = E(−Y ) = −E(Y ) = −E(aX1) = −aE(X1) = cE(X1),
where E(aX1) = aE(X1) follows from (4.1). If X1 is arbitrary and c < 0, we
prove the result E(cX1) = cE(X1) as follows. Note that
E(cX1) = E(−aX1) = E(−Y ) = −E(Y ) by Equation (4.2)
= −(E(Y
+) − E(Y
−)) = −(E((aX1)
+) − E((aX1)
−))
= −(aE(X
+
1
) − aE(X
−
1
)) = −aE(X1) = cE(X1).
Thus, for non-negative and arbitrary random variables E(cX1) = cE(X1),
where c is any real number.
(iii) Observe that,
X1 = 0 a.s. ⇒ X1 ≥ 0 a.s. & − X1 ≥ 0 a.s.
⇒ E(X1) ≥ 0 & − E(X1) ≥ 0 ⇒ E(X1) = 0.
(iv) We first prove the linearity property of expectations for the non-negative
random variables. Since X1 and X2 are non-negative random variables, by
Theorem 2.4.3, there exists a non-decreasing sequence {X1n, n ≥ 1} of non￾negative simple random variables such that X1n → X1 on Ω and a non￾decreasing sequence {X2n, n ≥ 1} of non-negative simple random variables
such that X2n → X2 on Ω. Note that,
(a) X1n → X1, & X2n → X2 on Ω ⇒ X1n + X2n → X1 + X2 on Ω,
(b) X1n ≤ X1(n+1) & X2n ≤ X2(n+1) ⇒ X1n + X2n ≤ X1(n+1) + X2(n+1),
(c) X1n ≥ 0 & X2n ≥ 0 ⇒ X1n + X2n ≥ 0, ∀ n ≥ 1
(d) X1n & X2n are simple ⇒ X1n + X2n are simple
random variables for all n ≥ 1 by Theorem 2.4.4. From (a),(b),(c) and (d), it
follows that {X1n + X2n, n ≥ 1} is a non-decreasing sequence of non-negative
simple random variables such that X1n + X2n → X1 + X2 on Ω. Hence, by
the definition of expectation of a non-negative random variable,
E(X1 + X2) = limn→∞
E(X1n + X2n) = limn→∞
E(X1n) + limn→∞
E(X2n)
= E(X1) + E(X2).
To prove linearity for arbitrary random variables, note that for any A ∈ A
and X ≥ 0 a.s.,
X = XIΩ = X(IA + IAc ) = XIA + XIAc
⇒ E(X) = E(XIA + XIAc ) = E(XIA) + E(XIAc ),Expectation of Non-Negative and Arbitrary Random Variables 175
by linearity of expectation of non-negative random variables. Since
XIA ≥ 0 a.s. and XIAc ≥ 0 a.s., it implies that E(X) is finite if E(XIA)
and E(XIAc ) are finite. This result can be extended to a finite partition of Ω.
Suppose Ω is partitioned into {A1, A2, · · · , A6} as follows.
A1 = [X1 ≥ 0, X2 < 0, X1 + X2 ≥ 0], A2 = [X1 < 0, X2 ≥ 0, X1 + X2 ≥ 0],
A3 = [X1 ≥ 0, X2 ≥ 0, X1 + X2 ≥ 0], A4 = [X1 < 0, X2 ≥ 0, X1 + X2 < 0],
A5 = [X1 ≥ 0, X2 < 0, X1 + X2 < 0], A6 = [X1 < 0, X2 < 0, X1 + X2 < 0] .
Since E(X1), E(X2) and E(X1)+E(X2) exist, we can assume that at least one
of the random variables is integrable, so we assume that X2 is integrable. Now
on A1, X1 + X2 ≥ 0 and −X2 > 0. Hence by linearity property of expectation
of non-negative random variables, we have,
E((X1 + X2)IA1
) + E(−X2IA1
) = E(X1IA1
)
⇒ E((X1 + X2)IA1
) + E(−X2IA1
) + E(X2IA1
) = E(X1IA1
) + E(X2IA1
)
⇒ E((X1 + X2)IA1
) = E(X1IA1
) + E(X2IA1
).
On A2, X1 + X2 ≥ 0 and −X1 > 0, hence
E((X1 + X2)IA2
) + E(−X1IA2
) = E(X2IA1
) < ∞ ⇒ E(X1IA2
) < ∞.
Adding E(X1IA2
) to both sides we have,
E((X1 + X2)IA2
) = E(X1IA2
) + E(X2IA2
).
On A3, X1 ≥ 0, X2 ≥ 0, hence by linearity property of expectation of non￾negative random variables,
E((X1 + X2)IA3
) = E(X1IA3
) + E(X2IA3
).
On A4, −(X1 + X2) ≥ 0, X2 ≥ 0. Hence,
E(−(X1 + X2)IA4
) + E(X2IA4
) = E(−X1IA4
).
Subtracting E(X2IA4
) and changing signs on both sides, we get,
E((X1 + X2)IA4
) = E(X1IA4
) + E(X2IA4
).
Using similar arguments we have,
E((X1 + X2)IA5
) = E(X1IA5
) + E(X2IA5
)
and E((X1 + X2)IA6
) = E(X1IA6
) + E(X2IA6
).
Thus we have,
E(X1IAi
) + E(X2IAi
) = E((X1 + X2)IAi
), i = 1, 2, · · · , 6.176 Expectation and Characteristic Function
From the definition of sets {A1, A2, · · · , A6}, we note that,
E(X1(IA1 + IA3 + IA5
)) = E(X1IA1 + X1IA3 + X1IA5
) = E(X
+
1
)
and E(−X1(IA2 + IA4 + IA6
)) = E(−X1IA2 − X1IA4 − X1IA6
) = E(X
−
1
),
so that P
6
i=1
E(X1IAi
) = E(X1). Similarly,
E(X2(IA2 + IA3 + IA4
)) = E(X
+
2
), E(−X2(IA1 + IA5 + IA6
)) = E(X
−
2
),
and hence, P
6
i=1
E(X2IAi
) = E(X2). Further, on similar lines we get,
P
6
i=1
E((X1+X2)IAi
) = E(X1+X2) and hence, E(X1+X2) = E(X1)+E(X2).
(v) Combining (ii) and (iv) we get, E(aX1+bX2) = aE(X1)+bE(X2), where a
and b are any real numbers. The linearity property is valid for a finite collection
of random variables. It is valid for a countable collection of non-negative ran￾dom variables, which follows from the monotone convergence theorem, which
we prove in Chapter 8.
(vi) Observe that
X1 ≥ X2 a.s. ⇒ X1 − X2 ≥ 0 a.s. ⇒ E(X1 − X2) ≥ 0
⇒ E(X1) ≥ E(X2).
Thus, if X1 = X2 a.s. then E(X1) = E(X2).
(vii) It is given that X1 is integrable, hence E(X
+
1
) and E(X
−
1
) are finite. As
a consequence, using linearity of expectation
E(|X1|) = E(X
+
1 + X
−
1
) = E(X
+
1
) + E(X
−
1
) < ∞ ⇒ |X1| is integrable.
Conversely, suppose |X1| is integrable, then
X1 ≤ |X1| ⇒ E(X1) ≤ E(|X1|) < ∞ ⇒ X1 is integrable.
Alternatively, |X1| is integrable implies
E(|X1|) < ∞ ⇒ E(X
+
1
) < ∞ & E(X
−
1
) < ∞
⇒ E(X1) = E(X
+
1
) − E(X
−
1
) < ∞
⇒ E(X1) is integrable.
(viii) |X1| ≤ Y ⇒ E(|X1|) < E(Y ) < ∞ ⇒ X1 is integrable.
As a consequence of linearity of expectation proved in (iv), we have the
following lemma, which is useful in many derivations.
Lemma 4.3.1. Suppose X is an integrable random variable defined on
(Ω, A, P) and A ∈ A. Then E(X) = R
Ω X dP =
R
A X dP +
R
Ac X dP.Expectation of Non-Negative and Arbitrary Random Variables 177
Proof. From the definition of an indicator function, XIA(ω) = X(ω) if ω ∈ A
and 0 if ω ∈ Ac
. Similarly, XIAc (ω) = X(ω) if ω ∈ Ac and 0 if ω ∈ A. Since
A ∪ Ac = Ω, ∀ ω ∈ Ω, IA(ω) + IAc (ω) = 1. Hence,
E(X) = Z
Ω
X dP =
Z
Ω
X (IA + IAc )dP =
Z
Ω
(XIA + XIAc )dP
=
Z
Ω
XIAdP +
Z
Ω
XIAc dP by linearity of expectation
=
Z
A
XdP +
Z
Ac
XdP.
Theorem 4.3.3. Suppose X is an integrable random variable defined on
(Ω, A, P) and A ∈ A is such that P(A) = 0. Then R
A X dP = 0.
Proof. As in Lemma 4.3.1, XIA(ω) = X(ω) if ω ∈ A and it is 0 if ω ∈ Ac
. By
the definition of expectation,
E(XIA) = Z
Ω
XIA dP =
Z
A
XIA dP+
Z
Ac
XIA dP =
Z
A
XIA dP =
Z
A
X dP .
We prove the result R
A X dP = E(XIA) = 0 in three steps as we have defined
E(X) in three steps.
Case(i) Suppose X is a simple random variable given by
X(ω) = Pk
i=1 aiIAi
(ω), where {A1, A2, · · · , Ak} is a measurable partitions of
Ω. Then XIA can be expressed as XIA(ω) = Pk
i=1 aiIAi∩A(ω). Thus, XIA
is also a simple random variable and hence by the definition of the expectation
of a simple random variable, we have
Z
A
X dP = E(XIA) = X
k
i=1
aiP(Ai ∩ A) = 0 ,
since for each i = 1, 2 · · · , k, P(Ai ∩ A) ≤ P(A) = 0.
Case(ii) Suppose X is a non-negative random variable, then there exists a non￾decreasing sequence {Xn, n ≥ 1} of non-negative simple random variables such
that Xn → X on Ω. As noted in case (i) for each n ≥ 1, XnIA is a simple
random variable. Further, Xn ≤ Xn+1 ⇒ XnIA ≤ Xn+1IA ∀ n ≥ 1. Now
Xn → X on Ω implies that for each ω ∈ Ω, given ϵ > 0 ∃ n0(ϵ, ω) such that
|Xn − X| < ϵ. Hence,
|XnIA −XIA| = |Xn −X||IA| ≤ |Xn −X| < ϵ ∀ n0(ϵ, ω) ⇒ XnIA → XIA
on Ω. Thus, {XnIA, n ≥ 1} is a non-decreasing sequence of non-negative
simple random variables converging to XIA on Ω and hence by the definition
of expectation of a non-negative random variable,
Z
A
X dP = E(XIA) = limn→∞
E(XnIA) = 0 ,178 Expectation and Characteristic Function
by case(i).
Case(iii) Suppose X is an arbitrary random variable. Then
X = X+ − X− ⇒ XIA = (X+ − X−)IA = X+IA − X−IA.
Hence by linearity property of expectation and case(ii),
Z
A
X dP = E(XIA) = E(X+IA − X−IA) = E(X+IA) − E(X−IA) = 0.
We will prove the same result in Chapter 5, using another method. The
result is parallel to the result that the Riemann integral R a
a
h(x) dx = 0. In this
case the Lebesgue measure of (a, a) is 0. Similarly if the probability measure
of the event A is 0, then R
A X dP = 0.
In Chapter 2, we have proved that Borel function of a random variable is
again a random variable and thus we can find its expectation as an integral
over Ω with respect to probability measure P. In the next theorem, we discuss
how to find the expectation of a Borel function of a random variable, using
the definition of integral of a Borel function as stated in Remark 4.1.1, with
respect to a probability measure PX(·) on R.
Theorem 4.3.4. Suppose X is a random variable defined on a probability
space (Ω, A, P) to (R, B, PX). Suppose g : (R, B) → (R, B) is a Borel function.
Then,
E(g(X)) = Z
Ω
g(X)dP =
Z
R
g(x)dPX.
Proof. The result is proved in three steps as follows.
Case(i) Suppose g is a simple Borel function given by g(x) = Pm
j=1 aj ISj
(x),
x, aj ∈ R, Sj ∈ B, j = 1, 2, · · · , m, where {S1, S2, · · · , Sm} is a measurable
partition of R. Hence as stated in Remark 4.1.1,
Z
R
g(x)dPX =
Xm
j=1
ajPX(Sj ). (4.3)
Now to find R
Ω
g(X)dP, we have to find out the nature of g(X). Observe that,
g(X)(ω) = g(X(ω)) = aj if X(ω) ∈ Sj ⇐⇒ ω ∈ X−1
(Sj )
⇐⇒ g(X) = Xm
j=1
aj IX−1(Sj )
,
where {X−1
(S1), X−1
(S2), · · · , X−1
(Sm)} is a measurable partition of Ω.
Thus, g(X) is a simple random variable on (Ω, A, P), hence by the definition
of expectation,
E(g(X)) = Z
Ω
g(X)dP =
Xm
j=1
ajP(X−1
(Sj )) = Xm
j=1
ajPX(Sj ) = Z
R
g(x)dPX,Expectation of Non-Negative and Arbitrary Random Variables 179
the last equality follows from (4.3).
Case(ii) Suppose g is a non-negative Borel function. Then there exists a non￾decreasing sequence {gn, n ≥ 1} of non-negative simple Borel functions such
that gn → g on R. Hence,
Z
R
g(x)dPX = limn→∞ Z
R
gn(x)dPX = limn→∞ Z
Ω
gn(X)dP, (4.4)
by Case(i). Now observe that,
(i) g(X)(ω) = g(X(ω)) ≥ 0, ∀ X(ω) ∈ R ⇐⇒ ∀ ω ∈ X−1
(R) = Ω.
Thus, g(X) is a non-negative random variable on (Ω, A, P).
(ii) gn → g on R ⇒ gn(X(ω)) → g(X(ω)) on Ω .
(iii) For each n ≥ 1, gn is a simple Borel function, hence as shown in Case(i),
for each n, gn(X) is a simple random variable on (Ω, A, P).
(iv) Further the sequence {gn, n ≥ 1} is non-decreasing implies that
{gn(X), n ≥ 1} is also a non-decreasing sequence of simple random vari￾ables.
Hence by the definition of expectation of a non-negative random variable and
(4.4),
E(g(X)) =Z
Ω
g(X)dP = limn→∞ Z
Ω
gn(X)dP = limn→∞ Z
R
gn(x)dPX =
Z
R
g(x)dPX .
Case(iii) Suppose g is an arbitrary function. Then g = g
+ − g
− where g
+
and g
− are positive and negative parts of g respectively. Further both these
are non-negative Borel functions. Hence, by the definition of expectation and
Case(ii) we have,
Z
R
g(x)dPX =
Z
R
g
+(x)dPX −
Z
R
g
−(x)dPX =
Z
Ω
g
+(X)dP −
Z
Ω
g
−(X)dP.
(4.5)
Now, observe that
(g(X))+(ω) = 
g(X)(ω) = g(X(ω)), if g(X(ω)) ≥ 0,
0, otherwise.
Now, for ω ∈ Ω, X(ω) = x ∈ R and hence
(g(X))+(ω) = 
g(x), if g(x) ≥ 0,
0, otherwise.
Thus,
(g(X))+(ω) = g
+(x) = g
+(X(ω)), ∀ ω ∈ Ω ⇐⇒ (g(X))+ = g
+(X).180 Expectation and Characteristic Function
On similar lines we get (g(X))− = g
−(X). Hence, by (4.5)
E(g(X)) = Z
Ω
g(X)dP =
Z
Ω
(g(X))+dP −
Z
Ω
(g(X))−dP
=
Z
Ω
g
+(X)dP −
Z
Ω
g
−(X)dP
=
Z
R
g
+(x)dPX −
Z
R
g
−(x)dPX by Case(ii)
=
Z
R
g(x)dPX.
Remark 4.3.2. In Section 2.4, we have proved that if X is a simple random
variable, then for any function g, g(X) is also a simple random variable. From
Case(i) of Theorem 4.3.4, we note that if g is a simple Borel function then for
any random variable X, g(X) is a simple random variable.
Theorem 4.3.4 states that expectation of a random variable can be ob￾tained as an integral with respect to probability measure P or with respect to
induced probability measure PX on Ω and R respectively. Further note that
to compute E(g(X)), it is not necessary to know the distribution of g(X). For
example, suppose X ∼ U(0, 1), then E(sin(X)) = R 1
0
sin x dx = 1−cos(1) and
it is not necessary to compute the distribution of sin(X).
In the correspondence theorem, Theorem 3.1.1, it is proved that there is a
one to one correspondence between the distribution function F and the proba￾bility measure P. Hence, E(X) can also be defined in terms of the distribution
function of X as follows.
E(g(X)) = Z
Ω
g(X)dP =
Z
R
g(x)dPX =
Z
R
g(x)dF(x),
where the last integral is the Riemann-Stieltjes integral.
Depending on the nature of F, the Riemann-Stieltjes integral can be ob￾tained as follows.
(i) Suppose F is a discrete distribution function with set D = {xi
, i ≥ 1}
as a set of points of discontinuity with pxi
as the size of jump at xi
, i ≥ 1,
that is, X is a discrete random variable with probability mass function as
{(xi
, pxi
), i ≥ 1}. In such a setup F is a step function with steps at xi with
jump size pxi
, i ≥ 1. From the definition of the Riemann-Stieltjes integral for
a step function F, the expectation of any Borel function g of X is given by,
E(g(X)) = Z
R
g(x)dF(x) = X
i≥1
g(xi)pxi
.
Note that
P
g(X) is integrable if |g(X)| is integrable, that is, if the series
i≥1
|g(xi)|pxi
is convergent.Expectation of Non-Negative and Arbitrary Random Variables 181
(ii) Suppose F is a continuous distribution function and in addition if it is
differentiable function with derivative d
dx F(x) = f(x), then from the definition
of the Riemann-Stieltjes integral for a differentiable function F, we have
E(g(X)) = Z
R
g(x)dF(x) = Z
R
g(x)f(x)dx.
Using this formula in the next example it is shown that the mean of a Cauchy
distribution does not exist.
Example 4.3.1. Suppose a random variable X follows Cauchy C(0, 1) dis￾tribution with location parameter 0, scale parameter 1 and the probability
density function f(x) = (1/π)(1/(1 + x
2
)), x ∈ R. We examine whether
E(X+) is finite using the following result. Suppose gr(x) and hs(x) are poly￾nomial functions of degree r and s respectively. Then R ∞
0
gr(x)/hs(x) dx
is convergent if and only if s − r ≥ 2. Now E(X+) is given by, E(X+) =
R ∞
0
(1/π)(x/(1 + x
2
)) dx. Observe that it is a divergent integral as s − r = 1.
On similar lines, it follows that E(X−) is also divergent. Hence, the mean of
the Cauchy C(0, 1) distribution does not exist. □
If F is neither discrete nor continuous, then we find E(X) as
E(X) = R
R
xdF(x) using the definition of the Riemann-Stieltjes integral. Fol￾lowing example illustrates the computation of E(X) in this setup.
Example 4.3.2. Suppose a distribution function F : R → [0, 1] is defined as
follows.
F(x) =



0, if x < 0,
1/4, if 0 ≤ x < 1,
1/2, if 1 ≤ x < 2,
1/2 + (x − 2)/2, if 2 ≤ x < 3,
1, if x ≥ 3.
In Example 3.3.2, we have noted that F is neither discrete nor continuous.
Thus, we find E(X) using the formula E(X) = R
R
g(x)dF(x) as a Riemann￾Stieltjes integral. Thus, E(X) = Pxpx +
R
xF′
(x) dx, where x in summation
denotes the point of discontinuity and corresponding px denotes the size of
jump at the point of discontinuity. Further integral is over the range when F
is continuous and differentiable with F
′ denoting its derivative. Thus,
E(X) = 0 ×
1
4
+ 1 ×
1
4
+
1
2
Z 3
2
x dx =
1
4
+
5
4
=
3
2
.
In Example 3.3.2, it is shown that F = (1/2)F1 + (1/2)F2 where F1 is a
distribution function of a discrete random variable X1 with probability mass
function given by, P[X1 = 0] = 1/2 = P[X1 = 1] and its mean is (1/2). F2 is
a distribution function of uniform U(2, 3) distribution and its mean is (5/2).
Using this approach E(X) = (1/2)(1/2) + (1/2)(5/2) = 3/2. □182 Expectation and Characteristic Function
Different choices of g in E(g(X)) correspond to various characteristics of
a random variable X. We list these below.
(i) If g is an identity function, then E(X) is the expectation of X, also
known as the mean of X.
(ii) If g(x) = x
r
, r > 0 then E(Xr
) is the r-th raw moment of X.
(iii) If g(x) = (x − E(X))r
, r > 0, then E(X − E(X))r
is the r-th central
moment of X.
(iv) If g(x) = (x − a)
r
, r > 0, then E(X − a)
r
is the r-th moment of X
around a.
(v) By taking g(x) = exp(tx), we get E(g(X)) = E(exp(tX)) = MX(t),
where the expectation exists for some values of t, which depends on the
distribution of X. MX(t) is known as a moment generating function of
X.
(vi) Suppose X is a discrete random variable with support as the set W of
whole numbers. Then taking g(x) = s
x
, we get E(g(X)) = E(s
X) =
PX(s), where the expectation exists when |s| ≤ 1. PX(s) is known as a
probability generating function of X.
The existence of a mean clearly depends on how quickly tails decay. Fol￾lowing two theorems support this assertion. For a discrete random variable
with support as the set W of whole numbers and for a continuous random
variable, we have one more procedure to find E(X). It is in terms of right tail
probabilities. We derive these formulae in the following theorems.
Theorem 4.3.5. Suppose X is a discrete random variable with support as
the set W of whole numbers and suppose P[X = i] = pi
, i ∈ W. Then
E(X) = P
n≥1 P[X ≥ n].
Proof. We have
E(X) = Z
R
xdF(x) = X
i≥0
ipi =
X
i≥1
ipi = p1 + 2p2 + 3p3 + · · · ,
= (p1 + p2 + p3 + · · · ,) + (p2 + p3 + · · · ,) + (p3 + p4 + · · · ,) + · · ·
= P[X ≥ 1] + P[X ≥ 2] + P[X ≥ 3] + · · · =
X
n≥1
P[X ≥ n].
Alternatively, E(X) = Z
R
xdF(x) = X
i≥0
ipi =
X
i≥1
ipi =
X∞
i=1
X
i
n=1
pi
=
X∞
n=1
X∞
i=n
pi =
X
n≥1
P[X ≥ n].Expectation of Non-Negative and Arbitrary Random Variables 183
Theorem 4.3.6. Suppose X is a continuous random variable with distribution
function F. Suppose F is differentiable with derivative f(x). Then
E(X) =



R∞
0
[1 − F(x)]dx, if X ≥ 0,
R∞
0
[1 − F(x)]dx −
R
0
−∞
F(x)dx, if X is arbitrary.
Proof. Suppose X ≥ 0, then using integration by parts we have,
Z ∞
0
[1 − F(x)]dx =
Z ∞
0
[1 − F(x)] d
dxx dx = [x(1 − F(x))]∞
0 +
Z ∞
0
xf(x) dx
=
Z ∞
0
xf(x) dx = E(X),
the term [x(1 − F(x))]∞
0
is 0 in view of the fact that (1 − F(x)) → 0 faster
than x → ∞. Thus, for non-negative X,
E(X) = Z ∞
0
[1 − F(x)] dx =
Z ∞
0
S(x) dx =
Z ∞
0
P[X ≥ x] dx,
where 1 − F(x) = S(x) is known as a survival function. Now suppose X is an
arbitrary random variable. Consider
−
Z 0
−∞
F(x) dx = −
Z 0
−∞
F(x)
d
dxx dx = −[xF(x)]0
−∞ +
Z 0
−∞
xf(x) dx
= 0 + Z 0
−∞
xf(x) dx.
Hence,
−
Z 0
∞
F(x) dx +
Z ∞
0
[1 − F(x)]dx =
Z 0
−∞
xf(x) dx +
Z ∞
0
xf(x) dx
=
Z ∞
−∞
xf(x) dx = E(X).
Example 4.3.3. Suppose X follows exponential distribution with scale pa￾rameter θ. We find E(X) using the formula in terms of its distribution func￾tion. The distribution function of X is given by,
F(x) = 
0 if x ≤ 0,
1 − e
−θx
, if x ≥ 0.
Hence, E(X) = Z ∞
0
[1 − F(x)]dx =
Z ∞
0
e
−θxdx = 1/θ. □184 Expectation and Characteristic Function
Example 4.3.4. Suppose X is a discrete random variable such that
P[X = i] = c/ir+2, i = 1, 2, · · · , r ≥ 1 and c is a norming constant. We have
E(Xk
) = P
i≥1
i
k
(c/ir+2) = P
i≥1
c/ir−k+2 and the series is convergent for
all k such that r − k + 2 ≥ 2, that is, k ≤ r and divergent for all k > r.
Hence, moments up to order r are finite, but moments of order higher than r
are infinite. □
Example 4.3.5. Suppose X is a discrete random variable such that
P[X = 2i
] = 2−i
, i = 1, 2, · · · . Observe that
P[X < ∞] = X
i≥1
P[X = 2i
] = X
i≥1
2
−i = 1.
But E(X) = P
i≥1
2
i2
−i = ∞. Thus, even if X is finite, E(X) is infinite. □
So far we discussed the expectation of a random variable. We now define
the expectation of a random vector.
Definition 4.3.4. Expectation of a random vector: Suppose
Z = (X1, X2, · · · , Xk)
′
is a k-variate random vector defined on a probability
space (Ω, A, P) to (R
k
, B
k
, PZ). Then expectation of Z is defined as E(Z) =
(E(X1), E(X1), · · · , E(Xk))′
.
Definition 4.3.5. Expectation of a sequence of random variable: Suppose
Z = {Xn, n ≥ 1} is a sequence of random variables defined on a probability
space (Ω, A, P) to (R∞, B∞, PZ). Then expectation of a sequence of random
variables is defined as a sequence of expectations of component random vari￾ables and it is given by {E(Xn), n ≥ 1}.
Thus, the expectation of a random vector is basically defined in terms
of the expectations of component random variables and hence all the results
developed above for univariate setup are applicable for vector setup as well.
It is known that there is an equivalence between R
2 and a class of complex
numbers. This fact is used to define a complex valued random variable and
its expectation.
Definition 4.3.6. Complex valued random variable and its expectation: Sup￾pose Z = (X, Y )
′
is a bivariate random vector defined on a probability space
(Ω, A, P) to (R
2
, B
2
, PZ). Then W = X + iY is a complex valued random
variable and its expectation is defined as E(W) = E(X) + iE(Y ).
A complex valued random variable W = X + iY is said to be integrable if
and only if both X and Y are integrable. In the following theorem, we prove
that |E(W)| ≤ E(|W|).
Theorem 4.3.7. Suppose W = X + iY is a complex valued random variable,
then
|E(W)| ≤ E(|W|).Characteristic Function 185
Proof. Using polar co-ordinates, a complex valued random variable W can be
expressed as
W = reiθ where r = |W| = (X2 + Y
2
)
1/2 & θ = tan−1
(Y /X).
Suppose E(W) = E(X) + iE(Y ) = αeiβ. Thus,
|E(W)| = α = e
−iβE(W) = e
−iβE(reiθ) = E(rei(θ−β)
)
= E(r cos(θ − β)) complex part is 0 as left hand side is real
≤ E(r) = E(|W|).
In the next section, we discuss a special type of complex valued random
variable and its expectation. It is known as a characteristic function of a ran￾dom variable and it is heavily used in probability theory to derive a variety of
results. We use it in all the subsequent chapters. It is similar to the moment
generating function or probability generating function as defined in this sec￾tion. But we note in the next section that a characteristic function has some
special features and hence it is preferred over other generating functions.
4.4 Characteristic Function
We begin with a definition of a characteristic function.
Definition 4.4.1. Characteristic function of a random variable: The charac￾teristic function ϕX(t) of a random variable X for t ∈ R is defined as
ϕX(t) = E(exp(itX)) = E(costX + isin tX) = E(costX) + iE(sin tX)
=
Z ∞
−∞
exp(itx)dF(x).
Note that for any t ∈ R,
| costX| ≤ 1 & |sin tX| ≤ 1 ⇒ E(costX) ≤ 1 & E(sin tX) ≤ 1.
Thus, real and complex parts are integrable random variables and hence
exp(itX) is an integrable random variable. Consequently, the domain of def￾inition of ϕX(t) = E(exp(itX)) is R. It is an important property of a char￾acteristic function and hence while proving a variety of results in probability
theory, a characteristic function is preferred over other generating functions.
Observe that the moment generating function may not exist for all real num￾bers. For example, if X has exponential distribution with scale parameter θ,
then its moment generating function is given by (1 − t/θ)
−1 and it is defined186 Expectation and Characteristic Function
for all t < θ. On the other hand the characteristic function is (1−it/θ)
−1 and
it is defined for all t ∈ R.
We now discuss some properties of a characteristic function.
(i) If Y = aX + b where a ̸= 0 and b are any real numbers, then a charac￾teristic function of Y is given by,
ϕY (t) = E(e
itY ) = E(e
it(aX+b)
) = e
itbϕX(at).
In particular, if a = −1 and b = 0, then
ϕ−X(t) = ϕX(−t) = E(cos(−tX)) + iE(sin(−tX))
= E(costX) − iE(sin(tX)) = ϕX(t),
a complex conjugate of ϕX(t).
(ii) Suppose the distribution of X is symmetric around 0, then X and−X are
identically distributed, hence they have the same characteristic function.
Thus,
ϕX(t) = ϕ−X(t) = ϕX(−t) = ϕX(t) ⇐⇒ ϕX(t) is a real valued
function for the distribution symmetric around 0.
(iii) If F is defined as F =
Pk
i=1 αiFi
, αi ≥ 0 & Pk
i=1 αi = 1, then it is a
convex combination of distribution functions. Its characteristic function
ϕ(t) is again a convex combination of the characteristic functions ϕi(t) of
component distribution functions and is given by ϕ(t) = Pk
i=1 αiϕi(t).
This result can also be extended to convex combination of countably
many distribution functions.
Table 4.1 lists the characteristic functions of some standard distributions.
To study some more properties of a characteristic function, we first intro￾duce a concept of a random variable and a sequence of random variables being
bounded in probability.
TABLE 4.1
Characteristic Functions of Standard Distribu￾tions
Distribution Characteristic Function
Degenerate at a e
ita
Binomial B(n, p) (1 − p + peit)
n
Geometric Ge(p) p/(1 − (1 − p)e
it)
Poisson P(λ) e
λ(e
it−1)
Uniform U(a, b) (e
itb − e
ita)(it(b − a))
Uniform U(−1, 1) sin t/t
Exponential Exp(α) (1 − it/α)
−1
Gamma G(α, λ) (1 − it/α)
−λ
Normal N(µ, σ2
) e
iµt−t
2σ
2/2
Cauchy C(0, 1) e
−|t|Characteristic Function 187
Definition 4.4.2. A random variables X is said to be bounded in probability
if given ϵ > 0 ∃ M > 0 such that P[|X| > M] < ϵ.
Definition 4.4.3. A sequence of random variables {Xn, n ≥ 1} is said to be
bounded in probability if given ϵ > 0, there exists a constant K and an integer
n0 such that,
P[|Xn| ≤ K] ≥ 1 − ϵ ⇐⇒ P[|Xn| > K] < ϵ, ∀ n ≥ n0.
If a sequence {Xn, n ≥ 1} is bounded in probability, then we write
Xn = Op(1). More generally, if anXn is bounded in probability, then we write
Xn = Op(1/an). In the following example, the sequence is not bounded in
probability.
Example 4.4.1. Suppose {Xn, n ≥ 1} is a sequence of random variables such
that Xn ∼ U(n, n + 1) distribution, n ≥ 1. Hence for any,
K > 0, P[|Xn| > K] = P[Xn > K] = 1, ∀ n > K .
Hence the sequence {Xn, n ≥ 1} is not bounded in probability. □
Following lemma proves that a real random variable is always bounded
in probability. The proof is based on the property of a distribution function
which states that F(x) → 1 as x → ∞ and F(x) → 0 as x → −∞.
Lemma 4.4.1. Suppose X is a random variable defined on a probability space
(Ω, A, P) to (R, B, PX). Then X is bounded in probability.
Proof. Suppose F denotes the distribution function of X, then F(x) → 1 as
x → ∞ and F(x) → 0 as x → −∞. Hence, as x → ∞
P[|X| > x] = P[X > x] + P[X < −x] = 1 − F(x) − F(−x−) → 0,
⇒ given ϵ > 0 ∃ M > 0, such that P[|X| > M] < ϵ .
Thus, X is bounded in probability.
We use Lemma 4.4.1 in the following theorem to establish the uniform
continuity of a characteristic function.
Theorem 4.4.1. Suppose ϕX(t) is a characteristic function of a random
variable X. Then (i) |ϕX(t)| ≤ 1, (ii) ϕX(0) = 1 and (iii) ϕX(·) is uniformly
continuous on R.
Proof. A characteristic function of a random variable X is given by
ϕX(t) = E(exp(itX)) for t ∈ R.
(i) Using Theorem 4.3.7, we have
|ϕX(t)| = |E(costX) + iE(sin tX)| ≤ E(| costX + isin tX|)
= E((cos2
tX + sin2
tX)
1/2
) = 1.188 Expectation and Characteristic Function
(ii) Using the result that cos(0) = 1 and sin(0) = 0, we get ϕX(0) = 1.
(iii) To prove the uniform continuity of a characteristic function, observe that
for t & h ∈ R,
|ϕX(t + h) − ϕX(t)| =




Z ∞
−∞
e
i(t+h)u
dF(u) −
Z ∞
−∞
e
itudF(u)




≤
Z ∞
−∞
|e
itu| |e
ihu − 1|dF(u)
=
Z ∞
−∞
|e
ihu − 1|dF(u) as |e
itu| = 1.
Now X is a real random variable and hence it is bounded in probability,
that is, given ϵ > 0 ∃ M = M(ϵ) > 0 such that P[|X| > M] < ϵ. Note that
for |u| ≤ M,
|e
ihu − 1| = [(cos(hu) − 1)2 + sin2
(hu)]1/2 → 0 as h → 0,
that is, for |u| ≤ M, given ϵ > 0 we can find h0(ϵ) such that |e
ihu − 1| < ϵ for
all |h| < h0(ϵ). Using these results in the above derivation we have,
|ϕX(t + h) − ϕX(t)| ≤ Z ∞
−∞
|e
ihu − 1|dF(u)
=
Z
|u|≤M
|e
ihu − 1|dF(u) + Z
|u|>M
|e
ihu − 1|dF(u)
≤ ϵP[|X| ≤ M] + 2P[|X| > M]
≤ ϵ + 2ϵ ∀ |h| < h0(ϵ).
In the third step, we use the result that |e
ihu − 1| ≤ |e
ihu| + |1| ≤ 2. Thus,
|ϕX(t1)−ϕX(t)| < 3ϵ ∀ t1 ∈ Nh(t) and h does not depend on t. Hence, ϕX(·)
is uniformly continuous on R.
We now discuss the connection between the existence of moments of X
and differentiability of its characteristic function in the following theorems.
We state a theorem below and refer to Loeve [16] for its proof.
Theorem 4.4.2. If the characteristic function of a random variable X is
differentiable n times and has derivatives at t = 0, then all moments up to
order n exist and are finite if n is even and all moments up to order n − 1
exist and are finite if n is odd.
In the following two theorems, the scenario is opposite to the above theo￾rem. We first state a result (see p. 136 of Rao [19]), which specifies a sufficient
condition for the interchange of integration and differentiation. It is to be noted
that differentiation is basically a limit. Hence the lemma is also useful to in￾terchange limit and integration. We prove similar result in Chapter 8, which
allows interchange of limit and expectation, that is, limit and integration. This
lemma is used in the proof of the next theorem and in some more theorems
in this section.Characteristic Function 189
Lemma 4.4.2. Suppose g is a measurable function such that d
dt g(t, x) ex￾ists for t in some set D. If |
d
dt g(t, x)| < G(x) where G is integrable, then
d
dt
R
R
g(t, x)dF(x) = R
R
d
dt g(t, x)dF(x).
Theorem 4.4.3. Suppose ϕX(t) is a characteristic function of a random
variable X. If E(|X|
n) < ∞ where n is a positive integer, then ϕX(t) is
differentiable n times for all t ∈ R and n-th derivative ϕ
(n)
X (t) is given by,
ϕ
(n)
X (t) = d
n
dtn
ϕX(t) = Z ∞
−∞
(ix)
n
e
itxdF(x) & ϕ
(n)
X (0) = i
nE(Xn
).
Proof. It is given that E(|X|
n) < ∞ and hence E(Xn) < ∞. Using the fact
that |e
itx| ≤ 1 and |i
n| = 1 we note that,




Z ∞
−∞
(ix)
n
e
itxdF(x)




≤
Z ∞
−∞
|(ix)
n
||e
itx|dF(x)
≤
Z ∞
−∞
|x|
n
dF(x) = E(|X|
n
) < ∞.
Further, R ∞
−∞(ix)
ne
itxdF(x) = R ∞
−∞
d
n
dtn e
itxdF(x). Since



R ∞
−∞(ix)
ne
itxdF(x)



is finite, by Lemma 4.4.2, the integration and differentiation can be inter￾changed. Hence we have,
Z ∞
−∞
(ix)
n
e
itxdF(x) = Z ∞
−∞
d
n
dtn
e
itxdF(x) = d
n
dtn
Z ∞
−∞
e
itxdF(x) = d
n
dtn
ϕX(t)
⇒
d
n
dtn
ϕX(t)



t=0
=
Z ∞
−∞
(ix)
n
dF(x) = i
nE(Xn
).
Example 4.4.2. Suppose ϕ(t) = 1/(1 + t
2
) is a characteristic function. Then
d
dt
1
1 + t
2
= −
2t
(1 + t
2)
2
&
d
2
dt2
1
1 + t
2
=
−2(1 + t
2
)
2 + 8t
2
(1 + t
2
)
(1 + t
2)
4
.
Hence, µ
′
1 = 0, µ′
2 = 2 = µ2. □
The next theorem proves that if X has finite moments up to certain order
then its characteristic function can be expressed in terms of moments. It is
a sort of Taylor’s series expansion for a characteristic function around t = 0
with a remainder term.
Theorem 4.4.4. Suppose ϕX(t) is a characteristic function of a random
variable X. If E(|X|
k
) < ∞ where k is a positive integer, then ϕX(t) can be
expressed,
ϕX(t) =
k
X−1
s=0
(it)
s
s!
E(Xs
) + t
k
Z 1
0
(1 − u)
k−1
(k − 1)! ϕ
(k)
X (tu) du,
where ϕ
(k)
X (tu) is the k-th derivative of ϕX(t) at tu.190 Expectation and Characteristic Function
Proof. By the definition of a characteristic function for t ∈ R,
ϕX(t) = Z ∞
−∞
e
itxdF(x) ⇒
d
k
dtk
ϕX(t) = Z ∞
−∞
(ix)
k
e
itxdF(x).
Hence, k-th derivative of ϕX(t) at tu is R ∞
−∞(ix)
k
e
ituxdF(x). Using integra￾tion by parts repeatedly we simplify the integral Ik =
R 1
0
(1−u)
k−1
(k−1)! e
iutx du as
follows.
Ik =
Z
1
0
(1 − u)
k−1
(k − 1)!
d
du
e
iutx
itx
du =

(1 − u)
k−1
(k − 1)!
e
iutx
itx 1
0
+
Z
1
0
(1 − u)
k−2
(k − 2)!
e
iutx
itx
du
=
−1
itx(k − 1)! +
1
itx Z
1
0
(1 − u)
k−2
(k − 2)! e
iutx du
= −
1
itx(k − 1)! −
1
(itx)
2(k − 2)! +
1
(itx)
2
Z 1
0
(1 − u)
k−3
(k − 3)! e
iutx du
.
.
.
= −
1
itx(k − 1)! −
1
(itx)
2(k − 2)! − · · · −
1
(itx)
k−1(k − (k − 1))!
+
1
(itx)
k−1
Z 1
0
(1 − u)
k−k
(k − k)! e
iutx du.
It further simplifies to
Ik = −
1
itx(k − 1)! −
1
(itx)
2(k − 2)! − · · · −
1
(itx)
k−1(k − (k − 1))!
+
1
(itx)
k−1

e
itx − 1
itx 
.
Hence, e
itx
(itx)
k can be expressed as follows.
e
itx
(itx)
k
=
1
itx(k − 1)! +
1
(itx)
2(k − 2)! + · · · +
1
(itx)
k
+
Z 1
0
(1 − u)
k−1
(k − 1)! e
iutx du
⇒ e
itx =
k
X−1
s=0
(itx)
s
s!
+ (itx)
k
Z 1
0
(1 − u)
k−1
(k − 1)! e
iutx du.Characteristic Function 191
Hence, ϕX(t) = R ∞
−∞ e
itxdF(x) can be written as follows.
ϕX(t) =
k
X−1
s=0
(it)
s
s!
Z ∞
−∞
x
s
dF(x) + Z 1
0
(1 − u)
k−1
(k − 1)! Z ∞
−∞
(itx)
k
e
iutxdF(x)

du
=
k
X−1
s=0
(it)
s
s!
E(Xs
) + t
k
Z 1
0
(1 − u)
k−1
(k − 1)! Z ∞
−∞
(ix)
k
e
iutxdF(x)

du
=
k
X−1
s=0
(it)
s
s!
E(Xs
) + t
k
Z 1
0
(1 − u)
k−1
(k − 1)! ϕ
(k)
X (tu) du.
The next corollary follows immediately from this theorem.
Corollary 4.4.1. Suppose ϕX(t) is a characteristic function of a random
variable X. If moments of all order of X are finite, then ϕX(t) can be expressed
as,
ϕX(t) = X∞
s=0
(it)
s
s!
E(Xs
).
We have noted above that an important property of a characteristic func￾tion is that its domain is R. Another important property is a uniqueness
theorem which states that if two random variables have the same characteris￾tic function then they also have the same distribution. This theorem is heavily
used to identify the limit laws in convergence in distribution in Chapter 7. We
first prove an inversion theorem, from which the uniqueness theorem follows.
In addition, an inversion theorem provides a formula for explicitly comput￾ing the distribution function from the characteristic function. By definition,
given a distribution function F, we can find the corresponding characteristic
function and using the inversion theorem, we can find a distribution function
from the characteristic function. Thus, there is a one-to-one correspondence
between a distribution function and a characteristic function and every ran￾dom variable possesses a unique characteristic function. In other words, the
characteristic function characterizes the distribution uniquely and hence it is
labeled as a characteristic function.
We state below a lemma which is needed to prove the inversion theorem.
For proof we refer to p. 557 of Gut [13].
Lemma 4.4.3. For α > 0,
(i)
Z c
0
sin(αt)
t
dt ≤ π ∀ c > 0 & (ii)
Z c
0
sin(αt)
t
dt →
π
2
as c → ∞.
As a consequence of the second result of this lemma we have
1
π
Z ∞
0
sin(αt)
t
dt = limc→∞
1
π
Z c
0
sin(αt)
t
dt =



1
2
if α > 0,
−
1
2
if α < 0,
0, if α = 0.
(4.6)192 Expectation and Characteristic Function
Suppose α < 0 and α = −δ where δ > 0. Then from (i) of the above lemma,
we have ∀ c > 0 & ∀ α ∈ R,
Z c
0
sin(αt)
t
dt = −
Z c
0
sin(δt)
t
dt ≥ − π ⇒




1
π
Z c
0
sin(αt)
t
dt




≤ 1.
Theorem 4.4.5. Inversion theorem: Suppose ϕX(t) is the characteristic func￾tion of a random variable X with distribution function FX. Then
FX(b) − FX(a) + 1
2
P[X = a] −
1
2
P[X = b]
=
1
2π
limc→∞ Z c
−c

e
−ita − e
−itb
it 
ϕX(t) dt.
If a < b ∈ C(FX), where C(FX) is a set of points of continuity of F, then
FX(b) − FX(a) = 1
2π
limc→∞ Z c
−c

e
−ita − e
−itb
it 
ϕX(t) dt.
The value of the integrand at t = 0 is determined by continuity, that is, by
using L’Hospital’s rule and it is b − a.
Proof. Suppose the integral 1
2π
R c
−c
h
e
−ita−e
−itb
it i
ϕX(t) dt is denoted by Jc.
Then Jc =
1
2π
Z c
−c

e
−ita − e
−itb
it 
ϕX(t) dt
=
1
2π
Z c
−c

e
−ita − e
−itb
it  Z ∞
−∞
e
itudFX(u)

dt
=
1
2π
Z c
−c
Z ∞
−∞ 
e
−it(a−u) − e
−it(b−u)
it 
dFX(u) dt
=
1
2π
Z ∞
−∞ Z c
−c

e
−it(a−u) − e
−it(b−u)
it 
dt
dFX(u). (4.7)
It is to be noted that in the last step the order of integration can be in￾terchanged as the integral over (−∞, ∞) is absolutely convergent and the
integral over (−c, c) is over a finite interval. Now we simplify the integral
R c
−c
e
−it(a−u)
it dt as follows.
Z c
−c
e
−it(a−u)
it
dt =
Z 0
−c
e
−it(a−u)
it
dt +
Z c
0
e
−it(a−u)
it
dt
= −
Z c
0
e
it(a−u)
it
dt +
Z c
0
e
−it(a−u)
it
dt
=
Z c
0
e
−it(a−u) − e
it(a−u)
it
dt.Characteristic Function 193
Similarly we have R c
−c
e
−it(b−u)
it dt =
R c
0
e
−it(b−u)−e
it(b−u)
it dt. Substituting these
expressions in Equation (4.7) and using the fact that e
iα − e
−iα = 2isin(α),
we get
Jc =
1
2π
Z ∞
−∞ Z c
0

e
−it(a−u) − e
it(a−u) − e
−it(b−u) + e
it(b−u)
it 
dt
dFX(u)
=
1
2π
Z ∞
−∞ Z c
0

e
it(u−a) − e
−it(u−a) − e
it(u−b) + e
−it(u−b)
it 
dt
dFX(u)
=
1
π
Z ∞
−∞ Z c
0

sin(t(u − a)) − sin(t(u − b))
t

dt
dFX(u)
=
Z∞
−∞
g(c, u)dFX(u), where g(c, u)= 1
π
Zc
0

sin(t(u − a)) − sin(t(u − b))
t

dt.
Thus, Jc can be written as
Jc =
Z a
−∞
g(c, u)dFX(u) + Z b
a
g(c, u)dFX(u) + Z ∞
b
g(c, u)dFX(u).
Now to find limc→∞
Jc we first find limc→∞
g(c, u) in the following five cases:
(i) u < a, (ii) u = a, (iii) a < u < b, (iv) u = b and (v) u > b.
(i) Suppose u < a. Then u − a < 0 and u − b < u − a < 0. Thus, using the
result in Equation (4.6) we have,
limc→∞
1
π
Z c
0

sin(t(u − a)) − sin(t(u − b))
t

dt =

−
1
2
−
−1
2

= 0.
(ii) Suppose u = a. Then u − a = 0 and u − b = a − b < 0. Again using the
result in Equation (4.6), we have,
limc→∞
1
π
Z c
0

sin(t(u − a)) − sin(t(u − b))
t

dt =

0 −
−1
2

=
1
2
.
(iii) Suppose a < u < b. Then u − a > 0 and u − b < 0. By Equation (4.6),
we have,
limc→∞
1
π
Z c
0

sin(t(u − a)) − sin(t(u − b))
t

dt =

1
2
−
−1
2

= 1.
(iv) Suppose u = b. Then u − a = b − a > 0 and u − b = 0. By Equation
(4.6), we have,
limc→∞
1
π
Z c
0

sin(t(u − a)) − sin(t(u − b))
t

dt =

1
2
− 0

=
1
2
.194 Expectation and Characteristic Function
(v) Suppose u > b. Then u − a > b − a > 0 and u − b > 0. Hence,
limc→∞
1
π
Z c
0

sin(t(u − a)) − sin(t(u − b))
t

dt =

1
2
−
1
2

= 0.
Thus,
g(u) = limc→∞
g(c, u) =



0 if u < a,
1/2 if u = a,
1 if a < u < b,
1/2 if u = b,
0, if u > b.
(4.8)
By Lemma 4.4.3 we have noted that 1
π
|
R c
0
sin(αt)
t
| ≤ 1 ∀ c > 0 and for all
α ∈ R, which implies that
|g(c, u)| ≤ 1
π




Z c
0
sin(t(u − a))
t




+
1
π




Z c
0
sin(t(u − b))
t




≤ 2.
Further limc→∞
g(c, u) = g(u) exists for all u ∈ R. Thus, g(c, u) → g(u) on R and
g(c, u) is bounded uniformly by 2. Hence, by Lemma 4.4.2 we can interchange
limit and integration in limc→∞
R ∞
−∞ g(c, u)dFX(u). We thus have,
limc→∞
Jc = limc→∞ Z a
−∞
g(c, u)dFX(u) + limc→∞
g(c, a)P[X = a]
+ limc→∞ Z b
a
g(c, u)dFX(u) + limc→∞
g(c, b)P[X = b]
+ limc→∞ Z ∞
b
g(c, u)dFX(u)
=
Z a
−∞
limc→∞
g(c, u)dFX(u) + limc→∞
g(c, a)P[X = a]
+
Z b
a
limc→∞
g(c, u)dFX(u) + limc→∞
g(c, b)P[X = b]
+
Z ∞
b
limc→∞
g(c, u)dFX(u)
= (1/2)P[X = a] + P[a < X < b] + (1/2)P[X = b] by (4.8)
= (1/2)P[X = a] + P[a < X ≤ b] − P[X = b] + (1/2)P[X = b]
= FX(b) − FX(a) + (1/2)P[X = a] − (1/2)P[X = b].
If a and b are points of continuity, then P[X = a] = P[X = b] = 0 and hence
limc→∞
Jc = FX(b) − FX(a).Characteristic Function 195
The inversion theorem leads to an important result that a characteristic
function uniquely determines the distribution of a random variable. Such a
uniqueness property of a characteristic function is heavily used in the proof of
the central limit theorem, to be discussed in Chapter 10 and in determining
the limiting distribution of an estimator or of a test statistic in large sample
inference. It is illustrated in Chapter 7.
Theorem 4.4.6. Uniqueness theorem: Suppose X and Y are random vari￾ables with characteristic functions ϕX and ϕY respectively.
ϕX(t) = ϕY (t) ∀ t ∈ R ⇐⇒ X
d= Y.
Proof. Suppose FX and FY are distribution functions of X and Y respectively.
Suppose X and Y are identically distributed, hence FX(x) = FY (x) ∀ x ∈ R.
By the definition of a characteristic function, for t ∈ R
ϕX(t) = Z
R
e
itxdFX(x) = Z
R
e
itxdFY (x) = ϕY (t) ∀ t ∈ R.
Suppose, ϕX(t) = ϕY (t) ∀ t ∈ R. As proved in Theorem 3.2.4,
C = C(FX) ∩ C(FY ) ≠ ∅, where C(FX) and C(FY ) are the sets of points of
continuity of FX and FY respectively. Suppose a, b ∈ C. Then by the inversion
theorem,
FX(b) − FX(a) = 1
2π
limc→∞ Z c
−c

e
−ita − e
−itb
it 
ϕX(t) dt
=
1
2π
limc→∞ Z c
−c

e
−ita − e
−itb
it 
ϕY (t) dt = FY (b) − FY (a).
Thus, ∀ a, b ∈ C,
FX(b) − FX(a) = FY (b) − FY (a) ⇐⇒ FX(b) − FY (b) = FX(a) − FY (a).
Allowing b to vary, for fixed a, we have FX(b) − FY (b) = FX(a) − FY (a) = d,
where d is a constant. To find d, suppose b ↑ ∞ through the points in C,
then we get FX(∞) − FY (∞) = 0 implies d = 0 which further implies that
FX(b) = FY (b) ∀ b ∈ C. Using arguments same as in Theorem 3.2.4, if
FX(x) = FY (x) ∀ x ∈ C, then FX(x) = FY (x) ∀ x ∈ R, which implies that
X and Y are identically distributed.
In particular, uniqueness theorem of a characteristic function implies that
ϕ(t) ≡ 1 must be a characteristic function of a distribution which is degen￾erate at zero and ϕ(t) = exp(−t
2/2) must be a characteristic function of the
standard normal distribution.196 Expectation and Characteristic Function
Using the links between moments and a characteristic function and the
uniqueness theorem, in the following example we examine whether a given
function is a characteristic function.
Example 4.4.3. Suppose ϕ(t) = exp(−t
4/2), t ∈ R. We examine whether
it is a characteristic function. Suppose ϕ(t) = exp(−t
4/2) is a characteristic
function. Then it is a differentiable function and derivatives of all order at
t = 0 exists. Hence by Theorem 4.4.2, moments of all order exist. Further,
ϕ(t) = exp(−t
4/2) can be expressed as ϕ(t) = exp(−t
4/2) = 1 − t
4/2 + · · · .
Thus by Corollary 4.4.1, µ
′
1 = µ
′
2 = 0 which implies that ϕ(t) is a characteristic
function of a random variable X which is degenerate at 0. However, if X is
degenerate at 0, then its characteristic function is E(exp(itX)) = 1 which
is not the same as ϕ(t) = exp(−t
4/2). Hence our assumption that ϕ(t) =
exp(−t
4/2) is a characteristic function is wrong and it is not a characteristic
function. □
We have already noted at the beginning of this section that if the distri￾bution of X is symmetric around 0, then its characteristic function is a real
valued function. Using uniqueness theorem, we now prove that the converse
is also true.
Theorem 4.4.7. If a characteristic function ϕX(t) of a random variable X
is a real valued function, then its distribution is symmetric around 0.
Proof. Observe that ϕX(t) is a real valued function implies that ∀ t ∈ R,
ϕX(t) = ϕX(t) ⇒ ϕX(t) = ϕX(−t) = ϕ−X(t) ⇒ X
d= −X
and hence the distribution of X is symmetric around 0.
In the following corollaries, we discuss some particular cases of the inver￾sion theorem, depending on the nature of the distribution function F.
Corollary 4.4.2. (i) If F is differentiable at x with F
′
(x) = f(x), then
f(x) = lim
h→0
limc→∞
1
2π
Z c
−c

1 − e
−ith
ith 
e
−itxϕX(t) dt,
if and only if the limits on the right hand side exist.
(ii) If ϕ is Riemann integrable on R and if F
′
(x) = f(x) exists ∀ x ∈ R,
then
f(x) = 1
2π
Z
R
e
−itxϕX(t) dt
and f(x) is continuous on R.Characteristic Function 197
Proof. Suppose Jc =
1
2π
R c
−c
h
e
−ita−e
−itb
it i
ϕX(t) dt. From Theorem 4.4.5,
limc→∞
Jc = limc→∞
1
2π
Z c
−c

e
−ita − e
−itb
it 
ϕX(t) dt
= (1/2)P[X = a] + P[a < X < b] + (1/2)P[X = b]
= FX(b − 0) − FX(a + 0)
+ (1/2)[FX(a + 0) − FX(a − 0) + FX(b + 0) − FX(b − 0)]
= (1/2)[FX(b + 0) + FX(b − 0)] − (1/2)[FX(a + 0) + FX(a − 0)]
= (1/2)[FX(x + h + 0) + FX(x + h − 0)]
− (1/2)[FX(x + 0) + FX(x − 0)],
with b = x + h & a = x. Since F is differentiable, F is continuous and hence
F(x + h) = F(x + h + 0) = F(x + h − 0), F(x) = F(x + 0) = F(x − 0).
By definition
f(x) = lim
h→0
F(x + h) − F(x)
h
= lim
h→0

F(x + h + 0) + F(x + h − 0)
2h
−
F(x + 0) + F(x − 0)
2h

= lim
h→0
1
h

limc→∞
1
2π
Z c
−c

e
−itx − e
−it(x+h)
it 
ϕX(t) dt
= lim
h→0

limc→∞
1
2π
Z c
−c

e
−itx(1 − e
−ith)
ith 
ϕX(t) dt
= lim
h→0
limc→∞
1
2π
Z c
−c

1 − e
−ith
ith 
e
−itxϕX(t) dt,
provided the limits on the right hand side exist.
(ii) It is given that ϕ is Riemann integrable on R, hence by Theorem 4.3.7, |ϕ|
is integrable. Note that for any h > 0 and t ∈ R
1 − e
−ith
ith =
1 − e
−ith
ith
ith
ith =
ith − ithe−ith
−th = −i + ie−ith
= −i + i(cos(−th) + isin(−th)) = i(cos(th) − 1) − sin(th)
⇒



1 − e
−ith
ith



2
= cos2
(th) − 2 cos(th) + 1 + sin2
(th)
= 2(1 − cos(th)) = 2 × 2 sin2
(th/2) ≤ 4.
Hence, for any c, h and x ∈ R,




Z c
−c

1 − e
−ith
ith 
e
−itxϕ(t) dt




≤ 2
Z c
−c
|ϕ(t)| dt ≤ 2
Z
R
|ϕ(t)| dt < ∞.198 Expectation and Characteristic Function
Hence, by Lemma 4.4.2, limh→0 can be taken inside the integral. Thus,
f(x) = lim
h→0
limc→∞
1
2π
Z c
−c

1 − e
−ith
ith 
e
−itxϕ(t) dt
= lim
h→0
1
2π
Z
R

1 − e
−ith
ith 
e
−itxϕ(t) dt
=
1
2π
Z
R
lim
h→0

1 − e
−ith
ith 
e
−itxϕ(t) dt =
1
2π
Z
R
e
−itxϕ(t) dt,
since limh→0(1−e
−ith)/ith = 1. To establish continuity of f, we note that for
x ∈ R,
|f(x + δ) − f(x)| =
1
2π




Z
R
(e
−it(x+δ) − e
−itx)ϕ(t) dt




≤
1
2π
Z
R
|(e
−itδ − 1)||ϕ(t)| dt ≤ 2
1
2π
Z
R
|ϕ(t)| dt < ∞,
since |(e
−itδ − 1)|
2 = 2 − 2 cos(tδ) = 2 × 2 sin2
(tδ/2) ≤ 4, as shown above.
Further, e
−itδ − 1 → 0 as δ → 0. Hence, again by Lemma 4.4.2, limδ→0 can
be taken inside the integral. Thus,
lim
δ→0
|f(x + δ) − f(x)| =
1
2π




Z
R
lim
δ→0
(e
−it(x+δ) − e
−itx)ϕ(t) dt




= 0
which proves that f is continuous on R.
Following examples illustrate the inversion theorem.
Example 4.4.4. Suppose X follows Cauchy C(0, 1) distribution. Then its
characteristic function is ϕX(t) = exp(−|t|). It is Riemann integrable. Hence
using Corollary 4.4.2, we find the probability density function of X as follows.
f(x) = 1
2π
Z
R
e
−itxϕ(t) dt =
1
2π
Z
R
e
−itxe
−|t|
dt
=
1
2π
Z
R
(cos(−tx) + isin(−tx))e
−|t|
dt =
1
π
Z ∞
0
cos(tx)e
−t
dt
=
1
π
Z ∞
0
cos(tx)
d
dt[−e
−t
] dt
=
1
π

[−e
−t
cos(tx)]∞
0 +
Z ∞
0
x sin(tx)e
−t
dt
=
1
π
+
x
π
Z ∞
0
sin(tx)
d
dt[−e
−t
] dt
=
1
π
+
x
π

[−e
−t
sin(tx)]∞
0 − x
Z ∞
0
cos(tx)e
−t
dt
=
1
π
+
x
π

−x
Z∞
0
cos(tx)e
−t
dt

 =
1
π
− x
2
f(x) ⇒ f(x) = 1
π
1
1 + x
2
,Characteristic Function 199
for x ∈ R. In the second step, we use the result that sine is an odd function
while cosine is an even function. Note that f(x) is the probability density
function of X. □
Example 4.4.5. Suppose X ∼ N(0, 1). Then its characteristic function is
given by,
ϕX(t) = E(e
itX) = Z
R
1
√
2π
e
itxe
−x
2/2
dx =
Z
R
1
√
2π
e
−(x
2−2itx+i
2
t
2−i
2
t
2
)/2
dx
= e
−t
2/2
Z
R
1
√
2π
e
−(x−it)
2/2
dx = e
−t
2/2
.
Hence, if X ∼ N(µ, σ2
). Then ϕX(t) = exp(iµt − t
2σ
2/2). Now suppose
ϕX(t) = exp(−t
2/2), it is Riemann integrable. Hence by Corollary 4.4.2, the
probability density function is given by,
f(x) = 1
2π
Z
R
e
−itxϕ(t)dt =
1
2π
Z
R
e
−itxe
− t
2
2 dt =
1
2π
Z
R
e
− x
2
2 e
− t
2+2itx+i
2x
2
2 dt
= e
− x
2
2
1
2π
Z
R
e
−
(t+ix)
2
2 dt = e
− x
2
2
1
2π
√
2π =
1
√
2π
e
− x
2
2 x ∈ R. □
In both the above examples we note a typical link between the character￾istic function and the corresponding probability density function. More pre￾cisely, we observe that in Example 4.4.5, the characteristic function is ϕX(t) =
exp(−t
2/2) and the probability density function is (1/
√
2π) exp(−x
2/2). In
Example 4.4.4, characteristic function is ϕX(t) = exp(−|t|) and the prob￾ability density function is f(x) = (1/π)(1/(1 + x
2
)), x ∈ R. It can be
shown that if X follows Laplace distribution, then its characteristic func￾tion is ϕX(t) = 1/(1 + t
2
) and its probability density function is given by
f(x) = (1/2) exp(−|x|), x ∈ R. Thus, except for a multiplicative constant,
the density of one of them equals the characteristic function of the other. If
a pair of distributions are related in such a manner, then these distributions
are known as a conjugate pair of distributions. We thus note that Laplace and
Cauchy distributions are conjugate to each other while normal distribution is
conjugate to itself.
Following corollary shows how to obtain the magnitude of jump at a point
of discontinuity of F, from the characteristic function.
Corollary 4.4.3. If P[X = a] > 0, then
P[X = a] = FX(a) − FX(a − 0) = limc→∞
1
2c
Z c
−c
e
−itaϕX(t) dt.
Proof. Suppose Ic =
1
2c
R c
−c
e
−itaϕX(t) dt. As in Theorem 4.4.5, interchanging
the order of integration we have200 Expectation and Characteristic Function
Ic =
1
2c
Z c
−c
e
−ita Z ∞
−∞
e
itudFX(u)

dt =
1
2c
Z ∞
−∞ Z c
−c
e
it(u−a)
dt
dFX(u)
=
1
2c
Z ∞
−∞ Z c
−c
(cos(t(u − a)) + isin(t(u − a)))dt
dFX(u)
=
1
2c
Z ∞
−∞ Z c
−c
cos(t(u − a)) dt
dFX(u) sine being an odd function
=
2
2c
Z ∞
−∞ Z c
0
cos(t(u − a)) dt
dFX(u) cosine being an even function
=
1
c
Z
R−{a}

sin(c(u − a))
(u − a)

dFX(u) + 1
c
cP[X = a] as cos(0) = 1
=
Z
R−{a}
sin(c(u − a))
c(u − a)
dFX(u) + P[X = a],
since at u = a,
R c
0
cos(t(u − a)) dt = c. Now |sin(c(u − a))| ≤ 1 and hence for
u ̸= a, limc→∞
sin(c(u−a))
c(u−a) = 0. Further, for any u ∈ R, |
sin(c(u−a))
c(u−a)
| is bounded.
Hence, by Lemma 4.4.2,
limc→∞
Ic =
Z
R−{a}

limc→∞
sin(c(u − a))
c(u − a)

dFX(u) + P[X = a]
= 0 + P[X = a] = P[X = a].
If X is a discrete random variable, then the above corollary conveys how
the probability mass function can be obtained from its characteristic function.
For a discrete distribution the support is a countable set. As a particular case,
if the support is
S = {a + xd|x = 0, ±1, ±2, · · · , }, d > 0 & a ∈ R
then the discrete distribution is known as a lattice distribution and smallest
such d is known as a span of the distribution. The characteristic function for
a lattice distribution with support S and px = P[X = a + xd], x ∈ I and the
corresponding inversion formula are given by,
ϕX(t) = X
x∈I
pxe
it(a+xd) & px =
d
2π
Z π/d
−π/d
e
−it(a+xd)ϕX(t) dt.
In particular, when a = 0 & d = 1, then
ϕX(t) = X
x∈I
pxe
itx & px = P[X = x] = 1
2π
Z π
−π
e
−itxϕX(t) dt. (4.9)
Following examples illustrate these results.Characteristic Function 201
Example 4.4.6. Suppose X is a degenerate random variable, degenerate at
C. Then its characteristic function is ϕX(t) = E(exp(itX)) = exp(itC). By
the inversion formula, the probability mass function is given by,
px = P[X = x] = 1
2π
Z π
−π
e
−itxe
itC dt
=
1
2π
Z π
−π
(cos((C − x)t) + isin((C − x)t)) dt
=
1
π
Z π
0
cos((C − x)t) = 1
π
(sin(C − x)t/(C − x))



π
0
= 0 if x ̸= C.
At x = C, px =
1
2π
Z π
−π
e
−itxe
itC dt =
1
2π
Z π
−π
1 dt = 1 .
Thus, P[X = C] = 1, which implies that the distribution of X is degenerate
at C. □
Example 4.4.7. Suppose X follows geometric distribution with probability
mass function px = P[X = x] = pqx
, x = 0, 1, 2, · · · , q = 1 − p. Then its
characteristic function is given by,
ϕX(t) = E(e
itX) = X∞
x=0
e
itxpqx =
X∞
x=0
(qeit)
x
p = p(1 − qeit)
−1
.
Now, by the inversion formula given in equation (4.9), the probability mass
function from its characteristic function is given by,
px = P[X = x] = 1
2π
Z π
−π
e
−itxϕX(t) dt =
p
2π
Z π
−π
e
−itx(1 − qeit)
−1
dt
=
p
2π
Z π
−π
e
−itxX∞
r=0
(qeit)
r
dt =
p
2π
X∞
r=0
q
r
Z π
−π
e
−itx+itr dt
=
p
2π
X∞
r=0
q
r
Z π
−π
(cos((r − x)t) + isin((r − x)t)) dt
=
p
π
X∞
r=0,r̸=x
q
r
Z π
0
cos((r − x)t) dt +
p
π
q
x
Z π
0
cos 0 dt
=
p
π
X∞
r=0,r̸=x
q
r
(sin(r − x)t/(r − x))



π
0
+
p
π
q
x
Z π
0
1 dt
= 0 + pqx
, x = 0, 1, 2, · · · ,
as for r ̸= x, sin(r − x)π = 0 = sin(0) . □202 Expectation and Characteristic Function
Example 4.4.8. Suppose X follows binomial distribution with probability
mass function px = P[X = x] = ￾n
x

p
x
q
n−x
, x = 0, 1, 2, · · · , n, q = 1 − p.
Then its characteristic function is given by,
ϕX(t) = E(e
itX) = Xn
x=0
e
itx
n
x

p
x
q
n−x =
Xn
x=0
(peit)
x
q
n−x = (peit + q)
n
.
By the inversion formula given in equation (4.9), the probability mass function
from its characteristic function is given by,
px = P[X = x] = 1
2π
Zπ
−π
e
−itxϕX(t) dt =
1
2π
Zπ
−π
e
−itx(peit + q)
n
dt
=
1
2π
Zπ
−π
e
−itxXn
r=0

n
r

(peit)
r
q
n−r
dt =
1
2π
Xn
r=0

n
r

p
r
q
n−r
Zπ
−π
e
−itx+itr dt
=
1
2π
Xn
r=0,r̸=x

n
r

p
r
q
n−r
Zπ
−π
e
−itx+itr dt +
1
2π

n
x

p
x
q
n−x
Zπ
−π
1 dt
=
1
π
Xn
r=0,r̸=x

n
r

p
r
q
n−r
(sin(r − x)t/(r − x))|
π
0 +
1
2π

n
x

p
x
q
n−x
2π
= 0 + 
n
x

p
x
q
n−x
, x = 0, 1, 2, · · · , n.
Last two steps follow from the same arguments as in Example 4.4.7. □
We now briefly discuss the characteristic function of a random vector. We
first define it.
Definition 4.4.4. Characteristic function of a random vector: A character￾istic function ϕZ(t) of a random vector Z = (X1, X2, · · · , Xk)
′
, where
t = (t1, t2, · · · , tk)
′
, ti ∈ R, i = 1, 2, · · · , k, is defined as
ϕZ(t) = ϕZ(t1, t2, · · · , tk) = E(exp(i(t1X1+t2X2+· · ·+tkXk)) = E(exp(t
′Z)).
In particular, if t = (t, t, · · · , t)
′
, then ϕZ(t) = E(exp(it(X1 + X2 + · · · +
Xk)), which is a characteristic function of X1 + X2 + · · · + Xk. From the
characteristic function ϕZ(t) of Z we can obtain the characteristic function
of the random vectors of lower order by substituting corresponding ti = 0.
For example, the characteristic function of the random vector (X1, X2, X3)
′
is ϕZ(t1, t2, t3, 0, · · · , 0). In particular, the characteristic function of X1 is
ϕZ(t1, 0, 0, · · · , 0), it is known as a marginal characteristic function.
Suppose a random vector Z has a multivariate normal distribution with
mean vector µ and dispersion matrix Σ, then its characteristic function is given
by ϕZ(t) = exp(t
′µ + t
′Σt/2). If Σ is singular and positive semi-definite, theMoment Inequalities 203
one cannot have the probability density function of Z, but its characteristic
function exists.
Some of the most useful tools in probability theory and statistics for pro￾viding finiteness or convergence of sums and integrals are probability inequal￾ities and moment inequalities. In the next section, we study some moment
inequalities.
4.5 Moment Inequalities
Moment inequalities play an important role in probability theory and statistics
as many times we need to determine or approximate probabilities of certain
events in terms of the other probabilities. These are also useful in the deter￾mination of moments of sum or in finding bounds on them by the sum of
moments. In this section we discuss some inequalities which are frequently
used in subsequent chapters.
Lemma 4.5.1. If E(|X|
r
) < ∞, then E(|X|
r
′
) < ∞, for 0 < r′ ≤ r and
E(Xk
) exists and is finite for k < r, if k is an integer.
Proof. For 0 < r′ ≤ r and for any ω ∈ Ω,
|X(ω)|
r
′
≤

1 if |X(ω)| ≤ 1,
|X(ω)|
r
, if |X(ω)| > 1.
Therefore, for all ω and for 0 < r′ ≤ r,
|X(ω)|
r
′
≤ 1 + |X(ω)|
r ⇒ E(|X|
r
′
) ≤ 1 + E(|X|
r
)
Hence E(|X|
r
) < ∞ ⇒ E(|X|
r
′
) < ∞.
For an integer k < r we have,
|X(ω)|
k = |X(ω)||X(ω)| · · · k times = |X(ω)X(ω)· · · k times| = |Xk
(ω)|.
Thus, |Xk
| = |X|
k and |X|
k
is integrable for k < r. It is known that Xk
is
integrable if and only if |Xk
| is integrable. Thus, E(Xk
) exists and is finite.
Remark 4.5.1. The space of all random variables such that E(|X|
r
) < ∞ is
known as Lr space. Lemma 4.5.1 states that if a moment of a certain order is
finite, then the moments of lower order are also finite, that is, if X ∈ Lr then
X ∈ Ls, ∀ s < r. However, the converse is not true, as shown in the following
examples.
Example 4.5.1. Suppose the probability density function of a random vari￾able X is given by,
f(x) = 2a
2
/(x + a)
3
, x ≥ 0, a ≥ 0.
Here, E(X) < ∞, but E(X2
) is not finite. □204 Expectation and Characteristic Function
Example 4.5.2. Suppose X is a discrete random variable with P[X = j] =
c/jk+2, j = 1, 2, · · · , where c = (P∞
j=1 1/jk+2)
−1
, k ∈ N. Note that,
E(Xk
) = c
X∞
j=1
j
k
/jk+2 = c
X∞
j=1
1/j2 < ∞ but E(Xk+1) = c
X∞
j=1
1/j = ∞. □
In the next lemma, we derive Cr inequality, which has many applications.
Lemma 4.5.2. Cr inequality: Suppose X ∈ Lr and Y ∈ Lr, then for any
r > 0, E(|X + Y |
r
) ≤ Cr (E(|X|
r
) + E(|Y |
r
)), where,
Cr =

1, if r ≤ 1,
2
r−1
, if r > 1.
Proof. For any two positive real numbers a and b and ∀ r ≤ 1,
a
a + b
< 1 & b
a + b
< 1 ⇒

a
a + b
r
≥
a
a + b
&

b
a + b
r
≥
b
a + b
⇒

a
a + b
r
+

b
a + b
r
≥
a
a + b
+
b
a + b
= 1
⇒ (a
r + b
r
) ≥ (a + b)
r
.
Hence, substituting a = |X(ω)| and b = |Y (ω)| and using triangle inequality,
we get, for all ω and for r ≤ 1,
|X(ω)|
r + |Y (ω)|
r ≥ (|X(ω)| + |Y (ω)|)
r ≥ |X(ω) + Y (ω)|
r
⇒ E(|X + Y |
r
) ≤ E(|X|
r
) + E(|Y |
r
), r ≤ 1 . (4.10)
For r > 1, we consider a function ϕ(p) = p
r + (1 − p)
r
, where 0 < p < 1.
Taking derivative with respect to p, we get,
dϕ(p)
dp = rpr−1 − r(1 − p)
r−1
.
Equating the derivative to zero yields, p = 1 − p. Hence p = 1/2. Second
derivative of ϕ(p) is,
d
2ϕ(p)
dp2
= r(r − 1)p
r−2 + r(r − 1)(1 − p)
r−2 > 0, ∀ p ∈ (0, 1).
Thus, ϕ(p) has minimum at p = 1/2. Therefore, using the fact that
0 < a/(a + b) < 1, we get
ϕ

a
a + b

≥ ϕ

1
2

⇒

a
a + b
r
+

b
a + b
r
≥

1
2
r
+

1
2
r
= 2−(r−1)
⇒ 2
r−1
(a
r + b
r
) ≥ (a + b)
r
.Moment Inequalities 205
Again substituting a = |X(ω)| and b = |Y (ω)| and using triangle inequality,
we get, for r > 1,
E(|X + Y |
r
) ≤ E((|X| + |Y |)
r
) ≤ 2
r−1
(E(|X|
r
) + E(|Y |
r
)). (4.11)
Thus, combining equations (4.10) and (4.11), we get the Cr inequality.
Cr inequality implies that if the r-th absolute moments of X and Y exist
and are finite, then r-th absolute moment of (X + Y ) also exists and is finite.
Thus, the class of random variables, whose r-th absolute moment is finite is
closed under addition. In this inequality the constant C depends on r, it is
1 if 0 < r ≤ 1 and is 2
r−1
if r > 1. Hence this inequality is known as Cr
inequality.
The following lemma specifies Holder’s inequality, which is about the ex￾pectation of the product of two random variables.
Lemma 4.5.3. Holder’s inequality: For r > 1 and 1/r + 1/s = 1,
E(|XY |) ≤ E
1/r(|X|
r
)E
1/s(|Y |
s
).
Proof. Using the condition that 1/r + 1/s = 1, we get s = r/(r − 1) > 1.
Further, (r + s)/s = r and (r + s)/r = s. For p > 0, we consider a function,
ϕ(p) = p
r
/r + p
−s
/s ⇒ ϕ(1) = 1
&
dϕ(p)
dp = p
r−1 − p
−s−1 = 0 ⇒ p
r+s = 1 ⇒ p = 1
Further, d
2ϕ(p)
dp2
= (r − 1)p
r−2 − (−s − 1)p
−s−2
and at p = 1,
d
2ϕ(p)
dp2
= r + s > 0
⇒ ϕ(p) has minimum at p = 1.
Now suppose p0 = a
1/s/b1/r, for some positive real numbers a, b. note that
ϕ(p0) ≥ ϕ(1) = 1
⇒ a
r/s/rb + b
s/r/sa = (br)
−1
a
r/s + (as)
−1
b
s/r ≥ 1
⇒ ab[(br)
−1
a
r/s + (as)
−1
b
s/r] ≥ ab
⇒ r
−1
a
r/s+1 + s
−1
b
s/r+1 ≥ ab
⇒ r
−1
a
(r+s)/s + s
−1
b
(s+r)/r ≥ ab
⇒ r
−1
a
r + s
−1
b
s = (sar + rbs
)/rs ≥ ab.
If E(|XY |) = 0 then P[|X| = 0] = 1 or P[|Y | = 0] = 1 which further implies
E(|X|
r
) = 0 or E(|Y |
s
) = 0. Thus Holder’s inequality is trivially true. Thus we
assume that E(|X|
r
) > 0 and E(|Y |
s
) > 0. Substituting a = |X|/E1/r(|X|
r
)
and b = |Y |/E1/s(|Y |
s
) in the above inequality we get,
s
|X|
r
E(|X|
r) + r
|Y |
s
E(|Y |
s)
rs
≥
|X||Y |
[E1/r(|X|
r)][E1/s(|Y |
s)].206 Expectation and Characteristic Function
Taking expectation on both sides and using monotonicity of expectations, we
get,
s + r
rs
≥
E(|X||Y |)
[E1/r(|X|
r)][E1/s(|Y |
s)].
But, (s + r)/rs = 1. Hence, we get,
E(|X||Y |) = E(|XY |) ≤ E
1/r(|X|
r
)E
1/s(|Y |
s
).
Following two inequalities, Lyapounov’s inequality and Schwarz inequality,
follow from Holder’s inequality.
Lemma 4.5.4. Lyapounov’s inequality:
E
1/s(|X|
s
) ≤ E
1/t(|X|
t
) for s < t.
Proof. By Holder’s inequality, for r > 1 and 1/r + 1/s = 1 we have,
E(|XY |) ≤ E
1/r(|X|
r
)E
1/s(|Y |
s
)
⇒ E(|X|) ≤ E
1/r(|X|
r
) with Y ≡ 1
⇒ E(|X|
s
) ≤ E
1/r(|X|
rs) by replacing |X| by |X|
s
⇒ E
1/s(|X|
s
) ≤ E
1/rs(|X|
rs)
⇒ E
1/s(|X|
s
) ≤ E
1/t(|X|
t
) with rs = t > s.
Lemma 4.5.5. Schwarz inequality :
E(|XY |) ≤
p
E(|X|
2)E(|Y |
2).
Proof. In Holder’s inequality if we take r = s = 2.
E(|XY |) ≤ E
1/2
(|X|
2
)E
1/2
(|Y |
2
) ⇐⇒ E(|XY |) ≤
p
E(|X|
2)E(|Y |
2).
Schwarz inequality is also known as the Cauchy-Schwarz inequality. Us￾ing this inequality we show that the correlation coefficient between any two
random variables is always between −1 and 1. Note that XY ≤ |XY | and
−XY ≤ |XY |. Thus, using monotonicity of expectations we get,
E(XY ) ≤ E(|XY |) and E(−XY ) = −E(XY ) ≤ E(|XY |)
⇒ |E(XY )| ≤ E(|XY |).
Further, using Schwarz inequality, we have, |E(XY )| ≤ p
E(|X|
2)E(|Y |
2).Moment Inequalities 207
Substituting X − E(X) and Y − E(Y ) in place of X and Y respectively, we
get,
|E[(X − E(X))(Y − E(Y ))]| ≤ p
E(|X − E(X)|
2)E(|Y − E(Y )|
2)
⇒ |Cov(X, Y )| ≤ p
V ar(X)V ar(Y )
⇒ |Corr(X, Y )| ≤ 1 .
Holder’s inequality is concerned with the moments of product of random vari￾ables, while the following Minkowski’s inequality is concerned with the mo￾ment of the sum of random variables.
Lemma 4.5.6. Minkowski’s inequality: For r ≥ 1,
E
1/r(|X + Y |
r
) ≤ E
1/r(|X|
r
) + E
1/r(|Y |
r
).
Proof. If r = 1 then Minkowski’s inequality is trivially true. Hence we assume
r > 1. For r > 1, we can write,
E(|X + Y |
r
) = E(|X + Y ||X + Y |
r−1
)
≤ E[(|X| + |Y |)|X + Y |
r−1
]
= E(|X||X + Y |
r−1
) + E(|Y ||X + Y |
r−1
). (4.12)
We know that in Holder’s inequality, s = r/(r − 1). For the first term on
the right hand side of equation (4.12) with X as first random variable and
|X + Y |
r−1 as second random variable, applying Holder’s inequality, we get,
E(|X||X + Y |
r−1
) ≤ E
1/r(|X|
r
)E
1−1/r(|X + Y |
r
).
Using similar adjustments for the second term, we get,
E(|X + Y |
r
) ≤
h
E
1/r(|X|
r
) + E
1/r(|Y |
r
)
i
E
1−1/r(|X + Y |
r
).
If E(|X +Y |
r
) = 0 then Minkowski’s inequality is trivially true. Hence assum￾ing E(|X + Y |
r
) > 0 and dividing by it on both the sides of above inequality
we get
E
1/r(|X + Y |
r
) ≤ E
1/r(|X|
r
) + E
1/r(|Y |
r
).
We now derive Jensen’s inequality for an expectation of a convex and a
concave function, which is frequently used in mathematical statistics. We first
define a convex and a concave function.
Definition 4.5.1. Convex and concave functions: A real valued Borel function
f defined on an interval I of R, which may be finite or infinite, is said to be
a convex function if
∀ x1, x2 ∈ I, f((x1 + x2)/2) ≤ (1/2)f(x1) + (1/2)f(x2).208 Expectation and Characteristic Function
Alternatively, for every x0 ∈ I, there corresponds a number λ(x0) such that
∀ x ∈ I, f(x0) + λ(x0)(x − x0) ≤ f(x). (4.13)
If for every pair x1, x2 ∈ I, f((x1 + x2)/2) ≥ (1/2)f(x1) + (1/2)f(x2), then
the function f is a concave function.
In Equation (4.13), the left hand side of the inequality may be interpreted
as a tangent through x0. If it exists, then the inequality implies that all the
points of the curve f(x) are above this tangent line. If f is twice differentiable
then the necessary and sufficient condition for f to be convex is f
′′(x) > 0
and for f to be concave is f
′′(x) < 0.
Lemma 4.5.7. Jensen’s inequality: If f(·) is a convex function and if E(X)
is finite, then
f(E(X)) ≤ E(f(X)).
If f(·) is a concave function and if E(X) is finite, then
f(E(X)) ≥ E(f(X)).
Proof. Suppose f(·) is a convex function and I is any interval in the domain of
f(·). By the property of convex function, for every x0 ∈ I, there corresponds
a number λ(x0) such that for all x ∈ I,
λ(x0)(x − x0) ≤ f(x) − f(x0) (4.14)
Suppose X is a random variable with support I. Replacing x0 by E(X) and
x by X in (4.14), we have,
λ(E(X))(X − E(X)) ≤ f(X) − f(E(X)).
Taking expectation on both the sides of the above inequality, we get
0 ≤ E(f(X)) − f(E(X)) ⇐⇒ f(E(X)) ≤ E(f(X)).
Proof for the concave function follows on similar lines.
If f(·) is convex, monotone increasing and has an inverse f
−1
(·), we get,
E(X) ≤ f
−1
(E(f(X))).
For example, if f(x) = x
r
, for r ≥ 1, x ≥ 0, we have, E(X) ≤ E1/r(Xr
).
If r = 2, then Jensen’s inequality conveys the well known fact that variance
of X is always non-negative.
Lemma 4.5.8. Basic inequality: Suppose X is an arbitrary random vari￾able and g(·) is a non-negative Borel function on R. If g(·) is even and non￾decreasing on [0, ∞), then for every a > 0,
E(g(X)) − g(a)
a.s.sup g(X)
≤ P[|X| ≥ a] ≤
E(g(X))
g(a)
.Moment Inequalities 209
Proof. Since g(·) is a Borel function on R, it follows that g(X) is a random
variable. Further, g(X) is non-negative, hence there exists a non-decreasing
sequence of non-negative simple random variables gn(X) such that
gn(X(ω)) → g(X(ω)) ∀ ω ∈ Ω. Note that E[gn(X)] is a non-decreasing se￾quence of non-negative real numbers, hence it converges. Thus, E[g(X)] =
limn→∞ E[gn(X)] exists. Therefore we can write,
E[g(X)] = Z
A
g(X)dP +
Z
Ac
g(X)dP, (4.15)
where, A = [|X| ≥ a]. We are given that g(·) is non-decreasing on [0, ∞).
Therefore, on A, a ≤ |X| ⇒ g(a) ≤ g(|X|) = g(X), in view of the fact
that g(X) is an even function. Thus, g(a) ≤ g(X) ≤ a.s.sup g(X). Using
monotonicity of integrals, we have,
Z
A
g(a)dP ≤
Z
A
g(X)dP ≤
Z
A
a.s.sup g(X)dP
⇒ g(a)P(A) ≤
Z
A
g(X)dP ≤ [a.s.sup g(X)]P(A). (4.16)
On Ac
, |X| < a. Therefore, using the same arguments as above and non￾negative nature of g(X), we get 0 ≤ g(X) ≤ g(a) and hence integrating
each of these terms over Ac
, we get,
0 ≤
Z
Ac
g(X)dP ≤ g(a)P(A
c
).
However, P(Ac
) ≤ 1. Hence, we get,
0 ≤
Z
Ac
g(X)dP ≤ g(a). (4.17)
Adding inequalities in (4.16) and (4.17) and using (4.15), we get,
g(a)P(A) ≤ E[g(X)] ≤ [a.s.sup g(X)]P(A) + g(a) . (4.18)
From the right hand side of the inequality in (4.18), we get
E(g(X)) − g(a)
a.s.sup g(X)
≤ P(A) = P[|X| ≥ a].
Using the left hand side of the inequality in (4.18), we get
P[|X| ≥ a] = P(A) ≤
E[g(X)]
g(a)
.
With specific choices of g in basic inequality we get famous Markov in￾equality and Chebyshev’s inequality.210 Expectation and Characteristic Function
Lemma 4.5.9. Markov inequality: For r > 0,
P(|X| ≥ a) ≤
E(|X|
r
)
a
r
.
Proof. It is to be noted that a function g(x) = |x|
r
is non-negative and even
as g(−x) = | − x|
r = |x|
r = g(x). Also, for any two positive real numbers
x1, x2, x1 ≤ x2 implies x
r
1 ≤ x
r
2
. Thus, g(x) is non-decreasing on [0, ∞).
Hence, using this function in basic inequality we get,
E(|X|
r
) − a
r
a.s.sup |X|
r
≤ P[|X| ≥ a] ≤
E(|X|
r
)
a
r
.
The right hand side of the above inequality is the Markov inequality.
Lemma 4.5.10. Chebychev’s inequality
P(|X| ≥ a) ≤
E(X2
)
a
2 ⇐⇒ P[|X| < a] ≥ 1 −
E(X2
)
a
2
.
Proof. Substituting r = 2 in Markov inequality, we get Chebyshev’s inequality.
From Chebyshev’s inequality we note that P[|X − E(X)| < a] ≥ 1 −
V ar(X)
a2 . It shows that if a random variable X has a small variance, then the
distribution of X is tightly concentrated about E(X), however the converse
is not true. The fact that X is tightly concentrated about E(X) tells us little
about the variance or other moments of X.
A quick recap of the results discussed in this chapter is given below.
Summary
1. For a simple random variable X =
Pk
i=1 aiIAi
, expectation E(X) is de￾fined as E(X) = R
Ω XdP =
Pk
i=1 aiP(Ai).
2. Suppose X1 and X2 are simple random variables. Then
(i) E(X1 ± X2) = E(X1) ± E(X2). (ii) E(aX1) = aE(X1), where a is any
real number. (iii) E(aX1 + bX2) = aE(X1) + bE(X2) where a and b are
any real numbers. (iv) If X1 ≥ X2 on Ω, then E(X1) ≥ E(X2).
(v) If X1 ≥ 0 a.s., then E(X1) ≥ 0.
3. Suppose X is a non-negative random variable, then
E(X) = R
Ω XdP = limn→∞ E(Xn), where {Xn, n ≥ 1} is a non￾decreasing sequence of non-negative simple random variables such that
Xn → X on Ω.Moment Inequalities 211
4. Suppose X is an arbitrary random variable with X+and X− as its positive
and negative parts respectively. Then E(X) is defined as
E(X) = R
Ω XdP = E(X+) − E(X−), provided at least one of the two
E(X+) and E(X−) is finite.
5. A random variable X is said to be integrable if E(X) is finite. An arbi￾trary random variable X is integrable if and only if both X+ and X− are
integrable.
6. Suppose X is an integrable random variable defined on (Ω, A, P) and
A ∈ A is such that P(A) = 0. Then R
A X dP = 0.
7. Suppose X1 and X2 are random variables such that E(X1), E(X2) and
E(X1) + E(X2) exist. (i) If X1 ≥ 0 a.s., then E(X1) ≥ 0 (Non￾negativity). (ii) E(cX1) = cE(X1), where c is any real number. (iii) If
X1 = 0 a.s., then E(X1) = 0. (iv) E(X1 + X2) = E(X1) + E(X2) (Lin￾earity). (v) If X1 ≥ X2 a.s., then E(X1) ≥ E(X2). (vi) X1 is integrable
if and only if |X1| is integrable. (vii) If |X1| ≤ Y , where Y is an integrable
random variable then X1 is integrable.
8. Suppose X is random variable defined on a probability space (Ω, A, P)
to (R, B, PX). Suppose g : (R, B) → (R, B) is a Borel function. Then,
E(g(X)) = R
Ω
g(X)dP =
R
R
g(x)dPX =
R
R
g(x)dF(x).
9. Suppose X is a discrete random variable with P[X = i] = pi
, i ∈ W, the
set of whole numbers . Then E(X) = P
n≥1 P[X ≥ n].
10. Suppose X is a continuous random variable with distribution function F
and suppose F is differentiable. Then
E(X) =



R∞
0
[1 − F(x)]dx, if X ≥ 0,
−
R
0
−∞
F(x)dx +
R∞
0
[1 − F(x)]dx, if X is arbitrary.
Characteristic Function
1. Suppose Z = (X, Y )
′
is a bivariate random vector defined on a probability
space (Ω, A, P) to (R
2
, B
2
, PZ). Then W = X + iY is a complex valued
random variable and its expectation is defined as E(W) = E(X) +iE(Y ).
A complex valued random variable W = X + iY is said to be integrable if
and only if both X and Y are integrable. Further, |E(W)| ≤ E(|W|).
2. The characteristic function ϕX(t) of a random variable X is defined as
ϕX(t) = E(exp(itX)) = E(costX + isin tX) = E(costX) + iE(sin tX).
It is defined for all t ∈ R.212 Expectation and Characteristic Function
3. If Y = aX+b where a ̸= 0 and b are any real numbers, then a characteristic
function of Y is given by,
ϕY (t) = E(exp(itY )) = E(exp(it(aX + b))) = exp(itb)ϕX(at).
4. ϕ−X(t) = ϕX(−t) = ϕX(t), a complex conjugate of ϕX(t).
5. If the distribution of X is symmetric around 0, then ϕX(t) is a real valued
function.
6. If F =
Pk
i=1 αiFi
, αi ≥ 0 & Pk
i=1 αi = 1 is a convex combination of
distribution functions, then the characteristic function ϕ(t) corresponding
to F is again a convex combination of the characteristic functions ϕi(t) of
component distribution functions and is given by ϕ(t) = Pk
i=1 αϕi(t).
7. A sequence of random variables {Xn, n ≥ 1} is said to be bounded in
probability if for a given ϵ > 0, there exists a constant K and an integer
n0 such that,
P[|Xn| ≤ K] ≥ 1 − ϵ ⇐⇒ P[|Xn| > K] < ϵ, ∀ n ≥ n0.
8. A real random variable is bounded in probability.
9. (i) |ϕX(t)| ≤ 1. (ii) ϕX(0) = 1. (iii) ϕX(·) is uniformly continuous on R.
10. If E(|X|
n) < ∞ where n is a positive integer, then ϕX(t) is differentiable
n times for all t ∈ R and n-th derivative ϕ
(n)
X (t) is given by,
ϕ
(n)
X (t) = d
n
dtn
ϕX(t) = Z ∞
−∞
(ix)
n
e
itxdF(x) & ϕ
(n)
X (0) = i
nE(Xn
).
11. If E(|X|
k
) < ∞ where k is a positive integer, then ϕX(t) can be expressed,
ϕX(t) =
k
X−1
s=0
(it)
s
s!
E(Xs
) + t
k
Z 1
0
(1 − u)
k−1
(k − 1)! ϕ
(k)
X (tu) du,
where ϕ
(k)
X (tu) is the k-th derivative of ϕX(t) at tu.
12. If moments of all order of X are finite, then ϕX(t) can be expressed,
ϕX(t) = X∞
s=0
(it)
s
s!
E(Xs
).
13. Inversion Theorem: Suppose ϕX(t) is a characteristic function of a random
variable X with distribution function FX. Then
FX(b) − FX(a) + (1/2)P[X = a] − (1/2)P[X = b]
=
1
2π
limc→∞ Z c
−c

e
−ita − e
−itb
it 
ϕX(t) dt.Moment Inequalities 213
If a < b ∈ C(FX), then
FX(b) − FX(a) = 1
2π
limc→∞ Z c
−c

e
−ita − e
−itb
it 
ϕX(t) dt.
The value of the integrand at t = 0 is determined by continuity, that is,
by using L’Hospital’s rule and it is b − a.
14. Uniqueness theorem: ϕX(t) = ϕY (t) ∀ t ∈ R ⇐⇒ X
d= Y .
15. If F is differentiable at x with F
′
(x) = f(x), then
f(x) = lim
h→0
limc→∞
1
2π
Z c
−c

1 − e
−ith
ith 
e
−itxϕ(t) dt,
if and only if the limits on the right hand side exist.
(ii) If ϕ is Riemann integrable on R and if F
′
(x) = f(x) exists ∀ x ∈ R,
then
f(x) = 1
2π
Z
R
e
−itxϕ(t) dt
and f(x) is continuous on R.
16. If P[X = a] > 0, then
P[X = a] = FX(a + 0) − FX(a − 0) = limc→∞
1
2c
Z c
−c
e
−itaϕX(t) dt.
17. If X is a discrete random variable with support I, then
ϕX(t) = X
x∈I
pxe
itx & px = P[X = x] = 1
2π
Z π
−π
e
−itxϕX(t) dt.
18. A characteristic function ϕZ(t) of a random vector Z = (X1, X2, · · · , Xk)
′
,
where t = (t1, t2, · · · , tk)
′
, ti ∈ R, i = 1, 2, · · · , k, is defined as
ϕZ(t) = ϕZ(t1, t2, · · · , tk) = E(exp(i(t1X1 + t2X2 + · · · + tkXk))
= E(exp(t
′Z)).
Moment Inequalities
1. If E(|X|
r
) < ∞, then E(|X|
r
′
) < ∞, for 0 < r′ ≤ r and E(Xk
) exists and
is finite for k < r, if k is an integer.
2. Cr inequality: Suppose X ∈ Lr and Y ∈ Lr, then for any r > 0,
E(|X + Y |
r
) ≤ Cr (E(|X|
r
) + E(|Y |
r
)), where,
Cr =

1, if r ≤ 1,
2
r−1
, if r > 1.214 Expectation and Characteristic Function
3. Holder’s inequality: E(|XY |) ≤ E1/r(|X|
r
)E1/s(|Y |
s
), for r > 1 and
1/r + 1/s = 1. With r = s = 2 we get E(|XY |) ≤
p
E(|X|
2)E(|Y |
2)
which is known as Schwarz inequality or Cauchy-Schwarz inequality.
4. Minkowski inequality: E1/r(|X + Y |
r
) ≤ E1/r(|X|
r
) + E1/r(|Y |
r
) for
r ≥ 1.
5. Jensen’s inequality: If f(·) is a convex function and if E(X) is finite, then
f(E(X)) ≤ E(f(X)). If f(·) is a concave function and if E(X) is finite,
then f(E(X)) ≥ E(f(X)).
6. Basic inequality: Suppose X is an arbitrary random variable and g(·) is
a non-negative Borel function on R. If g(·) is even and non-decreasing on
[0, ∞), then for every a > 0,
E(g(X)) − g(a)
a.s.sup g(X)
≤ P[|X| ≥ a] ≤
E(g(X))
g(a)
.
7. Markov inequality: For r > 0, P[|X| ≥ a] ≤ E(|X|
r
)/ar
.
8. Chebychev inequality: P[|X| ≥ a] ≤ E(X2
)/a2 which is equivalent to
P[|X| < a] ≥ 1 − E(X2
)/a2
.
4.6 Conceptual Exercises
4.6.1 Give an example of a discrete random variable with infinite mean.
4.6.2 Give an example of a discrete random variable with finite mean but with
infinite variance.
4.6.3 Suppose X and Y are random variables such that P[|X − Y | ≤ M] = 1
for some M > 0. Show that Y has finite mean if X has finite mean.
4.6.4 Show that for any non-negative random variable X,
(i) E(X) + E(1/X) ≥ 2 and (ii) E(max{X, 1/X}) ≥ 1.
4.6.5 Prove that for a non-negative random variable X, E(X) = 0 implies
X = 0 a.s.
4.6.6 Prove that if V ar(X) = 0, then X = E(X) a.s.
4.6.7 Suppose X is an integrable random variable and A∆B is a null event.
Show that R
A X dP =
R
B X dP.
4.6.8 Prove or disprove: X ≡ 0 implies R
Ω XdP = 0, but R
Ω XdP = 0 may
not imply X ≡ 0.Conceptual Exercises 215
4.6.9 Suppose Ω = {−2, −1, 3, 7} and A is a powerset of Ω. A measure µ
on (Ω, A) is defined as µ({−2}) = 2, µ({−1}) = 1, µ({3}) = 3 and
µ({7}) = 7. Obtain a probability measure P from µ. Suppose a random
variable X is defined on (Ω, A, P) as follows.
X(ω) = 
1, if ω = 3 or 7
−1, if ω = −2 or − 1 .
Find R
Ω X dP.
4.6.10 Suppose (Ω, A, P) is a probability space where A is a sigma field gener￾ated by a countable partition {An, n ≥ 1} of Ω. Suppose a random vari￾able X is defined on (Ω, A, P) as X = i on Ai
, i ≥ 1. Find R
Ω X dP if the
probability measure P is defined as (i) P(Ai) = c/i3
P
, where c is such that
i≥1
c/i3 = 1, (ii) P(Ai) = c/i2
, where c is such that P
i≥1
c/i2 = 1 and
(iii) P(Ai) = 1/2
i
. In all the three cases, find R
Ω
Y dP, when Y = X2
and Y = e
X.
4.6.11 Suppose a distribution function F : R → [0, 1] is defined as follows.
F(x) =



0, if x < 0,
0.2, if 0 ≤ x < 1,
0.5, if 1 ≤ x < 2,
0.8, if 2 ≤ x < 4,
1, if x ≥ 4.
Compute E(X) from F(x), without finding the probability mass func￾tion.
4.6.12 Suppose a distribution function F : R → [0, 1] is defined as follows.
F(x) =



0, if x < −2,
1/3, if −2 ≤ x < 0,
1/2, if 0 ≤ x < 5,
1/2 + (x − 5)2/2, if 5 ≤ x < 6,
1, if x ≥ 6.
Find (i) E(X) from F(x). (ii) Decompose F into discrete and continuous
components. (iii) Identify the distributions in the decomposition and
hence find E(X).
4.6.13 Suppose a distribution function F : R → [0, 1] is defined as follows.
F(x) =



0, if x < −2,
0.2, if −2 ≤ x < 1,
0.2 + x
2/10, if 1 ≤ x < 2,
0.6 + x/10, if 2 ≤ x < 3,
1, if x ≥ 3.216 Expectation and Characteristic Function
Find (i) E(X) from F(x). (ii) Decompose F into discrete and continuous
components. (iii) Identify the distributions in the decomposition and
hence find E(X).
4.6.14 Suppose a distribution function F : R → [0, 1] is defined as follows.
F(x) =



0 , if x < 2
(2/3)x − 1 , if 2 ≤ x < 3
1 , if x ≥ 3.
Find (i) E(X) from F(x). (ii) Decompose F into discrete and continuous
components. (iii) Identify the distributions in the decomposition and
hence find E(X).
4.6.15 Suppose a distribution function F : R → [0, 1] is defined as follows.
F(x) =



0 , if x < 0
1/4 , if 0 ≤ x < 1
1 −
1
2
e
−(x−1)
, if x ≥ 1.
(i) Find E(X) from F(x). (ii) Decompose F into discrete and continuous
components. (iii) Identify the distributions in the decomposition and
hence find E(X).
4.6.16 Suppose a distribution function F : R → [0, 1] is defined as follows.
F(x) =



0, if x < 0,
(pr + (1 − p)x)/k, if r ≤ x < r + 1, r = 0, 1, · · · , k − 1,
1, if x ≥ k,
0 < p < 1. (i) Find E(X) from F(x). (ii) Decompose F into discrete and
continuous components. (iii) Identify the distributions in the decompo￾sition and hence find E(X).
4.6.17 Prove that for a non-negative random variable X, E(X) = 0 implies
X = 0 a.s.
4.6.18 If X ≥ 0 on A and R
A X dP = 0 then show that X = 0 a.s. on A.
4.6.19 If a ≤ X ≤ b a.s. on A then show that aP(A) ≤
R
A X dP ≤ bP(A).
4.6.20 Examine whether following functions are characteristic functions.
(i) ϕ1(t) = ϕ(t/a) exp(ibt), a ̸= 0, b ∈ R and ϕ is a characteristic func￾tion,
(ii) ϕ1(t) = ϕ(−t), where ϕ is a characteristic function,
(iii) ϕ(t) = exp{−|t|}, t ∈ R,
(iv) ϕ(t) = exp{λ(ψ(t − 1))} where ψ is a characteristic function and
λ > 0,
(v) ϕ(t) = P∞
j=0 ajϕj (t), aj ≥ 0 and P∞
j=0 aj = 1 and ϕj (t) are char￾acteristic functions for all j = 0, 1, · · · and
(vi) ϕ(t) = 1/(1 + t
4
) where t ∈ R, (vii) ϕ(t) = | cost|.Multiple Choice Questions 217
4.6.21 Suppose a discrete random variable has finite second moment. Show
that it has finite mean.
4.6.22 Suppose Lr = {Z|E(|Z|
r
) < ∞}. Prove that the set Lr is closed under
addition.
4.6.23 Suppose X ∼ U(0, 2) distribution then without evaluating, show that
E(X log X) ≥ 0.
4.7 Multiple Choice Questions
Note: In each question, multiple options may be correct. Answers are given
in Chapter 11, after the solutions of conceptual exercises of Chapter 4.
4.7.1 If X is a real valued random variable, which of the following quantities
will always be finite?
(a) E(X)
(b) E(X+X−)
(c) E(X+ − X−)
(d) None of the above.
4.7.2 In which of the following cases, expectation may not exist?
(a) X is a degenerate random variable
(b) X is a simple random variable
(c) X is a non-negative random variable
(d) Support of X is R
4.7.3 Which of the following need not be always true?
(a) E(X + Y ) = E(X) + E(Y )
(b) E(X − Y ) = E(X) − E(Y )
(c) E(aX + bY ) = aE(X) + bE(Y )
(d) E(XY ) = E(X)E(Y )
4.7.4 Suppose X is a discrete random variable with support as the set W of
whole numbers and suppose P[X = i] = pi
, i ∈ W. Then which of the
following is not always true?
(a) E(X) = P
i≥0
ipi
(b) E(X) = P
n≥1 P[X ≥ n]
(c) E(X) = P
n>1 P[X ≥ n]
(d) E(X) = P
i≥1
ipi
4.7.5 If X is a non-negative random variable, which of the following is false?218 Expectation and Characteristic Function
(a) E(X2
) ≥ [E(X)]2
(b) E(X3
) ≥ [E(X)]3
(c) E(X−2
) ≥ [E(X)]−2
(d) E(X4
) ≤ [E(X)]4
4.7.6 Which of the following is/are not always true, if X is an arbitrary ran￾dom variable?
(a) E(X2
) ≥ [E(X)]2
(b) E(X3
) ≥ [E(X)]3
(c) E(X−2
) ≥ [E(X)]−2
(d) E(X4
) ≤ [E(X)]4
4.7.7 If E(X2
) is finite, which of the following need not be finite?
(a) E(X)
(b) E(|X|)
(c) E(X3/2
)
(d) E(X3
)
4.7.8 Which of the following statements is/are false?
(a) X is integrable implies |X| is integrable
(b) |X| is integrable implies X is integrable
(c) X is integrable implies X2
is integrable
(d) X2
is integrable implies X is integrable
4.7.9 Following are four statements: (I) X is integrable implies |X| is inte￾grable. (II) |X| is integrable implies X is integrable. (III) X is integrable
implies X2
is integrable. (IV) X2
is integrable implies X is integrable.
Then which of the following is/are true?
(a) Both (I) and (II) are true
(b) Both (III) and (IV) are true
(c) Both (II) and (IV) are true
(d) Both (I) and (III) are true
4.7.10 If support of a random variable X is denoted by S, in which of the
following cases, E(X) may not exist?
(a) S is a singleton set.
(b) S = (0, ∞)
(c) S is a finite set having positive as well as negative elements
(d) S = R
4.7.11 Suppose X and Y are two random variables whose third order moments
exist. Then which of the following statements is correct?
(a) ￾
E(|X + Y |)
3
1/3
≤
￾
E(|X|)
3
1/3
×
￾
E(|Y |)
3
1/3
(b) ￾
E(|X + Y |)
3
1/3
≤
￾
E(|X|)
3
1/3
+
￾
E(|Y |)
3
1/3
(c) ￾
E(|X + Y |)
3
1/3
≤ (E(|X|) + E(|YMultiple Choice Questions 219
(d) ￾
E(|X + Y |)
3
1/3
≤ (E(|X|) × E(|Y |))1/3
4.7.12 Suppose X is a non-negative random variable whose mean exists. Then
which of the following statements is correct?
(a) E(log X) ≤ log E(X)
(b) E(log X) ≥ log E(X)
(c) E(log X) = log E(X)
(d) None of (a), (b) and (c) is true
4.7.13 Suppose X is an arbitrary random variable and g(·) is a non-negative
Borel function on R. If g(·) is even and non-decreasing on [0, ∞), then
which of the following statements is correct? ∀ a > 0
(a) P[|X| ≤ a] ≤ E(g(X))/g(a)
(b) P[|X| ≤ a] ≥ E(g(X))/g(a)
(c) P[|X| ≥ a] ≤ E(g(X))/g(a)
(d) P[|X| ≥ a] ≥ E(g(X))/g(a)
4.7.14 Following are two statements. (I) If the distribution of X is symmetric
around 0, then its characteristic function is a real valued function.
(II) If the characteristic function of X is a real valued function, then the
distribution of X is symmetric around 0. Which of the following options
is correct?
(a) Both (I) and (II) are true
(b) Both (I) and (II) are false
(c) (I) is true but (II) is false
(d) (I) is false but (II) is true
4.7.15 The characteristic function of X ∼ B(n, p) is
(a) (p + (1 − p)e
it)
n
(b) (1 − p + peit)
−n
(c) (1 − p + peit)
n
(d) (p + (1 − p)e
it)
−n
4.7.16 The characteristic function of X ∼ P(λ) is
(a) e
−λ(e
it−1)
(b) e
λ(e
it+1)
(c) e
λ(e
−it−1)
(d) e
λ(e
it−1)
4.7.17 The domain of the characteristic function of any random variable X is
(a) R
(b) (0, ∞)
(c) (0, 1)
(d) depends on the distribution of X220 Expectation and Characteristic Function
4.7.18 Suppose ϕ(t) = 1/(1 + t
2
) is a characteristic function of a random
variable X. Then E(X) and V ar(X) are respectively given by
(a) {1/2, 1/8}
(b) {0, 2}
(c) {0, 1}
(d) {1/2, 1/16}
4.7.19 Suppose ϕ(t) = e
−|t|
is a characteristic function of a random variable
X. Then the distribution of X is
(a) normal
(b) Laplace
(c) Students t with 1 degree of freedom
(d) Cauchy
4.7.20 Following are two statements. (I) if X is a simple random variable,
then for any function g, g(X) is also a simple random variable. (II) If g
is a simple Borel function, then for any random variable X, g(X) is a
simple random variable. Which of the following options is correct?
(a) Both (I) and (II) are true
(b) Both (I) and (II) are false
(c) (I) is true but (II) is false
(d) (I) is false but (II) is true5
Independence
5.1 Introduction
There are some similarities between probability theory and measure theory.
A probability measure is essentially a normed measure with the measure of
the sample space equal to one. A probability space is a measure space where
the measure is replaced by a probability measure. A random variable in prob￾ability theory is nothing but a measurable function in measure theory, the
concept of expectation in probability theory parallels the concept of integra￾tion in measure theory. Some modes of convergence of a sequence of random
variables are similar to the convergence of a sequence of measurable functions.
For example, almost sure convergence from probability theory is the same as
the almost everywhere convergence in measure theory, convergence in proba￾bility is the same as the convergence in measure. In spite of such similarities,
probability theory is not merely a branch of measure theory.
A distinguishing and fundamental feature of probability theory is the no￾tion of independence, which has no parallel in measure theory. It is one of
the most central concepts of probability theory and a large part of the theory
explores the consequences of the presence of this property and the lack of it.
The present chapter is devoted to the study of the fundamentals of the theory
of independence of random variables and some related ideas.
In simple words, independence of trials of the experiment means that the
outcome in one trial of the experiment does not influence the chance of oc￾currence of a particular outcome in the next trial, that is, the probabilities
of occurrence of events in future does not depend on the occurrence of events
in the past, that knowledge of the outcomes of trials so far does not provide
any information about the chance of outcomes of the future trials. The clas￾sical examples are coin-tossing and throwing dice where successive outcomes
are independent. In sampling without replacement from a finite population,
successive outcomes are not independent, the typical example being drawing
cards from a deck of cards. We now proceed for the rigorous discussion of the
concept of independence.
In the next section, we discuss the concept of independence of events
and independence of classes of events. Section 3 is concerned with the in￾dependence of random variables and some related results. Section 4 presents
DOI: 10.1201/9781032619057-5 221222 Independence
Kolmogorov zero-one law about tail events, which is concerned with a sequence
of independent random variables.
5.2 Independence of Events and Classes of Events
Suppose (Ω, A, P) is a probability space. We begin with the basic definition
of independence of two events.
Definition 5.2.1. Independence of two events: Two events A1 and A2 in A
are said to be independent if P(A1 ∩ A2) = P(A1)P(A2).
As a consequence of this definition,
P(A1|A2) = P(A1 ∩ A2)/P(A2) = P(A1)
& P(A2|A1) = P(A1 ∩ A2)/P(A1) = P(A2).
Thus, the knowledge of occurrence of A2 does not affect the probability of
occurrence of A1 and the knowledge of occurrence of A1 does not affect the
probability of occurrence of A2. The conditional probability P(A1|A2) is the
same as the unconditional probability P(A1). Further, A1 and A2 are inde￾pendent implies that
P(A1 ∩ A2) = P(A1)P(A2)
⇐⇒ P(A1 ∩ A2)/P(A1) = P(A2) = P(A2)/P(Ω)
& P(A1 ∩ A2)/P(A2) = P(A1) = P(A1)/P(Ω).
Note that P(A1 ∩ A2)/P(A1) = P(A2)/P(Ω) implies that the relative prob￾ability measure of A1 ∩ A2 relative to that of A1 is the same as the relative
probability measure of A2 relative to that of Ω when A1 and A2 are indepen￾dent. Similarly, P(A1 ∩ A2)/P(A2) = P(A1) = P(A1)/P(Ω) implies that the
relative probability measure of A1 ∩ A2 relative to that of A2 is the same as
the relative probability measure of A1 relative to that of Ω.
An important point to be noted in the concept of independence is that
it is not a property of events, but it is a property of underlying probability
measure. The two events may be independent with respect one probability
measure but may not be with respect to another probability measure. This
feature is illustrated in the following example.
Example 5.2.1. Suppose (Ω, A) is a measurable space, where Ω =
{1, 2, 3, 4, 5, 6}, A = P(Ω). Two probability measures P and P
∗ on (Ω, A)
are defined as follows.
P(ω) = 1/6 ∀ ω ∈ Ω & P
∗
({1}) = P
∗
({3}) = P
∗
({6}) = 1/4,Independence of Events and Classes of Events 223
P
∗
({2}) = P
∗
({4}) = 1/8 & P
∗
({5}) = 0.
Suppose A = {1, 3, 5} and B = {2, 3, 4}. Observe that,
P(A) = P(B) = 1/2 & P(A ∩ B) = P({3}) = 1/6
⇒ P(A)P(B) = 1/4 ̸= P(A ∩ B) = 1/6
P
∗
(A) = P
∗
(B) = 1/2 & P
∗
(A ∩ B) = P({3}) = 1/4
⇒ P
∗
(A)P
∗
(B) = 1/4 = P
∗
(A ∩ B).
Thus A is not independent of B with respect to the probability measure P,
but A and B are independent with respect to the probability measure P
∗
. □
Example 5.2.1 conveys that whenever we discuss independence of events or
independence of random variables, underlying probability space must be the
same. Next theorem addresses some simple but frequently used results related
to independence of events.
Theorem 5.2.1. Suppose (Ω, A, P) is a probability space.
(i) An event A ∈ A is independent of itself if and only if its probability
measure is 0 or 1.
(ii) An event A ∈ A is independent of Ac
if and only if P(A) is 0 or 1.
(iii) Any event A ∈ A is independent of sure event Ω and null event ∅.
(iv) Suppose N ∈ A is a P-null event. Then any event A ∈ A is independent
of N and Nc
.
(v) Suppose N ∈ A is a P-null event. Then N is independent of Nc
.
(vi) Suppose A1, A2 ∈ A. If A1 and A2 are independent then A1 and Ac
2
, Ac
1
and A2, Ac
1 and Ac
2 are also independent.
Proof. (i) By the definition of independence, A is independent of itself if,
P(A ∩ A) = P(A)P(A) ⇒ P(A) = (P(A))2 ⇒ P(A)(1 − P(A)) = 0
⇒ P(A) = 0 or 1.
Suppose P(A) = 0 or 1. To examine if A is independent of itself, observe that
P(A) = 0 ⇒ P(A ∩ A) = P(A) = 0 = P(A)P(A)
& P(A) = 1 ⇒ P(A ∩ A) = P(A) = 1 = P(A)P(A)
⇒ A is independent of itself.
Thus, A is independent of itself if and only if its probability measure is 0 or
1, that is, it is either a P-null event or a complement of P-null event.
(ii) Note that P(A ∩ Ac
) = P(∅) = 0 = P(A)P(Ac
) if and only if P(A) is 0224 Independence
or 1.
(iii) It is clear that
P(A ∩ Ω) = P(A) = P(A)P(Ω) & P(A ∩ ∅) = P(∅) = 0 = P(A)P(∅).
Thus, any event A is independent of sure event Ω and impossible event ∅.
(iv) Note that
P(N) = 0 ⇒ P(A ∩ N) ≤ P(N) = 0 ⇒ P(A ∩ N) = 0 = P(A)P(N).
Hence, any event A ∈ A is independent of N. Further,
P(N
c
) = 1 ⇒ P(A ∩ N
c
) = P(A) − P(A ∩ N) = P(A) = P(A)P(N
c
).
Hence, any event A is independent of Nc
.
(v) It is clear that
P(N ∩ N
c
) = P(∅) = 0 = P(N)P(N
c
).
Hence, P-null event N is independent of Nc
.
(vi) Observe that
A1 = (A1 ∩ A2) ∪ (A1 ∩ A
c
2
) ⇒ P(A1) = P(A1 ∩ A2) + P(A1 ∩ A
c
2
)
⇒ P(A1 ∩ A
c
2
) = P(A1) − P(A1 ∩ A2)
⇒ P(A1 ∩ A
c
2
) = P(A1) − P(A1)P(A2) = P(A1)P(A
c
2
)
⇒ A1 & A
c
2 are independent.
Now
A2 = (A1 ∩ A2) ∪ (A
c
1 ∩ A2) ⇒ P(A2) = P(A1 ∩ A2) + P(A
c
1 ∩ A2)
⇒ P(A
c
1 ∩ A2) = P(A2) − P(A1 ∩ A2)
⇒ P(A
c
1 ∩ A2) = P(A2) − P(A1)P(A2) = P(A
c
1)P(A2)
⇒ A
c
1 & A2 are independent.
A
c
1 ∩ A
c
2 = (A1 ∪ A2)
c ⇒ P(A
c
1 ∩ A
c
2) = 1 − P(A1 ∪ A2)
⇒ P(A
c
1 ∩ A
c
2) = 1 − P(A1) − P(A2) + P(A1)P(A2)
⇒ P(A
c
1 ∩ A
c
2) = (1 − P(A1))(1 − P(A2)) = P(A
c
1)P(A
c
2)
⇒ A
c
1 & A
c
2 are independent.
We now extend the concept of independence of two events to a collection
of countable number of events.
Definition 5.2.2. Independence of k events: Suppose {A1, A2, · · · , Ak} is a
finite collection of events from A. We say that these k events are independent
if,
P(Ai1 ∩ Ai2 ∩ · · · ∩ Air
) = Yr
l=1
P(Ail
), (5.1)
for every possible combination {i1, i2, · · · , ir} of {1, 2, · · · , k}, 2 ≤ r ≤ k.Independence of Events and Classes of Events 225
To check the independence of k events, we need to verify,

k
2

+

k
3

+ · · · +

k
k

= 2k −

k
1

−

k
0

= 2k − k − 1
conditions as specified in Equation (5.1).
It is to be noted that independence of {A1, A2, A3} implies that for
three possible pairs, P(Ai ∩ Aj ) = P(Ai)P(Aj ) and P(A1 ∩ A2 ∩ A3) =
P(A1)P(A2)P(A3). The concept of pair-wise independence, as defined below,
is slightly weaker than the concept of independence.
Definition 5.2.3. Pair-wise independence: Suppose {A1, A2, · · · , Ak} is a
finite collection of events from A. We say that these k events are pair-wise
independent if,
P(Ai ∩ Aj ) = P(Ai)P(Aj ), ∀ i ̸= j = 1, 2, · · · , k. (5.2)
A collection of independent events is obviously a collection of pair-wise
independent events. However, the converse is not true as shown in the following
example.
Example 5.2.2. Suppose a probability space (Ω, A, P) is defined as follows.
Ω = {(1, 0, 0),(0, 1, 0),(0, 0, 1),(1, 1, 1)}, A = P(Ω) and P({ω}) = 1/4 ∀ ω ∈
Ω. Suppose an event Ai
is defined as Ai = {ω|i-th coordinate is 1}, i = 1, 2, 3.
Then it is clear that for i = 1, 2, 3,
P(Ai) = 1/2, P(Ai ∩ Aj ) = 1/4 i ̸= j = 1, 2, 3 & P(A1 ∩ A2 ∩ A3) = 1/4.
Observe that ∀ i ̸= j = 1, 2, 3, P(Ai ∩ Aj ) = P(Ai)P(Aj ), however
P(A1 ∩ A2 ∩ A3) ̸= P(A1)P(A2)P(A3). Thus, A1, A2, A3 are pair-wise inde￾pendent but not independent, which is usually referred to as A1, A2, A3 are
not mutually independent. □
Example 5.2.3. Suppose a probability space (Ω, A, P) is defined as follows.
Ω = {ω = (a1, a2, · · · , an)|ai = 0, 1, i = 1, 2, · · · , n}, A = P(Ω) & P(ω) = 1/2
n
.
An event Ai
is defined as Ai = {(a1, a2, · · · , an)|ai = 1}, i = 1, 2, · · · , n. We
examine whether the collection {A1, A2, · · · , An} is a collection of independent
events. By the definition of Ai
, i-th component is fixed at 1 and remaining
n − 1 components can be either 0 or 1. Thus, the number of elements in Ai
is 2
(n−1) and each has the same probability. Hence, for the given probability
measure, P(Ai) = 2n−1/2
n = 1/2 ∀ i = 1, 2, · · · , n. Suppose {i1, i2, · · · , im}
is any combination of {1, 2, · · · , n} for 2 ≤ m ≤ n. Then
Ai1 ∩ Ai2 ∩ · · · ∩ Aim = {(a1, a2, · · · , an)|aij = 1, j = 1, 2, · · · , m}
⇒ P(Ai1 ∩ Ai2 ∩ · · · ∩ Aim) = 2n−m/2
n = 1/2
m
⇒ P(Ai1 ∩ Ai2 ∩ · · · ∩ Aim) = P(Ai1
)P(Ai2
)· · · P(Aim) .226 Independence
Thus, every sub-collection of the collection {A1, A2, · · · , An} is a collection of
independent events. Hence, we claim that the collection {A1, A2, · · · , An} is
a collection of independent events. □
Definition 5.2.4. Sequence of independent events: Suppose {An, n ≥ 1} is
a sequence of events from A. We say that {An, n ≥ 1} is a sequence of inde￾pendent events if every finite sub-collection of {An, n ≥ 1} is a collection of
independent events.
We now extend the definition of independence of events to independence
among collections of events, in particular sigma fields of events.
Definition 5.2.5. Independence of two collections of events: Suppose C1 and
C2 are two collections of events in A. C1 and C2 are said to be independent
classes if
∀ A1 ∈ C1 and ∀ A2 ∈ C2, P(A1 ∩ A2) = P(A1)P(A2).
Example 5.2.4. Suppose C1 = {A, Ac
, ∅} and C2 = {B, Ω} are collections of
events. If A and B are independent events, then from the results in Theorem
5.2.1, it immediately follows that A and Ω, Ac and B, Ac and Ω, ∅ and B, ∅
and Ω are independent events. Thus,
∀ A1 ∈ C1 and ∀ A2 ∈ C2, P(A1 ∩ A2) = P(A1)P(A2).
Hence C1 and C2 are independent classes. □
Definition 5.2.6. Independence of k collections of events: Suppose
C1, C2, · · · , Ck are finite number of collections of events in A. Then
C1, C2, · · · , Ck are said to be independent collections if ∀ A1 ∈ C1, A2 ∈
C2, · · · , Ak ∈ Ck, {A1, A2, · · · , Ak} is a collection of independent events.
In particular, suppose Ci = σ(Xi) = {X
−1
i
(S)|S ∈ B} is a sigma field
induced by Xi
, i = 1, 2, · · · , k, where {X1, X2, · · · , Xk} are random variables
defined on (Ω, A, P) and B is the Borel field.
Definition 5.2.7. Sequence of independent collections: Suppose {Cn, n ≥ 1}
is a sequence of collections of events from A. We say that {Cn, n ≥ 1} is a
sequence of independent collections, if ∀ An ∈ Cn, n ≥ 1, {An, n ≥ 1} is a
sequence of independent events.
Remark 5.2.1. From the above definitions it follows that
(i) if every collection of events in Definition 5.2.7 contains exactly one event,
then this definition reduces to Definition 5.2.4.
(ii) an infinite collection of events is independent if and only if every finite
sub-collection is independent.
(iii) disjoint sub-collections of a sequence of independent events are indepen￾dent.Independence of Random Variables 227
Example 5.2.5. Suppose {An, n ≥ 1} is a sequence of independent events.
Thus, every finite sub collection of {An, n ≥ 1} is a collection of independent
events. Suppose we have a sequence of collections of events defined as
Cn = An = {{Ω, ∅, An, Ac
n}, n ≥ 1}. It is a sequence of sigma fields. We exam￾ine whether it is a sequence of independent sigma fields, given that {An, n ≥ 1}
is a sequence of independent events. In particular, A1 = {Ω, ∅, A1, Ac
1} and
A2 = {Ω, ∅, A2, Ac
2}. It is proved in Theorem 5.2.1, that any event is in￾dependent of Ω and ∅. Further, A1 is independent of A2 and also of Ac
2
.
Similarly, Ac
1
is independent of A2 and also of Ac
2
. Thus, A1 and A1 are in￾dependent sigma fields. On similar lines we can prove that every finite sub
collection of {An, n ≥ 1} is a collection of independent sigma fields and hence
{An = {Ω, ∅, An, Ac
n}, n ≥ 1} is a sequence of independent sigma fields. Note
that An is a σ-field induced by Xn = IAn
, n ≥ 1. □
Using these concepts of independence of sequence of events and indepen￾dence of collections of events, we define independence of random variables in
the next section.
5.3 Independence of Random Variables
Suppose {X1, X2, · · · , Xk} are random variables defined on (Ω, A, P) with
σ(Xi) as the sigma field induced by Xi
, i = 1, 2, · · · , k. The induced sigma
field contains all the information about the random variable. Hence, it is
appropriate to define independence of random variables in terms of induced
sigma fields.
Definition 5.3.1. Independence of random variables: Suppose {X1, · · · , Xk}
are random variables defined on (Ω, A, P) with σ(Xi) as the sigma field induced
by Xi
, i = 1, 2, · · · , k. If σ(Xi) i = 1, 2, · · · , k are independent sigma fields,
then X1, X2, · · · , Xk are said to be independent random variables.
We now demonstrate how this definition leads to the well known definitions
of independence in terms of distribution functions or density functions. Sup￾pose X1 and X2 are independent random variables. Thus, the induced sigma
fields σ(X1) and σ(X2) are independent collections of events in A. By Defi￾nition 5.2.5, ∀ A1 ∈ σ(X1) and ∀ A2 ∈ σ(X2), P(A1 ∩ A2) = P(A1)P(A2).
Suppose S1 and S2 in B are such that X
−1
1
(S1) = A1 and X
−1
2
(S2) = A2.
Now,
P(A1 ∩ A2) = P(A1)P(A2)
⇐⇒ P(X
−1
1
(S1) ∩ X
−1
2
(S2)) = P(X
−1
1
(S1))P(X
−1
2
(S2))
⇐⇒ P{ω|ω ∈ X
−1
1
(S1) ∩ X
−1
2
(S2)} = P{ω|ω ∈ X
−1
1
(S1)}P{ω|ω ∈ X
−1
2
(S2)}
⇐⇒ P{ω|X1(ω) ∈ S1, X2(ω) ∈ S2} = P{ω|X1(ω) ∈ S1}P{ω|X2(ω) ∈ S2}
⇐⇒ P[X1 ∈ S1, X2 ∈ S2] = P[X1 ∈ S1]P[X2 ∈ S2]228 Independence
Thus, ∀ A1 ∈ σ(X1) and ∀ A2 ∈ σ(X2)
P(A1 ∩ A2) = P(A1)P(A2)
⇐⇒ P[X1 ∈ S1, X2 ∈ S2] = P[X1 ∈ S1]P[X2 ∈ S2], (5.3)
∀ S1, S2 ∈ B. Equation (5.3) asserts that the joint probability distribution of
X1 and X2 is the product of marginal probability distributions of X1 and X2.
In particular, suppose S1 = (−∞, x1] and S2 = (−∞, x2], x1, x2 ∈ R. Then
Equation (5.3) reduces to
P[X1 ≤ x1, X2 ≤ x2] = P[X1 ≤ x1]P[X2 ≤ x2]
⇐⇒ FX1,X2
(x1, x2) = FX1
(x1)FX2
(x2) ∀ x1, x2 ∈ R.
Thus, the joint distribution function of X1 and X2 is the product of marginal
distribution functions of X1 and X2. Further if FX1,X2
(x1, x2) is totally differ￾entiable, then the condition of independence in terms of distribution function
reduces to that in terms of probability density function as given by,
fX1,X2
(x1, x2) = fX1
(x1)fX2
(x2).
If X1 and X2 are discrete random variables, then in view of sigma additivity
of probability measure, it is enough to take S1 = {x1} and S2 = {x2}. Then
Equation (5.3) reduces to,
P[X1 = x1, X2 = x2] = P[X1 = x1]P[X2 = x2] ∀ x1, x2 ∈ R.
Thus, if X1 and X2 are independent discrete random variables, then the joint
probability mass function is the product of marginal probability mass func￾tions.
Example 5.3.1. Suppose X is a random variable defined on (Ω, A, P) and
Y ≡ C is a degenerate random variable. The sigma field generated by Y ≡ C
is {Ω, ∅}. For any set A ∈ σ(X),
P(A ∩ Ω) = P(A) = P(A)P(Ω) and P(A ∩ ∅) = P(∅) = 0 = P(A)P(∅).
Thus, σ(X) and σ(Y ) = {Ω, ∅} are independent sigma fields and hence X
and Y ≡ C are independent random variables. Thus, any random variable is
always independent of a degenerate random variable. □
In particular a degenerate random variable is also independent of a degen￾erate random variable, as shown in the next example.
Example 5.3.2. Suppose X ≡ C and Y ≡ D are degenerate random variable
defined on (Ω, A, P). The sigma field generated by both is the same and is
{Ω, ∅}. It is known that Ω is independent of itself and of ∅. Hence X and Y
are independent random variables. □Independence of Random Variables 229
Example 5.3.3. Suppose P1 = {A1, A2} and P2 = {B1, B2, B3} form mea￾surable partitions of Ω. Then
σ(P1) = {Ω, ∅, A1, A2} & σ(P2) = {Ω, ∅, B1, B2, B3, B1∪B2, B1∪B3, B2∪B3}.
Suppose P1 and P2 are independent of each other. We examine whether σ(P1)
is independent of σ(P2). Since P1 and P2 are independent of each other, Ai
, i =
1, 2 are independent of Bj , j = 1, 2, 3. By Theorem 5.2.1, Ai
, i = 1, 2 are
independent of Ω and ∅, similarly Bj , j = 1, 2, 3 are independent of Ω and ∅.
By the same theorem Ai
, i = 1, 2 are independent of Bc
j
, j = 1, 2, 3. Note that
B1 ∪ B2 = Bc
3
, B1 ∪ B3 = Bc
2 and B2 ∪ B3 = Bc
1
. Independence of A1 with
B1 ∪ B2 can also be proved as follows.
P(A1 ∩ (B1 ∪ B2)) = P(A1 ∩ B1) + P(A1 ∩ B2)
= P(A1)P(B1) + P(A1)P(B2)
= P(A1)(P(B1) + P(B2)) = P(A1)P(B1 ∪ B2).
Thus, A1 and B1 ∪B2 are independent events. Thus we have noted that every
event in σ(P1) is independent of every event in σ(P2). Hence, if P1 and P2 are
independent of each other, then σ(P1) is independent of σ(P2). □
Example 5.3.4. Suppose X and Y are simple random variables defined on
(Ω, A, P) as
X =
Xm
i=1
aiIAi
and Y =
Xn
j=1
bj IBj
where {A1, A2, · · · , Am} and {B1, B2, · · · , Bn} form measurable partitions of
Ω and {a1, a2, · · · , am} and {b1, b2, · · · , bn} are real numbers. Since X is a
simple random variable, σ(X) includes an empty set and all sets of the form
A =
P
s∈T As, where T ⊆ {1, 2, · · · , m}. Similarly, σ(Y ) includes an empty
set and all sets of the form B =
P
r∈M Br, where M ⊆ {1, 2, · · · , n}. Suppose
{A1, A2, · · · , Am} are independent of {B1, B2, · · · , Bn}. Note that
P(A ∩ B) = P
X
s∈T
As ∩
X
r∈M
Br

= P
X
s∈T
X
r∈M
As ∩ Br

=
X
s∈T
X
r∈M
P(As ∩ Br) by finite additivity
=
X
s∈T
X
r∈M
P(As)P(Br) = X
s∈T
P(As)
X
r∈M
P(Br)
= P
X
s∈T
As

P
 X
r∈M
Br

= P(A)P(B)
It thus follows that any A ∈ σ(X) is independent of B ∈ σ(Y ). Hence, induced
sigma fields σ(X) and σ(Y ) are independent and hence X and Y are indepen￾dent random variables. Thus, if the measurable partitions are independent,
then the associated simple random variables are independent. □230 Independence
Remark 5.3.1. For simple random variables X and Y defined in Example
5.3.4, note that
P[X = ai
] = P(Ai), P[Y = bj ] = P(Bj )
& P[X = ai
, Y = bj ] = P(Ai ∩ Bj )
P(Ai ∩ Bj ) = P(Ai)P(Bj ) if Ai and Bj are independent
⇒ P[X = ai
, Y = bj ] = P[X = ai
]P[Y = bj ] if X and Y are independent.
Thus, if X and Y are independent, the joint probability mass function of
(X, Y )
′
is the product of marginal probability mass functions of X and Y .
We have noted in Example 5.2.1 that the concept of independence is not
a property of events, but it is a property of underlying probability measure.
Thus the two events may be independent with respect one probability mea￾sure but not with respect to another probability measure. It is applicable for
independence of two random variables as well. The next example illustrates
this important feature.
Example 5.3.5. Suppose X = IA and Y = IB are two random variables
defined on (Ω, A, P), where A, B ∈ A. Suppose the probability measure P is
such thatP(A) = P(B) = 1/2 and P(A ∩ B) = 1/4. The sigma fields induced
by X and Y are
σ(X) = {Ω, ∅, A, Ac
} & σ(Y ) = {Ω, ∅, B, Bc
}.
We know that Ω and ∅ are independent of each other and also with any event.
Further, since P(A) = P(B) = 1/2 and P(A ∩ B) = 1/4, P(Ac ∩ B) = 1/4,
P(A∩Bc
) = 1/4 and P(Ac∩Bc
) = 1/4. Thus any event in σ(X) is independent
of any event in σ(Y ). Hence, X = IA and Y = IB are independent random
variables corresponding to the given probability measure P. Now suppose the
probability measure P
∗
is such that, P
∗
(A) = P
∗
(B) = 1/3 and P
∗
(A ∩ B) =
1/4. Then P
∗
(A)P
∗
(B) = 1/9 ̸= P
∗
(A ∩ B) = 1/4. Hence, A and B are not
independent with respect to P
∗
. As a consequence, X = IA and Y = IB are
not independent random variables corresponding to the probability measure
P
∗
. □
We now discuss the most heavily used result regarding independence of
two random variables, which states that independence remains valid under
Borel transformations of X and Y .
Theorem 5.3.1. Suppose X and Y are independent random variables de￾fined on (Ω, A, P). If g and h are Borel functions, then g(X) and h(Y ) are
independent random variables.
Proof. It is proved in Section 2.3 that if g and h are Borel functions, then
g(X) and h(Y ) are random variables on (Ω, A, P) and
σ(g(X)) ⊆ σ(X) & σ(h(Y )) ⊆ σ(Y ).Independence of Random Variables 231
To prove that, g(X) and h(Y ) are independent is equivalent to prove that
σ(g(X)) and σ(h(Y )) are independent sigma fields. Hence, observe that
∀ A ∈ σ(g(X)) ⊆ σ(X) & ∀ B ∈ σ(h(Y )) ⊆ σ(Y )
X & Y are independent ⇒ σ(X) & σ(Y ) are independent
⇒ P(A ∩ B) = P(A)P(B)
⇒ σ(g(X)) & σ(h(Y )) are independent
⇒ g(X) & h(Y ) are independent.
As a consequence of this theorem, if X and Y are independent, then Xr
and Y
s are independent random variables for any r, s such that Xr and Y
s are
defined. Similarly, exp(X) and exp(Y ) are also independent, any trignometric
function of X will be independent of any trignometric function of Y . Note that
establishing independence using this theorem is much simpler than proving it
via distribution functions or density functions or probability mass functions.
It is to be noted that Theorem 5.3.1 states that if X and Y are independent
random variables, then g(X) and h(Y ) are independent random variables.
However, if X and Y are not independent random variables, then we cannot
conclude that g(X) and h(Y ) are also not independent random variables.
They may be independent or may not be independent as shown in the next
two examples.
Example 5.3.6. Suppose X1 and X2 are two random variables defined on
(Ω, A, P) as follows, where Ω = {a, b, c}, A = P(Ω) and P is defined as ∀ ω ∈ Ω,
P({ω}) = 1/3.
X1(ω) = 
−1, if ω = a
1, if ω = b, c & X2(ω) = 
5, if ω = b
10, if ω = a, c.
Note that X
−1
1
(B) = {Ω, ∅, {a}, {b, c}} & X
−1
2
(B) = {Ω, ∅, {b}, {a, c}}. Ob￾serve that P({a} ∩ {b}) = P(∅) = 0 ̸= P({a})P({b}). Hence, X1 and X2
are not independent. Suppose Y1 = g(X1) = X2
1 and Y2 = h(X2) = log X2.
Observe that Y1 is degenrate at 1 and Y2 is a one-to-one function of X2. Hence,
Y
−1
1
(B) = {Ω, ∅} & Y
−1
2
(B) = X
−1
2
(B) = {Ω, ∅, {b}, {a, c}}.
In Example 5.3.1, we have shown that any random variable is always indepen￾dent of a degenerate random variable. Thus, X1 and X2 are not independent
but g(X1) and h(X2) are independent random variables. □
Example 5.3.7. Suppose X1 and X2 are two random variables defined on
(Ω, A, P) as follows, where Ω = {a, b, c}, A = P(Ω) and P is defined as ∀ ω ∈ Ω,
P({ω}) = 1/3.
X1(ω) =



−1, if ω = a
0, if ω = b
1, if ω = c.
& X2(ω) = 
50, if ω = b
100, if ω = a, c.232 Independence
Note that X
−1
1
(B) = P(Ω) & X
−1
2
(B) = {Ω, ∅, {b}, {a, c}}. Observe that
for {a} ∈ X
−1
1
(B) and {b} ∈ X
−1
2
(B), P({a} ∩ {b}) = P(∅) = 0 which is
not equal to P({a})P({b}) = 1/9. Hence, X1 and X2 are not independent.
Suppose Y1 = g(X1) = X2
1 and Y2 = h(X2) = 3X3
2 + 4X2
2 + 7. Observe that
Y1(ω) = 
1, if ω = a, c
0, if ω = b.
Further, Y2 is a one-to-one function of X2. Hence,
Y
−1
1
(B) = {Ω, ∅, {b}, {a, c}} & Y
−1
2
(B) = X
−1
2
(B) = {Ω, ∅, {b}, {a, c}}.
Thus, the sigma fields induced Y1 and Y2 are the same. These are independent
if and only if every set in the sigma fields have probability 0 or 1. However,
P({b}) = 1/3 and P({a, c}) = 2/3. Hence, Y1 = g(X1) and Y2 = h(X2)
are not independent random variables. Thus, X1 and X2 are not independent
random variables, as well as g(X1) and h(X2) are also not independent random
variables. □
In Example 5.3.1, we have shown that any random variable is always inde￾pendent of a degenerate random variable. In Example 5.3.2, it shown that a
degenerate random variable is independent of itself. Both these results follow
as a particular case of Theorem 5.3.1 as shown in the following theorem.
Theorem 5.3.2. (i) Any random variable is always independent of a degen￾erate random variable. (ii) A degenerate random variable is independent of
itself.
Proof. In Theorem 5.3.1 we have proved that if X and Y are independent
random variables defined on (Ω, A, P) and if g and h are Borel functions, then
g(X) and h(Y ) are independent random variables.
(i) In particular, suppose g and h are Borel functions such that g(X) = X
and h(Y ) ≡ C. Then it follows that X and a random variable degenerate at
C are independent random variables.
(ii) With g(X) ≡ C and h(Y ) ≡ C, we conclude that a random variable
degenerate at C is always independent of itself.
From Theorem 5.3.1 it is known that if X and Y are independent random
variables their Borel functions are also independent. Following example shows
that X and Y are not independent but X2 and Y
2 are independent random
variables.
Example 5.3.8. Suppose X is a discrete random variable with P[X = ±1] =
1/2 and a random variable Y is defined as Y = −X. Since Y is one-to-one
function of X, it follows that the sigma fields induced by X and Y are the same
and it is given by {Ω, ∅, A, Ac} where A = {ω|X(ω) = 1} with probability
1/2. Thus, X and Y are not independent random variables. Now observe
that P[X2 = 1] = P[Y
2 = 1] = 1, which implies that both X2 and Y
2 areIndependence of Random Variables 233
degenerate random variables and hence by Theroem 5.3.2, are independent
random variables. Thus, X2 and Y
2 are independent random variables, but
X and Y are not independent random variables. □
Remark 5.3.2. Apparently the result from Example 5.3.8 may seem contra￾dictory to Theorem 5.3.1. However, it is to be noted in this example that X2
and Y
2 are independent random variables, but X is not a Borel function of
X2 or Y is not a Borel function of Y
2
, in fact it is not a function, in view of a
one-many correspondence from X2
to X. In Example 5.3.8, X and Y would
have been independent if P(A) = 0 or 1, which amounts to assuming that X
and hence Y are degenerate random variables.
In Chapter 4, we have noted that the expectation of sum of two random
variables is the sum of their expectations. However, expectation of product of
two random variables is in general not the product of their expectations. The
result is true if the underlying random variables are independent. We prove
it in the following theorem. The proof proceeds in six steps as the definition
of the expectation is different for a simple random variable, a non-negative
random variable and for an arbitrary random variable.
Theorem 5.3.3. If X and Y are independent random variables then,
E(XY ) = E(X)E(Y ).
Proof. Case(i): Suppose X and Y are simple random variables defined on
(Ω, A, P) as
X =
Xm
i=1
aiIAi
and Y =
Xn
j=1
bj IBj
where {a1, a2, · · · , am} and {b1, b2, · · · , bn} are real numbers and
{A1, A2, · · · , Am} and {B1, B2, · · · , Bn} are measurable partitions of Ω. It is
proved in Theorem 2.4.1 that when {A1, A2, · · · , Am} and {B1, B2, · · · , Bn}
are measurable partitions of Ω, {Ai ∩ Bj , i = 1, 2, · · · , m, j = 1, 2, · · · , n} is
also a measurable partition of Ω. As proved in Theorem 2.4.1, XY is also a
simple random variable and is given by XY =
Pm
i=1
Pn
j=1 aibj IAi∩Bj
. Since
X is a simple random variable, as discussed in Example 5.3.4, σ(X) includes
an empty set and all sets of the form A =
P
r∈T Ar, where T ⊆ {1, 2, · · · , m}.
Thus, {A1, A2, · · · , Am} are in σ(X). Similarly, {B1, B2, · · · , Bn} are in σ(Y ).
Now by the definition of expectation of a simple random variable,
E(X) =Xm
i=1
aiP(Ai), E(Y ) =Xn
j=1
bjP(Bj ) & E(XY ) =Xm
i=1
Xn
j=1
aibjP(Ai∩Bj ).
It is given that X and Y are independent, that is σ(X) and σ(Y ) are indepen￾dent sigma fields. Hence, P(Ai ∩ Bj ) = P(Ai)P(Bj ) for all i = 1, 2, · · · , m,
j = 1, 2, · · · , n. With this substitution in E(XY ) we get,
E(XY ) = Xm
i=1
Xn
j=1
aibjP(Ai)P(Bj ) = Xm
i=1
aiP(Ai)
Xn
j=1
bjP(Bj )) = E(X)E(Y ).234 Independence
Case(ii): Suppose X and Y are non-negative random variables defined on
(Ω, A, P). It is proved in Theorem 2.4.3 that there exists a non-decreasing
sequence {Xn, n ≥ 1} of non-negative simple random variables such that
Xn ↑ X on Ω and E(X) = limn→∞ E(Xn). Similarly, there exists a non￾decreasing sequence {Yn, n ≥ 1} of non-negative simple random variables such
that Yn ↑ Y on Ω and E(Y ) = limn→∞ E(Yn). Observe that as Xn ↑ X and
Yn ↑ Y on Ω, XnYn ↑ XY on Ω. Further as proved in case(i), if Xn and Yn
are simple random variables, then XnYn is also a simple random variable. As
discussed in Theorem 2.4.3, Xn can be expressed as,
Xn =
n2
Xn
k=1
k − 1
2
n
I
[
k−1
2n ≤X < k
2n ]
+ nI[X ≥ n] = g(X),
where g is a Borel function. Similarly,
Yn =
n2
Xn
k=1
k − 1
2
n
I
[
k−1
2n ≤Y < k
2n ]
+ nI[Y ≥ n] = g(Y ).
It is given that X and Y are independent random variables, hence Xn = g(X)
and Yn = g(Y ) are also independent random variables ∀ n ≥ 1. Thus,
E(XY ) = limn→∞
E(XnYn) = limn→∞
E(Xn) limn→∞
E(Yn) = E(X)E(Y ).
Case(iii): Suppose X and Y are arbitrary random variables defined on
(Ω, A, P). Hence, X = X+ − X− and Y = Y
+ − Y
−, where X+ = XI[X≥0] =
g(X) and X− = −XI[X≥0] = h(X). Y
+ and Y
− are defined on similar
lines. Thus, Y
+ = g(Y ) and Y
− = h(Y ). Note that both g and h are Borel
functions. Since it is given that X and Y are independent, the collection
{g(X), h(X)} ≡ {X+, X−} and {g(Y ), h(Y )} ≡ {Y
+, Y −} are independent
collections of random variables, that is, X+ is independent of {Y
+, Y −} and
X− is independent of {Y
+, Y −}. Hence,
E(XY ) = E(X+ − X−)(Y
+ − Y
−)
= E(X+Y
+) − E(X+Y
−) − E(X−Y
+) + E(X−Y
−)
= E(X+)E(Y
+) − E(X+)E(Y
−) − E(X−)E(Y
+) + E(X−)E(Y
−)
= E(X+)(E(Y
+) − E(Y
−)) − E(X−)(E(Y
+) − E(Y
−))
= (E(X+) − E(X−))(E(Y
+) − E(Y
−)) = E(X)E(Y ).
Case(iv): Suppose X is a non-negative simple random variable and Y is non￾negative random variable. Since Y ≥ 0, there exists a non-decreasing sequence
{Yn, n ≥ 1} of non-negative simple random variables such that Yn ↑ Y on Ω
and E(Y ) = limn→∞ E(Yn). It is to be noted that XYn ≥ 0, {XYn, n ≥ 1} is
a non-decreasing sequence, XYn ↑ XY and as proved in case(i), XYn is also
a simple random variable. As in case (ii) Yn = g(Y ), hence independence ofIndependence of Random Variables 235
X and Y implies independence of X and Yn for each n ≥ 1. Thus, by the
definition of expectation,
E(XY ) = limn→∞
E(XYn) = limn→∞
E(X)E(Yn)
= E(X) limn→∞
E(Yn) = E(X)E(Y ).
Case(v): Suppose X is a non-negative simple random variable and Y is an
arbitrary random variable. As in case (iii) Y
+ and Y
− are Borel functions of
Y , hence independence of X and Y implies independence of X and Y
+ and
of X and Y
−. Further X, Y +, Y − are non-negative random variables. Thus,
by the definition of expectation,
E(XY ) = E(X(Y
+ − Y
−)) = E(XY +) − E(XY −)
= E(X)E(Y
+) − E(X)E(Y
−) by case (iv)
= E(X)(E(Y
+) − E(Y
−)) = E(X)E(Y ).
Case(vi): Suppose X is a non-negative random variable and Y is an arbi￾trary random variable. As in case (iii) Y
+ and Y
− are Borel functions of Y ,
hence independence of X and Y implies independence of X and Y
+ and of X
and Y
−. Further X, Y +, Y − are non-negative random variables. Thus, by the
definition of expectation,
E(XY ) = E(X(Y
+ − Y
−)) = E(XY +) − E(XY −)
= E(X)E(Y
+) − E(X)E(Y
−) by case (ii)
= E(X)(E(Y
+) − E(Y
−)) = E(X)E(Y ).
Thus, it is proved that if X and Y are independent random variables then,
E(XY ) = E(X)E(Y ).
Remark 5.3.3. Theorem 5.3.3 can be extended to the expectation of product
of more than two random variables.
Example 5.3.9. Suppose X is an integrable random variable on (Ω, A, P) and
A ∈ A is such that P(A) = 0. The sigma field induced by IA is {∅, Ω, A, Ac}
and probability attached to these four events is either 0 or 1. Hence from
result (iii) of Theorem 5.2.1, any B ∈ σ(X) is independent of any D ∈ σ(IA),
which implies that X and IA are independent. Hence,
Z
A
X dP =
Z
Ω
XIA dP = E(XIA) = E(X)E(IA) = E(X)P(A) = 0 .
It then follows that
Z
Ac
X dP =
Z
Ac
X dP +
Z
A
X dP =
Z
A∪Ac
X dP =
Z
Ω
X dP = E(X) . □
Theorem 5.3.3 along with Theorem 5.3.1 immediately implies that if X
and Y are independent random variables, then the joint moment generating236 Independence
function is the product of marginal moment generating functions, moment
generating function of X + Y is the product of marginal moment generat￾ing functions. Similar results are true for the probability generating function
and the characteristic function. In the following theorem, we prove it for the
moment generating function, provided it exists.
Theorem 5.3.4. Suppose X and Y are independent random variables defined
on (Ω, A, P). Then (i) joint moment generating function of X and Y is the
product of marginal moment generating functions of X and Y and (ii) the
moment generating function of X + Y is the product of marginal moment
generating functions of X and Y, provided these exist.
Proof. The joint moment generating function of X and Y is defined as,
MX,Y (t1, t2) = E(exp(t1X + t2Y )). Note that exp(x) and exp(y) are continu￾ous functions and hence are Borel functions. Thus, if X and Y are independent
random variables, then by Theorem 5.3.1 exp(t1X) and exp(t2Y ) are also in￾dependent random variables. Hence,
MX,Y (t1, t2) = E(exp(t1X + t2Y )) = E(exp(t1X) exp(t2Y ))
= E(exp(t1X))E(exp(t2Y )) = MX(t1)MY (t2).
On similar lines it follows that the moment generating function of X + Y is
the product of marginal moment generating functions. The moment generating
function of X + Y can be expressed as,
MX+Y (t) = E(exp(t(X + Y ))) = E(exp(tX) exp(tY ))
= E(exp(tX))E(exp(tY )) = MX(t)MY (t).
Similar result is true for a characteristic function. We prove it below.
Theorem 5.3.5. Suppose X and Y are independent random variables defined
on (Ω, A, P). Then (i) joint characteristic function of X and Y is the product
of characteristic functions of X and Y and (ii) the characteristic function of
X + Y is the product of characteristic functions of X and Y .
Proof. Since X and Y are independent random variables, by Theorem 5.3.1,
cos(t1X) is independent of cos(t2Y ) and sin(t2Y ), similarly sin(t1X) is inde￾pendent of cos(t2Y ) and sin(t2Y ). We use Theorem 5.3.3 for the expectation of
product of these random variables. By the definition of the joint characteristic
function of X and Y
ϕX,Y (t1, t2) = E(exp(it1X + it2Y )) = E(exp(it1X)exp(it2Y ))
= E{(cos(t1X) + isin(t1X))(cos(t2Y ) + isin(t2Y ))}
= E(cos(t1X) cos(t2Y ) + i cos(t1X) sin(t2Y ))
+ E(isin(t1X) cos(t2Y ) + i
2
sin(t1X) sin(t2Y ))
= E(cos(t1X))E(cos(t2Y )) + iE(cos(t1X))E(sin(t2Y ))
+ iE(sin(t1X)E(cos(t2Y ) + i
2E(sin(t1X))E(sin(t2Y )).Independence of Random Variables 237
It further simplifies as follows.
ϕX,Y (t1, t2) = E(cos(t1X)){E(cos(t2Y )) + iE(sin(t2Y ))}
+ iE(sin(t1X){E(cos(t2Y ) + iE(sin(t2Y )}
= {E(cos(t1X)) + iE(sin(t1X)}{E(cos(t2Y )) + iE(sin(t2Y ))}
= ϕX(t1)ϕY (t2)
and (i) follows. Using similar arguments with t1 = t2 = t, (ii) follows.
Using Theorem 5.3.5 and the inversion theorem, we now derive the charac￾teristic function of the Cauchy C(0, 1) distribution in the following example.
Example 5.3.10. Suppose X and Y are independent and identically dis￾tributed random variables, each having exponential distribution with scale
parameter 1. Using the convolution formula, one can show that Z = X − Y
follows a Laplace distribution with the probability density function f(x) =
(1/2)e
−|x|
, x ∈ R. The characteristic function of X and Y is the same and
is given by ϕ(t) = (1 − it)
−1
. Hence, using Theorem 5.3.5, the characteristic
function of Z is given by
ϕZ(t) = (1 − it)
−1 × (1 + it)
−1 = (1 + t
2
)
−2
. Since this characteristic function
is integrable, using inversion formula as derived in Theorem 4.4.2 we have
1
2
e
−|x| =
1
2π
Z
R
e
itx 1
1 + t
2
dt ⇐⇒ e
−|t| =
1
π
Z
R
e
itx 1
1 + x
2
dt
by interchanging t and x. We note that the right-hand side is the characteristic
function of the Cauchy C(0, 1) distribution and is given by exp{−|t|}, t ∈ R.
Since Cauchy C(0, 1) distribution is symmetric around 0, the characteristic
function is a real valued function. □
In the following theorem, we derive three equivalent conditions for inde￾pendence of two random variables, which can be extended to a finite collection
of random variables. We state one result about independence of π-system in
the following theorem. It is needed to establish the equivalence of conditions
for independence.
Theorem 5.3.6. Suppose Pi
, i = 1, 2, · · · , k are independent π-systems. Then
σ(Pi), i = 1, 2, · · · , k are independent sigma fields.
For proof we refer to p.50 of Billingsley [5] or p.41 of Shao [21]. The proof
is based on Dynkin’s π-λ theorem. This theorem is also known as an extension
theorem, (p.246, Loeve [16]).
Theorem 5.3.7. Suppose X and Y are random variables defined on (Ω, A, P).
Then X and Y are independent random variables if any one of the following
three conditions are satisfied.
(i) σ(X) and σ(Y ) are independent sigma fields, that is
∀ S1, S2 ∈ B, P[X ∈ S1, Y ∈ S2] = P[X ∈ S1]P[Y ∈ S2].238 Independence
(ii) ∀ x, y ∈ R, FX,Y (x, y) = FX(x)FY (y).
(iii) ∀ t1, t2 ∈ R, ϕX,Y (t1, t2) = ϕX(t1)ϕY (t2).
Proof. We prove the equivalence of three conditions as follows. Suppose (i) is
true. Thus, X−1
(B) and Y
−1
(B) are independent sigma fields which further
implies for all S1, S2 ∈ B, P[X ∈ S1, Y ∈ S2] = P[X ∈ S1]P[Y ∈ S2]. In
particular, if we take S1 = (−∞, x] and S2 = (−∞, y] for x, y ∈ R, then we
get (ii). Thus, (i) implies (ii). Further, (i) implies (iii) follows from Theorem
5.3.5. Suppose now (ii) is true. We define C = {(−∞, x]|x ∈ R}. Observe that,
S1 = (−∞, a] ∈ C & S2 = (−∞, b] ∈ C
⇒ S1 ∩ S2 = (−∞, d] ∈ C where d = min{a, b}
⇒ C is a π system.
Suppose A1 = X−1
(C) and A2 = Y
−1
(C). Suppose A1, A2 ∈ A1 are such
that A1 = X−1
(S1) = {ω|X(ω) ≤ a}, A2 = X−1
(S2) = {ω|X(ω) ≤ b}. Then
A1 ∩ A2 = {ω|X(ω) ≤ d}. Now
(−∞, d] ∈ C ⇒ X−1
(−∞, d]) = A1 ∩ A2 ∈ A1 ⇒ A1 is a π system.
On similar lines we get that A2 is a π-system. From (ii) we have ∀ x, y ∈ R,
FX,Y (x, y) = FX(x)FY (y)
⇐⇒ P[X ≤ x, Y ≤ y] = P[X ≤ x]P[Y ≤ y]
⇐⇒ P(Ax ∩ By) = P(Ax)P(By),
for all Ax ∈ A1 and By ∈ A2, where Ax = X−1
((−∞, x]) and By =
Y
−1
((−∞, y]). It shows that A1 and A2 are independent π-systems. Hence
by Theorem 5.3.6, σ(A1) and σ(A2) are independent classes. However,
σ(A1) = σ(X−1
(C)) = X−1
(σ(C)) = X−1
(B) and σ(A2) = σ(Y
−1
(C)) =
Y
−1
(σ(C)) = Y
−1
(B), that is, sigma fields induced by X and Y are in￾dependent and thus (i) follows from (ii). Hence, (ii) ⇒ (i) ⇒ (iii),
hence, (ii) ⇒ (iii). Now we show that (iii) implies (i) using inversion for￾mula which gives the distribution function corresponding to a given char￾acteristic function. Suppose B is a two dimensional rectangle defined as
B = {(x, y)|a1 < x ≤ a1 + h1, a2 < y ≤ a2 + h2}. Then by the multivari￾ate inversion formula (Billingsley [5]) P[(X, Y ) ∈ B] is given by,
P[(X, Y ) ∈ B] = lim
T→∞
1
4π
2
Z T
−T
Z T
−T

e
−ia1t1 − e
−i(a1+h1)t1
it1

×

e
−ia2t2 − e
−i(a2+h2)t2
it2
ϕX,Y (t1, t2)

dt1dt2
= lim
T→∞
1
2π
Z T
−T
e
−ia1t1 − e
−i(a1+h1)t1
it1
ϕX(t1) dt1
× lim
T→∞
1
2π
Z T
−T
e
−ia2t2 − e
−i(a2+h2)t2
it2
ϕY (t2) dt2 by (iii)
= P[a1 < X ≤ a1 + h1]P[a2 < Y ≤ a2 + h2].Independence of Random Variables 239
Thus, for any a1, a2, h1, h2 ∈ R, we have
P[(X, Y ) ∈ B] = P[a1 < X ≤ a1 + h1]P[a2 < Y ≤ a2 + h2]
⇐⇒ P[X−1
((a1, a1 + h1]) ∩ Y
−1
((a2, a2 + h2])]
= P[X−1
((a1, a1 + h1])]P[Y
−1
((a2, a2 + h2])]. (5.4)
We now define C1 = {(a, b]|a ≤ b ∈ R}. If a = b, we define (a, b] = ∅. Observe
that,
S1 = (a1, a2] ∈ C1 & S2 = (b1, b2] ∈ C1 ⇒ S1 ∩ S2 = (d1, d2] ∈ C1
⇒ C1 is a π system where, d1 = max{a1, b1} &d2 = min{a2, b2}.
In some cases, S1 ∩ S2 = ∅. Suppose F1 = X−1
(C1) and F2 = Y
−1
(C1).
Suppose A1, A2 ∈ F1 are such that
A1 = X−1
(S1) & A2 = X−1
(S2) then A1 ∩ A2 = {ω|d1 < X(ω) ≤ d2}.
Now
(d1, d2] ∈ C1 ⇒ X−1
((d1, d2]) = A1 ∩ A2 ∈ F1 ⇒ F1 is a π system.
On similar lines we get that F2 is a π-system. From Equation (5.4), we claim
that F1 and F2 are independent π-systems. Hence by Theorem 5.3.6, σ(F1) and
σ(F2) are independent classes. However, as shown above σ(F1) = X−1
(B) and
σ(F2) = Y
−1
(B), that is, sigma fields induced by X and Y are independent
and thus (i) follows from (iii). Thus all the three conditions are equivalent and
the proof is complete.
So far we discussed the concept of independence of a collection of finitely
many random variables. We now extend it to a sequence of random variables
and any collection of random variables.
Definition 5.3.2. Sequence of independent random variables: A sequence
{Xn, n ≥ 1} is a sequence of independent random variables if and only if any
finite collection of the sequence is a collection of independent random variables.
Definition 5.3.3. Class of independent random variables: Suppose
{Xt, t ∈ T} is a class of random variables, where T is any non-empty index
set. It is said to a class of independent random variables if and only if any
finite sub class of this class is a class of independent random variables.
In view of these definitions, to examine independence of a sequence of ran￾dom variables or an indexed class of random variables, all the tools developed
for a finite collection of random variables are applicable.
Independence of random vectors and a class of independent random vectors
are defined analogously.240 Independence
Definition 5.3.4. Independence of random vectors: Two random vectors X
and Y defined on the same probability space are independent random vectors
if the induced sigma fields are independent.
In the following theorem, we prove that if two random vectors are inde￾pendent then each component random variable of one random vector is inde￾pendent of each component random variable of the second random vector.
Theorem 5.3.8. Suppose Z1 = (X1, X2, · · · , Xk) and Z2 = (Y1, Y2, · · · , Yl)
are random vectors defined on the same probability space. Then Z1 and Z2 are
independent implies each component of Z1
is independent of each component
of Z2
.
Proof. Note that the sigma fields induced by Z1
and Z2
are given by,
σ(Z1
) = σ
 [
k
i=1
σ(Xi)

& σ(Z2
) = σ
 [
l
j=1
σ(Yj )

.
Suppose Z1
and Z2
are independent. Then the corresponding sigma fields are
independent. Hence,
∀ A1 ∈ σ(Z1
) & ∀ A2 ∈ σ(Z2
), P(A1 ∩ A2) = P(A1)P(A2).
To prove that Xi
is independent of Yj , we examine whether the correspond￾ing sigma fields are independent. Observe that ∀ i = 1, 2, · · · , k and
j = 1, 2, · · · , l,
A1 ∈ σ(Xi) & A2 ∈ σ(Yj ) ⇒ A1 ∈ σ(Z1
) & A2 ∈ σ(Z2
)
⇒ P(A1 ∩ A2) = P(A1)P(A2)
⇒ σ(Xi) & σ(Yj ) are independent sigma fields
⇒ Xi & Yj are independent.
Following example illustrates that the converse of Theorem 5.3.8 is not
true, that is, if the component random variables of Z1
are independent of the
component random variables Z2
then Z1
and Z2 may not be independent
random vectors.
Example 5.3.11. Suppose (Ω, A, P) is a probability space, where Ω =
{a, b, c, d}, A = P(Ω) and P({ω}) = 1/4 ∀ ω ∈ Ω. Suppose events A, B, C, D ∈
A are defined as follows.
A = {a, b}, B = {a, c}, C = {b, c} & D = {a, d}.Independence of Random Variables 241
We define Z1 = (IA, IB)
′ and Z2 = (IC , ID)
′
. The sigma fields induced by
IA, IB, IC , ID, Z1
and Z2
are respectively given by,
I
−1
A (B) = {Ω, ∅, A, Ac
} I
−1
B (B) = {Ω, ∅, B, Bc
}
I
−1
C
(B) = {Ω, ∅, C, Cc
} I
−1
D (B) = {Ω, ∅, D, Dc
}
Z
−1
1
(B) = {Ω, ∅, A, Ac
, B, Bc
, A ∪ B, A ∪ B
c
, Ac ∪ B, Ac ∪ B
c
, Ac ∩ B
c
,
A
c ∩ B, A ∩ B
c
, A ∩ B,(A ∪ B
c
) ∪ (A
c ∪ B),
((A ∪ B
c
) ∪ (A
c ∪ B))c
}
Z
−1
2
(B) = {Ω, ∅, C, Cc
, D, Dc
, C ∪ D, C ∪ Dc
, Cc ∪ D, Cc ∪ Dc
, Cc ∩ Dc
,
C
c ∩ D, C ∩ Dc
, C ∩ D,(C ∪ Dc
) ∪ (C
c ∪ D),
((C ∪ Dc
) ∪ (C
c ∪ D))c
}.
Now note that
P(A ∩ B) = P({a}) = 1/4 = P(A)P(B) = (1/2)(1/2).
Thus, A is independent of B and hence I
−1
A (B) is independent of I
−1
B (B),
implying that IA and IB are independent random variables. Further,
P(C ∩ D) = P(∅) = 0 ̸= P(C)P(D) = (1/2)(1/2).
Thus, IC and ID are not independent random variables. Further,
P(A ∩ C) = P({b}) = 1/4 = P(A)P(C) = (1/2)(1/2)
P(A ∩ D) = P({a}) = 1/4 = P(A)P(D) = (1/2)(1/2)
P(B ∩ C) = P({c}) = 1/4 = P(B)P(C) = (1/2)(1/2)
P(B ∩ D) = P({a}) = 1/4 = P(B)P(D) = (1/2)(1/2).
Thus, A is independent of C and D, which implies that I
−1
A (B) is indepen￾dent of I
−1
C
(B) and I
−1
D (B). Thus, IA is independent of IC and ID. Similarly,
B is independent of C and D, which implies that IB is independent of IC
and ID. Thus, the component random variables of Z1
are independent of the
component random variables Z2
. We now examine whether Z1
and Z2
are
independent random vectors, by verifying whether the induced sigma fields
are independent. Note that A and B are independent of C and D implies that
A and B are independent of C
c and Dc
. Similarly, Ac and Bc are independent
of C and D. However, observe that for A ∩ B ∈ Z
−1
1
(B) and D ∈ Z
−1
2
(B),
P(A ∩ B ∩ D) = 1/4 ̸= P(A ∩ B)P(D) = (1/4)(1/2). Similarly, for A ∩ B ∈
Z
−1
1
(B) and C ∈ Z
−1
2
(B), P(A ∩ B ∩ C) = 0 ̸= P(A ∩ B)P(C) = (1/4)(1/2).
Hence, Z1
is not independent of Z2
. Thus, components of Z1
are independent
of Z2 but the random vector Z1
is not independent of Z2
. □
In Theorem 5.3.1 it is proved that Borel functions of independent random
variables are also independent random variables. The result remains valid even
for random vectors, as proved below.242 Independence
Theorem 5.3.9. Suppose X and Y are independent random vectors defined
on (Ω, A, P) to (R
k
, B
k
, PX) and (R
l
, B
l
, PY ) respectively.
(i) Suppose g : (R
k
, B
k
) → (R, B) is a Borel function and h : (R
l
, B
l
) → (R, B)
is a Borel function. Then g(X) and h(Y ) are independent random variables.
(ii) Suppose g : (R
k
, B
k
) → (R
m, B
m), m ≤ k is a Borel function and
h : (R
l
, B
l
) → (R
s
, B
s
), s ≤ l is a Borel function. Then g(X) and h(Y ) are
independent random vectors
Proof. In Theorem 2.3.5, it is proved that the sigma field induced by the
Borel function of a random vector is included in the sigma field induced by
the random vector. Hence,
σ(g(X)) ⊆ σ(X) & σ(h(Y )) ⊆ σ(X).
(i) To prove that, g(X) and h(Y ) are independent is equivalent to prove that
σ(g(X)) and σ(h(Y )) are independent sigma fields. Hence observe that,
A ∈ σ(g(X)) & B ∈ σ(h(Y )) ⇒ A ∈ σ(X) & B ∈ σ(Y )
⇒ P(A ∩ B) = P(A)P(B)
⇒ σ(g(X)) & σ(h(Y )) are independent
⇒ g(X) & h(Y ) are independent
random variables. (ii) follows on similar lines.
In particular, suppose X = (X1, X2)
′ and Y = (Y1, Y2)
′
. Then X1 + X2
is independent of Y1 + Y2, Y1Y2, e
Y1+Y2
. (X1 + X2, X1X2)
′
is independent of
(Y1 + Y2, Y1Y2)
′
, e
X1+X2
is independent of e
Y1+Y2 and so on.
We now proceed to one important result in probability theory, concerned
with a sequence of independent random variables. It deals with a situation in
which the probability of an event can only be 0 or 1. Theorems that provide
criteria for such a situation are called zero-one laws. The next section presents
one such law, known as Kolmogorov zero-one law. The other, known as Borel
zero-one law, is discussed in Section 6.4.
5.4 Kolmogorov Zero-One Law
In Section 2.3, we have introduced the concept of a tail sigma field generated
by a sequence {Xn, n ≥ 1} of random variables. In addition, if {Xn, n ≥ 1}
is a sequence of independent random variables, then the tail sigma field has
a peculiar nature and it is investigated in the Kolmogorov zero-one law. It
states that if {Xn, n ≥ 1} is a sequence of independent random variables,
then the tail sigma field generated by the sequence contains sets of probability
measure 0 or 1 only. We state below a lemma which is needed in the proof of
Kolmogorov zero-one law. For proof we refer to p.62 of Chow and Teicher [7].Kolmogorov Zero-One Law 243
Lemma 5.4.1. If C and D are independent classes of events and if D is a π￾system, then C and σ(D) are independent classes.
One more result related to a sequence of independent random variables is
needed in the proof of Kolmogorov zero-one law. We prove it below, which is
based on the extension theorem stated in Theorem 5.3.6.
Lemma 5.4.2. Suppose {Xn, n ≥ 1} is a sequence of independent random
variables. If T1 and T2 are non-empty disjoint subsets of {1, 2, · · · , }, then the
minimal sigma fields σ({Xn, n ∈ T1}) and σ({Xn, n ∈ T2}) are independent
sigma fields.
Proof. Since {Xn, n ≥ 1} is a sequence of independent random variables,
{σ(Xn), n ≥ 1} is a sequence of independent sigma fields. Suppose
A1 =
S
n∈T1
σ(Xn). Now,
A ∈ A1 ⇒ A ∈ σ(Xn) for at least one n ∈ T1
⇒ A
c ∈ σ(Xn) for at least one n ∈ T1
⇒ A
c ∈
[
n∈T1
σ(Xn) = A1.
Thus, A1 is closed under complementation. Further,
A, B ∈ A1 ⇒ A, B ∈ σ(Xn) for at least one n ∈ T1
⇒ A ∈ σ(Xr) for at least one r ∈ T1
& B ∈ σ(Xs) for at least one s ≥ r ∈ T1
Thus,
A ∈
[
i∈T1,i≤r
σ(Xi) & B ∈
[
j∈T1,j≤s
σ(Xj )
⇒ A ∪ B ∈
[
j∈T1,j≤s
σ(Xj ) ⇒ A ∪ B ∈
[
n∈T1
σ(Xn) = A1.
Thus, A1 is closed under finite union and hence it is a field. Similarly,
A2 =
S
n∈T2
σ(Xn) is also a field and hence both A1 and A2 are π- sys￾tems. Since T1 and T2 are non-empty disjoint classes and σ({Xn, n ≥ 1})
are independent sigma fields, it follows that A1 and A2 are independent
π- systems. Further, by Theorem 5.3.6, σ(A1) = σ({Xn, n ∈ T1}) and
σ(A2) = σ({Xn, n ∈ T2}) are independent sigma fields.
Theorem 5.4.1. Kolmogorov zero-one law: Suppose {Xn, n ≥ 1} is a se￾quence of independent random variables. Then the probability of tail events is
either 0 or 1.244 Independence
Proof. It is given that {Xn, n ≥ 1} is a sequence of independent random
variables. Suppose T1 = {1, 2, · · · , n} and T2 = {n + 1, n + 2, · · · }. Hence by
Lemma 5.4.2 ∀ n ≥ 1,
An = σ{X1, · · · , Xn} & Cn+1 = σ{Xn+1, Xn+2, · · · , } are independent.
(5.5)
As shown in Section 2.3, ∀ n ≥ 1 An ⊂ An+1 which implies that
{An, n ≥ 1} is a non-decreasing sequence of sigma fields. Hence, its limit exists
and is A =
S
n≥1 An. As discussed in Lemma 5.4.2, A is a field, hence a π
class. By definition, the tail sigma field T =
T
n≥1 Cn. Now
T =
\
n≥1
Cn ⇒ T ⊂ Cn ∀ n ≥ 1, hence A ∈ T ⇒ A ∈ Cn ∀ n ≥ 1
⇒ ∀ A ∈ T ⊂ Cn+1 & ∀ B ∈ An, P(A ∩ B) = P(A)P(B)
⇒ T & An are independent sigma fields ∀ n ≥ 1
Further, B ∈ A ⇒ B ∈ An for at least one n ≥ 1
⇒ For A ∈ T & B ∈ A, P(A ∩ B) = P(A)P(B)
⇒ T & A are independent
⇒ T & σ(A) are independent, by Lemma 5.4.1
⇒ T & σ({Xn, n≥1}) are independent, by Theorem 2.3.6
⇒ T & C1 are independent, by definition of C1
⇒ ∀ A ∈ T & ∀ B ∈ C1, P(A ∩ B) = P(A)P(B)
⇒ ∀ A ∈ T &A ∈ C1 P(A ∩ A) = P(A)P(A) as T ⊂ C1
⇒ ∀ A ∈ T, P(A) = 0 or P(A) = 1.
The second step follows by Equation (5.5) and the fifth step follows since T
and An are independent for all n ≥ 1. In other words, T is independent of T
itself which means that every event A ∈ T is independent of itself implying
that P(A) is either 0 or 1.
Tail events are determined by the behaviour of the sequence {Xn, n ≥ 1}
for large n and they remain unchanged if any finite sub collection of the X′
n
s
are dropped or replaced by another finite set of random variables. Hence,
events such as [lim supn→∞ Xn < x] or [limn→∞ Xn = X] are tail events. In
fact in Theorem 2.3.10, it is proved that lim inf Xn, lim sup Xn and lim Xn,
if it exists, are measurable with respect to tail sigma field T. Kolmogorov
zero one law implies that if {Xn, n ≥ 1} is a sequence of independent random
variables, then lim inf Xn, lim sup Xn and lim Xn, if it exists, are almost surely
degenerate random variables, as all these are measurable with respect to the
tail sigma field. More precisely, suppose a random variable X is measurable
with respect to T. Then for each x ∈ R, A = [X ≤ x] ∈ T. Further, by
Kolmogorov zero-one law P(A) = 0 or 1. Since, P[X ≤ x] increases as x
increases, it is 0 for x < x0 and is 1 for all x ≥ x0 for some x0 ∈ R, which
shows that X is degenerate at x0.Kolmogorov Zero-One Law 245
In the following example, we note that the limit random variable is degen￾erate at ∞.
Example 5.4.1. Suppose {Xn, n ≥ 1} is a sequence of random variables
where for each n ≥ 1, Xn ≡ n. Thus, Xn is degenerate at n for each n ≥ 1 and
hence it is a sequence of independent random variables with limn→∞ Xn =
X = ∞. The limit random variable is also a degenerate random variable.
Further, σ(Xn) = {Ω, ∅} ∀ n ≥ 1 implies T = {Ω, ∅} and the tail events have
probability either 0 or 1. □
A quick recap of the results discussed in this chapter is given below.
Summary
1. A finite collection {A1, A2, · · · , Ak} of events from A is said to be a col￾lection of independent events if, P(Ai1 ∩ Ai2 ∩ · · · ∩ Air
) = Qr
l=1 P(Ail
),
for every possible sub collection {i1, i2, · · · , ir} of {1, 2, · · · , k}, 2 ≤ r ≤ k.
2. A sequence {An, n ≥ 1} of events from A is a sequence of independent
events if every finite sub-collection of {An, n ≥ 1} is a collection of inde￾pendent events.
3. Suppose C1, C2, · · · , Ck are collections of events in A. Then these are
independent collections if ∀ A1 ∈ C1, A2 ∈ C2, · · · , Ak ∈ Ck,
{A1, A2, · · · , Ak} is a collection of independent events.
4. Suppose {Cn, n ≥ 1} is a sequence of collections of events from A. It
is a sequence of independent collections if {An, n ≥ 1} is a sequence of
independent events for every An ∈ Cn, n ≥ 1.
5. Random variables X1, X2, · · · , Xk are independent if σ(Xi) are indepen￾dent sigma fields, i = 1, 2, · · · , k.
6. Suppose X and Y are independent random variables and g and h are Borel
functions, then g(X) and h(Y ) are independent random variables.
7. Any random variable is always independent of a degenerate random vari￾able.
8. If X and Y are independent random variables then, E(XY ) = E(X)E(Y ).
9. Suppose X and Y are independent random variables. Then (i) joint char￾acteristic function of X and Y is the product of characteristic functions
of X and Y and (ii) the characteristic function of X + Y is the product of
characteristic functions of X and Y .246 Independence
10. Two random variables X and Y are independent random variables if any
one of the following three conditions are satisfied.
(i) σ(X) and σ(Y ) are independent sigma fields, that is
∀ S1, S2 ∈ B, P[X ∈ S1, Y ∈ S2] = P[X ∈ S1]P[Y ∈ S2].
(ii) ∀ x, y ∈ R, FX,Y (x, y) = FX(x)FY (y).
(iii) ∀ t1, t2 ∈ R, ϕX,Y (t1, t2) = ϕX(t1)ϕY (t2).
11. A sequence {Xn, n ≥ 1} is a sequence of independent random variables
if and only if any finite collection of the sequence is a collection of inde￾pendent random variables. A class {Xt, t ∈ T} is a class of independent
random variables if and only if any finite sub class of this class is a class
of independent random variables.
12. Two random vectors X and Y defined on the same probability space are
independent random vectors if the induced sigma fields are independent.
13. If two random vectors are independent, then each component random
variable of one random vector is independent of each component random
variable of the second random vector.
14. Borel functions of independent random vectors are also independent ran￾dom vectors.
15. Kolmogorov zero-one law: If {Xn, n ≥ 1} is a sequence of independent
random variables, then the tail events have probability either 0 or 1.
5.5 Conceptual Exercises
5.5.1 Prove or disprove: A P-null event is independent of itself.
5.5.2 Suppose N is a P-null event. Examine whether Nc
is independent of
itself.
5.5.3 Suppose P(C|A ∩ B) = P(C|B) and P(A ∩ B ∩ C) > 0. Show that
P(A|B ∩ C) = P(A|B).
5.5.4 Prove or disprove: (i) Mutually exclusive events are independent.
(ii) Independent events are mutually exclusive.
5.5.5 Show that two events A and B are independent if and only if σ({A})
and σ({B}) are independent. Show further that it is equivalent to IA
and IB are independent random variables.Conceptual Exercises 247
5.5.6 Give an example of events A1, A2, A3 which are pair-wise independent
but not independent.
5.5.7 Suppose {An, n ≥ 1} is a sequence of independent events. Show that
P
 Sk
r=1 Air

= 1−
Qk
r=1(1−P(Air
)), for any combination i1, i2, · · · , ik
of 1, 2, · · · , k and for finite k ≥ 2.
5.5.8 Suppose X1 and X2 are random variables defined on (Ω, A, P) as follows,
where Ω = {a, b, c}, A = P(Ω) and P is defined as P({ω}) = 1/3 ∀ ω ∈
Ω.
X1(ω) = 
0, if ω = a
1, if ω = b, c. & X2(ω) = 
2, if ω = b
3, if ω = a, c.
(i) Examine whether X1 and X2 are independent random variables on
(Ω, A, P). (ii) Examine whether 5X2
1 + 4 and 3X3
2 +e
X2 are independent
random variables on (Ω, A, P).
5.5.9 Suppose (Ω, A, P) is a probability space, where Ω = {a, b, c, d}, A =
P(Ω) and P({ω}) = 1/4 ∀ ω ∈ Ω. Suppose X1 and X2 are random
variables defined on (Ω, A, P) as follows.
X1(ω) = 
10, if ω = a, b
20, if ω = c, d. & X2(ω) = 
30, if ω = a, c
40, if ω = b, d.
Examine whether exp(5X1−7) and log(4X2+9) are independent random
variables.
5.5.10 Suppose (Ω, A, P) is a probability space and {A1, A2, A3} is a measur￾able partition of Ω. Suppose B ∈ A. Show that a random variable X
defined as X =
P3
i=1 iIAi
and IB are independent if and only if B is
independent of each of {A1, A2, A3}.
5.5.11 Suppose (Ω, A, P) is a probability space and A, B, C ∈ A are indepen￾dent events. Examine whether C is independent of an event obtained
from A and B by complementation, union and intersection.
5.5.12 Suppose (Ω, A, P) is a probability space and A, B, C ∈ A are indepen￾dent events. Can we claim that IA +3IB and IC are independent random
variables? Justify your answer.
5.5.13 Suppose (Ω, A, P) is a probability space. Suppose A, C ∈ A are inde￾pendent events and B, C ∈ A are independent events. Can we claim that
IA +IB and IC are independent random variables? Justify your answer.
5.5.14 Give two examples in which a random variable is independent of itself.
5.5.15 Give an example of random variables X1, X2, X3 which are pairwise
independent but not independent.248 Independence
5.5.16 Give an example of random variables X1, X2, X3, X4 which are inde￾pendent.
5.5.17 Prove or disprove: If F is a distribution function, then (i) F
4
is also a
distribution function, (ii) 2F − F
2
is also a distribution function.
5.5.18 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
and {fn, n ≥ 1} is a sequence of Borel functions. Show that {fn(Xn), n ≥
1} is a sequence of independent random variables.
5.5.19 If X and Y are independent and X is integrable, show that
R
[Y ∈B] X dP = E(X)P[Y ∈ B] for any Borel set B.
5.5.20 Give an example of two random variables X and Y such that X and Y
are not independent but the characteristic function of their sum is the
product of their characteristic functions.
5.5.21 Suppose X and Y are independent random variables. Show that if X
and X − Y are independent, then X must be degenerate.
5.6 Multiple Choice Questions
Note: In each question, multiple options may be correct. Unless specified
otherwise, identify which of the statement(s) is/are correct. Answers are given
in Chapter 11, after the solutions of conceptual exercises of Chapter 5.
5.6.1 A and B are two independent events with 0 < P(A), P(B) < 1. Which
of the following is/are false?
(a) P(Ac T
B) = P(B) − P(B)P(A)
(b) P(A
T
B) = P(A)P(B)
(c) A and B are mutually exclusive
(d) P(A
T
Bc
) = P(B) − P(B)P(A)
5.6.2 Following are two statements: (I) Mutually exclusive events are inde￾pendent. (II) Independent events are mutually exclusive. Then
(a) Both (I) and (II) are true
(b) (I) is true but (II) is false
(c) (II) is true but (I) is false
(d) Both (I) and (II) are false
5.6.3 Suppose A and B are independent events. Then
(a) P(Ac ∩ B) = P(B) − P(B)P(A)
(b) P(A ∩ B) = 0Multiple Choice Questions 249
(c) A and B are mutually exclusive events
(d) P(A ∪ B) = P(A) + P(B).
5.6.4 Suppose (Ω, A, P) is a probability space. Then an event A ∈ A is
(a) always independent of itself
(b) independent of itself if P(A) = 0
(c) independent of itself if P(A) = 1
(d) independent of a sure event
5.6.5 Suppose (Ω, A, P) is a probability space. Which of the following state￾ments is false?
(a) An event A ∈ A is always independent of itself
(b) An event A ∈ A is independent of itself if P(A) = 0
(c) An event A ∈ A is independent of itself if P(A) = 1
(d) An event A ∈ A is independent of a sure event
5.6.6 Suppose (Ω, A, P) is a probability space. Following are two statements
about an event A ∈ A. (I) A is independent of sure event Ω. (II) A is
independent of null event ∅.
(a) Both (I) and (II) are true
(b) (I) is true but (II) is false
(c) (II) is true but (I) is false
(d) Both (I) and (II) are false
5.6.7 Two random variables X1 and X2 are independent if
(a) σ(X1) ⊂ σ(X2)
(b) σ(X1) ⊃ σ(X2)
(c) σ(X1) = σ(X2)
(d) σ(X1) and σ(X2) are independent sigma fields.
5.6.8 Suppose X and Y are independent random variables. Following are two
statements: (I) If g and h are Borel functions, then g(X) and h(Y ) are
independent random variables. (II) If g and h are continuous functions,
then g(X) and h(Y ) are independent random variables.
(a) Both (I) and (II) are true
(b) (I) is true but (II) is false
(c) (II) is true but (I) is false
(d) Both (I) and (II) are false
5.6.9 Following are two statements: (I) Any random variable is always inde￾pendent of a degenerate random variable. (II) Any random variable is
always independent of itself.
(a) Both (I) and (II) are true
(b) (I) is true but (II) is false
(c) (II) is true but (I) is false250 Independence
(d) Both (I) and (II) are false
5.6.10 Following are two statements: (I) A random variable is independent of
itself. (II) A random variable is independent of itself if and only if it is
a degenerate random variable.
(a) Both (I) and (II) are true
(b) (I) is true but (II) is false
(c) (II) is true but (I) is false
(d) Both (I) and (II) are false
5.6.11 Following are two statements: (I) Suppose {Xn, n ≥ 1} is a sequence
of independent random variables. Then the tail events have probability
either 0 or 1. (II) Suppose {Xn, n ≥ 1} is a sequence of random variables.
Then the tail events have probability either 0 or 1.
(a) Both (I) and (II) are true
(b) (I) is true but (II) is false
(c) (II) is true but (I) is false
(d) Both (I) and (II) are false
5.6.12 Suppose g and h are Borel functions and X and Y are random vari￾ables. Following are two statements: (I) g(X) and h(Y ) are independent
random variables implies X and Y are independent random variables.
(II) g(X) and h(Y ) are not independent random variables for some func￾tions g and h implies X and Y are not independent random variables.
(a) Both (I) and (II) are true
(b) (I) is true but (II) is false
(c) (II) is true but (I) is false
(d) Both (I) and (II) are false
5.6.13 Following are two statements: (I) If two random vectors are indepen￾dent, then each component random variable of one random vector is
independent of each component random variable of the second random
vector. (II) If each component random variable of one random vector is
independent of each component random variable of the second random
vector, then two random vectors are independent.
(a) Both (I) and (II) are true
(b) (I) is true but (II) is false
(c) (II) is true but (I) is false
(d) Both (I) and (II) are false
5.6.14 Suppose X and Y are independent random variables and the expec￾tations in the following statements are finite. Following are three state￾ments:
(I) E(X3 + tan Y ) = E(X3
) + E(tan Y ).
(II) E((exp(5X3 + 10))(cos(4Y −6))) = E((exp(5X3 + 10))E((cos(4Y −
6)).Multiple Choice Questions 251
(III) E((3X3 + 6X + 9)(4Y
4 − 6Y )) ̸= E((3X3 + 6X + 9)E(4Y
4 − 6Y )
always.
(a) Only (I) is true
(b) Only (II) is true
(c) Both (I) and (II) are true
(d) (III) is false
5.6.15 Suppose Z1 = (X1, X2)
′ and Z2 = (Y1, Y2)
′
. Following are two state￾ments: (I) If Z1
and Z2
are independent, then Xi
is independent of Yj
∀ i, j = 1, 2. (II) If Xi
is independent of Yj ∀ i, j = 1, 2, then Z1
and
Z2
are independent.
(a) Both (I) and (II) are true
(b) (I) is true but (II) is false
(c) (II) is true but (I) is false
(d) Both (I) and (II) are false6
Almost Sure Convergence and
Borel Zero-One Law
6.1 Introduction
Statistics as a scientific discipline deals with various methods of collection of
data, a variety of tools for their analysis and interpretation of the results of
the analysis. Numerous techniques of analysis and their optimality properties
are discussed in statistical inference in its three branches - point estimation,
interval estimation and tests of hypotheses. These differ as the size of the data
differs. In some cases if the data size is small, optimal solution may not exist.
However, scenario changes as sample size increases. Statistics is concerned with
gathering data, hence it is naturally of interest to judge what happens when
we get more and more data. It is investigated in large sample or asymptotic
inference theory. Two most desirable properties of a point estimator in asymp￾totic inference setup are consistency and asymptotic normality with suitable
normalization. An estimator is a Borel function of sample observations and
hence is again a random variable. The optimality properties of the estimator
for finite sample size, such as unbiasedness and variance, are studied from
its distribution, known as the sampling distribution. When the sample size is
large, the optimality properties such as consistency and asymptotic normality
are based on the limiting behaviour of a sequence of estimators. Hence, the
principal probability tool in large sample inference is the convergence of a
sequence of random variables. It is the most important concept from proba￾bility theory and is heavily applied in statistical analysis. This chapter and
Chapters 7 to 10 are devoted to an elaborate discussion of this notion.
Suppose {Xn, n ≥ 1} is a sequence of random variables defined on a prob￾ability space (Ω, A, P). As discussed in Chapter 2, a sequence {Xn, n ≥ 1}
of random variables is equivalent to a collection of sequences of real num￾bers, {{Xn(w) = an, n ≥ 1}, ω ∈ Ω}. Hence, to discuss the convergence of a
sequence of random variables, one has to deal with the convergence of a col￾lection of sequences of real numbers. Using this approach in Chapter 2 we have
studied point-wise convergence. Almost sure convergence, which we discuss in
Section 2, also adopts the similar approach. Other approaches to reduce a se￾quence of random variables to a collection of sequences of real numbers lead to
other modes of convergence, namely, convergence in probability, convergence
DOI: 10.1201/9781032619057-6 252Definitions of Various Modes of Convergence 253
in law and convergence in r-th mean. We define all these modes of conver￾gence in the next section and study their properties in subsequent sections
and Chapter 7. In the present chapter, we concentrate on the almost sure
convergence and Borel zero-one law, which is also concerned with the almost
sure convergence. The other modes of convergence, namely, convergence in
probability, convergence in law and convergence in r-th mean are studied in
Chapter 7.
6.2 Definitions of Various Modes of Convergence
In all the modes of convergence, except convergence in law, it is assumed that
a sequence {Xn, n ≥ 1} of random variables and the limit random variable X
are defined on the same probability space (Ω, A, P). We begin with point-wise
convergence, denoted by Xn → X on Ω, which has been already introduced
in Chapter 2.
Definition 6.2.1. Point-wise convergence: A sequence {Xn, n ≥ 1} is said
to converge point-wise to a random variable X, if Xn(ω) → X(ω), ∀ ω ∈ Ω.
More precisely, ∀ ω ∈ Ω and ∀ ϵ > 0, ∃ an integer n0(ϵ, ω), such that
∀ n ≥ n0(ϵ, ω), |Xn(ω) − X(ω)| < ϵ.
A point-wise convergence of a sequence of random variables is denoted by,
Xn → X on Ω. The set B on which Xn(ω) → X(ω), can be expressed as
follows.
B =
\
ϵ>0
[
n≥1
\
m≥n
{ω||Xm(ω) − X(ω)| < ϵ}.
The set B is referred to as a set of convergence. It is to be noted that T
ϵ>0
is
an uncountable intersection, but it can be replaced by a countable intersection,
since for every ϵ > 0 there exists a positive integer k, such that 1/k < ϵ. Thus,
the set B can be represented as
B =
\
k≥1
[
n≥1
\
m≥n
{ω||Xm(ω) − X(ω)| < 1/k}.
The set B expressed in this way is a measurable set, so one can assign prob￾ability to B. In point-wise convergence B = Ω.
If Xn(ω) → X(ω) where X(ω) is finite, then Xn(ω) − Xm(ω) → 0 as
m, n → ∞ or equivalently Xm+n(ω) − Xn(ω) → 0 as n → ∞ uniformly in
m and conversely. This is known as a Cauchy criterion of convergence. If a
sequence converges in a Cauchy sense then it is said to converge mutually. If
Bc denotes the set of mutual convergence, then it is given by,
Bc =
\
k≥1
[
n≥1
\
m≥1
{ω||Xm+n(ω) − Xn(ω)| < 1/k}.254 Almost Sure Convergence and Borel Zero-One Law
Since mutual convergence implies convergence, Bc ⊂ B. If X is finite on B,
then Bc = B.
In practice it is very rare to have a point-wise convergence of a sequence
of random variables, in view of the fact that in most of the situations Ω is
countably infinite or uncountable. In the next mode of convergence, the al￾most sure convergence, the requirement of convergence for all sample points
is slightly relaxed. Almost sure convergence, also known as almost everywhere
convergence, is similar to the point-wise convergence of a sequence of random
variables, except that the convergence need not occur on a P-null set. Fol￾lowing is the definition of almost sure convergence of a sequence of random
variables.
Definition 6.2.2. Almost sure convergence: A sequence {Xn, n ≥ 1} is said
to converge almost surely to a random variable X, if and only if Xn(ω) →
X(ω) ∀ ω ∈ Nc
, such that P(N) = 0. More precisely, ∀ ω ∈ Nc and
∀ ϵ > 0, ∃ an integer n0(ϵ, ω), such that ∀ n ≥ n0(ϵ, ω), |Xn(ω)−X(ω)| < ϵ.
If n0(ϵ, ω) does not depend on ω, then we have uniform almost sure con￾vergence. The above definition can be expressed as P[limn→∞ Xn = X] = 1.
Hence, almost sure convergence is also known as convergence with probability
1. Almost sure convergence of Xn to X is denoted by Xn
a.s. → X. The set N
is a P-null set. In almost sure convergence, the set Nc of convergence is the
same as the set B of convergence defined above, with P(Nc
) = 1.
In point-wise convergence and in almost sure convergence, a sequence of
random variables is reduced to a sequence of real numbers by considering
images Xn(ω). In the next mode of convergence, convergence in probability,
the closeness of Xn and X is measured in terms of the underlying probability
measure and in this way the convergence of sequence of random variables is
reduced to convergence of sequence of real numbers. More precisely, suppose
pn(ϵ) = P[|Xn − X| < ϵ]. Thus, {pn(ϵ), n ≥ 1} is a sequence of real num￾bers and we examine whether it converges to 1 ∀ ϵ > 0 in convergence in
probability. We define this mode of convergence below.
Definition 6.2.3. Convergence in probability: A sequence {Xn, n ≥ 1} is said
to converge in probability to a random variable X, if and only if
∀ ϵ > 0, limn→∞
P[|Xn − X| < ϵ] = 1 ⇐⇒ limn→∞
P[|Xn − X| ≥ ϵ] = 0.
Convergence in probability can be viewed as a stochastic analog of the
convergence of a sequence of real numbers. It is denoted by Xn
P
→ X. Observe
that from the definition
Xn
P
→ X ⇐⇒ Xn − X
P
→ 0.
If Xn
P
→ 0, then we write Xn = op(1). If more generally, anXn
P
→ 0, then
we write Xn = op(1/an). From the definitions of almost sure convergence andDefinitions of Various Modes of Convergence 255
convergence in probability, observe that
Xn
P
→ X, if limn→∞
P[|Xn − X| < ϵ] = 1, ∀ ϵ > 0
and Xn
a.s. → X, if P[ limn→∞
Xn = X] = 1.
Thus, the two modes are quite different. In the next section, we prove that
almost sure convergence is stronger than the convergence in probability.
The frequent use of normal distribution in a variety of areas is based on
the fact that the sample mean is approximately normal when the sample
size is large. The large sample inference theory mainly deals with approxi￾mations of probability distributions and with the limit theorems underlying
these approximations for large sample size. Such limit theorems are based on
a concept of convergence of a sequence of distributions. Probability distribu￾tions can be characterized in different ways, for example, by their distribution
functions or their probability mass functions or probability density functions.
The convergence of a sequence of probability distributions is defined in terms
of convergence of their distribution functions, and this mode of convergence
is known as convergence in law or convergence in distribution. Thus in this
mode we study the behaviour of a sequence {Fn(x), n ≥ 1} of real numbers
for some values of x ∈ R.
Definition 6.2.4. Convergence in law: Suppose {Xn, n ≥ 1} is a sequence
of random variables defined on a probability space (Ω, A, P). Suppose Fn(·) is
a distribution function of Xn and FX(·) is a distribution function of X. A
sequence {Xn, n ≥ 1} is said to converge in law to a random variable X, not
necessarily defined on the same probability space, if and only if
Fn(x) = P[Xn ≤ x] → P[X ≤ x] = FX(x), ∀ x ∈ C(FX),
where C(FX) is a set of points of continuity of the distribution function FX.
Convergence in law is denoted by Xn
L
→ X or Xn
d
→ X. From the definition
of convergence in law, it immediately follows that for any interval I = (a, b],
such that a, b ∈ C(FX), as n → ∞
P[a < Xn ≤ b] = FXn
(b) − FXn
(a) → FX(b) − FX(a) = P[a < X ≤ b] .
It is to be noted that in the definition of convergence in law, it is required
that Fn(x) → FX(x) for all x which are the points of continuity of FX(x).
One might be concerned about such a restriction. However, it is enough to
restrict to a set C(FX) in view of the fact that the set of points of continuity is
dense in R. Further, it is shown in Section 3.2, that the distribution function is
completely determined by its values at all continuity points. It is to be noted
that in convergence in law, a sequence of random variables {Xn, n ≥ 1} and
the limit random variable is X need not be defined on the same probability
space.256 Almost Sure Convergence and Borel Zero-One Law
In convergence in law, a sequence of random variables {Xn, n ≥ 1} is
reduced to a sequence of real numbers by considering the sequence of distri￾bution functions, which is equivalent to a sequence of real numbers in [0, 1].
In the next mode of convergence, convergence in r-th mean, a sequence of
random variables {Xn, n ≥ 1} is reduced to a sequence of real numbers by
considering the sequence of expectations of the deviation |Xn−X|. This mode
of convergence is defined when both Xn and X belong to Lr space, as de￾fined in Chapter 4. If Xn and X belong to Lr space, by the Cr inequality,
E(|Xn − X|
r
) < ∞, r > 0 and hence Xn − X also belongs to Lr space.
Definition 6.2.5. Convergence in r-th mean: Suppose Xn for each n ≥ 1
and X belong to Lr space. A sequence {Xn, n ≥ 1} is said to converge in r-th
mean to a random variable X, if and only if
E(|Xn − X|
r
) → 0 as n → ∞, r > 0.
If r = 2 then the convergence is referred to as a convergence in quadratic
mean.
Convergence in r-th mean is denoted by Xn
r→ X and convergence in
quadratic mean is denoted by Xn
q.m. → X. Convergence in r-th mean is also
known as Lr convergence.
It is to be noted that the concept of convergence in probability, conver￾gence in r-th mean or almost sure convergence represents a sense in which,
for n sufficiently large, Xn and X approximate each other as functions on the
original probability space. The concept of convergence in distribution how￾ever, depends only on the closeness of distribution functions FXn
and FX
and does not require that Xn and X are close in any other sense; in fact, X
and Xn’s may not be defined on the same probability space. Among all these
modes of convergence, point-wise and uniformly point-wise convergence are
from calculus theory, almost sure convergence, convergence in probability and
convergence in r-th mean are unique to measure theory while convergence in
distribution is unique to probability theory.
In this and the next chapter we study all these modes of convergence in
detail. We investigate which properties of convergence of a sequence of real
numbers get extended to a convergence of a sequence of random variables. We
discuss some aspects listed below.
(i) Whether the limit is unique and in what sense?
(ii) Whether the convergence is closed under arithmetic operations?
(iii) Whether the convergence is invariant under continuous transforms?
(iv) Whether the convergence and the corresponding Cauchy convergence are
equivalent?
(v) What are the links among these modes of convergence?Almost Sure Convergence 257
In Section 3, we investigate the properties of the almost sure convergence.
Section 4 presents Borel zero-one law, which is mainly related to the almost
sure convergence of a sequence of independent random variables. We illustrate
all the results with a variety of theoretical examples. The concepts related
to various modes of convergence are difficult to grasp due to their abstract
nature. To absorb the notions easily, theoretical results are simultaneously
supported by the numerical computations, graphs and the simulation studies,
with R software. The R codes are given for some examples. Interested readers
may refer to Serfling [20] and van der Vaart [24] for some more theoretical
results.
6.3 Almost Sure Convergence
In this section we discuss various aspects of the almost sure convergence of
a sequence of random variables. We begin with an example illustrating the
almost sure convergence and the point-wise convergence. One illustration is
already discussed in Section 2.3.
Example 6.3.1. Suppose the probability space (Ω, A, P) is defined as follows.
Ω = [0, 1] and A is a sigma field of subsets of Ω. Suppose for A = (a, b) ⊂ [0, 1],
P(A) = b − a, the Lebesgue measure of A. In such a setup (Ω, A, P) is known
as a unit interval probability space. Definition of P(A) for A = (a, b) will
define P(A) for all A in A using the properties of probability measure. As in
Example 2.3.5, a sequence {Xn, n ≥ 1} of A measurable random variables and
a A measurable random variable X are defined as follows.
Xn(ω) = e
ω + ω
n
, n ≥ 1 & X(ω) = e
ω
.
It is clear that,
Xn(ω) = e
ω + ω
n → e
ω = X(ω), ∀ ω ∈ [0, 1).
But at ω = 1, Xn(ω) = e+1 ̸= e = X(ω). Thus Xn ↛ X point-wise. However,
note that Xn(ω) → X(ω), except for ω = 1. Thus, if Nc = [0, 1), then given
ϵ > 0
∀ ω ∈ N
c
, ∃ n0(ω, ϵ) such that |Xn(ω) − X(ω)| < ϵ.
Observe that P(Nc
) = 1 and hence, Xn
a.s. → X with N = {1} as the P-null
set. □
To understand the abstract concept of almost sure convergence, we verify
the results of Example 6.3.1, graphically using R software in the next example.
Example 6.3.2. Suppose a sequence {Xn, n ≥ 1} of random variables and
X are as defined in Example 6.3.1. We use the following code for verification
of the results obtained in Example 6.3.1.258 Almost Sure Convergence and Borel Zero-One Law
Code 6.3.1. Verification of almost sure convergence:
Xnw=function(n,w){return(exp(w)+w^n)}
Xw=function(w){return(exp(w))}
omegavec=seq(0,1,length=100)
nvec=c(1,10,100); nlab=paste("n=",nvec,sep="")
XnMat=matrix(nrow=length(omegavec),ncol=length(nvec))
for(i in 1:nrow(XnMat))
{
omega=omegavec[i]
for(j in 1:ncol(XnMat))
{
n=nvec[j]
XnMat[i,j]=Xnw(n,omega)
}
}
XVec=c()
for(i in 1:length(omegavec))
{
omega=omegavec[i]
XVec[i]=Xw(omega)
}
plot(omegavec,XVec,ylim=c(1,max(XnMat)+0.1),type="l",col=2,
lty=1,lwd=2,xlim=c(0,1.5),xaxt="n", xlab=expression(omega),
ylab=(expression(Xn(omega)~or~X(omega))),
main=(expression(Xn(omega)~"="~exp(omega)+ omega^n)))
axis(1,at=seq(0,1,by=0.1),labels=seq(0,1,by=0.1))
for(i in 1:ncol(XnMat))
{
lines(omegavec,XnMat[,i],col=1,lty=i+1,type="l",lwd=2)
}
legend("bottomright",legend=c(nlab,expression(X(omega))),
lty=c(2:(ncol(XnMat)+1),1),col=c(rep(1,3),2),lwd=2)
In Figure 6.1, the red curve displays the values of X(ω), whereas the black
curves present the values of Xn(ω) for different choices of n as indicated in
the legend. It can be seen that the black curves approach the red curve as n
increases except for the rightmost endpoint, that is, ω = 1. Thus, Xn ↛ X
point-wise, but Xn
a.s. → X. □Almost Sure Convergence 259
FIGURE 6.1
Almost Sure Convergence
It is of interest to see that even if ω is very close to 1, corresponding to given
ϵ > 0, we can find n0(ω, ϵ) such that |Xn(ω) − X(ω)| < ϵ. We demonstrate it
in the following example.
Example 6.3.3. Suppose a sequence {Xn, n ≥ 1} of random variables and X
are as defined in Example 6.3.1. Using the following code, we find the values
of n0 for different values of ϵ and of ω, which are close to 1.
Code 6.3.2. Computation of n0(ω, ϵ) in almost sure convergence:
Xnw=function(n,w){return(exp(w)+w^n)}
Xw=function(w){return(exp(w))}
omegavec=seq(0.999,0.9999, length=1000)
epsilon=c(0.1,0.5)
nvec=c(10,100,1000,5000,10000,50000)
nlab=paste("n=",nvec,sep="")
XnMat=matrix(nrow=length(omegavec),ncol=length(nvec))
for(i in 1:nrow(XnMat))
{
omega=omegavec[i]
for(j in 1:ncol(XnMat))
{
n=nvec[j]
XnMat[i,j]=Xnw(n,omega)260 Almost Sure Convergence and Borel Zero-One Law
}
}
XVec=c()
for(i in 1:length(omegavec))
{
omega=omegavec[i]
XVec[i]=Xw(omega)
}
plot(omegavec,XVec,ylim=c(XVec[1]-0.7,max(XnMat)+0.1),type="l",
col=2,lty=1,lwd=2,xlim=c(0.999,1),xaxt="n",
xlab=expression(omega),ylab=(expression(Xn(omega)~or~X(omega))),
main=(expression(Xn(omega)~"="~exp(omega)+ omega^n)))
text(x=0.999,y=XVec[1]-0.05,labels=expression(X(omega)),col=2)
axis(1,at=c(seq(0.999,1,by=0.0005),0.9999),
labels=c(seq(0.999,1,by=0.0005),0.9999))
for(i in 1:ncol(XnMat))
{
lines(omegavec,XnMat[,i],col=1,lty=i+1,type="l",lwd=2)
text(x=0.99995,y=XnMat[nrow(XnMat),i]-0.01*(-1)^i,labels=
nlab[i])
}
abline(h=XVec[1]+epsilon[1],col=2,lty=2,lwd=1.5)
abline(h=XVec[1]-epsilon[1],col=2,lty=2,lwd=1.5)
text(x=0.9995,y=XVec[1]+0.15,labels=expression
(X(omega)~"+"~0.1),
col=2)
text(x=0.9995,y=XVec[1]-0.15,labels=expression
(X(omega)~"-"~0.1),
col=2)
abline(h=XVec[1]-epsilon[2],col=4,lty=3,lwd=1.5)
abline(h=XVec[1]+epsilon[2],col=4,lty=3,lwd=1.5)
text(x=0.9995,y=XVec[1]+0.55,labels=expression
(X(omega)~"+"~0.5),
col=4)
text(x=0.9995,y=XVec[1]-0.55,labels=expression
(X(omega)~"-"~0.5),
col=4)
lines(1,Xw(1),col=2,type="p",pch=15)
lines(1,Xnw(100,1),col=1,type="p",pch=16)Almost Sure Convergence 261
FIGURE 6.2
Almost Sure Convergence: n0
Figure 6.2 displays the curves of Xn(ω) for ω values which are very close
to 1. More precisely, in Figure 6.2, we focus on ω values between 0.999 and
0.9999. It can be seen that even for ω values which are so close to 1, we can
always find n0 for each ϵ. Since the black curves approach the red curves
as seen in Figure 6.1, we can see that any n for which Xn(ω) lies within
(X(ω)−ϵ, X(ω)+ϵ) can work as n0. Note that n0 is not unique. Once we find
some n0, any n larger than it, can work as another n0. Looking at the graph,
some suggested values of n0 for different values ω and ϵ are given in Table 6.1.
From Table 6.1, we note that for ω = 0.9999 and ϵ = 0.1, n0 = 50000 is
very large. □
It is to be noted that to verify the almost sure convergence graphically, we
need to know Ω and the functional form of Xn and X. In many cases we know
TABLE 6.1
Almost Sure Convergence: n0(ϵ, ω)
ϵ 0.1 0.1 0.5 0.5
ω 0.9990 0.9999 0.9990 0.9999
n0 5000 50000 1000 10000262 Almost Sure Convergence and Borel Zero-One Law
only the probability distribution of Xn. To verify almost sure convergence in
such a setup, we have to use the definition or some necessary and sufficient
conditions for the almost sure convergence. We now proceed to derive such
conditions and illustrate its use by examples.
As defined in Section 2, Xn
a.s. → X ⇒ Xn(ω) → X(ω) ∀ ω ∈ Nc
, such
that P(N) = 0. Thus, the set Nc of convergence is given by,
N
c =
\
k≥1
[
n≥1
\
m≥n
{ω||Xm(ω) − X(ω)| < 1/k} with P(N
c
) = 1 .
Suppose an event Dk is defined as
Dk =
\
n≥1
[
m≥n
{ω||Xm(ω) − X(ω)| ≥ 1/k} (6.1)
= [lim sup[|Xn − X| ≥ 1/k]] = [|Xn − X| ≥ 1/k, infinitely often],
by the definition of the limit superior of a set. Thus,
Xn
a.s. → X ⇒ P(N) = 0
⇒ P
h [
k≥1
\
n≥1
[
m≥n
{ω||Xm(ω) − X(ω)| ≥ 1/k}
i
= 0
⇒ P
 [
k≥1
Dk

= 0
⇒ P(Dk) = 0, ∀ k ≥ 1 since Dk ⊂
[
k≥1
Dk
⇒ P[lim sup[|Xn − X| ≥ 1/k]] = 0
⇐⇒ P[lim inf[|Xn − X| < 1/k]] = 1
⇐⇒ P[|Xn − X| < 1/k, except for finitely many n] = 1.
Thus, Xn
a.s. → X implies that the probability of infinitely many deviations
are large is 0. In other words, with probability 1, most of the deviations are
small. Using these arguments, a necessary and sufficient condition for the
almost sure convergence can be derived as follows.
Theorem 6.3.1. Suppose a sequence of random variables {Xn, n ≥ 1} and
X are defined on the same probability space (Ω, A, P). Then ∀ k ≥ 1,
Xn
a.s. → X ⇐⇒ limn→∞
P
h [
m≥n
[|Xm − X| ≥ 1/k]
i
= 0
⇐⇒ limn→∞
lim
N→∞
P
h [
N
m=n
[|Xm − X| ≥ 1/k]
i
= 0. (6.2)Almost Sure Convergence 263
Proof. Suppose an event Dk is as defined in Equation (6.1). Thus,
Dk =
\
n≥1
[
m≥n
{ω||Xm(ω) − X(ω)| ≥ 1/k}
=
\
n≥1
Bnk where Bnk =
[
m≥n
{ω||Xm(ω) − X(ω)| ≥ 1/k}.
Observe that ∀ k ≥ 1,
Bnk ⊃ B(n+1)k ⇒ {Bnk, n ≥ 1} is a decreasing sequence of sets
⇒ limn→∞
Bnk exists
& limn→∞
Bnk =
\
n≥1
Bnk = Dk
Further, Bnk =
[
m≥n
{ω||Xm(ω) − X(ω)| ≥ 1/k}
= lim
N→∞ h [
N
m=n
[|Xm − X| ≥ 1/k]
i
.
Now from the definition of almost sure convergence, we have
Xn
a.s. → X ⇐⇒ P[Xn ↛ X] = 0
⇐⇒ P
h [
k≥1
\
n≥1
[
m≥n
[|Xm − X| ≥ 1/k]
i
= P
h [
k≥1
Dk
i
= 0
⇐⇒ ∀ k ≥ 1 P(Dk) = 0
⇐⇒ ∀ k ≥ 1 P[ limn→∞
Bnk] = 0
⇐⇒ ∀ k ≥ 1 limn→∞
P(Bnk) = 0
⇐⇒ ∀ k ≥ 1 limn→∞
P
h
lim
N→∞
[
N
m=n
[|Xm − X| ≥ 1/k]
i
= 0
⇐⇒ ∀ k ≥ 1 limn→∞
lim
N→∞
P
h [
N
m=n
[|Xm − X| ≥ 1/k]
i
= 0.
Note that
Xn
a.s. → X ⇐⇒ ∀ k ≥ 1 P(Dk) = 0
⇐⇒ ∀ k ≥ 1 P[lim sup[|Xn − X| ≥ 1/k]] = 0 (6.3)
Following example illustrates Theorem 6.3.1.264 Almost Sure Convergence and Borel Zero-One Law
Example 6.3.4. Suppose {Xn, n ≥ 1} is a sequence of random variables with
P[Xn = ±1/n] = 1/2. Note that,
j < k ⇒ |Xj | > |Xk| a.s. ⇒ Ak = [|Xk| > ϵ] ⊂ Aj = [|Xj | > ϵ]
⇒ An ⊃ An+1 ⊃ An+2 · · ·
⇒
[
m≥n
[|Xm| > ϵ] = [|Xn| > ϵ]
⇒ P[
[
m≥n
[|Xm| > ϵ]] = P[|Xn| > ϵ] ≤ P[|Xn| > 1/n] = 0,
since ∀ ϵ > 0 ∃ n ≥ 1 such that 1/n < ϵ. Hence, by the necessary and
sufficient condition for the almost sure convergence, Xn
a.s. → 0. □
Following corollary gives a sufficient condition for the almost sure conver￾gence.
Corollary 6.3.1. Suppose a sequence {Xn, n ≥ 1} of random variables and
X are defined on the same probability space (Ω, A, P).
(i) If P∞
n=1 P[|Xn − X| ≥ 1/k] < ∞ ∀ k ≥ 1, then Xn
a.s. → X.
(ii) If ∀ n ≥ 1, Xn and X belong to Lr and P∞
n=1 E(Xn − X)
r < ∞, for
some r > 0, then Xn
a.s. → X.
Proof. By Theorem 6.3.1,
∀ k ≥ 1 limn→∞
P
h [
m≥n
[|Xm − X| > 1/k]
i
= 0 ⇒ Xn
a.s. → X.
(i) Note that ∀ k ≥ 1,
limn→∞
P
h [
m≥n
[|Xm − X| > 1/k]
i
≤ limn→∞
X
m≥n
P[|Xm − X| > 1/k] = 0,
it being a remainder term of the convergent series P∞
n=1 P[|Xn − X| ≥ 1/k].
Hence,
X∞
n=1
P[|Xn − X| ≥ 1/k] < ∞ ∀ k ≥ 1 ⇒ Xn
a.s. → X.
(ii) By Markov’s inequality,
P[|Xn − X| > ϵ] ≤ E(Xn − X)
r
/ϵr
⇒
X∞
n=1
P[|Xn − X| ≥ ϵ] ≤
X∞
n=1
E(Xn − X)
r
/ϵr < ∞ ∀ ϵ > 0,
and the result follows from (i).Almost Sure Convergence 265
Remark 6.3.1. If P∞
n=1 P[|Xn − X| ≥ ϵ] < ∞ for all ϵ > 0, then the
sequence {Xn, n ≥ 1} is said to converge completely to a random variable
X. From Corollary 6.3.1, it follows that the complete convergence is stronger
than the almost sure convergence.
Example 6.3.5. As in Example 6.3.4, suppose {Xn, n ≥ 1} is a sequence of
random variables with
P
P[Xn = ±1/n] = 1/2. Thus, |Xn| ≡ 1/n and hence
∞
n=1 E(X2
n
) = P∞
n=1 1/n2 < ∞. Hence, by Corollary 6.3.1 for the almost
sure convergence, Xn
a.s. → 0. □
In Example 6.3.8 also, we illustrate Corollary 6.3.1. In Section 4, we discuss
some more illustrative examples and a different proof of the same corollary as
an application of the Borel-Cantelli lemma.
Example 6.3.6. Suppose {Xn, n ≥ 0} is a branching process with X0 = 1
and offspring mean λ > 0. Then E(Xn) = λ
n. Note that
λ < 1 ⇒
X∞
n=1
E(|Xn|) = X∞
n=1
λ
n < ∞ ⇒ Xn
a.s. → 0 by Corollary 6.3.1.
Thus, if the offspring mean is less than 1, then Xn
a.s. → 0. □
It is well known that the limit of a convergent sequence of real numbers is
unique. On similar lines, the limit random variable in almost sure convergence
is almost surely unique. It is proved in the following theorem.
Theorem 6.3.2. If Xn
a.s. → X and Xn
a.s. → Y , then X and Y are equivalent
random variables, that is, P[X = Y] = 1.
Proof. By the definition
Xn
a.s. → X ⇒ Xn(ω) → X(ω) ∀ ω ∈ N
c
1 where P(N1) = 0
& Xn
a.s. → Y ⇒ Xn(ω) → Y (ω) ∀ ω ∈ N
c
2 where P(N2) = 0.
If N = N1 ∪ N2, then P(N) = 0. Suppose ω ∈ Nc = Nc
1 ∩ Nc
2
. Then
∀ ϵ1 > 0 ∃ n1 ∈ N such that |Xn(ω) − X(ω)| < ϵ1, ∀ n ≥ n1
& ∀ ϵ2 > 0 ∃ n2 ∈ N such that |Xn(ω) − Y (ω)| < ϵ2, ∀ n ≥ n2.
Suppose n0 = max{n1, n2}. Then ∀ n ≥ n0 and ∀ ω ∈ Nc
,
|X(ω) − Y (ω)| = |X(ω) − Xn(ω) + Xn(ω) − Y (ω)|
≤ |Xn(ω) − X(ω)| + |Xn(ω) − Y (ω)| < ϵ1 + ϵ2 .
It is true for all ϵ1 & ϵ2 > 0. Hence, ∀ ω ∈ N, P[|X − Y | > 1/k] = 0 ∀ k ≥ 1
as n → ∞. It then follows that as n → ∞,
P[X ̸= Y ] = P
h [
k≥1
{ω||X(ω) − Y (ω)| > 1/k}
i
≤
X
k≥1
P[|X − Y | > 1/k] = 0,
⇒ P[X = Y ] = 1 ⇒ X = Y a.s.266 Almost Sure Convergence and Borel Zero-One Law
As noted in Section 2, we now prove that almost sure convergence implies
convergence in probability.
Theorem 6.3.3. For a sequence {Xn, n ≥ 1} of random variables,
Xn
a.s. → X ⇒ Xn
P
→ X.
Proof. Suppose Xn
a.s. → X. By the definition of almost sure convergence,
Xn
a.s. → X ⇒ Xn(ω) → X(ω), ∀ ω ∈ N
c
,
such that P(N) = P(
S
k≥1
Dk) = 0, where Dk =
T
n≥1
S
m≥n
[|Xm − X| ≥ 1/k]. As
discussed at the beginning of this section,
Dk =
\
n≥1
[
m≥n
{ω||Xm(ω) − X(ω)| ≥ 1/k}
=
\
n≥1
Bnk where Bnk =
[
m≥n
{ω||Xm(ω) − X(ω)| ≥ 1/k}
= limn→∞
Bnk, as {Bnk, n ≥ 1} is a decreasing sequence
⇒ P(Dk) = P( limn→∞
Bnk)
= limn→∞
P(Bnk) by continuity theorem for probability measures.
Further note that [|Xn − X| ≥ 1/k] ⊂ Bnk. As a consequence,
Xn
a.s. → X ⇒ P(
[
k≥1
Dk) = 0
⇒ P(Dk) = 0 ∀ k ≥ 1
⇒ P( limn→∞
Bnk) = 0, ∀ k ≥ 1
⇒ limn→∞
P(Bnk) = 0, ∀ k ≥ 1
⇒ limn→∞
P[|Xn − X| ≥ 1/k] = 0, ∀ k ≥ 1
⇒ Xn
P
→ X.
Thus almost sure convergence implies convergence in probability.
Remark 6.3.2. In general convergence in probability does not imply almost
sure convergence. It is illustrated in Example 6.4.5, after the discussion of
Borel zero-one law. However, the implication is valid if the sequence
{Xn, n ≥ 1} is a monotone sequence of random variables (Gut [13]).
Following example illustrates that for a monotone sequence of random
variables, convergence in probability implies almost sure convergence.Almost Sure Convergence 267
Example 6.3.7. Suppose (Ω, A, P) is a probability space, where Ω = [0, 1],
A is a sigma field of subsets of Ω and P is a Lebesgue measure.Thus, P(An) =
1/n for An = [0, 1/n). Suppose Xn = IAn
, n ≥ 1. Now ∀ ϵ > 0,
P[|Xn| > ϵ] = P[IAn > ϵ] = P[IAn = 1] = P(An) = 1
n
→ 0 ⇒ Xn
P
→ X ≡ 0.
It is clear that {An, n ≥ 1} is a decreasing sequence of sets and hence is
convergent with limn→∞
An =
T
n≥1
An = ∅. Hence by Theorem 2.3.9
IAn → I∅ on Ω ⇐⇒ Xn → X ≡ 0 on Ω
Thus, Xn converges to 0 point-wise and hence almost surely. It is to be noted
that {Xn, n ≥ 1} is a decreasing sequence. Further observe that for any r > 0,
E(Xr
n
) = 1/n → 0 ⇒ Xn
r→ X ≡ 0. Note that the distribution function Fn
of Xn, given by,
Fn(x) =



0, if x < 0
1 − 1/n, if 0 ≤ x < 1
1, if x ≥ 1.
→ FX(x) = 
0, if x < 0
1, if x ≥ 0.
Thus Fn(x) → FX(x) where FX is the distribution function of X ≡ 0. Hence,
Xn
L
→ X ≡ 0. Thus, in this example we have convergence in probability, in
law, in r-th mean, point-wise convergence and hence almost sure convergence.
□
Almost sure convergence of a sequence of random variables is closed under
arithmetic operations in view of the fact that almost sure convergence is a
point-wise convergence on Nc
. It is proved in the following theorem.
Theorem 6.3.4. Suppose {Xn, n ≥ 1}, X, {Yn, n ≥ 1} and Y are defined on
the same probability space (Ω, A, P). If Xn
a.s. → X and Yn
a.s. → Y , then
(i) Xn ± Yn
a.s. → X ± Y . (ii) XnYn
a.s. → XY . (iii) Xn/Yn
a.s. → X/Y , provided
Xn/Yn and X/Y are defined.
Proof. By definition
Xn
a.s. → X ⇒ Xn(ω) → X(ω) ∀ ω ∈ N
c
1 where P(N1) = 0
and Yn
a.s. → Y ⇒ Yn(ω) → Y (ω) ∀ ω ∈ N
c
2 where P(N2) = 0.
Suppose N = N1 ∪ N2, then P(N) = 0. If ω ∈ Nc = Nc
1 ∩ Nc
2
, then ω ∈ Nc
1
and ω ∈ Nc
2
. Hence for ω ∈ Nc
Xn(ω) ± Yn(ω) → X(ω) ± Y (ω), Xn(ω) × Yn(ω) → X(ω) × Y (ω)
& Xn(ω) /Yn(ω) → X(ω)/Y (ω) .
Thus, the almost sure convergence is closed under arithmetic operations.268 Almost Sure Convergence and Borel Zero-One Law
The next theorem proves that almost sure convergence is closed under
continuous transformation.
Theorem 6.3.5. Suppose Xn
a.s. → X and g : R → R is a continuous function
on R. Then g(Xn)
a.s. → g(X).
Proof. By the definition, Xn
a.s. → X ⇒ P[Xn → X] = 1. Since g is a
continuous function on R, it is a Borel function and hence g(Xn) and g(X)
are random variables on the same probability space. Continuity of g at every
point a ∈ R implies that for every sequence {xn, n ≥ 1} of real numbers, as
n → ∞,
xn → a ⇒ g(xn) → g(a)
⇒ {ω|g(Xn(ω)) → g(X(ω))} ⊃ {ω|Xn(ω) → X(ω)}
⇒ P{ω|g(Xn(ω)) → g(X(ω))} ≥ P{ω|Xn(ω) → X(ω)} = 1
⇒ P{ω|g(Xn(ω)) → g(X(ω))} = 1 ⇒ g(Xn)
a.s. → g(X).
Following example illustrates Corollary 6.3.1, Theorem 6.3.4 and Theorem
6.3.5.
Example 6.3.8. Suppose Xn ∼ B(n, p), 0 < p < 1 and a random variable
Yn is defined as,
Yn =

Xn/n, if Xn ≥ 1
0.001, if Xn = 0.
Note that Yn can be expressed as
Yn = (Xn/n)I[Xn̸=0] + 0.001 × I[Xn=0] = (Xn/n)(1 − Un) + 0.001 × Un.
where Un = I[Xn=0]. Now for 0 < ϵ < 1,
P[|Un| > ϵ] = P[Un = 1] = P[Xn = 0] = q
n
, q = 1 − p
⇒
X
n≥1
P[|Un| > ϵ] = X
n≥1
q
n < ∞
For ϵ ≥ 1, P[|Un| > ϵ] = 0 ⇒
X
n≥1
P[|Un| > ϵ] = 0 < ∞
⇒ Un = I[Xn=0]
a.s. → 0 by Corollary 6.3.1
⇒ 1 − Un = I[Xn̸=0]
a.s. → 1 by Theorem 6.3.5.
Further, if Xn ∼ B(n, p), then the fourth central moment µ4 is given by,Almost Sure Convergence 269
µ4 = 3(npq)
2 + npq(1 − 6pq) (Johnson et al. [14]). Hence,
Xn ∼ B(n, p) ⇒ E

Xn − np
n
4
=
3(npq)
2 + npq(1 − 6pq)
n4
⇒
X∞
n=1
E

Xn − np
n
4
=
X∞
n=1

3(pq)
2
n2
+
pq(1 − 6pq)
n3

< ∞
⇒ Xn/n a.s. → p by Corollary 6.3.1
⇒ (Xn/n)(1 − Un)
a.s. → p by Theorem 6.3.4
⇒ (Xn/n)(1 − Un) + 0.001 × Un
a.s. → p by Theorem 6.3.4
⇒ Yn
a.s. → p.
Suppose Zn is defined as Zn = − log Yn. Then by Theorem 6.3.5,
Zn
a.s. → − log p. If g is any continuous function, then by Theorem 6.3.5,
g(Yn)
a.s. → g(p). □
Remark 6.3.3. It is to be noted that Yn defined in Example 6.3.8, can be
considered as an estimator of p. In Example 6.3.8, it is proved that Yn is a
strongly consistent estimator of p. Further, g(Yn) is also a strongly consistent
estimator of g(p), where g a continuous function.
As in the setup of sequences of real numbers, we have a concept of Cauchy
convergence for a sequence of random variables. We now discuss the Cauchy
criterion of almost sure convergence.
Definition 6.3.1. Almost sure Cauchy convergence: A sequence {Xn, n ≥ 1}
is said to be Cauchy (fundamental) almost surely, if
∀ ω ∈ N
c
, |Xn(ω) − Xm(ω)| → 0 as m, n → ∞, where P(N
c
) = 1.
In the following theorem, we prove that almost sure convergence and al￾most sure Cauchy convergence are equivalent.
Theorem 6.3.6. Suppose a sequence {Xn, n ≥ 1} of random variables and
X are defined on the probability space (Ω, A, P). Then
Xn
a.s. → X ⇐⇒ {Xn, n ≥ 1} is Cauchy a.s.
Proof. Suppose Xn
a.s. → X, then there exists a set N with P(N) = 0 such that
∀ ω ∈ Nc
, Xn(ω) → X(ω) as n → ∞. Hence, ∀ ω ∈ Nc and arbitrary
positive numbers m and n,
|Xn(ω) − Xm(ω)| ≤ |Xn(ω) − X(ω)| + |Xm(ω) − X(ω)| → 0, as n, m → ∞.
Consequently, the sequence {Xn, n ≥ 1} is Cauchy almost surely.
Conversely, assume that the sequence {Xn, n ≥ 1} is Cauchy almost surely.
Thus ∀ ω ∈ Nc
, {Xn(ω), n ≥ 1} is Cauchy sequence of real numbers. Hence,
∃ a unique real number X(ω) such that X(ω) = limn→∞
Xn(ω), ∀ ω ∈ Nc
,
which implies that Xn
a.s. → X.270 Almost Sure Convergence and Borel Zero-One Law
We now derive a necessary and sufficient condition for the Cauchy almost
sure convergence. It is similar to that for almost sure convergence as derived
in Equation (6.2).
Theorem 6.3.7. Suppose {Xn, n ≥ 1} is a sequence of random variables
defined on the probability space (Ω, A, P). Then {Xn, n ≥ 1} is Cauchy a.s. if
and only if
limn→∞
P
h [
m≥n
[|Xm − Xn| > 1/k]
i
= 0 ∀ k ≥ 1 . (6.4)
Proof. By triangular inequality, |Xm − Xn| ≤ |Xm − X| + |Xn − X|. Hence,
∀ k ≥ 1, |Xm − X| ≤ 1/2k & |Xn − X| ≤ 1/2k ⇒ |Xm − Xn| ≤ 1/k.
Thus ∀ k ≥ 1 and ∀ m ≥ n,
\
m≥n
[|Xm − X| ≤ 1/2k] ⊂
\
m≥n
[|Xm − Xn| ≤ 1/k]
⇒ P
h \
m≥n
[|Xm − X| ≤ 1/2k]
i
≤ P
h \
m≥n
[|Xm − Xn| ≤ 1/k]
i
.
Now,
{Xn, n ≥ 1} is Cauchy a.s. ⇐⇒ Xn
a.s. → X
⇐⇒ limn→∞
P
h \
m≥n
[|Xm − X| ≤ 1/2k]
i
= 1
⇐⇒ limn→∞
P
h \
m≥n
[|Xm − Xn| ≤ 1/k]
i
= 1
⇐⇒ limn→∞
P
h [
m≥n
[|Xm − Xn| > 1/k]
i
= 0,
∀ k ≥ 1. The second step follows by (6.2).
In the next section, we revisit almost sure convergence when {Xn, n ≥ 1} is
a sequence of independent random variables. In Corollary 6.3.1 we have proved
that Xn
a.s. → X, if ∀ k ≥ 1,
P∞
n=1 P[|Xn − X| > 1/k] < ∞. If {Xn, n ≥ 1} is
a sequence of independent random variables, converse of this result is true. It
is a consequence of Borel zero-one law, to be discussed in the next section.
6.4 Borel Zero-One Law
Suppose {Xn, n ≥ 1} is a sequence of random variables and An ∈ σ(Xn), n ≥
1. If {Xn, n ≥ 1} is a sequence of independent random variables, thenBorel Zero-One Law 271
{An, n ≥ 1} is a sequence of independent events. Borel zero-one law states that
for a sequence {An, n ≥ 1} of independent events, P(lim sup An) is 0 or 1, de￾pending on whether P∞
n=1 P(An) is a convergent series or a divergent series.
Condition of independence is not needed to prove that P∞
n=1 P(An) < ∞ im￾plies that P(lim sup An) = 0. This result is the famous Borel-Cantelli lemma.
Both Borel zero-one law and Borel-Cantelli lemma are stated in terms of a se￾quence {An, n ≥ 1} of events. For a sequence of random variables {Xn, n ≥ 1},
event An is defined appropriately depending on a particular requirement. We
begin with a simple but frequently used Borel-Cantelli lemma.
Lemma 6.4.1. Borel-Cantelli Lemma: Suppose {An, n ≥ 1} is a sequence of
events defined on (Ω, A, P). If P∞
n=1 P(An) < ∞, then P(lim sup An) = 0.
Proof. By the definition of a limit supremum of a sequence of sets we have,
lim sup An =
\
n≥1
[
k≥n
Ak =
\
n≥1
Cn, where Cn =
[
k≥n
Ak
Further, Cn =
[
k≥n
Ak = An
[
Cn+1 ⇒ Cn ⊇ Cn+1 ⇒ limn→∞
Cn =
\∞
n=1
Cn,
{Cn, n ≥ 1} being a non-increasing sequence of events in A. Now using the
result that a tail of the convergent series converges to 0 we have,
P(lim sup An) = P(
\∞
n=1
[
k≥n
Ak) = P(
\∞
n=1
Cn) = P( limn→∞
Cn) = limn→∞
P(Cn)
= limn→∞
P(
[
k≥n
Ak) ≤ limn→∞
X
k≥n
P(Ak) = 0,
P
k≥n P(Ak) being a tail of the convergent series P∞
n=1 P(An). Thus,
P∞
n=1 P(An) < ∞ ⇒ P(lim sup An) = 0.
Converse of this result is not true in general, it is evident from the following
example.
Example 6.4.1. Suppose the probability space (Ω, A, P) is defined as Ω =
[0, 1], A is a Borel field of subsets of [0, 1] and P is a Lebesgue measure on
(Ω, A). A sequence {An, n ≥ 1} of sets in A is defined as An = [0, 1/n]. It is
clear that {An, n ≥ 1} is a decreasing sequence of events, hence limn→∞ An
exists and is given by,
limn→∞
An = lim sup
n→∞
An =
\∞
n=1
An = {0} ⇒ P(lim sup An) = P({0}) = 0,
but P∞
n=1 P(An) = P∞
n=1
P
1/n is divergent. Thus, P(lim sup An) = 0, but
∞
n=1 P(An) is not finite. □
In Section 3, we have derived two sufficient conditions for the almost sure
convergence. We prove below the same results, using the Borel-Cantelii lemma.272 Almost Sure Convergence and Borel Zero-One Law
Theorem 6.4.1. Suppose {Xn, n ≥ 1} is a sequence of random variables on
(Ω, A, P). Then Xn
a.s. → X, if (i) ∀ ϵ > 0,
X∞
n=1
P[|Xn − X| > ϵ] < ∞ ⇐⇒ ∀ k ≥ 1,
X∞
n=1
P[|Xn − X| > 1/k] < ∞.
(ii)
X∞
n=1
E(|Xn − X|
r
) < ∞ for some r > 0.
Proof. (i) By the Borel-Cantelli lemma,
X∞
n=1
P[|Xn − X| > 1/k] < ∞, ∀ k ≥ 1 ⇒ P[lim sup[|Xn − X| > 1/k] = 0.
Thus by the definition of a limit supremum, ∀ k ≥ 1,
P(Dk) = P
 \
m≥1
[
n≥m
{ω||Xn(ω) − X(ω)| > 1/k}

= 0.
⇒ P(
[
k≥1
Dk) ≤
X
k≥1
P(Dk) = 0.
Hence, ∀ k ≥ 1
P(Dk) = 0 ⇒ P
h [
k≥1
\
m≥1
[
n≥m
{ω||Xn(ω)X(ω)| > 1/k}
i
= 0
⇐⇒ P
h \
k≥1
[
m≥1
\
n≥m
{ω||Xn(ω) − X(ω)| < 1/k}
i
= 1
⇒ Xn
a.s. → X.
(ii) By Markov’s inequality,
P[|Xn − X| > ϵ] ≤ E(|Xn − X|
r
)/ϵr
⇒
X∞
n=1
P[|Xn − X| > ϵ] ≤
X∞
n=1
E(|Xn − X|
r
)/ϵr < ∞
⇒ Xn
a.s. → X by part (i).
Following two examples illustrate how these conditions are useful to estab￾lish almost sure convergence.
Example 6.4.2. Suppose {Yn, n ≥ 1} is a sequence of independent and iden￾tically distributed random variables each having uniform U(0, θ) distribution.Borel Zero-One Law 273
Hence the distribution function Fn(y) of Xn = Y(n) = max{Y1, Y2, · · · , Yn} is
given by,
Fn(y) = (F(y))n =



0, if y < 0
(y/θ)
n, if 0 ≤ y < θ
1, if y ≥ θ.
Note that if ϵ ≥ θ, then P[|Xn − θ| > ϵ] = 0. Suppose ϵ < θ, then
P[|Xn − θ| > ϵ] = 1 − P[θ − ϵ < Xn < θ + ϵ]
= 1 − P[θ − ϵ < Xn < θ]
= 1 − [1 − (θ − ϵ)
n
/θn
]
= (1 − ϵ/θ)
n → 0 as n → ∞ ⇒ Xn
P
→ θ
Further X∞
n=1
P[|Xn − θ| > ϵ] = X∞
n=1
(1 − ϵ/θ)
n < ∞, ∀ ϵ < θ
&
X∞
n=1
P[|Xn − θ| > ϵ] = 0 ∀ ϵ ≥ θ ⇒ Xn
a.s. → θ. □
Example 6.4.3. Suppose {Xn, n ≥ 1} is a sequence of independent and
identically distributed random variables each following normal N(µ, σ2
) dis￾tribution. Then Xn ∼ N(µ, σ2/n) distribution. Hence,
Yn =
￾√
n(Xn − µ)/σ2
∼ χ
2
1
⇒ E(Y
2
n
) = V ar(Yn) + (E(Yn))2 = 2 + 1 = 3
⇒
X∞
n=1
E(|Xn − µ|
4
) = X∞
n=1
3σ
4
/n2 < ∞ ⇒ Xn
a.s. → µ.
Another approach to show that E(Y
2
n
) = 3 is based on the cumulant gener￾ating function. Note that Un =
√
n(Xn − µ)/σ ∼ N(0, 1). Hence, its moment
generating function is exp(t
2/2). As a consequence, its cumulant generating
function is t
2/2 which implies the second cumulant k2 is 1 and the fourth cu￾mulant k4 is 0. Hence µ4 of Un is µ4 = k4+3k
2
2 = 3. Thus, E(Y
2
n
) = E(U
4
n
) = 3.
□
Remark 6.4.1. It is to be noted that in Example 6.4.3, if we take r = 2,
then P∞
n=1 E(|Xn − µ|
2
) = P∞
n=1 σ
2/n, it is not convergent. However, the
sufficient condition states that it is enough to have P∞
n=1 E(|Xn − x|
r
) < ∞
for some r > 0. Here r = 2 does not work but r = 4 works.
The Borel-Cantelli lemma states that if P∞
n=1 P(An) < ∞, then
P(lim sup An) is 0. We have seen in Example 6.4.1 that the converse is not
true in general, but if we impose some additional conditions on An’s, we ge274 Almost Sure Convergence and Borel Zero-One Law
that P∞
n=1 P(An) = ∞ implies that P(lim sup An) = 1. The additional con￾dition requires that the sequence {An, n ≥ 1} is a sequence of independent
events. In Example 6.4.1,
A2 = [0, 1/2], A3 = [0, 1/3] & A2 ∩ A3 = A3
Further, P(A2 ∩ A3) = P(A3) = 1/3 & P(A2)P(A3) = 1/6
⇒ A2 & A3 are not independent.
In general,
m > n ⇒ An ∩Am = [0, 1/m] ⇒ P(An ∩Am) = 1
m
̸=
1
n
1
m
= P(An)P(Am).
Hence, the sequence {An, n ≥ 1} is not a sequence of independent events.
P
In the next example, we note one more scenario of P(lim sup An) and
∞
n=1 P(An).
Example 6.4.4. Suppose {An, n ≥ 1} is a sequence of events such that
An = A for all n ≥ 1 with P(An) = p, 0 < p < 1. Then
limn→∞
An = lim sup
n→∞
An = A ⇒ P(lim sup An) = P(A) = p &
X∞
n=1
P(An) = ∞.
Thus, P(lim sup An) > 0 & P∞
n=1 P(An) = ∞. Note that the sequence
{An, n ≥ 1} is not a sequence of independent events, as all An’s are A and
P(A) ∈ (0, 1). □
In the next theorem, known as Borel zero-one law, it is proved that if
{An, n ≥ 1} is a sequence of independent events then P∞
n=1 P(An) = ∞
implies P(lim sup An) = 1. We require the following two results in the proof.
Result 6.4.1. If {An, n ≥ 1} is a sequence of independent events, then a
sequence obtained by replacing some or all An’s by their complements is also
a sequence of independent events.
Result 6.4.2. For all x ∈ [0, 1], 1−x ≤ e
−x
. To prove this result, we define a
function f(x) as f(x) = 1−x−e
−x
. Note that d
dx f(x) = −1+e
−x
. At x = 0 it
is 0 and for x ∈ (0, 1], e−x < 1. Thus, d
dx f(x) ≤ 0 for x ∈ [0, 1] and hence f(x)
is a decreasing function. Hence, x > 0 ⇒ f(x) ≤ f(0) = 0 ⇒ 1 − x ≤ e
−x
.
Theorem 6.4.2. Borel zero-one law: Suppose {An, n ≥ 1} is a sequence
of independent events. Then P∞
P n=1 P(An) < ∞ ⇒ P(lim sup An) = 0 and
∞
n=1 P(An) = ∞ ⇒ P(lim sup An) = 1.
Proof. Part (i) is the Borel-Cantelli lemma, which we have already proved and
it does not require the assumption of independence. To prove part(ii), noteBorel Zero-One Law 275
that from the proof of Borel-Cantelli lemma,
P(lim sup An) = P(
\
n≥1
[
k≥n
Ak) = P(
\
n≥1
Cn) = P( limn→∞
Cn)
= limn→∞
P(Cn) = limn→∞
P(
[
k≥n
Ak)
Further ω ∈
[
k≥n
Ak ⇐⇒ ω ∈ Am, for at least one m ≥ n
⇐⇒ ω ∈
[m
k=n
Ak, for at least one m ≥ n
⇐⇒ ω ∈
[∞
m=n
[m
k=n
Ak ⇒
[
k≥n
Ak =
[∞
m=n
[m
k=n
Ak.
Observe that
m[
+1
k=n
Ak =
[m
k=n
Ak
[
Am+1 ⇒
n [m
k=n
Ak, m ≥ n
o
is a non-decreasing sequence of events and hence its limit exists. Hence,
lim m→∞
[m
k=n
Ak =
[∞
k=n
Ak =
[∞
m=n
[m
k=n
Ak.
As a consequence,
P (lim sup An) = limn→∞
P
 [
k≥n
Ak

= limn→∞
P
 [∞
m=n
[m
k=n
Ak

= limn→∞
P

lim m→∞
[m
k=n
Ak

= limn→∞
lim m→∞
P
 [m
k=n
Ak

= limn→∞
lim m→∞ h
1 − P
 [m
k=n
Ak
ci
= limn→∞
lim m→∞ h
1 − P
 \m
k=n
A
c
k
i
= limn→∞
lim m→∞ h
1 −
Ym
k=n
P(A
c
k
)
i
by Result 6.4.1
= limn→∞
lim m→∞ h
1 −
Ym
k=n
(1 − P(Ak))i
≥ limn→∞
lim m→∞ h
1 −
Ym
k=n
e
−P (Ak)
i
by Result 6.4.2
= limn→∞
lim m→∞ h
1 − exp 
−
Xm
k=n
P(Ak)
i.276 Almost Sure Convergence and Borel Zero-One Law
Hence,
P (lim sup An) ≥ 1 − exp h
− limn→∞
lim m→∞
Xm
k=n
P(Ak)
i
= 1 − exp h
− limn→∞
gn
i
,
where gn = limm→∞ Pm
k=n P(Ak). Now it is given that P∞
n=1 P(An) = ∞,
hence for each n ≥ 1, gn = ∞, which further implies that limn→∞ gn = ∞.
Hence, P(lim sup An) = 1.
The first part of Borel zero-one law, is known as the first Borel-Cantelli
lemma and the second part of Borel zero-one law is known as the second
Borel-Cantelli lemma (Athreya and Lahiri [3]). Borel zero-one law is useful
in Chapter 9, in the proof of Kolmogorov’s strong law of large numbers.
Borel zero-one law is stated in different words in the following corollaries.
Corollary 6.4.1. For a sequence {An, n ≥ 1} of independent events,
P(lim sup An) = 1 ⇐⇒ X∞
n=1
P(An) = ∞.
Proof. Suppose P∞
n=1 P(An) = ∞. Then P(lim sup An) = 1 follows from part
(ii) of Borel zero-one law. Now suppose P(lim sup An) = 1. We have to prove
that P∞
n=1 P(An) = ∞. We assume the contrary that P∞
n=1 P(An) < ∞. But
then by the Borel-Cantelli lemma P(lim sup An) = 0 which is a contradiction
to the given setup that
P
P(lim sup An) = 1. Thus, if P(lim sup An) = 1, then
∞
n=1 P(An) = ∞.
Corollary 6.4.2. For a sequence {An, n ≥ 1} of independent events,
P(lim sup An) = 0 ⇐⇒ X∞
n=1
P(An) < ∞.
Proof. Suppose P∞
n=1 P(An) < ∞. Then P(lim sup An) = 0 follows from part
(i) of Borel zero-one law. Now suppose P(lim sup An) = 0. We have to prove
that P∞
n=1 P(An) < ∞. We assume the contrary that P∞
n=1 P(An) = ∞. But
then by the Borel zero-one law P(lim sup An) = 1 which is a contradiction
to the given setup that
P
P(lim sup An) = 0. Thus, if P(lim sup An) = 0, then
∞
n=1 P(An) < ∞.
Corollary 6.4.3. Suppose {An, n ≥ 1} is a sequence of independent events
such that An → A as n → ∞. Then (i) P(A) = 0 or 1. (ii) A is independent
of itself.
Proof. Note that
A = limn→∞
An = lim sup
n→∞
An ⇒ P(A) = P(lim sup An).Borel Zero-One Law 277
Further, P∞
n=1 P(An) is either convergent or divergent. Hence, by the Borel
zero-one law,
X∞
n=1
P(An) < ∞ ⇒ P(A) = 0 & X∞
n=1
P(An) = ∞ ⇒ P(A) = 1.
(ii) Since P(A) = 0 or 1 A is independent of itself, as proved in Theorem
5.2.1.
Corollary 6.3.1 states that
∀ k ≥ 1,
X∞
n=1
P[|Xn − X| > 1/k] < ∞ ⇒ Xn
a.s. → X.
Thus, as stated in Remark 6.3.1, if the sequence {Xn, n ≥ 1} converges com￾pletely to a random variable X, then Xn
a.s. → X. In the following theorem, we
prove that the converse of this result is true under the additional condition
that {Xn, n ≥ 1} is a sequence of independent random variables. Thus, for
a sequence of independent random variables complete convergence and the
almost sure convergence are equivalent and we get a necessary and sufficient
condition for the almost sure convergence.
Theorem 6.4.3. Suppose {Xn, n ≥ 1} is a sequence of independent random
variables. Then
Xn
a.s. → 0 ⇐⇒ X∞
n=1
P[|Xn| > 1/k] < ∞ ∀ k ≥ 1
or equivalently, Xn
a.s. → 0 ⇐⇒ X∞
n=1
P[|Xn| > ϵ] < ∞ ∀ ϵ ≥ 0.
Proof. In Corollary 6.3.1, we have already proved that
X∞
n=1
P[|Xn| > 1/k] < ∞ ∀ k ≥ 1 ⇒ Xn
a.s. → 0.
To prove the converse, observe that {Xn, n ≥ 1} is a sequence of independent
random variables implies {σ(Xn), n ≥ 1} is a sequence of independent sigma
fields, that is, for every An ∈ σ(Xn), {An, n ≥ 1} is a sequence of independent
events. In particular, suppose An = [|Xn| > 1/k]. Then by the Borel zero-one
law,
P[lim sup[|Xn| > 1/k]] = 0 ⇒
X∞
n=1
P[|Xn| > 1/k] < ∞ .
As in Section 3, suppose an event Dk is defined as
Dk =
\
n≥1
[
m≥n
{ω||Xm(ω)| ≥ 1/k} = lim sup[|Xn| ≥ 1/k].278 Almost Sure Convergence and Borel Zero-One Law
Now from the definition of almost sure convergence, we have
Xn
a.s. → 0 ⇐⇒ P[Xn ↛ 0] = 0
⇐⇒ P
h [
k≥1
\
n≥1
[
m≥n
[|Xm| ≥ 1/k]
i
= P
h [
k≥1
Dk
i
= 0
⇐⇒ ∀ k ≥ 1 P(Dk) = 0
⇐⇒ ∀ k ≥ 1 P[lim sup[|Xn| ≥ 1/k]] = 0.
Thus,
Xn
a.s. → 0 ⇒ ∀ k ≥ 1, P[lim sup[|Xn| ≥ 1/k]] = 0 ⇒
X∞
n=1
P[|Xn| > 1/k] < ∞.
The result in terms of ϵ follows by noting that for every ϵ > 0, there exists a
positive integer k such that 1/k < ϵ.
Remark 6.4.2. From Theorem 6.4.3, we note that for a sequence {Xn, n ≥ 1}
of independent random variables, if P∞
n=1 P[|Xn| > ϵ] = ∞ ∀ ϵ ≥ 0 then
Xn
a.s. ↛ 0, since Xn
a.s. → 0 ⇒
P∞
n=1 P[|Xn| > ϵ] < ∞.
The next example illustrates Remark 6.4.2. It also shows that convergence
in probability does not imply almost sure convergence.
Example 6.4.5. Suppose {Xn, n ≥ 1} is a sequence of independent random
variables such that P[Xn = 1] = 1/n and P[Xn = 0] = 1 − 1/n. Suppose
X ≡ 0. Observe that ∀ ϵ > 0,
P[|Xn| > ϵ] = P[Xn = 1] = 1/n → 0 ⇒ Xn
P
→ 0.
However, X∞
n=1
P[|Xn| > ϵ] = X∞
n=1
1/n = ∞ ⇒ Xn
a.s. ↛ 0,
by Theorem 6.4.3. □
Following example also illustrates Remark 6.4.2 and various modes of con￾vergence.
Example 6.4.6. Suppose in an experiment consisting of independent re￾peated tosses of a coin, an event An occurs if the n-th toss results in a head.
Suppose P(An) = p ∈ (0, 1). A random variable Xn is defined as Xn = IAn
.
Thus possible values of Xn are 0 and 1 with probabilities 1 − p and p respec￾tively. Note that ∀ ω ∈ Ω
lim inf
n→∞
Xn(ω) = 0 & lim sup
n→∞
Xn(ω) = 1 ⇒ limn→∞
Xn(ω) does not exist.
Thus Xn does not converge pointwise. Further, note that in view of inde￾pendence of tosses, {An, n ≥ 1} is a sequence of independent events andBorel Zero-One Law 279
{Xn, n ≥ 1} is a sequence of independent random variables. If the coin is fair,
P(An) = 1/2. By Borel zero-one law,
P(An) = 1/2 ∀ n ⇒
X∞
n=1
P(An) = ∞ ⇒ P(lim sup An) = 1
⇒ P[Xn = 1 infinitely often] = 1
P(A
c
n
) = 1/2 ∀ n ⇒
X∞
n=1
P(A
c
n
) = ∞ ⇒ P(lim sup A
c
n
) = 1
⇒ P[Xn = 0 infinitely often] = 1.
Thus, with probability 1, the sequence Xn oscillates between 0 and 1. Suppose
now that the coin is not fair and
P
P(An) = p ∈ (0, 1). In this setup also
∞
n=1 P(An) = ∞ and hence P(lim sup An) = 1. Similarly, P∞
n=1 P(Ac
n
) = ∞
and hence P(lim sup Ac
n
) = 1. It is to be noted that however small p may be,
probability that head will occur infinitely often is 1 and probability that tail
will occur infinitely often is 1. Observe that ∀ ϵ > 0,
P[|Xn| > ϵ] = P[Xn = 1] = P(An) = p ↛ 0 ⇒ Xn
P↛ 0
P[|Xn − 1| > ϵ] = P[Xn = 0] = P(A
c
n
) = 1 − p ↛ 0 ⇒ Xn
P↛ 1
X
n≥1
P[|Xn| > ϵ] = ∞ ⇒ Xn
a.s ↛ 0
X
n≥1
P[|Xn − 1| > ϵ] = ∞ ⇒ Xn
a.s ↛ 1
E(|Xn|
r
) = p ↛ 0 ⇒ Xn
r↛ 0
E(|Xn − 1|
r
) = 1 − p ↛ 0 ⇒ Xn
r↛ 1.
Note that the distribution function Fn(·) of Xn is given by,
Fn(x) =



0, if x < 0
1 − p, if 0 ≤ x < 1
1, if x ≥ 1.
Observe that Fn(·) is the same ∀ n ≥ 1 and hence Fn(x) → F(x) ∀ x ∈ R,
where F is the same as Fn. Thus, Xn
L
→ X, where the distribution function of
X is F. Thus, Xn does not converge pointwise, completely, almost surely, in
probability or in r-th mean to either 0 or 1, but converges in law, which is the
weakest mode of convergence. It is to be noted that if P(An) = c/n2
, n ≥ 1,
where c = (P
n≥1
1/n2
)
−1
, then Xn converges completely, almost surely, in
probability and in r-th mean to 0. □
Remark 6.4.3. In Section 3, we have shown that Xn
a.s. → X implies that
P[lim sup[|Xn − X| ≥ 1/k]] = P[|Xn − X| ≥ 1/k, infinitely often] = 0.280 Almost Sure Convergence and Borel Zero-One Law
Thus, almost sure convergence is concerned with lim sup An where An is de￾fined as An = [|Xn − X| ≥ 1/k]. In Section 2.3, we have noted that for point￾wise convergence, lim sup Xn, lim inf Xn and lim Xn, whenever it exists, are
tail events. Almost sure convergence is a point-wise convergence on a set with
probability 1. Borel zero-one law states that for a sequence of independent
events P(lim sup An) = 0 or 1, where lim sup An is a tail event. Thus, Borel
zero-one law and its corollaries have relation with Kolmogorov zero-one law,
proved in Section 5.4. However, Borel zero-one law gives a precise criterion for
P(lim sup An) to be 0 or 1 and its proof is comparatively more simple.
Following examples support the comments in Remark 6.4.3.
Example 6.4.7. Suppose {An, n ≥ 1} is a sequence of independent events.
Then {IAn
, n ≥ 1} is a sequence of independent random variables. Hence,
lim sup IAn
, lim inf IAn
and lim IAn
, if it exists, are tail measurable random
variables and hence by Kolmogorov zero-one law, are degenerate random vari￾ables. It is known that,
lim sup IAn = Ilim sup An
, lim inf IAn = Ilim inf An & lim IAn = Ilim An
.
Hence, Ilim sup An
is either 0 almost surely or 1 almost surely, which implies
that P(lim sup An) is either 0 or 1. Similarly, P(lim inf An) is 0 or 1 and
P(lim An) is 0 or 1, if lim An exists. Thus, the probabilities of tail events are
either 0 or 1. Borel zero-one law gives a criterion for P(lim sup An) to be 0 or
1. □
Example 6.4.8. Suppose {An, n ≥ 1} is a sequence of events. From Borel￾Cantelli lemma,
X∞
n=1
P(An) < ∞ ⇒ P(lim sup An) = 0
⇒ P(lim inf An) = 0, as lim inf An ⊂ lim sup An.
Similarly,
X∞
n=1
P(A
c
n
) < ∞ ⇒ P(lim sup A
c
n
) = 0
⇒ P((lim inf An)
c
) = 0, ⇒ P(lim inf An) = 1.
However, both P∞
n=1 P(An) and P∞
n=1 P(Ac
n
) cannot be convergent, since if
both are convergent then their sum which is a series of constant 1 will be con￾vergent. Thus, if P∞
n=1 P(An) < ∞ then P∞
n=1 P(Ac
n
) = ∞. If {An, n ≥ 1}
is a sequence of independent events, then {Ac
n
, n ≥ 1} is also a sequence of
independent events and hence P(lim sup Ac
n
) = 1 ⇒ P(lim inf An) = 0. It is
to be noted that lim sup An and lim inf An are tail events and their probabil￾ities are 0 or 1, supporting Kolmogorov zero-one law. In particular, supposeBorel Zero-One Law 281
P(An) = 1/n2
, then P∞
n=1 P(An) < ∞ and hence P(lim sup An) = 0. How￾ever, P∞
n=1 P(Ac
n
) = ∞. Suppose {An, n ≥ 1} is a sequence of independent
events with P(An) = 1/2. Then both P∞
n=1 P(An) and P∞
n=1 P(Ac
n
) are di￾vergent. Hence, by Borel zero-one law
P(lim sup An) = 1 & P(lim sup A
c
n
) = 1 ⇒ P(lim inf An) = 0
and again the probabilities of tail events are 0 or 1. It is to be noted here that
P(lim sup An) = 1 & P(lim inf An) = 0 and hence lim sup An ̸= lim inf An
and hence lim An does not exist. □
The next example illustrates an application of the Borel-Cantelli lemma
in asymptotic inference.
Example 6.4.9. Suppose X ∼ N(θ, 1) distribution, where θ ∈ Θ = I, a set of
integers. It can be shown that (Deshmukh and Kulkarni [11]), the maximum
likelihood estimator ˆθn of θ is given by,
ˆθn = k if Xn ∈ [k − 1/2, k + 1/2), where k ∈ I.
ˆθn can also be expressed as ˆθn = [Xn+1/2], integer part of Xn+1/2. Using the
sufficient condition (i) of almost sure convergence as given in Theorem 6.4.1,
we examine whether ˆθn
a.s. → θ. We first find the probability mass function of
ˆθn as follows. Suppose Φ(·) denotes the distribution function of the standard
normal distribution. For k ∈ I,
Pθ[
ˆθn = θ] = Pθ[θ − 1/2 ≤ Xn < θ + 1/2]
= Φ(√
n(θ + 1/2 − θ)) − Φ(√
n(θ − 1/2 − θ))
= Φ(√
n/2) − Φ(−
√
n/2)
= 1 − 2Φ(−
√
n/2) ∀ θ ∈ I.
It is to be noted that the probability mass function of ˆθn is the same for all
θ ∈ I. To examine the convergence of the series P
n≥1 Pθ[|
ˆθn − θ| > ϵ], we
approximate the expression of Pθ[
ˆθn = θ] as follows. We use the result that
for x > 0 and sufficiently large, Φ(−x) = ϕ(−x)/x, where ϕ(·) denotes the
probability density function of the standard normal distribution. With such a
relation we have,
Pθ[
ˆθn ≠ θ] = 2Φ(−
√
n/2) = 2ϕ
￾√
n/2

(2/
√
n) = (4/
√
2π)(e
−n/8
/
√
n)
⇒
X
n≥1
Pθ[
ˆθn ̸= θ] = (4/
√
2π)
X
n≥1
(e
−n/8
/
√
n) < ∞
⇒
X
n≥1
Pθ[|
ˆθn − θ| > ϵ] ≤
X
n≥1
Pθ[
ˆθn ≠ θ] < ∞, ∀ ϵ > 0282 Almost Sure Convergence and Borel Zero-One Law
Convergence of the series follows from the ratio test. Thus, ˆθn → θ completely
and hence by the sufficient condition of almost sure convergence as given in
Theorem 6.4.1, ˆθn
a.s. → θ.
Suppose an event An is defined as An = {ω|
ˆθn(ω) ≠ θ}, then P
n≥1 P(An) <
∞. Now by the Borel-Cantelli lemma,
X
n≥1
P(An) < ∞ ⇒ P(lim sup An) = 0 ⇐⇒ P(lim inf A
c
n
) = 1
⇒ Pθ{ω|
ˆθn(ω) = θ, ∀ n ≥ n0(ω)} = 1. □
In Example 6.4.9, we have noted that for large n,
ˆθn = θ almost surely.
In the next example using Code 6.4.1, we find ˆθn for various values of n and
examine whether it remains the same after a stage. We also find n0 for which
the series P
n≥1 Pθ[
ˆθn ≠ θ] stabilizes.
Example 6.4.10. Suppose X ∼ N(θ, 1) distribution, where θ ∈ Θ = I. In
Example 6.4.9, we have noted that ˆθn = [Xn + 1/2]. Using the following code,
we find ˆθn for various values of n by simulating random samples from N(θ, 1).
We take θ = −2.
Code 6.4.1. th=-2; mle=p=c(); n=c(10,30,50,70,90,110,130,150)
for(i in 1:length(n))
{
x=rnorm(n[i],th,1)
mle[i]=floor(mean(x)+.5)
p[i]=2*pnorm(-.5*n[i]^(.5))
}
d=round(data.frame(n,mle,p),4);d
# Using the following code, we compute the series
# and note when it stabilizes.
p=function(n)
{
a=c()
for(k in 1:n){a[k]=2*pnorm(-.5*k^(.5))}
p=sum(a);return(p)
}
N=seq(50,150,20); s=c()
for(j in N){s[j]=p(j)}
s1=s[N];d=round(data.frame(N,s1),4);d
The output from data frame d is organized in Table 6.2. From Table 6.2,
we note that for all n, even for n = 10,
ˆθn = θ = −2. The third row displays
Pθ[
ˆθn ≠ θ] and we observe that for n > 50 it is almost 0.Borel Zero-One Law 283
TABLE 6.2
MLE of θ for N(θ, 1) Distribution, θ ∈ I
n 10 30 50 70 90 110 130 150
ˆθn -2 -2 -2 -2 -2 -2 -2 -2
Pθ[
ˆθn ̸= θ] 0.1138 0.0062 0.0004 0 0 0 0 0
TABLE 6.3
P
N
n=1
Pθ[
ˆθn ̸= θ]
N 50 70 90 110 130 150
P
N
n=1
Pθ[
ˆθn ̸= θ] 3.5796 3.5823 3.5825 3.5825 3.5825 3.5825
Table 6.3 displays the values of the convergent series P
n≥1 Pθ[
ˆθn ̸= θ].
Note that it stabilizes at 3.5825 for n = 90. Such a computation reveals that
the estimator ˆθn is a good estimator, in the sense that its value will be very
close to the value of θ which generated the sample. □
Following is a quick recap of the results discussed in this chapter.
Summary
1. Almost sure convergence: Xn
a.s. → X, if as n → ∞, Xn(ω) → X(ω)
∀ ω ∈ Nc
, such that P(N) = 0.
2. Convergence in probability: Xn
P
→ X, if ∀ ϵ > 0, P[|Xn − X| < ϵ] → 1
as n → ∞.
3. Convergence in law: Xn
L
→ X, if Fn(x) = P[Xn ≤ x] → P[X ≤ x] =
F(x), ∀ x ∈ C(FX), where C(FX) is a set of points of continuity of the
distribution function of X.
4. Convergence in r-th mean: Xn
r→ X if E(|Xn − X|
r
) → 0 as n → ∞,
r > 0, where ∀ n ≥ 1, Xn & X ∈ Lr space. If r = 2 then the convergence
is referred to as convergence in quadratic mean.
5. For almost sure convergence, a sequence {Xn, n ≥ 1} of random variables
and X are defined on the same probability space.
6. For almost sure convergence, convergence and Cauchy convergence are
equivalent.
7. Xn
a.s. → X if and only if limn→∞ P
h S
m≥n
[|Xm−X| > 1/k]
i
= 0 ∀ k ≥ 1 .
8. Xn
a.s. → X if (i) P∞
P n=1 P[|Xn − X| ≥ 1/k] < ∞ ∀ k ≥ 1 or (ii) if
∞
n=1 E(Xn − X)
r < ∞ for some r > 0, where ∀ n ≥ 1, Xn & X ∈ Lr.284 Almost Sure Convergence and Borel Zero-One Law
9. In almost sure convergence, the limit random variable is almost surely
unique.
10. Xn
a.s. → X ⇒ Xn
P
→ X.
11. Xn
P
→ X ⇐⇒ Xn
a.s. → X if the sequence {Xn, n ≥ 1} is monotone.
12. Almost sure convergence is closed under arithmetic operations.
13. Almost sure convergence is closed under continuous transformation.
14. Borel-Cantelli lemma: Suppose {An, n ≥ 1} is a sequence of events defined
on (Ω, A, P). If P∞
n=1 P(An) < ∞ then P(lim sup An) = 0.
15. Borel zero-one law: Suppose {An, n ≥ 1} is a sequence of independent
events. (i) If P∞
n=1 P(An) < ∞, then P(lim sup An) = 0.
(ii) If P∞
n=1 P(An) = ∞, then P(lim sup An) = 1.
16. For a sequence {An, n ≥ 1} of independent events, P(lim sup An) = 1,
if and only if P∞
P n=1 P(An) = ∞ and P(lim sup An) = 0, if and only if
∞
n=1 P(An) < ∞.
17. Suppose {An, n ≥ 1} is a convergent sequence of independent events such
that
P
An → A as n → ∞. Then P(A) = 0 or 1 according as
∞
n=1 P(An) < ∞ or P∞
n=1 P(An) = ∞.
18. Suppose {Xn, n ≥ 1} is a sequence of independent random variables. Then
Xn
a.s. → 0 ⇐⇒ X∞
n=1
P[|Xn| > 1/k] < ∞ ∀ k ≥ 1.
6.5 Conceptual Exercises
6.5.1 Suppose {Xn, n ≥ 1} is a sequence of random variables such that
P[Xn = ±n] = 1/2. Examine if Xn
a.s. → 0.
6.5.2 Suppose {Xn, n ≥ 1} is a sequence of random variables defined on the
probability space (Ω, A, P) where Ω = [0, 1], A is a sigma field of subsets
of [0, 1] and P((a, b)) = b − a for (a, b) ∈ A. Suppose {Xn} is defined as
Xn(ω) = 
1, if 0 ≤ ω < (n + 1)/2n
0, otherwise.
X is a random variable defined as X(ω) = 1 if 0 ≤ ω < 1/2 and 0
otherwise. Examine whether Xn
a.s. → X.Conceptual Exercises 285
6.5.3 Suppose {Xn, n ≥ 1} is a sequence of continuous random variables with
support [−1/n, 1/n] and with probability density function given by,
fXn
(x) = 
n/2, if x ∈ [−1/n, 1/n]
0, if x /∈ [−1/n, 1/n].
Examine whether the sequence {Xn, n ≥ 1} converges almost surely.
6.5.4 Suppose Xn ∼ G(n, n). Examine if Xn
a.s. → 1.
6.5.5 Suppose Xn
a.s. → X. Show that lim inf Xn and lim sup Xn are equivalent
random variables.
6.5.6 Suppose (Ω, A, P) is a probability space, where Ω = [0, 1], A is a sigma
field of subsets of Ω and P is a Lebesgue measure on (Ω, A). Suppose
An = [1/n, 1] and Xn = IAn
, n ≥ 1. Examine whether Xn converges
point-wise, almost surely and in probability to 1. Examine whether
{Xn, n ≥ 1} is a monotone sequence of random variables.
6.5.7 Suppose {Xn, n ≥ 1} is a sequence of random variables. If Xn
a.s. → 0,
show that Xn
a.s. → 0.
6.5.8 Suppose (Ω, A, P) is a probability space where Ω = {1, 2, · · · , } and
probability measure P assigns probability 1/(k(k + 1)) to a set {k}, k =
1, 2, · · · .
(i) Define A appropriately so that sets {k}, k = 1, 2, · · · , are in A. If
An = {n, n + 1, · · · }, show that it is in A. (ii) Find P(An) and
limn→∞ P(An). (iii) Show that {An, n ≥ 1} is a convergent sequence
and find its limit A and P(A). (iv) Verify whether converse of the Borel￾Cantelli lemma is true for this sequence of sets. If not, why? Justify your
answer.
6.5.9 If {An, n ≥ 1} is a sequence of independent events converging to A,
prove that A is independent of itself.
6.5.10 Prove or disprove: If P
n≥1 P(An) < ∞ then P(lim inf An) = 0.
6.5.11 Suppose (Ω, A, P) is a probability space and {An, n ≥ 1} is a sequence
of independent events from A such that P(An) < 1 ∀ n ≥ 1. Show that
(i) P(
Sn
i=1 Ai) = 1 −
Qn
i=1(1 − P(Ai)),
(ii) P(
Sn
i=1 Ai) ≥ 1 − exp(−
Pn
i=1 P(Ai)),
(iii) P
n≥1 P(An) = ∞ ⇒ P(
S
n≥1 An) = 1 and
(iv) P(lim sup An) = 1 ⇐⇒ P(
S
n≥1 An) = 1 .
6.5.12 Suppose (Ω, A, P) is a probability space and {An, n ≥ 1} is a sequence
of independent events from A. If P
n≥1 P(A ∩ An) = ∞ for any A ∈ A
such that P(A) > 0, then show that P(lim sup An) = 1.286 Almost Sure Convergence and Borel Zero-One Law
6.6 Computational Exercises
6.6.1 Suppose a probability space (Ω, A, P) is defined as Ω = [0, ∞) and A
is a sigma field of subsets of Ω. Suppose a sequence {Xn, n ≥ 1} of A
measurable random variables and a A measurable random variable X
are defined as follows.
Xn(ω) = exp(−nω), n ≥ 1 & X(ω) = 0 ∀ ω ∈ Ω.
(i) Examine graphically if Xn
a.s. → X, if P({0}) = 0 and P({0}) > 0.
6.6.2 Suppose X ∼ N(θ, 1) distribution, where θ ∈ Θ = [2, 7]. Find the
maximum likelihood estimator ˆθn for various values of n and examine
whether it remains the same after a stage. Also find n0 for which the
series P
n≥1 Pθ[
ˆθn ̸= θ] stabilizes.
6.7 Multiple Choice Questions
Note: In each of the questions, multiple options may be correct. Unless spec￾ified otherwise, identify which of the statement(s) is/are correct. Answers are
given in Chapter 11, after the solutions of conceptual exercises of Chapter 6.
6.7.1 Xn
a.s. → X implies
(a) P[lim sup[|Xn − X| ≥ 1/k]] = 0
(b) P[lim sup[|Xn − X| ≥ 1/k]] = 1
(c) P[lim inf[|Xn − X| ≥ 1/k]] = 0
(d) P[lim inf[|Xn − X| ≥ 1/k]] = 1
6.7.2 Xn
a.s. → X implies
(a) P[lim inf[|Xn − X| < 1/k]] = 1
(b) P[lim inf[|Xn − X| < 1/k]] = 0
(c) P[lim sup[|Xn − X| < 1/k]] = 1
(d) P[lim sup[|Xn − X| < 1/k]] = 0
6.7.3 Xn
a.s. → X if
(a) P∞
n=1 P[|Xn − X| ≥ 1/k] = ∞ ∀ k ≥ 1
(b) P∞
n=1 P[|Xn − X| ≥ 1/k] < ∞ ∀ k ≥ 1
(c) P∞
n=1 P[|Xn − X| ≤ 1/k] < ∞ ∀ k ≥ 1
(d) P∞
n=1 P[|Xn − X| ≤ 1/k] = ∞ ∀ k ≥ 1Multiple Choice Questions 287
6.7.4 Suppose for all n ≥ 1, Xn and X belong to Lr, then a sufficient condition
for Xn
a.s. → X is P∞
n=1
E(Xn − X)
r < ∞. Following are two statements.
(I) The condition should be satisfied for all r > 0. (II) It is enough if
the condition is satisfied for some r > 0.
(a) Both (I) and (II) are true
(b) Both (I) and (II) are false
(c) (I) is true but (II) is false
(d) (I) is false but (II) is true
6.7.5 Suppose {An, n ≥ 1} is a sequence of events on a probability space
(Ω, A, P). Then
(a) P(lim sup An) = 0 ⇒
P
n≥1 P(An) < ∞
(b) P(lim sup An) = 1 ⇒
P
n≥1 P(An) = ∞
(c) P
n≥1 P(An) < ∞ ⇒ P(lim sup An) = 0
(d) P
n≥1 P(An) = ∞ ⇒ P(lim sup An) = 1
6.7.6 Suppose {An, n ≥ 1} is a sequence of events on a probability space
(Ω, A, P). Then
(a) P(lim sup An) = 0 ⇒
P
n≥1 P(An) < ∞
(b) P(lim sup An) = 1 ⇒
P
n≥1 P(An) = ∞
(c) P
n≥1 P(An) < ∞ ⇒ P(lim inf An) = 0
(d) P
n≥1 P(An) = ∞ ⇒ P(lim inf An) = 1
6.7.7 Suppose {An, n ≥ 1} is a sequence of independent events on a probabil￾ity space (Ω, A, P). Then
(a) P(lim sup An) = 0 ⇒
P
n≥1 P(An) < ∞
(b) P(lim sup An) = 1 ⇒
P
n≥1 P(An) = ∞
(c) P
n≥1 P(An) < ∞ ⇒ P(lim sup An) = 0
(d) P
n≥1 P(An) = ∞ ⇒ P(lim sup An) = 1
6.7.8 Suppose {An, n ≥ 1} is a sequence of independent events on a probabil￾ity space (Ω, A, P). Then
(a) P(lim sup An) = 0 ⇒
P
n≥1 P(An) < ∞
(b) P(lim inf An) = 1 ⇒
P
n≥1 P(An) = ∞
(c) P
n≥1 P(An) < ∞ ⇒ P(lim inf An) = 0
(d) P
n≥1 P(An) = ∞ ⇒ P(lim sup An) = 17
Convergence in Probability, in Law and
in r-th Mean
7.1 Introduction
Suppose {Xn, n ≥ 1} is a sequence of random variables defined on a probabil￾ity space (Ω, A, P). In Chapter 6, we defined different modes of convergence
and discussed almost sure convergence in detail and studied Borel zero-one
law. The present chapter is devoted to the remaining three modes of conver￾gence, namely, convergence in probability, convergence in law and convergence
in r-th mean. In all these modes of convergence, except convergence in law,
it is assumed that a sequence {Xn, n ≥ 1} of random variables and the limit
random variable X are defined on the same probability space (Ω, A, P).
In large sample inference, the weak consistency of an estimator is defined
in terms of convergence in probability. A sequence of estimators {Tn, n ≥ 1} of
a parameter θ, is said to be consistent for θ if Tn →
Pθ
θ, ∀ θ ∈ Θ as n → ∞. The
weak law of large numbers, which we discuss in Chapter 9, is also concerned
with convergence in probability. In the next section, we study some of its
properties and illustrate with conceptual as well as numerical examples using
R.
7.2 Convergence in Probability
We have already defined convergence in probability in Section 6.2. However,
for ready reference, it is given below.
Definition 7.2.1. Convergence in probability: Xn
P
→ X, if
∀ ϵ > 0, limn→∞
P[|Xn − X| < ϵ] = 1 ⇐⇒ limn→∞
P[|Xn − X| ≥ ϵ] = 0,
or equivalently, given
δ > 0 & k ≥ 1, ∃ n0(δ, k) such that ∀ n ≥ n0(δ, k), P[|Xn−X| > 1/k] < δ.
DOI: 10.1201/9781032619057-7 288Convergence in Probability 289
We begin with some examples to illustrate the concept of convergence in
probability.
Example 7.2.1. If {An, n ≥ 1} is a sequence of events such that P(An) → 0,
then for any real random variable X and for all ϵ > 0,
P[|XIAn
| > ϵ] ≤ P[IAn = 1] = P(An) → 0 ⇒ XIAn
P
→ 0. □
Example 7.2.2. Suppose as in Example 6.3.1, the probability space (Ω, A, P)
is defined as follows. Ω = [0, 1], A is sigma field of subsets of Ω and for
A = (a, b) ⊆ [0, 1], P(A) = b−a. Suppose a random variable X and a sequence
of random variables {Xn, n ≥ 1} are defined as Xn(ω) = e
ω + ω
n, n ≥ 1 and
X(ω) = e
ω. In Example 6.3.1, we have noted that the sequence of random
variables {Xn, n ≥ 1} does not converge point-wise to X but Xn
a.s. → X with
{1} as a P-null set. In Section 6.3, it is proved that almost sure convergence
implies convergence in probability. Thus, Xn
P
→ X. We now examine it using
the definition of convergence in probability. Observe that
P[|Xn − X| < ϵ] = P[|ω
n
| < ϵ] = P[ω
n < ϵ] = 
1, if ϵ > 1
ϵ
1/n → 1, if ϵ ≤ 1.
Hence, Xn
P
→ X as n → ∞. □
In the following example, we compute P[|Xn − X| < ϵ] = ϵ
1/n for some
values of ϵ ≤ 1 and some values of n and examine its nature as ϵ changes and
as n increases.
Example 7.2.3. In Example 7.2.2, we have discussed convergence in proba￾bility and has shown that P[|Xn − X| < ϵ] = ϵ
1/n. We use the following code
to compute these values for some values of ϵ.
Code 7.2.1. Values of ϵ are specified in a variable epvec and values of n are
specified in a variable nvec. The values ϵ
1/n are stored in a matrix probmat.
prob=function(epsilon,n)
{
pr=epsilon^(1/n)
return(pr)
}
epvec=c(0.01,0.05,0.1,0.5); epl=length(epvec)
nvec=c(100,200,400,800,1000)
nn=length(nvec); probmat=matrix(nrow=nn,ncol=epl)
for(i in 1:nn)
{
for(j in 1:epl)290 Convergence in Probability, in Law and in r-th Mean
{
n=nvec[i]
ep=epvec[j]
probmat[i,j]=prob(ep,n)
}
}
P=round(probmat,4);P
plot(nvec,probmat[,1],type="o",lwd=2,xlab="n",ylab=
"Probability",
ylim=c(.95,1),pch=20)
for(i in 2:epl)
{
lines(nvec,probmat[,i],type="o",lwd=2,lty=i,col=i,pch=20)
}
legend("bottomright",legend=c(epvec[1],epvec[2],epvec[3],
epvec[4]),
lty=1:epl,col=1:epl,lwd=2,title=expression(paste(epsilon)))
Table 7.1 displays the values of P[|Xn − X| < ϵ] for four values of ϵ and
five values of n.
TABLE 7.1
P[|Xn − X| < ϵ] for Given n and ϵ
❍
n
❍❍❍❍
ϵ
0.01 0.05 0.1 0.5
100 0.9550 0.9705 0.9772 0.9931
200 0.9772 0.9851 0.9886 0.9965
400 0.9886 0.9925 0.9943 0.9983
800 0.9943 0.9963 0.9971 0.9991
1000 0.9954 0.9970 0.9977 0.9993
From Table 7.1, we observe that for ϵ = 0.5, P[|Xn − X| < ϵ] is 0.9931
for n = 100 while for ϵ = 0.01, P[|Xn − X| < ϵ] is 0.9954 for n = 1000.
Thus, the rate of convergence depends on ϵ, as is expected. As n increases,
the probabilities increase to 1, supporting the conclusion that Xn
P
→ X as
n → ∞. Figure 7.1 also conveys these features. It is to be noted that even for
n = 200, P[|Xn − X| < ϵ] is close to 99%, except for ϵ = 0.01. □
Example 7.2.4. Suppose {X1, X2, · · · , Xn} are independent and identically
distributed random variables each having Cauchy C(θ, 1) distribution, with
location parameter θ ∈ R and scale parameter 1. The common characteristic
function ϕ(t) of Yi − θ is given by, ϕ(t) = exp{−|t|}. Hence the character￾istic function ϕn(t) of Y n = Xn − θ is given by, ϕn(t) = exp{n(−|t/n|)} =Convergence in Probability 291
FIGURE 7.1
Convergence in Probability of Xn = e
ω + ω
n to X = e
ω
exp{−|t|}. Thus, Xn = Y n + θ follows the Cauchy distribution with location
parameter θ and scale parameter 1. Hence for any ϵ > 0,
P[|Xn − θ| < ϵ] = Z θ+ϵ
θ−ϵ
1
π
1
1 + (x − θ)
2
dx =
1
π

tan−1
(x − θ)
θ+ϵ
θ−ϵ
= 2 tan−1
(ϵ)/π .
It is free from n and hence does not converge to 1 as n → ∞. Hence, Xn
P↛ θ.
□
Example 7.2.5. Suppose {X1, X2, · · · , Xn} are independent and identi￾cally distributed random variables each having uniform U(0, 1) distribu￾tion. Suppose {X(1), X(2), · · · , X(n)} is the corresponding order statistics. If
X ∼ U(0, 1), then its distribution function FX(x) is given by,
FX(x) =



0, if x < 0
x, if 0 ≤ x < 1
1, if x ≥ 1.
Note that, being Borel functions of {X1, X2, · · · , Xn}, Yn = X(1) and Zn =
X(n) are also random variables. We now discuss the convergence in probability
of Yn and Zn. The distribution functions FYn
(x) of Yn and FZn
(x) of Zn are
given by,
FYn
(x) =



0, if x < 0
1 − (1 − x)
n, if 0 ≤ x < 1
1, if x ≥ 1
& FZn
(x) =



0, if x < 0
x
n, if 0 ≤ x < 1
1, if x ≥ 1.292 Convergence in Probability, in Law and in r-th Mean
Observe that,
if ϵ > 1, P[|X(1)| < ϵ] = P[−ϵ < X(1) < ϵ] = P[0 < X(1) < ϵ] = 1
& if ϵ ≤ 1, P[|X(1)| < ϵ] = P[0 < X(1) < ϵ] = FX(1) (ϵ)
= 1 − (1 − ϵ)
n → 1 ⇒ X(1)
P
→ 0.
Further if ϵ > 1, P[|X(n) − 1| < ϵ] = P[1 − ϵ < X(n) < 1 + ϵ]
= P[1 − ϵ < X(n) < 1] = 1.
If ϵ ≤ 1, P[|X(n) − 1| < ϵ] = P[1 − ϵ < X(n) < 1]
= FX(n)
(1) − FX(n)
(1 − ϵ)
= 1 − (1 − ϵ)
n → 1 ⇒ X(n)
P
→ 1.
Thus, if X ∼ U(0, 1), then X(1)
P
→ 0 and X(n)
P
→ 1. We now examine
whether X(1)
P
→ a for any a which is close to 0. Suppose we take a = 0.01.
Observe that for ϵ < 0.01,
P[|X(1) − 0.01| < ϵ] = P[0.01 − ϵ < X(1) < 0.01 + ϵ]
= 1 − (1 − 0.01 − ϵ)
n − 1 + (1 − 0.01 + ϵ)
n
= (0.99 + ϵ)
n − (0.99 − ϵ)
n → 0 ⇒ X(1)
P↛ 0.01,
since there are some values of ϵ for which P[|X(1) − 0.01| < ϵ] ↛ 1. By the
definition of convergence in probability, Xn
P
→ X if P[|Xn − X| < ϵ] → 1
for all ϵ > 0. On similar lines it can be shown that X(1)
P↛ a ̸= 0.
Similarly, we examine whether X(n)
P
→ b for any b which is close to 1.
Suppose we take b = 0.99. Observe that for ϵ < 0.01,
P[|X(n) − 0.99| < ϵ] = P[0.99 − ϵ < X(n) < 0.99 + ϵ]
= (0.99 + ϵ)
n − (0.99 − ϵ)
n → 0 ⇒ X(n)
P↛ 0.99.
Using similar arguments, it can be shown that X(n)
P↛ b ̸= 1. □
Remark 7.2.1. As in Example 7.2.3, we can compute P[|X(1)| < ϵ] and
P[|X(n) − 1| < ϵ] from their expressions and verify numerically that these
probabilities approach 1 as n increases. In Example 7.2.16, we verify by sim￾ulation that X(1)
P
→ 0 and X(n)
P
→ 1.
In Example 7.2.5, we noted that X(n)
P
→ 1 but X(n)
P↛ 0.99. Similarly,
X(1)
P
→ 0 but X(1)
P↛ 0.01. It indicates that the limit random variable in
convergence in probability may be unique. We prove in the following theorem
that, as in the almost sure convergence, the limit random variable in con￾vergence in probability is almost surely unique. In asymptotic inference, this
result is useful to conclude that a given estimator cannot be consistent for two
different parametric functions.Convergence in Probability 293
Theorem 7.2.1. If Xn
P
→ X and Xn
P
→ Y , then X and Y are equivalent
random variables, that is, X = Y a.s.
Proof. From the definition of convergence in probability, Xn
P
→ X implies
that given δ1 > 0 and k ≥ 1, ∃ n0(δ1, k) such that P[|Xn −X| > 1/(2k)] < δ1,
for all n ≥ n0(δ1, k). Similarly, Xn
P
→ Y implies that given δ2 > 0 and
k ≥ 1, ∃ n1(δ2, k) such that ∀ n ≥ n1(δ2, k), P[|Xn − Y | > 1/(2k)] < δ2.
Suppose n2(k) = max{n0(δ1, k), n1(δ2, k)}. To prove that X = Y a.s. we
prove that P[X ≠ Y ] = 0. Observe that,
P[X ̸= Y ] = P
h [
k≥1
[|X − Y | > 1/k]
i
Further, 1/k < |X − Y | = |X − Xn + Xn − Y | < |Xn − X| + |Xn − Y |
⇒ [|X − Y | > 1/k] ⊆ [|Xn − X| > (1/2k)] ∪ [|Xn − Y | > (1/2k)]
⇒ P[|X − Y | > 1/k] ≤ P[|Xn − X| > (1/2k)] + P[|Xn − Y | > (1/2k)]
< δ1 + δ2 = δ, say, ∀ n ≥ n2(k).
It is true for all δ > 0, hence P[|X − Y | > 1/k] = 0 ∀ k ≥ 1 for large n. It
then follows that,
P[X ̸= Y ] = P
h [
k≥1
[|X − Y | > 1/k]
i
≤
X
k≥1
P[|X − Y | > 1/k] = 0
for large n, which proves that X = Y a.s.
We have already proved that the limit random variable in almost sure
convergence is almost surely unique. The same result follows from the above
theorem. It is proved in the following corollary.
Corollary 7.2.1. If Xn
a.s. → X and Xn
a.s. → Y , then X = Y a.s.
Proof. If Xn
a.s. → X and Xn
a.s. → Y then Xn
P
→ X and Xn
P
→ Y and hence
X = Y a.s.
In Section 6.3, it is shown that almost sure convergence implies convergence
in probability. We now examine more links of convergence in probability with
the other modes of convergence.
Example 7.2.6. Suppose {Xn, n ≥ 1} is a sequence of random variables such
that Xn ∼ N(1/n, 1/n) distribution. Then
E(Xn − 0)2 = E(X2
n
) = 1/n + 1/n2 → 0 as n → ∞ ⇒ Xn
q.m. → 0.
Now by Chebyshev’s inequality, for ϵ > 0
P[|Xn| > ϵ] ≤ E(X2
n
)/ϵ2 = (1/ϵ2
)
￾
1/n + 1/n2

→ 0 as n → ∞ ⇒ Xn
P
→ 0. 294 Convergence in Probability, in Law and in r-th Mean
The above example shows that convergence in quadratic mean implies
convergence in probability. It is true in general and can be proved using the
Markov inequality, proved in Chapter 4. Moreover, it provides a sufficient
condition for convergence in probability, as is clear from the following theorem.
Theorem 7.2.2. Convergence in r-th mean implies convergence in probabil￾ity.
Proof. By the Markov inequality, for all ϵ > 0 and for some r > 0,
P[|Xn − X| > ϵ] ≤ E|Xn − X|
r
/ϵr → 0 since Xn
r→ X
⇒ P[|Xn − X| > ϵ] → 0 ⇒ Xn
P
→ X.
Thus, Xn
r→ X ⇒ Xn
P
→ X.
Following examples illustrate this implication.
Theorem 7.2.2 is very useful in verifying the consistency of an estimator,
as illustrated in the following example.
Example 7.2.7. Suppose X is a random variable with mean µ and finite
variance σ
2
. Suppose {X1, X2, · · · , Xn} is a random sample of size n from the
distribution of X, that is, {X1, X2, · · · , Xn} are independent and identically
distributed random variables, each having the same distribution function F.
Suppose Xn denotes the sample mean based on this random sample. Then
E(Xn − µ)
2 = V ar(Xn) = σ
2
/n → 0 ⇒ Xn
q.m. → µ ⇒ Xn
P
→ µ.
In particular suppose X has Poisson P(θ) distribution, then Xn
q.m. → θ which
implies Xn
P
→ θ. Suppose if possible, Xn
P
→ g(θ) where g is any real valued
function. However, as proved in Theorem 7.2.1, the limit random variable in
convergence in probability is almost surely unique. Hence, g(θ) = θ, that is,
if Xn is a consistent estimator of θ, then it cannot be a consistent estimator
for any other parametric function of θ. □
In the following example, we show that the r-th order sample raw mo￾ment converges in probability to the corresponding population moment under
certain conditions.
Example 7.2.8. Suppose X is a random variable with the r-th order raw
moment µ
′
r = E(Xr
). Suppose µ
′
2r < ∞. Hence by Lemma 4.5.1, all the
moments of lower order are finite. Suppose m′
r =
Pn
i=1 Xr
i
/n denotes the r￾th order sample raw moment based on a random sample of size n from the
distribution of X. If Yi = Xr
i
, i = 1, 2, · · · , n, then µ
′
r = E(Xr
) = E(Y1),
V ar(Y1) = µ
′
2r − (µ
′
r
)
2
is finite. Hence, as shown in Example 7.2.7, m′
r =
Y n
P
→ µ
′
r
. Thus, the r-th order sample raw moment converges in probability
to the corresponding population moment. □Convergence in Probability 295
In Chapter 9, we prove that the requirement µ
′
2r < ∞ can be replaced by
µ
′
r < ∞.
Example 7.2.9. Suppose {Xn, n ≥ 1} is a sequence of random variables such
that Xn ∼ N(θ, σ2
n
) distribution. Then E(Xn − θ)
2 = σ
2
n
. Suppose σ
2
n → 0,
then Xn
q.m. → θ and hence Xn
P
→ θ. Now suppose Xn
P
→ θ, then ∀ ϵ > 0,
P[|Xn − θ| < ϵ] = P [|Xn − θ|/σn < ϵ/σn]
= Φ (ϵ/σn) − Φ (−ϵ/σn) = 2Φ (ϵ/σn) − 1 → 1
⇒ Φ (ϵ/σn) → 1 ⇒ σn → 0 ⇒ Xn
q.m. → θ.
Thus, in this example, the two modes of convergence are equivalent. □
However, the converse of Theorem 7.2.2 is not true. Convergence in prob￾ability does not imply convergence of sequence of moments or convergence in
r-th mean, as is clear from the following example.
Example 7.2.10. Suppose {Xn, n ≥ 1} is a sequence of random variables,
and the probability mass function of Xn is given by,
Xn =

1, with probability 1 − pn
n, with probability pn .
From the given probability distribution of Xn, it is clear that for any ϵ > 0
P[|Xn − 1| < ϵ] ≥ P[Xn = 1] = 1 − pn → 1 provided pn → 0 .
Suppose pn = a/nδ
, δ > 0, a > 0 is such that 0 < pn < 1, ∀ n ≥ 1. Thus,
pn → 0 ∀ δ > 0 and Xn
P
→ X ≡ 1. From the distribution of Xn we have,
E(Xn) = (1 − pn) + npn = 1 + (n − 1)pn,
E(X2
n
) = (1 − pn) + n
2
pn = 1 + (n
2 − 1)pn ⇒ E(Xn − 1)2 = (n − 1)2
pn.
With pn = a/nδ
, δ > 0, a > 0, observe that,
E(Xn) →



1 + a, if δ = 1
1, if δ > 1
∞, if δ < 1
& E(X2
n
) →



1 + a, if δ = 2
1, if δ > 2
∞, if δ < 2
Further, E(Xn − 1)2 = (n − 1)2
pn →



a, if δ = 2
0, if δ > 2
∞, if δ < 2 .
It is to be noted that for δ > 2, Xn
P
→ 1, E(Xn) → 1, E(X2
n
) → 1 and
E(Xn − 1)2 → 0. However, for 1 < δ ≤ 2, Xn
P
→ X ≡ 1 and E(Xn) → 1, but
E(X2
n
) ↛ 1 and E(Xn − 1)2 ↛ 0. Thus, Xn
P
→ 1 but Xn
q.m. ↛ 1. □296 Convergence in Probability, in Law and in r-th Mean
This example clearly shows the difference between the convergence in prob￾ability of a sequence {Xn, n ≥ 1} of random variables and the limiting be￾haviour of sequence of moments. Observe that Xn
P
→ C, states that for large n,
Xn is very likely to be close to C. However, it says nothing about the location
of the remaining small probability mass assigned to points that are not close
to C and can strongly affect the mean and other moments. This distinction
depends on the assumption that the distribution of Xn has a positive proba￾bility mass for arbitrarily large or small values. Thus, the two statements -
(a) Xn
P
→ C and (b) E(Xn) → C are clearly distinct. Statement (a) is con￾cerned with the bulk of the probability mass and is independent of the position
of the small remainder. However, statement (b) heavily depends on the be￾haviour of Xn in the extreme tails. The situation changes if the Xn’s are
uniformly bounded.
Definition 7.2.2. A sequence {Xn, n ≥ 1} of random variables is said to be
uniformly bounded if there exists M > 0 such that P[|Xn| < M] = 1 ∀ n ≥ 1.
Theorem 7.2.3. Suppose a sequence {Xn, n ≥ 1} of random variables is
uniformly bounded. Then
Xn
P
→ C ⇒ E(Xn) → C, E(Xn−C)
2 → 0 and E(|Xn−C|
r
) → 0, r > 0.
Proof. The proof follows from the basic inequality given by,
E(g(X)) − g(a)
a.s.sup(g(X)) ≤ P[|X| ≥ a] ≤
E(g(X))
g(a)
, a ≥ 0,
where g is a non-negative, even and non-decreasing function on R
+. Now, Xn
is uniformly bounded, hence there exists M > 0 such that P[|Xn| < M] = 1
for all n. Thus,
C ≥ 0 & − M < Xn < M ⇒ − M − C < Xn − C < M − C < M + C
⇒ |Xn − C| < M + C
C < 0 & − M < Xn < M ⇒ − M + C < −M − C < Xn − C < M − C
⇒ |Xn − C| < M − C.
Thus if Xn is uniformly bounded, then |Xn − C| is also uniformly bounded.
Suppose a function g is defined as g(x) = |x|, x ∈ R. Then for any ϵ > 0,
(E(|Xn − C|) − g(ϵ))/M1 ≤ P[|Xn − C| ≥ ϵ] → 0 ⇒ E(|Xn − C|) → 0,
where M1 is almost sure supremum of |Xn − C| and it is finite. Now,
E(Xn − C) ≤ E(|Xn − C|) → 0 ⇒ E(Xn) → C .
To prove that E(Xn−C)
2 → 0, suppose g(x) = x
2
, x ∈ R. Now for any ϵ > 0,
(E(Xn − C)
2 − ϵ
2
)/M2 ≤ P[|Xn − C| ≥ ϵ] → 0 ⇒ E(Xn − C)
2 → 0,Convergence in Probability 297
where M2 is almost sure supremum of |Xn −C|
2
. Thus, Xn
P
→ C ⇒ Xn
q.m. →
C. It further shows that E(X2
n
) → C
2
. With g(x) = |x|
r
, x ∈ R, for any ϵ > 0,
(E(|Xn − C|
r
) − ϵ
r
)/Mr ≤ P[|Xn − C| ≥ ϵ] → 0 ⇒ E(|Xn − C|
r
) → 0,
where Mr is almost sure supremum of |Xn − C|
r
. Thus, Xn
P
→ C implies
Xn
r→ C.
In the following examples, we illustrate Theorem 7.2.3 and verify by sim￾ulation.
Example 7.2.11. In Example 7.2.5, it is shown that if X ∼ U(0, 1), then
X(n)
P
→ Y1 ≡ 1 and X(1)
P
→ Y0 ≡ 0. In Example 7.2.16, we verify these results
by simulation using R. Using the distribution of X(1) and X(n) we can find
their moments. Thus,
E(X(n)) = n/(n + 1) → 1 = E(Y1) & E(X(1)) = 1/(n + 1) → 0 = E(Y0).
Further, |X(n)
| = X(n) ≤ 1 and |X(1)| = X(1) ≤ 1. Hence, X(n) and X(1) both
are uniformly bounded random variables. Thus by Theorem, 7.2.3
limn→∞
E(X(n)) = 1 & limn→∞
E(X(1)) = 0.
Now, E(X2
(n)
) = n/(n + 2) & E(X2
(1)) = 2/(n + 1)(n + 2)
⇒ limn→∞
E((X(n) − 1)2
) = 0 & limn→∞
E(X2
(1)) = 0. □
We verify these results by simulation using Code 7.2.2 in the following
example.
Example 7.2.12. Suppose {X1, X2, · · · , Xn} are independent and identically
distributed random variables each having uniform U(0, 1) distribution. We
take n = 100 to 1100 with an increment of 300 and simulate 300 observations
for each n. From 300 simulated values of X(n) and X(1), we find mean Mn
and mn of these values as estimates of E(X(n)) and E(X(1)) respectively.
We also find Vn and Wn as mean of (X(n) − 1)2 and (X(1))
2 as estimates of
E((X(n) − 1)2
) and E((X(1) − 0)2
) respectively. We use the following code.
Code 7.2.2. N=seq(100,1100,200); nsim=300; umax=umin=m1=m2=
v1=v2=c()
for(j in 1:length(N))
{
for(m in 1:nsim)
{
set.seed(m)
x=runif(N[j],0,1)
umax[m]=max(x)
umin[m]=min(x)298 Convergence in Probability, in Law and in r-th Mean
TABLE 7.2
Verification of Theorem 7.2.3 for U(0, 1)
Distribution
n Mn mn Vn Wn
100 0.9896 0.0111 0.0002 0.0002
300 0.9964 0.0038 0 0
500 0.9980 0.0023 0 0
700 0.9985 0.0015 0 0
900 0.9988 0.0011 0 0
1100 0.9991 0.0009 0 0
}
m1[j]=mean(umax)
m2[j]=mean(umin)
v1[j]=mean((umax-1)^2)
v2[j]=mean(umin^2)
}
d=round(data.frame(N,m1,m2,v1,v2),4);d
We examine whether Mn → 1, mn → 0 and both Vn and Wn converge to
0 as n increases. The output in data frame d is organized in Table 7.2.
From Table 7.2, we note that Mn → 1 and mn → 0 as n increases. Further
and both Vn and Wn are almost 0 for all n. Thus, the results proved in
Theorem 7.2.3 are verified by simulation. □
As in almost sure convergence, it is of interest to examine whether Xn
P
→ X
implies that g(Xn)
P
→ g(X), for some reasonably behaved function g. The
following two theorems address this issue. In the first theorem, we take X ≡
C, a degenerate limit random variable; in the second, it is a non-degenerate
random variable.
Theorem 7.2.4. If Xn
P
→ C, then g(Xn)
P
→ g(C), provided g is a continuous
function on R.
Proof. Continuity of the function g implies that g is a Borel function, hence
g(Xn) is a random variable for each n ≥ 1 and {g(Xn), n ≥ 1} is a sequence
of random variables defined on the same probability space (Ω, A, P). Since g
is continuous on R, g is continuous at each a ∈ R. Hence
∀ ϵ > 0, ∃ δ(a, ϵ) > 0, such that |x − a| < δ(a, ϵ) ⇒ |g(x) − g(a)| < ϵ.
Hence, [|Xn − C| < δ] ⊆ [|g(Xn) − g(C)| < ϵ], where δ depends on C and ϵ.
As a consequence,
P[|g(Xn) − g(C)| < ϵ] ≥ P[|Xn − C| < δ] → 1 since Xn
P
→ C.
Hence, ∀ ϵ > 0, P[|g(Xn) − g(C)| < ϵ] → 1 and g(Xn)
P
→ g(C).Convergence in Probability 299
In the above proof, δ depends on ϵ and C. Suppose Xn
P
→ X where X
is a non-degenerate random variable. If we use arguments similar to those in
Theorem 7.2.4, then continuity of g at X(ω) implies that for all ϵ > 0, ∃ δ > 0
which depends on ϵ and X(ω) and hence on ω ∈ Ω. Hence using continuity of g,
we cannot conclude that [|Xn(ω)−X(ω)| < δ(ϵ, ω)] is included in [|g(Xn)(ω)−
g(X)(ω)| < ϵ]. This inclusion is valid if g is uniformly continuous, that is,
when δ does not depend on ω. A function g is said to be uniformly continuous
on S, if ∀ ϵ > 0, ∃ δ(ϵ) > 0 such that x1, x2 ∈ S with |x1 − x2| < δ
implies that |g(x1) − g(x2)| < ϵ. Thus, if Xn
P
→ X, then g(Xn)
P
→ g(X),
provided g is uniformly continuous. In the following theorem, we prove that
it is not necessary to impose this additional condition of uniform continuity
on g. In the proof, we use the fact that a continuous function on a compact
set is uniformly continuous, and secondly, X being a real random variable is
bounded in probability.
Theorem 7.2.5. Xn
P
→ X ⇒ g(Xn)
P
→ g(X), provided g is a continuous
function.
Proof. Continuity of the function g implies that g is a Borel function, hence
g(X) is a random variable and {g(Xn), n ≥ 1} is a sequence of random vari￾ables defined on the same probability space (Ω, A, P). It is given that X is a
real random variable and hence by Lemma 4.4.1, it is bounded in probability,
that is, for any ϵ > 0, there exists a constant K such that, P[|X| ≤ K] ≥ 1−ϵ.
Further, Xn
P
→ X implies that given ϵ1 > 0 & δ > 0, ∃ n0(ϵ1, δ) such that
P[|Xn − X| ≤ δ] ≥ 1 − ϵ1 ∀ n ≥ n0. Observe that,
|Xn − X| ≤ δ & |X| ≤ K ⇒ X − δ ≤ Xn ≤ X + δ & − K ≤ X ≤ K
⇒ −K − δ ≤ X − δ ≤ Xn ≤ X + δ ≤ K + δ
⇒ |Xn − X| < δ & Xn, X ∈ [−K − δ, K + δ] .
Now g is a continuous function. Hence it is uniformly continuous on
[−K−δ, K+δ]. Hence, when Xn, X ∈ [−K−δ, K+δ], given ϵ2 > 0 ∃ δ1(ϵ2) > 0
such that |Xn − X| ≤ δ1(ϵ2) ⇒ |g(Xn) − g(X)| < ϵ2. Suppose δ2 =
min{δ, δ1}. Thus we have,
|Xn − X| ≤ δ2 & |X| ≤ K ⇒ |g(Xn) − g(X)| < ϵ2 .
Now observe that ∀ n ≥ n0,
1 − ϵ1 ≤ P[|Xn − X| ≤ δ2]
= P[|Xn − X| ≤ δ2, |X| ≤ K] + P[|Xn − X| ≤ δ2, |X| > K]
≤ P[|Xn − X| ≤ δ2, |X| ≤ K] + P[|X| > K]
≤ P[|Xn − X| ≤ δ2, |X| ≤ K] + ϵ .
Hence, P[|Xn − X| ≤ δ2, |X| ≤ K] ≥ 1 − ϵ1 − ϵ. Further ∀ n ≥ n0,
P[|g(Xn) − g(X)| < ϵ2] ≥ P[|Xn − X| ≤ δ2, |X| ≤ K] ≥ 1 − ϵ1 − ϵ
and hence g(Xn)
P
→ g(X).300 Convergence in Probability, in Law and in r-th Mean
This result is stated as convergence in probability is invariant under con￾tinuous transformation. Such a property of convergence in probability is intu￾itively appealing. If with high probability Xn is close to X, then by continuity,
g(Xn) will be close to g(X) with high probability. In the setup of inference, the
above theorem states that the consistency of an estimator is invariant under
continuous transformation, and this result is heavily used to verify the con￾sistency of the estimators for parametric functions. For example, in Example
7.2.7 it is shown that the sample mean Xn based on a random sample of size
n from Poisson P(θ) distribution is consistent for θ. Since g(x) = exp(−x) is
a continuous function, it then follows that exp(−Xn) is a consistent estimator
of exp(−θ) = P[X = 0], where X ∼ P(θ).
In Theorem 7.2.5, it is proved that if g is a continuous function, then
Xn
P
→ X implies g(Xn)
P
→ g(X). If g is not a continuous function, then we
cannot conclude that g(Xn)
P↛ g(X). One has to use the definition to arrive
at a conclusion. In some cases, g(Xn)
P
→ g(X) and in some cases, it does
not. In the next example, we note that Xn
P
→ X, g is not continuous and
g(Xn)
P↛ g(X) (Stoyanov [23]). We discuss one example in the next section,
where g is not continuous, but still g(Xn)
P
→ g(X), under the condition that
the probability measure assigned to the point of discontinuity is 0.
Example 7.2.13. Suppose {Xn, n ≥ 1} is a sequence of random variables
such that for n ≥ 2, P[Xn = 1] = 1/n and P[Xn = 1/n] = 1 − 1/n. Note that
E(X2
n
) = 1/n + 1/n2 − 1/n3 → 0 ⇒ Xn
q.m. → X ≡ 0 ⇒ Xn
P
→ X ≡ 0.
Suppose a function g : R → R is defined as
g(x) = 
0, if x ≤ 0
1, if x > 0.
Note that g is not a continuous function and 0 is a point of discontinuity.
Further, for each n, Xn > 0, hence g(Xn) = 1. However, X ≡ 0 which implies
g(X) ≡ 0. Hence |g(Xn) − g(X)| ≡ 1. Thus, for ϵ < 1, P[|g(Xn) − g(X)| <
ϵ] = 0. Thus, g(Xn)
P↛ g(X). □
The following example gives an application of Theorem 7.2.5.
Example 7.2.14. Suppose X is a random variable with an absolutely con￾tinuous distribution, with support [a, b] and distribution function F. Suppose
{X1, X2, · · · , Xn} are independent and identically distributed random vari￾ables, each having the distribution same as that of X. It is known that if
the distribution of X is absolutely continuous with distribution function F(·),
then by the probability integral transformation, U = F(X) ∼ U(0, 1) distri￾bution. As a consequence, (F(X(1)), F(X(n)))′ are distributed as (U(1), U(n))
′
,
minimum and maximum order statistics corresponding to a random sampleConvergence in Probability 301
of size n from U(0, 1). In Example 7.2.5, it is shown that if
U ∼ U(0, 1), then U(1)
P
→ 0 & U(n)
P
→ 1 .
Suppose F
−1
(·) exists. It is continuous, as F is continuous, in view of the
inverse function theorem (Apostol [1]). Hence, by the invariance property of
convergence in probability under continuous transformation, it follows that
U(1) = F(X(1))
P
→ 0 ⇒ F
−1
(F(X(1))) = X(1)
P
→ F
−1
(0) = a
& U(n) = F(X(n))
P
→ 1 ⇒ F
−1
(F(X(n))) = X(n)
P
→ F
−1
(1) = b ,
for all a and b. □
In Example 7.2.8, we have shown that the r-th order sample raw moment
converges in probability to the corresponding population moment. Using The￾orem 7.2.5, we now prove that sample quantiles converge in probability to the
corresponding population quantiles under certain conditions.
Suppose X is an absolutely continuous random variable with distribution
function F(x). Suppose ap is such that
P[X ≤ ap] ≥ p & P[X ≥ ap] ≥ 1 − p.
Then ap is known as the p-th population quantile or fractile. There may be
multiple values of ap unless the distribution function F(x) is strictly monotone.
We assume that the distribution function F(x) is strictly monotone. Hence
p-th population quantile ap is a unique solution of F(ap) = p, 0 < p < 1. We
assume that the solution of the equation F(ap) = p exists. As an illustration,
suppose X follows an exponential distribution with scale parameter θ. Its dis￾tribution function F(x, θ) is given by, F(x, θ) = 1−exp(−θx) for x > 0. Hence
the solution of the equation F(ap(θ), θ) = p is given by, ap(θ) = − log(1−p)/θ,
0 < p < 1 and it is the p-th population quantile of the distribution of X.
To define the corresponding sample quantile, suppose {X1, X2, · · · , Xn}
is a random sample from the distribution of X with distribution function
F(x). Suppose {X(1), X(2), · · · , X(n)} is the corresponding order statistic.
Then X(rn)
is defined as a p-th sample quantile, where rn = [np]+1, 0 < p < 1.
In the following theorem, we prove that the p-th sample quantile converges in
probability to the p-th population quantile.
Theorem 7.2.6. Suppose X is an absolutely continuous random variable with
distribution function F(x) and {X1, X2, · · · , Xn} are independent and iden￾tically distributed random variables with the distribution function F. Suppose
F is strictly increasing and p-th population quantile ap is a unique solution
of F(ap) = p, 0 < p < 1. Then the p-th sample quantile X(rn) converges in
probability to the p-th population quantile ap, where rn = [np] + 1.
Proof. Since the distribution of X is absolutely continuous with distribu￾tion function F(x), by the probability integral transformation U = F(X) ∼302 Convergence in Probability, in Law and in r-th Mean
U(0, 1) distribution. As a consequence, {F(X(1)), F(X(2)), · · · , F(X(n))} are
distributed as an order statistic corresponding to a random sample of size n
from uniform U(0, 1) distribution. Thus, the distribution of U(rn) = F(X(rn))
is the same as that of the rn-th order statistic from uniform U(0, 1) distribu￾tion. The probability density function of U(rn)
is given by,
grn
(u) = n!
(rn − 1)!(n − rn)! u
rn−1
(1 − u)
n−rn , 0 < u < 1.
It then follows from the definition of a beta function that
E(U(rn)) = rn
n + 1
& E(U
2
(rn)
) = rn(rn + 1)
(n + 1)(n + 2)
⇒ E(U(rn) − p)
2 = E(U
2
(rn)
) − 2pE(U(rn)) + p
2
=
rn(rn + 1)
(n + 1)(n + 2) − 2p
rn
n + 1
+ p
2
.
To find the limit of E(U(rn) − p)
2
, observe that
rn = [np] + 1 ⇒ np < rn ≤ np + 1
⇒
np
n + 1
<
rn
n + 1
≤
np + 1
n + 1
⇒ limn→∞
np
n + 1
≤ limn→∞
rn
n + 1
≤ limn→∞
np + 1
n + 1
⇒ p ≤ limn→∞
rn/(n + 1) ≤ p
⇒ limn→∞
rn/(n + 1) = p
⇒ limn→∞
rn + 1
n + 2
= limn→∞
rn
n + 1
n + 1
n + 2
+
1
n + 2
= p.
Hence,
limn→∞
E(U(rn) − p)
2 = limn→∞ 
rn(rn + 1)
(n + 1)(n + 2) − 2p
rn
n + 1
+ p
2

= 0
⇒ U(rn)
q.m. → p ⇒ U(rn)
P
→ p ⇒ F(X(rn))
P
→ p
⇒ F
−1
(F(X(rn))) P
→ F
−1
(p) ⇒ X(rn)
P
→ ap.
Thus, the p-th sample quantile X(rn) converges in probability to the p-th
population quantile ap.
This result is helpful in finding a consistent estimator for the parame￾ter based on a sample quantile. The procedure is illustrated in the following
example.
Example 7.2.15. (i) For normal N(θ, 1) and Cauchy C(θ, 1) distributions,
θ is a population median. Hence in both the cases, by Theorem 7.2.6, theConvergence in Probability 303
sample median X([n/2]+1)
P
→ θ.
(ii) For a uniform U(0, θ) distribution, θ/2 is a population median. Hence,
X([n/2]+1)
P
→ θ/2. Using invariance of convergence in probability under con￾tinuous transformation, 2X([n/2]+1)
P
→ θ.
(iii) More generally, for a normal N(θ, 1) distribution, the p-th quantile is
ap(θ) = θ + Φ−1
(p), hence X([np]+1) − Φ
−1
(p)
P
→ θ, 0 < p < 1.
(iv) For a uniform U(0, θ) distribution, the p-th quantile is given by, ap(θ) =
θp, hence X([np]+1)/p P
→ θ, 0 < p < 1.
(v) For a Cauchy C(θ, 1) distribution, the p-th quantile is given by,
ap(θ) = θ+ tan(π(p−1/2)), hence X([np]+1) −tan(π(p−1/2)) P
→ θ, 0 < p < 1.
In illustrations (iii), (iv) and (v), we use the result that convergence in prob￾ability is invariant under continuous transformation. In the inference setting,
we thus have an uncountable family of consistent estimators for θ as p varies
over (0, 1) for normal N(θ, 1), uniform U(0, θ) and Cauchy C(θ, 1) distribu￾tions. We have to choose p appropriately to get a better estimator. Note that
a given estimator cannot be consistent for more than one parametric function,
but there can be more than one consistent estimators for a given parametric
function. □
In Example 7.2.8, it is shown that r-th order sample raw moment con￾verges in probability to the r-th order population moment when 2r-th order
population moment is finite. Theorem 7.2.6 proves that p-th sample quan￾tile converges in probability to the p-th population quantile. We verify these
results when {X1, X2, · · · , Xn} are independent and identically distributed
random variables, each having uniform U(0, 1) distribution. Thus, we exam￾ine by simulation whether the sample mean converges in probability to 1/2
and the sample median converges in probability to 1/2. In Example 7.2.5,
we have shown that X(n)
P
→ 1 and X(1)
P
→ 0. We can verify these results
by computing P[|Xn − X| < ϵ] for some ϵ and some n, since we have the
explicit expressions for P[|Xn − X| < ϵ]. However, if we do not have the ex￾plicit expression for P[|Xn − X| < ϵ], we cannot adopt such a procedure for
verification. For example, suppose Yn = Xn, where {X1, X2, · · · , Xn} are in￾dependent and identically distributed random variables each having uniform
U(0, 1) distribution. Then we cannot find P[|Yn − 1/2| < ϵ] explicitly to ver￾ify whether Yn
P
→ 1/2. Hence, we now discuss another approach to verify
convergence in probability by simulation, using R software. It is useful even if
we do not have the explicit expression for P[|Xn − X| < ϵ]. According to the
definition of convergence in probability,
∀ ϵ > 0, P[|Xn − X| < ϵ] → 1 as n → ∞ ⇒ Xn
P
→ X.
To verify it by simulation, we generate m observations from the distributions of
Xn and X and find the relative frequency rfn as an estimate of the probability
pn(ϵ) = P[|Xn − X| < ϵ]. It is defined as rfn =
Pm
i=1 I[|Xn−X|<ϵ]

/m. We304 Convergence in Probability, in Law and in r-th Mean
then examine whether rfn approaches 1 as n increases for various values of ϵ.
The stepwise procedure is as follows.
1. Fix a value of n and ϵ.
2. Generate m observations from the distribution of Xn and X.
3. Find the estimate rfn of the probability pn(ϵ).
4. Increase n and repeat the steps 2 and 3 and examine whether rfn → 1 as
n increases.
5. Repeat steps 2 to 4 for various values of ϵ.
In the following example, we illustrate the procedure for the results derived
in Example 7.2.5 and for the sample mean and the sample median.
Example 7.2.16. In Example 7.2.5, it is shown that if X ∼ U(0, 1), then
X(n)
P
→ 1 and X(1)
P
→ 0. Further, suppose Yn = Xn and Mn is a sample
median based on a random sample {X1, X2, · · · , Xn}. From Example 7.2.8,
it follows that Yn
P
→ 1/2 and from Theorem 7.2.6, we know that Mn
P
→ 1/2.
We generate samples from the uniform distribution and obtain estimates of
P[|X(n) − 1| < ϵ], P[|X(1)| < ϵ], P[|Yn − 1/2| < ϵ] and P[|Mn − 1/2| < ϵ].
Using the stepwise procedure outlined above, we examine their behaviour as
n increases to verify the convergence in probability. We use the following code
for these computations.
Code 7.2.3. eps=c(0.01,0.02,0.03); nsim=500; Max=Min=me=med=c()
N=seq(100,700,100)
p1=p2=p3=p4=matrix(nrow=length(eps),ncol=length(N))
for(i in 1:length(eps))
{
for(j in 1:length(N))
{
for(m in 1:nsim)
{
set.seed(m)
x=runif(N[j],0,1)
Max[m]=max(x)
Min[m]=min(x)
me[m]=mean(x)
med[m]=median(x)
}
p1[i,j]=length(which(abs(Max-1)<eps[i]))/nsim
p2[i,j]=length(which(abs(Min)<eps[i]))/nsimConvergence in Probability 305
p3[i,j]=length(which(abs(me-.5)<eps[i]))/nsim
p4[i,j]=length(which(abs(med-.5)<eps[i]))/nsim
}
}
p1;p2;p3;p4; p=list(p1,p2,p3,p4)
var=c("Maximum","Minimum","Sample Mean","Sample Median")
par(mfrow=c(2,2))
name=paste(var,sep=" ")
for(i in 1:4)
{
plot(N,p[[i]][1,],type="o",xlab="n",ylab="r_n",main=name[i],
lty=1,col="dark blue",ylim=range(.2,1.02),pch=20,lwd=1)
lines(N,p[[i]][2,],lty=2,col="purple",type="o",pch=20,lwd=1)
lines(N,p[[i]][3,],lty=3,col="blue",type="o",pch=20,lwd=1)
legend("bottomright",legend=c(eps[1],eps[2],eps[3]),
lty=c(1,2,3),col=c("dark blue","purple","blue"),
title=expression(paste(epsilon)))
}
The output is organized in Table 7.3.
Corresponding to three values of ϵ and n = 100, 200, · · · , 700, the second,
third and fourth rows display the estimate of P[|X(n) −1| < ϵ], the next three
display estimate of P[|X(1)| < ϵ], the next three display the estimate of
P[|Xn−1/2| < ϵ] and the last three display the estimate of P[|Mn−1/2| < ϵ].
Figure 7.2 displays the nature of rfn as n increases for all four sequences.
TABLE 7.3
U(0,1) Distribution: Convergence in Probability
ϵ 100 200 300 400 500 600 700
0.01 0.624 0.856 0.946 0.978 0.998 1.000 1.000
0.02 X(n) 0.870 0.990 0.998 1.000 1.000 1.000 1.000
0.03 0.936 0.994 0.998 1.000 1.000 1.000 1.000
0.01 0.576 0.840 0.928 0.970 0.992 0.998 1.000
0.02 X(1) 0.836 0.982 1.000 1.000 1.000 1.000 1.000
0.03 0.942 0.998 1.000 1.000 1.000 1.000 1.000
0.01 0.260 0.370 0.474 0.506 0.566 0.618 0.666
0.02 Xn 0.528 0.706 0.778 0.844 0.878 0.914 0.944
0.03 0.694 0.858 0.910 0.956 0.976 0.986 0.996
0.01 0.142 0.214 0.296 0.320 0.342 0.378 0.376
0.02 Mn 0.282 0.430 0.550 0.614 0.646 0.698 0.710
0.03 0.432 0.600 0.734 0.780 0.834 0.902 0.892306 Convergence in Probability, in Law and in r-th Mean
FIGURE 7.2
U(0,1) Distribution: Convergence in Probability of X(n)
, X(1), Xn and Sample
Median
From Table 7.3 and Figure 7.2, we note that as n increases, the estimate of
the probability pn(ϵ) converges to 1. The rate depends on ϵ as is expected. The
convergence is faster for larger ϵ. Further, we observe that rate of convergence
to 1 of rfn for sample mean and sample median is slow as compared to that
of X(n) and X(1). This feature is clearly revealed in Figure 7.2. In general,
the rate of convergence depends on the probability structure of the sequence
{Xn, n ≥ 1}. Thus, by simulation, we have verified that if X ∼ U(0, 1), then
X(1)
P
→ 0, X(n)
P
→ 1, the sample mean and the sample median converge
in probability to 1/2, which is the mean and median of the uniform U(0, 1)
distribution. □
In Example 7.2.15, we have noted that for the normal distribution sample
median converges in probability to the population median. Likewise, from
Example 7.2.8, it follows that the sample mean also converges in probability
to the population mean. In the following example, we verify these results
by simulation for the standard normal distribution and compare the rate of
convergence.
Example 7.2.17. Suppose X1, X2, · · · , Xn are independent and identically
distributed random variables, each following the standard normal distribution.Convergence in Probability 307
Then from Example 7.2.8, Xn
P
→ 0 and from Example 7.2.15, Mn
P
→ 0,
where Mn denotes the sample median. We simulate the samples from the
standard normal distribution for n = 100, 300, 500, 700, 900 and find the rel￾ative frequency rfn. We then examine whether it converges to 1. We further
examine the rate of its convergence to 1 for the sample mean and the sample
median. We use the following code.
Code 7.2.4. eps=c(0.05,0.08,0.1); nsim=300; me=med=c()
N=seq(100,900,200)
p1=p2=matrix(nrow=length(eps),ncol=length(N))
for(i in 1:length(eps))
{
for(j in 1:length(N))
{
for(m in 1:nsim)
{
set.seed(m)
x=rnorm(N[j],0,1)
me[m]=mean(x)
med[m]=median(x)
}
p1[i,j]=length(which(abs(me)<eps[i]))/nsim
p2[i,j]=length(which(abs(med)<eps[i]))/nsim
}
}
p1=round(p1,4);p1;p2=round(p2,4); p2;
par(mfrow=c(3,1))
namevec=paste("epsilon",eps,sep="=")
for(i in 1:length(eps))
{
plot(N-10,p1[i,],type="h",xlab="n",ylab="r_n",main=namevec[i],
lty=1,col="dark blue",ylim=range(.2,1.02),pch=20,lwd=2,
xaxt="n",xlim=c(50,1200))
axis(1,at=N)
points(N-10,p1[i,],pch=16)
lines(N+10,p2[i,],lty=2,col="purple",type="h",pch=20,lwd=2)
points(N+10,p2[i,],pch=16)
legend("bottomright",legend=c("Mean","Median"),
lty=c(1,2),col=c("dark blue","purple"),lwd=2)
}308 Convergence in Probability, in Law and in r-th Mean
TABLE 7.4
Values of rfn for Sample Mean and Sample Median
ϵ 100 300 500 700 900
0.05 Sample Mean 0.3633 0.6133 0.7200 0.8133 0.8600
0.05 Sample Median 0.3467 0.5333 0.6533 0.7167 0.7833
0.08 Sample Mean 0.5733 0.8533 0.9267 0.9733 0.9800
0.08 Sample Median 0.5400 0.7633 0.8400 0.9200 0.9433
0.10 Sample Mean 0.7067 0.9267 0.9800 0.9933 1.0000
0.10 Sample Median 0.6400 0.8633 0.9300 0.9800 0.9867
Values of rn for n = 100, 300, 500, 700, 900 and ϵ = 0.05, 0.08, 0.1 are pre￾sented in Table 7.4. From the table, we note that values of rfn are higher for
the sample mean than that for the sample median for all values of n and ϵ.
Figure 7.3 displays the vertical lines corresponding to rfn for the
sample mean and the sample median adjacent to each other for n =
100, 300, 500, 700, 900 and ϵ = 0.05, 0.08, 0.1. From Figure 7.3, we note that
the height of vertical lines, representing the value of rfn for the sample mean,
is higher than that for the sample median, for all values of n and ϵ. Further,
the difference is small for ϵ = 0.1 and n = 700, and n = 900. Thus, from Table
7.4 and Figure 7.3, we conclude that the sample mean converges in probability
to 0 faster than the sample median. □
We have introduced the concept of a sequence of random variables being
bounded in probability in Section 4.4. In Example 7.2.10, {Xn, n ≥ 1} is
bounded in probability if pn → 0 but not if pn → p > 0. In Lemma 4.4.1, it
is proved that a real random variable is always bounded in probability or is
finite almost surely. Using this lemma, we now prove that if Xn
P
→ X, then
the sequence {Xn, n ≥ 1} is bounded in probability.
Lemma 7.2.1. If Xn
P
→ X, then the sequence {Xn, n ≥ 1} is bounded in
probability.
Proof. By definition, Xn
P
→ X implies that ∀ ϵ > 0 & δ1 > 0, ∃ n0 ∈ N such
that ∀ n ≥ n0, P[|Xn − X| > ϵ] < δ1. Further, X is a real random variable
and hence by Lemma 4.4.1, it is bounded in probability, that is,
∀ δ2 > 0 ∃ M > 0 , such that P[|X| > M] < δ2.
Now for K > M we have,
P[|Xn| > K] = P[|Xn| > K, |X| ≤ M] + P[|Xn| > K, |X| > M]
≤ P[|Xn − X| > K − M] + P[|X| > M]
≤ δ1 + δ2 = δ, say, with ϵ = K − M, ∀ n ≥ n0.
Thus, the sequence {Xn, n ≥ 1} is bounded in probability.Convergence in Probability 309
FIGURE 7.3
Rate of Convergence of Sample Mean and Sample Median
Lemma 7.2.1 is useful in many examples and derivations in subsequent
sections and chapters.
Theorem 7.2.7. Suppose {Yn, n ≥ 1} is a sequence of random variables such
that Yn
P
→ 0. (i) If X is a real random variable then XYn
P
→ 0. (ii) Suppose
{Xn, n ≥ 1} is a sequence of random variables such that Xn
P
→ X. Then
XnYn
P
→ 0.
Proof. (i) If X ≡ 0, then the result is trivially true. Hence we assume X = 0 ̸ .
For any ϵ > 0 and M > 0, observe that
P[|XYn| > ϵ] = P[|XYn| > ϵ, |X| > M] + P[|XYn| > ϵ, |X| ≤ M]
≤ P[|X| > M] + P[|Yn| > ϵ/M] → 0,
using the fact that X is bounded in probability for the first term and Yn
P
→ 0
for the second term. Thus, XYn
P
→ 0.
(ii) By Theorem 7.2.1, if Xn
P
→ X, then the sequence {Xn, n ≥ 1} is bounded310 Convergence in Probability, in Law and in r-th Mean
in probability. Further, Yn
P
→ 0 and hence using similar arguments as in (i),
it follows that XnYn
P
→ 0.
As in almost sure convergence, convergence in probability is also closed
under arithmetic operations. It is proved in the following theorem, using The￾orem 7.2.7.
Theorem 7.2.8. Suppose {Xn, n ≥ 1} and {Yn, n ≥ 1} are sequences of
random variables defined on the same probability space (Ω, A, P). If Xn
P
→ X
and Yn
P
→ Y , then (i) aXn
P
→ aX. (ii) Xn ±Yn
P
→ X ±Y . (iii) XnYn
P
→ XY .
(iv) Xn/Yn
P
→ X/Y , provided Xn/Yn and X/Y are defined.
Proof. (i) Xn
P
→ X implies aXn
P
→ aX is trivially true if a = 0. Suppose
a ̸= 0, then observe that,
P[|aXn−aX| > ϵ] = P[|Xn−X| > ϵ/|a|] = P[|Xn−X| > ϵ∗
] → 0, as n → ∞ ,
where ϵ
∗ = ϵ/|a|.
(ii) Xn
P
→ X and Yn
P
→ Y implies that,
∀ ϵ > 0, P[|Xn − X| > ϵ] → 0 and P[|Yn − Y | > ϵ] → 0.
Observe that for ϵ > 0,
ϵ < |(Xn + Yn) − (X + Y )| = |(Xn − X) − (Yn − Y )| < |Xn − X| + |Yn − Y |.
It is clear that if the sum of two non-negative numbers exceeds ϵ, then at least
one of the two has to be greater than ϵ/2. Thus as n → ∞,
P[|(Xn + Yn) − (X + Y )| > ϵ] ≤ P[|Xn − X| > ϵ/2] + P[|Yn − Y | > ϵ/2]
→ 0 ⇒ Xn + Yn
P
→ X + Y.
Another approach is as follows. If
En = [|Xn − X| < ϵ/2] & Fn = [|Yn − Y | < ϵ/2]
⇒ P(En) → 1 & P(Fn) → 1 ⇒ P(En ∩ Fn) → 1.
If both |Xn − X| and |Yn − Y | are < ϵ/2 then |(Xn + Yn) − (X + Y )| < ϵ].
Hence n → ∞,
P[|(Xn + Yn) − (X + Y )| < ϵ] ≥ P[|Xn − X| < ϵ/2, |Yn − Y | < ϵ/2]
→ 1 ⇒ Xn + Yn
P
→ X + Y.
Using (i) if Yn
P
→ Y then −Yn
P
→ − Y hence
Xn − Yn = Xn + (−Yn)
P
→ X − Y .Convergence in Probability 311
(iii) Observe that for ϵ > 0,
ϵ < |XnYn − XY | = |XnYn − XnY + XnY − XY )|
≤ |Xn(Yn − Y )| + |Y (Xn − X)|
⇒ P[|XnYn − XY | > ϵ] ≤ P[|Xn(Yn − Y )| > ϵ/2] + P[|Y (Xn − X)| > ϵ/2].
Note that Yn − Y
P
→ 0 and by Lemma 7.2.1, {Xn, n ≥ 1} is bounded in
probability. Hence by the result (ii) of Theorem 7.2.7, Xn(Yn − Y )
P
→ 0.
Further, Xn − X
P
→ 0 and Y is bounded in probability. Hence by the result
(i) of Theorem 7.2.7, Y (Xn − X)
P
→ 0. As a consequence,
P[|XnYn − XY | > ϵ] ≤ P[|Xn(Yn − Y )| > ϵ/2] + P[|Y (Xn − X)| > ϵ/2]
→ 0 ⇒ XnYn
P
→ XY.
(iv) To prove that Xn/Yn
P
→ X/Y , it is enough to prove that 1/Yn
P
→ 1/Y
and use result (iii). Suppose a function g is defined as g(x) = 1/x, x ̸= 0.
Then g is a continuous function. Hence
Yn
P
→ Y ⇒ g(Yn) = 1/Yn
P
→ g(Y ) = 1/Y .
Hence, together with result (iii) we get Xn/Yn
P
→ X/Y .
In Example 7.2.8, it is shown that the r-th order sample raw moment
converges in probability to the corresponding population raw moment. In the
next example, using Theorem 7.2.8, we show that the r-th order sample cen￾tral moment converges in probability to the corresponding population central
moment.
Example 7.2.18. Suppose X is a random variable with the r-th order central
moment µr = E((X − E(X))r
) and µ
′
2r < ∞. Suppose mr =
Pn
i=1(Xi −
m′
1
)
r/n denotes the r-th order sample central moment based on a random
sample of size n from the distribution of X. By the binomial theorem, we
have,
µr = E(X − E(X))r =
Xr
j=0

r
j

E(Xj
)(−1)r−j
(E(X))r−j
=
Xr
j=0

r
j

µ
′
j
(−1)r−j
(µ
′
1
)
r−j
.
On similar lines, mr can be expressed as,
mr =
Xn
i=1
(Xi − m′
1
)
r
.n =
Xn
i=1
Xr
j=0

r
j

X
j
i
(−1)r−j
(m′
1
)
r−j
.n
=
Xr
j=0

r
j

m′
j
(−1)r−j
(m′
1
)
r−j
.312 Convergence in Probability, in Law and in r-th Mean
In Example 7.2.8, it is shown that m′
j
P
→ µ
′
j
. In Theorem 7.2.8, it is proved that
convergence in probability is closed under all arithmetic operations. Hence,
mr
P
→ µr. Thus, the sample central moment mr converges in probability to
the population central moment µr. □
In the setup of inference, Theorem 7.2.8 implies that a class of consistent
estimators is closed under all arithmetic operations. The following example
illustrates this result.
Example 7.2.19. Suppose the probability density function of an absolutely
continuous random variable X is given by f(x, θ) = θxθ−1
, 0 < x < 1, θ > 0.
Then E(X) = θ/(θ+1) and V ar(X) = θ/((θ+2)(θ+1)2
). Suppose Xn denotes
the sample mean based on a random sample of size n from the distribution
of X. Then, by Chebyshev’s inequality, Xn
q.m. → θ/(θ + 1) and hence Xn
P
→
θ/(θ + 1). Now using the fact that convergence in probability is closed under
the arithmetic operations, we have
Xn →
Pθ θ
θ + 1
⇒
1
Xn
→
Pθ θ + 1
θ
=
1
θ
+ 1 ⇒
1
Xn
− 1 →
Pθ 1
θ
⇒
Xn
1 − Xn
→
Pθ
θ.
Thus, Xn/(1 − Xn) is a consistent estimator of θ. □
We have a following corollary to Theorem 7.2.8, which is useful in many
examples and derivations.
Corollary 7.2.2. Suppose {Xn, n ≥ 1} and {Yn, n ≥ 1} are sequences of
random variables defined on the same probability space (Ω, A, P). If Xn−Yn
P
→
0 and Yn
P
→ X, then Xn
P
→ X.
Proof. Observe that Xn = (Xn − Yn) + Yn
P
→ X by Theorem 7.2.8.
The following example illustrates Corollary 7.2.2.
Example 7.2.20. In Example 7.2.5, it is shown that if X ∼ U(0, 1), then
X(n)
P
→ 1. We now examine whether X(n−1)
P
→ 1. Observe that for ϵ > 0
P[|X(n−1) − X(n)
| < ϵ] ≥ P[X(n−1) = X(n)
] = P[X(n−1) ≥ Xn]
= E(P[X(n−1) ≥ Xn|Xn]) = E(1 − Xn−1
n
)
=
Z 1
0
(1 − u
n−1
) du = 1 − 1/n → 1
⇒ X(n−1) − X(n)
P
→ 0
⇒ X(n−1)
P
→ 1 since X(n)
P
→ 1. □
We use Corollary 7.2.2 in the following theorem.Convergence in Probability 313
Theorem 7.2.9. (i) Suppose {Xn, n ≥ 1} is a sequence of random variables
defined on (Ω, A, P) such that Xn
P
→ X and {An, n ≥ 1} is a sequence of sets
in A. (i) If An ↓ ∅, then XIAn
P
→ 0 and XnIAn
P
→ 0. (ii) If An ↑ Ω, then
XIAn
P
→ X and XnIAn
P
→ X.
Proof. It is proved in Theorem 2.3.9 that An → A ⇒ IAn → IA point-wise,
hence almost surely and hence in probability.
(i) If An ↓ ∅, then IAn
P
→ I∅ ≡ 0. Further, X being a real random variable,
X is bounded in probability. Hence by Theorem 7.2.7, XIAn
P
→ 0. Note that
Xn
P
→ X implies that Xn is bounded in probability and hence XnIAn
P
→ 0.
(ii) If An ↑ Ω, then IAn
P
→ IΩ ≡ 1 ⇒ (IAn − 1) P
→ 0. By Theorem 7.2.7,
X(IAn − 1) P
→ 0 which implies that XIAn
P
→ X, by Corollary 7.2.2. Fur￾ther, IAn → IA point-wise and hence in probability. Thus, IAn
is bounded in
probability. It is given that Xn
P
→ X. Consequently, (Xn − X)IAn
P
→ 0, but
XIAn
P
→ X and hence XnIAn
P
→ X.
The next example demonstrates various approaches to show that Xn
P
→ X.
Example 7.2.21. Suppose {Xn, n ≥ 1} is a sequence of random variables
defined as Xn = (1 + 1/n)X, where X is a discrete random variable with
support {0, 1} and P[X = 0] = 2/3. We show that Xn
P
→ X by various
approaches.
(i) From the distribution of X it is clear that E(Xr
) = 1/3 ∀ r ≥ 1. Thus
for any ϵ > 0, as n → ∞,
P[|Xn − X| < ϵ] = P [|X/n| < ϵ] ≥ 1 − E(X/n)
2
/ϵ2 = 1 − 1/3n
2
ϵ
2 → 1.
Hence, Xn
P
→ X.
(ii) Observe that Xn − X = (1/n)X. X is a real random variable and hence
is bounded in probability, 1/n → 0 and hence by Theorem 7.2.7, (1/n)X
P
→ 0
and hence Xn
P
→ X.
(iii) Further for any r > 0, E(|Xn − X|
r
) = (1/nr
)E(|X|
r
) = 1/(3n
r
) → 0,
hence Xn
r→ X and hence Xn
P
→ X.
(iv) For any
ω ∈ Ω, Xn(ω) = (1 + 1/n)X(ω) → X(ω),
implying that Xn → X point-wise, hence almost surely and hence in proba￾bility.
(v) Further ∀ r > 1,
X∞
n=1
E(|Xn − X|
r
) = X∞
n=1
1/(3n
r
) < ∞ ⇒ Xn
a.s. → X ⇒ Xn
P
→ X. □314 Convergence in Probability, in Law and in r-th Mean
We now define the Cauchy criterion of convergence in probability. It is also
known as mutual convergence in probability.
Definition 7.2.3. A sequence {Xn, n ≥ 1} of random variables is said to be
Cauchy (fundamental) in probability if ∀ ϵ > 0, P[|Xn − Xm| > ϵ] → 0 as
m, n → ∞.
Convergence in probability implies mutual convergence in probability, as
shown in the following theorem.
Theorem 7.2.10. If Xn
P
→ X as n → ∞ then Xn−Xm
P
→ 0 as m, n → ∞.
Proof. Since X is a real random variable, it is finite almost surely, that is, on
Nc where P(N) = 0. Thus for all ω ∈ Nc and for any ϵ > 0, we have
[|Xn − Xm| > ϵ] ⊆ [|Xn − X| > ϵ/2] ∪ [|Xm − X| > ϵ/2]
⇒ P[|Xn − Xm| > ϵ] ≤ P[|Xn − X| > ϵ/2] + P[|Xm − X| > ϵ/2] → 0
⇒ Xn − Xm
P
→ 0 as m, n → ∞.
To prove that Cauchy convergence in probability implies convergence in
probability, we need to prove the following theorem. It is also helpful in proving
Lebesgue dominated probability convergence theorem in Chapter 8.
Theorem 7.2.11. Suppose {Xn, n ≥ 1} is a sequence of random variables
such that Xn
P
→ X. Then there exists a sub-sequence of {Xn, n ≥ 1} which
converges to X almost surely and hence in probability.
Proof. By definition
Xn
P
→ X ⇒ ∀ ϵ > 0, limn→∞
P[|Xn − X| > ϵ] = 0
⇐⇒ ∀ k ≥ 1, ∃ n(k) such that P[|Xn − X| > 1/2
k
] < 1/2
k
,
∀ n ≥ n(k). We define n1 = n(1), n2 = max{n1 + 1, n(2)}, · · · ,
nk = max{nk−1 + 1, n(k)}. Thus, {nk, k ≥ 1} is an increasing sequence and
nk → ∞ as k → ∞. Thus, {Xnk
, k ≥ 1} is a sub-sequence of the sequence
{Xn, n ≥ 1}. Now,
X∞
n=1
P[|Xnk − X| > 1/2
k
] <
X∞
n=1
1/2
k < ∞ ⇒ Xnk
a.s → X
by Corollary 6.3.1. Since almost sure convergence implies convergence in prob￾ability, Xnk
P
→ X
Using Theorem 7.2.11, we now prove that Cauchy convergence in proba￾bility implies convergence in probability.Convergence in Probability 315
Theorem 7.2.12. A sequence {Xn, n ≥ 1} of random variables is Cauchy in
probability implies that Xn
P
→ X, for some X.
Proof. A sequence {Xn, n ≥ 1} is Cauchy in probability implies that
Xn − Xm
P
→ 0 as m, n → ∞. Hence, ∀ k ≥ 1, ∃ n(k) such that ∀ n, m ≥ n(k),
P[|Xn − Xm| ≥ 1/2
k
] < 1/2
k
. Consequently, as shown in Theorem 7.2.11,
there exists a sub-sequence {Xnk − Xmk
, k ≥ 1} of the sequence
{Xn − Xm, n ≥ 1} such that Xnk − Xmk
a.s → 0. In Theorem 6.3.6, it is proved
that almost sure convergence and almost sure Cauchy convergence are equiv￾alent. Hence, Xnk
a.s → X for some X. Almost sure convergence implies conver￾gence in probability and hence Xnk
P
→ X. Thus, ∀ ϵ > 0,
P[|Xn − X| > ϵ] ≤ P[|Xn − Xnk
| > ϵ/2] + P[|Xnk − X| > ϵ/2] → 0 ,
as n, k → ∞, where P[|Xn − Xnk
| > ϵ/2] → 0 in view of Cauchy convergence
in probability and P[|Xnk − X| > ϵ/2] → 0 as Xnk
P
→ X. Thus, Xn
P
→ X, for
some X.
The following theorem gives a necessary and sufficient condition for con￾vergence in probability, using the basic inequality discussed in Chapter 4.
Theorem 7.2.13. Xn
P
→ 0 if and only if E (|Xn|/(1 + |Xn|)) → 0 as n → ∞.
Proof. Suppose a function g is defined as g(x) = |x|/(1 + |x|), x ∈ R. It is
clear that g is a non-negative and even function. Further,
|x1| ≤ |x2| ⇒ 1 +
1
|x1|
≥ 1 +
1
|x2|
⇒
|x1|
1 + |x1|
≤
|x2|
1 + |x2|
.
Thus, g(x) = |x|/(1+|x|) is a non-decreasing function. By definition, g(x) ≤ 1,
thus supremum of g(x) is 1 and almost sure supremum of g(X) is 1. With such
a choice of a function g, we replace X by Xn and a by ϵ in the basic inequality
to get,
E

|Xn|
1 + |Xn|

−
ϵ
1 + ϵ
≤ P[|Xn| ≥ ϵ] ≤

E

|Xn|
1 + |Xn|
 . 
ϵ
1 + ϵ

.
Suppose E (|Xn|/(1 + |Xn|)) → 0 as n → ∞. Then by the right hand side of
the above inequality, we get P[|Xn| ≥ ϵ] → 0 as n → ∞, ∀ ϵ > 0 and
hence Xn
P
→ 0. Conversely, assume that Xn
P
→ 0, that is, P[|Xn| ≥ ϵ] → 0 as
n → ∞ ∀ ϵ > 0, hence by the left hand side of the above inequality, we get
E (|Xn|/(1 + |Xn|)) → 0.
The next section is concerned with an important mode of convergence,
convergence in law.316 Convergence in Probability, in Law and in r-th Mean
7.3 Convergence in Law
Convergence in law is the most frequently used mode of convergence in asymp￾totic inference, in large sample interval estimation and to find the asymptotic
null distribution of a test statistic. The important theorem in this mode of
convergence is the central limit theorem, which we discuss in detail in Chapter
10. In the present section, we study some aspects listed at the end of Section
6.2 for this mode of convergence and illustrate by examples. We state below
its definition, which is already given in Section 6.2.
Definition 7.3.1. Convergence in law: Suppose {Xn, n ≥ 1} is a sequence
of random variables defined on a probability space (Ω, A, P). Suppose Fn(·) is
a distribution function of Xn and FX(·) is a distribution function of X. A
sequence {Xn, n ≥ 1} is said to converge in law to a random variable X, not
necessarily defined on the same probability space, if
Fn(x) = P[Xn ≤ x] → P[X ≤ x] = FX(x), ∀ x ∈ C(FX),
where C(FX) is a set of points of continuity of the distribution function FX.
We illustrate below the convergence in law with some examples.
Example 7.3.1. Suppose {Xn, n ≥ 1} is a sequence of random variables
with P[Xn = ±1/n] = 1/2. Then note that the distribution function Fn of
Xn, given by,
FXn
(x) =



0, if x < −1/n
1/2, if −1/n ≤ x < 1/n
1, if x ≥ 1/n
→ F(x) = 
0, if x < 0
1, if x > 0.
If we define X ≡ 0, then 0 is the only point of discontinuity of a distribution
function F. Thus, FXn
(x) → FX(x) for all x ∈ C(FX). Hence, we conclude
that Xn
L
→ X. □
Example 7.3.2. Suppose {Xn, n ≥ 1} is a sequence of random variables
such that Xn has exponential distribution with mean θn = 1 + 1/n. For
x < 0, Fn(x) = 0 ∀ n ≥ 1 and hence converges to 0 as n → ∞. For x ≥ 0,
Fn(x) = P[Xn ≤ x] = 1 − exp{−x/θn} → 1 − exp{−x} = FX(x) ,
where F is a distribution function of a random variable following the expo￾nential distribution with mean 1. Thus, Fn(x) → FX(x) ∀ x ∈ R = C(FX)
and hence Xn
L
→ X where X has exponential distribution with mean 1. □Convergence in Law 317
Example 7.3.3. Suppose X1, X2, · · · , Xn are independent and identically
distributed random variables each having uniform U(0, θ) distribution. Then
as shown in Example 7.2.5, distribution function of X(n) given by,
FX(n)
(x) = [FX(x)]n =



0, if x < 0
(x/θ)
n, if 0 ≤ x < θ
1, if x ≥ θ.
Using similar arguments as in Example 7.2.5, it can be shown that X(n)
P
→ θ.
Suppose Yn = n(θ − X(n)). We derive its distribution function GYn
(y) for
y ∈ R from the distribution function of X(n)
. Since X(n) ≤ θ, Yn ≥ 0, hence
for y < 0, GYn
(y) = 0. Suppose y ≥ 0, then
GYn
(y) = Pθ[n(θ − X(n)) ≤ y] = Pθ[X(n) ≥ θ − y/n] = 1 − FX(n)
(θ − y/n).
Hence,
GYn
(y) =



1 − 0, if θ − y/n < 0
that is y ≥ nθ
1 −

θ−y/n
θ
n
= 1 − (1 −
y
nθ )
n, if 0 < y ≤ nθ
1 − 1, if y ≤ 0.
As n → ∞,
GYn
(y) = Gn(y) → FY (y) = 
0, if y < 0
1 − e
−(y/θ)
, if y ≥ 0.
However, FY (y) is a distribution function of a random variable Y , which has
an exponential distribution with location parameter 0 and scale parameter
1/θ. Thus,
Yn = n(θ − X(n))
L
→ Y ⇐⇒ Yn/θ = Un
L
→ U
where U which has exponential distribution with location parameter 0 and
scale parameter 1. □
In the following example, using R, we examine the convergence of Gn(·) to
FY (·) as proved in Example 7.3.3.
Example 7.3.4. Suppose {X1, X2, · · · , Xn} are independent and identically
distributed random variables, each having uniform U(0, θ) distribution. Then
it is shown in Example 7.3.3 that Yn
L
→ Y , where Y has an exponential
distribution with location parameter 0 and scale parameter 1/θ. We use the
following code to examine the convergence of Gn(·) to FY (·). We take n =
40, 60, 80, 100 and θ = 0.2.318 Convergence in Probability, in Law and in r-th Mean
Code 7.3.1. th=0.2; nvec=c(40,60,80,100);l=length(nvec)
u=0:20; x=1-exp(-u/th); y=z=list(); par(mfrow=c(2,2))
no=paste("n=",nvec,sep=" ")
for(j in 1:l)
{
y[[j]]=seq(0,nvec[j]*th,length=100)
z[[j]]=1-(1-y[[j]]/(nvec[j]*th))^(nvec[j])
plot(y[[j]],z[[j]],type="o", col="green",main=no[j],pch=19,
ylab=expression(paste(Gn(y))),xlab=expression(paste(y)),lwd=1)
lines(u,x,type="o",col="dark green",pch=20)
legend("bottomright",legend=c("Gn(y)","F(y)"),lwd=c(1,1),
pch=c(19,20),col=c("green","dark green"))
}
Figure 7.4 displays graphs of Gn(y) for four values of n, and the graph
of FY (y) is imposed on it. We note that as n increases, the curves of two
distribution functions are closer to each other. For n = 100, these are very
close to each other. □
We now discuss how to verify convergence in law by simulation using R
software and illustrate for Example 7.3.3. We generate m observations from
the given distribution of Xn and obtain a histogram of simulated values of Xn
or some function of Xn, with relative frequencies on the Y-axis. For Example
7.3.3, we obtain the histogram of Un. From the visual inspection, we may
guess the limiting distribution. We then impose a curve of the corresponding
probability law on it and can judge the closeness. We can justify the claim an￾alytically using the chi-square goodness of fit test or the Komogorov-Smirnov
test.
For example, if the histogram is bell-shaped, we impose the curve of the
probability density function of the normal distribution on it. We observe
whether the two are close to each other as the sample size increases. We
may also draw a box plot and QQ plot to assess the normality of Xn for large
n. In addition, we draw a graph of the empirical distribution function of sim￾ulated values of Xn and impose the graph of the distribution function of the
normal distribution on it. The visual impression produced by these four types
of plots can be judged analytically by the Shapiro-Wilk test. We adopt such
a procedure in Example 7.3.25.
The stepwise procedure to verify the convergence in law is as follows.
(i) Generate m observations from the distribution of Xn.
(ii) Corresponding to m values of Xn, draw a histogram with relative fre￾quencies on the Y-axis and impose a curve of the probability density
function of a suitable distribution on it. Further, carry out the appro￾priate goodness of fit test.Convergence in Law 319
FIGURE 7.4
Convergence in law of Yn
(iii) Increase the sample size n and repeat the steps (i) and (ii).
We illustrate the above procedure for Example 7.3.3, using Code 7.3.2.
Example 7.3.5. Suppose {X1, X2, · · · , Xn} are independent and identically
distributed random variables, each having uniform U(0, θ) distribution. Sup￾pose Un = n(θ − X(n))/θ, then it is shown in Example 7.3.3 that Un
L
→ U,
where U has exponential distribution with location parameter 0 and scale pa￾rameter 1. In Example 7.3.4, we have noted that the two distribution functions
are close to each other for n = 100. Hence, we verify this result by simulation
for n = 100 and θ = 0.2 using the following code.
Code 7.3.2. n=100; th=0.2; m=500; t=c()
for(i in 1:m)
{
set.seed(i)
x=runif(n,0,th)320 Convergence in Probability, in Law and in r-th Mean
t[i]=max(x)
}
tn=n*(th-t)/th; me=mean(tn);me; v=var(tn)*(m-1)/m;v
sd=v^.5; sd; r=seq(0,8,.1); y=dexp(r,rate=1)
par(mfrow=c(1,1))
hist(tn,freq=FALSE,main="Histogram of U_n",ylim=c(0,0.6),
xlab = expression(paste("U"[n])),col="light blue")
lines(r,y,"o",pch=20,col="dark blue",lty=1)
legend("topright",legend="pdf of exponential distribution
with mean 1",lty=1,pch=20,col="dark blue",cex=.9)
O=hist(tn,plot=FALSE)$counts; sum(O)
bk=hist(tn,plot=FALSE)$breaks; bk
M=max(bk); u=seq(0,M,.1); y1=dexp(u, rate=1)
e=exp(1); ep=c()
for(i in 1:(length(bk)-1))
{
ep[i]=e^(-bk[i])-e^(-bk[i+1])
}
a=1-sum(ep); a; ep1=c(ep, a); ef=sum(O)*ep1; O1=c(O,0)
d=data.frame(O1,round(ef,2)); d
ts=sum((O1-ef)^2/ef);ts
df=length(ef)-1; df; b=qchisq(.95,df); b
p1=1-pchisq(ts,df); p1; chisq.test(O1,p=ep1)
# pooling of frequencies less than 5 is ignored
From the output, we note that sample mean 1.0371 and sample standard
deviation 1.0284 of the simulated values of Un are close to each other, support￾ing the result that for large n the distribution of Un can be approximated by
the exponential distribution. Further, the histogram indicates that the limit￾ing distribution is skew. We have imposed the curve of the probability density
function of the exponential distribution with mean 1. We note that there is
a close agreement. We carry out the goodness of fit test to test the null hy￾pothesis that for large n, the distribution of Un is an exponential distribution
with a mean one. We use Karl Pearson’s chi-square test statistic T given by
T =
Pk
i=1(oi − ei)
2/ei
, where k denotes the number of classes in which m
observations on Un are classified, oi and ei denote the observed frequency
and expected frequency respectively, expected under the exponential distri￾bution with mean 1, for the i-th class. Under the null setup, T has χ
2
k−1
distribution. For the simulated data, T = 8.3287, with 8 degrees of free￾dom, the cut-off is 15.5073, and the p-value is 0.4020. The built-in func￾tion chisq.test(O1,p=ep1) gives the same results. From the cut-off point,Convergence in Law 321
FIGURE 7.5
U(0, θ) Distribution: Convergence in Law of n(θ − X(n))/θ
p-value, results of the built-in function and Figure 7.5, we note that for large
n, the distribution of Un = n(θ − X(n))/θ can be approximated by that of U,
where U has an exponential distribution with location parameter 0 and scale
parameter 1. □
It is a well-known result that a binomial distribution under certain condi￾tions converges to a Poisson distribution. We prove it below by showing that
the probability mass function of a binomial distribution converges to that of a
Poisson distribution. Convergence of the corresponding distribution functions
then follows by Scheffe’s lemma, refer to p.228 of Gut [13].
Example 7.3.6. Suppose Xn ∼ B(n, pn) distribution. Suppose as n → ∞,
pn → 0 such that npn → λ where λ is a positive constant. Under these
conditions, we examine whether the probability mass function of a binomial
distribution tends to that of a Poisson distribution. Suppose qn = 1−pn, then
limn→∞
n log qn = limn→∞
{−n(pn + p
2
n/2 + p
3
n/3 + · · ·)}
= limn→∞
{−npn − (npn)(pn/2) − (npn)(p
2
n/3) − · · · }
= −λ as npn → λ & pn → 0
⇒ limn→∞
q
n
n = e
−λ
.322 Convergence in Probability, in Law and in r-th Mean
With this limit, observe that,
P[Xn = k] = 
n
k

p
k
n
q
n−k
n =
n(n − 1)· · ·(n − k + 1)
k(k − 1)· · · 1
p
k
n
q
k
n
q
n
n
=
(1 − 1/n)(1 − 2/n)· · ·(1 − (k − 1)/n)
k!
(npn)
k
(1 − pn)
k
q
n
n
→ (1/k!)λ
k
e
−λ = P[X = k],
as n → ∞ and pn → 0 such that npn → λ. Note that X ∼ P(λ). □
In the following example, we verify the results of Example 7.3.6 by drawing
the graphs of the probability mass function of binomial B(n, pn) distribution
for different values of n and comparing these with the graph of Poisson dis￾tribution with parameter λ. It gives some idea of how large n is needed and
the rate of convergence of pn to 0.
Example 7.3.7. Suppose Xn ∼ B(n, pn). We have proved in the above ex￾ample that binomial distribution can be approximated by the Poisson P(λ)
distribution as n → ∞, pn → 0 such that npn → λ. We use the following code
for verification.
Code 7.3.3. We take n = 10, 50, 100, 500, λ = 2 and pn = λ/(n+ 1). We plot
the probability mass function of B(n, pn) and P(λ) and their distribution
functions to observe for which n these are close. Figure 7.6 displays these
graphs.
lambda=2; nvec=c(10,50,100,500)
k=1;pvec=lambda/(nvec+k); xvec=0:10
PMFPois=dpois(xvec,lambda)
PMFBin=matrix(ncol=length(xvec),nrow=length(nvec))
for(i in 1:length(nvec))
{
n=nvec[i]
p=pvec[i]
PMFBin[i,]=dbinom(xvec,size=n,prob=p)
}
PMF=rbind(PMFBin,PMFPois); colnames(PMF)=xvec
rownames(PMF)=c(nvec,"Poisson"); PMF
par(mfrow=c(1,2))
M=max(PMFPois,PMFBin)
plot(xvec+0.05*(length(nvec)+2),PMFPois,col=1,type="h",
ylim=c(0,M+0.1),xaxt="n",xlab="X",ylab="PMF",
xlim=c(-0.5,max(xvec)+0.5))
for(i in 1:length(nvec))Convergence in Law 323
{
lines(xvec+0.05*i,PMFBin[i,],type="h",col=i+1)
}
axis(1,at=xvec+0.25,labels=xvec)
labvec=paste("n=", nvec, sep="")
labvec=c("Poisson",labvec)
legend("topright",col=1:(length(nvec)+1),legend=labvec,
lty=1,xjust=1)
CDF=t(apply(PMF,1,cumsum))
View(CDF)
plot(xvec,CDF[length(nvec)+1,],col=1,type="s",ylim=c(0,1.1),
xlab="X",ylab="CDF",yaxs="i",lwd=2)
for(i in 1:length(nvec))
{
lines(xvec,CDF[i,],type="s",col=i+1)
}
legend("bottomright",col=1:(length(nvec)+1),legend=labvec,
lty=1,xjust=1)
In the code for both the distributions, we compute probabilities for x = 0
to x = 10 since for x > 10, these are almost 0. From Figure 7.6, we observe that
for n = 100 and 500, the probability mass function, as well as the distribution
function of the two distributions, are close to each other. From the output, we
note that
P[Xn = 0] = q
n = 0.1344, 0.1353, 0.1353, 0.1353 for n = 10, 50, 100, 500
respectively and P[X = 0] = exp(−λ) = 0.1353, where X ∼ P(λ). In the
left panel of the graph, displaying the probability mass function, the five
vertical lines at x = 0 are almost identical and in the right panel of the
graph, displaying the distribution function, the five horizontal lines from x = 0
to x = 1 overlap each other. Thus, the result limn→∞ q
n
n = e
−λ proved in
Example 7.3.6, is verified numerically. We note that the limit is attained at
n = 100. A minute observation of the graph in the left panel shows that
the height of vertical lines corresponding to the probability mass function
of the binomial distribution is not monotonically increasing or decreasing, it
increases initially and then decreases. Such a nature results from the fact that
the total probability has to add to 1. □
We now investigate the links between convergence in law and other modes
of convergence. In the following theorem, we prove that convergence in prob￾ability implies convergence in law. We have already proved that almost sure
convergence and convergence in r-th mean imply convergence in probability.324 Convergence in Probability, in Law and in r-th Mean
FIGURE 7.6
Poisson Distribution Approximation to Binomial Distribution
Thus, both the almost sure convergence and convergence in r-th mean imply
convergence in law. Consequently, convergence in law is the weakest form of
convergence discussed in Chapters 6 and 7.
Theorem 7.3.1. Suppose {Xn, n ≥ 1} is a sequence of random variables
defined on the probability space (Ω, A, P). Then Xn
P
→ X ⇒ Xn
L
→ X.
Proof. Suppose Fn(·) and FX(·) are distribution functions of Xn and X re￾spectively. Xn
L
→ X if Fn(x) → FX(x) ∀ x ∈ C(FX), provided limn→∞ Fn(x)
exists. We first check whether limn→∞ Fn(x) exists, that is, whether
lim supn→∞ Fn(x) = lim infn→∞ Fn(x), for all x ∈ C(FX). Note that
lim infn→∞ Fn(x) ≤ lim supn→∞ Fn(x) always. Thus it is enough to prove
that
FX(x) ≤ lim inf
n→∞
Fn(x) & lim sup
n→∞
Fn(x) ≤ FX(x) ∀ x ∈ C(FX) .
Observe that for any ϵ > 0,
Xn
P
→ X ⇒ limn→∞
P[|Xn − X| > ϵ] = 0
⇒ lim sup
n→∞
P[|Xn − X| > ϵ] = lim inf
n→∞
P[|Xn − X| > ϵ] = 0. (7.1)Convergence in Law 325
Note that for any real numbers x and x1 such that x1 < x,
P[X ≤ x1] = P[X ≤ x1, Xn ≤ x] + P[X ≤ x1, Xn > x]
≤ P[Xn ≤ x] + P[|Xn − X| > x − x1]
⇒ FX(x1) ≤ Fn(x) + P[|Xn − X| > x − x1]
⇒ lim inf
n→∞
FX(x1) ≤ lim inf
n→∞
Fn(x) + lim inf
n→∞
P[|Xn − X| > x − x1]
⇒ FX(x1) ≤ lim inf
n→∞
Fn(x), by Equation (7.1).
Similarly, for any real numbers x and x2 such that x < x2,
P[Xn ≤ x] = P[Xn ≤ x, X ≤ x2] + P[Xn ≤ x, X > x2]
≤ P[X ≤ x2] + P[|Xn − X| > x2 − x]
⇒ Fn(x) ≤ FX(x2) + P[|Xn − X| > x2 − x]
⇒ lim sup
n→∞
Fn(x) ≤ lim sup
n→∞
FX(x2) + lim sup
n⇒∞
P[|Xn − X| > x2 − x]
⇒ lim sup
n→∞
Fn(x) ≤ FX(x2), by Equation (7.1).
Consequently,
FX(x1) ≤ lim inf
n→∞
Fn(x) ≤ lim sup
n→∞
Fn(x) ≤ FX(x2). (7.2)
Suppose x1 = x − h1 and x2 = x + h2, h1, h2 > 0 and suppose x is a point of
continuity so that F is right continuous as well as left continuous at x. Hence,
as h1 → 0, FX(x1) = FX(x − h1) → FX(x)
and as h2 → 0, FX(x2) = FX(x + h2) → FX(x).
If h1, h2 → 0 in Equation (7.2), then
FX(x) ≤ lim inf
n→∞
Fn(x) ≤ lim sup
n→∞
Fn(x) ≤ FX(x).
Thus, ∀ x ∈ C(FX), limn→∞ Fn(x) exists and is given by FX(x) and hence,
Xn
L
→ X.
The next example illustrates Theorem 7.3.1.
Example 7.3.8. Suppose {X1, X2, · · · , Xn} are independent and identically
distributed random variables each having uniform U(0, 1) distribution. In Ex￾ample 7.2.5, it is shown that X(1)
P
→ 0 & X(n)
P
→ 1. Hence by Theorem
7.3.1, X(1)
L
→ 0 & X(n)
L
→ 1. We now prove the convergence in law using
the definition. From Example 7.2.5 we have,
FX(1) (x)=



0, if x < 0
1 − (1 − x)
n, if 0 ≤ x < 1
1, if x ≥ 1
&FX(n)
(x)=



0, if x < 0
x
n, if 0 ≤ x<1
1, if x ≥ 1.326 Convergence in Probability, in Law and in r-th Mean
Observe that,
FX(1) (x) →

0, if x < 0
1, if x ≥ 0
& FX(n)
(x) →

0, if x < 1
1, if x ≥ 1.
Hence, X(1)
L
→ 0 & X(n)
L
→ 1. □
In Theorem 7.3.1, we have proved that Xn
P
→ X ⇒ Xn
L
→ X. Thus,
Xn
L↛ X ⇒ Xn
P↛ X. The next example illustrates this assertion.
Example 7.3.9. Suppose {Xn, n ≥ 1} is a sequence of random variables such
that Xn ∼ U(−n, n) distribution. The distribution function of Xn is given by,
Fn(x) =



0, if x < −n
(x + n)/2n, if −n ≤ x < n
1, if x ≥ n.
Then ∀ x ∈ R, Fn(x) → 1/2. Thus, Fn(x) does not converge to a distribution
function and Xn
L↛ X, say. Now observe that,
for ϵ < n, P[|Xn| < ϵ] = P[−ϵ < Xn < ϵ] = (ϵ + n)/2n − (−ϵ + n)/2n
= ϵ/n → 0 as n → ∞
⇒ Xn
P↛ 0 ⇒ Xn
r↛ 0 and Xn
a.s. ↛ 0.
Thus, in this example, {Xn, n ≥ 1} does not converge almost surely, in prob￾ability, in r-th mean and in law. □
The converse Theorem 7.3.1 is not true in general. We illustrate this as￾sertion in the following two examples.
Example 7.3.10. Suppose an unbiased die is rolled many times. A random
variable Xn is defined as follows.
Xn =

1, if n-th toss results in an even number
0, if n-th toss results in an odd number.
The probability distribution of Xn is given by, P[Xn = 1] = P[Xn = 0] = 1/2,
since the die is unbiased. Hence its distribution function is given by,
Fn(x) =



0, if x ≤ 0
1/2, if 0 ≤ x < 1
1, if x ≥ 1.
It is the same for all n, and hence its limit is the same distribution function
as specified above. Thus, Xn
L
→ X, where the probability distribution of X is
the same as that of Xn. With Y = 1 − X, the probability distribution of Y is
given by, P[Y = 1] = P[Y = 0] = 1/2 and its distribution function is the sameConvergence in Law 327
as that of Xn and X. Hence, Xn
L
→ Y also. Since their distribution functions
are the same, X and Y are identically distributed random variables. However,
observe that if X(ω) = 0 then Y (ω) = 1 and if X(ω) = 1 then Y (ω) = 0.
Thus, P[X = Y ] = 0 and X and Y are not equivalent random variables. Now
using the result that for each n ≥ 1, Xn and X are identically distributed and
Y (ω) = 1 − X(ω), we have
P[|Xn − Y | > ϵ] = P[|X − (1 − X)| > ϵ] = P[|2X − 1| > ϵ] = 1 if ϵ < 1
and hence Xn
P↛ Y . Thus, Xn
L
→ Y but Xn
P↛ Y . □
Example 7.3.11. Suppose {Xn, n ≥ 1} is a sequence of random variables
such that Xn = −X, ∀ n ≥ 1 where X ∼ N(0, 1). Further, −X ∼ N(0, 1).
Thus,
Xn
d= X ⇒ Xn
L
→ X ∼ N(0, 1). However, for any ϵ > 0,
P[|Xn − X| > ϵ] = P[|X| > ϵ/2] ↛ 0, as n → ∞.
Hence, Xn
P↛ X. Thus, Xn
L
→ X but Xn
P↛ X. □
As noted in the above two examples, the converse of Theorem 7.3.1 is not
true. However, it is true if the limit random variable is a degenerate random
variable. We prove it in the following theorem.
Theorem 7.3.2. Suppose {Xn, n ≥ 1} is a sequence of random variables
defined on the probability space (Ω, A, P). Then Xn
L
→ C ⇐⇒ Xn
P
→ C,
where C is a constant.
Proof. By Theorem 7.3.1, Xn
P
→ C ⇒ Xn
L
→ C. Suppose Xn
L
→ C, that is,
Fn(x) → FC (x), ∀ x ∈ C(FC ), where FC (x) is given by,
FC (x) = 
0, if x < C
1, if x ≥ C.
Hence, the set C(FC ), of points of continuity of FC is given by R − {C}. To
check if Xn
P
→ C, consider for ϵ > 0,
P[|Xn − C| ≤ ϵ] = P[C − ϵ ≤ Xn ≤ C + ϵ] = Fn(C + ϵ) − Fn(C − ϵ−)
= Fn(C + ϵ) − Fn(C − ϵ) → 1 as n → ∞
and hence, Xn
P
→ C.
The following examples illustrate Theorem 7.3.2.
Example 7.3.12. Suppose {X1, X2, · · · , Xn} are independent and identically
distributed random variables each having uniform U(0, 1) distribution. In Ex￾ample 7.2.5, it is shown that X(1)
P
→ 0 & X(n)
P
→ 1. In Example 7.3.8, it is
shown that X(1)
L
→ 0 & X(n)
L
→ 1. Thus as proved in Theorem 7.3.2, if the
limit random variable is degenerate, then convergence in probability and law
are equivalent. □328 Convergence in Probability, in Law and in r-th Mean
Example 7.3.13. Suppose Xn ∼ N(0, 1/n) distribution. Then its distribu￾tion function Fn(x) is given by,
Fn(x) = P[Xn ≤ x] = P[
√
nXn ≤
√
nx] = Φ(√
nx).
Hence, Fn(x) →



0, if x < 0
1/2, if x = 0
1, if x > 0.
Note that the distribution function FX(x) of X ≡ 0 is given by,
FX(x) = 
0, if x < 0
1, if x ≥ 0,
Thus, as n → ∞,
Fn(x) → FX(x) ∀ x ∈ C(FX) = R − {0} ⇒ Xn
L
→ X ≡ 0
⇒ Xn
P
→ X ≡ 0, by Theorem 7.3.2.
We now verify whether Xn
P
→ X ≡ 0 using the definition. Observe that,
P[|Xn| > ϵ] ≤ E(X2
n
)/ϵ2 = 1/nϵ2 → 0 ∀ ϵ > 0 ⇒ Xn
P
→ 0.
Note that the limit law is degenerate and hence the sequence convergence in
law as well as in probability. □
Remark 7.3.1. The above example illustrates that a sequence of absolutely
continuous random variables converges in law to a discrete random variable.
Using Theorem 7.3.1, we prove an interesting result in the following theo￾rem, which is useful in many theorems and examples. Result (i) is heavily used
to show that under certain regularity conditions, with probability approaching
1, the likelihood equation has a consistent solution, refer to Deshmukh and
Kulkarni [11].
Theorem 7.3.3. (i) If Xn
P
→ C < 0, then P[Xn ≤ 0] → 1 as n → ∞.
(ii) If Xn
P
→ C > 0, then P[Xn > 0] → 1 as n → ∞.
Proof. From Theorem 7.3.1, Xn
P
→ C ⇒ Xn
L
→ C and hence FXn
(x) con￾verges to the distribution function of X ≡ C at all real numbers except C, it
being a point of discontinuity. Thus,
FXn
(x) = P[Xn ≤ x] →

0, if x < C
1, if x > C .
(i) Observe that if C < 0, P[Xn ≤ 0] → 1.
(ii) Further, if C > 0, P[Xn ≤ 0] → 0 ⇐⇒ P[Xn > 0] → 1.Convergence in Law 329
In Theorem 7.2.5, it is proved that convergence in probability is invariant
under continuous transforms. Following example shows that Xn
P
→ C and
g(Xn)
P
→ g(C), even if g is not continuous. It illustrates the application of
Theorem 7.3.3.
Example 7.3.14. Suppose Xn
P
→ C, C ∈ R. Suppose a function g : R → R
is defined as
g(x) = 
−1, if x < 1
1, if x ≥ 1.
It is clear that g is not a continuous function, 1 being a point of discontinuity,
and hence we cannot use Theorem 7.2.5 to claim g(Xn)
P
→ g(C). We verify
whether g(Xn)
P
→ g(C) from the first principles. We assume that P[Xn =
1] = 0. Suppose C ≥ 1, then g(C) = 1. Now,
P[|g(Xn) − g(C)| < ϵ] = P[|g(Xn) − 1| < ϵ] = P[1 − ϵ < g(Xn) < 1 + ϵ] = 1,
if ϵ > 2, as possible values of g(Xn) are −1 and 1.
For 0 < ϵ ≤ 2, P[1 − ϵ < g(Xn) < 1 + ϵ] = P[g(Xn) = 1] = P[Xn ≥ 1] .
Suppose now C < 1, then g(C) = −1. Observe that for ϵ > 2,
P[|g(Xn)−g(C)| < ϵ]=P[|g(Xn)−(−1)| < ϵ]=P[−1−ϵ < g(Xn) < −1+ϵ]= 1 .
For 0 < ϵ ≤ 2, P[−1−ϵ < g(Xn) < −1 +ϵ] = P[g(Xn) = −1] = P[Xn < 1] .
Now, we use Theorem 7.3.3 to show that P[Xn ≥ 1] and P[Xn < 1] converge
to 1. Suppose C < 1, then
Xn
P
→ C ⇒ Xn − 1
P
→ C − 1 < 0
⇒ P[Xn − 1 ≤ 0] → 1 as n → ∞
⇒ P[Xn ≤ 1] → 1 as n → ∞.
Now with the assumption that P[Xn = 1] = 0, [Xn ≤ 1] = [Xn < 1] → 1.
Thus, if C < 1 then P[Xn < 1] → 1. Suppose C ≥ 1, then
Xn
P
→ C ⇒ 1 − Xn
P
→ 1 − C ≤ 0
⇒ P[1 − Xn ≤ 0] → 1 as n → ∞
⇒ P[Xn ≥ 1] → 1 as n → ∞.
Thus, if C ≥ 1 then P[Xn ≥ 1] → 1. Hence we claim that g(Xn)
P
→ g(C) for
all C ∈ R. Observe that for
ϵ = 2 & C = 8, P[|g(Xn) − C| < ϵ] = P[6 < g(Xn) < 10] = 0
and hence g(Xn) does not converge in probability to C, which has to be true
in view of the fact that the limit random variable in convergence in probability
is almost surely unique. □330 Convergence in Probability, in Law and in r-th Mean
Remark 7.3.2. It is to be noted that in the above example, the probability
measure assigned to the set of points of discontinuity is 0.
In Example 7.3.10, it is shown that Xn
L
→ X and Xn
L
→ Y = 1−X, where
X and Y are identically distributed. It is also noted that,
{ω|X(ω) = 1} = {ω|Y (ω) = 0} & {ω|X(ω) = 0} = {ω|Y (ω) = 1}
⇒ P[X = Y ] = 0.
Thus, X and Y are not equivalent random variables, but they are identically
distributed random variables. From this example, we note that, as in almost
sure convergence and convergence in probability, the limit random variables
in convergence in law are not equivalent random variables. However, they are
identically distributed random variables. It is true in general and is proved in
the following theorem.
Theorem 7.3.4. If Xn
L
→ X and Xn
L
→ Y , then X and Y are identically
distributed random variables.
Proof. By definition of convergence in law,
Xn
L
→ X ⇒ Fn(x) → FX(x) ∀ x ∈ C(FX)
& Xn
L
→ Y ⇒ Fn(x) → FY (x) ∀ x ∈ C(FY ),
where C(FX) and C(FY ) are sets of points of continuity of FX(x) and FY (x)
respectively. By Theorem 3.2.4, C(FX) ∩ C(FY ) ̸= ∅. Now,
∀ x ∈ C(FX) ∩ C(FY ), Fn(x) → FX(x) and Fn(x) → FY (x).
Note that {Fn(x), n ≥ 1} is a sequence of real numbers converging to FX(x)
and FY (x). Since the limit of a convergent sequence of real numbers is unique,
FX(x) = FY (x), ∀ x ∈ C(FX) ∩ C(FY ).
Now suppose x ∈ (C(FX) ∩ C(FY ))c
. Again as in Theorem 3.2.4, if
x ∈ (C(FX) ∩ C(FY ))c
, then there exists a sequence {x + rn, n ≥ 1} of points
in C(FX) ∩ C(FY ) such that x + rn → x, as rn ↓ 0. Further, using the right
continuity of distribution functions, we have for x ∈ (C(FX) ∩ C(FY ))c
,
FX(x) = lim
h↓0
FX(x + h) = lim
rn↓0
FX(x + rn)
= lim
rn↓0
FY (x + rn) = lim
h↓0
FY (x + h) = FY (x).
Thus, FX(x) = FY (x) ∀ x ∈ R and hence X and Y are identically distributed
random variables.Convergence in Law 331
The following theorem states that if the difference Xn − Yn converges
to zero in probability, then both {Xn, n ≥ 1} and {Yn, n ≥ 1} have the
same limit law. It is an important result since it is heavily used in asymptotic
inference theory to decide the asymptotic distribution of a suitably normalized
estimator. The proof is similar to that of Theorem 7.3.1.
Theorem 7.3.5. Suppose {Xn, n ≥ 1} and {Yn, n ≥ 1} are sequences of
random variables defined on the same probability space (Ω, A, P). If Xn−Yn
P
→
0 and Yn
L
→ X, then Xn
L
→ X.
Proof. It is given that Xn − Yn
P
→ 0, hence ∀ ϵ > 0
limn→∞
P[|Xn − Yn| > ϵ] = 0
⇒ lim inf
n→∞
P[|Xn − Yn| > ϵ] = lim sup
n→∞
P[|Xn − Yn| > ϵ] = 0. (7.3)
To prove that Xn
L
→ X, we show that FXn
(x) → FX(x) ∀ x ∈
C(FX), provided limn→∞ FXn
(x) exists, that is, lim supn→∞ FXn
(x) =
lim infn→∞ FXn
(x), for all x ∈ C(FX). Further, lim infn→∞ FXn
(x) ≤
lim supn→∞ FXn
(x) is always true. Thus as in Theorem 7.3.1, it is enough
to prove that
FX(x) ≤ lim inf
n→∞
FXn
(x) & lim sup
n→∞
FXn
(x) ≤ FX(x) ∀ x ∈ C(FX) .
Now, Yn
L
→ X ⇒ FYn
(x) → FX(x), ∀ x ∈ C(FX)
⇒ lim inf
n→∞
FYn
(x) = lim sup
n→∞
FYn
(x) = FX(x) ∀ x ∈ C(FX).
These results suggest that we have to find some inequalities between the dis￾tribution functions of Xn and Yn. Observe that for any real numbers x and
x1 such that x1 < x,
P[Yn ≤ x1] = P[Yn ≤ x1, Xn ≤ x] + P[Yn ≤ x1, Xn > x]
≤ P[Xn ≤ x] + P[|Xn − Yn| > x − x1]
⇒ FYn
(x1) ≤ FXn
(x) + P[|Xn − Yn| > x − x1]
⇒ lim inf
n→∞
FYn
(x1) ≤ lim inf
n→∞
FXn
(x) + lim inf
n→∞
P[|Xn − Yn| > x − x1]
⇒ lim inf
n→∞
FYn
(x1) ≤ lim inf
n→∞
FXn
(x) by Equation (7.3).
Now, for any real numbers x and x2 such that x < x2,
P[Xn ≤ x] = P[Xn ≤ x, Yn ≤ x2] + P[Xn ≤ x, Yn > x2]
≤ P[Yn ≤ x2] + P[|Xn − Yn| > x2 − x]
⇒ FXn
(x) ≤ FYn
(x2) + P[|Xn − Yn| > x2 − x]
⇒ lim sup
n→∞
FXn
(x) ≤ lim sup
n→∞
FYn
(x2) + lim sup
n→∞
P[|Xn − Yn| > x2 − x]
⇒ lim sup
n→∞
FXn
(x) ≤ lim sup
n→∞
FYn
(x2) by Equation (7.3).332 Convergence in Probability, in Law and in r-th Mean
Thus we have,
lim inf
n→∞
FYn
(x1) ≤ lim inf
n→∞
FXn
(x) ≤ lim sup
n→∞
FXn
(x) ≤ lim sup
n→∞
FYn
(x2) . (7.4)
Suppose x1 and x2 are points of continuity of FX. Hence,
lim inf
n→∞
FYn
(x1) = limn→∞
FYn
(x1) = FX(x1)
& lim sup
n→∞
FYn
(x2) = limn→∞
FYn
(x2) = FX(x2) .
Consequently, Equation (7.4) reduces to
FX(x1) ≤ lim inf
n→∞
FXn
(x) ≤ lim sup
n→∞
FXn
(x) ≤ FX(x2). (7.5)
Suppose x1 = x−h1 and x2 = x+h2, h1, h2 > 0 and x is a point of continuity
of FX. Hence,
h1 → 0 ⇒ FX(x1) = FX(x − h1) → FX(x)
& h2 → 0 ⇒ FX(x2) = FX(x + h2) → FX(x).
Suppose h1, h2 → 0 in Equation (7.5), then
FX(x) ≤ lim inf
n→∞
FXn
(x) ≤ lim sup
n→∞
FXn
(x) ≤ FX(x) .
Thus, ∀ x ∈ C(FX), limn→∞ FXn
(x) exists and is given by FX(x) and hence
Xn
L
→ X.
The following example illustrates the result obtained in Theorem 7.3.5 and
how to identify the limiting distribution. The limit law in this example comes
out to be a distribution function which is neither discrete nor continuous. We
decompose it according to the Jordan decomposition theorem, as discussed in
Chapter 3.
Example 7.3.15. Suppose X ∼ N(θ, 1) distribution and θ ∈ Θ = [a, b]. It
can be shown that (Deshmukh and Kulkarni [11]) the maximum likelihood
estimator ˆθn of θ, based on a random sample of size n from the distribution
of X is given by,
ˆθn =



a, if Xn < a
Xn, if Xn ∈ [a, b]
b, if Xn > b.
We first examine whether ˆθn
P
→ θ and investigate the limit law of
Un =
√
n(
ˆθn − θ). Since X ∼ N(θ, 1), Xn ∼ N(θ, 1/n) distribution for each n
and hence √
n(Xn − θ) ∼ N(0, 1) distribution for each n. Hence for all ϵ > 0
and for all θ ∈ Θ,
Pθ[|Xn − θ| < ϵ] = Φ(ϵ
√
n) − Φ(−ϵ
√
n) → 1 ⇒ Xn
P
→ θ ⇒ Xn
L
→ θ.Convergence in Law 333
Now for ϵ > 0 and θ ∈ (a, b),
Pθ[|
ˆθn − Xn| < ϵ] ≥ Pθ[
ˆθn = Xn] = Pθ[a ≤ Xn ≤ b]
= Φ(√
n(b − θ)) − Φ(√
n(a − θ)) → 1
⇒ ˆθn − Xn
P
→ 0
⇒ ˆθn
L
→ θ ⇒ ˆθn
P
→ θ,
by Theorem 7.3.5 and Theorem 7.3.2. Now we examine convergence in prob￾ability at the boundary points a and b. Since ˆθn ≥ a, for θ = a we have,
Pa[|
ˆθn − a| > ϵ] = 
Pa[
ˆθn > a + ϵ] = 0 , if ϵ > b − a
Pa[Xn > a + ϵ] = 1 − Φ(√
nϵ) → 0, if ϵ ≤ b − a.
Thus, ˆθn →
Pa
a. Further, ˆθn ≤ b implies that the event [|
ˆθn −b| > ϵ] is the same
as [b − ˆθn > ϵ]. Hence for the boundary point b,
Pb[|
ˆθn − b| > ϵ] = 
Pb[
ˆθn < b − ϵ] = 0 , if ϵ > b − a
Pb[Xn < b − ϵ] = Φ(−
√
nϵ) → 0, if ϵ ≤ b − a.
Hence, ˆθn →
Pb
b. Thus, we have shown that ∀ θ ∈ [a, b],
ˆθn
P
→ θ. We now
investigate the limit law of Un =
√
n(
ˆθn −θ). If X ∼ N(θ, 1) distribution then
Yn =
√
n(Xn − θ) has the standard normal distribution for all θ ∈ [a, b] and
for all n. Thus, Yn
L
→ Z, where Z ∼ N(0, 1). Now
Un − Yn =
√
n(
ˆθn − θ) −
√
n(Xn − θ) = √
n(
ˆθn − Xn) and ∀ ϵ > 0,
P[|Un − Yn| < ϵ] = P[
√
n|
ˆθn − Xn| < ϵ]
≥ P[
ˆθn = Xn] = P[a ≤ Xn ≤ b]
= Φ ￾√
n(b − θ)

− Φ
￾√
n(a − θ)

→ 1 − 0 = 1 as n → ∞, ∀ θ ∈ (a, b).
Thus, Un−Yn
P
→ 0. Hence, the limit law of Un and Yn is the same ∀ θ ∈ (a, b).
But for all θ ∈ (a, b) Yn
L
→ Z and hence by Theorem 7.3.5, Un
L
→ Z ∼ N(0, 1).
To find the limit law of Un at θ = a, we study the limit of Pa[
√
n(
ˆθn −a) ≤ x]
for all x ∈ R. Since ˆθn ≥ a, for x < 0, Pa[
√
n(
ˆθn −a) ≤ x] = 0. Suppose x = 0.
Then
Pa[
√
n(
ˆθn − a) ≤ 0] = Pa[
√
n(
ˆθn − a) = 0] = Pa[
ˆθn = a] = Pa[Xn < a]
= Pa[
√
n(Xn − a) < 0] = Φ(0) = 1/2.
From the expression of ˆθn, we have ˆθn ≤ b ⇒
√
n(
ˆθn − a) ≤
√
n(b − a).
Suppose 0 < x < √
n(b − a). Then
Pa[
√
n(
ˆθn − a) ≤ x] = Pa[
√
n(
ˆθn − a) ≤ 0] + Pa[0 <
√
n(
ˆθn − a) ≤ x]
= 1/2 + Pa[0 <
√
n(Xn − a) ≤ x]
= 1/2 + Φ(x) − 1/2 = Φ(x334 Convergence in Probability, in Law and in r-th Mean
If x ≥
√
n(b − a), then Pa[
√
n(
ˆθn − a) ≤ x] = 1. Thus,
Pa[
√
n(
ˆθn − a) ≤ x] =



0, if x < 0
1/2 = Φ(x), if x = 0
Φ(x), if 0 < x < √
n(b − a)
1, if x ≥
√
n(b − a) .
Hence, Pa[
√
n(
ˆθn − a) ≤ x] →

0, if x < 0
Φ(x), if x ≥ 0 .
Thus for θ = a, the limit law of Un is not normal, and 0 is a point of discontinu￾ity. We now show that it is a mixture of discrete and continuous distributions,
and the continuous distribution is related to the standard normal distribution.
Suppose W1 is a random variable with a distribution degenerate at 0. Then
its distribution function is given by,
FW1
(x) = 
0, if x < 0
1, if x ≥ 0 .
Suppose a random variable W2 is defined as W2 = |Z| where Z ∼ N(0, 1).
Then P[W2 ≤ x] = 0 if x < 0. Suppose x ≥ 0, then
P[W2 ≤ x] = P[|Z| ≤ x] = P[−x ≤ Z ≤ x] = Φ(x) − Φ(−x) = 2Φ(x) − 1.
Thus, the distribution function of W2 is given by,
FW2
(x) = 
0, if x < 0
2Φ(x) − 1, if x ≥ 0 .
It is easy to verify that
Pa[
√
n(
ˆθn − a) ≤ x] → (1/2)FW1
(x) + (1/2)FW2
(x).
To find the limit law of Un at θ = b, we adopt the similar procedure as that
for θ = a and study the limit of Pb[
√
n(
ˆθn−b) ≤ x] for all x ∈ R. By definition
ˆθn ≥ a, so that √
n(
ˆθn − b) ≥
√
n(a − b) < 0. Hence, for x < √
n(a − b),
Pb[
√
n(
ˆθn − b) ≤ x] = 0. Suppose √
n(a − b) ≤ x < 0, then
Pb[
√
n(
ˆθn − b) ≤ x] = Pb[
√
n(Xn − b) ≤ x] = Φ(x).
Suppose x = 0. Then Pb[
√
n(
ˆθn − b) ≤ 0] = Pb[
ˆθn ≤ b] = 1. Suppose x > 0.
By definition, ˆθn ≤ b implying that √
n(
ˆθn − b) ≤ 0, hence Pb[
√
n(
ˆθn − b) ≤
x] = 1, ∀ x > 0. Thus,
Pb[
√
n(
ˆθn − b) ≤ x] =



0, if x < √
n(a − b)
Φ(x), if √
n(a − b) ≤ x < 0
1, if x ≥ 0 .Convergence in Law 335
Consequently, as n → ∞,
Pb[
√
n(
ˆθn − b) ≤ x] →

Φ(x), if x < 0
1, if x ≥ 0 .
Note that as in the case of θ = a, the limit law of Un is not normal at θ = b,
and 0 is a point of discontinuity. Further, the limit law is a mixture of discrete
and continuous distributions, as shown below. Suppose a random variable W3
is defined as W3 = −|Z| where Z ∼ N(0, 1). Since W3 ≤ 0, P[W3 ≤ x] = 1
for all x ≥ 0. Suppose x < 0, then
P[W3 ≤ x] = P[|Z| ≥ −x] = 1−P[x ≤ Z ≤ −x] = 1−Φ(−x)+Φ(x) = 2Φ(x).
Thus, the distribution function of W3 is given by,
FW3
(x) = 
2Φ(x), if x < 0
1, if x ≥ 0 .
It then follows that Pb[
√
n(
ˆθn − b) ≤ x] → (1/2)FW1
(x) + (1/2)FW3
(x). □
In Section 2, we have proved that convergence in probability is closed under
continuous transformation. Similarly, convergence in law is also closed under
continuous transformation. This result is known as a continuous mapping
theorem. We state it below. For proof, refer to Billingsley [5].
Theorem 7.3.6. Continuous mapping theorem: If Xn
L
→ X and g is a con￾tinuous function, then g(Xn)
L
→ g(X).
Following example presents some illustrations of the continuous mapping
theorem.
Example 7.3.16. Suppose Xn
L
→ X. With different choices for a continuous
function g, we have the following results. (i) −Xn
L
→ −X. (ii) |Xn|
L→ |X|.
(iii) Suppose g(x) = a0 +a1x+a2x
2
. Then a0 +a1Xn +a2Xn2 L
→ a0 +a1X +
a2X2
. (iv) Suppose X has exponential distribution with location parameter
0 and scale parameter 1. Then the distribution of U = exp(−X) is uniform
U(0, 1). Hence, exp(−Xn)
L
→ exp(−X) = U ∼ U(0, 1) distribution. (v) If
X ∼ N(0, 1) distribution, then X2
n
L
→ X2 ∼ χ
2
1
.
It is proved in Lemma 7.2.1 that if the sequence {Xn, n ≥ 1} converges
in probability, then it is bounded in probability. A similar result is true if the
sequence {Xn, n ≥ 1} converges in law. It is proved in the following lemma.
Lemma 7.3.1. If the sequence {Xn, n ≥ 1} converges in law, then it is
bounded in probability.
Proof. Suppose Xn
L
→ X, that is, ∀ x ∈ C(FX), Fn(x) → FX(x). To prove
that {Xn, n ≥ 1} is bounded in probability, given ϵ > 0 we have to find M336 Convergence in Probability, in Law and in r-th Mean
and n0 such that P[|Xn| ≤ M] > 1−ϵ for all n ≥ n0. Since the set of points of
continuities of a distribution function is uncountable, any distribution function
can have arbitrarily large continuity points. Suppose M1 > 0 and −M2 < 0 are
points of continuity of FX such that FX(M1) > 1 − ϵ/4 and FX(−M2) < ϵ/4.
Since M1 and −M2 are points of continuity of FX, Fn(M1) → FX(M1) and
Fn(−M2) → FX(−M2). Thus, for ϵ > 0, there exists n0 such that ∀ n ≥ n0,
|Fn(M1) − FX(M1)| < ϵ/4 & |Fn(−M2) − FX(−M2)| < ϵ/4
⇒ Fn(M1) > FX(M1) − ϵ/4 > 1 − ϵ/2
& Fn(−M2) < FX(−M2) + ϵ/4 < ϵ/2
⇒ P[−M2 < Xn ≤ M1] = Fn(M1) − Fn(−M2) > 1 − ϵ
⇒ P[|Xn| ≤ M] ≥ P[−M2 < Xn ≤ M1] > 1 − ϵ,
where M = max{|M1|, |M2|}+ 1. Thus, the sequence {Xn, n ≥ 1} is bounded
in probability.
Theorem 7.3.7. If Xn
L
→ X and if Yn
P
→ 0, then XnYn
P
→ 0 and XnYn
L
→ 0.
Proof. Since Xn
L
→ X, the sequence {Xn, n ≥ 1} is bounded in probability.
Hence, by Theorem 7.2.7, we claim that XnYn
P
→ 0. The result can be proved
using the definition of convergence in probability as follows. For any ϵ > 0,
note that P[|XnYn| > ϵ] = 0 for all those ω for which Yn(ω) = 0. Further, for
any ϵ > 0 and δ > 0 and for all ω such that Yn(ω) = 0 ̸ , observe that
P[|XnYn| > ϵ] = P[|XnYn| > ϵ, |Yn| ≤ δ] + P[|XnYn| > ϵ, |Yn| > δ]
≤ P [|Xn| > ϵ/δ] + P[|Yn| > δ] → 0,
using the result that the sequence {Xn, n ≥ 1} is bounded in probability for
the first term, and Yn
P
→ 0 for the second term. Thus, XnYn
P
→ 0 and hence
XnYn
L
→ 0 .
As in almost sure convergence and convergence in probability, convergence
in law is closed under arithmetic operations, under a restrictive setup, in
the sense that one of the two limit laws must be degenerate. Of course, if
the limit law is degenerate, convergence in probability and convergence in law
are equivalent, as proved in Theorem 7.3.2. The theorem proving the closure of
convergence in law under arithmetic operations is known as Slutsky’s theorem.
It is also referred to as Cramer’s theorem (Gut [13]). It is heavily used in the
studentization procedure to construct a large sample confidence interval and
also in deriving the large sample null distribution of some test statistics. We
prove it below.
Theorem 7.3.8. Slutsky’s theorem: Suppose {Xn, n ≥ 1} and {Yn, n ≥ 1} are
sequences of random variables defined on the same probability space (Ω, A, P).Convergence in Law 337
If Xn
L
→ X and Yn
L
→ C, where C is a degenerate random variable, then
(i) Xn + Yn
L
→ X + C, (ii) Xn − Yn
L
→ X − C, (iii) XnYn
L
→ XC and
(iv) Xn/Yn
L
→ X/C, provided Xn/Yn and X/C are defined.
Proof. (i) Note that,
Yn
L
→ C ⇒ Yn
P
→ C ⇒ (Xn + Yn) − (Xn + C) = Yn − C
P
→ 0.
Hence by Theorem 7.3.5, limit law of (Xn+Yn) is the same as that of (Xn+C).
We find the limit law of (Xn + C) as follows. Observe that
FXn+C (x) = P[Xn + C ≤ x] = P[Xn ≤ x − C]
= Fn(x − C) → FX(x − C) = P[X ≤ x − C] = FX+C (x),
provided x − C is a point of continuity of FX. Now, Xn + C
L
→ X + C if x
is a point of continuity of FX+C . To establish it, suppose x − C is a point of
continuity of FX. FX being a distribution function, is always right continuous.
Hence, x − C is a point of continuity of FX implies that,
lim
h→0
FX(x − C − h) = FX(x − C)
⇐⇒ lim
h→0
P[X ≤ x − C − h] = P[X ≤ x − C]
⇐⇒ lim
h→0
P[X + C ≤ x − h] = P[X + C ≤ x]
⇐⇒ lim
h→0
FX+C (x − h) = FX+C (x).
Thus, x is a point of continuity of FX+C . Thus, Xn + C
L
→ X + C and hence,
Xn + Yn
L
→ X + C.
(ii) Observe that Yn
P
→ C ⇒ − Yn
P
→ −C. Hence by (i) Xn − Yn
L
→ X − C.
(iii) If C = 0, then the result follows from Theorem 7.3.7. Hence we now
assume that C ̸= 0. To prove (iii), we adopt an approach different than in (i).
We make two cases depending on C > 0 and C < 0.
Case(a) C > 0: Suppose x ∈ R is such that x/C ∈ C(FX). Hence,
lim
h→0
FX(x/C − h) = FX(x/C)
⇐⇒ lim
h→0
P[X ≤ x/C − h] = P[X ≤ x/C]
⇐⇒ lim
h→0
P[XC ≤ x − Ch] = P[XC ≤ x]
⇐⇒ lim
h→0
FXC (x − Ch) = FXC (x).
Thus, x is a point of continuity of FXC . Suppose ϵ > 0 is such that x/(C − ϵ)
and x/(C + ϵ) are in C(FX). It is posiible since C(FX) is dense in R. For
large n we assume Yn > 0, it is valid since by Theorem 7.3.3, P[Yn > 0] → 1.
Observe that
|Yn − C| ≤ ϵ ⇒ 1/(C + ϵ) ≤ 1/Yn ≤ 1/(C − ϵ). (7.6)338 Convergence in Probability, in Law and in r-th Mean
Suppose x > 0. Note that
FXnYn (x) = P[XnYn ≤ x] = P[XnYn ≤ x, |Yn − C| ≤ ϵ]
+ P[XnYn ≤ x, |Yn − C| > ϵ]
≤ P[Xn ≤ x/Yn, |Yn − C| ≤ ϵ] + P[|Yn − C| > ϵ]
≤ P[Xn ≤ x/(C − ϵ)] + P[|Yn − C| > ϵ]
⇒ lim sup FXnYn (x) ≤ lim sup P[Xn ≤ x/(C − ϵ)] + lim sup P[|Yn − C| > ϵ]
⇒ lim sup FXnYn (x) ≤ lim sup FXn (x/(C − ϵ)). (7.7)
Further observe that,
FXn (x/(C + ϵ)) = P[Xn ≤ x/(C + ϵ)]
= P[Xn ≤ x/(C + ϵ), |Yn − C| ≤ ϵ]
+ P[Xn ≤ x/(C + ϵ), |Yn − C| > ϵ]
≤ P[Xn ≤ x/Yn] + P[|Yn − C| > ϵ]
⇒ lim inf FXn (x/(C + ϵ)) ≤ lim inf P[XnYn ≤ x] + lim inf P[|Yn − C| > ϵ]
⇒ lim inf FXn (x/(C + ϵ)) ≤ lim inf FXnYn (x). (7.8)
From Equation (7.7) and Equation (7.8), we have
lim inf FXn
(x/(C + ϵ)) ≤ lim inf P[XnYn ≤ x] ≤ lim sup FXnYn
(x)
≤ lim sup P[Xn ≤ x/(C − ϵ)]
⇒ lim FXn
(x/(C + ϵ)) ≤ lim inf P[XnYn ≤ x] ≤ lim sup FXnYn
(x)
≤ lim P[Xn ≤ x/(C − ϵ)]
⇒ FXnYn
(x) → FX(x/C) = FXC (x),
since ϵ is arbitrary. If x ≤ 0, then the entire derivation of Case (a) goes through
with C − ϵ interchanged with C + ϵ.
Case(b) C < 0: Suppose x ∈ R is such that x/C ∈ C(FX). Hence,
P[X ≤ x/C] = P[X < x/C]. We select h such that as h ↓ 0, x/C−h ∈ C(FX),
it is possible since C(FX) is dense in R. Thus,
lim
h→0
FX(x/C − h) = FX(x/C)
⇐⇒ lim
h→0
P[X ≤ x/C − h] = P[X ≤ x/C]
⇐⇒ lim
h→0
P[X < x/C − h] = P[X < x/C]
⇐⇒ lim
h→0
P[XC > x − Ch] = P[XC > x]
⇐⇒ lim
h→0
1 − FXC (x − Ch) = 1 − FXC (x)
⇐⇒ lim
h→0
FXC (x − Ch) = FXC (x)
Thus, x is a point of continuity of FXC . Suppose ϵ > 0 is such that x/(C − ϵ)
and x/(C + ϵ) are in C(FX). For large n we assume Yn ≤ 0, it is valid sinceConvergence in Law 339
Theorem 7.3.3, P[Yn ≤ 0] → 1. By Equation (7.6), 1/(C + ϵ) < 1/Yn <
1/(C − ϵ). Suppose x > 0. Note that
FXnYn
(x) = P[XnYn ≤ x] = P[XnYn ≤ x, |Yn − C| < ϵ]
+ P[XnYn ≤ x, |Yn − C| ≥ ϵ]
≤ P[Xn ≥ x/Yn, |Yn − C| < ϵ] + P[|Yn − C| ≥ ϵ]
≤ P[Xn > x/(C + ϵ)] + P[|Yn − C| ≥ ϵ]
⇒ lim sup FXnYn
(x) ≤ lim sup P[Xn > x/(C + ϵ)] + lim sup P[|Yn− C| > ϵ]
⇒ lim sup FXnYn
(x) ≤ lim sup P[Xn > x/(C + ϵ)]. (7.9)
Further,
P[Xn > x/(C − ϵ)] = P[Xn > x/(C − ϵ), |Yn − C| < ϵ]
+ P[Xn > x/(C − ϵ), |Yn − C| ≥ ϵ]
≤ P[Xn > x/Yn] + P[|Yn − C| ≥ ϵ]
⇒ lim inf P[Xn > x/(C − ϵ)] ≤ lim inf P[XnYn < x] + lim inf P[|Yn− C| ≥ ϵ]
⇒ lim inf P[Xn > x/(C − ϵ)] ≤ lim inf P[XnYn ≤ x]
⇒ lim inf P[Xn > x/(C − ϵ)] ≤ lim inf FXnYn
(x). (7.10)
In the second last step, note that P[XnYn < x] ≤ P[XnYn ≤ x]. Since
x/(C − ϵ) ∈ C(FX), observe that
FXn
(x/(C − ϵ)) → FX(x/(C − ϵ))
⇒ P[Xn ≤ x/(C − ϵ)] → P[X ≤ x/(C − ϵ)]
⇒ P[Xn > x/(C − ϵ)] → P[X > x/(C − ϵ)] = P[X ≥ x/(C − ϵ)]. (7.11)
Similarly, x/(C + ϵ) ∈ C(FX) implies that
P[Xn > x/(C + ϵ)] → P[X > x/(C + ϵ)] = P[X ≥ x/(C + ϵ)]. (7.12)
From Equations (7.9), (7.10), (7.11) and (7.12), we have
lim inf P[Xn > x/(C − ϵ)] ≤ lim inf FXnYn
(x) ≤ lim sup FXnYn
(x)
≤ lim sup P[Xn > x/(C + ϵ)]
⇒ P[X ≥ x/(C − ϵ)] ≤ lim inf P[XnYn ≤ x] ≤ lim sup FXnYn
(x)
≤ P[X ≥ x/(C + ϵ)]
⇒ lim P[XnYn ≤ x] = P[X ≥ x/C] as ϵ is arbitrary
⇒ lim P[XnYn ≤ x] = P[XC ≤ x] = FXC (x) as C < 0.
If x ≤ 0, then the entire derivation of Case(b) goes through with C − ϵ
interchanged with C +ϵ. Thus, it is proved that if Xn
L
→ X and Yn
L
→ C, then
XnYn
L
→ XC for all C ∈ R.
(iv) Note that Yn
P
→ C ⇒ 1/Yn
P
→ 1/C. Hence by (iii) Xn/Yn
L
→ X/C,
provided Xn/Yn and X/C are defined.340 Convergence in Probability, in Law and in r-th Mean
Following corollaries follow immediately from Slutsky’s theorem.
Corollary 7.3.1. If Xn
L
→ X, then a+bXn
L
→ a+bX. The result also follows
from the continuous mapping theorem. As a particular case, with a = 0 and
b = −1, −Xn
L
→ −X.
Corollary 7.3.2. If Xn
L
→ X and Un and Vn converge in probability to
constants a and b respectively, then Un + VnXn
L
→ a + bX.
The following example illustrates Slutsky’s theorem, in which we show that
Student’s tn distribution converges in law to the standard normal distribution
as the degrees of freedom n → ∞.
Example 7.3.17. Suppose a random variable Yn is defined as Yn =
Un/
p
Vn/n where Un ∼ N(0, 1) distribution, Vn ∼ χ
2
n distribution and Un
and Vn are independent random variables. Then Yn ∼ tn distribution. Since
Un ∼ N(0, 1) distribution for each n, Un
L
→ Z ∼ N(0, 1). Further, Vn ∼ χ
2
n
distribution hence E(Vn) = n and V ar(Vn) = 2n. By Chebyshev’s inequality,
as n → ∞,
P [|Vn/n − 1| > ϵ] ≤ (E (Vn/n − 1)2
)/ϵ2 = V ar(Vn)/n2
ϵ
2 = 2/nϵ2 → 0.
Thus, Vn/n P
→ 1. Hence, by the invariance of convergence in probability under
continuous transformation, p
Vn/n P
→ 1. Further, by Slutsky’s theorem
Yn = Un/
p
Vn/n L
→ Z ∼ N(0, 1). Thus, Student’s tn distribution converges
in law to the standard normal distribution as degrees of freedom n → ∞. □
Theorem 7.3.7 is heavily used in large sample inference to show that the
remainder term converges to 0, as is clear from the proof of the following result,
which is the well-known delta method in asymptotic inference. We prove it
below in inference terminology. We also use Slutsky’s theorem. We first prove
a lemma.
Lemma 7.3.2. If Un =
√
n(Xn − µ)
L
→ X, then Xn
P
→ µ.
Proof. It is given that Un
L
→ X and hence by Lemma 7.3.1, Un is bounded in
probability. Further, 1/
√
n → 0 and hence by Theorem 7.3.7,
(Xn − µ) = (1/
√
n)(√
n(Xn − µ)) = (1/
√
n)Un
P
→ 0 ⇒ Xn
P
→ µ.
As an application of this lemma, if an estimator Tn of a parameter µ, is
such that √
n(Tn − µ)
L
→ X, then it is consistent for µ.
Theorem 7.3.9. Delta method: Suppose Tn is an estimator of µ such that
√
n(Tn − µ)
L
→ X ∼ N(0, σ2
) distribution. Suppose g is a differentiable func￾tion with g
′
(µ) ̸= 0, then √
n(g(Tn) − g(µ)) L
→ Y ∼ N(0,(g
′
(µ))2σ
2
) distribu￾tion.Convergence in Law 341
Proof. It is given that Un =
√
n(Tn − µ)
L
→ X ∼ N(0, σ2
) distribution. Since
g is a differentiable function with g
′
(µ) ̸= 0, by the Taylor series expansion,
g(Tn) = g(µ) + (Tn − µ)g
′
(µ) + Rn, where |Rn| ≤ M|Tn − µ|
1+δ
, δ > 0 .
Thus,
√
n(g(Tn) − g(µ)) = √
n(Tn − µ)g
′
(µ) + √
nRn
L
→ Y ∼ N(0,(g
′
(µ))2σ
2
),
provided √
nRn
P
→ 0. Now, |
√
nRn| ≤ M
√
n|Tn − µ||Tn − µ|
δ
. As shown
in Lemma 7.3.2, (Tn − µ)
P
→ 0, hence |Tn − µ|
δ P
→ 0, since convergence in
probability is invariant under continuous transformation. Further,
√
n(Tn −µ)
L
→ X ⇒
√
n|Tn −µ|
L→ |X|, by continuous mapping theorem
and hence √
n|Tn − µ| is bounded in probability. As a consequence,
√
n|Tn − µ||Tn − µ|
δ P
→ 0 ⇒
√
nRn
P
→ 0 ⇒
√
n(g(Tn) − g(µ)) L
→ Y ,
by Slutsky’s theorem, where Y follows normal N(0,(g
′
(µ))2σ
2
) distribution.
Remark 7.3.3. In the delta method, it is assumed that g is differentiable
and hence it is continuous. Thus, by the continuous mapping theorem
g(
√
n(Tn − µ)) L
→ g(X). It is known that if X is normally distributed, then
only linear functions of X will have a normal distribution. Observe that
g(
√
n(Tn − µ)) = √
n(g(Tn) − g(µ)) if g is a linear function. However, the
delta method is valid for any differentiable function g such that g
′
(µ) ̸= 0
and for any such function, g(X) has a normal distribution. Hence the result,
which says that √
n(g(Tn) − g(µ)) also converges to a normal distribution,
may seem surprising. However, from the proof of the delta method, we note
that √
n(g(Tn) − g(µ)) is expressed as a linear function of √
n(Tn − µ) with
an additional term which converges to zero in probability, and hence we get
that √
n(g(Tn) − g(µ)) converges to a normal distribution, even if g is not a
linear function.
The delta method provides a basis for deriving variance stabilizing trans￾formations, that is, transformations leading to an asymptotic variance free
from the parameter. Such transformations are helpful in finding large sam￾ple confidence intervals for the parameter of interest. It is illustrated in the
following example.
Example 7.3.18. Suppose {X1, X2, · · · , Xn} is a random sample from nor￾mal N(θ, θ2
) distribution, θ > 0. Then Tn =
√
n(Xn − θ) ∼ N(0, θ2
) distri￾bution. We now find a differentiable function g such that (g
′
(θ))2 ̸= 0 and
V ar(g(Xn)) is free from θ, that is (g
′
(θ))2
θ
2 = c
2
, that is, g(θ) = R
c dθ
θ =
c log θ. Hence,
Qn =
√
n(log Xn − log θ)
L
→ Z ∼ N(0, 1) ⇒ Qn is a pivotal quantity.342 Convergence in Probability, in Law and in r-th Mean
Thus, we find a(1−α/2) such that P[−a(1−α/2) < Qn < a(1−α/2)] = 1 − α, the
given confidence coefficient. Now, −a(1−α/2) < Qn < a(1−α/2) is equivalent
to log Xn − a(1−α/2)/
√
n < log θ < log Xn + a(1−α/2)/
√
n. Thus, the
asymptotic confidence interval for θ with confidence coefficient (1−α) is given
by,
￾
exp ￾
log Xn − a(1−α/2)/
√
n

, exp ￾
log Xn + a(1−α/2)/
√
n
 . □
Remark 7.3.4. It is to be noted that Xn ∼ N(θ, θ2/n) distribution for each
n but log Xn ∼ N(log θ, 1/n) distribution for large n.
One of the most important tools to establish convergence in law of a suit￾ably scaled and centred average is the central limit theorem (CLT). We discuss
in detail various versions of CLT in Chapter 10. We state below the simplest
version of CLT, which is used to solve some examples.
Theorem 7.3.10. Lindeberg-Levy CLT: Suppose {Xn, n ≥ 1} is a sequence
of independent and identically distributed random variables with mean µ and
positive, finite variance σ
2
, then
Yn =
Xn
i=1
Xi−nµ
/(
√
nσ) = (Sn−nµ)
√
nσ =
√
n(Xn−µ)/σ L
→ Z ∼ N(0, 1).
The following example illustrates how CLT and Slutsky’s theorem are use￾ful for constructing a large sample confidence interval.
Example 7.3.19. Suppose {X1, X2, · · · , Xn} is a random sample from Pois￾son distribution with mean θ. Then V ar(X) = θ < ∞ and V ar(Xn) = θ/n →
0. Hence
Xn
P
→ θ & by the CLT Qn =
p
n/θ(Xn − θ)
L
→ Z ∼ N(0, 1).
Thus, Qn is a pivotal quantity, for large n. However, it is not useful to construct
a confidence interval for θ. We define Q˜
n as
Q˜
n =
√
n
p
Xn
(Xn − θ) = ( √
θ
p
Xn
) √
n
√
θ
(Xn − θ)

L
→ 1 × Z ∼ N(0, 1)
by CLT and Slutsky’s theorem. Thus, Q˜
n can be taken as a pivotal quantity
for large n, which is suitable to find the asymptotic confidence interval for θ.
Hence, given the confidence coefficient (1 − α), we find a(1−α/2) such that
P[−a(1−α/2) < Q˜
n < a(1−α/2)] = 1 − α. Now, −a(1−α/2) < Q˜
n < a(1−α/2)
is equivalent to Xn −
q
Xn/n a(1−α/2) < θ < Xn +
q
Xn/n a(1−α/2).
Thus, asymptotic confidence interval for θ with confidence coefficient (1 − α)
is given by,

Xn −
q
Xn/n a(1−α/2), Xn +
q
Xn/n a(1−α/2)Convergence in Law 343
which can also be written as
￾
Xn − s.e.(Xn)a(1−α/2), Xn + s.e.(Xn)a(1−α/2)
,
where q
Xn/n is the standard error of Xn. □
Generating functions, such as characteristic function, moment generating
function or probability generating function for discrete integer-valued random
variables, are always used to derive the distribution of sums of independent
random variables. One essential feature underlying these derivations is the
uniqueness theorem which states that if the generating functions of two ran￾dom variables are the same, then their distributions are the same. In partic￾ular, if the moment generating function or probability generating function of
two random variables X and Y are the same on the domain, then X and Y
are identically distributed random variables. In Chapter 4, we have proved the
uniqueness theorem for characteristic functions. This idea can be extended to
decide the limit distribution in convergence in law, that is, it is possible to
identify the limit law if one identifies the limit of a sequence of generating
functions corresponding to a sequence of random variables. We state some
theorems which are useful to find the limit law of Xn using generating func￾tions. In Chapter 4, we noted that the domain of a characteristic function is R.
Hence, we work with a characteristic function rather than the corresponding
moment generating function. For a discrete integer-valued random variable, it
is better to deal with a probability generating function defined on [−1, 1]. We
state below some theorems which convey a connection between convergence
in law and convergence of a sequence of characteristic functions.
Theorem 7.3.11. Suppose {Xn, n ≥ 1} is a sequence of random variables
with ϕn(t), t ∈ R, being a characteristic function of Xn, n ≥ 1. Suppose X is
a random variable with ϕ(t), t ∈ R as its characteristic function. Then
ϕn(t) → ϕ(t) ∀ t ∈ R ⇐⇒ Xn
L
→ X.
For proof, we refer to Gut [13].
Suppose {Xn, n ≥ 1} and {Yn, n ≥ 1} are sequences of random variables. If
Xn
L
→ X and Yn
L
→ C, then Slutsky’s theorem states that Xn + Yn
L
→ X + C.
If Yn
L
→ Y , then the result Xn + Yn
L
→ X + Y is not always true. It is true if
∀ n ≥ 1, Xn and Yn are independent. Theorem 7.3.11 is useful to prove this
result.
Theorem 7.3.12. Suppose Xn
L
→ X, Yn
L
→ Y and ∀ n ≥ 1, Xn and Yn are
independent. Suppose X and Y are also independent. Then Xn+Yn
L
→ X +Y .
Proof. From Theorem 7.3.11
Xn
L
→ X & Yn
L
→ Y ⇒ ϕXn
(t) → ϕX(t) & ϕYn
(t) → ϕY (t)
⇒ ϕXn
(t)ϕYn
(t) → ϕX(t)ϕY (t)
⇒ ϕXn+Yn
(t) → ϕX+Y (t)344 Convergence in Probability, in Law and in r-th Mean
The last step follows in view of the independence of Xn and Yn and of X and
Y . Note that ϕX+Y (t) is a characteristic function of X + Y . Hence again by
Theorem 7.3.11, Xn + Yn
L
→ X + Y .
The following example illustrates that Theorem 7.3.12 is not true if we
drop the independence condition (Stoyanov [23]).
Example 7.3.20. Suppose {Xn, n ≥ 1} and {Yn, n ≥ 1} are sequences of
random variables. Suppose Xn
L
→ X and Yn
L
→ Y where X ∼ N(0, 1) and
Y ∼ N(0, 1). If Xn and Yn are independent ∀ n ≥ 1, then Xn+Yn ∼ N(0, 2)
distribution. Moreover, in this case, the distribution of (Xn, Yn)
′
converges to
the bivariate normal distribution with zero mean vector and dispersion matrix
diag(1, 1). Suppose now {Xn, n ≥ 1} is a sequence of random variables, such
that Xn
L
→ X ∼ N(0, 1). If Yn = Xn ∀ n ≥ 1, then Yn
L
→ X ∼ N(0, 1).
However, Xn and Yn are not independent. Further, Xn + Yn = 2Xn and
2Xn
L
→ 2X ∼ N(0, 4) distribution and not N(0, 2) distribution. □
The theorem similar to Theorem 7.3.12 is stated below. For proof, refer to
Grimmett and Stirzaker [12].
Theorem 7.3.13. Suppose Xn
L
→ X, Yn
L
→ Y and the joint distribution
(Xn, Yn)
′
converges to that of (X, Y )
′
. Suppose X and Y are independent.
Then Xn + Yn
L
→ X + Y .
Suppose ϕn(t) is a characteristic function of Xn, n ≥ 1. If one can show
that a sequence {ϕn(t), n ≥ 1} of characteristic functions converges to some
function, we can conclude that a sequence {Xn, n ≥ 1} converges in law,
under one condition on the limit of ϕn(t). A statement of the theorem is given
below. It is referred to as a continuity theorem for characteristic functions and
is heavily used in identifying the limit law of a sequence of random variables.
Theorem 7.3.14. Continuity theorem for characteristic functions: Suppose
{Xn, n ≥ 1} is a sequence of random variables with ϕn(t), t ∈ R being a
characteristic function of Xn, n ≥ 1. Suppose ϕn(t) → ϕ(t) ∀ t ∈ R as
n → ∞, where ϕ(t) is continuous at t = 0. Then there exists a random
variable X such that Xn
L
→ X and ϕ(t) is a characteristic function of X.
For proof, we refer to Gut [13]. The following example shows how the
continuity of ϕ(t) at t = 0 is crucial.
Example 7.3.21. Suppose {Xn, n ≥ 1} is a sequence of random variables
such that Xn has uniform U(−n, n) distribution. Then the characteristic func￾tion ϕXn
(t) of Xn is given by
ϕXn
(t) = 1
2n
Z n
−n
e
itx dx =
1
2n
2
Z n
0
cos(tx) dx
= 1 if t = 0 & sin(nt)/nt if t ̸= 0.Convergence in Law 345
If t ̸= 0 then limn→∞ ϕXn
(t) = limn→∞ sin(nt)/nt = 0 using the result that
|sin(nt)| ≤ 1. Thus,
ϕXn
(t) →

1, if t = 0
0, if t ̸= 0.
It is to be noted that limn→∞ ϕXn
(t) is not continuous at t = 0 and Theorem
7.3.14 is not applicable. In Example 7.3.9, we have shown that Xn does not
converge in law by finding the limit of the distribution function of Xn. □
We discuss some examples below to illustrate Theorem 7.3.14 and the
uniqueness theorem of a characteristic function, proved in Chapter 4. Conti￾nuity and uniqueness theorems for characteristic functions are also useful to
establish a weak law of large numbers and the central limit theorem, which
we discuss in Chapters 9 and 10 respectively.
Example 7.3.22. Suppose {Xn, n ≥ 1} is a sequence of random variables
such that characteristic function ϕXn
(t) → exp(itC) for some C ∈ R and
∀ t ∈ R. It is to be noted that exp(itC) is continuous at t = 0, and it
is a characteristic function of a random variable degenerate at C. Hence by
Theorem 7.3.14, Xn
L
→ X and by the uniqueness theorem for characteristic
functions X ≡ C. Since the limit random variable is degenerate, convergence
in law implies convergence in probability, thus Xn
P
→ C. □
The following simple example illustrates both Theorem 7.3.11 and Theo￾rem 7.3.14.
Example 7.3.23. Suppose Xn has normal N(θn, σ2
n
) distribution and θn → θ
and σ
2
n → σ
2
. Then observe that,
Fn(x) = P[Xn ≤ x] = P

Xn − θn
σn
≤
x − θn
σn

= Φ 
x − θn
σn

→ Φ

x − θ
σ

,
∀ x ∈ R = C(FX). Thus, Xn
L
→ X ∼ N(θ, σ2
). Thus, the large sample
distribution of Xn is N(θ, σ2
). Alternatively, we can prove the same result
using the continuity theorem for characteristic functions. Since
Xn ∼ N(θn, σ2
n
) distribution, its characteristic function ϕXn
(t) is given by,
ϕXn
(t) = exp(itθn − t
2σ
2
n/2). Note that as θn → θ and σ
2
n → σ
2
,
ϕXn
(t) = exp(itθn − t
2σ
2
n/2) → exp(itθ − t
2σ
2
/2) = ϕX(t), ∀ t ∈ R.
Further, ϕX(t) is continuous at t = 0 and it is a characteristic function of
X ∼ N(θ, σ2
). Hence by the continuity theorem and the uniqueness theorem
for characteristic functions, we conclude that Xn
L
→ X ∼ N(θ, σ2
). Conversely,
suppose now Xn
L
→ X ∼ N(θ, σ2
), where Xn ∼ N(θn, σ2
n
). We examine
whether θn → θ and σ
2
n → σ
2
. It is known that for any complex number
z = a + ib,
e
z = e
a
e
ib = e
a
(cos b + isin b) ⇒ |e
z
| = (e
2a
cos2
b + e
2a
sin2
b)
1/2 = e
a
.346 Convergence in Probability, in Law and in r-th Mean
Thus,
Xn
L
→ X ⇒ ϕXn
(t) → ϕX(t) ∀ t ∈ R by Theorem 7.3.11
⇒



e
itθn−t
2σ
2
n/2



→



e
itθ−t
2σ
2/2



∀ t ∈ R
⇒ e
−t
2σ
2
n/2 → e
−t
2σ
2/2 ⇒ σ
2
n → σ
2
as n → ∞
Further, limn→∞
e
itθn = limn→∞
ϕXn
(t)
|ϕXn
(t)|
=
ϕX(t)
|ϕX(t)|
= e
itθ ⇒ θn → θ,
as n → ∞. □
Example 7.3.24. Suppose Xn ∼ G(n, n) distribution with probability den￾sity function, mean and variance given by,
f(x, n) = n
n
Γ(n)
exp(−nx)x
n−1
, x > 0, n ∈ N, E(Xn) = 1 & V ar(Xn) = 1/n.
Its characteristic function is given by ϕXn
(t) = (1 − it/n)
−n.
As n → ∞, ∀ t ∈ R, ϕXn
(t) = (1 − it/n)
−n → exp(it) = ϕ(t), say.
ϕ(t) is continuous at t = 0 and it is the characteristic function of X ≡ 1. By
Theorem 7.3.14, Xn
L
→ 1 and since the limit random variable is degenerate,
Xn
P
→ 1. Further,
E(Xn − 1)2 = V ar(Xn) = 1/n → 0 ⇒ Xn
q.m. → 1 ⇒ Xn
P
→ 1 ⇒ Xn
L
→ 1.
Suppose now we centre and scale Xn and define Yn =
√
n(Xn − 1) and study
its limit distribution. Suppose ϕn(·) denotes the characteristic function of Yn.
Then ∀ t ∈ R
ϕn(t) = E(e
itYn ) = E(e
it√
n(Xn−1)) = e
−it√
nE(e
it√
nXn )
= e
−it√
n
(1 − it√
n/n)
−n
⇒ log ϕn(t) = −it√
n − n log(1 − it/√
n)
= −it√
n + n(it/√
n − t
2
/2n − it3
/3n
3/2 + · · ·)
= −t
2
/2 + δn → − t
2
/2 = ϕ(t), say
since δn → 0 as n → ∞. Thus, the sequence {ϕn(t), n ≥ 1} of charac￾teristic functions converges to ϕ(t) = exp(−t
2/2), which is continuous at
t = 0. Hence, by the continuity theorem for characteristic functions Yn
L
→ Z,
where ϕ(t) = exp(−t
2/2) is a characteristic function of Z. It is known
that ϕ(t) = exp(−t
2/2) is a characteristic function of the standard normal
distribution. Hence by the uniqueness theorem of a characteristic function,
Z ∼ N(0, 1) distribution. □
In the following example, we verify the results shown in Example 7.3.24
by simulation.Convergence in Law 347
Example 7.3.25. Suppose Xn ∼ G(n, n). Using Code 7.3.4, by simulation,
we verify convergence in probability and quadratic mean of {Xn, n ≥ 1} to
1, and convergence to the standard normal distribution of Yn =
√
n(Xn − 1).
We verify that Xn
L
→ 1 in the next example, as we need large values of n
to arrive at the desired result. To verify that Xn
P
→ 1, as in Example 7.2.16,
we obtain the estimate of the probability pn(ϵ) as rfn =
Pm
i=1 I[|Xi−1|<ϵ]/m,
where Xi
is the realized observation from the given gamma distribution. We
examine whether it approaches 1 as n increases. To examine if Xn
q.m→ 1, we
compute qn = (1/m)
Pm
i=1(Xi −1)2 and observe whether it approaches 0 as n
increases. To examine Yn =
√
n(Xn − 1) L
→ Z ∼ N(0, 1), based on m realized
values of Yn, we plot the histogram with relative frequencies on Y-axis and
impose on it the curve of the probability density function of the standard
normal distribution. We then observe how close the two are. To support the
visual impression, we carry out the Shapiro-Wilk test of normality and decide
based on p-values. To judge the normality, we also draw a box plot, a QQ
plot with a QQ line imposed on it and a graph of the empirical distribution
function of simulated values of Yn and impose the graph of the distribution
function of the standard normal distribution on it. We adopt this approach
for n = 1800. We use the following code.
Code 7.3.4. eps=0.05; p=me=v=q=p=pval=c(); M=500
s=c(300,600,900,1200,1500,1800)# vector of values of n
y=matrix(nrow=M,ncol=length(s))
for(i in 1:length(s))
{
n=s[i]
set.seed(i)
x=rgamma(M,shape=n,scale=1/n )
y[,i]= (n)^0.5*(x-1)
me[i]=mean(x)
v[i]=var(x)*(M-1)/M
q[i]=mean(x-1)^2
p[i]=length(which(abs(x-1)<eps))/M
pval[i]=shapiro.test(y[,i])$p.value
}
d=round(data.frame(s,p,me,v,q,pval),4); d
r=seq(-4,4,.1); u=dnorm(r)
par(mfrow=c(3,2))
no=paste("n =",s,sep=" ")
for(j in 1:length(s))
{348 Convergence in Probability, in Law and in r-th Mean
hist(y[,j],freq=FALSE,main=no[j],ylim=c(0,0.5),col="light blue",
xlim=c(-4,4),xlab="")
lines(r,u,"o",pch=20,col="dark blue")
}
par(mfrow=c(2,2))
hist(y[,6],freq=FALSE,main="Histogram of Y_1800",ylim=c(0,0.5),
col="light blue",xlim=c(-4,4),xlab="")
lines(r,u,"o",pch=20,col="dark blue")
boxplot(y[,6],main="Box Plot of Y_1800")
qqnorm(y[,6]); qqline(y[,6])
plot(ecdf(y[,6]),main="Empirical df of Y_1800",col="light blue",
xlab=expression(paste("Y"[n])),ylab=expression(paste("F"[n]
(t))),lty=1)
lines(r,pnorm(r),col="dark blue",lty=2)
legend("bottomright",legend=c("ecdf","df"),
col=c("light blue","dark blue"),lty=c(1,2))
From Table 7.5, we note that as n increases, rfn → 1, qn → 0. Thus,
Xn
P
→ 1 and Xn
q.m. → 1. We also note that the mean and the variance of
the simulated values approach 1 and 0, respectively. The p-values in the last
column support the theoretical derivation that for large n, the distribution of
Yn can be approximated by the standard normal distribution.
From Figure 7.7, we note that the curve of the probability density function,
imposed on the histogram, also supports the approximation. The four plots
in Figure 7.8 drawn for n = 1800 convey the same findings. □
In the next example, using Code 7.3.5, we verify by simulation that Xn
L
→ 1
where Xn ∼ G(n, n).
Example 7.3.26. Suppose Xn ∼ G(n, n). To verify that Xn
L
→ 1, as in
Example 7.2.16, we examine whether as n increases, the distribution func￾tion Fn(x) of Xn approaches to the distribution function F of X ≡ 1 for all
TABLE 7.5
Gamma Distribution: Convergence in Probabil￾ity and in Quadratic Mean
n rfn Mean Variance qn p-val
300 0.590 1.0004 0.0034 0 0.3625
600 0.754 1.0033 0.0017 0 0.2577
900 0.878 1.0002 0.0011 0 0.3160
1200 0.924 0.9998 0.0009 0 0.3043
1500 0.952 0.9995 0.0006 0 0.7862
1800 0.970 0.9994 0.0005 0 0.7911Convergence in Law 349
FIGURE 7.7
Convergence in Law of Yn =
√
n(Xn − 1): Histograms
x ∈ R − {1}. Based on the simulated observations from Xn, we can find the
empirical distribution function Gn(x) and check whether, as n increases, it
also approaches to that of X ≡ 1. In Chapter 9, using strong law of large
numbers, we prove that Gn(x)
a.s. → F(x) for all x ∈ R − {1}. Glivenko-Cantelli
theorem (Gut [13]) states that the convergence is uniform in x. Using the
following code, we verify whether Fn(x) and Gn(x) approach F(x).
Code 7.3.5. M=500; s=c(500,1500,2500,3500)# vector of values of n
x=matrix(nrow=M,ncol=length(s))
z=seq(.9,1,.001);length(z)
z1=seq(1,1.2,.001);length(z1); z2=c(z,z1)
w=c(rep(0,length(z)),rep(1,length(z1)))
w1=seq(.92,1.1,.001)
w2=matrix(nrow=length(w1),ncol=length(s))
par(mfrow=c(2,2))
for(i in 1:length(s))
{
n=s[i]
no=paste("n =",s,sep=" ")350 Convergence in Probability, in Law and in r-th Mean
FIGURE 7.8
Convergence in Law of Yn =
√
n(Xn − 1)
set.seed(i)
x[,i]=rgamma(M,shape=n,scale=1/n )
plot(ecdf(x[,i]),main=s[i],col="blue",lwd=2)
w2[,i]=pgamma(w1,shape=n,scale=1/n )
lines(w1,w2[,i],main=s[i],col="red",lwd=1)
lines(z2,w,col="dark blue")
}
legend("bottomright",legend=c("ecdf","df"),col=c("blue","red"),
lwd=c(2,1))
From Figure 7.9, we note that the curves of Fn and Gn are close to each
other for all the four values of n. However, not very close to the curve of F.
It may still need a larger n. It may be in view of the approximation of a con￾tinuous distribution function by a discrete one. This example also illustrates
that a sequence of absolutely continuous random variables converges in law
to a discrete random variable. □
We now state the analogue of Theorem 7.3.11 for a sequence probability
generating functions of discrete integer-valued random variables. For proof, weConvergence in Law 351
FIGURE 7.9
Xn ∼ G(n, n): Convergence in Law to 1
refer to Gut [13]. As the characteristic function determines the distribution
uniquely, the probability generating function also determines the distribution
uniquely.
Theorem 7.3.15. Continuity theorem for probability generating functions:
Suppose {Xn, n ≥ 1} is a sequence of discrete integer valued random variables
with Pn(t) as the probability generating function of Xn, t ∈ [−1, 1]. Suppose
probability generating function of X is P(t), t ∈ [−1, 1]. If as n → ∞, Pn(t) →
P(t) ∀ t ∈ [−1, 1] then Xn
L
→ X.
We have shown in Example 7.3.6 that under certain conditions, binomial
distribution converges to Poisson distribution by showing that the probability
mass function of a binomial distribution converges to that of a Poisson distri￾bution. In the following example, we discuss the same result using Theorem
7.3.15.
Example 7.3.27. Suppose Xn ∼ B (n, λ/n) distribution. Its probability gen￾erating function is given by Pn(t) = (1 − λ/n + λt/n)
n
. Then as n → ∞,
∀ t ∈ [−1, 1],
Pn(t) = 
1 −
λ
n
+
λt
n
n
=

1 +
λ(t − 1)
n
n
→ e
λ(t−1) = P(t), say.352 Convergence in Probability, in Law and in r-th Mean
Hence by Theorem 7.3.15, binomial distribution converges to some distri￾bution. However, P(t) is the probability generating function of X ∼ P(λ)
distribution. Hence from the uniqueness theorem of probability generating
functions, we conclude that the limiting distribution is a Poisson distribution.
More generally, suppose Xn ∼ B(n, pn) distribution, where n → ∞ in such a
way that pn → 0 and npn → λ. Then as n → ∞, ∀ t ∈ [−1, 1],,
Pn(t) = (1 − pn + pnt)
n = ((t − 1)pn + 1)n + 1 + n(t − 1)pn
+
n(n − 1)
2! (t − 1)2
p
2
n +
n(n − 1)(n − 2)
3! (t − 1)3
p
3
n + · · ·
→ 1 + (t − 1)λ +
(t − 1)2λ
2
2! +
(t − 1)3λ
3
3! + · · · = e
λ(t−1) = P(t),
where P(t) is the probability generating function of X ∼ P(λ) distribution.
Hence, binomial B(n, pn) distribution converges to Poisson distribution as
n → ∞ in such a way that pn → 0 and npn → λ. □
Remark 7.3.5. While verifying that binomial distribution converges to Pois￾son distribution, under certain conditions, we can also use Theorem 7.3.14.
Thus, if Xn ∼ B (n, λ/n) distribution. The limit of its characteristic function
is given by
ϕn(t) = ￾
1 − λ/n + λeit/nn
=
￾
1 + λ(e
it − 1)/nn → e
λ(e
it−1) = ϕ(t),
say. It is continuous at t = 0 and hence Xn
L
→ X. Note that ϕ(t) is a
characteristic function of P(λ) distribution. Hence by the uniqueness theorem
of characteristic functions, X ∼ P(λ) distribution.
We now briefly discuss the weak convergence of a sequence of distribution
functions and its relation with convergence in law. We begin with an example.
Example 7.3.28. Suppose {Xn, n ≥ 1} is a sequence of random variables
such that Xn ∼ N(0, σ2
n
) distribution. The distribution function of Xn is
given by,
Fn(x) = P[Xn ≤ x] = Φ(x/σn) → Φ(0)
= 1/2 ifσn → ∞ as n → ∞, ∀ x ∈ R.
Thus, Fn(x) does not converge to a distribution function. □
In the above example and in Example 7.3.9, a sequence of distribution
functions does not converge to a proper distribution function. Convergence
of this type is known as weak convergence or convergence in a wide sense or
vague convergence of a sequence of distribution functions. The definition of
weak convergence is as given below.
Definition 7.3.2. Weak convergence: A sequence of distribution functions
{Fn(x), n ≥ 1} is said to converge weakly to a non-decreasing and right￾continuous function F if Fn(x) → F(x), ∀ x ∈ C(F) as n → ∞, where
C(F) is a set of points of continuity of Convergence in r-th Mean 353
In this definition, F is not necessarily a distribution function of a random
variable. Weak convergence of {Fn(x), n ≥ 1} is denoted by Fn
w→ F. It can
be proved that set D(F) of points of discontinuity of F is at most countable,
which in turn implies that set C(F) of points of continuity is dense in R. If
limx→∞ F(x) = 1 and limx→−∞ F(x) = 0, then we say that Fn converges
completely to F. In particular, if Fn is a distribution function of a random
variable Xn, n ≥ 1 and F is a distribution function of a random variable X,
and if Fn
w→ F then Xn
L
→ X. Thus, the distinction between weak conver￾gence and convergence in law is that the limit random variable in the former
case may not be a proper or real random variable but may be an extended
valued random variable. In weak convergence, the limit distribution is referred
to as a pseudo distribution or sub-probability distribution and the limit ran￾dom variable is referred to as an improper random variable. Another subtle
difference between the two is that in convergence in law, the probability mea￾sure P in Fn(x) = P[Xn ≤ x] is fixed, and we get a sequence of distribution
functions corresponding to the sequence of the random variables. In weak
convergence, Fn need not be a distribution function of a random variable and
Fn((a, b]) = Pn((a, b]) and thus we have a sequence of measures {Pn, n ≥ 1}
and Pn need not be a probability measure.
It is to be noted that convergence in law implies weak convergence. Thus,
convergence in law is a stronger mode of convergence than weak convergence.
The following section presents some results related to convergence in r-th
mean.
7.4 Convergence in r-th Mean
As defined in Section 6.1, Xn
r→ X if E(|Xn − X|
r
) → 0, r > 0. In almost
sure convergence and in convergence in probability, it is proved that the limit
random variable is almost surely unique. The same result holds for convergence
in r-th mean, which follows from the Cr inequality proved in Section 4.5.
Theorem 7.4.1. If Xn
r→ X and Xn
r→ Y , then X and Y are equivalent
random variables, that is, X = Y a.s.
Proof. By Cr inequality,
E(|X − Y |
r
) = E(|X − Xn + Xn − Y |
r
)
≤ Cr[E(|Xn − X|
r
) + E(|Xn − Y |
r
)] → 0, as n → ∞.354 Convergence in Probability, in Law and in r-th Mean
Thus, E(|X − Y |
r
) = 0. Suppose Z = |X − Y |
r/2
. Observe that
E(|X − Y |
r
) = 0 ⇒ E(|X − Y |
r/2
)
2 = 0 ⇒ E(Z
2
) = 0
⇒ V ar(Z) ≤ E(Z
2
) = 0 ⇒ V ar(Z) = 0
V ar(Z) = 0 & E(Z
2
) = 0 ⇒ E(Z) = 0.
Thus, Z is a degenerate random variable, degenerate at E(Z) = 0. Hence,
P[Z = 0] = 1, that is, X = Y a.s. Alternatively, using Theorem 7.2.2,
Xn
r→ X ⇒ Xn
P
→ X & Xn
r→ Y ⇒ Xn
P
→ Y ⇒ X = Y a.s.
by Theorem 7.2.1.
In Section 2, we have noted that convergence in r-th mean implies conver￾gence in probability. The converse is not true in general, as shown in Example
7.2.10. It is also clear from the following example. However, the converse is
true if the random variables Xn’s are almost surely bounded. We discuss it in
the next theorem.
Example 7.4.1. Suppose a probability mass function of a random variable
Xn is given by,
P[Xn = 1/n] = 1 − 1/n2 = 1 − P[Xn = n].
From the given distribution of Xn, it is clear that,
P[|Xn| < ϵ] = 
1 − 1/n2
, if ϵ < n
1, if ϵ ≥ n
and it converges to 1 as n → ∞, for every ϵ > 0. Hence, Xn
P
→ X ≡ 0 and
hence in law. Now,
E(|Xn − X|) = E(|Xn|) = E(Xn) = 2/n − 1/n3 → 0
but
E(|Xn − X|)
2 = E(|Xn|)
2 = E(X2
n
) = 1 + 1/n2 − 1/n4 → 1.
Thus, E(Xn) → 0 but E(X2
n
) → 1 and hence Xn
q.m. ↛ 0. □
In Theorem 7.2.3 it is proved that for a sequence {Xn, n ≥ 1} of uniformly
bounded random variables Xn
P
→ C implies E(Xn − C)
2 → 0. The following
theorem proves a similar result when Xn’s are almost surely bounded, and
the limit random variable is non-degenerate.
Theorem 7.4.2. Suppose {Xn, n ≥ 1} is a sequence of random variables
defined on the probability space (Ω, A, P). If Xn’s are almost surely bounded,
then Xn
P
→ X ⇒ Xn
r→ X.Convergence in r-th Mean 355
Proof. It is given that |Xn(ω)| ≤ M ∀ ω ∈ Nc
, where P(N) = 0. Since
|Xn| ≤ M, its distribution function Fn(x) is given by
Fn(x) =



0, if x ≤ −M
hn(x) if − M ≤ x < M
1, if x ≥ M.
Since Xn
P
→ X ⇒ Xn
L
→ X, Fn(x) → FX(x) ∀ x ∈ C(FX) and FX(x) is
given by,
FX(x) =



0, if x ≤ −M
limn→∞
hn(x) if −M ≤ x < M
1, if x ≥ M,
where limn→∞
hn(x) exists as Fn(x) → FX(x) ∀ x ∈ C(FX). From the form of
FX(x) it is clear that
|X| ≤ M ⇒ |Xn − X| ≤ |Xn| + |X| = 2M ⇒ |Xn − X|
r ≤ (2M)
r = S,
say. Now from the basic inequality we have for all ϵ > 0,
(E(|Xn − X|
r
) − ϵ
r
)/S ≤ P[|Xn − X| > ϵ] → 0 ⇒ Xn
r→ X.
The following theorem gives a necessary and sufficient condition for con￾vergence in quadratic mean of a sequence of random variables to a constant.
Theorem 7.4.3. Suppose {Xn, n ≥ 1} is a sequence of random variables
defined on the probability space (Ω, A, P). Xn
q.m. → b if and only if E(Xn) → b
and V ar(Xn) → 0, where b is a constant.
Proof. Suppose E(Xn) → b and V ar(Xn) → 0. Observe that
E(|Xn − b|
2
) = E(|Xn − E(Xn) + E(Xn) − b|
2
)
= E(Xn − E(Xn))2 + (E(Xn) − b)
2
= V ar(Xn) + (E(Xn) − b)
2 → 0 ⇒ Xn
q.m. → b.
Now assume that Xn
q.m. → b. Note that
Xn
q.m. → b ⇒ E(|Xn − b|
2
) → 0 ⇒ V ar(Xn) + (E(Xn) − b)
2 → 0
⇒ E(Xn) → b & V ar(Xn) → 0,
since the sum of two non-negative numbers converges to zero, each must con￾verge to zero.356 Convergence in Probability, in Law and in r-th Mean
Theorem 7.4.3 is useful to verify the consistency of an estimator Tn of a
parameter θ, provided its mean squared error exists. If the bias of Tn and
V ar(Tn) both converge to zero, that is, if the mean squared error converges
to zero, then Tn is a consistent estimator of θ. For example, suppose Xn is a
sample mean based on a random sample of size n from the distribution of X
with mean µ and variance σ
2
. Then E(Xn) = µ and V ar(Xn) = σ
2/n. Thus
Xn is an unbiased estimator of µ, and its variance converges to 0 as n → ∞.
Hence sample mean Xn is always a consistent estimator of the population
mean µ.
In Example 7.4.1 we have noted that, E(Xn)→ 0 but V ar(Xn)↛ 0 and
Xn
q.m. ↛ 0. The following example also demonstrates that both the conditions
in Theorem 7.4.3 are not satisfied, we do not get convergence in quadratic
mean. It also shows that convergence in probability does not imply conver￾gence in r-th mean.
Example 7.4.2. Suppose a probability mass function of a random variable
Xn is given by,
P[Xn = 0] = 1 − 1/n = 1 − P[Xn = n].
From the given distribution of Xn, we have,
P[|Xn| < ϵ] = 
1 − 1/n, if ϵ < n
1, if ϵ ≥ n
and it converges to 1 as n → ∞, for every ϵ > 0. Hence, Xn
P
→ X ≡ 0. Now
∀ n ≥ 1,
E(|Xn − X|) = E(|Xn|) = E(Xn) = n.1/n = 1 → 1 ⇒ Xn
1↛ 0
& E(|Xn − X|)
2 = E(|Xn|)
2 = E(X2
n
) = n
2
.1/n = n → ∞
⇒ Xn
q.m. ↛ 0. □
It is interesting to note that the convergence of moments differs from con￾vergence in r-th mean. Convergence in r-th mean implies convergence of r-th
order moments, but the converse is not true. We discuss these issues below.
Example 7.4.3. Suppose {Xn, n ≥ 1} is a sequence of random variables
defined on (Ω, A, P) as Xn = IA, A ∈ A. Suppose X on (Ω, A, P) is defined
as X = IAc . Suppose P(A) = 1/2, then ∀ r ≥ 1 and ∀ n ≥ 1,
E(|X|
r
) = 1/2 & E(|Xn|
r
) = 1/2 ⇒ E(|Xn|
r
) → E(|X|
r
)
Now, Xn − X = 1 if ω ∈ A & Xn − X = −1 if ω ∈ A
c
⇒ E(|Xn − X|
r
) = 1/2 + 1/2 = 1 ∀ n, r ≥ 1 ⇒ Xn
r↛ X.
Thus, in general, the convergence of moments does not imply convergence in
r-th mean. □Convergence in r-th Mean 357
In the following theorem, we prove that convergence in r-th mean implies
convergence of r-th order moments.
Theorem 7.4.4. Suppose {Xn, n ≥ 1} is a sequence of random variables
defined on a probability space (Ω, A, P). Then Xn
r→ X ⇒ E(|Xn|
r
) →
E(|X|
r
), r > 0.
Proof. By Cr inequality,
E(|Xn|
r
) = E(|Xn − X + X|
r
) ≤ Cr{E(|Xn − X|
r
) + E(|X|
r
)}.
Suppose r ≤ 1, then Cr = 1 and hence, E(|Xn|
r
) − E(|X|
r
) ≤ E(|Xn − X|
r
).
Interchanging Xn and X we get, E(|X|
r
)−E(|Xn|
r
) ≤ E(|X − Xn|
r
). Hence,



E(|Xn|
r
) − E(|X|
r
)


 ≤ E(|Xn − X|
r
) → 0 ⇒ E(|Xn|
r
) → E(|X|
r
).
Suppose r > 1, then by Minkowski’s inequality
(E|Xn|
r
)
1/r = (E|Xn − X + X|
r
)
1/r ≤ {(E|Xn − X|
r
)
1/r + (E|X|
r
)
1/r}.
Hence, (E|Xn|
r
)
1/r − (E|X|
r
)
1/r ≤ (E|Xn − X|
r
)
1/r
. Interchanging Xn and
X we get, (E|X|
r
)
1/r − (E|Xn|
r
)
1/r ≤ (E|X − Xn|
r
)
1/r
. Hence,


(E|Xn|
r
)
1/r −(E|X|
r
)
1/r


 ≤ (E|Xn − X|
r
)
1/r → 0 ⇒ E(|Xn|
r
) → E(|X|
r
).
In Chapter 4 we have noted that if X ∈ Lr then X ∈ Ls, ∀ s < r. On
similar lines, if the sequence {Xn, n ≥ 1} converges in r-th mean, then it also
converges in s-th mean for all s < r. We prove it in the following theorem
using Jensen’s inequality.
Theorem 7.4.5. Suppose {Xn, n ≥ 1} is a sequence of random variables
defined on a probability space (Ω, A, P). Then
Xn
r→ X ⇒ Xn
s→ X, ∀ s < r .
Proof. From the moment inequality studied in Lemma 4.5.1, we know that if
X ∈ Lr then X ∈ Ls for all s < r. Observe that
E(|Xn−X|
s
)=E((|Xn−X|
r
))s/r =E(g(|Xn−X|
r
)), whereg(x) = x
s/r, x > 0.
Now for x > 0, if g(x) = x
u
, then g
′
(x) = uxu−1 and g
′′(x) = u(u−1)x
u−2 < 0
for u < 1. A necessary and sufficient condition for a differentiable function to
be concave is that its second derivative is negative. Thus, g(x) = x
u
, x > 0 is
a concave function for u < 1 and hence by Jensen’s inequality
E(g(X)) ≤ g(E(X)). Now s < r ⇒ s/r < 1. Hence,
E(|Xn − X|
s
) = E((|Xn − X|
r
))s/r = E(g(|Xn − X|
r
))
≤ g(E(|Xn − X|
r
)) = (E(|Xn − X|
r
))s/r → 0 as n → ∞
⇒ Xn
s→ X, ∀ s < r.358 Convergence in Probability, in Law and in r-th Mean
However, the converse of the Theorem 7.4.5 is not true. It is illustrated in
the following example.
Example 7.4.4. Suppose {Xn, n ≥ 1} is a sequence of random variables such
that
P[Xn = n] = n
−(r+s)/2 = 1 − P[Xn = 0], n ≥ 1 & 0 < s < r
Observe that E(|Xn|
s
) = n
s
n
−(r+s)/2 = n
(s−r)/2 → 0 since s < r
E(|Xn|
r
) = n
r
n
−(r+s)/2 = n
(r−s)/2 → ∞ since s < r.
Thus if s < r, Xn
s→ 0, however Xn
r↛ 0. □
In general, almost sure convergence neither implies nor is implied by the
convergence in r-th mean. The next two examples illustrate that almost sure
convergence does not imply convergence in quadratic mean.
Example 7.4.5. Suppose {Xn, n ≥ 1} is a sequence of random variables
defined on a probability space (Ω, A, P) where Ω = [0, 1], A is a sigma field of
subsets of Ω and P is the Lebesgue measure on (Ω, A). The random variable
Xn is defined as,
Xn(ω) = 
2
n, if ω ∈ (0, 1/n)
0 if ω /∈ (0, 1/n).
It is to be noted that ∀ ω ∈ Ω, ∃ n0(ω) such that ω > 1/n ∀ n ≥ n0.
Hence,
∀ ω ∈ Ω, & ∀ n ≥ n0, Xn(ω) = 0 which implies that ∀ ω ∈ Ω, Xn(ω) → 0
and hence Xn
a.s. → 0. However, E(X2
n
) = 22n/n → ∞ as n → ∞. Thus,
Xn
q.m. ↛ 0. □
Example 7.4.6. Suppose {Xn, n ≥ 1} is a sequence of random variables such
that P[Xn = 0] = 1 − 1/n2 and P[Xn = e
n] = 1/n2
. Note that for ϵ > 0,
P[|Xn| > ϵ] = 1/n2 → 0 and hence Xn
P
→ 0. Further,
X
n≥1
P[|Xn| > ϵ] = X
n≥1
1/n2 < ∞ ⇒ Xn
a.s. → 0.
However, E(|Xn|
r
) = e
nr/n2 → ∞ as n → ∞. Hence, Xn
r↛ 0. □
The following example illustrates that convergence in r-th mean does not
imply almost sure convergence.
Example 7.4.7. Suppose {Xn, n ≥ 1} is a sequence of independent random
variables such that P[Xn = 1] = 1/n & P[Xn = 0] = 1 − 1/n, n ≥ 1.
It is clear that E(Xr
n
) = 1/n → 0 as n → ∞. Hence, Xn
r→ 0 ∀ r > 0.
It is to be noted that {Xn(ω), n ≥ 1} is a sequence of 0’s and 1’s and hence
Xn(ω) → 0 if and only if Xn(ω) = 0 for sufficiently large n. Thus we computeConvergence in r-th Mean 359
P[Xn(ω) = 0 ∀ n ≥ n0] where n0 is a large positive integer and examine its
behaviour.
P[Xn(ω) = 0 ∀ n ≥ n0] = P[
\∞
n=n0
[Xn = 0]] = P[ lim
N→∞
\
N
n=n0
[Xn = 0]]
= lim
N→∞
P[
\
N
n=n0
[Xn = 0]]
= lim
N→∞
Y
N
n=n0
P[Xn = 0] in view of independence
= lim
N→∞
Y
N
n=n0
(1 − 1/n)
= lim
N→∞
n0 − 1
n0
n0
n0 + 1
n0 + 1
n0 + 2
· · ·
N − 2
N − 1
N − 1
N
= lim
N→∞
(n0 − 1)/N = 0
Thus, Xn
a.s. ↛ 0. Alternatively, note that
X
n≥1
P[|Xn| > ϵ] = X
n≥1
(1/n) = ∞ ⇒ Xn
a.s. ↛ 0,
in view of Theorem 6.4.3. □
Remark 7.4.1. In the above example, it is to be noted that for any r > 0
E(|Xn|
r
) = 1/n and hence P∞
n=1 E(|Xn|
r
) is a divergent series. Similarly,
for any ϵ > 0, P[|Xn| > ϵ] = 1/n and hence P∞
n=1 P[|Xn| > ϵ] is also a
divergent series. Hence, we cannot use the sufficient conditions for the almost
sure convergence as proved in Section 6.3.
In the following example, the sequence neither converges in r-th mean nor
almost surely.
Example 7.4.8. Suppose {Xn, n ≥ 1} is a sequence of random variables
such that Xn has uniform U(−n, n) distribution. In Example 7.3.9, we have
shown that Xn does not converge in law by finding the limit of the distribution
function of Xn. Hence, Xn
P↛ 0 and hence Xn
a.s. ↛ 0. Now,
E(|Xn|
2
) = E(X2
n
) = V ar(Xn) + (E(Xn))2 = n
2
/3 → ∞ ⇒ Xn
q.m. ↛ X.□
In the following example, the sequence converges in both the modes, r-th
mean and almost surely.
Example 7.4.9. Suppose {Xn, n ≥ 1} is a sequence of random variables
with probability mass function given by, P[Xn = ±1/n] = 1/2. It is clear that360 Convergence in Probability, in Law and in r-th Mean
E|Xn|
r = 1/nr → 0 hence Xn
r→ X ≡ 0 and Xn
P
→ X ≡ 0 Further for all
n ≥ 1, E(Xn) = 0, hence E(Xn) → E(X) = 0. Thus, we have convergence
in Lr and also the convergence of a sequence of means. In Example 6.3.4, we
have shown that Xn
a.s. → 0. □
The following example illustrates that almost sure convergence does not
imply convergence of moments.
Example 7.4.10. Suppose {Xn, n ≥ 1} is a sequence of random variables
defined on a probability space (Ω, A, P) where Ω = (0, 1), A is a sigma field of
subsets of Ω and P is the Lebesgue measure on (Ω, A). The random variable
Xn is defined as,
Xn(ω) = 
2
n/r
, if ω ∈ (0, 1/n), r > 0
0, if ω /∈ (0, 1/n).
It is to be noted that ∀ ω ∈ Ω, ∃ n0(ω) such that ω > 1/n ∀ n ≥ n0.
Hence,
∀ ω ∈ Ω, & ∀ n ≥ n0, Xn(ω) = 0 ⇒ ∀ ω ∈ Ω, Xn(ω) → X = 0 and
hence Xn
a.s. → 0. However, E(|Xn|
r
) = (2n/r)
r
(1/n) = 2n/n ↛ 0 = E(|X|
r
) as
n → ∞. Thus, E(|Xn|
r
) ↛ E(|X|
r
). □
The following example illustrates convergence in all four modes of conver￾gence.
Example 7.4.11. Suppose {Xn, n ≥ 1} is a sequence of random variables
such that Xn ∼ N(1/n, 1/n) distribution. Then as n → ∞,
E(Xn−0)2 = E(X2
n
) = 1/n+1/n2 → 0 ⇒ Xn
q.m. → 0 ⇒ Xn
P
→ 0 ⇒ Xn
L
→ 0.
To examine whether Xn
a.s.
P
→ 0, we examine whether for some r > 0,
n≥1 E(|Xn − X|
r
) is finite. Note that as in Example 6.4.3, r = 2 will not be
helpful. Suppose we take r = 4. To find E(|Xn|
4
) = E(X4
n
), note that Yn = √
n(Xn − 1/n) ∼ N(0, 1) and hence E(Y
3
n
) = 0 which implies E(X3
n
) = 4/n3
.
Further, E(Y
4
n
) = 3 implies that
3 = n
2E(X4
n − 4X3
n/n + 6X2
n/n2 − 4Xn/n3 + 1/n4
)
⇒ E(X4
n
) = 13/n4 − 6/n3 + 3/n2 = (3n(n − 2) + 13)/n4 > 0
⇒
X
n≥1
E(|Xn|
4
) < ∞ ⇒ Xn
a.s. → 0.
In this example Xn
q.m. → 0 and Xn
a.s. → 0. However, it may not always be true,
as noted in some examples above. □
The following example illustrates the implications among various modes
of convergence.Convergence in r-th Mean 361
Example 7.4.12. Suppose {Xn, n ≥ 1} is a sequence of independent random
variables such that
P[Xn = 0] = 1 − 1/nα & P[Xn = n] = 1/nα
, n ≥ 1, α > 0 .
We examine whether {Xn, n ≥ 1} converges in probability, in law, almost
surely and in r-th mean. For any
ϵ > 0, P[|Xn| > ϵ] = 1/nα → 0 ∀ α > 0 ⇒ Xn
P
→ 0 ⇒ Xn
L
→ 0.
To examine almost sure convergence, observe that by Theorem 6.4.3,
∀ α > 1,
X∞
n=1
P[|Xn| > ϵ] < ∞ ⇒ Xn
a.s. → 0 .
It is given that {Xn, n ≥ 1} is a sequence of independent random variables.
Hence, by Theorem 6.4.3,
∀ α ≤ 1
X∞
n=1
P[|Xn| > ϵ] = ∞ ⇒ Xn
a.s. ↛ 0 .
It is to be noted that Xn
P
→ 0 ∀ α > 0 but Xn
a.s. ↛ 0 for α ≤ 1. Now to
examine convergence in r-th mean observe that,
E(|Xn|
r
) = 1/nα−r →



0, if r < α
1, if r = α
∞, if r > α.
Hence, Xn
r→ 0 if r < α. In particular if α = 1 then Xn
P
→ 0, but Xn
a.s. ↛ 0
and Xn
q.m. ↛ 0. □
In the following example, the sequence converges in quadratic mean, prob￾ability, law and almost surely.
Example 7.4.13. Suppose the joint probability density function of (Xn, Y )
for n ≥ 1 is given by, f(x, y) = ne−y
, 0 < y < x < y + 1/n. We exam￾ine various modes of convergence for the sequence {Xn, n ≥ 1}. To examine
whether Xn
q.m. → Y , we compute E(Xn − Y )
2
from the given joint probability
distribution as follows. With u = x − y,
E(Xn − Y )
2 = n
Z∞
0

y+1/n
Z
y
e
−y
(x − y)
2
dx
dy = n
Z∞
0
e
−y

1/n
Z
0
u
2
du
dy
= n
Z∞
0
e
−y
(1/3n
3
) dy = 1/3n
2
.362 Convergence in Probability, in Law and in r-th Mean
E(Xn − Y )
2
can also be computed as E(Xn − Y )
2 = E(E(Xn − Y )
2
|Y ).
Thus, we first find the conditional distribution of Xn given Y . The marginal
distribution of Y is given by,
f(y) = Z y+1/n
y
ne−y
dx = ne−y
(1/n) = e
−y
, y ≥ 0.
Thus, Y follows exponential distribution with E(Y ) = 1 & E(Y
2
) = 2. The
conditional distribution of Xn given Y is given by, f(x|y) = n, y < x <
y + 1/n. Thus, Xn|Y ∼ U(Y, Y + 1/n). Hence, E(Xn|Y ) = (2Y + 1/n)/2 =
Y + 1/2n and
E(X2
n
|Y ) = (n/3)[(Y + 1/n)
3 − Y
3
]= Y
2+ Y /n + 1/3n
2
⇒ E((Xn − Y )
2
|Y ) = Y
2 + Y /n + 1/3n
2 − 2Y (Y + 1/2n) + Y
2
⇒ E(Xn − Y )
2 = E(E(Xn − Y )
2
|Y ) = 1/3n
2 → 0 as n → ∞
⇒ Xn
q.m. → Y ⇒ Xn
P
→ Y ⇒ Xn
L
→ Y
Further X
n≥1
E(Xn − Y )
2 =
X
n≥1
1/3n
2 < ∞ ⇒ Xn
a.s → Y.
Observe that E(Xn) = 1 + 1/2n → 1 = E(Y ) = 1 and
E(X2
n
) = E(E(X2
n
|Y )) = 1/3n
2 + 2 + 1/n → 2 = E(Y
2
) = 2. In general,
E(X
r
n) = E(E(X
r
n|Y )) = E

n
Z Y +1/n
Y
x
r
dx
= E

(n/(r + 1))[(Y + 1/n)
r+1 − Y
r+1]

= E
 n
r + 1
h
Y
r+1 +
(r + 1)
n
Y
r +
(r + 1)r
2n2
Y
r−1 + · · · +
1
nr − Y
r+1i
= E

Y
r +
(r + 1)r
2n
Y
r−1 + · · · +
1
nr−1

→ E(Y
r
) = r! < ∞ ∀ finite r.
Thus, E(Xr
n
) → E(Y
r
) for r ≥ 1. We can also show that Xn
P
→ Y by
using the definition of convergence in probability. Thus, using the conditional
distribution of Xn given Y , for ϵ > 0 we find P[|Xn − Y | < ϵ] as follows.
P[|Xn − Y | < ϵ] = E(P[|Xn − Y | < ϵ|Y ]) = E(P[Y − ϵ < Xn < Y + ϵ|Y ])
= 1 if ϵ > 1/n, since Y + ϵ > Y + 1/n & Y − ϵ < Y
= E(P[Y < Xn < Y + ϵ|Y ]) = nϵ ≤ 1, if ϵ ≤ 1/n.
As n → ∞, for ϵ > 0, P[|Xn − Y | < ϵ] → 1 and hence Xn
P
→ Y . □
In the following example, we verify the results established in Example
7.4.13 by simulation using R.Convergence in r-th Mean 363
Example 7.4.14. Suppose the joint probability density function of (Xn, Y )
for n ≥ 1 is given by, f(x, y) = ne−y
, 0 < y < x < y + 1/n. We have noted
that the marginal distribution of Y is exponential with mean 1, while the
conditional distribution of Xn given Y is uniform U(Y, Y + 1/n). To obtain
a realization from (Xn, Y ), we first obtain a realization from the distribu￾tion of Y and then, corresponding to the realized value of Y = y, obtain
a realization from the conditional distribution of Xn given Y = y. On the
basis of m observations on (Xn, Y ), for some values of n, we obtain the esti￾mate rfn, estimate qn = (1/m)
Pm
i=1(Xni − Yi)
2 of E(Xn − Y )
2 and estimate
m′
rn = (1/m)
Pm
i=1(Xni)
r of E(Xr
n
) for r = 1, 2, 3, 4. We examine whether as
n increases, rfn → 1, qn → 0 and m′
rn → E(Y
r
), to decide whether Xn
P
→ Y ,
Xn
q.m. → Y and E(|Xn|
r
) → E(|Y |
r
) respectively. Since Y follows the expo￾nential distribution with mean 1, E(Y
r
) = r!, r ≥ 1. We use the following
code.
Code 7.4.1. eps=0.01; me=m2=m3=m4=q=p=c(); M=400
s=c(50,100,150,200,250,300,350,400)# vector of values of n
y=matrix(nrow=M,ncol=length(s))
z=matrix(nrow=M,ncol=length(s))
for(i in 1:length(s))
{
n=s[i]
set.seed(i)
y[,i]=rexp(M,rate=1)
set.seed(i+10)
z[,i]=runif(M,y[,i],y[,i]+1/n )
me[i]=mean(z[,i])
m2[i]=mean(z[,i]^2)
m3[i]=mean(z[,i]^3)
m4[i]=mean(z[,i]^4)
q[i]=mean(z[,i]-y[,i])^2
p[i]=length(which(abs(z[,i]-y[,i])<eps))/M
}
d=round(data.frame(s,p,me,m2,m3,m4,q),4); d
The output in data frame d is organized in Table 7.6. From Table 7.6, we
note that as n increases, rfn → 1, qn → 0 and m′
rn → E(Y
r
), r = 1, 2, 3, 4.
Thus, Xn
P
→ Y , Xn
q.m. → Y and E(|Xn|
r → E|Y |
r
, r = 1, 2, 3, 4. It is to be
noted that for ϵ = 0.01 and n = 50, ϵ < 1/n, hence as we have derived above,
P[|Xn − Y | < ϵ] = nϵ = 0.5. From the simulated data, we get it as 0.5225,
close to 0.5. Since we have shown that Xn
P
→ Y , we conclude that Xn
L
→ Y .364 Convergence in Probability, in Law and in r-th Mean
TABLE 7.6
Convergence in Probability, in Quadratic Mean and Convergence of Mo￾ments
n rfn E(|Xn|) E(|Xn|
2
) E(|Xn|
3
) E(|Xn|
4
) E(|Xn − Y |
2
)
50 0.5225 0.9829 1.7705 4.6202 15.7312 0.0001
100 1.0000 1.0437 2.1255 5.9997 20.0075 0
150 1.0000 0.9426 1.6497 3.8887 10.8662 0
200 1.0000 1.0791 2.4553 8.6685 39.8851 0
250 1.0000 1.0777 2.2721 7.4608 34.2127 0
300 1.0000 0.9182 1.6727 4.4615 15.6058 0
350 1.0000 0.9794 1.8759 5.2096 18.0000 0
400 1.0000 0.9863 1.9713 5.9920 23.8426 0
In the next example, we now prove it using the definition and verify it by
simulation. □
Example 7.4.15. Suppose the joint probability density function of (Xn, Y )
is given by, f(x, y) = ne−y
, 0 < y < x < y + 1/n, n ≥ 1. We have already
noted that the marginal distribution of Y is exponential with mean 1. To
examine whether Xn
L
→ Y , we find the distribution function of Xn and study
its limiting behaviour. Now, the marginal distribution of Xn is given by,
fXn
(x) = Z x
x−1/n
ne−y
dy = n(e
1/n − 1)e
−x
, 1/n < x < ∞
= e
−x
(e
1/n − 1)/(1/n) → e
−x
loge
e = e
−x
as n → ∞.
Thus, the probability density function of Xn converges to that of the expo￾nential distribution with mean 1. Hence, by Scheffe’s lemma (refer to p.227 of
Gut [13]) Xn
L
→ Y . It can also be shown by the definition of convergence in
law. Observe that the distribution function Fn(x) of Xn for x > 0 is given by,
Fn(x) = n(e
1/n − 1) Z x
1/n
e
−u
du = n(e
1/n − 1)(e
−1/n − e
−x
)
= (e
−1/n − e
−x
)(e
1/n − 1)/(1/n) → 1 − e
−x = F(x), x > 0
⇒ Xn
L
→ Y.
Since we have the explicit expressions for Fn(x) and F(x), we draw the curves
of F and Fn for n = 10, 50, 100, 200 and examine for which n these are close.
We also draw the box plots of values of |Fn(x) − F(x)| and compute
Tn = supx
|Fn(x)−F(x)|, for these values of n, to judge the closeness of Fn(x)
with F(x). We use the following code.
Code 7.4.2. nvec=c(10,50,100,200); l=length(nvec)
a=seq(0,7,length=200); F=pexp(a)Convergence in r-th Mean 365
FnMat=DiffMat=matrix(nrow=length(a),ncol=l)
par(mfrow=c(1,1))
plot(a,F,type="l",col="dark blue",ylim=c(0,1),xlab="x",
ylab="Distribution Function",lty=1,lwd=2)
for(j in 1:l)
{
n=nvec[j]
cm=(exp(1/n)-1)/(1/n)
FnMat[,j]=cm*(exp(-1/n)-exp(-a))
DiffMat[,j]=FnMat[,j]-F
lines(a,FnMat[,j],lty=j,col=j+1,type="l")
}
nlab=paste("n=",nvec,sep="")
legend("bottomright",legend=c("exp(1)",nlab),
col=c("dark blue",2:(l+1)),lty=1:(l+1))
colnames(DiffMat)=nlab
boxplot(abs(DiffMat),col="light blue")
diff=apply(abs(DiffMat),2,max)
lines(diff,col=2,type="b",pch=16,lwd=2)
legend("topright","sup |Fn - F|", col=2, lwd=2,pch=16)
DisTab=round(cbind(nvec,diff),4)
colnames(DisTab)=c("n","sup|Fn-F|")
rownames(DisTab)=c(); DisTab
Figure 7.10 displays the distribution functions F(x) and Fn(x). From the
graph, we note that except for n = 10, curves of Fn overlap on the curve
of F, supporting the convergence of distribution function Fn to F. Table 7.7
presents the values of Tn for n = 10, 50, 100, 200.
We again note that except for n = 10, values of Tn are very close to 0.
Figure 7.11 displays box plots of values of |Fn(x) − F(x)| and the values of
Tn. These indicate that except for n = 10, values of |Fn(x) − F(x)| are very
small. Further, the values of Tn decrease as n increases.
Thus, Figure 7.10, Figure 7.11 and Table 7.7 support the theoretical result
that Fn(x) → F(x) and the convergence is achieved at n = 200. □
In the next example, we verify Xn
L
→ Y by simulation.
TABLE 7.7
Values of Tn
n 10 50 100 200
Tn 0.1001 0.0200 0.0100 0.0050366 Convergence in Probability, in Law and in r-th Mean
FIGURE 7.10
Distribution Functions Fn and F
Example 7.4.16. Suppose the joint probability density function of (Xn, Y ),
is given by, f(x, y) = ne−y
, 0 < y < x < y+1/n, n ≥ 1. In Example 7.4.15, we
have already noted that Xn
L
→ Y , where Y follows the exponential distribution
with mean 1. To verify Xn
L
→ Y , by simulation, we plot histograms based on
simulated data for n = 50, 100, 150, 200 and on the histograms, impose the
graph of the probability density function of the exponential distribution with
mean 1. We also carry out the test for goodness of fit. We use the following
code to draw these plots and perform the test procedure.
Code 7.4.3. M=300; s=c(50,100,150,200)# vector of values of n
y=matrix(nrow=M,ncol=length(s))
z=matrix(nrow=M,ncol=length(s))
w1=seq(.1,20,.1);length(w1)
w2=matrix(nrow=length(w1),ncol=length(s))
par(mfrow=c(2,2))
for(i in 1:length(s))
{
n=s[i]
set.seed(i+20)Convergence in r-th Mean 367
FIGURE 7.11
Box Plots of |Fn(x) − F(x)| and Values of Tn
y[,i]=rexp(M,rate=1)
set.seed(i+5)
z[,i]=runif(M,y[,i],y[,i]+1/n )
no=paste("n =",s,sep=" ")
hist((z[,i]),freq=FALSE,main=no[i],col="light blue",
xlab=expression(paste(X_n)))
w2[,i]=dexp(w1,rate=1 )
lines(w1,w2[,i],main=s[i],col="dark blue",lwd=1,type="o",
pch=20)
}
O=hist(z[,4],plot=FALSE)$counts; sum(O)
bk=hist(z[,4],plot=FALSE)$breaks; bk
m=max(bk); e=exp(1); ep=c()
for(i in 1:(length(bk)-1))
{
ep[i]=e^(-bk[i])-e^(-bk[i+1])
}
a=1-sum(ep); a; ep1=c(ep, a); ef=sum(O)*ep1; O1=c(O,0)368 Convergence in Probability, in Law and in r-th Mean
d=data.frame(O1,round(ef,2)); d
ts=sum((O1-ef)^2/ef);ts
df=length(ef)-1; df; b=qchisq(.95,df); b
p1=1-pchisq(ts,df); p1; chisq.test(O1,p=ep1)
# pooling of frequencies less than 5 is ignored
From Figure 7.12, we note that for all n, there is a close agreement be￾tween the two curves, which supports the convergence in law of Xn to Y . We
carry out the goodness of fit test for n = 200. The value of the test statistic
is 10.8026, the 95% cut-off of χ
2
13 is 22.3620 and the p-value comes out to
be 0.6274. Thus, from the graph and the goodness of fit test, we claim that
Xn
L
→ Y . □
As in the mode of almost sure convergence or convergence in probability,
we have Cauchy convergence in r-th mean as defined below.
Definition 7.4.1. A sequence {Xn, n ≥ 1} is said to be Cauchy in r-th mean
if E(|Xn − Xm|
r
) → 0 as , n & m → ∞.
FIGURE 7.12
Convergence in Law of Xn to YConvergence in r-th Mean 369
The advantage of the Cauchy criterion of convergence is that it permits
checking for convergence in r-th mean without identifying the limit of a se￾quence. We will prove the equivalence of Cauchy convergence in r-th mean
and convergence in r-th mean in Chapter 8 after discussing Fatou’s lemma.
Following is a quick recap of the results discussed in this chapter.
Summary
1. Convergence in probability: Xn
P
→ X, if P[|Xn − X| < ϵ] → 1 as
n → ∞, ∀ ϵ > 0.
2. Convergence in law: If Fn(x) = P[Xn ≤ x] → P[X ≤ x] = F(x),
∀ x ∈ C(FX), then Xn
L
→ X, where C(FX) is a set of points of continuity
of the distribution function of X.
3. Convergence in r-th mean: Xn
r→ X if E(|Xn−X|
r
) → 0 as n → ∞, r > 0,
where ∀ n ≥ 1, Xn & X ∈ Lr space. If r = 2, then the convergence is
referred to as convergence in quadratic mean.
4. For all the modes of convergence, except convergence in law, a sequence
{Xn, n ≥ 1} of random variables and X are defined on the same probability
space.
5. For all the modes of convergence, except convergence in law, convergence
and Cauchy convergence are equivalent.
6. In convergence in probability and convergence in r-th mean, the limit
random variable is almost surely unique. However, in convergence in law,
limit random variables are identically distributed.
7. Xn
a.s. → X ⇒ Xn
P
→ X ⇒ Xn
L
→ X.
8. Xn
P
→ X ⇐⇒ Xn
L
→ X if and only if X is a degenerate random
variable.
9. Xn
r→ X ⇒ Xn
P
→ X.
10. Xn
P
→ X ⇒ Xn
r→ X, if Xn’s are almost surely bounded.
11. If Xn
P
→ X, then there exists a sub-sequence of {Xn, n ≥ 1} which con￾verges to X almost surely.
12. Convergence in probability does not imply convergence of moments or
convergence in r-th mean.
13. Convergence in r-th mean implies convergence of r-th order moments, but
the converse is not true.370 Convergence in Probability, in Law and in r-th Mean
14. In general, almost sure convergence neither implies nor is implied by the
convergence in r-th mean.
15. Xn
r→ X ⇒ Xn
s→ X, ∀ s < r .
16. Xn
q.m. → b if and only if E(Xn) → b and V ar(Xn) → 0, where b is a
constant.
17. If a sequence {Xn, n ≥ 1} of random variables is uniformly bounded, then
Xn
P
→ C implies E(Xn) → C and E(Xn − C)
2 → 0.
18. Convergence in probability is closed under arithmetic operations.
19. Convergence in law and convergence in probability are closed under con￾tinuous transformation.
20. If Xn
P
→ X or if Xn
L
→ X, then the sequence {Xn, n ≥ 1} is bounded in
probability.
21. If Yn
P
→ 0 and if X is a real random variable then XYn
P
→ 0.
22. If Xn
P
→ C < 0, then P[Xn ≤ 0] → 1 as n → ∞. If Xn
P
→ C > 0, then
P[Xn > 0] → 1 as n → ∞.
23. If Xn − Yn
P
→ 0 and Yn
L
→ X, then Xn
L
→ X.
24. If the sequence {Xn, n ≥ 1} is bounded in probability and if Yn
P
→ 0, then
XnYn
P
→ 0.
25. Slutsky’s theorem: If Xn
L
→ X and Yn
L
→ C, then (i) Xn ± Yn
L
→ X ± C.
(ii) XnYn
L
→ XC. (iii) Xn/Yn
L
→ X/C, provided Xn/Yn and X/C are
defined.
26. Suppose {Xn, n ≥ 1} is a sequence of random variables with ϕn(t), t ∈ R
being a characteristic function of Xn, n ≥ 1. Suppose X is a random
variable with ϕ(t), t ∈ R as its characteristic function. Then
ϕn(t) → ϕ(t) ∀ t ∈ R ⇐⇒ Xn
L
→ X .
27. Suppose {Xn, n ≥ 1} is a sequence of random variables with ϕn(t), t ∈ R
being a characteristic function of Xn, n ≥ 1. Suppose ϕn(t) → ϕ(t) ∀ t ∈
R as n → ∞, where ϕ(t) is continuous at t = 0. Then there exists a random
variable X with characteristic function ϕ(t) such that Xn
L
→ X.Conceptual Exercises 371
7.5 Conceptual Exercises
7.5.1 Suppose {Xn, n ≥ 1} is a sequence of random variables such that
P[Xn = ±n] = 1/2. Using the definitions, examine if Xn
L
→ X, Xn
P
→ 0
and Xn
r→ 0. Verify the known implications among these modes of
convergence. Examine if Xn
a.s. → X.
7.5.2 Suppose Xn ≡ 1/n and Yn ≡ −1/n. Using the definitions examine
whether Xn and Yn converge in law, in probability, r-th mean and almost
surely.
7.5.3 Suppose{Xn, n ≥ 1} is a sequence of random variables such that
P[Xn = 0] = 1 − 1/n2 & P[Xn = e
n] = 1/n2
. Using the definitions,
examine if Xn
L
→ 0, Xn
P
→ 0 and Xn
r→ 0. Using a sufficient condition,
examine if Xn
a.s. → 0. Hence, verify the known implications among these
modes of convergence.
7.5.4 Suppose a probability mass function of a random variable Xn is given
by,
P[Xn =
√
n] = 1/n = 1 − P[Xn = 0].
Examine whether Xn
P
→ 0, Xn
L
→ 0 and Xn
q.m. → 0.
7.5.5 Suppose a probability mass function of a random variable Xn is given
by,
P[Xn = 0] = 1/n2 = 1 − P[Xn = n].
Examine whether Xn
P
→ 0, Xn
L
→ 0, Xn
a.s. → 0 and Xn
q.m. → 0.
7.5.6 Suppose {Xn, n ≥ 1} is a sequence of discrete random variables with
probability mass function given by,
P[Xn = x] = 
1/n, if x = n
1 − 1/n, if x = 0.
Discuss the limiting behaviour of {Xn, n ≥ 1} in probability, in law and
in quadratic mean.
7.5.7 Suppose {Xn, n ≥ 1} is a sequence of random variables defined as
Xn = X+Yn where X is a random variable and {Yn, n ≥ 1} is a sequence
of random variables such that E(Yn) = 1/n and V ar(Yn) = σ
2/n where
σ > 0 is a constant. Verify whether Xn
P
→ X.
7.5.8 Suppose {Xn, n ≥ 1} is a sequence of random variables defined on the
probability space (Ω, A, P) where Ω = [0, 1], A is a sigma field of subsets
of [0, 1] and P((a, b)) = b − a for (a, b) ∈ A. Suppose {Xn} is defined as
Xn(ω) = 
1, if 0 ≤ ω < (n + 1)/2n
0, otherwise.372 Convergence in Probability, in Law and in r-th Mean
X is a random variable defined as X(ω) = 1 if 0 ≤ ω < 1/2 and 0
otherwise. Examine whether Xn
a.s. → X, Xn
P
→ X, Xn
L
→ X and
Xn
q.m. → X.
7.5.9 Suppose {Xn, n ≥ 1} is a sequence of discrete random variables with
probability mass function given by,
P[Xn = −(n + 4)] = 1/(n + 4), P[Xn = −1] = 1 − 4/(n + 4)
& P[Xn = n + 4] = 3/(n + 4).
Discuss the limiting behaviour of {Xn} in probability, in law and in
quadratic mean to X ≡ −1 and X ≡ 0. Examine whether E(Xn) con￾verges.
7.5.10 Suppose {Xn, n ≥ 1} is a sequence of discrete random variables with
probability mass function given by, P[Xn = ±1/n] = 1/2. Discuss the
limiting behaviour of {Xn} in probability, in law, almost surely and in
quadratic mean to X. Examine whether E(Xn) → E(X).
7.5.11 Suppose {Xn, n ≥ 1} is a sequence of continuous random variables with
support [−1/n, 1/n] and with the probability density function given by,
fXn
(x) = 
n/2, if x ∈ [−1/n, 1/n]
0, if x /∈ [−1/n, 1/n].
Examine whether the sequence {Xn, n ≥ 1} converges in quadratic
mean, in probability, in law and almost surely.
7.5.12 Suppose (Ω, A, P) is a probability space, where Ω = [0, 1], A is a sigma
field of subsets of Ω and P(An) = 1/n for An = [0, 1/n). Suppose
Xn = e
nIAn
, n ≥ 1. Show that Xn
P
→ 0, but Xn
r↛ 0.
7.5.13 Suppose {X1, X2, · · · , Xn} are independent and identically distributed
random variables with the probability density function f(x) = αx−α−1
for x > 1, α > 0. Suppose Yn = n
−1/αX(n)
. Examine whether Yn con￾verges in law.
7.5.14 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables, such that Xn = 1 or 0 with probability
1/2 each. Suppose Yn = 1−Xn. Show that Xn
L
→ X and Yn
L
→ Y , where
X and Y are identically distributed random variables, with values 1 and
0 with equal probabilities 1/2. Examine whether Xn + Yn
L
→ X + Y .
Examine whether Xn and Yn are independent random variables.
7.5.15 Suppose {Xn, n ≥ 1} is a sequence of random variables such that Xn
follows N(0, σ2/n). Suppose a function g : R → R is defined as
g(x) = 
0, if x ≤ 0
1, if x > 0.
Show that Xn
P
→ X ≡ 0, but g(Xn)
P↛ g(X).Conceptual Exercises 373
7.5.16 Suppose Xn ∼ G(n, n). Examine if Xn
r→ 1 for r > 1 and Xn
a.s. → 1.
7.5.17 Suppose {Xn, n ≥ 1} is a sequence of random variables such that Xn
has Cauchy distribution with probability density function given by
f(x, n) = (n/π)(1/(1 + n
2x
2
)), x ∈ R. Examine whether Xn
P
→ 0,
Xn
r→ 0, r ≥ 1 and Xn
L
→ 0.
7.5.18 Suppose {Xn, n ≥ 1} is a sequence of random variables such that Xn
has Cauchy distribution with probability density function given by
f(x, n) = (n/π)(1/(n
2 + x
2
)), x ∈ R. Examine whether Xn
P
→ 0, Xn
r→
0, r ≥ 1, Xn
L
→ 0 and Xn
a.s. → 0.
7.5.19 Suppose X is a real random variable defined on a probability space on
(Ω, A, P) and {An, n ≥ 1} is a sequence of sets in A such that P(An) →
0. Then show that XIAn
P
→ 0.
7.5.20 Show that equivalent random variables are identically distributed.
7.5.21 Suppose Xn = min{Y1, Y2, · · · , Yn}, where {Yn, n ≥ 1} is a sequence of
independent and identically distributed random variables, each having
an exponential distribution with location parameter θ and scale parame￾ter 1. (i) Show that Xn
P
→ θ and Xn
a.s. → θ. (ii) Suppose Un = n(Xn −θ),
then show that Un
L
→ U, where U has exponential distribution with
location parameter 0 and scale parameter 1. (iii) From the limit law of
Un, find the limit law of Vn =
√
n(Xn − θ). (iv) From the limit law of
Un, find the limit law of exp(−Un).
7.5.22 Suppose Xn
L
→ X and Yn
L
→ C, where C ̸= 0 is a degenerate ran￾dom variable. Using the definition of convergence in law, show that (i)
XnC
L
→ XC and (ii) Xn/C L
→ X/C, provided these are defined. Hence
show that XnYn
L
→ XC, and Xn/Yn
L
→ X/C, provided these are de￾fined.
7.5.23 Suppose Xn ∼ χ
2
n
, n ≥ 1 and Yn = (Xn − n)/
√
2n. Examine whether
(i) Xn/n P
→ 1, Xn/n q.m. → 1 and (ii) Yn
L
→ Z ∼ N(0, 1). What is the
distribution of Y
2
n as n → ∞?
7.5.24 Suppose Xn ∼ P(λn) and Yn = (Xn − λn)/
√
λn. Show that Yn
L
→ Z,
which follows N(0, 1) distribution as λn → ∞. What is the distribution
of Y
2
n as λn → ∞?
7.5.25 Suppose {Xn, n ≥ 1} is a sequence of independent random vari￾ables each having uniform U(0, 1) distribution. Suppose X(1) =
min{X1, X2, · · · , Xn} and X(n) = max{X1, X2, · · · , Xn}. Show that (i)
nX(1)
L
→ X, where X has exponential distribution with mean 1, (ii)374 Convergence in Probability, in Law and in r-th Mean
1 − (X(1) + X(n))
P
→ 0 and
(iii) n(1 − X(n))X(1)
P
→ 0.
7.5.26 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables, each having U(0, 1) distribution. Find the
limiting distribution of n(1 − X(n−1)).
7.5.27 Suppose {X1, X2, · · · , Xn} is a random sample from a normal N(θ, 1)
distribution and θ ∈ [0, ∞). The maximum likelihood estimator ˆθn of θ
is given by,
ˆθn =

Xn, if Xn ≥ 0
0, if Xn < 0,
Examine whether ˆθn
P
→ θ. Find the limit law of Yn =
√
n(
ˆθn − θ).
Identify the limiting distribution at θ = 0.
7.5.28 Suppose Xn
P
→ X. Show that |Xn|
L→ |X|.
7.5.29 Suppose Xn
L
→ X where X is a continuous random variable. Using the
definition of convergence in law, show that |Xn|
L→ |X|.
7.5.30 Suppose (Ω, A, P) is a probability space, where Ω = [0, 1], A is a sigma
field of subsets of Ω and P(An) = 1/n for An = [0, 1/n). Suppose the
random variable X and Xn, n ≥ 1 are defined on this space as follows.
X(ω) = 
0, if 0 ≤ ω ≤ 1/2
1, if 1/2 < ω ≤ 1
& Xn(ω) = 
1, if 0 ≤ ω ≤ 1/2
0, if 1/2 < ω ≤ 1.
Examine whether Xn
L
→ X and Xn
P
→ X.
7.5.31 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables, each having the exponential distribution
with scale parameter 1. Examine whether X(n) − log n
L
→ X, where the
distribution function of X is FX(x) = exp(−e
−x
), − ∞ < x < ∞.
7.5.32 Suppose mn is a median of a random variable Xn, n ≥ 1. Show that
if Xn
L
→ X, then any limit point of mn is a median of X.
7.5.33 If {Xn, n ≥ 1} is Cauchy in r-th mean, show that it is Cauchy in
probability.
7.5.34 If Xn
r→ X and Yn
r→ Y , examine whether (i) Xn ± Yn
r→ X ± Y and
(ii) XnYn
r→ XY .
7.5.35 If Xn
r→ X and Yn
r→ Y , examine whether E(XnYn) → E(XY ).Computational Exercises 375
7.5.36 Suppose {Xn, n ≥ 1} is a sequence of independent random vari￾ables such that Pn
i=1(Xi − E(Xi))/sn
L
→ Z ∼ N(0, 1), where s
2
n =
Pn
i=1 V ar(Xi). Show that Pn
i=1(Xi − E(Xi))/n P
→ 0 if and only if
sn/n → 0 as n → ∞.
7.5.37 Suppose {X1, X2, · · · , Xn} is a random sample from a normal N(θ, 1)
distribution, where θ ∈ {0, 1}. The maximum likelihood estimator ˆθn of
θ is given by,
ˆθn =

1, if Xn >
1
2
0, if Xn ≤
1
2
.
Examine whether (i) ˆθn
P
→ θ. (ii) Suppose Yn =
√
n(
ˆθn−θ). Examine the
convergence in law of Yn. (iii) Examine whether ˆθn
a.s. → θ. (iv) Examine
whether for large n,
ˆθn = θ almost surely.
7.6 Computational Exercises
7.6.1 Suppose {X1, X2, · · · , Xn} is a random sample from a normal N(θ, 1)
distribution, where θ ∈ {0, 1}. The maximum likelihood estimator ˆθn of
θ is given by,
ˆθn =

1, if Xn >
1
2
0, if Xn ≤
1
2
.
Examine by simulation whether (i) ˆθn
P
→ θ. (ii) Suppose Yn =
√
n(
ˆθn −
θ). Examine the convergence in law of Yn by simulation.
7.6.2 Suppose Xn ∼ B(n, p). In Section 3, it is shown that Xn
L
→ X, as
p → 0 & n → ∞ such that np → λ, where X ∼ P(λ). Verify the result
by Karl Pearson’s goodness of fit test based on the simulated data.
7.6.3 Suppose Xn = min{Y1, Y2, · · · , Yn}, where {Yn, n ≥ 1} is a sequence of
independent and identically distributed random variables, each having
an exponential distribution with location parameter θ and scale param￾eter 1. Examine by simulation whether (i) Xn
P
→ θ and (ii) Un
L
→ U,
where U has exponential distribution with location parameter 0 and
scale parameter 1 and Un = n(Xn − θ).
7.6.4 Suppose Xn, n ≥ 1 be a sequence of random variables such that
P[Xn = 0] = 1 − 1/n2 & P[Xn = e
n] = 1/n2
. In Exercise 3, we
have examined if Xn
L
→ 0, Xn
P
→ 0 and Xn
r→ 0. Verify these modes of
convergence via simulations.376 Convergence in Probability, in Law and in r-th Mean
7.6.5 Suppose {Xn, n ≥ 1} is a sequence of independent and identically dis￾tributed random variables, each having an exponential distribution with
location parameter 0 and scale parameter 1. Examine by simulation
whether X(n) − log n
L
→ X where the distribution function of X is
FX(x) = exp(−e
−x
), − ∞ < x < ∞.
7.6.6 Suppose Xn ∼ χ
2
n
, n ≥ 1 and Yn = (Xn − n)/
√
2n. Verify the following
results by simulation. (i) Xn/n P
→ 1, (ii)Xn/n q.m. → 1 and (iii) Yn
L
→ Z ∼
N(0, 1) distribution. Use Karl Pearson’s goodness of fit test for (iii).
7.6.7 Suppose Xn ∼ P(λn) and Yn = (Xn − λn)/
√
λn. Verify the result
Yn
L
→ Z ∼ N(0, 1) as λn → ∞, by simulation, graphically and by
Karl Pearson’s goodness of fit test.
7.6.8 Suppose {X1, X2, · · · , Xn} are independent and identically distributed
random variables with the probability density function f(x) = αx−α−1
for x > 1, α > 0. Suppose Yn = n
−1/αX(n)
. In Exercise 7.5.13, it is
shown that Yn converges in law. Verify it by simulation. Use Karl Pear￾son’s goodness of fit test to verify convergence in law. Also verify by
simulation that Yn converges in r-th mean and in probability.
7.7 Multiple Choice Questions
Note: In each question, multiple options may be correct. Unless specified
otherwise, identify which of the statement(s) is/are correct. Answers are given
in Chapter 11, after the solutions of conceptual exercises of Chapter 7.
7.7.1 Among the various modes of convergence of a sequence of random vari￾ables,
(a) almost sure convergence implies convergence in probability
(b) convergence in probability always implies almost sure convergence
(c) almost sure convergence implies convergence in quadratic mean
(d) convergence in quadratic mean implies convergence in law
7.7.2 Among the various modes of convergence of a sequence of random vari￾ables,
(a) almost sure convergence implies convergence in probability
(b) convergence in probability implies almost sure convergence for
monotone sequences
(c) almost sure convergence implies convergence in quadratic mean
(d) convergence in quadratic mean implies almost sure convergenceMultiple Choice Questions 377
7.7.3 Suppose a probability space (Ω, A, P) is defined as follows. Ω = [0, 1], A
is a sigma field of subsets of Ω and P is a Lebesgue measure. Suppose a
sequence {Xn, n ≥ 1} of random variables and a random variable X are
defined as Xn(ω) = e
ω + ω
n, n ≥ 1 and X(ω) = e
ω on (Ω, A, P). Then
(a) Xn
a.s. → X
(b) Xn
P
→ X
(c) Xn
L
→ X
(d) Xn → X pointwise.
7.7.4 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
with
E(Xn) = 0 and V (Xn) = σ
2
n
. In which of the following cases, Sn/n2 P
→ 0,
where Sn =
Pn
k=1 Xk?
(a) σ
2
n = 1
(b) σ
2
n = n
(c) σ
2
n = n
2
(d) σ
2
n = n
3
7.7.5 In which of the following cases, X = Y almost surely?
(a) Xn
P
→ X, Xn
P
→ Y
(b) Xn
a.s. → X, Xn
a.s. → Y
(c) Xn
L
→ X, Xn
L
→ Y
(d) Xn
q.m. → X, Xn
q.m. → Y
7.7.6 In which of the following cases, P[X ̸= Y ] > 0?
(a) Xn
P
→ X, Xn
P
→ Y
(b) Xn
a.s. → X, Xn
a.s. → Y
(c) Xn
L
→ X, Xn
L
→ Y
(d) Xn
q.m. → X, Xn
q.m. → Y
7.7.7 In which of the following cases, X and Y are identically distributed?
(a) Xn
P
→ X, Xn
P
→ Y
(b) Xn
a.s. → X, Xn
a.s. → Y
(c) Xn
L
→ X, Xn
L
→ Y
(d) Xn
q.m. → X, Xn
q.m. → Y
7.7.8 Which of the following types of convergence is/are always invariant un￾der arithmetic operations?
(a) Almost sure convergence
(b) Point-wise convergence
(c) Convergence in probability
(d) Convergence in distribution378 Convergence in Probability, in Law and in r-th Mean
7.7.9 Which of the following types of convergence is/are invariant under con￾tinuous transformation?
(a) Almost sure convergence
(b) Point-wise convergence
(c) Convergence in probability
(d) Convergence in distribution
7.7.10 Suppose (Ω, A, P) is a probability space, where Ω = [0, 1], A is a sigma
field of subsets of Ω and P(An) = 1/n for An = [0, 1/n). Suppose
Xn = IAn
, n ≥ 1. Then
(a) Xn
a.s. → 0
(b) Xn
P
→ 0
(c) Xn
L
→ 0
(d) Xn
r→ 0
7.7.11 Suppose {Xn, n ≥ 1} is a sequence of random variables such that
Xn ∼ N(1/n, 1/n) distribution. Then
(a) Xn
q.m. → 0
(b) Xn
P
→ 0
(c) Xn
L
→ 0
(d) √
n(Xn − 1/n)
L
→ Z ∼ N(0, 1)
7.7.12 Suppose {Xn, n ≥ 1} is a sequence of random variables such that
Xn ∼ U(−n, n) distribution. Then
(a) Xn
L↛ 0
(b) Xn
P↛ 0
(c) Xn
a.s ↛ 0
(d) Xn
q.m. ↛ 0
7.7.13 Suppose Xn
L
→ X and Xn
L
→ Y . The following are three statements.
(I) X and Y are identically distributed random variables. (II) X and
Y are identical random variables. (III) X and Y are equivalent random
variables. Then which of the following is/are true?
(a) Only I is true
(b) Both I and II are true
(c) Both II and III are true
(d) Both I and III are true
7.7.14 Following are three statements. Suppose Xn − Yn
P
→ 0 and Yn
L
→ X.
Then (I) Xn
P
→ X, (II) Xn
L
→ X and (III) the characteristic function
of Xn converges to that of X on R. Then which of the following is/are
true?Multiple Choice Questions 379
(a) Only I is true
(b) Both I and II are true
(c) Both II and III are true
(d) Only II is true
7.7.15 Suppose {Xn, n ≥ 1} is a sequence of random variables such that
P[Xn = 0] = 1 − 1/n3 & P[Xn = n] = 1/n3
, n ≥ 1 .
Following are four statements. (I)Xn
P
→ 0. (II) Xn
L
→ 0. (III) Xn
a.s. → 0.
(IV) Xn
r↛ 0 for r = 3, 4. Then which of the following is/are true?
(a) Only I and III are true
(b) Only I and II are true
(c) Only I, II and III are true
(d) All four are true
7.7.16 If Un =
√
n(Xn − µ)
L
→ X, then which of the following is always true?
(a) Xn
L
→ µ
(b) Xn
a.s. → µ
(c) Xn
P
→ µ
(d) Xn
r→ µ
7.7.17 Following are two statements. Suppose Xn
L
→ X and Yn
L
→ Y . Then
(I) Xn±Yn
L
→ X ±Y always, (II) Xn±Yn
L
→ X ±Y if Xn is independent
of Yn for all n and if X is independent of Y . Which of the following is
true?
(a) Both (I) and (II) are false
(b) Both (I) and (II) are true
(c) (I) is true but (II) is false
(d) (I) is false but (II) is true
7.7.18 If Xn
L
→ X and Yn
L
→ C, where C is a constant. Then
(a) Xn + Yn
L
→ X + C
(b) XnYn
L
→ XC
(c) Xn/Yn
L
→ X/C, provided Xn/Yn and X/C are defined
(d) Xn − Yn
L
→ X − C
7.7.19 Suppose Xn ∼ G(n, n) with probability density function
f(x, n) = n
n
Γ(n)
exp(−nx)x
n−1
, x > 0, n ∈ I
+. Then
(a) Xn
L
→ 1
(b) Xn
P
→ 1
(c) Xn
q.m. → 1380 Convergence in Probability, in Law and in r-th Mean
(d) E(Xn) → 1
7.7.20 Xn
q.m. → b if and only if
(a) E(Xn) → b, where b is a constant
(b) E(Xn) → b and V ar(Xn) → b
(c) E(Xn) → b and V ar(Xn) → 0
(d) E(Xn) → 0 and V ar(Xn) → b
7.7.21 Suppose Xn and X ∈ Lr. Then
(a) E(|Xn − X|
r
) → 0 ⇒ E(|Xn|
r
) → E(|X|
r
)
(b) E(|Xn − X|
r
) → 0 ⇒ Xn
P
→ X
(c) E(|Xn|
r
) → E(|X|
r
) ⇒ E(|Xn − X|
r
) → 0
(d) E(|Xn − X|
r
) → 0 ⇒ Xn
L
→ X
7.7.22 If Xn
a.s. → X, then which of the following is/are always true?
(a) e
Xn
a.s. → e
X
(b) e
Xn
P
→ e
X
(c) e
Xn
L
→ e
X
(d) e
Xn
q.m. → e
X
7.7.23 suppose Xn
a.s. → X, Yn and Y are defined as Yn = X3
n + 2X2
n + 3Xn + 2
and Y = X3 + 2X2 + 3X + 2. The following are three statements.
(I) Yn
a.s. → Y (II) Yn
P
→ Y (III) Yn
L
→ Y . Which of the following is the
correct option?
(a) Only I is true
(b) Only I and II are true
(c) Only II and III are true
(d) All three are true
7.7.24 If Xn
a.s. → X, then which of the following statements is/are not always
correct?
(a) e
Xn
a.s. → e
X
(b) e
Xn
P
→ e
X
(c) e
Xn
L
→ e
X
(d) e
Xn
q.m. → e
X
7.7.25 If Xn
r→ X, then which of the following statements is/are always cor￾rect?
(a) |Xn|
P→ |X|
(b) |Xn|
L→ |X|
(c) |Xn|
a.s. → |X|
(d) E(|Xn|
r
) → E(|X|
r
), r > 0 as n → ∞Multiple Choice Questions 381
7.7.26 If Xn
P
→ X, then which of the following statements is/are always true?
(a) E(|Xn|
r
) → E(|X|
r
), r > 0 as n → ∞
(b) E(|Xn − X|
r
) → 0, r > 0 as n → ∞
(c) E(|Xn − X|
r
) → 0, r > 0 as n → ∞, if Xn’s are almost surely
bounded.
(d) E(Xn) → E(X) as n → ∞
7.7.27 Suppose X is a real random variable on a probability space (Ω, A, P)
and
{An, n ≥ 1} is a sequence of sets in A. Then
(a) An ↓ ∅ ⇒ XIAn
P
→ 0
(b) An ↓ ∅ ⇒ XIAn
P
→ X
(c) An ↓ ∅ ⇒ XIAn
P
→ 1
(d) An ↓ ∅ ⇒ IAn
L
→ 0
7.7.28 Suppose X is a real random variable on a probability space (Ω, A, P)
and
{An, n ≥ 1} is a sequence of events in A. Then
(a) An ↑ Ω ⇒ XIAn
P
→ 0
(b) An ↑ Ω ⇒ XIAn
P
→ X
(c) An ↑ Ω ⇒ XIAn
P
→ 1
(d) An ↑ Ω ⇒ IAn
L
→ 1
7.7.29 Suppose {Xn, n ≥ 1} is a sequence of random variables defined as
Xn = (1 + 1/n) X, where X is a discrete random variable with support
{0, 1} and P[X = 0] = 2/3. Then
(a) Xn
P
→ X
(b) Xn
r→ X
(c) Xn
a.s. → X
(d) Xn
L
→ X
7.7.30 Suppose {Xn, n ≥ 1} be a sequence of random variables such that Xn
has uniform U(−n, n) distribution. Then
(a) Xn does not converge in law
(b) Xn converges to 0 in probability
(c) Xn does not converge in quadratic mean
(d) Xn converges to 0 almost surely
7.7.31 Following are two statements: (I) Xn
L
→ C ⇒ Xn
P
→ C, where C is a
constant. (II) Xn
P
→ C ⇒ Xn
L
→ C, where C is a constant. Then which
of the following statements is true?
(a) Both (I) and (II) are false382 Convergence in Probability, in Law and in r-th Mean
(b) Both (I) and (II) are true
(c) (I) is true but (II) is false
(d) (I) is false but (II) is true
7.7.32 Suppose X is a non-degenerate random variable. Following are two
statements: (I) Xn
L
→ X ⇒ Xn
P
→ X. (II) Xn
P
→ X ⇒ Xn
L
→ X. Then
which of the following statements is true?
(a) Both (I) and (II) are false
(b) Both (I) and (II) are true
(c) (I) is true but (II) is false
(d) (I) is false but (II) is true
7.7.33 Suppose Xn has normal N(0, 1/n) distribution. Then
(a) Xn
L
→ 0
(b) Xn
P
→ 0
(c) Xn
q.m. → 0
(d) Xn
a.s. → 0
7.7.34 Suppose Xn has normal N(0, 1/n) distribution. Then
(a) Xn
L
→ 0
(b) Xn
P
→ 0
(c) Xn
q.m. → 0
(d) √
nXn
L
→ Z ∼ N(0, 1)
7.7.35 Suppose √
n(Xn − µ)
L
→ X ∼ N(0, σ2
) distribution. Suppose g is a
differentiable function with g
′
(µ) ̸= 0 and Un =
√
n(g(Xn) − g(µ)). Fol￾lowing are four statements. (I)Un
L
→ U ∼ N(0, g(σ
2
)) distribution.
(II) Un
L
→ U ∼ N(0, g′
(µ)σ
2
) distribution. (III) Un
L
→ U ∼
N(0,(g
′
(µ))2σ
2
) distribution. (IV) The given information is not suffi￾cient to find the limit law of Un. Then which of the following statements
is true?
(a) Only (I) is true
(b) Only (II) is true
(c) Only (III) is true
(d) Only (IV) is true
7.7.36 Suppose (Ω, A, P) is a probability space, where Ω = [0, 1], A is a sigma
field of subsets of Ω and P(An) = 1/n for An = [0, 1/n). Suppose the
random variable X and Xn, n ≥ 1 are defined as on this space as follows.
X(ω) = 
0, if 0 ≤ ω ≤ 1/2
1, if 1/2 < ω ≤ 1
& Xn(ω) = 
1, if 0 ≤ ω ≤ 1/2
0, if 1/2 < ω ≤ 1.
Following are two statements. (I) Xn
L
→ X. (II) Xn
P
→ X. Then which
of the following statements is true?Multiple Choice Questions 383
(a) Both (I) and (II) are false
(b) Both (I) and (II) are true
(c) (I) is true but (II) is false
(d) (I) is false but (II) is true
7.7.37 Suppose {Xn, n ≥ 1} is Cauchy in r-th mean. Following are two state￾ments. (I) {Xn, n ≥ 1} is Cauchy in probability. (II) {Xn, n ≥ 1} con￾verges in law. Then which of the following statements is true?
(a) Both (I) and (II) are false
(b) Both (I) and (II) are true
(c) (I) is true but (II) is false
(d) (I) is false but (II) is true
7.7.38 Suppose {Xn, n ≥ 1} is Cauchy in r-th mean. Following are two state￾ments. (I) {Xn, n ≥ 1} is Cauchy in probability. (II) {Xn, n ≥ 1} con￾verges in probability. Then which of the following statements is true?
(a) Both (I) and (II) are false
(b) Both (I) and (II) are true
(c) (I) is true but (II) is false
(d) (I) is false but (II) is true
7.7.39 Suppose {Xn, n ≥ 1} is Cauchy in r-th mean. Following are two state￾ments. (I) {Xn, n ≥ 1} is Cauchy in probability. (II) {Xn, n ≥ 1} con￾verges almost surely. Then which of the following statements is true?
(a) Both (I) and (II) are false
(b) Both (I) and (II) are true
(c) (I) is true but (II) is false
(d) (I) is false but (II) is true
7.7.40 Suppose {Xn, n ≥ 1} is a sequence random variables such that
P[Xn = 1] = 1/ log n and P[Xn = 0] = 1 − 1/ log n. Following are
two statements. (I) Xn
P
→ 0 (II) Xn
r→ 0. Then which of the following
statements is true?
(a) Both (I) and (II) are false
(b) Both (I) and (II) are true
(c) (I) is true but (II) is false
(d) (I) is false but (II) is true
7.7.41 Suppose {Xn, n ≥ 1} is a sequence random variables such that
P[Xn = 1] = 1/ log n and P[Xn = 0] = 1 − 1/ log n. The following are
three statements. (I) Xn
P
→ 0. (II). Xn
r→ 0. (III) Xn
L
→ 0. Then which
of the following statements is/are true?
(a) Only (I) is true
(b) Only (II) is true
(c) Only (I) and (II) are true384 Convergence in Probability, in Law and in r-th Mean
(d) All three are true
7.7.42 Suppose {Xn, n ≥ 1} is a sequence random variables such that
P[Xn = 0] = 1/n2 and P[Xn = n] = 1 − 1/n2
. Following are four
statements. (I) Xn
L
→ 0. (II) Xn
r→ 0. (III) Xn
P
→ 0. (IV) Xn
a.s → 0.
Then which of the following statements is true?
(a) Only (I) is true
(b) Only (II) is true
(c) Only (I) and (II) are true
(d) None of the statements is true
7.7.43 Suppose {Xn, n ≥ 1} is a sequence random variables such that
P[Xn = 0] = 1 − 1/n3 and P[Xn = n] = 1/n3
. Following are four
statements. (I) Xn
P
→ 0. (II) Xn
q.m. → 0. (III) Xn
L
→ 0. (IV) Xn
a.s. → 0.
Then which of the following statements is true?
(a) Only (I) is true
(b) Only (II) is true
(c) Only (I), (II) and (III) are true
(d) All four are true
7.7.44 Suppose {Xn, n ≥ 1} is a sequence of random variables such that Xn
follows Cauchy distribution with probability density function
f(x, n) = (n/π)(1/(n
2 + x
2
)), x ∈ R. Following are three statements.
(I) Xn
L
→ 0. (II) Xn
P
→ 0. (III) Xn
a.s → 0. Then which of the following
statements is true?
(a) Only (I) is false
(b) Only (II) is false
(c) Only (I) and (II) are false
(d) All the statements are false
7.7.45 Suppose {Xn, n ≥ 1} is a sequence random variables such that
P[Xn = ±n] = 1/(2n
α) and P[Xn = 0] = 1 − 1/nα, 0 < α ≤ 2.
Following are two statements. (I) Xn
P
→ 0 (II) Xn
q.m. → 0. Then which of
the following statements is true?
(a) Both (I) and (II) are false
(b) Both (I) and (II) are true
(c) (I) is true but (II) is false
(d) (I) is false but (II) is true
7.7.46 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables, each following uniform U(2, 6) distribu￾tion. Following are four statements. (I) X(n)
P
→ 6 (II) X(1)
P
→ 2. (III)
X(1)
L
→ 2.Multiple Choice Questions 385
(IV) Mn
P
→ 4, where Mn is the median of {X1, X2, · · · , Xn}. Then which
of the following statements is true?
(a) Only (I) and (II) are true
(b) Only (I) and (IV) are true
(c) Only (I), (II) and (III) are true
(d) All four are true
7.7.47 Suppose {Xn, n ≥ 1} is a sequence of random variables with ϕn(t),
t ∈ R, being a characteristic function of Xn, n ≥ 1. Suppose X is a
random variable with ϕ(t), t ∈ R as its characteristic function. Then
which of the following statements is/are true?
(a) Xn
P
→ X ⇒ ϕn(t) → ϕ(t) ∀ t ∈ R
(b) Xn
q.m. → X ⇒ ϕn(t) → ϕ(t) ∀ t ∈ R
(c) Xn
a.s. → X ⇒ ϕn(t) → ϕ(t) ∀ t ∈ R
(d) Xn
L
→ X ⇒ ϕn(t) → ϕ(t) ∀ t ∈ R8
Convergence of a Sequence of Expectations
8.1 Introduction
In Chapters 6 and 7, we studied various modes of convergence of a sequence
of random variables. It is of interest to examine which of these modes im￾ply convergence of a sequence of expectations of random variables. We have
discussed some examples and theorems, where we have the convergence of a
sequence of expectations corresponding to two modes of convergence. These
are listed below.
(i) In Example 7.2.10, we have noted that convergence in probability does
not in general imply convergence of the corresponding moments. But
if the random variables are uniformly bounded, then it is proved in
Theorem 7.2.3 that
Xn
P
→ C ⇒ E(Xn) → C & Xn
r→ C, C ∈ R.
(ii) Theorem 7.4.4 proves that Xn
r→ X ⇒ E(|Xn|
r
) → E(|X|
r
) for r > 0.
(iii) In Theorem 7.4.2, it is proved that if Xn’s are almost surely bounded,
then
Xn
P
→ X ⇒ Xn
r→ X ⇒ E(|Xn|
r
) → E(|X|
r
), r > 0.
In the present chapter, we discuss the following three results in which
we have convergence of sequence of expectations of random variables, corre￾sponding to pointwise convergence, almost sure convergence and convergence
in probability.
(i) If {Xn, n ≥ 1} is a non-decreasing sequence of non-negative random
variables such that Xn → X on Ω then E(Xn) → E(X).
(ii) If |Xn| ≤ Y such that E(Y ) < ∞ and if Xn
a.s. → X then E(Xn) → E(X).
(iii) If |Xn| ≤ Y a.s. such that E(Y ) < ∞ and if Xn
P
→ X then E(Xn) →
E(X).
DOI: 10.1201/9781032619057-8 386Monotone Convergence Theorem 387
The first result is known as the monotone convergence theorem. We prove
in the next section that the result is true for a monotone sequence converging
to X on Ω. In literature there is some confusion in labeling the results (ii)
and (iii). Many authors label result (ii) as Lebesgue dominated convergence
theorem or dominated convergence theorem, for example refer to Athreya and
Lahiri [3], Billingsley [5], Gut [13] and Shao [21]. In result (iii) almost sure
convergence from (ii) is replaced by convergence in probability. This result is
also referred to as the dominated convergence theorem, for example refer to
Bhat [4] and Loeve [16]. To avoid the confusion, we label result (ii) as the
Lebesgue dominated almost sure convergence theorem and result (iii) as the
Lebesgue dominated probability convergence theorem.
We begin with the monotone convergence theorem in the next section and
using it prove the Lebesgue dominated almost sure convergence theorem. The
Lebesgue dominated probability convergence theorem is discussed in Section
3.
8.2 Monotone Convergence Theorem
In Chapter 4 we have defined the expectation of a random variable as an inte￾gral with respect to a probability measure. The expectation of a non-negative
random variable X is defined as E(X) = limn→∞ E(Xn) where {Xn, n ≥ 1}
is a non-decreasing sequence of non-negative simple random variables such
that Xn → X on Ω. The definition of expectation of a non-negative random
variable X can be expressed as E(X) = E(limn→∞ Xn) = limn→∞ E(Xn).
It is to be noted that here limit and expectation are interchanged. It is of
interest to see in which other cases we can interchange limit and expectation.
In this chapter we study three theorems, which specify the conditions under
which we can interchange limit and expectation.
Following lemma is heavily used in the proof of the monotone convergence
theorem.
Lemma 8.2.1. Suppose U1, U2, · · · , Uk are simple random variables defined
on a probability space (Ω, A, P). Then Wk = max{U1, U2, · · · , Uk} is also a
simple random variables defined on the probability space (Ω, A, P).
Proof. Suppose U1 =
Pm
i=1 aiIAi
and U2 =
Pn
j=1 bj IBj where {A1, A2, · · · ,
Am} and {B1, B2, · · · , Bn} form measurable partitions of Ω and {a1, a2, · · · ,
am} and {b1, b2, · · · , bn} are real numbers. Now for
ω ∈ Cij = Ai ∩ Bj , W2(ω) = max{U1(ω), U2(ω)} = max{ai
, bj} = cij , say.
Further, when {A1, A2, · · · , Am} and {B1, B2, · · · , Bn} are measurable parti￾tions of Ω, as shown in Theorem 2.4.1, {Cij , i = 1, 2, · · · , m, j = 1, 2, · · · , n}
is also a measurable partition of Ω. Thus W2 can be expressed as388 Convergence of a Sequence of Expectations
W2 =
Pm
i=1
Pn
j=1 cij ICij and hence W2 is a simple random variable. Thus,
the lemma is true for k = 2. Suppose k = 3, then
W3 = max{U1, U2, U3} = max{max{U1, U2}, U3} = max{W2, U3}
is again a simple random variable. Continuing in this manner, it follows that
Wk is a simple random variable.
In Theorem 2.4.3 we have proved that, if X is a non-negative random
variable then there exists a non-decreasing sequence {Xn, n ≥ 1} of non￾negative simple random variables, such that Xn → X on Ω. Expectation
E(X) of X is then defined as limn→∞ E(Xn). Thus, if Xn → X on Ω then
E(Xn) → E(X). Monotone convergence theorem, proved below states that
Xn → X on Ω implies E(Xn) → E(X), even if {Xn, n ≥ 1} is not a sequence of
simple random variables but it has to be a monotone sequence. In the proof, we
use Theorem 2.4.3 and the definition of expectation of a non-negative random
variable as given above. We prove it in four steps as follows: {Xn, n ≥ 1} is
such that (i) 0 ≤ Xn ↑ X, (ii) Y ≤ Xn ↑ X with E(Y ) < ∞, (iii) 0 ≥ Xn ↓ X
and (iv) Y ≥ Xn ↓ X with E(Y ) < ∞. The first case is traditionally known
as the monotone convergence theorem and the other cases are given as the
corollaries to the monotone convergence theorem. We begin with case (i).
Theorem 8.2.1. Monotone convergence theorem for non-decreasing sequence
of non-negative random variables: Suppose {Xn, n ≥ 1} is a non-decreasing
sequence of non-negative random variables defined on a probability space
(Ω, A, P). If Xn ↑ X on Ω, then E(Xn) ↑ E(X).
Proof. From the properties of expectation, ∀ n ≥ 1
Xn ≥ 0 ⇒ E(Xn) ≥ 0 & Xn ≤ Xn+1 ⇒ E(Xn) ≤ E(Xn+1).
Thus, {E(Xn), n ≥ 1} is a non-decreasing sequence of non-negative real
numbers and hence it has a limit, which may be finite or infinite. Now
Xk ≥ 0, hence by Theorem 2.4.3, corresponding to each Xk there exists a
non-decreasing sequence {Xkn, n ≥ 1} of non-negative simple random vari￾ables, such that Xkn → Xk on Ω as n → ∞. Thus, we have
0 ≤ X11 ≤ X12 ≤ X13 ≤ · · · → X1
0 ≤ X21 ≤ X22 ≤ X23 ≤ · · · → X2
0 ≤ X31 ≤ X32 ≤ X33 ≤ · · · → X3
.
.
.
.
.
.
0 ≤ Xn1 ≤ Xn2 ≤ Xn3 ≤ · · · → Xn. (8.1)Monotone Convergence Theorem 389
We define
Y1 = max{Xk1, k ≤ 1} = X11
Y2 = max{Xk2, k ≤ 2} = max{X12, X22} = max{X11, X12, X21, X22}
= max
i≤2,j≤2
{Xij}, since X11 ≤ X12 & X21 ≤ X22.
Continuing in this manner we define
Yn = max{Xkn, k ≤ n} = max
i≤n,j≤n
{Xij},
which follows from the array presented in (8.1). In Lemma 8.2.1 we have
proved that the maximum of simple random variables is again a simple random
variable, hence Yn is a simple random variable. Further, 0 ≤ Yn ≤ Yn+1 ∀ n ≥
1. Thus, {Yn, n ≥ 1} is a non-decreasing sequence of non-negative simple
random variables. To find its limit, from the definitions of Yn and Xkn we
note that,
Xkn ≤ Yn ≤ Xn on Ω ⇒ E(Xkn) ≤ E(Yn) ≤ E(Xn). (8.2)
Allowing n → ∞ in (8.2) we get,
Xk ≤ limn→∞
Yn ≤X on Ω & limn→∞
E(Xkn)=E(Xk) ≤ limn→∞
E(Yn)≤ limn→∞
E(Xn),
(8.3)
as {Xkn, n ≥ 1} is a sequence of simple random variables converging to Xk.
Allowing k → ∞ in (8.3) we get,
X ≤ limn→∞
Yn ≤ X on Ω & lim
k→∞
E(Xk) ≤ limn→∞
E(Yn) ≤ limn→∞
E(Xn). (8.4)
Equation (8.4) further implies that,
limn→∞
Yn = X on Ω & limn→∞
E(Yn) = limn→∞
E(Xn). (8.5)
Thus, {Yn, n ≥ 1} is a non-decreasing sequence of non-negative simple random
variables converging to X ≥ 0 on Ω. Hence, by the definition of expectation
of a non-negative random variable,
E(X) = limn→∞
E(Yn) = limn→∞
E(Xn) by Equation (8.5)
⇐⇒ E( limn→∞
Xn) = limn→∞
E(Xn).
Following are some corollaries to Theorem 8.2.1.
Corollary 8.2.1. Suppose Y ≤ Xn ↑ X on Ω and Y is an integrable random
variable. Then E(Y ) ≤ E(Xn) ↑ E(X).390 Convergence of a Sequence of Expectations
Proof. Suppose Zn = Xn − Y then 0 ≤ Zn ↑ X − Y on Ω. Hence by Theorem
8.2.1, E(Zn) = E(Xn) − E(Y ) ↑ E(X) − E(Y ). It is given that Y is an
integrable random variable, hence E(Y ) < ∞. Thus, adding E(Y ) on both
sides we get E(Xn) ↑ E(X).
Remark 8.2.1. Corollary 8.2.1 conveys that Xn’s need not be non-negative
but the sequence {Xn, n ≥ 1} must be non-decreasing and bounded from
below by an integrable random variable.
Corollary 8.2.2. Suppose 0 ≥ Xn ↓ X on Ω, then E(Xn) ↓ E(X).
Proof. Since 0 ≥ Xn ↓ X, 0 ≤ −Xn ↑ −X on Ω. Hence by Theorem 8.2.1,
E(−Xn) = −E(Xn) ↑ E(−X) = −E(X). Thus, E(Xn) ↓ E(X).
Corollary 8.2.3. Suppose Y ≥ Xn ↓ X on Ω and Y is an integrable random
variable. Then E(Xn) ↓ E(X).
Proof. Suppose Zn = Xn − Y then 0 ≥ Zn ↓ X − Y on Ω. Hence by Corollary
8.2.2, E(Zn) = E(Xn) − E(Y ) ↓ E(X) − E(Y ), which implies that E(Xn) ↓
E(X) since E(Y ) < ∞.
Remark 8.2.2. Corollary 8.2.3 conveys that Xn’s need not be non-positive
but the sequence {Xn, n ≥ 1} must be non-increasing and bounded from above
by an integrable random variable.
Remark 8.2.3. Theorem 8.2.1 and Corollaries 8.2.1, 8.2.2 and 8.2.3 con￾vey that if {Xn, n ≥ 1} is non-decreasing and bounded from below or non￾increasing and bounded from above, by an integrable random variable, then
lim E(Xn) = E(lim Xn). Hence, we may state the monotone convergence the￾orem as follows. The proof follows by combining the proofs of Theorem 8.2.1
and Corollaries 8.2.1, 8.2.2 and 8.2.3.
Theorem 8.2.2. Monotone convergence theorem: Suppose {Xn, n ≥ 1} is a
non-decreasing sequence bounded from below by an integrable random variable
or a non-increasing sequence bounded from above by an integrable random
variable. If Xn → X on Ω, then limn→∞ E(Xn) = E(limn→∞ Xn).
In Chapter 4, we have discussed the linearity property of the expecta￾tion, which states that expectation of a finite sum of random variables is the
sum of their expectations. In many applications we would like to have such a
property for a countably infinite sum of random variables. The following two
corollaries convey that it is possible, using the monotone convergence theorem.
Thus, if we have a monotone sequence of random variables, then summation
and expectation can be interchanged. In other words, “E” operation is sigma
additive on the family of such random variables.
Corollary 8.2.4. Suppose {Xn, n ≥ 1} is a sequence of non-negative random
variables then E(
P
n≥1 Xn) = P
n≥1 E(Xn).Monotone Convergence Theorem 391
Proof. Suppose Zn =
Pn
i=1 Xi
. Then 0 ≤ Zn ↑
P
i≥1 Xi = X, say on Ω. It is
to be noted that lim Zn =
P
i≥1 Xi
is well defined, it may be infinite for some
ω. Hence by the monotone convergence theorem, lim E(Zn) = E(lim Zn). Now
limn→∞
E(Zn) = limn→∞
E
Xn
i=1
Xi

= limn→∞
Xn
i=1
E(Xi) = X
i≥1
E(Xi)
& E( limn→∞
Zn) = E
X
i≥1
Xi

Hence, limn→∞
E(Zn) = E( limn→∞
Zn) ⇒ E
X
n≥1
Xn

=
X
n≥1
E(Xn).
Corollary 8.2.5. Suppose {Xn, n ≥ 1} is a sequence of non-positive random
variables then E(
P
n≥1 Xn) = P
n≥1 E(Xn).
Proof. Suppose Yn = −Xn. Then {Yn, n ≥ 1} is a sequence of non-negative
random variables. Hence by Corollary 8.2.4,
E
X
n≥1
Yn

=
X
n≥1
E(Yn) ⇐⇒ E
X
n≥1
(−Xn)

=
X
n≥1
E(−Xn)
⇐⇒ E
X
n≥1
Xn

=
X
n≥1
E(Xn).
Example 8.2.1. Suppose (Ω, A, P) is a probability space, where Ω = [0, 1],
A is a sigma field of subsets of Ω, An = [0, 1/n) and Xn = IAn
, n ≥ 1. In
Example 6.3.7, we have noted that {An, n ≥ 1} is a decreasing sequence of
sets and hence is convergent with limn→∞ An =
T
n≥1 An = ∅. By Theorem
2.3.9 IAn
↓ I∅ on Ω ⇐⇒ Xn ↓ X ≡ 0 on Ω. Note that by Corollary 8.2.3,
1 ≥ IAn
↓ I∅ on Ω ⇒ E(IAn
) ↓ E(I∅) ⇒ P(An) ↓ 0,
which also follows from the continuity theorem for a probability measure. □
In the following theorem, we prove an interesting result which states that
a random variable X is integrable if and only if P
n≥1 P[|X| ≥ n] < ∞. In
Theorem 4.3.5, it is proved that for a discrete random variable X with support
as the set W of whole numbers E(X) = P
n≥1 P[X ≥ n]. We use Theorem
4.3.5 in the proof of the theorem. We also need the following lemma in the
proof. The proof is based on the Corollary 8.2.4.
Lemma 8.2.2. Suppose (Ω, A, P) is a probability space and {An, n ≥ 1} is a
measurable partition of Ω, then for A measurable random variable X
E(X) = Z
Ω
X dP =
X
n≥1
Z
An
X dP.392 Convergence of a Sequence of Expectations
Proof. Case (i): Suppose X ≥ 0. By the definition of expectation,
E(X) = Z
Ω
X dP =
Z
Ω
X (I P
n≥1
An
)dP =
Z
Ω
X
n≥1
XIAn dP = E
X
n≥1
XIAn

=
X
n≥1
E(XIAn
) by Corollary 8.2.4
=
X
n≥1
Z
Ω
XIAn dP =
X
n≥1
Z
An
XdP.
(ii) Suppose X ≤ 0 ⇒ Y = −X ≥ 0. Hence by case(i)
E(Y ) = X
n≥1
Z
An
Y dP ⇐⇒ E(−X) = X
n≥1
Z
An
(−X)dP
⇐⇒ E(X) = X
n≥1
Z
An
XdP.
Theorem 8.2.3. For any random variable X defined on (Ω, A, P)
X
n≥1
P[|X| ≥ n] ≤ E(|X|) ≤ 1 + X
n≥1
P[|X| ≥ n]
and X is integrable random variable if and only if P
n≥1 P[|X| ≥ n] < ∞.
Proof. Since X is A measurable, |X| is also A measurable random variable.
Suppose an event An is defined as An = [n ≤ |X| < n + 1] = |X|
−1
(Sn) ∈ A,
where Sn = [n, n + 1), n ≥ 0. For n ≥ 0, Sn = [n, n + 1) are disjoint sets and
hence by Result (v) of Lemma 2.2.1, it follows that An = |X|
−1
(Sn), n ≥ 0
are disjoint events. Further by Result (iii) of Lemma 2.2.1,
[
n≥0
Sn = R
+ ⇒ |X|
−1
 [
n≥0
Sn

= |X|
−1
(R
+
) ⇒
[
n≥0
|X|
−1
(Sn) = |X|
−1
(R
+
)
⇒
[
n≥0
An =
X
n≥0
An = Ω.
Thus, {An, n ≥ 0} is a measurable partition of Ω. Hence, by Lemma 8.2.2,
E(|X|) = P
n≥0
R
An
|X| dP. Observe that on An
n ≤ |X| < n + 1
⇒
Z
An
n dP ≤
Z
An
|X| dP < Z
An
(n + 1) dP
⇒ nP(An) ≤
Z
An
|X| dP < (n + 1)P(An).Monotone Convergence Theorem 393
Hence,
X
n≥0
nP(An) ≤
X
n≥0
Z
An
|X| dP < X
n≥0
(n + 1)P(An)
⇒
X
n≥0
nP(An) ≤ E(|X|) <
X
n≥0
P(An) + X
n≥0
nP(An)
⇒
X
n≥1
nP(An) ≤ E(|X|) < PX
n≥0
An

+
X
n≥1
nP(An)
⇒
X
n≥1
nP(An) ≤ E(|X|) < 1 + X
n≥1
nP(An). (8.6)
To prove the theorem, we need to prove that
P
n≥1
nP(An) = P
n≥1 P[|X| ≥ n]. To prove it, suppose an elementary ran￾dom variable Y is defined as Y =
P
n≥0
nIAn =
P
n≥1
nIAn
. Then by Corol￾lary 8.2.4
E(Y ) = E
X
n≥1
nIAn

=
X
n≥1
E(nIAn
)
=
X
n≥1
nP(An) = X
n≥1
nP[Y = n] = X
n≥1
P[Y ≥ n],
by Theorem 4.3.5, since Y is a discrete random variable with support as the
set W of whole numbers. Now, Y ≥ n if ω ∈ Ak for any one k ≥ n. Hence,
P[Y ≥ n] = P
X∞
k=n
Ak

= P
X∞
k=n
[k ≤ |X| < k + 1]
= P[|X| ≥ n]
⇒ E(Y ) = X
n≥1
nP(An) = X
n≥1
P[Y ≥ n] = X
n≥1
P[|X| ≥ n]. (8.7)
Now using Equation (8.7) in Equation (8.6), we get
X
n≥1
nP(An) ≤ E(|X|) < 1 + X
n≥1
nP(An)
⇐⇒ X
n≥1
P[|X| ≥ n] ≤ E(|X|) ≤ 1 + X
n≥1
P[|X| ≥ n].
P
From the above inequality it follows that X is integrable if and only if
n≥1 P[|X| ≥ n] < ∞.
We use this result in the next chapter in Khintchine’s weak laws of large
numbers and Kolmogorov’s strong laws of large numbers.
Following lemma, known as Fatou’s lemma, is based on the monotone con￾vergence theorem and is heavily used in the proof of the Lebesgue dominated
almost sure convergence theorem. It is also known as Fatou-Lebesgue theorem,
(Loeve [16]).394 Convergence of a Sequence of Expectations
Lemma 8.2.3. Fatou’s lemma: Suppose {Xn, n ≥ 1} is a sequence of random
variables defined on a probability space (Ω, A, P). If Y and Z are integrable
random variables, then
(i) Y ≤ Xn ⇒ E(lim inf Xn) ≤ lim inf E(Xn).
(ii) Z ≥ Xn ⇒ E(lim sup Xn) ≥ lim sup E(Xn).
(iii) Y ≤ Xn ≤ Z & Xn
a.s. → X ⇒ limn→∞ E(Xn) = E(X).
Proof.
(i) Note that on Ω
Y ≤ Xn ⇒ the sequence {Xn, n ≥ 1} is bounded from below
⇒ lim inf Xn < ∞
Similarly Y ≤ Xn ⇒ E(Y ) ≤ E(Xn) ⇒ lim inf E(Xn) < ∞.
Suppose Yn = infk≥n Xk, then {Yn, n ≥ 1} is a non-decreasing sequence
of random variables and
limn→∞
Yn = limn→∞
( inf
k≥n
Xk) = sup
n≥1
( inf
k≥n
Xk) = lim inf Xn.
Case (a): Suppose Yn ≥ 0. Then by the monotone convergence theorem,
0 ≤ Yn ↑ lim inf Xn ⇒ E(Yn) ↑ E(lim inf Xn).
Observe that,
Xn ≥ Yn ⇒ E(Xn) ≥ E(Yn)
⇒ lim inf E(Xn) ≥ lim inf E(Yn)= limn→∞
E(Yn) = E(lim inf Xn)
⇒ E(lim inf Xn) ≤ lim inf E(Xn).
Case(b): Suppose Yn’s are arbitrary. If Zn = Xn − Y , then Zn ≥ 0.
Suppose Un = infk≥n Zk, then {Un, n ≥ 1} is a non-decreasing sequence
of non-negative random variables. Hence,
limn→∞
Un = limn→∞
( inf
k≥n
Zk) = sup
n≥1
( inf
k≥n
Zk) = lim inf Zn.
By the monotone convergence theorem,
0 ≤ Un ↑ lim inf Zn ⇒ E(Un) ↑ E(lim inf Zn).
Observe that,
Zn ≥ Un ⇒ E(Zn) ≥ E(Un)
⇒ lim inf E(Zn) ≥ lim inf E(Un) = limn→∞
E(Un) = E(lim inf Zn)
⇒ E(lim inf Zn) ≤ lim inf E(Zn)
⇐⇒ E(lim inf(Xn − Y )) ≤ lim inf E(Xn − Y )
⇐⇒ E(lim inf Xn) ≤ lim inf E(Xn) since E(Y ) < ∞.Monotone Convergence Theorem 395
(ii) It is given that on Ω,
Xn ≤ Z ⇒ the sequence {Xn, n ≥ 1} is bounded from above
⇒ lim sup Xn < ∞.
Further, Xn ≤ Z ⇒ E(Xn) ≤ E(Z) ⇒ lim sup E(Xn) < ∞.
Now Xn ≤ Z ⇒ Vn = Z − Xn ≥ 0, hence by part (i) we get,
E(lim inf Vn) ≤ lim inf E(Vn)
⇐⇒ E(lim inf(Z − Xn)) ≤ lim inf E(Z − Xn)
⇐⇒ E(Z) − E(lim sup Xn) ≤ E(Z) − lim sup E(Xn)
⇐⇒ E(lim sup Xn) ≥ lim sup E(Xn) as E(Z) < ∞.
(iii) Note that
Xn
a.s. → X ⇒ lim inf Xn = lim sup Xn = X a.s.
⇒ E(lim inf Xn) = E(lim sup Xn) = E(X).
It is given that, Y ≤ Xn ≤ Z hence, E(Y ) ≤ E(Xn) ≤ E(Z). Thus,
lim inf E(Xn) and lim sup E(Xn) both are finite. Using part (i) and part
(ii) we get,
E(lim inf Xn) ≤ lim inf E(Xn) ≤ lim sup E(Xn) ≤ E(lim sup Xn)
⇐⇒ E(X) ≤ lim inf E(Xn) ≤ lim sup E(Xn) ≤ E(X)
⇒ lim inf E(Xn) = lim sup E(Xn) = E(X)
⇒ limn→∞
E(Xn) = E(X).
Following theorem is an immediate consequence of Fatou’s Lemma. As
mentioned in Section 1, we label it as the Lebesgue dominated almost sure
convergence theorem.
Theorem 8.2.4. Lebesgue dominated almost sure convergence theorem: Sup￾pose {Xn, n ≥ 1} is a sequence of random variables defined on a probability
space (Ω, A, P). If Y is an integrable random variable such that |Xn| ≤ Y a.s.
and if Xn
a.s. → X, then limn→∞ E(Xn) = E(X).
Proof. Note that |Xn| ≤ Y a.s. ⇒ − Y ≤ Xn ≤ Y a.s. where Y is an
integrable random variable. Further, Xn
a.s. → X and hence by (iii) of Fatou’s
lemma, we conclude that limn→∞ E(Xn) = E(X).
In particular if Y is degenerate at constant C, that is, if the random
variables Xn’s are uniformly bounded, the Lebesgue dominated almost sure
convergence theorem is called as the Lebesgue bounded convergence theorem,
refer to Billingsley [5].396 Convergence of a Sequence of Expectations
Example 8.2.2. Suppose {An, n ≥ 1} is a sequence of events in A and
suppose Xn = IAn
. Then |IAn
| ≤ Y ≡ 1. By Fatou’s Lemma and Lemma
2.3.2,
E(lim inf Xn) ≤ lim inf E(Xn) ⇒ E(lim inf IAn
) ≤ lim inf E(IAn
)
⇒ E(Ilim inf An
) ≤ lim inf E(IAn
) ⇒ P(lim inf An) ≤ lim inf P(An) .
Similarly,
lim sup E(Xn) ≤ E(lim sup Xn) ⇒ lim sup E(IAn
) ≤ E(lim sup IAn
)
⇒ lim sup E(IAn
) ≤ E(Ilim sup An
) ⇒ lim sup P(An) ≤ P(lim sup An) .
Combining two results we have
P(lim inf An) ≤ lim inf P(An) ≤ lim sup P(An) ≤ P(lim sup An) .
The same result is proved in Section 1.5. Further, it is proved in Theorem
2.3.9 that An → A ⇒ IAn → IA pointwise and hence almost surely. Moreover,
|IAn
| ≤ Y ≡ 1. Hence by Theorem 8.2.4 we get,
limn→∞
E(IAn
) = limn→∞
P(An) = E(IA) = P(A),
which is the continuity theorem for a probability measure. In particular, if
An → ∅ ⇒ P(An) → 0.
We have defined convergence in quadratic mean and Cauchy convergence
in quadratic mean in Section 7.4. We now prove their equivalence using Fatou’s
lemma. This result is known as L2 completeness theorem.
Theorem 8.2.5. L2 completeness theorem: Suppose a sequence {Xn, n ≥ 1}
of random variables and X are defined on the same probability space (Ω, A, P)
and X, Xn ∈ L2 for all n ≥ 1. Then Xn
q.m. → X as n → ∞ if and only if
Xn − Xm
q.m. → 0 as m, n → ∞.
Proof. Suppose Xn
q.m. → X. Then by Cr inequality, with r = 2
E(|Xn − Xm|
2
) ≤ 2[E(|Xn − X|
2
) + E(|Xm − X|
2
)] → 0 as m, n → ∞
⇒ Xn − Xm
q.m. → 0.
Conversely, suppose Xn − Xm
q.m. → 0. Now as m, n → ∞,
Xn − Xm
q.m. → 0 ⇒ Xn − Xm
P
→ 0 ⇒ Xn
P
→ X for some X
since convergence in quadratic mean implies convergence in probability and
Cauchy convergence in probability implies convergence in probability, as
proved in Section 7.2. Further, by Theorem 7.2.11, there exists a subsequence
{Xnk
, k ≥ 1} of {Xn, n ≥ 1} such that Xnk
a.s. → X as k → ∞. Hence for fixedMonotone Convergence Theorem 397
m, Xm − Xnk
a.s. → Xm − X as k → ∞ and (Xm − Xnk
)
2 a.s. → (Xm − X)
2 as
k → ∞. Thus,
E((Xm − X)
2
) = E( lim
k→∞
(Xm − Xnk
)
2
) = E(lim inf
k→∞
(Xm − Xnk
)
2
). (8.8)
Now 0 ≤ (Xm − Xnk
)
2
. As a consequence, by the first part of Fatou’s lemma,
E(lim inf
k→∞
(Xm − Xnk
)
2
) ≤ lim inf
k→∞
E(Xm − Xnk
)
2 = lim
k→∞
E(Xm − Xnk
)
2 = 0,
(8.9)
since Xm − Xnk
q.m. → 0 as m, k → ∞. Using result in (8.9) in Equation (8.8),
we get
E(|Xm − X|
2
) → 0 as m → ∞ ⇒ Xm
q.m. → X.
In Example 7.4.10, it is shown that almost sure convergence does not imply
convergence of moments. However, using Fatou’s lemma we can find a certain
relation between E(|Xn|
r
) and E(|X|
r
) when Xn
a.s. → X, as shown in the
following theorem.
Theorem 8.2.6. If Xn
a.s. → X then ∀ r > 0, (i) E(|X|
r
) ≤
lim infn→∞ E(|Xn|
r
) and (ii) E(|X|
r
) ≤ lim supn→∞ E(|Xn|
r
).
Proof. Xn
a.s. → X ⇒ |Xn|
r
(ω)
a.s. → |X|
r
(ω) ∀ ω ∈ Nc where P(N) = 0.
(i) By Fatou’s lemma,
0 ≤ |Xn|
r ⇒
Z
Ω
lim inf
n→∞
|Xn|
r
dP ≤ lim inf
n→∞ Z
Ω
|Xn|
r
dP
⇒ E(|X|
r
) = Z
Ω
|X|
r
dP =
Z
Nc
limn→∞
|Xn|
r
dP =
Z
Nc
lim inf
n→∞
|Xn|
r
dP
≤ lim inf
n→∞ Z
Nc
|Xn|
r
dP = lim inf
n→∞ Z
Ω
|Xn|
r
dP = lim inf
n→∞
E(|Xn|
r
),
the last step follows since P(N) = 0.
(ii) It follows immediately from (i), since
E(|X|
r
) ≤ lim inf
n→∞
E(|Xn|
r
) ≤ lim sup
n→∞
E(|Xn|
r
).
In the next section, we prove a theorem, labeled as the Lebesgue domi￾nated probability convergence theorem. In this theorem we prove the result
of the Lebesgue dominated almost sure convergence theorem, under a weaker
condition, when the almost sure convergence is replaced by the convergence
in probability.398 Convergence of a Sequence of Expectations
8.3 Lebesgue Dominated Probability Convergence
Theorem
In Theorem 7.2.3, it is proved that if Xn
P
→ C and if Xn’s are uniformly
bounded, that is |Xn| < M, ∀ n ≥ 1, then limn→∞ E(Xn) = E(limn→∞ Xn).
In the Lebesgue dominated probability convergence theorem, M is replaced
by an integrable random variable Y and limit random variable in convergence
in probability is a non-degenerate random variable.
In the proof, we heavily use the result that every subsequence of a conver￾gent sequence of real numbers is convergent and has the same limit. We need
one more result proved in Theorem 7.2.11, which states that if Xn
P
→ X, then
there exists a subsequence of {Xn, n ≥ 1} which converges to X almost surely.
We also use the Lebesgue dominated almost sure convergence theorem. Since
the almost sure convergence is replaced by a weaker condition, the proof is
rather involved as compared to that of the Lebesgue dominated almost sure
convergence theorem.
Theorem 8.3.1. Lebesgue dominated probability convergence theorem: Sup￾pose {Xn, n ≥ 1} is a sequence of random variables defined on (Ω, A, P). If
Y is an integrable random variables such that |Xn| ≤ Y a.s. and if Xn
P
→ X,
then limn→∞ E(Xn) = E(X).
Proof. It is given that |Xn| ≤ Y a.s. ⇒ E(|Xn|) ≤ E(Y ), that is, −E(Y ) ≤
E(Xn) ≤ E(Y ). Thus the sequence {E(Xn), n ≥ 1} is bounded from above
and below and hence lim inf E(Xn) and lim sup E(Xn) both are finite. We
want to show that both are the same and the common value is E(X).
Case (i) Suppose X ≡ 0. By definition of convergence in probability,
Xn
P
→ X ≡ 0 ⇐⇒ ∀ ϵ > 0, pϵn = P[|Xn| > ϵ] → 0 as n → ∞.
Thus, {pϵn, n ≥ 1} is a sequence of real numbers in [0, 1] converging to 0, hence
every subsequence {pϵnk
, k ≥ 1} of {pϵn, n ≥ 1} is convergent and has the same
limit 0 for all ϵ > 0. Thus, Xn
P
→ 0 as n → ∞ implies Xnk
P
→ 0 as k → ∞
for any subsequence. Suppose we divide all subsequences of {Xn, n ≥ 1} in
two classes C1 and C2. C1 consists of all subsequences {Xn′ , n′ ≥ 1} such
that E(Xn′ ) → lim inf E(Xn) and C2 consists of all subsequences {Xn′′ , n′′ ≥
1} such that E(Xn′′ ) → lim sup E(Xn). It is to be noted that, for every
subsequence from C1, the sequence {E(Xn′ ), n′ ≥ 1} is a convergent sequence
and its every subsequence has the same limit as lim inf E(Xn). To identify the
value of the limit, consider a subsequence {Xn′
k
, n′
k ≥ 1} of {Xn′ , n′ ≥ 1},
such that Xn′
P
→ 0 and Xn′
k
a.s. → 0, which exists in view of Theorem 7.2.11.Lebesgue Dominated Probability Convergence Theorem 399
Now, |Xn| ≤ Y a.s. ⇒ |Xn′
k
| ≤ Y a.s.
⇒ limn→∞
E(Xn′
k
) = 0 by Theorem 8.2.4
⇒ limn→∞
E(Xn′ ) = lim inf E(Xn) = 0,
as a subsequence {E(Xn′
k
), n′
k ≥ 1} of {E(Xn′ ), n′ ≥ 1} has limit 0 and it
implies that lim inf E(Xn) = 0. Using similar arguments, it can be shown that
lim sup E(Xn) = 0. Hence, limn→∞ E(Xn) exists and is 0. Since X ≡ 0,
E(X) = 0. Thus, limn→∞ E(Xn) = E(X).
Case (ii) Suppose X ̸= 0. If Zn = (Xn−X) then Xn
P
→ X ⇒ Zn = (Xn−X)
P
→
0. If Zn is bounded by an integrable random variable, then by case (i) we get
the required result. To prove it, observe that,
|Xn| ≤ Y a.s. ⇒ |Xn(ω)| ≤ Y (ω) ∀ ω ∈ N
c
1 & P(N1) = 0
⇒ Zn(ω) = |Xn(ω) − X(ω)| ≤ |Xn(ω)| + |X(ω)|
≤ Y (ω) + |X(ω)| ∀ ω ∈ N
c
1
.
To examine whether X is bounded by an integrable random variable, we again
use Theorem 7.2.11. Thus,
Xn
P
→ X ⇒ ∃ a subsequence {Xnk
, k ≥ 1} such that Xnk
a.s. → X
⇒ |X(ω)| = lim nk→∞
|Xnk
(ω)| ∀ ω ∈ N
c
2 & P(N2) = 0
⇒ |X(ω)| = lim nk→∞
|Xnk
(ω)| ≤ Y (ω) ∀ ω ∈ N
c = N
c
1 ∩ N
c
2
⇒ |Zn(ω)| = |Xn(ω) − X(ω)| ≤ Y (ω) + Y (ω) = 2Y (ω) ∀ ω ∈ N
c
.
Note that P(N) = 0. Consequently, {Zn, n ≥ 1} is a sequence of random
variables such that |Zn| ≤ 2Y a.s. where 2Y is an integrable random variable.
Further, Zn
P
→ 0. Hence by case (i),
limn→∞
E(Zn) = 0 ⇒ limn→∞
E(Xn) = E(X).
It is to be noted that in both the dominated convergence theorems, Xn is
dominated by an integrable random variable Y and hence the theorems are
labeled as the dominated convergence theorems.
Remark 8.3.1. In the proof of the Lebesgue dominated probability conver￾gence theorem, we have considered subsequences at two levels and used the
result about almost sure convergence at the second level. It is necessary to
proceed on these lines in view of the following problems. We are given that
Xn
P
→ 0, hence by Theorem 7.2.11, there exists a subsequence {Xn′ , n′ ≥ 1}
such that Xn′
a.s. → 0. By Fatou’s lemma, then E(Xn′ ) → 0. However, from this
we cannot conclude that sequence of expectations of every subsequence con￾verges to 0. This is the reason we have to consider two levels of subsequences.400 Convergence of a Sequence of Expectations
Corollary 8.3.1. Suppose X is a random variable on (Ω, A, P) such that
E(|X|) < ∞. If {An, n ≥ 1} is a sequence of sets in A such that An ↓ ∅, then
R
An
X dP → 0. If An ↑ Ω, then R
An
X dP → E(X).
Proof. It is proved in Corollary 7.2.9 that if X is a random variable defined
on (Ω, A, P) and {An, n ≥ 1} is a sequence of sets in A, then An ↓ ∅ implies
XIAn
P
→ 0 and An ↑ Ω implies that XIAn
P
→ X. Further, |XIAn
| ≤ |X| and it
is given that |X| is integrable. Hence by the Lebesgue dominated probability
convergence theorem,
An ↓ ∅ ⇒ Z
An
X dP =
Z
Ω
IAn X dP = E(XIAn
) → 0
& An ↑ Ω ⇒
Z
An
X dP =
Z
Ω
IAn X dP = E(XIAn
) → E(X) .
Dominated convergence theorems are heavily used in all branches of statis￾tics, to justify interchange of summation and integration or derivatives and in￾tegration or limits and integration. In Section 4.4, in the proof of the inversion
theorem for a characteristic function, we have used the dominated convergence
theorem to interchange limit and integration. We use the Lebesgue dominated
probability convergence theorem in Chapter 9 in the proof of Khintchine’s
weak law of large numbers and Kolmogorov’s strong law of large numbers,
and also in Lindeberg-Levy central limit theorem in Chapter 10 .
In the next example, we verify the Lebesgue dominated probability con￾vergence theorem and Theorem 7.2.3 by simulation.
Example 8.3.1. Suppose X ∼ N(θ, 1) distribution and θ ∈ Θ = [a, b]. The
maximum likelihood estimator ˆθn of θ, based on a random sample of size n
from the distribution of X, is given by,
ˆθn =



a, if Xn < a
Xn, if Xn ∈ [a, b]
b, if Xn > b.
In Example 7.3.15, we have shown that ˆθn
P
→ θ. Now ˆθn ∈ [a, b], with a < b,
we have |
ˆθn| ≤ max{|a|, |b|}. Hence, by the Lebesgue dominated probability
convergence theorem and Theorem 7.2.3 E(
ˆθn) → θ. Further, by Theorem
7.2.3, E(
ˆθn − θ)
2 → 0. We verify these results using the following code.
Code 8.3.1. We take a = 2, b = 4 and generate a random sample of size n
from normal N(θ, 1) with θ = 2.5 and n = 100 to n = 2500 with increment of
300. On the basis of sample we find ˆθn. On the basis of 400 simulated values of
ˆθn we compute rfn, an estimate of P[|
ˆθn − θ| < ϵ], mn, an estimate of E(
ˆθn)
and vn, an estimate of E(
ˆθn − θ)
2
. We examine whether, rfn → 1, mn → θ =
2.5 and vn → 0 as n increases.Lebesgue Dominated Probability Convergence Theorem 401
N=seq(100,2500,300); nsim=400; th=2.5; a=2; b=4
me=mle=u=v=p=c(); ep=0.05
for(j in 1:length(N))
{
for(m in 1:nsim)
{
set.seed(m)
x=rnorm(N[j],th,1)
if(mean(x)>b)
{
mle[m]=b
if(mean(x)<a)
mle[m]=a
}
else
{
mle[m]=mean(x)
}
}
p[j]=length(which(abs(mle-th)<ep))/nsim
u[j]=mean(mle)
v[j]=mean((mle-th)^2)
}
d=round(data.frame(N,p,u,v),4); d
The output is organized in Table 8.1.
TABLE 8.1
Verification of LDCT for N(θ, 1)
Distribution, θ ∈ [a, b]
n rn mn vn
100 0.3775 2.5034 0.0094
400 0.6975 2.5017 0.0023
700 0.8125 2.5017 0.0014
1000 0.8825 2.5004 0.0011
1300 0.8975 2.5010 0.0008
1600 0.9525 2.5006 0.0007
1900 0.9825 2.5008 0.0005
2200 0.9850 2.5011 0.0004
2500 0.9950 2.5010 0.0004
From the table we note that rfn → 1, mn → θ = 2.5 and vn → 0 as n
increases. Thus, we have verified by simulation that if ˆθn
P
→ θ, E(
ˆθn) → θ,402 Convergence of a Sequence of Expectations
as proved in the Lebesgue dominated probability convergence theorem and
E(
ˆθn − θ)
2 → 0, as proved in Theorem 7.2.3. Using similar code, it can be
verified that the results remain true for any θ ∈ [a, b], even at boundary points
a and b. □
Following is a quick recap of the results discussed in this chapter.
Summary
1. Suppose {Xn, n ≥ 1} is a non-decreasing sequence of non-negative random
variables defined on a probability space (Ω, A, P). If Xn ↑ X on Ω, then
E(Xn) ↑ E(X). If Y ≤ Xn ↑ X on Ω and Y is an integrable random
variable, then E(Y ) ≤ E(Xn) ↑ E(X).
2. Suppose 0 ≥ Xn ↓ X on Ω, then E(Xn) ↓ E(X). If Y ≥ Xn ↓ X on Ω and
Y is an integrable random variable, then E(Xn) ↓ E(X).
3. Suppose {Xn, n ≥ 1} is a non-decreasing sequence bounded from below
by an integrable random variable or a non-increasing sequence bounded
from above an integrable random variable. If Xn → X on Ω, then
limn→∞ E(Xn) = E(limn→∞ Xn).
4. Suppose {Xn, n ≥ 1} is a sequence of random variables then
E(
P
n≥1 Xn) = P
n≥1 E(Xn).
5. Fatou’s lemma: Suppose {Xn, n ≥ 1} is a sequence of random variables
defined on a probability space (Ω, A, P).
(i) If Y is an integrable random variable such that Y ≤ Xn, then
E(lim inf Xn) ≤ lim inf E(Xn).
(ii) If Z is an integrable random variable such that Xn ≤ Z, then
lim sup E(Xn) ≤ E(lim sup Xn).
(iii) If Y and Z are integrable random variables such that Y ≤ Xn ≤ Z,
and if Xn
a.s. → X, then limn→∞ E(Xn) = E(X).
6. Lebesgue dominated almost sure convergence theorem: Suppose
{Xn, n ≥ 1} is a sequence of random variables defined on a probability
space (Ω, A, P). If Y is an integrable random variables such that |Xn| ≤ Y
and if Xn
a.s. → X, then limn→∞ E(Xn) = E(X).
7. Lebesgue dominated probability convergence theorem: Suppose
{Xn, n ≥ 1} is a sequence of random variables defined on a probability
space (Ω, A, P). If Y is an integrable random variables such that |Xn| ≤ Y
a.s. and if Xn
P
→ X, then limn→∞ E(Xn) = E(X).
8. Suppose X is a random variable on (Ω, A, P) such that E(|X|) < ∞. If
{An, n ≥ 1} is a sequence of sets in A such that An ↓ ∅, then R
An
X dP →
0. If An ↑ Ω, then R
An
X dP → E(X).Conceptual Exercises 403
8.4 Conceptual Exercises
8.4.1 Suppose a sequence {(Xn, Y ), n ≥ 1} of random variables is such that
the conditional distribution of Xn given Y is uniform U(Y − 1/n, Y +
1/n),
n ≥ 1 and the marginal distribution of Y is exponential with location
parameter 1 and scale parameter 1. Examine whether the sequence
{Xn, n ≥ 1} converges in quadratic mean, probability, law and almost
surely to Y. Examine whether a sequence {E(Xn), n ≥ 1} converges to
E(Y ). Check whether the conditions of the Lebesgue dominated proba￾bility convergence theorem are satisfied.
8.4.2 Suppose {Xn, n ≥ 1} is a sequence of random variables such that Xn
follows exponential distribution with mean θ
n, 0 < θ < 1. Show that
E(
P
n≥1 Xn) = θ/(1 − θ). State the results that you may use.
8.4.3 Suppose {Xn, n ≥ 1} is a sequence of identically distributed random
variables such that E(|X1|) < ∞. Suppose Yn = (1/n) max1≤i≤n |Xi
|.
Show that limn→∞ E(Yn) = 0.
8.4.4 Show that
P
X is an integrable random variable if and only if
n≥1 P[|X| ≥ cn] < ∞, for some c > 0. In particular, deduce that if
the above series converges for some c > 0 then it converges for all c > 0.
8.4.5 Suppose X is a non-negative random variable. Show that
(i) limn→∞ nE(I[X>n]/X) = 0 and (ii) limn→∞(1/n)E(I[X>1/n]/X) =
0.
8.4.6 Suppose {Xn, n ≥ 1} is a sequence of random variables defined on
(Ω, A, P) and Y is an integrable random variables such that |Xn| ≤ Y
a.s. Prove that if Xn
L
→ 0, then limn→∞ E(Xn) = 0.
8.5 Computational Exercises
8.5.1 Suppose X ∼ N(θ, 1) distribution and θ ∈ Θ = {0, 1}. Verify the
Lebesgue dominated probability convergence theorem and Theorem
7.2.3 by simulation.
8.6 Multiple Choice Questions
Note: In each question, multiple options may be correct. Unless specified
otherwise, identify which of the statement(s) is/are correct. Answers are given
in Chapter 11, after the solutions of conceptual exercises of Chapter 8.404 Convergence of a Sequence of Expectations
8.6.1 E(Xn) → E(X) if
(a) {Xn, n ≥ 1} is a non-decreasing sequence of non-negative random
variables converging to X on Ω
(b) {Xn, n ≥ 1} is a non-increasing sequence of negative random vari￾ables converging to X on Ω
(c) {Xn, n ≥ 1} is a non-decreasing sequence of random variables con￾verging to X almost surely and the sequence is bounded below by
an integrable random variable
(d) {Xn, n ≥ 1} is a non-increasing sequence of random variables con￾verging to X almost surely and the sequence is bounded above by
an integrable random variable
8.6.2 E(Xn) → E(X) always if
(a) {Xn, n ≥ 1} is a non-decreasing sequence of non-negative random
variables converging to X on Ω
(b) {Xn, n ≥ 1} is a non-increasing sequence of negative random vari￾ables converging to X almost surely
(c) {Xn, n ≥ 1} is a non-decreasing sequence of random variables con￾verging to X almost surely and the sequence is bounded below by
an integrable random variable
(d) {Xn, n ≥ 1} is a non-increasing sequence of random variables con￾verging to X almost surely and the sequence is bounded above by
an integrable random variable
8.6.3 If Y is an integrable random variable such that Y ≤ Xn, then
(a) E(lim inf Xn) ≥ lim inf E(Xn)
(b) E(lim sup Xn) ≤ lim sup E(Xn)
(c) E(lim inf Xn) ≤ lim sup E(Xn)
(d) E(lim sup Xn) ≤ lim inf E(Xn)
8.6.4 If Z is an integrable random variable such that Xn ≤ Z, then
(a) lim sup E(Xn) ≥ E(lim sup Xn)
(b) lim inf E(Xn) ≤ E(lim sup Xn)
(c) lim sup E(Xn) ≤ E(lim sup Xn)
(d) lim sup E(Xn) ≥ E(lim inf Xn)
8.6.5 If Y is an integrable random variables such that |Xn| ≤ Y , then
limn→∞ E(Xn) = E(X) always, if
(a) Xn
a.s. → X
(b) Xn
P
→ X
(c) Xn
q.m. → X
(d) Xn
L
→ XMultiple Choice Questions 405
8.6.6 If Y is an integrable random variables such that |Xn| ≤ Y , then
limn→∞ E(Xn) = E(X) always, if (I) Xn
a.s. → X. (II) Xn
P
→ X.
(III) Xn
q.m. → X. (IV) Xn
L
→ X. Which of the following is a correct
option?
(a) Only (I) is true
(b) Only (II) is true
(c) Both (II) and (IV) are true
(d) (I), (II) and (III) are true
8.6.7 If Y is an integrable random variables such that |Xn| ≤ Y , then
limn→∞ E(Xn) = 0, if
(a) Xn
a.s. → 0
(b) Xn
P
→ 0
(c) Xn
q.m. → 0
(d) Xn
L
→ 09
Laws of Large Numbers
9.1 Introduction
In probability theory we study limit theorems of two types: (i) strong limit
theorems which deal with the almost sure convergence of a sequence of ran￾dom variables and (ii) weak limit theorems which deal with convergence in
probability of a sequence of random variables as well as convergence of a se￾quence of distribution functions. We have discussed in detail these modes of
convergence in Chapters 6 and 7. In the present chapter, we study almost sure
convergence and convergence in probability of a sequence {Sn, n ≥ 1} derived
from a sequence {Xn, n ≥ 1} by defining Sn =
Pn
i=1 Xi
. Sn is known as
n-th partial sum. The laws of large numbers are concerned with the limiting
behaviour of {Sn, n ≥ 1}. These state conditions under which the sequence
{Sn, n ≥ 1} of partial sums converges almost surely, in probability and in
distribution, with suitable norming. The weak law of large numbers (WLLN)
refers to convergence in probability, whereas the strong law of large numbers
(SLLN) refers to the almost sure convergence. Central limit theorem (CLT) is
concerned with the convergence in distribution of the appropriately normed
sequence {Sn, n ≥ 1}. We define these below.
Definition 9.1.1. Suppose {Xn, n ≥ 1} is a sequence of random variables
and Sn =
Pn
i=1 Xi. Suppose there exists two sequences {an, n ≥ 1} of real
numbers and {bn, n ≥ 1} of positive real numbers such that bn → ∞. A
sequence {Xn, n ≥ 1} of random variables is said to obey a
(i) SLLN, if (Sn − an)/bn
a.s. → 0 as n → ∞.
(ii) WLLN, if (Sn − an)/bn
P
→ 0 as n → ∞.
(iii) CLT, if (Sn − an)/bn
L
→ Z as n → ∞ where Z ∼ N(0, 1).
In the next section, in some examples, we note that we can have more
than one sequences {an, n ≥ 1} and {bn, n ≥ 1} for which the WLLN holds.
In Chapter 10, we note that in many cases for b
2
n = V ar(Sn), CLT is valid.
When a sequence {Xn, n ≥ 1} satisfies WLLN, it is said to be stable in
probability, when it satisfies SLLN, it is said to be almost surely stable and
when it satisfies CLT, it is said to be stable in law.
DOI: 10.1201/9781032619057-9 406Weak Law of Large Numbers 407
Laws of large numbers have important applications in establishing asymp￾totic properties, such as consistency and asymptotic normality of estimators.
From WLLN one can conclude that the mean of the large sample of observa￾tions is close to the population mean with very high chance. Depending on
the conditions, there are various versions of laws of large numbers and CLT.
In the next two sections, we discuss WLLN and SLLN. Various types of CLT
are studied in the next chapter.
9.2 Weak Law of Large Numbers
WLLN is considered as a great achievement in probability in view of its num￾ber of applications. As defined in Section 1, it deals with convergence in prob￾ability of the sequence {Sn, n ≥ 1} of partial sums. We begin with some
examples.
Example 9.2.1. Suppose {Xn, n ≥ 1} is a sequence of independent random
variables with P[Xn = 2n] = P[Xn = −2
n] = 1/2. It is clear that
E(Xn) = 0 & V ar(Xn) = 4n ⇒ V ar(Sn) =Xn
i=1
V ar(Xi) =Xn
i=1
4
i =
4(4n − 1)
3
.
We now examine whether {Xn, n ≥ 1} follows WLLN. E(Xn) = 0 suggests
an = 0. To find bn > 0 and tending to ∞, observe that
V ar(Sn/bn) = 4(4n−1)/3b
2
n = 4((2n
)
2−1)/3b
2
n → 0 if bn = (2+δ)
n
, δ > 0.
Thus by Chebyshev’s inequality, for any ϵ > 0
P [|(Sn − E(Sn))/bn| > ϵ] ≤ (1/ϵ2
)V ar(Sn/bn) → 0, with bn = (2+δ)
n
.
Thus, {Xn, n ≥ 1} follows WLLN with an = 0 and bn = (2 +δ)
n, δ > 0. Note
that corresponding to different values of δ, we have an uncountable family of
sequences {bn, n ≥ 1} with which WLLN holds. Now we investigate whether
we have some more sequences {an, n ≥ 1}, apart from an ≡ 0 which satisfy
WLLN. Note that E(Sn) = 0 and hence E(S
2
n
) = V ar(Sn). Observe that by
Chebyshev’s inequality,
P [|(Sn − an)/bn| > ϵ] ≤ (1/ϵ2
)E((Sn − an)/bn)
2
= (1/ϵ2
b
2
n
)(E(S
2
n
) − 2anE(Sn) + a
2
n
)
= (1/ϵ2
b
2
n
)(4(4n − 1)/3 + a
2
n
) → 0 if a
2
n/b2
n → 0.
For a
2
n/b2
n → 0, we may select a
2
n = n or n
2 or 2
n, in general any sequence
{an, n ≥ 1}, in which a
2
n → ∞ at a slower rate than b
2
n
tending to infinity. □408 Laws of Large Numbers
Remark 9.2.1. Example 9.2.1 coveys that, in general we have more than one
sequences {an, n ≥ 1} and {bn, n ≥ 1} with which the WLLN holds.
Example 9.2.2. Suppose {Xn, n ≥ 1} is a sequence of independent random
variables with
P[Xn = 2n
] = P[Xn = −2
n
] = 2−(2n+1) & P[Xn = 0] = 1 − 2
−2n
.
Note that E(Xn) = 0, V ar(Xn) = 1 and hence V ar(Sn/bn) = n/b2
n
. This
expression of V ar(Sn/bn) suggests that if we select b
2
n = n
1+δ
, δ > 0, then
bn > 0, bn → ∞ and V ar(Sn/bn) → 0. Hence by Chebyshev’s inequality,
it follows that (Sn − an)/bn
P
→ 0, with an = 0 and with b
2
n = n
1+δ
. Thus,
the sequence {Xn, n ≥ 1} follows WLLN. With different values of δ, we have
many sequences {bn, n ≥ 1} for which the WLLN holds. As in Example 9.2.1,
can find more than one sequences {an, n ≥ 1} with which the WLLN holds.□
In the following theorems and corollaries, we investigate under which con￾ditions, the sequence {Xn, n ≥ 1} follows WLLN.
Theorem 9.2.1. Chebyshev’s WLLN: Suppose {Xn, n ≥ 1} is a sequence
of uncorrelated random variables with uniformly bounded variances, then the
sequence follows WLLN with an = E(Sn) and bn = n.
Proof. It is given that {Xn, n ≥ 1} is a sequence of uncorrelated random
variables with uniformly bounded variances. Hence,
Cov(Xn, Xm) = 0 ∀ n ̸= m & V ar(Xn) ≤ M, ∀ n ≥ 1
⇒ V ar(Sn − E(Sn)) = V ar(Sn) = Xn
i=1
V ar(Xi) ≤ nM
⇒ V ar (Sn − E(Sn))/n ) = V ar(Sn − E(Sn))/n2 ≤ M/n
⇒ P

|Sn − E(Sn)|
n
> ϵ
≤ E

Sn − E(Sn)
nϵ 2
by Chebyshev’s inequality
≤ M/nϵ2 → 0, as n → ∞ ∀ ϵ > 0
⇒ (Sn − E(Sn))/n P
→ 0.
Thus, {Xn, n ≥ 1} follows WLLN with an = E(Sn) and bn = n.
Corollary 9.2.1. Suppose {Xn, n ≥ 1} is a sequence of independent random
variables with uniformly bounded variances, then the sequence follows WLLN
with an = E(Sn) and bn = n.
Proof. Since{Xn, n ≥ 1} is a sequence of independent random variables, it
follows that {Xn, n ≥ 1} is a sequence of uncorrelated random variables and
hence the result follows from Theorem 9.2.1.Weak Law of Large Numbers 409
Corollary 9.2.2. Suppose {Xn, n ≥ 1} is a sequence of independent and
identically distributed random variables with mean µ and finite variance σ
2
,
then the sequence follows WLLN with an = E(Sn) = nµ and bn = n.
Proof. Since {Xn, n ≥ 1} is a sequence of independent and identically dis￾tributed random variables with mean µ and finite variance σ
2
, E(Sn) = nµ
and V ar(Sn) = nσ2
. Hence,
V ar(Sn − E(Sn))/n = V ar(Sn)/n2 = σ
2
/n → 0 as n → ∞.
The proof now follows by Chebyshev’s inequality as in Theorem 9.2.1.
Corollary 9.2.3. Suppose {Xn, n ≥ 1} is a sequence of independent and iden￾tically distributed random variables each having Bernoulli B(1, p) distribution.
Then Pn = Xn
P
→ p.
Proof. Since {Xn, n ≥ 1} is a sequence of independent and identically dis￾tributed random variables each having Bernoulli B(1, p) distribution,
E(Xn) = p & V ar(Xn) = p(1 − p) ⇒ E(Sn) = np & V ar(Sn) = np(1 − p)
⇒ (Sn − np)/n P
→ 0 ⇐⇒ Sn/n = Xn = Pn
P
→ p,
by Corollary 9.2.2,
Corollary 9.2.3 states that in a sequence of independent Bernoulli trials,
sample proportion Pn of successes, which is the same as the relative frequency
of success, stabilizes at p. In the setup of large sample inference, it states that
sample proportion Pn is a consistent estimator of probability p of success.
Corollary 9.2.3 is known as a Bernoulli WLLN.
In two examples, in Theorem 9.2.1 and in the corollaries to the theorem,
we heavily used Chebyshev’s inequality, to prove that the sequence satisfies
the WLLN. Hence the underlying assumption is that random variables of the
sequence are in L2. In the following theorem, known as Khintchine’s WLLN,
we note that the condition of finiteness of variance can be relaxed. As a con￾sequence, the proof to establish WLLN requires some more techniques. The
proof is based on a truncation technique. We briefly describe it below. A ran￾dom variable X is said to be truncated at c, 0 < c < ∞ if X∗
is defined as a
function of X as follows.
X∗ =

X, if |X| ≤ c
0, if |X| > c.
Thus with this technique, the values of X such that |X| > c are replaced by
0 and hence an arbitrary random variable X is replaced by an almost surely
bounded random variable X∗
. As a consequence, all moments of X∗
exist and410 Laws of Large Numbers
are finite. Thus,
E(X∗
) = Z
Ω
X∗
dP =
Z
[|X|≤c]
X∗
dP +
Z
[|X|>c]
X∗
dP =
Z
[|X|≤c]
XdP
≤ c
Z
Ω
dP = c
& V ar(X∗
) ≤ E(X∗
)
2 =
Z
[|X|≤c]
X2
dP ≤ c
2
Z
[|X|≤c]
dP ≤ c
2
Z
Ω
dP = c
2
.
Further, P[X ̸= X∗
] = P[|X| > c]. It can be made arbitrarily small by select￾ing c large, since X is bounded in probability, being a real random variable.
As a pre-requisite in the proofs of Khintchine’s WLLN and Kolmogorov’s
SLLN in Section 3, we need certain results. We discuss these below.
Definition 9.2.1. Suppose {Xn, n ≥ 1} and {Yn, n ≥ 1} are sequences of
random variables defined on the same probability space. The two sequences
are said to be equivalent sequences if P
n≥1 P[Xn ̸= Yn] < ∞.
The limiting behaviour of the two sequences is the same as elaborated in
the following theorem.
If {Zn, n ≥ 1} is a sequence of random variables, then we say that P∞
i=1 Zi
is defined if limn→∞ Pn
i=1 Zi exists in some sense and is finite almost surely.
Theorem 9.2.2. Suppose {Xn, n ≥ 1} and {Yn, n ≥ 1} are equivalent se￾quences of random variables defined on the same probability space. Then
(i) P
n≥1
(Xn − Yn) converges a.s.
(ii) Pn
i=1(Xi − Yi)/bn
a.s. → 0 as n → ∞, where {bn, n ≥ 1} is a sequence of
positive real numbers such that bn → ∞ as n → ∞.
(iii) Pn
i=1 Yi/bn
a.s. → Y ⇒
Pn
i=1 Xi/bn
a.s. → Y as n → ∞.
(iv) Pn
i=1 Yi/bn
P
→ Y ⇒
Pn
i=1 Xi/bn
P
→ Y as n → ∞.
Proof.
(i) Suppose {Xn, n ≥ 1} and {Yn, n ≥ 1} are equivalent sequences of ran￾dom variables. Then by the Borel-Cantelli lemma,
X
n≥1
P[Xn ̸= Yn] < ∞
⇒ P[lim sup[Xn ̸= Yn]] = 0 ⇐⇒ P[lim inf[Xn = Yn]] = 1.
Thus, there exists a p-null set N and an integer n0(ω), ω ∈ Nc
, such
that Xn(ω) = Yn(ω) ∀ n ≥ n0 & ∀ ω ∈ Nc
. Thus,
∀ ω ∈ N
c
,
X∞
n=1
(Xn−Yn)=Xn0
n=1
(Xn−Yn)<∞ ⇒X
n≥1
(Xn−Yn) converges a.s.Weak Law of Large Numbers 411
(ii) In view of (i), Pn
i=1(Xi − Yi) converges to a finite number almost surely
and bn → ∞ as n → ∞, hence we get (ii).
(iii) From the result in (ii)
(1/bn)
Xn
i=1
Xi = (1/bn)
Xn
i=1
(Xi − Yi) + (1/bn)
Xn
i=1
Yi
a.s. → 0 + Y = Y.
(iv) From the result in (ii),
(1/bn)
Xn
i=1
(Xi − Yi)
a.s. → 0 ⇒ (1/bn)
Xn
i=1
(Xi − Yi)
P
→ 0
⇒ (1/bn)
Xn
i=1
Xi = (1/bn)
Xn
i=1
(Xi − Yi) + (1/bn)
Xn
i=1
Yi
P
→ 0 + Y = Y.
In Theorem 8.2.3, we have proved that for any random variable X defined
on (Ω, A, P),
X
n≥1
P[|X| ≥ n] ≤ E(|X|) ≤ 1 + X
n≥1
P[|X| ≥ n].
Thus, a random variable X is integrable if and only if P
n≥1 P[|X| ≥ n] < ∞.
In the proof of Khintchine’s WLLN, we use Toeplitz’ lemma. It is stated
below, Loeve [16].
Lemma 9.2.1. Suppose {xn, n ≥ 1} is a sequence of real numbers such that
xn → x as n → ∞. Then as n → ∞,
bn =
Xn
k=1
ak → ∞ ⇒ (1/bn)
Xn
k=1
xkak → x.
As a particular case, suppose ak = 1 ∀ k = 1, 2, · · · , n. Then bn = n → ∞
as n → ∞ and (1/n)
Pn
k=1 xk = xn → x, whenever xn → x.
In the proof of Khintchine’s WLLN in the next theorem, we use truncation
technique and all these results.
Theorem 9.2.3. Khintchine’s WLLN: Suppose {Xn, n ≥ 1} is a sequence of
independent and identically distributed random variables with finite mean µ,
then the sequence follows WLLN with an = E(Sn) = nµ and bn = n, that is,
(Sn − nµ)/n = Xn − µ
P
→ 0.
Proof. Using truncation technique, for every n ≥ 1, a random variable X∗
n
is
defined as follows.
X∗
n =

Xn, if |Xn| < n
0, if |Xn| ≥ n.412 Laws of Large Numbers
Note that being Borel functions of Xn, {X∗
n
, n ≥ 1} is also a sequence of
independent random variables. Suppose S
∗
n =
Pn
k=1 X∗
k
and an event En is
defined as En = [|Xn| ≥ n], n ≥ 0 with E0 = Ω. Thus, X∗
n = Xn on Ec
n and
X∗
n ̸= Xn on En. By Theorem 8.2.3,
X
n≥1
P[Xn ̸= X∗
n
] = X
n≥1
P(En) = X
n≥1
P[|Xn| ≥ n] ≤ E(|Xn|) < ∞
⇒ {Xn, n ≥ 1} & {X∗
n
, n ≥ 1} are equivalent sequences
⇒ (Sn − S
∗
n
)/n a.s. → 0 by result (ii) of Theorem 9.2.2
⇒ (Sn − S
∗
n
)/n P
→ 0. (9.1)
Thus, by result (iii) and (iv) of Theorem 9.2.2, the limiting behaviour of Sn/n
is the same as that of S
∗
n/n. We now study the limiting behaviour of S
∗
n/n.
Suppose Xn, n ≥ 1 are distributed as X with finite mean µ. Observe that for
each n ≥ 1,
E(X∗
n
) = Z
Ω
X∗
ndP =
Z
En
X∗
ndP+
Z
Ec
n
X∗
ndP =
Z
Ec
n
XndP =
Z
Ec
n
XdP = E(XIEc
n
),
since Xn is distributed as X. Further, observe that |XIEc
n
| ≤ |X| and
E(|X|) < ∞. From the definition of Ec
n
, note that for n1 < n2,
|Xn(ω)| < n1 ⇒ |Xn(ω)| < n2 ⇒ E
c
n1 ⊂ E
c
n2
⇒ {E
c
n
, n ≥ 1} ↑ [
n≥1
E
c
n = Ω as n → ∞
⇒ IEc
n
a.s. → IΩ ⇒ XIEc
n
a.s. → XIΩ = X as n → ∞
⇒ E(XIEc
n
) → E(X) by dominated a.s. convergence theorem
⇒ E(X∗
n
) → µ as n → ∞
⇒ E(S
∗
n/n) = 1
n
Xn
k=1
E(X∗
k
) → µ by Toeplitz’ lemma. (9.2)
Now we study the nature of V ar(S
∗
n/n). Suppose {an, n ≥ 1} is a sequence
positive integers such that 0 < an < n and an → ∞ in such a way that
an/n → 0 as n → ∞. Then V ar(S
∗
n
) can be expressed as
V ar(S
∗
n
) = Xn
i=1
V ar(X∗
i
) ≤
Xn
i=1
E(X∗
i
)
2 ≤
Xn
i=1
Z
[|X|≤i]
X2
dP
=
Xan
i=1
Z
[|X|≤i]
X2
dP +
Xn
i=an+1
Z
[|X|≤i]
X2
dP
=
Xan
i=1
Z
[|X|≤i]
X2
dP +
Xn
i=an+1
Z
[|X|≤an]
X2
dP +
Xn
i=an+1
Z
[an<|X|≤i]
X2
dP.Weak Law of Large Numbers 413
Further note that
V ar(S
∗
n
) ≤
Xan
i=1
an
Z
[|X|≤an]
|X| dP +
Xn
i=an+1
an
Z
[|X|≤an]
|X| dP
+
Xn
i=an+1
n
Z
[an<|X|≤n]
|X| dP
= nan
Z
[|X|≤an]
|X| dP + n(n − an)
Z
[an<|X|≤n]
|X| dP
≤ nan
Z
[|X|∈R+]
|X| dP + n
2
Z
[|X|>an]
|X| dP as n − an < n.
It is given that E(X) < ∞, hence R
[|X|∈R+]
|X| dP = E(|X|) = M < ∞.
Observe that I[|X|>an]
|X| < |X| and |X| is integrable. Further, an → ∞ as
n → ∞, hence I[|X|>an] → I∅ ≡ 0 a.s. Hence |X|I[|X|>an] → 0 a.s. Then by
the Lebesgue dominated almost sure convergence theorem,
R
[|X|>an]
|X| dP = E(I[|X|>an]
|X|) → 0. As a consequence,
V ar(S
∗
n/n) ≤ (an/n)M +
Z
[|X|>an]
|X| dP → 0
⇒ E ((S
∗
n − E(S
∗
n
))/n)
2 → 0
⇒ (S
∗
n − E(S
∗
n
))/n q.m. → 0 ⇒ (S
∗
n − E(S
∗
n
))/n P
→ 0. (9.3)
Using results in Equation (9.1), Equation (9.2) and Equation (9.3), we have
Sn/n − µ = (Sn − S
∗
n + S
∗
n
)/n − µ + E(S
∗
n
)/n − E(S
∗
n
)/n
= (Sn − S
∗
n
)/n + (S
∗
n − E(S
∗
n
))/n + E(S
∗
n
)/n − µ
P
→ 0
⇒ Sn/n P
→ µ ⇐⇒ Xn − µ
P
→ 0
and the theorem is proved.
There is one more approach to prove Khintchine’s WLLN which does not
use truncation technique but uses some results related to a characteristic func￾tion. We prove some of these below. These are also useful to prove a central
limit theorem in the next chapter. We refer to Gut [13] for these results.
Lemma 9.2.2. Suppose u1, u2, ..., um and w1, w2, ..., wm are complex numbers
where |ui
| ≤ 1, |wi
| ≤ 1, i = 1, 2, · · · , m. Then,





Ym
i=1
ui −
Ym
i=1
wi





≤
Xm
i=1
|ui − wi
|.414 Laws of Large Numbers
Proof. The proof is by induction. Result is obviously true for m = 1. For
m = 2 observe that,





Y
2
i=1
ui −
Y
2
i=1
wi





= |(u2 − w2)u1 + w2(u1 − w1)|
≤ |(u2 − w2)||u1| + |w2||(u1 − w1)|
≤
X
2
i=1
|ui − wi
|, since |u1| ≤ 1, |w2| ≤ 1.
We assume the result is true for m = k. Now
k
Y
+1
i=1
ui −
k
Y
+1
i=1
wi =
"
(uk+1 − wk+1)
Y
k
i=1
ui
#
+
"
wk+1 Y
k
i=1
ui −
Y
k
i=1
wi
!#
⇒





k
Y
+1
i=1
ui −
k
Y
+1
i=1
wi





≤ |uk+1 − wk+1| +





Y
k
i=1
ui −
Y
k
i=1
wi





≤ |uk+1 − wk+1| +
X
k
i=1
|ui − wi
|, by induction hypothesis
=
k
X
+1
i=1
|ui − wi
|,
The second step follows since |
Q
k
i=1
ui
| and |wk+1| ≤ 1.
We state a lemma below, for proof refer to Lemma A 1.2, p. 556 of Gut [13].
Lemma 9.2.3. For all real numbers x and i =
√
−1,






e
ix −
X
k
j=0
(ix)
j
/j!






≤ min 
2|x|
k
/k!, |x|
k+1/(k + 1)!	
.
We use Lemma 9.2.3 in the following theorem, which is useful in proving
Khintchine’s WLLN and Lindeberg-Levy CLT in the next chapter.
Theorem 9.2.4. If E(|X|
k
) < ∞ and if ϕ is a characteristic function of X,
then ∀ t ∈ R,


ϕ(t) −
X
k
j=0
(it)
j
j!
E(Xj
)


 ≤ E

min n2|tX|
k
k!
,
|tX|
k+1
(k + 1)!
o.Weak Law of Large Numbers 415
Proof. From the definition of a characteristic function we have


ϕ(t) −
X
k
j=0
(it)
j
j!
E(Xj
)


 =



E(e
itX) − E
X
k
j=0
(it)
j
j!
Xj



≤ E



e
itX −
X
k
j=0
(itX)
j
/j!




≤ E

min n2|tX|
k
k!
,
|tX|
k+1
(k + 1)!
o, by Lemma 9.2.3.
In the following theorem, we give another proof of Khintchine’s WLLN
which is based on these results about a characteristic function.
Theorem 9.2.5. Khintchine’s WLLN: Suppose {Xn, n ≥ 1} is a sequence of
independent and identically distributed random variables with finite mean µ,
then (Sn − nµ)/n = Xn − µ
P
→ 0.
Proof. The proof is in two steps: (i) µ = 0 and (ii) µ ̸= 0.
Case (i): Suppose µ = 0. By Theorem 7.3.2, Sn/n P
→ 0 ⇐⇒ Sn/n L
→ 0.
Hence we show that Sn/n L
→ 0 by proving that the characteristic function of
Sn/n converges to the characteristic function ϕ0(t) ≡ 1 of X ≡ 0. Suppose
ϕ(·) denote the common characteristic function of Xi
, i = 1, 2, · · · , n. Then
by Theorem 5.3.5, the characteristic function of Sn/n is ϕ
n(t/n). With k = 1
and µ = 0 in Theorem 9.2.4 we have,
|ϕ(t/n) − (1 + itE(X))| = |ϕ(t/n) − 1| ≤ E
￾
min 
2|tX|/n, |tX|
2
/2n
2
	
= (1/n)E
￾
min 
2|tX|, |tX|
2
/2n
	
⇒ n|ϕ(t/n) − 1| ≤ E(Wn), where Wn = min 
2|tX|,
|tX|
2
2n

. (9.4)
Further, note that Wn ≤ 2|tX| ∀ n and E(|X|) < ∞. Hence, Wn is dominated
by an integrable random variable. Observe that for large n, Wn = |tX|
2/2n.
Now X is bounded in probability, being a real random variable which implies
that Wn
P
→ 0 as n → ∞. Hence, by the Lebesgue dominated probability
convergence theorem, limn→∞ E(Wn) = E(limn→∞ Wn) = 0. Observe that,
|ϕSn/n(t) − 1| = |ϕ
n
(t/n) − 1| = |ϕ
n
(t/n) − 1
n
|
≤
Xn
k=1
|ϕ(t/n) − 1|, by Lemma 9.2.2
= n|ϕ(t/n) − 1| ≤ E (Wn) by (9.4)
⇒ limn→∞
|ϕSn/n(t) − 1| ≤ limn→∞
E (Wn) = E

limn→∞
Wn

= 416 Laws of Large Numbers
Thus, ∀ t ∈ R, ϕSn/n(t) → 1 ≡ ϕ0(t) and ϕ0(t) = 1 is continuous at t = 0.
Hence by the continuity theorem and the uniqueness theorem for characteristic
functions, we conclude that
Sn/n L
→ 0 ⇐⇒ Sn/n P
→ 0.
Case-(ii): When µ ̸= 0, we define a random variables Yn = Xn − µ so that
{Yn, n ≥ 1} is a sequence of independent and identically distributed random
variables with mean zero. Hence from case (i),
(Y1 + Y2 + · · · + Yn)/n P
→ 0 ⇐⇒ Sn/n P
→ µ.
Remark 9.2.2. We have already proved in Corollary 9.2.2 that a sequence
{Xn, n ≥ 1} of independent and identically distributed random variables with
mean µ and finite variance σ
2
follows WLLN with an = E(Sn) = nµ and
bn = n. The same result follows from the Theorem 9.2.5 since, V ar(X1) < ∞
implies E(X1) < ∞.
In Example 7.2.8, we have shown that the r-th order sample raw moment
converges in probability to the corresponding population moment, provided
µ
′
2r < ∞. In the following example, we show that this result is true even if the
condition µ
′
2r < ∞ is relaxed to µ
′
r < ∞. It follows from Khintchine’s WLLN.
Example 9.2.3. Suppose {Xn, n ≥ 1} is a sequence of independent and iden￾tically distributed random variables with finite r-th order raw moment
µ
′
r = E(Xr
1
), r ≥ 1. Being Borel functions, {Xr
n
, n ≥ 1} is also a sequence
of independent and identically distributed random variables with finite mean
µ
′
r
. Hence, by Khintchine’s WLLN, the r-th order sample raw moment
m′
r =
Pn
i=1 Xr
i
/n P
→ µ
′
r
. Further using binomial theorem, r-th order cen￾tral moment µr can be expressed as a polynomial function of r-th order raw
moments for r ≤ 1 as follows.
µr =

r
0

µ
′
r +

r
1

µ
′
r−1µ
′
1 +

r
2

µ
′
r−2
(µ
′
1
)
2 + · · · +

r
r

(µ
′
1
)
r
, r ≥ 1.
Similarly, r-th order sample central moment mr =
Pn
i=1(Xi − Xn)
r/n can be
written as
mr =

r
0

m′
r +

r
1

m′
r−1m′
1 +

r
2

m′
r−2
(m′
1
)
2 + · · · +

r
r

(m′
1
)
r
, r ≥ 1.
In view of the result that the convergence in probability is closed under all
arithmetic operations, mr
P
→ µr. □
From this example, it thus follows that raw moments of a random sample
are consistent for the corresponding population raw moments and further by
invariance property of convergence in probability under arithmetic operations,
sample central moments are also consistent for the corresponding populationWeak Law of Large Numbers 417
central moments. In particular, the sample mean and the sample variance are
consistent for population mean and population variance respectively.
Khintchine’s WLLN is a foundation of large sample inference procedures.
Suppose an estimator based on a random sample {X1, X2, · · · , Xn} is in the
form of average Tn =
Pn
i=1 g(Xi)/n, say, where g is a Borel function. Then
Khintchine’s WLLN conveys that Tn
P
→ E(g(X)), provided it is finite. If
E(g(X)) = h(θ) and h
−1
exists and is continuous then by the invariance prop￾erty of convergence in probability under continuous transformation, h
−1
(Tn)
will be a consistent estimator of θ.
In the following example using R, we examine convergence in probability
of some raw and central moments to the corresponding population moments
for some distributions.
Example 9.2.4. In this example we verify that sample mean converges in
probability to the mean of the distribution of X. For comparison of the rate of
convergence we consider three distributions, exponential, geometric and Pois￾son. For uniformity, we set the parameters of the distributions so that mean of
each is 1. As discussed in Section 7.2, to verify the convergence in probability,
we simulate m random samples, each of size n from the distributions and find
the estimate rfn. We examine whether rfn → 1 as n → ∞. In this example
for illustration, we have fixed ϵ = 0.05, m = 500 and n takes values from 500
to 3000 with an increment of 500.
Code 9.2.1. We use the following code to compute rfn for three distributions.
eps=0.05; nsim=500; N=seq(500,3000,500)
meex=meg=mep=p1=p2=p3=c()
for(j in 1:length(N))
{
for(m in 1:nsim)
{
set.seed(m)
x=rexp(N[j],1)
y=rgeom(N[j],.5)
z=rpois(N[j],1)
meex[m]=mean(x)
meg[m]=mean(y)
mep[m]=mean(z)
}
p1[j]=length(which(abs(meex-1)<eps))/nsim
p2[j]=length(which(abs(meg-1)<eps))/nsim
p3[j]=length(which(abs(mep-1)<eps))/nsim
}
d=data.frame(N,p1,p2,p3);d418 Laws of Large Numbers
TABLE 9.1
Verification of WLLN: Exponential, Geometric and Poisson
Distributions
n 500 1000 1500 2000 2500 3000
Exponential 0.738 0.884 0.946 0.978 0.982 0.990
Geometric 0.586 0.766 0.818 0.896 0.914 0.948
Poisson 0.720 0.904 0.952 0.966 0.992 0.986
The output is organized in Table 9.1.
From Table 9.1, we note that rfn → 1 as n increases. The rate is compar￾atively slow for the geometric distribution. □
In the next example, we verify WLLN by examining that the sample mean,
the sample variance and the sample second raw moment converge in proba￾bility to respective population characteristics.
Example 9.2.5. We simulate m random samples, each of size n from the bi￾nomial B(6, 1/3) distribution and find the estimate rfn. We examine whether
rfn → 1 as n → ∞. We have fixed ϵ = 0.05, m = 500 and n takes values from
1000 to 6000 with an increment of 1000.
Code 9.2.2. We use the following code to compute rfn for three charac￾teristics, the sample mean, the sample variance and the sample second raw
moment.
eps=0.05; nsim=1000; N=seq(1000,6000,1000)
me=me2=p1=p2=p3=c()
for(j in 1:length(N))
{
for(m in 1:nsim)
{
set.seed(m)
x=rbinom(N[j],6,1/3)
me[m]=mean(x)
me2[m]=mean(x^2)
}
v=me2-(me)^2
p1[j]=length(which(abs(me-2)<eps))/nsim
p2[j]=length(which(abs(me2-16/3)<eps))/nsim
p3[j]=length(which(abs(v-4/3)<eps))/nsim
}
d=data.frame(N,p1,p2,p3);dStrong Law of Large Numbers 419
TABLE 9.2
Verification of WLLN: Binomial Distribution
n 1000 2000 3000 4000 5000 6000
Sample Mean 0.822 0.936 0.974 0.994 0.996 0.998
m′
2 0.232 0.317 0.387 0.440 0.494 0.520
Sample variance 0.627 0.805 0.871 0.917 0.948 0.967
The output is organized in Table 9.2.
From Table 9.2, we observe that rfn → 1 as n increases for all the se￾quences. However, rfn converges faster to 1 for the sample mean, the rate is
comparatively slow for sample variance and very slow for the sample second
raw moment. □
The next section is devoted to SLLN.
9.3 Strong Law of Large Numbers
SLLN is similar to WLLN, the word “strong” basically replaces convergence
in probability by the almost sure convergence as is clear from Definition 9.1.1.
However, almost sure convergence being stronger than the convergence in
probability, the techniques needed to establish SLLN are slightly involved
than those for WLLN. In the Bernoulli WLLN as given in Corollary 9.2.3, we
have noted that if {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables each having Bernoulli B(1, p) distribution, then
the sample proportion Pn = Xn
P
→ p. In the following theorem, known as
Bernoulli SLLN, we prove that the convergence in probability in Bernoulli
WLLN can be extended to the almost sure convergence. To prove it we use
the sufficient condition for almost sure convergence as given in (i) of Corollary
6.3.1.
Theorem 9.3.1. Bernoulli SLLN: Suppose {Xn, n ≥ 1} is a sequence of
independent and identically distributed random variables each having Bernoulli
B(1, p) distribution. Then
(Sn − np)/n a.s. → 0 ⇐⇒ Pn = Xn
a.s. → p.
Proof. Since Xi ∼ B(1, p) for each i ≥ 1, we have
Sn ∼ B(n, p) ⇒ E(Sn) = np, V ar(Sn) = np(1 − p)
& E((Sn − np)/n)
2 = p(1 − p)/n
⇒ P [|(Sn − np)/n| > ϵ] ≤ p(1 − p)/nϵ2 ∀ ϵ > 0,420 Laws of Large Numbers
by Chebyshev’s inequality. With the same arguments, replacing n by n
2 we
have ∀ ϵ > 0,
P

|(Sn2 − n
2
p)/n2
| > ϵ
≤ p(1 − p)/n2
ϵ
2
⇒
X
n≥1
P

|(Sn2 − n
2
p)/n2
| > ϵ
≤
X
n≥1
p(1 − p)/n2
ϵ
2 < ∞
⇒ Sn2 /n2 a.s. → p.
Suppose kn is an integer and kn → ∞ as n → ∞, then using the same
arguments we have, Sk2
n
/k2
n
a.s. → p. We now prove that |Sn/n − Sk2
n
/k2
n
| → 0
pointwise and hence almost surely. As a consequence, Sk2
n
/k2
n
a.s. → p implies
that Sn/n a.s. → p. It is to be noted that ∀ n ≥ 1 ∃ kn such that k
2
n ≤ n <
(kn + 1)2
. Now
k
2
n ≤ n < (kn + 1)2 ⇒ 0 ≤ n − k
2
n < 2kn + 1 ⇒ 0 ≤ n − k
2
n ≤ 2kn,
n − k
2
n being an integer. Further as n → ∞, kn → ∞. Since Xi = 0 or 1, for
n > k2
n and ∀ ω ∈ Ω observe that,




Sn
n
−
Sk2
n
k
2
n



 =



Xn
i=1
Xi/n −
k
2 Xn
i=1
Xi/k2
n


 =




1
n
−
1
k
2
n
 k
2 Xn
i=1
Xi +
1
n
Xn
i=k2
n+1
Xi



≤ ((n − k
2
n
)/nk2
n
)
k
2 Xn
i=1
Xi + (1/n)
Xn
i=k2
n+1
Xi
≤ ((n − k
2
n
)k
2
n/nk2
n
)) + (n − k
2
n
)/n = 2(n − k
2
n
)/n as Xi = 0, 1
≤ 4kn/n as n − k
2
n ≤ 2kn
≤ 4kn/k2
n as n > k2
n
= 4/kn → 0 as n → ∞.
Thus, |Sn/n − Sk2
n
/k2
n
| → 0 pointwise and hence almost surely. As a conse￾quence we have,
Sn/n − p = (Sn/n − Sk2
n
/k2
n
) + (Sk2
n
/k2
n − p)
a.s. → p.
Remark 9.3.1. Another simpler proof for Bernoulli SLLN also uses the suf￾ficient condition for almost sure convergence as given in (ii) of Corollary 6.3.1
and as illustrated in Example 6.3.8. Observe that Sn ∼ B(n, p), hence
E(Sn − np)
4 = 3(npq)
2 + npq(1 − 6pq)
⇒ E ((Sn − np)/n)
4 = (3(npq)
2 + npq(1 − 6pq))/n4
= 3(pq)
2
/n2 + pq(1 − 6pq)/n3
⇒
X∞
n=1
E ((Sn − np)/n)
4 =
X∞
n=1

3(pq)
2
/n2 + pq(1 − 6pq)/n3

< ∞
⇒ Sn/n a.s. → p.Strong Law of Large Numbers 421
Using Bernoulli SLLN we show in the following example that the empirical
distribution function converges almost surely to the distribution function from
which the sample is generated.
Example 9.3.1. Suppose {X1, X2, · · · , Xn} are independent and identically
distributed random variables each having the distribution function F(x), x ∈
R. For each fixed x ∈ R, the empirical distribution function Fn(x), also known
as the sample distribution function, corresponding to {X1, X2, · · · , Xn} is
defined as
Fn(x) = (number of Xi ≤ x)/n =
Xn
i=1
Yi(x)/n, where
Yi(x) = 
1, if Xi ≤ x
0, if Xi > x.
for i = 1, 2, · · · , n. Thus, Yi(x) is a Borel function of Xi and hence
{Yi(x), i = 1, 2, · · · , n} are also independent and identically distributed ran￾dom variables, each having Bernoulli distribution with E(Yi(x)) = F(x) < ∞.
Hence by the Bernoulli WLLN, Fn(x) = Pn
i=1 Yi(x)/n P
→ E(Yi) = F(x). Fur￾ther,
nFn(x) ∼ B(n, F(x)) ⇒ V ar(Fn(x)) = F(x)(1 − F(x))/n ≤ 1/4n.
Thus, by Chebyshev’s inequality it can be shown that the convergence in
probability is uniform in x. By the Bernoulli SLLN, Fn(x) = Pn
i=1 Yi(x)/n a.s. →
F(x). It can further be proved that the almost sure convergence is also uniform
in x, that is, P[supx∈R |Fn(x) − F(x)| → 0] = 1, Loeve [16]. This result is a
well known Glivenko Cantelli theorem. It states that the sample distribution
function converges almost surely uniformly to the distribution function from
which we have drawn the random sample. In other words, for large n, the
sample distribution function is a good approximation for F(x). It is a very
important result and forms the basis of non-parametric inference. Hence, it is
also referred to as the central statistical theorem, Loeve [16]. □
Remark 9.3.2. In Example 7.3.26 using Code 7.3.5, we have verified the
convergence in law of {Xn, n ≥ 1} where Xn ∼ G(n, n), by showing that as n
increases, the distribution function Fn(x) of Xn approaches to the distribution
function F of X ≡ 1 for all x ∈ R − {1}. Based on simulated observations
from Xn, we have obtained the empirical distribution function Gn(x) and has
verified that as n increases, it also approaches to that of X ≡ 1, see Figure
7.9.
We now proceed to the most important result, it is Kolmogorov’s SLLN. It
states that for a sequence of independent and identically distributed random
variables with finite mean µ, sample mean converges almost surely to µ. As in422 Laws of Large Numbers
Khintchine’s WLLN, we use truncation technique and related results as given
in Theorem 9.2.2 and Lemma 8.2.3. The proof of Kolmogorov’s SLLN is as
outlined in Breiman [6]. We need one more result, known as Kolmogorov’s
proposition, in the proof of Kolmogorov’s SLLN. We state it below.
Theorem 9.3.2. Kolmogorov’s proposition: If {Xn, n ≥ 1} is a sequence of
independent random variables such that P
n≥1
V ar(Xn)/n2 < ∞, then
(Sn − E(Sn))/n a.s. → 0.
The proof is based on Kolmogorov’s inequality concerning the maximum of
the partial sums. For the proof of Kolmogorov’s inequality and Kolmogorov’s
proposition we refer to Loeve [16].
Using Theorem 9.2.2, Lemma 8.2.3 and Kolmogorov’s proposition, we
prove Kolmogorov’s SLLN in the following theorem. The proof proceeds on
the same lines as that of Khintchine’s WLLN, with the only difference that to
claim (S
∗
n − E(S
∗
n
))/n a.s. → 0 we have to use Kolmogorov’s proposition. The
initial part of the proof is the same as that of Khintchine’s WLLN.
Theorem 9.3.3. Kolmogorov’s SLLN: Suppose {Xn, n ≥ 1} is a sequence
of independent and identically distributed random variables with finite mean
µ, then the sequence follows SLLN with an = E(Sn) = nµ and bn = n, that
is, (Sn − E(Sn))/n = Xn − µ
a.s. → 0. Conversely if, Xn
a.s. → C, then Xn’s are
integrable random variables and C = µ is the common expectation.
Proof. (I) Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables each having distribution same as that of X, with
finite mean µ. As in Khintchine’s WLLN, for every n ≥ 1, we define a random
variable X∗
n as follows.
X∗
n =

Xn, if |Xn| < n
0, if |Xn| ≥ n.
Note that being Borel functions of Xn, {X∗
n
, n ≥ 1} is also a sequence of
independent random variables. Suppose S
∗
n =
Pn
k=1 X∗
k
and an event En is
defined as En = [|Xn| ≥ n], n ≥ 0 with E0 = Ω. Thus, X∗
n = Xn on Ec
n and
X∗
n ≠ Xn on En. By Theorem 8.2.3,
X
n≥1
P[Xn ̸= X∗
n
] = X
n≥1
P(En) = X
n≥1
P[|Xn| ≥ n] ≤ E(|Xn|) < ∞
⇒ {Xn, n ≥ 1} & {X∗
n
, n ≥ 1} are equivalent sequences
⇒ (Sn − S
∗
n
)/n a.s. → 0, (9.5)
the last step follows by result (ii) of Theorem 9.2.2. Thus, limiting behaviour
of Sn/n is the same as that of S
∗
n/n. We now study the limiting behaviour of
S
∗
n/n. Observe that for each n ≥ 1,
E(X∗
n
) = Z
Ω
X∗
ndP =
Z
En
X∗
ndP+
Z
Ec
n
X∗
ndP =
Z
Ec
n
XndP =
Z
Ec
n
XdP = E(XIEc
n
),Strong Law of Large Numbers 423
since Xn is distributed as X. Further, observe that |XIEc
n
| ≤ |X| and
E(|X|) < ∞. From the definition of Ec
n
, note that for n1 < n2,
|Xn(ω)| < n1 ⇒ |Xn(ω)| < n2 ⇒ E
c
n1 ⊂ E
c
n2
⇒ {E
c
n
, n ≥ 1} ↑ [
n≥1
E
c
n = Ω as n → ∞
⇒ IEc
n
a.s. → IΩ ⇒ XIEc
n
a.s. → XIΩ = X as n → ∞
⇒ E(XIEc
n
) → E(X) by dominated a.s. convergence theorem
⇒ E(X∗
n
) → µ as n → ∞
⇒ E(S
∗
n/n) = (1/n)
Xn
k=1
E(X∗
k
) → µ by Toeplitz’ lemma. (9.6)
To decide the nature of P
n≥1
V ar(X∗
n
)/n2
, we define an event Ak as
Ak = [k ≤ |Xn| < k + 1], k ≥ 0. Further as proved in Lemma 8.2.3, these
events are mutually exclusive. Then the event Ec
n
can be expressed as,
E
c
n = [|Xn| < n] = [n
k=1
[k − 1 ≤ |Xn| < k] = Xn
k=1
Ak−1, n ≥ 1
⇒ V ar(X∗
n
) ≤ E((X∗
n
)
2
) = Z
Ec
n
X2
ndP =
Z
Pn
k=1
Ak−1
X2
ndP
=
Xn
k=1
Z
Ak−1
X2
ndP ≤
Xn
k=1
k
2
Z
Ak−1
dP
=
Xn
k=1
k
2P(Ak−1), since on Ak−1 X2
n ≤ k
2
.
Since Xn’s are distributed as X,
P(Ak−1) = P[k ≤ |Xn| < k + 1] = P[k ≤ |X| < k + 1].
Hence, X
n≥1
V ar(X∗
n
)
n2
≤
X
n≥1
Xn
k=1
(k
2
/n2
)P(Ak−1) = X
k≥1
k
2P(Ak−1)
X∞
n=k
(1/n2
).
To find a bound on P∞
n=k
(1/n2
P
), suppose Bn = (n − 1, n], n ≥ 1 so that
∞
n=k+1 Bn = (k, ∞) = B, say. Note that
Z∞
k
1
x
2
dx =
Z
B
1
x
2
dx =
X∞
n=k+1
Z
Bn
1
x
2
dx ≥
X∞
n=k+1
1
n2
Z
Bn
dx
=
X∞
n=k+1
1
n2
Z n
n−1
dx =
X∞
n=k+1
1
n2424 Laws of Large Numbers
Hence, X∞
n=k
1
n2
=
1
k
2
+
X∞
n=k+1
1
n2
≤
1
k
2
+
Z∞
k
1
x
2
dx
=
1
k
2
+
1
k
≤ 2/k as k
2 ≥ k ⇐⇒ 1/k2 ≤ 1/k
Hence, X
n≥1
V ar(X∗
n
)/n2 ≤
X
k≥1
k
2P(Ak−1)
X∞
n=k
(1/n2
) ≤
X
k≥1
k
2P(Ak−1)(2/k)
= 2X
k≥1
kP(Ak−1) = 2X
k≥0
(k + 1)P(Ak)
= 2(1 + X
n≥1
P(En)) as in Theorem 8.2.3
= 2(1 + X
n≥1
P[|Xn| ≥ n]) = 2(1 + X
n≥1
P[|X| ≥ n])
≤ 2(1 + E(X)) < ∞.
The second last step follows by Theorem 8.2.3. Thus, {X∗
n
, n ≥ 1} is a sequence
of independent random variables such that P
n≥1
V ar(X∗
n
)/n2 < ∞. Hence,
by Kolmogorov’s proposition
(S
∗
n − E(S
∗
n
))/n a.s. → 0 (9.7)
Using the results in Equation (9.5), Equation (9.6) and Equation (9.7), we
have
Sn/n − µ = (Sn − S
∗
n + S
∗
n
)/n − µ + E(S
∗
n
)/n − E(S
∗
n
)/n
= (Sn − S
∗
n
)/n + (S
∗
n − E(S
∗
n
))/n + E(S
∗
n
)/n − µ
a.s → 0
⇒ Sn/n a.s. → µ.
(II) Conversely, suppose Sn/n a.s. → C. To prove that Xn’s are integrable random
variables, we use the fact that {Xn, n ≥ 1} are independent random variables
and hence the Borel zero-one law is applicable. Observe that,
Xn/n = (Sn − Sn−1)/n = Sn/n − ((n − 1)/n)(Sn−1/(n − 1)) a.s. → 0
⇒ P [lim sup[|Xn/n| > ϵ]] = 0 ∀ ϵ > 0
⇒ P[lim sup[|Xn| > n]] = 0 with ϵ = 1
⇒
X
n≥1
P[|Xn| > n] < ∞ by Borel zero-one law
⇒ E(Xn) < ∞ by Theorem 8.2.3,
that is, Xn’s are integrable random variables. Thus, {Xn, n ≥ 1} is a sequence
of independent and identically distributed random variables with finite mean
E(X). Hence by part (I), Sn/n a.s. → E(X). Since the limit random variable in
almost sure convergence is almost surely unique, C = E(X).Strong Law of Large Numbers 425
SLLN is useful to establish strong consistency of estimators which are
averages. From SLLN one can conclude that the r-th raw moment based on
a random sample is a strongly consistent estimator for the corresponding
population moment. Using the property that almost sure convergence is closed
under arithmetic operations, it follows that r-th central moment based on
a random sample is a strongly consistent estimator for the corresponding
population moment.
Example 9.3.2. Suppose {X1, X2, · · · , Xn} are independent and identically
distributed random variables with mean µ and variance σ
2 < ∞. By SLLN,
(1/n)
Xn
i=1
Xi
a.s. → µ & (1/n)
Xn
i=1
X2
i
a.s. → σ
2 + µ
2
⇒
Xn
i=1
Xi
.Xn
i=1
X2
i
a.s. → µ/(σ
2 + µ
2
). □
We summarize below the results discussed in this chapter.
Summary
1. A sequence {Xn, n ≥ 1} of random variables is said to obey a SLLN, if
there exists two sequences {an, n ≥ 1} of real numbers and {bn, n ≥ 1} of
positive real numbers tending to ∞ such that, (Sn − an)/bn
a.s. → 0 and a
WLLN, if (Sn − an)/bn
P
→ 0.
2. Chebyshev’s WLLN: Suppose {Xn, n ≥ 1} is a sequence of uncorrelated
random variables with uniformly bounded variances, then the sequence
follows WLLN with an = E(Sn) and bn = n.
3. Suppose {Xn, n ≥ 1} is a sequence of independent random variables with
uniformly bounded variances, then the sequence follows WLLN with an =
E(Sn) and bn = n.
4. Suppose {Xn, n ≥ 1} is a sequence of independent and identically dis￾tributed random variables with mean µ and finite variance σ
2
, then the
sequence follows WLLN with an = E(Sn) = nµ and bn = n.
5. Khintchine’s WLLN: Suppose {Xn, n ≥ 1} is a sequence of independent
and identically distributed random variables with finite mean µ, then the
sequence follows WLLN with an = E(Sn) = nµ and bn = n, that is,
(Sn − E(Sn))/n = Xn − µ
P
→ 0.
6. Bernoulli SLLN: Suppose {Xn, n ≥ 1} is a sequence of independent and
identically distributed random variables each having Bernoulli B(1, p) dis￾tribution. Then (Sn − np)/n a.s. → 0 ⇐⇒ Pn = Xn
a.s. → p.426 Laws of Large Numbers
7. Kolmogorov’s SLLN: Suppose {Xn, n ≥ 1} is a sequence of independent
and identically distributed random variables with finite mean µ, then the
sequence follows SLLN with an = E(Sn) = nµ and bn = n, that is,
(Sn − E(Sn))/n = Xn − µ
a.s. → 0. Conversely if, Xn
a.s. → C, then Xn’s are
integrable random variables and C = µ is the common expectation.
9.4 Conceptual Exercises
9.4.1 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
such that P[Xn = 2n] = 1/2
n, n ≥ 1. Examine whether the sequence
{Xn, n ≥ 1} obeys the WLLN. Find more that one sequences {an, n ≥ 1}
and {bn, n ≥ 1} with which WLLN holds.
9.4.2 Suppose {Xn, n ≥ 1} is a sequence of independent random variables with
E(Xn) = 0 and V (Xn) = n
2
. Examine whether the sequence {Xn, n ≥
1} obeys the WLLN.
9.4.3 Suppose {Xn, n ≥ 1} is a sequence of independent random variables with
E(Xn) = 0 and V (Xn) = n. Examine whether the sequence {Xn, n ≥ 1}
obeys the WLLN.
9.4.4 Suppose {Xn, n ≥ 1} is a sequence of independent random variables with
P[Xn = 2n] = P[Xn = −2
n] = 2−2(n+1) and P[Xn = 0] = 1 − 2
−2n−1
.
Examine whether the sequence {Xn, n ≥ 1} obeys the WLLN.
9.4.5 Suppose {Xn, n ≥ 1} is a sequence of independent random variables with
P[Xn = n] = P[Xn = −n] = 1/(2n
λ
) and P[Xn = 0] = 1−1/nλ
, λ > 0.
Examine whether the sequence {Xn, n ≥ 1} obeys the WLLN.
9.4.6 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
with P[Xn = n
α] = P[Xn = −n
α] = 1/2n
2 and P[Xn = 0] = 1 − 1/n2
,
where α < 3/2. Examine whether the sequence {Xn, n ≥ 1} obeys the
WLLN.
9.4.7 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
with P[Xn = n/ log n] = P[Xn = −n/ log n] = log n/2n and P[Xn =
0] = 1 − log n/n. Examine whether the sequence {Xn, n ≥ 1} obeys the
WLLN.
9.4.8 Suppose {Xn, n ≥ 1} is a sequence of independent and identically dis￾tributed random variables with the characteristic function
ϕ(t) = 
1 − |t|, if |t| ≤ 1
0, if |t| > 1.Computational Exercises 427
Show that Sn/n L
→ X, where X has Cauchy distribution with location
parameter 0 and scale parameter 1 and hence WLLN does not hold.
9.4.9 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
such that P[Xn =
√
n] = P[Xn = −
√
n] = 1/2. (i) Show that the char￾acteristic function ϕn(t) of Sn/n is Qn
k=1 cos 
t
√
k/n
and converges to
exp(−t
2/4) as n → ∞. (ii) Hence, show that Sn/n P↛ 0. (iii) Find a
sequence {an, n ≥ 1} and {bn, n ≥ 1} such that (Sn − an)/bn
P
→ 0 as
n → ∞.
9.4.10 Suppose {Xn, n ≥ 1} is a sequence of random variables such that
E(Xn) = 0, V ar(Xn) = σ
2 & Cov(Xn, Xm) = σ
2α
|m−n|
, |α| < 1.
Verify whether WLLN holds.
9.4.11 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables with V ar(X1) < ∞. Show that
(2/n(n + 1)) Pn
i=1
iXi
P
→ E(X1).
9.5 Computational Exercises
9.5.1 Repeat Example 9.2.4 for any two discrete and continuous distributions,
other than those in Example 9.2.4.
9.5.2 Repeat Example 9.2.5 when random samples, each of size n are simu￾lated from the Poisson P oi(1.2) distribution.
9.6 Multiple Choice Questions
Note: In each question, multiple options may be correct. Unless specified
otherwise, identify which of the statement(s) is/are correct. Answers are given
in Chapter 11, after the solutions of conceptual exercises of Chapter 9.
9.6.1 A sequence {Xn, n ≥ 1} of random variables is said to obey a SLLN, if
there exists two sequences {an, n ≥ 1} of real numbers and {bn, n ≥ 1}
of positive real numbers, with bn → ∞, such that n → ∞,
(a) (Sn − an)/bn
P
→ 0 where Sn =
Pn
i=1 Xi428 Laws of Large Numbers
(b) (Sn − an)/bn
a.s. → 0
(c) (Sn − an)/bn
L
→ 0
(d) (Sn − an)/bn
q.m. → 0
9.6.2 A sequence {Xn, n ≥ 1} of random variables is said to obey a WLLN, if
there exists two sequences {an, n ≥ 1} of real numbers and {bn, n ≥ 1}
of positive real numbers, with bn → ∞, such that n → ∞,
(a) (Sn − an)/bn
L
→ 0 where Sn =
Pn
i=1 Xi
(b) (Sn − an)/bn
a.s. → 0
(c) (Sn − an)/bn
P
→ 0
(d) (Sn − an)/bn
q.m. → 0
9.6.3 A sequence {Xn, n ≥ 1} of random variables satisfies a WLLN, if as
n → ∞
(a) (Sn − an)/bn
L
→ 0
(b) (Sn − an)/bn
a.s. → 0
(c) (Sn − an)/bn
P
→ 0
(d) (Sn − an)/bn
q.m. → 0
where Sn =
Pn
i=1 Xi
, {an, n ≥ 1} is a sequence of real numbers and
{bn, n ≥ 1} is a sequence of positive real numbers with bn → ∞ as
n → ∞.
9.6.4 Suppose {Xn, n ≥ 1} is a sequence of independent random variables.
Kolmogorov’s SLLN is applicable, if
(a) Xn ∼ Poisson(2)
(b) Xn ∼ Exp(0.1)
(c) Xn ∼ t1
(d) Xn ∼ Beta(1, 1)
9.6.5 Suppose {Xn, n ≥ 1} is a sequence of independent random variables.
Khintchine’s WLLN is not applicable if
(a) Xn ∼ Poisson(2)
(b) Xn ∼ Exp(0.1)
(c) Xn ∼ t1
(d) Xn ∼ Beta(1, 1)
9.6.6 Suppose {Xn, n ≥ 1} is a sequence of independent random variables.
Khintchine’s WLLN is applicable, if
(a) Xn ∼ Geometric(0.2)
(b) Xn ∼ χ
2
5
(c) Xn ∼ t1
(d) Xn ∼ Beta(1, 1)Multiple Choice Questions 429
9.6.7 Suppose {Xn, n ≥ 1} is a sequence of independent and identically dis￾tributed random variables with finite mean µ and Sn =
Pn
k=1 Xk. Fol￾lowing are two statements:
(I) Sn/n P
→ µ. (II) Sn/n a.s. → µ. Then
(a) Both (I) and (II) are false
(b) Both (I) and (II) are true
(c) (I) is true but (II) is false
(d) (I) is false but (II) is true
9.6.8 Suppose {X1, X2, · · · , Xn} are independent and identically distributed
random variables, each having the distribution function F(x), x ∈ R.
Suppose Fn(x) is the empirical distribution function. Then for each fixed
x ∈ R,
(a) Fn(x)
a.s. → F(x), uniformly in x
(b) Fn(x)
a.s. → F(x), for each fixed x
(c) Fn(x)
P
→ F(x), for each fixed x
(d) √
n(Fn(x) − F(x)) converges in law, for each fixed x
9.6.9 Glivenko-Cantelli theorem states that
(a) Fn(x)
a.s. → F(x), uniformly in x
(b) Fn(x)
a.s. → F(x), for each fixed x
(c) Fn(x)
P
→ F(x), for each fixed x
(d) √
n(Fn(x) − F(x)) converges in law, for each fixed x10
Central Limit Theorem
10.1 Introduction
The sample mean is the most frequently used statistic in statistical estimation
and in testing of hypotheses and its large sample behaviour is quite important
in these inference procedures. The WLLN and SLLN state that the distri￾bution of the sample mean piles up near the population mean, however, this
information is not enough to approximate the probability statements about
the sample mean. Using WLLN and SLLN, one can claim that the distribution
of the sample mean is degenerate at the population mean, but it is not useful
to obtain confidence intervals. With suitable normalization, its limiting non￾degenerate distribution is obtained in one of the most fundamental theorems
in statistics and it is the central limit theorem (CLT).
CLT is the most useful result in probability theory. It states that the
mean of a large number of random variables, no matter what their distribu￾tion is, with the only condition on the variance of the random variables, is
approximately normally distributed. Empirical findings in applied sciences,
dating back to the seventeenth century, showed that the averages of labora￾tory measurements on various physical quantities tend to have a bell shaped
distribution. The CLT provides a theoretical justification for this observation.
The importance of CLT is that it is one of the first theorems that allowed
respectability to probability theory, which was initially thought of as only
related to gambling and card playing.
CLT plays a central role in probability theory and in asymptotic infer￾ence and hence is named as the central limit theorem by Polya in 1920. A
remarkable feature of the result is that it is distribution-free, that is, there is
no assumption on the distribution of the random variables, it could be uni￾form or exponential or Poisson or chi-square. In the setup of independent and
identically distributed random variables, the only condition is finite positive
second moment. In view of this distribution-free feature, it is possible to derive
from it statistical inference procedures which are asymptotically valid without
specific distributional assumptions.
CLT is not a single theorem, but it embodies a variety of results concerned
with a sum of a large number of random variables which, suitably normalized,
has a limit distribution as a normal distribution. Lindeberg-Levy CLT is the
simplest version of CLT, a generalization of the De Moivre-Laplace theorem.
DOI: 10.1201/9781032619057-10 430Lindeberg-Levy CLT 431
The gain in generality from the De Moivre-Laplace to the Lindeberg-Levy CLT
is enormous. The De Moivre-Laplace theorem states that if Xn has binomial
B(n, p) distribution, then
√
n(Xn/n − p)
L
→ X ∼ N(0, p(1 − p)) distribution.
In Lindeberg-Levy CLT, starting from virtually no assumptions about the
distribution of random variables in the sum, apart from the finiteness of vari￾ance and variance being positive, we end up with normality. The condition
that the variance is positive excludes the case that the random variables have
degenerate distribution while finiteness of variance excludes the distributions
with infinite variance, such as Cauchy distribution. Lindeberg-Feller CLT and
Lyapounov’s CLT are further extensions of Lindeberg-Levy CLT, when the
random variables in the sum need not be identically distributed. Random sum
CLT is concerned with the setup when the number of summands is a discrete
integer valued random variable. Multivariate CLT deals with the sequence of
random vectors. CLT is also established in the setup of Markov dependence
and martingales.
The usefulness of the CLT is greatly increased by Slutsky’s theorem and
by the delta method which extends the limit result to smooth functions of
random variables having asymptotically normal distribution.
The next section deals with the simplest but the most heavily applied
version of CLT. It is the Lindeberg-Levy CLT, which is stated in Chapter 7.
10.2 Lindeberg-Levy CLT
The proof of Lindeberg-Levy CLT is based on Theorem 7.3.14, that is, the
continuity theorem for characteristic function and one more result proved
in Theorem 5.3.5, which states that a characteristic function of sum of n
independent and identically distributed random variables is the n-th power of
the common characteristic function of the summands. We give two proofs of
the theorem, one in Theorem 10.2.1, which is rather approximate and another
in Theorem 10.2.2, which is rigorous.
Theorem 10.2.1. Lindeberg-Levy CLT: Suppose {Xn, n ≥ 1} is a sequence
of independent and identically distributed random variables with mean µ and
positive, finite variance σ
2
. Suppose Sn =
Pn
i=1 Xi. Then
Yn = (Sn − nµ)/
√
nσ =
√
n(Xn − µ)/σ L
→ Z ∼ N(0, 1).
Proof. Suppose ϕn(t) and ϕ(t) denote the characteristic functions of Yn and
of X1 respectively for t ∈ R. Observe that,
ϕn(t) = E(exp(itYn)) = E
￾
exp it ￾
(Sn − nµ)/
√
nσ
= exp(−it√
nµ/σ)E(exp(itSn/
√
nσ)) = exp(−it√
nµ/σ)ϕSn
(t/√
nσ)
= exp(−it√
nµ/σ)(ϕ(t/√
nσ))n432 Central Limit Theorem
Now taking logarithm of both sides, using series expansion of e
x and log(1+x),
which is valid for complex x as well, we get,
log ϕn(t) = −it√
nµ/σ + n log(ϕ(t/√
nσ))
= −it√
nµ/σ + n log(E(exp(itX/√
nσ)))
= −it√
nµ/σ + n log 
E

1 +
itX
√
nσ
−
t
2X2
2nσ2
+ · · · 
= −it√
nµ/σ + n log 
1 +
itµ
√
nσ
−
t
2E(X2
)
2nσ2
+ · · · 
Suppose un = itµ/√
nσ − t
2E(X2
)/2nσ2 + · · · . Then log(1 + un) = un −
u
2
n/2 + u
3
n/3 − · · · . Substituting for un and simplifying we get,
log ϕn(t) = −it√
nµ/σ + it√
nµ/σ − t
2E(X2
)/2σ
2 + t
2µ
2
/2σ
2 + δn
= −(t
2
/2σ
2
)(E(X2
) − µ
2
) + δn = −t
2
/2 + δn,
where δn consists of all terms which tend to 0 as n tends to ∞. Thus, ϕn(t) →
exp(−t
2/2) as n → ∞. Observe that exp(−t
2/2) is continuous at t = 0 and it
is the characteristic function of Z ∼ N(0, 1). Hence, by Theorem 7.3.14 and
the uniqueness theorem for characteristic function, Yn
L
→ Z ∼ N(0, 1).
In the above proof, the term δn consists of moments of order larger than
two. We do not have any assumption about these higher order moments. To
avoid these issues, we give below another more rigorous and elegant proof of
the same theorem. Similar approach is adopted in the Lindeberg-Feller CLT in
the next section, when random variables in the sequence are independent but
not identically distributed. The proof is based on Lemma 9.2.2, which states
that if u1, u2, ..., um and w1, w2, ..., wm are complex numbers with |ui
| ≤ 1
and |wi
| ≤ 1, i = 1, 2, · · · , m. Then,



Ym
i=1
ui −
Ym
i=1
wi


 ≤
Xm
i=1
|ui − wi
|.
We also need Theorem 9.2.4, which states that if E(|X|
k
) < ∞ and if ϕ is a
characteristic function of X, then ∀ t ∈ R,


ϕ(t) −
X
k
j=0
(it)
jE(Xj
)/j!


 ≤ E

min n
2|tX|
k
/k!, |tX|
k+1/(k + 1)!o.
Thus with k = 2,


ϕ(t) − 1 − itE(X) + t
2E(X2
)/2


 ≤ E

min n
|tX|
2
, |tX|
3
/6
o.Lindeberg-Levy CLT 433
Theorem 10.2.2. Lindeberg-Levy CLT: Suppose {Xn, n ≥ 1} is a sequence
of independent and identically distributed random variables with mean µ and
positive, finite variance σ
2
. Suppose Sn =
Pn
i=1 Xi. Then
Yn = (Sn − nµ)/
√
nσ =
√
n(Xn − µ)/σ L
→ Z ∼ N(0, 1).
Proof. Without loss of generality, we assume that µ = 0 and σ = 1. Otherwise,
we define Wn = (Xn −µ)/σ and work with the sequence {Wn, n ≥ 1} which is
a sequence of independent and identically distributed random variables with
mean 0 and variance 1. Suppose ϕ(·) is the common characteristic function of
Xn’s, then by Theorem 5.3.5, the characteristic function of Sn/
√
n is given by
ϕ
n(t/√
n). It is known that ϕZ(t) = exp(−t
2/2) is the characteristic function
of Z ∼ N(0, 1) distribution, which can be expressed as
ϕZ(t) = e
−t
2/2 =
n
e
−t
2/2n
on
= ϕ
n
Z(t/√
n).
Now observe that,

ϕSn/
√
n(t) − ϕZ(t)

 =


ϕ
n
(t/√
n) − e
−t
2/2


 =

ϕ
n
(t/√
n) − ϕ
n
Z(t/√
n)


=





Yn
k=1
ϕ(t/√
n) −
Yn
k=1
ϕZ(t/√
n)





≤
Xn
k=1
|ϕ(t/√
n) − ϕZ(t/√
n)| by Lemma 9.2.2
= n × |ϕ(t/√
n) − ϕZ(t/√
n)|
= n × |ϕ(t/√
n) − (1 − t
2
/2n) + (1 − t
2
/2n) − ϕZ(t/√
n)|
≤ n × |ϕ(t/√
n) − (1 − t
2
/2n)|
+ n × |ϕZ(t/√
n) − (1 − t
2
/2n)|. (10.1)
Since E(X2
1
) & E(Z
2
) < ∞, with k = 2 in Theorem 9.2.4 we have,
|ϕ(t) − (1 − t
2
/2)| ≤ E
￾
min 
|tX1|
2
, |tX1|
3
/6
	
& |ϕZ(t) − (1 − t
2
/2)| ≤ E
￾
min 
|tZ|
2
, |tZ|
3
/6
	 .
Consequently,
|ϕ(t/√
n) − (1 − t
2
/2n)| ≤ E

min n
|tX1|
2
/n, |tX1|
3
/6n
3/2
o
& |ϕZ(t/√
n) − (1 − t
2
/2n)| ≤ E

min n
|tZ|
2
/n, |tZ|
3
/6n
3/2
o .
With these substitutions, inequality in (10.1) reduces as follows.

ϕSn/
√
n(t) − ϕZ(t)

 ≤ n × E

min n
|tX1|
2
/n, |tX1|
3
/6n
3/2
o
+ n × E

min n
|tZ|
2
/n, |tZ|
3
/6n
3/2
o
= E(Un) + E(Vn), (10.434 Central Limit Theorem
where Un = min 
|tX1|
2
, |tX1|
3/6n
1/2
	
and Vn = min 
|tZ|
2
, |tZ|
3/6n
1/2
	
.
It is to be noted that
∀ n ≥ 1, Un ≤ |tX1|
2 & E(X2
1
) < ∞, Vn ≤ |tZ|
2 & E(Z
2
) < ∞.
Thus, both Un and Vn are dominated by integrable random variables. Further,
for large n, Un = |tX1|
3/6n
1/2 and Vn = |tZ|
3/6n
1/2
. Note that X1 and Z are
bounded in probability, being real random variables and hence n → ∞
Un = |tX1|
3
/6n
1/2 P
→ 0 & Vn = |tZ|
3
/6n
1/2 P
→ 0
⇒ E(Un) → 0 & E(Vn) → 0,
using the Lebesgue dominated probability convergence theorem. Taking limits
as n → ∞ on both sides of the inequality in (10.2) we get,
limn→∞

ϕSn/
√
n(t) − ϕZ(t)

 = 0 ⇒ limn→∞
ϕSn/
√
n(t) = ϕZ(t) = e
−t
2/2
.
Thus, the sequence {ϕSn/
√
n(t), n ≥ 1} of characteristic functions of Sn/
√
n
converges to exp(−t
2/2), which is continuous at zero. Hence by the continu￾ity theorem for characteristic functions, the corresponding sequence of dis￾tribution functions converges in law to a distribution function with charac￾teristic function exp(−t
2/2). But exp(−t
2/2) is the characteristic function of
Z ∼ N(0, 1) and hence by the uniqueness theorem of characteristic functions
Sn/
√
n
L
→ Z ∼ N(0, 1).
Remark 10.2.1. When {Xn, n ≥ 1} is a sequence of independent and identi￾cally distributed random variables, each having Bernoulli B(1, p) distribution,
then the Lindeberg-Levy theorem reduces to Demoivre-Lapalce CLT.
For all standard discrete and continuous distributions with mean µ and
positive and finite variance σ
2
, we can claim that the large sample distribution
of the sample mean is normal, using the Lindeberg-Levy CLT. If the distribu￾tion function of √
n(Xn −µ)/σ is denoted by Fn(x), then the CLT states that
Fn(x) → Φ(x) as n → ∞. However, it provides no indication of the speed of
the convergence of Fn(x) to Φ(x) and hence of the error to be expected when
approximating Fn(x) by Φ(x). Thus, although the CLT gives a useful general
approximation, there is no way of knowing how good the approximation is.
In fact, goodness of the approximation is a function of the original distribu￾tion and so must be checked case by case. In Example 10.2.1 and in Example
10.2.2, we illustrate how the approximation can be judged by simulation.
The approximation we discussed above is the first order approximation.
Such approximations are somewhat crude and can be improved. However, the
resulting second or higher order approximations are more complicated and re￾quire more knowledge of the underlying distribution. The CLT is strengthened
in two directions: (i) The Berry-Essen theorem provides a bound for the error
of the normal approximation and (ii) a better approximation can be obtainedLindeberg-Levy CLT 435
through the first terms of Edgeworth expansion. We will not elaborate on
these issues but state below two results related to these. The following result
gives the bound for the error.
Theorem 10.2.3. Berry-Esseen theorem: Suppose {Xn, n ≥ 1} is a sequence
of independent and identically distributed random variables with mean µ, vari￾ance σ
2 and finite third moment, then there exists a constant C, independent
of common distribution F of Xn, such that for all x,
|Fn(x) − Φ(x)| ≤ (C/√
n)(E|X1 − µ|
3
/σ3
).
The important feature of the theorem is that the constant C is independent
of F. Further, the bound given by the theorem is not a limit statement but is
an exact statement valid for any F, n and x. The Edgeworth expansion stated
below conveys that the order of the error bound in Berry-Esseen theorem is
1/
√
n
Theorem 10.2.4. Suppose {Xn, n ≥ 1} is a sequence of independent and
identically distributed random variables with mean µ, variance σ
2 and finite
third central moment µ3, then,
Fn(x) = Φ(x) + µ3(1 − x
2
)ϕ(x)/(6σ
3√
n) + o(1/
√
n).
The second term on the right hand side of the above identity is known as
the first Edgeworth correction.
We have noted that it is difficult to assess the approximations theoretically,
since the accuracy of these approximations is not distribution-free, it very
much depends both on the underlying distribution as well as on the values
of parameters. We now proceed to discuss in the following examples, how the
approximations can be judged by simulation using R.
The following example is concerned with three distributions, exponential,
geometric and Poisson, which are skew distributions. Using R, we verify the
CLT for these distributions and compare the approximations.
Example 10.2.1. Suppose X follows either exponential or geometric or Pois￾son distribution with mean µ and variance σ
2
. Suppose {X1, X2, · · · , Xn} is
a random sample from the distribution of X. By the CLT,
Yn =
√
n(Xn − µ)/σ L
→ Z ∼ N(0, 1). We fix the parameters of these distri￾butions so that µ = 1.4 is the same for all. Thus, for exponential distribution
µ = σ = 1.4, for Poisson distribution µ = σ
2 = 1.4 and for geometric distribu￾tion success probability p = 1/(1 + µ) = 0.41667 and σ
2 = µ(1 + µ) = 0.5833.
We examine the values of n for which normality of Yn is acceptable based on
300 simulations, using the following code.
Code 10.2.1. s=c(30,60,90,120); mu=1.4; nsim=300; p1=p2=p3=c()
y=z=t=matrix(nrow=nsim,ncol=length(s))
for(j in 1:length(s))436 Central Limit Theorem
{
n=s[j]
for(i in 1:nsim)
{
set.seed(i)
x=rexp(n,rate=1/mu)
y[i,j]= n^(.5)*(mean(x)-mu)/mu
set.seed(i)
w=rpois(n,mu)
z[i,j]= n^(.5)*(mean(w)-mu)/(mu^(.5))
set.seed(i)
v=rgeom(n,1/(1+mu))
t[i,j]= n^(.5)*(mean(v)-mu)/((mu*(1+mu))^(.5))
}
p1[j]=shapiro.test(y[,j])$p.value
p2[j]=shapiro.test(z[,j])$p.value
p3[j]=shapiro.test(t[,j])$p.value
}
d=round(data.frame(s,p1,p2,p3),4); d
r=seq(-4,4,.03); u=dnorm(r)
par(mfrow= c(3,1))
hist(y[,3],freq=FALSE,main="Exponential Distribution",
col="light blue",xlim=c(-4,4),xlab="")
lines(r,u,"o",pch=20,col="dark blue")
hist(z[,3],freq=FALSE,main="Poisson Distribution",
col="light blue",ylim=range(0,.4),xlim=c(-4,4),xlab="")
lines(r,u,"o",pch=20,col="dark blue")
hist(t[,3],freq=FALSE,main="Geometric Distribution",
col="light blue",ylim=range(0,.4),xlim=c(-4,4),xlab="")
lines(r,u,"o",pch=20,col="dark blue")
The p-values of Shapiro-Wilk test are reported in Table 10.1.
TABLE 10.1
p-values: Exponential, Poisson and Geo￾metric Distributions
n Exponential Poisson Geometric
30 0.0049 0.0453 0.0011
60 0.4664 0.0106 0.0007
90 0.2870 0.0895 0.0217
120 0.2122 0.2324 0.9326Lindeberg-Levy CLT 437
FIGURE 10.1
CLT: Exponential, Poisson and Geometric Distributions
From these p-values, we note that the values of n for which normality of
Yn is acceptable are different for three distributions. For exponential distri￾bution for n = 60 normality of Yn is acceptable, while for Poisson, it is 90
and for geometric, it is 120. These values are corresponding to fixed value of
µ and fixed number of simulations. These may change as µ and number of
simulations change.
Figure 10.1 displays the histogram of Yn values with the curve of the
standard normal distribution imposed on it for n = 90. For exponential and
Poisson distribution the curve of the standard normal distribution closely ap￾proximates the histogram, but not for the geometric distribution. These results
are consistent with the p-values reported in Table 10.1. □
The next example is concerned with a binomial distribution B(m, p) with
mean µ = mp and variance σ
2 = mp(1 − p) < ∞ . When p = 1/2 it is a sym￾metric distribution. We simulate random samples from a binomial distribution
B(m, p) distribution for two different values of p and examine the limit law
of the sample mean and whether it depends on the values of p. In Example
10.2.1, we have noted that normal approximation depends on the underlying
distribution. In the next example, we note that for the same distribution, it
may depend on the values of the parameters.
Example 10.2.2. Suppose X ∼ B(m, p) and {X1, X2, · · · , Xn} is a random
sample from the distribution of X. Then as n → ∞ by the CLT,438 Central Limit Theorem
Yn =
√
n(Xn − mp)/
p
mp(1 − p)
L
→ Z ∼ N(0, 1) distribution. We consider
m = 10, two values of p as 0.5 and 0.1 and examine the values of n where
normality of Yn is acceptable based on 1000 simulations, using the following
code.
Code 10.2.2. nsim=1000; m=10; s=c(20,50,100) # sample sizes
p1=p2=c(); y=z=matrix(nrow=nsim,ncol=length(s))
for(j in 1:length(s))
{
n=s[j]
for(i in 1:nsim)
{
set.seed(i)
x=rbinom(n,size=m,prob=.5)
y[i,j]=n^(.5)*(mean(x)-m*.5)/((m*.5*(1-.5))^(.5))
set.seed(i)
w=rbinom(n,size=m, prob=.1)
z[i,j]=n^(.5)*(mean(w)-m*.1)/((m*.1*(1-.1))^(.5))
}
p1[j]=shapiro.test(y[,j])$p.value
p2[j]=shapiro.test(z[,j])$p.value
}
d=round(data.frame(s,p1,p2),4); d
set.seed(2); u=rnorm(nsim)
par(mfrow=c(2,1))
plot(density(y[,1]),main="B(10,0.5)",lwd=2)
lines(density(y[,2]),col=2,lty=2,lwd=2)
lines(density(y[,3]),col=3,lty=3,lwd=2)
lines(density(u),col=4,lty=4,lwd=2)
abline(v=0)
legend("topright",legend=c("n=20","n=50","n=100","N(0,1)"),
col=1:4,lty=1:4)
plot(density(z[,1]),main="B(10,0.1)",ylim=range(0,.42),lwd=2)
lines(density(z[,2]),col=2,lty=2,lwd=2)
lines(density(z[,3]),col=3,lty=3,lwd=2)
lines(density(u),col=4,lty=4,lwd=2)
abline(v=0)
legend("topright",legend=c("n=20","n=50","n=100","N(0,1)"),
col=1:4,lty=1:4)Lindeberg-Levy CLT 439
TABLE 10.2
p-values: CLT for Binomial
Distribution
n B(10, 0.5) B(10, 0.1)
20 0.0349 0.0000
50 0.2449 0.0009
100 0.2288 0.0148
The p-values of the Shapiro-Wilk test are presented in Table 10.2.
From Table 10.2, we observe that when p = 1/2, that is, when the binomial
distribution is symmetric, based on p-values of Shapiro-wilk test, normality of
Yn is acceptable even for n = 50. On the other hand, normality of Yn is not
acceptable even for n = 100 when p = 0.1 and when the distribution is skew.
Figure 10.2 presents the same scenario. When p = 0.5, curves of Yn for
n = 50, 80 and curve of the probability density function of the standard nor￾mal distribution are in close agreement as compared to that for p = 0.1, as
expected in view of symmetry for p = 0.5. This example thus illustrates that
the approximation by the CLT depends not only on the distribution but also
on the parameters of the distribution. □
The applicability of the CLT is greatly extended by combining it with
Slutsky’s theorem, in large sample inference to construct confidence intervals
and to decide the asymptotic null distribution of a test statistic. It is illus￾trated in Example 7.3.17, in Example 7.3.19 in Chapter 7 and in the following
example. In this example we show that the sample variance and the unbiased
estimator of the population variance, both converge in probability to popu￾lation variance and with suitable scaling their large sample distributions are
normal. Many results such as, (i) if Xn
P
→ X or Xn
L
→ X, then {Xn, n ≥ 1}
is bounded in probability, (ii) Slutsky’s theorem and (iii) CLT, are illustrated
in this example.
Example 10.2.3. Suppose {X1, X2, · · · , Xn} are independent and identically
distributed random variables with mean 0, variance σ
2 and finite fourth order
moment. We show that the asymptotic distribution of the sample variance
S
2
n =
Pn
i=1 X2
i
/n − X
2
n
, with suitable normalization, is normal. Observe that
by WLLN,
Xn =
1
n
Xn
i=1
Xi
P
→ E(X1) = 0 & 1
n
Xn
i=1
X2
i
P
→ E(X2
1
) = σ
2 ⇒ S
2
n
P
→ σ
2
Further,
√
n(S
2
n−σ
2
) = √
n
 1
n
Xn
i=1
X2
i −X
2
n−σ
2

=
1
√
n
Xn
i=1
X2
i −nσ2

−(
√
nXn)Xn.440 Central Limit Theorem
FIGURE 10.2
Verification of CLT for Binomial Distribution
It is to be noted that by the CLT, √
nXn
L
→ Z1 ∼ N(0, σ2
) and hence
√
nXn is bounded in probability. Further, Xn
P
→ 0. Hence (
√
nXn)Xn
P
→ 0.
Now, {X1, X2, · · · , Xn} are independent and identically distributed random
variables implies that {X2
1
, X2
2
, · · · , X2
n} are also independent and identi￾cally distributed random variables with mean σ
2 and variance V = E(X4
1
) −
(E(X2
1
))2 < ∞. Hence, by the CLT (
Pn
i=1 X2
i − nσ2
)/
√
n
L
→ Z2 ∼ N(0, V ).
Thus by Slutsky’s theorem,
√
n(S
2
n − σ
2
) = 1
√
n
Xn
i=1
X2
i − nσ2

− (
√
nXn)Xn
L
→ Z2 ∼ N(0, V ).
The unbiased estimator of σ
2
is given by
Tn =
1
n − 1
Xn
i=1
(Xi − Xn)
2 =
n
n − 1
S
2
n = anS
2
n
, where an =
n
n − 1
→ 1.Lindeberg-Levy CLT 441
Further, S
2
n
P
→ σ
2
, hence Tn
P
→ σ
2
. To find the asymptotic distribution of
Tn consider,
√
n(Tn − σ
2
) −
√
n(S
2
n − σ
2
) = √
n(anS
2
n − σ
2
) −
√
n(S
2
n − σ
2
)
=
√
nS2
n
(an − 1) =
√
n
n − 1
S
2
n
P
→ 0,
as S
2
n
P
→ σ
2 and hence is bounded in probability. But √
n(S
2
n −σ
2
)
L
→ Z2 ∼
N(0, V ) and hence √
n(Tn − σ
2
)
L
→ Z2 ∼ N(0, V ). These results remain valid
even if E(X) ̸= 0, since
S
2
n =
1
n
Xn
i=1
(Xi−Xn)
2 =
1
n
Xn
i=1
((Xi−E(X)−(Xn−E(X)))2 =
1
n
Xn
i=1
(Yi−Y n)
2
,
where Yi = Xi − E(X), i = 1, 2, · · · , n and E(Yi) = 0, i = 1, 2, · · · , n. We
then proceed exactly on similar lines as above to find the limiting distribution
of S
2
n and of Tn. □
Remark 10.2.2. In the setup of large sample inference, the results of Ex￾ample 10.2.3 are interpreted as follows. If X is a random variable with vari￾ance σ
2 and finite fourth order moment, then based on a random sample
{X1, X2, · · · , Xn} from the distribution of X, both S
2
n and Tn are consis￾tent and asymptotically normal estimators of σ
2 with approximate variance
(E(X4
) − (E(X2
))2
)/n.
Example 10.2.4. Suppose {X1, X2, · · · , Xn} are independent and identically
distributed random variables with mean µ and variance σ
2
. On the basis of
these n observations, suppose we wish to test a null hypothesis H0 : µ = µ0
against the alternative H1 : µ ̸= µ0, when σ
2
is unknown. Suppose a test
statistic Tn is proposed as,
Tn =
Xn − µ0
s.e.of Xn
=
Xn − µ0
Sn/
√
n
, where S
2
n =
Xn
i=1
(Xi − Xn)
2
/n
and s.e.of Xn is the standard error of Xn. To obtain the p-value, we need to
know the null distribution of test statistic Tn. As a particular case, suppose
Xi ∼ N(µ, σ2
) distribution. Then under H0, Xn has normal N(µ0, σ2/n)
distribution, nS2
n/σ2 has chi-square distribution with n−1 degrees of freedom
and Xn and S
2
n are independent. Suppose the test statistic Tn is expressed as
Tn =
Xn − µ0
Sn/
√
n
=
Un
Vn
where Un =
√
n(Xn − µ0)
σ
& Vn =
vuuut
Pn
i=1
(Xi − Xn)
2
σ
2(n − 1)
n − 1
n
.442 Central Limit Theorem
Now, Un ∼ N(0, 1) & Xn
i=1
(Xi − Xn)
2
/σ2 ∼ χ
2
n−1 ⇒
r n
n − 1
Tn ∼ tn−1
distribution for each finite n. If the common distribution of Xi
’s is not normal,
then it is in general difficult to obtain the null distribution of Tn for finite n.
However, using CLT and Slutsky’s theorem we can obtain its asymptotic null
distribution, assuming 0 < σ2 < ∞. Observe that,
Un =
√
n(Xn − µ0)
σ
L
→ Z ∼ N(0, 1),
Pn
i=1
(Xi − Xn)
2
σ
2(n − 1)
P
→ 1
(n − 1)/n → 1 ⇒ Vn
P
→ 1 ⇒ Tn = Un/Vn
L
→ Z ∼ N(0, 1),
by Slutsky’s theorem. Thus, the asymptotic null distribution of Tn is N(0, 1).
□
Example 10.2.5. This example illustrates how Lindeberg-Levy CLT is use￾ful to evaluate limn→∞ P[nλ]
i=0
e
−nλ(nλ)
i
i!
. It is clear that the summands are the
probabilities P[X = i], i = 0, 1, · · · , [nλ] where X ∼ P(nλ) distribution. Sup￾pose {Xn, n ≥ 1} is a sequence of independent and identically distributed
random variables each having Poisson P(λ) distribution. Then X
d=
Pn
i=1 Xi
.
Since V ar(Xn) = λ is positive and finite, by Lindeberg-Levy CLT
Yn =
Xn
i=1
(Xi − λ)/
√
nλ L
→ Z ∼ N(0, 1)
⇒ limn→∞
X
[nλ]
i=0
e
−nλ(nλ)
i
i!
= limn→∞
P[X ≤ nλ] = limn→∞
P
"Xn
i=1
Xi ≤ nλ#
= limn→∞
P
"Xn
i=1
(Xi − λ)/
√
nλ ≤ 0
#
= limn→∞
FYn
(0) = P[Z ≤ 0] = Φ(0) = 1/2 . □
Example 10.2.6. Similar to Example 10.2.5, this example illustrates how to
evaluate
limn→∞ Z n+t
√
2n
0
(1/2)n/2
Γ(n/2) x
n/2−1
e
−x/2
dx
using Lindeberg-Levy CLT. From the integrand, we note that it is a probability
density function of G(1/2, n/2) distribution which is the same as the chi￾square distribution with n degrees of freedom. Thus, we have to find the limit
as n → ∞ of P[Yn ≤ n + t
√
2n] where Yn ∼ χ
2
n
. Note that Yn
d=
Pn
i=1 Xi
,
where {X1, X2, · · · , Xn} are independent and identically distributed random
variables each having χ
2
1 distribution, with mean 1 and positive finite varianceLindeberg-Levy CLT 443
2. Thus by Lindeberg-Levy CLT,
Un =
Xn
i=1
Xi − n

/
√
2n = (Yn − n)/
√
2n
L
→ Z
⇒ limn→∞
P[Y ≤ n + t
√
2n] = limn→∞
P
h
(Yn − n)/
√
2n ≤ t
i
= limn→∞
FUn
(t) = P[Z ≤ t] = 1
√
2π
Zt
−∞
e
−u
2/2
du,
where Z ∼ N(0, 1). In particular when t = 0,
limn→∞ Z n
0
(1/2)n/2
Γ(n/2) x
n/2−1
e
−x/2
dx = 1/2. □
Example 10.2.7. Suppose {Xn, n ≥ 1} is a sequence of independent and
identically distributed random variables with mean µ and positive, finite vari￾ance σ
2
. By Lindeberg-Levy CLT,
Yn = (Pn
i=1 Xi − nµ)/
√
nσ
L
→ Z ∼ N(0, 1). Hence, ∀ x ∈ R
limn→∞
P[Yn ≤ x] = P[Z ≤ x]
⇒ limn→∞
P[Yn ≤ 0] = P[Z ≤ 0] = 1/2, with x = 0
⇒ limn→∞
P[Xn ≤ µ] = 1/2 ⇐⇒ limn→∞
P[Xn > µ] = 1/2.
Thus, in the long run, the probability that sample mean is larger than the
population mean is 1/2. It is to be noted that for large n, distribution Xn is
approximated by the normal distribution N(µ, σ2
) and µ is the median of the
limiting distribution and hence the result seems reasonable. □
In the following example, we verify the result of Example 10.2.7 by simu￾lation for three distributions.
Example 10.2.8. We consider three distributions with the same mean µ = 2,
exponential, Poisson and geometric with support as a set of whole numbers.
We generate 1000 samples of size n and find the proportion of times in 1000
samples Xn ≤ µ. As n goes on increasing, we examine whether the proportion
approaches 1/2. Following is the code for these computations.
Code 10.2.3. mu=2; nsim=1000; N=seq(50,250,50);
me=mp=mg=pe=pp=pg=c()
for(j in 1:length(N))
{
n = N[j]
for(m in 1:nsim)
{444 Central Limit Theorem
set.seed(m)
x=rexp(n,rate=1/mu)
y=rpois(n,mu)
z=rgeom(n,1/(1+mu))
me[m]=mean(x)
mp[m]=mean(y)
mg[m]=mean(z)
}
pe[j]=length(which(me<=mu))/nsim
pp[j]=length(which(mp<=mu))/nsim
pg[j]=length(which(mg<=mu))/nsim
}
d=round(data.frame(N,pe,pp,pg),4); d
The output is organized in Table 10.3.
From Table 10.3, we note that as n increases, P[Xn ≤ µ] is close to 1/2
for the three distributions. □
Example 10.2.9. Suppose {Xn, n ≥ 1} is a sequence of independent and
identically distributed random variables with mean finite µ and as in Example
10.2.7, we wish to find limn→∞ P[Xn ≤ µ]. It is to be noted that nothing is
specified about variance, so as in Example 10.2.7 we cannot use Lindeberg￾Levy CLT to find the limit. Since it is given that mean is finite, we can use
Khintchine’s WLLN and conclude that Xn
P
→ µ. Convergence in probability
implies convergence in law, hence Xn
L
→ µ. Thus, ∀ x ∈ R
P[Xn ≤ x] →

0, if x < µ
1, if x > µ,
(10.3)
µ being the only point of discontinuity of a distribution function of a random
variable which is degenerate at µ. However, we cannot find limn→∞
P[Xn ≤ µ]
on the basis of given information. □
TABLE 10.3
P[Xn ≤ µ] → 1/2: Exponential, Poisson
and Geometric Distributions
n Exponential Poisson Geometric
50 0.508 0.529 0.534
100 0.494 0.525 0.520
150 0.486 0.508 0.506
200 0.503 0.532 0.515
250 0.505 0.509 0.512Lindeberg-Levy CLT 445
Example 10.2.10. In this example we consider a distribution whose mean is
finite but variance is not finite. Suppose X is a random variable with probabil￾ity density function given by f(x, θ) = 2θ
2/x3
, x ≥ θ. Then E(X) = 2θ and
the integral corresponding to E(X2
) is divergent hence variance is infinite. As
discussed in Example 10.2.9, we cannot use the CLT to find limn→∞
P[Xn ≤ µ].
Hence, we find it by simulation using R. We generate m random samples from
this distribution, each of size n for n = 500 to n = 7500 with an increment
of 1000. We then find the proportion of times Xn ≤ x in m samples for
x < µ, x = µ and x > µ. To generate a random sample from the given distri￾bution we use probability integral transformation. The distribution function
of X for x ≥ θ is given by, F(x, θ) = 1 − (θ/x)
2
. We use the following code to
generate the samples and find the proportions.
Code 10.2.4. th=1.5; N=seq(500,7500,1000); nsim=500
mean=p1=p2=p3=c()
for(j in 1:length(N))
{
for(m in 1:nsim)
{
set.seed(m)
u=runif(N[j],0,1)
x=th/((1-u)^(1/2))
mean[m]=mean(x)
}
p1[j]=length(which(mean<=2*th-1))/nsim
p2[j]=length(which(mean<=2*th))/nsim
p3[j]=length(which(mean<=2*th+1))/nsim
}
d=round(data.frame(N,p1,p2,p3),4);d
The output is organized in Table 10.4. From Table 10.4, we note that
P[Xn ≤ x] → 0 if x < µ, P[Xn ≤ x] → 1 if x > µ, as shown in Equation
10.3. Further, P[Xn ≤ µ] approaches 0.5, it is 0.548 for sample size n = 7500.
We may require still large n for it to be close to 0.5, the reason may be the
infinite variance of X. □
In Lindeberg-Levy theorem, n is deterministic. The CLT continues to hold
even if n is random with some additional condition. It is known as a random
sum CLT. We state it below. For proof we refer to Billingsley [5] or page 346
of Gut [13].
Theorem 10.2.5. Random sum CLT: Suppose {Xn, n ≥ 1} is a sequence
of independent and identically distributed random variables with mean 0 and446 Central Limit Theorem
TABLE 10.4
P[Xn ≤ x] : x < µ, x = µ, x > µ
n P[Xn ≤ 2θ − 1] P[Xn ≤ 2θ] P[Xn ≤ 2θ + 1]
500 0 0.628 0.994
1500 0 0.596 1.000
2500 0 0.552 1.000
3500 0 0.544 1.000
4500 0 0.570 1.000
5500 0 0.556 1.000
6500 0 0.558 1.000
7500 0 0.548 1.000
variance 1. Suppose {N(t), t ≥ 0} is a family of positive integer valued random
variables where N(t)
a.s. → ∞ such that N(t)/t P
→ c, where c ∈ (0, ∞) is a
constant. Then as t → ∞,
YN(t) =
N
X
(t)
i=1
Xi/
p
N(t)
L
→ Z ∼ N(0, 1).
Random sum CLT has applications in a variety of fields, such as in risk
theory in general insurance, in a compound Poison process, in a renewal pro￾cess and in branching processes. Following example illustrates an application
of random sum CLT in a compound Poison process. If {N(t), t ≥ 0} is a Pois￾son process, with rate λ, then for each fixed t, N(t) ∼ P(λt) distribution. It
can be shown that N(t)/t P
→ λ. If {Xn, n ≥ 1} is a sequence of independent
and identically distributed random variables with mean µ and variance σ
2
,
then by random sum CLT,
YN(t) =
N
P
(t)
i=1
(Xi − µ)/σ
p
N(t)
=
(X(t) − E(X(t))
p
V ar(X(t))
L
→ Z ∼ N(0, 1),
where X(t) = PN(t)
i=1 Xi
. Following example illustrates the application of the
random sum CLT, (Sivaprasad and Deshmukh [22]).
Example 10.2.11. Customers arrive at the ATM according to a Poisson
process with rate 15 per hour. The amount of money withdrawn on each
transaction is a random variable with mean Rs 5000 and standard deviation
1000. The machine is in use for 24 hours. The total daily withdrawal is then
modelled as a compound Poisson process as X(t) = PN(t)
i=1 Xi
, where Xi
denotes the amount withdrawn by the i-th individual. Thus, expected total
daily withdrawal and its variance are given by,
E(X(24)) = 15 × 24 × 5000 = 1800000
and V ar(X(24)) = 15 × 24 × (10002 + 50002
) = (9.36) × 109
.Lindeberg-Levy CLT 447
The standard deviation of X(24) is 96747.09. By the random sum CLT, distri￾bution of X(24) can be approximated by the normal distribution with mean
18 × 105 and standard deviation 96747.09. We can then compute the ap￾proximate probability that the total daily withdrawal is less than 1900000 as
follows.
P[X(24)) ≤ 1900000] = P

Z ≤ (1900000 − 18 × 105
)/96747.09
= P[Z ≤ 1.033623] = 0.8493.
Using similar arguments we get that
P[X(24)) ≤ 2000000] = 0.9806 & P[X(24)) ≤ 2100000] = 0.99904.
Such an analysis is helpful for the management to decide on how much cash
to be deposited daily at the ATM. □
Lindeberg-Levy CLT is extended to k dimensional random vectors, using
Cramer-Wold device as stated below. Suppose Xn
and X are k dimensional
random vectors. Then Cramer-Wold device states that
Xn
L
→ X if and only if L
′Xn
L
→ L
′X ∀ L ∈ R
k
, L ̸= 0 .
Cramer-Wold device allows higher-dimensional problems to reduce to the one￾dimensional case.
Theorem 10.2.6. Multivariate CLT: Suppose X is a k dimensional ran￾dom vector with mean vector E(X) = µ and dispersion matrix Σ, which is
positive definite. Suppose {X1
, X2
, · · · , Xn
} are independent and identically
distributed random vectors each distributed as X. Suppose Xn denotes the
sample mean vector, then as n → ∞
√
n(Xn − µ)
L
→ U ∼ Nk(0, Σ) distribution.
Proof. Suppose a random variable Yi
is defined as Yi = L
′Xi
, i = 1, 2, · · · , n,
where L ̸= 0 is a k dimensional vector of real numbers. Then {Y1, Y2, · · · , Yn}
are independent and identically distributed random variables with common
mean θ = L
′µ and variance σ
2 = L
′ΣL. Since Σ is positive definite and L ̸= 0,
σ
2
is positive. We assume it to be finite. Then by the Lindeberg-Levy CLT,
√
n(Y n −θ)
L
→ Z1 ∼ N(0, σ2
) ⇐⇒ L
′
(
√
n(Xn −µ)) L
→ Z1 ∼ N(0, L′ΣL)
Hence, by Cramer-Wold device √
n(Xn − µ)) L
→ U ∼ Nk(0, Σ) distribution.
Multivariate CLT is heavily used in multivariate analysis and asymptotic
inference when the distribution of a random variable is indexed by a vector
parameter. We illustrate below one application of multivariate CLT in the
asymptotic inference setup, for more illustrations in the asymptotic inference
setup refer to (Deshmukh and Kulkarni [11]). Suppose X is a random vari￾able or a random vector defined on a probability space (Ω, A, P) where the448 Central Limit Theorem
probability measure P is indexed by a vector parameter θ ∈ Θ ⊂ R
k
. Suppose
θ = (θ1, θ2, · · · , θk)
′
. Given a random sample {X1, X2, · · · , Xn} of size n from
the distribution of X, suppose T n = (T1n, T2n, · · · , Tkn)
′
is an estimator of θ.
If it is in the form of an average, then Multivariate CLT is useful to verify
whether the asymptotic distribution of T n
, with suitable centering and scaling
is normal. In the following example, it is shown that the large sample distri￾bution of a vector of the first k sample raw moments, with suitable centering
and scaling is multivariate normal.
Example 10.2.12. Suppose {X1, X2, · · · , Xn} are independent and identi￾cally distributed random variables with µ
′
2k < ∞. Suppose
T n = (m′
1
, m′
2
, · · · , m′
k
)
′
is a random vector, where m′
r =
Pn
i=1 Xr
i
/n, r =
1, 2, · · · , k. Suppose µ = (µ
′
1
, µ′
2
, · · · , µ′
k
)
′
. From the WLLN, it follows that
m′
r
P
→ µ
′
r
, r = 1, 2, · · · , k. We now examine whether √
n(T n − µ)
L
→ Z ∼
Nk(0, Σ). Suppose a random vector Z is defined as Z = (X, X2
, · · · , Xk
).
Then E(Z) = µ and the dispersion matrix of Z is Σ = [σij ], where
σij = Cov(Xi
, Xj
), i, j = 1, 2, · · · , k. To examine whether Σ is positive defi￾nite, suppose a random variable Y is defined as Y =
Pk
i=1 aiXi
. Without loss
of generality we assume that X is a non-degenerate random variable which im￾plies that Y is also a non-degenerate random variable and hence V ar(Y ) > 0.
Observe that for any non-zero vector a = (a1, a2, · · · , ak)
′ of real numbers
0 < V ar(Y ) = V ar X
k
i=1
aiXi
!
=
X
k
i=1
X
k
j=1
aiajCov(Xi
, Xj
) = a
′Σa,
which proves that Σ is a positive definite matrix. Thus Z is a random
vector with mean vector µ and positive definite dispersion matrix Σ. Now
{X1, X2, · · · , Xn} are independent and identically distributed random vari￾ables implies that {Z1
, Z2
, · · · , Zn} are independent and identically dis￾tributed random vectors, each following the distribution same as that of Z.
Suppose Zn =
Pn
i=1 Zi/n denotes the sample mean vector. Then by the mul￾tivariate CLT,
√
n(Zn − µ)
L
→ Z ∼ Nk(0, Σ) ⇒
√
n(T n − µ)
L
→ Z ∼ Nk(0, Σ)
distribution as n → ∞ since Zn = Tn. □
In Theorem 7.3.9, we have proved that if √
n(Xn − µ)
L
→ X ∼ N(0, σ2
)
distribution and g is a differentiable function with g
′
(µ) ̸= 0, then
√
n(g(Xn)−g(µ)) L
→ Y ∼ N(0,(g
′
(µ))2σ
2
) distribution. The result is true for
a random vector Xn
. We state it below, it is also known as a delta method.
Theorem 10.2.7. Suppose {Xn
, n ≥ 1} is a sequence of random vectors such
that √
n(Xn − µ)
L
→ Z ∼ Nk(0, Σ), where Σ is a positive definite dispersion
matrix. Suppose g : R
k → R is a totally differentiable function. Then
√
n(g(Xn
) − g(µ)) L
→ U ∼ N(0, v), as n → ∞,Lindeberg-Levy CLT 449
where v = ∆′Σ∆ and ∆ is a gradient vector of order k × 1 of g, with i-th
component given by ∂g
∂xi
.
Using multivariate CLT and Theorem 10.2.7, in the next example we show
that the properly scaled sample correlation coefficient, based on the random
sample from a bivariate normal distribution, converges to the standard normal
distribution. The famous arctan transformation of Fisher, popularly known
as Fisher’s Z transformation, for the correlation parameter in the bivariate
normal distribution is obtained from this result using the variance stabilization
technique. For details refer to Deshmukh and Kulkarni [11]. This example
illustrates number of results proved in Chapter 7.
Example 10.2.13. Suppose (X, Y )
′ has a bivariate normal distribution with
zero mean vector and dispersion matrix Σ = [σij ], where σ11 = σ22 = 1 and
σ12 = σ21 = ρ ∈ (−1, 1). Suppose {(Xi
, Yi)
′
, i = 1, 2, · · · , n} are independent
and identically distributed random vectors each having the distribution same
as that of (X, Y )
′
. The correlation coefficient Rn is defined as
Rn =
S
2
XY
SXSY
where S
2
XY =
1
n
Xn
i=1
(Xi − Xn)(Yi − Y n),
S
2
X =
1
n
Xn
i=1
(Xi − Xn)
2 & S
2
Y =
1
n
Xn
i=1
(Yi − Y n)
2
.
As shown in Example 10.2.3, S
2
X
P
→ 1 and S
2
Y
P
→ 1. Similarly by the WLLN,
(1/n)
Pn
i=1 XiYi
P
→ E(XY ) and hence S
2
XY
P
→ E(XY ) = Cov(X, Y ). In
view of the result that convergence in probability is closed under arithmetic
operations, it follows that Rn
P
→ ρ. We now examine whether suitably scaled
Rn converges in law to the standard normal distribution. Note that X ∼
N(0, 1), Y ∼ N(0, 1) and the conditional distribution of X given Y = y is
also normal N(ρy, 1 − ρ
2
). Suppose a random vector U is defined as U =
(X2
, Y 2
, XY )
′
. Then µ = E(U) = (1, 1, ρ)
′
. To find the dispersion matrix V
of U, note that
V ar(X2
)=V ar(Y
2
) = 2 & V ar(XY )=E(X2Y
2
)−(E(XY ))2 =E(X2Y
2
)−ρ
2
.
Using the conditional distribution of X given Y = y, we find E(X2Y
2
) and
the remaining elements of V as follows.
E(X2Y
2
) = E(E(X2Y
2
)|Y ) = E(Y
2E(X2
|Y ))
= E(Y
2
(V ar(X|Y ) + (E(X|Y ))2
))
= E(Y
2
(1 − ρ
2 + ρ
2Y
2
))
= 1 − ρ
2 + ρ
2E(Y
4
) = 1 − ρ
2 + 3ρ
2 = 1 + 2ρ
2
.450 Central Limit Theorem
Hence,
V ar(XY ) = 1 + ρ
2 & Cov(X2
, Y 2
) = 1 + 2ρ
2 − 1 = 2ρ
2
Cov(X2
, XY ) = E(X3Y ) − E(X2
)E(XY ) = E(E(X3Y |Y )) − ρ
= E(Y E(X3
|Y )) − ρ
E((X − ρY )
3
|Y ) = 0 since X|Y = y ∼ N(ρy, 1 − ρ
2
)
⇒ E(X3
|Y ) = 3ρY E(X2
|Y ) − 3ρ
2Y
2E(X|Y ) + ρ
3Y
3
= 3ρ(1 − ρ
2
)Y + ρ
3Y
3
⇒ E(X3Y ) = E(Y E(X3
|Y )) = 3ρ(1 − ρ
2
)E(Y
2
) + ρ
3E(Y
4
) = 3ρ
⇒ Cov(X2
, XY ) = 2ρ similarly Cov(Y
2
, XY ) = 2ρ.
Hence the dispersion matrix V of U is given by,
V =


2 2ρ
2 2ρ
2ρ
2 2 2ρ
2ρ 2ρ 1 + ρ
2

.
From the principal minors of V , it follows that it is a positive definite ma￾trix with determinant 4(1 − ρ
2
)
2 ̸= 0. Note that {(Xi
, Yi)
′
, i = 1, 2, · · · , n}
are independent and identically distributed random vectors implies that
{U1
, U2
, · · · , U n
} are also independent and identically distributed random
vectors, each having the distribution same as that of U. Hence by the multi￾variate CLT,
√
n(U n − µ)
L
→ W ∼ N3(0, V ) where U n
=
Xn
i=1
X2
i /n,Xn
i=1
Y
2
i /n,Xn
i=1
XiYi/n′
.
It is to be noted that
√
n((S
2
X, S2
Y
, SXY )
′ − µ) = √
n(U n − µ) −
√
n(X
2
n
, Y
2
n
, XnY n)
′
.
Now,
X ∼ N(0, 1) ⇒
√
n Xn ∼ N(0, 1) & Xn
P
→ 0 by WLLN
Y ∼ N(0, 1) ⇒
√
n Y n ∼ N(0, 1) & Y n
P
→ 0 by WLLN
⇒ (
√
n Xn)Xn
P
→ 0 as √
nXn is bounded in probability
⇒ (
√
n Y n)Y n
P
→ 0 as √
nY n is bounded in probability
⇒ (
√
n Xn)Y n
P
→ 0 as √
nXn is bounded in probability
⇒
√
n((S
2
X, S2
Y
, SXY )
′ − µ) −
√
n(U n − µ)
P
→ 0
⇒
√
n((S
2
X, S2
Y
, SXY )
′ − µ)
L
→ W ∼ N3(0, V ),CLT for Independent Random Variables 451
since √
n(U n−µ)
L
→ W. To examine the limit law of the correlation coefficient
Rn, observe that
Rn =
S
2
XY
SXSY
= g(S
2
X, S2
Y
, SXY ) where g(x1, x2, x3) = x3/(x1x2)
1/2
,
a function from R
3 − {(0, 0, 0)} → (−1, 1). Hence, the vector of partial deriva￾tives of g is given by,
∂
∂x1
g(x1, x2, x3) = −x3
2x
3/2
1 x
1/2
2
,
∂
∂x2
g(x1, x2, x3) = −x3
2x
1/2
1 x
3/2
2
∂
∂x3
g(x1, x2, x3) = 1
x
1/2
1 x
1/2
2
.
By Theorem 10.2.7,
√
n(g(S
2
X, S2
Y , SXY ) − g(µ)) = √
n(Rn − ρ)
L→ W1 ∼ N(0, σ
2
) where σ
2 = ∆′
V ∆
and ∆′ = (−ρ/2, −ρ/2, 1). Hence σ
2 = (1 − ρ
2
)
2
. □
The next section is concerned with the CLT for a sequence of independent,
but not necessarily identically distributed random variables.
10.3 CLT for Independent Random Variables
The classical Lindeberg-Levy CLT is related to a sequence of independent
and identically distributed random variables. We now relax the assumption
that random variables in the sequence are identically distributed and retain
the assumption of independence. Thus, suppose {Xn, n ≥ 1} is a sequence of
independent random variables defined on (Ω, A, P) such that E(Xk) = µk,
V ar(Xk) = σ
2
k < ∞ and Fk is a distribution function of Xk, k ≥ 1. Suppose
Sn =
Pn
k=1(Xk − µk) and s
2
n = V ar(Sn) = Pn
k=1 σ
2
k
. It is assumed that
σ
2
k > 0 for at least one k = 1, 2, · · · , n, which implies that s
2
n > 0. In such a
setup, we have two CLTs, one is Lyapounov’s CLT and the other is Lindeberg￾Feller CLT. These state that Sn/sn has approximately normal distribution for
large n, under certain conditions, such as Lyapounov’s condition, Lindeberg’s
condition and Feller’s condition (Shao [21]). We state below these conditions.
(i) Lyapounov’s condition: A sequence {Xn, n ≥ 1} satisfies Lyapounov’s
condition if for some δ > 0,
Pn
k=1 E(|Xk −µk|
2+δ
)/s2+δ
n → 0 as n → ∞.
(ii) Lindeberg’s condition: Suppose for k = 1, 2, · · · , n, a subset Ank of R is
defined as Ank = {xk|xk − µk| > ϵsn}. A sequence {Xn, n ≥ 1} satisfies
Lindeberg’s condition if ∀ ϵ > 0, as n → ∞,452 Central Limit Theorem
gn(ϵ) = 1
s
2
n
Xn
k=1
Z
Ank
(xk − µk)
2
dFk(xk)
=
Xn
k=1
E
￾
((Xk − µk)/sn)
2
IAnk 
→ 0,
where expectation is a Riemann-Stieltjes integral with respect to Fk. It
can also be written as
gn(ϵ) = Xn
k=1
E
 
Xk − µk
sn
2
IBnk!
=
Xn
k=1
Z
Ω

Xk − µk
sn
2
IBnk dP → 0,
where expectation is an integral with respect to probability measure P
and Bnk = {ω|Xk(ω) − µk| > ϵsn}. Note that Bnk = X
−1
k
(Ank).
(iii) Feller’s condition: A sequence {Xn, n ≥ 1} satisfies Feller’s condition if
maxk≤n σ
2
k
/s2
n → 0 as n → ∞.
Feller’s condition is also stated as, maxk≤n P(Bnk) → 0 as n → ∞ for any
ϵ > 0, refer to p. 348 of Athreya and Lahiri [3]. It follows from Chebyshev’s
inequality. Observe that as n → ∞,
P(Bnk) = P[|Xk−µk| > ϵsn] ≤ σ
2
k/ϵ2
s
2
n ⇒ max
k≤n
P(Bnk) ≤ max
k≤n
σ
2
k/ϵ2
s
2
n → 0.
We now analyze Lindeberg’s condition. Suppose the sequence {Xn, n ≥ 1}
satisfies Lindeberg’s condition. Note that on Ank, 1 < (x − µk)
2/ϵ2
s
2
n
,
k = 1, 2, · · · , n. Hence,
P
h
max
1≤k≤n
|Xk − µk| > ϵsn
i
= P
 [n
k=1
Bnk
≤
Xn
k=1
P(Bnk) = Xn
k=1
Z
Ank
1dFk(x)
<
Xn
k=1
Z
Ank
(x − µk)
2
ϵ
2s
2
n
dFk(x) = gn(ϵ)/ϵ2 → 0 .
Thus, if the sequence {Xn, n ≥ 1} satisfies the Lindeberg’s condition, then
∀ ϵ > 0, Ph
max
1≤k≤n
|Xk − µk| > ϵsn
i
→ 0
and we say that the deviations |Xn − µn|’s are uniformly asymptotically neg￾ligible.
We now discuss the implications among the three conditions stated above.
Lemma 10.3.1. Feller’s condition implies that s
2
n → ∞ as n → ∞.
Proof. It is assumed that V ar(Xk) = σ
2
k > 0 for at least one k = 1, 2, · · · , n.
We assume that ∃ m such that σ
2
m > 0. Hence,
∀ n > m, σ2
m > 0 ⇒
σ
2
m
s
2
n
≤ max
k≤n
σ
2
k
s
2
n
→ 0 ⇒ s
2
n → ∞ as n → ∞CLT for Independent Random Variables 453
In the next lemma, we prove that Lyapounov’s condition implies Linde￾berg’s condition.
Lemma 10.3.2. Lyapounov’s condition implies Lindeberg’s condition.
Proof. Suppose the sequence {Xn, n ≥ 1} satisfies Lyapounov’s condition.
Observe that on Ank, |xk − µk|/ϵsn > 1. Hence ∀ ϵ > 0 and δ > 0,
gn(ϵ) = 1
s
2
n
Xn
k=1
Z
Ank
(xk − µk)
2
dFk(xk)
≤
1
s
2
n
Xn
k=1
Z
Ank
(xk − µk)
2

|xk − µk|
ϵsn
δ
dFk(xk)
≤
1
ϵ
δs
2+δ
n
Xn
k=1
Z
R
|xk − µk|
2+δ
dFk(xk) = 1
ϵ
δs
2+δ
n
Xn
k=1
E(|Xk − µk|
2+δ
)
→ 0,
if Lyapounov’s condition is satisfied. Thus, Lyapounov’s condition implies
Lindeberg’s condition.
In view of Lemma 10.3.2, we first prove the Lindeberg-Feller CLT. Lya￾pounov’s CLT then follows from the Lindeberg-Feller CLT. It is proved in
the first part of the Lindeberg-Feller CLT that Lindeberg’s condition implies
Feller’s condition. Thus, Lyapounov’s condition implies Lindeberg’s condition
and Lindeberg’s condition implies Feller’s condition.
We prove below a lemma involving a trignometric function, which is used
in the proof of Lindeberg-Feller CLT.
Lemma 10.3.3. cos(x) − 1 + x
2/2 ≥ 0 ∀ x ∈ R.
Proof. Suppose h(x) = cos(x) − 1 + x
2/2. Observe that h(−x) = h(x), thus h
is an even function and h(0) = 0. Suppose x ≥ 0. Note that
h
′
(x) = − sin(x) + x & h
′
(0) = 0, h′′(x) = − cos(x) + 1 ≥ 0 ∀ x ∈ R
⇒ h
′
(x) is a non-decreasing function ⇒ for x ≥ 0, h′
(x) ≥ h
′
(0) = 0
⇒ h(x) is a non-decreasing function ⇒ for x ≥ 0, h(x) ≥ h(0) = 0
⇒ For x < 0 h(x) = h(−x) ≥ 0 ⇒ h(x) ≥ 0, ∀ x ∈ R.
Theorem 10.3.1. Lindeberg-Feller CLT: Suppose {Xn, n ≥ 1} is a sequence
of independent random variables such that E(Xk) = µk, V ar(Xk) = σ
2
k > 0
for at least one k and Fk is a distribution function of Xk, k ≥ 1. Suppose
Ank = {xk||xk − µk| > ϵsn}, k = 1, 2, · · · , n and s
2
n =
Pn
k=1 σ
2
k
.
If ∀ ϵ > 0, gn(ϵ) = 1
s
2
n
Xn
k=1
Z
Ank
(xk − µk)
2
dFk(x) → 0 (10.4)
then, Xn
k=1
(Xk − µk)/sn
L
→ Z ∼ N(0, 1) & max
k≤n
σk/sn → 0. (10.5)454 Central Limit Theorem
Conversely, if both the results in Equation (10.5) are satisfied, then Equation
(10.4) is satisfied, that is, ∀ ϵ > 0, gn(ϵ) → 0.
Proof. Part (i): We first prove that Equation (10.4) implies Equation (10.5).
For notational convenience, for ∀ n ≥ 1 and k = 1, 2 · · · , n, we define
Xnk =
Xk − µk
sn
, Sn =
Xn
k=1
Xnk & Ank = {xnk|xnk| > ϵ}, with xnk = Xnk(ω)
⇒ E(Xnk) = 0, V ar(Xnk) = σ
2
k/s2
n = σ
2
nk, say
⇒ E(Sn) = 0 & V ar(Sn) = Xn
k=1
σ
2
nk = 1.
In view of the above notation we prove that ∀ ϵ > 0,
gn(ϵ) = Xn
k=1
Z
Ank
x
2
nkdFk(x) → 0 ⇒ Sn
L
→ Z ∼ N(0, 1) & max
k≤n
σnk → 0.
We begin by showing that gn(ϵ) → 0 ⇒ max
k≤n
σnk → 0. Note that for all
k = 1, 2, · · · , n,
σ
2
nk = E(X2
nk) = Z
[|xnk|≤ϵ]
x
2
nkdFk(x) + Z
[|xnk|>ϵ]
x
2
nkdFk(x)
≤ ϵ
2P[|Xnk| ≤ ϵ] +Xn
k=1
Z
Ank
x
2
nkdFk(x) ≤ ϵ
2 + gn(ϵ)
⇒ max
1≤k≤n
σ
2
nk ≤ ϵ
2 + gn(ϵ) → 0 if gn(ϵ) → 0 as n → ∞.
Thus, Lindeberg’s condition implies Feller’s condition. We now prove that
Lindberg’s condition implies Sn
L
→ Z ∼ N(0, 1). Suppose
Ψnk(t) = E(e
itXnk ) & Ψn(t) = E(e
itSn ) = Yn
k=1
Ψnk(t), t ∈ R
are characteristic functions of Xnk and Sn respectively. Observe that,
Sn
L
→ Z ∼ N(0, 1) ⇐⇒ Ψn(t) → e
−t
2/2 ∀ t ∈ R,
in view of the continuity and uniqueness theorems for characteristic functions.
Since Pn
k=1 σ
2
nk = 1, note that
e
−t
2/2 =
Yn
k=1
e
−(t
2σ
2
nk)/2 =
Yn
k=1
ϕnk(t), where ϕnk(t) = e
−(t
2σ
2
nk)/2CLT for Independent Random Variables 455
is a characteristic function of Znk ∼ N(0, σ2
nk) distribution and for each fixed
n, Znk, k = 1, 2, · · · , n are independent random variables. Now, by Lemma
9.2.2



Ψn(t) − e
−t
2/2


 =





Yn
k=1
Ψnk(t) −
Yn
k=1
ϕnk(t)





≤
Xn
k=1
|Ψnk(t) − ϕnk(t)|
=
Xn
k=1

Ψnk(t) − (1 − t
2σ
2
nk/2) + (1 − t
2σ
2
nk/2) − ϕnk(t)


≤
Xn
k=1

Ψnk(t) −
￾
1 − t
2σ
2
nk/2

+
Xn
k=1

ϕnk(t) −
￾
1 − t
2σ
2
nk/2


≤
Xn
k=1
E
￾
min 
|tXnk|
2
, |tXnk|
3
/6
	
+
Xn
k=1
E
￾
min 
|tZnk|
2
, |tZnk|
3
/6
	 , (10.6)
with k = 2 in Theorem 9.2.4. It is to be noted that Sn
L
→ Z ∼ N(0, 1), if
both the terms on the right hand side of (10.6) converge to 0 as n → ∞. We
now examine whether the first term converges to 0. Suppose
Unk = min 
|tXnk|
2
, |tXnk|
3/6
	
and Vnk = min 
|tZnk|
2
, |tZnk|
3/6
	
. Ob￾serve that for small ϵ,
|Xnk| ≤ ϵ ⇒ Unk = |tXnk|
3
/6 < |tXnk|
3
& |Xnk| > ϵ ⇒ Unk = |tXnk|
2
.
Hence,
E(Unk) = Z
Ω
UnkdP =
Z
[|Xnk|≤ϵ]
UnkdP +
Z
[|Xnk|>ϵ]
UnkdP
≤ |t|
3
ϵ
Z
[|Xnk|≤ϵ]
|Xnk|
2
dP + t
2
Z
[|Xnk|>ϵ]
|Xnk|
2
dP
≤ |t|
3
ϵ
Z
Ω
|Xnk|
2
dP + t
2
Z
[|Xnk|>ϵ]
|Xnk|
2
dP
= |t|
3
ϵ σ2
nk + t
2
Z
[|Xnk|>ϵ]
|Xnk|
2
dP
⇒
Xn
k=1
E(Unk) ≤ ϵ|t|
3Xn
k=1
σ
2
nk + t
2 Xn
k=1
Z
[|Xnk|>ϵ]
|Xnk|
2
dP
= ϵ |t|
3 + t
2
gn456 Central Limit Theorem
Now taking limits as n → ∞ on both sides of the above inequality and using
Lindeberg condition we have,
limn→∞
Xn
k=1
E(Unk) ≤ ϵ|t|
3 = 0,
since ϵ is arbitrary. The proof of convergence to 0 of the second term in (10.6)
follows when Znk are substituted for Xnk in the above steps. Hence,
|Ψn(t) − e
−t
2/2
| → 0 ∀ t ∈ R ⇒
Xn
k=1
(Xk − µk)/sn
L
→ Z ∼ N(0, 1).
Part (ii): We now proceed to prove that if both the results in Equation (10.5)
are satisfied then, ∀ ϵ > 0, gn(ϵ) → 0. With k = 1 in Theorem 9.2.4 and
using the result that max1≤k≤n σ
2
nk → 0 as n → ∞, we have
|1 − Ψnk(t)| ≤ E
￾
min 
2|tXnk|, |tXnk|
2
/2
	
≤ E
￾
|tXnk|
2
/2

= t
2σ
2
nk/2
⇒ max
1≤k≤n
|1 − Ψnk(t)| ≤ (t
2
/2) max
1≤k≤n
σ
2
nk → 0
⇒ limn→∞
|1 − Ψnk(t)| = 0 uniformly in k. (10.7)
Hence, Xn
k=1
|1 − Ψnk(t)|
2 ≤ max
1≤k≤n
|1 − Ψnk(t)|
Xn
k=1
|1 − Ψnk(t)|
≤ (t
2
/2) max
1≤k≤n
σ
2
nkXn
k=1
t
2σ
2
nk/2
≤ (t
4
/4) max
1≤k≤n
σ
2
nk, (10.8)
since Pn
k=1
σ
2
nk = 1. We have already noted in Chapter 7 that for any complex
number z = a + ib,
e
z = e
a
e
ib = e
a
(cos b + isin b) ⇒ |e
z
| = (e
2a
cos2
b + e
2a
sin2
b)
1/2 = e
a
⇒ z = Ψnk(t) − 1 = E(costXnk) − 1 + iE(sin tXnk)
⇒ |e
z
| = e
E(cos tXnk)−1 ≤ e
−1
e = 1.
In Equation (10.7), it is proved that |1 − Ψnk(t)| → 0 as n → ∞ uniformly
in k, hence for large n, one can assume that |z| ≤ 1/2. Hence using the
result from p. 555 of Gut [13], we have |e
z − 1 − z| ≤ |z|
2
. Now, |Ψnk(t)|CLT for Independent Random Variables 457
1 & |e
Ψnk(t)−1
| ≤ 1. Hence by Lemma 9.2.2





Yn
k=1
e
Ψnk(t)−1 − Ψn(t)





=





Yn
k=1
e
Ψnk(t)−1 −
Yn
k=1
Ψnk(t)





≤
Xn
k=1



e
Ψnk(t)−1 − Ψnk(t)



=
Xn
k=1



e
Ψnk(t)−1 − (Ψnk(t) − 1) − 1



≤
Xn
k=1
|Ψnk(t) − 1|
2 using |e
z − 1 − z| ≤ |z|
2
≤ (t
4
/4) max
1≤k≤n
σ
2
nk by (10.8)
→ 0 , (10.9)
since it is given that max
1≤k≤n
σ
2
nk → 0. We further know that
Sn
L
→ Z ∼ N(0, 1) ⇐⇒ Ψn(t) − e
−t
2/2 → 0 ∀ t ∈ R. (10.10)
Hence,





Yn
k=1
e
Ψnk(t)−1 − e
−t
2/2





=





Yn
k=1
e
Ψnk(t)−1 − Ψn(t) + Ψn(t) − e
−t
2/2





≤





Yn
k=1
e
Ψnk(t)−1 − Ψn(t)





+



Ψn(t) − e
−t
2/2



→ 0 by (10.9) and (10.10)
⇒
Yn
k=1
e
Ψnk(t)−1 → e
−t
2/2 = e
−(t
2/2)Pn
k=1 σ
2
nk as Xn
k=1
σ
2
nk = 1
⇒
Yn
k=1
e
Ψnk(t)−1
e
(t
2/2)Pn
k=1 σ
2
nk → 1.
Thus,
exp (Xn
k=1
￾
Ψnk(t) − 1 + (t
2
/2)σ
2
nk
)
→ 1
⇒
Xn
k=1
￾
Ψnk(t) − 1 + (t
2
/2)σ
2
nk
→ 458 Central Limit Theorem
It is to be noted that the limit of a sequence of complex numbers is 0 and
hence the real part must converge to 0. Thus,
Xn
k=1
(E(cos(tXnk)) − 1 + (t
2
/2)σ
2
nk) = Xn
k=1
(E(cos(tXnk)) − 1 + (t
2
/2)E(X2
nk))
=
Xn
k=1
Z
Ω
(cos(tXnk) − 1 + (t
2
/2)X2
nk) dP
→ 0 as n → ∞.
Now by Lemma 10.3.3, the integrand (cos(x) − 1 + x
2/2) ≥ 0 ∀ x ∈ R.
Thus, if integral over Ω converges to 0, integral over any subset of Ω
must converge to
P
0. We take a subset to be [|Xnk| > ϵ]. Suppose un =
n
k=1 E
￾
(1 − cos(tXnk))I[|Xnk|>ϵ]

. Now, | cos(x) − 1| ≤ 2, ∀ x ∈ R. Hence,
|un| ≤ Xn
k=1
E
￾
| cos(tXnk) − 1|I[|Xnk|>ϵ]

≤
Xn
k=1
2P[|Xnk| > ϵ]
≤ 2
Xn
k=1
σ
2
nk/ϵ2 = 2/ϵ2 ⇒ lim sup
n→∞
un ≤ 2/ϵ2
.
In the second step we use Chebyshev’s inequality. Now for ϵ > 0,
Xn
k=1
E(cos(tXnk) − 1 + (t
2
/2)X2
nk) → 0
⇒
Xn
k=1
E
￾
(cos(tXnk) − 1 + (t
2
/2)X2
nk)I[|Xnk|>ϵ]

→ 0
⇒
Xn
k=1
(t
2
/2)E
￾
X2
nk)I[|Xnk|>ϵ]

− un → 0
⇒ (t
2
/2)gn(ϵ) − un → 0
⇒ gn(ϵ) − (2/t2
)un → 0,
Hence, lim sup
n→∞
gn(ϵ) = lim sup
n→∞

gn(ϵ) − (2/t2
)un + (2/t2
)un

≤ lim sup
n→∞

gn(ϵ) − (2/t2
)un

+ lim sup
n→∞
(2/t2
)un
≤ limn→∞ 
gn(ϵ) − (2/t2
)un

+ (2/t2
)(2/ϵ2
) = 0 + 4/t2
ϵ
2
,
which can be made arbitrarily small by selecting t sufficiently large for each
ϵ > 0. Further gn(ϵ) ≥ 0, hence we conclude that ∀ ϵ > 0, gn(ϵ) → 0 as
n → ∞ and the theorem is proCLT for Independent Random Variables 459
Remark 10.3.1. In the first part of the proof, it is proved that Lindeberg’s
condition implies Feller’s condition. From the second part of the theorem, we
note that if Feller’s condition is assumed, then Lindeberg’s condition is not
only sufficient but also necessary for the normality of Sn. The first part of
the proof is established by Lindeberg and the second part is proved by Feller.
Hence, it is known as a Lindeberg-Feller CLT. The second part of the theorem
is also referred to as Feller’s theorem (Athreya and Lahiri [3]).
We now show that Lindeberg-Levy CLT follows from Lindeberg-Feller
CLT, as is expected.
Theorem 10.3.2. Lindeberg-Feller CLT implies Lindeberg-Levy CLT.
Proof. Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables such that E(Xk) = µ, V ar(Xk) = σ
2
, 0 < σ2 <
∞ and F is the common distribution function. Thus, s
2
n = nσ2
. We now verify
whether the Lindeberg condition is satisfied. Observe that ∀ ϵ > 0,
gn(ϵ) = 1
s
2
n
Xn
k=1
Z
Ank
(xk − µk)
2
dFk(xk)
=
1
nσ2
Xn
k=1
Z
[|x−µ|>ϵσ√
n]
(x − µ)
2
dF(x) = 1
σ
2
Z
[|x−µ|>ϵσ√
n]
(x − µ)
2
dF(x).
It is to be noted that P [|X − µ|/σ > ϵ√
n] → 0 in view of the fact that the
real random variable (X − µ)/σ is bounded in probability. Further, (X − µ)
2
is an integrable random variable. Hence, R
[|x−µ|>ϵσ√
n]
(x − µ)
2dF(x) → 0,
by Corollary 8.3.1. Thus, ∀ ϵ > 0, gn(ϵ) → 0 and the Lindeberg’s condi￾tion is satisfied by the sequence {Xn, n ≥ 1} of independent and identically
distributed random variables. Hence the sequence {Xn, n ≥ 1} satisfies the
Lindeberg-Feller CLT. Thus,
Xn
k=1
(Xk − µk)/sn =
Xn
k=1
(Xk − µ)/
√
nσ
L
→ Z ∼ N(0, 1).
Thus the sequence {Xn, n ≥ 1} satisfies the Lindeberg-Levy CLT.
We now prove Lyapounov’s CLT in the following theorem.
Theorem 10.3.3. Lyapounov’s CLT: Suppose {Xn, n ≥ 1} is a sequence of
independent random variables with mean µk and V ar(Xk) = σ
2
k > 0. Suppose
Sn =
Pn
k=1(Xk − µk) and s
2
n = V ar(Sn) < ∞. In addition, suppose
E(|Xk − µk|
2+δ
) > 0 for some δ > 0. Then for some δ > 0,
Xn
k=1
E(|Xk − µk|
2+δ
)/s2+δ
n → 0 ⇒ Sn/sn
L
→ Z ∼ N(0, 1).460 Central Limit Theorem
Proof. In Lemma 10.3.2 it is proved that Lyapounov’s condition implies Linde￾berg’s condition. Hence, Lyapounov’s CLT follows from the Lindeberg-Feller
CLT and hence Sn/sn
L
→ Z ∼ N(0, 1) distribution.
Remark 10.3.2. It is in general difficult to verify Lindeberg’s condition. As
noted above a sufficient condition for Lindeberg’s condition is Lyapounov’s
condition, which is somewhat easier to verify. However, one criticism about
Lyapounov’s condition is that it involves moments of higher order than the
moments in the formulation of the problem.
Corollary 10.3.1. Suppose {Xn, n ≥ 1} is a sequence of independent random
variables with mean 0 and Xn’s are uniformly bounded. Suppose Sn =
Pn
i=1 Xi
and s
2
n = V ar(Sn). If sn → ∞, then Sn/sn
L
→ Z ∼ N(0, 1).
Proof. Observe that
|Xk| ≤ C < ∞ ⇒ E(|Xk|
2+δ
) ≤ C
δE(|X2
k
|) = C
δσ
2
k
⇒
Pn
k=1
E(|Xk|
2+δ
)
s
2+δ
n
≤
C
δ
s
δ
n
→ 0, as sn → ∞
⇒ Sn/sn
L
→ Z ∼ N(0, 1),
by Lyapounov’s CLT.
Example 10.3.1. Suppose {Xn, n ≥ 1} is a sequence of independent random
variables, where Xk follows Bernoulli B(1, pk) distribution, 0 < pk < 1. Then
Xk’s are uniformly bounded by 1. If s
2
n =
Pn
k=1 pk(1 − pk) → ∞, then by the
above corollary, (Sn − E(Sn))/sn
L
→ Z ∼ N(0, 1). □
In Lyapounov’s theorem, it is assumed that Lyapounov’s condition holds
for some δ > 0. It is proved below that if Lyapounov’s condition holds for δ2,
then it also holds with δ1 where 0 < δ1 < δ2. In applications, Lyapounov’s
condition is verified first for δ = 1 or 2 and if it fails, then verified for δ < 1.
In Example 10.3.2 and in Example 10.3.3, the condition is verified for δ = 1,
while in Example 10.3.10 it is verified for δ = 2.
Lemma 10.3.4. Lyapounov’s condition with δ2 > 0 is satisfied implies that
Lyapounov’s condition is satisfied for every δ1, such that 0 < δ1 < δ2, that is,
limn→∞
Xn
k=1
E(|Xnk|
2+δ2
) = 0 ⇒ limn→∞
Xn
k=1
E (|Xnk|
2+δ1
) = 0, ∀ δ1 ∈ (0, δ2),
where Xnk = (Xk − µk)/sn, k = 1, 2 · · · , n.CLT for Independent Random Variables 461
Proof. Suppose the set {xnk||xnk| ≤ ϵ} is denoted by [|xnk| ≤ ϵ]. For ϵ > 0
observe that,
E(|Xnk|
2+δ1
) = Z
[|xnk|≤ϵ]
|xnk|
2+δ1 dFnk(x) + Z
[|xnk>ϵ]
|xnk|
2+δ1 dFnk(x)
≤ ϵ
δ1
Z
[|xnk|≤ϵ]
|xnk|
2
dFnk(x) + Z
[|xnk|>ϵ]
|xnk|
2+δ2
|xnk|
δ2−δ1
dFnk(x)
≤ ϵ
δ1
Z
R
|xnk|
2
dFnk(x) + Z
[|xnk|>ϵ]
|xnk|
2+δ2
ϵ
δ2−δ1
dFnk(x)
≤ ϵ
δ1E(|Xnk|
2
) + 1
ϵ
δ2−δ1
Z
R
|xnk|
2+δ2 dFnk(x)
= ϵ
δ1 σ
2
nk + E(|Xnk|
2+δ2
)/ϵδ2−δ1
.
Hence, Xn
k=1
E(|Xnk|
2+δ1
) ≤ ϵ
δ1 Xn
k=1
σ
2
nk +
Xn
k=1
E|Xnk|
2+δ2 /ϵδ2−δ1
= ϵ
δ1 +
Xn
k=1
E|Xnk|
2+δ2 /ϵδ2−δ1
⇒ lim sup
n→∞
Xn
k=1
E(|Xnk|
2+δ1
) ≤ ϵ
δ1 + lim sup
n→∞
Xn
k=1
E(|Xnk|
2+δ2
)/ϵδ2−δ1
Now, the second term on the right hand side is zero. By taking ϵ to be suffi￾ciently small it follows that lim supn→∞ Pn
k=1
E(|Xnk|
2+δ1 ) = 0 and the result
follows.
Following examples illustrate the verification of the three conditions and
also illustrate Lindeberg-Feller CLT and Lyapounov’s CLT.
Example 10.3.2. Suppose {Xn, n ≥ 1} is a sequence of independent random
variables where Xn ∼ B(1, pn) distribution, 0 < pn < 1. Then E(Xn) = pn
and V ar(Xn) = pnqn, where qn = 1−pn. Suppose Sn =
Pn
k=1(Xk −pk), then
s
2
n = V ar(Sn) = Pn
k=1 pkqk. Note that s
2
n ≤ n/4. Suppose s
2
n → ∞. We now
show that all the three conditions are satisfied. If Xk ∼ B(1, pk), then using
the fact that p
2
k + q
2
k ≤ 2, we have
E(|Xk − E(Xk)|
3
) = p
3
k
qk + pkq
3
k = pkqk(p
2
k + q
2
k
) ≤ 2pkqk
⇒
Xn
k=1
E(|Xk − µk|
3
)/s3
n ≤ 2
Xn
k=1
pkqk/s3
n = 2s
2
n/s3
n → 0.462 Central Limit Theorem
Thus, Lyapounov’s condition is satisfied with δ = 1. It is shown in Exam￾ple 10.3.1 that Lyapounov’s CLT is satisfied as the random variables Xk are
uniformly bounded by 1. It is proved in Lemma 10.3.2 that
gn(ϵ) ≤
1
ϵ
δs
2+δ
n
Xn
k=1
E(|Xk − µk|
2+δ
).
Hence, with δ = 1, it follows that gn(ϵ) ≤ 2/sn → 0. Thus, Lindeberg’s
condition is also satisfied. We can also verify it as follows. Note that for each
k = 1, 2, · · · , n, the deviations |Xk − pk| ∈ (0, 1). Given ϵ > 0, we can select
n0 such that ϵ > 1/n0. Since sn → ∞, corresponding to this n0, ∃ n1 ∈ N
such that sn > n0 ∀ n ≥ n1. Suppose Bnk = [|Xk − pk| > ϵsn]. Note that
∀ n ≥ n1,
1/sn < 1/n0 < ϵ ⇒ ϵsn > 1 ⇒ Bnk = ∅ ⇒ IBnk = 0.
Hence,
gn(ϵ) = 1
s
2
n
Xn
k=1
E((Xk − pk)
2
IBnk ) = 1
s
2
n
nX1−1
k=1
E((Xk − pk)
2
IBnk )
+
1
s
2
n
Xn
k=n1
E((Xk − pk)
2
IBnk ) = 1
s
2
n
nX1−1
k=1
E((Xk − pk)
2
IBnk ) → 0,
as n → ∞, since the sum is finite and sn → ∞ as n → ∞. Thus, it is ver￾ified that Lindeberg’s condition is satisfied. Observe that maxk≤n pkqk/sn ≤
1/4sn → 0 and hence Feller’s condition is satisfied. Thus if s
2
n → ∞, then the
sequence {Xn, n ≥ 1} satisfies CLT.
Suppose s
2
n → c < ∞, then we can choose ϵ, for example ϵ = 1/2sn,
such that P[|Xk − pk| > ϵsn] = P[|Xk − pk| ≥ 1/2] > 0, ∀ k ≥ 1. Then
gn(ϵ) does not converge to 0 for all ϵ > 0. Thus, gn(ϵ) → 0 only if s
2
n → ∞.
Hence, for a sequence {Xn, n ≥ 1} of independent random variables where
Xn ∼ B(1, pn) distribution, the necessary and sufficient condition for CLT to
hold is s
2
n =
Pn
k=1 pkqk → ∞ as n → ∞. If pn = p, ∀ n ≥ 1, then s
2
n → ∞.
Thus, for a sequence {Xn, n ≥ 1} of independent and identically distributed
random variables where Xn ∼ B(1, p) distribution, CLT always holds. It also
follows from Lindeberg-Levy CLT. □
Example 10.3.3. Suppose {Xn, n ≥ 1} is a sequence of independent random
variables such that Xn ∼ U(−n, n) distribution. We examine whether CLT is
satisfied by {Xn, n ≥ 1}. Observe that
Xk ∼ U(−k, k) ⇒ E(Xk) = µk = 0
V ar(Xk) = k
2
/3 ⇒ s
2
n =
Xn
k=1
k
2
/3 = n(n + 1)(2n + 1)/18 → ∞.CLT for Independent Random Variables 463
Further,
|Xk| ∼ U(0, k) ⇒ E(|X3
k
|) = k
3
/4 ⇒
Xn
k=1
E(|X3
k
|) = n
2
(n + 1)2
/4
⇒
Xn
k=1
E(|Xk − µk|
3
)/s3
n =
Xn
k=1
E(|Xk|
3
)/s3
n → 0.
Thus, Lyapounov’s condition is satisfied for δ = 1 and hence Sn/sn
L
→ Z ∼
N(0, 1) distribution. Thus, CLT holds for the sequence {Xn, n ≥ 1}. Since the
sequence satisfies Lyapounov’s condition, by Lemma 10.3.2 Lindeberg’s con￾dition is also satisfied, which further implies that Feller’s condition is satisfied.
We verify these below. To verify Lindeberg’s condition, we have to examine
whether ∀ ϵ > 0, gn(ϵ) → 0 as n → ∞. Observe that n/sn → 0, which
implies that given ϵ > 0, ∃ n0, such that n < ϵsn for all n ≥ n0. Further,
|Xk| > ϵsn > n for all n ≥ n0 and k = 1, 2, · · · , n. Hence, in view of the fact
that P[|Xn| > n] = 0, P(Bnk) = P[|Xk| > ϵsn] = 0 for all n ≥ n0. Hence as
n → ∞, ∀ ϵ > 0
Z
Ank
x
2
kdFk(xk) → 0
⇒ (1/n)
Xn
k=1
Z
Ank
x
2
kdFk(xk) → 0 by Toeplitz’ lemma
⇒ gn(ϵ) = 1
sn
n
sn
 1
n
Xn
k=1
Z
Ank
x
2
kdFk(xk)

→ 0.
It is easy to check that
max
1≤k≤n
V ar(Xk)/s2
n = (n
2
/3)(18/n(n + 1)(2n + 1) → 0 as n → ∞
and Feller’s condition is satisfied. □
In the next example, we verify by simulation the normal approximation of
Sn/sn shown in Example 10.3.3.
Example 10.3.4. Suppose {Xn, n ≥ 1} is a sequence of independent ran￾dom variables such that Xn ∼ U(−n, n) distribution. In Example 10.3.3
we have examined that the sequence {Xn, n ≥ 1} satisfies CLT and hence
Sn/sn
L
→ Z ∼ N(0, 1) distribution. We verify this result by simulation using
the following code and find the values of n for which normal approximation
is acceptable.
Code 10.3.1. s=c(50,100,150,200);nsim=300; x=p=p1=v=c()
y=matrix(nrow=nsim,ncol=length(s))464 Central Limit Theorem
for(j in 1:length(s))
{
n=s[j]
for(i in 1:nsim)
{
set.seed(i)
for(k in 1:n)
{
x[k]=runif(1,-k,k)
}
v[j]=(n*(n+1)*(2*n+1)/18)^(.5)
y[i,j]=sum(x)/v[j]
}
p1[j]=shapiro.test(y[,j])$p.value
}
d=round(data.frame(s,p1,v),4); d
The output is organized in Table 10.5.
TABLE 10.5
Verification of Lindeberg-Feller
CLT: Xk ∼ U(−k, k)
n p-value sn
50 0.8354 119.6174
100 0.2749 335.8323
150 0.9828 615.4335
200 0.5867 946.3438
From p-values of the Shapiro-Wilk test we note that normal approximation
of Sn/sn is acceptable even for n = 50. We also note that sn increases as n
increases. □
In the next example, we note that Lyapounov’s condition and Lindeberg’s
condition are not satisfied, but Feller’s condition is satisfied.
Example 10.3.5. Suppose {Xn, n ≥ 1} is a sequence of independent random
variables such that P[Xn = ±n] = 1/2n
2 and P[Xn = 0] = 1 − 1/n2
. Hence,
E(Xn) = 0, V ar(Xn) = 1 ⇒ s
2
n =
Xn
k=1
V ar(Xk) = n
E(|Xk|
2+δ
) = k
δ ⇒
Xn
k=1
E(|Xk|
2+δ
) ≈
Z n
0
x
δ
dx =
n
δ+1
δ + 1
.CLT for Independent Random Variables 465
Hence,
1
s
2+δ
n
Xn
k=1
E(|Xk|
2+δ
) = n
δ+1
(δ + 1)nδ/2+1 =
n
δ/2
δ + 1
↛ 0,
since δ > 0. Thus, Lyapounov’s condition is not satisfied. Observe that for
ϵ > 0, with Ank = {xk||xk| > ϵsn},
Z
Ank
x
2
kdFk(xk) > ϵ2
s
2
nP[|Xk| > ϵn] = ϵ
2
s
2
nP[|Xk| ̸= 0] = ϵ
2
s
2
n
(1/k2
)
⇒ gn(ϵ) = (1/s2
n
)
Xn
k=1
Z
Ank
x
2
kdFk(xk) > ϵ2Xn
k=1
(1/k2
)
= ϵ
2A, where A =
Xn
k=1
(1/k2
) < ∞
⇒ gn(ϵ) ↛ 0.
Thus, Lindeberg’s condition is also not satisfied. However, note that
max
1≤k≤n
V ar(Xk)/s2
n = 1/n → 0,
that is, Feller’s condition is satisfied. □
Example 10.3.6. Suppose {Yn, n ≥ 1} and {Zn, n ≥ 1} are independent
sequences of independent random variables such that {Yn, n ≥ 1} is a sequence
of independent and identically distributed random variables with E(Yn) =
0 & V ar(Yn) = 1. {Zn, n ≥ 1} is a sequence of independent random variables
such that P[Zn = n] = P[Zn = −n] = 1/2n
2 and P[Zn = 0] = 1 − 1/n2
.
Thus, E(Zn) = 0 & V ar(Zn) = 1. If Xn is defined as Xn = Yn + Zn, then
{Xn, n ≥ 1} is a sequence of independent random variables and
E(Xn) = 0, V ar(Xn) = 2 & s
2
n =
Xn
k=1
V ar(Xk) = 2n.
Suppose Un =
Pn
k=1 Yk, Vn =
Pn
k=1 Zk and Sn =
Pn
k=1 Xk. {Yn, n ≥ 1} is
a sequence of independent and identically distributed random variables with
positive finite variance 1, hence Un/
√
n
L
→ Z ∼ N(0, 1) distribution by the
Lindeberg-Levy CLT. Further ∀ ϵ > 0,
X∞
n=1
P[|Zn| > ϵ] = X∞
n=1
1/n2 < ∞ ⇒ Zn
a.s. → 0, as n → ∞, by Theorem 6.4.1.
Hence, ∃ N with P(N) = 0 & n0 such that Zn(ω) = 0 ∀ n ≥ n0 and
∀ ω ∈ Nc
. As a consequence, ∀ ω ∈ Nc
,
X∞
k=1
Zk(ω) =
nX0−1
k=1
Zk(ω) + X∞
k=n0
Zk(ω) =
nX0−1
k=1
Zk(ω) = M, say
⇒
X∞
k=1
Zk(ω) = M < ∞ ⇒ X∞
k=1
Zk
a.s. → M.466 Central Limit Theorem
Hence,
Xn
k=1
Zk/
√
n = Vn/
√
n
a.s. → 0
⇒ Sn/
√
n = Un/
√
n + Vn/
√
n
L
→ Z ∼ N(0, 1)
⇒ Sn/
√
2n = Sn/sn
L
→ Z1 ∼ N(0, 1/2).
The second last step follows from Slutsky’s theorem. Further note that,
max1≤k≤n V ar(Xk)/s2
n = 2/2n → 0, which implies that Feller’s condition is
satisfied. Thus, Sn/sn has normal distribution for large n and Feller’s condi￾tion is satisfied and hence by the Lindeberg-Feller CLT, Lindeberg’s condition
must be satisfied. We examine it below. Observe that |Xk| = |Yk| with proba￾bility 1−1/k2
, |Xk| = |Yk +k| with probability 1/2k
2 and |Xk| = |Yk −k| with
probability 1/2k
2
. Hence for any distribution of Yn with mean 0 and variance
1, large k and ϵ = 1/
√
n,
P[|Xk| > ϵ√
2n] = P[|Xk| >
√
2] > 0 ⇒
Z
Ank
x
2
kdFk(xk) > 0
⇒ gn(ϵ) = 1
s
2
n
Xn
k=1
Z
Ank
x
2
kdFk(xk)
>
1
2n
ϵ
2
2n
Z
Ann
1dFn(xn) > ϵ2P(Ann) > 0.
Thus, limn→∞
gn(ϵ) > 0 and hence Lindeberg’s condition is not satisfied. This
result may appear contradictory to the second part of the Lindeberg-Feller
theorem. Note that the Lindeberg-Feller theorem requires the asymptotic nor￾mal distribution of Sn/sn to be the standard normal. In this case it is not
N(0, 1) but N(0, 1/2). Thus, there is no contradiction to the second part of
the Lindeberg-Feller theorem. □
Following example illustrates that neither Lindeberg’s condition nor
Feller’s condition is necessary for normality of Sn. It also illustrates that if
one the two results in (10.5) is not satisfied, then Lindeberg’s condition is not
satisfied.
Example 10.3.7. Suppose {Xn, n ≥ 1} is a sequence of independent random
variables where Xn ∼ N(0, θn) distribution, θ > 1. Suppose Sn =
Pn
k=1 Xk,
then V ar(Sn) is given by s
2
n =
Pn
k=1 θ
k = θ(θ
n − 1)/(θ − 1). Thus, for each
n ≥ 1, Sn ∼ N(0, s2
n
) distribution. Hence, Sn/sn
L
→ Z ∼ N(0, 1) distribution
and we do not need any CLT to claim normality of Sn/sn for large n. Observe
that
max
1≤k≤n
V ar(Xk)
s
2
n
= max
1≤k≤n
θ
k
s
2
n
=
θ
n(θ − 1)
θ(θ
n − 1) =
θ − 1
θ
1
(1 − θ−n)
→
θ − 1
θ
.CLT for Independent Random Variables 467
Thus, Feller’s condition is not satisfied. As a consequence Lindeberg’s condi￾tion is also not be satisfied. We verify it below. Observe that k = 1, 2, · · · , n
and ∀ ϵ > 0,
P[|Xk| > ϵsn] = P[|Xk|/σk > ϵsn/σk]
= [1 − Φ (ϵsn/σk) + Φ (−ϵsn/σk)] > 0,
since Xk/σk ∼ N(0, 1) distribution, where σk = θ
k/2
. Hence, taking only the
last term from gn(ϵ), we have
gn(ϵ) = 1
s
2
n
Xn
k=1
Z
Ank
x
2
kdFk(xk) >
Z
Ann
x
2
n
s
2
n
dFn(xn)
> ϵ2
Z
Ann
dFn(xn) = ϵ
2P[|Xn| > ϵsn]
= ϵ
2P [|Xn|/σn > ϵsn/σn]
= ϵ
2
[1 − Φ (ϵsn/σn) + Φ (−ϵsn/σn)]
→ ϵ
2
h
1 − Φ(p
θ1ϵ) + Φ(−
p
θ1ϵ)
i
̸= 0 where θ1 = θ/(θ − 1).
Thus, Lindeberg’s condition is not satisfied and hence Lyapounov’s condition
is not satisfied. □
Remark 10.3.3. In the statement of Lindeberg-Feller CLT, we have noted
that Equation (10.4) implies Equation (10.5), which consists of two results.
Hence, if at least one the two results in (10.5) is not satisfied, then Equa￾tion (10.4) is not satisfied. Example 10.3.7 supports this statement as in
this example Sn/sn
L
→ Z ∼ N(0, 1) distribution, but the second result is
not satisfied, since maxk≤n σ
2
k
/s2
n → (θ − 1)/θ. Thus, one the two results in
(10.5) is not satisfied and hence (10.4) is not satisfied. It is to be noted that
Sn/sn
L
→ Z ∼ N(0, 1) distribution, in view of the fact that Xn for each n has
normal distribution. Observe that in this example σ
2
n and s
2
n both increase to
∞ very fast, at the same rate of θ
n. As a consequence, σ
2
n/s2
n
converges to a
constant (θ − 1)/θ.
In the following example, none of the three conditions are satisfied, but
still asymptotic distribution of Sn/sn is normal.
Example 10.3.8. Suppose {Xn, n ≥ 1} is a sequence of independent random
variables where Xn ∼ N(0, 2
−n) distribution. Then Sn =
Pn
k=1 Xk follows
N(0, s2
n
) distribution where s
2
n = V ar(Sn) = Pn
k=1 2
−k = (1 − 2
−n) ∀ n ≥ 1.
Hence Sn/sn
L
→ Z ∼ N(0, 1) distribution. Observe that s
2
n ↑ 1 and
max
1≤k≤n
V ar(Xk)/s2
n = max
1≤k≤n
2
−k
/s2
n = (1/2)/(1 − 2
−n
) → 1/2.
Thus, Feller’s condition is not satisfied which implies that Lindeberg’s condi￾tion is not satisfied, which further implies that Lyapounov’s condition is not468 Central Limit Theorem
satisfied. We verify these below. We now examine whether Lindeberg’s condi￾tion is satisfied. Since Xk ∼ N(0, 2
−k
) distribution, P[|Xk| > ϵsn] > 0 for all
k = 1, 2, · · · , n. Hence,
gn(ϵ) = 1
s
2
n
Xn
k=1
Z
Ank
x
2
kdFk(xk) >
Z
An1
x
2
1
s
2
n
dFn(x1)
> ϵ2
Z
An1
dFn(x1) = ϵ
2P[|X1| > ϵsn] > 0.
Note that in this case s
2
n → 1. Thus, Lindeberg’s condition is not satisfied. We
show below that Lyapounov’s condition is not satisfied for δ = 2. Note that,
E(X4
k
) = 3 × 2
−2k ⇒
Xn
k=1
E(X4
k
) = 1 − 4
−n
⇒
1
s
4
n
Xn
k=1
E(|Xk|
4
) = (1 − 4
−n)
(1 − 2−n)
2 → 1.
Thus, Lyapounov’s condition is not satisfied for δ = 2. □
We have proved at the beginning of this section that if Feller’s condition
is satisfied, then s
2
n → ∞. In the above example, s
2
n → 1 and none of the
three conditions is satisfied, still Sn/sn
L
→ Z ∼ N(0, 1) distribution. It is to
be noted that normality of Sn/sn results from that fact that Xn has normal
distribution for each n.
It is proved that if s
2
n ↑ s
2 < ∞, then each Xk in the sum Sn must have a
normal distribution, refer to p.340 of Gut [13]. As a consequence Sn will have
a normal distribution and there is nothing to prove. Thus, in order to obtain
non-trivial results, it is necessary that s
2
n → ∞.
As in Example 10.3.8, in the next example also, none of the conditions are
satisfied, under certain setup.
In a birth process and in a birth-death process, we come across with a se￾quence of independent but not identically distributed random variables. Sup￾pose Xi denotes the sojourn time in state i ≥ 1 of a birth process with birth
rates {λi
, i ≥ 1}. Then {Xi
, i ≥ 1} is a sequence of independent random vari￾ables and Xi follows exponential distribution with scale parameter λi
, i ≥ 1.
The distribution of Sn =
Pn
i=1 Xi
is known as a hypoexponential distribution.
In the next two examples, we examine whether {Xi
, i ≥ 1} satisfies CLT for
two different sets of birth rates.
Example 10.3.9. Suppose {Xn, n ≥ 1} is a sequence of independent random
variables such that Xn follows exponential distribution with rate parameter
nλ. Observe that from the moment generating function (1 − t/nλ)
−1 of Xn,
E(Xk) = µk = 1/kλ, V ar(Xk) = 1/(kλ)
2 ⇒s
2
n = (1/λ2
)
Xn
k=1
(1/k2
)
E(X4
k
) = 4!/(kλ)
4 ⇒µ4 = E(|Xk − µk|
4
) = 9/(kλ)
4
.CLT for Independent Random Variables 469
It is to be noted that P∞
k=1(1/k2
) is a convergent series. Thus, s
2
n → s < ∞,
where s is a positive real number. Hence,
max
1≤k≤n
V ar(Xk)/s2
n = 1/(λ
2
s
2
n
) → 1/(λ
2
s) ̸= 0
which implies that Feller’s condition is not satisfied. In Lemma 10.3.1, we
have proved that Feller’s condition implies that s
2
n → ∞. Thus, s
2
n → s < ∞
implies that Feller’s condition is not satisfied. By Equation (10.5), it further
implies that Lindeberg’s condition will not be satisfied and hence Lyapounov’s
condition is also not satisfied. Observe that, P∞
k=1(1/k4
) is a convergent series.
Hence,
Xn
k=1
E(|Xk − µk|
4
)/s4
n = 9Xn
k=1
(1/k4
)/(
Xn
k=1
(1/k2
))2 ↛ 0,
being a ratio of two non-negative real numbers. Thus, Lyapounov’s condition
is not satisfied for δ = 2 and hence will not be satisfied for any δ > 2. We
have thus shown that for a sequence {Xn, n ≥ 1}, none of the conditions are
satisfied. As a consequence, Sn/sn
L↛ Z ∼ N(0, 1). Using the following code
we show that when λ = 0.05, even for n = 1000 or n = 2000, normality of
Sn/sn is not acceptable, based on the p-values of Shapiro-Wilk test.
Code 10.3.2. la=.05; s=c(1000,2000);nsim=500; x=p=p1=v=mu=a=c()
y=matrix(nrow=nsim,ncol=length(s))
for(j in 1:length(s))
{
n=s[j]
for(i in 1:nsim)
{
set.seed(i)
for(k in 1:n)
{
x[k]=rexp(1,rate=k*la)
mu[k]=1/k*la
v[k]=1/(k*la)^2
}
a[j]=sum(v)^(.5)
y[i,j]=sum(x-mu)/a[j]
}
p1[j]=shapiro.test(y[,j])$p.value
}
d=round(data.frame(s,p1,a),4); d470 Central Limit Theorem
TABLE 10.6
Hypoexponential Distribution:
p-values
n p-value sn
1000 0 25.6432
2000 0 25.6471
The output is organized in Table 10.6. From Table 10.6, we note that for
n = 1000 and n = 2000, p-value of the Shapiro-Wilk test is 0. Further, sn
stabilizes at 25.64. □
In the next example, we take λi = λ/√
i and show that all the three
conditions are satisfied, thus the scenario of Example 10.3.9 changes as birth
rates change.
Example 10.3.10. Suppose {Xn, n ≥ 1} is a sequence of independent ran￾dom variables such that Xn follows exponential distribution with rate param￾eter λ/√
n. Then,
E(Xk) = µk =
√
k/λ, V ar(Xk) = k/λ2 ⇒ s
2
n =
Xn
k=1
k/λ2
= n(n + 1)/2λ
2 → ∞.
Further observe that,
E(X4
k
) = 4!k
2
/λ4 ⇒ µ4 = E(|Xk − µk|
4
) = 9k
2
/λ4
⇒
Xn
k=1
E(|Xk − µk|
4
)/s4
n = 36Xn
k=1
k
2
/(n(n + 1))2
= 6(2n + 1)/n(n + 1) → 0.
Thus, Lyapounov’s condition is satisfied with δ = 2 and hence for all δ <
2. Hence by Lyapounov’s CLT, Sn/sn
L
→ Z ∼ N(0, 1) distribution. Since
the sequence satisfies Lyapounov’s condition, Lindeberg’s condition is also
satisfied, which further implies that Feller’s condition is satisfied. We verify
Feller’s condition below. It is easy to see that
max
1≤k≤n
V ar(Xk)/s2
n = 2n/n(n + 1) → 0 as n → ∞
and Feller’s condition is satisfied. Using the following code, we examine nor￾mality of Sn/sn for four values of n, based on the p-values of Shapiro-Wilk
test.
Code 10.3.3. la=.05; s=c(100,200,300,400);nsim=200;
x=p=p1=v=mu=a=c()
y=matrix(nrow=nsim,ncol=length(s))
for(j in 1:length(s))CLT for Independent Random Variables 471
{
n=s[j]
for(i in 1:nsim)
{
set.seed(i)
for(k in 1:n)
{
x[k]=rexp(1,rate=la/k^(.5))
mu[k]=k^(.5)/la
v[k]=k/la^2
}
a[j]=sum(v)^(.5)
y[i,j]=sum(x-mu)/a[j]
}
p1[j]=shapiro.test(y[,j])$p.value
}
d=round(data.frame(s,p1,a),4); d
TABLE 10.7
Lindeberg-Feller CLT: Hypoex￾ponential Distribution
n p-value sn
100 0.1502 1421.267
200 0.8754 2835.489
300 0.6770 4249.706
400 0.4665 5663.921
The output is organized in Table 10.7. From p-values of the Shapiro-Wilk
test we note that normal approximation of Sn/sn is acceptable. The values of
sn increase as n increases, as expected. □
We summarize below the results discussed in this chapter.
Summary
1. Lindeberg-Levy CLT: Suppose {Xn, n ≥ 1} is a sequence of independent
and identically distributed random variables with mean µ and positive,
finite variance σ
2
, then √
n(Xn − µ)/σ L
→ Z ∼ N(0, 1).
2. Random sum CLT: Suppose {Xn, n ≥ 1} is a sequence of independent
and identically distributed random variables with mean 0 and variance472 Central Limit Theorem
1. Suppose {N(t), t ≥ 0} is a family of positive integer valued random
variables where N(t)
a.s. → ∞ such that N(t)/t P
→ c, where c ∈ (0, ∞) is
a constant. Then as t → ∞,
PN(t)
i=1 Xi/
p
N(t)
L
→ Z ∼ N(0, 1).
3. Multivariate CLT: Suppose X is a k dimensional random vector with mean
vector E(X) = µ and dispersion matrix Σ, which is positive definite.
Suppose {X1
, X2
, · · · , Xn
} are independent and identically distributed
random vectors each distributed as X. Suppose Xn denotes the sample
mean vector, then √
n(Xn − µ)
L
→ U ∼ Nk(0, Σ) distribution as n → ∞.
4. Suppose {Xn, n ≥ 1} is a sequence of independent random variables such
that E(Xk) = µk, V ar(Xk) = σ
2
k < ∞ and Fk is a distribution function of
Xk, k = 1, 2, · · · , n. Suppose Sn =
Pn
k=1(Xk − µk) and s
2
P n = V ar(Sn) =
n
k=1 σ
2
k
. Then Lyapounov’s condition, Lindeberg’s condition and Feller’s
condition are as follows.
(i) Lyapounov’s condition: Pn
k=1 E(|Xk−µk|
2+δ
)/s2+δ
n → 0 as n → ∞,
for some δ > 0.
(ii) Lindeberg’s condition: With Ank = {xk|xk − µk| > ϵsn}, ∀ ϵ > 0,
gn(ϵ) = 1
s
2
n
Xn
k=1
Z
Ank
(xk − µk)
2
dFk(xk) → 0 as n → ∞.
(iii) Feller’s condition: maxk≤n σ
2
k
/s2
n → 0 as n → ∞.
5. Lyapounov’s condition implies Lindeberg’s condition and Lindeberg’s con￾dition implies Feller’s condition
6. Lindeberg-Feller CLT: Suppose {Xn, n ≥ 1} is a sequence of independent
random variables such that E(Xk) = µk, V ar(Xk) = σ
2
k
and Fk is a distri￾bution function of Xk. Suppose Sn =
Pn
k=1(Xk−µk) and s
2
n = V ar(Sn) =
Pn
k=1 σ
2
k
. If ∀ ϵ > 0, gn(ϵ) → 0, then Sn/sn
L
→ Z ∼ N(0, 1) and
maxk≤n σk/sn → 0. Conversely if Sn/sn
L
→ Z ∼ N(0, 1) and Feller’s
condition is satisfied, then Lindeberg’s condition is satisfied.
7. Lyapounov’s CLT: Suppose {Xn, n ≥ 1} is a sequence of independent
random variables with mean µk and V ar(Xk) = σ
2
P
k > 0. Suppose Sn =
n
k=1(Xk − µk) and s
2
n = V ar(Sn) = Pn
k=1 σ
2
k
. In addition, suppose
E(|Xk − µk|
2+δ
) > 0 for some δ > 0. Then Sn/sn
L
→ Z ∼ N(0, 1) if
Xn
k=1
E(|Xk − µk|
2+δ
)/s2+δ
n → 0 for some δ > 0.Conceptual Exercises 473
10.4 Conceptual Exercises
10.4.1 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables, each having P(λ) distribution. Suppose
Sn =
Pn
i=1 Xi
. Find limn→∞ P[Sn ≤ nλ +
√
nλ].
10.4.2 Suppose {Xn, n ≥ 1} is a sequence of independent and identically dis￾tributed random variables, each having Pareto-type distribution, with
probability density function f(x) = c/(|x|
3
(log |X|)
2
) for |x| > 2 and
0 otherwise, where c is a normalizing constant. Examine whether the
sequence satisfies CLT. Examine whether one can verify Lyapounov’s
condition.
10.4.3 Prove that limn→∞ e
−n Pn
i=0 n
i/i! = 1/2.
10.4.4 Evaluate limn→∞ P[nq/p]
i=0 ￾
i+k−1
i

p
k
q
i−k
, where 0 < p < 1 and q =
1 − p.
10.4.5 Examine whether (Xn − E(Xn))/
p
V (Xn)
L
→ Z ∼ N(0, 1) as n → ∞,
if Xn ∼ G(α, n), where n is a natural number.
10.4.6 Evaluate limn→∞ R n/α+2√
n/α
0
α
n
Γ(n)
x
n−1
e
−αx dx.
10.4.7 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables each having standard normal distribution.
Suppose Yn =
Pn
i=1 X2
i
. Show that (Yn − n)/
p
(2n)
L
→ Z ∼ N(0, 1).
What is the distribution of (Yn − n)
2/(2n) for large n? Justify.
10.4.8 Suppose X ∼ P(λ), λ > 0. Prove that for large λ, distribution of
(X − λ)
2/λ can be approximated by the chi-square distribution.
10.4.9 Suppose {Xn, n ≥ 1} is a sequence of independent and identically dis￾tributed random variables, each following U(0, θ) distribution, θ > 0.
Suppose Sn = (Qn
i=1 Xi)
1/n. Find the non-degenerate limiting distri￾bution of √
n(Sn − θe−1
).
10.4.10 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed positive random variables. Suppose Sn = (Qn
i=1 Xi)
1/n
.
Find the non-degenerate limiting distribution of suitably normalized
Sn.
10.4.11 Suppose {Xn, n ≥ 1} is a sequence of independent and identically dis￾tributed random variables, each following a Poisson P(θ) distribution.
Find the non-degenerate limiting distribution of suitably normalized
sample variance474 Central Limit Theorem
10.4.12 Suppose Xn ∼ B(n, p), 0 < p < 1, n ≥ 1 and Yn = log(Xn/n) if
Xn ̸= 0 and Yn = 1 if Xn = 0. Show that √
n(Yn − log p)
L
→ Z1 ∼
N(0, q/p), where q = 1 − p.
10.4.13 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
with P[Xn = ±n] = n
−λ/2 and P[Xn = 0] = 1 − n
−λ
, λ > 0. Show
that Liapounov’s condition for the central limit theorem holds for this
sequence for some λ.
10.4.14 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
with P[Xn = ±n
λ
] = 1/2. Examine whether Liapounov’s condition,
Lindeberg’s condition and Feller’s condition are satisfied. Examine if
CLT holds for some values of λ.
10.4.15 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
such that for α ≥ 1/2,
P[Xn = ±n
α
] = n
1−2α
/2 & P[Xn = 0] = 1 − n
1−2α
, n ≥ 1.
Show that ∀ α ∈ [1/2, 1), Sn/sn
L
→ Z ∼ N(0, 1).
10.4.16 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
such that Xk ∼ U(0, k) distribution. Suppose Yk = Xk/n1/2
,
k = 1, 2, · · · , n, n ≥ 1. Show that {Yk, k ≥ 1} satisfies Liapounov’s,
Lindeberg’s and Feller’s conditions and hence CLT is valid for
Sn =
Pn
k=1(Yk − E(Yk)).
10.5 Computational Exercises
10.5.1 Verify conceptual exercise 10.4.3 by simulation.
10.5.2 Suppose Xn ∼ B(n, p) 0 < p < 1, n ≥ 1 and Yn = log(Xn/n) if Xn = 1
and Yn = 1 if Xn = 0. By simulation verify that √
n(Yn − log p)
L
→
Z1 ∼ N(0, q/p), where q = 1 − p.
10.5.3 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables, each following U(0, θ) distribution, θ >
0. Suppose Sn = (Qn
i=1 Xi)
1/n. By simulation verify that the non￾degenerate limiting distribution of √
n(Sn − θe−1
) is normal.
10.5.4 Suppose X ∼ P(λ), λ > 0. Verify by simulation that for large λ,
distribution of (X − λ)
2/λ can be approximated by the chi-square dis￾tribution.Multiple Choice Questions 475
10.6 Multiple Choice Questions
Note: In each question, multiple options may be correct. Unless specified
otherwise, identify which of the statement(s) is/are correct. Answers are given
in Chapter 11, after the solutions of conceptual exercises of Chapter 10.
10.6.1 A sequence {Xn, n ≥ 1} of random variables is said to obey a CLT, if
there exists two sequences {an, n ≥ 1} of real numbers and {bn, n ≥ 1}
of positive real numbers, with bn → ∞, such that n → ∞,
(a) Sn−an
bn
a.s. → Z where Z ∼ N(0, 1) and Sn =
Pn
i=1 Xi
(b) Sn−an
bn
P
→ Z
(c) Sn−an
bn
q.m. → Z
(d) Sn−an
bn
L
→ Z
10.6.2 A sequence {Xn, n ≥ 1} of random variables satisfies a CLT, if
(a) Sn−an
bn
a.s. → Z where Z ∼ N(0, 1)
(b) Sn−an
bn
P
→ Z
(c) Sn−an
bn
q.m. → Z
(d) Sn−an
bn
L
→ Z, where Sn =
Pn
i=1 Xi
, {an, n ≥ 1} is a sequence of
real numbers and {bn, n ≥ 1} is a sequence of positive real numbers
with bn → ∞ as n → ∞
10.6.3 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
and Sn =
Pn
k=1 Xk, s
2
n =
Pn
k=1 V (Xk). Then (Sn − E(Sn)/sn
L
→ Z ∼
N(0, 1), if
(a) Xn ∼ Binomial(5, 0.3)
(b) Xn ∼ t(2)
(c) Xn ∼ Beta(1, 1)
(d) Xn ∼ G(α, n), with scale parameter α and shape parameter n.
10.6.4 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables and Sn =
Pn
k=1 Xk. s
2
n =
Pn
k=1 V (Xk).
Then (Sn − E(Sn)/sn
L
→ Z ∼ N(0, 1) if
(I) Xn ∼ Binomial(5, 0.3). (II) Xn ∼ t(2). (III) Xn ∼ Beta(1, 1).
(IV) Xn ∼ G(α, n), with scale parameter α and shape parameter n.
Which of the following is correct?
(a) (I) and (II)
(b) (I) and (III)
(c) (II) and (III)
(d) (I) and (IV).476 Central Limit Theorem
10.6.5 (X − E(X))/
p
V (X)
L
→ Z ∼ N(0, 1) as n → ∞, if
(a) X ∼ Poisson(n)
(b) X ∼ χ
2
n
(c) X ∼ Gamma(α, n)
(d) X ∼ N(µ, σ2/n)
10.6.6 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables with mean 0 and variance 1. Which of
the following is/are correct?
(a) √
nXn
L
→ U, where U has normal distribution
(b) √
nX
2
n
L
→ U, where U has chi-square distribution
(c) nX
2
n
L
→ U, where U has chi-square distribution
(d) √
nX
2
n
P
→ U, where distribution of U is degenerate at 0
10.6.7 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables with mean 0 and variance 1. Which of
the following statements is not correct?
(a) √
nXn
L
→ U, where U has normal distribution
(b) √
nX
2
n
L
→ U, where U has chi-square distribution
(c) nX
2
n
L
→ U, where U has chi-square distribution
(d) √
nX
2
n
P
→ U, where distribution of U is degenerate at 0
10.6.8 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables with mean 0 and variance 1. Which of
the following is/are correct?
(a) √
nX
2
n
L
→ U, where U has normal distribution
(b) √
nX
2
n
L
→ U, where U has chi-square distribution
(c) √
nX
2
n
L
→ U, where distribution of U is degenerate at 0
(d) √
nX
2
n
P
→ U, where distribution of U is degenerate at 0
10.6.9 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables with mean 0 and finite moment of order
4. Suppose m′
1
, m′
2 denote the sample raw moments of order 1 and
2 respectively and µ
′
2 denote the population raw moment of order 2.
Which of the following is/are correct?
(a) √
n(m′
2 − µ
′
2
)
L
→ U, where U has normal distribution
(b) √
n(m′
2 − µ
′
2
)m′
1
L
→ U, where U has normal distribution
(c) √
n(m′
2 − µ
′
2
)µ
′
1
L
→ U, where distribution of U is degenerate at 0
(d) m′
2m′
1
P
→ U, where distribution of U is degenerate at 0Multiple Choice Questions 477
10.6.10 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
with E(Xk) = 0, V ar(Xk) = σ
2
k < ∞, k = 1, 2, · · · , n. Suppose
Sn =
Pn
k=1 Xk, s2
n = V ar(Sn) = Pn
k=1 σ
2
k
. Then Lyapounov’s condi￾tion for Sn/sn
L
→ Z ∼ N(0, 1) is
(a) Pn
k=1 E(|Xk|
2+δ
)/s2+δ
n → ∞ ∀ δ > 0 as n → ∞
(b) Pn
k=1 E(|Xk|
2+δ
)/s2+δ
n → 0 for some δ > 0 as n → ∞
(c) Pn
k=1 E(|Xk|
2
)/s2+δ
n → 0 for some δ > 0 as n → ∞
(d) Pn
k=1 E(|Xk|
2+δ
)/s2
n → 0 for some δ > 0 as n → ∞
10.6.11 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
with E(Xk) = 0, V ar(Xk) = σ
2
k < ∞, k = 1, 2, · · · , n. Suppose
Sn =
Pn
k=1 Xk, s2
n =
Pn
k=1 σ
2
k
and Bnk = [|Xk| >
ϵsn], k = 1, 2, · · · , n, ϵ > 0. Then Lindeberg’s condition for
Sn/sn
L
→ Z ∼ N(0, 1) is
(a) (1/s2
n
)
Pn
k=1 E
￾
X2
k
IBnk 
→ 1 as n → ∞, ∀ ϵ > 0
(b) (1/s2
n
)
Pn
k=1 E
￾
X2
k
IBnk 
→ 0 as n → ∞, for some ϵ > 0
(c) (1/s2
n
)
Pn
k=1 E
￾
X2
k
IBnk 
→ 0 as n → ∞, ∀ ϵ > 0
(d) (1/s2
n
)
Pn
k=1 E (|Xk|IBnk ) → 0 as n → ∞, ∀ ϵ > 0
10.6.12 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
such that E(Xk) = 0, V ar(Xk) = σ
2
k < ∞, k = 1, 2, · · · , n. Suppose
Sn =
Pn
k=1 Xk and s
2
n = V ar(Sn) = Pn
k=1 σ
2
k
, k = 1, 2, · · · , n. Then
Feller’s condition is
(a) maxk≤n σ
2
k
/s2
n → 0 as n → ∞
(b) maxk≤n σ
2
k
/s2
n → 1 as n → ∞
(c) maxk≤n σ
2
k
/sn → 0 as n → ∞
(d) mink≤n σ
2
k
/s2
n → 0 as n → ∞
10.6.13 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
such that E(Xk) = 0, V ar(Xk) = σ
2
k < ∞, k = 1, 2, · · · , n. Following
are two statements related to conditions for asymptotic normality of
Sn =
Pn
k=1 Xk. (I) Lyapounov’s condition implies Lindeberg’s condi￾tion. (II) Lindeberg’s condition implies Feller’s condition.
(a) Both (I) and (II) are false
(b) Both (I) and (II) are true
(c) (I) is true but (II) is false
(d) (I) is false but (II) is true
10.6.14 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
such that E(Xk) = 0, V ar(Xk) = σ
2
k < ∞, k = 1, 2, · · · , n. Following
are two statements related to conditions for asymptotic normality of
Sn =
Pn
k=1 Xk. (I) Lyapounov’s condition implies Feller’s condition.
(II) Lindeberg’s condition implies Lyapounov’s condition.
(a) Both (I) and (II) are fa478 Central Limit Theorem
(b) Both (I) and (II) are true
(c) (I) is true but (II) is false
(d) (I) is false but (II) is true
10.6.15 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
such that E(Xk) = 0, V ar(Xk) = σ
2
k < ∞, k = 1, 2, · · · , n. Following
are two statements related to conditions for asymptotic normality of
Sn =
Pn
k=1 Xk. (I) If Feller’s condition is not satisfied then Lya￾pounov’s condition is also not satisfied. (II) Lyapounov’s condition is
not satisfied then Lindeberg’s is also not satisfied.
(a) Both (I) and (II) are false
(b) Both (I) and (II) are true
(c) (I) is true but (II) is false
(d) (I) is false but (II) is true
10.6.16 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
such that E(Xk) = 0, V ar(Xk) = σ
2
k < ∞, k = 1, 2, · · · , n. Following
are two statements related to conditions for asymptotic normality of
Sn =
Pn
k=1 Xk. (I) If Feller’s condition is satisfied then V ar(Sn) → 0.
(II) If Lindeberg’s condition is satisfied then V ar(Sn) → 0.
(a) Both (I) and (II) are false
(b) Both (I) and (II) are true
(c) (I) is true but (II) is false
(d) (I) is false but (II) is true
10.6.17 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
such that E(Xk) = 0, V ar(Xk) = σ
2
k < ∞, k = 1, 2, · · · , n and
s
2
n = V ar(Sn), where Sn =
Pn
k=1 Xk. Following are two statements re￾lated to conditions for asymptotic normality of Sn. P[max1≤k≤n |Xk| >
ϵsn] → 0 ∀ ϵ > 0 as n → ∞ (I) if Lyapounov’s condition is satisfied
(II) if Lindeberg’s condition is satisfied .
(a) Both (I) and (II) are false
(b) Both (I) and (II) are true
(c) (I) is true but (II) is false
(d) (I) is false but (II) is true11
Solutions to Conceptual Exercises
11.1 Chapter 1
1.6.1 Verify whether the following sequences of the sets are monotone.
(i) {(a −
1
n
, b +
1
n
)}, n = 1, 2, . . .. (ii) {(a +
1
n
, b −
1
n
)}, n = 1, 2, . . ..
(iii) {(a +
1
n
, b +
1
n
)}, n = 1, 2, . . .. (iv) Suppose {An} is a sequence of
the sets defined as An = {(x, y)|0 ≤ x ≤ n, 0 ≤ y ≤ 1/n}.
Solution: Sequence in (i) is decreasing while in (ii) is increasing. (iii)
and (iv) are not monotone.
1.6.2 For the following sequences {An, n ≥ 1} of sets, examine whether it has
a limit. If yes, find it.
(i) An = (a − 1/n, a + 1/n), (ii)An = [a − 1/n, a + 1/n],
(iii) An = (a − 1/n, a + 1/n], (iv) An = [a − 1/n, a + 1/n),
(v) An = (a − 1/n, a], (vi) An = (a, b + 1/n), (vii) An = (a, b + 1/n],
(viii) An = [a, b + 1/n), (ix) An = [a, b + 1/n], (x) An = (a, b − 1/n),
(xi) An = (a, b − 1/n], (xii) An = [a, b − 1/n), (xiii) An = [a, b − 1/n],
(xiv) An = (a − 1/n, b + 1/n), (xv) An = [a − 1/n, b + 1/n],
(xvi) An = (a − 1/n, b + 1/n], (xvii) An = [a − 1/n, b + 1/n).
Solution: For the first four sequences, limit exists and is {a}. (v) {a},
(vi),(vii) (a, b],(viii) [a, b], (ix) [a, b], (x),(xi) (a, b), (xii),(xiii) [a, b). For
the last four sequences limit exists and is [a, b].
1.6.3 For the following sequences {An, n ≥ 1} of sets examine whether it has
a limit. If yes, find it.
(i) An =

(0, 1/n), if n is odd
(−1/n, 1/n), if n is even.
(ii) An =

(0, 1/n), if n is odd
(1 − 1/n, 1), if n is even.
(iii) An =

(0, 1 − 1/n), if n is odd
(1/n, 1), if n is even.
DOI: 10.1201/9781032619057-11 479480 Solutions to Conceptual Exercises
(iv) An =
 ￾
2 −
1
n
, 2 + 1
n

, if n is odd
∅, if n is even.
(v) An =
 ￾
2 −
1
n
, 2

, if n is odd
∅, if n is even.
(vi) An = {0, 1/n, 2/n, · · · , 1 − 1/n, 1}.
(vii) An : set of rationals in 
1 −
1
n+1 , 1 + 1
n
i
,
(viii) A2n =
￾
0,
1
2n

, A2n+1 =
h
−1,
1
2n+1 i
, A1 = [−1, 1],
(ix) An: set of rationals in (1 −
1
n
, 1 + 1
n
).
Solution: (i) By the definition, lim sup An =
T
n≥1
S
k≥n Ak =
T
n≥1 Cn
where Cn =
S
k≥n Ak. Hence, for n = 2m,
C2m = (−1/(2m), 1/(2m))∪(0, 1/(2m+1))∪(−1/(2m+2), 1/(2m+2)· · ·
which is (−1/(2m), 1/(2m)). For n = 2m − 1,
C2m−1 =
S
k≥2m−1 Ak = (0, 1/(2m−1))∪(−1/(2m), 1/(2m))· · · which
is (−1/2m, 1/(2m − 1)). Hence, lim sup An =
T
n≥1 Cn = (−1/2, 1) ∩
(−1/4, 1/4) ∩ (−1/6, 1/5] · · · = {0} Now, lim inf An =
S
n≥1
T
k≥n Ak = S
n≥1 Bn where Bn =
T
k≥n Ak. For n = 2m,
B2m = (−1/(2m), 1/(2m)) ∩ (0, 1/(2m + 1)) ∩ (−1/(2m + 2), 1/(2m +
2)· · · , which is ∅. For n = 2m − 1,
B2m−1 =
T
k≥2m−1 Ak = (0, 1/(2m − 1)) ∩ (−1/(2m), 1/(2m))· · · = ∅.
Hence, lim inf An = ∅ which implies that lim An does not exist.
(ii) We proceed as in (i) and note that
C2m =
[
k≥2m
Ak = (1 − 1/2m, 1) ∪ (0.1/(2m + 1)· · · = (0, 1)
C2m−1 =
[
k≥2m−1
Ak = (0, 1/(2m − 1)) ∪ (1 − 1/(2m), 1)· · · = (0, 1).
Hence, lim sup An = (0, 1). Similarly,
B2m =
\
k≥2m
Ak = (1 − 1/2m, 1) ∩ (0.1/(2m + 1)· · · = ∅
B2m−1 =
\
k≥2m−1
Ak = (0, 1/(2m − 1)) ∩ (1 − 1/(2m), 1)· · · = ∅.
Hence, lim inf An = ∅ and lim An does not exist.
(iii) Observe that A1 = ∅, A2 = (1/2, 1), A3 = (0, 2/3), A4 =
(1/4, 1), A5 = (0, 4/5), A6 = (1/6, 1)· · · Hence, Cn = (0, 1) ∀ n ≥ 1
which implies that lim sup An = (0, 1). Now note that B1 = ∅, B2 =
(1/2, 2/3), B3 = (1/4, 2/3), B4 = (1/4, 4/5), B5 = (1/6, 4/5). Hence,
lim inf An = (0, 1) which implies that lim An exists and is (0, Chapter 1 481
(iv) By definition, lim inf An =
S
n≥1
T
k≥n Ak =
S
n≥1
∅ = ∅. Now,
lim sup An =
T
n≥1
S
k≥n Ak. Suppose n is odd. Then
[
k≥n
Ak =

2 −
1
n
, 2 +
1
n

∪ ∅ ∪ 
2 −
1
n + 2
, 2 +
1
n + 2
· · ·
=

2 −
1
n
, 2 +
1
n

.
Hence, lim sup An =
T
n≥1
￾
2 −
1
n
, 2 + 1
n

= [2, 2] = {2}. Thus, lim An
does not exist.
(v) With Cn =
S
k≥n Ak, note that
C1 = (1, 2) ∪ ∅ ∪ (5/3, 2)∅ ∪ (9/5, 2)· · · = (1, 2)
C2 = ∅ ∪ (5/3, 2)∅ ∪ (9/5, 2)· · · = (5/3, 2)
C3 = (5/3, 2)∅ ∪ (9/5, 2)· · · = (5/3, 2) = C2.
Thus, we get C2m = C2m+1 = (2−1/(2m+ 1), 2) ∀ m ≥ 1. Note that it
is decreasing sequence with limit ∩Cn = ∅. Hence lim sup An = ∅. Since
for odd values of n, An = ∅, Bn =
T
k≥n Ak = ∅. Hence lim inf An = ∅.
Thus, limit of the sequence exists and it is ∅.
(vi) It is given that An = {0, 1/n, 2/n, · · · , 1 − 1/n, 1}. Note that any
rational number in [0, 1] can be written as p/q where p and q are integers
such that 0 ≤ p ≤ q ≤ 1. Thus, p/q ∈ Aq, q ∈ N. To find lim sup An = T
n≥1 Cn, observe that
C1 = A1 ∪ A2 ∪ A3 ∪ · · · = {0, 1} ∪ {0, 1/2, 1} ∪ {0, 1/3, 2/3, 1} ∪ · · ·
which is a set of all rational numbers in [0, 1]. Now, A1 ⊂ A2 which
implies that A2 = A1 ∪ A2. Hence,
C2 = A2 ∪ A3 ∪ · · · = {0, 1/2, 1} ∪ {0, 1/3, 2/3, 1} ∪ · · · = C1.
Note that, 1/2 = 2/4 ∈ A4 hence,
C3 = A3 ∪ A4 · · · = {0, 1/3, 2/3, 1} ∪ {0, 1/4, 2/4, 3/4, 1} ∪ · · · = C1.
Similarly, 1/3 = 2/6 ∈ A6, 2/3 = 4/6 ∈ A6, 1/2 = 2/4 ∈ A4 implies
that C4 = C1. In general, any number of the form p/q can be writ￾ten as 2p/2q ∈ A2q or 3p/3q ∈ A3q. Proceeding on these lines we get
Cn = C1 ∀ n ≥ 1. Hence, lim sup An =
T
n≥1 Cn = C1. We now find
lim inf An =
S
n≥1 Bn, where Bn =
T
k≥n Ak. Observe that B1 = {0, 1}.
Since 1/2 ∈/ A3, B2 = {0, 1}. In general, any number in Ak is not in Ak+1
as shown below. Note that any number in Ak is of the form p/k, 0 ≤
p ≤ k and any number in Ak+1 is of the form r/(k + 1), 0 ≤ r ≤ k + 1. If
some number in Ak is also in Ak+1, then p/k = r/(k+1) for some p such
that 0 ≤ p ≤ k and for some r such that 0 ≤ r ≤ k + 1, which implie482 Solutions to Conceptual Exercises
that r = (p/k)(k + 1). However, p ≤ k and hence r will be an integer if
and only if (k + 1) is a multiple of k. This is not possible unless k = 1.
Thus, Ak ∩Ak+1 = {0, 1} ∀ k ≥ 1 and hence Bn = {0, 1} ∀ n ≥ 1, which
further implies that lim inf An = {0, 1} ̸= lim sup An. Thus lim An does
not exist.
(vii) Suppose Q denotes the set of rational numbers. Note that with
Cn =
S
k≥n Ak,
C1 = (1 − 1/2, 2) ∩ Q, C2 = (1 − 1/3, 1 + 1/2) ∩ Q
C3 = (1 − 1/4, 1 + 1/3) ∩ Q
⇒ Cn = (1 − 1/(n + 1), 1 + 1/n) ∩ Q, n ≥ 1
⇒ lim sup An =
\
n≥1
Cn = {1} ∩ Q = {1}.
Now with Bn =
T
k≥n Ak,
B1 = {1} ∩ Q = {1}, B2 = {1} ∩ Q = {1}, B3 = {1}
⇒ Bn = {1}, ∀ n ≥ 1
⇒ lim inf An =
[
n≥1
Bn = {1}.
Thus, limit of the sequence exists and it is {1}.
(viii) with Cn =
S
k≥n Ak,
C1 = [−1, 1] ∪ (0, 1/2) ∪ [−1, 1/3] ∪ · · · = [−1, 1]
C2 = (0, 1/2) ∪ [−1, 1/3] ∪ · · · = [−1, 1/2)
⇒ C2n = [−1, 1/2n) & C2n+1 = [−1, 1/(2n+)]
⇒ lim sup An =
\
n≥1
Cn = [−1, 0].
Now with Bn =
T
k≥n Ak,
B1 = [−1, 1] ∩ (0, 1/2) ∩ [−1, 1/3] ∩ · · · = {0}
⇒ Bn = {0}, ∀ n ≥ 1
⇒ lim inf An =
[
n≥1
Bn = {0}.
Thus, limit of the sequence does not exist.
(ix) Suppose Q denotes the set of rational numbers. Note that with
Cn =
S
k≥n Ak,
C1 = (0, 2) ∩ Q, C2 = (1 − 1/2, 1 + 1/2) ∩ Q
C3 = (1 − 1/3, 1 + 1/3) ∩ Q
⇒ Cn = (1 − 1/(n + 1), 1 + 1/n) ∩ Q, n ≥ 1
⇒ lim sup An =
\
n≥1
Cn = {1} ∩ Q = {1}.Chapter 1 483
Now with Bn =
T
k≥n Ak,
B1 = {1} ∩ Q = {1}, B2 = {1} ∩ Q = {1}, B3 = {1}
⇒ Bn = {1}, ∀ n ≥ 1
⇒ lim inf An =
[
n≥1
Bn = {1}.
Thus, limit of the sequence exists and it is {1}.
1.6.4 Suppose a sequence {An, n ≥ 1} is defined as follows.
An =

B, if n is even
C, if n is odd.
Examine whether the sequence {An, n ≥ 1} converges. If yes find the
limit. If not, impose a condition on B and C so that it is a convergent
sequence.
Solution: By definition, lim inf An =
S
n≥1
T
k≥n
Ak =
S
n≥1
Bn, where
Bn =
T
k≥n
Ak. If n is even, then Bn = B ∩ C ∩ B · · · = B ∩ C and if n
is odd then Bn = C ∩ B ∩ C · · · = B ∩ C. Hence, lim inf An = B ∩ C.
Now, lim sup An =
T
n≥1
S
k≥n
Ak. Suppose n is even. Then S
k≥n
Ak = B ∪
C ∪ B · · · = B ∪ C. If n is odd then S
k≥n
Ak = C ∪ B ∪ C · · · = B ∪ C.
Hence, lim sup An = B ∪ C. Thus, lim An does not exist. It exists if
B ∩ C = B ∪ C, that is, if B = C.
1.6.5 Examine the limiting behaviour of the following sequence.
An =
￾
− ∞, 0

∪ (1/n, ∞), ∀ n ∈ N.
Solution: Observe that Ac
n = [0, 1/n], n ≥ 1 and it is a decreasing
sequence with limit T
n≥1 Ac
n = {0}. Hence limn→∞ An = {0}
c
.
1.6.6 Give an example of a sequence of sets {An, n ≥ 1} where
lim sup An ̸= lim inf An.
Solution: Suppose {An, n ≥ 1} is a sequence of sets where,
An =

(5 − 1/n, 5 + 1/n), if n is odd ,
∅, if n is even.
With An = ∅ for n odd we have,
lim sup An =
\
n≥1
[
k≥n
Ak =
\
n≥1
Cn =
\
n≥1
(5 − 1/n, 5 + 1/n)
⇒ lim sup An = {5}
Now, lim inf An =
[
n≥1
\
k≥n
Ak =
[
n≥1
Bn = ∅
⇒ lim inf An = ∅
⇒ lim sup An ̸= lim inf An484 Solutions to Conceptual Exercises
1.6.7 Give an example to show that lim inf An ∪lim inf Bn ̸= lim inf(An ∪Bn)..
Solution: Suppose {An, n ≥ 1} and {Bn, n ≥ 1} are sequences of sets
defined as follows. A1 = {1}, A2n = {2n} and A2n+1 = {1, 2, · · · , 2n +
1} and B1 = {1}, B2n = {1, 2, · · · , 2n} and B2n+1 = {2n + 1}. It is
easy to check that lim inf An = lim inf An = ∅. Note that An ∪ Bn =
{1, 2, · · · , n} and {An ∪ Bn, n ≥ 1} is an increasing sequence. Hence,
lim sup An ∪ Bn = lim An ∪ Bn =
S
n≥1 An ∪ Bn. Thus,
lim sup An ∪ Bn =
[
n≥1
{1, 2, · · · , n} = N ̸= lim inf An ∪ lim inf Bn = ∅.
1.6.8 Examine whether (i) lim sup(An
T
Bn) = lim sup An
T
lim sup Bn and
(ii) lim inf(An
S
Bn) = lim inf An
S
lim inf Bn if sequences {An, n ≥ 1}
and {Bn, n ≥ 1} are defined as follows. A1 = {1}, A2n = {2n},
A2n+1 = [1, 2n + 1] and B1 = {1}, B2n = [1, 2n], B2n+1 = {2n + 1}.
Solution: For the given sequences {An, n ≥ 1} and {Bn, n ≥ 1},
An ∩ Bn = {n}, n ≥ 1. Thus, {An ∩ Bn, n ≥ 1} is a sequence of disjoint
sets. Hence, lim sup An ∩ Bn = lim inf An ∩ Bn = ∅. Further note that
An ∪ Bn = [1, n], n ≥ 1. Thus, {An ∪ Bn, n ≥ 1} is an increasing se￾quence of sets with lim sup(An
S
Bn) = lim inf(An
S
Bn) = [1, ∞). Fur￾ther, lim sup An = lim sup Bn = [1, ∞) and lim inf An = lim inf Bn = ∅.
Hence,
lim sup(An
\
Bn) = ∅ ̸= lim sup An
\
lim sup Bn = [1, ∞)
& lim inf(An
[
Bn) = [1, ∞) ̸= lim inf An
[
lim inf Bn = ∅.
1.6.9 Examine whether
(i) lim inf An ∪ lim inf Bn ⊆ lim inf(An ∪ Bn)
⊆ lim sup(An ∪ Bn)
= lim sup An ∪ lim sup Bn
& (ii) lim inf An ∩ lim inf Bn = lim inf(An ∩ Bn)
⊆ lim sup(An ∩ Bn)
⊆ lim sup An ∩ lim sup Bn.
Solution: To examine whether lim inf An ∪ lim inf Bn ⊆ lim inf(An ∪
Bn), observe that
ω ∈ lim inf An ∪ lim inf Bn
⇒ ω ∈ lim inf An and/or ω ∈ lim inf Bn
⇒ ω ∈
[
n≥1
\
k≥n
Ak and/or ω ∈
[
n≥1
\
k≥n
Bk
⇒ ω ∈
\
k≥n
Ak for at least one n, say, n1 ≥ 1Chapter 1 485
and/or ω ∈
\
k≥n
Bk for at least one n, say, n2 ≥ 1
⇒ ω ∈ Ak ∀ k ≥ n1 and/or ω ∈ Bk ∀ k ≥ n2
⇒ ω ∈ Ak ∀ k ≥ n0 and/or ω ∈ Bk ∀ k ≥ n0
⇒ ω ∈ (Ak ∪ Bk) ∀ k ≥ n0 for at least one n0 ≥ 1
⇒ ω ∈
\
k≥n0
(Ak ∪ Bk) for at least one n0 ≥ 1
⇒ ω ∈
[
n≥1
\
k≥n
Ak ∪ Bk
⇒ ω ∈ lim inf(An ∪ Bn)
⇒ lim inf An ∪ lim inf Bn ⊆ lim inf(An ∪ Bn),
where n0 = max{n1, n2}. Further, as proved in Theorem 1.3.6,
lim inf(An ∪ Bn) ⊆ lim sup(An ∪ Bn). Similarly, it is shown in Example
1.3.17, lim sup(An ∪ Bn) = lim sup An ∪ lim sup Bn. Thus, (i) is proved.
To examine whether lim sup(An ∩Bn) ⊆ lim sup An ∩lim sup Bn, observe
that
ω ∈ lim sup(An ∩ Bn) ⇒ ω ∈
\
n≥1
[
k≥n
(Ak ∩ Bk)
⇒ ω ∈ Ak ∩ Bk for at least one k ≥ n & ∀ n ≥ 1
⇒ ω ∈ Ak for at least one k ≥ n & ∀ n ≥ 1
& ω ∈ Bk for at least one k ≥ n & ∀ n ≥ 1
⇒ ω ∈
\
n≥1
[
k≥n
Ak & ω ∈
\
n≥1
[
k≥n
Bk
⇒ ω ∈ lim sup An & ω ∈ lim sup Bn
⇒ ω ∈ lim sup An ∩ lim sup Bn
⇒ lim sup(An ∩ Bn) ⊆ lim sup An ∩ lim sup Bn.
As shown in Example 1.3.17, lim inf An ∩ lim inf Bn = lim inf(An ∩Bn).
Further, as proved in Theorem 1.3.6, lim inf(An∩Bn) ⊆ lim sup(An∩Bn)
and hence (ii) is proved.
1.6.10 Give an example where the sequences {An, n ≥ 1} and {Bn, n ≥ 1} do
not converge, but {An ∩ Bn, n ≥ 1} and {An ∪ Bn, n ≥ 1} converge.
Solution: Suppose sequences {An, n ≥ 1} and {Bn, n ≥ 1} are defined
as follows.
A2n+1 = {2n + 1}, n ≥ 0 A2n = {1, 2, · · · , 2n}, n ≥ 1
B2n+1 = {1, 2, · · · , 2n + 1}, n ≥ 0 & B2n = {2n}, n ≥ 1.486 Solutions to Conceptual Exercises
Note that
lim sup An =
\
n≥1
[
k≥n
Ak =
\
n≥1
Cn, where
Cn =
[
k≥n
Ak = N, ∀ n ≥ 1 ⇒ lim sup An = N
lim inf An =
[
n≥1
\
k≥n
Ak =
[
n≥1
Wn, where
Wn =
\
k≥n
Ak = ∅, ∀ n ≥ 1 ⇒ lim inf An = ∅.
Thus, limn→∞
An does not exist. Similarly,
lim sup Bn =
\
n≥1
[
k≥n
Bk =
\
n≥1
Cn, where
Cn =
[
k≥n
Bk = N, ∀ n ≥ 1 ⇒ lim sup Bn = N
lim inf Bn =
[
n≥1
\
k≥n
Bk =
[
n≥1
Dn, where
Dn =
\
k≥n
Bk = ∅, ∀ n ≥ 1 ⇒ lim inf Bn = ∅.
Thus, limn→∞
Bn does not exist. Suppose Mn = An ∩ Bn, n ≥ 1. Observe
that A1∩B1 = {1}, A2∩B2 = {2} and in general Mn = An ∩Bn = {n}.
Hence,
lim sup Mn =
\
n≥1
[
k≥n
Mk =
\
n≥1
Nn, where
Nn =
[
k≥n
{k} = {n, n + 1, n + 2, · · · }
⇒ lim sup Mn =
\
n≥1
Nn = ∅
lim inf Mn =
[
n≥1
\
k≥n
Mk =
[
n≥1
En, where
En =
\
k≥n
{k} = ∅ ⇒ lim inf Mn =
[
n≥1
Nn = ∅.
Hence, limn→∞
(An ∩ Bn) = ∅. Suppose Fn = An ∪ Bn, n ≥ 1. Observe
that A1 ∪ B1 = {1}, A2 ∪ B2 = {1, 2} and in general Fn = An ∪ Bn =Chapter 1 487
{1, 2, · · · , n}. Hence,
lim sup Fn =
\
n≥1
[
k≥n
Fk =
\
n≥1
Gn, where
Gn =
[
k≥n
{k} = N ⇒ lim sup Fn =
\
n≥1
Gn = N
lim inf Fn =
[
n≥1
\
k≥n
Fk =
[
n≥1
Hn, where
Hn =
\
k≥n
{k} = {1, 2, · · · , n}
⇒ lim inf Fn =
[
n≥1
Hn = N ⇒ limn→∞
(An ∪ Bn) = N.
Thus, the sequences {An, n ≥ 1} and {Bn, n ≥ 1} do not converge, but
{An ∩ Bn, n ≥ 1} and {An ∪ Bn, n ≥ 1} converge.
1.6.11 Suppose A = lim sup An and B = lim inf An. Then show that
M −A = lim inf(M −An) and M −B = lim sup(M −An) for any M ∈ Ω.
Solution: Note that using results in Example 1.3.17, we have
lim inf(M − An) = lim inf(M ∩ A
c
n
) = lim inf M ∩ lim inf A
c
n
= M ∩ (lim sup An)
c = M − lim sup An = M − A.
By the definition,
lim sup(M − An) = lim sup(M ∩ A
c
n
) = \
n≥1
[
k≥n
(M ∩ A
c
k
)
=
\
n≥1
Dn where Dn =
[
k≥n
(M ∩ A
c
k
).
Note that
ω ∈ Dn ⇐⇒ ω ∈ (M ∩ A
c
k
) for at least one k ≥ n
⇐⇒ ω ∈ M & ω ∈ A
c
k
for at least one k ≥ n
⇐⇒ ω ∈ M & ω ∈
[
k≥n
A
c
k ⇐⇒ ω ∈ M ∩ (
[
k≥n
A
c
k
)
Further, ω ∈
\
n≥1
Dn ⇐⇒ ω ∈ Dn ∀ n ≥ 1
⇐⇒ ω ∈ M & ω ∈
[
k≥n
A
c
k ∀ n ≥ 1
⇐⇒ ω ∈ M & ω ∈
\
n≥1
[
k≥n
A
c
k ⇐⇒ ω ∈ M ∩ (lim sup A
c
k
)
⇐⇒ ω ∈ M ∩ (lim inf Ak)
c ⇐⇒ ω ∈ (M − lim inf Ak)
⇐⇒ ω ∈ (M − B) ⇒ M − B = lim sup(M − An).488 Solutions to Conceptual Exercises
1.6.12 Suppose Ω is a finite set. Examine whether (i) a collection of all finite
subsets of Ω is a field and (ii) a collection of all singleton subsets of Ω
is a field.
Solution: (i) Suppose C a collection of all finite subsets of Ω. Note that
A ∈ C ⇒ Ac ∈ C as Ω is finite. Further a union of two finite sets
is again a finite set and hence C is closed under finite unions. Thus, C
is a field. (ii) Suppose C1 a collection of all singleton subsets of Ω. If
A ∈ C then Ac ∈/ C as Ac
is not a singleton set, unless Ω has exactly
two elements. Further a union of two singleton sets is not a singleton
set and hence C1 is not a field.
1.6.13 Examine whether the following classes of subsets of Ω are field and/or
sigma field, where Ω is an uncountable set. Suppose A ⊆ Ω
(i) {Ω, ∅} (ii) {Ω, ∅, A}, (iii) {Ω, ∅, A, Ac}, (iv) P(Ω), (v) the class of all
finite subsets of Ω and (vi) the class of all countable subsets of Ω.
Solution: (i) and (iii) are fields and sigma fields, (iv) is sigma field. (ii)
is not a field since it is not closed under complementation. In (v) class
of all finite subsets will not include Ω and hence cannot be a field or a
sigma field. In (vi) class of all countable subsets will not include Ω and
hence cannot be a field or a sigma field.
1.6.14 Suppose F is a sigma field of subsets of Ω. Suppose E ∈ F and E ̸= ∅.
Show that FE = {A ∩ E|A ∈ F} is the sigma field of subsets of E.
Solution: Suppose A = Ω, then A ∩ E = E. Thus, E plays the role of
Ω for the collection FE. Note that M = (A ∩ E)
c = Ac ∪ Ec ∈ F. From
the definition of FE,
B ∈ FE ⇒ B = A ∩ E ⇒ B
c = E ∩ (A ∩ E)
c = E ∩ M ∈ FE.
Thus, FE is closed under complementation. Further,
∀ n ≥ 1, Bn ∈ FE ⇒ Bn = An∩E ⇒
[
n≥1
Bn =
 [
n≥1
An

∩E ∈ FE
since S
n≥1 An ∈ F. Thus, FE is closed under complementation with
respect to whole space as E and it is also closed under countable union
and hence it is a sigma field of subsets of E.
1.6.15 Suppose C2 is a class of intervals of the type (a, b], a < b ∈ R and C6
is a class of intervals of the type (−∞, a], a ∈ R. Then show that the
minimal sigma field generated by C2 is the same as that by C6.
Solution: Suppose σ(C2) is the minimal sigma field generated by C2.
Note that,
∀ n ≥ 1, (−n, a] ∈ C2 ⇒ ∀ n ≥ 1, (−n, a] ∈ σ(C2)
⇒
[
n≥1
(−n, a] = (−∞, a] ∈ σ(C2)
⇒ C6 ⊆ σ(C2) ⇒ σ(C6) ⊂ σ(C2).Chapter 1 489
Now by the definition of C6,
(−∞, a] ∈ C6 ⇒ (−∞, a] ∈ σ(C6)
⇒ (−∞, a]
c = (a, ∞) ∈ σ(C6)
⇒ for b > a, (−∞, b] ∩ (a, ∞) = (a, b] ∈ σ(C6)
⇒ C2 ⊆ σ(C6) ⇒ σ(C2) ⊆ σ(C6).
Thus, σ(C2) = σ(C6).
1.6.16 Give an example of a class of events, which is closed under finite unions
and finite intersections but not under complementation.
Solution: Suppose Ω = R and class A is a class of intervals of the type
(x, ∞), x ∈ Ω. With u = min{x, y} & v = max{x, y},
(x, ∞) ∪ (y, ∞) = (u, ∞) ∈ A & (x, ∞) ∩ (y, ∞) = (v, ∞) ∈ A
but (x, ∞)
′ = (−∞, x] ∈/ A.
1.6.17 Suppose Ω is a finite set and A is a field of subsets of Ω. Show that is
a sigma field.
Solution: Since A is a field of subsets of Ω, it is closed under com￾plementation and finite union. Further, Ω is a finite set implies that
any sequence {An, n ≥ 1} of sets in A is a finite collection. Hence,
a countable union S
n≥1 An is a finite union. Thus, A is closed under
complementation and countable union and hence is a sigma field.
1.6.18 Suppose {Fn, n ≥ 1} is a sequence of fields of subsets of Ω, such that
Fn ⊆ Fn+1, ∀ n ≥ 1. (i) Prove that S∞
n=1 Fn is a field. (ii) What can
one say if {Fn, n ≥ 1} is a sequence of sigma fields? Justify.
Solution: (i) Observe that
A ∈
[∞
n=1
Fn ⇒ A ∈ Fn for at least one n ≥ 1
⇒ A
c ∈ Fn for at least one n ≥ 1 ⇒ A
c ∈
[∞
n=1
Fn.
Suppose for m = 1, 2
Am ∈
[∞
n=1
Fn ⇒ Am ∈ FM for some Mm ≥ 1
⇒ Am ∈ Fn ∀ n ≥ Mm since Fn ⊆ Fn+1
⇒
[
2
m=1
Am ∈ Fn ∀ n ≥ M0, where M0 = max{M1, M2}
⇒
[
2
m=1
Am ∈
[∞
n=1
Fn.490 Solutions to Conceptual Exercises
Hence, S∞
n=1 Fn is a field.
(ii) Suppose Ω = {1, 2, · · · , } and Fn = σ({A1, A2, · · · , An}) where
An = {n}, n ≥ 1. Thus, Fn consists of all finite and co-finite sets and
hence S∞
n=1 Fn also consists of all finite and co-finite sets. As shown in
Example 1.4.6, S∞
n=1 Fn is a field. Now
∀ n ≥ 1, Bn = {2n} ∈ [∞
n=1
Fn but [∞
n=1
Bn = {2, 4, 6, · · · , } ∈/
[∞
n=1
Fn,
since it is neither finite nor its complement is finite. Hence, S∞
n=1 Fn is
not a sigma field.
1.6.19 Suppose Ω = N, the set of all natural numbers and An = {1, 2, . . . , n},
n ≥ 1. If An = σ({An}), verify whether {An, n ≥ 1} is an increasing
sequence.
Solution: Observe that ∀ n ≥ 1,
An ⊆ An+1 ⊂ σ({An+1}) = An+1
⇒ An = σ({An}) ⊆ σ(An+1) = An+1
⇒ {An, n ≥ 1} is an increasing sequence.
The second statement follows by the definition of the minimal sigma
field.
1.6.20 Suppose P = {A1, A2, . . . , } is a countable partition of Ω and
A = {E|E = ∅ or E is a union of sets in P}. Show that A is the
minimal sigma field containing P.
Solution: Since P = {A1, A2, . . . , } is a partition of Ω, Ai ∩ Aj = ∅ for
all i ̸= j and S
i≥1 Ai = Ω. Note that ∅ & Ω ∈ A. Any set E ∈ A is of
the form E =
S
i∈T Ai where T ⊂ N. Hence, Ec =
S
i∈Tc Ai and hence
is in A. Thus, A is closed under complementation. Further, suppose
{En, n ≥ 1} is a sequence of sets in A. Then ∀ n ≥ 1, En =
S
i∈Tn
Ai
,
Tn ⊆ N ∀ n ≥ 1. As a consequence,
[
n≥1
En =
[
n≥1
(
[
i∈Tn
Ai) = [
i∈
S
n≥1
Tn
Ai ∈ A.
Thus, A is a sigma field. Further, ∀ n ≥ 1, An ∈ P ⇒ An ∈ A Thus,
P ⊂ A and A is a sigma field generated by P. Suppose σ
∗
(P) is any other
sigma field generated by P. Note that for any E ∈ A, E is either ∅ or is
of the form E =
S
i∈T Ai where T ⊂ N and hence, it is in σ
∗
(P). Thus,
A ⊂ σ
∗
(P) and hence A is the minimal sigma field containing P.
1.6.21 Suppose P1 = {Ai
, i = 1, 2, · · · , m} and P2 = {Bj , j = 1, 2, · · · , n} are
two partitions of Ω. Show that (i) P = {Ai ∩ Bj , i = 1, 2, · · · , m, j =
1, 2, · · · , n} is a partition of Ω and (ii) σ(σ(P1) ∪ σ(P2)) = σ(P).Chapter 1 491
Solution: (i) Suppose Cij = Ai ∩ Bj , i = 1, 2, · · · , m and j =
1, 2, · · · , n. Then for i ̸= r and j ̸= s,
Cij ∩ Crs = (Ai ∩ Bj ) ∩ (Ar ∩ Bs) = (Ai ∩ Ar) ∩ (Bj ∩ Bs) = ∅.
Similarly, even if i = r and j ̸= s or i ̸= r and j = s, then Cij ∩ Crs = ∅.
Thus, Cij = Ai ∩ Bj , i = 1, 2, · · · , and j = 1, 2, · · · , are all disjoint
sets. Note that,
[
k
i=1
[
l
j=1
Cij =
[
k
i=1
[
l
j=1
(Ai ∩ Bj ) = [
k
i=1
 [
l
j=1
(Ai ∩ Bj )

=
[
k
i=l
(Ai ∩ Ω) = Ω.
Further, Ai ∈ A and Bj ∈ A, a sigma field of subsets of Ω. Hence
Cij = Ai ∩ Bj ∈ A, i = 1, 2, · · · , m and j = 1, 2, · · · , n. Thus,
P = {Cij , i = 1, 2, · · · m, j = 1, 2, · · · , n} forms a measurable partition
of Ω.
(ii) As shown in Example 1.4.2, the sigma field generated by P1 is given
by,
σ(P1) = {A | A =
X
t∈T
At} where T is the powerset corresponding to
{1, 2, · · · , m}, where summation over empty set is taken as the empty
set. Similarly,
σ(P2) = {B | B =
X
s∈S
Bs} where S is the powerset corresponding to
{1, 2, · · · , n}, where summation over empty set is taken as the empty set.
Observe that any set Ai ∈ P1 can be expressed as Ai =
Sn
j=1(Ai∩Bj ) ∈
P. Similarly, any set Bj ∈ P2 can be expressed as Bj =
Sm
i=1(Ai ∩Bj ) ∈
P. Hence,
Pi ⊆ P, i = 1, 2
⇒ σ(Pi) ⊆ σ(P), i = 1, 2 by Theorem 1.4.6
⇒ σ(P1) ∪ σ(P1) ⊆ σ(P)
⇒ σ

σ(P1) ∪ σ(P1)

⊆ σ(P),
the last step follows by the definition of the minimal sigma field. To
establish inclusion in the reverse direction, note that if A ∈ σ(P), then
either A ∈ P1 or A ∈ P2 or A is a finite or union or intersection of sets
in σ(P1) and σ(P2) and hence any set in P is in σ

σ(P1)∪σ(P1)

. Thus,
P ⊆ σ

σ(P1) ∪ σ(P1)

⇒ σ(P) ⊂ σ

σ(P1) ∪ σ(P1)

.
Hence σ(σ(P1) ∪ σ(P2)) = σ(P).492 Solutions to Conceptual Exercises
1.6.22 Suppose (Ω, A, P) is a probability space. Prove that for {A1, A2, · · · ,
An} in A, P(
Tn
i=1 Ai) ≥
Pn
i=1 P(Ai) − (n − 1).
Solution: From the property of the probability measure P,
1 ≥ P(A1 ∪ A2) = P(A1) + P(A2) − P(A1 ∩ A2)
⇒ P(A1 ∩ A2) ≥ P(A1) + P(A2) − 1 = P(A1) + P(A2) − (2 − 1).
Now,
P(A1 ∩ A2 ∩ A3) ≥ P(A1 ∩ A2) + P(A3) − 1
≥ P(A1) + P(A2) − 1 + P(A3) − 1
= P(A1) + P(A2) + P(A3) − 2
= P(A1) + P(A2) + P(A3) − (3 − 1).
We assume P
 Tm
i=1 Ai

≥
Pm
i=1 P(Ai)−(m−1). It is true for m = 2, 3.
Observe that
P
 m\
+1
i=1
Ai

= P
 \m
i=1
Ai ∩ Am+1
≥ P(
\m
i=1
Ai) + P(Am+1) − 1
≥
Xm
i=1
P(Ai) − (m − 1) + P(Am+1) − 1
=
mX
+1
i=1
P(Ai) − (m + 1 − 1).
Thus, we get the required result by induction.
1.6.23 Suppose (Ω, A, P) is a probability space. Suppose {A1, A2, A3} ∈ A are
such that P(A1 ∩ A2 ∩ A3) = P(Ac
1 ∩ Ac
2 ∩ Ac
3
). Then show that each is
equal to
1
2
[1−(P(A1)+P(A2)+P(A3))+P(A1∩A2)+P(A1∩A3)+P(A2∩A3)].
Solution: We have
P(A
c
1 ∩ A
c
2 ∩ A
c
3
) = 1 − P(A1 ∪ A2 ∪ A3)
= 1 − P(A1) − P(A2) − P(A3) + P(A1 ∩ A2)
+ P(A1 ∩ A3) + P(A2 ∩ A3) − P(A1 ∩ A2 ∩ A3)
= 1 − P(A1) − P(A2) − P(A3) + P(A1 ∩ A2)
+ P(A1 ∩ A3) + P(A2 ∩ A3) − P(A
c
1 ∩ A
c
2 ∩ A
c
3
)
⇒ P(A
c
1 ∩ A
c
2 ∩ A
c
3
) = 1
2
[1 − (P(A1) + P(A2) + P(A3)) + P(A1 ∩ A2)
+ P(A1 ∩ A3) + P(A2 ∩ A3)].
1.6.24 Show that if P
n≥1 P(An) < ∞, then P(lim sup An) = 0. Examine if
P(lim inf An) = 0.Chapter 1 493
Solution: By definition of limit supremum of a set we have,
lim sup An =
\
n≥1
[
k≥n
Ak =
\
n≥1
Cn, where Cn =
[
k≥n
Ak.
Now,
Cn =
[
k≥n
Ak = An
[
Cn+1 ⇒ Cn ⊇ Cn+1
⇒ {Cn, n ≥ 1} is a non-increasing sequence of events in A
⇒ limn→∞
Cn =
\∞
n=1
Cn = lim sup An
⇒ P(lim sup An) = P(
\∞
n=1
Cn) = P( limn→∞
Cn)
= limn→∞
P(Cn) = limn→∞
P(
[
k≥n
Ak) ≤ limn→∞
X
k≥n
P(Ak) = 0
in view of the fact that P
k≥n P(Ak) forms a tail of the convergent series
P∞
n=1 P(An). Thus, P(lim sup An) ≤ 0, but being probability it cannot
be less that 0. Hence, P∞
n=1 P(An) < ∞ ⇒ P(lim sup An) = 0. Since
P(lim inf An) ≤ P(lim sup An), P(lim inf An) = 0
1.6.25 Suppose Ω = W, a set of whole numbers and A = P(Ω) and a set
function P on (Ω, P(Ω)) is defined as P(A) = P
i∈A p(1 − p)
i
for A ∈
P(Ω) and p ∈ (0, 1). Examine whether P is a probability measure on
(Ω, P(Ω)).
Solution: Observe that P(A) = P
i∈A p(1 − p)
i ≥ 0 ∀ A ∈ P(Ω).
Further,
P(Ω) = X
i∈Ω
p(1 − p)
i =
X∞
i=0
p(1 − p)
i = 1.
To examine σ-additivity, suppose {An, n ≥ 1} is a sequence of disjoint
sets in A. Then
P
X
n≥1
An

=
X
i∈
P
n≥1
An
p(1 − p)
i =
X
n≥1
X
i∈An
p(1 − p)
i =
X
n≥1
P(An).
Hence, we conclude that P is a probability measure on (Ω, P(Ω)).
1.6.26 Suppose (Ω, P(Ω), P) is a probability space, where P({ω}) = p ∈ (0, 1).
Show that Ω must be finite. If Ω consists of k elements, then p must be
1/k.
Solution: Suppose Ω = {1, 2, · · · , } which is countably infinite. Then
P(Ω) = X
ω∈Ω
P({ω}) = X
ω∈Ω
p = ∞,494 Solutions to Conceptual Exercises
which is a contradiction. Hence, Ω must be finite. If it consists of k
elements, then P(Ω) = 1 ⇒ p = 1/k.
1.6.27 Suppose Ω = N, a set of natural numbers and P is a set function
defined on (Ω, P(Ω)) such that
P(A) = 
0, if A is finite
1, if A is infinite.
Is P a probability measure on (Ω, P(Ω))?
Solution: Suppose P is a probability measure. If An = {2n}, n ≥ 1,
then for each n ≥ 1 An is a finite set and hence P(An) = 0. Further,
S
n≥1 An = {2, 4, · · · , } is a set of all even numbers which is infinite,
which implies P(
S
n≥1 An) = 1. But P
n≥1 P(An) = 0. Thus the condi￾tion of sigma additivity is not satisfied and hence P cannot be a prob￾ability measure.
1.6.28 Suppose Ω = W, a set of whole numbers, A is a power set of Ω. Examine
whether set functions P defined below in (i), (ii) and (iii) are probability
measures on (Ω, A). (i) P(A) = number of points in A, (ii) for a non￾empty set A ∈ A, P(A) = P
x∈A µ({x}), where µ({x}) = 1/2
x
, x =
1, 2, · · · , µ({0}) = 1/2 and µ(∅) = 0 and (iii) µ({x}) = 1/2
x+1, x ∈ Ω.
Solution:(i) Suppose A = {1, 2}, then P(A) = 2 > 1. Hence the set
function P defined in (i) cannot be a probability measure.
(ii) Note that P(Ω) = P
x≥0 µ({x}) = 1/2 +P
x≥1
(1/2
x
) = 1/2 + 1 > 1
and the set function P defined in (ii) cannot be a probability measure.
(ii) With µ({x}) = 1/2
x+1, x ∈ Ω, P(A) ≥ 0, P(Ω) = P
x≥0 µ({x}) = 1.
Suppose {An, n ≥ 1} is a sequence of disjoint events. Then An is any
subset of Ω and P(An) = P
x∈An
µ({x}). Hence,
P(
X
n≥1
An) = X
x∈
P
n≥1
An
µ({x}) = X
n≥1
X
x∈An
µ({x}) = X
n≥1
P(An).
Thus, P satisfies sigma additivity condition and hence P is a probability
measure.
1.6.29 Suppose (Ω, A, P) is a probability space and {An, n ≥ 1} and
{Bn, n ≥ 1} are sequences of sets from A. Suppose P(lim sup An) =
P(lim sup Bn) = 1. Examine whether (i) P(lim sup An ∩lim sup Bn) = 1
and (ii) P(lim sup An ∩ Bn) = 1.
Solution: (i) Note that
P(lim sup An ∪ lim sup Bn) = P(lim sup An) + P(lim sup Bn)
− P(lim sup An ∩ lim sup Bn)
= 2 − P(lim sup An ∩ lim sup Bn) ≤ 1
⇒ P(lim sup An ∩ lim sup Bn) ≥ 1
⇒ P(lim sup An ∩ lim sup Bn) = 1.Chapter 2 495
(ii) Suppose Ω = N, A = P(Ω) and the probability measure P is defined
as P({x}) = pqx−1
, x ∈ N and q = 1 − p. As in Example 1.3.18, we
define sequences {An, n ≥ 1} and {Bn, n ≥ 1} of sets in A as follows.
A2n+1 = {2n + 1}, n ≥ 0 A2n = {1, 2, · · · , 2n}, n ≥ 1
B2n+1 = {1, 2, · · · , 2n + 1}, n ≥ 0 & B2n = {2n}, n ≥ 1.
In the same example, it is shown that
lim sup An = lim sup Bn = N
⇒ P(lim sup An) = P(lim sup Bn) = 1
lim sup(An ∩ Bn) = ∅ ⇒ P lim sup((An ∩ Bn)) = 0.
Thus, P(lim sup An ∩ lim sup Bn) = 1 but P(lim sup(An ∩ Bn)) ̸= 1.
1.6.30 Suppose (Ω, A) is a measurable space and B ∈ A is any non empty
subset of Ω. Suppose a class is defined as B ∩ A = {B ∩ A|A ∈ A} =
AB say. Show that AB is a sigma field of subsets of B. A function
PB : (B, AB) → [0, 1] is defined as PB(A) = P(B ∩A)/P(B) ∀ A ∈ A.
Show that PB is a probability measure on (B, AB).
Solution: The result that AB is a sigma field of subsets of B follows from
the solution of Exercise 1.6.22. To examine PB(A) = P(B ∩ A)/P(A)
is a probability measure on (B, AB), we examine whether Kolmogorov’s
three axioms are satisfied. Observe that (i) PB(A) = P(B ∩ A)/P(A) ≥
0. (ii) PB(B) = P(B ∩B)/P(B) = 1. Suppose {An, n ≥ 1} is a sequence
of disjoint events in A. Then, Dn = B ∩ An ∈ AB and {Dn, n ≥ 1}
is a sequence of disjoint events. Further, P(
P
n≥1 An) = P
n≥1 P(An).
Now,
PB(
[
n≥1
Dn) = P(B ∩
[
n≥1
B ∩ An)/P(B)
= P(
[
n≥1
B ∩ An)/P(B) = X
n≥1
PB(Dn)
1.6.31 Suppose {Bn, n ≥ 1} is a sequence of sets from A such that
P(Bn) = 1, ∀ n ≥ 1. Then show that P(
T
n≥1 Bn) = 1.
Solution: Observe that
∀ n ≥ 1, P(Bn) = 1 ⇒ ∀ n ≥ 1, P(B
c
n
) = 0
⇒ P(
[
n≥1
B
c
n
) ≤
X
n≥1
P(B
c
n
) = 0
⇒ P(
\
n≥1
Bn) = 1 − P(
[
n≥1
B
c
n
) = 1.
Answers to the multiple choice questions, based on Chapter 1, are given
in Table 11.1.496 Solutions to Conceptual Exercises
TABLE 11.1
Answer Key to MCQs in Chapter 1
Q.No. 1 2 3 4 5 6 7 8
Ans b a a,b,d a,b,d b a,d c c,d
Q.No. 9 10 11 12 13 14 15 16
Ans a,d b,c,d a,b,c,d d c a,b,c,d b,c b
Q.No. 17 18 19 20 21 22 23 24
Ans b a,c,d c b a,b,c,d a,b a,b
11.2 Chapter 2
2.6.1 Suppose Ω is a sample space corresponding to the experiment of rolling
a die once. Suppose A = {Ω, ∅, {1, 3, 5}, {2, 4, 6}}. Define two functions
on (Ω, A) such that one is a random variable on (Ω, A) and the other is
not a random variable on (Ω, A).
Solution: Suppose A = {1, 3, 5} and B = {1, 2, 3, 4}. Functions X and
Y are defined as follows.
X(ω) = 
10, if ω ∈ A
20, if ω ∈ Ac & Y (ω) = 
10, if ω ∈ B
20, if ω ∈ Bc
.
Then, X−1
(B) = {Ω, ∅, A, Ac} = A. Hence, X is a random variable on
(Ω, A). Further, Y
−1
(B) = {Ω, ∅, B, Bc} and B /∈ A. Hence, Y is not a
random variable on (Ω, A).
2.6.2 Suppose Ω = (0, 1] and A is a minimal sigma field consisting of all Borel
sets which are subsets of Ω. Examine whether a function X(ω) = 6ω + 2
is a random variable on (Ω, A). (i) Use the economical definition. (ii)
Use the result that a Borel function of a random variable is a random
variable.
Solution: (i) The range of a function X is (2, 8]. Note that
X−1
(−∞, x]) = [X ≤ x] =



∅, if x ≤ 2
(0,(x − 2)/6], if 2 < x < 8
Ω, if x ≥ 8.
Thus, ∀ x ∈ R, X−1
(−∞, x]) ∈ A. Hence, X is a random variable on
(Ω, A), measurable with respect to A.
(ii) Suppose Y is an identity function defined on (Ω, A). Then
∀ S ∈ B, Y −1
(S) = S ∈ A. Hence, Y is A measurable random variable.
Now, X(ω) = g(Y (ω)) where g(x) = 6x + 2. Now g is a continuous
function, hence a Borel function, implying that X is a random variable
on (Ω, A).Chapter 2 497
2.6.3 Suppose X is a random variable, measurable with respect to A. Examine
whether (i) Y1 = e
X and Y2 = e
X + X3 + 5X are random variables,
measurable with respect to A. (ii) If X is a positive random variable
measurable with respect to A, examine whether Y3 = log X is a random
variable. Is Z = (Y1, Y2, Y3)
′ a random vector measurable with respect
to A? Justify.
Solution: (i) Observe that e
X = g(X) where g(x) = e
x
is a continuous
and hence a Borel function. Hence, e
X is a random variable, measurable
with respect to A. Note that X3 and 5X, being Borel functions of X,
are random variables, measurable with respect to A. A class of random
variables is closed under arithmetic operations and hence e
X +X3 + 5X
is a random variable, measurable with respect to A. Alternatively, e
X +
X3 + 5X = g(X), where g(x) = e
x + x
3 + 5x. It is a continuous and
hence a Borel function. Thus, being Borel function of a random variable,
e
X + X3 + 5X is a random variable, measurable with respect to A.
(ii) Since X > 0, log X is defined. Further g(x) = log x, x > 0 is a
continuous and hence a Borel function. Thus, being Borel function of
a random variable X, log X is a random variable. Since Y1, Y2, Y3 are
random variables, measurable with respect to A, Z = (Y1, Y2, Y3)
′
is a
random vector measurable with respect to A.
2.6.4 (i) Suppose A and B are mutually exclusive events. Find the minimal
sigma field induced by IA + IB. (ii) Suppose A and B are not mutually
exclusive events. Find the minimal sigma field induced by IA + IB.
Solution: (i) By the definition of an indicator function, if A and B are
mutually exclusive events, then IA + IB is given by,
(IA + IB)(ω) = 
0, if ω /∈ A, ω /∈ B, that is ω ∈ Ac ∩ Bc
,
1 if ω ∈ A ∪ B = A + B.
Hence, the minimal sigma field induced by IA + IB is {Ω, ∅, A ∪ B,(A ∪
B)
c}.
(ii) Suppose A and B are not mutually exclusive events. Then IA + IB
is given by,
(IA + IB)(ω) =



0, if ω ∈ (A ∪ B)
c
1, if ω ∈ (A ∩ Bc
) ∪ (Ac ∩ B)
2, if ω ∈ A ∩ B.
Hence, the inverse images of Borel sets are give by
(IA + IB)
−1
(S) =



∅, if0 ∈/ S, 1 ∈/ S, 2 ∈/ S, ,
(A ∪ B)
c
, if0 ∈ S, 1 ∈/ S, 2 ∈/ S,
(A ∩ Bc
) ∪ (Ac ∩ B), if0 ∈/ S, 1 ∈ S, 2 ∈/ S,
A ∩ B, if0 ∈/ S, 1 ∈/ S, 2 ∈ S,
(A ∩ B)
c
, if0 ∈ S, 1 ∈ S, 2 ∈/ S,
(A ∪ B)
c ∪ (A ∩ B), if0 ∈ S, 1 ∈/ S, 2 ∈ S,
A ∪ B, if0 ∈/ S, 1 ∈ S, 2 ∈ S,
Ω, if0 ∈ S, 1 ∈ S, 2 ∈ S.498 Solutions to Conceptual Exercises
Hence, the minimal sigma field induced by IA + IB is {Ω, ∅, A ∪ B,(A ∪
B)
c
, A ∩ B,(A ∩ B)
c
,(A ∩ Bc
) ∪ (Ac ∩ B),(A ∪ B)
c ∪ (A ∩ B)}.
2.6.5 Suppose Ω = {a, b, c} and A = {Ω, ∅, {a}, {b, c}}. Examine whether A is
a sigma field. If yes, specify any non-constant function on (Ω, A) which
is measurable with respect to A.
Solution: It is easy to verify that A is closed under complementation
and countable union and hence it is a sigma field. Suppose a function
on (Ω, A) is defined as
X(ω) = 
10, if ω = a
30, if ω = b, c.
Then X−1
(B) = A and hence X is measurable with respect to A.
2.6.6 Suppose X and Y are random variables on (Ω, A, P) such that σ(X) =
σ(Y ). Show that σ(X + Y ) ⊆ σ(X).
Solution: Note that X + Y is a Borel function of (X, Y )
′ and hence
sigma field induced by X + Y is included in the sigma field induced by
(X, Y )
′
. Thus,
σ(X + Y ) ⊆ σ(X−1
(B) ∪ Y
−1
(B)) = σ(X−1
(B) ∪ X−1
(B))
= σ(X−1
(B)) = X−1
(B) = σ(X).
2.6.7 Suppose X is a random variable. Show that σ(X2
) ⊆ σ(X).
Solution: We have a result which states that sigma field induced by
a Borel function of a random variable is included in the sigma field
induced by the random variable. Note that X2
is a Borel function of
X and hence σ(X2
) ⊆ σ(X). If X2
is a one-to-one function of X, then
σ(X2
) = σ(X), otherwise σ(X2
) ⊂ σ(X).
2.6.8 Give an example of a random variable such that σ(X2
) ̸= σ(X).
Solution: Suppose X is a random variable defined on (Ω, A) to (R, B)
as X(i) = i, where Ω = {−1, 0, 1}. Then we have obtained a sigma field
induced by X and Y = X2
in Example 2.2.12. These are given by,
X−1
(B) = {Ω, ∅, {−1}, {0}, {1}, {−1, 0}, {−1, 1}, {0, 1}}
and Y
−1
(B) = {Ω, ∅, {0}, {−1, 1}}. We note that σ(X2
) ̸= σ(X). Ob￾serve that X2
is not a one-to-one function of X.
2.6.9 Give an example of a random variable such that σ(X2
) = σ(X).
Solution: Suppose X is a random variable defined on (Ω, A) to (R, B)
as follows. For A ∈ A,
X(ω) = 
2, if ω ∈ A
3, if ω /∈ A.Chapter 2 499
Then sigma fields induced by X and Y = X2 are the same and are given
by {Ω, ∅, A, Ac}. Observe that X2
is a one-to-one function of X.
2.6.10 Suppose Ω = {1, 2, 3, 4}, A = {1, 2} and A = {Ω, ∅, A, Ac}. Functions
X, Y and W on (Ω, A) are defined as follows. X(ω) = 4 ∀ ω ∈ Ω,
Y (ω) = 1 if ω ∈ A and 0 otherwise and W(ω) = 5ω ∀ ω ∈ Ω. Examine
whether Z = (X, Y, W) is random vector on (Ω, A). If not, modify A,
so that Z = (X, Y, W) is random vector on (Ω, A). Find the sigma field
induced by Z.
Solution: It is known that Z = (X, Y, W) is random vector on (Ω, A) if
and only if each of the components is A measurable random variable. We
use this result to examine whether Z = (X, Y, W) is random vector on
(Ω, A). Observe that X(ω) = 4 ∀ ω ∈ Ω. Hence, X−1
(B) = {Ω, ∅} ⊂ A.
Thus, X is A measurable random variable. Y (ω) = 1 if ω ∈ A and 0
otherwise. Hence, Y
−1
(B) = {Ω, ∅, A, Ac} = A. Thus, Y is A measurable
random variable. Further, W(ω) = 5ω ∀ ω ∈ Ω and W−1
(B) = P(Ω).
It is not included in A. Thus, W is not A random variable. Hence, Z =
(X, Y, W) is not a random vector on (Ω, A). Suppose A = P(Ω). Then
X, Y, W are measurable with respect to A and hence Z = (X, Y, W) is
random vector on (Ω, A). By definition
σ(Z) = σ(σ(X) ∪ σ(Y ) ∪ σ(W)) = σ(P(Ω)) = P(Ω).
2.6.11 Suppose Ω = N, the set of natural numbers, and A = P(N). Construct
one finite and one countably infinite measurable partition of Ω. Give
an example of one simple random variable and one elementary random
variable defined on (N, P(N)).
Solution: Suppose E and O denote the set of even natural numbers and
odd natural numbers respectively. Then a finite partition Pf is defined
as Pf = {E, O}. Suppose a function X on (Ω, A) is defined as follows.
X(ω) = 
200, if ω ∈ E
300, if ω /∈ E.
Then X−1
(B) = {Ω, ∅, E, Ec
} ⊂ A = P(N)
which implies that X is the simple random variable on (Ω, A). Suppose
a countable partition Pc is defined as Pc{{1}, {2}, {3}, · · · , } and a func￾tion X on (Ω, A) is defined as X(i) = i, i ∈ N, that is X =
P
i∈N
iI{i}
then the sigma field induced by X is P(N). Hence, X is the elementary
random variable defined on (N, P(N)).
2.6.12 Prove or disprove: X−1
(lim Sn) = lim X−1
(Sn), where Sn is a Borel
set.
Solution: Suppose {Sn, n ≥ 1} is a sequence of Borel sets. We assume
that lim Sn exists. Thus, lim Sn = lim sup Sn = lim inf Sn. By definition500 Solutions to Conceptual Exercises
lim sup Sn =
T
n≥1 Bn where Bn =
S
k≥n Sk and lim inf Sn =
S
n≥1 Cn
where Cn =
T
k≥n Sk. Observe that
X−1
(lim sup Sn) = X−1
(
\
n≥1
Bn) = \
n≥1
X−1
(Bn) = \
n≥1
X−1
(
[
k≥n
Sk)
=
\
n≥1
[
k≥n
X−1
(Sk) = lim sup X−1
(Sn).
Using similar steps, it follows that X−1
(lim inf Sn) = lim inf X−1
(Sn).
Now we have, assumed that lim Sn exists. Thus,
lim Sn = lim sup Sn = lim inf Sn
⇒ X−1
(lim Sn) = X−1
(lim sup Sn) = X−1
(lim inf Sn)
⇒ X−1
(lim Sn) = lim sup X−1
(Sn) = lim inf X−1
(Sn)
⇒ X−1
(lim Sn) = lim X−1
(Sn).
2.6.13 Show that a necessary and sufficient condition for a function to be
measurable is that its positive and negative parts are measurable.
Solution: Suppose f defined on (Ω, A) is a measurable function with
respect to A, Ω may be R and A may be B, that is, f may be a Borel
measurable function. Then f
+ = g(f) and f
− = h(f) where g and h are
Borel measurable functions. Hence, f
+ and f
− are measurable functions.
Conversely, assume that f
+ and f
− are measurable functions. Further,
f = f
+ −f
− = g2(f
+, f −) where g2 is a Borel measurable function from
(R
2
, B
2
) to (R, B). Hence f is a measurable function.
2.6.14 Suppose f and g are Borel functions on (R, B). For A ∈ B, a function
h is defined as h = f on A and h = g on Ac
. Show that h is a Borel
function.
Solution: It is given that f and g are Borel functions. Since A ∈ B, IA
and IAc are Borel measurable functions. A function h can be expressed
as h = fIA + gIAc = g4(f, g, IA, IAc ) where g4 is a Borel measurable
function from (R
4
, B
4
) to (R, B). Hence h is a Borel measurable function.
2.6.15 Suppose |X| is A measurable. Examine whether X+ and X− are also
A measurable.
Solution: Suppose Ω = {H, T}, A = {Ω, ∅} and X is defined as X = 1
if ω = H and X = −1 if ω = T. Thus |X| ≡ 1 and is A measurable.
Note that
X+ =

1, if ω = H,
0, if ω = T. & X− =

0, if ω = H,
1, if ω = T.
Hence, both X+ and X− are not A measurable.Chapter 2 501
2.6.16 Suppose (X1, X2, · · · , Xn)
′
is a random vector on (Ω, A). Show that
(i) Pn
i=1 liXi
is real valued random variable where l1, l2, · · · , ln are any
real numbers, (ii) (sin X1, X2, X3, · · · , eXn−1
, |Xn|) is a random vector
and (iii) (X2, X3, · · · , Xn−1) is a random vector, all defined on the same
probability space (Ω, A).
Solution: Since (X1, X2, · · · , Xn)
′
is a random vector on (Ω, A, P), each
component is a random variable on (Ω, A).
(i) Note that Pn
i=1 liXi = g((X1, X2, · · · , Xn)
′
) where g(x) = Pn
i=1 lixi
is a Borel function from (R
n, B
n) to (R, B). Hence, it is a random vari￾able.
(ii) Since each Xi
is a random variable, being Borel functions,
sin X1, eXn−1
, |Xn| are random variables and hence
(sin X1, X2, X3, · · · , eXn−1
, |Xn|) is a random vector.
(iii) Since each Xi
is a random variable, (X2, X3, · · · , Xn−1) is a (n−2)
dimensional random vector.
2.6.17 Suppose a measurable space (Ω, A) is defined as Ω = [0, ∞) and A is
a sigma field of subsets of Ω. Suppose a sequence {Xn, n ≥ 1} of A
measurable random variables and a A measurable random variable X
are defined as follows.
Xn(ω) = exp(−nω), n ≥ 1 & X(ω) = 0 ∀ ω ∈ Ω.
(i) Examine if Xn → X on Ω or any subset of Ω. (ii) If not, identify
another X such that Xn → X on Ω.
Solution: Observe that,
Xn(ω) = exp(−nω) → 0 = X(ω), ∀ ω ∈ (0, ∞) .
But at ω = 0, Xn(ω) = 1 ∀ n ≥ 1 hence converges to 1 ̸= X(ω) = 0.
Thus the sequence of random variables {Xn, n ≥ 1} does not converge
point-wise to X. However, note that Xn(ω) → X(ω), except for ω = 0.
Thus, if A = (0, ∞), then Xn → X on A.
(ii) Suppose a random variable X is defined as follows.
X(ω) = 
0, if ω ∈ (0, ∞)
1, if ω = 0.
Then Xn → X on Ω.
2.6.18 Suppose a random variable X is defined on (Ω, A, P) and X ∼ N(0, 1)
distribution. Suppose An = [X ≤ 1/n]. Find limn→∞ P(An).
Solution: Observe that An = [X ≤ 1/n] = {ω|X(ω) ≤ 1/n} =
X−1
(Sn), where Sn = (−∞, 1/n]. Note that Sn+1 ⊂ Sn, ∀ n ≥ 1.
Hence, {Sn, n ≥ 1} is a decreasing sequence with limit S = (−∞, 0].
Hence, {An = X−1
(Sn), n ≥ 1} is also a decreasing sequence with limit502 Solutions to Conceptual Exercises
A = X−1
(S) = X−1
(−∞, 0] = [X ≤ 0]. Now by the continuity theorem
for a probability measure,
limn→∞
P(An) = P( limn→∞
An) = P[X ≤ 0] = 1/2.
2.6.19 Suppose a random variable X is defined on (Ω, A, P) and X ∼ χ
2
5 and
An = [X ≤ 1/n]. Find limn→∞ P(An).
Solution: As in the previous example,
limn→∞
P(An) = P( limn→∞
An) = P[X ≤ 0] = 0,
since X ∼ χ
2
5
.
2.6.20 Suppose a random variable X is defined on (Ω, A, P) and X has expo￾nential distribution with mean 1 and An = [1−1/n ≤ X ≤ 2+1/n]. Find
limn→∞ P(An). Suppose Bn = [n < X ≤ n + 1]. Find limn→∞ P(Bn).
Solution: As in Exercise 2.6.17, note that {An, n ≥ 1} is a decreasing
sequence and decreases to [X ∈ [1, 2]] = A. Hence,
limn→∞
P(An) = P( limn→∞
An) = P(A) = P[1 ≤ X ≤ 2]
= e
−1 − e
−2 = 0.2325.
Observe that Bn = [n < X ≤ n + 1] = [X ∈ (n, n + 1] is a sequence of
mutually exclusive events and hence its limit is ∅. Hence, limn→∞
P(Bn) =
P( limn→∞
Bn) = 0.
2.6.21 Suppose a random variable X is defined on (Ω, A, P) and P[X = n] =
an, n ∈ N, an ≥ 0 and P
n∈N
an = 1. Find limn→∞ P[X = n].
Solution: Suppose An = [X = n] = X−1
({n}). Then {An, n ≥ 1} is a
sequence of mutually exclusive events and hence its limit is ∅. Hence,
limn→∞
P(An) = P( limn→∞
An) = 0.
Answers to the multiple choice questions, based on Chapter 2, are given
in Table 11.2.
TABLE 11.2
Answer Key to MCQs in Chapter 2
Q.No. 1 2 3 4 5 6 7 8 9 10
Ans a b b a,b a,b a,b b d b b
Q.No. 11 12 13 14 15 16 17 18 19 20
Ans b c b d b a,b,c,d b d a,c a
Q.No. 21 22 23 24 25 26 27 28 29 30
Ans c a a b cChapter 3 503
11.3 Chapter 3
3.5.1 Suppose functions F are defined as follows. In each case examine whether
F is a distribution function. If yes, find the set of points of discontinu￾ities and points of increase of a distribution function. Decompose the
distribution function and decide the type of distribution function F.
(i) F(x) =



0, if x < 0,
x
2
/4, if 0 ≤ x < 2,
1, if x ≥ 2.
(ii) F(x) =



0, if x < 0,
x
2
, if 0 ≤ x ≤
2
3
,
1, if x > 2
3
.
(iii)F(x) = 
0, if x ≤ 1,
1 −
1
x2 , if x > 1.
(iv)F(x) = 
0, if x ≤ 0,
1
2 +
1
2
e
−x
, if x > 0.
(v)F(x) = 
0, if x < 0,
1 −
1
2
e
−x
, if x ≥ 0.
(vi)F(x) =



0, if x < 0,
sin x, if 0 ≤ x < π
2
,
1, if x ≥
π
2
.
(vii) F(x) = sin x, 0 < x < π/2.
(viii) F(x) = sin x, x ∈ R.
(ix)F(x) =



0, if x < 0,
x/2, if 0 ≤ x < 1,
1, if x ≥ 1.
(x) F(x) =



0, if x < 2,
x/3, if 2 ≤ x < 3,
1, if x ≥ 3.
Solution: (i) It satisfies the four requirements of a distribution function and
hence is a distribution function. Further, set of points of discontinuities is
∅. Hence, it is a distribution function of an absolutely continuous random
variable. The set of points of increase is [0, 2].
(ii) Here F is not right continuous at x = 2/3 and hence it is not a distribution
function.
(iii) It satisfies the four requirements of a distribution function and hence is a
distribution function. Further, set of points of discontinuities is ∅. Hence, it is
a distribution function of an absolutely continuous random variable. The set
of points of increase is [1, ∞).
(iv) For x > 0 it is decreasing and as x → ∞ it tends to 1/2. Further, F
is not right continuous at x = 0 and hence it is not a distribution function.
(v) It satisfies the four requirements of a distribution function and hence is
a distribution function. It can be decomposed as F = l1F1 + l2F2, where
l1 = l2 = 1/2, F1 is a distribution function of a discrete random variable X1
which is degenerate at 0 and F2 is a distribution function of an absolutely
continuous random variable X2 which has exponential distribution with mean
1.
(vi) It satisfies the four requirements of a distribution function and hence is
a distribution function. The set of points of discontinuities is ∅ and the set
of points of increase is [0, π/2]. It is an absolutely continuous distribution
function.504 Solutions to Conceptual Exercises
(vii) Domain of F is not R and hence it is not a distribution function.
(viii) F is not non-decreasing on R and hence it is not a distribution function.
(ix) It satisfies the four requirements of a distribution function and hence is
a distribution function. Note that 1 is a point of discontinuity with size 1/2.
Hence G and H are given by,
G(x) = 
0, if x < 1,
1/2, if x ≥ 1
& H(x) =



0, if x < 0,
x/2, if 0 ≤ x < 1,
1/2, if x ≥ 1.
Hence, F1(x) = G(x)/l1 & F2(x) = H(x)/l2 where l1 = l2 = 1/2 and
F(x) = l1F1(x) + l2F2(x).
(x) It satisfies the four requirements of a distribution function and hence is
a distribution function. Further, 2 is a point of discontinuity with size 2/3.
Hence G and H are given by,
G(x) = 
0, if x < 2,
2/3, if x ≥ 2
& H(x) =



0, if x < 2,
(x − 2)/3, if 2 ≤ x < 3,
1/3, if x ≥ 2.
Hence, F1(x) = G(x)/l1 & F2(x) = H(x)/l2 where l1 = 2/3 & l2 = 1/3 and
F(x) = l1F1(x) + l2F2(x).
3.5.2 If D is the set of points of discontinuity of a distribution function, give an
example of each of the following types of distribution functions.
(i) D is empty. (ii) D is singleton. (iii) D is finite, but not singleton. (iv) D
is countably infinite. Write the distribution function or probability density
function or probability mass function.
Solution: (i) If the set D = ∅, then the corresponding distribution function
is continuous. For example, the distribution function of any absolutely con￾tinuous distribution, such as exponential distribution with probability density
function f(x) = λe−λx, x > 0 and 0 otherwise.
(ii) For a degenerate distribution, D is singleton. The probability mass func￾tion of a random variable X ≡ C is P[X = C] = 1.
(iii) For a Binomial B(n, p) distribution, D is finite and is given by D =
{0, 1, · · · , n}. Its probability mass function is P[X = i] = ￾n
i

p
i
(1 − p)
n−i
,
i ∈ D. (iv) For a Poisson distribution D is countably infinite, given by
D = W, the set of whole numbers. Its probability mass function is P[X =
i] = e
−λλ
i
/i!, i ∈ D.
3.5.3 A function F : R → R is defined as F(x) = 0 if x ≤ 0 and
F(x) = α + ke−x
2/2
if x > 0. Determine values of α and k so that F is a
distribution function.
Solution: For F to be a distribution function it has to be a right continuous
function on R. Thus, from the right continuity at x = 0 we have,
limh→0
F(0 + h) = F(0) = 0 ⇒ limh→0
(α + ke−h
2/2
) = α + k = 0.
Further, limx→∞ F(x) = 1 ⇒ α + 0 = 1 ⇒ α = 1 and hence k = −1Chapter 3 505
3.5.4 Examine whether a convex combination of k distribution functions is a distri￾bution function.
Solution: Suppose F(x) = Pk
i=1 αiFi(x), x ∈ R is a convex combination
of distribution functions Fi, αi ≥ 0, i = 1, 2, · · · , k and Pk
i=1 αi = 1. We
examine whether F satisfies the four requirements of a distribution function.
(i) Observe that ∀ x ∈ R,
0 ≤ Fi(x) ≤ 1 ⇒ 0 ≤ αiFi(x) ≤ αi, ∀ i = 1, 2, · · · , k
⇒ 0 ≤
Xk
i=1
αiFi(x) ≤
Xk
i=1
αi ⇒ 0 ≤ F(x) ≤ 1.
(ii) Further ∀ x1 < x2 ∈ R
Fi(x1) ≤ Fi(x1) ⇒ αiFi(x1) ≤ αiFi(x1) ∀ i = 1, 2, · · · , k
⇒
Xk
i=1
αiFi(x1) ≤
Xk
i=1
αiFi(x2)
⇒ F(x1) ≤ F(x1) ⇒ F is non-decreasing on R.
(iii) Fi being a distribution function is right continuous for each i. Thus, for
x ∈ R and for each i,
limh→0
Fi(x + h) = Fi(x) ⇒ limh→0
αiFi(x + h) = αiFi(x)
⇒ limh→0
Xk
i=1
αiFi(x + h) = Xk
i=1
αiFi(x)
⇒ limh→0
F(x + h) = F(x)
⇒ F is right continuous on R.
(iv) Note that for each i
limx→∞
Fi(x) = 1 ⇒ limx→∞
αiFi(x) = αi
⇒ limx→∞
Xk
i=1
αiFi(x) = Xk
i=1
αi ⇒ limx→∞
F(x) = 1.
On similar lines, we have limx→−∞ F(x) = 0. Thus, a convex combination of
k distribution functions is a distribution function.
3.5.5 Does there exist a distribution function F such that ∀ x, y ∈ R
F(x + y) = F(x) + F(y)? Justify your answer.
Solution: Allow x, y → ∞ in F(x + y) = F(x) + F(y), then we get 1 = 2.
Hence, we conclude that there does not exist a distribution function such that
F(x + y) = F(x) + F(y) ∀ x, y ∈ R.
3.5.6 Suppose F and G are distribution functions of X and Y respectively. If X > Y
on Ω, show that F(x) ≤ G(x) ∀ x ∈ R. Show that the converse is not true.
Solution: Since X > Y on Ω, ∀ x ∈ R,
X(ω) ≤ x ⇒ Y (ω) ≤ x ⇒ P[X ≤ x] ≤ P[Y ≤ x] ⇒ F(x) ≤ G(x).506 Solutions to Conceptual Exercises
To show that the converse is not true, suppose X ∼ U(0, 1) and
Y = q(1 − X) where 0 < q < 1. Suppose F and G denote the distribution
functions of X and Y respectively. From F we find the distribution function
G of Y and it is given by G(x) = 1−F(1−x/q). Thus, F and G are given by,
F(x) =



0, if x < 0,
x, if 0 ≤ x < 1,
1, if x ≥ 1
& G(x) =



0, if x < 0,
x/q, if 0 ≤ x < q,
1, if x ≥ q.
Thus, Y ∼ U(0, q). For x < 0, F(x) = G(x) = 0. For 0 ≤ x < q < 1,
F(x) = x < x/q = G(x). For q ≤ x < 1, F(x) = x < G(x) = 1 and for
x ≥ 1, F(x) = G(x) = 1. Thus, F(x) ≤ G(x) ∀ x ∈ R. However, when
X(ω) = 0, Y (ω) = q > X(ω). Thus, X(ω) is not larger than Y (ω) for all
ω ∈ Ω.
3.5.7 Suppose a distribution function F : R → [0, 1] is defined as follows.
F(x) =



0, if x < −2,
0.2, if −2 ≤ x < 1,
0.2 + x
2
/10, if 1 ≤ x < 2,
0.6 + x/10, if 2 ≤ x < 3,
1, if x ≥ 3.
Decompose F into discrete and continuous components. Identify the distribu￾tions in the decomposition.
Solution: We first find a set of points of discontinuities and corresponding size
of the discontinuity. Observe that at F(−2−) = 0 ̸= 0.2 = F(−2), implying
that −2 is a point of discontinuity with size of discontinuity 0.2. Similarly,
F(1−) = 0.2 ̸= 0.3 = F(1), hence 1 is a point of discontinuitywith size of
discontinuity 0.1. Proceeding on similar lines we note that 2 and 3 are also
points of discontinuity, with respective sizes 0.2, 0.1. Hence, as in Theorem
3.3.1, we have G(x) = P
xn≤x
pxn , x ∈ R and H(x) = F(x) − G(x), x ∈ R.
G and H are given by,
G(x) =



0, if x < −2,
0.2, if −2 ≤ x < 1,
0.3, if 1 ≤ x < 2,
0.5, if 2 ≤ x < 3,
0.6, if x ≥ 3
& H(x) =



0, if x < 1,
x
2
10 −
1
10 , if 1 ≤ x < 2,
x
10 +
1
10 , if 2 ≤ x < 3,
0.4, if x ≥ 3.
Note that l1 = G(∞) = 0.6 and H(∞) = 1 − G(∞) = l2 = 0.4. Suppose F1
and F2 are defined as F1 = (1/l1)G and F2 = (1/l2)H so that F1(∞) = 1 and
F2(∞) = 1. Thus, F1 and F2 are given by,
F1(x) =



0, if x < −2,
2/6, if −2 ≤ x < 1,
3/6, if 1 ≤ x < 2,
5/6, if 2 ≤ x < 3,
1, if x ≥ 3
&F2(x) =



0, if x < 1,
x
2
4 −
1
4
, if 1 ≤ x < 2,
x
4 +
1
4
, if 2 ≤ x < 3,
1, if x ≥ 3.Chapter 4 507
It is easy to verify that F(x) = l1F1(x)+l2F2(x) for all x ∈ R. F1 is a discrete
distribution function and corresponding probability mass function is given by
{(−2, 2/6),(1, 1/6),(2, 2/6),(3, 1/6)}. F1 is a continuous distribution function
and it is differentiable with corresponding probability density function
f2(x) =



0, if x < 1 & x ≥ 3,
x/2, if 1 ≤ x < 2,
1/4, if 2 ≤ x < 3.
3.5.8 Suppose a distribution function F : R → [0, 1] is defined as follows.
F(x) =



0, if x < 0,
(pr + (1 − p)x)/5, if r ≤ x < r + 1, r = 0, 1, · · · , 4,
1, if x ≥ 5,
0 < p < 1. Examine whether F is a distribution function. If yes, decompose
F into discrete and continuous components. Identify the distributions in the
decomposition.
Solution: The given function satisfies the four requirements of the distribu￾tion function. Hence, it is a distribution function. It can be expressed as
F(x) =



0, if x < 0
(1 − p)x/5, if 0 ≤ x < 1
(p + (1 − p)x)/5, if 1 ≤ x < 2
(2p + (1 − p)x)/5, if 2 ≤ x < 3
(3p + (1 − p)x)/5, if 3 ≤ x < 4
(4p + (1 − p)x)/5, if 4 ≤ x < 5
1, if x ≥ 5,
Observe that the left hand limit at 0 is 0, F(0) = 0 and the right hand limit
is also 0. Thus, 0 is a point of continuity. Further, the left hand limit at 1 is
(1−p)/5, F(1) = 1/5 and the right hand limit is also 1/5. Thus, 1 is a point of
discontinuity. Similarly, 2, 3, 4, 5 are points of discontinuity. Thus, the set D of
points of discontinuity is D = {1, 2, 3, 4, 5}. Note that F can be decomposed
as l1F1 + l2F2 where l1 = p, l2 = 1 − p and F1, F2 are as follows.
F1(x) =



0, if x ≤ 1
1/5, if 1 ≤ x < 2
2/5, if 2 ≤ x < 3
3/5, if 3 ≤ x < 4
4/5, if 4 ≤ x < 5
1, if x ≥ 5
& F2(x) =



0, if x < 0
x/5, if 0 ≤ x < 5
1, if x ≥ 5,
Thus, F1 is a distribution function of the discrete random variable X1 with
probability mass function P[X1 = i] = 1/5, i = 1, 2, 3, 4, 5, which is the prob￾ability mass function of a discrete uniform distribution with support D. Fur￾ther, F2 is a distribution function of the absolutely continuous random variable
X2 with probability density function f(x) = 1/5,
x ∈ (0, 5), which is the probability density function of the uniform U(0, 5)
distribution.
Answers to the multiple choice questions, based on Chapter 3, are given
in Table 11.3.508 Solutions to Conceptual Exercises
TABLE 11.3
Answer Key to MCQs in Chapter 3
Q.No. 1 2 3 4 5 6 7 8 9 10
Ans c c c d a,b,d d b a b,c d
11.4 Chapter 4
4.6.1 Give an example of a discrete random variable with infinite mean.
Solution: Suppose X is a discrete random variable such that
P[X = 2i
] = 2−i
, i = 1, 2, · · · . Observe that
P[X < ∞] = X
i≥1
P[X = 2i
] = X
i≥1
2
−i = 1 but E(X) = X
i≥1
2
i
2
−i = ∞.
Thus, even if X is finite, E(X) is infinite.
4.6.2 Give an example of a discrete random variable with finite mean but with
infinite variance.
Solution: Suppose X is a discrete random variable such that
P[X = i] = c/i3
, i = 1, 2, · · · and c is a norming constant. Note that
E(X) = X
i≥1
i(c/i3
) = X
i≥1
c/i2 < ∞
but E(X2
) = X
i≥1
i
2
(c/i3
) = X
i≥1
c/i = ∞ ⇒ V ar(X) = ∞.
4.6.3 Suppose X and Y are random variables such that P[|X − Y | ≤ M] = 1
for some M > 0. Show that Y has finite mean if X has finite mean.
Solution: It is given that P[|X − Y | ≤ M] = 1. If E(X) ≥ 0, note that
X − M ≤ Y ≤ X + M a.s ⇒ E(X − M) ≤ E(Y ) ≤ E(X + M)
⇒ E(X) − M ≤ E(Y ) ≤ E(X) + M
⇒ −E(X) − M ≤ E(Y ) ≤ E(X) + M
⇒ |E(Y )| ≤ E(X) + M
⇒ E(Y ) < ∞ if E(X) < ∞
Similarly, if E(X) < 0, note that E(X) + M < −E(X) + M. Hence,
X − M ≤ Y ≤ X + M a.s ⇒ E(X − M) ≤ E(Y ) ≤ E(X + M)
⇒ E(X) − M ≤ E(Y ) ≤ E(X) + M
⇒ E(X) − M ≤ E(Y ) ≤ −E(X) + M
⇒ |E(Y )| ≤ −E(X) + M
⇒ E(Y ) < ∞ if E(X) < ∞Chapter 4 509
4.6.4 Show that for any non-negative random variable X,
(i) E(X) + E(1/X) ≥ 2 and (ii) E(max{X, 1/X}) ≥ 1.
Solution: (i) Note that
X ≥ 0 & (X − 1)2 ≥ 0 ⇒ (X − 1)2
/X ≥ 0 ⇒ X − 2 + 1/X ≥ 0
⇒ X + 1/X ≥ 2 ⇒ E(X) + E(1/X) ≥ 2.
(ii) Observe that
0 < X ≤ 1 ⇒ 1/X ≥ 1 ⇒ max{X, 1/X} ≥ 1
X ≥ 1 ⇒ 1/X ≤ 1 ⇒ max{X, 1/X} ≥ 1 ⇒ E(max{X, 1/X}) ≥ 1.
4.6.5 Prove that if V ar(X) = 0, then X = E(X) a.s.
Solution: The result follows from the fact that for a non-negative ran￾dom variable X, E(X) = 0 implies X = 0 a.s. Observe that
0 = V ar(X) = E(X−E(X))2 ⇒ X−E(X) = 0 a.s. ⇒ X = E(X) a.s.
4.6.6 Suppose X is an integrable random variable and A∆B is a null event.
Show that R
A X dP =
R
B X dP.
Solution: Note that A∆B is a null event implies that P(A∆B) = 0
which further implies that P(A ∩ Bc
) = 0 and P(Ac ∩ B) = 0. We use
the result that if X is an integrable random variable and A is a null
event, then R
A X dP = 0. Observe that
Z
A
X dP =
Z
A∩Bc
X dP +
Z
A∩B
X dP =
Z
A∩B
X dP
=
Z
A∩B
X dP +
Z
Ac∩B
X dP =
Z
B
X dP
4.6.7 Show that if X is A measurable and R
A X dP = 0 ∀ A ∈ A then
X = 0 a.s.
Solution: Suppose R
A X dP = 0 ∀ A ∈ A, but X ̸= 0 a.s. Thus, the
distribution function F of X is not of the form
F(x) = 
0, if x < 0
1, if x ≥ 0.
Thus, ∃ a > 0 such that 0 < F(a) < 1. Suppose A = (−∞, a], then
0 < P(A) < 1 ⇒ 0 < P(Ac
) < 1. On Ac
, X > a. Hence,
R
Ac X dP > aP(Ac
) > 0 which is a contradiction to the given statement
that R
A X dP = 0 ∀ A ∈ A. Hence, the assumption that X ̸= 0 a.s.
is wrong. Thus, R
A X dP = 0 ∀ A ∈ A implies that X = 0 a.s.510 Solutions to Conceptual Exercises
4.6.8 Prove or disprove: X ≡ 0 implies R
Ω XdP = 0, but R
Ω XdP = 0 may
not imply X ≡ 0.
Solution: If X ≡ 0, that is, X = 0 a.s. then it is proved that E(X) = 0.
However, converse is not true. Suppose X is a discrete random vari￾able with probability mass function{(−1, 1/3),(0, 1/3),(1, 1/3)}. Then
E(X) = 0 but P[X = 0] = 1/3 ̸= 1. Thus, E(X) = 0 may not imply
X ≡ 0.
4.6.9 Suppose Ω = {−2, −1, 3, 7} and A is a powerset of Ω. A measure µ
on (Ω, A) is defined as µ({−2}) = 2, µ({−1}) = 1, µ({3}) = 3 and
µ({7}) = 7. Obtain a probability measure P from µ. Suppose a random
variable X is defined on (Ω, A, P) as follows. Find R
Ω X dP.
X(ω) = 
1, if ω = 3 or 7
−1, if ω = −2 or − 1.
Solution: For the given measure µ(Ω) = 13 and hence the correspond￾ing probability measure P is given by,
P({−2})= 2/13, P({−1}) = 1/13, P({3})= 3/13 & P({7})= 7/13.
Further, X is a simple random variable. Hence, R
Ω X dP = 1(P({3}) +
P({7})) − 1(P({−2}) + P({−1})) = 10/13 − 3/13 = 7/13.
4.6.10 Suppose (Ω, A, P) is a probability space where A is a sigma field gener￾ated by a countable partition {An, n ≥ 1} of Ω. Suppose a random vari￾able X is defined on (Ω, A, P) as X = i on Ai
, i ≥ 1. Find R
Ω X dP if the
probability measure P is defined as (i) P(Ai) = c/i3
P
, where c is such that
i≥1
c/i3 = 1, (ii) P(Ai) = c/i2
, where c is such that P
i≥1
c/i2 = 1 and
(iii) P(Ai) = 1/2
i
. In all the three cases, find R
Ω
Y dP, when Y = X2
and Y = e
X.
Solution:Note that X is an elementary random variable. Hence,
(i)
Z
Ω
X dP = E(X) = X
i≥1
ic/i3 = c
X
i≥1
1/i2 < ∞
(ii)
Z
Ω
X dP = E(X) = X
i≥1
ic/i2 = c
X
i≥1
1/i = ∞
(iii)
Z
Ω
X dP = E(X) = X
i≥1
i/2
i
= (1/2)(1 + (1/2) + (1/2)2 + (1/2)3 + · · ·)
= (1/2)((1/2))−2 = 2.Chapter 4 511
Suppose Y = X2
. Then
(i)
Z
Ω
Y dP = E(Y ) = X
i≥1
i
2
c/i3 = ∞
(ii)
Z
Ω
Y dP = E(Y ) = X
i≥1
i
2
c/i2 = ∞
(iii)
Z
Ω
X dP = E(Y ) = X
i≥1
i
2
/2
i < ∞.
since by the ratio test the series P
i≥1
i
2/2
i
is convergent. Suppose Y = e
X.
Then
(i)
Z
Ω
Y dP = E(Y ) = X
i≥1
e
i
c/i3 = ∞
(ii)
Z
Ω
Y dP = E(Y ) = X
i≥1
e
i
c/i2 = ∞
(iii)
Z
Ω
X dP = E(Y ) = X
i≥1
e
i
/2
i = ∞.
since in all the three cases, by the ratio test the concerned series are
divergent.
4.6.11 Suppose a distribution function F : R → [0, 1] is defined as follows.
F(x) =



0, if x < 0,
0.2, if 0 ≤ x < 1,
0.5, if 1 ≤ x < 2,
0.8, if 2 ≤ x < 4,
1, if x ≥ 4.
Compute E(X) from F(x), without finding the probability mass func￾tion.
Solution: It is clear that the given distribution function F is a discrete
distribution function with points of discontinuity as 0, 1, 2, 4, with re￾spective jump sizes as 0.2, 0.3, 0.3, 0.2. Thus, we find E(X) using the
formula E(X) = R
R
g(x)dF(x) as a Riemann-Stieltjes integral for a step
function F. Thus,
E(X) = 0 × 0.2 + 1 × 0.3 + 2 × 0.3 + 4 × 0.2 = 1.7.512 Solutions to Conceptual Exercises
4.6.12 Suppose a distribution function F : R → [0, 1] is defined as follows.
F(x) =



0, if x < −2,
1/3, if −2 ≤ x < 0,
1/2, if 0 ≤ x < 5,
1/2 + (x − 5)2/2, if 5 ≤ x < 6,
1, if x ≥ 6.
Find (i) E(X) from F(x). (ii) Decompose F into discrete and contin￾uous components. (iii) Find the probability mass function of a discrete
random variable and the probability density function of a continuous
random variable involved in the decomposition and hence find E(X).
Solution: It is clear that the given distribution function F is neither
discrete nor continuous. Thus, we find E(X) using the formula
E(X) = R
R
g(x)dF(x) as a Riemann-Stieltjes integral. Thus,
E(X) = −2 ×
1
3
+ 0 ×
1
6
+
Z 6
5
x(x − 5) dx = −
2
3
+
17
6
=
13
6
.
In Example 3.3.1, it is shown that the distribution function F can be
expressed as,
F(x) =



0, if x < −2,
1/2 × 2/3, if −2 ≤ x < 0,
1/2 × 1, if 0 ≤ x < 5,
1/2 + 1/2(x − 5)2
, if 5 ≤ x < 6,
1/2 + 1/2, if x ≥ 6,
Suppose
F1(x) =



0, ifx < −2,
2/3, if − 2 ≤ x < 0,
1, ifx ≥ 0.
& F2(x) =



0, ifx < 5,
(x − 5)2
, if5 ≤ x < 6,
1, ifx ≥ 6.
Then F = (1/2)F1 + (1/2)F2 where F1 is a distribution function of a
discrete random variable with possible values −2, 0 with respective prob￾abilities 2/3, 1/3. Thus its mean is −4/3. F2 is a distribution function
of an absolutely continuous random variable with probability density
function f(x) = 2(x − 5) with support (5, 6). Its mean is 17/3. Using
this approach E(X) = (1/2)(−4/3) + (1/2)(17/3) = 13/6.
4.6.13 Suppose a distribution function F : R → [0, 1] is defined as follows.
F(x) =



0, if x < −2,
0.2, if −2 ≤ x < 1,
0.2 + x
2/10, if 1 ≤ x < 2,
0.6 + x/10, if 2 ≤ x < 3,
1, if x ≥ 3.Chapter 4 513
Find (i) E(X) from F(x). (ii) Decompose F into discrete and continuous
components. (iii) Identify the distributions in the decomposition and
hence find E(X).
Solution: In Exercise 7 in Chapter 3, we have noted that −2, 1, 2, 3 are
points of discontinuities with respective sizes 0.2, 0.1, 0.2, 0.1. On the
intervals (1, 2) and (2, 3), F is differentiable. Hence using the definition
of Reimann-Stieltjes integral E(X) is obtained as follows.
E(X) = −2 × 0.2 + 1 × 0.1 + 2 × 0.2 + 3 × 0.1
+
Z 2
1
x(x/5) dx +
Z 3
2
x(1/10) dx = 2/5 + 7/17 + 1/4 = 67/60.
In the same exercise, we have shown that F can be decomposed as
F(x) = l1F1(x) + l2F2(x) ∀ x ∈ R, where l1 = 0.6, l2 = 0.4 and F1 and
F2 are given by,
F1(x) =



0, if x < −2,
2/6, if −2 ≤ x < 1,
3/6, if 1 ≤ x < 2,
5/6, if 2 ≤ x < 3,
1, if x ≥ 3.
& F2(x) =



0, if x < 1,
x
2
4 −
1
4
, if 1 ≤ x < 2,
x
4 +
1
4
, if 2 ≤ x < 3,
1, if x ≥ 3.
F1 is a discrete distribution function and corresponding probability mass
function is given by, {(−2, 2/6),(1, 1/6),(2, 2/6),(3, 1/6)}. Its mean is
2/3. F2 is a continuous distribution function and it is differentiable with
corresponding probability density function
f2(x) =



0, if x < 1 & x ≥ 3,
x/2, if 1 ≤ x < 2,
1/4, if 2 ≤ x < 3.
Mean corresponding to F2 is 43/24. Hence,
E(X) = 0.6 × (2/3) + 0.4 × (43/24) = 67/60.
4.6.14 Suppose a distribution function F : R → [0, 1] is defined as follows.
F(x) =



0 , if x < 2
(2/3)x − 1 , if 2 ≤ x < 3
1 , if x ≥ 3.
Find (i) E(X) from F(x). (ii) Decompose F into discrete and continuous
components. (iii) Identify the distributions in the decomposition and
hence find E(X).
Solution: The given distribution function F is neither discrete nor con￾tinuous. Thus, we find E(X) using the formula E(X) = R
R
g(x)dF(x)
as a Riemann-Stieltjes integral. It is clear that 2 is the only point of514 Solutions to Conceptual Exercises
discontinuity with jump size 1/3. For x ∈ (2, 3), F(x) is differentiable
with derivative f(x) = 2/3. Thus,
E(X) = 2 ×
1
3
+
Z 3
2
2
3
x dx =
2
3
+
5
3
=
7
3
.
The distribution function F can be expressed as,
F(x) =



0, if x < 2,
1
3
1 + 2
3
(x − 2), if 2 ≤ x < 3,
1
3
1 + 1
3
1, if x ≥ 3,
It is easy to check that F = (1/3)F1 + (2/3)F2 where
F1(x) = 
0, if x < 2,
1, if x ≥ 2.
& F2(x) =



0, if x < 2,
(x − 2), if 2 ≤ x < 3,
1, if x ≥ 3.
Note that F1 is a distribution function of a degenerate random variable,
degenerate at 2. Thus its mean is 2. F2 is a distribution function of an ab￾solutely continuous random variable with uniform U(2, 3) distribution.
Its mean is (5/2). Using this approach E(X) = (1/3)2 + (2/3)(5/2) =
7/3.
4.6.15 Suppose a distribution function F : R → [0, 1] is defined as follows.
F(x) =



0 , if x < 0
1/4 , if 0 ≤ x < 1
1 − (1/2)e
−(x−1)
, if x ≥ 1.
(i) Find E(X) from F(x). (ii) Decompose F into discrete and continuous
components. (iii) Identify the distributions in the decomposition and
hence find E(X).
Solution: It is clear that 0 and 1 are the two points of discontinuities
with respective sizes 1/4, 1/4. On the interval (1, ∞), F is differentiable
with derivative (1/2)e
−(x−1). Hence,
E(X) = 0 × (1/4) + 1 × (1/4) + (1/2) Z ∞
1
xe−(x−1) dx = 1/4 + 1 = 5/4.
Further, F can be decomposed as F(x) = l1F1(x)+l2F2(x) for all x ∈ R,
where l1 = 1/2, l2 = 1/2 and F1 and F2 are given by,
F1(x) =



0, if x < 0,
1/2, if 0 ≤ x < 1,
1, if x ≥ 1.
& F2(x) = 
0, if x < 1,
1 − e
−(x−1)
, if x ≥ 1.
Note that F1 is a discrete distribution function and corresponding prob￾ability mass function is given by, {(0, 1/2),(1, 1/2)}. Its mean is 1/2. F2Chapter 4 515
is a continuous distribution function and it is differentiable with corre￾sponding probability density function
f2(x) = 
0, if x < 1,
e
−(x−1)
, if x ≥ 1.
It is the probability density function of a random variable following the
exponential distribution with location parameter 1 and scale parameter
1. Mean corresponding to F2 is 2. Hence, E(X) = (1/2)(1/2)+ (1/2)2 =
5/4.
4.6.16 Suppose a distribution function F : R → [0, 1] is defined as follows.
F(x) =



0, if x < 0,
(pr + (1 − p)x)/k, if r ≤ x < r + 1, r = 0, 1, · · · , k − 1,
1, ifx ≥ k,
0 < p < 1. (i) Find E(X) from F(x). (ii) Decompose F into discrete
and continuous components. (iii) Identify the distributions in the de￾composition and hence find E(X).
Solution: In Exercise 8 in Chapter 3, we have discussed such a distri￾bution function with k = 5. Proceeding on similar lines we note that the
set D of points of discontinuity of F is D = {1, 2, · · · , k} with size of
discontinuity to be p/k for each. Further, on the interval (r, r + 1), F is
continuous and differentiable with derivative (1−p)/k, r = 0, 1, · · · , k−1.
Hence,
E(X) = (p/k)
X
k
r=1
r + ((1 − p)/k)
k
X−1
r=0
Z r+1
r
x dx
= (p/k)(k(k + 1)/2) + ((1 − p)/2k)
k
X−1
r=0
[(r + 1)2 − r
2
]
= p(k + 1)/2 + ((1 − p)/2k)
k
X−1
r=0
(2r + 1)
= p(k + 1)/2 + ((1 − p)/2k)k
2 = p(k + 1)/2 + ((1 − p)k/2
= (p + k)/2.
Note that F can be decomposed as l1F1 + l2F2 where l1 = p, l2 = 1 − p
and F1, F2 are as follows.
F1(x) =



0, if x ≤ 1
r
k
, if r ≤ x < r + 1,
r = 0, 1, · · · , k − 1,
1, if x ≥ k,
& F2(x) =



0, if x < 0
x
k
, if 0 ≤ x < k
1, if x ≥ k,
Thus, F1 is a distribution function of the discrete random variable X1
with probability mass function P[X1 = i] = 1/k, i = 1, 2, · · · , k, which516 Solutions to Conceptual Exercises
is the probability mass function of a discrete uniform distribution with
support D and its mean is (k + 1)/2. Further, F2 is a distribution func￾tion of the absolutely continuous random variable X2 with probability
density function f(x) = 1/k, x ∈ (0, k), which is the probability density
function of the uniform U(0, k) distribution. Its mean is k/2. Hence,
E(X) = p(k + 1)/2 + (1 − p)k/2 = (p + k)/2.
4.6.17 Prove that if X ≥ 0 then E(X) = 0 ⇒ X = 0 a.s.
Solution: If a non-negative random variable X is a simple random
variable, then in Theorem 4.2.2 it is proved that E(X) = 0 implies
X = 0 a.s. Suppose now X is a non-negative random variable. To prove
X = 0 a.s., we have to prove that P[X > 0] = 0, X being a non-negative
random variable. Note that
P[X > 0] = P[
[
n≥1
[X ≥ 1/n]] ≤
X
n≥1
P[X ≥ 1/n] = X
n≥1
P(An),
where An = [X ≥ 1/n], n ≥ 1. Note that
(1/n)IAn ≤ XIAn ≤ X ⇒ E((1/n)IAn
) ≤ E(XIAn
) ≤ E(X)
⇒ (1/n)P(An) ≤ E(XIAn
) ≤ E(X) = 0
⇒ P(An) = 0 ∀ n ≥ 1
⇒ P[X > 0] = 0 ⇒ P[X = 0] = 1
⇒ X = 0 a.s.
4.6.18 If X ≥ 0 on A and R
A X dP = 0 then show that X = 0 a.s. on A.
Solution:
P
Suppose X is a simple random variable defined as X =
k
i=1 aiAi where A1, A2, · · · , Ak is a partition of A. It is given that
X ≥ 0 on A. Suppose on A1, X = 0, that is, a1 = 0 and on all
other partition sets X > 0, that is, ai > 0 for i = 2, 3, · · · , k. Now
R
A X dP =
Pk
i=1 aiP(Ai) = 0. Thus, sum of non-negative numbers is
0, so each term must be 0. Note that
0 = Z
A
X dP = a1P(A1) +X
k
i=2
aiP(Ai) = X
k
i=2
aiP(Ai)
⇒ P(Ai) = 0 ∀ i = 2, 3, · · · , k
⇒ P(A1) = P[X = 0] = 1 ⇒ X = 0 a.s. on A.
Suppose X ≥ 0. Then Y = XIA ≥ 0 and R
A X dP = 0 ⇐⇒
E(XIA) = E(Y ) = 0. Hence the result follows using the similar ar￾guments as in the previous exercise.Chapter 4 517
4.6.19 If a ≤ X ≤ b a.s. on A then show that aP(A) ≤
R
A X dP ≤ bP(A).
Solution: Observe that
a ≤ X ≤ b a.s. on A ⇒ aIA ≤ XIA ≤ bIA
⇒
Z
Ω
aIA ≤
Z
Ω
XIA ≤
Z
Ω
bIA
⇒ aP(A) ≤
Z
A
X dP ≤ bP(A).
4.6.20 Examine whether following functions are characteristic functions.
(i) ϕ(t/a) exp(ibt), a ̸= 0, b ∈ R and ϕ is a characteristic function,
(ii) ϕ(−t), where ϕ is a characteristic function,
(iii) Pk
i=1 ajϕj (t), aj ≥ 0 and Pk
i=1 aj = 1 and ϕj (t) are characteristic
functions for all j = 1, 2, · · · , k and (iv) ϕ(t) = 1/(1 + t
4
) where t ∈ R.
Solution: (i) It is given that ϕ is a characteristic function. Suppose a
random variable Y is defined as Y = X/a + b. Then
ϕY (t) = E(e
itY ) = e
itbE(e
itX/a) = e
itbϕ(t/a).
Hence, ϕ(t/a) exp(ibt) is a characteristic function.
(ii) Observe that E(e
−itX) = E(e
i(−t)X) = ϕ(−t). Thus, ϕ(−t) is a
characteristic function of −X if ϕ(t) is a characteristic function of X.
(iii) Suppose a distribution function F of X is a convex combination of
k distribution functions given by, F(x) = Pk
i=1 ajFj (x), x ∈ R. Then
observe that
E(e
itX) = Z
e
itx dF(x) = Z
e
itx d
X
k
i=1
ajFj (x)
=
X
k
i=1
aj
Z
e
itx dFj (x) = X
k
i=1
ajϕj (t).
Hence, Pk
i=1 ajϕj (t) is a characteristic function.
(iv) Suppose ϕ(t) = 1/(1 + t
4
) is a characteristic function. Then it is a
differentiable function and derivatives of all order at t = 0 exist. Hence,
moments of all order exist and can be obtained by taking successive
derivatives and substituting t = 0. Thus,
d
dt
1
1 + t
4
= −
4t
3
(1 + t
4)
2
&
d
2
dt2
1
1 + t
4
=
−12t
3
(1 + t
4
)
2 + 32t
6
(1 + t
4
)
(1 + t
4)
4
⇒ µ
′
1 = 0, µ′
2 = 0 .
First two raw moments are 0 implies that ϕ(t) is a characteristic function
of a random variable X which is degenerate at 0. However, if X is
degenerate at 0, then its characteristic function is E(e
itX) = 1 which518 Solutions to Conceptual Exercises
is not same as characteristic function 1/(1 + t
4
). Hence our assumption
that ϕ(t) = 1/(1 +t
4
) is a characteristic function is wrong. Thus, ϕ(t) =
1/(1 + t
4
) is not a characteristic function.
4.6.21 Suppose a discrete random variable has finite second moment. Show
that it has finite mean.
Solution: We have a result which states that if r-th order moments are
finite, then all lower order moments are also finite. Alternatively, for a
discrete random variable X with probability mass function {(i, pi), i ≥
0}, E(X2
) = P
i≥0
i
2pi and it is given to be finite. Observe that by
Cauchy-Schwarz inequality,
X
i≥0
ipi
2
=
X
i≥0
X
j≥0
ipijpj ≤
X
i≥0
i
2
p
2
i
X
j≥0
j
2
p
2
j
1/2
≤
X
i≥0
i
2
pi
X
j≥0
j
2
pj < ∞.
In the second step, we use the result that if 0 ≤ a ≤ 1 then a
2 ≤ a.
4.6.22 Suppose Lr = {Z|E(|Z|
r
) < ∞}. Prove that the set Lr is closed under
addition.
Solution: Follows from the Cr inequality.
4.6.23 Suppose X ∼ U(0, 2) distribution then without evaluating, show that
E(X log X) ≥ 0.
Solution: Since X ∼ U(0, 2) distribution, E(X) = 1. Suppose
g : R
+ → R is defined as g(x) = x log x. Note that
g(x) = x log x ⇒
d
dxg(x) = 1 + log x ⇒
d
2
dx2
g(x) = 1/x > 0.
Hence g is a convex function and by Jensen’s inequality,
E(X log X) = E(g(X)) ≥ g(E(X)) = g(1) = 1 log 1 = 0.
Answers to the multiple choice questions, based on Chapter 4, are given
in Table 11.4.
TABLE 11.4
Answer Key to MCQs in Chapter 4
Q.No. 1 2 3 4 5 6 7 8 9 10
Ans b d d c d b,d d c a,c d
Q.No. 11 12 13 14 15 16 17 18 19 20
Ans b a c a c d a b c,d aChapter 5 519
11.5 Chapter 5
5.5.1 Prove or disprove: A P-null event is independent of itself.
Solution: Suppose N is a P-null event. Hence P(N) = 0. Observe that
P(N ∩ N) = P(N) = 0 = P(N)P(N) ⇒ N is independent of itself.
5.5.2 Suppose N is a P-null event. Examine whether Nc
is independent of
itself.
Solution: Suppose N is a P-null event. Hence P(Nc
) = 1. Note that
P(N
c∩N
c
) = P(N
c
) = 1 = P(N
c
)P(N
c
) ⇒ N
c
is independent of itself.
5.5.3 Suppose P(C|A ∩ B) = P(C|B) and P(A ∩ B ∩ C) > 0. Show that
P(A|B ∩ C) = P(A|B).
Solution: Note that
P(A ∩ B ∩ C) > 0 ⇒ P(A ∩ B), P(B ∩ C) & P(B) > 0.
Using the definition of conditional probability we have,
P(C|A ∩ B) = P(C|B) ⇒
P(A ∩ B ∩ C)
P(A ∩ B)
=
P(B ∩ C)
P(B)
⇒
P(A ∩ B ∩ C)
P(B ∩ C)
=
P(A ∩ B)
P(B)
⇒ P(A|B ∩ C) = P(A|B).
5.5.4 Prove or disprove: (i) Mutually exclusive events are independent.
(ii) Independent events are mutually exclusive.
Solution: (i) Suppose A and B are mutually exclusive events, hence
A ∩ B = ∅ ⇒ P(A ∩ B) = 0. Suppose Ω = {1, 2, 3, 4, 5, 6},
A = {1, 3, 5}, B = {2, 4, 6} with P(A) = P(B) = 1/2. Here A and B
are mutually exclusive events, but 0 = P(A ∩ B) ̸= P(A)P(B). Thus, A
and B are not independent.
(ii) Suppose Ω = {a, b, c, d}, A = {a, b}, B = {b, c} and ∀ ω ∈ Ω,
P({ω}) = 1/4. Then P(A) = P(B) = 1/2. A ∩ B = {b}, hence P(A ∩
B) = 1/4 = P(A)P(B). Thus, A and B are independent. Note that
A∩B = {b} ̸= ∅ which implies that A and B are not mutually exclusive
events. Thus there is no relation between mutually exclusive events and
independent events. Independence is defined in terms of probabilities
of events, while definition of mutually exclusive events does not need
probabilities associated with these events.520 Solutions to Conceptual Exercises
5.5.5 Show that two events A and B are independent if and only if σ({A})
and σ({B}) are independent. Show further that it is equivalent to IA
and IB are independent random variables.
Solution: Note that
σ({A}) = {Ω, ∅, A, Ac
} & σ({B}) = {Ω, ∅, B, Bc
}.
(i) Suppose A and B are independent. Then as proved in Theorem 5.2.1,
A and Ω, ∅, B, Bc are independent. Similarly, Ac and Ω, ∅, B, Bc are in￾dependent. Hence, σ({A}) and σ({B}) are independent. (ii) Suppose
σ({A}) and σ({B}) are independent. Hence every event in σ({A}) is
independent of every event in σ({B}) which implies A and B are inde￾pendent. IA and IB are independent random variables, if the induced
sigma fields are independent. Note that
σ(IA) = {Ω, ∅, A, Ac
} & σ(IB) = {Ω, ∅, B, Bc
}.
Thus, IA and IB are independent random variables if and only if A and
B are independent events.
5.5.6 Give an example of events A1, A2, A3 which are pair-wise independent
but not independent.
Solution: Suppose a probability space (Ω, A, P) is defined as follows.
Ω = {a, b, c, d}, A = P(Ω) and P({ω}) = 1/4 ∀ ω ∈ Ω. Suppose events
Ai
, i = 1, 2, 3 are defined as follows.
A1 = {a, b}, A2 = {a, c} & A3 = {b, c}.
Then it is clear that for i = 1, 2, 3,
P(Ai) = 1/2, P(Ai∩Aj ) = 1/4 i ̸= j = 1, 2, 3 & P(A1∩A2∩A3) = 0.
Observe that ∀ i ̸= j = 1, 2, 3, P(Ai ∩ Aj ) = P(Ai)P(Aj ), however
0 = P(A1 ∩ A2 ∩ A3) ̸= P(A1)P(A2)P(A3). Thus, A1, A2, A3 are pair￾wise independent but not mutually independent.
5.5.7 Suppose {An, n ≥ 1} is a sequence of independent events. Show that
P
 Sk
r=1 Air

= 1−
Qk
r=1(1−P(Air
)), for any combination i1, i2, · · · , ik
of 1, 2, · · · , k and for finite k ≥ 2.
Solution: Since {An, n ≥ 1} is a sequence of independent events, its
every finite sub-collection is a collection of independent events. Thus,
for finite k ≥ 2 and for any combination i1, i2, · · · , ik of 1, 2, · · · , k,
{Ai1
, Ai2
, · · · , Aik
} are independent events. Hence, {Ac
i1
, Ac
i2
, · · · , Ac
ik
}Chapter 5 521
are also independent events. Observe that
P
 [
k
r=1
Air

= P
 [
k
r=1
Air
cc
= 1 − P
 [
k
r=1
Air
c
= 1 − P
 \
k
r=1
A
c
ir

= 1 −
Y
k
r=1
P(A
c
ir
) = 1 −
Y
k
r=1
(1 − P(Air
)).
5.5.8 Suppose X1 and X2 are random variables defined on (Ω, A, P), where
Ω = {a, b, c}, A = P(Ω) and P is defined as ∀ ω ∈ Ω, P({ω}) = 1/3.
X1(ω) = 
0, if ω = a
1, if ω = b, c. & X2(ω) = 
2, if ω = b
3, if ω = a, c.
(i) Examine whether X1 and X2 are independent random variables on
(Ω, A, P). (ii) Examine whether 5X2
1 + 4 and 3X3
2 +e
X2 are independent
random variables on (Ω, A, P).
Solution: (i) To examine whether X1 and X2 are independent random
variables, we examine whether the induced sigma fields are independent.
Note that
X
−1
1
(B) = {Ω, ∅, {a}, {b, c}} & X
−1
2
(B) = {Ω, ∅, {b}, {a, c}}.
Observe that P({a} ∩ {b}) = P(∅) = 0 ̸= P({a})P({b}). Hence, X1 and
X2 are not independent.
(ii) Note that 5X2
1 + 4 and 3X3
2 + e
X2 are Borel functions of X1 and
X2 respectively. We have a result which states that if X1 and X2 are
independent random variables, then any Borel function of X1 is inde￾pendent of any Borel function of X2. However, if X1 and X2 are not
independent random variables, then we cannot conclude that a Borel
function of X1 is not independent of a Borel function of X2. Hence,
to examine whether 5X2
1 + 4 and 3X3
2 + e
X2 are independent random
variables, we find their induced sigma fields and examine whether these
are independent. Observe that 5X2
1 + 4 and 3X3
2 + e
X2 are one-to-one
functions of X1 and X2 respectively. Hence the sigma fields induced by
5X2
1 + 4 and 3X3
2 + e
X2 are the same as those induced by X1 and X2
respectively. But from (i) we note that the sigma fields induced by X1
and X2 are not independent which implies that the sigma fields induced
by 5X2
1 + 4 and 3X3
2 + e
X2 are not independent. Thus, 5X2
1 + 4 and
3X3
2 + e
X2 are not independent random variables.
5.5.9 Suppose (Ω, A, P) is a probability space, where Ω = {a, b, c, d}, A =
P(Ω) and P({ω}) = 1/4 ∀ ω ∈ Ω. Suppose X1 and X2 are random
variables defined on (Ω, A, P) as follows.
X1(ω) = 
10, if ω = a, b
20, if ω = c, d. & X2(ω) = 
30, if ω = a, c
40, if ω = b, d.522 Solutions to Conceptual Exercises
Examine whether e
5X1−7 and log(4X2 + 9) are independent random
variables.
Solution: Note that e
5X1−7 and log(4X2 + 9) are Borel functions of
X1 and X2 respectively. These are independent random variables, if X1
and X2 are independent random variables. To examine whether X1 and
X2 are independent random variables, we examine whether the induced
sigma fields are independent. Suppose A = {a, b} and B = {a, c}. Note
that
X
−1
1
(B) = {Ω, ∅, A, Ac
} & X
−1
2
(B) = {Ω, ∅, B, Bc
}.
Observe that P(A ∩ B) = P({a}) = 1/4 = P(A)P(B). Hence, A and
B are independent. As a consequence, X
−1
1
(B) and X
−1
2
(B) are inde￾pendent. Hence, X1 and X2 are independent random variables which
further implies that e
5X1−7 and log(4X2 + 9) are independent random
variables.
5.5.10 Suppose (Ω, A, P) is a probability space and {A1, A2, A3} is a measur￾able partition of Ω. Suppose B ∈ A. Show that a random variable X
defined as X =
P3
i=1 iIAi
and IB are independent if and only if B is
independent of each of {A1, A2, A3}.
Solution: The sigma field induced by IB is given by I
−1
B (B) =
{Ω, ∅, B, Bc} and the sigma field induced by X is given by
X−1
(B) = {Ω, ∅, A1, A2, A3, A1 + A2, A1 + A3, A2 + A3}.
Suppose B is independent of each of {A1, A2, A3}. Then B is inde￾pendent of Ac
3 = A1 + A2, Ac
2 = A1 + A3, Ac
1 = A2 + A3. Any event
is always independent of Ω and ∅. Similarly, Bc
is independent of all
sets in X−1
(B). Hence, X and IB are independent random variables.
Conversely, suppose X and IB are independent random variables which
implies X−1
(B) and I
−1
B (B) are independent sigma fields. Thus, every
event in X−1
(B) is independent of every event in I
−1
B (B) and hence B
is independent of each of {A1, A2, A3}.
5.5.11 Suppose (Ω, A, P) is a probability space and A, B, C ∈ A are indepen￾dent events. Examine whether C is independent of an event obtained
from A and B by complementation, union and intersection.
Solution: Using the arguments as in the proof of Theorem 5.2.1,
independence of A, B, C implies independence of Ac
, B, C, A, Bc
, C,
A, B, Cc
, Ac
, Bc
, C, Ac
, B, Cc
, A, Bc
, Cc and Ac
, Bc
, Cc
. To examine
whether, A ∪ B is independent of C, observe that
P((A ∪ B) ∩ C) = P((A ∩ C) ∪ (B ∩ C))
= P(A ∩ C) + P(B ∩ C)) − P(A ∩ B ∩ C)
= P(A)P(C) + P(B)P(C) − P(A)P(B)P(C)
= P(A ∪ B)P(C).Chapter 5 523
Thus, A∪B is independent of C. Hence, (A∪B)
c = Ac ∩Bc
is indepen￾dent of C and C
c
. Further, A ∪ B is independent of C
c
. Since Ac
, Bc
, C
are independent, Ac∪Bc
is independent of C. Hence, (Ac∪Bc
)
c = A∩B
is independent of C. It also follows from the definition of independence
of A, B, C, since independence of A, B, C implies that all possible pairs
are independent and P(A ∩ B ∩ C) = P(A)P(B)P(C). On similar lines,
since A, Bc
, C are independent, A ∪ Bc
is independent of C. Hence,
(A ∪ Bc
)
c = Ac ∩ B is independent of C and C
c
. Using the same argu￾ments, we can prove that if A, B, C ∈ A are independent events, then
C is independent of Ac ∪ B, Ac ∩ B, A ∩ Bc
.
5.5.12 Suppose (Ω, A, P) is a probability space and A, B, C ∈ A are indepen￾dent events. Can we claim that IA +3IB and IC are independent random
variables? Justify your answer.
Solution: Since A, B, C ∈ A are independent events, IA, IB, IC are
independent random variables. Suppose Z = (IA, IB)
′
. Then the sigma
field Z
−1
(B) induced by Z is defined as Z
−1
(B) = σ(I
−1
A (B) ∪ I
−1
B (B)).
The sigma fields induced by IA, IB, IC and Z are respectively given by,
I
−1
A (B) = {Ω, ∅, A, Ac
}, I−1
B (B) = {Ω, ∅, B, Bc
}
I
−1
C
(B) = {Ω, ∅, C, Cc
}
Z
−1
(B) = {Ω, ∅, A, Ac
, B, Bc
, A ∪ B, A ∪ B
c
,
A
c ∪ B, Ac ∪ B
c
, Ac ∩ B
c
, Ac ∩ B, A ∩ B
c
, A ∩ B}.
To examine whether Z = (IA, IB)
′ and IC are independent, we examine
whether Z
−1
(B) and I
−1
C
(B) are independent. It is known that Ω and
∅ are independent of any event in A. Further, as shown in the previous
exercise, C is independent of all other events in Z
−1
(B). Hence, Z =
(IA, IB)
′ and IC are independent. Further, IA + 3IB is a Borel function
of (IA, IB)
′
. Hence by Theorem 5.3.9, IA + 3IB and IC are independent
random variables.
5.5.13 Suppose (Ω, A, P) is a probability space. Suppose A, C ∈ A are inde￾pendent events and B, C ∈ A are independent events. Can we claim that
IA +IB and IC are independent random variables? Justify your answer.
Solution: If A, C ∈ A are independent events, B, C ∈ A are indepen￾dent events, then IA+IB and IC may or may not be independent random
variables. We consider the following probability space (Ω, A, P), where
Ω = {a, b, c, d}, A = P(Ω) and ∀ ω ∈ Ω, P({ω}) = 1/4. Suppose events
A, B, C are defined as follows.
A = {a, b}, B = {a, c} & C = {b, c}.
Observe that
(IA + IB)(ω) =



0, if ω ∈ Ac ∩ Bc = (A ∪ B)
c
1, if ω ∈ (A ∩ Bc
) ∪ (Ac ∩ B)
2, if ω ∈ A ∩ B.524 Solutions to Conceptual Exercises
The sigma fields induced by IA, IB, IC and IA +IB are respectively given
by,
I
−1
A (B) = {Ω, ∅, A, Ac
}, I−1
B (B) = {Ω, ∅, B, Bc
}
I
−1
C
(B) = {Ω, ∅, C, Cc
}
(IA + IB)
−1
(B) = {Ω, ∅,(A ∪ B)
c
,(A ∩ B
c
) ∪ (A
c ∩ B), A ∩ B,
A ∪ B, Ac ∪ B
c
,(A ∪ B)
c ∪ (A ∩ B)}.
Note that IA, IB, IC are independent of each other. However,
P(A ∩ B ∩ C) = P(∅) = 0 ̸= P(A ∩ B)P(C) = (1/4)(1/2)
and hence, (IA + IB)
−1
(B) is not independent of I
−1
C
(B). Thus, IA + IB
and IC are not independent random variables. Suppose Z1 = (IA, IB)
′
and Z2 = IC are random vectors. Note that IA + IB is a Borel function
of Z1
and it is not independent of IC . Hence, Z1
is also not independent
of IC . Thus, components of Z1
are independent of IC but the random
vector Z1
is not independent of IC .
5.5.14 Give two examples in which a random variable is independent of itself.
Solution: Suppose X ≡ C is a degenerate random variable on (Ω, A, P).
Then the sigma field induced by X is {Ω, ∅}. Hence, X is independent
of itself. Suppose Y = IA is defined on (Ω, A, P). Then the sigma field
induced by Y is σ(Y ) = {Ω, ∅, A, Ac}. If P(A) = 0 then every event in
σ(Y ) is independent of itself and hence Y is independent of itself. Note
that if P(A) = 0 then P[Y = 0] = 1, that is, Y is a degenerate random
variable.
5.5.15 Give an example of random variables X1, X2, X3 which are pairwise
independent but not independent.
Solution: Random variables X1, X2, X3 are pairwise independent, if
and only if all possible pairs are independent. Suppose a probability
space (Ω, A, P) is defined as follows. Ω = {(1, 0, 0),(0, 1, 0),(0, 0, 1),
(1, 1, 1), A = P(Ω) and P({ω}) = 1/4 ∀ ω ∈ Ω. Suppose an event Ai
is
defined as Ai = {ω|i-th coordinate is 1}, i = 1, 2, 3. Then it is clear that
for i = 1, 2, 3, P(Ai) = 1/2, P(Ai ∩ Aj ) = P(Ai)P(Aj ) ∀ i ̸= j = 1, 2, 3
and P(A1 ∩ A2 ∩ A3) = 1/4. Observe that P(A1 ∩ A2 ∩ A3) ̸=
P(A1)P(A2)P(A3). Thus, {A1, A2, A3} is not a collection of indepen￾dent events. Suppose a random variable Xi
is defined as Xi = 1 if i-th
coordinate is 1 and 0 otherwise, that is, Xi = IAi
for i = 1, 2, 3. Then for
i = 1, 2, 3, σ(Xi) = {Ω, ∅, Ai
, Ac
i
}. Observe that ∀ i ̸= j = 1, 2, 3, σ(Xi)
is independent of σ(Xi). However, for Ai ∈ σ(Xi), P(A1 ∩ A2 ∩ A3) ̸=
P(A1)P(A2)P(A3). Thus, X1, X2, X3 are pair-wise independent but not
independent.
5.5.16 Give an example of random variables X1, X2, X3, X4 which are inde￾pendent.Chapter 5 525
Solution: Suppose (Ω, A, P) is a probability space and Ai ∈ A,
i = 1, 2, 3, 4. If {A1, A2, A3, A4} is a collection of independent events,
then Xi = IAi
, i = 1, 2, 3, 4 are independent random variables. As an
another illustration, suppose Xi = Ci
, i = 1, 2, 3, 4 are degenerate ran￾dom variables and hence are independent random variables.
5.5.17 Prove or disprove: If F is a distribution function, then (i) F
4
is also a
distribution function, (ii) 2F − F
2
is also a distribution function.
Solution: Suppose X1, X2, X3, X4 are independent random variables,
each having the same distribution function F.
(i) Suppose U = max{X1, X2, X3, X4}. Then for x ∈ R,
P[U ≤ x] = P[max{X1, X2, X3, X4} ≤ x]] = Y
4
i=1
P[Xi ≤ x] = (F(x))4
.
Hence, F
4
is a distribution function of U.
(ii) Suppose V = min{X1, X2}. Then for x ∈ R,
P[V ≥ x] = P[min{X1, X2} ≥ x] = Y
2
i=1
P[Xi ≥ x] = (1 − F(x))2
⇒ P[V ≤ x] = 1 − (1 − F(x))2 = 2F − F
2
.
Hence, 2F − F
2
is a distribution function of V .
5.5.18 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
and {fn, n ≥ 1} is a sequence of Borel functions. Show that {fn(Xn), n ≥
1} is a sequence of independent random variables.
Solution: Since {Xn, n ≥ 1} is a sequence of independent ran￾dom variables, every finite collection {Xi1
, Xi2
, · · · , Xik
} of k ≥ 2
random variables is a collection of independent random variables.
Further, fn is a Borel function implies that every finite collection
{fi1
(Xi1
), fi2
(Xi2
), · · · , fik
(Xik
)} of k ≥ 2 random variables is a col￾lection of independent random variables. Hence, {fn(Xn), n ≥ 1} is a
sequence of independent random variables.
5.5.19 If X and Y are independent and X is integrable, show that
R
[Y ∈B] X dP = E(X)P[Y ∈ B] for any Borel set B.
Solution: Since X and Y are independent, I[Y ∈B] = g(Y ) and X are
independent for any Borel set B, g being a Borel function. Observe that
Z
[Y ∈B]
X dP =
Z
Ω
X I[Y ∈B]dP = E(X I[Y ∈B])
= E(X)E(I[Y ∈B]) = E(X)P[Y ∈ B].526 Solutions to Conceptual Exercises
5.5.20 Give an example of two random variables X and Y such that X and Y
are not independent but the characteristic function of their sum is the
product of their characteristic functions.
Solution: Suppose X and Y are identical random variables, each having
standard Cauchy distribution. Suppose X and Y are not independent
of each other. Note that ϕX(t) = ϕY (t) = e
−|t|
, t ∈ R. Now
ϕX+Y (t) = ϕ2X(t) = ϕX(2t) = e
−|2t| = e
−|t|
e
−|t| = ϕX(t)ϕY (t).
5.5.21 Suppose X and Y are independent random variables. Show that if X
and X − Y are independent, then X must be degenerate.
Solution: Since X and Y are independent, −X and Y are also inde￾pendent. Hence, ∀ t ∈ R,
ϕY −X(t) = ϕY (t)ϕ−X(t) = ϕY (t)ϕX(−t)
⇒ ϕY (t) = ϕX+(Y −X)(t) = ϕX(t)ϕY −X(t) = ϕX(t)ϕY (t)ϕX(−t),
the second step follows since X and X − Y are independent. Since
ϕY (0) = 1 and ϕY (t) is continuous function, ϕY (t) = 0 ̸ in a neigh￾borhood Nδ(0) of 0. Hence,
ϕX(t)ϕX(−t) = |ϕX(t)|
2 = 1 ∀ t ∈ Nδ(0)
⇒ (E(cos(tX))2 + (E(sin(tX))2 = 1 ∀ t ∈ Nδ(0)
⇒ X = 0 a.s.
Thus, X is a degenerate random variable, degenerate at 0.
Answers to the multiple choice questions, based on Chapter 5, are given
in Table 11.5.
TABLE 11.5
Answer Key to MCQs in Chapter 5
Q.No. 1 2 3 4 5 6 7 8 9 10
Ans c,d d a b,c,d a a d a b c
Q.No. 11 12 13 14 15 16 17 18 19 20
Ans b c b c,d b
11.6 Chapter 6
6.5.1 Suppose {Xn, n ≥ 1} is a sequence of random variables such that
P[Xn = ±n] = 1/2. Examine if Xn
a.s. → 0.Chapter 6 527
Solution: Observe that P[|Xn| = n] = 1, hence for ϵ < n,
P[|Xn| < ϵ] = 0 ⇒ Xn
P↛ X ≡ 0 ⇒ Xn
a.s. ↛ X ≡ 0.
6.5.2 Suppose {Xn, n ≥ 1} is a sequence of random variables defined on the
probability space (Ω, A, P) where Ω = [0, 1], A is a sigma field of subsets
of [0, 1] and P((a, b)) = b − a for (a, b) ∈ A. Suppose {Xn} is defined as
Xn(ω) = 
1, if 0 ≤ ω < (n + 1)/2n
0, otherwise.
X is a random variable defined as X(ω) = 1 if 0 ≤ ω ≤ 1/2 and 0
otherwise. Examine whether Xn
a.s. → X.
Solution: Note that X and Xn can be expressed as X = IA where
A = [0, 1/2] and Xn = IAn where An = [0, 1/2 + 1/2n). It is clear that
{An, n ≥ 1} is a decreasing sequence of sets and hence is convergent
with limn→∞
An =
T
n≥1
An = [0, 1/2] = A. Hence by Theorem 2.3.9
IAn → IA on Ω ⇐⇒ Xn → X on Ω ⇒ Xn
a.s. → X.
6.5.3 Suppose {Xn, n ≥ 1} is a sequence of continuous random variables with
support [−1/n, 1/n] and with probability density function given by,
fXn
(x) = 
n/2, if x ∈ [−1/n, 1/n]
0, if x /∈ [−1/n, 1/n].
Examine whether the sequence {Xn, n ≥ 1} converges almost surely.
Solution: From the given probability density function, it follows that
Xn ∼ U(−1/n, 1/n). Hence,
E(Xn) = 0 & E(X2
n
) = 1/3n
2 ⇒
X∞
n=1
E(X2
n
) = X∞
n=1
1/3n
2 < ∞
⇒ Xn
a.s. → 0, by Theorem 6.4.3.
6.5.4 Suppose Xn ∼ G(n, n). Examine if Xn
a.s. → 1.
Solution: Since Xn ∼ G(n, n), E(Xn) = 1 and V ar(Xn) = 1/n. To
examine whether, Xn
a.s. → 1, by using Theorem 6.4.3, we obtain the
fourth central moment of Xn from its cumulant generating function528 Solutions to Conceptual Exercises
Cn(t). It is given by,
Cn(t) = log (1 − t/n)
−n = −n log (1 − t/n) = n
X
i≥1
t
i
/ini
=
X
i≥1
(t
i
/i!)((i − 1)!/ni−1
) ⇒ k2 = 1/n & k4 = 6/n3
⇒ E(Xn − E(Xn))4 = E(Xn − 1)4 = k4 + 3k
2
2 = 6/n3 + 3/n2
⇒
X
n≥1
E(Xn − 1)4 =
X
n≥1
(6/n3 + 3/n2
) < ∞ ⇒ Xn
a.s. → 1.
6.5.5 Suppose Xn
a.s. → X. Show that lim inf Xn and lim sup Xn are equivalent
random variables.
Solution: By the definition of almost sure convergence,
Xn
a.s. → X ⇒ P[ limn→∞
Xn = X] = 1
⇒ P[lim sup
n→∞
Xn = lim inf
n→∞
Xn = X] = 1
⇒ P[lim inf Xn = lim sup Xn] = 1 .
Hence, lim inf Xn and lim sup Xn are equivalent random variables.
6.5.6 Suppose (Ω, A, P) is a probability space, where Ω = [0, 1], A is a sigma
field of subsets of Ω and P is a Lebesgue measure on (Ω, A). Suppose
An = [1/n, 1] and Xn = IAn
, n ≥ 1. Examine whether Xn converges
point-wise, almost surely and in probability to 1. Examine whether
{Xn, n ≥ 1} is a monotone sequence of random variables.
Solution: We have An = [1/n, 1]. It is clear that {An, n ≥ 1} is an
increasing sequence of sets and hence is convergent with
limn→∞ An =
S
n≥1 An = A = (0, 1] and P(A) = 1. Suppose for n ≥ 1,
Xn = IAn
and X = IA, then X ≡ 1. Hence by Theorem 2.3.9
IAn → IA on Ω ⇐⇒ Xn → X ≡ 1 on Ω.
Thus, Xn converges to 1 point-wise, hence almost surely and hence
in probability. Observe that ∀ ϵ ≥ 1, P[|Xn − 1| > ϵ] = 0. Further
∀ ϵ ∈ (0, 1),
P[|Xn −1| > ϵ] = P[IAn = 0] = P(A
c
n
) = 1/n → 0 ⇒ Xn
P
→ X ≡ 1 .
It is to be noted that {Xn, n ≥ 1} is a monotone sequence of random
variables. Thus, convergence in probability and almost sure convergence
are equivalent.
6.5.7 Suppose {Xn, n ≥ 1} is a sequence of random variables. If Xn
a.s. → 0,
show that Xn
a.s. → 0.Chapter 6 529
Solution: Suppose {an, n ≥ 1} is a sequence of real numbers and
{bn, n ≥ 1} is a sequence of positive real numbers. Toeplitz’ lemma
states that if an → a and PN
n=1 bn → ∞ as N → ∞, then
PN
n=1 anbn/
PN
n=1 bn → a as N → ∞. Now, Xn
a.s. → 0 implies ∀ ω ∈ Nc
with P(N) = 0, Xn(ω) → 0. Hence by Toeplitz’ lemma with bn = 1,
∀ ω ∈ Nc
,
PN
n=1 Xn(ω)/N → 0 and hence XN
a.s. → 0 as N → ∞.
6.5.8 Suppose (Ω, A, P) is a probability space where Ω = {1, 2, · · · , } and
probability measure P assigns probability 1/(k(k + 1)) to a set {k}, k =
1, 2, · · · . (i) Define A appropriately so that sets {k}, k = 1, 2, · · · , are
in A. If An = {n, n + 1, · · · }, show that it is in A. (ii) Find P(An) and
limn→∞ P(An). (iii) Show that {An, n ≥ 1} is a convergent sequence
and find its limit A and P(A). (iv) Verify whether converse of the Borel￾Cantelli lemma is true for this sequence of sets. If not, why? Justify your
answer.
Solution: (i) With A = P(Ω), sets {k}, k = 1, 2, · · · , are in A. Since
An = {n, n + 1, · · · } =
S
k≥n
{k}, it is in A.
(ii) Note that
P(An) = X
k≥n
P({k}) = X
k≥n
1
k(k + 1) =
X
k≥n
h
1
k
−
1
k + 1
i
=
1
n
→ 0.
(iii) Observe that An+1 ⊂ An, ∀ n ≥ 1. Thus {An, n ≥ 1} is a
decreasing sequence of events and hence is convergent. Further,
An → A =
\
n≥1
An = ∅
⇒ P(A) = 0 ⇒ P( limn→∞
An) = P(lim sup
n→∞
An) = 0
But X
n≥1
P(An) = X
n≥1
1/n = ∞.
Hence, the converse of Borel-Cantelli lemma is not true for this sequence
of sets. It is to be noted that
P(An ∩ An+1) = P(An+1) = 1
n + 1
̸=
1
n
1
n + 1
= P(An)P(An+1).
Thus, {An, n ≥ 1} is a sequence of dependent events and hence the
converse of the Borel-Cantelli lemma is not true.
6.5.9 If {An, n ≥ 1} is a sequence of independent events converging to A,
prove that A is independent of itself.
Solution: It is given that An → A, hence lim inf An = lim sup An = A
which implies that P(lim sup An) = P(A). Further, {An, n ≥ 1} is a
sequence of independent events, hence by the Borel zero-one law,
P(lim sup An) = P(A) = 0 or 1, depending on convergence or the di￾vergence of the series P
n≥1 P(An). With P(A) = 0 or 1, the identity
P(A ∩ A) = P(A)P(A) is satisfied. Hence, A is independent of itself.530 Solutions to Conceptual Exercises
6.5.10 Prove or disprove: If P
n≥1 P(An) < ∞ then P(lim inf An) = 0.
Solution: If P
n≥1 P(An) < ∞ then P(lim sup An) = 0 by the Borel￾Cantelli lemma. Now,
0 ≤ P(lim inf An) ≤ P(lim sup An) = 0 ⇒ P(lim inf An) = 0 .
Alternatively, by the definition of a limit infimum of a sequence of sets
we have,
lim inf An =
[
n≥1
\
k≥n
Ak =
\
n≥1
Bn, where Bn =
\
k≥n
Ak = An
\
Bn+1
⇒ Bn ⊂ Bn+1 ⇒ limn→∞
Bn =
[∞
n=1
Bn,
{Bn, n ≥ 1} being a non-decreasing sequence of events in A. Now using
the result that a tail of the convergent series converges to 0 we have,
P(lim inf An) =P(
[∞
n=1
\
k≥n
Ak) = P(
[∞
n=1
Bn)=P( limn→∞
Bn) = limn→∞
P(Bn)
= limn→∞
P(
\
k≥n
Ak) ≤ limn→∞
P(
[
k≥n
Ak)
≤ limn→∞
X
k≥n
P(Ak) = 0,
P
k≥n P(Ak) being a tail of the convergent series P∞
n=1 P(An). Thus,
P∞
n=1 P(An) < ∞ ⇒ P(lim inf An) = 0.
6.5.11 Suppose (Ω, A, P) is a probability space and {An, n ≥ 1} is a sequence
of independent events from A such that P(An) < 1 ∀ n ≥ 1. Show that
(i) P
 Sn
i=1 Ai

= 1 −
Qn
i=1(1 − P(Ai)), (ii) P
 Sn
i=1 Ai

≥ 1 −
e
−
Pn
i=1 P (Ai)
,
(iii) P
n≥1 P(An) = ∞ ⇒ P
 S
n≥1 An

= 1 and
(iv) P(lim sup An) = 1 ⇐⇒ P
 S
n≥1 An

= 1 .
Solution: Note that {An, n ≥ 1} is a sequence of independent events
implies {Ac
n
, n ≥ 1} is also a sequence of independent events. (i) Hence,
noting that P(An) < 1 ∀ n ≥ 1 we have
P
 [n
i=1
Ai

= 1 − P
 \n
i=1
A
c
i

= 1 −
Yn
i=1
P(A
c
i
) = 1 −
Yn
i=1
(1 − P(Ai)).
(ii) To prove (ii) we use the result which states that ∀ x ∈ [0, 1],
1 − x ≤ e
−x
. From (i)
P
 [n
i=1
Ai

= 1 −
Yn
i=1
(1 − P(Ai)) ≥ 1 −
Yn
i=1
e
−P (Ai) = 1 − e
−
Pn
i=1
P (Ai)
.Chapter 6 531
(iii) Observe that
Cn+1 =
n[
+1
i=1
Ai =
 [n
i=1
Ai

∪ An+1 = Cn ∪ An+1 ⇒ {Cn} is ↑ sequence
⇒ limn→∞
Cn =
[
n≥1
Cn =
[
n≥1
An.
Hence,
P
 [
n≥1
An

= P

limn→∞  [n
i=1
Ai
 = limn→∞
P
 [n
i=1
Ai

≥ limn→∞
(1 − exp(−
Xn
i=1
P(Ai)))
= 1 − exp(− limn→∞
Xn
i=1
P(Ai)) = 1 − exp(−
X
n≥1
P(An))
= 1 − exp(−∞) = 1 ⇒ P
 [
n≥1
An

= 1.
(iv) Since {An, n ≥ 1} is a sequence of independent events, by Borel
zero-one law, P(lim sup An) = 1 ⇐⇒ P
n≥1 P(An) = ∞. Thus, by
(iii)
P(lim sup An) = 1 ⇒
X
n≥1
P(An) = ∞ ⇒ P
 [
n≥1
An

= 1.
In (iii) we have proved that P
 S
n≥1 An

≥ 1 − exp(−
P
n≥1 P(An)).
Observe that
1 = P
 [
n≥1
An

≥ 1 − exp(−
X
n≥1
P(An))
⇒ exp(−
X
n≥1
P(An)) ≤ 0 ⇒ exp(−
X
n≥1
P(An)) = 0
⇒
X
n≥1
P(An) = ∞ ⇒ P(lim sup An) = 1.
6.5.12 Suppose (Ω, A, P) is a probability space and {An, n ≥ 1} is a sequence
of independent events from A. If P
n≥1 P(A ∩ An) = ∞ for any A ∈ A
such that P(A) > 0, then show that P(lim sup An) = 1.
Solution: Note that if P(A) = 0, then P(A ∩ An) ≤ P(A) = 0 and532 Solutions to Conceptual Exercises
P
n≥1 P(A ∩ An) cannot be ∞. Now for ∀ n ≥ 1,
An ⊃ A ∩ An ⇒ P(An) ≥ P(A ∩ An)
⇒
X
n≥1
P(An) ≥
X
n≥1
P(A ∩ An) = ∞
⇒
X
n≥1
P(An) = ∞ ⇒ P(lim sup An) = 1.
Answers to the multiple choice questions, based on Chapter 6, are given
in Table 11.6.
TABLE 11.6
Answer Key to MCQs in Chapter 6
Q.No. 1 2 3 4 5 6 7 8
Ans a,c a,c b d c c a,b,cd a,b,c,d
11.7 Chapter 7
7.5.1 Suppose {Xn, n ≥ 1} is a sequence of random variables such that
P[Xn = ±n] = 1/2. Using the definitions, examine if Xn
L
→ X, Xn
P
→ 0
and Xn
r→ 0. Verify the known implications among these modes of
convergence. Examine if Xn
a.s. → X.
Solution: The distribution function of Xn is given by,
Fn(x) =



0, if x < −n
1
2
, if −n ≤ x < n
1, if x ≥ n.
Then ∀ x ∈ R, Fn(x) → 1/2 ≡ F(x), say. Thus, F(x) satisfies all the
properties of a distribution function except that the limits at −∞ and
∞ are not 0 and 1 respectively. Hence, Xn
L↛ X for any X, but Fn
w→ F.
Observe that P[|Xn| = n] = 1, hence for ϵ < n, P[|Xn| < ϵ] = 0 and
hence Xn
P↛ X ≡ 0, which further implies that Xn
a.s. ↛ X ≡ 0. Similarly
E(|Xn|
r
) = n
r → ∞ as n → ∞. Hence, Xn
r↛ 0. Thus, we note that
Xn
L↛ 0 ⇒ Xn
P↛ 0 ⇒ Xn
a.s. ↛ 0 & Xn
P↛ 0 ⇒ Xn
r↛ 0.
7.5.2 Suppose Xn ≡ 1/n and Yn ≡ −1/n. Using the definitions examine
whether Xn and Yn converge in law, in probability, r-th mean and almost
surely.Chapter 7 533
Solution: Suppose Xn ≡ 1/n. Then
FXn
(x) = 
0, if x < 1/n
1, if x ≥ 1/n → G(x) = 
0, if x ≤ 0
1, if x > 0.
Thus, FXn → G(x) ∀ x ∈ R, but G is not a distribution function since it
is not right continuous at 0. However, we cannot conclude that Xn does
not converge in law. Since FXn may converge to another distribution
function, may not be for all x ∈ R but for all x in the set of its points
of continuity, as is required in the definition. Suppose X ≡ 0. Then its
distribution function F is given by,
F(x) = 
0, if x < 0
1, if x ≥ 0.
Observe that FXn → F(x) ∀ x ∈ C(FX). Hence by the definition of
convergence in law, Xn
L
→ X ≡ 0. Since the limit random variable X is
degenerate at 0, convergence in law implies convergence in probability.
We now examine convergence in probability using the definition. Note
that |Xn| ≡ 1/n. For given ϵ > 0, ∃ n0 such that 1/n0 < ϵ and hence
1/n < ϵ ∀ n ≥ n0. As a consequence
∀ ϵ > 1/n, P[|Xn| < ϵ] = 1 ⇒ ∀ n ≥ n0 P[|Xn| < ϵ] = 1 ⇒ Xn
P
→ 0.
Further for any r > 0,
E(|Xn|
r
) = 1/nr → 0 ⇒ Xn
r→ 0.
To examine almost sure convergence, observe that for a P-null set N
P[Xn = 1/n] = 1 ⇒ Xn(ω) = 1/n ∀ ω ∈ N
c = [Xn = 1/n]
⇒ limn→∞
Xn(ω) = 0 ∀ ω ∈ N
c ⇒ Xn
a.s. → 0.
Suppose Yn ≡ −1/n. Then
FYn
(x) = 
0, if x < −1/n
1, if x ≥ −1/n → F(x) = 
0, if x < 0
1, if x ≥ 0.
Observe that FYn
(x) → F(x) ∀ x ∈ R, where F(x) is a distribution
function of X ≡ 0. Thus, FYn
(x) → F(x) ∀ x ∈ C(FX) and hence Yn
L
→
X ≡ 0. Since the limit random variable X is degenerate at 0, convergence
in law implies convergence in probability. Using the definition, it follows
as in the case of Xn ≡ 1/n, since |Yn| ≡ 1/n. Further for any r > 0,
E(|Yn|
r
) = (| − 1/n|)
r → 0 ⇒ Yn
r→ 0.534 Solutions to Conceptual Exercises
To examine almost sure convergence, observe that for a P-null set N
P[Yn = −1/n] = 1 ⇒ Yn(ω) = −1/n ∀ ω ∈ N
c = [Yn = −1/n]
⇒ limn→∞
Yn(ω) = 0 ∀ ω ∈ N
c ⇒ Yn
a.s. → 0.
It is to be noted that both the sequences converge almost surely, in r-th
mean, in probability and in law.
7.5.3 Suppose {Xn, n ≥ 1} is a sequence of random variables such that
P[Xn = 0] = 1 − 1/n2 & P[Xn = e
n] = 1/n2
. Using the definitions,
examine if Xn
L
→ 0, Xn
P
→ 0 and Xn
r→ 0. Using a sufficient condition,
examine if Xn
a.s. → 0. Hence, verify the known implications among these
modes of convergence.
Solution: Observe that the distribution function Fn(x) of Xn, given by,
Fn(x) =



0, if x < 0
1 − 1/n2
, if 0 ≤ x < en
1, if x ≥ e
n
→ F(x) = 
0, if x < 0
1, if x ≥ 0.
Note that F(x) is a distribution function of X ≡ 0 and Fn(x) → F(x)
for all x ∈ R, where F is a distribution function of X ≡ 0. Thus,
Xn
L
→ 0. Since the limit law is degenerate, convergence in law implies
convergence in probability. We can verify it independently also. Observe
that for ϵ > 0, P[|Xn| > ϵ] = 1/n2 → 0 and hence Xn
P
→ 0. Further,
X
n≥1
P[|Xn| > ϵ] = X
n≥1
1/n2 < ∞ ⇒ Xn
a.s. → 0.
E(|Xn|
r
) = e
nr/n2 → ∞ as n → ∞. Hence, Xn
r↛ 0. It is to be noted
that Xn
r↛ 0 but Xn
P
→ 0. Further, Xn
a.s. → 0 but not in r-th mean.
7.5.4 Suppose a probability mass function of a random variable Xn is given
by,
P[Xn =
√
n] = 1/n = 1 − P[Xn = 0].
Examine whether Xn
P
→ 0, Xn
L
→ 0 and Xn
q.m. → 0.
Solution: From the given probability distribution of Xn,
P[|Xn| > ϵ] = P[|Xn| =
√
n] = 1/n → 0, as n → ∞, ∀ ϵ > 0.
Thus, Xn
P
→ 0 and hence Xn
L
→ 0. Now,
∀ n, E(|Xn − 0|
2
) = E(X2
n
) = n(1/n) = 1 ⇒ Xn
q.m. ↛ 0.Chapter 7 535
7.5.5 Suppose a probability mass function of a random variable Xn is given
by,
P[Xn = 0] = 1/n2 = 1 − P[Xn = n].
Examine whether Xn
P
→ 0, Xn
L
→ 0, Xn
a.s. → 0 and Xn
q.m. → 0.
Solution: From the given probability mass function of a random vari￾able Xn, its distribution function FXn
(x) for any x ∈ R is given by,
FXn
(x) =



0, if x < 0
1/n2
, if 0 ≤ x < n
1, if x ≥ n.
Observe that
FXn
(x) → 0 ∀ x ∈ R ⇒ Xn
L↛ 0 ⇒ Xn
P↛ 0 ⇒ Xn
q.m. ↛ 0.
Further, Xn
P↛ 0 ⇒ Xn
a.s. ↛ 0. Note that E(X2
n
) = n
2
(1−1/n2
) → ∞
also implies that Xn
q.m. ↛ 0.
7.5.6 Suppose {Xn, n ≥ 1} is a sequence of discrete random variables with
probability mass function given by,
P[Xn = x] = 
1/n, if x = n
1 − 1/n, if x = 0.
Discuss the limiting behaviour of {Xn, n ≥ 1} in probability, in law and
in quadratic mean.
Solution: From the given probability mass function, E(X2
n
) = n → ∞
hence Xn
q.m. ↛ 0. Now, given ϵ > 0, ∃ n0 ∈ N such that ϵ ≤ n0. Hence
P[|Xn| > ϵ] = 0 ∀ n ≤ n0 and ∀ n > n0, P[|Xn| > ϵ] = 1/n → 0 as
n → ∞. As a consequence, Xn
P
→ 0 ⇒ Xn
L
→ 0.
7.5.7 Suppose {Xn, n ≥ 1} is a sequence of random variables defined as
Xn = X+Yn where X is a random variable and {Yn, n ≥ 1} is a sequence
of random variables such that E(Yn) = 1/n & V ar(Yn) = σ
2/n, where
σ > 0 is a constant. Verify whether Xn
P
→ X.
Solution: Observe that
E(Xn − X)
2 = E(Yn)
2 = V ar(Yn) + (E(Y
2
n
))2 = σ
2
/n + 1/n2 → 0
⇒ Xn
q.m. → X ⇒ Xn
P
→ X.
7.5.8 Suppose {Xn, n ≥ 1} is a sequence of random variables defined on the
probability space (Ω, A, P) where Ω = [0, 1], A is a sigma field of subsets
of [0, 1] and P((a, b)) = b − a for (a, b) ∈ A. Suppose {Xn} is defined as
Xn(ω) = 
1, if 0 ≤ ω < (n + 1)/2n
0, otherwise.536 Solutions to Conceptual Exercises
X is a random variable defined as X(ω) = 1 if 0 ≤ ω ≤ 1/2 and
0 otherwise. Examine whether Xn
a.s. → X, Xn
P
→ X, Xn
L
→ X and
Xn
q.m. → X.
Solution: Note that X and Xn can be expressed as X = IA where
A = [0, 1/2] and Xn = IAn where An = [0, 1/2 + 1/2n). It is clear that
{An, n ≥ 1} is a decreasing sequence of sets and hence is convergent
with limn→∞ An =
T
n≥1 An = [0, 1/2] = A. Hence by Theorem 2.3.9
IAn = Xn → IA = X on Ω ⇒ Xn
a.s. → X ⇒ Xn
P
→ X ⇒ Xn
L
→ X.
Further observe that Xn − X = IBn where Bn = [1/2, 1/2 + 1/2n).
Hence,
E(Xn − X)
r = 1/2n → 0 ⇒ Xn
q.m. → X ⇒ Xn
P
→ X.
7.5.9 Suppose {Xn, n ≥ 1} is a sequence of discrete random variables with
probability mass function given by, P[Xn = −(n + 4)] = 1/(n + 4),
P[Xn = −1] = 1 − 4/(n + 4) and P[Xn = n + 4] = 3/(n + 4). Discuss
the limiting behaviour of {Xn} in probability, in law and in quadratic
mean to X ≡ −1 and X ≡ 0. Examine whether E(Xn) converges.
Solution: Observe that for ϵ > 0,
P[|Xn + 1| < ϵ] ≥ P[Xn = −1] = 1 − 4/(n + 4) → 1
⇒ Xn
P
→ −1 ⇒ Xn
L
→ −1
⇒ Xn
P↛ 0 ⇒ Xn
L↛ 0.
Now E(Xn) = 4/(n + 4) + 1 → 1.
E(X2
n
) = 1 − 4/(n + 4) + 4(n + 4) → ∞ ⇒ Xn
q.m. ↛ 0.
Further E((Xn + 1)2
) → ∞ ⇒ Xn
q.m. ↛ −1.
7.5.10 Suppose {Xn, n ≥ 1} is a sequence of discrete random variables with
probability mass function given by, P[Xn = ±1/n] = 1/2. Discuss the
limiting behaviour of {Xn} in probability, in law, almost surely and in
quadratic mean to X. Examine whether E(Xn) → E(X).
Solution: From the given probability mass function,
E|Xn|
r = 1/nr → 0 ⇒ Xn
r→ 0 ⇒ Xn
P
→ 0 ⇒ Xn
L
→ 0.
Further, ∀ r ≥ 2,
X
n≥1
E|Xn|
r =
X
n≥1
1/nr < ∞ ⇒ Xn
a.s. → 0.
Observe that E(Xn) = 0 ∀ n ≥ 1 and hence E(Xn) → 0 = E(X)
where X ≡ 0.Chapter 7 537
7.5.11 Suppose {Xn, n ≥ 1} is a sequence of continuous random variables with
support [−1/n, 1/n] and with the probability density function given by,
fXn
(x) = 
n/2, if x ∈ [−1/n, 1/n]
0, if x /∈ [−1/n, 1/n].
Examine whether the sequence {Xn, n ≥ 1} converges in quadratic
mean, in probability, in law and almost surely.
Solution: From the given probability density function, it follows that
Xn ∼ U(−1/n, 1/n). Hence,
E(Xn) = 0 & E(X2
n
) = 1/3n
2 → 0
⇒ Xn
q.m. → 0 ⇒ Xn
P
→ 0 ⇒ Xn
L
→ 0.
Further,
X∞
n=1
E(X2
n
) = X∞
n=1
1/3n
2 < ∞ ⇒ Xn
a.s. → 0,
by Theorem 6.4.3.
7.5.12 Suppose (Ω, A, P) is a probability space, where Ω = [0, 1], A is a sigma
field of subsets of Ω and P(An) = 1/n for An = [0, 1/n). Suppose
Xn = e
nIAn
, n ≥ 1. Show that Xn
P
→ 0, but Xn
r↛ 0.
Solution: For any ϵ > 0, as n → ∞,
P[|Xn| > ϵ] = P[IAn = 1] = 1/n → 0 ⇒ Xn
P
→ 0.
On the other hand, for any r > 0,
E(|Xn|
r
) = e
nr/n → ∞ as n → ∞ ⇒ Xn
r↛ 0.
7.5.13 Suppose {X1, X2, · · · , Xn} are independent and identically distributed
random variables with the probability density function f(x) = αx−α−1
for x > 1, α > 0. Suppose Yn = n
−1/αX(n)
. Examine whether Yn con￾verges in law.
Solution: To find the limit law of Yn, observe that the distribution
function of X1 is
F(x) = 
0, if x < 1
1 − x
−α, if x ≥ 1.
Now, X(n) ≥ 1 ⇒ Yn ≥ n
−1/α. Hence, the distribution function Fn
of Yn given by,
Fn(x) = 
0, if x < n−1/α
(1 − n
−1x
−α)
n, if x ≥ n
−1/α538 Solutions to Conceptual Exercises
Observe that
Fn(x) → F(x) = 
0, if x < 0
exp(−x
−α), if x ≥ 0.
Note that F is non-decreasing and continuous. Further,
limx→∞
exp(−x
−α
) = 1 & lim x→−∞
F(x) = 0 ⇒ Yn
L
→ X,
where F is the distribution function of X.
7.5.14 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables, such that Xn = 1 and 0 with probability
1/2 each. Suppose Yn = 1−Xn. Show that Xn
L
→ X and Yn
L
→ Y , where
X and Y are identically distributed random variables, with values 1 and
0 with equal probabilities 1/2. Examine whether Xn + Yn
L
→ X + Y .
Examine whether Xn and Yn are independent random variables.
Solution: Since {Xn, n ≥ 1} is a sequence of independent and iden￾tically distributed random variables, it follows that Xn
L
→ X, where
X = 1 and 0 with probability 1/2 each. Further Yn = 1 − Xn and hence
by Slutsky’s theorem Yn
L
→ Y = 1 − X. It is to be noted that X and Y
are identically distributed random variables, with values 1 and 0 with
equal probabilities 1/2. Further, Xn + Yn ≡ 1 and possible values of
X + Y are 0, 1, 2, with probabilities 1/4, 1/2, 1/4 respectively. It thus
clearly follows that Xn + Yn
L↛ X + Y . Observe that,
P[Xn = 1, Yn = 0] = P[Xn = 1, Xn = 1]
= P[Xn = 1] = 1/2 ̸= P[Xn = 1]P[Yn = 0] = 1/4,
which implies that Xn and Yn are not independent random variables.
7.5.15 Suppose {Xn, n ≥ 1} is a sequence of random variables such that Xn
follows N(0, σ2/n). Suppose a function g : R → R is defined as
g(x) = 
0, if x ≤ 0
1, if x > 0.
Show that Xn
P
→ X ≡ 0, but g(Xn)
P↛ g(X).
Solution: It is clear that g is not a continuous function and 0 is a point
of discontinuity. Observe that,
E(X2
n
) = σ
2
/n → 0 ⇒ Xn
q.m. → X ≡ 0 ⇒ Xn
P
→ X ≡ 0.
Since the distribution Xn is symmetric around 0, the distribution of
g(Xn) is as given below.
g(Xn) = 
0, with probability 1/2
1, with probability 1/2.Chapter 7 539
However, X ≡ 0 which implies that g(X) ≡ 0. Hence,
|g(Xn) − g(X)| =

0, with probability 1/2
1, with probability 1/2.
Thus, for
ϵ ∈ (0, 1), P[|g(Xn) − g(X)| < ϵ] = 1/2 ↛ 1 ⇒ g(Xn)
P↛ g(X).
7.5.16 Suppose Xn ∼ G(n, n). Examine if Xn
r→ 1 for r > 1 and Xn
a.s. → 1.
Solution: In Example 7.3.24, it is shown that if Xn ∼ G(n, n), then
Xn
q.m. → 1, Xn
P
→ 1 and Xn
L
→ 1. To examine whether, Xn
r→ 1 for
r > 2, we need moments of Xn of order r. We obtain these from the
cumulant generating function Cn(t) of Xn. It is given by,
Cn(t) = log (1 − t/n)
−n = −n log (1 − t/n)
= n
X
i≥1
t
i
/ini

=
X
i≥1
(t
i
/i!)((i − 1)!/ni−1
)

.
Thus, i-th cumulant ki
is given by ki = (i − 1)!/ni−1
, i ≥ 1 and hence
cumulants of all order larger than 1 converge to 0 as n → ∞, which
implies that E(Xn − 1)r → 0. It is to be noted that E|Xn − 1|
2k =
E(Xn − 1)2k and E|Xn − 1|
2k+1 = E(Xn − 1)2k+1, when Xn − 1 > 0
and E|Xn − 1|
2k+1 = −E(Xn − 1)2k+1, when Xn − 1 ≤ 0. Hence,
E(Xn − 1)r → 0 implies that Xn
r→ 1 for r > 2. To examine almost
sure convergence, observe that
k2 = 1/n & k4 = 6/n3 ⇒ E(Xn − E(Xn))4 = k4 + 3k
2
2
⇒ E(Xn − 1)4 = 6/n3 + 3/n2
⇒
X
n≥1
E(Xn − 1)4 =
X
n≥1
(6/n3 + 3/n2
) < ∞
⇒ Xn
a.s. → 1
7.5.17 Suppose {Xn, n ≥ 1} is a sequence of random variables such that Xn
has Cauchy distribution with probability density function given by
f(x, n) = (n/π)(1/(1 + n
2x
2
)), x ∈ R. Examine whether Xn
P
→ 0,
Xn
r→ 0, r ≥ 1 and Xn
L
→ 0.
Solution: It is given that Xn has Cauchy distribution with location
parameter 0 and scale parameter 1/n. Hence, its distribution function
is given by Fn(x) = (1/2) + (1/π) tan−1
(nx), x ∈ R. Hence ∀ ϵ > 0,
as n → ∞
P[|Xn| < ϵ] = Fn(ϵ) − Fn(−ϵ) = (2/π) tan−1
(nϵ) → (2/π)(π/2) = 1
⇒ Xn
P
→ 0 ⇒ Xn
L
→ 0.540 Solutions to Conceptual Exercises
Convergence in law can be verified independently using the definition as
follows. Observe that
Fn(x) =



1/2 + (1/π) tan−1
(nx), if x < 0
1/2 if x = 0
1/2 + (1/π) tan−1
(nx), if x > 0
→



0, if x < 0
1/2 if x = 0
1, if x > 0.
If FX denotes the distribution function of X ≡ 0. Then Fn(x) → FX(x)
∀ x ∈ C(FX) = R − {0} and hence Xn
L
→ 0. It is to be noted that for
all r ≥ 1, E(|Xn|
r
) = 2 R ∞
0
n
π
x
r
1+n2x2 dx and it is a divergent integral.
Hence, we cannot define convergence in r-th mean.
7.5.18 Suppose {Xn, n ≥ 1} is a sequence of random variables such that Xn
has Cauchy distribution with probability density function given by
f(x, n) = (n/π)(1/(n
2 + x
2
)), x ∈ R. Examine whether Xn
P
→ 0, Xn
r→
0, r ≥ 1, Xn
L
→ 0 and Xn
a.s. → 0.
Solution: It is given that Xn has Cauchy distribution with location
parameter 0 and scale parameter n. Hence its distribution function is
given by Fn(x) = 1/2 + (1/π) tan−1
(x/n), x ∈ R. Hence ∀ ϵ > 0, as
n → ∞,
P[|Xn| < ϵ] = Fn(ϵ) − Fn(−ϵ) = (2/π) tan−1
(ϵ/n) → 0 ⇒ Xn
P↛ 0.
To verify convergence in law, observe that for all x, Fn(x) → 1/2. Hence,
Xn does not converge in law. Convergence in r-th mean is not defined
as Xn ∈/ Lr for any r ≥ 1. Since Xn
P↛ 0, Xn
a.s ↛ 0.
7.5.19 Suppose X is a real random variable defined on a probability space on
(Ω, A, P) and {An, n ≥ 1} is a sequence of sets in A such that P(An) →
0. Then show that XIAn
P
→ 0.
Solution: For ϵ > 0 observe that
P[|IAn
| > ϵ] = P[IAn = 1] = P(An) → 0 ⇒ IAn
P
→ 0 .
Further X is a real random variable and hence is bounded in probability.
Thus, XIAn
P
→ 0.
7.5.20 Show that equivalent random variables are identically distributed.
Solution: Suppose X and Y are equivalent random variables, that is,
P[X = Y ] = P(Nc
) = 1, where Nc = {ω|X(ω) = Y (ω)}. Observe that
for any x ∈ R
FX(x) = P[X ≤ x] = P[X ≤ x, Nc
] + P[X ≤ x, N]
= P[X ≤ x, Nc
] as P[X ≤ x, N] ≤ P(N) = 0
= P[Y ≤ x, Nc
] as on N
c
, X(ω) = Y (ω)
= P[Y ≤ x, Nc
] + P[Y ≤ x, N] = P[Y ≤ x] = FY (x).Chapter 7 541
Thus, X and Y are identically distributed random variables.
7.5.21 Suppose Xn = min{Y1, Y2, · · · , Yn}, where {Yn, n ≥ 1} is a sequence of
independent and identically distributed random variables, each having
an exponential distribution with location parameter θ and scale parame￾ter 1. (i) Show that Xn
P
→ θ and Xn
a.s. → θ. (ii) Suppose Un = n(Xn −θ),
then show that Un
L
→ U, where U has exponential distribution with
location parameter 0 and scale parameter 1. (iii) From the limit law of
Un, find the limit law of Vn =
√
n(Xn − θ). (iv) From the limit law of
Un, find the limit law of exp(−Un).
Solution: A random variable Y1 has exponential distribution with loca￾tion parameter θ and scale parameter 1. Hence, its distribution function
F(y) is given by,
F(y) = 
0, if y < θ,
1 − e
−(y−θ)
, if y ≥ θ.
Thus, the distribution function Fn(y) of Xn = min{Y1, Y2, · · · , Yn} is,
Fn(y) = 1 − (1 − F(y))n =

0, if y < θ
1 − e
−n(y−θ)
, if y ≥ θ.
Hence, for ϵ > 0, P[|Xn − θ| > ϵ] is obtained as follows.
P[|Xn − θ| > ϵ] = 1 − P[θ − ϵ < Xn < θ + ϵ]
= 1 − P[θ < Xn < θ + ϵ]
= 1 − P[Xn < θ + ϵ] + P[Xn < θ]
= 1 − (1 − e
−n(θ+ϵ−θ)
) = e
−nϵ
→ 0 as n → ∞ ∀ ϵ > 0.
Consequently, Xn
P
→ θ. To examine almost sure convergence, observe
that ∀ ϵ > 0, e−ϵ < 1. Hence,
X∞
n=1
P[|Xn − θ| > ϵ] = X∞
n=1
e
−nϵ =
X∞
n=1
(e
−ϵ
)
n < ∞ ⇒ Xn
a.s. → θ.
(ii) From the distribution function Fn of Xn, it follows that for each n,
Xn has an exponential distribution with location parameter θ and scale
parameter n, which further implies that for each n, Un = n(Xn − θ)
has the exponential distribution with location parameter 0 and scale
parameter 1. Hence, Un
L
→ U, where U follows the exponential distribu￾tion with location parameter 0 and scale parameter 1.
(iii) Observe that Vn can be written as, Vn =
√
n(Xn − θ) = (1/
√
n)Un.
Now Un
L
→ U implies that the sequence {Un, n ≥ 1} is bounded in
probability. Hence, Vn = (1/
√
n)Un
P
→ 0, which further implies that542 Solutions to Conceptual Exercises
√
n(Xn − θ)
L
→ 0. Thus, the limit law of √
n(Xn − θ) is degenerate at 0.
(iv) By the continuous mapping theorem, Un
L
→ U ⇒ exp(−Un)
L
→
exp(−U). Since U follows the exponential distribution with location pa￾rameter 0 and scale parameter 1, the distribution of exp(−U) is uniform
U(0, 1).
7.5.22 Suppose Xn
L
→ X and Yn
L
→ C, where C ̸= 0 is a degenerate ran￾dom variable. Using the definition of convergence in law, show that (i)
XnC
L
→ XC and (ii) Xn/C L
→ X/C, provided these are defined. Hence
show that XnYn
L
→ XC, and Xn/Yn
L
→ X/C, provided these are de￾fined.
Solution: (i) Suppose C > 0 and x/C is a point of continuity of FX.
Note that for C > 0,
FXnC (x) = P[XnC ≤ x] = P[Xn ≤ x/C] = Fn(x/C)
→ FX(x/C) = P[X ≤ x/C] = FXC (x).
Now, XnC
L
→ XC if x is a point of continuity of FXC . To prove it,
observe that since x/C is a point of continuity of FX,
lim
h→0
FX(x/C − h) = FX(x/C)
⇐⇒ lim
h→0
P[X ≤ x/C − h] = P[X ≤ x/C]
⇐⇒ lim
h→0
P[XC ≤ x − Ch] = P[XC ≤ x]
⇐⇒ lim
h→0
FXC (x − Ch) = FXC (x).
Thus, x is a point of continuity of FXC . Hence for C > 0, XnC
L
→ XC.
Suppose C < 0 and C = −D. Then
Xn(−D)
L
→ X(−D) ⇒ − XnC
L
→ −XC ⇒ XnC
L
→ XC,
by continuous mapping theorem. To find the limit law of XnYn, note
that by Theorem 7.3.7,
(XnYn) − (XnC) = Xn(Yn − C)
P
→ 0.
Hence by Theorem 7.3.5, limit law of (XnYn) is the same as that of
(XnC).
(ii) Suppose xC is a point of continuity of FX. For C > 0,
FXn/C (x) = P[Xn/C ≤ x] = P[Xn ≤ xC] = Fn(xC)
→ FX(xC) = P[X ≤ xC] = FX/C (x).Chapter 7 543
Now, Xn/C L
→ X/C if x is a point of continuity of FX/C . Since xC is a
point of continuity of FX, we have
lim
h→0
FX(xC − h) = FX(xC)
⇐⇒ lim
h→0
P[X ≤ xC − h] = P[X ≤ xC]
⇐⇒ lim
h→0
P[X/C ≤ x − h/C] = P[X/C ≤ x]
⇐⇒ lim
h→0
FX/C (x − h/C) = FX/C (x).
Thus, x is a point of continuity of FX/C . Hence, Xn/C L
→ X/C. If C < 0,
with C = −D we have
Xn/(−D)
L
→ X/(−D) ⇒ − Xn/C L
→ −X/C ⇒ Xn/C L
→ X/C,
by continuous mapping theorem. Observe that
(Xn/Yn) − (Xn/C) = Xn(1/Yn − 1/C)
P
→ 0
by Theorem 7.3.7. Hence, the limit law of (Xn/Yn) is the same as that
of (Xn/C).
7.5.23 Suppose Xn ∼ χ
2
n
, n ≥ 1 and Yn = (Xn − n)/
√
2n. Examine whether
(i) Xn/n P
→ 1, Xn/n q.m. → 1 and (ii) Yn
L
→ Z ∼ N(0, 1). What is the
distribution of Y
2
n as n → ∞?
Solution: Since Xn ∼ χ
2
n
, E(Xn) = n and V ar(Xn) = 2n. Hence,
E(Xn/n − 1)2 = E(Xn − n)
2
/n2 = 2n/n2 → 0 ⇒ Xn/n q.m. → 1
⇒ Xn/n P
→ 1.
(ii) Since Xn ∼ χ
2
n
, its characteristic function is ϕXn
(t) = (1 − 2it)
−n/2
.
Suppose ϕn(t) denotes the characteristic function of Yn. Then ∀ t ∈ R
ϕn(t) = E(e
itYn ) = E(e
it(Xn−n)/
√
2n
) = e
−it√
n/√
2E(e
itXn/
√
2n
)
= e
−it√
n/√
2
(1 − 2it/√
2n)
−n/2
⇒ log ϕn(t) = −it√
n/√
2 − (n/2) log(1 −
√
2it/√
n)
= −it√
n/√
2 + (n/2)(√
2it/√
n − t
2
/n − it3
2
3/2
/3n
3/2
+ · · ·)
= −t
2
/2 + δn → − t
2
/2 = ϕ(t), say
since δn → 0 as n → ∞. Thus, a sequence {ϕn(t), n ≥ 1} of charac￾teristic functions converges to ϕ(t) = exp(−t
2/2), which is continuous
at t = 0. Hence, by the continuity theorem for characteristic functions,544 Solutions to Conceptual Exercises
Yn
L
→ Z, where ϕ(t) = exp(−t
2/2) is a characteristic function of Z.
It is known that ϕ(t) = exp(−t
2/2) is a characteristic function of the
standard normal distribution hence Z ∼ N(0, 1).
By the continuous mapping theorem, Yn
L
→ Z ⇒ Y
2
n
L
→ Y ∼ χ
2
1
.
7.5.24 Suppose Xn ∼ P(λn) and Yn = (Xn−λn)/
√
λn. Show that as λn → ∞,
Yn
L
→ Z ∼ N(0, 1). What is the distribution of Y
2
n as λn → ∞?
Solution: Suppose Xn ∼ P(λn). Then E(Xn) = λn, V ar(Xn) = λn
and its characteristic function is given by ϕXn
(t) = exp{λn(e
it − 1)}.
Suppose ϕn(t) denotes the characteristic function of Yn. Then ∀ t ∈ R
ϕn(t) = E(e
itYn ) = E(e
it (X√n−λn)
λn ) = e
−it√
λn E(e
i √t
λn
Xn
)
= e
−it√
λn exp{λn(e
i √t
λn − 1)}
⇒ log ϕn(t) = −itp
λn + λn(e
i √t
λn − 1)
= −itp
λn + λn(1 + it/p
λn − t
2
/2λn − it3
/6(λn)
3/2
+ · · · − 1) = −t
2
/2 + δn → − t
2
/2 = ϕ(t), say
since δn → 0 as λn → ∞. Thus, a sequence {ϕn(t), n ≥ 1} of char￾acteristic functions converges to ϕ(t) = exp(−t
2/2), which is a contin￾uous function at t = 0. Further ϕ(t) = exp(−t
2/2) is a characteristic
function of Z which follows N(0, 1) distribution. Hence, by the continu￾ity theorem and the uniqueness theorem of the characteristic functions
Yn
L
→ Z ∼ N(0, 1). By the continuous mapping theorem,
Yn
L
→ Z ⇒ Y
2
n
L
→ Y ∼ χ
2
1
.
7.5.25 Suppose {Xn, n ≥ 1} is a sequence of independent random vari￾ables each having uniform U(0, 1) distribution. Suppose X(1) =
min{X1, X2, · · · , Xn} and X(n) = max{X1, X2, · · · , Xn}. Show that (i)
nX(1)
L
→ X, where X has exponential distribution with mean 1, (ii)
1 − (X(1) + X(n))
P
→ 0 and (iii) n(1 − X(n))X(1)
P
→ 0.
Solution: (i) If X1 ∼ U(0, 1), then as shown in Example 7.2.5, the
distribution function FX(1) (x) of X(1) is given by,
FX(1) (x) =



0, if x < 0
1 − (1 − x)
n, if 0 ≤ x < 1
1, if x ≥ 1.
From the distribution function of X(1), the distribution function of nX(1)
is given by,
FnX(1) (x) = P[X(1) ≤ x/n] =



0, if x < 0
1 − (1 − x/n)
n, if 0 ≤ x < n
1, if x ≥ nChapter 7 545
It then follows that
FnX(1) (x) →

0, if x < 0
1 − e
−x
, if x ≥ 0.
But the limit is the distribution function of the exponential distribution
with mean 1, which is continuous for all x ∈ R and hence nX(1)
L
→ X,
where X has exponential distribution with mean 1.
(ii) As shown in Example 7.2.5,
X(1)
P
→ 0 & X(n)
P
→ 1 ⇒ 1−(X(1)+X(n)) = −X(1)+(1−X(n))
P
→ 0.
(iii) Observe that n(1 − X(n))X(1) = (nX(1))(1 − X(n)). Now by (i)
nX(1)
L
→ X and hence the first factor nX(1) is bounded in probabil￾ity and the second factor (1 − X(n))
P
→ 0 which implies that n(1 −
X(n))X(1)
P
→ 0. Alternatively as shown in Example 7.3.3, n(1 − X(n))
converges in law and hence is bounded in probability, X(1)
P
→ 0 which
implies that n(1 − X(n))X(1)
P
→ 0.
7.5.26 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables, each having U(0, 1) distribution. Find the
limiting distribution of n(1 − X(n−1)).
Solution: As shown in Example 7.3.3, n(1 − X(n))
L
→ X, where X fol￾lows exponential distribution with mean 1. To find the limiting distribu￾tion of n(1−X(n−1)), we examine whether n(1−X(n−1))−n(1−X(n)) =
n(X(n−1) − X(n))
P
→ 0. Observe that for ϵ > 0
P[|n(X(n−1) − X(n))| < ϵ] ≥ P[X(n−1) = X(n)
] = P[X(n−1) ≥ Xn]
= E(P[X(n−1) ≥ Xn|Xn]) = E(1 − Xn−1
n
)
=
Z 1
0
(1 − u
n−1
) du = 1 − 1/n → 1
⇒ n(X(n−1) − X(n))
P
→ 0
⇒ n(1 − X(n−1)) − n(1 − X(n))
P
→ 0.
Hence, n(1−X(n−1)) and n(1−X(n)) converge in law to the same random
variable. However, n(1 − X(n))
L
→ X and hence n(1 − X(n−1))
L
→ X,
where X follows exponential distribution with mean 1.
7.5.27 Suppose {X1, X2, · · · , Xn} is a random sample from a normal N(θ, 1)
distribution and θ ∈ [0, ∞). The maximum likelihood estimator ˆθn of θ
is given by,
ˆθn =

Xn, if Xn ≥ 0
0, if Xn < 0,546 Solutions to Conceptual Exercises
Examine whether ˆθn
P
→ θ. Find the limit law of Yn =
√
n(
ˆθn − θ).
Identify the limiting distribution at θ = 0.
Solution: To verify ˆθn
P
→ θ, we note that Xn
q.m. → θ and hence Xn →
Pθ
θ,
for all θ ≥ 0. Now for ϵ > 0,
Pθ[|
ˆθn − Xn| < ϵ] ≥ Pθ[
ˆθn = Xn] = Pθ[Xn ≥ 0] = 1 − Φ(−
√
nθ) → 1
if θ > 0. As a consequence, if θ > 0 then ˆθn − Xn →
Pθ
0 and Xn →
Pθ
θ
implies that ˆθn →
Pθ
θ when θ > 0. Suppose θ = 0. Then using the fact
that ˆθn ≥ 0, for ϵ > 0, as n → ∞,
P0[|
ˆθn| > ϵ] = P0[
ˆθn > ϵ] = P0[Xn > ϵ] = 1−Φ(√
nϵ) → 0 ⇒ ˆθn →
P0
0 .
Thus, ˆθn →
Pθ
θ for all θ ≥ 0.
(ii) Since X ∼ N(θ, 1),
√
n(Xn − θ) ∼ N(0, 1) for each n and hence in
limit. Further, √
n(Xn − θ) −
√
n(
ˆθn − θ) = √
n(Xn − ˆθn). Observe that
for θ > 0 and for ϵ > 0,
Pθ[|
√
n(Xn − ˆθn)| < ϵ] ≥ Pθ[Xn = ˆθn] = Pθ[Xn ≥ 0]
= 1 − Φ(−
√
nθ) → 1 if θ > 0.
Thus, for θ > 0,
√
n(Xn − θ) −
√
n(
ˆθn − θ) →
Pθ
0, hence √
n(Xn − θ) and
√
n(
ˆθn − θ) have the same limit law. But √
n(Xn − θ)
L
→ Z ∼ N(0, 1)
and hence √
n(
ˆθn − θ)
L
→ Z ∼ N(0, 1), for θ > 0. Suppose now θ = 0.
If x < 0, P0[
√
n(
ˆθn − 0) ≤ x] = 0 as ˆθn ≥ 0.
For x = 0, P0[
√
nˆθn ≤ 0] = P0[
√
nˆθn = 0] = P0[Xn < 0] = Φ(0) = 1/2.
For x > 0, P0[
√
nˆθn ≤ x] = P0[
√
nˆθn ≤ 0] + P0[0 <
√
nˆθn ≤ x]
= 1/2 + P0[0 <
√
n(Xn) ≤ x]
= 1/2 + Φ(x) − Φ(0) = Φ(x).
Thus P0[
√
nˆθn ≤ x] =



0, if x < 0
1/2, if x = 0,
Φ(x), if x > 0,
which shows that at θ = 0, the asymptotic distribution of √
nˆθn is not
normal and 0 is a point of discontinuity. Suppose U1 is a random variable
with a distribution degenerate at 0. Then its distribution function is
given by,
FU1
(x) = 
0, if x < 0
1, if x ≥ 0Chapter 7 547
Suppose a random variable U2 is defined as U2 = |U| where U ∼ N(0, 1).
Then P[U2 ≤ x] = 0 if x < 0. Suppose x ≥ 0, then
P[U2 ≤ x] = P[|U| ≤ x] = P[−x ≤ U ≤ x] = Φ(x)−Φ(−x) = 2Φ(x)−1.
Thus, the distribution function of U2 is given by,
FU2
(x) = 
0, if x < 0
2Φ(x) − 1, if x ≥ 0
Thus, P0[
√
n(
ˆθn − 0) ≤ x] → (1/2)FU1
(x) + (1/2)FU2
(x).
7.5.28 Suppose Xn
P
→ X. Show that |Xn|
L→ |X|.
Solution: A function g(x) = |x|, x ∈ R is a continuous function, hence
by invariance of convergence in probability under continuous transforms,
Xn
P
→ X ⇒ |Xn|
P→ |X|. Further, convergence in probability implies
convergence in law. Hence, |Xn|
L→ |X|. Alternatively,
Xn
P
→ X ⇒ Xn
L
→ X ⇒ |Xn|
L→ |X|,
by continuous mapping theorem.
7.5.29 Suppose Xn
L
→ X where X is a continuous random variable. Using the
definition of convergence in law, show that |Xn|
L→ |X|.
Solution: Xn
L
→ X ⇒ FXn
(x) → F(x) ∀ x ∈ C(FX) = R as X is
a continuous random variable. Now, |Xn| being a non-negative random
variable, F|Xn|(x) = 0 ∀ x < 0. For x ≥ 0
F|Xn|(x) = P[|Xn| ≤ x] = P[−x ≤ Xn ≤ x] = FXn
(x) − FXn
(−x−)
as FXn
(x) may not be continuous at −x. Since Xn
L
→ X, FXn
(x) →
FX(x). To find limn→∞
FXn
(−x − 0) observe that,
limn→∞
FXn
(−x−) = limn→∞
lim
h→0
FXn
(−x − h)
= lim
h→0
limn→∞
FXn
(−x − h)
= lim
h→0
FX(−x − h) as − x − h ∈ C(FX) = R
= F(−x) as X is a continuous random variable
In the second step, we can interchange the limits as FXn
is a monotone
and bounded function. Thus, ∀ x ≥ 0
F|Xn|(x) = FXn
(x) − FXn
(−x − 0) → FX(x) − FX(−x) = P[|X| ≤ x].
Hence, |Xn|
L→ |X|.548 Solutions to Conceptual Exercises
7.5.30 Suppose (Ω, A, P) is a probability space, where Ω = [0, 1], A is a sigma
field of subsets of Ω and P(An) = 1/n for An = [0, 1/n). Suppose the
random variable X and Xn, n ≥ 1 are defined on this space as follows.
X(ω) = 
0, if 0 ≤ ω ≤ 1/2
1, if 1/2 < ω ≤ 1
& Xn(ω) = 
1, if 0 ≤ ω ≤ 1/2
0, if 1/2 < ω ≤ 1.
Examine whether Xn
L
→ X and Xn
P
→ X.
Solution: From the definitions of Xn and X, observe that for any x ∈ R,
FXn
(x) = FX(x) =



0, if x < 0
1/2, if 0 ≤ x < 1
1, if x ≥ 1.
Thus, FXn
(x) = FX(x) ∀ x ∈ R. Hence, Xn
L
→ X. Now ∀ ω ∈ Ω,
|Xn(ω)−X(ω)| = 1 ⇒ ∀ ϵ ∈ (0, 1) P[|Xn−X| > ϵ] = 1 ⇒ Xn
P↛ X.
7.5.31 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables, each having the exponential distribution
with scale parameter 1. Examine whether X(n) − log n
L
→ X, where the
distribution function of X is FX(x) = exp(−e
−x
), − ∞ < x < ∞.
Solution: The distribution function of Xn for each n is given by,
F(x) = 
0, if x < 0
1 − e
−x
, if x ≥ 0.
Hence, The distribution function of X(n)
is given by,
FX(n)
(x) = 
0, if x < 0
(1 − e
−x
)
n, if x ≥ 0.
Observe that
P[X(n) − log n ≤ x] = P[X(n) ≤ (x + log n)] = FX(n)
(x + log n)
= 0 if x + log n < 0 ⇐⇒ x < − log n.
If x + log n ≥ 0, that is, if x ≥ − log n then
P[X(n) − log n ≤ x] = FX(n)
(x + log n)
= (1 − e
−(x+log n)
)
n = (1 − e
−x
/n)
n
→ exp(−e
−x
), − ∞ < x < ∞
⇒ X(n) − log n
L
→ X,
where FX(x) = exp(−e
−x
), − ∞ < x < ∞.Chapter 7 549
7.5.32 Suppose mn is a median of a random variable Xn, n ≥ 1. Show that
if Xn
L
→ X, then any limit point of mn is a median of X.
Solution: Suppose m is any limit point of mn. For ϵ > 0 such that
m + ϵ and m − ϵ are continuity points of the distribution of X, we have
m − ϵ < mn < m + ϵ for sufficiently large n. By the definition of the
median we get,
1
2
≤ P[Xn ≤ mn] ≤ P[Xn ≤ m+ϵ] & 1
2
≤ P[Xn ≥ mn] ≤ P[Xn ≥ m−ϵ].
Allowing n → ∞, we obtain
1/2 ≤ P[X ≤ m + ϵ] & 1/2 ≤ P[X ≥ m − ϵ].
Now allowing ϵ → 0, we get
1/2 ≤ P[X ≤ m] & 1/2 ≤ P[X ≥ m]
and hence m is a median of X.
7.5.33 If {Xn, n ≥ 1} is Cauchy in r-th mean, show that it is Cauchy in
probability.
Solution: The sequence {Xn, n ≥ 1} is Cauchy in r-th mean implies
that there exists a random variable X such that Xn
r→ X. Hence, Xn
P
→
X and hence it is Cauchy in probability.
7.5.34 If Xn
r→ X and Yn
r→ Y , examine whether (i) Xn ± Yn
r→ X ± Y and
(ii) XnYn
r→ XY .
Solution: It is given that Xn
r→ X and Yn
r→ Y . Thus, it is assumed
that Xn, X, Y and Yn belong to Lr. By Cr inequality
E(|(Xn ± Yn) − (X ± Y )|
r
) = E(|(Xn − X) ± (Yn − Y )|
r
)
≤ Cr(E(|Xn − X|
r
) + E(|Yn − Y |
r
)) → 0
⇒ Xn ± Yn
r→ X ± Y.
To examine whether XnYn
r→ XY , we again use Cr inequality and also
use Holder’s inequality proved in Section 4.5. It states that for s > 1
and 1/s + 1/l = 1, E(|XY |) ≤ E1/s(|X|
s
)E1/l(|Y |
l
). Thus,
E(|(XnYn) − (XY )|
r
) = E(|XnYn − XnY + XnY − XY |
r
)
= E(|Xn(Yn − Y ) + Y (Xn − X)|
r
)
≤ Cr(E(|Yn − Y |
r
|Xn|
r
) + E(|Xn − X|
r
|Y |
r
))
≤ Cr(E
1/l(|Yn − Y |
rl)E
1/s(|Xn|
rs)
+ Cr(E
1/l(|Xn − X|
rl)E
1/s(|Y |
rs)) → 0,
assuming that Xn
rl
→ X and Yn
rl
→ Y , E(|Xn|
rs) < ∞ and E(|Y |
rs) <
∞, where 1/l + 1/s = 1. It then follows that XnYn
r→ XY .550 Solutions to Conceptual Exercises
7.5.35 If Xn
r→ X and Yn
r→ Y , examine whether E(XnYn) → E(XY ).
Solution: It is given that Xn
r→ X and Yn
r→ Y . Thus, it is assumed
that Xn, X, Y and Yn are belong to Lr and hence in Ls for any s < r.
We use Holder’s inequality to examine whether E(XnYn) → E(XY ).
Observe that 1/r+1/s = 1 ⇒ s = r/(r−1) < r. Hence, E1/s(|Xn|
s
) <
∞ and E1/s(|Y |
s
) < ∞. Now using Holder’s inequality we have,
|E(XnYn) − E(XY )| = |E(XnYn − XnY + XnY − XY )|
≤ E(|Yn − Y ||Xn|) + E(|Xn − X||Y |)
≤ E
1/r(|Yn − Y |
r
)E
1/s(|Xn|
s
)
+ E
1/r(|Xn − X|
r
)E
1/s(|Y |
s
) → 0,
as Xn
r→ X and Yn
r→ Y . Thus, E(XnYn) → E(XY ).
7.5.36 Suppose {Xn, n ≥ 1} is a sequence of independent random vari￾ables such that Pn
i=1(Xi − E(Xi))/sn
L
→ Z ∼ N(0, 1), where s
2
n =
Pn
i=1 V ar(Xi). Show that Pn
i=1(Xi − E(Xi))/n P
→ 0 if and only if
sn/n → 0 as n → ∞.
Solution: Since Pn
i=1(Xi − E(Xi))/sn
L
→ Z ∼ N(0, 1), it is bounded
in probability. Suppose sn/n → 0 as n → ∞. Then
1
n
Xn
i=1
(Xi − E(Xi)) = sn
n
 
1
sn
Xn
i=1
(Xi − E(Xi))!
P
→ 0.
Suppose now that Pn
i=1(Xi − E(Xi))/n P
→ 0 but sn/n → c > 0. Then
1
sn
Xn
i=1
(Xi − E(Xi)) = n
sn
 
1
n
Xn
i=1
(Xi − E(Xi))!
P
→ 0 ⇒
1
sn
Xn
i=1
(Xi − E(Xi)) L
→ 0
which is a contradiction to Pn
i=1(Xi−E(Xi))/sn
L
→ Z ∼ N(0, 1). Thus,
sn/n → 0 as n → ∞.
7.5.37 Suppose {X1, X2, · · · , Xn} is a random sample from a normal N(θ, 1)
distribution, where θ ∈ {0, 1}. The maximum likelihood estimator ˆθn of
θ is given by,
ˆθn =

1, if Xn > 1/2
0, if Xn ≤ 1/2.
Examine whether (i) ˆθn
P
→ θ. (ii) Suppose Yn =
√
n(
ˆθn−θ). Examine theChapter 7 551
convergence in law of Yn. (iii) Examine whether ˆθn
a.s. → θ. (iv) Examine
whether for large n,
ˆθn = θ almost surely.
Solution: (i) To verify ˆθn
P
→ θ we have to check whether ˆθn →
P0
0 and
ˆθn →
P1
1. Observe that for all ϵ ≤ 1,
P0[|
ˆθn − 0| < ϵ] ≥ P0[
ˆθn = 0] = P0

Xn ≤ 1/2

= Φ ￾√
n/2

→ 1
as n → ∞. On similar lines for all ϵ ≤ 1,
P1[|
ˆθn − 1| < ϵ] ≥ P1[
ˆθn = 1] = P1

Xn > 1/2

= 1 − Φ
￾
−
√
n/2

→ 1
as n → ∞. For ϵ > 1, Pθ[|
ˆθn − θ| < ϵ] = 1 for θ = 0 and θ = 1. Thus,
ˆθn
P
→ θ.
(ii) Suppose Yn =
√
n(
ˆθn − θ). We find the limit law of √
n(
ˆθn − θ) for
θ = 0 and θ = 1. For θ = 0,
P0[
√
n(
ˆθn − 0) ≤ x] = P0[
ˆθn ≤ x/√
n] = 0 if x < 0 as ˆθn = 0 or 1.
For x = 0, P0[
√
n(
ˆθn−0) ≤ 0] = P0[
ˆθn = 0] = P0[Xn ≤ 1/2]=Φ(√
n/2).
For x > 0,
P0[
ˆθn ≤ x/√
n] = 
P0[
ˆθn = 0] = Φ(√
n/2), if 0 < x/√
n < 1
1, if x/√
n ≥ 1 .
Thus, P0[
√
n(
ˆθn − 0) ≤ x] =



0, if x < 0
Φ(√
n/2), if x = 0
Φ(√
n/2), if 0 < x < √
n
1, if x ≥
√
n .
Consequently as n → ∞,
P0[
√
n(
ˆθn − 0) ≤ x] →

0, if x < 0
1, if x ≥ 0 .
Thus, for θ = 0,
√
n(
ˆθn − 0) L
→ U ≡ 0. Suppose θ = 1,
P1[
√
n(
ˆθn − 1) ≤ x] = P1[
ˆθn ≤ 1 + x/√
n] = 0
if 1 + x/√
n < 0 ⇐⇒ x < −
√
n.
Suppose −
√
n < x < 0 ⇐⇒ 1 + x/√
n < 1. Then
P1[
ˆθn ≤ 1 + x/√
n] = P1[
ˆθn = 0] = P1[Xn ≤ 1/2]
= P1[
√
n(Xn − 1) ≤
√
n(1/2 − 1)] = Φ(−
√
n/2552 Solutions to Conceptual Exercises
For x = 0, P1[
√
n(
ˆθn − 1) ≤ 0] = P1[
ˆθn ≤ 1] = 1.
For x > 0 ⇐⇒ 1 + x/√
n > 1, then P1[
ˆθn ≤ 1 + x/√
n] = 1. Thus,
P1[
√
n(
ˆθn − 1) ≤ x] =



0, if x < −
√
n
Φ(−
√
n/2), if −
√
n < x < 0
1, if x ≥ 0 .
Hence, as n → ∞,
P1[
√
n(
ˆθn − 1) ≤ x] →

0, if x < 0
1, if x ≥ 0 .
Thus, for θ = 1 also, √
n(
ˆθn − 1) L
→ U ≡ 0. Hence, the limit law of
√
n(
ˆθn − θ) is degenerate at 0 for θ ∈ {0, 1}.
(iii) It is noted in (i) that for ϵ > 1, Pθ[|
ˆθn − θ| > ϵ] = 0 for θ = 0 and
θ = 1. For large n and 0 < ϵ ≤ 1,
Pθ[|
ˆθn − θ| ≥ ϵ] = 1 − Φ
√
n
2

= Φ 
−
√
n
2

≈ ϕ
√
n
2

2
√
n
=
2
√
2π
e
−n/8
√
n
,
where ϕ(·) is the probability density function of the standard normal
distribution. By the ratio test for convergence of series,
e
−(n+1)/8
√
n + 1
√
n
e−n/8
=
√
n
√
n + 1
e
−1/8 → e
−1/8 < 1
⇒
X
n≥1
Pθ[|
ˆθn − θ| > ϵ] = 2
√
2π
X
n≥1
e
−n/8
√
n
< ∞
⇒ ˆθn
a.s. → θ,
by the sufficient condition of almost sure convergence. Further we have,
P0[
ˆθn = 0] = P1[
ˆθn = 1] = Φ ￾√
n/2

⇐⇒ Pθ[
ˆθn = θ] = Φ ￾√
n/2

∀ θ
⇒ Pθ[
ˆθn ̸= θ] = 1 − Φ
￾√
n/2

= Φ ￾
−
√
n/2

=
2
√
2π
e
−n/8
√
n
&
2
√
2π
X
n≥1
e
−n/8
√
n
< ∞.
Suppose an event An is defined as An = {ω|
ˆθn(ω) ̸= θ}, then by the
Borel-Cantelli lemma,
X
n≥1
Pθ[
ˆθn ̸= θ] < ∞ ⇒ X
n≥1
P(An) < ∞
⇒ P(lim sup An) = 0 ⇐⇒ P(lim inf A
c
n
) = 1
⇒ Pθ{ω|
ˆθn(ω) = θ, ∀ n ≥ n0(ω)} Chapter 8 553
TABLE 11.7
Answer Key to MCQs in Chapter 7
Q.No. 1 2 3 4 5 6 7 8
Ans a,d a,b a,b,c a,b,c a,b,d c a,b,c,d a,b,c
Q.No. 9 10 11 12 13 14 15 16
Ans a,b,c,d a,b,c,d a,b,c,d a,b,c,d a c d a,c
Q.No. 17 18 19 20 21 22 23 24
Ans d a,b,c,d a,b,c,d c a,b,d a,b,c d d
Q.No. 25 26 27 28 29 30 31 32
Ans a,b,d c a,d b,d a,b,c,d a,c b d
Q.No. 33 34 35 36 37 38 39 40
Ans a,b,c,d a,b,c,d c c b b c b
Q.No. 41 42 43 44 45 46 47 48
Ans d d d d c d a,b,c,d
Hence we conclude that for large n,
ˆθn = θ almost surely.
Answers to the multiple choice questions, based on Chapter 7, are given
in Table 11.7.
11.8 Chapter 8
8.4.1 Suppose a sequence {(Xn, Y ), n ≥ 1} of random variables is such that
the conditional distribution of Xn given Y is uniform
U(Y − 1/n, Y + 1/n), n ≥ 1 and the marginal distribution of Y is
exponential with location parameter 1 and scale parameter 1. Exam￾ine whether the sequence {Xn, n ≥ 1} converges in quadratic mean,
probability, law and almost surely to Y. Examine whether a sequence
{E(Xn), n ≥ 1} converges to E(Y ). Check whether the conditions of
the dominated convergence theorem are satisfied.
Solution: From the conditional distribution of Xn given Y and the
marginal distribution of Y , we have ∀ n ≥ 1,
E(Y ) = 2, E(Xn|Y ) = Y ⇒ E(Xn) = E(Y ) = 2,
E((Xn − Y )
2
|Y ) = E((Xn − E(Xn|Y ))2
|Y ) = V ar(Xn|Y ) = 1/3n
2
⇒ E(Xn − Y )
2
) = E(E((Xn − Y )
2
|Y )) = 1/3n
2 → 0
⇒ Xn
q.m. → Y ⇒ Xn
P
→ Y ⇒ Xn
L
→ Y.554 Solutions to Conceptual Exercises
Further, X
n≥1
E(Xn − Y )
2 =
X
n≥1
1/3n
2 < ∞ ⇒ Xn
a.s → Y.
Thus, the sequence converges in quadratic mean, probability, law and
almost surely. Further, E(Y ) = E(Xn) = 2 ∀ n ≥ 1, Thus,
{E(Xn), n ≥ 1} is a sequence of constants 2 and hence has limit 2. Ob￾serve that |Xn| = Xn ≤ Y +1 and E(Y +1) = 3. Thus, Xn is dominated
by an integrable random variable and Xn
P
→ Y . Thus, the requirements
of the Lebesgue dominated probability convergence theorem are sat￾isfied. It is to be noted that since {E(Xn), n ≥ 1} is a sequence of
constants, we do not need the dominated convergence theorem to find
its limit.
8.4.2 Suppose {Xn, n ≥ 1} is a sequence of random variables such that Xn
follows exponential distribution with mean θ
n, 0 < θ < 1. Show that
E(
P
n≥1 Xn) = θ/(1 − θ). State the results that you may use.
Solution: Note that {Xn, n ≥ 1} is a sequence of non-negative random
variables. Hence by Corollary 8.2.4,
E
X
n≥1
Xn

=
X
n≥1
E(Xn) = X
n≥1
θ
n = θ
X
n≥1
θ
n−1 = θ/(1 − θ).
8.4.3 Suppose {Xn, n ≥ 1} is a sequence of identically distributed random
variables such that E(|X1|) < ∞. Suppose Yn = (1/n) max1≤i≤n |Xi
|.
Show that limn→∞ E(Yn) = 0.
Solution: Note that Un = max1≤i≤n |Xi
| is a non-negative random
variable. Hence,
E(Yn) = (1/n)E(Un) = (1/n)
Z ∞
0
P[Un > x] dx.
Suppose fn(x) = (1/n)P[Un > x]. Then limn→∞ fn(x) = 0 for any
x > 0. We use the following lemma to prove the required result.
Lemma: Suppose hn(x) → h(x) and |hn(x)| ≤ g(x) where R
g(x) dx is
finite. Then
limn→∞ Z
hn(x) dx =
Z
limn→∞
hn(x) dx =
Z
h(x) dx.
Note that this lemma is a version of Lebesgue dominated almost sureChapter 8 555
convergence theorem. Observe that
P[Un > x] = P[
[n
i=1
[|Xi
| > x]] ≤
Xn
i=1
P[|Xi
| > x]
⇒ 0 ≤ fn(x) ≤ (1/n)
Xn
i=1
P[|Xi
| > x] = P[|X1| > x]
&
Z ∞
0
P[|X1| > x] = E(|X1|) < ∞
⇒ limn→∞
E(Yn) = limn→∞ Z ∞
0
fn(x) dx =
Z ∞
0
limn→∞
fn(x) = 0,
by the above lemma.
8.4.4
P
Show that X is an integrable random variable if and only if
n≥1 P[|X| ≥ cn] < ∞, for some c > 0. In particular, deduce that if
the above series converges for some c > 0 then it converges for all c > 0.
Solution: Suppose a random variable Y is defined as X/c. Then
P[|X| ≥ cn] = P[|Y | ≥ n] and hence the result follows from Lemma
8.2.2. Further, if the result is true for any c > 0 it is true for all c > 0.
8.4.5 Suppose X is a non-negative random variable. Show that
(i) limn→∞ nE(I[X>n]/X) = 0 and (ii) limn→∞(1/n)E(I[X>1/n]/X) =
0.
Solution: (i) Observe that I[X>n]/X = 0 if X ≤ n. Note that
X > n ⇒ 1/X < 1/n ⇒ n/X < 1 ⇒ (n/X)I[X>n] < 1.
Suppose An = [X > n], then An+1 ⊂ An ∀ n ≥ 1. Thus, {An, n ≥ 1}
is a decreasing sequence with limit T
n≥1 An = ∅. Hence, I[X>n]
a.s. → 0.
Observe that n/X < 1 implies that (n/X)I[X>n]
a.s. → 0. Hence, by the
Lebesgue dominated almost sure convergence theorem,
limn→∞
nE(I[X>n]/X) = E( limn→∞
(n/X)I[X>n]) = 0.
(ii) Note that I[X>1/n]/X = 0 if X ≤ 1/n. Further,
X > 1/n ⇒ 1/nX < 1 ⇒ (1/nX)I[X>1/n] < 1.
Suppose Bn = [X > 1/n], then Bn+1 ⊂ Bn ∀ n ≥ 1. Thus, {Bn, n ≥ 1}
is an increasing sequence with limit S
n≥1 An = Ω. Hence, I[X>1/n]
a.s. → 1
and hence in probability. Observe that X being a real random variable,
1/X is bounded in probability. Hence, (1/n)(1/X)I[X>1/n]
P
→ 0. Hence,
by the Lebesgue dominated probability convergence theorem,
limn→∞
(1/n)E(I[X>1/n]/X) = E( limn→∞
(1/n)E(I[X>1/n]/X) = 0.556 Solutions to Conceptual Exercises
8.4.6 Suppose {Xn, n ≥ 1} is a sequence of random variables defined on
(Ω, A, P) and Y is an integrable random variables such that |Xn| ≤ Y
a.s. Prove that if Xn
L
→ 0, then limn→∞ E(Xn) = 0.
Solution: Note that if Xn
L
→ 0, then Xn
P
→ 0 and the result follows
from case (i) of Lebesgue dominated probability convergence theorem.
Answers to the multiple choice questions, based on Chapter 8, are given
in Table 11.8.
TABLE 11.8
Answer Key to MCQs in Chapter 8
Q.No. 1 2 3 4 5 6 7
Ans a,b a c b,c a,b,c d a,b,c,d
11.9 Chapter 9
9.4.1 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
such that P[Xn = 2n] = 1/2
n, n ≥ 1. Examine whether the sequence
{Xn, n ≥ 1} obeys the WLLN. Find more that one sequences {an, n ≥ 1}
and {bn, n ≥ 1} with which WLLN holds.
Solution: We have
E(Xn) = 1 & V ar(Xn) = 2n − 1
⇒ V ar(Sn) = 2(2n − 1) − n ⇒ V ar(Sn/bn) = 2
n+1
b
2
n
−
n + 2
b
2
n
.
Hence, if we select b
2
n = (2 + δ)
n+1
, δ > 0, then bn > 0, bn → ∞
and V ar(Sn/bn) → 0. Hence by Chebyshev’s inequality, it follows that
(Sn − an)/bn
P
→ 0, with an = n and with b
2
n = (2 + δ)
n+1, δ > 0. With
δ > 0, we have many options for bn. Suppose an = 0.Then ∀ ϵ > 0
P[|Sn/bn| > ϵ] ≤ E(S
2
n
)/b2
n
ϵ
2 = (2(2n − 1) − n + n
2
)/b2
n
ϵ
2→0.
It also follows from Sn/bn = (Sn−n)/bn+n/bn
P
→ 0. Thus, the sequence
{Xn, n ≥ 1} obeys the WLLN with an = n and bn = (2 + δ)
(n+1)/2 as
well as with an = 0 and bn = (2 + δ)
(n+1)/2
. Note that (Sn − an)/bn =
Sn/bn − an/bn
P
→ 0 for any sequence {an, n ≥ 1} such that an/bn → 0.
9.4.2 Suppose {Xn, n ≥ 1} is a sequence of independent random variables with
E(Xn) = 0 and V (Xn) = n
2
. Examine whether the sequence {Xn, n ≥
1} obeys the WLLN.Chapter 9 557
Solution: We have E(Xn) = 0, V ar(Xn) = n
2
. Hence,
V ar(Sn) = n(n + 1)(2n + 1)
6
⇒ V ar(Sn/bn) = n(n + 1)(2n + 1)
6b
2
n
.
The expression of V ar(Sn/bn) suggests that if we select 6b
2
n = n
3+δ
, δ >
0, then bn > 0, bn → ∞ and V ar(Sn/bn) → 0. Hence by Chebyshev’s
inequality, it follows that (Sn − an)/bn
P
→ 0, with an = 0 and with
b
2
n = n
3+δ/6. Thus, the sequence {Xn, n ≥ 1} follows WLLN.
9.4.3 Suppose {Xn, n ≥ 1} is a sequence of independent random variables with
E(Xn) = 0 and V (Xn) = n. Examine whether the sequence {Xn, n ≥ 1}
obeys the WLLN.
Solution: We have E(Xn) = 0 and V ar(Xn) = n. Hence,
V ar(Sn) = n(n + 1)
2
⇒ V ar(Sn/bn) = n(n + 1)
2b
2
n
.
The expression of V ar(Sn/bn) suggests that if we select 2b
2
n = n
2+δ
, δ >
0, then bn > 0, bn → ∞ and V ar(Sn/bn) → 0. Hence by Chebyshev’s
inequality, it follows that (Sn − an)/bn
P
→ 0, with an = 0 and with
b
2
n = n
2+δ/2. Thus, the sequence {Xn, n ≥ 1} follows WLLN.
9.4.4 Suppose {Xn, n ≥ 1} is a sequence of independent random variables with
P[Xn = 2n] = P[Xn = −2
n] = 2−2(n+1) and P[Xn = 0] = 1 − 2
−2n−1
.
Examine whether the sequence {Xn, n ≥ 1} obeys the WLLN.
Solution: From the given probability distribution of Xn, we have
E(Xn) = 0, V ar(Xn) = 222n
2
2n+2 =
1
2
& V ar(Sn/bn) = n
2b
2
n
.
Thus, if we select 2b
2
n = n
1+δ
, δ > 0, then bn > 0, bn → ∞ and
V ar(Sn/bn) → 0. Hence by Chebyshev’s inequality, it follows that
(Sn − an)/bn
P
→ 0, with an = 0 and with b
2
n = (1/2)n
1+δ
.
9.4.5 Suppose {Xn, n ≥ 1} is a sequence of independent random variables with
P[Xn = n] = P[Xn = −n] = 1/(2n
λ
) and P[Xn = 0] = 1−1/nλ
, λ > 0.
Examine whether the sequence {Xn, n ≥ 1} obeys the WLLN.
Solution: From the given probability distribution of Xn, we have
E(Xn) = 0 and V ar(Xn) = n
2−λ
. Hence,
V ar(Sn/bn) = 1
b
2
n
Xn
i=1
i
2−λ <
1
b
2
n
Xn
i=1
i
2 =
n(n + 1)(2n + 1)
6b
2
n
.
If we select b
2
n = n
3+δ
, δ > 0, then bn > 0, bn → ∞ and V ar(Sn/bn) →
0 and the sequence {Xn, n ≥ 1} follows WLLN with an = 0 and b
2
n =
n
3+δ
.558 Solutions to Conceptual Exercises
9.4.6 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
with P[Xn = n
α] = P[Xn = −n
α] = 1/2n
2 and P[Xn = 0] = 1 − 1/n2
,
where α < 3/2. Examine whether the sequence {Xn, n ≥ 1} obeys the
WLLN.
Solution: We have E(Xn) = 0 and V ar(Xn) = n
2α−2
. It is to be noted
that α < 3/2 ⇒ 2α − 2 < 3 − 2 = 1. Hence,
V ar(Sn/bn) = 1
b
2
n
Xn
i=1
i
2α−2 <
1
b
2
n
Xn
i=1
i =
n(n + 1)
2b
2
n
.
If we select b
2
n = n
2+δ
, δ > 0, then bn > 0, bn → ∞ and V ar(Sn/bn) →
0 and the sequence {Xn, n ≥ 1} follows WLLN with an = 0 and
b
2
n = n
2+δ
.
9.4.7 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
such that X1 is degenerate at 0 and ∀ n ≥ 2,
P[Xn = ±n/ log n] = log n/(2n) & P[Xn = 0] = 1 − (log n)/n.
Examine whether the sequence {Xn, n ≥ 1} obeys the WLLN.
Solution: We have E(Xn) = 0 and V ar(Xn) = n/ log n, n ≥ 2. Hence,
V ar(Sn/bn) = 1
b
2
n
Xn
i=2
i
log i
<
1
b
2
n
log 2
Xn
i=2
i =
1
b
2
n
log 2 
n(n + 1)
2
− 1

.
If we select b
2
n = n
2+δ
, δ > 0, then bn > 0, bn → ∞ and V ar(Sn/bn) →
0 and the sequence {Xn, n ≥ 1} follows WLLN with an = 0 and
b
2
n = n
2+δ
.
9.4.8 Suppose {Xn, n ≥ 1} is a sequence of independent and identically dis￾tributed random variables with characteristic function
ϕ(t) = 
1 − |t|, if |t| ≤ 1
0, if |t| > 1.
Show that Sn/n L
→ X, where X ∼ C(0, 1), Cauchy distribution with
location parameter 0 and scale parameter 1 and hence WLLN does not
hold.
Solution: Note that Sn is a sum of n independent and identically dis￾tributed random variables, hence its characteristic function is given by,
ϕ Sn
n
(t) = (ϕ(t/n))n. Since ϕ(t) = 0 for |t| > 1, ϕ(t/n) = 0 if n < |t| and
∀ n ≥ |t|, it is 1 − |t/n|. Thus ∀ n ≥ |t|,
ϕ Sn
n
(t) = (ϕ(t/n))n = (1 − |t/n|)
n → e
−|t| ∀ t ∈ R.
However, e
−|t|
is a characteristic function Cauchy C(0, 1) distribution.Chapter 9 559
Hence, Sn/n L
→ X ∼ C(0, 1) distribution which further implies that
Sn/n is bounded in probability. To show that WLLN does not hold,
we assume the contrary. Suppose {Xn, n ≥ 1} satisfies the WLLN, that
is, there exist sequences {an, n ≥ 1} of real numbers and {bn, n ≥ 1}
of positive real numbers with bn → ∞ such that (Sn − an)/bn
P
→ 0 as
n → ∞. Then using the result that the sequence {(Sn − an)/bn, n ≥ 1}
is bounded in probability, we have
(Sn − an)
n
=
(Sn − an)
bn
bn
n
P
→

0, if n → ∞ faster than bn
∞, if bn → ∞ faster than n.
If bn → ∞ at the same rate as that of n, then also (Sn − an)/n P
→ 0,
since (Sn − an)/bn
P
→ 0. Observe that if bn → ∞ faster than n, then
(Sn−an)/n P↛ 0 and hence the WLLN does not hold with such sequences
{bn, n ≥ 1}. Hence we focus on sequences {bn, n ≥ 1} which → ∞ at a
rate slower than or equal to n. Since convergence in probability implies
convergence in law, for all such sequences {bn, n ≥ 1}, (Sn −an)/n L
→ 0.
We have proved that Sn/n L
→ X ∼ C(0, 1) distribution. Now we make
following three cases. (i) If the sequence {an, n ≥ 1} of real numbers is
such that an/n → 0, then by Slusky’s theorem (Sn−an)/n also converges
in law to Cauchy C(0, 1) distribution. (ii) If the sequence {an, n ≥ 1} of
real numbers is such that an/n → a, then by Slusky’s theorem
(Sn − an)/n L
→ X + a. (iii) If the sequence {an, n ≥ 1} of real numbers
is such that an/n → ∞, then for (Sn − an)/n to converge in probabil￾ity or in law to 0, Sn/n must → ∞. It is a contradiction to the result
that Sn/n is bounded in probability. Hence we discard all the sequences
{an, n ≥ 1} as considered in case (iii). For sequences in cases (i) and
(ii) (Sn − an)/n L
→ X or X + a. It is known that the limit random vari￾ables in convergence in law are identically distributed. This result gets
violated when we assume that {Xn, n ≥ 1} satisfies the WLLN, since in
that case (Sn − an)/n L
→ 0. Hence, we claim that {Xn, n ≥ 1} does not
satisfy the WLLN.
9.4.9 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
such that P[Xn =
√
n] = P[Xn = −
√
n] = 1/2. (i) Show that the char￾acteristic function ϕn(t) of Sn/n is Qn
k=1 cos 
t
√
k/n
and converges to
exp(−t
2/4) as n → ∞. (ii) Hence, show that Sn/n P↛ 0. (iii) Find a
sequence {an, n ≥ 1} and {bn, n ≥ 1} such that (Sn − an)/bn
P
→ 0 as
n → ∞.
Solution: From the probability distribution of Xn, E(Xn) = 0 and
V ar(Xn) = n. Further, the characteristic function ϕk(t) of Xk is
ϕk(t) = E(e
itXk ) = (1/2)(e
it√
k + e
−it√
k
) = cos(t
√
k). Hence the
characteristic function of Sn/n is given by, ϕn(t) = ϕSn/n(t) =560 Solutions to Conceptual Exercises
Qn
k=1 cos 
t
√
k/n
, ∀ t ∈ R. To find its limit as n → ∞, observe that
log ϕn(t) = log Yn
k=1
cos 
t
√
k/n
!
=
Xn
k=1
log cos 
t
√
k/n
=
Xn
k=1
log 
1 −
t
2k
2n2
+
t
4k
2
4n4
− · · · 
= −
Xn
k=1

t
2k
2n2
−
t
4k
2
4n4
− · · · 
−
Xn
k=1
1
2

t
2k
2n2
− · · · 2
− · · ·
= −
t
2
2n2
n(n + 1)
2
+
t
4
4n4
n(n + 1)(2n + 1)
6
− · · · .
Hence,
log ϕn(t) = −
t
2
4
n(n + 1)
n2
+ ∆n → − t
2
/4,
since ∆n consists of all the terms which converge to 0 as n → ∞. Hence,
ϕn(t) → exp(−t
2/4) which is the characteristic function of Z which has
normal N(0, 1/2) distribution. Thus, Sn/n = Xn
L
→ Z, without any
norming.
(ii) Suppose Sn/n P
→ 0. Then Sn/n L
→ 0. But we have proved that
Sn/n L
→ Z ∼ N(0, 1/2). Thus the result that the limit random variables
in convergence in law are identically distributed gets violated. Hence,
we conclude that Sn/n P↛ 0.
(iii) Observe that V ar(Sn/bn) = n(n + 1)/2b
2
n
. Hence, if we take
bn = n
1+δ with δ > 0 then V ar(Sn/bn) → 0 and the WLLN holds
with bn = n
1+δ
.
9.4.10 Suppose {Xn, n ≥ 1} is a sequence of random variables with E(Xn) =
0, V ar(Xn) = σ
2 and Cov(Xn, Xm) = σ
2α
|m−n|
, |α| < 1. Verify
whether WLLN holds.
Solution: Since E(Xn) = 0, V ar(Xn) = σ
2 and Cov(Xn, Xm) =
σ
2α
|m−n|
,
V ar(Sn) = V arXn
i=1
Xi

= nσ2 + 2Xn
i=1
Xn
j=i+1
Cov(Xi
, Xj )
= nσ2 + 2σ
2Xn
i=1
Xn
j=i+1
α
|j−i|
= nσ2 + 2σ
2
((n − 1)α + (n − 2)α
2 + · · · + α
n−1
)
⇒ V ar(Sn/n) = σ
2
n
+
2σ
2
n2
((n − 1)α + (n − 2)α
2 + · · · + α
n−1
)
→ 0 as n → ∞.
Hence if we take an = 0 and bn = n, then V ar((Sn − an)/bn) → 0 and
the WLLN holds.Chapter 10 561
TABLE 11.9
Answer Key to MCQs in Chapter 9
Q.No. 1 2 3 4 5 6 7 8 9
Ans b c a,b,c,d a,b,d c a,b,d b a,b,c,d a
9.4.11 Suppose {Xn, n ≥ 1} is a sequence of independent and identically dis￾tributed random variables with V ar(X1) < ∞. Show that
(2/n(n + 1))Pn
i=1 iXi
P
→ E(X1).
Solution: It is clear that
E
 
2
n(n + 1)
Xn
i=1
iXi
!
=
2
n(n + 1)
Xn
i=1
iE(Xi) = E(X1)
V ar 
2
n(n + 1)
Xn
i=1
iXi
!
=
4
n2(n + 1)2
Xn
i=1
i
2V ar(Xi)
=
4
n2(n + 1)2
V ar(X1)
n(n + 1)(2n + 1)
6
→ 0,
as n → ∞. The required result follows from Chebyshev’s inequality.
Answers to the multiple choice questions, based on Chapter 9, are given
in Table 11.9.
11.10 Chapter 10
10.4.1 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables, each having P(λ) distribution. Suppose
Sn =
Pn
i=1 Xi
. Find limn→∞ P[Sn ≤ nλ +
√
nλ].
Solution: Since Xn ∼ P(λ) distribution, E(Xn) = V ar(Xn) = λ <
∞. Hence by the CLT, (Sn − nλ)/
√
nλ L
→ Z ∼ N(0, 1). Hence,
P[Sn ≤ nλ +
√
nλ] = P[(Sn − nλ)/
√
nλ ≤ 1] → Φ(1) = 0.8413.
10.4.2 Suppose {Xn, n ≥ 1} is a sequence of independent and identically dis￾tributed random variables, each having Pareto-type distribution, with
probability density function f(x) = c/(|x|
3
(log |X|)
2
) for |x| > 2 and
0 otherwise, where c is a normalizing constant. Examine whether the
sequence satisfies CLT. Examine whether one can verify Lyapounov’s
condition.
Solution: Observe that f(x) = f(−x) ∀ x ∈ R. Thus the distribution
is symmetric around 0. Hence E(Xn) = 0 and V ar(Xn) = E(X2
n
).562 Solutions to Conceptual Exercises
With log x = y, E(X2
n
) is obtained as follows.
E(X2
n
) = Z −2
−∞
x
2
f(x) dx +
Z ∞
2
x
2
f(x) dx
= 2 Z ∞
2
x
2
f(x) dx = 2c
Z ∞
2
x
2
/(x
3
(log x)
2
) dx
= 2c
Z ∞
2
1/(x(log x)
2
) dx = 2c
Z ∞
log 2
(1/y2
) dy =
2c
log 2 < ∞.
Hence, the sequence satisfies CLT. To examine whether Lyapounov’s
condition is satisfied, we find E(|Xn|
2+δ
), δ > 0 as follows.
E(|Xn|
2+δ
) = 2 Z ∞
2
x
2+δ
f(x) dx = 2c
Z ∞
2
x
2+δ−3
/(log x)
2
) dx
= 2c
Z ∞
log 2
e
yδ/(y
2
) dy with log x = y
> 2c
Z ∞
log 2
y
3
δ
3
/(6y
2
) dy = (2c/6)δ
3
Z ∞
log 2
y dy = ∞.
Hence, one cannot verify Lyapounov’s condition.
10.4.3 Prove that limn→∞ e
−n Pn
i=0 n
i/i! = 1/2.
Solution: Suppose {Xn, n ≥ 1} is a sequence of independent and iden￾tically distributed random variables, each following P(1) distribution.
Thus, E(Xn) = V ar(Xn) = 1 ∀ n ≥ 1. Hence by the additive property
of Poisson distribution, Yn =
Pn
i=1 Xi ∼ P(n) distribution and by the
CLT, Pn
i=1(Xi − 1)/
√
n = (Yn − n)/
√
n
L
→ Z ∼ N(0, 1). Note that
e
−nXn
i=0
n
i
/i! = P[Yn ≤ n] = P[(Yn − n)/
√
n ≤ 0] → P[Z ≤ 0] = 1/2.
10.4.4 Evaluate limn→∞ P[nq/p]
i=0 ￾
i+k−1
i

p
k
q
i−k
, where 0 < p < 1 and q =
1 − p.
Solution: Note that En =
P[nq/p]
i=0 ￾
i+k−1
i

p
k
q
i−k = P[Xn ≤ nq/p],
where Xn follows negative binomial distribution with parameters n
and p. Hence Xn
d=
Pn
i=1 Yi
, where Yi follows geometric distribu￾tion with parameter p and support as set W of whole numbers.
Further, E(Yi) = q/p and V ar(Yi) = q/p2
. Hence by the CLT,
(
Pn
i=1 Yi − nq/p)/
p
nq/p2
L
→ Z ∼ N(0, 1) distribution. Thus,
En = P[Xn ≤ nq/p] = P
h
(Xn − nq/p)
p
nq/p2
≤
(nq/p − nq/p)
p
nq/p2
i
= P
h
(
Xn
i=1
Yi − nq/p)/
p
nq/p2 ≤ 0
i
→ P[Z ≤ 0] = 1/Chapter 10 563
10.4.5 Examine whether (Xn − E(Xn))/
p
V (Xn)
L
→ Z ∼ N(0, 1) as n → ∞,
if Xn ∼ G(α, n), where n is a natural number.
Solution: Observe that Xn ∼ G(α, n) ⇒ Xn
d=
Pn
i=1 Yi
, where
Yi ∼ G(α, 1), i = 1, 2, · · · , n. Hence, E(Yi) = 1/α and V ar(Yi) = 1/α2
.
Hence by the CLT,
(Xn −E(Xn))/
p
V (Xn)
d=
Xn
i=1
Yi −n(1/α)

/
p
n/α2
L
→ Z ∼ N(0, 1).
10.4.6 Evaluate limn→∞ R n/α+2√
n/α
0
α
n
Γ(n)
x
n−1
e
−αx dx.
Solution: Observe that In =
R n/α+2√
n/α
0
(α)
n
Γ(n)
x
n−1
e
−αx dx is the same
as P[Xn ≤ n/α + 2√
n/α], where Xn ∼ G(α, n). Note that Xn
d
P =
n
i=1 Yi
, where Yi ∼ G(α, 1) with E(Yi) = 1/α and V ar(Yi) = 1/α2
.
Hence by the CLT, (
Pn
i=1 Yi − n/α)/
p
n/α2
L
→ Z ∼ N(0, 1) distribu￾tion. Thus,
In = P[Xn ≤ n/α + 2√
n/α] = P
h
(Xn − n/α)
p
n/α2
≤
2
√
n/α
p
n/α2
i
= P
hXn
i=1
(Yi − n/α)/
p
n/α2 ≤ 2
i
→ Φ(2) = 0.9773.
10.4.7 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables each having standard normal distribution.
Suppose Yn =
Pn
i=1 X2
i
. Show that (Yn − n)/
p
(2n)
L
→ Z ∼ N(0, 1).
What is the distribution of (Yn − n)
2/(2n) for large n? Justify.
Solution: Since Xi ∼ N(0, 1) distribution, {X2
1
, X2
2
, · · · , X2
n} are in￾dependent and identically distributed random variables, each having
χ
2
1 distribution with mean 1 and variance 2. Hence by the CLT,
(Yn − n)/
p
(2n) = Xn
i=1
(X2
i − E(X2
i
))/
q
(nV ar(X2
i
)) L
→ Z ∼ N(0, 1).
By the continuous mapping theorem, it follows that (Yn − n)
2/(2n)
L
→
U ∼ χ
2
1 distribution.
10.4.8 Suppose X ∼ P(λ), λ > 0. Prove that for large λ, distribution of
(X − λ)
2/λ can be approximated by the chi-square distribution.564 Solutions to Conceptual Exercises
Solution: The characteristic function ϕ of X ∼ P(λ) is
ϕ(t) = exp{λ(e
it − 1)}. Suppose Yλ = (X − λ)/
√
λ. Then its charac￾teristic function is given by
ϕYλ
(t) = E(exp(itYλ) = E(exp(it(X − λ)/
√
λ)
= e
−it√
λ
exp{λ(e
it/√
λ − 1)}
⇒ log ϕ(t)Yλ = −it√
λ + λ(e
it/√
λ − 1)
= −it√
λ + λ(it/√
λ − (1/2)t
2
/λ − (1/6)it3
/λ3/2 + · · ·)
= −t
2
/2 + ∆λ → −t
2
/2 ⇒ ϕYλ
(t) → exp(−t
2
/2),
as λ → ∞, since ∆λ → 0 as λ → ∞. Hence, by the continuity theorem
and the uniqueness theorem of characteristic functions Yλ
L
→ Z ∼
N(0, 1). Further by the continuous mapping theorem, (X − λ)
2/λ L
→
U ∼ χ
2
1 distribution. Thus, for large λ, distribution of (X − λ)
2/λ can
be approximated by the chi-square distribution.
10.4.9 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed random variables, each following U(0, θ) distribution, θ > 0.
Suppose Sn = (Qn
i=1 Xi)
1/n. Find the limiting distribution of
√
n(Sn − θe−1
).
Solution: Suppose Tn = − log Sn = (1/n)
Pn
i=1(− log Xi) =
(1/n)
Pn
i=1 Yi where Yi = − log Xi
, i = 1, 2, · · · , n. If X ∼ U(0, θ)
and Y = − log X, then the probability density function fY (y, θ) of Y
is given by,
fY (y, θ) = (1/θ)e
−y
, − log θ < y < ∞.
Using the method of integration by parts, we have
E(Y ) = 1
θ
Z ∞
− log θ
ye−y =
1
θ
Z ∞
− log θ
y
d
dy (−e
−y
)

= 1 − log θ
E(Y
2
) = 1
θ
Z ∞
− log θ
y
2
e
−y =
1
θ
Z ∞
− log θ
y
2
d
dy (−e
−y
)

=
1
θ

(−y
2
e
−y
)
∞
− log θ + 2 Z ∞
− log θ
ye−y

= (log θ)
2 + 2 − 2 log θ = 1 + (1 − log θ)
2
.
Thus, V ar(Y ) = 1 and {Y1, Y2, · · · , Yn} are independent and identi￾cally distributed random variables with finite mean 1 − log θ = ϕ and
variance 1. Hence by the Lindeberg-Levy CLT, √
n(Tn − ϕ)
L
→ Z ∼
N(0, 1). Now to find the limiting distribution of √
n(Sn−θe−1
), we con￾sider a transformation g(x) = e
−x
, it is a differentiable function withChapter 10 565
g
′
(x) = −e
−x ̸= 0. Hence, √
n(g(Tn) − g(ϕ)) L
→ Z1 ∼ N(0,(g
′
(ϕ))2
)
by Theorem 7.3.9. Note that
g(Tn) = e
−Tn = Sn =
Yn
i=1
Xi
1/n
, g(ϕ) = e
−1+log θ = θe−1
& (g
′
(ϕ))2
) = (−e
−1+log θ
)
2 = θ
2
e
−2
.
Thus, the limiting distribution of √
n(Sn−θe−1
) is normal N(0, θ2
e
−2
).
From Lemma 7.3.2, we also conclude that Sn
P
→ θe−1
. In the termi￾nology of large sample inference, we say that Sn is a consistent and
asymptotically normal estimator of θe−1 with approximate variance
θ
2
e
−2/n.
10.4.10 Suppose {Xn, n ≥ 1} is a sequence of independent and identically
distributed positive random variables. Suppose Sn = (Qn
i=1 Xi)
1/n
.
Find the non-degenerate limiting distribution of suitably normalized
Sn.
Solution: Suppose Tn = log Sn = (Pn
i=1 log Xi)/n. Since {Xn, n ≥
1} is a sequence of independent and identically distributed positive
random variables, {log Xn, n ≥ 1} is a sequence of independent and
identically distributed random variables. Suppose µ = E(log X) and
σ
2 = V ar(log X) < ∞. Then √
n(Tn − µ)/σ L
→ Z ∼ N(0, 1), by the
Lindeberg-Levy CLT. Suppose a function g is defined as g(x) = e
x
,
x > 0. Then it is differentiable and g
′
(x) = e
x ̸= 0 ∀ x > 0. Hence
by the δ method, √
n(g(Tn) − g(µ))/σ L
→ Z ∼ N(0,(g
′
(µ))2
) which
implies that √
n(Sn − e
µ)/
L
→ Z1 ∼ N(0, σ2
e
2µ) distribution.
10.4.11 Suppose {Xn, n ≥ 1} is a sequence of independent and identically dis￾tributed random variables, each following a Poisson P(θ) distribution.
Find the non-degenerate limiting distribution of suitably normalized
sample variance.
Solution: Since X ∼ P(θ), E(X) = V ar(X) = θ < ∞. The sample
variance S
2
n
is given by S
2
n = (1/n)
Pn
i=1(Xi−Xn)
2
. To find its limiting
distribution, observe that
S
2
n =
1
n
Xn
i=1
(Xi − Xn)
2 =
1
n
Xn
i=1
((Xi − θ) − (Xn − θ))2
=
1
n
Xn
i=1
(Yi − Y n)
2 =
1
n
Xn
i=1
Y
2
i − Y
2
n
,
where Yi = Xi − θ. Thus, E(Yi) = 0 and E(Y
2
i
) = V ar(Yi) =
θ. Hence by the WLLN, Y n
P
→ E(Yi) = 0. By the CLT
√
n(Y n)
L
→ Z1 ∼ N(0, θ). Hence, it is bounded in probability, as566 Solutions to Conceptual Exercises
a consequence, √
n(Y n)(Y n)
P
→ 0. Further, by the CLT applied to
{Y
2
1
, Y 2
2
, · · · , Y 2
n },
√
n((1/n)
Xn
i=1
Y
2
i − θ)
L
→ Z2 ∼ N(0, v(θ)), where
v(θ) = V ar(Y
2
i
) = E(Xi − θ)
4 − (E(Xi − θ)
2
)
2
⇒
√
n(S
2
n − θ) = √
n
 1
n
Xn
i=1
Y
2
i − Y
2
n − θ

=
√
n
 1
n
Xn
i=1
Y
2
i − θ

−
√
n(Y n)(Y n)
L
→ Z2
where Z2 ∼ N(0, v(θ)). To find v(θ) we need to find the fourth central
moment of P oi(θ) distribution. We obtain it from its cumulant gener￾ating function CX(t). The moment generating function MX(t) of X is
MX(t) = exp(θ{e
t − 1}) and hence CX(t) = θ(e
t − 1) = θ(t + t
2/2! +
t
3/3!+t
4/4!+· · ·). Using the relation between cumulants ki and central
moments µi we have ki = µi = θ, i = 2, 3 and µ4 = k4 + 3k
2
2 = θ + 3θ
2
.
Thus, v(θ) = E(Xi − θ)
4 − (E(Xi − θ)
2
)
2 = µ4(θ) − θ
2 = θ + 2θ
2
.
10.4.12 Suppose Xn ∼ B(n, p), 0 < p < 1, n ≥ 1 and Yn = log(Xn/n) if
Xn ̸= 0 and Yn = 1 if Xn = 0. Show that √
n(Yn − log p)
L
→ Z1 ∼
N(0, q/p), where q = 1 − p.
Solution: Note that Yn can be expressed as
Yn = log(Xn/n)I[Xn̸=0] + 1 × I[Xn=0] = log(Xn/n)(1 − Un) + Un,
where Un = I[Xn=0]. Observe that,
√
n(Yn − log p) = √
n

log(Xn/n)(1 − Un) + Un − log p

=
√
n (log(Xn/n) − log p) −
√
nUn log(Xn/n) + √
nUn.
We discuss the limiting behaviour of these terms. For ϵ > 0,
P[
√
n|Un| > ϵ] = P[Un = 1] = P[Xn = 0] = q
n
⇒
X
n≥1
P[
√
n|Un| > ϵ] = X
n≥1
q
n < ∞ ⇒ √
nUn
a.s. → 0. (11.1)
by Corollary 6.3.1. Hence, √
nUn
a.s. → 0. Further, if Xn ∼ B(n, p),
then Xn
d=
Pn
i=1 Wi where {W1, W2, · · · , Wn} are independent and
identically distributed random variables each having Bernoulli B(1, p)
distribution with mean p and variance pq, which is positive and finite.Chapter 10 567
Hence by the Lindeberg-Levy CLT,
Xn
i=1
Wi − np
/
√
npq
L
→ Z ∼ N(0, 1)
⇒
√
n

(Xn/n) − p

L
→ Z1 ∼ N(0, pq)
⇒
√
n

log(Xn/n) − log p

L
→ Z1 ∼ N(0, q/p),
by the δ method. Observe that as in Example 6.3.8,
(Xn/n)
a.s. → p ⇒ log(Xn/n)
a.s. → log p
√
nUn
a.s. → 0 by Equation (11.1)
⇒
√
nUn log(Xn/n)
a.s. → 0 ⇒
√
nUn log(Xn/n)
P
→ 0.
Hence,
√
n(Yn − log p) = √
n (log(Xn/n) − log p) −
√
nUn log(Xn/n) + √
nUn
L
→ Z1 ∼ N(0, q/p) by Slutsky’s theorem.
10.4.13 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
with P[Xn = ±n] = n
−λ/2 and P[Xn = 0] = 1 − n
−λ
, λ > 0. Show
that Lyapounov’s condition for the central limit theorem holds for this
sequence for some λ.
Solution: We verify the condition for δ = 1. From the given distribu￾tion of Xk,
E(Xk) = 0, V ar(Xk) = k
2−λ & E(|Xk|
3
) = k
3−λ
⇒ s
2
n =
Xn
k=1
V ar(Xk) = Xn
k=1
k
2−λ ≈
Z n
0
x
2−λ
dx = n
3−λ
/(3 − λ)
& un =
Xn
k=1
E(|Xk|
3
) = n
4−λ
/(4 − λ)
⇒ un/s3
n =
n
4−λ
4 − λ
3 − λ
n3−λ
3/2
=
(3 − λ)
3/2
4 − λ
1
n(1−λ)/2 → 0
if λ < 1. Hence with δ = 1, Lyapounov’s condition for the central
limit theorem holds for this sequence when λ < 1. Hence, Lindeberg’s
condition also holds. Thus, the CLT holds for this sequence for λ < 1.
Note that
max
1≤k≤n
σk/s2
n = n
2−λ
(3 − λ)/n3−λ = 1/n → 0.
Hence Feller’s condition is also satisfied.568 Solutions to Conceptual Exercises
10.4.14 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
with P[Xn = ±n
λ
] = 1/2. Examine whether Lyapounov’s condition,
Lindeberg’s condition and Feller’s condition are satisfied. Examine if
CLT holds for some values of λ.
Solution: From the given distribution of Xk,
E(Xk) = 0, V ar(Xk) = k
2λ & E(|Xk|
3
) = k
3λ
⇒ s
2
n =
Xn
k=1
V ar(Xk) = Xn
k=1
k
2λ ≈
Z n
0
x
2λ
dx = n
2λ+1/(2λ + 1).
Note that s
2
n > 0, if 2λ + 1 > 0 ⇐⇒ λ > −1/2. Further,
un =
Xn
k=1
E(|Xk|
3
) = Xn
k=1
k
3λ ≈
Z n
0
x
3λ
dx = n
3λ+1/(3λ + 1)
⇒ un/s3
n =
n
3λ+1
3λ + 1
2λ + 1
n2λ+1 3/2
=
(2λ + 1)3/2
3λ + 1
1
n1/2 → 0.
Thus, if λ > −1/2 with δ = 1, Lyapounov’s condition for the central
limit theorem holds for this sequence and hence Lindeberg’s condition
also holds. Thus, the CLT holds for this sequence for λ > −1/2. Note
that for λ > 0,
max
1≤k≤n
σ
2
k/s2
n = n
2λ
(2λ + 1)/n2λ+1 = (2λ + 1)/n → 0.
If λ ∈ (−1/2, 0), then
max
1≤k≤n
σ
2
k/s2
n = (2λ + 1)/n2λ+1 → 0.
Hence Feller’s condition is also satisfied. We now verify Lindeberg’s
condition separately. Note that n
λ/sn = 1/(n
1/2
(2λ + 1)) → 0, for
all λ ≥ −1/2. Hence given ϵ > 0, ∃ n0 such that ∀ n ≥ n0,
n
λ/sn < ϵ ⇐⇒ ϵsn > nλ
. Hence, ∀ k = 1, 2, · · · , n, [|Xk| > ϵsn] ⊆
[|Xk| > nλ
].
Case (i) Suppose λ > 0. Then ∀ k = 1, 2, · · · , n
k ≤ n ⇒ |Xk| = k
λ ≤ n
λ = |Xn| ⇒ P[|Xk| > nλ
] = 0
⇒ P[|Xk| > ϵsn] ≤ P[|Xk| > nλ
] = 0
⇒ gn(ϵ) = (1/s2
n
)
Xn
k=1
Z
[|Xk|≥ϵsn]
x
2
kdFk(xk) → 0.
Case (ii) Suppose
p −1/2 < λ ≤ 0. Note that 1/sn =
(2λ + 1)/n(2λ+1)/2 → 0. Hence given ϵ > 0, ∃ n1 such that
∀ n ≥ n1, 1/sn < ϵ, that is, ϵsn > 1. Further, for −1/2 < λ ≤ 0,
|Xk| = k
λ ≤ 1. Thus, ∀ n ≥ n1, ϵsn > 1 > |Xk| which implies that
P[|Xk| > ϵsn] = 0 ∀ k = 1, 2, · · · , n. Hence gn(ϵ) → 0 and Lindeberg’s
condition holds.Chapter 10 569
10.4.15 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
such that for α ≥ 1/2,
P[Xn = ±n
α
] = n
1−2α
/2 & P[Xn = 0] = 1 − n
1−2α
, n ≥ 1.
Show that ∀ α ∈ [1/2, 1), Sn/sn
L
→ Z ∼ N(0, 1).
Solution: Observe that α ≥ 1/2 ⇒ 1−2α ≤ 0. Hence, 1−n
1−2α ≤ 1
and n
1−2α/2 ≤ 1. From the given probability distribution we have
E(Xk) = 0, V ar(Xk) = E(X2
k
) = k ⇒ s
2
n = n(n + 1)/2
E(|Xk|
3
) = k
1+α ⇒
Xn
k=1
E(|Xk|
3
) ≈
Zn
0
x
1+α
dx = n
2+α
/(2 + α)
⇒
Pn
k=1
E(|Xk|
3
)
s
3
n
=
2
3/2 n
2+α
(n(n + 1))3/2(2 + α)
=
2
3/2
(2 + α)
1
(1 + 1/n)
3/2n1−α → 0, for α < 1.
Hence by Lyapounov’s CLT, Sn/sn
L
→ Z ∼ N(0, 1) distribution for
α < 1.
10.4.16 Suppose {Xn, n ≥ 1} is a sequence of independent random variables
such that Xk ∼ U(0, k) distribution. Suppose Yk = Xk/n1/2
,
k = 1, 2, · · · , n, n ≥ 1. Show that {Yk, k ≥ 1} satisfies Lyapounov’s,
Lindeberg’s and Feller’s conditions and hence CLT is valid for
P
Sn =
n
k=1(Yk − E(Yk)).
Solution: Since Xk ∼ U(0, k)
E(Xk) = k/2 V ar(Xk) = k
2
/12 & E(X3
k
) = k
3
/4
E|Xk − E(Xk)|
3 =
1
k
Z k
0
|x − k/2|
3
dx = k
3
/32
Yk = Xk/n1/2 ⇒ E(Yk) = k/2n
1/2 & V ar(Yk) = k
2
/12n
⇒ s
2
n =
Xn
k=1
V ar(Yk) = n(n + 1)(2n + 1)/72n → ∞
⇒ E|Yk − E(Yk)|
3 = k
3
/32n
3/2
⇒
Xn
k=1
E|Yk − E(Yk)|
3 = n
2
(n + 1)2
/128n
3/2
.570 Solutions to Conceptual Exercises
TABLE 11.10
Answer Key to MCQs in Chapter 10
Q.No. 1 2 3 4 5 6 7 8 9 10
Ans d a,b,c,d a,d d a,b,c,d a,c,d b c,d a,c,d b
Q.No. 11 12 13 14 15 16 17 18 19 20
Ans c a b c c b b
Observe that max1≤k≤n V ar(Yk)/s2
n =
n
2/12n
n(n+1)(2n+1)/72n → 0 which
implies that Feller’s condition is satisfied. To examine whether Lya￾pounov’s condition is satisfied, note that with δ = 1,
Pn
k=1
E|Yk − E(Yk)|
3
s
3/2
n
=
n
2
(n + 1)2
128n3/2
(72n)
3/2
(n(n + 1)(2n + 1))3/2 → 0
which implies that Lyapounov’s condition is satisfied. Lyapounov’s
condition implies Lindeberg’s condition and hence it is also satisfied.
Hence, CLT is valid for Sn =
Pn
k=1(Yk − E(Yk)).
Answers to the multiple choice questions, based on Chapter 10, are given
in Table 11.10.Bibliography
[1] Apostol T. (1967). Calculus, Vol I, second edition, John Wiley, New
York.
[2] Ash, R. B. (1970) Probability and Measure Theory, second edition, Aca￾demic Press, USA
[3] Athreya, K. B. and Lahiri, S. N. (2006). Measure Theory and Prob￾ability Theory, Springer, New York.
[4] Bhat, B. R. (2007). Modern Probability Theory, New Age International
Publishers, New Delhi.
[5] Billingsley, P. (1986). Probability and Measure, John Wiley, London.
[6] Breiman, L. (1968) Probability, Addison Wesley, London.
[7] Chow, Y. S. and Teicher, H. (1979). Probability Theory, Springer,
New York.
[8] Chung, K. L. (2001). A Course in Probability Theory, third edition,
Academic Press, London.
[9] Crawley, M. J. (2007). The R Book, John Wiley, London.
[10] Dalgaard, P. (2008). Introductory Statistics with R, second edition,
Springer, New York.
[11] Deshmukh, S. R. and Kulkarni, M. G. (2021). Asymptotic Statistical
Inference: A Basic Course Using R, Springer, New York.
[12] Grimmett, G. R. and Stirzaker, D. R. (1982) Probability and
Stochastic Processes. Clarendon Press, Oxford.
[13] Gut, A. (2005). Probability: A Graduate Course, Springer, New York.
[14] Johnson, N. L., Kemp, A. W. and Kotz, S. (2005). Univariate
Discrete Distributions, third edition, Wiley, New Jersey.
[15] Kumar, A. and Kumaresan, S.(2014) A Basic Course in Real Anal￾ysis, Chapman and Hall/CRC, USA.
[16] Loeve, M. (1977). Probability Theory I, fourth edition, Springer, New
York.
571572 Bibliography
[17] Purohit, S. G., Gore, S. D. and Deshmukh, S. R. (2008). Statistics
using R, second edition Narosa Publishing House, New Delhi.
[18] R Core Team (2019). R: A language and environment for statistical
computing, R Foundation for Statistical Computing, Vienna, Austria.
URL- https://www.R-project.org/.
[19] Rao, C. R. (1978). Linear Statistical Inference and its Applications,
Wiley, New York.
[20] Serfling, R. J. (1980). Approximation Theorems of Mathematical Statis￾tics, John Wiley, New York.
[21] Shao, J. (2003). Mathematical Statistics, second edition, Springer, New
York.
[22] Sivaprasad, M. and Deshmukh, S. R. (2003). Introduction to
Stochastic Processes Using R, Springer, New York.
[23] Stoyanov, J. (1996). Counter Examples in Probability, John Wiley, New
York.
[24] van der Vaart, A. (1998). Asymptotic Statistics, Cambridge University
Press, Cambridge.
[25] Verzani, J. (2005). Using R for Introductory Statistics, Chapman and
Hall/CRC Press, New York.Index
almost sure Cauchy convergence, 269
almost sure convergence, 99, 254,
257, 262, 264, 266, 271, 278,
314, 358, 421, 528, 533, 541,
552
basic inequality, 209, 315
Bernoulli SLLN, 419, 421
Bernoulli WLLN, 409
binomial distribution, 321, 323, 351
Boole’s inequality, 53
Borel field, 42, 45, 94
Borel field in k dimensions, 46
Borel function, 81, 82, 91, 118, 122,
178, 230, 241, 496, 500, 525
Borel set, 42
Borel zero-one law, 274, 276, 529
Borel-Cantelli lemma, 271, 272, 281,
410, 529, 552
bounded in probability, 186, 188,
308, 335, 545, 550, 555, 565
Cauchy convergence in r-th mean,
368
Cauchy convergence in probability,
314
Cauchy convergence in quadratic
mean, 396
Cauchy distribution, 291, 539, 540,
558
Cauchy-Schwarz inequality, 206
characteristic function, 185, 189, 236,
343, 517, 526, 543, 559
characteristic function of a random
vector, 202
Chebyshev’s inequality, 209, 407,
409, 421, 556, 561
Chebyshev’s WLLN, 408
CLT, 342, 406, 430, 435, 439, 442,
463, 561, 563
complete convergence, 265
complex valued random variable, 93,
184
continuity theorem for a probability
measure, 50, 502
continuity theorem for characteristic
functions, 344
continuous distribution function, 144
continuous mapping theorem, 335,
544, 547, 564
convergence in r-th mean, 256, 353,
358
convergence in distribution, 255
convergence in law, 255, 316, 318,
323, 342, 352, 533, 542, 547,
551
convergence in probability, 254, 278,
289, 294, 300, 303, 310, 314,
323, 329, 356, 417, 533
convergence in quadratic mean, 256,
294, 355
convergence of sequence of moments,
295
convergence with probability 1, 254
convergent sequence of subsets, 18
countable intersection, 9, 16
countable set, 140
countable union, 9, 12
Cramer’s theorem, 336
De Morgan’s law, 10
delta method, 340, 341, 448
discrete distribution function, 144
573574 Index
distribution function, 135, 136, 138,
503, 511
distribution function of a random
vector, 158
equivalent random variables, 265,
293, 330, 353, 528
event, 46
expectation, 233
expectation of a non-negative
random variable, 171
expectation of a random vector, 184
expectation of a simple random
variable, 167
expectation of an arbitrary random
variable, 172
Fatou’s lemma, 393, 397
Feller’s condition, 452, 453, 466, 567
field, 34, 488
Holder’s inequality, 205, 550
independence of k events, 225
independence of random variables,
227
independence of two events, 222
independent random vectors, 239
induced probability measure, 122
induced probability space, 122
induced sigma field, 79, 227
infinite dimensional random vector,
94
integrable random variable, 172, 176,
392, 509, 554, 555
inverse image of a collection of sets,
73
inverse image of a set, 68, 71
inversion theorem, 191, 198, 237
Jensen’s inequality, 207, 357
Jordan decomposition theorem, 145,
332
Khintchine’s WLLN, 410, 411, 415,
444
Kolmogorov zero-one law, 242, 280
Kolmogorov’s SLLN, 410, 422
Lebesgue dominated almost sure
convergence theorem, 395,
555
Lebesgue dominated probability
convergence theorem, 397,
400, 554, 555
limit infimum of a sequence of sets,
11
limit of a non-monotone sequence of
sets, 20
limit of a non-decreasing sequence of
sets, 12, 13
limit of a non-increasing sequence of
sets, 14
limit of a sequence of random
variables, 98
limit of a sequence of sets, 11
limit supremum of a sequence of sets,
271
Lindeberg’s condition, 451–453, 466,
567
Lindeberg-Feller CLT, 453, 459, 461,
467
Lindeberg-Levy CLT, 431, 433, 442,
444, 459, 567
Lyapounov’s CLT, 459, 461, 569
Lyapounov’s condition, 451, 453,
561, 567
Lyapounov’s inequality, 206
Markov inequality, 209
minimal sigma field, 41, 43, 75, 488,
490, 497
Minkowski’s inequality, 207, 357
moment inequalities, 203
monotone class, 47
monotone convergence theorem, 387,
388, 390, 393
monotone field, 47
monotone sequence of sets, 10
multivariate CLT, 447, 449
non-decreasing sequence of sets, 10Index 575
non-increasing sequence of sets, 10,
17
point of continuity, 325
point of discontinuity of a
distribution function, 139,
316
point of increase of a distribution
function, 143, 503
point-wise convergence of a sequence
of random variables, 99,
101, 253
Poisson distribution, 321, 322, 351
population quantiles, 301
probability density function, 144
probability distribution of X, 122
probability mass function, 144
probability measure, 48, 222, 230,
492, 493
probability space, 48
R software, 2, 5, 8, 257
random sum CLT, 445
random variable, 69, 78
random vector, 84, 87, 90, 499
ring, 46
sample quantile, 301, 302
sequence of independent events, 226,
274, 520, 529, 530
sequence of independent random
variables, 239
sequence of random variables, 97
set of points of continuities of a
distribution function, 316
set of points of continuity of a
distribution function, 140
sigma additivity, 49
sigma field, 35, 37, 74, 488, 489, 498
sigma ring, 46
simple random variable, 106, 109,
112, 499, 516
SLLN, 406, 419, 425, 430
Slutsky’s theorem, 336, 340, 342,
439, 442
sub sigma additivity, 53
tail event, 104, 243
tail sigma field, 104, 242
Toeplitz’ lemma, 411, 529
uniqueness theorem of a
characteristic function, 195,
345, 346
weak convergence, 352
WLLN, 406–408, 416, 418, 430, 556,
557, 565
