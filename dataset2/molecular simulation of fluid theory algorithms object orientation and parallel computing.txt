Molecular Simulation of Fluids
Theory, Algorithms, Object-Orientation, and Parallel ComputingMolecular Simulation
of Fluids
Theory, Algorithms, Object-Orientation, and
Parallel Computing
Second Edition
Richard J. Sadus
Department of Computing Technologies, Swinburne University of
Technology, Wurundjeri Country, AustraliaElsevier
Radarweg 29, PO Box 211, 1000 AE Amsterdam, Netherlands
The Boulevard, Langford Lane, Kidlington, Oxford OX5 1GB, United Kingdom
50 Hampshire Street, 5th Floor, Cambridge, MA 02139, United States
Copyright © 2024 Elsevier B.V. All rights reserved.
No part of this publication may be reproduced or transmitted in any form or by any means,
electronic or mechanical, including photocopying, recording, or any information storage and
retrieval system, without permission in writing from the publisher. Details on how to seek
permission, further information about the Publisher’s permissions policies and our
arrangements with organizations such as the Copyright Clearance Center and the Copyright
Licensing Agency, can be found at our website: www.elsevier.com/permissions.
This book and the individual contributions contained in it are protected under copyright by the
Publisher (other than as may be noted herein).
Notices
Knowledge and best practice in this field are constantly changing. As new research and
experience broaden our understanding, changes in research methods, professional practices, or
medical treatment may become necessary.
Practitioners and researchers must always rely on their own experience and knowledge in
evaluating and using any information, methods, compounds, or experiments described herein.
In using such information or methods they should be mindful of their own safety and the safety
of others, including parties for whom they have a professional responsibility.
To the fullest extent of the law, neither the Publisher nor the authors, contributors, or editors,
assume any liability for any injury and/or damage to persons or property as a matter of
products liability, negligence or otherwise, or from any use or operation of any methods,
products, instructions, or ideas contained in the material herein.
ISBN: 978-0-323-85398-9
For Information on all Elsevier publications
visit our website at https://www.elsevier.com/books-and-journals
Publisher: Candice Janco
Acquisitions Editor: Amy Shapiro
Editorial Project Manager: Leticia M. Lima
Production Project Manager: Kumar Anbazhagan
Cover Designer: Miles Hitchen
Typeset by MPS Limited, Chennai, IndiaTo AngelicaThis page intentionally left blankContents
Preface to the second edition xv
Preface to the first edition xvii
1. Introduction 1
1.1 What is molecular simulation? 1
1.1.1 The MC method 4
1.1.2 MD 5
1.2 Progress in molecular simulation 6
1.2.1 Early work on hard spheres and atoms 6
1.2.2 Small nonpolar molecules 7
1.2.3 Polar molecules and ions 7
1.2.4 Chain molecules and polymers 8
1.2.5 Ensembles for molecular simulation 9
1.2.6 Phase equilibria 9
1.2.7 Interatomic interactions 11
1.2.8 Many-body interactions 11
1.2.9 Nonequilibrium MD simulation 12
1.2.10 Molecular simulation and object orientation 12
1.2.11 Parallel computing 12
References 13
2. Ensembles, thermodynamic averages,
and particle dynamics 19
2.1 Statistical mechanics, ensembles, and averaging 20
2.1.1 Ensembles 20
2.1.2 Simple thermodynamic averages 22
2.2 Properties from fluctuations 24
2.2.1 Thermodynamic properties 25
2.2.2 Transport coefficients 28
2.2.3 Molecular simulation and choice of ensemble 29
2.3 Alternative methods for thermodynamic properties 30
2.3.1 MD NVE ensemble 30
2.3.2 MC NVT ensemble 32
2.3.3 MC NpT ensemble 35
2.3.4 MC μVT ensemble 36
2.3.5 MC NpH ensemble 37
vii2.4 Particle dynamics 39
2.4.1 Motion of unconstrained particles 39
2.4.2 Motion of constrained particles 39
2.4.3 The Liouville equation 46
2.4.4 The virial theorem 47
2.5 Summary 48
References 48
3. Intermolecular pair potentials and force fields 51
3.1 Calculation of the potential energy 52
3.1.1 Use of notation 54
3.2 Intermolecular forces 54
3.2.1 Types of intermolecular forces 54
3.2.2 Quantum theory of intermolecular potentials 55
3.3 Potentials with a hard sphere contribution 56
3.3.1 The HS potential 57
3.3.2 Non-HS repulsive potentials 58
3.3.3 HSA potentials 59
3.4 Soft sphere potentials 62
3.5 Fully interpenetrable potentials 63
3.5.1 Gaussian core model potential 63
3.5.2 Double Gaussian core model potential 64
3.6 Effective pairwise potentials for atoms and simple molecules 64
3.6.1 Repulsion 1 dispersion pair potentials 64
3.6.2 General refinement of repulsion and dispersion models 74
3.6.3 Shifted-force potentials 75
3.6.4 SR potentials 75
3.7 Contributions to molecular interactions 77
3.7.1 Intermolecular ionic and polar potentials 77
3.7.2 Intermolecular hydrogen bond potentials 80
3.7.3 Intramolecular bond potentials 81
3.7.4 Intramolecular angle-bending potentials 82
3.7.5 Intramolecular out-of-plane bending potentials 82
3.7.6 Intramolecular torsional potentials 83
3.7.7 Intramolecular cross-terms 83
3.8 Simple atom-based pairwise potentials for molecules 84
3.8.1 Stockmayer potential 84
3.8.2 SpurlingMason potential 85
3.8.3 Restricted primitive model 85
3.8.4 FumiTosi potential 86
3.9 Extension to molecules 86
3.9.1 Nonbonded interactions in molecules 86
3.9.2 Adding nonbonded interactions: the WCA 1 finitely
extensible nonlinear elastic potential 87
3.10 Pairwise force fields from molecular mechanics 88
3.10.1 Optimized force fields 89
3.10.2 Comparison of force fields and future improvements 95
viii Contents3.11 Case study: Models for water 97
3.11.1 Rigid models 97
3.11.2 Flexible models 100
3.11.3 Polarizable models 100
3.12 Application to mixtures 101
3.13 Summary 102
References 102
4. Ab initio, two-body and three-body intermolecular
potentials 117
4.1 Ab initio calculations 118
4.1.1 HartreeFock method 119
4.1.2 Density functional theory 120
4.1.3 The CarParrinello method 122
4.2 Two-body atomic potentials 123
4.2.1 Empirical potentials 123
4.2.2 Ab initio potentials 125
4.3 Three-body atomic potentials 130
4.3.1 Three-body dispersion 131
4.3.2 The triple-dipole term and the AxilrodTellerMuto¯
potential 132
4.3.3 Density-dependent effective three-body potential 135
4.3.4 Multipolar contributions beyond the triple-dipole term 136
4.3.5 Three-body repulsion 139
4.3.6 Three-body dispersion versus three-body repulsion 140
4.4 Four- and higher-body atomic interactions 143
4.5 Potentials for molecules 144
4.5.1 Two-body ab initio molecular potentials 144
4.5.2 Three-body molecular potentials 147
4.5.3 Ab initio potentials for combinations of molecules 151
4.6 Case study: Augmenting ab initio potentials for
fluid properties 152
4.6.1 Systematic improvement of water potentials 152
4.6.2 Efficient three-body calculations 153
4.7 Summary 155
References 155
5. Calculating molecular interactions 165
5.1 Calculation of short-range interactions 166
5.1.1 Naive energy and force calculations 166
5.1.2 Periodic boundary conditions and minimum image
convention 167
5.1.3 Long-range corrections to periodic
boundary calculations 169
5.1.4 Neighbor list 170
Contents ix5.1.5 Linked cells 174
5.1.6 Look-up table 178
5.1.7 Comparison of computational efficiency 179
5.2 Calculation of long-range interactions 180
5.2.1 The Ewald sum 181
5.2.2 The Wolf approximation of the Ewald sum 186
5.2.3 The reaction field method 187
5.2.4 Particle-particle and particle-mesh methods 191
5.2.5 Tree-based methods 197
5.2.6 Comparison of computational efficiency 205
5.3 Summary 206
References 206
6. Monte Carlo simulation 215
6.1 Basic concepts 216
6.1.1 Background 216
6.1.2 Metropolis sampling and Markov chains 217
6.2 Application to molecules 219
6.2.1 Rigid molecules 219
6.2.2 Small flexible molecules 220
6.2.3 Polymers 220
6.3 Advanced techniques 223
6.3.1 Configurational bias MC 224
6.3.2 Cluster moves 230
6.4 Path integral Monte Carlo 233
6.5 Summary 235
References 235
7. Integrators for molecular dynamics 243
7.1 Integrating the equations of motion 244
7.2 Gear predictorcorrector methods 244
7.2.1 The basic Gear algorithm 245
7.2.2 Other representations of the Gear algorithm 249
7.3 Verlet predictor methods 250
7.3.1 Original Verlet algorithm 251
7.3.2 Leap-frog Verlet algorithm 253
7.3.3 Velocity-Verlet algorithm 254
7.3.4 Beeman modification 256
7.4 RungeKutta integration 258
7.5 Comparison of integrators 261
7.6 Integrators for molecules 262
7.6.1 Small molecules 262
7.6.2 Large molecules 263
7.7 Summary 279
References 280
x Contents8. Nonequilibrium molecular dynamics 285
8.1 An example NEMD algorithm 286
8.2 Synthetic NEMD algorithms 288
8.2.1 Shear viscosity 289
8.2.2 Self-diffusion 298
8.2.3 Thermal conductivity 299
8.3 Application of NEMD algorithms to molecules 300
8.4 Application of NEMD algorithms to mixtures 301
8.5 Comparison with EMD 301
8.6 Summary 302
References 303
9. Molecular simulation of ensembles 309
9.1 Monte Carlo 310
9.1.1 Canonical (NVT) ensemble 310
9.1.2 IsobaricIsothermal (NpT) ensemble 314
9.1.3 Grand canonical (μVT) ensemble 319
9.1.4 Microcanonical (NVE) ensemble 322
9.2 Molecular dynamics 326
9.2.1 Microcanonical (NVE) ensemble 326
9.2.2 Canonical (NVT) ensemble 330
9.2.3 Isobaricisoenthalpic (NpH) ensemble 339
9.2.4 Isothermalisobaric (NpT) ensemble 342
9.2.5 Grand canonical (μVT) ensemble 346
9.3 Summary 353
References 353
10. Molecular simulation of phase equilibria 359
10.1 Calculating the chemical potential 360
10.2 Gibbs ensemble Monte Carlo 362
10.3 MD Gibbs ensemble 367
10.3.1 LoPalmer method 367
10.3.2 KotelyanskiiHentschke method 370
10.3.3 BaranyaiCummings method 371
10.4 NpT 1 test particle 373
10.5 GibbsDuhem integration 373
10.6 Thermodynamic scaling 380
10.6.1 Temperature and density MC 380
10.6.2 Thermodynamic-scaling Gibbs ensemble MC 381
10.7 Pseudo-ensemble methods 382
10.8 Histogram reweighting algorithms 384
10.8.1 Grand canonical MC 385
10.8.2 Isothermalisobaric MC 386
10.8.3 GEMC 386
10.9 Finite-size scaling 387
Contents xi10.10 Empirically based simulation algorithms 387
10.10.1 Synthetic method 388
10.10.2 Combined NEMD/EMD method for SLE 390
10.11 Accurate determination of SLE 392
10.12 Summary 394
References 395
11. Molecular simulation and object-orientation 405
11.1 Fundamental concepts of OO 407
11.1.1 Classes and objects 407
11.1.2 Abstraction and encapsulation 408
11.1.3 Methods and message passing 408
11.1.4 Inheritance 409
11.1.5 Aggregation 410
11.1.6 Association 412
11.1.7 Polymorphism 413
11.2 Case study: application of OO to the microcanonical MD
simulation of Lennard-Jones atoms 414
11.2.1 OOA and OOD 414
11.2.2 Detailed class description 420
11.2.3 Object-oriented programming in C11 433
11.3 Case study: application of object orientation to the
microcanonical MC simulation of Lennard-Jones atoms 474
11.3.1 OOA and OOD 474
11.3.2 Detailed class description 479
11.3.3 OOP in C11 489
11.4 Case study: combined MD and MC program for
Lennard-Jones atoms in the microcanonical ensemble 517
11.4.1 OOA 517
11.4.2 OOP in C11 518
11.5 Case study: extensions 521
11.5.1 Other ensembles 522
11.5.2 Other ensembles and other potentials 522
11.5.3 Other ensembles, other potentials, and molecules 523
11.6 Summary 524
References 524
12. GPU and CPU parallel molecular simulation
with CUDA and MPI 527
12.1 Basic GPU implementations with CUDA 528
12.1.1 Defining a Kernel 529
12.1.2 Allocating and copying memory 530
12.1.3 Launching the kernel 531
12.1.4 Reduction 531
12.1.5 General GPU algorithm 533
xii Contents12.1.6 Compiling molecular simulation codes using CUDA 534
12.2 Case study: CUDA implementation of MD code
(/mdCU_Ver2.0) 534
12.2.1 Key variable additions 535
12.2.2 The force kernel 537
12.2.3 Launching the force kernel 540
12.2.4 Changes to the MD integrator 542
12.3 Case study: CUDA implementation of MC code
(/mcCU_Ver2.0) 542
12.3.1 Energy kernels 543
12.3.2 Launching the energy kernels 545
12.4 Parallel programming with MPI 546
12.4.1 General MPI procedure 547
12.5 Case study: MPI implementation of MD code
(/mdMPI_Ver2.0) 548
12.5.1 Key variable additions 549
12.5.2 Changes to mainMD.cpp 549
12.5.3 Changes to ljForceMD.cpp 550
12.5.4 Changes to the MD integrator 553
12.6 Case study: MPI implementation of MC code
(/mcMPI_Ver2.0) 553
12.6.1 Changes to mainMC.cpp 553
12.6.2 Changes to ljEnergyMC.cpp 554
12.7 Case study: relative performance of MD and MC MPI and
GPU codes 556
12.7.1 Performance of MD and MC GPU codes 556
12.7.2 Performance of the MD MPI code 558
12.8 Summary 559
References 559
Appendix 1: Software user’s guide 561
Appendix 2: List of algorithms 567
Appendix 3: Notation 571
Index 577
Contents xiiiThis page intentionally left blankPreface to the second edition
The intervening years since the publication of the first edition of this book
have witnessed an enormous growth in popularity of molecular simulation. It
is now arguably the preferred computational approach for both the evaluation
of molecular properties and the prediction of macroscopic properties. The
areas of theory, algorithms, and object-orientations covered by the first edi￾tion have greatly expanded. Examples include advances in computational
chemistry, resulting in highly accurate two-body ab initio potentials; new
methods for simulating solid-liquid equilibria; and the widespread use of
object-orientation for simulation. The latter is particularly significant, as it
has permitted the continuous development of sophisticated molecular soft￾ware that can be used to tackle highly complicated situations involving pro￾teins and other large macromolecules.
The emergence of parallel computing is the most important contributor to
the growing success of molecular simulation that was not covered by the first
edition. Initially, this simply involved the use of multiple central processing
units (CPUs) but its impact has been supercharged by the introduction of gra￾phics processing units (GPUs). The combination of object-orientation and
parallel computing provides an important route for the development of
adaptable software for future computationally challenges.
The second edition reflects advances made in key areas of molecular sim￾ulation. Each chapter has been updated, providing details of new algorithms
and theory, while maintaining most of the original content that still remains
both relevant and useful. Readers have often commented that the algorithms
in pseudo-code from the first edition could be easily transformed into work￾ing programs. This feature has been retained and improved by adopting
greater modularization via the use of subalgorithms. Case studies have been
added to provide detailed explanations of some challenging aspects. The
C11 code provided in Chapter 11 has also been updated.
The most significant changes are the addition of two new chapters.
Chapter 4 covers the use of ab initio potentials and two-and three-body inter￾actions. Advances in theory mean that the interactions between both atoms
and molecules can be reliably obtained from first principles with increasingly
less reliance on empirical models. Chapter 12 covers parallel computing
using both multiple CPUs and GPUs. It is written specifically to assist read￾ers who would like to quickly take advantage of parallel computing, perhaps
xvby modifying existing serial code. Therefore it is a starting point for further
learning rather than a comprehensive examination of the topic. It may also
be useful for readers who require an improved understanding of some of the
key underlying technical aspects of large scale parallel-enabled molecular
simulation software packages. Using detailed case studies, Chapter 12 shows
how the C11 codes from Chapter 11 can be simply modified to execute in
parallel on both multiple CPUs and GPUs. MPI is used for the multi-CPU
code. CUDA integrates very well with C11 code and facilitates the near￾seamless transition to GPUs. The codes are available at the book’s website
(https://www.elsevier.com/books-and-journals/book-companion/9780323853989)
that is maintained by the publisher.
I thank Ulrich K. Deiters, Karl. P. Travis, and Billy D. Todd for reading
drafts of various chapters and providing both valuable comments and
insights. I also thank Angelica M. Vecchio-Sadus for proofreading. The
molecular simulations were conducted on the Swinburne University super￾computer (OzSTAR), which is located on the traditional lands of the
Wurundjeri people. It is illustrated on the front cover.
Richard J. Sadus
August, 2023
xvi Preface to the second editionPreface to the first edition
Molecular simulation is being used increasingly to study a widening range of
both molecular systems and fluid phenomena. Today, the goal of many simu￾lators is to study complicated molecules such as proteins, whereas attention
was formerly confined almost exclusively to simple atoms and molecules.
Similarly, the simulation of phase equilibria is now common, whereas just
over a decade ago, it was a difficult and rare undertaking. The impetus for
the increasing use of molecular simulation can be attributed to many factors
such as improvements in theory, algorithms, and computer hardware. These
new developments have generated enormous growth in the simulation litera￾ture. A simple search on the keywords “Monte Carlo” and “molecular
dynamics” in any journal database is likely to yield thousands of entries for
the past five years alone. An aim of this book is to examine some of the
important aspects of recent progress in molecular simulation.
The other important aims of this book are reflected in the title. The topic
covered by the book is the molecular simulation of fluids which encompasses
both Monte Carlo and molecular dynamics methods. Although the principles
behind these two simulation methods are quite different, they are often com￾plementary rather than competing approaches. The practice of molecular
simulation involves three overlapping aspects. First, the theoretical basis of
molecular simulation is underpinned by the fundamental concepts of statisti￾cal mechanics and particle dynamics. Second, informed by theory, algo￾rithms are developed to calculate the properties of fluids. Third, theory and
algorithms are “brought to life” on a computer via a simulation program.
There are many simulation algorithms in the literature with varying levels
of usage. Some algorithms such as the “leap-frog” algorithm for molecular
dynamics are well known and used widely. There are also algorithms at
intermediate stage of usage, and many other potentially useful algorithms are
relatively “new” and as such, they are not known widely. In this book, we
have opted to present a mixture of new, intermediate, and well-established
algorithms. However, the mix is biased deliberately to favor new algorithms
many of which have not yet been used widely or tested exhaustively. In
many cases, to facilitate implementation, the algorithms are presented in
pseudo code.
Historically, the implementation of simulation algorithms has been
achieved using a structured programming approach typified by programming
xviilanguages such as C and FORTRAN. In a deliberate break with tradition,
there are few references in this book to either FORTRAN or C code. Instead,
attention is focused on the concepts of object-oriented analysis, design, and
programming. The value of object-orientation to molecular simulation
remains largely untried; however, it offers potential benefits particularly for
the development of simulation code involving complicated molecules such
as large polymers and proteins. Simulation code is predominantly developed
and used by physicists, chemists, and chemical engineers and not by com￾puter scientists. However, advances in computer science such as object￾orientation can be of potential benefit to molecular simulation practitioners.
This book is in part, an effort to bridge this gap between practitioners and
advances in computer science. Sample object-oriented simulation code writ￾ten in C11 is included on the accompanying disk.
This book has benefited from the contributions of others. I thank Ross
Daws for his valuable assistance with the object-oriented analysis and
Gianluca Marcelli for reading the manuscript carefully. Thanks are also due
to Peter Cummings, Denis Evans, and Rolf Lustig for access to their work
prior to publication. Most importantly, I thank my wife Angelica for contrib￾uting her good judgment to many aspects of both the appearance and con￾tents of the book.
Richard J. Sadus
January, 1999
xviii Preface to the first editionChapter 1
Introduction
This chapter introduces the concept of molecular simulation and provides a
brief survey of developments in the field. Many of the topics introduced here
are examined in greater detail in subsequent chapters. Various aspects of
molecular simulation have also been reviewed elsewhere (Ciccotti et al.,
1987; Haile, 1992; Allen and Tildesley, 1993; Heyes, 1998; Leach, 2001;
Frenkel and Smit, 2023; Rapaport, 2004; Allen and Quigley, 2013; Allen
and Tildesley, 2017; Raabe, 2017). Battimelli et al. (2020) have reported a
historical narrative for some aspects of the development of molecular simula￾tion in the twentieth century.
1.1 What is molecular simulation?
Molecular simulation is a generic term encompassing both Monte Carlo
(MC) and molecular dynamics (MD) computing methods. The primary moti￾vation for molecular simulation is to provide exact results for statistical
mechanical problems in preference to approximate solutions. The feature
that distinguishes molecular simulation from other computing methods and
approximations is that the molecular coordinates of the system are evolved
in accordance with a rigorous calculation of intermolecular energies or
forces.1 Molecular simulation can be aptly described as a computational sta￾tistical mechanics. It allows us to determine macroscopic properties by eval￾uating exactly a theoretical model of molecular behavior using a computer
program. The keyword in the earlier description is “exactly.” The results of a
molecular simulation are determined solely by the nature of the theoretical
model used. Consequently, comparison of simulation results with experimen￾tal data is an unambiguous test of the accuracy of the model. Discrepancies
between accurate experimental measurements and molecular simulation data
can be attributed unambiguously to the failure of the model to represent
molecular behavior.
The history of molecular simulation largely parallels the history of the
digital computer. However, it is interesting to reflect that some aspects of
1. Some useful complementary methods (Klamt, 2005) that do not involve the evolution of coor￾dinates are not considered here.
1 Molecular Simulation of Fluids. DOI: https://doi.org/10.1016/B978-0-323-85398-9.00002-2
© 2024 Elsevier B.V. All rights reserved.what we would now recognize as molecular simulation predate the comput￾ing era, when the term “molecular dynamics” simply referred to the dynam￾ical behavior of molecules. For example, Lord Kelvin (1904) offers the
following description of an experiment to obtain the distribution of velocities
involved in molecular collision.
“For our present problem we require two lotteries to find the influential condi￾tions at each instant, when Q enters P’s cage—Lottery I. for the velocity (v) of
Q at impact: lottery II. for the phase of P’s motion. For lottery I. (after trying
837 small squares of papers with velocities written on them and mixed in a
bowl, and finding the plan unsatisfactory) we took nine stiff cards, numbered
1, 2 ... 9, of size of ordinary playing-cards with round corners, with one hun￾dred numbers written on each in ten lines of ten numbers. The velocities on
each card are shown on the following table. The number of times each velocity
occurs was chosen to fulfill as nearly as may be the Maxwellian law ...”
This quaint description includes aspects such as obtaining a Maxwell
Boltzmann velocity distribution and random sampling that are routinely per￾formed by computer-based MD and MC molecular simulations, respectively.
The first computer-era molecular simulation of a liquid was performed by
Metropolis et al. (1953) on the MANIAC computer at Los Alamos. Metropolis
et al. introduced the Monte Carlo method. During a MC simulation, different
trial configurations are generated randomly. The intermolecular interactions in
the trial configuration are evaluated and probabilities are used to either accept
or reject the change. Later, Alder and Wainwright (1957, 1959) introduced
the molecular dynamics (MD) method (Chapter 6). In a MD simulation, the
equations of motion (Chapter 2) for the system of molecules are solved. The
molecular coordinates and momenta change according to the intermolecular
forces experienced by the individual molecules. As the name implies, MD
enables us to obtain the dynamic properties of the system. Unlike MC simula￾tions, MD is totally deterministic and chance plays no role.2 Another important
distinction between MC and MD methods is that MD uses intermolecular
forces to evolve the system, whereas MC simulation involves primarily the
calculation of changes in intermolecular energy.
The practice of molecular simulation has continued to benefit enormously
from subsequent improvements in the evolution of computer hardware
(Fig. 1.1) and software (Chapters 11 and 12). Today, researchers in many
disciplines use both simulation techniques widely. The popularity of molecu￾lar simulation as a research tool is evident from the many thousands of
entries for the keywords “Monte Carlo” and “molecular dynamics” found in
The Web of Science and Scopus databases for each successive year. The
choice between the two alternatives depends often on the type of property
2. Sometimes it is convenient to combine both approaches resulting in a hybrid-MD algorithm.
2 Molecular Simulation of Fluidsbeing investigated. For example, a MD strategy is required to obtain time￾dependent dynamic properties of the system, whereas the MC method can be
used in situations where the systems have no intrinsic dynamics. Either MC
or MD can be used for equilibrium properties.
Molecular simulation is increasingly providing valuable insights into fluid
properties. An example of the value of molecular simulation is illustrated by
its role in the correct interpretation of neutron scattering data for water
(Chialvo et al., 1998). Postorino et al. (1993) reported neutron scattering data
for supercritical water, which indicated the absence of hydrogen bonding in
contradiction to molecular simulation studies that predicted hydrogen bonding.
FIGURE 1.1 Computers then and now. The CDC 6600 computer (top, Science Museum,
London) with its “spaghetti wiring” was the workhorse for many computational tasks in the
1960s. In contrast, today’s supercomputers (bottom, OzSTAR Swinburne University of
Technology) are compact racks of thousands of CPUs and GPUs (Chapter 12).
Introduction Chapter | 1 3Based on their analysis, Postorino et al. (1993) concluded that the models of
water used in the MD studies were inadequate. However, further careful
molecular simulation studies (Chialvo and Cummings, 1994) with revised
models for water continued to show the presence of hydrogen bonding. It
became apparent subsequently (Soper et al., 1997) that the original neutron
scattering data had been analyzed incorrectly. The revised analysis (Soper
et al., 1997) showed the presence of hydrogen bonding as predicted by molec￾ular simulation. Furthermore, there was good qualitative agreement between
the revised analysis and molecular simulation predictions. Molecular simula￾tion can also be used increasingly to resolve conflicts between experimental
data for difficult-to-measure properties such as the critical densities of
thermally unstable high-molecular-weight alkanes (Siepmann et al., 1993).
Molecular simulations can be used to make genuine predictions from first
principles that are either close to or exceed experimental accuracy (Deiters
and Sadus, 2022a,b, 2023).
1.1.1 The MC method
The MC method is a stochastic strategy that relies on probabilities, which
explains the association with the eponymous casino in the principality of
Monaco (Fig. 1.2). To simulate fluids, transitions between different states or
configurations are achieved by (1) generating a trial configuration randomly;
FIGURE 1.2 Casino de Monte-Carlo on December 29, 2013. In the absence of certainty, there
is a nonzero probability (chance) that the white substance in the foreground could be real snow.
4 Molecular Simulation of Fluids(2) evaluating an “acceptance criterion” by calculating the change in energy
and other properties in the trial configuration; and (3) comparing the accep￾tance criterion to a random number and either accepting or rejecting the trial
configuration. It is important to realize that not all states will make a signifi￾cant contribution to the configurational properties of the system. To deter￾mine accurately the properties of the system in the finite time available for
the simulation, it is important to sample those states that make the most sig￾nificant contributions. This is achieved by generating a Markov chain
(Chapters 6 and 9), which is a sequence of trails in which the outcome of
successive trails depends only on the immediate predecessor. In a Markov
chain, a new state will only be accepted if it is more “favorable” than the
existing state. In the context of a simulation using an ensemble, this usually
means that the new trial state is lower in energy. The MC algorithm is sum￾marized by Algorithm 1.1.
In the MC process, a new configuration is obtained typically by displa￾cing, exchanging, removing, or adding a molecule. Probabilities are also
often involved in determining the nature and extent of the attempted move.
The exact nature of the transition probability depends on the ensemble cho￾sen (Chapter 9), but it always involves evaluating the energy of the new con￾figuration and comparing it with the energy of the existing (old) state.
Notice, that if the attempted change is rejected, then the old state is counted
as the new state. Details of MC simulations are examined in Chapter 6.
ALGORITHM 1.1 General outline of a MC process.
1.1.2 MD
In contrast to the MC method, which relies on transition probabilities, MD
solves (Chapters 79) the equations of motion of the molecules to generate
Introduction Chapter | 1 5new configurations. Consequently, MD simulations can be used to obtain
time-dependent properties of the system. A general MD algorithm is pre￾sented in Algorithm 1.2.
ALGORITHM 1.2 General outline of a MD process.
Algorithm 1.2 hides a considerable degree of complexity. There are several
possible algorithms for solving the equations of motions, which are examined
in detail in Chapter 7. The practical implementation of MC and MD methods
have many features in common, which are apparent from the considerations
discussed in Chapters 35.
1.2 Progress in molecular simulation
1.2.1 Early work on hard spheres and atoms
The very early work on molecular simulation was confined to either evaluating
the properties of hard spheres (HS) or using the Lennard-Jones (LJ) potential
(Chapter 3). The LJ potential remains the most widely used intermolecular
potential for molecular simulation. Metropolis et al. (1953) showed how the
MC method could be used to calculate the properties of two-dimensional rigid
spheres. Most significantly, they introduced the concepts of importance sam￾pling (Chapter 6) and periodic boundary conditions (Chapter 5). Later, Wood
and Parker (1957) reported MC simulations using the LJ potential. They found
evidence for a solidfluid phase transition, which was later confirmed by
Hansen and Verlet (1969). Their paper also discusses the minimum image con￾vention (Chapter 5) to account for the truncation of the potential required by
the periodic boundary conditions.
Alder and Wainwright (1957) reported the first MD simulation for HS.
Their data was found to be in good agreement with MC results (Wood and
Jacobson, 1957), thereby demonstrating the equivalence of the two molecular
simulation methods. The first MD simulation of a LJ fluid was reported by
Rahman (1964). Verlet (1967) also performed MD simulations for the LJ
potential using an improved integration scheme (Chapter 7) for the equations
6 Molecular Simulation of Fluidsof motion and introducing the concept of a neighbor list (Chapter 5) to
reduce computation time. Verlet’s algorithm and subsequent modifications
(Chapter 7) are widely used today. The predictorcorrector integration
method (Chapter 7) proposed by Gear (1971) is also used extensively.
1.2.2 Small nonpolar molecules
Small diatomic or polyatomic molecules represent a natural extension of the appli￾cation of molecular simulation. Harp and Berne (1968) applied the MD method
for diatomic molecules. It is common to consider the intermolecular interactions
between two diatomic molecules via a sitesite approximation (Singer et al.,
1977), in which the interaction sites correspond to the position of the nuclei of the
real molecules Consequently, diatomic molecules such as nitrogen can be depicted
as two LJ atoms separated by a fixed bond length. This approach was used by
Cheung and Powles (1975) to model the nitrogen molecule.
The MD simulation of polyatomic molecules requires us to consider how
to account for vibrational and rotational degrees of freedom in the integration
of the equations of motion (Chapter 2). In most cases, it is safe to ignore
molecular vibration and treat the molecule as a rigid body. The kinematics
of rigid bodies is well developed (Goldstein et al., 2002); however, the time
evolution of the Euler angles results in an awkward singularity. For small
molecules, this problem is commonly avoided by using the quaternions
approach proposed by Evans and Murad (1977), whereas the method of con￾straint (Ciccotti et al., 1982) is particularly advantageous for larger, more
flexible molecules. In contrast, MC simulations of polyatomic molecules
address the issue of rotation by proposing special moves (Chapter 6).
1.2.3 Polar molecules and ions
In contrast to interactions between nonpolar molecules, interactions between dipo￾lar molecules or ions are long-range. A long-range force is defined as one which
falls off no faster than r
2d
, where r is the intermolecular separation and d is the
dimensionality of the system. Typically, ionion and dipoledipole potentials are
proportional to r
21 and r
23
, respectively. Consequently, the effect of either inter￾action extends well past half the length of the simulation box, and special techni￾ques (Chapter 5) are required to incorporate these long-range forces. Rigorous
formulas are available (Chapter 3) to determine the contribution of various nonpo￾lar interactions, but the most commonly used approach is to assign partial charges
to the constituent atoms and evaluate the Coulombic contributions.
For ionic systems, the Coulombic energies and forces are calculated
commonly using either an Ewald sum (Nose´ and Klein, 1983) or a reaction
field (Barker and Watts, 1969). A particleparticle and particlemesh
(PPPM) algorithm (Eastwood et al., 1980) is also effective. Fast multipole
methods (FMM) have also been developed (Greengard and Rokhlin, 1987),
Introduction Chapter | 1 7which are potentially useful in simulations involving thousands of
molecules. Barker (1994) combined elements of DebyeHu¨ckel theory for
electrolytes with the reaction field method used for dipolar simulation
resulting in a relatively simple algorithm for including long-range effects.
Examples of ionic systems studied by molecular simulation include simple
molten salts (Hansen and McDonald, 1975) and electrolyte solutions
(Valleau and Cohen, 1980). Molecular simulations have been reported for
the vaporliquid phase equilibria of both sodium chloride (Guissani and
Guillot, 1994) and binary mixtures containing sodium chloride (Strauch
and Cummings, 1993).
The Ewald sum (Chapter 5) can also be applied to calculate dipoledi￾pole interactions (Adams and McDonald, 1976; de Leeuw et al., 1980). A
relatively simple reaction field method (Barker and Watts, 1969) or the
method proposed by Ladd (1977, 1978) can also be used.
The most commonly studied dipolar molecule is water. Water has been
investigated by both MC (Barker and Watts, 1969; Ladd, 1977) and MD
(Rahman and Stillinger, 1971) methods. The investigation of the properties
of water by molecular simulation remains currently of topical interest
because of its both technological importance and unique physical properties
(Shvab and Sadus, 2016). Several different models of the water molecule
have been investigated using molecular simulation (de Pablo and Prausnitz,
1989; de Pablo et al., 1990). Chialvo and Cummings (1999) have reported a
detailed review of models for water at supercritical conditions. It is increas￾ingly apparent that the accurate prediction of the properties of water
(Chapter 4) requires interaction potentials that incorporated the effects of
polarization (Shvab and Sadus, 2016).
1.2.4 Chain molecules and polymers
Long-chain molecules, highly branched molecules, and polymers impose
considerable difficulties for molecular simulation when compared with either
atoms or polyatomic molecules. The computational difficulties are particu￾larly acute for MD methods for which the effect of molecular rotation must
be incorporated into the equations of motion. Consequently, early examples
of MD simulations were confined largely to chains of moderate complexity
such as butane (Ryckaert and Bellemans, 1975; Daivis and Evans, 1995) and
smaller alkanes (Ryckaert and Bellemans, 1978). Later, MD simulations
were reported for eicosane (Morriss et al., 1991), branched alkanes (Daivis
et al., 1992), entangled hard chains (Smith et al., 1996) and dendrimers
(Bosko et al., 2004). However, the advent of improved computing architec￾tures (Abraham et al., 2015) (Chapter 12) means that proteins and other large
biomolecules can be handled using MD.
MC simulation has been applied to chain molecules of considerable size and
complexity (Siepmann et al., 1993; Smit et al., 1995). A configurational-bias
8 Molecular Simulation of FluidsMonte Carlo method (Siepmann and Frenkel, 1992) (Chapter 5) based on the
work of Rosenbluth and Rosenbluth (1955) has been developed to facilitate the
simulation of long chains. The vaporliquid coexistence of alkanes as large as
octatetracontane (C48) (Siepmann et al., 1993; Smit et al., 1995) and other large
chains (Escobedo and de Pablo, 1996) have been studied. Monte Carlo simula￾tions have been reported for the properties of star polymers (Ohno et al., 1996;
Tobita, 1996), dendrimers (Mansfield and Klushin, 1993) and large cyclic
alkanes (Lee et al., 2005).
1.2.5 Ensembles for molecular simulation
The original MC simulations of Metropolis et al. (1953) sampled a canonical
ensemble for which the number of particles, temperature, and volume are con￾stant. However, there are many physical processes that occur under different
conditions, for example, constant temperature and pressure. Consequently, it is
desirable to conduct simulations in a variety of different ensembles depending
on the nature of the property being investigated.
It is relatively easy to extend the MC method to other ensembles (Chapter 9)
because the importance of sampling technique can be applied in any problem for
which it is possible to construct a Markov chain. McDonald (1972) reported
Monte Carlo calculations for binary mixtures in an isothermalisobaric (NpT)
ensemble. Valleau and Cohen (1980) conducted Monte Carlo calculations in the
grand canonical (μVT) ensemble. The transformation to other ensembles is
achieved by sampling the variable that is conjugate to the new fixed parameter in
addition to sampling the particle coordinates. For the isothermalisobaric ensem￾ble, the new variable to be sampled is volume, whereas the number of particles is
sampled for the grand canonical ensemble. Techniques have also been developed
for MC simulations in the microcanonical (Ray, 1991) and canonical (Lustig,
2011) ensembles. The calculation of thermodynamic properties from different
ensembles is examined in Chapter 2.
Generalizing ensembles for MD is complicated by the fact that the equa￾tions of motion lead naturally to the microcanonical (NVE) ensemble.
Consequently, there is no well-defined method for modifying the equations of
motion. Andersen (1980) conducted MD simulations at constant pressure and/
or temperature by introducing additional degrees of freedom. Nose´ (1984)
introduced temperature control by adding additional terms to the Hamiltonian
of the system. Later, Hoover (1985) re-structured Nose´’s equations of motion,
interpreting the additional variables as dynamical friction coefficients. MD
algorithms for various ensembles are outlined in Chapter 9.
1.2.6 Phase equilibria
The traditional Monte Carlo and molecular techniques based on the canonical
ensemble and constant pressure ensemble, respectively, do not yield reliable
Introduction Chapter | 1 9chemical potential data required for phase equilibria calculations. This limitation
was partly addressed by test particle (Adams, 1974; Widom, 1963, 1982; Shing
and Gubbins, 1982) and grand canonical ensemble (Adams, 1975; Mezei, 1980;
Yao et al., 1982) methods. Computer simulation was most commonly restricted
to pure substances (Adams, 1976, 1979) with only limited applications to binary
mixtures (Fincham et al., 1986; Panagiotopoulos et al., 1988).
In the last three decades, considerable progress has been made in the appli￾cation of molecular simulation to phase equilibria. The main impetus has been
the formulation of a Gibbs ensemble MC method (Panagiotopoulos,1987;
Panagiotopoulos et al., 1988). In the Gibbs ensemble, the problem of obtaining
reliable chemical potentials and uncertainties caused by interfaces are elimi￾nated by representing the coexisting phases as separate simulation boxes.
Equilibrium between the boxes (phases) is achieved by attempting molecular
displacements with each box, volume changes, and particle interchanges
between the boxes. The Gibbs ensemble has been used successfully to
calculate phase equilibria in pure fluids (Smit et al., 1995), binary mixtures
(Guo et al., 1994), and ternary mixtures (Tsang et al., 1995). The range
of application of the Gibbs ensemble includes simple molecules, ions
(Orkoulas and Panagiotopoulos, 1994), and polymers (de Pablo, 1995).
Comprehensive reviews of the application of the Gibbs ensemble are available
(Panagiotopoulos, 1992; Gubbins and Sandler, 1994).
Kofke (1993a,b) proposed a GibbsDuhem integration (GDI) scheme for
the simulation of phase equilibrium that combines elements of thermody￾namic integration with the Gibbs ensemble method. The Gibbs ensemble
is used to locate one point on the phase envelope from which the rest of the
curve can be traced. Accurate phase equilibria calculations have been
reported (Panagiotopoulos et al., 1998) by applying histogram re-weighting
techniques to the grand canonical ensemble.
A MD implementation of the Gibbs ensemble has been reported (Palmer
and Lo, 1994). Mo¨ller and Fischer (1990) determined the phase coexistence
of pure fluids using a MD NpT 1 test particle approach. Their approach has
been applied to predict the vaporliquid phase behavior of both pure fluids
(Kriebel et al., 1995) and binary mixtures (Mo¨ller et al., 1992). Successful
calculations of phase equilibria have also been reported using other MD
methods (Schaink and Hoheisel, 1992; Guissani and Guillot, 1993).
The application of molecular simulation has been largely confined to
vaporliquid equilibria, with solidliquid equilibria (SLE) proving much
more challenging. The low probability of particle insertion into dense phases
usually defeats Gibbs ensemble MC. GDI has been used very successfully for
SLE but its accuracy depends on the availability of a reliable starting point.
This mean SLE prediction often requires very specialized simulation method
that suffer from limitations from such as the loss of precision when evaluating
the chemical potential, unwanted surface effects, and difficulty in applying the
method to molecules. However, progress in SLE predictions has been made
10 Molecular Simulation of Fluidswith the advent of new algorithms (Deiters and Sadus, 2022a,b). Details of
algorithms for phase equilibria are given in Chapter 10.
1.2.7 Interatomic interactions
Molecular simulation methods are almost invariably implemented assuming
that intermolecular interactions are confined to pairs of molecules. The cal￾culations are usually achieved by using effective pair-wise potential for
which the LJ potential is the most common example. By making this approx￾imation, it is relatively straightforward to design force fields (Chapter 3) that
can be applied to complicated molecular systems (Martin, 2006).
Effective potentials are computationally convenient, but are largely empirical
without a solid theoretical background. In the last decade, advances in computa￾tional quantum chemistry (Chapter 4) have permitted the evaluation of two￾body interactions from principles, resulting in highly accurate ab initio potentials
for the noble gases (Hellmann et al., 2017; Deiters and Sadus, 2019). The
advantage of such ab initio potentials is that they allow us to unambiguously
determine the effect of two-body interactions on macroscopic properties.
1.2.8 Many-body interactions
The effect of three- or higher-body interactions has not been investigated exten￾sively by molecular simulation. There is a very high computational impediment
to implementing many-body interactions for an N-component systems. The sim￾ulation algorithm is of order Nm
, where m $ 2 is the number of molecules con￾tributing to the interaction. In contrast to the two-body case, there are few three￾body ab initio potentials and their accuracy is much less certain.
Simulations of the effect of three-body (m 5 3) interactions have been
reported using the AxilrodTellerMut ¯o (ATM) potential (Axilrod and
Teller, 1943; Mut ¯o, 1943). Barker et al. (1971) demonstrated that the ATM
potential makes a significant contribution (5%10%) to the overall energy
of liquid argon and Monson et al. (1983) reported that three-body interac￾tions are important for diatomic fluids. Rittger (1990a) included three-body
interactions in a simulation for the chemical potential of liquid xenon.
Following an examination of the thermodynamic data of xenon, Rittger
(1990b) found that three-body dispersion interactions alone were insufficient
to explain xenon’s behavior. The profound effect of ATM interactions on
phase equilibria and other thermophysical properties (Chapter 4) is well
documented (Marcelli and Sadus, 1999; Sadus and Prausnitz, 1996; Wang
and Sadus, 2006; Deiters and Sadus, 2019).
Despite advances in computer technology (Chapter 12), the use of three￾body interaction is far from a routine undertaking, highlighting the need for
careful approximations (Chapter 4) (Marcelli and Sadus, 2000). Calculating
Introduction Chapter | 1 11three-body interactions is particularly beneficial when coupled with two￾body ab initio two-body potentials (Deiters and Sadus, 2022a,b).
1.2.9 Nonequilibrium MD simulation
There are some properties of a fluid that are not in equilibrium. These prop￾erties can be described by nonequilibrium statistical mechanics (Evans and
Morriss, 2008) and are calculated from nonequilibrium molecular dynamics
(NEMD) simulation. Several NEMD techniques (Chapter 8) have been
developed (Evans and Morriss, 1984). Typically, NEMD methods involve
applying a perturbation to the usual equations of motion. The perturbation
can be constant throughout the simulation, it can evolve with time, or alter￾natively, a sinusoidally oscillating perturbation can be used.
Gosling et al. (1973) used NEMD to determine shear viscosity. Evans
and Morriss (1984) and Gillan and Dixon (1983) provided the theoretical
basis for determining heat flow. Diffusion has also been investigated
(Ciccotti et al., 1979). The application of NEMD continues to expand
(Chapter 8). Examples include the study rheology (Morriss, et al., 1991) and
elongational flow (Hunt et al., 2010). Many new and promising NEMD algo￾rithms has been summarized by Todd and Daivis (2017).
1.2.10 Molecular simulation and object orientation
Historically, code for molecular simulation has been developed either prior to
or during the era of structured procedural programming. Structured procedural
programming emphasizes the decomposition of a problem into algorithms that
are represented in languages such as FORTRAN or C as functions and/or sub￾routines. Structured procedural programming has “evolved” into object orien￾tation. Object orientation has many benefits for code design, simplification,
and re-use that can potentially benefit molecular simulation. It is now arguably
the preferred method for code design, which has been exploited in many
sophisticated simulation codes (Phillips et al., 2020; Thompson et al., 2022).
Chapter 11 explores the potential benefits of object orientation.
1.2.11 Parallel computing
Arguably the most important development that has facilitated the growth in
molecular simulation is the advent of parallel computing (Kirk and Hwu, 2010)
(Chapter 12). Initially this simply involved distributing the computational load
over multiple processors. However, the introduction of the graphics processing
unit (GPU) has enabled (Kohnke et al., 2020) an enormous acceleration of MD
code, making simulations with very large number of atoms or molecules compu￾tationally feasible (Hou et al., 2013; Heinecke et al., 2015). Object orientation
12 Molecular Simulation of Fluidsand parallel computing are a powerful combination that will greatly facilitate
future scientific discoveries. This is examined in Chapter 12.
References
Abraham, M.J., Murtolad, T., Schulz, R., Szilard, P., Smith, J.C., Hess, B., Lindahl, E., 2015. ´
GROMACS: High performance molecular simulations through multi-level parallelism from
laptops to supercomputers. SoftwareX 12, 1925.
Adams, D.J., 1974. Chemical potential of hard sphere fluids by Monte Carlo methods. Mol.
Phys. 28, 12411252.
Adams, D.J., 1975. Grand canonical ensemble Monte Carlo for a Lennard-Jones fluid. Mol.
Phys. 29, 307311.
Adams, D.J., 1976. Calculating the low temperature vapour line by Monte Carlo. Mol. Phys. 32,
647657.
Adams, D.J., 1979. Calculating the high-temperature vapour line by Monte Carlo. Mol. Phys.
37, 211221.
Adams, D.J., McDonald, I.R., 1976. Thermodynamic and dielectric properties of polar lattices.
Mol. Phys. 32, 931947.
Alder, B.J., Wainwright, T.E., 1957. Phase transition for a hard sphere system. J. Chem. Phys.
27, 12081209.
Alder, B.J., Wainwright, T.E., 1959. Studies in molecular dynamics. I. General method. J.
Chem. Phys. 31, 459466.
Allen, M.P., Quigley, D., 2013. Some comments on Monte Carlo and molecular dynamics meth￾ods. Mol. Phys. 111, 34423447.
Allen, M.P., Tildesley, D.J. (Eds.), 1993. Computer Simulation in Chemical Physics. Kluwer,
Dordrecht.
Allen, M.P., Tildesley, D.J., 2017. Computer Simulation of Liquids, second ed. Oxford
University Press, Oxford.
Andersen, H.C., 1980. Molecular dynamics simulations at constant pressure and/or temperature.
J. Chem. Phys. 72, 23842393.
Axilrod, B.M., Teller, E., 1943. Interaction of the van der Waals’ type between three atoms. J.
Chem. Phys. 11, 299300.
Barker, J.A., 1994. Reaction field, screening, and long-range interactions in simulations of ionic
and dipolar systems. Mol. Phys. 83, 10571064.
Barker, J.A., Watts, R.O., 1969. Structure of water: a Monte Carlo calculation. Chem. Phys.
Lett. 3, 144145.
Barker, J.A., Fisher, R.A., Watts, R.O., 1971. Liquid argon: Monte Carlo and molecular dynam￾ics calculations. Mol. Phys. 21, 657673.
Battimelli, Ciccotti, G., Greco, 2020. Computer Meets Theoretical Physics: The New Frontier of
Molecular Simulation. Springer, Cham.
Bosko, J.T., Todd, B.D., Sadus, R.J., 2004. Viscoelastic properties of dendrimers in the melt
from nonequilibrium molecular dynamics. J. Chem. Phys. 121, 1205012059.
Cheung, P.S.Y., Powles, J.G., 1975. The properties of liquid nitrogen. IV. A computer simula￾tion. Mol. Phys. 30, 921949.
Chialvo, A.A., Cummings, P.T., 1994. Hydrogen bonding in supercritical water. J. Chem. Phys.
101, 44664469.
Chialvo, A.A., Cummings, P.T., 1999. Molecular-based modeling of water and aqueous solutions
at supercritical conditions. Adv. Chem. Phys. 109, 207433.
Introduction Chapter | 1 13Chialvo, A.A., Cummings, P.T., Simonson, J.M., Mesmer, R.E., Cochran, H.D., 1998. Interplay
between molecular simulation and neutron scattering in developing new insights into the
structure of water. Ind. Eng. Chem. Res. 37, 39213025.
Ciccotti, G., Ferrario, M., Ryckaert, J.P., 1982. Molecular dynamics of rigid systems in
Cartesian coordinates. A general formulation. Mol. Phys. 47, 12531264.
Ciccotti, G., Jacucci, G., McDonald, I.R., 1979. Thought experiments’ by molecular dynamics.
J. Stat. Phys. 21, 122.
Ciccotti, G., Frenkel, D., McDonald, I.R. (Eds.), 1987. Simulation of Liquids and Solids.
Molecular Dynamics and Monte Carlo Methods in Statistical Mechanics. North-Holland,
Amsterdam.
Daivis, P.J., Evans, D.J., 1995. Temperature dependence of the thermal conductivity for two
models of liquid butane. Chem. Phys. 198, 2534.
Daivis, P.J., Evans, D.J., Morriss, G.P., 1992. Computer simulation of the comparative rheology
of branched and linear alkanes. J. Chem. Phys. 97, 616627.
de Leeuw, S.W., Perram, J.W., Smith, E.R., 1980. Simulation of electrostatic systems in periodic
boundary conditions. I. Lattice sums and dielectric constant. Proc. R. Soc. Lond. A373, 2756.
de Pablo, J.J., 1995. Simulation of phase equilibria for chain molecules. Fluid Phase Equilib.
104, 195206.
de Pablo, J.J., Prausnitz, J.M., 1989. Phase equilibria for fluid mixtures from Monte Carlo simu￾lation. Fluid Phase Equilib. 53, 177189.
de Pablo, J.J., Prausnitz, J.M., Strauch, H.J., Cummings, P.T., 1990. Molecular simulation of
water along the liquid-vapor coexistence curve from 25C to the critical point. J. Chem.
Phys. 93, 73557359.
Deiters, U.K., Sadus, R.J., 2019. Two-body interatomic potentials for He, Ne, Ar, Kr, and Xe
from ab initio data. J. Chem. Phys. 150, 134504.
Deiters, U.K., Sadus, R.J., 2022a. Accurate determination of solid-liquid equilibria by molecular
simulation: behavior of Ne, Ar, Kr, and Xe from low to high pressures. J. Chem. Phys. 157,
204504.
Deiters, U.K., Sadus, R.J., 2022b. First-principles determination of the solid-liquid-vapor triple
point: the noble gases. Phys. Rev. E. 105, 054128.
Deiters, U.K., Sadus, R.J., 2023. An intermolecular potential for hydrogen: classical molecular
simulation of pressure-density-temperature behavior, vapor-liquid equilibria, and critical and
triple point properties. J. Chem. Phys. 158, 194502.
Eastwood, J.W., Hockney, R.W., Lawrence, D., 1980. P3M3DP-the three dimensional periodic
particle-particle/particle-mesh program. Comp. Phys. Commun. 19, 215261.
Escobedo, F.A., de Pablo, J.J., 1996. Simulation and prediction of vapour-liquid equilibria for
chain molecules. Mol. Phys. 87, 347366.
Evans, D.J., Morriss, G.P., 1984. Non-Newtonian molecular dynamics. Comp. Phys. Rep. 1,
297343.
Evans, D.J., Morriss, G.P., 2008. Statistical Mechanics of Nonequilibrium Liquids, second ed.
Cambridge University Press, Cambridge.
Evans, D.J., Murad, S., 1977. Singularity free algorithm for molecular dynamics simulation of
rigid polyatomics. Mol. Phys. 34, 327331.
Fincham, D., Quirke, N., Tildesley, D.J., 1986. Computer simulation of molecular liquid mix￾tures. I. A diatomic Lennard-Jones model mixture for CO2/C2H6. J. Chem. Phys. 88,
45354546.
Frenkel, D., Smit, B., 2023. Understanding Molecular Simulation. From Algorithms to
Applications, third ed. Academic Press, San Diego.
14 Molecular Simulation of FluidsGear, C.W., 1971. Numerical Initial Value Problems in Ordinary Differential Equations.
Prentice-Hall, Englewood Cliffs.
Gillan, M.J., Dixon, M., 1983. The calculation of thermal conductivities by perturbed molecular
dynamics simulation. J. Phys. C. 16, 869878.
Goldstein, H., Poole, C., Safko, J., 2002. Classical Mechanics, third ed. Addison Wesley, San
Francisco.
Gosling, E.M., McDonald, I.R., Singer, K., 1973. On the calculation by molecular dynamics of
the shear viscosity of a simple fluid. Mol. Phys. 26, 14751484.
Greengard, L., Rokhlin, V., 1987. A fast algorithm for particle simulations. J. Comput. Phys. 73,
325348.
Gubbins, K.E., Sandler, S.I. (Eds.), 1994. Models For Thermodynamic and Phase Equilibria
Calculations. Marcel Dekker, New York.
Guissani, Y., Guillot, B., 1993. A computer simulation study of the liquid-vapor coexistence
curve of water. J. Chem. Phys. 98, 82218235.
Guissani, Y., Guillot, B., 1994. Coexisting phases and criticality in NaCl by computer simula￾tion. J. Chem. Phys. 101, 490509.
Guo, M.X., Li, Y.G., Li, Z.C., Lu, J.F., 1994. Molecular simulation of liquid-liquid equilibria for
Lennard-Jones fluids. Fluid Phase Equilib. 98, 129139.
Haile, J.M., 1992. Molecular Dynamics Simulation. Elementary Methods. John Wiley & Sons,
New York.
Hansen, J.P., McDonald, I.R., 1975. Statistical mechanics of dense ionized mater. IV. Density
and charge fluctuations in a simple molten salt. Phys. Rev. A 11, 21112123.
Hansen, J.P., Verlet, L., 1969. Phase transitions of the Lennard-Jones system. Phys. Rev. 184,
151161.
Harp, G.D., Berne, B.J., 1968. Linear and angular momentum autocorrelation functions in
diatomic liquids. J. Chem. Phys. 49, 12491254.
Heinecke, A., Eckhardt, W., Horsch, M., Bungartz, H.-J., 2015. Supercomputing for Molecular
Dynamics Simulations: Handling Multi-Trillion Particles in Nanofluidics. Springer, Heidelberg.
Hellmann, R., Ja¨jer, B., Bich, E., 2017. State-of-the-art ab initio potential energy curve for the
xenon atom pair and related spectroscopic and thermophysical properties. J. Chem. Phys.
147, 034304.
Heyes, D.M., 1998. The Liquid State: Applications of Molecular Simulation. John Wiley &
Sons, Chichester.
Hoover, W.G., 1985. Canonical dynamics: equilibrium phase-space distribution. Phys. Rev. A
31, 16951697.
Hou, Q., Li, M., Zhou, Y., Cui, J., Cui, Z., Wang, J., 2013. Molecular dynamics simulations
with many-body potentials on multiple GPUs—The implementation, package and perfor￾mance. Comput. Phys. Commun. 184, 20912101.
Hunt, T.A., Bernardi, S., Todd, B.D., 2010. A new algorithm foe extended nonequilibrium
molecular dynamics simulations of mixed flow. J. Chem. Phys. 133, 154116.
Kirk, D.B., Hwu, W.-M.W., 2010. Programming Massively Parallel Processor: A Hands-on
Approach. Morgan Kaufmann, Amsterdam.
Klamt, A., 2005. COSMOS-RS: From Quantum Chemistry to Fluid Phase Thermodynamics and
Drug Design. Elsevier, Amsterdam.
Kofke, D.A., 1993a. Gibbs-Duhem integration: a new method for direct evaluation of phase
coexistence by molecular simulation. Mol. Phys. 78, 13311336.
Kofke, D.A., 1993b. Direct evaluation of phase coexistence by molecular simulation via integra￾tion along the coexistence line. J. Chem. Phys. 98, 27042719.
Introduction Chapter | 1 15Kohnke, B., Kutzner, C., Grubmu¨ller, J., 2020. A GPU-accelerated fast multiple method for
GROMAS: Performance and accuracy. J. Chem. Thoer. Comput. 16, 69386949.
Kriebel, C., Mu¨ller, A., Winkelmann, J., Fischer, J., 1995. Vapour-liquid equilibria of two-centre
Lennard-Jones fluids from the NpT plus test particle method. Mol. Phys. 84, 381394.
Ladd, A.J.C., 1977. Monte Carlo simulation of water. Mol. Phys. 33, 10391050.
Ladd, A.J.C., 1978. Long-range dipolar interactions in computer simulations of polar liquids.
Mol. Phys. 36, 463474.
Leach, A.R., 2001. Molecular Modelling: Principles and Applications, second ed. Prentice Hall,
Harlow.
Lee, J.-S., Wick, C.D., Stubbs, J.M., Siepmann, J.I., 2005. Simulating the vapour-liquid equilib￾ria of cyclic alkanes. Mol. Phys. 103, 99104.
Lord Kelvin, 1904. Baltimore Lectures on Molecular Dynamics and the Wave Theory of Light.
C. J. Clay and Sons, Cambridge University Press, London, p. 522.
Lustig, R., 2011. Direct molecular NVT simulation of the isobaric heat capacity, speed of sound
and Joule-Thomson coefficient. Mol. Sim. 37, 457465.
Mansfield, M.L., Klushin, L.I., 1993. Monte Carlo studies of dendrimer macromolecules.
Macromolecules 26, 42624268.
Marcelli, G., Sadus, R.J., 1999. Molecular simulation of the phase behavior of noble gases using
accurate two-body and three-body intermolecular potentials. J. Chem. Phys. 111, 15331540.
Marcelli, G., Sadus, R.J., 2000. A link between the two-body and three-body interaction energies
of fluids from molecular simulation. J. Chem. Phys. 112, 63826385.
Martin, M.G., 2006. Comparison of the AMBER, CHARMM, COMPASS, GROMOS, OPLS,
TraPPE and UFF force fields for the prediction of vapor-liquid coexistence curves and liquid
densities. Fluid Phase Equilib. 248, 5055.
McDonald, I.R., 1972. NpT-ensemble Monte Carlo calculations for binary liquid mixtures. Mol.
Phys. 23, 4158.
Metropolis, N., Rosenbluth, A.W., Rosenbluth, M.N., Teller, A.H., Teller, E., 1953. Equation of
state calculations by fast computing machines. J. Chem. Phys. 21, 10871092.
Mezei, M., 1980. A cavity-biased (TVμ) Monte Carlo method for the computer simulation of
fluids. Mol. Phys. 40, 901906.
Mo¨ller, D., Fischer, J., 1990. Vapour liquid equilibrium of a pure fluid from test particle method
in combination with NpT molecular dynamics simulations. Mol. Phys. 69, 463473.
Mo¨ller, D., O´ przynski, J., Mu¨ller, A., Fischer, J., 1992. Prediction of thermodynamic properties of
fluid mixtures by molecular dynamics simulations: methane-ethane. Mol. Phys. 75, 363378.
Monson, A.P., Rigby, M., Steele, W.A., 1983. Non-additive energy effects in molecular liquids.
Mol. Phys. 49, 893898.
Morriss, G.P., Daivis, P.J., Evans, D.J., 1991. The rheology of n alkanes: decane and eicosane. J.
Chem. Phys. 94, 74207433.
Mut ¯o, Y. (1943). On the forces acting between nonpolar molecules. J. Phys.-Math. Soc. Japan
17, 629631. [This paper is most often incorrectly cited in the literature as Muto, Y.
(1943). Proc. Phys. Math. Soc. Japan 17, 629. The correct paper (in Japanese) is freely
available from https://doi.org/10.11429/subutsukaishi1927.17.10-11-12_629.]
Nose´, S., 1984. A unified formulation of the constant temperature molecular dynamics methods.
J. Chem. Phys. 81, 511519.
Nose´, S., Klein, M.L., 1983. Constant pressure molecular dynamics for molecular systems. Mol.
Phys. 50, 10551076.
Ohno, K., Shida, K., Kmiura, M., Kawazoe, Y., 1996. Monte Carlo study of the second virial
coefficient of star polymers in a good solvent. Macromolecules 29, 22692274.
16 Molecular Simulation of FluidsOrkoulas, G., Panagiotopoulos, A.Z., 1994. Free energy and phase equilibria for the restricted primi￾tive model of ionic fluids from Monte Carlo simulations. J. Chem. Phys. 101, 14521459.
Palmer, B.J., Lo, C., 1994. Molecular dynamics implementation of the Gibbs ensemble calcula￾tion. J. Chem. Phys. 101, 1089910907.
Panagiotopoulos, A.Z., 1987. Direct determination of phase coexistence properties of fluids by
Monte Carlo simulation in a new ensemble. Mol. Phys. 61, 813826.
Panagiotopoulos, A.Z., 1992. Direct determination of fluid phase equilibria by simulation in the
Gibbs ensemble: a review. Mol. Sim. 9, 123.
Panagiotopoulos, A.Z., Quirke, N., Stapleton, M., Tildesley, D.J., 1988. Phase equilibria by sim￾ulation in the Gibbs ensemble. Alternative derivation, generalization and application to mix￾ture and membrane equilibria. Mol. Phys. 63, 527546.
Panagiotopoulos, A.Z., Wong, V., Floriano, M.A., 1998. Phase equilibria of lattice polymers
from histogram reweighting Monte Carlo simulations. Macromolecules 31, 912918.
Phillips, J.C., Hardy, D.J., Maia, J.D.C., Stone, J.E., Ribeiro, J.V., Bernardi, R.C., Buch, R.,
Fiorin, G., He´nin, J., Jiang, W., McGreevy, R., Melo, M.C.R., Radak, B.K., Skeel, R.D.,
Singharoy, A., Wang, Y., Roux, B., Aksimentiev, A., Luthey-Schulten, Z., Kale´, L.V.,
Schulten, K., Chipot, C., Tajkhorshid, E., 2020. Scalable molecular dynamics on CPU and
GPU architectures with NAMD. J. Chem. Phys. 153, 044130.
Postorino, P., Tromp, R.H., Ricci, M.-A., Soper, A.K., Neilson, G.W., 1993. The interatomic
structure of water at supercritical temperatures. Nature 366, 668670.
Raabe, G., 2017. Molecular Simulation Studies on Thermophysical Properties with Application
to Working Fluids. Springer, Berlin.
Rahman, A., 1964. Correlations in the motion of atoms in liquid argon. Phys. Rev. 136, 405411.
Rahman, A., Stillinger, F.H., 1971. Molecular dynamics study of liquid water. J. Chem. Phys.
55, 33363359.
Rapaport, D.C., 2004. The Art of Molecular Dynamics Simulation, second ed. Cambridge
University Press, Cambridge.
Ray, J.R., 1991. Microcanonical ensemble Monte Carlo method. Phys. Rev. A 44, 40614064.
Rittger, E., 1990a. The chemical potential of liquid xenon by computer simulation. Mol. Phys.
69, 853865.
Rittger, E., 1990b. Can three-atom potentials be determined from thermodynamic data? Mol.
Phys. 69, 867894.
Rosenbluth, M.N., Rosenbluth, A.W., 1955. Monte Carlo calculations of the average extension
of molecular chains. J. Chem. Phys. 23, 356359.
Ryckaert, J.P., Bellemans, A., 1975. Molecular dynamics of liquid n-butane near its boiling
point. Chem. Phys. Lett. 30, 123125.
Ryckaert, J.P., Bellemans, A., 1978. Molecular dynamics of liquid alkanes. Chem. Soc. Faraday
Discuss. 66, 95106.
Sadus, R.J., Prausnitz, J.M., 1996. Three-body interactions in fluids from molecular simulation:
vapor-liquid phase coexistence of argon. J. Chem. Phys. 104, 47844787.
Schaink, H.M., Hoheisel, C., 1992. The phase-behavior of Lennard-Jones mixtures with nonaddi￾tive hard cores: comparison between molecular dynamic calculations and perturbation the￾ory. J. Chem. Phys. 97, 85618567.
Shing, K.S., Gubbins, K.E., 1982. The chemical potential in dense fluids and fluid mixtures via
computer simulation. Mol. Phys. 46, 11091128.
Shvab, I., Sadus, R.J., 2016. Atomistic water models: aqueous thermodynamic properties from
ambient to supercritical conditions. Fluid Phase Equilib. 407, 730.
Introduction Chapter | 1 17Siepmann, J.I., Frenkel, D., 1992. Configurational-bias Monte Carlo: a new sampling scheme for
flexible chains. Mol. Phys. 75, 5970.
Siepmann, J.I., Karaborni, S., Smit, B., 1993. Simulating the critical behaviour of complex
fluids. Nature 365, 330332.
Singer, K., Taylor, A., Singer, J.V.L., 1977. Thermodynamic and structural properties of liquids
modelled by ‘two-Lennard-Jones centres’ pair potentials. Mol. Phys. 33, 17571795.
Smit, B., Karaborni, S., Siepmann, J.I., 1995. Computer simulation of vapor-liquid phase equilib￾ria of n-alkanes. J. Chem. Phys. 102, 21262140.
Smith, S.W., Hall, C.K., Freeman, B.D., 1996. Molecular dynamics study of entangled hard￾chain fluids. J. Chem. Phys. 104, 56155637.
Soper, A.K., Bruni, F., Ricci, M.A., 1997. Site-site pair correlation functions of water from 25 to
400 C: revised analysis of new and old diffraction data. J. Chem. Phys. 106, 247254.
Strauch, H.J., Cummings, P.T., 1993. Gibbs ensemble simulation of mixed solvent electrolyte
solutions. Fluid Phase Equilib. 86, 147172.
Thompson, A.P., Aktulga, H.M., Berger, R., Bolintineanu, D.S., Brown, W.M., Crozier, P.S.,
’t Veld, P.J., Kohlmeyer, A., Moore, S.G., Nguyen, T.C., Shan, R., Stevens, M.J.,
Tranchida, J., Trott, C., Plimpton, S.J., 2022. LAMMPS  a flexible simulation tool for
particle-based materials modeling at the atomic, meso, and continuum scales. Comp. Phys.
Commun. 271, 108171.
Tobita, H., 1996. Random degradation of branched polymers. 1. Star polymers. Macromolecules
29, 30003009.
Todd, B.D., Daivis, P.J., 2017. Nonequilibrium Molecular Dynamics: Theory, Algorithms and
Applications. Cambridge University Press, Cambridge.
Tsang, P.C., Omar, N.W., Perigard, B.Y., Vega, L.F., Panagiotopoulos, A.Z., 1995. Phase equi￾libria in ternary Lennard-Jones systems. Fluid Phase Equilib. 107, 3143.
Valleau, J.P., Cohen, L.K., 1980. Primitive model electrolytes. I. Grand canonical Monte Carlo
computations. J. Chem. Phys. 72, 59355941.
Verlet, L., 1967. Computer “experiments” on classical fluids. I. Thermodynamical properties of
Lennard-Jones molecules. Phys. Rev. 159, 98103.
Wang, L., Sadus, R.J., 2006. Three-body interactions and solid-liquid Phase equilibria: applica￾tion of a molecular dynamics algorithm. Phys. Rev. E 74, 031203.
Widom, B., 1963. Some topics in the theory of fluids. J. Chem. Phys. 39, 28082812.
Widom, B., 1982. Potential distribution theory and the statistical mechanics of fluids. J. Phys.
Chem. 86, 869872.
Wood, W.W., Jacobson, J.D., 1957. Preliminary results from a recalculation of the Monte Carlo
equation of state of hard spheres. J. Chem. Phys. 27, 12071208.
Wood, W.W., Parker, F.R., 1957. Monte Carlo equation of state of molecules interacting with
the Lennard-Jones potential. I. A supercritical isotherm at about twice the critical tempera￾ture. J. Chem. Phys. 27, 720733.
Yao, J., Greenkorn, R.A., Chao, K.C., 1982. Monte Carlo simulation of the grand canonical
ensemble. Mol. Phys. 46, 587594.
18 Molecular Simulation of FluidsChapter 2
Ensembles, thermodynamic
averages, and particle dynamics
The principles of statistical thermodynamics are fundamental to both Monte
Carlo (MC) and molecular dynamics (MD) simulation methods. It can be
argued that molecular simulation is computational statistical mechanics.
Molecular simulation allows us to evaluate exactly the properties of mole￾cules as described by statistical mechanics. Statistical mechanics relates mac￾roscopic properties to the properties of individual molecules. In turn, the
properties of individual molecules can be evaluated directly using molecular
simulation methods. In a MC simulation, the evaluation of the properties of
molecules is performed independently of the dynamics of motion. In con￾trast, knowledge of particle dynamics is essential for MD simulation.
Very comprehensive and detailed descriptions of statistical mechanics are
available elsewhere (Fowler and Guggenheim, 1956; Garrod, 1995; Hill,
1986; Hill, 1987; Mayer and Mayer, 1946; Reed and Gubbins, 1973; Reif,
1965; Rushbrooke, 1962; Wannier, 1987). Section 2.1 provides a brief over￾view of the results of statistical mechanics that are used commonly in molec￾ular simulation programs. The concept of an ensemble is reviewed and
various common thermodynamic properties are defined in terms of ensemble
averages. These properties can be determined via molecular simulation by
evaluating the behavior of suitable intermolecular potentials. Maitland et al.
(1981) have provided a detailed description of several intermolecular poten￾tials, and this important aspect is discussed further in Chapters 3 and 4.
Obtaining ensemble averages of pressure and energy is straightforward,
whereas historically averages of other thermodynamic properties were obtained
via fluctuations (Section 2.2). However, a more contemporary approach (Lustig,
1994a; Meier and Kabelac, 2006) is discussed in Section 2.3, which offers con￾siderable advantages, arguably providing the preferred method for the future
determination of thermodynamic properties via simulation.
An overview of the underlying mechanics of particle motion is presented in
Section 2.4. In a sense, this can be regarded as a primer for MD because an
understanding of the mechanics of particle motion is the cornerstone of the
implementation of MD algorithms. The motion of particles can be described in
the framework of Newtonian, Lagrangian, or Hamiltonian mechanics. Here, we
19 Molecular Simulation of Fluids. DOI: https://doi.org/10.1016/B978-0-323-85398-9.00016-2
© 2024 Elsevier B.V. All rights reserved.illustrate the relationship between these mechanical frameworks. Starting from
Newton’s equation, first the Lagrangian equations and then the Hamiltonian
equations are obtained. This section follows closely the work of Goldstein
(1950). Although Newton’s equations are sufficient for simple atomic systems,
Lagrangian or Hamiltonian dynamics is advantageous for more complicated sys￾tems. Lagrangian and Hamiltonian dynamics are discussed comprehensively
elsewhere (Calkin, 1996), and there are several books that describe particle
mechanics in the context of molecular simulation (Haile, 1992; Hoover, 1986;
Hoover, 1991; Rapaport, 2004; Allen and Tildesley, 2017).
2.1 Statistical mechanics, ensembles, and averaging
2.1.1 Ensembles
Molecular simulation permits the rigorous application of the principles of statisti￾cal mechanics to calculate the properties of a chosen system. A typical simulation
program requires the implementation of several algorithms involving the calcula￾tion of energies, forces, molecular orientation, and the like. However, the overall
simulation framework is determined by the choice of an ensemble (Chapter 9).
From the perspective of statistical mechanics, a system’s macroscopic prop￾erties such as pressure or density represent averages over all possible quantum
states. To calculate the properties of a real system, it is convenient to define an
ensemble. An ensemble can be regarded as an imaginary collection of a very
large number of systems in different quantum states with common macroscopic
attributes. For example, each system of the ensemble must have the same tem￾perature (T), pressure (p), and number of particles (N) as the real system it
represents. The ensemble average (Reed and Gubbins, 1973; Hill, 1986) of any
dynamic property (A) can be obtained from the relationship,
h i A 5 X
i
Aiℙi; ð2:1Þ
where Ai is the value of A in a quantum state i; ℙi represents the probability
of observing the ith state, and the angular brackets denote an ensemble aver￾age. The time-averaged properties of the real system are related to the
ensemble average by invoking the following assumption:
At 5N 5 h i A : ð2:2Þ
The above equivalence of the time average and ensemble average is
called the ergodic hypothesis (Haile, 1992).
The form of ℙi is determined by which macroscopic properties are com￾mon for every system of the ensemble. For example, if the volume (V), T,
and N are constant, then it can be shown that,
ℙi 5 e2βEiðN;VÞ
ZNVT
; ð2:3Þ
20 Molecular Simulation of Fluidswhere E is the energy, β 5 1/kT (k is Boltzmann’s constant), and ZNVT is the
canonical partition function.
ZNVT 5 X
i
e2βEiðN;VÞ ð2:4Þ
Eq. (2.3) represents the canonical ensemble. Other ensembles are possible
depending on the choice of constant macroscopic properties (Hill, 1986).
Some commonly used ensembles are summarized in Table 2.1, where δ is
Dirac’s delta function.
It is apparent that the ensembles summarized in Table 2.1 occur in two broad
categories. The microcanonical, canonical, and isothermalisobaric ensembles
describe closed systems for which there is no change in the number of particles.
In contrast, the grand canonical ensemble is appropriate for an open system in
which the number of particles can change. In the thermodynamic limit, all of the
ensembles are equivalent, and it is also possible to transform between different
ensembles (Allen and Tildesley, 2017; Raabe, 2017). The choice of ensemble for
a simulation is often a matter of convenience. Many physical processes do not
involve a change in N and occur at either constant T and V, or constant T and p.
In these cases, the natural choices are the canonical and isothermalisobaric
ensembles, respectively. It is common practice to use the constraints as a short￾hand notation for the ensembles.
Each ensemble is associated with a characteristic thermodynamic function. The
entropy (S) can be obtained directly from the microcanonical partition function.
S 5 klnZNVE ð2:5Þ
The Helmholtz function (A) is associated with the canonical ensemble.
A 5 2 kTlnZNVT ð2:6Þ
The isobaricisothermal ensemble yields the definition for the Gibbs
function (G),
G 5 2 kTlnZNpT ; ð2:7Þ
TABLE 2.1 Summary of common statistical ensembles.
Ensemble Constraints Z ℙi
Microcanonical N, V, E X
i
δðEi 2 EÞ δðEi 2 EÞ
ZNVE
Canonical N, V, T X
i
e2βEiðN;VÞ e2βEiðN;VÞ
ZNVT
Grand canonical μ, V, T X
i
eβNiμZNVT e2βðEi2μNiÞ
ZμVT
Isothermalisobaric N, p, T X
i
eβpVi ZNVT e2βðEi1pViÞ
ZNpT
Ensembles, thermodynamic averages, and particle dynamics Chapter | 2 21where p is the appropriate thermodynamic function for the grand canonical
ensemble.
pV 5 2 kTlnZμVT ð2:8Þ
2.1.2 Simple thermodynamic averages
2.1.2.1 Energy
The total energy (E) (or Hamiltonian) of the ensemble can be obtained from
the kinetic (K) and potential energies (U)
E 5 h i K 1 h i U ; ð2:9Þ
where the angled brackets denote ensemble averages.
The kinetic energy can be evaluated from the individual momenta of the par￾ticles. The potential energy is the sum of the interparticle interactions
(Chapter 3). As discussed subsequently, the interparticle interactions are usually
calculated by assuming a particular intermolecular function. Typically, the cal￾culation involves a summation over all distinct pairs of molecules (Chapter 3),
although other many-body interactions (Chapter 4) can be involved.
2.1.2.2 Temperature
The temperature can be obtained (Allen and Tildesley, 2017) from the virial the￾orem. In terms of generalized momenta (pk), the theorem can be expressed as:
pk
@E
@pk
  5 kT ð2:10Þ
For N atoms, each with three degrees of freedom, we obtain the relationship.
T 5 2h i K
3Nk ð2:11Þ
Alternatively, we can consider T to be the average of instantaneous tem￾perature (t) contributions.
t 5 2K
3Nk ð2:12Þ
2.1.2.3 Pressure
The pressure can also be obtained (Allen and Tildesley, 2017) from the virial
theorem. In terms of generalized coordinates (qk), the virial theorem can be
expressed as:
qk
@E
@qk
  5 kT ð2:13Þ
Starting from Eq. (2.13), it can be shown (Allen and Tildesley, 2017) that,
pV 5 NkT 1 h i W ; ð2:14Þ
22 Molecular Simulation of Fluidswhere W is the internal virial (defined below). We can define an instanta￾neous pressure function analogous to the instantaneous temperature.
p 5 ρkt 1
W
V ð2:15Þ
The internal virial is defined as,
W 5 1
3
X
i
X
j . i
rijUfij 5 2 1
3
X
i
X
j . i
wðrijÞ; ð2:16Þ
where w(r) is the intermolecular pair virial function and i and j denote the
atoms or molecules.
wðrÞ 5 r
duðrÞ
dr ð2:17Þ
Eq. (2.17) introduces the intermolecular potential function (u(r)) into the
calculation of the ensemble pressure. The potential pressure can be identified
as ppot 5 W=V.
2.1.2.4 Residual chemical potential
The residual chemical potential (μr) is obtained typically from the insertion of
a test particle (Widom, 1963, 1982). A ghost test particle is inserted randomly
into the system and the resulting change in potential energy (Utest) is calcu￾lated. The formula for calculating μr is ensemble-dependent. For the canonical
(Widom, 1963) and grand canonical (Henderson, 1983) ensembles we have:
μr 5 2 kTln expð Þ 2βUtest   ð2:18Þ
Fluctuations of the kinetic temperature mean that the corresponding for￾mula (Frenkel, 1986) for the microcanonical ensemble requires the instanta￾neous temperature:
μr 5 2 k th iln
t
3=2exp 2Utest
kt    
h it 3=2
" # ð2:19Þ
For the isothermalisobaric ensemble, allowance must be made for vol￾ume fluctuations (Shing and Chung, 1987).
μr 5 2 kTln
Vexpð2 βUtestÞ  
h i V
 	 ð2:20Þ
The total configurational chemical potential can be obtained by adding
the ideal contribution (see below). For atoms, it is,
μid 5 2 kTln N
V
2πmkT
h

 3=2 ( ); ð2:21Þ
Ensembles, thermodynamic averages, and particle dynamics Chapter | 2 23where m and h are the mass of a single atom and Planck’s constant, respec￾tively. The additional degrees of freedom of molecules means that the ideal
contribution to molecular properties should also include contributions from
rotation and vibration. Although well-known statistical relationships exist
(Reed and Gubbins, 1973), it has become common practice to deduce empir￾ical relationships for real molecules (Lemmon et al., 2009).
2.2 Properties from fluctuations
During the course of a simulation, fluctuations will be observed (Lebowitz
et al., 1967) in various properties of the ensemble, for example, energy fluc￾tuations occur in the canonical ensemble. These fluctuations are useful
because they can be related to thermodynamic derivatives such as specific
heat and isothermal compressibility. It is particularly useful to calculate the
root mean square (RMS) deviation of an ensemble property,
σ2
ðAÞ 5 δA2   5 A2   2 h i A 2
; ð2:22Þ
where
δA 5 A 2 h i A ð2:23Þ
It should be noted that the fluctuations in different ensembles are not the
same. This is exemplified in Table 2.2 for the isochoric heat capacity ð Þ CV
of atoms.
TABLE 2.2 Fluctuation formulas for the CV of atoms in different ensembles.a
Ensemble Fluctuation formula
NVE 2
3Nk 2 4 δY2  
9k3N2T2

 21
5 2
3Nk 2 4 Y2  2h i Y 2  
9k3N2T2
 !21
NVT δU2  
kT2 1
3Nk
2 5 U2   2 h i U 2
kT2 1
3Nk
2
μVT 1
kT2 δU2   2 h i δUδN 2
δN2  
0
@
1
A 1
3Nk
2
5 1
kT2 U2   2 h i U 2 2 h i h i UN 2h i U h i N 2
N2   2 h i N 2
0
@
1
A 1
3Nk
2
a
Y can be either K or U. The formulas include the contribution for the ideal gas term for atoms that
should be replaced for molecules.
24 Molecular Simulation of Fluids2.2.1 Thermodynamic properties
The thermodynamic definition of various properties is given in Table 2.3. These
properties involve evaluating thermodynamic derivatives, which comprise fluctua￾tions of quantities such as energy, pressure, volume, and number of particles. The
evaluation of some thermodynamic properties is “natural” in a particular ensemble
because of the different constraints (Table 2.1) that determine which quantities
can fluctuate. For example, CV is easily calculated in the NVT ensemble, whereas
there is a straightforward relationship for Cp in the NpT ensemble. Nonetheless,
all the thermodynamic quantities can be obtained from any ensemble. That is,
none are specifically limited to a particular choice ensemble, which is simply a
matter of preference or convenience rather than any theoretical restriction.
An explanation of fluctuation formulas for different ensembles is given
elsewhere (Adams, 1975; Allen and Tildesley, 2017; Brown, 1958; Lebowitz
et al., 1967; Rowlinson, 1969), and the relationships for the NpT ensemble
(Brown, 1958) are summarized in Table 2.3. In the NpT ensemble, it is
TABLE 2.3 Thermodynamic definitions of various properties and their
evaluation in the NpT ensemble using fluctuation formulas.a
Property Thermodynamic
definition
NpT ensemble
fluctuation formula
Isochoric heat capacity
(CV )
@ðE5U1KÞ
@T

 
V
Cp 2 TVα2
p =βT
Isobaric heat capacity (Cp ) @ðH5U1K 1pVÞ
@T

 
p
δ H5U1K 1pV  2 D E
kT2
Isothermal compressibility
(βT ) 2 1
V
@V
@p

 
T
δV2  
kTV
Adiabatic compressibility
(βS ) 2 1
V
@V
@p

 
S
βT 2 TVα2
p
Cp
Thermal pressure
coefficient (γV )
@p
@T

 
V
αp
βT
Thermal expansion
coefficient (αp )
1
V
@V
@T

 
p
δVδ H 5 U 1 K 1 pV    
kT2V
Zero frequency speed of
sound (w0)
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
2 V2
NM
@p
@V

 
S
s
w0 5
ffiffiffiffiffiffiffiffiffiffiffiffiffi
V
NMβS
s
JouleThomson coefficient
(μJT )
@T
@p

 
H
γV 2 1=TβT
γ2
V 1 NCV
VTβT
a
M is the total mass of the system.
Ensembles, thermodynamic averages, and particle dynamics Chapter | 2 25natural to calculate Cp, βT , and αp, which involve δV and δH. Having deter￾mined these key properties, all other thermodynamic properties can be
obtained using the relationships in Eq. (2.24) (Rowlinson, 1969; Mu¨nster,
1970), which is the basis of the formulas for CV, w0, and μJT in Table 2.3.
In general, for a given ensemble, only three key properties are required from
molecular simulation to determine all of the remaining thermodynamic prop￾erties. That is, CV, βT and γV for the NVE, NVT, and μVT ensembles and
Cp, βT , and αp for the NpT and NpH ensembles, respectively.
Cp 5 CV 1
Vγ2
V
Nk
5 CV 1
TVα2
p
βT
5 CV 1 TVβT γ2
V
5 CV 1 TVαpγV
5 CV βT =βs
 
β21
S 5 β21
T 1 VTγ2
V =CV
μJT 5 γV 2 1=βT T
γ2
V 1
NCV
VTβT
αp 5 βT γV
w0 5
ffiffiffiffiffiffiffiffiffiffiffiffi V
NMβS
s
9
>>>>>>>>>>>>>>>>>>>>>>>>>>>>=
>>>>>>>>>>>>>>>>>>>>>>>>>>>>;
ð2:24Þ
The definition of both E and enthalpy (H) involves a contribution to the
kinetic energy. This can be explicitly calculated in MD but not in MC. In the
latter case, the contribution is typically incorporated separately as an ideal
term, and the MC calculation involves the evaluation of a residual quantity
only. Therefore it is also often useful (Lagache et al., 2001) to separate the
contribution of a thermodynamic property (X) into its residual (Xr) and ideal
components (Xid) because the value of the latter will depend on the number
of degrees of freedom (f) of the molecule.
X 5 Xr 1 Xid ð2:25Þ
This separation of contributions is evident in the alternative formulas
for CV given for atoms (f 5 3) in Table 2.2 with the terms involving U
providing the residual term. The residual term arises from interactions
between particles that can be calculated via an intermolecular potential
(Chapter 3). As such it can also be described as either the potential or
configurational contribution. The residual contribution is sometimes misi￾dentified in the literature as an excess property. In chemical thermody￾namics, the term “excess” should be strictly reserved for the specific case
26 Molecular Simulation of Fluidsof mixture properties: the difference between the property of a mixture of
two or more components and the property of an ideal solution at the same
T and p (Prigogine and Defay, 1954; Hansen and McDonald, 2013;
Prausnitz et al., 1999).
Formulas for the ensemble averages of the thermodynamic properties in
the literature typically include the contributions to K from the three degrees
of freedom of translational motion of an atom that arises from the equiparti￾tion theorem, that is, K 5 Kid 5 3kT/2. The additional degrees of freedom of
molecular systems mean that ideal contributions to thermodynamic properties
account for nontranslational contributions such as vibration and rotation. For
the properties of molecules composed of n-atoms, the contribution to K of
rotation must be included. That is, for linear and nonlinear molecules, adding
the contribution from rotation yields, Kid 5 5kT=2 (two additional degrees of
freedom) and Kid 5 3kT (three additional degrees of freedom), respectively.
Separately identifying only the residual contribution to the thermodynamic
property means that the molecule-specific ideal component can be added as
required to obtain the full value. It reduces the likelihood of unwittingly
either underestimating (by using the in-formula atomic value for a molecule)
or overestimating (by adding the molecular value to the in-formula atomic
value) the contribution of K for molecules.1
For a linear n-atom molecule, application of the equipartition theorem
yields CV; id 5 5k=2 1 ð3n 2 5Þk, whereas the value for an n-atom nonlinear
molecule is CV; id 5 3k 1 ð3n 2 6Þk. The second term in these equations is
the contribution from vibrations. However, in many cases, high temperatures
are usually required to even partially observe these contributions because
vibrational motions are not fully excited at low to moderate temperatures. In
most cases deviations from the constant values can be exclusively attributed
to vibrations. Therefore it is normally sufficient to account for only transla￾tional and rotational contributions. That is, CV; id 5 5k=2 and CV; id 5 3k for
linear and nonlinear n-atom molecules, respectively.
Alternatively, the ideal contribution for molecules is sometimes estimated
(Raabe, 2017; Elliott et al., 2023) from either experimental data or theory,
which is particularly useful for obtaining reliable values for large polyatomic
molecules. In contrast, large deviations from the ideal gas formula for small
molecules are usually only observed at high T with the onset of significant
vibrational contributions. However, water is an exception. Fig. 2.1 compares
the calculated (Friedman and Haar, 1954) ideal gas Cp of water (n 5 3) to
contributions from the simple equipartition formula, that is,
Cp; id 5 CV; id 1 k 5 4k. It is apparent that significant deviations occur for T
. 200 K.
1. An insidious problem in the literature is that formulas originally derived for atoms are applied
unmodified to molecules. To add to the confusion, atoms are sometimes also incorrectly referred
to as molecules and vice versa.
Ensembles, thermodynamic averages, and particle dynamics Chapter | 2 272.2.2 Transport coefficients
In contrast to MC, MD simulation allows us to determine the time￾dependent properties of fluids such as transport coefficients. Here, we
simply state the results that connect molecular simulation with transport
properties. A theoretical justification can be found elsewhere (Rapaport,
2004; Hansen and McDonald, 2013; Allen and Tildesley, 2017). Hoheisel
(1994) has reviewed the use of MD simulation for the transport properties
of molecular fluids.
2.2.2.1 Diffusion
The coefficient of diffusion (D) can be obtained (Rapaport, 2004) from,
D 5 lim
t-N
1
6Nt
X
N
j51
rjðtÞ2rjð0Þ 
 

2
* +; ð2:26Þ
where t denotes time. To evaluate correctly the right-hand side of Eq. (2.26),
account must be taken of the superfluous folding back of particle coordinates
common in the application of periodic boundary conditions. If we assume
that the displacement per time step is small relative to the size of the system,
FIGURE 2.1 Relative difference between the ideal gas formula for the Cp of water and accu￾rate calculations. The increased deviations at T . 200 K reflect the commencement of signifi￾cant vibrational contributions.
28 Molecular Simulation of Fluidsthe true atom displacements (r’) can be obtained from the following relation￾ship (Rapaport, 2004),
r
;
xjðtÞ 5 rxjðtÞ 1 nint r
;
xjðt 2 ΔtÞ 2 rxjðtÞ
Lx

 Lx; ð2:27Þ
where nint(x) is the nearest integer to x.
2.2.2.2 Shear viscosity
The shear viscosity (η) is calculated (Rapaport, 2004) from:
η 5 lim
t-N
1
6kTVt
X
x , y
X
j
mjrxjðtÞvyjðtÞ2X
j
mjrxjð0Þvyjð0Þ
* + " #2
ð2:28Þ
The reason for the sum Σx , y over the three pairs of distinct vector com￾ponents xy, yz, and zx in Eq. (2.28) is to improve the accuracy of the calcula￾tion. It is not required by theory and it can be omitted.
2.2.2.3 Thermal conductivity
The thermal conductivity (λ) is given (Rapaport, 2004) by:
λ 5 lim
t-N
1
6kT2Vt
X
x
X
j
rxjðtÞejðtÞ2X
j
rxjð0Þejð0Þ
* + " #2
ð2:29Þ
In Eq. (2.29), Σx is the sum over all vector components and e is the
instantaneous excess energy of atom j defined by,
ej 5 mv2
j
2
1
X
i . j
uðrijÞ 2 h ie
2 ; ð2:30Þ
where h ie is the mean energy.
2.2.3 Molecular simulation and choice of ensemble
In the thermodynamic limit all ensembles are equivalent (Hill, 1986) and
should yield identical outcomes. However, molecular simulations are con￾ducted for a finite number of particles and care should always be taken to
examine the influence of finite size on a given property. In practice, this
means performing simulations with a varying number of particles to gauge
the influence on particle numbers on a given property.
It is sometimes observed that the pressure calculated from a MD NVT
ensemble simulation using the density (ρ 5 N/V) obtained from an NpT
ensemble does not exactly match the pressure of the NpT MD simulation.
This problem persists irrespective of the number of particles used, and as
Ensembles, thermodynamic averages, and particle dynamics Chapter | 2 29such at least partly reflects some deficiencies in the thermostat or barostat
(Chapters 79). It is an issue that is arguably underreported in the literature,
which can be partly attributed to the preference for the NpT ensemble and
relatively few contemporary comparisons (Bosko et al., 2005) between dif￾ferent ensembles.
2.3 Alternative methods for thermodynamic properties
A disadvantage of the fluctuation approach is that the properties require post￾simulation processing to determine the contributions of the fluctuations. This
contrasts with quantities such as E and p that are simply calculated during
the normal course of the simulation. Lustig (1994a,b,c) showed that, in gen￾eral, all thermodynamic state variables could be obtained from derivatives
determined directly from MD simulations in a classical NVEP ensemble. The
nature of MD and MC simulations are discussed in Chapters 6 and 7,
respectively.
It should be noted that the formulas for the NVT, NpT, μVT, and NpH
ensembles detailed below are strictly only valid for MC because the addi￾tional reduction in the degrees of freedom that occur in MD simulations
have not been taken into account. However, from a practical perspective,
using them for MD simulations is usually unlikely to incur any noticeable
loss of accuracy above the statistical uncertainties of the simulation.
2.3.1 MD NVE ensemble
The NVE ensemble is the natural ensemble to conduct MD because the appli￾cation of Newton’s laws results in the conservation of energy. In addition,
momentum (P 5 0) is also conserved in MD, which means that strictly
speaking MD simulations are conducted in an NVEP ensemble. Meier and
Kabelac (2006) observed that the MD NVEP ensemble also conserves
another vectorial quantity (G) that is related to the initial position of the cen￾ter of mass, which means that we are dealing with an NVEPG ensemble.
The fundamental equation of state for the system in the (Meier and
Kabelac, 2006) NVEPG ensemble is obtained from the entropy postulate,
S ð N; V; E ; P ; GÞ 5 k ln Ω ðN; V; E ; P ; G Þ; ð2:31Þ
where Ω ðN; V; E ; P ; G Þ is the phase-space volume. The basic phase-space
functions can be expressed via abbreviations that represent the derivatives of
the phase-space volume with respect to the independent thermodynamic state
variables,
Ω m n 5 1
ω
@m1n Ω
@Em @Vn ; ð2:32Þ
30 Molecular Simulation of Fluidswhere ω is the phase-space density. The general expression is given (Meier
and Kabelac, 2006) by,
Ω m n 5 N
V
0
@
1
A
n
1
Nn ð Þ 21 m 2
F 2 d 2F2d
2
0
@
1
A
m
ð21Þ
n
ð Þ 2½  N21 n K2ð Þ m21  
1 ð Þ 1 1 δ0n
Xn
i51
n
i

 ð21Þ
n2i
ð Þ 2½  N21 n2i
N
V
0
@
1
A
n2i
1
Nn2i
3
2
F 2 d
X
i
l51
ð21Þ
m1l 2F2d
2
0
@
1
A
m1l
K2ðm1l21Þ
kmaxX
ði; lÞ
k51
cilkWilk * + !
ð2:33Þ
which involves the ensemble averages of products of powers of the kinetic energy
K 5 E 2 U rN   and of volume derivatives of the potential energy @n
U=@ Vn. In
Eq. (2.33), the total number of degrees of freedom is F 5 fN as used previously for
the conventional fluctuation formulas; ð Þ x n 5 x ð x 1 1Þ ð x 1 2Þ ... ð x 1 n 2 1Þ
represents the Pochhammer symbol with ð Þ x 0 5 1 and δij is the Kronecker delta
(Abramowitz and Stegun, 1972); cilk Wilk is a product of certain volume derivatives
of the potential energy Wilk 5 ð2 @i
U=@Vi
Þ ð2 @k
U=@VkÞ ... and of multino￾mial coefficients cilk described in detail elsewhere (Lustig, 1994a). The (Fd)/2
terms accounts for the contribution of the kinetic energy minus the momentum con￾straint in d dimensions. For molecules it should be replaced by a term that reflects
the additional degrees of freedom. The volume derivatives of nth order for the
potential energy are given by,
@n
U
@Vn 5 1
3nVn
X
N21
i51
X
N
j5i11
Xn
k51
an k r
k
ij
@k
u
@rk
ij
; ð2:34Þ
where u is the pair potential energy and ri j denotes the distance between par￾ticles i and j. A recursion relationship (Lustig, 1994a) is used to determine
the a n k coefficients.
The key thermodynamic quantities obtained from this approach are sum￾marized in Table 2.4. The remaining thermodynamic quantities can be
obtained by using the relationships given in Eq. (2.24). It should be noted
that this approach provides us with useful relationships for both T and p.
The Ωnm terms can be evaluated from Eqs. (2.35) to (2.39):
Ω00 5 kT 5 2
F 2 d h i K ð2:35Þ
Ω10 5 1 ð2:36Þ
Ω01 5 N 2 1
V
kT 2 @U
@V
  ð2:37Þ
Ensembles, thermodynamic averages, and particle dynamics Chapter | 2 31Ω11 5 N 2 1
V
1 1 2 F 2 d
2
 	 K21 @U
@V
  
  ð2:38Þ
Ω20 5 2 1 2 F 2 d
2
 	 K21   ð2:39Þ
For N atoms, each with 3 degrees of translational freedom, F 5 3N and
d 5 3.
This approach has been used to evaluate the thermodynamic properties for
a wide variety of cases. Examples include simple potentials (Lustig, 1998;
Mausbach and Sadus, 2011); polarizable water models (Shvab and Sadus,
2013); supercritical fluids (Yigzawe and Sadus, 2013); and binary mixtures
(Shvab and Sadus, 2014; Stiegler and Sadus, 2015). The ease of integrating
this approach into a conventional NVE MD algorithm (Chapter 10) provides a
very compelling argument that it should be the method of choice for determin￾ing thermodynamic quantities from molecular simulation. The only significant
limitation is that it requires the potential to be differentiable at all separations,
which means it cannot be used for discontinuous potentials. For discontinuous
potentials, the traditional fluctuation formulas continue to have a useful role.
The fluctuation formulas are also independent of the simulation method. That
is, the same fluctuation formulas are valid for both MC and MD simulations.
2.3.2 MC NVT ensemble
In the same way that the NVE ensemble is the natural ensemble of MD, the
MC method is most easily implemented (Chapter 9) in the NVT ensemble.
Lustig (2011, 2012) extended the approach for MC simulations in the NVT
ensemble. The extension makes use of the MassieuPlanck system of ther￾modynamics (Mu¨nster, 1970), and proceeds from the entropy form of the
TABLE 2.4 Relationships for the key thermodynamic quantities in terms of
phase-space functions for the NVEPG MD ensemble.
Quantity Formula in terms of Ωnm
T Ω 00
k
p Ω 01
CV k ð Þ 12Ω 00 Ω 20 21
γV k Ω 11 2 Ω 01 Ω 20
1 2 Ω 00 Ω 20
β21
T V Ω01ð Þ 2 Ω11 2 Ω01Ω20 2 Ω00Ω112
1 2 Ω00Ω20
2 Ω02  	
32 Molecular Simulation of Fluidsfundamental equation S Eð Þ ; V;N to the Helmholtz energy A=T 1=T; V;N  
via successive Legendre transformations. The outcome, as illustrated below,
is that any thermodynamic property can be obtained in terms of the partial
derivatives of the Helmholtz function. The relevant statistical mechanics
relationship is,
2βAð Þ β; V; N 5 lnZð Þ β; V;N ; ð2:40Þ
where Z is a partition function that depends on N, T, and V. Eq. (2.40) is
the NVT ensemble analog of Eq. (2.31) and all thermodynamic properties
can be obtained from combinations of partial derivatives of the partition
function:
Zmn 5 1
Z
@m1n
Z
@βm@Vn ð2:41Þ
The key thermodynamic relationships (Lustig, 2011) in terms of Znm are
summarized in Table 2.5.
The values of Znm can be evaluated from the following relationships.
Z01 5 N
V 2 β @U
@V
  ð2:42Þ
Z10 5 2 F
2 β21 2 h i U ð2:43Þ
Z02 5 N
V

 2
1 2 1
N

  1 2β N
V 2 @U
@V
  1 β 2 @2
U
@V2
  1 β2 @U
@V

 2 * +
ð2:44Þ
Z20 5 F
2
F
2
1 1

 β22 1 Fβ21
h i U 1 U2   ð2:45Þ
TABLE 2.5 Relationships for the key thermodynamic quantities in terms of
derivatives of the partition function for the MC NVT ensemble.
Quantity Formula in terms of Znm
CV Z20 2 Z2
10
NkT2
γV kZ01 2 ð Þ Z11 2 Z01Z10
T
β21
T 2kTV Z02 2 Z2
01  
Ensembles, thermodynamic averages, and particle dynamics Chapter | 2 33Vlasiuk et al. (2016) observed that these relationships need to be modi￾fied by the special case for which there is a temperature dependence in the
intermolecular potential. The partition function involving a temperature￾dependent potential u qð Þ ; β is,
Z~ð Þ β; V;N ~β2F=2
ð
... ð
e2βu qð Þ ;β dq; ð2:46Þ
where the tilde sign indicates the temperature dependence. There are no
changes to the terms Z~
01 5 Z01 and Z~
02 5 Z02 that are the result of the deriva￾tives of the partition function with respect to the volume. However, ensemble
averages that involve differentiation with respect to β are affected:
Z~
10 5 1
Z~
@Z~
@β
Z~
11 5 1
Z~
@2
Z~
@β @V
Z~
20 5 1
Z~
@2
Z~
@β2
9
>>>>>>>>>>=
>>>>>>>>>>;
ð2:47Þ
Applying the relationships in Eq. (2.47) yields:
Z~
10 5 2 F
2 β21 2 U 1 β @U
@β
  ð2:48Þ
Z~
11 5 2 F
2 β21 N
V 2 N
V
U 1 β @U
@β
* + 1
F
2 2 1
0
@
1
A
@U
@V
* +
2 β @2
U
@V @β
* + 1 β @U
@V
U 1 β @U
@β
0
@
1
A
* +
ð2:49Þ
Z~
20 5 F
2
F
2
1 1
0
@
1
Aβ22 1 Fβ21 U 1 β @U
@β
* +
1 U1β @U
@β
0
@
1
A
* +2
2 2
@U
@β
1 β @2
U
@β2
* + ð2:50Þ
This approach has proved useful for the evaluation of the thermodynamic
properties of neon (Vlasiuk et al., 2016) and other noble gases (Vlasiuk and
Sadus, 2017). It is of interest to note that the formula for Cv (Table 2.2) is
equivalent to the determination of this property from the fluctuation approach.
However, this is not the case for the other thermodynamic properties.
34 Molecular Simulation of Fluids2.3.3 MC NpT ensemble
Stro¨ker et al. (2021) have extended Lustig’s approach to the NpT ensemble.
In common with the NVT case, thermodynamic quantities can be obtained in
terms of partial derivatives of the phase-space functions (Znm).
Zmn 5 1
Z
@m1n
Z
@βm@pn ð2:51Þ
The key thermodynamic quantities as expressed by combinations of Znm
are summarized in Table 2.6.
The Znm contributions can be evaluated from,
Z01 5 2 βh i V ð2:52Þ
Z10 5 2 F
2β 2 h i Hr ð2:53Þ
Z02 5 β2 V2   ð2:54Þ
Z20 5 F2
4β2 1
F
2β2 1
F Hh ir
β
1 H2
r
 ; ð2:55Þ
where Hr 5 U 1 pV is the residual enthalpy. Inserting Eqs. (2.52) to (2.55)
for the thermodynamic quantities given in Table 2.6 yields equivalent rela￾tionships to that obtained for the fluctuation approach (Brown, 1958; Hill,
1986). In contrast to both the NVE and NVT ensembles, the evaluation of the
thermodynamic properties in the NpT ensemble do not require knowledge of
the volume derivatives of U.
Following the procedure of Vlasiuk et al. (2016) detailed above for the NVT
ensemble, Stro¨ker et al. (2021) also reported the evaluation of Znm for
TABLE 2.6 Relationships for the key thermodynamic quantities in terms of
derivatives of the partition function for the MC NpT ensemble.
Quantity Formula in terms of Znm
Cp Z20 2 Z2
10
kT2
γV 2 Z01 2 βð Þ Z11 2 Z10Z01
T Z02 2 Z2
01  
β21
T 2 Z01
Z02 2 Z2
01
Ensembles, thermodynamic averages, and particle dynamics Chapter | 2 35temperature-dependent potentials. In common with the NVT case, Z~
01 5 Z01 and
Z~
02 5 Z02, whereas the remaining terms can be evaluated from:
Z~
10 5 2 F
2 β21 2 U 1 β @U
@β
1 pV   ð2:56Þ
Z~
11 5 F
2 2 1

 h i V 1 β U 1 β @U
@β
1 pV 
 V
  ð2:57Þ
Z~
20 5 F
2
F
2
1 1
0
@
1
Aβ22 1 Fβ21 U 1 β @U
@β
1 pV * +
1 U1β @U
@β
1pV
0
@
1
A
* +2
2 2
@U
@β
1 β @2
U
@β2
* +
ð2:58Þ
The convenience of using the NpT ensemble suggests that the approach
will be helpful in the future (Nitzke and Vrabec, 2023; Young et al., 2023).
2.3.4 MC µVT ensemble
Using a procedure (Stro¨ker and Meier, 2021) that is analogous to the NVT and
NpT cases, all thermodynamic properties for μVT ensemble can be obtained from
combinations of partial derivatives of the grand canonical partition function (ψ):
ψnmo 5 1
ψ
@m1n1o
ψ
@βm@Vn@μo ð2:59Þ
However, in contrast to the other ensembles there are now derivatives with
respect to all three independent variables, with the special case of ψ000 5 1. The
key thermodynamic relationships (Stro¨ker and Meier, 2021) in terms of ψnmo
are summarized in Table 2.7.
The ψnmo contributions can be evaluated from:
ψ100 5 μ 2 f
2kT 
 h i N 2 h i U ð2:60Þ
ψ200 5 μ2 f
2kT 
 2
N2   2 f Nh i
2ðkTÞ
2 1 f
kT 2 2μ

 h i NU 1 U2   ð2:61Þ
ψ010 5 h i N
V 2 1
kT
@U
@V
  ð2:62Þ
ψ020 5 N2  
V2 2 h i N
V2 2 2
kTV N
@U
@V
  2 1
kT
@2
U
@V2
  1
1
ðkTÞ
2
@U
@V

 2 * + ð2:63Þ
36 Molecular Simulation of Fluidsψ001 5 h i N
kT ð2:64Þ
ψ002 5 N2  
ð Þ kT 2 ð2:65Þ
ψ110 5 μ 2 f
2kT
0
@
1
A
N2  
V
1 f
2 2 μ
kT
0
@
1
A N
@U
@V
* + 2 h i NU
V 2 @U
@V
* + 1
1
kT U
@U
@V
* + ð2:66Þ
ψ101 5 μ
kT 2 f
2

  N2   1 h i N 2 h i NU
kT ð2:67Þ
ψ011 5 N2  
kTV 2 1
ðkTÞ
2 N
@U
@V
  ð2:68Þ
It should be noted that the generalization to any number of degrees of
freedom in the above equations involves simply f and not F 5 fN.
2.3.5 MC NpH ensemble
Stro¨ker and Meier (2022) further extended Lustig’s approach for the NpH
ensemble, for which the thermodynamic properties are obtained from deriva￾tives of phase-space functions (Ωnm).
Ωnm 5 1
ω
@m1n
Ω
@Hm@pn ð2:69Þ
TABLE 2.7 Relationships for the key thermodynamic quantities for the
MC μVT ensemble in terms of derivatives of the partition.
Quantity Formula in terms of ψnmo
CV ψ200 2 ψ2
100
kT2 2 k ψ0012 ψ1012ψ100ψ001  =kT  2
ψ002 2 ψ2
001
γV kψ010 2 ψ110 2 ψ100ψ010  =T
2 ψ011 2 ψ010ψ011   kψ001 2 ψ101 2 ψ100ψ001  =T  
ψ002 2 ψ2
001
β21
T 2kTV ψ020 2 ψ2
010 2 ψ0112ψ010ψ001  2
ψ002 2 ψ2
001 !
Ensembles, thermodynamic averages, and particle dynamics Chapter | 2 37Eq. (2.69) contains the special cases of Ω10 5 1 and Ω00 5 Ω=ω, where ω
is the phase-space density. The evaluation of the thermodynamic averages
can be determined in two different ways that depends on whether entropy is
defined in terms of either the phase-space volume or density. The two routes
are completely equivalent. However, the relationships for the phase-space
volume route have the advantage of being slightly algebraically simpler and
these are summarized in Table 2.8. In this case, Cp has a particularly simple
definition and Cv can be easily obtained from the first relationship in
Eq. (2.24).
The Ωnm contributions required in Table 2.8 can be evaluated from:
Ω00 5 2 H 2 U 2 pV  
F ð2:70Þ
Ω20 5 ðF=2 2 1Þ 1
H 2 U 2 pV   ð2:71Þ
Ω01 5 2 h i V ð2:72Þ
Ω02 5 ðF=2 2 1Þ V2
H 2 U 2 pV   ð2:73Þ
Ω11 5 ð1 2 F=2Þ V
H 2 U 2 pV   ð2:74Þ
In Eqs. (2.70)(2.74), the quantity HUpV can be interpreted as the instanta￾neous kinetic energy. In common with the NpT ensemble (Eqs. 2.522.55), the
contributions to the ensembles required in Eqs. (2.70)(2.74) are relatively simple.
Stro¨ker and Meier (2022) observed a sizeable N-dependency for the Lennard-Jones
potential, requiring an extrapolation procedure to obtain results for N - N.
TABLE 2.8 Relationships for the key thermodynamic quantities for the
MC NpH ensemble in terms of derivatives of the phase-space function
using the phase-volume definition of entropy.
Quantity Formula in terms of Ωnm
Cp k
1 2 Ω00Ω20
γV kðΩ11 2 Ω20Ω01Þ
ð1 2 Ω00Ω20ÞðΩ11Ω01 2 Ω02Þ 2 ðΩ01 2 Ω00Ω11ÞðΩ20Ω01 2 Ω11Þ
βT Ω11 2 Ω02
Ω01
2 Ω20 2 Ω11
Ω01 
  Ω01 2 Ω00Ω11
1 2 Ω00Ω20
38 Molecular Simulation of Fluids2.4 Particle dynamics
2.4.1 Motion of unconstrained particles
For a single particle, Newton’s second law of motion is,
F 5 mr€ ð2:75Þ
where F is the total force acting on the particle, m is the mass of the particle,
and €r is the second time derivative of the position vector r. All derivatives
below are with respect to time unless otherwise indicated. In a simulation,
we are normally interested in many particles and Eq. (2.75) can be easily
generalized for a system containing many particles (Goldstein et al., 2002).
It is useful to distinguish between external forces (Fe
) acting on the particles
from outside the system (e.g., walls of a container) and internal forces (Fij)
caused by interparticle interaction. In this case, the particles are atoms and
molecules are treated as a constrained set of atoms. Consequently, Newton’s
second law of motion for particle i becomes
X
j
Fji 1 Fe
i 5 mir€i ð2:76Þ
and summing over all particles, we obtain:
X
j . i
X
i
Fji 1 XFe
i 5 Xmir€i ð2:77Þ
The first sum in Eq. (2.77) must vanish as a consequence of Newton’s
second law, which requires that every action has an equal and opposite reac￾tion, that is, each pair Fij 1 Fji is zero. The second summation is simply the
total external force (Fe
), consequently:
Fe 5 X
i
mir€i ð2:78Þ
2.4.2 Motion of constrained particles
2.4.2.1 Holonomic and nonholonomic constraints
The above treatment assumed that the particles are unconstrained in their move￾ment. However, in most realistic systems, constraints are typically in operation.
For example, gas atoms enclosed in a container are constrained by the walls of
the container to move only inside it. A rigid body, defined as a system of parti￾cles in which the interparticle distances are fixed and cannot vary with time, is
another example of a constrained system. Formally, we can distinguish between
holonomic and nonholonomic constraints (Goldstein et al., 2002). Holonomic
systems have constraints that can be expressed as equations connecting the coor￾dinates of the particles of the type:
fðr1; r2; r3. . .. . .:tÞ 5 0 ð2:79Þ
Ensembles, thermodynamic averages, and particle dynamics Chapter | 2 39The constraints of a rigid body are holonomic because they can be formu￾lated as:
ðri2rjÞ
2 2 c2
ij 5 0 ð2:80Þ
For example, the implication of Eq. (2.80) for a diatomic molecule is that
there is no breakage of the bond between the two atoms.
Other constrains such as the wall of a container, which cannot be
expressed in terms of Eq. (2.79), are referred to as nonholonomic constraints.
Strictly speaking, nonholonomic constraints can only be treated on a case￾by-case basis. Fortunately, nonholonomic constraints often only apply on a
macroscopic level, whereas molecular simulation is primarily concerned with
the atomic or molecular scale. The wall of a container that imposes a nonho￾lonomic constraint on a macroscopic level can be treated as a holonomic
constraint at the atomic or molecular level. In reality, the container wall is
composed of atoms or molecules that exert definite forces and the notion of
constraint is somewhat artificial. Consequently, if a constraint is present it is
typically assumed to be holonomic.
2.4.2.2 Consequences of constraints on particles
The presence of constraints imposes two difficulties for particle mechanics.
First, the coordinates (ri) are not all independent because they are connected
by the equations of the constraint. Therefore the equations of motion are not
all independent. Second, the forces of the constraint, for example, the effect
of the wall on the gas particles, are not known beforehand. Instead, they are
one of the unknowns of the problem being investigated.
For holonomic constraints, the first difficulty is solved by using gener￾alized coordinates. In the absence of constraints, a system of N particles
has 3N independent coordinates or degrees of freedom. If there are k con￾straints expressed in terms of Eq. (2.79), the number of independent coor￾dinates or degrees of freedom is reduced to 3Nk. Consequently, a total
of 3Nk independent variables (q1..... q3Nk) in terms of the old coordi￾nates (r1.. . .. . . rN) are introduced and expressed by equations of the form
(Goldstein et al., 2002):
r1 5 r1ðq1; q2:...q3N2k; tÞ
:
:
rN 5 rNðq1; q2:...q3N2k; tÞ
9
>>>=
>>>;
ð2:81Þ
To overcome the difficulty that the forces of constraint are unknown
beforehand, we can re-formulate the mechanics in such a way that the forces
of the constraint disappear. The resulting equations are the Lagrange and/or
Hamilton equations of motion.
40 Molecular Simulation of Fluids2.4.2.3 Lagrange equations of motion
It is useful to introduce the concept of a virtual displacement (Goldstein et al.,
2002). A virtual displacement is an infinitesimal change in coordinates (δr),
which is consistent with the forces and constraints imposed on the system at the
time. Unlike an actual displacement, there is no possibility of any change in the
force of constraint. When the system is at equilibrium, Fi 5 0 and the virtual
work (FiUδri) resulting in the virtual displacement also vanishes. Similarly, the
sum of the virtual work over all particles is also zero.
X
i
FiUδri 5 0 ð2:82Þ
The force (Fi) has contributions from both the applied force (Fi
a
) and the
force of constraint (fi).
Fi 5 Fa
i 1 fi ð2:83Þ
Substituting Eq. (2.83) into Eq. (2.82), we obtain:
X
i
Fa
i Uδri 1 X
i
fiUδri 5 0 ð2:84Þ
For many systems the virtual work of the forces of constraint is zero. In
these cases, the condition for equilibrium involves only the applied forces.
X
i
Fa
i Uδri 5 0 ð2:85Þ
Eq. (2.85) is the principle of virtual work (Goldstein et al., 2002). In
general, Fa
i 6¼ 0 because δri is not completely independent but is connected
by the constraints. Therefore a transformation is required such that the coef￾ficients of δr are zero. Newton’s equations of motion (Eq. (2.75)) for each
particle can be rewritten as
Fi 2 p_i 5 0; ð2:86Þ
where pi 5 mir_i. Consequently, we can formulate the following alternative to
Eq. (2.82) for the equilibrium condition.
X
i
ðFi 2 p_iÞUδri 5 0 ð2:87Þ
By decomposing force into applied and constraint components, we obtain:
X
i
ðFa
i 2 p_iÞUδri 1 X
i
fiUδri 5 0 ð2:88Þ
If there is no virtual work from the forces of constraint, then:
X
i
ðFa
i 2 p_iÞUδri 5 0 ð2:89Þ
Ensembles, thermodynamic averages, and particle dynamics Chapter | 2 41Eq. (2.89) is known as D’Alembert’s principle (Goldstein et al., 2002).
The forces of constraint do not appear in Eq. (2.89) and the coefficients of
δri are zero as required. To make Eq. (2.89) useful, we can transform the vir￾tual displacements to generalized coordinates that are independent of each
other. Using the relationship,
ri 5 riðq1; q2. . .. . .:qn; tÞ ð2:90Þ
and assuming n independent coordinates, it can be shown (Goldstein et al.,
2002; Mach, 1960) that Eq. (2.89) can be transformed to,
X
j
d
dt
@K
@q_j
 ! 2 @K
@qj
( ) 
  2 Qj
" #δqj 5 0; ð2:91Þ
where Qj are the components of the generalized force defined by,
Qj 5 X
i
FiU
@ri
@qj
; ð2:92Þ
where the superscript a has been omitted from the force term. If the con￾straints are assumed to be holonomic, the qj terms are independent of each
other. Because δqj is independent of δqk, Eq. (2.91) will only be satisfied if
the coefficients vanish, that is,
d
dt
@K
@q_j
 ! 2 @K
@qj
5 Qj; ð2:93Þ
where there are n such equations.
Eq. (2.93) are the Lagrange equations (Goldstein et al., 2002; Calkin, 1996)
for the general case where the forces are not derivable from a potential.
However, the forces are commonly derivable from a potential function V:
Fi 5 2 riV ð2:94Þ
Consequently, the generalized forces can be obtained from,
Qj 5 2 X
i
riVU
@ri
@qj
ð2:95Þ
which is identical to the partial derivative of a function V(r1..... rN) with
respect to qj.
Qj 5 2 @V
@qj
ð2:96Þ
Substituting Eq. (2.96) into Eq. (2.93), we obtain:
d
dt
@K
@q_j
 ! 2 @ðK 2 VÞ
@qj
5 0 ð2:97Þ
42 Molecular Simulation of FluidsV is completely independent of the generalized velocity because it is a
function only of position. Therefore it can be included in the partial deriva￾tive with respect to q_.
d
dt
@ðK 2 VÞ
@q_j
 ! 2 @ðK 2 VÞ
@qj
5 0 ð2:98Þ
If we define a new function, the Lagrangian L as,
L 5 K 2 V ð2:99Þ
Eq. (2.98) becomes:
d
dt
@L
@q_j
 ! 2 @L
@qj
5 0 ð2:100Þ
Eq. (2.100) is the familiar form of the Lagrange equations (Goldstein et al.,
2002; Calkin, 1996).
The advantage of the Lagrange function is that the need to use vector
forces in Newton’s equations of motion is replaced by the scalar functions of
K and V. Any problem of mechanics can be transferred to the Lagrangian
coordinates by writing K and V in generalized coordinates, hence obtain L
and substitute it into Eq. (2.100). For example, for the motion of a particle in
Cartesian coordinates x, y, and z, we obtain L 5 mðx_
2 1 y_
2 1 z_
2Þ=2 2 V.
Substituting this into Eq. (2.100), we find that,
Fx 5 @V
@x 5 mx€
Fy 5 @V
@y 5 my€
Fz 5 @V
@z 5 mz€
9
>>>>>>>>>=
>>>>>>>>>;
ð2:101Þ
which are Newton’s equations of motion.
2.4.2.4 Hamilton equations of motion
The Lagrangian formulation is a description of mechanics in terms of gener￾alized coordinates and velocity, with time as a parameter. In contrast, the
Hamilton equations of motion use generalized coordinates and generalized
momenta as the independent variables. The generalized momentum (pi) is
defined as (Goldstein et al., 2002; Calkin, 1996):
pi 5 @Lðqj; q_i; tÞ
@q_i
ð2:102Þ
Ensembles, thermodynamic averages, and particle dynamics Chapter | 2 43The change in independent variables can be achieved by using a Legendre
transformation, which results in the definition of the Hamiltonian (H) function.
Hðp; q; tÞ 5 X
i
q_ipi 2 Lðq; q_i; tÞ ð2:103Þ
The differential of H as a function of only p, q, and t is:
dH 5 X
i
@H
@qi
dqi 1 X
i
@H
@pi
dpi 1
@H
@t
dt ð2:104Þ
In addition, from Eq. (2.100) we can also obtain:
dH 5 X
i
q_idpi 1 X
i
pidq_i 2 X
i
@L
@ qi
:
dq_i 2 X
i
@L
@ qi
dqi 2 @L
@t
dt ð2:105Þ
The terms in Eq. (2.105) involving dq_i cancel because of the following
definition of generalized momentum,
X
i
pidq_i 2 X
i
@L
@q_i
dq_i 5 0 ð2:106Þ
and from the Lagrange equations we have:
@L
@qi
5 p_i ð2:107Þ
Consequently, Eq. (2.105) becomes:
dH 5 X
i
q_idpi 2 X
i
p_idqi 2 @L
@t
dt ð2:108Þ
Comparing Eq. (2.108) with Eq. (2.104) we obtain the following 2n 1 1
relationships (Goldstein et al., 2002):
q_i 5 @H
@pi
ð2:109Þ
p_i 5 2 @H
@qi
ð2:110Þ
@L
@t 5 2 @H
@t ð2:111Þ
Eqs. (2.109)(2.111) are referred to as Hamilton’s canonical equations of
motion (Goldstein et al., 2002). In general, problems in mechanics can be
solved by determining the Lagrangian using Eq. (2.102) to determine the
momenta and hence formulate the Hamiltonian from Eq. (2.103).
Substituting the Hamiltonian obtained from this procedure into
Eqs. (2.109)(2.111) yields first-order equations of motion.
44 Molecular Simulation of FluidsIf the Hamiltonian is not explicitly a function of time, it can be shown that the
Hamiltonian is constant with respect to motion. Furthermore, if the potential is
independent of velocity and the equations that define the generalized coordinates
(Eq. (2.77)) are not explicitly time-dependent, the Hamiltonian is the total energy.
H 5 K 1 V ð2:112Þ
For the cases when Eq. (2.112) is valid, the equations of motion can be
obtained directly by substituting the right-hand side of Eq. (2.112) into
Eqs. (2.109)(2.111).
2.4.2.5 Gauss’s principle of least constraint
In 1829, Gauss (Mach, 1960) formulated an alternative to Newtonian dynam￾ics by applying a least squares technique to mechanical properties. He postu￾lated that any mechanical constraint on a system should be satisfied by using
the smallest constraint force. If we have the following constrained equation
of motion:
mr€ 5 F 1 Fc ð2:113Þ
Gauss’s principle of least constraint states that the constrained forces Fc
should be as small as possible, that is, the following summation should have
a minimum value.
X
i
F2
c;i
2mi
ð2:114Þ
Evans et al. (1983) “re-discovered” Gauss’s principle showing how it could
be made useful for numerical calculations. For either holonomic constraints (g
(r,t) 5 0) or nonholonomic constraints (g(r,_r,t) 5 0), the acceleration is confined
to lie on a constant-g hypersurface by the restriction of the form:
nðr; r_; tÞUr€ 1 wðr; r€; tÞ 5 0 ð2:115Þ
In the absence of any constraints, the unconstrained motion of the system
calculated from,
mr€ u 5 F ð2:116Þ
could leave the constraint hypersurface. This is prevented in Gauss’s formu￾lation by the addition of an acceleration normal to the surface, that is,
r€ c 5 r€ u 2 λ nðr; r_; tÞ
m ð2:117Þ
with the Lagrange multiplier, λ, satisfying the restriction given by Eq. (2.118).
λ 5 nUr€ u 1 w
nUðn=mÞ ð2:118Þ
Ensembles, thermodynamic averages, and particle dynamics Chapter | 2 45The added acceleration can also be expressed in terms a constrained
force (Fc).
r€ c 5 F 1 Fc
m 5 F
m 2 λ n
m ð2:119Þ
2.4.3 The Liouville equation
From the perspective of molecular simulation or statistical mechanics the N
particles form a single mechanical system and the concept of phase space is
used routinely to visualize the changing state of the system. Phase space can
be defined as the Cartesian space of 6N dimensions. The 6N dimensions of
phase space are composed of the 3N generalized configurational coordinates
(qi) and the 3N momenta (pi). A point in phase space describes completely
the dynamical state of the system. The change with time of any point of the
system traces out the trajectory of the system as governed by Hamilton’s
canonical equations.
The change in a property of the system F 5 F(qi, pi, t), which depends
both on the dynamical state of the system and explicitly on time can be
obtained from (Hirschfelder et al., 1954):
DF
Dt 5 @F
@t
1 X
i
@F
@qi
q_ 1
@F
@pi
p_

  ð2:120Þ
5 @F
@t
1 X
i
@F
@qi
@H
@pi
2 @F
@pi
@H
@qi

  ð2:121Þ
5 @F
@t
1 ½  F; H ð2:122Þ
Eq. (2.122) introduces the use of the Poisson bracket. Any constant of
motion (α) such as the total energy or total linear momentum has the prop￾erty that:
½  α; H 5 0 ð2:123Þ
The state of the entire collection of systems, which do not interact and
differ from each other only in their initial conditions, can be represented by
a set of points. The set of representative points is obtained from a continuous
distribution function (ρ(qi, pi, t)), which is referred to as the density in phase
space. The distribution function must satisfy the following relationship
(Hirschfelder et al., 1954) because there are neither sources nor sinks for
phase points:
@ρ
@t
1 X
i
@
@qi
ðq_ρÞ 1
@
@pi
ðp_ρÞ

  5 0 ð2:124Þ
46 Molecular Simulation of FluidsFrom Eq. (2.124), using Hamilton’s canonical equations and the definition of
the Poisson bracket, we obtain the Liouville equation (Hirschfelder et al., 1954):
Dρ
Dt 5 @ρ
@t
1 ½  ρ; H 5 0 ð2:125Þ
Eq. (2.125) is important for the development of statistical mechanics, in
particular, the definition of statistical ensembles (Section 2.1.1).
2.4.4 The virial theorem
An interesting consequence of the equations of motion is that they can be used
to derive the virial theorem (Hirschfelder et al., 1954). The equations of motion
for a system of particles with position vectors (ri) and applied forces (Fi) are:
p_i 5 Fi ð2:126Þ
We also define a quantity:
G 5 X
i
piUri ð2:127Þ
The total time derivative of G is:
dG
dt 5 X
i
r_iUpi 1 X
i
p_iUri ð2:128Þ
The first term of the right-hand side of Eq. (2.128) is simply twice the kinetic
energy (2K), and from Eq. (2.126) the second summation can be evaluated as:
X
i
p_iUri 5 X
i
F_iUri ð2:129Þ
Consequently, Eq. (2.128) becomes:
d
dt
X
i
p_iUri 5 2K 1 X
i
F_iUri ð2:130Þ
The time average of Eq. (2.130) over a time interval (τ) is obtained by
integrating both sides with respect to t from 0 to τ, and dividing by τ:
2K 1X
i
FiUri 5 1
τ
½  GðτÞ 2 Gð0Þ ð2:131Þ
As τ-N we obtain (Hirschfelder et al., 1954):
K 5 2 1
2
X
i
FiUri ð2:132Þ
Eq. (2.132) is the virial theorem, which is used frequently in statistical
mechanics and applications of molecular simulation.
Ensembles, thermodynamic averages, and particle dynamics Chapter | 2 472.5 Summary
The statistical mechanics definition of the ensemble determines the overall
nature of either a MC or MD simulation. It also determines the strategy required
to determine thermodynamic averages of various properties. Traditionally, ther￾modynamic properties have been evaluated via ensemble fluctuations, requiring
post simulation analysis. However, alternative methods are available that can be
used during the course of the simulation itself. Knowledge of particle dynamics
is used to determine the equations of motion required for MD simulations in
various ensembles. The influence of the choice of ensemble on MC and MD
simulations is examined in Chapter 9.
References
Abramowitz, M., Stegun, I.A. (Eds.), 1972. Handbook of Mathematical Functions with Formula,
Graphs and Mathematical Tables. Dover, New York, p. 256.
Adams, D.J., 1975. Grand canonical ensemble Monte Carlo for a Lennard-Jones fluid. Mol.
Phys. 29, 307311.
Allen, M.P., Tildesley, D.J., 2017. Computer Simulation of Liquids, second ed. Oxford
University Press, Oxford.
Bosko, J., Todd, B.D., Sadus, R.J., 2005. Molecular simulation of dendrimers and their mixtures
under shear: comparison of isothermal-isobaric (NpT) and isothermal-isochoric (NVT)
ensemble systems. J. Chem. Phys. 123, 034905.
Brown, W.B., 1958. Constant pressure ensembles in statistical mechanics. Mol. Phys. 1, 6882.
Calkin, M.G., 1996. Lagrangian and Hamiltonian Mechanics. World Scientific, Singapore.
Elliot, J.R., Diky, V., Knotts IV, T., Wilding, W. V. 2023. Properties of Gases and Liquids, 6th
ed. McGraw Hill, New York.
Evans, D.J., Hoover, W.G., Failor, B.H., Moran, B., Ladd, A.J.C., 1983. Nonequilibrium molecu￾lar dynamics via Gauss’s principle of least constraint. Phys. Rev. A 28, 10161021.
Fowler, R., Guggenheim, E.A., 1956. Statistical Thermodynamics: A Version of Statistical
Mechanics for Students of Physics and Chemistry. Cambridge University Press, Cambridge.
Frenkel, D., 1986. In: Ciccotti, G., Hoover, W.G. (Eds.), Molecular Dynamics Simulations of
Statistical Mechanical Systems. North-Holland, Amsterdam.
Friedman, A.S., Haar, L., 1954. High-speed machine computation of ideal gas thermodynamic
functions. I. Isotopic water molecules. J. Chem. Phys. 22, 20512058.
Garrod, C., 1995. Statistical Mechanics and Thermodynamics. Oxford University Press, New
York.
Goldstein, H., Poole, C., Safko, J., 2002. Classical Mechanics, third ed. Addison Wesley, San Francisco.
Haile, J.M., 1992. Molecular Dynamics Simulation. Elementary Methods. John Wiley & Sons,
New York.
Hansen, J.P., McDonald, I.R., 2013. Theory of Simple Liquids, fourth ed. Academic Press,
Amsterdam.
Henderson, J.R., 1983. Statistical mechanics of fluids at spherical structureless walls. Mol. Phys.
51, 741761.
Hill, T.L., 1986. An Introduction to Statistical Thermodynamics. Dover Publications, New York.
Hill, T.L., 1987. Statistical Mechanics. Principles and Selected Applications. Dover Publications,
New York.
48 Molecular Simulation of FluidsHirschfelder, J.O., Curtiss, C.F., Bird, R.B., 1954. Molecular Theory of Gases and Liquids. John
Wiley & Sons, New York.
Hoheisel, C., 1994. Transport properties of molecular liquids. Phys. Rep. 245, 111157.
Hoover, W.G., 1986. Molecular Dynamics. Springer-Verlag, Berlin.
Hoover, W.G., 1991. Computational Statistical Mechanics. Elsevier, Amsterdam.
Lagache, M., Ungerer, P., Boutin, A., Fuchs, A.H., 2001. Prediction of thermodynamic derivative
properties of fluids by Monte Carlo simulation. Phys. Chem. Chem. Phys. 3, 43334339.
Lebowitz, J.L., Percus, J.K., Verlet, L., 1967. Ensemble dependence of fluctuations with applica￾tions to machine computations. Phys. Rev. 153, 250254.
Lemmon, E.W., McLinden, M.O., Wagner, W., 2009. Thermodynamic properties of propane. III.
A reference equation of state for temperatures from the melting line to 650 K and pressures
up to 1000 MPa. J. Chem. Eng. Data 54, 31313180.
Lustig, R., 1994a. Statistical thermodynamics in the classical molecular dynamics ensemble. I.
Fundamentals. J. Chem. Phys. 100, 30483059.
Lustig, R., 1994b. Statistical thermodynamics in the classical molecular dynamics ensemble. II.
Application to computer simulation. J. Chem. Phys. 100, 30603067.
Lustig, R., 1994c. Statistical thermodynamics in the classical molecular dynamics ensemble. III.
Numerical results. J. Chem. Phys. 100, 30683078.
Lustig, R., 1998. Microcanonical Monte Carlo simulation of thermodynamic properties. J. Chem.
Phys. 109, 88168828.
Lustig, R., 2011. Direct molecular NVT simulation of the isobaric heat capacity, speed of sound
and Joule-Thomson coefficient. Mol. Sim. 37, 457465.
Lustig, R., 2012. Statistical analogues for fundamental equation of State derivatives. Mol. Phys.
110, 30413052.
Mach, E., 1960. McCormack, T.J. (Trans.), The Science of Mechanics, sixth ed. The Open Court
Publishing Co., La Salle.
Maitland, G.C., Rigby, M., Smith, E.B., Wakeham, W.A., 1981. Intermolecular Forces: Their
Origin and Determination. Clarendon Press, Oxford.
Mausbach, P., Sadus, R.J., 2011. Thermodynamic properties in the molecular dynamics ensem￾ble applied to the Gaussian core model fluid. J. Chem. Phys. 134, 114515.
Mayer, J.E., Mayer, M.G., 1946. Statistical Mechanics. John Wiley & Sons, New York.
Meier, K., Kabelac, S., 2006. Pressure derivatives in the classical molecular-dynamics ensemble.
J. Chem. Phys. 124, 064104.
Mu¨nster, A., 1970. Halberstadt, E.S. (Trans.), Classical Thermodynamics. John Wiley & Sons,
London, p. 83.
Nitzke, I., Vrabec, J. 2023. Numerical discrimination of thermodynamic Monte Carlo simula￾tions in all eight ensembles J. Chem. Theory Comput. 19, 34602468.
Prausnitz, J.M., de Azevedo, E.G., Lichtenthaler, R.N., 1999. Molecular Thermodynamics of
Fluid-Phase Equilibria, third ed. Prentice Hall, p. 216.
Prigogine, I., Defay, R., 1954. Everett, D.H. (Trans.), Chemical Thermodynamics. Longmans
Green, p. 381.
Raabe, G., 2017. Molecular Simulation Studies on Thermophysical Properties with Application
to Working Fluids. Springer, Berlin.
Rapaport, D.C., 2004. The Art of Molecular Dynamics Simulation, 2nd ed. Cambridge
University Press, Cambridge.
Reed, T.M., Gubbins, K.E., 1973. Applied Statistical Mechanics. Thermodynamic and Transport
Properties of Fluids. Butterworth-Heinemann, Boston.
Reif, F., 1965. Fundamentals of Statistical and Thermal Physics. McGraw-Hill, Tokyo.
Ensembles, thermodynamic averages, and particle dynamics Chapter | 2 49Rowlinson, J.S., 1969. Liquids and Liquid Mixtures, second ed. Butterworth, London, pp. 247258.
Rushbrooke, G.S., 1962. Introduction to Statistical Mechanics. Oxford University Press, London.
Shing, K.S., Chung, S.-T., 1987. Computer simulation methods for the calculation of solubility
in supercritical extraction systems. J. Phys. Chem. 91, 16741681.
Shvab, I., Sadus, R.J., 2013. Intermolecular potentials and the accurate predication of the ther￾modynamic properties of water. J. Chem. Phys. 139, 194505.
Shvab, I., Sadus, R.J., 2014. Thermodynamic properties and diffusion of water 1 methane binary
mixtures. J. Chem. Phys. 140, 104505.
Stiegler, T., Sadus, R.J., 2015. Molecular simulation of fluids with non-identical intermolecular
potentials: thermodynamic properties of 10-5 1 12-6 Mie potential binary mixtures. J.
Chem. Phys. 142, 084504 (2015).
Stro¨ker, P., Meier, K., 2021. Classical statistical mechanics in the grand canonical ensemble.
Phys. Rev. E 104, 014117.
Stro¨ker, P., Meier, K., 2022. Rigorous expressions for thermodynamic properties in the NpH
ensemble. Phys. Rev. E 105, 035301.
Stro¨ker, P., Hellmann, R., Meier, K., 2021. Systematic formulation of thermodynamic properties
in the NpT ensemble. Phys. Rev. E 103, 023305.
Vlasiuk, M., Sadus, R.J., 2017. Ab initio interatomic potentials and the thermodynamic proper￾ties of fluids. J. Chem. Phys. 147, 024505.
Vlasiuk, M., Frascoli, F., Sadus, R.J., 2016. Molecular simulation of the thermodynamic, struc￾tural and vapor-liquid equilibrium properties of neon. J. Chem. Phys. 145, 104501.
Wannier, G., 1987. Statistical Physics. Dover Publications, New York.
Widom, B., 1963. Some topics in the theory of fluids. J. Chem. Phys. 39, 28082812.
Widom, B., 1982. Potential distribution theory and the statistical mechanics of fluids. J. Phys.
Chem. 86, 869872.
Yigzawe, T.M., Sadus, R.J., 2013. Intermolecular interactions and the thermodynamic properties
of supercritical fluids. J. Chem. Phys. 138, 194502.
Young, J. M., Bell, I. H., Harvey, A. H. 2023. Entropy scaling of viscosity for molecular models
of molten salts. J. Chem. Phys. 158, 024502.
50 Molecular Simulation of FluidsChapter 3
Intermolecular pair potentials
and force fields
It is apparent from Chapter 2 that the calculation of any thermodynamic aver￾age requires us to determine the kinetic and potential energies of the system.
In either a Monte Carlo (MC) or molecular dynamics (MD) simulation, the
potential energy of the system or the force acting between molecules is calcu￾lated commonly from a pairwise additive intermolecular potential. The devel￾opment of intermolecular potentials has a long history (Reed and Gubbins,
1973; Maitland et al., 1981; Stone, 2013; Rowlinson, 2002), which predates
the advent of molecular simulation methods. However, except for the simplest
cases, the accuracy of intermolecular potentials for the prediction of thermo￾physical properties can only be evaluated rigorously by molecular simulation.
The terms “intermolecular potential” and “potential model” are often used
interchangeably in the literature. However, strictly speaking the latter should
be reserved for situations that involve modeling assumptions regarding the
nature of interactions describing a particular system. For example, to determine
the properties of a molecule requires an overall model to describe such contri￾butions as bond angles and geometries. The term “force field” is often used to
describe the collection of contributions used to evaluate the terms required by
the model. It is apparent that the different potential models or force fields can
utilize either the same or different intermolecular potentials. If the contribu￾tions of the intermolecular potentials are the same then different outcomes
reflect the different assumptions of the overall model. The simplest potentials
involve interactions between atoms and are correctly described as interatomic
potentials, although distinction between interatomic and intermolecular poten￾tial is not always made with the latter also applied to the former case.
Most intermolecular potentials are exclusively pairwise additive, whereas
many-body effects are important in many cases. The terms pairwise and two￾body potentials are often used interchangeably in the literature. However,
although both involve only the evaluation of pairs of interactions, a pairwise
potential often implicitly includes multi-body effects, whereas two-body poten￾tials do not. For example, the development of the Lennard-Jones (LJ) potential
was not confined exclusively to two-body interactions and as such it is an
effective multi-body pairwise potential but not a two-body potential. The focus
51 Molecular Simulation of Fluids. DOI: https://doi.org/10.1016/B978-0-323-85398-9.00017-4
© 2024 Elsevier B.V. All rights reserved.of this chapter is on effective pair potentials and special consideration of two￾and other multi-body potentials given in Chapter 4. The historical development
of some empirical intermolecular potentials has been discussed by Fischer and
Wendland (2023).
Relatively few of the large number of available intermolecular pair poten￾tials have been comprehensively evaluated by molecular simulation.
Nonetheless, the use of molecular simulation for increasingly more compli￾cated molecular systems will inevitably require models that are not currently
in widespread use. Therefore, knowledge of possible alternatives is certainly
worthwhile. A nascent possibility is the use of machine learning (Jung, 2022)
to determine intermolecular potentials (Gao et al., 2019; Mueller et al., 2020;
Pant et al., 2020; Moradzadeh and Aluru, 2021; Perepu et al., 2023)
Water is an example of an important molecular system whose properties
are significantly affected by the overall model framework and the contribution
from component intermolecular potential. An overview is provided for the
potential models for water. It provides a convenient case study of the applica￾tion of both modeling principles and the use of intermolecular potentials.
3.1 Calculation of the potential energy
The calculation of the potential energy (or force) arising from intermolecular
interaction is the most time consuming and crucial step in any molecular
simulation. In general, the potential energy (U) of N interacting particles can
be evaluated as,
U 5 X
i
u1ð Þ ri 1 X
i
X
j . i
u2 ri;rj
  1 X
i
X
j . i
X
k . j . i
u3 ri;rj;rk
  1??
ð3:1Þ
where the first term represents the effect of an external field and the remain￾ing terms represent particle interactions, that is, u2 is the potential between
pairs of particles and u3 is the potential between particle triplets etc. Two￾body interactions undoubtedly make the most significant contribution to par￾ticle interactions, and Eq. (3.1) is typically truncated after the second term.
This approximation means that the simulation algorithm is of order Nm,
where m $ 2 denotes the number of interactions. However, except for prop￾erties involving dilute gases, the properties of real fluids involve the contri￾bution of other multi-body interactions. It is relatively rare that accurate
prediction can be accomplished by accounting only for two-body interac￾tions. In particular, it is well-established that three-body interactions are very
important in many cases (Bobetic and Barker, 1970; Klein and Venables,
1976; Monson et al., 1983; Rittger, 1990a,b,c). The dilemma is that, although
three- or more-body interactions are important for accurate predictions, they
impose a very large increase in computing time compared with two-body
52 Molecular Simulation of Fluidscalculations. Despite the considerable advances in computer hardware,
involving systems of thousands of central and graphics processing units
(Chapter 12), calculations beyond two-body interactions remain, in most cir￾cumstances, both computationally prohibitive and impractical.
The solution to this computational dilemma is to use an effective pairwise
intermolecular potential (ueff), that while involving only the evaluation of
pairs of interactions, incorporates the effect of three- or more-body interac￾tions. This means, that in the absence of an external field, Eq. (3.1) is simply
approximated as:
U  X
i
X
j . i
ueff ri;rj
  ð3:2Þ
As explained below, Eq. (3.2) has most commonly been applied uninten￾tionally because the true nature of the pair potential has not been fully recog￾nized. Therefore, the apparent success of effective potentials in predicting
the properties of fluids via molecular simulation has often been a fortuitous
outcome rather than the result of a deliberately implemented strategy.
The development of intermolecular potentials greatly predates the advent
of molecular simulation, typically involving the combination of various con￾tributions to intermolecular interactions (Mie, 1903; Jones, 1924) and making
a comparison with experimental data. Most commonly, the empirical poten￾tials were compared with data for the second virial coefficient, which is a
genuine two-body property. This route for evaluating early pair potentials
has led to the term “pair/pairwise” being incorrectly used as a synonym for
two-body (Rowlinson, 2002). However, it has been known since the 1960s
and confirmed by many subsequent state-of-the-art accurate ab initio calcula￾tions (Chapter 4) that genuine two-body potentials for the noble gases are
much more complicated and do not accurately correspond to the simple
empirical potentials. Typically, the depths of the potential minimum of the
empirical pair potentials are considerably smaller than those obtained from
genuine two-body potentials. Arguably, the formulas used for many of the
empirical pairwise potentials have unintentionally at least partially incorpo￾rated some of the effects of multi-body interactions. Therefore, such poten￾tials are more accurately described as effective pairwise potentials. This
historical accident is quite fortuitous because it means that Eq. (3.2) is often
a good approximation for the properties of real fluids.
The distinction between the terms “pair” and “two-body” might appear
somewhat pedantic but it is an important distinction when molecular simula￾tion results are used to precisely investigate the influence of underlying inter￾actions on the macroscopic properties of fluids. No pair potential can be
fully equivalent to a multi-body potential. One danger in not observing this
distinction is unwittingly (Sadus and Prausnitz, 1996) double counting the
same intermolecular contributions. To avoid any confusion, we will usually
denote pairwise potentials that are not explicitly confined to only two-body
Intermolecular pair potentials and force fields Chapter | 3 53interactions simply as ueff and the u2 and u3 nomenclature will be reserved
for genuine two- and three-body potentials, respectively.
Although using Eq. (3.2) is the most common approach in molecular simula￾tion, there is a growing literature involving two-body plus three-body interactions.
As discussed in Chapter 4, this has been facilitated by ways of accurately approxi￾mating the contribution of three-body interactions in a computationally efficient
fashion. It would be desirable to have one two-body potential that was valid for
all atoms. However, the evidence from accurate ab initio calculations indicates
that the intermolecular potential must be tailored to each atom. For example, dif￾ferent potentials are required to accurately evaluate the properties of the different
noble gases (Deiters and Sadus, 2019a,b, 2020, 2021). In contrast, a common
interatomic potential (Seng et al, 2020) for the noble gases is inaccurate for many
of their thermodynamic properties (Deiters and Sadus, 2023).
3.1.1 Use of notation
In discussing and comparing the various intermolecular potentials in this
chapter, an effort has been made to standardize the notation for various com￾mon parameters. This inevitably means that the notation will sometimes dif￾fer from that given in the original articles. Symbols are defined when they
first occur and the definition is not necessarily repeated for subsequent
potentials involving the same quantity. For example, irrespective of the
potential, the symbol ε always denotes the depth of the potential well.
3.2 Intermolecular forces
In principle, the development of intermolecular potentials should be informed by
the nature of intermolecular forces. However, in practice the role of theory often
takes second place to empirical considerations. A brief background of the nature
of intermolecular forces is given here, which is discussed in much greater detail
elsewhere (Maitland et al., 1981; Gray and Gubbins, 1984; Stone, 2013).
3.2.1 Types of intermolecular forces
Calculation of the potential energy inevitably involves assumptions concern￾ing the nature of attraction and repulsion between molecules. Intermolecular
interaction is the result of both short- and long-range (LR) effects.
Electrostatic, induction, and dispersion effects are examples of LR interac￾tions. In these cases, the energy of interaction is proportional to some inverse
power of intermolecular separation. Electrostatic interactions result from the static
charge distribution between molecules. The effect can be either attractive or
repulsive, and it is exclusively pairwise additive. Induction effects are always
attractive, resulting from the distortions caused by the molecular fields of neigh￾boring molecules. However, the most important contribution is the attractive
54 Molecular Simulation of Fluidsinfluence of dispersion arising from instantaneous electric field caused by elec￾tron movement. Neither induction nor dispersion is pairwise additive.
Short-range (SR) interactions are characterized by an exponential decay
in the interaction energy with respect to intermolecular separation. At small
intermolecular separations, there is a significant overlap of the molecular
wave functions causing either intermolecular exchange or repulsion. These
interactions are not pairwise additive (Stone, 2013).
It is possible to calculate the intermolecular interactions from first principles.
However, in practice the first principles or ab initio approach is confined to rela￾tively simple systems. More commonly, the influence of intermolecular interac￾tion is expressed by some type of intermolecular potential. The justification for
the intermolecular potential is often entirely empirical, although, as will be dis￾cussed in Chapter 4, it is possible to determine an ab initio potential during the
course of a simulation (Car and Parrinello, 1985).
3.2.2 Quantum theory of intermolecular potentials
The theoretical background for the development of intermolecular potentials
is discussed in detail elsewhere (Maitland et al., 1981; Gray and Gubbins,
1984; Stone, 2013) and our discussion will be limited only to the most
salient features. There are two distinct methods for developing an intermo￾lecular potential (Pople, 1982). In the spirit of the LJ potential, the total
interaction can be partitioned into LR and SR contributions. The LR part is
typically proportional to inverse powers of the intermolecular distance,
whereas the SR repulsive part is associated with exchange or overlap of the
electronic distributions. The two contributions can be evaluated separately,
and the total potential is obtained by combining the two parts.
ΔUab 5 ΔULR
ab 1 ΔUSR
ab ð3:3Þ
The alternative approach is to treat the interacting a ... b complex as a
single large molecule or “supermolecule.” The interaction potential is
obtained by calculating the energy of ab and subtracting the energies of the
separated a and b molecules.
ΔUab 5 Uab 2 Ua 2 Ub ð3:4Þ
Both of the above methods can be considered in terms of the principle of
quantum mechanics. Molecules a and b are associated with the unperturbed
wave functions ψa and ψb, respectively. The interaction Hamiltonian Vab
resulting from Coulombic interaction between the electrons and nuclei of a
and the electrons and nuclei of b can be introduced as a perturbation. If the
wave functions do not overlap, the interaction energy resulting from a first￾order perturbation (Pople, 1982; Stone, 2013) is:
Δ1ULR
ab 5 h i ΨaΨbj j Vab ΨaΨb ð3:5Þ
Intermolecular pair potentials and force fields Chapter | 3 55Eq. (3.5) is the rigid electronic interaction potential resulting from the
Coulombic interaction of unperturbed electronic distributions of the isolated
a and b molecules. This first-order treatment fails to describe the LR interac￾tion between spherical systems. To account for dispersion interaction, it is
necessary to introduce the interaction potential Vab to second order. In terms
of the RayleighSchro¨dinger perturbation theory (Pople, 1982; Stone, 2013),
the second-order contribution to the LR potential is,
Δ2ULR
ab 5 2 X
i6¼0
X
j6¼0
ΨaΨbj j Vab Ψi
aΨj
b
   

2
Ui
a 2 Ua 1 Uj
b 2 Ub
; ð3:6Þ
where the superscripts represent the ith excited state. From Eq. (3.6) it can
be shown (Pople, 1982; Stone, 2013) that the dispersion potential for spheri￾cal atoms is,
ΔUdisp
ab 5 C6
r6 1
C8
r8 1??; ð3:7Þ
where C6, C8 ... are coefficients that depend on relative orientations. These
contributions appear explicitly in many intermolecular potentials.
A third-order perturbation treatment is required to determine the contribu￾tion of three-body interactions. Axilrod and Teller (1943) and Mut ¯o (1943)
formulated an explicit expression for triple-dipole interactions. Third-order
perturbation theory can also be used to obtain the higher multipole moments
that contribute to three-body interactions (Bell and Zucker, 1976). This topic
is discussed in greater detail in Chapter 4.
In the supermolecule method, the interaction between molecules a and b
is not treated as a perturbation. Instead, the wave function ψab for the com￾pound a .... b system is calculated for every required relative intermolecular
configuration.
ΔUab 5 h i Ψabj j Hab Ψab 2 h i Ψaj j Ha Ψa 2 h i Ψbj j Hb Ψb ð3:8Þ
Eq. (3.8) has the advantage that it takes account of repulsive interactions at
short intermolecular separation. The disadvantages of the supermolecule approach
center on the limitations of the wave functions that are used. Most supermolecule
calculations use the HartreeFock procedure, which fails to account for disper￾sion interactions. The usefulness of supermolecule HartreeFock calculations is
confined to polar systems dominated by electrostatic interactions. To be generally
useful, the supermolecule approach must be used with a post-HartreeFock tech￾nique (Chapter 4).
3.3 Potentials with a hard sphere contribution
Potentials with a hard sphere(s) (HS) term have a special place (Mulero,
2008) in the application of molecular simulation because they represent the
56 Molecular Simulation of Fluidssimplest possible potential that nonetheless can at least approximately repre￾sent some of the properties of real fluids. The scope of such potentials can
be systematically expanded via the addition of attractive contributions,
resulting in “hard sphere 1 attractive term” (HSA) potentials. A comparison
of some repulsive potentials is given in Fig. 3.1.
3.3.1 The HS potential
The simplest approximation is to treat atoms as impenetrable HS, that is,
uHSðrÞ 5 N r # σ
0 r . σ

ð3:9Þ
where σ is the HS diameter (Fig. 3.1). In a molecular simulation, special proce￾dures are required (Allen and Tildesley, 2017; Wu and Sadus, 2005) to evaluate
the effect of the HS potential. The properties of Eq. (3.9) are exclusively evalu￾ated via pair interactions and there are no meaningful contributions of multi￾body interactions. Accurate values of the compressibility factors for the HS sys￾tem have been obtained up to very high densities (Wu and Sadus, 2005), and
its thermal conductivity has been investigated (Pieprzyk et al., 2020).
The HS potential remains of considerably utility as the theoretical basis
for the development of HS equations of state (Sadus, 1992). The properties
of the HS potential have been investigated extensively by molecular simula￾tion (Boubl´ık and Nezbeda, 1986; Mulero, 2008). Alder and Wainwright
(1957) reported the first MD simulation for HS. Their data were found to be
FIGURE 3.1 Comparison of some repulsive potentials, representing HS (Eq. (3.9)), WCA
(Eq. (3.10)), and GCM (Eq. (3.19)) interactions.
Intermolecular pair potentials and force fields Chapter | 3 57in good agreement with MC results (Wood and Jacobson, 1957), thereby
demonstrating the equivalence of the two molecular simulation methods. The
transport coefficients of HS fluids (Alder et al., 1970) have been investigated
and molecular simulation studies of mixtures of HS have been reported
(Boubl´ık and Nezbeda, 1986). The conventionally accepted view is that the
HS fluid is only capable of a single solid-fluid transition, although there are
some simulation data that suggest the possibility of an additional transition
(Wu and Sadus, 2004). However, the absence of attractive interactions means
that it cannot even predict qualitatively the properties of real fluids.
3.3.2 Non-HS repulsive potentials
The HS potential is a purely repulsive potential. However, the extent of its
repulsion is unrealistically steep compared with the behavior of real fluids
and its reliance on determining particle overlap makes it awkward to imple￾ment in MD compared with continuous potentials.
3.3.2.1 WeeksChandlerAnderson potential
The WeeksChandlerAnderson (WCA) potential (Weeks et al., 1971) pro￾vides a widely used non-HS alternative for purely repulsive interactions
(Fig. 3.1). The WCA potential modifies the LJ potential (see Section 3.6.1):
uWCA 5 4ε

 σ
r
12
2

 σ
r
6	
1 ε; r # 21=6σ
0; r . 21=6σ
8
><
>:
ð3:10Þ
In Eq. (3.10), the LJ potential is made repulsive by simply adding the value
of ε at all separations below the minimum of the potential, which always yields
a finite positive value. Eq. (3.10) provides a more realistic description of repul￾sive interactions that is easier to implement the infinitely steep HS term. It has
been incorporated to study the behavior of molecular fluids such as polymers
(Kro¨ger, 2005) and dendrimers (Bosko et al., 2004, 2006), and it forms part of
many theories (Chandler et al., 1983) of the liquid state. Eq. (3.10) has been
useful for the simulation of chains composed of hard tangent spheres (Gao and
Weiner, 1989). It yields properties that are broadly similar to the HS potential,
for example, only solidliquid equilibria (SLE) are possible (Ahmed and Sadus,
2009a; Dyre and Pedersen, 2023). It has been observed that SLE behavior do
not necessarily scale inversely with the number of particles (N) and N $ 4000
is recommended (Ahmed and Sadus, 2009a).
Although the WCA potential has been overwhelmingly tied to the 126 LJ
potential, it could easily be re-formulated with many other suitable potentials.
Indeed, it is generally accepted that 12-power exponent used in the 126 LJ
version of the WCA potential, while a better alternative to the HS potential, is
itself too steep to accurately represent repulsion in real fluids.
58 Molecular Simulation of Fluids3.3.3 HSA potentials
It is well-known that properties of most real fluids require interactions from
both intermolecular repulsion and attraction. In particular, vaporliquid
equilibria (VLE) invariably require the cohesion generated by intermolecular
attraction. Comparisons of some HSA potentials are given in Fig. 3.2.
3.3.3.1 The Square well potential
The square well (SW) potential is the simplest HSA intermolecular potential
that is capable of representing the properties of liquids,
uHSAðrÞ 5
N r # σ
2 ε σ , r # λσ
0 r . λσ
;
8
<
:
ð3:11Þ
where λ is some multiple of the HS diameter. The SW potential represents a
mathematically idealized model of molecular interactions. The properties of the
SW fluid have been investigated widely (Haile, 1992), and it remains a useful
starting point for the development of fluid state theories (Yuste and Santos, 1994).
By varying λ, Eq. (3.11) can be used as an approximation for continuous poten￾tials, which is useful in some theoretical evaluations (Paricaud, 2006). For exam￾ple λ 5 1.5 (Elliott and Hu, 1999) is sometimes used as an approximation of the
LJ potential (Fig. 3.2). The overall size of both the VLE phase envelope and the
critical point are noticeably affected by the choice of λ (Vega et al., 1992a;
Orkoulas and Panagiotopoulos, 1999; Gloor et al., 2004; Patel et al., 2005).
FIGURE 3.2 Comparison of repulsion 1 attraction represented by the DGCM (ε25 0.02ε2,
ζ 5 3σ1, the small attractive minimum is at 3.017σ1), Yukawa (z 5 1.8), IP (n 5 6), SW (λ 5 1.5),
and LJ (dashed line) potentials.
Intermolecular pair potentials and force fields Chapter | 3 593.3.3.2 Penetrable SW potential
A modification of the SW potential is to allow a small degree of particle
penetration. The penetrable sphere attractive (PSA) potential (Santos et al.,
2008) is
uHSAðrÞ 5
εrep r # σ
2 ε σ , r # λσ
0 r . λσ
;
8
<
:
ð3:12Þ
where the infinite repulsion is replaced by a finite value (εrep) and the εrep/ε
ratio can be considered as a measure of penetrability. Simulations of the
phase behavior of the PSA potential have been compared (Fantoni et al.,
2011) with the SW potential. Values of λ 5 1.5 and εrep/ε 5 1.8 approxi￾mately coincide with the SW potential, whereas there are significant devia￾tions from SW behavior for other choices of parameters.
3.3.3.3 Triangular well potential
There are various possible variations on the HSA concept. For example, it is
possible to envisage a triangular potential (Feinberg and de Rocco, 1964;
Fowler et al., 1965) of the following form:
uHSAðrÞ 5
N r # σ ε
λ 2 1

 r
σ 2 λ

σ , r # λσ
0 r . λσ
8
>><
>>:
ð3:13Þ
It has been used to investigate the VLE of both two- (Reyes et al., 2016)
and three-dimensional (Barcenas et al., 2014 ´ ) fluids, indicating broadly simi￾lar λ-dependent behavior to that observed for the SW fluid.
3.3.3.4 Yukawa potential
Considerable interest has been demonstrated in simulating the properties of
atoms interacting via the HS Yukawa potential (Rudisill and Cummings,
1989; Smit and Frenkel, 1991; Rosenfeld, 1993, 1996; Kalyuzhnyi and
Cummings, 1996). The Yukawa potential can be written as
uHSAðrÞ 5
N r # σ
2εσ
r exp
2z

 r
σ 2 1
	 r . σ ;
8
<
:
ð3:14Þ
where z is an adjustable parameter. Part of the appeal of this potential is that
its behavior approximately reflects (Rudisill and Cummings, 1989) other
more complicated potentials. The inverse power dependence of this potential
means that it can be applied to ionic systems (Rowlinson, 1989). When
60 Molecular Simulation of Fluidsz 5 1.8 the results obtained (Duh and Mier-Y-Teran, 1997 ´ ) are similar to the
LJ (126) potential. The phase diagram resulting from the Yukawa potential
has been reported (Rudisill and Cummings, 1989; Smit and Frenkel, 1991;
Galicia-Pimental et al., 2008). Kalyuzhnyi and Cummings (1996) have calcu￾lated the phase diagram for a LJ fluid modeled by the Yukawa potential. In
common with the SW potential, the VLE diagram of the Yukawa potential is
very sensitive to the choice of z (Lomba and Almarza, 1994; Shukla, 2000;
Spear, 2000). Its VLE properties in the vicinity of the sticky sphere limit
have been studied (Scho¨ll-Paschinger et al., 2013). The Yukawa potential
has been used (de Carvalho and Evans, 1997) in conjunction with the
restricted primitive (see subsequent discussion) model to calculate the prop￾erties of a charged HS binary fluid. It has also been coupled (Mate et al., ´
2011) with dipolar interactions for the heat capacities. The potential has also
proved useful for studying colloids and proteins (Valdez-Pe´rez et al., 2012).
3.3.3.5 Inverse power potential
A more realistic HSA potential can be obtained by using the attractive term
from an inverse power (IP) law, that is,
uHSAðrÞ 5 N r # σ
2Cnr2n r . σ ;

ð3:15Þ
where n and Cn are constants. When n 5 6, Eq. (3.15) is the Sutherland
potential and C6 is the leading dispersion coefficient (Fig. 3.2). No molecular
simulations have been reported using this potential. This lack of interest can
be partially explained by the greater flexibility offered by other HSA poten￾tials via the simple expedient of varying the depth of the attractive well. It
should also be noted that values of C6 obtained by parameterization with
experimental data are unrealistically large (Sherwood and Prausnitz, 1964).
It nonetheless may have a useful future role in identifying the relative contri￾bution of different dispersion coefficients on the properties of fluids.
3.3.3.6 Sticky sphere potential
Baxter (1968) proposed a HAS potential that has become known as the
“sticky sphere” potential. It combines HS repulsion with an infinitely narrow
potential well when λ  σ is allowed to be infinitesimally small, that is,
uHSAðrÞ 5
N r , σ
kT loge
12τðλ 2 σÞ
λ
2
4
3
5 σ , r , λ
0 r . λ
;
8
>>><
>>>:
ð3:16Þ
where k is Boltzmann’s constant, T is temperature, and τ is a stickiness
parameter that is related to the temperature. Unlike other HSA potentials,
Intermolecular pair potentials and force fields Chapter | 3 61Eq. (3.16) is temperature-dependent. As detailed by Stell (1991), Eq. (3.16)
has proved useful in describing mono-dispersed systems and nonionic
micelles (Rao et al., 1991).
3.3.3.7 Kihara hard core potential
The HSA approach can be generalized to any hard core (HC) plus attraction
(HCA) interactions. The Kihara potential (Kihara, 1951; Maitland et al.,
1981) is the best-known example of this approach,
uHCAðrÞ 5
N r # d
4ε

 σ2d
r2d
12
2

 σ2d
r2d
6	
r . d ;
8
><
>:
ð3:17Þ
where d is the diameter of an impenetrable HC at which u(r) 5N, which is
used to modify the contribution of the LJ potential. The Kihara potential has
the advantage that it can be applied to nonspherical molecule by using a con￾vex core of any shape. It has been studied extensively (Sherwood and
Prausnitz, 1964; Vega et al., 1992b; Tee et al., 1966), and it generally pre￾dicts the second virial coefficient more accurately than the LJ potential. The
potential, which forms the theoretical basis of hard convex body (HCB)
equations of state (Wei and Sadus, 2000), has not been studied widely by
molecular simulation. The hardness of Eq. (3.17) can obviously be softened
by removing the requirement that u(r) 5N for r # d.
3.4 Soft sphere potentials
A simple and more realistic alternative to the HS potential is the soft
sphere (SS) potential, which is not infinite at interatomic separations less
than the sphere diameter. SS potentials typically use an IP relationship,
for example,
uSSðrÞ 5 C

 σ
r
n
r # σ
0 r . σ
8
><
>:
ð3:18Þ
In Eq. (3.18), C is a constant. In common with HS potentials, the absence
of attractive interactions means that SS potentials cannot be used to model
real liquids. Neither vaporliquid nor liquidliquid equilibria are possible
for particles interacting via a SS potential. However, many simulation studies
have been reported using SS potentials to determine the effect of repulsion
in fluids and SLE.
MC simulations have been reported (Hoover et al., 1970, 1971) using
the inverse fourth-, sixth-, ninth-, and twelfth-power SS potential to deter￾mine the thermodynamic properties of fluids and face-centered-cubic solids.
62 Molecular Simulation of FluidsThe fluidsolid melting line of particles interacting via various SS potentials
has been determined (Hoover et al., 1972) by MC simulation and the influ￾ence of interatomic repulsion of the structure of liquids at melting has been
investigated (Hansen and Schiff, 1973). The sixth-power potential has been
used (Laird and Haymet, 1989) to study the crystalliquid interface of a
body-centered-cubic solid. Substances interacting via a sixth-power potential
undergo a transition between body-centered-cubic and face-centered-cubic
orientations at temperatures slightly above the freezing point (Laird and
Haymet, 1992).
The general thermodynamic properties of such potentials have been
extensively documented (Hamad, 1995). Investigations of the n-dependence
of transport properties (Heyes and Powles, 1998) and radial distribution func￾tions (Heyes et al., 2004) are also available.
3.5 Fully interpenetrable potentials
The defining feature of the HS and HSA potentials is that the particles are
impenetrable below a separation of σ. This requirement is partially relaxed
for the SS potentials (Eq. (3.18)) but repulsion nonetheless rises very steeply
at small interparticle separations. An interesting alternative to this conven￾tional approach is to completely relax this barrier and allow the particles to
be fully interpenetrable at all interparticle separations.
3.5.1 Gaussian core model potential
The Gaussian core model (GCM) potential (Stillinger, 1976) is an example
of a fully interpenetrable potential.
uGCMðrÞ 5 εexp 2 r
σ
 2  	 ð3:19Þ
It is apparent from Eq. (3.18) that the value of the potential increases in a
controlled fashion for r , σ, attaining a maximum value of ε (Fig. 3.1).
This means that complete interparticle penetration is possible without a very
steep increase in energy. The potential rapidly decays to 0 for r . σ. These
behaviors may appear to be physically unrealistic, but it is nonetheless useful
(Likos, 2001) for phenomena involving intra-particle penetrations, such as
networks of polymers or gels. The GCM potential also reproduces (Ahmed
et al., 2009, 2010; Mausbach and Sadus, 2011) some of the anomalies
(Shvab and Sadus, 2016) exhibited by water, which are attributed to the
extensive network formed by hydrogen bonds. In common with water, the
thermal expansion coefficient of the GCM potential is negative and the iso￾choric heat capacity has a minimum. Only SLE are observed (Prestipino
et al., 2005; Mausbach et al., 2009) for the GCM potential with the unusual
feature of a re-entrant solid phase.
Intermolecular pair potentials and force fields Chapter | 3 633.5.2 Double Gaussian core model potential
The GCM potential can be modified (Prestipino, et al., 2014) to include a
Gaussian shape attractive term (Fig. 3.2). The result of this modification is
the double Gaussian core model (DGCM) potential.
uDGCMðrÞ 5 ε1exp 2 r
σ1

 2 " # 2 ε2exp 2 r2ζ
σ2

 2 " # ð3:20Þ
The DGCM potential has both maximum (uDGCM(0)5 ε1) and minimum
(uDGCM(ζ) 5 2ε2) values, when r 5 0 and r 5 ζ, where ζ . σ1. There are also
two characteristic distances, satisfying the condition that σ2 $ σ1. A consequence
of adding attractive interactions is the DGCM displays VLE (Speranza et al.,
2014; Losey and Sadus, 2019). Compared to the GCM potential, the DGCM
potential also exhibits more water-like anomalies in its thermodynamic properties.
3.6 Effective pairwise potentials for atoms and simple molecules
The proceeding discussion of HS, HSA, SS, GCM, and DGCM potentials
have involved largely theoretical systems, which do not attempt directly to
describe the behavior of real systems. In contrast, many effective pairwise
potentials have been specifically developed (Maitland et al., 1981; Stone,
2013) to predict the properties of either atoms or small molecules. Much of
this work has predated the advent of molecular simulation, but it is the appli￾cation of molecular simulation that is decisive in evaluating both the
strengths and weaknesses of intermolecular potentials.
Historically, an empirical approach was used with the parameters of the
potential being obtained from experimental data such as second virial coeffi￾cients, viscosities, molecular beam cross sections, and the like. Conclusions
regarding the accuracy of pair potential were made by comparing the properties
predicted by the potential with experiment. In contrast, computer simulation per￾mits the theoretically rigorous evaluation of the accuracy of intermolecular poten￾tials. However, very few potentials have been tested extensively using molecular
simulation. Notable exceptions are the HS, LJ, and exp-6 potentials.
Effective pair potentials for atoms are often incorporated into the molecular
simulation of polyatomic molecules and increasingly, macromolecules. Therefore,
the atomic pair potential is an important starting basis for predicting molecular
properties. In view of this, the evaluation of pair potentials by molecular simula￾tion is likely to be increasingly important for the prediction of molecular fluids.
3.6.1 Repulsion 1 dispersion pair potentials
3.6.1.1 Generalized nm Lennard-Jones/Mie potential
Typically, an adequate representation of the intermolecular forces between
nonpolar molecules can be obtained by combining repulsion and dispersion
64 Molecular Simulation of Fluidsterms to generate a pair potential. Many “repulsion 1 dispersion” pair poten￾tials have been developed; however, relatively few different types of poten￾tials are used routinely in molecular simulation.
In contrast to the HSA potentials, a more realistic representation of inter￾molecular interaction is given by continuous intermolecular potentials. Mie
(1903) and later Lennard-Jones (Jones, 1924) proposed empirical potentials
of the type,
ueffðrÞ 5 υ
rn 2 μ
rm ; ð3:21Þ
where ν, μ, n, and m are constants. Fowler and Guggenheim (1939) and
Mayer and Mayer (1940) observed, without any derivation, that Eq. (3.21)
could be generalized as,
ueffðrÞ 5 ε m
n 2 m
  rm
r
 n
2 n
n 2 m
  rm
r
h i  m
; ð3:22Þ
where m . 3 and rm is the separation corresponding to the minimum energy
corresponding to ueffð Þr 5 2 ε. The separation (σ) when ueffð Þr 5 0, which is
the HS diameter in the HS potentials, is related to rm via:
σ 5 rm
m
n
  1
n2m
ð3:23Þ
Alternatively, making use of Eq. (3.23) to determine rm from σ trans￾forms Eq. (3.22) to,
ueffðrÞ 5 ε n
n 2 m
  n
m
  m ð Þ n2m σ
r
 n
2 σ
r
h i  m
; ð3:24Þ
which has the advantage of only involving a common single pre-factor term.
This simplification is not obvious from Eq. (3.22).
In the literature, Eqs. (3.22) and (3.24) are interchangeably referred to as
either the generalized Mie (1903) or generalized LJ (Jones, 1924) potential
with the former designation being the most common. Neither Mie nor
Lennard-Jones proposed the generalization of the potentials given by either
Eq. (3.22) or Eq. (3.24) in their original publications. Possibly the earliest
contemporaneous representation of Eq. (3.22) can be found in a 1939 text￾book on statistical mechanics (Fowler and Guggenheim, 1939). Eq. (3.24)
only appears in much later textbooks (Reed and Gubbins, 1973). It appears
that the convenience of using Eq. (3.24) compared with Eq. (3.22) was not
immediately apparent. We will refer to either Eq. (3.22) or Eq. (3.24) as the
LJ/M potential to equally acknowledge both contributors in alphabetical
order.
Changing the n and m exponents significantly alters the nature of the
intermolecular potential as is illustrated in Fig. 3.3. When n 5 12 and m 5 6,
we obtain the most-widely used version of the LJ/M potential, which is
Intermolecular pair potentials and force fields Chapter | 3 65simply known as the LJ potential, which is the most common form of the
LJ/M potential.
ueffðrÞ 5 4ε σ
r
 12
2 σ
r
 6  	 ð3:25Þ
The LJ potential was previously encountered in the context of the WCA
potential (Eq. (3.11)), and it is undoubtedly the most-widely used potential
for molecular simulation. Wood and Parker (1957) investigated the LJ poten￾tial by MC simulations, and the first MD simulation of a LJ fluid was
reported by Rahman (1964). It yields a reasonable overall qualitative repre￾sentation for the properties of argon, and it has been applied to many other
atoms with varying success. Its usefulness for real fluids has been discussed
elsewhere (Wang et al., 2020) and, despite its many limitations, it is likely to
remain in widespread use for the foreseeable future.
In the LJ potential, intermolecular repulsion and dispersion interactions are
represented by different IP dependencies of intermolecular separations. The r
26
dependence of the attractive term is consistent with the leading term of the 1/r
expansion of dispersion energy; however, the dispersion coefficient (i.e.,
C65 4εσ6
) is typically overestimated by a factor of 2 compared with experimental
values. This can be partly explained partly by the absence of r
28 and r
210 terms. It
should be noted that there is no theoretical justification for the r
212 repulsion term.
The LJ potential is often used as part of a larger potential for molecular sys￾tems. For example, it is used frequently to calculate the interactions between
atoms that constitute a model of a many-atom molecule such as a polymer
FIGURE 3.3 Comparison of the energy curve for the (n 5 m 1 1, m) LJ/M potentials. Results are
shown for m 5 4, 5, and 10 and compared with the values obtained for the LJ potential (dashed line).
66 Molecular Simulation of Fluids(Escobedo and de Pablo, 1996; Johnson and Gubbins, 1992; Johnson et al.,
1994). It is also used commonly as part of a molecular mechanics potential (see
discussion below).
The appeal of the LJ potential is that it combines a realistic description of
the intermolecular interaction separation with computational simplicity. The
application of the LJ potential requires the evaluation of the intermolecular para￾meters. This is commonly done by fitting the predicted second virial coefficient
(B) of the LJ potential to experimental data for real atoms or molecules. This is
a convenient route because the LJ/M has an analytical solution for B, that as dis￾cussed elsewhere (Sadus, 2018, 2019) can be easily evaluated, that is,
B Tð Þ 5 2
3
πσ3
F yð Þ; ð3:26Þ
where
FðyÞ 5 y3=ðn2mÞ Γ n 2 3
n

  2 3
n
XN
i51
Γ im 2 3
n

 yi
=i!
( ); ð3:27Þ
yn 5 n
n2m
 n n2m
m
 m ε
kT
 n2m
; ð3:28Þ
and Γ is the gamma function (Abramowitz and Stegun, 1972). Tables of parame￾ter values for many atoms and small atoms are available in the literature
(Hirschfelder et al., 1954; Maitland et al., 1981; Gray and Gubbins, 1984) and are
almost universally accepted and used. For example, the often-quoted values for
argon are ε/k 5 119.8 K and σ 5 0.3405 nm. The parameters for the LJ potential
for noble gases have been re-evaluated (Sadus, 2018), which has resulted in better
overall agreement with the experimental B data (Table 3.1). However, the
TABLE 3.1 Comparison of literature values (Maitland et al., 1981) and
re-evaluated (Sadus, 2019) LJ parameters obtained from the experimental
second coefficient data for noble gases. The agreement with experiment
for the entire temperature range is quantified using the root mean
squared deviation (RMSD).
Atom Literature Re-evaluated
T Range
(K)
ε/k
(K)
σ
(nm)
RMSD
(cm3
/mol)
ε/k
(K)
σ
(nm)
RMSD
(cm3
/mol)
Ne 50870 47.0 0.272 9.81 34.91 0.278 0.40
Ar 761000 119.8 0.341 9.33 120.32 0.342 7.10
Kr 110870 164.0 0.383 6.48 175.34 0.366 5.81
Xe 165970 222.2 0.401 20.30 226.51 0.408 8.16
Intermolecular pair potentials and force fields Chapter | 3 67agreement with experiment remains imperfect, which reflects the fact the LJ
potential is not a two-body potential. Simply inserting an effective pair potential
into the formula for a genuine two-body property such as the second virial coeffi￾cient does not transform the potential to a two-body potential. It is noteworthy
that although the LJ potential is commonly attributed in the literature are being at
least approximately suitable for argon, the deviation for experimental B values
(Table 3.1) is significant.
The LJ potential is unarguably the most popular and widely used variant of
the LJ/M potentials. However, other combinations of the n and m exponents
have been investigated via molecular simulation. In particular, the n-6 LJ/M
potentials have been the focus of several studies (Kiyohara et al., 1996;
Okumura and Yonezawa, 2000; Gordon, 2006; Ahmed and Sadus, 2009b; Orea
et al., 2008; Potoff and Bernard-Brunel, 2009). The purpose of these studies has
been to investigate the effect of varying n on thermodynamic properties. The
extent of both VLE (Kiyohara et al., 1996; Okumura and Yonezawa, 2000) and
SLE (Ahmed and Sadus, 2009b) varies systematically with n. It has been dem￾onstrated (Potoff and Bernard-Brunel, 2009; Potoff and Kamath, 2014; Mick
et al., 2015) that experimental VLE data of both the noble gases and a range of
molecules can be accurately fitted to n-6 LJ/M potentials by using n as an
adjustable parameter. For example the 146 and 366 LJ/M potentials yield
optimal agreement (Potoff and Bernard-Brunel, 2009) for the VLE properties of
methane and tetrafluoromethane, respectively.
In contrast, studies of nm LJ/M potentials for m 6¼ 6 are much less com￾mon, which can be at least partly attributed to the fact m 5 6 corresponds to
the decay of the leading term of dispersion interactions. Sadus (2018)
mapped the behavior of the second virial coefficients for many combinations
of n and m values. The n-4 LJ/M potentials (Sadus, 2020a) display a high
degree of cohesive behavior and the VLE diagrams in some cases are similar
to that observed for dipolar systems. The (m 1 1, m) LJ/M potential has
also been investigated (Sadus, 2020b) systematically resulting in a range of
m-dependent thermodynamic behavior.
It is apparent that there are many different combinations of the n and m
exponents. Therefore, it is likely that some of the different combinations
may result in potentials that are very closely related resulting in the predic￾tion of broadly similar phenomena. That is, a given combination of n and m
exponents does not necessarily yield a unique LJ/M potential. Mej´ıa et al.
(2014) and Ramrattan et al. (2015) proposed that different combinations of
the n and m exponents may yield similar behavior if they share a common
value of α defined by:
α 5 n
n 2 m
  n
m
  m
n2m 1
m 2 3 2 1
n 2 3

  ð3:29Þ
Values of α for various nm potentials are compared in Fig. 3.4, which
highlights cases of constant α 5 0.5 and 1.6. It is apparent that when m $ 6
68 Molecular Simulation of Fluidsthat there are likely to be several broadly equivalent cases involving other m
values. In contrast, when m 5 4, intersection is only possible for m 5 5 cases.
It should be noted that the exact equivalence between different LJ/M poten￾tials would generally require the use of nonintegral n and m exponents. This
type of analysis is useful to avoid the unintended duplication of simulations
involving broadly similar LJ/M potentials.
3.6.1.2 Egelstaff potential
Egelstaff (1987, 1994) proposed the following variant of the LJ potential,
ueffðrÞ 5 ε 2 rm
r
 12
2 2 rm
r
 9
2 rm
r
 6  	; ð3:30Þ
where rm is the distance at which there is maximum attraction. In Eq. (3.30),
the inclusion of the r
29 term means that the C6 dispersion coefficient is
closer to the experimentally determined value.
3.6.1.3 MaitlandSmith potential
There is no theoretical basis to justify the r
212 dependence of repulsion in
the LJ, Kihara, or Egelstaff potentials. This fact motivated Maitland and
FIGURE 3.4 Comparison of α as a function of n for various nm potentials, where m 5 4 (x),
5 (Δ)6(1), 7, (e), and 10(&). The dotted red lines for α 5 0.5 and 1.6 contrast the greater
number of possible combinations for m $ 6 compared with m 5 4, which can only intersect
with m 5 5 data.
Intermolecular pair potentials and force fields Chapter | 3 69Smith (1973) to propose the following modification of the LJ potential using
a generalized distance term (x).
ueffðrÞ 5 ε
6
n 2 6

 x2n 2 n
n 2 6
 x26
 	 ð3:31Þ
Eq. (3.31) retains the r
26 dependence of dispersion but the value of n,
which governs the distance-dependence of repulsion is obtained from
n 5 13:0 1 γð Þ x 2 1 ; ð3:32Þ
where γ is an adjustable parameter. This three-parameter potential more
accurately (Kohler et al., 1976) describes the properties of inert gases than
the LJ potential.
3.6.1.4 BornMayer and London potentials
The early work of Born and Mayer (1932) indicated that the repulsion
between atoms should have an exponential dependence on distance because
of the overlap of wave functions. If the BornMayer exponential term is
coupled with the London dispersion formula, we obtain
ueffð Þr 5 Aexpð Þ 2Br 2 C6
r6 ; ð3:33Þ
where A and B are empirical constants determined from experimental data.
London (1937) also recognized the theoretical superiority of the exponential
form proposing the following potential
ueffð Þr 5 bexp 2r
a
  2 C6
r6 2 C8
r8 ; ð3:34Þ
where a and b are adjustable parameters.
3.6.1.5 BuckinghamCorner potential
A limitation of both the BornMayer and London potentials is that they go
to -N at the origin. This deficiency was addressed by Buckingham and
Corner (1947), who proposed the following modification
ueffð Þr 5
b exp

2αr
rm

2

 C6
r6 1
C8
r8

exp
24

 rm
r 21
3	
r # rm
b exp

2αr
rm

2 C6
r6 2 C8
r8 r . rm
;
8
>>>>><
>>>>>:
ð3:35Þ
where rm is the distance at which the energy is a minimum and α is the
steepness of the exponential repulsion. Despite their theoretical superiority,
70 Molecular Simulation of Fluidsthe earlier potentials have not been adopted widely in molecular simulation.
Arguably Eq. (3.35) has been superseded by the more practical exp-6 poten￾tial (Rice and Hirschfeler, 1954) discussed below. Some applications of
Eq. (3.34) have been reported (Homer et al., 1991).
A common feature of Eqs. (3.33) to (3.35) is the use of an exponential term
for repulsion. Although these potentials may have not been widely used in
molecular simulations, a general exponential model for repulsion has proved
useful in many different contexts (Sherwood and Mason, 1965; Kooij and
Lerner, 2017; Bacher et al., 2018a,b; Pedersen et al., 2019) and contributed to
the development of improved equations of state (Lafitte et al., 2013).
3.6.1.6 ShaviitBoys potential
Another interesting variation on the use of an exponential term is the poten￾tial proposed by Shavitt and Boys (1956),
ueffð Þr 5 4ε
r
σ
 2
1B2
h i3
XN
i50
C2i
r
σ
 2i
exp A 2 A r
σ
 2  	 2 1
 ; ð3:36Þ
where A, B, C0, C2, and C4 are adjustable constants. This potential has been
applied (Munn, 1964) to inert gases but no simulation data have been
reported.
3.6.1.7 Modified Buckingham (exp-6) potential
Possibly the most-widely used intermolecular potential containing an exponen￾tial term is the modified Buckingham or exp-6 potential originally proposed by
Rice and Hirschfeler (1954). The exp-6 potential is based on the BornMayer
potential. For practical applications, the form of the exp-6 potential is,
ueffð Þr 5
N r # λrm
ε
1 2 6
α
 6
α exp
α


1 2 r
rm
	 2

 rm
r
6
r . λrm;
8
><
>:
ð3:37Þ
where λrm is the distance at which Eq. (3.37) goes through a false maximum.
Eq. (3.37) often appears in the literature without an attribution to work of
Rice and Hirschfeler (1954), which is perhaps testimony to its widespread
familiarity. The value of λ can be obtained (Hirschfelder et al., 1954) by
finding the smallest root of the following equation:
λ7
exp½  αð1 2 λÞ 2 1 5 0 ð3:38Þ
The false maximum is an unsatisfactory feature of the exp-6 potential. At
r 5 0 the exponential term has a finite value allowing the dispersion term to
dominate at very small intermolecular separation. Consequently, the potential
Intermolecular pair potentials and force fields Chapter | 3 71passes through a maximum and then tends to 2N as r -0. Therefore, the
condition that u(r) 5N when r # λrm must be imposed to use the potential
meaningfully in a simulation. Alternatively, damping functions (see discus￾sion below) for the dispersion term have been proposed, which overcome
this problem.
It is apparent from Eq. (3.37) that α 6¼ 6. A value of α 5 7 corresponds to
λ 5 1, which would mean an abrupt transition to infinite repulsion at rm.
Therefore, physically meaningful values commence from α . 7. The rela￾tionship between α and λ that values that are obtained from solving
Eq. (3.38) are illustrated in Fig. 3.5.
Fig. 3.5 shows that when α is reasonably large, the issue of infinite repul￾sion at small separations for the exp-6 potential is unlikely to be encountered
for the properties of fluids under normal conditions.
For real fluids, values of α are typically in the range of 12 to 15 (Wu and
Sadus, 2000). For this range of values, the following relationships have been
determined (Wu and Sadus, 2000) between σ, λ, and rm.
σ 5 0:71311 1 0:01966α 2 5:0619 3 1024α2  rm
λ 5 1:76044 2 0:18315α 1 0:00514α2

ð3:39Þ
The LJ potential is compared in Fig. 3.6 with the exp-6 potentials for dif￾ferent values of α, which indicates a reduction in the steepness of repulsion
when α , 15. This partially explains the improved accuracy of the exp-6
potential for the properties of real fluids.
It has been observed (Galliero and Boned, 2008) that a value of
α 5 13.772 approximately corresponds to the LJ and exp-6 having the same
FIGURE 3.5 Values of λ as a function α for the exp-6 potential obtained from solving Eq. (3.38).
72 Molecular Simulation of Fluidscurvature at rm, whereas α 5 14.338 yields equal values of energy at rm.
Although such mapping of different potentials is interesting, from the per￾spective of improving the accuracy of predictions, there is nothing to be
gained by effectively limiting the behavior of the exp-6 potential to the infe￾rior LJ potential. Conversely, there would be considerable merit in trans￾forming an accurate but complicated potential to a simpler, but equally
accurate, representation that greatly facilitated computations.
Molecular simulation has been used (de Kuijper et al., 1990; Sellers
et al., 2015) to evaluate the properties of the exp-6 potential and it has been
applied in simulations of the phase behavior of the helium 1 hydrogen
binary mixture (Schouten et al., 1991). Zarragoicoechea and Scalise (1997)
used the exp-6 potential to simulate “gasgas” phase equilibria of nonpolar
mixtures. The effect of α on VLE has been investigated (Tavares and
Sandler, 1996) using Gibbs ensemble (Panagiotopoulos, 1987) simulation
(Chapter 10). Increasing the value of α reduces substantially the range of
temperatures for which vaporliquid coexistence is observed. Wu and Sadus
(2000) have demonstrated that the exp-6 potential yields reliable calculation
of high pressure VLE of binary atomic mixtures. It has also been used to
investigate SLE, involving the freezing transition (Khrapak et al., 2011),
high pressure behavior (Saija and Prestipino, 2005), and the possibility of re￾entrant melting (Saija et al., 2010).
The exp-6 potential has been applied successfully to polar fluids
(Peyrovedin and Shariati, 2020). For example, a MD study has been reported
(Koshi and Matsui, 1994) for the high temperature phase separation in the
water 1 nitrogen binary mixture. The supercritical properties of water have
FIGURE 3.6 Comparison of the exp-6 potential with the LJ potential (dashed gray line).
Results are given from right to left for α 5 12 (red line), 13 (blue line), and 15 (green line).
Intermolecular pair potentials and force fields Chapter | 3 73been studied (Bastea and Fried, 2008) with an exp-6 potential augmented by
dipolar interactions. It has also been used (Galliero and Boned, 2008) to pre￾dict transport properties.
3.6.2 General refinement of repulsion and dispersion models
It is evident from the preceding discussion that many successful intermolecu￾lar potentials treat repulsion as having an exponential dependence on inter￾molecular separation. It is well-documented (Stone, 2013) that even the
simple potential of Born and Mayer (1932) provides a very accurate descrip￾tion of repulsion at moderate densities. However, as discussed in detail else￾where (Buckingham et al., 1988; van Vleet et al., 2016), considerable efforts
have been made to both improve the prediction of short-ranged repulsion
and more accurately represent the contribution of dispersion interactions.
A refined model of repulsion is the exchange Coulomb model (Dham
et al., 1989; Stone, 2013), for which the energy of repulsion is represented by
Erep 5 γð Þ 1 1 ar exp a0 1 a1 1 a1
r 1 a2
r2
h i; ð3:40Þ
where the constants are fitted using accurate ab initio charge densities for the
atoms.
When an exponential repulsion term is coupled to a dispersion term, it is often
found that the dispersion term dominates at small intermolecular separation. This
can result in a unrealistic intermolecular potential as illustrated by the exp-6
potential, which has a false maximum. This problem is overcome by introducing
a damping term for the dispersion term. For example, in the HartreeFock disper￾sion (HFD) model (Hepburn et al., 1975; Ahlrichs et al., 1977),
udispð Þr 5 F rð Þ C6
r6 1
C8
r8 1
C10
r10 
 ; ð3:41Þ
where
FðrÞ 5 exp
2

 1:28rm
r 21
2	
r , 1:28rm
1 r $ 1:28rm
8
><
>:
ð3:42Þ
Eq. (3.41) was obtained by fitting the dispersion interactions for molecu￾lar hydrogen assuming that the same correction could be applied to all of the
dispersion contributions.
Douketis et al. (1982) determined different damping terms for each con￾tribution to dispersion, that is,
udispðrÞ 5 2 X
n 5 6;8;10
FnðrÞ
Cn
rn ; ð3:43Þ
74 Molecular Simulation of Fluidswhere
Fnð Þr 5 gð Þ ρr fnð Þ ρr : ð3:44Þ
In Eq. (3.43), fn is a damping function to correct for charge overlap in the
R2n term; g is the correction for exchange effects in the dispersion terms;
and ρ is a scaling distance. When ρ 5 1, we find (Kreek and Meath, 1969):
g rð Þ 5 1 2 r
1:68expðÞ ð 20:78r 3:45Þ
fnð Þr 5 12exp 22:1r
n 2 0:109r2
ffiffiffi
n p
 	 
  n
ð3:46Þ
Various alternative damping functions have been proposed, which
improve the prediction of the potential for various properties (Koide et al.,
1981; Tang and Toennies, 1984; Wheatley and Meath, 1993; Boyes, 1994).
For example, the damping function for argon proposed by Boyes (1994)
improves the prediction of acoustic virial coefficients.
3.6.3 Shifted-force potentials
A common feature of realistic potentials is that the intermolecular potential
only asymptotes to zero at large intermolecular separation. That is zero energy
is not achieved at large separation. It is sometimes expedient computationally
to have a potential, which is exactly zero at distances beyond a cut-off point
rc. This can be achieved by applying the following transformation yielding a
shifted-force us(r) potential (Haile, 1992; Nicolas et al., 1979).
usð Þr 5 uðrÞ 2 uðrcÞ 2 ðr 2 rcÞ

 du
dr
rc
r # rc
0 r . rc
8
<
:
ð3:47Þ
Eq. (3.47) can be applied to any continuous intermolecular potential. The
advantage of Eq. (3.47) is that long range corrections (LRC) (Chapter 5) are
not required because us(r) 5 0 at and after the cut-off distance (rc). The use
of LRC introduces a degree of uncertainty when comparing different simula￾tion data that use different cut-off values. Ahmed and Sadus (2010) com￾pared the SLE properties from the shift-force LJ potential to those obtained
using the full LJ potential. A value of rc 5 6.5σ was required to obtain con￾sistent results between the potentials.
3.6.4 SR potentials
An alternative to the shifted-force approach is to develop a continuous poten￾tial that deliberately has a restricted range. This approach has the advantages
Intermolecular pair potentials and force fields Chapter | 3 75of both avoiding LRC and discontinuities in the force due to the shift-force
approach. Hoover (2006) proposed the following 84 potential,
ueffð Þr 5 ε 22 r
σ
 2 
 8
2 2 22 r
σ
 2 
 4 " #; ð3:48Þ
where the interactions between particles are restricted to a very narrow range of
separations, that is, r # ffiffiffi
2 p σ. This simple potential has proved particularly use￾ful (Travis and Sadus, 2023) in examining high pressure phase transitions.
In the same spirit of Eq. (3.49), a generalized SR potential can be devised
(Wang et al., 2020) depending on the choice of n and m exponents and rc,
ueffð Þr 5 γε σ
r
 2n
2 1

  rc
r
 2n
21

 2m
ð3:49Þ
where γ is a term that ensures that the depth of the well is -ε.
rm 5 rc

 112m
112mr2m
c
1=2m
γ 5 2mr2m
c

 112m
2mðr2m
c 21Þ
2m11
9
>>>>>=
>>>>>;
ð3:50Þ
When n 5 m 5 1 and rc 5 2.5σ, Eq. (3.49) generates the conventional phase
diagram with VLE, SLE, and triple and critical points. In contrast, n 5 m 5 1
and rc 5 1.2σ yields a phase diagram associated with some colloidal systems. A
comparison of the SR potentials with the LJ potential is given in Fig. 3.7. It is
FIGURE 3.7 Comparison of the LJ potential with the short-ranged 84 (Eq. (3.48)) and Wang
et al. (Eq. (3.49), n 5 m 5 1, rc 5 2.5σ, γ 5 0.2915) potentials. The 84 and Wang et al. poten￾tials are exactly zero beyond a distance of ffiffiffi
2 p σ and 2.5σ, respectively.
76 Molecular Simulation of Fluidsevident that the shape of the potentials is distinct (Chapter 4), which will be
reflected in different macroscopic properties.
3.7 Contributions to molecular interactions
Constructing an accurate pair potential for a molecule is considerably more
complicated than an atomic potential. The nonspherical nature of the electron
clouds of polyatomic molecules introduces many additional problems such
as anisotropic overlap, dispersion, and induction forces etc. These problems
can be tackled using ab initio methods such as HartreeFock or density
function theory (Chapter 4). However, a simple alternative is to use a semi￾empirical approach to construct a potential, which includes various molecular
contributions. The first step in formulating a molecular potential is to iden￾tify the various molecular contributions. These contributions are commonly
incorporated into an overall model of the molecule governed by a compre￾hensive force field (Chapter 4).
For a molecule, we can identify contributions to the potential from both
inter- and intramolecular interactions. The intermolecular interactions are the
interactions between the different atoms of the molecule, which occur inde￾pendently of molecular bonds. In addition, a molecule will experience the
effects of intramolecular interactions as a consequence of molecular bonds.
The separation between intra- and intermolecular interactions is based some￾what arbitrarily on the extent of intermolecular distance. It is common to
assume that atoms separated by four or more bonds are distant and interact
only via nonbonding forces. Therefore, bond interactions are restricted to
atoms that are bonded directly together (1,2 interactions), atoms that are
joined via bonds to a common atom (1,3 interactions), and atoms with a
topology involving three intermediary bonds (1,4 interactions). The potential
associated with these interactions are functions of bond lengths, bond angles,
proper torsional angles, and improper torsional angles.
3.7.1 Intermolecular ionic and polar potentials
Unlike atoms, molecules are associated commonly with permanent multipole
moments or charges, which result in electrostatic interactions. The theoretical
basis of electrostatic interactions is well known (Hirschfelder et al., 1954).
The application of Coulomb’s law of electrostatic interaction between
charges q, dipole moments μ, and quadrupole moments Q between molecules
a and b yields,
uð Þ q;q ð Þr 5 qaqb
4πεor ð3:51Þ
uð Þ q;μ ð Þr 5 2 qaμbcosθb
4πεor2 ð3:52Þ
Intermolecular pair potentials and force fields Chapter | 3 77uð Þ q;Q ð Þr 5 qaQb 3cos2θb 2 1  
16πεor3 ð3:53Þ
uð Þ μ;μ ð Þr 5 2 μaμb 2cosθa cosθb 2 sinθa sinθb cos φa 2 φb
   
4πεor3 ð3:54Þ
uð Þ μ;Q ð Þr 5 3μaQb
16πεor4
cosθa 3cos2θb 2 1  
2 2sinθa sinθb cosθb cos φa 2 φb
   	 ð3:55Þ
uð Þ Q;Q ð Þr 5 3QaQb
64πεor5
1 2 5cos2θa 2 5cos2θb 2 15cos2θa cos2θb
1 2 sinθa sinθb cos φa2φb
 24cosθa cosθb
 2
 	 ð3:56Þ
where the angles θa, θb, Φa, and Φb are defined in Fig. 3.8. The earlier electro￾static terms represent pointdipoles, pointquadrupoles, and the like. Polar
molecules can also be modeled by placing partial changes on selected sites.
Eqs. (3.51) to (3.56) each include a contribution in the denominator of
4πεo. This term is required when SI units are used for u(J) r(m), q(C), μ
(Cm), and Q(Cm2
). The value εo 5 8:854188128 13 ð Þ 3 10212C2N21m22 is
the vacuum electric permittivity (Tiesinga et al., 2021) and the contribution
of 4π is required to rationalize the units (Kennelly, 1931) for spherical
symmetry.
The previous definitions assume that the interactions are completely
unobstructed as would be the case in a vacuum. For many real molecules,
more realistic values of the electrostatic interactions can be obtained by
including the dimensionless value of relative permittivity (εr) in the denomi￾nator. This contribution can be quite substantial for nonpolar systems, for
example, εr 5 78.5 at 298 K for water (Raabe and Sadus, 2011). By defini￾tion, εr 5 1 is the lower limit for a vacuum.
It should be noted that because all of the multipolar potentials decay
more slowly than r
23 special techniques such as the Ewald sum (Allen and
Tildesley, 2017) are required in the simulation to account for LR interactions
(Chapter 4). However, we can also calculate an average contribution of
FIGURE 3.8 Definition of angles for multipole interaction of two molecules denoted by a and
b. The dotted lines through the centers of a and b indicate the axis of either the dipole or quadru￾pole of the molecules.
78 Molecular Simulation of Fluidsmultipolar interactions. The results (Hirschfelder et al., 1954) when using SI
units are:
uð Þ q;q ave ð Þr 5 qaqb
4πεor ð3:57Þ
uð Þ q;μ ave ð Þr 5 2 q2
aμ2
b
3 4ð Þ πε0
2
kTr4 ð3:58Þ
uð Þ q;Q ave ð Þr 5 2 q2
aQ2
b
20 4ð Þ πε0
2
kTr6 ð3:59Þ
uð Þ μ;μ ave ð Þr 5 2 μ2
aμ2
b
3 4ð Þ πε0
2
kTr6 ð3:60Þ
uð Þ μ;Q ave ð Þr 5 2 μ2
aQ2
b
ð Þ 4πε0
2
kTr8 ð3:61Þ
uð Þ Q;Q ave ð Þr 5 2 7Q2
aQ2
b
40 4ð Þ πε0
2
kTr10 ð3:62Þ
Historically, many force fields (see discussion below) have been developed
using non-SI units for the charge and other multipolar interactions and as such not
include the 4πεo term. Notice that, except for the Coulomb term (Eq. (3.58)), the
contribution of the average-angled interactions will always be ,0, whereas the
sign of values obtained from Eqs. (3.52) to (3.56) is angle-dependent.
Except for chargecharge interaction (Eq. (3.51)) that remains unaltered, the
average multipolar interactions decay faster than r
23
. Consequently, LR interac￾tions are not an issue when using these potentials. Furthermore, the need to eval￾uate intermolecular angles and trigonometric functions is eliminated.
In simulations it is often convenient to use reduced units, which in this
case means q 5 q= ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
4πεoσε p , μ 5 μ= ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
4πεoσ3ε p , Q 5 Q= ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
4πεoσ5ε p ,
r 5 r=σ, and T 5 kT=ε. These definitions allow us to compare Eqs. (3.57) to
(3.62) in Fig. 3.9 for the special case when all the contributions are equal to
one. It is apparent from Fig. 3.9 that chargecharge interactions dominate at
all separations. Chargedipole interactions are also important but decline
much more rapidly. In contrast, the contribution of chargequadrupole inter￾actions is noticeably less important. Dipoledipole interactions are the most
important noncharge interaction. However, at relatively small separations,
dipolequadrupole interactions takeover. Of course, the relative importance of
these contributions will be affected by the charge, dipole, and quadrupole
moments. In general, we can expect that chargecharge interactions will dom￾inate with dipoledipole interactions being the most important noncharge con￾tribution. If both chargecharge and noncharge interactions are present, the
effect of the latter will be to subtract from the repulsive nature of the former.
Intermolecular pair potentials and force fields Chapter | 3 79Simulation studies of quadrupolequadrupole and quadrupoledipole
interactions are also available (Smit and Williams, 1990; Dubey and O’Shea,
1994; Jiang and Pitzer, 1995; O’Shea et al., 1997). The critical temperature
of a fluid is directly proportional to the strength of the quadrupole moment
(Stapleton et al., 1989). The effects of chargequadrupole interactions have
not been studied by molecular simulation.
Sadus (1996a,b) reported simulations of both vaporliquid and
liquidliquid equilibria of dipolar fluids using the Keesom potential, which
combines the LJ potential with a potential similar to Eq. (3.59). Comparison
with calculations using the Stockmayer potential indicates that the average
dipole potential was a good approximation for relatively weak dipoles.
However, for strong dipoles large differences in the predicted VLE can be
expected (Gao et al., 1997) using the Keesom and Stockmayer potentials.
MD calculations of the pressurevolumetemperature behavior of polariz￾able dipolar linear molecules and rigid polarizable molecules are available
(Kriebel and Winkelmann, 1996, 1998). The averaged multipolar contribu￾tions have proved useful in coarse graining the properties of a number of
real fluids (Mu¨ller and Gelb, 2003; Mognetti et al., 2008).
3.7.2 Intermolecular hydrogen bond potentials
Hydrogen bond interactions are a special class of nonbonded interactions. It
is often found that conventional nonbonded potentials do not account accu￾rately for hydrogen bonding. For example, instead of the traditional 126 LJ
FIGURE 3.9 Comparison of the absolute value of the reduced potential energy (log scale) ver￾sus separation for chargecharge (r), chargedipole (x), chargequadrupole (e) dipoledi￾pole (&), dipolequadrupole (Δ), and quadrupolequadrupole (e) interactions obtained from
Eqs. (3.57) to (3.62) when q 5 μ 5 Q 5 T 5 1.
80 Molecular Simulation of Fluidspotential, the effect of hydrogen bonding can be described more accurately
using a 1210 LJ potential
ueffð Þr 5 A
r12 2 C
r10 ; ð3:63Þ
where A and C are empirical constants. The 1210 potential provides an
improved description of the geometry of hydrogen bonding between the
hydrogen atom and the acceptor atom. Other potentials attempt to account
for deviations from the hydrogen bond geometry. Goodford (1985) proposed
ueffð Þr 5 C
r6 2 D
r4

 cos4
θ; ð3:64Þ
where C and D are empirical parameters and θ is the angle subtended at the
hydrogen. Vedani (1988) proposed the following potential
ueffð Þr 5 A
r12
H2Acc
2 C
r10
H2Acc

 cos2
θDon2H2Acccos4
ωH2Acc2LP; ð3:65Þ
where rH-Acc is the distance between the hydrogen atom (H) and the acceptor
atom (Acc); θdon-H-acc is the inner angle formed by the donor molecule
(Don), hydrogen atom and acceptor molecule configuration; and ωH-Acc-LP is
the angle formed between the hydrogen atom, the acceptor molecule (Acc),
and the lone pair (LP) of electrons on the acceptor molecule.
3.7.3 Intramolecular bond potentials
The bond potential represents the effect of bond stretching. The Morse potential
(Rappe´ and Casewit, 1997) is an example of an accurate bond potential,
ubð Þ b 5 De 12exp½  2αðl2l0Þ  2 ð3:66Þ
where De is the bond dissociation energy, α is a constant that depends on
both the masses of the atoms and the shape of the potential well, and l0 is
the reference or natural bond separation. It should be noted that the reference
bond length is not necessarily the same as the equilibrium bond separation.
The reference bond length is the separation when all other force terms expe￾rienced by the molecule are zero. In contrast, the equilibrium bond separa￾tion reflects the contribution of other forces on the molecule.
The Morse potential is a physically realistic representation of a bond,
which allows for the breaking of bonds at large interatomic separation.
However, evaluating the exponential term is expensive computationally. It
also requires the evaluation of three potential parameters (De, l0, and α). If
bond dissociation is excluded, a simple alternative can be obtained by
expanding Eq. (3.67) about the equilibrium separation
ubð Þl 5 Kbð Þ l2l0
2
2
1 2 αð Þ l 2 l0 1
7
12 
 α2
ð Þ l2l0
2 1?
 	; ð3:67Þ
Intermolecular pair potentials and force fields Chapter | 3 81where Kb 5 2Deα2
. Eq. (3.67) eliminates the evaluation of the exponential
term but three parameters must be evaluated per bond stretch. If only the
first term of Eq. (3.67) is used, the bond potential takes the form of Hooke’s
law
ubð Þl 5 Kbð Þ l2l0
2
2 ; ð3:68Þ
where Kb is the force constant. The choice between these different levels of
approximation depends on the accuracy of the desired calculation and
computational expediency. Eq. (3.68) is a good approximation for bonding
in ground-state molecules but it is considerably less accurate than the other
alternatives at nonequilibrium separations.
3.7.4 Intramolecular angle-bending potentials
A Hooke’s law approach is also used commonly for both the bond-angle
potential and out-of-plane bending. The bond-angle potential can be evalu￾ated (Dinur and Hagler, 1991) from either
ubð Þ θ 5 Kθð Þ θ2θ0
2
2
1 2 α θð Þ 2 θ0 1
7
12 
 α2
ð Þ θ2θ0
2 1?
 	 ð3:69Þ
or
uθð Þ θ 5 Kθð Þ θ2θ0
2
2 ; ð3:70Þ
where Kθ is the bending force constant and θ0 is the reference or normal
bond angle. Eq. (3.69) represents simple, harmonic bending, which is
suitable for open and unstrained chains. In contrast, Eq. (3.69) is a more
accurate alternative if anharmonicity is present.
More sophisticated alternatives for angle bending have been developed.
For example, Rappe´ et al. (1992) proposed the following angle-bending
potential.
uθð Þ θ 5 Kθ
2cos2θ0 1 1
4sin2
θ0
2 4cosθ0 cosθ
4sin2
θ0
1
cos2θ
4sin2
θ0

  ð3:71Þ
Unlike potentials that assume an idealized geometry, Eq. (3.71) is in prin￾ciple valid for all nonlinear geometries.
3.7.5 Intramolecular out-of-plane bending potentials
Out-of-plane bending occurs typically in planar molecules with trigonal cen￾ters. The energy associated with out-of-plane bending arises from the dis￾placement of the trigonal atom either above or below the molecular plane.
82 Molecular Simulation of FluidsOut-of-plane bending is usually harmonic, and the potential is given (Dinur
and Hagler, 1991) simply by
uχð Þ χ 5 Kχ χ2χ0
 2
2 ; ð3:72Þ
where Kχ is the barrier for out-of-plane bending and χ0 is the reference
angle for out-of-plane bending.
3.7.6 Intramolecular torsional potentials
The torsional potential represents the effect of rotation about a bond and as
such it is a function of the dihedral angles. It can be calculated from a
Fourier series expansion (Dinur and Hagler, 1991)
uτ ð Þ τ 5 1
2
X
j
Vj 1 1 2ð Þ 1 j11
cosð Þ jτ  ; ð3:73Þ
where Vj is the rotational barrier height, τ is the dihedral angle, and j is the
periodicity.
3.7.7 Intramolecular cross-terms
In principle, every motion of a molecule is coupled to other motions.
Consequently, an accurate description of the physics of motion sometimes
requires cross-terms that represent the coupling of different types of motion.
Fortunately, the coupling effect is only really significant for neighboring
motions. The effect of coupling stretchstretch interactions between bonds 1
and 2 can be represented (Dinur and Hagler, 1991) by
u lð Þ 1; l2 5 Kl1;2 l1 2 l1;0
  l2 2 l2;0
   
2 ð3:74Þ
Experimental observations indicate that reducing the bond angle between
bonds will induce bond stretching to minimize the strain. The effect of bond￾stretching and bond-angle motion can be obtained from the following potential:
u lð Þ 1; l2; θ 5 Kl1;2 l1 2 l1;0
  1 l2 2 l2;0
    ð Þ θ 2 θ0
2 ; ð3:75Þ
where the two bonds (denoted 1 and 2) are joined to a common atom and θ
is the angle between these two bonds. An alternative to Eq. (3.76) is the
UreyBradley potential, which determines the potential between the non￾bonded atoms (denoted 1 and 3) as a result of bond-stretching and bond￾angle motion. The UreyBradley potential is
u rð Þ 123 5 Kr123 r1232r123;0
 2
2 ; ð3:76Þ
Intermolecular pair potentials and force fields Chapter | 3 83where the distances refer to the separation between the nonbonded atoms.
The torsional motion can be coupled to both stretching and bond-bending
motion. The coupling of torsion and stretching terms can be obtained from
u lð Þ ; τ 5 Kl;τ ½  ð Þ l 2 l0 ð Þ 1 1 cos3τ
2 ; ð3:77Þ
whereas the interaction between torsional motion and bond bending can be
represented (Dinur and Hagler, 1991) by:
uð Þ θ; τ 5 Kθ;τ ð Þ θ 2 θ0 ð Þ 1 2 cosτ
2 : ð3:78Þ
In the case of molecules forming two angles at a common center, the
effect of two bendbend interactions must be considered.
uð Þ θ1; θ2 5 Kθ1;2 θ1 2 θ1;0
  θ2 2 θ2;0
 
2 ð3:79Þ
3.8 Simple atom-based pairwise potentials for molecules
The relative importance of the intermolecular and intramolecular terms
depends on the nature of the molecule. It should be emphasized that the non￾bonded interactions are of primary importance. Often, a good representation
of the energy of the molecule can be obtained by ignoring bond and angle
terms and only considering nonbonded and electrostatic interactions. Some
examples are given below.
3.8.1 Stockmayer potential
The Stockmayer potential is obtained if Eqs. (3.25) and (3.54) are used for the
contributions from repulsion, dispersion, and dipolar interactions, respectively.
ueffð Þ r; θ; φ 5 4ε

 σ
r
12
2

 σ
r
6	
2 μaμb 2cosθa cosθb 2 sinθa sinθb cos φa 2 φb
   
4πε0r3
ð3:80Þ
Several simulations have been reported using the Stockmayer potential to
investigate the effect of dipoledipole interactions on the VLE of pure fluids
(Smit et al., 1989; van Leeuwen and Smit, 1993; van Leeuwen et al., 1993;
Bartke and Hentschke, 2007; Jia and Hentschke, 2011). The work of van
Leeuwen and Smit (1993) indicates that dispersion interactions are necessary
to sustain vaporliquid phase coexistence in a dipolar fluid. The Stockmayer
potential has also been used to study polar 1 nonpolar binary mixtures (de
Leeuw et al., 1990; Mooij et al., 1992). The excess free energy of mixing
decreases with increasing polarizability and at high dipole strength, the
84 Molecular Simulation of Fluidsdipolar and nonpolar components separate into different phases. The VLE of
binary mixtures interacting via the Stockmayer potential has been investi￾gated (Gao et al., 1997). The effect of dipolar interaction is to increase the
region of two-phase coexistence. A theoretical explanation of the dependence
of the critical point on the dipole strength of the Stockmayer fluid has been
determined (Hentschke et al., 2007). The usefulness of the Stockmayer
potential to molecules is limited because molecules are not spherical.
In the force fields given below, the 4πε0 term does not appear in the elec￾trostatic contributions because the parameterization has been most commonly
reported using non-SI units. Therefore, some care is required when convert￾ing to SI units.
3.8.2 SpurlingMason potential
Spurling and Mason (1967) studied the virial coefficients and viscosity data
of quadrupolar molecules using a potential, which explicitly incorporated the
effect of quadrupole moments and other molecular factors. Their potential is
ueffð Þr 5 4ε

 σ
r
12
2

 σ
r
6	
1
3Q2
r5
1 2 5 cos2θa 1 cos2θb
  2 15cos2θa cos2θb
1 2sinθa sinθb cos φa 2 φb
   	
2 9Q2αm
8r8 sin4
θa 1 sin4
θb 1 4 cos4
θa 1 cos4
θb
   
1 4ε

 σ
r
6
κ 2 3
2
κ 2 κ2   cos2θa 1 cos2θb
 
2 κ2 sinθa sinθb cos φa2φb
 22cosθa cosθb
 2
8 " # <
:
9
=
;
1 4Dε

 σ
r
12
3 cos2θa 1 cos2θb
  2 2  
;
ð3:81Þ
where αm, κ, and D are the mean polarizability, the anisotropy of the polariz￾ability, and a shape parameter, respectively. The first term in Eq. (3.82) is
the LJ potential. The second and third terms represent the effect of quadru￾pole, and quadrupole-induced dipole interactions, respectively. The potential
also attempts to account for molecular anisotropy (fourth term) and shape
(fifth term). When Eq. (3.82) is applied to the viscosity data of small poly￾atomic molecules, reasonable estimates of the quadrupole moments can be
obtained (Spurling and Mason, 1967).
3.8.3 Restricted primitive model
Molten salts (Hansen and McDonald, 1975) and other ionic (Smith and
Haymet, 1993) fluids have been studied using chargecharge potentials.
Intermolecular pair potentials and force fields Chapter | 3 85Potentials of the form of Eq. (3.52) have been used in simulations of aqueous
electrolyte solutions. The most commonly used potential for ionic fluids is
the restricted primitive model (RPM), which is composed of a HS potential
in conjunction with Eq. (3.54).
ueffð Þr 5 uHSð Þr 1 qaqb
r ð3:82Þ
Orkoulas and Panagiotopoulos (1994) have reported MC calculations of
the free energy and phase equilibria of an ionic fluid using the RPM poten￾tial. The dielectric constant of RPM electrolytes on the vapor branch of the
coexistence line has also been reported (Caillol, 1995).
3.8.4 FumiTosi potential
A more realistic intermolecular potential for ions is the Fumi and Tosi
(1964) potential,
ueffð Þr 5 Aexpð Þ 2Br 2 E
r6 2 D
r8 1 qaqb
r ð3:83Þ
where A, B, D, and E are parameters obtained from fitting experimental data.
Strauch and Cummings (1993) have used the HugginsMayer form of this
potential to calculate successfully vaporliquid equilibria in water 1 NaCl
and water 1 methanol 1 NaCl mixtures. Guissani and Guillot (1994) used
Eq. (3.50) to determine the critical point of NaCl.
3.9 Extension to molecules
3.9.1 Nonbonded interactions in molecules
The proceeding sections have focused exclusively on atomic systems but the
potentials can be directly applied within a molecular framework. Irrespective
of the complexity of a molecule, the dispersion and repulsion interactions of
the atoms that constitute the molecule are of primary importance. This non￾bonded contribution can be calculated by using any of the potentials discussed
earlier in the chapter. In practice, the most-widely used approach for calculat￾ing nonbonded interactions is to model molecules as a series of interaction
sites. The interaction sites usually coincide with the constituent atoms of the
molecule. Consequently, a simple atomic potential such as the LJ potential is
used to evaluate the various atomatom interactions. For example (Cheung
and Powles, 1975; Monson et al., 1983), the interactions between molecules
(i and j) each composed of m-atoms can be calculated from
uij rαβ   5 Xm
α51
Xm
β51
4ε σ
rαβ 
 12
2 σ
rαβ 
 6 " #; ð3:84Þ
86 Molecular Simulation of Fluidswhere rαβ is the separation of atoms α and β on two different molecules. In
Eq. (3.84), the LJ is used as an example only and any other pair atomic
potential can be substituted. The atomatom model of a diatomic molecule
is illustrated in Fig. 3.10.
3.9.2 Adding nonbonded interactions: the WCA 1 finitely
extensible nonlinear elastic potential
In Section 3.9, quite complicated molecular potentials will be examined, but
a simple example of a molecular system is a chain of atoms that require us
to consider both nonbonded interactions and molecular constraints. Possibly
the simplest model for chain or polymer molecules is the freely jointed tan￾gent HS chain. This approach neglects variation of bond length and torsional
angles but it incorporates some essential features such as molecular connec￾tivity and intra- and intermolecular sitesite excluded volume interactions.
Molecular simulation of the properties of chains containing up to 200 sites
have been reported (Gao and Weiner, 1989). Data for mixtures of chains are
limited to relatively small chains (Chang and Sandler, 1995).
A somewhat more realistic model for molecular chains can be obtained
by combining the WCA potential for the excluded volume of the HS beads
(nonboded interactions) with the finitely extensible nonlinear elastic (FENE)
potential (Warner, 1972; Grest and Kremer, 1986) that is responsible for
maintaining the molecular topology of the beads via both a maximum intra￾molecular separation (r0) and a “spring constant” (K).
uFENEð Þr 5
Kr2
0 ln
1 2

 r
r0
2	
2 r , r0
N r $ r0
8
>>>><
>>>>:
ð3:85Þ
FIGURE 3.10 An atomatom model of a diatomic molecule.
Intermolecular pair potentials and force fields Chapter | 3 87The WCA 1 FENE potential has proven very useful (Bosko et al., 2004)
in determining the viscoelastic properties of dendrimers of different genera￾tions (Newkome et al., 2001).
3.10 Pairwise force fields from molecular mechanics
In view of the preceding considerations, the energy of a molecular system
resulting from pairwise interactions can be evaluated from
U rð Þ ; l; θ; τ;χ 5 X
nonbonds
unbðrÞ 1 X
bonds
ubðlÞ 1 X
bending
uθðθÞ 1 X
dihedral
uτ ðτÞ
1 X
out 2 of 2 plane
uχðχÞ 1 Xuel 1?;
ð3:86Þ
where unb is the nonbonded potential, ub is the bond potential, uθ is the
bond-angle potential, uτ is the torsional potential, uχ is the out-of-plane
bending (improper torsional) potential, and uel is the Coulombic potential.
Eq. (3.86) only includes “diagonal terms,” but it can be extended to include
contributions from “cross terms” such as bondangle or angleangle inter￾actions. This approach is referred to generally as molecular mechanics
(Dinur and Hagler, 1991; DeKock et al., 1993). For example, to model an
alkane, we can compose an overall potential, which includes a potential for
nonbonded interactions; a potential for bond-bending, and a potential for
angle torsion (Siepmann et al., 1993).
In effect, Eq. (3.86) attempts to capture the essential physics of the mole￾cule. The result is a composite potential incorporating the contributions of
the various possible intra- and intermolecular interactions. This combination
of various contributions to describe molecular interactions is commonly
referred to as a “force field.” The term of force field is obviously a misno￾mer because Eq. (3.86) evaluates the energy not the force; however the
nomenclature is in widespread use in the literature.
The accuracy of the force field depends critically on obtaining accu￾rate values for the various potential parameters. The bond and angle
parameters can be obtained from X-ray, infrared, nuclear magnetic reso￾nance, and microwave data. The nonbonded parameters can be obtained
from experimental data for second virial coefficients and molecular beam
experiments. The parameters can be calculated using ab initio and semi￾empirical methods (Maple et al., 1994; Dinur and Hagler, 1991). A com￾prehensive review of molecular mechanics has been reported (Rappe´ and
Casewit, 1997).
The primary motivation for developing force field is to realistically cap￾ture the behavior of large molecules, most notably biomolecules and proteins
(van Gunsteren et al., 2006). The literature on force fields is both large and
continuously expanding (Cisneros et al., 2013; Lopes et al., 2015; Rinker,
88 Molecular Simulation of Fluids2018), and documenting all possibilities is an impossible undertaking. The
difficulty in providing a comprehensive description is further compounded
that many “new” force fields are arguably incremental improvements on
existing ones via the use of improved parameterization rather than funda￾mentally novel insights into intermolecular behavior.
The complexity of force fields has increased to the point, that some like
the Groningen molecular simulation (GROMOS) approach (Scott et al.,
1999) have become a general software package that offer multiple possible
customizations rather than a conventional standalone force field that can be
realistically implemented independently by the researcher. Many researchers
have become expert users of force field software packages that can be tai￾lored to a diverse range of applications and molecular systems.
The following discussion is focused on a few key force fields that have
provided a framework for many other alternatives. The optimized potential
for liquid simulation (OPLS) model (Jorgensen and Tirado-Rives, 1988) is
one of the simplest force fields. Other examples of force fields are the empir￾ical conformational energy program for peptides (ECEPP/3) (Ne´methy et al.,
1992); chemistry at Harvard macromolecular mechanics (CHARMM)
(Brooks et al., 1983; Smith and Karplus, 1992); assisted model building with
energy refinement (AMBER) (Weiner et al., 1984); and molecular mechanics
(MM3) (Allinger et al., 1989; Lii and Allinger, 1989a,b) potentials. These
force fields typically contain terms involving bond stretching, bond angle,
torsional motions, and nonbonded and electrostatic interactions.
3.10.1 Optimized force fields
There are several examples of elaborate force fields that have been optimized
for various molecular properties. Historically this has involved the laborious
fitting of experimental data, although more recent approaches such as super￾vised machine learning (Behler, 2016) can be expected to an increasingly
important role (Mueller et al., 2020).
3.10.1.1 OPLS/OPLS-AA force fields
The OPLS force field is of particular interest because it is specifically opti￾mized for liquid properties (Jorgensen and Tirado-Rives, 1988). The OPLS
force field has the following form:
U 5 X
j . i
Aij
r12
ij
2 Bij
r6
ij
1 qiqj
rij !: ð3:87Þ
The interaction sites of the OPLS force field can be either nuclei or
(CH)n groups. Later, Kaminski et al. (1994) added a torsional term to create
an all-atom (AA) force field (OPLS-AA), which can be parameterized
(Damm et al., 1997) for carbohydrates. Despite its obvious simplicity, the
Intermolecular pair potentials and force fields Chapter | 3 89OPLS-AA force field often yields results of comparable accuracy (Martin,
2006) to more sophisticated alternative models (see subsequent discussion)
that are more widely used.
3.10.1.2 ECEPP models
The ECEPP/3 force field (Ne´methy et al., 1992) is an updated version of the
ECEPP force field, which was originally developed by Momany et al. (1975)
and subsequently improved (ECEPP/2) by Ne´methy et al. (1983). ECEPP/3
retains the same functional form as its predecessors but it uses an improved
set of parameters based on accurate experimental data. The ECEPP/3 force
field has the following form:
U 5X
j . i
εij
r

ij
rij
0
@
1
A
12
2 r

ij
rij
0
@
1
A
2 6
4
3
5 1X
j . i
εij 5 r

ij
rij
0
@
1
A
12
2 6 r

ij
rij
0
@
1
A
2 10
4
3
5
1X
n
Kn
2 ð Þ 1 6 cosnτn 1X
j . i
qiqj
Drij
;
ð3:88Þ
where D is the dielectric constant and r is the separation corresponding to
the minimum of nonboded pair interaction. Like the OPLS force field,
Eq. (3.88) includes the contribution of LJ interaction between nonbonded
atoms (first term) and electrostatic interactions (fourth term). However, the
ECEPP potential explicitly includes a contribution from hydrogen bonding
(the 1210 term) and torsional motion (third term).
3.10.1.3 AMBER force field
The energy obtained from the AMBER force field is calculated as:
U 5 X
bonds
Kl
2 ð Þ l2l0
2 1 X
angles
Kθ
2 ð Þ θ2θ0
2
1 X
dihedrals
X
n
Vn
2 ½  1 1 cosðnτ 2 γÞ 1X
i , j
4εij
σij
rij
0
@
1
A
12
2 σij
rij
0
@
1
A
2 6
4
3
5
1
1
vdWscale
1;
X
4terms
i , j
σij
rij
0
@
1
A
12
2 σij
rij
0
@
1
A
2 6
4
3
5 1 X
H 2 bonds
Cij
r12
ij
2 Dij
r10
ij
2
4
3
5
1X
i , j
qiqj
εrij
1
1
EEscale
1;
X
4terms
i , j
qiqj
Drij
:
ð3:89Þ
90 Molecular Simulation of FluidsIn Eq. (3.89), the first three terms represent the bonded interaction of the
molecules. These terms contain force constants for the bonds (Kl) and angles
(Kθ); l0 and θ0 are the experimentally determined normal bond distances and
angles, respectively. A truncated Fourier series represent the torsional poten￾tial with contributions from the torsional barrier (Vn), periodicity (n), the cal￾culated dihedral angle (τ), and phase (γ). The remaining terms are the
contribution of nonbonded interactions to repulsion and dispersion (LJ poten￾tial), hydrogen bonding (the 1012 term), and electrostatic interactions
between point charges (qi). The ε parameter in the last two terms is the
dielectric constant, and C and D are empirically determined parameters.
Several revisions of the AMBER force field have been made, particularly
to improve the representation of dihedral angles. This involved (Hornak
et al., 2006) making use of an improved quantum-level understanding of
interactions. An improved backbone has been reported (Best and Hummer,
2009). Its ability to deal with an aqueous protein environment has been
improved (Kirschner and Woods, 2001; Joung and Cheatham, 2008).
3.10.1.4 CHARMM force field
The CHARMM force field includes a contribution from out-of-plane bending
E 5 X
bonds
Kl
2 ð Þ l2l0
2 1 X
angles
Kθ
2 ð Þ θ2θ0
2
1 X
angles
Kχ
2 χ2χ0
 2
1 X
dihedrals
X
n
Vn
2 ½  1 1 cosð Þ nτ 2 γ
1X
i , j
4εij
σij
rij
0
@
1
A
12
2 σij
rij
0
@
1
A
2 6
4
3
5 1X
i , j
qiqj
εrij
;
ð3:90Þ
where χ is the out-of-plane angle and kχ is the force constant for out-of￾plane bending. Both the CHARMM and AMBER force fields use the same
representation of nonbonded and electrostatic forces. Unlike the AMBER
force field, the CHARMM force filed does not include a hydrogen-bonding
term. The CHARMM force field has been developed for proteins (MacKerell
et al., 1998), nucleic acids (Foloppe and MacKerell, 2000), lipids (Klauda
et al., 2010), and carbohydrates (Guvench et al., 2011). Its accuracy for these
systems is continuously updated (Best et al., 2012) with additional terms and
new parameters. The variants are often distinguished by the addition of
numerical suffixes, for example, CHARMM27.
3.10.1.5 MM3 force field
The MM3 force field (Allinger et al., 1989) incorporates a more elaborate
description of the various bond and nonbonded potentials. MM3 eliminates the
deficiencies of the earlier MM2 (Allinger, 1977) by using improved theoretical
Intermolecular pair potentials and force fields Chapter | 3 91models for bond and nonbond interactions and specifically addressing vibra￾tional and spectroscopic data. The MM3 force field is represented by Eq. (3.91).
U 5 X
bonds
Kl
2 ð Þ l2l0
2

1 2 2:55ð Þ l 2 l0 1

 7
12 
2:55ð Þ l2l0
2
	
1 X
angles
Kθ
2 ð Þ θ2θ0
2 1 2 0:014ð Þ θ 2 θ0 1 5:6 3 1025ð Þ θ2θ0
2
2 7 3 1027ð Þ θ2θ0
3 1 9 3 10210ð Þ θ2θ0
3
 	
1 X
angles
Kχ
2 χ2χeq  2 1 2 0:014 χ 2 χ0
  1 5:6 3 1025 χ2χ0
 2
2 7 3 1027 χ2χ0
 3
1 9 3 10210 χ2χ0
 3
" #
1 X
dihedrals
1
2
½  Vτ1ð Þ 1 1 cosτ 1 Vτ2ð Þ 1 2 cos2τ 1 Vτ3ð Þ 1 1 cos3τ
1 X
bonds=angles
Klθ
2
l1 2 l1;0
  1 l2 2 l2;0
    ð Þ θ 2 θ0
1 X
bonds=torsion
Klχ
2 ð Þ l 2 l0 ð Þ 1 1 cos3χ
1 X
angles=angles
Kθ1θ2
2
θ1 2 θ1;0
  θ2 2 θ2;0
 
1X
i , j
εij
22:25
 σij
rij 6
1 1:84 3 105
exp

212σij
rij 	
1X
i , j
μi
μj
εr3
ij
2cosθi cosθj 2 sinθi sinθj cos φi 2 φj
   
ð3:91Þ
In the MM3 force field, the accuracy of the bond-stretching term (the first term)
is improved by incorporating more terms of the Taylor series expansion. The bond￾stretching term is a better approximation of the Morse potential than the simple
Hooke’s law potential used in both the AMBER and CHARMM force fields.
Similarly, the accuracy of the bond-angle bending (second term) and out-of-plane
bending (third term) is improved by using a higher-order expansion. Three different
periodicities are used to represent the effects of torsional motion (fourth term).
A feature of the MM3 force filed is the inclusion of cross-terms arising
from bond stretching/bending (fifth term), bond stretching/torsional motion
(sixth term), and bending/bending (seventh term) motions. The nonbonded
contributions to dispersion and repulsion are modeled by an empirically modi￾fied Buckingham potential (eighth term). In contrast to either the AMBER or
CHARMM force fields, the MM3 force field does not use Coulomb’s law to
determine the electrostatic interactions (ninth term). Instead, each bond in the
molecule is assigned a bond dipole moment (μ) and the total electrostatic
interaction is the sum of all possible dipoledipole interactions. The dihedral
angle made by the bond dipoles is represented by χ and θ, which are the
angles made by each of the bond dipoles with the r vector.
92 Molecular Simulation of FluidsIn many cases, the MM3 force field can be used to calculate heats of forma￾tion, conformational energies, and rotational barriers to an accuracy that is close
to experimental uncertainty (Allinger et al., 1989). Vibrational frequencies and
thermodynamic properties are also calculated accurately using the MM3 force
field (Lii and Allinger, 1989a,b). Improvements on the MM3 potential include
parameters obtained from ab initio data (Shannon et al., 2019).
A common feature of many realistic force fields is that of atom type. The atom
type is defined by factors such as atomic number, hybridization, and details of the
local environment. For example, to apply a force field to a molecule containing car￾bon atoms, a distinction must be made between sp3
, sp2
, and sp hybridized carbons,
which generate tetrahedral, trigonal, and linear geometries, respectively. This dis￾tinction is important because the geometry of the atom type affects the values of
the potential parameters. The local environment also affects the force field para￾meters. The MM3 force field distinguishes between carbonyl, cyclopropane, cyclo￾propene, radical, and carbonium ion carbon atoms. The AMBER approach assigns
a different atom type to carbon atoms at the junction between a six- and five￾member ring compared with carbon atoms in an isolated five-member ring.
3.10.1.6 UFF
Complicated rules for assigning atom types means that it is often difficult to
obtain parameters for different categories of molecules. Rappe´ et al. (1992)
attempted to address this limitation by proposing a universal force field (UFF)
using parameters estimated from general rules based only on the element, its
hybridization, and its connectivity. The functional form of the UFF is
E 5 X
bonds
D0½  expð2αðl2l0Þ 2
1 X
angles
Kθ
2cos2θ0 1 1
4sin2
θ0
2 4cosθ0 cosθ0
4sin2
θ0
1
cos2θ
4sin2
θ0
0
@
1
A
1 X
χ 2 angles
Kχð Þ C0 1 C1cosχ 1 C2cos2χ
1 X
dihedrals
X
n
Vn
2 ½  1 2 cosnτ0cosnτ
1X
j . i
εij
rij

r
0
@
1
A
12
2 2 rij

r
0
@
1
A
2 6
4
3
5
1X
j . i
322:0637 qiqj
εrij
;
ð3:92Þ
where the different terms represent bond stretching, angle bending, out-of￾plane bending, torsional motion, nonbonded interaction, and electrostatic
interactions, respectively. The angle-bending term is a general term valid for
all linear and nonlinear geometries. The torsional term includes an improved
description of torsional periodicities and minima. Parameters for the UFF
Intermolecular pair potentials and force fields Chapter | 3 93have been evaluated for elements (Rappe´ et al., 1992), organic molecules
(Casewit et al., 1992a), and main group compounds (Casewit et al., 1992b).
In common with other force fields, it requires knowledge of the charge distri￾bution of the interaction sites of the molecule (Rappe´ and Goddard, 1991).
3.10.1.7 CFF93
Instead of using experimental data directly, an intermolecular potential can
be obtained by applying the principles of quantum mechanics. The advantage
of using quantum mechanics is that there are an unlimited number of observ￾able quantities, which can be fitted to the potential. The parameters can also
be derived for any functional group that can be calculated using quantum
mechanics. For example, a force field has been developed (Maple et al.,
1994) that reproduces the HartreeFock energy surface for alkane mole￾cules. The relative energies and the first and second Cartesian energy deriva￾tives obtained from quantum mechanics for alkanes were fitted to an
intermolecular potential. Hwang et al. (1994) extended the approach to
include alkyl functional groups. The CFF93 is given by Eq. (3.93).
U 5X
b
K2bðb2b0Þ
2 1 K3bðb2b0Þ
3 1 K4bðb2b0Þ
4  
1X
θ
K2θðθ2θ0Þ
2 1 K3θðθ2θ0Þ
3 1 K4θðθ2θ0Þ
4  
1X
τ
½  K1τ ð1 2 cosτÞ 1 K2τ ð1 2 cos2τÞ 1 K3τ ð1 2 cos3τÞ
1X
χ
Kχχ2
1X
b
X
b0
Kbb0ðb 2 b0Þðb0
2 b0
0
Þ
1X
θ
X
θ0
Kθθ0ðθ 2 θ0Þðθ0
2 θ0
0
Þ
1X
b
X
θ
Kbθðb 2 b0Þðθ 2 θ0Þ
1X
τ
X
b
ðb 2 b0Þ½  K1τbcosτ 1 K2τbcos2τ 1 K3τbcos3τ
1X
τ
X
b0
ðb0
2 b0
0Þ K1τb0cosτ 1 K2τb0cos2τ 1 K3τb ½  0cos3τ
1X
τ
X
θ
ðθ 2 θ0Þ½  K1τθcosτ 1 K2τθcos2τ 1 K3τθcos3τ
1X
τ
X
θ
X
θ0
Kτθθ0ðθ 2 θ0Þðθ0
2 θ0
0Þcosτ
1X
i . j
ε 2 r
rij
0
@
1
A
9
2 3 r
rij
0
@
1
A
2 6
4
3
5
1X
i . j
qiqj
rij
ð3:93Þ
94 Molecular Simulation of FluidsThe first three terms in Eq. (3.93) represent the contributions from bond
stretching, bond bending, torsional motion, and out-of-plane bending, respec￾tively. Similar terms have been incorporated in the other force fields dis￾cussed previously. However, unlike other models, the CFF93 emphasizes the
importance of cross interactions. The fourth, fifth, and sixth terms represent
the coupling of different bond stretches, different bending motions, and
stretching and bending, respectively. The coupling of different bond stretch￾ing with torsional motion is represented by the seventh and eighth terms.
The ninth term couples bond bending with torsional motion. The tenth term
represents the effect of coupling different bond bending and torsional
motions. The remaining terms are the LJ and Coulombic potentials of the
nonbonded atoms, respectively. All twelve terms are necessary for the quan￾titative representation of the quantum mechanical data and many of the terms
make an equal contribution to the energy.
3.10.2 Comparison of force fields and future improvements
The already discussed force fields introduce an increasing degree of sophisti￾cation to the description of the physics of molecules. How do the results
obtained for the various force fields compare? The answer to this question is
complicated by the fact that the parameters for the various potentials cannot
be extended to all molecules. The large number of possible permutations
within a force field software package is also a daunting impediment for com￾parative purposes. This makes a definitive comparison between forces fields
an impossible task. Inevitably, the usefulness of a particular force field will
depend on the properties for which it is applied to. Comparisons of several
different types of force fields are available (Roterman et al., 1989 & b;
Hwang et al., 1994; Landis et al., 1995; MacKerell, 2004; Hornak et al.,
2006; Becker et al., 2013; Vanommeslaeghe and MacKerell, 2015; Sun and
Deng, 2017; Rinker, 2018; Bedrov et al., 2019). There is no force field that
is consistently superior for all applications.
Landis et al. (1995) reported a comparison of the parameters required for
CHARMM and MM3 force fields. Their analysis indicated that there was a
considerable difference in the parameter values required by the different
potentials. Rappe´ et al. (1992) compared the results obtained for UFF
and the MM3 force field for some organic molecules. The comparison indi￾cated that MM3 force field is less prone to error than the UFF. On the other
hand, the UFF can be applied to a large variety of different combinations of
atoms, whereas the large number of parameters required restricts the variety
of molecules supported by force fields such as MM3.
Roterman et al. (1989a,b) compared the AMBER, CHARMM, and
ECEPP force fields for peptides. These force fields gave significantly differ￾ent results for the minimum energy configurations. Hwang et al. (1994) com￾pared the structures predicted by the AMBER, MM3, and CFF93 force fields
Intermolecular pair potentials and force fields Chapter | 3 95with experimental data. The bond angles for many classes of molecules were
calculated more accurately with the CFF93 than the AMBER model. The
MM3 and AMBER methods can be used to calculate both rotational barriers
and conformational energy differences with a reasonable degree of accuracy.
However, the CFF93 model provides the most accurate predictions. Asensio
et al. (1995) have concluded that the AMBER, CVFF, and CFF91 force
fields predict the observed conformation of methyl α-lactoside with a similar
degree of accuracy.
A common feature of the AMBER, CHARMM, ECEPP and MM3,
OPLS, and UFF models is the assumption that the charge distribution associ￾ated with each atom is independent of the conformation of the molecule.
These models are isotropic and no account is taken of the rearrangement of
valance electron found in molecular bonds. Consequently, sitesite interac￾tions are often not transferable to other molecules within the same group.
Anisotropic sitesite potentials (Price, 1988; Price and Stone, 1992) have
been reported, which overcome this deficiency. The results obtained from
anisotropic models are generally better than that can be obtained for isotropic
models, particularly if hydrogen bonding is involved.
An alternative to generalized force fields is to develop force fields for
either a specific class of molecules or a particular application. An AA force
field for liquid ethanol has been devised (Mu¨ller-Plathe, 1996) and used in
MD simulations. Nath et al. (1998a) reported successful simulations of the
VLE of alkanes modeled via a potential dubbed “NERD.” The NERD poten￾tial combines nonbonded interaction with elements of intramolecular interac￾tion in the spirit of molecular mechanics. The potential yields satisfactory
agreement with experiment without using adjustable parameters (Nath et al.,
1998b). The transferable potentials for phase equilibria (TraPPE) was specif￾ically developed (Martin and Siepmann, 1998) for phase behavior. It has
undergone continual development (Shah et al., 2017) for phase behavior,
providing a very good representation of VLE (Eggimann et al., 2020).
Historically, force fields have been developed without accounting for the
effect of polarization, but the importance of this contribution is being
increasingly recognized (Vanommeslaeghe and MacKerell, 2015; Bedrov
et al., 2019) and incorporated into existing force fields. The statistical
mechanics (Gray and Gubbins, 1984) of polarization is well understood, but
it poses several computational challenges (Li et al., 2008) resulting in the
use of various approximations. Apart from the effectiveness of these approxi￾mations, they are often applied to force fields with known theoretical short￾comings such as the widespread use of the LJ potential for nonbonded
interactions. In principle, accounting for polarization should have an impor￾tant influence on the properties of real fluids
Increasingly ab initio data are being used to inform the development (Sun
and Deng, 2017) of force fields. The use of ab initio data to determine the
entire force field of even a simple system is challenging (Chapter 4). Instead,
96 Molecular Simulation of Fluidscalculations from first principles are primarily used to determine key aspects,
such as the constants involved in bond stretching and bending.
The determination of force field parameters is both very time consuming
and subject to interrelated influences that inhibit efficient changes. For
example, the parameters of some force fields in biomolecular simulations
have been developed assuming a particular model for water and would need
to be re-evaluated for a new water model. In this context the application of
machine learning (Huang and von Lilienfeld, 2021; Keith et al., 2021) has
the potential of greatly facilitating the selection of parameters for new
situations.
3.11 Case study: Models for water
Water is arguably the most-widely studied molecule. However, despite an
enormous scientific effort spanning several decades (Chialvo and Cummings,
1999; Guillot, 2002; Vega et al., 2009), our understanding of its behavior
remains incomplete. There are at least 85 different models for water, many
of which have been evaluated elsewhere (Shvab and Sadus, 2016). For our
purposes, water provides us useful illustration of the development of models
for molecular simulation.
3.11.1 Rigid models
In principle, water is a simple triatomic nonlinear molecule with a H-O-H
bond angle of 104.5. Although it is well-understood that molecules flex, a
simplifying approximation is to treat the bonds as complexly rigid. These
considerations suggest that the simplest realistic model would involve three
sites, corresponding to the presence of the oxygen and hydrogen atoms
(Fig. 3.11).
The nonlinear geometry gives rise to a dipole moment, which results in a
large dipole moment. The contribution from the dipole moment can be
obtained by situating partial charges of the atoms such that electro-neutrality
FIGURE 3.11 The structure of water, identifying intramolecular terms, constituent atoms, and
an additional site (M) used to evaluate its properties.
Intermolecular pair potentials and force fields Chapter | 3 97is observed. In addition, nonbonded oxygenoxygen, oxygenhydrogen,
and hydrogenoxygen dispersion interactions can be envisaged between dif￾ferent pairs of water molecules. We would expect that the oxygenoxygen
interactions would make the dominant contribution, which could be approxi￾mated via the LJ potential. A simple potential corresponding to these consid￾erations is
ueffð Þr 5 4ε
X
N
i
X
N
j6¼i
σ
roo
ij !12
2 σ
roo
ij !6 8
<
:
9
=
;
1 e2
4πε0
X
N
i
X
N
j6¼i
qiqj
rij
; ð3:94Þ
where roo
ij and rij are the distances between the oxygen sites and charged sites
of two molecules, respectively; e 5 1.602176634 3 10219 C is the charge
(Tiesinga et al., 2021) such that the charges are conveniently represented as
multiples of e. Notice that in Eq. (3.93), there is no contribution from the
bond angle because in a ridged model it is invariant. The triangular configu￾ration is obtained by specifying the relative positions of the oxygen and
hydrogen atoms according to the bond lengths and bond angle.
Eq. (3.94) is the three-site simple point charge (SPC) potential proposed
by Berendsen et al. (1981). The SPC models give a good description of the
dielectric constant but it does not predict adequately phase equilibria, partic￾ularly at high temperatures (de Pablo et al., 1990). One example of the many
reported improvements is to allow the charges to fluctuate (Martin et al.,
1998). The SPC model also does not correctly predict the energy, self￾diffusion constant, and radial distribution function. However, its accuracy
can be improved (Berendsen et al., 1987) by applying a polarization
correction
ΔUpol 5
μl2μg
 2
2α ; ð3:95Þ
where μl is the dipole moment of the molecule, μg is the dipole moment of
the isolated molecule, and the α is the isotropic scalar polarizability of water
molecule. Eq. (3.95) does not change Eq. (3.94), but simply results in new
values of the model’s parameters (Table 3.2). This extended version (SPC/E)
of the SPC model reproduces the vaporization enthalpy and more accurately
predicts features such as the critical behavior, pair correlation, and dielectric
constant reasonably well (Guillot, 2002). Deficiencies in its accuracy include
slightly high self-diffusion coefficients and specific heat capacities (Mao and
Zhang, 2012).
The SPC and SPC/E potentials are three-site models with the partial
charges associated with the position of the oxygen and hydrogen atoms. This
is intuitively the most obvious distribution of charges. By definition, a model
is a theoretical abstraction of reality and as such it does not have to conform
to either our intuition or the actual situation. An improved representation of
98 Molecular Simulation of FluidsTABLE 3.2 Summary of intermolecular bond distance, bond angle, and energy parameters for water models.
Model q1 (e) q2 (e) rOH (A
˚
) rOM (A
˚
) θ () φ () σ (A
˚
) ε (kJ/mol)
SPCa 0.41 2 0.82 1.0 109.47 3.166 0.65
SPC/Eb 0.4238 2 0.8476 1.0 109.47 3.166 0.65
SPC/Fwc 0.417 2 0.834 1.012 113.24 3.1655 0.6507
TIP4Pd 0.52 2 1.04 0.9572 0.15 104.52 52.26 3.154 0.65
TIP4P/2005e 0.5564 2 1.1280 0.9572 0.1546 104.52 52.26 3.1589 0.7749
TIP5Pf 0.241 2 0.241 0.9572 0.70 104.52 109.47 3.12 0.6694
aBerendsen et al., 1981.
bBerendsen et al., 1987.
cWu et al., 2006.
dJorgensen et al., 1983.
eAbascal and Vega, 2005. fMahoney and Jorgensen, 2000.the properties of water can be obtained by introducing other partial charge
sites that are not associated with the constituent atoms. Jorgensen et al.
(1983) introduced a fourth charge site (Fig. 3.11) to generate a transferable
intermolecular potential 4-point (TIP4P) model for water, which was later
re-parametrized (Abascal and Vega, 2005) to yield TIP4P/2005. The TIP4P/
2005 model accurately predicts (Shvab and Sadus, 2016) properties such as
the overall phase diagram, VLE densities, and the surface tension. The addi￾tion of a fifth site (TIP5P) (Mahoney and Jorgensen, 2000) improves the pre￾diction of densities over a wide range of temperatures and more accurately
determines the configurational energy.
A common feature of the various multisite models is that the method for
calculating the energy of interaction remains the same via Eq. (3.93). The
only changes are (a) more sites need to be included and (b) the values of the
potential parameters are different.
3.11.2 Flexible models
A simple improvement to water models can be achieved (Wu et al., 2006) by
allowing the bonds to be flexible. For example, The SPC/Fw model main￾tains the overall three-site SPC geometry, while allowing both the bond
angle and bond distance to change. Therefore, the calculation of the energy
requires the following intramolecular contribution to be added to Eq. (3.93),
uintrað Þr 5
Kb roh12ro
oh  2
1 roh22ro
oh  2 h i
2
1
Kθ θ+HOH2θo
+HOH  2
2 ð3:96Þ
where ro
oh and θo
+HOH are the equilibrium bond length and bond angle in the
gas phase. This simple addition results in significant improvements to the pre￾diction of VLE (Raabe and Sadus, 2007), dielectric behavior (Raabe and
Sadus, 2011) and transport properties (Raabe and Sadus, 2012). A partial
explanation for the improved agreement with experiment is that bond flexibil￾ity mimics the effects of polarization. This is particularly useful as polarization
is computationally expensive (Li et al., 2008; Shvab and Sadus, 2016).
3.11.3 Polarizable models
It is becoming increasingly apparent that progress in predicting the properties
of water requires the explicit inclusion of polarization (Chapter 4). A review
of polarizable models is given elsewhere (Shvab and Sadus, 2016). An atomic
multipole optimized energetics for biomolecular applications (AMOEBA)
model has been proposed (Ren and Ponder, 2003). Evaluating polarization is
computationally expensive and a simplified version (iAOMEBA, where “i”
denotes inexpensive) has also been developed (Wang et al., 2013). Although
initially developed for biomolecular applications, AMOEBA yields results for
100 Molecular Simulation of Fluidsthermodynamic properties (Shvab and Sadus, 2016) that are of superior accu￾racy to those obtained for rigid models. A systematic approach to improving
water models is further examined in Chapter 4.
3.12 Application to mixtures
The proceeding intermolecular potentials and force fields have been developed
exclusively for the properties of pure components. However, it is rare in nature
for substances to be isolated in their pure state and the calculation of the proper￾ties of real materials requires us to account for the properties of the mixtures.
Unlike conventional calculations (Wei and Sadus, 2000), which inevitably
require invoking a theory of mixtures, molecular simulations can be easily
extended from pure systems to mixtures by the addition of different molecular
species. However, a way is required to account for interactions between the con￾tributions of interactions between dissimilar molecules. This is almost invariably
achieved via combining rules for the various intermolecular parameters. Most
commonly, the LorentzBerthelot rules (Wei and Sadus, 2000) are used.
σij 5 σi 1 σj
2 ð3:97Þ
εij 5 ffiffiffiffiffiffiffi
εiεj
p ð3:98Þ
Eq. (3.97) is exact only for the case of HS, and most real molecules do
not behave as HS as is apparent from the realistic potentials discussed
previously. It has also been known for a long time (Guggenheim, 1952)
that Eq. (3.98) has no theoretical basis. Eqs. (3.97) and (3.98) do not
accurately represent (Delhommelle and Millie´, 2001) the properties of the
relatively simple case of the noble gases, let alone molecules of greater
complexity and interest such as proteins and macromolecules. Many alter￾native combining rules have been proposed (Wei and Sadus, 2000;
Hasalm et al., 2008); however, none are sufficiently accurate to avoid the
use of adjustable parameters to fully optimize agreement between theory
and experiment. This means that the predictive usefulness of molecular
simulation is restricted to relatively few mixtures.
An alternative to averaging the potential parameters is to average the con￾tributions of the intermolecular potentials (Stiegler and Sadus, 2015):
uij 5 uα 1 uβ
2 ; ð3:99Þ
where the two distinct intermolecular potentials are denoted by uα and uβ.
Using Eq. (3.99), the force (fij) between the two particles is obtained from
fij 5 2 rij
2rij
duα
drij
1
duβ
drij 
 : ð3:100Þ
Intermolecular pair potentials and force fields Chapter | 3 101For a binary mixture of molecules interacting via the LJ and 105 LJ/M
potential, Eq. (3.99) yields:
uð Þ α 6¼ β 5 2εij
σij
rij 
 12
1 σij
rij 
 10
2 σij
rij 
 6
2 σij
rij 
 5 " # ð3:101Þ
Comparison of simulations (Stiegler and Sadus, 2015) using Eq. (3.101)
with results obtained by combining the LJ/M potentials by averaging the expo￾nents indicates good agreement for a range of thermodynamic properties. The
main advantage of Eq. (3.99) is that different intermolecular potentials can be
used for the individual mixture components. In contrast, the traditional combin￾ing rule approach is limited to mixtures with both common potentials and com￾mon intermolecular parameters.
3.13 Summary
Ultimately the development of intermolecular potentials and force fields
should be guided by theory. Although progress is being achieved toward this
goal via, for example, the application of ab initio data, most potentials are
empirically based and should be regarded as effective pair potentials.
Nonetheless, a wide variety of potentials are available, many of which have
not been evaluated fully. The force fields are particularly useful for the prop￾erties of macromolecules and biological systems, capturing many details of
the underlying physics of both inter- and intramolecular interactions. An
ongoing challenge is that potentials are developed for pure systems and the
predictive capability of the simulation of mixtures is restricted by the need
to use combining rules to determine the interactions between dissimilar
molecules. This is likely to benefit from future developments in the applica￾tion of machine learning.
References
Abascal, J.L.F., Vega, C., 2005. A general purpose model for the condensed phases of water:
TIP4P/2005. J. Chem. Phys. 124, 024503.
Abramowitz, M., Stegun, I.A. (Eds.), 1972. Handbook of Mathematical Functions with Formula,
Graphs and Mathematical Tables. Dover, New York, p. 255.
Ahlrichs, R., Penco, P., Scoles, G., 1977. Intermolecular forces in simple systems. Chem. Phys.
19, 119130.
Ahmed, A., Sadus, R.J., 2009a. Phase diagram of the Weeks-Chandler-Andersen potential from
very low to high temperatures and pressures. Phys. Rev. E 80, 061101. Erratum: Phys. Rev.
E 99, 029901 (2019).
Ahmed, A., Sadus, R.J., 2009b. Solid-liquid equilibria and triple points of n-6 Lennard-Jones
fluids. J. Chem. Phys. 131, 174504. Erratum: J. Chem. Phys. 133, 229902 (2010).
Ahmed, A., Sadus, R.J., 2010. Effect of potential truncations and shifts on the solid-liquid phase
coexistence of Lennard-Jones fluids. J. Chem. Phys. 133, 124515.
102 Molecular Simulation of FluidsAhmed, A., Mausbach, P., Sadus, R.J., 2009. Strain-rate dependent shear viscosity of the
Gaussian core model fluid. J. Chem. Phys. 131, 224511.
Ahmed, A., Mausbach, P., Sadus, R.J., 2010. Pressure and energy behavior of the Gaussian core
model fluid under shear. Phys. Rev. E 82, 011201.
Alder, B.J., Wainwright, T.E., 1957. Phase transition for a hard sphere system. J. Chem. Phys.
27, 12081209.
Alder, B.J., Gass, D.M., Wainwright, T.E., 1970. Studies in molecular dynamics. VIII. The trans￾port coefficients for a hard-sphere fluid. J. Chem. Phys. 53, 38133826.
Allen, M.P., Tildesley, D.J., 2017. Computer Simulation of Liquids, second ed. Oxford
University Press, Oxford.
Allinger, N.L., 1977. Conformational analysis. 130. MM2. A hydrocarbon force field utilizing
V1 and V2 torsional terms. J. Am. Chem. Soc. 99, 81278134.
Allinger, N.L., Yuh, Y.H., Lii, J.-H., 1989. Molecular mechanics. The MM3 force field for
hydrocarbons. J. Am. Chem. Soc. 111, 85518575.
Asensio, J.L., Martin-Pastor, M., Jimenez-Barbero, J., 1995. The use of CVFF and CFF91 force
fields in conformational analysis of carbohydrate molecules. Comparison with AMBER
molecular mechanics and dynamics calculations for methyl α-lactoside. Int. J. Macromol.
17, 137148.
Axilrod, B.M., Teller, E., 1943. Interaction of the van der Waals’ type between three atoms.
J. Chem. Phys. 11, 299300.
Bacher, A.K., Schrøder, T.B., Dyre, J.C., 2018a. The EXP pair-potential system. I. Fluid phase
isotherms, isochores, and quasinuniversality. J. Chem. Phys. 149, 114501.
Bacher, A.K., Schrøder, T.B., Dyre, J.C., 2018b. The EXP pair-potential system. II. Fluid phase
isomorphs. J. Chem. Phys. 149, 114502.
Barcenas, M., Odriozola, G., Orea, P., 2014. Coexistence and interfacial properties of triangular- ´
well fluids. Mol. Phys. 112, 21142121.
Bartke, J., Hentschke, R., 2007. Phase behavior of the Stockmayer fluid via molecular dynamics
simulation. Phys. Rev. E 75, 061503.
Bastea, S., Fried, L.E., 2008. Exp6-polar thermodynamics of dense supercritical water. J. Chem.
Phys. 128, 174502.
Baxter, R.J., 1968. Percus-Yevick equation for hard spheres with surface adhesion. J. Chem.
Phys. 49, 27702774.
Becker, C.A., Tavazza, F., Trautt, Z.T., de Macedo, R.A.B., 2013. Considerations for choosing
and using force fields and interatomic potentials in material science and engineering. Curr.
Opin. Sol. State. Mat. Sci. 17, 277283.
Bedrov, D., Piquemal, J.-P., Borodin, O., MacKerell Jr, A.D., Roux, B., Schro¨der, C., 2019.
Molecular dynamics simulations of ionic liquids and electrolytes using polarizable force
fields. Chem. Rev. 119, 79407995.
Behler, J., 2016. Perspective: Machine learning potentials for atomistic simulations. J. Chem.
Phys. 145, 170901.
Bell, R.J., Zucker, I.J., 1976. In: Klein, M.L., Venables, J.A. (Eds.), Rare Gas Solids, Vol. 1.
Academic Press, London.
Berendsen, H.J.C., Postma, J.P.M., von Gunsteren, W.F., Hermans, J., 1981. In: Pullman, B.
(Ed.), Intermolecular Forces. Reidel, Dordrecht.
Berendsen, H.J.C., Grigera, J.R., Straatsma, T.P., 1987. The missing term in effective pair poten￾tials. J. Phys. Chem. 91, 62696271.
Best, R.B., Hummer, G., 2009. Optimized molecular dynamics force fields applied to the helix￾coil transition of polypeptides. J. Phys. Chem. B 113, 90049015.
Intermolecular pair potentials and force fields Chapter | 3 103Best, R.B., Zhu, X., Shim, J., Lopes, P.E.M., Mittal, J., Feig, M., MacKerell Jr, A.D., 2012. Optimization
of the additive CHARMM all-atom protein force field targeting improved sampling of the backbone
φ, ψ and side-chain χ1 χ2 dihedral angles. J. Chem. Theory Comput. 8, 32573273.
Bobetic, M.V., Barker, J.A., 1970. Lattice dynamics with three-body forces: argon. Phys. Rev.
B. 2, 41694175.
Born, M., Mayer, J.E., 1932. Zur Gittertheorie der Ionenkristalle. Z. Phys. 75, 118.
Bosko, J.T., Todd, B.D., Sadus, R.J., 2004. Internal structure of dendrimers in the melt: A
molecular dynamics study. J. Chem. Phys. 121, 10911096.
Bosko, J.T., Todd, B.D., Sadus, R.J., 2006. Analysis of the shape of dendrimers under shear.
J. Chem. Phys. 124, 044910.
Boubl´ık, T., Nezbeda, I., 1986. P-V-T behaviour of hard body fluids. Theory and experiment.
Coll. Czech. Chem. Commun. 51, 23012432.
Boyes, S.J., 1994. The interatomic potential of argon. Chem. Phys. Lett. 221, 467472.
Brooks, B.R., Bruccoleri, R.E., Olafson, B.D., States, D.J., Swaminathan, S., Karplus, M., 1983.
CHARMM: A program for macromolecular energy, minimization, and dynamics calcula￾tions. J. Comput. Chem. 4, 187217.
Buckingham, R.A., Corner, J., 1947. Tables of second virial and low-pressure Joule-Thompson
coefficients for intermolecular potentials with exponential repulsion. Proc. Roy. Soc. A 189,
118129.
Buckingham, A.D., Fowler, P.W., Hutson, 1988. Theoretical studies of van der Waals molecules
and intermolecular forces. Chem. Rev. 88, 963988.
Caillol, J.M., 1995. A Monte Carlo study of the dielectric constant of the restricted primitive
model of electrolytes on the vapor branch of the coexistence line. J. Chem. Phys. 102,
54715478.
Car, R., Parrinello, M., 1985. Unified approach for molecular dynamics and density-functional
theory. Phys. Rev. Lett. 55, 24712474.
Casewit, C.J., Colwell, K.S., Rappe´, A.K., 1992a. Application of a universal force field to
organic molecules. J. Am. Chem. Soc. 114, 1003510046.
Casewit, C.J., Colwell, K.S., Rappe´, A.K., 1992b. Application of a universal force field to main
group compounds. J. Am. Chem. Soc. 114, 1004610053.
Chandler, D., Weeks, J.D., Andersen, H.C., 1983. Van der Waals picture of liquids, solids, and
phase transformations. Science 220, 787794.
Chang, J., Sandler, S.I., 1995. The Wertheim integral equation theory with the ideal chain
approximation and a dimer equation of state: generalization to mixtures of hard-sphere chain
fluids. J. Chem. Phys. 103, 31963211.
Cheung, P.S.Y., Powles, J.G., 1975. The properties of liquid nitrogen IV. A computer simulation.
Mol. Phys. 30, 921949.
Chialvo, A.A., Cummings, P.T., 1999. Molecular-based modeling of water and aqueous solutions
at supercritical conditions. Adv. Chem. Phys. 109, 207433.
Cisneros, G.A., Karttunen, M., Ren, P., Sagui, C., 2013. Classical electrostatics for biomolecular
simulations. Chem. Rev. 114, 779814.
Damm, W., Frontera, A., Tirado-Rives, J., Jorgensen, W.L., 1997. OPLS All-atom force field for
carbohydrates. J. Comp. Chem. 18, 19551970.
de Carvalho, R.J.F.L., Evans, R., 1997. The screened Coulomb (Yukawa) charged hard sphere
binary fluid. Mol. Phys. 92, 211228.
de Kuijper, A., Smit, B., Schouten, J.A., Michels, J.P.J., 1990. Fluid-fluid phase separation in a
repulsive α-exp-6 mixture: a comparison with the full α-exp-6 mixture by means of com￾puter simulations. Europhys. Lett. 13, 679682.
104 Molecular Simulation of Fluidsde Leeuw, S.W., Smit, B., Williams, C.P., 1990. Molecular dynamics studies of polar/nonpolar
fluid mixtures. I. Mixtures of Lennard-Jones and Stockmayer fluids. J. Chem. Phys. 93,
27042714.
de Pablo, J.J., Prausnitz, J.M., Strauch, H.J., Cummings, P.T., 1990. Molecular simulation of
water along the liquid-vapor coexistence curve from 25C to the critical point. J. Chem.
Phys. 93, 73557359.
Deiters, U.K., Sadus, R.J., 2019a. Two-body interatomic potentials for He, Ne, Ar, Kr, and Xe
from ab initio data. J. Chem. Phys. 150, 134504.
Deiters, U.K., Sadus, R.J., 2019b. Fully a priori prediction of the vapor-liquid equilibria of Ar,
Kr, and Xe from ab initio two-body plus three-body interatomic potentials. J. Chem. Phys.
151, 034509.
Deiters, U.K., Sadus, R.J., 2020. Ab initio interatomic potentials and the classical molecular simula￾tion prediction of the thermophysical properties of helium. J. Phys. Chem. B 124, 22682276.
Deiters, U.K., Sadus, R. J., (2023), to be submitted.
Deiters, U.K., Sadus, R.J., 2021. Interatomic interactions responsible for the solid-liquid and
vapor-liquid phase equilibria of neon. J. Phys. Chem. B 125, 85228531.
DeKock, R.L., Madura, J.D., Rioux, F., Casanova, J., 1993. In: Lipkowitz, K.B., Boyd, D.B.
(Eds.), Reviews in Computational Chemistry, Vol. 4. VCH Publishers, New York.
Delhommelle, J., Millie´, P., 2001. Inadequacy of the Lorentz-Berthelot combining rules for accurate
predictions of equilibrium properties by molecular simulation. Mol. Phys. 99, 619625.
Dham, A.K., Allnatt, A.R., Meath, W.J., Aziz, R.A., 1989. The Kr-Kr potential energy curve
and related physical properties: the XC and HFD-B potential models. Mol. Phys. 67,
12911307.
Dinur, U., Hagler, A.T., 1991. In: Lipkowitz, K.B., Boyd, B. (Eds.), Reviews in Computational
Chemistry, Vol. 2. VCH Publishers, New York.
Douketis, C., Scoles, G., Marchetti, S., Zen, M., Thakkar, A.J., 1982. Intermolecular forces via
hybrid Hartree-Fock-SCF plus damped dispersion (HFD) energy calculations: an improved
spherical model. J. Chem. Phys. 76, 30573063.
Dubey, G.S., O’Shea, S.F., 1994. Phase equilibria of Lennard-Jones plus quadrupolar fluids by
Gibbs-ensemble Monte Carlo simulation. Phys. Rev. E 49, 21752183.
Duh, D.-M., Mier-Y-Teran, L., 1997. An analytical equation of state for the hard-core Yukawa ´
fluid. Mol. Phys. 90, 373379.
Dyre, J.C., Pedersen, U.R., 2023. Comparing zero-parameter theories for the WCA and har￾monic-repulsive melting lines. J. Chem. Phys. 158, 154504.
Egelstaff, P.A., 1987. In: Price, D.L., Sko¨ld (Eds.), Methods of Experimental Physics: Neutron
Scattering. Academic Press, San Diego.
Egelstaff, P.A., 1994. An Introduction to the Liquid State, second ed. Clarendon Press, Oxford.
Eggimann, B.L., Sun, Y., DeJaco, R.F., Singh, R., Ahsan, M., Josephson, T.R., Siepmann, J.I.,
2020. Assessing the quality of molecular simulations for vapor-liquid equilibra: an analysis
of the TraPPE database. J. Chem. Eng. Data 65, 13301344.
Elliott, J.R., Hu, L., 1999. Vapor-Liquid equilibria of square-well spheres. J. Chem. Phys. 110,
30433048.
Escobedo, F.A., de Pablo, J.J., 1996. Simulation and prediction of vapour-liquid equilibria for
chain molecules. Mol. Phys. 87, 347366.
Fantoni, R., Malijevsky, A., Santos, A., Giacometti, A., 2011. Phase diagram of the penetrable￾square-well model. Eur. Phys. Lett. 93, 26002.
Feinberg, M.J., de Rocco, A.G., 1964. Intermolecular forces: the triangle well and some compar￾isons with the square well and Lennard-Jones. J. Chem. Phys. 41, 34393540.
Intermolecular pair potentials and force fields Chapter | 3 105Fischer, J., Wendland, M., 2023. On the history of key empirical intermolecular potentials. Fluid
Phase Equilib. 573, 113876.
Foloppe, N., MacKerell Jr, A.D., 2000. All-atom empirical force field for nucleic acids: I.
Parameter optimization based on small molecule and condensed phase macromolecular tar￾get data. J. Comp. Chem. 21, 86104.
Fowler, R., Guggenheim, E.A., 1939. Statistical Thermodynamics: A version of Statistical
Mechanics for Students of Physics and Chemistry. Cambridge University Press, Cambridge,
p. 280.
Fowler, R.H., Graben, H.W., de Rocco, A.G., Feinberg, M.J., 1965. Some additional results for
the triange-well potential model. J. Chem. Phys. 43, 10831084.
Fumi, F.G., Tosi, M.P., 1964. Ionic sizes and Born repulsive parameters in the NaCl-type
alkali halides. I. The Huggins-Mayer and Pauling forms. J. Phys. Chem. Solids 25,
3143.
Galicia-Pimental, U.F., Lo´pez-Lemus, J., Orea, P., 2008. Liquid-vapor interfacial properties of
attractive Yukawa fluids. Fluid Phase Equilib. 265, 205208.
Galliero, G., Boned, C., 2008. Molecular dynamics study of the repulsive form influence of the
interaction potential on structural, thermodynamic, interfacial, and transport properties.
J. Chem. Phys. 129, 074506.
Gao, J., Weiner, J.H., 1989. Contribution of covalent bond force to pressure in polymer melts.
J. Chem. Phys. 91, 31683173.
Gao, G.T., Woller, J.B., Zeng, X.C., Wang, W., 1997. Vapour-liquid equilibria of binary mix￾tures containing Stockmayer molecules. J. Phys.: Condens. Matter 9, 33493360.
Gao, H., Wang, J., Sun, J., 2019. Improve the performance of machine-learning potentials by
optimizing descriptors. J. Chem. Phys. 150, 244110.
Gloor, G.J., Jackson, G., Blas, F.J., del Rio, F.J., de Miguel, E., 2004. An accurate density func￾tional theory for the vapor-liquid interface of associating chain molecules based on the sta￾tistical associating fluid theory for potentials of variable range. J. Chem. Phys. 121,
1274012759.
Goodford, P.J., 1985. A computational procedure for determining energetically favorable binding
sites on biologically important macromolecules. J. Med. Chem. 28, 849857.
Gordon, P.A., 2006. Development of intermolecular potentials for predicting transport properties
of hydrocarbons. J. Chem. Phys. 125, 014504.
Gray, C.G., Gubbins, K.E., 1984. Theory of Molecular Fluids, Vol. 1: Fundamentals. Clarendon
Press, Oxford.
Grest, G.S., Kremer, K., 1986. Molecular dynamics simulation for polymers in the presence of a
heat bath. Phys. Rev. A 33, 36283631.
Guggenheim, E.A., 1952. Mixtures: the theory of the Equilibrium Properties of some Simple
Classes of Mixtures, Solutions and Alloys. Clarendon Press, Oxford, p. 158.
Guillot, B., 2002. A reappraisal of what we have learnt during three decades of computer simula￾tions of water. J. Mol. Liq. 101, 219260.
Guissani, Y., Guillot, B., 1994. Coexisting phases and criticality in NaCl by computer simula￾tion. J. Chem. Phys. 101, 490509.
Guvench, O., Mallajosyula, S.S., Raman, E.P., Hatcher, Vanommeslaeghe, K., Foster, T.J.,
Jamison II, F.W., MacKerell Jr, A.D., 2011. CHARMM additive all-atom force field for car￾bohydrate derivatives and its utility in polysaccharide and carbohydrate protein modelling.
J. Chem. Theory Comput. 7, 31623180.
Haile, J.M., 1992. Molecular Dynamics Simulation. Elementary Methods. John Wiley & Sons,
New York.
106 Molecular Simulation of FluidsHamad, E., 1995. Thermodynamic properties of molecules interacting with inverse power poten￾tials. Z. Phys. Chem. 190, 183191.
Hansen, J.P., McDonald, I.R., 1975. Statistical mechanics of dense ionized matter. IV. Density
and charge fluctuations in a simple molten salt. Phys. Rev. A 11, 21112123.
Hansen, J.P., Schiff, D., 1973. Influence of interatomic repulsion on the structure of liquids at
melting. Mol. Phys. 25, 12811290.
Hasalm, A.J., Galindo, A., Jackson, G., 2008. Prediction of binary intermolecular potential para￾meters for use in modeling fluid mixtures. Fluid Phase Equilib. 266, 105128.
Hentschke, R., Bartke, J., Pesth, F., 2007. Equilibrium polymerization and gas-liquid critical
behavior in the Stockmayer fluid. Phys. Rev. E 75, 011506.
Hepburn, J., Scoles, G., Penco, R., 1975. A simple but reliable method for prediction of intermo￾lecular potentials. Chem. Phys. Lett. 36, 451456.
Heyes, D.M., Powles, J.G., 1998. Thermodynamic, mechanical and transport properties of fluids
with steeply repulsive potentials. Mol. Phys. 95, 259267.
Heyes, D.M., Rickaysen, G., Branka, 2004. Static properties and time correlation functions of
fluids with steeply repulsive potentials. Mol. Phys. 102, 20572070.
Hirschfelder, J.O., Curtiss, C.F., Bird, R.B., 1954. Molecular Theory of Gases and Liquids. John
Wiley & Sons, New York.
Homer, J., Jenkins, J.D., Porter, K.E., Kakhu, A.I., 1991. Prediction of vapour-liquid equilibrium
data for binary mixtures from molecular parameters using a generalized London potential. J.
Chem. Soc. Faraday Trans. 87, 5762.
Hoover, W.G., 2006. Smooth Particle Applied Mechanics: The State of the Art. World
Scientific, Singapore.
Hoover, W.G., Ross, M., Johnson, K.W., Henderson, D., Barker, J.A., Brown, B.C., 1970. Soft￾sphere equation of state. J. Chem. Phys. 52, 49314941.
Hoover, W.G., Gray, S.G., Johnson, K.W., 1971. Thermodynamic properties of the fluid and
solid phases for inverse power potentials. J. Chem. Phys. 55, 11281136.
Hoover, W.G., Young, D.A., Grover, R., 1972. Statistical mechanics of phase diagrams. I.
Inverse power potentials and the close-packed to body-centered cubic transition. J. Chem.
Phys. 56, 22072210.
Hornak, V., Abel, R., Okur, A., Strockbine, B., Roitberg, A., Simmerling, C., 2006. Comparison
of multiple Amber force fields and development of improved backbone parameters.
Proteins: Struct. Func. BioInfo. 65, 712725.
Huang, B., von Lilienfeld, A., 2021. Ab initio machine learning in chemical compound space.
Chem. Rev. 121, 1000110036.
Hwang, M.J., Stockfisch, T.P., Hagler, A.T., 1994. Derivation of class II force fields. 2.
Derivation and characterization of a class II force field, CFF93, for the alkyl functional
group and alkane molecules. J. Am. Chem. Soc. 116, 25152525.
Jia, R., Hentschke, R., 2011. Simulation study of the polarizable Stockmayer fluid in an external
field. Phys. Rev. E. 84, 051508.
Jiang, S., Pitzer, K.S., 1995. Thermodynamic properties of mixtures of dipolar and quadrupolar
hard spheres: theory and simulation. J. Chem. Phys. 102, 76327640.
Johnson, J.K., Gubbins, K.E., 1992. Phase equilibria for associating Lennard-Jones fluids from
theory and simulation. Mol. Phys. 77, 10331053.
Johnson, J.K., Mu¨ller, E.A., Gubbins, K.E., 1994. Equation of state for Lennard-Jones chains.
J. Phys. Chem. 98, 64136419.
Jones, J.E., 1924. On the determination of molecular fileds. II. From the equation of state of a
gas. Proc. R. Soc. London, Ser. A 106, 463477.
Intermolecular pair potentials and force fields Chapter | 3 107Jorgensen, W.L., Tirado-Rives, J., 1988. The OPLS potential functions for proteins. Energy minimi￾zations for crystals of cyclic peptides and crambin. J. Am. Chem. Soc. 110, 16571666.
Jorgensen, W.L., Chandrachekar, J., Madura, J.D., Impey, R.W., Klein, M.L., 1983. Comparison
of simple potential functions for simulating liquid water. J. Chem. Phys. 79, 926935.
Joung, I.S., Cheatham III, T.E., 2008. Determination of alkali and halide monovalent ion parameters
for use in explicitly solvated biomolecular simulations. J. Chem. Phys. B 112, 90209041.
Jung, A., 2022. Machine Learning: The Basics. Springer, Berlin.
Kalyuzhnyi, Y.V., Cummings, P.T., 1996. Phase diagram for the Lennard-Jones fluid modelled
by the hard-core Yukawa fluid. Mol. Phys. 87, 14591462.
Kaminski, G., Duffy, E.M., Matsui, T., Jorgensen, W.L., 1994. Free energies of hydration and
pure liquid properties of hydrocarbons from the OPLS all-atom model. J. Phys. Chem. 98,
1307713088.
Keith, J.A., Vassilev-Galindo, V., Cheng, B., Chmiela, S., Gastegger, M., Mu¨ller, K.-R.,
Tkatchenko, A, 2021. Combining machine learning and computational chemistry for predic￾tive insights into chemical systems. Chem. Rev. 121, 98169872.
Kennelly, A.E., 1931. Rationalised versus unrationalised practical electromagnetic units. Proc.
Amer. Phil. Soc. 70, 103119.
Khrapak, S.A., Chaudhuri, M., Morfill, G.E., 2011. Freezing of Lennard-Jones-type fluids.
J. Chem. Phys. 134, 054120.
Kihara, T., 1951. The second virial coefficient of non-spherical molecules. J. Phys. Soc. Jpn. 6,
289296.
Kirschner, K.N., Woods, R.J., 2001. Solvent interactions determine carbohydrate conformation.
PNAS 98, 1054110545.
Kiyohara, K., Spyriouni, T., Gubbins, K.E., Panagiotopoulos, A.Z., 1996. Thermodynamic scal￾ing Gibbs ensemble Monte Carlo: A new method for determination of phase coexistence
properties of fluids. Mol. Phys. 89, 965974.
Klauda, J.B., Venable, R.M., Freites, J.A., O’Connor, J.W., Tobias, D.J., Mondragon-Ramirez, C.,
Vorobyov, I., MacKerell Jr, A.D., Pastor, R.W., 2010. Update of the CHARMM all-atom
additive force field for lipids: validation on six lipid types. J. Chem. Phys. B 114,
78307843.
Klein, M.L., Venables, J.A. (Eds.), 1976. Rare Gas Solids, Vol. 1. Academic Press, London.
Kohler, F., Wilhem, E., Posch, H., 1976. Recent advances in the physical chemistry of the liquid
state. Adv. Mol. Relax. Process. 8, 195239.
Koide, A., Meath, W.J., Allnatt, A.R., 1981. Second-order charge overlap effects and damping
functions for isotropic atomic and molecular interactions. Chem. Phys. 58, 105119.
Kooij, S., Lerner, E., 2017. Unjamming in models with analytic pairwise potentials. Phys. Rev.
E 95, 062141.
Koshi, M., Matsui, H., 1994. Molecular dynamics study of high temperature phase-separation in
a H2O/N2 mixture with exp-6 interactions. Mol. Sim. 12, 227239.
Kreek, H., Meath, W.J., 1969. Charge-overlap effects. Dispersion and induction forces. J. Chem.
Phys. 50, 22892302.
Kriebel, C., Winkelmann, J., 1996. Thermodynamic properties of polarizable Stockmayer fluids:
Perturbation theory and simulation. Mol. Phys. 88, 559578.
Kriebel, C., Winkelmann, J., 1998. Simulation studies on mixtures of polarizable dipolar and
polarizable non-polar linear molecules. Mol. Phys. 93, 347353.
Kro¨ger, M., 2005. Models for Polymeric and Anisotropic Liquids. Springer, Berlin.
108 Molecular Simulation of FluidsLafitte, T., Apostolakou, A., Avendan˜o, C., Galindo, A., Adjiman, C.S., Mu¨ller, E.A., Jackson, G.,
2013. Accurate statistical associating fluid theory for chain molecules formed from Mie
segments. J. Chem. Phys. 139, 154504.
Laird, B.B., Haymet, A.D.J., 1989. The crystal-liquid interface of a body-centered-cubic-forming
substance: computer simulation of the r26 potential. J. Chem. Phys. 91, 36383646.
Laird, B.B., Haymet, A.D.J., 1992. Phase diagram for the inverse sixth power potential system
from molecular dynamics computer simulation. Mol. Phys. 75, 7180.
Landis, C.R., Root, D.M., Cleveland, T., 1995. In: Lipkowitz, K.B., Boyd, D.B. (Eds.), Reviews
in Computational Chemistry, Vol. 6. VCH Publishers, New York.
Li, J., Zhou, Z., Sadus, R.J., 2008. Parallel algorithms for molecular dynamics with induction
forces. Comput. Phys. Comm. 178, 384392 (2008).
Lii, J.-H., Allinger, N.L., 1989a. Molecular mechanics. The MM3 force field for hydrocarbons.
2. Vibrational frequencies and thermodynamics. J. Am. Chem. Soc. 111, 85668575.
Lii, J.-H., Allinger, N.L., 1989b. Molecular mechanics. The MM3 force field for hydrocarbons.
3. The van der Waals potentials and crystal data for aliphatic and aromatic hydrocarbons.
J. Am. Chem. Soc. 111, 85768582.
Likos, C.N., 2001. Effective interactions in soft condensed matter physics. Phys. Rep. 348,
267439.
Lomba, E., Almarza, N.G., 1994. Role of the interaction range in the shaping of phase diagrams
in simple fluids. The hard sphere Yukawa fluid as a case study. J. Chem. Phys. 100,
83678372.
London, F., 1937. The general theory of molecular forces. Trans. Faraday Soc. 33, 826.
Lopes, P.E.M., Guench, O., Mackerell Jr., A.D., 2015. Current status of protein force fields for
molecular dynamics. Methods Mol. Biol. 1215, 4771.
Losey, J., Sadus, R.J., 2019. Thermodynamic properties and anomalous behavior of double￾Gaussian core model potential fluids. Phys. Rev. E 100, 012112.
MacKerell Jr, A.D., 2004. Empirical force fields for biological macromolecules: overview and
issues. J. Comp. Chem. 25, 15851604.
MacKerell Jr, A.D., Bashford, D., Bellott, M., Dunbrack Jr, R.L., Evanseck, J.D., Field, M.J.,
Fischer, S., Gao, J., Guo, H., Ha, S., Joseph-McCarthy, D., Kuchnir, L., Kuczera, K.,
Lau, F.T.K., Mattos, C., Michnick, S., Ngo, T., Nguyen, D.T., Prodhom, B., Reiher III, W.E.,
Roux, B., Schlenkrich, M., Smith, C.J., Stote, R., Straub, J., Watanabe, M.,
Wio´rkiewicz-Kuczera, J., Yin, D., Karplus, M., 1998. All-atom empirical potential for
molecular modelling and dynamics studies of proteins. J. Chem. Phys.B 102,
35863616.
Mahoney, M.W., Jorgensen, W.L., 2000. A five site model of liquid water and the reproduction
of the density anomaly by rigid, nonpolarizable potential functions. J. Chem. Phys. 112,
89108922.
Maitland, G.C., Smith, E.B., 1973. Simplified representation of intermolecular potential energy.
Chem. Phys. Lett. 22, 443446.
Maitland, G.C., Rigby, M., Smith, E.B., Wakeham, W.A., 1981. Intermolecular Forces: Their
origin and Determination. Clarendon Press, Oxford.
Mao, Y., Zhang, Y., 2012. Thermal conductivity, shear viscosity and specific heat of rigid water
models. Chem. Phys. Lett. 542, 3741.
Maple, J.R., Hwang, M.-J., Stockfisch, T.P., Dinur, U., Waldman, M., Ewig, C.S., Hagler, A.T.,
1994. Derivation of class II force fields. I. Methodology and quantum force field for the
alkyl functional group and alkane molecules. J. Comput. Chem. 15, 162182.
Intermolecular pair potentials and force fields Chapter | 3 109Martin, M.G., 2006. Comparison of the AMBER, CHARMM, COMPASS, GROMOS, OPLS,
TraPPE and UFF force fields for the prediction of vapor-liquid coexistence curves and liquid
densities. Fluid Phase Equilib. 248, 5055.
Martin, M.G., Siepmann, J.I., 1998. Transferable potentials for phase equilibria. 1. United-atom
description of n-alkanes. J. Phys. Chem. B 102, 25692577.
Martin, M.G., Chen, B., Siepmann, J.I., 1998. A novel Monte Carlo algorithm for polarizable force
fields: application to a fluctuating charge model for water. J. Chem. Phys. 108, 33833385.
Mate, Z., Szalai, I., Boda, D., Henderson, D., 2011. Heat capacities of dipolar Yukawa model ´
polar fluid. Mol. Phys. 109, 203208.
Mausbach, P., Sadus, R.J., 2011. Thermodynamic properties in the molecular dynamics ensem￾ble applied to the Gaussian core model fluid. J. Chem. Phys. 134, 114515.
Mausbach, P., Ahmed, A., Sadus, R.J., 2009. Solid-liquid phase equilibrial of the Gaussian core
model fluid. J. Chem. Phys. 131, 184507. Erratum: J. Chem. Phys. 132, 019901 (2010).
Mayer, J.E., Mayer, M.G., 1940. Statistical Mechanics. John Wiley & Sons, Ney York, p. 271.
Mej´ıa, M., Herdes, C., Mu¨ller, E.A., 2014. Force fields for coarse-grained molecular simulations
from a corresponding states correlation. Ind. Eng. Chem. Res. 53, 41314141.
Mick, J.R., Barhahi, M.S., Jackman, B., Rushaidat, K., Schwiebert, L., Potoff, J.J., 2015.
Optimized Mie potentials for phase equilibria: application to noble gases and their mixtures
with n-alkanes. J. Chem. Phys. 143, 114504.
Mie, G., 1903. Zur Kinetschen Theorie der einatomigen Ko¨rp. Ann. Phys. 316, 657697.
Mognetti, B.M., Virnau, P., Yelash, L., Paul, W., Binder, K., Mu¨ller, M., MacDowell, L.G.,
2008. Coarse-graining dipolar interactions in simple fluids and polymer solutions: Monte
Carlo studies of the phase behavior. Phys. Chem. Chem. Phys. 11, 19231933.
Momany, F.A., McGuire, R.F., Burgess, A.W., Scheraga, H.A., 1975. Energy parameters in
polypeptides. VII. Geometric parameters, partial atomic charges, nonbonded interactions,
hydrogen bond interactions, and intrinsic torsional potentials for the naturally occurring
amino acids. J. Phys. Chem. 79, 23612381.
Monson, A.P., Rigby, M., Steele, W.A., 1983. Non-additive energy effects in molecular liquids.
Mol. Phys. 49, 893898.
Mooij, G.C.A.M., de Leeuw, S.W., Smit, B., Williams, C.P., 1992. Molecular dynamics studies
of polar/nonpolar fluid mixtures. II. Mixtures of Stockmayer and polarizable Lennard-Jones
fluids. J. Chem. Phys. 97, 51135120.
Moradzadeh, A., Aluru, N.R., 2021. Understanding simple liquids through statistical and deep
learning. J. Chem. Phys. 154, 204503.
Mueller, T., Hernandez, A., Wang, W., 2020. Machine learning for interatomic potential models.
J. Chem. Phys. 152, 050902.
Mulero, A. (Ed.), 2008. Theory and Simulation of Hard-Sphere Fluids and Related Systems.
Springer, Berlin.
Mu¨ller, E.A., Gelb, L.D., 2003. Molecular modeling of fluid-phase equilibria using an isotropic
multipolar potential. Ind. Eng. Chem. Res. 42, 41234131.
Mu¨ller-Plathe, F., 1996. An all-atom force field for liquid ethanol - properties of ethanol-water
mixtures. Mol. Sim. 18, 133143.
Munn, R.J., 1964. Interaction potential of the inert gases. I. J. Chem. Phys. 40, 14391446.
Mut ¯o, Y., 1943. On the forces acting between nonpolar molecules. J. Phys.-Math. Soc. Jpn. 17,
629631. Available from: https://doi.org/10.11429/subutsukaishi1927.17.10-11-12_629 [In
the literature, this paper is often incorrectly cited as Muto, Y., 1943. Proc. Phys. Math. Soc.
Japan 17, 629.].
110 Molecular Simulation of FluidsNath, S.K., Escobedo, F.A., de Pablo, J.J., 1998a. On the simulation of vapor-liquid equilibria
for alkanes. J. Chem. Phys. 108, 99059911.
Nath, S.K., Escobedo, F.A., de Pablo, J.J., Patramai, I., 1998b. Simulation of vapor-liquid equi￾libria for alkane mixtures. Ind. Eng. Chem. Res. 37, 31953902.
Ne´methy, G., Pottle, M.S., Scheraga, H.A., 1983. Energy parameters in polypeptides. 9.
Updating of geometrical parameters, nonbonded interactions, and hydrogen bond interac￾tions for the naturally occurring amino acids. J. Phys. Chem. 87, 18831887.
Ne´methy, G., Gibson, K.D., Palmer, K.A., Yoon, C.N., Paterlini, G., Zagari, A., Rumsey, S.,
Scheraga, H.A., 1992. Energy parameters in polypeptides. 10. Improved geometrical para￾meters and nonbonded interactions for use in the ECEPP/3 algorithm, with application to
proline-containing peptides. J. Phys. Chem. 96, 64726484.
Newkome, G.R., Moorefield, C.N., Vo¨gtle, 2001. Dendrimers and Dendroms: Concepts,
Syntheses, Applications. Wiley-VCH, Weinheim.
Nicolas, Gubbins, K.E., Streett, W.B., Tildesley, D.J., 1979. Equation of state for Lennard-Jones
molecules. Mol. Phys. 37, 14291454.
O’Shea, S.F., Dubey, G.S., Rasaiah, J.C., 1997. Phase transitions of quadrupolar fluids. J. Chem.
Phys. 107, 237242.
Okumura, H., Yonezawa, F., 2000. Liquid-vapor coexistence curves of several interatomic model
potentials (2000) J. Chem. Phys. 113, 91629168.
Orea, P., Reyes-Mercado, Y., Duda, Y., 2008. Some universal trends of the Mie (n, m) fluid
thermodynamics. Phys. Letts A 372, 7024.
Orkoulas, G., Panagiotopoulos, A.Z., 1994. Free energy and phase equilibria for the restricted primi￾tive model of ionic fluids from Monte Carlo simulations. J. Chem. Phys. 101, 14521459.
Orkoulas, G., Panagiotopoulos, A.Z., 1999. Phase behavior of the restricted primitive model and
square-well fluids from Monte Carlo simulations in the grand canonical ensemble. J. Chem.
Phys. 110, 15811590.
Panagiotopoulos, A.Z., 1987. Direct determination of phase coexistence properties of fluids by
Monte Carlo simulation in a new ensemble. Mol. Phys. 61, 813826.
Pant, S., Smith, Z., Wang, Y., Tajkhorshid, E., Tiwary, P., 2020. Confronting pitfalls of AI￾augmented molecular dynamics using statistical physics. J. Chem. Phys. 153, 234118.
Paricaud, P., 2006. A general perturbation approach for equation of state development:
Applications to simple fluids, ab initio potentials, and fullerenes. J. Chem. Phys. 124,
154505.
Patel, B.H., Docherty, H., Varga, S., Galindo, A., Maitland, G.C., 2005. Generalized equation of
state for square-well potentials of variable range. Mol. Phys. 103, 129139.
Pedersen, U.R., Bacher, A.K., Schrøder, T.B., Dyre, J.C., 2019. The EXP par-potential system.
III. Thermodynamic phase diagram. J. Chem. Phys. 150, 174501.
Perepu, P.K., Mishra, B.K., Pandu, A.M., 2023. Prediction of interaction energy for rare gas
dimers using machine learning approaches. J. Chem. Sci. 135, 12.
Peyrovedin, H., Shariati, A., 2020. Polar hard-core exponential-6 intermolecular potential func￾tion for determining the thermodynamic properties of polar gases. Ind. Eng. Chem. Res. 59,
1410614114.
Pieprzyk, S., Branka, A.C., Heyes, D.M., Bannerman, M.N., 2020. A comprehensive study of
the thermal conductivity of the hard sphere fluid and solid by molecular dynamics simula￾tion. Phys. Chem. Chem. Phys. 22, 88348845.
Pople, J.A., 1982. Intermolecular binding. Faraday Discuss. Chem. Soc. 73, 717.
Potoff, J.J., Bernard-Brunel, D.A., 2009. Potentials for phase equilibria calculations: applications
to alkanes and perfluoroalkanes. J. Phys. Chem. B. 113, 1472514731.
Intermolecular pair potentials and force fields Chapter | 3 111Potoff, J.J., Kamath, G., 2014. Mie potentials for phase equilibria: applications to alkenes.
J. Chem. Eng. Data 59, 31443150.
Prestipino, S., Saija, F., Giaquinta, P.V., 2005. Phase diagram of the Gaussian-core model. Phys.
Rev. E 71, 050102.
Prestipino, S., Speranza, C., Malescio, G., Giaquinta, P.V., 2014. Twofold reentrant melting in a
double-Gaussian fluid. J. Chem. Phys. 140, 084906.
Price, S.L., 1988. Is the isotropic atom-atom model potential adequate? Mol. Sim. 1, 135156.
Price, S.L., Stone, A.J., 1992. Electrostatic models for polypeptides: can we assume transferabil￾ity? J. Chem. Soc. Faraday Trans. 88, 17551763.
Raabe, G., Sadus, R.J., 2007. Influence of bond flexibility on the vapor-liquid phase equilibria
of water. J. Chem. Phys. 126, 044701 (2007).
Raabe, G., Sadus, R.J., 2011. Molecular dynamics simulation of the dieletric constant of water:
The effect of bond flexibility. J. Chem. Phys. 134, 235501.
Raabe, G., Sadus, R.J., 2012. Molecular dynamics simulation of the effect of bond flexibility on
the transport properties of water. J. Chem. Phys. 137, 104512.
Rahman, A., 1964. Correlations in the motion of atoms in liquid argon. Phys. Rev. 136,
405411.
Ramrattan, N.S., Avendan, C., Mu¨ller, E.A., Galindo, A., 2015. A corresponding-states frame￾work for the description of the Mie family of intermolecular potentials. Mol. Phys. 113,
932947.
Rao, K.S., Goyal, P.S., Dasannacharya, B.A., Menon, S.V.G., Kelkar, V.K., Manohar, C.,
Mishra, B.K., 1991. Application of Baxter sticky hard-sphere model to nonionic micelles.
Phys. B 174, 170173.
Rappe´, A.K., Casewit, C.J., 1997. Molecular Mechanics Across Chemistry. University Science
Books, Sausalito.
Rappe´, A.K., Goddard III, W.A., 1991. Charge equilibration for molecular dynamics simulation.
J. Phys. Chem. 95, 33583363.
Rappe´, A.K., Casewit, C.J., Colwell, K.S., Goddard III, W.A., Skiff, W.M., 1992. UFF, a full
periodic table force field for molecular mechanics and molecular dynamics simulations.
J. Am. Chem. Soc. 114, 1002410035.
Reed, T.M., Gubbins, K.E., 1973. Applied Statistical Mechanics: Thermodynamic and Transport
Properties of Fluids. Butterworth-Heinemann, Boston, p. 114.
Ren, P.Y., Ponder, J.W., 2003. Polarizable atomic multipole water for molecular mechanics sim￾ulation. J. Chem. Phys. B 117, 59335947.
Reyes, Y., Barcentas, M., Odriozola, G., Orea, P., 2016. Thermodynamic properties of triangle- ´
well fluids in two dimensions: MC and MD simulations. J. Chem. Phys. 145, 174505.
Rice, W.E., Hirschfeler, J.O., 1954. Second virial coefficients of gases obeying a modified
Buckingham (Exp-Six) potential. J. Chem. Phys. 22, 187192.
Rinker, S., 2018. Fixed-charge atomistic force fields for molecular dynamics simulations in the
condensed phase: An overview. J. Chem. Inf. Model. 58, 565578.
Rittger, E., 1990a. The chemical potential of liquid xenon by computer simulation. Mol. Phys.
69, 853865.
Rittger, E., 1990b. Can three-atom potentials be determined from thermodynamic data? Mol.
Phys. 69, 867894.
Rittger, E., 1990c. An empirical three-atom potential for xenon. Mol. Phys. 71, 7996.
Rosenfeld, Y., 1993. Free energy model for inhomogeneous fluid mixtures: Yukawa-charged
hard spheres, general interactions, and plasmas. J. Chem. Phys. 98, 81268148.
Rosenfeld, Y., 1996. Ewald method for simulating Yukawa systems. Mol. Phys. 88, 13571363.
112 Molecular Simulation of FluidsRoterman, I.K., Gibson, K.D., Scheraga, H.A., 1989a. A comparison of the CHARMM, AMBER
and ECEPP potentials for peptides. I. Conformational predictions for the tandemly repeated
peptide (Asn-Ala-Asn-Pro)9. J. Biomol. Struct. Dyn. 7, 391419.
Roterman, I.K., Lambert, M.H., Gibson, K.D., Scheraga, H.A., 1989b. A comparison of the
CHARMM, AMBER and ECEPP potentials for peptides. II. φ-ψ maps for N-acetyl Alanine
N’-methyl amide: comparisons, contrasts and simple experimental tests. J. Biomol. Struct.
Dyn. 7, 421453.
Rowlinson, J.S., 1989. The Yukawa potential. Phys. A 156, 1534.
Rowlinson, J.S., 2002. Cohesion: A Scientific History of Intermolecular Forces. Cambridge
University Press, Cambridge.
Rudisill, E.N., Cummings, P.T., 1989. Gibbs ensemble simulation of phase equilibrium in the
hard core two-Yukawa fluid model for the Lennard-Jones fluid. Mol. Phys. 68, 629635.
Sadus, R.J., 1992. High Pressure Phase Behaviour of Multicomponent Fluid Mixtures. Elsevier,
Amsterdam.
Sadus, R.J., 1996a. Molecular simulation of the vapour-liquid equilibria of pure fluids and binary mix￾tures containing dipolar components: the effect of Keesom interactions. Mol. Phys. 87, 979990.
Sadus, R.J., 1996b. Molecular simulation of the liquid-liquid equilibria of binary mixtures con￾taining non-polar and dipolar components interacting via the Keesom potential. Mol. Phys.
89, 11871194.
Sadus, R.J., 2018. Second virial coefficient properties of the n-m Lennard-Jones/Mie potential.
J. Chem. Phys. 149, 074504. Erratum: J. Chem. Phys. 149, 079902 (2019).
Sadus, R.J., 2019. Two-body intermolecular potentials from second virial coefficient properties.
J. Chem. Phys. 150, 024503. Erratum: J. Chem. Phys. 150, 024503 (2019).
Sadus, R.J., 2020a. Vapor-liquid equilibria and cohesive r24 interactions. J. Chem. Phys. 153,
204504.
Sadus, R.J., 2020b. Effect of the range of particle cohesion on the phase behavior and thermody￾namic properties of fluids. J. Chem. Phys. 153, 244502.
Sadus, R.J., Prausnitz, J.M., 1996. Three-body interactions in fluids from molecular simulation:
vapor-liquid phase coexistence of argon. J. Chem. Phys. 104, 47844787.
Saija, F., Prestipino, S., 2005. High-pressure phase diagram of the exp-6 model: the case of Xe.
Phys. Rev. B 72, 024113.
Saija, F., Malescio, G., Prestipino, S., 2010. Re-entrant melting of the exp-6 fluid: The role of
repulsion softness. Phys. Chem. Liq. 48, 477487.
Santos, A., Fanton, R., Giacometti, 2008. Penetrable square-well fluids: Exact results in one
dimension. Phys. Rev. E. 77, 051206.
Seng, X., Toennies, J. P., Tang, K. T., 2020. Conformal potential for all the rare gas dimers over
the full range of internuclear distances. Phys. Rev. Lett. 125, 253402.
Scho¨ll-Paschinger, E., Valdez-Pe´rez, N.E., Benavides, A.L., Castan˜edo-Priego, R., 2013. Phase
behavior of the modified-Yukawa fluid and its sticky limit. J. Chem. Phys. 139, 184902.
Schouten, J.A., de Kuijper, A., Michels, J.P.J., 1991. The critical line of He-H2 up to 2500
Kelvin and the influence of attraction on fluid-fluid separation. Phys. Rev. B: Condens.
Matter 44, 66306634.
Scott, W.R.P., Hu¨nenberger, P.H., Tironi, I.G., Mark, A.E., Billeter, S.R., Fennen, J., Torda,
A.E., Huber, T., Kru¨ger, P., van Gunsteren, W.F., 1999. The GROMOS biomolecular simu￾lation program package. J. Phys. Chem. A 103, 35963607.
Sellers, M.S., Lisal, M., Brennan, J.K., 2015. Mol. Phys. 113, 4554.
Shah, M.S., Siepmann, J.I., Tsapatsis, M., 2017. Transferable potentials for phase equilibria:
improved united-atom description of ethane and ethylene. AIChE J. 63, 50985109.
Intermolecular pair potentials and force fields Chapter | 3 113Shannon, R.J., Hornung, B., Tew, D.P., Glowacki, D.R., 2019. Anharmonic molecular mechan￾ics: ab initio based Morse parametrizations for the popular MM3 force field. J. Phys. Chem.
A 123, 29912999.
Shavitt, I., Boys, S.F., 1956. A General expression for intermolecular potentials. Nature 178, 1340.
Sherwood, A.E., Mason, E.A., 1965. Virial coefficients for the exponential repulsive potential.
Phys. Fluids 8, 15771579.
Sherwood, A.E., Prausnitz, J.M., 1964. Third virial coefficient for the Kihara, exp-6, and square￾well potentials. J. Chem. Phys. 41, 413428.
Shukla, K.P., 2000. Phase equilibria and thermodynamic properties of hard core Yukawa fluids
of variable range from simulations and an analytical theory. J. Chem. Phys. 112,
1035810367.
Shvab, I., Sadus, R.J., 2016. Atomistic water models: aqueous thermodynamic properties from
ambient to supercritical conditions. Fluid Phase Equilib. 407, 730.
Siepmann, J.I., Karaborni, S., Smit, B., 1993. Simulating the critical behaviour of complex
fluids. Nature 365, 330332.
Smit, B., Frenkel, D., 1991. Vapour-liquid equilibria of the hard core Yukawa fluid. Mol. Phys.
74, 3539.
Smit, B., Williams, C.P., 1990. Vapour-liquid equilibria for quadrupolar Lennard-Jones fluids.
J. Phys.: Condens. Matter 2, 42814288.
Smit, B., Williams, C.P., Henriks, E.M., de Leeuw, S.W., 1989. Vapour-liquid equilibria for
Stockmayer fluids. Mol. Phys. 68, 765769.
Smith, D.E., Haymet, A.D.J., 1993. Simulations of aqueous solutions: the role of flexibility and
the treatment of long-range forces. Fluid Phase Equilib. 88, 7987.
Smith, J.C., Karplus, M., 1992. Empirical force field study of geometries and conformational
transitions of some organic molecules. J. Am. Chem. Soc. 114, 801812.
Spear, R.P., 2000. Fluid-fluid transition of hard spheres with very-short-range attraction. Phys.,
Rev. E 61, 60196022.
Speranza, C., Prestipino, S., Malescio, G., Giaquinta, P.V., 2014. Phase behavior of a fluid with
a double Gaussian potential displaying waterlike features. Phys. Rev. E. 90, 012305.
Spurling, T.H., Mason, E.A., 1967. Determination of molecular quadrupole moments from vis￾cosities and second virial coefficients. J. Chem. Phys. 46, 322326.
Stapleton, M.R., Tildesley, D.J., Panagiotopoulos, A.Z., Quirke, N., 1989. Phase equilibria of
quadrupolar fluids by simulation in the Gibbs ensemble. Mol. Sim. 2, 147162.
Stell, G., 1991. Sticky spheres and related systems. J. Stat. Phys. 63, 12031221.
Stiegler, T., Sadus, R.J., 2015. Molecular simulation of fluids with non-identical intermolecular
potentials: thermodynamic properties of 10-5 1 12-6 Mie potential binary mixtures.
J. Chem. Phys. 142, 084504.
Stillinger, F.H., 1976. Phase transitions in the Gaussian core system. J. Chem. Phys. 65,
39683974.
Stone, A.J., 2013. The Theory of Intermolecular Forces, 2nd Ed Oxford University Press,
Oxford.
Strauch, H.J., Cummings, P.T., 1993. Gibbs ensemble simulation of mixed solvent electrolyte
solutions. Fluid Phase Equilib. 86, 147172.
Sun, L., Deng, W.-Q., 2017. Recent developments of first-principles force fields. WIREs
Comput. Mol. Sci. 7, 115.
Tang, K.T., Toennies, J.P., 1984. An improved simple model for the van der Waals potential based
on universal damping functions for the dispersion coefficients. J. Chem. Phys. 80, 37263741.
114 Molecular Simulation of FluidsTavares, F.W., Sandler, S.I., 1996. Vapour-liquid equilibria of exponential-six fluids. Mol. Phys.
87, 14711476.
Tee, S.L., Gotoh, S., Stewart, W.E., 1966. Molecular parameters for normal fluids: The Kihara
potential with spherical core. Ind. Eng. Chem. Fundam. 5, 363366.
Tiesinga, E., Mohr, P.J., Newell, D.B., Taylor, B.N., 2021. CODATA recommended values of
the fundamental physical constants: 2018. Rev. Mod. Phys. 93, 025010. Available from:
https://physics.nist.gov/cuu/Constants/index.html.
Travis, K.P. and Sadus, R.J. (2023), to be submitted.
Valdez-Pe´rez, N.E., Benavides, A.L., Scho¨ll-Paschinger, E., Castan˜edo-Priego, R., 2012. Phase
behavior of colloids and proteins in aqueous suspensions: theory and computer simulations.
J. Chem. Phys. 137, 084905.
van Gunsteren, W.F., Bakowies, D., Baron, R., Chandrasekhar, I., Christen, M., Daura, X., Gee,
P., Geerke, D.P., Gla¨ttli, A., Hu¨nenberger, H., Kastenholz, M.A., Oostenbrink, C., Schenk,
M., Trzesniak, D., va der Vegt, N.F.A., Yu, H.B., 2006. Biomolecular modeling: Goals, pro￾blems, perspectives. Angew. Chem. Int. Ed. 45, 40644092.
van Leeuwen, M.E., Smit, B., 1993. What makes a polar liquid a liquid? Phys. Rev. Lett. 71,
39913994.
van Leeuwen, M.E., Smit, B., Hendriks, E.M., 1993. Vapour-liquid equilibria of Stockmayer
fluids. Computer simulations and perturbation theory. Mol. Phys. 78, 271283.
van Vleet, M.J., Misquitta, A.J., Stone, A.J., Schmidt, J.R., 2016. Beyond Born-Mayer:
Improved models for short-range repulsion in ab initio force fields. J. Chem. Theory
Comput. 12, 38513870.
Vanommeslaeghe, K., MacKerell Jr, A., D., 2015. CHARMM additive and polarizable force
fields for biophysics and computer-aided drug design. Biochim. Biophys. Acta 1850,
861871.
Vedani, A., 1988. YETI: An interactive molecular mechanics program for small-molecular pro￾tein complexes. J. Comput. Chem. 9, 269280.
Vega, L., de Miguel, E., Rull, L.F., Jackson, G., McLure, I.A., 1992a. Phase equilibria and criti￾cal behavior of square-well fluids of variable width by Gibbs ensemble Monte Carlo
Simulation. J. Chem. Phys. 96, 22962305.
Vega, C., Lago, S., de Miguel, E., Rull, L.F., 1992b. Liquid-vapor equilibria of linear Kihara
molecules. J. Phys. Chem. 96, 74317437.
Vega, C., Abascal, J.L.F., Conde, M.M., Aragones, J.L., 2009. What ice can teach us about water
interactions: A critical comparison of the performance of different water models. Farad.
Discuss. 141, 251276.
Wang, L.-P., Head-Gordon, T., Ponder, J.W., Ren, P., Chodera, J.D., Eastman, P.K., Martinez,
T.J., Pande, V.S., 2013. Systematic improvement of a classical molecular model of water. J.
Phys. Chem. B 117, 99569972.
Wang, X., Ramirez-Hinestrosa, S., Dobnikar, J., Frenkel, D., 2020. The Lennard-Jones potential:
When (not) to use it. Phys. Chem. Chem. Phys. 22, 1052410633.
Warner Jr., H.R., 1972. Kinetic theory and rheology of dilute suspensions of finitely extendible
dumbbells. Ind. Eng. Chem. Fundam. 11, 379387.
Weeks, J.D., Chandler, D., Andersen, H.C., 1971. Role of repulsive forces in determining the
equilibrium structure of simple liquids. J. Chem. Phys. 54, 52375247.
Wei, Y.S., Sadus, R.J., 2000. Equations of state for the calculation of fluid-phase equilibria.
AIChE J. 46, 169196.
Intermolecular pair potentials and force fields Chapter | 3 115Weiner, S.J., Kollman, P.A., Case, D.A., Singh, U.C., Chio, C., Alagona, G., Profeta Jr, S.,
Weiner, P., 1984. A new force field for molecular mechanical simulation of nucleic acids
and proteins. J. Am. Chem. Soc. 106, 765784.
Wheatley, R.J., Meath, W.J., 1993. Dispersion energy damping functions, and their relative scale
with interatomic separation, for (H, He, Li)-(H, He, Li) interactions. Mol. Phys. 79, 253275.
Wood, W.W., Jacobson, J.D., 1957. Preliminary results from a recalculation of the Monte Carlo
equation of state for hard spheres. J. Chem. Phys. 27, 1207.
Wood, W.W., Parker, F.R., 1957. Monte Carlo equation of state of molecules interacting with
the Lennard-Jones potential. I. A supercritical isotherm at about twice the critical tempera￾ture. J. Chem. Phys. 27, 720733.
Wu, G.-W., Sadus, R.J., 2000. Molecular simulation of the high pressure phase equilibria of
binary atomic fluid mixtures using the exponential-6 intermolecular potential. Fluid Phase
Equilib. 170, 269284.
Wu, G.-W., Sadus, R.J., 2004. A new phase for one-component hard spheres. J. Chem. Phys.
120, 1168611691.
Wu, G.-W., Sadus, R.J., 2005. Hard sphere compressibility factors for equation of state develop￾ment. AIChE J. 51, 309313.
Wu, Y., Tepper, H., Voth, G., 2006. Flexible simple point-charge water model with improved
liquid-state properties. J. Chem. Phys. 124, 024503.
Yuste, S.B., Santos, A., 1994. A model for the structure of square-well fluids. J. Chem. Phys.
101, 23552364.
Zarragoicoechea, G.J., Scalise, O.H., 1997. On the gas-gas equilibria of second kind of nonpolar
fluid binary mixtures from a hard-sphere exp-6 molecular model. J. Chem. Phys. 107,
42584363.
116 Molecular Simulation of FluidsChapter 4
Ab initio, two-body and three￾body intermolecular potentials
In Chapter 3 details of effective pair potentials and force fields that are used
in molecular simulation to evaluate the contribution to energy via Eq. (3.1)
were given. In this chapter, we examine both two- and three-body intermo￾lecular potentials used to calculate energy via Eq. (3.2). These potentials can
be obtained from empirical, theory, and ab initio sources.
It is common to assume that intermolecular interactions are pairwise
additive. Two-body interactions dominate other multi-body interaction and
pairwise potentials alone are often sufficiently accurate. However, from a
theoretical perspective, it is well known that some aspects of intermolecular
interactions cannot be exclusively pairwise additive. Strictly, pairwise addi￾tivity only applies to electrostatic, magnetic, and short-range penetration
interactions. To some extent, many-body effects will be present in induction,
dispersion, resonance, exchange, repulsion, and charge transfer interactions.
In particular, many-body effects are likely to exert a strong influence on
induction energy. For example, Wilson and Madden (1994) have reported
that many-body induction effects have a crucial role in stabilizing the crystal
structures of CdCl2 and MgCl2.
Despite the evidence for deviations from pairwise additivity, molecu￾lar simulations of liquids have been confined almost exclusively to pair￾wise potentials. However, with the increasing sophistication of both
experimental and theoretical techniques, it is likely that many-body inter￾actions will be required for the quantitative description of liquids. This is
particularly the case for large molecules and polar molecules, which are
likely to be influenced substantially by many-body interactions. The
increasing importance of many-body interactions with molecular size and
complexity is illustrated in Fig. 4.1, which shows that the nonadditive dis￾persion coefficient (v) increases progressively with molecular size relative
to the two-body dispersion coefficient (C6). It has been reported (Barker
et al., 1974; Rittger, 1990c) that calculating three-body interactions is
required to obtain satisfactory agreement with experiment for the proper￾ties of xenon. In a dipolar system, the effect of three-body interactions
can be expected to be considerably greater because of additional nonaddi￾tive effects from induction.
117 Molecular Simulation of Fluids. DOI: https://doi.org/10.1016/B978-0-323-85398-9.00009-5
© 2024 Elsevier B.V. All rights reserved.Advances in computational chemistry have witnessed the development of
intermolecular potentials from first principles or ab initio data. Ab initio poten￾tials can be accurate alternatives to empirically derived potentials. As discussed
below, ab initio calculations can be used to determine the interaction between
atoms from first principles. The information obtained from ab initio calculations
can be fitted to obtain an ab initio potential that can be employed in both Monte
Carlo (MC) and molecular dynamics (MD) simulations.
The current state-of-the-art for ab initio potentials is largely confined to
the two-body properties of simple atoms or small polyatomic molecules. Ab
initio potentials for large molecules typically include ab initio data for part
of the molecule’s properties (Sun and Deng, 2017), such as bond-stretching
terms, rather than being fully ab initio potentials. Therefore, it is useful to
make the distinction between fully ab initio potentials and potentials
informed or augmented by ab initio data. Obtaining ab initio potentials for
three-body interactions is more challenging than the two-body case.
Consequently, most three-body potentials are obtained from conventional
theory or empirical considerations. A useful strategy is to augment ab
initio two-body potentials with three-body potentials. The combination facili￾tates the prediction of the properties of real systems.
4.1 Ab initio calculations
The objective of ab initio methods is to calculate molecular properties from the
Schro¨dinger equation. Typically, the BornOppenheimer approximation is used,
FIGURE 4.1 Relative importance of the nonadditive triple-dipole dispersion coefficient with
respect to molecular size. Values are given for helium, argon, krypton, and xenon.
118 Molecular Simulation of Fluidswhich assumes that the movement of the nuclei and electron are independent of
each other. The electronic energy is obtained by solving the Schro¨dinger equation
for the electrons. This results in a wave function, which is used to calculate prop￾erties such as the molecular multipole moments. The electronic energy as a func￾tion of nuclear coordinates generates a potential energy surface, which is the
potential energy term in the Schro¨dinger equation. The other properties of the
molecule are functions of the potential energy.
Approximations are required to solve the Schro¨dinger equation. The most
common methods used are systematic corrections to the HartreeFock (HF)
or self-consistent field (SCF) models and density functional theory (DFT).
Sandre´ and Pasturel (1997) have reviewed the use of ab initio calculations in
the context of molecular dynamics. The description of the ab initio approach
given here is limited to the key underlying principles because the topic has
been discussed in detail elsewhere (Scheiner, 1997; Marx and Hutter, 2009).
The current state-of-the-art for ab initio potentials is to determine the
potential energy curve using a supermolecular calculation up to the coupled
cluster (CC) with single, double, and perturbative triple excitation [CCSD
(T)] contributions (Raghavachari et al., 1989; Stone, 2013). In a few cases
(Hellmann et al., 2021) this can be taken to up to the triple and quadruple
level with pentuple excitations [CCSDTQ(P)]. Here, we will mainly focus on
contemporary potentials, which have benefited from the latest advances in
computational chemistry.
4.1.1 HartreeFock method
The HF approach commonly involves expanding molecular orbitals in a con￾tracted Gaussian set and evaluating integrals over the contracted Gaussians.
The general form of the integrals is:
ðij\klÞ 5
ððχið1Þ

χjð1Þ 1
r12
χkð1Þ

χlð1Þdτ1dτ2 ð4:1Þ
To solve Eq. (4.1), we must first determine the basis functions (χI). The
most-widely used basis functions are
χ 5 RlkðrÞ
X
i
ciNiexpð2 αir2
Þ; ð4:2Þ
where Rlk is a solid harmonic, r  (r,θ,ϕ) is the position of the electron rela￾tive to the nucleus, Niexp(-αir
2
) is a primitive Gaussian function, Ni is a nor￾malizing factor, and ci is an expansion coefficient, which optimizes the energy
of the isolated atom. Generally, there are approximately N4
/8 two-electron
integrals for a calculation involving N basis functions. It is common to solve
these integrals using software packages such as GAUSSIAN.1
1. https://gaussian.com
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 119The basic HF method cannot be used to calculate the intermolecular
energy because it does not consider the effect of electron correlation.
However, it can be extended (Friesner, 1991) to include electron correlation
effects. Some examples include perturbation expansion (Møller and Plesset,
1934); optimized multiconfigurational wave function methods (MCSCF)
(Shepard, 1987); valence bond (VB) methods (Goddard and Harding, 1978);
CC, and configuration interaction (CI) methods (Bartlett, 1981). These addi￾tional refinements are at the expense of a considerable increase in computa￾tional cost. If Nb denotes the number of basis sets, the HF electron
correlation algorithms are typically of order Nb
5 to Nb
8
. Consequently, appli￾cations of the HF method are confined generally to relatively small mole￾cules. The HF plus dispersion (HFD) method is an alternative to a full ab
initio calculation. The HFD approach combines an ab initio calculation with
an empirical expression for dispersion. The quality of both the HF and post￾HF predictions depends on the basis set. Currently, the best basis sets are
augmented correlation-consistent sets such as aug-cc-pVnZ (n 5 D, T, Q, 5),
which allow an extrapolation to infinitely large basis sets.
4.1.2 Density functional theory
DFT is an alternative to the HF method. Instead of calculating the wave
functions, DFT evaluates the electron density profile (n(r)). The DFT method
is based on the work of Hohenberg and Kohn (1964), which postulated that
the ground-state properties of a system are functions of charge density. The
total electronic energy is a function of the electron density (ρ),
EðρÞ 5 EKEðρÞ 1 ECðρÞ 1 EHðρÞ 1 EXCðρÞ; ð4:3Þ
where EKE, EC, EH, and EXC are the contributions from kinetic energy, elec￾tronnuclear interaction, electronelectron Coulombic energy, and
exchange and correlation, respectively. It is apparent from Eq. (4.3) that the
density determines the ground-state properties of the system.
The general procedure for a density functional calculation is to express
the various contributions to Eq. (4.3) in terms of the density and attempt to
optimize the energy with respect to density in accordance with any con￾straints on the system. Eq. (4.3) can be written as,
EðρÞ 5 2
Xð
ψi
 
2r2
2
!
ψidv 1
ð
VnuclearρðrÞdv 1
1
2
ððdvdv0 ρðrÞρðr0
Þ
r 2 r0 j j
1 EXC½ρðrÞ
; ð4:4Þ
where ψ is the spatial orbital and ρ(r) the charge density at a point r. The
charge density is the sum over occupied molecular orbitals of ψ2
.
120 Molecular Simulation of FluidsρðrÞ 5
N
Xoccupied
i51
ψiðrÞ 
 

2 ð4:5Þ
To complete the evaluation of Eq. (4.5), an approximation for the
exchange-correlation term is required. Typically, a local density approxima￾tion is used, which assumes that the charge density varies slowly throughout
a molecule. Therefore, a localized region of a molecule behaves like a uni￾form electron gas and
EXC½ρðrÞD
ð
ρðrÞεXC½ρðrÞdr; ð4:6Þ
where εXC is the exchange-correlation energy per particle in a uniform elec￾tron gas. The exchange energy of a uniform electron gas can be obtained
from a variety of analytical expressions. For example, Kohn and Vashista
(1983) proposed be following simple relationship:
εXCðρðrÞÞ 5 2 0:78558770½ρðrÞ1=3
: ð4:7Þ
Kohn and Sham (1965) showed that E could be found from the solution
of single-particle equations of the form:
2r2
2
1 VnuclearðrÞ 1
ð
dv0 ρðrÞ
r-r0 j j
1 VXCðrÞ
 	ψiðrÞ 5 εiψiðrÞ; ð4:8Þ
where the exchange-correlation function VXC is obtained from:
VXCðrÞ 5 dEXC½ρðrÞ
dρðrÞ : ð4:9Þ
The most important advantages of the DFT approach compared with
HF-based methods are that electron correlations are included from the start
and that it is considerably less expensive computationally. A DFT calculation
scales typically as Nb
3 compared with Nb
5 to Nb
7 for HF calculations. The
computational cost is not affected greatly by replacing the local density
approximation with more accurate alternatives. However, unlike HF meth￾ods, DFT cannot be improved systematically. The HF methods are also more
accurate than DFT calculations for small molecules.
DFT has been used with mixed success to obtain intermolecular poten￾tials. Good results have been reported for water (Xantheas, 1995). However,
a comparison of DFT results with experiment for hydrogen bonded complex
indicated generally poor agreement (del Berne et al., 1995). Poor results
have also been reported (Pe´rez-Jorda and Becke, 1995 ´ ) for the application of
DFT for some inert gases. A weakness of conventional DFT is that current
density functionals do not describe intermolecular interaction energy as
decaying according to r
26 at large separations. Further, the errors associated
with numerical quadratures are similar in magnitude to the intermolecular
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 121interaction energies. Therefore, the prediction of dispersion interaction often
fails; however, some progress in improving this situation has been reported
(Johnson et al., 2009).
It should be noted that the earlier issues are not fundamental limitations
of the DFT method, and they may be overcome in the future. It is an area of
ongoing research interest and several comprehensive reviews of DFT are
available (Parr and Yang, 1990; Trickey, 1990; Friesner, 1991; March, 1992;
Orio et al., 2009; Cohen et al., 2012; Kryanko and Luden˜a, 2014; Bretonnet,
2017; Verma and Truhlar, 2020).
4.1.3 The CarParrinello method
The accuracy of conventional simulations is limited to the accuracy of the inter￾molecular potential used. Car and Parrinello (1985) have combined molecular
dynamics with some elements of electronic-structure theory. The CarParrinello
molecular dynamics (CPMD) method provides an alternative to the conventional
development of intermolecular potentials by determining interactions “on-the-fly.”
The main element of their approach is the formulation of a new Lagrangian
(Chapter 2) function from which the equations of motion are derived for the
nuclear coordinates and electronic orbitals. The Lagrangian function is
L 5P
i
1
2
μ
ð
Ω
d3
r ψ_
i

 

2
1X
I
1
2
MIR_ 2
I 1X
v
1
2
μvα_ 2
v
2 E fψig;fRIg;fαvg   ; ð4:10Þ
where the orbitals ψi are subject to holonomic constraints.
ð
Ω
d3
rψ

iðr; tÞψjðr; tÞ 5 δij ð4:11Þ
In Eq. (4.10), E is the energy; {RI} are nuclear coordinates; {αv} are all the
possible external constraints such as volume Ω; MI are the physical ionic masses;
and μ and μv are arbitrary parameters and the dot indicates a time derivative.
The definition of the Lagrangian function generates a dynamics for the
{ψi}’s, {RI}’s, and {αv}’s through the equations of motion
μψ€i ðr; tÞ 5 2 δE
δψ
i ðr; tÞ
1X
k
Λikψkðr; tÞ
MIR€I 5 2 rRIE
μvα€ v 5 2 @E
@αv
9
>>>>>=
>>>>>;
; ð4:12Þ
where Λik are the Lagrange multipliers (Chapter 2) introduced to satisfy the
constraints in Eq. (4.10). The ion dynamics in Eq. (4.10) have a physical
122 Molecular Simulation of Fluidsmeaning, whereas the dynamics associated with the {ψi}’s and {αv}’s are
fictitious. From Eq. (4.10), the kinetic energy Ekin is:
Ekin 5X
i
1
2
μ
ð
Ω
d3
r ψ_i

 

2
1X
I
1
2
MIR_ 2
I 1X
v
1
2
μvα_ 2
I : ð4:13Þ
In principle, these equations can be used for ab initio molecular dynamics
simulation for which the intermolecular potential is not specified in advance.
Variations on the CPMD method have been discussed by Payne et al. (1990,
1992) and Marx and Hutter (2009). Tuckerman and Parrinello (1994a,b) have
developed strategies for integrating the equations of motion in CarParrinello
simulations. The technique has also been applied (Tuckerman et al., 1996) to
path integral molecular dynamics. Woo et al. (1997) have reported an interesting
combination of the CPMD method with quantum mechanics and molecular
mechanics principles. CPMD has been applied to a variety of situations includ￾ing material investigation (Sahoo and Nair, 2016), biomolecular chemical reac￾tions (Hofbauer and Frank, 2012), and water (Frank, 2020).
4.2 Two-body atomic potentials
In Chapter 3, we emphasized the distinction between effective pairwise
potentials and two-body potentials. The square well, Lennard-Jones (LJ), and
exp-6 potentials are generic potentials, which can be applied to a wide vari￾ety of fluids with a varying degree of accuracy. In contrast, considerable
effort has been made in developing highly accurate intermolecular potentials
that are specific to the two-body interactions of particular atom or class of
atoms. The state-of-the-art is to obtain two-body interactions form ab initio
data; however, reasonably accurate two-body potentials have been obtained
via the careful study of experimental two-body data such as the second virial
coefficients.
4.2.1 Empirical potentials
The noble gases have been the focus of the work to obtain two-body potentials
from the analysis of experimental data. The resulting potentials have been com￾pared extensively (Klein, 1984; Klein and Venables, 1976; Rowlinson, 2002).
Many of the empirical two-body potentials have the following general form:
u2ðrÞ 5 Xn
i51
fiðrÞexpðgðrÞÞ 2 Xm
j5o
hðrÞC2j16
k 1 r2j16 ; ð4:14Þ
where f(r), g(r), and h(r) are some functions of intermolecular separation (r)
and k is a constant, which is often 0. Eq. (4.14) combines an exponential
contribution from repulsion with attractive terms from the dispersion coeffi￾cients (C2j16). The nature of Eq. (4.14) has been informed by the long his￾tory of developing effective pairwise potentials as discussed in Chapter 3.
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 123Several workers (Bobetic and Barker, 1970; Barker et al., 1971; Maitland
and Smith, 1971) have assessed experimental data to obtain accurate poten￾tials for argon. The potentials of Barker and Pompe (1968) and Bobetic and
Barker (1970) have the following form:
u2ðrÞ 5 ε X
5
i50
Aiðx21Þ
i
exp½  αð1 2 xÞ 2 X
2
j50
C2j16
δ 1 x2j16
" #: ð4:15Þ
In Eq. (4.15), ε is the depth of the potential and the minimum separation
(rm), x 5 r/rm and the other parameters are obtained by fitting the potential to
experimental data for molecular beam scattering, second virial coefficients,
and long-range interaction coefficients. The contribution from repulsion has
an exponential dependence on intermolecular separation and the contribution
to dispersion of the C6, C8, and C10 coefficients are included. Comparing
Eq. (4.15) to Eq. (4.14) yields:
fiðrÞ 5 εAiðx21Þ
i
gðrÞ 5 αð1 2 xÞ
hðrÞ 5 ε
k 5 δ
9
>>=
>>;
: ð4:16Þ
The only difference between the BarkerPompe and BobeticBarker poten￾tials is that a different set of parameters is used in each case. Later, Barker et al.
(1971) proposed a linear combination of the two potentials, which is known
commonly as the BarkerFisherWatts (BFW) potential. The BFW potential
provides an accurate representation of the two-body interactions of argon.
The molecule-specific nature of the intermolecular potential is illustrated
by attempts to use Eq. (4.15) for other noble gases such as krypton and
xenon. Barker et al. (1974) reported that modifications to Eq. (4.15) were
required to obtain an optimal representation for these larger noble gases.
They determined a potential of the form u(r) 5 u0(r) 1 u1(r), where u0(r) is
identical to Eq. (4.15) and u1(r) is given by:
u1ðrÞ 5 Pðx21Þ
4 1 Qðx21Þ
5  exp α0 ½  ð1 2 xÞ x . 1
0 x # 1

ð4:17Þ
and α’, P, and Q are additional parameters obtained by fitting data for differ￾ential scattering cross sections.
Parson et al. (1972) developed a potential based largely on molecular
beam data.
u2ðrÞ 5
εexp½  22βðx 2 1Þ 2 2εexp 2β0
ðx 2 1Þ   0 # x # x1
εb1 1 εðx 2 x1Þ½  b2 1 ðx 2 x2Þ ½  b3 1 ðx 2 x1Þb4 x1 , x # x2
ε C6x26 1 C8x28 1 C10x210   x2 , x #N
8
<
:
ð4:18Þ
The potential provides a good description of interatomic interactions in
argon.
124 Molecular Simulation of FluidsThe potential of Aziz and Slaman (1986) gives a particularly accurate
description of the thermodynamic properties of argon. The AzizSalman
potential is
u2ðrÞ 5 εAexpð2 αx 1 β
x2
Þ 2 εFðxÞ
X
2
j50
c2j16
x2j16 ; ð4:19Þ
where
FðxÞ 5 exp 2
 D
x 21
2  	 x , D
1 x $ D
8
<
:
ð4:20Þ
x 5 r/rm, and the other terms are adjustable parameters. In common with the
BornMayer potential (1932) (Eq. (3.33)), the AzizSalman potential uses
an exponential distance dependence for repulsion, and it includes all the dis￾persion coefficients. The contribution of the dispersion term is regulated by a
damping term (Eq. (4.20)). It is evident that the Aziz-Salman potential also
conforms to the general form given by Eq. (4.14). An accurate potential has
been proposed for helium (Tang et al., 1995) that uses elements of this
approach.
Although the empirical two-body potentials have arguably been super￾seded (see discussion below) by ab initio potentials, they remain useful for
contemporary molecular simulation applications. For example, the BFW
potential has been applied to vaporliquid equilibria (VLE) (Marcelli and
Sadus, 1999; Sadus, 2019), solidliquid equilibria (SLE) (Wang and
Sadus, 2006), and thermodynamic properties (Vlasiuk and Sadus, 2017b).
4.2.2 Ab initio potentials
Early ab initio potentials have been reviewed elsewhere (Klein, 1984;
Rowlinson, 2002). Woon (1993) used fourth-order MøllerPlesset (MP4) ab
initio calculations to determine the intermolecular forces between two argon
atoms. McLean et al. (1988) also reported ab initio calculations for the inter￾action between argon atoms. Woon (1993) fitted ab initio results to the fol￾lowing Morse-type potential
uðrÞ 5 εQexp 2
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
ðQ 1 1Þke
Qε
s
ðr 2 reÞ
" # 2 εðQ 1 1Þexp 2
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
Qke
ðQ 1 1Þε
s
ðr 2 reÞ
" #;
ð4:21Þ
where ε the depth of the potential well, re is the equilibrium separation, ke is
the force constant, and Q is a weighting constant. Ermakova et al. (1995)
used Eq. (4.21) in a molecular dynamics study of liquid argon. They con￾cluded that the potential predicted many thermodynamic and transport
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 125properties accurately but many-body interactions were required to improve
the predictions of pressure, internal energy, and enthalpy.
Eggenberger et al. (1994) used ab initio calculations to obtain the follow￾ing potential for the interactions between neon atoms:
uðrÞ 5 a1exp½ 2 a2ðr=a0Þ
2
 1 a3exp½ 2 a4ðr=a0Þ
2

1 a5exp½ 2 a6ðr=a0Þ
2
 1 a7ðr=a0Þ
210 1 a8ðr=a0Þ
28 1 a7ðr=a0Þ
26 ; ð4:22Þ
where a0 is the Bohr radius and the remaining parameters do not have any phys￾ical meaning. Eggenberger et al. (1994) demonstrated that Eq. (4.22) could be
used to predict many of the properties of neon with reasonable accuracy. It is
interesting to compare the functional similarity of Eq. (4.22) with accurate
empirical potentials such as those proposed by Barker et al. (Eq. (4.15)) and
Aziz and Salman (Eq. (4.19)). All of these potentials have an exponential term
and contributions from r
26
, r
28
, and r
210 intermolecular separations.
Ab initio potentials are typically determined by fitting the first principles
data to a suitable equation. The general form of many of these relationships is
u2ðrÞ 5 γexpð Þ fðrÞ 2 X
8
n53
g2nðτrÞ
C2n
r2n ; ð4:23Þ
where λ and τ are the most commonly simple constants, although γ could
also be a function of r. Eqs. (4.23) and (4.15) share a high degree of mathe￾matical similarity. This is perhaps not surprising because both the experi￾mental data fitted to Eq. (4.15) and the ab initio data fitted to Eq. (4.23)
represent two-body interactions. Therefore, we would expect the optimal
strategy used to accurately fit the data from either to be broadly similar
(Deiters et al., 1999; Nasrabad et al., 2004).
The g2n(x) contribution in Eq. (4.23) is a damping function for the disper￾sion coefficients. Contemporary two-body potentials almost invariably use
the TangToennies term (Tang and Toennies, 1984) given by:
g2nðxÞ 5 1 2 e2x
X
2n
k50
xk
k! ð4:24Þ
The use of Eq. (4.24) in Eq. (4.23) introduces a nested summation into
the evaluation of the potential energy, which is computationally expensive in
a molecular simulation. This is particularly the case in MD, which also
requires the derivative of the potential to evaluate the force.
Ab initio data and accurate two-body potentials for helium (Hellmann
et al., 2007), neon (Hellmann et al., 2008a), argon (Ja¨ger et al., 2009;
Patkowski and Szalewicz, 2010), krypton (Ja¨ger et al., 2016), and xenon
(Hellmann et al., 2017) are available. The ab initio data for most of these
cases are illustrated in Fig. 4.2. The nature of some of these potentials, which
all use the TangToennies term, are summarized in Table 4.1. The poten￾tials have been applied to the molecular simulation prediction of
126 Molecular Simulation of Fluids–300
–200
–100
0
100
200
300
0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
u/k (K)
r (nm)
Ne
Ar
Kr
Xe
FIGURE 4.2 Comparison of potential energies for neon ( ), argon ( ), krypton ( ), and
xenon ( ) obtained from ab initio calculations (see text for sources). The lines through the data
points are only for guidance.
TABLE 4.1 Comparison of the contribution of different terms to the two￾body ab initio noble gas potentials obtained from Eq. (4.23) and using
Eq. (4.24).
Atom γ τ f(r)
Heliuma A b a1r 1 a2r2 1 a21r21 1 a22r22 1 d1sinðd2r 1 d3Þ
Neonb A b a1r 1 a2r2 1 a21r21 1 a22r22
Argonc A b a1r 1 a2r2 1 a21r21 1 a22r22
Argond a 1 b0
r 1 cr21 1 dr2 1 er3 b 2α
Kryptone A b a1r 1 a2r2 1 a21r21
Xenonf A b a1r 1 a2r2 1 a21r21 1 a22r22
a
Hellmann et al., 2007. b
Hellmann et al., 2008a. c
Ja¨ger et al., 2009. d
Patkowski and Szalewicz, 2010. e
Ja¨ger et al., 2016. f
Hellmann et al., 2017.
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 127thermodynamic properties (Vlasiuk and Sadus, 2017b) and VLE (Vlasiuk
and Sadus, 2017a; Deiters and Sadus, 2019a).
In addition to the various parameters summarized in Table 4.1, Eq. (4.23)
also requires five values of C2n. This means that the accurate determination
of a two-body potential from ab initio data is a major exercise in parameter
fitting. This is also the case for empirical two-body potentials. It is apparent
from Fig. 4.2 that the ab initio data are not uniformly distributed over
the full range of separations. In particular, there are relatively few data in the
vicinity of the energy minimum and the data points, and there are very large
differences in energy at small separations. There is arguably a danger of
overfitting to such limited data, resulting in a potential that reflects unrecog￾nized errors in the data. This issue is not widely appreciated in the literature.
It is apparent from Fig. 4.2 that the magnitude of the minimum in the potential
well increases with the size of the noble gas atom. The magnitudes (ε/k) for neon
(41.19 K), argon (142.223 K), krypton (200.875 K), and xenon (279.98 K) are
considerably larger than values of 34.91 K, 119.8 K, 164.0 K, and 222.2 K,
respectively, typically assigned to the LJ potential (Maitland et al., 1981). As dis￾cussed in Chapter 3, the discrepancy can be at least partly attributed to the fact
that the LJ potential does not exclusively reflect the influence of two-body interac￾tion. Multi-body effects generally make a positive contribution to interaction
energy resulting in a smaller potential well than two-body interactions alone.
The complexity of ab initio two-body potentials is a serious computa￾tional impediment to their usefulness in molecular simulation, particularly in
comparison with the effective intermolecular potentials examined in
Chapter 3 that can be easily evaluated. This impediment has been addressed
by Deiters and Sadus (2019a), via the introduction of the simplified ab initio
atomic potential (SAAP). The SAAP is given by:
u2ðrÞ 5
a0
r
 exp a1r 1 a6r2   1 a2expð Þ a3r 1 a4
1 1 a5r6 : ð4:25Þ
In contrast to other ab initio potential for the noble gas, the SAAP has at
most six parameters and more commonly five parameters because a6 5 0 for
most cases (Deiters and Sadus, 2019a). Values of the SAAP parameters are
summarized in Table 4.2. The values for helium in Table 4.2 reflect updated
ab initio data (Deiters and Sadus, 2020) that was not available when the
potential was initially parameterized (Deiters and Sadus, 2019a).
Apart from a reduced number of parameter terms, a computational advan￾tage of the SAAP is that the ab initio data can be accurately reproduced without
using the TangToennies term (Eq. (4.24)). The ability of the SAAP and a mul￾tiparameter (Hellmann et al., 2017) potential using Eq. (4.23) to reproduce the
ab initio data of xenon is compared in Fig. 4.3. In general, the SAAP reproduces
the ab initio data to an accuracy of 6 0.5% with a noticeable divergence in
accuracy for r # 0.4 nm corresponding to repulsive behavior.
128 Molecular Simulation of FluidsTABLE 4.2 Summary of the two-body SAAP parameters (Deiters and Sadus, 2019a, 2020).
He Ne Ar Kr Xe
ε /k (K) 11.06271073 42.36165080 143.4899372 201.0821392 280.1837503
σ (nm) 0.2638439772 0.2759124561 0.3355134529 0.357999364 0.3901195551
a0=εσ 73625.983757 211781.8544 65214.64725 60249.13228 44977.3164
a1σ 29.672069031 210.89769496 29.452343340 29.456080572 29.121814449
a2=ε 211.1831994 220.94225988 219.42488828 224.40996013 229.63636182
a3σ 21.785403435 22.317079421 21.958381959 22.182279261 22.278991444
a4=ε 22.764109154 21.854049559 22.379111084 21.959180470 21.876430370
a5=σ6 1.003480097 0.7454617542 1.051490962 0.874092399 0.8701531593
a6=σ2 00000The SAAP has proved useful in the accurate evaluation of both VLE
(Deiters and Sadus, 2019b) and SLE (Deiters and Sadus, 2021, 2022a,b; Singh
et al., 2021) properties. It can also be parameterized (Deiters and Sadus, 2023)
to yield accurate predictions of some properties of molecular hydrogen.
4.3 Three-body atomic potentials
The two-body potentials considered earlier are rarely useful by themselves for the
accurate prediction of the properties of real substances. In principle, to fully con￾sider many-body interactions we must consider all possible n-body interactions.
However, in practice the contribution from interactions other than molecular pairs
and triplets is likely to be extremely small. Further, the contributions from four￾or more-body interactions are of alternating sign and, therefore, there is likely to
be a high degree of cancellation of terms. Consequently, including only two-body
and three-body interactions is probably an excellent approximation for many-body
interactions. It should be noted, however, that including three-body effects greatly
increases the required computational cost. For a three-body calculation involving
N atoms there are N(N  1)(N  2)/6 distinct interactions compared with only N
(N  2)/2 interactions for a pairwise calculation.
Adopting a potential-based approach for many-body interactions requires
the formulation of a suitable intermolecular potential for three-body interac￾tions. In contrast to the large literature on two-body potentials, the subject of
three-body or more-body potentials has received relatively little attention.
-0.01
-0.005
0
0.005
0.01
0.015
0.02
0.025
0.03
0.2 0.3 0.4 0.5 0.6 0.7 0.8
(upot - uabo)/uabo
r (nm)
FIGURE 4.3 The relative differences between the energies calculated from the multiparameter
potentials (circles) (Hellmann et al., 2017; Table 4.1) and the SAAP (solid line) and ab initio
data of xenon. No actual discontinuity should be inferred from the apparent break in the line.
130 Molecular Simulation of FluidsMost work reported in the literature has focused on three-body dispersion
interactions as calculated by Axilrod and Teller (1943) and Mut ¯o (1943).
However, three-body repulsion is also likely to be significant in some cases.
In multipolar fluids, we must also consider the influence of three-body
effects on interactions involving permanent dipoles. Very little work has
been reported, which addresses either three-body repulsion or three-body
effects for polar molecules. The effect of three-body interactions has been
reviewed elsewhere (Elrod and Saykally, 1994; Gray et al., 2011).
4.3.1 Three-body dispersion
Various contributions to three-body dispersion interactions can be envisaged
arising from instantaneous dipole (D), quadrupole (Q), octupole (O), and
hexadecapole (H) moments of a triplet of atoms (see Fig. 4.4).
Different types of interaction are possible depending on the distribution
of multipole moments between the atoms. In principle, the dispersion or
long-range, nonadditive three-body interaction is the sum of these various
combinations of multipole moments (Bell, 1970).
u32body
disp 5 uDDD 1 uDDQ 1 uDQQ 1 uDDO 1 uDDD4 1 uQQQ 1 uDQO 1 uDDH 1 ::
ð4:26Þ
These terms are all third-order with the exception of the contribution of
the fourth-order triple-dipole term (uDDD4). The main contribution to
FIGURE 4.4 Calculation of the third virial coefficient (C) of krypton using additive ( ); addi￾tive 1 triple-dipole ( ); and additive 1 triple-dipole 1 other third-order multipolar ( ) terms
(Barker et al., 1972b).
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 131attractive three-body interaction is the third-order triple-dipole term (uDDD).
The other terms collectively (uDDQ 1 uDQQ, 1 uDDO, 1 uDDD4 1 ...) are
the higher multipole contributions.
4.3.2 The triple-dipole term and the AxilrodTellerMuto¯
potential
The triple-dipole potential can be evaluated from the formula proposed by
Axilrod and Teller (1943) and Mut ¯o (1943):
uDDDðijkÞ 5 vDDDðijkÞ 1 1 3cosθi cosθj cosθk
 
rijrikrjk  3 ; ð4:27Þ
where vDDD(ijk) is the nonadditive coefficient, and the angles and intermo￾lecular separations refer to the triangular configuration of atoms as illustrated
in Fig. 4.5. We will refer to Eq. (4.27) as the AxilrodTellerMut ¯o (ATM)
potential. A detailed derivation of the ATM potential from third-order pertur￾bation theory has been given by Axilrod (1951). Mut ¯o’s original 1943 paper
in Japanese also provides a derivation that appears to have a sign error in
equation 15. The ATM potential can be conveniently expressed without the
cosine terms:
uDDDðijkÞ 5
vDDDðijkÞ rijrjkrik  2
1 3 rikUrjk   rikUrij   rijUrjk    
rijrjkrik  5 : ð4:28Þ
FIGURE 4.5 Triplet configuration of atoms I, j, and k in Eq. (4.25).
132 Molecular Simulation of FluidsThe contribution of the ATM potential can be either negative or positive
depending on the orientation adopted by the three atoms. The potential is posi￾tive for an acute triangular arrangement of atoms, whereas it is negative for near
linear geometries. The potential can be expected to make an overall repulsive
contribution in a close-packed solid and in the liquid phase. The r
23 terms indi￾cate that the magnitude of the potential is very dependent on intermolecular sep￾aration. The major contribution to the potential will occur for configurations in
which at least one pair of atoms is in close proximity to each other.
The nonadditive coefficient (vDDD(ijk)) can be calculated approximately
from the C6 dispersion coefficient and polarizability data (α) via the follow￾ing relationship:
vDDDðijkÞ  3C6α
4 : ð4:29Þ
Alternatively, the relationship proposed by Tang (1969) can be used
vDDDðijkÞ  2SiSjSkðSi 1 Sj 1 SkÞ
ðSi 1 SjÞðSj 1 SkÞðSk 1 SiÞ
; ð4:30Þ
where
Si 5 C6;iαjαk
αi
ð4:31Þ
However, the preferred option is to obtain vDDD directly from experimental
data. This can be achieved by analyzing dipole oscillator strength distributions.
Leonard and Barker (1975) have reported experimental values of the nonaddi￾tive coefficient for the noble gases and mixtures of noble gases. Experimental
values of v have also been reported by Kumar and Meath (1984, 1985). An
analysis using updated theoretical procedures has also been reported (Kumar
and Thakkar, 2010). Values of vDDD for all of the atomic triplets containing a
stable noble gas atom are given in Table 4.3, which compares historical experi￾mental values to contemporary theoretical analysis. It is noteworthy that the con￾temporary theoretical values are in very good agreement with the experimental
values of early decades.
The ATM potential was initially studied by several workers (Bobetic and
Barker, 1970; Barker et al., 1971; Haile, 1978; Hoheisel, 1981; Monson
et al., 1983; Rittger, 1990a,b,c; Attard, 1992; Smit et al., 1992; Miyano,
1994). It appeared that the ATM interactions typically contribute 5% to the
energy of the liquid. This conclusion was also supported by additional
Monte Carlo (MC) results (Sadus and Prausnitz, 1996). Most of the calcula￾tions relied on some type of approximation rather than a rigorous evaluation.
The question that remained unresolved is: What effect does this relatively
small contribution have on the properties of the fluids?
The advent of greater computational capability has enabled the full evalu￾ation of the ATM potential (Anta et al., 1997; Sadus, 1998a,b; Marcelli and
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 133TABLE 4.3 Comparison of vDDD(ijk) valuesa obtained from the historical
analysis of experimental datab and contemporary theory.c
Atom i Atom j Atom k vDDD(ijk) (a.u.)
(experiment)
vDDD(ijk) (a.u.)
(theory)
He He He 1.481
He He Ne 2.296
He He Ar 10.25
He He Kr 14.55
He He Xe 21.89
He Ar Ar 5.95
He Ne Ar 20.33
He Ne Kr 28.80
He Ne Xe 43.27
He Ar Ar 72.24
He Ar Kr 103.3
He Ar Xe 156.4
He Kr Kr 148.2
He Kr Xe 224.9
He Xe Xe 342.4
Ne Ne Ne 12.02 11.92
Ne Ne Ar 40.49 40.41
Ne Ne Kr 57.20 57.48
Ne Ne Xe 85.79 85.11
Ne Ar Ar 142.5 142.7
Ne Ar Kr 203.4 204.8
Ne Ar Xe 307.5 306.6
Ne Kr Kr 291.2 294.6
Ne Kr Xe 441.5 442.6
Ne Xe Xe 671.4 667.9
Ar Ar Ar 517.4 519.0
Ar Ar Kr 744.6 750.2
Ar Ar Xe 1134 1134
(Continued)
134 Molecular Simulation of FluidsSadus, 1999; Wang and Sadus, 2006; Vlasiuk and Sadus, 2017a). Molecular
simulation studies of VLE (Marcelli and Sadus, 1999; Vlasiuk and Sadus,
2017a) have reported that three-body interactions can alter significantly the
coexisting density of the liquid phase, whereas the vapor-phase branch is
unaffected. The ATM interactions also significantly influence SLE (Wang
and Sadus, 2006; Deiters and Sadus, 2021). These influences are much larger
than the 5% of total potential energy would intuitively suggest. The clear les￾son is that the contribution to potential energy of three-body interactions per
se is not necessarily a good indicator of the importance of the effect of
three-body interactions on shaping the macroscopic properties of the fluid.
4.3.3 Density-dependent effective three-body potential
Although the ATM potential is an accurate representation of three-body
interactions, the computational expense of calculating the interactions of all
possible triplets remains far from a routine undertaking. As discussed in
Chapter 3, most simulation codes are exclusively confined to the evaluation
of pair interactions. Therefore, it is highly desirable to have a means of
incorporating three-body interactions via pairwise interactions only. By com￾paring the energy obtained from the ATM potential (UATM) to the two-body
contribution (UBFW) of BFW potential of argon, krypton, and xenon,
Marcelli and Sadus (2000) observed the following density (ρ 5 N/V; N is the
number of atoms; V is the volume)-dependent empirical relationship:
UATM 5 2 λνDDDρUBFW
εσ6 ; ð4:32Þ
TABLE 4.3 (Continued)
Atom i Atom j Atom k vDDD(ijk) (a.u.)
(experiment)
vDDD(ijk) (a.u.)
(theory)
Ar Kr Kr 1074 1087
Ar Kr Xe 1640 1647
Ar Xe Xe 2509 2505
Kr Kr Kr 1554 1577
Kr Kr Xe 2377 2397
Kr Xe Xe 3646 3656
Xe Xe Xe 5605 5595
a
1 a.u. 5 1.41825 3 10292 J cm9
. b
Leonard and Barker, 1975. c
Kumar and Thakkar, 2010.
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 135where ε is the depth of the two-body potential well; σ is the distance at
which the two-body energy is zero; and λ is a constant required to optimally
fit the simulation data. Originally its value was assigned as 2/3 but a later
study (Wang and Sadus, 2006), using a larger number of atoms, indicated
that λ 5 0.85 was a better choice.
A theoretical rationale (Ustinov, 2010) for this relationship has been
given, and it appears to be independent (Vlasiuk and Sadus, 2017a,b; Deiters
and Sadus, 2019b) of the choice of the two-body potential. Therefore, in gen￾eral, we have
U3  UATM 5 2 λνDDDρ
εσ6
X
i
X
j . i
u2ðri;rjÞ; ð4:33Þ
which can be utilized for any two-body potential for which ε and σ have
been determined. Eq. (4.33) means that the overall intermolecular potential
for the fluid is simply:
u 5 u2 1 2 λνDDDρ
εσ6

 : ð4:34Þ
The usefulness of Eq. (4.34), which is denoted as the
MarcelliWangSadus (MWS) potential, is discussed in greater detail
below as part of the case study.
4.3.4 Multipolar contributions beyond the triple-dipole term
Bell (1970) has derived the other multipolar nonadditive third-order poten￾tials that contribute to Eq. (4.26),
uDDQðijkÞ 5 3vDDQðijkÞ
16r3
ijðrjkrikÞ
4 3
9cosθk 2 25cos3θk 1 6cosðθi 2 θjÞð3 1 5cos2θkÞ  
ð4:35Þ
uDQQðijkÞ 5 15vDQQðijkÞ
64r5
jkðrijrikÞ
4 3
3ðcosθi 1 5cos3θiÞ 1 20cosðθj 2 θkÞð1 2 3cos2θiÞ
1 70cos2ðθj 2 θkÞcosθi
 	 ð4:36Þ
uQQQðijkÞ 5 15vQQQðijkÞ
128ðrijrikrjkÞ
5 3
2 27 1 220cosθi cosθj cosθk 1 490cos2θi cos2θj cos2θk
1 175½cos2ðθi 2 θjÞ 1 cos2ðθj 2 θkÞ 1 cos2ðθk 2 θiÞ  	 ; ð4:37Þ
where Eqs. (4.35)(4.37) represent the effect of dipoledipolequadrupole,
dipolequadrupolequadrupole, and quadrupolequadrupolequadrupole
136 Molecular Simulation of Fluidsinteractions, respectively. The derivation of these formulas uses third-order
perturbation theory (Bell and Zucker, 1976). Formulas for the different
ordering of the multipole moments on the three atoms (i.e., QDD, DQD,
QDQ, and QQD) can be generated from Eq. (4.36) by cyclic permutation of
θi, θj, and θk. It should be noted that Eq. (4.34) disagrees with an earlier deri￾vation for dipoledipolequadrupole interactions reported by Ayres and
Tredgold (1956). In addition to these terms, the dipoledipoleoctupole
term has also been evaluated (Doran and Zucker, 1971).
uDDOðijkÞ 5 45vDDOðijkÞ
64
3
1 1 cos2θi
ðrijrikÞ
6 1
1 1 cos2θj
ðrijrjkÞ
6 1
1 1 cos2θk
ðrikrjkÞ
6
" # ð4:38Þ
Bell (1970) proposed that the multipolar nonadditive coefficients could
be related to the triple-dipole nonadditive coefficient via the relationships,
vDDQðijkÞ  γvDDDðijkÞ
vDQQðijkÞ  γ2vDDDðijkÞ
vQQQðijkÞ  γ3vDDDðijkÞ
)
; ð4:39Þ
where γ is the ratio of the dipole polarizability and the quadrupole
polarizability.
γ 5 αQQQ
αDDD
ð4:40Þ
The fourth-order triple-dipole term can be evaluated from the relationship
(Johnson and Spurling, 1974),
uDDD4ðijkÞ 5 vDDD4ðijkÞ 1 1 cos2θi
ðrikrjkÞ
6 1
1 1 cos2θj
ðrijrikÞ
6 1
1 1 cos2θk
ðrijrjkÞ
6
" #; ð4:41Þ
where
vDDD4ðijkÞ 5 2 5α2C6
24 ð4:42Þ
A discussion of dipoledipole contributions to dispersion is available
(Bade, 1957a,b; Bade, 1958).
How significant is the contribution of the higher multipolar terms in com￾parison to the triple-dipole potential? The other, higher multipole terms are
generally believed to be small by comparison. Fig. 4.6 illustrates the contri￾bution of additive and nonadditive terms to the calculated third virial coeffi￾cient for krypton reported by Barker et al. (1972b).
It is apparent from Fig. 4.5 that the triple-dipole term has a significant
effect, whereas the contributions from other third-order multipolar terms are
small. There is also evidence that the higher multipole terms compensate for
each other (Barker et al., 1974). For example, Etters and Danilowicz (1979)
reported that the third-order (uDDQ) and fourth-order (uDDD4) terms for rare
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 137gases at equilibrium separations are typically 20% of the triple-dipole term.
Furthermore, the sign of the fourth-order triple-dipole term is negative,
which effectively cancels the positive contribution of the third-order uDDQ,
uDQQ, and uQQQ terms. Barker et al. (1972a) calculated the contribution of
the fourth-order triple-dipole term to the crystalline energy of noble gases
and compared their results with the contribution of other higher multipole
moments reported by Doran and Zucker (1971). These data are summarized
in Table 4.4, which shows that the fourth-order triple-dipole contribution
-0.1
-0.05
0
0.05
0.1
0.15
0.2
0.82 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98
U/
kT/
FIGURE 4.6 Contribution of DDD ( ), DDQ ( ), DQQ ( ), QQQ ( ), and DDD4 ( )
interactions (Marcelli and Sadus, 1999) to the total three-body energy along the liquid saturation
curve of xenon. The sum (DDD 1 DDQ 1 DQQ 1 QQQ 1 DDD4) of the contributions is also
illustrated ( 3 ), which coincides closely with the DDD values.
TABLE 4.4 Contribution of three-body interactions to the crystalline
energy of noble gases.a
U(J/mol)
Atom DDD DDQ DQQ QQQ DDD4
Ne 62.4 15.5 2.7 0.2 24.8
Ar 579.6 173.8 37.0 3.5 2126.7
Kr 1004.0 220.1 34.3 2.4 2281.4
Xe 1597.9 373.6 62.0 4.6 2636.6
a
Doran and Zucker, 1971; Barker et al., 1972a.
138 Molecular Simulation of Fluidscancels to a large extent the contribution of the other higher multipole terms.
For xenon, the magnitude of the fourth-order term is significantly larger than
the combined contributions of the other higher multipole terms. The reported
contributions from octupoles and fourth- and higher-order energy perturba￾tions are small (Meath and Aziz, 1984).
In addition to the theoretical evaluations detailed previously for the crys￾talline energy of the noble gases, the contributions of the multipolar nonaddi￾tive potentials have also been evaluated (Marcelli and Sadus, 1999) via
molecular simulation for the vapor and liquid phases of the noble gases. The
various contributions to the total three-body energy of xenon along the liquid
saturation curve are illustrated in Fig. 4.6. It is apparent that DDD makes the
largest overall contribution followed by DDQ. Both DQQ and QQQ are close
to zero, whereas DDD4 is negative. In contrast, the DQQ contribution in
the crystalline phase (Table 4.4) is considerably much more substantial.
However, irrespective of the nature of the phase (crystalline, vapor, or liq￾uid), the negative value of DDD4 cancels the contributions of DDQ, DQQ,
and QQQ. Therefore, the leading, triple-dipole DDD term alone is a good
approximation for three-body dispersion interaction. This an important con￾clusion because it means that the calculation of three-body interactions can
be limited to the ATM potential.
The substantial negative contribution to the energy of DDD4 interactions
is very important in establishing the primary role of ATM potential.
Commentaries in the simulation literature, which sometimes suggest that the
ATM underpredicts three-body interactions, typically neglect this counter￾vailing contribution. This is perhaps not surprising as comprehensive simula￾tions involving DDD4 are possibly confined to a single study (Marcelli and
Sadus, 1999). Adding either the higher multipolar terms or other contribu￾tions the ATM potential without the counteracting DDD4 term would lead to
the erroneous conclusion that three-body contribution to the energy is
larger than it should be. However, legitimate sources of uncertainty are the
calculations of the nonadditive coefficients. Accurate values of νDDD are
available for the noble gases (Table 4.2), but this is not the case for both
other terms and other atoms.
A molecular dynamics technique has been reported (van der Hoef and
Madden, 1998) that accounts for the contribution of both two- and three￾body dispersion interactions up to the triple-quadrupole (QQQ) term.
4.3.5 Three-body repulsion
The effect of three-body repulsion has not been studied as extensively as
three-body dispersion interactions. Consequently, a rigorous potential for
three-body repulsion potential has not been developed. Sherwood et al.
(1966) investigated the effect of three-body interactions on the virial coeffi￾cients. In particular, they developed models of repulsion between three
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 139atoms. Their electrostatic distortion model is particularly convenient for
molecular simulation:
urepðijkÞ 5 4εσ21
9
cos2θi
ðrijrikÞ
9
r3
jk
1
cos2θj
ðrijrjkÞ
9
r3
ik
1
cos2θk
ðrikrjkÞ
9
r3
ij " #; ð4:43Þ
where ε and σ are the parameters for the LJ potential, and the angles and
intermolecular separation refer to Fig. 4.5. The use of the LJ potential means
that Eq. (4.41) should only be considered as an approximation. The sign of
the potential depends on the geometry of the three atoms. If the atoms form
an equilateral or right-angle triangle, the potential is negative, whereas it is
positive for a linear configuration. Thus, the sign of the repulsive potential is
opposite to the ATM potential. Consequently, the effect of repulsion will be
to partially cancel the effect of the triple-dipole term.
Three-body repulsion can also be calculated from the following
relationship:
urepðijkÞ 5 v expð2 γijrij 2 γikrik 2 γjkrjkÞ; ð4:44Þ
where the γ constants characterize the interactions between the different
pairs of atoms. Lybrand and Kollman (1985) have used this potential to cal￾culate the overlap of ionwaterwater trimers. It should be noted that the
theoretical basis of the three-body repulsion is considerably less well devel￾oped than three-body dispersion. The derivation of both the above repulsion
potentials is less rigorous than the three-body dispersion potentials.
Nonetheless, these potentials can be used to provide a useful approximation
of three-body repulsion.
4.3.6 Three-body dispersion versus three-body repulsion
As outlined previously in the discussion of three-body dispersion interac￾tions, for practical purposes, three-body dispersion interactions can be mod￾eled exclusively using the triple-dipole term. What is the role of three-body
repulsion? The answer to this question is complicated by uncertainties in the
two-body potential and various approximations used in the calculation of
three-body interaction.
Early work (Rosen, 1953; Jansen, 1962) indicated that three-body repul￾sion made a negative contribution. Later, Williams et al. (1967) observed
that three-body overlap was positive and contributed 10% of the
AxilrodTeller term. Similarly, O’Shea and Meath (1974, 1976) reported
that the effect of charge overlap reduced the impact of the AxilrodTeller
term by between 15% and 40%. Calculations of the third virial coefficient
(Graben and Present, 1962; Dymond et al., 1965; Barker et al., 1972b) indi￾cate that including the AxilrodTeller term improved substantially the
agreement of theory with experiment. Sherwood and Prausnitz (1964)
140 Molecular Simulation of Fluidsreported that the virial coefficient of helium was influenced by three-body
repulsion. In general, calculations using a pair potential 1 ATM term alone
have predicted successfully many experimental properties. For example, the
crystal-binding energies of noble gases are predicted satisfactorily when
the pairwise potential is supplemented by the ATM term. Ab initio calcula￾tions for the nonadditive forces for helium (Bulski, 1975; Wells and Wilson,
1985), neon (Bulski and Chałasinski, 1980; Wells and Wilson, 1986 ´ ) and
argon (Bulski and Chałasinski, 1982; Wells, 1987 ´ ) indicate that the ATM
term was offset largely by three-body repulsion.
The relative importance of repulsion for noble gases using the ATM
potential and Eq. (4.40) is illustrated in Fig. 4.7. The energies of the intermo￾lecular potentials were calculated for equidistant atoms arranged in either a
linear or a triangular configuration. The vDDD values were taken from
Leonard and Barker (1975) (Table 4.3), and the LJ parameters required for
Eq. (4.42) were taken from Hirschfelder et al. (1954). Fig. 4.8 shows that
repulsion completely dominates the ATM term at small interatomic separa￾tions. For argon, krypton, and xenon, the dominance of repulsion commences
at a similar interatomic separation, whereas for both helium and neon, repul￾sion is important at considerably larger distances. A comparison of Fig. 4.7
(a) with Fig. 4.7 (b) indicates that for a given interatomic separation, repul￾sion is more important in an equilateral configuration compared with a linear
geometry. These results need to be considered with the caveat that Eq. (4.42)
is a relatively crude approximation and as such may require future reassess￾ment using a more accurate model of repulsion.
MC estimates are available (Sadus and Prausnitz, 1996) for the contribution
of three-body repulsion as calculated from Eq. (4.43) and ATM interactions to
the configurational energy of liquid argon for several densities. The results are
compared in Fig. 4.8. The magnitudes of both ATM and repulsive interactions
increase synchronously with increasing density. Three-body repulsion makes a
negative contribution to the energy, which is approximately 45% of the contri￾bution of the ATM term. Therefore, the effect of three-body repulsion is to off￾set substantially the effect of three-body dispersion interactions. However, a
confounding aspect of the analysis given in Fig. 4.9 is the use of the LJ potential
for pairwise interactions instead of a genuine two-body potential. This means
that the relative contribution of ATM interactions may not be accurately repre￾sented. This, in turn, may be counterbalanced by the fact that Eq. (4.43) was
derived specifically for the LJ potential.
Schwerdtfeger and Hermann (2009) have proposed an empirical modifi￾cation of the ATM potential to combine dispersion and repulsion:
u3ðijkÞ 5 1 1 3 cos θi cos θj cos θk
  νEATM
rijrikrjk  3 1 e2αð Þ rij1rik1rjk Xn
i50
A2i rijrikrjk  2i=3
" #;
ð4:45Þ
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 141where n is typically equal to 5; the terms in Eq. (4.45) are usually treated as
adjustable parameters that are fitted to data. We would normally expect that
νEATM 5 νDDD; however, using fitting procedures for the parameters means
that this is not necessarily the case. For example, although there is good agree￾ment (Smits et al., 2020) for krypton (νEATM 5 1506 a.u; νDDD 5 1554 a.u.),
the value obtained for xenon (νEATM 5 3471 a.u; νDDD 5 5605 a.u.) is much
smaller than expected (Smits et al., 2020).
This extended ATM (EATM) potential has the advantage that it provides
a continuous transition between repulsion and dispersion at separations corre￾sponding to atomic overlap. This transition also occurs at considerably
FIGURE 4.7 The ratio of repulsion to triple-dipole interactions as a function of distance for
equidistant noble gas atom triplets arranged in (a) linear and (b) triangular configurations.
142 Molecular Simulation of Fluidssmaller separation than alternative models (Ermakova et al., 1998; Freiman
and Tretyak, 2007). The potential has proved useful for third virial coeffi￾cients (Ja¨ger et al., 2016) and the SLE of the noble gases (Smits et al.,
2020). However, there appears to be no difference (Vlasiuk and Sadus,
2017b) between the ATM and EATM calculations for the isochoric heat
capacities of krypton along the liquid saturation curve.
In summary, the relative importance of three-body repulsion and three￾body dispersion remains unresolved. There is some evidence (Figs. 4.7 and
4.8) that the ATM term could be canceled by three-body repulsion.
However, as will be discussed subsequently, comparison with experimental
properties indicates that three-body repulsion is not required to gain a good
representation of macroscopic properties such as VLE. Our knowledge of
three-body dispersion is superior to three-body repulsion and better theoreti￾cal techniques, and experimental data are required to resolve the issue. These
issues have been discussed extensively by Elrod and Saykally (1994).
4.4 Four- and higher-body atomic interactions
As noted previously, the literature on many-body interactions is confined
almost exclusively to three-body interactions. The work of Johnson and
Spurling (1974) is a rare example of the theoretical investigation of four￾body interaction. Johnson and Spurling (1974) investigated the effect of
-0.1
-0.05
0
0.05
0.1
0.15
0.2
0.61 0.63 0.65 0.67 0.69 0.71
U/
ATM
3-body repulsion
FIGURE 4.8 Comparison of the contributions of ATM (K Sadus, 1998c) and three-body
repulsion (Eq. (4.40)) interactions ( , Sadus and Prausnitz, 1996) to the energy of argon at satu￾rated liquid densities.
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 143four-body interactions on the fourth virial coefficient using the following
intermolecular potential (Bade, 1958),
uðijklÞ 5 vðijklÞ½  fðijklÞ 1 fðijklÞ 1 fðikjlÞ ; ð4:46Þ
where:
fðijklÞ 5 1
ðrijrjkrklrliÞ
3 3
2 1 1 ðuijUujkÞ
2 1 ðuijUuklÞ
2 1 ðuijUuliÞ
2 1 ðujkUuklÞ
2 1 ðuklUuliÞ
2
2 3ðuijUujkÞðujkUuklÞðuklUuliÞ 2 3ðuijUujkÞðujkUuklÞðuliUuijÞ
2 3ðuijUuklÞðuklUuliÞðuliUuijÞ 2 3ðujkUuklUuliÞðuliUujkÞ
1 9ðuijUujkÞðujkUuklÞðuklUuliÞðuliUuijÞ
2
6
6
4
3
7
7
5
ð4:47Þ
and where uij is the unit vector in the direction of particle i to particle j.
Johnson and Spurling (1974) demonstrated that four-body interactions made
an important contribution to the fourth virial coefficients at low to moderate
temperatures.
4.5 Potentials for molecules
In common with the development of molecular force fields discussed in
Chapter 3, the starting point for either two- or three-body potentials for
molecules is a suitable model that captures the required molecular features
such as the distribution of the constituent arrangement of atoms, bond
lengths, bond angles, and the like. This modeling procedure is common to
the development of a two- or three-body molecular potential, irrespective of
whether the interatomic potentials are empirical, theoretical, or ab initio. The
discussion given subsequently will focus primarily on two-body ab initio
potentials.
It is likely that many-body interactions play a greater role in molecular
fluids than in atomic fluids because induction interactions, which are not
pairwise additive, are possible in nonspherically symmetric molecules. In
view of the results obtained for atoms, we can reasonably expect three-body
interactions to make the most important contribution to many-body interac￾tions. Similarly, it is likely that the third-order triple-dipole potential will
make the most important contribution to three-body dispersion interaction
between molecules.
4.5.1 Two-body ab initio molecular potentials
The construction of a two-body potential for molecules follows the same
general procedure as for pairwise force fields detailed in Chapter 3: (a) pro￾pose a molecular framework and identify interaction sites (N); (b) apply the
two-body atomic potential to the interaction sites between molecular dimers;
144 Molecular Simulation of Fluidsand (c) add an angle-dependent (θ, Φ, see Figure 3.8) contribution. In gen￾eral, this means:
u2ðr; θn; φmÞ 5 X
N
i51
X
N
j51
uij rijðr; θn; φmÞ   ð4:48Þ
4.5.1.1 Diatomic molecules
Apart from molecular hydrogen, which includes quantum considerations
(Deiters and Sadus, 2023), the simplest molecular systems are diatomic
molecules such as N2, F2, Cl2, and the like, which have the same constituent
atoms. These cases only involve quadrupole moments (Harrison, 2005) in
addition to dispersion and repulsion. The contribution of two-body interac￾tions in ab initio potentials for diatomic molecules can often be generalized
by relationships of the type,
uij 5 urep
ij 2 X
M
i50
f612iðxÞ
C612i
r612i
ij
1 gðxÞ
qiqj
rij
; ð4:49Þ
which combines contributions from repulsion (rep), dispersion coeffi￾cients, and charges (q); and f(x) and g(x) are damping functions in terms
of an appropriate distance contribution (x). In Eq. (4.47), the charges are
chosen to represent the effect of the quadrupole moment of the dimer via
the Coulomb potential (Eq. (3.51)). For example, the Leonhard and
Deiters (LD) (2002) proposed a five-site (N 5 5) potential for nitrogen,
which conforms to the previously discussed relationship when M 5 0, and
the repulsion is obtained from a modified Morse-type potential. The five￾site potential for nitrogen reported by Hellmann (2013) also uses M 5 0,
with f(x) obtained from Eq. (4.22), g(x) 5 1, and urep
ij 5 Aije2αijrij , where
A and α are adjustable parameters. Both the LD and Hellmann potentials
involved CCSD(T) calculations, yielding good agreement with experiment
for a range of thermodynamic properties.
The previously discussed principles can be easily adapted for hetero￾geneous diatomic molecules such as CO, NO, and so forth. In these cases,
the influence of molecular diploes (Zakharov et al., 2005) is reflected in
the choice of charges. The alternative to assigning charges is to specify
values for the dipole and other multiple moments as exemplified
by Eqs. (3.52)(3.56). However, this alternative (Sadus, 1996) is not
widely used. It is of interest to note that the contribution of repulsion
used in Eq. (4.48) is mathematically simpler than the contribution used
for atoms (Eq. 4.23, Table 4.1).
4.5.1.2 Triatomic molecules
Triatomic molecules are by definition heterogeneous and can be either
linear or nonlinear with carbon dioxide and water being notable examples
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 145of the former and latter, respectively. Ab initio two-body potentials for
carbon dioxide have been developed via the supermolecular/MP2 method
(Bock et al., 2000; Oakley and Wheatley, 2009) and symmetry-adapted
perturbation theory (SAPT) (Bukowski et al., 1999; Wang et al., 2012).
Good agreement with experiment for second virial coefficient viscosities
and thermal conductivities of carbon dioxide in the dilute gas limit has
been reported (Hellmann, 2014) using a potential based on CCSD(T) level
of theory. Despite involving three atoms, the functional form of the
potential is identical to the diatomic case Eq. (4.49) with the number of
interaction sites increased to seven.
The attempt to determine an accurate ab initio intermolecular potential
for water is a good example of the use of ab initio calculations for a nonlin￾ear triatomic molecules. The intermolecular potential of water is compli￾cated by the significant influence exerted by polarizability, many-body
effects, molecular flexibility, and quantum corrections. Generally, ab initio
two-body potentials for water do not predict accurately thermodynamic
properties for a wide range of conditions. A review of ab initio potentials
for water has been reported by Shvab and Sadus (2016), and our discussion
will be restricted to a few examples that highlight key attributes of the
modeling approach.
The potential reported by Niesar et al. (1990) (NCC) builds on the four￾site model (see Figure 3.11) proposed by Matsuoka, Clementi, and
Yoshimine (MCY) (1976), which is the common backbone of many water
potentials. The NCC potential uses partial charges on the hydrogen atoms
and a compensating negative charge on a site located along the bisector of
the HOH angle.
uðrÞ 5 q2 1
r13
1
1
r14
1
1
r23
1
1
r24
0
@
1
A 1
4q2
r78
2 2q2 1
r81
1
1
r82
1
1
r73
1
1
r74
0
@
1
A
1 AOO expð2 BOOr56Þ 1 AHH expð2 B4
HHr13r14r23r24Þ
1 AOH expð2 B4
OHr53r54r61r62Þ 1 A0
OH expð2 B0
HH4r53r54r61r62Þ
1 APH expð2 B4
PHr73r74r81r82Þ 1 APO expðB2
POr76r85Þ
ð4:50Þ
The NCC potential considers interaction between two water molecules;
the oxygens are labeled 5 and 6; labels 1, 2, 4, and 8 denote the hydrogens
associated with oxygen 5 and 6, respectively. The positions 7 and 8 are for
the negative charge associated with each oxygen and q is the charge on each
hydrogen (Fig. 4.9). The NCC potential predicts correctly the equilibrium
water dimer in the gas phase, and the predicted binding energy is in good
agreement with experiment. It also provides accurate predictions for the sec￾ond virial coefficient, heat capacity, and diffusion coefficient at room tem￾perature. However, the predicted pressure is too low and the predicted
configurational energy is too high by 7%.
146 Molecular Simulation of FluidsBukowski et al. (2007) performed first principles calculations for water
and obtained a potential that utilized a five-site monomer model (Mas et al.,
2000) for water plus a polarization contribution. The functional form of the
potential used by Mas et al. (2000) is identical to Eq. (4.49). The quality of
predictions obtained from ab initio potentials for the thermodynamic proper￾ties of water are of moderate accuracy. This is in contrast to empirical poten￾tial that often yield very good agreement with experiment (Chapter 3).
However, the contribution from ab initio terms can be augmented to improve
the overall accuracy (Li et al., 2007, 2008).
4.5.1.3 Polyatomic molecules
Polyatomic molecules represent a challenge to ab initio calculations because of
the increase in both the number of atoms and the complexity of the molecular
geometry. For example, the tetrahedral geometry of methane means that there
are seventeen different angular orientations between the molecular pairs
(Hellmann et al., 2008b). Nonetheless, a potential for methane can be obtained
(Hellmann et al., 2008b) from the ab initio data via Eqs. (4.48) and (4.49) with
M 5 1 and N 5 9. The same approach has been used successfully for ethylene
oxide (M 5 1 N 5 19) (Crusius et al., 2014) and propane (M 5 1 N 5 14)
(Hellmann, 2017b). In common with other ab initio potentials, these potentials
have only been evaluated for the second virial coefficients and/or dilute gas ther￾modynamic properties.
4.5.2 Three-body molecular potentials
The triple-dipole potential for nonspherical molecules depends on both posi￾tion and molecular orientation. Stogryn (1970) generalized the
FIGURE 4.9 Illustration of the dimer geometry showing the interatomic separations common
to many four-site models of water.
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 147AxilrodTeller potential for nonspherical molecules. The result is
uDDDðαβγÞ 5 vDDD
3αααβαγ
ðTαβÞijðTαγÞklðTβγÞmnðααÞikðαβÞjmðαγÞln  ; ð4:51Þ
where αα is the mean polarizability of molecule α, (αα)ij is the component
of the polarizability tensor of molecule α, and (Tαβ)ij is the ij component of
the interaction tensor between molecules α and β. This tensor is defined by,
ðTαβÞij 5 2 3ðuαβÞiðuαβÞj 2 δij
r3
αβ
; ð4:52Þ
where (uαβ)i is the ith component of a unit vector pointing from molecule α
toward β.
Stogryn (1970) examined the relative contribution of three-body interac￾tion for nonspherical molecules compared with the ATM potential for spheri￾cal symmetry. If the centers of three linear molecules are positioned on a
common axis, two different orientations can be envisaged as illustrated in
Fig. 4.10. In Case 1, the axes of the two end molecules are aligned with the
common axis, whereas in Case 2, the molecular axes are perpendicular to it.
In both cases, the middle molecule can rotate in the plane of the
figure making an angle ω with the common axis. For Case 1,
unon2shperical
uspherical
5 1 1
9
2
κ 2 11
2 κ3 1
3
2
κð3 1 10κ 1 11κ2
Þcos2
ω ð4:53Þ
and for Case 2,
unon2shperical
uspherical
5 1 1
3
2
κ2 2 5
2
κ3 2 9
2
κsin2
ω 2 6κ2
ð1 2 κÞcos2
ω ð4:54Þ
where κ is the anisotropy.
FIGURE 4.10 Two possible orientations of three molecules sharing a common axis.
148 Molecular Simulation of FluidsThe effect of nonsphericity on the three-body interactions of nitrogen
(κ 5 0.266) is illustrated in Fig. 4.11. It is apparent from Fig. 4.11 that the
contribution of three-body interactions between nonspherical molecules can
be considerably greater than for either spherical molecules or atoms. The
ATM potential is negative for atoms arranged in a linear configuration,
whereas Fig. 4.11 indicates that three-body potential for nonspherical mole￾cules is positive in some circumstances.
The analysis of three-body interactions in molecules is complicated by
the absence of accurate molecular pair potentials. Instead of isolating the
effect of two-body interactions in a true two-body potential, “effective”
potentials are used commonly in which many-body effects are incorporated
into the pairwise parameters. Monson et al. (1983) used the ATM potential
in conjunction with the LJ potential to determine configurational internal
energy of chlorine. They concluded that the contribution of triple-dipole
interactions was between 8% and 12% of the pairwise term. This compares
with a value of 5% reported typically for atomic fluids. Latajka and
Scheiner (1988) observed that the three-body contribution for liquid hydro￾gen fluoride was 17.2% of pairwise interactions. Ab initio calculations
(Kofranek et al., 1987) for hydrogen cyanide indicate a 12% contribution
from three-body interactions.
FIGURE 4.11 Relative three-body dispersion energy of linear molecules compared with spher￾ically symmetric molecules. Results are shown for κ 5 0.266, which is the anisotropy associated
with nitrogen (Stogryn, 1970).
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 149McDowell (1996) used third-order perturbation theory to derive a triple￾dipole potential for linear Σ-state molecules. The result is:
uDDDðabcÞ 5 vDDDðabcÞð Þ 1 1 3cosθAcosθB cosθC
ð Þ rabrbcrac 3 3
Re
1 2 ΓðaÞWðθa; φa; θA; θBÞ 2 ΓðbÞWðθb; φb; θA; θBÞ
2 ΓðcÞWðθc; φc; θA; θBÞ
1 Γða; bÞWðθa; φa; θb; φb; θA; θBÞ 1 Γða; cÞWðθa; φa; θc; φb; θA; θBÞ
1 Γðb; cÞWðθb; φb; θc; φc; θA; θBÞ
2 Γða; b; cÞWðθa; φa; θb; φb; θc; φc; θA; θBÞ
2
6
6
6
6
4
3
7
7
7
7
5
ð4:55Þ
The first term on the right-hand side of Eq. (4.55) is the ATM potential for
three linear molecules a, b, c forming internal angles θA, θB, and θC. This is for￾mally identical to the situation depicted in Fig. 4.5 for atoms. The Re[...] term
indicates the real part of [....], the W terms are angular coefficients, and θa and
φa are spherical polar angles describing the orientation of molecule a. The Γ’s
are coefficients that depend on the oscillator strengths/excitation energies of the
allowed dipolar transitions in the constituent molecules.
In addition to the third-order triple term, for nonpolar linear molecules there
is also a second-order nonadditive induction contribution to the long-range energy
(McDowell, 1996; McDowell et al., 1996). Linear molecules can have a quadru￾pole moment that can induce dipole moments in neighboring molecules resulting
in a second-order nonadditive induction energy in molecular trimers that varies
as r
28
. McDowell (1996) investigated the effect of this second-order nonadditive
correction for trimers of hydrogen molecules. Unlike the ATM potential, which
typically makes a negative contribution, the second-order nonadditive term makes
a positive contribution to the energy of interaction. Furthermore, for most orienta￾tions, the second-order nonadditive induction energy is comparable in magnitude
or larger than the triple-dipole dispersion energy.
The effect of many-body interactions has been investigated extensively
for water (Elrod and Saykally, 1994). The influence on the structure and
properties of water of three-body interactions is considerably greater than is
observed in atomic systems. HartreeFock calculations (Kistenmacher et al.,
1974) show that three-body interactions contribute 10% of pairwise interac￾tions for cyclic water trimers and tetramers. The main contribution to many￾body interactions can be attributed to orbital deformation as modeled by
classical polarization (Clementi and Corongiu, 1983). Kim et al. (1986)
reported MC simulations using an intermolecular potential containing up to
four-body interactions for the minimum energy structures of (H2O)n clusters.
They concluded that three- and four-body terms made an important contribu￾tion when n . 5. Ab initio calculations of the cyclic water tetramer (Koehler
et al., 1987) indicate that three-body interactions contribute 18% of pair
interactions to the stabilization of the structure.
150 Molecular Simulation of FluidsAn ab initio potential for carbon dioxide has been proposed (Hellmann,
2017a), which involves using the ATM potential coupled with contributions
from induction and exchange effects. Although the ATM potential is strictly
only valid for atomic interactions, it can be applied to molecules by using it
as a sitesite potential for the constituent atoms of a molecules. The
sitesite approach has proved useful in incorporating three-body interactions
into a model for water (Li et al., 2007, 2008).
4.5.3 Ab initio potentials for combinations of molecules
In Chapter 3, it was observed that both intermolecular pair potentials and force
fields have been almost exclusively developed for pure component and that
combining rules (Sadus, 1992; Hasalm et al., 2008) need to be used to apply the
potentials to systems containing molecules of dissimilar components, that is, a
mixture. Some efforts (Klein, 1984) have been made to obtain mixed two-body
potentials from experimental data. However, the limitation of this approach is
that experimental data invariably contain both like and dissimilar interactions,
which are difficult to separate from each other. In contrast, it is possible to
determine the interactions between nonidentical atoms and molecules from first
principles and use the data to obtain an ab initio potential for the dissimilar
interactions. This would be particularly useful in molecular simulation of mix￾tures by enabling completely a prior prediction without the need for combining
rules or unlike adjustable parameters. Despite this, the development of ab initio
potentials has been overwhelmingly focused on pure component properties.
Combined potentials for dissimilar noble gas atoms have been reported
(Haley and Cybulski, 2003; Cacheiro et al., 2004; Ja¨ger and Bich, 2017). Ab
initio data for dissimilar molecules are relatively scarce and largely confined
to either CH4, CO2, or H2O as one of the components. Examples include H2S
+ H2O (Hellmann, 2023), SO2 + H2O (Hellmann, 2023), CO2 1 H2O
(Hellmann, 2019), CO2 1 CH4 (Hellmann et al., 2016), CO2 1 H2S
(Hellmann et al., 2016), CH4 1 H2S (Hellmann et al., 2016), and CH4 1 N2
(Hellmann et al., 2014). Obtaining the intermolecular potential for the mixed
pair follows the same procedure that is used for identical pairs via a simple
modification to Eq. (4.48).
u2ðr; θn; φmÞ 5 X
Nα
i51
X
Nβ
j51
uij rijðr; θn; φmÞ   ð4:56Þ
Nα and Nβ are the number of interaction sites on molecule α and β,
respectively, with the pair interaction energy obtained from Eq. (4.49).
Performing this analysis means that any parameters required by Eq. (4.49)
reflect the mixed interaction. The combined potential allows the direct evalu￾ation of the mixed virial coefficient.
As noted previously, the number of ab initio three-body potentials is lim￾ited to a few examples and no three-body mixture potential has been
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 151reported. It this case, there is usually no alternative to combining rules. In a
binary mixture, it has been observed (Sadus, 1996) that the nonadditive coef￾ficient required for the ATM potential can be obtained by taking a geometric
average of the like interactions.
vααβ 5 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
vαααvαααvβββ p3
vββα 5 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
vβββvβββvααα p3
)
ð4:57Þ
4.6 Case study: Augmenting ab initio potentials for fluid
properties
Although some three-body ab initio potentials have been developed for a limited
set of circumstances, the current state-of-the-art is limited to two-body potentials.
As documented above, advances in computational chemistry have been utilized to
determine high accurate two-body interaction, which undoubtedly genuinely
reflect the contribution of pair interaction. However, the scope of useful applica￾tion of these two-body potentials is largely limited to the properties of dilute
gases. It is appropriate to utilize two-body potentials more broadly because two￾body interactions dominate the interactions of nonpolar molecules. This can be
achieved by augmenting the two-body ab initio potentials (u2
ab) with contribution
that are not available from first principles,
u 5 uab
2 1 X
N
i
unon2ab
i ; ð4:58Þ
where unon-ab represents any contributions that involves neither two-body
interactions nor contributions from ab initio data.
4.6.1 Systematic improvement of water potentials
The large number of empirical potentials for water was discussed in
Chapter 3. Although some of the empirical potentials for water (Shvab and
Sadus, 2016) have resulted in considerable improvement in accuracy, this
has not been achieved via a systematic approach. It is often the case that the
high degree of parameterization required to achieve optimal results at a given
state point means reduced accuracy at other conditions. In the spirit of
Eq. (4.58), Li et al. (2007) identified contributions from three-body interac￾tions (u3) and polarization (up).
u 5 uab
2 1 u3 1 upol ð4:59Þ
In Eq. (4.59), u2
ab was obtained from the four-site MCY potential (similar
to Eq. (4.50)), which alone cannot be used to accurately represent the proper￾ties of real water. This deficiency is rectified by the other nonadditive (na)
terms, and the new potential is designated as MCYna. The contribution of
152 Molecular Simulation of Fluidsthree-body interactions was modeled via the ATM potential, interacting via
only oxygen triplets.
The contribution from polarization (Gray and Gubbins, 1984) interactions
was obtained from,
upol 5 2 1
2
X
N
i51
μind
i UEo
i ; ð4:60Þ
where E0 is the electrostatic field of surrounding charges and μind is the
induced dipole at site i given by:
μind
i 5 αβUEi 5 αβU Eo
i 1 X
N
j51;j6¼i
Tijμind
j
" #: ð4:61Þ
In Eq. (4.61), αβ is the polarizability and Tij element of the dipole tensor
given by:
Tij 5 1
4πεor5
ij
3rijr
0
ij 2 r
2
ij h i: ð4:62Þ
For the MCYna potential, a value of β 5 0.557503 is used to reproduce
the dipole moment of liquid water.
The MCYna potential yields a good representation of the dielectric con￾stant of both pure water (Shvab and Sadus, 2013) and its mixtures (Shvab
and Sadus, 2014); and thermodynamic properties (Yigzawe and Sadus,
2013a,b) such as heat capacities (Cv, Cp), compressibilities (βT, βS), thermal
pressure coefficients (γV), expansion coefficient (αp), the speed of sound
(w0), and the JouleThomson coefficient (μJT) over a wide range of tem￾peratures and pressures. A partial comparison with experiment and empirical
intermolecular potentials discussed in Chapter 3 is given in Table 4.5. The
comparison indicates that the MCYna gives superior agreement with experi￾ment than the other potentials. This can be attributed to the addition of non￾additive effects, most notably polarization. Perhaps more importantly, it
highlights the effectiveness of the augmentation process, which has expanded
the scope of the MCY potential form dilute gas to liquid phase properties.
4.6.2 Efficient three-body calculations
The MWS potential (Eq. 4.34) is a straightforward example of augmentation
of a two-body potential. It was originally developed (Marcelli and Sadus,
2000) in conjunction with the empirical BFW potential, yielding calculations
that were in very good agreement with the ATM potential. Subsequently
(Vlasiuk et al., 2016; Vlasiuk and Sadus, 2017a,b), it has been proved useful
when used in conjunction with ab initio potentials.
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 153TABLE 4.5 Comparison of experiment data with predictions from
different intermolecular potentials.a
Property Expt MCYna SPC/E TIP4P TIP4P/2005
CV (J/molK) 74.44 74.4 79.3 82.1 81.8
Cp (J/molK) 75.312 74.6 80.4 89.0 82.6
βT (GPa21
) 0.458 0.448 0.476 0.590 0.497
βS (GPa21
) 0.425 0.446 0.470 0.544 0.492
γV (MPa/K) 0.436 0.383 0.731 0.746 0.618
αp (1024
/K) 2.00 2.63 3.48 4.4 3.08
μJT (K/MPa) 20.222 20.230 20.201 20.187 20.194
w0 (m/s) 1496.7 1498.4 1460.1 1357.4 1427.2
a
Shvab and Sadus, 2016.
0
0.4
0.8
1.2
1.6
0.0065 0.007 0.0075 0.008 0.0085 0.009
loge p ( [ MPa)]
1/T (K-1)
FIGURE 4.12 Comparison of experimental vapor pressures of argon (solid line) with predic￾tions of the SAAP ( ) and the three-body augmented SAAP (x) (Deiters and Sadus, 2019b).
154 Molecular Simulation of FluidsThe SAAP provides a computationally efficient way of calculating two￾body interactions in a molecular simulation. However, in common with other
two-body potentials its usefulness is largely restricted to the dilute properties
of gases. This is illustrated in Fig. 4.12, which compares the vapor pressures
of argon predicted by the SAAP alone and the MWS three-body augmenta￾tion of the SAAP (Deiters and Sadus, 2019b). It is apparent from this com￾parison that the SAAP considerably underestimates the vapor pressures over
the entire pressure range. The three-body augmentation results in much
closer agreement with experiment. Although the agreement with experiment
remains imperfect, the calculation is a genuine prediction that has expanded
the usefulness of the SAAP. A similar conclusion can be reached for other
thermodynamic properties (Deiters and Sadus, 2020, 2021).
4.7 Summary
Historically, intermolecular potentials have been empirically determined,
whereas the advent of recent advances in computational chemistry means
that potentials can be determined from first principles or ab initio data. This
has resulted in some highly accurate two-body potentials for both atomic sys￾tems and some small molecules. Although two-body potentials accurately
represent the properties of dilute gases, the prediction of the properties of
liquids require the contributions from multi-body interactions. However, the
combination of two-body plus three-body interactions is often sufficient to
obtain accurate results for the thermodynamic properties of real molecules.
The computational expense of three-body calculation can often be
avoided by a simple density-dependent representation of the ATM that can
be added to the two-body potential. This straightforward augmentation
means that the use of accurate ab initio two-body potentials is not confined
to the properties of dilute gases. That is, they can be usefully employed to
determine the properties of real substances in the dense fluid region.
References
Anta, J.A., Lomba, E., Lombardero, M., 1997. Influence of three-body forces on the gas-liquid
coexistence of simple fluids: the phase equilibrium of argon. Phys. Rev. E 55, 27072712.
Attard, P., 1992. Simulation for a fluid with the Axilrod-Teller triple dipole potential. Phys. Rev.
A 45, 56495653.
Axilrod, B.M., 1951. Triple-dipole interaction. I. Theory. J. Chem. Phys. 19, 719729.
Axilrod, B.M., Teller, E., 1943. Interaction of the van der Waals’ type between three atoms.
J. Chem. Phys. 11, 299300.
Ayres, R.U., Tredgold, R.H., 1956. On the crystal structure of the rare gases. Proc. Phys. Soc.
69, 840842.
Aziz, R.A., Slaman, M.J., 1986. The argon and krypton interatomic potentials revisited. Mol.
Phys. 58, 679697.
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 155Bade, W.L., 1957a. Drude-model calculation of dispersion forces. I. General theory. J. Chem.
Phys. 27, 12801284.
Bade, W.L., 1957b. Drude-model calculation of dispersion forces. II. The linear lattice. J. Chem.
Phys. 27, 12841288.
Bade, W.L., 1958. Drude-model calculation of dispersion forces. III. The fourth-order contribu￾tion. J. Chem. Phys. 28, 282284.
Barker, J.A., Pompe, A., 1968. Atomic interactions in argon. Aust. J. Chem. 21, 16831694.
Barker, J.A., Fisher, R.A., Watts, R.O., 1971. Liquid argon: Monte Carlo and molecular dynam￾ics calculations. Mol. Phys. 21, 657673.
Barker, J.A., Johnson, C.H.J., Spurling, T.H., 1972a. On the cancellation of certain three- and
four-body interactions in inert gases. Aust. J. Chem. 25, 18111812.
Barker, J.A., Johnson, C.H.J., Spurling, T.H., 1972b. Third virial coefficients for krypton. Aust.
J. Chem. 25, 18131814.
Barker, J.A., Watts, R.O., Lee, J.K., Schafer, T.P., Lee, Y.T., 1974. Interatomic potentials for
krypton and xenon. J. Chem. Phys. 61, 30813088.
Bartlett, R.J., 1981. Many-body perturbation theory and coupled cluster theory for electron cor￾relation in molecules. Ann. Rev. Phys. Chem. 32, 359401.
Bell, R.J., 1970. Multipolar expansion for the non-additive third-order interaction energy of three
atoms. J. Phys. B 3, 751762.
Bell, R.J., Zucker, I.J., 1976. In: Klein, M.L., Venables, J.A. (Eds.), Rare Gas Solids, Vol. 1.
Academic Press, London.
Bobetic, M.V., Barker, J.A., 1970. Lattice dynamics with three-body forces: argon. Phys. Rev.
B. 2, 41694175.
Bock, S., Bich, E., Vogel, E., 2000. A new intermolecular potential energy surface for carbon
dioxide from ab initio calculations. Chem. Phys. 257, 147156.
Born, M., Mayer, J.E., 1932. Zur Gittertheorie der Ionenkristalle. Z. Phys. 75, 118.
Bretonnet, J.-L., 2017. Basics of the density functional theory. AIMS Mat. Sci. 4, 13721405.
Bukowski, R., Sadlej, J., Jeziorski, B., Jankowski, P., Szalewicz, K., Kucharski, S.A., Williams,
H.L., Rice, B.M., 1999. Intermolecular potential of carbon dioxide dimer from symmetry￾adapted perturbation theory. J. Chem. Phys. 110, 37853803.
Bukowski, R., Szalewicz, K., Groenenboom, G.C., van der Avoird, A., 2007. Predictions of the
properties of water from first principles. Science 315, 12491252.
Bulski, M., 1975. On the exchange repulsion between beryllium atoms. Mol. Phys. 29,
11711179.
Bulski, M., Chałasinski, G., 1980. Many-orbital cluster expansion for the exchange-repulsion ´
nonadditivity in the interaction of rare gas atoms. The neon trimer. Theor. Chim. Acta 56,
199210.
Bulski, M., Chałasinski, G., 1982. On exchange-repulsion non-additivity in the interaction of ´
three argon atoms. Chem. Phys. Lett. 89, 450453.
Cacheiro, J.L., Fernandez, B., Marchesan, D., Coriani, S., Ha ´ ¨ttig, C., Rizzo, A., 2004. Coupled
cluster calculations of the ground state potential and interaction induced electric properties
of the mixed dimers of helium, neon and argon. Mol. Phys. 102, 101110.
Car, R., Parrinello, M., 1985. Unified approach for molecular dynamics and density-functional
theory. Phys. Rev. Lett. 55, 24712474.
Clementi, E., Corongiu, G., 1983. Monte Carlo study of liquid water with two- and three-body
ab initio potentials. Int. J. Quant. Chem. Quant. Bio. Symp. 10, 3141.
Cohen, A.J., Mori-Sanchez, P., Yang, W.T., 2012. Challenges for density functional theory.
Chem. Rev. 112, 289320.
156 Molecular Simulation of FluidsCrusius, J.P., Hellmann, R., Hassel, E., Bich, E., 2014. Intermolecular potential energy surface
and thermophysical properties of ethylene oxide. J. Chem. Phys. 141, 164322. Publisher’s
note: J. Chem. Phys. 141, 189902 (2014).
Deiters, U.K., Sadus, R.J., 2019a. Two-body interatomic potentials for He, Ne, Ar, Kr, and Xe
from ab initio data, J. Chem. Phys., 150. p. 134504.
Deiters, U.K., Sadus, R.J., 2019b. Fully a priori prediction of the vapor-liquid equilibria of Ar,
Kr, and Xe from ab initio two-body plus three-body interatomic potentials. J. Chem. Phys.
151, 034509.
Deiters, U.K., Sadus, R.J., 2020. Ab Initio interatomic potentials and the classical molecular sim￾ulation prediction of the thermophysical properties of helium. J. Phys. Chem. B 124,
22682276.
Deiters, U.K., Sadus, R.J., 2021. Interatomic interactions responsible for the solid-liquid and
vapor-liquid phase equilibria of neon. J. Phys. Chem. B 125, 85228531.
Deiters, U.K., Sadus, R.J., 2022a. First-principles determination of the solid-liquid-vapor triple
point: the noble gases. Phys. Rev. E. 105, 054128 (2022).
Deiters, U.K., Sadus, R.J., 2022b. Accurate determination of solid-liquid equilibria by molecular
simulation: behavior of Ne, Ar, Kr, and Xe from low to high pressures. J. Chem. Phys. 157,
204504 (2022).
Deiters, U.K, Sadus, R.J., 2023. An intermolecular potential for hydrogen: classical molecular
simulation of pressure-denisty-temperature behavior, vapor-liquid equilibria, critical and tri￾ple point properties. J. Chem. Phys. 158, 194502.
Deiters, U.K., Hloucha, M., Leonhard, K., 1999. Experiments?  No, thank you!. In: Letcher, T.
M. (Ed.), Chemistry for the 21st Century: Chemical Thermodynamics. Blackwell Science,
Oxford, pp. 187195.
del Berne, J.E., Person, W.B., Szczepaniak, K., 1995. Properties of hydrogen-bonded complexes
obtained from the B3LYP functional with 631 G(d,p) and 631 1 G(d,p) basis sets. J.
Phys. Chem. 99, 1070510707.
Doran, M.B., Zucker, I.J., 1971. Higher order multipole three-body van der Waals interactions
and stability of rare gas solids. J. Phys. C. 4, 307312.
Dymond, J.H., Rigby, M., Smith, E.B., 1965. Intermolecular potential-energy function for simple
molecules. J. Chem. Phys. 42, 28012806.
Eggenberger, R., Gerber, S., Huber, H., Welker, M., 1994. A new ab initio potential for the neon
dimer and its application in molecular dynamics simulations of the condensed phase. Mol.
Phys. 82, 689699.
Elrod, M.J., Saykally, R.J., 1994. Many-body effects in intermolecular forces. Chem. Rev. 94,
19751997.
Ermakova, E., Solca, J., Huber, H., Welker, M., 1995. Argon in condensed phase: quantitative
calculations of structural, thermodynamic, and transport properties from pure theory.
J. Chem. Phys. 102, 49424951.
Ermakova, E., Solca, J., Steinebrunner, G., Huber, H., 1998. Ab initio calculation of a three￾body potential to be applied in simulations of fluid neon. Chem. Eur. J. 4, 377382.
Etters, R.D., Danilowicz, R., 1979. Three-body interactions in small rare-gas clusters. J. Chem.
Phys. 71, 47674768.
Frank, I., 2020. Some simple facts about water: CPMD simulation. Mol. Phys. 118 (21), 16.
Freiman, Y.A., Tretyak, S.M., 2007. Many-body interactions and high-pressure equations of state
in rare-gas solids. Low. Temp. Phys. 33, 545552.
Friesner, R.A., 1991. New methods for electronic structure calculations on large molecules. Ann.
Rev. Phys. Chem. 42, 341367.
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 157Goddard III, W.A., Harding, L.B., 1978. The description of chemical bonding from ab initio cal￾culations. Ann. Rev. Phys. Chem. 29, 363396.
Graben, H.W., Present, R.D., 1962. Evidence for three-body forces from third virial coefficients.
Phys. Rev. Lett. 9, 247248.
Gray, C.G., Gubbins, K.E., 1984. Theory of Molecular Fluids, Vol. 1: Fundamentals. Clarendon
Press, Oxford.
Gray, C.G., Gubbins, K.E. Joslin, C.G., 2011. Theory of Molecular Fluids. Vol. 2: Applications,
Oxford University Press, Oxford.
Haile, J.M., 1978. Molecular dynamics simulation of simple fluids with three-body interactions
included. ACS Symp. Ser. 86, 172191.
Haley, T.P., Cybulski, S.M., 2003. Ground state potential energy curves for He-Kr, Ne-Kr, Ar￾Kr and Kr2: coupled-cluster calculations and comparison with experiment. J. Chem. Phys.
119, 54875496.
Harrison, J.F., 2005. On the representation of molecular quadrupole moments in terms of atomic
moments. J. Phys. Chem. A 109, 54925497.
Hasalm, A.J., Galindo, A., Jackson, G., 2008. Prediction of binary intermolecular potential para￾meters for use in modeling fluid mixtures. Fluid Phase Equilib 266, 105128.
Hellmann, R., 2013. Ab initio potential energy surface for the nitrogen molecule pair and ther￾mophysical properties of nitrogen gas. Mol. Phys. 111, 387401.
Hellmann, R., 2014. Ab initio potential energy surface for the carbon dioxide molecule pair and
thermophysical properties of dilute carbon dioxide gas. Chem. Phys. Lett. 613, 133138.
Hellmann, R., 2017a. Nonadditive three-body potentials and third to eighth virial coefficients of
carbon dioxide. J. Chem. Phys. 146, 054302.
Hellmann, R., 2017b. Intermolecular potential energy surface and thermophysical properties of
propane. J. Chem. Phys. 146, 114304.
Hellmann, R., 2019. Cross second virial coefficient and dilute gas transport properties of the
(H2O 1 CO2) system from first-principles calculations. Fluid Phase Equilib. 485, 252263.
Erratum: Fluid Phase Equilib. 518, 112624 (2020).
Hellmann, R., 2023. Cross second virial coefficients of the H2O-H2S and H2O-SO2 systems from
first principles. J. Chem. Eng. Data 68, 108117.
Hellmann, R., Bich, E., Vogel, E., 2007. Ab initio potential energy curve for the helium atom
pair and thermophysical properties of dilute helium gas. I. Heliumhelium interatomic
potential. Mol. Phys. 105, 30133023.
Hellmann, R., Bich, E., Vogel, E., 2008a. Ab initio potential energy curve for the neon atom pair
and thermophysical properties of the dilute neon gas. I. Neonneon interatomic potential
and rovibrational spectra. Mol. Phys. 106, 133140.
Hellmann, R., Bich, E., Vogel, E., 2008b. Ab initio intermolecular potential energy surface and
second pressure virial coefficients of methane. J. Chem. Phys. 128, 214303.
Hellmann, R., Bich, E., Vogel, E., Vesovic, V., 2014. Intermolecular potential energy surface
and thermophysical properties of the CH4-N2 system. J. Chem. Phys. 141, 224301.
Hellmann, R., Bich, E., Vesovic, V., 2016. Cross second virial coefficients and dilute gas trans￾port properties of the (CH4 1 CO2), (CH4 1 H2S) and (H2S 1 CO2) systems from accurate
intermolecular potential energy surfaces. J. Chem. Thermodyn. 102, 429441.
Hellmann, R., Ja¨jer, B., Bich, E., 2017. State-of-the-art ab initio potential energy curve for the xenon
atom pair and related spectroscopic and thermophysical properties. J. Chem. Phys. 147, 034304.
Hellmann, R., Gaiser, C., Fellmuth, B., Vasyltsova, T., Bich, S., 2021. Thermophysical proper￾ties of low-density neon gas from highly accurate first-principles calculations and dielectric￾constant gas thermometry measurements. J. Chem. Phys. 154, 164304.
158 Molecular Simulation of FluidsHirschfelder, J.O., Curtiss, C.F., Bird, R.B., 1954. Molecular Theory of Gases and Liquids. John
Wiley & Sons, New York.
Hofbauer, F., Frank, I., 2012. CPMD simulation of a bimolecular chemical reaction:
Nucleophilic attack of a disulfide bond under mechanical stress. Chem. Eur. J. 18,
1632216338.
Hoheisel, C., 1981. Effect of three-body forces on the static and dynamic correlation functions
of a model liquid. Phys. Rev. A 23, 19982005.
Hohenberg, P., Kohn, W., 1964. Inhomogeneous electron gas. Phys. Rev. B 136, 864871.
Ja¨ger, B., Bich, E., 2017. Thermophysical properties of krypton-helium gas mixtures from ab
initio pair potentials. J. Chem. Phys. 146, 214302.
Ja¨ger, B., Hellmann, R., Bich, E., Vogel, E., 2009. Ab initio pair potential energy curve for
the argon atom pair and thermophysical properties of the dilute argon gas. I.
Argonargon interatomic potential and rovibrational spectra. Mol. Phys. 107,
21812188.
Ja¨ger, B., Hellmann, R., Bich, E., Vogel, E., 2016. State-of-the-art ab initio potential energy
curve for the krypton atom pair and thermophysical properties of dilute krypton gas. J.
Chem. Phys. 144, 11304.
Jansen, L., 1962. Systematic analysis of many-body interactions in molecular solids. Phys. Rev.
125, 17981804.
Johnson, C.H.J., Spurling, T.H., 1974. Non-additivity of intermolecular forces: Effects on the
fourth virial coefficient. Aust. J. Chem. 27, 241247.
Johnson, R.R., Mackie, I.D., DiLabio, G.A., 2009. Dispersion interactions in density-functional
theory. J. Phys. Org. Chem. 22, 11271135.
Kim, K.S., Dupuis, M., Lie, G.C., Clementi, E., 1986. Revisiting small clusters of water mole￾cules. Chem. Phys. Lett. 131, 451456.
Kistenmacher, H., Lie, G.C., Popkie, H., Clementi, E., 1974. Study of the structure of molecular
complexes. VI. Dimers and small clusters of water molecules in the Hartree-Fock
Approximation. J. Chem. Phys. 61, 546561.
Klein, M.L. (Ed.), 1984. Inert Gases: Potentials, Dynamics and Energy Transfer in Doped
Crystals. Springer-Verlag, Berlin.
Klein, M.L., Venables, J.A. (Eds.), 1976. Rare Gas Solids, Vol. 1. Academic Press, London.
Koehler, J.E.H., Sanger, W., Lesyng, B., 1987. Cooperative effects in extended hydrogen bonded
systems involving O-H groups. Ab initio studies of the cyclic S4 water tetramer. J. Comput.
Chem. 8, 10901098.
Kofranek, M., Karpfen, A., Lischka, H., 1987. Ab initio studies on hydrogen-bonded clusters.
I. Linear and cyclic oligomers of hydrogen cyanide. Chem. Phys. 113, 5364.
Kohn, W., Sham, L.J., 1965. Self-consistent equations including exchange and correlation
effects. Phys. Rev. A 140, 11331138.
Kohn, W., Vashista, P., 1983. In: Lundquist, S., March, N.H. (Eds.), Theory of Inhomogeneous
Electron Gas. Plenum, New York.
Kryanko, E.S., Luden˜a, E.V., 2014. Density functional theory: foundations reviewed. Phys. Rep
544, 123239.
Kumar, A., Meath, W.J., 1984. Pseudo-spectral dipole oscillator-strength distributions for SO2,
CS2 and OCS and values of some related dipole-dipole and triple-dipole dispersion energy
constants. Chem. Phys. 91, 411418.
Kumar, A., Meath, W.J., 1985. Pseudo-spectral dipole oscillator strengths and dipole-dipole and
triple-dipole dispersion energy coefficients for HF, HCl, HBr, He, Ne, Ar, Kr and Xe. Mol.
Phys. 54, 823833.
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 159Kumar, A., Thakkar, A.J., 2010. Dipole oscillator strength distributions with improved high￾energy behavior: Dipole sum rules and dispersion coefficients for Ne, Ar, Kr, and Xe revis￾ited. J. Chem. Phys. 132, 074301.
Latajka, Z., Scheiner, S., 1988. Structure, energetics and vibrational spectra of H-bonded sys￾tems. Dimers and trimers of HF and HCl. Chem. Phys. 122, 413430.
Leonard, P.J., Barker, J.A., 1975. In: Eyring, H., Henderson, D. (Eds.), Theoretical Chemistry:
Advances and Perspectives, Vol. 1. Academic Press, London.
Leonhard, K., Deiters, U.K., 2002. Monte Carlo simulations of nitrogen using an ab initio poten￾tial. Mol. Phys. 100, 25712585.
Li, J., Zhou, Z., Sadus, R.J., 2007. Role of nonadditive forces on the structure and properties of
liquid water. J. Chem. Phys. 127, 154509.
Li, J., Zhou, Z., Sadus, R.J., 2008. Parallel algorithms for molecular dynamics with induction
forces. Comput. Phys. Comm. 178, 384392 (2008).
Lybrand, T.P., Kollman, P.A., 1985. Water-water and water-ion potential functions including
terms for many body effects. J. Chem. Phys. 83, 29232933.
Maitland, G.C., Smith, E.B., 1971. The intermolecular potential of argon. Mol. Phys. 22,
861868.
Maitland, G.C., Rigby, M., Smith, E.B., Wakeham, W.A., 1981. Intermolecular Forces: Their
origin and Determination. Clarendon Press, Oxford.
Marcelli, G., Sadus, R.J., 1999. Molecular simulation of the phase behavior of noble gases using
accurate two-body and three-body intermolecular potentials. J. Chem. Phys. 111, 15331540.
Marcelli, G., Sadus, R.J., 2000. A link between the two-body and three-body interaction energies
of fluids from molecular simulation. J. Chem. Phys. 112, 63826385.
March, N.H., 1992. Electron Density Theory of Atoms and Molecules. Academic Press, London.
Marx, D., Hutter, J., 2009. Ab Initio Molecular Dynamics: Basic Theory and Advanced
Methods. Cambridge University Press, Cambridge.
Mas, E.M., Bukowski, R., Szalewicz, K., Groenenboom, G.C.S., Wormer, P.E., van der Avoird,
A., 2000. Water pair potential of near spectroscopic accuracy. I. Analysis of potential sur￾face and virial coefficients. J. Chem. Phys. 113, 66876701.
Matsuoka, O., Clementi, E., Yoshimine, M., 1976. CI study of the water dimer potential surface.
J. Chem. Phys. 64, 13511361.
McDowell, S.A.C., 1996. Nonadditive interactions in the H2 trimer. J. Chem. Phys. 105,
41804184.
McDowell, S.A.C., Kumar, A., Meath, W.J., 1996. On the anisotropy of the triple-dipole disper￾sion energy for interactions involving linear molecules. Mol. Phys. 87, 845858.
McLean, A.D., Liu, B., Barker, J.A., 1988. Ab initio calculation of argon-argon potential.
J. Chem. Phys. 89, 63396347.
Meath, W.J., Aziz, R.A., 1984. On the importance and problems in the construction of many￾body potentials. Mol. Phys. 52, 225243.
Miyano, Y., 1994. An effective triplet potential for argon. Fluid Phase Equilib 95, 3143.
Møller, C., Plesset, M.S., 1934. Note on an approximation treatment for many-electron systems.
Phys. Rev. 46, 618621.
Monson, A.P., Rigby, M., Steele, W.A., 1983. Non-additive energy effects in molecular liquids.
Mol. Phys. 49, 893898.
Mut ¯o, Y., 1943. On the forces acting between nonpolar molecules. J. Phys.-Math. Soc. Jpn. 17,
629631. Available (in Japanese) from: https://doi.org/10.11429/subutsukaishi1927.17.10-
11-12_629 [This paper is most often incorrectly cited in the literature as Muto, Y. (1943).
Proc. Phys. Math. Soc. Japan 17, 629].
160 Molecular Simulation of FluidsNasrabad, A.E., Laghaei, R., Deiters, U.K., 2004. Prediction of the thermophysical properties of
pure neon, pure argon, and the binary mixtures neonargon and argonkrypton by Monte
Carlo simulation using ab initio potentials. J. Chem. Phys. 121, 64236434.
Niesar, U., Corongiu, G., Clementi, E., Keller, G.R., Bhattacharya, D.K., 1990. Molecular
dynamics simulations of liquid water using the NCC ab initio potential. J. Phys. Chem. 94,
79497956.
O’Shea, S.F., Meath, W.J., 1974. Charge-overlap effects in the non-additive triple-dipole interac￾tion. Mol. Phys. 28, 14311439.
O’Shea, S.F., Meath, W.J., 1976. On the validity of the triple-dipole interaction as a representa￾tion of non-additive intermolecular forces. Mol. Phys. 31, 515528.
Oakley, M.T., Wheatley, R.J., 2009. Additive and nonadditive models of vapor-liquid equilib￾rium in CO2 from first principles. J. Chem. Phys. 130, 034110.
Orio, M., Pantazis, D.A., Neese, F., 2009. Density functional theory. Photosyn. Res. 102,
443453.
Parr, R.G., Yang, W., 1990. Density Functional Theory. Springer-Verlag, Berlin.
Parson, J.M., Siska, P.E., Lee, Y.T., 1972. Intermolecular potentials from crossed-beam differen￾tial elastic scattering measurements. IV. Ar 1 Ar. J. Chem. Phys. 56, 15111516.
Patkowski, K., Szalewicz, K., 2010. Argon pair potential at basis set and excitation limits.
J. Chem. Phys. 133, 094304.
Payne, M.C., Teter, M.P., Allan, D.C., 1990. Car-Parrinello methods. J. Chem. Soc. Faraday
Trans. 86, 12211226.
Payne, M.C., Teter, M.P., Allan, D.C., Arias, T.A., Joannopoulos, J.D., 1992. Iterative minimiza￾tion techniques for ab initio total-energy calculations: molecular dynamics and conjugate
gradients. Rev. Mod. Phys. 64, 10451097.
Pe´rez-Jorda, J.M., Becke, A.D., 1995. A density-functional study of van der Waals forces: rare ´
gas diatomics. Chem. Phys. Lett. 233, 134137.
Raghavachari, K., Trucks, G.W., Pople, J.A., Head-Gordon, M., 1989. A fifth-order perturbation
comparison of electron correlations theories. Chem. Phys. Lett. 157, 479.
Rittger, E., 1990a. The chemical potential of liquid xenon by computer simulation. Mol. Phys.
69, 853865.
Rittger, E., 1990b. Can three-atom potentials be determined from thermodynamic data? Mol.
Phys. 69, 867894.
Rittger, E., 1990c. An empirical three-atom potential for xenon. Mol. Phys. 71, 7996.
Rosen, P., 1953. The nonadditivity of the repulsive potential of helium. J. Chem. Phys. 21,
10071012.
Rowlinson, J.S., 2002. Cohesion: A Scientific History of Intermolecular Forces. Cambridge
University Press, Cambridge.
Sadus, R.J., 1992. High Pressure Phase Behaviour of Multicomponent Fluid Mixtures. Elsevier,
Amsterdam.
Sadus, R.J., 1996. Monte Carlo simulation of vapour-liquid equilibria in “Lennard-Jones 1
three-body potential” binary fluid mixtures. Fluid Phase Equilib 116, 289295.
Sadus, R.J., 1998a. Exact calculation of the effect of three-body Axilrod-Teller interactions on
vapour-liquid phase coexistence. Fluid Phase Equilib 144, 351359.
Sadus, R.J., 1998b. The effect of three-body interactions on the liquid-liquid equilibria of binary
fluid mixtures. Fluid Phase Equlib 150, 6372.
Sadus, R.J., 1998c. The effect of three-body interactions between dissimilar molecules on the
phase behaviour of binary mixtures: The transition from vapour-liquid equilibria to type III
behaviour. Ind. Eng. Chem. Res. 37, 29772982.
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 161Sadus, R.J., 2019. Molecular simulation of orthobaric heat capacities near the critical point.
Phys. Rev. E 99, 012139.
Sadus, R.J., Prausnitz, J.M., 1996. Three-body interactions in fluids from molecular simulation:
vapor-liquid phase coexistence of argon. J. Chem. Phys. 104, 47844787.
Sahoo, S.K., Nair, N., 2016. CPMD/GULP QM/MM interface for modeling periodic solids:
implementation and its application in the study of Y-zeolite supported Rhn clusters. J.
Comp. Chem. 37, 16571667.
Sandre´, E., Pasturel, A., 1997. An introduction to ab-initio molecular dynamics schemes. Mol.
Sim. 20, 6377.
Scheiner, S. (Ed.), 1997. Molecular Interactions: From van der Waals to Strongly Bound
Complexes. John Wiley & Sons, Chichester.
Schwerdtfeger, P., Hermann, A., 2009. Equation of state for solid neon from quantum theory.
Phys. Rev. B 80, 064106.
Shepard, R., 1987. The multiconfiguration self-consistent field method. Adv. Chem. Phys. 69,
63200.
Sherwood, A.E., Prausnitz, J.M., 1964. Third virial coefficient for the Kihara, exp-6, and square￾well potentials. J. Chem. Phys. 41, 413428.
Sherwood, A.E., de Rocco, A.G., Mason, E.A., 1966. Nonadditivity of intermolecular forces:
effects on the third virial coefficient. J. Chem. Phys. 44, 29842994.
Shvab, I., Sadus, R.J., 2013. Intermolecular potentials and the accurate predication of the ther￾modynamic properties of water. J. Chem. Phys. 139, 194505.
Shvab, I., Sadus, R.J., 2014. Thermodynamic properties and diffusion of water 1 methane binary
mixtures. J. Chem. Phys. 140, 104505.
Shvab, I., Sadus, R.J., 2016. Atomistic water models: aqueous thermodynamic properties from
ambient to supercritical conditions. Fluid Phase Equilib. 407, 730.
Singh, A.N., Dyre, J.C., Pedersen, U.R., 2021. Solidliquid coexistence of neon, argon, krypton,
and xenon studied by simulations. J. Chem. Phys. 154, 134501.
Smit, B., Hauschild, T., Prausnitz, J.M., 1992. Effect of a density-dependent potential on the
phase behaviour of fluids. Mol. Phys. 77, 10211031.
Smits, O.R., Jerabek, P., Phal, E., Schwerdtfeger, P., 2020. First-principles melting of krypton
and xenon based on many-body relativistic coupled-cluster interaction potentials. Phys. Rev.
B. 101, 104103.
Stogryn, D.E., 1970. Pairwise nonadditive dispersion potential for asymmetric molecules. Phys.
Rev. Lett. 24, 971973.
Stone, A.J., 2013. The Theory of Intermolecular Forces, second ed. Oxford University Press, Oxford.
Sun, L., Deng, W.-Q., 2017. Recent developments of first-principles force fields. WIREs
Comput. Mol. Sci. 7, 115.
Tang, K.T., 1969. Dynamic polarizabilities and van der Waals coefficients. Phys. Rev. 177,
108114.
Tang, K.T., Toennies, J.P., 1984. An improved simple model for the van der Waals potential
based on universal damping functions for the dispersion coefficients. J. Chem. Phys. 80,
37263741.
Tang, K.T., Toennies, J.P., Yiu, C.L., 1995. Accurate analytical He-He van der Waals potential
based on perturbation theory. Phys. Rev. Lett. 74, 15461549.
Trickey, S.B. (Ed.), 1990. Density Functional theory of Many-Fermion Systems. Adv. Quantum
Chem., Vol. 21. Academic Press, San Diego.
Tuckerman, M.E., Parrinello, M., 1994a. Integrating the Car-Parrinello equations. I. Basic inte￾gration techniques. J. Chem. Phys. 101, 13021315.
162 Molecular Simulation of FluidsTuckerman, M.E., Parrinello, M., 1994b. Integrating the Car-Parrinello equations. II. Multiple
time scale techniques. J. Chem. Phys. 101, 13161329.
Tuckerman, M.E., Marx, D., Klein, M.L., Parrinello, M., 1996. Efficient and general algorithms
for path integral Car-Parrinello molecular dynamics. J. Chem. Phys. 104, 55795588.
Ustinov, E.A., 2010. Effect of three-body interactions on Ar adsorption on graphitized carbon
black. J. Chem. Phys. 132, 194703.
van der Hoef, M.A., Madden, P.A., 1998. Novel simulation model for many-body multipole dis￾persion interactions. Mol. Phys. 94, 417433.
Verma, P., Truhlar, D.G., 2020. Status and challenges of density functional theory. Trends Chem
4, 302318.
Vlasiuk, M., Sadus, R.J., 2017a. Predicting vapour-liquid phase equilibria with augmented ab
initio interatomic potentials. J. Chem. Phys. 146, 244504.
Vlasiuk, M., Sadus, R.J., 2017b. Ab Initio interatomic potentials and the thermodynamic proper￾ties of fluids. J. Chem. Phys. 147, 024505.
Vlasiuk, M., Frascoli, F., Sadus, R.J., 2016. Molecular simulation of the thermodynamic, struc￾tural, and vapor-liquid equilibrium properties of neon. J. Chem. Phys. 145, 104501.
Wang, L., Sadus, R.J., 2006. Three-body interactions and solid-liquid Phase equilibria: applica￾tion of a molecular dynamics algorithm. Phys. Rev. E 74, 031203.
Wang, F.-F., Kumar, R., Jordan, K.D., 2012. A distributed point polarizable force field for car￾bon dioxide. Theor. Chem. Acc. 131, 1132.
Wells, B.H., 1987. Van der Waals interaction potentials. Non-additivity in neon and argon lat￾tices. Mol. Phys. 61, 12831293.
Wells, B.H., Wilson, S., 1985. Van der Waals interaction potentials. Many-body effects. Mol.
Phys. 55, 199210.
Wells, B.H., Wilson, S., 1986. Van der Waals interaction potentials. Many-body effects in Ne3.
Mol. Phys. 57, 2132.
Williams, D.R., Schaad, L.J., Murrell, J.N., 1967. Deviations from pairwise additivity in inter￾molecular potentials. J. Chem. Phys. 47, 49164922.
Wilson, M., Madden, P.A., 1994. Anion polarization and the stability of layered structures in
MX2 systems. J. Phys.: Condens. Matter 6, 159170.
Woo, T.K., Margl, P.M., Blo¨chl, P.E., Ziegler, T., 1997. A combined Car-Parrinello QM/MM
implementation for ab initio molecular dynamics simulations of extended systems: applica￾tion to transition metal catalysis. J. Phys. Chem. B 101, 78777880.
Woon, D.E., 1993. Accurate modeling of intermolecular forces: a systematic Møller-Plesset
study of the argon dimer using correlation consistent basis sets. Chem. Phys. Lett. 204,
2935.
Xantheas, S.S., 1995. Ab initio studies of cyclic water clusters (H2O)n, n 5 1-6. III. Comparison
of density functional with MP2 results. J. Chem. Phys. 102, 45054517.
Yigzawe, T.M., Sadus, R.J., 2013a. Thermodynamic properties of liquid water from a polarizable
intermolecular potential. J. Chem. Phys. 138, 044503.
Yigzawe, T.M., Sadus, R.J., 2013b. Intermolecular interactions and the thermodynamic proper￾ties of supercritical fluids. J. Chem. Phys. 138, 194502.
Zakharov, I.I., Anufrienko, V.F., Zakharova, O.I., Yashnik, S.A., Ismaguilov, Z.R., 2005. Ab
Initio calculation of nitogen oxide dimer structure and its anion-radical. J. Struct. Chem. 46,
213219.
Ab initio, two-body and three-body intermolecular potentials Chapter | 4 163This page intentionally left blankChapter 5
Calculating molecular
interactions
Calculating the interaction between molecules is at the heart of either a
Monte Carlo (MC) or a molecular dynamics (MD) simulation program. In a
MC simulation, the configurational energy resulting from the interaction of
each molecule with all other molecules is evaluated. This information is
used to either accept or reject the current configuration. In contrast, a MD
simulation determines the individual forces experienced by each molecule.
The force experienced by the molecule is used to determine new molecular
coordinates in accordance with the equations of motion. In either case, evalu￾ating the effect of molecular interaction is the most computational timecon￾suming step and as such, it governs the order of the overall algorithm.
In principle, for a system of N molecules, the order of the algorithm scales as
Nm
, where m is the number of interactions that are included. Typically, only inter￾actions between pairs of molecules are considered (Chapter 3) resulting in an
algorithm of order N2
. If only the distinguishable interactions are considered, N
(N1)/2 calculations are required for each configuration. This is a large computa￾tional cost because simulations involve routinely several hundred molecules.
However, in practice, the use of computation-saving strategies (detailed below)
can sometimes result in an order N algorithm. In many circumstances there is no
need to re-evaluate all pair interactions to generate new configurations.
The requirement to evaluate forces means that MD algorithms for pairwise
interactions have an intrisinc N2 dependence. In a MC algorithm not involving
either polar or Coulombic interaction, the N2 calculation is typically performed
only once at the start of the simulation to obtain the initial energy of the system.
Subsequent MC moves involve updating the energy via an order N calculation.
However, these MC moves are typically repeated for N cycles, which means the
overall order remains N2
. Many of the computation-saving procedures that are
applied to MD algorithms may also potentially benefit MC simulations, particu￾larly if either nonpolar or Coulombic interactions are involved.
Molecular forces can be characterized (Chapters 3 and 4) as either short￾range or long-range, and different techniques are required to simulate both
types of properties. A long-range force is defined as one that falls off no fas￾ter than r
2d
, where d is the dimensionality of the system. Typically, ionion
165 Molecular Simulation of Fluids. DOI: https://doi.org/10.1016/B978-0-323-85398-9.00014-9
© 2024 Elsevier B.V. All rights reserved.and dipoledipole potentials are proportional to r
21 and r
23
, respectively.
Dispersion and repulsion are examples of short-range forces.
Many computation-saving devices can be employed to calculate short-range
interactions such as periodic boundary conditions and neighbor lists. However,
calculating long-range interaction requires special methods such as the Ewald
sum, reaction field, and particlemesh methods, because the effect of long-range
interaction extends well past half the length of the simulation box.
The purpose of this chapter is to provide an overview of algorithms for molec￾ular interactions. Calculating molecular interactions is an example of the many￾body problem that is common to many branches of science. Considerable progress
has been achieved in developing algorithms for many-body interactions particu￾larly for long-range interactions. Various tree and fast multipole (FMM) algo￾rithms are available, which reduce the computational cost of pairwise interactions
to either O(N ln N) or O(N). Some of these algorithms are not used widely in
molecular simulation programs because several thousand molecules are required
to make the FMM algorithms competitive computationally with conventional sim￾ulation strategies. This is in contrast to their wider use for other applications, such
as cosmology, that also tackle N-body calculations. Nonetheless, on going
improvements to FMM algorithms, particularly parallel implementations, are
likely to lower this efficiency threshold. These developments, when coupled with
an increasing desire to study large number of molecules, is likely to result in a
greater use of such algorithms for molecular simulation. This is particularly the
case for implementations using graphics processing units (Chapter 12).
5.1 Calculation of short-range interactions
5.1.1 Naive energy and force calculations
Let us consider a simple short-range potential, such as the Lennard-Jones
(LJ) potential, which was discussed extensively in Chapter 3.
uðrÞ 5 4ε σ
r
 12
2 σ
r
 6  	 ð5:1Þ
If intermolecular interaction is restricted to pairs of molecules, the total poten￾tial energy (U) is obtained by summing up the contribution of all of the individual
pairs.
U 5 X
N21
i . j
X
N
j51
uðrijÞ ð5:2Þ
The summation in Eq. (5.2) is confined only to distinct pairs, which is
usually the most computationally efficient option. Instead, if all pairs were
evaluated, the resulting summation would have to be halved to yield the
same value as Eq. (5.2).
166 Molecular Simulation of FluidsThe force can be obtained by differentiating the potential with respect to
intermolecular separation. To calculate the force fi on each atom i, we must
account for the contribution from all other atoms,
fi 5 2 X
N
j6¼i
1
rij
@uðrijÞ
@rij 
 rij 5 2 X
N
j6¼i
wij
r2
ij
rij; ð5:3Þ
where wij is the virial introduced in Eq. (2.17) and rij is required in the
denominator because force is directed along the interatomic vector
(rij 5 ri 2 rj). A computationally convenient feature of Eq. (5.3) is that, if
u(rij) is an even function of rij, then it is only necessary to determine r2
ij and
not the absolute magnitude of rij.
It is apparent that the calculation of either energy or force requires a pair
of nested loops. The outer loop in the force calculation is required to obtain
values of fi for all i 5 1 to N molecules. The general procedure is summa￾rized by Algorithm 5.1.
ALGORITHM 5.1 Calculation of either intermolecular forces or energy.
loop i  1 ... N - 1
loop j  i + 1 ... N
Evaluate rij.
Evaluate u(rij) or fi.
Accumulate energy or force.
end j loop
end i loop
The pseudo code in Algorithm 5.1 follows directly from the problem descrip￾tion and illustrates the nesting of loops required for the evaluation of either forces
or energy. Care is taken to avoid identical molecules, and a total of N(N1)/2
iterations will be performed. However, this algorithm is normally used with a
very important modification. Simulations are performed typically with a few hun￾dred molecules arranged commonly on a cubic lattice. The small sample size
means that a large fraction of the molecules can be expected at the surface of the
lattice rather than in the bulk. This is undesirable because the forces experienced
by the surface molecules are different from the bulk. Periodic boundary conditions
are incorporated into Algorithm 5.1 to avoid this problem.
5.1.2 Periodic boundary conditions and minimum image convention
Periodic boundary conditions can be applied by constructing an infinite lat￾tice that replicates the cubic simulation box throughout space. Molecules in
any box on this lattice have a mirror image counterpart in all the other boxes.
Changes in one box are matched exactly in the other boxes. If a molecule
Calculating molecular interactions Chapter | 5 167leaves a box, then its counterpart in a neighboring box enters through the
opposite face. Consequently, the central box is devoid of any boundaries,
and surface effects are eliminated.
The use of a periodic boundary condition solves the problem of surface mole￾cules, but it poses another potential difficulty for the simulation. The heart of a
simulation program is the calculation of either molecular forces or energies. If
there are N molecules in the simulation, then to calculate the pairwise force or
energy experienced by each other molecule involves a summation of N1 terms.
In principle, we are also faced with the impossible task of including the interac￾tions of the infinite array of periodic images. In the case of a short-ranged inter￾molecular potential, this problem is avoided by invoking the minimum image
convention. To calculate the intermolecular interaction of any molecule, we posi￾tion it at the center of a box with dimensions identical to the simulation box. The
central molecule interacts with all molecules whose centers fall with this region,
that is, the closest periodic images of the other N1 molecules.
If the origin of the coordinate system is taken as the center of the simula￾tion box of length L, then the algorithms for applying the minimum image
convention and periodic boundaries are very simple. All the coordinates lie
within the range of 1
/2 L and -
1
/2L. Consequently, when the molecule leaves
the box, we can focus attention on its mirror image by either adding or sub￾tracting L to its coordinates. This can be easily coded in FORTRAN using
the intrinsic anint(x) to determine the nearest integer of x. For example, to
add the correct number of box lengths to the molecular coordinates rij or the
pair separation vector, we write:
rxij(i) = rxij(i) - boxl * anint( rxij(i) / boxl )
The original C/C11 programming language did not have a nearest integer
function as part of its standard maths library, which meant that a user￾defined function was required. An example of such a function (nearestInt) is
given in Chapter 11. The corresponding C/C11 statement is:
rxij[i] = rxij[i] - boxl * nearestInt(rx[ij], boxl);
Alternatively, this can now be achieved using the C/C++ round() function,
i.e., rxij[i] = rxij[i] - boxl * (int) round(rx[ij] / boxl); The
above statements are usually evaluated in a loop, for example, during the
evaluation of energies.
Although using a cubic box is overwhelmingly the most common choice
for implementing a molecular simulation, other geometries are possible
(Allen and Tildesley, 2017) that require the application of different periodic
boundary conditions. Examples include the rhombic dodecahedron (Wang
and Krumhansl, 1972) and the truncated octahedron (Adams, 1979). Reasons
for using different geometries include avoiding simulation-induced artefacts
168 Molecular Simulation of Fluidsin specific cases (Reed and Flurchick, 1996; White et al., 2008) or more
closely reproducing the behavior that is being investigated. The shape of the
simulation box may affect the properties of some protein systems
(Wassenaar and Mark, 2006), and helical periodic boundary conditions
(Kessler and Bour, 2014) may more closely match the conditions of some
biopolymers. The efficient study of elongational flow also requires special
boundary conditions (Hunt and Todd, 2003; Todd and Daivis, 1998).
The general procedure for calculating the energy or force using periodic
boundary conditions is given in Algorithm 5.2.
ALGORITHM 5.2 Calculation of either intermolecular forces or energy
using periodic boundary conditions.
loop i 1 ... N - 1
loop j  i + 1 ... N
Evaluate rij.
Convert rij to its periodic image (rij').
if (ri' < cutOffDistance) 
Evaluate u(rij') or fi.
Accumulate energy or force.
end if
end j loop
end i loop
Algorithm 5.2 differs from Algorithm 5.1 in two important respects. First, the
accumulated energy and forces are calculated for the periodic separation distances.
Second, only molecules separated by a distance less than the cut-off distance con￾tribute to the calculated energy or forces. The cut-off distance is a consequence of
the periodic boundary conditions. It can be any distance up to half the length of
the simulation box. A higher cut-off is not permitted because it would violate the
minimum image convention. Consequently, Algorithm 5.2 evaluates the properties
of a truncated intermolecular potential rather than the full potential. The full con￾tributions of the intermolecular potential can be obtained by using long-range cor￾rection terms.
5.1.3 Long-range corrections to periodic boundary calculations
The contribution to a property X of the fluid from the missing long-range
part of the potential can be obtained by adding a long-range correction.
Xfull 5 Xc 1 Xlrc ð5:4Þ
The long-range corrections are calculated by assuming that the pair￾distribution function is unity beyond the cut-off distance rc. Using this sim￾plification, the long-range corrections for energy (U), the virial term (W),
Calculating molecular interactions Chapter | 5 169and the chemical potential (μ) are obtained (Allen and Tildesley, 2017)
from,
Ulrc 5 2πNρ
Nð
rc
r2
uðrÞdr ð5:5Þ
Wlrc 5 2 2πNρ
3
Nð
rc
r2
wðrÞdr ð5:6Þ
μlrc 5 4πρ
Nð
rc
r2
uðrÞdr; ð5:7Þ
where:
wðrÞ 5 r
duðrÞ
dr ð5:8Þ
If these formulas are applied to the LJ potential, we obtain:
Ulrc 5 8επNρσ3
9
σ
r
 9
2 3 σ
r
 3  	 ð5:9Þ
Wlrc 5 32επNρσ3
9
σ
r
 9
2 3
2
σ
r
 3  	 ð5:10Þ
μlrc 5 16επρσ3
9
σ
r
 9
2 3 σ
r
 3  	 ð5:11Þ
Most short-range potentials decay rapidly with increasing intermolecular
separations. For example, the LJ potential asymptotes rapidly to zero for distances
greater than 2.5 σ. Therefore, rc$ 2.5 σ is an appropriate choice for the LJ poten￾tial in many situations. The cut-off value of 2.5 σ should be considered as the
absolute lower limit for the LJ potential and, in many circumstances, it is prudent
to use a larger value. This is particularly the case for the investigation of phase
coexistence, which requires much larger cut-off values to obtain consistently
reproducible results (Baidakov et al., 2000; Ahmed and Sadus, 2010). Cut-off￾induced discrepancies have also been observed for the pressure (Huang et al.,
2010) in various ensembles. The widespread ongoing use of a cut-off value of
2.5 σ is arguably an outdated legacy of early simulation studies, which were
severely restricted by meager computational resources. This should no longer be a
significant limitation for most contemporary simulations.
5.1.4 Neighbor list
The implementation of periodic boundary conditions reduces the computation
cost significantly because calculations involving intermolecular separation
170 Molecular Simulation of Fluidsgreater than the cut-off distance are not included. Verlet (1967) proposed that
keeping a periodically updated list of the neighbors of each molecule could
reduce computation time further. Instead of searching repeatedly for neighboring
molecules, the neighbors of each molecule are found from the list and the inter￾actions are calculated. This avoids searching for molecules that do not contribute
to the short-range interaction because they are beyond the cut-off separation.
Algorithm 5.3 illustrates the neighbor list method.
Starting with an empty list (Algorithm 5.3, Part 1), each molecule is selected
in turn (Algorithm 5.3, Part 1.1), and a search is made for neighbors (Algorithm
5.3, Part 2), which involves evaluating the intermolecular separation (Algorithm
5.3, Part 2.1). If a neighbor is found, it is entered on the list (Algorithm 5.3,
Part 2.2). The creation of a neighbor list involves two arrays. The array list con￾tains the neighbors of molecule i. The array listEntry stores the position of the
last neighbor of molecule i in list. For each molecule, the listEntry value allows
us to index the neighboring molecules. The variable d is used to encompass
molecules slightly outside the cut-off distance. This provides a buffer for those
molecules that are likely to come within the cut-off distance in the next few
MC cycles or MD time steps, thereby reducing the update frequency of the
neighbor list.
ALGORITHM 5.3 Creation of a Verlet neighbor list.
Part 1 topOfList  0 //start with empty list
Part 1.1 loop i 1 ... N – 1 //select molecule i
listEntryi  0
Part 2 loop j  i + 1 ... N //look for neighbors of i
Part 2.1 Evaluate rxij, ryij and rzij.
Evaluate periodic images ( rxij', ryij' and rzij')
r
2  rxij'
2 + ryij'
2 + rzij'
2
Part 2.2 if (r
2 < (rCut 2 + d)) //neighbor found
topOfList  topOfList + 1
listEntryi  topOfList //position of j on list
listtopOfList  j //enter j on list
end if
end j loop
end i loop
The use of the neighbor list in conjunction with energy/force evaluation
is illustrated in Algorithm 5.4. At the start of the simulation, the neighbor
list is created. The neighbor listed is subsequently updated periodically
(Algorithm 5.4, Part 1) during the course of the simulation (update ’true).
In the force/energy evaluation (Algorithm 5.4, Part 2), the inner loop
(Algorithm 5.4, Part 2.1) over molecules of type j is replaced by a loop
over the neighbors of I found in the array list, where the value of listEntryi is
the position of the last neighbor of i in the list. After all the neighbors of i
Calculating molecular interactions Chapter | 5 171are considered, the value of last is updated in preparation for the next i
molecule.
The use of neighbor lists reduces the computing substantially, particularly
for systems with 500 or more molecules (Allen and Tildesley, 2017). An
update interval of 1020 steps is usually sufficient; the optimal number
depends on the size of the cut-off distance. Alternatively, the algorithm can
be extended to update the neighbor list automatically (Fincham and Ralston,
1981) when the sum of the magnitudes of the two largest displacements
exceeds the buffer distance (d). Algorithm 5.5 illustrates this latter approach.
ALGORITHM 5.4 Calculation of energies/forces using a neighbor list.
Part 1 If (update)
Create neighbor list (Algorithm 5.3). 
update  false
end if
last  0
Part 2 loop i  1 ... N - 1
if (listEntryi > 0)
Part 2.1 loop m  last + 1 ... listEntryi
j  listm
Evaluate rxij, ryij and rzij.
Evaluate periodic images ( rxij', ryij' and rzij').
r2  rxij'
2 + ryij'
2 + rzij'
2
if (r 2 < rCut 2
)
Evaluate u(rij) or fi.
Accumulate energy or force.
end if
end m loop
last listEntryi
end if
end i loop
Before each force/energy evaluation (Algorithm 5.5, Part 1), the highest
newMax and second highest displacements oldMax in all directions are evalu￾ated (Algorithm 5.5, Part 1.1) and compared with d (Algorithm 5.5, Part 1.2).
At the commencement of the force/energy evaluation (Algorithm 5.5, Part 2)
if update is true, the current coordinates are stored (Algorithm 5.5, Part 2.1),
a new list is created (Algorithm 5.5, Part 2.2), and the forces/energies
(Algorithm 5.5, Part 2.3) are calculated. Otherwise, the forces/energies are
evaluated from the existing list (Algorithm 5.5, Part 2.4). The advantage of
this method is that it avoids the overhead of re-evaluating the neighbor list
too often.
The importance of the neighbor list is reflected by the continuing
efforts made to improve its capabilities (Awile et al., 2012; Gonnet, 2013;
172 Molecular Simulation of FluidsSutmann and Stegailov, 2006). The common feature of all neighbor list
implementations is the need to periodically update the list. This is a
source of imprecision that can be expected to increase during the course
of the simulation. Therefore when practical, it is particularly useful to
compare the results obtained from a neighbor list implementation with a
brute-force calculation.
ALGORITHM 5.5 Use of an automatically updated neighbor list.
Part 1 Check if displacement has been exceeded:
newMax  0
oldMax  0
Part 1.1 loop i  1 ... N
xDisp  |rxi - rxOldi|
yDisp  |ryi - ryOldi|
zDisp  |rzi - rzOldi|
if (xDisp > newMax)
oldMax  newMax
newMax  xDisp
end if
if (yDisp > newMax)
oldMax  newMax
newMax  yDisp
end if
if (zDisp > newMax)
oldMax  newMax
newMax  zDisp
end if
end i loop
Part 1.2 if (newMax + oldMax > d)
update  true
else
update false
end if
Part 2 Calculate forces/energies:
if (update)
Part 2.1 Save current configuration:
loop i 1 ... N
rxOldi rxi
ryOldi ryi
rzOldi rzi
end i loop
Part 2.2 Create new neighbor list (Algorithm 5.3). 
Part 2.3 Evaluate forces/energies (Algorithm 5.4).
else
Part 2.4 Evaluate forces/energies (Algorithm 5.4) from the existing list.
end if
Calculating molecular interactions Chapter | 5 1735.1.5 Linked cells
For simulations involving a large number of molecules (N $ 1000), the logi￾cal testing of every pair in the system required by the neighbor list becomes
increasingly inefficient computationally. Quentrec and Brot (1973) proposed
an alternative bookkeeping method that is particularly advantageous for large
systems. The method involves creating a linked list of cells. The simulation
box is divided into a lattice of M 3 M 3 M cells. The value of M is chosen
such that the length of the cells (L/M) is greater than the cut-off distance of
the forces.
A two-dimensional cell has eight neighbors, whereas a three￾dimensional cell has twenty-six neighbors. However, if Newton’s third
law is used to evaluate forces in a MD simulation, only half the neighbors
need to be considered. At the start of the simulation, the identities of the
cells and their neighbors must be specified. The indexing required in three
dimensions is illustrated by Algorithm 5.6. Algorithm 5.6 uses a three￾dimensional array to locate the various cells in the simulation box. This
involves a triple loop (Algorithm 5.6., Part 1). An index is assigned to
each cell in the inner loop (Algorithm 5.6, Part 2). When locating nearest
neighbors, care must be taken to account for indices that are outside the
scope of the array (Algorithm 5.6, Parts 2.12.4). In these cases, a value
of -1 can be assigned to map, which indicates that there are no neighbors.
Fig. 5.1 illustrates the allocation of cell identities to the different cells for
the two-dimensional case. According to Algorithm 5.6, the cell numbered
5 is located at cell2,2 and the numbers 6, 9, 8, and 7, which correspond to
map13, map14, map15, and map16, respectively, identify their four nearest
neighbors.
7 8 9
4 5 6
1 2 3
FIGURE 5.1 Illustration of cell numbering for a two-dimensional simulation cell with M 5 3.
174 Molecular Simulation of FluidsALGORITHM 5.6 Three-dimensional map of cells and nearest neighbors.
Part 1 Triple loop for 3-D cases:
loop z 1 ... M
loop y 1 ... M
loop x  1 ... M
Part 2 Assign an index to each cell:
cell(x)(y)(z) 1 + mod(x - 1 + M, M)
+ mod(y - 1 + M, M)  M
+ mod(z - 1 + M, M)  M2
Part 2.1 Identify half the nearest neighbors of each cell: 
index  13  (cell(x)(y)(z) - 1)
mapindex + 1  cell(x+1)(y)(z)
mapindex + 2  cell(x+1)(y+1)(z)
mapindex + 3  cell(x)(y+1)(z)
Part 2.2 if (x = 1)
mapindex + 4  -1
else
mapindex + 4  cell(x-1)(y+1)(z)
end if
Part 2.3 if (x = 1 or z = 1)
mapindex + 5  -1
mapindex + 6  -1
mapindex + 7  -1
mapindex + 8  -1
else
mapindex + 5  cell(x+1)(y)(z-1)
mapindex + 6  cell(x+1)(y+1)(z-1)
mapindex + 7  cell(x)(y+1)(z-1)
mapindex + 8  cell(x-1)(y+1)(z-1)
end if
mapindex + 9  cell(x+1)(y)(z+1)
mapindex + 10  cell(x+1)(y+1)(z+1)
mapindex + 11  cell(x)(y+1)(z+1)
Part 2.4 if (x = 1)
mapindex + 12  -1
else
mapindex + 12  cell(x-1)(y+1)(z+1)
end if
mapindex + 13  cell(x)(y)(z+1)
end x loop
end y loop
end z loop
Calculating molecular interactions Chapter | 5 175The procedure for creating a linked-cell list is illustrated by Algorithm
5.7. At the outset of the simulation (Algorithm 5.7, Part 1) the length and
number of cells are determined. At each time step of the simulation, sorting
all the molecules into their appropriate cells creates a linked list of cells. The
process involves initializing headi to zero (Algorithm 5.7, Part 2), allocating
particles to cells Algorithm 5.7, Part 3.1), and identifying “head” particles
(Algorithm 5.7, Part 3.1).
ALGORITHM 5.7 Creation of a linked-cell list.
Part 1 Determine length and number of cells:
lCell int(lBox/rCutOff)
nCell  lCell3
Part 2 Initialise head array to zero:
loop i  1 .... nCell
headi  0
end i loop
Part 3 Allocate particles to cells and identify ‘head’ particles:
loop i  1 ..... nParticles
Part 3.1 cell  1 + int( (rxi + lBox/2)  lCell)
+ int( (ryi + lBox/2)  lCell)  lCell
+ int( (rzi + lBox/2)  lCell)  lCell  lCell
listi headcell
Part 3.2 headcell  i
end i loop
Algorithm 5.8 gives an example of using a linked-cell list in a force
evaluation. At the outset (Algorithm 5.8, Part 1) the parameters are ini￾tialized as in a conventional simulation. The length and number of cells
are determined (Algorithm 5.8, Part 2), followed by the creation of a cell
map (Algorithm 5.8, Part 3) and a linked-cell list (Algorithm 5.8, Part 4).
The evaluation of forces (Algorithm 5.8, Part 5) involves loops over all
cells (Algorithm 5.8, Part 5.1), over all molecules in the cell (Algorithm
5.8, Part 5.2), and over neighboring cells (Algorithm 5.8, Part 5.3).
Comparing the execution times of simulations, the linked-cell procedure
with the neighbor list indicates that the former may be advantageous in
some circumstances (Morales, 1996).
176 Molecular Simulation of FluidsALGORITHM 5.8 Force calculation using a linked-cell list.
Part 1 Initialise parameters as in conventional simulation.
Part 2 Determine length and number of cells:
lCell int(lBox/rCutOff)
nCell lCell3
Part 3 Create cell map (Algorithm 5.6).
Part 4 Create linked-cell list (Algorithm 5.7).
Part 5 Evaluate forces:
Part 5.1 loop cell 1 ... nCell //loop over all cells
i headcell
Part 5.2 loop while (i > 0) // loop over all molecules in the cell
j listi
loop while (j > 0)
Evaluate forces.
j listj
end j loop
jCell0 13 (cell - 1)
Part 5.3 loop neighbor 1 ... 13 //loop over neighboring cells
jCell map
if (jCell > 0)
j headjCell
else
j 0
end if
loop while (j > 0)
Evaluate forces.
j listj
end j loop
i listi
end neighbor loop
end i loop
end cell loop
jCell0 + neighbor
The basic approach illustrated in Algorithms 5.65.8 has been modified to
improve its efficiency (Everaers and Kremer, 1994; Fanourgakis et al., 2007;
Fomin, 2011; Wang et al., 2007; Welling and Germano, 2011). Watanabe et al.
(2011) have provided details of a parallel implementation and it has been com￾bined (Fomin, 2011; Luo et al., 2015) with a look-up table (see Section 5.1.6).
The refinements sometime result in a many-fold improvement (Heinz and
Hu¨nenberger, 2004; Yao et al., 2004) in computational speed. Traditionally, the
Calculating molecular interactions Chapter | 5 177linked-cell list has been implemented for a cubic simulation box, but there are
examples of its use in other geometries (Cui et al., 2009). The approach has been
modified (Matin et al., 2003) to deal with the special case of elongational flow,
which requires nonconventional boundary conditions.
5.1.6 Look-up table
A look-up table is a computation-saving alternative to the direct evaluation of
either the intermolecular potential or force. At the start of the simulation, the
potential u(s) and force (f 5 2 2rij (du/ds)) are calculated at intervals of δs, where
s 5 rij
2
. Typically, δs 5 0.01rm
2
, where rm is the separation that corresponds to
the minimum of the potential. The values of the calculated potentials and/or forces
are stored in look-up tables as is illustrated by Algorithm 5.9.
ALGORITHM 5.9 Creation of look-up tables.
s 0.01 × rPotMin
max int(rCutOff/s)
loop i 1... max
s  i  s
rij s
Evaluate potential (potTablei).
Evaluate force (forceTablei).
end i loop
During the simulation, values of s 5 rij
2 are calculated for each pair of
molecules, and the potential and/or force is interpolated for the table. The
most widely used interpolation formula is the NewtonGregory forward dif￾ference method (Booth, 1972),
uðsÞ 5 uk 1 ξðuk11 2 ukÞ 1
1
2
ξðξ 2 1Þðuk12 2 2uk11 1 ukÞ; ð5:12Þ
where:
ξ 5 s 2 sk
δk
ð5:13Þ
Algorithm 5.10 illustrates the use of a look-up table in conjunction with a
neighbor list. A look-up table is particularly useful for complicated intermolecular
potentials. It has been used (Barker et al., 1971) for the BarkerFisherWatts
(BFW) potential, which contains 11 adjustable parameters and an exponential
term. It is also likely to be particularly useful in the implementation of the molec￾ular mechanics force fields described in Chapter 3. In this context, several
tables could be used to store values of the different contributions from both inter￾and intramolecular interactions. Improvements to the basic algorithm have been
proposed (Andrea et al., 1983), which reduce the storage requirements of the
178 Molecular Simulation of Fluidstables. The use of look-up tables in conjunction with an Ewald sum has been
described (Danese et al., 1998).
ALGORITHM 5.10 Calculation of energies using a neighbor list and a look￾up table.
if (update)
Create neighbor list.
update  false
end if
last  0
loop i  1 ... N - 1
if (listEntryi > 0)
loop m  last + 1 ... listEntryi
j  listm
Evaluate rxij, ryij and rzij.
Evaluate periodic images (rxij', ryij' and rzij').
s  rxij'
2 + ryij'
2 + rzij'
2
if (s < rCut 2
)
k int(s/s) // Look-up table index
  s/s-k
pot  potTablek +   (potTablek+1 –potTablek)
+ 0.5  (2 - ) 
(potTabkek+2 - 2  potTablek+1 + potTablek)
Accumulate energy.
end if
end m loop
last listEntryi
end if
end i loop
The linked-cell method is used frequently as part of the particleparticle
particlemesh (PPPM) algorithm (see subsequent discussion) and improvements
are being made continually. Fincham (1994) has reported a small-cell version
of the linked-cell method that can be used to improve the efficiency of calculating
the real space contribution of the Ewald sum (see subsequent discussion).
Milchev et al. (1993) have applied the linked-cell algorithm in a MC simulation
of the properties of polymers. Grest et al. (1989) reported MD code using a vec￾torized linked-cell algorithm. Pinches et al. (1996) have implemented a parallel
version of the linked-cell algorithm.
5.1.7 Comparison of computational efficiency
The computation time t of the brute-force evaluation of all distinct pairs is,
t 5 α NðN 2 1Þ
2 ; ð5:14Þ
Calculating molecular interactions Chapter | 5 179where α is a constant. In contrast, when a Verlet list is used, the calculation
of energy is proportional to the number of molecules, and the N2 term only
arises when the list is updated. Consequently,
t 5 γN 1 λ NðN 2 1Þ
2 ; ð5:15Þ
where γ and λ are constants associated with the energy/force evaluation and
with the frequency of updating the Verlet list, respectively. It is evident that
if λ is small, the Verlet list can reduce the computational complexity of the
algorithm. Typically, algorithms, which use a Verlet, list scale as N3/2. In
contrast, the two main processes involved in the linked-cell method, namely,
energy evaluation and creation of the cell list, both have a linear dependence
on the number of molecules,
t 5 κN 1 τN ð5:16Þ
where κ and τ are constants associated with energy/force evaluation and cell
list creation, respectively.
It is apparent that using either the Verlet list or the linked-cell list can poten￾tially have considerable computational advantages. However, it should be noted
that the benefits of the list methods for a system with few molecules (N 5 1000)
may be outweighed by the computational overhead of creating and maintaining
a list. It is also clear that automatic updates of the Verlet list are essential to
maximize computational efficiency. The list methods are likely to be more ben￾eficial for MD simulations rather than MC. For example, Frenkel and Smit
(2002) have compared the computation times for MC simulations using various
methods. They concluded that the simple brute-force algorithm was superior to
the list methods for simulating the properties of a LJ fluid of 200500 mole￾cules. However, the cell method is vastly superior when a large number of
molecules are involved, particularly at low densities. For 10,000 particles,
Frenkel and Smit (2023) reported an 18-fold improvement using the cell method
compared with a brute-force evaluation of all distinct pairs.
5.2 Calculation of long-range interactions
The use of periodic boundary conditions is a standard feature of the molecular
simulation of bulk properties using short-range intermolecular potentials. It avoids
inaccuracies caused by surface effects and it also provides the additional benefit
that computation time is reduced significantly by using cut-off corrections instead
of calculating the interactions of all periodic images. However, long-range interac￾tions such as Coulombic or dipolar interactions typically exert an influence that is
much greater than half the length of the simulation box. The decay of the
Coulombic [Eq. (3.51)], Stockmayer [Eq. (3.80)], and LJ [Eq. (3.25)] potentials as
a function of intermolecular separation are compared in Fig. 5.2. It is apparent
from Fig. 5.2 that the Coulombic and, to a much lesser extent, the Stockmayer
180 Molecular Simulation of Fluidspotentials, are nonzero for quite large intermolecular separations. The obvious
solution is to use a very large simulation box; however, this approach is prohibi￾tive computationally. Instead, various computational procedures have been devised
and some of the alternatives are discussed below. It should be noted that calcula￾tions of electrostatic interactions are prone to a greater degree of uncertainty and
error (Coelho and Cheary, 1997; Bogusz et al., 1998; Resat and McCammon,
1998) than simulations involving nonpolar molecules.
5.2.1 The Ewald sum
The Ewald sum has arguably become the default method for the evaluation
of electrostatic interactions. It deals specifically with the interactions
between charges, which makes it particularly suitable for ionic interactions.
However, it can also be applied more generally to nonpolar systems
because nonpolar interactions between molecules (Chapter 3) are routinely
modeled by assigning partial charges to the constituent atoms. The Ewald
sum is considered to be the most rigorous method available, as it has been
described in considerable detail elsewhere (Allen and Tildesley, 2017;
Rapaport, 2004; Tuckerman, 2010). Many efforts have been made to both
make improvements and apply it to an increasing variety of situations
(Wells and Chaffee, 2015; Tornberg, 2016; Lindbo and Tornberg, 2012;
Villarreal and Montich, 2005; Skeel, 2016).
FIGURE 5.2 Comparison of the decay of (A) Coulombic (qaqb/εσ 5 1), (B) Stockmayer (μaμb/
εσ3 5 1, θa 5 90 degrees, θb 5 90 degrees and φa 5 φb), and (C) LJ (u/ε) reduced potentials (non￾SI versions) as a function of reduced intermolecular separation.
Calculating molecular interactions Chapter | 5 181First, consider a central simulation box of length L. Using the non-SI ver￾sion of Eq. (3.51), the energy from electrostatic interactions between N mole￾cules confined in the central box can be obtained from:
U 5 1
2
X
N
i51
X
N
j51
qiqj
rij
ð5:17Þ
Six periodic images of the central box can be constructed at a distance L
from the central box with coordinates (rbox) specified by (0, 0, L), (0, 0, L),
(0, L, 0), (0, L, 0), (L, 0, 0), and (L, 0, 0). Eq. (5.17) must be modified to
include the contribution of Coulombic interactions between charges in the
central box and all images of all particles in the six surrounding boxes.
U 5 1
2
X
6
nbox51
X
N
i51
X
N
j51
qiqj
rij 1 rbox

 

ð5:18Þ
We can construct a further five periodic images for each of these new boxes
and they in turn, also have periodic images. A sphere of simulation boxes is
constructed by continual repetition of this process. In general, the energy of
interaction of an ion and all of its periodic images can be obtained from,
U 5 1
2
XN
n50
X
N
i51
X
N
j51
qiqj
rij 1 n 
 
 ; ð5:19Þ
where the summation over n is taken over all lattice points, n 5 (nxL, nyL,
nzL) with nx, ny, nz integers. The prime indicates the omission of i 5 j for
n 5 0. Eq. (5.19) is the Ewald sum (Ewald, 1921).
In practice, Eq. (5.19) is not evaluated directly because it converges very
slowly. Instead, Eq. (5.19) is converted (de Leeuw et al., 1980; Heyes, 1981)
into two series each of which converges more rapidly. The assumption is made
that each charge is surrounded by a neutralizing charge distribution of equal
magnitude but of opposite sign. Typically, a Gaussian charge distribution is used.
ρi
ðrÞ 5 qiκ3
π
3
2
expð2 κ2
r2
Þ ð5:20Þ
The summation over point charges becomes a summation of the interac￾tion between charges plus the neutralizing distributions. The new summation
is often referred to as the “real space” summation. The real space energy is,
Ureal2s 5 1
2
X
N
i51
X
N
j51
XN
n50
qiqjerfc κ rij 1 n 
 
  
rij 1 n 
 
 ; ð5:21Þ
where erfc is the complementary error function (Abramowitz and Stegun, 1972).
erfcðxÞ 5 2
ffiffiffi
π p
Nð
x
expð2 t
2
Þdt ð5:22Þ
182 Molecular Simulation of FluidsMost programming languages implement the error function as part of
their mathematical library, which means that it is not a programming impedi￾ment. The value of κ is chosen such that only terms corresponding to n 5 0
(interactions involving charges in the central box only) make a contribution.
Typically, κ 5 5/L (Woodcock and Singer, 1971).
A second charge distribution is required, which counteracts exactly the
neutralizing distribution. The summation is performed in “reciprocal space,”
Urecip2s 5 1
2
X
k6¼0
X
N
i51
X
N
j51
4πqiqj
k2L3 exp
k2
4κ2

 cosðkUrijÞ; ð5:23Þ
where k 5 2πn/L2 are the reciprocal vectors. Typically, 100200 k vectors
are used (Woodcock and Singer, 1971). Evaluating a triple summation is
expensive computationally. Instead, complex algebra (Heyes, 1981;
Anastasiou and Fincham, 1982) is used to replace the sum involving i and j
with a single summation. The result is:
Urecip2s 5 1
2
X
k6¼0
4π
k2L3 exp
k2
4κ2

  X
N
i51
qiexpðikUriÞ










2
ð5:24Þ
The summation of Gaussian functions in real space also includes the interac￾tion of each Gaussian with itself. The effect of this interaction on the energy is:
UGauss 5 2 κ
ffiffiffi
π p X
N
k51
q2
i ð5:25Þ
The medium surrounding the sphere of simulation boxes must also be con￾sidered in the calculation because the sphere can interact with its surroundings.
No correction is required if the surrounding medium is a good conductor charac￾terized by infinite relative permittivity (ε0 5N). However, if the surrounding
medium is a vacuum (ε05 1), the following correction applies.
Ucorr 5 2π
3L3
X
N
i51
qiri










2
ð5:26Þ
Consequently, the final expression for Coulombic interaction is:
U 5 Ureal2s 1 Urecip2s 1 UGauss 1 Ucorr ð5:27Þ
The Ewald sum can be applied to dipoledipole interactions (Adams and
McDonald, 1976; de Leeuw et al., 1980). The contributions to Eq. (5.27) for
dipoledipole interactions are,
Ureal2s 5 1
2
X
N
i51
X
N
j51
XN
j j n 50
ðµi
Uµj
ÞBðrij 1 nÞ 2 ðµi
UrijÞCðrij 1 nÞ ð5:28Þ
Calculating molecular interactions Chapter | 5 183Urecip2s 5 1
2
X
N
i51
X
N
j51
X
k6¼0
4πðµi
UkÞðµj
UkÞ
κ2L3 exp
k2
4κ2

 cosðkUrijÞ ð5:29Þ
UGauss 5 2 2κ
3 ffiffiffi
π p X
N
i51
µ2
i ð5:30Þ
Ucorr 5 2π
3L3
X
N
i51
X
N
j51
µi
Uµj ð5:31Þ
where the summations over i and j are for dipoles in the central box and:
BðrÞ 5 erfcðκrÞ
r3 1
2κ
ffiffiffi
π p r2 expð2 κ2
r2
Þ ð5:32Þ
CðrÞ 5 3erfcðκrÞ
r5 1
2κ
ffiffiffi
π p r2 2κ2 1
3
r2

 expð2 κ2
r2
Þ ð5:33Þ
The triple summation in Eq. (5.29) can be avoided by using complex
algebra resulting in:
Urecip2s 5 1
2
X
k6¼0
4π
k2L3 exp
k2
4κ2

  X
N
i51
ðµj
UkÞ expðikUriÞ










2
ð5:34Þ
The implementation of the Ewald sum for ions is illustrated by
Algorithms 5.11 and 5.12 (Smith, 1992). Before calculating the reciprocal
space sum (Algorithm 5.11), the forces of the molecules (Algorithm 5.11,
Part 1) and exponential k vector terms (Algorithm 5.11, Part 2) are initial￾ized. A feature of the practical implementation of algorithms to calculate the
reciprocal space contribution is inner loops (Algorithm 5.11, Parts 3.1 and
3.2) with variable terms (mmin and nmin). This exploits the inversion symmetry
of the reciprocal lattice, halving the required computation time.
The implementation of the real space terms is straightforward
(Algorithm 5.12). The Gaussian (Algorithm 5.12, Part 1) and correction
terms (Algorithm 5.12, Part 2) are determined prior to the evaluation of
the real space contribution. The calculation of the real space contribution
(Algorithm 5.12, Part 3) involves a relatively minor change to the normal
force evaluation algorithms. An improvement in computational efficiency
can be obtained by incorporating a neighbor list (Algorithm 5.4). Smith
(1992) has discussed an improved replicated data algorithm for the Ewald
sum that exploits parallel computers. Sperb (1998) has reported an alter￾native to the Ewald sum based on redefining particle identities. Details
are also available (Lekner, 1998) of the calculation of Coulombic interac￾tions in an orthorhombic unit cell.
184 Molecular Simulation of FluidsALGORITHM 5.11 Calculation of the reciprocal space contribution in the
Ewald sum.
Part 1 Initialise forces on molecules:
loop j 1 ... N 
fxj 0
fyj 0
fzj 0
end j loop
Part 2 Initialise exponential k vector terms:
loop k  -kMax ... kMax
loop j 1... N
exkj  exp(i2k/L)
eykj  exp(i2k/L)
ezkj  exp(i2k/L)
end j loop
end k loop
Part 3 Calculate reciprocal space terms:
mMin 0
nMin 1
loop l  0 ... k
rl 2l/L
Part 3.1 loop m  mMin ... kMax
rm 2m/L
loop j  1 ... N
exyj exlj  eymj
end j loop
Part 3.2 loop n  nMin ... kMax
rn 2n/L
k2  l
2 + m2 + n2
if k2  kmax2
rk
2  rl
2 + rm2 + rn
2
Ak  exp(rk
2
/4	
2
)/rk
2
loop j 1 ... N
exyzj Cj  exyj  eznj
end j loop
QSum  0
loop j 1 ... N
QSum QSum + exyzj
end j loop
E  Ak
QSum

2
/L3
loop j 1 ... N
fxj  fxj + real(2i  Ak  QSum  exyzj  rl)/L3
fyj  fyj + real(2i  Ak  QSum  exyzj  rm)/L3
fzj  fzj + real(2i  Ak  QSum  exyzj  rn)/L3
end j loop
end if
end n loop
nMin  -kMax
end m loop
mMin  -kMax
end l loopALGORITHM 5.12 Calculation of the real space contribution in the Ewald
sum.
Part 1 Calculate Gaussian term using eq. (5.25).
Part 2 Calculate correction term:
if (0 = )
Obtain Ecorr form eq. (5.26).
else
Ecorr 0
end if
Part 3 Calculate Real Space Term:
loop i 1 to N - 1
loop j  j + 1 to N
Evaluate rxij, ryij and rzij.
Evaluate periodic images (rxij', ryij' and rzij').
r 2  rxij'
2 + ryij'
2 t rz ij'
2
if (r2< rCut2
)
r r 2
E E + Ecorr + EGauss+ CiCjerfc(	r)/r
  CiCj[erfc(	r)/r + exp(-(	r)
2
)]/r 2
fxi  fxi - rxij
fyi  fyi - ryij
fzi  fzi - rzij
fxj  fxj + rxij
fyj  fyj + ryij
fzj  fzj + rzij
end if
end j loop
end i loop
5.2.2 The Wolf approximation of the Ewald sum
The calculation of the reciprocal part of the contribution to energy is the
most computational expense aspect of the Ewald sum. An alternative, pro￾posed by Wolf (Wolf, 1992; Wolf et al., 1999) is to truncate the calculation
beyond a certain distance (Rc). For ionic systems, this means, the calculation
of energy becomes (Avendan˜o and Gil-Villegas, 2006),
UðRcÞ  1
2
X
N
i51
X
j6¼i
ðrij , RcÞ
qiqj

 erfcðαrijÞ
rij
2 erfcðαRcÞ
Rc

2

 erfcðαRcÞ
2Rc
1 α
ffiffiffi
π p
X
N
i51
q2
i
; ð5:35Þ
Where α is a tuning parameter that is used to restrict the contribution of the real
part of the potential to the first cell of the Ewald system. In contrast to the Ewald
186 Molecular Simulation of Fluidssum, using Eq. (5.35) means a relatively straightforward adaptation of Algorithm
5.2. The key advantage of the Wolf method is that it is computationally much
less expensive (Sadeghifar et al., 2012) than the Ewald sum. The disadvantage of
the Wolf method is that the values of both α and Rc are not known beforehand.
Instead, they are typically obtained by matching the results of Ewald sum calcula￾tions. Modifications have been proposed (Ma and Garofalini, 2005; Waibel et al.,
2019), and it has been applied successfully to a broad range of situations
(Gdoutos et al., 2010; Mendoza et al., 2008).
5.2.3 The reaction field method
The reaction field method is a relatively simple procedure for accounting for
dipole interactions. Every molecule is at the center of an imaginary sphere
the size of which is determined by the cut-off radius rc. The sphere is
inside a homogeneous medium with a characteristic dielectric constant εs.
The energy resulting from interaction of the central molecule with all other
molecules within the sphere are calculated fully.
UðshortÞi 5 X
j;r # rc
uðrijÞ ð5:36Þ
This corresponds to the short-range contribution of dipolar interaction.
The long-range contribution to the energy results from interaction with the
medium beyond the sphere. The contribution to energy caused by the sur￾rounding medium is,
UðlongÞi 5 2 μi
ðεs 2 1Þ
2εs 1 1
1
r3
c

  X
j;rij # rc
µj ð5:37Þ
where μi is the dipole moment of the central molecule and μj is the dipole
moment of neighboring molecules within the sphere. Consequently, the total
energy experienced by each molecule is evaluated from:
Ui 5 UðshortÞi 1 UðlongÞi ð5:38Þ
It should be noted that a discontinuity in energy is generated when mole￾cules enter or leave the sphere. Therefore, it is usual practice to taper the
interactions at the sphere’s surface (Adams et al., 1979) by applying a
weighting factor f(rij) that approaches zero continuously at rij 5 rc. Several
different tapering functions have been proposed (Adams et al., 1979; Andrea
et al., 1983). In many cases, a simple linear function is appropriate,
fðrijÞ 5
1 rij , rt rc 2 rij
rc 2 rt
rt # rij # rc
0 rc , rij
;
8
>><
>>:
ð5:39Þ
where rt 5 0.95rc.
Calculating molecular interactions Chapter | 5 187The advantage of the reaction field method is that it can be incorporated
easily into a conventional MD or MC simulation with a minimal increase in
computation time. The necessary changes are illustrated in Algorithm 5.13,
which represents a relatively small modification to Algorithm 5.2. The main
disadvantages of the method are the potential discontinuity in energy arising
from molecules entering and leaving the sphere, and the need to know the
external dielectric constant in advance. The external dielectric constant can
be estimated from the following relationship (Allen and Tildesley, 2017),
1
ε 2 1 5 3kT
4πρμ2gðεsÞ
2 1
2εs 1 1
; ð5:40Þ
where ε is the relative permittivity and g(εs) is related to the fluctuation of
the total dipole moment of the central box.
gðεsÞ 5
P
N
i51
µi








2 * + 2 P
N
i51
µi








 2
Nμ2 ð5:41Þ
Alternatively, the reaction field algorithm itself can be used to calculate
the dielectric constant (Essex, 1998).
ALGORITHM 5.13 Calculation of dipole interactions using the reaction
field method.
Eshort  0
ELong  0
loop i 1 to N - 1
loop j  i + 1 to N
Evaluate rxij, ryij and rzij.
Evaluate periodic images (rxij', ryij' and rzij').
r
2  rxij'
2 + ryij'
2 + rzij'
2
if (r < cutOffDistance)
Calculate u(rij) to determine Ei.
Determine weighting factor f.
EShort  EShort + f  Ei
ELong,  ELong + f  i  j
end if
end j loop
end i loop
E Eshort + ELong  (s - 1)/(rc
3
(2s+ 1))
The reaction field method has been applied widely to dipolar fluids (Alder
and Pollock, 1981; de Leeuw et al., 1986). However, it cannot be used for ionic
fluids without modification because the assumption that the average charge den￾sity is zero beyond the cut-off radius excludes the interactions of the central par￾ticle with ions. Barker (1994) proposed a method that can be used for fluids
188 Molecular Simulation of Fluidscontaining both ions and dipoles. According to Barker (1994), the energy result￾ing from interaction between dipoles (identified by i and j) and ions (identified
by α and β) can be calculated as:
U 5 X
i
vi 1 X0
i , j
vij 1 X
α
wα 1 X0
α , β
wαβ 1 X0
iα
xiα ð5:42Þ
Eq. (5.42) includes contribution from self-dipole, self-ion, unlike-dipole,
unlike-ion, and iondiploe interactions. The primed summations are per￾formed over all pairs with separation less than rc. The terms v, w, and x are
defined by the equations,
vi 5 2 d1
2r3
c
μ2
i ð5:43Þ
vij 5 2 d1
r3
c
μi
μj ð5:44Þ
wα 5 2 d0
2r3
c
q2
α ð5:45Þ
wαβ 5 2 d0
rc
qαqβ 2 d1
r3
c
qiqjr2
αβ ð5:46Þ
xij 5 2 d1
r3
c
qαriαμj
; ð5:47Þ
where:
d0 5 εsð1 1 κrcÞ 2 1
εsð1 1 κrcÞ ; ð5:48Þ
d1 5 εsð2 1 2κrc 1 ðκrcÞ
2
Þ 2 2ð1 1 κrcÞ
εsð2 1 2κrc 1 ðκrcÞ
2
Þ 1 1 1 κrc
; ð5:49Þ
κ2 5 4πe2
εskT
X
i
niz
2
i ; ð5:50Þ
e is the charge of an electron, n is the bulk concentration, and z is the sign of
the charge.
The simplicity of the reaction field method has made it a popular choice for
molecular simulations involving dipoles, although application (Baumketner, 2009;
Lee, 2020) to ions is also possible via modified schemes as noted previously.
Improvements to the basic method are being made continually. Garzon et al.
(1994) applied the reaction field to the simulation of vaporliquid equilibria of
dipolar fluids. They concluded that the reaction field dielectric constant does not
affect either the coexistence properties or the structure of the coexisting phases.
Calculating molecular interactions Chapter | 5 189Ruocco and Sampoli (1994) have extended the reaction field method to include
polarization effects. The extended procedure provides a convenient method for
incorporating both long-range dipolar forces and many-body polarization effects
for large numbers of molecules. It has been applied successfully (Ruocco and
Sampoli, 1995) to determine the induced dipole of a polarizable model for water.
The reaction field has also been applied (Hloucha and Deiters, 1997) to a polariz￾able model for acetonitrile. Alper and Levy (1993) have proposed a generalized
reaction field method for the simulation of liquid water. It is based on a solution
of the Poisson equation for the reaction field acting on charges in a spherical cav￾ity that is surrounded by a dielectric continuum. Smith and van Gunsteren (1995)
and Omelyan (1997) have also investigated water via a reaction field method.
Zhou et al. (1996) have reported a procedure that eliminates the need for calculat￾ing the self-interaction energy. Millot et al. (1996) have compared calculations of
the static dielectric constant of polarizable Stockmayer fluids using both lattice
summation and reaction field methods. Houssa et al. (1998) reported results of
equal quality using either the Ewald sum or the reaction field for simulations
involving the GayBerne potential. Omelyan (1996) has proposed modifications
to the reaction field.
Tironi et al. (1995) have reported a generalized reaction field method that can
be incorporated very easily into a traditional MD simulations. Two regions are
defined, which are separated by a spherical boundary at a given radius R from the
origin. The inner region is characterized by a dielectric permittivity of ε1 and N
point charges qi at positions ri
. The outer region surrounding the sphere represents
a continuum characterized by a dielectric permittivity of ε2 and constant ionic
strength. The potential energy for the total system is given by:
U 5 1
2
X
N
i51
qi
4πε0ε1
φðriÞ ð5:51Þ
In the limit as r - 0, the electrostatic potential is,
φ1ð0Þ 5 1
4πε0ε1
X
i
qi
1
ri
1
1 1 B0
R
 	 ð5:52Þ
and the electric field is,
2rrφ1ðrÞ




r50
5 21
4πε0ε1
X
i
qi
ri
r3
i
1 ð1 1 B1Þri
R3
 	; ð5:53Þ
where:
B0 5 ε1 2 2ε2ð1 1 κRÞ
ε2ð1 1 κRÞ ð5:54Þ
B1 5 ðε1 2 4ε2Þð1 1 κRÞ 2 2ε2ðκRÞ
2
ðε1 1 2ε2Þð1 1 κRÞ 1 ε2ðκRÞ
2 ð5:55Þ
190 Molecular Simulation of FluidsIn Eqs. (5.54) and (5.55), κ is the inverse Debye screening length, which
can be obtained related to the ionic strength (I), Faraday’s constant (F), tem￾perature (T), the ideal gas constant (R), and the permittivity (ε0):
κ2 5 2IF2
ε0ε2RT ð5:56Þ
According to Eq. (5.53), the Coulomb force acting on a charge qi is:
FðrijÞ 5 qiqj
4πε0ε1
 1
r3
ij
1
1 1 B1
R3
c
	
rij
5 qiqj
4πε0ε1
 1
r3
ij
2 1
R3
c
2ðε2 2 ε1Þð1 1 κRcÞ 1 ε2ðκRcÞ
2
ðε1 1 2ε2Þð1 1 κRcÞ 1 ε2ðκRcÞ
2
	
rij
ð5:57Þ
Eq. (5.57) can be used directly in a conventional MD algorithm. The energy
can be calculated from Eq. (5.52), or alternatively, it can be obtained by integrat￾ing Eq. (5.57). Comparison of the results of the generalized reaction field method
(Tironi et al., 1995) with results obtained from the Ewald sum indicate that the
values obtained for energy, temperature, and volume are similar but that the root
mean fluctuations are greater for the reaction field approach. The main advantages
of the method are that it is very simple to implement, and there is no significant
increase in computational cost compared with nonionic simulations. Furthermore,
the method avoids the singularity at the dielectric boundary, which is common to
other reaction filed methods. Tironi et al. (1997) reported a spacetime-correlated
reaction field method that does not use the traditional static response of the dielec￾tric continuum.
Many examples of the application of the reaction field have involved small
polyatomic dipolar molecules, most notably water. However, the technique can
also be applied to systems containing large biomolecules. For example, a reaction
field method has been used (Sakurai et al., 1997) to investigate intermolecular
interaction at the lipidwater interface. A multicavity reaction field method for
flexible molecules has also been reported (Karelson et al., 1993).
The reliability of the method is sometimes affected by the nature of the appli￾cation. Good agreement with the Ewald sum has been reported (Stenhammar
et al., 2009) for the solvation of polar liquids, whereas inferior outcomes have
been obtained (English, 2005) for water models. It has been applied successfully
(Nozawa et al., 2015) to liquid crystal systems. A generalized reaction field
method has been developed (Wallace and Shen, 2012) for constant pH MD and it
has been useful for biomolecules (Ni and Baumketner, 2011) and proteins
(Gargallo et al., 2003). Improvements to account for charges and polarizability
have been reported (Nymand and Linse, 2000; Sidler et al., 2018).
5.2.4 Particle-particle and particle-mesh methods
In common with the Ewald sum and reaction field methods, the PPPM algorithm
(Eastwood et al., 1980) handles short-range and long-range interactions separately.
Calculating molecular interactions Chapter | 5 191The short-range interactions are obtained by a conventional particleparticle (PP)
calculation as illustrated by Algorithm 5.1. Long-range interactions are handled
by a particlemesh (PM) technique. In principle, the particlemesh method can
be used to calculate both short- and long-range interactions. However, in practice,
the particlemesh method alone is generally inaccurate. In contrast, the combina￾tion of particleparticle and particlemesh methods optimizes computational
speed and accuracy. The PPPM calculation (Algorithm 5.14) is of order Ng log
Ng (Ng is the number of grid points) compared with an order of N2 for the PP
algorithm.
The PM force calculations involve three steps. First, the charge density
of the fluid is modeled by assigning charges to a finely spaced mesh in the
simulation box. Second, the potential at each mesh point is calculated solv￾ing Poisson’s equation for the electrostatic potential caused by the charge
distribution on the mesh. In three dimensions, Poisson’s equation is,
@2
φ
@x2 1
@2
φ
@y2 1
@2
φ
@z2 5 2 4πρðx; y;zÞ; ð5:58Þ
where φ and ρ are the electrostatic potential and source distribution, respectively.
This equation is usually solved by using a fast Fourier transformation. Third,
numerical differentiation is used to calculate the field at each mesh point. The
force on a particle is calculated from the mesh field by interpolation.
The PM is constructed by dividing the simulation box of length L into an
integral number of cells of width H. The mesh or grid point that stores the
charge density, potential, and electric fields is at the center of each cell. If
the origin is taken at mesh point 0, the position of the mesh point p is
xp 5 pH. When periodic boundary conditions are used, the number of cells is
equal to the number of grid points Ng.
ALGORITHM 5.14 Calculation of intermolecular forces for a single time
step using the PPPM method.
Part 1 Initialisation:
Initialise accumulators, positions, momenta, etc.
Part 2 Calculate long-range particle-mesh interactions:
Assign charge to mesh.
Solve for potential.
Update momenta.
Part 3 Short-range force calculation:
Create linked-cell.
Calculate short-ranged forces.
Update momenta.
Part 4 Time integration calculation:
Update particle positions, momenta, and energy accumulators.
192 Molecular Simulation of FluidsAfter the PM contribution is evaluated, the contribution from short-range inter￾actions is added. The steps required for the PPPM method are summarized by
Algorithm 5.15. The principles behind the PPPM calculations can be most easily
illustrated by first considering the simple case of a one-dimensional system.
In one dimension, the charge density ρ at any mesh point p for a system
of N particles can be calculated from the density at the origin by,
ρp 5 CN
H
X
Np
i51
Wðxi 2 xpÞ 1 ρ0; ð5:59Þ
where W is a charge assignment function.
WðxÞ 5 1 j j x # H=2
0 j j x . H=2

ð5:60Þ
In practice, charges can be assigned efficiently by using Algorithm 5.15.
ALGORITHM 5.15 Assignment of charges to the particlemesh in one￾dimension.
Part 1 Calculate average number of particles per cell:
Nc  0H/(N  |C|) //assuming charge neutrality
Part 2 Initialise charge density accumulators:
loop p 1 ... Ng
p  -Nc
end p loop
Part 3 Accumulate charge density:
loop j  1 ... Np
p  nint(xj) // locate nearest mesh point
p  ( + 1)/Nc // increment charge density
end j loop
The field equations in one dimension are,
φp21 2 2φp 1 φp11 5 2 ρpH2
ε0
ð5:61Þ
φp21 2 φp11 5 2EpH; ð5:62Þ
where φ and E are the potential and electric field, respectively. These equa￾tions can be expressed conveniently in reduced form,
φ

p21 2 2φ

p 1 φ

p11 5 ρ

p ð5:63Þ
φ

p21 2 φ

p11 5 E

p; ð5:64Þ
Calculating molecular interactions Chapter | 5 193where
φ

p 5 2 qðΔTÞ
2
2meH2 φp; ð5:65Þ
E

p 5 2 qðΔTÞ
2
2meH
Ep; ð5:66Þ
ρ

p 5 2 qðΔTÞ
2
2meε0
ρp; ð5:67Þ
me is the mass of an electron, and ΔT is the simulation time step. We must
solve Ng equations of type (5.63) subject to the requirements of charge neu￾trality and the choice of a reference potential. It can be shown (Hockney and
Eastwood, 1988) that the first solution can be obtained from:
φ1 5 1
Ng
X
Ng
p51
pρp ð5:68Þ
Substituting the left-hand side of Eq. (5.68) into the first equation of type
(5.62) yields φ2. If both φ1 and φ2 are known, φ3 can be determined from the sec￾ond equation of type (5.63). This process can be repeated to find φ for all Ng
equations of type (5.63). This is a special example of the Thomas tridiagonal
algorithm (Hockney and Eastwood, 1988) that is valid when the tridiagonal coef￾ficients are 1, -2, and 1, respectively. The Thomas tridiagonal algorithm can be
generalized for arbitrary coefficients. Other algorithms for the solution of the field
equations including mesh-relaxation techniques, matrix methods, and rapid elliptic
solvers are discussed extensively elsewhere (Hockney and Eastwood, 1988).
Algorithm 5.16 illustrates how the field equations are solved in one dimension.
ALGORITHM 5.16 Solution of the field equations in one dimension using
the Thomas tridiagonal algorithm.
Part 1 Determine potential and electric field at mesh point 1:
*
1  0
loop p 1 ... Ng
*
1  *
1 + p*
p
end p loop
*
1  *
1 /Ng
E*
1 *
1
Part 2 Determine potential at mesh point 2:
*
2  *
1 + 2 *
1
Part 3 Determine remaining potentials and electric fields:
loop p 3 ... Ng
*
p  *
1 + 2 *
p-1 - *
p-2
Ep-1* *
p - *
p-2
end p loop
Ep  *
p
194 Molecular Simulation of FluidsThe force on any molecule can be obtained by using the interpolation
formula:
fi 5 Nq
N
Xg21
p50
Wðxi 2 xpÞEp ð5:69Þ
In Eq. (5.56), periodic boundary conditions are handled by treating mesh
point Ng as mesh point 0. In terms of reduced properties, Eq. (5.69) becomes
(Algorithm 5.17),
f

i 5
N
Xg21
p50
Wðx

i 2 pÞE

p ð5:70Þ
where x 5 x/H.
ALGORITHM 5.17 Force interpolation in one dimension of the
particlemesh.
E*
0 E*
p
f
*
i 0
loop p 0 ... Ng - 1
if (|xi*-p|  H/2)
W  1
else
W  0
end if
f
*
i  f
*
i + W  E*
p
end p loop
Eastwood et al. (1980) have reported a three-dimensional PPPM program.
In three dimensions, the volume L3 of the cubic simulation box is covered by
N3 mesh points separated by a distance H 5 L/N. Each mesh point is associ￾ated with a cubic cell of side H and an integer label p 5 (p1, p2, p3), where pi
has values from 0 to N1. The position of mesh point p is given by
xp 5 (p1H, p2H, p3H). Points x 5 (x1, x2, x3) falling within the cell belonging
to mesh point p satisfy the inequality that,
piH # xi , ðpi 1 1ÞH ð5:71Þ
where i 5 1, 2, 3. Any labels pi
0 that are outside the range of 0 to N1 are
transformed by the periodic boundary condition,
p 5 p
0
i 1 mN ð5:72Þ
where m is an integer.
Calculating molecular interactions Chapter | 5 195In three dimensions, the mesh field charge density [cf. the one￾dimensional case Eq. (5.59)] is given by,
ρðpÞ 5 X
s
qs
H3
X
i
Wðxi 2 xpÞ; ð5:73Þ
where the summation is over all species s and all particles i of each species.
The interpolation function W is given by the triangular shaped cloud (TSC)
charge function (Eastwood and Hockney, 1974),
qWðx; y;zÞ 5 qTp1ðxÞTp2ðxÞTp3ðxÞ; ð5:74Þ
where:
TsðtÞ 5
ð12tÞ
2
=2 s 5 2 1
0:5 1 t 2 t
2 s 5 0
t
2=2 s 5 1
0 otherwise
:
8
>><
>>:
ð5:75Þ
In contrast to the simple one-dimensional case, the calculation of the
mesh potential in three dimensions is quite complicated and requires the use
of a Fourier transformation. The mesh potential is defined by the sum over
all mesh points p0 in the simulation box,
φðpÞ 5 H3
ε0
X
p0
Gðp 2 p0
Þρðp0
Þ; ð5:76Þ
where G is the mesh defined by Green’s function and ε0 is the permittivity
of free space. A discrete Fourier transformation (DFT) is used to evaluate
this summation. If the following triple DFT pair A *Ab is defined,
AðpÞ 5 1
L3
X
l
A^ðIÞexp i
2π
N
IUp

  ð5:77Þ
A^ðIÞ 5 1
H3
X
p
AðpÞexp 2i
2π
N
IUp

  ð5:78Þ
Eq. (5.76) is transformed to:
φ^ 5 G^
ε0
 !ρ^ ð5:79Þ
For a given value of ðG^=ε0Þ, the solution to Eq. (5.79) is obtained by
transforming ρ*ρ^, multiplying by ðG^=ε0Þ to obtain φ^, which is transformed
to yield φ.
The mesh force on a particle at any position is calculated from:
Fm 5 qs
X
p
Wðxi 2 xpÞEðpÞ ð5:80Þ
196 Molecular Simulation of FluidsThe mesh-defined field values E(p) 5 (E1(p), E2(p), E3(p)) are obtained
by differencing the potential values. The i-component of E is given by,
EiðpÞ 5 2 γ
φðp 1 eiÞ 2 φðp 2 eiÞ
2H
1 ð1 2 γÞ
φðp 1 2eiÞ 2 φðp 2 2eiÞ
4H
 ;
ð5:81Þ
where ei is a unit vector in the i direction and the value of γ is chosen to
minimize errors in the interparticle force.
Some improvements to the original PPPM method have been described
elsewhere (Beckers et al., 1998). It has been adapted for parallel implementa￾tion for use on both conventional central processing units (Brieu and Evrad,
2000) and graphics processing units (Brown et al., 2012; Zhang and Bridson,
2014). Optimizations have been reported for periodic (Ballenegger et al.,
2008) and nonperiodic (Yao and Capecelatro, 2021) systems. Dipolar sys￾tems have been further investigated (Cerda` et al., 2011), and it has been
applied (Sirk et al., 2013) in nonequilibrium MD (Chapter 8).
5.2.5 Tree-based methods
The traditional particleparticle, particlemesh, or a combination of these
methods benefit commonly from potential truncation and neighbor list strate￾gies. The philosophy behind these computational strategies is to identify and
distinguish between neighboring molecules that make large contributions to
molecular interactions, and distant molecules that make only small contribu￾tions. This distinction between near and far interactions can be handled effi￾ciently by ordering the molecules in a hierarchical tree structure. Tree-based
algorithms are used commonly in computer science sorting and searching
applications. The use of tree-based algorithms to many-body problems has
been discussed by Pfalzner and Gibbon (1996). They offer the possibility of
large gains in computational efficiency, particularly for the calculation of
long-range interactions. For example, the fast multipole method is of order N
compared with N2 for a traditional particleparticle calculation. In this sec￾tion, the BarnesHut (Barnes and Hut, 1986) and fast multipole (Greengard
and Rokhlin, 1987) algorithms are discussed. Both of these algorithms use a
hierarchical tree to distinguish between near and far interactions to improve
the efficiency of calculating long-range interactions.
5.2.5.1 The BarnesHut algorithm
The BarnesHut algorithm utilizes a hierarchical tree. The basic philosophy
is to organize particles into a nested hierarchy of cells and compute the mul￾tipole moments of each cell up to a fixed order. The acceleration is obtained
Calculating molecular interactions Chapter | 5 197by allowing each particle to interact with various elements of the hierarchy
governed by a prescribed accuracy criterion. The force from nearby particles
is calculated by direct summation, whereas the influence of remote particles
is included by evaluating the multipole expansion of the cells that satisfy the
accuracy criterion at the location of each particle.
In computer science, a tree is a well-known and often used data structure.
The so-called binary tree is often employed to assist in the positioning and
retrieval of data in sorting applications. Binary trees can be applied directly
to store particle positions (Benz, 1988; Jernigham and Porter, 1989). The
advantage of the binary tree is that it usually closely reflects the structure of
the system. However, the octagonal tree structure proposed by Barnes and
Hut (1986) is conceptually simpler and easier to construct.
Barnes and Hut (1986) constructed their octagonal tree data structure by
successively placing particles initially into an empty cubic box. The empty
box is the “root” cell, and it is large enough to contain all the particles. As
particles are added to the root cell, it is further subdivided into smaller cells
such that every particle is contained within its own cell. For example, after
the addition of a second particle into the root cell, the cell is divided into
child cells having exactly half the length and width of their parent. In three
dimensions, this corresponds to splitting the cell into eight pieces. If follow￾ing this division, the two particles are found in the same child cell, the child
cell is subdivided recursively until the particles are in different boxes. The
next particle is then added to the root cell and the process is repeated. When
all the particles have been added, the space within the root cell has been par￾titioned into a number of cubic cells of different sizes each containing a
maximum of one particle.
In practice (Hernquist, 1988), the BarnesHut algorithm is usually imple￾mented starting from a fully populated root cell rather than a completely
empty box. The root cell is first divided into eight child cells. The number of
particles in each child cell is examined successively. If the cell is empty, it is
ignored. If there is only one particle in the cell, it is stored as a “leaf” node
of the tree structure. If there is more than one particle in a cell, the cell is
stored as a “twig” node, and the cell is further subdivided. The process of
subdivision continues until every cell contains a maximum of one particle.
The result of this subdivision and the interconnection between levels in the
simple two-dimensional case is illustrated in Fig. 5.3.
The preceding description has introduced the components of the tree
analogy, namely “root,” “twig,” and “leaf” that we will now examine more
formally. The “root” is the initial simulation cell containing every particle.
The tree grows from the “root” cell by successive division. Each division
generates a further level in the tree with a number of nodes associated with a
cubic volume of space containing a given number of particles. It should be
noted that empty cells are not stored. If the division generates a cell with
only one particle, a “leaf” is created, otherwise if there are two or more
198 Molecular Simulation of Fluidsparticles, a “twig” or “branch” is created. During the tree-building procedure,
the total mass, center of mass coordinates, and quadrupole moments of each
cell are computed recursively.
It is apparent from the above description that some bookkeeping is neces￾sary to keep track of the relationship between the root, twigs, and leaves.
The root cell is also the biggest “twig.” For the root, we must store an identi￾fier as a twig plus the number of nonempty child cells. Every other twig
requires the storage of a twig identifier; the number of nonempty child cells;
and a pointer to its parent cell. Each leaf requires a leaf identifier; a pointer
to the parent cell; and a particle label. The particle label associated with
each leaf is the link to the physical quantities of the particle required for
force evaluation.
How is the force evaluated? The force on a particle is obtained by walking
through the tree starting from the root cell. At each step, the ratio of the size of
the current cell (s) to its distance from the particle (d) is compared with a prede￾fined accuracy parameter (θ  1). If s/d # θ, the influence of all particles in the
cell is calculated as a single particlecell interaction. Otherwise, the cell is subdi￾vided by continuing the descent through the tree until either the accuracy criterion
is satisfied or an elementary cell is reached.
The advantage of this algorithm is that the force evaluation can be per￾formed in O(N ln N) time compared with O(N2
) for a brute-force parti￾cleparticle evaluation. Hernquist (1990) has reported that the tree traversals
FIGURE 5.3 Division of space for a two-dimensional particle distribution.
Calculating molecular interactions Chapter | 5 199can be vectorized fully by using a level-by-level approach rather than tra￾versing the tree node by node. This results in a two- to threefold increase in
speed compared with the original BarnesHut algorithm.
The BarnesHut algorithm is most often implemented in the context of
astronomical calculations (Belleman et al., 2008; Rein and Liu, 2012) that,
in common with molecular simulation, involve the evaluation of N-body
interactions. Considerable efforts have been made to develop parallel ver￾sions on both conventional multiprocessors (Munier et al., 2020; Winkel
et al., 2012) and hybrid systems (Iwasawa et al., 2020; Polyakov et al.,
2013) involving graphics processing units. Although it is typically used for
force evaluation, it can also be applied (Gan and Xu, 2014; Stransky, 2016)
in MC simulations (Chapter 6).
5.2.5.2 The fast multipole method
The fast multipole method (FMM), developed originally by Greengard and
Rokhlin (Greengard, 1987; Greengard and Rokhlin, 1987; Carrier et al., 1988),
also uses the hierarchical tree concept. The FMM algorithm involves multipole
expansions for boxes on the lowest level of the tree. These expansions are com￾bined and shifted as they are passed up and down the tree. Particles are assigned
to cells at the finest level of the tree. In contrast to the BarnesHut algorithm,
some cells may be empty, whereas some cells may have several particles. The
multipole expansion of the particle configuration on the finest level is formed
about the center of the box. Each “child” box communicates this information to
its “parent” box on the next level. Aggregate information about distant particles
comes back down the low-level boxes.
The original exposition of the FMM algorithm by Greengard and Rokhlin
(1987) concentrated primarily on one and two dimensions. Schmidt and Lee
(1991) have discussed the implementation in three dimension. In common
with the BarnesHut algorithm, the FFM subdivides the simulation box
(Fig. 5.4). The simulation box of length d is subdivided into a box of length
d/2r
, where r is an integer representing the level of refinement. This division
r = 0 r = 1 r = 2
FIGURE 5.4 Two-dimensional example of the division of the simulation box in the fast multi￾pole method algorithm.
200 Molecular Simulation of Fluidsis equivalent to forming 8r equal-sized subvolumes. This is done for every
single box to a maximum level of refinement R irrespective of the number of
particles that they contain. The maximum level of refinement R is approxi￾mately equal to the number of particles (N), that is, R 5 log8N. At the maxi￾mum level of refinement, there is on average one particle per box. The
interrelationship between the center of mass multiples at different levels of
refinement is illustrated for the two-dimensional case in Fig. 5.5.
The work of Schmidt and Lee (1991) provides a very clear description of
the FMM algorithm in three dimensions, and the following discussion is
based largely on their interpretation. The implementation of the FMM uses
three transformations of the potential. The transformations begin with a mul￾tipole expansion of the potential,
uðrÞ 5 4π
X
l;m
MlmYlmðθ; φÞ
ð2l 1 1Þrl11 ð5:82Þ
or a local expansion,
uðrÞ 5 4π
X
l;m
Llmrl
Ylmðθ; φÞ; ð5:83Þ
FIGURE 5.5 Two-dimensional representation of the interrelationship between the center of
mass multipoles at different levels in the FMM algorithm.
Calculating molecular interactions Chapter | 5 201where Ylm is a modified spherical harmonic that does not include the
normalization factor ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
ð2l 1 1Þ=4π p ; spherical coordinates (r, θ, r) are used
relative to an origin; and Mlm and Llm are the multipole and local expan￾sion coefficients, respectively. The multipole moments are defined by
Jackson (1983):
Mlm 5 X
i
qis
l
i
Y

lmðθi; φiÞ ð5:84Þ
A feature of the FMM is the need to make transformations between dif￾ferent coordinate systems. If the properties of the different coordinate sys￾tems are distinguished by the use of primes, it can be shown (Greengard,
1987) that:
M0
l
0
m0 5 X
l;m
TMM
l
0
m0
;lmMlm ð5:85Þ
L
0
l
0
m0 5 X
l;m
TLM
l
0
m0
;lmMlm ð5:86Þ
L
0
l
0
m0 5 X
l;m
TLL
l
0
m0
;lmLlm ð5:87Þ
In Eqs. (5.85) to (5.87), the Ts are transformation matrices of the follow￾ing form:
TMM
l
0
m0
;lm 5 4π
ð2rtÞ
l
0
21
Y
l
0
2l;m0
2mðθt; φtÞal
0
21;m0
2malmð2l
0 1 1Þ
ð2l 1 1Þ½2ðl
0 2 lÞ 1 1al
0
m0
; ð5:88Þ
TLM
l
0
m0
;lm 5 4π
ð21Þ
l1mY
l
0
1l;m0
2mðθt; φtÞalmal
0
m0
rl
0
1l11 t ð2l 1 1Þð2l
0 1 1Þal
0
1l;m0
2m
; ð5:89Þ
TLL
l
0
m0
;lm 5 4π rl2l
0
t Yl2l
0
;m2m0ðθt; φtÞal
0
m0al2l
0
;m2m0
almð2l0 1 1Þ½2ðl 2 l
0
Þ 1 1 ; ð5:90Þ
where the subscript t denotes a translation property between the different
coordinate systems and:
alm 5 ð21Þ
l1m
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
2l 1 1
4nðl 1 mÞ!ðl 2 mÞ!
s
ð5:91Þ
We will first consider an implementation of the three-dimensional FMM
algorithm for an open system. The issues raised by periodic boundary condi￾tions will be addressed separately. The system that we are interested consists
of N charges confined to a cube of sides d centered at the origin. The initiali￾zation phase of the FMM algorithm involves dividing the cube into
202 Molecular Simulation of Fluidssuccessively smaller cubic subvolumes. We define a maximum refinement
level (R) such that N is approximately equal to 8R
. The maximum multipole
expansion (L) is chosen in accordance with the predetermined relative preci￾sion (ε), that is, 22L # ε. Each level of refinement r contains an increasing
number of subvolumes. At r 5 0 we have the original cube, whereas at r 5 1,
2, 3 ..., there are 8, 16, 32, ... subvolumes. The refinement levels are the
“parent” boxes, which contain “child” boxes. Each box has 26 touching
boxes, which have a common face, edge, or corner. The algorithm proceeds
in four distinct stages.
Stage 1. First, starting from refinement level R, the 8R truncated multi￾pole expansions about the center of each box are calculated for particles con￾tained in each box in level R.
Stage 2. For refinement levels R1 to 0, the truncated multipole moment
expansions for all charges in all boxes about their centers are formed by
using Eq. (5.84) to transform the multipole expansions of the eight child
boxes to the center of their parent.
Stage 3. For each level of refinement, the multipole expansions are con￾verted to local expansions about the center of all the boxes. The multipole
expansions that contribute to the local expansions are those that do not touch
the one box. This calculation can be performed efficiently by combining
local-to-local and multipole-to-local transformations. At refinement levels 0
and 1, the local expansion is zero because the boxes are too close to allow a
valid multipole-to-local transformation. For the remaining levels, the local
expansion of the parent box is transformed to the center of the current box.
To this local expansion is added the transformation of the multipole poten￾tials for all boxes of the current level, which satisfy the conditions that (1)
the box does not touch the current box and (2) the charges in the box do not
contribute to the local potential. This results in a local potential in each box
from interactions between all particles in all boxes at the same level, which
do not touch the current box.
Stage 4. The final potential and forces of all particles in the boxes at the
finest level of refinement are calculated. This involves (1) evaluating the
potential and force from the local expansion at each particle location for
each box in level R and (2) evaluating the remaining interactions of each
particle with the other particles in the current box plus the particles i touch￾ing boxes.
Schmidt and Lee (1991) showed how the previously discussed algo￾rithm could be modified to include periodic boundary conditions. The
FMM algorithm requires the local expansion of the potential from all
periodic images except the 26 nearest neighbors of the original simulation
cell. To accommodate periodic boundary conditions, the values of
rt
2(l11)Yl,m(θt, φt) in Eq. (5.89) are replaced by sums over values corre￾sponding to all the images of the simulation cell except its 26 surrounding
Calculating molecular interactions Chapter | 5 203cells. The sum over all the cells except the simulation cell can be calcu￾lated using an Ewald sum.
X
n;o;p6¼0;0;0
r
2ð11lÞ nop Ylmðθnop; φnopÞ
5X0
n;o;p
Ylmðθ; φÞ
ð2l 1 1Þ!
2αðαrnopÞ
0
π3=2 expð2 α2
r
2
nopÞ
1
4 3 2l
ffiffiffi
π p rl11 Il 1 ð2πiÞ
l
r
l22
exp 2 π2r2
nop
α2
0
@
1
A
2
6
6
6
6
6
4
3
7
7
7
7
7
5
; ð5:92Þ
where rnop, θnop, and φnop terms are the spherical coordinates of the vec￾tor rnop 5 dðnx^ 1 oy^ 1 pz^Þ, α is the Ewald convergence parameter, and Il is
given by the recursion relation,
Il 5 2l 1 1
2
Il21 1
1
2
expð2 α2
r2
ÞðαrÞ
2l11 ð5:93Þ
with:
I0 5
ffiffiffi
π p
4 erfcðαrÞ 1 αr
2 expð2 α2
r2
Þ ð5:94Þ
The prime on the sum indicates omission of the n 5 o 5 p 5 0 term. This
enables the contribution of the 26 surrounding cells to be subtracted.
The incorporation of periodic boundary conditions requires minor modifi￾cations to the conventional algorithm. During the initialization phase, the
image mutipole-to-local transformations are created. Stage 3 is modified by
adding the nonzero local expansions for levels r 5 0 and r 5 1, and full mul￾tipole transformations are now required for each local expansion.
How does the efficiency of the FMM algorithm compare with parti￾cleparticle algorithms? The answer to this question depends on the number
of particles in the simulation, the maximum level of refinement, and the
number of mutipoles. Schmidt and Lee (1991) analyzed several different sce￾narios. Typically, the FMM algorithm is advantageous for simulations
involving tens of thousands of molecules.
It should be noted that the FMM algorithm is an active area of research
and improvements in efficiency are being made continually. White and
Head-Gordon (1994) have proposed changes to the transformations that
improves the efficiency of the algorithm. White et al. (1994) have developed
a continuous FMM (CFMM), which uses continuous functions to calculate
charge interactions between particles. The CFMM approach is more efficient
than direct calculations for less than 10,000 or more particles. Kutteh et al.
(1995) have reported a generalized FMM algorithm for HartreeFock and
density functional computations. Efficiency gains have also been reported by
204 Molecular Simulation of FluidsMcKenney et al. (1996). Petersen et al. (1994) have proposed a very FMM
(VFMM). In three dimensions, the VFMM algorithm is two to three times
faster than FMM without any loss of accuracy. Niedermeier and Tavan
(1996) have applied the principles of FMM to the simulation of electrostatic
interaction in proteins. A large-scale simulation of macromolecules have
been reported (Figueirido et al., 1997), which combines the FMM approach
with multiple time step integrators. Wang and LeSar (1996) obtained the
multipole expansions in terms of solid harmonics instead of spherical meth￾ods. They concluded that using solid harmonics greatly increases the compu￾tational efficiency of the FMM algorithm.
The FMM approach is increasingly being applied to a wide variety of
large-scale systems (Andoh et al., 2013; Kurzak and Petititt, 2006), including
the use of polarizable force fields (Coles and Masella, 2015) and application
to dipolar systems (Shamshirgar et al., 2019). Its usefulness is further
enhanced by parallel implementations (Board et al., 1992; Ibeid et al., 2016),
which also include the use of graphics processing units (Kohnke et al., 2020;
Wilson et al., 2021; Yokota et al., 2013). Parallel versions of the FMM algo￾rithm specifically for MD have been reported (Andoh et al., 2013, 2021),
which could facilitate long-time simulations.
The effect of these improvements to the FMM algorithm is that the number
of particles for which FMM codes are more efficient than direct particleparti￾cle evaluation is being progressively lowered. Simple particleparticle algo￾rithms assisted by time-saving devices such as a neighbor list are adequate for
atoms or simple polyatomic molecules involving relatively few particles
(N 1000). However, the rigorous evaluation of the properties of real macromo￾lecules (Cisneros, et al., 2014) by molecular simulation requires thousands of
interaction sites per molecules. Alternative computational strategies are required
to deal with this increased level of complexity. It is in this context that hierar￾chical tree algorithms such as FMM or BarnesHut are likely to play an
increasingly important role in molecular simulation.
5.2.6 Comparison of computational efficiency
There are no definitive studies comparing the computational efficiency and
accuracy of the reaction field, Ewald sum, PPPM, and hierarchical tree meth￾ods. The reaction field method is undoubtedly the simplest to implement
and, when used in conjunction with computation-saving devices such as a
neighbor list, it is an O(N) algorithm. The main limitations of the reaction
field method are that the dielectric constant of the medium must be known,
and there is some evidence to suggest that accuracy is compromised when
highly charged species are involved. The Ewald sum is possibly the most
widely used method for the simulation of charged species. Luty et al. (1994,
1995) have reported comparisons of the Ewald sum with PPPM calculations.
They concluded that the PPPM algorithm was considerably more efficient
Calculating molecular interactions Chapter | 5 205than the Ewald sum, particularly if a large number of charges are involved.
This can be partly attributed to the use of a discrete Fourier transform in the
PPPM method, whereas the Ewald method sums the Fourier series of the
long-range function analytically. Either the PPPM or FMM algorithms can
also be used to calculate efficiently the Coulombic interactions in large bio￾molecules (Shimada et al., 1993, 1994). For nonperiodic systems, the PPPM
method may introduce an artificial periodicity into the system. Techniques
are available (Luty and van Gunsteren, 1996) to overcome this possible limi￾tation. Pollock and Glosli (1996) have reported a comparison of the PPPM,
FMM, and Ewald techniques. They concluded that the PPPM technique was
more efficient computationally than either the FMM or Ewald algorithms.
The O(N) scaling of the FMM algorithms means that it is potentially the
most efficient method but, because of computational overheads, it is cur￾rently viable only for large systems. However, improvements to FMM are
resulting in substantial efficiency gains for increasingly smaller systems,
which are further magnified by parallel implementations.
5.3 Summary
Evaluating either the energy or force experienced by a molecule from inter￾molecular interactions is at the heart of a molecular simulation. Periodic
boundary conditions coupled with long-range corrections are used commonly
to evaluate short-range interactions experienced by nonpolar molecules and
atoms. Computational procedures such as neighbor lists and linked-cell lists
have been developed to reduce the computational overhead. They are partic￾ularly advantageous in MD simulation. Special techniques such as Ewald
sum, reaction field, particlemesh, or tree-based methods are required to cal￾culate the long-range interactions experienced by ions of polar molecules.
Tree-based methods such as the FMM are used less commonly in molecular
simulations because a large number of molecules is required to make them
competitive with traditional approaches. However, the computational limita￾tion is being eroded continually. The process is being further accelerated by
parallel implementations on both traditional multicore and hybrid computing
architectures (Chapter 12).
References
Abramowitz, M., Stegun, I.A. (Eds.), 1972. Handbook of Mathematical Functions with Formula,
Graphs and Mathematical Tables. Dover, New York, p. 295.
Adams, D.J., 1979. Computer simulation of ionic systems: the distorting effects of the boundary
conditions. Chem. Phys. Lett. 62, 329332.
Adams, D.J., McDonald, I.R., 1976. Thermodynamic and dielectric properties of polar lattices.
Mol. Phys. 32, 931947.
Adams, D.J., Adams, E.H., Hills, G.J., 1979. The computer simulation of polar liquids. Mol.
Phys. 38, 387400.
206 Molecular Simulation of FluidsAhmed, A., Sadus, R.J., 2010. Effect of potential truncations and shifts on the solid-liquid phase
coexistence of Lennard-Jones Fluids. J. Chem. Phys. 133, 124515.
Alder, B.J., Pollock, E.L., 1981. Simulation of polar and polarizable fluids. Ann. Rev. Phys.
Chem. 32, 311329.
Allen, M.P., Tildesley, D.J., 2017. Computer Simulation of Liquids, second ed. Oxford
University Press, Oxford.
Alper, H., Levy, R.M., 1993. Dielectric and thermodynamic response of a generalized reaction
field model for liquid state simulations. J. Chem. Phys. 99, 98479852.
Anastasiou, N., Fincham, D., 1982. Programs for the dynamic simulation of liquids and solids II.
MDIONS: rigid ions using the Ewald sum. Comp. Phys. Commun. 25, 159176.
Andoh, Y., Yoshii, N., Fujimoto, K., Mizuntani, K., Kojima, H., Yamada, A., Okazaki, S.,
Kawaguchi, K., Nago, H., Iwahashi, K., Mizutani, F., Minami, K., Ichikawa, S.-I., Komatsu,
H., Ishizuki, S., Takeda, Y., Fukushima, M., 2013. MODYLAS: a highly parallelized
general-purpose molecular dynamics simulation program for large-scale systems with long￾range forces calculated by fast multipole method (FMM) and highly scalable fine-grained
new parallel processing algorithms. J. Chem. Theory Comput. 9, 32013209.
Andoh, Y., Ichikawa, S.-I., Sakashita, T., Yoshii, N., Okazaki, S., 2021. Algorithm to minimize
MPI communications in the parallelized fast multipole method combined with molecular
dynamics. J. Comput. Chem. 42, 10731087.
Andrea, T.A., Swope, W.C., Andersen, H.C., 1983. The role of long ranged forces in determin￾ing the structure and properties of liquid water. J. Chem. Phys. 79, 45764584.
Avendan˜o, C., Gil-Villegas, A., 2006. Monte Carlo simulations of primitive models for ionic
systems using the Wolf method. Mol. Phys. 104, 14751486.
Awile, O., Bu¨yu¨kkec¸eci, F., Reboux, S., Sbalzarini, I.F., 2012. Fast neighbor lists for adaptive￾resolution particle simulations. Comput. Phys. Commun. 183, 10731081.
Baidakov, V.G., Chernykh, G.G., Protsenko, S.P., 2000. Effect of the cut-off radius of the inter￾molecular potential on phase equilibrium and surface tension in LennardJones systems.
Chem. Phys. Lett. 321, 315320.
Ballenegger, V., Cerda, J.J., Lenz, O., Holm, C., 2008. The optimal P3M algorithm for comput￾ing electrostatic energies in periodic systems. J. Chem. Phys. 128, 034109.
Barker, J.A., 1994. Reaction field, screening, and long-range interactions in simulations of ionic
and dipolar systems. Mol. Phys. 83, 10571064.
Barker, J.A., Fisher, R.A., Watts, R.O., 1971. Liquid argon: Monte Carlo and molecular dynam￾ics calculations. Mol. Phys. 21, 657673.
Barnes, J., Hut, P., 1986. A hierarchical O(N log N) force-calculation algorithm. Nature 324,
446449.
Baumketner, A., 2009. Removing systematic errors in interionic potentials of mean force com￾puted in molecular simulations using reaction-field-based electrostatics. J. Chem. Phys. 130,
104106.
Beckers, J.V.L., Lowe, C.P., de Leeuw, S.W., 1998. An iterative PPPM method for simulating
Coulombic systems on distributed memory parallel computers. Mol. Sim. 20, 369383.
Belleman, R.G., Be´dorg, J., Portegies Zwart, S.F., 2008. High performance direct gravitational
N-body simulations on graphics processing units II: an implementation in CUDA. N. Astron
13, 103112.
Benz, W., 1988. Applications of smooth particle hydrodynamics (SPH) to astrophysical pro￾blems. Comp. Phys. Commun. 48, 97105.
Calculating molecular interactions Chapter | 5 207Board Jr, J.A., Causey, J.W., Leathrum Jr, J.F., Windemuth, A., Schulten, K., 1992. Accelerated
molecular dynamics simulation with the parallel fast multipole algorithm. Chem. Phys. Lett.
198, 8994.
Bogusz, S., Cheatham III, T.E., Brooks, B.R., 1998. Removal of pressure and free energy arti￾facts in charged periodic systems via net charge corrections to the Ewald potential. J. Chem.
Phys. 108, 70707084.
Booth, A.D., 1972. Numerical Methods, third ed. Butterworth, London.
Brieu, P.P., Evrad, A.E., 2000. P4M: a parallel version of P3M. New Astron. 5, 163180.
Brown, W.M., Kohlmeyer, A., Plimpton, S.J., Tharrington, A.N., 2012. Implementing molecular
dynamics on hybrid high performance computers  Particleparticle particle-mesh. Comp.
Phys. Commun. 183, 449459.
Carrier, J., Greengard, L., Rokhlin, V., 1988. A fast adaptive multipole algorithm for particle
simulations. SIAM J. Sci. Stat. Comput. 9, 669686.
Cerda`, J.J., Ballenegger, V., Holm, C., 2011. Particle-particle-mesh methods for dipolar interac￾tions: on error estimates and efficiency of schemes with analytical differentiation and mesh
interlacing. J. Chem. Phys. 135, 184110.
Cisneros, G.A., Karttunen, M., Ren, P., Sagui, C., 2014. Classical electrostatics for biomolecular
simulations. Chem. Rev. 114, 779814.
Coelho, A.A., Cheary, R.W., 1997. A fast and simple method for calculating electrostatic poten￾tials. Comp. Phys. Commun. 104, 1522.
Coles, J.P., Masella, M., 2015. The fast multipole method and point dipole moment polarizable
force fields. J. Chem. Phys. 142, 024109.
Cui, Z.W., Sun, Y., Qu, J.M., 2009. The neighbor list algorithm for parallelepiped box in molec￾ular dynamics simulations. Chin. Sci. Bull. 54, 14631469.
Danese, G., de Lotto, I., Dotti, D., Leporati, F., 1998. Ewald potentials evaluated through look￾up tables. Comp. Phys. Commun. 108, 211217.
de Leeuw, S.W., Perram, J.W., Smith, E.R., 1980. Simulation of electrostatic systems in periodic
boundary conditions. I. Lattice sums and dielectric constant. Proc. R. Soc. Lond. A373,
2756.
de Leeuw, S.W., Perram, J.W., Smith, E.R., 1986. Computer simulation of the static dielectric
constant of systems with permanent electric dipoles. Ann. Rev. Phys. Chem. 37, 245270.
Eastwood, J.W., Hockney, R.W., 1974. Shaping the force law in two-dimensional particle-mesh
models. J. Comput. Phys. 16, 342359.
Eastwood, J.W., Hockney, R.W., Lawerence, D., 1980. P3M3DP - the three dimensional periodic
particle-particle/particle-mesh program. Comp. Phys. Commun. 19, 215261.
English, N.J., 2005. Molecular dynamics simulations of liquid water using various long-range
electrostatic techniques. Mol. Phys. 103, 19451960.
Essex, J.W., 1998. The application of the reaction-field method to the calculation of dielectric
constants. Mol. Sim. 20, 159178.
Everaers, R., Kremer, K., 1994. A fast grid search algorithm for molecular dynamics simulations
with short-range interactions. Comp. Phys. Commun. 81, 1955.
Ewald, P., 1921. Die Berechnung optischer und elektrostatischer Gitterpotentiale. Ann. Phys.
64, 253287.
Fanourgakis, G.S., Tipparaju, V., Nieplocha, J., Xantheas, S.S., 2007. An efficient parallelization
scheme for molecular dynamics simulations with many-body, flexible, polarizable empirical
potentials: application to water. Theor. Chem. Acc. 117, 7384.
208 Molecular Simulation of FluidsFigueirido, F., Levy, R.M., Zhou, R., Berne, B.J., 1997. Large scale simulation of macromole￾cules in solution: combing the periodic fast multipole method with multiple time step inte￾grators. J. Chem. Phys. 106, 98359849.
Fincham, D., 1994. Optimisation of the Ewald sum for large systems. Mol. Sim. 13, 19.
Fincham, D., Ralston, B.J., 1981. Molecular dynamics simulation using the CRAY-1 vector pro￾cessing computer. Comp. Phys. Commun. 23, 127134.
Fomin, E.S., 2011. Consideration of data load time on modern processors for the Verlet
table and linked-cell algorithms. J. Comput. Chem. 32, 13861599.
Frenkel, D., Smit, B., 2023. Understanding Molecular Simulation. From Algorithms to
Applications, second ed. Academic Press, San Diego, p. 635.
Gan, Z.C., Xu, Z.L., 2014. Efficient implementation of the Barnes-Hut octree algorithm for
Monte Carlo simulations of charged systems. Sci. China Math. 57, 13311340.
Gargallo, R., Hu¨nenberger, P.H., Avile´s, F.X., Oliva, B., 2003. Molecular dynamics simulation
of highly charged proteins: comparison of the particle-particle particle-mesh and reaction
field methods for the calculation of electrostatic interactions. Protein Sci. 12, 21612172.
Garzon, B., Lago, S., Vega, C., 1994. Reaction field simulations of the vapor-liquid equilibria of
dipolar fluids. Does the reaction field dielectric constant affect the coexistence properties?
Chem. Phys. Lett. 231, 366372.
Gdoutos, E.E., Agrawal, R., Espinosa, H.D., 2010. Comparison of the Ewald and Wolf methods
for modeling electrostatic interactions in nanowires. Int. J. Numer. Meth. Engng 84,
15411551.
Gonnet, P., 2013. Pseudo-Verlet lists: a new, compact neighbour list representation. Mol. Sim.
39, 721727.
Greengard, L., 1987. The Rapid Evaluation of Potential Fields in Particle Systems. MIT Press,
Cambridge, MA.
Greengard, L., Rokhlin, V., 1987. A fast algorithm for particle simulations. J. Comput. Phys. 73,
325348.
Grest, G.S., Du¨nweg, B., Kremer, K., 1989. Vectorised link cell FORTRAN code for molecular
dynamics simulations of large number of particles. Comp. Phys. Commun. 55, 269285.
Heinz, T.M., Hu¨nenberger, P.H., 2004. A fast pairlist-construction algorithm for molecular simu￾lations under periodic boundary conditions. J. Comput. Chem. 25, 14741486.
Hernquist, L., 1988. Hierarchical N-body methods. Comp. Phys. Commun. 48, 107115.
Hernquist, L., 1990. Vectorization of tree traversals. J. Comput. Phys. 87, 137147.
Heyes, D.M., 1981. Electrostatic potentials and fields in infinite point charge lattices. J. Chem.
Phys. 74, 19241929.
Hloucha, M., Deiters, U.K., 1997. Monte Carlo simulations of acetonitrile with an anisotropic
polarizable molecular model. Mol. Phys. 90, 593597.
Hockney, R.W., Eastwood, J.W., 1988. Computer Simulation Using Particles. Adam Hilger,
Bristol.
Houssa, M., Oualid, A., Rull, L.F., 1998. Reaction field and Ewald summation study of meso￾phase formation in dipolar Gay-Berne model. Mol. Phys. 94, 439446.
Huang, C., Li, C., Choi, P.Y.K., Nandakumarc, K., Kostiuk, L.W., 2010. Effect of cut-off dis￾tance used in molecular dynamics simulations on fluid properties. Mol. Sim. 36, 856864.
Hunt, T.A., Todd, B.D., 2003. On the Arnold cat map and periodic boundary conditions for pla￾nar elongational flow. Mol. Phys. 101, 34453454.
Ibeid, H., Yokota, R., Keyes, D., 2016. A performance model for the communication in fast mul￾tipole methods on high-performance computing platforms. Int. J. High. Perform. Comput.
Appl. 30, 423437.
Calculating molecular interactions Chapter | 5 209Iwasawa, M., Namekata, D., Sakamoto, R., Makamura, T., Kimura, Y., Nitadori, K., Wang, L.,
Tsubouchi, M., Makino, J., Liu, Z., Fu, H., Yang, G., 2020. Int. J. High. Perform. Compt.
Appl. 34, 615628.
Jackson, J.D., 1983. Classical Electrodynamics. Wiley, New York.
Jernigham, J.G., Porter, D.H., 1989. A tree code with logarithmic reduction of force terms, hier￾archical regularization of all variables, and explicit accuracy controls. Astrophys. J. Suppl.
Ser. 71, 871893.
Karelson, M., Tamm, T., Zerner, M., 1993. Multicavity reaction field method for the solvent
effect description in flexible molecular systems. J. Phys. Chem. 97, 1190111907.
Kessler, J., Bour, P., 2014. Molecular dynamics with helical periodic boundary conditions.
J. Comput. Chem. 35, 15521559.
Kohnke, B., Kutzner, C., Beckmann, A., Lube, G., Kabadshow, I., Dachsel, H., Grubmu¨ller, H.,
2020. High. Perform. Comput. Appl. 35, 97117.
Kurzak, J., Petititt, B.M., 2006. Fast multipole methods for particle dynamics. Mol. Sim. 32,
775790.
Kutteh, R., Apra`, E., Nichols, J., 1995. A generalized fast multipole approach for Hartree-Fock
and density functional computations. Chem. Phys. Lett. 238, 173179.
Lee, S.H., 2020. Ionic mobilities of Na1 and Cl2 at 25C as a function of Ewald sum parameter:
A comparative molecular dynamics simulation study. Mol. Sim. 46, 262270.
Lekner, J., 1998. Coulomb forces and potentials in systems with an orthorhombic unit cell. Mol.
Sim. 20, 357368.
Lindbo, D., Tornberg, A.-K., 2012. Fast and spectrally accurate Ewald summation for 2-periodic
electrostatic systems. J. Chem. Phys. 136, 164111.
Luo, J., Liu, L., Su, P., Duan, P., Lu, D., 2015. A piecewise lookup table for calculating non￾bonded pairwise atomic interactions. J. Mol. Model. 21, 288290.
Luty, B.A., van Gunsteren, W.F., 1996. Calculating electrostatic interactions using the particle￾particle particle-mesh method with nonperiodic long-range interactions. J. Phys. Chem. 100,
25812587.
Luty, B.A., Davis, M.E., Tironi, I.G., van Gunsteren, W.F., 1994. A comparison of particle￾particle, particle-mesh (PPPM) and Ewald methods for calculating electrostatic interactions
in periodic molecular systems. Mol. Sim. 14, 1120.
Luty, B.A., Tironi, I.G., van Gunsteren, W.F., 1995. Lattice-sum methods for calculating electro￾static interactions in molecular systems. J. Chem. Phys. 103, 30143021.
Ma, Y., Garofalini, S.H., 2005. Modified Wolf electrostatic summation: Incorporating an empiri￾cal charge overlap. Mol. Sim. 31, 739748.
Matin, M.L., Daivis, P.J., Todd, B.D., 2003. Cell neighbor list method for planar elongational
flow: Rheology of a diatomic fluid. Comp. Phys. Commun. 151, 3546.
McKenney, A., Pachter, R., Patnaik, S., Adams, W., 1996. Molecular dynamics simulations of a
siloxane-based liquid crystal using an improved fast multipole algorithm implementation.
Mat. Res. Soc. Symp. Proc. 408, 99105.
Mendoza, F.N., Lo´pez-Lemus, J., Chapela, G.A., Alejandre, J., 2008. The Wolf method applied
to the liquid-vapor interface of water. J. Chem. Phys. 129, 024706.
Milchev, A., Paul, W., Binder, K., 1993. Off-lattice Monte Carlo simulation of dilute and con￾centrated polymer solutions under theta conditions. J. Chem. Phys. 99, 47864798.
Millot, C., Soetens, J.C., Costa, M.T.C.M., 1996. Static dielectric constant of the polarizable
Stockmayer fluid. Comparison of lattice summation and reaction field methods. Mol. Sim.
18, 367383.
210 Molecular Simulation of FluidsMorales, J.J., 1996. Computer dependence of an improvement of the cell neighbour-table method
for short-range potentials. Mol. Sim. 18, 325337.
Munier, B., Aleem, M., Khan, M., Islam, M.A., Iqbal, M.I., Khattak, K., 2020. On the paralleli￾zation and performance analysis of Barnes-Hut algorithm using Java parallel platforms. SN
Appl. Sci. 2, 601.
Ni, B., Baumketner, A., 2011. Effect of atom- and group-based truncations on biomolecules sim￾ulated with reaction-field electrostatics. J. Mol. Model. 17, 28832893.
Niedermeier, C., Tavan, P., 1996. Fast version of the structure adapted multipole method - effi￾cient calculation of electrostatic forces in protein dynamics. Mol. Sim. 17, 5766.
Nozawa, T., Takahashi, K.Z., Narumi, T., Yasuoka, K., 2015. Comparison of the accuracy of
periodic reaction field methods in molecular dynamics simulations of a model liquid crystal
system. J. Comput. Chem. 36, 24062411.
Nymand, T.M., Linse, P., 2000. Ewald summation and reaction field methods for potentials with
atomic charges, dipoles, and polarizabilities. J. Chem. Phys. 112, 61526160.
Omelyan, I.P., 1996. On the reaction field for interaction site models of polar systems. Phys.
Lett. A 223, 295302.
Omelyan, I.P., 1997. Ewald summation technique for interaction site models of polar fluids.
Comp. Phys. Commun. 107, 113122.
Petersen, H.G., Soelvason, D., Perram, J.W., Smith, E.R., 1994. The very fast multipole method.
J. Chem. Phys. 101, 88708876.
Pfalzner, S., Gibbon, P., 1996. Many-Body Tree Methods in Physics. Cambridge University
Press, Cambridge.
Pinches, M.R.S., Tildesley, D.J., Smith, W., 1996. In: Gubbins, K.E., Quirke, N. (Eds.),
Molecular Simulation and Industrial Applications. Methods, Examples and Properties.
Gordon and Breach, Amsterdam.
Pollock, E.L., Glosli, J., 1996. Comments on P3
M, FMM, and the Ewald method for large peri￾odic Coulombic systems. Comp. Phys. Commun. 95, 93110.
Polyakov, A.Y., Lyutyy, T.V., Denisov, S., Reva, V.V., Ha¨nggi, P., 2013. Large-scale ferrofluid
simulations on graphics processing units. Comp. Phys. Commun. 184, 14831489.
Quentrec, B., Brot, C., 1973. New method for searching for neighbors in molecular dynamics
computations. J. Comput. Phys. 13, 430432.
Rapaport, D.C., 2004. The Art of Molecular Dynamics Simulation, second ed. Cambridge
University Press, Cambridge.
Reed, M.S.C., Flurchick, K.M., 1996. Investigation of artifacts due to periodic boundary condi￾tions. Comp. Phys. Commun. 95, 3946.
Rein, H., Liu, S.-F., 2012. REBOUND: an open-source multi-purpose N-body code for colli￾sional dynamics. Astron. Astrophys. 537, A128.
Resat, H., McCammon, J.A., 1998. Correcting for electrostatic cutoffs in free energy simula￾tions: toward consistency between simulations with different cutoffs. J. Chem. Phys. 108,
96179623.
Ruocco, G., Sampoli, M., 1994. Computer simulation of polarizable fluids: a consistent and fast
way for dealing with polarizability and hyperpolarizability. Mol. Phys. 82, 875886.
Ruocco, G., Sampoli, M., 1995. Computer simulation of polarizable fluids: on the determination
of the induced dipoles. Mol. Sim. 15, 281300.
Sadeghifar, A., Dadvar, M., Karimi, S., Ghobadi, A.F., 2012. The Wolf method applied to the
type I methane and carnon dioxide hydrates. J. Mol. Graph. Model. 38, 455464.
Calculating molecular interactions Chapter | 5 211Sakurai, M., Tamagawa, H., Inoue, Y., Ariga, K., Kunitake, T., 1997. Theoretical study of inter￾molecular interaction at the lipid-water interface. 1. Quantum chemical analysis using a
reaction field theory. J. Phys. Chem. B 101, 48104816.
Schmidt, K.E., Lee, M.A., 1991. Implementing the fast multipole method in three dimensions.
J. Stat. Phys. 63, 12231235.
Shamshirgar, D.S., Yokota, R., Tornberg, A.-K., Hess, B., 2019. Regularizing the fast multipole
method for use in molecular simulation. J. Chem. Phys. 151, 234113.
Shimada, J., Kaneko, H., Takada, T., 1993. Efficient calculations of Coulombic interactions in
biomolecular simulations with periodic boundary conditions. J. Comput. Chem. 14,
867878.
Shimada, J., Kaneko, H., Takada, T., 1994. Performance of fast multipole methods for calculat￾ing electrostatic interactions in biomacromolecular simulations. J. Comput. Chem. 15,
2843.
Sidler, D., Frasch, S., Cristo`fol-Clough, M., Riniker, S., 2018. Anisotropic reaction field correc￾tion for long-range electrostatic interactions in molecular dynamics simulations. J. Chem.
Phys. 148, 234105.
Sirk, T.W., Moore, S., Brown, E.F., 2013. Characteristics of thermal conductivity in classical
water models. J. Chem. Phys. 138, 064505.
Skeel, R.D., 2016. An alternative construction of the Ewald sum. Mol. Phys. 114, 31663170.
Smith, W., 1992. A replicated data molecular dynamics strategy for parallel Ewald sum. Comp.
Phys. Commun. 67, 392406.
Smith, P.E., van Gunsteren, W.F., 1995. Reaction field effects on the simulated properties of liq￾uid water. Mol. Sim. 15, 233245.
Sperb, R., 1998. An alternative to Ewald sums. Part 1. Identities for sums. Mol. Sim. 20,
179200.
Stenhammar, J., Linse, P., Karlstro¨m, G., 2009. Nondielectric long-range solvation of polar
liquids in cubic symmetry. J. Chem. Phys. 131, 164507.
Stransky, M., 2016. Monte Carlo simulations of ionization potential depression in dense plasmas.
Phys. Plasmas 23, 012708.
Sutmann, G., Stegailov, V., 2006. Optimization of neighbor list techniques in liquid matter simu￾lations. J. Mol. Liq. 125, 197203.
Tironi, I.G., Sperb, R., Smith, P.E., van Gunsteren, W.F., 1995. A generalized reaction field
method for molecular dynamics simulations. J. Chem. Phys. 102, 54515459.
Tironi, I.G., Luty, B.A., van Gunsteren, W.F., 1997. Space-time correlated reaction field. A sto￾chastic dynamical approach to the dielectric continuum. J. Chem. Phys. 106, 60686075.
Todd, B.D., Daivis, P.J., 1998. Nonequilibrium molecular dynamics simulations of planar elon￾gational flow with spatially and temporally periodic boundary conditions. Phys. Rev. Lett.
81, 11181121.
Tornberg, A.-K., 2016. The Ewald sums for singly, doubly and triply periodic electrostatic sys￾tems. Adv. Comput. Math. 42, 227248.
Tuckerman, M.E., 2010. Statistical Mechanics: Theory and Molecular Simulation. Oxford
University Press, Oxford.
Verlet, L., 1967. Computer “experiments” on classical fluids. I. thermodynamical properties of
Lennard-Jones molecules. Phys. Rev. 159, 98103.
Villarreal, M.A., Montich, G.G., 2005. On the Ewald artifacts in computer simulations. The test￾case of the octaalanine peptide with charged termini. J. Biomol. Struct. Dyn. 23, 135142.
Waibel, C., Feinler, M.S., Gross, J., 2019. A modified shifted force approach to the Wolf sum￾mation. J. Chem. Theory Comput. 15, 572583.
212 Molecular Simulation of FluidsWallace, J.A., Shen, J.K., 2012. Charge-leveling and proper treatment of long-range electrostat￾ics in all-atom molecular dynamics at constant pH. J. Chem. Phys. 137, 184105.
Wang, S.S., Krumhansl, J.A., 1972. Superposition approximation. II. High density fluid argon.
J. Chem. Phys. 56, 42874290.
Wang, H.Y., LeSar, R., 1996. An efficient fast-multipole algorithm based on expansion in the
solid harmonics. J. Chem. Phys. 104, 41734179.
Wang, D.-B., Hsiao, F.-B., Chuang, C.-H., Lee, Y.-C., 2007. Algorithm optimization in molecu￾lar dynamics simulation. Comp. Phys. Commun. 177, 551559.
Wassenaar, T.A., Mark, A.E., 2006. The effect of box shape on the dynamic properties of pro￾teins simulated under periodic boundary conditions. J. Comput. Chem. 27, 316325.
Watanabe, H., Suzuki, M., Ito, N., 2011. Efficient implementations of molecular dynamics simu￾lations for Lennard-Jones systems. Prog, Theor. Phys. 126, 203235.
Welling, U., Germano, G., 2011. Efficiency of linked Verlet algorithms. Comp. Phys. Commun.
182, 611615.
Wells, B.A., Chaffee, A.L., 2015. Ewald summation for molecular simulations. J. Chem. Theory
Comput. 11, 36843695.
White, C.A., Head-Gordon, M., 1994. Derivation and efficient implementation of the fast multi￾pole method. J. Chem. Phys. 101, 65936605.
White, C.A., Johnson, B.G., Gill, P.M.W., Head-Gordon, M., 1994. The continuous fast multi￾pole method. Chem. Phys. Lett. 230, 816.
White, J.A., Roman, F.L., Gonz ´ alez, A., Velasco, S., 2008. Periodic boundary conditions and the ´
correct molecular-dynamics ensemble. Phys. A 387, 67056711.
Wilson, K., Vaughn, N., Krasny, R., 2021. A GPU-accelerated fast multipole method based on
barycentric Lagrange interpolation and dual tree traversal. Comp. Phys. Commun. 265,
108017.
Winkel, M., Speck, R., Hu¨bner, H., Arnold, L., Krause, R., Gibbon, P., 2012. A massively paral￾lel, multi-disciplinary Barnes-Hut tree code for extreme-scale N-body simulations. Comp.
Phys. Commun. 183, 880889.
Wolf, D., 1992. Reconstruction of NaCl surfaces from a dipolar solution to the Madelung prob￾lem. Phys. Rev. Lett. 68, 33153318.
Wolf, D., Keblinski, P., Phillpot, S.R., Eggebrecht, J., 1999. Exact method for the simulation of
Coulombic systems by spherically truncated, pairwise r21 summation. J. Chem. Phys. 110,
82548282.
Woodcock, L.V., Singer, K., 1971. Thermodynamic and structural properties of liquid ionic salts
obtained by Monte Carlo computation. Trans. Faraday Soc. 67, 1230.
Yao, Y., Capecelatro, J., 2021. An accurate particle-mesh method for simulating charged parti￾cles in wall-bounded flows. Powder Tech. 387, 239250.
Yao, Z., Wang, J.-S., Liu, G.-R., Cheng, M., 2004. Improved neighbor list algorithm in molecu￾lar simulations using cell decomposition and data sorting method. Comp. Phys. Commun.
161, 2735.
Yokota, R., Barba, L.A., Narumi, T., Yasuoka, K., 2013. Comp. Phys. Commun. 184, 445455.
Zhang, X., Bridson, R., 2014. A PPPM fast summation method for fluids and beyond. ACM
Trans. Graph. 33, 206.
Zhou, Z., Payne, P., Vasquez, M., Kuhn, N., Levitt, M., 1996. Finite-difference solution of the
Poisson-Boltzmann equation. Complete elimination of self-energy. J. Comput. Chem. 17,
13441351.
Calculating molecular interactions Chapter | 5 213This page intentionally left blankChapter 6
Monte Carlo simulation
The Monte Carlo (MC) method is a stochastic strategy that relies on probabili￾ties. To simulate fluids, transitions between different states or configurations
are achieved by (1) generating a random trial configuration; (2) evaluating an
“acceptance criterion” by calculating the change in energy and other properties
in the trial configuration; and (3) comparing the acceptance criterion to a ran￾dom number and either accepting or rejecting the trial configuration.
It is important to realize that not all states will make a significant contri￾bution to the configurational properties of the system. To accurately deter￾mine the properties of the system in the finite time available for the
simulation, it is important to sample those states that make the most signifi￾cant contributions. This is achieved by generating a Markov chain, which is
a sequence of trials in which the outcome of successive trials depends only
on the immediate predecessor. In a Markov chain, a new state will only be
accepted if it is more “favorable” than the existing state. In the context of a
simulation using an ensemble, this usually means that the new trial state is
lower in energy.
A MC simulation samples from a 3N-dimensional space represented by
the positions of particles. Unlike molecular dynamics (MD) methods
(Chapter 7), particle momenta are not involved. It is not necessary to know
particle momenta to calculate thermodynamic properties because the
momenta contribute exclusively to the ideal gas term. Deviations from ideal
gas behavior are caused by interactions between particles, which can be cal￾culated from a potential energy function (Chapters 3 and 4). The potential
energy depends only on the positions of atoms and not on their momenta. In
effect, a MC simulation calculates the residual thermodynamic properties
(Chapter 2) that result in deviations from ideal gas behavior. The appropriate
ideal gas term can be simply added at the conclusion of the simulation to
obtain the total thermodynamic property.
The general underlying principles of the MC method that underpin its use
in molecular simulation have been examined by Hammersley and
Handscomb (1964), Sobol (1994), Sabelfeld (1991), and Moony (1997).
Gilks et al. (1996) have detailed the importance of the Markov chain in MC
processes. A very broad range of MC methods have been documented by
Kroese and Rubinstein (2011) and Kroese et al. (2011). Binder (1995a),
215 Molecular Simulation of Fluids. DOI: https://doi.org/10.1016/B978-0-323-85398-9.00004-6
© 2024 Elsevier B.V. All rights reserved.Binder and Heermann (1997), Newman and Barkema (1999), and Landau
and Binder (2000) have discussed MC in the context of the statistical physics
relevant to molecular simulation. Binder (1997) has reviewed the application
of the MC methods to problems in statistical physics in general. Many
molecular simulation applications of MC have been detailed by Ferguson
et al. (1999), and MC algorithms for polymers have been addressed by
Binder (1995b). Descriptions of MC algorithms also form part of other texts
(Allen and Tildesley, 2017; Berendsen, 2007; Hansen and McDonald, 2013;
Heermann, 1990; Frenkel and Smit, 2023; Tuckerman, 2010).
In this chapter, the theoretical basis of MC simulations is discussed with
emphasis on contemporary techniques. Algorithms for phase equilibria are
detailed separately in Chapter 10. It should be noted that the application of
MC algorithms is ensemble dependent. Sampling in the various ensembles is
discussed in detail in Chapter 9.
6.1 Basic concepts
6.1.1 Background
The average of any thermodynamic property AðrNÞ   can be obtained by
evaluating the following multidimensional integral over the 3 N degrees of
freedom on the N particles in the system,
AðrNÞ   5
ð
AðrNÞρðrNÞdrN; ð6:1Þ
where ρðrNÞ is the probability of obtaining configuration rN, which depends
on the potential energy (U) of the configuration,
ρðrNÞ 5 exp 2βUðrNÞ  
ð
exp 2βUðrN ½ Þ drN
ð6:2Þ
and β 5 1/kT, where T denotes temperature and k is Boltzmann’s constant. These
integrals cannot be evaluated analytically, and conventional methods of integra￾tion are also not feasible. For example, to apply either Simpson’s rule or the tra￾pezium rule to evaluate a 3N-dimensional integral would require m3N function
evaluations, where m is the number of points required to determine the integral
in each dimension. The MC solution is to generate a large number of trial config￾urations r
N and replace the integrations by summations over a finite number of
configurations. If the configurations are chosen randomly, Eq. (6.1) becomes:
AðrNÞ   5
N
Ptrial
i51
AiðrNÞexp 2βUiðrNÞ  
N
Ptrial
i51
exp 2βUiðrN ½ Þ
ð6:3Þ
216 Molecular Simulation of FluidsIn practice, this simple approach is not feasible because random sampling
yields many configurations, which have a very small Boltzmann factor. Such
configurations make very little contribution to the average. Therefore, a pro￾hibitively large number of configurations are required to obtain the correct
answer.
6.1.2 Metropolis sampling and Markov chains
The limitations of random sampling can be avoided by generating configura￾tions that make a large contribution to the right-hand side of Eq. (6.3). This
is the philosophy behind Metropolis sampling (Metropolis et al., 1953).
Metropolis sampling biases the generation of configurations toward those
that make the most significant contribution to the integral. It generates states
with a probability of exp[-βU(rN)] and counts each of them equally. In con￾trast, simple MC integration generates states with equal probability assigning
them a weight of exp[-βU(rN)].
Metropolis sampling generates a Markov chain, which satisfies the con￾ditions, that (1) the outcome of each trial depends only on the proceeding
trail and (2) each trail belongs to a finite set of possible outcomes. The for￾mer condition highlights the distinction between MC and MD simulation
(Chapter 7) methods. In a MD simulation, all the states are connected in
time. Metropolis et al. (1953) showed that a transition probability matrix
that ensures Eq. (6.2) is obeyed,
πmn 5 Cmn
ρn
ρm
$ 1; m 6¼ n
πmn 5 Cmn
ρn
ρm
0
@
1
A
ρn
ρm
, 1; m 6¼ n
9
>>>>=
>>>>;
; ð6:4Þ
where ρm and ρn are the probability densities for states m and n given by
Eq. (6.2) and Cmn is the conditional probability of choosing n as the trial
state. The calculation of the integral in the denominator of Eq. (6.2) is not
required because Eq. (6.4) only involves the ratio of the probability densities.
Furthermore,
X
n
πmn 5 1 ð6:5Þ
ρmπmn 5 ρnπnm ð6:6Þ
The Metropolis scheme is implemented by attempting a trial displace￾ment and calculating the change in energy ΔU 5 Un 2 Um. If ΔU , 0, then
(ρn=ρm) . 1, and the move is accepted. Otherwise, if ΔU . 0, (ρn=ρm) ,1
and the move is accepted with a probability of (ρn=ρm) 5 exp(-βΔU). A ran￾dom number R is generated and the move is accepted if exp(-βΔU) $ R.
Monte Carlo simulation Chapter | 6 217Typically, this procedure is summarized by defining the probability of accep￾tance as:
p 5 min 1½  ; expð2 βΔUÞ ð6:7Þ
It should be noted that Eq. (6.7) only represents the acceptance criteria
resulting from molecular displacement. A different criterion is required as a
result of either a volume change or a change in a number of particles. The cri￾teria for accepting different types of moves are discussed in Chapter 9 in the
context of MC algorithms for different ensembles. Efficiency issues relating to
the Metropolis algorithm are discussed elsewhere (Stedman et al., 1998).
ALGORITHM 6.1 Basic MC procedure for accepting changes in atomic
displacements.
Part 1 loop cycle 1 ... maxCycle
Part 2 Attempt trial displacements:
loop atom 1 ... maxAtom
Part 2.1 Generate a trial displacement: 
rxTrial pbc(rxatom + (2  rand() - 1)  dMax) 
ryTrial pbc(ryatom + (2  rand() - 1)  dMax) 
rzTrial pbc(rzatom + (2  rand() - 1)  dMax) 
Part 2.2 Calculate change in energy: 
 Calculate energy of the atom (UTrial) at trial position.
U UTrial - Uatom
Part 2.3 Apply Metropolis acceptance criterion: 
if (U < 0 or exp(-U)  rand()) 
rxatom rxTrial //accept move 
ryatom ryTrial
rzatom rzTrial 
 Uatom UTrial
U U + U
 numAccept numAccept + 1 
end if
end atom loop
Part 2.4 Update periodically the maximum displacement: 
if (mod(cycle, updateCycle) = 0) 
acceptRatio numAccept/(cycle  atomMax) 
if (acceptRatio > 0.5) 
dMax 1.05  dMax
else
dMax 0.95  dMax
 end if
end if
 end cycle loop 















Application of the Metropolis method is illustrated by Algorithm 6.1. Typically,
a MC simulation is performed in cycles (Algorithm 6.1, Part 1). During each cycle,
a displacement is attempted for every atom (Algorithm 6.1, Part 2). The atom to be
218 Molecular Simulation of Fluidsdisplaced can be chosen randomly or alternatively, each atom can be considered
in turn as illustrated in Algorithm 6.1. It is also possible to displace every atom
and apply the acceptance criterion to the combined move. New trial coordinates
(Algorithm 6.1, Part 2.1) are obtained randomly up to a maximum value of
dMax. This involves generating random numbers on the interval from 0 to 1 and
applying periodic boundary conditions (pbc). The change in energy resulting
from the trial displacement (Algorithm 6.1, Part 2.2) is simply the energy expe￾rienced by the atom at the trial position (Utrial) minus the energy of the atom at
its existing position (Uatom). This change in energy is evaluated and the
Metropolis acceptance (Algorithm 6.1, Part 2.3) rule is applied. If the move is
accepted, the atom’s coordinates, the atom’s energy, and the total energy (U) are
updated. The maximum allowed displacement (dMax) affects the acceptance
rate. Experience indicates that an acceptance rate of approximately 50% is often
desirable for a MC simulation. A small value of dMax will generally improve
the acceptance rate but the phase space of the liquid may be sampled too slowly.
Conversely, increasing the value of dMax will reduce the acceptance rate. It is
common to adjust the value of dMax during the course of the simulation to main￾tain a 50% acceptance rate. In Algorithm 6.1 (Part 2.4), the value of dMax is
adjusted at intervals specified by updateCycle. If acceptRatio . 0.5, the value of
dMax is increased, whereas it is decreased if acceptRatio , 0.5.
It should be noted that there is no theoretical basis for using an accep￾tance rate of 50% and in some cases it may be actually detrimental to effi￾cient sampling. Mountain and Thirumalai (1994) proposed an algorithm for
determining the efficiency of MC simulations. They reported that an accep￾tance ratio of 20% was twice as efficient in generating a satisfactory sample
as compared with the traditional acceptance rate of 50%. Therefore, it may
be advantageous to first establish the optimal acceptance rate from short
exploratory MC simulations.
6.2 Application to molecules
As illustrated by Algorithm 6.2 and discussed previously, application of the
MC method to atoms is straightforward. However, the treatment of poly￾atomic molecules requires us to consider bond rotation in addition to transla￾tional motion.
6.2.1 Rigid molecules
The usual approach adopted for the MC simulation of rigid molecules is to
combine translation and rotation of one molecule. The translational move is
obtained by displacing randomly the center of mass of a molecule along
each of its axes. The rotational move involves attempting a random change
of the Euler angles ϕ, θ, and ψ that define molecular orientation (Chapter 6).
Monte Carlo simulation Chapter | 6 219For a rigid molecule of arbitrary geometry, trial changes to the Euler angles
can be obtained from:
φtrial 5 φ 1 ð2R1 2 1ÞΔφmax ð6:8Þ
cosθtrial 5 cosθ 1 ð2R2 2 1ÞΔðcosθÞmax ð6:9Þ
ψtrial 5 ψ 1 ð2R3 2 1ÞΔψmax ð6:10Þ
Δφmax, ðcosθÞmax, and Δψmax are the maximum allowed changes in the Euler
angles and R1, R2, and R3 are random numbers between 0 and 1. Notice that
in Eq. (6.9), a random change is made to cosθ rather than θ. Sampling in cosθ
is used to achieve a uniform distribution of points. Following the attempted
translationrotational move, the energy experienced by the molecule in its
trial position is calculated and the combined move is accepted with a probabil￾ity given by Eq. (6.7). It should be noted that in the case of a linear rigid mol￾ecule, only Eq. (6.9) is required because the other Euler angles are unaffected.
There are alternatives to the above procedure. For example, Barker and
Watts (1969) proposed a method for rotating the whole molecule.
Furthermore, the use of Euler angles can be avoided by using the quaternion
approach (Chapter 7). If quaternions are used, a new orientation is generated
by rotating the quaternion vector to a new random orientation (Veseley,
1982). The application of these techniques is described elsewhere (Allen and
Tildesley, 2017; Leach, 2001; Tildesley, 1993).
6.2.2 Small flexible molecules
The technique used for rigid molecules can be extended with minor modifica￾tion (Tildesley, 1993) to flexible molecules of moderate size such as n-butane.
A trial configuration is generated by (1) displacing the head atom; (2) chang￾ing the molecular orientation by making random changes to the Euler angles;
and (3) changing the conformation by making a random change to the tor￾sional angle χ in the range 0 to 2π. The trial configuration is accepted with a
probability given by Eq. (6.7), where the change in energy now includes con￾tributions from both intermolecular and intramolecular potentials.
6.2.3 Polymers
There is considerable interest in the application of MC algorithms (Binder
1995a,b) to determine the properties of large molecules such as polymers. In
principle, the approach used for small flexible molecules could be extended to
polymers. However, the practice of changing randomly the torsional angle is
likely to lead to a high rejection rate. Even a relatively small change in the tor￾sional angle in the middle of a large flexible molecule is likely to result in a
large translational displacement of the terminal atoms. Consequently, there is a
high probability of molecular overlap resulting in the rejection of the move.
220 Molecular Simulation of FluidsAnother limitation of the small flexible molecule approach is that determining
Euler angles or using quaternion ions for each atom of a large molecule
requires considerable computational effort. Instead, specific MC algorithms
have been developed to model molecular chains. Some commonly used algo￾rithms are described subsequently. Comprehensive reviews of alternative algo￾rithms are available elsewhere (Binder, 1995a,b).
6.2.3.1 The reptation or slithering snake algorithm
Wall and Mandel (1975) proposed an algorithm that propagates a chain in the
fashion of a slithering snake. The motion is alternatively described as “repta￾tion” (de Gennes, 1971). The reptation algorithm was originally devised for a
lattice polymer but it can be used also for an off-lattice polymer. A freely
jointed linear polymer consists of p 1 1 monomers, and p links. The reptation
algorithm propagates the polymer via a four-stage process:
Stage 1: One end of the chain is chosen randomly to be the head of the
chain, for example, atom 1.
Stage 2: The tail link and the corresponding tail atom p 1 1 is removed.
The tail link is attached to the head of the chain at a randomly
chosen orientation.
Stage 3: The change in energy is calculated as ΔU 5 U1(trial)Up11(old),
which is the energy difference for swapping the tail atom to a new
head position.
Stage 4: The move is accepted by applying Eq. (6.7).
The effect of this algorithm is to generate a slithering motion as illus￾trated by Fig. 6.1. The random choice of the head and tail atoms is important
to avoid the chain being locked with the head unable to move because of
potential overlap with neighboring molecules. This algorithm has been
applied to polymers on a three-dimensional lattice (Wall et al., 1977) and to
continuum fluids (Bishop et al., 1980; Brender and Lax, 1983).
FIGURE 6.1 Illustration of a trial move using the reptation algorithm.
Monte Carlo simulation Chapter | 6 221The application of the reptation algorithm is restricted generally to open
linear chains characterized by free end units. Various modifications and
improvements to the basic reptation algorithm have been proposed. Murat and
Witten (1990) generalized the reptation algorithm by allowing the removal of
an arbitrary monomer and replacing it randomly elsewhere in the chain. The
two neighbors of the removed monomer are connected by a new bond. If the
new bond is longer than the maximum bond length, the move is rejected. If
the removal is allowed, an attempt is made to reconnect the removed mono￾mer elsewhere. A collective reptation method has been reported (Pakula,
1987; Pakula and Geyler, 1987; Geyler et al., 1990; Reiter et al., 1990), which
involves a conventional reptation of a kink-jump algorithm (see subsequent
discussion) to one chain followed by specific rearrangements of other chains.
The rearrangements of other chains potentially remove excluded volume vio￾lations caused by the first move chain.
Variations on the general reputation algorithm have proved particularly
useful in the MC investigation of the properties of polymers (Foo and
Pandey, 2000; Kreer et al., 2001; Terranova et al., 2007), particularly when
lattice dynamics (Hua and Ke, 2005) is involved. Improvements include
adaptations (Santos et al., 2001; Uhlherr et al., 2002) for parallel execution.
The general principles have been applied to specific polymer mixtures
(Gharibi et al., 2006), polydispersity (Rorrer and Dorgan, 2014), and melts
(Lin et al., 2007; Kampmann et al., 2015; Karantrantos et al., 2019).
6.2.3.2 The kink-jump algorithm
The kink-jump algorithm was used initially (Verdier and Stockmayer, 1962)
for lattice polymers. In this context, it effectively involves “flipping” a ran￾domly chosen monomer from its position rn to a trial position r’
n 5 rn11 1
rn-1 1 rn. At small intermolecular separations, strong intermolecular repul￾sion between monomer units results in an excluded, or empty volume. To
account for the effect of excluded volume, a local “crankshaft” motion (Lax
and Brender, 1977) must be added.
Baumga¨rtner and Binder (1979) formulated a kink-jump algorithm to
study freely jointed linear off-lattice chains with excluded volume interac￾tions. If the chain has p links and p 1 1 monomers, the kink-jump algorithm
proceeds in the following fashion:
Stage 1: A monomer i is chosen randomly.
Stage 2: If i is either the head (i 5 1) or tail (i 5 p 1 1) of the chain, a trial
state is obtained by choosing a random orientation for the first or
pth link, respectively. Otherwise, i is rotated in a circle around the
vector joining i1 to i 1 1 by choosing an angle Δφ uniformly in
the range Δφmax to Δφmax.
Stage 3: The trial configuration is accepted according to Eq. (6.7).
222 Molecular Simulation of FluidsThe move is illustrated in Fig. 6.2. The kink-jump algorithm has been
particularly useful (Stampe and Sokolov, 2001) in describing Rouse behavior
(Doi and Edwards, 1995) of polymer solutions.
It should be noted that the various configurations changing MC moves
are not mutually exclusive and it is common to combine different moves in a
single simulation. Manka et al. (2013) ´ combined reputation and kink-jump
moves to study polymer chains on a cubic lattice. A similar combined
approach has been used for polymer membranes (Pandey and Seyfarth, 2003)
and other properties (Bentrem et al., 2002a,b; Maycock and Bhattacharya,
2006). A comparison of the kink-jump algorithm and configuration bias MC
methods has been reported (Tsonchev et al., 2004).
6.2.3.3 The pivot algorithm
The pivot algorithm (Lal, 1969) is used in conjunction with a self avoiding
walk (SAW) (Binder and Heermann, 1997) to generate new configurations
on a lattice. A pivot point is chosen randomly at some point on the SAW. A
new chain is obtained by rotating part of the chain around the pivot point. If
the position of the rotated chain overlaps with the unmoved part of the chain,
the move is rejected. Otherwise, acceptance of the move is governed by
Eq. (6.7). Although there is a high probability of rejection, relatively few
successful moves are required to obtain a radically different configuration.
For a chain of p links, Madras and Sokal (1988) have demonstrated that the
pivot algorithm is p times more efficient than standard SAW algorithms. The
pivot algorithm can also be used for off-lattice simulations (Freire and Horta,
1976). It is an efficient means of studying single polymer chains but it is
unlikely to be useful for polymer melts because of the very high probability
of overlap with other chains. Other SAW-based algorithms have been
reviewed (Sokal, 1995). The pivot algorithm can be applied to ring polymers
(Zifferer and Preusser, 2001; Kindt, 2002), star polymers (von Ferber et al.,
2009), and dendrimers (Gergidis et al., 2009). Very long SAW simulations
with the pivot algorithm have been attempted (Clisby, 2018).
6.3 Advanced techniques
Many improvements to the basic MC techniques have been proposed.
Allen and Tildesley (2017) have discussed “smarter MC” sampling, and
FIGURE 6.2 Illustration of a trial move using the kink-jump algorithm for off-lattice chains.
Monte Carlo simulation Chapter | 6 223Binder (1995a,b) has detailed the application of MC techniques to polymers.
In this section, we will focus on a few important methods. One of the most
significant advances has been the application of the Gibbs ensemble grand
canonical MC method (Panagiotopoulos, 1987) to predict phase equilibria.
The histogram reweighting technique (Ferrenberg and Swendsen, 1989) is
another important MC for phase equilibria. The Gibbs ensemble and other
techniques for phase equilibria are discussed separately in Chapter 10.
6.3.1 Configurational bias MC
An important application of the MC method is the simulation of a grand
canonical ensemble (Chapter 9). The simulation of a grand canonical ensem￾ble requires both particle transfer and insertion moves. The transfer or inser￾tion of either atoms or small molecules is relatively straightforward and it
can be handled via a conventional Widom (1963) method. However, it is dif￾ficult to move large molecules such as polymers because of the very high
probability of steric overlap. This problem has been addressed by configu￾rational bias MC (CBMC) methods (Siepmann, 1990; Frenkel et al., 1991;
Siepmann and Frenkel, 1992; de Pablo et al., 1992a,b; Laso et al., 1992,
Mooij and Frenkel, 1996). CBMC combines elements of sampling proposed
by Rosenbluth and Rosenbluth (1955) with segment-by-segment insertion.
The general approach has been reviewed (Frenkel, 1995; Frenkel and Smit,
2023). It has proved (de Pablo et al., 1999: Panagiotopoulos, 2000; Singh
et al., 2009) particularly advantageous in the simulation of phase equilibria
(Chapter 10). The use of a continuous fractional MC method (Shi and
Maginn, 2008) is also advantageous (Rahbari et al., 2021; Mayr et al., 2023).
6.3.1.1 Lattice chains
Let us consider the conventional insertion of a three-unit molecule beginning
at point s on a two-dimensional lattice illustrated by Fig. 6.3. From point s
there are four possible lattice sites, however only sites a and b are free.
Therefore, the probability of a successful insertion is only 50%. If site b is
chosen, further growth of the molecule is inhibited, whereas if site c was
chosen, there would be three further sites to grow the molecule. On average,
only one trial in twelve will successfully grow a molecule from site s.
CBMC (Siepmann, 1990; Siepmann and Frenkel, 1992) tackles this prob￾lem in a different fashion. Starting from s, the vacant sites (a and b) are
identified and one of these vacant sites is selected randomly. Unlike the con￾ventional MC procedure, the occupied sites are not considered in the selec￾tion process. A Rosenbluth weight is calculated for the move,
Wi 5 navail
n Wi21 ð6:11Þ
224 Molecular Simulation of Fluidswhere Wi-1 is the weight for the previous step (W0 5 1) and navail is the
number of available sites where n is the total number of neighboring sites
excluding the site occupied by the previous unit. For the present example,
W1 5 2/4 5 1/2. If site b is chosen, the attempt is abandoned because there
is no site available for the third unit. If site a is chosen, the adjacent sites
are examined and the only vacant site is filled with the third unit. The
Rosenbluth weight for this step is 1=3 3 1=2 5 1=6. The overall statistical
weight for the move is obtained by multiplying the number of successful
trials by the Rosenbluth weight, that is, 1=2 3 1=6 5 1=12. This is the
same result as conventional sampling. However, in the conventional
scheme only one trial in twelve is successful whereas the proportion of
successful trials for the method is one in two.
The algorithm can be extended to account for the interactions between
the growing chain and its lattice neighbors. If UΓ(i) denotes the energy of
segment i when occupying a particular site Γ, that site is chosen with a prob￾ability of,
pΓðiÞ 5 exp½  2βUΓðiÞ
Zi
ð6:12Þ
where Zi is defined as,
Zi 5 X
b
Γ51
exp½  2UΓðiÞ ð6:13Þ
that is, the sum of the Boltzmann factors for the b possible orientations of
the chain segment. The sum of Boltzmann factors plays the role of navail in
Eq. (6.11). Therefore the Rosenbluth weight for an entire chain of length l
can be obtained from,
Wl 5 exp½  2βUtotalðlÞ L
l
i52
Zi
b ð6:14Þ
FIGURE 6.3 Insertion possibilities for a three-unit molecule on a two-dimensional lattice from
a starting point s. Closed and open circles represent occupied and vacant sites, respectively.
Monte Carlo simulation Chapter | 6 225where Utotal(l) is the total energy of the chain, which is equal to the sum of
the individual segment energies, UΓ(i). The residual chemical potential is
related to the average Rosenbluth weight.
μr 5 kTlnh i Wl ð6:15Þ
There are many examples for which the properties of both polymers
(Abreu and Escobedo, 2005; Cootes et al., 2000) and proteins (Zou and
Saven, 2003) can be obtained using lattice-based CBMC.
6.3.1.2 Flexible chains
de Pablo et al. (1992a, 1993) and Siepmann and Frenkel (1992) demonstrated
that the algorithm could be generalized for a fully flexible chain. de Pablo
et al. (1992a) introduced the term “continuum configurational bias (CCB)”
to describe the application of method to flexible chains. When each segment
of a flexible chain is grown, a subset k random directions is chosen. The
energy UΓ(i) for each of these orientations is calculated and an orientation is
chosen with a probability of,
pΓðiÞ 5 exp½  2βUΓðiÞ
P
k
Γ51
exp½  2βUΓðiÞ
ð6:16Þ
and the Rosenbluth factor is accumulated from:
Wi 5 Wi21
1
k
X
k
Γ51
exp½  2βUΓðiÞ ð6:17Þ
The trial conformation is accepted if the following criterion is satisfied,
R #
Wl;trial
Wl;old
ð6:18Þ
where R is a random number between 0 and 1.
The general procedure for implementing a CBMC simulation is outlined
in Algorithm 6.2. It involves three distinct stages. The first stage (Algorithm
6.2, Part 1) generates a trial configuration and determines the Rosenbluth
weight. This involves selecting a chain randomly (Algorithm 6.2, Part 1.1);
selecting a starting position randomly (Algorithm 6.2, Part 1.2); growing the
chain and calculating the Rosenbluth weight (wTrial) for the trial chain
(Algorithm 6.2, Part 1.3). The starting point can occur anywhere on the
chain. If the value of start equals 1, the whole chain is regrown, whereas any
other value means that the chain is only regrown partially. The number of
attempted insertions k is specified and the chain is grown using Algorithm 6.3.
The second stage (Algorithm 6.2, Part 2) calculates the Rosenbluth weight for
the old configuration (wOld) by using Algorithm 6.3 to retrace the chain.
226 Molecular Simulation of FluidsTo retrace the old chain, Algorithm 6.3 is used with k set to unity. In stage 3
(Algorithm 6.3, Part 3) the old and trial Rosenbluth weights are used to either
accept or reject the trial configuration (Algorithm 6.3, Part 3.1) in accordance
with criterion (6.15).
ALGORITHM 6.2 CBMC algorithm for a chain.
Part 1 New trial configuration:
trialConfiguration  true
Part 1.1 Select a chain randomly:
chain  int(rand()  numberOfChains) + 1
Part 1.2 Select starting position:
start Int(rand()  Lengthchain)
k  number of attempted insertions
Part 1.3 Grow chain from start using Algorithm 6.3
and determine wTrial.
Part 2 Old configuration:
trialConfiguration  false
k  1
Part 2.1 Retrace chain from start using Algorithm 6.3
and determine wOld.
Part 3 Acceptance of trial:
Part 3.1 test  wTrial/wOld
if (test > rand())
Accept move.
end if
Algorithm 6.3 is responsible for fully or partially regrowing
(trialConfiguration 5 true) a chain or retracing part or all of an existing chain
(trialConfiguration 5 false). At the outset (Algorithm 6.3, Part 1), the coordinates
of that part of the chain, which are not involved in the regrowth, are stored.
The chain is either regrown or retraced by considering each atom in turn
(Algorithm 6.3, Part 2). If the first atom of the chain is encountered it is trea￾ted specially (Algorithm 6.3, Part 2.1). For the remaining atoms, k trial posi￾tions are located (Algorithm 6.3, Part 2.2). The location of the trial positions
depends on the nature of the chain (Algorithm 6.3, Part 2.3). If the chain is
fully flexible, the trial positions can be located randomly, whereas bond and
angular constraints must be imposed for semiflexible or rigid molecules. The
external energy or energy from nonbonded interactions is calculated and the
Rosenbluth weight is calculated. After the k orientations are found, the
Rosenbluth weight is updated and one of the orientations is selected
(Algorithm 6.3, Part 2.4). The selection is made with the probability given
by Eq. (6.16). The algorithm has been discussed in detail by Frenkel and
Smit (2023).
Monte Carlo simulation Chapter | 6 227ALGORITHM 6.3 Growing/retracing either a fully flexible or semi-flexible
chain.
Part 1 Store positions that are not regrown or retraced:
loop atom  1 .... start - 1
rxStoreatom  rxatom
ryStoreatom  ryatom
rzStoreatom  rzatom
end atom loop
Part 2 Grow/retrace chain:
W  1 //initial Boltzmann weight
loop atom  start ... chainLength
Part 2.1 if (atom = 1)
if(trialConfiguration) //generate random positions
rxTrial1  rand()  boxLength
ryTrial1  rand()  boxLength
rzTrial1  rand()  boxLength
else
rxTrial1  rand()  rxStore1
ryTrial1  rand()  ryStore1
rzTrial1  rand()  rzStore1
end if
Calculate change in energy:
Calculate energy of the atom (UTrial) at trial position. 
U1  UTrial - U1
W  k  exp(-U1) //Rosenbluth factor
else //consider other atoms
sumW  0
Part 2.2 loop attempt  1 ... k
if (trialConfiguartion = false and attempt = 1)
rxTrial  rxatom
ryTrial  ryatom
rzTrial  rzatom
else
Part 2.3 Generate a trial position (rxTrial, ryTrial, rzTrial) in
accordance with the chain’s constraint.
end if
Calculate change in energy:
Calculate energy (UTrial) at trial position. 
Uatom  UTrial - Uatom
WTrialattempt  exp(-Uatom)
sumW  sumW + WTrialattempt
end loop
W W  sumW //update Rosenbluth factor
228 Molecular Simulation of FluidsPart 2.4 if (trialConfiguration)
Select one of the trial attempts (position):
selectW  rand()  sumW
cummulativeW  Wtrial1
position  1
loop while (cummulativeW < selectW )
position  position + 1
cummulativeW  cummulativeW + WTrialposition
end while loop
rxStoreatom  rxTrialposition
ryStoreatom  ryTrialposition
rzStoreatom  rzTrialposition
else
rxStoreatom  rxatom
ryStoreatom  ryatom
rzStoreatom  rzatom
end if
end if
end atom loop
The computation time and efficiency of Algorithm 6.3 depends largely
on the value of k. If k 5 1, the algorithm is equivalent to Widom particle
insertion, which is inefficient for chain molecules. For chains, k . 1 is
required to obtain improvements in efficiency. However, if k is too large, too
much time is used in calculating Rosenbluth weights for trial positions that
are very close to each other. The effect of the value k has been investigated
by Frenkel et al. (1991). For small chains, an excessive value of k leads to
poor computational performance, whereas larger k values are required to
sample long chains. Typically, a value of k 5 4 is often a good compromise
between efficient sampling and excessive computation (Frenkel, 1995).
An important application of methods is the simulation of phase equilibria
involving either polymers or chain molecules. The method has been com￾bined (Laso et al., 1992; Mooij et al., 1992) with the Gibbs ensemble
(Chapter 10) to predict the phase equilibria of chain molecules. In particular,
good results have been obtained (Siepmann et al., 1993a,b; Smit et al., 1995,
1998) for the vaporliquid equilibria of alkanes from pentane to octatetra￾contane and branched alkanes (Cui et al., 1997). A hybrid Gibbs ensemble/
MD method has been used (de Pablo, 1995) to improve the efficiency of par￾ticle interchange. Vaporliquid coexistence of square-well chains consisting
of up to one hundred segments has been reported (Escobedo and de Pablo,
1996).
The method is clearly superior to the simple Widom test particle
approach. However, it has some limitations. In common with the Widom
method, it relies on finding vacancies in the fluid, therefore, insertion pro￾blems will still arise for very long chains. A reasonably large system size
( . 200 chains) is also required to avoid finite size effects.
Monte Carlo simulation Chapter | 6 229Improving methods is an active area of research. Shelley and Patey (1994,
1995) developed a configurational bias method for the insertion and deletion of
ions and water molecules in grand canonical MC simulations. Escobedo and de
Pablo (1995a) proposed an extended continuum configurational bias (ECCB)
method, which is particularly useful for very large molecular chains. Suen et al.
(1997) used the ECCB method to examine the collapse of a polymer chain in
an athermal solvent. Configurational bias sampling has also been used in an
expanded ensemble (Escobedo and de Pablo, 1995b). The expanded ensemble
formalism has been used successfully (Escobedo and de Pablo, 1997) to simu￾late both pure athermal mesogenic chains and mixtures.
Deem and Bader (1996) have described a configurational bias method
that can be applied to either linear or cyclic peptides. Haas and Hilfer (1996)
have reported continuum MC calculations for stiff chain molecules at
surfaces. Methods of optimization have also been addressed (Mooij and
Frenkel, 1996). Sadanobu and Goddard (1997) combined continuum configu￾rational bias sampling with a Boltzmann factor-biased enrichment method.
The resulting algorithm requires the simulation of dramatically fewer chains
to obtain an accurate value of free energy. Vendruscolo (1997) has proposed
modifications to the configurational bias method involving the regrowth of
the internal segments of polymer chains. The computational efficiency of
CBMC is improved considerably via parallel implementations (Vlugt, 1999;
Cezar et al., 2020; Glaser et al., 2015).
6.3.2 Cluster moves
Systems of strongly interacting particles such as ions in a medium of low
dielectric constant or surfactants exhibit significant clustering. One consequence
of clustering is that independent particle moves may be inhibited. In such cases,
it may be preferable to attempt to move clusters of atoms rather than individual
atoms. Swendsen and Wang (1987) proposed a cluster algorithm to facilitate
MC sampling of near-critical systems. Later, Wu et al. (1992) modified the pro￾cedure for self-assembling systems. The key feature of the Swedsen-Wang
algorithm is the creation of virtual bonds between neighboring particles. Wu
et al. (1992) proposed that the probability of bond formation is only a function
of distance. Once clusters have formed, they are moved as a whole.
The probability of accepting a cluster move depends on the probabilities
of bond formation at the old and new cluster positions. Instead of applying
Eq. (6.7), cluster moves are accepted with a probability given by,
p 5 min 1; expð2 βΔUÞ L
kl
1 2 pf
ðk; lÞ
1 2 prðk; lÞ
 	 ð6:19Þ
where k denotes a particle on the cluster, l denotes a particle outside the clus￾ter, pr is the probability of the reverse move, and pf is the probability of the
230 Molecular Simulation of Fluidsforward move. Wu et al. (1992) have used the simplifying assumption that
p(i,j) 5 1 for rij less than a specified cluster distance rc, and p(i,j) 5 0 beyond
that distance. Orkoulas and Panagiotopoulos (1993, 1994) have demon￾strated the usefulness of cluster moves in the simulation of vaporliquid
coexistence of ionic fluids. Cluster moves have been examined in detail by
Frenkel (1995) and Frenkel and Smit (2023). The general algorithm for
implementing a cluster move is:
1. Identify clusters;
2. Choose a cluster at random;
3. Change the position of the cluster by applying the same random displace￾ment to all atoms of the cluster;
4. Calculate the energy and probability factor experienced by all atoms of
the cluster in the new position; and
5. Apply Eq. (6.19).
A possible implementation of this procedure is given by Algorithm 6.4.
Before the clusters are identified (Algorithm 6.4, Part 1.1), every atom is avail￾able takenatom’false for cluster formation. The clusters are identified by choos￾ing a “seed” atom clusterSeed (Algorithm 6.4, Part 1.2) and finding all atoms
within the separation distance from clusterSeed (Algorithm 6.4, Parts 1.3 and 1.4).
These atoms are now not available takenatom’false for any other cluster.
The coordinates are assigned to a two-dimensional array rxcluster, cAtomIndex’rxatom.
This process is continued until all atoms are assigned to a cluster
totalTaken 5 maxAtoms. Algorithm 6.4 also allows for the possibility that some
atoms may be outside any cluster (Algorithm 6.4, Part 1.5). The MC procedure
(Algorithm 6.4, Part 2) is broadly similar to Algorithm 6.1. For each cycle, a
cluster is selected randomly (Algorithm 6.4, Part 2.1). All the atoms
(numOfAtomscluster) of the chosen cluster are displaced randomly by the same
amount (Algorithm 6.4, Part 2.2). For each atom of the cluster, the change in
energy experienced at the trial position is calculated (Algorithm 6.4, Part 2.3).
The probability factor is also determined. The change in energy (ΔUcluster) for
the move is simply the sum of the change in energy experienced by atoms of
the cluster at their trial positions. The combined probability factor (prob) is the
product of one minus the probability factor for all the atoms in the cluster. If
prob becomes equal to zero, the move is rejected immediately because this sig￾nifies that an atom of the trial cluster has become part of another cluster and
microscopic reversibility has been violated. If microscopic reversibility is not
violated, the decision to accept the move depends on the change in energy of
the move (Algorithm 6.4, Part 2.4). The maximum allowed displacement is
updated periodically (Algorithm 6.4, Part 2.5) to obtain the desired acceptance
rate. It should be noted that cluster moves should be combined with single parti￾cle moves, to allow for a change in both the configuration of the cluster and the
number of particles in the cluster.
Monte Carlo simulation Chapter | 6 231ALGORITHM 6.4 MC procedure for accepting cluster moves.
Part 1 Identify Clusters:
Part 1.1 loop atom  1 ... maxAtom
takenatom false
end atom loop
totalTaken  0
clusterSeed  0
cluster  0
Part 1.2 loop while (totalTaken < maxAtom)
cAtomIndex  0
cluster  cluster + 1
clusterSeed  clusterSeed + 1
loop atom  2 .. maxAtom
Part 1.3 if (atom  clusterSeed and takenatom = false)
Calculate the separation between atom
and clusterSeed.
Part 1.4 If (separation < rCluster) //member of cluster found
cAtomIndex  cAtomIndex + 1
rxctuster, cAtomIndex  rxatom
rycluster, cAtomIndex  ryatom
rzcluster, cAtomIndex  rzatom
takenatom  true
totalTaken  totalTaken + 1
end if
end if
end atom loop
Part 1.5 if (takenclusterSeed = false) //take care of lone atoms
cAtomIndex  cAtomIndex + 1
rxctuster, cAtomIndex  rxclusterSeed
rycluster, cAtomIndex  ryatomSeed
rzcluster, cAtomIndex  rzatomSeed
takenclusterSeed  true
totalTaken  totalTaken + 1
end if
numOfAtomscluster  cAtomIndex
end while loop
totalCluster  cluster
Part 2 MC Simulation:
loop cycle 1 ... maxCycle
Part 2.1 Select cluster at random:
cluster [1, totalCluster]
Part 2.2 Attempt trial displacements of a cluster:
loop cAtomIndex  1 ... numOfAtomscluster
rxTrialcluster,cAtomIndex
 pbc(rxcluster, cAtomIndex + (2  rand() - 1)  dMax)
ryTrialcluster,cAtomIndex
 pbc(rycluster,cAtomIndex + (2  rand() - 1)  dMax)
rzTrialcluster,cAtomIndex
 pbc(rzcluster,cAtomIndex + (2  rand() - 1)  dMax)
end cAtomIndex loop
232 Molecular Simulation of FluidsPart 2.3 Calculate Energy/Probability factors of trial position:
prob  1
cAtomIndex  1
UCluster  0
loop
Calculate UcAtomIndex from interaction with outside atoms.
Calculate probcAtomIndex
UCluster  UCluster + UcAtomIndex
prob prob*(1 - probcAtomIndex)
cAtomIndex  cAtomIndex + 1
while (cAtomIndex  numOfAtomscluster and prob = 1)
Part 2.4 Apply acceptance criterion:
If (prob = 1)
if (UCluster < 0 or exp(-  UCluster)  rand())
loop cAtomIndex  1 ... numOfAtomscluster
rxcluster,cAtomIndex  rxTrialcluster, cAtomIndex
rycluster,cAtomIndex  ryTrialcluster,cAtomIndex
rzcluster,cAtomIndex  rzTrialcluster,cAtomIndex
Ucluster,cAtomIndex  Ucluster,cAtomIndex + UcAtomIndex
end cAtomIndex loop
U  U+ UCluster
numAccept  numAccept + 1
end if
Part 2.5 Update the maximum displacement periodically:
if (mod(cycle, updateCycle) = 0)
acceptRatio  numAccept/cycle  atomMax)
if (acceptRatio > 0.5)
dMax  1.05  dMax
else
dMax  0.95  dMax
end if
end if
end cycle loop
6.4 Path integral Monte Carlo
The above MC methods are appropriate for classical molecular interactions. In
contrast, path integral MC (PIMC) methods allow the investigation of systems
involving quantum interactions (Feynman and Hibbs, 2010). Instead of discrete
particle trajectories, a particle is treated as a ring polymer consisting of P beads.
Assuming a sufficiently large value of P (Chandler and Wolynes, 1981), the
canonical (NVT) partition function (Chapter 2) of a three-dimensional system of
N rings of P beads is given by,
ZP 5 mP
2πβ_2

 3NP=2ð
L
N
i51
dr1
i ...drP
i e2β Φðr1
i ...rP
NÞ
r1
i 5rP11 i




ð6:20Þ
Monte Carlo simulation Chapter | 6 233where m is the mass of a single particle, h is Planck’s constant divided by
2π, and rk
i is the radius vector of bead k of ring i. The propagator potential is
defined as,
Φðr1
1; ...; rP
NÞ 5 mP
2β2
_2
X
P
k51
X
N
i51
rk
i 2rk21
i
 2
1
1
P
X
P
k51
X
N
j . i
u rk
i 2 rk
j






  ð6:21Þ
and r1
i 5 rP11
i to satisfy the ring condition. In Eq. (6.21), the first term is the
quantum kinetic contribution that describes the harmonic beadbead interac￾tion within the ring. The second term of Eq. (6.21) accounts for the potential
energy contribution from the interaction of beads with the same index.
A property of interest can be obtained (Barker, 1979) by taking the deriv￾ative of the partition function with respect to a corresponding variable. For
example, the isochoric heat capacity (CV) can be obtained from,
CV 5 β2 UTD
2   2 h i UTD
2 1
3NP
2β2 2 mP
β3
_2
X
P
τ51
X
N
j51
r
ðτÞ
j 2r
ðτ11Þ
j
 2
" # ð6:22Þ
where UTD is the energy calculated using the thermodynamic method.
UTD 5 3NP
2β 2 mP
2β2
_2
X
P
τ51
X
N
j51
r
ðτÞ
j 2r
ðτ11Þ
j
 2
1
1
P
X
P
τ51
X
N
i . j
u r
ðτÞ
i 2 r
ðτÞ
j






 
ð6:23Þ
The so-called thermodynamic or primitive estimators (Barker, 1979) are
associated with increasing standard error with P because the kinetic energy
exhibits large fluctuations. This has been partly addressed by Herman et al.
(1982), who formulated a path integral version of the virial theorem. Both
virial and virial centroid estimator expressions are available for energy and
pressure. Glaesemann and Fried (2002a,b) have also introduced the double
virial and double centroid virial estimators for specific heat capacity at con￾stant volume, which is more efficient than primitive or virial estimators.
These estimators, which require either the calculation of the second-order
derivatives of the potential function or the evaluation of the Hessian matrix
at each accepted step, are very computationally expensive. As such, they are
only computationally feasible using powerful parallel computing platforms.
A PIMC simulation can be simply implemented by conducting a con￾ventional MC Markov chain process with Metropolis importance sam￾pling (Algorithm 6.1). There are alternative ways of generating the trial
displacements. Thirumalai et al. (1984) proposed first moving a ring as a whole,
and then displacing all beads of the same chain by a small amount. Singer and
Smith (1988) implemented a trial displacement of one bead at a time. Both
these methods are relatively slow and result in low acceptance rates. A more
computationally efficient approach is to use a staging algorithm (Ceperley and
Pollock, 1984), where a ring is divided into segments and an attempt is made to
234 Molecular Simulation of Fluidsdisplace a moderate number of beads in one move. This approach increases the
sampling efficiency. The staging variables are sampled randomly from their
Gaussian distribution. A ring is moved as a whole after internal displacement is
completed. The Li-Broughton (1987) correction is commonly applied to reduce
error caused by the discreet values of P.
Thirumalai et al. (1984) applied PIMC to the properties of neon, showing
the importance of quantum efforts at both 35 K and 40 K. Singer and Smith
(1988) have reported a PIMC study of LJ systems in liquid phase, including
several state points of neon and helium. Vlasiuk et al. (2016) have deter￾mined the heat capacity of neon using PIMC and Eq. (6.22). Although con￾siderable uncertainty was observed, the errors were not as large as reported
by Sese´ (1995). A hybrid PIMC method has been proposed (Miura, 2007) to
more easily handle rotation.
6.5 Summary
The MC strategy provides a relatively simple mechanism for determining the
nondynamical properties of fluids without requiring specific details of the under￾lying physics. The basis of the procedure involves generating a Markov chain
with an appropriate stochastic sampling scheme. The change in the energy of
intermolecular interaction at different trail states is used to determine whether or
not the trial configurations are accepted. MC algorithms can be applied rela￾tively to a wide variety of situations. Atomic systems represent the simplest
case with the acceptance criterion depending on the change in energy of a trial
displacement. In contrast, for molecules, additional acceptance criteria and MC
move a required account for changes in molecular configuration. Nonetheless,
the MC approach can be used to determine efficiently the properties of large
molecules such as polymers and proteins.
References
Abreu, C.R.A., Escobedo, F.A., 2005. A novel configurational-bias Monte Carlo method for lat￾tice polymers: application to molecules with multicyclic architectures. Macromolecules 38,
85328545.
Allen, M.P., Tildesley, D.J., 2017. Computer Simulation of Liquids, second ed. Oxford
University Press, Oxford.
Barker, J.A., 1979. A quantum-statistical Monte Carlo method: path integrals with boundary con￾ditions. J. Chem. Phys. 70, 29142918.
Barker, J.A., Watts, R.O., 1969. Structure of water: a Monte Carlo calculation. Chem. Phys.
Lett. 3, 144145.
Baumga¨rtner, A., Binder, K., 1979. Monte Carlo studies on the freely jointed polymer chain
with excluded volume interaction. J. Chem. Phys. 71, 25412544.
Bentrem, F.W., Xie, J., Pandey, R.B., 2002a. Density and conformation with relaxed substrate,
bulk, and interface in electrophoretic deposition of polymer chains. J. Mol. Struct.
(Theochem) 592, 95103.
Monte Carlo simulation Chapter | 6 235Bentrem, F.W., Xie, J., Pandey, R.B., 2002b. Interface relaxation in electrophoretic deposition of
polymer chains: effects of segmental dynamics, molecular weight, and field. Phys. Rev. E
65, 041606.
Berendsen, H.J., 2007. Simulating the Physical World: Hierarchical Modeling from Quantum
Mechanics to Fluid Dynamics. Cambridge University Press, Cambridge.
Binder, K. (Ed.), 1995a. The Monte Carlo Method in Condensed Matter Physics. second ed.
Springer-Verlag, Berlin.
Binder, K. (Ed.), 1995b. Monte Carlo and Molecular Dynamics Simulations in Polymer Science.
Oxford University Press, New York.
Binder, K., 1997. Applications of Monte Carlo methods to statistical physics. Rep. Prog. Phys.
60, 487599.
Binder, K., Heermann, D.W., 1997. Monte Carlo Simulation in Statistical Physics: An
Introduction, third ed. Springer-Verlag, Berlin.
Bishop, M., Ceperley, D., Frisch, H.L., Kalos, M.H., 1980. Investigations of static properties of
model bulk polymer fluids. J. Chem. Phys. 72, 32283235.
Brender, C., Lax, M., 1983. A Monte Carlo off-lattice method: the slithering snake in a contin￾uum. J. Chem. Phys. 79, 24232425.
Ceperley, D.M., Pollock, E.L., 1984. Simulation of quantum many-body systems by path￾integral methods. Phys. Rev. B 30, 25552568.
Cezar, H.M., Canuto, S., Coutinho, K., 2020. DICE: a Monte Carlo code for molecular simula￾tion including the configurational bias Monte Carlo method. J. Chem. Info. Model. 60,
34723488.
Chandler, D., Wolynes, P.G., 1981. Exploiting the isomorphism between quantum theory and
classical statistical mechanics of polyatomic fluids. J. Chem. Phys. 74, 40784095.
Clisby, N., 2018. Monte Carlo study of four-dimensional self-avoiding walks of up to one billion
steps. J. Stat. Phys. 172, 477492.
Cootes, A.P., Gurmi, P.M.G., Torda, A.E., 2000. Biased Monte Carlo optimization of protein
sequences. J. Chem. Phys. 113, 24892496.
Cui, S.T., Cummings, P.T., Cochran, H.D., 1997. Configurational bias Gibbs ensemble Monte
Carlo simulation of vapor-liquid equilibria of linear and short-branched alkanes. Fluid Phase
Equilib. 141, 4561.
de Gennes, P., 1971. Reptation of a polymer chain in the presence of fixed obstacles. J. Chem.
Phys. 55, 572579.
de Pablo, J.J., 1995. Simulation of phase equilibria for chain molecules. Fluid Phase Equilib.
104, 195206.
de Pablo, J.J., Laso, M., Suter, U.W., 1992a. Estimation of the chemical potential of chain mole￾cules by simulation. J. Chem. Phys. 96, 61576162.
de Pablo, J.J., Laso, M., Suter, U.W., 1992b. Simulation of polyethylene above and below the
melting point. J. Chem. Phys. 96, 23952403.
de Pablo, J.J., Laso, M., Siepmann, J.I., Suter, U.W., 1993. Continuum-configurational-bias
Monte Carlo simulations of long-chain alkanes. Mol. Phys. 80, 5563.
de Pablo, J.J., Yan, Q., Escobedo, F.A., 1999. Simulation of phase transitions in fluids. Annu.
Rev. Phys. Chem. 50, 377411.
Deem, M.W., Bader, J.S., 1996. A configurational bias Monte Carlo method for linear and cyclic
peptides. Mol. Phys. 87, 12451260.
Doi, M., Edwards, S.E., 1995. The Theory of Polymer Dynamics. Clarendon Press, Oxford.
Escobedo, F.A., de Pablo, J.J., 1995a. Extended continuum configurational bias Monte Carlo
methods for simulation of flexible molecules. J. Chem. Phys. 102, 26362652.
236 Molecular Simulation of FluidsEscobedo, F.A., de Pablo, J.J., 1995b. Monte Carlo simulation of the chemical potential of poly￾mers in an expanded ensemble. J. Chem. Phys. 103, 27032710.
Escobedo, F.A., de Pablo, J.J., 1996. Simulation and prediction of vapour-liquid equilibria for
chain molecules. Mol. Phys. 87, 347366.
Escobedo, F.A., de Pablo, J.J., 1997. Monte Carlo simulation of athermal mesogenic chains:
pure systems, mixtures, and constrained environments. J. Chem. Phys. 106, 98589868.
Ferguson, D.M., Siepmann, J.I., Truhlar, D.G. (Eds.), 1999. Monte Carlo Methods in Chemical
Physics, Advances in Chemical Physics, Vol. 105. John Wiley & Sons, New York.
Ferrenberg, A.M., Swendsen, R.H., 1989. New Monte Carlo technique for studying phase transi￾tions. Phys. Rev. Lett. 61, 26352638.
Feynman, R.P., Hibbs, A.R., 2010. Quantum Mechanics and Path Integrals (emended by Styer,
D. F.). Dover Publications, Mineola.
Foo, G.M., Pandey, R.B., 2000. Characteristics of driven polymer surfaces: growth and rough￾ness. Phys. Rev. E 61, 17931799.
Freire, J.J., Horta, A., 1976. Mean reciprocal distances of short polymethylene chains. Calculation
of the translational diffusion coefficient of n-alkanes. J. Chem. Phys. 65, 40494054.
Frenkel, D., 1995. In: Baus, M., Rull, L.F., Ryckaert, J.-P. (Eds.), Observation, Prediction and
Simulation of Phase Transitions in Complex Fluids. Kluwer, Dordecht.
Frenkel, D., Smit, B., 2023. Understanding Molecular Simulation. From Algorithms to
Applications, third ed. Academic Press, San Diego.
Frenkel, D., Mooij, G.C.A.M., Smit, B., 1991. Novel scheme to study structural and thermal
properties of continuously deformable molecules. J. Phys.: Condens. Matter 3, 30533076.
Gergidis, L.N., Moultos, O., Georgiadis, C., Kosmas, M., Vlahos, C., 2009. Off lattice Monte
Carlo simulations of AB hybrid dendritic star copolymers. Polymers 50, 328355.
Geyler, S., Pakula, T., Reiter, J., 1990. Monte Carlo simulation of dense polymer systems on a
lattice. J. Chem. Phys. 92, 26762680.
Gharibi, H., Behjatmanesh-Ardakani, R., Hashemianzadeh, M., Mousavi-Khoshdel, M., 2006.
Complexation between a macromolecule and an amphiphile by Monte Carlo technique.
J. Phys. Chem. B 110, 1354713553.
Gilks, W.R., Richardson, S., Spiegelhalter, D.J. (Eds.), 1996. Markov Chain Monte Carlo in
Practice. Chapman & Hall, Boca Raton.
Glaesemann, K.R., Fried, L.E., 2002a. An improved thermodynamic energy estimator for path
integral simulations. J. Chem. Phys. 116, 59515955.
Glaesemann, K.R., Fried, L.E., 2002b. Improved heat capacity estimator for path integral simula￾tions. J. Chem. Phys. 117, 30203026.
Glaser, J., Karas, A.S., Glotzer, S.C., 2015. A parallel algorithm for implicit depletant simula￾tions. J. Chem. Phys. 143, 184110.
Haas, F.M., Hilfer, R., 1996. Continuum Monte Carlo simulation at constant pressure of stiff
chain molecules at surfaces, J. Chem. Phys., 105. pp. 38593867.
Hammersley, J.M., Handscomb, D.C., 1964. Monte Carlo Methods. Methuen & Co., London.
Hansen, J.P., McDonald, I.R., 2013. Theory of Simple Liquids, fourth ed. Academic Press,
Amsterdam.
Heermann, D.W., 1990. Computer Simulation Methods in Theoretical Physics, second ed.
Springer-Verlag, Berlin.
Herman, M.F., Bruskin, E.J., Berne, B.J., 1982. On path integral Monte Carlo simulations.
J. Chem. Phys. 76, 51505155.
Hua, C.C., Ke, C.C., 2005. A reptation-based lattice model with tube-chain coupling for the lin￾ear dynamics of bidisperse entangled linear polymer. Int. Polym. Res. 12, 181197.
Monte Carlo simulation Chapter | 6 237Kampmann, T.A., Boltz, H.-H., Kierfeld, J., 2015. Monte Carlo simulation of dense polymer
melts using event chain algorithms. J. Chem. Phys. 143, 0441095.
Karantrantos, A., Composto, R.J., Winey, J.I., Kro¨ger, M., Clarke, N., 2019. Modeling of
entangled polymer diffusion in melts and nanocomposites: a review. Polymers 11, 876.
Kindt, J.T., 2002. Pivot-coupled grand canonical Monte Carlo method for ring simulations.
J. Chem. Phys. 116, 68176825.
Kreer, T., Baschnagel, J., Mu¨ller, Binder, K., 2001. Monte Carlo simulation of long chain poly￾mers melts: crossover from Rouse to reputation dynamics. Macromolecules 34, 11051117.
Kroese, D.P., Rubinstein, R.Y., 2011. Monte Carlo methods. WIREs Comp. Stat. 4, 4858.
Kroese, D.P., Taimre, T., Botev, Z.I., 2011. Handbook of Monte Carlo Methods. John Wiley &
Sons, Hoboken.
Lal, M., 1969. ‘Monte Carlo’ computer simulation of chain molecules. I. Mol. Phys. 17, 5764.
Landau, D.P., Binder, K., 2000. A Guide to Monte Carlo Simulations in Statistical Physics.
Cambridge University Press, Cambridge.
Laso, M., de Pablo, J.J., Suter, U.W., 1992. Simulation of phase equilibria for chain molecules.
J. Chem. Phys. 97, 28172819.
Lax, M., Brender, C., 1977. Monte Carlo study of lattice polymer dynamics. J. Chem. Phys. 67,
17851787.
Leach, A.R., 2001. Molecular Modelling: Principles and Applications, second ed. Addison
Wesley Longman, Harlow.
Li, X.-P., Broughton, J.Q., 1987. High-order correction to the Trotter expansion for use in com￾puter simulation. J. Chem. Phys. 86, 50945100.
Lin, H., Mattice, W.L., von Meerwall, E.D., 2007. Chain dynamics of bidisperse polyethylene
melts: a Monte Carlo study on a high-coordination lattice. Macromolecules 40, 959966.
Madras, N., Sokal, A.D., 1988. The pivot algorithm: a highly efficient Monte Carlo method for
the self-avoiding walk. J. Stat. Phys. 50, 109186.
Manka, A., Nowicki, W., Nowicka, G., 2013. Monte Carlo simulations of a polymer chain con- ´
formation. The effectiveness of local moves algorithms and estimation of entropy. J. Mol.
Model. 19, 36593670.
Maycock, V., Bhattacharya, A., 2006. Effect of head-tail ratio and the range of the head-head
interaction in amphiphlic self-assembly. Eur. Phys. J. E 20, 201207.
Mayr, N., Haring, M., Wallek, T., 2023. Continuous fraction component Gibbs ensemble Monte
Carlo. Am. J. Phys. 91, 235246.
Metropolis, N., Rosenbluth, A.W., Rosenbluth, M.N., Teller, A.H., Teller, E., 1953. Equation of
state calculations by fast computing machines. J. Chem. Phys. 21, 10871092.
Miura, S., 2007. Rotational fluctuation of molecules in quantum clusters. I. Path integral hybrid
Monte Carlo algorithm. J. Chem. Phys. 126, 114308.
Mooij, G.C.A.M., Frenkel, D., 1996. A systematic optimization scheme for configurational bias
Monte Carlo. Mol. Sim. 17, 4155.
Mooij, G.C.A.M., Frenkel, D., Smit, B., 1992. Direct simulation of phase equilibria of chain
molecules. J. Phys.: Condens. Matter 4, L255L259.
Moony, C.Z., 1997. Monte Carlo Simulation. Sage Publications, Thousand Oaks.
Mountain, R.D., Thirumalai, D., 1994. Quantative measure of efficiency of Monte Carlo simula￾tions. Phys. A 210, 453460.
Murat, M., Witten, T.A., 1990. Relaxation in bead-jump polymer simulations. Macromolecules
23, 520527.
Newman, M.E.J., Barkema, G.T., 1999. Monte Carlo Methods in Statistical Physics. Clarendon
Press, Oxford.
238 Molecular Simulation of FluidsOrkoulas, G., Panagiotopoulos, A.Z., 1993. Chemical potentials in ionic systems from Monte
Carlo simulations with distance-biased test particle insertion. Fluid Phase Equilib. 93,
223231.
Orkoulas, G., Panagiotopoulos, A.Z., 1994. Free energy and phase equilibria for the restricted
primitive model of ionic fluids from Monte Carlo simulations. J. Chem. Phys. 101,
14521459.
Pakula, T., 1987. Cooperative relaxations in condensed macromolecular systems. 1. A model for
computer simulation. Macromolecules 20, 679682.
Pakula, T., Geyler, S., 1987. Cooperative relaxations in condensed macromolecular systems. 2.
Computer simulation of self-diffusion of linear chains. Macromolecules 20, 29092914.
Panagiotopoulos, A.Z., 1987. Direct determination of phase coexistence properties of fluids by
Monte Carlo simulation in a new ensemble. Mol. Phys. 61, 813826.
Panagiotopoulos, A.Z., 2000. Monte Carlo methods for phase equilibria of fluids. J. Phys.:
Condens. Matter 12, R25R52.
Pandey, R.B., Seyfarth, R., 2003. Driven chain macromolecule in a heterogeneous membrane￾like medium. Struct. Chem. 14, 445449.
Rahbari, A., Hens, R., Ramdin, M., Moultos, O.A., Dubbeldam, D., Vlugt, T.J.H., 2021. Recent
advances in the continuous fractional component Monte Carlo methodology. Mol. Sim. 47,
804823.
Reiter, J., Eding, T., Pakula, T., 1990. Monte Carlo simulation of lattice models for macromole￾cules at high densities. J. Chem. Phys. 93, 837844.
Rorrer, N.A., Dorgan, J.R., 2014. Effects of polydispersity on confined homopolymer melts: a
Monte Carlo study. J. Chem. Phys. 141, 214905.
Rosenbluth, M.N., Rosenbluth, A.W., 1955. Monte Carlo calculation of the average extension of
molecular chains. J. Chem. Phys. 23, 356359.
Sabelfeld, K.K., 1991. Monte Carlo Methods in Boundary Value Problems. Springer-Verlag,
Berlin.
Sadanobu, J., Goddard III, W.A., 1997. The continuous configurational Boltzmann biased direct
Monte Carlo method for free energy properties of polymer chains. J. Chem. Phys. 106,
67226729.
Santos, S., Suter, U.W., Mu¨ller, M., Nievergelt, J., 2001. A novel parallel-rotation algorithm
for atomistic Monte Carlo simulation of dense polymer systems. J. Chem. Phys. 114,
97729779.
Sese´, L.M., 1995. Feynman-Hibbs potentials and path integrals for quantum Lennard-Jones sys￾tems: theory and Monte Carlo simulations. Mol. Phys. 85, 931947.
Shelley, J.C., Patey, G.N., 1994. A configuration bias Monte Carlo method for ionic solutions.
J. Chem. Phys. 100, 82658270.
Shelley, J.C., Patey, G.N., 1995. A configuration bias Monte Carlo method for water. J. Chem.
Phys. 102, 76567663.
Shi, W., Maginn, E.J., 2008. Improvement in molecular exchange efficiency in Gibbs ensemble
Monte Carlo: development and implementation of continuous fractional component move. J.
Comput. Chem. 29, 25202530.
Siepmann, J.I., 1990. A method for the direct calculation of chemical potentials for dense chain
systems. Mol. Phys. 70, 11451158.
Siepmann, J.I., Frenkel, D., 1992. Configurational bias Monte Carlo: a new sampling scheme for
flexible chains. Mol. Phys. 75, 5970.
Siepmann, J.I., Karaborni, S., Smit, B., 1993a. Vapor-liquid equilibria of model alkanes. J. Am.
Chem. Soc. 115, 64546455.
Monte Carlo simulation Chapter | 6 239Siepmann, J.I., Karaborni, S., Smit, B., 1993b. Simulating the critical behaviour of complex
fluids. Nature 365, 330332.
Singer, K., Smith, W., 1988. Path integral simulations of condensed phase Lennard-Jones sys￾tems. Mol. Phys. 64, 12151231.
Singh, S.K., Sinha, A., Deo, G., Singh, J.K., 2009. Vapor-liquid phase coexistence, critical prop￾erties, and surface tension of confined alkanes. J. Phys. Chem. C. 113, 71707180.
Smit, B., Karaborni, S., Siepmann, J.I., 1995. Computer simulation of vapor-liquid phase equilib￾ria of n-alkanes. J. Chem. Phys. 102, 21262140.
Smit, B., Karaborni, S., Siepmann, J.I., 1998. Erratum: “Computer simulation of vapor-liquid
phase equilibria of n-alkanes.” [J. Chem. Phys. 102, 2126 (1995)]. J. Chem. Phys. 109, 352.
Sobol, I.M., 1994. A Primer for the Monte Carlo Method. CRC Press, Boca Raton.
Sokal, A.D., 1995. In: Binder, K. (Ed.), Monte Carlo and Molecular Dynamics Simulations in
Polymer Science. Oxford University Press, New York.
Stampe, J., Sokolov, I.N., 2001. Cyclization of a polymer with charged reactive end groups.
J. Chem. Phys. 114, 50435048.
Stedman, M.L., Foulkes, W.M.C., Nekovee, M., 1998. An accelerated Metropolis method.
J. Chem. Phys. 109, 26303634.
Suen, J.K.C., Escobedo, F.A., de Pablo, J.J., 1997. Monte Carlo simulation of polymer chain col￾lapse in an athermal solvent. J. Chem. Phys. 106, 12881290.
Swendsen, R.H., Wang, J.-S., 1987. Nonuniversal critical dynamics in Monte Carlo simulations.
Phys. Rev. Lett. 58, 8688.
Terranova, G., Aldao, C.M., Martin, H.O., 2007. Diffusion in the two-dimensional necklace ´
model for reputation. Phys. Rev. E 76, 031111.
Thirumalai, D., Hall, R.W., Berne, B.J., 1984. A path integral Monte Carlo study of liquid neon
and the quantum effective pair potential. J. Chem. Phys. 81, 25232527.
Tildesley, D.J., 1993. In: Allen, M.P., Tildesley, D.J. (Eds.), Computer Simulation in Chemical
Physics. Kluwer, Dordrecht.
Tsonchev, S., Coalson, R.D., Liu, A., Beck, T.L., 2004. Flexible polyelectrolyte simulations at
the Poisson-Boltzmann level: a comparison of the kink-jump and multigrid configurational￾bias Monte Carlo methods. J. Chem. Phys. 120, 98179821.
Tuckerman, M.E., 2010. Statistical Mechanics: Theory and Molecular Simulation. Oxford
University Press, Oxford.
Uhlherr, A., Leak, S.J., Adam, N.E., Nyber, P.E., Doxastakis, M., Mavrantzas, V.G., Theodorou,
D.N., 2002. Large scale atomistic polymer simulations using Monte Carlo methods for paral￾lel vector processors. Comp. Phys. Commun. 144, 122.
Vendruscolo, M., 1997. Modified configurational bias Monte Carlo method for simulation of
polymer systems. J. Chem. Phys. 106, 29702976.
Verdier, P.H., Stockmayer, W.H., 1962. Monte Carlo calculations on the dynamics of polymers
in dilute solution. J. Chem. Phys. 36, 227235.
Veseley, F.J., 1982. Angular Monte Carlo integration using quaternion parameters: a spherical
reference potential for CCl4. J. Comput. Phys. 47, 291296.
Vlasiuk, M., Frascoli, F., Sadus, R.J., 2016. Molecular simulation of the thermodynamic, struc￾tural, and vapor-liquid equilibrium properties of neon. J. Chem. Phys. 145, 104501.
Vlugt, T.J.H., 1999. Efficiency of parallel CBMC simulations. Mol. Sim. 23, 6378.
von Ferber, C., Monteith, J.T., Bishop, M., 2009. Shapes of two-dimensional excluded volume
continuum star polymers. Macromolecules 42, 36273631.
Wall, F.T., Mandel, F., 1975. Macromolecular dimensions obtained by an efficient Monte Carlo
method without sample attrition. J. Chem. Phys. 63, 45924596.
240 Molecular Simulation of FluidsWall, F.T., Chin, J.C., Mandel, F., 1977. Configurations of macromolecular chains confined to
strips or tubes. J. Chem. Phys. 66, 30663069.
Widom, B., 1963. Some topics in the theory of fluids. J. Chem. Phys. 39, 28082812.
Wu, D., Chandler, D., Smit, B., 1992. Electrostatic analogy for surfactant assemblies. J. Phys.
Chem. 96, 40774083.
Zifferer, G., Preusser, W., 2001. Monte Carlo simulation studies of the size and shape of ring
polymers. Macromol. Theory Sim. 10, 397407.
Zou, J., Saven, J.G., 2003. Using self-consistent fields to bias Monte Carlo methods with appli￾cations to designing and sampling protein sequences. J. Chem. Phys. 118, 38433854.
Monte Carlo simulation Chapter | 6 241This page intentionally left blankChapter 7
Integrators for molecular
dynamics
A common feature of all molecular dynamics (MD) algorithms is that the
positions of molecules are evolved with time by integrating the equations of
motion. Mathematically, the equations of motion represent a set of initial
value differential equations, which involve the evaluation of forces. In prin￾ciple, using any standard finite-difference algorithm can solve these equa￾tions. However, calculating the forces is the most time-consuming step in
MD and any algorithm that requires more than one force evaluation per time
step is unlikely to be viable computationally. This often excludes many com￾mon finite-difference algorithms such as the conventional RungeKutta
(RK) method, which would require multiple force evaluations. The other
important requirement is that the integration algorithm must be well behaved
for the force encountered in MD. As a rule of thumb, this latter requirement
means that the order of the algorithm defined as the highest order of the time
step for the equation for the solution of the coordinates should be at least
two. A consequence of these requirements is that the algorithms available for
MD form a small subset of the finite-difference algorithms in the literature
(Dahlquist and Bjo¨rk, 1974). Some finite-difference algorithms have been
both developed and specifically tuned for applications to MD.
Finite-difference algorithms used in molecular simulation can be classi￾fied as either predictor or predictorcorrector methods. In the predictor
methods, the molecular coordinates are updated from quantities that are
either calculated in the current step or that are known from previous steps.
The Verlet (1967) algorithm and its subsequent modifications are widely
used examples of predictor algorithms. In contrast, predictorcorrector algo￾rithms involve predicting new molecular coordinates; using the predicted
coordinates to calculate the value of some function; and subsequently using
this value to correct the initial prediction. The Gear (1966, 1971) algorithm
is a widely used predictorcorrector algorithm for MD. It should be noted
that these algorithms are most easily applied to atoms, and special modifica￾tions are required for molecular systems.
In this chapter, the motivation for integrator algorithms is discussed
briefly and some of the most commonly used integration schemes are
243 Molecular Simulation of Fluids. DOI: https://doi.org/10.1016/B978-0-323-85398-9.00015-0
© 2024 Elsevier B.V. All rights reserved.considered in detail. The problem imposed by molecular systems is also
addressed. The merits of various integration schemes have been discussed
elsewhere (Berendsen and van Gunsteren, 1986; Hockney and Eastwood,
1988; Heermann, 1990; Gould and Tobochnik, 1996; Gubbins and Quirke,
1996; Frenkel and Smit, 2023; Rapaport, 2004; Allen and Tildesley, 2017).
7.1 Integrating the equations of motion
At the outset, it is instructive to formulate the problem posed specifically by
MD. The force experienced by a particle during displacement is given by
Newton’s second law of motion,
Fi 5 miai ð7:1Þ
where F is the force acting on the particle, and m and a are the particle’s
mass and acceleration, respectively. It is more convenient to express acceler￾ation as the second derivative of displacement r with respect to time t
because we are interested in the evolution of the particle with time.
d2ri
dt2 5 Fi
mi
ð7:2Þ
The dynamic behavior of the whole system can be obtained by solving
Eq. (7.2) for each and every particle. Integrating Eq. (7.2) with respect to
time for a small time interval during which the force is constant yields:
dri
dt 5 Fi
mi

 t 1 c1 ð7:3Þ
At time t 5 0, the first term vanishes and the velocity is given by the con￾stant c1, which represents the initial velocity vi. In general, at time t, we obtain:
dri
dt 5 ait 1 vi ð7:4Þ
If we integrate Eq. (7.4) with respect to t, we obtain,
ri 5 rit 1
ait
2
2
1 c2 ð7:5Þ
where the constant c2 is the particle’s current position. Eq. (7.5) enables us
to calculate the particle’s displacement simply from the initial velocity and
acceleration.
7.2 Gear predictorcorrector methods
In this section, the concept of a finite-difference approach to integrating the
equations of motion is introduced and the Gear algorithm is derived
(Gear, 1971). There are many possible predictorcorrector algorithms
244 Molecular Simulation of Fluids(Dahlquist and Bjo¨rk, 1974) but only the Gear algorithm appears routinely in
MD. We note that the Gear algorithm is used much less commonly than
alternatives, such as the Verlet algorithm (discussed below) and it has been
almost completely omitted from some revised texts (Allen and Tildesley,
2017). Nonetheless, it has proved to be a consistently reliable many contem￾porary applications including thermodynamic properties (Losey and Sadus,
2019), solidliquid equilibria (Ahmed and Sadus, 2010), and nonequilibrium
behavior (Ahmed et al., 2010). The Gear approach has proved to be particu￾larly stable for the MD of polarizable molecules (Kolafa, 2005) and improve￾ments have been reported (Janek and Kolafa, 2020). When compared (Haile,
1992) with the Verlet method, the Gear algorithm shows superior conserva￾tion of energy for small time steps. In view of such considerations, it has
useful ongoing role in MD.
7.2.1 The basic Gear algorithm
Equation (7.5) shows how the particle coordinates change with time.
However, any changes in particle displacement will also affect the strength
of interparticle forces, velocities, and accelerations. Consequently, a general
method is required to evolve all of the dynamic properties of the system. In
general, the evolution of particle coordinates or any time-dependent property
can be estimated from a Taylor series expansion. The Taylor series expan￾sion for the coordinate vector is:
rðt 1 ΔtÞ 5 rðtÞ 1
dr
dt
Δt 1
1
2!
d2r
dt2 Δt
2 1
1
3!
d3r
dt3 Δt
3 1
1
4!
d4r
dt4 Δt
4 1? ð7:6Þ
Equation (7.6) represents the “finite-difference” approach that is com￾monly used to solve ordinary differential equations such as Eq. (7.2).
Naively, the particle velocities and accelerations could be updated by simply
using other appropriate expansions similar to Eq. (7.6).
vðt 1 ΔtÞ 5 vðtÞ 1 Δt
d2r
dt2 1
1
2!
Δt
2 d3r
dt3 1?
aðt 1 ΔtÞ 5 aðtÞ 1 Δt
d3r
dt3 1?
9
>>>>=
>>>>;
ð7:7Þ
However, this simple approach does not yield the correct trajectories because
of truncation errors. Instead, the values “predicted” by Eqs. (7.6) and (7.7) must
be “corrected” to yield the actual trajectory. The correction step involves actu￾ally calculating the accelerations ac from the new coordinates and determining
the difference Δa between these values and the predicted ap values.
Δaðt 1 ΔtÞ 5 acðt 1 ΔtÞ 2 apðt 1 ΔtÞ ð7:8Þ
Integrators for molecular dynamics Chapter | 7 245The predicted value of r can be corrected by,
rcðt 1 ΔtÞ 5 rpðt 1 ΔtÞ 1 kdΔaðt 1 ΔtÞ ð7:9Þ
where rp is the value of r originally predicted by Eq. (7.6). In Eq. (7.9), kd is a
constant that depends on the nature of the time derivative denoted by d. For
example, k0, k1, and k2 are the constants associated with position (d 5 0), veloc￾ity (d 5 1), and acceleration (d 5 2), respectively. Suitable values of kd have
been determined by Gear (1966, 1971) and they are summarized in Table 7.1.
It should be noted that the accuracy of the values obtained from the Taylor
series will depend partly on the extent of truncation. When Eq. (7.6) is trun￾cated after the second term, it is identical to Eq. (7.5). Typically, the position
vectors, velocities, and accelerations are truncated after the fourth, third, and
second time derivative, respectively. The number of equations of type (7.7)
depends on where Eq. (7.6) is truncated. For the Gear predictorcorrector
algorithm, Eq. (7.6) cannot be truncated below the third term because the algo￾rithm depends on the evaluation of accelerations in the corrector step.
The values of kd (Table 7.1) are dependent on the number of properties
that are being evolved using the predictorcorrector method. The minimum
is three corresponding to the set of position vectors r, velocities v, and accel￾erations a. However, in the estimation of these properties, we can make use
of the higher derivatives of the Taylor series (Eq. 7.6) to improve the accu￾racy of the predictions. Values for these higher derivatives can also be
evolved using a predictorcorrector equation. The improved accuracy of
these derivatives in turn impacts positively on the accuracy of the other
quantities. Consequently, we can identify three-, four-, five- and six-value
Gear algorithms depending on the number of predictorcorrector equations.
An expanded table of coefficients for various improved Gear schemes is
available (Janek and Kolafa, 2020).
The general scheme of either the Gear predictorcorrector or other pre￾dictorcorrector methods is given by Algorithm 7.1. Basically, it is a simple
TABLE 7.1 Gear corrector coefficients kd for a second-order equation
using time-scaled variables.
No. Eqs. d
r v 5 dr/dt a 5 d2
r/dt2 d3
r/dt3 d4
r/dt4 d5
r/dt5
3 01 1
4 1/6 5/6 1 1/3
5 19/120 3/4 1 1/2 1/12
6 3/20 251/360 1 11/18 1/6 1/60
246 Molecular Simulation of Fluidsthree-stage process. Initially, the coordinates and other time derivatives are
predicted from a Taylor series expansion. The new coordinates are used to
determine the true accelerations. This is the most computationally expensive
part of the simulation cycle because it involves force re-evaluation.
Subsequently, the new accelerations are used to correct the predicted posi￾tions and other time derivatives of position.
ALGORITHM 7.1 General predictorcorrector procedure for solving
equations of motion.
Predictor-Corrector:
loop
Use a Taylor series expansion to predict the positions, velocities,
 accelerations, etc.
Use the new coordinates to evaluate the true accelerations.
Use the new accelerations to correct the initial predictions.
t t + t
while(t < tmax)
It is evident from Eq. (7.6) that the various derivatives of r are multi￾plied by various constants involving time. It is common to take advan￾tage of this by defining successive scaled time derivatives r0, r1 5 Δt
(dr0/dt), r2 5 1
/2(Δt)
2
(d2
r0/dt2
), r3 5 1/6(Δt)
3
(d3
r0/dt3
). The advantage of
using time-scaled coordinates is that the predictor step of the Gear algo￾rithm can be expressed in terms of a Pascal triangle matrix, which is
easy to apply. For example, the predictor step for a four-value Gear algo￾rithm is:
r p
0 ðt 1 ΔtÞ
r p
1 ðt 1 ΔtÞ
r p
2 ðt 1 ΔtÞ
r p
3 ðt 1 ΔtÞ
0
BBB@
1
CCCA 5
1111
0123
0013
0001
0
BBB@
1
CCCA
r0ðtÞ
r1ðtÞ
r2ðtÞ
r3ðtÞ
0
BBB@
1
CCCA
ð7:10Þ
The corresponding corrector step is simply:
rc
0ðt 1 ΔtÞ
rc
1ðt 1 ΔtÞ
rc
2ðt 1 ΔtÞ
rc
3ðt 1 ΔtÞ
0
BBB@
1
CCCA 5
r
p
0ðt 1 ΔtÞ
r
p
1ðt 1 ΔtÞ
r
p
2ðt 1 ΔtÞ
r
p
3ðt 1 ΔtÞ
0
BBB@
1
CCCA
1
k0
k1
k2
k3
0
BBB@
1
CCCA
Δaðt 1 ΔtÞ ð7:11Þ
The use of time-scaled coordinates is very common and the corrector
coefficients are almost invariably quoted assuming that time-scaled variables
are used.
Integrators for molecular dynamics Chapter | 7 247ALGORITHM 7.1 Example of the implementation of Gear’s four-value
(third-order) predictorcorrector algorithm using scaled time derivatives.
Overall Algorithm
Part 1 Predictor step.
Part 2 Determine forces (fxi,, fyi, ,fzi).
Part 3 Corrector step.
Sub Algorithms
Part 1 Predictor step:
loop i  1 ... nAtom
Part 1.1 Predict new position vectors:
rxi  rxi + vxi + axi + (d3
rxi/dt3
)+(d4
rxi/dt4
)
ryi  ryi + vyi + ayi + (d3
ryi/dt3
)+ (d4
ryi/dt4
)
rzi  rzi + vzi + azi + (d3
rzi/dt3
)+ (d4
rzi/dt4
)
Part 2.2 Predict new (scaled time) velocities:
vxi  vxi + axi + 2(d3
rxi/dt3
) + 3(d4
rxi/dt4
)
vyi  vyi + ayi + 2(d3
ryi/dt3
) + 3(d4
ryi/dt4
)
vzi  vzi + azi + 2(d3
rzi/dt3
) + 3(d4
rzi/dt4
)
Part 2.3 Predict new (scaled time) accelerations:
axi  axi + (d3
rxi/dt3
) + 3(d4
rxi/dt4
)
ayi  ayi + (d3
ryi/dt3
)+ 3(d4
ryi/dt4
)
azi  azi + (d3
rzi/dt3
)+ 3(d4
rzi/dt4
)
Part 2.4 Predict new third (scaled time) derivatives:
(d3
rxi/dt3
) (d3
rxi/dt3
)+ (d4
rxi/dt4
)
(d3
ryi/dt3
) (d3
ryi/dt3
)+ (d4
ryi/dt4
)
(d3
rzi/dt3
) (d3
rzi/dt3
)+ (d4
rzi/dt4
)
end i loop
Part 3 Corrector step:
loop i  1 ... nAtom
Part 3.1 Determine new accelerations:
axNew  fxi/mi
ayNew  fyi/mi
azNew  fzi/mi
Part 3.2 Determine corrections:
deltax  axNew - axi
deltay  ayNew - ayi
deltaz  azNew - azi
Part 3.3 Correct position vectors:
rxi  rxi + k0  deltax
ryi  ryi + k0  deltay
rzi  rzi + k0  deltaz
248 Molecular Simulation of FluidsPart 3.4 Correct velocities:
vxi  vxi + k1  deltax
vyi  vyi + k1  deltay
vzi  vzi + k1  deltaz
Part 3.5 Correct accelerations:
axi  axNew
ayi  ayNew
azi  azNew
Part 3.6 Correct third time derivatives:
(d3
rxi/dt3
) (d3
rxi/dt3
) + k3  deltax
(d3
ryi/dt3
)  (d3
ryi/dt3
) + k3  deltay
(d3
rzi/dt3
) (d3
rzi/dt3
) + k3  deltaz
end i loop
Algorithm 7.2 demonstrates the use of a four-value Gear method. The
implementation is relatively straightforward. New positions, velocities, accel￾erations, and third time derivatives are predicted (Algorithm 7.2, Parts
1.11.4). The forces on the atoms at their predicted positions are evaluated
(Algorithm 7.2, Part 2) as detailed in Chapter 5. This is the most time￾consuming part of the algorithm. In the corrector step (Algorithm 7.2, Part
3), the forces are used to update the accelerations (Algorithm 7.2, Part 3.1)
and to determine corrections. The corrections are subsequently applied
(Algorithm 7.2, Parts 3.23.6) to update the positions, velocities, and the
like. In Algorithm 7.2, the Gear constants are represented by the variables
k0, k1, and k3.
7.2.1.1 Cautionary note on nomenclature
There is some confusion in the literature in the description of the different
Gear algorithms. The order of the algorithm should refer to the order of the
highest derivative. This means that a fourth-order Gear algorithm involves at
most a fourth-order derivative but it has five coefficients or values (see
Table 7.1). Therefore, fourth-order and five-value are interchangeable
descriptions for the same Gear algorithm. However, a four-value (third￾order) Gear algorithm is sometimes mistakenly referred to as fourth order,
which would incorrectly imply the use of five values. The “value” descrip￾tion used here avoids this ambiguity.
7.2.2 Other representations of the Gear algorithm
The algorithm described earlier represents the most commonly used repre￾sentation of the Gear predictorcorrector algorithm, namely, the Nordsieck
Integrators for molecular dynamics Chapter | 7 249or N-representation (Berendsen and van Gunsteren, 1986). Other representa￾tions are also possible depending on what information is kept. In the four￾value N-representation, three derivatives of r are kept, which can be used to
define the column vector rn. Using dot notation for the time derivatives, we
have (Berendsen and van Gunsteren, 1986),
rn 5 rn; Δtr_n;
Δt
2r€n
2 ;
Δt
3 r
...
n
6
 	T
? ð7:12Þ
where the elements of this vector are also vectors of length 3 N. The N-repre￾sentation only uses values from step n. An alternative is to keep only the
coordinates from previous steps. For example:
rn 5 ½  rn; rn21; rn22
T ð7:13Þ
Equation (7.13) represents a three-value, three-step coordinate or C-repre￾sentation of the Gear algorithm. It is also sometimes convenient to use coor￾dinates and velocities of one step with forces from a previous step.
rn 5 rn; Δtr_n;
Δt
2tr€n
2 ;
Δt
2r€n21
2 ;
Δt
2r€n22
2
 	T
: ð7:14Þ
Equation (7.14) is a five-value, three-step method in the force or F-repre￾sentation. Berendsen and van Gunsteren (1986) have discussed the different
representations in greater detail and they have reported values of the correc￾tor coefficients for several cases. Janek and Kolafa (2020) have also pro￾posed alternative Gear algorithms.
7.3 Verlet predictor methods
Verlet (1967) demonstrated that a simple predictor method developed by
Sto¨rmer could be used successfully in MD. Many subsequent modifica￾tions and improvements have been proposed, and the “Verlet family” of
algorithms collectively are the most widely used integration algorithms
for MD.
The Verlet algorithm belongs to the symplectic class of integrators that
preserves a canonical structure. There is evidence that symplectic algorithms
are likely to be the preferred choice for the long-time integration of
Hamiltonian dynamic systems (Leimkuhler and Skeel, 1994). Isbister et al.
(1997) have discussed symplectic algorithms for nonequilibrium MD. The
development and improvement of such integrators is an increasingly active
area of research (Greer, 1994; Okunbor and Skeel, 1994; Janeziˇ c and ˇ
Merzel, 1995; Jay, 1996; Okabe et al., 1996; Skeel et al., 1997). In this sec￾tion, we trace the development of the cornerstone Verlet algorithms and we
show how they are implemented.
250 Molecular Simulation of Fluids7.3.1 Original Verlet algorithm
In common with the correctorpredictor algorithm, the starting point for the
Verlet (1967) algorithm is a Taylor series expansion. We start by considering
the following Taylor series expansions about r(t).
rðt 1 ΔtÞ 5 rðtÞ 1
dr
dt
Δt 1
1
2!
d2r
dt2 Δt
2 1? ð7:15Þ
rðt 2 ΔtÞ 5 rðtÞ 2 dr
dt
Δt 1
1
2!
d2r
dt2 Δt
2 1? ð7:16Þ
When Eq. (7.15) and Eq. (7.16) are added, we obtain:
rðt 1 ΔtÞ 5 2rðtÞ 2 rðt 2 ΔtÞ 1
d2r
dt2 Δt
2 ð7:17Þ
Equation (7.17) is known as Verlet’s algorithm. It enables us to
advance the position of the molecules without calculating their velocities.
However, the velocities are required to determine kinetic energy. They are
obtained from:
vðtÞ 5 rðt 1 ΔtÞ 2 rðt 2 ΔtÞ
2Δt ð7:18Þ
The implementation of the Verlet algorithm is illustrated by
Algorithm 7.3. Before the Verlet algorithm can be implemented, the forces
must be calculated (Algorithm 7.3, Part 1). The forces are used subsequently
(Algorithm 7.3, Part 2.1) to calculate the accelerations (ax) required in
Eq. (7.17). The first step in the Verlet procedure (Algorithm 7.3, Part 2.1) is
to calculate the accelerations, which are used subsequently to advance the
atomic coordinates (Algorithm 7.3, Part 2.2). Unlike the Gear algorithm,
Eq. (7.17) requires both the current (rxi
) and previous values of position
(rxOldi
) to be stored in order to advance the coordinates (rxNew). The veloci￾ties must also be calculated during the execution (Algorithm 7.3, Part 2.3) of
the Verlet algorithm because this is the only time that both the updated posi￾tions (rxNew) and the previous positions (rxOld) required by Eq. (7.18) are
available. Strictly, the velocity calculations in the Verlet procedure are
optional because they do not contribute to the advancement of the atomic
coordinates. However, the calculation should be included because the indi￾vidual velocities and velocity sums are required to determine the total linear
momentum, and kinetic energy, respectively. After the new positions and
velocities are calculated, the values of the current and previous positions are
updated (Algorithm 7.3, Parts 2.4 and 2.5).
Integrators for molecular dynamics Chapter | 7 251ALGORITHM 7.3 Original Verlet method for integrating equations of motion.
Overall Algorithm
Part 1 Determine forces (fxi,, fyi, ,fzi).
Part 2 Apply Verlet algorithm.
Sub Algorithms
Part 2 Apply Verlet algorithm:
v2  0, vx  0, vy  0, vz  0 (optional)
loop i  1 ... nAtom
Part 2.1 Calculate current accelerations:
ax  fxi/mi
ay  fyi/mi
az  fzi/mi
Part 2.2 Calculate new positions:
rxNew pbc(2  rxi- rxOldi + t
2  ax)
ryNew pbc(2  ryi - ryOldi + t
2  ay)
rzNew pbc(2  rzi - rzOldi + t
2  az)
Part 2.3 Calculate new velocities (optional):
vx  (rxNew - rxOldi)/2t
vy  (ryNew - ryOldi)/2t
vz  (rzNew - rzOldi)/2t
v 2v 2
+ vx 2 + vy 2 + vz 2
vx vx + vx
vy vy + vy
vz vz + vz
Part 2.4 Update old coordinates:
rxOldi  rxi
ryOldi  ryi
rzOldi  ryi
Part 2.5 Update current coordinates:
rxi  rxNew
ryi  ryNew
rzi  rzNew
end i loop
The Verlet method is compact, easy to implement, time reversible, and it
conserves energy even for long time steps. A minor disadvantage is that the
algorithm is not self-starting. At t 5 0, an estimate is required for the position
at t 5 2 Δt. Any reasonable estimate can be used without affecting the integ￾rity of the algorithm. The main disadvantages of the Verlet algorithm are that
it does not handle velocities well and its numerical precision is not optimal
(Dahlquist and Bjo¨rk, 1974). It should be noted that the velocities calculated
by Eq. (7.18) are the current velocities rather than the velocities corresponding
to the new time step. Consequently, the calculated velocities lag the calculated
positions by one time interval. These deficiencies have been addressed by vari￾ous modifications described below.
252 Molecular Simulation of Fluids7.3.2 Leap-frog Verlet algorithm
Hockney (1970) proposed the following “leap-frog” scheme, which makes
use of the velocity at half-time intervals.
rðt 1 ΔtÞ 5 rðtÞ 1 Δtv t 1
Δt
2

  ð7:19Þ
v t 1
Δt
2

  5 v t 2 Δt
2

  1 ΔtaðtÞ ð7:20Þ
vðtÞ 5 v t 1 Δt
2
  1 v t 2 Δt
2
 
2 ð7:21Þ
Unlike the original Verlet method, the next position is determined by
both the current position and the velocity at the next half-time interval
(Eq. 7.19). The velocity at the next half-time interval is determined by the
current acceleration and the velocity at the previous half-time interval
(Eq. 7.20). The current velocity is the average velocity of the velocities at
the next and previous half-time intervals.
The implementation of the leap-frog scheme is illustrated by Algorithm 7.4.
The algorithm follows the same general procedure as the Verlet algorithm but
the calculation of velocities is now an integral part of the algorithm. The calcu￾lated accelerations (Algorithm 7.4, Part 2.1) are used to determine the half-time
velocities (Algorithm 7.4, Part 2.2). In turn, the half-time velocities are used to
update the atomic positions (Algorithm 7.4, Part 2.3) and the current velocities
(Algorithm 7.4, Part 2.4). In the leap-frog algorithm, the values that must be
stored at each time step are the current position (rxi) and the previous half-time
velocity (vxHalfOldi). These values are updated following each change in coor￾dinates (Algorithm 7.4, Parts 2.4 and 2.5).
ALGORITHM 7.4 Leap-frog Verlet method for integrating equations of motion.
Overall Algorithm
Part 1 Calculate forces (fxi,, fyi, ,fzi) at time t.
Part 2 Apply Verlet Leap-Frog algorithm at time t + t.
Sub Algorithms
Part 2 Apply Verlet Leap-Frog algorithm at time t + t:
v 2 0, vx  0, vy  0, vz  0
loop i  1 ... nAtom
Part 2.1 Calculate accelerations:
ax  fxi/mi
ay  fyi/mi
az  fzi/mi
Part 2.2 Calculate new half-time velocities:
vxHalf vxHalfOldi + t  ax
vyHalf vyHalfOldi + t  ay
vzHalf vzHalfOldi + t  az
Integrators for molecular dynamics Chapter | 7 253Part 2.3 Calculate new positions:
rxNew  pbc(rxi + t  vxHalf)
ryNew  pbc(ryi + t  vyHalf)
rzNew  pbc(ryi + t  vzHalf)
Part 2.4 Calculate current velocities:
vx  (vxHalf - vxHalfOldi)/2
vy  (vyHalf - vyHalfOldi)/2
vz  (vzHalf - vyHalfOldi)/2
v2 v2 + vx2 + vy2 + vz2
vx vx + vx
vy vy + vy
vz vz + vz
Part 2.5 Update old half-time velocities:
vxHalfOldi vxHalf
vyHalfOldi vyHalf
vzHalfOldi vzHalf
Part 2.6 Update current coordinates:
rxi  rxNew
ryi  ryNew
rzi  rzNew
end i loop
The main advantage of the leaf-frog algorithm is that numerical impreci￾sion is reduced because it uses differences between smaller quantities.
However, the calculation of velocities relies on velocity averaging at differ￾ent time intervals and the algorithm is not self-starting because initially, we
need to know the velocity at t 5 2 Δt/2. This latter difficultly can be over￾come by using reverse Euler estimates of velocities.
v 2Δt
2

  5 vð0Þ 2 að0Þ
Δt
2 ð7:22Þ
In common with the original Verlet algorithm, the calculation of veloci￾ties lags one time interval behind the calculation of positions.
7.3.3 Velocity-Verlet algorithm
Swope et al. (1982) proposed the following velocity-Verlet procedure that
improves the calculation of the velocities.
rðt 1 ΔtÞ 5 rðtÞ 1 ΔtvðtÞ 1
Δt
2aðtÞ
2 ð7:23Þ
v t 1
Δt
2

  5 vðtÞ 1
ΔtaðtÞ
2 ð7:24Þ
vð Þ t 1 Δt 5 v t 1
Δt
2

  1
Δtaðt 1 ΔtÞ
2 ð7:25Þ
The velocity-Verlet algorithm is effectively a three-value predictorcorrec￾tor procedure as illustrated by Algorithm 7.5. First, the new positions (rxNewi
)
254 Molecular Simulation of Fluids(Algorithm 7.5, Part 1.1) and half-time velocities (rxHalfi
) (Algorithm 7.5, Part
1.2) are calculated in accordance with Eqs. (7.23) and (7.24), respectively. The
forces experienced by the atoms in their new positions are calculated
(Algorithm 7.5, Part 2). Notice that in contrast to either the Verlet or leap-frog
algorithms, the calculation of forces occurs at the midway point and not at the
start of the algorithm. The remaining part of the calculation involves complet￾ing the velocity calculation (Algorithm 7.5, Part 3). The newly calculated
forces are used to calculate the accelerations at t 5 t 1 Δt (Algorithm 7.5,
Part 3.1), which then enables the completion of the velocity calculation
(Algorithm 7.5, Part 3.2) via Eq. (7.25). The current velocities (Algorithm 7.5,
Part 3.3), accelerations (Algorithm 7.5, Part 3.3), and positions (Algorithm 7.5,
Part 3.4) are updated at the completion of the algorithm.
ALGORITHM 7.5 Velocity-Verlet method for integrating equations of motion.
Overall Algorithm
Part 1 Calculate positions at time t + t and half-time velocities.
Part 2 Calculate forces (fxi,, fyi, ,fzi) at the new positions.
Part 3 Complete velocity calculation.
Sub Algorithms
Part 1 Calculate positions at time t + t and half-time velocities:
loop i  1 .. nAtom
Part 1.1 Calculate new positions:
rxNewi  pbc(rxi + t  vxi + t
2  axi/2)
ryNewi  pbc(ryi + t  vyi + t
2  ayi/2)
rzNewi  pbc(rzi + t  vzi + t
2  azi/2)
Part 1.2 Calculate new half-time velocities:
vxHalfi  vxi + t  axi/2
vyHalfi  vyi + t  ayi/2
vzHalfi  vzi + t  azi/2
end i loop
Part 3 Complete velocity calculation:
v2  0, vx  0, vy  0, vz  0
loop i  1 .. nAtom
Part 3.1 Calculate updated accelerations:
axNew  fxi/mi
ayNew  fyi/mi
azNew  fzi/mi
Part 3.2 Complete the calculation of velocities:
vxNew  vxHalfi + t  axNew
vyNew  vyHalfi + t  ayNew
vzNew  vzHalfi + t  azNew
v 2v 2
+ vxNew2 + vyNew2 + vzNew2
vx vx + vxNew
vy vy + vyNew
vz vz + vzNew
Integrators for molecular dynamics Chapter | 7 255Part 3.3 Update current velocities:
vxi vxNew
vyi vyNew
vzi vzNew
Part 3.4 Update current accelerations:
axi  axNew
ayi  ayNew
azi  azNew
Part 3.5 Update current positions:
rxi  rxNew
ryi  ryNew
rzi  rzNew
end i loop
Unlike either the Verlet or the leap-frog algorithms, which require the
force calculation to be performed upfront, the force calculation occurs mid￾way through the velocity-Verlet procedure. The velocity-Verlet algorithm
has the advantage that the calculation of the velocities is synchronized with
the evolution of position. Equation (7.23) requires the storage of both posi￾tions and velocities, whereas the acceleration can be calculated from the
stored values of force as required. However, because the accelerations are
calculated at step 3 (axNew) as part of the evaluation of Eq. (7.25), it is also
advantageous to store them (axi
). Some adaptations to the velocity-Verlet
approach have been proposed, but as noted by Lippert et al. (2007), care is
required to avoid unintended side effects that may degrade the numerical
accuracy.
7.3.4 Beeman modification
The procedure proposed by Beeman (Beeman, 1976; Sangster and Dixon,
1976) is possibly the most accurate of the Verlet family of algorithms for the
calculation of velocities.
rðt 1 ΔtÞ 5 rðtÞ 1 ΔtvðtÞ 1
2
3
Δt
2
aðtÞ 2 1
6
Δt
2
aðt 2 ΔtÞ ð7:26Þ
vðt 1 ΔtÞ 5 vðtÞ 1
1
3
Δtaðt 1 ΔtÞ 1
5
6
ΔtaðtÞ 2 1
6
Δtaðt 2 ΔtÞ ð7:27Þ
Equation (7.27) ensures that the calculation of velocities is synchronized
with the calculation of positions (Eq. 7.26).
The implementation of this strategy is illustrated by Algorithm 7.6. The
advancement of positions via Eq. (7.26) does not involve a recalculation of
forces. Instead, in the first step (Algorithm 7.6, Part 1), the positions are
advanced using the current positions (rxi
), current velocities (vxi
), current
accelerations (axi
), and previous accelerations (axOldi
). However, after the
256 Molecular Simulation of Fluidsnew positions have been calculated, the forces must be recalculated
(Algorithm 7.6, Part 2) to update the velocities (Algorithm 7.6, Part 3.1)
because Eq. (7.27) requires new values of the accelerations (axNew).
Following the calculation of the new accelerations (Algorithm 7.6, Part 3.1)
and velocities (Algorithm 7.6, Part 3.2), the stored values must be updated
(Algorithm 7.6, Parts 3.3 and 3.4). The algorithm requires the storage of cur￾rent values of position (rxi
), velocity (vxi
), and acceleration (axi
) in addition to
accelerations (axOldi
) from a previous time step.
In common with other modifications of the Verlet algorithm, the
BeemanVerlet algorithm is not self-starting. It also requires the storage of
the old value of acceleration a(t 2 Δt). However, this increase in
complexity is small and the algorithm is likely to yield both improved calcu￾lation of velocities and better energy conservation. In some cases, a shift in
pressure has been reported (Litniewski, 2003) using the Beeman algorithm.
ALGORITHM 7.6 BeemanVerlet method for integrating equations of motion.
Overall Algorithm
Part 1 Calculate new positions.
Part 2 Calculate forces (fxi,, fyi, ,fzi) at the new positions.
Part 3 Calculate new accelerations and velocities.
Sub Algorithms
Part 1 Calculate new positions:
loop i  1 .. nAtom
rxi  pbc(rxi + t  vxi + 2  t
2  axi/3 - t
2  axOldi/6)
ryi  pbc(ryi + t  vyi + 2  t
2  ayi/3 - t
2  ayOldi/6)
rzi  pbc(rzi + t  vzi + 2  t
2  azi/3 - t
2  azOldi/6)
end i loop
Part 3 Calculate new accelerations and velocities:
v2  0, vx  0, vy  0, vz  0
loop i  1 .. nAtom
Part 3.1 Calculate new accelerations:
axNew  fxi/mi
ayNew  fyi/mi
azNew  fzi/mi
Part 3.2 Calculate new velocities:
vxNew vxi + t  axNew/3 + 5  t  axi/6 - t  axOldi/6
vyNew vyi + t  ayNew/3 + 5  t  ayi/6 - t  ayOldi/6
vzNew vxi + t  azNew/3 + 5  t  azi/6 - t  azOldi/6
v 2v 2
+ vxNew2 + vyNew2 + vzNew2
vx vx + vxNew
vy vy + vyNew
vz vz + vzNew
Part 3.3 Update velocities:
vxi vxNew
vyi vyNew
vzi vzNew
Integrators for molecular dynamics Chapter | 7 257Part 3.4 Update accelerations:
axOldi  axi
ayOldi  ayi
azOldi  azi
axi  axNew 
ayi  ayNew
azi  azNew
end i loop
7.4 RungeKutta integration
The Verlet algorithms have been specifically adapted and refined for use in
MD. However, as noted in the introduction, the problem can be generalized as
the study of a pair of N-coupled first-order systems of differential equations.
y0 5 fðx; y;zÞ
z0 5 gðx; y;zÞ

ð7:28Þ
Equation (7.28) is solved in parallel. The fourth-order RungeKutta (RK4)
solution (Abramowitz and Stegun, 1972) involves the following evaluations,
yn11 5 yn 1
k1
6
1
k2
3
1
k3
3
1
k4
6
zn11 5 zn 1
l1
6
1
l2
3
1
l3
3
1
l4
6
9
>>>>=
>>>>;
ð7:29Þ
where:
k1 5 hfðxn; yn;znÞ
l1 5 hgðxn; yn;znÞ
k2 5 hf xn 1
h
2
; yn 1
k1
2 ;zn 1
l1
2
0
@
1
A
l2 5 hg xn 1
h
2
; yn 1
k1
2 ;zn 1
l1
2
0
@
1
A
k3 5 hf xn 1
h
2
; yn 1
k2
2 ;zn 1
l2
2
0
@
1
A
l3 5 hg xn 1
h
2
; yn 1
k2
2 ;zn 1
l2
2
0
@
1
A
k4 5 hf xð Þ n 1 h; yn 1 k3;zn 1 l3
l4 5 hg xð Þ n 1 h; yn 1 k3;zn 1 l3
9
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>=
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>;
ð7:30Þ
In the context of MD, y 5 r, z 5 v, x 5 t and h 5 Δt. Algorithm 7.7 illus￾trates a possible MD implementation of the RK4 algorithm.
258 Molecular Simulation of FluidsALGORITHM 7.7 RK4 integration of the equations of motion.
Overall Algorithm
Part 1 Store existing positions and velocities.
Part 2 Determine k1 and l1 terms and update positions and velocities.
Part 3 Calculate forces (fxi,, fyi, ,fzi) at the new positions.
Part 4 Determine k2 and l2 terms and update positions and velocities.
Part 5 Calculate forces (fxi,, fyi, ,fzi) at the new positions.
Part 6 Determine k3 and l3 terms and update positions and velocities.
Part 7 Calculate forces (fxi,, fyi, ,fzi) at the new positions.
Part 8 Determine k4 terms.
Part 9 Determine the final positions and velocities.
Part 10 Update forces (fxi,, fyi, ,fzi) at the final positions.
Sub Algorithms
Part 1 Store existing positions and velocities:
loop i  1 .. nAtom
rxOldi  rxi
ryOldi  ryi
rzOldi  rzi
vxOldi  vxi
vyOldi  vyi
vzOld  vzi
end i loop
Part 2 Determine k1 and l1 terms and update positions and velocities:
loop i  1 .. nAtom
k1xi  vxi
k1yi  vyi
k1zi  vzi
rxi  rxOldi + ∆t  k1xi /2
ryi  ryOldi + ∆t  k1yi /2
rzi  rzOldi + ∆t  k1zi /2
l1xi  fxi/mi
l1yi  fyi/mi
l1zi  fzi/mi
vxi  vxOldi + ∆t  l1xi /2
vyi  vyOldi + ∆t  l1yi /2
vzi  vzOldi + ∆t  l1zi /2
end i loop
Part 4 Determine k2 and l2 terms and update positions and velocities:
loop i  1 .. nAtom
k2xi  vxi
k2yi  vyi
k2zi  vzi
rxi  rxOldi + ∆t  k2xi /2
ryi  ryOldi + ∆t  k2yi /2
rzi  rzOldi + ∆t  k2zi /2
l2xi  fxi/mi
l2yi  fyi/mi
l2zi  fzi/mi
Integrators for molecular dynamics Chapter | 7 259k3zi  vzi
rxi  rxOldi + ∆t  k3xi
ryi  ryOldi + ∆t  k3yi
rzi  rzOldi + ∆t  k3zi
l3xi  fxi/mi
l3yi  fyi/mi
l3zi  fzi/mi
vxi  vxOldi + ∆t  l3xi
vyi  vyOldi + ∆t  l3yi
vzi  vzOldi + ∆t  l3zi
end i loop
Part 8 Determine k4 terms:
loop i  1 .. nAtom
k4xi  vxi
k4yi  vyi
k4zi  vzi
l4xi  fxi/mi
l4yi  fyi/mi
l4zi  fzi/mi
end i loop
Part 9 Determine the final positions and velocities:
loop i  1 .. nAtom
rxi  rxOldi + ∆t  (k1xi /6 + k1xi/ 3 + k2xi /3 + k3xi /3 + k3xi /6)
ryi  ryOldi + ∆t  (k1xi /6 + k1xi/ 3 + k2xi /3 + k3xi /3 + k3xi /6)
rzi  rzOldi + ∆t  (k1xi /6 + k1xi/ 3 + k2xi /3 + k3xi /3 + k3xi /6)
vxi vxOldi + ∆t  (l1xi /6 + l1xi/3 + l2xi /3 + l3xi /3 + l3xi /6)
vyi vyOldi + ∆t  (l1xi /6 + l1xi/3 + l2xi /3 + l3xi /3 + l3xi /6)
vzi vzOldi + ∆t  (l1xi /6 + l1xi/3 + l2xi /3 + l3xi /3 + l3xi /6)
end i loop
vxi  vxOldi + ∆t  l2xi /2
vyi  vyOldi + ∆t  l2yi /2
vzi  vzOldi + ∆t  l2zi /2
end i loop
Part 6 Determine k3 and l3 terms and update positions and velocities:
loop i  1 .. nAtom
k3xi  vxi
k3yi  vyi
The algorithm starts (Algorithm 7.7, Part 1) by storing the initial posi￾tions and velocities because these will be needed repeatedly. Values of k1
and l1 are determined and new coordinates are determined (Algorithm 7.7,
Part 2). The new coordinates are used to determine the forces
(Algorithm 7.7, Part 3). This is repeated for the k2, l2 (Algorithm 7.7, Parts 4
and 5) and k3, l3 (Algorithm 7.7, Parts 6 and 7) pairs. The k4 and l4 terms are
subsequently evaluated (Algorithm 7.7, Part 8), which allows the final coor￾dinates and velocities to be determined (Algorithm 7.7, Part 9) via
260 Molecular Simulation of FluidsEq. (7.29). Although not explicitly shown, it is also advisable to apply peri￾odic boundary conditions after Part 9. The final update to the coordinates
means that the forces have to be re-evaluated (Algorithm 7.7, Part 10).
The advantages of the RK4 algorithm are that it is self-starting and highly
accurate. However, the major disadvantage is that it requires four force eva￾luations compared with only one force evaluation of alternative algorithms.
The sequential order-dependency of the force evaluations also limits opportu￾nities for computational gains from parallel implementation strategies.
Therefore, RK4 is used in relatively limited circumstances (Janeziˇ c and Orel, ˇ
1993; Trembiay and Carrington, 2004; Tupper, 2005), which require a high
degree of accuracy. One such example is the transient-time correlation func￾tion (Todd, 1997). It is also not symplectic, but modifications have been
reported (Yoshida, 1990) to address this issue. A simper alternative is the
second-order RungeKutta (RK2) algorithm (Abramowitz and Stegun,
1972) but this lacks the accuracy of RK4 while still requiring multiple force
devaluations. The RK4 algorithm can play a valuable supporting role for
non-self-starting algorithms by providing the first few simulation data.
7.5 Comparison of integrators
The various integrator algorithms have been compared extensively (Berendsen
and van Gunsteren, 1986; Allen and Tildesley, 2017). Kolafa (1996) has exam￾ined the suitability of several different integrators for polarizable fluids. The
main criteria for evaluating an algorithm are: speed, ease of implementation, and
accuracy. Another issue for some applications is whether the integrator is sym￾plectic, which would exclude the Gear and RK4 algorithms. For example, it has
been reported (Ratanapisit et al., 2001) that symplectic algorithms may be more
accurate than non-symplectic algorithms for some transport properties. However,
in most circumstances, this is not an important decision-making consideration.
It should be noted that speed of execution of the above integrator algo￾rithms is very similar. The Gear algorithms are slower than the
Verlet algorithms but the difference in speed is not significant. This is
because the speed of the integration is dominated overwhelming by the eval￾uation of forces. Therefore, because all of the above integrators require one
force evaluation, the execution times for the algorithms are broadly equiva￾lent. Some of the algorithms require more storage of variables than others.
However, all of the memory requirements are modest and they can be han￾dled very easily by modern computers.
The Verlet algorithms are considerably easier to implement than the Gear
algorithms and this is certainly an advantage. However, the crucial factor is accu￾racy. The trajectory predicted by the Verlet algorithms are likely to be equivalent.
However, either the velocity-Verlet or Beeman algorithms calculate the velocity
more accurately. If the time step Δt is small and the duration of the simulation
is relatively short, either a four- or five-value Gear algorithm is more accurate
Integrators for molecular dynamics Chapter | 7 261than the Verlet algorithms. However, the accuracy of the Gear algorithms dete￾riorates rapidly with both increasing step size and duration of the simulation. The
root mean square fluctuation in energy for the Verlet algorithm is almost a linear
function of Δt
2
. Consequently, for medium to large values of Δt, the
Verlet algorithms are considerably more accurate than the Gear algorithms.
7.6 Integrators for molecules
The previously discussed integrators can be applied directly to determine the
equations of motion for atoms interacting via an appropriate intermolecular
potential. For example, many MD studies of atomic systems have been
reported (Haile, 1992; Rapaport, 2004) using the square-well, Lennard-Jones,
and other potentials (Chapters 3 and 4). However, the goal of molecular sim￾ulation is to model real molecules as closely as possible. Unlike atoms that
can be treated as spherical particles, the simulation of molecules is compli￾cated by features such as rotation, intramolecular bonds, and the like. In par￾ticular, molecular bonds constrain the motion of the atoms that comprise the
molecule. Therefore, methods to integrate the equations of motion of mole￾cules must take account of the constraints imposed by bonds.
7.6.1 Small molecules
The treatment of dimers, trimers, tetramers, and the like introduces the com￾plication of molecular bonds and intramolecular orientations. From the per￾spective of mechanics (Chapter 2), it is possible to treat these small
polyatoms as rigid bodies by assuming that the bond lengths and bond angles
are fixed. This is a reasonable approximation if the amplitude of molecular
vibration is small compared with molecular size.
Goldstein et al. (2008) formulated the kinematics of rigid bodies
(Chapter 2). The motion of a rigid body has two independent contributions
arising from the translational motion of the center of mass and rotation about
the center of mass. The translational motion is determined by the total force
acting on the body, whereas rotation depends on the applied torque.
Translation of a polyatomic molecule can be treated in the same way as trans￾lation of an atom but the dynamics of rotation must be treated separately.
To treat rotation, three Euler angles are defined, which represent the
sequence of rotations of the Cartesian axes about the origin. The φ angle is the
extent of clockwise rotation about the z-axis, which is followed by a rotation of
θ about the new x-axis, and a final rotation ψ about the new z-axis. However,
the solution of either the Lagrangian or Hamiltonian equations (Chapter 2) using
Euler angles to represent the orientations suffers from the limitation that each of
these equations possesses singularities at θ 5 0 or π. The problem can be
avoided by redefining the laboratory coordinate frame (Barojas et al., 1973).
Alternatively, Evans (1977) proposed a set of four parameters or quaternions to
replace the Euler angles in the equations of motion.
262 Molecular Simulation of FluidsThe quaternion parameters are defined in terms of Euler angles.
q0 5 cos
θ
2
0
@
1
Acos
ðφ 1 ψÞ
2
0
@
1
A
q1 5 sin θ
2
0
@
1
Acos
ðφ 2 ψÞ
2
0
@
1
A
q2 5 sin θ
2
0
@
1
Asin ðφ 2 ψÞ
2
0
@
1
A
q3 5 cos
θ
2
0
@
1
Asin ðφ 1 ψÞ
2
0
@
1
A
9
>>>>>>>>>>>>>>>>>>>>=
>>>>>>>>>>>>>>>>>>>>;
ð7:31Þ
The quaternions are not independent but satisfy the relationship:
q2
0 1 q2
1 1 q2
2 1 q2
3 5 1 ð7:32Þ
The rotation matrix A is defined by,
Vprincipal 5 AUVlaboratory ð7:33Þ
and is given by:
A 5
q2
0 1 q2
1 2 q2
2 2 q2
3 2ð Þ q1q2 1 q0q3 2ð Þ q1q3 2 q0q2
2ð Þ q1q2 2 q0q3 q2
0 2 q2
1 1 q2
2 2 q2
3 2ð Þ q2q3 1 q0q1
2ð Þ q1q3 1 q0q2 2ð Þ q2q3 2 q0q1 q2
0 2 q2
1 2 q2
2 1 q2
3
0
B@
1
CA ð7:34Þ
The principal angular velocity, ωp, is related to the quaternions by the
matrix:
q_0
q_1
q_2
q_3
0
BBB@
1
CCCA 5 1
2
q0 2q1 2q2 2q3
q1 q0 2q3 q2
q2 q3 q0 2q1
q3 2q2 q1 q0
0
BBB@
1
CCCA
0
ωpx
ωpy
ωpz
0
BBB@
1
CCCA
ð7:35Þ
The quarternion method and other alternatives have been discussed in
detail elsewhere (Rapaport, 2004; Allen and Tildesley, 2017). One possible
alternative is rotation-shake (Kol et al., 1997).
7.6.2 Large molecules
In general, molecules can be considered as chains of atoms linked by bonds
of various strength, length, and type. In principle, the quaternions approach
could be applied to a large multi-atom molecules. For example, Refson and
Integrators for molecular dynamics Chapter | 7 263Pawley (1987a, b) have applied the technique to butane. However, finding
the required coordinates for large flexible molecules is difficult and would
invariably result in very awkward equations of motion.
Molecules are constrained by various intra-atomic separations and bond
angles. The concept of constraint introduced in the formulation of
Lagrangian and Hamiltonian mechanics (Chapter 2) can be applied usefully
to model the dynamics of large molecules. Consider the simple case of a tri￾atomic molecule as illustrated in Fig. 7.1.
Ignoring any angular constraints, the triatomic molecule is subject to at
least two bonding constraints,
r2
ij 2 d2
ij 5 0
r2
jk 2 d2
jk 5 0
)
ð7:36Þ
where, in this case, the d values are the equilibrium bond separations.
If either condition in Eq. (7.36) is not satisfied, a bond is broken and the tri￾atomic molecule is fragmented.
In general, if σ(r) represents the constraint, a molecule composed of N
atoms can have M constraints (de Leeuw et al., 1990; Tildesley, 1993).
σ1ðrÞ 5 0
:
:
σMðrÞ 5 0
9
>>>=
>>>;
ð7:37Þ
The 3 N EulerLagrange equations (see Chapter 2) for the molecule are:
d
dt
@L
@r_i

  2 @L
@ri
5 gi ð7:38Þ
In Eq. (7.38), L is the Lagrangian for the system of N atoms and gi is the
constraint force on atom i,
gi 5 X
M
α51
λα
@σα
@ri

  ð7:39Þ
where λα are the undetermined multipliers associated with the constraints.
i rij rjk
j
k
FIGURE 7.1 Representation of a triatomic molecule.
264 Molecular Simulation of FluidsEquation (7.38) can be used (de Leeuw et al., 1990) to derive 6 N
Hamiltonian equations of motions,
r_i 5 pi
mi
2 1
mi
X
M
α51
γα
@σα
@ri

  ð7:40Þ
p_i 5 2 @u
@ri
1 X
M
α51
X
N
j51
γα
@2
σα
@ri@rj

 r_j ð7:41Þ
where γ_α 5 λα. Furthermore, these first-order equations can be transformed
to 3N second-order differential equations of the form,
r€ 5 ai 2 1
mi
X
α
λα
@σα
@ri

  ð7:42Þ
where ai is the acceleration of atom i. The time derivative of the constraining
forces is obtained by differentiating Eq. (7.37).
dσα
dt 5 X
i
r_i
@σα
@ri

  5 0 ð7:43Þ
d2σα
dt2 5 X
i
r€i
@σα
@ri

  1 X
i
X
j
r_i
@2
σα
@ri@rj

 r_j 5 0 ð7:44Þ
An equation for the multipliers can be obtained by multiplying Eq. (7.42)
by (@σα/@ri), summing over i and substituting Eqs. (7.43) and (7.44).
2X
i
X
j
r_i
@2
σα
@ri@rj

 r_j 5 X
i
ai
@σα
@ri

  2 X
i
1
mi
X
β
λβ
@σα
@ri

  @σβ
@ri

  ð7:45Þ
In matrix notation, we have
Λ 5 ðMÞ
-1
ðF 1 TÞ ð7:46Þ
where M is a M 3 M matrix with the elements:
ðMÞαβ 5 X
i
1
mi
@σα
@ri

  @σβ
@ri

  ð7:47Þ
Λ, F, and T are vectors of length α.
ð Þ Λ α 5 λα ð7:48Þ
ðFÞα 5 X
i
ai
@σα
@ri

  ð7:49Þ
ðTÞα 5 X
i
X
j
r_i
@2
σα
@ri@rj

 r_j ð7:50Þ
Integrators for molecular dynamics Chapter | 7 265Equation. (7.42) can now be solved exactly because Eq. (7.48) provides
the required values of the undetermined multipliers. However, in practice, an
exact solution leads to considerable inaccuracy because the error in the
numerical solution of the differential equation means that the constraints are
only satisfied to the accuracy of the algorithm. Consequently, the error asso￾ciated with the exact solution increases progressively with time.
7.6.2.1 The shake algorithm
The shake1 algorithm (Ryckaert et al., 1977) is possibly the most widely
used method for calculating the equations of motion for molecules that are
subject to constraints.
Shake was developed specifically to be used in conjunction with the
Verlet (1967) integrator, which for unconstrained atoms is:
r0
i
ðt 1 ΔtÞ 5 2riðtÞ 2 riðt 2 ΔtÞ 1
Δt
2
mi
fi ð7:51Þ
However, because the atoms are subject to constraints such as bond
separations, the true positions are:
riðt 1 ΔtÞ 5 2riðtÞ 2 riðt 2 ΔtÞ 1
Δt
2
mi
ðfi 2 giÞ ð7:52Þ
Obtaining the constraining force from Eq. (7.39):
riðt 1 ΔtÞ 5 r0
i
ðt 1 ΔtÞ 2 Δt
2
mi
X
M
α51
λα
@σαðrðtÞÞ
@ri

  ð7:53Þ
The atomic coordinates at time t 1 Δt must obey the constraint equations
given by (37).
σ1ð Þ rðt 1 ΔtÞ 5 0
:
:
σMð Þ rðt 1 ΔtÞ 5 0
9
>>>=
>>>;
ð7:54Þ
Equation (7.54) represents a set of α nonlinear equations for the multi￾pliers λα that can be solved using the shake algorithm (Ryckaert et al., 1977;
Ciccotti and Ryckaert, 1986).
The first step in the shake algorithm is to obtain the unconstrained atomic
positions ri(t 1 Δt) as represented by Eq. (7.51). These coordinates are
adjusted iteratively until the constraint equations are satisfied to within a
1. We note that the shake algorithm is most commonly denoted as “SHAKE.” This can be attrib￾uted to its origin as a FORTRAN implementation (Ryckaert et al., 1977), which only used
uppercase letters. However, as the name does not represent an acronym, the use of italics is
more appropriate.
266 Molecular Simulation of Fluidsspecified tolerance. Each iteration cycles through all of the independent con￾straints. Typically, a given constraint (ω) will only involve a subset of all the
atoms (Nω). At the Ith iterative loop, the atomic coordinates are ri
old. The
forces of constraint act on these atoms at this iteration to yield new
positions.
rnew
1 5 rold
1 2 λI
ϖ
@σωðrðtÞÞ
@r1
0
@
1
A
:
:
rnew
Nω 5 rold
Nω 2 λI
ϖ
@σωðrðtÞÞ
@rNω
0
@
1
A
9
>>>>>>>>>>=
>>>>>>>>>>;
ð7:55Þ
The Lagrange multiplier is evaluated from:
λI
ω 5 σωðroldÞ
Δt2 P
Nω
i51
1
mi
@σωðrold Þ
@ri
  @σωðrðtÞÞ
@ri
 
ð7:56Þ
The multiplier evaluated from Eq. (7.56) for the ωth constraint and Ith
iteration is used in Eq. (7.55) to obtain a new guess for the atomic positions.
After tens of iterations, all the constraints are satisfied to a high degree of
accuracy and the constrained atomic positions r(t 1 Δt) are known.
A shake algorithm for a chain molecule consisting of nAtom units with
bond constraints is illustrated by Algorithm 7.8. Prior to the implementa￾tion of the shake algorithm (Algorithm 7.8, Part 2), values of the atomic
coordinates and the forces acting on each atom must be evaluated
(Algorithm 7.8, Part 1). The shake algorithm applies the constraints sub￾ject to a predetermined tolerance limit. At the outset, new atomic coordi￾nates are evaluated for each atom of each molecule using the
Verlet algorithm (Algorithm 7.8, Part 2.1). During the Verlet procedure,
two bookkeeping arrays are initialized to keep track of whether the atoms
are being moved. The array moving indicates whether the atom is being
moved whereas moved indicates whether or not the atom was moved previ￾ously. The use of these arrays is optional, however, they enable us to mini￾mize unnecessary computation by repeatedly correcting the position of the
same atom. The iterative procedure (Algorithm 7.8, Part 2.2) for evaluat￾ing the constraints follows the Verlet step. The squared bond length
bondSq is used to constrain the new positions. The constraint is applied
between each atom and its neighbor found at position atom 1 1. The number
of bonds (nBonds) is equal to the number of atoms (nAtoms) for cyclic mol￾ecule whereas for a noncyclic molecule, nBonds 5 nAtoms - 1. The square of
the distances between neighboring molecule separationSq in their new
Integrators for molecular dynamics Chapter | 7 267positions is evaluated (Algorithm 7.8, Part 2.2.1). If separationSq exceeds
the tolerance value, the old neighbor separations rxOldSepartaion,
ryOldSeparation, and rzOldSeparation are calculated. A check is made to deter￾mine whether or not the vector product rNewOld of the old and new config￾urations is less than the tolerated separation. If so, an error has been
encountered and the shake procedure is terminated. Otherwise, λ is evalu￾ated and the atomic coordinates are adjusted accordingly. A correction is
also made to the virial. The iteration terminates when either all the con￾straints are satisfied, an error is encountered, or a predefined iteration
count is exceeded. At the end of the shake procedure (Algorithm 7.8, Part
2.3), the kinetic energy is calculated, and the new and old atomic coordi￾nates are updated.
ALGORITHM 7.8 Shake method for incorporating bond-length constraints.
Overall Algorithm
Part 1 Calculate the positions and forces of all atoms.
Specify bond constraints.
tolerance 10-6
virialCorrection  0
kineticEnergy 0
Part 2 Apply shake for all molecules:
loop i 1 ... nMolecule
Part 2.1 Update atomic positions for each molecule.
Part 2.2 Iterative application of constraints.
Part 2.3 Evaluate kinetic energy and update atomic coordinates.
end i loop
if (error = false and done = true)
viralCorrection  virialCorrection/(3t
2
)
kineticEnergy kineticEnergy/2
end if
Sub Algorithms
Part 2.1 Update atomic positions for each molecule (Verlet method):
loop atom  1 ... nAtom
rxOldatom  rxi,atom
ryOldatom  ryi,atom
rzOldatom  rzi,atom
rxNewatom  pbc(2  rxi,atom - rxOldi,atom + t
2  fxi,atom/massatom)
ryNewatom  pbc(2  ryi,atom - ryOldi,atom + t
2  fyi,atom/massatom)
rzNewatom  pbc(2  rzi,atom - rzOldi,atom + t
2  fzi,atom/massatom)
movingatom  false
movedatom  true
end atom loop
268 Molecular Simulation of FluidsPart 2.2.1 Evaluate separation between neighboring atoms:
if (movedatom or movedneighbor )
rxNewSeparation  pbc(rxNewatom - rxNewneighbor)
ryNewSeparation  pbc(ryNewatom - ryNewneighbor)
rzNewSeparation  pbc(rzNewatom - rzNewneighbor)
end if
separationSq  rxNewSeparation2
+ ryNewSeparation2 + rzNewSeparation2
if (bondSqatom - separationSq > 2 × tolerance × bondSqatom)
rxOldSeparation  pbc(rxOldatom - rxOldneighbor)
ryOldSeparation  pbc(ryOldatom - ryOldneighbor)
rzOldSeparation  pbc(rzOldatom - rzOldneighbor)
rNewOld  rxOldSeparation  rxNewSeparation
+ ryOldSeparation  ryNewSeparation
+ rzOldSeparation  rzNewSeparation 
if (rNewOld  tolerance  bondSqatom)
  bondSqatom - separationSq/
(2  rNewOld  (1/massatom + 1/massneighbor))
virialCorrection  virialCorrection +   bondSqatom
rxNewatom  pbc (rxNewatom +   rxOldSeparation/massatom)
ryNewatom  pbc (ryNewatom +   ryOldSeparation/massatom)
rzNewatom  pbc (rzNewatom +   rzOldSeparation/massatom)
rxNewneighbor  pbc
(rxNew +   rxOldSeparation/massneighbor)
ryNewneighbor  pbc
(ryNew +   ryOldSeparation/massneighbor)
rzNewneighbor  pbc
(rzNewneighbor +   rzOldSeparation/massneighbor)
movingatom  true
movingneighbor  true
Part 2.2 Iterative application of constraints:
count  1
done  false
error  false
loop while (done = false and count < maxCount)
done  true
atom  1
loop while (atom < nBonds and error = false)
neighbor  atom + 1
if (neighbor > nAtom)
neighbor  1
end if
Part 2.2.1 Evaluate separation between neighboring atoms. 
end while loop
if(error = false)
loop atom 1 ... nAtom
movedatom  movingatom
movingatom  false
end atom loop
count  count + 1
end if
end while loop

neighbor
neighbor
Integrators for molecular dynamics Chapter | 7 269done false
atom atom + 1
end if
else
error  true
end if
Part 2.3 Evaluate kinetic energy and update atomic coordinates:
if (error = false and done = true)
loop atom  1, nAtom
vx  (rxNewatom - rxOldi,atom)/2t
vy  (ryNewatom - ryOldi,atom)/2t
vz  (rzNeqatom - rzOldi,atom)/2t
kineticEnergy  kineticEnergy + massatom  (vx 2 + vy 2 + vz2
)
rxi,atom  rxNewatom
ryi,atom  ryNewatom
rzi,atom  rzNewatom
rxOldi,atom  rxatom
ryOldi,atom  ryatom
rzOldi,atom  rzatom
end atom loop
end if
The shake algorithm can also be implemented (van Gunsteren and
Berendsen, 1977) using the predictorcorrector integrator. Brown (1997) has
clarified some aspects of the force of constraint used in the original predic￾torcorrector implementation of the shake algorithm and he reported an
improved version. To describe the predictorcorrector implementation of the
shake algorithm, we will use the following notation.
shakeðÞ ð r1; r2; r3 7:57Þ
This means that the positions r2 resulting from the nonconstraint step
are reset to constrained positions r3. The direction of the
displacement vectors (r2  r1) is determined by the reference positions
r1.
The first step of the algorithm is initiated by predicting new positions,
accelerations, and velocities via,
xpðt 1 ΔtÞ 5 BxðtÞ ð7:58Þ
where x is a vector containing the positions, accelerations, and velocities,
and B is the predictor matrix in the F-representation. At this stage, the fol￾lowing summation is calculated for later use.
Y 5 X
k21
i50
i 6¼ 1
ðB1i 2 B11B0iÞriðtÞ ð7:59Þ
270 Molecular Simulation of FluidsIn the absence of any forces, the positions are obtained by applying the fol￾lowing correction to the positions r(t 1 Δt) predicted from Eq. (7.58),
r2 5 rpðt 1 ΔtÞ 2 k0
Δt
2r€pðt 1 ΔtÞ
2 ð7:60Þ
where k0 is the corrector coefficient associated with position.
The shake procedure is applied to positions r2 using positions r(t) as a
reference.
shakeðÞ ð rð Þt ; r2; r3 7:61Þ
The positions are corrected for the effect of the unconstrained or free
forces.
rfreeðt 1 ΔtÞ 5 r3 1 k0
Δt
2ffree;pðt 1 ΔtÞ
2m ð7:62Þ
The shake procedure is now applied to the above positions using the
rp(t 1 Δt) positions as a reference.
shakeðrpðt 1 ΔtÞ; rfree;pðt 1 ΔtÞ; rtotalðt 1 ΔtÞÞ ð7:63Þ
This results in the final positions rtotal(t 1 Δt).
The force of constraint is calculated from:
fconstraint 5 2ðrtotalðt 1 ΔtÞ 2 rfreeðt 1 ΔtÞÞ
k0Δt2 ð7:64Þ
Consequently, the total force can be calculated.
ftotal 5 ffree 1 fconstraint ð7:65Þ
Finally, the accelerations and velocity can be obtained from,
aðt 1 ΔtÞ 5 apðt 1 ΔtÞ 1
k2
2
ftotal
m 2 r€pðt 1 ΔtÞ

  ð7:66Þ
and:
vðt 1 ΔtÞ 5 B11rðt 1 ΔtÞ 1 Y
Δt
1
Δt
2
ftotal
m 2 r€pðt 1 ΔtÞ

  ð7:67Þ
7.6.2.2 The rattle algorithm
The Verlet-based implementation of the shake algorithm suffers from the
same limitations that characterize the Verlet algorithm. The atomic velocities
are not used in the integration of the equations of motion. Instead, approximate
values are calculated following the integration step. It is difficult to start the
algorithm with previously chosen values of coordinates and velocities, and it
is also difficult to alter the time step and continue the calculation. The
Integrators for molecular dynamics Chapter | 7 271algorithm also suffers from loss of precision because it involves adding quanti￾ties that vary greatly in magnitude.
For atomic systems, the limitations of the original Verlet algorithm are
addressed by the velocity-Verlet algorithm described in Section 7.3.3.
However, as discussed by Andersen (1983), the shake algorithm cannot be
expressed in terms of the velocity-Verlet method. Instead, it is possible to
generalize the shake algorithm to include the calculation of velocities
(Andersen, 1983). The resulting rattle2 algorithm that is called calculates the
positions and velocities at a future time step from the positions and velocities
of the present time step without information from earlier time steps.
The key equations for the rattle algorithm (Andersen, 1983) are:
r_iðt 1 ΔtÞ 5 r_iðtÞ 1 hr_iðtÞ 1
Δt
2
2mi
fiðtÞ 2 2
X
j
λRRijðtÞrijðtÞ
" # ð7:68Þ
r_ðt 1 ΔtÞ 5 r_ðtÞ 1
Δt
2mi
fiðiÞ
2 Δt
2mi
2
X
j
λRRijðtÞrijðtÞfiðt 1 ΔtÞ 1 2
X
j
λRVijðt 1 ΔtÞrijðt 1 ΔtÞfi
" # ð7:69Þ
In Eqs. (7.68) and (7.69), there are two separate Lagrange multipliers for
the forces associated with the constraint. The λRRij(t) values are chosen such
that the constraint Eq. (7.37) is satisfied at time t 1 Δt. In contrast, the
λRVij(t 1 Δt) values are chosen to satisfy the time derivative of the con￾straint equations at time t 1 Δt.
r_iðtÞ 2 r_jðtÞ   riðtÞ 2 rjðtÞ   5 0 ð7:70Þ
The Lagrange multipliers can be obtained by using the same iterative
method as in the shake algorithm.
An example of the rattle algorithm is given by Algorithm 7.9. Before the
rattle algorithm can be applied the positions, forces, and bond constraints
must be known (Algorithm 7.9, Part 1). The rattle algorithm follows closely
the shake algorithm, but unlike shake, there are two distinct parts. In the first
part of rattle (Algorithm 7.9, Part 2), the positions are advanced and the
velocities are advanced half way with applied constraints. The atomic posi￾tions are updated (Algorithm 7.9, Part 2.1) using the velocity-Verlet algo￾rithm. The bond constraints are subsequently applied iteratively
(Algorithm 7.9, Part 2.2). In common with the shake algorithm this involves
evaluating the separation between bonded atoms (Algorithm 7.9, part 2.2.1)
2. It is often denoted in the literature as “RATTLE” but like shake it is not an acronym. This too
is a historical legacy of previous FORTRAN programming style that is no longer necessary in
modern implementations of the language.
272 Molecular Simulation of Fluidsand testing whether the atomic displacements satisfy the bond constraints. In
the second part of rattle (Algorithm 7.9, Part 3), the velocity move is com￾pleted and the kinetic energy and the constraint contributions to the virial are
calculated. This involves using the Verlet algorithm (Algorithm 7.9, Part 3.1)
to update the atomic positions of each molecule and the iterative application
of velocity constrains (Algorithm 7.9, Part 3.2). Applying the velocity con￾straints requires the calculation of the difference in both velocity and separa￾tion (Algorithm 7.9, part 3.2.1) between bonded atoms. The kinetic energy
(Algorithm 7.9, Part 3.3) is evaluated at the end of rattle. An alternative to
the rattle algorithm that incorporates the shake algorithm directly into the
velocity-Verlet algorithm has been also reported (Palmer, 1993).
The utility of both the shake and rattle algorithms was witnessed an
ongoing process of continuing improvements and adaptations. Versions spe￾cifically tailored to ridged water models have been reported (Miyamoto and
Kollman, 1992) and angular constraints have been considered (Gonnet et al.,
2009). Other improvements include improved efficiencies for small mole￾cules (Kra¨utler et al., 2001); geometric generalizations (McLachlan et al.,
2014); accounting for semi-rigid molecules (Forester and Smith, 1998;
Gonnet, 2007), and molecules such as the alkanes (Bailey and Lowe, 2009);
and dealing with internal constraints (Lee et al., 2005). Different ways of
benefiting for parallelization have been investigated (Weinbach and Elber,
2005; Oh and Klein, 2006; Elber et al., 2011; Ruymgaart and Elber, 2012).
7.6.2.3 Application of Gauss’s principle of least constraint
An alternative to the shake and rattle algorithms is to correct the trajectories
resulting from an exact solution of Eq. (7.42). Edberg et al. (1986) observed
that Gauss’s principle of least constraint (Chapter 2) provides an exact prescrip￾tion for deriving equations of motion involving holonomic constraint. The start￾ing point for their procedure is to differentiate the bonding constraint (Eq. 7.37)
with respect to time. For the simple case of a diatomic molecule, we find:
r12Ur€12 1 ðr_12Þ
2 5 0 ð7:71Þ
The above equation defines a plane in either r€1 or r€2 space on which the
constrained acceleration vectors must terminate. Applying Gauss’s principle
of least constraint, the equations of motion become:
q_i 5 pi
p_ 5 f1
m 2 λr12
p_ 5 f2
m 2 λr12
9
>>>>>=
>>>>>;
ð7:72Þ
Integrators for molecular dynamics Chapter | 7 273ALGORITHM 7.9 Rattle method for incorporating bond-length constraints.
Overall Algorithm
Part 1 Calculate the positions and forces of all atoms.
Specify bond constraints.
tolerance 10-6
virialCorrection  0
kineticEnergy 0
Part 2 Advance position and advance velocities half way:
loop i 1 ... nMolecule
Part 2.1 Update atomic positions for each molecule using
the velocity-Verlet algorithm.
Part 2.2 Iterative application of constraints.
end i loop
Part 3 Complete the advancement of velocities:
if (error = false and done = true)
loop i 1 ... nMolecule
Part 3.1 Update atomic positions for each molecule.
Part 3.2 Iterative application of velocity constraints.
Part 3.3 Evaluate kinetic energy and update velocities.
end i loop
if (done = true)
viralCorrection  virialCorrection/(3t
2
)
kineticEnergy kineticEnergy/2
end if
end if
Sub Algorithms
Part 2.1 Update atomic positions for each molecule using
the velocity-Verlet algorithm:
loop atom  ... nAtom
rxOldatom  rxi,atom
ryOldatom  ryi,atom
rzOldatom  rzi,atom
rxNewatom  pbc (rxOldi,atom + t  vxi,atom + t
3  fxi,atom/(2  massatom))
ryNewatom  pbc (ryOldi,atom + t  vyi,atom+ t
3  fyi,atom/(2  massatom))
rzNewatom  pbc (rzOldi,atom + t  vzi,atom + t
3  fzi,atom/(2  massatom))
vxatom  vxi,atom + t  fxi,atom/(2  massatom)
vyatom  vyi,atom + t  fyi,atom/(2  massatom)
vzatom  vzi,atom + t  fzi,atom/(2  massatom)
movingatom  false
movedtatom  true
end atom loop
Part 2.2 Iterative application of constraints:
count  1
done  false
error  false
while loop (done = false and count < maxCount)
done  true
atom  1
while (atom < nBonds and error = false)
neighbor  atom + 1
if (neighbor > nAtom)
274 Molecular Simulation of Fluidsneighbor  1
end if
 Part 2.2.1 Evaluate separation between bonded molecules.
end while loop
if(error = false)
loop atom 1 ... nAtom
movedatom  movingatom
movingatom  false
end atom loop
count count + 1
end if
end while loop
if (error = false and done = true)
loop atom  1, nAtom
rxi,atom  rxNewatom
ryi,atom  ryNewatom
rzi,atom  rzNewatom
vxi,atom  vxatom
vyi,atom  vyatom
vzi,atom  vzatom
end atom loop
end if
Part 2.2.1 Evaluate separation between bonded molecules:
if (movedatom or movedneighbor)
rxNewSeparation  pbc(rxNewatom - rxNewneighbor)
ryNewSeparation  pbc(ryNewatom - ryNewneighbor)
rzNewSeparation  pbc(rzNewatom - rzNewneighbor)
end if
separationSq rxNewSeparation2 + ryNewSeparation2
+ rzNewSeparation2
if (bondSqatom - separationSq > 2 × tolerance × bondSqatom)
rxOldSeparation pbc(rxOldatom - rxOldneighbor)
ryOldSeparation pbc(ryOldatom - ryOldneighbor)
rzOldSeparation pbc(rzOldatom - rzOldneighbor)
rNewOld  rxOldSeparation  rxNewSeparation 
+ ryOldSeparation  ryNewSeparation
+ rzOldSeparation  rzNewSeparation
if (rNewOld  tolerance  BondSqatom)
   bondSqatom - separationSq /
(2  rNewOld  (1/massatom + 1/massneighbor ))
rxNewatom  pbc (rxNewatom +   rxOldSeparation/massatom)
ryNewatom  pbc (ryNewatom +   ryOldSeparation/massatom)
rzNewatom  pbc (rzNewatom +   rzOldSeparation/massatom)
rxNewneighbor  pbc
(rxNewneighbor -   rxOldSeparation/massneighbor)
ryNewneighbor  pbc
(ryNewneighbor -   ryOldSeparation/massneighbor)
rzNewneighbor  pbc
(rzNewneighbor -   ryOldSeparation/massneighbor)
vxatom  vxatom +   rxOldSeparation/massatom
vyatom  vyatom +   ryOldSeparation/massatom
vzatom  vzatom +   rzOldSeparation/massatom
Integrators for molecular dynamics Chapter | 7 275vxneighbor  vxneighbor -   rzOldSeparation/(t  massneighbor)
vyneighbor  vyneighbor -   ryOldSeparation/(t  massneighbor)
vzneighbor  vzneighbor -   rzOldSeparation/(t  massneighbor)
movingatom  true
movingneighbor  true
done false
atom atom + 1
end if
else
error  true
end if
Part 3.1 Update atomic positions for each molecule (Verlet method):
loop atom  1 ... nAtom
rxatom  rxi,atom
ryatom  ryi,atom
rzatom  rzi,atom
vxatom  vxi,atom + t  fxi,atom /(2  massatom)
vyatom  vyi,atom + t  fyi,atom /(2  massatom)
vzatom  vzi,atom + t  fzi,atom /(2  massatom)
movingatom  false
movedtatom  true
end atom loop
Part 3.2 Iterative application of velocity constraints:
count  1
done  false
error  false
loop while (done = false and count < maxCount)
done  true
atom  1
loop while (atom < nBonds and error = false)
neighbor  atom + 1
if (neighbor > nAtom)
neighbor  1
end if
Part 3.2.1 Evaluate velocity difference/separation btw 
 bonded atoms.
atom atom + 1
end while loop
if (error = false)
loop atom 1 ... nAtom
movedatom movingatom
movingatom false
end atom loop
count count + 1
end if
end while loop
276 Molecular Simulation of FluidsPart 3.2.1 Evaluate velocity difference/separation between bonded 
atoms:
if (movedatom or movedneighbor)
vxDiff  vxatom - vxneighbor
vyDiff  vyatom - vyneighbor
vyDiff  vzatom - vzneighbor
rxSeparation  pbc(rxatom - rxneighbor)
rySeparation  pbc(ryatom - ryneighbor)
rzSeparation  pbc(rzatom - rzneighbor)
sepVel  rxSeparation  vxDiff + rySeparation  vyDiff 
+ rzSeparation  vzDiff
  -sepVel/(bondSqatom  (1/massatom + 1/massneighbor))
if ( > tolerance)
virialCorrection  virialCorrection +   bondSqatom
vxatom  vxatom +   rxSeparation/massatom
vyatom  vyatom +   rySeparation/massatom
vzatom  vzatom +   rzSeparation/massatom
vxneighbor  vxneighbor +   rxSeparation/massneighbor
vyneighbor  vyneighbor +   rySeparation/massneighbor
vzneighbor  vzneighbor +   rzSeparation/massneighbor
movingatom  true
movingneighbor  true
done false
else
error  true
end if
end if
Part 3.3 Evaluate kinetic energy and update velocities:
if (done = true)
loop atom  1, nAtom
vxi,atom  vxatom
vyi,atom  vyatom
vzi,atom  vzatom
kineticEnergy kineticEnergy + massatom  (vx 2 + vy 2 + vz 2
)
end atom loop
end if
If the molecule has more than two atoms, the site equations of motion are
the same as Eq. (7.72) except that each site is subject to coupled constraint
forces. It is apparent that a set of multipliers λij must also be calculated to
solve these equations.
Edberg et al. (1986) proposed the use of penalty functions to keep the solu￾tion on track. If Eq. (7.42) is solved exactly, at some stage the predicted posi￾tions and velocities will be a significant distance from the constraint surface.
When this occurs, the trajectory can be relaxed back on the constraint surface
by minimizing the following penalty functions.
Φα 5 ð Þ σαðrÞ 2 ð7:73Þ
Ψα 5 ð Þ σ_ αðr; r_Þ 2 ð7:74Þ
Integrators for molecular dynamics Chapter | 7 277Overall values of Φ and Ψ are obtained for each molecule by summing
the contributions from the individual constraints. When Φ and Ψ reach a pre￾determined value, a nonlinear minimization is performed to find the 6 N
values of ri and r_i at the minimum. Edberg et al. (1986) found that a simula￾tion involving sixty-four butane molecules modeled as united atoms required
a mean minimization period of eighty-six integration steps.
7.6.2.4 Matrix inversion method
de Leeuw et al. (1990) proposed a method of correcting trajectories using
matrix inversion. Solving Eq. (7.42) exactly normally results in a set of coor￾dinates r0, which have drifted from the true constrained values. If the con￾straints were satisfied at a particular time step, the drift in coordinates
caused by subsequently solving Eq. (7.42) can be represented by,
σαðroÞ 5 0ðΔt
k
Þ ð7:75Þ
where k is the order of the differential solver. The true coordinates can be
obtained by applying the following correction.
ri 5 ri0 1 Δt
kX
M
α51
εα
@σαðrÞ
@ri

  ð7:76Þ
The correction parameters are obtained by substituting these coordinates
into the constraint equations (Eq. 7.37). The constraints can be obtained to 0
(Δt
2k) by using a Taylor expansion of σ(r) and @σα/@ri about r0.
σαðrÞ 5 σαðr0Þ 1 Δt
kX
M
β51
X
N
i51
εβ
@σαðr0Þ
@ri

  @σβðr0Þ
@ri

  ð7:77Þ
A set of M equations is obtained for the correction coefficients because
the higher order terms in Eq. (7.77) are negligible and they can be neglected,
ε 5 2 Δt
2k
ðM0Þ
21
σ ð7:78Þ
where:
ðM0Þαβ 5 X
N
i51
@σαðr0Þ
@ri

  @σβðr0Þ
@ri

  ð7:79Þ
ðσÞα 5 σαðr0Þ ð7:80Þ
ðεÞα 5 εα ð7:81Þ
The εα values are those used in Eq. (7.76) to convert the atomic positions
to 0(Δt
2k). The following approximation is necessary to use Eq. (7.76):
278 Molecular Simulation of Fluids@σαðrÞ
@ri

  5 @σαðr0Þ
@ri

  ð7:82Þ
7.6.2.5 Other methods
Yoneya et al. (1994) proposed a self-correcting noniterative constraint proce￾dure. The starting point for their method is a Taylor expansion of the con￾straint condition.
σnðt 1 ΔtÞ 1 OðΔt
3
Þ 5 σnðtÞ 1 Δtσ_ nðtÞ 1
Δt
2σ€ nðtÞ
2 ð7:83Þ
If the Verlet algorithm is applied to the constraint conditions, we obtain:
σnðt 1 ΔtÞ 5 ð Þ 2rnðtÞ2rnðt2ΔtÞ 2 2 d2
n 1 2Δt
2ð Þ 2rnðtÞ 2 rnðt 2 ΔtÞ r€nðtÞ
1 OðΔt
4Þ 5 0
ð7:84Þ
In deriving the above equation, terms nonlinear in λ were neglected. A
set of M linear equations for λ(t) is obtained by substituting the expression
for r€ obtained from the equations of motion, into Eq. (7.84).
Slusher and Cummings (1996) proposed a velocity-Verlet implementation
of the algorithm of Yoneya et al. (1994).
σðt 1 ΔtÞ 5 r2
nðtÞ 2 d2
n 1 2ΔtrnðtÞr_nðt 2 ΔtÞ 1 Δt
2r2
nðt 2 hÞ
1 Δt
2 rnðtÞ 1 Δtr_ ð Þ nðt 2 ΔtÞ 2r€nðtÞ 1 r€ ð Þ nðt 2 ΔtÞ
1 OðΔt
4Þ
5 0
ð7:85Þ
Substituting the constrained equations of motion for in the above equa￾tion yields a rank M matrix. Equation (7.85) can be used immediately after
the position update and force evaluation by the velocity-Verlet algorithm.
Consequently, the same force constraints are used in both the velocity and
position updates.
Another alternative to the shake algorithm is the successive overrelaxa￾tion (SOR) method (Barth et al., 1995). The SOR method has been imple￾mented using the CHARMM potential (Chapter 3) and a twofold
improvement in execution speed over the shake algorithm has been reported
(Barth et al., 1995).
7.7 Summary
MD simulation requires a suitable algorithm to integrate the equations of
motion. The choice of integrators is constrained by the necessity of limiting
the costly evaluation of forces to once per time step. For atoms, there are a
variety of widely used integrator algorithms. The origin of many integrator
algorithms used in MD can be traced to either the Gear predictorcorrector
Integrators for molecular dynamics Chapter | 7 279or Verlet predictor algorithms. These algorithms only require one force eval￾uation per time step. A general fourth-order RungeKutta integrator is use￾ful for accurate evaluations but is computationally expensive because it
requires multiple force evaluations per time step. Solving the equations of
motion for molecules is considerably more challenging than the atomic case
because of the restrictions imposed by bonding constrains. The shake and
rattle algorithms are possibly the most commonly used algorithms for mole￾cules. The application of MD in the context of ensembles is discussed in
Chapter 9. In Chapter 11, MD code using the Gear algorithm is provided.
References
Abramowitz, M., Stegun, A. (Eds.), 1972. Handbook of Mathematical Functions with Formulas,
Graphs and Mathematical Tables, 9th Printing. Dover Publications, p. 897.
Ahmed, A., Sadus, R.J., 2010. Effect of potential truncations and shifts on the solid-liquid phase
coexistence of Lennard-Jones fluids. J. Chem. Phys. 133, 124515.
Ahmed, A., Mausbach, P., Sadus, R.J., 2010. Pressure and energy behavior of the Gaussian core
model fluid under shear. Phys. Rev. E 82, 011201.
Allen, M.P., Tildesley, D.J., 2017. Computer Simulation of Liquids, second ed. Oxford
University Press, Oxford.
Andersen, H.C., 1983. Rattle: a “velocity” version of the shake algorithm for molecular dynam￾ics calculations. J. Comput. Phys. 52, 2434.
Bailey, A.G., Lowe, C.P., 2009. MILCH SHAKE: An efficient method for constraint dynamics
applied to alkanes. J. Comput. Chem. 30, 24852493.
Barojas, J., Levesque, D., Quentrec, B., 1973. Simulation of diatomic homonuclear liquids.
Phys. Rev. A7, 10921105.
Barth, E., Kuczera, K., Leimkuhler, B., Skeel, R.D., 1995. Algorithms for constrained molecular
dynamics. J. Comput. Chem. 16, 11921209.
Beeman, D., 1976. Some multistep methods for use in molecular dynamics calculations.
J. Comput. Phys. 20, 130139.
Berendsen, H.J. C. and van Gunsteren, W.F. in Ciccotti, G. and Hoover, W. G. (Eds), Molecular￾Dynamics Simulation of Statistical-Mechanical Systems, North-Holland, Amsterdam, 1986.
Brown, D., 1997. The force of constraint in predictor-corrector algorithms for shake constraint
dynamics. Mol. Sim. 18, 339348.
Ciccotti, G., Ryckaert, J.P., 1986. Molecular dynamics simulation of rigid molecules. Comp.
Phys. Rep. 4, 345392.
Dahlquist, G., Bjo¨rk, A., 1974. Numerical Methods. Prentice-Hall, Englewood Cliffs, NJ.
de Leeuw, S.W., Perram, J.W., Petersen, H.G., 1990. Hamilton’s equations for constrained
dynamical systems. J. Stat. Phys. 61, 12031221.
Edberg, R., Evans, D.J., Morriss, G.P., 1986. Constrained molecular dynamics: simulations of
liquid alkanes with a new algorithm. J. Chem. Phys. 84, 69336939.
Elber, R., Ruymgart, A.P., Hess, B., 2011. SHAKE parallelization. Eur. Phys. J. Spec. Top. 200,
211223.
Evans, D.J., 1977. On the representation of orientation space. Mol. Phys. 34, 317325.
Forester, T.R., Smith, W., 1998. SHAKE, Rattle, and roll: efficient constraint algorithms for
linked rigid bodies. J. Comput. Chem. 19, 102111.
280 Molecular Simulation of FluidsFrenkel, D., Smit, B., 2023. Understanding Molecular Simulation. From Algorithms to
Applications, third ed. Academic Press, San Diego.
Gear, C.W. (1966). The numerical integration of ordinary differential equations of various
orders. Report ANL 7126, Argone National Laboratory (Available at: https://www.osti.gov/
biblio/4534813-numerical-integration-ordinary-differential-equations-various-orders).
Gear, C.W., 1971. Numerical Initial Value Problems in Ordinary Differential Equations.
Prentice-Hall, Englewood Cliffs, NJ.
Goldstein, H., Poole, C., Safko, J., 2008. Classical Mechanics, third ed. Addison Wesley, San
Francisco.
Gonnet, P., 2007. P-SHAKE: A quadratically convergent SHAKE in O (n2
). J. Comput. Phys.
220, 740750.
Gonnet, P., Walther, J.H., Koumoutsakos, P., 2009. θ-SHAKE: An extension to SHAKE for the
explicit treatment of angular constraints. Comp. Phys. Commun. 180, 360364.
Gould, H., Tobochnik, 1996. An Introduction to Computer Simulation Methods: Application to
Physical Systems, second ed. Addison-Wesley, Reading.
Greer, J.C., 1994. An approximate time evolution operator to generate the Verlet algorithm.
J. Comput. Phys. 115, 245247.
Gubbins, K.E., Quirke, N. (Eds.), 1996. Molecular Simulation and Industrial Applications.
Methods, Examples and Prospects. Gordon and Breach, Amsterdam.
Haile, J.M., 1992. Molecular Dynamics Simulation. Elementary Methods. John Wiley & Sons,
New York.
Heermann, D.W., 1990. Computer Simulation Methods in Theoretical Physics, second ed.
Springer-Verlag, Heidelberg.
Hockney, R.W., 1970. The potential calculation and some applications. Methods Comput. Phys.
9, 136211.
Hockney, R.W., Eastwood, J.W., 1988. Computer Simulation Using Particles. Adam Hilger,
Bristol.
Isbister, D.J., Searles, D.J., Evans, D.J., 1997. Symplectic properties of algorithms and simula￾tion methods. Phys. A 240, 105114.
Janek, J., Kolafa, J., 2020. Novel Gear-like predictor-corrector integration methods for molecular
dynamics. Mol. Phys. 118, 210.
Janeziˇ c, D., Orel, F., 1993. Implicit Runge-Kutta method for molecular dynamics integration. ˇ
J. Chem. Inf. Comput. Sci. 33, 252257.
Janeziˇ c, D., Merzel, F., 1995. An efficient symplectic integration algorithm for molecular ˇ
dynamics simulations. J. Chem. Inf. Comput. Sci. 35, 321326.
Jay, L., 1996. Symplectic partitioned Runge-Kutta methods for constrained Hamitonian systems.
SIAM J. Numer. Anal. 33, 368387.
Kol, A., Laird, B.B., Leimkuhler, B.J., 1997. A symplectic method for rigid-body molecular sim￾ulation. J. Chem. Phys. 107, 25802588.
Kolafa, J., 1996. Numerical integration of equations of motion with self-consistent field given
by an implicit equation. Mol. Sim. 18, 193212.
Kolafa, J., 2005. Gear formalism of the always stable predictor-corrector method for molecular
dynamics of polarizable molecules. J. Chem. Phys. 122, 164105.
Kra¨utler, V., van Gunsteren, W.F., Hu¨nenberger, P.H., 2001. A fast SHAKE algorithm to solve
distance constraint equations for small molecules in molecular dynamics simulations.
J. Comput. Chem. 22, 501508.
Lee, S.-H., Palmo, K., Krimm, S., 2005. WIGGLE: A new constrained molecular dynamics algo￾rithm in Cartesian coordinates. J. Comput. Phys. 210, 171182.
Integrators for molecular dynamics Chapter | 7 281Leimkuhler, B.J., Skeel, R.D., 1994. Symplectic numerical integrators in constrained
Hamiltonian systems. J. Comput. Phys. 112, 117125.
Lippert, R.A., Bowers, K.J., Dror, R.O., Eastwood, M.P., Gregersen, B.A., Klepeis, J.L.,
Kolossvary, I., Shaw, D.E., 2007. A common, avoidable source of error in molecular
dynamics integrators. J. Chem. Phys. 126, 046101.
Litniewski, M., 2003. On molecular dynamics algorithms. Mol. Sim. 29, 223229.
Losey, J., Sadus, R.J., 2019. Thermodynamic properties and anomalous behavior of double￾Gaussian core model potentials. Phys. Rev. E 100, 0132112.
McLachlan, R.I., Modin, K., Verdier, O., Wilkins, M., 2014. Geometric generalisations of
SHAKE and RATTLE. Found. Comput. Math. 14, 339370.
Miyamoto, S., Kollman, P.A., 1992. SETTLE  An analytical version of the SHAKE and
RATTLE algorithms for rigid water models. J. Compt. Chem. 13, 952962.
Oh, K.J., Klein, M.L., 2006. A parallel molecular dynamics simulation scheme for a molecular
system with bond constraints in NPT ensemble. Comp. Phys. Commun. 174, 263269.
Okabe, T., Yamada, H., Goda, M., 1996. How is symplectic integrator applicable to molecular
dynamics. Int. J. Mod. Phys. C. 7, 613633.
Okunbor, D.I., Skeel, R.D., 1994. Canonical numerical methods for molecular dynamics simula￾tions. J. Comput. Chem. 15, 7279.
Palmer, B.J., 1993. Direct application of SHAKE to the velocity Verlet algorithm. J. Comput.
Phys. 104, 470472.
Rapaport, D.C., 2004. The Art of Molecular Dynamics Simulation, second ed. Cambridge
University Press, Cambridge.
Ratanapisit, J., Isbister, D.J., Ely, J.F., 2001. Transport properties of fluids: Symplectic integra￾tors and their usefulness. Fluid Phase Equilib. 183184, 351361.
Refson, K., Pawley, G.S., 1987a. Molecular dynamics studies of the condensed phases of n￾butane and their transitions. I. Techniques and model results. Mol. Phys. 61, 669692.
Refson, K., Pawley, G.S., 1987b. Molecular dynamics studies of the condensed phases of n￾butane and their transitions. II. The transition to the true plastic phase. Mol. Phys. 61,
693709.
Ruymgaart, A.P., Elber, R., 2012. Revisiting molecular dynamics on a CPU/GPU system: water
kernel and SHAKE parallelization. J. Chem. Theory Comput. 8, 46244636.
Ryckaert, J.P., Ciccotti, G., Berendsen, H.J.C., 1977. Numerical integration of the Cartesian
equations of motion of a system with constraints: molecular dynamics of n-alkanes.
J. Comput. Phys. 23, 327341.
Sangster, M.J.L., Dixon, M., 1976. Interionic potentials in alkali halides and their use in simula￾tion of molten salts. Adv. Phys. 25, 247342.
Skeel, R.D., Zhang, G., Schlick, T., 1997. A family of symplectic integrators: stability, accuracy,
and molecular dynamics applications. SIAM J. Sci. Comput. 18, 203222.
Slusher, J.T., Cummings, P.T., 1996. Non-iterative constraint dynamics using velocity-explicit
Verlet methods. Mol. Sim. 18, 213224.
Swope, W.C., Andersen, H.C., Berens, P.H., Wilson, K.R., 1982. A computer simulation method
for the calculation of equilibrium constants for the formulation of physical clusters of mole￾cules: application to small water clusters. J. Chem. Phys. 76, 637649.
Tildesley, D.J., 1993. In: Allen, M.P., Tildesley, D.J. (Eds.), Computer Simulation in Chemical
Physics. Dordecht, Kluwer.
Todd, B.D., 1997. Application of transient-time correlation functions to nonequilibrium
molecular-dynamics simulations of elongational flow. Phys. Rev. E 56, 67236728.
282 Molecular Simulation of FluidsTrembiay, J.C., Carrington Jr, T., 2004. Using preconditioned adaptive step size Runge-Kutta
methods for solving the time-dependent Schro¨dinger equation. J. Chem. Phys. 121,
1153511541.
Tupper, P.F., 2005. A test problem for molecular dynamics integrators. IMA J. Numer. Anal. 25,
286309.
van Gunsteren, W.F., Berendsen, H.J.C., 1977. Algorithms for macromolecular dynamics and
constraint dynamics. Mol. Phys. 34, 13111327.
Verlet, L., 1967. Computer “experiments” on classical fluids. I. Thermodynamical properties of
Lennard-Jones molecules. Phys. Rev. 159, 98103.
Weinbach, Y., Elber, R., 2005. Revisiting and parallelizing SHAKE. J. Comput. Phys. 209,
193206.
Yoneya, M., Berendsen, H.J.C., Hirasawa, K., 1994. A non-iterative matrix method for constraint
molecular dynamics simulations. Mol. Sim. 13, 395405.
Yoshida, H., 1990. Construction of higher order symplectic integrators. Phys. Lett. A 150,
262268.
Integrators for molecular dynamics Chapter | 7 283This page intentionally left blankChapter 8
Nonequilibrium molecular
dynamics
In addition to equilibrium properties, molecular dynamics (MD) can be applied
to nonequilibrium systems. Nonequilibrium molecular dynamics (NEMD)
algorithms fall into two broad categories, namely, inhomogeneous and homoge￾neous methods. The distinction between the two categories is based on the
nature of the boundary conditions required. Inhomogeneous methods involve
nonperiodic boundary conditions whereas homogeneous methods employ
some sort of periodic boundaries.
Ashurst and Hoover (1973) employed an inhomogeneous NEMD
approach to simulate steady flow. They used a pair of nonperiodic bound￾ary layers consisting of a small number of particles with the same spatial
correlations as the fluid in the central cell. Shear flow was induced by
moving the boundary layers in opposite directions along parallel planes.
A secondary role of the boundary layers was to act as thermostats to
extract the heat generated by the viscous flow. Several variants of this
general approach have been developed (Tenenbaum et al., 1982; Trozzi
and Ciccotti, 1984).
Although inhomogeneous methods are useful in some important applica￾tions (Wold and Hafskjold, 1999; Todd and Daivis, 2017), we will focus
exclusively on homogeneous methods. In general, homogeneous methods are
preferred because replacing physical walls by periodic boundaries means that
all atoms experience the same environment. In contrast, the properties of
inhomogeneous systems are perturbed artificially by wallfluid interactions.
A disadvantage of homogeneous methods is that the equations of motions of
the molecules must be altered artificially.
The earliest application of homogeneous NEMD techniques also involved
shear flow. Lees and Edwards (1972) used a moving periodic boundary,
whereas Gosling et al. (1973) induced shear flow by applying a sinusoidal
transverse force field to the particles. A limitation of these early methods
was that the strong fields used resulted in substantial heating, which required
the introduction of a thermostat. This problem can be circumvented by using
a subtraction of trajectories strategy (Ciccotti et al., 1979).
285 Molecular Simulation of Fluids. DOI: https://doi.org/10.1016/B978-0-323-85398-9.00006-X
© 2024 Elsevier B.V. All rights reserved.The use of a thermostat can be avoided by making only small perturba￾tions but the nature of the perturbation must be defined for the particular
problem being studied. This problem has been addressed by the use of the
dolls tensor (Hoover et al., 1980) and the sllod1 tensor (Ladd, 1984; Evans
and Morriss, 1984a).
If large perturbations are used, further devices must be used to prevent
the system overheating. One approach is to employ Nose´Hoover dynamics
(Hoover, 1985). Evans et al. (1983) performed NEMD by employing
Gauss’s principle of least constraint (Chapter 2). The general approach is to
use a driving force to maintain a thermodynamic flux while using constraint
forces to extract the heat.
This chapter provides a brief overview of NEMD with emphasis on
synthetic NEMD and its applications. The main use for NEMD is the cal￾culation of transport properties (Sadus, 2006). Cummings and Evans
(1992) have reviewed the use of NEMD for transport properties. Evans
and Morriss (2008) have discussed the statistical mechanical basis of non￾equilibrium liquids. The theoretical basis and historical development of
NEMD have been discussed elsewhere (Evans and Morriss, 1984b; Evans,
1986a,b; Ciccotti, 1991; Hoover 1991; Rapaport, 2004; Allen and
Tildesley, 2017). A notable advance has been the development of NEMD
algorithms for elongational flow (Todd and Daivis, 1998; Hunt and Todd,
2003; Hunt et al., 2010). The practical implementation of many new and
promising NEMD algorithms has been very extensively detailed by Todd
and Daivis (2017).
Transport properties can be also be calculated from equilibrium molecu￾lar dynamics (EMD) trajectories using either Einstein or GreenKubo rela￾tionships. An example of the EMD to the calculation of shear viscosity is
given by Schoen and Hoheisel (1985). An EMD algorithm (Heffelfinger and
van Swol, 1994) has been used to investigate diffusion involving Lennard￾Jones (LJ) fluids (Heffelfinger and Ford, 1998) and polymers (Ford and
Heffelfinger, 1998).
8.1 An example NEMD algorithm
In Chapter 1, a general EMD algorithm was outlined (Algorithm 1.1). Before
considering the theoretical aspects of NEMD, it is useful to consider the
overall structure of an NEMD algorithm. This is illustrated in Algorithm 8.1
for the special case of the Gear predictorcorrector integrator at a constant
strain rate (γ_). The general procedure used in Algorithm 8.1 can be applied
to other integrators.
1. In the literature dolls and sllod are commonly denoted as “DOLLS” and “SLLOD,” respec￾tively. The use of capital letters is misleading as neither of the terms corresponds to any mean￾ingful acronym. Indeed, sllod is simply the word dolls spelt backward.
286 Molecular Simulation of FluidsIn common with an EMD algorithm, NEMD Algorithm 8.1 begins
with an initial configuration (Part 1) that is evolved over time (Part 2),
resulting in the accumulation of time-averaged quantities (Part 2.3). At
each time step, the total strain (γ) is determined by the applied strain rate
(γ_). This is reset periodically following the traversal of the length (L) of
the simulation box. In common with EMD, the heart of the algorithm is
solving the equations of motion (Part 2.2). In the NEMD case, the
Newtonian equations of motion are modified in the integrator step. The
Gear predictor (Part 2.2.1) is invoked to provide new predictions of
the positions and momenta. No NEMD-specific modifications are intro￾duced into predictor part of the simulation. Following the predictor step,
the coordinates in the x direction are adjusted to account for bottom/top
movements out of the box (Eqs. (8.12) and (8.13)) and periodic boundary
conditions are applied in all directions to account for left/right crossings
(see Fig. 8.1). The use of different boundary conditions is an important
departure from EMD simulations.
The position coordinates are used to determine the forces according to
Newton’s law (Part 2.2.3). The intermolecular contributions to the pressure
tensor are calculated as part of the force evaluations. The integrator step con￾cludes with the corrector step (Part 2.2.4), which both makes use of the
newly calculated forces and applies the appropriate NEMD modifications,
for example, sllod. That is, the NEMD-specific modifications are applied in
the integrator step and not in the force evaluations, which are evaluated con￾ventionally. This means that much of the code developed for EMD can be
reused in NEMD. The kinetic contributions to the pressure tensor are
FIGURE 8.1 Illustration of the sliding brick boundary conditions for shear viscosity simula￾tions. The central cell is replicated infinitely in the x, y, and z directions. The boxes above the
central cell move to the right whereas the boxes below move to the left. The velocities of this
movement are determined by the strain rate γ_.
Nonequilibrium molecular dynamics Chapter | 8 287calculated as either part of the corrector step (not shown here) or immedi￾ately afterwards.
ALGORITHM 8.1 General outline of a NEMD process at constant strain
rate (γ_) using the Gear predictorcorrector integrator.
Part 1 Create an initial configuration ( = 0, specify a value of ).
Part 2 Simulation for a duration tMax:
loop
Part 2.1  +  t //strain at each time step
 - integer value of  //reset to 0 after traversal of one L
Part 2.2 Solve modified equation of motions:
Part 2.2.1 Gear predictor.
Part 2.2.2 loop i  1 ... nAtom
rxi  rxi - 

 nearestInt(yi/L)  L
pbc(rxi)
pbc(ryi)
pbc(rzi)
end i loop
Part 2.2.3 Calculate forces according to Newton’s law.
Determine intermolecular contributions to pressure
tensor as part of the force evaluation.
Part 2.2.4 Gear corrector.
Determine kinetic contribution to the pressure in the
corrector and add intermolecular contributions
Part 2.3 Calculate quantities to be time-averaged.
while (time  tMax)
.

.
8.2 Synthetic NEMD algorithms
The general approach (Evans and Morriss, 2008) adopted by widely used
NEMD methods is to introduce an applied field (Fe) into the equations of
motion of the system. The effect of Fe is to drive the conjugate thermody￾namic flux (J). Examples of fluxes are the momentum flux in planar Couette
flow or the heat current associated with thermal conductivity. The nature of
Fe is subject to two requirements: it must be consistent with the periodic
boundary condition; and any transport property (L) must be calculated from
the relationship:
L 5 lim
Fe-0
lim
t-N
J
Fe
ð8:1Þ
Using an applied field generates a synthetic NEMD algorithm because
the perturbation does not exist in nature. Linear response theory (Evans,
1986a,b) provides the formal proof that an algorithm satisfies these two crite￾ria. Knowledge of the GreenKubo (Green, 1951; Kubo, 1957) relationship
288 Molecular Simulation of Fluidsleads directly (Evans, 1986a,b) to a corresponding NEMD algorithm. The
theoretical basis of many NEMD algorithms is underpinned by linear and
nonlinear response theory (Evans and Morriss, 1984b, 2008; Morriss and
Evans, 1985).
A NaiverStokes transport coefficient (L) is related to the flux (J) by the
simple relationship,
J 5 LX ð8:2Þ
where X is a gradient in the density of the quantity that is conserved. In turn,
L is related to equilibrium fluctuations by GreenKubo relations. In general,
a synthetic NEMD algorithm can be generated by using the following proce￾dure (Evans and Morriss, 2008). A GreenKubo relationship is identified for
the transport coefficient (Lij).
Lij 5
Nð
0
Jjð0ÞJið0Þ  dt ð8:3Þ
The form of Eq. (8.3) identifies the flux (J). Next, a fictitious field (Fe) is
invented and it is coupled to the system such that the adiabatic energy deriv￾ative (H_ ad
0 ) can be related directly to the dissipative flux (Jj):
H_ ad
0 5 2 JjFe ð8:4Þ
A check is made to ensure that the adiabatic incompressibility of phase
space (Evans and Morriss, 2008) is satisfied and that the equations of motion
are both homogeneous and consistent with periodic boundary conditions. A
thermostat is applied and Fe is coupled to the system either isothermally or
isoenergetically. The steady-state average ( , JiðtÞ . ) is subsequently calcu￾lated as a function of the external field (Fe) and applying Eq. (8.1), the trans￾port coefficient is obtained from:
Li 5 lim
Fe-0
lim
t-N
JiðtÞ  
Fe
ð8:5Þ
The application of this procedure to the calculation of various transport
coefficients is examined subsequently.
8.2.1 Shear viscosity
The GreenKubo relationship for shear viscosity (η) is,
η 5 V
kT
Nð
0
Pxyð0ÞPxyðtÞ  dt ð8:6Þ
Nonequilibrium molecular dynamics Chapter | 8 289where Pxy is the xy component of the pressure tensor (P) (Evans, 1979a).
PV 5 X
N
i51
p2
i
mi
2 1
2
X
N
i;j
rijFij ð8:7Þ
The procedure for calculating the pressure tensor is outlined in
Algorithm 8.2, which is quite general in nature and can be used for either
EMD or NEMD simulations. It is apparent from Eq. (8.7) that this involves
contributions from both intermolecular and kinetic interactions. The intermo￾lecular contributions to the pressure tensor are calculated as part of the over￾all evaluation of forces. In the context of predictorcorrector algorithms,
this is performed immediately after the predictor step. The components are
initialized (Part 1) prior to the commencement of the double loop (Part 2)
that evaluates the forces between all distinct pairs of atoms. This double
loop is common to all molecular simulation algorithms. Part 2.1 involves the
evaluation of the x, y, and z components, which enables the calculation of
the forces.
Different periodic boundaries are required for EMD and NEMD (see
Algorithm 8.1, Part 2.2.2) simulations, but otherwise the force calculation
for both cases is identical. These forces are used (Part 2.2.2) to evaluate
the intermolecular contributions of the pressure tensor. This part of the
algorithm concludes (Part 2.3) with the accumulation of the forces, which
will be required in the corrector step (Part 3). The corrector step is
required before the calculation of the kinetic contribution to the pressure
tensors (Part 4) because it requires the updated values of velocities
(Part 4). The intermolecular contributions are added to the kinetic contri￾bution rather than being subtracted as indicated by Eq. (8.7) because the
evaluation of the pair forces (Part 2.1) involved a negative sign. The ten￾sor components are divided by the volume (Part 5) to obtain the dimen￾sions of pressure, which can then be evaluated. It should be noted that for
most commonly used intermolecular potentials, the evaluation of forces
will yield pxy 5 pyx. When a strain rate is applied, all the off-diagonal ele￾ments of the pressure tensor will be nonzero.
Algorithm 8.2 is completely general. To use it for properties under
shear requires both suitable periodic boundary conditions (e.g.,
LeesEdwards) and appropriate modifications in the corrector step (e.g.,
sllod). When using Algorithm 8.2, the normal pressure, p, can be obtained
as one-third of the trace of the pressure tensor (P), that is, p 5 1/3Tr(P) 5
(pxx 1 pyy 1 pzz)/3.
290 Molecular Simulation of FluidsALGORITHM 8.2 Evaluation of the tensor components to pressure.
Part 1 Initialize pressure tensor components in all dimensions:
pxx = pyy = pzz = pxy = pxz … = 0
Initialize forces for all atoms: fxi = fyi, = fzi = 0.
Part 2 Evaluate forces on all distinct pairs of atoms:
loop i  1 ... nAtom
loop j  i + 1 ... nAtom - 1
Part 2.1 Determine pair separations (rijxi, rijyi and rijyi).
Apply periodic boundary conditions. 
Determine forces between pairs (fijxi,, fijyi, ,fijzi).
Part 2.2 Calculate pressure tensor components:
pxx  pxx + rijxi  fijxi
pxy  pxy + rijxi  fijyi
pxz  pxz + rijxi  fijzi
pyx  pyx + rijyi  fijxi
pyy  pyy + rijyi  fijyi
pyz  pyz + rijyi  fijzi
pzx  pzx + rijzi  fijxi
pzy  pzy + rijzi  fijyi
pzz  pzz + rijzi  fijzi
end j loop
Part 2.3
fxi  fxi + fijxi
fyi  fyi + fijyi
fzi  fzi + fijzi
end i loop
Part 3 Obtained corrected velocities.
Part 4 Add kinetic contributions from corrected velocities:
loop i  1 ... nAtom
pxx  pxx + mi  vxi  vxi
pxy  pxy + mi  vxi  vyi
pxz  pxz + mi  vxi  vzi
pyx  pyx + mi  vyi  vxi
pyy  pyy + mi  vyi  vyi
pyz  pyz + mi  vyi  vzi
pzx  pzx + mi  vzi  vxi
pzy  pzy + mi  vzi  vyi
pzz  pzz + mi  vzi  vzi
end i loop
Part 5 Divide by volume to determine the pressure:
pxx  pxx/V
pxy  pxy/V
pxz  pxz/V
pyx  pyx/V
pyy  pyy/V
pyz  pyz/V
pzx  pzx/V
pzy  pzy/V
pzz  pzz/V
Accumulate total forces and energies etc:
Nonequilibrium molecular dynamics Chapter | 8 291Viscosity has been studied widely by molecular simulation (Ashurst and
Hoover, 1973; Gosling et al., 1973; Ciccotti et al., 1979; Hoover et al., 1980;
Singer et al., 1980; Ladd, 1984; Evans and Morriss, 1984b). For shear viscosity,
the most efficient NEMD algorithms are the dolls tensor method (Hoover et al.,
1980) and the sllod algorithm (Ladd, 1984; Evans and Morriss, 1984b). It has
been shown (Evans and Morriss, 2008) that the sllod algorithm is exact for arbi￾trarily large strain rates and it can be applied to nonlinear, non-Newtonian sys￾tems. Consequently, we will focus exclusively on the sllod algorithm.
The isokinetic sllod equations of motion are,
r_i 5 pi
mi
1 ðÞ ð riUru 8:8Þ
p_i 5 Fi 2 piUru   2 αpi ð8:9Þ
where u 5 (ux, 0, 0) and ux 5 γ_y is the velocity field corresponding to planar
Couette flow with a strain rate denoted as2 γ_. In Eq. (8.9), α is a Gaussian
thermostating constant is given by:
α 5
PN
i51 FiUpi 2 γ_pxipyi
PN
i51 p2
i
ð8:10Þ
Other non-Gaussian thermostats, such as the Nose´Hoover thermostat
(Chapter 9) can also be used with sllod. In contrast to EMD, which involves
discontinuing the thermostat after the equilibration stage, NEMD requires a
thermostat for the entire length of the simulation.
The calculation of α occurs following the determination of the forces and is
quite straightforward as illustrated in Algorithm 8.3 (Parts 1 and 2). However, a
common complication is that the accumulation of numerical error results in drift
from the desired temperature. It has been reported (Baranyai and Evans, 1990)
that this issue can be addressed by incorporating a proportional feedback term.
For the Gaussian thermostat, this involves (Part 3) determining the proportional
deviation (T-dev) between the kinetic temperature and the desired temperature. The
value of α is then adjusted by w 3 T-dev, where w is obtained by trial and error
and is typically in the range of 0 to 10. Initially, w5 0 should be used to test that
the thermostat is working correctly.
8.2.1.1 Cautionary note on modifications to sllod
Tuckerman et al. (1997) proposed a generalized sllod algorithm (gsllod).
Some theoretical aspects of the procedure have been debated from the outset
(Evans et al., 1998; Tuckerman et al., 1998). Subsequently, different variants
have been proposed (Edwards et al., 2006) that are commonly identified by
other single letter prefixes to sllod. However, there are very detailed scien￾tific arguments (Daivis and Todd, 2006; Todd and Daivis, 2017) to support
both the validity and the primacy of the original approach. Therefore, we
2. This should not be confused with the strain, which is commonly denoted as γ.
292 Molecular Simulation of Fluidswill focus exclusively on the original sllod algorithm, which is implemented
in widely used software packages.3
ALGORITHM 8.3 Calculation of the α thermostatic constant.
-den  -num  0
loop i  1 ... nAtom
Part 1 Determine denominator and numerator parts of :
-den  mi  mi  (vxi  vxi + vyi  vyi + vzi  vzi)
-num  mi  (fxi  vxi + fyi  vyi + fzi  vzi -  vxi  vyi)
end i loop
Part 2   -num/-den
Part 3 Account for numerical drift:
T-dev  (-den/mi – 3(nAtom – 1)  k  T)
/( 3(nAtom – 1)  k  T)
   + w  T-dev

.
Eqs (8.8)(8.10) must be used in conjunction with suitable periodic
boundary conditions such as the LeesEdwards sliding brick boundary con￾ditions (Lees and Edwards, 1972) as illustrated by Fig. 8.1.
In the LeesEdwards periodic boundary conditions, the movement of
particles outside the central simulation box is imaged in three distinct ways.
If the particle passes through either face parallel to the y-axis, the new posi￾tion vector is obtained from,
rnew
i 5 ðriÞmod L ð8:11Þ
where L is the length of the simulation box. If the particle moves out of the
bottom of the simulation box, its position and velocity are calculated from,
rnew
i 5 ðri 1 iγLtÞmod L
vnew
i 5 vi 1 iγL
o
ð8:12Þ
where γ is the strain. If it moves out of the top of the box:
rnew
i 5 ðri 2 iγLtÞmod L
vnew
i 5 vi 2 iγL
o
ð8:13Þ
After the simulation reaches a steady state for a given γ_, the pressure ten￾sor given by Eq. (8.7) is computed and averaged. The strain rate-dependent
shear viscosity is obtained from Newton’s law of viscosity.
η 5 2 Pyx   1 Pxy  
2γ_ ð8:14Þ
The application of the sllod algorithm is handled as a modification of Newton’s
law in the integrator part of the MD algorithm. No modifications are required to
3. For example, the sllod algorithm is used in LAMMPS (https://www.lammps.org). This should
be verified at the time of use because of changes made during periodical software updates.
Nonequilibrium molecular dynamics Chapter | 8 293the predictor step. However, an alternative predictor version to that introduced pre￾viously (Algorithm 7.2) is given in Algorithm 8.4. In this version, the correspond￾ing corrector step (Algorithm 8.5) of the Gear method is applied independently to
both the positions and velocities, solving two first-order differential equations.4 In
common with Algorithm 8.4, the solution illustrated by Algorithm 8.5 involves
scaled time derivatives. The prediction of new positions (Part 1.1) involves three
derivatives, which are in turn predicted in each time step (Parts 1.11.4). The sec￾ond part (Part 2) of the algorithm involves applying the predictor method to deter￾mine new velocities, which involves other derivatives (Parts 2.22.4).
The corrector step (Algorithm 8.5) incorporates the effect of a streaming
velocity (ux) in the x direction and a constant strain rate (γ_ 5 @ux=@y). The correc￾tion to the positions (Δrx, Δry, Δrz) using Eq. (8.8) are given at the beginning of
Part 1 and are used subsequently to update both positions and its derivatives
(Parts 1.11.4). The involvement of the γ_ term is confined to the x direction
(Δrx). The velocity corrections (Δvx, Δvy, Δvz) using Eq. (8.8) are given at the
start of Part 2. In common with the positions, the γ_ term is only applied in the x
direction. However, the α term is applied in all directions, which corresponds to
the application of a thermostat. The subsequent parts of the algorithm (Parts
2.12.4) involve applying the corrections to both the velocity and its derivatives.
It is only after the velocities have been corrected that both the momenta and
kinetic energies (not shown in Algorithm 8.5) are calculated.
ALGORITHM 8.4 A four-value Gear predictor applied independently to
both positions and velocities using scaled time derivatives.
loop i  1 ... nAtom
Part 1 Predict new position vectors using Gear method:
Part 1.1 Predict Positions:
rxi  rxi + (drxi/dt) +(d2
rxi/dt2
)+(d3
rxi/dt3
)+(d4
rxi/dt4
)
ryi  ryi + (dryi/dt) +(d2
ryi/dt2
)+(d3
ryi/dt3
)+(d4
ryi/dt4
)
rzi  rzi + (drzi/dt) +(d2
rzi/dt2
)+(d3
rzi/dt3
)+(d4
rzi/dt4
)
Part 1.2 First (scaled time) derivatives of position:
(drxi/dt)  (drxi/dt) +(d2
rxi/dt2
) + 2(d3
rxi/dt3
) + 3(d4
rxi/dt4
)
(dryi/dt)  (dryi/dt) +(d2
ryi/dt2
) + 2(d3
ryi/dt3
) + 3(d4
rxi/dt4
)
(drzi/dt)  (drzi/dt) v (d2
rzi/dt2
) + 2(d3
rzi/dt3
) + 3(d4
rzi/dt4
)
Part 1.3 Second (scaled time) derivatives of position:
(d2
rxi/dt2
)  (d2
rxi/dt2
)+(d3
rxi/dt3
) + 3(d4
rxi/dt4
)
(d2
ryi/dt2
)  (d2
ryi/dt2
)+(d3
ryi/dt3
) + 3(d4
ryi/dt4
)
(d2
rzi/dt2
)  (d2
rzi/dt2
)+(d3
rzi/dt3
) + 3(d4
rzi/dt4
)
Part 1.4 Third (scaled time) derivatives of position:
(d3
rxi/dt3
)  (d3
rxi/dt3
)+(d4
rxi/dt4
)
(d3
ryi/dt3
)  (d3
ryi/dt3
)+ (d4
ryi/dt4
)
(d3
rzi/dt3
)  (d3
rzi/dt3
)+ (d4
rzi/dt4
)
4. The Gear corrector coefficients for the first-order differential equations are k0 5 3/8, k1 5 1,
k2 5 3/4, and k3 5 1/6.
294 Molecular Simulation of FluidsPart 2 Predict new velocities using Gear algorithm:
Part 2.1 Predict velocities:
vxi  vxi + (dvxi/dt) +(d2
vxi/dt2
)+(d3
vxi/dt3
)+(d4
vxi/dt4
)
vyi  vyi + (dvyi/dt) +(d2
vyi/dt2
)+(d3
vyi/dt3
)+(d4
vyi/dt4
)
vzi  vzi + (dvzi/dt) +(d2
vzi/dt2
)+(d3
vzi/dt3
)+(d4
vzi/dt4
)
Part 2.2 First (scaled time) derivatives of velocity:
(dvxi/dt)  (dvxi/dt) +(d2
vxi/dt2
) + 2(d3
vxi/dt3
) + 3(d4
vxi/dt4
)
(dvyi/dt)  (dvyi/dt) +(d2
vyi/dt2
) + 2(d3
vyi/dt3
) + 3(d4
vxi/dt4
)
(dvzi/dt)  (dvzi/dt) + (d2
vzi/dt2
) + 2(d3
vzi/dt3
) + 3(d4
vzi/dt4
)
Part 2.3 Second (scaled time) derivatives of velocity:
(d2
vxi/dt2
)  (d2
vxi/dt2
)+ (d3
vxi/dt3
) + 3(d4
vxi/dt4
)
(d2
vyi/dt2
)  (d2
vyi/dt2
)+ (d3
vyi/dt3
) + 3(d4
vyi/dt4
)
(d2
vzi/dt2
)  (d2
vzi/dt2
)+ (d3
vzi/dt3
) + 3(d4
vzi/dt4
)
Part 2.4 Third time (scaled time) derivatives of velocity:
(d3
vxi/dt3
)  (d3
vxi/dt3
)+(d4
vxi/dt4
)
(d3
vyi/dt3
)  (d3
vyi/dt3
)+(d4
vyi/dt4
)
(d3
vzi/dt3
)  (d3
vzi/dt3
)+(d4
vzi/dt4
)
end i loop
ALGORITHM 8.5 A four-value Gear corrector applied independently to
both positions and velocities implementing sllod under constant strain
rate, using scaled time derivatives.
loop i  1 ... nAtom
Part 1 Determine corrections to positions and its derivatives:
rx  (vxi +  ryi)  t - (drxi/dt)
ry  vyi  t -(dryi/dt)
rz  vzi  t -(drzi/dt)
Part 1.1 Correct Positions:
rxi  rxi + k0  rx
ryi  ryi + k0  ry
rzi  rzi + k0  rz 
Part 1.2 Correct first (scaled time) derivatives of position:
(drxi/dt)  (drxi/dt) + rx
(dryi/dt)  (dryi/dt) + ry
(drzi/dt)  (drzi/dt) + rz
Part 1.3 Second (scaled time) derivatives of position:
(d2
rxi/dt2
)  (d2
rxi/dt2
) + k2  rx
(d2
ryi/dt2
)  (d2
ryi/dt2
) + k2  ry
(d2
rzi/dt2
)  (d2
rzi/dt2
) + k2  rz

.
Nonequilibrium molecular dynamics Chapter | 8 295Part 1.4 Third (scaled time) derivatives of position:
(d3
rxi/dt3
)  (d3
rxi/dt3
) + k3  rx
(d3
ryi/dt3
)  (d3
ryi/dt3
) + k3  rx
(d3
rzi/dt3
)  (d3
rzi/dt3
) + k3  rx
Part 2 Determine corrections to velocity and its derivatives:
vx  (fxi /mi -  vyi -   vxi)  t -(dvxi/dt)
vy  (fyi /mi -   vxi)  t -(dvyi/dt)
vz  (fzi /mi -   vxi)  t -(dvzi/dt)
Part 2.1 Correct velocities:
vxi  vxi + k0  vx
vyi  vyi + k0  vy
rzi  vzi + k0  vz 
Part 2.2 Correct first (scaled time) derivatives of velocity:
(dvxi/dt)  (dvxi/dt) + vx
(dvyi/dt)  (dvyi/dt) + vy
(dvzi/dt)  (dvzi/dt) + vz
Part 2.3 Second (scaled time) derivatives of velocity:
(d2
vxi/dt2
)  (d2
vxi/dt2
) + k2  vx
(d2
vyi/dt2
)  (d2
vyi/dt2
) + k2  vy
 (d2
vzi/dt2
)  (d2
vzi/dt2
) + k2  vz
Part 2.4 Third (scaled time) derivatives of velocity:
(d3
vxi/dt3
)  (d3
vxi/dt3
) + k3  vx
(d3
vyi/dt3
)  (d3
vyi/dt3
) + k3  vx
(d3
vzi/dt3
)  (d3
vzi/dt3
) + k3  vx
end i loop

.
Hansen and Evans (1994) have discussed how shear flow can be simu￾lated efficiently on a distributed memory parallel processor. Bhupathiraju
et al. (1996) applied the sllod algorithm with a deforming cell method
instead of the LeesEdwards periodic boundary conditions. They concluded
that the modification improved the accuracy of calculated viscosities for low
shear rates. The modified algorithm was also more efficient computationally
than the conventional LeesEdwards approach.
Shear viscosity has been widely examined by NEMD techniques. Examples
of systems studied include methane (Simmons and Cummings, 1986; Evans,
1979b; Cummings and Evans, 1992), carbon dioxide (Wang and Cummings,
1989a,b), water (Cummings and Varner, 1988; Balasubramanian et al., 1996), liq￾uid metals (Cummings and Morriss, 1987, 1988; Cummings and Evans, 1992),
and alkanes (Edberg et al., 1987; Morriss et al., 1991; Berker et al., 1992). These
studies have used various intermolecular potentials, and comparison with experi￾mental shear viscosity data has proved useful in identifying the relative accuracy
of the different intermolecular potentials. Lee and Cummings (1994) investigated
shear viscosity using both two-body and three-body intermolecular potentials.
They concluded that three-body interactions make a contribution of only 3%. This
relatively small contribution was confirmed by subsequent studies (Marcelli et al.,
2001a,b). It is much less than the influence on nontransport properties such as
296 Molecular Simulation of Fluidseither phase equilibria (Marcelli and Sadus, 1999) or thermodynamic properties
(Raabe et al., 2005; Vlasiuk and Sadus, 2017).
NEMD simulations have demonstrated (Marcelli et al., 2001a; Ge et al., 2001)
that the pressure (p) and energy (U) of simple fluids under planer shear flow are
only linear functions of γ_ 2=3 in the vicinity of the triple point. More generally,
U 5 U0 1 aγ_α
p 5 p0 1 bγ_α

ð8:15Þ
where the 0 subscript denotes an equilibrium property; a and b are density
and temperature-dependent constants. Ge et al. (2003) determined the follow￾ing relationship for α in terms of the reduced temperature (T ) and reduced
density (ρ).
α 5 3:67 1 0:69T 2 3:35ρ ð8:16Þ
The constants in Eq. (8.16) are either universally the same for a one com￾ponent fluid or dependent only on the intermolecular potential. The signifi￾cance of Eqs. (8.15) and (8.16) is that the properties of normal
nonequilibrium fluids as a function of strain rate could be predicted for any
arbitrary state point. However, this does not appear to be the case (Ahmed
et al., 2010) for the special case of intrapenetrable fluids such as the
Gaussian core model fluid (Chapter 3).
The LJ potential has been the most widely studied intermolecular poten￾tial for shear viscosity. Ahmed and Sadus (2010) made use of extensive
NEMD sllod simulations to determine an empirical equation of state for the
LJ potential.
p 5 ρT 1X
8
i51
AiðTÞρi11 1 e2δρ2X
8
i51
BiðTÞρ2i11
1 ρ
X
3
i50
X
3
j
fijγ_i
Xi1mT12j ð8:17Þ
In Eq. (8.17), all quantities are in nondimensional reduced form and the
first three terms on the right-hand side refer to LJ equilibrium properties
(Nicolas et al., 1979). The contribution at nonzero strain rate is given be the
third term, which involves parameters ( fij) fitted to the simulation data with
X 5 ρT21=4. This can serve as an accurate reference equation of state for LJ
at different values of γ_, which greatly reduces the need to repeat NEMD
simulations for new cases.
The utility of NEMD is evident by the concept of electropumping of
fluids (de Luca et al., 2013) in nanopores, which involves the application of
an external electric field that induces enhanced flow rates. In particular, it
has been reported (Ostler et al., 2020) that electropumping could be many
Nonequilibrium molecular dynamics Chapter | 8 297times more efficient than conventional Poiseuille flows in nanochannels such
as carbon nanotubes (CNT).
8.2.2 Self-diffusion
The GreenKubo relationship for the self-diffusion coefficient is:
Ds 5 1
3
Nð
0
við0ÞUviðtÞ  dt ð8:18Þ
Evans et al. (1983) developed the “color conductivity” algorithm to cal￾culate the self-diffusion coefficient. The system is described by the following
Hamiltonian,
H 5 H0 2 X
N
i51
cixiFðtÞ ð8:19Þ
where H0 is the unperturbed Hamiltonian, F is a fictitious color field in the x
direction, and ci 5 ( 2 1)
i is the “color charge” on molecule i. The equations
of motion derived from this Hamiltonian are:
ri 5 pi
mi
ð8:20Þ
p_xi 5 Fxi 2 Fci
p_yi 5 Fyi 2 λspyi
p_zi 5 Fzi 2 λspzi
9
=
;
ð8:21Þ
In Eq. (8.21), λs is a thermostating constraint parameter. The applied
color field F is obtained from:
F 5 1
N
X
N
i51
ciFxi ð8:22Þ
This drives the color current (Jx).
Jx 5 X
N
i51
ci
pix
mi
ð8:23Þ
The constraint parameter can be calculated from:
λs 5
PN
i51 piyFiy 1 pizFiz  
PN
i51 p2
iy 1 p2
iz   ð8:24Þ
The work W generated by the field (F) is given by:
W 5 F
X
N
i51
cipxi ð8:25Þ
298 Molecular Simulation of FluidsThe self-diffusion coefficient is calculated from:
Ds 5 2 kTðN 2 1ÞJx
N2h i W ð8:26Þ
Examples of the calculation of the self-diffusion coefficient have been
reported for carbon dioxide (Wang and Cummings, 1989b) and mercury
(Raabe et al., 2005).
8.2.3 Thermal conductivity
The GreenKubo relationship for the thermal conductivity coefficient (λ) is,
λ 5 V
3kT2
Nð
0
JQð0ÞUJQðtÞ  dt ð8:27Þ
where JQ is the heat current. A Hamiltonian-based algorithm for thermal conduc￾tivity cannot be devised because the equations of motion obtained from the
Hamiltonian are discontinuous when used with periodic boundary conditions.
Evans (1982, 1986a,b) introduced a fictitious vector field (F) as the driving force
for the heat flux (JQ). The equations of motion for atomic systems are,
r_i 5 pi
mi
ð8:28Þ
p_i 5 Fi 1 ðEi 2 EÞFðtÞ
2 1
2
X
N
j51
FijðrijUFðtÞÞ 1
1
2N
X
N
j51
X
N
k51
FjkðrjkUFðtÞÞ 2 αpi
ð8:29Þ
where Fij is the force exerted by particle j on particle i, Ei is the instanta￾neous energy of i, and E is the instantaneous average energy per particle. In
Eq. (8.29), α is the thermostating multiplier.
α 5
P
i Fi 1 ðEi 2 EÞFðtÞ 2 1
2
P
N
j51
FijðrijUFðtÞÞ 1 1
2N
P
N
j51
P
N
k51
FjkðrjkUFðtÞÞ " #Upi
P
i p2
i
ð8:30Þ
The heat current (JQ) is derived from,
JQV 5 X
N
i51
Ei
pi
mi
2 1
2
X
N
i51
X
N
j51
rijðpiUFijÞ ð8:31Þ
and the thermal conductivity is calculated using:
λ 5 JQ
 
TF ð8:32Þ
Nonequilibrium molecular dynamics Chapter | 8 299Evans (1986a,b) has demonstrated that this algorithm can be used to pre￾dict the thermal conductivity of argon at the triple point more precisely than
experimental measurements. Gillan and Dixon (1983) have derived a similar
algorithm from a different perspective.
Molecular simulations of thermal conductivity are reported less fre￾quently than for other transport phenomena. The NEMD studies of carbon
dioxide (Wang and Cummings, 1989b; Cummings and Evans, 1992) and
butane (Daivis and Evans, 1994, 1995) are relatively rare examples. An
investigation has been reported (Searles et al., 1998) of thermal conductivity
near the critical point.
8.2.3.1 Cautionary note on the triple point
Studies of transport properties are often conducted near the triple point to provide
examples of behavior in a dense liquid phase. In particular, the LJ triple point is a
very common choice. There are varying estimates in the literature (Ahmed and
Sadus, 2010) of the LJ triple point. Currently, the most precise value (Schultz and
Kofke, 2018) of the reduced triple point is T  5 0.69455, p 5 0.001267,
ρ
l 5 0:84535, and ρ
s 5 0:960765. This is for the full potential, and its value will
be significantly affected by cut-off values, truncations, and potential shifts.
Therefore, care is required when performing simulations in the vicinity of the tri￾ple point to ensure that the nominated state points are genuinely in the single￾phase region. The same considerations also apply to other choices of intermolecu￾lar potential (Deiters and Sadus, 2022).
8.3 Application of NEMD algorithms to molecules
Early work on NEMD algorithms focused on either atomic systems or small
molecules. For small polyatomic molecules, the sllod algorithm can be
adapted (Edberg et al., 1987) in terms of a quaternionic framework. More
generally, however, the synthetic NEMD algorithms for atomic systems can
be used with the constraint dynamics techniques and realistic intermolecular
potentials to predict the transport properties of multiatom molecules.
Daivis and Evans (1994, 1995) have investigated the thermal conductivity of
butane using different models. Comparison with experiment indicates (Daivis and
Evans, 1995) deficiencies in both the Ryckaert and Bellemans (1978) and aniso￾tropic united-atom (Toxvaerd, 1990) models of butane. Allen and Rowley (1997)
compared the viscosity of alkanes predicted by the RyckaertBellemans, united￾atom, and all-atom intermolecular potentials. The comparison indicated that results
obtained using the all-atom model were generally superior to the results obtained
with the other intermolecular potentials.
NEMD techniques have also been used to examine the rheology of both
linear and branched alkanes (Berker et al., 1992; Morriss et al. 1991; Daivis
et al., 1992). Mundy et al. (1995) investigated the shear viscosity of decane
300 Molecular Simulation of Fluidsusing sllod algorithms in both the isothermalisobaric and canonical ensem￾bles. Good agreement between simulation and experimental data for the
shear viscosity of alkanes has been reported (Mundy et al., 1996). Lahtela
et al. (1998) reported NEMD simulations for branched alkanes, which indi￾cate that viscosity is dominated by the size of the branch. Tang et al. (1998)
has developed a theory for the dynamics of flexible chains. NEMD has also
proved useful in providing insights for the behavior of macromolecules. For
example, it has been used to determine the generation-dependence of both
the structural properties (Bosko et al., 2004a) and shear-thing behavior
(Bosko et al., 2004b) of dendrimers. The shape of the dendrimer and its
shear viscosity are directly related (Bosko et al. 2006).
8.4 Application of NEMD algorithms to mixtures
The use of NEMD algorithms has been historically focused on pure component
properties, but the prediction of the transport properties of fluid mixtures is
becoming increasingly more important. Murad (1986) used the sllod algorithm to
evaluate different mixture rules for the viscosity of binary LJ mixtures. Wang and
Cummings (1996) performed NEMD sllod calculations for the shear viscosity for
mixtures containing carbon dioxide and ethane. Both carbon dioxide and ethane
were modeled as two-center LJ molecules yielding good agreement with experi￾mental data. Wheeler and Rowley (1998) reported simulations for the water 1
methanol 1 acetone ternary mixture in addition to results for binary mixtures con￾taining these components. Sarman and Evans (1992a,b) used NEMD to evaluate
heat flow and mass diffusion in binary LJ mixtures. The thermal conductivity of
mixtures of polyatomic fluids has also been studied by NEMD (Ravi and Murad,
1992). EMD has arguably been used more widely than NEMD for the calculation
of the self-diffusion coefficient of mixtures (Jacucci and McDonald, 1975; Schoen
and Hoheisel, 1984a,b; Jolly and Bearman, 1980; Vogelsang and Hoheisel, 1988;
Heyes and Preston 1991a,b; Gardner et al., 1991). The shear viscosity of mixtures
of dendrimers has also been studied (Bosko et al., 2005) in different ensembles.
A very important example (Losey et al., 2019) of the use of NEMD algo￾rithms for mixtures is their usefulness for investigating transport phenomena
in either pores or CNTs. This involves mixture properties in two ways: inter￾actions between a pure confined fluid and the CNT; and interaction between
both the CNT and a confined mixture and between the individual compo￾nents of the confined fluid.
8.5 Comparison with EMD
As noted earlier, transport properties can also be calculated from EMD tra￾jectories using either Einstein or GreenKubo relationships. The Einstein
relationships for diffusion, shear viscosity, and thermal conductivity are
Nonequilibrium molecular dynamics Chapter | 8 301given by Eq. (2.48), Eq. (2.49), and Eq. (2.52), respectively. When Fe 5 0,
the NEMD algorithms discussed earlier revert to their equilibrium form.
The main advantage of using EMD is that all the transport properties can be
obtained from a single run. However, the disadvantages are that the equilibrium
calculations are expensive computationally, they sometimes yield poor signal to
noise ratios; and the results may depend strongly on the size of the simulated sys￾tem. Consequently, NEMD is the preferred method for obtaining transport phe￾nomena. Nonetheless, it is of interest to compare results obtained from NEMD
with EMD calculations. A comparison between the two simulation approaches
has been given by Cummings and Evans (1992). Hoheisel (1994) has reviewed
the calculation of transport properties of EMD.
Holian and Evans (1983) reported a direct comparison of NEMD and
EMD for shear viscosity calculated from the GreenKubo relationship. They
concluded that the NEMD results were size independent for a system of 100
or more particles, whereas EMD results were strongly size-dependent.
Schoen and Hoheisel (1985) reported good agreement between EMD
GreenKubo and NEMD results. The EMD calculations were not signifi￾cantly size-dependent beyond a system size of 500 particles. Chialvo and
Debenedetti (1991) and Chialvo et al. (1989) used EMD with the Einstein
formula to calculate the shear viscosity of linear molecules and LJ mole￾cules, respectively. These results indicate that the Einstein formula gives low
noise prediction. For linear molecules, there is a discrepancy between EMD
results and the NEMD calculations of Wang and Cummings (1989a). For LJ
molecules, the EMD results were strongly system dependent.
Cummings and Evans (1992) reported that EMD calculations for the self￾diffusion coefficient using either the Einstein or GreenKubo relationships
yield similar results to NEMD calculations. Furthermore, the EMD method
requires fewer time steps than the NEMD algorithm to obtain the same
degree of accuracy.
A direct comparison between different EMD and NEMD techniques is
not available for thermal conductivity. Levesque and Verlet (1987) observed
a strong size dependence for the thermal conductivity calculated by the
GreenKubo EMD method in systems containing up to 4000 LJ molecules.
8.6 Summary
NEMD algorithms have been successful in extending the application of MD
to phenomena in which thermodynamic equilibrium does not occur. The
most widely used NEMD algorithms are synthetic and their development
parallels the extension of MD to different thermodynamic ensembles
(Chapter 9). The application of NEMD to mixtures is continually increasing
and providing theoretical insights into the behavior of real systems. It can be
anticipated that NEMD algorithms will play an increasing role in the investi￾gation of the rheological properties of large molecules.
302 Molecular Simulation of FluidsReferences
Ahmed, A., Sadus, R.J., 2010. Effect of potential truncations and shifts on the solid-liquid phase
coexistence of Lennard-Jones fluids. J. Chem. Phys. 133, 124515.
Ahmed, A., Mausbach, P., Sadus, R.J., 2010. Pressure and energy behavior of the Gaussian core
model fluid under shear. Phys. Rev. E 82, 011201.
Allen, M.P., Tildesley, D.J., 2017. Computer Simulation of Liquids, second ed. Oxford
University Press, Oxford.
Allen, W., Rowley, R.L., 1997. Predicting the viscosity of alkanes using nonequilibrium molecular
dynamics: evaluation of intermolecular potential models. J. Chem. Phys. 106, 1027310281.
Ashurst, W.T., Hoover, W.G., 1973. Argon shear viscosity via a Lennard-Jones potential with
equilibrium and nonequilibrium molecular dynamics. Phys. Rev. Lett. 31, 206208.
Balasubramanian, S., Mundy, C.J., Klein, M.L., 1996. Shear viscosity of polar fluids: molecular
dynamics calculations of water. J. Chem. Phys. 105, 1119011195.
Baranyai, A., Evans, D.J., 1990. New algorithm for constrained molecular-dynamics simulation
of liquid benzene and naphthalene. Mol. Phys. 70, 5363.
Berker, A., Chynoweth, S., Klomp, U.C., Michopoulos, Y., 1992. Non-equilibrium molecular
dynamics (NEMD) simulations of the rheological properties of liquid n-hexadecane.
J. Chem. Soc. Faraday Trans. 88, 17191725.
Bhupathiraju, R., Cummings, P.T., Cochran, H.D., 1996. An efficient parallel algorithm for non￾equilibrium molecular dynamics simulations of very large systems in planar Couette flow.
Mol. Phys. 88, 16651670.
Bosko, J.T., Todd, B.D., Sadus, R.J., 2004a. Internal structure of dendrimers in the melt: a
molecular dynamics study. J. Chem. Phys. 121, 10911096.
Bosko, J.T., Todd, B.D., Sadus, R.J., 2004b. Viscoelastic properties of dendrimers in the melt
from nonequilibrium molecular dynamics. J. Chem. Phys. 121, 1205012059.
Bosko, J.T., Todd, B.D., Sadus, R.J., 2005. Molecular simulation of dendrimers and their mix￾tures under shear: comparison of isothermal-isobaric (NpT) and isothermal-isochoric (NVT)
ensemble systems. J. Chem. Phys. 123, 034905.
Bosko, J.T., Todd, B.D., Sadus, R.J., 2006. Analysis of the shape of dendrimers under shear.
J. Chem. Phys. 124, 044910.
Chialvo, A.A., Debenedetti, P.G., 1991. Use of the McQuarrie equation for the computation of
shear viscosity via equilibrium molecular dynamics. Phys. Rev. A 43, 42894295.
Chialvo, A.A., Heath, D.L., Debenedetti, P.G., 1989. A molecular dynamics study of the influ￾ence of elongation and quadrupole moment upon some thermodynamic and transport proper￾ties of linear heteronuclear triatomic fluids. J. Chem. Phys. 91, 78187830.
Ciccotti, G., 1991. In: Meyer, M., Pontikis, V. (Eds.), Computer Simulation in Materials
Science. Interatomic Potentials, Simulation techniques and Applications. Kluwer, Dordrecht.
Ciccotti, G., Jacucci, G., McDonald, I.R., 1979. “Thought-experiments” by molecular dynamics.
J. Stat. Phys. 21, 199226.
Cummings, P.T., Evans, D.J., 1992. Nonequilibrium molecular dynamics approaches to transport
properties and non-Newtonian fluid rheology. Ind. Eng. Chem. Res. 31, 12371252.
Cummings, P.T., Morriss, G.P., 1987. Nonequilibrium molecular dynamics calculation of the
shear viscosity of liquid rubidium. J. Phys. F. 17, 593604.
Cummings, P.T., Morriss, G.P., 1988. Shear viscosity of liquid rubidium at the triple point.
J. Phys. F. 18, 14391447.
Cummings, P.T., Varner Jr, T.L., 1988. Nonequilibrium molecular dynamics calculation of the
shear viscosity of liquid water. J. Chem. Phys. 89, 63916398.
Nonequilibrium molecular dynamics Chapter | 8 303Daivis, P.J., Evans, D.J., 1994. Non-equilibrium molecular dynamics calculation of thermal con￾ductivity of flexible molecules: butane. Mol. Phys. 81, 12891295.
Daivis, P.J., Evans, D.J., 1995. Temperature dependence of the thermal conductivity for two
models of liquid butane. Chem. Phys. 198, 2534.
Daivis, P.J., Todd, B.D., 2006. A simple, direct derivation and proof of the validity of the SLLOD
equations of motion for generalized homogeneous flows. J. Chem. Phys. 124, 194103.
Daivis, P.J., Evans, D.J., Morriss, G.P., 1992. Computer simulation study of the comparative rhe￾ology of branched and linear alkanes. J. Chem. Phys. 97, 616627.
de Luca, S., Todd, B.D., Hansen, J.S., Daivis, P.J., 2013. Electropumping of water with rotating
electric fields. J. Chem. Phys. 138, 154712.
Deiters, U.K., Sadus, R.J., 2022. First-principles determination of the solid-liquid-vapor triple
points: the noble gases. Phys. Rev. E 105, 054128.
Edberg, R., Morriss, G.P., Evans, D.J., 1987. Rheology of n-alkanes by nonequilibrium molecu￾lar dynamics. J. Chem. Phys. 86, 45554570.
Edwards, B.J., Baig, C., Keffer, D.J., 2006. A validation of the p-SLLOD equations of motion
for homogeneous steady-state flows. J. Chem. Phys. 124, 194104.
Evans, D.J., 1979a. The non-symmetric pressure tensor in polyatomic fluids. J. Stat. Phys. 20,
547555.
Evans, D.J., 1979b. The frequency dependent shear viscosity of methane. Mol. Phys. 37,
17451754.
Evans, D.J., 1982. Homogeneous NEMD algorithm for thermal conductivity -application of non￾canonical linear response theory. Phys. Lett. A 91, 457460.
Evans, D.J., 1986a. Thermal conductivity of the Lennard-Jones fluid. Phys. Rev. A 34,
14491453.
Evans, D.J., 1986b. In: Ciccotti, G., Hoover, W.G. (Eds.), Molecular Dynamics Simulation of
Statistical-Mechanical Systems. North-Holland, Amsterdam.
Evans, D.J., Morriss, G.P., 1984a. Nonlinear response theory for steady planar Couette flow.
Phys. Rev. A 30, 15281530.
Evans, D.J., Morriss, G.P., 1984b. Non-Newtonian molecular dynamics. Comp. Phys. Rep. 1,
297343.
Evans, D.J., Morriss, G.P., 2008. Statistical Mechanics of Nonequilibrium Liquids, second ed.
Cambridge University Press, Cambridge.
Evans, D.J., Hoover, W.G., Failor, B.H., Moran, B., Ladd, A.J.C., 1983. Nonequilibrium molecu￾lar dynamics via Gauss’s principle of least constraint. Phys. Rev. A 28, 10161021.
Evans, D.J., Searles, D.J., Hoover, W.G., Hoover, C.G., Holian, B.L., Posch, H.A., Morriss, G.P.,
1998. Comment on “Modified nonequilibrium molecular dynamics for fluid flows with energy
conservation” [J. Chem. Phys. 106, 5615 (1997)]. J. Chem. Phys. 108, 43514352.
Ford, D.M., Heffelfinger, G.S., 1998. Massively parallel dual control grand canonical molecular
dynamics with LADERA. II. Gradient driven diffusion through polymers. Mol. Phys. 94,
673683.
Gardner, P.J., Heyes, D.M., Preston, S.R., 1991. Molecular dynamics computer simulations of
binary Lennard-Jones fluid mixtures: Thermodynamics of mixing and transport coefficients.
Mol. Phys. 73, 141173.
Ge, J., Marcelli, G., Todd, B.D., Sadus, R.J., 2001. Energy and pressure of shearing fluids at dif￾ferent state points. Phys. Rev. E 64, 02120. Erratum: Phys. Rev. E. 65, 069901 (2002).
Ge, J., Todd, B.D., Wu, G.-W., Sadus, R.J., 2003. Scaling behavior for the pressure and energy
of shearing fluids. Phys. Rev. E 67, 061201.
304 Molecular Simulation of FluidsGillan, M.J., Dixon, M., 1983. The calculation of thermal conductivities by perturbed molecular
dynamics simulation. J. Phys. C. 16, 869878.
Gosling, E.M., McDonald, I.R., Singer, K., 1973. On the calculation by molecular dynamics of
the shear viscosity of a simple fluid. Mol. Phys. 26, 14751484.
Green, H.S., 1951. The quantum mechanics of assemblies of interacting particles. J. Chem.
Phys. 19, 955962.
Hansen, D.P., Evans, D.J., 1994. A parallel algorithm for nonequilibrium molecular dynamics
simulation of shear flow on distributed memory machines. Mol. Sim. 13, 375393.
Heffelfinger, G.S., Ford, D.M., 1998. Massively parallel dual control grand canonical molecular
dynamics with LADERA. I. Gradient driven diffusion in Lennard-Jones fluids. Mol. Phys.
94, 659671.
Heffelfinger, G.S., van Swol, F., 1994. Diffusion in Lennard-Jones fluids using dual control vol￾ume grand canonical molecular dynamics simulation (DCV-GCMD). J. Chem. Phys. 100,
75487552.
Heyes, D.M., Preston, S.R., 1991a. Transport coefficients of argon-krypton mixtures by molecu￾lar dynamics computer simulation. Phys. Chem. Liq. 23, 123149.
Heyes, D.M., Preston, S.R., 1991b. Equilibrium molecular dynamics computer simulations of the
transport coefficients of argon-methane mixtures. Mol. Sim. 7, 221239.
Hoheisel, C., 1994. Transport properties of molecular liquids. Phys. Rep. 245, 111157.
Holian, B.L., Evans, D.J., 1983. Shear viscosities away from the melting line: a comparison of
equilibrium and nonequilibrium molecular dynamics. J. Chem. Phys. 78, 51475150.
Hoover, W.G., 1985. Canonical dynamics: equilibrium phase-space distributions. Phys. Rev. A
31, 16951697.
Hoover, W.G., 1991. Computational Statistical Mechanics. Elsevier, Amsterdam.
Hoover, W.G., Evans, D.J., Hickman, R.B., Ladd, A.J.C., Ashurst, W.T., Moran, B., 1980.
Lennard-Jones triple-point bulk and shear viscosities. Green-Kubo theory, Hamiltonian
mechanics, and nonequilibrium molecular dynamics. Phys. Rev. A 22, 16901697.
Hunt, T.A., Todd, B.D., 2003. On the Arnold cat map and periodic boundary conditions for pla￾nar elongational flow. Mol. Phys. 101, 34453454.
Hunt, T.A., Bernardi, S., Todd, B.D., 2010. A new algorithm foe extended nonequilibrium
molecular dynamics simulations of mixed flow. J. Chem. Phys. 133, 154116.
Jacucci, G., McDonald, I.R., 1975. Structure and diffusion in mixtures of rare-gas liquids. Phys.
A 80, 607625.
Jolly, D.L., Bearman, R.J., 1980. Molecular dynamics simulation of the mutual and self diffusion
in Lennard-Jones liquid mixtures. Mol. Phys. 41, 137147.
Kubo, R., 1957. Statistical-mechanical theory of irreversible processes. I. General theory and
simple applications to magnetic and conduction problems. J. Phys. Soc. Jpn. 12, 570586.
Ladd, A.J.C., 1984. Equations of motion for nonequilibrium molecular dynamics simulations of
viscous flow in molecular liquids. Mol. Phys. 53, 459463.
Lahtela, M., Linnolahti, M., Pakkanen, T.A., Rowley, R.L., 1998. Computer simulations of
branched alkanes: the effect of side chain and its position on rheological behavior. J. Chem.
Phys. 108, 26262630.
Lee, S.H., Cummings, P.T., 1994. Effect of three-body forces on the shear viscosity of liquid
argon. J. Chem. Phys. 101, 62066209.
Lees, A.W., Edwards, S.F., 1972. The computer study of transport processes under extreme con￾ditions. J. Phys. C. 5, 19211929.
Levesque, D., Verlet, L., 1987. Molecular dynamics calculations of transport coefficients. Mol.
Phys. 61, 143159.
Nonequilibrium molecular dynamics Chapter | 8 305Losey, J., Kannam, S.K., Todd, B.D., Sadus, R.J., 2019. Flow of water through carbon nanotubes
predicted by different atomistic models. J. Chem. Phys. 150, 194501.
Marcelli, G., Sadus, R.J., 1999. Molecular simulation of the phase behavior of noble gases using accu￾rate two-body and three-body intermolecular potentials. J. Chem. Phys. 111, 15331540.
Marcelli, G., Todd, B.D., Sadus, R.J., 2001a. The strain rate dependence of shear viscosity, pres￾sure and energy from two-body and three-body interactions. Fluid Phase Equilib. 183-184,
371379.
Marcelli, G., Todd, B.D., Sadus, R.J., 2001b. Analytic dependence of the pressure and energy of
an atomic fluid under shear. Phys. Rev. E 63, 021204.
Morriss, G.P., Evans, D.J., 1985. Isothermal response theory. Mol. Phys. 54, 629636.
Morriss, G.P., Daivis, P.J., Evans, D.J., 1991. The rheology of n-alkanes: decane and eicosane.
J. Chem. Phys. 94, 74207433.
Mundy, C.J., Siepmann, J.I., Klein, M.L., 1995. Decane under shear: a molecular dynamics study
using reversible NVT-SLLOD and NPT-SLLOD algorithms. J. Chem. Phys. 103,
1019210200.
Mundy, C.J., Balasubramanian, S., Bagchi, K., Siepmann, J.I., Klein, M.L., 1996. Equilibrium
and Non-Equilibrium simulation studies of fluid alkanes in bulk and at interfaces. Faraday
Discuss. 104, 1736.
Murad, S., 1986. The viscosity of dense fluid mixtures: mixing rules reexamined using nonequi￾librium molecular dynamics. AIChE J. 32, 513516.
Nicolas, J.J., Gubbins, K.E., Street, W.B., Tildesley, D.J., 1979. Equation of state for the
Lennard-Jones fluid. Mol. Phys. 37, 14291454.
Ostler, D., Kannam, S.K., Frascoli, F., Daivis, P.J., Todd, B.J., 2020. Efficiency of electropump￾ing in nanochanels. Nano Lett. 20, 33963402.
Raabe, G., Todd, B.D., Sadus, R.J., 2005. Molecular simulation of the shear viscosity and the
self diffusion coefficient of mercury along the vapor-liquid coexistence curve. J. Chem.
Phys. 123, 034511.
Rapaport, D.C., 2004. The Art of Molecular Dynamics Simulation, second ed. Cambridge
University Press, Cambridge.
Ravi, P., Murad, S., 1992. Thermal conductivity of mixtures of polyatomic fluids using nonequi￾librium molecular dynamics. Mol. Sim. 9, 239245.
Ryckaert, J.-P., Bellemans, A., 1978. Molecular dynamics of liquid alkanes. Discuss. Faraday
Soc. 66, 95106.
Sadus, R.J., 2006. Molecular simulation of the thermophysical properties of fluids: phase behav￾iour and transport properties. Mol. Sim. 32, 185189.
Sarman, S., Evans, D.J., 1992a. Heat flow and mass diffusion in binary Lennard-Jones mixtures.
Phys. Rev. A 45, 23702379.
Sarman, S., Evans, D.J., 1992b. Heat flow and mass diffusion in binary Lennard-Jones mixtures.
II. Phys. Rev. A 46, 19601966.
Schoen, M., Hoheisel, C., 1984a. The mutual diffusion coefficient D12 in binary liquid model
mixtures. Molecular dynamics calculations based on Lennard-Jones (12-6) potentials. I. The
method of determination. Mol. Phys. 52, 3356.
Schoen, M., Hoheisel, C., 1984b. The mutual diffusion coefficient D12 in binary liquid model
mixtures. A molecular dynamics study based on Lennard-Jones (12-6) potentials. II.
Lorentz-Berthelot mixtures. Mol. Phys. 52, 10291042.
Schoen, M., Hoheisel, C., 1985. The shear viscosity of a Lennard-Jones fluid calculated by equi￾librium molecular dynamics. Mol. Phys. 56, 653672.
306 Molecular Simulation of FluidsSchultz, A.J., Kofke, D.A., 2018. Comprehensive high-precision high-accuracy equation of state
and coexistence properties for classical Lennard-Jones crystals and low-temperature fluid
phases. J. Chem. Phys. 149, 204508.
Searles, D.J., Evans, D.J., Hanley, H.J.M., Murad, S., 1998. Simulations of the thermal conduc￾tivity in the vicinity of the critical point. Mol. Sim. 20, 385395.
Simmons, A.D., Cummings, P.T., 1986. Non-equilibrium molecular dynamics simulation of
dense fluid methane. Chem. Phys. Lett. 129, 9298.
Singer, K., Singer, J.V.L., Fincham, D., 1980. Determination of the shear viscosity of atomic
liquids by non-equilibrium molecular dynamics. Mol. Phys. 40, 515519.
Tang, W.H., Kostov, K.S., Freed, K.F., 1998. Theory for the nonequilibrium dynamics of flexi￾ble chain molecules: relaxation to equilibrium of pentadecane from an all-trans conforma￾tion. J. Chem. Phys. 108, 87368742.
Tenenbaum, A., Ciccotti, G., Gallico, R., 1982. Stationary non-equilibrium states by molecular
dynamics. Fourier’s law. Phys. Rev. A 25, 27782787.
Todd, B.D., Daivis, P.J., 1998. Nonequilibrium molecular dynamics simulations of planar elon￾gational flow with spatially and temporally periodic boundary conditions. Phys. Rev. Lett.
81, 11181121.
Todd, B.D., Daivis, P.J., 2017. Nonequilibrium Molecular Dynamics: Theory, Algorithms and
Applications. Cambridge University Press, Cambridge.
Toxvaerd, S., 1990. Molecular dynamics calculation of the equation of state of alkanes. J. Chem.
Phys. 93, 42904295.
Trozzi, C., Ciccotti, G., 1984. Stationary nonequilibrium states by molecular dynamics. II.
Newton’s law. Phys. Rev. A 29, 916925.
Tuckerman, M.E., Mundy, C.J., Balasubramanian, S., Klein, M.L., 1997. Modified nonequilib￾rium molecular dynamics for fluid flows with energy conservation. J. Chem. Phys. 106,
56155621.
Tuckerman, M.E., Mundy, C.J., Balasubramanian, S., Klein, M.L., 1998. Response to “Comment
on ‘Modified nonequilibrium molecular dynamics for fluid flows with energy conservation’”
[J. Chem. Phys. 108, 4351 (1998)]. J. Chem. Phys. 108, 43534354.
Vlasiuk, M., Sadus, R.J., 2017. Ab initio interatomic potentials and the thermodynamic proper￾ties of fluids. J. Chem. Phys. 147, 024505.
Vogelsang, R., Hoheisel, C., 1988. The Dufour and Soret coefficients of isotopic mixtures from
equilibrium molecular dynamics calculations. J. Chem. Phys. 89, 15881591.
Wang, B.Y., Cummings, P.T., 1989a. Non-equilibrium molecular dynamics calculation of the
shear viscosity of carbon dioxide. Int. J. Thermophys. 10, 929940.
Wang, B.Y., Cummings, P.T., 1989b. Non-equilibrium molecular dynamics calculation of the
transport properties of carbon dioxide. Fluid Phase Equilib. 53, 191198.
Wang, B.Y., Cummings, P.T., 1996. In: Gubbins, K.E., Quirke, N. (Eds.), Molecular Simulation
and Industrial Applications: Methods, Examples and Prospects. Gordon and Breach,
Amsterdam.
Wheeler, D.R., Rowley, R.L., 1998. Shear viscosity of polar liquid mixtures via non-equilibrium
molecular dynamics: water, methanol, and acetone. Mol. Phys. 94, 555564.
Wold, I., Hafskjold, B., 1999. Nonequilibrium molecular dynamics simulations of coupled heat
and mass transport in binary fluid mixtures in pores. Int. J. Thermophys. 20, 847856.
Nonequilibrium molecular dynamics Chapter | 8 307This page intentionally left blankChapter 9
Molecular simulation of
ensembles
Previous chapters have described most of the fundamental aspects of molecu￾lar simulation methods. However, molecular simulations are almost invari￾ably conducted in the context of an ensemble. The choice of the ensemble
determines the overall simulation algorithm. Monte Carlo (MC) and molecu￾lar dynamics (MD) algorithms for a specified ensemble are very different,
reflecting fundamental differences in the two simulation methods. In this
chapter, MC and MD simulation algorithms for commonly used ensembles
are outlined. This topic has also been discussed by Allen and Tildesley
(2017), Heermann (1990), Rapaport (2004), Frenkel and Smit (2023), and
Heyes (1998).
The original MC method (Metropolis et al., 1953) sampled the canoni￾cal (NVT) ensemble. Metropolis et al. (1953) introduced the concept of
importance sampling to construct a Markov chain. The MC method can be
extended relatively easily to other ensembles because importance sampling
can be used for any Markov chain process. In general, the MC method can
be extended to other ensembles by sampling the variable that is conjugate
to the new fixed parameter. For example, McDonald (1972) reported MC
simulations in the isobaricisothermal (NpT) ensemble by sampling vol￾ume (the conjugate of pressure) in addition to molecular coordinates. In the
grand canonical ensemble, the chemical potential is fixed and the total
number of molecules N is the conjugate variable that is sampled (Valleau
and Cohen, 1980). In the past, it has not been possible to perform MC
simulations in the microcanonical ensemble. However, The MC method
has been extended specifically (Ray, 1991; Lustig, 1998) for the microca￾nonical ensemble.
Newton’s equations of motion lead naturally to the microcanonical
(NVE) ensemble because the total energy is conserved. Therefore, in con￾trast to MC simulations, the microcanonical ensemble is the natural
choice for MD. Extending MD to other ensembles requires some artificial
tampering with the equations of motion. A canonical (NVT) ensemble can
be obtained by either using velocity scaling or explicitly adapting the
309 Molecular Simulation of Fluids. DOI: https://doi.org/10.1016/B978-0-323-85398-9.00003-4
© 2024 Elsevier B.V. All rights reserved.equations of motion (Nose´, 1984; Hoover, 1985). Andersen (1980) formu￾lated an isobaricisoenthalpic (NpH) and isobaricisothermal (NpT) MD
algorithms by introducing additional degrees of freedom that are coupled
to the particle coordinates. This work has been extended rigorously
(Nose´, 1984; Hoover, 1985). Considerable progress has been achieved in
the development of MD algorithms for the grand canonical ensemble
(C¸ agin and Pettitt, 1991a & b; Lo and Palmer, 1995; Beutler and van
Gunsteren, 1994). The calculation of thermodynamic properties for differ￾ent ensembles is discussed in Chapter 2. MC and MD simulation algo￾rithms for different ensembles in a single phase are discussed here,
whereas techniques for multiphase equilibria are examined in Chapter 10.
9.1 Monte Carlo
All MC simulations use probabilities in conjunction with importance sampling
to generate a Markov chain of events. The theoretical basis of the MC method,
Markov chains, and importance sampling has been discussed extensively else￾where (Allen and Tildesley, 2017; Sobol’, 1994; Frenkel and Smit, 2023). From
a practical point of view, these concepts can be best understood in the context
of determining ensemble averages. Indeed, the concept of importance sampling
was first introduced (Metropolis et al., 1953) in the context of simulation of the
canonical ensemble, which will be the starting point for our discussion. In a later
section, we will show how simulations in the canonical ensemble can be
extended to other ensembles.
9.1.1 Canonical (NVT) ensemble
From the definition of the canonical (NVT) ensemble (Chapter 2), the canoni￾cal average of any function of particle coordinates h i A can be obtained from,
h i A 5
Ð
AðrNÞexp 2βUðrNÞ  drN
Ð
exp 2βUðrN ð ÞÞ drN ð9:1Þ
where β 5 1/kT and U is the total potential energy. In principle, by generat￾ing a large number of configurations (M) of particles, h i A can be estimated
by replacing the integrals with finite sums.
h i A 5
P
M
i51
AðiÞexp½ 2 βUðiÞ
P
M
i51
exp½ 2 βUðiÞ
ð9:2Þ
However, in practice, this simple approach is very inefficient because
many of the configurations sampled are unlikely to make a substantial
310 Molecular Simulation of Fluidscontribution to h i A . To sample phase-space efficiently, a mechanism is
required to ensure that the finite configurations sampled are genuinely repre￾sentative of the system. This is the concept of importance sampling, which
ensures that regions of configuration space that make the largest contribution
to the integrals of Eq. (9.1) are also the regions that are sampled most fre￾quently. However, importance sampling also introduces a bias to the sam￾pling. This bias can be removed from the ensemble averages by weighting
each configuration appropriately. If W(i) is the probability of choosing a con￾figuration i, Eq. (9.2) is replaced by:
h i A 5
P
M
i51
AðiÞexpð Þ 2βUðiÞ
WðiÞ
P
M
i51
expð Þ 2βUðiÞ
WðiÞ
ð9:3Þ
The Boltzmann distribution can be used as the weighting factor.
WðiÞ 5 expðÞ ð 2βUðiÞ 9:4Þ
By substituting Eq. (9.4) into Eq. (9.3), we obtain:
h i A 5 1
N
X
M
i51
AðiÞ ð9:5Þ
Eq. (9.5) indicates that the canonical ensemble is obtained as an
unweighted average over configurations in the sample. Therefore, as will be
illustrated subsequently, the trick of transforming the MC method to other
ensembles is to choose an appropriate weighing factor such that Eq. (9.5) is
obtained.
The procedure for a MC simulation in the canonical ensemble is to dis￾place a particle (i) randomly and determine the change in potential energy
ΔU 5 Utrial  Ui. If ΔU , 0, the move is accepted because it lowers the
energy of the system, and the particle is placed in its new position. If ΔU .
0, the move is allowed with a probability of exp(-βΔU). To decide the fate
of the particle, a random number R is generated between 0 and 1. If R .
exp(-βΔU), the particle remains to its original position otherwise the move
is accepted. It is important to note that irrespective of the outcome of the
move, that is, whether a different configuration has been generated or the
original configuration has been retained, a new configuration is created for
the purpose of the ensemble average. This process generates a so-called
Markov chain in which the probability of obtaining any configuration is
determined solely by the previous configuration. This procedure is illustrated
in Algorithm 9.1.
In common with all MC simulations, Algorithm 9.1 involves an initializa￾tion phase during which ensemble and simulation parameters are specified
Molecular simulation of ensembles Chapter | 9 311(Algorithm 9.1, Part 1) and an initial configuration is generated. Typically,
the initial state is created by positioning particles on a face-centered cubic
lattice common to many solids. If we assume pairwise interaction, the initial
potential energy (Utotal) is evaluated by calculating the contribution of all dis￾tinct pair interactions using a suitable intermolecular potential. This is the
only time that a double-loop is require in a typical NVT MC simulation.
Initial values for other ensemble properties such as the virial and pressure
are also evaluated.
The heart of a MC simulation is the generation of a Markov chain
(Algorithm 9.2, Part 2). The Markov chain is generated typically for sev￾eral thousand cycles (NCycles) with each cycle consisting of many MC
moves. Each new link or configuration in the Markov chain is created by
generating trial positions for all the atoms in turn. Each atom i is selected
randomly, typically using a random number generator (rand()) that returns
numbers on the interval from 0 to 1 (Algorithm 9.1, Part 2.1). Selecting
the atoms randomly is best practice for MC, although simply cycling
through all the full range is also commonly used. The coordinates of the
chosen atom are displaced randomly within a predetermined maximum
range of -rMax to rMax, adjusted for periodic boundary conditions(pbc(),
Algorithm 5.2)
The contribution to the total potential energy (Utriali) of atom i in the trial
position is evaluated (Algorithm 9.1, Part 2.2). The evaluation of Utriali
involves using an intermolecular potential to calculate the energy of interac￾tion between atom i and the remaining N - 1 atoms. Consequently, a MC algo￾rithm for pairwise interaction is of order N (Algorithm 1.1). The change in
potential energy (ΔU) is the difference in energy between atom i at its trial
and original positions (Algorithm 9.1, Part 2.3). The next part of the algo￾rithm (Algorithm 9.1, Part 2.4) is to determine whether or not the trial move
is accepted. If the trial move is accepted, the position of atom i and the
energy of the ensemble are updated. Otherwise, no change is made and
the next atom is considered. Both changed and unchanged states contribute
to the Markov chain.
During the equilibration period, the maximum displacements (rMax) used
for the trail moves are continually adjusted (Part 2.5.1) to achieve a desired
acceptance rate (acceptR), which involves continually updating the value of
the progressive acceptance ratio (acceptRatio).
It should also be noted that the system is allowed to come to equilibrium
(NEquilibration) before contributions to the ensemble average are accumulated
(Part 2.5.2). The equilibration period is important for obtaining reliable
ensemble averages because the initial state generally does not reflect accu￾rately the configuration at equilibrium. Therefore, the equilibration period is
used to “melt” the solid lattice to create a fluid state.
312 Molecular Simulation of FluidsAlgorithm 9.1 is the basis of MC simulations of a wide range of appli￾cations (Dubbeldam et al., 2013), including thermodynamic properties
(Vlasiuk et al., 2016).
ALGORITHM 9.1 MC simulation in the canonical (NVT) ensemble.
Overall Algorithm
Part 1 Initialization
Assign values for N, V, T, NCycles, DispCounter = 0, acceptR = 0.5
Assign initial coordinates rxi, ryi, rzi for the N atoms.
Evaluate and store Utotal, Ui, ptotal, pi etc.
Part 2 Generate a Markov Chain
loop n 1... NCycles
k 1
loop while (k <= NAtom)
2.1 Generate a trial displacement.
2.2 Calculate energy of atom i at the trial position
2.3 Calculate change in the potential energy:
U  Utriali - Ui
2.4 Displacement acceptance criterion.
k  k + 1
end while loop
2.5 if (n <= NEquilibration)
2.5.1 Adjust maximum displacement.
else
2.5.2 Accumulate averages. //post equilibration period
end if
end n loop
Details of Some Key Sub-Parts
Part 2.1 Generate a trial displacement:
Select i randomly, assuming indexes starting from 1:
i  nearest integer value of rand()  NAtom
rxTrial pbc(rxi + rMax  (2  rand() - 1))
ryTrial pbc(ryi + rMax  (2  rand() - 1))
rzTrial pbc(rzi + rMax  (2  rand() - 1))
Part 2.4 Displacement acceptance criterion: 
if (U < 0) //accept new positions
rx i  rxTrial
ry i  ryTrial
rxi  rzTrial
Ei  Etriali
Utotal  Utotal + U //update energy, pressure etc
DispCounter  DispCounter + 1
else
(Utriali).
Molecular simulation of ensembles Chapter | 9 313BF  exp(-U) //Boltzmann factor
if (BF > rand()) //accept new positions
rx i  rxTrial
ry i  ryTrial
rzi  rzTrial
Ui  Utriali
Utotal  Utotal + U //update energy, pressure etc
DispCounter  DispCounter + 1
end if
end if
end if 
end if 
Part 2.5.1 Adjust maximum displacement:
acceptRatio = DispCounter/n
if (acceptRatio < acceptR)
rMax  0.95  rMax
else
rMax  1.05  rMax
As discussed subsequently, other MC ensemble simulations can be
performed by modifying the acceptance criterion used in Algorithm 9.1.
In general, it is useful to define the following “pseudo-Boltzmann
factor,”
WðiÞ 5 expðÞ ð 2βY 9:6Þ
Where the nature of Y depends on the characteristics of the ensemble. For
the canonical ensemble, Y is simply U; however, additional terms are
required to calculate Y for other ensembles.
9.1.2 IsobaricIsothermal (NpT) ensemble
At conditions of constant temperature and pressure, the equivalent of
Eq. (9.2) (McDonald, 1972) is:
h i A 5
Ð N
0 expð2 βpVÞdVÐ
V AðrN; VÞexp½ 2 βUðrNÞdrN
Ð N
0 expð2 βpVÞdVÐ
Vexp½ 2 βUðrNÞdrN ð9:7Þ
In a MC simulation, the particles are confined to a cube of fluctuating
length (L). Consequently, we can make use of scaled coordinates (αi 5 ri/L)
such that the integrals over particle coordinates in Eq. (9.7) become integrals
over the unit cube (Ω).
h i A 5
Ð N
0 VNexpð2 βpVÞdVÐ
ΩAð½Lα
N; VÞexp 2βUð½Lα
N; LÞ  dαN
Ð N
0 VNexpð2 βpVÞdVÐ
Ωexp 2βEð½Lα
N; LÞ  dαN ð9:8Þ
314 Molecular Simulation of FluidsBy analogy with Eq. (9.4), we can define a pseudo-Boltzmann weighting
factor by using (9.6) with:
Y 5 pV 1 U ½Lα
N; L   2 NkTlnV ð9:9Þ
The algorithm for performing the NpT simulation is therefore a relatively
simple modification on the NVT algorithm. In addition to attempted particle
displacements, which are accepted or rejected depending of the value of ΔU,
attempted volume fluctuations are required to maintain constant pressure.
The value of ΔY will determine whether or not an attempted volume change
is accepted. In principle, attempting a volume change is more expensive
computationally than particle displacement because it requires the re￾evaluation of N(N  1) interactions compared with N  1 calculations for
particle displacement. However, this computational overhead can be often
avoided by using a “scalable” intermolecular potential.
Formally, the nth derivative of U with respect to volume V can be calcu￾lated from (Lustig, 1994).
@n
U
@Vn 5 1
2ð3VÞ
n
Xn
k51
X
i
X
i6¼j
ankr
k
ij
@k
uðrijÞ
@rk
ij ! ð9:10Þ
In Eq. (9.10), u is the intermolecular potential and the coefficients ank are
Sterling numbers of the second kind (Abramowitz and Stegun, 1970), which
can be calculated from the following recursive algorithm.
an11;k 5 an;k21 1 kank
an0  0
ann 5 1
)
ð9:11Þ
When n 5 1 we obtain:
@U
@V 5 1
6V
X
i
X
i6¼j
rij
@uðrijÞ
@rij 
  ð9:12Þ
The usefulness of these equations for determining thermodynamic properties
is detailed in Chapter 2.
It is evident from the earlier equation that a volume fluctuation can be
very expensive computationally because it affects all particles. The change
in volume also means that long-range corrections must also be re-evaluated.
However, for many simple intermolecular potentials, the need to re-calculate
all the pairwise interactions can be avoided by using scaling. For example, if
a Lennard-Jones (LJ)-type intermolecular potential is used, the energy of the
trial state can be calculated from:
U 5 4ε
X
i
X
j . i
σij
Lαij 
 12
2 4ε
X
i
X
j . i
σij
Lαij 
 6
ð9:13Þ
Molecular simulation of ensembles Chapter | 9 315Equation (9.13) indicates that there are two distinct contributions to the
energy with a different power dependence. To make use of scaling, the 12th
and 6th dependence must be stored separately. Therefore, we define the
potential energy as:
U 5 Uð12Þ 1 Uð6Þ ð9:14Þ
Consequently, the effect of changing the length of the box on the poten￾tial energy can be calculated from:
Utrial 5 Uð12Þ Ltrial
L

 12
1 Uð6Þ Ltrial
L

 6
ð9:15Þ
The same procedure can be applied to obtain the virial.
The scaling procedure can only be applied if there is only one characteristic
length in the potential function. Consequently, its usefulness is limited to rela￾tively simple intermolecular potentials. It is not appropriate for any molecular
models, which involve intramolecular bond lengths in addition to sitesite inter￾actions. For these cases, the computationally expensive N(N  1) pair calcula￾tion may be unavoidable.
A possible implementation of the NpT MC procedure is illustrated by
Algorithm 9.2. The initialization phase (Algorithm 9.2, Part 1) of
Algorithm 9.2 is similar to the initialization phase of Algorithm 9.1 except
that the “scalability” of the intermolecular potential is identified. Whether
or not the potential is scalable will influence how the volume fluctuation is
handled (Algorithm 9.2, Parts 2.3 and 2.5). As discussed previously, a
scalable potential avoids the recalculation of the total energy and as such is
very computationally advantageous.
Each configuration in the Markov chain for a NpT ensemble is the result of
two different possible trial moves involving atomic displacement
(Algorithm 9.2, Part 2.1) and volume change (Algorithm 9.2, Part 2.2), respec￾tively. The displacement stage (Algorithm 9.2, Part 2.1) of the Markov process
proceeds identically to the NVT ensemble (Algorithm 9.1, Parts 2.1 to 2.4). It
involves the generation of trial coordinates, calculation of the energy experi￾enced at the trial position and determining the overall change in the energy of
the ensemble. At this stage, the volume is unaffected, and the acceptance crite￾rion reduces to the NVT ensemble criterion (Algorithm 9.1, Part 2.4).
The next stage (Algorithm 9.2, Part 2.2) of the Markov process is to
attempt a volume fluctuation. The trial volume is obtained by resizing ran￾domly the length of the simulation box by a predefined amount with the range
of -LMax to LMax. If the potential is scalable (Algorithm 9.2, Part 2.3), the
energy of the ensemble is scaled by the new volume otherwise the trial energy
is calculated by considering all pair interactions at the trial coordinates. The
change in energy and volume of the ensemble (Algorithm 9.2, Part 2.4) are
used to determine ΔY. The acceptance of the volume fluctuation
(Algorithm 9.2, Part 2.5) is determined by the value of ΔY. If the trail volume
316 Molecular Simulation of Fluidsmove is accepted, the assignment of the updated coordinates depends on
whether or not the potential was scalable as illustrated in Part 2.5. In common
with the displacement step, the acceptance of volume changes is continually
monitored during the equilibration phase to achieve a specified acceptance
value (acceptV). The nature of the adjustments (Algorithm 9.2, Part 2.5.1) fol￾lows the same procedure as for the displacement step.
ALGORITHM 9.2 MC simulation in the NpT ensemble.
Overall Algorithm
Part 1 Initialization
Assign values for N, p, T, NCycles, DispCounter = 0, acceptR = 0.5,
 VolCounter = 0, acceptV = 0.5 etc.
Assign initial coordinates rxi, ryi, rzi for the N atoms.
Evaluate and store Utotal, Ui, ptotal, pi etc.
if (intermolecular potential is scalable)
scalable  true
else
scalable  false
end if
Part 2 Generate a Markov Chain
loop n 1... NCycles
k 1
loop while (k <= NAtom)
2.1 Implement Parts 2.1-2.4 of Algorithm 9.1 (NVT Ensemble)
k  k +1
end while loop
2.2 Generate a trial move by attempting a volume change:
Ltrial  L + LMax  (2  rand() - 1)
Vtrial  Ltrial3
2.3 Evaluate Utrial:
if (scalable)
Scale Utotal to obtain UtrialTotal.
else
loop i  1 .. NAtom //scale coordinates
rxTriali  rxi  (L/Ltrial)
ryTriali  ryi  (L/Ltrial)
rzTriali  rzi  (L/Ltrial)
end i loop
Perform N(N-1) calculations for UtrialTotal, Utriali.
end if
2.4 Calculate change in energy and acceptance term.
U  UtrialTotal - Utotal
Y p  (Vtrial - V) + E + N  k  T  ln(V/Vtrial)
2.5 Volume change acceptance criterion.
if (n <= NEquilibration)
2.5.1 Adjust maximum volume change.
Adjust maximum displacement change (see Algorithm 9.1).
else
Molecular simulation of ensembles Chapter | 9 317Accumulate averages.
end if
end n loop
Details of Some Key Sub-Parts
Part 2.5 Volume change acceptance criterion:
if (Y < 0) //accept new configuration
if (scalable)
loop i  1 .. NAtom //scale coordinates
rx i  rxi  (L/Ltrial)
ry i  ryi  ( L/Ltrial)
rzi  rzi  (L/Ltrial)
Scale Ui
end i loop
else
loop i  1 .. NAtom //update coordinates
rx i  rxTriali
ry i  ryTriali
rzi  rzTriali
Ui  Utriali
end i loop
end if
L Ltrial //update properties
V Vtrial
Utotal UtrialTotal
VolCounter  VolCounter + 1
else
PBF  exp(-Y) //pseudo-Boltzmann factor
if (PBF > rand()) //accept new configuration
if (scalable)
loop i  1 .. NAtom //scale coordinates
rx i  rxi  (L/Ltrial)
ry i  ryi  (L/Ltrial)
rzi  rzi  (L/Ltrial)
Scale Ei
end i loop
else
loop i  1 .. NAtom //update coordinates
rx i  rxTriali
ry i  ryTriali
rzi  rzTriali
Scale Ui
end i loop
end if
L Ltrial //update properties
V Vtrial
Utotal Utotal + U
VolCounter  VolCounter + 1
end if
end if
end if
Part 2.5.1 Adjust maximum volume change:
acceptVRatio = VolCounter/n
if (acceptVRatio < acceptV)
LMax  0.95  LMax
else
LMax  1.05  LMax
318 Molecular Simulation of FluidsIt should be noted that there are different possible combinations of trial
moves. In Algorithm 9.2, a displacement is attempted for each atom followed
by a single attempt to change the volume. However, both attempted displace￾ments and volume changes could be combined in the same trial move but
this would complicate the algorithm. It is also possible to choose randomly
between particle displacement and volume change. The choice should be
biased heavily toward particle displacement to ensure that equilibrium is
achieved rapidly. In practice, one attempted volume change per cycle is often
sufficient to bring the system to equilibrium. The efficiency of volume
changes is discussed in greater detail by Brennan and Madden (1998). Some
useful improvements to the basic algorithm have also been discussed
(Okumura and Okamoto, 2004a &b; McGrath et al., 2005). The approach
can also be adapted for MC simulations in the isobaricisenthalpic (NpH)
ensemble (Stro¨ker and Meier, 2022).
9.1.3 Grand canonical (µVT) ensemble
MC simulation in the grand canonical ensemble has been discussed by sev￾eral workers (Adams, 1974; Valleau and Cohen, 1980; Nicholson and
Parsonage, 1982). The distinctive feature of the grand canonical ensemble is
that number of particles fluctuates while maintaining a constant chemical
potential (μ), volume, and temperature. The average of any property of the
grand canonical ensemble can be obtained from
h i A 5
P
N
N50
Λ23N
N! expðβNμÞ
Ð
AðrNÞexp 2βUðrNÞ  drN
ZμVT
ð9:16Þ
where ZμVT is the canonical partition function and Λ is the de Broglie ther￾mal wavelength. Using scaled coordinates and making use of the relationship
βμideal 5 log (N/V) 1 3 log Λ, Eq. (9.16) can be rewritten (Adams, 1974;
Hansen and McDonald, 2013) as,
h i A 5
P
N
N50
expðβNμ

2 lnN!Þ
Ð
ΩAexpð Þ 2βU dαN
ZμVT
ð9:17Þ
where μ

involves the contribution of the residual1 chemical potential (μr
).
μ

5 μr 1 kTlnhi ð N 9:18Þ
1. As noted in Chapter 2, a residual quantity is sometimes mistakenly referred to as an excess
property, whereas in chemical thermodynamics, the latter term should be applied only to mixture
properties.
Molecular simulation of ensembles Chapter | 9 319The pseudo-Boltzmann factor for this ensemble is given by Eq. (9.6)
with:
Y 5 2 Nμr 1 kTlnN! 1 U rN   ð9:19Þ
The grand canonical ensemble involves the possible removal and/or addi￾tion of particles. If there is no change in the number particles, it is apparent
from Eq. (9.19) that ΔY 5 ΔU and Eq. (9.8) is simply the Boltzmann aver￾age used in the canonical NVT ensemble. Therefore, an algorithm for the
grand canonical ensemble can be devised consisting of three attempted
moves: particle displacement (identical to the canonical ensemble); particle
insertion; and particle removal.
Algorithm 9.3 illustrates one possible procedure for conducting a grand
canonical MC simulation. Following initialization (Algorithm 9.3, Part 1), a
Markov chain is created (Algorithm 9.3, Part 2) by implementing molecular dis￾placement (Algorithm 9.3, Part 2.1), particle creation (Algorithm 9.3, Part 2.2),
or particle destruction (Algorithm 9.3, Part 2.3). The type of move implemented
is chosen with equal probability. A particle displacement corresponds to a con￾ventional MC NVT ensemble move. In Algorithm 9.3, when a displacement
move is chosen, an attempt is made to displace all the particles. Alternatively,
only one particle could be displaced per move and the number of cycles could
be increased considerably. The particle insertion move (Algorithm 9.3, Part 2.2)
involves selecting coordinates randomly and determining the energy that the
atom would experience in the trial location. This evaluation of energy involves
calculating the particle’s interaction with the N particles. The interaction energy
is used to calculate ΔY, which is used in evaluating the acceptance criterion
(Algorithm 9.3, Part 2.2.1). The particle removal move (Algorithm 9.3, Part 2.3)
proceeds in a similar fashion except that an existing particle must be selected
randomly. The algorithm proceeds directly to the evaluation of ΔY and the
application of the acceptance criterion (Algorithm 9.3, Part 2.3.1) because the
energy of the selected particle is known.
In an object-oriented language such as C11 (Chapter 11), particle addi￾tion and removal can be achieved by creating and deleting an object, respec￾tively. Alternately, if arrays are used, the addition of a particle can be
handled by simply increasing the size of the array by 1 and assigning
the coordinates of the added particle to rxm11, rym11, and rzm11, where m is
the last index of the original array. Particle deletion can be accomplished by
assigning the array index of the deleted particle to the mth particle and then
changing the last array index to m  1.
The importance of particle creation and destruction in the μVT ensemble
has been the impetus to development of novel approaches (Orkoulas, 2007;
Shi and Maginn, 2007), which are particularly important when large macro￾molecules are involved. (Hu et al., 2005; Turesson et al., 2008). As discussed
in Chapter 2, new approaches (Stutzman et al., 2018; Stro¨ker et al., 2021)
320 Molecular Simulation of Fluidsfor determining thermodynamic properties in the μVT ensemble have been
developed. It should be noted that the μVT approach generally fails at high
densities because insertion attempts are overwhelmingly rejected, which
means it is inappropriate for solids. Suitable algorithms for solidliquid
equilibrium are discussed in Chapter 10.
ALGORITHM 9.3 MC simulation in the µVT ensemble.
Overall Algorithm
Part 1 Initialization
Assign values for , N, V, T, NCycles, DispCounter = 0,
acceptR = 0.5,etc.
Assign initial coordinates rxi, ryi, rzi for the N atoms.
Evaluate and store Utotal, Ei, ptotal, pi etc.
Part 2 Generate a Markov Chain
loop n 1... NCycles
choice  rand()
if (0 < choice  1/3)
k 1
loop while ( k <= NAtom)
2.1 Implement Parts 2.1-2.4 of Algorithm 9.1 (NVT Ensemble)
k  k+ 1
end while loop
else if (1/3 > choice  2/3)
2.2 Attempt to insert an atom:
Randomly select a position (rxTrial, ryTrail, rxTrial).
Evaluate Ui.
Y  -* + kTln(N + 1) + Ui
2.2.1 Insertion acceptance criterion.
else
2.3 Attempt to remove an atom:
Select randomly an atom (i) to be removed.
Y  * - kTln(N ) + Ui
2.3.1 Removal acceptance criterion.
end if
2.4 if (n <= NEquilibration)
2.4.1 Adjust maximum displacement change (see Algorithm 9.1).
else
Accumulate averages.
end if
end n loop
Details of Some Key Sub-Parts
Part 2.2 Insertion acceptance criterion:
if (Y < 0)
Accept new atom.
Utotal Utotal + Ui
Molecular simulation of ensembles Chapter | 9 321else
PBF  exp(-Y)
if (PBF > rand())
Accept new atom.
Utotal Utotal + Ui
end if
end if
Part 2.3.1 Removal acceptance criterion:
if (Y < 0)
Remove selected atom.
Utotal Utotal - Ui
else
PBF  exp(-Y)
if (PBF > rand())
Remove selected atom.
Utotal Utotal - Ui
end if
end if
9.1.4 Microcanonical (NVE) ensemble
The microcanonical ensemble conserves the number of particles, volume,
and total energy (E). As discussed in the preceding sections, the basis of MC
simulations is the algorithm of Metropolis et al. (1953), which generates the
canonical (NVT) ensemble. This algorithm can be incorporated into simula￾tions for the isothermalisobaric and grand canonical ensembles but it can￾not be used to generate a microcanonical ensemble. However, theoretical
advances (Creutz, 1983; Ray, 1991; Lustig, 1998) have made MC simula￾tions possible.
Creutz (1983) reported the first MC simulations in the microcanonical
ensemble. This particular solution to the problem was confined to lattice￾based systems and involves the use of an energy “demon” in conjunction
with a random walk through possible configurations that satisfy the con￾straint of constant total energy. Later, Ray (1991) reported a general solution
to the problem based on the statistical mechanical formulation of Pearson
et al. (1985). Ray’s procedure involves Metropolis-type moves and uses the
acceptance criterion PE 5 minð1; WEðr
0
Þ=WEðrÞÞ, where the probability den￾sity (WE) plays the same role as the “pseudo-Boltzmann factor” in the other
ensembles.
WEðrÞ 5 C E2UðrNÞ  3N=2 21
Θ E 2 UðrNÞ   ð9:20Þ
322 Molecular Simulation of FluidsIn Eq. (9.20), C is a constant and Θ(x) 5 1 for x . 0 and Θ(x) 5 0 for
x # 0. The corresponding partition function for the ensemble is:
ZNVE 5 CðNÞ
ð
E2UðrNÞ  3N=2
Θ E 2 UðrNÞ  drN ð9:21Þ
The relationships S 5 klnðZNVEÞ and T21 5 @S=@E enable us to determine
the temperature.
T 5 2 E 2 UðrNÞ  
3Nk 5 2h i K
3Nk ð9:22Þ
In Eq. (9.22), we have identified the kinetic energy (K) as simply
E 2 UðrNÞ. Strictly, the constraints imposed (Lustig, 1998; Hu¨neneberger,
2005) by the MD simulation should be subtracted from the 3 N contribution
in Eq. (9.22). However, in practice this has a negligible effect because of
large values of N typically used in modern simulations. The pressure is
obtained by differentiating the entropy with respect to volume.
p 5 NkT
V 2 @U
@V
  ð9:23Þ
If the entropy is differentiated with respect to energy, the specific heat at
constant volume (CV) can be calculated (Chapter 2).
Nk
CV
5 1 2 1 2 2
3N

 h i K K21   ð9:24Þ
Application of MC simulations for the microcanonical ensemble has been
discussed by Lustig (1998).
Equation (9.22) is significant because it enables the calculation of tem￾perature from a MC simulation. The temperature depends on the momenta of
the atoms and it can be calculated easily in a MD simulation. In contrast, in
a MC simulation, the temperature is a fixed variable, which cannot be
obtained from the simulation because the momenta of the atoms cannot be
calculated in MC procedure. Equation (9.22) overcomes this problem by cal￾culating temperature from the configurational properties of the ensemble
without requiring any dynamical information. Butler et al. (1998) have
shown that the temperature can be also calculated from the following
formula,
1
kT 5 r2
qU
rqU 
 

2
* + ð9:25Þ
whererqis the gradient operator with respect to the particle positions (q).
Equation (9.25) implies that the temperature can be calculated by evaluating
Molecular simulation of ensembles Chapter | 9 323the first and second derivatives of the intermolecular potential during the
course of the simulation. For a pairwise potential the scalar separation
between particle i and j in terms of the x, y, and z components is given by
rij 5
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
x2
ij 1 y2
ij 1 z2
ij q
and the derivatives that are required to evaluate the con￾tributions to Eq. (9.25) can be obtained from:
@U
@ri
5 2 @U
@rj
5 rij
rij
@U
@rij
@2
U
@r2
i
5 @2
U
@r2
j
5 @2
U
@x2
i
1
@2
U
@y2
i
1
@2
U
@z2
i
@2
U
@x2
i
5

 1
rij
2 x2
ij
r3
ij
 @U
@rij
1 x2
ij
r2
ij
@2
U
@r2
ij
9
>>>>>>>>>>=
>>>>>>>>>>;
ð9:26Þ
Using Eq. (9.25) provides an additional check on the accuracy of the sim￾ulation, as the configurational temperature must equal the fixed value of tem￾perature specified at the outset of the MC simulation.
Algorithm 9.4 illustrates an implementation of a MC simulation in the
microcanonical ensemble. The procedure is similar to Algorithm 9.1 except
that the acceptance or rejection of a move depends on the ratio of kinetic
energies rather than the change in potential energy. The initial kinetic energy
is determined in the initialization phase (Algorithm 9.4, Part 1). In common
with the canonical ensemble, a trial move is attempted (Algorithm 9.4, Part
2.1) and the energy experienced by the atom is determined. The change in
energy is used to calculate the new kinetic energy. The acceptance of a
move (Algorithm 9.4, Part 2.2) depends on the ratio of the new and old
kinetic energies (W). The value of W plays the analogous role to ΔU in the
canonical ensemble. The allowed values of Θ mean that the only moves that
can be accepted are those for which the energy of interaction is lower than
the total energy. Configurations with W . 1 can be accepted immediately
because they have a lower potential energy than the current configuration. It
is also important to update the maximum displacement periodically
(Algorithm 9.4, Part 2.3) to avoid a low acceptance rate. An alternative
implementation of Algorithm 9.4 is to attempt random displacements for
every atom and apply the acceptance criterion for the combined move. This
alternative is described in Chapter 6 and an implementation in C11 is given
in Chapter 11.
It should be noted that a similar procedure can also be used to generate
an NpH ensemble. For the NpH ensemble, the appropriate probability density
is (Ray, 1991):
WEðrÞ 5 C H2pV2UðrNÞ  3N=2 21
Θ H 2 pV 2 UðrNÞ   ð9:27Þ
324 Molecular Simulation of FluidsAlgorithm 9.4 can be modified easily to use Eq. (9.27) instead of
Eq. (9.20), however in this case volume fluctuations are also required period￾ically to maintain constant pressure.
ALGORITHM 9.4 MC simulation in the NVE ensemble.
Overall Algorithm
Part 1 Initialization
Assign values for N, V, Efixed, NCycles, DispCounter = 0,
acceptR = 0. 5etc.
Assign initial coordinates rxi, ryi, rzi for the N atoms.
Evaluate and store Utotal, Ui, ptotal, pi etc.
F  3N/2 - 1
Kold  Efixed – Utotal
Part 2 Generate a Markov Chain
loop n 1... NCycles
k 1
loop while (k <= NAtom)
2.1 Implement Parts 2.1-2.3 of Algorithm 9.1 (NVT Ensemble).
Knew Efixed - (Utotal + U) //kinetic energy
2.2 NVE acceptance criterion.
k  k +1
end while loop
2.3 if (n <= NEquilibration)
2.3.1 Adjust maximum displacement change (see Algorithm 9.1).
else
Accumulate averages.
end if
end n loop
Details of Some Key Sub-Parts
Part 2.2 NVE acceptance criterion:
if(Knew > 0)
W  (Knew/Kold)
F
if (W > 1 or W > rand())
rx i  rxTrial //accept new positions
ry i  ryTrial
rzi  rzTrial
Ui Utriali
Utotal  Utotal + U //update energy
Kold  Knew
end if
end if
Some examples of the use of the NVE approach include investigations of the
high temperature behavior of square well fluids (Sastre et al., 2015 & 2018) and
lattice gas systems (Shida et al., 2003). An alternative NVE implementation that
makes use of Eq. (9.25) has been proposed (Palma and Riveros, 2021).
Molecular simulation of ensembles Chapter | 9 325As discussed in Chapter 2, properties obtained from different ensembles
should yield the same values in the thermodynamic limit. Comparisons of
properties obtained for common state points using different ensembles are rela￾tively scarce in the literature. Assembling a comparison from different sources
is also subject to confounding factors such as the differences in the number of
particles, cut-off values, and other differences in the simulation settings.
Table 9.1 compares MC simulations in the NVE, NVT (Lustig, 2011), NpT
(Stro¨ker et al., 2021), and NpH (Stro¨ker and Meier, 2022) ensembles for vari￾ous thermodynamic properties at close to a common state point for the LJ
potential (Chapter 3). The difficulty in obtaining E and H to exactly generate
common values of p, V, and T for a finite number of particles means that iden￾tical results cannot be realistically expected. Nonetheless, reasonably close
agreement for the thermodynamic quantities obtained using different ensem￾bles is apparent from the data in Table 9.1. This conclusion is supported by
other work (Nitzke and Vrabec, 2023), which also indicates that the microca￾nonical ensemble yields results with the best overall statistical quality. In con￾trast, the choice of NVT and NpT ensembles in nonequilibrium MD
simulations (Chapter 8) has a noticeable effect (Bosko et al., 2005) on the
observation of shear thickening at high strain rates.
9.2 Molecular dynamics
9.2.1 Microcanonical (NVE) ensemble
The microcanonical ensemble is the default ensemble for MD because
Newton’s equations of motion conserve energy. The MD algorithm for the
TABLE 9.1 Comparison of MC simulations for the isobaric heat capacity
(Cp), JouleThomson coefficient (μJT), and zero frequency speed of sound
(w0) for the Lennard-Jones potential in the NVE, NVT, NpT, and NpH
ensembles (Lustig, 2011; Stro¨ ker et al., 2021; Stro¨ ker and Meier, 2022).
The values in brackets are the reported uncertainties in the final digit.
Ensemble/
Reduced Property
NVE NVT NpT NpH
kT=ε 1.015 1.015 1.0 1.05781(7)
pσ3=ε 1.071(5) 1.070(6) 1.0 1.0
ρσ3 0.8 0.8 0.79878(48) 0.780391(13)
Cp =k 4.8(1) 4.8(2) 4.79(7) 4.820(21)
kμJT =σ3 2 0.16(1) 2 0.15(1) 2 0.1573(43) 2 0.1493(14)
w0= ffiffiffiffiffiffiffiffiffi
ε=m p 5.563(3) 5.557(4) 5.5159(24) 5.3479(46)
326 Molecular Simulation of FluidsNVE ensemble also conserves linear momentum (Chapter 2). As was dis￾cussed in Chapter 2, the motion of particles does not affect the energy of the
ensemble, which remains constant. In principle, a microcanonical (NVE)
ensemble is generated automatically by solving Newton’s equations of
motion. The general procedure for obtaining a microcanonical ensemble is
illustrated by Algorithm 9.5.
The initialization phase (Algorithm 9.5, Part 1.1) of Algorithm 9.5 involves
assigning initial velocities to the atoms. The velocities can take any initial
values because they will be corrected quickly in the integrator phase
(Algorithm 9.5, Part 2.1.2) of the main body of the simulation. Consequently,
initial velocities can be either assigned randomly or set to zero. Similarly, with
the exception of acceleration, any other time derivatives required by the inte￾grator algorithm can be assigned to zero. The initial forces (Algorithm 9.5,
Part 1.2) on the atoms must be calculated accurately by considering all N(N 
1) interactions. During the initial force evaluations, the initial accelerations are
determined accurately from the relationship ai 5 fi/mi. The total potential
energy is also calculated during the force evaluation. The main body
(Algorithm 9.5, Part 2) of the algorithm is a loop, which executes repeatedly
the key simulation strategies. The heart of any MD program is the calculation
of the force (Algorithm 9.5, Part 2.1.1) experienced by each atom as the result
of interaction with all other atoms. This invariably involves using an appropri￾ate intermolecular potential to evaluate particle interactions. Examples of inter￾molecular potentials are discussed in Chapters 3 and 4. The newly calculated
forces are used in conjunction with a finite-difference algorithm (Chapter 7) to
evaluate Newton’s equations of motion, and thereby determine new atomic
coordinates, velocities, accelerations, and any other time derivatives
(Algorithm 9.5, Part 2.1.2). Each pass through the loop represents the advance￾ment of time t by an amount Δt. Consequently, after M cycles, the total dura￾tion or elapsed time of the simulation is equal to MΔt. Contributions to
ensemble averages are only accumulated after a period of equilibration
(tEquilibration) (Algorithm 9.5, Part 2.2).
It is apparent from Algorithm 9.5 that the key feature of a MD algorithm
is the evaluation of force, which via a suitable integrator algorithm
(Chapter 7) determines new molecular coordinates and other dynamical prop￾erties in accordance with Newton’s laws of motion. Unlike MC simulations,
chance plays no part in MD. Although the potential energy is determined
during the force evaluations, it plays no part in determining molecular displa￾cements. The need to re-evaluate all forces at each time step means that MD
algorithms are intrinsically order N2 compared with order N for MC algo￾rithms.2 Considerable attention has been directed toward computation-saving
strategies (Chapter 5).
2. However, the displacement step for each MC cycle is typically repeated N times, which means
that both MC and MD are overall of order N2 for a given cycle/time step.
Molecular simulation of ensembles Chapter | 9 327ALGORITHM 9.5 General MD NVE ensemble strategy.
Part 1 Initialization
1.1 Assign number of particles, energy, volume, etc.
Assign coordinates (ri) at time (t) = 0.
Assign molecules an initial velocity (vi).
Assign any other (n
r/t
n
)i values (n > 2).
1.2 Initial force calculations:
Calculate forces (fi) on each atom from all other j atoms.
Calculate acceleration (ai) for each atom.
Part 2 Simulation Process
loop
2.1 Integrate equations of motion: 
2.1.1 Calculate fi on each atom from all other j atoms.
2.1.2 Apply integrator to update ri, ai, vi, (n
r/t
n
)i.
2.2 If (t > tEquilibration)
Accumulate averages.
end if
t  t + t
while (t  tMax)
In the microcanonical ensemble, the number of particles, volume, and energy
are constant. Keeping the number of particles and volume constant is straightfor￾ward. They are specified during the initialization phase and they cannot change
because the algorithm does not involve volume fluctuations, particle removal, or
particle addition. Control of the total energy is achieved via the contribution
from kinetic energy. At the start of the simulation, the desired energy per parti￾cle is specified (ED), however the actual energy (EA) depends on the actual
kinetic energy (KA) and the calculated potential energy (U).
EA 5 KA 1 U ð9:28Þ
The desired kinetic energy (KD) is obtained from the calculated potential
energy.
KD 5 ED 2 U ð9:29Þ
The desired energy can be achieved by scaling the initial velocities (vi) of
each molecule with respect to the desired and actual kinetic energies.
vnew
ix 5 vix
ffiffiffiffiffiffi
KD
KA
s
vnew
iy 5 viy
ffiffiffiffiffiffi
KD
KA
s
vnew
iz 5 viz
ffiffiffiffiffiffi
KD
KA
s
9
>>>>>>>>>>=
>>>>>>>>>>;
ð9:30Þ
328 Molecular Simulation of FluidsAt the start of MD simulation, the linear momentum is usually set to
zero. In principle, it is only necessary to scale the velocities once at the
beginning of the simulation and thereafter, the energy conservation proper￾ties of the canonical ensemble should ensure that the energy remains con￾stant. However, in practice a drift in energy is observed caused partly by
inaccuracies in the calculation of forces. Therefore, to keep the calculations
on track, the velocities are scaled periodically during the equilibration
period. This scaling must not be continued after the equilibration period
because it would introduce an artificial discontinuity in energy.3 This strat￾egy is illustrated by Algorithm 9.6.
ALGORITHM 9.6 MD in the NVE ensemble using periodic scaling of
velocities.
Part 1 Initialization
1.1 Assign number of particles, energy, volume, etc.
Assign coordinates (ri) at time (t) = 0.
Assign molecules an initial velocity (vi). 
Scale vi consistent with the energy of the ensemble.
Assign any other (n
r/t
n
)i values (n > 2).
1.2 Initial force calculations:
Calculate forces (fi) on each atom from all other j atoms.
Calculate acceleration (ai) for each atom.
Part 2 Simulation Process
loop
2.1 Integrate equations of motion: 
2.1.1 Calculate fi on each atom from all other j atoms.
2.1.2 Apply integrator to update ri, ai, vi, (n
r/t
n
)i.
2.2 If (t > tEquilibration)
Accumulate averages.
else if (mod(m, scalingInterval) = 0)
Scale velocities. 
end if
t  t + t
m  m + 1
while (t  tMax)
Algorithm 9.6 follows closely Algorithm 9.5 with the exception that the
velocities are scaled in Parts 1.1 and 2.2. The choice of scalingInterval is arbi￾trary and depends on the behavior of the integrator. Typically, a scaling
interval of 10100 time steps is usually sufficient. An implementation of
Algorithm 9.6 is described in Chapter 11. MC and MD implementations of
3. As noted in Chapter 8, this does not necessarily apply to NEMD algorithms because the modi￾fication of the Newton’s law introduces additional heating that requires the application of a ther￾mostat for the full length of the simulation.
Molecular simulation of ensembles Chapter | 9 329the NVE ensemble have been directly compared of a restricted range of
applications (Schierz et al., 2015).
9.2.2 Canonical (NVT) ensemble
Microcanonical ensemble simulations are not used routinely because we gen￾erally have a much better idea of temperature than energy. If the number of
particles, volume, and temperature are constant, a canonical ensemble is gen￾erated. There are a few different options for generating a canonical ensem￾ble. The simplest methods to obtain constant temperature involve either
velocity scaling or heat-bath coupling. Alternatively, the thermostats of
Andersen (1980), Nose´ (1984), and Hoover (1985) or a general constraint
(Hoover et al., 1982; Evans, 1983) approach can be used. These latter alter￾natives involve modifying the equations of motion. The implementation and
merits of the various strategies are discussed subsequently. A general review
of thermostats used in MD is available elsewhere (Hu¨neneberger, 2005).
9.2.2.1 Simple velocity scaling
In principle, the simplest method to maintain a constant temperature is to re￾scale periodically the particle velocities. The kinetic energy per particle for
the ensemble can be calculated from,
h i K 5 1
2N
X
i
miviUvi
* + ð9:31Þ
or from the kinetic theory of gases.
h i K 5 3kT
2 ð9:32Þ
Equating Eqs. (9.31) and (9.32), we obtain the following relationship for
temperature.
T 5 1
3Nk
X
i
miviUvi
* + ð9:33Þ
Equation (9.33) enables4 us to determine the actual temperature (TA) for
the ensemble at any time. Consequently, the velocities can be scaled with
respect to the actual and desired temperatures (TD).
4. For MD, Eq. (9.33) should be modified to account for the reduction in the number of degree
of freedom due to the conservation of linear momentum. That is, 3 N should be replaced with
3 N  3.
330 Molecular Simulation of Fluidsvnew
ix 5 vix
ffiffiffiffiffi
TD
TA
s
vnew
iy 5 viy
ffiffiffiffiffi
TD
TA
s
vnew
iz 5 viz
ffiffiffiffiffi
TD
TA
s
9
>>>>>>>>>>=
>>>>>>>>>>;
ð9:34Þ
ALGORITHM 9.7 Molecular dynamics in the NVT ensemble using simple
velocity scaling.
Part 1 Initialization
1.1 Assign number of particles, temperature, volume, etc.
Assign coordinates (ri) at time (t) = 0.
Assign molecules an initial velocity (vi). 
Scale vi consistent with the temperature of the ensemble.
Assign any other (n
r/t
n
)i values (n > 2).
1.2 Initial force calculations:
Calculate forces (fi) on each atom from all other j atoms.
Calculate acceleration (ai) for each atom.
Part 2 Simulation Process
loop
2.1 Integrate equations of motion: 
2.1.1 Calculate fi on each atom from all other j atoms.
2.1.2 Apply integrator to update ri, ai, vi, (n
r/t
n
)i.
2.2 if (t > tEquilibration)
Accumulate averages.
else if (mod(m, scalingInterval) = 0)
Scale velocities according to temperature. 
end if
t  t + t
m  m + 1
while (t  tMax)
The algorithm for the canonical ensemble (Algorithm 9.7) is similar to
the velocity-scaled microcanonical ensemble (Algorithm 9.6) except
that the velocities are scaled via temperature (Algorithm 9.7, Part 2.2)
rather than energy. In the velocity-scaled microcanonical ensemble algo￾rithm, velocity scaling after the initialization phase is optional. However,
for the canonical algorithm, periodic re-scaling in the loop is essential.
Velocity scaling is less effective in achieving a set-point temperature than
energy scaling to obtain a set-point energy because kinetic energy is not
a constant of motion. Energy is exchanged between the potential and
Molecular simulation of ensembles Chapter | 9 331kinetic energy contributions during equilibration causing a drift away
from the desired temperature. Re-scaling during this period is required to
compensate for this drift.
Velocity scaling is appealing because it is simple to implement in
diverse range of different situations (Zhou et al., 2010; Kouza and
Hansmann, 2011), although other approaches have arguably a stronger
theoretical basis (Kutteh, 1999a & b; Page et al., 2012). A relatively sim￾ple modification has been proposed (Morishita, 2003a) to improve its use￾fulness in the velocity-Verlet algorithm (Chapter 7). It has used to
optimize for replica exchange MD (REMD) (Kouza and Hansmann, 2011;
Yu et al., 2015) and applied to NEMD (Chapter 8) simulations (Kuang
and Gezelter, 2010 & 2012).
9.2.2.2 Heat-bath coupling
An alternative to simple velocity scaling is to couple the system to an exter￾nal heat-bath corresponding to the desired temperature. The bath acts as
either a heat source or heat sink by providing or removing heat to the sys￾tem. The rate of change of the actual temperature is related to the desired
temperature (the bath temperature) by,
dTA
dt 5 TD 2 TA
τ
ð9:35Þ
where τ is a constant, which determines how tightly the bath and the system
are coupled together. From Eq. (9.35), the change in temperature between
successive time intervals is
ΔT 5 ΔtðTD 2 TAÞ
τ
ð9:36Þ
and the following velocity scaling applies.
vnew
ix 5 vix
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
1 1
Δt
τ

 TD
TA
2 1
s 
vnew
iy 5 viy
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
1 1
Δt
τ

 TD
TA
2 1
s 
vnew
iz 5 viz
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
1 1
Δt
τ

 TD
TA
2 1
s 
9
>>>>>>>>>>=
>>>>>>>>>>;
ð9:37Þ
332 Molecular Simulation of FluidsWhen τ 5 Δt, Eq. (9.37) is identical to the simple velocity scaling
method. This form of scaling is implemented in the same way as illus￾trated in Algorithm 9.7. Typically, Δt/τ 5 0.0025 gives satisfactory
results.
The advantage of Algorithm 9.7 is that it is an intuitively simple
extension of the velocity-scaling microcanonical ensemble. However, it
should be noted that strictly speaking, temperature is not fixed exactly but
instead fluctuates around the desired value. It is legitimate to use a scaling
procedure during the equilibration period to bring the system to the desired
temperature but until this is achieved the system may not have a genuinely
canonical distribution. Issues regarding heat baths have been studied
extensively (Baldovin et al., 2009; Cano and Stuart, 2001; Morishita, 2000
& 2003b).
9.2.2.3 Andersen thermostat
Andersen (1980) proposed an alternative to velocity scaling, which combines
MD with stochastic processes and guarantees a canonical distribution. At
constant temperature, the energy of a system of N particles must fluctuate.
This fluctuation can be introduced by changing the kinetic energy via peri￾odic stochastic collisions. At the outset of the simulation, the temperature (T)
and the frequency (ν) of stochastic collisions are specified. At any time inter￾val (Δt), the probability that a particular particle is involved in a stochastic
collision is νΔt. A suitable value of ν is,
ν 5 νc
N2=3 ð9:38Þ
where νc is the collision frequency.
During the simulation, random numbers can be used to determine which
particles undergo stochastic collision at any small time interval. The simula￾tion proceeds as follows. Initial values of positions and momenta are chosen
and the equations of motion are integrated in the normal way until the time
is reached for the first stochastic collision. The momentum of the particle
chosen for the stochastic collision is chosen randomly from a Boltzmann dis￾tribution at temperature, T. The collision does not effect any of the other par￾ticles and the Hamiltonian equations for the entire particles are integrated
until the next stochastic collision occurs. The process is then repeated. This
strategy is summarized by Algorithm 9.8.
Molecular simulation of ensembles Chapter | 9 333ALGORITHM 9.8 MD in the NVT ensemble using the Andersen
thermostat.
Part 1 Initialization
1.1 Assign number of particles, temperature, volume,  etc.
Assign coordinates (ri) at time (t) = 0.
Assign molecules an initial velocity (vi). 
Assign any other (n
r/t
n
)i values (n > 2).
1.2 Initial force calculations:
Calculate forces (fi) on each atom from all other j atoms.
Calculate acceleration (ai) for each atom.
Part 2 Simulation Process
loop
2.1 Integrate equations of motion: 
2.1.1 Calculate fi on each atom from all other j atoms.
2.1.2 Apply integrator to update ri, ai, vi, (n
r/t
n
)i.
2.2 Andersen thermostat:
2.2.1 if (rand() < t)
i nearest integer  [1,N] //select molecule randomly
vi  random value from a Boltzmann distribution
end if
2.3 If (t > tEquilibration)
Accumulate averages. 
end if
t  t + t
while (t  tMax)
In Algorithm 9.8, the initialization phase (Algorithm 9.8, Part 1) pro￾ceeds as normal except that no velocity scaling occurs. In Part 2, after the
application of the integrator algorithm (Algorithm 9.8, Part 2.1.2), the
Andersen thermostat (Algorithm 9.8, Part 2.2.1) is applied periodically.
The molecule that undergoes the collision is selected randomly after it has
been determined that a collision has occurred (Algorithm 9.8, Part 2.2).
Depending on ν, this may not generate a sufficient number of collisions
during the course of the simulation. If the collision rate is too low, the sys￾tem will not sample from a canonical distribution of energies. An alterna￾tive would be to check for collisions from i equals 1 to N times. If a
collision is found, then the collision is with the ith molecule. This proce￾dure is likely to result in a far greater number of collisions because N is
typically 500 or more. However, it should be noted that if the collision rate
is too high, temperature control dominates and the desired fluctuations in
kinetic energy are suppressed.
The use of random numbers makes the Andersen thermostat a hybrid of
MC and MD. There is evidence to suggest that the use of stochastic
334 Molecular Simulation of Fluidsprocesses may compromise the integrity of the calculation of dynamical
quantities and that the frequency of stochastic collisions must be chosen
carefully (Tanaka et al., 1983). A detailed theoretical discussion of the
Andersen thermostat is available (Weinan and Dong, 2008).
9.2.2.4 Nose´ thermostat
Nose´ (1984) showed that the canonical (NVT) ensemble could be obtained
rigorously by an unaided MD strategy. In Nose´’s approach, the thermal res￾ervoir is an integral part of the system and it is manifested as an additional
degree of freedom (s). The potential energy of the reservoir (res) is,
Ures 5 gkTDln s ð9:39Þ
where g is the number of degrees of freedom of the physical system. The res￾ervoir also has kinetic energy, which can be obtained from,
Kres 5 Q
2
ds
dt 
 2
5 Q
2 p2
s ð9:40Þ
where Q is a parameter which couples the reservoir to the real system and
which affects temperature fluctuations. It has the dimensions of energy 3
time2 but it can be considered usefully as the imaginary mass of the extra
degree of freedom. Typically, Q is proportional to gkTD with the proportion￾ality constant determined by trial simulations to observe whether or not the
desired temperature is maintained satisfactorily. If Q is too large, there is no
energy flow between the reservoir and the system, whereas if Q is too small,
energy oscillations occur inhibiting equilibration.
Each state that can be generated for the extended system corresponds to a
unique state in the real system. The velocities of the atoms in the real system
are given by:
v 5 s
dr
dt 5 p
ms
ð9:41Þ
Consequently, the kinetic energy of the real system is:
Kreal 5 p2
2ms2 ð9:42Þ
Therefore, the Hamiltonian for the extended system is:
H 5 X
i
p2
i
2mis2 1 UðqÞ 1 p2
s
2Q
1 gkTDln s ð9:43Þ
The key feature of Nose´’s approach (Hoover, 1991) is the use of an
extended Hamiltonian (Chapter 2). Any change in the Hamiltonian will be
Molecular simulation of ensembles Chapter | 9 335reflected by changes in the equations of motion. The equations of motion
obtained from Eq. (9.43) are:
q_ 5 p
ms2 ð9:44Þ
p_ 5 FðqÞ ð9:45Þ
s_ 5 ps
Q ð9:46Þ
p_s 5 X
i
p2
i
mis3 2 gkTD
s
ð9:47Þ
9.2.2.5 Nose´Hoover equations
The equations for the Nose´ thermostat contain the inconvenient s variable.
Hoover (1985) demonstrated that Nose´’s equations of motion could be refor￾mulated to remove the s variable. These equations, hereafter referred to as
the Nose´Hoover equations, are:
q_ 5 p
m ð9:48Þ
p_ 5 FðqÞ 2 ζp ð9:49Þ
ζ
:
5
P
i
p2
i
mi 2 gkTD
Q ð9:50Þ
In the Nose´Hoover equations, ζ is a “friction” coefficient that
evolves with time according to Eq. (9.50). The value of ζ is determined
by using Eq. (9.50) as a feedback equation. The overall algorithm for gen￾erating a NVT ensemble using the Nose´Hoover equation is a straightfor￾ward adaptation of Algorithm 9.5. The only difference is that the ζ
parameter must be re-evaluated at each time step. The integration of the
equations of motion can be most simply handled by predictorcorrector
(see discussion below) or RungeKutta (Chapter 7) algorithms. The
appearance of a velocity in the acceleration (Eq. (9.49)) poses problems
for the velocity-Verlet algorithm but this can be overcome (Frenkel and
Smit, 2002). The predictorcorrector calculation strategy is illustrated by
Algorithm 9.9.
In the initialization phase (Algorithm 9.9, Part 1), values are assigned to
the m-derivatives of position with respect to time required by the
predictorcorrector strategy and ζ is initially assigned to zero. During
the simulation process (Algorithm 9.9, Part 2), the equations of motion are
solved using a predictorcorrector calculation (Algorithm 9.9, Part 2.1). The
336 Molecular Simulation of Fluidsforce on each atom is calculated (Algorithm 9.9, Part 2.1.1) and it is used to
predict (Algorithm 9.9, Part 2.1.2) new positions and all of the time deriva￾tives except acceleration. The acceleration (Algorithm 9.9, Part 2.1.3) is pre￾dicted using the latest predicted velocity. The newly predicted positions and
all time derivatives are subsequently refined in the corrector step
(Algorithm 9.9, Part 2.1.4). To update the ζ term (Algorithm 9.9, Part 2.1.5),
it is necessary to determine the sum of the squared velocities. This calcula￾tion is performed conveniently during the corrector step of the integration.
ALGORITHM 9.9 MD in the NVT ensemble using the Nose´Hoover
equations of motion and a predictorcorrector strategy.
Part 1 Initialization
1.1 Assign number of particles, temperature, volume,  etc.
Assign coordinates (ri) at time (t) = 0.
Assign molecules an initial velocity (vi). 
Assign any other (n
r/t
n
)i values (n > 2 ... m).
g 3N //3-D unconstrained system
 0
1.2 Initial force calculations:
Calculate forces (fi) on each atom from all other j atoms.
Calculate acceleration (ai) for each atom.
Part 2 Simulation Process
loop
2.1 Integrate equations of motion using a PC method: 
2.1.1 Calculate fi on each atom from all other j atoms.
2.1.2 Predict new positions and (n
r/t
n
)i (n  2).
2.1.3 ai fi/mi - vi
2.1.4 Correct new positions and (n
r/t
n
)i (n = 1 ... m).
2.1.5   + t(vi
2
/mi - gkTD)/Q
2.2 If (t > tEquilibration)
Accumulate averages. 
end if
t  t + t
while (t  tMax)
It has been observed that the Nose´Hoover equations are not genu￾inely ergodic for either small or stiff systems. To correct this, a modifica￾tion has been proposed (Martyna et al., 1992) that replaces the single
thermostat with a chain of variables. The Nose´Hoover equations using
M thermostats are:
q_ 5 p
m ð9:51Þ
p_ 5 FðqÞ 2 ζ1p ð9:52Þ
Molecular simulation of ensembles Chapter | 9 337ζ1 5
P
i
p2
i
mi 2 gkTD
Q1
2 ζ1ζ2 ð9:53Þ
ζj 5 Qj21ζ2
j21 2 kTD
Qj
2 ζjζj11 ð9:54Þ
ζM 5 QM21ζ2
M21 2 kTD
QM
ð9:55Þ
It is apparent that the definition of ζ is recursive. This natural recursion
can be exploited to simplify the coding in languages such as C11, particu￾larly if M is a large number. Reversible MD algorithms for Nose´Hoover
chains have also been developed (Jang and Voth, 1997).
9.2.2.6 Constraint methods
In general, constant temperature can be achieved by introducing a tempera￾ture constraint into the equations of motion. A constant kinetic temperature
dynamics is generated by the following modified equations of motion
(Hoover et al., 1982; Evans, 1983).
r_ 5 p
m ð9:56Þ
p_ 5 f 2 ζðr; pÞp ð9:57Þ
In Eq. (9.57), ζ(r,p) acts as a “friction coefficient,” which varies to con￾strain the instantaneous temperature to a constant value. The ζ term plays a
similar role to the corresponding term in the Nose´Hoover thermostat
(Eqs. (9.48) and (9.50)). However, by applying Gauss’s principle of least
constraint (Chapter 2), it can be shown (Hoover, 1983; Evans and Morriss,
1984) that:
ζ 5
P
i piUfi
P
i pi

 

2 ð9:58Þ
Equations (9.56) and (9.57) can be most easily solved using a Gear pre￾dictorcorrector algorithm but a variant of the leap-frog scheme can also be
used (Brown and Clarke, 1984). The use of a Gaussian constraint is likely to
lead to a drift in T with time caused by rounding errors. This can be miti￾gated by factors such as the choice of integrator (Chapter 7) or using a linear
proportional feedback mechanism (Travis et al., 1995).
338 Molecular Simulation of Fluids9.2.3 Isobaricisoenthalpic (NpH) ensemble
The isobaricisoenthalpic ensemble is not used commonly in molecular
simulations. However, NpH ensemble algorithms are worthy of consideration
because they introduce techniques for obtaining constant pressure, and they
can be extended easily to generate the more useful NpT ensemble. The NpH
ensemble is particularly useful for calculation of the JouleThomson coeffi￾cient (Kioupis and Maginn, 2002; Travis, 2023). Obtaining thermodynamic
properties from the NpH ensemble is discussed in Chapter 2.
9.2.3.1 Andersen’s algorithm
The general approach used by Andersen (1980) is to introduce additional
degrees of freedom to the physical system. Specifically, the volume is con￾sidered as a dynamical variable that is coupled to particle coordinates.
Newton’s equations of motion are solved for the “extended system” involv￾ing both particle coordinates and volume.
Using scaled coordinates xi 5 ri/V1/3, Andersen (1980) proposed the fol￾lowing Lagrangian at constant pressure, which introduces a new variable, Q.
L 5 Q2=3
2
X
N
i51
mix_Ux_ 2 X
N
j . i
vðQ1=3
xijÞ 1
MQ_2
2 2 αQ ð9:59Þ
The variable Q can be interpreted as the volume, and the first two terms
represent the conventional Lagrangian expressed in terms of new variables.
The third term is the kinetic energy of Q, and the fourth term is the potential
energy associated with Q. The terms α and m are constants. A physical inter￾pretation of the Lagrangian can be gained by considering the system to be a
container of variable volume controlled by a piston. In this context, the vol￾ume Q of the system is determined by the coordinates of the piston, αQ is a
potential derived from an external pressure α acting on the piston, and m is
the mass of the piston. The Hamiltonian for this system is,
H 5 1
2Q2=3
X
N
i51
πiUπi
mi
1 X
N
j . i
vðQ1=3
xijÞ 1
Π2
2M
1 αQ ð9:60Þ
where π and Π are the momenta conjugate to x and Q, respectively. We
define the following relationships between the scaled and unscaled
coordinates.
V 5 Q
r 5 Q1=3x
p 5 π
Q1=3
9
>>=
>>;
ð9:61Þ
Molecular simulation of ensembles Chapter | 9 339Using Eq. (9.59) in conjunction with Eq. (9.61), we obtain the following
equations of motion.
r_ 5 p
m 1
r
3
dlnV
dt ð9:62Þ
p_ 5 FðrijÞ 2 p
3
dlnV
dt ð9:63Þ
Md2V
dt2 5 2 α 1
2
3V
X
N
i51
piUpi
2mi
2 1
3V
X
N
j . i
rij
@uðrijÞ
@rij
ð9:64Þ
By recognizing that α is the desired pressure (pD), and that the actual
pressure (pA) is obtained from,
pA 5 2
3V
X
N
i51
piUpi
2mi
2 1
3V
X
N
j . i
rij
@uðrijÞ
@rij
ð9:65Þ
Equation (9.65) can be expressed simply as:
d2V
dt2 5 pA 2 pD
M ð9:66Þ
The change in volume with time in Eqs. (9.62) and (9.63) is determined
by using Eq. (9.64) as a “feedback” equation. In turn, the volume is adjusted
depending on the value of dV/dt.
It can be shown (Andersen, 1980) that this approach generates an isobar￾icisoenthalpic (NpH) ensemble. The enthalpy of the system is the energy
(E) associated with the scaled system minus the time average kinetic energy
associated with the motion of Q. Parrinello and Rahman (1980, 1981 &
1982) generalized Andersen’s approach to allow for changes in the shape of
the simulation box, which is particularly useful for solid-state calculations.
Alternative approaches (Kioupis and Maginn, 2002; Travis, 2023) are also
possible.
An implementation of the isobaricisoenthalpic ensemble is illus￾trated by Algorithm 9.10. In the initialization phase (Algorithm 9.10, Part
1), the volume derivatives can be set to zero. Their values will be cor￾rected rapidly in the simulation phase (Algorithm 9.10, Part 2). The actual
pressure of the ensemble (pA) is calculated conveniently during the force
evaluation. The integrator (Algorithm 9.10, Part 2.1.3) subsequently
updates the coordinates, velocities, accelerations, and other time deriva￾tives. The first time through the simulation loop, we are effectively apply￾ing Newton’s equations of motion because the volume derivatives in
340 Molecular Simulation of FluidsEqs. (9.62) to (9.64) are zero. However, updating the volume derivatives
(Algorithm 9.10, Part 2.1.4) results subsequently in the application of
Andersen’s equations.
ALGORITHM 9.10 MD in the NpH ensemble using Andersen’s method.
Part 1 Initialization
1.1 Assign M, N, V, v, TD, pD, etc.
Assign coordinates (ri) at time (t) = 0.
Assign molecules an initial velocity (vi). 
Assign any other (n
r/t
n
)i values (n > 2).
dlnV/dt  0
dV/dt  0
d2
V/dt2  0
Vold  V
1.2 Initial force calculations:
Calculate forces (fi) on each atom from all other j atoms.
Calculate acceleration (ai) for each atom.
Part 2 Simulation Process
loop
2.1 Integrate equations of motion: 
2.1.1 Calculate fi on each atom from all other j atoms.
2.1.2 Calculate pA.
2.1.3 Apply integrator to update ri, ai, vi, (n
r/t
n
)i.
2.1.4 dV2
/dt2  dV2
/dt2 + t  (pD - pA)/M
dV/dt  dV/dt + t  (dV2
/dt2
)
V  V + t  (dV/dt)
dlnV/dt  (ln(V) - ln(Vold))/ t
Vold  V 
2.2 If (t > tEquilibration)
Accumulate averages.
end if
t  t + t
while (t  tMax)
9.2.3.2 Constraint methods
Gauss’s principle of least constraint (Chapter 2) can be used to obtain modi￾fied equations of motion that are appropriate at constant pressure and
enthalpy (Evans and Morriss, 1984),
r_ 5 p
m 1 χðr; pÞr ð9:67Þ
p_ 5 f 2 χðr; pÞp ð9:68Þ
V_ 5 3Vχðr; pÞ ð9:69Þ
Molecular simulation of ensembles Chapter | 9 341where χ is a Lagrange multiplier, which represents the rate of dilation of the
system.
χ 5 2
2
P
i
piUfi
mi 2 P
i
P
j . i
ðrijUpijÞ
mirij
dwðrijÞ
drij  
2
P
i
p2
i
mi 1 P
i
P
j . i rij
dwðrijÞ
drij   1 9pV
ð9:70Þ
Long-range corrections (Chapter 5) must be included in the calculation of
both the virial and pressure terms in Eq. (9.70).
9.2.4 Isothermalisobaric (NpT) ensemble
There are three distinct methods for simulating an NpT ensemble by MD,
which involve extending the approach used for NVT ensemble MD. The
first is the hybrid MC and MD approach used by Andersen (1980). The
Andersen thermostat can be modified to include constant pressure result￾ing in an isobaricisoenthalpic (NpH) ensemble, which can be trans￾formed to an NpT ensemble via a stochastic process. Alternatively, either
Hoover’s equations for the NVT ensemble can be modified to incorporate
a pressure constraint or the general constraint procedure can be extended.
The development of MD NpT algorithms remains an active area of inter￾est (Braga and Travis, 2005; Bussi et al., 2009; Huang et al., 2011; Kim
et al., 2019).
9.2.4.1 Hybrid MD/MC
To modify Andersen’s algorithm for the NpH ensemble to generate an algo￾rithm for the NpT ensemble, the energy and enthalpy of the system must be
allowed to fluctuate. Fluctuations can be achieved by the introduction of sto￾chastic collisions that affect the momentum of one particle at a time. The
stochastic collisions are instantaneous events and they occur at a particular
value of Q. The effect of each stochastic collision is to replace the momen￾tum of the affected particle by a new value chosen at random from a distri￾bution given by:
exp 2 πiUπi
2miQ2=3kT 
  ð9:71Þ
The implementation of the NpT ensemble algorithm proceeds in a similar
fashion to the NpH ensemble except that allowance is made for stochastic
collisions that result in a constant temperature. The procedure is illustrated
by Algorithm 9.11.
342 Molecular Simulation of FluidsALGORITHM 9.11 MD in the NpT ensemble using Andersen’s method.
Part 1 Initialization
1.1 Assign M, N, V, v, TD, pD, etc.
Assign coordinates (ri) at time (t) = 0.
Assign molecules an initial velocity (vi). 
Assign any other (n
r/t
n
)i values (n > 2).
dlnV/dt  0
dV/dt  0
d2
V/dt2  0
Vold  V
1.2 Initial force calculations:
Calculate forces (fi) on each atom from all other j atoms.
Calculate acceleration (ai) for each atom.
Part 2 Simulation Process
loop
2.1 Integrate equations of motion: 
2.1.1 Calculate fi on each atom from all other j atoms.
2.1.2 Calculate PA.
2.1.3 Apply integrator to update ri, ai, vi, (n
r/t
n
)i.
2.1.4 Change momenta via stochastic collision:
loop i 1 ... N
if (rand() < t)
pi random value from Boltzmann distribution
end if
end i loop
2.1.5 dV2
/dt2  dV2
/dt2 + t  (pD - pA)/M
dV/dt  dV/dt + t  (dV2
/dt2
)
V  V + t  (dV/dt)
dlnV/dt  (ln(V) - ln(Vold))/ t
Vold  V 
2.2 If (t > tEquilibration)
Accumulate averages.
end if
t  t + t
while (t  tMax)
Algorithm 9.11 is similar to Algorithm 9.10 except for the presence of
stochastic collisions (Algorithm 9.11, Part 2.1.4). After the integrator has
updated the coordinates, velocities, accelerations, and the like, N random
numbers are generated. If rand() , νΔt, a collision is deemed to have taken
place and the momentum of the atom (pi
) is assigned a random value from a
Boltzmann distribution. In the absence of any stochastic collisions
Algorithm 9.11 generates a NpH ensemble.
9.2.4.2 Extension of the Nose´Hoover equations
The equations of motion for the NpT ensemble can be obtained as a straight￾forward extension of the Nose´Hoover equations for the NVT ensemble. In
Molecular simulation of ensembles Chapter | 9 343terms of reduced coordinate (x  q/V1/d
; d is the number of dimensions),
Hoover (1985) defined,
x_ 5 p
mV1=d ð9:72Þ
p_ 5 F 2 ðε_ 1 ζÞp ð9:73Þ
ζ
:
5
P
i
p2
i
mi 2 gkTD
Q ð9:74Þ
ε_ 5 V_
dV ð9:75Þ
ε€ 5 pA 2 pD
τ2kTD
ð9:76Þ
where pA and pD are the actual and desired pressure, respectively, and τ is
the relaxation time. Equations (9.729.75) make use of an additional dilation
rate ε_, which is determined by using Eq. (9.76) as a feedback equation in a
similar way to the calculation of ζ in the NVT ensemble. The definition and
role of Eq. (9.76) is similar to Eq. (9.66) for Andersen’s NpH ensemble
algorithm.
The overall NpT ensemble algorithm proceeds in a similar way to the
NVT ensemble for the Nose´Hoover equations except that both ε_ and ζ
must be calculated for each time step via the feedback equations. The simu￾lation strategy is illustrated by Algorithm 9.12. To update ε_and ζ, both the
sum of the squared velocities and the actual pressure must be calculated. The
actual pressure, calculated from the virial relationship (Eq. (9.65)), can
be obtained conveniently during the force evaluation (Part 2.1.1) and the
squared velocities can be calculated during the corrector step
(Algorithm 9.12, Part 2.1.4). The values of ε_ and ζ are updated after the cor￾rector step (Algorithm 9.12, Part 2.1.5). It should be noted that because the
actual pressure is calculated before the application of either the corrector or
the predictor, its value at Part 2.1.5 effectively lags the simulations by one
step. However, the imprecision this introduces is likely to be very small. If
the intermolecular potential is scalable, an accurate value could be obtained
after the corrector step via a simple scaling procedure. If the intermolecular
potential is not scalable, an accurate value can only be obtained by perform￾ing a computationally expensive N(N  1) re-evaluation.
The Nose´Hoover approach is a topic of active interest, which have
proved particularly useful (Hoover, 2007) in NEMD (Chapter 8) simulations.
Issues addressed include reversibility (Jiang and Voth, 1997; Tchouar et al.,
2007), temperatureenergyspace sampling (Fukuda and Moritsugu, 2020),
relationship to a fluctuating heat-bath (Fukuda and Moritsugu, 2016), multi￾ple thermostat systems (Morishita, 2010; Fukuda, 2016), the removal of time
344 Molecular Simulation of Fluidsscaling (Fukuda and Moritsugu, 2017), muticanonical ensembles (Jang et al.,
2002), and dissipative particle dynamics (Allen and Schmid, 2007).
Traditionally, MD thermostats have controlled the kinetic temperature.
However, the concept of the configurational temperature embodied in
Eq. (9.25) provides an alternative. Braga and Travis (2005) have utilized
Eq. (9.25) to develop a configurational Nose´Hoover thermostat, which has
proved (Travis and Braga, 2006) particularly useful for NEMD. The basic
concept has also been extended (Travis and Braga, 2008; Beckedahl et al.,
2016) to other situations.
ALGORITHM 9.12 MD in the NpT ensemble using the Nose´Hoover
equations of motion and a correctorpredictor strategy.
Part 1 Initialization
1.1 Assign Q, N, TD, pD,  etc.
Assign coordinates (ri) at time (t) = 0. 
Scale coordinates (x = q/V1/d).
Assign molecules an initial velocity (vi). 
Assign any other (n
r/t
n
)i values (n > 2).
g 3N
 0
Dot  0
1.2 Initial force calculations:
Calculate forces (fi) on from all other j atoms.
Calculate acceleration (ai) for each atom.
Part 2 Simulation Process
loop
2.1 Integrate equations of motion using a PC method: 
2.1.1 Calculate fi on each atom from all other j atoms.
Calculate pA.
2.1.2 Predict new positions and (n
r/t
n
)i (n  2).
2.1.3 ai fi/mi - (Dot + )vi
2.1.4 Correct new positions and (n
r/t
n
)i (n = 1 ... m).
2.1.5   + t(vi
2
/mi - gkTD)/Q
Dot  Dot + t(PA - PD)/(
2
kTD)
2.2 If (t > tEquilibration)
Accumulate averages. 
end if
t  t + t
while (t  tMax)
9.2.4.3 Constraint methods
To obtain an NpT ensemble, the following modifications are made to the
constrained NVT ensemble equations of motion (Evans and Morriss, 1984).
r_ 5 p
m 1 χðr; pÞr ð9:77Þ
Molecular simulation of ensembles Chapter | 9 345p_ 5 f 2 χðr; pÞp-ζðr; pÞp ð9:78Þ
V_ 5 3Vχðr; pÞ ð9:79Þ
These equations introduce Lagrange multipliers for both the “rate of dila￾tion” of the system (χ) and “friction” (ζ).
χ 5 2
P
i
P
j . i
ðrijUpijÞ
mirij
dwðrijÞ
drij  
P
i
P
j . i rij
dwðrijÞ
drij   1 9pV
ð9:80Þ
where w is the instantaneous virial and:
ζ 5
P
i piUfi
P
i pi

 

2 2 χ ð9:81Þ
The formulation of alternative NpT ensembles is an active area of
research. Melchionna et al. (1993) have reported that the trajectories of iso￾baric ensembles may have an unphysical dependence on the choice of basis
lattice vectors. To compensate, modifications to the Nose´Hoover equations
have been proposed (Martyna et al., 1994).
9.2.5 Grand canonical (µVT) ensemble
In the grand canonical ensemble, the chemical potential is constant and the
number of particles changes. In contrast to the MC method, which handles
particle variations by straightforward addition or removal, it is considerably
more difficult to apply MD to the grand canonical ensemble. The problem
has been addressed by several workers (Lupkowski and van Swol, 1991;
C¸ agin and Pettitt, 1991a & b; Ji et al., 1992; Lo and Palmer, 1995;
Papadopoulou et al., 1993; Lynch and Pettitt, 1997; Kuznetsova and
Kvamme, 1999; Boinepalli and Attard, 2003; Samways et al., 2020). A fea￾ture of many MD implementations of the grand canonical ensemble is the
use of a stochastic process for particle fluctuation.
9.2.5.1 Lupkowskivan Swol method
The method proposed by Lupkowski and van Swol (1991) is a simple combi￾nation of MD and MC methods. In their approach, a conventional MD NVT
ensemble simulation is interrupted periodically by an attempt to either create
or destroy a particle. A particle is created with a probability of,
P1 5 min 1; exp μ 2 ΔUtrial
kT
1 ln V
Λ3NðN 1 1Þ
 	 
  
  ð9:82Þ
346 Molecular Simulation of Fluidswhereas a particle is removed with a probability of:
P2 5 min 1; exp 2μ 1 ΔUtrial
kT
1 ln NΛ3N
V
 	 
  
  ð9:83Þ
The particle creation and removal steps are conducted according to the
MC grand canonical algorithm (Algorithm 9.3). The velocity of the newly
created particle is obtained from a MaxwellBoltzmann distribution. The
algorithm is relatively simple to implement. However, the particle creation
and removal procedure may affect the velocity autocorrelation functions
required for the calculation of transport properties.
9.2.5.2 C¸ aginPettitt method
C¸ agin and Pettitt (1991a & b) used the concept of “fractional particles” to for￾mulate a MD method for the grand canonical ensemble. The number of particles
in a system is considered to be a function of time. During the simulation, the
system has fractional particles at position rf, which are in the process of either
becoming full particles or vanishing. The Nose´Hoover thermostat for an NVT
ensemble exploits parameters that couple the system to a heat-bath. To couple
the system to a chemical potential reservoir, C¸ agin and Pettitt introduced a real
continuous variable (c), whose integer part represents the number of particles in
the system (N). The kinetic and potential energies of the system are subse￾quently scaled by c  N. Either an adiabatic constant chemical ensemble or the
grand canonical ensemble can be formulated by keeping the chemical potential
constant. The Lagranian for the grand canonical ensemble is:
L 5 1
2
X
N
a51
ms2
x_ 2
a 1 c 2 N
2 mfs
2
x_ 2
f 1
Wc_
2
2
1 Qs_
2
2
2X
N21
a51
X
N
b . a
uðrabÞ 2 ðc 2 NÞ
X
N
a51
uðrfaÞ 1 μc 2 gkTlns
ð9:84Þ
In common with the work of Andersen (1980), Nose´ (1984), and Hoover
(1985) for the NVT and NpT ensembles, Eq. (9.84) is the Lagrangian for the
extended system. The variable x represents the coordinates of the extended
system, s is the parameter that couples the system to a heat-bath, and Q is
the mass associated with s. Equation (9.84) introduces the new variable W,
which can be interpreted as the mass associated with the new dynamical var￾iable c. The equations of motion for this Lagrangian are:
ms2
x€ai 5 2 X
N
b51
@uðrabÞ
@rab 
  xabi
rab
2 ðc 2 NÞ @uðrafÞ
@raf 
  xafi
raf
2 2mss_x€ai ð9:85Þ
Molecular simulation of ensembles Chapter | 9 347ðc 2 NÞms2x€fi 5 2 ðc 2 NÞ
X
N
a51

 @uðrfaÞ
@rfa  xfai
rfa
2 ms2
c_x_fi
2 2ðc 2 NÞmss_x_fi
ð9:86Þ
Wc€ 5 μ 1
ms2x_
2
f
2 2 X
N
a51
uðrfaÞ ð9:87Þ
Qss€ 5 X
a
1
2
ms2
x_
2
a 1
1
2
ðc 2 NÞms2
x_
2
f 2 gkT ð9:88Þ
The method has been applied successfully to determine the density
dependence of the chemical potential of a three-site water model (Ji et al.,
1992). A limitation of (Eqs. 9.859.88) is that they do not reproduce cor￾rectly the behavior of the ideal gas. The algorithm can be modified
(Weerasinghe and Pettitt, 1994) to include the corrected ideal gas behavior.
However, Lo and Palmer (1995) observed that the modified algorithm may
compromise the accuracy of the predicted densitytemperaturechemical
potential behavior for the LJ fluid.
9.2.5.3 LoPalmer method
The method of Lo and Palmer (1995) is of particular interest because it can
be used to reproduce correctly the densitytemperaturechemical potential
behavior of the LJ fluid; it can be extended to the Gibbs ensemble
(Chapter 10), and in the limit, the properties of the ideal gas are described
properly. Following the general approach of Nose´ (1984), Lo and Palmer
(1995) proposed an extended Hamiltonian for the grand canonical ensemble
of the form:
H 5X
N
i51
p2
i
2mis2 1 UðqNÞ 1 p2
f
2mfs2 1 UfðqN; qf ; cÞ 1 p2
s
2Q
1 gkTlns 1 p2
v
2W
1 ckTln½  ðN 1 1Þ!
1 ð1 2 cÞkTln
 VN!
Λ3
f

2 ðN 1 cÞμ
ð9:89Þ
The earlier Hamiltonian distinguishes between the properties of ordinary
particles and “fractional” particles denoted by the subscript f. Therefore,
there is a contribution to kinetic energy and potential energy from both ordi￾nary and fractional particles. The variable c is the coupling coordinate that
couples the fractional particle to the rest of the system. It plays a similar role
to the corresponding parameter in the C¸ aginPettitt algorithm and it can
348 Molecular Simulation of Fluidshave any value between 0 and 1. The constant W is the mass associated with
the variable c and Λf is the de Brogile wavelength of the fractional particle.
The remaining terms have the same meaning as in the Nose´Hamiltonian
(Eq. (9.43)). When c 5 1, the fractional particle is completely coupled to the
rest of the system, whereas a value of c 5 0 indicates that the fractional parti￾cle is totally decoupled from the system. When c 5 1, Eq. (9.89) is formally
identical to Nose´’s Hamiltonian except for the addition of the -Nμ term. In
terms of real variables, the equation of motion resulting from this
Hamiltonian are:
p_ 5 F 1 Ff 2 s_p
s
ð9:90Þ
p_f 5 Ff 2 s_pf
s
ð9:91Þ
s€5 s_
2
s
1
s
Q
X
N
i51
p2
i
mi
1 p2
f
mf
2 gkT ! ð9:92Þ
c€ 5 s_c_
s
1
s2
W 2@Uf
@c 1 kTln V
Λ3
f ðN 1 1Þ
 ! 1 μ
" # ð9:93Þ
Equations (9.92) and (9.93) are feedback equations that enable the calcu￾lation of c and s and their time derivatives at each time step. A possible
implementation is illustrated by Algorithm 9.13.
The algorithm starts with a normal initialization phase (Algorithm 9.13, Part 1).
The first phase of the simulation process (Algorithm 9.13, Part 2) is to create an
equilibrated NVT ensemble (Algorithm 9.13, Part 2.1). This can be achieved by
applying any NVT ensemble algorithm; however, the Nose´Hoover algorithm is
the most obvious choice because in the absence of a constant chemical potential,
the LoPalmer equations reduce to the Nose´Hoover algorithm.
After the NVT ensemble is generated, it is transformed to a μVT ensemble
via a stochastic process (Algorithm 9.13, Part 2.2). A random choice is made to
either create (Algorithm 9.13, Part 2.2.1) or remove a particle (Algorithm 9.13,
Part 2.2.2). Creating a new particle is quite straightforward. In contrast, remov￾ing a particle requires reordering of indices. Alternatively, the deleted particle
can be simply tagged as being deleted and ignored in subsequent force evalua￾tions. If a particle is created (Algorithm 9.13, Part 2.2.1), c is set to zero, the
coordinates of the fractional particle are selected randomly, and a
MaxwellBoltzmann distribution is used to obtain the initial velocity and c_. If a
particle is deleted (Algorithm 9.13, Part 2.2.2), the deleted particle is chosen ran￾domly, c is set to 1, and c_ is obtained from a MaxwellBoltzmann distribution.
The equations of motion are solved repeatedly (Algorithm 9.13, Part 2.3) until c
is either 0 or 1. If c equals 1 (Algorithm 9.13, Part 2.4), the fractional coordi￾nates and velocities are reassigned as ordinary particles.
Molecular simulation of ensembles Chapter | 9 349ALGORITHM 9.13 MD in a μVT ensemble using the LoPalmer algorithm.
Part 1 Initialization
1.1 Assign values of Q, W, N, V, T, etc.
Assign coordinates (ri) at time (t) = 0. 
Scale coordinates (x = q/V1/d).
Assign molecules an initial velocity (vi). 
Assign any other (n
r/t
n
)i values (n > 2).
g 3N
s 0
sDot  0
1.2 Initial force calculations:
Calculate forces (fi) on each atom from all other j atoms.
Calculate acceleration (ai) for each atom.
Part 2 Simulation Process
loop
if (t  tNVTEquilibration)
2.1 Create an equilibrated NVT-ensemble:
Nosé-Hoover algorithm (e.g., Algorithm 9.9).
else
2.2 Transform NVT-ensemble to a VT-ensemble:
if (rand() < 0.5)
2.2.1 Particle addition:
c  0
Create new particle i.
Assign coordinates for new particle i, randomly.
Assign particle i a velocity from a 
Maxwell-Boltzmann distribution.
Assign cDot a value from a Maxwell-Boltzmann distribution.
else
2.2.2 Particle removal:
i  [ 1, N] //select a particle randomly
Delete all reference to particle i.
c 1
Assign cDot from a Maxwell-Boltzmann distribution.
end if
loop
2.3 Integrate equation of motion (eqs (9.91)-(9.94)).
Evaluate c2Dot and s2Dot from eqs (9.93) and (9.94).
sDot  sDot + t  s2Dot
cDot  cDot + t  c2Dot
s  s + t  sDot
c  c + t  cDot
2.4 if (c = 1)
Make fractional particle a real particle.
end if
if (t > tEquilibration)
Accumulate averages.
end if
t  t + t
while (0 > c < 1 )
end if
while (t  tmax)
350 Molecular Simulation of Fluids9.2.5.4 Beutervan Gunsteren method
Beutler and van Gunsteren (1994) developed a grand canonical MD algo￾rithm by weakly coupling the system to a bath of constant chemical poten￾tial. Their chemical potential weak coupling (CPWC) algorithm is based on
the concepts behind the thermostat of Berendsen et al. (1984). The CPWC
algorithm relies on an estimate of the instantaneous chemical potential to
drive the system to the correct number of particles. A mean Boltzmann fac￾tor (MBF) can be obtained by performing Widom test particle insertions.
MBFðNÞ 5 exp 2Utest
kT   
 
N
ð9:94Þ
The MBF is related to the residual chemical potential via the
relationship:
μr 5 2 kTlnðMBFðNÞÞ ð9:95Þ
The correct number of particles is estimated using,
Nðt 1 ΔtÞ 5 NðtÞ 1 round½  αNð Þ MBFðNÞ 2 MBFðNðtÞÞ ð9:96Þ
where αN is a coupling constant and round yields the nearest integer of the
term in square brackets. Application of the CPWC algorithm has three dis￾tinct stages.
Stage 1. Sampling. The value of MBF(N(t)) is determined by performing
nw Widom particle insertions for each of the n1 MD time steps. At the end of
this sampling period, Eq. (9.96) is used to determine the change in the num￾ber of particles.
Stage 2. Growing/shrinking. A total of n2 time steps are involved in this
stage. If particles are added, a MC estimate is used to determine the energeti￾cally most favorable starting points for new particles. The particles are given
an initial velocity of zero and the size of their interactions are scaled pro￾gressively from zero to their full values. If particles are removed, the parti￾cles with the highest potential energy are chosen to be scaled down to zero
interaction in n2 time steps.
Stage 3. Relaxation. The sub-ensemble created following the growing/
shrinking phase is simulated for n3 MD time steps.
9.2.5.5 Parallel algorithm
Vega et al. (1994) reported an algorithm which exploits parallelism. The dis￾tinguishing feature of the parallel grand canonical MD (PGCMD) algorithm
is that several different NVT ensembles are generated with different number
of particles. At each time step, a decision is made to change to an ensemble
with either greater or fewer number of particles. The change in ensemble,
which effectively corresponds to either a particle addition or removal, is
accepted with the following probability
Molecular simulation of ensembles Chapter | 9 351P1 5 min 1; 1
N 1 1
exp μ
kT
1 ln V
Λ3

  
  exp 2Utest
kT   
 
N
 	 ð9:97Þ
P2 5 min 1;
Nexp 2 μ
kT 2 ln V
Λ3
   
exp 2Utest
kT    
N21
2
4
3
5 ð9:98Þ
where P1 represents the probability of moving between an ensemble containing N
particles to an ensemble containing N 1 1 particles whereas P2 is the probability
of moving from an ensemble containing N particles to an ensemble containing
N 1 particles. The implementation of this method is illustrated by Algorithm 9.14.
ALGORITHM 9.14 Parallel grand canonical molecular dynamics (PGCMD)
algorithm.
Part 1 Initialization
1.1 Assign values of N, V, T.
Assign values required for NVT ensemble algorithm.
Assign maximum fluctuation in N (fluctuation).
1.2 Generate several ensembles:
loop i  (N - fluctuation) .... (N + fluctuation)
Assign coordinates (ri) at time (t) = 0 for ensemblei.
Assign molecules initial velocities for ensemblei.
1.2.1 Calculate forces (fi) in ensemblei.
Calculate acceleration (ai) for each atom.
1.2.2 Calculate <exp(-Utest/kT)>i
end i loop
i N
Part 2 Simulation Process
loop
2.1 Solve NVT-ensemble equation of motions for ensemblei.
2.2 Attempt change in ensemble:
if (rand()  0.5)
2.2.1 Attempt to move to an ensemble with more particles:
Apply eq. (9.96).
if (attempt is successful)
i  i + 1
end if
else
2.2.2 Attempt to move to an ensemble with fewer particles:
Apply eq. (9.97).
If (attempt is successful)
i  i - 1
end if
end if
2.3 if (t > tEquilibration)
Accumulate averages.
end if
t  t + t
while (t  tmax)
352 Molecular Simulation of FluidsThe initialization phase (Part 1) of Algorithm 9.14 is considerably more
complicated than the initialization phase of a normal MD simulation. It
involves creating several different ensembles (Algorithm 9.14, Part 1.2) at
the same temperature and volume but with a different number of particles.
For each ensemble, initial coordinates and forces (Algorithm 9.14, Part
1.2.1) must be calculated in addition to the Widom test particle term
(Algorithm 9.14, Part 1.2.2). In Part 2, a particular NVT ensemble is selected
and the particle coordinates are evolved (Algorithm 9.14, Part 2.1) until a
successful attempt is made to change the ensemble (Algorithm 9.14, Part
2.2). The attempt to change to an ensemble with more or fewer particles is
made with equal probability. Equation (9.97) is used to determine the suc￾cess of a move to an ensemble with more particles (Algorithm 9.14, Part
2.2.1), otherwise Eq. (9.98) is used (Algorithm 9.14, Part 2.2.2). The new
NVT ensemble is in turn evolved until a new ensemble is selected.
Consequently, at any time step, only one ensemble is evolving and the other
ensembles remain dormant. Ensemble averages are accumulated from the
current ensemble in the usual way (Algorithm 9.14, Part 2.3). Any NVT
ensemble algorithm can be used to evolve the ensemble.
It is apparent that implementing the PGCMD algorithm in conventional
procedural languages is awkward, requiring a considerable amount of book￾keeping to keep track of the properties of the various ensembles. In contrast,
we note that implementation of PGCMD in an object-oriented language is
simply involves using different objects of type ensemble (Chapter 11).
9.3 Summary
The choice of ensemble governs the nature of the simulation algorithm. The
natural choice for MC simulations is the canonical ensemble but it is rela￾tively simple to construct MC algorithms for other ensembles. In contrast,
the equations of motion lead naturally to a microcanonical ensemble and
MD simulation in other ensembles involves altering the equations of
motions. The MD implementation of the grand canonical ensemble invari￾ably involves the introduction of stochastic elements. An implementation of
both MC and MD simulation in the microcanonical ensemble is given in
Chapter 11.
References
Abramowitz, A., Stegun, I.A., 1970. Handbook of Mathematical Functions. Dover, New York.
Adams, D.J., 1974. Chemical potential of hard-sphere fluids by Monte Carlo methods. Mol.
Phys. 28, 12411252.
Allen, M.P., Schmid, F., 2007. A thermostat for molecular dynamics of complex fluids. Mol.
Sim. 33, 2126.
Allen, M.P., Tildesley, D.J., 2017. Computer Simulation of Liquids, second ed. Oxford
University Press, Oxford.
Molecular simulation of ensembles Chapter | 9 353Andersen, H.C., 1980. Molecular dynamics at constant pressure and/or temperature. J. Chem.
Phys. 72, 23842393.
Baldovin, F., Chavanis, P.-H., Orlandini, E., 2009. Microcanonical quasistationarity of long￾range interacting systems in contact with a heat bath. Phys. Rev. E 79, 011102.
Beckedahl, D., Obaga, E.O., Uken, D.A., Sergi, A., Ferrario, M., 2016. On the configurational
temperature Nose´-Hoover thermostat. Phyica A 461, 1935.
Berendsen, H.J.C., Postma, J.P.M., van Gunsteren, W.F., DiNola, A., Haak, J.R., 1984.
Molecular dynamics with coupling to an external bath. J. Chem. Phys. 81, 36843690.
Beutler, T.C., van Gunsteren, W.F., 1994. Molecular dynamics simulations with first order cou￾pling to a bath of constant chemical potential. Mol. Sim. 14, 2134.
Boinepalli, S., Attard, P., 2003. Grand canonical molecular dynamics. J. Chem. Phys. 119,
1276912775.
Bosko, J., Todd, B.D., Sadus, R.J., 2005. Molecular simulation of dendrimers and their mixtures
under shear: Comparison of isothermal-isobaric (NpT) and isothermal-isochoric (NVT)
ensemble systems. J. Chem. Phys. 123, 034905.
Braga, C., Travis, K.P., 2005. A configurational temperature Nose´-Hoover thermostat. J. Chem.
Phys. 123, 134101.
Brennan, J.K., Madden, W.G., 1998. Efficient volume changes in constant-pressure Monte Carlo
simulations. Mol. Sim. 20, 139157.
Brown, D., Clarke, J.H.R., 1984. A comparison of constant energy, constant temperature, and
constant pressure ensembles in molecular dynamics simulations of atomic liquids. Mol.
Phys. 51, 12431252.
Bussi, G., Zykova-Timan, T., Parrinello, M., 2009. Isothemal-isobaric molecular dynamics using
stochastic velocity rescaling. J. Chem. Phys. 130, 074101.
Butler, B.D., Atyon, G., Jepps, O.G., Evans, D.J., 1998. Configurational temperature verification
of Monte Carlo simulations. J. Chem. Phys. 109, 65196522.
C¸ agin, T., Pettitt, B.M., 1991a. Grand molecular dynamics: a method for open systems. Mol.
Sim. 6, 526.
C¸ agin, T., Pettitt, B.M., 1991b. Molecular dynamics with a variable number of molecules. Mol.
Sim. 72, 169175.
Cano, B., Stuart, A.M., 2001. Underresolved simulations of heat baths. J. Comput. Phys. 169,
193214.
Creutz, M., 1983. Microcanonical Monte Carlo simulation. Phys. Rev. Lett. 50, 14111414.
Dubbeldam, D., Torres-Knoop, A., Walton, K.S., 2013. Monte Carlo codes, tools and algorithms:
on the inner workings of Monte Carlo codes. Mol. Sim. 39, 12531292.
Evans, D.J., 1983. Computer “experiment” for nonlinear thermodynamics of Couette flow.
J. Chem. Phys. 78, 32973302.
Evans, D.J., Morriss, G.P., 1984. Non-Newtonian molecular dynamics. Comp. Phys. Rep. 1,
297344.
Frenkel, D., Smit, B., 2023. Understanding, Molecular Simulation. From Algorithms to
Applications, third ed. Academic Press, San Diego.
Fukuda, I., 2016. Coupled Nose´-Hoover lattice: a set of the Nose´-Hoover equations with differ￾ent temperatures. Phys. Lett. A 380, 24652474.
Fukuda, I., Moritsugu, K., 2016. Coupled Nose´-Hoover equations of motion to implement a fluc￾tuating heat-bath temperature. Phys. Rev. E 93, 033306.
Fukuda, I., Moritsugu, K., 2017. Coupled Nose´-Hoover equations of motion without time scal￾ing. J. Phys. A: Math. Theor. 50, 015002.
354 Molecular Simulation of FluidsFukuda, I., Moritsugu, K., 2020. Temperature-energy-space sampling molecular dynamics: deter￾ministic and single-replica method utilizing continuous temperature system. J. Phys. A:
Math. Theor. 53, 375004.
Hansen, J.-P., McDonald, I.R., 2013. Theory of Simple Liquids, fourth ed. Academic Press,
Amsterdam.
Heermann, D.W., 1990. Computer Simulation Methods in Theoretical Physics, second ed.
Springer-Verlag, Heidelberg.
Heyes, D.M., 1998. The Liquid State: Applications of Molecular Simulations. John Wiley &
Sons, Chichester.
Hoover, W.G., 1983. Nonequilibrium molecular dynamics. Ann. Rev. Phys. Chem. 34,
103127.
Hoover, W.G., 1985. Canonical dynamics: equilibrium phase-space distribution. Phys. Rev. A.
31, 16951697.
Hoover, W.G., 2007. Nose´-Hoover nonequilibrium dynamics and statistical mechanics. Mol.
Sim. 33, 1319.
Hoover, W.G., 1991. Computational Statistical Mechanics. Elsevier, Amsterdam.
Hoover, W.G., Ladd, A.J.C., Moran, B., 1982. High strain rate plastic flow studied via nonequi￾librium molecular dynamics. Phys. Rev. Lett. 48, 18181820.
Hu, J., Ma, A., Dinner, A.R., 2005. Monte Carlo simulations of biomolecules: the MC module in
CHARMM. J. Comput. Chem. 27, 203216.
Huang, C., Li, C., Choi, P.Y.K., Nandakumar, K., Kostiuk, L.W., 2011. A novel method for
molecular dynamics simulation in the isothermal-isobaric ensemble. Mol. Phys. 109,
191202.
Hu¨neneberger, P.H., 2005. Thermostat algorithms for molecular dynamics simulations. Adv.
Polym. Sci. 173, 105149.
Jang, S., Voth, G., 1997. Simple reversible molecular dynamics algorithms for Nose´-Hoover
chain dynamics. J. Chem. Phys. 107, 95149526.
Jang, S., Pak, Y., Shin, S., 2002. Multicanonical ensemble with Nose´-Hoover molecular dynam￾ics simulation. J. Chem. Phys. 116, 47824786.
Ji, J., C¸ agin, T., Pettitt, B.M., 1992. Dynamic simulations of water at constant chemical poten￾tial. J. Chem. Phys. 96, 13331342.
Jiang, S., Voth, G.A., 1997. Simple reversible molecular dynamics algorithms for Nose´-Hoover
chain dynamics. J. Chem. Phys. 107, 95149526.
Kim, M., Kim, E., Lee, S., Kim, J.S., Lee, S., 2019. J. Phys. Chem. A 123, 16891699.
Kioupis, L.I., Maginn, E.J., 2002. Pressure-enthalphy driven molecular dynamics for thermody￾namic property calculation. I. Methodology. Fluid Phase Equilib. 200, 7592.
Kouza, M., Hansmann, U.H.E., 2011. Velocity scaling for optimizing replica exchange molecu￾lar dynamics. J. Chem. Phys. 134, 044124.
Kuang, S., Gezelter, J.D., 2010. A gentler approach to RNEMD: nonisotropic velocity scaling
for computing thermal conductivity and shear viscosity. J. Chem. Phys. 133, 164101.
Kuang, S., Gezelter, J.D., 2012. Velocity shearing and scaling RNEMD: a minimally perturbing
method for simulating temperature and momentum gradients. Mol. Phys. 110, 691701.
Kutteh, R., 1999a. New approaches for molecular dynamics simulations with nonholonomic con￾straints. Comp. Phys. Commun. 119, 159168.
Kutteh, R., 1999b. New methods for incorporating nonholonomic constraints into molecular
dynamics simulations. J. Chem. Phys. 111, 13941406.
Kuznetsova, T., Kvamme, B., 1999. Grand canonical molecular dynamics for TIP4P water sys￾tems. Mol. Phys. 97, 423431.
Molecular simulation of ensembles Chapter | 9 355Lo, C., Palmer, B., 1995. Alternative Hamiltonian for molecular dynamics simulations in the
grand canonical ensemble. J. Chem. Phys. 102, 925931.
Lupkowski, M., van Swol, F., 1991. Ultrathin films under shear. J. Chem. Phys. 95, 19951998.
Lustig, R., 1994. Statistical thermodynamics in the classical molecular dynamics ensemble. II.
Application to computer simulation. J. Chem. Phys. 100, 30603067.
Lustig, R., 1998. Microcanonical Monte Carlo simulation of thermodynamic properties. J. Chem.
Phys. 109, 88168828.
Lustig, R., 2011. Direct molecular NVT simulation of the isobaric heat capacity, speed of sound
and Joule-Thomson coefficient. Mol. Sim. 37, 457465.
Lynch, G.C., Petititt, B.M., 1997. Grand canonical ensemble molecular dynamics simulations:
Reformation of extended system dynamics approaches. J. Chem. Phys. 107, 85948610.
Martyna, G.J., Klein, M.L., Tuckerman, M., 1992. Nose´-Hoover chains: The canonical ensemble
via continuous dynamics. J. Chem. Phys. 97, 26352643.
Martyna, G.J., Tobias, D.J., Klein, M.L., 1994. Constant pressure molecular dynamics algo￾rithms. J. Chem. Phys. 101, 41774189.
McDonald, I.R., 1972. NpT-ensemble Monte Carlo calculations for binary liquid mixtures. Mol.
Phys. 23, 4158.
McGrath, M.J., Siepmann, J.I., Kuo, I.-F.W., Mundy, C.J., VandeVondele, J., Hutter, J.,
Mohamed, F., Krack, M., 2005. Isobaric-isothermal Monte Carlo simulations from first prin￾ciples: application to liquid water at ambient conditions. ChemPhysChem 6, 18941901.
Melchionna, S., Ciccotti, G., Holian, B.L., 1993. Hoover NPT dynamics for systems varying in
shape and size. Mol. Phys. 78, 533544.
Metropolis, N., Rosenbluth, A.W., Rosenbluth, M.N., Teller, A.H., Teller, E., 1953. Equation of
state calculations by fast computing machines. J. Chem. Phys. 21, 10871092.
Morishita, T., 2000. Fluctuation formulas in molecular-dynamics simulations with weak coupling
heat bath. J. Chem. Phys. 113, 29762982.
Morishita, T., 2003a. Modified velocity scaling for molecular dynamics at constant temperature
and/or pressure. Mol. Sim. 29, 6369.
Morishita, T., 2003b. Generalized coupling to a heath bath: extension of the Gaussian isokinetic
dynamics and effect of time scaling. J. Phys. Chem. 119, 70757082.
Morishita, T., 2010. From Nose´-Hoover chain to Nose´-Hoover network: design on non￾Hamiltonian equations of motion for molecular dynamics with multiple thermostats. Mol.
Phys. 108, 11371347.
Nicholson, D., Parsonage, N.G., 1982. Computer Simulation and the Statistical Mechanics of
Adsorption. Academic Press, New York.
Nitzke, I., Vrabec, J. 2023. Numerical discrimination of thermodynamic Monte Carlo simula￾tions in all eight statistical ensembles. J. Chem. Theory Comput. 19, 34603468.
Nose´, S., 1984. A unified formulation of the constant temperature molecular dynamics methods.
J. Chem. Phys. 81, 511519.
Okumura, H., Okamoto, Y., 2004a. Molecular Carlo simulations in the multibaricmultithermal
ensemble. Chem. Phys. Lett. 383, 391396.
Okumura, H., Okamoto, Y., 2004b. Monte Carlo simulations in generalized isobaric-isothermal
ensembles. Phys. Rev. E 70, 026702.
Orkoulas, G., 2007. Acceleration of Monte Carlo simulations through spatial updated in the
grand canonical ensemble. J. Chem. Phys. 127, 084106.
Page, A.J., Isomoto, T., Knaup, J.M., Irle, S., Morokuma, K., 2012. Effects of molecular dynamics ther￾mostats on descriptions of chemical nonequilibrium. J. Chem. Theory Comput. 8, 40194028.
356 Molecular Simulation of FluidsPalma, G., Riveros, A., 2021. General method to sample systems in the microcanonical ensemble
using Monte Carlo simulations. Eur. Phys. J. B 94, 23.
Papadopoulou, A., Becker, E.D., Lupkoski, M., van Swol, F., 1993. Molecular dynamics and
Monte Carlo simulations in the grand canonical ensemble: Local versus global control.
J. Chem. Phys. 98, 48974908.
Parrinello, M., Rahman, A., 1980. Crystal structure and pair potentials: a molecular dynamics
study. Phys. Rev. Lett. 45, 11961199.
Parrinello, M., Rahman, A., 1981. Polymorphic transitions in single crystals: a new molecular
dynamics method. J. Appl. Phys. 52, 71827190.
Parrinello, M., Rahman, A., 1982. Strain fluctuations and elastic constants. J. Chem. Phys. 76,
26622666.
Pearson, E.M., Halicioglu, T., Tiller, W.A., 1985. Laplace-transform technique for deriving thermody￾namic equations from the classical microcanonical ensemble. Phys. Rev. A 32, 30303039.
Rapaport, D.C., 2004. The Art of Molecular Dynamics Simulation, second ed. Cambridge
University Press, Cambridge.
Ray, J.R., 1991. Microcanonical ensemble Monte Carlo method. Phys. Rev. A. 44, 40614064.
Samways, M.L., Bruce Macdonald, H.E., Essez, J.W., 2020. Grand: A python module for grand
canonical water sampling in OpenMM. J. Chem. Info. Model. 60, 44364441.
Sastre, F., Benavides, A.L., Torres-Areanas, J., Gil-Villegas, A., 2015. Microcanonical ensemble
simulation method applied to discrete potential fluids. Phys. Rev. E 92, 033303.
Sastre, F., Moreno-Hilario, E., Sotelo-Serna, M.G., Gil-Villegas, A., 2018. Microcanonical￾ensemble computer simulation of the high-temperature expansion coefficients of the
Helmholtz free energy of a square-well fluid. Mol. Phys. 116, 351360.
Schierz, P., Zierenberg, J., Janke, W., 2015. Molecular dynamics and Monte Carlo simulations
in the microcanonical ensemble: quantitative comparison and reweighting techniques.
J. Chem. Phys. 143, 134114.
Shi, W., Maginn, E.J., 2007. Continuous fractional component Monte Carlo: An adaptive biasing
method for open atomistic simulations. J. Chem. Theory Comput. 3, 14511463.
Shida, C.S., Henriques, V.B., de Oliveira, M., 2003. Microcanonical Monte Carlo simulation of
lattice gas models. Phys. Rev. E 68, 066125.
Sobol’, I.M., 1994. A Primer for the Monte Carlo Method. CRC Press, Boca Raton.
Stro¨ker, P., Meier, K., 2022. Rigorous expressions for thermodynamic properties in the NpH
ensemble. Phys. Rev. E 105, 035301.
Stro¨ker, P., Hellmann, R., Meier, K., 2021. Systematic formulation of thermodynamic properties
in the NpT ensemble. Phys. Rev. E 103, 023305.
Stutzman, L.B., Escobedo, F.A., Tester, J.W., 2018. Heat capacities of supercritical fluids via
grand canonical ensemble simulations. Mol. Sim. 44, 147155.
Tanaka, H., Nakanishi, K., Watanabe, N., 1983. Constant temperature molecular dynamics calcu￾lation on Lennard-Jones fluid and its application to water. J. Chem. Phys. 78, 26262634.
Tchouar, N., Benyettou, M., Baghli, H., 2007. A reversible algorithm for Nose´ molecular
dynamics simulations. Equilibrium properties of liquids methane. J. Mol. Liq. 136, 510.
Travis, K.P. (2023), in preparation.
Travis, K.P., Braga, C., 2006. Configurational temperature and pressure molecular dynamics:
review of current methodology and applications to the shear flow of a simple fluid. Mol.
Phys. 104, 2224.
Travis, K.P., Braga, C., 2008. Configurational temperature control for atomic and molecular sys￾tems. J. Chem. Phys. 128, 014111.
Molecular simulation of ensembles Chapter | 9 357Travis, K.P., Daivis, P.J., Evans, D.J., 1995. Computer simulation algorithms for molecules
undergoing planar Couette flow: a nonequilibrium molecular dynamics study. J. Chem.
Phys. 103, 11091118.
Turesson, M., Woodward, C.E., A˚ kesson, T., Forsman, 2008. Simulating equilibrium surface
forces in polymer solutions using a canonical grid method. J. Phys. Chem. B 112,
98029809.
Valleau, J.P., Cohen, L.K., 1980. Primitive model electrolytes. I. Grand canonical Monte Carlo
computations. J. Chem. Phys. 72, 59355941.
Vega, L.F., Shing, K.S., Rull, L.F., 1994. A new algorithm for molecular dynamics simulations
in the grand canonical ensemble. Mol. Phys. 82, 439453.
Vlasiuk, M., Frascoli, F., Sadus, R.J., 2016. Molecular simulation of the thermodynamic, struc￾tural and vapor-liquid equilibrium properties of neon. J. Chem. Phys. 145, 104501.
Weerasinghe, S., Pettitt, B.M., 1994. Ideal chemical potential contribution in molecular dynam￾ics simulations of the grand canonical ensemble. Mol. Phys. 82, 897911.
Weinan, E., Dong, E., 2008. The Andersen thermostat in molecular dynamics. Commun. Pure
Appl. Math. 61, 96136.
Yu, Y., Wang, J., Shao, Q., Shi, J., Zhu, W., 2015. Increasing the sampling efficiency of protein
conformational transition using velocity-scaling optimized hybrid explicit/implicit solvent
REMD simulation. J. Chem. Phys. 142, 125105.
Zhou, Y., Huai, X., Lin, L., 2010. Molecular dynamics simulation for homogeneous nucleation
of water and liquid nitrogen in explosive boiling. Appl. Therm. Eng. 30, 859863.
358 Molecular Simulation of FluidsChapter 10
Molecular simulation of phase
equilibria
Molecular simulation is performed most commonly for a single isolated system
characterized by certain physical properties that define the nature of the ensemble
(Chapter 2). In effect, these simulations represent the properties of the fluid for a
single isolated phase. However, the techniques of molecular simulation can be
extended to multiple phases, providing a powerful tool for the investigation of the
phase coexistence of both pure fluids and fluid mixtures. Historically, the applica￾tion of molecular simulation to phase equilibria has lagged applications to other
areas. This can be attributed partly to the difficulty in obtaining free energy or
chemical potential data required for phase coexistence. Phase transitions for elastic
disks were first reported by Alder and Wainwright (1962), and Hoover and Ree
(1967) located a melting transition via molecular simulation. Hansen and Verlet
(1969) reported simulations of vaporliquid equilibria (VLE) for a Lennard-Jones
(LJ) fluid (Chapter 3). Later, Adams (1976, 1979) reported extensive Monte Carlo
(MC) (Chapter 6) calculations for the vapor line of a LJ fluid. The advent of the
Gibbs ensemble (Panagiotopoulos, 1987) has been the impetus for a massive
increase in the number, range, and scope of phase equilibria simulations.
Conceptually, the most straightforward method for simulating coexisting
phases is to divide the simulation box into distinct regions. For example, VLE
can be simulated in a box containing three distinct regions that correspond the liq￾uid phase, vapor phase, and an interfacial region, respectively. The simulation is
initiated by introducing a slab of previously equilibrated liquid into the center of
the simulation box with a vacuum on either side. If the density of the liquid is
close to coexisting density, the liquid will evaporate into the vacuum to form a
stable two-phase system. This approach is particularly useful for interfacial studies
(Rowlinson and Widom, 1982). A disadvantage of this approach is that the den￾sity must be known in advance. However, Chapela et al. (1987) have reported a
variation of the traditional approach, which overcomes this difficulty.
The two-phase method is conceptually appealing because it corresponds
directly with experimental observation. However, the disadvantages of the method
are numerous. The simulations are slow because a large number of molecules are
required and the equilibration of the interfacial region is a slow process. It is diffi￾cult to simulate stable phase equilibria between phases of similar densities.
359 Molecular Simulation of Fluids. DOI: https://doi.org/10.1016/B978-0-323-85398-9.00013-7
© 2024 Elsevier B.V. All rights reserved.Furthermore, the confinement of the fluid between parallel walls can potentially
influence both the density and pressure of the coexisting phases resulting in a sim￾ulation of the properties of confined fluids rather than a bulk fluid.
The limitations of the traditional two-phase method are overcome by
using the Gibbs ensemble (Panagiotopoulos, 1987, 1992a). The Gibbs
ensemble method is characterized by two homogeneous phases that are in
thermodynamic equilibrium but not in physical contact. Unlike the two￾phase method, there is no interface thus resulting in much shorter run times.
The Gibbs ensemble was formulated originally as a MC method, however,
a few molecular dynamics (MD) (Chapter 9) implementations of the Gibbs
ensemble have been proposed (Palmer and Lo, 1994; Vega et al., 1994;
Kotelyanskii and Hentschke, 1995; Baranyai and Cummings, 1996).
Indirect methods provide an alternative to direct methods of simulating
phase equilibria. Indirect methods work by calculating the chemical potential
for a series of state points. Phase coexistence can be determined by finding
points in the state space where two phases have the same chemical potential,
pressure, and temperature. Conventional molecular simulations do not pro￾vide information on thermal properties such as free energies but instead yield
mechanical properties such as the energy and pressure. Consequently, special
techniques are required such as test particle methods, umbrella sampling,
grand canonical and semigrand ensembles, and thermodynamic integration.
Comprehensive reviews of these methods are available elsewhere (Gubbins
et al., 1983; Gubbins, 1989, 1994; Frenkel, 1986). Generally, indirect meth￾ods are less efficient computationally than direct methods.
It should be noted that progress in the simulation of phase equilibria is being
made continually (Kofke, 1993a; de Pablo et al., 1999; Bruce and Wilding,
2003; Panagiotopoulos, 2000). For example, efficient histogram reweighting
algorithms have been reported (Kiyohara et al., 1997, 1998), which can in turn
be used in conjunction with transition-matrix MC (Shen and Errington, 2005;
Singh, 2018). The focus has been mainly on VLE, however, improved algo￾rithms for solidliquid equilibria (SLE) have also been reported (Ge et al.,
2003; Singh et al., 2021; Deiters and Sadus, 2022a,b). We will largely restrict
our attention to advances made post-1985. Comprehensive reviews of earlier
work are available elsewhere (Rowlinson and Widom, 1982; Gubbins et al.,
1983; Frenkel, 1986; Gubbins, 1989, 1994; Frenkel and Smit, 2023).
10.1 Calculating the chemical potential
The criteria for phase equilibria requires the equivalence of temperature
(thermal equilibrium), pressure (mechanical equilibrium), and chemical
potential (material equilibrium) for every particle in the coexisting phases.
Consequently, the chemical potential is a very important quantity, particu￾larly for indirect methods that rely on an accurate determination of the chem￾ical potential. In other methods such as the Gibbs ensemble, which does not
360 Molecular Simulation of Fluidsrely on knowledge of the chemical potential, calculating the chemical poten￾tial can serve as independent verification that equilibrium has been attained.
The most common approach for calculating the chemical potential is the
Widom test particle method (Widom, 1963). The method involves inserting a
“ghost” particle (i) randomly into the ensemble and calculating the energy of its
interaction (Ui,test) with the particles of the ensemble. For a canonical ensemble,
the residual chemical potential (i.e., the chemical potential minus the contribution
from the ideal gas) is obtained subsequently from the following ensemble average:
μir 5 2 kTln expð2βUitestÞ  
N ð10:1Þ
It should be stressed that because the test particle is a “ghost,” it does not affect
the properties of the N real molecules of the ensemble. Eq. (10.1) can be applied
to every type of molecule and it is completely independent of any assumption con￾cerning pairwise additivity or the nature of intermolecular forces. Eq. (10.1) can be
incorporated easily into a conventional molecular simulation. In principle, it can
be used to calculate the chemical potential at any density, however, in practice
some difficulties are encountered at high density. At high density, attractive config￾urations make the dominant contribution to Eq. (10.1) but they are sampled less
frequently as the density is increased because of the exp(βUitest) term.
Strictly, Eq. (10.1) is only valid for the canonical ensemble. In the NpT
ensemble, density variations mean that Eq. (10.1) should be replaced with:
μir 5 2 kTln
Vexpð2 βUitestÞ  
h i V
 	 ð10:2Þ
Generally, either Eqs. (10.1) or (10.2) yield similar results. However,
there are significant differences near the critical region.
For the Gibbs ensemble, the correct theoretical value of the chemical
potential can be calculated from (Smit and Frenkel, 1989):
μir 5 2 kTln V
N 1 1
expð2 βUitestÞ
  ð10:3Þ
In practice, the values obtained from Eq. (10.3) only vary significantly
from the results of Eq. (10.1) in the region of the critical point.
As noted earlier, the simple test particle method fails at high densities. Several
strategies have been proposed to improve the calculation of the chemical potential.
One possibility is to use umbrella sampling (Torrie and Valleau, 1974). The prin￾ciple behind umbrella sampling is to assign a weight (w) to the configurational
energy (U). The weighting function is chosen to sample regions of E that are
important to the chemical potential. For example, in a MC simulation, configura￾tions are chosen with a probability of w(Utest)exp(βU) instead of exp(βU).
Consequently, the ensemble average in Eq. (10.1) is obtained from:
expðβUitestÞ   5 expð2 βUitestÞ=w  
1=w   ð10:4Þ
Molecular simulation of phase equilibria Chapter | 10 361This procedure works well for LJ fluids (Torrie and Valleau, 1977) at high liq￾uid densities. However, the limitations of the procedure are that appropriate
weights can only be obtained by trial and error and, unlike the test particle method,
it requires considerable modification to the conventional MC simulation algorithm.
An alternative to “ghost” particle insertions is to use real molecules to evalu￾ate the chemical potential. When real molecules are used as test particles, the
equation for the chemical potential becomes (Shing and Gubbins, 1982).
μir 5 kTln expð2βUitestÞ  
N11 ð10:5Þ
This equation can be rewritten (Shing and Gubbins, 1982) as,
μir 5 kTln
Nð
2N
gðUitestÞexpð2 βUitestÞdUitest ð10:6Þ
where g(Uitest)dUitest is the probability that Uitest for a real test molecule lies
in the range Uitest to Uitest 1 dUitest. For a given Uitest, the distribution func￾tions f and g are related by:
gðUitestÞ 5 expðβμirÞ expð2 βUitestÞfðUitestÞ ð10:7Þ
The averages in Eqs. (10.5) and (10.6) are dominated by repulsive config￾urations that are likely to be positive even at moderate densities. Therefore,
it should be noted that special sampling techniques are required (Shing and
Gubbins, 1982; Kumar, 1992) to take advantage of these equations.
The calculation of the chemical potential is an area of continuing research
interest. Rowley et al. (1994, 1995) proposed an osmotic MD method for calculat￾ing the chemical potential. Their method involves establishing an osmotic equilib￾rium across a semipermeable membrane. The chemical potential is calculated
using the mechanical properties of the fluid on either side of the membrane.
Swope and Andersen (1995) reported calculations of the chemical potential in a
“bicanonical ensemble.” The bicanonical ensemble is characterized by a tempera￾ture and a volume in which all systems have either N or N1 particles. The chem￾ical potential is related to the fraction of the systems that have N particles. Sokhan
(1997) developed a coupled test particle approach for determining the chemical
potential at high liquid densities. Soto-Campos et al. (1998) have discussed the cal￾culation of chemical potentials using a small system grand ensemble method.
10.2 Gibbs ensemble Monte Carlo
In principle, because the grand canonical ensemble allows chemical potential to
be specified, it can be used to determine phase coexistence. However, the grand
canonical ensemble is not a practical method for calculating phase coexistence
because a large number of simulations are required to determine the phase enve￾lope, and the computational cost increases dramatically for two or more
362 Molecular Simulation of Fluidscomponents. The chemical potential can also be calculated by using Widom’s test
particle approach in conjunction with a NVT ensemble simulation. The most con￾venient and widely used method for calculating phase coexistence is to use the
Gibbs ensemble (Panagiotopoulos, 1987; Panagiotopoulos et al., 1988).
Panagiotopoulos (1987) proposed that phase coexistence could be simulated
by following the evolution in phase space of a system composed of two distinct
regions. Equilibrium between the different region or phases is achieved by per￾forming three distinct MC moves as illustrated by Fig. 10.1. Molecular displace￾ments are attempted to obtain internal equilibrium resulting in equivalence of
temperatures. Mechanical equilibrium requires that the pressure in the two
regions are identical and this is obtained by allowing fluctuations in volume.
Attempts are made to exchange particles between the regions to obtain material
equilibrium. The acceptance of the three moves are governed by the normal
acceptance criterion for MC moves involving the “pseudo-Boltzmann term” (min
[1, exp(βΔY)]) discussed in Chapter 6. In the case of molecular displacement,
ΔYdisp 5 ΔUα 1 ΔUβ ð10:8Þ
(A) Attempt molecular displacement
Box 2: N2, V2, T 
(B) Attempt volume fluctuation
(C) Attempt molecular transfer 
Box 1: N1, V1, T
Box 1: N1, V1+ ∆V, T 
Box 1: N1+ 1, V1, T 
Box 2: N2, V2 - ∆V, T 
Box 2: N2 - 1, V2, T 
FIGURE 10.1 Illustration of MC moves used in the Gibbs ensemble.
Molecular simulation of phase equilibria Chapter | 10 363where the subscripts α and β denote the two different regions or simulation
boxes. For volume changes, we have:
ΔYvolume 5 ΔUα 1 ΔUβ
2 NαkTln Vα 1 ΔVα
Vα
2 NβkTln Vβ 1 ΔVβ
Vβ
1 pðΔVα 1 ΔVβÞ
ð10:9Þ
In the Gibbs ensemble, the total number of particles is conserved.
Consequently, a successful particle transfer from box β to box α implies a
particle destruction in box β. For particle transfers, we obtain:
ΔYtrans 5 ΔUα 1 ΔUβ 1 kTln VβðNα 1 1Þ
VαNβ
ð10:10Þ
A general scheme for a Gibbs ensemble MC (GEMC) calculation is illus￾trated by Algorithm 10.1. A feature of Algorithm 10.1 is that the sequence
of moves is determined randomly instead of being predetermined. It is possi￾ble to use a predetermined sequence, however, when the probability of parti￾cle transfer exceeds 3%, erroneous results may be obtained (Smit, 1992).
In the particle displacement step (Algorithm 10.1, Part 2.1), new particle coordi￾nates are chosen randomly, whereas in the volume change step (Algorithm 10.1,
Part 2.2), the length of the simulation box is either decreased or increased by a ran￾dom amount. Typically, at least a 50% acceptance rate is desirable to achieve equi￾librium efficiently, however, this is only a guide and it does not have any
theoretical justification. The acceptance rate can be adjusted by altering the values
of the maximum possible displacement and maximum change in box length. For
many intermolecular potentials (Chapters 3 and 4), the effect of a change in volume
can be calculated simply by scaling the molecular coordinates (see Chapter 8).
The particle transfer step (Algorithm 10.1, Part 2.3) involves selecting ran￾domly a molecule in one box and attempting to insert it randomly in the other
box. It is difficult to prescribe exactly a desirable acceptance rate for particle
transfer. In the case of mixtures, it is important that each particle is selected with
equal probability to satisfy the requirements of thermodynamic reversibility.
Typically, an acceptance rate of a few percent is usually sufficient for material
equilibrium. During the particle transfer test, the chemical potential can be easily
calculated using Widom’s test particle approach. Identical, or at least very similar
chemical potentials in the boxes, indicate that the acceptance rate is satisfactory
and that material equilibrium has been achieved.
Eqs. (10.8)(10.10) can be used to generate either a NVT Gibbs ensemble
or an NpT ensemble depending on the treatment of volume fluctuations in
Eq. (10.9). For the NVT Gibbs ensemble, the total volume of the two boxes is
conserved, that is, ΔVα 5 ΔVβ, whereas for the NpT ensemble, the volume
fluctuation of the two boxes are independent of each other. An alternative
implementation of the Gibbs ensemble, which allows heat exchange between
the phases, is discussed elsewhere (Kristo´f and Liszi, 1998).
364 Molecular Simulation of FluidsALGORITHM 10.1 Gibbs ensemble MC.
Part 1 Initialization:
Specify the number of cycles (nCycles), number of particles in
the boxes (nBox1, nBox2), number of volume (nVol), transfer
attempts (nTrans), and the total number of moves 
(nTotal = nBox1 + nBox2 + nVol + nTrans).
Part 2 Generate Markov chain:
loop i 1 ... nCycles
loop j 1 ... nTotal
if (rand()  nBox1/nTotal) //Decide which move to perform
Part 2.1 Displace particle in box 1.
else if(rand()  (nBox1 + nBox2)/nTotal)
Displace particle in box 2.
else if(rand()  (nBox1 + nBox2 + nVol)/nTotal)
Part 2.2 Change volume.
else if(rand() 
(nBox1 + nBox2 + nVol + 0.5nTrans)/nTotal)
Part 2.3 Transfer particle from box 1 to box 2.
else
Transfer particle from box 2 to box 1.
end if
end j loop
end i loop
GEMC is arguably the most commonly used algorithm for fluid phase equilib￾ria (Panagiotopoulos, 1992a; Panagiotopoulos, 2000; Silva Fernandes and Fartaria,
2015). It has been used widely to predict VLE in both conventional one￾component fluids and binary mixtures and extended to cover quantum systems
(Kowalczyk et al., 2013; Fantoni and Moroni, 2014). It has been used in conjunc￾tion with many empirical intermolecular potentials (Chapters 3 and 4) including
the LJ (Panagiotopoulos, 1987; Plackov and Sadus, 1997; Potoff and ˇ
Panagiotopoulos, 1998), square-well (Vega et al., 1992), Stockmayer (Smit et al.,
1989), restrictive primitive (Panagiotopoulos, 1992b), Yukawa (Rudisill and
Cummings, 1989), GayBerne (de Miguel et al., 1990), Keesom (Sadus, 1996a),
Mie (Mick et al., 2015; Sadus, 2020a,b), and double-Gaussian core model (Losey
and Sadus, 2019) potentials. The VLE behavior of various water models
(Chapter 4) have been evaluated (Raabe and Sadus, 2007) and it has been used
(Vogt et al., 2001; Vlasiuk et al., 2016; Vlasiuk and Sadus, 2017; Deiters and
Sadus, 2019) to evaluate the pure component VLE behavior displayed by ab initio
potentials. GEMC has also been applied (Sadus, 1998a; Marcelli and Sadus,
1999; Wang and Sadus, 2006a; Sadus, 2020c; Raabe and Sadus, 2003) to study
the relative effect of two- and three-body interaction on the VLE of pure fluids.
Contrary to some earlier indications (Valleau, 2003), there is evidence (Dinpajooh
et al., 2015) that GEMC can be used to accurately determine VLE critical points
using relatively small system sizes.
Molecular simulation of phase equilibria Chapter | 10 365Examples of GEMC binary VLE simulations include mixtures modeled via
the LJ (van Leeuwen et al., 1991), hard-sphere/soft-sphere (Amar, 1989), Keesom
(Sadus, 1996b), and Mie (Potoff and Kamath, 2014; Mick et al., 2015) potentials.
The VLE of hydrocarbon mixtures (de Pablo and Prausnitz, 1989), polydisperse
fluids (Stapleton et al., 1990), and the effect of three-body interactions in mixtures
(Marcelli and Sadus, 2001) have also been determined using GEMC. In general,
the results are remarkably insensitive to the number of molecules used with the
possible exception of near-critical equilibria (Valleau, 1998). The method has
been applied to the calculation of Henry’s constant (Sadus, 1997) at vaporliquid
and liquidliquid phase boundaries. The Gibbs ensemble can also be used in con￾junction with a “reaction ensemble” to simulate phase-dependent chemical reac￾tions (Johnson et al., 1994; Smith and Triska, 1994).
Binary mixtures also provide the first opportunity to study liquidliquid
equilibria (LLE). GEMC can also be used for LLE, although greater difficulties
are encountered in the particle exchange step, which now involve the insertion
of atoms or molecules between phases of similar densities. Nonetheless, success￾ful GEMC for LLE in binary mixtures have been reported for several different
cases (Sadus, 1996b, 1998b; Bergermann et al., 2021a,b).
As discussed previously, GEMC can be easily applied to one, two, three, or
more components. However, applications of the GEMC have been overwhelmingly
restricted to either pure components or binary mixtures. This situation, which is
common to other phase behavior algorithms, reflects the relative interest in such
systems rather than any theoretical impediment. Indeed, the ease of extending
GEMC to multicomponent mixtures would make it arguably the method of choice
for systems containing three or more components. A few examples of GEMC simu￾lations for ternary mixtures have been reported (Tsang et al., 1995; Sadus, 1999).
The main limitation of the MC Gibbs ensemble method is that it is diffi￾cult to apply successfully for highly nonspherical, multisegment, or strongly
interacting molecules because the particle transfer step has a very low proba￾bility of acceptance for these molecules. In this context, the use of the Gibbs
ensemble algorithm with configurational bias methods is advantageous (see
Chapter 6). Gromov et al. (1998) have reported calculations of polymer￾supercritical solvent mixtures using an “expanded” Gibbs ensemble in con￾junction with a multiple-time-step hybrid MC technique, which alleviates
this difficulty. This issue has been addressed using a continuous fractional
component (CFC) MC move (Shi and Maginn, 2008), which involves assign￾ing the strength of particle interaction on a scale of 0 (ideal gas) to 1 (nor￾mal). The CFC MC approach results in increased efficiency (Rahbari et al.,
2021) of particle exchanges between phases. Another possible solution to
this problem is the formulation of a MD equivalent of the Gibbs ensemble
(Palmer and Lo, 1994; Hentschke et al., 1996). The MD adaption (discussed
below) also makes use of fractional particles to facilitate particle exchanges.
The difficulty of particle transfer means that GEMC is not a practical
algorithm for SLE, although an attempt (Sweatman and Quirke, 2004) has
366 Molecular Simulation of Fluidsbeen made to address this issue. Eike et al. (2005) have discussed the chal￾lenges posed by SLE for simulation algorithms in general.
10.3 MD Gibbs ensemble
The Gibbs ensemble was developed initially as a MC technique for calculating
phase equilibria. The main limitation of the MC implementation of the Gibbs
ensemble is that it does not handle large molecules efficiently. It is difficult to
design MC moves for molecules with large or complicated molecular structures
that sample configuration space efficiently, and successful particle exchanges
become increasingly rare. To overcome these difficulties, some MD Gibbs ensem￾ble methods have been developed (Palmer and Lo, 1994; Kotelyanskii and
Hentschke, 1995; Baranyai and Cummings, 1996) as detailed below. Very little
use has been made of these MD adaptations. These methods have also be supple￾mented by MD simulations (Kuznetsova and Kvamme, 2005; Eslami and Mu¨ller￾Plathe, 2007) of the grand canonical ensemble.
10.3.1 LoPalmer method
A MD implementation of the Gibbs ensemble has been proposed based on
the following Hamiltonian (Palmer and Lo, 1994).
H 5X
Nα
i51
p2
i
2mi
1 uαðqNα Þ 1X
Nβ
j51
p2
j
2mj
1 uβðqNβ Þ
1 p2
αf
2mf
1 uαfðqNα ; qαf ; cαÞ 1 p2
βf
2mf
1 uβfðqNβ ; qβf ; cβÞ
1 p2
s1
2Q1
1 p2
s2
2Q2
1 g1kTlns1 1 g2kTlns2 1 p2
Vα
2W
1 p2
cα
2X
1 cαkTln VβðNα 1 1Þ!Nβ!   1 cβkTln VαðNβ 1 1Þ!Nα!  
ð10:11Þ
Eq. (10.11) is an extension of Eq. (9.89) (Lo and Palmer, 1995) for two differ￾ent phases denoted by α and β of volume Vα and Vβ, respectively. It is written in
terms of real variables. The total volume of the system is conserved (Vtotal5 Vα
1 Vβ). The subscripts i and j refer to the ordinary particles in boxes α and β,
respectively, whereas the label f denotes a fractional particle that exists simulta￾neously in both boxes. We can distinguish between the coordinates q and
momenta p of the ordinary particles (qαi
, pαi
, etc.) and fractional particles (qαf
,
pαf
, etc.). The terms cα and cβ are coupling parameters for the two boxes, which
satisfy the relationship cα 1 cβ 5 1. Consequently, when cα 5 1, the fractional
particle is coupled completely to box α, whereas when cβ 5 1, the fractional parti￾cle is coupled completely to box β. The temperatures of the two boxes are con￾trolled separately using two Nose´ thermostats with the velocity scaling parameters
s1 and s2. The variables ps1, ps2, pVα, and pcα are the momenta conjugate to s1,
s2, Vα, and cα, respectively. The constants Q1, Q2, W, and X are the masses
Molecular simulation of phase equilibria Chapter | 10 367associated with the velocity scaling variables s1 and s2, the volume Vα, and the
coupling parameter cα, respectively. The constants g1 and g2 denote the total num￾ber of degrees of freedom of each box, and the u terms are the potential energy
functions of the two boxes.
The equations of motion derived from this Hamiltonian are:
p_ 5 F 1 Ff
s2
1
2 2ms_1
s1
v 2 1
3
V_α
Vα

 q
 	 2 2m
9
V_α
Vα

 2
q 1 m
3
V€
Vα

 q ð10:12Þ
s€1 5 s1
Q1
XNα
i51
mi vi2 1
3
V_α
Vα

 qi

 2
1 mfs1 vαf 2 1
3
V_α
Vα

  
  2
2 g1
s1
kT " # ð10:13Þ
WV€α 5XNα
i51
mis2
1
3Vα


vi21
3
V_α
Vα

 qi
2
1 mfs2
1
3Vα


vfα21
3
 V_α
Vα

qfα
2
2XNβ
j51
mjs2
2
3Vβ


vj21
3

 V_β
Vβ

qj
2
2 mfs2
2
3Vβ


vfβ21
3
V_β
Vβ

 qf β
2
2 @uα
@Vα
2 @uαf
@Vα
1
@uβf
@Vβ
2 cβ
kT
Vα
1 cα
kT
Vβ
ð10:14Þ
Xc€α 5 2 @uαf
@cα
1
@uβf
@cβ
1 kTln VαðNβ 1 1Þ
VβðNα 1 1Þ ð10:15Þ
The equations of motion for the remaining coordinates and s2 can be
obtained by manipulating the indices of Eqs. (10.12) to (10.15).
An implementation of the LoPalmer method for a multiphase system is illus￾trated by Algorithm 10.2. The first step in the simulation process (Algorithm 10.2,
Part 2) involves generating an equilibrated NVT ensemble for each phase
(Algorithm 10.2, Part 2.1). The phases are initially characterized by an identical
temperature but different number of particles, volumes, and pressure. The NVT
ensembles can be generated by any suitable algorithm; however, it is convenient to
use the Nose´Hoover algorithm (Algorithm 10.2, Part 2.1.1) because, when there
are no particle fluctuations, the LoPalmer algorithm reduces to the Nose´Hoover
algorithm. After the NVT ensemble equilibration period (Algorithm 10.2, Part 2.2),
a particle is chosen randomly from one of the phases α (Algorithm 10.2, Part
2.2.1). The chosen particle represents the fractional particle fα for phase α, cα 5 1,
and c_α is obtained from a Boltzmann distribution. A particle is inserted into another
phase β (Algorithm 10.2, Parts 2.2.2 and 2.2.3) with momenta obtained from a
Boltzmann distribution. The inserted particle fβ represents the fractional particle in
phase β with cβ 5 0. Solutions to the equations of motion [Eqs. (10.12) to (10.15)]
are obtained until cα equals 0 or 1 (Algorithm 10.2, Part 2.2.4). A value of cα 5 1
indicates that the fractional particle has become coupled to phase α. Consequently,
it is transformed (Algorithm 10.2, 2.2.5) into a normal particle of phase α. If
cα 5 0, the fractional particle has become coupled to phase β and it is transformed
to a normal particle of phase β. The other fractional particle fβ is removed and the
368 Molecular Simulation of Fluidsentire procedure is repeated until the simulation is completed. Averages are accu￾mulated following an equilibration period (Algorithm 10.2, Part 2.2.6).
ALGORITHM 10.2 Gibbs ensemble MD using the LoPalmer algorithm.
Part 1 Initialisation:
Assign values of W, Q, X, N1, N2, V1, V2, T, etc.
Part 1.1 Initialise all phases:
loop i  1 ... nPhases
Assign coordinates (ri) at time (t) = 0.
Assign molecules initial velocities.
Scale coordinates.
gi 3N
si 0
siDot  0
end loop
Part 2 Simulation Process:
Part 2.1 Create equilibrated NVT-ensembles for nPhases:
loop
loop i  1 ... nPhases
Part 2.1.1 Implement Nosé-Hoover algorithm for ensemblei
(e.g. Algorithm 9.9).
end loop
t  t + t
while (t  tNVTEquilibration)
Part 2.2 Implement Lo-Palmer Algorithm:
loop
 integer[1, nPhases] // Choose a phase randomly
Part 2.2.1 Choose a fractional particle randomly for the phase:
f   integer[1, N]
c  1
cDot  Boltzmann distribution
Part 2.2.2 Choose the insertion phase randomly:
loop
 integer[1, nPhases]
while ()
Part 2.2.3 Insert a fractional particle (f) into phase .
pf Boltzmann distribution
c 0
Part 2.2.4 loop
Evaluate eqs. (10.12) to (10.15).
t  t + t
while ( c < 1)
Part 2.2.5 if (c = 1)
Re-assign f as a normal particle of phase .
else
Re-assign f as a normal particle of phase .
end if
Remove f.
Part 2.2.6 if (t > tEquilibration)
Accumulate averages.
end if
while (t  tMax)
Molecular simulation of phase equilibria Chapter | 10 36910.3.2 KotelyanskiiHentschke method
Kotelyanskii and Hentschke (Kotelyanskii and Hentschke, 1995, 1996;
Hentschke et al., 1996) have also used a fractional particle approach to
derive a MD version of the Gibbs ensemble. To simulate a variable num￾ber of molecules in the simulation boxes, they introduced an additional
degree of freedom ξi for each molecule. The value of ξi can vary between
0 and 1. When ξi 5 1, molecule i is in box 1 whereas when ξi 5 0, the
molecule is in box 2. At intermediate values of ξi, the molecule is in a
transition state and it is felt by both boxes. Consequently, the potential
energy of the system is a function of both ξi and the intermolecular
coordinates,
Uðrij; ξi; V1; V2Þ 5X
i , j
uðrij; V1Þξiξj 1 uðrij; V2Þð1 2 ξiÞð1 2 ξjÞ  
1X
i
gðξiÞ
5 U1 1 U2 1X
i
gðξiÞ
ð10:16Þ
where Vi and Ui are the volumes and energies, respectively, of the boxes
indicated by the subscript. In Eq. (10.16), g(ξi) is a potential function, which
accounts for the presence of transition state molecules. The value of g must
equal zero at either ξi 5 0 or ξi 5 1 but it is greater than zero at intermediate
values of ξi, which correspond to any transition molecule. Kotelyanskii and
Hentschke (1995) proposed the following g function,
gðξiÞ 5 w tanhðvξiÞ 1 tanh vð1 2 ξiÞ   2 1   0 # ξi # 1
N otherwise 
ð10:17Þ
where w and v represent a height barrier and steepness parameter, respec￾tively between the states corresponding to the real particles. The effect of
the w and v parameters is to make the transition state unfavorable
energetically.
The conditions for phase coexistence require that the temperature, pres￾sure, and chemical potential of the coexisting phases are identical. For a one￾component system, this is achieved by ensuring that every change of volume
in one of the boxes is accompanied by an opposite but equal change in vol￾ume in the other box. Therefore the total volume of the system remains con￾stant, whereas the volumes of the individual boxes are variable. The MD
equation of motion for a one-component system becomes:
p 5 mr_ ð10:18Þ
p_ 5 2 @U
@r 5 ηp ð10:19Þ
370 Molecular Simulation of Fluidsη_ 5 1
QT
X
i
p2
i
mi
2 XkT " # ð10:20Þ
pξi 5 mξi
_
ξi ð10:21Þ
p_ ξi 5 2 @U
@ξi
5 2 X
i , j
uðrij; V1Þξj 2 uðrij; V2Þð1 2 ξjÞ   2 X
i
@
@ξi
gðξiÞ ð10:22Þ
pV1 5 QpV_1 ð10:23Þ
p_ V1 5 pe
1 2 pe
2 ð10:24Þ
Together, Eqs. (10.22) to (10.24) determine the evolution of particle
coordinates, particle transfers, and volume fluctuations. The variables pi and
pξ are the momenta conjugate to the normal Cartesian coordinates, and the
transfer coordinate, respectively. Eqs. (10.18) and (10.19) represent the evo￾lution of a system that is coupled to an external heat-bath of temperature T.
In the case of only one simulation box they correspond to a NVT simulation
controlled with the Nose´Hoover thermostat (Chapter 9). The transfer of
molecules between the boxes is controlled by Eqs. (10.21) and (10.22).
Eqs. (10.23) and (10.24) are the equations of motion of the box of volume
V1, where pV1 is a momentum variable conjugate to V1 and Qp is a parameter
governing volume relaxation. The volume changes are controlled by the dif￾ference between the instantaneous values of the “external” pressures pe
1 and
pe
2 in the two boxes.
The method can be extended easily to multicomponent fluids. For exam￾ple, to simulate two-phase coexistence in a two-component system,
Eqs. (10.23) and (10.24) are replaced by,
p_ Vk 5 QpV_k ð10:25Þ
p_ Vk 5 pe
k 2 p ð10:26Þ
where p is the predetermined value of pressure and k 5 1,2.
10.3.3 BaranyaiCummings method
Baranyai and Cummings (1996) have proposed a MD implementation of the
Gibbs ensemble in which the conditions for mechanical and thermal equilib￾rium are obtained from the equations of motion via a Hoover-type determin￾istic feedback approach, whereas a MC move is used to determine the
equivalence of the chemical potentials.
Molecular simulation of phase equilibria Chapter | 10 371The system is considered to be constrained by the following conditions:
V 5 V1 1 V2 ð10:27Þ
N 5 N1 1 N2 ð10:28Þ
The equations of motion are derived to satisfy the above constraint while
guiding the system to mechanical and thermal equilibrium. The starting
points are the equations of motion in the Hoover-type form,
q_ 5 p
m 1 εðÞ ð q 2 R0 10:29Þ
p_ 5 F 2 εp 2 αp ð10:30Þ
where R0 is the center of mass of the system, ε is a strain rate factor that
couples the system to a barostat, and α is the feedback multiplier that cou￾ples the system to a heat-bath. These equations are supplemented by the
Nose´Hoover thermostat (Chapter 9),
α_ 5 1
QT
TðtÞ
T0
2 1

  ð10:31Þ
where QT is a constant and T0 is the reservoir temperature.
The change in volume can be obtained using ε.
V_ 5 3Vε ð10:32Þ
To obtain equations for dε/dt while maintaining the restriction of constant
volume, Eq. (10.27) is differentiated twice with respect to time.
V1 3ε2
1 1 ε_1
  1 V2 3ε2
2 1 ε_2
  5 0 ð10:33Þ
To relate dε/dt to the pressure of the two phases, we have,
ε_1 5 p1 2 p2
V1QV
2 3
2 ε2
1 1 ε2
2
V2
V1

  ð10:34Þ
ε_2 5 p1 2 p2
V2QV
2 3
2 ε2
2 1 ε2
1
V1
V2

  ð10:35Þ
where QV is a constant. If Eqs. (10.34) and (10.35) are substituted into
Eq. (10.33), it becomes apparent that the relative volume changes are deter￾mined by the difference in the instantaneous pressures.
V1ε_1 2 V2ε_2 5 2ð Þ p1 2 p2
QV
ð10:36Þ
372 Molecular Simulation of FluidsEqs. (10.29)(10.35) govern the dynamics of both phases and bring the
system to mechanical and thermal equilibrium. To obtain the equivalence
in the chemical potentials, the MD run is halted after n time steps and a
particle interchange is attempted in the same way as the MC Gibbs ensem￾ble. The only difference is that we must also choose a random velocity
from a MaxwellBoltzmann distribution corresponding to the fixed inter￾nal temperature.
10.4 NpT 1 test particle
VLE can be studied using the NpT 1 test particle method (Mo¨ller and
Fischer, 1990; Lotfi et al., 1992). The basic approach is to determine the
phase coexistence properties at a given temperature from the intersection of
the vapor and liquid branches in the chemical potential versus pressure dia￾gram. The chemical potential is written in terms of a Taylor series expan￾sion in pressure. The coefficients of the Taylor series are determined by
MD simulations in the liquid and vapor phases. The technique has been
developed further (Boda et al., 1995a,b; Kronome et al., 2000), and it can
also be used in conjunction with the NVT (Szalai et al., 1995; Okumura and
Yonezawa, 2001) and grand canonical ensembles (Boda et al., 1996, 1997).
It has been applied to determine (Okumura and Yonezawa, 2000) the pure
VLE behavior of different intermolecular potentials. Studies involving
binary mixtures have also been reported (Vrabec et al., 1995; Vrabec and
Gross, 2008).
10.5 GibbsDuhem integration
Kofke (1993a,b) proposed a GibbsDuhem simulation method, which com￾bines elements of the Gibbs ensemble with integration of the Clapeyron
equation. It is commonly referred to as GibbsDuhem integration (GDI).
For a one-component system, the GibbsDuhem equation is
dðβμÞ 5 hdβ 1 βvdp ð10:37Þ
where μ is the chemical potential, h is the molar enthalpy, v is the molar vol￾ume, p is the pressure, and β 5 1/kT. The Clapeyron equation is obtained by
writing Eq. (10.37) for two coexisting phases (I and II)
dp
dβ

 
s
5 2 Δh
βΔv
ð10:38Þ
where Δh 5 hI  hII and Δv 5 vI  vII are the differences in the molar
enthalpies and molar volumes, respectively, of the coexisting phases.
Molecular simulation of phase equilibria Chapter | 10 373The subscript s indicates that the derivative is taken along the saturation line.
Alternatively:
dlnp
dβ

 
s
5 2 Δh
βpΔv 5 fðβ; pÞ ð10:39Þ
Eqs. (10.38) and (10.39) represent first-order differential equations that
regulate the change in pressure required to maintain two-phase coexistence.
If the pressure at a given coexistence point is known, either Eqs. (10.38) or
(10.39) can be integrated numerically to obtain the entire coexistence curve.
In practice, it is advantageous to use Eq. (10.39) rather than Eq. (10.38)
because the right-hand side of Eq. (10.38) varies only slowly.
Many different strategies are available for solving differential equa￾tions (Chapter 7). A simple and convenient method is the Adams predic￾torcorrector algorithm
P: yi11 5 yi 1
Δβ 55fi 2 59fi21 1 37fi22 2 9f ð Þ i23
24
C: yi11 5 yi 1
Δβ 9fi11 1 19fi 1 5fi21 1 f ð Þ i22
24
9
>>>>=
>>>>;
ð10:40Þ
where y represents ln p, f is f(β, P), Δβ is the difference in β between the cur￾rent simulation and the initial condition, and P and C denote the predictor and
corrector parts of the algorithm, respectively. The Adams algorithm is chosen
because it can be used to solve accurately (Kofke, 1993b) the Clapeyron equa￾tion. However, the algorithm is not self-starting requiring four previous values of
f. The initial estimate can be obtained from the trapezoid predictorcorrector.
P: y1 5 y0 1 Δβf0
C: y1 5 y0 1
Δβð Þ f1 1 f0
2
9
>=
>;
ð10:41Þ
The second point can be determined from the midpoint predictorcorrector.
P: y2 5 y0 1 2Δβf1
C: y2 5 y0 1
Δβð Þ f2 1 4f1 1 f0
3
9
>=
>;
ð10:42Þ
The third point can be obtained by combining the midpoint predictor
with the Adams corrector.
P: y3 5 y1 1 2Δβf2
C: y3 5 y2 1
Δβð Þ 9f3 1 19f2 2 5f1 1 f0
24
9
>=
>;
ð10:43Þ
374 Molecular Simulation of Fluids
.In the above equations, it should be stressed that the values of f refer to
results of previous simulations at different values of β.
The starting point for the simulation is a known coexistence point.
This can be obtained by performing a conventional GEMC simulation.
These data are used to calculate f0, and thereby obtain an estimate of the
pressure at the new temperature. For example, applying the trapezoid pre￾dictor we obtain:
p 5 poexpðf0ΔβÞ ð10:44Þ
An NpT ensemble simulation is conducted in both phases for a short
period using the earlier estimate of pressure. At the end of this period, the
average energy and volume of the phases are calculated and used to update
the pressure using the corrector formula. Using the trapezoid-corrector
yields,
p 5 poexp
Δβð Þ f0 1 f1
2

  ð10:45Þ
where f1 is the estimate of f obtained from the simulation in progress. The
simulation is continued using the new pressure and the process is repeated
after another sampling interval. It should be noted that either MC or MD
simulations can be used. A MD implementation of GDI has been reported by
L´ısal and Vacek (1996a,b, 1997).
Algorithm 10.3 illustrates a possible implementation of GDI for a one￾component fluid at several different temperatures. The first stage
(Algorithm 10.3, Part 1) involves a GEMC simulation to obtain the coex￾istence properties for an initial value of β. These GEMC data are used
(Algorithm 10.3, Part 2) to estimate the pressure at a new value of β,
which differs from the initial value by an amount Δβ. This new value of
β is used for the first GDI simulation (Algorithm 10.3, Part 3). Several
GDI simulations are performed until the desired βEnd value is reached. At
the start of each new simulation (Algorithm 10.3, Part 3), the average
values of the properties required to calculate f are initialized to zero.
Each simulation is conducted for nCycles (typically several thousand
cycles are required). During each cycle, a phase is selected randomly
(Algorithm 10.3, Part 3.1) and a random choice is made to attempt either
a molecular displacement or volume change (Algorithm 10.3, Part 3.2).
The decision to accept the move is made according to the standard MC
acceptance criteria as illustrated in Algorithm 9.2 for a NpT ensemble.
Following the MC move, if the update frequency has been reached (update
is assigned typically a value of 10), the pressure is re-evaluated using an
appropriate predictorcorrector method (Algorithm 10.3, Part 3.3). This
involves evaluating f from the running averages of enthalpy and volume
Molecular simulation of phase equilibria Chapter | 10 375differences. If the update interval has not been reached, the running
averages are updated (Algorithm 10.3, Part 3.4). During each simulation
cycle, a check is performed to determine whether the equilibration period
(nEquilibration) has been reached. When the system has been equilibrated,
the running averages are re-initialized to zero (Algorithm 10.3, Part 3.5)
and contributions to the ensemble averages are accumulated (Algorithm
10.3, Part 3.6). At the end of the simulation (Algorithm 10.3, Part 3.7),
the properties of the ensemble and f are stored and β is changed by a fur￾ther amount of Δβ.
The main advantage of GDI is that it avoids the difficult particle insertion
step required by GEMC. Consequently, unlike the GEMC method, it can be
used to predict equilibria involving a solid phase (L´ısal and Vacek, 1997;
Poison and Frenkel, 1998). It may also be useful in predicting the phase
behavior of polymers and other large molecules for which it is difficult to
obtain successful particle insertions. However, GDI relies heavily on having
an accurately determined starting point that must be obtained by other simu￾lation techniques such as GEMC. If the starting point is inaccurate, the rest
of coexistence curve predicted by GDI will also be obtained inaccurately
(Kofke, 1993b).
Mehta and Kofke (1994) extended the GDI method to binary mixtures.
The GibbsDuhem equation for binary mixtures (Denbigh, 1961) is,
x1dlnf1 5 hrdβ 1 Zdlnp 2 x2dlnf2 ð10:46Þ
where xi is the mole fraction of component i with fugacity fi, hr is the
residual molar enthalpy (i.e., the enthalpy excluding the ideal gas contri￾bution), and Z 5 pv/RT is the compressibility factor. It can be shown
(Mehta and Kofke, 1994) that the Clapeyron relationship arising from
Eq. (10.46) is,
@p
@f2

 
β;s
5 1
xv
1Zl 2 xl
1Zv
xv
1
φl
2
2 xl
1
φv
2
 ! ð10:47Þ
where the superscripts l and v refer to the liquid and vapor phases, respectively,
and φ2 5 f2/(px2) is the fugacity coefficient of component 2. Eq. (10.47) pre￾scribes simulation in an osmotic ensemble in which the independent variables
are temperature, pressure, and the fugacity of component 2.
376 Molecular Simulation of FluidsALGORITHM 10.3 MC implementation of GDI for an one-component
fluid at several different temperatures.
Part 1 GEMC for initial coexistence point (Algorithm 10.1).
Part 2 Initialisation for GDI:
fo - Enthalpy/(pressure  Volume)
Calculate p from trapezoidal-predictor.
 +  //value for first Gibbs-Duhem simulation
simulation 1
offset  0
Part 3 GDI/Markov Chain:
loop //simulation for several temperatures
accumEnthalpy  0 //initialise accumulators
accumVolume  0
loop n  1 ... nCycles //Markov process
Part 3.1 Select a phase:
if(rand()  0.5)
phase 1
else
phase 2
end if
Part 3.2 Select MC move:
if(rand()  0.5)
Random displacement (Algorithm 9.2, Part 2.1).
else
Random volume fluctuation (Algorithm 9.2, Part 2.2).
end if
Part 3.3 Update pressure:
if(mod(nCycles,update) = 0)
if (simulation = 1)
Update pressure using trapezoidal-PC.
else if (simulation = 2)
Update pressure using midpoint-PC.
else if (simulation = 3)
Update pressure using midpoint-P/Adams-C.
else
Update pressure using Adams-PC.
end if
Part 3.4 else //update accumulators
accumEnthalpy  accumEnthalpy + Enthalpy
accumVolume  accumVolume + Volume
Molecular simulation of phase equilibria Chapter | 10 377averageEnthalpy  accumEnthalpy/(n - offset)
averageVolume  accumVolume/(n - offset)
end if
Part 3.5 if (n = nEquilibration) //re-initialise accumulators
accumEnthalpy  0
accumVolume  0
offset  nEquilibration
end if
Part 3.6 if (n  nEquilibration)
Accumulate averages.
end if
end n loop
Part 3.7 Store pressure, enthalpy, etc. data for completed simulation.
fsimulation  - Enthalpy/(pressure  Volume)
 + 
simulation  simulation + 1
while ( does not equal End)
It is also possible to obtain a Clapeyron relationship for the semi-grand
ensemble. The following fugacity fraction (ξ2) for component 2 is defined.
ξ2 5 f2
f1 1 f2
ð10:48Þ
Substituting Eq. (10.48) into Eq. (10.46) yields:
dlnð Þ f1 1 f2 5 hrdβ 1 Zdlnp 2 x2 2 ξ2
ξ2 1 2 ξ2
  dξ2 ð10:49Þ
Mehta and Kofke (1994) showed that Eq. (10.49) leads to the following
Clapeyron relationship:
@lnp
@ξ2

 
β;s
5 xl
2 2 xv
2
ξ2 1 2 ξ2
  Zl 2 Zv ð Þ ð10:50Þ
Eq. (10.50) prescribes a simulation in a semi-grand ensemble (Briano and
Glandt, 1984; Kofke and Glandt, 1988), which has the temperature, pressure,
fugacity fraction, and the total number of molecules as the independent variables.
Mehta and Kofke (1994) have reported details of the MC implementation
of GDI in both the osmotic and semi-grand ensembles. The method has been
used to calculate three-phase coexistence lines (Agrawal et al., 1994). L´ısal
and Vacek (1997) reported a MD version of GDI for the semi-grand ensem￾ble. For mixtures, some of the advantage of GDI over the Gibbs ensemble
method is lost. Attempted particle deletions and insertions are required for
the osmotic ensemble, whereas the implementation of the algorithm for the
semigrand ensemble requires attempts to change particle identity.
The semigrand ensemble implementation has the advantage over the
Gibbs ensemble that it avoids particle interchange attempts. In principle, the
378 Molecular Simulation of FluidsMC acceptance criteria for particle displacement and volume change are
identical to the criteria used in the Gibbs ensemble. In practice, it is useful to
couple the volume moves in both phases to prevent unilateral condensation
or vaporization of either phase. The acceptance criterion for volume changes
must be modified (Mehta and Kofke, 1994) to account for the effects of vol￾ume coupling. The acceptance criterion for changing the identity of particles
is relatively simple. If the identity of particle of component 2 is changed to
component 1, the change in identity is accepted with a probability of:
min 1; exp 2βΔU 2 ln ξ2
1 2 ξ2
 	   
  ð10:51Þ
If the identity of particle of component 1 is changed to component 2, the
change in identity is accepted with a probability of:
min 1; exp 2βΔU 1 ln ξ2
1 2 ξ2
 	   
  ð10:52Þ
Swapping particle identities is likely to be most effective when the parti￾cles are of similar size and shape. In contrast, the acceptance rate for
attempts to change the identities of very dissimilar molecules is likely to be
similar to the Gibbs ensemble deletion/insertion move. In particular, swap￾ping the identity of a small molecule for a large molecular is likely to fail
because of particle overlap with neighboring molecules.
Escobedo and de Pablo (1997) have reformulated the GDI method. In the
reformulated approach, phase coexistence of a one-component system is gov￾erned by,
dðβμÞ
dβ

 
s
5 ρIIhII 2 ρI
hI
ρII 2 ρI ð10:53Þ
where μ is the chemical potential and the superscripts I and II distinguish
between the different coexisting phases. For a two-component system,
dβμ 5 1 2 xI
i
 hII 2 1 2 xII
i
 hI
xII
i 2 xI
i
  dβ 1
1 2 xI
i
 vII 2 1 2 xII
i
 vI
xII
i 2 xI
i
  βdp ð10:54Þ
where i 5 1, 2. Eq. (10.54) allows the generation of either isothermal
(dβ 5 0) or isobaric (dp 5 0) diagrams. The simulations can be performed
osmotically with T, p, N1, and μ2 being held constant. Alternatively, a grand
canonical-type simulation can be conducted at constant μ1, μ2, V, and T. The
μ1μ2VT method is potentially useful for simulations of polymers because vol￾ume moves are avoided (for simulations involving large molecules, volume
moves have a low probability of acceptance) and the simulations can be per￾formed using an expanded grand canonical approach.
An improvement to GDI (van ‘t Hof et al., 2006a), particularly for mix￾tures, is to combine it with histogram reweighting (discussed below). This
Molecular simulation of phase equilibria Chapter | 10 379provides greater computational efficiency without sacrificing accuracy. The
issue of obtaining a reliable VLE starting point has also been addressed
(van ‘t Hof et al., 2006b), which may be particularly useful for determining
the properties of mixtures of chain molecules.
If a suitable starting point can be determined, a significant benefit of GDI is
the ability to determine SLE, which is practically impossible to achieve using
GEMC. The SLE starting point is often obtained from the evaluation of free ener￾gies but a combined equilibrium/nonequilibrium method (Ge et al., 2003, dis￾cussed below) provides a useful alternative in many cases. The SLE behavior of
pure fluids represents the simplest case. GDI has been used to determine (Fartaria
et al., 2002) the SLE and triple points on (n6) LJ fluids (Ahmed and Sadus,
2009a), C60 (Fartaria et al., 2001, 2002), and the noble gases (Deiters and Sadus,
2021; Singh et al., 2021) using ab initio potentials (Chapter 4).
Application of GDI for the SLE of mixtures has been confined largely to
binary systems. The SLE of different LJ atoms (Hitchcock and Hall, 1999; Lamm
and Hall, 2001, 2002) and both LJ diatomic (Galbraith and Hall, 2007) and chain
(Poison and Frenkel, 1998) molecules have been studied. SLE diagrams for binary
metallic alloys have also been reported (Nam et al., 2007). The GDI method has
also been extended (Attwood and Hall, 2008) to ternary systems, which allowed
the determination of SLE of mixtures of three different LJ components.
10.6 Thermodynamic scaling
10.6.1 Temperature and density MC
Valleau (1991) developed a thermodynamic-scaling MC method, which can
be used to calculate phase coexistence. The difference in the residual
Helmholtz function (ΔAr) at two different densities, characterized by box
lengths L1 and L2 is given by,
ΔAr 5 2 kTln QðN; L2; TÞ
QðN; L1; TÞ
  ð10:55Þ
where Q is the reduced configurational integral. The ratio of the reduced
configurational integrals can be obtained from,
QðN; L2; TÞ
QðN; L1; TÞ
5 exp 2βUðrN; L2Þ  =πðrNÞ  
π
exp 2βUðrN ð Þ ; L1Þ =πðrNÞ  
π
ð10:56Þ
where ,... . π indicates an average over the sampling distribution π(rN).
Consequently, the average of any thermodynamic property X at each density
ρk of the canonical ensemble can be obtained from:
h i X ρk 5 XðrN; LkÞexp 2βUðrN; LkÞ  =πðrNÞ  
π
exp 2βUðrN ð Þ ; LkÞ =πðrNÞ  
π
ð10:57Þ
380 Molecular Simulation of FluidsThis “density-scaling” procedure has been used successfully to calculate
the properties of hard spheres and electrolytes described by the restricted
primitive model (Valleau, 1991) and subcritical LJ fluids (Valleau, 1993). A
“temperature-scaling” version of Eq. (10.57) has been used (Graham and
Valleau, 1990) to determine the phase coexistence of electrolytes. The gen￾eral principles been applied to obtain thermodynamic properties in the NVT
(Valleau, 2005a) and NpT (Valleau, 2005b) ensembles.
Thermodynamic scaling can provide significantly more accurate results than
the Gibbs ensemble. The disadvantages of the method are that some of the ther￾modynamic states sampled are not of any interest and additional composition vari￾ables are required to apply the method to the phase behavior of multicomponent
mixtures. The thermodynamic-scaling MC algorithm has also been used to
predict the phase diagram of a two-dimensional Coulomb gas (Orkoulas and
Panagiotopoulos, 1996) and a square-well fluid (Brilliantov and Valleau, 1998a,b).
10.6.2 Thermodynamic-scaling Gibbs ensemble MC
Kiyohara et al. (1996) proposed a procedure for combining the thermodynamic￾scaling procedure with the Gibbs ensemble. In the NVT Gibbs ensemble, the aver￾age of any thermodynamic property X of the system interacting with the
Hamiltonian n at an inverse temperature βi5 1/kTi can be calculated from,
h i X βi;n 5
XðrN; nÞ ΨðrN;βi;nÞ
πðrNÞ
D E
πðrNÞ
ΨðrN;βi;nÞ
πðrNÞ
D E
πðrNÞ
ð10:58Þ
where:
ψðrN; βi; nÞ 5 VNI
I VNII
II
NI!NII!
exp 2βiUI
nðrNI
Þ 2 βiUII
n ðrNII Þ   ð10:59Þ
In Eq. (10.59), UI
nðrNI Þ and UII
n ðrNII Þ are the potential energies in regions I
and II, respectively.
The Gibbs ensemble generates a Markov chain by using particle displace￾ments, volume changes, or particle interchanges to obtain a trial configuration
(r
N
trial) from the existing configuration (r
N
i). The trial configuration is accepted
with a probability:
pi-trial 5 min 1;
πðrN
trialÞ
πðrN
i Þ

  ð10:60Þ
To use thermodynamic scaling in conjunction with the Gibbs ensemble, con￾figurations relevant to several Hamiltonians at different temperatures must be
sampled in a single simulation. Therefore it is important that the distribution
π(r
N
) samples configurations relevant to all thermodynamic states with equal
Molecular simulation of phase equilibria Chapter | 10 381frequency. A convenient distribution is a weighted linear combination of the
Boltzmann factors of all the thermodynamic states of interest,
πðrNÞ 5 X
i
X
n
Wβi;nψðrN; βi; nÞ ð10:61Þ
where Wβi;n is the sampling weight for the thermodynamic state character￾ized by inverse temperature βi, and Hamiltonian n. A possible distribution of
weights between two thermodynamic states (βi,n) and (βj,m) can be obtained
(Kiyohara et al., 1996) from:
Wβi;n
Wβj;m
5
ΨðrN;βi;nÞ
πðrNÞ
D E
πðrNÞ
ΨðrN;βj;mÞ
πðrNÞ
D E
πðrNÞ
ð10:62Þ
However, the proper weights are obtained from an iterative process
because the estimate of the ratio of weights becomes more accurate as the
weights used in the distribution (rN) are improved.
The formulation of thermodynamic scaling for the NpT Gibbs ensemble
is almost identical. The only modification required is that Eq. (10.59) is
replaced with,
ψðrN; βi; nÞ 5 VNI
I VNII
II
NIα!NIIβ!
exp 2βiUI
nðrNI
Þ 2 βiUII
n ðrNII Þ 2 βipVI 2 βipVII  
ð10:63Þ
where p is the imposed value of pressure and NIα is the number of molecules
of species α in region I.
Kiyohara et al. (1996) used thermodynamic-scaling GEMC to calculate
VLE for a (n6) LJ fluid where n 5 10, 11, and 12. The different values of n
for the potential correspond to different Hamiltonians for the fluid. The
thermodynamic-scaling Gibbs ensemble method was found to be more efficient
than the conventional Gibbs ensemble for the calculation of the properties the
related potentials at many different thermodynamic states. This method has
also been applied successfully to phase equilibria involving the exp-6 potential
(Errington and Panagiotopoulos, 1998a). Valleau (2003) has addressed some
issues concerning the effectiveness of thermodynamic-scaling GEMC.
10.7 Pseudo-ensemble methods
A general feature of the simulation of phase equilibria is the insertion and
deletion or particles associated with either the NpT ensemble or the grand
canonical ensemble. The particle insertion is the most difficult MC move
to implement successfully, particularly at high density or if the insertion
involves a large molecule such as a polymer. A low success rate for particle
insertions or deletions slows dramatically the attainment of thermodynamic
382 Molecular Simulation of Fluidsequilibrium. To overcome this problem, Mehta and Kofke (1995) proposed a
procedure in which particle insertion and deletions are replaced by volume
fluctuations. The acceptance criterion for the volume changes (ΔV) that are
designed to mimic particle insertion or deletion attempts is given by,
min 1; exp ΔN βμGC 2 βμðρÞ 1 ZðρÞ   1 Nln V 1 ΔV
V 2 βΔU
 	 
  ð10:64Þ
where:
ΔN 5 2 ΔV
N
V 1 ΔV ð10:65Þ
In Eq. (10.64), μGC is the predetermined grand canonical chemical potential
and ΔU is the change in potential energy resulting from the change in volume.
Eq. (10.64) requires the calculation of the chemical potential μ(ρ) and the com￾pressibility factor Z(ρ) at the instantaneous density of the system ρ. The chemical
potential can be calculated from ghost particle insertions, and the compressibility
can be obtained from the virial theorem. As an alternative to these traditional
calculations, Mehta and Kofke (1995) accumulated instantaneous values of
the chemical potential and pressure into density histograms. Subsequently, μ(ρ)
and Z(ρ) required in Eq. (10.64) were obtained from empirical correlations fitted
to the histogram data. Incorporating Eq. (10.64) into a grand canonical ensemble
effectively results in a pseudo-grand canonical simulation.
Phase coexistence between different phases can be simulated directly by
replacing the particle/insertion move of the Gibbs ensemble algorithm with a
pseudo-exchange move. Camp and Allen (1996) showed that the attempted
pseudo-exchange of ΔN particles from phase II to phase I is accepted with a
probability of,
min 1; exp
ΔN ZI 1 ZII 2 β μI 2 μII     1 NI
ln VI 1 ΔVI
VI
1 NIIln VII 1 ΔVII
VII 2 β ΔUI 1 ΔUII  
0
BBBB@
1
CCCCA
2
6
6
6
6
4
3
7
7
7
7
5
ð10:66Þ
where the compressibility factors and chemical potentials are evaluated for
the density corresponding to the volume change, and the volume increments
are related to ΔN by:
ΔVI 5 2 VI
ΔN
NI 1 ΔN
ΔVII 51
VIIΔN
NII 1 ΔN
9
>>>=
>>>;
ð10:67Þ
If the μ(ρ) and Z(ρ) functions are known accurately, the limiting distribu￾tion probed by the pseudo-grand canonical ensemble is that of the NpT
Molecular simulation of phase equilibria Chapter | 10 383ensemble (Camp and Allen, 1996). Escobedo and de Pablo (1997) used this
observation to formulate an alternative criterion for the volume move,
min 1; exp 2βpeqΔV 1 Nln V 1 ΔV
V 2 βΔU
 	 
  ð10:68Þ
where peq is an initial estimate of the equilibrium pressure, which is refined pro￾gressively during the simulation. During the simulation, peq can be refined using:
peq 5 pðρÞ 1 ρ½μGC 2 μðρÞ ð10:69Þ
In the context of a pseudo-Gibbs ensemble simulation, Eq. (10.68)
becomes (Escobedo and de Pablo, 1997):
min 1; exp
2 βpeq ΔVI 1 ΔVII   1 NI
ln VI 1 ΔVI
VI
1 NIIln VII 1 ΔVII
VII 2 β ΔUI 1 ΔUII  
0
BBBB@
1
CCCCA
2
6
6
6
6
4
3
7
7
7
7
5
ð10:70Þ
Escobedo and de Pablo (1997) have also applied this technique to an
expanded grand canonical ensemble. It has been argued (Escobedo, 1998)
that pseudo-ensembles provide connections between histogram reweighting,
Gibbs ensemble, GibbsDuhem, and thermodynamic integration algorithms.
10.8 Histogram reweighting algorithms
If, in a MC simulation, σ represents a configuration, the Hamiltonian (H) can
be obtained from,
2βHðσÞ 5 KlðσÞ ð10:71Þ
where K is a dimensionless coupling constant associated with the operator l(σ). A
MC simulation of N steps at an inverse temperature of β0 produces a histogram H
(S, β0, N) for values S of the operator l(σ). The normalized distribution function,
PKðSÞ 5 HðS; β0;NÞexpð Þ ðK 2 K0ÞS
P
fSg HðS; β0;NÞexpð Þ ðK 2 K0ÞS ð10:72Þ
can be used to calculate the expectation value of any function of S in the
neighborhood of β0.
fðSÞ  
K 5 X
fsg
fðSÞPKðSÞ ð10:73Þ
The theory of histograms was developed by Salsburg et al. (1959) and later
implemented in a simulation by McDonald and Singer (1967). Valleau and Card
(1972) introduced multistage sampling (MSS) to broaden the range of tempera￾tures. MSS has been used (Bhanot et al., 1987a,b,c,d) to produce graphs of
384 Molecular Simulation of Fluidsthermodynamic quantities over a wide range of parameters. Several workers
(Falcioni et al., 1982; Marinari, 1984; Ferrenberg and Swendsen, 1989) applied
histograms to phase transitions. Ferrenberg and Swendsen (1988) introduced a
multihistogram method that combined the advantages of multistage sampling with
an improved method (Bennett, 1976) for estimating free energy differences.
Histogram methods, which are continually being made more efficient
(Lidmar, 2012), have been employed very successfully for phase equilibria
(Kiyohara et al., 1997, 1998; Conrad and de Pablo, 1998; Panagiotopoulos
et al., 1998; Kamath and Potoff, 2006). The approach has been used for iden￾tifying the VLE of alkynes (Barhaghi et al., 2017) and the determination of
the critical properties of binary mixtures (Lenart and Panagiotopoulos,
2006). The investigation of the SLE in protein solutions (Chang et al., 2004)
has been facilitated by the histogram reweighting approach.
10.8.1 Grand canonical MC
In a MC simulation for a grand canonical ensemble, Kiyohara et al. (1997)
showed that the average of any thermodynamic property X can be obtained from,
h i X μVT 5
P
N
P
EN XðN; UNÞfμVT ðN; UNÞ
P
N
P
EN fμVT ðN; UNÞ ð10:74Þ
where P
N denotes the summation of N from 0 to infinity and P
EN is a sum￾mation over all energy levels for each N. In Eq. (10.74), fμVT(N,UN) is a two￾dimensional histogram, which is related to the components of the grand
canonical partition function by,
fμVT ðN; UNÞUC 5 exp½  βðNμ 2 UNÞ ΩðN; V; UNÞ ð10:75Þ
where C is a simulation-specific simulation constant and Ω (N, V, UN) is the num￾ber of microstates for number of particles N, volume V, and energy EN. The grand
canonical partition function for different states (μ’, V, T’) can be calculated from,
Zμ0
VT0 5 X
N
X
UN
WfμVT ðN; UNÞC ð10:76Þ
where use is made of the following reweighting term:
W 5 exp N β0
μ ð Þ 0 2 βμ 2 β0 ð Þð ð Þ 2 β UN 10:77Þ
Therefore the average of any thermodynamic property X at a different
temperature (T’) and chemical potential (μ’) can be calculated from:
h i X μ0
VT0 5
P
N
P
UN XðN; UNÞWfμVT ðN; UNÞ
P
N
P
UN WfμVT ðN; UNÞ ð10:78Þ
It is evident from Eqs. (10.74)(10.78) that if the components of the
grand canonical partition function (fμVT (N,UN)) are known at one particular
Molecular simulation of phase equilibria Chapter | 10 385state (μ, V, T), the grand canonical partition function at any other state (μ’,
V, T’) can be obtained by reweighting each component using W.
The histogram reweighting technique can be applied (Kiyohara et al.,
1997) to subcritical vaporliquid coexistence by finding the chemical poten￾tial that gives the same pressure for both phases. In terms of the grand
canonical partition function (ZμVT), the pressure for a given thermodynamic
state (μ, V, T) is calculated from:
pμVT 5 ln ZμVT
V ð10:79Þ
If a histogram is made for the state (μ, V, T) from Eqs. (10.77) and
(10.79), the pressure at (μ’, V, T’) is given by:
pμ0
VT0 5 1
V
lnX
N
X
EN
WfμVT ðN; UNÞC ð10:80Þ
The value of C is determined by calculating the pressure at (μ, V, T)
from the virial theorem, that is,
p 5 h i N μVT kT
V
1
dU
dV  
μVT
ð10:81Þ
and equating this value with the right-hand side of Eq. (10.80).
The grand canonical MC reweighting procedure has been applied to
both polar fluids (Kiyohara et al., 1997, 1998; Errington et al., 1998;
Errington and Panagiotopoulos, 1998b) and lattice polymers
(Panagiotopoulos et al., 1998). The main advantage of the technique is
that the coexistence properties can be obtained very accurately. In partic￾ular, vaporliquid coexistence in the vicinity of the critical point can be
obtained much more accurately than could be otherwise calculated using
the Gibbs ensemble.
10.8.2 Isothermalisobaric MC
Conrad and de Pablo (1998) have applied histogram reweighting techniques
for the NpT ensemble. They compared results obtained from the NpT and
grand canonical histogram reweighting. Both approaches yielded results of
similar accuracy.
10.8.3 GEMC
Boulougouris et al. (2010) have combined histogram reweighting with
GEMC. The combination of the two methods improves the accuracy of pre￾dications both close to and away from the pure fluid critical point.
386 Molecular Simulation of Fluids10.9 Finite-size scaling
Generally, conventional molecular simulations that typically involve only a
few hundred particles are not accurate in the region of the critical point.
Near the critical point, the correlation length becomes very large and often
exceeds the size of the simulation. The result is that the discontinuities and
singularities that characterize critical phenomena in the thermodynamic lim￾ited are shifted. Such finite-size effects can affect adversely the accuracy of
the estimated critical point.
Finite-size-scaling (FSS) methods have been developed (Wilding,
1995, 1997) to overcome these problems. FSS methods are typically con￾ducted in the context of grand canonical MC simulations, although appli￾cation to the canonical and isothermalisobaric ensembles is possible
(Wilding and Binder, 1996). The finite-size behavior in the Gibbs ensem￾ble has been studied (Bruce, 1997). The advantage of FSS methods is that
they allow the critical point to be estimated with a high degree of accu￾racy (Kim et al., 2003; Binder, 2010). For example, the critical tempera￾ture and density of a three-dimensional LJ fluid has been calculated
(Wilding, 1995; Caillol, 1998; Rżysko and Boro´wko, 2011) to a high
degree of accuracy. FSS has been used to investigate accurately the criti￾cal exponent of both square-well (de Miguel, 1997) and dipolar square￾well fluids (Mart´ın-Betancourt et al., 2009). In contrast to earlier studies,
the FSS results indicate that the square-well fluid does not exhibit mean￾field behavior. The method is often used in conjunction with algorithms
such as histogram reweighting (Shi and Johnson, 2001) and applied to
real fluids (Bianco and Franzese, 2014).
Applications of FSS to mixtures have also been reported. Systems studied
include electrolytes (Hynninen et al., 2005), mixtures of colloids and poly￾mers (Chou et al., 2006), rods and spheres (Jungblut et al., 2008), nonaddi￾tive hard spheres (Go´zd´ z, 2003 ´ ), different LJ atoms (Pe´rez-Pellitero et al.,
2006), and polydisperse (Kristo´f and Liszi, 2001) fluids. The application to
binary mixtures means that LLE can be studied (Jagannathan and Yethiraj,
2005; Das, 2015; Go´zd´ z, 2017; Ricci and Debenedetti, 2017 ´ ).
10.10 Empirically based simulation algorithms
The previous examples of molecular simulation algorithms typically have
well-articulated theoretical foundations. In contrast, a much less-studied
route is to determine an algorithm by actually observing the effect of a phase
change on either measurable or calculated thermodynamic proprieties.
The synthetic method (Sadus, 2012) is an example of the former whereas the
combined equilibrium/nonequilibrium MD approach (Ge et al., 2003) is an
example of the latter.
Molecular simulation of phase equilibria Chapter | 10 38710.10.1 Synthetic method
There is a wide variety of ways for experimentally observing phase equilib￾ria. However, these experimental methods are totally disconnected from the
simulation algorithms used for phase equilibria. The disconnect between
experiment and simulation is understandable because it is generally impossi￾ble to directly translate actual laboratory practice into a usable algorithm. An
exception is the “synthetic” experimental method pioneered by Lentz (1969)
and Lentz and Franck (1969) for high-pressure phase equilibria. The method,
which was specifically designed for mixtures, involves an autoclave of vari￾able volume with known amounts of two components that are initially
immiscible. For any given constant volume, the temperature is increased
gradually while monitoring the increase in pressure until the meniscus sepa￾rating the two phases disappears resulting in a single phase. The point of
transition is a coexistence point on the three-dimensional pTx surface, where
x represents the composition.
Of course, it is not possible to observe a meniscus in a molecular simula￾tion, but the transition is also apparent as a “knick point” of the pT curve.
An experimental example of such a knick point for the methane 1 methanol
mixture (Francesconi, 1978) for one isochore is illustrated in Fig. 10.2. The
volume of the autoclave can be adjusted and by repeating the procedure at
different constant volumes. The locus of the resulting different knick points
36
34
32
30
28
26
400 410 420 430 440 450 460 470 480
T (K)
p (MPa)
FIGURE 10.2 An experimentally determined (Francesconi, 1978) iscochore (x) for methane 1
methanol (x2 5 0.4511, V 5 81.94 cm3
/mol) showing the location of a knick point (K) at
T 5 442.15 K and p 5 30.35 MPa. For a given composition, an isopleth is the locus of knick
points obtained from different isochores. The line through the points is only for guidance.
388 Molecular Simulation of Fluidsfor a given composition is an isopleth. The high temperature of the isopleths
is the critical curve for the mixture. It is apparent that the conditions experi￾enced in the autoclave could be represented via an NVT ensemble, resulting
in Algorithm 10.4.
ALGORITHM 10.4 Synthetic algorithm for fluid phase equlibria.
Part 1 Initialization:
Specify a fixed composition (x2 = N2/N) involving N1 and N2
Particles of components 1 and 2 respectively such that 
N = N1 + N2. Initialize other settings etc.
Part 2 Locate knick points at different isochores:
loop
Part 2.1 Look for knick point:
T = Tiintial
knickPoint = false
knickPointRef = false
notFound = true
first = true
i = 1
loop
Part 2.1.1 Perform NVT MC/MD simulation (Algorithm 9.1/9.7).
Determine if knick point is crossed.
if (knickPoint and first)
Tlower = T - T
Tupper = T
notFound = false
first = false
end if
Part 2.1.2 Refine knick point location:
If (knickPoint)
T = Tlower
loop
Perform NVT MC/MD simulation (Algorithm 9.1/9.7).
Determine if knick point is crossed.
If (knickPointRef)
Tkpi = T
pkpi = p
i = i + 1 
end if 
T = T + T/factor
while (knickPointRef = false or T <= Tupper)
end if
while (notFound and T <= Tmax)
V = V + V
while (V ≤ Vmax) 
Algorithm 10.4 commences (Part 1) in the usual way with the initialization
of simulation settings. As it is normally applied to mixtures, care is required to
specify the number of each component such that the sum does not exceed N.
Molecular simulation of phase equilibria Chapter | 10 389The example is for a binary mixture but there is no theoretical limitation on
the number of components. The main part of the algorithm (Part 2) is a loop
that sweeps over a range of different V to determine knick points at different
isochores. This involves performing NVT simulations (Part 2.1.1) for a range
of T. This can be implemented in either MC (Algorithm 9.1) or MD
(Algorithm 9.7). Alternatively an NVE implementation in either MC
(Algorithm 9.4) or MD (Algorithm 9.5) can be used. In each case, this will
involve a mixture implementation of the simulation algorithms. Following the
NVT simulation, a check is made to determine whether the knick point has
been located. In the original implementation (Sadus, 2012), this involved a
visual inspection by producing a figure equivalent to Fig. 10.2. A more sophis￾ticated alternative would be to calculate @p=@T, which should change abruptly
either side of the knick point. This could be facilitated by the relationships for
@p=@T detailed in Chapter 2. It is unlikely that the initial determination would
be sufficiently precise, which means repeating (Part 2.1.2) the process over a
narrow range of T, over a desired increment size (factor).
Although intended for mixtures, the algorithm can be applied to pure sys￾tems (Sadus, 2012). The main disadvantages of the algorithm are (1) it
requires many NVT simulations to locate a coexistence point; (2) the location
of the knick point is hard to automate; and (3) the coexistence densities are
not determined. Statistical uncertainties in the simulation may also mean that
the knick point is not as clear as the experimental case (Fig. 10.2). The
advantages are (1) implementation in either MC/MD using either NVT/NVE;
(2) discrimination of very small differences in composition (Sadus, 2012) is
possible; and (3) direct estimation of the critical locus as the high tempera￾ture envelope of the isopleths.
10.10.2 Combined NEMD/EMD method for SLE
As noted previously, a limitation of most simulation algorithms is that they
are difficult to apply to SLE, which is usually addressed using specialized
free energy techniques. GDI is very useful for SLE but it requires a
suitable starting point that is commonly obtained from free energy calcula￾tions. In the course of an nonequilibrium MD (NEMD) investigation
(Chapter 8) of the properties of LJ fluids at different strain rates (γ_) and con￾stant isochores, Ge et al. (2003) observed that the onset of SLE was associ￾ated with an abrupt discontinuity in the pressure between γ_ 5 0 (equilibrium
cases) and γ_ . 0 (nonequilibrium case). This is illustrated in Fig. 10.3.
In Fig. 10.3, the isochores corresponding to a single liquid phase (black
line) are almost linear irrespective of the value of γ_, whereas isochores (red
lines) involving a solidliquid transition display a sudden drop in pressure at
zero strain rate. This feature can be used to combine equilibrium MD (EMD)
and NEMD simulations to determine SLE as outlined in Algorithm 10.5
390 Molecular Simulation of FluidsALGORITHM 10.5 Combined EMD/NEMD algorithm for SLE.
Part 1 Determine the freezing density (f) and pressure (pf) for a given Tf:
discontinuity = false
loop
Part 1.1 NVT MD simulation 
NEMD NVT simulation (Algorithm 8.1) 
NEMD NVT simulation (Algorithm 8.1) 
Part 1.2 Check for discontinuity in p:
if (discontinuity = true)
f = 
pf = p
discontinuity = true
end if 
increment .
while ( <= Max and discontinuity = false)
Part 2 Repeat Part 1 as necessary to refine accuracy of f and pf.
Part 3 Determine p- curves:
Specify initial and final  values (Max).
loop
NVT simulation (Algorithm 9.9) to determine p.
increment .
while ( <= Max)
Part 4 Determining melting density (m) using f and pf
and data from Part 3.
FIGURE 10.3 Reduced pressure versus reduced strain rate at different reduced isochores (as
labeled) for a LJ fluid when T 5 1.0 (Ge et al., 2003). The abrupt changes indicate the presence
of a solid phase.The first part of Algorithm 10.5 (Part 1) is to determine a serious of isochores
by performing NVT EMD and NVT NEMD simulations in parallel (Part 1.1).
The number of nonzero values of γ_ is arbitrary and one well-chosen value could
be sufficient. The discontinuity in p (Part 1.2), which signifies the values of the
freezing pressure (pf
) and density (ρf
), can either be obtained graphically by repro￾ducing a plot such as Fig. 10.3 or it could be detected by monitoring for an
abrupt change in @p=@γ_. In either case, this is likely to be very easy to detect, as
it is apparent from Fig. 10.3 that isochores exclusively in the liquid phase will
have only a slight gradient. Depending on the initial spacing between the iso￾chores, the procedure may need to be repeated (Part 2) to obtain sufficiently pre￾cise values of pf and ρf
. The goal is to locate the first time this transition occurs.
Part 3 involves determining the freezing and melting lines using conventional
NVT simulations. It should be noted that this stage could be performed using
either MC or MD simulations. However, it is convenient to use MD as an EMD
algorithm can be always obtained by running an NEMD algorithm with γ_ 5 0.
By definition, freezing and melting pressures are identical, which means that the
melting density (ρm) can be obtained by extending a constant pf tie line from the
freezing curve to the melting curve data obtained in Part 3. Strictly, Part 3 only
needs to generate the melting curve, which could be obtained by restricting the
simulations to only high densities.
The main advantage of Algorithm 10.5 is that it can be used in all situa￾tions and it utilizes existing EMD and NEMD techniques. A disadvantage is
that it requires several simulations per state point and coding NEMD is
largely unfamiliar to researchers interested in phase equilibria, which by def￾inition is an equilibrium property. Nonetheless, it can be used to obtain the
entire SLE behavior and as such is particularly useful for difficult situations
(Wang and Sadus, 2006b; Mausbach et al., 2009). Alternatively, it can pro￾vide a highly reliable starting point for extensive simulations using GDI
(Ahmed and Sadus, 2009a,b; Ahmed and Sadus, 2010).
10.11 Accurate determination of SLE
As detailed earlier, VLE properties can be accurately determined via a vari￾ety of simulation algorithms. SLE properties can also be evaluated; however,
the accuracy of previously discussed approaches is very limited. Deiters and
Sadus (2022a,b) have addressed the issue of accuracy via the entropy corre￾lation method (ECM). For a fixed displacement (α) in a MC simulation, the
residual entropy (Sr
) for dense phases is an inverse function value of a dis￾placement parameter (λα), i.e.,
Sr
C2 Nk c1
λα
1 1 c3e2c2=λα
  1 c0

  ð10:82Þ
where N is the number of particles; c0, c1, c2, and c3 are coefficients
that depend on the intermolecular potential; and c0 also depends on α.
392 Molecular Simulation of FluidsThe change in the residual molar entropy (ΔSr
m) along an isothermal com￾pression from the molar density ρ0 to ρ1 depends of the enthalpy (H), com￾pressibility factor (Z), and the universal gas constant (R) via Eq. (10.83),
ΔSr
m 5 Sr
mðρ1Þ 2 Sr
mðρ0Þ 5 Hr
mðρ1Þ 2 Hr
mðρ0Þ
T 2 R
ðρ1
ρ0
Z 2 1
ρ
dρ 1 Zðρ1Þ 2 Zðρ0Þ
 !
ð10:83Þ
which can be transformed to obtain:
ΔSr
m 5 Sr
mðρ1Þ 2 Sr
mðρ0Þ 5 2 Rc1
1 1 c3e2c2=λαðρ1Þ
λαðρ1Þ 2 1 1 c3e2c2=λαðρ1Þ
λαðρ0Þ

  ð10:84Þ
The residual molar chemical potential (Δμr
) at a given T is obtained
from the residual molar enthalpy (Hr;f
m and Hr;s
m ) of the fluid (f) and solid (s)
phases and the corresponding molar volumes (Vf and Vs
).
Δμr 5 Hr;f
m 2 Hr;s
m 1 RT c1
1 1 c3e2c2=λf
α
λf
α
2 1 1 c3e2c2=λs
α
λs
α
 ! 2 ln Vf
Vs

  2 1
" #
ð10:85Þ
Using these thermodynamic relationships, the ECM is a six-step process
as illustrated in Algorithm 10.6.
ALGORITHM 10.6 ECM algorithm for SLE.
Part 1 Starting form either a gas or liquid state, perform NpT MC
simulations (Algorithm 9.2) for a given T and a series of . p
Part 2 Interpolate the compression factors obtained in Part 1 using a
quadratic polynomial to facilitate integration in Part 3.
Part 3 Evaluate Eq. (10.83).
Part 4 Starting from an fcc lattice, tentatively determine the values of Hr
,
V and λ form a series of NpT MC simulations and the 
same values of p.
Part 5 Use Eq. (10.89) to obtain r from the simulation results for
the liquid and solid phases. A 2nd or 3rd order polynomial can
be used to fit the differences a function of p. The equilibrium
p is the nearest root of this polynomial.
Part 6 Using the p obtained in Part 5, the values of V for the liquid
and solid phases are obtained via interpolation.
Molecular simulation of phase equilibria Chapter | 10 393It is apparent from the description given in Algorithm 10.6 that the ECM
process requires repeated NpT MC simulations and a considerable amount of
postsimulation analysis. The reward for this effort is that SLE properties can
be evaluated form low to very high pressures with an unprecedented degree of
accuracy. For example, the triple point T of argon can be determined (Deiters
and Sadus, 2022a) to an accuracy of within approximately 0.1 K of its experi￾mental value using a combination of SAAP 1 ATM 1 FH-1-2 potentials
(Chapter 4). This is a considerable improvement in accuracy of the previous
discrepancy of 7 K reported by an alternative method (Pahl et al., 2008). This
exceptional agreement with experiment data (Crawford, 1977) continues from
the triple point to vary high values of p as is illustrated in Fig. 10.4.
10.12 Summary
MC algorithms are used overwhelmingly to simulate the phase behavior of
fluids. The GEMC algorithm is the standard algorithm for phase equilibria
simulation. However, more accurate MC techniques based on histogram
rescaling are being developed and improved continually. The options for
MD simulations are more limited. A promising route, which is arguably
underutilized, is provided by the MD implementation of the Gibbs ensemble.
Simulations regarding SLE are considerably more challenging than VLE.
FIGURE 10.4 Comparison of ECM molecular simulation (red circles) with experimental data
(Crawford, 1977) (solid lines) for the SLE properties of argon obtained for the SAAP 1 ATM 1
FH-1-2 potential (Chapter 4) (Deiters and Sadus, 2022b).
394 Molecular Simulation of FluidsThe GDI method is very useful for SLE but requires initial starting point that
can be difficult to obtain. Perhaps somewhat unexpectedly a combined
EMD/NEMD has proved useful for SLE. It can be used both independently
of other algorithms or provide reliable initial values for GDI simulations.
However, SLE properties can be obtained with an unprecedented level of
accuracy using the ECM simulations.
References
Adams, D.J., 1976. Calculating the low temperature vapour line by Monte Carlo. Mol. Phys. 32,
647657.
Adams, D.J., 1979. Calculating the high-temperature vapour line by Monte Carlo. Mol. Phys.
37, 211221.
Agrawal, R., Mehta, M., Kofke, D.A., 1994. Efficient evaluation of three-phase coexistence
lines. Int. J. Thermophys. 15, 10731083.
Ahmed, A., Sadus, R.J., 2009a. Solid-liquid equilibria and triple points of n-6 Lennard-Jones
fluids. J. Chem. Phys. 131, 174504. Erratum: J. Chem. Phys. 133, 229902 (2010).
Ahmed, A., Sadus, R.J., 2009b. Phase diagram of the Weeks-Chandler-Andersen potential from
very low to high temperatures and pressures. Phys. Rev. E 80, 061101. Erratum: Phys. Rev.
E 80, 029901 (2019).
Ahmed, A., Sadus, R.J., 2010. Effect of potential truncations and shifts on the solid-liquid phase
coexistence of Lennard-Jones fluids. J. Chem. Phys. 133, 124515.
Alder, B.J., Wainwright, T.E., 1962. Phase transition in elastic disks. Phys. Rev. 127, 359361.
Amar, J.G., 1989. Application of the Gibbs ensemble to the study of fluid-fluid phase equilib￾rium in a binary mixture of symmetric non-additive hard spheres. Mol. Phys. 67, 739745.
Attwood, B.C., Hall, C.K., 2008. Solid-liquid phase behavior of ternary mixtures. AIChE J. 54,
18861894.
Baranyai, A., Cummings, P.T., 1996. On the molecular dynamics algorithm for Gibbs ensemble
simulation. Mol. Sim. 17, 2125.
Barhaghi, M.S., Mick, J.R., Potoff, J.J., 2017. Optimised Mie potentials for phase equilibria:
application to alkynes. Mol. Phys. 115, 13781388.
Bennett, C.H., 1976. Efficient estimation of free energy differences from Monte Carlo data.
J. Comput. Phys. 22, 245268.
Bergermann, A., French, Redmer, R., 2021a. Gibbs-ensemble Monte Carlo simulation of H2-
H2O. Phys. Chem. Chem. Phys. 23, 1263712643.
Bergermann, A., French, M., Scho¨ttler, M., Redmer, R., 2021b. Gibbs-ensemble Monte Carlo
simulation of H2-He mixtures. Phys. Rev, E. 103, 013307.
Bhanot, G., Black, S., Carter, P., Salvador, R., 1987a. A new method for the partition function
of discrete systems with applications to the 3D Ising model. Phys. Lett. B 183, 331336.
Bhanot, G., Bitar, K., Black, S., Carter, P., Salvador, R., 1987b. The partition function of Z(2)
and Z(8) lattice gauge theory in four dimensions: a novel approach to simulations of lattice
systems. Phys. Lett. B 187, 381386.
Bhanot, G., Bitar, K., Salvador, R., 1987c. On solving four-dimensional SU(2) gauge theory by
numerically finding its partition function. Phys. Lett. B 188, 246252.
Bhanot, G., Salvador, R., Black, S., Carter, P., Toral, R., 1987d. Accurate estimate of ν for the
three-dimensional Ising model from a numerical measurement of its partition function. Phys.
Rev. Lett. 59, 803806.
Molecular simulation of phase equilibria Chapter | 10 395Bianco, V., Franzese, G., 2014. Critical behavior of a water monolayer under hydrophobic con￾finement. Sci. Rep. 4, 4440.
Binder, K., 2010. Computer simulations of critical phenomena and phase behavior of fluids.
Mol. Phys. 108, 17971815.
Boda, D., Liszi, J., Szalai, I., 1995a. An extension of the NpT plus test particle method for the
determination of the vapour-liquid equilibria of pure fluids. Chem. Phys. Lett. 235,
140145.
Boda, D., Liszi, J., Szalai, I., 1995b. Dielectric constant of a Stockmayer fluid along the vapour￾liquid coexistence curve. Mol. Phys. 85, 429444.
Boda, D., Liszi, J., Szalai, I., 1996. A new simulation method for the determination of the
vapour-liquid equilibria in the grand canonical ensemble. Chem. Phys. Lett. 256, 474482.
Boda, D., Chan, K.-Y., Szalai, I., 1997. Determination of vapour-liquid equilibrium using cavity￾biased grand canonical Monte Carlo method. Mol. Phys. 92, 10671072.
Boulougouris, G.C., Peristeras, L.D., Economou, I.G., Theodorou, D.N., 2010. J. Suprcrit. Fluids
55, 503509.
Briano, J.G., Glandt, E.D., 1984. Statistical thermodynamics of polydisperse fluids. J. Chem.
Phys. 80, 33363343.
Brilliantov, N.V., Valleau, J.P., 1998a. Thermodynamic scaling Monte Carlo study of the liquid￾gas transition in the square-well fluid. J. Chem. Phys. 108, 11151122.
Brilliantov, N.V., Valleau, J.P., 1998b. Effective Hamiltonian analysis of fluid criticality and
application to the square-well fluid. J. Chem. Phys. 108, 11231130.
Bruce, A.D., 1997. Finite-size critical behavior in the Gibbs ensemble. Phys. Rev. E 55,
23152320.
Bruce, A.D., Wilding, N.B., 2003. Computational strategies for mapping equilibrium phase dia￾grams. Adv. Chem. Phys. 127, 164.
Caillol, J.M., 1998. Critical-point of the Lennard-Jones fluid: a finite-size scaling study. J.
Chem. Phys. 109, 48854893.
Camp, P.J., Allen, M.P., 1996. Phase coexistence in a pseudo Gibbs ensemble. Mol. Phys. 88,
14591469.
Chang, J., Lenhoff, A.M., Sandler, S.I., 2004. Determination of fluid-solid transitions in model
protein solutions using the histogram rewighting method and expanded ensemble simula￾tions. J. Chem. Phys. 120, 30033014.
Chapela, G.A., Martinez-Casas, S.E., Varea, C., 1987. Square well orthobaric densities via spi￾nodal decomposition. J. Chem. Phys. 86, 56835688.
Chou, C.-Y., Vo, T.T.M., Panagiotopoulos, A.Z., Robert, M., 2006. Phys. A 369, 275290.
Conrad, P.B., de Pablo, J.J., 1998. Comparison of histogram reweighting techniques for a flexi￾ble water model. Fluid Phase Equilib. 150, 5161.
Crawford, R.K., 1977. Melting, vaporization and sublimation. In: Klein, M.L., Venables, J.A.
(Eds.), Rare Gas Solids, Vol. 2. Academic Press, London, pp. 663728.
Das, S.K., 2015. Atomistic simulations of liquid-liquid coexistence in confinement: comparison
of thermodynamics and kinetics with bulk. Mol. Sim. 41, 382401.
de Miguel, E., 1997. Critical behavior of the square-well fluid with λ 5 2: a finite-size-scaling
study. Phys. Rev. E 55, 13471354.
de Miguel, E., Rull, L.F., Chalam, M.K., Gubbins, K.E., 1990. Liquid-vapour coexistence of the
Gay-Berne fluid by Gibbs-ensemble simulation. Mol. Phys. 71, 12231231.
de Pablo, J.J., Prausnitz, J.M., 1989. Phase equilibria for fluid mixtures from Monte Carlo simu￾lation. Fluid Phase Equilib. 53, 177189.
396 Molecular Simulation of Fluidsde Pablo, J.J., Yann, Q., Escobedo, F.A., 1999. Simulation of phase transitions in fluids. Annu.
Rev. Phys. Chem. 50, 377411.
Deiters, U.K., Sadus, R.J., 2019. Fully a priori prediction of the vapor-liquid equilibria of Ar,
Kr, and Xe from ab initio two-body plus three-body interatomic potentials. J. Chem. Phys.
151, 034509.
Deiters, U.K., Sadus, R.J., 2021. Interatomic interactions responsible for the solid-liquid and
vapor-liquid phase equilibria of neon. J. Phys. Chem. B 125, 85228531.
Deiters, U.K., Sadus, R.J., 2022a. First-principles determination of the solid-liquid-vapor triple
point: the noble gases. Phys. Rev. E. 105, 054128.
Deiters, U.K., Sadus, R.J., 2022b. Accurate determination of solid-liquid equilibria by molecular
simulation: behavior of Ne, Ar, Kr, and Xe from low to high pressures. J. Chem. Phys. 157,
204504.
Denbigh, K., 1961. Principles of Chemical Equilibrium. Cambridge University Press,
Cambridge.
Dinpajooh, M., Bai, P., Allan, D.A., Siepmann, J.I., 2015. Accurate and precise determination of
critical properties from Gibbs ensemble Monte Carlo simulations. J. Chem. Phys. 143,
114113.
Eike, D.M., Brennecke, J.F., Maginn, E.J., 2005. Toward a robust and general molecular simula￾tion method for computing solid-liquid coexistence. J. Chem. Phys. 122, 014155.
Errington, J.R., Panagiotopoulos, A.Z., 1998a. Phase equilibria of the modified Buckingham
exponential-6 potential from Hamiltonian scaling grand canonical Monte Carlo. J. Chem.
Phys. 109, 10931100.
Errington, J.R., Panagiotopoulos, A.Z., 1998b. A fixed point charge model for water optimized
to vapor-liquid coexistence properties. J. Phys. Chem. B 102, 74707475.
Errington, J.R., Kiyohara, K., Gubbins, K.E., Panagiotopoulos, A.Z., 1998. Monte Carlo simula￾tion of high-pressure phase equilibria in aqueous systems. Fluid Phase Equilib. 150, 3340.
Escobedo, F.A., 1998. Novel pseudoensembles for simulation of multicomponent phase equilib￾ria. J. Chem. Phys. 108, 87618772.
Escobedo, F.A., de Pablo, J.J., 1997. Pseudo-ensemble simulations and Gibbs-Duhem integra￾tions for polymers. J. Chem. Phys. 106, 29112923.
Eslami, H., Mu¨ller-Plathe, F., 2007. Molecular dynamics simulation in grand canonical ensem￾ble. J. Comput. Chem. 28, 17631773.
Falcioni, M., Marinari, E., Paciello, M.L., Parisi, G., Taglienti, B., 1982. Complex zeros in the
partition function of the four-dimensional SU(2) lattice gauge model. Phys. Lett. B 108,
331332.
Fantoni, R., Moroni, S., 2014. Quantum Gibbs ensemble Monte Carlo. J. Chem. Phys. 141,
114110.
Fartaria, R.P.S., Silva Fernades, F.M.S., Freitas, F.F.M., Rodrigues, P.C.R., 2001. Phase behavior
of C60 by computer simulation using ab-initio interaction potential. Int. J. Quant. Chem. 84,
375387.
Fartaria, R.P.S., Silva Fernades, F.M.S., Freitas, F.F.M., 2002. Monte Carlo simulation of the
phase diagram of C-60 using two interaction potentials. Enthalpies of sublimation. J. Chem.
Phys. B 106, 1022710232.
Ferrenberg, A.M., Swendsen, R.H., 1988. New Monte Carlo technique for studying phase transi￾tions. Phys. Rev. Lett. 61, 26352638.
Ferrenberg, A.M., Swendsen, R.H., 1989. Optimized Monte Carlo data analysis. Phys. Rev. Lett.
63, 11951198.
Molecular simulation of phase equilibria Chapter | 10 397Francesconi, A.Z., Kritische Kurve, Phasengleichewichte und PVT-Daten im System Methanol￾Methan bis 3 bar und 240C, Doctoral thesis (University of Karlsruhe, Germany, 1978).
Frenkel, D., 1986. In: Ciccotti, G., Hoover, W.G. (Eds.), Molecular Dynamics Simulation of
Statistical Mechanical Systems. North-Holland, Amsterdam.
Frenkel, D., Smit, B., 2023. Understanding Molecular Simulation. From Algorithms to
Applications, third ed. Academic Press, San Diego.
Galbraith, A.L., Hall, C.K., 2007. Solid-liquid phase equilibria for mixtures containing diatomic
Lennard-Jones molecules. Fluid Phase Equilib. 262, 113.
Ge, J., Wu, G.-W., Todd, B.D., Sadus, R.J., 2003. Equilibrium and nonequilibrium molecular
dynamics methods for determining solid-liquid phase coexistence at equilibrium. J. Chem.
Phys. 119, 1101711023.
Go´zd´ z, W.T., 2003. Critical-point and coexistence curve properties of a symmetric mixture of ´
nonadditive hard spheres: a finite size scaling study. J. Chem. Phys. 119, 33093315.
Go´zd´ z, W.T., 2017. Investigation of fluid-fluid and solid-solid phase separation of symmetric ´
nonadditive hard spheres at high density. Langmuir 23, 1172711732.
Graham, I.S., Valleau, J.P., 1990. A Monte Carlo study of the coexistence region of the
restricted primitive model. J. Phys. Chem. 94, 78947898.
Gromov, D.G., de Pablo, J.J., Luna-Barcenas, G., Sanchez, I.C., Johnston, K.P., 1998. ´
Simulation of phase equilibria for polymer-supercritical mixtures. J. Chem. Phys. 108,
46474653.
Gubbins, K.E., 1989. The role of computer simulation in studying fluid phase equilibria. Mol.
Sim. 2, 223252.
Gubbins, K.E., 1994. In: Sandler, S.I. (Ed.), Models for Thermodynamic and Phase Equilibria
Calculations. Marcel Dekker, New York.
Gubbins, K.E., Shing, K.S., Streett, W.B., 1983. Fluid phase equilibria: computer simulation,
and theory. J. Phys. Chem. 87, 45734585.
Hansen, J.P., Verlet, L., 1969. Phase transitions of the Lennard-Jones system. Phys. Rev. 184,
151161.
Hentschke, R., Bast, T., Aydt, E., Kotelyanskii, M., 1996. Gibbs-ensemble molecular dynamics:
a new method for simulations involving particle exchange. J. Mol. Model. 2, 319326.
Hitchcock, M.R., Hall, C.K., 1999. Solid-liquid phase equilibrium for binary Lennard-Jones mix￾tures. J. Chem. Phys. 110, 1143311444.
Hoover, W.G., Ree, F.H., 1967. Use of computer experiments to locate the melting transition
and calculate the entropy in the solid phase. J. Chem. Phys. 47, 48734878.
Hynninen, A.-P., Dijkstra, M., Panagiotopoulos, A.Z., 2005. Critical point of electrolyte mix￾tures. J. Chem. Phys. 123, 084903.
Jagannathan, K., Yethiraj, A., 2005. Dynamics of fluids near the consolute critical point: a
molecular-dynamics study of the Widom-Rowlinson mixture. J. Chem. Phys. 122, 244506.
Johnson, J.K., Panagiotopoulos, A.Z., Gubbins, K.E., 1994. Reactive canonical Monte Carlo: a
new simulation technique for reacting or associating fluids. Mol. Phys. 81, 717733.
Jungblut, S., Binder, K., Schilling, T., 2008. Isotropic-isotopic phase separation in mixtures of
rods and spheres: some aspects of Monte Carlo simulation in the grand canonical ensemble.
Comput. Phys. Commun. 179, 1316.
Kamath, G., Potoff, J.J., 2006. Monte Carlo predictions for the phase behavior of the H2S 1 n￾alkane, H2S 1 CO2, CO2 1 CH4 and H2S 1 CO2 1 CH4 mixtures. Fluid Phase Equilib. 246,
7178.
Kim, Y.C., Fisher, M.E., Luijten, E., 2003. Precise simulation of near-critical fluid coexistence.
Phys. Rev. Lett. 91, 065701.
398 Molecular Simulation of FluidsKiyohara, K., Spyriouni, T., Gubbins, K.E., Panagiotopoulos, A.Z., 1996. Thermodynamic scal￾ing Gibbs ensemble Monte Carlo: a new method for determination of phase coexistence
properties of fluids. Mol. Phys. 89, 965974.
Kiyohara, K., Gubbins, K.E., Panagiotopoulos, A.Z., 1997. Phase coexistence properties of
polarizable Stockmayer fluids. J. Chem. Phys. 106, 33383347.
Kiyohara, K., Gubbins, K.E., Panagiotopoulos, A.Z., 1998. Phase coexistence properties of
polarizable water models. Mol. Phys. 94, 803808.
Kofke, D.A., 1993a. Gibbs-Duhem integration: a new method for direct evaluation of phase
coexistence by molecular simulation. Mol. Phys. 78, 13311336.
Kofke, D.A., 1993b. Direct evaluation of phase coexistence by molecular simulation via integra￾tion along the saturation line. J. Chem. Phys. 98, 41494162.
Kofke, D.A., Glandt, E.D., 1988. Monte Carlo simulation of multicomponent equilibria in a
semigrand canonical ensemble. Mol. Phys. 64, 1105-1031.
Kotelyanskii, M.J., Hentschke, R., 1995. Gibbs-ensemble molecular dynamics: liquid-gas equi￾librium in a Lennard-Jones system. Phys. Rev. E 51, 51165119.
Kotelyanskii, M.J., Hentschke, R., 1996. Gibbs-ensemble molecular dynamics: liquid-gas equi￾libria for Lennard-Jones spheres and n-hexane. Mol. Sim. 17, 95112.
Kowalczyk, P., Gauden, P.A., Terzyk, A.P., Pantatosaki, E., Papadopoulos, G.K., 2013. J. Chem.
Theory Comput. 9, 29222929.
Kristo´f, T., Liszi, J., 1998. Alternative Gibbs ensemble Monte Carlo implementations: applica￾tion in mixtures. Mol. Phys. 94, 519525.
Kristo´f, T., Liszi, J., 2001. Phase coexistence and critical point determination in polydisperse
fluids. Mol. Phys. 99, 167173.
Kronome, G., Szalai, I., Wendland, M., Fischer, J., 2000. Extension of the NpT 1 test particle
method for the calculation of phase equilibria of nitrogen1 ethane. J. Mol. Liq. 85, 237247.
Kumar, S.K., 1992. A modified real particle method for the calculation of the chemical poten￾tials of molecular systems. J. Chem. Phys. 97, 35503556.
Kuznetsova, T., Kvamme, B., 2005. Grand canonical molecular dynamic simulations for polar
systems. Chem. Eng. Commun. 192, 189197.
Lamm, M.H., Hall, C.K., 2001. Molecular simulation of complete phase diagrams for binary
mixtures. AIChE J. 47, 16641675.
Lamm, M.H., Hall, C.K., 2002. Equilibria between solid, liquid, and vapor phases in binary
Lennard-Jones mixtures. Fluid Phase Equilib. 194197, 197206.
Lenart, P.J., Panagiotopoulos, A.Z., 2006. Tracing the critical loci of binary fluid mixtures using
molecular simulation. J. Phys. Chem. B 110, 1720017206.
Lentz, H., 1969. A method of studying the behavior of fluid phases at high pressures and tem￾peratures. Rev. Sci. Intstrum. 40, 371372.
Lentz, H., Franck, E.U., 1969. Das System Water-Argon bei hohen Drucken und Temperaturen.
Ber. Busnen-Ges. Physik. Chem. 73, 2835.
Lidmar, J., 2012. Improving the efficiency of extended ensemble simulations: the accelerated
weight histogram method. Phys. Rev. E 85, 056708.
L´ısal, M., Vacek, V., 1996a. Direct evaluation of vapour-liquid equilibria by molecular dynamics
using Gibbs-Duhem integration. Mol. Sim. 17, 2739.
L´ısal, M., Vacek, V., 1996b. Direct evaluation of vapour-liquid equilibria of mixtures by molec￾ular dynamics using Gibbs-Duhem integration. Mol. Sim. 18, 7599.
L´ısal, M., Vacek, V., 1997. Direct evaluation of solid-liquid equilibria by molecular dynamics
using Gibbs-Duhem integration. Mol. Sim. 19, 4361.
Molecular simulation of phase equilibria Chapter | 10 399Lo, C., Palmer, B., 1995. Alternative Hamiltonian for molecular dynamics simulations in the
grand canonical ensemble. J. Chem. Phys. 102, 925931.
Losey, J., Sadus, R.J., 2019. Thermodynamic properties and anomalous behavior of double￾Gaussian core model potential fluids. Phys. Rev. E 100, 012112.
Lotfi, A., Vrabec, J., Fischer, J., 1992. Vapour liquid equilibria of the Lennard-Jones fluid from
the NpT 1 test particle method. Mol. Phys. 76, 13191333.
Marcelli, G., Sadus, R.J., 1999. Molecular simulation of the phase behavior of noble gases using
accurate two-body and three-body intermolecular potentials. J. Chem. Phys. 111, 15331540.
Marcelli, G., Sadus, R.J., 2001. Three-body interactions and the phase equilibria of mixtures.
High. Temp.-High-Press 33, 111118.
Marinari, E., 1984. Complex zeroes of the d 5 3 Ising model: finite-size scaling and critical
amplitudes. Nucl. Phys. B 235, 123134.
Mart´ın-Betancourt, M., Romero-Enrique, J.M., Rull, L.F., 2009. Finite-size scaling study of the
liquid-vapour critical point of dipolar square-well fluids. Mol. Phys. 107, 563570.
Mausbach, P., Ahmed, A., Sadus, R.J., 2009. J. Chem. Phys. 131, 184507. Erratum: J. Chem.
Phys. 132, 019901 (2010).
McDonald, I.R., Singer, K., 1967. Calculation of thermodynamic properties of liquid argon from
Lennard-Jones parameters by a Monte Carlo method. Discuss. Faraday Soc. 43, 4049.
Mehta, M., Kofke, D.A., 1994. Coexistence diagrams of mixtures by molecular simulation.
Chem. Eng. Sci. 49, 26332645.
Mehta, M., Kofke, D.A., 1995. Molecular simulation in a pseudo grand canonical ensemble.
Mol. Phys. 86, 139147.
Mick, J.R., Barhahi, M.S., Jackman, B., Rushaidat, K., Schwiebert, L., Potoff, J.J., 2015.
Optimized Mie potentials for phase equlibria: Apllication to noble gases and their mixtures
with n-alkanes. J. Chem. Phys. 143, 114504.
Mo¨ller, D., Fischer, J., 1990. Vapour liquid equilibrium of a pure fluid from test particle method
in combination with NpT molecular dynamics simulations. Mol. Phys. 69, 463473.
Nam, H.-S., Mendelev, M.I., Srolocitz, D.J., 2007. Solid-liquid phase diagrams for binary metal￾lic alloys: adjustable interatomic potentials. Phys. Rev. B 75, 014204.
Okumura, H., Yonezawa, F., 2000. Liquid-vapor coexistence curves of several interatomic model
potentials. J. Chem. Phys. 113, 91629168.
Okumura, H., Yonezawa, F., 2001. Method for liquid-vapor coexistence curves by test-particle
insertions in the canonical ensemble. J. Non-Cryst. Solids 293295, 715718.
Orkoulas, G., Panagiotopoulos, A.Z., 1996. Phase diagram of the two-dimensional Coulomb gas:
a thermodynamic scaling Monte Carlo study. J. Chem. Phys. 104, 72057209.
Pahl, E., Calvo, F., Koci, L., Schwerdtfeger, P., 2008. Accurate melting temperatures for neon and ˇ
argon from ab inito Monte Carlo Simulations. Angew. Chem. Int. Ed. 47, 82078210 (2008).
Palmer, B.J., Lo, C., 1994. Molecular dynamics implementation of the Gibbs ensemble calcula￾tion. J. Chem. Phys. 101, 1089910907.
Panagiotopoulos, A.Z., 1987. Direct determination of phase coexistence properties of fluids by
Monte Carlo simulation in a new ensemble. Mol. Phys. 61, 813826 (1987).
Panagiotopoulos, A.Z., 1992a. Direct determination of fluid phase equilibria by simulation in the
Gibbs ensemble: a review. Mol. Sim. 9, 123.
Panagiotopoulos, A.Z., 1992b. Molecular simulation of fluid-phase equilibria: simple, polymeric
and ionic fluids. Fluid Phase Equilib. 76, 97112.
Panagiotopoulos, A.Z., 2000. Monte Carlo methods for phase equilibria of fluids. J. Phys.:
Condens. Matt. 12, R25R52.
400 Molecular Simulation of FluidsPanagiotopoulos, A.Z., Quirke, N., Stapleton, M., Tildesley, D.J., 1988. Phase equilibria by sim￾ulation in the Gibbs ensemble: alternative derivation, generalization and application to mix￾ture and membrane equilibria. Mol. Phys. 63, 527545.
Panagiotopoulos, A.Z., Wong, V., Floriano, M.A., 1998. Phase equilibria of lattice polymers
form histogram reweighting Monte Carlo simulations. Macromolecules 31, 912918.
Pe´rez-Pellitero, J., Ungerer, P., Orkoulas, G., Mackie, A.D., 2006. Critical point estimation of
the Lennard-Jones pure fluid and binary mixtures. J. Chem. Phys. 125, 054515.
Plackov, Ð., Sadus, R.J., 1997. Molecular simulation of intermolecular attraction and repulsion ˇ
in coexisting liquid and vapour phases. Fluid Phase Equilib. 134, 7795.
Poison, J.M., Frenkel, D., 1998. Calculation of solid-fluid phase equilibria for systems of chain
molecules. J. Chem. Phys. 109, 318328.
Potoff, J.J., Kamath, G., 2014. Mie potentials for phase equilibria: applications to alkenes.
J. Chem. Eng. Data 59, 31443150.
Potoff, J.J., Panagiotopoulos, A.Z., 1998. Critical point and phase behavior of the pure fluid and
a Lennard-Jones mixture. J. Chem. Phys. 109, 1091410920.
Raabe, G., Sadus, R.J., 2003. Molecular simulation of the vapor-liquid coexistence of mercury.
J. Chem. Phys. 119, 66916697.
Raabe, G., Sadus, R.J., 2007. Influence of bond flexibility on the vapor-liquid phase equilibria
of water. J. Chem. Phys. 126, 044701.
Rahbari, A., Hens, R., Ramdin, M., Moultos, O.A., Dubbeldam, D., Vlugt, T.J.H., 2021. Recent
advances in the continuous fractional component Monte Carlo methodology. Mol. Sim. 47,
804823.
Ricci, F., Debenedetti, P.G., 2017. A free energy study of the liquid-liquid phase transition of
the Jagla two-scale potential. J. Chem. Sci. 129, 801823.
Rowley, R.L., Shupe, T.D., Schuck, M.W., 1994. A direct method for determination of chemical
potential with molecular dynamics simulation. 1. Pure components. Mol. Phys. 82, 841855.
Rowley, R.L., Schuck, M.W., Perry, J.C., 1995. A direct method for determination of
chemical potential with molecular dynamics simulations. Part 2. Mixtures. Mol. Phys.
86, 125137.
Rowlinson, J.S., Widom, B., 1982. Molecular Theory of Capillarity. Clarendon Press, Oxford.
Rudisill, E.N., Cummings, P.T., 1989. Gibbs ensemble simulation of phase equilibrium in the
hard core two-Yukawa fluid for the Lennard-Jones fluid. Mol. Phys. 68, 629635.
Rżysko, W., Boro´wko, M., 2011. A critical behavior of the Lennard-Jones dimeric fluid in two￾dimensions. A Monte Carlo study. Surf. Sci. 605, 12191223.
Sadus, R.J., 1996a. Molecular simulation of the vapour-liquid equilibria of pure fluids and binary
mixtures containing dipolar components: the effect of Keesom interactions. Mol. Phys. 87,
979990.
Sadus, R.J., 1996b. Molecular simulation of the liquid-liquid equilibria of binary mixtures con￾taining dipolar and non-polar components interacting via the Keesom potential. Mol. Phys.
89, 11871194.
Sadus, R.J., 1997. Molecular simulation of Henry’s constant at vapor-liquid and liquid-liquid
phase boundaries. J. Phys. Chem. B. 101, 38343838.
Sadus, R.J., 1998a. Exact calculation of the effect of three-body Axilrod-Teller interactions on
vapour-liquid phase coexistence. Fluid Phase Equilib. 144, 351359.
Sadus, R.J., 1998b. Effect of three-body interactions between dissimilar molecules on the phase
behaviour of binary mixtures: the transition from vapor-liquid equilibria to type III behav￾iour. Ind. Eng. Chem. Res. 37, 29772982.
Molecular simulation of phase equilibria Chapter | 10 401Sadus, R.J., 1999. Molecular simulation of the phase behaviour of ternary fluid mixtures: the
effect of a third component on vapour-liquid and liquid-liquid coexistence. Fluid Phase
Equilib. 157, 169180.
Sadus, R.J., 2012. Molecular simulation of the phase behavior of fluids and fluid mixtures using
the synthetic method. J. Chem. Phys. 137, 054507.
Sadus, R.J., 2020a. Vapor-liquid equilibria and cohesive r24 interactions. J. Chem. Phys. 153,
204504.
Sadus, R.J., 2020b. Effect of the range of particle cohesion on the phase behavior on thermody￾namic properties of fluids. J. Chem. Phys. 153, 244502.
Sadus, R.J., 2020c. Combining intermolecular potentials for the prediction of fluid properties:
two-body and three-body interactions. J. Chem. Phys. 153, 214509.
Salsburg, Z.W., Jackson, J.D., Fickett, W., Wood, W.W., 1959. Application of the Monte Carlo
method to the lattice-gas model. I. Two-dimensional triangular lattice. J. Chem. Phys. 30, 6572.
Shen, V.K., Errington, J.R., 2005. Determination of fluid-phase behavior using transition-matrix
Monte Carlo: Binary Lennard-Jones mixtures. J. Chem. Phys. 122, 064508.
Shi, W., Johnson, J.K., 2001. Histogram reweighting and finite-size scaling study of the
Lennard-Jones fluids. Fluid Phase Equilib. 187188, 171191.
Shi, W., Maginn, E.J., 2008. Improvement in molecule exchange efficiency in Gibbs ensemble
Monte Carlo: development and implentation of the continuous fractional component move.
J. Comput. Chem. 29, 25202530.
Shing, K.S., Gubbins, K.E., 1982. The chemical potential in dense fluids and fluid mixtures via
a computer simulation. Mol. Phys. 46, 11091128.
Silva Fernandes, F.M.S., Fartaria, R.P.S., 2015. Gibbs ensemble Monte Carlo. Amr. J. Phys. 83,
809816.
Singh, S.K., 2018. Critical temperature estimation of bulk and confined atomic fluid using
vapour-liquid interfacial free energy. Mol. Sim. 44, 156163.
Singh, A.N., Dyre, J.C., Pedersen, U.R., 2021. Solid-liquid coexistence of neon, argon, krypton
and xenon studied by simulations. J. Chem. Phys. 154, 134501.
Smit, B., 1992. In: Allen, M.P., Tildesley, D.J. (Eds.), Computer Simulation in Chemical
Physics. Kluwer, Dordrecht.
Smit, B., Frenkel, D., 1989. Calculation of the chemical potential in the Gibbs ensemble. Mol.
Phys. 68, 951958.
Smit, B., Williams, C.P., Hendriks, E.M., de Leeuw, S.W., 1989. Vapour-liquid equilibria for
Stockmayer fluids. Mol. Phys. 68, 765769.
Smith, W.R., Triska, B., 1994. The reaction ensemble method for the computer simulation of chemi￾cal and phase equilibria. I. Theory and basic examples. J. Chem. Phys. 100, 30193027.
Sokhan, V.P., 1997. The chemical potential of dense liquids by the couples test particle method.
Mol. Sim. 19, 181204.
Soto-Campos, G., Corti, D.S., Reiss, H., 1998. A small system grand ensemble method for the
study of hard-particle systems. J. Chem. Phys. 108, 25632570.
Stapleton, M.R., Tildesley, D.J., Quirke, N., 1990. Phase equilibria in polydisperse fluids.
J. Chem. Phys. 92, 44564467.
Sweatman, M.B., Quirke, N., 2004. Simulating fluid-solid equilibrium with the Gibbs ensemble.
Mol. Sim. 30, 2328.
Swope, W.C., Andersen, H.C., 1995. A computer simulation method for the calculation of chem￾ical potentials of liquids and solids using the bicanonical ensemble. J. Chem. Phys. 102,
28512863.
402 Molecular Simulation of FluidsSzalai, I., Liszi, J., Boda, D., 1995. The NVT plus test particle method for the determination of
the vapour-liquid equilibria of pure fluids. Chem. Phys. Lett. 246, 214220.
Torrie, G.M., Valleau, J.P., 1974. Monte Carlo free energy estimates using non-Boltzmann sam￾pling: application to the sub-critical Lennard-Jones fluid. Chem. Phys. Lett. 28, 578581.
Torrie, G.M., Valleau, J.P., 1977. Monte Carlo study of a phase-separating mixture by umbrella
sampling. J. Chem. Phys. 66, 14021408.
Tsang, P.C., White, O.N., Perigard, B.Y., Vega, L.F., Panagiotopoulos, A.Z., 1995. Phase equi￾libria in ternary Lennard-Jones systems. Fluid Phase Equilib. 107, 3143.
Valleau, J.P., 1991. Density-scaling: a new Monte Carlo technique in statistical mechanics.
J. Comput. Phys. 96, 193216.
Valleau, J.P., 1993. Density-scaling Monte Carlo study of subcritical Leannard-Jonesium.
J. Chem. Phys. 99, 47184728.
Valleau, J.P., 1998. Number-dependence concerns in Gibbs-ensemble Monte Carlo. J. Chem.
Phys. 108, 29622966.
Valleau, J.P., 2003. A thermodynamic-scaling study of Gibbs-ensemble Monte Carlo. Mol. Sim.
29, 627642.
Valleau, J.P., 2005a. Temperature-and-density-scaling Monte Carlo: methodology and the canon￾ical thermodynamics of Lennard-Jonesium. Mol. Sim. 31, 223253.
Valleau, J.P., 2005b. Temperature-and-density-scaling Monte Carlo: isothermal-isobaric thermo￾dynamics of Lennard-Jonesium. Mol. Sim. 31, 255275.
Valleau, J.P., Card, D.N., 1972. Monte Carlo estimation of the free energy by multistate sam￾pling. J. Chem. Phys. 57, 54575462.
van ‘t Hof, A., de Leeuw, S.W., Peters, C.J., 2006a. An advanced Gibbs-Duhem integration
method: theory and applications. J. Chem. Phys. 124, 054906.
van ‘t Hof, A., de Leeuw, S.W., Peters, C.J., 2006b. Computing the starting state for Gibbs￾Duhem integration. J. Chem. Phys. 124, 054905.
van Leeuwen, M.E., Peters, C.J., de Swaan Arons, J., Panagiotopoulos, A.Z., 1991. Investigation
of the transition to liquid-liquid immiscibility for Lennard-Jones (12,6) systems using
Gibbs-ensemble molecular simulations. Fluid Phase Equilib. 66, 5775.
Vega, L., de Miguel, E., Rull, L.F., Jackson, G., McLure, I.A., 1992. Phase equilibria and critical
behavior of square-well fluids of variable width by Gibbs ensemble Monte Carlo simulation.
J. Chem. Phys. 96, 22962305.
Vega, L.F., Shing, K.S., Rull, L.F., 1994. A new algorithm for molecular dynamics simulations
in the grand canonical ensemble. Mol. Phys. 82, 439453.
Vlasiuk, M., Sadus, R.J., 2017. Predicting vapour-liquid phase equilibria with augmented ab
initio interatomic potentials. J. Chem. Phys. 146, 244504.
Vlasiuk, M., Frascoli, F., Sadus, R.J., 2016. Molecular simulation of the thermodynamic, struc￾tural, and vapor-liquid equilibrium properties of neon. J. Chem. Phys. 145, 104501.
Vogt, P.S., Liapine, E., Kirchner, B., Dyson, A.J., Huber, H., Marcelli, G., Sadus, R.J., 2001.
Molecular simulation of the vapour-liquid phase coexistence of neon and argon using ab
initio potentials. Phys. Chem. Chem. Phys. 3, 12971302.
Vrabec, J., Gross, J., 2008. Vapor-liquid equilibria simulations and an equation of state contribu￾tion for dipole-quadrupole interactions. J. Phys. Chem. B 112, 5160.
Vrabec, J., Lofti, A., Fischer, J., 1995. Vapour liquid equilibria of Lennard-Jones model mixtures
from the NpT plus test particle method. Fluid Phase Equilib. 112, 173197.
Wang, L., Sadus, R.J., 2006a. Effect of three-body interactions on the vapor-liquid phase equilib￾ria of binary fluid mixtures. J. Chem. Phys. 125, 074503.
Molecular simulation of phase equilibria Chapter | 10 403Wang, L., Sadus, R.J., 2006b. Three-body interactions and solid-liquid phase equilibria: applica￾tion of a molecular dynamics algorithm. Phys. Rev. E 74, 031203.
Widom, B., 1963. Some topics in the theory of fluids. J. Chem. Phys. 39, 28082812.
Wilding, N.B., 1995. Critical-point and coexistence-curve properties of the Lennard-Jones fluid:
a finite-size scaling study. Phys. Rev. E 52, 602611.
Wilding, N.B., 1997. Simulation studies of fluid critical behaviour. J. Phys.: Condens. Matter 9,
585612.
Wilding, N.B., Binder, K., 1996. Finite-size scaling for near-critical continuum fluids at constant
pressure. Phys. A 231, 439477.
404 Molecular Simulation of FluidsChapter 11
Molecular simulation and
object-orientation
In common with most scientific or engineering programming applications,
molecular simulation algorithms have been traditionally coded in procedural
languages such as FORTRAN or C that emphasize the decomposition of a
problem into various functions. Confronted with a problem to solve, a proce￾dural language programmer typically performs a functional analysis, decom￾posing the problem into several composite algorithms that are implemented
as either subroutines or functions. This algorithm-centered approach is a nat￾ural choice for problem solving for many scientific applications, and it usu￾ally works well. When used properly, modern procedural languages allow
the programmer to write modularized code that can be easily reused, chan￾ged, and minimize errors. However, software developers are moving increas￾ingly away from the procedural approach in favor of object-orientation
(OO). In contrast to the procedural approach involving a set of functions
sharing a global state, OO uses a set of interacting individual objects with
their own private states. When used properly, OO offers enhanced flexibility
in code design, error minimization, and software that can be more easily
adapted to meet new situations and challenges (Amorsy et al., 2013).
At the outset, it should be emphasized that functional design and OO are
complementary approaches. It is possible to include elements of OO in a pro￾cedural language. For example, two features of OO are information hiding
and encapsulation. Information hiding in a procedural language such as C
can be achieved via the use of library interfaces, and structures can be
employed to encapsulate related variables together. Similarly, the structured
programming strategies that are essential in good procedural code are also
necessary to write good code for the methods contained in objects. In a
sense, OO is an evolution from the procedural approach rather than a revolu￾tionary step. Khan et al. (1995) have provided a detailed comparison of the
similarities and differences between structural programming and OO.
The OO approach offers significant benefits for the development of
molecular simulation codes, particularly for simulations involving compli￾cated molecules. Historically, the priority for molecular simulation codes has
been overwhelming computational efficiency. There is an ever increasing
405 Molecular Simulation of Fluids. DOI: https://doi.org/10.1016/B978-0-323-85398-9.00010-1
© 2024 Elsevier B.V. All rights reserved.interest in studying complicated molecules such as proteins and massive poly￾mers. Apart from the computational difficulties involved in modeling compli￾cated molecules, the structured programming approach alone is not ideally
suited to meet the challenge of increasing molecular complexity. Converting a
procedure-based program developed for simulating atoms to work for protein
molecules is a daunting task. It may involve the development of new algorithms
which, in part, are likely to be motivated by the limitation imposed by the struc￾tured programming approach rather than the molecule itself. It can be argued
that the features of structured programming have partly dictated the nature of
some molecular simulation algorithms. In contrast, OO has features, which can
make the task much less daunting by promoting code reuse. Nelson et al. (1996)
have discussed a parallel implementation of molecular dynamics (MD) using
OO. Baekdal et al. (1996) have discussed the use of OO in protein dynamics.
The OO approach forms the basis of commonly used open source molecular
simulation software packages (Abraham et al., 2015; Phillips et al., 2020;
Thompson et al., 2022) that are in widespread use.
Relatively few molecular simulators have formal training in software
engineering and learn their craft “on the job.” In the process of developing
code using an OO programming language, aspects of the object-oriented
approach are often not fully appreciated. In particular, coding often takes
precedence over object-oriented modeling, which is contrary to good soft￾ware development practice. The aim of this chapter is to attempt to bridge
this gap by explaining and applying object-oriented concepts for both MD
and Monte Carlo (MC) simulations via detailed case studies.
The outcomes of the object-oriented approach are implemented using C11.
The choice1 of C11 has the advantage that the code can be easily modified for
parallel execution on graphical processor units (Chapter 12). The widely used
and highly optimized C11 simulation codes are available (Abraham et al.,
2015; Phillips et al., 2020; Thompson et al., 2022). Interestingly, there is evi￾dence (Pereira et al., 2021) that it is energy efficient, which is an increasingly
important consideration. Details of programming in C11 can be found in well￾known texts (Deitel and Deitel, 2002; Stroustrup, 2013). A good description of
the use of OO and C11 has been given by Parsons (1997). Haney (1994) has
discussed some aspects of the computational speed of C11 code.
Code availability
The C11 source code for the MD, MC, and combined MC and MD
programs are available for download from the book’s website at:
https://www.elsevier.com/books-and-journals/book-companion/9780323853989.
A software user’s guide is given in the Appendix.
1. OO principles are entirely independent of the programming language and can be applied in
other OOP languages such as python or Java. Too much time and effort is often devoted to
championing a preferred language.
406 Molecular Simulation of Fluids11.1 Fundamental concepts of OO
The strategy of OO involves OO analysis (OOA), OO design (OOD), and
OO programming (OOP). The first step in OOP is to analyze the problem
and identify the composite classes. In the design stage, the relationships
between the classes are identified. Finally, the design is implemented in a
programming language that supports object-oriented concepts. In reality,
there is often a seamless boundary between these processes, and we will not
dwell on the distinction.
In practice, OO is built on the principles of abstraction, encapsulation,
inheritance, aggregation, and polymorphism. Abstraction and encapsulation
are essential to an object-oriented program whereas other features may or
may not be present. It quickly becomes evident that OO has a vocabulary,
which is largely foreign to structural programming approaches. Therefore
our starting point is to explain the key concepts of OO. At the outset, it
should be noted that OO is not confined to programming. As explained sub￾sequently, developing object-oriented code is the end process of the object￾oriented approach. Indeed, many object-oriented practitioners do not com￾plete the object-oriented processes by actually creating a program! OO pro￾vides a new perspective on problem solving in which algorithmic
development is deferred until the final stages of the process. This is possibly
the biggest difference from the structural programming approach in which
the choice of algorithm is made at the outset and as such, dictates the nature
of the code.
11.1.1 Classes and objects
OO is an attempt to represent real-world objects in software. Some objects
are concrete things whereas others are more abstract. However, the most
important aspect of OO is that objects can be composed of both data (vari￾ables) and processes (methods), whereas in procedural programming, data
and processes are always treated separately. The concept of a class and that
of an object are closely linked. The first step in the object-oriented approach
is to identify classes from which objects can be created. In the jargon of OO,
an object is instantiated from a particular class. An obvious example of a
class in the context of MD is an atom. The Atom class contains the attributes
or properties of the atom such as the mass, position, velocity, energy, and
the like. Argon is a concrete example of the class Atom. Therefore, we can
create an object to represent argon from the class Atom. Krypton, xenon, and
the like are other examples of atoms, and objects representing these atoms
can be created from the Atom class. Indeed, we can create different objects
to represent all the elements of the periodic table from the same Atom class.
It is convenient and very useful to make use of a diagrammatic notation
to represent both classes and interactions between classes. Here, we will
Molecular simulation and object-orientation Chapter | 11 407mainly use the broad features of the unified modeling language (UML) as
described by Eriksson et al. (2003). The UML approach is an attempt to
unify various object notations and it has many similarities with the object
modeling technique (OMT) (Rumbaugh et al., 1991). It is possibly the most
widely used form of object representation.
Fig. 11.1 is an UML diagram for the Atom class. The class is represented
by a rectangle with three distinct divisions separated by solid lines. The
name of the class is given as a heading in the top division. As discussed sub￾sequently, the class can have both private and public information. The pri￾vate properties are listed subsequently the class heading, whereas the bottom
division is reserved for public information.
11.1.2 Abstraction and encapsulation
In general terms, abstraction is the attempt to define all the essential features
of an object and group or encapsulate them with the object itself. In the ear￾lier example, the class Atom was associated with various attributes, namely,
position, mass, velocity, etc. Linking data with processes is an example of
encapsulation and it allows the implementation of information hiding.
Everything the object needs is encapsulated within the object and therefore
hidden from all other objects. The definition of member variables inside
structures in C is also an example of information hiding. However, unlike
structures, encapsulation within classes is not limited to variables. Functions
(or methods in object-oriented terminology) can also be encapsulated in a
class. The encapsulated methods determine the behavior of the class and any
object instantiated from it. Objects have a private part of hidden internal
detail and a public interface, which defines the possible behavior of the
object. An UML diagram for the Atom class with some possible attributes
(mass, position, and velocity) and behavior (getMass, getVelocity, getPosition,
setMass, setVelocity and setPosition) is illustrated by Fig. 11.2.
11.1.3 Methods and message passing
In general terms, an OO program works by passing messages between
various objects using methods. Method is the OO terminology for
...
...
Atom
FIGURE 11.1 UML diagram representation of an Atom class. The middle and lower divisions
are for private and public properties, respectively.
408 Molecular Simulation of Fluidsfunctions/subroutines in procedural programming languages such as C and
FORTRAN. As noted earlier, methods are encapsulated within the object.
Methods can be divided into two broad types responsible for setting and get￾ting values of attributes, respectively. Figure 11.2 illustrates some potential
‘set’ and ‘get’ methods for the attributes of the Atom class. The way ‘set’
and ‘get’ methods work in practice depends in part on how the objects are
interrelated. This in turn depends on the inheritance, aggregation, and associ￾ation characteristics of the objects.
11.1.4 Inheritance
A feature of OO is that one class can inherit properties from other classes.
Inheritance is a powerful device for extending the functionality of a class
and sharing common behaviors and properties between objects. However, it
is important to note that inheritance only makes sense if a class is ‘a kind of’
another class. For example, polymers, proteins, and surfactants are different
kinds of molecules. Therefore if we have a class Molecule, which represents
the properties of molecules, we can have classes Polymer, Protein, and
Surfactant that can legitimately inherit the properties and behavior of the
Molecule class. An UML diagram representing inheritance between classes is
illustrated in Fig. 11.3.
In UML, notation inheritance between classes is represented by arrows
linking the classes. The head of the arrow points to the superclass (in this
case the Molecule class) from which properties are inherited. The Polymer,
Protein, and Surfactant classes are said to be derived from the Molecule
superclass. Alternatively, they can be viewed as child classes obtained
-mass
-position
-velocity
getMass
getPosition
getVelocity
setMass
setPosition
setVelocity
Atom
FIGURE 11.2 UML diagram for an Atom class showing private attributes (mass, velocity,
and position) and public methods (getMass, getVelocity, getPosition, setMass, setVelocity,
and setPosition).
Molecular simulation and object-orientation Chapter | 11 409from a parent class. It should be noted that inheritance is a one-way pro￾cess from parent class to the child classes. The parent class cannot inherit
from a child class.
11.1.5 Aggregation
Some objects are ‘part of’ another object rather than being a ‘kind of’ a particu￾lar object. This important distinction allows us to create objects that are aggrega￾tions of other objects. In molecular simulation, there are many opportunities to
exploit aggregations and/or associations (defined subsequently). Perhaps the
most important candidate for aggregation is the Molecule class. By definition, an
atom is part of a molecule. The UML diagram illustrating the aggregation rela￾tionship between Molecule and Atom is illustrated in Fig. 11.4. Notice that the dia￾mond is attached to aggregated class (the Molecule class in this case). In general,
a molecule is composed of two or more atoms, and therefore the cardinality of
the relationship between Molecule and Atom is one to many represented in the
UML diagram by the notation 1 ... N.
Of course, atoms are themselves composed of subatomic particles such as
neutrons, electrons, and protons. Therefore if it is desired, the Atom class itself
can be represented as an aggregation of objects representing subatomic proper￾ties as illustrated by Fig. 11.5.
It is quite common to combine aggregation and inheritance in an object￾oriented analysis. Using the preceding examples, a complete description of poly￾mers, surfactants, or polymers spanning the molecular level to the subatomic
level can be obtained by the addition (Figs. 11.3 to 11.5), resulting in Fig. 11.6.
Polymer, Protein, and Surfactant inherit from Molecule, giving them access to all the
properties and behavior of Molecule including Atom, Neutron, Proton, and Electron.
Molecule
Polymer Protien Surfactant
FIGURE 11.3 UML diagram illustrating the notation for inheritance from the superclass
(Molecule) to the derived classes (Polymer, Protein, and Surfactant).
410 Molecular Simulation of FluidsMolecule
Atom
1..N
FIGURE 11.4 UML diagram representing the aggregation relationship between Molecule and
Atom. The diagram indicates that one Molecule is composed of many Atoms.
Molecule
Atom
Proton Neutron Electron
1..N
1..N
1..N
1..N
FIGURE 11.5 UML diagram illustrating different levels of aggregation. Molecule is an aggre￾gation of Atoms, which in turn is an aggregation of different subatomic particles.
Molecular simulation and object-orientation Chapter | 11 41111.1.6 Association
Aggregation is a form of association. However, more generally, an object
may require another object without it being a ‘part of’ the object. This type
of association is identified by the ‘has a,’ ‘uses a,’ ‘needs a,’ or any other
similar dependency relationship. For example, in a molecular simulation,
atomic interactions are typically described by an intermolecular potential.
Therefore we can identify that the Atom class needs an intermolecular poten￾tial. In UML notation this is illustrated by a line between the class diagrams
(Fig. 11.7).
It is important to note that the attributes and methods of an associated
object could be also encapsulated directly into the object with which it
is associated. For example, the attributes and methods of the
Intermolecular_Potential class could become additional attributes and methods
1..N
1..N
1..N
1..N
FIGURE 11.6 UML diagram illustrating the combined use of inheritance and aggregation.
412 Molecular Simulation of Fluidsof the Atom class without having to create the Intermolecular_Potential
class! Therefore the decision to create an association should be considered
carefully.
11.1.7 Polymorphism
An advantage of OOP programming languages is that the same symbol
can have different meanings depending on the context that it is used.
Polymorphism is used to describe the ability to have many different
forms. For example, in C the “” operator is used to denote both multipli￾cation and a pointer. There is no conflict between its different behaviors
because the intended behavior is clear from the context that it is used.
When multiplication is intended, “” is used as a binary operator, whereas
1..N
1..N 1..N 1..N
FIGURE 11.7 UML diagram showing the association (has a) between Atom and
Intermolecular_Potential in addition to aggregation and inheritance relationships.
Molecular simulation and object-orientation Chapter | 11 413it is used as a unary operator to denote pointer behavior. Languages such
as C11 which support OOP allow us to define polymorphic behavior as
required.
11.2 Case study: application of OO to the microcanonical
MD simulation of Lennard-Jones atoms
In this section we illustrate the use of OO to the MD (Chapter 8) simulation
of the microcanonical ensemble for Lennard-Jones (LJ) atoms. The three dis￾tinct stages of the processes—analysis, design, and programming—are illus￾trated separately. However, it should be noted that in reality the distinction is
blurred. The design stage often results in a re-evaluation of the analysis.
Similarly, the programming component can result in a re-think of the analy￾sis and design. Commonly, the best software solution typically requires sev￾eral iterations of the analysis, design, and programming stages.
It should be noted that the analysis provided here is exemplary only and
intended to illustrate the key processes involved. It is likely that the same
outcome can be obtained by adopting different strategies. Alternative out￾comes are also valid; there are many ways to solve a problem and many dif￾ferent software solutions!
11.2.1 OOA and OOD
The starting basis for any object-oriented analysis is to provide a description of
the problem to be solved. This problem description is used to identify potential
classes, which will form the backbone of the object-oriented description. There
are many ways to identify classes. Normally we can use our understanding of
the problem to identify candidate classes. However, an effective and widely
used technique is to identify major nouns. An example problem description is
given subsequently; the nouns have been underlined as potential classes.
Molecular dynamics simulation can be performed in a microcanonical (NVE) ensemble,
in which the number of atoms, volume, and energy are held constant. The simulation
proceeds for many time steps (Δt) until a predetermined duration (ttotal) is reached. At
the outset (t 5 0) of the simulation, the atoms are placed on a face-centered cubic lattice
and given initial values of velocity and accelerations. The nature of the atoms and initial
values of density, energy, and/or temperature are specified. Temperature scaling of the
velocities ensures that the ensemble has a constant energy. The force and energy inter￾acting on each atom is calculated assuming pairwise interaction and an intermolecular
potential such as the Lennard-Jones potential. Using the initial values of forces, veloci￾ties, and acceleration, Newton’s equations of motion are applied to determine the next
position at time t 5 t 1 Δt . In practice, this requires an integrator algorithm such as
the Gear predictor method. If the Gear predictor method is used additional time deriva￾tives with respect to position are calculated for each atom. The result of applying
414 Molecular Simulation of FluidsNewton’s equations of motion is to update the positions, velocities, acceleration, and
force. The density and energy of the ensemble are stored at each time steps. Prior to
equilibrium (teq), temperature scaling of the velocities is applied periodically to maintain
the ensemble at constant energy. After the equilibrium period, ensemble averages of
energy, temperature, and density are accumulated and statistics regarding these proper￾ties are kept. The statistical data for the ensemble is given at the end.
The potential candidates for classes arising from the problem description
are listed in Table 11.1. In Table 11.1 some obviously related or identical
potential classes (e.g., statistics/statistical data/averages) have been grouped
together. The next step is to decide which of the potential classes from this
noun-based analysis form useful classes. Of course, nouns can also be potential
attributes. How do we distinguish between class and attributes? This part of the
analysis benefits greatly from insights we have regarding the problem.
TABLE 11.1 Distinction between classes and attributes.
Potential class Does the potential class have
attributes/classes itself?
Class or
attribute
acceleration No, but vector components Attribute
atom Yes, type, position, etc. Class
NVE ensemble Yes, atoms, temperature, etc. Class
density No Attribute
energy Yes, but not useful in MD Attribute
fcc lattice Yes, positions Class
force Yes Class
Gear Predictor-Corrector
Newton’s equations
Yes, force, acceleration, etc. Class
integrator Yes Class
intermolecular potential
Lennard-Jones potential
Yes, potential parameters but these are
also part of atom
Attribute
molecular dynamics Yes, all of the above Class
statistical data, statistics Yes, many! Class
simulation Yes, for example, molecular dynamics Class
temperature No Attribute
time, step, time derivative No Attribute
velocity No, but vector components Attribute
volume No Attribute
Molecular simulation and object-orientation Chapter | 11 415However, as a rule of thumb useful classes are usually composed of other attri￾butes and/or other classes. Therefore, for each potential class we ask the ques￾tion: does this class contain attributes or other classes? If the answer is ‘yes’
then it may be a useful class otherwise it is an attribute. Of course, classes are
also likely to contain methods but this aspect is excluded from our criterion
because simple ‘set’ and ‘get’ methods can be devised for trivial classes, which
are not useful for the problem analysis. The results of this analysis are summa￾rized in Table 11.1. The assignment of velocity, acceleration, and energy as
attributes rather than classes was the result of our insight into the problem as
will become apparent later. However, because these properties each have vector
components they could also be designated legitimately as classes.
In general, apart from making the distinction between classes and attri￾butes, elimination of potential classes can be made by other criteria
(Rumbaugh et al., 1991) such as redundancy, vagueness, irrelevancy, and
operations. Redundant classes are classes that have an identical meaning but
are expressed differently, for example, statistics, statistical data, and averages.
We may also decide that some potential classes are defined too vaguely to
have any practical meaning whereas others are irrelevant. Some nouns may
also represent dynamic processes that are better viewed as operations rather
than classes. Furthermore, some potential classes may arise as an artefact of
the implementation rather than as part of the description of the problem. For
example, it may be helpful to define classes to handle such items as data
input, output, and array allocation, which arise from the implementation but
they are clearly not part of the problem description.
The major classes are identified in Fig. 11.8 using short-hand UML nota￾tion. The short-hand notation is used because at this early stage we are not
interested in either the attributes or methods. The next step is to identify the
relationships or associations between the various classes. This is achieved by
identifying either dependency (needs-a, has-a, requires-a, etc.) or inheritance
(is-a kind of) relationship between the classes. Molecular_Dynamics is a type
of Simulation. Molecular_Dynamics is performed in the context of the
NVE_Ensemble. Consequently, there is a well-defined association between
Atom
NVE_Ensemble
Gear_Predictor-Corrector
Molecular_Dynamics
Force
Simulation Integrator FCC_Lattice
FIGURE 11.8 Short-hand UML notation for the preliminary major classes identified from
object-oriented analysis.
416 Molecular Simulation of Fluidsthese two classes. A NVE_Ensemble is composed of many Atoms indicating an
aggregation relationship between these two classes. In turn each Atom has a
Force. In Molecular_Dynamics the position, velocity, and acceleration of the
Atoms is updated by a differential equation Integrator algorithm. Therefore
Molecular_Dynamics requires an Integrator. The Gear_Predictor-Corrector is an
example of an Integrator. The usefulness of the FCC_Lattice class is question￾able because it has no independent existence of the atoms. Instead, the crea￾tion of a lattice is a candidate method of the ensemble. Therefore we
eliminate it at this stage. These relationships are summarized in the UML
diagram given in Fig. 11.9.
At this stage the UML diagram (Fig. 11.9) should be examined to iden￾tify any weakness in the design. One potential problem in the design is the
relationship between Atom and Force. Although each atom has-a force, the
calculation of force is not independent of each atom but rather it is the result
of all pairwise interaction between the atoms. Therefore, it is preferable to
make Force a property of the NVE_Ensemble rather than the Atom class as illus￾trated in Fig. 11.10. In Fig. 11.10 an association has been maintained
between force and atoms. To work effectively, Force needs Atoms. However,
as represented in Fig. 11.10 there is only one Force object, compared with N
Force objects implied by Fig. 11.9. The weakness in the original design
(Fig. 11.9) would have become very apparent in the programming phase
because of the large overhead imposed by instantiating objects of type Force
and Gear_Predictor-Corrector for each object of type Atom.
Simulation
Molecular_Dynamics
NVE_Ensemble
Atom
Force
Gear_Predictor-Corrector
Integrator
FIGURE 11.9 Preliminary UML diagram for MD in the microcanonical ensemble.
Molecular simulation and object-orientation Chapter | 11 417By examining Fig. 11.10 and considering the problem description, further
refinements to the analysis are suggested. We know that the microcanonical
ensemble is only one possible ensemble. This suggests that the creation of a
generic Ensemble class may be useful. Conversely, the Atom and Force classes are
generic, whereas the problem description deals specifically with atoms interacting
via the Lennard-Jones potential. These insights suggest the use of LJ_Atom and
LJ_Force classes. The revised UML diagram incorporating these additional classes
is illustrated in Fig. 11.12. In Fig. 11.11, the Ensemble, Force, and Atom classes are
denoted as abstract classes. In effect, abstract classes serve as placeholders for
other classes. The benefit of using abstract classes is that they facilitate expansion
of the analysis at a later date (see Chapter 11.5). The NVE_Ensemble is an exam￾ple of an Ensemble class so it inherits from Ensemble. Similarly, LJ_Atom and
LJ_Force inherit from the Atom and Force classes, respectively.
Reflecting on the association between classes in Fig. 11.11 suggests the
possibility of a further refinement. In Fig. 11.11, there is no direct interaction
between the Atom and Integrator classes. To operate effectively, Integrator needs
to access Atom because part of its role is to update the properties of Atom.
The additional association between Integrator and Atom is illustrated in
Fig. 11.12. An alternative and equally valid mechanism is to define an asso￾ciation between the Integrator and Molecular_Dynamics classes. However, this
would be less direct involving Molecular_Dynamics to provide Atom to Integrator.
The process of identifying associations between classes, determining their
attributes, and behavior can be facilitated by maintaining and updating a data
dictionary. The dictionary describes the classes, detailing associations, attri￾butes, and operations. A preliminary dictionary summarizing the details to
date is illustrated in Table 11.2.
Simulation
Molecular_Dynamics
NVE_Ensemble
Atom Force Gear_Predictor-Corrector
Integrator
FIGURE 11.10 First revision of the UML diagram for the MD simulation in the microcanoni￾cal ensemble. Atom and force are now both created from NVE_Ensemble.
418 Molecular Simulation of FluidsAtom
{abstract}
NVE_Ensemble Gear_Predictor-Corrector
Molecular_Dynamics
Force
{abstract}
Ensemble
{abstract}
LJ_Force LJ_Atom
Integrator
{abstract}
Simulation
FIGURE 11.11 Second revision of UML diagram showing the use of abstract classes.
Atom
{abstract}
NVE_Ensemble Gear_Predictor-Corrector
Molecular_Dynamics
Force
{abstract}
Ensemble
{abstract}
LJ_Force LJ_Atom
Integrator
{abstract}
Simulation
FIGURE 11.12 Third revision of UML diagram showing the added association between the
Integrator and Atom classes.11.2.2 Detailed class description
Determining the attributes (both variables and methods) is very much an
iterative process. Some attributes are fairly obvious, many attributes are
apparent from the OOA but the remainder will require further analysis of
the problem. Often, ‘missing’ attributes will only become apparent at the
programming phase. Here we will present the ‘final’ result, which has
undergone the process of iterative refinement. The process of determining
attributes and methods is similar to the process that is undertaken in con￾ventional structural programming in identifying functions and appropriate
variables for functions. The main difference is that the methods and attri￾butes both belong to a class. To create a working object or class, two dis￾tinct methods are usually required. The ‘set’ methods perform calculations
and are responsible for assigning values to class attributes. They corre￾spond to either functions or subroutines in structural programming lan￾guage. The ‘get’ methods are used to retrieve the values of the class’s
attributes determined by the ‘set’ methods. They involve typically one line
of code containing an appropriate ‘return’ statement. Later, the attributes
and workings of specific classes must be identified. In C11 , the class
description can be mapped very closely into header files and we will
TABLE 11.2 Preliminary data dictionary describing classes.
Class Description
Atom Abstract class serving as a placeholder for the LJ_Atom class.
Created by NVE_Ensemble.
NVE_Ensemble An example of an ensemble used to generate all the Atoms
in the Ensemble and the Force class. Created by Ensemble.
Ensemble Abstract class created by Molecular_Dynamics. Generates
NVE_Ensemble.
Force Abstract class serving as a placeholder for LJ_Force class.
Force needs Atom. Created by NVE_Ensemble.
Gear_Predictor￾Corrector
Contains information related to the Gear PC method.
Updates positions, velocities, and acceleration. Created by
Molecular_Dynamics.
LJ_Atom Contains details of the Lennard-Jones atom. Created by
Atom.
LJ_Force Performs the force calculation. Created by Force.
Molecular_Dynamics Creates the Ensemble and the Integrator classes and drives
the simulation. It requires Atom.
Simulation Creates the Molecular_Dynamics and handles I/O.
420 Molecular Simulation of Fluidstherefore provide the header files side by side with the UML diagrams. The
use of header files2 is advantageous because it separates the programming
interface from the working program. In some small number of cases, the
source code contains additional methods not given in the UML diagrams,
which post-design coding decision, for example, different implementations
of a particular method.
The C11 20 standard released in 2021 provides the ability to express
modularity using the module keyword. This can now be used as an alternative
to header files. Details of the latest changes to C11 have been summarized
by Stroustrup (2023).
11.2.2.1 Simulation
The Simulation class is the driver class for the whole program. It has one
method readSimParameters() responsible for determining the choice of simula￾tion. After the Molecular_Dynamics object is created the run() method of that
class is called.
Simulation Class md_Ver2.0\simMD.h 
// File: simMD.h
// -----------------
// This file contains the definition of
// the Simulation class, which defines
// all methods and data for MD or MC.
#ifndef _sim_h_
#define _sim_h_
-MolecularDynamics *md
readSimParameters()
Simulation
#include "md.h"
class Simulation{
private:
MolecularDynamics *md;
public:
void readSimParameters();
};
#endif
11.2.2.2 Molecular_Dynamics
The Molecular_Dynamics class controls the simulation process via the runNVE()
method, which is called by the run() method. It contains a reference to the
Ensemble and Integrator classes.
2. The naming of the header file is arbitrary but it is sensible to adhere to the convention of
source-file-name.h. Some C11 programmers prefer to use the .hpp extension for differentiation
with C header files. However, we prefer .h because .hpp can be easily mistaken for .cpp increas￾ing the likelihood of the wrong file being inadvertently deleted or overwritten.
Molecular simulation and object-orientation Chapter | 11 421Simulation Class md_Ver2.0\md.h
// File: md.h
// -----------------
// This file contains the definition of
// the MolecularDynamics class, which
// defines all methods and data for a
// Molecular Dynamics simulation.
#ifndef _md_h_
#define _md_h_
#include "integrtMD.h"
#include "ensembleMD.h"
class MolecularDynamics
{
private:
Ensemble *ensemble;
Integrator *integrator;
int theEnsemble,derivatives;
protected:
int nSize, nEquil, nStep;
double tStep;
public:
MolecularDynamics();
int getnSize();
int getnEquil();
int getnStep();
double gettStep();
void runNVE();
void readInNVE(int );
void run();
};
#endif
-Ensemble *ensemble
-Integrator *integrator 
-theEnsemble
Molecular_Dynamics
-derivatives
MolecularDynamics()
readinNVE()
run()
runNVE()
11.2.2.3 Ensemble
The Ensemble class contains most of the required variables and methods of
the simulation. It has references to the Force object, an array of Atoms and the
simulation parameters. Ensemble also has abstract methods that are defined in
the derived class NVE_Ensemble.
422 Molecular Simulation of FluidsSimulation Class md_Ver2.0\ensembleMD.h 
// File: ensembleMD.h
// -----------------
// This file contains the definition of the
// abstract class Ensemble that defines all
// methods and data common to different
// ensemble types (eg derived classes), as
// well as foreshadowing methods of those
// derived classes through the use of abstract
// methods.
#ifndef _ensembleMD_h
#define _ensembleMD_h
#include "atomMD.h"
#include "forceMD.h"
// Class: EnsembleMD
// ---------------
// The EnsembleMD class contains the physical
// attributes of the abstract ensemble, from
// which instantiable ensemble classes are
// derived, such as the NVE ensemble.
class EnsembleMD
{
protected:
Atom **atoms; //array of atoms 
Force *theForce; //the force
int numComp; //no. of components
int numAtom; //no. of atoms
int *comp; //no. comp. each type
double temperature; //temperature
double density; //density
double boxVol; //box volume
double boxLen; //box length
double *molFract; //mole fractions
double kineticE; //kinetic energy
double potEnergy; //potential energy
public:
Ensemble(Atom **, int, int,
double, double, double *, int *); 
virtual ~Ensemble();
Atom **getAtoms(); //return atom array 
Molecular simulation and object-orientation Chapter | 11 423void setVolume(); //set box volume
void setLength(); //set box length
void setComp(); //set atom type
void initAcceleration(); //initial accel.
int getNumAtom(); //get total atoms
int *getComp(); //get no.components
int getNumComp(); //get total comp.
double getTemp(); //get temperature
double getVolume(); //get box volume 
double getLength(); //get box length
double getPotEnergy();//get pot energy
double getVirial(); //get virial
getKineticE(); //get kinetic energy 
// Abstract Methods
// ----------------
// The following methods are defined in 
// the NVEensembleMD class(nve.h &nve.cpp).
virtual void initialVelocity()=0;
//assign the initial atom velocities
virtual void initialCoord()=0;
//place atoms on lattice
virtual void scaleVelocity()=0;
//scale velocities to temperature
virtual void setForce()=0;
//instigate force calculations
virtual void setKineticE()=0;
//set ensemble Kinetic Energy
virtual void setKineticE(double) = 0;
//set the Kinetic Energy;
virtual double getEnergyLRC()=0;
//get energy long range correction
virtual double getVirialLRC() = 0;
//get virial long range correction
virtual void lrc()=0;
//trigger the long range corrections
};
#endif
11.2.2.4 NVE_Ensemble
The NVE_Ensemble class contains attributes and methods that are specific to
the microcanonical ensemble and other methods that are required for the
simulation. The constant energy is maintained via velocity scaling.
424 Molecular Simulation of FluidsSimulation Class md_Ver2.0\nveMD.h
// File: nveMD.h
// -----------------
// This file contains the definition of the
// NVEensembleMD class, which defines all
// methods and data for the microcanonical
// ensemble.
#ifndef _nveMD_h
#define _nveMD_h
#include "ensembleMD.h"
class NVEensemble : public EnsembleMD
{
private:
double energyLRC; //long range E.corr.
double virialLRC; //long range vir. corr
public:
NVEensemble(AtomMD **, int, int, double,
double, double *, int *);
void readInNVE();
//read in ensemble data
virtual void initialVelocity();
//assign the initial atom velocities
virtual void initialCoord();
//place atoms on lattice
virtual void scaleVelocity(double);
//scale velocities to temperature
virtual void setForce();
//instigate force calculations
virtual void setKineticE();
//set ensemble Kinetic Energy
virtual void setKineticE(double);
//set the ensmble kinetic energy
virtual double getEnergyLRC();
//get energy long range correction
virtual double getVirialLRC();
//get virial long range correction
virtual void lrc();
//trigger the long range corrections
};
#endif
11.2.2.5 Atom
The class Atom is an abstract container class for all data and methods common
to all atom types such as position and mass. Atom contains a two-dimensional
array, highTimeDerivs, which stores values of ð@n
r=@t
nÞ where n . 2 required by
the Gear predictorcorrector algorithm. The velocity (n 5 1) and acceleration
(n 5 2) are given separately.
Molecular simulation and object-orientation Chapter | 11 425Simulation Class
// File: atomMD.h
// -------------
// This file contains the definition of
// abstract class Atom, which defines all
// methods and data common to different
// atom types (eg derived classes), as well as
// foreshadowing methods of those derived
// classes through the use of abstract
// methods.
#ifndef _atomMD_h_
#define _atomMD_h_
class AtomMD
{
protected:
int type; //type of atom
double mass; //mass of the atom
double **rCutOff; //cut off distance
double *position; //position
double *velocity; //velocity
double *acceleration; //acceleration
double **highTimeDerivs; //high. time der.
double *force; //force
public:
Atom(int, double, int, int);
Atom();
void setType(int);
//assign type to atom
void setrCutOff(double **);
//assign cut off point for atom
void setMass(double);
//assign mass to atom
void setAcceleration(double *); 
//assign acceleration to the atom
void setPosition(double *);
//assign position of atom
void setVelocity(double *);
//assign velocity to atom
void setHighTimeDerivs(double **);
//set derivatives of time
md_Ver2.0\atomMD.h
426 Molecular Simulation of Fluidsvoid setForce(double *);
void setForce(double,double,double);
void setForce(int, double *);
//set the force of the atom
double **getrCutOff();
//return cut off point for atom
double *getAcceleration();
//get acceleration of atom
double *getPosition();
//get position of atom
double *getVelocity();
//get velocity of atom
double **getHighTimeDerivs(); 
//get derivatives of time
double *getForce(); 
double *getForce(int);
//get the force of the atom
double getMass();
//get mass of atom
int getType();
//get type of atom
// Abstract Virtual Methods
// ------------------------
// LJatom derived class methods
// ------------------------------
virtual void setSigma(double **)=0;
//set sigma for atom pairs
virtual void setEpsilon(double **)=0;
//set epsilon for atom pairs
virtual double **getEpsilon()=0;
//get epsilon for atom pairs
virtual double **getSigma()=0;
//get sigma for atom pairs
};
#endif
11.2.2.6 LJ_Atom
The LJatom class inherits from Atom and defines those attributes and meth￾ods that are specific to atoms interacting via the LJ potential. In particular, it
contains the ε and σ parameters.
Molecular simulation and object-orientation Chapter | 11 427Simulation Class md_Ver2.0\ljatomMD.h
// File: ljatomMD.h
// -----------------
// This file contains the definition of the
// LJatomMD class, which defines all methods a
// and data for an LJatomMD interacting via
// the Lennard-Jones 12-6 intermolecular
// potential.
#ifndef _ljatomMD_h
#define _ljatomMD_h
#include "atomMD.h"
class LJatom : public Atom
{
private:
double **epsilon; //LJ epsilon 
double **sigma; //LJ sigma
public:
LJatom(int , double , double **,
double **, double **, int, int);
LJatom();
virtual void setSigma(double **);
//set sigma for atom pairs
virtual void setEpsilon(double **);
//set epsilon for atom pairs
virtual double **getEpsilon();
//get epsilon for atom pairs
virtual double **getSigma();
// get sigma for atom pairs
};
#endif
11.2.2.7 Force
Force is an abstract class that maintains a reference to the array of atoms. It
is a container class for the methods in its derived classes that are responsible
for performing the setForce calculations and the long-range corrections.
428 Molecular Simulation of FluidsSimulation Class md_Ver2.0\forceMD.h
// File: forceMD.h
//----------------
// This file contains the definition of
// abstract class ForceMD, which defines all
// methods and data common to different
// force types (eg derived classes), as well
// as foreshadowing methods of those derived
// classes through the use of abstract
// methods.
#ifndef _forceMD_h
#define _forceMD_h
#include "atomMD.h"
class Force
{
protected:
Atom **atoms; //reference to atom array
public:
Force(Atom **);
virtual ~Force();
// Abstract Methods for subclasses
// -------------------------------
// for LJforce:
virtual void setForce(int, double, 
double *, double *)=0;
//set force calculations
virtual void lrc(int, int *, double, 
double *, double)=0;
//long range corrections 
};
#endif
-Atom **atoms
Force()
lrc() {abstract}
setForce() {abstract}
Fo rce
{abstract}
11.2.2.8 LJ_Force
LJ_Force is the subclass of Force that is responsible for performing the long￾range corrections and force calculations using the LJ potential.
Molecular simulation and object-orientation Chapter | 11 429Simulation Class md_Ver2.0\ljforceMD.h
// File: ljforceMD.h
// -------------
// This file contains the definition of the
// Ljforce class, which defines all methods
// and data for a ForceMD object which 
// interacts according to the Lennard-Jones
// intermolecular potential.
#ifndef _ljforceMD_h_
#define _ljforceMD_h_
#include "forceMD.h"
class LJforce : public Force
{
private:
double **epsilon, **sigma, **rCut;
//reference to epsilon, sigma and rCut
public:
LJforce (Atom **);
virtual void setForce(int, double,
double *, double *);
//set force calculations
virtual void lrc(int, int *, double,
double *, double *);
//long range corrections
};
#endif
LJ_Force
LJForce()
Irc() 
setForce()
-epsilon 
-rCutOff 
-sigma
11.2.2.9 Integrator
The Integrator class is a container class for all derived integrator methods.
Apart from its constructor, it only contains abstract methods that will be
implemented in its subclasses.
430 Molecular Simulation of FluidsSimulation Class md_Ver2.0\integrtMD.h
// File: integrtMD.h
// -----------------
// This file contains the definition of the
// abstract class IntegratorMD, which defines
// all methods and data common to integrator
// methods.
#ifndef _integrtMD_h_
#define _integrtMD_h_
#include "atomMD.h"
class Integrator
{
protected:
Atom **atoms;
public:
Integrator(Atom **);
~Integrator();
virtual void gearPredict(int,
double, double, double)=0;
//Gear's predictor
virtual void gearCorrect(int, double,
double)=0;
//Gear's Corrector
};
#endif
gearCorrect() {abstract} 
gearPredict() {abstract}
Integrator 
{abstract}
-Atom **atoms
Integrator()
11.2.2.10 Gear_Predictorcorrector
The Gear_PC class implements the methods of the Gear predictorcorrector
integrator algorithm (Algorithm 7.2). It inherits a reference to the array of
atoms from its base class, which allows calculations to be performed with lit￾tle overhead from parameter passing.
Molecular simulation and object-orientation Chapter | 11 431Simulation Class md_Ver2.0\gpcMD.h
// File: gpcMD.h
// -----------------
// This file contains the definition of the
// GearPCMD class, which defines all methods 
// data for the Gear predictor-corrector
// implementation of the integrator method.
#ifndef _gpcMD_h_
#define _gpcMD_h_
#include "integrtMD.h"
class GearPC : public Integrator
{
public:
GearPC(Atom **);
virtual void gearPredict(int, double,
double);
//Gear's predictor
virtual void gearCorrect(int, double,
double);
//Gear’s Corrector
};
#endif
Gear_PC
GearPC()
GearCorrect()
GearPredict()
The Gear predictor method relies on a number of constants, which could
have been also included in the gpcMD.h file. However, in this case, a separate
gpcConstants.h file is used, as illustrated below.
md_ver2.0/gpcConstantsMD.h
// File: gpcConstantsMD.h
// -----------------
// This file contains the constants required for 
// the Gear-Predictor method.
#ifndef _gpcConstantsMD_h_
#define _gpcConstantsMD_h_
const double G0 = 0.1875;
const double G1 = 0.6972222222;
const double G3 = 0.6111111111;
const double G4 = 0.1666666667;
const double G5 = 0.0166666667;
#endif
11.2.2.11 Auxiliary methods
In common with many applications, there are a subset of methods and utili￾ties that are not specific to a particular but are required by several classes. In
432 Molecular Simulation of Fluidseffect, these methods supplement the methods in the standard libraries that
are provided with the compiler. The header file for these functions is
auxfunc.h.
md_Ver2.0\auxfunc.h
// File: auxfunc.h
// -----------------
// Library interface for general purpose methods
// that are not specific to any class.
#ifndef _auxfunc_h
#define _auxfunc_h
double **getMemory(int num);
//Allocates memory for a one dimensional array
double **getMemory(int xNum, int yNum);
//Allocates memory for a two dimensional array 
double nearestInt(double vector, double boxL);
//Finds the nearest integer
double random(int *idum);
//Finds a random number on the interval 0 to 1
void freeMemory(double **);
void freeMem(double **, int);
//Methods to free memory
#endif
11.2.3 Object-oriented programming in C11
After defining the class diagrams and prototyping the methods and variables
required for the various classes, we enter the programming phase. The vari￾ables and methods for each class are written in a source file with the same
name as the header file. This aspect of the object-oriented process involves
using the principles of structural programming to design robust and well￾structured methods. The design of methods is the algorithm phase of OO.
Notice that it comes naturally as the last step in the object-oriented process,
whereas the structural programming approach is algorithm-centered from the
outset.
11.2.3.1 Code for the main() function
The previous object-oriented analysis has not addressed the role of the main()
function. All C or C11 programs must contain the main() function. Where is
the main() function in our analysis? The answer to this question is that it is
effectively outside of the analysis. In the context of any object-oriented anal￾ysis, main() has a minimal role involving typically only the instantiation of
one object. Thereafter, the program proceeds in accordance with the
Molecular simulation and object-orientation Chapter | 11 433instructions in the various classes, which control the creation of objects and
message passing between objects via method calls. In view of the object￾oriented analysis summarized by Fig. 11.18, the role of main() is clearly to
instantiate an object of type Simulation as illustrated in the code subsequently.
An object of type 
Simulation is created. 
Call to 
readSimParameters() 
invokes the simulation 
process.
// File mainMD.cpp
// -----------
// This file contains the main() function 
// responsible for starting the simulation
/ process.
#include "simMD.h"
int main(int argc, char **arv)
{
Simulation sim;
sim.readSimParameters();
return 0;
}
md_Ver2.0\mainMD,cpp
434 Molecular Simulation of Fluids11.2.3.2 Code for the simulation class
md_Ver2.0\simMD.cpp
The simulation class is 
responsible for reading 
in the simulation 
parameters. 
In the main() an object 
of type Simulation is 
instantiated and the 
readSimparameters() 
method is called. 
The simulation settings 
are read from the 
“simMD.dat” file. 
If the MD option is 
chosen a reference 
(md) to an object of 
MolecularDynamics is 
created.
The run() method of 
MolecularDynamics is 
called which starts the 
simulation process. 
The Simulation class 
can be expanded later 
to include MC.
// File: simMD.cpp
// -----------------
// This file contains the implementation of
// the Simulation class, which defines all
// methods and data for a molecular
// simulation, using either MD or MC.
#include "simMD.h"
#include <fstream>
#include <iostream>
using namespace std;
// Method: readSimParameters
// Usage: readSimParameters();
// ---------------------
// Reads in parameters for NVE ensemble
void Simulation::readSimParameters()
{
int simulation;
//open the sim.dat file
ifstream in;
in.open("simMD.dat");
if(in.fail())
{
cout << "Cannot open simMD.dat!\n";
return;
}
in >> simulation;
in.close();
switch(simulation)
{
case 1: //Molecular Dynamics
md = new MolecularDynamics();
md->run();
break;
case 2: //Monte Carlo
cout << "Not Yet Implemented" << endl;
break;
default:
cout << "Invalid! Aborting!" << endl;
break;
}
return;
}
Molecular simulation and object-orientation Chapter | 11 43511.2.3.3 Code for the Molecular_Dynamics class
md_Ver2.0\md.cpp
The constructor is 
called when a 
MolecularDynamics 
object (md) is created 
in the Simulation 
object (sim).
The number of 
derivatives depends on 
the order of the Gear 
// File: md.cpp
// Class: MolecularDynamics
// ------------------------
// This file contains the implementation
// details for the Molecular dynamics class
// to perform an MD simulation
#include "md.h"
#include "nveMD.h"
#include "gpcMD.h"
#include "ljatomMD.h"
#include "auxfunc.h"
#include <math.h>
#include <fstream>
#include <iostream>
using namespace std;
// Constructor
// -----------
// Accesses parameter file md.dat, which
// identifies the choice of intermolecular
// potential, ensemble, and integrator method,
// & constructs the MolecularDynamics object.
MolecularDynamics::MolecularDynamics()
{
int integratorM, InterPotential;
ifstream in;
in.open("md.dat");
if(in.fail())
{
cout << "Unable to open md.dat 
for MD parameters" << endl;
return;
}
in >> nStep;
in >> nEquil;
in >> nSize;
in >> tStep;
in >> integratorM;
if(integrator ==1) //Gear PC
in >> derivatives;
436 Molecular Simulation of FluidsPC (5 in this case).
The appropriate read￾in method is called.
Integrator points to an 
object of type GearPC.
The run method is 
invoked by md->run() 
from the sim object. 
Different 
ensembles/integrator 
combinations will 
require different run() 
methods. This method 
controls the execution 
of the simulation.
Simulation settings.
in >> theEnsemble >> InterPotential;
in.close();
switch(theEnsemble)
{
case 1: //NVE ensemble
readInNVE(potential);
break;
//other ensembles here
}
switch(integratorM)
{
case 1:
integrator = new
GearPC(ensemble->getAtoms());
break;
}
}
// Method: run
// Usage: run();
// --------------
// Runs the appropriate simulation run method
// determined by the choice of ensemble.
void MolecularDynamics::run()
{
switch(theEnsemble)
{
case 1: // NVE ensemble
runNVE();
break;
//other ensembles can be inserted here
}
}
void MolecularDynamics::runNVE()
{
ofstream out;
out.open("md_nve.out", ios::out);
if(out.fail()) {
cout << "could not open output file!" 
<< endl;
return;
}
int i, j = 0, n, nTotal; 
int nStep = getnStep();
int nEquil = getnEquil();
int nSize = getnSize();
Molecular simulation and object-orientation Chapter | 11 437Initialising averages.
Determine size of 
simulation blocks.
Properties to be 
averaged are 
accumulated in blocks 
of size n.
Initialization of the 
properties of ensemble 
prior to the simulation.
int num = ensemble->getNumAtom();
double length = ensemble->getLength();
double volume = ensemble->getVolume();
double tStep = gettStep();
double potE, kinE, totE, temp, lrc, lrcw;
double avPotEnergy = 0.0;
double avKinEnergy = 0.0;
double avTotEnergy = 0.0;
double avVirial = 0.0;
double avTemperature = 0.0;
double erKinEnergy = 0.0;
double erPotEnergy = 0.0;
double erTotEnergy = 0.0;
double erTotEnergy = 0.0;
double erVirial = 0.0;
double erTemperature = 0.0;
double pressure, erPress;
double *accumPotE, *accumKinE;
double *accumTotE, *accumVir, *accumTemp;
nTotal = nStep - nEquil;
n = nTotal/nSize;
accumPotE = new double [n];
accumKinE = new double [n];
accumTotE = new double [n];
accumTemp = new double [n]; 
accumVir = new double [n];
accumTemp = new double [n];
for (i = 0; i < n; i++)
{
accumPotE[i] = 0.0;
accumKinE[i] = 0.0;
accumTotE[i] = 0.0;
accumTemp[i] = 0.0;
accumVir[i] = 0.0;
accumTemp[i] = 0.0;
}
ensemble->lrc();
//long range corrections
lrc = ensemble->getEnergyLRC();
lrcW = ensemble->getVirialLRC();
ensemble->setForce();
//set initial force
ensemble->initAcceleration();
//initial acceleration
ensemble->initialVelocity();
//initial velocity
ensemble->setKineticE();
//determine kinetic energy
ensemble->scaleVelocity();
//scale velocities to coincide with energy
ensemble->setKineticE();
//Re-determine KE with scaled velocities
438 Molecular Simulation of FluidsStart of simulation 
using Gear PC.
Velocity scaling at 
every 10 time steps to 
keep energy constant.
Accumulation of 
averages after 
equilibration period.
Calculation of 
ensemble averages and 
standard deviations.
cout << "Results will be directed to the 
file \"md_nve.out\"" << endl;
for(i = 0; i < nStep; i++)
{
integrator->gearPredict(num, length,
tStep);
ensemble->setForce();
ensemble->setKineticE();
kinE = integrator->
gearCorrect(num, length, tStep);
ensemble->setKineticE(kinE);
if(((i % 10) == 0) && i < nEquil)
ensemble->scaleVelocity(tStep);
if(i >= nEquil)
{
potE = ensemble->getPotEnergy() + lrc;
kinE = ensemble->getKineticE();
virial = ensemble->getVirial() + lrcW; 
totE = potE + kinE;
temp = 2.0*kinE/(3.0*num -3);
avPotEnergy += potE;
avKinEnergy += kinE;
avTotEnergy += totE;
avVirial += virial;
avTemperature += temp;
if((i !=nEquil) && ((i % nSize)==0))
{
accumPotE[j] /= nSize;
accumKinE[j] /= nSize;
accumTotE[j] /= nSize;
accumVir[j] /= nSize;
accumTemp[j] /= nSize;
j++;
}
accumPotE[j] += potE; 
accumKinE[j] += kinE;
accumTotE[j] += totE;
accumVir[j] += virial;
accumTemp[j] += temp;
}
}
avPotEnergy /= nTotal;
avKinEnergy /= nTotal;
avTotEnergy /= nTotal;
avVirial /= nTotal;
avTemperature /= nTotal;
Molecular simulation and object-orientation Chapter | 11 439Printing out ensemble 
averages at the end of 
the simulation.
The readInNVE() 
method is called by the 
constructor of the 
MolecularDynamics 
object.
Some of the input 
values depend on the 
potential. In this case 
only the LJ has been 
implemented.
References to the 
Atom class.
Check for successful 
file opening.
for(i = 0; i < n; i++)
{
erPotEnergy +=
pow((accumPotE[i] - avPotEnergy),2);
erKinEnergy +=
pow((accumKinE[i] - avKinEnergy),2);
erTotEnergy +=
pow((accumTotE[i] - avTotEnergy),2);
erVirial +=
pow((accumVir[i] - avVirial),2);
erTemperature +=
pow((accumTemp[i] - avTemperature),2);
}
pressure = avVirial/volume + 
num*ensemble->getTemp()/volume;
erPress = erVirial/volume;
out <<"Average Potential Energy/N:\t"
<< avPotEnergy/num <<" +/-
"<<sqrt(erPotEnergy)/(nTotal*num)<<endl;
out <<"Average Kinetic Energy/N:\t " 
<< avKinEnergy/num <<" +/-
"<<sqrt(erKinEnergy)/(nTotal*num)<<endl;
out <<"Average Total Energy/N:\t\t"
<< avTotEnergy/num <<" +/-
"<<sqrt(erTotEnergy)/(nTotal*num)<<endl;
out <<"Average Pressure:\t\t " << pressure
<<" +/- "<<sqrt(erPress)/nTotal<<endl;
out <<"Temperature:\t\t\t " << avTemperature
<<" +/-
"<<sqrt(erTemperature)/nTotal<<endl;
out.close();
}
// Method: readInNVE
// Usage: readInNVE();
// __________________
// ReadIn reads-in the NVE ensemble settings
// from the NVEfile.dat data file.
void MolecularDynamics::readInNVE
(int interPotential)
{
int i, j, dimensions = 3;
int, numComp, numAtom, *comp;
double numType, *molFract;
double temperature, density, *mass;
AtomMD *newAtom, **atoms;
//open the NVEfile.dat file
ifstream in;
in.open("NVEfileMD.dat");
440 Molecular Simulation of FluidsCheck that there is at 
least one component!
Check that there are at 
least four atoms to 
build lattice.
The following code 
continues to read-in 
data and performs 
various bookkeeping 
tasks.
This can be expanded 
for other potentials.
if(in.fail())
{
cout << "Cannot open NVEFile.dat!\n";
return;
}
in >> numComp;
if(numComp <= 0)
{
cout << "Number of components must
be > 0!\n";
return;
}
comp = new int[numComp];
in >> numAtom;
if(numAtom < 4)
{
cout << "At least 4 atoms are
required!\n";
return;
}
if(!(molFract = new double [numComp]))
{
cout << "Cannot allocate memory
to molFract" << endl;
return;
}
for(i = 0; i < numComp; i++)
in >> molFract[i];
mass = new double[numComp];
for(i = 0; i < numComp; i++)
in >> mass[i];
in >> temperature;
in >> density;
in.close();
// construct array of atoms
if(potential == 1) // Lennard-Jones
{
in.open("paramLJ.dat");
if(in.fail())
{
cout<<"Cannot open paramLJ.dat!\n";
return;
}
// assign memory to arrays
if(!(atoms = new Atom * [numAtom]))
Molecular simulation and object-orientation Chapter | 11 441{
cout<<"Cannot allocate memory to
atoms!\n";
return;
}
epsilon = getMemory(numComp);
sigma = getMemory(numComp);
rCut = getMemory(numComp);
for (i = 0; i < numComp; i++)
{
for (j = 0; j < numComp; j++)
{
in>>epsilon[i][j]>> sigma[i][j]
>> rCut[i][j];
//adjust for indistinguishable pairs
if (j!=i)
{
epsilon[j][i] = epsilon[i][j];
sigma[j][i] = sigma[i][j];
rCut[j][i] = rCut[i][j];
}
}
}
// close input file
in.close();
int *atnum = new int[numComp + 1];
atnum[0] = 0;
//calculate the number of atoms of each
//type from the molFract
for(i = 0; i < numComp; i++)
{
numType = numAtom * molFract[i];
int rem = (int) numType;
if ((numType - rem) >= .5)
atnum[i+1] = (int) numType + 1;
else
atnum[i+1] = (int) numType;
}
int sum = 0;
for (i = 0; i <= numComp; i++)
sum += atnum[i];
while (atnum[numComp] < numAtom)
atnum[numComp]++;
for(i = 0; i < numComp; i++)
atnum[i+1] += atnum[i];
442 Molecular Simulation of FluidsThis section of code 
creates objects of type 
Ljatom, which is 
accessible via the 
atoms array. The 
properties of ljatom are 
passed to the 
constructor
A pointer to the NVE 
ensemble. The 
properties of the 
ensemble are passed to 
the constructor.
Get size of block 
averages.
Get number of 
equilibration steps.
//loop through the number of components
for (i = 0; i < numComp; i++)
{
//loop through the number of atoms
//of that type
for(int j=atnum[i];j<atnum[i+1];j++)
{
//create atom(s) and assign mass,
//type, sigma, epsilon, and rCut
//(derivatives-2) because
//acceleration and velocity are
//stored separately
newAtom =
new Ljatom(i, mass[i], epsilon,
sigma, rCut, dimensions,
(derivatives-2));
//store reference to atom in array
atoms[j] = newAtom;
}
}
} // end of LJ atom array creation
ensemble = 
new NVEensemble(atoms, numComp, 
numAtom, temperature,
density, molFract, comp);
return;
}
// Method: getnSize()
// Usage: n = getnSize();
// ----------------------
// Gets the size of the blocks to be averaged.
int MolecularDynamics::getnSize()
{
return nSize;
}
// Method: getnEquil()
// Usage: n = getnequil();
// ----------------------
// Gets the equilibration period.
int MolecularDynamics::getnEquil()
{
return nEquil;
}
Molecular simulation and object-orientation Chapter | 11 443Get the total number of 
steps in the simulation.
Get the time step.
// Method: getnStep()
// Usage: n = getnStep();
// ----------------------
// Gets the total number of simulation steps.
int MolecularDynamics::getnStep()
{
return nStep;
}
// Method: gettStep()
// Usage: n = gettStep();
// ----------------------
// Gets the size of the time step.
int MolecularDynamics::gettStep()
{
return tStep;
}
11.2.3.4 Code for the ensemble class
md_Ver2.0\ensembleMD.cpp
The ensemble 
constructor is called 
during from the read-in 
function during the 
construction of the md 
object. The properties 
of the Ensemble are 
initialised by the 
constructor.
// File: ensembleMD.cpp
// ____________________
// File containing functions to implement the
// Abstract EnsembleMD class.
#include "ensembleMD.h"
#include <math.h>
// Method: EnsembleMD
// Usage: EnsembleMD;
// -------------------
// Constructor for the EnsembleMD class
EnsembleMD::EnsembleMD(Atom **theAtoms,
int nComp, int nAtoms, double temp, 
double dens, double *mol, int *cmp)
{
atoms = theAtoms;
numComp = nComp;
numAtom = nAtoms;
temperature = temp;
density = dens;
molFract = mol;
comp = cmp;
potEnergy = 0.0;
}
// Destructor for EnsembleMD class
444 Molecular Simulation of FluidsCalculate volume of 
simulation box
Length of simulation 
box.
Number of 
components of each 
atom.
EnsembleMD::~EnsembleMD(){}
// setMethods
// ----------
// These methods assign values to the volume,
// length, and component number for the
// ensemble. They do not take any parameters,
// and are called during the construction
// phase of the ensemble
// Method: setVolume
// Usage: setVolume();
// -----------------_
// Determines the volume of the simulation
// box.
void EnsembleMD::setVolume()
{
boxVol = numAtom/density;
}
// Method: setLength
// Usage: setLength();
// -------------------
// Determines the length of the simulation
// box.
void EnsembleMD::setLength()
{
boxLen = pow(boxVol, 1.0/3.0);
}
// Method: setComp
// Usage: setComp();
// -----------------
// Determines the number of atoms of each
// type.
void EnsembleMD::setComp()
{
int i, sum = 0;
for(i =0; i < numComp - 1; i++)
{
comp[i] = (int)(molFract[i] * numAtom);
sum += comp[i];
}
comp[numComp - 1] = numAtom - sum;
}
// getMethods
// ----------
// These methods return the number of atoms,
// an array describing the number of each
Molecular simulation and object-orientation Chapter | 11 445Get the number of 
atoms in the ensemble.
Get the temperature.
Get the number of 
components.
Get the number of 
each component.
Get the volume.
// atom of each type, the number of
// components, the temperature of the
// ensemble, the volume of the ensemble box,
// the length of the ensemble box, the
// potential energy and the kinetic energy. 
// Method: getNumAtom
// Usage: n = getNumAtom();
// ------------------------
// Gets the total number of molecules.
int EnsembleMD::getNumAtom()
{
return numAtom;
}
// Method: getTemp
// Usage: getTemp();
// ------------------
// Gets the temperature of the ensemble.
double EnsembleMD::getTemp()
{
return temperature;
}
// Method: getNumComp
// Usage: n = getNumComp();
// -------------------------
// Gets the number of components.
int EnsembleMD::getNumComp()
{
return numComp;
}
// Method: getComp
// Usage: p = getComp();
// ----------------------
// Gets the number of each individual comp.
int * EnsembleMD::getComp()
{
return comp;
}
// Method: getVolume
// Usage: getVolume();
// --------------------
// Gets the volume of the simulation box.
double EnsembleMD::getVolume()
{
return boxVol;
}
446 Molecular Simulation of FluidsGet the box length.
Get the potential 
energy.
Get the virail
Get the kinetic energy.
Get the array of Atom 
objects.
Get atoms
// Method: getLength
// Usage: getLength();
// --------------------
// Gets the length of the simulation box.
double EnsembleMD::getLength()
{
return boxLen;
}
// Method: getPotEnergy
// Usage: getPotEnergy();
// ----------------------
// Gets potential energy following force cal.
double EnsembleMD::getPotEnergy()
{
return potEnergy;
}
// Method: getVirial
// Usage: getVirial();
// -------------------
// Gets virial following force calculation.
double Ensemble::getVirial()
{
return virial;
}
// Method: getKineticE
// Usage n = getKineticE();
// --------------------------
// Gets the kinetic energy.
double EnsembleMD::getKineticE()
{
return kineticE;
}
// Method: getVirial
// Usage: getVirial();
// -------------------
// Gets virial following force calculation.
double Ensemble::getVirial()
{
return virial;
}
// Method: getAtoms
// Usage: n = getAtoms();
// -----------------------
// Return array of atoms
Molecular simulation and object-orientation Chapter | 11 447Set the initial 
accelation.
AtomMD **EnsembleMD::getAtoms()
{
return atoms;
}
// Method: initAcceleration
// Usage: initAcceleration();
// ----------------------------
// Performs initialisation on the
// accelerations of all the atoms
// in the ensemble prior to starting the
// simulation. It requires the force values to
// have been initialised.
void EnsembleMD::initAcceleration()
{
double *accel, *force, mass;
accel = new double [3];
for(int i = 0; i < numAtom; i++)
{
force = atoms[i]->getForce();
mass = atoms[i]->getMass();
for (int j = 0; j < 3; j++)
atoms[i]->setAcceleration(&accel[0]);
}
}
448 Molecular Simulation of Fluids11.2.3.5 Code for NVE_Ensemble class
md_Ver2.0\nveMD.cpp
Create NVEensemble.
Set the kinetic energy.
The sum of all 
components of 
velocity.
// File: nveMD.cpp
// ---------------
// File containing methods to implement the
// NVEensembleMD class.
#include "nveMD.h"
#include "auxfunc.h"
#include "ljforceMD.h"
#include <iostream>
#include <math.h>
using namespace std;
// Method: NVEensembleMD
// Usage: NVEensembleMD;
// ----------------------
// Instantiate the NVEensembleMD class
NVEensemble::NVEensemble(Atom **atoms,
int numComp, int numAtom, double temperature,
double density, double *molFract, int *comp)
: Ensemble(atoms, numComp, numAtom, 
temperature, density, molFract, comp)
{
setVolume();
setLength();
setComp();
initialCoord();
theForce = new LJforceMD(atoms);
}
// Method: setKineticE
// Usage: setKineticE();
// ----------------------
// Determines the kinetic energy.
void NVEensembleMD::setKineticE()
{
int i;
double sum = 0.0, *velocity;
for(i = 0; i < numAtom; i++)
{
velocity = atoms[i]->getVelocity();
sum += atoms[i]->getMass() *
(velocity[0] * velocity[0] +
velocity[1] * velocity[1] +
velocity[2] * velocity[2]);
}
kineticE = sum/2;
}
Molecular simulation and object-orientation Chapter | 11 449Scale the velocities.
The array indexes, 0, 
1,2 signify the x,y and 
z components of 
velocity, respectively.
Set the initial 
velocities.
// Method: scaleVelocity
// Usage: scaleVelocity();
// ----------------------------
// Scales the velocities during the
// equilibration phase of the simulation. The
// scaling ensures that the simulation
// is performed at the specified energy.
void NVEensemble::scaleVelocity()
{
int i;
double tScale, mass, kinE, temp, 
sumVSq = 0.0, *velocity;
kinE = getKineticE();
temp = 2*kinE/(3*numAtom - 3);
tScale = sqrt(getTemp()/temp); 
// scale velocities to reproduce the desired
// temperature (temp) and acumulate sum
// for momentum adjustment
for(i = 0; i < numAtom; i++)
{
velocity = atoms[i]->getVelocity();
velocity[0] *= tScale;
velocity[1] *= tScale;
velocity[2] *= tScale;
atoms[i]->setVelocity(velocity);
}
}
// Method: initialVelocity
// Usage: initialVelocity();
// --------------------------
// Invokes a random number generator to assign
// initial velocities to molecules at the
// start of a molecular dynamics simulation.
void NVEensemble::initialVelocity()
{
int seed; //seed for random number generator
int i;
double vX, vY, vZ, vSq, rValue;
double sumX = 0.0, sumY = 0.0;
double sumZ = 0.0;
double *velocity;
// assign random velocities to molecules in
// the range of 1 to - 1
seed = -29;
450 Molecular Simulation of FluidsGet the long range 
corrections to the 
potential energy.
for(i = 0; i < numAtom; i++)
{
vX = random(&seed);
vY = random(&seed);
vZ = random(&seed);
vSq = vX * vX + vY * vY + vZ * vZ;
rValue = sqrt(vSq);
vX /= rValue;
vY /= rValue;
vZ /= rValue;
sumX += vX;
sumY += vY;
sumZ += vZ;
velocity = new double[3];
//create new array with 3 elements
velocity[0] = vX;
velocity[1] = vY;
velocity[2] = vZ;
atoms[i]->setVelocity(velocity);
//adjust velocity of atom i
}
//adjust velocities so that the total linear
//momentum is zero
for(i = 0; i < numAtom; i++)
for(i = 0; i < numAtom; i++)
{
velocity = atoms[i]->getVelocity();
velocity[0] -= sumX/numAtom;
velocity[1] -= sumY/numAtom;
velocity[2] -= sumZ/numAtom;
atoms[i]->setVelocity(velocity);
}
}
// Method: getEnergyLRC
// Usage: n = getEnergyLRC();
// ---------------------------
// Gets the long range energy correction.
double NVEensembleMD::getEnergyLRC()
{
return energyLRC;
}
Molecular simulation and object-orientation Chapter | 11 451Get virial LRC
Set the initial 
coordinates by placing 
the atoms on a face￾centred cubic lattice.
Assign x,y and z 
coordinates for the 
four atoms in the unit 
cell.
// Method: getVirialLRC
// Usage: n = getVirialLRC();
// --------------------------
// Gets the long range virial correction.
double NVEensemble::getVirialLRC()
{
return virialLRC;
}
void NVEensemble::initialCoord()
{
int i, j, x, y, z, offset;
double cells, dcells, cellL, halfCellL,
*tempPos, *position;
double (*holdPos)[3] = new double
[numAtom][3];
tempPos= new double [numAtom];
position = new double [numAtom];
//Determine the number of unit cells in 
//each coordinate direction
dcells = pow(0.25*numAtom, 1.0/3);
cells = (int) nearestInt(dcells, 1.0);
//check if numAtom is an non-fcc number
//and increase the number of cells 
while((4 * cells * cells * cells) < numAtom)
cells = cells + 1;
//Determine length of the unit cell
cellL = boxLen/ (double) cells;
halfCellL = cellL/2;
//Construct the unit cell
//point to atoms position
position[0] = 0.0;
position[1] = 0.0;
position[2]= 0.0;
atoms[0]->setPosition(position);
position[0] = halfCellL;
position[1] = halfCellL;
position[2]= 0.0;
atoms[1]->setPosition(position);
position[0] = 0.0;
position[1] = halfCellL;
position[2]= halfCellL;
atoms[2]->setPosition(position);
position[0] = halfCellL;
position[1] = 0.0;
position[2]= halfCellL;
452 Molecular Simulation of FluidsAssign the remaining 
positions on the lattice.
atoms[3]->setPosition(position);
for(i = 4; i < numAtom; i++)
{
position = atoms[i]->getPosition();
position[0] = 0.0;
position[1] = 0.0;
position[2] = 0.0;
atoms[i]->setPosition(position);
} //init all other atoms to 0
//Build the lattice from the unit cell by
//repeatly translating the four vectors of
//the unit cell through a distance cellL in
//the x, y and z directions
offset = 0;
for (z = 1; z <= cells; z++)
for (y = 1; y <= cells; y++)
for (x = 1; x <= cells; x++)
{
for (i = 0; i < 4; i++)
{
j = i + offset;
if(j < numAtom)
{
position =
atoms[i]->getPosition();
holdPos[j][0] = position[0] 
+ cellL * (x-1);
holdPos[j][1] = position[1] 
+ cellL * (y-1);
holdPos[j][2] = position[2] 
+ cellL * (z-1);
}
}
offset = offset + 4;
}
//Shift centre of box to the origin.
for (i = 0; i < numAtom; i++)
{
tempPos = atoms[i]->getPosition();
tempPos[0] = holdPos[i][0] - halfCellL;
tempPos[1] = holdPos[i][1] - halfCellL;
tempPos[2] = holdPos[i][2] - halfCellL;
atoms[i]->setPosition(tempPos);
}
}
// Method: setforce
// Usage: setForce();
// ------------------
Molecular simulation and object-orientation Chapter | 11 453Set the force.
Get the long range 
corrections.
// Set the force calculations using Ljforce
void NVEensemble::setForce()
{
theForce->setForce(numAtom, boxLen,
&potEnergy, &virial);
}
// Method: lrc
// Usage: lrc();
// --------------
// Calculations for long range corrections
void NVEensemble::lrc()
{
theForce->lrc(numComp, comp, boxVol,
&energyLRC, &virialLRC);
}
11.2.3.6 Code for the Atom class
md_Ver2.0\atomMD.cpp
This constructor is 
used to build the atom 
class using the 
parameters described 
in the parameter list.
// File: atomMD.cpp
// --------------
// File containing the methods to implement
// the atom class.
#include "atomMD.h"
#include "auxfunc.h"
#include <iostream>
#include <fstream>
#include <math.h>
// Constructor:Atom
// Usage: Atom atom;
// -------------------
// Builds the Atom class
Atom::Atom(int theType, double theMass, int 
dimensions, int derivatives)
{
int i;
mass = theMass;
type = theType;
//allocate memory for the arrays
position = new double[dimensions];
velocity = new double[dimensions];
454 Molecular Simulation of FluidsThis initialization of 
acceleration is a
safeguard only because 
acceleration will be re￾assigned in the 
initialisation phase of 
the simulation.
i = 0,1,2 represent the 
3rd,4th and 5th time 
derivatives
This constructor is 
used to create an array 
reference for the 
objects created by the 
first constructor.
The purpose and 
behavior of the 
remaining methods for 
this class are explained 
in detail in the 
comments.
Set the cut-off.
Set the masses.
acceleration = new double[dimensions];
force = new double[dimensions];
highTimeDerivs = 
getMemory(derivatives, dimensions);
//initialise values for acceleration 
//and higher time derivatives
for(i = 0; i < dimensions; i++)
acceleration[i] = 0.0;
for(i = 0; i < 3; i++)
for(int j = 0; j < dimensions; j++)
highTimeDerivs[i][j] = 0.0;
}
//2nd constructor for array reference
//construction
AtomMD::AtomMD(){}
// Method: setType
// Usage: setType(atomType);
// ---------------------------
// Used to identify the atom as belonging to
// a certain type of component within the
// ensemble.
void Atom::setType(int t)
{
type = t;
}
// Method: setrCutOff
// Usage: setrCutOff(atomic_rCutOffValue);
// ----------------------------------------
// Used to assign the values for the rCutOffs
// for the various atom types that make up the
// ensemble
void Atom::setrCutOff(double **newrCut)
{
rCutOff = newrCut;
}
// Method: setMass
// Usage: setMass(double atomicMass);
// ------------------------------------
// Assign the mass of the atom
void Atom::setMass(double newMass)
{
mass = newMass;
}
Molecular simulation and object-orientation Chapter | 11 455Set the acceleration.
Set the positions.
Set the velocities.
// Method: setAcceleration
// Usage: setAcceleration(acceleration);
// --------------------------------------
// Sets the pointer within the atom object to
// point to a new 1D array of doubles,
// representing the acceleration of the atom
// in its various dimensions. Assuming a 3D 
// simulation, the required array would have
// three elements, where:
// atomicAcceleration[0] is the x component
// atomicAcceleration[1] is the y component
// atomicAcceleration[2] is the z component
// Note: this method requires an _array_ to
// be passed to it which has already had
// memory allocated to it.
void Atom::setAcceleration(double *newAccel)
{
for(int i = 0; i < 3; i++)
acceleration[i] = newAccel[i];
}
// Method: setPosition
// Usage: setPosition(position);
// -------------------------------
// Sets the pointer within the atom object to
// point to a new 1D array of doubles,
// representing the position of the atom in
// its various dimensions. Assuming a 3D
// simulation, the required array would have 
// three elements, where:
// atomicPosition[0] = x component of position 
// atomicPosition[1] = y component of position 
// atomicPosition[2] = z component of position
// Note: this method requires an _array_ to
// be passed to it which has already had
// memory allocated to it.
void Atom::setPosition(double *newPos)
{
for(int i = 0; i < 3; i++)
position[i] = newPos[i];
}
// Method: setVelocity
// Usage: setVelocity(velocity);
// -------------------------------
// Sets the pointer within the atom object to
// point to a new 1D array of doubles,
// representing the velocity of the atom in
// its various dimensions. Assuming a 3D
// simulation, the required array would have 
// three elements, where:
// atomicVelocity[0] = x component of velocity 
456 Molecular Simulation of FluidsSet higher derivatives 
of distance w.r.t. time.
Set the force.
// atomicVelocity[1] = y component of velocity 
// atomicVelocity[2] = z component of velocity 
// Note: this method requires an _array_ to
// be passed to it which has already had
// memory allocated to it. 
void Atom::setVelocity(double *newV)
{
for(int i = 0; i < 3; i++)
velocity[i] = newV[i];
}
// Method: setHighTimeDerivs
// Usage: setHighTimeDerivs(timeDerivative); 
// -------------------------------------------
// Sets the pointer within the atom object to
// point to a new 2D array of doubles,
// representing the derivatives of time after
// acceleration and velocity fro that atom,
// in its various dimensions. Assuming a 3D
// simulation, the required array would be 2D
// where: the first dimension represents the
// derivative of time, and the second
// dimension represents the dimension in
// space.
// For example, timeDerivative[a][b] refers to
// the derivative of time for:
// - derivative a, where a is 0 for the third
// derivative of time, 1 is the fourth
// derivative of time, and 2 is the fifth, and
// - dimension b, where b is 0 for the x
// component, 1 for the y component, and 2 for 
// the z component
// Note: this method requires an _array_ to
// be passed to it which has already had
// memory allocated to it.
void Atom::setHighTimeDerivs(double
**newHighTimeDerivs)
{
for(int i = 0; i < 3; i++)
for(int j = 0; j < 3; j++) 
highTimeDerivs[i][j] = 
newHighTimeDerivs[i][j];
}
// Method: setForce
// Usage: setForce(atomicForce);
// -------------------------------
// Sets the pointer within the atom object to
// point to a new 1D array of doubles,
// representing the force acting on the atom
// in its various dimensions. Assuming a 3D
// simulation, the required array would have
// three elements, where:
Molecular simulation and object-orientation Chapter | 11 457Get the type of atom.
Get atomic masses.
// atomicForce[0] = x component of force 
// atomicForce[1] = y component of force 
// atomicForce[2] = z component of force
// Note: this method requires an _array_ to
// be passed to it which has already had
// memory allocated to it.
void Atom::setForce(double *newForce)
{
for(int i = 0; i < 3; i++)
force[i] = newForce[i];
}
// Alternate version as required
void Atom::setForce(double fX, double fY,
double fZ)
{
force[0] = fX;
force[1] = fY;
force[2] = fZ;
}
// Access (Get) Methods
// Usage: n = getXxxx();
// -----------------------
// These methods return the _value_ stored for
// the mass or type of the atom.
// Method: getType
// Usage: p = getType();
// ----------------------
// Gets the type associated with each atom.
int Atom::getType()
{
return type;
}
// Method: getMass
// Usage: n = getMass();
// ---------------------
// Get values of the atomic masses.
double Atom::getMass()
{
return mass;
}
/
/ Access (Get) Methods
// Usage: n = getXxxxx();
// ------------------------
// These methods return a reference to the
458 Molecular Simulation of FluidsGet cut-off values.
Get accelerations.
Get positions.
Get velocities.
Get higher derivatives 
of distance w.r.t. time.
// arrays which hold the values for rCutOff,
// acceleration, position, velocity, time
// step, and force, as described above their
// respective set method.
// Method: getrCutOff
// Usage: n = getrCutOff();
// ---------------------
// Returns the cut off distances for atom
// pairs
double **Atom::getrCutOff()
{
return rCutOff;
}
// Method: getAcceleration
// Usage: n = getAcceleration();
// -----------------------------
// return acceleration of atom
double *Atom::getAcceleration()
{
return acceleration;
}
// Method: getPosition
// Usage: n = getPosition();
// --------------------------
// Return position of atom
double *Atom::getPosition()
{
return position;
}
// Method: getVelocity
// Usage: n = getVelosity();
// -------------------------
// Return the velocity of the atom
double *Atom::getVelocity()
{
return velocity;
}
// Method: getHighTimeDerivs
// Usage: n = getHighTimeDerivs();
// --------------------------------
// Return the derivatives of time
double **Atom::getHighTimeDerivs()
{
return highTimeDerivs;
}
Molecular simulation and object-orientation Chapter | 11 459Get forces. // Method: getForce
// Usage: n = getForce();
// -----------------------
// Returns reference to the force array in the
// atom object
double *AtomM::getForce()
{
return force;
}
11.2.3.7 Code for LJ_Atom class
md_Ver2.0\ljatomMD.cpp
This constructor is 
used to build the 
LJatom object.
This constructor is 
used to reference the 
objects built by the first 
constructor.
Set methods
// File: ljatom.cpp
// ----------------
// File containing the functions to implement
// the LJatomMD class.
#include "ljatomMD.h"
// Constructor: LJatom
// Usage: LJatom atom;
// ---------------------
// Builds the LJatomMD class
LJatom::LJatom
(int theType, double theMass, double **ep,
double **sig, double **rC, int dimensions,
int derivatives)
:Atom(theType, theMass, dimensions,
derivatives)
{
epsilon = ep;
sigma = sig;
rCutOff = rC;
}
// Second constructor
LJatom::LJatom(){}
// Methods: setSigma and setEpsilon
// Usage: setSigma(sigma); 
// setEpsilon(epsilon);
// -----------------------------------------
// These methods accept a reference to a 2D
// array of doubles, representing the sigma
// and epsilon values for the interactions
// between each atomic pair type.
// Each dimension will be exactly the number
460 Molecular Simulation of FluidsSet LJ epsilon value.
Set LJ sigma value.
Get methods
Get LJ epsilon.
Get LJ sigma.
// of atom types in the ensemble, where
// sigma[0][0] is the sigma value for
// interactions between an atom of type 0 and
// an atom of type 0, sigma[0][1] is the sigma
// value for interactions between an atom of
// type 0 and an atom of type 1, etc and 
// likewise for epsilon. 
// Method: setEpsilon
// Usage: setEpsilon(epsilon);
// ----------------------------
// Assign values of LJ epsilon parameter
void LJatom::setEpsilon(double **newEpsilon)
{
epsilon = newEpsilon;
}
// Method: setSigma
// Usage: setSigma(sigma);
// ------------------------
// Set the LJ parameter Sigma
void LJatom::setSigma(double **newSigma)
{
sigma = newSigma;
}
// Methods: getEpsilon and getSigma
// Usage: n = getEpsilon(); n = getSigma();
// -------------------------------------------
// These methods return references to the
// arrays which store the values for sigma and
// epsilon for that atom.
// Method: getEpsilon
// Usage: n = getEpsilon();
// -------------------------
// Get values of the Lennard-Jones epsilons.
double **Ljatom::getEpsilon()
{
return epsilon;
}
// Method: getSigma
// Usage: n = getSigma();
// -----------------------
// Get values of the Lennard-Jones sigmas.
double **LJatom::getSigma()
{
return sigma;
}
Molecular simulation and object-orientation Chapter | 11 46111.2.3.8 Code for the Force class
md_Ver2.0\forceMD.cpp
The code for the 
abstract Force class is
very simple because 
the abstract methods 
are defined in the class 
(in this case LJforce) 
which inherits from it.
// File: forceMD.cpp
// -----------------
// File containing functions to implement 
// the abstract ForceMD class.
#include "forceMD.h"
// Constructor
// Method: ForceMD
// Usage: n = ForceMD(atoms);
// --------------------------
// Used to construct the force component of
// any derived force classes
Force::Force(Atom **theAtoms)
{
atoms = theAtoms;
}
// destructor
ForceMD::~ForceMD(){}
462 Molecular Simulation of Fluids11.2.3.9 Code for the LJ_Force class
The setForce method 
is the heart of the MD 
simulation and it 
determines largely the 
overall speed of the 
calculation.
// File: ljforceMD.cpp
// -----------------
// File containing functions to implement the
// LJforceMD class.
#include "ljforceMD.h"
#include “auxfuncMD.h”
#include <iostream>
#include <fstream>
using namespace std;
// constructor
LJforce::LJforce(Atom **theAtoms)
:ForceMD(theAtoms)
{
epsilon = atoms[0]->getEpsilon();
sigma = atoms[0]->getSigma();
rCut = atoms[0]->getrCutOff();
}
// Method: setForce
// Usage: setForce();
// -------------------
// The ljForce function calculates the force
// experienced by all num atoms due to 
// pairwise interatomic interaction.
// The forces are calculated using the
// Lennard-Jones (6-12) potential. The 
// potential is truncated at a distance
// rCut and long range corrections must be 
// applied outside the method to obtain the
// full contributions to the energy.
void LJforce::setForce(int num, double length,
double *potEnergy, double *virial)
{
int i, j, kindi, kindj;
double rXi, rYi, rZi;
// position vectors for atom i
double rXj, rYj, rZj;
// position vectors for atom j
double rXij, rYij, rZij;
// pair seperation vectors
double rijSq;
// interatomic seperation squared
double fXi, fYi, fZi;
// force vectors for atom i
double fij, fXij, fYij, fZij;
// force between atoms i and j
md_Ver2.0\ljforceMD.cpp
Molecular simulation and object-orientation Chapter | 11 463These method calls are 
simple and should be 
quick. The speed may 
be enhanced by 
explicit inlining.
Pair separation.
double rCutSq, sigmaSq;
// squared cut and sigma values
double sigma2, sigma6, sigma12; 
// multiples of LJ sigma
double pot; // Potential between 2 atoms
double *tempPos; // postion vectors
double *tempPosj; // postion vector
double potECal, virialCal; 
double *fX = new double [num];
double *fY = new double [num];
double *fZ = new double [num];
// Zero the force arrays.
for(i = 0; i < num; i++)
{
fX[i] = 0.0;
fY[i] = 0.0;
fZ[i] = 0.0;
}
potECal = 0.0;
virialCal = 0.0;
//Calculate forces experienced by atoms due
//interatomic pair interactions.
for(i = 0; i < num; i++)
{
//Select molecue i
kindi = atoms[i]->getType();
tempPos = atoms[i]->getPosition();
rXi = tempPos[0];
rYi = tempPos[1];
rZi = tempPos[2];
fXi = fX[i];
fYi = fY[i];
fZi = fZ[i];
for(j = i + 1; j < num; j++)
{
kindj = atoms[j]->getType();
tempPosj = atoms[j]->getPosition();
rXj = tempPosj[0];
rYj = tempPosj[1];
rZj = tempPosj[2];
//Calculate pair seperation
rXij = rXi - rXj;
rYij = rYi - rYj;
rZij = rZi - rZj;
464 Molecular Simulation of FluidsMinimum image 
convention.
It may be 
advantageous to inline 
the nearestInt method.
Only calculate forces 
below the cut-off 
distance.
Energy is calculated 
during the force 
evaluation at very little 
addition computational 
cost.
Application of
Newton’s third law 
saves computing time.
//Apply periodic boundary
rXij -= length * nearestInt(rXij,
length);
rYij -= length * nearestInt(rYij,
length);
rZij -= length * nearestInt(rZij,
length);
rijSq = rXij * rXij + rYij * rYij 
+ rZij * rZij;
rCutSq = rCut[kindi][kindj] * 
rCut[kindi][kindj];
//Calculate forces for seprations
//below the cutoff
if (rijSq <= rCutSq)
{
//Determine i-j interactions
sigmaSq = sigma[kindi][kindj] 
* sigma[kindi][kindj];
sigma2 = sigmaSq/rijSq;
sigma6 = sigma2 * sigma2 * sigma2;
sigma12 = sigma6 * sigma6;
pot = sigma12 - sigma6;
potECal += 4*epsilon[kindi][kindj]
*pot;
virialCal += 24*epsilon[kindi][kindj]
*(pot + sigma12)/3;
//Calculate forces between atoms
fij = 24*epsilon[kindi][kindj] *
(pot + sigma12)/rijSq;
fXij = fij * rXij;
fYij = fij * rYij;
fZij = fij * rZij;
fXi += fXij;
fYi += fYij;
fZi += fZij;
//Apply Newton's third law
fX[j] -= fXij;
fY[j] -= fYij;
fZ[j] -= fZij;
}
}
fX[i] = fXi;
fY[i] = fYi;
fZ[i] = fZi;
}
Molecular simulation and object-orientation Chapter | 11 465Currently the long 
range correction is 
specific to the 
Lennard-Jones (12-6) 
potential.
// Store forces
for(i = 0; i < num; i++)
atoms[i]->setForce(fX[i], fY[i], fZ[i]);
*potEnergy = potECal;
*virial = virialCal;
delete [] fX;
delete [] fY;
delete [] fZ;
}
// Method: lrc
// Usage: n = lrc(num, nComp, volume,
// energyLRC);
// -----------------------------------
// ljLRC calculates the long range correction
// terms to both the energy and virial for an
// ensemble interacting via the Lennard-Jones
// (12-6) potential.
void LJforce::lrc(int num, int *nComp,
double boxV, double *energyLRC,
double *virialLRC)
{
int i, j;
const double PI = 3.141592654;
double sigmaSq, sig3, rCutSq, rCut3, 
sig3R, sig9R, den;
*energyLRC = 0.0;
*virialLRC = 0.0;
for(i = 0; i < num; i++)
for(j = 0; j < num; j++)
{
sigmaSq = sigma[i][j] * sigma[i][j];
rCutSq = rCut[i][j] * rCut[i][j];
sig3 = sigma[i][j] * sigmaSq;
rCut3 = rCut[i][j] * rCutSq;
sig3R = sig3/rCut3;
sig9R = sig3R * sig3R * sig3R;
den = nComp[i] * nComp[j] 
* sig3/boxV;
*energyLRC += (8/9.0) * den * PI *
epsilon[i][j]
* (sig9R - 3 * sig3R);
*virialLRC += (16/9.0) * den * PI * 
epsilon[i][j]
* (2 * sig9R - 3 * sig3R);
}
}
466 Molecular Simulation of Fluids11.2.3.10 Code for the Integrator class
md_Ver2.0\integrtMD.cpp
The Integrator class is 
a container class for all 
derived integrator 
methods
// File: integrtMD.cpp
// Class: Integrator
#include "integrtMD.h"
// Constructor
// -----------
IntegratorMD::Integrator(Atom **theAtoms)
{
atoms = theAtoms;
}
// Destructor
// ----------
Integrator::~Integrator(){}
11.2.3.11 Code for the Gear_Predictorcorrector class
md_Ver2.0\gpcMD.cpp
5-value Gear predictor.
// File: gpc.cpp
// Class: GearPC
#include "gpcMD.h"
#include "gpcConstantsMD.h"
#include "auxfunc.h"
#include <iostream>
using namespace std;
// Constructor
// ------------
GearPC::GearPC(Atom **theAtoms)
:Integrator(theAtoms)
{
//construct superclass
}
// Method: gearPredict
// Usage: gearPredict(num, length);
// --------------------------------
// The Method gearPredict uses Gear's 5-value
// algorithm to predict new coordinates,
// accelerations, velocities, third and fourth
// time derivatives of position.
Molecular simulation and object-orientation Chapter | 11 467Predict positions.
highTimeDerivs[a][b]:
a is the 3rd, 4th and 5th
and b denotes the x, y 
and z components,.
Apply PBC
Predict velocities.
Predict accelerations.
Predict 3rd derivatives.
Predict 4th derivatives.
Store new values.
void GearPC::gearPredict(int num, double
length, double delT)
{
int i, j;
double *position, *velocity, *acceleration,
**highTimeDerivs;
double c1, c2, c3, c4, c5;
c1 = delT;
c2 = c1*delT/2;
c3 = c2*delT/3;
c4 = c3*delT/4;
c5 = c4*delT/5;
for(i = 0; i < num; i++)
{
position = atoms[i]->getPosition();
velocity = atoms[i]->getVelocity();
acceleration = 
atoms[i]->getAcceleration();
highTimeDerivs = 
atoms[i]->getHighTimeDerivs();
for(j = 0; j < 3; j++)
{
//components in the x, y and z directions
position[j] += c1*velocity[j] 
+ c2*acceleration[j]
+ c3*highTimeDerivs[0][j]
+ c4*highTimeDerivs[1][j]
+ c5*highTimeDerivs[2][j];
position[j] -= length * 
nearestInt(position[j], length);
velocity[j] += c1*acceleration[j]
+ c2*highTimeDerivs[0][j] 
+ c3*highTimeDerivs[1][j] 
+ c4*highTimeDerivs[2][j];
acceleration[j]
+= c1*highTimeDerivs[0][j]
+ c2*highTimeDerivs[1][j] 
+ c3*highTimeDerivs[2][j];
highTimeDerivs[0][j]
+= c1*highTimeDerivs[1][j] 
+ c2*highTimeDerivs[2][j];
highTimeDerivs[1][j]
+= c1*highTimeDerivs[2][j]; 
}
atoms[i]->setAcceleration(acceleration);
atoms[i]->setVelocity(velocity);
atoms[i]->setHighTimeDerivs(highTimeDerivs);
atoms[i]->setPosition(position);
}
}
468 Molecular Simulation of FluidsGear corrector method.
Make use of the ‘time’ 
relationships
Correction terms 
involving Gear’s 
constants
Retrive values 
predicted in the first 
part of Gear’s 
algorithm.
// Method: gearCorrect
// Usage: gearCorrect
// (num, type, length, time, mass);
// ----------------------------------------
// gearCorrect corrects the values of
// position, acceleration, velocity, third 
// and forth time derivatives predicted
// by the 5-value Gear method.
// It is called following calls to
// gearPredict and getForce.
double GearPC::gearCorrect(int num, double
length, double delT)
{
int i, j;
double aNew; // new accelerations
double adjust; // corrections to apply
double mass, sumVSq;
double c1, c2, c3, c4, c5;
double cr, cv, cb, cc, cd;
double *force, *acceleration, *position;
double *velocity, **highTimeDerivs;
c1 = delT;
c2 = c1*delT/2;
c3 = c2*delT/3;
c4 = c3*delT/4;
c5 = c4*delT/5;
// Terms involving Gear's constants
cr = G0*c2;
cv = G1*c2/c1;
cb = G3*c2/c3;
cc = G4*c2/c4;
cd = G5*c2/c5;
sumVSq = 0.0;
for(i = 0; i < num; i++)
{
mass = atoms[i]->getMass();
force = atoms[i]->getForce();
acceleration = 
atoms[i]->getAcceleration();
position = atoms[i]->getPosition();
velocity = atoms[i]->getVelocity();
highTimeDerivs = 
atoms[i]->getHighTimeDerivs();
Molecular simulation and object-orientation Chapter | 11 469Make the corrrections
Calculate adjustments.
Correct positions
Apply PBC
Correct velocity
Update acceleration
Correct 3rd derivative
Correct 4th derivatrive
Correct 5th derivative
Store corrections for 
future use
Calculate kinetic 
energy.
Apply corrections to 
positions.
Return kinetic energy
//determine corrections
for(j = 0; j < 3; j++)
{
aNew = force[j]/mass;
adjust = aNew - acceleration[j];
position[j] += cr*adjust;
position[j] -= length * 
nearestInt(position[j], length);
velocity[j] += cv*adjust;
acceleration[j] = aNew;
highTimeDerivs[0][j] += cb*adjust;
highTimeDerivs[1][j] += cc*adjust;
highTimeDerivs[2][j] += cd*adjust;
}
atoms[i]->setAcceleration(acceleration);
atoms[i]->setHighTimeDerivs(highTimeDerivs);
atoms[i]->setPosition(position);
// It is computationally convient to
// calculatre the kinetic energy too:
sumVSq += mass*(velocity[0]*velocity[0] 
+ velocity[1]*velocity[1] 
+ velocity[2]*velocity[2]);
atoms[i]->setVelocity(velocity);
}
return sumVSq/2;
}
470 Molecular Simulation of Fluids11.2.3.12 Code for auxiliary methods
md_Ver2.0\auxfunc.cpp
There are many 
instances where it is 
convenient to use 2-D
arrays. The 
getMemory method 
allows us to allocate 
memory to 2-D arrays 
dynamically rather 
than pre-determining 
the array size. 
A general method to 
assign memory to 2-D
arrays with different 
row (xNum) and 
column (yNum) 
dimensions. In this 
case it is used 
specifically for the 
higher derivatives.
#include "auxfunc.h"
#include <math.h>
#include <iostream>
using namespace std;
// Method: getMemory
// Usage: p = getMemory(num);
// --------------------------
// Assigns memory to 2D arrays.
double **getMemory(int num)
{
int i;
double **mat;
mat = new double *[num];
for(i = 0; i < num; i++)
mat[i] = new double [num];
return mat;
}
// Method: getMemory
// Usage: p = getMemory(xNum, yNum);
// ---------------------------------
// Assigns memory to 2D arrays.
double **getMemory(int row, int col)
{
int i;
double **mat;
mat = new double *[row];
for(i = 0; i < row; i++)
mat[i] = new double [col];
return mat;
}
Molecular simulation and object-orientation Chapter | 11 471Methods to deallocate 
2D array memory
The nearestInt method 
is useful in applying 
the minimum image 
convention to vectors.
Alternatively, the round()
function could be used
as noted in Chapter 5.
// Method: freeMemory
// Usage: freeMemory(array);
// ---------------------------------
// Free memory of 2-dimensional arrays;
void freeMemory(double **array)
{
free(*array);
free(array);
}
// Method: freeMemory
// Usage: freeMemory(array);
// ---------------------------------
// Free memory of 2-dimensional arrays;
void freeMem(double **array, int row)
{
int i;
for(i = 0; i < row; i++)
delete[] array[i];
delete array;
}
// Method: nearestInt
// Usage: n = nearestInt(vector, boxL);
// ------------------------------------
// Return the next nearest integer
// resulting from the divison of vector
// by boxL.
int nearestInt(double vector, double
boxL)
{
int nInt;
double div;
div = vector/boxL;
if(vector >= 0)
nInt = (int)(div + 0.5);
else
nInt = -(int)(0.5 - div);
return nInt;
}
472 Molecular Simulation of FluidsThe random number 
generator is used to 
generate random 
numbers for initial 
velocities etc. It is 
also useful in MC
applications.
// Method: random
// Usage: n = random(idum);
// ------------------------
// Random initally takes any negative
// number (idum) and returns a random 
// on the interval 0 to 1. The
// algorithm is adapted from
// Press et al.,Numerical Receipies in C:
// The Art of Scientific Computing,
// Cambridge University Press, 
// Cambridge, 1988.
double random(int *idum)
{
// constants for random number generator
const long int M1 = 259200;
const int IA1 = 7141;
const long int IC1 = 54773;
const long int M2 = 134456;
const int IA2 = 8121;
const int IC2 = 28411;
const long int M3 = 243000;
const int IA3 = 4561;
const long int IC3 = 51349;
int j;
static int iff = 0;
static long int ix1, ix2, ix3;
double RM1, RM2, temp;
static double r[97];
RM1 = 1.0/M1;
RM2 = 1.0/M2;
if(*idum < 0 || iff == 0){
// initialise on first call
iff = 1;
ix1 = (IC1 - (*idum)) % M1;
// seeding routines
ix1 = (IA1 *ix1 + IC1) % M1;
ix2 = ix1 % M2;
ix1 = (IA1 * ix1 + IC1) % M1;
ix3 = ix1 % M3;
for (j = 0; j < 97; j++) {
ix1 = (IA1 * ix1 + IC1) % M1;
ix2 = (IA2 * ix2 + IC2) % M2;
r[j] = (ix1 + ix2 * RM2) * RM1;
Molecular simulation and object-orientation Chapter | 11 473}
*idum = 1;
}
// generate next number for 
each sequence
ix1 = (IA1 * ix1 + IC1) % M1;
ix2 = (IA2 * ix2 + IC2) % M2;
ix3 = (IA3 * ix3 + IC3) % M3;
// randomly sample r vector
j = 0 + ((96 * ix3) / M3);
if (j > 96 || j < 0)
cout <<"Error in generator\n";
temp = r[j];
// replace r[j] with next value
// in the sequence
r[j] = (ix1 + ix2 * RM2) * RM1;
return temp;
}
11.3 Case study: application of object orientation to the
microcanonical MC simulation of Lennard-Jones atoms
The next example is the application of object-oriented analysis, design, and
programming to the MC simulation of Lennard-Jones atoms in the NVE
ensemble. The analysis, design, and programming issues involved in a MC
simulation have many similarities with MD. OO enables us to exploit these
similarities to reuse existing code/design with either no modifications or rela￾tively minor modifications. Consequently, our approach would be to exploit
these similarities rather than starting entirely from scratch.
11.3.1 OOA and OOD
In common with the treatment of MD, our starting basis is a description of
the problem underlining the nouns as potential classes.
Monte Carlo simulation can be performed in a NVE ensemble in which the number of
atoms, volume, and energy are held constant. The nature of the atoms and initial values of
density and energy are specified. At the outset of the simulation, the atoms are placed ran￾domly on a face-centered cubic lattice and the energy of interaction between pairs of atoms
in the ensemble is calculated using the Lennard-Jones potential. The simulation proceeds
by generating a Markov chain for a predetermined number of cycles (Mcycle). Each cycle
474 Molecular Simulation of Fluidsconsists of an attempt to displace all the atoms randomly. The change in energy for the trial
move is obtained by calculating the energy of the displaced atom via pair interaction with
the atoms. The change in energy is used in conjunction with Ray’s modified Metropolis cri￾teria to either accept or reject the move. If the move is accepted, the energy of the ensem￾ble and the position of the atom are updated. Both successful and unsuccessful moves
contribute to the Markov chain. After the equilibrium period, ensemble averages of energy
and density are accumulated and statistics regarding these properties are kept. The statisti￾cal data is given at the end.
The candidate classes identified from the earlier problem description are
listed in Table 11.3. Comparison with Table 11.1 indicates a high degree of
overlap as well as some differences. Some of the potential classes can be
easily eliminated because they are too vague and our experience with the
MD case can be used to eliminate fcc lattice immediately. One important
distinction between the MD and MC approaches is the treatment of energy.
In the MD case, energy was treated as an attribute, whereas in Table 11.3 it
is designated as a class. This distinction arises because of the different role
TABLE 11.3 Distinction between classes and attributes for the MC
simulation.
Potential class Does the potential class have
attributes/classes itself?
Class or
attribute
atom Yes, type, mass, position, etc. Class
cycle No Attribute
density No Attribute
energy Yes Class
equilibrium period No Attribute
fcc lattice Yes, positions. But a method
Intermolecular potential
Lennard-Jones potential
Yes, potential parameters but these are
also part of atom
Attribute
Markov chain No Vague
Metropolis criteria No Vague
Monte Carlo Yes, all of the above Class
NVE ensemble ensemble Yes, atoms, temperature, etc. Class
position No, but vector components Attribute
simulation Yes, for example, MC Class
statistical data, statistics Yes, many! Class
temperature No Attribute
volume No Attribute
Molecular simulation and object-orientation Chapter | 11 475of energy in the two simulation techniques. In MD, the simulation is driven
by the calculation of forces and the energy is calculated as a by-product of
the force evaluation. In contrast, a MC simulation depends critically on the
calculation of energy and forces are not determined Fig. 11.13.
The major classes identified from Table 11.3 are illustrated in UML nota￾tion in Fig. 11.13. Comparison with Fig. 11.8 indicates that fewer classes
have been identified. The Simulation, NVE_Ensemble, and Atom classes are com￾mon to both problems, whereas the Monte_Carlo and Energy classes can be
identified as MC analogues of the Molecular_Dynamics and Force classes,
respectively, in the MD case study. Consequently, the associations between
the classes can be identified by analogy with the MD case. Monte_Carlo is a
type of Simulation, which can be performed in an NVE_Ensemble. The
NVE_Ensemble is composed of Atoms, and it has an Energy arising from atomic
interactions. These associations are illustrated by the UML diagram in
Fig. 11.14. Comparison of Fig. 11.14 with Fig. 11.10 highlights the similarity
in the associations between classes for the MD and MC techniques. The
Simulation
Atom
NVE_Ensemble
Energy
Monte_Carlo
FIGURE 11.14 Preliminary UML diagram for Monte Carlo simulations in the NVE ensemble.
Simulation
NVE_Ensemble Atom
Monte_Carlo Energy
FIGURE 11.13 Short-hand UML notation for the preliminary major classes identified from the
OOA of the MC description.
476 Molecular Simulation of FluidsUML diagram for the MD case is slightly more complicated because of the
additional requirement to have an integrator.
In the MD case, it was argued that there was benefit in having an abstract
Ensemble class. The same arguments are clearly valid in this case. Similarly,
the Atom and Energy classes can be implemented as abstract classes serving
placeholders for potential specific classes. In the current case, we are specifi￾cally dealing with Lennard-Jones atoms. These refinements are illustrated in
Fig. 11.15. Comparison with Fig. 11.11 shows clearly the similarities and
differences between the two simulation techniques.
In the MD simulation, the Molecular_Dynamics class controlled the process
of the simulation. In Fig. 11.15, the Monte_Carlo class performs a similar func￾tion. However, there is a fundamental difference in the way that this control
function is performed. In a MD simulation every molecular displacement cor￾responds to a valid move because it occurs as a consequence of Newton’s
Simulation
Atom
{abstract}
NVE_Ensemble
Energy
{abstract}
Monte_Carlo
Ensemble
{abstract}
LJ_Atom LJ_Energy
FIGURE 11.15 Further revision of UML diagram for MC simulations showing the use of
abstract classes.
Molecular simulation and object-orientation Chapter | 11 477equations of motion. Therefore, the Molecular_Dynamics class does not need to
interact directly with the Atom class to modify atomic coordinates. In contrast,
in a MC simulation a decision must be made to either accept or reject a move
depending on the outcome of using the acceptance criterion. To implement
this decision-making role effectively, the Monte_Carlo class must be able to
access atomic coordinates directly. This can be achieved by associating the
Monte_Carlo class with the Atom class as illustrated by Fig. 11.16.
A brief description of these classes is summarized in the preliminary data
dictionary (Table 11.4). The role of such a dictionary is to have a point of
reference during the software design. In the case of a complicated design, it
can be expected that the dictionary will evolve considerably before the soft￾ware is finally coded.
Simulation
Atom
{abstract}
NVE_Ensemble
Energy
{abstract}
Monte_Carlo
Ensemble
{abstract}
LJ_Atom LJ_Energy
FIGURE 11.16 Final UML diagram for MC simulations showing the addition of a direct asso￾ciation between the Monte_Carlo and Atom classes.
478 Molecular Simulation of Fluids11.3.2 Detailed class description
As noted previously in the development of the class description for MD sim￾ulation, determining the attributes (both variables and methods) of class is
very much an iterative process. However, as will become apparent subse￾quently, the class descriptions for our MC simulation are very similar to the
descriptions for corresponding classes in MD. In most cases, determining
MC classes simply involves either the deletion or removal of a few attributes
or methods. Indeed, strictly speaking it is not necessary to remove redundant
molecular dynamic variables and methods because the encapsulation feature
of classes means that these variables will remain dormant unless specifically
called upon in the program. However, for the benefit of clarity, redundant
MD attributes and methods have been removed in the design presented sub￾sequently. The similarity of the MD and MC classes means that a high per￾centage of the code developed for the MD program can be reused in the MC
program. The reuse of code is an important advantage of OO compared with
structural programming.
11.3.2.1 Simulation
The Simulation class is the driver class for the whole program. It has one
method readSimParameters() responsible for determining the choice of simula￾tion. After the MonteCarlo object is created the run() method of that class is
TABLE 11.4 Preliminary data dictionary describing classes in a NVE
ensemble MC simulation.
Class Description
Atom Abstract class serving as a placeholder for the LJ_Atom classes.
Created by NVE_Ensemble.
NVE_Ensemble An example of an ensemble used to generate all the Atoms in the
Ensemble and the Energy classes. Created by Ensemble.
Ensemble Abstract class created by Monte_Carlo. Generates
NVE_Ensemble.
Energy Abstract class serving as a placeholder for LJ_Atom class. Created
by NVE_Ensemble.
LJ_Atom Contains details of the Lennard-Jones atom. Created by Atom.
LJ_Energy Performs the energy calculation. Created by Energy.
Monte_Carlo Creates the Ensemble and drives the simulation.
Simulation Creates the Monte_Carlo class and handles input, output, and
statistical data.
Molecular simulation and object-orientation Chapter | 11 479called. The class is very similar to its implementation in MD. The major
change is that a reference is made to the Monte_Carlo class rather than the
Molecular_Dynamics class.
UML Diagram mc_Ver2.0\simMC.h 
// File: simMC.h
// -----------------
// This file contains the definition of
// the Simulation class, which defines
// all methods and data for a MC or MD
// simulation, using either.
#ifndef _simMC_h_
#define _simMC_h_
#include "mc.h"
class Simulation
{
private:
MonteCarlo *mc;
public:
void readSimParameters();
};
#endif
Simulation
-MonteCarlo *mc
readSimParameters()
11.3.2.2 Monte_Carlo
The Monte_Carlo class controls the simulation process via the runNVE()
method, which is called by the run() method. It contains a reference to the
Ensemble and Atom classes. There is a high degree of similarity between the
Monte_Carlo and Molecular_Dynamics classes. The main change has been the
removal of MD attributes and apart from the reference to the Atom class and
the addition of the MonteCarlo() constructor, no new attributes or methods
have been added.
480 Molecular Simulation of FluidsUML Diagram mc_Ver2.0\mc.h 
// File: mc.h
// -----------------
// This file contains the definition of
// the MonteCarlo class, which
// defines all methods and data for a
// MonteCarlo simulation.
#ifndef _mc_h_
#define _mc_h_
#include "ensembleMC.h"
#include "ljatomMC.h"
class MonteCarlo
{
private:
Atom **atom;
Ensemble *ensemble;
int theEnsemble;
protected:
int nSize, nEquil, nStep;
public:
MonteCarlo();
int getnSize();
int getnEquil();
int getnStep();
double gettStep();
void readInNVE(int );
void runNVE();
void run();
};
#endif
Monte_Carlo
-Ensemble*ensemble
-Atom **atom
-theEnsemble
-nSize
-nEquil
-nStep
MonteCarlo()
getnSize()
getnEquil()
getnStep()
readlnNVE()
runNVE()
run()
11.3.2.3 Ensemble
The Ensemble class contains most of the required variables and methods of
the simulation. It has references to the Atom object, an array of Atoms, and the
simulation parameters. Ensemble also has abstract methods that are defined in
the derived class NVE_Ensemble. The Force and Energy classes share many
common methods and variables.
Molecular simulation and object-orientation Chapter | 11 481UML Diagram mc_Ver2.0\ensembleMC.h 
// File: ensembleMC.h
// -----------------
// This file contains the definition of the
// abstract class Ensemble that defines all
// methods and data common to different
// ensemble types (eg derived classes), as
// well as foreshadowing methods of those
// derived classes through the use of abstract
// methods.
#ifndef _ensemble_h
#define _ensemble_h
#include "atomMC.h"
#include "energyMC.h"
// Class: Ensemble
// ---------------
// The EnsembleMC class contains the physical
// attributes of the abstract ensemble, from
// which instantiable ensemble classes are
// derived, such as the NVE ensemble.
class Ensemble
{
protected:
Atom **atoms; //array of atoms 
Energy *theEnergy; //the energy
int numComp; //no. of components
int numAtom; //no. of atoms
int *comp; //no. comp. each type
double totEfixed; //total energy
double density; //density
double boxVol; //box volume
double boxLen; //box length
double *molFract; //mole fractions
double kineticE; //kinetic energy
double potEnergy; //potential energy
double trialPotE; //trial potential E.
public:
EnsembleMC(Atom **, int, int,
double, double, double *, int *); 
482 Molecular Simulation of Fluidsvirtual ~Ensemble();
void setVolume(); //set box volume
void setLength(); //set box length
void setComp(); //set atom type
void setKineticE(double);//set Kinetic E.
int getNumAtom(); //get total no.atoms
int *getComp(); //get no.components
int getNumComp(); //get total no.comp.
double getVolume(); //get box volume 
double getLength(); //get box length
double getPotEnergy();//get pot.energy 
double getTotalEfixed();//get total energy
double getKineticE(); //get kinetic E.
// Abstract Methods
// ----------------
// The following methods are defined in 
// the NVEensemble class (nve.h,nve.cpp).
virtual void initialCoord()=0;
//place atoms on lattice
virtual void setEnergy()=0;
//Orfer N*N energy calculations
virtual void reSetEnergy(double)=0;
//re-set the energy after move is accepted
virtual void lrc()=0;
//trigger the long range corrections
virtual double getTrialPotE(int,Atom **)=0;
//get potential energy of trial
virtual double getEnergyLRC()=0;
//get energy long range correction
};
#endif
11.3.2.4 NVE_Ensemble
The NVE_ensemble class contains attributes and methods that are specific to
the microcanonical ensemble and other methods that are required for the
simulation.
Molecular simulation and object-orientation Chapter | 11 483UML Diagram mc_Ver2.0\nveMC.h
// File: nveMC.h
// -----------------
// This file contains the definition of the
// NVEensembleMC class, which defines all
// methods and data for the microcanonical
// ensemble.
#ifndef _nveMC_h
#define _nveMC_h
#include "ensembleMC.h"
class NVEensemble : public Ensemble
{
private:
double energyLRC; //long range E.corr.
Public:
NVEensemble(Atom **, int, int, double,
double, double *, int *);
void readInNVE();
//read in ensemble data
virtual void initialCoord();
//place atoms on lattice
virtual void setEnergy();
//instigate energy calculations
virtual void reSetEnergy(double);
//re-set energy after successful move
virtual void lrc();
//trigger the long range corrections
virtual double getEnergyLRC();
//get energy long range correction
virtual double getTrialPotE(int, Atom **);
//get trial potential energy
};
#endif
11.3.2.5 Atom
The class Atom is an abstract container class for all data and methods com￾mon to all atom types such as position and mass. The Atom class for the MC
simulation is somewhat simpler than the corresponding class for MD because
the time derivatives of position are not required. The new additions are vari￾ables and methods relating to the trial position.
484 Molecular Simulation of FluidsUML Diagram
// File: atomMC.h
// -------------
// This file contains the definition of
// abstract class AtomMC, which defines all
// methods and data common to different
// atom types (eg derived classes), as well as
// foreshadowing methods of those derived
// classes through the use of abstract
// methods.
#ifndef _atomMC_h_
#define _atomMC_h_
class Atom
{
protected:
int type; //type of atom
double mass; //mass of the atom
double **rCutOff; //cut off distance
double *position; //position
double *trialPosition; //trial position
public:
Atom(int, double, int);
Atom();
void setType(int);
//assign type to atom
void setrCutOff(double **);
//assign cut off point for atom
void setMass(double);
//assign mass to atom
void setPosition(double *);
//assign position of atom
void reSetPosition()
//re-assign position of atom
void setTrialPosition(double *);
//assign atom trial position of atom
int getType();
//get type of atom
double getMass();
//get mass of atom
double **getrCutOff();
//return cut off point for atom
mc_Ver2.0\atomMC.h
Molecular simulation and object-orientation Chapter | 11 485double *getPosition();
//get position of atom
double *getTrialPosition();
//get trial position of atom
// Abstract Virtual Methods
// ------------------------
// LJatomMD derived class methods
// ----------------------------
virtual void setSigma(double **)=0;
//set sigma for atom pairs
virtual void setEpsilon(double **)=0;
//set epsilon for atom pairs
virtual double **getEpsilon()=0;
//get epsilon for atom pairs
virtual double **getSigma()=0;
//get sigma for atom pairs
};
#endif
11.3.2.6 LJ_Atom
The LJ_Atom class inherits from Atom and defines those attributes and meth￾ods that are specific to atoms interacting via the Lennard-Jones potential. In
particular, it contains the ε and σ parameters. The LJatom class used in MC
simulations is almost identical to that used for MD. The only difference
between the two classes is a subtle difference in the second constructor.
486 Molecular Simulation of FluidsUML Diagram mc_Ver2.0\ljatomMC.h
// File: ljatomMC.h
// -----------------
// This file contains the definition of the
// Ljatom class, which defines all methods and
// data for an LJatomMC object interacting via 
// the Lennard-Jones 12-6 intermolecular
// potential.
#ifndef _ljatomMC_h
#define _ljatomMC_h
#include "atomMC.h"
class LJatom : public Atom {
private:
double **epsilon; //LJ epsilon 
double **sigma; //LJ sigma
public:
LJatom(int , double , double **,
double **, double **, int);
LJatom();
virtual void setSigma(double **);
//set sigma for atom pairs
virtual void setEpsilon(double **);
//set epsilon for atom pairs
virtual double **getEpsilon();
//get epsilon for atom pairs
virtual double **getSigma();
// get sigma for atom pairs
};
#endif
11.3.2.7 Energy
Energy is an abstract class that maintains a reference to the array of atoms. It
is a container class for the methods in its derived classes that are responsible
for performing the setEnergy calculations and long-range corrections. The
Energy class performs the analogous role to the Force class in MD.
Molecular simulation and object-orientation Chapter | 11 487UML Diagram mc_Ver2.0\energyMC.h
// File: energyMC.h
//-----------------
// This file contains the definition of
// abstract class Energy, which defines all
// methods and data common to different
// force types (eg derived classes), as well
// as foreshadowing methods of those derived
// classes through the use of abstract
// methods.
#ifndef _energyMC_h
#define _energyMC_h
#include "atomMC.h"
class Energy
{
protected:
Atom **atoms; //reference to atom array
public:
Energy(Atom **);
virtual ~Energy();
// Abstract Methods for subclasses
// -------------------------------
// For LJEnergy:
virtual void setEnergy(int, double, 
double *)=0;
//set energy calculations
virtual void lrc(int, int *, double, 
double *)=0;
//long range corrections
virtual double getTrialPotE
(int, double, int, Atom **)=0;
//get trial potential energy 
};
#endif
11.3.2.8 LJ_Energy
LJ_Energy is the subclass of Energy that is responsible for performing the
long-range corrections and energy calculations using the Lennard-Jones
potential. It plays the analogous role to LJforce in a MD simulation.
488 Molecular Simulation of FluidsUML Diagram mc_Ver2.0\ljenergyMC.h
// File: ljenergyMC.h
// -------------
// This file contains the definition of the
// Ljenergy class, which defines all methods
// and data for an EnergyMC object which
// interacts according to the Lennard-Jones
// intermolecular potential.
#ifndef _ljenergyMC_h_
#define _ljenergyMC_h_
#include "energyMC.h"
class Ljenergy : public Energy
{
private:
double **epsilon, **sigma, **rCut;
//reference to epsilon, sigma and rCut
public:
Energy(Atom **);
virtual void setEnergy(int, double,
double *);
//set energy calculations
virtual void lrc(int, int *, double ,
double *); 
//long range corrections
virtual double getTrialPotE(int, double,
int, Atom **);
//get trial potential energy
};
#endif
LJ_Energy
-sigma
-epsilon
-rCut
LJenergy()
Irc()
setEnergy()
getTrialPotE()
11.3.2.9 Auxiliary methods
The auxiliary methods required for the MC simulation are identical to the
auxiliary methods used in MD.
11.3.3 OOP in C11
After defining the class diagrams and prototyping the methods and variables
required for the various classes, we enter the programming phase. The vari￾ables and methods for each class are written in a source file with the same
name as the header file. The code for many of the methods is identical to the
MD program. This illustrates the reusability feature of the object-oriented
approach.
11.3.3.1 Code for the main() function
As discussed previously, the main() exists effectively outside of the analysis.
It has a minimal role involving the instantiation of an object of type
Molecular simulation and object-orientation Chapter | 11 489Simulation and the execution of one simple method. Thereafter, the program
proceeds in accordance with the instructions in the various classes, which
control the creation of objects and message passing between objects via
method calls. The code for main() presented subsequently is identical to the
code for main() in the MD simulation.
mc_Ver2.0\mainMC.cpp
An object of type 
Simulation is 
instantiated. 
Call to 
readSimParameters() 
invokes the simulation 
process.
// File mainMC.cpp
// -----------
// This file contains the main() function 
// responsible for starting the simulation
/ process.
#include "simMC.h"
main()
{
Simulation sim;
sim.readSimParameters();
return 0;
}
11.3.3.2 Code for the simulation class
The code for the Simulation class is identical to the corresponding class for
MD except that an object of type Monte_Carlo is created rather than an object
of type Molecular_Dynamics.
490 Molecular Simulation of FluidsThe simulation class is 
responsible for reading 
in the simulation 
parameters. 
In the main() an object 
of type Simulation is 
instantiated and the 
readSimparameters() 
method is called. 
The simulation settings 
are read from the 
“sim.dat” file. 
If the MC option is 
chosen a reference 
(mc) to an object of 
MonteCarlo is created. 
The run() method of 
MonteCarlo is called 
which starts the 
simulation process. 
// File: simMC.cpp
// -----------------
// This file contains the implementation of
// the Simulation class, which defines all
// methods and data for a molecular
// simulation, using either molecular 
// dynamics or Monte Carlo etc.
#include "simMC.h"
#include <fstream>
#include <iostream>
using namespace std;
// Method: readSimParameters
// Usage: readSimParameters();
// ---------------------
// Reads in parameters for NVE ensemble
void Simulation::readSimParameters()
{
int simulation;
//open the simMC.dat file
ifstream in;
in.open("simMC.dat");
if(in.fail()){
cout << "Cannot open simMC.dat!\n";
return;
}
in >> simulation;
in.close();
switch(simulation)
{
case 2: //Monte Carlo
mc = new MonteCarlo();
mc->run();
break;
default:
cout << "Invalid! Aborting!" << endl;
break;
}
return;
}
mc_Ver2.0\simMC.cpp
11.3.3.3 Code for the Monte_Carlo class
There is considerable similarity between the Monte_Carlo and
Molecular_Dynamics classes. The code for the getnSize(), getnEquil(), and getnStep
() methods are identical and only minor changes are required in the readInNVE
() method. The most significant changes are confined to the runNVE() method,
which is an implementation of Algorithm 9.4.
Molecular simulation and object-orientation Chapter | 11 491mc_Ver2.0\mc.cpp
The constructor is 
called when a 
Monte_Carlo object 
(mc) is created in the 
Simulation object 
(sim).
Read-in the simulation 
settings.
The appropriate read￾in method is called 
#include "mc.h"
#include "nveMC.h"
#include "auxfunc.h"
#include <fstream>
#include <iostream>
#include <math.h>
using namespace std;
// File: mc.cpp
// Class: MonteCarlo
// ------------------------
// This file contains the implementation
// details for the MonteCarlo class
// Constructor
// -----------
// Accesses parameter file mc.dat, which
// identifies the choice of intermolecular
// potential, and ensemble, and it
// constructs the MonteCarlo object.
MonteCarlo::MonteCarlo()
{
int potential;
ifstream in;
in.open("mc.dat");
if(in.fail())
{
cout << "Unable to open mc.dat
for MC parameters" << endl;
return;
}
in >> nStep;
in >> nEquil;
in >> nSize;
in >> theEnsemble;
in >> potential;
in.close();
switch(theEnsemble)
{
492 Molecular Simulation of Fluidsdepending on the 
choice of ensemble..
The run method is 
invoked by mc->run() 
from the sim object. 
Different ensembles 
will require different 
run() methods.This 
method controls the 
execution of the 
simulation.
The runNVE() method 
controls the execution 
of the simulation
Simulation settings.
Initialising averages
case 1: //NVE ensemble
readInNVE(potential);
break;
//other ensembles here
}
}
// Method: run
// Usage: run();
// ---------------
// Runs the appropriate simulation run method
// determined by the choice of ensemble.
void MonteCarlo::run()
{
switch(theEnsemble)
{
case 1: // NVE ensemble
runNVE();
break;
//run methods for other ensembles can be 
//inserted here
}
}
void MonteCarlo::runNVE()
{
ofstream out;
out.open("mc_nve.out", ios::out);
if(out.fail()) {
cout << "could not open output file!" 
<< endl;
return;
}
int i, index, j = 0, k, n, nTotal, 
seed = -50, counter = 0, accept = 0;
int nStep = getnStep();
int nEquil = getnEquil();
int nSize = getnSize();
int num = ensemble->getNumAtom();
double length = ensemble->getLength();
double avPotEnergy = 0.0;
double avKinEnergy = 0.0;
double avTotEnergy = 0.0;
double avTemperature = 0.0;
double erKinEnergy = 0.0;
double erPotEnergy = 0.0;
double erTotEnergy = 0.0;
double erTemperature = 0.0;
double *accumPotE, *accumKinE;
double *accumTotE, *accumTemp;
double *trial, *position, f;
double eOld, eNew, eTrial, eDelta,
trialPotE, potE, kinE, totE, temp;
Molecular simulation and object-orientation Chapter | 11 493Determine maximum 
displacement
Determine size of 
simulation blocks.
Properties to be 
averaged are 
accumulated in blocks 
of size n.
Initialisation of the 
properties of ensemble 
prior to the simulation.
Check for a valid 
initial configuration
Start of Markov chain
Each cycle in num trial 
displacements long.
Randomly select atom.
double rMax, eFixed, kNew, kOld, wFactor;
double tally = 0.0, lrc;
double const MAX = 0.1;
rMax = MAX*length; 
nTotal = nStep - nEquil;
n = nTotal/nSize;
f = 3.0*num/2.0 - 1.0;
accumPotE = new double [n];
accumKinE = new double [n];
accumTotE = new double [n];
accumTemp = new double [n];
position = new double [3];
trial = new double [3];
for (i = 0; i < n; i++)
{
accumPotE[i] = 0.0;
accumKinE[i] = 0.0;
accumTotE[i] = 0.0;
accumTemp[i] = 0.0;
}
atom = ensemble->getAtoms();
ensemble->lrc();
//perform long range corrections
lrc = ensemble->getEnergyLRC();
ensemble->setEnergy();
//set initial energy
potE = ensemble->getPotEnergy();
eFixed = ensemble->gettotEfixed();
kNew = eFixed - (potE + lrc); 
//determine inital kinetic energy
if(kNew > 0)
ensemble->setKineticE(kNew);
else
{
cout << "Initial configutaion has
negative kinetic energy. Aborting."
<< endl;
exit(0);
}
cout << "Results will be directed to 
the file \"mc_nve.out\"" << endl;
for(i = 0; i < nStep; i++)
{
for (k = 0; k < num; ++k)
{
++counter;
potE = ensemble->getPotEnergy();
kOld = ensemble->getKineticE();
//Select atom randomly
494 Molecular Simulation of FluidsDetermine a trial 
position for each atom 
of the ensemble.
Set trial position.
Minimum image 
convention.
Determine the energy 
of the ensemble at the 
trial positions
Check for valid kinetic 
energy.
Apply Ray’s modified 
Metropolis acceptance 
criterion.
Re-set atomic 
coordinates and 
ensemble energy.
The maximum 
displacement is 
adjusted to obtain the 
desired acceptance 
rate.
index = (int) num*random(&seed);
position = atom[index]->getPosition();
atom[index]
->setTrialPosition(position);
// determine energy at current position
eOld = ensemble
->getTrialPotE(index,atom);
// find trial position
trial[0] = position[0] 
+ rMax*(2.0*random(&seed)-1.0);
trial[1] = position[1] 
+ rMax*(2.0*random(&seed)-1.0);
trial[2] = position[2] 
+ rMax*(2.0*random(&seed)-1.0);
// apply periodic boundary conditions
trial[0] -= length 
* nearestInt(trial[0],length);
trial[1] -= length 
* nearestInt(trial[1],length);
trial[2] -= length 
* nearestInt(trial[2],length);
atom[index]->setTrialPosition(trial);
// calculate energy at trial position
eNew = ensemble
->getTrialPotE(index,atom);
eDelta = eNew - eOld;
trialPotE = potE + eDelta;
kNew = eFixed - (trialPotE +lrc);
if (kNew > 0)
{
wFactor = pow(kNew/kOld, f);
if (wFactor > 1 || wFactor > 
random(&seed)) //accept move
{
atom[index]->reSetPosition();
ensemble->setKineticE(kNew);
ensemble->reSetEnergy(trialPotE);
accept++;
}
}
}
tally = accept/(double) counter;
if (i < nEquil)
{
if (tally < 0.5)
rMax *=0.95;
else
rMax *= 1.05;
Molecular simulation and object-orientation Chapter | 11 495Accumulation of 
averages after 
equilibration period.
Accumulation of block 
statistics.
Analysis of block 
averages and statistical 
uncertainties
}
if(i >= nEquil)
{
potE = ensemble->getPotEnergy() + lrc;
kinE = ensemble->getKineticE();
totE = potE + kinE;
temp = 2.0*kinE/(3.0*num);
avPotEnergy += potE;
avKinEnergy += kinE;
avTotEnergy += totE;
avTemperature += temp;
if((i != nEquil) && 
((i % nSize) == 0))
{
accumPotE[j] /= nSize;
accumKinE[j] /= nSize;
accumTotE[j] /= nSize;
accumTemp[j] /= nSize;
j++;
}
accumPotE[j] += potE;
accumKinE[j] += kinE;
accumTotE[j] += totE;
accumTemp[j] += temp;
}
}
avPotEnergy /= nTotal;
avKinEnergy /= nTotal;
avTotEnergy /= nTotal;
avTemperature /= nTotal;
for(i = 0; i < n; i++)
{
erPotEnergy += pow((accumPotE[i]
- avPotEnergy),2);
erKinEnergy += pow((accumKinE[i] 
- avKinEnergy),2);
erTotEnergy += pow((accumTotE[i] 
- avTotEnergy),2);
erTemperature += pow((accumTemp[i]
- avTemperature),2);
}
out <<"Average Potential Energy/N:\t"
<< avPotEnergy/num <<" +/"<<
sqrt(erPotEnergy)/(num*nTotal)<<endl;
out <<"Average Kinetic Energy/N:\t " 
<< avKinEnergy/num <<" +/"<<
sqrt(erKinEnergy)/(num*nTotal)<<endl;
out <<"Average Total Energy/N:\t\t" << 
avTotEnergy/num <<" +/-
496 Molecular Simulation of FluidsThe readInNVE() 
method is called by the 
constructor of the 
Monte_Carlo object.
References to the 
Atom class.
Some of the input 
values depend on the 
potential. In this case 
only the LJ has been 
implemented.
Check for successful 
file opening.
Check that there is at 
least one component!
Check that there are at 
least four atoms to 
build lattice.
The following code 
performs continues to 
read-in data and 
performs various 
bookkeeping tasks.
"<<sqrt(erTotEnergy)/(num*nTotal)<<endl;
out <<"Average Temperature:\t\t " 
<< avTemperature <<" +/-
"<<sqrt(erTemperature)/nTotal<<endl;
out <<"Acceptance Rate:\t\t "<<100*tally 
<<" %"<<endl;
out.close();
}
void MonteCarlo::readInNVE(int interPotential)
{
int i, j;
double numType, *molFract, **epsilon,
**sigma, **rCut, potE, density;
int dimensions = 3, numComp, numAtom, *comp;
Atom *newAtom, **atoms;
// open the NVEfileMC.dat file
ifstream in;
in.open("NVEfileMC.dat");
if(in.fail()){
cout << "Cannot open
NVEFileMC.dat!\n";
return;
}
in >> numComp;
if(numComp <= 0){
cout << "Number of components 
must be > 0!\n";
return;
}
comp = new int[numComp];
in >> numAtom;
if(numAtom < 4){
cout << "At least 4 atoms 
are required!\n";
return;
}
if(!(molFract = new double [numComp]))
{
cout << "Cannot allocate memory
to molFract" << endl;
return;
}
for(i = 0; i < numComp; i++)
in >> molFract[i];
double *mass = new double[numComp];
Molecular simulation and object-orientation Chapter | 11 497This can be expanded 
for other potentials.
In a mixture the i-j and 
j-i potential parameters 
are the same
for(i = 0; i < numComp; i++)
in >> mass[i];
in >> potE;
in >> density;
// Convert potE per particle to the 
// total ensemble value
potE *= numAtom;
in.close();
// construct array of atoms
if(interPotential == 1) // Lennard-Jones
{
in.open("paramLJ.dat");
if(in.fail()){
cout << "Cannot open paramLJ.dat!\n";
return;
}
// assign memory to arrays
if(!(atoms = new Atom * [numAtom]))
{
cout << "Cannot allocate memory
to atoms!\n";
return;
}
epsilon = getMemory(numComp);
sigma = getMemory(numComp);
rCut = getMemory(numComp);
for (i = 0; i < numComp; i++)
{
for (j = 0; j < numComp; j++)
{
in >> epsilon[i][j] >> 
sigma[i][j] >> rCut[i][j];
//adjust for indistinguishable
// pairs
if (j!=i)
{
epsilon[j][i] = epsilon[i][j];
sigma[j][i] = sigma[i][j];
rCut[j][i] = rCut[i][j];
}
}
}
// close input file
in.close();
int *atnum = new int[numComp + 1];
498 Molecular Simulation of FluidsCreate objects of type 
Ljatom which is 
accessible via the 
atoms array. The 
properties of Ljatom 
are passed to the 
constructor
A pointer to the NVE
ensemble. The 
properties of the 
ensemble are passed to 
the constructor.
Get block size.
atnum[0] = 0;
// calculate the numebr of atoms
// of each type from the molFract
for(i = 0; i < numComp; i++)
{
numType = numAtom * molFract[i];
int rem = (int) numType;
if ((numType - rem) >= .5)
atnum[i+1] = (int) numType + 1;
else
atnum[i+1] = (int) numType;
}
int sum = 0;
for (i = 0; i <= numComp; i++)
sum += atnum[i];
while (atnum[numComp] < numAtom)
atnum[numComp]++;
for(i = 0; i < numComp; i++)
atnum[i+1] += atnum[i];
// loop through the components
for (i = 0; i < numComp; i++)
{
//loop through the atoms of that type
for (int j = atnum[i]; j < 
atnum[i+1]; j++)
{
//create atom(s) and assign
// properties,
newAtom = 
new LJatom(i, mass[i], 
epsilon, sigma, rCut, dimensions);
//store reference to atom in array
atoms[j] = newAtom;
}
}
} // end of LJ atom array creation
ensemble = 
new NVEensemble
(atoms, numComp, numAtom, potE,
density, molFract, comp);
return;
}
// Method: getnSize()
// Usage: n = getnSize();
// -----------------------
Molecular simulation and object-orientation Chapter | 11 499Get equilibration 
period.
Get number of 
simulation cycles.
// Gets the size of the blocks to be averaged.
int MonteCarlo::getnSize()
{
return nSize;
}
// Method: getnEquil()
// Usage: n = getnequil();
// ------------------------
// Gets the equilibration period.
int MonteCarlo::getnEquil()
{
return nEquil;
}
// Method: getnStep()
// Usage: n = getnStep();
// -----------------------
// Gets the total number of simulation steps.
int Montecarlo::getnStep()
{
return nStep;
}
11.3.3.4 Code for the Ensemble class
The code for the Ensemble class is similar to the corresponding class for MD.
The code for the setVolume(), setLength(), setComp(), getNumAtom(), getComp(),
getVolume(), getAtoms(), and getKineticE() methods that were developed for MD
can be reused for MC simulations without any modification. New code is
required only for the setKineticE()andgetTotalEfixed() methods. In addition, a
slight modification is required in the constructor method to initialize
totalEfixed and trialPotE and remove the temperature variable.
500 Molecular Simulation of Fluidsmc_ver2.0\ensembleMC.cpp
The ensemble 
constructor is called 
from the read-in 
function during the 
construction of the mc 
object. The properties 
of the Ensemble are 
initialized by the 
constructor.
// File: ensembleMC.cpp
// --------------------
// File containing functions to implement the
// Abstract EnsembleMC class.
#include "ensembleMC.h"
#include <math.h>
// Method: EnsembleMC
// Usage: EnsembleMC;
// -------------------
// Constructor for the EnsembleMC class
Ensemble::Ensemble(AtomMC **theAtoms, 
int nComp, int nAtoms, double totE, 
double dens, double *mol, int *cmp)
{
atoms = theAtoms;
numComp = nComp;
numAtom = nAtoms;
totEfixed = totE;
density = dens;
molFract = mol;
comp = cmp;
potEnergy = 0.0;
trialPotE = 0.0;
}
// Destructor for EnsembleMC class
EnsembleMC::~EnsembleMC(){}
// setMethods
// ----------
// These methods assign values to the volume,
// length, and component number for the
Molecular simulation and object-orientation Chapter | 11 501Volume of the 
ensemble.
Length of simulation 
box.
Number of 
components of each 
atom.
Set the kinetic energy.
// ensemble. They do not take any parameters,
// and are called during the construction
// phase of the ensemble
// Method: setVolume
// Usage: setVolume();
// --------------------
// Determines the volume of the simulation
// box.
void EnsembleMC::setVolume()
{
boxVol = numAtom/density;
}
// Method: setLength
// Usage: setLength();
// --------------------
// Determines the length of the simulation
// box.
void EnsembleMC::setLength()
{
boxLen = pow(boxVol, 1.0/3.0);
}
// Method: setComp
// Usage: setComp();
// ------------------
// Determines the number of atoms of each 
// type.
void EnsembleMC::setComp()
{
int i, sum = 0;
for(i =0; i < numComp - 1; i++)
{
comp[i] = (int)(molFract[i] * numAtom);
sum += comp[i];
}
comp[numComp - 1] = numAtom - sum;
}
// Method: setKineticE
// Usage: setKineticE(kNew);
// --------------------------
// Sets the kinetic energy of the ensemble.
double EnsembleMC::setKinetic(double kNew)
{
kineticE = knew;
}
502 Molecular Simulation of FluidsGet the number of 
atoms in the ensemble.
Get the number of 
components.
Get the number of 
each component.
Get the volume.
Get the box length.
// getMethods
// ----------
// These methods return the number of atoms,
// an array describing the number of each
// atom of each type, the number of
// components, the temperature of the
// ensemble, the volume of the ensemble box,
// the length of the ensemble box, the
// potential energy, the total energy, and the
// kinetic energy of the ensemble.
// Method: getNumAtom
// Usage: n = getNumAtom();
// -------------------------
// Gets the total number of molecules in the
// ensemble.
int Ensemble::getNumAtom()
{
return numAtom;
}
// Method: getNumComp
// Usage: n = getNumComp();
// -------------------------
// Gets the number of components.
Int EnsembleMC::getNumComp()
{
return numComp;
}
// Method: getComp
// Usage: p = getComp();
// ----------------------
// Gets the number of each individual comp.
int * Ensemble::getComp()
{
return comp;
}
// Method: getVolume
// Usage: getVolume();
// --------------------
// Gets the volume of the simulation box.
double Ensemble::getVolume()
{
return boxVol;
}
// Method: getLength
// Usage: getLength();
// --------------------
// Gets the length of the simulation box.
Molecular simulation and object-orientation Chapter | 11 503Get the potential 
energy.
Get the total energy
Get the kinetic energy.
Get the array of Atom 
objects.
double EnsembleMC::getLength()
{
return boxLen;
}
// Method: getPotEnergy
// Usage: getPotEnergy();
// -----------------------
// Gets potential energy following force cal.
double EnsembleMC::getPotEnergy()
{
return potEnergy;
}
// Method: gettotEfixed
// Usage: n = gettotEfixed();
// ---------------------------
// Gets virial following force calculation.
double EnsembleMC::gettotEfixed()
{
return totEfixed;
}
// Method: getKineticE
// Usage n = getKineticE();
// ------------------------
// Gets the kinetic energy.
double EnsembleMC::getKineticE()
{
return kineticE;
}
// Method: getAtoms
// Usage: n = getAtoms();
// -----------------------
// Return array of atoms
AtomMC **EnsembleMC::getAtoms()
{
return atoms;
}
11.3.3.5 Code for NVE_Ensemble class
The code for the NVE_Ensemble class reuses the code for the initialCoord() and
getEnergyLRC() methods in the corresponding class in MD simulation. The
code force the setEngergy() method analogous to the setForce() method and
only minor changes are required to the NVEensemble() and lrc() methods. The
only entirely new code required is for getTrialPotE() method.
504 Molecular Simulation of Fluidsmc_Ver2.0\nveMC.cpp
Create NVEensemble
Set the initial 
coordinates by placing 
the atoms on a face￾centred cubic lattice.
// File: nveMC.cpp
// --------------------
// File containing functions to implement the
// NVEensembleMC class.
#include <math.h>
#include <string.h>
#include "nveMC.h"
#include "auxfunc.h"
#include "ljenergyMC.h"
// Method: NVEensemble
// Usage: NVEensemble;
// ----------------------
// Instantiate the NVEensembleMC class
NVEensemble::NVEensemble(Atom **atoms, int 
numComp, int numAtom, double totEfixed, double 
density, double *molFract, int *comp)
: Ensemble(atoms, numComp, numAtom, totEfixed, 
density, molFract, comp)
{
setVolume();
setLength();
setComp();
initialCoord();
theEnergy = new LJenergy(atoms);
}
// Method: initialCoord
// Usage: initialCoord();
// -----------------------
// Places atoms upon a lattice to get initial
// coordinates
void NVEensembleMC::initialCoord()
{
int i, j, x, y, z, offset;
double cells, dcells, cellL, halfCellL,
*tempPos, *position;
Molecular simulation and object-orientation Chapter | 11 505Assign x, y and z 
coordinates for the 
four atoms in the unit 
cell.
Assign the remaining 
positions on the lattice.
double (*holdPos) [3] = 
new double [numAtom][3];
tempPos= new double [numAtom];
position = new double [numAtom];
//Determine the number of unit cells in each
//coordinate direction
dcells = pow(0.25 * (double)
numAtom, 1.0/3.0);
cells = (int) nearestInt(dcells, 1.0);
//check if numAtom is an non-fcc number of
//atoms and increase the number of cells if
//necessary
while((4 * cells * cells * cells) < numAtom)
cells = cells + 1;
//Determine length of the unit cell
cellL = boxLen/ (double) cells;
halfCellL = 0.5 * cellL;
//Construct the unit cell
//point to atoms position
position[0] = 0.0;
position[1] = 0.0;
position[2]= 0.0;
position = atoms[0]->setPosition(position);
position[0] = halfCellL;
position[1] = halfCellL;
position[2]= 0.0;
position = atoms[1]->setPosition(position);
position[0] = 0.0;
position[1] = halfCellL;
position[2]= halfCellL;
position = atoms[2]->setPosition(position);
position[0] = halfCellL;
position[1] = 0.0;
position[2]= halfCellL;
position = atoms[3]->setPosition(position);
for(i = 4; i < numAtom; i++)
{
position[0] = 0.0;
position[1] = 0.0;
position[2] = 0.0;
atoms[i]->setPosition(position);
} //init all other atoms to 0
// Build the lattice from the unit cell by
// repeatedly translating the four vectors
// of the unit cell through a distance cellL 
// in the x, y and z directions
506 Molecular Simulation of FluidsSet the potential 
energy at the start of 
the simulation. 
Re-set the energy after 
an accepted move.
offset = 0; 
for (z = 1; z <= cells; z++)
for (y = 1; y <= cells; y++)
for (x = 1; x <= cells; x++){
for (i = 0; i < 4; i++){
j = i + offset;
if(j < numAtom){
position = 
atoms[i]->getPosition();
holdPos[j][0] = position[0] 
+ cellL * (x-1);
holdPos[j][1] = position[1] 
+ cellL * (y-1);
holdPos[j][2] = position[2] 
+ cellL * (z-1);
}
}
offset = offset + 4;
}
// Shift centre of box to the origin.
for (i = 0; i < numAtom; i++)
{
tempPos = atoms[i]->getPosition();
tempPos[0]= holdPos[i][0}- halfCellL;
tempPos[1]= holdPos[i][1]- halfCellL;
tempPos[2]= holdPos[i][2]- halfCellL;
atoms[i]->setPosition(temPos)
}
}
// Method: setEnergy
// Usage: setEnergy();
// --------------------
// Set the energy calculations using
// LJenergy. This is an N*N calculation to
// set the energy at the start of the
// simulation.
void NVEensemble::setEnergy()
{
theEnergy->setEnergy(numAtom, boxLen,
&potEnergy);
}
// Method: reSetEnergy
// Usage: reSetEnergy(energy);
// ----------------------------
// Re-sets the energy of the ensemble
// following an accepted move
void NVEensembleMC::reSetEnergy(double eng)
{
potEnergy = eng;
Molecular simulation and object-orientation Chapter | 11 507Determines the energy 
of the trial 
configuration.
Determine l.r.c to 
energy
Get energy long range 
correction
}
// Method: getTrialPotE
// Usage: n = getTrialPotE(atoms)
// ---------------------------------
// Performs N*N calculations to update energy
// after all atoms are moved.
double NVEensemble::getTrialPotE
(int index, Atom **a)
{
return theEnergy->getTrialPotE
(numAtom, boxLen, index, a);
}
// Method: lrc
// Usage: lrc();
// ------------
// initiate the force calculations for long
// range corrections
void NVEensemble::lrc()
{
theEnergy->lrc(numComp, comp, boxVol,
&energyLRC);
}
// Method: getEnergyLRC
// Usage: n = getEnergyLRC();
// --------------------------
// Gets the long range energy correction.
double NVEensemble::getEnergyLRC()
{
return energyLRC;
}
11.3.3.6 Code for the Atom class
The Atom class reuses the unaltered code for setType(), setCutOff(), setMass(),
setPosition(), getType(), getMass() and getrCutOff(), and getPosition() methods of
the corresponding class in the MD program. Very little coding is required for
the new setTrialPosition(), reSetPosition(), and getTrialPosition() methods.
508 Molecular Simulation of FluidsThis constructor is 
used to build the atom 
class using the 
parameters described 
in the parameter list
Set the atom type.
Set the cut-off 
distance.
// File: atomMC.cpp
// --------------
// File containing the method bodies 
// to implement the atom class.
#include "atomMC.h"
// Constructor:Atom
// Usage: Atom atom;
// -------------------
// Builds the Atom class
Atom::Atom(int theType, double theMass, 
int dimensions)
{
int i;
mass = theMass;
type = theType;
// allocate memory for the arrays
position = new double[dimensions];
trialPosition = new double[dimensions];
}
// 2nd constructor for array reference
// construction
Atom::AtomMC(){}
// Method: setType
// Usage: setType(atomType);
// --------------------------
// Used to identify the atom as belonging to
// a certain type of component within the
// ensemble.
void Atom::setType(int t)
{
type = t;
}
// Method: setrCutOff
// Usage: setrCutOff(atomic_rCutOffValue);
// ----------------------------------------
// Used to assign the values for the rCutOffs
// for the various atom types that make up the
// ensemble
void Atom::setrCutOff(double **newrCut)
{
rCutOff = newrCut;
mc_Ver2.0\atomMC.cpp
Molecular simulation and object-orientation Chapter | 11 509Set the atomic masses
Set the position.
Set the trial position.
Re-set the position 
when move is 
accepted.
}
// Method: setMass
// Usage: setMass(double atomicMass);
// -----------------------------------
// Assign the mass of the atom
void Atom::setMass(double newMass)
{
mass = newMass;
}
// Method: setPosition
// Usage: setPosition(position);
// -------------------------------
// Sets the pointer within the atom object to
// point to a new 1D array of doubles,
// representing the position of the atom in
// its various dimensions. Assuming a 3D
// simulation, the required array would have 
// three elements, where:
// atomicPosition[0] = x component of position
// atomicPosition[1] = y component of position 
// atomicPosition[2] = z component of position
// Note: this method requires an _array_ to
// be passed to it which has already had
// memory allocated to it. It does not
// take on the values in the array, but the
// address of the array itself.
void Atom::setPosition(double *newPos)
{
position = newPos;
}
// Method: setTrialPosition
// Usage: setTrialPosition(newPos);
// ---------------------------------
// Assigns trial positions
void Atom::setTrialPosition(double *newPos)
{
trialPosition[0] = newPos[0];
trialPosition[1] = newPos[1];
trialPosition[2] = newPos[2];
}
// Method: reSetPosition()
// Usage: reSetPosition();
// ------------------------
// Re-sets the positions if a move
// is accepted.
void Atom::reSetPosition()
{
510 Molecular Simulation of FluidsGet the type of atom.
Get the atomic mass.
Get the cut-off value.
Get the position.
Get the trial position.
position[0] = trialPosition[0];
position[1] = trialPosition[1];
position[2] = trialPosition[2];
}
// Method: getType
// Usage: p = getType();
// ----------------------
// Gets the type associated with each atom.
int Atom::getType()
{
return type;
}
// Method: getMass
// Usage: n = getMass();
// ----------------------
// Get values of the atomic masses.
double Atom::getMass()
{
return mass;
}
// Access (Get) Methods
// Usage: n = getXxxxx();
// -----------------------
// These methods return a reference to the
// arrays which hold the values for rCutOff,
// acceleration, position, velocity, time
// step, and force.
// Method: getrCutOff
// Usage: n = getrCutOff();
// -------------------------
// Returns the cut-off distances for atoms.
double **Atom::getrCutOff()
{
return rCutOff;
}
// Method: getPosition
// Usage: n = getPosition();
// --------------------------
// Return position of atom
double *Atom::getPosition()
{
return position;
}
// Method: getTrialPosition
// Usage: n = getTrialPosition();
Molecular simulation and object-orientation Chapter | 11 511// ------------------------------
// Return the trial position
double *Atom::getTrialPosition()
{
return trialPosition;
}
11.3.3.7 Code for the LJ_Atom class
The code for the LJ_Atom class (mc_Ver2.0\ljatomMC.cpp) is identical to the cor￾responding code for the MD program, and it is therefore not listed here. This
is not surprising because the LJatom class deals with the simulation para￾meters of the Lennard-Jones potential, which are totally independent of the
nature of the simulation.
11.3.3.8 Code for the Energy class
The Energy class plays the analogous role to the Force class in the MD simu￾lation. The code for the class is a trivial adaptation of the Force class.
mc_Ver2.0\energyMC.cpp
// File: energyMC.cpp
// ----------------
// File containing functions to implement 
// the abstract EnergyMC class.
#include "energyMC.h"
// constructor
// Method: Energy
// Usage: n = Energy(atoms);
// --------------------------
// Used to construct the force component of
// any derived energy classes.
Energy::Energy(Atom **theAtoms)
{
atoms = theAtoms;
}
// destructor
EnergyMC::~EnergyMC(){}
11.3.3.9 Code for the LJ_Energy class
The constructor for the LJ_Energy class is identical to the constructor of the
LJ_Force class, and the setEnergy() method is analogous to the setForce()
method with the exception that the force calculations have been omitted. The
getTrialPotE() method reuses almost all of the code of the setEnergy() method.
The lrc() method reuses the code for the corresponding method in the
LJ_Force class.
512 Molecular Simulation of FluidsDetermine the 
potential energy of the 
ensemble at the start of 
the simulation.
// File: ljenergyMC.cpp 
// --------------------
// File containing methods to implement 
// the Ljenergy class.
#include "ljenergyMC.h"
#include “auxfunc.h”
// constructor
LJenergy::LJenergy(AtomMC **theAtoms)
:Energy(theAtoms)
{
epsilon = atoms[0]->getEpsilon();
sigma = atoms[0]->getSigma();
rCut = atoms[0]->getrCutOff();
}
// Method: setEnergy
// Usage: setEnergy();
// --------------------
// The ljenergy method calculates the energy
// experienced by all num atoms due to pair
// interatomic interaction. The energy is
// calculated using the Lennard-Jones (6-12)
// potential. The potential is truncated at a
// distance rCut and long range corrections
// must be applied outside the method to
// obtain the full contributions to energy.
void Ljenergy::setEnergy(int num, 
double length, double *potEnergy)
{
int i, j, kindi, kindj;
double rXi, rYi, rZi; //position vect. of i
double rXj, rYj, rZj; //position vect. of j
double rXij, rYij, rZij; //separation vect.
double rijSq; //separation squared
double rCutSq, sigmaSq;//squared rCut etc
double sigma2, sigma6; //sigma multiples 
double sigma12;
mc_Ver2.0\ljenergyMC.cpp
Molecular simulation and object-orientation Chapter | 11 513Outer energy loop.
Inner energy loop.
Determine pair 
separations.
Periodic boundary 
calculation.
Separation must be 
less than the cut-off 
distance for calculation 
to proceed.
double pot , eps;
double *tempPos, *tempPosj;
*potEnergy = 0.0;
// perform full N^2 calculation at the
// beginning of the simulation.
// Calculate energy experienced by atoms due
// interatomic pair interactions.
for(i = 0; i < num - 1; i++)
{
// Select molecule i
kindi = atoms[i]->getType();
tempPos = atoms[i]->getPosition();
rXi = tempPos[0];
rYi = tempPos[1];
rZi = tempPos[2];
for(j = i + 1; j < num; j++)
{
kindj = atoms[j]->getType();
tempPosj = atoms[j]->getPosition();
rXj = tempPosj[0];
rYj = tempPosj[1];
rZj = tempPosj[2];
// Calculate pair separation
rXij = rXi - rXj;
rYij = rYi - rYj;
rZij = rZi - rZj;
// Apply periodic boundary
rXij -= length * 
nearestInt(rXij, length);
rYij -= length * 
nearestInt(rYij, length);
rZij -= length * 
nearestInt(rZij, length);
rijSq = rXij*rXij + 
rYij*rYij + rZij*rZij;
// Calculate energy for separations
// below the cutoff
rCutSq = rCut[kindi][kindj] *
rCut[kindi][kindj];
if (rijSq < rCutSq){
// Determine potential between i and j
sigmaSq = sigma[kindi][kindj] *
sigma[kindi][kindj];
sigma2 = sigmaSq/rijSq;
514 Molecular Simulation of FluidsCalculate the energy of 
a trial ensemble 
obtained by displacing 
one atom a tim.
Properties of trial 
atom.
sigma6 = sigma2 * sigma2 * sigma2;
sigma12 = sigma6 * sigma6;
pot = sigma12 - sigma6;
eps = epsilon[kindi][kindj];
*potEnergy += eps * pot;
}
}
}
*potEnergy *= 4.0;
}
// Method: getTrialPotE
// Usage: getTrialPotE();
// -----------------------
// The ljenergy method calculates the energy
// experienced by a given atom (index) due to 
// pair interatomic interaction. The energy is
// calculated using the Lennard-Jones (6-12)
// potential. The potential is truncated at a
// distance rCut and long range corrections
// must be applied outside the method to
// obtain the full contributions to energy.
void LJenergy::getTrialPotE(int num,
double length, int index, Atom **atom)
{
int i, j, kindi, kindj;
double rXi, rYi, rZi; //position vect. of i
double rXj, rYj, rZj; // position vect. of j
double rXij, rYij, rZij; //separation vect.
double rijSq; //separation squared
double rCutSq, sigmaSq; //squared rCut etc
double sigma2, sigma6; //sigma multiples 
double sigma12;
double pot, potE, eps;
double *tempPos, *tempPosj;
potE = 0.0;
// Calculate energy experienced by the
// sellected atom (index)
// with all other distinct pairs
// Properties of index atom.
kindi = atom[index]->getType();
tempPos = atom[index]->getTrialPosition();
rXi = tempPos[0];
rYi = tempPos[1];
rZi = tempPos[2];
Molecular simulation and object-orientation Chapter | 11 515Energy loop.
Avoid self-interaction 
with the trial atom.
Determine pair 
separations.
Periodic boundary 
calculation.
Separation must be 
less than the cut-off 
distance for calculation 
to proceed.
// Loop over all the other atoms
for(j = 0; j < num; j++)
{
//Exclude self-interaction
if(j = != index)
{
kindj = atom[j]->getType();
tempPosj = atom[j]->getTrialPosition();
rXj = tempPosj[0];
rYj = tempPosj[1];
rZj = tempPosj[2];
// Calculate pair separation
rXij = rXi - rXj;
rYij = rYi - rYj;
rZij = rZi - rZj;
// Apply periodic boundary
rXij -= length * 
nearestInt(rXij, length);
rYij -= length * 
nearestInt(rYij, length);
rZij -= length * 
nearestInt(rZij, length);
rijSq = rXij*rXij 
+ rYij*rYij + rZij*rZij;
// Calculate energy for separations
// below the cutoff
rCutSq = rCut[kindi][kindj] *
rCut[kindi][kindj];
if (rijSq < rCutSq){
// Determine potential between i and j
sigmaSq = sigma[kindi][kindj] *
sigma[kindi][kindj];
sigma2 = sigmaSq/rijSq;
sigma6 = sigma2 * sigma2 * sigma2;
sigma12 = sigma6 * sigma6;
pot = sigma12 - sigma6;
eps = epsilon[kindi][kindj];
potE += eps * pot;
}
}
}
return 4*potE;
}
516 Molecular Simulation of FluidsDetermine long range 
corrections.
// Method: lrc
// Usage: n = lrc(num, nComp, 
// volume, energyLRC);
// ------------------------------------
// ljLRC calculates the long range correction
// term to the energy for an ensemble
// interacting via the Lennard-Jones (12-6)
// potential.
void Ljenergy::lrc(int num, int *nComp, double
boxV, double *energyLRC)
{
int i, j;
const double PI = 3.141592654;
double eps, sigmaSq, sig3, rCutSq, rCut3,
sig3R, sig9R, den;
*energyLRC = 0.0;
for(i = 0; i < num; i++)
for(j = 0; j < num; j++)
{
eps = epsilon[i][j];
sigmaSq = sigma[i][j] * sigma[i][j];
rCutSq = rCut[i][j] * rCut[i][j];
sig3 = sigma[i][j] * sigmaSq;
rCut3 = rCut[i][j] * rCutSq;
sig3R = sig3/rCut3;
sig9R = sig3R * sig3R * sig3R;
den = nComp[i] * nComp[j] *
sig3/boxV;
*energyLRC += (8.0/9.0) * den * 
PI * eps* (sig9R - 3*sig3R);
}
}
11.3.3.10 Code for the auxiliary methods
The code for the auxiliary methods (mc_ver2.0\auxfunc.cpp) is identical to
that used for the MD program and therefore it is not listed here.
11.4 Case study: combined MD and MC program for
Lennard-Jones atoms in the microcanonical ensemble
11.4.1 OOA
It is evident that the UML diagrams for the MD (Fig. 11.12) and MC simula￾tion (Fig. 11.16) have many features in common. This commonality is also
reflected in the high degree of code reuse between the two different simula￾tion programs. The MD and MC UML diagrams can be combined easily to
produce a combined analysis for simulation in general. The combined analy￾sis is illustrated in Fig. 11.17.
Molecular simulation and object-orientation Chapter | 11 51711.4.2 OOP in C11
The design presented in Fig. 11.17 did not require any new analysis to be
performed. Similarly, the implementation of the design can be achieved
almost without the addition of any new code! Two different approaches can
be taken. The code for the classes of the combined simulation program can
be obtained simply by merging the code for the MC and MD programs. For
example, to obtain the Atom class, we can combine the attributes and methods
of the Atom classes from the MC and MD programs. Alternately, we can
obtain a combined MC/MD program by simply compiling the files contain￾ing MC and MD classes together. This latter approach is adopted here.
Therefore, the only changes required to the code is a trivial modification to
the simulation class and the main(). The code for main() presented subse￾quently is identical to the corresponding code for either simulation techni￾ques with the exception that the header file for the combined simulation
class (simMCMD.h) must be used.
Atom
{abstract}
NVE_Ensemble
Gear_Predictor-Corrector
Molecular_Dynamics
Force
{abstract}
Ensemble
{abstract}
LJ_Force LJ_Atom
Integrator
{abstract}
Simulation
Monte_Carlo
Energy
{abstract}
LJ_Energy
FIGURE 11.17 UML diagram unifying the MD and MC techniques.
518 Molecular Simulation of FluidsAn object of type 
Simulation is 
instantiated. 
Call to 
readSimParameters() 
invokes the simulation 
process.
// File mainMCMD.cpp
// -----------
// This file contains the main() function 
// responsible for starting the simulation
/ process.
#include "simMC.h"
main()
{
Simulation sim;
sim.readSimParameters();
return 0;
}
mcmd_Ver2.0\mainMCMD.cpp
The description of the simulation class must contain a reference to both
the Monte_Carlo and Molecular_Dynamics object. Only one of these objects will
be instantiated depending on the choice made by the user.
UML Diagram
// File: simMCMD.h
// -----------------
// This file contains the definition of
// the Simulation class, which defines
// all methods and data for a
// Molecular Simulation, using either
// molecular dynamics or Monte Carlo.
#ifndef _simMCMD_h_
#define _simMCMD_h_
#include "mc.h"
#include “md.h”
class Simulation
{
private:
MonteCarlo *mc;
MolecularDynamics *md;
public:
void readSimParameters();
};
#endif
Simulation
-MonteCarlo *mc
-MolecularDvnamics *md
readSimParameters()
mcmd_Ver2.0\simMCMD.h
Molecular simulation and object-orientation Chapter | 11 519The simulation class is 
responsible for reading 
in the simulation 
parameters. 
In the main() an object 
of type Simulation is 
instantiated and the 
readSimparameters() 
method is called. 
The simulation settings 
are read from the 
“sim.dat” file. 
The object created 
depends on whether 
the MC or MD option 
is chosen. The 
corresponding run() 
method is called which 
starts the simulation 
process. 
// File: simMCMD.cpp
// -----------------
// This file contains the implementation of
// the Simulation class, which defines all
// methods and data for a molecular
// simulation, using either molecular 
// dynamics or Monte Carlo etc.
#include "simMCMD.h"
#include <fstream>
#include <iostream>
using namespace std; 
// Method: readSimParameters
// Usage: readSimParameters();
// ---------------------
// Reads in parameters for NVE ensemble
void Simulation::readSimParameters()
{
int simulation;
//open the sim.dat file
ifstream in;
in.open("simMCMD.dat");
if(in.fail()){
cout << "Cannot open sim.dat!\n";
return;
}
in >> simulation;
in.close();
switch(simulation)
{
case 1: //Molecular dynamics
md = new MolecularDynamics();
md->run();
break;
case 2: //Monte Carlo
mc = new MonteCarlo();
mc->run();
break;
default:
cout << "Invalid! Aborting!" << endl;
break;
}
}
return;
mcmd_Ver2.0\simMCMD.cpp
520 Molecular Simulation of FluidsApart from these trivial changes, no other changes are required to the
remaining code (mcmd_Ver2.0). This clearly illustrates the advantage of the
object-oriented approach in promoting maximum code reuse with minimal
effort. To achieve the same effect using a procedural programming approach
would almost invariably require additional code development and algorithm
changes.
11.5 Case study: extensions
An advantage of OO is that the design and code can be extended to other
situations relatively easily. For the benefit of simplicity we illustrate exten￾sions to other situations using the MC analysis as the basic building block.
Extension of the MD simulation is exactly analogous.
Simulation
Atom
{abstract}
NVE_Ensemble
Energy
{abstract}
Monte_Carlo
Ensemble
{abstract}
LJ_Atom LJ_Energy
NVT_Ensemble NPT_Ensemble
FIGURE 11.18 UML diagram showing the extension of the MC object-oriented analysis for
new ensembles.
Molecular simulation and object-orientation Chapter | 11 52111.5.1 Other ensembles
Our analysis has been limited to the microcanonical ensemble; however the
analysis can be extended easily to any desired ensemble as illustrated by
Fig. 11.18.
The additional coding implications of Fig. 11.18 are minimal. For each
new ensemble we create a new Ensemble class along the same lines as the
microcanonical ensemble. Different read-in methods (readInNVE(), readInNVE(),
and readInNPT()) will be required in the Ensemble class because each ensemble
is characterized by different properties. Similarly, because the simulation
algorithm is specific to the type of ensemble, specific run methods (runNVE(),
runNVE(), and runNPT()) are required in the Monte_Carlo class.
11.5.2 Other ensembles and other potentials
The analysis can be extended simply to include any desired potential as
shown in Fig. 11.19.
The incorporation of additional potentials such as the exp-6 (Exp6) or
hard-sphere intermolecular potential (HS) involves the creation of new
Simulation
Atom
{abstract}
NVE_Ensemble
Energy
{abstract}
Monte_Carlo
Ensemble
{abstract}
LJ_Atom LJ_Energy
NVT_Ensemble NPT_Ensemble
HS_Atom Exp6_Atom HS_Energy Exp6_Energy
FIGURE 11.19 UML diagram showing the addition of various intermolecular potentials.
522 Molecular Simulation of Fluidsclasses that inherit from the Atom class. The potential classes contain the
characteristic potential parameters. The read-in method must also be altered
to account for the different potential. However, more significantly, the choice
of potential changes the nature of the energy calculation. The creation of
potential specific energy classes such as HS_Energy and Exp6_Energy involves
new methods to account for the potential specific interactions.
11.5.3 Other ensembles, other potentials, and molecules
Our analysis has been confined to atomic systems. A strength of the OO is
that the analysis can be extended readily to molecules. By definition, a mole￾cule is composed of two or more atoms. Consequently, we can devise a
Molecule class, which is an aggregation of Atom classes. This is illustrated in
Fig. 11.20.
FIGURE 11.20 UML diagram showing the extension of the object-oriented analysis to
molecules.
Molecular simulation and object-orientation Chapter | 11 523In Fig. 11.20 the Molecule class acts as a container for Atoms that com￾pose the molecule and as such it contains information regarding the molecule
such as number of atoms, bond separation, etc.
11.6 Summary
OO has a valuable role in the development of simulation software, particu￾larly for complicated molecules and processes. It requires a shift of focus
from algorithm-centered to object-centered design. The benefit of an object￾oriented approach is that it permits a high degree of software reuse. The
reuse of code is illustrated by the high degree of commonality between the
MD and MC programs. OO allows us to manage future increases in com￾plexity much more effectively than can be achieved using procedural pro￾gramming. However, to derive full benefit of OO approach it is important
that the analysis and design aspects are carefully considered before coding
commences. Of course, redesign after coding is natural part of iterative
improvement during the software life cycle but a well-thought out initial
OOA and OOD should greatly help minimize the effort that is subsequently
required. The extent of reuse will be tested in Chapter 12 when the codes are
modified for parallel execution.
References
Abraham, M.J., Murtolad, T., Schulz, R., Szilard, P., Smith, J.C., Hess, B., Lindahl, E., 2015. ´
GROMACS: high performance molecular simulations through multi-level parallelism from
laptops to supercomputers. SoftwareX 1-2, 1925.
Amorsy, M., Grundy, J., Sadus, R.J., van Straten, W., Barnes, D.G., Kaluza, O., 2013. A suite of
domain-specific visual languages for scientific software application modeling. In:
Proceedings of the IEEE Symposium on Visual Languages and Human-Centric Computing.
Baekdal, L., Joosen, W., Larsen, T., Kolafa, J., Ovesen, J.H., Perram, J.W., Petersen, H.G.,
Bywater, R., Ratner, M., 1996. The object-oriented development of a parallel application in
protein dynamics: why we need software tools for HPCN applications. Comp. Phys.
Commun. 97, 124135.
Deitel, H.M., Deitel, P.J., 2002. C11 How to Program, fourth ed. Prentice-Hall, Englewood
Cliffs, New Jersey.
Eriksson, H.-E., Penker, M., Lyons, B., Fado, D., 2003. UML 2 Toolkit. John Wiley & Sons,
New York.
Haney, S.W., 1994. Is C11 fast enough for scientific computing? Comp. Phys. 8, 690694.
Khan, E.H., Al-A’ali, M., Girgis, M.R., 1995. Object-oriented programming for structured proce￾dural programmers. Computer 28, 4857.
Nelson, M.T., Humphrey, W., Gursoy, A., Dalke, A., Kale´, L.V., Skeel, R.D., Schulten, K.,
1996. NAMD: A parallel, object-oriented molecular dynamics program. Int. J. Supercompter
Appl. High. Perform. Comput. 10, 251268.
Parsons, D., 1997. Object-Oriented Programming with C11 , second ed. DP Publications,
London.
524 Molecular Simulation of FluidsPereira, R., Couto, M., Ribeiro, F., Rua, R., Cunha, J., Fernades, J.P., Saraiva, J., 2021. Ranking
programming languagues by energy efficiency. Sci. Compt. Program. 205, 102609.
Phillips, J.C., Hardy, D.J., Maia, J.D.C., Stone, J.E., Ribeiro, J.V., Bernardi, R.C., Buch, R.,
Fiorin, G., He´nin, J., Jiang, W., McGreevy, R., Melo, M.C.R., Radak, B.K., Skeel, R.D.,
Singharoy, A., Wang, Y., Roux, B., Aksimentiev, A., Luthey-Schulten, Z., Kale´, L.V.,
Schulten, K., Chipot, C., Tajkhorshid, E., 2020. Scalable molecular dynamics on CPU and
GPU architectures with NAMD. J. Chem. Phys. 153, 044130.
Rumbaugh, J., Blaha, M., Premerlani, W., Eddy, F., Lorensen, W., 1991. Object-Oriented
Modelling and Design. Prentice Hall, Englewood Cliffs.
Stroustrup, B., 2013. The C11 Programming Language, fourth ed. Addison-Wesley, Reading,
Massachusetts. See also: https://www.stroustrup.com/4th.html.
Stroustrup, B. 2023. A Tour of C11 , third ed. Addison-Wesley, Boston.
Thompson, A.P., Aktulga, H.M., Berger, R., Bolintineanu, D.S., Brown, W.M., Crozier, P.S.,
Veld, P.J., Kohlmeyer, A., Moore, S.G., Nguyen, T.C., Shan, R., Stevens, M.J., Tranchida,
J., Trott, C., Plimpton, S.J., 2022. LAMMPS - a flexible simulation tool for particle-based
materials modeling at the atomic, meso, and continuum scales. Comp. Phys. Commun. 271,
108171.
Molecular simulation and object-orientation Chapter | 11 525This page intentionally left blankChapter 12
GPU and CPU parallel molecular
simulation with CUDA and MPI
The previous chapters have implicitly assumed that molecular simulations are exe￾cuted in serial on a single processor. In practice, many useful molecular simula￾tion codes leverage the power of advances in parallel computation (Sanders and
Kandrot, 2011) to provide results that have immensely expanded both the value
and the scientific reach (Abraham et al., 2015; Kirk and Hwu, 2010; Couturier,
2014; Heinecke et al., 2015) of molecular simulation methods. The general
approach for parallel computing (Heermann and Burkitt, 1991; Mattson et al.,
2005) is to distribute the numerically intensive aspects over multiple processors or
cores, which are executed simultaneously. This inevitably requires the use of addi￾tional instructions in the software to take advantage of the parallel hardware archi￾tecture. The use of message passing (MP) directives, such as in OpenMP1
(Chandra et al., 2001; Quinn, 2004; Mattson et al., 2019), is a simple way to
achieve this, whereas the use of a message passing interface (MPI)2 (Pacheco,
1997; Karniadakis and Kerby, 2003) provides much greater control and customi￾zation, and as such it is arguably the most commonly used approach for multipro￾cessor systems.
Hardware architectures (Owens et al., 2008; Hwu, 2011; Sanders and
Kandrot, 2011; Barlas, 2015) have been developed by combining a central pro￾cessing unit (CPU) with a graphics processing unit (GPU). Although originally
used in gaming and to enhance image rendering (Scarpino, 2012), the use of
GPUs provides an enormous speed-up for numerical computing (Heinecke et al.,
2015). Similar to conventional parallel CPU programming, directives in the soft￾ware are required to take advantage of the GPU architecture. The most widely
used GPUs are provided by Nvidia,3 which uses the compute unified device
architecture (CUDA) language (Ansorge, 2022; Farber, 2011; Ploskas and
Samaras, 2016; Storti and Yurtoglu, 2016) to instruct the GPUs. We will focus
on CUDA, but OpenCL (Gaster et al., 2012; Munshi et al., 2012) also provides
an alternative means of GPU instruction.
1. Details of OpenMP are maintained at https://www.openmp.org
2. Details of Open-MPI are maintained at https://www.open-mpi.org
3. Details of CUDA are maintained by Nvidia at https://developer.nvidia.com/cuda-toolkit
527 Molecular Simulation of Fluids. DOI: https://doi.org/10.1016/B978-0-323-85398-9.00011-3
© 2024 Elsevier B.V. All rights reserved.This chapter aims to illustrate how the principles of parallel computation
can be applied to molecular dynamics (MD) and Monte Carlo (MC) molecular
simulation code. To achieve this goal, case studies are provided using the
serial MC and MD simulation C11 code outlined in Chapter 11. This
approach aims to maximize the clarity of explanation of the parallel imple￾mentation by making the simplest possible CUDA and MPI changes to the
serial code. The emphasis on simplicity means that no attempt has been made
to optimize the computational efficiency of the code. Details of much more
sophisticated approaches can be obtained elsewhere (Pacheco, 1997; Pacheco,
2011; Couturier, 2014; Heinecke et al., 2015). The parallel implementation
inevitably means that some explanations of CUDA and MPI directives are
required. Again, this has been kept to a minimum and it is not a substitute for
detailed sources of information that are available elsewhere (Ansorge, 2022;
Barlas, 2015; Karniadakis and Kerby, 2003; Quinn, 2004).
Code availability
The CUDA and MPI source code for programs developed in the case studies are
available for download formthe book’s website, whichismaintained bythe publisher:
https://www.elsevier.com/books-and-journals/book-companion/9780323853989.
A software user’s guide is given in the Appendix.
12.1 Basic GPU implementations with CUDA
Traditional computing involves executing code exclusively on either one CPU
or distributing the computational load on several CPUs. In contrast, GPU pro￾gramming involves coordinating the calculations between a host CPU and a
GPU, which is commonly referred to as the device. Modern high-performance
computers (Couturier, 2014; Hou et al., 2013) involve both multiple CPUs and
GPUs. However, for the benefit of simplicity, our discussion will be limited to
a prototype system comprising one CPU and one GPU. Hereafter, the terms
“host” and “device” will be used almost exclusively. The host and the device
have their own separate areas of memory, and a lot of GPU programming
involves the allocation/deallocation of memory and copying the stored mem￾ory of variables between the host and the device as required.
The CUDA language possess many functions, keywords, and other syntax
to handle interactions between the host and the device, which are being contin￾ually expanded and modified. In the case studies detailed below, we will
restrict our attention to only a small subset of the available options that are
necessary to implement the serial codes on the GPUs. These are summarized
in Table 12.1. Ansorge (2022) and Storti and Yurtoglu (2016) have provided
comprehensive descriptions of CUDA for scientific applications. Depending
on how much time has elapsed since publication, it is likely that alternative
functions will be available but, assuming backward compatibility is main￾tained, the implementations given here should still work.
528 Molecular Simulation of Fluids12.1.1 Defining a Kernel
The first step in creating a GPU program is to determine the computational
intensive parts and create the so-called kernel functions that are called from the
host but executed of the device. The syntax of a kernel function is the same as
a C/C11 function but with the addition of the __global__ specifier, that is,
__global__
void nameOfKernel(parameter list …)
{
// body of kernel
}
The other distinguishing feature of the kernel is that void is the only pos￾sible return type. The code within the kernel is largely indistinguishable
from C/C11 code expect for a few additional CUDA statements required by
TABLE 12.1 Summary of key CUDA functions or syntax used in the case
studies.
CUDA code Description
__global__ Specifier used for kernel functions
__device__ Specifier used for functions that are accessed in a
kernel
__shared__ Specifier to indicate shared memory
__syncthreads() Function to synchronize threads on the device
cudaMalloc() Function to allocate memory on the device
cudaMemcpy() Function to copy memory to or from the device
cudaMemcpyHostToDevice Keyword used in cudaMemcpy() to indicate
memory is copied from host to device
cudaMemcpyDeviceToHost Keyword used in cudaMemcpy() to indicate
memory is copied from device to host
cudaFree() Function to free memory on the device
,,, x, y ... Syntax used when kernel is launched, providing
details of the number of blocks (x) and the size of
the blocks (y)
threadIndex.x Keyword for the index of threads in a block
blockIndex.x Keyword for the index of the block
blockDim.x Keyword for the number of threads in the block
gridDim.x Keyword for the number of threads in a grid
composed of all the blocks
GPU and CPU parallel molecular simulation with CUDA and MPI Chapter | 12 529the device. Other functions can be accessed within the kernel but they must
have the __device__ specifier, that is,
__device__
return type nameOfDeviceFunction
{
// body of device function
}
where type is the data type of the variable being retuned, that is, int, float,
double, etc. Unlike the kernel itself, the device function can have any possi￾ble return type.
12.1.2 Allocating and copying memory
Memory for pointer variables is allocated on both the host and the device,
which is handled via various memory functions. Memory on the host is allo￾cated in the normal way using malloc():
pointer = (type *) malloc (sizeof(type));
The cudaMalloc() function is used to allocate memory on the device, that is,
cudaMalloc((void **) &pointer_dev, sizeof(type));
Notice that, in this example, the _dev suffix has been appended to the
name of the device variable. This is a handy convention to distinguish
between host (no suffix) and device variables.
The cudaMemcpy() function handles the copying of pointers to and from
the device. This is necessary to allow the device access to pointers allocated
on the host. To copy a pointer to the device, we make use of the keyword
cudaMemcpyHostToDevice, that is,
cudaMemcpy(pointer_dev, pointer, sizeof(type), cudaMemcpyHostToDevice);
After the kernel is invoked, any pointer on the device can be copied to
the host by using the reverse of this function, that is,
cudaMemcpy(pointer, pointer_dev, sizeof(type), cudaMemcpyDeviceToHost);
This is necessary for the host to access any pointers modified by the
device. It is also advisable to free memory when no longer required. This is
done on the host side via:
free(pointer);
cudaFree(pointer_dev);
530 Molecular Simulation of Fluids12.1.3 Launching the kernel
It is common GPU parlance to use the word “launch” for the invocation of a
kernel. The kernel is launched (or invoked) by the statement:
nameOfKernel <<< numOfBlocks, blockSize >>> (parmeter list …);
The kernel is launched in the same way as any other void function except
for the terms contained within the ,,, ... bracket, which is responsible
for the parallel execution of the code. The variable blockSize is the number of
threads per block. GPUs execute kernels using blocks of threads that are in
multiples of 32, and the programmer has discretion to choose a
suitable value depending on the size (N) of the computation. In a molecular
simulation, N will be the number of particles. To distribute the calculation
among parallel threads, numOfBlocks is determined via the relationship,
numOfBlocks = (N + blockSize – 1)/blockSize
where the use of 1 and integer division ensures the correct number of
blocks to obtain at least N threads.
Collectively, the blocks of parallel threads constitute a grid. In one dimen￾sion, CUDA makes use of keywords, threadIndex.x (the index of the threads
within the block), blockIndex.x (the index of the block), blockDim.x (the number
of threads in each block), and gridDim.x (the number of threads in the grid com￾posed of all blocks) to appropriately distribute the calculation within the kernel.
In all cases the indices commence from 0. We will examine this in more detail
when developing the appropriate simulation kernels. There are similar keywords
for the y and z dimensions, but we will not make use of these here.
12.1.4 Reduction
When GPUs are used, the properties evaluated in a molecular simulation, such as
energy and pressure, are evaluated in a GPU application across multiple threads
in different blocks. These partial results need to be summed in a process known
as reduction. In contrast to MPI (see Section 12.5), there is no CUDA function
that performs this operation. Instead, a suitable user-specified code is required.
There are many considerations that are required to optimize this process, involv￾ing factors such as interleaved or sequential addressing. Here, we will adapt a
simple approach reported by Harris,4 which is suitable for molecular simulation.
The general approach is to perform the reduction process for all the threads in
each block during the execution of the kernel and sum the contributions on the
host. The reduction process is common to both MD and MC simulations.
4. Harris, M., https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf (last accessed
in January 2023).
GPU and CPU parallel molecular simulation with CUDA and MPI Chapter | 12 531The CUDA code for the reduction operation is given in Listing 12.1.
LISTING 12.1 CUDA code for the reduction operation.
1. Code to be executed on the device within the kernel 
// Shared memory is required to sum the energy (and any other of property) from 
// the diiferent threads.
__shared__ double kernelECache[numThreadsInBlock];
// Add similar statements for other properties here
// Insert code for force/energy calculations here
int cacheIndex = threadIdx.x; 
//Set the kernel cache values after force/energy calculation
kernelECache[cacheIndex] = potE;
// Set other cache values here as required for other properties
// Synchronize thread in this block
__syncthreads();
// Perform reductions, assuming numThreadsInBox is a power of 2.
int k = blockDim.x/2; 
while(k != 0)
{
if(cacheIndex < k)
{
kernelECache[cacheIndex] += kernelECache[cacheIndex + k];
// Add other cache values here as required for other properties
}
__syncthreads();
k /= 2;
}
if(cacheIndex == 0)
{
potEnergy[blockIdx.x] = kernelECache[0];
// Add other array entries here as required for other properties
}
2. Code to be executed on the host following the completion of the kernel
// Sum the partial contributions of the CPU side 
potE = 0;
//Initialize other sums here as required for other properties
for(int k = 0; k < numBlocks; k++)
{
potE += potEnergy[k]; 
// Accumulate other properties here as required
} 
532 Molecular Simulation of FluidsIn Listing 12.1, codes are provided that must be separately executed on
the device and the host. The device code forms part of the kernel that evalu￾ated either the force (MD) or the energy (MC and MD). To perform the
required reduction, a shared memory is required, which explains the follow￾ing array definition:
__shared__ double kernelECache[numThreadsInBlock];
Prior to the reduction operation, the threads in the block are
synchronized:
__syncthreads();
The code assumes that numThreadsInBox is a power of 2, which allows the
initial value of k of the while loop to be determined by
int k = blockDim.x/2;
The while loop continues to sum the required properties until the 0 index
is encountered, with k being halved for each new iteration. When cacheIndex
equals 0, the complete sum of the property of the block is stored. It is only
after the execution of the kernel is completed that the complete value to the
property is obtained by adding together the individual block contributions on
the host.
12.1.5 General GPU algorithm
As will be illustrated in the case studies discussed subsequently, some
general steps are required both before and after the launch of the kernel.
These steps, which are not restricted to molecular simulation, are given in
Algorithm 12.1.
ALGORITHM 12.1 General procedure for GPU implementation via a kernel.
Part 1. Identify the computationally intensive code to be executed on
the GPU using a kernel (nameOfKernel(parameters)). 
Part 2. Specify the number of threads (blockSize) and use this with 
the size of the calculation (N) to determine numOfBlocks: 
numOfBlocks (N + blockSize – 1)/blockSize 
Part 3. Devise a way to distribute the calculation amongst the 
threads using code inside of the kernel, e.g.,
GPU and CPU parallel molecular simulation with CUDA and MPI Chapter | 12 533Part 3.1 tID threadIdx.x + blockIdx.x * blockDim.x 
step blockDim.x * gridDim.x
Part 3.2 loop i tID ... N
.
.
i i + step
end i loop
Part 3.3 Perform any necessary reductions (Listing 12.1).
Part 4. Allocate array/pointer memory required by the host and
device with malloc() and cudaMalloc().
Part 5. Copy arrays/pointers from the host to the device
with cudaMemcpy(….. cudaMemcpyHostToDevice ). 
Part 6. Launch the kernel:
nameOfKernel <<<numBlocks, blockSize>>> (parameters)
Part 7. Copy required arrays/pointers from the device to the host
with cudaMemcpy(….cudaMemcpyDeviceToHost).
Part 8. Perform any required post-kernel calculations on the host.
Part 9. Free array/pointer memory on the device and host 
with cudaFree() and free(). 
12.1.6 Compiling molecular simulation codes using CUDA
The details for compiling the CUDA codes are summarized in the software user’s
guide given in the appendix. However, there is an important issue that affects the
accuracy of molecular simulations, which warrants particular attention. GPUs and
CUDA were not specifically designed for numerical computation but primarily to
incorporate the requirements of both graphics and gaming applications. To opti￾mize these latter applications, the floating-point multiply-add (FMAD) instruction
is widely used and, at the time of writing, the default setting for the CUDA com￾piler (nvcc) is to replace as much as possible of the floating-point computations
with FMAD instructions. The effect of the FMAD instructions is to reduce the
precision of the calculations. As maintaining precision is very important for the
accuracy of molecular simulations, the code should be compiled without FMAD
instructions, which is achieved by using the --fmad 5 false compiler directive.
12.2 Case study: CUDA implementation of MD code
(/mdCU_Ver2.0)
The starting basis for the GPU code development is the serial MD code as detailed
in Chapter 11 (found in the directory /md_Ver2.0). The advantage of using this code
534 Molecular Simulation of Fluidsis that it has been previously tested, and it is known to work correctly in serial. This
is important because the results obtained from the parallel code must exactly match
the serial case. Even small deviations are a sign that errors have been made and
should never be dismissed as unimportant. Retrofitting parallel concepts to serial
code also has the learning advantage of focusing on the key elements of CUDA,
providing lessons that can be easily applied to other situations. The goal of this case
study is to transform the serial MD code to work on GPUs as simply as possible.
This almost invariably means that optimal performance cannot be realistically
expected because parallel execution was not incorporated into its initial design.
The most straightforward way (Heermann and Burkett, 1991) to introduce par￾allelization in a molecular simulation is via force/energy decomposition, which
involves assigning the force/energy calculation among different threads or CPUs.
This is the approach that is used here. An alternative approach is spatial or domain
decomposition (Fincham, 1987), which splits the computational load into different
regions. The merits of different approaches is discussed elsewhere (Li et al., 2006,
2008). It should also be noted that our case studies involve simple pairwise interac￾tions using the Lennard-Jones (LJ) potential (Chapter 3) and as such they do not
address the complexities involved in electrostatic interactions. Issues involved in
parallel implementation for induction and three-body interactions are detailed else￾where (Li et al., 2006, 2008). Considerable progress has been reported in using
GPUs in large-scale simulations involving fast multiple methods (Chapter 5)
(Kohnke et al., 2020) and biological systems (Phillips et al., 2020).
Our implementation of the MD program in CUDA code (found in the direc￾tory /mdCU_Ver2.0) maintains all but one of the existing .cpp and .h files: ljforceMD.
cpp becomes ljforceMD.cu. There is only one additional .cu file (cudaSimKernels.cu)
plus a corresponding header file (cudaSimKernels.h). The compiler requires the.cu
suffix for the two source files. The only changes to the class definitions are con￾fined to atom. The key changes to the files are summarized in Table 12.2.
12.2.1 Key variable additions
In the atom class (atomMD.h), the following public variables have been added:
int *kind; // atom type
double *r; // position vector
double *f; // force array
double *rCutii // cut-off distance
double *epsii; // LJ parameter
double *sigii; // LJ parameter
The addition of these new public variables is entirely for the pragmatic reason
of avoiding the need to pass objects to kernels. The r and f pointers are the key
changes, whereas the other variables are included to maintain the generality of the
code to handle mixtures and as such are not required for pure systems. Apart
from these simple additions, no other changes are required in the class definitions.
Values for these additional variables are initialized in the md.cpp file. The
required additional code is given in Listing 12.2.
GPU and CPU parallel molecular simulation with CUDA and MPI Chapter | 12 535TABLE 12.2 Summary of key changes and additions to the MD files.
Existing file New file Description of changes and/or
additions
atomMD.h New public variables added to the
atom class
md.cpp New code to initialize additional
variables in the atom class
gearPC.cpp Minor code changes to reflect the use
of the variables added to the atom class
cudaSimKernels.h Definition of the kernel setLJForceKernel
cudaSimKernels.cu Code to implement the kernel
setLJForceKernel
ljforceMD.cpp ljforceMD.cu The .cpp suffix is replaced with .cu.
Instead of performing the calculations,
the kernel setLJForceKernel is
launched, which requires the addition
of memory management code
LISTING 12.2 Additional code required in md.cpp to initialize the new
variables in the atom class.
atom = ensemble->getAtoms(); 
for(i = 0; i < num; i++)
{
position = atom[i]->getPosition();
atom[0]->r[3*i] = position[0];
atom[0]->r[3*i + 1] = position[1];
atom[0]->r[3*i + 2] = position[2];
l = atom[0]->kind[i] = atom[i]->getType();
eps = atom[0]->getEpsilon();
sig = atom[0]->getSigma();
cut = atom[0]->getrCutOff();
atom[0]->epsii[i] = eps[l][l];
atom[0]->sigii[i] = sig[l][l];
atom[0]->rCutii[i] = cut[l][l];
}
536 Molecular Simulation of FluidsAs it is apparent from the above initializations, the atom[0] array becomes the
master array for the GPU implementation containing the properties of the ensem￾ble. Small changes are required in gpcMD.cpp to reflect the use of the atom[0] array.
12.2.2 The force kernel
The most time-consuming operation in the MD code is the evaluation of the
forces (Algorithm 12.1, Part 1), which are evaluated in the ljforceMD.cpp
file. The heart of this code becomes the kernel setLJForceKernel, which is
defined in cudaSimKernels.h as:
__global__
void setLJForceKernel(int num, int *type, double length, double *rCut,
double *sigma, double *epsilon, double *r, double *force, 
double *potEnergy, double *virial);
The complete implementation is found in the cudaSimKernels.cu file, and
here we focus on the key CUDA features of the code. A partial listing, with
the salient features, is given in Listing 12.3.
In the force code, the calculations of potE and virE are spread among the
various threads in the different blocks and their values need to be reduced.
This requires a few memory operations and a purpose-built reduction code,
such as given in Listing 12.1. First, the shared memory is needed to sum
potE and virE of the different threads. This requirement explains the following
array declarations:
__shared__ double kernelECache[numThreadsInBlock];
__shared__ double kernelVCache[numThreadsInBlock];
When the kernel is launched, multiple blocks of multiple threads are exe￾cuted in parallel. This means that we must account for the thread identity
(tID), which is conveniently determined by
int tID = threadIdx.x + blockIdx.x * blockDim.x;
That is, the identity of the thread is determined by calculating the offset
(block index multiplied by block size) to the beginning of its block. This is a
standard code for GPU applications and not specific to our molecular simula￾tions (Algorithm 12.1, Part 3.1)
In a serial MD code, the forces are evaluated using a step size of one. In
contrast, the key to obtain parallelism is to use a very large step size
(Algorithm 12.1, Part 3.1) determined by
int step = blockDim.x * gridDim.x;
This is a very simple but effective way to divide force calculation among
the threads, which is in contrast to other more sophisticated approaches (Li
et al., 2006, 2008) used in MPI applications.
GPU and CPU parallel molecular simulation with CUDA and MPI Chapter | 12 537LISTING 12.3 Key code details for the kernel setLJForceKernel.
// Shared memory is required to sum the energy and virial of
// the diiferent threads. 
__shared__ double kernelECache[numThreadsInBlock];
__shared__ double kernelVCache[numThreadsInBlock];
// Distribute calculations among the threads
int tID = threadIdx.x + blockIdx.x * blockDim.x;
int cacheIndex = threadIdx.x;
int step = blockDim.x * gridDim.x;
potE = 0.0;
virE = 0.0;
// Calculate forces experienced by ALL distinct pairs of atoms 
// without using Newton's third law short cut (fij = -fji).
for(i = tID; i < num; i += step)
{
// Type of atom i
kindi = type[i];
rXi = r[3*i];
rYi = r[3*i + 1];
rZi = r[3*i + 2];
fXi = force[3*i];
fYi = force[3*i + 1];
fZi = force[3*i + 2];
for(j = 0; j < num; j++)
{
// Exclude self-self interaction
if(j != i)
{
// Type of atom j
kindj = type[j];
// Select position vectors
rXj = r[3*j];
rYj = r[3*j + 1];
rZj = r[3*j + 2];
// Calculate pair separation
rXij = rXi - rXj;
rYij = rYi - rYj;
rZij = rZi - rZj;
// Apply periodic boundary conditions
div = rXij/length;
if(rXij >= 0)
nInt = (int)(div + 0.5);
538 Molecular Simulation of Fluidselse
nInt = -(int)(0.5 - div);
// Add similar code for rYij, and rZij here
// Account for dissimilar atoms in a binary mixture for rCutSq (code not shown)
if (rijSq <= rCutSq)
{
// Account for dissimilar atoms of binary mixture here (code not shown)
// Determine potential between i and j
sigmaSq = sig * sig;
sigma2 = sigmaSq/rijSq;
sigma6 = sigma2 * sigma2 * sigma2;
sigma12 = sigma6 * sigma6;
pot = sigma12 - sigma6;
potE += 4*eps * pot;
virE += 24*eps * (pot + sigma12)/3;
// Calculate forces between atoms
fij = 24 * eps * (pot + sigma12)/rijSq;
fXij = fij * rXij;
fYij = fij * rYij;
fZij = fij * rZij;
fXi += fXij;
fYi += fYij;
fZi += fZij;
} // end of rijSq check
} // end of i != j check
} // end of j loop 
force[3*i] = fXi;
force[3*i + 1] = fYi;
force[3*i + 2] = fZi;
} // end of i loop
// Values of energy terms are halved because ALL pairs, including
// Indistinguishable pairs (ij and ji), were included in the calculations
potE /= 2.0;
virE /= 2.0;
// Implement reduction (listing 12.1) here before returning to the host
kernelECache[cacheIndex] = potE;
kernelVCache[cacheIndex] = virE;
The code for step is common to most GPU applications, and CUDA auto￾matically determines both blockDim.x and gridDim.x for us.
GPU and CPU parallel molecular simulation with CUDA and MPI Chapter | 12 539In most respects, the above code is a minor variation of the standard force
evaluation such as that coded in ljforceLJ.cpp. The calculations in the outer force
loop (Algorithm 12.1, Part 3.2) are commenced from tID and incremented by step.
When num is small, the value of step can be relatively large, which means few
executions in a given block. Although this is not optimal, MD simulations with
only a few hundred atoms still benefit from a very large speed-up. It should be
noted that MD code with millions of atoms (Heinecke et al., 2015) can be very
efficiently executed on GPU-enabled code, which means the relative system size
computational impediment of serial code is not an issue for GPU applications.
An important difference with the serial code is that the force loop calculates
all interaction pairs, that is, it does not use Newton’s third law shortcut. The rea￾son that Newton’s third law shortcut cannot be safely used is that the assignment
of the jth contribution on any given thread is in a race with the assignment of the
jth contribution on other threads.5 The parallel code without the shortcut will eval￾uate twice as many interactions than the serial code. This means that the values of
potE and virE are halved after the force evaluation to reflect the fact that indistin￾guishable pairs were included. The large speed-up of the GPU implementation
more than compensates for the additional force evaluations. The shortcut can be
successfully implemented (Pacheco, 2011), but this requires great care and the
gains are at least partially offset by other computational impediments.
Other relatively minor differences in the above code compared with the serial
version stem from the introduction and use of the additional public variables in the
atom class as detailed previously. A host function cannot be called from within a
kernel, which means that rather than handling the periodic boundary conditions
(PBC) using the nearestInt() function, the code for the PBC is explicitly given in the
kernel. The alternative6 would be to write the nearestInt() function specifically for
the device using the __device__ specifier. After the force evaluation, a reduction is
performed as given in Listing 12.1. The kernelECache[] and kernelVCache[] arrays are
subsequently summed on the host to obtain the total energy and virial, respectively.
12.2.3 Launching the force kernel
The creation of the kernel setLJForceKernel means that the role of the ljforceMD
method is to launch the kernel (Algorithm 12.1, Part 6) and handle the memory
requirements (Algorithm 12.1, Parts 4, 5, and 7) for the interaction between the
host and the device. The ljforceMD.cpp file is redesigned as ljforceMD.cu because it
now contains the kernel. A partial listing ljforceMD.cu is summarized in Listing 12.4.
5. This also applies to OpenMP and MPI code. Some publicly distributed parallel codes do not
appear take this into account, which means that care is required when choosing codes for
research applications. This is an insidious problem that could be easily masked by the the calcu￾lated statistical uncertainties. As a precaution, parallel code should be initially tested by compari￾son with results from the equivalent serial code.
6. This complication can be avoided by simply using the round() function (Chapter 5) in the
PBC statements.
540 Molecular Simulation of FluidsLISTING 12.4 Key code details for ljforceMD.cu.
int blockSize = numThreadsInBlock;
int numBlocks = (num + blockSize - 1)/blockSize;
// Initialize forces
for(int i = 0; i < num; i++)
{
atoms[0]->f[3*i] = 0;
atoms[0]->f[3*i + 1] = 0;
atoms[0]->f[3*i + 2] = 0;
}
// Allocate memory on the host
energy = (double *) malloc(numBlocks*sizeof(double));
vir = (double *) malloc(numBlocks*sizeof(double));
// Allocate memory on the device
cudaMalloc((void **) &r_dev, 3*num*sizeof(double));
// Add similar cudaMalloc() statements for force_dev, energy_dev, vir_dev, kind_dev, 
// sigma_dev, epsilon_dev and rCut_dev here
// Copy arrays to the deivice
cudaMemcpy(r_dev, atoms[0]->r, 3*num*sizeof(double), cudaMemcpyHostToDevice);
// Add similar cudaMemcpy() statements for force_dev, force_dev, kind_dev, 
// sigma_dev, epsilon_dev and rCut_dev here 
// Launch the kernel on the device
setLJForceKernel <<<numBlocks, blockSize>>> (num, kind_dev, length, 
rCut_dev, sigma_dev, epsilon_dev, r_dev, force_dev,
energy_dev, vir_dev); 
// Copy the 'energy' 'virial' and 'force' arrays back from the device to the host
cudaMemcpy(energy, energy_dev, numBlocks*sizeof(double), cudaMemcpyDeviceToHost);
cudaMemcpy(vir, vir_dev, numBlocks*sizeof(double), cudaMemcpyDeviceToHost);
cudaMemcpy(atoms[0]->f, force_dev, 3*num*sizeof(double), cudaMemcpyDeviceToHost);
// Determine potE and virE
potE = 0;
virE = 0;
for(int k = 0; k < numBlocks; k++)
{
potE += energy[k]; 
virE += vir[k];
} 
*potEnergy = potE;
*virial = virE;
// Free memory on the device
cudaFree(energy_dev);
// Add similar cudFree() statements for r_dev, force_dev, kind_dev,sigma_dev
// epsilon_dev and rCut_dev here
// Free memory on the host
free(energy);
free(vir);
GPU and CPU parallel molecular simulation with CUDA and MPI Chapter | 12 541At the outset, the calculations are distributed among the threads as out￾lined above by determining blockSize and numBlocks. These values are calcu￾lated using numThreadsInBlock (Algorithm 12.1, Part 2), which is a symbolic
constant defined in cudaSimKernels.h. The force array is reinitialized prior to
the execution of the kernel.
Memory for pointer variables that are passed to the kernel is allocated on
both the host and the device using suitable malloc() and cudaMalloc() state￾ments, respectively (Algorithm 12.1, Part 4). Memory for the arrays is copied
to the device using cudaMemcpy() statements (Algorithm 12.1, Part 5), which
involve the cudaMemcpyHostToDevice keyword.
Having established the appropriate memory requirements, the kernel
setLJForceKernel is launched with numBlocks and blockSize specified between
,, , and .. . (Algorithm 12.1, Part 6). The remaining parameters are
passed to the kernel in the conventional way for a normal function.
After the execution of the kernel is completed, cudaMemcpy() statements
using the cudaMemcpyDeviceToHost keyword are required to copy values
from the device to the host (Algorithm 12.1, Part 7). This is restricted to
values of f, energy, and vir arrays, as these are the only quantities that are
required for further computations on the host (Algorithm 12.2, Part 8). The
remainder of the code involves adding the contributions of the energy and vir
arrays to obtain potE and virE and using free() and cudaFree() statements to
release memory on the host and the device, respectively (Algorithm 12.1,
Part 9).
12.2.4 Changes to the MD integrator
The integrator code, in this case gearPC.cpp, is also a candidate for transforma￾tion into one or more kernels. However, as there is a trade-off among memory
management, communication, and kernel execution time, this would not have
much (if any) additional computational advantage compared with the speed-up
of the force calculation. Therefore the modifications to gearPC.cpp have been
restricted to the changes required to evaluate the positions, velocities, accelera￾tion, and higher derivatives involving the new public variables introduced in
the atom class. Nonetheless, it would be a useful exercise to apply the above
concepts to the gearPC.cpp code and compare the different outcomes.
12.3 Case study: CUDA implementation of MC code
(/mcCU_Ver2.0)
The transformation of the serial MC code of Chapter 11 (found in the directory
/mc_Ver2.0) for use on GPUs can be achieved in a similar way to the transfor￾mation of the MD code in the MC case study. Indeed, much of the CUDA
code required for MC is identical to MD, and as such, the discussion of these
common aspects will not be repeated here, except to point out the similarities.
542 Molecular Simulation of FluidsA summary of the key changes to the serial MC code is given in Table 12.3. In
common with the MD case, the details closely follow Algorithm 12.1.
In common with the transformed MD code, the .cpp files are retained,
with the ljenergyMC.cpp file redesignated as ljenergyMC.cu. The additional files
are cudaSimKernels.cpp and cudaSimKernels.cu.
12.3.1 Energy kernels
The serial MC code involves two types of energy calculations. At the begin￾ning of the simulation, the energy is determined (setEnergy()) for all indistin￾guishable pair of atoms. Thereafter, the change in energy (getTrialPotE()) is
calculated in response to attempted atom displacements, which involves only
N 2 1 calculations. This means that two key kernels for the calculation of
energy can be identified (Algorithm 12.1, Part 1). Namely, one for calculat￾ing the total energy of all pairs (setLJEnergyKernel) and another for calculating
the energy of a simple atom with all other atoms (energyLJKernel). The proto￾type statements for these kernels are found in cudaSimKernels.h, and the code
is given in cudaSimKernels.cu. The prototype statements are:
TABLE 12.3 Summary of key changes and additions to the MC files.
Existing file New file Description of changes and/or
additions
atomMC.h New public variables added to the atom
class
mc.cpp New code to initialize additional variables
in the atom class
cudaSimKernels.h Definition of the kernels
setLJEnergyKernel and energyLJKernel
cudaSimKernels.cu Code to implement the kernels
setLJEnergyKernel and energyLJKernel
ljenergyMC.cpp ljenergyMC.cu The .cpp suffix is replaced with .cu.
Instead of performing the calculations, the
kernels setLJEnergyKernel
energyLJKernel are launched from the
setEnergy() and getTrialPotE() methods,
respectively. This requires the addition of
memory management code
GPU and CPU parallel molecular simulation with CUDA and MPI Chapter | 12 543_global__
void setLJEnergyKernel(int num, int *type, double length, double *rCut,
double *sigma, double *epsilon, double *r, double *energy); 
__global__
void energyLJKernel(int num, int index, int *type, double length, double *rCut,
double *sigma, double *epsilon, double *ri, double *r, double *potEnergy);
Although the setLJEnergyKernel has a relatively minor role in either NVE
or NVT MC simulations, it has nonetheless been implemented in our CUDA
code for both the benefit of completeness and its utility in future NpT code
for which it would have an important role. For the benefit of brevity, we will
focus on the details of the kernel energyLJKernel, which also reflect most of
the aspects of the kernel setLJEnergyKernel. However, before proceeding fur￾ther, it is important to note that, unlike the equivalent serial code, the
setLJEnergyKernel code is not restricted to indistinguishable pairs. This change
ensures that no ij pairs are missed in the process of parallelization.
Therefore the value of any property calculated in the all-pair energy calcula￾tion must be halved.
A partial listing of the code for the kernel energyLJKernel is given in
Listing 12.5. Comparing Listing 12.5 with Listing 12.1, it is apparent that
CUDA implementation of the MC code to determine the energy is identical
to the steps required for the force evaluation. Apart from the fact that only
N 2 1 interactions are evaluated, the difference between the two listings are
largely confined to the existing differences in the serial code that are
required to evaluate forces instead of energies. The mechanism (Algorithm
12.1, Part 3.1) to distribute the calculation between threads using tID and a
loop (Algorithm 12.1, Part 3.2) increment size of step instead of 1 are the
same in both cases.
LISTING 12.5 Key code details for the kernel energyLJKernel.
__shared__double kernelECache[numThreadsInBlock];
int tID = threadIdx.x + blockIdx.x * blockDim.x;
int cacheIndex = threadIdx.x;
int step = blockDim.x * gridDim.x;
// Calculate energy experienced by the selected atom (index)
// with all other distinct pairs
kindi = type[index];
potE = 0.0;
544 Molecular Simulation of Fluids// Loop over all the other atoms
for(int j = tID; j < num; j += step) 
{ 
// Exclude self-interaction
if(j != index)
{
rXij = ri[0] - r[3*j];
rYij = ri[1] - r[3*j + 1];
rZij = ri[2] - r[3*j + 2];
// Apply periodic boundary conditions
div = rXij/length;
if(rXij >= 0)
nInt = (int)(div + 0.5);
else
nInt = -(int)(0.5 - div);
rXij -= length * (double) nInt;
// Add similar code for rYij, and rZij here
// Add code here to account for dissimilar atoms in the binary mixture
// Calculate forces for separations below the cutoff
if (rijSq <= rCutSq)
{
// Add code here to account for dissimilar atoms in the binary mixture
sigmaSq = sig * sig;
sigma2 = sigmaSq/rijSq;
sigma6 = sigma2 * sigma2 * sigma2;
sigma12 = sigma6 * sigma6;
pot = sigma12 - sigma6;
potE += eps*pot;
} // end rijSq if
} // end j != index if 
} // end for loop
// Implement reduction (listing 12.1) here before returning to the host 
kernelECache[cacheIndex] = 4*potE;
12.3.2 Launching the energy kernels
The use of energy kernels means that that role of the getTrialPotE() and
setEnergy() methods is largely confined to preparing launching the kernels
(Algorithm 12.1, Part 6). As the details of the two kernels have a high degree
of commonality, we will only detail the steps for getTrialPotE().
GPU and CPU parallel molecular simulation with CUDA and MPI Chapter | 12 545LISTING 12.6 Key code details of getTrialPotE.cu.
// Distribution among threads
int blockSize = numThreadsInBlock;
int numBlocks = (num + blockSize - 1)/blockSize;
// Assign properties of the index atom
position = atom[index]->getTrialPosition();
ri[0] = position[0];
ri[1] = position[1];
ri[2] = position[2];
// Allocate memory on host
ri = (double *) malloc(3*sizeof(double)); 
energy = (double *) malloc(numBlocks*sizeof(double));
// Allocate memory on device
cudaMalloc((void **) &ri_dev, 3*sizeof(double));
// Similar cudaMalloc statements for r_dev, energy_dev, kind_dev, 
// sigma_dev, epsilon_dev and rCut_dev
// Copy memory to device
cudaMemcpy(ri_dev, ri, 3*sizeof(double), cudaMemcpyHostToDevice);
// Similar cudaMemcpy statements for r_dev, kind_dev, sigma_dev, 
// epsilon_dev and rCut_dev
// Launch kernel
energyLJKernel <<<numBlocks, blockSize>>> (num, index, kind_dev, length, rCut_dev, 
sigma_dev, epsilon_dev, ri_dev, r_dev, energy_dev); 
// Copy memory to host
cudaMemcpy(energy, energy_dev, numBlocks*sizeof(double), cudaMemcpyDeviceToHost);
// Sum partial results from reduction in device
for(int k = 0; k < numBlocks; k++)
potE += energy[k];
// Free memory on device
cudaFree(energy_dev);
// Additional cudaFree() statements for ri_dev, r_dev, kind_dev, 
// sigma_dev, epsilon_dev, rCut_dev
// Free memory on host
free(energy);
free(ri);
It is evident that Listing 12.6 for MC largely mirrors Listing 12.3 for MD.
12.4 Parallel programming with MPI
MPI provides the functions to allow computations to be distributed over mul￾tiple CPUs or cores. There are a large number of MPI functions, which are
examined in detail elsewhere (Karniadakis and Kirby, 2003; Quinn, 2004).
546 Molecular Simulation of FluidsWe will only focus on a very small subset of these functions that represent
the bare minimum to execute the serial MD and MC codes in parallel. These
are summarized in Table 12.4. As the aim is to illustrate parallel concepts as
simply as possible, it is almost inevitable that the computational efficiency
of the resulting code will not be optimal.
12.4.1 General MPI procedure
Our implementation of MPI for both the MD and MC simulations will follow
the general procedure in Algorithm 12.2, the details of which also apply to
other situations.
TABLE 12.4 Summary of key MPI functions or syntax used in the case
studies.
MPI function or syntax Description
MPI_Init (&argc, &argv) Initialize the MPI process to setup the use of
the MPI library
MPI_Finalize() Called after MPI functions are no longer
needed, used to free memory etc. It is
typically the last statement in main
MPI_Datatype The data type, e.g., MPI_DOUBLE,
MPI_INT, for double, int, respectively
MPI_Op The type of operation, e.g., MPI_SUM,
MPI_PROD, for addition and
multiplication, respectively
MPI_Comm The type of communication, e.g.,
MPI_COMM_WORLD for all the processor
running at the start of execution
Int MPI_Comm_size(MPI_Comm,
int size)
Determine the number of processors that
can send message, i.e., the size parameter
is the number of processors used in the
communicator
Int MPI_Comm_rank(MPI_Comm,
int rank)
Determine the rank of the process via the
rank parameter
Int MPI_Allreduce(void  input, void
result, int, size, MPI_Datatype,
MPI_Op, MPI_Comm)
Combine all the contents (size) of each
processor (input) according to MPI_Op and
assign it to the second parameter (result).
All processors have the combined value
GPU and CPU parallel molecular simulation with CUDA and MPI Chapter | 12 547ALGORITHM 12.2 General procedure for implementing MPI.
Part 1. Place MPI_Init() before MPI calls and MPI_Finalize() 
after MPI is finished.
Part 2. Identify computationally intensive code that would benefit
from parallel execution (nameOfParallelFunction()).
Part 3. Devise a way to distribute the nameOfParallelFunction()
calculation among the processors, e.g.,
Part 3.1 MPI_Comm_size (MPI_COMM_WORLD, &totalNodes) 
MPI_Comm_rank (MPI_COMM_WORLD, &myNode) 
step totalNodes
start myNode
Part 3.2 loop i start... N
.
.
i i + step 
end i loop
Part 3.3 MPI_Allreduce()
12.5 Case study: MPI implementation of MD code
(/mdMPI_Ver2.0)
The aim of this case study is to use MPI to enable execution of the serial
MD code (/md_Ver2.0) on multiple CPUs or cores (/mdMPI_Ver2.0). A
summary of the required changes to the serial MD files is given in
Table 12.5.
TABLE 12.5 Summary of changes required for implementing MPI for MD.
Existing MD file Description of changes
atomMD.h New public variables added to the atomMD class
md.cpp New code to initialize additional variables in the atomMD class
gearMD.cpp Minor code changes to reflect the use of the variables added to atomMD
mainMD.cpp Include the mpi.h library and add calls to MPI_Init () and
MPI_Finalize()
ljForceMD.cpp Include the mpi.h library, distribute the force calculation among
the CPUs or cores, and add calls to MPI_Comm_size(),
MPI_Comm_rank(), and MPI_Allreduce()
548 Molecular Simulation of FluidsIt is apparent from Table 12.5 that relatively few changes are required to
implement MPI on the existing serial code.
12.5.1 Key variable additions
In the atom class (atomMD.h), the following public variables have been
added:
double *r; // position vector
double *f; // force array
In common with the CUDA implementation, the need for these additional
values is entirely for pragmatic reason to avoid multiple arrays for the x, y,
and z components. Unlike the CUDA code, additional variables to handle the
LJ potential mixture parameters are not required.
The atom[0] array becomes the master array for handling the position
vectors (r) and forces (f). The vectors are initialized in md.cpp via the fol￾lowing code, whereas the initialization of the forces occurs later in
setForce().
// Initialize ‘master’ root node position array
atom = ensemble->getAtoms();
for(i = 0; i < num; i++)
{
position = atom[i]->getPosition();
k = 3*i;
atom[0]->r[k] = position[0];
atom[0]->r[k + 1] = position[1];
atom[0]->r[k + 2] = position[2];
}
12.5.2 Changes to mainMD.cpp
The new mainMD() function is given in full in Listing 12.7. The changes to
main() are the additions of the MPI_Init() and MPI_Finalize() functions
(Algorithm 12.2, Part 1) and the inclusion of the mpi.h library. MPI_Init() must
be called only once, and this must occur before any other MPI functions are
called. Although it uses pointers (argc and argv) from the main function, it can
be called elsewhere in the program. The MPI_Finalize() function is commonly
included at the end of main(), but it could be included anywhere after the
MPI functions are no longer used.
GPU and CPU parallel molecular simulation with CUDA and MPI Chapter | 12 549LISTING 12.7 Code details of main.cpp.
#include "simMD.h"
#include <mpi.h>
int main(int argc, char **argv)
{
// Initialise MPI
MPI_Init(&argc,&argv);
Simulation sim;
sim.readSimParameters();
/ / End MPI
MPI_Finalize();
return 0;
}
12.5.3 Changes to ljForceMD.cpp
The implementation of MPI to the setForce() method (Algorithm 12.2, Part
2) in ljForceMD.cpp is detailed in Listing 12.8. At the start of the method,
some new additional variables (potECalR, virialCalR and f) are defined,
which will be required later for the reduction part of the method. The MPI
implementation (Algorithm 12.2, Part 3) also requires the definition of
myNode, totalNodes, lastNode, start, end, and step. The variable myNode identi￾fies the rank (or index) of the CPU or core. The initial setup involves
using the MPI_Comm_size() and MPI_Comm_rank() functions (Algorithm
12.2, Part 3.1) to determine totalNodes and myNode, respectively
LISTING 12.8 Key code details of the setForce() method in ljForceMD.cpp.
// Receiving variables for MPI_Allreduce()
double potECalR, virialCalR; 
double *f = new double [3*num]; 
// Zero the force arrays.
for(i = 0; i < num; i++)
{
k = 3*i;
f[k] = f[k + 1] = f[k + 2] = 0;
}
// Additional variables for MPI
int myNode, totalNodes;
int start, end, step;
// Set-up MPI 
MPI_Comm_size (MPI_COMM_WORLD, &totalNodes);
MPI_Comm_rank (MPI_COMM_WORLD, &myNode);
550 Molecular Simulation of Fluidsstep = totalNodes;
start = myNode;
end = num;
// Calculate forces experienced by atoms due
// interatomic pair interactions.
for(i = start; i < end; i += step)
{
k = 3*i;
// Select molecule i
kindi = atoms[i]->getType();
rXi = atoms[0]->r[k];
rYi = atoms[0]->r[k + 1];
rZi = atoms[0]->r[k + 2];
fXi = f[k];
fYi = f[k + 1];
fZi = f[k + 2];
for(j = 0; j < num; j++)
{
if(j != i) // Exclude self interaction
{
kindj = atoms[j]->getType();
l = 3*j;
rXj = atoms[0]->r[l];
rYj = atoms[0]->r[l + 1];
rZj = atoms[0]->r[l + 2];
// Calculate pair separation
rXij = rXi - rXj;
rYij = rYi - rYj;
rZij = rZi - rZj;
// Apply periodic boundary coinditions
rXij -= length * nearestInt(rXij, length);
rYij -= length * nearestInt(rYij, length);
rZij -= length * nearestInt(rZij, length);
rijSq = rXij * rXij + rYij * rYij + rZij * rZij;
// Calculate forces for separationsbelow the cutoff
rCutSq = rCut[kindi][kindj] * rCut[kindi][kindj];
if (rijSq <= rCutSq)
{
// Determine potential between i and j
sigmaSq = sigma[kindi][kindj] * sigma[kindi][kindj];
sigma2 = sigmaSq/rijSq;
sigma6 = sigma2 * sigma2 * sigma2;
sigma12 = sigma6 * sigma6;
pot = sigma12 - sigma6;
potECal += 4*epsilon[kindi][kindj] *pot;
virialCal += 24*epsilon[kindi][kindj] *(pot + sigma12)/3;
GPU and CPU parallel molecular simulation with CUDA and MPI Chapter | 12 551// Calculate forces between atoms
fij = 24*epsilon[kindi][kindj] * (pot + sigma12)/rijSq;
fXij = fij * rXij;
fYij = fij * rYij;
fZij = fij * rZij;
fXi += fXij;
fYi += fYij;
fZi += fZij;
} // end rijSq if
} // end j != i if 
} // end j for loop 
f[k] = fXi;
f[k + 1] = fYi;
f[k + 2] = fZi;
} // end i for loop 
// MPI Reductions 
MPI_Allreduce(&potECal, &potECalR, 1, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);
MPI_Allreduce(&virialCal, &virialCalR, 1, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);
MPI_Allreduce(f, atoms[0]->f, 3*num, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);
delete [] f;
*potEnergy = potECalR/2;
*virial = virialCalR/2;
The outer i force loop of the serial code starts with the 0 index and incre￾ments this to the number of atoms (num) in increments of 1. The simplest way
to distribute the force calculation (Algorithm 12.2, Part 3.2) is to increase the
increment used (step) to be equal to the total number of CPUs or cores
(totalNodes). This is similar to the way the force calculation was handled with
GPUs, and more elaborate MPI force decompositions are also possible (Li
et al., 2006, 2008). The starting point (start) for the loop corresponds to the
rank (myNode) and continues until end, which is the number of atoms (num). If
only one CPU is available, the range of the for loop is between 0 and num in
increments of 1, which is the case of a conventional serial execution.
An alternative to the above implementation is to distribute the atoms between
the processors. This is done using the following code prior to the for loop.
int lastNode = totalNodes - 1; // Node count starts at 0
int numCal = num/totalNodes; // Distribute calculation evenly between nodes
start = myNode*numCal; // Different starting point for each node
if (myNode == lastNode) // Different end point for each node
end = num;
else
end = (myNode + 1)* numCal;
step = 1;
552 Molecular Simulation of FluidsIn this case, the increment of the for loop is 1. The number of calculations
(numCal) is divided equally between the processors, and both the start and end
points of the for loop depend on the rank of the processor. This approach
requires some additional bookkeeping via the if-else statement, but the differ￾ence in computational efficiency between the two approaches is negligible.
The inner j for loop increments over all the atoms. This means that the
calculations are not confined to indistinguishable i-j combinations, that is,
both i-j and j-i contributions are countered. Consequently, Newton’s third law
shortcut is not implemented and the properties evaluated in the force evalua￾tions are halved. This is done to avoid inaccuracies because of the racing
condition as discussed previously for the GPU implementation. A specialized
algorithm is required to implement Newton’s third law in MPI and is
detailed elsewhere (Pacheco, 2011).
At the end of the force evaluations (Algorithm 12.2, Part 3.3), the par￾tially evaluated properties are combined using the All_Reduce() MPI function.
In contrast, the CUDA implementation required a user-defined function
(Listing 12.1) to perform the reduction operation.
12.5.4 Changes to the MD integrator
In common with the CUDA case, the integrator code (gearPC.cpp) is also a
candidate for MPI execution because of the loop over all atoms. However,
the computational benefit (if any) is likely to be relatively small compared to
using MPI for the force evaluations. Therefore the modifications to gearPC.
cpp have been restricted to the changes required to accommodate the use of
the new variables introduced in the atom class.
12.6 Case study: MPI implementation of MC code
(/mcMPI_Ver2.0)
This case study uses MPI to enable execution of the serial MC code
(/mc_Ver2.0) on multiple CPUs or cores (/mcMPI_Ver2.0). The required changes
to the serial MC files are summarized in Table 12.6. It is apparent from
Table 12.6 that the changes are confined to only two files and that unlike the
other case studies, the changes can be accomplished without any changes to
the membership of any classes.
12.6.1 Changes to mainMC.cpp
The changes required to main.cpp exactly mirror Listing 12.7. Namely, the
addition of calls (Algorithm 12.2, Part 1) to both MPI_Init() and MPI_Finalize(),
and the inclusion of the mpi.h library.
GPU and CPU parallel molecular simulation with CUDA and MPI Chapter | 12 55312.6.2 Changes to ljEnergyMC.cpp
The changes to the ljEnergyMC.cpp file involve changes to the setEnergy() and
getTrialPotE() methods (Algorithm 12.2, Part 2). The former is called only
once at the start of the simulation to determine the initial energy, whereas
the latter is called repeatedly when individual attempted particle displace￾ments are involved. MPI have been implemented for both methods. As the
required MPI changes are similar, we will focus on getTrialPotE(). It should be
noted that, as the setEnergy() method involves a double loop, it must be
implemented for all pairs, including indistinguishable pairs. The calculated
properties are then halved at the end of the energy evaluation. This is neces￾sary to avoid inaccuracies due to the racing condition as described previously
in the other case studies.
A partial listing of getTrialPotE() is given in Listing 12.9. In common
with MPI MD case study, additional variables required for the MPI imple￾mentation are defined and the MPI setup commences (Algorithm 12.2, Part
3.1) by determining the total number of processors (totalNodes) available
and the rank of the current processor (myNode) using the MPI_Comm_Size()
and MPI_Comm_Rank() functions. The properties of the index atom are
determined in the same way as given in the serial MC code. Thereafter, the
energy of interaction of the index atom is obtained by calculating the inter￾actions of all the other atoms.
In the MPI MD case study, the calculation was simply allocated
between the processors by using a step size that was equal to totalNodes.
This procedure could be applied in the current case, but instead we have
illustrated the alternative that was discussed, but not used, in the MPI MD
case study.
TABLE 12.6 Summary of changes required to implement MPI for MC.
Existing MC File Description of changes
mainMC.cpp Include the mpi.h library and add calls to MPI_Init() and
MPI_Finalize()
ljEnergyMC.cpp Include the mpi.h library, distribute the energy calculation for the
setEnergy() and getTrialPotE() methods among the CPUs or
cores, and add calls to MPI_Comm_size(), MPI_Comm_rank(),
and MPI_Allreduce()
554 Molecular Simulation of FluidsLISTING 12.9 Key code details of the getTrialPotE() method in ljEnergyMC.
cpp.
// Additonal variables for MPI implentation
int myNode, totalNodes, lastNode;
int start, end, numCal;
double potECalR, virialCalR; //Receiving variables for MPI_Allreduce
// Set-up MPI
MPI_Comm_size(MPI_COMM_WORLD, &totalNodes);
MPI_Comm_rank(MPI_COMM_WORLD, &myNode);
lastNode = totalNodes - 1; // Node count starts at 0
numCal = num/totalNodes; // Distribute calculation evenly between nodes
start = myNode*numCal; // Different starting point for each node
if(myNode == lastNode) // Different end point for each node
end = num;
else
end = (myNode + 1)* numCal;
// Calculate energy experienced by the selected atom (index)
// with all other distinct pairs
// Properties of index atom.
kindi = atom[index]->getType();
tempPos = atom[index]->getTrialPosition();
rXi = tempPos[0];
rYi = tempPos[1];
rZi = tempPos[2];
potE = 0.0;
// Loop over all the other atoms 
for(j = start; j < end; j++)
{
// Exclude self-interaction
if(j != index)
{
kindj = atom[j]->getType();
tempPosj = atom[j]->getPosition();
rXj = tempPosj[0];
rYj = tempPosj[1];
rZj = tempPosj[2];
// Calculate pair separation
rXij = rXi - rXj;
rYij = rYi - rYj;
rZij = rZi - rZj;
// Apply periodic boundary conditions
rXij -= length * nearestInt(rXij, length);
rYij -= length * nearestInt(rYij, length);
rZij -= length * nearestInt(rZij, length);
GPU and CPU parallel molecular simulation with CUDA and MPI Chapter | 12 555// Determine potential between i and j
sigmaSq = sigma[kindi][kindj] * sigma[kindi][kindj];
sigma2 = sigmaSq/rijSq;
sigma6 = sigma2 * sigma2 * sigma2;
sigma12 = sigma6 * sigma6;
pot = sigma12 - sigma6; 
eps = epsilon[kindi][kindj];
potE += eps * pot;
} // end rijSq if
} // end j != index if
} // end j for
// MPI reduction
MPI_Allreduce(&potE, &potECalR, 1, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);
return 4*potECalR;
rijSq = rXij * rXij + rYij * rYij + rZij * rZij;
// Calculate forces for separations below the cutoff
rCutSq = rCut[kindi][kindj] * rCut[kindi][kindj];
if (rijSq <= rCutSq)
{
At the end of the energy evaluation (Algorithm 12.2, Part 3.3), MPI_Allreduce()
is called to determine potECalR. In contrast, an additional reduction for the forces
was required in the MPI MD case study. The absence of this contribution explains
why no additional force variables were required in the atom class. The MPI imple￾mentation also does not require the additional position vector in the atom class
because the positions are updated outside the energy evaluation.
12.7 Case study: relative performance of MD and MC MPI
and GPU codes
It is of interest to determine the performance of the parallel codes compared
to the serial implementations. To achieve this, we have tested the code
against a common benchmark condition for the LJ dense supercritical fluid
(T 5 1.5, ρ 5 0.6, E 5 21.6088 using rcut 5 3.4 σ) for a large range of N.
A relatively small run length was used for the benchmark comparisons (8000
overall, with 6000 for equilibration) because of the very long execution times
of the serial code for large values of N. Much larger run lengths are used for
actual production runs (Chapter 8).
12.7.1 Performance of MD and MC GPU codes
The speed-up is defined as an execution time of the serial code divided by the
execution time of the GPU code. The speed-up obtained for the MD GPU code
556 Molecular Simulation of Fluidsis illustrated in Fig. 12.1. For N ,500, there is no advantage in using the GPU
code compared with serial execution. However, thereafter, the speed-up
increases rapidly with N, as the larger values of N take full advantage of the
simultaneous launch of multiple threads on the GPU. The MD GPU code pro￾vides outstanding performance, nearly reaching a 200-fold speed-up compared
with the serial code. This would allow simulations with much larger values of
N, making million atom simulations feasible. It should be noted that these
impressive gains were made without any attempts to optimize the efficiency of
the code, and further improvements are possible. Nonetheless, the performance
is broadly consistent with earlier results (Hou et al., 2013; Rapaport, 2022).
In contrast, the performance of the MC GPU code is very much less
impressive as illustrated in Fig. 12.2, which show the speed-up versus N. It
is apparent that the GPU MC code is only beneficial when N . 10,000, and
the speed-up quickly starts to tail-off. This is a disappointing result, particu￾larly in contrast to the enormous computational advantage of GPUs for MD.
A partial explanation for the performance difference between the MD and
MC GPU codes is that for each MC cycle, N (N 2 1) interactions are calcu￾lated by launching the x threads 2 N times, that is, N energy calculations for
an atom in its current location plus N energy calculations of the trial dis￾placed location. The equivalent of a MC cycle is the MD time step. In con￾trast, for each MD time step, the N (N 2 1) interactions are calculated by
launching the x threads only once. There is scope to improve the perfor￾mance of the MC code by taking advantage of algorithms such as a neighbor
list (Chapter 6).
FIGURE 12.1 Speed-up of GPU MD code (32 threads) compared to serial code versus N for
the LJ fluid (see text for details). The line through the points is only for guidance.
GPU and CPU parallel molecular simulation with CUDA and MPI Chapter | 12 55712.7.2 Performance of the MD MPI code
Fig. 12.3 illustrates the speed-up of MD MPI code distributed over 32 pro￾cessors. In this instance, the maximum theoretical speed-up is 16 because the
MPI code performs on average twice as many force evaluations than the
serial code because Newton’s shortcut is not implemented in the MPI code.
FIGURE 12.2 Speed-up of GPU MC code (32 threads) compared to serial code versus N for
the LJ fluid (see text for details). The line through the points is only for guidance.
FIGURE 12.3 Speed-up of MC MPI code (32 CPUs) compared to serial code versus N for the
LJ fluid (see text for details). The line through the points is only for guidance.
558 Molecular Simulation of FluidsIt is apparent from the comparison given in Fig. 12.3 that the MPI
implantation is computationally advantageous when N . 250. The speed-up
increases steadily with N before reaching a plateau value of 8 for N .
10,000. This is half of the maximum theoretical value, which indicates that
there is ample scope to attempt to optimize the code further. However, any
gains in efficiency would be dwarfed by much greater speed of the GPU
code illustrated in Fig. 12.1.
12.8 Summary
The serial MC and MD codes developed in Chapter 11 can be easily trans￾formed to execute in parallel using either MPI of GPUs. This transformation
was achieved by using only a small subset of the available MPI or CUDA func￾tions. When using parallel computation, care must be taken to avoid the racing
condition, which is the source of potential inaccuracies. Compared with serial
calculations, indicated GPU execution provides a much greater speed-up than is
possible with MPI. In contrast, MC simulations do not share the enormous bene￾fits of MD code executed using GPUs. However, these observations come with
some important caveats, such as no attempt was made to optimize the codes;
the LJ potential is a simple potential that does not include electrostatic interac￾tions; and the calculations were confined to pairwise interactions.
References
Abraham, M.J., Murtolad, T., Schulz, R., Szilard, P., Smith, J.C., Hess, B., Lindahl, E., 2015. ´
GROMACS: high performance molecular simulations through multi-level parallelism from
laptops to supercomputers. SoftwareX 12, 1925.
Ansorge, R., 2022. Programming in Parallel with CUDA: A Practical Guide. Cambridge
University Press, Cambridge.
Barlas, G., 2015. Multicore and GPU Programming: An Integrated Approach. Morgan
Kaufmann, Amsterdam.
Chandra, R., Dagum, L., Kohr, D., Maydan, D., McDonald, J., Menon, R., 2001. Parallel
Programming in OpenMP. Morgan Kaufmann, San Francisco.
Couturier, R. (Ed.), 2014. Designing Scientific Applications on GPUs. CRC Press, Boca Raton.
Farber, R., 2011. CUDA: Application Design and Development. Morgan Kaufmann, Amsterdam.
Fincham, D., 1987. Parallel computers and molecular simulation. Mol. Sim. 1, 145.
Gaster, B.R., Howes, L., Kaeli, D.R., Mistry, P., Schaa, D., 2012. Heterogeneous Computing
with OpenCL. Morgan Kaufmann, Amsterdam.
Heermann, D.W., Burkitt, A.N., 1991. Parallel Algorithms in Computational Science. Springer,
Berlin.
Heinecke, A., Eckhardt, W., Horsch, M., Bungartz, H.-J., 2015. Supercomputing for Molecular
Dynamics Simulations: Handling Multi-Trillion Particles in Nanofluidics. Springer,
Heidelberg.
Hou, Q., Li, M., Zhou, Y., Cui, J., Cui, Z., Wang, J., 2013. Molecular dynamics simulations
with many-body potentials on multiple GPUs—the implementation, package and perfor￾mance. Comput. Phys. Commun. 184, 20912101.
GPU and CPU parallel molecular simulation with CUDA and MPI Chapter | 12 559Hwu, W.-M., 2011. GPU Computing Gems: Emerald Edition. Morgan Kaufmann, Burlington.
Karniadakis, G.E., Kirby II, R.M., 2003. Parallel Scientific Computing in C 1 1 and MPI: A
Seamless Approach to Parallel Algorithms and their Implementation. Cambridge University
Press, Cambridge.
Kirk, D.B., Hwu, W.-M.W., 2010. Programming Massively Parallel Processor: A Hands-on
Approach. Morgan Kaufmann, Amsterdam.
Kohnke, B., Kutzner, C., Grubmu¨ller, J., 2020. A GPU-accelerated fast multiple method for
GROMAS: performance and accuracy. J. Chem. Theor. Comput. 16, 69386949.
Li, J., Zhou, Z., Sadus, R.J., 2006. Modified force decomposition algorithms for calculating
three-body interaction via molecular Dynamics. Comput. Phys. Commun. 175, 384392.
Li, J., Zhou, Z., Sadus, R.J., 2008. Parallel algorithms for molecular dynamics with induction
forces. Comput. Phys. Commun. 178, 384392.
Mattson, T.G., Sanders, B.A., Massingill, B.L., 2005. Patterns for Parallel Programming.
Addison-Wesley, Boston.
Mattson, T.G., He, Y., Koniges, A.E., 2019. The OpenMP Common Core: Making OpenMP
Simple Again. MIT Press, Cambridge.
Munshi, A., Gaster, B.R., Mattson, T.G., Fung, J., Ginsburg, D., 2012. OpenCL Programming
Guide. Addison-Wesley, Upper Saddle River.
Owens, J.D., Houston, M., Luebke, D., Green, S., Stone, J.E., Phillips, J.C., 2008. GPU comput￾ing. Proc. IEEE 96, 879899.
Pacheco, P.S., 1997. Parallel Programming with MPI. Morgan Kaufmann, San Francisco.
Pacheco, P.S., 2011. An Introduction to Parallel Programming. Morgan Kaufmann, Amsterdam.
Phillips, J.C., Hardy, D.J., Maia, J.D.C., Stone, J.E., Ribeiro, J.V., Bernardi, R.C., Buch, R.,
Fiorn, G., He´nin, J., Jiang, W., McGreevy, R., Melo, M.C., Radak, B.K., Skeel, R.D.,
Singharoy, A., Wang, Y., Roux, B., Aksimentiev, A., Luthey-Schulten, Z., Kale´, Schultern,
K., Chipot, C., Tajkhorshid, E., 2020. Scalable molecular dynamics on CPU and GPU archi￾tectures with NAMD. J. Chem. Phys. 153, 044130.
Ploskas, N., Samaras, M., 2016. GPU Programming in MATLAB. Morgan Kaufmann,
Amsterdam.
Quinn, M.J., 2004. Parallel Programming in C with MPI and OpenMP. McGraw-Hill, Boston.
Rapaport, D.C., 2022. GPU molecular dynamics: algorithms and performance. J. Phys. Conf.
Ser. 2241, 012007.
Sanders, J., Kandrot, E., 2011. CUDA by Example: An Introduction to General-Purpose GPU
Programming. Addison-Wesley, Upper Saddle River.
Scarpino, M., 2012. OpenCL in Action: How to Accelerate Graphics and Computation.
Manning, Shelter Island.
Storti, D., Yurtoglu, M., 2016. CUDA for Engineers: An Introduction to High-Performance
Parallel Computing. Addison-Wesley, New York.
560 Molecular Simulation of FluidsAppendix 1
Software user’s guide
The following is a brief description of the how to use the software that was
detailed in Chapters 11 and 12. The software can be downloaded from the book’s
(https://www.elsevier.com/books-and-journals/book-companion/9780323853989),
where any future updates will also be posted as required. The code can be either
used or modified for any noncommercial research application. It should be noted
that the programs were developed specifically for this book to illustrate the appli￾cation of object-orientation to molecular simulation. We believe that they are free
from significant error. In particular, the serial and parallel codes yield exactly the
same results. However, the codes have not had the benefit of extensive testing
and their application to mixtures has not been investigated. Therefore the onus is
on the user to verify the correctness of the code if it is used in a research
application.
A.1 C11 code for the molecular dynamics simulation of
Lennard-Jones Atoms in the Microcanonical
Ensemble (\md_Ver2.0)
The molecular dynamics code is located in the “md_Ver2.0” directory. The
names of both the source files (.cpp) and header files (.h) follow closely
the names of the class that they represent. Files relevant to molecular dynam￾ics are identified by the “MD” suffix. The source files are: atomMD.cpp,
auxfuncMD.cpp, ensembleMD.cpp, forceMD.cpp, gpcMD.cpp, integrtMD.cpp, ljatomMD.
cpp, ljforceMD.cpp, mainMD.cpp. md.cpp, nveMD.cpp and simMD.cpp. The header files
are atomMD.h, auxfuncMD.h, ensembleMD.h, forceMD.h, gpcMD.h, integrtMD.h,
ljatomMD.h, ljforceMD.h, md.h, nveMD.h and simMD.h. Notice that each source file
(expect mainMD.cpp) has a corresponding header file. Both the source and
header files must be compiled together.
In addition to the source files and header files, there are four data files:
md.dat, NVEfileMD.dat, paramLJ.dat and sim.dat. The structure and meaning of
the data files are explained in Table A.1. All input data are in reduced units
relative to the intermolecular potential parameters.
561The data in Table A.1 are for a simulation of a one-component system.
However, the program can be executed for a multicomponent mixture with￾out any modification of the source code. To use the program for a multicom￾ponent mixture, changes are required only in the NVEfileMD.dat and paramLJ.
dat files. In NVEfileMD.dat, the number of components is specified and
the mole fractions and masses of each component must be given. In the
paramLJ.dat file, an additional line of data is required for each component. By
default, the program will calculate the properties of a three-dimensional
fluid, however, calculations for the two-dimensional case can be achieved by
simple modification of the source code. The Gear 5-value method is the
default integrator. If another Gear integrator is desired, this can be achieved
by simply specifying the value in NVEfileMD.dat and changing the constants in
the gearCorrect() method.
The output is written to nve_md.out. This file simply contains the average
energies and temperature of the ensemble in reduced units. The source code
can be modified easily to collect statistics for other thermodynamic proper￾ties of the ensemble such as heat capacity, pressure, etc.
TABLE A.1 organization of data files for molecular dynamics simulation.
Name of file Contents Meaning
sim.dat 1 Simulation choice
md.dat 8000 Total Number of time steps
6000 Number of equilibration time steps
10 Size of blocks to average
0.002 Time step
1 Integrator method (1 5 Gear)
5 Number of Gear values
1 Ensemble ( 1 5 NVE ensemble)
1 Potential (1 5 Lennard-Jones)
NVEfileMD.dat 1 Number of components
256 Number of atoms
1.0 Mole fraction for each type of atom
1.0 Mass of each type of atom
1.5 Temperature
0.6 Density
paramLJ.dat 1.0 1.0 3.4 Epsilon, sigma and rcut
562 Software user’s guideA.2 C11 code for the Monte Carlo simulation of
Lennard-Jones
Atoms in the Microcanonical Ensemble (\mc_Ver2.0)
The Monte Carlo code is located in the “mc_Ver2.0” directory. The names
of both the source files (.cpp) and header files (.h) follow closely the names
of the class that they represent. Files relevant to Monte Carlo simulation are
identified by the “MC” suffix. The source files are: atomMC.cpp, auxfuncMC.
cpp, energyMC.cpp, ensembleMC.cpp, ljatomMC.cpp, ljenergyMC.cpp, mainMC.cpp.
mc.cpp nveMC.cpp and simMC.cpp. The header files are atomMC.h, auxfuncMC.h,
energyMC.h, ensembleMC.h, ljatomMC.h, ljenergyMC.h, mc.h, nveMC.h and simMC.
h. Notice that each source file (except mainMC.cpp) has a corresponding
header file. Both the source and header files must be compiled together.
In addition to the source files and header files, there are four data files:
mc.dat, NVEfileMC.dat, paramLJ.dat and sim.dat. The structure and meaning of
the data files are explained in Table A.2. All input data are in reduced units
relative to the intermolecular potential parameters.
The data in Table A.2 are for a simulation of a one-component system.
However, the program can be executed for a multicomponent mixture without
any modification of the source code. To use the program for a multicomponent
mixture, changes are required only in the NVEfileMC.dat and paramLJ.dat files. In
TABLE A.2 Organization of data files for Monte Carlo simulation.
Name of file Contents Meaning
sim.dat 2 Simulation choice
mc.dat 8000 Total number of cycles
2000 Number of equilibration cycles
10 Size of blocks to average
1 Ensemble ( 1 5 NVE ensemble)
1 Potential (1 5 Lennard-Jones)
NVEfileMC.dat 1 Number of components
256 Number of atoms
1.0 Mole fraction for each type of atom
1.0 Mass of each type of atom
-1.6088 Total energy of the ensemble
0.6 Density of the ensemble
paramLJ.dat 1.0 1.0 3.4 Epsilon, sigma and rcut
Software user’s guide 563NVEfileMC.dat, the number of components is specified and the mole fractions and
masses of each component must be given. In the paramLJ.dat file, an additional
line of data is required for each component. By default, the program will calculate
the properties of a three-dimensional fluid, however, calculations for the two￾dimensional case can be achieved by simple modification of the source code.
The output is written to nve_mc.out. This file simply contains the average
energies and temperature of the ensemble in reduced units. The source code
can be modified easily to collect statistics for other thermodynamic proper￾ties of the ensemble such as heat capacity, pressure, etc.
A.3 C11 code for the combined Monte Carlo and molecular
Dynamics Simulation Program for Lennard-Jones Atoms in the
Microcanonical Ensemble (\mcmd_Ver2.0)
The “mcmd_Ver2.0” directory contains the source and header files for both
the Monte Carlo and molecular dynamics programs outlined above. The only
difference is that that simMD.cpp and simMD.h, or simMC.cpp and simMC.h files
are replaced by the files simMCMD.cpp and simMCMD.h, respectively. The data
files used are identical to those required for the molecular dynamics and
Monte Carlo programs, with the exception that there is a single simMCMD.dat
file that replaces either simMC.dat or simMD.dat. This is a name change only
and the organisation of the file is unaltered.
A.4 CUDA code for the molecular dynamics simulation of
Lennard-Jones Atoms in the Microcanonical
Ensemble (\mdCU_Ver2.0)
The MD files for the CUDA implementation are located in the “mdCU_Ver2.0”
directory. Details of the .cpp files and associated.h files are mostly identical
to the descriptions given in A.1. The exceptions are the presence of the
cudaSimKernels,cu, ljForce.cu, cudaSimKernels.h files. In the cudaSimKernels.h, the
constant numThreadInBock is used to specify the number of threads used. The
organization of the data files is identical to that given in Table A.1.
A.5 CUDA code for the Monte Carlo simulation of
Lennard-Jones Atoms in the Microcanonical
Ensemble (\mdCU_Ver2.0)
The MC files for CUDA are located in the “mcCU_Ver2.0” directory and
are mostly identical to the files used in A.2. The organization of the data
files is identical to that given in Table A.2. The additional CUDA files are:
cudaSimKernels,cu, ljenergyMC.cu, cudaSimKernels.h files. In the cudaSimKernels.h,
the constant numThreadInBock is used to specify the number of threads used.
564 Software user’s guideA.6 MPI code for the molecular dynamics simulation of
Lennard-Jones Atoms in the Microcanonical
Ensemble (\mdMPI_Ver2.0)
The MPI MD files are located in the directory “mdMPI_Ver2.0.” The file
structure and the use of the input files are identical to those given in A.1.
A.7 MPI code for the molecular dynamics simulation of
Lennard-Jones Atoms in the Microcanonical
Ensemble (\mcMPI_Ver2.0)
The MPI MC files are located in the directory “mcMPI_Ver2.0.” The file
structure and the use of the input files are identical to those given in A.2.
A.8 Compilation
A.8.1 Serial compilation
To generate executable code, all the source files and header files in the
respective directories must be compiled together. For example, on a UNIX
system, programs for a Monte Carlo (mcprogram.exe), molecular dynamics
(mdprogram.exe) and combined (mcmdprogram.exe) simulation can be obtained
using the g11 compiler as follows:
g11 -o mcprogram.exe mc.cpp MC.cpp
g11 -o mdprogram.exe md.cpp MD.cpp
g11 -o mcmdprogram.exe .cpp
Note that, the corresponding header files must be present in the same
directory. It is good practice to keep the Monte Carlo and molecular dynam￾ics code in separate directories. However, if they become mixed, the com￾mon files can be easily identified by the “MC” and “MD” suffixes.
A.8.2 MPI compilation
The compilation of the MPI files using the g11 compiler requires the addi￾tion of the -lmpi compiler option, that is,
g11 -o mcprogram.exe mc.cpp MC.cpp -lmpi
g11 -o mdprogram.exe md.cpp MD.cpp -lmpi
The code, can be executed on, for example, 4 processes by using the
command
mipirun np 4./mdprogram.exe
Software user’s guide 565A.8.2.1 CUDA compilation
The .cpp and .cu files are compiled together using the CUDA (nvcc) com￾piler. Examples of simple valid compilation statements are:
nvcc --fmad5false -o mcprogram.exe mc.cpp MC.cpp .cu
nvcc --fmad5false -o mdprogram.exe md.cpp MD.cpp .cu
For the CUDA compilation it is highly advisable to disable the use of
FMAD, which is the default option for the nvcc compiler. This is discussed
in Chapter 12.
566 Software user’s guideAppendix 2
List of algorithms
Algorithms described in the text using pseudo code are summarized below.
Some additional algorithms are also discussed in the text without using
pseudo code.
No. Algorithm description Page
General algorithms
5.1 Calculation of either intermolecular forces or energy 167
5.2 Calculation of either intermolecular forces or energy using periodic
boundary conditions
169
5.3 Creation of a Verlet neighbor list 171
5.4 Calculation of energies/forces using a neighbor list 172
5.5 Use of an automatically updated neighbor list 173
5.6 Three-dimensional map of cells and nearest neighbors 175
5.7 Creation of a linked-cell list 176
5.9 Creation of look-up tables 178
5.10 Calculation of energies using a neighbor list and a look-up table 179
5.12 Calculation of the real space contribution in the Ewald sum 186
5.15 Assignment of charges to the particle mesh in one-dimension 193
5.16 Solution of the field equation in one-dimension using the Thomas
tridiagonal algorithm
194
Monte Carlo
1.1 General outline of a Monte Carlo process 5
5.13 Calculation of the reciprocal space contribution in the Ewald sum 188
6.1 Basic Monte Carlo procedure for accepting changes in atomic
displacements
218
6.2 Configurational bias algorithm for a chain 227
6.3 Growing/retracing either a fully flexible or semi-flexible chain 228
6.4 Monte Carlo procedure for accepting cluster moves 232
9.1 Monte Carlo simulation in the canonical (NVT) ensemble 313
9.2 Monte Carlo simulation in the NpT ensemble 317
9.3 Monte Carlo simulation in the μVT ensemble 321
9.4 Monte Carlo simulation in the NVE ensemble 325
10.1 Monte Carlo Gibbs ensemble 365
(Continued)
567(Continued)
No. Algorithm description Page
10.3 Monte Carlo implementation of Gibbs-Duhem integration for a one￾component fluid at several different temperatures
377
10.6 ECM algorithm for SLE 393
Molecular dynamics
1.2 General outline of a molecular dynamics process 6
5.8 Force calculation using a linked-cell list 177
5.14 Calculation of intermolecular forces for a single time step using the PPPM
method
192
5.17 Force interpolation in one-dimension of the particle mesh 195
7.1 General predictor-corrector procedure for solving equations of motion 247
7.2 Example of the implementation of Gear’s four-value (3rd order) predictor￾corrector algorithm using scaled time derivatives
248
7.3 Original Verlet method for integrating equations of motion 252
7.4 Leap frog Verlet method for integrating equations of motion 253
7.5 Velocity-Verlet method for integrating equations of motion 255
7.6 Beeman-Verlet method for integrating equations of motion 257
7.7 RK4 integration of the equations of motion 259
7.8 Shake method for incorporating bond-length constraints 268
7.9 Rattle method for incorporating bond-lengthconstraints 274
8.4 A four-value Gear predictor applied independently to both positions and
velocities using scaled time derivatives
294
9.5 General molecular dynamics NVE ensemble strategy 328
9.6 Molecular dynamics in the NVE ensemble using periodic scaling of
velocities
329
9.7 Molecular dynamics in the NVT ensemble using simple velocity
scaling
331
9.8 Molecular dynamics in the NVT ensemble using the Andersen thermostat 334
9.9 Molecular dynamics in the NVT ensemble using the Nose´-Hoover
equations of motion and a predictor-corrector strategy
337
9.10 Molecular dynamics in the NpH ensemble using Andersen’s method 341
9.11 Molecular dynamics in the NpT ensemble using Andersen’s method 343
9.12 Molecular dynamics in the NpT ensemble using the Nose´-Hoover
equations of motion and a predictor-corrector strategy
345
9.13 Molecular dynamics in a μVT ensemble using the Lo-Palmer algorithm 350
9.14 Parallel grand canonical molecular dynamics (PGCMD) algorithm 352
10.2 Gibbs ensemble molecular dynamics using the Lo-Palmer algorithm 369
Nonequilibrium molecular dynamics
8.1 General outline of a NEMD process at constant strain rate (γ_) using the
Gear predictor-corrector integrator
288
8.2 Evaluation of the tensor components to pressure 291
8.3 Calculation of the α thermostatic constant 293
8.5 A four-value Gear corrector applied independently to both positions and
velocities implementing sllod under constant strain rate, using scaled time
derivatives
295
(Continued)
568 List of algorithms(Continued)
No. Algorithm description Page
Combined algorithms
10.4 Synthetic algorithm for fluid phase equlibria 389
10.5 Combined EMD/NEMD algorithm for SLE 391
Parallel algorithms
12.1 General procedure for GPU implementation via a kernel 533
12.2 General procedure for implementing MPI 548
List of algorithms 569This page intentionally left blankAppendix 3
Notation
In each chapter, all symbols and abbreviations are defined in the text when
they are encountered for the first time. The most commonly used notation is
summarized below; vectors are distinguished from scalar quantities by the
use of bold typeface. Extensive use has been made of pseudo code to
describe algorithms and we have endeavored to make the pseudo code non￾language specific. The major pseudo code conventions are summarized; We
have also made some use of UML notation that is also explained here.
Acronyms and abbreviations
μVT grand canonical ensemble
a.u. atomic units
AMBER assisted model building with energy refinement
AMOEBA atomic optimized multipole optimized energetics for biomolecular application
ATM Axilrod-Teller-Mut ¯o
BFW Barker-Fisher-Watts
CBMC configurational bias Monte Carlo
CCSD(T) coupled cluster single and double excitations
CFC continuous fractional component
CHARMM chemistry at Harvard macromolecular mechanics
CPMD Car-Parrinello molecular dynamics
CPU central processing unit
CPWC chemical potential weak coupling
CUDA compute unified device architecture
DCMG double Gaussian core model
DFT density functional theory
ECEPP empirical conformational energy program for peptides
EMD equilibrium molecular dynamics
ECM entropy correlation method
erfc complementary error function
exp-6 exponential-6
FENE finitely extensible nonlinear elastic
FMAD floating-point multiply-add
571FMM fast multipole method
FSS finite size scaling
GCM Gaussian core model
GDI Gibbs-Duhem integration
GEMC Gibbs ensemble Monte Carlo
GPU graphics processing unit
HF Hartree-Fock
HFD Hartree-Fock dispersion
HS hard sphere
HSA hard sphere plus attractive
LD Leonhard-Deiters
LJ Lennard-Jones
LJ/M Lennard-Jones/Mie
LR long-range
LRC long-range correction
MBF mean Boltzmann factor
MC Monte Carlo
MCY Matsuoka-Clement-Yoshimine
MCYna MCY nonadditive
MD molecular dynamics
MM molecular mechanics
MSS multistage sampling
MWS Marcelli-Wang-Sadus
NCC Niesar-Corongiu-Clementi
NEMD nonequilibrium molecular dynamics
NpH isobaric constant-enthalpy ensemble
NpT isobaric isothermal ensemble
NVE microcanonical ensemble
NVEPG microcanonical ensemble, with constant P and G
OMT object modeling technique
OO object-orientation
OOA object-oriented analysis
OOD object-oriented design
OOP object-oriented programming
OPLS optimized potential for liquid simulation
PC predictor-corrector; personal computer
PGCMD parallel grand canonical molecular dynamics
rattle method for handling bond constraints (Algorithm 7.9)
PPPM particle-particle and particle-mesh
RMSD root mean squared deviation
RK Runge-Kutta
RPM restricted primitive model
SAAP simplified ab initio atomic potential
SCF self consistent field
shake method for handling bond constraints (Algorithm 7.8)
sllod method for handling equations of motion in NEMD
SLE solid-liquid equilibria
SPC simple point charge
572 NotationSPC/E SPC/extended
SR short-range
SS soft sphere
TIPxP transferable intermolecular potential x point
UFF universal force field
UML unified modeling language
VLE vapor-liquid equilibria
WCA Weeks-Chandler-Anderson
Latin alphabet
a acceleration vector
A Helmholtz function; dynamic property; empirical constant
B empirical constant in intermolecular potentials
b empirical constant in intermolecular potentials
C heat capacity; dispersion coefficient; potential constant
d diameter of an impenetrable hard core; dimensions
D diffusion coefficient; damping parameters; bond dissociation energy; dipole
E total energy (Hamiltonian)
F force vector
F total number of degrees of freedom
f force; damping function; degrees of freedom
G Gibbs function; general variable
G quantity for the initial position of the center of mass
H Hamiltonian; enthalpy; hexadecapole
h Planck’s constant
k Boltzmann’s constant
K kinetic energy; force constant
k reciprocal vector in Ewald sum
l bond separation
L Lagrangian; box length
m mass
N number of particles
O octupole
P linear momentum; pressure tensor
Pi probability of observing the ith state
p probability; instantaneous pressure
q charge; position
Q generalized force; quadrupole
R maximum level of refinement
r position vector
r separation; refinement
S entropy
t instantaneous temperature
T temperature
U potential energy (internal energy)
V volume; potential function; rotational barrier
v velocity vector
Notation 573w instantaneous virial
W internal virial
X general property
z adjustable parameter
Z partition function
Greek alphabet
α thermal expansion coefficient; constant of motion; repulsive steepness parameter;
molecule identifier; atom constant; polarizability; adjustable parameter
β inverse temperature (1/kT); isothermal compressibility molecular identifier
δ instantaneous change; Dirac’s delta
Γ oscillator coefficient; gamma function
γ ratio of polarizabilities; atomic interaction constant; thermal pressure
coefficient; general parameter
ε intermolecular potential energy parameter; relative permittivity
η viscosity
θ bond angle
λ thermal conductivity coefficient; multiple of hard sphere diameter;
Lagrange multiplier
μ chemical potential; dipole moment
ρ density; distribution function; source distribution
σ intermolecular potential distance parameter; root mean square deviation
τ dihedral angle
ν three-body non-additive coefficient
ϕ electrostatic potential
χ out-of-plane bond angle
ψ wave function; grand canonical partition function
Ω phase-space volume
ω phase-space density
Subscripts and superscripts
0 reference property
a applied
a,b,i,j molecule identifiers
ave average
b bond
c constraint; correction
corr correction
disp dispersion
e external
ens ensemble
m minimum position
pot potential
r residual
rep repulsive
r residual property
test test property
574 NotationPseudo code conventions
Code Explanation
if (logical test)
statement 1
else(optional test)
statement 2
end if
If some logical test is satisfied, statement 1 is executed
otherwise, another (optional) test is performed. If the second test
is satisfied, statement 2 is executed.
’ The arrow signifies assignment, e.g., a ’ 5 means a is assigned
the value of 5.
5 The equals sign is used to signify equivalence in logical tests
(compare with assignment above).
// Start of a comment.
loop i ’ 1... N
statement 1
end loop
Execute statement 1 N times, that is, until i is equal to N. The
value of i is incremented by 1 each time through the loop. In
nested loops, the end of a particular loop is specified by
incorporating the loop index into the end loop statement.
loop
statement 1
while (logical test)
The code represented by statement 1 is executed until a
termination condition is reached. The termination condition is
determined at the end of the loop.
loop while (logical test)
statement 1
end loop
The code represented by statement 1 is executed until a
termination condition is reached. The termination condition is
determined at the start of the loop.
erfc(x) The complementary error function of x.
exp(x) The exponential of x.
int(x) The integer component of x.
mod (x,y) The remainder obtained when x is divided by y.
ln(x) The natural logarithm of x.
nint(x) The nearest integer to x.
pbc(distance) Apply periodic boundary conditions and adjust the distance
accordingly.
rand() Generate a random number on the interval of 0 to 1.
real(x) The real component of x.
UML conventions
UML notation Explanation
Name
private
public
UML diagram for a class. The name of the class is given at the top
followed by private and public attributes and/or methods.
(Continued)
Notation 575(Continued)
UML notation Explanation
Name
Short-hand notation for a class, containing only the name of the
class.
This arrow is used to signify association (needs-a, requires-a, uses-a
relationship). The arrow signifies the direction of the relationship
This arrow is used to signify aggregation (part-of relationship). The
diamond is placed on the container class and the arrow points to
the parts. For example, an atom is part of a molecule.
This arrow symbol is used to denote inheritance (is-a relationship)
between classes. The parent class is positioned at the head of the
arrow and the child class is placed at the bottom. The child class
inherits properties from the parent class.
576 NotationIndex
Note: Page numbers followed by “b,” “f,” and “t” refer to boxes, figures, and tables,
respectively.
A
Abstract methods, 481483
Abstraction, 408, 409f
Acceleration, 46, 336337
Acceptance criterion, 45, 378379. See also
Monte Carlo (MC)
Adams predictorcorrector algorithm, 374.
See also Integrators
Aggregation, 410412
UML diagram
illustrating combined use of inheritance
and aggregation, 412f
illustrating different levels of
aggregation, 411f
representing aggregation relationship
between Molecule and Atom, 411f
Alkanes, 273, 296297
All-atom (AA) potential, 8990
α thermostatic constant, calculation of, 293b
Ab initio
approach, 55
calculations, 118123
CarParrinello method, 122123
density functional theory, 120122
HartreeFock method, 119120
data, 9697, 126128
methods, 77
NCC, 146
potentials, 118, 125130
for carbon dioxide, 151
case study, 152155
for combinations of molecules,
145147
comparison of contribution of different
terms to two body ab initio noble gas
potentials, 127t
efficient three-body calculations,
153155
for fluid properties, 152155
relative differences between energies
calculated from multiparameter
potentials, 130f
systematic improvement of water
potentials, 152153
two-body SAAP parameters, 129t
SAAP, 128
two-body potentials, 128, 146
for carbon dioxide, 145146
AMBER. See Assisted model building with
energy refinement (AMBER)
AMOEBA. See Atomic multipole optimized
energetics for biomolecular
applications (AMOEBA)
Andersen thermostat, 333335
MD in NVT ensemble using, 334b
Andersen’s algorithm, 339341
MD in NpH ensemble using Andersen’s
method, 341b
MD in NpT ensemble using, 343b
for NpH ensemble, 342
Angle-bending potential, 82
Angular constraints, 264
Argon, 141, 407
Assisted model building with energy
refinement (AMBER), 8991
Association, 412413, 413f
ATM. See AxilrodTellerMut ¯o (ATM)
Atomatom model of diatomic molecule, 87f
Atomic displacements, basic MC procedure
for accepting changes in, 218b
Atomic multipole optimized energetics for
biomolecular applications (AMOEBA),
100101
Atoms, 408
class, 407, 476477
code for, 454459, 508511
effective pairwise potentials for, 6477
in microcanonical ensemble, 563
577Atoms (Continued)
OO application to microcanonical MC
simulation of Lennard-Jones atoms,
484485
OO application to microcanonical MD
simulation of Lennard-Jones atoms,
425426
Attributes, 420421
distinction between classes and, 415t
distinction between classes and attributes
for MC simulation, 475t
Automatically updated neighbor list, 173b
Auxiliary methods
code for, 471473, 517
OO application to microcanonical MC
simulation of Lennard-Jones atoms,
489
OO application to microcanonical MD
simulation of Lennard-Jones atoms,
432433
AxilrodTellerMut¯o (ATM), 11, 132133
comparison of contributions of, 143f
potential, 132135, 150
for nonspherical molecules, 147148
AzizSalman potential, 125
B
BaranyaiCummings method, 371373
BarkerFisherWatts potential (BFW
potential), 124, 178179
BarkerPompe potentials, 124
BarnesHut algorithm, 197200
division of space for two-dimensional
particle distribution, 199f
Beeman modification, 256258
BeemanVerlet method for integrating
equations of motion, 257b
BeemanVerlet algorithm, 257258
Beutervan Gunsteren method, 351
BFW potential. See BarkerFisherWatts
potential (BFW potential)
Bicanonical ensemble, 362
Binary mixtures, 366
of molecules, 102
Binary tree, 198
blockDim.x (number of threads in block), 531,
539
blockIndex.x (index of block), 531
blockSize, 542
BobeticBarker potentials, 124
Boltzmann distribution, 311
Boltzmann factors, 225226, 413f
Bond potential, 81
Bond separations, 266
Bond-length constraints, Shake method for
incorporating, 268b
BornMayer potentials, 7071, 125
BornOppenheimer approximation, 118119
BuckinghamCorner potential, 7071
Butane n-butane
C
C (procedural language), 12, 405, 408409
C11(object-oriented language), 320,
413414
code for combined Monte Carlo and
molecular dynamics simulation
program for Lennard-Jones atoms in
microcanonical ensemble, 564
for molecular dynamics simulation,
561562
organization of data files for molecular
dynamics simulation, 562t
for Monte Carlo simulation of Lennard￾Jones, 563564
organization of data files for Monte
Carlo simulation, 563t
object-oriented programming in, 433473,
489521
C¸ aginPettitt method, 347348
Canonical (NVT) ensemble, 310314,
330338
Andersen thermostat, 333335
constraint methods, 338
heat-bath coupling, 332333
MC simulation in canonical ensemble, 313b
molecular dynamics in NVT ensemble using
simple velocity scaling, 331b
Nose´ thermostat, 335336
Nose´Hoover equations, 336338
simple velocity scaling, 330332
Canonical ensemble, 21, 309310, 361
Carbon dioxide, 296297
Carbon nanotubes (CNT), 297298
CarParrinello molecular dynamics (CPMD),
122123
CBMC. See Configurational bias MC
(CBMC)
CC. See Coupled cluster (CC)
CCB. See Continuum configurational bias
(CCB)
CFF93, 9495
CFMM. See Continuous FMM (CFMM)
Chain molecules, 89
578 IndexChargecharge interaction, 79
Chargedipole interactions, 79
CHARMM. See Chemistry at Harvard
macromolecular mechanics
(CHARMM)
Chemical potential, 309, 346, 360362
Chemical potential weak coupling (CPWC),
351
Chemistry at Harvard macromolecular
mechanics (CHARMM), 89, 91, 279
CI. See Configuration interaction (CI)
Clapeyron equation, 373374, 378
Classes, 407408
distinction between attributes, 415t
for MC simulation and, 475t
OO application to microcanonical MC
simulation of Lennard-Jones atoms,
479489
Atom, 484485
auxiliary methods, 489
Energy, 487
Ensemble, 481482
LJ_Atom, 486
LJ_Energy, 488
Monte_Carlo, 480
NVE_Ensemble, 483
Simulation, 479480
OO application to microcanonical MD
simulation of Lennard-Jones atoms,
420433
Atom, 425426
auxiliary methods, 432433
ensemble, 422423
Force, 428
Gear_Predictor_corrector, 431432
Integrator, 430
LJ_Atom, 427
LJ_Force, 429
Molecular_Dynamics, 421
NVE_Ensemble, 424
Simulation, 421
UML diagram representation of Atom class,
408f
Cluster moves, 230233
MC procedure for accepting, 232b
CNT. See Carbon nanotubes (CNT)
Coefficient of diffusion, 2829
“Color conductivity” algorithm, 298
Combined MD and MC program for Lennard￾Jones atoms in microcanonical
ensemble, 517521
OOA, 517
OOP in C11, 518521
Combined NEMD/EMD method for SLE,
390392
combined EMD/NEMD algorithm for SLE,
391b
reduced pressure vs. reduced strain rate at
different reduced isochores, 391f
Combined potentials, 151
Compilation, 565566
MPI compilation, 565566
serial compilation, 565
Computation time, 179180
Computation-saving devices, 166, 205206
Computational efficiency, comparison of,
179180, 205206
Compute unified device architecture (CUDA),
527
basic GPU implementations with, 528534
code for
molecular dynamics simulation of
Lennard-Jones atoms in
microcanonical ensemble, 564
Monte Carlo simulation of Lennard-Jones
atoms in microcanonical ensemble,
564
reduction operation, 532b
compilation, 566
compiling molecular simulation codes
using, 534
functions or syntax, 529t
implementation of MC code, 542546
energy kernels, 543545
key changes and additions to MC files,
543t
implementation of MD code, 534542,
536b
changes to MD integrator, 542
force kernel, 537540, 538b
key changes and additions, 536t
key variable additions, 535537
Configuration interaction (CI), 120
Configurational bias MC (CBMC), 224230,
251
algorithm for chain, 227b
flexible chains, 226230
lattice chains, 224226
Configurational temperature, 345
Constrained particle motion, 3946
consequences of constraints on particles,
40
Gauss’s principle of least constraint, 4546
Hamilton equations of motion, 4345
Index 579Constrained particle motion (Continued)
holonomic and nonholonomic constraints,
3940
Lagrange equations of motion, 4143
Constraints, 264
equations, 266
methods, 338, 341342, 345346
of rigid body, 40
Continuous FMM (CFMM), 204205
Continuum configurational bias (CCB), 226
Coordinate system, 168
Coulomb model, 74
Coulomb’s law of electrostatic interaction, 74,
7778, 180181, 183
Coupled cluster (CC), 119
Coupled test particle approach, 362
Coupling stretchstretch interactions, 83
CPMD. See CarParrinello molecular
dynamics (CPMD)
CPWC. See Chemical potential weak coupling
(CPWC)
CUDA. See Compute unified device
architecture (CUDA)
cudaMalloc() function, 530
cudaMemcpy() function, 530
CVFF potential and CVFF91 potential, 9596
D
D’Alembert’s principle, 42
DebyeHu¨ckel theory, 78
Dendrimers, 58
Density functional calculation, 120121
Density functional theory (DFT), 77,
119122
Density MC, 380381
Density-dependent effective three-body
potential, 135136
“Density-scaling” procedure, 381
Device, 528
DFT. See Density functional theory (DFT);
Discrete Fourier transformation (DFT)
DGCM potential. See Double Gaussian core
model potential (DGCM potential)
Diatomic molecules, 7, 145
atomatom model of, 87f
Diffusion, 2829
Dipolar interactions, 180181
Dipole interactions using reaction field
method, calculation of, 188b
Dipoledipole interactions, 79, 137, 183184
Dipolequadrupole interactions, 79
Discrete Fourier transformation (DFT), 196
Dispersion
effects, 5455
general refinement of dispersion models,
7475
interactions, 66
Dissipative flux, 289
dolls tensor method, 285286, 292
Domain decomposition, 535
Double Gaussian core model potential
(DGCM potential), 64
E
EATM potential. See Extended ATM potential
(EATM potential)
ECCB. See Extended continuum
configurational bias (ECCB)
ECEPP/3. See Empirical conformational
energy program for peptides
(ECEPP/3)
ECM. See Entropy correlation method (ECM)
Effective pairwise potentials for atoms and
simple molecules, 6477
general refinement of repulsion and
dispersion models, 7475
repulsion 1 dispersion pair potentials,
6474
shifted-force potentials, 75
SR potentials, 7577
Efficient three-body calculations, 153155
Egelstaff potential, 69
Electrostatic distortion model, 139140
Electrostatic effects, 5455
EMD. See Equilibrium molecular dynamics
(EMD)
Empirical conformational energy program for
peptides (ECEPP/3), 8990
Empirically based simulation algorithms,
387392
combined NEMD/EMD method for SLE,
390392
synthetic method, 388390
Encapsulation, 408, 409f
Energy, 22, 191, 331332
calculation of energies using neighbor list
and lookup table, 179b
calculation of energies/forces using
neighbor list, 172b
classes, 481483
code for, 512
kernels, 543545
launching, 545546
of molecular system, 88
580 IndexOO application to microcanonical MC
simulation of Lennard-Jones atoms,
487
energyLJKernel, 544545
key code details, 544b
Ensemble averages of pressure and energy, 19
Ensemble class, 422424
code for, 444448, 491499
OO application to microcanonical MC
simulation of Lennard-Jones atoms,
481482
Ensembles, 1924, 522524
alternative methods for thermodynamic
properties, 3038
MC NpH ensemble, 3738
MC NpT ensemble, 3536
MC NVT ensemble, 3234
MC μVT ensemble, 3637
MD NVE ensemble, 3032
molecular simulation and choice of, 2930
OO application to microcanonical MD
simulation of Lennard-Jones atoms,
422423
particle dynamics, 3947
properties from fluctuations, 2430
statistical mechanics, ensembles, and
averaging, 2024
simple thermodynamic averages, 2224
Enthalpy of system, 340
Entropy, 21, 323
Entropy correlation method (ECM), 392393
algorithm for SLE, 393b
Equations of motion, 122123, 335336,
340, 347348, 368. See also
Integrators
for atomic systems, 299
BeemanVerlet method for integrating,
257b
general predictorcorrector procedure for
solving, 247b
integrating, 244
leap-frog Verlet method for integrating,
253b
original Verlet method for integrating, 252b
RK4 integration of, 259b
velocity-Verlet method for integrating,
255b
Equilibration period, 312
Equilibrium molecular dynamics (EMD), 286,
301302, 390392
Euler angles, 262
Ewald sum, 8, 7879, 166, 179, 181186
calculation
real space contribution in, 186b
reciprocal space contribution in, 185b
Wolf approximation of, 186187
exp-6 potentials, 7174, 123, 522523
comparison of exp-6 potential with LJ
potential, 73f
values of λ as function α for exp-6
potential, 72f
Exp6_Energy, 522523
Exponential repulsion, 74
Extended ATM potential (EATM potential),
142143
Extended continuum configurational bias
(ECCB), 230
F
Fast multipole methods (FMM), 78,
200205
algorithms, 166
two-dimensional example of division of
simulation box, 200f
two-dimensional representation of
interrelationship, 201f
FCC_Lattice class, 416417
FENE. See Finitely extensible nonlinear
elastic (FENE)
Field equations
in one dimension, 193194
solution of field equations in one dimension
using Thomas tridiagonal algorithm,
194b
Finite-difference algorithms, 243, 327
Finitely extensible nonlinear elastic (FENE),
8788
Finitesizescaling (FSS), 387
Flexible chains, 226230
CBMC algorithm for chain, 227b
growing/retracing either fully flexible or
semi-flexible chain, 228b
Floating-point multiply-add instruction
(FMAD instruction), 534
Fluctuations
formulas for CV of atoms in different
ensembles, 24t
molecular simulation and choice of
ensemble, 2930
properties from, 2430
thermodynamic definitions of properties
and evaluation in NpT ensemble,
25t
thermodynamic properties, 2527
Index 581Fluctuations (Continued)
relative difference between the calculated
ideal contribution, 28f
transport coefficients, 2829
Fluid phase equilibria, synthetic algorithm for,
389b
Fluidsolid melting line Solid-liquid
equilibria (SLE)
FMAD instruction. See Floating-point
multiply-add instruction (FMAD
instruction)
FMM. See Fast multipole methods (FMM)
Forces and force fields, 41, 51, 88, 96, 167
All atom (AA) potentiaql, 8990
AMBER, 9091
AMOEBA, 100101
application to mixtures, 101102
calculation of potential energy, 5254
calculations, 166167
forces using neighbor list, 172b
using linked-cell list, 177b
case study, 97101
CFF93, 9495
CFMM, 204205
CHARMM, 9192, 9596
classes, 481483
code for, 462
of constraint, 41
contributions to molecular interactions,
7784
CVFF, 9596
CVFF, 9596
ECEPP/3, 9596
effective pairwise potentials for atoms and
simple molecules, 6477
extension to molecules, 8688
fully interpenetrable potentials, 6364
intermolecular forces, 5456
interpolation in one dimension of
particlemesh, 195b
kernel, 537540, 538b
launching, 540542
MM3, 9193
OO application to microcanonical MD
simulation of Lennard-Jones atoms,
428
OPLS/OPLS-AA, 8990
pairwise force fields from molecular
mechanics, 8897
optimized force fields, 8995
potentials with hard sphere contribution,
5662
simple atom-based pairwise potentials for
molecules, 8486
soft sphere potentials, 6263
UFF, 9394
FORTRAN (procedural language), 12, 168,
405, 408409
Four-body atomic interactions, 143144
Fourth-order MøllerPlesset calculation
(MP4), 125126
Fourth-order RungeKutta calculation (RK4),
258
Fourth-order triple-dipole term, 131132, 137
Fractional particles, 347349
Friction coefficient, 338
FSS. See Finitesizescaling (FSS)
Fully flexible chain, growing/retracing either,
228b
Fully interpenetrable potentials, 6364
DGCM potential, 64
GCM potentials, 63
FumiTosi potential, 86
G
Gauss’s principle of least constraint, 4546,
273278, 338, 341342
GAUSSIAN (software packages), 119
Gaussian charge distribution, 182
Gaussian core model fluid, 297
Gaussian core model potential (GCM
potential), 6364
GCM potential. See Gaussian core model
potential (GCM potential)
GDI. See GibbsDuhem integration (GDI)
Gear predictorcorrector algorithm,
249250, 338
Gear predictorcorrector integrator, NEMD
process at constant strain rate using,
288b
Gear predictorcorrector methods, 244247,
249250, 279280, 338, 432,
567569
basic Gear algorithm, 245249
cautionary note on nomenclature, 249
Gear corrector coefficients kd for second￾order equation using time-scaled
variables, 246t
Gear’s four-value predictorcorrector
algorithm using scaled time
derivatives, 248b
general predictorcorrector procedure
for solving equations of motion, 247b
Four-value Gear-predictor, 294b, 295b
582 IndexNEMD process at constant strain rate using,
288b
Gear’s 5 value method, 562
representations of Gear algorithm, 249250
Gear_Predictor_corrector class, 416417
code for, 467470
OO application to microcanonical MD
simulation of Lennard-Jones atoms,
431432
Gear’s four-value predictorcorrector
algorithm using scaled time
derivatives, 248b
GEMC. See Gibbs ensemble MC (GEMC)
Generalized momentum, 4344
Generalized nm Lennard-Jones/Mie
potential, 6469
comparison of energy curve, 66f
comparison of literature values and re￾evaluated, 67t
generalized sllod algorithm (gsllod), 292293
Get’ methods, 420421
getAtoms() method, 500504
getComp() method, 500504
getEnergyLRC() method, 504508
getKineticE() method, 500504
getMass() method, 508512
getnEquil() method, 491500
getnSize() method, 491500
getnStep () method, 491500
getNumAtom() method, 500504
getPosition() method, 508512
getrCutOff() method, 508512
getTotalEfixed() method, 500504
getTrialPosition() method, 508512
getTrialPotE() method, 504508, 512517,
545546, 546b, 554, 555b
getType() method, 508512
getVolume() method, 500504
Gibbs ensemble, 10, 73, 360361, 364, 381
grand canonical MC method, 223224
MD using LoPalmer algorithm, 369b
method, 360
Monte Carlo simulation, 362367, 365b
MC moves used in Gibbs ensemble, 363f
Gibbs ensemble MC (GEMC), 364365, 376,
386
binary VLE simulations, 366
simulation, 375376
GibbsDuhem equation, 373374
for binary mixtures, 376378
GibbsDuhem integration (GDI), 10,
373380
MC implementation of GDI for one￾component fluid at several different
temperatures, 377b
GibbsDuhem simulation method, 373374
GPU. See Graphics processing unit (GPU)
Grand canonical (μVT) ensemble, 319322,
346353
Beutervan Gunsteren method, 351
C¸ aginPettitt method, 347348
LoPalmer method, 348350
Lupkowskivan Swol method, 346347
MC simulation in μVT ensemble, 321b
parallel algorithm, 351353
Grand canonical ensemble, 320
Grand canonical MC, 385386
reweighting procedure, 386
Grand canonical partition function, 36
Graphics processing unit (GPU), 1213, 527
basic GPU implementations with CUDA,
528534
allocating and copying memory, 530
compiling molecular simulation codes
using CUDA, 534
general GPU algorithm, 533534
kernel, 529530
launching kernel, 531
reduction, 531533
Green_Kubo EMD method, 302
GreenKubo relationship, 288289
for self-diffusion coefficient, 298
for shear viscosity, 289290
for thermal conductivity coefficient, 299
gridDim. x (number of threads in grid
composed of all blocks), 531, 539
GROMOS approach. See Groningen
molecular simulation approach
(GROMOS approach)
Groningen molecular simulation approach
(GROMOS approach), 89
Growing/shrinking, 351
gsllod. See generalized sllod algorithm
(gsllod)
H
Hamiltonian, 44
dynamic systems, 1920, 250
equations of motion, 1920, 4345, 47,
262, 333334
Hamiltonian-based algorithm for thermal
conductivity, 299
Hard convex body (HCB), 62
Hard core (HC), 62
Index 583Hard sphere 1 attractive (HSA), 5657
approach, 62
potentials, 5963
comparison of repulsion 1 attraction
represented by DGCM, 59f
inverse power potential, 61
Kihara hard core potential, 62
penetrable SW potential, 60
sticky sphere potential, 6162
SW potential, 59
triangular well potential, 60
Yukawa potential, 6061
Hard spheres (HS), 6, 5657
contribution
comparison of some repulsive potentials,
57f
HS potential, 5758
HSA potentials, 5962
non-HS repulsive potentials, 58
potentials with, 5662
early work on hard spheres and atoms, 67
intermolecular potential, 522523
potentials, 58, 6263
HartreeFock, 56, 77, 150
dispersion models (HFD models), 119120
energy surface, 9495
HC. See Hard core (HC)
HCB. See Hard convex body (HCB)
Header files, 561, 563
Heat current, 299300
Heat-bath coupling, 332333
Helmholtz function, 21, 3233
Higher-body atomic interactions, 143144
Histogram, 386
methods, 385
reweighting
algorithms, 384386
GEMC, 386
grand canonical MC, 385386
isothermalisobaric MC, 386
technique, 223224, 386387
Holonomic constraints, 3940
Homogeneous methods, 285
Hooke’s law approach, 8182
Host, 528
function, 540
HS. See Hard spheres (HS)
HS_Energy, 522523
HSA. See Hard sphere 1 attractive (HSA)
Hybrid MD/MC, 342343
MD in NpT ensemble using Andersen’s
method, 343b
Hybrid PIMC method, 235
Hydrogen Molecular hydrogen
Hydrogen bond interactions, 8081
I
Importance sampling concept, 310311
Induction effects, 5455
Inheritance, 409410
UML diagram
combined use of inheritance and
aggregation, 412f
notation for inheritance, 410f
initialCoord() method, 504508
Integrators
code for, 467
comparison of, 261262
for molecular dynamics
Addams predictorcorrector algorithm,
374
Beeman-Verlet alforithm, 257258
comparison of integrators, 261262
Gear predictorcorrector methods,
244250
integrating equations of motion, 244
integrators for molecules, 262279
large molecules, 263279
RungeKutta integration, 258261
small molecules, 262263
Verlet algorithm, 244245, 250254,
257258, 261262, 271272, 279
velocity-Verlet algorithm, 254256,
255b, 272273, 279
Verlet predictor methods, 250258
OO application to microcanonical MD
simulation of Lennard-Jones atoms,
430
Intermolecular forces, 5456. See also
Intermolecular pair potentials
calculation
energy using periodic boundary
conditions, 169b
single time step using PPPM method,
192b
hydrogen bond potentials, 8081
quantum theory of intermolecular
potentials, 5556
types of, 5455
Intermolecular interactions, 54, 77, 117, 166
Intermolecular ionic and polar potentials,
7780
Intermolecular pair potentials, 52. See also
Forces and force fields
584 Indexapplication to mixtures, 101102
calculation of potential energy, 5254
use of notation, 54
case study, 97101
contributions to molecular interactions,
7784
effective pairwise potentials for atoms and
simple molecules, 6477
extension to molecules, 8688
fully interpenetrable potentials, 6364
intermolecular forces, 5456
inverse power potential, 61
pairwise force fields from molecular
mechanics, 8897
optimized force fields, 8995
potentials with hard sphere contribution,
5662
simple atom-based pairwise potentials for
molecules, 8486
soft sphere potentials, 6263
Intermolecular potentials
ab initio, 125130
angle-bending potentials, 82
ATM, 132133
AzizSlaman, 125
BarkerPompe, 124
BarkerFisher-Watts, 124, 178179
bond potentials, 8182
BuckinghamCorner, 7071
cross-terms, 8384
Egelstaff, 69
exp-6, 7174, 123, 522523
DGCM, 64
FumiTosi, 86
Goodford, 8081
GCM, 6364
HSA, 5963
HugginsMayer, 86
intraparticle, penetrations, 63, 297
Keesom, 80
Kihara, 62
Leonhard and Deiters (LD), 145
LennardJones, 6, 38, 418, 474475,
486489, 512, 535
London, 7071
MCY, 146
MCYna, 153
Mie, 6469
out-of-plane bending potentials, 8283
RPM, 8586
SAAP, 128, 130, 155
ShavittBoys, 71
sticky sphere, 6162
SPC, 98100
SPC/E, 98100
square-well, 365
shift-force, 75
SpurlingMason, 85
Stockmayer, 8485
Sutherland, 61
TangToennies, 126
TIP4P, 98100
TIP4P/2005, 98100
TIP5P, 98100
WCA, 58
WCA 1 FENE, 8788
Yukawa, 6061
Intermolecular_Potential class, 412413
Internal virial, 23
Inverse Debye screening length, 191
Ionic fluids, 8586
Ionic systems, 78
Ions, 78, 230
Isobaricisoenthalpic (NpH) ensemble,
339342
Andersen’s algorithm, 339341
constraint methods, 341342
MD algorithms, 309310
Isobaricisoenthalpic ensemble, 340341
Isobaricisoenthalpic MD algorithms,
309310
Isobaricisothermal (NpT) ensemble, 2122,
309, 314319
MC simulation in NpT ensemble, 317b
MD algorithms, 309310
Isochoric heat capacity, 234
Isokinetic sllod equations of motion, 292
Isothermalisobaric (NpT) ensemble,
342346
constraint methods, 345346
extension of Nose´Hoover equations,
343345
MC, 386
hybrid MD/MC, 342343
K
Keesom potential, 80
Kernel, 529530
launching, 531
Kihara hard core potential, 62
Kinetic energy, 22, 323, 328, 339340
Kink-jump algorithm, 222223, 223f
KotelyanskiiHentschke method, 370371
Krypton, 124, 141
Index 585L
Lagrangian, 1920, 43
dynamics, 1920
equations of motion, 4143
for grand canonical ensemble, 347
Large molecules, 263279
Rattle method for incorporating bond-length
constraints, 274b
Shake method for incorporating bond-length
constraints, 268b
triatomic molecule, 264f
Lattice chains, 224226
insertion possibilities for three-unit
molecule on two-dimensional lattice,
225f
Leap-frog Verlet algorithm, 253254, 256.
See also Integrators
for integrating equations of motion, 253b
Least constraint, Gauss’s principle of, 4546,
273278
LeesEdwards periodic boundary conditions,
293
Lennard-Jones potential, 6, 38, 418, 474475,
486489, 512, 535
application of object orientation to
microcanonical MC simulation of,
474517
application of OO to microcanonical MD
simulation of, 414473
in microcanonical ensemble, 561
C11 code for combined Monte Carlo
and molecular dynamics simulation
program for, 564
combined MD and MC program for,
517521
CUDA code for molecular dynamics
simulation of, 564
CUDA code for Monte Carlo simulation
of, 564
MPI code for molecular dynamics
simulation of, 565
generalized nm, 6469
Linear response theory, 288289
Linked cells, 174180
cell numbering for two-dimensional
simulation cell, 174f
creation of linked-cell list, 176b
force calculation using linked-cell list, 177b
three-dimensional map of cells and nearest
neighbors, 175b
Liouville equation, 4647
Liquid metals, 296297
Liquidliquid equilibria (LLE), 62, 366
LJ fluids
LJ potentials. See Lennard-Jones potentials
(LJ potentials)
LJ/M potential, 6566
LJ_Atom
code for, 460461, 512
OO application to microcanonical MC
simulation of Lennard-Jones atoms,
486
OO application to microcanonical MD
simulation of Lennard-Jones atoms,
427
LJ_Energy class
code for, 512516
OO application to microcanonical MC
simulation of Lennard-Jones atoms,
488
LJ_Force class
code for, 463466
OO application to microcanonical MD
simulation of Lennard-Jones atoms,
429
LLE. See Liquidliquid equilibria (LLE)
London potentials, 7071
Long-range (LR)
corrections to periodic boundary
calculations, 169170
effects, 54
force, 7, 165166
interactions, 180181, 191192
assignment of charges to particlemesh
in one dimension, 193b
calculation of, 180206
calculation of intermolecular forces for
single time step using PPPM method,
192b
comparison of computational efficiency,
205206
Ewald sum, 181186
force interpolation in one dimension of
particlemesh, 195b
particle-particle and particle-mesh
methods, 191197
reaction field method, 187191
solution of field equations in one
dimension using Thomas tridiagonal
algorithm, 194b
tree-based methods, 197205
Wolf approximation of Ewald sum,
186187
Look-up table, 178179
586 Indexcalculation of energies using neighbor list
and, 179b
creation of, 178b
LoPalmer method, 348350, 367369
Gibbs ensemble MD using LoPalmer
algorithm, 369b
MD in μVT ensemble using LoPalmer
algorithm, 350b
LP. See Lone pair (LP)
lrc() methods, 504508, 512517
Lupkowskivan Swol method, 346347
Lustig’s approach, 35, 3738
M
Machine learning, 52, 97
Macromolecules, 101
MaitlandSmith potential, 6970
malloc(), 530
MANIAC computer, 2
MarcelliWangSadus potential (MWS
potential), 136
Markov chains, 215, 217219, 218b,
309311
MassieuPlanck system of thermodynamics,
3233
Matsuoka, Clementi, and Yoshimine (MCY),
146
MaxwellBoltzmann distribution, 347,
349351
of velocities, 12
MBF. See Mean Boltzmann factor (MBF)
MC. See Monte Carlo (MC)
MCSCF. See Multiconfigurational wave
function methods (MCSCF)
MCY. See Matsuoka, Clementi, and
Yoshimine (MCY)
MCYna potential, 153
MD. See Molecular dynamics (MD)
Mean Boltzmann factor (MBF), 351
Mechanical equilibrium, 363364
Memory, allocating and copying, 530
Mesh potential, 196
Message passing interface (MPI), 527
code for molecular dynamics simulation of
Lennard-Jones atoms in
microcanonical ensemble, 565
compilation, 565566
CUDA compilation, 566
implementation of MC code, 553556
implementation of MD code, 548553,
548t
changes to ljForceMD. cpp, 550553
changes to mainMD. cpp, 549550
changes to MD integrator, 553
key variable additions, 549
parallel programming with, 546548
Methane, 296297
Metropolis sampling, 217219
basic MC procedure for accepting changes
in atomic displacements, 218b
Metropolis-type moves, 322323
Microcanonical (NVE) ensemble, 322330
comparison of MC simulations, 326t
general MD NVE ensemble strategy, 328b
MC simulation in NVE ensemble, 325b
MD in NVE ensemble using periodic
scaling of velocities, 329b
Microcanonical ensemble, 21, 309310, 328
atoms in, 563
C11 code for combined Monte Carlo and
molecular dynamics simulation
Program for Lennard-Jones atoms in,
564
combined MD and MC program for
Lennard-Jones atoms in, 517521
CUDA code for molecular dynamics
simulation of Lennard-Jones atoms in,
564
CUDA code for Monte Carlo simulation of
Lennard-Jones atoms in, 564
Lennard-Jones atoms in, 561
MPI code for molecular dynamics
simulation of Lennard-Jones atoms in,
565
preliminary UML diagram for MD in, 417f
Microcanonical MC simulation of Lennard￾Jones atoms, application of object
orientation to, 474517
Microcanonical MD simulation of Lennard￾Jones atoms, application of OO to,
414473
Mie potential, generalized nm, 6469
Minimum image convention, 167169
Mixtures, application of NEMD algorithms to,
301
MM. See Molecular mechanics (MM)
MM2 potential and MM3 potential, 9192
MM3 force field, 9193
Modified Buckingham potential, 7174
Molecular displacements, 363364
Molecular dynamics (MD), 13, 56, 285,
326353, 360, 405406, 528
in μVT ensemble using LoPalmer
algorithm, 350b
Index 587Molecular dynamics (MD) (Continued)
algorithms, 243, 309, 567569
canonical (NVT) ensemble, 330338
code, 561
CUDA implementation of MD code,
534542
equation of motion, 370371
general outline of, 6b
Gibbs ensemble, 367373
BaranyaiCummings method, 371373
KotelyanskiiHentschke method,
370371
LoPalmer method, 367369
grand canonical (μVT) ensemble, 346353
isobaricisoenthalpic (NpH) ensemble,
339342
isothermalisobaric (NpT) ensemble,
342346
microcanonical (NVE) ensemble, 326330
molecular simulation method, 19
in NpH ensemble using Andersen’s method,
341b
in NpT ensemble using
Andersen’s method, 343b
Nose´Hoover equations of motion and
correctorpredictor strategy, 345b
in NVE ensemble, 3032
relationships for key thermodynamic
quantities in terms of phase-space
functions for, 32t
using periodic scaling of velocities, 329b
in NVT ensemble using
Andersen thermostat, 334b
Nose´Hoover equations of motion and
predictorcorrector strategy, 337b
using simple velocity scaling, 331b
preliminary UML diagram for MD in
microcanonical ensemble, 417f
relative performance of MD and MC MPI
and GPU codes, 556559
performance of MD and MC GPU codes,
556557
performance of MD MPI code, 558559
simulation, 28, 51, 329, 414, 477478
C11 code for, 561562
CUDA code for Lennard-Jones atoms in
microcanonical ensemble, 564
MPI code for Lennard-Jones atoms in
microcanonical ensemble, 565
organization of data files for, 562t
of polyatomic molecules, 7
thermostats, 345
Molecular force fields, 144, 165166
Molecular hydrogen, 145
Molecular interactions, 166
calculation
of long-range interactions, 180206
of short-range interactions, 166180
contributions to, 7784
intermolecular hydrogen bond potentials,
8081
intermolecular ionic and polar potentials,
7780
intramolecular angle-bending potentials,
82
intramolecular bond potentials, 8182
intramolecular cross-terms, 8384
intramolecular out-of-plane bending
potentials, 8283
intramolecular torsional potentials, 83
Molecular mechanics (MM), 89
pairwise force fields from, 8897
Molecular simulation, 16, 1920, 46, 54,
73, 139140, 359, 410, 527
application of OO to
microcanonical MC simulation of
Lennard-Jones atoms, 474517
microcanonical MD simulation of
Lennard-Jones atoms, 414473
and choice of ensemble, 2930
combined MD and MC program for
Lennard-Jones atoms in
microcanonical ensemble, 517521
of ensembles
molecular dynamics, 326353
Monte Carlo, 310326
extensions, 521524
fundamental concepts of OO, 407414
MC method, 45
MD, 56
methods, 11, 5758
of phase equilibria
accurate determination of SLE, 392394
calculating chemical potential, 360362
empirically based simulation algorithms,
387392
finite-size scaling, 387
Gibbs ensemble Monte Carlo, 362367
GibbsDuhem integration, 373380
histogram reweighting algorithms,
384386
MD Gibbs ensemble, 367373
NpT 1 test particle, 373
pseudo-ensemble methods, 382384
588 Indexthermodynamic scaling, 380382
progress in, 613
chain molecules and polymers, 89
early work on hard spheres and atoms,
67
ensembles for molecular simulation, 9
interatomic interactions, 11
many-body interactions, 1112
molecular simulation and object
orientation, 12
nonequilibrium MD simulation, 12
parallel computing, 1213
phase equilibria, 911
polar molecules and ions, 78
small nonpolar molecules, 7
studies of VLE, 133135
of thermal conductivity, 300
Molecular_Dynamics, 416417
class, 477480
code for, 436443
object, 421, 519520
OO application to microcanonical MD
simulation of Lennard-Jones atoms,
421
Molecules, 7778, 263264, 273, 523524
Ab initio potentials for combinations of,
145147
application, 219223
of NEMD algorithms to, 300301
class, 409410
extension to, 8688
adding nonbonded interactions, 8788
nonbonded interactions in molecules,
8687
integrators for, 262279
large molecules, 263279
small molecules, 262263
potentials for, 144152
simple atom-based pairwise potentials for,
8486
Molten salts, 8586
Monte Carlo (MC), 13, 133, 310326, 528
μVT ensemble, 3637
relationships for key thermodynamic
quantities in terms of derivatives of
partition, 37t
acceptance criteria, 378379
algorithm, 165, 309, 567569
C11 code for combined Monte Carlo and
molecular dynamics simulation
program for Lennard-Jones atoms in
microcanonical ensemble, 564
C11 code for Monte Carlo simulation of
Lennard-Jones, 563564
canonical (NVT) ensemble, 310314
code, 563
CUDA code for Monte Carlo simulation of
Lennard-Jones atoms in
microcanonical ensemble, 564
files for CUDA, 564
general outline of, 5b
Gibbs ensemble method, 366
grand canonical (μVT) ensemble, 319322
grand canonical algorithm, 347
implementation of GDI for one-component
fluid at several different temperatures,
377b
isobaricisothermal (NpT) ensemble,
314319
method, 45, 215
Casino de Monte-Carlo, 4f
microcanonical (NVE) ensemble, 322326
molecular simulation method, 19, 51
NpH ensemble, 3738
relationships for key thermodynamic
quantities for, 38t
NpT ensemble, 3536
relationships for key thermodynamic
quantities in terms of derivatives of
partition function for, 35t
NVT ensemble, 3234
relationships for key thermodynamic
quantities in terms of derivatives of
partition function for, 33t
procedure for accepting cluster moves,
232b
simulations, 2, 89, 6263, 312, 319320,
327328, 385, 406, 474475
in μVT ensemble, 321b
advanced techniques, 223233
application to molecules, 219223
background, 216217
basic concepts, 216219
in canonical ensemble, 313b
cluster moves, 230233
comparison of, 326t
configurational bias MC, 224230
Metropolis sampling and Markov chains,
217219
in NpT ensemble, 317b
in NVE ensemble, 325b
organization of data files for, 563t
path integral Monte Carlo, 233235
polymers, 220223
Index 589Monte Carlo (MC) (Continued)
rigid molecules, 219220
small flexible molecules, 220
Monte_Carlo, 476477
class, 477480
code for, 491499
object, 519520
OO application to microcanonical MC
simulation of Lennard-Jones atoms,
480
MonteCarlo() constructor, 480481
Morse potential, 8182, 125126
MP4. See Fourth-order MøllerPlesset
calculation (MP4)
MPI. See Message passing interface (MPI)
MPI_Allreduce(), 556
MPI_Comm_rank() function, 550552
MPI_Comm_size() function, 550552
MPI_Finalize() function, 549550
MPI_Init() function, 549550
Multi-body effects, 128
Multiconfigurational wave function methods
(MCSCF), 120
Multiparameter potentials, relative
differences between energies
calculated from, 130f
Multiphase system, 368369
Multiple-time-step hybrid MC technique, 366
Multipolar contributions beyond triple-dipole
term, 136139
contribution of three-body interactions to
crystalline energy of noble gases, 138t
Multipolar nonadditive coefficients, 137
Multipolar nonadditive third-order potentials,
136137
Multipole moments, 201202
MWS potential. See MarcelliWangSadus
potential (MWS potential)
N
n-butane, 220
N-coupled first-order systems of differential
equations, 258
Naive energy, 166167
NaiverStokes transport coefficient, 289
NCC potential, 146
nearestInt() function, 540
Neighbor list, 170173
automatically updated neighbor list, 173b
calculation of energies/forces using
neighbor list, 172b, 179b
creation of Verlet neighbor list, 171b
NEMD. See Nonequilibrium molecular
dynamics (NEMD)
NERD potential, 96
Newton’s equations of motion, 1920, 41, 43,
287, 309310, 326327, 339341
Newton’s law of viscosity, 293
Newton’s second law of motion, 39, 244
Newton’s third law, 174176, 540
NewtonGregory forward difference method,
178
Nitrogen, 7
nm LJ/M potentials, 68
Noble gases, 123124
Non-Gaussian thermostats, 292
Non-HS repulsive potentials, 58
WCA potentials, 58
Nonadditive coefficient, 133
Nonbonded interactions, 8788
atomatom model of diatomic molecule,
87f
in molecules, 8687
Nonequilibrium molecular dynamics (NEMD),
12, 285, 302, 390, 567569
application
to mixtures, 301
to molecules, 300301
comparison with EMD, 301302
example NEMD algorithm, 286288
at constant strain rate using Gear
predictorcorrector integrator, 288b
illustration of sliding brick boundary
conditions for shear viscosity
simulations, 287f
simulations, 12, 297
synthetic NEMD algorithms, 288300
Nonholonomic constraints, 3940
Nose´ thermostat, 335336
Nose´’s equations of motion, 9
Nose´Hoover algorithm, 349
Nose´Hoover equations, 336338
extension of, 343345
MD in NpT ensemble using
Nose´Hoover equations of motion and
correctorpredictor strategy, 345b
MD in NVT ensemble using Nose´Hoover
equations of motion and
predictorcorrector strategy, 337b
Nose´Hoover thermostat, 347
NpH ensemble algorithms, 324325, 339
NpT 1 test particle, 373
NpT ensemble, 316, 345346
algorithm, 344
590 IndexMC simulation in, 317b
simulation, 375
thermodynamic definitions of properties
and evaluation in, 25t
NpT MC procedure, 316
NVE ensemble, 30, 474475
preliminary data dictionary describing
classes in NVE ensemble MC
simulation, 479t
preliminary UML diagram for Monte Carlo
simulations in, 476f
NVE_Ensemble class, 416418, 476477,
483
code for, 449453, 504507
OO application to microcanonical MD
simulation of Lennard-Jones atoms,
424
NVEPG ensemble, 30
NVT ensemble, 349351
NVT Gibbs ensemble, 364365
O
Object modeling technique (OMT),
407408
Object-orientation (OO), 405
application of OO to microcanonical MC
simulation of Lennard-Jones atoms,
474517
detailed class description, 479489
OOA and OOD, 474478
OOP in C11, 489517
application of OO to microcanonical MD
simulation of Lennard-Jones atoms,
414473
detailed class description, 420433
object-oriented programming in C11,
433473
OOA and OOD, 414419
combined MD and MC program for
Lennard-Jones atoms in
microcanonical ensemble, 517521
extensions, 521524
fundamental concepts of, 407414
abstraction and encapsulation, 408
aggregation, 410411
association, 412413
classes and objects, 407408, 408f
inheritance, 409410
methods and message passing, 408409
polymorphism, 413414
molecular simulation and, 12
Object-orientation analysis (OOA), 407, 517
OO application to microcanonical MC
simulation of Lennard-Jones atoms,
474478
distinction between classes and attributes
for MC simulation, 475t
preliminary data dictionary describing
classes in NVE ensemble MC
simulation, 479t
preliminary UML diagram for Monte
Carlo simulations in NVE ensemble,
476f
OO application to microcanonical MD
simulation of Lennard-Jones atoms,
414419
distinction between classes and attributes,
415t
preliminary data dictionary describing
classes, 420t
preliminary UML diagram for MD in
microcanonical ensemble, 417f
short-hand UML notation, 416f
Object-orientation design (OOD), 407
OO application to microcanonical MC
simulation of Lennard-Jones atoms,
474478
distinction between classes and attributes
for MC simulation, 475t
preliminary data dictionary describing
classes in NVE ensemble MC
simulation, 477f
OO application to microcanonical MD
simulation of Lennard-Jones atoms,
414419
distinction between classes and attributes,
415t
preliminary data dictionary describing
classes, 420t
preliminary UML diagram for MD in
microcanonical ensemble, 417f
short-hand UML notation, 416f
Object-oriented analysis, 414
Object-oriented approach, 406
Object-oriented language, 320
Object-oriented programming (OOP), 407
in C11, 433473, 489521
code for Atom class, 454459, 508511
code for auxiliary methods, 471473,
517
code for Energy class, 512
code for ensemble class, 444448,
491499
code for Force class, 462
Index 591Object-oriented programming (OOP)
(Continued)
code for Gear_Predictor_corrector class,
467470
code for Integrator class, 467
code for LJ_Atom class, 460461, 512
code for LJ_Energy class, 512516
code for LJ_Force class, 463466
code for main() function, 433434,
489490
code for Molecular_Dynamics class,
436443
code for Monte_Carlo class, 491499
code for NVE_Ensemble class, 449453,
504507
code for simulation class, 435, 490
languages, 413414
Objects, 407408, 408f
OMT. See Object modeling technique
(OMT)
One-component system, 370371, 373374,
379
OO. See Object-orientation (OO)
OOA. See Object-orientation analysis
(OOA)
OOD. See Object-orientation design (OOD)
OOP. See Object-oriented programming
(OOP)
OpenCL, 527
OpenMP, 527
OPLS. See Optimized potential for liquid
simulation (OPLS)
Optimized force fields, 8995
AMBER force field, 9091
CFF93, 9495
CHARMM force field, 91
comparison of force fields and future
improvements, 9597
ECEPP models, 90
MM3 force field, 9193
OPLS/OPLS-AA force fields, 8990
UFF, 9394
Optimized potential for liquid simulation
(OPLS), 89
force field, 90
OPLS/OPLS-AA force fields, 8990
Ordinary differential equations, 245
Organization of data files for molecular
dynamics simulation, 562t
Original Verlet algorithm, 251252
for integrating equations of motion, 252b
Out-of-plane bending, 8283
P
Pairwise force fields from molecular
mechanics, 8897. See also
Intermolecular pair potentials; Forces
and force fields
Parallel algorithms, 351353, 567569
PGCMD algorithm, 352b
Parallel computation principles, 528
Parallel computing, 1213, 234, 527
Parallel grand canonical MD algorithm
(PGCMD algorithm), 351353, 352b
Parallel programming with MPI, 546548
general MPI procedure, 547548, 548b
key MPI functions or syntax, 547t
Particlemesh (PM), 191192, 197
assignment of charges to particlemesh in
one dimension, 193b
force interpolation in one dimension of,
195b
methods, 166
Particleparticle and particlemesh algorithm
(PPPM algorithm), 78, 179,
191197, 205206
calculation of intermolecular forces for
single time step using, 192b
Particleparticle calculation (PP calculation),
191192, 197
Particles
consequences of constraints on, 40
dynamics, 3947
Liouville equation, 4647
motion of constrained particles, 3946
motion of unconstrained particles, 39
virial theorem, 47
Partition function, 3234, 234
Path integral Monte Carlo (PIMC), 230,
233235
PBC. See Periodic boundary conditions (PBC)
Penetrable sphere attractive potential (PSA
potential), 60
Penetrable SW potential, 60
Periodic boundary conditions (PBC),
167169, 180181, 540
Periodic scaling of velocities, MD in NVE
ensemble using, 329b
PGCMD algorithm. See Parallel grand
canonical MD algorithm (PGCMD
algorithm)
Phase equilibria, 911, 383
Phase-space functions, 35, 3738, 46
PIMC. See Path integral MC (PIMC)
Pivot algorithm, 223
592 IndexPM. See Particlemesh (PM)
Poisson’s equation, 189190, 192
Polar molecules, 78
Polarizable models, 100101
Polymers, 89, 58, 6667, 220224, 286,
383
kink-jump algorithm, 222223
pivot algorithm, 223
reptation or slithering snake algorithm,
221222
Polymorphism, 413414
Position coordinates, 287288
Post-HartreeFock technique procedure, 56
Potentials, 523524
energy, 22, 339340
calculation of, 5254
for total system, 190
ensembles and, 522523
model, 51
for molecules, 144152
Ab initio potentials for combinations of
molecules, 145147
three-body molecular potentials, 145
two-body ab initio molecular potentials,
144147
potential-based approach, 130131
pressure, 23
PP calculation. See Particleparticle
calculation (PP calculation)
PPPM algorithm. See Particleparticle and
particlemesh algorithm (PPPM
algorithm)
Predicted value, 246
Predictorcorrector methods, 67, 243,
246247, 336. See also Integrators;
Adams predictor-corrector algorithm;
Gear predictor-corerctor methods;
Runge-Kutta integration
procedure for solving equations of motion,
247b
MD in NVT ensemble using, 337b
MD in NpT ensemble using, 345b
Preliminary UML diagram
for MD in microcanonical ensemble, 417f
for Monte Carlo simulations in NVE
ensemble, 476f
Pressure, 2223
evaluation of tensor components to, 291b
tensor, 289290
Primitive estimators, 234
Principal angular velocity, 263
Private variables, 409f
Propagator potential, 233234
Proteins, 101, 405406
PSA potential. See Penetrable sphere
attractive potential (PSA potential)
Pseudo code, 167, 571
Pseudo-Boltzmann factor, 315, 320, 322323
Pseudo-ensemble methods, 382384
Public variables, 535
Q
Quadrupoledipole interactions, 80
Quadrupolequadrupole interactions, 80
Quantum mechanics principle, 5556
Quantum theory of intermolecular potentials,
5556
Quaternions, 220, 263264
R
Random numbers, 333335
Random sampling, 217
Rapid elliptic solvers, 194195
Rattle algorithm, 271273
Ray’s modified Metropolis criteria, 474475
RayleighSchro¨dinger perturbation theory, 56
Reaction ensemble, 366
Reaction field, 166
calculation of dipole interactions using,
188b
method, 187191
readSimParameters() method, 479480
Real space
calculation of real space contribution in
Ewald sum, 186b
energy, 182183
summation, 182183
Reciprocal space, 183, 185b
Reduction in CUDA, 531533
REMD. See Replica exchange MD (REMD)
Replica exchange MD (REMD), 332
Reptation algorithm, 221222
trial move illustration using, 221f
Repulsion 1 dispersion pair potentials, 6474
BornMayer and London potentials, 70
BuckinghamCorner potential, 7071
Egelstaff potential, 69
generalized nm Lennard-Jones/Mie
potential, 6469
MaitlandSmith potential, 6970
Modified Buckingham potential, 7174
ShaviitBoys potential, 71
Repulsion models, general refinement of,
7475
Index 593reSetPosition() method, 508512
Residual chemical potential, 2324
Residual molar chemical potential, 393.
See also Chemical potential
Residual molar enthalpy, 393
Restricted primitive model (RPM), 8586
Reverse Euler estimates of velocities, 254
Rigid body, 3940
Rigid electronic interaction potential, 56
Rigid models, 97100
structure of water, 97f
Rigid molecules, 219220
RK. See RungeKutta (RK)
RK2 algorithm. See Second-order
RungeKutta algorithm (RK2
algorithm)
RK4 integration of equations of motion, 259b
RK4. See Fourth-order RungeKutta
calculation (RK4)
RMS. See Root mean square (RMS)
Root mean square (RMS), 24
Rosenbluth weight, 224225
RPM. See Restricted primitive model
(RPM)
run() method, 421422, 479481
RungeKutta (RK), 243
algorithms, 336
integration, 258261
RK4 integration of equations of motion,
259b
method, 243
runNPT() method, 522
runNVE() method, 421422, 480481,
491500, 522
S
SAAP. See Simplified ab initio atomic
potential (SAAP)
SAPT. See Symmetry-adapted perturbation
theory (SAPT)
SAW. See Self avoiding walk (SAW)
Scaled coordinates, 339
Scaled time derivatives, Gear’s four-value
predictorcorrector algorithm using,
248b
scalingInterval, 329330
SCF models. See Self-consistent field models
(SCF models)
Schro¨dinger equation, 118119
Second-order equation using time-scaled
variables, gear corrector coefficients kd
for, 246t
Second-order RungeKutta algorithm (RK2
algorithm), 261
Self avoiding walk (SAW), 223
Self-consistent field models (SCF models),
119
Self-diffusion, 298299
coefficient, 299
Semi-flexible chain, growing/retracing, 228b
Semigrand ensembles, 360, 378379
Serial compilation, 565
Set’ methods, 420421
setComp() method, 500504
setCutOff() method, 508512
setEnergy()method, 512517, 545546, 554
setForce()method, 504508, 550552, 550b
setKineticE() method, 500504
setLength()method, 500504
setLJEnergyKernel, 544
setLJForceKernel, 540542
setMass() method, 508512
setPosition() method, 508512
setTrialPosition() method, 508512
setType() method, 508512
setVolume() method, 500504
Shake
algorithm, 266271
method for incorporating bond-length
constraints, 268b
ShaviitBoys potential, 71
Shear flow, 285
Shear viscosity, 29, 289298
cautionary note on modifications to sllod,
292298
Shifted-force approach, 7576
Short-hand UML notation, 416417
Short-range (SR)
interactions, 55, 166, 191192
calculation of, 166180
calculation of either intermolecular
forces or energy, 167b
comparison of computational efficiency,
179180
linked cells, 174178
long-range corrections to periodic
boundary calculations, 169170
look-up table, 178179
Naive energy and force calculations,
166167
neighbor list, 170173
periodic boundary conditions and
minimum image convention, 167169
potentials, 7577, 76f, 166
594 IndexSimple atom-based pairwise potentials for
molecules, 8486
FumiTosi potential, 86
restricted primitive model, 8586
SpurlingMason potential, 85
Stockmayer potential, 8485
Simple molecules, effective pairwise
potentials for, 6477
Simple point charge (SPC), 98
potentials, 98100
SPC/E potentials, 98100
SPC/Fw model, 100
Simple thermodynamic averages, 2224
energy, 22
pressure, 2223
residual chemical potential, 2324
temperature, 22
Simple velocity scaling, 330332
molecular dynamics in NVT ensemble
using, 331b
Simplified ab initio atomic potential (SAAP),
128, 130, 155
Simulation, 80, 178, 333334, 476477
class, 421
code for, 435, 490
OO application to
microcanonical MC simulation of
Lennard-Jones atoms, 479480
microcanonical MD simulation of
Lennard-Jones atoms, 421
process, 336337, 421422
strategy, 344
techniques, 376
SLE. See Solidliquid equilibria (SLE)
Slithering snake algorithm, 221222
sllod
algorithm, 292, 300
modifications to, 292298
calculation of α thermostatic constant,
293b
four-value gear corrector, 295b
four-value gear predictor, 294b
tensor, 285286
Small flexible molecule approach, 220221
“Smarter MC” sampling, 223224
Soft sphere potential (SS potential), 6263
Software user’s guide
C11 code for
combined Monte Carlo and molecular
Dynamics simulation program for
Lennard-Jones atoms in
microcanonical ensemble, 564
molecular dynamics simulation, 561562
Monte Carlo simulation of Lennard￾Jones, 563564
compilation, 565566
CUDA code for
molecular dynamics simulation of
Lennard-Jones atoms in
microcanonical ensemble, 564
Monte Carlo simulation of Lennard-Jones
atoms in microcanonical ensemble,
564
MPI code for
molecular dynamics simulation of
Lennard-Jones atoms in
microcanonical ensemble, 565
Solidliquid equilibria (SLE), 1011, 58,
6263, 125, 360
accurate determination of, 392394
comparison of ECM molecular
simulation with experimental data,
394f
ECM algorithm for SLE, 393b
combined NEMD/EMD method for,
390392
ECM algorithm for, 393b
SOR. See Successive overrelaxation (SOR)
Spatial decomposition, 535
SPC. See Simple point charge (SPC)
Spring constant, 8788
SpurlingMason potential, 85
Square well potential (SW potential), 59, 123
SS potential. See Soft sphere potential (SS
potential)
Statistical mechanics, 2024, 46
of polarization, 96
Statistical thermodynamics principles, 19
Sticky sphere potential, 6162
Stockmayer potential, 80, 8485
Strain rate-dependent shear viscosity, 293
Structural programming approach, 433
Successive overrelaxation (SOR), 279
Summation, 182183
of Gaussian functions, 183
Supermolecule method, 5556
Supervised machine learning, 89
Sutherland potential, 61
SW potential. See Square well potential (SW
potential)
Symmetry-adapted perturbation theory
(SAPT), 145146
Synthetic experimental method, 388
Synthetic method, 387390
Index 595Synthetic method (Continued)
synthetic algorithm for fluid phase
equilibria, 389b
Synthetic NEMD algorithms, 288300
evaluation of tensor components to
pressure, 291b
self-diffusion, 298299
shear viscosity, 289298
thermal conductivity, 299300
T
TangToennies term, 126
Taylor expansion of constraint condition,
279
Taylor series expansions, 251
for coordinate vector, 245
Temperature, 22, 323324, 380381
dependent potential, 34
scaling, 331332
Tensor components to pressure, evaluation of,
291b
Test particle methods, 360
Thermal conductivity, 29, 299300
of butane, 300
triple point, 300
Thermodynamic averages
alternative methods for thermodynamic
properties, 3038
MC NpH ensemble, 3738
MC NpT ensemble, 3536
MC NVT ensemble, 3234
MC μVT ensemble, 3637
MD NVE ensemble, 3032
particle dynamics, 3947
properties from fluctuations, 2430
statistical mechanics, ensembles, and
averaging, 2024
simple thermodynamic averages, 2224
Thermodynamic properties of argon, 125
Thermodynamic relationships, 393394
Thermodynamic scaling, 380382
MC method, 380381
temperature and density MC, 380381
thermodynamic-scaling Gibbs ensemble
MC, 381382
Thermostat, 285286
Third-order perturbation theory, 56, 150
Third-order triple term, 150
Third-order triple-dipole term, 131132
Thomas tridiagonal algorithm, 194195
solution of field equations in one dimension
using, 194b
threadIndex.x (index of threads within block),
531
Three-dimensional map of cells and nearest
neighbors, 175b
3 N EulerLagrange equations, 264
Threebody interactions, 11, 130143, 149.
See also AxilrodTellerMut¯o
(ATM)
case study, 152155
efficient three-body calculations,
153155
systematic improvement of water
potentials, 152153
density-dependent effective three-body
potential, 135136
multipolar contributions beyond triple￾dipole term, 136139
three-body ab initio potentials, 152
three-body dispersion, 131132
triplet configuration of atoms, 132f
three-body dispersion vs. three-body
repulsion, 140143
comparison of contributions of ATM,
143f
illustration of dimer geometry, 147f
ratio of repulsion to triple-dipole
interactions, 142f
three-body molecular potentials, 145, 149f
three-body repulsion, 139140
triple-dipole term and ATM potential,
132135
Time-scaled coordinates, 247249
Time-scaled variables, gear corrector
coefficients kd for second-order
equation using, 246t
TIP4P. See Transferable intermolecular
potential 4-point (TIP4P)
Total configurational chemical potential,
2324
Total energy, 22
Total external force, 39
Total potential energy, 312, 327
Transferable intermolecular potential 4-point
(TIP4P), 98100
Transferable potentials for phase equilibria
(TraPPE), 96
Transition probability matrix, 217
Transport coefficients, 2829
diffusion, 2829
shear viscosity, 29
thermal conductivity, 29
Transport properties
596 Indexcalculation, 286
of fluid mixtures, 301
Trapezoid-corrector yields, 375
TraPPE. See Transferable potentials for phase
equilibria (TraPPE)
Tree algorithms, 205
Tree-based methods, 197205
BarnesHut algorithm, 197200
FMM, 200205
Triangular shaped cloud (TSC), 196
Triangular well potential, 60
Triatomic molecules, 145147, 264
Triple-dipole potential, 132133
for nonspherical molecules, 147148
Triple-dipole term, 132135
multipolar contributions beyond, 136139
TSC. See Triangular shaped cloud (TSC)
Two-body ab initio molecular potentials,
144147
diatomic molecules, 145
polyatomic molecules, 147
triatomic molecules, 145147
Two-body potentials, 130. See also
Intermolecular pair potentials
Two-body SAAP parameters, 129t
Two-dimensional cell, 174176
Two-dimensional fluids, 60
Two-dimensional particle distribution,
division of space for, 199f
Two-phase method, 359360
Twobody atomic potentials, 123130.
See also Intermolecular pair potentials
Ab initio potentials, 125130
case study, 152155
empirical potentials, 123125
U
UFF. See Universal force field (UFF)
Umbrella sampling, 360
UML. See Unified modeling language (UML)
Unconstrained particles motion, 39
Unified modeling language (UML), 407410
diagram
aggregation relationship between
Molecule and Atom, 411f
association between Atom and
Intermolecular_Potential, 413f
combined use of inheritance and
aggregation, 412f
different levels of aggregation, 411f
notation for inheritance, 410f
notation, 571
Universal force field (UFF), 9394
UreyBradley potential, 8384
V
Vaporliquid equilibria (VLE), 59, 62, 68,
125, 359, 373
of hydrocarbon mixtures, 366
Velocity scaling, 332
Velocity-scaled microcanonical ensemble
algorithm, 331332
Velocity-Verlet algorithm, 254256, 279, 332
for integrating equations of motion, 255b
Verlet algorithm, 67, 244245, 250251,
258, 261262, 271272, 279.
See also Integrators
Verlet list, 179180
Verlet neighbor list, creation of, 171b
Verlet predictor methods, 250258
Beeman modification, 256258
leap-frog Verlet algorithm, 253254
original Verlet algorithm, 251252
velocity-Verlet algorithm, 254256
Verlet-based implementation of shake
algorithm, 271272
Very FMM (VFMM), 204205
VFMM. See Very FMM (VFMM)
Virial theorem, 22, 47, 386
Virtual displacement, 41
Viscosity, 292
VLE. See Vaporliquid equilibria (VLE)
W
Water, 8, 52, 296297
models for, 97101
flexible models, 100
polarizable models, 100101
rigid models, 97100
systematic improvement of water potentials,
152153
WCA. See WeeksChandlerAnderson
potential (WCA)
WeeksChandlerAnderson potential
(WCA), 58
WCA 1 finitely extensible nonlinear elastic
potential, 8788
Widom test particle method, 361
Wolf approximation of Ewald sum, 186187
X
Xenon, 124, 141
Y
Yukawa potential, 6061
Index 597
