MODERN SPACECRAFT
GUIDANCE,
NAVIGATION, AND
CONTROLThis page intentionally left blankMODERN SPACECRAFT
GUIDANCE,
NAVIGATION, AND
CONTROL
FROM SYSTEM MODELING TO AI AND
INNOVATIVE APPLICATIONS
Edited by
VINCENZO PESCE
Airbus D&S, Advanced Studies Department, Toulouse, France
ANDREA COLAGROSSI
Politecnico di Milano, Aerospace Science and Technology
Department, Milan, Italy
STEFANO SILVESTRINI
Politecnico di Milano, Aerospace Science and Technology
Department, Milan, ItalyElsevier
Radarweg 29, PO Box 211, 1000 AE Amsterdam, Netherlands
The Boulevard, Langford Lane, Kidlington, Oxford OX5 1GB, United Kingdom
50 Hampshire Street, 5th Floor, Cambridge, MA 02139, United States
Copyright  2023 Elsevier Inc. All rights reserved.
No part of this publication may be reproduced or transmitted in any form or by any
means, electronic or mechanical, including photocopying, recording, or any information
storage and retrieval system, without permission in writing from the publisher. Details on
how to seek permission, further information about the Publisher’s permissions policies
and our arrangements with organizations such as the Copyright Clearance Center and the
Copyright Licensing Agency, can be found at our website: www.elsevier.com/permissions.
This book and the individual contributions contained in it are protected under copyright
by the Publisher (other than as may be noted herein).
Notices
Knowledge and best practice in this field are constantly changing. As new research and
experience broaden our understanding, changes in research methods, professional
practices, or medical treatment may become necessary.
Practitioners and researchers must always rely on their own experience and knowledge in
evaluating and using any information, methods, compounds, or experiments described
herein. In using such information or methods they should be mindful of their own safety
and the safety of others, including parties for whom they have a professional
responsibility.
To the fullest extent of the law, neither the Publisher nor the authors, contributors, or
editors, assume any liability for any injury and/or damage to persons or property as a
matter of products liability, negligence or otherwise, or from any use or operation of any
methods, products, instructions, or ideas contained in the material herein.
ISBN: 978-0-323-90916-7
For information on all Elsevier publications visit our website
at https://www.elsevier.com/books-and-journals
Publisher: Matthew Deans
Acquisitions Editor: Chiara Giglio
Editorial Project Manager: Sara Greco
Production Project Manager: Surya Narayanan Jayachandran
Cover Designer: Christian J. Bilbow
Typeset by TNQ TechnologiesContents
List of contributors xi
Biography xiii
PART 0 Introduction
1. Introduction 3
Vincenzo Pesce, Andrea Colagrossi and Stefano Silvestrini
Modern spacecraft GNC: what, why, how, for whom? 3
A brief historical review of classical spacecraft GNC 10
GNC terminology 13
GNC architecture: from requirements to preliminary design 15
Notation rules 38
References 42
PART 1 Fundamental GNC tools
2. Reference systems and planetary models 45
Andrea Colagrossi, Stefano Silvestrini and Vincenzo Pesce
Earth and planetary models 46
Coordinate reference systems 53
Coordinate transformations 63
Time 69
What is relevant for GNC? 73
References 75
3. The space environment 77
Andrea Capannolo, Emanuele Paolini, Andrea Colagrossi, Vincenzo Pesce
and Stefano Silvestrini
Perturbation sources 78
External perturbations 79
External perturbations modeling guidelines 97
Internal perturbations 100
Internal perturbations modeling guidelines 123
What is relevant for GNC? 124
References 126
v j4. Orbital dynamics 131
Andrea Capannolo, Stefano Silvestrini, Andrea Colagrossi and
Vincenzo Pesce
Two-body problem 132
Three-body problem 161
Irregular solar system bodies 170
Relative orbital dynamics 174
References 204
5. Attitude dynamics 207
Aureliano Rivolta, Andrea Colagrossi, Vincenzo Pesce and
Stefano Silvestrini
Attitude kinematics 208
Attitude dynamics 227
Three-body problem attitude dynamics 248
Relative attitude dynamics 249
Multibody spacecraft dynamics 250
References 252
6. Sensors 253
Andrea Colagrossi, Vincenzo Pesce, Stefano Silvestrini,
David Gonzalez-Arjona, Pablo Hermosin and Matteo Battilana
Sensor modeling for GNC 254
Sensor faults 275
Orbit sensors 276
Attitude sensors 286
Inertial sensors 306
Electro-optical sensors 322
Altimeters 330
References 334
7. Actuators 337
Andrea Colagrossi, Lisa Whittle, Vincenzo Pesce, Stefano Silvestrini and
Matteo Battilana
Actuator modeling for GNC 338
Thrusters 344
Reaction wheels 354
Control moment gyros 366
Magnetorquers 369
References 375
vi ContentsPART 2 Spacecraft GNC
8. Guidance 381
Thomas Peters, Stefano Silvestrini, Andrea Colagrossi and Vincenzo Pesce
What is guidance? 381
On-board versus ground-based guidance 382
Guidance applications 385
Guidance implementation best practices 438
References 438
9. Navigation 441
Vincenzo Pesce, Pablo Hermosin, Aureliano Rivolta, Shyam Bhaskaran,
Stefano Silvestrini and Andrea Colagrossi
What is navigation? 441
On-board versus ground-based navigation 443
Sequential filters 445
Batch estimation 461
Absolute orbit navigation 470
Absolute attitude navigation 488
Relative navigation 504
Image processing techniques 507
Navigation budgets 528
Navigation implementation best practices 533
References 540
10. Control 543
Francesco Cavenago, Aureliano Rivolta, Emanuele Paolini,
Francesco Sanfedino, Andrea Colagrossi, Stefano Silvestrini and
Vincenzo Pesce
What is control? 543
Control design 545
Review of control methods 592
Control budgets 618
Control implementation best practices 626
References 629
11. FDIR development approaches in space systems 631
Massimo Tipaldi, Stefano Silvestrini, Vincenzo Pesce and Andrea Colagrossi
FDIR in space missions, terms, and definitions 633
Current FDIR system development process and industrial practices 637
Contents viiFDIR system hierarchical architecture and operational concepts 639
FDIR system implementation in European Space missions 641
FDIR system verification and validation approach 642
FDIR concept and functional architecture in GNC applications: a short overview 642
References 645
12. GNC verification and validation 647
Francesco Pace, Emanuele Paolini, Francesco Sanfedino, Daniel Alazard,
Andrea Colagrossi, Vincenzo Pesce and Stefano Silvestrini
Why it is important? 648
Statistical methods 652
MIL test 656
SIL/PIL test 667
HIL test 677
In-orbit test 682
References 683
13. On-board implementation 685
David Gonzalez-Arjona, Vincenzo Pesce, Andrea Colagrossi and
Stefano Silvestrini
Spacecraft avionics 686
On-board processing avionics 694
On-board implementation alternatives 700
On-board implementation and verification 705
References 711
PART 3 AI and modern applications
14. Applicative GNC cases and examples 715
Stefano Silvestrini, Andrea Colagrossi, Emanuele Paolini,
Aureliano Rivolta, Andrea Capannolo, Vincenzo Pesce, Shyam Bhaskaran,
Francesco Sanfedino and Daniel Alazard
AOCS design 717
Orbital control system 730
Attitude control system 742
Relative GNC 775
On-board sensor processing 791
viii ContentsIrregular solar system bodies fly around 803
GNC for planetary landing 806
References 814
15. Modern Spacecraft GNC 819
Stefano Silvestrini, Lorenzo Pasqualetto Cassinis, Robert Hinz,
David Gonzalez-Arjona, Massimo Tipaldi, Pierluigi Visconti, Filippo Corradino,
Vincenzo Pesce and Andrea Colagrossi
AI in spacedIntroduction 821
Artificial intelligence and navigation 867
Validation of AI-based systems 883
Reinforcement learning 890
AI use cases 906
AI on-board processors 923
Innovative techniques for highly autonomous FDIR in GNC applications 925
Small satellites/CubeSats 938
References 971
Further reading 981
16. Mathematical and geometrical rules 983
Andrea Capannolo, Aureliano Rivolta, Andrea Colagrossi,
Vincenzo Pesce and Stefano Silvestrini
Matrix algebra 983
Vector identities 991
Quaternion algebra 994
Basics of statistics 1000
ECI-ECEF transformation 1002
References 1006
17. Dynamical systems theory 1007
Francesco Cavenago, Andrea Colagrossi, Stefano Silvestrini and
Vincenzo Pesce
State-space models 1007
Discrete-time systems 1009
Transfer functions 1011
References 1015
Contents ix18. Autocoding best practices 1017
Francesco Pace, Vincenzo Pesce, Andrea Colagrossi and
Stefano Silvestrini
List of main architectural and implementation rules 1017
Reference 1026
Index 1027
x ContentsList of contributors
Daniel Alazard
ISAE-SUPAERO, Toulouse, France
Matteo Battilana
OHB Italia S.p.A., Milan, Italy
Shyam Bhaskaran
NASA Jet Propulsion Laboratory, Pasadena, CA, United States
Andrea Capannolo
Politecnico di Milano, Milan, Italy
Lorenzo Pasqualetto Cassinis
TU Delft, Delft, the Netherlands
Francesco Cavenago
Leonardo, Milan, Italy
Andrea Colagrossi
Politecnico di Milano, Milan, Italy; Airbus D&S Advanced Studies, Toulouse, France
Filippo Corradino
Tyvak International, Turin, Italy
David Gonzalez-Arjona
GMV Aerospace & Defence, Madrid, Spain
Pablo Hermosin
Deimos Space, Madrid, Spain
Robert Hinz
Deimos Space, Madrid, Spain
Francesco Pace
GMV Aerospace & Defence, Madrid, Spain
Emanuele Paolini
D-Orbit, Fino Mornasco, Italy
Vincenzo Pesce
Airbus D&S Advanced Studies, Toulouse, France
Thomas Peters
GMV Aerospace & Defence, Madrid, Spain
Aureliano Rivolta
D-Orbit, Fino Mornasco, Italy
Francesco Sanfedino
ISAE-SUPAERO, Toulouse, France
xi jStefano Silvestrini
Politecnico di Milano, Milan, Italy
Massimo Tipaldi
University of Sannio, Benevento, Italy
Pierluigi Visconti
Tyvak International, Turin, Italy
Lisa Whittle
Asteroid Exploration, Leiden, the Netherlands
xii List of contributorsBiography
Dr. Vincenzo Pesce is a guidance, navigation, and control (GNC)
engineer at Airbus D&S Advanced Studies Department in Toulouse. Prior
to joining Airbus, he worked for GMV, Spain. He holds a PhD in Aerospace
Engineering from Politecnico di Milano with a thesis titled “Autonomous
Navigation for Close Proximity Operations around Uncooperative Space
Objects.” During his studies, he spent a research period at NASAdJet
Propulsion Laboratory (2017) and at the University of Florida (2015). He
is author or coauthor of about 30 scientific publications on GNC, autono￾mous navigation, small-body exploration, and microgravity experiments in
international journals and conference proceedings. He received the
prestigious Leonardo Committee Graduation Award and the Guido Horn
D’Arturo Award for his research on vision-based autonomous navigation.
He has been involved in several international projects in collaboration
with European companies and agencies. Recently, he has been working
on the development of GNC algorithms for the Mars Sample Return
mission and for the ESA’s European Large Logistics Lander project. His cur￾rent research interests include autonomous GNC for proximity operations,
rendezvous and landing, vision-based navigation, and GNC innovative
methods.
Dr. Andrea Colagrossi is an assistant professor of flight mechanics at
the Aerospace Science and Technology Department of Politecnico di
Milano. He holds a PhD in Aerospace Engineering with a thesis on “Abso￾lute and Relative 6DOF Dynamics, Guidance and Control for Large Space
Structures in Cislunar Environment.” He earned his MSc degree in Space
Engineering in 2015 from Politecnico di Milano, with a double degree
from Politecnico di Torino. In 2012, he obtained his BSc degree in Aero￾space Engineering at Politecnico di Torino. He was a visiting researcher at
Deimos Space (Spain) and Purdue University (Indiana, USA). He has
been involved in several national and international-funded projects, collab￾orating with Italian and European companies, institutions, and agencies,
working on development studies about GNC for modern applications,
such as nanosat constellations for astrophysical observations, rendezvous in
cislunar environment, and proximity operations for active debris removal.
He is author and coauthor of about 30 scientific publications in international
journals and conference proceedings on GNC, small space systems, and
non-Keplerian dynamics. His main research interests are spacecraft GNC
xiii jand system engineering for advanced small satellite applications, with a focus
on effective GNC implementation with limited hardware resources, inno￾vative GNC techniques, and autonomous failure and contingency modes
management.
Dr. Stefano Silvestrini is a postdoctoral researcher at the Aerospace
Science and Technology Department of Politecnico di Milano. He obtained
his PhD cum laude with a thesis titled “AI-augmented Guidance, Naviga￾tion and Control for Proximity Operations of Distributed Systems.” He
earned his MSc degree in Aerospace Engineering in 2017 from TU Delft.
In 2016, he worked as a trainee for Airbus D&S in Munich. In 2015, he
earned his BSc degree in Aerospace Engineering at the Universita degli Studi
di Padova. During his BSc, he spent a six-month research period at the Col￾lege of Aerospace Engineering of Boston University under awarded schol￾arship. He has been involved in national and EU/ESA-funded projects for
developing nanosat constellation for science observation, mission analysis,
and system design for fractionated space architecture and artificial intelli￾gence (AI) for spacecraft GNC. He has worked as a teaching assistant for
several courses throughout his MSc and PhD career. His research interests
include the development of AI algorithms for autonomous GNC in distrib￾uted space systems and proximity operations, particularly tailored for
embedded applications in small platforms.
xiv BiographyPART 0
Introduction
1jThis page intentionally left blankCHAPTER ONE
Introduction
Vincenzo Pesce1
, Andrea Colagrossi2
, Stefano Silvestrini2
1
Airbus D&S Advanced Studies, Toulouse, France
2
Politecnico di Milano, Milan, Italy
Modern spacecraft GNC: what, why, how, for whom?
Ever since the beginning of human existence, humans had to rely on
basic tools, or simply on their intuition, to “guide” themselves throughout
their habitat, developing instrument to “determine their location” and to
“act” accordingly. The concept of Guidance, Navigation, and Control
(GNC), even if in a different fashion, was familiar to the first nomadic tribes
and to the following pioneers of human exploration. Still, it is true that
everyone approached the GNC problem in his own life, by simply going
outside home and walking.
Spaceflight has been one of the most revolutionary shades of human
exploration, allowing men and automated vehicles to escape Earth’s gravity,
turning imagination and wonder into reality. The technology of satellites
and space vehicles has rapidly evolved since the first signal received from
the Sputnik 1 (Спутник 1) or the first awe-inspiring images from the
Moon surface, becoming now capable to land man-made objects on planets,
comets, and asteroids, or to deploy constellations of orbiting bodies, or to
make two spacecraft encounter while traveling thousands of kilometers
per second.
In performing all these activities, one of the original problems of human￾ity came back under a new perspective: spacecraft GNC. Even in space, one
needs to know the path, the current location, and the steps to stay on the
right track. In these regards, spacecraft GNC has followed a quick techno￾logical evolution, drawing inspiration from the first Earth-based methods,
such as sextants, chronometers, and landmarks, to rapidly evolve acquiring
the peculiarities of the space environment. Then, with the arising of power￾ful computers and advanced techniques, this branch of spacecraft technology
made giant leaps toward autonomy and high performances. Nowadays, it is
at the dawn of a new era, with artificially intelligent machines starting to
help space explorers to travel across the solar system.
Modern Spacecraft Guidance, Navigation, and Control
ISBN: 978-0-323-90916-7
https://doi.org/10.1016/B978-0-323-90916-7.00001-9
© 2023 Elsevier Inc.
All rights reserved. 3 jThis book aims at presenting an updated and comprehensive set of the￾ory and applications about spacecraft GNC, from fundamentals to advanced
concepts, including modern artificial intelligence (AI)-based architectures,
with focus on software and hardware practical applications. In fact, one of
the main purposes of this book is to discuss updated GNC design and vali￾dation processes, from requirements to final system implementation. This
book is focused on delivering a coherent path to design a spacecraft GNC
system, starting from theory and digging the critical steps toward implemen￾tation. In other words, the book is intended to provide the necessary theory,
omitting redundant derivations, already present in literature, from the spe￾cific perspective of spacecraft systems.
The topics discussed in the book are typically found scattered in a vast
pool of literature; or they are limited to academic theoretical manuals, which
have been published quite few years ago; or they are available from docu￾mentation and technical notes, retrieved from international standards, which
are not easy to be understood maintaining a general overlook on the whole
problem. Moreover, GNC is typically regarded as the convergence of the
three individual entities: Guidance, Navigation, and Control. This is
partially valid; nevertheless, a holistic approach in the design of the system
is lacking in book-type literature.
The book starts from a revision of the basic tools and theoretical back￾ground required to understand how a spacecraft moves in space and what
are the elements a GNC system requires to be operative. Then, the main
GNC blocks are introduced, describing their role within the overall
ensemble, and explaining some theoretical foundations to understand the
methods and technologies of spacecraft GNC. The discussion begins from
the basic knowledge needed to understand the GNC system design process,
and it is integrated with the steps driving from the requirements to the sys￾tem implementation and verification. Finally, spacecraft GNC applications
and examples are discussed, together with a broad survey on modern tech￾niques, methods, and scenario, including an extensive chapter on the role of
AI in modern spacecraft GNC.
This book does not want to provide an in-depth theoretical description
of GNC foundations, but it offers a unique perspective on design and veri￾fication processes, practical applications, and novel, cutting-edge,
techniques.
A unique text to understand the fundamentals of modern spacecraft
GNC design, from theory to applications, which can guide both students,
young professionals, and experts, is currently missing. The practical and
4 Vincenzo Pesce et al.applicative focus of the book makes is appealing to junior and graduate aero￾space engineers. Moreover, the discussion on modern and advance tech￾niques should make it a reference updated handbook. In fact, spacecraft
system engineers and attitude and orbit control system (AOCS)/GNC spe￾cialists may want to use it to be updated on the latest promising
advancements.
In summary, the book may address different categories of readers: devel￾opers, researchers, young professionals, Ph.D. students, designers in the field
of spacecraft GNC; AOCS and system engineers; Assembly Integration and
Verification/ Assembly Integration and Test (AIV/AIT) technicians; profes￾sionals in the field of estimation and control sciences who want to approach
the space sector; experts who are looking for an updated discussion on mod￾ern problems and applications.
Book content
Following this introductory part, the book has three main parts plus an ap￾pendix section.
The first Part 1 e Basic Tools offers an overview of the main theoretical
and fundamental concepts supporting spacecraft GNC. In particular, the
used reference systems and planetary models are detailed along with the
most important elements of the space environment. An overview of the
main orbital and attitude dynamical models is provided. Subsequently,
sensors and actuators are described, with particular focus on common
GNC-related issues and on the most relevant modeling principles. With
more details:
Reference Systems and Planetary Models contains the models to describe
planetary geometry, with a brief introduction to position representation
methods; the main coordinate reference systems; the methods to transform
the coordinates from one reference system to another one; the primary time
conventions and scales, including the concept of Julian dates; a final section
summarizing the most relevant aspects for the GNC system.
The Space Environment chapter describes the main perturbation sources
influencing the spacecraft dynamics, dividing between external perturba￾tions (i.e., nonspherical gravitational, magnetic field, atmospheric drag, solar
radiation pressure, and third-body) and internal ones (i.e., flexibility and
sloshing, electromagnetic disturbances, internal vibrations, thermal snap,
parasitic forces and torques due to thruster firing and plume impingement);
the main guidelines to model the perturbation contributions; the concepts
relating external and internal perturbations with the GNC design.
Introduction 5The chapter on Orbital Dynamics introduces the two-body problem and
the three-body problem, with the most useful elements for a GNC engi￾neer; the gravitational environment around irregular solar system bodies;
the relative orbital dynamics.
The Attitude Dynamics chapter presents the fundamental rules and
methods to deal with attitude kinematics; attitude dynamics, including a dis￾cussion on the inertia properties of the spacecraft and on the main equations
to deal with significant attitude motions; relative attitude dynamics; multi￾body spacecraft dynamics.
The chapter about Sensors discusses the main sensor modeling concepts
for spacecraft GNC, including some elements of metrology, and the basic
principles about statistics and random variables; orbit sensors; attitude sen￾sors, inertial sensors; electro-optical sensors; altimeters.
The chapter about Actuators discusses the main actuator modeling prin￾ciples for spacecraft GNC; thrusters; reaction wheels; control moment gyros;
magnetorquers.
Part 2 e Spacecraft GNC represents the core of the book, in which the
main techniques and methods for spacecraft GNC are presented and deeply
analyzed. Fault detection isolation and recovery methods, GNC verification
and validation tools, and on-board practical implementation are detailed
with particular emphasis. Specifically:
The Guidance chapter contains the different implementation philoso￾phies of on-board and ground-based guidance, the formal discriminant be￾tween AOCS and GNC systems; the guidance system design process,
including two applicative cases of rendezvous guidance and attitude guid￾ance; the most relevant guidance implementation best practices.
The Navigation chapter describes the main navigation filtering tech￾niques, including sequential and batch filters; absolute orbit navigation,
including the basics of GNSS, pulsars, ground-based orbit determination
techniques; absolute attitude navigation; relative navigation; image process￾ing techniques; the influence of navigation budgets on the overall GNC
chain; the most relevant navigation implementation best practices.
The Control chapter discusses the control design process, including both
the design in the state space and in the frequency domain; an introduction to
nonlinear control design; Proportional-Integral-Derivative control
methods; Linear Quadratic Regulator methods; robust control fundamen￾tals, including Model Predictive Control and Sliding Mode Control; the
control budgets; the most relevant control implementation best practices.
6 Vincenzo Pesce et al.The chapter about FDIR Development Approaches in Space Systems presents
technical solutions and industrial processes used by the space engineers to
design, develop, test, and operate health management systems, also known
as Failure Detection, Isolation, and Recovery (FDIR) systems.
The GNC Verification and Validation chapter introduces the main indus￾trial process to verify and validate a GNC system, including Model-in-the￾Loop, Software-in-the-Loop, Processor-in-the-Loop, Hardware-in-the￾Loop, In-Orbit testing activities.
The On-board Implementation chapter presents a brief overview on the
final implementation of the GNC algorithms and functions in the on￾board avionics’ modules, with the associated data interfaces; the main tech￾nologies for modern processing devices, such as general-purpose Processors/
Microcontrollers, Digital Signal Processors, Graphical Processing Units,
Field Programmable Gate Array, or specific ad-hoc electronic circuits.
The last main Part 3 e AI and Modern Applications introduces the most
advanced solutions for spacecraft GNC. The fundamentals of AI theory
and some cutting-edge spacecraft GNC applications are described in this
part. A strong focus to the space environment is imposed, and the main al￾gorithms that can benefit from AI or other modern computing techniques
are considered, without an extensive, general treatment as a classical AI or
computer science textbook. This part is different from a generic AI or com￾puter science book to stress only the peculiar algorithms and aspects of mod￾ern spacecraft GNC that are applicable in the space context. In particular:
The Applicative GNC Cases and Examples chapter presents a set of appli￾cative GNC examples and use cases covering the topics of GNC that are of
relevance for practical and modern applications. It contains examples on
AOCS design; orbital control systems; attitude control systems; relative
GNC; on-board sensor processing; irregular solar system bodies fly around;
planetary landing.
The Modern Spacecraft GNC chapter gives an overview on modern GNC
techniques and methods, including an overview on AI techniques for space￾craft, on the innovative methods for GNC FDIR, and on the emerging
topic of CubeSats and nanosatellites. It contains an introduction to AI in
space; AI techniques for spacecraft navigation; validation of AI-based sys￾tems; reinforcement learning; AI use cases; AI on-board processors; innova￾tive techniques for highly autonomous FDIR systems; small satellites and
CubeSats GNC.
Introduction 7Finally, an appendix section provides a summary of the fundamentals of
mathematical and geometrical rules; dynamical systems theory; Automated
Code Generation (ACG) or autocoding.
How to use the book?
This book is intended to cover the entire spacecraft GNC domain, with the
most updated developments, trying not to leave any concept or application
unexplored. However, the topics cannot be treated with the finest details of
a specialized book. Thus, the book presents the main tools and methods to
deal with the covered contents and support the discussion with several liter￾ature references to further explore the topics. The reader should either have
a sufficient theoretical background on the matter, or it should deepen and
review those concepts that are not completely clear after a first reading of
the book content.
The book is designed and structured to support the practical work and
the daily life of modern spacecraft GNC/AOCS engineers, aerospace engi￾neers, avionic developers, and AIV/AIT technicians. Thus, it can be used as
a handbook, without the need of reading it from the beginning to the end.
The applicative examples and the modern GNC presented in Part 3 are sup￾ported by the fundamentals of spacecraft GNC discussed in Part 2, which are
developed starting from the basic tools introduced in Part 1. Hence, reading
it bottom-up can be useful for an experienced GNC engineer who want to
update his knowledge, while a student or a young professional is suggested
to read it following the normal flow.
Most of the chapters in Part 1 and Part 2 are enriched with sections dedi￾cated in summarizing the chapter’s aspects relevant for GNC applications or
to list tips and best practices to design and practically implement the GNC
functions into the spacecraft system. Similarly, some modeling guidelines are
clearly outlined to better support the GNC design process. The chapters
about FDIR systems, verification and validation processes, and on-board
implementation are self-contained, and they should be used to have a clear
preliminary overview on these important concepts, often overlooked in
classical textbooks about spacecraft GNC.
Part 3 contains diverse and various applicative and modern concepts,
spanning the entire applicative spectrum of spacecraft GNC. Thus, it is not
uncommon that the different sections of this part belong to different domains
and have a broad variety of terminology and theoretical concepts. Thus, Part
3 could be read considering each section as an autonomous block, performing
the necessary links to the previous parts and to the appendices of the book.
8 Vincenzo Pesce et al.What is not contained in this book?
The book is intended to be a practical and useful support to the work and to
the knowledge of spacecraft GNC/AOCS engineers, aerospace engineers,
avionic developers, and AIV/AIT technicians. Thus, it is not designed to
provide all the basic and theoretical concepts behind each of the covered
contents. Moreover, the reader is expected to have a solid knowledge on
mathematics, physics, dynamics, and basics of space systems.
The description of orbital and attitude dynamics is constrained to the
most relevant aspects useful for the GNC design. Consequently, few topics
about orbit and attitude dynamics have been omitted, mainly because of
length restrictions. All the landmarks and milestones of the GNC design
and verification are included, but the details are sometimes just hinted in or￾der to avoid a lengthy and cumbersome discussion that would not fit with
the handbook purposes of this book. In all these cases, invitation for the
reader to deepen those aspects on existing literature references is included.
The book does not contain extensive discussion on theoretical aspects of
spacecraft dynamics and environment modeling. Furthermore, it overlooks
the theoretical details on sensors and actuators, focusing more on the prac￾tical aspects about their integration in the GNC design (e.g., calibration,
testing, and numerical modeling). In other words, in this book, environ￾mental terms, dynamical equations, sensors and actuators are more intended
as mathematical models, rather than as the physical principles they represent.
The GNC description directly applies the methods to the spacecraft
design; hence, no extensive discussion about general GNC methods is
included. Moreover, mathematical derivations and proofs are limited to
those cases where they are directly applicable in the design and verification
processes.
The example and applicative cases are limited to those with interest in
present and future mission scenario. Moreover, the focus is dedicated to
modern applications that are somehow less common in classic literature
about spacecraft GNC. Even in this case, proper references to classic litera￾ture examples are included. The AI section only considers techniques and
methodologies that are more consolidated in spacecraft GNC design. As
already said, AI is specifically limited to spacecraft GNC; thus, an extensive,
general treatment as a classical AI textbook is not contained in this book.
Furthermore, given the close relation to research aspects, some details on
the most innovative applications are given, highlighting their current devel￾opment status and their applicative limitations.
Introduction 9The list of covered applications is obviously not exhaustive, but contains
those examples that are deemed to be more relevant for the modern chal￾lenges faced, on a day-by-day basis, by the spacecraft GNC engineers.
The editors apologize from now for any missing content the reader would
have desired to find in this book; the interested reader is invited to contact
them to directly ask for specific suggestions on how to find and deepen its
knowledge about the missing topics.
A brief historical review of classical spacecraft GNC
Despite the concepts of GNC are intrinsic with the human move￾ments across the globe, the true ancestor of spacecraft GNC is the ancient
mariner, who had to explore the world by guiding, navigating, and control￾ling the motion of an artificial object through a vast environment, still un￾explored, without references and landmarks. Indeed, to master the art of
driving a ship across the sea, humans outlined fundamental concepts,
invented methods and tools that are nowadays still applicable to the whole
field of GNC. Three thousand years ago, Polynesians and Phoenicians mar￾iners were capable to sail on the high seas, and ever since the humans have
been developing celestial navigation, compass bearing, landmark ranging,
route tracing, and so on. They also invented a variety of instruments and
methods to accomplish these tasks. The first magnetic compass used in nav￾igation applications is dated back to the 11th century, the mariner’s astrolabe
to the 14th century, the marine chronometer and the sextant to the 17th and
18th century. Similarly, the rhumb line or loxodrome navigation method
was formulated and applied in the 16th century. Moreover, also the etymol￾ogy of the word “navigation” belongs to the sea and to the mariners: it was
first used in the 1530s, from Latin “navigationem,” which derives from
“navigatus” meaning “to sail, sail over, go by sea, steer a ship,” from “navis”
(i.e., ship) and the root of “agere” (i.e., to drive). Note how at that time, and
sometimes also in present days, the word navigation was encompassing the
entire GNC definition.
The direct evolution of maritime navigation (i.e., maritime GNC) was
the aircraft GNC, which shared several common elements with his progen￾itor. Indeed, airplanes move in vast regions following routes by means of
navigation instruments and control systems, such as the pilot or the auto￾pilot. In fact, as for the ships, the first aircrafts were controlled by men,
who read the information of on-board instruments (e.g., altimeter, compass,
attitude indicator, etc.) to follow the path they computed before the take￾10 Vincenzo Pesce et al.off. Namely, the first aircraft GNC was human in the loop. A very similar
evolution happened in space for spacecraft GNC.
As obvious, spacecraft moving in space share most of the fundamental
characteristics with the ships and airplanes traveling across the seas and in
the skies, even though the orbital conditions are even more harsh and diffi￾cult. The first spacecraft were indeed only passively controlled: launched
into ballistic trajectories (i.e., the natural orbits) and with passive rotational
stabilization. The first man-made object orbiting around the Earth was
the Sputnik 1, launched by the Soviet Union on the fourth of October
1957. It was a simple polished metal sphere with a diameter of 58 cm, but
it had no orbital and attitude control capabilities. The first American satellite
was the Explorer 1, launched on the first of February 1958. It had not orbital
control, and its rotational state was designed to spin the spacecraft around its
elongated axis to achieve a passive attitude stabilization. However, soon after
the release, the spacecraft entered in a flat spin dynamics, an undesirable rota￾tion about an axis perpendicular to the preferred axis. Later it was discovered
that this was due to energy dissipation from flexible structural elements, and
this small accident motivated further developments of the theory of rigid
body dynamics after nearly 200 years from the first Eulerian formulation.
The spacecraft dynamics was not completely understood yet to correctly
develop a GNC system.
The unmanned Luna-3 soviet space probe, which took pictures of the far
side of the Moon in 1959, was the first guided spacecraft, having a very basic
attitude control system. It was spin-stabilized for most of its flight, but its
three-axis attitude control system was activated while taking photos. How￾ever, the need to control the spacecraft motion increased with the advent of
manned spacecraft and more complex orbital operations.
The first human in space was the Soviet cosmonaut Yuri Gagarin,
launched with a Vostok 1 on the April 12, 1961. Despite he was a trained
air force pilot, carefully selected to accomplish his task, the mission was
designed to be automatically controlled or controlled from ground. In
fact, the medical doctors were not sure how a human might react to space
environment, and therefore it was decided to lock the pilot’s manual con￾trols. This primitive spacecraft control system was only partially trusted by
the spacecraft engineers themselves, and thus a code to unlock the controls
was placed in an on-board envelope to be used in case of emergency. The
code was “1-2-5,” and Gagarin was anyway told about it before launch.
Anyhow, this sun-seeking attitude control system, inherited from the
Luna-3 mission, was correctly activated at 06:51 UTC to orient the Vostok
Introduction 111 for retrofire. The manual emergency back-up was not needed, and the
cold nitrogen gas thruster systems were automatically controlled.
Soon after Gagarin, the United States launched into orbit the astronaut
Alan Shepard, on-board the Freedom 7 spacecraft, belonging to the project
Mercury. The launch date was the fifth of May 1961, and, after the launcher
separation, the automated attitude control system (i.e., Automatic Stabiliza￾tion Control System) damped out any residual tumbling motion. Then, it
steered the spacecraft around 180 degrees, so the retrorockets would face
forward, ready for firing. Soon after that, Shepard began manually control￾ling the spacecraft’s orientation. For redundancy purposes, the Mercury
spacecraft’s manual and automatic attitude control systems used a different
set of control jets, and they had individual fuel supplies. When Shepard
piloted the spacecraft, moving the three-axis control stick, he proportionally
opened the valves of the manual jets. The system could be selectively
enabled on each axis, with the automatic control taking the lead on the non￾enabled axes. Shepard gradually assumed manual control, one axis at a time.
At first, he took manual control of pitch, reorienting the spacecraft from its
“orbit attitude” of 14 degrees nose-down pitch to the “retrofire attitude” of
34 degrees nose-down pitch, then returning to orbit attitude. He then took
manual control of yaw along with pitch, yawing the spacecraft to the left and
then to the right to bring it back in line. Finally, he assumed control of the
roll axis as well, testing it and then restoring the spacecraft’s roll to normal.
Once Shepard had taken control of all three axes, he found that the space￾craft’s manual response was about the same as that of the Mercury simulator
[1]. Already then, the importance of setting up a proper design, verification,
and testing simulator was evident.
The evolution curve of spacecraft design and on-orbit operations was
extremely steep, and in a short time, the spacecraft were asked to accomplish
complex tasks. The development of automated GNC systems was immedi￾ately started, to both improve the spacecraft performance and to aid the as￾tronauts to pilot the capsules. Anyway, most of the GNC capabilities were
demanded to ground or to the astronauts on-board. It is interesting to note
that until the late 1970s, the attitude estimation and navigation techniques
actually remained in a very underdeveloped state. Similarly, most of the
guidance solutions were computed on ground and telemetered to the
spacecraft.
The first orbital rendezvous between two spacecraft was accomplished
by the United States astronaut Wally Schirra on December 15, 1965. The
Gemini 6 spacecraft was maneuvered within 30 cm of the target spacecraft:
12 Vincenzo Pesce et al.the Gemini 7. The rendezvous was not finalized with docking, but the
spacecraft maintained the proximity condition for more than 20 min. The
astronaut later described the manual rendezvous with a remarkable
comment: “Somebody said . when you come to within three miles (i.e., 5 km),
you’ve rendezvoused. If anybody thinks they’ve pulled a rendezvous off at three
miles, have fun! This is when we started doing our work. I don’t think rendezvous
is over until you are stopped e completely stopped e with no relative motion between
the two vehicles, at a range of approximately 120 feet (i.e., 37 m). That’s rendez￾vous! Otherwise, it is the equivalent of a male walking down a busy main street
with plenty of traffic whizzing by and he spots a cute girl walking on the other
side. He’s going ‘Hey wait’ but she’s gone. That’s a passing glance, not a rendezvous.
Now if that same male can cut across all that traffic and nibble on that girl’s ear, now
that’s a rendezvous!”
The necessity of completely automated GNC subsystem to perform even
the most complex operations, such as rendezvous and docking, is therefore
evident. In fact, the risks and the costs of sending astronauts in space or the
extreme ground effort to support spacecraft operations make automatic
spacecraft GNC fundamental for present space applications.
Furthermore, modern spacecraft are required to accomplish these diffi￾cult tasks (e.g., rendezvous and docking, planetary and minor celestial bodies
landing, on-orbit servicing, etc.), at a distance from the Earth that makes
ground support almost impossible in real time or dramatically expensive.
Hence, nowadays, spacecraft are required to be autonomous and make cor￾rect decisions, even in the case of unexpected circumstances. Indeed, we are
currently in the epoch of autonomous and artificially intelligent spacecraft,
exploring the space on Earth orbits and beyond, and the GNC system is
crucial to guarantee this: it is the time of modern spacecraft GNC.
GNC terminology
The first terminological definitions we shall introduce are those
immediately related with the word GNC. According to the dictionary,
the GNC is a branch of engineering dealing with the “design of systems
to control the movement of vehicles.” In particular:
• Guidance is referring to the determination of the desired path (i.e., “tra￾jectory”) from the vehicle’s current location to an assigned target. It also
establishes the desired changes in velocity, rotation, and acceleration to
follow that course.
Introduction 13• Navigation is referringtothe determination, at a given instant oftime, ofthe
vehicle’s location, velocity, rotation, and angular rate (i.e., “state vector”).
• Control is referring to the manipulation of forces and torques, by means
of actuators (i.e., steering device, thrusters, etc.), needed to follow the
desired path while maintaining vehicle stability.
For what concerns space engineering terminology, different names can
be found to indicate similar subsystems, which are referred as GNC in this
book. The definition of GNC can be casted into the set of functions in
charge of targeted orbit and attitude computation, attitude and orbit deter￾mination, attitude and orbit control [2]. GNC is commonly used for the on￾board segment, when the satellite position is controlled in closed loop, for
instance, in case of rendezvous or formations flying. In the most general
terms, the GNC functions are:
• Attitude estimation, which is referred as attitude navigation or determi￾nation in this book.
• Attitude guidance.
• Attitude control.
• Orbit control.
• Orbit estimation, which is referred as orbital navigation in this book.
• Acquisition and maintenance of a safe attitude state in emergency cases
and return to nominal mission upon command.
• Real-time on-board orbital trajectory guidance and control.
• Real-time on-board relative position estimation and control, in case the
mission requires it.
AOCS is commonly used when the orbit guidance is not performed on
board, which is the case for standard low Earth orbit (LEO), medium Earth
orbit, and geostationary orbit missions. However, the GNC term can be also
used for the whole function, distributed between on-board and ground sys￾tems. The classical AOCSs considered here include the following functions:
• Attitude estimation, which is referred as attitude navigation or determi￾nation in this book.
• Attitude guidance.
• Attitude control.
• Orbit control.
• Orbit estimation, which is referred as orbital navigation in this book.
• Acquisition and maintenance of a safe attitude in emergency cases and
return to nominal mission upon command.
Within the GNC domain, one can furtherly distinguish between AOCS
and Attitude Determination Control System (ADCS). Many satellites do not
14 Vincenzo Pesce et al.have any orbit control capabilities (e.g., without propulsion subsystem);
thus, in some cases, the AOCS can be limited to the ADCS only, which
features:
• Attitude estimation/determination, which is referred as attitude naviga￾tion or determination in this book.
• Attitude guidance.
• Attitude control.
• Acquisition and maintenance of a safe attitude in emergency cases and
return to nominal mission upon command.
GNC architecture: from requirements to preliminary
design
The GNC is a complex subsystem that extensively involves hardware
and software components. Indeed, as we will see throughout the book, the
GNC system interfaces sensors (cfr. Chapter 6 e Sensors), on-board soft￾ware (cfr. Part 2 and Part 3), and actuators (cfr. Chapter 7 e Actuators).
Furthermore, many implemented algorithms or, at least, their design process
require a very good knowledge of the orbital and the physical environment
in which the spacecraft flies.
Let us systematically decompose the GNC subsystem in the so-called
GNC architecture:
• Guidance. The term refers to the generation of desired future plans to
fulfill the mission objectives. This entails the creation of reference trajec￾tories, both translational and rotational, that the spacecraft needs to
follow. The guidance module must deliver feasible trajectories based
on the spacecraft capabilities; therefore, it must take into account the
spacecraft system design, as well as the constraints and the feasibility of
the mission. Given its higher level of abstraction, descending directly
from the mission objectives, the guidance module has been reserved to
ground control for many years, nevertheless on-board guidance has
recently become prominent for innovative and daring missions. The
guidance module generally needs the output of the navigation to deliver
inputs to the control module. Such workflow shall not be intended as
dogmatic, as many different system architectures can be deployed.
Certainly, the guidance module needs to know the actual state of the
system to adjust future trajectories to the current system status. A
comprehensive description of the guidance module is presented in
Chapter 8 e Guidance.
Introduction 15• Navigation. The navigation module interfaces with the sensors. It over￾sees the sensing of the environment to deliver the best estimate of the
current state of the spacecraft, both in terms of orbital and attitude state.
The navigation entails different algorithms, which are highly dependent
on the sensor suite implemented on-board. The main task of the navi￾gation is to fuse measurements from different sensors to deliver the best
possible estimate, also based on the environment knowledge. In general,
the navigation output represents the input to the guidance and/or
control module. A comprehensive description of the navigation module
is presented in Chapter 9 e Navigation.
• Control. The control module interfaces with the actuators. It oversees the
spacecraft reaction to the environment to follow the desired trajectory,
based on the actual state of the spacecraft. It generally receives inputs
from the guidance and navigation modules. A comprehensive descrip￾tion of the control module is presented in Chapter 10 e Control.
• Sensors. The sensor suite is the ensemble of hardware in charge of sensing
the environment to deliver a direct or indirect measurement of the space￾craft state, both orbital and attitude one. Sensors must be characterized
and calibrated because a proper modeling of their functioning is critical
for the navigation algorithms to perform well. A comprehensive descrip￾tion of sensors is presented in Chapter 6 e Sensors.
• Actuators. The actuator suite is the ensemble of hardware in charge of
delivering either an external torque or thrust interacting with the envi￾ronment. Also, actuators must be characterized and calibrated because a
proper modeling of their functioning is critical for the GNC algorithms
to perform well. A comprehensive description of actuators is presented in
Chapter 7 e Actuators.
• Environment. The environment represents the ensemble of physical laws
dominating the surrounding of the spacecraft. In other words, it is a
mathematical representation of the natural forces and torques acting on
the spacecraft. For a GNC engineer, the environment has a twofold
role: on one hand, it represents a partially known entity that drives the
actual system state, whose accurate modeling is critical to validate the
developed algorithms; on the other hand, environmental modeling
achieves different level of accuracy when designing the algorithms them￾selves, depending on their complexity, computational burden, etc. In
other words, the former is something we cannot do much about and
the spacecraft is simply reacting to it, the latter is the engineering knowl￾edge that needs to be traded-off in each application. A comprehensive
16 Vincenzo Pesce et al.description of the space environment, the orbital and attitude dynamics is
presented in Chapter 3 e The Space Environment, Chapter 4 e Orbital
Dynamics, and Chapter 5 e Attitude Dynamics.
A schematic of a generic GNC architecture is shown in Fig. 1.1.
Another important block of the GNC system is represented by a set of
management routines, which fall within the so-called FDIR system. Such
system oversees the malfunctioning of the GNC system with the goal of
detecting the anomaly, isolating it and to compute recovery action to main￾tain mission operability in contingent situations. As thoroughly discussed in
Chapter 11 e FDIR Development Approaches in Space Systems, the FDIR
involves reasoning at system level, due to the fact that spacecraft anomalies
may impact the GNC system bidirectionally. Indeed, the FDIR is directly
interfaced with the Mission and Spacecraft Management (MSM) system,
also known as Mission and Vehicle Management (MVM), which is in charge
to oversee the overall behavior of the spacecraft and its subsystems, including
the GNC one, in order to achieve the mission goals, managing the system
phases and modes. Adding this to our scheme of Fig. 1.1, we obtain the
scheme depicted in Fig. 1.2.
The mission management is highly dependent on mission objectives,
costs, and other collateral elements. Hence, ground control support is often
Figure 1.1 GNC system architecture. Dotted lines are representative of alternative path
of different potential system implementations.
Introduction 17utilized in the FDIR and MSM loop, yielding semiautonomous systems that
can handle only a subset of contingent situations. As mentioned, the reader is
referred to Chapter 11 e FDIR Development Approaches in Space Systems
for a comprehensive description of these management blocks.
GNC subsystem design
GNC subsystem design is an iterative process. Table 1.1 summarizes the
typical steps in a GNC design process, with inputs and outputs that would
be expected for each design step.
The first step of the GNC design process is the definition of guiding re￾quirements based on mission goals, as shown Table 1.1. The GNC require￾ments for the development of space programs are typically part of the Project
Requirements Document, which is comprehensive of the entire mission. The
levels of completeness and detail vary very much from project to project.
Figure 1.2 GNC-FDIR system architecture. Dotted lines are representative of alternative
path of different potential system implementations.
18 Vincenzo Pesce et al.Table 1.1 GNC subsystem design steps.
Design
step Description Inputs Outputs
1 Subsystem requirements
definition and
derivationdsubsystem
criticalities
• Mission
requirements
• System
requirements
• Subsystems
constraints
• Mission Concept
of Operations
(ConOps)
• Mission timeline
GNC subsystem
requirements
2 Definition of GNC
modes
• GNC subsystem
requirements
• Subsystems
constraints
• Mission ConOps
• Mission timeline
List of different GNC
modes
3 Environment and
disturbance assessment
• Spacecraft
geometry
• Operational orbit
• Epoch and mission
timeline
• Mission ConOps
• Station-keeping
needs
• Disturbance forces
(i.e., internal and
external)
• Disturbance
torques (i.e.,
internal and
external)
4 Sizing and selection of
GNC subsystem
hardware
• Spacecraft
geometry
• Operational orbit
• Epoch and
mission timeline
• Mission ConOps
• Disturbances
• Subsystem
constraints
• Preliminary
definition of the
sensors suite
• Preliminary
definition of
actuators suite
• Preliminary
definition of
computational
architecture (i.e.,
on-board software
e OBSW e and
on-board
computer e OBC)
(Continued)
Introduction 19This is very important for a designer that shall identify the right level of
complexity and performance for the project. Let us state it as a golden design
rule:
A designer knows that he has achieved perfection not when there is nothing left to
add, but when there is nothing left to take away.
For each mission, it is necessary to adapt the specified requirements
through a complete tailoring process [2], which entails:
• To decide if a requirement is necessary, taking into account the specific
functionalities required for the mission (cfr. golden design rule). For
instance, if a mission requires an on-board navigation function, then
the requirements dedicated to this function or to an on-board GNSS
receiver are applicable.
• To adapt the numerical values of a requirement, considering the exact
performances required for the mission. The designer must reason on
the actual needs of the mission, without spending resources for unneces￾sary performance level.
• To quantify the new hardware and software development necessary for
the program, which is a key factor in adapting the verification
requirements.
The types of GNC requirements can be divided into [2]:
• Functional requirements.
• Operational requirements.
Table 1.1 GNC subsystem design steps.dcont’d
Design
step Description Inputs Outputs
5 Definition of GNC
algorithm
• Sensors suite
performance and
characterization
• Actuators suite
performance and
characterization
• Subsystem
performance
requirements
• Algorithms for
GNC subsystem
• Mode manager
6 Iterate from 1 Output from 1, 2,
3, 4, 5
Refined mission and
GNC subsystem
requirements.
20 Vincenzo Pesce et al.• Performance requirements: these requirements are often referred to
characterize the GNC system in terms of the following features:
• Performance errors and budgets. For a comprehensive description of these
errors, please refer to Chapter 10 e Control e Control Budgets.
• Stability. It expresses the ability of a system submitted to bounded
external disturbances to remain indefinitely in a bounded domain
around an equilibrium position or around an equilibrium trajectory.
• Stability margins. They are used to quantify maximum parameters ex￾cursions preserving stability properties. The most frequent stability
margins, defined in classical control design (cfr. Chapter 10 e Con￾trol), are the gain margin, the phase margin, the modulus margin,
and, less frequently, the delay margin.
• Agility. It assesses the ability of a system to perform a maneuver in a
given time interval, including the tranquilization phase.
• Transient response. It characterizes the ability of a system to reach the
steady state with given maximum parameters. Common response
metrics are the settling time or system overshoot.
• Robustness. It describes the ability of a controlled system to maintain
some performance or stability characteristics in the presence of plant,
sensors, actuators, and/or environmental uncertainties.
• Verification requirements.
Typically, as for other subsystems, the GNC requirements originate from
mission requirements, expressed in various ways and directly linked to the
final objectives of the mission. It is interesting to report that international
standard claims that, in some cases, it can be preferable to keep the perfor￾mance requirements expressed at mission level and not at GNC level, in or￾der to allow the best optimization of the system [2]. An applicative use case
showing the GNC design process from requirements to preliminary design is
presented in Chapter 14 e Applicative GNC Cases and Examples.
The GNC subsystem is a part of the whole spacecraft; thus, many re￾quirements may also come from other spacecraft subsystems. The interfaces
between subsystems are obviously critical to be assessed when dealing with
system and subsystem design, especially GNC. An example of input/output
relationship is given in Fig. 1.3.
GNC modes
Mission objectives and requirements often imply more than one mode of
operating a spacecraft. Indeed, a contextual step to the requirement gener￾ation is the identification of the GNC modes. Often, the guiding
Introduction 21requirements generally begin with a description of the control modes the
GNC is expected to execute to meet those goals. This is because most of
the requirements, functional, operational, and performance are dependent
on the specific GNC mode involved.
GNC modes shall be defined by evaluating mission operations against:
• Flexibility. It is the capacity to adapt and solve more circumstances,
without ambiguities, with simple and effective configuration options.
• Autonomy. It is the capacity to be operative without the need of ground
intervention.
• Redundancy. It is the capacity to be operative in case of the loss of some
hardware components.
• Performance. It is the capacity to guarantee GNC functionalities with
various control authority and computational performances.
In principle, each GNC mode may rely on different sensors, actuators,
navigation, guidance, and control functions. In particular, the GNC func￾tions should be as independent and unique as possible.
Typical GNC modes are reported in Table 1.2, and they are thoroughly
discussed in Chapter 14 e Applicative GNC Cases and Examples.
Figure 1.3 Typical system and subsystem interfaces with GNC.
22 Vincenzo Pesce et al.Table 1.2 Typical GNC modes.
GNC mode Tasks Characteristics
Commissioning • Commissioning of the GNC
system
• Sequential start-up of
components
• To be used before relevant
mission phases
• It should include a monitoring
of the system in order to be
able to detect (autonomously
or from ground) anomalies
prior to the operative phases
• No particular performance
requirement is imposed
• Refer to Chapter 12 e GNC
Verification and Validation
Nominal • It fulfills the main mission
objectives
• It may be comprehensive of
submodes, such as image
acquisition, communication
pointing, proximity control
• Best performing hardware is
involved
• Highest performance
requirements
Safe • Detumble the satellite
• Power-saving
• Stable pointing, usually
toward the Sun
• Reliable hardware is
employed
• No performance requirement
is imposed (i.e., also rough
navigation or control are
accepted)
• Must be autonomous
Standby • Power positive pointing
• Ground station pointing
• Particular pointing required by
a set of subsystems (e.g., power
and thermal)
• Drag drift minimization (e.g.,
hold point)
• It is typically autonomous
• In general, the spacecraft is
more operative with respect
to safe mode
• Different GNC functions with
respect to Safe mode
Orbit control • It performs orbital maneuvers • It can be split into inertial and
relative maneuvers
• Propulsion subsystem is
involved
• Parasitic torques coming from
thrust misalignment have to
be controlled
Transfer • It controls the attitude and
orbital state during long
transfers (e.g., to get to GTO
or interplanetary transfer)
• Interplanetary navigation
• It shares a lot with orbit
control mode
• It may have additional system
requirements during ballistic
arcs
Special • It fulfills particular extended
objectives of the mission
• Various
Introduction 23System redundancy
With respect to the mode’s characteristics, it is important to highlight the
concept of redundancy. The harsh space environment yield degradation
or failures of space missions. A typical requirement for many missions is
the ability to survive and function even in the case components failures
have occurred. Redundancy aims at implementing such requirement to pre￾serve the full capabilities of the spacecraft. Redundancy can be split into cold,
hot, and active [3]:
• Cold redundancy design. The secondary hardware is not operative and nor￾mally switched off until a failure on the primary component occurs. The
advantage of such kind of redundancy is that the component does not
require any power. Nevertheless, the latency of the system to react to
the failure increases, as the secondary component needs to be turned
on and, potentially, commissioned.
• Hot redundancy configuration. All entities are powered on with only one
operating. This allows a quick recovery of the functionality whenever
a failure in the primary component occurs.
• Active redundancy configuration. All the components are operative, and the
system can continue to function without downtime or defects despite the
loss of one or more entities.
Finally, if redundancy is implemented at functional level (i.e., not on
specific hardware), it is often referred as analytical redundancy. In an analytical
redundancy configuration, the function of a failed component is provided
by using an entirely different component or ensemble of components,
with a different set of GNC functions. Such strategy largely involves algo￾rithm design and often requires higher computational cost.
The redundancy of multiple GNC elements (e.g., architecture including
sensors, on-board computers, actuators, etc.) can be implemented in mainly
two different alternative configurations, namely in a block redundant or in a
cross-strapped configuration [4]. Their difference is depicted in Fig. 1.4.
Figure 1.4 Multiple elements redundancy configuration. Dotted lines indicate redun￾dant components in the nominal design.
24 Vincenzo Pesce et al.Block redundant configuration replicates two (or more) independent
fully functional pipelines. Whenever one of the components (e.g., sensor
1, OBC, or actuator 2) fails, the entire pipeline is dismissed and the redun￾dant is used, being it in cold, hot, or active redundancy. In a cross-strapped
configuration, each element is connected to both the nominal and the
redundant successive element. Thus, the failure of one element in one pipe￾line does not prevent the elements belonging to it to maintain their
operativity.
Both configurations are single-fault tolerant. Block redundant configu￾ration has a simpler implementation, but it can withstand a second fault
only if the failure occurs in the pipeline where the first one occurred. It
can be seen that the number of connections linearly scale with the number
of redundant paths. Cross-strapped configuration is certainly more robust at
the cost of higher complexity, given the large number of additional connec￾tions, potentially unused in nominal conditions. In this case, it is important
to remark that the number of functional connections exponentially scale
with the number of redundant paths.
Each mission requires an accurate reliability analysis to define the proper
redundancy strategy and configuration. Moreover, throughout the genera￾tion of the requirements, the definition of the modes, the selection of system
redundancies and the preliminary design, the concept of trade-off is crucial.
Several iterations, as detailed in Chapter 14 e Applicative GNC Cases and
Examples, are required to converge to the final GNC architecture.
Mission phases
The GNC system design, implementation, and operation follow the devel￾opment of the standard mission phases. Table 1.3 reports an overview of the
different phases of the life cycle of a typical space mission.
Table 1.3 Mission life cycle.
Phase 0
Mission analysis and
identification
Phase A Feasibility
Phase B Preliminary definition
Phase C Detailed definition
Phase D Qualification and production
Phase E Utilization
Phase F Disposal
Introduction 25During phase 0 and A of the mission design, prototypes of key GNC al￾gorithms may be developed to demonstrate the feasibility of the intended
approach. The GNC algorithms may be run in open loop as stand-alone
functions, or they may be integrated in highly simplified simulators of the
dynamics to ensure that the algorithms can sequentially run in discrete time.
During the late phase A and in the early phase B (i.e., B1) of the mission
design, a full simulator containing all the dynamical effects that are relevant
for the GNC design may be implemented. However, this simulator still con￾tains simplified models of the sensors and actuators. During phase A/B1, the
architecture and the most important modes of the GNC functions are iden￾tified. A preliminary implementation of the full GNC subsystem may be car￾ried out and tested to demonstrate the feasibility of the GNC solution. Some
efforts may be spent to ensure that all the functions meet the requirements
on the computational load; that is to say, to demonstrate that the GNC func￾tions can be executed within the available time. The technical requirements
for the on-board software are defined at the end of phase A.
During the phases B and C, the GNC architecture and the functionalities
of the GNC software are consolidated, and the engineering efforts shift to￾ward verification and validation of the software. Code analysis tools may be
used to ensure that no prohibited operations (e.g., division by zero) can
occur, and again to ensure that the GNC functions meet requirements on
the computational load. During these phases, the software matures from
prototypes to the actual flight software. More attention is paid to the correct
definition of interfaces and more detailed models of the real world, in partic￾ular sensors and actuators, are included into the GNC simulator, as more in￾formation from the hardware design of the spacecraft becomes available.
During phase D, the final version of the on-board software is integrated
in the spacecraft computer for validation, verification, and testing purposes.
The whole system is manufactured and integrated to be finally qualified for
the launch in space. Even the on-board software undergoes qualification
testing activities before launch. Finally, during phase E, the spacecraft and
the GNC subsystem are utilized and operated by the operation engineers.
The original software and GNC development team may be occasionally
called upon to solve problems, and even patch software problems if required.
Consider the anomalies
An operational spacecraft shall be able to handle nonnominal conditions that
may arise, endangering the correct operation of a given subsystem or the
26 Vincenzo Pesce et al.overall mission. In fact, on-orbit maintenance is not yet a feasible and
economically sustainable alternative for most of the space missions. For
this reason, it is extremely important to design an FDIR subsystem to detect
and successfully recover, in an autonomous or semiautonomous way, from
faults. FDIR system development should be carried out in parallel with the
mission design and it’s addressed since the very beginning of the GNC
development. The definition of reliability, availability, and safety objectives
is strongly dependent on the designed FDIR system.
FDIR system conception and implementation for a spacecraft is an
extremely complex task. This is particularly true because the analysis of
spacecraft failures is not always straightforward. The cause of malfunctions
could be one or more failed components, incorrect control actions, or
external disturbances, which impact system operations. Usually, in order
to identify the failure scenarios, reliability design analysis (i.e., risk analysis)
techniques are used. In particular, Fault Tree Analysis (FTA) and Failure
Mode Effects and Criticality Analysis (FMECA) are usually employed.
FTA is a top-down deductive method where top-level failures are addressed
and all the basic faults (i.e., failure causes), which can lead to such states, are
identified. FTA helps to identify how the system or subsystem can fail and
the best way to minimize the risk connected to a given failure. On the other
hand, FMECA is an inductive bottom-up analysis, and it is used to compute
the casual effects on the system of a given fault combination. It is primarily
used to identify potential single-point failures.
FMECA is usually applied for spacecraft risk assessment and the main
process steps are [5,6]:
• Establish FMECA analysis approach. The purpose of this phase is to define
the objectives of the analysis and the mission phases to be examined. Fail￾ure modes and criticality levels are defined. Procedures to be adopted and
format of the final FMECA worksheet are selected.
• System definition. Functional behavior, operational modes, and mission
phases are identified.
• Construct functional block diagram. A functional block diagram of the system
to be assessed is detailed. Blocks and outputs at the level of detail required
for the analysis are identified.
• Identify failure modes and effects. All functional, hardware, software, and
product single point failures are identified and eventually included into
the critical items list. Critical items are those items which are reliability,
mission, or safety critical.
Introduction 27• Failure mode effect. The failure effect for each mission phase and for the
considered components is assessed.
• Failure detection method. Failure detection techniques are defined for each
mission phase. Telemetry and on-board fault management can be used to
this purpose.
• Provide compensating provisions. Failure mode compensation methods are
identified for each failure mode. This is usually carried out by the on￾board autonomous fault management system (i.e., FDIR) or by the
ground anomaly detection and resolution control system, which im￾plements recovery plans and procedures. These methods can include
fault tolerant systems, redundancy, workaround, and alternate modes of
operations.
• Perform criticality analysis. Each failure mode is evaluated in terms of the
worst potential consequences and a severity category is assigned.
• Documentation and reporting. Document the analysis and summarize the
results and the problems that cannot be solved by the corrective actions.
• Recording. Record all critical items into a dedicated table as an input to
the overall project critical item list.
Once the FMECA documentation is produced, an assessment of the risk
associated with each failure mode can be performed evaluating the following
quantities:
• Severity number (SN): the severity of failure effects on the system.
• 1 e catastrophic.
• 2 e critical.
• 3 e major.
• 4 e minor or negligible.
• Probability number (PN): probability of occurrence of a failure mode.
• 1 e extremely unlikely.
• 2 e unlikely.
• 3 e likely.
• 4 e very likely.
• Detection number (DN): the probability of detection of a failure mode.
• 1 e very likely.
• 2 e likely.
• 3 e unlikely.
• 4 e extremely unlikely.
• Criticality number (CN): obtained as product of SN, PN, and DN (i.e.,
CN ¼ SN $PN $DNÞ It quantifies the risk associated with a given fail￾ure mode.
28 Vincenzo Pesce et al.Mode management
During the GNC design, the modes shall be defined together with their
transitions. Indeed, once the main modes at system and GNC subsystem
level are identified, a mission manager has to be designed. The role of a
mission management software is to provide commands to the GNC subsys￾tem in order to adapt its modes and configurations to a specific mission
phase. In general, an on-board mission manager shall perform four main
tasks [7]:
• Monitoring. Processing spacecraft state and status, checking for possible
problems with the current plan. Given certain mission objective, the
mission manager should be able to evaluate if the current state and status,
propagated in time to the end of the mission phase, satisfy the given
requirements.
• Diagnosis. Identifying problems with the current plan and configuration
and taking the action of replanning or reconfiguration. This task is very
similar to the FDIR objective even though mission manager diagnosis is
limited to plan and configuration problems.
• Planning. Creating a series of commands that achieve mission objectives.
This is done at the beginning of the mission or after replanning.
• Execution. The plan is enabled by sending sequential commands to the
Guidance and Control functions. This sequencing may be time- or
event-triggered.
A high-level schematic of a mode management system is reported in
Fig. 1.5. Sometimes, to simplify the overall architecture, a plan is defined be￾forehand, and the mission manager tasks are reduced to monitoring and
execution. This is a common practice for many spacecraft missions to reduce
the overall mission complexity and shorten validation and verification
activities.
Figure 1.5 Mode manager architecture.
Introduction 29Mode transition and finite state machine
During the design of a mode management system, particular attention must
be paid to the definition of mode transitions. In general, a good practice
while implementing GNC mode transitions is to accurately design them
in order to avoid:
• Logical errors (e.g., an event triggering no state).
• Ambiguous states (e.g., an event triggering multiple states).
• Transition errors (e.g., an event triggering the wrong state).
• Unreachable states (e.g., states that cannot be activated by any event).
• Loop states (e.g., states that cannot be excited after their activation).
A common solution to design GNC mode architecture and transitions is
to use Finite State Machine (FSM) and visual programming. The combina￾tion of these two tools allows for a formal, simple, and visual representation
of the modes of architecture and eases the operator monitoring phase. An
FSM is a mathematical model describing an event-triggered system, allow￾ing to model transitions within a fixed number of states. FSMs have the
following properties:
• Can be in exactly one of a finite number of states at any given time.
• Change from one state to another (i.e., perform a transition) in response
to some inputs.
• Are dynamics, discrete, finite.
• Can be represented as directed graph.
FSM can be described in Specification and Description Language, which
can make these models executable for verification, validation, and testing
purposes. Two major types of FSM are acceptors and transducers [8]. The
main difference between these two categories of FSM is that an acceptor
generates a binary output that indicates if the given input is accepted and
rejected, while the transducers FSMs performs actions to generate the ex￾pected outputs. Finally, an interpreter is needed to implement and execute
the FSM.
The simplicity of FSM models allows for a visual representation of states
and modes transitions based on node-link diagrams (i.e., visual program￾ming) using dataflow languages [9]. A common software used for mode
transitions and management is MATLAB/Simulink Stateflow tool [10].
With this approach, each FSM can be treated as a single module and a dia￾gram representing mode transitions through FSM can be graphically
depicted, providing a very intuitive visual representation.
30 Vincenzo Pesce et al.Automation, autonomy, and autonomicity
During the design of mode management and, in general, of spacecraft oper￾ations, different levels of autonomy can be identified. Even if we speak about
autonomy while referring to a process executed without any human inter￾vention, specific terms are defined to indicate different facets of this concept
[11]:
• Automation. A sequence of commands is executed by software/hardware,
replacing the corresponding manual process. No independent decision￾making task is expected. In the case of automatic mode transitions, these
steps are executed according to a given schedule (i.e., time-triggered), or
after a task is completed, or after an event occurrence (i.e., event￾triggered).
• Autonomy. Software and hardware components try to emulate the hu￾man process rather than simply replacing it. In this case, human￾independent decisions are expected. In the case of mode transitions, an
internal logic is designed to command the mode switch based on the
received states and status of FDIR and GNC subsystem.
• Autonomicity (or intelligent autonomy). This kind of systems is expected to
be able to perform self-management rather than simply self-governance,
as in the case of autonomy. In other words, autonomicity can be seen as a
form of autonomy specifically designed to manage the system. As an
example, the goal of a system may be to detect a given phenomenon
using an on-board payload [11]. The autonomy capability is to choose
between different parameters to achieve this goal. However, the
objective of ensuring that the system is fault-tolerant and continues to
operate under fault conditions falls into the autonomicity domain rather
than autonomy. Without autonomic capabilities, the spacecraft’s per￾formance degrades, and the spacecraft may be unable to recover from
faults. As discussed before, in the last years, the concept of autonomicity
is gaining attention for spacecraft operation and design. Autonomic
systems definition derives from the human Autonomic Nervous System
that is the core of most nonconscious brain activities (e.g., breathing,
reflex reactions, etc.). The idea is to have a self-managing system with the
following objectives [11e16]:
• Self-configuring. System’s ability to readjust itself automatically.
• Self-healing. System’s ability to recover after a fault occurs.
• Self-optimizing. System’s ability to measure its current performance
and to improve it.
• Self-protecting. System’s ability to defend itself from external threats.
Introduction 31On-board versus ground-based
In general, a space mission consists of the ground segment and the space
segment and controlling and operating a spacecraft is a task shared between
the ground segment and the space segment, depending on the level of au￾tonomy of the platform.
Fig. 1.6 shows a ground-based control system. In this case, spacecraft data
obtained from the sensors are sent to ground for processing, and commands
are calculated under human supervision. These commands are uploaded to
the spacecraft where the commands are stored and managed by the on-board
computer. The on-board computer sends the commands to the actuators at
the appropriate times.
More computational power is available on-ground than on board a
spacecraft. This means that the ground segment can use more complete
models of the spacecraft dynamics and sensors, more sophisticated filtering
techniques to obtain a guidance solution, and more detailed dynamics
models for computing maneuvers. Maneuvers can be computed on ground
using optimization techniques that may be prohibitively expensive to imple￾ment on-board or using techniques that require human supervision to
ensure that the maneuvering solution is acceptable. In general, downloading
the telemetry data requires regular ground station visibility, and the visibility
Figure 1.6 Notional ground-based system.
32 Vincenzo Pesce et al.windows determine the frequency with which the spacecraft orbit and atti￾tude can be determined, and commands can be uploaded. The number of
ground stations that are available and their overlap determine whether
and how long continuous contact is possible, and how long a spacecraft
needs to be able to survive between contacts. Needless to say, the more
ground stations needed for the mission, the more expensive the operations
become. Likewise, if the space segment needs to be monitored continuously
by human operators, then the cost of operation is high. It is possible to design
the overall mission in such a way that critical operations can count on
continuous supervision, while during the less critical operations, the super￾vision by human operators is reduced.
Another important aspect is that downloading and processing the data
and generating and uploading the commands can require a significant
amount of time. This is especially true for missions that take place in orbits
that are further away than LEO. For example, a Mars Sample Return
mission requires a higher degree of autonomy because the two-way light
time can be as high as 48 min. In general, rendezvous missions may require
autonomous abort capabilities for the close proximity operations as the re￾action time available becomes too short for human operators to respond
in time adequately [12].
For example, if robotic proximity operations are conducted with a
ground operator in the loop, then it may be necessary to download video
data and upload thruster and robotic arm commands. This requires a
high-bandwidth link, and if the operations are critical, it must be ensured
that the operations can be completed within the ground visibility window.
Fig. 1.7 shows an alternative control system in which more autonomy is
placed in the space segment. A navigation function processes the data com￾ing from the sensors, a guidance function provides the reference trajectory
and the feed-forward forces and torques, and the control function provides
feed-back forces and torques based on inputs from the navigation and the
Figure 1.7 Notional on-board GNC system.
Introduction 33guidance function. A mode manager is in charge of managing the overall
behavior of the on-board GNC system.
In recent years, microprocessors for space applications have become sub￾stantially more powerful. However, on-board computational resources are
still usually limited when compared to the resources available on-ground.
This means that the algorithms for on-board applications tend to be less so￾phisticated than the algorithms for on-ground applications.
The advantage of having greater autonomy on-board is that it allows for
less frequent commanding of the spacecraft. For example, this could enable
missions that require ground personnel to be present at the mission opera￾tions center only during working hours, which in turn would reduce the
cost of operations. On the other hand, the increased level of autonomy
also requires more time and effort to be spent on the development, verifica￾tion, and validation of the software, which increases the cost of the on-board
software. In general, the reduction of the cost of operation is expected to be
greater than the increased cost of the software development [13].
A space system can also use a mixed approach. Some functions could be
performed on-board while others are performed on-ground. For example,
the time scales involved are different for the attitude dynamics, which
tend to be faster, and the orbital dynamics, which tend to be slower. Func￾tions such as target pointing for rendezvous require a fast reaction time, such
that it may make sense to implement this functionality on-board, while
orbital maneuvers can potentially be planned up to perhaps an hour in
advance. Of course, implementing target pointing capability on-board
also implies the need to implement a relative navigation function and an atti￾tude controller on board. In addition, the level of autonomy could be
dependent on the mission phase. For example, a robotic capture could be
performed under full ground control, while the rendezvous operations
that precede the capture are performed autonomously. The level of control
the ground has can also vary. For example, the ground interactions could be
limited to sending GO/NO-GO commands, or be as extensive as having
full control over the spacecraft with a direct video link. Table 1.4 provides
a formal description of autonomy of space systems that is based on the ECSS
Space Segment Operability Standard [14]. The approach that is described in
Fig. 1.7, and the sections that follow tacitly assume a level of autonomy that
is broadly compatible with level E3 in Table 1.4.
34 Vincenzo Pesce et al.Summarizing, the reasons for increasing the level of on-board autonomy
are the following:
• Reduces the complexity of ground operations.
• Implies that the ground segment no longer has direct control over on￾board operations that may be critical to the survival of the spacecraft [15].
• Reduces personnel requirements on ground, possibly single shift, and it
may reduce propellant cost and it allows for more precise timing of on￾board events [16].
• Reduces operational complexity when there are limited communication
windows and/or large communication delays, such as, for example, plan￾etary sample return missions.
• Reduces operational complexity when fast actions are required, such as,
for example, detection of an imminent collision.
The European ECSS Space Segment Operability Standard provides a
definition of on-board autonomy [16]: “On-board autonomy management
addresses all aspects of on-board autonomous functions that provide the
space segment with the capability to continue mission operations and to sur￾vive critical situations without relying on ground segment intervention.”
Table 1.5 [9] provides an overview of factors that influence the level of
autonomy.
Table 1.4 Autonomy levels as defined in the European ECSS space segment
operability standard.
Level Description Functions
E1 Mission execution from ground
control; limited onboard
capability for safety issues
Real-time control from
ground for nominal
operations. Execution of
time-tagged commands for
safety issues
E2 Execution of preplanned,
ground-defined, mission
operations on-board
Capability to store time-based
commands in an on-board
scheduler
E3 Execution of adaptive mission
operations on-board
Event-based autonomous
operations. Execution of
on-board operations control
procedures
E4 Execution of goal-oriented
mission operations on-board
Goal-oriented mission
(re-)planning
Introduction 35Verify the preliminary design
As previously explained, after the preliminary GNC design and imple￾mentation, preliminary verification and validation of the software is
performed.
The software design and development process itself is shown in Fig. 1.8.
In particular, for the given software development projects, the following
phases can be identified:
• Definition of requirements.
• Definition of software architecture and preliminary design.
• Detailed design.
• Implementation.
• Verification.
Customer or mission requirements are encoded in the User Requirements
Document. These requirements are flowed down to algorithm and software
requirements specifications. The algorithm and software requirements are
contained in the Software Requirements Document. Based on this document,
a preliminary design of the software, including the software architecture,
is performed, followed by a detailed design of the software and the algo￾rithms. During each of these steps, a Software Verification and Validation plan
is created and maintained, such that all the algorithms can be tested and veri￾fied. After the algorithms are coded, the software is tested. The first tests are
Table 1.5 Factors that influence the level of autonomy.
Assumption Comments
Environment with
high uncertainty
Three sources of uncertainty: partial observability which
leads to a partial understanding of the state of the real
world; nondeterminism appears in real-world domains
because actions can lead to different possible states; a
dynamic domain could spontaneously change its state due
to external events.
Limited on-board
resources
Available on-board resources, especially in terms of
computing power, memory, and energy, are limited.
Limited
communications
Communications to the spacecraft might be limited due to
obstacles (e.g., operations inside a crater), long delays
(e.g., interplanetary missions), or communication
windows.
Highly complex
operations
Increasing payload and platform capabilities enables the
achievement of more complex missions.
Criticality Spacecraft represent critical systems for which high safety
standards must be enforced.
36 Vincenzo Pesce et al.unitary tests that determine whether the algorithms and functions behave
properly as stand-alone functions. Next, the software is (partially) integrated
and integration tests are performed to ensure that all the components of the
software work well together. Finally, a full test campaign is performed to
ensure that the software meets all the performance specifications that have
been established in the requirements documents.
Fig. 1.8 shows a single waterfall design cycle, but in an actual design pro￾cess, more iterations and customer feedback take place at each step of this
process. The feedback can result in modifications of any part of the require￾ments and the software design. At the same time, early implementation and
testing may occur to help in the definition of the requirements. Finally,
design projects at different stages of the mission life cycle can make different
loops through the waterfall that serve to consolidate the user requirements
for the next phase of the project. In this case, the set of user requirements
for the next phase of the design can come with a preliminary design that
was established during the phase that came before.
Figure 1.8 Model-based design and prototyping.
Introduction 37Notation rules
The main notation rules used in this book are detailed in this
paragraph.
Vectors and matrices are represented with bold symbols or in parenthesis
as follows:
xnx1 ¼ fxig ¼
8
>><
>>:
x1
«
xn
9
>>=
>>;
; Anxm ¼ 
Aij
¼
2
6
6
6
6
4
A11 A12 /
« «
An1 An2 /
A1m
«
Anm
3
7
7
7
7
5
.
Most of the times, vectors are indicated with small letter symbols, while
matrices with capital letter symbols. Therefore, the previous notation indi￾cates column vectors of n components and matrices of n rows and m col￾umns. Note that the subscript with the dimensions will be indicated only
if necessary. The single component is represented by the nonbold symbol
with one or two indices. A row vector is always the transpose of a column
vector:
xT ¼ fxi / xng.
The inverse of a nonsingular square matrix is represented by the symbol
ð Þ1
, and it is defined by the condition:
AA1 ¼ A1A ¼ In; with Iij ¼
( 1 if i ¼ j
0 if isj
where In is the identity matrix with size n.
It is assumed that the reader is familiar with matrix algebra, also briefly
summarized in Appendix Chapter 16 e Mathematical and Geometrical
Rules. In this book, the dot product will be represented with the dot symbol
"$" and the vector product with the cross symbol “” The dot symbol “$”
always refers to a dot product of two vectors; on the contrary, the product of
two scalars x and y will be written as xy, with no specific symbol.
The cross product operation is also commonly indicated in matrix form,
by exploiting the cross product matrix that is defined for a generic vector in
three-dimensional space as:
½x3x1   ¼
2
6
6
4
0 x3 x2
x3 0 x1
x2 x1 0
3
7
7
5;
38 Vincenzo Pesce et al.which is skew-symmetric (i.e., its transpose is equal to the same matrix with
opposite sign).
A general quaternion will be expressed as q ¼ q1i þ q2j þ q3k þ q4.
Here i; j; k are the units of quaternions, satisfying i
2 ¼ j
2 ¼ k2 ¼ ijk ¼ 1
and q1; q2; q3; q4 are all real numbers. q4 is the scalar part of the quaternion,
and q1i þ q2j þ q3k is the vector part of the quaternion.
Notation table
A more comprehensive list of the used notation symbols is reported in the
table:
Vectors
xnx1 ¼ fxig ¼
8
>><
>>:
x1
«
xn
9
>>=
>>;
Column vector with n entries x1/ xn
xr:s Subvector with entries from r to s
x ¼k x k Norm of vector x
bxnx1 ¼ xnx1
kxnx1k Unit norm vector with n entries
rms ðxÞ Root-mean-square value of vector x
avg ðxÞ Average of entries of vector x
std ðxÞ Standard deviation of vector x
Matrices
Anxm ¼ 
Aij ¼
2
6
6
6
6
4
A11 A12 /
« «
An1 An2 /
A1m
«
Anm
3
7
7
7
7
5
n  m matrix with entries A11/ Amn
Ar:s; p:q Submatrix with rows r to s and columns p to q
In Identity matrix with size n
AT Transpose of matrix A
k A k Norm of matrix A
Ak (Square) matrix A to the kth power
A1 Inverse of matrix A
diag ðxÞ Diagonal matrix with diagonal entries
x1/ xn
diag ðAÞ Diagonal entries x1/ xn of the matrix A
½x3x1  ¼
2
6
6
4
0 x3 x2
x3 0 x1
x2 x1 0
3
7
7
5
3  3 skew-symmetric cross-product matrix
(Continued)
Introduction 39List of Acronyms
Artificial Intelligence AI
Artificial Neural Networks ANNs
Assembly Integration and Test AIT
Assembly Integration and Verification AIV
dcont’d
Quaternions
q ¼ q1i þ q2j þ q3k þ q4 Quaternion vector, scalar part last
q  q ¼
"
q4q1:3 þ q4q1:3  q1:3  q1:3
q4q4  q1:3$q1:3
# First added quaternion operation
q* ¼ q1i  q2j  q3k þ q4 Conjugate quaternion
q1 ¼ q*

k q k Inverse quaternion
Functions and derivatives
f : A/B f is a function on the set A into the set B
Vf Gradient of function f : Rn/R at z
df
dx ¼

vf
vxi
 Derivative of function f with respect to
vector x
Vx f Jacobian of vectorial function f : Rn/Rm
V2
x f Hessian matrix of f
_
f ¼ df
dt
Time derivative of function f
f Reference function
df ¼ f  f Perturbation function
Random variables
Efxg ¼ m Expected values of a random vector
Pfxg ¼ Sfxg ¼ E

ðx mÞðx  mÞ
T Covariance matrix
s2fxg ¼ diagðPÞ ¼ E

ðx  mÞ
2 Variance
sfxg ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffi
s2fxg p Standard deviation
Errors and variables elaboration
xðtÞ True variable
xðtÞ Measured variable
exðtÞ or bxðtÞ Estimated variable
xðtÞ or xrefðtÞ Reference variable
dx ¼ xðtÞ  xðtÞ Error variable
dq ¼ q  q1 Error quaternion
40 Vincenzo Pesce et al.Attitude and Orbit Control System AOCS
Attitude Determination and Control System ADCS
Automated Code Generation ACG
Center of Mass CoM
Central Processing Unit CPU
Circular Restricted Three-Body Problem CRTBPdCR3BP
Collision Avoidance Maneuver CAM
Commercial Off the Shelf COTS
Control Moment Gyros CMG
Deep Learning DL
Degrees of Freedom DoF
Digital Signal Processors DSPs
Electrical Ground Support Equipment EGSE
Elliptic Restricted Three-Body Problem ERTBPdCR3BP
European Cooperation for Space Standardization ECSS
Extended Kalman Filter EKF
Failure Detection Isolation and Recovery FDIR
Failure Mode Effects and Criticality Analysis FMECA
Fault Tree Analysis FTA
Field Programmable Gate Array FPGA
Geostationary Orbits GEOs
Global Navigation Satellite System GNSS
Graphical Processing Units GPUs
Ground Support Equipment GSE
Guidance, Navigation, and Control GNC
H-Infinity HN
Hardware HW
Hardware-in-the-Loop HIL
In-Orbit testing IOT
Inertial Measurement Unit IMU
Inertial Navigation System INS
International Geomagnetic Reference Field IGRF
Kalman Filter KF
Kee Out Zone KOZ
Launch and Early Orbit Phase LEOP
LIght Detection and Ranging LIDAR
Linear Quadratic Regulator LQR
Low Earth Orbit LEO
Machine Learning ML
Medium Earth Orbits MEOs
Minimum Impulse Bit MIB
Mission and Vehicle Management MVM
Model Predictive Control MPC
Model-in-the-Loop MIL
On-Board Software OBSW
Particle Filter PF
Processor-in-the-Loop PIL
Proportional-Integral-Derivative PID
Reinforcement Learning RL
Reliability, Availability, Maintainability, and Safety RAMS
Introduction 41Singular Value Decomposition SVD
Sliding Mode Control SMC
Software SW
Software-in-the-Loop SIL
Solar Radiation Pressure SRP
Special Check-Out Equipment SCOE
Sun-Synchronous Orbits SSOs
Technology Readiness Level TRL
Two-Line Elements TLE
Unscented Kalman UKF
Validation and Verification V&V
References
[1] J.B. Hammack, Postlaunch Report for Mercury-Redstone No. 3 (MR-3), NASA
Report, 1961.
[2] ECSS-E-ST-60-30C, Satellite Attitude and Orbit Control System (AOCS)
Requirements, ECSS Standards, 2013.
[3] ECSS-S-ST-00-01C, Glossary of Terms, ECSS Standards, 2012.
[4] F.L. Markley, J.L. Crassidis, Fundamentals of Spacecraft Attitude Determination and
Control, Space Technology Library, Springer, New York, 2014.
[5] R.J. Duphily, Air Force Space Command, Space Vehicle Failure Modes, Effects, and
Criticality Analysis (FMECA) Guide, Space Missile System Center, 2009. El Segundo,
CA, USA, Aerosp. Rep. No. TOR-2009 (8591)-13.
[6] ECSS-Q-ST-30-02C e Failure Modes, Effects (And Criticality) Analysis (FMEA/
FMECA), ECSS Standards, 2009.
[7] M. Jackson, C. D’Souza, H. Lane, Autonomous Mission Management for Spacecraft
Rendezvous using an Agent Hierarchy, in: Infotech@ Aerospace, 2005, p. 7062.
[8] R. Turner, et al., ExecSpec: visually designing and operating a finite state machine￾based spacecraft autonomy system, in: 9th International Symposium on Artificial Intel￾ligence, Robotics and Automation for Space (i-Sairas’08), Pasadena, CA, 2008.
[9] W.M. Johnston, et al., Advances in dataflow programming languages, ACM
Computing Surveys 36 (1) (March 2004) 1e34.
[10] https://www.mathworks.com/products/stateflow.html.
[11] W. Truszkowski, et al., Autonomous and Autonomic Systems: With Applications to
NASA Intelligent Spacecraft Operations and Exploration Systems, Springer Science
& Business Media, 2009.
[12] D.K. Geller, Orbital rendezvous: when is autonomy required? Journal of Guidance,
Control, and Dynamics 30 (4) (2007) 974e981.
[13] J.R. Wertz, W.J. Larson, in: Space Mission Analysis and Design, Microcosm, 1999.
[14] https://www.h2020-ergo.eu/project/background-on-autonomy-software-frame￾works/autonomy-in-space-systems/.
[15] P. Grandjean, T. Pesquet, A.M.M. Muxi, M.C. Charmeau, What on-board autonomy
means for ground operations: an autonomy demonstrator conceptual design, in: Space
OPS 2004 Conference, 2004, p. 267.
[16] R. Sterritt, D.W. Bustard, Autonomic computingda means of achieving depend￾ability?, in: Proc. IEEE International Conference on the Engineering of Computer
Based Systems (ECBS-03), Pages 247e251, Huntsville, Alabama (USA) IEEE Com￾puter Society Press, Los Alamitos, California (USA), April 2003.
42 Vincenzo Pesce et al.PART ONE
Fundamental GNC tools
43jThis page intentionally left blankCHAPTER TWO
Reference systems and planetary
models
Andrea Colagrossi1
, Stefano Silvestrini1
, Vincenzo Pesce2
1
Politecnico di Milano, Milan, Italy
2
Airbus D&S Advanced Studies, Toulouse, France
This chapter presents an overview of the key concepts regarding generic
planetary models and the definition of standardized time models, as well
as relevant reference systems commonly used in the Guidance Navigation
and Control (GNC) design. The notions of this chapter, although here
only briefly outlined, are extremely important to avoid inherent and
intrinsic errors in the system design. Also, a careful analysis of the presented
topics prevents ambiguities when dealing with typical GNC operations,
scheduling, and, in general, system and algorithm features that require
unique and well-established representations of the environment.
The content of this chapter is structured as follows:
• Earth and planetary models. This section describes the models to describe
planetary geometry, with focus on the Earth’s ellipsoid and geoid. It
also includes a brief introduction to position representation methods
for objects on and above the planetary surface.
• Coordinate reference systems. In this section, the most relevant coordinate
reference systems are presented. Heliocentric, geocentric, topocentric,
lunar, three-body, and satellite-based reference systems are discussed.
• Coordinate transformations. This section briefly explains the methods to
transform the coordinates from one reference system to another one,
with some examples of the most relevant transformations for GNC
applications.
• Time. The most relevant time conventions and scales are discussed in this
section. The most common time systems are described, and the concept
of Julian dates (JDs) is introduced.
• What is relevant for GNC? This section summarizes and highlights the
most relevant concepts for GNC applications discussed in this chapter.
Modern Spacecraft Guidance, Navigation, and Control
ISBN: 978-0-323-90916-7
https://doi.org/10.1016/B978-0-323-90916-7.00002-0
© 2023 Elsevier Inc.
All rights reserved. 45 jEarth and planetary models
The description of the Earth or the planet around which a spacecraft is
orbiting is a preliminary task every GNC designer must accomplish before
tackling the GNC system design. In fact, we must define a set of funda￾mental parameters to specify the shape and the geometry of any planet.
These values allow us to specify locations, shape, the planet’s precise size,
and the gravity field. This task is known as geodesy. We will focus the
following discussion on the Earth, but it can be easily generalized and
extended to most of the planets and natural satellites in the Solar System,
as long as the proper reference models are found and defined according to
the international standards.
Earth and most planetary shapes can be conveniently described exploit￾ing an oblate ellipsoid (i.e., an ellipsoid resulting from the revolution of an
ellipse around its minor axis), based on two physical characteristics:
• The equatorial radius, RE.
• The planetary eccentricity or flattening, eE or fE.
The Earth’s radius has been investigated since the beginning of human
presence, and the first calculation made by Eratosthenes in the third century
BC was astonishingly accurate (i.e., he made an error in the order of 1%e2%
with respect to the current values). Modern efforts began to converge on an
accepted value in the mid-1800s. The WGS-84 model [1] defines the mean
equatorial radius of the Earth, RE, as:
RE ¼ 6 378 137m
Eccentricity and flattening of the Earth’s ellipsoid are in WGS-84:
eE ¼ 0:081 819 190 842
fE ¼ 0:003 352 810 664 ¼ 1
298:257 223 563:
We can also calculate the semiminor axis of the Earth’s ellipsoid, using
RE as the semimajor axis, to aid in formulas relating positions on the Earth’s
surface. The semiminor axis, bE, also called the polar axis, is in WGS-84:
bEy6 356 752:314 245 m
Note that this is a derived quantity, and the overline bar indicates the
digits beyond the original accuracy in RE. The equatorial radius and polar
axis are related with the flattening as: fE ¼ ðRE bEÞ=RE. The flattening
is also denoted as oblateness.
46 Andrea Colagrossi et al.The WGS-84, World Geodetic Survey 1984 latest version, is a standard
geodetic model for use in geodesy and satellite navigation, including global
navigation satellite system (GNSS). This standard includes the definition of
the coordinate system’s fundamental and derived constants, the normal grav￾ity Earth Gravitational Models (EGMs) (EGM-96/EGM-2008 [2,3]), and it
is the reference ellipsoid for the standard Internal Geomagnetic Field Model
(IGRF). WGS-84 is of primary use and definition by the American associ￾ations, while European standards [4] suggest the use of EIGEN-GL04C as a
standard for gravity field modeling and geodesy. Note that European stan￾dards require anyway the use of WGS-84 as a reference ellipsoid for IGRF
usage. In any case, EIGEN-GL04C defines the Earth ellipsoid with an equa￾torial radius of RE ¼ 6 378 136 m, a polar radius of bE ¼ 6 356 752 m,
and an oblateness of fE ¼ 1=298:257. Hence, the differences with respect
to WGS-84 are minimal for what concern the geodesy and the reference
ellipsoid definition.
Additional physical characteristics of the Earth are:
• The rotational velocity, uE.
• The gravitational parameter, mE.
The Earth’s rotational velocity, uE, is frequently assumed to be constant
in time, and indeed it seemed to be so for many years, given the limitation of
existing measurement instruments. The accepted constant value for the
Earth’s rotation is:
uE ¼ 7:292 115 146 706 980  105 rad=s.
The last parameter is the standard gravitation parameter, which is now
commonly measured from satellite observations, rather than traditional
methods (e.g., Cavendish method [5]). Although the precise definition in￾cludes the masses of the Earth and the satellite, we neglect the satellite’s
mass because it’s so small relative to the Earth’s. Then, the standard gravita￾tion parameter of the Earth is:
me ¼ G

mE þ ms=c

yGmE ¼ 3:986 004 415  105 km3
=s
2;
where G ¼ 6:673  1020 km3
kg s2

is the gravitational constant, and
mE is the mass of the Earth. The value of me is the same in EGM-96, EGM￾08 and EIGEN-GL04C. Note that, me and G are experimentally measured,
while mE is a derived quantity. The standard gravitational parameters of
other celestial bodies and extensive discussions about several Earth and
planetary models may be found in Ref. [6].
Reference systems and planetary models 47Position representation
To represent the position of a spacecraft in space, cartesian coordinates may
be used. They are typically defined with respect to inertial, planetary-fixed,
or orbit-fixed three-dimensional cartesian reference frames. The most useful
for GNC application will be described in the next section of this chapter. An
alternative and very convenient approach to represent the position of a body
around the Earth, or a planet, is to use spherical coordinates, defining a
radius vector and two angles, which are typically denoted as latitude, or
declination, and longitude, or right ascension. The latter terms (i.e., declina￾tion and right ascension) are typically used to refer to position with respect to
the celestial sphere and inertial reference frames, the former (i.e., latitude and
longitude) are more commonly used around one planet, as seen in Fig. 2.1.
However, it is important to note that it is only a terminological difference,
depending from the reference directions from which the angles are
measured. Mathematically, they are analogous quantities: the two angles
used in spherical coordinate frames.
Focusing on position representation on the Earth, latitude and longitude
are the common spherical angles to define the position of a spacecraft with
Figure 2.1 Right ascension, a, declination, d, longitude, l, latitude, 4, as spherical co￾ordinates to define position. They are typically referred to the equatorial plane, but
they can be referred to other fundamental planes. For example, ecliptic longitude,
lecliptic, and ecliptic latitude, 4ecliptic, shown in the figure.
48 Andrea Colagrossi et al.respect to the Earth’s surface. Latitude is the northesouth angular measure￾ment with respect to the equatorial plane (i.e., the plane containing the
Earth’s equator). It takes on values from 0 to 90, and it’s positive in
the northern hemisphere. Longitude is an eastewest angular displacement
measured positive to the east from the plane containing the prime meridian.
The prime meridian for the Earth is the meridian (i.e., the intersection of a
plane passing through the Earth’s axis and the Earth’s surface) that the Royal
Observatory at Greenwich lies on. Longitude may take on values from 0 to
360 when measured east, or from 0 to 180 if measured eastdpositived
and west.
However, the Earth and most of the celestial bodies are not perfect
spheres. Thus, to precisely locate an object with respect to their surface, lati￾tude and longitude definitions may become a bit more complicated, also
depending on the planet of interest. For example, the Moon is better repre￾sented by a triaxial ellipsoid (i.e., an ellipsoid with three different semiaxes).
While, as already discussed, the Earth can be represented by a simpler oblate
ellipsoid, whose semimajor axis is equal to the equatorial radius, RE, and
semiminor axis is equal to the polar radius, bE. In this case, longitude, l,
has no definition ambiguities, due to the ellipsoid rotation around the polar
axis, while latitude shall be defined considering the flattening of the Earth.
With references to Fig. 2.2, we can define:
Figure 2.2 Geocentric and Geodetic Latitude: The geodetic latitude, 4gd, makes an
angle perpendicular to the surface and the equatorial plane, whereas the geocentric
latitude, 4gc, is referenced to the center of the Earth.
Reference systems and planetary models 49• Geocentric latitude, 4gc, as the angle measured at the Earth’s center from
the plane of the equator to the point of interest. Geocentric latitude is
equal to the spherical latitude definition.
• Geodetic latitude, 4gd, as the angle between the equatorial plane and the
normal to the surface of the ellipsoid. The latitude on most maps is
geodetic latitude.
To convert between geocentric latitude-longitude values and cartesian
coordinates, simple geometrical considerations are necessary. A position
with respect to the Earth can be defined as:
r ¼
2
6
6
4
rI
rJ
rK
3
7
7
5 ¼
2
6
6
4
r cos
4gc
cosðlÞ
r cos
4gc
sinðlÞ
r sin
4gc
3
7
7
5.
For locations on the Earth’s surface (i.e., r corresponding to the ellip￾soidal radius), we can define a conversion between geocentric and geodetic
latitude as:
tan
4gd
¼
tan
4gc
1  e
2
E
Note that the above equation can be inverted to compute 4gc from a
given 4gd, but it is valid only for locations on the Earth’s ellipsoid (i.e., on
the planetary surface). Neglecting the difference between geocentric and
geodetic latitudes can cause errors up to about 20 km.
Above the Earth’s surface, like for orbiting spacecraft, we shall first refer
to declination, d, and right ascension, a, with respect to the inertial celestial
sphere. Then, we shall convert to the Earth fixed position to find geodetic
latitude and longitude of the spacecraft’s sublatitude point. The sublatitude
point on the Earth’s surface is defined as the point which lies directly
perpendicular below the satellite, and it is generally different from the sur￾face point which lies along the position vector, as represented in Fig. 2.3.
When sublatitude point of the spacecraft is found, we can convert between
geocentric and geodetic latitudes of sublatitude point using the previous
equation valid on the planetary surface. In general, we shall note that
geocentric latitude of the spacecraft, 4gcsat , is conceptually equivalent to
declination, but geocentric and geodetic latitudes of sublatitude point on
the Earth’s surface are different from declination of the satellite.
50 Andrea Colagrossi et al.Converting the position vector of a satellite to the corresponding latitude
and longitude is the core technique in determining ground tracks and in
designing GNC applications with respect to the Earth’s (or planet’s) surface.
First, we need to remark that if the planet were a perfect sphere, the algebraic
relationship between spherical and cartesian coordinates would have a direct
solution. With ellipsoidal and more complex shapes, there exists two ways to
perform the transformation of position to latitude and longitude: one itera￾tive and one analytical.
Both methods are extensively described, also with pseudocode examples
in Ref. [6]. Here, we just want to highlight the main steps of the procedure.
The right ascension can be directly computed from the cartesian position
vector as:
sinðaÞ ¼ rJ ffiffiffiffiffiffiffiffiffiffiffiffiffi
r
2
I þ r
2
J
q and cosðaÞ ¼ rI ffiffiffiffiffiffiffiffiffiffiffiffiffi
r
2
I þ r
2
J
q ;
and the approximate conversion to longitude is basically an angular shift
with respect to the prime meridian reference:
l ya  qGMT ;
where qGMT is the right ascension of Greenwich mean meridian.
Figure 2.3 Spherical coordinates above ground and satellite sublatitude point.
Reference systems and planetary models 51This is only an approximate formula to explain the fundamental idea
behind this conversion, while the complete conversion is discussed in the
following, when the transformation between Earth-centered inertial (ECI)
and Earth-centered, Earth-fixed (ECEF) frames is presented. The next steps
to find the geodetic latitude are the most difficult, where the iterative
approach or the analytical one is used. To determine a starting value for
the iterations, we can use the position vector as a rough guess because the
declination and geocentric latitude of the satellite are equal:
sinðdÞ ¼ rK
r .
At this point, the geodetic latitude can be computed with one of the
dedicated methods described in the cited reference [6].
Geoid and geopotential models
The reference ellipsoid is a good approximation of the hypothetical surface
referred to as mean sea level (MSL). The actual MSL surface, excluding small
atmospheric effects, is called the geoid, and it deviates from the reference
ellipsoid because of the uneven distribution of mass in the Earth’s interior.
The geoid is a geopotential surfaceda plumb bob will hang perpendicular
to it at every pointdbecause the gravity potential is equal at all points
and the direction of gravity is always perpendicular to the geoid surface.
Hence, the concept of height relies on geopotential surfaces at which the
gravity is equal at all points. The geoid’s undulation, NE, is the geoid’s
height above the ellipsoid, whereas the actual height of the topography
above the geoid is called the orthometric height, HMSL. The latter is the
height we all used because of maps and road signs. Finally, the ellipsoidal
height, hellp, is like the orthometric height, but it’s measured perpendicular
to the ellipsoid and differs by the geoid undulation:
NE yhellp  HMSL.
The geoid definition is closely related to the gravity potential expressed
with spherical harmonics expansions, which will be extensively described in
Chapter 3dThe Space Environment. In fact, the geoid’s undulation can be
mathematically represented exploiting similar harmonics expansions. How￾ever, geoid’s undulation takes on values between þ85 and 107 m, and the
full series expansions must be used only for very precise applications. In most
GNC utilizations, NE can be tabulated in a grid of 1  1 or even
10  10. Locations not directly contained on the grid are found using
interpolation techniques and two-dimensional look-up tables. Note that
52 Andrea Colagrossi et al.the geoid geopotential model should be used in agreement with the used
gravitational model. For instance, EIGEN-GL04C geoid shall be used
together with EIGEN-GL04C gravitational coefficients, while WGS-84
geoid shall be used together with the EGM coefficients (e.g., EGM-96 or
EGM-08).
Coordinate reference systems
When a GNC system has to be designed and analyzed, one of the first
decision to take is the definition of a suitable reference system or a set of
them. We define a rectangular coordinate system by specifying its origin,
fundamental plane, and preferred positive directions. For most reference sys￾tems, the preferred positive directions have a right-handed sense. We use
three unit vectors to represent three orthogonal axes and express any other
vector in the coordinate system as a linear combination of the base unit vec￾tors. We have to bear in mind that, despite the definition in rectangular car￾tesian coordinates, the spherical coordinates may be obtained by converting
the vector components as described above. This can be helpful for some ap￾plications where two angles and a radius vector are more explicative than
three cartesian components.
Heliocentric coordinate system, XYZ
For GNC applications involving interplanetary missions, a coordinate refer￾ence system centered in the Sun is very useful. The Heliocentric Coordinate
System, XYZ, has its origin at the center of the Sun, and the fundamental
plane is the ecliptic. The primary direction for this system, X, is the intersec￾tion of the ecliptic and Earth’s equatorial planes. The positive direction of
the X axis is given by the location of the Sun with respect to the Earth as
it crosses the equatorial plane on the first day of spring: vernal equinox. In
other words, the vernal equinox, or first point of Aries, is the direction of
the line that joins the Earth with the Sun when the Sun’s declination is
0 and it changes from negative to positive. The Z axis is orthogonal to
the ecliptic plane, positive in the direction of the Earth’s angular mo￾mentum. The Y axis completes the right-handed triad. The location of
an object in this reference frame can be also expressed in terms of ecliptic
latitude and longitude.
In some cases, the center of the interplanetary reference system is at the
barycenter of the Solar System, and not at the center of the Sun, as in the
International Celestial Reference Frame (ICRF), which is the current
Reference systems and planetary models 53standard International Astronomical Union (IAU) inertial reference system.
The ICRF is defined through observations of compact extragalactic radio
sources. These astronomical objects are so far away that their expected mo￾tions should be negligibly small. The precise definition of an interplanetary
reference system may be subject to periodic reevaluation after accurate ob￾servations are performed to update the location of the reference astronom￾ical objects. In any case, the new solutions introduce no rotation from
previous realizations, since numerical operations benefit from the axes
remaining fixed.
Geocentric equatorial coordinate system, IJK (ECI)
This system originates at the center of the Earth. The fundamental plane is
the Earth’s equator. The I axis points toward the vernal equinox, and the K
axis extends through the North Pole. J completes the right-handed triad.
The geocentric frame can be also referred as ECI, and it is reported in
Fig. 2.4.
Since both the equinox and the equatorial plane slightly move over time,
due to precession, nutation, and other secular motions, the above definition
does not represent an inertial frame. A “pseudo” Newtonian inertial system
can be obtained by referring to the axes directions at a particular epoch,
specifying the transformations to move from the current epoch to the refer￾ence one and vice versa. Throughout the years, different reference systems at
epoch have been proposed:
Figure 2.4 Example of ECI. J2000 reference system.
54 Andrea Colagrossi et al.J2000 is an inertial frame realized in the IAU-76/FK5 system, which is
based on the Fundamental Katalog, FK5 star catalog. For many years, it has
been the standard reference system for geocentric coordinates. The system
exploits the equator, equinox, and polar axis directions at 12:00 (i.e.,
noon) TDB (Barycentric Dynamical Time), on January 1st, 2000. Numer￾ical data to transform other systems to the J2000 were obtained from the
IAU-1976 Precession Model and the IAU-1980 Theory of Nutation.
Geocentric Celestial Reference Frame (GCRF) is the geocentric counterpart
of the ICRF, and it is the current standard inertial coordinate system for the
Earth. To provide continuity with former references, the axes directions are
selected to be as close as possible to the J2000 frame. Note that only a very
small rotational difference (i.e., <0.1 arcseconds) exists between the two
frames. It was officially adopted in 1997, effectively replacing the IAU￾76/FK5 J2000 system. As the ICRF, the GCRF is subject to periodic reeval￾uations which increase the stability of the axes by adding more defining
sources and improving their coordinates. Nevertheless, the newest versions
do not introduce any rotations with respect to previous ones. The Interna￾tional Earth Rotation and Reference Systems Service (IERS) has maintained
tabulated corrections to transform a vector from the GCRF to the IAU-76/
FK5 J2000 frame.
These pseudoinertial systems are considered as inertial for precise orbit
determination and calculations. In this book, the acronym ECI will be
used interchangeably with the GCRF.
ECI spherical coordinates are commonly denoted as:
• Right ascension, a: the angle measured eastward on the plane of the equa￾tor from the vernal equinox to the celestial meridian that contains the
object.
• Declination, d: the angle between the equatorial plane and the object,
measured in the meridional plane that passes through the object, positive
above the equator.
• Radial distance: the distance between the Earth’s center and the object.
Geocentric earth-fixed coordinate system, IFJFKF
A geocentric coordinate system fixed to the rotating Earth results in the
ECEF coordinate frame. The ECEF is a noninertial geocentric coordinate
system that rotates with the Earth, and it is fixed with respect to the Earth’s
surface. The official IAU earth-fixed terrestrial frame is named the Interna￾tional Terrestrial Reference Frame (ITRF). The ITRF origin is at the center
Reference systems and planetary models 55of the Earth, and the axes have been defined through the coordinates of a set
of stations on the Earth’s surface. Since the tectonic plate motion affects the
position of these reference locations, the ITRF is regularly updated such that
there is no net rotation with respect to previous versions. In this book, the
acronym ECEF will be preferably used for referring to the ITRF. In the
ITRF, the Z axis is parallel to the direction of the North Pole, the X axis
is defined as the intersection between the fundamental plane (perpendicular
to Z) and the Greenwich mean meridian. The Y axis is orthogonal to X and
Y. ECEF frame is reported in Fig. 2.5.
As this coordinate system rotates, the epoch when observation and data
are acquired must be specified to allow the transformation to the ECI/
GCRF system. The time precision to perform this transformation is crucial
to maintain the accuracy of the measurements without introducing rotation￾related errors. The ECEF is based on the Earth’s equatorial plane. It is espe￾cially useful to process satellite observations to/from a specific site and to
convert Earth-based data to ECI for further processing.
ECEF spherical coordinates are differently denoted with respect to the
ECI as:
Figure 2.5 Example of ECEF reference system. l and 4 are the east longitude and
geocentric latitude, respectively.
56 Andrea Colagrossi et al.• East longitude, l. The angle measure eastward in the equatorial plane,
from the Greenwich meridian to the meridian containing the object.
• Geocentric latitude, 4gc. The angle between the object and the equatorial
plane, measured in the meridional plane that passes through the object,
positive above the equator.
A similar reference frame exists, and it is based on the WGS-84 model. It
is practically identical to the ITRF; however, it has been defined through
Global Positioning System (GPS) measurements. The WGS-84 and the
ITRF differ only at cm level. Within the uncertainty of the WGS-84 frame,
they are equivalent.
Orbit determination and many GNC applications typically require both
celestial inertial reference frames and terrestrial (or planetary) reference
frames. The former defines the Newtonian-inertial space in which differen￾tial equations of satellite motion are valid, while the latter is commonly used
to take some relevant observations and measurements.
Topocentric coordinate systems
Topocentric coordinate systems are centered at a site on the Earth’s surface.
So, they are Earth-based systems, but they are not geocentric. Different
topocentric frames exists; a brief survey is here reported.
Topocentric equatorial
This system is equal to the geocentric equatorial coordinate system (ECI),
but it has the origin translated from the Earth’s center toward the observer
location on the Earth’s surface. The directions of the axes are parallel to the
ECI reference frames. The location of an object is then identified through its
topocentric right ascension and declination. However, since the geocentric and
topocentric systems do not have the same origin, for an earth-orbiting sat￾ellite, the topocentric right ascension and declination will be different
from the geocentric ones. On the other hand, if the object is far away
from Earth (e.g., distant planets or stars), the difference between the two po￾sition vectors becomes negligible. It is mainly used for highly accurate opti￾cal systems.
Topocentric horizon
In a topocentric horizon coordinate system, the fundamental plane is defined
by the local horizon (i.e., the plane tangent to the ellipsoid at the observer
location), and the reference is centered at the observer site on the Earth’s
Reference systems and planetary models 57surface. If the observer is not located on the Earth’s surface (e.g., an aircraft),
the fundamental plane is still oriented along the geodetic directions defined
by the Earth’s surface below it. Topocentric horizon coordinate systems are
very useful in observing satellites from ground, and they are used extensively
with Earth-based sensor systems. Depending on which directions the refer￾ence axes are pointing, different topocentric horizon frames exist:
• SEZ (South, East, Zenith). The X axis points south, even in the southern
hemisphere. The Y axis is directed east from the site and is undefined for
the North or South Pole. The Z axis points radially outward from the
site, along the site’s local vertical (i.e., the Zenith). Fig. 2.6 reports an
example of SEZ reference frame.
• NED (North, East, Down). The X axis points north, the Y axis is directed
eastward, and the Z axis points inwards, toward the nadir. This system is
particularly useful on-board of airplanes, as most objects of interest are
below the aircraft.
Figure 2.6 Topocentric horizon reference system, SEZ.
58 Andrea Colagrossi et al.• ENZ (East, North, Zenith). The X axis points east, the Y axis is directed
north, and the Z axis points outwards toward the Zenith. It is obtained
by rotating the SEZ reference frame of 90 around the Z axis.
Note that the observer location on the Earth is defined as exploiting
geodetic latitude and right ascension of the site, aL: Alternatively, east longi￾tude of the site may be used, but the right ascension of the prime meridian
must be known.
Topocentric reference spherical coordinates are denoted as:
• Azimuth, b. The angle measured from north, clockwise (as viewed from
above) to the location beneath the object of interest.
• Elevation, el. The angle measured from the local horizon, positive up to
the object of interest. It takes on values from 90 to 90. We rarely
encounter negative values for sites on the Earth, but they often appear
with an orbiting satellite.
Lunar coordinate systems
There is not an official definition of a Lunar-Centered Inertial (LCI) refer￾ence frame; however, such system can be straightforwardly obtained by
translating the origin of the GCRF toward the Moon center. On the other
hand, different lunar-fixed reference systems have been proposed.
Mean earth/polar axis
The Mean Earth/Polar Axis (ME) reference system is a lunar body-fixed co￾ordinate system. It exploits the mean direction of Earth to define the prime
meridian (i.e., 0 in longitude). In some reference, this system is also referred
to as the Mean Earth/Rotation Axis (MER) system.
The first axis, XME, is pointing in the mean Earth direction. YME is
perpendicular to the X and Z axes, forming a right-handed triad. The third
axis, ZME, is parallel to the lunar mean rotational pole. The intersection be￾tween the lunar equator and the lunar prime meridian is named the Moon’s
mean sub-Earth point. This concept of “sub-Earth point” originates from the
fact that the Moon’s rotation is tidally locked to Earth (i.e., the rotation and
orbital period are equal). The true sub-Earth point is subject to slight vari￾ations in time due to the lunar’s orbit eccentricity and other perturbations;
thus, a mean point is exploited. In its latest release, this point does not coin￾cide with any crater or surface feature; however, it happens to be close to the
Oppolzer A crater. The spherical coordinates for this system, also known as
selenocentric coordinates, work the very same way of the planetocentric longi￾tude and latitude, ranging from 0 to 360 and from 90 to 90,
respectively.
Reference systems and planetary models 59Principal axes
The Principal Axes (PA) reference system is a lunar body-fixed coordinate
system, whose axes are defined by the PA of inertia of the Moon. Their di￾rections are taken from analyses of the Gravity Recovery and Interior Lab￾oratory data. Historically, the PA reference system has been especially useful
for dynamical studies on the lunar gravity field and for Lunar Laser Ranging.
An ellipsoidal Moon with only a second-degree gravity contribution would
have its principal and mean Earth axes parallel. However, third- and higher￾degree coefficients of the gravitational model cause a rotation between the
PA and ME frames, which leads to a difference of about 1 km on the lunar
surface.
The orientation of the ME and PA frames with respect to their inertial
counterpart (i.e., LCI) is written as a function of 3 libration angles, whose
expressions are simultaneously integrated with the lunar orbital
ephemerides.
Three-body synodic and inertial coordinate systems, XsYsZs
and XIYIZI
When three-body problems are analyzed, three-body synodic coordinate
systems are commonly used. These reference frames are rotating with the
two primary bodies, they are centered at the center of mass of the three￾body system (e.g., barycenter of the two primary celestial objects), and the
fundamental plane contains the orbits of the primaries. The first axis, XS,
is aligned with the instantaneous rotating vector from the first primary
body to the second one. The ZS axis is in the direction of the angular mo￾mentum of the two primary bodies rotating about their common barycen￾ter. The last axis, YS, completes the right-handed triad.
An inertial frame, XIYIZI, can also be used in three-body problems. It
has the same center and fundamental plane of the synodic reference. The
reference directions are aligned with the synodic frame at an epoch. Thus,
three-body inertial reference systems are defined fixing the relative position
between the primary bodies at a reference time.
Lunar Centered ROTating
The Lunar Centered ROTating (LCROT) frame is a three-body synodic
reference system centered at the center of the Moon. This reference frame is
often used to investigate the behavior of the Cislunar environment in lunar
vicinity. This reference frame is constructed translating the origin of the
EartheMoon synodic reference in the Moon’s center. The first axis, XS,
60 Andrea Colagrossi et al.is parallel to the instantaneous EartheMoon direction. The ZS axis is
perpendicular to the EartheMoon orbital plane, being aligned with the
orbital angular momentum of the two primary bodies. The third axis, YS,
is orthogonal to XS and ZS, completing the right-handed triad.
Satellite-based coordinate systems
Many satellite-based reference systems exist, but most of their nomenclature
isn’t standard, and many systems are developed for specific satellite missions.
The fundamental point is that satellite-based coordinate systems are based on
the plane of the satellite’s orbit. They use the classical orbital elements to
describe object locations.
Perifocal coordinate systems, PQW
The perifocal coordinate system, PQW, is a satellite’s orbit-based reference
frame. It has the fundamental plane on the satellite’s orbital plane, and the
origin is at the center of the Earth. The P axis points toward perigee, and
the Q axis is 90 from the P axis in the direction of satellite motion. The
W axis is along the orbital angular momentum. This reference frame is
convenient for processing satellite observations.
Satellite coordinate system, RSW (LVLH)
The satellite coordinate system, RSW, moves with the satellite, and it is
commonly referred as LVLH (Local Vertical, Local Horizontal). The origin
of the LVLH frame is the satellite. The R axis always points out from the
satellite along the Earth’s radius vector to the satellite as it moves through
the orbit (Local Vertical). The W axis is normal to the orbital plane. The
S axis completes the right-handed triad. The S axis is perpendicular to the
radius vector (Local Horizontal), and it is pointed in the direction of the ve￾locity vector. Note that the S axis is usually not aligned with the velocity
vector, except for circular orbits or for elliptical orbits at apogee and perigee.
Concerning the terminology for satellite motion:
• Radial motions are parallel to the position vector (i.e., along the R axis).
• Along-track or transverse displacements are normal to the position vector
(i.e., along the S axis).
• Cross-track positions are normal to the plane defined by the current po￾sition and velocity vectors (i.e., along the W axis).
Some applications define the satellite coordinate frame in different ways.
For example, alternative definitions of the LVLH place the primary axis
perpendicular to the radius vector, the second axis opposite the angular
Reference systems and planetary models 61momentum vector, and the third axis pointing to the Earth’s center. We
need to be sure which convention is assumed in the considered application.
The satellite coordinate system can be effectively defined in attitude dy￾namics as an “airplane-like” reference frame. Indeed, the LVLH can be
rotated to define the roll-pitch-yaw axes:
• Roll axis is the same as the S axis of RSW (i.e., þ S).
• Yaw axis is opposite to the position vector, points toward the center of
the Earth, and also lies in the orbital plane (i.e., R).
• Pitch axis is opposite to the angular-momentum vector (i.e., W).
In this book, the RSW is mainly referred according to the above defini￾tion and named Di;j;k. In the comoving frame LVLH-based Gm;n;p, differ￾ently from Di;j;k, the radial direction toward the attracting body is called z
axis, whereas the y axis is opposite to the angular momentum vector. The
following rotation holds from Gm;n;p to Di;j;k:
DRG ¼
2
6
6
4
0 0 1
10 0
0 1 0
3
7
7
5:
Satellite body coordinate systems, b1b2b3
The satellite body coordinate systems, b1b2b3, are commonly centered at the
center of mass or at the geometrical center of the satellite. Their axes are
aligned with notable body-defined directions, such as the geometrical axes
or the principal inertia axes. These reference frames are mainly used for atti￾tude dynamics or for GNC applications based on the spacecraft body. There
is not a standardization of these coordinate systems, and they are usually
developed for specific satellite missions.
The most common satellite body reference frame is the principal inertia
one, since it is typically used to describe the spacecraft attitude dynamics.
The principal inertia reference frame is centered at the barycenter of the
spacecraft, and its axes are aligned with the principal inertia directions, b1,
b2, b3, of the rigid body, composing a right-handed triad.
Auxiliary satellite body coordinate systems
Auxiliary satellite body coordinate systems can be defined. They can be
centered in relevant points of the spacecrafts (e.g., payload location, center
of pressure, sensors, etc.). The axes of these references can be aligned along
important reference directions (e.g., solar panels axes, main geometrical
62 Andrea Colagrossi et al.directions, sensor line-of-sight, etc.). They cannot be standardized since they
are only defined according to the specific application requirements. Howev￾er, they should be right-handed triads, and they should be defined by a rigid
roto-translation with respect to the main satellite body coordinate system.
To avoid confusion, they are introduced in the book immediately after their
use, with a unique coordinate naming.
Coordinate transformations
Coordinate transformations can be derived every time the definition
of two different reference frames is known with respect to each other’s.
An alternative to derive the required transformation is knowing the defini￾tion of each reference system with respect to a third one.
The transformation matrices exploited to perform elementary rotations
between the reference frames use the right-hand rule to define the sign of
the rotations. There exist different sequences of rotation angles according
to the specific transformation in use. In fact, two reference frames can be
aligned exploiting a generic sequence of three rotations around the reference
frame axes, and the coordinate transformation is characterized by the specific
order of the axes around which the rotations are performed. This concept
will be discussed again in the Chapter 5dAttitude.
Now let’s assume a coordinate transformation exploiting three consecu￾tive rotations around the x, y, and z axes. This rotation sequence is denoted
as “x-y-z,” and it is associated to the following rotation matrices:
Rxð Þ¼ a
2
6
6
6
4
10 0
0 ca sa
0 sa ca
3
7
7
7
5
Ryð Þ a ¼
2
6
6
6
4
ca 0 sa
01 0
sa 0 ca
3
7
7
7
5
Rzð Þ¼ a
2
6
6
6
4
ca sa 0
sa ca 0
0 01
3
7
7
7
5
Reference systems and planetary models 63where ca ¼ cosðaÞ, sa ¼ sinðaÞ and a is a generic rotation angle along the
relevant axis of the right-handed reference frame. The reader should pay
attention to the specific order of the rotation sequence, and, in general, it is
advised to work out the elementary rotations for any transformation in use,
as it will be done in the next paragraphs. Note that the signs used to compute
the rotation sequence depend on the rotation order. If the rotation goes
in the positive right-hand rule direction, the angle is positive. On the
contrary, the rotation goes in the negative direction and the angle has the
opposite sign.
ECI to ECEF
The transformation between the ECI (GCRF) and the ECEF (ITRF) is per￾formed through a series of rotations that are known as Earth orientation model.
There are two different approaches to perform such operation: the classical
equinox-based transformation and the Celestial Intermediate Origin approach.
The latter is defined in the IAU2010 convention; a summary of the various
contributions is here reported:
• Polar motion. It is defined as the motion of the rotation axis with respect
to the crust of the Earth. The rotation axis of Earth, perpendicular to the
true equator, is named the Celestial Intermediate Pole (CIP). Thus, this
transformation accounts for the change of basis between the ITRF and
the Pseudo-Earth Fixed (PEF) frame.
• Earth rotation angle or sidereal time. It considers Earth rotation and allows to
switch from the rotating frame to a nonrotating set of axes. The IERS
does not provide this angle, but its associated time scale, UT1. In fact,
this transformation requires knowledge of the Greenwich apparent side￾real time, which is obtained from the equation of the equinoxes.
Formally, the definition allows to switch from the rotating coordinate
frame (PEF) to a nonrotating True of Date (TOD) frame.
• Nutation. It accounts for the periodic effects primarily due to the Moon,
which consist in small oscillations in the Earth’s rotation axis. This oper￾ation transforms from the TOD to the Mean equator of Date (MOD)
frame.
• Precession. This transformation accounts for the perturbations due to the
Sun, Moon, and other planets’ gravitational forces on the Earth’s orbit.
Specifically, precession results in a slow secular decrement of the ecliptic
obliquity (e.g., 0.013/century) and in a westward precession of the
equinox (e.g., 0.0033/century). As a result, it causes a roughly circular
motion of Earth’s rotation axis over each period of precession
(26.000 years). This final process converts a vector in the MOD frame
64 Andrea Colagrossi et al.to a vector in the ECI frame. Depending on the approach used, a com￾bined PN matrix can be exploited.
The position, velocity, and acceleration transformations take the form of:
rECI ¼ PðtÞNðtÞRðtÞWðtÞrECEF (2.1)
vECI ¼ PðtÞNðtÞRðtÞðWðtÞvECEF þ uE  rPEFÞ (2.2)
aECI ¼ PðtÞNðtÞRðtÞ½WðtÞaECEF þ uE  ðuE  rPEFÞ þ 2uE  vPEF
(2.3)
with:
rPEF ¼WðtÞrECEF vPEF ¼ WðtÞvECEF
where P and N are the precession-nutation matrices of date t, R is the
sidereal-rotation matrix of date t, W is the polar-motion matrix of date t, and
uE represents the rotation rate of the Earth. The complete expressions of
these matrices are available in Ref. [6] and in the appendix Chapter 16d
Mathematical and Geometrical Rules.
The angles required to perform all these rotations are provided as five
Earth Orientation Parameters (EOPs) data, officially released and maintained
by the IERS:
• Universal Time (UT1). It is a standard time that reflects the average speed
of the Earth’s rotation, using the prime meridian as a reference point.
The excess of the rotation period with respect to the mean period is
called Length of Day. The difference between UT1 and UTC is indicated
as DUT1, and it is periodically corrected to ensure its absolute value al￾ways remains below 0.9. This will be discussed with more details in the
section about Time.
• Coordinates of the pole. The angles that describe the polar motion are
expressed as the displacements of the CIP with respect to the International
Reference Pole, which is the agreed location of the terrestrial pole.
• Celestial pole offsets. They provide the difference of the actual celestial mo￾tion with the one predicted by the conventional IAU precession/nuta￾tion model. Depending on the adopted approach, they are either
expressed as the offsets in longitude and in obliquity of the celestial
pole (Dj, Dε) or as the coordinates of the CIP in the ICRS (dX, dY).
The transition between them is reported in the IERS technical note [7].
These values are daily updated by the IERS and published in different
bulletins. EOP data are comprehensive of all values since 1962, including
180 days of predictions. Several interpolations are also available.
Reference systems and planetary models 65ECI to PQW
The transformation between ECI and perifocal frame (PQW) is here re￾ported due to its wide use in orbital mechanics. Nevertheless, it is a simple
transformation comprising three consecutive rotations of notable angles,
which are defined as orbital elements. Indeed, the transformation yields
the necessary rotation to express a vector from ECI to a reference frame
that is coplanar with the orbit being analyzed.
1. Right ascension of the ascending node rotation: it is a rotation along the Z-axis
of the ECI reference frame, as shown in Fig. 2.7. The rotation matrix can
be expressed as:
RU ¼
2
6
6
4
cosU sinU 0
sinU cosU 0
0 01
3
7
7
5
2. Inclination rotation: it is a rotation along the I’ axis of the transformed
reference frame, as shown in Fig. 2.8. The rotation aligns the new Z￾axis with the orbital angular momentum vector. The rotation matrix
can be expressed as:
Ri ¼
2
6
6
4
10 0
0 cosi sini
0 sini cosi
3
7
7
5
Figure 2.7 RAAN rotation from ECI to PQW.
66 Andrea Colagrossi et al.3. Argument of pericenter rotation: it is a rotation along the I’ axis of the trans￾formed reference frame, as shown in Fig. 2.9. The rotation aligns the
new X-axis with the periapsis. The rotation matrix can be expressed as:
Ru ¼
2
6
6
4
cos u sin u 0
sin u cos u 0
0 01
3
7
7
5
Hence, the final transformation from ECI to PQW or vice versa can be
expressed as:
PQW RECI ¼ RuRiRU
ECIRPQW ¼ PQW RT
ECI ¼ RT
URT
i RT
u
ECI to RSW (LVLH)
Similar to the previous paragraphs, an important and common reference
frame transformation is the one used to express vectorial quantity from
ECI to RSW (or LVLH) frame. We recall that the RSW is a comoving
frame attached to the spacecraft center of mass. Let us assume that the orbital
position and velocity in the ECI frame is given by the vector rðtÞ and vðtÞ,
and the constant specific angular momentum is calculated as
Figure 2.8 Inclination rotation from ECI to PQW.
Reference systems and planetary models 67h ¼ rðtÞ  vðtÞ. Using the definition of the RSW reference frame, we can
express the rotation matrix between ECI to RSW, and vice versa, as:
RSW RECI ¼
2
6
6
4
r
h  r
h
3
7
7
5
RSW RECI ¼ RSW RT
ECI
where r and h are the normalized unit vectors.
Being the RSW reference frame defined based on the orbital state of the
spacecraft, it is possible to derive the rotation matrix from RSW to ECI us￾ing the orbital elements of the spacecraft orbit, as:
RSW RECI ¼
2
6
6
4
cosðnÞcosðUÞ  sinðnÞcosðiÞsinðUÞ sinðnÞcosðUÞ  cosðnÞcosðiÞsinðUÞ sinðiÞsinðUÞ
cosðnÞsinðUÞ þ sinðnÞcosðiÞcosðUÞ sinðnÞsinðUÞ þ cosðnÞcosðiÞcosðUÞ sinðiÞcosðUÞ
sinðnÞsinðiÞ cosðnÞsinðiÞ cosðiÞ
3
7
7
5
where n ¼ u þ q is the true latitude, with q the true anomaly.
Figure 2.9 Argument of perigee rotation from ECI to PQW.
68 Andrea Colagrossi et al.Time
The main purpose of time is to define with precision the moment of
an event. This moment is referred to as the epoch of the event; thus, the
epoch designates a particular instant described as a date. The date is defined
as a certain time interval elapsed from a reference epoch. For instance, the
days passed from a reference event, or the years, months, days, hours, mi￾nutes, and seconds from the year zero. To have a practical time system,
we need a precise, repeatable time interval measurement, which is based
on some physical phenomenon that we can easily measure. Current time￾keeping for scientific, engineering, and general-purpose applications are
based on:
• Sidereal time.
• Solar time.
• Dynamical time.
• Atomic time.
Sidereal time and solar time are based on the Earth’s rotation and are
related through mathematical relationships. Dynamical and atomic time
are independent from the other forms.
Solar time is loosely defined by successive transits of the Sun over a local
meridian, while sidereal time is defined as the time between successive tran￾sits of the stars over a specific meridian. However, the apparent motion of
celestial objects in the sky is not regular, and so we had to define a constant
pace time reference. The concept of universal time, UT, was adopted years
ago. It’s based on a fictitious mean Sun with uniform motion in right ascen￾sion along the equator. This fictitious mean Sun is now defined mathemat￾ically as a function of the sidereal time. So, ultimately, we derive UT from
sidereal time.
Dynamical time measures time by analyzing the motion of celestial
bodies, such as the Earth’s motion about the Sun. In this case, the measure
of the time is associated to the ephemerides of the celestial objects. Terres￾trial time, TT, and TDB are common dynamical time references, which are
equivalent for the vast majorities of applications.
Finally, whenever accurate time measurements are needed, atomic time
shall be used. The International Atomic Time, TAI, is based on counting the
cycles of a high-frequency electrical circuit maintained in resonance with a
cesium-133 atomic transition. One SI (International System) second equals
the duration of 9 192 631 770 periods of the wavelength associated with the
radiation emitted by the electron transition between two hyperfine levels of
Reference systems and planetary models 69the ground state of cesium-133 at 0 K. TAI achieves a precision that permits
the observation of relativistic effects for clocks in motion or accelerated by a
local gravitational field.
Universal time
Going back to the most common UT, we shall consider that there are three
distinct realizations of UT. For precise applications, we must distinguish be￾tween UT, UT0 and UT1, even if the differences are small. Note that
Greenwich mean time, (GMT), the local time in England, is not equivalent
to UT. For this purpose, it’s useful to introduce procedures that determine
the various forms of UT and to distinguish their differences.
At first, we must define the UT as the mean solar time at Greenwich.
The mean solar time is derived from measurements of the Earth orientation
with respect to the apparent Sun. Then, the difference between apparent so￾lar time and mean solar time can be computed from the equation of time,
which describes the discrepancy between these two kinds of solar time
[8]. Note that the apparent solar time is the interval between successive tran￾sits that we observe from a particular longitude, and thus the length of each
apparent day differs by a small amount.
UT0 is found by reducing the observations of stars from many ground
stations. This is done because the motion of the Sun (i.e., UT) cannot be
measured with enough precision, while the apparent motion of the stars,
or radio galaxies can be tracked with great accuracy. UT0 is calculated as
12 h plus the Greenwich Hour Angle. Indeed, when the Greenwich hour
angle is 0 (i.e., the Sun is exactly over the prime meridian), the UT0 shall
be 12:00.
Then, we correct UT0 for polar motion, so the time is independent of
station location to obtain UT1. Differences from UT0 are typically about
30 milliseconds, and they can be computed exploiting the Earth orientation
model and the tabulated EOP. However, UT1 is commonly tabulated and
given to be directly used in GNC applications. Moreover, UT1 is the refer￾ence time for reference frame conversion calculation.
The most commonly used time system is Coordinated Universal Time,
UTC, which is derived from an ensemble of atomic clocks. It’s designed to
follow UT1 within 0.9s:
DUT1 ¼ UT1  UTC.
Because UT1 varies irregularly due to variations in the Earth’s rotation,
we must periodically insert leap seconds into UTC to keep the two different
70 Andrea Colagrossi et al.time scales in close agreement. UTC is the basis of civil time systems and is
on ordinary clocks. The local time in England, GMT, is thus associated to
the time zone UTCþ00:00, and not the solar definition of the UT.
Satellite often uses GPS time. This time system began with the introduc￾tion of the GPS system operational capability in 1980: the GPS epoch is
January 6, 1980, 00:00 UTC. GPS time is not adjusted, so it differs from
UTC by the number of leap seconds:
GPS ¼ UTC þ DAT  19:0s:
DAT represents the number of leap seconds posing the difference be￾tween GPS and UTC times, and 19s is the delta between GPS time and
atomic clock time, TAI:
GPS ¼ TAI  19:0s.
As a result, atomic time relates to UTC as:
TAI ¼ UTC þ DAT:
UTC always differs by an integer number of leap seconds from TAI (i.e.,
DAT), but the two reference times are maintained on a daily basis to keep
them within one microsecond from each other, although they are usually
much closer.
The TT also relates to TAI by a constant offset as:
TT ¼ TAI þ 32:184s.
Looking at the offsets between the reference times, graphically repre￾sented in Fig. 2.10, we can note that the difference in atomic time, DAT,
remains constant until changed with a leap second, whereas the difference
in coordinated and universal time, DUT1, changes continuously. Time off￾sets to the GNSS/GPS satellites are needed when determining navigation
information.
Julian dates
Time intervals are managed in UTC counting years, months, days, hours,
minutes, and seconds from a reference epoch, the beginning of Christian
era. This results in a date format composed by six variables, with different
time interval meanings. Moreover, the calendar dates contain periodic cycles
with discrete steps through the addition of leap years and seconds. To avoid
these problems, time for spacecraft applications is conveniently managed
exploiting the JDs. The JD is a continuous interval of time measured in
days from the epoch January 1, 4713 B.C., 12:00. JDs are precisely
Reference systems and planetary models 71365.25 days per year (i.e., a leap year every four years). Note that the
convention starts each JD at noon each day.
The JD values are typically very large, so we may be tempted to use only
a few decimal places. However, because the units are days, it is suggested to
retain at least eight decimal digits to provide reasonable accuracy (i.e., about
4  10e4 s). The most precise approach for GNC and numerical applica￾tions is to split the JD into a day and factional day part.
Finally, the IAU recommends using a Modified Julian Date, MJD,
commonly calculated as follows:
MJD ¼ JD  2400000:5:
MJD reduces the size of the date by about two significant digits, and it
can reduce potential confusion because it begins each day at midnight
instead of noon. Moreover, additional MJDs can be defined for specific ap￾plications. For instance, JDs since GPS epoch (i.e., GPS-JD), or since specific
recent epochs (i.e., J2000-JD, J2020-JD) can further improve the reduction
of the significant digits of the date.
Few commonly used epochs are:
GPS epoch ¼ 2 444 244.5 ¼ January 6, 1980e00:00:00.000 UTC
J2000.0 ¼ 2 451 545.0 ¼ January 1, 2000e12:00:00.000 TDB (TT)
Figure 2.10 Reference time conversion with respect to TAI.
72 Andrea Colagrossi et al.J1900.0 ¼ 2 415 021.0 ¼ January 1, 1900e12:00:00.000 TDB (TT)
As desired, the JD provides a continuous, simple, concise method of pre￾serving year-month-day-hour-minute-second information in one variable,
which is especially nice for computer and GNC applications. However,
the time accuracy reduction due to JD large numbers shall be considered,
and proper numerical techniques shall be implemented to avoid too coarse
time values.
What is relevant for GNC?
Planetary models, reference systems, and time intervals are among the
fundamental elements on which every GNC subsystem is based. Hence,
they shall be taken in great consideration since the beginning of the GNC
design.
In these regards, the accuracy of the models, reference frame conversions,
and timekeeping shall be in agreement with the accuracy of the whole GNC
system. It is pointless to convert reference frames with accuracies down to
the millimeter, and then have navigation precision in the order of the kilo￾meter. Similarly, maintaining the deviation with respect to UTC within one
microsecond is not wise if the on-board clock accuracy is one second. These
considerations are valid for any section of the GNC design, but they are
fundamental when dealing with standard references and basic models.
The used references shall be selected in agreement with each other, and
in accordance with the prescription of the international standards. The spe￾cific references to be used to model the environment will be discussed in
Chapter 3dThe Space Environment. However, to make some examples,
the IGRF geomagnetic model shall be used together with the WGS-84
ellipsoid, similarly the EGM gravitational models shall be used with the
WGS-84 geoid, while EIGEN-GL04 gravity model shall be used in agree￾ment with its geoid definition. The European designs are invited to use the
latter, while in the United States, the former is used. Also, the time refer￾ences shall be selected in agreement with the used models. For instance,
the astronomical ephemerides typically use the number of Julian centuries
from J2000, while the reference frame rotations use UT1 and the TT. In
these regards, the relations between the reference times shall be considered,
and the time conversions shall be performed with the accuracy required by
the GNC system.
Time accuracy is one of the critical aspects to consider when dealing with
GNC and with reference frame conversion. In fact, considering that a
Reference systems and planetary models 73spacecraft is orbiting with a velocity in the order of km=s, errors in the order
of milliseconds immediately result in few meters of additional errors. This
has even a deeper impact if a reference frame conversion is performed inside
the GNC functions. In fact, in this case, the errors can be magnified because
the position, plus the time-induced errors, is rotated in a reference frame
which is not coincident with the correct one because of the time delay of
the conversion. Thus, accurate GNC system shall take into account the
time offsets DUT1 and DAT. The latter is seldom modified, but the former
is frequently updated, and dedicated uploads of the new values shall be
planned.
This last point opens to the general comment on the on-board availabil￾ity of ancillary data used to set-up reference models and conversions. In fact,
EOPs, IGRF, and geopotential coefficients, as well as updated reference
time offsets values shall be known to guarantee the proper calculations in
the GNC functions. Moreover, these values shall be known with an accu￾racy level which is in agreement with the accuracy of the GNC. To make
some examples, neglecting DUT1 correction leads to error in the order of
100 m in position and 0.02 m/s in velocity. Even worse if GPS time is
directly associated to UTC or UT1, since the resulting error is in the order
of 10 km and 10 m/s. A simple ECI-ECEF rotation, without EOP data, in￾troduces an error in the order of 30 km and 40 m/s. Considering the preces￾sion reduces the error to 200 m and 0.25 m/s, while adding the nutation
effects brings down the error to 15 m and 0.1 m/s. If continuous updates
of EOP are not possible (i.e., an update frequency of one month would
be suggested), linear interpolation for these parameters can be used [9]. In
this case, using interpolated EOP, the reference frame transformation errors
are in the order of 2 m and 0.002 m/s. Note that a good interpolation is
possible for polar motion, precession, nutation, and length of the day, while
DUT1 cannot be effectively interpolated. Then, DUT1 should updated
with a frequency in the order of one month.
A final consideration shall be dedicated to numerical precision in man￾aging these quantities. In fact, most of the GNC software is based on
single-precision floating-point values, since double-precision floating￾point numbers are more demanding in terms of computational resources.
However, reference frame and time conversion should be performed in
double precision. In fact, despite single precision is intrinsically responsible
for a position accuracy not better than 0.5 m in Launch and Early Orbit
phase, due to float truncation errors, single precision ECI-ECEF transforma￾tion may lead to 10 km and 50 m/s spike errors in the converted data.
74 Andrea Colagrossi et al.Hence, reference frame conversion should be computed in double preci￾sion, and then the output converted to single precision, if this down￾scaling is needed. The numerical precision is an issue also for timekeeping
in JDs. If the JD is not divided in integer and fractional part, the single pre￾cision values can have a maximum resolution not better than few hours in
the present days. Using MJDs with respect to more recent epochs (e.g.,
GPS-JD or J2020-JD) can improve the single precision date resolution to
a few seconds. The best practice is to divide any JD in integer and fractional
parts. In this case, considering the single precision data type, according to
IEEE Standard 754, the day units can have a resolution of w1  107 d,
corresponding to around 0.01 s. Anyway, it is evident how double￾precision floating-point numbers should be used for JDs operations, and
in general for all timekeeping functions. Furthermore, it is globally suggested
not to use JDs in GNC applications, but to use MJD, GPS-JD, or the JD at
the epoch of the IGRF model (i.e., IGRF-13 to be used with J2020-JD).
References
[1] ICAO, World Geodetic Systemd1984 (WGS-84) Manual, 2002.
[2] F.G. Lemoine, S.C. Kenyon, J.K. Factor, et al., The Development of the Joint NASA
GSFC and NIMA Geopotential Model EGM96, NASA Goddard Space Flight Center,
Greenbelt, Maryland, 20771 USA, July 1998.
[3] K.P. Nikolaos, A.H. Simon, C.K. Steve, K.F. John, EGM2008: the development and
evaluation of the earth gravitational model 2008 (EGM2008), Journal of Geophysical
Research: Solid Earth 117 (B4) (April 2012), https://doi.org/10.1029/2011JB008916.
[4] ECSS-E-ST-10-04C, Space Engineering e Space Environment, 2008.
[5] E. Gregersen, Cavendish Experiment, Encyclopedia Britannica, 17 January 2019.
Accessed 15 March 2022, https://www.britannica.com/science/Cavendish￾experiment.
[6] D.A. Vallado. Fundamentals of Astrodynamics and Applications, Space Technology Li￾brary, Microcosm Press, 2013.
[7] G. Petit, B. Luzum, IERS Conventions (2010), IERS Technical Note No. 36, in: IERS
Technical Note No. 36, International Earth Rotation and Reference Systems Service,
Frankfurt am Main, 2010.
[8] D.W. Hughes, B.D. Yallop, C.Y. Hohenkerk, The equation of time, Monthly Notices
of the Royal Astronomical Society 238 (June 15, 1989) 1529e1535.
[9] D.A. Vallado, T.S. Kelso, Earth orientation parameter and space weather data for flight
operations, in: 23rd AAS/AIAA Space Flight Mechanics Meeting, American Institute of
Aeronautics and Astronautics (AIAA), 2013. AAS 13-373.
Reference systems and planetary models 75This page intentionally left blankCHAPTER THREE
The space environment
Andrea Capannolo1
, Emanuele Paolini2
, Andrea Colagrossi1
,
Vincenzo Pesce3
, Stefano Silvestrini1
1
Politecnico di Milano, Milan, Italy
2
D-Orbit, Fino Mornasco, Italy
3
Airbus D&S Advanced Studies, Toulouse, France
All the bodies in space interact with the surrounding environment: the space
environment. This strongly influences the design of a space mission, for what
concern the materials to use, the suitable electronical components, and, in
general, most of the design choices leading to an operative spacecraft.
Regarding the guidance, navigation, and control (GNC) system, the most
relevant aspects of the space environment to consider are the perturbation
forces and torques. Whenever a spacecraft is on orbit, it is subject to the in￾fluence of many perturbation sources that affect its dynamics. Hence, the
GNC system shall manage these effects in order to properly control the space￾craft’s motion. This chapter explains the concept of perturbation, discussing
the major external and internal perturbations sources. External perturbations
are those properly related with the surrounding space environment, while in￾ternal perturbations are related with the elements inside the spacecraft, which
anyway influences the satellite dynamics. The combination of the two com￾poses the complete space environment. As a matter of fact, the internal
perturbation sources are characterized by the fact the satellite is in space
and not on ground. This chapter is composed by the following sections:
• Perturbation sources. This section has the purpose of introducing the main
perturbation sources influencing the spacecraft dynamics.
• External perturbations. In this section, the external perturbations effects are
introduced. Gravitational and magnetic contributions, atmospheric drag,
solar radiation pressure (SRP), and third-body perturbations are
described.
• External perturbations modeling guidelines. The main guidelines to model
the presented external perturbations, while designing a GNC system,
are given in this section.
• Internal perturbations. The internal perturbative sources are detailed in this
section. Flexibility and sloshing are introduced as well as electromagnetic
Modern Spacecraft Guidance, Navigation, and Control
ISBN: 978-0-323-90916-7
https://doi.org/10.1016/B978-0-323-90916-7.00003-2
© 2023 Elsevier Inc.
All rights reserved. 77 jdisturbances, internal vibrations, thermal snap, and parasitic forces and
torques due to thruster firing and plume impingement.
• Internal perturbations modeling guidelines. The main guidelines to model the
presented internal perturbations, while designing a GNC system, are
given in this section.
• What is relevant for GNC? In this section, the influence of external and
internal perturbations on the GNC chain is carefully explained.
Perturbation sources
The equations of Keplerian orbital motion, which will be discussed in
Chapter 4 e Orbital Dynamics, rely on the strong assumption that an orbit￾ing body is only affected by the attractor’s gravity, and that such gravity is a
perfect central force field. In the real case, this is not true, since the orbital
environment is filled with various force fields, not always of gravitational na￾ture. Such forces (or accelerations) are, in most cases, of several orders of
magnitude smaller than the gravity from the main attractor, and for this
reason, they are labeled as “perturbations”; however, their modeling is para￾mount if accurate simulations and GNC design are desired.
In general, the perturbative accelerations may be taken care of through a
simple summation in the external forces term of the second law of motion.
In particular, the equation of orbital perturbed dynamics reads (Chapter 4 e
Orbital Dynamics):
r€¼  Gm
r3 r þ ap
where ap is the sum of all the considered perturbative forces. It is relevant to
note that any perturbation source interacts with the spacecraft that is an
extended body with distributed mass, and, thus, it does not only produce a
resulting force but also a resulting torque. Thus, both the translational and
rotational motion are affected by the perturbations. This chapter describes
the main features of the perturbation sources, and their specific effects on the
orbital and attitude dynamics will be discussed in the related chapters
(Chapter 4 e Orbital Dynamics, Chapter 5 e Attitude Dynamics).
The GNC designer shall know how the perturbations interact with the
spacecraft in order to implement a system that is capable to counteract the
forces and torques influencing the dynamics. Moreover, it shall be capable
to understand which perturbation sources are the most relevant to be
considered and modeled. The goal of this chapter is to learn the fundamental
concepts leading to the solution of these problems.
78 Andrea Capannolo et al.External perturbations
External perturbations are those effectively associated with the space
environment surrounding the spacecraft, and they are associated to physical
phenomena already present in space. The most relevant external perturba￾tion sources in space applications are:
• Gravity irregularities from nonspherical attractors (agravity).
• Magnetic fields (amag).
• Drag from interaction with atmospheres (adrag).
• Pressure of incoming solar radiation (asrp).
• Gravity from other celestial objects (a3bp).
Although a full inclusion of all perturbation sources always provides the
most accurate results, it is often sufficient to consider some perturbations
only, as the others may have a negligible effect on a specific orbit. Indeed,
their orders of magnitude greatly change with the environment type (i.e.,
mass of the attractor, presence of an atmosphere, presence of a liquid metal
core, distance from other celestial bodies, in-light/in-shadow orbital mo￾tion, etc.), and with the distance of the orbiting body from the main attrac￾tor. Fig. 3.1 shows an example of the orders of magnitude for Earth orbits.
The GNC design shall take into account only those perturbations are actu￾ally relevant, and the understanding of the relative magnitudes of the pertur￾bation terms is crucial. For example, from Fig. 3.1, it is evident that a GNC
Figure 3.1 Order of magnitude of perturbations as function of the distance from Earth
center of mass. Courtesy: K. Yazdi, E. Messerschmid, Analysis of parking orbits and transfer
trajectories for mission design of cis-lunar space stations, Acta Astronautica 55 (3e9)
(2004) 759e771.
The space environment 79design in low Earth orbit (LEO) shall account more for atmospheric drag
and the first harmonics of the gravity field, while in geostationary Earth orbit
(GEO), it shall consider the gravity attraction of the Moon and Sun more
than the other terms. It can be remarked here that considering the atmo￾spheric drag contribution above a 1000 kilometers is pointless.
In the next sections, each perturbation source is explained, and its formu￾lation derived. The discussion is valid and can be generalized to the space
environment about any celestial body, but it is focused on perturbation
models for Earth applications.
Gravity field of a central body
The most simple approximation, when dealing with gravitational attraction,
is to consider the celestial objects as perfect spheres. This enormously sim￾plifies the construction of dynamical models, as the gravitational force can
be easily expressed through an elementary analytical formulation.
Let’s consider the general formulation of the gravitational potential:
U ¼ G
ZZZ
m
1
r
dm (3.1)
where G is the gravitational constant, dm an infinitesimal mass portion of the
attracting body, and rp the distance between the control point (or spacecraft)
and such infinitesimal mass. According to the shell theorem [1], the potential
of a perfect sphere is equivalent to the one of a dimensionless point, where
all the attractor’s mass has been shrunk in the center of the sphere, hence Eq.
(3.1) becomes:
U ¼ Gm
r ;
which is the point mass gravitational potential, and its gradient leads to the
point mass (or spherical) gravitational acceleration vector:
VU ¼ Gm
r3 r
In practice, any celestial object possesses some irregularities and oblate￾ness, which acts as a perturbation that adds up to the point mass gravity.
To describe such irregularities in the field, let’s consider again Eq. (3.1).
Now, the integral has to be solved for a finite distribution of mass.
80 Andrea Capannolo et al.This can be done through the Spherical Harmonics Expansion (SHE)
model, by approximating the integral quantity 1
rp as a series of Legendre’s Poly￾nomials [2]:
1
rp
wXN
k¼0
r
k
m
rkþ1PkðcosðbÞÞ (3.2)
where rm and r are the positions of the infinitesimal mass and of the control
point, respectively, from the attractor’s center of mass (CoM); b is the angle
between the two positions vectors, and Pk is the kth-degree Legendre’s
polynomial, expressed in the Rodrigues’ formula form as:
PkðxÞ ¼ 1
2nn!
dn
dxn

x
2  1
n
By substituting (3.2) into (3.1), and by developing the integral, the new
gravitational potential for an irregular gravity field is obtained [3]:
U ¼ Gm
r
(
1 þ Xn
i¼2
X
i
j¼0

R
r
i

Cij cosðjlÞ þ Sij sinðjlÞ

PijðcosðqÞÞ)
(3.3)
Here, m and R are the mean mass and radius of the attractor, q and l
represent the colatitude and longitude of the point where the potential is be￾ing evaluated, Cij and Sij are the normalized Stokes coefficients, and Pijð $Þ are
the associated Legendre’s polynomials, which read:
PijðxÞ ¼ 
1  x
2j
2 dj
dxj
PjðxÞ
The Stokes coefficients are instead expressed in terms of the infinitesimal
mass element and its related quantities (radius, colatitude, and associated
polynomial of the longitude):
Cij ¼ 1
m
ZZZ
m
rm
R
	iði  jÞ!
ði þ jÞ!
PijðsinðqmÞÞcosðjlmÞdmSij
¼ 1
m
ZZZ
m
rm
R
	iði  jÞ!
ði þ jÞ!
PijðsinðqmÞÞsinðjlmÞdm (3.4)
Typically, a scaling factor Nij is introduced [4] to reduce machine over￾flow and underflow during computation:
Nij ¼
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi

2  dij
ð2i þ 1Þ
ði  jÞ!
ði þ jÞ!
s
(3.5)
The space environment 81Using (3.5) to scale the coefficients from Eq. (3.4), the normalized Stokes
coefficients are obtained:
Cij ¼ 1
m
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi

2  d0j

ði  jÞ!
ð2i þ 1Þði þ jÞ!
s ZZZ
m
 r
R
	i
PijðsinðqÞÞcosðjlÞdmSij
¼ 1
m
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
2ði  jÞ!
ð2i þ 1Þði þ jÞ!
s ZZZ
m
 r
R
	i
PijðsinðqÞÞsinðjlÞdm
To avoid altering the result of Eq. (3.3), the scaling factor is also applied
to the associated Legendre function 
Pij ¼ Pij
Nij 
.
From Eq. (3.3), one can notice that the first term is the point mass grav￾itational potential. Since we are here interested in the perturbative forces
only, the point mass term can be omitted. Also, from the second equation
of (3.4), it is observed that when j ¼ 0, then Sij ¼ 0. Given these consid￾erations, the gravity potential expression can be reorganized as follows:
Ugravity ¼ Gm
r
(Xn
i¼2
Ci0
R
r
i
PiðcosðqÞÞ þ Xn
i¼2
 X
i
j¼1

R
r
i

Cij cosðjlÞ þ Sij sinðjlÞ

PijðcosðqÞÞ)
(3.6)
The Ci0 terms are independent from the longitude and are related to the
colatitude only. They are commonly referred to as zonal harmonics, and typi￾cally contain the most relevant terms of the irregular mass distribution of the
attractor. An alternative expression of this (nonnormalized) coefficients is Ji
and relates to the previous one as follows:
Ji ¼  Ci0
Notice that in the case of purely axisymmetric objects, zonal harmonics
are the only source of irregularity in the gravitational field. The other terms
describe the Sectorial Harmonics (when i ¼ j), dependent on longitude only,
and the Tesseral Harmonics (when isjs0), which are affected by both lati￾tude and longitude.
To obtain the acceleration generated by the irregular field’s potential, its
gradient is taken. In particular, we are interested in defining the acceleration
in cartesian coordinates, despite the potential of Eq. (3.6) is function of
spherical coordinates’ quantities (radius, longitude, colatitude). Hence,
82 Andrea Capannolo et al.defining r ¼ ½x; y; z as the vector of cartesian coordinates of the field point,
the acceleration can be expressed as:
agravity ¼ VU ¼ vU
vr
vr
vr
u
þ
vU
vq vq
vr
u
þ
vU
vl vl
vr
u
By developing the partial derivatives, and omitting the point mass grav￾ity, the perturbative acceleration becomes:
agravity ¼
2
6
6
6
6
6
6
6
6
4

1
r
vU
vr  z
r
2
ffiffiffiffiffiffiffiffiffiffiffiffiffiffi
x
2 þ y
2
q
vU
vq 
x 
 1
x
2 þ y
2
vU
vl 
y
1
r
vU
vr  z
r
2
ffiffiffiffiffiffiffiffiffiffiffiffiffiffi
x
2 þ y
2
q
vU
vq 
y 
 1
x
2 þ y
2
vU
vl 
x

1
r
vU
vr  z
r
2
ffiffiffiffiffiffiffiffiffiffiffiffiffiffi
x
2 þ y
2
q
vU
vq 
x 
 1
x
2 þ y
2
vU
vl 
y
3
7
7
7
7
7
7
7
7
5
The potential of Eq. (3.6) assumes that the attractor has a fixed shape and
mass distribution. If a very high precision in modeling perturbations is
required, it is desirable to include the effect of tides, for both the solid and
the liquid masses characterizing the attractor. To account for tides, the
Stokes coefficients must be varied in time, according to the motion of the
main objects causing the tide (e.g., in the case of Earth, the major contribu￾tions are given by the gravity of Moon and Sun). In the specific case of Earth,
it is useful to distinguish between solid Earth tides and ocean tides.
Solid Earth tides consider the coefficients variation due to the deforma￾tion of the solid part of the planet. After labeling the Moon and the Sun with
the indexed q ¼ 2 and q ¼ 3, the variation of the coefficients is modeled as
follows:
DCij ¼ kij
2i þ 1
X
3
q¼2
mq
m
 R
Rq
iþ1
Pijðcosð ÞÞ q cosðjlÞDSij
¼ kij
2i þ 1
X
3
q¼2
mq
m
 R
Rq
iþ1
Pijðcosð ÞÞ q sinðjlÞ
where kij are the Love numbers [5]. Such expression is valid for all j when i˛
½2; 3 and for J˛½0; 2 when i ¼ 4. Details about the model can be found in
Ref. [6], where additional minor effects such as pole tide (tide from Earth’s
rotation) are also described.
The space environment 83The ocean tides cause a smaller variation in mass distribution than solid
Earth tides. Their effect on the coefficients is described by the following
equations:
DCij ¼ 4pR2rw
m
 
1 þ k0
ij
2i þ 1
!X
2
q¼1
mq
m
 R
Rq
iþ1
PijðcosðqÞÞcosðjlÞ DSij
¼ k0
ij
2i þ 1
X
2
q¼1
mq
m
 R
Rq
iþ1
PijðcosðqÞÞsinðjlÞ
where k0
ij are the load deformation coefficients, and rw is the density of seawater.
Again, details of the ocean tides can be found in Ref. [6]. Note that in LEO,
solid Earth tides are the same order of magnitude of Sun gravity attraction,
and they are more relevant than SRP. At GEO altitude, they can be
neglected in the vast majority of the applications. Ocean tides are always
less relevant than solid Earth tides, and they typically account for about
10%e15% of their magnitude.
Gravitational models
Gravity field modeling is dependent from the selection of the coefficients to
insert into the spherical harmonic expansions. In fact, there are different
gravitational models with different accuracy levels. The most relevant are:
• Joint Gravity Model (JGM-3)dOrder: 70  70d1996.
• Earth Gravity Model 96 (EGM-96)dOrder: 360  360d1997.
• Earth Gravity Model 08 (EGM-08)dOrder: 2190  2190d2008.
• European Improved Gravity model of the Earth by New techniques 04
(EIGEN-GL04C)dOrder: 360  360d2006.
The first three are maintained by the US entities, while the latter is
developed by an effort of European contributions, and it is standard for
GNC applications in Europe [7].
Their order of expansion is quite above the typical needs for GNC ap￾plications. Indeed, GNC accuracy requirements drive the maximum degree
and order. For instance, 4  4 fields are often adequate for deep-space or￾bits, while some low Earth satellites need around 50  50 field. However,
the most accurate and updated models are suggested, since they also improve
the accuracy of low-order coefficients. In these regards, EGM-08 or
EIGEN-GL04C is preferred.
Note that, as remarked in Chapter 2 e Reference Systems and Planetary
Models, we must consistently use a gravitational model with its associated
84 Andrea Capannolo et al.constants. Only in this way, it is possible to obtain documented accuracy,
since mixing constants from different theories and models leads to errors
and inconsistencies.
For reader’s convenience, the first three zonal harmonics of the Earth’s
gravity field (EGM-08) are reported here:
• J2 ¼ 0:00108262617385.
• J3 ¼ 0:0000025324.
• J4 ¼ 0:0000016198.
Note how J2 is by far the strongest perturbation due to the Earth’s shape.
It is almost 1000 times larger than the next largest coefficient (J3).
Magnetic field
The magnetic field acts as a perturbation through the interaction with
charged particles on the orbiting object. It is worth mentioning that this
kind of perturbation has a minor effect on the translatory motion, while
has a more significant role in the rotational dynamics.
The magnetic field B can be expressed as the gradient of a potential func￾tion Um:
B ¼ VUmag
The magnetic potential can be expressed in terms of a spherical harmonic
expansion, which resembles the gravitational potential formulation, and it
reads:
Umag ¼ R0
Xn
i¼1
R0
r
iþ1
X
i
j¼0
h
gij cosðjlÞ þ hij sinðjlÞ
i
PijðcosðqÞÞ
Here, gij and hij are the Schmidt coefficients which are tabulated data
referred to the International Geomagnetic Reference Field (IGRF) model [8].
The bar over the Schmidt coefficients indicates a normalization, which
however is different from the one performed in the gravitational case, and
results in:
gij ¼ Pijgij
hij ¼ Pijhij
Pij ¼
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi

2  d0j

ði  jÞ!
ði þ jÞ!
s
ð2i  1Þ!
ði  jÞ!
The space environment 85For what concern magnetic field modeling, the IGRF is the standard
model accepted worldwide. The IGRF describes the large-scale structure
of the Earth’s main magnetic field and its secular variation. It covers a
significant time span, and so it is useful for interpreting historical data and
to perform forecasts within its validity time interval. The IGRF is updated
at five-year intervals, reflecting the most accurate measurements and predic￾tions available at the release time. For example, the 13th edition of the IGRF
model (IGRF-13 or IGRF-2020) was released in December 2019, and it is
valid from 1900 until 2025. The IGRF assumes R0 ¼ 6 371:2 km, being
the geomagnetic conventional Earth’s mean reference spherical radius, but
it shall be handled (e.g., to convert between geocentric and geodetic coor￾dinates) over the WGS-84 ellipsoid with major equatorial radius equal to
6378.137 km. The order of truncation of the harmonic expansion is
n ¼ 13. The IGRF has been produced and updated under the direction
of the International Association of Geomagnetism and Aeronomy (IAGA)
since 1965.
Atmospheric drag
In case of relatively low-altitude orbits around bodies with an atmosphere,
even the slightest, rarefied presence of gaseous particles causes a long-term
deviation in the trajectory of an orbiting object. Such effect is still orders
of magnitude below the nominal gravitational attraction of the celestial
body; hence, it can be considered as a perturbative force.
The formula of the atmospheric drag, acting on the orbiting body, fol￾lows the classical expression from fluid dynamics [9], and reads:
adrag ¼  1
2
cDA
m
r v
2
relbvrel (3.7)
Note that Eq. (3.7) can be applied to the entire spacecraft, in a simplified
modeling approach, or it can be subdivided in more elemental terms
composing the body, to be summed at the end to find a more accurate per￾turbing force on the spacecraft. The latter finite element method-like
approach guarantees improved results, at the cost of increased computational
burden.
The drag coefficient cD scales the drag effect according to the properties of
the orbiting body (e.g., its shape). For practical space engineering applica￾tion, a common preliminary approach is to set such value to 2.2, which de￾rives from a flat plate model.
86 Andrea Capannolo et al.A and m are, respectively, the section area of the object facing the relative
wind and its mass. Their ratio indicates how a low-mass and extended body is
subjected to drag perturbative acceleration significantly more than a small,
massive body. The drag coefficient, mass, and section area appearing in
Eq. (3.7) are often collected and describe as a single quantity, namely the bal￾listic coefficient:
BC ¼ m
cDA.
From precious considerations, one can understand the sensitivity of the
orbiting body to drag force by evaluating this single quantity: a large ballistic
coefficient implies a low effect of drag perturbation on the body, while a low
value implies a higher contribution of such acceleration to the spacecraft
dynamics.
The relative wind velocity vrel, and its unit vector bvrel, shall not be confused
with the orbital velocity. In fact, the atmosphere has its own motion, mainly
given by the planet’s rotation (and, for a minor part, from winds). Hence,
the relative wind speed can be expressed as:
vrel ¼ vrel bvrel ¼ dr
dt  u  r
with r being the orbiting body’s position in a rotating frame jointed to the
attractor’s rotation, and u being the attractor’s angular velocity vector.
The final, and perhaps most complex, term of Eq. (3.7) is the atmospheric
density r. The actual density depends on several factors, and it is a quantity
varying with time, geographical location, and altitude. Because of the com￾plex behavior, several models have been developed to provide an acceptable
and increasingly accurate representation of the atmosphere. Fig. 3.2 displays
the development flow of the currently available models, sorted by subgroup
(according to the model’s method and assumptions) and the year of
development.
Most models rely on the ideal gas law and the hydrostatic equations,
respectively:
r ¼ pM
gRT
Dp ¼ rgDh
where p is the local pressure, M the mean molecular mass, g the gravity
acceleration, R the universal gas constant, T the local temperature, r the
The space environment 87local density, and h the altitude. Nevertheless, a major distinction is made
between static models and time-varying models. Static models provide relatively
simple formulas and are the easiest to implement. Despite the static nature,
some of them implement variations as function of the local coordinates
(latitude and longitude). Typically more accurate, the time-varying models
implement atmospheric variations from several nonstatic factors, such as solar
cycles and fluxes, dayenight cycles, etc.
Relevant examples of relatively simple atmospheric models are the expo￾nential model, the US Standard Atmosphere and CIRA models [10,11], and the
Jacchia models [12,13]. A detailed listing and description of available models
can be found in Ref. [14].
The exponential model represents the simplest approach to describe the at￾mosphere’s quantities and relies on the following analytical expression:
r ¼ r0e
hh0
H (3.8)
with r0 and h0 being the reference density and altitude, respectively, and H
the scale height (fractional change in density with height). Despite its
Figure 3.2 Development scheme of available atmospheric models. Courtesy: D.A. Val￾lado, D. Finkleman, A critical assessment of satellite drag and atmospheric density
modeling, Acta Astronautica 95 (2014) 141e165.
88 Andrea Capannolo et al.simplicity, the model is not suitable for a proper evaluation of the drag, as
Eq. (3.8) poorly describes the true density variation with height.
A more accurate representation of density (suitable for preliminary/gen￾eral studies) is provided by the US Standard Atmosphere and the CIRA models.
Such models leverage the same formula from (3.8) but implement different
reference values (r0; h0; H) for different portions of the atmosphere.
The Jacchia models, instead, leverage empirical temperature profiles and
analytical expressions to retrieve the atmospheric parameters as function of
position, time, solar, and geomagnetic activity, thus providing more accurate
results than the previous models. The Jacchia models are also recommended
by the international standards, with specifications on the limitations and the
parameters to properly set-up the model. In particular, Jacchia-Roberts (J71
and successive) and Jacchia-Bowman (JB-2006) are the most used atmo￾spheric models for LEO applications (i.e., 150e1000 km).
Accurate atmospheric models require input to correctly model solar and
geomagnetic activity. Indeed, direct collisions of the solar wind and air parti￾cles interacting with the Earth’s geomagnetic field heat the atmosphere vary￾ing the density-altitude profile. The commonly used geomagnetic planetary
index, Kp, is a quasilogarithmic, worldwide average of geomagnetic activity
below the auroral zones. The geomagnetic planetary amplitude, ap, is a linear
equivalent of the Kp index, and it can be averaged on a daily basis. For what
concern solar activity, the contribution of solar flux to atmospheric density is
mainly from incoming solar radiation. Solar flux can be related to incoming
solar radiation analyzing the wavelength of 10.7 cm. Regular measurements
of F10.7 exist from about 1940. Daily values are regularly distributed world￾wide, as well as 81-day average values (i.e., three solar rotations).
These geomagnetic and solar parameters need to be known to perform
correct atmospheric analyses. Note that their values are usually correlated,
since the daily planetary amplitude tends to follow the 11-year cycle of sun￾spots, although consistently large maxima of ap usually occur in the declining
phase of each 11-year cycle of F10.7. For this reasons, geomagnetic storms, if
not properly taken into account, represent a threat for spacecraft operations.
In February 2022, a strong geomagnetic storm caused the increase of drag at
the low altitudes that prevented the 40 SpaceX Starlink satellites from begin
orbit-raising maneuvers and led to their premature reentry [15].
Solar radiation pressure
The SRP typically represents one of the most relevant perturbation sources
when far from the attractor and in deep space. The resulting acceleration
The space environment 89exerted on the spacecraft (or any orbiting object) depends on several factors,
which can be collected into two subgroups, i.e., Sun properties and space￾craft properties.
Sun properties are related to time variations of solar activity and solar cy￾cles and involve the spectrum of the emitted radiation as well as its intensity.
In practice, such properties are averaged through the solar flux
(SF 
W=m2
), a constant value which varies with the distance from Sun
only, except for minor variations depending on the period within the solar
cycle. A legacy value for Earth orbits is 1367 W=m2 (still used for many ap￾plications), although various measurements across the years provided a range
of solar fluxes spanning from below 1360 W=m2 to above 1370 W=m2
.
More accurate models may rely on F10.7 measurements and predictions.
The corresponding pressure exerted by the radiation is directly obtained
by dividing the flux per the speed of light c, namely:
psrp ¼ SF
c
which, in case of Earth missions, translates to 4:57  106N=m2
.
Concerning the spacecraft, several factors have to be considered to prop￾erly compute the perturbing acceleration, namely the extension and orien￾tation of spacecraft’s sides facing the Sun, and their (time-variant) absorption
and reflection properties. In practice, there are different levels of depth in the
SRP perturbation model.
The simplest is the so-called cannonball model. As the name suggests, it
considers the spacecraft as a sphere, thus removing dependencies from the
attitude of the spacecraft itself. In this way, a single section A (the largest sec￾tion of the sphere) can be considered. Furthermore, the model does not
distinguish between specular and diffusive reflection and considers only
the transparency, reflectivity, and absorptivity of the object. The cannonball
model equation reads:
asrp ¼  pSRPCRA
m brSun (3.9)
with brSun being the Sun direction from the spacecraft, m the spacecraft mass,
and CR the reflectivity coefficient. From Eq. (3.9), one can understand that low￾mass and wide objects are subjected to a larger perturbation from the solar
radiation. Also, only a radial perturbation from the Sun can be computed
with this model.
90 Andrea Capannolo et al.The reflectivity coefficient CR spans from 0 to 2 and defines how the
transparency/reflectivity/absorptivity properties of the object affect the mo￾mentum exchange between the radiation and the object itself. A value of
zero indicates a completely transparent object, which does not exchange
momentum. A value of 1 represents a fully absorbing object (a black
body), so the full radiation momentum is transferred to the object. A value
of 2, instead, represents a fully reflecting object, which doubles the incoming
momentum from the radiation.
Despite the easy implementation of the cannonball model, one may need
a more detailed representation of the SRP perturbation, by considering both
the actual shape of the spacecraft and its specular and diffusive reflection
properties. To do so, consider each surface of the spacecraft, with its own
orientation (normal vector nb) and absorptivity/reflectivity properties. It is
possible, for each surface, to separately compute the accelerations due to
the absorption (aa
SRP), diffused reflection (ad
SRP), and specular reflection
(as
SRP) of the radiation:
aa
srp ¼  psrpcaA
m
cosðfÞbrSun
ad
srp ¼  psrpcdA
m
cosðfÞ

2
3
nb þbrSun
(3.10)
as
srp ¼  2
psrpcsA
m
cos
2
ðfÞnb
where f is the angle between the Sun direction and the surface normal, and
ca; cd; cs are the absorptivity, diffusive reflectivity, and specular reflectivity coefficients,
such that:
ca þ cd þ cs ¼ 1 (3.11)
The overall acceleration from SRP is then the summation of the three
components from (3.10), for every lit surface “i” of the spacecraft. By col￾lecting the components aligned with nb and brSun , and using (3.11) to elim￾inate the absorptivity coefficient, the total acceleration reads:
asrp ¼ X
N
i¼1
pSRPAi
m
cosðfi
Þ
h
2
cri
3 þ csi cosðfiÞ
	
nb þ ð1  csiÞbrSuni
(3.12)
The space environment 91where N is the total number of lit surfaces of the spacecraft. Notice that a
further level of depth can be obtained by using (3.12) with variable co￾efficients with respect to other quantities (such as surface temperature),
when such relations are available.
Eclipse
The SRP force is directly dependent on the solar flux SF. If eclipse occurs,
the value of the Sun luminosity has to be modified accordingly. A simple
way to implement eclipses is by considering a conical model. Let’s consider
the following vectors as in Fig. 3.3:
• rB ¼ rscj
P vector from vehicle to planet.
• rS ¼ rscj
P þ rSunj
P vector from vehicle to Sun.
Then, the following quantities can be computed:
• HB ¼ asin
RP
jrBj

apparent planet radius as seen by the vehicle.
• HS ¼ asin
RSun
jrSj

apparent Sun radius as seen by the vehicle.
• g ¼ acos r0
B*rS
jrBjjrSj

angular separation between planet and Sun as seen by
the vehicle.
RP and RSun are the radii of considered body and Sun, respectively.
Given HB, HS, and g, the necessary and sufficient eclipse conditions
(illustrated in Fig. 3.4) are:
• No eclipse:
g > HB þ HS
Figure 3.3 Eclipse geometry.
92 Andrea Capannolo et al.• Total eclipse:
HB > g þ HS
• Annular eclipse:
HS > g þ HB
• Partial eclipse: if there is an eclipse not belonging to any of the previous
categories.
The Sun luminosity changes for the four cases, and it can be expressed as
ratio with respect to the ideal case I0. The luminosity ratio during eclipse
conditions is computed as:
• No eclipse: I
I0 ¼ 1
• Total eclipse: I
I0 ¼ 0
• Annular eclipse: I
I0 ¼ 1  1cosðHBÞ
1cosðHSÞ
• Partial eclipse:
I
I0
¼ 1


p  cos HS acoscos HB  cos HS cos g
sin HS sin g

 cosfbacoscos HS  cos HB cos g
sin HB sin g

 acos
cos g  cos HS cos HB
sin HS sin HB

p  ð1  cos HS Þ
Albedo and infrared emission
Solar radiation immediately reflecting off the Earthdor off any planetd
back to space is called albedo. The Earth reflects almost 30% of the incoming
Figure 3.4 Eclipse conditions.
The space environment 93solar radiation The remaining solar radiation is absorbed and reemitted at a
later time as infrared (IR) radiation or emissivity. The emitted IR energy at
the Earth’s surface (IR) is about 237 W/m2
. Both terms can be measurable
on some satellites. Albedo and emitted IR are commonly associated to spe￾cific wavelengths, each of which transfer through the atmosphere
differently.
Albedo and IR-induced accelerations on the spacecraft are computed as
for the direct SRP, with Eq. (3.12). However, first we have to compute
ground albedo and emissivity, and also consider each region of the Earth
that is visible to the satellite, or to one satellite flat plate surface. Obviously,
albedo and emitted IR are directed and oriented from the Earth surface and
not from the Sun. The albedo and emissivity at the ground can be modeled
as spherical harmonic expansions with respect to the geoid [16] or as simple
expressions only function of the altitude.
Third-body perturbation
When distance from the main attractor is sufficiently large, a relevant source
of disturbance is provided by the additional gravitational pulls from other
massive bodies (i.e., third-body, fourth-body, etc.). To model these contri￾butions to satellite’s acceleration, one may start by recalling the equation of
the N-body problem (Chapter 4 e Orbital Dynamics), where this time, all
the relevant masses are preserved within the formulation.
By shifting the origin to the main attractor’s CoM, the following equa￾tion is obtained:
r€¼ m
r3 r þXn
i¼1
mi
 
r  ri



r  ri

j
3  ri
r
3
i
!
¼ m
r3 r þ a3bp (3.13)
where mi represents the individual constant of the i-th additional gravity
source, and ri its position vector with respect to the main attractor.
Notice that the sum in the right-hand side of Eq. (3.13) contains the
gravity pull of the additional source to the spacecraft, plus the gravitational
pull of the main body to the additional source. This formulation may cause
numerical problem in case of a third (fourth, fifth, etc.) body which is at very
large distance from both the main attractor and the spacecraft, like the Sun
for an Earth-orbiting object, such that jjr  rijjwri. In this situation, the sec￾ond term of Eq. (3.13) will have two very small terms (the two ratios), which
are in turn subtracted from one another, making this term prone to numer￾ical error.
94 Andrea Capannolo et al.Although this issue is not always relevant and should be evaluated case by
case, there are some workarounds that have been developed to solve the
problem. A direct analytical solution to the problem has been provided,
and it can be found in Ref. [17]. Other techniques leverage series expan￾sions. A straightforward approach in this sense is to leverage a Taylor series,
as shown in Ref. [18]. For example, if the series is stopped at the second or￾der, the following expression holds:
r€¼  m
r3 r þ m3
r
3
3

r  3r3
r$r3
r
2
3
 15
2

r$r3
r
2
3
2
r3

which is obtained by assuming r  r3. Despite the numerical stability, this
formulation may still lead to relevant errors due to the approximated
formulation itself. Although still approximated, a more accurate approach is
described in Ref. [19], where the norm jjr  rijj is expressed through the
cosine law, enabling the usage of Legendre polynomials as done for irregular
gravity fields (Eq.3.2). Details on the Legendre-based expansion of third￾body perturbation can also be found in Ref. [14].
Ephemerides
When modeling third-body perturbations, it is fundamental to have a right
representation for the relative position of the involved celestial objects. This
is done by exploiting planetary ephemerides, which are time-dependent ex￾pressions of the deterministic evolution of the celestial objects’ positions.
The ephemerides of the Jet Propulsion Laboratory are considered as the
most accurate, but we can use less precise formulations from the Astronom￾ical Almanac [20] or Meeus [21].
In general, planetary ephemerides use interpolating polynomials in terms
of the classical orbital elements and the elapsed Julian centuries to provide
the planet’s position and velocity vector at a given epoch in a given frame.
They are created by numerically integrating the planetary dynamics ac￾counting for the mutual influence of the planets. The numerical integration
commonly uses a variable step-size that averages about 7 h. Once the ephe￾merides are created, the results are fit with Chebyshev polynomials and
collected into few days blocks (e.g., 4, 8, 16, or 32 days). The general accu￾racy of the ephemerides is about 0.0100. The Moon ephemerides are accurate
to about 2 m (0.00100), and the Sun is accurate to about 200 m (0.000300).
Data are available for the planets (e.g., Development Ephemeris, DE￾405d1998, DE-430d2013) and the Moon (e.g., Lunar Ephemeris, LE￾The space environment 95405d1998, LE-430d2013). The reported versions are among the ones
suggested by the international standards, even if more recent ephemerides
data have been released. For the sake of completeness, the classical derivation
of Chebyshev polynomials for ephemeris approximation is described here.
Chebyshev polynomials
Chebyshev polynomials of the first kind are usually adopted. The general
definition of the Chebyshev polynomial TnðxÞ of the first kind in x (inter￾polation points) of degree n is defined by the relation [22]:
TnðxÞ ¼ cosðnwÞ when x ¼ cosðwÞ.
From this general definition, it is possible to derive the fundamental
recurrence relation of the Chebyshev polynomials:
T0ðxÞ ¼ 1; T1ðxÞ ¼ x
TnðxÞ ¼ 2xTn1ðxÞ  Tn2ðxÞ; cn  2:
This general expression is valid in the range ½ 1; 1 of x. In order to
generalize the expression for an interval ½a;b, the following variable has
to be introduced:
s ¼ 2x  ða þ bÞ
b  a
with a and b being the limits (or boundaries) of the interval. The Cheby￾shev polynomials of the first kind appropriate to ½a;b are thus TnðsÞ.
Coefficients computation
In order to compute the interpolating Chebyshev coefficients, the following
steps are implemented:
• The reference position y of the body is computed from reference ephem￾eris files (e.g., JPL, Almanacs).
• Interval limits a and b, and interpolation points x are defined.
• The normalized Chebyshev polynomials TnðsÞ up to the desired order n
are computed.
• All the polynomials are collected in a vector p, and the following equa￾tion is solved:
c ¼ p
T
y.
Once the coefficients are computed, the Chebyshev interpolation can be
performed at each time step to retrieve the approximated body position.
96 Andrea Capannolo et al.Chebyshev interpolation
The final Chebyshev interpolation is performed according to the classical
formula:
f ðtÞ ¼ Xn
i¼0
ciTiðstÞ:
where f ðtÞ is the approximated body position at time t.
External perturbations modeling guidelines
To help the GNC designer, modeling the space environment, inter￾national standards, and guidelines have been developed. Several standards
exist and are variously applied worldwide. For what concern European
standards, the perturbation modeling guidelines are collected by the “Eu￾ropean Cooperation for Space Standardization” (ECSS) in a dedicated
document [7].
The main aspects and standards for the described perturbations are re￾ported in the following paragraphs.
Gravity
The gravitational potential, described in Eq. (3.6), allows to compute the
gravitational attraction of a nonspherical object, for any point in space and
with any desired accuracy, by choosing the coefficients and the truncation
level of the expansion. Nevertheless, it is desirable to minimize the compu￾tational effort for evaluating the potential, by properly selecting the useful
coefficients for the specific application (distance from the attractor and loca￾tion of the orbit).
The ECSS standards provide a guideline for this selection. Two main as￾pects have to be considered when dealing with truncation of the series:
⁃ The “attenuation factor”

R0
r
i
from Eq. (3.6) rapidly decreases as the dis￾tance from the attractor increases, leading to a lesser influence of the local
irregularities of the attractor itself (the uneven gravity model approaches
the point mass model).
⁃ Contributions that have a lower order of magnitude with respect to the
inherent model noise level can safely be neglected.
The space environment 97From these observations, a rule-of-thumb was developed by Kaula [4] to
obtain the order of magnitude of normalized expansion coefficients as func￾tion of the degree i:
Cij; Sij ¼ 105
i
2 (3.14)
By multiplying the Kaula term in Eq. (3.14) with the attenuation factor
for every degree i, one gets the remaining signal power of the correspond￾ing harmonic term. Once such value becomes sufficiently lower (i.e., one
order of magnitude less) than the inherent noise level of the model, the cor￾responding degree can be selected as a truncation level for the expansion.
For example, at the eighth order expansion, the Kaula term is
1.5  107
, and an orbit with radius equal to 25,000 000 km has an atten￾uation factor at the eighth order of 1.5  105
. The remaining signal power
results 2.25  1012. Then, for a 360  360 model, the inherent noise level
can be approximated by Eq. (3.14) as 7.7  1011. Since the order of
magnitude of the remaining signal power is lower than the noise level of
the model, an eighth order expansion would be sufficient for the considered
orbit. In practice, being the Kaula’s rule an approximation, adding few
more degrees is strongly suggested, having a minor impact on the compu￾tational burden. For instance, a 12  12 expansion would be ideal for the
example case.
A second aspect that should be considered is the presence of resonances
between the attractor’s rotation and the orbital motion. In this situation,
certain harmonic components are continuously sensed by the satellite in
exactly the same way, and even very small harmonic components that are
in exact phase with orbital motion may then result in significant orbital per￾turbations after sufficient propagation time intervals. If such resonances exist
(i.e., as in repeated orbits, where the ground track of the spacecraft returns to
the same point on the Earth surface after M orbital revolutions), some terms
of the expansion, even if negligible according to Kaula’s rule, may lead to
the long-term perturbation. Therefore, such isolated terms shall be identi￾fied and included in the expansion.
Magnetic field
Magnetic field shall be modeled according to the available international
geomagnetic models. The last version of IGRF shall be used as the internal
geomagnetic field model (i.e., main geomagnetic field due to Earth internal
phenomena). The IGRF shall use the standard parameters for ellipsoid and
98 Andrea Capannolo et al.reference radius definition, and geodetic coordinates calculations, as
described in the previous sections. For times in the past and in the future,
IGRF shall be used in association with its secular variations. However, the
validity time interval shall not be exceeded.
Internal geomagnetic field is the primary (i.e., >90%) magnetic field un￾der quiet solar and geomagnetic activity conditions. However, currents
flowing in the ionosphere induce an external magnetic field component.
Regarding the modeling of the average Earth external magnetic field, and
its variations due to geomagnetic and solar activity, the international guide￾lines provide two standard models to choose from:
⁃ Alexeev’s model [23].
⁃ Tsyganenko and Stern [24].
Atmospheric models
The critical aspect of modeling the atmospheric drag perturbation is the
choice of the model for the attractor’s atmosphere, which determines tem￾perature and pressure profiles with altitude. Despite the large number of
available models, the international guidelines indicate two specific models
to be used for Earth:
⁃ The NRLMSISE-00 [25] model shall be used for calculating the neutral
temperature, the total density, and the detailed composition of the
atmosphere.
⁃ The JB-2006 [26] model or JB-2008 [27] model may be used for calcu￾lating the total atmospheric density above an altitude of 120 km.
The NRLMSISE-00 model shall not be mixed with the JB-2006 model.
Furthermore, the guidelines provide information on how to deal with
cyclic atmospheric properties due to interactions with solar radiation and
geomagnetic activity. In the document, a table containing inputs for the
aforementioned models is provided to cover “long-term” and “short￾term” effects.
Also, additional information is provided for Earth wind models, as well as
for other planets’ atmospheres. For the details, the reader is invited to read
Ref. [7].
Solar radiation
The international guidelines do not provide information about the models
for SRP; however, they indicate which value should be considered for
the total solar irradiance.
The space environment 99In particular, despite the wide use of a value around 1367 W
m2, the
document indicates an average value at one astronomical unit of distance
from the Sun of 1361 W=m2
, with one-sigma uncertainty of 
0:5 W=m2
. In addition to that, a long-term smoothed solar cycle is consid￾ered, leading to a minimum value of 1360:5 W=m2 and to a maximum
value of 1362 W=m2
. In addition to that, the international guidelines report
the oscillation due to the distance of the Earth from the Sun. At the
aphelion, the total solar irradiance is 1316 W=m2
, while at the perihelion
1407 W=m2
.
For what concern Earth’s albedo and IR-emitted radiation, international
guidelines suggest to consider their variability across the globe, function of
the cloud coverage, and surface properties. Average albedo and IR values
shall be used with care only for short duration analyses.
Third-body perturbation
The two main aspects to select, when including the third-body perturbation,
are which attractors to consider, and what model to rely on for their
trajectories.
The international guidelines provide some suggestion in the specific case
of Earth-orbiting satellites. In particular, it is stated that the only significant
attraction (i.e., other than the Sun and the Moon) arises from Venus, Mars,
Jupiter, and Saturn, as the other bodies are either too small or too far away.
In this case, all the attractors, other than the Earth, can be modeled as point
masses without visible losses in accuracy.
Regarding the bodies’ trajectories, the standards indicate that Develop￾ment Ephemerides data on planets (DE-430) and Lunar Ephemerides data
(LE-430), both given in Ref. [28], shall be used.
Internal perturbations
In addition to external disturbances, caused by environmental ele￾ments, a spacecraft is subject to several sources of internal disturbances for
the dynamics, which distinguish from the previous as being caused by ele￾ments that are part of the satellite. As such, spacecraft designers have the pos￾sibility to manipulate them through design choices, leading to requirements
constraints, in order to limit the influence of these perturbations. The most
common internal disturbances are:
100 Andrea Capannolo et al.• Flexibility.
• Sloshing.
• Parasitic forces and torques during thrusters firing.
• Electromagnetic disturbances.
• Internal vibrations.
• Parasitic forces and torques due to plume impingement.
• Thermal snap effects.
Internal perturbations modeling is very difficult to be generalized, since it
is very mission-specific and related to characteristics of the spacecraft. To un￾derstand the effects and the magnitude of the internal perturbation sources,
preliminary models shall be applied on the spacecraft dynamics in order to
have a general overview of the spacecraft internal environment. Then, we
shall select the relevant internal perturbations in order to implement the
refined models for the design analyses. The following sections give an over￾view on how the internal perturbations sources interact with the spacecraft.
Flexibility
Deep studies have been developed about the control of rigid bodies since the
very beginning of the space era, but far inferior efforts have been concen￾trated on the control of rigid bodies with flexible appendages until the
mid-90s, when the problem became of large interest. In general terms,
the necessity to take into account spacecraft flexibility depends on the level
of accuracy required to the GNC subsystem, since every spacecraft is flexible
at some extent. The growing interest in the field is due to several factors:
first, the increasing performance of payloads reflects in a higher power de￾mand, thus in larger solar panels, up to a point where flexibility of such
panels has a nonnegligible influence on the satellite dynamics. Second,
increasing performances also mean more stringent requirements on GNC
in terms of control error (i.e., pointing error) and stability. Moreover, mis￾sions are increasingly requiring fast maneuvering to acquire different targets
in limited time, and therefore the satellite experiences higher accelerations
that can excite flexibility.
Flexible appendages (e.g., solar panels, large antennas, etc.) modify the
dynamics of the satellite from the simple rigid-body case: indeed, the flexible
appendages interact with the main body of the spacecraft, creating a different
overall response to external disturbances or to commanded forces and tor￾ques. The movement of the propellant inside the tank (i.e., sloshing) causes
the same effects, but it will be treated separately in the next paragraph. The
presence of vibrations can perturb both the orbital motion and the attitude
The space environment 101one. However, in terms of orders of magnitude, the variation of position of
the satellite’s CoM in the inertial frame due to vibrations is usually negligible
in comparison with the tolerance on the orbit altitude imposed, for example,
by the ground track. In fact, the energy of the orbital motion is extremely
large, and the attitude and flexible dynamics have negligible effect upon
the orbital one. Moreover, the attitude-control frequencies are closer (i.e.,
more influenced) to those of the flexible structures, and this may further in￾crease the coupling between attitude and flexible dynamics. Thus, the
following discussion will focus on the attitude perturbations due to flexi￾bility, yielding to a simplification decoupling between flexible and orbital
motions. This is generally true for most internal perturbations. Flexible ef￾fects, and other internal disturbs, can be extended to the CoM dynamics
for very advanced and peculiar studies.
The difference in complexity between flexible dynamics and rigid dy￾namics is evident: the flexible problem is not only infinite dimensional for
the structural flexibility but also highly nonlinear. Often, the problem can
be simplified considering a discrete parameters model: in this way, the infin￾ite number of dimensions involved is reduced to that of the primary modes
of vibrations taken into account [29]. The following approaches can be
considered for the aim of modeling spacecraft flexibility [30]:
• Distributed parameters. The solar array, or extended appendage, is repre￾sented by a cantilever beam, whose deformations are expressed in
continuous coordinates. The EulereBernoulli equation is used, consid￾ering an appendage deflection, d, as the product of a time-dependent
function (i.e., generalized coordinate) and a space-dependent term
(i.e., mode shape):
dðl; tÞ ¼ Xn
1¼1
fi
ðlÞpiðtÞ
being n the number of flexible modes taken into account. Partial deriv￾atives equations are obtained for the deflection of the beam, ordinary deriv￾atives equations for the spacecraft dynamics [31,32]. A RitzeGalerkin
approximation is often used to represent the solar array or the flexible struc￾ture, as it will described in the following.
• Discrete parameters. Every appendage is a punctual mass interconnected by
a spring. In this case, ordinary differential equations are obtained both for
the flexible part and the spacecraft. Each mass-spring system represents a
mode of vibration for the appendage [33]. A similar approach can be used
102 Andrea Capannolo et al.for modeling the sloshing effects. The damping factor of the spring can
only be measured on a spacecraft prototype; for simulations, a value in
the range of 0.01%e0.1% of the critical damping is typically used as a
conservative approach.
• N-bodies modeling. The structure is seen as N interconnected rigid bodies,
each of which is a mass with its own inertia. Multibody dynamics
modeling approaches and theories are used to represent and analyze
the whole flexible system [34].
• Finite elements methods (FEMs). This approach combines the two first
techniques together. The finite elements may be modeled separately as
spring-mass elements or as “distributed parameters.” The FEM tech￾niques are then applied to model and simulate the flexible elements on
the spacecraft [29].
In any case, flexible effects are not accounted in the dynamics as addi￾tional perturbation terms, but the aforementioned approaches are used to
derive flexible equations of motion, which shall be used in place of the rigid
body ones. Hence, the spacecraft dynamics including the flexibility effects
shall be modeled with flexible dynamical equations plus the terms due to
the other external and internal perturbation sources [35].
Example of a discrete parameters modeling
In the following, the approach presented in Ref. [33] is reported as an
example, where the equations of motions of a spacecraft with reaction
wheels and flexible solar panels are derived from the Lagrange equations
in terms of quasicoordinates:
d
dt vL
vu
þ ½u
vL
vu
¼ t;
where t is the torque vector, L the Lagrangian function, and ½u the cross￾product matrix associated to the angular rate of the spacecraft:
½u ¼
2
6
6
4
0 uz uy
uz 0 ux
uy ux 0
3
7
7
5.
The equation of the panels deflection angle a can be expressed by means
of the usual Lagrange equation, adding the presence of a dissipation function
D that acts as a natural damping for the system. In this way, the equation for
the panels’ deflection can be written as:
The space environment 103d
dt 
vL
va_
!


vL
va
þ
 
vD
va_
!
¼ 0
The Lagrangian function L is the difference between the kinetic energy
T and the potential energy U; these can be expressed for the spacecraft￾wheels-panels system as:
2T ¼
Z
R
ðu  rÞ$ðu  rÞdm þX
4
i¼1
Z
W
ðu  r þ uwi  rwiÞ$
ðu  r þ uwi  rwiÞdm þ mðV1$V1 þ V2$V2Þ þ 2Ipg_ 2
0 T ¼ 1
2
uTIu þX
4
i¼1
1
2
Isu2
wi þX
4
i¼1
Isuwiu $bai þ
1
2
mðV1$V1 þ V2$V2Þ
þ Ipg_ 2
U ¼ 1
2
K

l
2
a2 þ l
2
a2
¼ Kl2a2
R indicates an integration over the rigid body, W an integration over the
wheels; u is the angular rate vector in body coordinates, r the radius of inte￾gration over the rigid body. uwi represents the i-th wheel angular rate, rwi
the radius of integration over the i-th wheel. V1 and V2 are the linear ve￾locities of the two masses, I is the matrix of inertia of the rigid body in body
coordinates, excluding the presence of the appendages; the considered body
frame is assumed to be the principal frame of inertia, and this implies I to be
diagonal. The assumption is likely in many cases, since most spacecrafts tend
to be almost symmetric along two axes. Ip is the beam-like panel moment of
inertia and Is the wheel polar moment of inertia. bai is the unit vector that
expresses the orientation of the i-th wheel axis in the body frame; later in
this discussion, the notation aix; aiy; aiz will be used to indicate the compo￾nents of the unit vector bai along the body axes. K is the flexional rigidity of
the panels.
In the simplest model, the two solar arrays can be schematized as canti￾lever beams of length l, with tip mass m and a spring of flexional rigidity K, as
in Fig. 3.5.
The angle a measures the panel deflection that is assumed to be equal in
absolute value between the two arrays. The panels are considered to lie in a
plane inclined of an angle g with respect to the XsatYsat plane: if g is zero,
the array is in the XsatYsat plane; if g is 90, the array is in the YsatZsat
104 Andrea Capannolo et al.plane. It is reasonable to assume that the deflections are so small that sin ay
a; cos ay1; therefore, the positions of the two masses can be identified by:
p1 ¼
2
6
6
4
dx þ la sin g
dy  l
dz þ la cos g
3
7
7
5
p2 ¼
2
6
6
4
dx  la sin g
dy þ l
dz  la cos g
3
7
7
5
being dx, dy, and dz the distances in absolute value from the point of
attack of the panel to the rigid body, to the total CoM, respectively, along
the Xsat, Ysat, and Zsat axis. From this, it is possible to compute all the needed
terms in the equation of the Lagrangian, leading to a final system in the form:
I
2
6
6
6
6
4
u_x
u_y
u_z
3
7
7
7
7
5
¼
2
6
6
4
f1
f2
f3
3
7
7
5
where I is the inertia matrix of the whole system:
I ¼
2
6
6
6
6
6
6
4
I1  I
2
l cos
2 g
2ml2 Ila sin g
I
2
l cos g sin g
2ml2  2mdxdz
Ila sin g I2 Ila cos g
I
2
l cos g sin g
2ml2  2mdxdz Ila cos g I3  I
2
l sin2 g
2ml2
3
7
7
7
7
7
7
5
It is worth noticing that the matrix of inertia I of the whole system is no
longer diagonal because the presence of the arrays creates a misalignment be￾tween the body frame and the principal axis frame of reference. The varia￾tions caused to I depend on a, and therefore the corresponding terms are
Figure 3.5 Flexible spacecraft scheme.
The space environment 105time-variant. Anyway, these terms are of at least three orders of magnitude
inferior to the in-diagonal terms.
Example of a distributed parameters modeling
In this paragraph, the approach presented in Ref. [36] is described, where,
for a higher representativeness of the model, a two-dimensional (2D) sche￾matization of the array as a thin plate is chosen. In fact, in some cases, the
assumption to reduce the solar array to a beam can be imprecise, given
the real dimensions and geometry of the appendages. It is important to un￾derline that the in-plane behavior of the plates is supposed to be negligible in
the problem, which is absolutely the case for most spacecrafts since torsional
in-plane rotations of the solar panels are far less likely to induce disturbances
on the satellite attitude dynamics. Thus, the only possible responses of the
structures are bending and twisting in the out-of-plane direction, under
the hypothesis of the Kirchhoff kinematic model [29,30].
Also in this case, the Lagrangian formalism in quasicoordinates is used to
find the equations of motion, but considering the alternative schematization
of the solar panels, this time it shall be considered the position of a generic
point P1 on panel 1 and P2 on panel 2, referring to Fig. 3.6:
rP1 ¼
8
>><
>>:
Rh þ xa1
ya1 þ w1ðxa1; za1; tÞ
za1
9
>>=
>>;
rP2 ¼
8
>><
>>:
Rh þ xa2
ya2  w2ðxa2; za2; tÞ
za1
9
>>=
>>;
In this way, the kinetic and the potential energy of the system can be
found, but flexibility is still represented by continuous variable in space
and time domains: the Lagrangian formalism can be applied only to discrete
systems, so a suitable approximation is needed. In this way, the continuous
variable w is replaced by a set of N generalized (or physical) coordinates,
continuous in time domain but discretized in space. The discretization of
a plate by means of a RitzeGalerkin approximation, conceptually, divides
the plate in a grid of beams. In a cantilever plate, there will be a set of canti￾lever beams (x-axis) and a set of freeefree beam (z-axis). Each group is rep￾resented as a linear combination of a set of admissible functions N (in space
domain) times a set of generalized coordinates uð Þt :
wðx; z; tÞ ¼ X
Nc
i¼1
X
Nf
j¼1
NiNjuðtÞ ¼ NuðtÞ
106 Andrea Capannolo et al.The order of accuracy of the approximation depends on the grade and
number of the functions. Using this approach, it is possible to get a system
in the form of:
Msys
8
>>><
>>>:
u_
u€1
u€2
9
>>>=
>>>;
þ Ksys
8
>><
>>:
u
u1
u2
9
>>=
>>;
¼ t
where Msys is the inertia matrix of the system, Ksys is the stiffness matrix of
the system, t is the torque vector, u is the angular rate of the spacecraft, and
u are the displacements of the considered points of the arrays. The structure
of the equations is the expected one, indeed, it is a set of 3 þ 2NcNf
Coupled Ordinary Differential Equations in a Continuous Time Domain,
with mass and stiffness matrices counting for (3 þ 2NcNf )  (3 þ 2NcNf )
elements. This is not acceptable considering reasonable computational ca￾pabilities; therefore, a typical approach is to introduce Modal Coordinates to
reduce the size of the problem. The modes of the plates can be computed by
solving the eigenvalues problem:
ðMi  lKiÞv ¼ 0
Figure 3.6 Schematics of the central hub and the two solar arrays, with main quantities
used in computation.
The space environment 107The solution of the eigenvalues problem yields to a set of NcNf mode
shapes, each one vibrating at a specific discrete frequency uni. Each mode,
mathematically, represents a single independent harmonic oscillator
vibrating at a specific frequency. The overall vibration of the plate will be
a linear combination of these modes, uðtÞ ¼ U qðtÞ, where qðtÞ is the vec￾tor of the so-called qiðtÞ Modal Coordinates, representing the weight in
time of the i-th mode shapes, contained in the modal matrix U. Depending
on the frequency content of the physical loads in the problem, not all the
modes will be equally excited: higher frequency modes typically belong
to low mass participation factors and therefore can be discarded. How
many modes should be included in the model is a trade-off between how
much accuracy is lost in the truncation and the computational cost that
can be sustained. Introducing also the damping elements, the final form of
the system is obtained as:
Msys
8
>>>><
>>>>:
u_
q€1
q€2
9
>>>>=
>>>>;
þ Csys
8
>>><
>>>:
u
q_1
q€2
9
>>>=
>>>;
þ Ksys
8
>><
>>:
u
q1
q2
9
>>=
>>;
¼ t
where Csys is the damping matrix of the system and the line above the
matrices indicates the projection in the modal space.
Effects on dynamics and GNC
When the simple rigid body is considered, the simplified dynamics of the
satellite can be represented by:
Iu_ ¼ t
being t the torque vector, I the satellite inertia matrix, and u the angular
rate. The transfer function of this system is simply:
GðsÞ ¼ 1
I s2
which, since it has two poles in the origin, is represented in the Bode di￾agram by a line with a slope of 40dB=decade for amplitude and a constant
180 in phase, as shown in Fig. 3.7.
The introduction of flexibility can be associated to the addition of two
poles and two zeros for each vibrational mode, so that the transfer function
becomes:
GðsÞ ¼ s
2 þ 2xufs þ uf
Is2ðs
2 þ 2xuns þ unÞ
108 Andrea Capannolo et al.with x the damping coefficient, un the natural pulse of the system, and
uf the resonance of the spring. Therefore, there will be two breakouts in
the Bode diagram: the first one is due to the two zeros and leads to a change
of amplitude slope from 40dB=decade to 0 and to a change in phase from
180 to 0; the second one is due to the two poles, and it brings back the
amplitude to 40dB=decade and the phase to 180. Visually, two peaks
can be identified for each modeled mode of vibration, corresponding to
the resonance and the antiresonance of each mode, as can be seen in Fig. 3.8.
Clearly, GNC design should take care that the bandwidth of the control
system shall remain well below the first frequency of resonance of the flex￾ible modes (i.e., the frequency range in which the magnitude of the control
action is greater than a certain minimum value shall be smaller and well sepa￾rated from the resonance frequency of the flexible vibrations). On the other
side, the resonance frequencies of the flexible modes shall not be too close to
the controller frequency or its multiples, at least for the modes with most
relevant mass participation factors [29,30].
The effect of flexibility is clearly visible during slews that excite bending
modes: supposing a bang-bang attitude maneuver, the effect will be a first
excitation of the panel to bending, then a second vibration when the torque
changes in sign, and a last one when the torque comes back to 0. The second
Figure 3.7 Bode diagram of a plant considering the rigid body model, with inertia of
350 kg m2
.
The space environment 109excitation will be higher, since the torque step will be double than in the
other two cases, as can be seen in Fig. 3.9. It is evident that these vibrations
can affect attitude pointing both during the slew, but even after the maneu￾ver, when a stable attitude is very likely to be needed to perform acquisitions
Figure 3.8 Bode diagram of a plant with inertia of 350 kg m2 and the flexibility of the
solar arrays. The first two bending modes have been included in the model: the first is
clearly visible at un ¼ 4 Hz, the second one is much smoother at un > 10 Hz. The peaks
correspond to the two vibration frequencies of the solar panel.
Figure 3.9 Solar array tip mass displacement during an attitude maneuver exciting
bending mode.
110 Andrea Capannolo et al.of data. Therefore, depending on amplitude and duration of vibration versus
pointing requirements, a tranquilization period could be needed before
starting operations to allow stability of attitude pointing. On the other
hand, the amplitude of the vibration and the time needed for vibrations
to cease depend on the physical properties of the flexible appendage; there￾fore, appendage design, when possible, can be constrained to allow lower
impact on attitude pointing and stability.
Sloshing
The fuel and liquids contained in the tanks inside the spacecraft shows a
dynamical behavior that clearly cannot be assimilated to that of a rigid
body, and consequently introduces oscillation effects into the spacecraft dy￾namics. The fuel motion within a tank is usually addressed to as sloshing
[37,38].
When dealing with free liquids inside a tank, the classical and simplest
approach to assess the impact of propellant sloshing on S/C dynamics and
associated GNC performance consists in including reduced-order linear
lateral sloshing models, such as pendulum or mass-spring mechanical
models, as in the Abramson model [39], into the S/C dynamics model.
This enables synthesis and first-order analysis of the control system in
time- and frequency-domain at reduced computational costs, exactly the
same way that has been analyzed in previous chapter about flexibility.
This is done because equations of motions of oscillating point masses and
rigid bodies are easier to be integrated in the equations of motion of a flex￾ible spacecraft than those of a continuous liquid. By lateral sloshing is meant
the standing wave formed on the surface of a liquid when a tank partially
filled with liquid is oscillated. In the moment when the propellant mass im￾pacts the wall of the fuel tank, it will transfer momentum to the spacecraft. If
the tank is not at the center of mass of the vehicle, this will create an impulse
moment that will affect the vehicle attitude. However, the pendulum or
spring-mass models are adequate under gravity or gravity-like conditions,
where inertial forces dominate over capillary forces in determining the fluid
dynamics, which is true on ground or in diaphragm tanks, during thrusters
firing or during attitude acceleration due to slews. When dealing with Pro￾pellant Management Device tanks under microgravity conditions, the sim￾ple pendulum mechanical models is no more accurate enough, since gas and
fuel are not separated. In these cases, the propellant tends to spread over all
the tank available internal surface, leading bubbles of gas to move toward the
center of the tank, thus creating a configuration whose dynamics needs
The space environment 111specific computational fluid dynamics (CFD) analyses to be computed. To
assess whether the motion is dominated or not by inertia forces, two nondi￾mensional numbers can be taken into consideration when the fluid is in mo￾tion: the first one as the ratio between inertia and capillarity forces, the Weber
number; the other one is the Froude number that compares inertia to gravity
actions.
We ¼ rv2L
s
Fr ¼ v2
gL
being r the density of the fuel, v its velocity, L the characteristic dimen￾sion, s the surface tension, and g the gravity acceleration. When these
nondimensional numbers are much greater than 1, then the fluid motion
is driven by inertia forces and lateral sloshing can be considered not negli￾gible. In this case, mechanical models are accurate enough and CFD analyses
can be avoided.
Following the largely used mass-spring representation of sloshing, the
general form of the equations of motion for each tank slosh mode frequency
is the one of a small point mass attached to an extended, rigid, center body,
allowed to execute small oscillations about its equilibrium positions. The
equations of motion may be derived from a Lagrangian formulation,
following the same procedure described in the previous paragraph when
dealing with general flexibility. The effects on pointing and stability are
the same, reminding that sloshing only is effective where relevant accelera￾tions are present in the system; thus, it can be usually neglected during slow
rate data acquisitions. However, if extremely accurate analyses are necessary
for these specific conditions, CFD analyses of the fluid motion inside the
tanks may be needed.
The slosh motion is characterized by a natural frequency that is a func￾tion of the tank shape and of the axial acceleration imposed on the tank; for a
spherical tank, this becomes:
un ¼ Pu
ffiffiffiffiffiffi
r=g p
where Pu is the natural frequency parameter, r the tank radius, and g the
acceleration the tank is subjected to. The acceleration influencing the
sloshing dynamics, g, is the dynamically induced acceleration acting along
112 Andrea Capannolo et al.the axis of the tank; for practical applications, it can be selected to be equal to
the average gravitational acceleration along the orbital motion. Pu is
dependent from the geometry of the tank and from the properties of the
fluid [39,37,38]. Note that the sloshing model shall also consider the liquid
damping. For surface-tension tank technology, the slosh motion damping is
primarily provided by the liquid viscosity; for diaphragm tank technology,
the damping ratio is much higher than for surface tension tanks due to the
elastic flexing of the diaphragm and to the increased viscous effects at the
liquid-diaphragm interface. The liquid damping is then included in
the dynamical models with the equations of a mechanical damper, and the
sloshing equivalent mechanical model results in a damped pendulum or
mass-spring-damper system [29]. Similar to the flexibility, the sloshing is
commonly directly integrated in the equations of motion, which are then
combined with forces and torques of other perturbation sources.
Parasitic forces and torques during thrusters firing
Spacecrafts often need a propulsion system to perform orbital maneuvers: for
example, a satellite in LEO can use propulsion for initial orbit acquisition or
orbit maintenance, or even to perform collision avoidance maneuvers. Pro￾pulsion is used also as the most common solution for deorbiting a spacecraft
at the end of its lifecycle to comply with the current international guidelines
to limit orbital debris. Similarly, geostationary satellites typically use thrusters
for station-keeping and a large apogee motor for the initial acquisition of
their nominal orbit after the injection in a geostationary transfer orbit by
the launcher. Whatever the purpose of the on-board propulsion system,
the system shall be designed taking into account the fact that propulsive
forces are just ideally in the designed direction: in reality, those directions
will have a misalignment with respect to the nominal ones, creating an
out-of-plane component of the force that also generates a torque. More￾over, the position of the CoM can have a displacement with respect
to the thrust direction, and it will also vary during the spacecraft lifetime
as the propellant is consumed, leading to further torques generated about
the CoM. In addition, if the propulsion system is based on thrusters used
symmetrically with respect to the CoM, so that torques are not nominally
created, then it has to be considered that the real amount of thrust generated
by each thruster will differ from the nominal one. Typically, in the order of
5%e10% up to 15%. This results in a worst case in which one thruster pro￾vides less force than it is supposed to, and its symmetric one delivers more
than expected. This of course results in undesired force and torque
The space environment 113contributions around the CoM. The following discussion will aim to the
parasitic torque effects, since the force ones are inherently described to
compute the torques.
As long as thrusters are continuously firing, these parasitic forces and tor￾ques manifest as constant force and torque disturbances. Clearly, these dis￾turbances are only present during firing, therefore only during orbital
maneuvers, if the propulsion system is aimed at that purpose. However, dur￾ing these phases of the satellite lifecycle, every steady-state error will result in
a constant misalignment between the required and the delivered DV.
Therefore, it is of utmost importance to compensate for these constant dis￾turbances by designing a controller that removes, or at least limits, any
steady-state error in presence of constant disturbance forces and torques.
It is important to underline that parasitic torques, when present, are one
of the highest attitude disturbances acting on the satellite. Obviously, errors
and disturbances in thruster firings do not affect only the attitude motion,
but the whole translational and rotations dynamics. As said, even if this sec￾tion focuses on parasitic torques, the internal perturbation forces due to
thrusters’ errors directly apply to the translational GNC.
In the following, a short insight on how to compute the different con￾tributions is provided.
Deviation angle
The real thrust direction will be different from the ideal one, by a deviation
angle that is the sum of two contributions: the difference between the thrust
direction and the longitudinal axis of the thrusters, and the difference be￾tween this longitudinal axis and the spacecraft reference direction (i.e., the
direction where we desire our thruster to be along). These two contribu￾tions to the total deviation angle can vary in a range from 0.1 to 1 each,
depending on the quality level of the thruster manufacturing and the atten￾tion during the spacecraft assembly phase. In fact, the most proper way to
reduce the angle between the longitudinal axis of the thrusters and the
spacecraft reference axis is to have an alignment measure of that angle and
then act to reduce it with mechanisms on the thruster, if they are present.
The measurement is typically a laser measure, acquiring the output circum￾ference of the nozzle to define the perpendicular to that surface, to be
compared with the spacecraft reference axes.
If we assume to have two symmetrical thrusters with respect to a refer￾ence axis of the satellite, as in Fig. 3.10, where a simplified 2D schematic is
provided, the worst case for the generation of parasitic torques is when both
114 Andrea Capannolo et al.thrusters have a deviation angle in the same direction, so that the difference
between arms is maximum. Both contributions to the deviation angle dis￾cussed before are independently affecting the system.
In this case, a torque around the x-axis will be generated, approximated
by:
t ¼ 2 F hsin a
where t is the generated parasitic torque, F is the nominal force of each
thruster, a is the deviation angle, and h is the CoM height with respect to
force application point.
Center of mass variation
With reference to Fig. 3.10, the same concept of generating a parasitic
torque applies when it is not the thrust direction deviating, but the CoM
moving from the longitudinal axis. For example, if the CoM is biased
from the z-axis along the y-axis, then, one thrust will have a longer arm
than the other, creating a parasitic torque:
t ¼ 2FDy
where Dy is the offset of the CoM along the y-axis.
Therefore, it is important to configure the spacecraft such that the
displacement of the CoM from the axis parallel to thrust direction is con￾tained within an acceptable threshold, i.e., a threshold that allows for
manageable parasitic torques. However, CoM position can also vary
throughout the mission, for example, due to fuel consumption inside the
tank: in this case, care must be paid in order to let the CoM move possibly
only along the longitudinal direction, i.e., the z-axis in the example in
Figure 3.10 Parasitic torque generated by a deviation angle of the thrusters.
The space environment 115Fig. 3.10, so that nominally no parasitic torque is created. In a real case, a
slight parasitic torque will be created even in that case, due to the presence
of misalignments and the coupling between an even small deviation angle
and the CoM movement along Z.
Thrust magnitude accuracy
The third contribution to parasitic torques is provided by the fact that
thrusters deliver a force with an associated accuracy: in fact, given the
same conditions (i.e., temperature of the tank and pressure), a thruster can
provide a certain percentage more, or less, than the nominal thrust for those
conditions. In other words, the delivered thrust will be: nominal  X%,
where X is typically less than 15% at 3s. This translates in another contribu￾tion to the total parasitic torque. As already stated, the worst case occurs
when one thruster delivers less torque than it was expected, while its sym￾metric delivers more, leading to:
t ¼ 2DFd
where DF is the delta-thrust respect to the nominal case and d the arm
between the thrusters.
Effects on dynamics and GNC
Once all the distinct contributions have been assessed, the total parasitic tor￾que can be computed. It is a good practice to not directly sum the three
terms, as those are worst cases that are very unlikely to occur at the same
time, but to use instead a root-sum-square to define the total disturbance
torque in a less pessimistic, yet very conservative way.
The impact of parasitic torques upon the spacecraft is twofold: on one
side, GNC designers shall ensure that there is sufficient control authority
to cope with the disturbance torque, and at the same time with all the other
disturbances acting on the spacecraft. On the other side, if momentum ex￾change actuators (e.g., reaction wheels) are used on the satellite as the pri￾mary controlling equipment, it shall be assessed whether the momentum
build-up caused by parasitic torques during thrusters firing can be coped
with the available momentum storage given the size of the wheels and
the configuration of the wheel assembly. Indeed, if a 0.1Nm parasitic torque
is generated during firing, then a 100s burn will cause 10Nm in momentum
build-up that shall be stored in reaction wheels. It is not rare that one of these
two assessments, or even both, leads to conclude that the boarded reaction
wheels cannot cope with the generated parasitic torques. In case it is not
116 Andrea Capannolo et al.possible to board larger wheels, there are essentially two ways to solve the
issue: limiting the parasitic torque, for example, reducing the deviation angle
or the CoM displacement or controlling attitude during firing by off￾modulating thrusters forces instead of using reaction wheels, or using a com￾bination of both methods, as described in Ref. [40]. In the cases where only
the momentum build-up may lead to GNC issues, while control authority is
sufficient to grant controllability, it could be considered to limit the firing
duration and split orbital maneuvers in more thruster burns. However,
this option is less preferable given the evident impact on the operability of
the spacecraft.
Electromagnetic disturbances
Earth magnetic field has a negligible effect on the translational orbital mo￾tion, but it strongly interacts with spacecraft residual dipole, generating a
disturbance torque equal to:
tmag ¼ m  B (3.15)
where m is the satellite residual dipole and B is the Earth’s magnetic field.
Both these quantities need to be evaluated in order to assess this disturbance
torque. Earth’s magnetic field can be modeled as described above in the
external space environment sections, and its evaluation is relatively simple by
exploiting the standard reference models.
The same cannot be said for the other term of the equation, the space￾craft residual dipole. This can be evaluated in essentially two ways: a detailed
budget of the residual dipole of each component of the spacecraft or a mea￾surement of the spacecraft magnetic field. The first is simpler and less expen￾sive but assumes that information is available for each relevant component of
the satellite, typically payloads, electronic drives, magnetic parts, etc. Evalu￾ation of the dipole can otherwise be done indirectly through a measurement
of the spacecraft magnetic field, possibly from several positions and at
different distances, and then applying the formula of the magnetic field pro￾duced by a dipole at a given distance:
B ¼ m0
4p
"
3rðm$rÞ
jrj
5  m
jrj
3
#
where m0 is the magnetic permeability in vacuum. The formula cannot be
simply reversed, so a dipole model could be fitted to the magnetic field
measurements using a nonlinear least squares optimization, as performed in
The space environment 117Ref. [41]. When performing such measurements, extreme care must be paid
in order to reduce the effect of external magnetic sources and the magnetic
field due to sources different from the spacecraft itself: for this reason, the
utilization of an anechoic chamber is addressed as the most proper solution
for this kind of test. As such, this kind of measurement is typically used for
smaller satellites when estimation is not possible or not sufficiently accurate.
For example, when commercial off-the-shelf components are used, the
residual dipole information of the equipment is usually not available. On the
contrary, for larger satellites, which can barely fit an anechoic chamber and
for which information are likely available from suppliers, a dipole budget is
typically assessed. As an order of magnitude, a satellite weighing between
500 and 800 kg can have a residual dipole in the order of a few Am2 (i.e., 1
to even 4e5) that decreases for smaller satellites, typically ranging below
0.1e0.01 Am2 for CubeSats [42].
The effect of this disturbance is certainly related to the generation of a
torque according to Eq. (3.15) that shall be compensated by the attitude
control system. However, there is another subtle effect: residual magnetic
dipoles can degrade magnetometers measurements, since the spacecraft
dipole generates a magnetic field that locally distorts Earth’s field. The
strength of this local field decreases with the cube of the distance from the
source of the dipole, thus it is important to accommodate magnetometers
inside the satellite far from any sources of disturbance, as far as it is enough
to not degrade magnetic field measurements. If magnetic torquers are used
on the spacecraft, it is a common practice both to place magnetometers as far
as possible from the torquers and to acquire magnetometers data in a duty
cycle only when torquers are off.
Internal vibrations
A spacecraft can be affected by several sources of vibrations, that in general
can be associated to all the rotary parts present on board: reaction wheels,
Solar Array Drive Mechanism, rotating motors in the payload, etc. These
components emit microvibrations as forces and torques, whose amplitude
and frequency depend on the equipment speed of rotation. Moreover, these
forces and torques are modulated by the satellite structure and ultimately
result in perturbations on the spacecraft dynamics. Therefore, they affect
the relative stability of the pointing error, and they are of particular impor￾tance for missions requiring high pointing accuracy and stability.
A general approach to study the problem is to develop a FEM model for
each relevant component of the spacecraft, integrate it into the spacecraft
118 Andrea Capannolo et al.FEM model, and then analyze the overall response of the system to micro￾vibrations in different situations. Since reaction wheels are in most cases one
of the highest contributors to microvibrations, due to wheel imbalance,
bearing torque noise due to imperfections, bearing friction effects, motor
torque ripple, motor cogging, etc., particular care is taken while analyzing
wheels behavior. A typical outcome of this analysis is the waterfall plot for
the reaction wheels, a three-dimensional graph representing the amplitude
of their vibrations versus the speed of the wheel and its vibrational fre￾quency, as in Fig. 3.11 taken from Ref. [43].
This graph is useful to evaluate the frequencies of resonance of the
wheel, to see if they can interact with the spacecraft structure, and how
operative wheel speed can affect the amplitude of these critical frequencies.
However, the end-result of the microvibration analysis is typically the effect
of the microvibration on the line of sight of instruments present on board, as
can be well seen in Ref. [44]. Microvibrations in space missions are a wide
topic that cannot be treated in detail here, but the topic can be deepened in
[43e45,46].
Reaction wheel jitter
If, on one side, forces and torques due to microvibrations can cause coupling
effects with the spacecraft structure, leading to possible resonances and a
Figure 3.11 3D vibrations amplitude versus the speed of the wheel and vibrational
frequency.
The space environment 119depointing of the payload, on the other side, a similar final depointing effect
can be caused by torques generated by reaction wheels due to their intrinsic
vibration, referred to as jitter. Jitter torques on the spacecraft are caused by
static and dynamic unbalances of the reaction wheels, which generate forces,
and thus torques, applied to the mounting structure of the wheels as in
Fig. 3.12.
Static imbalances are radial asymmetries in mass distribution: each spin￾ning wheel with a static imbalance will impose a periodic force on the space￾craft. The magnitude of the force vector is constant; however, its direction
changes with time. As explained in Ref. [45], in the case of a wheel with spin
axis aligned with the z-axis, the force on the spacecraft breaks down as:
f z ¼ Szu2
z cosðuzt þ fzÞbx þ Szu2
z sinðuzt þ fzÞby
Being Sz the static unbalance (in [kg m]), uz the wheel speed in rad/s,
and fz the phase, considered null here as a simplifying assumption. These
forces are applied at the site of the reaction wheel assembly: as a result,
any force not acting through the CoM also acts as a torque on the spacecraft.
Below it is shown the set of all forces and torques on the body due to any
static imbalance as a function of the wheel angular velocities:
Figure 3.12 Reaction wheels jitter representation.
120 Andrea Capannolo et al.fs

ux; uy; uz

¼

Syu2
y sin
uyt þ fy
	
þ Szu2
z cosðuzt þ fzÞ
	
bx
þ 
Szu2
z sinðuzt þ fzÞ þ Sxu2
x cosðuxt þ fxÞ

by
þ

Sxu2
x sinðuxt þ fxÞ þ Syu2
y cos
uyt þ fy
		bz
ts

ux; uy; uz

¼ rw  fs

ux; uy; uz

Dynamic imbalances are asymmetries in mass distribution across the
thickness of the wheel. Combining the effects of three wheels of a typical
reaction wheel assembly, the net torque on the spacecraft due to dynamic
imbalances Dx; Dy; Dz (in [kg m2]) is:
td

ux; uy; uz

¼

Dzu2
z sinðuzt þ f'zÞ þ Dyu2
y cos
uyt þ f'y
	
bx
þ 
Dxu2
x sinðuxt þ f'xÞ þ Dzu2
z cosðuzt þ f'zÞ

by
þ

Dyu2
y sin
uyt þ f'y

þ Dxu2
x cosðuxt þ f'xÞ
	
bz
It is worth to notice that since these are pure torques, the net force on the
spacecraft is null.
Depending on wheel size and imbalances, satellite inertia, and wheel
speed, jitter final effect on depointing the line of sight of the payload can
be very relevant in some cases, typically those missions with large satellites
requiring a high degree of pointing accuracy or results to be negligible in
other cases. Jitter effect on the pointing error varies with the square of the
reaction wheel speed, thus suggesting that, for a given wheel size and imbal￾ance and satellite inertia, varying (i.e., reducing) the working point of the
reaction wheels is highly impactful on this disturbance, and it can be a
good ally to reduce undesired depointing effects in situations where jitter
is relevant. Further details about reaction wheels disturbances will be dis￾cussed in the Chapter 7 e Actuators.
Parasitic forces and torques due to plume impingement
Another cause of disturbances acting on the satellite is represented by
thrusters’ plume impingement, that is usually negligible, but can become
relevant in particular situations.
In general, the flux exiting thrusters’ nozzle is not linear but widespread,
as in Fig. 3.13.
This has two main consequences: on one hand, part of the flux can
possibly reach solar panels and degrade their performance; on the other
The space environment 121hand, every part of the flux which hits other parts of the satellite creates a
force acting on the spacecraft, and thus a torque with arm, the segment be￾tween the application point of the force and the CoM of the satellite. Even if
thrusters are symmetric, their plume forces could be asymmetric due to
different alignments and different thrust magnitude accuracy. Typically,
these parasitic forces and torques are negligible if compared to other sources
of disturbance due to the fact that the accommodation of the thrusters is usu￾ally such that the exit surface of the nozzle is perpendicular and opposite to
relevant surfaces of the spacecraft (e.g., solar arrays). However, there can be
rare cases where the accommodation of thrusters and the configuration of
large solar panels is such that relevant parasitic torques can be created during
prolonged thrusters firing, as it was experienced for the ESA Sentinel 1 sat￾ellite [47]. For modeling purpose, please refer to Ref. [48].
Thermal snap
Thermal shock can happen during transition from sunlight to shadow or vice
versa, when solar panels and other sensible components experience a fast, high
thermal gradient. In fact, thermal conditions are significantly different for the
surfaces exposed to the Sun compared to the back ones. This thermal differ￾ence between the two sides of the panels can possibly lead to thermal snaps,
exciting vibrations in the panels, which in turn cause perturbations on the atti￾tude dynamics. However, thermal snap shall be considered only for spacecraft
with very large, flexible solar arrays or even booms, and for missions where
fine attitude pointing during flight over the terminator line or in its proximity
is important. Thus, this is typically not the case for optical satellites.
Figure 3.13 Thruster flux representation.
122 Andrea Capannolo et al.Internal perturbations modeling guidelines
International standards and guidelines do not enter the details of inter￾nal perturbations modeling because they are extremely mission- and system￾dependent, and their generalization and standardization are extremely
difficult.
International standards classify the internal perturbations as error sources,
and they give general guidelines on how to handle these internal error sour￾ces in the GNC design. Internal error sources are elementary physical pro￾cesses originating from a well-defined internal source, which contributes to a
GNC performance error. Obviously, sensor errors also fall in this category,
but microvibrations, subsystem flexibility, internal mass movements, mis￾alignments, thermal distortions, jitter, etc., are listed by the standards as rele￾vant internal error sources.
The guidelines suggest handling these disturbances by listing all signifi￾cant internal perturbations contributing to the GNC design [49,50].
Then, they shall be preliminarily quantified and ranked by disturbance
magnitude. According to the required accuracy level of the system, and in
agreement with the details of the external perturbations modeling, the least
relevant internal perturbations may be discarded. A justification for neglect￾ing some potential error sources should be maintained in the GNC design
documentation to show that they have been considered. Error sources shall
be ranked in terms of mean and standard deviation along each spacecraft axis.
Furthermore, the internal perturbations shall be also classified according to
their temporal distributions and reproducibility. In fact, they can be:
• Time constant.
• Periodic.
• Transient.
• Linearly varying (i.e., increasing/decreasing).
Moreover, their evolution can be:
• Deterministic.
• Random.
In the case of random internal disturbances, they are associated to a spe￾cific distribution, which can be uniform, Gaussian, or another one. When
the list of the selected relevant internal perturbations is available, with their
magnitude, temporal evolution, reproducibility, and distribution, the GNC
design can be performed, exploiting system simulations including the most
updated internal perturbations’ models.
The space environment 123It is relevant to remark that the accuracy level of external and internal
perturbations modeling shall be balanced, including effects of comparable
magnitude in the two domains. Moreover, as a general rule, we should
follow a conservative approach and include as many error sources as possible
rather than assuming that some are negligible. Even small errors can
contribute significantly if there are enough of them.
What is relevant for GNC?
The space environment sets the boundary conditions for any space￾craft while on orbit along its operative lifetime. Evidently, it is strongly
characterizing the entire design of a space mission. The same is true for
the GNC system, which is particularly affected by the space environment
in terms of perturbative forces and torques. Thus, the GNC design shall be
based on a correct space environment modeling, in terms of accounted
perturbations and evaluation of their effects on the spacecraft dynamics.
As discussed in Chapter 10 e Control, the disturbances on the dynamics
enter the GNC loop and induce errors on the desired state, if not properly
managed. Moreover, perturbations may lead to actuators ineffectiveness if
the GNC design underestimate the environmental perturbations, both
external and internal.
One of the main aspects to consider is what kind of perturbations need to
be accounted to model the space environment. Indeed, as presented in this
chapter, the perturbation sources have different impact on the spacecraft dy￾namics according to the region of space the spacecraft is operating in (e.g.,
central attractor, distance from the surface, inclination with respect to equa￾torial planes), to its internal components and system characteristics, to its
dynamical state (e.g., velocity, rotation rates), to its current GNC mode
(e.g., actuators in use, required accuracy and stability), just to name the prin￾cipal ones. Thus, it is evident that a complete system level analysis shall be
performed beforehand to define the operative external and internal environ￾ments. Then, a trade-off between desired accuracy and design complexity,
also considering the associated computational and modeling costs, is per￾formed to set the threshold when a particular perturbation source can be
neglected. As already said, this analysis phase may be supported by prelimi￾nary models and tools providing a rough estimation of any present pertur￾bation to rank them and conservatively select those that may truly affect
the dynamics and the GNC design. Finally, the definitive perturbation
models are implemented according to the international standards and
124 Andrea Capannolo et al.guidelines. These models shall be used to simulate and analyze the spacecraft
in any of its operative conditions in order to drive the design of the space
mission in all its elements.
Particular care must be given to internal perturbations and spacecraft
configuration analyses, since they may prevent actuator and sensor ineffec￾tiveness. To make some examples, large offsets in the CoM or in the inertia
moments may lead to oversized actuators, bad electromagnetic configura￾tion can deteriorate the nominal performance of magnetic sensors and actu￾ators, wrong thermo-structural design might create dynamical coupling that
are difficult to be managed and controlled.
Obviously, even if more standardized and easier to be analyzed, external
environment shall not be overlooked. We shall always have in mind that
there is no environment model or set of perturbation sources that fits for
any space mission. A superficial environment analysis will lead to a failed
GNC design. For instance, some sensors and actuators may not properly
work on certain orbits (e.g., due to weak or unknown magnetic fields,
due to unmodeled sunlight reflection or albedo from the planet). In general,
a GNC design can be not adequate if relevant perturbation sources are
neglected or mismodeled (e.g., overlooked torques exceeding actuation ca￾pabilities, underestimated environmental phenomena disturbing sensor
measurements).
Perturbation sources need to be tuned at a level of accuracy that is
coherent with the whole GNC design. The modeling details shall be
coherent and comparable between external and internal perturbing terms.
Moreover, as a rule of thumb, if a perturbation source is included, all the
terms that are more relevant must be included. For example, considering
a LEO orbiting spacecraft, the rough orders of magnitude of the external
orbital perturbations are:
• Keplerian acceleration: w 8:5 m=s
2
.
• J2: w 102 m=s
2
.
• J22: w 104 m=s
2
.
• J66: w 105 m=s
2
.
• Atmospheric drag: w 105

108 m=s
2
.
• Moon/Sun: w 106 m=s
2
.
• Dynamic solid tides: w 107 m=s
2
.
• SRP: w 107 m=s
2
.
The space environment 125Hence, if SRP is considered, all the previously listed terms shall be
included as well. Similarly, internal perturbations leading to accelerations
larger than w 107 m=s
2 shall be accounted.
Space environment models are not only used for GNC design and an￾alyses, but they are also embedded in GNC system to have an on-board
representation of the environment, which can be used for GNC purposes.
For example, planetary ephemerides may be used to implement guidance
targets or reference pointing directions, Sun or Earth models are used to be
compared with sensor measured data in navigation functions, internal vi￾bration or flexible models can be included in the control laws to have
improved performance. Therefore, having a proper environment modeling
has also a direct impact on the GNC functions. Mismodeled effects may
lead to errors with respect to the desired reference states or wrong distur￾bance rejection actions. Analogous problems arise from poorly accurate
models. However, the on-board models shall carefully balance accuracy
with the required computational resources. In these regards, it is crucial
to balance the fidelity of the environment models with the practical needs
and with the requirements of the GNC system. Excessively accurate envi￾ronment models waste the on-board resources without improving the final
performance, on the contrary too rough models can limit the precision of a
refined GNC chain.
References
[1] I. Newton, Philosophiae Naturalis Principia Mathematica 2, 1833 typis A. et JM
Duncan.
[2] A.M. Legendre, Recherches sur l’attraction des sphéroïdes homogenes, De l’Imprim￾erie Royale, 1785.
[3] E.W. Hobson, The Theory of Spherical and Ellipsoidal Harmonics, Cambridge Uni￾versity Press, 1931.
[4] W.M. Kaula, Theory of Satellite Geodesy, Chap. 1, Blaisdell Publishing Company,
Waltham, Massachusetts, 1966.
[5] A.E.H. Love, The yielding of the Earth to disturbing forces, in: Proceedings of the
Royal Society of London - Series A: Containing Papers of a Mathematical and Physical
Character 82, 1909, pp. 73e88.
[6] D.D. McCarthy, G. Petit, IERS conventions (2003). International Earth Rotation And
Reference Systems Service (IERS)(Germany), Journal of Geodesy 77 (10) (2004)
585e678.
[7] E.C.S.S. Secretariat, Space Engineering: Space Environment (ECSS-E-ST-10-04C),
European Cooperation for Space Standardization, 2020. https://ecss.nl/.
[8] https://www.ngdc.noaa.gov/IAGA/vmod/igrf.html.
[9] G. Batchelor, An Introduction to Fluid Dynamics (Cambridge Mathematical Library),
Cambridge: Cambridge University Press, 2000, https://doi.org/10.1017/
CBO9780511800955.
126 Andrea Capannolo et al.[10] N. Sissenwine, M. Dubin, H. Wexler, The US standard atmosphere, 1962, Journal of
Geophysical Research 67 (9) (1962) 3627e3630.
[11] D. Rees, J.J. Barnett, K. Labitzke, COSPAR International Reference Atmosphere, Pt.
2: middle atmosphere models, Advances in Space Research 10 (12) (1986) 1990.
[12] L.G. Jacchia, Revised Static Models of the Thermosphere and Exosphere with Empir￾ical Temperature Profiles, SAO Special Report, 1971, p. 332.
[13] L.G. Jacchia, Thermospheric Temperature, Density, and Composition: New Models,
SAO Special Report, 1977, p. 375.
[14] D.A. Vallado, Fundamentals of Astrodynamics and Applications, vol. 12, Springer Sci￾ence & Business Media, 2001.
[15] https://www.spacex.com/updates/ 8th February 2022.
[16] P.C. Knocke, J.C. Ries, B.D. Tapley, Earth Radiation Pressure Effects on Satellites,
Proceedings of the AIAA/AAS Astrodynamics Conference, Washington DC, 1988,
pp. 577e586.
[17] A. Roy, Orbital Motion, John Wiley & Sons, New York, 1988.
[18] F.T. Geyling, H.R. Westerman, Introduction to Orbital Mechanics, Addison-Wesley
Aerospace Series, 1971.
[19] A.C. Long, J.O. Cappellari Jr., C.E. Velez, A.J. Fuchs, Goddard Trajectory Determi￾nation System (GTDS) Mathematical Theory, National Aeronautics and Space
Administration/Goddard Space Flight Center, 1989.
[20] The Astronomical Almanac, UKHO General Publication: GP 100-21, 2021.
[21] J. Meeus, Astronomical Algorithms, Willmann-Bell, 1991.
[22] J.C. Mason, D.C. Handscomb, Chebyshev Polynomials, Chapman and Hall/CRC,
2002.
[23] I.I. Alexeev, V.V. Kalegaev, E.S. Belenkaya, S.Y. Bobrovnikov, Y.I. Feldstein,
L.I. Gromova, Dynamic model of the magnetosphere: case study for January 9e12,
1997, Journal of Geophysical Research: Space Physics 106 (A11) (2001)
25683e25693.
[24] N.A. Tsyganenko, D.P. Stern, Modeling the global magnetic field of the large-scale
Birkeland current systems, Journal of Geophysical Research: Space Physics 101
(A12) (1996) 27187e27198.
[25] J.M. Picone, A.E. Hedin, D.P. Drob, A.C. Aikin, NRLMSISE-00 empirical model of
the atmosphere: statistical comparisons and scientific issues, Journal of Geophysical
Research: Space Physics 107 (A12) (2002). SIA-15.
[26] B.R. Bowman, W.K. Tobiska, F.A. Marcos, C. Valladares, The JB2006 empirical ther￾mospheric density model, Journal of Atmospheric and Solar-Terrestrial Physics 70 (5)
(2008) 774e793.
[27] B. Bowman, W.K. Tobiska, F. Marcos, C. Huang, C. Lin, W. Burke, A new empirical
thermospheric density model JB2008 using new solar and geomagnetic indices, in:
AIAA/AAS Astrodynamics Specialist Conference and Exhibit, 2008, p. 6438.
[28] W.M. Folkner, J.G. Williams, D.H. Boggs, R.S. Park, P. Kuchynka, The planetary
and lunar ephemerides DE430 and DE431, Interplanetary Network Progress Report
196 (1) (2014).
[29] L. Meirovitch, Fundamentals of Vibrations, Waveland Press, Long Grove, 2010.
[30] J.L. Junkins, Introduction to Dynamics and Control of Flexible Structures, AIAA Ed￾ucation Series, Reston, 1993.
[31] R. Zhang, S.N. Singh, Adaptive Output Feedback Control of Spacecraft with Flexible
Appendages, American Control Conference, 2001.
[32] G. Bodineau, S. Boulade, B. Frapard, W. Chen, S. Salehi, F. Ankersen, Robust control
of large flexible appendages for future space missions, in: Proceedings of 6th Interna￾tional Conference on Dynamics and Control of Systems and Structure in Space, July
2004.
The space environment 127[33] E. Paolini, M. Battilana, F. Curti, Fast attitude maneuvers and accurate pointing for an
ultra-agile spacecraft with flexible appendages actuated by thrusters and reaction
wheels, in: ESA GNC 2011 Conference, 2011.
[34] A.A. Shabana, Dynamics of Multibody Systems, Cambridge University Press, Cam￾bridge, 2013.
[35] A. Colagrossi, M. Lavagna, Integrated vibration suppression attitude control for flexible
spacecrafts with internal liquid sloshing, Multibody System Dynamics 51 (2021)
123e157, https://doi.org/10.1007/s11044-020-09755-9.
[36] C. Angelone, E. Paolini, M. Lavagna, Spacecraft flexible attitude dynamics modelling
for accurate control design, in: ESA GNC 2021 Conference, 2011.
[37] F.T. Dodge, The New Dynamic Behavior of Liquids in Moving Containers, South￾west Research Institute, San Antonio, 2000.
[38] R.A. Ibrahim, Liquid Sloshing Dynamics: Theory and Applications, Cambridge Uni￾versity Press, Cambridge, 2005.
[39] H.N. Abramson, W.H. Chu, G.E. Ransleben Jr., Representation of fuel sloshing in
cylindrical tanks by an equivalent mechanical model, ARS Journal 31 (12) (1961)
1697e1705.
[40] L. Cederna, E. Paolini, J.D. Biggs, C. Celiberti, Thrusters OFF-Modulation for Atti￾tude Control during Orbital Manoeuvres, ESA GNC 2021 Conference, 2011.
[41] M.P. Christopher, On-orbit performance and operation of the attitude and pointing
control subsystems on ASTERIA, in: Small Satellites Conference (SmallSat 2018),
Logan, Utah, August 4e9, 2018, 2018.
[42] NASA Technical Report, Spacecraft Magnetic Torques, NASA SP-8018, 1969.
[43] Z. Zhang, G.S. Aglietti, W. Ren, Coupled microvibration analysis of a reaction wheel
assembly including gyroscopic effects in its accelerance, Journal of Sound and Vibration
332 (22) (2013) 5748e5765.
[44] M. Vitelli, B. Specht, F. Boquet, A process to verify the microvibration and pointing
stability requirements for the BepiColombo mission, in: International Workshop on
Instrumentation for Planetary Missions 1683, 2012, p. 1023.
[45] C. Galeazzi, P.C. Marucchi-Chierro, L.V. Holtz, Experimental activities on
ARTEMIS for the microvibration verification, in: ESA International Conference on
Spacecraft Structures, Materials and Mechanical Testing, Noordwijk, Netherlands,
1996, pp. 997e1006.
[46] D.-K. Kim, Micro-vibration model and parameter estimation method of a reaction
wheel assembly, Journal of Sound and Vibration 333 (18) (2014) 4214e4231.
[47] M.M. Serrano, M. Catania, J. Sanchez, A. Vasconcelos, D. Kuijper, X. Marc, Sentinel￾1A flight dynamics LEOP operational experience, in: International Symposium on
Space Flight Dynamics Symposium, October 2015.
[48] T. Teil, H. Schaub, Force and Torque Disturbance Modeling Due to General Thruster
Plume Impingement, 68th International Astronautical Congress, Adelaide, Australia,
2017.
[49] E.C.S.S. Secretariat, Space Engineering: Control Performance (ECSS-E-ST-60-10C),
European Cooperation for Space Standardization, 2008. https://ecss.nl/.
[50] ESA, Pointing Error Engineering Handbook, 2011. ESSB-HB-E-003.
[51] K. Yazdi, E. Messerschmid, Analysis of parking orbits and transfer trajectories for
mission design of cis-lunar space stations, Acta Astronautica 55 (3e9) (2004) 759e771.
[52] D.A. Vallado, F. David, A critical assessment of satellite drag and atmospheric density
modeling, Acta Astronautica 95 (2014) 141e165.
[53] R. Hahn, R. Seiler, Simulating and analyzing the microvibration signature of reaction
wheels for future non-intrusive health monitoring methods, in: Proceedings 14th Eu￾ropean Space Mechanisms & Tribology Symposium, Konstanz, Germany, 2011.
128 Andrea Capannolo et al.[54] K.C. Liu, P. Maghami, C. Blaurock, Reaction wheel disturbance modeling, jitter anal￾ysis, and validation tests for solar dynamics observatory, in: AIAA Guidance, Naviga￾tion and Control Conference and Exhibit, 2008, p. 7232.
[55] M.P. Le, M.H.M. Ellenbroek, R. Seiler, P. van Put, E.J.E. Cottaar, Disturbances in re￾action wheels: from measurements to modeling, in: ESA GNC 2014 Conference, 2014.
[56] L. Liu, Jitter and basic requirements of the reaction wheel assembly in the attitude con￾trol system, Advances in Space Research 52 (1) (2013) 222e231, https://doi.org/
10.1016/j.asr.2013.02.014.
The space environment 129This page intentionally left blankCHAPTER FOUR
Orbital dynamics
Andrea Capannolo1
, Stefano Silvestrini1
, Andrea Colagrossi1
,
Vincenzo Pesce2
1
Politecnico di Milano, Milan, Italy
2
Airbus D&S Advanced Studies, Toulouse, France
Orbital dynamics describes the translational motion of any object flying in
space. Indeed, whenever the spacecraft motion is not directly forced by
the control actions computed and actuated by the GNC system, it is affected
by the gravitational attractions of the celestial bodies and by the perturbations
forces due to the surrounding space environment. The gravity forces are
notably larger than the other terms, and, thus, they are primarily character￾izing the dynamics in space. According to the Newton’s Laws, this results
in a spacecraft motion that is always described as an orbit around one or
more gravitational attractors. Then, spacecraft natural translational motion
is modeled and described exploiting the fundamental rules of the orbital dy￾namics. The effects of the Guidance, Navigation, and Control (GNC) actions
are always directed in modifying the fundamental orbits driving the spacecraft
in space. Hence, it is mandatory to master the main concepts of orbital dy￾namics in order to properly design, implement, and operate a GNC system.
Along its orbit, the spacecraft is theoretically influenced by the gravita￾tional attraction of any existing celestial object. But under a practical
perspective, this is obviously not true since the magnitude of many perturb￾ing forces is dramatically larger than the gravity forces exerted by far away
planets or other minor celestial bodies. In real world, any spacecraft is pri￾marily orbiting around one main central attractor (i.e., the Earth, Mars,
the Moon, the Sun for interplanetary missions, etc.), and its orbit is described
according to the two-body problem (2BP) model. This dynamical model
can be very simple, modeling the unperturbed Keplerian orbits for prelim￾inary design, or extremely accurate, accounting for any relevant perturba￾tion force.
This chapter is divided in four sections:
• Two-body problem. This section introduces the main concepts of 2BP dy￾namics, listing all the useful elements for a GNC engineer. It presents the
basic two-body equations, orbit classification, and time laws.
Modern Spacecraft Guidance, Navigation, and Control
ISBN: 978-0-323-90916-7
https://doi.org/10.1016/B978-0-323-90916-7.00004-4
© 2023 Elsevier Inc.
All rights reserved. 131 jThen, two additional dynamical models are described, since they are
becoming very relevant for modern missions and applications: the three￾body problem (3BP) and the irregular body dynamics.
• Three-body problem. This section introduces the 3BP, which shall be used
whenever a mission is set in the region between two comparably relevant
gravitational attractors, with the spacecraft orbiting around the so-called
Lagrange points. This is becoming very common for missions in Cislunar
space, astronomical telescopes in the SuneEarth system, or exploration
missions for other planets’ moons, just to make some examples.
• Irregular solar system bodies. This section describes the gravitational envi￾ronment around irregular solar system bodies. Such modeling technique
is mandatory for any space mission around an asteroid, a comet, or
another minor solar system object.
• Relative orbital dynamics. The chapter is concluded with a section on the
relative spacecraft orbital dynamics. In fact, two objects in close orbits can
be analyzed describing their relative dynamics under a dedicated point of
view. Modern GNC applications are dedicated in solving relative dy￾namics problems, such as rendezvous, formation flying, or on-orbit
servicing.
The reader is invited to deepen the study of spacecraft orbital dynamics
in the dedicated books listed in the reference section [1e6].
Two-body problem
The 2BP represents the most known and used model for orbit design
and analysis. The model considers two masses only, with the smaller one be￾ing of negligible mass with respect to the larger (the main attractor).
The derivation of the 2BP equations of motions starts from the Newton’s
law of universal gravitation, applied to a generic distribution of N point
masses. The gravitational acceleration acting on the i-th body can be written
as [7]:
r€i ¼  X
N
j¼1; jsi
Gmj

rji


3rji
Here, r€i is the acceleration vector of the i-th mass with respect to the
barycenter of the system, G is the gravitational constant, mj is the mass of
the j-th body of the group, and rji is the position vector of the i-th body
with respect to the j-th body. The above Newton’s inverse square law
132 Andrea Capannolo et al.predicts that the attraction decreases based on the reciprocal of the square of
increasing distance of the i-th body from the j-th point mass, but it eventu￾ally does not go to zero. Although we commonly say satellites in orbit expe￾rience “zero-gravity,” this is not true. Of course, we think gravity is zero
because no normal reaction force is supporting the object. The force of grav￾ity is always present and causes the i-th body (e.g., a satellite) to fall contin￾ually around the j-th mass (e.g., the Earth).
In the vast majority of space applications, the motion of the object of in￾terest (an artificial satellite, a moon, etc.) is typically close to a main attractor
and rather distant from all other bodies of the cluster. In this context, it is
therefore natural to reduce the summation to the mutual attraction of the
two close bodies, hence:
r€1 ¼  Gm2
kr21k3r21
r€2 ¼  Gm1
kr12k3r12
(4.1)
The previous equation describes the motion of the two isolated masses
(or binary system) with respect to their common center of mass; however,
for space application, we are interested in how one body moves relatively
to the other. This requires an adaptation of the previous dynamics system,
exploiting the fact that the barycenter of the binary system is isolated and
not subjected to external forces. The motion of the full binary system is
described by the following equation:
m1r€1 þ m2r€2 ¼ 0
Considering that r12 ¼ r2  r1 by definition, it follows that the relative
acceleration of body “2” from body “1” reads:
r€2 ¼ m1
m1 þ m2
r€12 (4.2)
Substituting Eq. (4.2) to the second equation of the binary system dy￾namics (Eq. 4.1), the relative motion is obtained, and reads:
r€12 ¼  Gðm1 þ m2Þ
kr12k3 r12
In common applications, the body with mass “m2” (of which it is desired
to define the dynamics) is significantly smaller than the body having the mass
“m1” (the reference attractor). This implies that the overall mass of the binary
Orbital dynamics 133system can be approximated with one of the primary gravitational sources,
hence:
m1 þ m2w m1
This allows to define the so called “Restricted Two-Body Problem”
(R2BP), which reads:
r€¼  Gm1
krk3 r ¼ m
r3 r (4.3)
where m is called the “standard gravitational parameter,” r ¼ r12 and r ¼ krk
for simplicity of notation.
Integrals of motion and orbital elements
The dynamics of Eq. (4.3) system admits some integrals of motion, i.e., re￾lations among the state variables, which are constant over time, that provide
isosurfaces where the motion takes place. Such isosurfaces can be exploited
to reconstruct the motion in time, without resorting to numerical integra￾tion [8]. The search of the integrals of motion allows then to transform
the dynamics problem into a set of known parameters as a direct function
of the independent variable (i.e., time).
Integrals of motion
Given the three scalar, second-order differential equations of the R2BP, six
integration constants have to be defined.
Specific angular momentum
The specific angular momentum can be proven to be an integration con￾stant, by simply verifying that its time derivative is null:
h_ ¼ d
dt

r  r_

¼ r  r€¼ r  
m
r3 r ¼ 0
which is verified for all central forces, such as gravitation (i.e., r aligned to r€).
The condition ¼ r  r_ ¼ C, with C being a constant, implies that the
motion happens on a fixed plane (i.e., perpendicular to h).
Eccentricity vector
To define a second integration constant, consider the cross product between
r€ and h:
r€ h ¼ r€

r  r_

¼ m
d
dt
r
r

(4.4)
134 Andrea Capannolo et al.where the last equality can be verified by substituting the R2BP dynamics to
the acceleration term and developing the cross products in the rotating
frame.
The left-hand side of Eq. (4.4) can also be rearranged as:
r€ h ¼ dr_
dt
 h ¼ d
dt

r_  h

(4.5)
Hence, the combination of right-hand sides of Eqs. (4.4) and (4.5)
returns:
d
dt

r_  h  m
r
r

¼ 0
The argument of the derivation is therefore constant and represents the
expression of the eccentricity vector (or Laplace vector) e:
e ¼ 1
m

r_  h

 r
r
where the argument has been divided in advance by m. Notice that, by
definition, e lies on the orbital plane.
Specific energy
The two integrals of motion (h and e) provide six conditions, technically
enough to fully characterize the motion; however, such quantities are not
fully independent, as they are related through the condition h $ e ¼ 0.
Hence, a further scalar condition is needed. This is provided by the con￾servation of energy. Consider the product of the velocity r_ and acceleration
r€, i.e., the specific energy rate of the system:
r_ $ r€¼ r_ $

m
r3 r

The left-hand side is the (specific) kinetic energy rate, and it can be rear￾ranged as 1
2
d
dt 
r_ $ r_

. The right-hand side is the (specific) potential energy
rate, and it can be expressed in time derivative terms as m d
dt 
1
r

. Overall, the
specific energy rate reads:
d
dt 
1
2

r_ $ r_

 m
r

¼ 0
Hence, the specific orbital energy is proved to be constant, and its
expression reads:
Orbital dynamics 135ε ¼ 1
2

r_ $ r_

 m
r
(4.6)
Orbital elements
From the three integrals of motion ðh; e; εÞ, the six-dimensional state of an
orbiting object 
rðtÞ; r_ðtÞ

can be completely described. Nevertheless, one
may be interested in finding a more meaningful representation of the mo￾tion, through specific orbital parameters (or elements). This can be achieved
through the manipulation and elaboration of the integrals of motion. Notice
that dimensions of the problem are not affected by the change of parameters;
therefore, a set of six parameters is still required.
The constant nature of the specific angular momentum h implies the ex￾istence of a fixed plane on which the orbit lies. Hence, such plane defines a
fixed inclination angle “i” with respect to the x  y plane of the inertial
reference frame in which the state is represented. Furthermore, the intersec￾tion of the two planes defines a Nodal Axis, N. The angular distance be￾tween the x axis of the inertial frame and N represents a second fixed
parameter U, and it is named Right Ascension of the Ascending Node
(RAAN). On the orbital plane, N and e form a third fixed parameter (the
angle between the two vectors), named Argument of Periapsis, and labeled u.
The three parameters i, U, and u uniquely define the orientation of the
orbit; however, no information about its shape is provided so far.
On the orbital plane, the norm of the specific angular momentum can be
expressed in a simpler way leveraging a rotating reference frame with two of
its axes aligned with the position r and with h itself 
br qb hb

:
r ¼ rbr
r_ ¼ r_br þ r _
qqb
h ¼



r  r_


 ¼ r
2 _
q
(4.7)
Since h is constant, the third equation represents a confirmation of the
Kepler’s second law of planetary motion [2]. This equivalence will also be useful
to express the remaining orbital parameters.
From the eccentricity vector, it is possible to directly extract its magni￾tude e, which is used as shape-related parameter of the orbit. To better un￾derstand its meaning, consider the eccentricity vector e and the position
vector r, and define q as the angle between the two vectors. The following
relations hold:
r $ e ¼ r e cos q
136 Andrea Capannolo et al.r $ e ¼ r $

1
m

r_  h

 r
r

¼ h2
m  r
Putting together the right-hand terms of the two equations, it is possible
to express the orbital radius as a function of q:
rðqÞ ¼ h2=m
1 þ e cos q ¼ p
1 þ e cos q (4.8)
where p is the semilatus rectum, and reads:
p ¼ h2
m
(4.9)
Not only does this relation provide the evolution of the distance from
the gravity source along the orbit but also it confines the types of motion
existing in the R2BP to the conics subset (e.g., circles, ellipses, parabolas,
and hyperbolas), thus confirming (and extending) the Kepler’s First Law of
Planetary Motion [2].
From Eq. (4.8), other information can be extracted. The parameter q
(i.e., the angle between position and eccentricity vectors) is called True
Anomaly and is indeed another orbital parameter (function of time) which
defines the position of the orbiting object along its trajectory.
Furthermore, it is possible to find the minimum distance from the gravity
source by setting q ¼ 0:
rp ¼ rð0Þ ¼ p
1 þ e
(4.10)
In case of closed orbits, a maximum distance (i.e., the apocenter) can also
be derived, and it is located at q ¼ p:
ra ¼ rðpÞ ¼ p
1  e
(4.11)
Then, a last orbital element, i.e., the semimajor axis of the conic, is easily
derived from minimum and maximum radii as:
a ¼ rp þ ra
2 ¼ p
1  e2
Also, it follows that:
rp ¼ að1  eÞ
ra ¼ að1 þ eÞ
p ¼ a
	
1  e
2

(4.12)
Orbital dynamics 137Indeed, the semimajor axis of the conic represents the last constant
parameter, characterizing the size of the orbit. To prove it, the conservation
of specific orbital energy is exploited. As the energy value is preserved along
the orbit, it can be computed at any point of the conic. For convenience, the
pericenter point is considered, as the velocity is fully tangential (i.e., r_p ¼ 0),
and can be easily expressed in terms of the specific angular momentum,
namely:
vp ¼ rp _
q
	
rp


¼ h
rp
Then, the energy reads:
ε ¼ 1
2
h2
r2
p
 m
rp
Recalling that rp ¼ að1 eÞ and h2 ¼ pm ¼ a
	
1 e
2


m, the new expres￾sion of the specific energy is derived:
ε ¼  m
2a
(4.13)
Eq. (4.13) links the energy associated with an orbit and its size through
the semimajor axis value and is valid for all conics.
To recap, the full set of orbital elements (and their meaning) are:
⁃ Semimajor axis (size): a.
⁃ Eccentricity (shape): e.
⁃ Inclination (orientation): i:
⁃ RAAN (orientation): U.
⁃ Argument of periapsis (orientation): u.
⁃ True anomaly (location along the orbit): qðtÞ.
The R2BP motion can be therefore fully defined through five constant
quantities (identifying the orbit) and a sixth parameter (the true anomaly),
function of time. Despite the relation between the true anomaly and time
can be fully described through the presented integrals of motion, its deriva￾tion deserves a dedicated analysis in a separate section.
As a final remark, it is worth mentioning that sometimes the true anom￾aly is substituted with an alternative parameter, called mean anomaly:
M ¼
ffiffiffiffi
m
a3
r
Dt ¼ nDt
with n ¼
ffiffiffi
m
a3
q
being the mean motion (or mean angular velocity). The physical
meaning of the mean anomaly will become clear when the time laws will be
derived in the next sections.
138 Andrea Capannolo et al.Two-line elements
Despite the wide utilization of the orbital elements as defined in the previous
section, alternative sets have been developed depending on the applications.
For practical use and GNC applications, it is common to find the so￾called Two-Line Elements (TLEs). The TLEs resemble the classical elements
but display some relevant differences. As the name suggests, parameters are
organized in two lines for a standardized automatic processing. They display
the alternative set of the six parameters, which are necessary to define the
orbit, and they present additional quantities to describe the effect of pertur￾bations on satellites’ motion or needed to categorize the data.
In particular, the parameters set found in TLEs is ðn;e; i; U;u; MÞ. From
classical elements, the semimajor axis a has been substituted with the mean
motion n (with the Kozai mean value of the semimajor axis [9]), and the true
anomaly q is now replaced by the mean anomaly M.
The additional elements are:
⁃ Satellite number.
⁃ Classification (U: unclassified data).
⁃ International designator (launch year, launch number of the year, piece of
the launch).
⁃ Reference epoch of the time-varying elements (year, day of the year, and
fractional portion of the day).
⁃ First and second derivatives of the mean motion 
n_
2; n€
6
!
.
⁃ Mean ballistic coefficient 
B* ¼ 1
2
cDA
m r0R

.
⁃ Ephemeris type (orbital model) to generate the data.
⁃ Element number.
⁃ Revolution number at epoch.
⁃ Checksum (used for errors checking).
With the only exception of the satellite number and the checksum
(which appear in both lines of the set, respectively, as first and last element),
the first line presents the previously listed elements from the classification to
the element number (in the same order), while the second line displays the
orbital elements first, in the order fi; U;e; u; M; ng, plus the number of rev￾olutions at epoch.
Orbital dynamics 139Below is a typical structure of a TLE:
NOAA 14
1 23455U 94089A 97320.90946019 .00000140 00000  0 10191  3 0.2621
2 23455 99.0090 272.6745 0008546 223.1686 136.8816 14.11711747148495
Geometrical classification of the conics
Any conic can be fully defined by two parameters; however, there are
various way to express such parameters. As an example, consider the ellipse
in Fig. 4.1:
A straightforward approach is to consider the semimajor axis and semi￾minor axis of the conic, i.e., the couple a and b. Alternatively, one can sub￾stitute b (for example) with some parameters linked to the foci distance from
the ellipse center, i.e., the focal half-distance c, such that:
c
2 ¼ a
2  b
2
The ratio between the focal half-distance and the semimajor axis defines
the oblateness of the conic, i.e., the eccentricity e:
e ¼ c
a
From the previous equations, it follows also an alternative expression of
the semiminor axis:
Figure 4.1 Conic’s geometrical parameters.
140 Andrea Capannolo et al.b ¼ a ffiffiffiffiffiffiffiffiffiffiffiffi
1  e2 p
With reference to previous section, a further parameter characterizing a
conic is the semilatus rectum, i.e., the distance between the focus and the
conic itself in the direction perpendicular to the eccentricity vector. It can
be defined by geometrical means (Pythagorean theorem) and leveraging
previous quantities as:
p ¼ b2
a ¼ a
	
1  e
2

Notice that the same expression was obtained in previous section (Eq.
4.12), leveraging the orbital radius equation.
Overall, the set of parameters that can be used to characterize a conic are:
⁃ a (semimajor axis)
⁃ b (semiminor axis)
⁃ c (half-distance between foci)
⁃ p (semiparameter or semilatus rectum)
⁃ e (eccentricity)
By leveraging the derived relations from integrals of motion, geometrical
parameters can be used to classify the type of conic and, as a consequence, of
orbit.
Let’s consider the expression of specific energy as a function of semima￾jor axis 
ε ¼ m
2a

. Then the following conditions are verified:
⁃ ε < 05a > 0
⁃ ε ¼ 05a/N
⁃ ε > 05a < 0
By extracting a from the energy equation and substituting it to the semi￾latus rectum expression, the eccentricity e can be defined as:
e
2 ¼ 1 þ
2pε
m
Recalling also that p ¼ h2
m > 0 (strictly positive for orbital motion), the
previous expression implies that:
⁃ ε < 050  e < 1
⁃ ε ¼ 05e ¼ 1
⁃ ε > 05e > 1
Notice that, since e
2 is by definition a positive quantity, it implies that a
minimum energy value exists to ensure orbital motion, when e ¼ 0.
Extending the concept to the focal distance, we obtain that:
Orbital dynamics 141⁃ ε < 05c < a
⁃ ε ¼ 05c ¼ a/N
⁃ ε > 05c > a
To understand the conic type from to the geometrical parameters’
ranges, we can exploit the orbital radius expression from Eq. (4.8), where
the semilatus rectum is replaced by the expression of Eq. (4.12):
rðqÞ ¼ a
	
1  e
2


1 þ e cos q
The minimum energy case implies e ¼ 0 and a > 0, hence c ¼ 0, and
the radius reads:
r ¼ a
This means that the foci are collapsed to the center of the conic, and that
the distance from the gravity source is constant and does not depend on the
true anomaly; hence, the orbiting object describes a circular orbit.
Within the range 0 < e < 1 instead, the radius expression maintains its
original form, and the two foci are distinct, and displaced from the center.
Furthermore, the denominator of the expression is always positive, thus
admitting a maximum and minimum distance, i.e., a percenter and an apoc￾enter, already defined in Eqs. (4.10) and (4.11). These characteristics identify
an elliptical orbit.
In the case e ¼ 1 and a/N, the focus and the center of the conic
collapse at infinity. Here, it is still possible to find a minimum distance rp as:
rp ¼ p
2
Notice that p is undefined if expressed in terms of a and e (Eq. 4.12) and
requires the formulation in terms of the angular momentum of the orbit (Eq.
4.9).
On the contrary, the denominator of the radius equation here ap￾proaches zero at its minimum; therefore, the maximum distance is at infin￾ity. There, the velocity tends to zero. In fact, ε ¼ 0 in this case, and if the
original expression of the specific energy is evaluated at infinity, we obtain:
0 ¼ 1
2

r_ $ r_

 m
r 0
r/N 1
2

r_ $ r_

/0
Such behavior characterizes the parabolic orbit, which is the minimum en￾ergy escaping trajectory, and represents a degenerate case of hyperbolic
trajectories.
142 Andrea Capannolo et al.Hyperbolic trajectories are described by a semimajor axis a < 0 and ec￾centricity e > 1. These escaping trajectories are characterized by a residual
velocity at infinite ðvN ¼ ffiffiffiffiffi
2ε p Þ, asymptotically achieved at a specific true
anomaly. In particular, the asymptotes of the hyperbola are characterized
by a deflection angle d, i.e., the angle measured from the perpendicular axis
bp to the eccentricity vector, and the asymptote. Then, at infinite the true
anomaly reads:
wN ¼ p
2 þ d
Furthermore, such angle can be directly related to eccentricity, by
substituting r/N to the radius equation and extracting qN, namely:
qN ¼ acos
1
e

Table 4.1 summarizes the characteristics of the conics for the R2BP.
Energetic analysis and cosmic velocities
Information about the conics can also be extracted through a purely ener￾getic approach, by leveraging the expression of the specific orbital energy
of Eq. (4.6). Furthermore, additional information about orbital velocities
can be extracted by analyzing the kinetic component of the energy.
Extracting the radial component of the velocity from the kinetic energy,
and leveraging the expression of the specific angular momentum from Eq.
(4.7), one can write:
1
2
r_
2 ¼ ε 
 h2
2r2  m
r

Calling v0 ¼ 1
2r_
2, it is always verified that v0  0. Notice that v0 ¼ 0 im￾plies a local purely tangential velocity of the orbiting body with respect to
the gravitational source. Fig. 4.2 depicts the locus of points where such con￾dition is verified, for any distance r.
Hence, for a given angular momentum and planetary constant, the min￾imum energy allowed at each radius (to have an orbital motion) is provided
by the v0 ¼ 0 line, and reads:
εðrÞ ¼ h2
2r2  m
r
(4.14)
The lowest value of the plot is the minimum of the εðrÞ curve. There, a
single value of radius can exist; therefore, only a purely circular motion
Orbital dynamics 143Table 4.1 Characteristic parameters of the conics.
Orbit Semimajor axis Eccentricity Focal distance Specific energy True anomaly range Radius range
Circle a > 0 e ¼ 0 c < a ε < 0 q˛½0; 2p r ¼ a
Ellipse a > 0 0 < e < 1 c < a ε < 0 q˛½0; 2p p 1þe < r < p 1e
Parabola a/N e ¼ 1 c ¼ að/NÞ ε ¼ 0 q˛ðp; pÞ p 1þe < r < N
Hyperbola a < 0 e > 1 c > a ε > 0 q˛  a cos1e;
a cos1e p 1þe < r < N
144 Andrea Capannolo et al.around the gravity source is allowed (circular orbit). The orbital velocity is
purely tangential (perpendicular to the radius); therefore, its magnitude is
directly related to the angular momentum:
v
2 ¼
h
r
2
(4.15)
Recalling Eq. (4.13), and remembering that for circles the semimajor axis
coincides with the radius, the energy equation can be solved for v, and
returns:
v ¼
ffiffiffi
m
a
r
¼
ffiffiffi
m
r
r
which is known as First Cosmic Velocity, and often labeled as C1.
If the energy level is increased, two distinct intersections with the εðrÞ
curve are found. This implies that the radial-velocity kinetic energy ðv0
Þ
can have positive values and equals zero in two distinct points of the graph,
i.e., at two distinct radii. Hence, the motion oscillates between a maximum
Figure 4.2 Specific orbital energy with null radial velocity, as a function of orbital
radius.
Orbital dynamics 145and a minimum radius where the velocity is purely tangential, which iden￾tifies an elliptical orbit.
When the ε ¼ 0 level is approached, a single intersection is identified.
Indeed, the curve approaches the zero value at infinity; hence, a minimum
radius is defined, while the maximum radius tends to infinity. At infinity, the
energy equation reads:
0 ¼ 1
2

r_ $ r_

 m
r 0
r/N 1
2

r_ $ r_

/0
This means that, at infinity, the orbital velocity approaches zero. The
orbit represents the minimum energy escaping trajectory, which is the para￾bolic orbit.
If we leverage Eqs. (4.14) and (4.15), the velocity magnitude at pericen￾ter can be extracted, and reads:
v ¼
ffiffiffiffiffi
2m
rp
s
This also known as Second Cosmic Velocity and represents the minimum
orbital speed required for escaping the gravitational source.
Finally, consider energy levels in the positive region of the graph. Again,
a single intersection is identified, representing the minimum orbital radius of
the orbit. However, even at r/N, a gap between the energy level and the
εðrÞ curve is observed. This implies that a residual radial velocity is present at
escape conditions; therefore, a hyperbolic orbit is obtained.
The residual escape velocity can be computed from Eqs. (4.8) and (4.6),
knowing that the gravitational potential term tends to zero:
v ¼
ffiffiffiffiffiffiffi
m
a
r
This velocity is also known as Third Cosmic Velocity, and it is widely used
in the design of interplanetary transfers. Notice that the value within the
square root is still positive, as for hyperbolas, the semimajor axis is negative.
Operative classification of orbits
Geometrical classification of orbits, despite useful to understand the basics of
orbital motion, does not provide enough insight when real applications need
to be studied. Indeed, orbits can be classified by operative means according
to the environment in which they exist, and to their size and orientation. It is
worth noticing that because of this correlation with the environment,
146 Andrea Capannolo et al.different attractors typically imply the existence of different classes of orbits.
Here, the main Earth-centered orbits are listed and described.
Low Earth orbits
All circular and quasicircular orbits around the Earth, with an altitude below
2000 km are labeled as low Earth orbits (LEOs). Their close distance to sur￾face and the relatively short orbital period make them a suitable solution for
convenient transportation, telecommunication, and Earth surface observa￾tion. Main drawbacks are the small field of view from surface (affecting vis￾ibility time windows between ground station and satellites) and the fast
orbital decay due to the high influence of atmospheric drag and planet’s
oblateness, which demands frequent orbital control.
Geosynchronous/geostationary orbits
Geosynchronous orbits (GEOs) around the Earth are characterized by a spe￾cific and narrow altitude range (around 35,786 km), such that the orbital
period matches the Earth rotation. Consequently, a spacecraft on a GEO
will maintain nearly the same geographical location with respect to Earth’s
surface. To exploit this characteristic, GEOs shall have a low or null inclina￾tion with respect to Earth equator and a low eccentricity value. A perfectly
circular, equatorial orbit at the altitude of geosynchronous family is called
geostationary orbit, where a spacecraft would virtually have a fixed zenith
with respect to the planet’s surface.
Because of synchronicity, and of the large portion of Earth surface visible
at this altitude, GEOs are mainly used for telecommunication assets, as
ground stations are always in-sight and require minor reorientation of the
antennas. In this environment, the Earth oblateness effect and atmospheric
drag are negligible, while solar radiation pressure and third-body perturba￾tion from the Moon become more significant.
It is worth mentioning that a match between orbital period and spin of
the main attractor can be found for other celestial bodies. For example, Are￾osynchronous and Areostationary orbits can be found around Mars, about
17,000 km above the Martian surface.
Medium Earth orbits
All the orbits between the altitude ranges of LEO and GEO are classified as
medium Earth orbits (MEOs). This region is most commonly used by nav￾igation constellations, such as Galileo, GPS, and GLONASS, as well as by
communication satellites.
Orbital dynamics 147The MEO region is largely occupied by the Van Allen radiation belts;
therefore, additional shielding is typically required from spacecraft popu￾lating MEOs.
Sun-synchronous orbits
At high inclination with respect to the Earth equator, and relatively low al￾titudes, there exists a specific condition where the oblateness of the planet
perturbs the orbital plane, making it rotate at the same rate of the Earth orbit
around the Sun. This kind of orbit is known as a Sun-synchronous orbit
(SSO) and displays a nearly fixed orientation with respect to the Sun direc￾tion (and the terminator), thanks to the perturbative effect of the Earth’s
shape.
This property becomes particularly useful when illumination conditions
are important (e.g., for imaging, weather, and reconnaissance satellites) and
provide a stable and repeated light-shadow cycle, useful for the design of po￾wer and thermal aspects of the spacecraft.
As for GEOs, SSO can be found around other attractors (such as Mars),
with properly tuned altitudes and inclinations to accommodate the different
oblateness of the planet.
Time laws and orbital period
The orbital motion has been described so far through six parameters derived
from the integrals of motion. In particular, five of them are constants that
identify the orbit, while the sixth (the true anomaly) is a function of the
time and identifies the actual position of the orbiting object along the orbit.
To fully define the motion, it is therefore necessary to find the law that links
the true anomaly q to the time t.
Recalling the specific angular momentum and the orbital radius (Eqs. 4.8
and 4.7), one can define a differential relation between q and t, namely:
h ¼
 p
1 þ e cos q
2
_
q (4.16)
Then, the time law is provided by the integration of such relation. The
solution of Eq. (4.16) depends on the type of orbit, i.e., on the eccentricity
value. The following paragraphs describe the solving approach for the four
conics (circles, parabolas, ellipses, and hyperbolas).
Circular orbits
In case of a circular orbit ðe ¼ 0Þ, the time law is analytical and easily ob￾tained by solving the integral. In fact, the denominator of the right-hand
side becomes equal to 1, and the integration reads:
148 Andrea Capannolo et al.Z
q
0
dq ¼
Z
Dt
t0
h
p2 dt
where t0 represents the time at pericenter, commonly chosen as reference.
Since neither h nor p depends on time, and leveraging the semilatus rectum
definition as in Eq. (4.12), the time law for circular orbits is obtained:
qðtÞ ¼
ffiffiffiffi
m
a3
r
Dt
Notice that if the integration over the full orbit is performed, the expres￾sion of the orbital period is derived:
T ¼ 2p
ffiffiffiffi
a3
m
s
(4.17)
This implies that the period of the orbit depends on its semimajor axis
only, and in particular that the squared value of the period is proportional
to the cube of the semimajor axis, thus proving the Kepler’s Third Law [2].
Parabolic orbits
In case of a parabola ðe ¼ 1Þ, the integrals read:
Z
Dt
t0
h dt ¼
Z
q
0
 p
1 þ cos q
2
dq
Here, the solution can be achieved by leveraging trigonometric proper￾ties, so that:
rðqÞjparabola ¼ p
1 þ cos q ¼ 1
2
p

1 þ tan2
1
2
q

Then, the integration returns:
tan3

1
2
q

þ 3 tan
1
2
q

¼ 3
ffiffiffiffi
m
p3
r
Dt (4.18)
which is known as Barker’s Equation.
To solve Eq. (4.18), various methods were developed, such as the Jerome
Cardan’s Method, the François Vieta’s Method, the Karl Stumpff’s Method, and
others [3].
Orbital dynamics 149Elliptic orbits
In case of elliptic orbits ð0 < e < 1Þ, a direct integration does not allow to
define a time law. Here, an auxiliary variable needs to be defined. With
reference to Fig. 4.3, consider the circle centered at the ellipse’s center
and having a radius equal to the ellipse’s semimajor axis.
We define the Eccentric Anomaly, E, as the angle formed by the orbit’s
periapsis and the position vector on the circle (from center) whose projec￾tion on the periapsis coincides to that of the real position along the ellipse.
The cartesian components of the ellipse can be expressed as the function of E
as:
x ¼ a cos E
y ¼ b sin E
It is easy to verify that any position ðx; yÞ on the ellipse satisfies the
following conditions:
a cos E ¼ ae þ r cos q (4.19)
b sin E ¼ r sin q (4.20)
Figure 4.3 Auxiliary circle and variables, built on the reference elliptic orbit (first quad￾rant depicted).
150 Andrea Capannolo et al.From the radius Eq. (4.8), the equivalence “r cos q ¼ pr
e ” is derived;
hence, a new expression of the radius as a function of E can be obtained
from Eq. (4.19), and reads:
r ¼ að1  e cos EÞ (4.21)
By equating Eqs. (4.8) and (4.21), and leveraging Eqs. (4.19) and (4.20),
the following relation between the true anomaly and the eccentric anomaly
is obtained:
tan
1
2
q

¼
ffiffiffiffiffiffiffiffiffiffi
1 þ e
1  e
r
tan
1
2
E

(4.22)
Notice that despite other forms of the relation exist, this is particularly
useful as 1
2 q and 1
2 E are always within the same quadrant.
With a relation available between the two angles, the problem of finding
the time law can be expressed in terms of the eccentric anomaly. In partic￾ular, if the derivatives in time of the radius expression in Eq. (4.8) and the
equivalent expression in Eq. (4.21) are evaluated and compared, it is possible
to verify that:
ffiffiffi
m
p
r
sin q ¼ aE_ sin E (4.23)
Exploiting Eqs. (4.20) and (4.21), and eliminating the true anomaly from
23, the following integral equation is derived:
Zt
t0
ffiffiffiffi
m
a3
r
dt ¼
Z
E
0
ð1  e cos EÞ dE
and its integration returns:
ffiffiffiffi
m
a3
r
Dt ¼ E  e sin E
which is known as the Kepler’s Time Law.
As shown for the circular orbit case, if the integral is computed for the
full orbit, the same expression as Eq. (4.17) is obtained, thus confirming
the generality of the Kepler’s Third Law.
Orbital dynamics 151Hyperbolic orbits
In the case of hyperbolic orbits ðe > 1Þ, a similar approach to the elliptic or￾bits case is followed. However, here hyperbolic functions are used instead of
trigonometric functions, hence:
x ¼ a cosh H
y ¼ b sinh H
r ¼ a ð1  e cosh HÞ
(4.24)
with H ¼ iE, being i the imaginary number.
The following relation holds between H and the true anomaly q:
tan
1
2
q ¼
ffiffiffiffiffiffiffiffiffiffi
e þ 1
e  1
r
tanh
1
2
H
Finally, by evaluating the time derivative of r in terms of its equivalent
expressions (Eqs. 4.8 and 4.24), and eliminating the true anomaly from
the equivalence, the integration returns the new time law:
ffiffiffiffiffiffiffiffi
m
a3
r
Dt ¼ esinhH  H
which is the hyperbolic form of Kepler’s time law.
Universal time law
The main drawback of the time laws presented in the previous section is the
necessity of a different law for each orbital type. It is therefore desirable to
have a general expression, applicable regardless of the eccentricity of the
orbit. This can be obtained through the so-called universal parameter (or var￾iable). The change to the universal variable is achieved through the Sund￾man’s transformation.
Consider the energy Eqs. (4.6) and (4.13) and recall the angular mo￾mentum equivalence h ¼ ffiffiffiffiffi
mp p ¼ r
2 _
q. Then, the time derivative of the
orbital radius reads:
r_
2 ¼  mp
r2 þ
2m
r  m
a
(4.25)
The objective is to substitute the time derivative, with the universal var￾iable derivative of r. Define the universal variable c such that:
c_ ¼
ffiffiffi
m p
r
152 Andrea Capannolo et al.cð0Þ ¼ 0
Then, Eq. (4.25) becomes:
dr
dc
2
¼  p þ 2r  r
2
a
whose integral returns rðcÞ:
rðcÞ ¼ a

1 þ e sin
c þ C0 ffiffi
a p
 (4.26)
This result is valid only for positive semimajor axis a. Also, the eccentric￾ity e is still present, and the integration constant C0 is to be determined. The
next steps allow to completely remove the dependency on the conic type
and to generalize the previous expression.
First, substitute the expression in Eq. (4.26) into the time derivative of c
to obtain the relationship between the universal variable and time:
ffiffiffi
m p Dt ¼ ac  ae ffiffi
a p 
cosc þ C0 ffiffi
a p

 cosC0
ffiffi
a p
 (4.27)
Then, if rðcÞ and r_ðcÞ are evaluated for the initial condition t ¼ 0,
recalling that cð0Þ ¼ 0, the following relations hold:
e sinC0
ffiffi
a p

¼ r0
a  1
e cosC0
ffiffi
a p

¼ r0 $ r_0 ffiffiffiffiffi
ma p
Substituting these expressions in Eqs. (4.26) and (4.27), the final relation
between r and c, and the universal time law are defined:
rðcÞ ¼ a
(
1 þ
r0 $ r_0 ffiffiffiffiffi
ma p
sinc
a

þ
r0
a  1

cos c
ffiffi
a p

)
ffiffiffi
m p Dt ¼ ac  a ffiffi
a p (
r0 $ r_0 ffiffiffiffiffi
ma p
cos c
ffiffi
a p


r0
a  1

sin c
ffiffi
a p

 r0 $ r_0 ffiffiffiffiffi
ma p
)
Summary
Table 4.2 collects the final expressions for the time law, derived in the pre￾vious paragraph.
Orbital dynamics 153Orbital perturbations
The previous section dealt with the full characterization of the R2BP, in
terms of dynamics equations, integrals of motion, and parametric represen￾tation of the solutions (conics) of the problem. Furthermore, insight has
been given about energy-related features of orbits, and time laws defined.
All these results have been derived in the context of an unperturbed envi￾ronment, where only single attractor gravitational force is present. In practice,
orbits are subjected to a series of perturbation, which deviate the nominal mo￾tion and that must be considered for higher fidelity simulations. The most
relevant perturbations and their modeling rules have been described in Chap￾ter 3 e The Space Environment. Here, the way in which they affect the
orbital dynamics and the methods to compute their effects are presented.
Indeed, the effects of perturbation can be taken into account following
two main approaches (although hybrid techniques are also available), namely
through an analytical formulation or a numerical one. In the next subsections,
the main analytical and numerical approaches are formulated and described.
A numerical approach: the Cowell’s formulation
The numerical formulation is of simpler derivation, as it directly acts on the
equations of motion, through the addition of the perturbing term.
Table 4.2 Time law solution methods.
Time law Solving equations
Circular orbits qðtÞ ¼
ffiffiffi
m
a3
q
Dt
Parabolic orbits
tan3

1
2 q

þ 3 tan
1
2 q

¼ 3
ffiffiffi
m
p3
q
Dt
Elliptic orbits tan
1
2 q

¼
ffiffiffiffiffiffi
1þe 1e
q
tan
1
2 E

ffiffiffi
m
a3
q
Dt ¼ E  e sin E
Hyperbolic orbits tan 1
2 q ¼
ffiffiffiffiffiffi
eþ1 e1
q
tanh 1
2 H ffiffiffiffiffiffi
m
a3
q
Dt ¼ e sinh H  H
Universal variable
rðcÞ ¼ a
(
1 þr0 $ r_0 ffiffiffiffi
ma p sin
c
a

þ

r0
a 1

cos cffiffi
a p

)
ffiffiffi
m p Dt ¼ ac
a ffiffi
a p
(
r0$r_0 ffiffiffiffi
ma p cos cffiffi
a p



r0
a 1

sin cffiffi
a p

 r0 $ r_0 ffiffiffiffi
ma p
)
154 Andrea Capannolo et al.Furthermore, it generally provides accurate results, regardless of the orders of
magnitude of the perturbative effects. On the other hand, its formulation
implies dependency on the initial conditions (hence, a loss of generality of
the dynamical behavior), and a generally higher effort from the computa￾tional point of view.
The Cowell’s formulation represents the easiest approach and consists of
a simple addition of the perturbative accelerations f to the R2BP equations
of motion (Eq. 4.3):
r€¼  m
r3 r þ f
Hence, the complexity of this approach (if there is any) is to choose a
proper numerical propagation method, which suits the desired accuracy
and speed of the process.
Noteworthy suitable methods for orbital propagation are the predictore
corrector schemes, and in particular the Verner’s RungeeKutta eighth(se￾venth) order method [10], and the variable-step/variable-order Adame
BashfortheMoulton solver of orders from 1st to 13th [11].
An analytical approach: Gaussian Variation of Parameters
The analytical formulation relies on the fact that perturbative forces are
significantly smaller than the main gravitational force; hence, they can be
locally approximated by series expansions. This implies that the orbital mo￾tion can still be locally expressed in terms of the orbital parameters (osculating
elements), but that such parameters are no longer constant and that they
possess some rate of change with time, that is:
dc
dt ¼ f ðc; tÞ
where c represents the vector collecting the six orbital elements
ða;e; i; U;u; qÞ.
The mathematical derivation provides general formulas which are valid
regardless of the initial conditions. The more complex development is
compensated by the insight given by the formulas about the local behavior
of the orbit.
Among the analytical techniques, the Gaussian Variation of Parameters
(VOPs) provides relatively simple expressions, applicable in the presence
of both conservative and nonconservative forces (as opposed, e.g., to the
Lagrangian VOP [2]). Nevertheless, they have a limited applicability range,
as they are suited for closed orbits only (eccentricity less than one) and
Orbital dynamics 155present some singularities (related to the orbital angles). Alternative formu￾lations have been developed to deal with singularities, such as the expression
of the VOP in terms of equinoctial elements [3].
In the following paragraphs, the expression of each parameter’s variation
is derived as a result of a generic perturbing acceleration “f.” The equations
are expressed in a reference frame (br; qb; hb), with br aligned with orbital po￾sition vector and hb aligned with the angular momentum vector. For
simplicity, the components of the perturbative acceleration along the three
axes are named “f r; f q; f h.”
Semimajor axis
The rate of variation of the semimajor axis can be derived from the specific
energy equation. In particular, the specific energy is not constant anymore
due to the presence of the perturbations. Its rate is provided by the product
of the perturbative acceleration and the local orbital velocity:
dε
dt ¼ f $ r_ ¼ r_ f r þ r _
q f q (4.28)
Recalling that ε ¼ m
2a , the derivative of the semimajor axis with
respect to energy reads:
da
dε
¼ m
2ε2 ¼ 2a2
m
(4.29)
Leveraging the chain rule of derivatives in Eqs. (4.28) and (4.29), and
recalling that
r_¼ p
ð1 þ e cos qÞ
2 e_
q sin q
p ¼ a
	
1  e
2

¼ h2
m
(4.30)
h ¼ r
2 _
q
the time rate of a is provided:
da
dt ¼ 2e sin q
n ffiffiffiffiffiffiffiffiffiffiffiffi
1  e2 p f r þ
2a ffiffiffiffiffiffiffiffiffiffiffiffi
1  e2 p
nr
f q (4.31)
n ¼
ffiffiffiffi
m
a3
r
(4.32)
156 Andrea Capannolo et al.Eccentricity
To derive the rate of change of the orbital eccentricity, Eq. (4.30) can be
used as starting point. From its derivation, and isolating the eccentricity
term, the expression reads:
de
dt ¼  h
mae
dh
dt þ
h2
2ma2e
da
dt (4.33)
The first term contains the variation of angular momentum’s magnitude,
caused by the perturbations. Its expression can be retrieved deriving the h
vector in time:
dh
dt ¼ _
h hb þ h_
qqb (4.34)
We are interested in the _
h term. To express it in terms of perturbing ac￾celeration, differentiate again the h vector, expressed in terms of r and r_:
dh
dt ¼ d
dt

r  r_

¼ r  r€¼ r f qhb  r f hqb (4.35)
Notice that, as expected, the gravitational term cancels out as it is aligned
with the position vector r, proving again that the variation of the angular
momentum is preserved in the absence of perturbations.
To extract the expression of _
h ¼ dh
dt, the terms along hb of Eqs. (4.31) and
(4.35) are compared:
dh
dt ¼ r f q (4.36)
Regarding the second term of Eq. (4.33) is the semimajor axis rate,
already defined in Eq. (4.34). Substituting Eqs. (4.34) and (4.36) in Eq.
(4.33), and leveraging again the relations in Eqs. (4.30) and (4.32), the final
expression of the eccentricity rate is obtained:
de
dt ¼
ffiffiffiffiffiffiffiffiffiffiffiffi
1  e2 p sin q
na
f r þ
ffiffiffiffiffiffiffiffiffiffiffiffi
1  e2 p
na2e

a2
	
1 e
2


r  r

f q (4.37)
Inclination
To compute the rate of change of the inclination di
dt, recall the inertial refer￾ence frame 	
bI;bJ; Kb 

, such that:
hb $ Kb ¼ cos i (4.38)
br $ 	
Kb  hb

¼ cos ðu þ qÞ
Orbital dynamics 157Also, leveraging the spherical angles trigonometry, it is possible to derive
a relation with respect to bq:
qb $ Kb ¼ sin i cosðu þ qÞ (4.39)
Eq. (4.38) can be modified to include the magnitude of the angular mo￾mentum as:
cos i ¼ hb $ Kb
h (4.40)
The differentiation in time of Eq. (4.40) (here omitted for simplicity)
presents the derivative terms di
dt, dh
dt , and dh
dt ¼ _
h, with the first being the
new quantity to be determined. The other two quantities have already
been defined in Eqs. (4.35) and (4.36). Substituting such quantities, and
leveraging the relations in Eqs. (4.38) and (4.39), the final form of the incli￾nation rate is obtained:
di
dt ¼ r cosðu þ qÞ f h
na2 ffiffiffiffiffiffiffiffiffiffiffiffi
1  e2 p (4.41)
Right ascension of the ascending node
Following the same approach used for the inclination, the RAAN (U) can be
extracted from vectorial relationships between the two reference frames

br; qb; hb

and 	
bI;bJ; Kb 

:
cosU ¼
bI $
	
Kb  h



Kb  h


(4.42)
bI $ 	
Kb  hb

¼ cosUsin i (4.43)
bI $

Kb  qb

¼ sinUsinðu þ qÞ  cosUcosðu þ qÞcos i (4.44)
Differentiating Eq. (4.42) and substituting the relations in Eqs. (4.43) and
(4.44), the expression of dU
dt appears in the terms of dh
dt and di
dt. Then, substitut￾ing the two quantities with Eqs. (4.36) and (4.41), the final equation for the
RAAN variation in time is obtained:
dU
dt ¼ r sinðu þ qÞ
h sin i
f h
158 Andrea Capannolo et al.True anomaly
The variation of true anomaly dq
dt can be derived from the differentiation of
the orbital radius equation:
r
de
dt
cos q  e sin q
dq
dt 
¼ 2h
m
dh
dt (4.45)
Notice that the radius r was not differentiated in time, as here we are
deriving the local variation due to perturbation and not due to orbital mo￾tion. For the same reason, dq
dt represents the true anomaly variation as a pure
perturbative effect, and it is different from the previously defined _
q (related
to orbital motion). This approximated and local “separation of effects”
further highlights the bounds of applicability of the analytical approach,
which quickly loses accuracy as time moves forward.
Eq. (4.45) presents the time derivative of both eccentricity and angular
momentum magnitude; hence, by substituting them with Eqs. (4.36) and
(4.37), the final time variation of the true anomaly is obtained:
dq
dt ¼
ffiffiffiffiffiffiffiffiffiffiffiffi
1  e2 p
nae
cos q f r 
ffiffiffiffiffiffiffiffiffiffiffiffi
1  e2 p
nae
2 þ e cos q
1 þ e cos q f q: (4.46)
Argument of periapsis
Following the same approach as the inclination and the RAAN, the time
variation of the argument of periapsis (due to perturbation forces) can be
derived from vectorial relationships. Consider the argument of latitude
ðu þqÞ, formed by the vector br of the rotating frame and by the nodal
axis Nb ¼ Kb  hb. The following relation holds:
cosðu þ qÞ ¼br $
	
Kb  hb

¼ r $
	
Kb  h


r

 Kb  h


(4.47)
Differentiating Eq. (4.47) will highlight time derivatives of both h and q,
which can be replaced by Eqs. (4.36) and (4.46). The explicit expression of
du
dt reads:
du
dt ¼
ffiffiffiffiffiffiffiffiffiffiffiffi
1  e2 p
nae 
 cos q f r þ
2 þ e cos q
1 þ e cos q
sin q f q

 r cot i sin u
h
f h
Orbital dynamics 159Validity range of the two-body problem
The 2BP is valid whenever its fundamental assumption is satisfied: the space￾craft motion is influenced by the gravity attraction of one central body and
all the other forces can be treated as perturbations. This assumption shall be
verified by comparing the gravitational forces of other celestial objects, since
all the other nongravitational perturbations are typically few orders of
magnitude smaller than the gravity ones.
To verify this, the concept of the sphere of influence (SOI) shall be intro￾duced. The SOI of a celestial body with mass, m, is described as the region of
space within which the motion of a spacecraft is influenced by that object’s
gravity more than any other celestial body with mass, M. For example, the
Earth’s SOI is found by identifying the region of space where the Earth’s
gravity is more dominant than the Sun or any other planet’s gravity.
The SOI is mathematically defined with its radius:
rSOI ¼ a
m
M
2=5
;
where a is the semimajor axis of the object with mass m (e.g., a planet, a
moon) orbiting around the body with mass M (i.e., the Sun, the main
planet). For example, the SOI of the Earth with respect to the Sun is about
924 645 km; and for the Moon with respect to the Earth, it is about
66 183 km.
It is wrong to apply the R2BP outside the SOI of the central planet. When
dealing with interplanetary missions and the spacecraft is moving between the
neighborhoods of different celestial objects using a two-body approximation
(i.e., ellipses and hyperbolae), the SOI is taken as the boundary where the tra￾jectory switches which mass field it is governing the R2BP orbital dynamics.
This method is denoted as patched conic trajectory analysis [2]. As an illustra￾tive example, we can consider a patched conic analysis of a trajectory from
the Earth to Phobos. At first, the patched conic method would model the
spacecraft exiting the Earth’s SOI to enter the Sun’s SOI. Then, the space￾craft would enter the SOI of Mars, and, finally, while inside the Mars’
SOI, it would enter the Phobos’ SOI. The motion of the spacecraft within
the Phobos’ SOI would be modeled using Phobos-centered orbits, treating
as perturbations the influence of Mars, as well as the Sun. In fact, the moons
of a planet are typically well inside of the planet’s SOI, but they have their
own SOIs. Inside them, the motion of a spacecraft is governed more by
the moon’s gravity than by the Sun’s or by the planet’s gravity.
160 Andrea Capannolo et al.Three-body problem
The 3BP represents the natural extension of the single attractor dy￾namics. It is employed in all scenarios where an additional gravitational
source is as relevant as the primary one, and it cannot be modeled as a pertur￾bation source (as in Chapter 3 - The Space Environment, Section Perturba￾tion Sources). With reference to the validity range of the R2BP, this
condition is likely to occur at the borders of the spheres of influence, and
in any space regions where a central attractor cannot be uniquely identified.
3BP is getting an increased attention for GNC applications, since modern
space missions effectively exploit the dynamics offered by 3BP environ￾ments, such as the Cislunar space, or the SuneEarth SOI borders.
Following the same procedure for the 2BP, the general 3BP dynamics
can be derived from the expression of the N-body, point mass gravitational
acceleration [7], by limiting the number of masses to three. The acceleration
acting on the i-th body of the triplet reads:
r€i ¼  X
3
j¼1; jsi
Gmj

rji


3rji (4.48)
The full motion of the system is provided by integrating in parallel Eq.
(4.48) for i ¼ 1; 2; 3.
This expression, although elegant, is characterized by a complex and
chaotic behavior when integrated in time and fails to provide a sufficiently
regular environment where periodic or quasiperiodic motions (of particular
interest for engineering purposes) can be found [12]. To overcome this issue,
simplified models are usually exploited.
From an applicative, engineering point of view, we are interested in the
motion of only one of the three masses (the spacecraft) as a consequence of
the other bodies’ gravitation (planets, moons, the Sun, etc.). It is reasonable
to assume a negligible mass of the spacecraft than one of the celestial bodies
exerting their gravitational force. With reference to Eq. (4.48), assuming that
the two massive bodies correspond to i ¼ 1; 2, and the spacecraft to i ¼ 3,
the new dynamical system reads:
r€3 ¼  Gm1
kr13k3r13  Gm2
kr23k3r23
r€1 ¼  Gm2
kr21k3r21
r€2 ¼  Gm1
kr12k3r12
(4.49)
Orbital dynamics 161The new expression is known as “Restricted Three-Body Problem”
(RTBP), and it represents the basis of the dynamics models used to prelim￾inary design orbits in binary systems. Within the RTBP, the two attractors
are subjected to the 2BP dynamics, and their motion can be decoupled from
the third body.
Depending on the attractors’ motion, we talk about “Circular Restricted
Three-Body Problem” (CRTBP) or “Elliptic Restricted Three-Body Prob￾lem” (ERTBP).
Circular Restricted Three-Body Problem
In the CRTBP, the two attractors’ motion describes circular orbits around
the barycenter of the binary system. In such framework, it is convenient to
express the equations of motion of the third body in the so called “synodic
reference frame” [13], which rotates along with the attractors (or primaries)
at the same angular rate. Within such frame, the primaries are fixed, and
their dependence on time is eliminated.
By applying the classical rotation rules to Eq. (4.3), the new equations
read:
r€¼ u2
2
6
6
4
100
010
000
3
7
7
5
r  2u
2
6
6
4
0 1 0
100
000
3
7
7
5
r_
 G
 
m1
kr  r1k3 ðr  r1Þ þ m2
kr  r2k3 ðr  r2Þ
!
(4.50)
where r refers to the third body position vector in the synodic reference
frame, r1 and r2 are the primaries position from the barycenter, and u is the
angular velocity of the binary system, computed according to the 2BP as:
u ¼
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
Gðm1 þ m2Þ
L3
r
(4.51)
with L being the (constant) distance between the two primaries.
It is a common practice to express Eq. (4.50) in nondimensional form,
leveraging the constant parameters that characterize the CRTBP. In partic￾ular, it is possible to normalize the quantities according to the total mass of
the attractors ðm1 þm2Þ, to their distance ðLÞ, and to the angular velocity
ðuÞ. From Eq. (4.51), it can be observed that such normalization implies
setting G ¼ 1.
162 Andrea Capannolo et al.The resulting nondimensional form of Eq. (4.50) reads:
€
br ¼
2
6
6
6
6
4
100
010
000
3
7
7
7
7
5
br  2
2
6
6
6
6
4
0 1 0
100
000
3
7
7
7
7
5
_
br  1  m
kbr1k3br1 þ m
kbr2k3br2
br1 ¼ br þ
2
6
6
6
6
4
m
0
0
3
7
7
7
7
5
br2 ¼ br þ
2
6
6
6
6
4
m  1
0
0
3
7
7
7
7
5
(4.52)
with m being the mass ratio of the primaries, expressed as follows:
m ¼ m2
m1 þ m2
(4.53)
An even more compact form can be expressed by identifying a “pseudo￾potential” function U such that:
U ¼ 1
2
	
x
2 þ y
2

þ
1  m



er1




þ m



er2




(4.54)
where x and y represent the planar components of the nondimensional
position vector of the third body.
Then, the first expression of Eq. (4.52) reads:
€
br þ 2
2
6
6
4
0 1 0
100
000
3
7
7
5_
br ¼ VU (4.55)
From Eq. (4.55), it is possible to identify five fixed equilibrium points in
the synodic reference frame, also known as “Lagrangian Points.” The equi￾librium condition requires that:
VU ¼ 0 (4.56)
Orbital dynamics 163Two of the three conditions of Eq. (4.56) allow to locate the equilibrium
points on the binary system’s plane ðz ¼ 0Þ and identify one of the two co￾ordinates on the plane (typically the y component). Furthermore, three of
them result to be aligned with the primaries ðy ¼ 0Þ, and for this reason,
they are referred to as “Collinear Lagrangian Points” (L1, L2, and L3).
The third condition is a quintic equation that allows to find also the x
component of the equilibria position vectors. In particular, it is observed
that the two points not aligned with the primaries (L4 and L5) are located
at the vertices of two equilateral triangles, with their bases connecting the
primaries; hence, their coordinates can be expressed in the synodic frame
as a function of the mass ratio:
rL4 ¼

 m þ
1
2
;
ffiffiffi
3 p
2 ; 0
T
rL5 ¼

 m þ
1
2
; 
ffiffiffi
3 p
2 ; 0
T (4.57)
For this reason, they are also called “Equilateral Lagrangian Points.”
The collinear Lagrangian points are saddle points; hence, they are unsta￾ble. The equilateral Lagrangian points possess stable properties if the mass ra￾tio ðmÞ is below the value 0.03852 [13].
Elliptic Restricted Three-Body Problem
In the ERTBP, the two attractors’ motion describes elliptic orbits around
the barycenter of the binary system. Similar to the CRTBP, it is possible
to define a rotating reference frame which rotates at the same rate of the bi￾nary system. However, the elliptic motion of the primaries makes the prob￾lem nonautonomous, as their mutual distance and the corresponding
rotation rate depend on time.
The time-dependent, dimensional equations of motion of the ERTBP
read:
r€¼
0
BB@
uðtÞ
2
2
6
6
4
100
010
000
3
7
7
5  u_ ðtÞ
2
6
6
4
0 1 0
100
000
3
7
7
5
1
CCA
r
 2uðtÞ
2
6
6
4
0 1 0
100
000
3
7
7
5
r_
 G
 
m1
kr  r1k3 ðr  r1Þ þ m2
kr  r2k3 ðr  r2Þ
!
(4.58)
164 Andrea Capannolo et al.Here, the time-dependent angular velocity is expressed as:
uðtÞ ¼
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
Gðm1 þ m2Þ
LðtÞ
3
s
(4.59)
The variable primaries’ distance is expressed through the 2BP orbital
parameters:
LðtÞ ¼ að1  e cos EðtÞÞ (4.60)
with a; e; and E being the semimajor axis, the eccentricity, and the
eccentric anomaly of the 2BP orbit.
The presence of the eccentric anomaly in Eq. (4.60) implies that Eq.
(4.58) shall be augmented with the variation of such parameter, namely:
E_ ¼ 1
1  e cos EðtÞ (4.61)
A nondimensional form can be expressed also for the ERTBP. Here, the
normalization is performed according to the total mass of the primaries
ðm1 þm2Þ, to the gravitational constant ðGÞ, and to the semimajor axis of
the 2BP ðaÞ. Consequently, the nondimensional angular velocity, and its de￾rivative, take the form:
ubðtÞ ¼
ffiffiffiffiffiffiffiffiffiffiffiffi
1  e
2 p
ð1  e cos EðtÞÞ2
_
ubðtÞ¼ 2e ffiffiffiffiffiffiffiffiffiffiffiffi
1  e
2 p
ð1  e cos EðtÞÞ2 sin EðtÞ
(4.62)
The nondimensional equations of dynamics read:
€
br ¼
0
BBBB@
ubðtÞ
2
2
6
6
6
6
4
100
010
000
3
7
7
7
7
5
 _
ubðtÞ
2
6
6
6
6
4
0 1 0
100
000
3
7
7
7
7
5
1
CCCCA
br  2ubðtÞ
2
6
6
6
6
4
0 1 0
100
000
3
7
7
7
7
5
_
br  1  m
kbr1k3br1 þ m
kbr2k3br2
E_ ¼ 1
1  e cos EðtÞ
br1 ¼ br þ
2
6
6
6
6
4
mð1  e cos EðtÞ Þ
0
0
3
7
7
7
7
5
br2 ¼ br þ
2
6
6
6
6
4
ðm  1Þð1  e cos EðtÞÞ
0
0
3
7
7
7
7
5
(4.63)
Orbital dynamics 165Again, Eq. (4.62) can be expressed in a more compact form as:
€
br þ _
ubðtÞ
2
6
6
6
6
4
0 1 0
100
000
3
7
7
7
7
5
br þ 2ubðtÞ
2
6
6
6
6
4
0 1 0
100
000
3
7
7
7
7
5
_
br ¼ VU
E_ ¼ 1
1  e cos EðtÞ
(4.64)
where a new pseudopotential U is defined for the ERTBP, and reads:
U ¼ 1
2
ub2	
bx
2 þ by
2

þ
1  m
krb1k þ m
krb2k (4.65)
Equilibrium points can also be identified within the ERTBP, as per Eq.
(4.56); however, the new points move with time, and their coordinates
should be computed at each time step.
Periodic Motion in the Restricted Three-Body Problem
The dynamics described by Eqs. (4.55) and (4.64) enables the existence of
periodic solutions. Nevertheless, periodicity can be found by numerical
means only, leveraging an initialization-correction-continuation iterative
process.
The initialization is highly tailored to the orbital family to be
developed and to the dynamics model. In general, the initial guess can be
generated starting from a Lagrangian point, one of the primaries, an analyt￾ical approximation, or solutions from a different dynamics model. The
output is the initial state of the orbit (or a set of states along the orbit) and
its period.
The continuation process consists of introducing a perturbation to a pre￾viously defined solution. Various approaches can be leveraged, from a single
state element perturbation (“natural parameter continuation”) to methods
leveraging local tangent direction to the orbital family (“pseudoarclength
continuation”).
The correction process is carried out after the first initialization and after
each continuation, to ensure periodicity of the first guess or of the perturbed
state, respectively. The correction is based on an iterative, Newton-like nu￾merical approach, where first derivative information of a set of conditions
are used to converge to the desired conditions. In particular, periodicity is
ensured by achieving the equivalence of the initial state of the orbit and
166 Andrea Capannolo et al.of the final state. The final state is obtained through a propagation for a
certain time, which is an additional variable of the problem, that corresponds
to the orbital time after the correction process is converged. The set of con￾ditions reads:
GðcÞ ¼ fðbr 0; TÞ  br 0 ¼ 0
c ¼ 
br
T
0 ; T
T (4.66)
To define the single trajectory within the family, a further condition
“sðcÞ” is required (called “Poincaré phase condition”), which is typically
set as a fixed element of the initial state (commonly, the “x” or “z” compo￾nent, depending on the specific orbit family) or as a fixed orbital energy.
Thus, the full set of conditions reads:
FðcÞ ¼ 
GðcÞ
T ; sðcÞ
T T ¼ 0 (4.67)
The iterative correction can be performed through the Newtone
Raphson formula, as per Eq. (4.68):
ckþ1 ¼ ck  
J
T J
1
J
T FðckÞ (4.68)
where J is the Jacobian matrix obtained from the derivatives of F with
respect to c.
The conditions of Eq. (4.67), and the corresponding Jacobian matrix,
vary depending on the dynamics model. Such differences are described
hereafter.
Circular Restricted Three-Body Problem
The CRTBP is described by an autonomous system. While this
ensures the existence of a continuous set of orbits (orbital family), it makes
the solution of Eq. (4.67) nonunique, as long as a single Poincaré
phase condition is set. The uniqueness is recovered by adding a second
condition, which can be again another state element or an energetic
constraint.
To build the Jacobian, first the State Transition Matrix (STM) of the
problem is required. From the linearization of Eq. (4.55), expressed in the
first-order form, the following set is obtained:
Orbital dynamics 167x ¼
"
br
T ; _
br
T
#T
x_ ¼ Ax
A ¼
2
4
03 I3
VðVUÞ U
3
5
U ¼
2
6
6
6
6
4
0 20
200
0 00
3
7
7
7
7
5
(4.69)
The STM “F” is obtained from a time propagation leveraging the matrix
A and setting an identity matrix as initial condition, namely:
F_ ðtÞ ¼ AFðtÞ
Fð0Þ ¼ I6
(4.70)
Notice that the STM can be propagated in parallel with the state to
obtain the 42 elements (6 from the state and 36 from the STM) within a sin￾gle propagation. Finally, the Jacobian matrix is built as:
J ¼
2
6
6
4
Fð Þ T f_ ðbr 0; TÞ
ds cð Þ
dc
0
3
7
7
5
(4.71)
A particular situation occurs when orbits around collinear Lagrangian
points are developed. In such case, the symmetry with respect to the x-z
plane of the synodic frame can be leveraged to reduce the number of vari￾ables. According to the mirror theorem [14e16], the orbit shall be perpendic￾ular to the aforementioned plane at their intersection points. This applies for
both the initial state and for the state at half orbital period. Hence, perpen￾dicularity at half period is imposed by setting:
GðcÞ ¼
2
6
6
6
4
yðT=2Þ
x_ðT=2Þ
z_ðT=2Þ
3
7
7
7
5 ¼ 0 (4.72)
Since the same conditions apply for the initial state, the problem is solved
for the reduced set of variables:
168 Andrea Capannolo et al.c ¼
2
6
6
6
6
6
6
6
4
x0
z0
y_
0
T
3
7
7
7
7
7
7
7
5
The corresponding rows and columns of the Jacobian matrix are
removed as well.
Elliptic Restricted Three-Body Problem
The ERTBP is characterized by a nonautonomous system, as initial condi￾tion of the primaries affects the trajectory of the third body. For this reason,
no continuous orbital families can be defined, as only periodic orbits with a
commensurable period to the one of the binary systems exist [17,18]. As a
consequence, the correction process shall start from an already defined solu￾tion in the CRTBP, whose period is resonant with the binary system.
Regardless, the nonautonomous nature of the problem requires a single
Poincaré condition to uniquely define the periodic solution.
The procedure for defining the correction formula (Eq. 4.68), tailored to
the elliptic problem, follows the same steps carried out for the CRTBP case.
However, necessary modifications are required to deal with the different dy￾namics. In particular, the ERTBP dynamics involves a further variable, that
is, the eccentric anomaly, as per Eq. (4.64). Hence, Eq. (4.73) shall be
extended, and reads:
x ¼
"
br
T ; _
br
T
; E_
#T
x_ ¼ Ax
A ¼
2
6
6
6
6
6
6
6
6
6
6
4
03 I3 03x1
VðVUÞ þ 1
2
_
ubU 2ubU d€
br
dE
013 013
dE_
dE
3
7
7
7
7
7
7
7
7
7
7
5
U ¼
2
6
6
6
6
4
0 20
200
0 00
3
7
7
7
7
5
(4.73)
Orbital dynamics 169Here, the additional derivatives of the equations of motion with respect
to the eccentric anomaly E (not derived here for the sake of compactness of
the expressions) are included in the linearization matrix A.
Regardless, the STM and the Jacobian matrix can be built as per Eqs.
(4.70) and (4.71) as in the CRTBP case, keeping in mind that the STM
will have one more dimension due to the eccentric anomaly.
Irregular solar system bodies
A large amount of the celestial bodies in the Solar System is repre￾sented by asteroids and comets, commonly defined as “small bodies.” Their
main characteristics are the very weak gravitational attraction and highly
irregular shape. Despite planets and moons are not perfect shapes as well,
the gravitational perturbation caused by such irregularities are orders of
magnitude below the overall gravity force exerted by the body. On the con￾trary, local shape variation in small bodies profoundly affect the gravitational
field exerted by these objects, and they cannot be neglected. For this reason,
several methods and models have been developed to describe irregular grav￾ity fields, and they are becoming very popular in modern GNC applications
for missions exploring small celestial objects.
As for the point mass gravitational potential, the derivation of such
models starts from the general expression (cfr. Chapter 3 - The Space
Environment):
U ¼ G
ZZZ
m
1
r
dm (4.74)
being G the gravitational constant, dm the infinitesimal mass portion of
the overall attractor, and r the distance between the control point (or space￾craft) and such infinitesimal mass.
The difference between each gravitational model derives from the way
the integral of Eq. (4.74) is solved.
Spherical Harmonics Expansion Model
The “Spherical Harmonics Expansion (SHE) Model” is a computationally
light approach to deal with gravitational irregularities, and it is frequently
used to model the perturbations from the small irregularities of planets
and moons. Nevertheless, the same approach can be followed to model
highly irregular objects.
170 Andrea Capannolo et al.Following the derivation of the SHE model from Chapter 3 - The Space
Environment, the gravitational potential is approximated through Legendre’s
Polynomials [19], leading to the final expression [20]:
Ushe ¼ Gm
r
(
1 þ Xn
i¼2
X
i
j¼0

R0
r
i

Cij cosðjlÞ þ Sij sinðjlÞ

PijðcosðqÞÞ)
(4.76)
where l and q are the attractor’s longitude and colatitude, respectively,
R0 a reference radius (typically the average equatorial radius), PijðxÞ are
“Associated Legendre Polynomials” [21], while Cij and Sij are the normal￾ized Stokes coefficients, computed as:
Cij ¼ 1
m
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
	
2  d0j


ði  jÞ!
ð2i þ 1Þði þ jÞ!
s ZZZ
m
 r
R0
i
PijðsinðqÞÞcosðjlÞdm
Sij ¼ 1
m
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
2ði  jÞ!
ð2i þ 1Þði þ jÞ!
s ZZZ
m
 r
R0
i
PijðsinðqÞÞsinðjlÞdm
(4.77)
Stokes coefficients require the knowledge of the object’s shape, which
can be reconstructed via preliminary estimation (through ground observa￾tions, especially for small solar system bodies), or through in-situ radio￾science experiments [22,23] and other techniques [24].
The final accuracy of the gravity field is determined by the number of
terms in the expansion from Eq. (4.76). This is particularly critical in the
case of small irregular bodies, if compared to the perturbative gravity model
of oblate massive bodies. In fact, the low gravity field and the larger irregu￾larities make the higher order terms of the SHE more relevant and compa￾rable to the point mass term of the expansion. For this reason, while the sole
J2 term would be sufficient for modeling the perturbation of Earth oblate￾ness, a small asteroid may require contributions above J10, including sectorial
and tesseral harmonics (commonly neglected for massive bodies).
Regardless of the higher number of terms, the analytical expression al￾lows a fast evaluation, thus limiting the computational cost.
The real limit of this approach is its applicability only outside the “Bril￾louin sphere,” the spherical region encompassing the whole attractor, with a
radius equal to the maximum surface radius of the body. To deal with grav￾ity modeling inside the sphere, while maintaining a SHE approach, other
types of function must be explored, like “Bessel functions” [25].
Orbital dynamics 171Ellipsoidal model
In the case the small object can be approximated as a triaxial ellipsoid, an
ellipsoidal model (ELL), developed by MacMillan [26], can be exploited.
The new formulation has the advantage over the SHE of being valid also
within the Brillouin sphere, down to the surface of the object.
By expressing the integral of Eq. (4.74) in spherical coordinates and inte￾grating over the radius, with the ellipsoid formula as upper bound (the reader
is invited to consult reference [26] for further details), the new potential
reads:
Uell ¼ Grpabc Z
N
k
1  x2
a2 þ s
 y2
b2 þ s
 z2
c2 þ s ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
ða2 þ sÞ
	
b2 þ s


ðc2 þ sÞ
q ds (4.78)
where a;b; c are the three semiaxes, such that a > b > c, r is the constant
density of the body, and the lower bound of the integral, k, corresponds to
the algebraic largest root of equation:
x2
a2 þ k
þ y2
b2 þ k
þ
z2
c2 þ k ¼ 1 (4.79)
The evaluation of the integral from Eq. (4.78) leads to the following final
expression:
Uell ¼ 2Grpabc ffiffiffiffiffiffiffiffiffiffiffiffiffi
a2  c2 p
1  x2
a2  b2 þ y2
a2  b2

Fðuk; kÞ þ  x2
a2  b2

	
a2  c
2


y2
	
a2  b2

	b2  c2

 þ
z2
b2  c2

Eðuk; kÞ þ 	
c
2 þ k


y2
b2  c2

	
b2 þ k


z2
b2  c2
 ffiffiffiffiffiffiffiffiffiffiffiffiffi
a2  c2 p
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
ða2 þ kÞ
	
b2 þ k


ðc2 þ kÞ
q

(4.80)
where F and E are the Legendre’s elliptic integrals of first and second kind,
and uk and k satisfy the following conditions:
sinðukÞ ¼
ffiffiffiffiffiffiffiffiffiffiffiffiffi
a
2  c
2
a
2 þ k
s
k2 ¼ a
2  b
2
a
2  c
2
(4.81)
172 Andrea Capannolo et al.The accuracy of this model is strongly dependent on how close the actual
body surface is to a triaxial ellipsoid. It is worth mentioning that the evalu￾ation of Eq. (4.80) is typically computationally heavier than the SHE model
due to the computation of the elliptic integrals. Hence, such model is sug￾gested only if the spacecraft is very close or inside the Brillouin sphere.
Mass concentration model
The principle behind the Mass Concentration (MasCon) differs from the
previous approaches, as the integral of Eq. (4.74) is not solved continuously
through some approximation, but rather it is discretized and solved as a sum￾mation of many point masses composing the attractor. The result is a cluster
of points that take, overall, the actual shape of the body.
The expression of the MasCon potential reads:
UMasCon ¼ GX
Nm
i¼1
mi
ri
(4.82)
where mi and ri are respectively the mass of the ith point mass of the cluster,
and its distance from the field point where the potential is being evaluated.
Nm is the total number of masses that approximate the body.
The expression of Eq. (4.82) is simpler than the other methods that solve
the continuous integral. However, the difficulty of the MasCon approach
lies in the strategy for distributing the masses within the attractor’s volume.
Indeed, the challenge is to find a balance between the total number of masses
and their distribution.
In general, as the number of masses increases, the accuracy of the poten￾tial estimation improves, but the numerical effort to compute the potential
value becomes higher. If their distribution is well arranged, it is possible to
maintain the same accuracy level with less masses, thus improving the
computational performances. Several strategies for the distribution of masses
have been developed, and include “uniform distributions,” “multiple
cores,” “multiple layers,” “core-shell,” and others [27].
The great advantage of such model is the capability of dealing with
possible internal cavities or changes of density within the body. Neverthe￾less, the computational burden is relatively high, plus field points close to
surface suffer from oscillations of the potential, due to the singularities intro￾duced by the single point masses [28].
Orbital dynamics 173Polyhedral model
The “Polyhedral Model” (POL) is a method developed by Werner and
Scheeres [29], which solves the integral of the potential expression by
modeling the attractor as a set of tetrahedrons, making the overall body a
polyhedral object. The tetrahedrons have always one vertex coincident
with the center of mass of the body and the opposite face representing
the surface element of the body.
After several rearrangements of the integral expression of Eq. (4.74),
leveraging normal and tangent vectors to the external surface of the tetrahe￾drons (the reader is invited to consult Ref. [29] for the formal derivation),
the final potential expression reads:
Upolyðx; y; zÞ¼  1
2
Gr
0
@ X
f ˛faces
rf $ Ff $ rf uf  X
e˛edges
re $ Ee $ reLe
1
A
(4.83)
Ff is the dyad associated to face f , and Ee is the dyad associated to edge e of
the polyhedron model, and read:
Ff ¼ bnf bnf
Ee ¼ bnf1bnf1
e þ bnf2bnf2
e
(4.84)
where f1 and f2 denote the two faces sharing the edge e. The term Le rep￾resents the potential of a wire associated to the edge e and depends on the
distance between the field point and the edge’s ends and on the edge’s
length. uf is the solid angle associated to the face f , and it is dependent on
the distance vectors between the field point and the three face’s vertexes.
The accuracy of the POL is uniquely related to the number of faces that
constitute the full polyhedron. The great advantage of such model is the cor￾rectness of the gravitational field down to the surface of the body, without
any restriction in the shape of the body itself (as it is for the ELL model). The
downside is the high computational burden given by the summations in Eq.
(4.83), especially when the number of tetrahedrons composing the body be￾comes very large [28,30].
Relative orbital dynamics
The term relative dynamics generally refers to the description of the mo￾tion of one body with respectto a moving reference frame. In this book, relative
orbital dynamics strictly refers to the equations of motion of a spacecraft with
respect to a free-falling nonattractive point, material or fictitious, in orbit.
174 Andrea Capannolo et al.Such dynamical expression is quite common in missions involving rendezvous
and docking, formation-flying, on-orbit servicing, and proximity operations,
which are common applications in modern spacecraft GNC. To obtain impul￾sive maneuvers and acceleration analysis from observations made in the noni￾nertial frame, we need to transform them into an inertial frame. Otherwise, it
is impossible to distinguish between thrusting forces and inertia forces. The
aim of this chapter is to give the critical insights on the derivation of spacecraft
relative orbital dynamics, but it assumes that the reader is familiar with Newto￾nian mechanics and vector derivatives. A brief discussion on relative spacecraft
attitude dynamics is included in Chapter 5 e Attitude Dynamics.
Let us assume that we want to describe the motion of a spacecraft and to
attach a reference frame Di;j;k (typically the adopted comoving reference
frame is the Local-Vertical-Local-Horizontal [LVLH]) to an orbiting target
or a fictitious point that follows an orbital trajectory with angular velocity
UðtÞ. In this derivation, the inertial reference frame is referred as II;J;K .
Please note that it represents the same inertial ECI reference frame presented
in Chapter 2 e Reference Systems and Planetary Models. Hereby, we recall
useful relationship to describe the angular velocity and its derivative of an
orbital point referred with subscript 0:
U ¼ h
r
2
0
¼ r0  v0
r
2
0
U_ ¼  2
h
r
3
0
r_0 ¼ 2
v0 $ r0
r
2
0
U
With reference to Fig. 4.4, we can define the following vectorial quan￾tities. First, the inertial position of the spacecraft in the inertial frame can be
described as:
rI ¼ r0;I þ drI (4.85)
The unit vectors of the Di;j;k reference frame can be defined as:
bi ¼ r0
r0
; bk ¼ h
h
; bj ¼ bk bi
where h is the specific angular momentum. This allows us to transform the
relative position and velocity into the comoving frame as:
drD ¼ dxbi þ dybj þ dzbk
Orbital dynamics 175dvD ¼ _dxbi þ _dybj þ _dzbk
Taking advantage of the topic discussed in the previous section
describing the two-body problem, we have the characteristic R2BP
equation:
r€I ¼  Gm1
r3 rI ¼ m
r3rI (4.86)
By recalling Eqs. (4.84 and 4.85), one can simply substitute to get the
explicit dependence of the relative position:
dr€I ¼  r€0;I  m
r3
	
r0;I þ drI

 (4.87)
So far, we have developed equations with vector quantities referred to
the inertial frame I. Nevertheless, as already mentioned, we are interested
in formulating the equations of motion with respect to a moving frame.
Figure 4.4 Moving frame for relative motion description.
176 Andrea Capannolo et al.To this purpose, the classical relative kinematics solves our issues. Indeed, the
relative acceleration measured in the comoving frame can be expressed as:
daD ¼ €dx bi þ €dy bj þ €dz bk
which is related to the absolute relative acceleration by the following
relation:
dr€D ¼ daD þ U_  drD þ U  ðU  drDÞ þ 2U  dvD (4.88)
where the relative acceleration measured in the moving frame is added to
the contributions known as Euler acceleration U_  drD, centrifugal accel￾eration U  ðU drDÞ, and Coriolis acceleration 2U  dvD. Now, if we
express Eq. (4.87) into the moving frame, knowing that r0;D ¼ r0
bi by
definition, and substitute Eq. (4.88), we obtain the nonlinear expression of
the relative dynamics in the moving frame:
8
>>>>>>>>><
>>>>>>>>>:
dx€ 2Udy_  U_ dy  U2
dx ¼ m
ðr0 þ dxÞ

ðr0 þ dxÞ
2 þ dy
2 þ dz
23
2
þ m
r
2
0
dy€þ 2Udx_ þ U_ dx  U2dy ¼ m
dy

ðr0 þ dxÞ
2 þ dy
2 þ dz
23
2
dz€ ¼ m
dz

ðr0 þ dxÞ
2 þ dy
2 þ dz
23
2
(4.89)
One can immediately perceive some key insights of the unperturbed
relative motion: in general, the moving reference frame position is a func￾tion of the time r0 ¼ r0ðtÞ, as well as the angular velocity U ¼ UðtÞ. It
can be demonstrated that there exists only one equilibrium point that coin￾cides with the origin of the moving reference frame d!dreq ¼ 0.
Hence, we actually need additional differential equations in order to
solve the motion. In the following paragraphs, some assumptions will be
made in order to converge to analytical solutions, which are of paramount
importance in GNC design.
Linearization of the equations of motion
The equations of motion described in Eq. (4.89) are nonlinear, and there exists
no analytical solution to predict the motion. Obviously, the equations can be
solved numerically, provided that the motion of the moving frame is known,
or at least the differential equations describing it. What we strive to obtain
Orbital dynamics 177during GNC design is an analytical solution in order to derive and synthesize
the algorithms. Often, the analytical solutions provide good accuracies under
specific assumptions. It is safe to state that, although we may think of imple￾menting more accurate models, analytical solutions are critical to investigate
the expected motion: we need them to get a better insight on the motion
evolution without using an immense pool of numerical simulations. A sche￾matic of the crucial steps toward simplifying the model is reported in Fig. 4.5.
The first step toward this goal is to linearize the system of ordinary dif￾ferential equations presented in Eq. (4.88). If we set the assumption of close
relative motion, we can state that:
dr
r0
 1
This means that we want to describe the relative motion of two objects
in orbit, whose relative distance is much less than their distance with respect
to the attracting body. Such assumption sounds very reasonable if we think
of the typical applications in which relative dynamics is used, for instance,
rendezvous and proximity operations. Thus, making use of Taylor expan￾sion and Eqs. (4.84a and b), we can write:
dr€I z  m
r
3
0

drI  3
r
2
0
	
r0;I $ drI


r0

(4.90)
where all the terms in dr
R higher than order one have been neglected. Similar
to the nonlinear derivation, taking Eq. (4.88) and substituting in Eq. (4.90),
we obtain the set of linear second-order differential equations describing the
relative motion expressed in the comoving frame (LVLH):
Figure 4.5 Schematics of relative dynamics derivation and main assumptions.
178 Andrea Capannolo et al.8
>>>>>>>>><
>>>>>>>>>:
dx€
2m
r
3
0
þ
h2
r
4
0

dx þ
2ðv0 $ r0Þh
r
4
0
dy  2h
r
2
0
dy_ ¼ 0
dy€þ
m
r
3
0
 h2
r
4
0

dy  2ðv0 $ r0Þh
r
4
0
dx þ
2h
r
2
0
dx_ ¼ 0
dz€þ m
r
3
0
dz ¼ 0
(4.91)
The linearized equations of motion show some key insights on the rela￾tive motion in close proximity:
• The in-plane components, namely dx and dy, are coupled, whereas the
cross-track component is independent. Moreover, the cross-track
component presents the peculiar form of the harmonic oscillator.
• As for the nonlinear version, the vectors r0 and v0 are generally functions
of time. The two vectors represent the position and velocity of the
comoving reference frame center, which typically lies on the path of a
reference orbit. For instance, for eccentric reference orbits, r0 and v0
vary with time, although with constant specific angular momentum.
Similarly, for the linearized equations, there is not an easy analytical so￾lution given the time dependence of the reference frame position and veloc￾ity in the linear differential equations. The derivation so far is the most
general one could work with in presence of the unperturbed relative motion.
Many researchers have studied alternative forms and parametrizations to
be able to solve the set of linear differential equations. Hereby, we briefly
discuss the most used models in GNC design.
True anomaly parametrization in linearized relative dynamics
One strategy to work out analytical solutions is to reparametrize the time
dependence as a function of the true anomaly. In other words, such
approach allows to solve for the relative motion of the spacecraft as a func￾tion of the true anomaly of the reference orbit. The true anomaly is indeed
used as free-variable. The time derivative _ ð$Þ of a given quantity is linked to
the derivative ð$Þ
0 with respect to the true anomaly in this way:
_ ð$Þ¼ð$Þ
0 _
q
€ð$Þ ¼ ð$Þ
00 _
q
2
þ _
q _
q0
ð$Þ
0
Using fundamentals notions of two-body orbital mechanics, described in
the previous chapter, we can express the reference orbit quantities as:
Orbital dynamics 179r0ð Þ¼ q
a
	
1  e
2


1 þ e cos q
; U ð Þ¼ q nð1 þ e cosð ÞÞ q 2
ð1  e2Þ
3
2
; n ¼
m
a3
 1
2
With these transformations, the set of linear time-varying second-order
differential equations arising from Eq. (4.90) can be rewritten for a
generic eccentric reference orbit:
8
>>>>>>><
>>>>>>>:
dx00 ¼ 2e sinðqÞ
1 þ e cosðqÞ
dx0 þ
3 þ e cosðqÞ
1 þ e cosðqÞ
dx þ 2dy0  2e sinðqÞ
1 þ e cosðqÞ
dy
dy00 ¼ 2dx0 þ
2e sinðqÞ
1 þ ecosðqÞ
dx þ
2e sinðqÞ
1 þ e cosðqÞ
dy0  e cosðqÞ
1 þ e cosðqÞ
dy
dz00 ¼ 2e sinðqÞ
1 þ e cosðqÞ
dz0  1
1 þ e cosðqÞ
dz
(4.92)
The equation presents the same peculiarities on the in-plane versus out￾of-plane components decoupling. The difficulty results from the lineariza￾tion process, which maps the curvilinear space to a rectangular one by a small
curvature approximation. Fig. 4.6 shows the effects of the linearization and
the small curvature assumption. In this case, a relative separation in the in￾track direction in the linearized equations corresponds to an incremental
phase difference in true anomaly.
Eq. (4.92) can be solved analytically in its homogenous form to obtain
the solution for the motion. The solutions are available in the literature in
various forms using different reference frames and variables. The most
notable solutions are presented by Carter [31], Inhalan and Tillerson [32],
which extend Carter’s work. However, the analytical solutions, and
Figure 4.6 Mapping from curvilinear to linear space.
180 Andrea Capannolo et al.consequent STM, imply nontrivial integrations: this makes the formulation
complex for engineering use.
A remarkable solution and STM has been proposed by Yamanaka and
Ankersen [33]. If we set the following coordinate transformation, calling
r ¼ ð1 þe cosðqÞÞ:
0
BBBBB@
dex
dey
dez
1
CCCCCA
¼ r
0
BB@
dx
dy
dz
1
CCA
Whose derivative with respect to the true anomaly is in the form of:
dex0
¼ rdx0  e sinðqÞdx
dex00 ¼ rdx00  2esinðqÞdx0  e cosðqÞdx
Thus, Eq. (4.92) can be rewritten simply as:
8
>>>>>>>><
>>>>>>>>:
dex00 ¼ 3dex
r
þ 2dey
dey00 ¼ 2dex0
dez00 ¼ dez
(4.93)
Eq. (4.93) can be solved by using the proposed integral formulation [33]
to derive the following solution algorithm for the STM, which is very much
used in GNC algorithm design. In the original formulation of Yamanaka,
the comoving frame Gm;n;p is taken differently from Di;j;k, in particular,
the following rotation holds from Gm;n;p to Di;j;k:
DRG ¼
2
6
6
4
0 0 1
10 0
0 1 0
3
7
7
5:
In practical words, the radial direction toward the attracting body is
called z axis, whereas the y axis is opposite to the angular momentum vector.
1. Given a set of initial conditions, we find the transformed variables:
d r
w
0 ¼ r dr0; dv
w
0 ¼ e sinð Þq dr0 þ
p2
hr

dv0
Orbital dynamics 1812. The pseudoinitial values for the in-plane components are necessary in
order to use the proposed STM. They need to be calculated as follows,
bearing in mind that they are expressed in the Gm;n;p reference frame:
0
BBBBB@
dx0
dz0
dvx0
dvz0
1
CCCCCA
¼ 1
1  e2
2
6
6
6
6
6
4
1  e
2 3es	
1=r þ 1=r2
 esð1 þ 1=rÞ ec þ 2
0 3s
	
1=r þ e
2
=r2
 sð1 þ 1=rÞ c  2e
0 3ðc=r þ eÞ cð1 þ 1=rÞ þ e s
0 3r þ e
2  1 r2 es
3
7
7
7
7
7
5
0
BBBBBBBBB@
dex0
dez0
devx0
devz0
1
CCCCCCCCCA
where c ¼ r cosðqÞ and s ¼ r sinðqÞ. The out-of-plane (or cross-track)
initial conditions can be used as they are in the STM.
3. The STM for the in-plane and out-of-plane reads, respectively:
0
BBBBBBBBB@
dext
dezt
devxt
devzt
1
CCCCCCCCCA
G
¼
2
6
6
6
6
6
4
1 cð1 þ 1=rÞ sð1 þ 1=rÞ 3r2J
0 s c 2  3esJ
0 2s 2c  e 3ð1  2esJÞ
0 s
0 c
0 3e
	
s
0
J þ s=r2


3
7
7
7
7
7
5
q
0
BBBBB@
dx0
dz0
dvx0
dvz0
1
CCCCCA
0
B@
deyt
devyt
1
CA
G
¼ 1
rj
qq0
" c s
s c #
qq0
0
B@
dey0
devy0
1
CA
where q can be calculated at any time using Kepler’s equation and the
auxiliary terms are:
r ¼ 1 þ e cosðqÞ; s ¼ r sinðqÞ; c ¼ r cosðqÞ
s
' ¼ cosð Þþ q e cosð2qÞ; c
' ¼ ðsinð Þþ q e sinð2qÞÞ; J ¼ k2
ðt  t0Þ; k2
¼ h=p
2
182 Andrea Capannolo et al.Linearized equations of motion for nearly circular orbits
The particular case in which the reference orbit can be assumed circular (or
nearly circular), the equations of motion can be further simplified and deeply
treated analytically. Such assumption can be formalized as:
e ¼ 0/v0 $ r0 ¼ 0//h ¼ ffiffiffiffiffiffi
mr0
p /n ¼
ffiffiffiffi
m
r
3
0
r
where n is called mean motion. In a circular orbit, the position and velocity
vector are always perpendicular. The moving reference frame rotates around
the attracting body with a constant angular velocity, n indeed. The resultant
linearized equations of motion for nearly circular orbits are best known as
ClohessyeWiltshire (CeW) model and read (in the D frame):
8
>>>><
>>>>:
dx€ 3n
2
dx  2ndy_ ¼ 0
dy€þ 2ndx_ ¼ 0
dz€þ n
2
dz ¼ 0
(4.94)
Since there are no time-dependent coefficients, the equations can be in￾tegrated to derive the analytical solutions for the set of initial conditions
dr0D ¼ 	
dx0; dy0; dz0; dvx0; dvy0; dvz0


. The solutions are here reported in
the state-space form as STM, which is very useful for the purpose of
GNC design:
0
BBBBBBBBBBBBBB@
dxt
dyt
dzt
dvt0
dvt0
dvt0
1
CCCCCCCCCCCCCCA
D
¼
2
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
4
4  3 cosðntÞ 0 0 1
n sinðntÞ 2
n ð1  cosðntÞÞ 0
6ðsinðntÞ  ntÞ 1 0 2
n ðcosðntÞ  1Þ 1
n ð4 sinðntÞ  3ntÞ 0
0 0 cosðntÞ 0 0 1
n sinðntÞ
3n sinðntÞ 0 0 cosðntÞ 2 sinðntÞ 0
6nðcosðntÞ  1Þ 0 0 2 sinðntÞ 4 cosðntÞ  3 0
0 0 n sinðntÞ 0 0 cosðntÞ
3
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
5
0 t
BBBBBBBBBBBBBB@
dx0
dy0
dz0
dvx0
dvy0
dvz0
1
CCCCCCCCCCCCCCA
D
(4.95)
Orbital dynamics 183The solutions are truly insightful to derive some peculiar features of the
relative motion:
• As already seen, the in-plane components, namely dx and dy, are
coupled, whereas the cross-track component is independent. Moreover,
the cross-track component presents the peculiar form of the harmonic
oscillator.
• All the components are a composition of sinusoidal functions with 1= n as
fundamental frequency.
• The radial and cross-track components are purely harmonic.
• The only component that possesses a secular term is the along-track
component dy.
The CeW equations are very relevant for control and guidance syn￾thesis. Furthermore, they provide a key tool to investigate the relative
motion and its geometry with simple considerations on the initial condi￾tions. The drawbacks of such model are the restricting assumptions that
involve both a boundary on eccentricity ðe/0Þ and on the relative
position. Roughly speaking, a general guideline for the applicability of
this model in one period prediction, we could set as upper boundaries:
dx
r0 < 8e
3;
dy
r0 < 6e
2; dz
r0 < 6e
2:
Analysis and characteristic of the unperturbed motion
The solutions of the linearized nearly circular motion allow a deep under￾standing of the relative motion. In particular, we could manipulate the equa￾tions to derive the fundamental characteristic of the unperturbed relative
motion. We already know that the cross-track component is completely
decoupled from the in-plane components. The out-of-plane motion fol￾lows harmonic oscillations around the origin. To analyze the in-plane mo￾tion, let us recast the solutions in Eq. (4.95) as:
dx ¼ C1 þ C4 sinðntÞ  C3 cosðntÞ (4.96a)
dy ¼ C2  3
2
C1nt þ 2C3 sinðntÞ þ C4 cosðntÞ (4.96b)
where C1 ¼

4dx0 þ2dvy0
n

; C2
¼

dy0  2
dvx0
n

; C3 ¼

3dx0 þ 2
dvy0
n

; C4 ¼ dvx0
n :
184 Andrea Capannolo et al.If we take the linear combination of the squared Eqs. (4.96a and b), we
obtain:
ðdx  C1Þ
2 þ

dy  C2 þ
3
2
C1ðntÞ
2
4
¼ C2
3 þ C2
4 if 	
C2
3 þ C2
4


s0then ðdx  C1Þ
2
	
C2
3 þ C2
4


þ

dy  C2 þ
3
2
C1ðntÞ
2
4
	
C2
3 þ C2
4

 ¼ 1
The latter formulation resembles the canonical formulation of an ellipse
in the orbital plane. In particular, when 	
C2
3 þC2
4


s0, the equation de￾scribes an ellipse in dx; dy plane, whose dy center coordinates vary linearly
in time. The center coordinates are given as:
dxC ¼ 4dx0 þ 2
dvy0
n
dyC ¼ dy0  2
dvx0
n  3
2

4dx0 þ 2
dvy0
n

nt//dy_C
¼ 3
	
2ndx0 þ dvy0


In general, the semimajor axis is along the y-axis with a value of a ¼
2
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
	
C2
3 þ C2
4
q 
 and semiminor axis b ¼ a
2 meaning that the amplitude of
the along-track relative motion is twice the radial one. The interesting result
is that, regardless of the initial condition, the relative elliptical orbits (oscu￾lating ellipses whose center varies) have always an eccentricity of e ¼ 1
2
ffiffiffi
3 p .
The generic drifting motion is shown in Fig. 4.7.
Particular cases can be identified by inspecting Eq. (4.95) and the
following derivations. In particular, the motion can be investigated by
working out relationships in terms of the initial conditions. For the unper￾turbed and unforced motion, the initial conditions fully determine the mo￾tion. Initial conditions on the relative velocities different from zero can be
thought as the results of impulsive shots.
Concentric coplanar absolute orbit
If we investigate the term C2
3 þ C2
4 and set it to 0, we no longer obtain a
moving ellipse. In detail, by removing the assumption adopted beforehand,
Orbital dynamics 185we can set C3 ¼ C4 ¼ 0, which is the only condition that vanishes the term
C2
3 þ C2
4 . In addition, taking advantage of the decoupling between the in￾plane and out-of-plane motion, we focus on the coplanar scenario. Summa￾rizing the initial conditions constraints:
dvx0 ¼ 0; dvy0 ¼ 3
2
ndx0; dz0 ¼ 0; dvz0 ¼ 0
We obtain a spacecraft that orbits the attracting body in a circular orbit,
close to the reference one. The circular orbit has a slight difference in radius
given by the entity of dx0. If for instance, if the circular orbit has a slightly
larger radius ðdx0 > 0Þ, then the spacecraft simply lags the reference frame.
The plot in Fig. 4.8 shows a straight line due to the linearization of the
analyzed model.
Circular relative orbit
A relative circular motion around the moving reference frame origin can be
achieved by canceling the secular term. If we set C1 ¼ C2 ¼ 0, we obtain a
Figure 4.7 Generic relative motion. Drifting trajectories: the in-plane projection is a set
of osculating ellipses.
186 Andrea Capannolo et al.centered relative orbit. For the above conditions the center offset, and the
drifting term, vanish. The in-plane motion is an ellipse, centered at the
origin of the moving reference frame, with the semimajor axis lying on
the along-track direction and the semiminor axis along the radial direction,
as shown in Fig. 4.9.
Stationary coplanar elliptical relative orbit
The center of the relative ellipse does not necessarily need to be at the origin
of the moving reference frame. Hence, if we only keep the assumption of
C1 ¼ 0, then the motion takes place in the orbital plane of the reference
orbit. Consequently, the motion of the spacecraft is an ellipse, whose center
does not move with respect to the origin of the moving reference frame, as
shown in Fig. 4.10.
Impulsive shots
An initial condition in the relative velocities can be regarded as an impulsive
shot, i.e., an instantaneous change of velocity from the equilibrium point.
The resultant motion can be summarized as in Table 4.3.
The impulsive relative maneuvers will be described in detail in
Chapter 8dGuidance.
Figure 4.8 Relative motion from concentric coplanar absolute orbits.
Orbital dynamics 187Figure 4.9 Three-dimensional circular relative orbit.
Figure 4.10 Stationary coplanar elliptical relative orbit.
188 Andrea Capannolo et al.J2-perturbed relative dynamics
Several authors have proposed relative dynamical models that include pertur￾bations. Certainly, one of the most important perturbations is the J2-term due
to Earth oblateness. Here, we report the formulation of the J2-perturbed rela￾tive dynamics without reporting the detailed derivation, which can be found
in Ref. [34]. The nonlinear J2-perturbed dynamics reads:
dx€¼ 2uzdy_ 

n
2
j  u2
z

dx þ azdy  uxuzdz  	
zj  z


sisq
 r

n
2
j  n
2

þ ax
dy€¼  2uzdx_ þ 2uxdz  azdx 

n
2
j  u2
z  u2
x

dy þ axdz
 	
zj  z


sicq þ ay
dz€¼  2uxdy_  uxuzdx  axdy 

n
2
j  u2
x

dz  	
zj  z


ci þ az þ az
where the contributing terms are:
n
2 ¼ m
r
3
0
þ
kJ2
r
5
0
 5kJ2s
2
i s
2
q
r5 ; rJZ ¼ ðr0 þ dxÞsisq þ dysicq þ dzci
n
2
j ¼ m
r3 þ
kJ2
r5  5kJ2r
2
JZ
r7 ; kJ2 ¼ 3J2mR2
e
2
ux ¼ kJ2s2isq
hr3
0
; uz ¼ h
r
2
0
Table 4.3 Impulsive motion in linearized relative dynamics for nearly circular orbits.
Impulse direction Motion description
Along-track dy exhibits a periodic
variation
superimposed with a
linear drift
Radial Purely periodic in
dx; dy. Bounded and
closed relative orbit
without any drift.
Normal Cross-track oscillatory
motion.
Orbital dynamics 189ax ¼ u_x ¼ kJ2s2icq
r
5
0
þ
3r_
0kJ2s2isq
r
4
0 h  8k2
J2s
3
i cis
2
qcq
r6h2
az ¼ u_z ¼ 2hr_
0
r
3
0
 kJ2s
2
i s2q
r
5
0
; z ¼ 2kJ2sisq
r4 ; zj ¼ 2kJ2rJZ
r5
in which h is the orbital angular momentum, i orbital inclination, J2 is the
zonal harmonic coefficient 1:0826$103 for Earth, Re is the Earth radius, q is
the orbital true anomaly, and a ¼ 
ax;ay;az
T is the forced acceleration
vector. Last, sx and cx stand for sinðxÞ and cosðxÞ, where x is a generic angle.
The spacecraft relative motion is actually described by 11 first-order dif￾ferential equations, namely 
dx; dy; dz; dx_; dy_; dz_

and 
r0; r_
0; h; i; q

.
Nevertheless, in practical terms, the latter quantities can be computed using
an external high-fidelity propagator. This can be representative of an on￾board absolute state estimator. Alternatively, these quantities can be
included in the integration step of the dynamical model using an approxi￾mated absolute dynamical model. An acceptable set of differential equations
for the reference orbit is suggested here:
r€0 ¼  m
r
2
0
þ
h2
r
3
0
 kJ2
r
4
0
	
1  3s
2
i s
2
q


_
h ¼  kJ2s
2
i s2q
r
3
0
U_ ¼  2kJ2s
2
qci
hr3
0
d
dt i ¼  kJ2s2is2q
2hr3
0
_
q ¼ h
r
2
0
þ
2kJ2c
2
i s
2
q
hr3
0
Relative dynamics modeling using relative orbital elements
Up to this point, we have parametrized the motion of the spacecraft in the
most natural manner: using position and velocity expressed in a given refer￾ence frame. An important and rapidly increasing approach to describe the
190 Andrea Capannolo et al.relative motion is to use a combination of the relevant orbital elements of the
reference and spacecraft orbits.
Indeed, we developed our models assuming there exists a reference frame
that moves along a reference orbit and a spacecraft nearby, which is flying its
own orbit, although quite close to the reference one. In general, in the 2BP,
we can parametrize the orbits using the Keplerian elements. Even though the
following reasoning can be developed using the classical set of orbital ele￾ments, we use a slightly different parametrization that will help us, namely:
c ¼
0
BBBBBBBBBBBB@
a
u
ex
ey
i
U
1
CCCCCCCCCCCCA
¼
0
BBBBBBBBBBBB@
a
u þ Mq
e cosðuÞ
e sinðuÞ
i
U
1
CCCCCCCCCCCCA
where M is the mean anomaly, a the semimajor axis, e the eccentricity, i the
orbit inclination, u the argument of perigee, and U the RAAN. The classical
set of Keplerian elements is modified considering the eccentricity vector e ¼ 	
ex;ey

T and the mean argument of longitude u to avoid singularities for
near-circular orbits. If we think at two orbits close to each other, we can
easily, and quite intuitively, introduce a set of relative orbital elements dc that
is a combination of the orbital elements of the spacecraft and reference orbit.
There exist multiple ways one could define the set of relative orbital ele￾ments: one could use the pure mathematical difference Dc ¼ cs  cr;
nevertheless, researchers have tried to define smart combination of orbital
elements to derive a set of relative orbital elements, which could be robust to
typical singularities that may be encountered in orbit representation [35e38].
One common set of relative orbital elements is the one proposed by
D’Amico and later extended [35,37]. The set of quasisingular relative orbital
elements reads:
dc ¼
0
BBBBBBBBBBBB@
da
dl
dex
dey
dix
diy
1
CCCCCCCCCCCCA
¼
0
BBBBBBBBBBBB@
ðas  arÞ=ar
ðus  urÞþðUs  UrÞcosðiÞ
exs  exr
eys  eyr
is  ir
ðUs  UrÞsinðiÞ
1
CCCCCCCCCCCCA
(4.97a)
Orbital dynamics 191where the s subscript refers to the spacecraft, r to the reference orbit. The
semimajor axis difference has been normalized through the chief semimajor
axis to have dimensionless quantities. dl denotes the relative mean longitude
between the spacecraft. Apart from da and dl, the relative orbit parame￾trization is based on the relative eccentricity and inclination vectors for
which the following Cartesian and polar notations are applied:
de ¼
0
B@
dex
dey
1
CA ¼ de
0
@
cosðfÞ
sinðfÞ
1
A
di ¼
0
B@
dix
diy
1
CA ¼ di
0
@
cosðqÞ
sinðqÞ
1
A
(4.97b)
The amplitudes (or lengths) of the relative e/i-vectors are denoted by de
and di, respectively, and should not be confused with the arithmetic differ￾ences of eccentricity and inclination. DThe phases of the relative e/i-vectors
are termed relative perigee f and relative ascending node q because they
characterize the geometry of the relative orbit as seen by the chief spacecraft.
In particular, as will be shown later, f and q determine the angular locations
of the perigee and ascending node of the relative orbit.
The benefit of using such model is that, if the perturbations are
neglected, the geometry of the relative motion with respect to a reference
orbit is uniquely determined by a set of invariant relative orbital elements,
except for the relative mean longitude, which follows the Keplerian prop￾agation. Indeed, in absolute terms, we the natural evolution of the dynamic
system can be described only by the rate of change of the mean anomaly:
dMq
dt ¼
ffiffiffiffi
m
a3
r
if DM; Da  1 then DM_ q ¼ dðDMÞ
dt ¼ 3
2
ffiffiffiffi
m
a5
r
Da
¼ 3
2
n
Da
a ¼ 3
2
nda
In which only the assumption of small discrepancies between the along￾track positions and orbital semimajor axes is used. It is important to remark
that no constraints have been put to the relative eccentricity. The unper￾turbed model is then simply written as:
dc_ ¼
2
6
6
4
0
1:5n 065
041
3
7
7
5
(4.98)
192 Andrea Capannolo et al.Coordinates transformation
The active collision avoidance maneuvers depend on the relative metric dis￾tance between two agents. The relative distance is naturally expressed in the
Cartesian LVLH reference frame. The mapping between the cartesian rela￾tive state to the Relative Orbital Elements (ROE) dc is required to process
the measurements and compute the guidance and control output. The trans￾formation matrices are derived by using the classical orbital elements differ￾ence DOE ¼ ½Da DM Du De Di DU as follows:
JX
dc ¼ vX
vDOE $ vDOE
vdc ; J
dc
X ¼ vdc
vDOE $ vDOE
vX
where a is the semimajor axis, Mq is the mean anomaly, u the argument of
perigee, e the eccentricity, i the inclination, and U the RAAN. The first￾order approximation of the mapping between the Hill state and classical
osculating orbital elements yields:
dx ¼ r0
a
Da  a $ cos qDe þ
ae sin q ffiffiffiffiffiffiffiffiffiffiffiffi
1  e
2 p DM
dy ¼

a þ
r0
1  e
2

sin qDe þ
a
2
r0
ffiffiffiffiffiffiffiffiffiffiffiffi
1  e
2 p
DM þ r0Du þ r0 cos iDU
dz ¼ r0 sinðq þ uÞDi  r0 sin i cosðq þ uÞDU
(4.99)
By differentiation, the full transformation is obtained:
dx_ ¼  ne sin q
2 ffiffiffiffiffiffiffiffiffiffiffiffi
1  e2 p Da þ n sin q ffiffiffiffiffiffiffiffiffiffiffiffi
1  e2 p 
a3
r
2
0

De þ en cos q
a3
r
2
0
DM
dy_ ¼
"
n ffiffiffiffiffiffiffiffiffiffiffiffi
1  e2 p 
1 þ
r0
að1  e2Þ

a3
r
2
0

cos q þ
aen sin2 q
ð1  e2Þ
3
2
#
De
 en sin q
a3
r
2
0
DM þ
aen sin q ffiffiffiffiffiffiffiffiffiffiffiffi
1  e2 p Du
dz_ ¼ an
ffiffiffiffiffiffiffiffiffiffiffiffi
1  e2 p ðsin i½sinðq þ uÞ þ e sin uDU þ ½cos q þ u þ e cos uDiÞ
Combining the equations, the transformation matrix between Hill state
and classical orbital elements DOE, namely vX
vDOE and its inverse, can be ob￾tained. To formulate the complete transformation, the Jacobian of the
Orbital dynamics 193transformation between classical orbital elements and relative orbital ele￾ments dc is required. Such transformation is obtained from the definition
of dc for DOE / 0:
vDOE
vdc ¼
2
6
6
6
6
6
6
6
6
6
6
6
6
6
6
4
a 0 0 0 00
0 1
sinðuÞ
e cosðuÞ
e
0
cosðiÞ
sinðiÞ
0 0 sinðuÞ
e
cosðuÞ
e
0 0
0 0 cosðuÞ sinðuÞ 0 0
00 0 0 1 0
0 0 0 0 0 sinðiÞ
3
7
7
7
7
7
7
7
7
7
7
7
7
7
7
5
vdc
vDOE ¼
2
6
6
6
6
6
6
6
6
6
6
6
6
6
4
1
a
0 0 0 00
0 1 1 0 0 cosðiÞ
0 0 e sinðuÞ e cosðuÞ 0 0
0 0 e cosðuÞ sinðuÞ 0 0
00 0 0 1 0
0 0 0 0 0 sinðiÞ
3
7
7
7
7
7
7
7
7
7
7
7
7
7
5
The described model is very useful to perform the design of the relative
trajectories. Indeed, such model parametrization is very much used in forma￾tion flying.
At this point, we need to make an important consideration to clear up
the potential ambiguity the reader may find while choosing between
different models, or better, model parametrization. If the first-order map￾ping between the Cartesian and ROE state in Eq. (4.99), which is valid
for any eccentricity, is furtherly constrained with the additional assumption
of nearly circular reference orbit, one would find [35]:
dx=a ¼ da  dex $ cos u  dey $ sin u
dy=a ¼ 3
2
dau þ dl þ 2dex $ cos u  2dey $ sin u
dz=a ¼ dix $ sin u  diy $ cos u
(4.100)
194 Andrea Capannolo et al.where u is the mean argument of latitude. The equations directly match the
parametrization given in Eq. (4.96a and b). Indeed, the relative orbital el￾ements can be thought as the integration constants of the CeW equations.
The geometrical meaning is then trivially derived. For instance, we can
already expect that the term 3
2 da þ dl replaces the combination of C1 and
C2; hence, we could expect that da and dl will be responsible for the ellipse
center shift and drift.
To better highlight the abovementioned considerations, we can use a
slightly modified version of Eq. (4.100). If we rearrange Eq. (4.100) using
the polar representation of de and di vectors in Eq. (4.97b), we obtain:
dx=a ¼ da  de $ cosðu  FÞ
dy=a ¼ 3
2
dau þ dl þ 2de $ sinðu  FÞ
dz=a ¼ di $ sinðu  qÞ
(4.101)
Relative motion geometry
The mapping between ROE state and CartesianeHill state has been
described in the previous section. Hence, the reader should already be
familiar with the geometry of the resultant relative motion. As already stated,
and important features of ROE parametrization are the unperturbed motion
is characterized by a set of five invariant relative orbital elements and a free
coordinate that indicates the relative phase angle along the relative orbit.
Analyzing Eq. (4.101), we can derive the necessary conditions for
bounded, centered relative motion of a spacecraft with respect to the mov￾ing reference frame (D or G):
da ¼ 0
dl ¼ 04Du ¼ DUcosðiÞ
where the definition of the relative orbital elements has been used. If
these conditions apply, then we obtain an elliptical motion as in Fig. 4.11,
whose semimajor axis lies on the along-track direction and equals to 2ade.
The semiminor axis instead lies on the radial direction and equals to ade.
The in-plane motion geometry is fully defined by the relative eccentricity
vector. The size of the ellipse is defined by the absolute value de ¼ jdej,
whereas the phase angle of the polar representation F represents the relative
pericenter. When the mean argument of latitude u equals F, the spacecraft is
below the origin along the radial direction. Similarly, the relative inclination
Orbital dynamics 195vector defines the cross-track motion, which is a harmonic oscillation with
amplitude adi and phase angle u  q.
The drifting trajectories are natural drift orbits achieved by a different
semimajor axis. The different semimajor axis results in slightly different pe￾riods, which determines the relative drift velocity. These trajectories allow
helicoidal trajectories enclosing the along-track direction. Given a drift dis￾tance 	
ddrift
 and duration 	
Tdrift

, we can determine the drift rate and
consequently the ada necessary to enter the ballistic drift by inverting the dy￾namics equation expressed in Eq. (4.98).
_dl ¼ 3
2
nda/ada ¼  2ddrift
3Tdriftn
where n is the mean motion.
Energy-matching condition and passive safety
The parametrization using relative orbital elements allows deriving straight￾forward relationship to achieve motion characteristics, such as bounded rela￾tive orbits and passive safety.
To avoid the relative drift, it is critical that the relative motion of the
spacecrafts remains bounded. A fundamental concept in spacecraft relative
motion is the orbital energy-matching method to generate bounded forma￾tions. The orbital energy of the satellites is a function of the semimajor axis
only:
Figure 4.11 Relative motion geometry parametrized using relative orbital elements.
196 Andrea Capannolo et al.E ¼  m
2a
Hence, it is sufficient to match the orbital energy of the reference orbit to
generate bounded formations. In order to work out relevant initial condi￾tions, being either in the Cartesian space or dc, we refer to the dc relative
space. It is sufficient that da ¼ 0 for the relative orbital elements defining
the relative motion. Fig. 4.12 shows trajectories propagation based on
energy-matching initial conditions in perturbed models.
A remarkable observation on passively safe trajectories can be derived
from the relationship between de and di vectors. The idea of using e/i￾vector separation to collocate satellites has been studied for many years in
the context of geostationary satellites station-keeping. A similar approach
can be used for formation flying and in general relative trajectories design.
In such application, the presence of along-track location uncertainties
leads to the criticality of designing a relative trajectory that can properly
separate the satellites in the radial and cross-track direction.
If we take Eq. (4.101) and calculate the minimum relative distance as a
function of the mean argument of latitude, one can write:
Figure 4.12 Energy-matching condition and bounded orbits for highly eccentric refer￾ence orbits [39].
Orbital dynamics 197dxz ¼
ffiffiffi
2
p jde $ dij
	
de2 þ di^2 þ jde þ dij $ jde  dij

1=2
The expression shows that the minimum distance projected on the xz
plane is maximized when the de and di vectors are either parallel or antipar￾allel. This condition ensures that, when the spacecraft crosses the orbital
plane (cross-track distance vanished), it is at its maximum radial distance
and vice versa. In contrast, if we take the condition detdi, the radial and
cross-track distances can vanish simultaneously, yielding a trajectory that
intersect the along-track axis.
Perturbed relative dynamics with relative orbital elements
Similar to the Cartesian models, researchers have expanded the relative
dynamical model parametrized with relative orbital elements to a J2-per￾turbed dynamics. Here we report only the formulation: for a detailed deri￾vation, the reader is suggested to refer to Ref. [37]. The complete dynamical
model can be expressed as:
_ dc ¼ 	
Ak þ AJ2


$ dc þ Bu
AJ2 ¼
2
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
4
0 0 0 0 00
7
2
ð1 þ hÞ
	
3 cos2ir  1

 0 exGFP eyGFP FS 0
7
2
eyQ 0 4exeyGQ 

1 þ 4Ge2
y

Q 5eyS 0
7
2
exQ 0 	
1 þ 4Ge2
x


Q 4exeyGQ 5exS 0
0 0 0 0 00
7
2
S 0 4exGS 4eyGS 2T 0
3
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
5
where the r subscript refers to the reference orbits and the contributing terms
are:
k ¼ ga
7
2 r h4
; h ¼
ffiffiffiffiffiffiffiffiffiffiffiffi
1  e2
r
q
; g ¼ 3
4 J2R2
e
ffiffiffi
m p ; ex ¼ er cos ur; ey
¼ er sin ur; E ¼ 1 þ h; G ¼ 1
h2;
F ¼ 4 þ 3h; P ¼ 3 cos2
ir  1; Q ¼ 5 cos2
ir  1; S ¼ sin 2ir; T ¼ sin2
ir
198 Andrea Capannolo et al.The control matrix is derived from Gauss Variational Equation as in
Ref. [37]:
B ¼ 1
an
2
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
4
2
h
er sinðqÞ 2
h ð1 þ er cosðqÞÞ 0
 2h2
ð1 þ er cosðqÞ 0 0
h sinðurÞ þ q h ð2 þ er cosðqÞÞcosður þ qÞ þ ex
1 þ er cosðqÞ h ey
tanðirÞ
sinður þ qÞ
1 þ er cosðqÞ
h cosðurÞ þ q h ð2 þ er cosðqÞÞsinður þ qÞ þ ey
1 þ er cosðqÞ h ex
tanðirÞ
sinður þ qÞ
1 þ er cosðqÞ
0 0 h cosður þ qÞ
1 þ er cosðqÞ
0 0 h
sinður þ qÞ
1 þ er cosðqÞ
3
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
5
A very useful visualization of the effects of Earth oblateness on relative
motion is given by Koenig in Ref. [37]. If we plot the combined effects
of J2 and Keplerian motion of the evolution of the relative orbital elements,
we could produce Fig. 4.13.
A modal decomposition of the combined effects of Keplerian relative
motion and J2 is illustrated in Fig. 4.13. The dotted lines denote individual
modes, and solid lines denote combined trajectories. Each of these plots su￾perimposes the motion of each of three state component pairs. The first pair
includes the relative semimajor axis and mean along-track separation, the
second pair includes state components that are functions of the eccentricity
and argument of perigee, and the third pair includes components that are
functions of the inclination and U. The combined effects of Keplerian rela￾tive motion and J2 produce four distinct relative motion modes:
Figure 4.13 J2 effects on the evolution of the relative orbital elements.
Orbital dynamics 199• a constant drift of dl due to both Keplerian relative motion and J2
• a rotation of the relative eccentricity vector due to J2
• a secular drift of the relative eccentricity vector proportional to the chief
eccentricity and orthogonal to the phase angle of the chief argument of
perigee due to J2
• a constant drift of diy due to J2.
Beside Earth oblateness, the orbital perturbations arise from multiple
sources as discussed in Chapter 3 - The Space environment. The magnitude
of relative accelerations for close near-circular relative motion in LEOs
(<1500 km) as a function of the relative distance is shown in Fig. 4.14.
For a more complete analysis, please refer to Ref. [35].
Comparison of relative dynamics modeling
A thorough comparison between different relative dynamical models is
beyond the scope of this book. Nevertheless, we can take advantage of liter￾ature results reporting comprehensive and exhaustive results on the use of
different analytical models [40]. We report here the comparison between
the following models (some of them have been fully described in the
chapter):
• ClohessyeWiltshire model, or HilleClohessyeWiltshire model (CeW, CW,
HCV). Keplerian nearly circular reference orbits based on Cartesian
translational states [1].
• Quadratic Volterra (QV) model. Keplerian nearly circular reference orbits
based on Cartesian translational states [41].
Figure 4.14 Magnitude of relative accelerations for close nearly circular motion as a
function of the relative distances.
200 Andrea Capannolo et al.• SchweigharteSedwick model. Perturbed nearly circular reference orbits
based on Cartesian translational states [42].
• YamanakaeAnkersen STM. Keplerian eccentric reference orbits based on
Cartesian translational states [33].
• Broucke STM. Keplerian eccentric reference orbits based on Cartesian
translational states [43].
• GAM STM. Perturbed nearly circular reference orbits based on orbital
element states [44].
• GimeAlfriend STM. Perturbed eccentric reference orbits based on orbital
element states [36].
• KGD STM. Perturbed eccentric reference orbits based on orbital
element states [37].
• YaneAlfriend nonlinear theory. Perturbed eccentric reference orbits based
on orbital element states [45].
• BiriaeRusseleVinti method. Perturbed eccentric reference orbits [46].
The comparison between the models is performed for a 24 h simulation
for each test case. The metric is the error in position prediction. The bench￾mark is represented by a high-fidelity propagator, which entails the forces
contribution of 120  120 gravity field, atmospheric drag, solar radiation
pressure, third-body sun and moon, relativistic and tidal effects.
Tables 4.4e4.6 report propagation results for reference scenarios.
Table 4.4 Scenario: fixed relative motion geometry with small separation (w300 m)
and a chief orbit with eccentricity varied over the range 104 to 0.7.
Prediction Errors [m]dOrder of magnitude
Eccentricity [L]
Model 10e4 10e3 10e2 10e1 0.7
CW/QV 3.5•102 4.0•102 1.0•103 9.0•103 4.5•104
YamanakaeAnkersen/
Brouke
3.0•102 3.0•102 5.0•102 7.0•102 1.5•103
SchweigharteSedwick 2.5•102 2.5•102 5.0•102 1.5•103 6.0•103
GimeAlfriend 2.0•102 2.0•102 1.5•102 5.0•101 5.0•101
YaneAlfriend/KGD 2.0•102 2.0•102 1.5•102 5.0•101 5.0•101
GAM 2.0•102 2.0•102 1.5•102 7.0•101 1.5•102
BiriaeRusseleVinti 2.0•102 2.0•102 1.5•102 5.5•101 5.0•101
Inspired by J. Sullivan, S. Grimberg, S. D’Amico, Comprehensive survey and assessment of spacecraft
relative motion dynamics models, Journal of Guidance, Control, and Dynamics 40 (8) (2017)
1837e1859. https://doi.org/10.2514/1.G002309.
Orbital dynamics 201Table 4.5 Scenario: nearly circular sun-synchronous LEO with perigee altitude of
750 km and a nominally bounded a centered relative motion trajectory. The
relative distance is varied from approximately 2 m to 250 km.
Prediction Errors [m]dOrder of magnitude
drmax/a [L]
Model 3•10L5 10e4 10e3 10e2 6.5•10L2
CW 2.0•102 4.0•102 7.0•103 1.5•105 3.0•106
QV 2.0•102 4.0•102 6.0•103 9.0•104 8.0•105
YamanakaeAnkersen/
Brouke
2.0•102 2.5•102 2.0•103 2.0•104 1.5•105
SchweigharteSedwick 2.0•102 2.5•102 1.5•103 1.5•104 1.5•105
GimeAlfriend 2.0•102 2.0•102 6.0•102 7.0•104 3.0•106
YaneAlfriend 2.0•102 2.0•102 2.2•102 3.0•102 4.5•102
KGD 2.0•102 2.0•102 2.2•102 3.0•102 3.0•103
GAM 2.0•102 2.0•102 2.2•102 3.5•102 3.0•103
BiriaeRusseleVinti 2.0•102 2.0•102 2.0•103 6.0•104 6.0•105
Inspired by J. Sullivan, S. Grimberg, S. D’Amico, Comprehensive survey and assessment of spacecraft
relative motion dynamics models, Journal of Guidance, Control, and Dynamics 40 (8) (2017)
1837e1859. https://doi.org/10.2514/1.G002309.
Table 4.6 Scenario: highly inclined, eccentric reference orbit with e ¼ 0.5 and a
perigee altitude of 750 km. The relative distance is varied from approximately 2 m
to 250 km.
Prediction Errors [m]dOrder of magnitude
drmax/a [L]
Model 6•10L6 10e4 10e3 10e2 7•10L2
CW 6.0•101 4.0•103 3.0•104 4.0•105 6.0•106
QV 6.0•101 4.0•103 3.0•104 3.5•105 3.0•106
YamanakaeAnkersen/
Brouke
6.0•101 3.0•102 7.0•103 5.0•105 2.5•106
SchweigharteSedwick 6.0•101 4.0•103 3.0•104 3.5•105 1.5•105
GimeAlfriend 6.0•101 1.0•102 9.0•102 5.0•104 4.0•106
YaneAlfriend 6.0•101 6.0•101 5.0•101 4.0•102 3.0•103
KGD 6.0•101 6.0•101 5.0•101 4.0•102 4.0•103
GAM 6.0•101 1.0•102 2.5•102 4.0•103 3.0•104
BiriaeRusseleVinti 6.0•101 6.0•101 6.5•101 8.0•102 2.0•104
Inspired by J. Sullivan, S. Grimberg, S. D’Amico, Comprehensive survey and assessment of spacecraft
relative motion dynamics models, Journal of Guidance, Control, and Dynamics 40 (8) (2017)
1837e1859. https://doi.org/10.2514/1.G002309.
202 Andrea Capannolo et al.Cartesian and relative orbital elements mapping
The coordinates transformation has been presented in the previous section.
However, some concerns may arise with respect to the accuracy of such
model, reason for which a set of propagation tests have been performed,
in order to assess the level of confidence to pose into the ROE formulation.
The dynamics has indeed been compared to different Cartesian formulations
of the relative dynamics and to a high-fidelity orbital propagator. The pro￾cedure for the validation of the ROE formulation with the high-fidelity
propagator is presented in Fig. 4.15.
The selection of the initial conditions for the propagation of the Carte￾sian state is fundamental. An incoherence among the different methods can
arise for what concerns the different level of linearization required by the
translation of the ROE into the Cartesian state. Indeed, different state prop￾agations arise if such conversion is performed through the nonlinear chain of
transformations described in the bottom branch Fig. 4.12 or through the
direct linear transformation, as in the last conversion of the upper branch
of the graph. The former starts from the ROE and, passing through the dif￾ference in orbital elements DOE and the reference orbital elements OEref ,
recovers the inertial state which can be remapped to the relative Cartesian
state in the LVLH frame. The latter uses instead a direct transformation
from the initial ROE to the relative Cartesian frame, implying a higher de￾gree of linearization. Details on the two mappings can be found in previous
works [44]. Fig. 4.16 presents the position error dr accuracy obtained by a
nonlinear Cartesian relative dynamics model, when initialized with the
linear transformation (left plot) and the nonlinear one (right plot). The prop￾agation of the ROE with the given formulation is also presented for com￾parison. The position errors dr are computed with respect to the trajectory
propagated with the high-fidelity orbital simulator, over a time span of a
complete day. It is easy to appreciate the much higher drift rate of the
nonlinear Cartesian model exploiting the linearized initial condition, with
respect to the evolution using the nonlinear transformation. On the con￾trary, as highlighted also in other works [44], when dealing with a linearized
Figure 4.15 Propagation scheme for Cartesian and relative orbital elements.
Orbital dynamics 203dynamics, such as the CeW equations, in order to keep the consistency in
terms of nonlinear effects, the linearized transformation ensures a better rep￾resentation of the system. Nevertheless, this analysis also gave the hint on
the feasibility of exploiting the ROE with J2 perturbations for the design
of the relative trajectories, without introducing huge inaccuracies, as seen
by the plots in Fig. 4.16, where a maximum of w2 km error is introduced
over a one-day propagation arc.
References
[1] H. Curtis, Orbital Mechanics for Engineering Students, Elsevier, 2005.
[2] D.A. Vallado, Fundamentals of Astrodynamics and Applications, vol. 12, Springer Sci￾ence & Business Media, 2001.
[3] R.H. Battin, An Introduction to the Mathematics and Methods of Astrodynamics,
Aiaa, 1999.
[4] R.R. Bate, D.D. Mueller, J.E. White, W.W. Saylor, Fundamentals of Astrodynamics,
second ed., Dover Publications, New York, 2020.
[5] V.A. Chobotov, Orbital Mechanics, American Institute of Aeronautics and Astronau￾tics, 2002.
[6] J.E. Prussing, B.A. Conway, Orbital Mechanics, Oxford University Press, USA, 1993.
[7] K.B. Bhatnagar, L.M. Saha, N-body problem, Bulletin of the Astronomical Society of
India 21 (1993) 1e25.
[8] R.A. Howland, Intermediate Dynamics: A Linear Algebraic Approach, Springer Sci￾ence & Business Media, 2005.
[9] Y. Kozai, The motion of a close earth satellite, The Astronomical Journal 64 (1959)
367.
[10] J.H. Verner, Explicit RungeeKutta methods with estimates of the local truncation
error, SIAM Journal on Numerical Analysis 15 (4) (1978) 772e790.
[11] L.F. Shampine, M.K. Gordon, Computer Solution of Ordinary Differential Equations:
The Initial Value Problem, Freeman, San Francisco, 1975.
[12] J. Barrow-Green, Poincaré and the Three Body Problem, No. 11, American Mathe￾matical Soc., 1997.
Figure 4.16 Comparison of the position error of the (A) nonlinear Cartesian relative dy￾namics and (B) ROE formulation with respect to the high-fidelity simulator. The initial
conditions for the nonlinear model are generated using the linear transformation
(left) or the nonlinear derivation.
204 Andrea Capannolo et al.[13] V. Szebehely, Theory of Orbits: The Restricted Problem of Three Bodies, Academic
Press, New York and London, 1967.
[14] F. Ferrari, Non-keplerian models for mission analysis scenarios about solar system
bodies, Ph.D. Dissertation, 2016.
[15] K.C. Howell, Three-dimensional, periodic, ‘halo’ orbits, Celestial Mechanics 32 (1)
(1984) 53e71.
[16] M.W. Lo, Halo orbit generation using the center manifold, Advances in the Astronau￾tical Sciences 95 (part 1) (1997) 109e116.
[17] R. Broucke, Stability of periodic orbits in the elliptic, restricted three-body problem,
AIAA Journal 7 (6) (1969) 1003e1009.
[18] J.D. Hadjidemetriou, Resonant motion in the restricted three body problem, Celestial
Mechanics and Dynamical Astronomy 56 (1) (1993) 201e219.
[19] A.M. Legendre, Recherches sur l’attraction des sphéroïdes homogenes, De l’Imprim￾erie Royale, 1785.
[20] E.W. Hobson, The Theory of Spherical and Ellipsoidal Harmonics, Cambridge Uni￾versity Press, 1931.
[21] S.L. Belousov, Tables of Normalized Associated Legendre Polynomials, Mathematical
Tables Series, 2014.
[22] A. Konopliv, S. Asmar, B. Bills, et al., The dawn gravity investigation at vesta and ceres,
Space Science Reviews 163 (2011) 461e486, https://doi.org/10.1007/s11214-011-
9794-8.
[23] J.K. Miller, A.S. Konopliv, P.G. Antreasian, et al., Determination of shape, gravity, and
rotational state of asteroid 433 eros, Icarus 155 (1) (2002) 3e17, https://doi.org/
10.1006/icar.2001.6753.
[24] A. Pasquale, S. Silvestrini, A. Capannolo, et al., Non-uniform Gravity Filed Model on
Board Learning during Small Bodies Proximity Operations, International Astronautical
Congress, Washington D.C., USA, 2019.
[25] Y. Takahashi, D.J. Scheeres, Small body surface gravity fields via spherical harmonic
expansions, Celestial Mechanics and Dynamical Astronomy 119 (2) (2014) 169e206.
[26] W.D. MacMillan, The Theory of the Potential, 1958, pp. 6e60, https://doi.org/
10.1021/ed007p2530.
[27] P.T. Wittick, R.P. Russell, Mascon models for small body gravity fields, in: AAS/
AIAA Astrodynamics Specialist Conference, 2017.
[28] A. Colagrossi, F. Ferrari, M. Lavagna, et al., Dynamical evolution about asteroids with
high fidelity gravity field and perturbations modeling, Advances in the Astronautical
Sciences 156 (2015) 885e903.
[29] R.A. Werner, D.J. Scheeres, Exterior gravitation of a polyhedron derived and
compared with harmonic and mascon gravitation representations of asteroid 4769
castalia, Celestial Mechanics and Dynamical Astronomy 65 (1997) 313e344,
https://doi.org/10.1007/bf00053511.
[30] A. Colagrossi, F. Ferrari, M. Lavagna, et al., Coupled dynamics analysis around aster￾oids by means of accurate shape and perturbations modeling, in: Proceedings of the In￾ternational Astronautical Congress, IAC 2015, vol. 7, 2015, pp. 5360e5370.
[31] T.E. Carter, State transition matrices for terminal rendezvous studies: brief survey and
new example, Journal of Guidance, Control, and Dynamics 21 (1) (2008) 148e155,
https://doi.org/10.2514/2.4211.
[32] G. Inalhan, M. Tillerson, J.P. How, Relative dynamics and control of spacecraft for￾mations in eccentric orbits, Journal of Guidance, Control, and Dynamics 25 (1) (2002)
48e59, https://doi.org/10.2514/2.4874.
[33] K. Yamanaka, F. Ankersen, New state transition matrix for relative motion on an arbi￾trary elliptical orbit, Journal of Guidance, Control, and Dynamics 25 (1) (2002) 60e66,
https://doi.org/10.2514/2.4875.
Orbital dynamics 205[34] D. Wang, B. Wu, E.K. Poh, Satellite Formation Flying 87 (2017), https://doi.org/
10.1007/978-981-10-2383-5.
[35] S. D’Amico, Autonomous Formation Flying in Low Earth Orbit, 2010. http://www.
narcis.nl/publication/RecordID/oai:tudelft.nl:uuid:a10e2d63-399d-48e5-884b￾402e9a105c70.
[36] D.-W. Gim, K.T. Alfriend, State transition matrix of relative motion for the perturbed
noncircular reference orbit, Journal of Guidance, Control, and Dynamics 26 (6) (2003)
956e971, https://doi.org/10.2514/2.6924.
[37] A.W. Koenig, T. Guffanti, S. D’Amico, New state transition matrices for spacecraft
relative motion in perturbed orbits, Journal of Guidance, Control, and Dynamics 40
(7) (2017) 1749e1768, https://doi.org/10.2514/1.G002409.
[38] H. Schaub, S.R. Vadali, J.L. Junkins, K.T. Alfriend, Spacecraft formation flying control
using mean orbit elements, Journal of the Astronautical Sciences 48 (1) (2001) 69e87,
https://doi.org/10.1007/bf03546219.
[39] S. Silvestrini, M. Lavagna, Neural-aided GNC reconfiguration algorithm for distrib￾uted space system: development and PIL test, Advances in Space Research 67 (5)
(March 1, 2021) 1490e1505, https://doi.org/10.1016/j.asr.2020.12.014.
[40] J. Sullivan, S. Grimberg, S. D’Amico, Comprehensive survey and assessment of space￾craft relative motion dynamics models, Journal of Guidance, Control, and Dynamics
40 (8) (2017) 1837e1859, https://doi.org/10.2514/1.G002309.
[41] B.A. Newman, A.J. Sinclair, A. Lovell, A. Perez, Comparison of nonlinear analytical
solutions for relative orbital motion, in: AIAA/AAS Astrodynamics Specialist Confer￾ence, AIAA Paper 2014-4163, 2014, https://doi.org/10.2514/6.2014-4163.
[42] S.A. Schweighart, R.J. Sedwick, High-fidelity linearized J2 model for satellite forma￾tion flight, Journal of Guidance, Control, and Dynamics 25 (6) (2002) 1073e1080,
https://doi.org/10.2514/2.4986.
[43] R.A. Broucke, Solution of the elliptic rendezvous problem with the time as indepen￾dent variable, Journal of Guidance, Control, and Dynamics 26 (4) (2003) 615e621,
https://doi.org/10.2514/2.5089.
[44] G. Gaias, J.S. Ardaens, O. Montenbruck, Model of J2 perturbed satellite relative mo￾tion with time-varying differential drag, Celestial Mechanics and Dynamical Astron￾omy 123 (4) (2015) 411e433, https://doi.org/10.1007/s10569-015-9643-2.
[45] K. Alfriend, Nonlinear considerations in satellite formation flying, in: AIAA/AAS
Astrodynamics Specialist Conference and Exhibit, AIAA Paper 2002-4741, August
2002, https://doi.org/10.2514/6.2002-4741.
[46] A. Biria, R. Russell, A satellite relative motion model using J2 and J3 via vinti’s inter￾mediary, in: AIAA/AAS Space Flight Mechanics Conference, AAS Paper 16-537,
Napa, CA, 2016.
206 Andrea Capannolo et al.CHAPTER FIVE
Attitude dynamics
Aureliano Rivolta1
, Andrea Colagrossi2
, Vincenzo Pesce3
,
Stefano Silvestrini2
1
D-Orbit, Fino Mornasco, Italy
2
Politecnico di Milano, Milan, Italy
3
Airbus D&S Advanced Studies, Toulouse, France
Attitude dynamics describes the rotational motion of any object flying in
space. When considering the spacecraft dynamics, we have in mind first
the orbits and the motion of the spacecraft around the Earth or another ce￾lestial object. However, in addition to this, we shall also consider the rota￾tion of the spacecraft around its center of mass. Indeed, the spacecraft is an
object moving in a three-dimensional space with a total of six degrees of
freedom: three of them concerning the translational dynamics of the center
of mass (i.e., orbital dynamics) and other three for the rotational dynamics
about the center of mass (i.e., attitude dynamics).
Orbital and attitude dynamics are often studied as separate branches, since
in most applications, there exist a substantial decoupling between the space￾craft rotational and translational dynamics. In fact, the orbital motion has a
notably larger energy with respect to the attitude one, and the latter has a mi￾nor influence upon the spacecraft’s orbit. Moreover, in the case of unper￾turbed natural dynamics, the two dynamics are actually decoupled, as
assumed in the classical rigid body dynamics. It shall be noted that this is
strictly true only for a rigid body, but it is practically applicable also to space￾craft with some degrees of flexibility, as noted in the Chapter 3 e The Space
Environment. The orbit and attitude coupling is becoming consistent when
the environmental perturbations are accounted in the analyses, even if the
influence of the orbital dynamics on the attitude one is always more signif￾icant than the opposite. The effects of the attitude dynamics on the orbit
begin to be relevant only for modern and future applications, whenever
the spacecraft is very extended and flexible (i.e., large space structures, solar
sails, etc.), or when there is a weakly stable orbit (i.e., orbits in the three￾body problem (3BP) or irregular body environments).
This chapter discusses the fundamentals of spacecraft attitude dynamics
with the rigid body assumption, since the flexibility can be then accounted
Modern Spacecraft Guidance, Navigation, and Control
ISBN: 978-0-323-90916-7
https://doi.org/10.1016/B978-0-323-90916-7.00005-6
© 2023 Elsevier Inc.
All rights reserved. 207 jas described in the Chapter 3 e The Space Environment. The content of
this chapter is structured as follows:
• Attitude kinematics In this section, the most useful mathematical attitude
representations are presented, with particular focus on the Direction
Cosine Matrix (DCM), the Euler angles, the Euler axis and angle, and
the quaternions. The concept of angular velocity is introduced, together
with the fundamental kinematics rules for Euler angles and quaternions.
• Attitude dynamics This section introduces the fundamental concepts about
the rigid body rotational dynamics. It includes a discussion on the inertia
properties of the spacecraft, together with the derivation of the Euler
equations of motion. The torque-free attitude dynamics is also pre￾sented, being the basis for any further attitude dynamics model, with
some elements of attitude stability. Moreover, the motion of a spinning
spacecraft is discussed and the equations of motion of a spacecraft with
internal rotating elements are derived. Finally, this section describes the
attitude perturbation torques, specifying the effects of the space envi￾ronment on the rotational motion of a spacecraft.
The chapter is concluded with some brief sections on attitude dynamics
for modern applications:
• Attitude dynamics in three-body environments.
• Relative attitude dynamics.
• Multibody spacecraft dynamics.
The reader is invited to deepen the study of spacecraft attitude dynamics
in the dedicated books listed in the reference section [1e5].
Attitude kinematics
Attitude dynamics studies the evolution in time of the orientation of a
rigid body in space under the influence of applied torques. Hence, it allows
to investigate how and why the body rotates, and how fast the rotation is.
However, differently from translational motion that is represented by a set
of intuitive independent variables (i.e., cartesian or spherical coordinates),
rotations are associated to less immediate mathematical parametrizations
that are the core of attitude kinematics. Indeed, attitude dynamics is based
on the attitude kinematics, which describes the rotations of a body or a sys￾tem of bodies without considering the torques that cause them to move. It is
the analogous of translational kinematics, but the position vector, r, is
substituted by one attitude parametrization describing the body rotation,
and the velocity, v, is replaced by the angular velocity, u.
208 Aureliano Rivolta et al.The mathematical parametrizations of rotations can take different forms,
and the main ones will be discussed in this section, but they are all intrinsi￾cally associated to the same physical concept: the relative orientation of a
reference frame with respect to another one. Thus, the first step is recalling
the definition of reference frames from Chapter 2 e Reference Systems and
Planetary Models, considering that the most common spacecraft attitude
definition relates the satellite body coordinate system, b1b2b3; to an inertial
(or pseudoinertial) one, such as the geocentric equatorial reference frame,
IJK. In more mathematical terms, we can define a reference frame in a N
dimensional space as a set of N vectors that can be used to express any point
in that space. It is possible to perform transformations and rotations on such
frames to change the viewpoint from which we are analyzing the system.
Intuitively, whenever we look at the people sitting on a moving bus from
the roadside, we see them moving in one direction, while they see us mov￾ing in the opposite direction. The same event is thus described in two
different reference frames, and the same translation is described with oppo￾site signs because we have performed a 180 degrees rotation of two people
looking at each other. If we continue to follow the bus moving our head, we
are performing a further rotation between the two reference frames, since
we are changing the direction of our sight, and we are orienting our heads
differently from our body. In this case, the head orientation can be related to
the orientation of our body, and the time evolution of our line of sight can
be parametrized applying a rotation to the reference system based on our
body. We can generalize the concept and define attitude as the orientation
of a reference system with respect to another reference system. Without
reference systems, attitude loses meaning, and without attitude, two refer￾ence systems cannot share information.
We perceive reality as three-dimensional; hence, the most common
reference frames for satellites are taken as three-dimensional with N ¼ 3.
When we talk about spacecraft attitude, the reference systems are always
orthogonal, cartesian, and three-dimensional, although in some examples,
a two-dimensional system can be used for simplicity. This implies that we
are basing our discussion on the 3D rotation group, often denoted as
SO(3): the orthogonal group of dimension three. This is the group of all
the rotations about the origin of three-dimensional Euclidean spaces, under
the operation of composition of successive rotations. By definition, a rota￾tion about the origin is a transformation that preserves the origin, the
Euclidean distance, and the orthogonality.
Attitude dynamics 209Direction cosine matrix
The first and fundamental attitude parametrization we encounter in attitude
kinematics is the DCM, or attitude matrix, A. The DCM is the fundamental
representation of a rotation. In fact, the SO(3) group theory defines the ro￾tations as linear transformations, which can be represented by a matrix once a
basis of the three-dimensional Euclidean space is defined. Sticking with the
reference frames useful to satellite attitude dynamics, we will limit to orthog￾onal three-dimensional cartesian spaces. Hence the axes of a reference frame
are three unit vectors orthogonal to each other, defining an orthonormal ba￾sis. This directly implies that the DCM has some interesting properties:
• Orthogonal 3  3.
• Symmetric.
• Positive definite.
• Unitary determinant.
The DCMs are also known as “special orthogonal matrices,” explaining
the notation SO(3).
The DCM allows us to connect two distinct reference frames to manip￾ulate vectors expressed in different reference frames, and it is the basis to un￾derstand the attitude kinematics. Formally, the DCM contains the
projections of the axis of one target reference frame (i.e., the spacecraft
body frame) onto the axis of another reference frame (i.e., the inertial one):
A ¼
2
6
6
4
b1I b1J b1K
b2I b2J b2K
b3I b3J b3K
3
7
7
5;
where each row represents one axis of the target reference frame.
Note that a generic 3  3 matrix contains nine elements, since three
generic 3D vectors have nine independent components. However, if these
vectors are unitary, the number of independent components drops to six.
Then, if we state that those vectors are mutually perpendicular, with null
projection, we add three constraints that drop the independent components
to only three. Since the basis of a reference frame is orthonormal, the DCM
belongs to this special condition, and only three components are indepen￾dent and necessary to fully express a DCM.
Given a generic vector in the inertial reference frame, vIJK, we have
three projections along each unit vector IJK; and we can express the vector
through those projections. The common values that we give vectors are
210 Aureliano Rivolta et al.simply the projections along the reference axes, and they become the way
we represent and understand such vectors. A generic vector rotation from
the reference IJK into reference b1b2b3 is expressed as:
vb ¼ bAIJK vIJK;
where vb is the vector expressed in the spacecraft body frame b1b2b3.
Any rotation can be reversed easily and without additional computations.
Formally we can write the rotation of the vector vb from the reference
b1b2b3 to reference frame IJK through the inverse of the DCM. In fact,
mathematically speaking, we should left-multiply by the inverse to obtain
the inverse relation. However, due to the orthonormality property, the
DCM inverse is equal to the transpose of the DCM.
vIJK ¼ IJKAb vb ¼ bA1
IJK vb ¼ bAT
IJKvb
Knowing the DCM allows us to know both direct and inverse
transformations.
Note that the previous discussion can be generalized to any rotation be￾tween two generic reference frames. Moreover, we can simplify the nota￾tion for the following discussion with:
A ¼ bAIJK
AT ¼ A1 ¼ IJKAb;
reminding that AAT ¼ I3, where I3 is the 3  3 identity matrix.
The composition of successive rotations can be defined with the multi￾plication of the associated DCMs, resulting in another DCM. In fact,
composing two rotations results again in a rotation, and the overall DCM
is the product of the two individual successive rotations, taken in the
reversed order compared to the sequence of rotations.
For example, assuming that we want to define a successive rotation from
the body frame to a frame aligned with the spacecraft’s payload, b0
1b0
2b0
3 as:
vb0 ¼ A0
vb;
where vb0 is a vector expressed in the payload reference frame. Then, the
rotation of a vector from the inertial frame, IJK, to the payload frame
becomes:
vb0 ¼ A0 vb ¼ A0

A vIJK
¼ A0
A vIJK ¼ A00vIJK;
Attitude dynamics 211with A00 ¼ A0
A, since the vector is first rotated in b1b2b3 and then in b0
1b0
2b0
3,
but the matrix multiplication is taken in reversed order.
It shall be remarked that any attitude matrix shall preserve the properties
of a DCM. Hence, after any numerical manipulation on these matrices, it is
suggested to check if the DCM properties are still valid. If this is not the case,
proper mathematical correction shall be applied to remove numerical errors
and enforce the DCM properties. For example, the orthonormalization of
the resulting DCM may be needed after few mathematical operations are
executed on the attitude matrix.
The time evolution of the DCM is directly the time evolution of the
spacecraft attitude. In fact, when the attitude matrix is known at different
instants of time, it is possible to understand how the spacecraft body frame
is rotating with respect to the inertial reference frame. Furthermore,
composing other successive rotations, it is possible to know the rotations
of any satellite-based reference frame with respect to another generic base
reference frame.
Direction cosine matrices are the fundamental attitude representation pa￾rameters, and they are necessary to rotate a vector from a reference frame to a
different one. However, they have nine components and few mathematical
constraints making them not very suitable for guidance, navigation, and
control (GNC) applications. In fact, functions used in attitude GNC usually
employ a representation of the attitude having fewer parameters and fewer
constraints than the attitude matrix. The next paragraphs describe the main
and most used attitude parametrization methods:
• Euler angles.
• Euler axis and angle.
• Quaternions.
Euler angles
The description of the spacecraft attitude in a reference frame requires only
three independent components. This leads to one of the simplest and most
intuitive way to address attitude parametrization: a sequence of three rota￾tions around three nonconsecutive axes. Indeed, it is always possible to
make two orthogonal frames overlap by appropriate rotation of one of
them three times around its reference axes. Each of these successive rotations
is identified by an axis (commonly x, y, and z) and an angle. The set of the
three rotation angles is commonly referred to as Euler angles. The sequence
of rotations is important, and we can identify 12 different sets of three rota￾tions to express the DCM:
212 Aureliano Rivolta et al.• Proper Euler angles: z-x-z, x-y-x, y-z-y, z-y-z, x-z-x, y-x-y.
• TaiteBryan, Cardan, or yaw-pitch-roll angles: x-y-z, y-z-x, z-x-y, x-z￾y, z-y-x, y-x-z.
Euler angles are by far the most intuitive means of representing the atti￾tude of a satellite, and they have a clear physical meaning. However, they
suffer from computational issues.
Let us take a simple object like a six-faced dice. We try to understand the
principle of Euler angles using three 90 degrees positive rotations. We define
the x axis to be the normal to face 1, the y axis of face 3, and z axis of face 2,
as illustrated in Fig. 5.1. The first rotation is performed around the x axis,
now we have face 3 instead of face 2, and face 5 instead of face 3. Let the
second rotation be around face 3 (i.e., y axis). Now we have face 1 onto
original face 3 position, and face 2 where it was face 1. Last, a rotation is per￾formed around face 2 (i.e., z axis), and we find face 4 where it was face 3 at
the beginning, face 1 where it was face 2, and face 2 on top where face 1 was.
The associated sequence of rotations is x-y-z, and the way in which these
rotations have been defined is the intrinsic one. Intrinsic rotations are
defined around the axes of the rotating coordinate system xyz, fixed with
the moving body, which changes its orientation after each elemental
rotation.
The DCM that relates the final configuration with respect to the first is:
A ¼
2
6
6
4
00 1
0 1 0
10 0
3
7
7
5.
The procedure of generating the DCM starting from the Euler angles
can be seen as a matrix chain multiplication of successive elemental rotations.
Figure 5.1 Euler angles intrinsic rotations on a six-faced dice.
Attitude dynamics 213Thus, they are taken in reverse order than executed: the first rotation is on
the right and the last is on the left side, since successive rotations accumulate
on the left side. Taking wx; wy; and wz, the Euler angles triplet for x-y-z
rotation, and recalling the elemental matrix for simple rotations discussed
in Chapter 2e Reference Systems and Planetary Models, we get:
A ¼
2
6
6
4
cos wz sin wz 0
sin wz cos wz 0
0 01
3
7
7
5
2
6
6
4
cos wy 0 sin wy
0 10
sin wy 0 cos wy
3
7
7
5

2
6
6
4
10 0
0 cos wx sin wx
0 sin wx cos wx
3
7
7
5
A ¼
2
6
6
4
cos wy cos wz cos wx sin wz þ sin wx sin wy cos wz sin wx sin wz  cos wx sin wy cos wz
cos wy sin wz cos wx cos wz  sin wx sin wy sin wz sin wx cos wz þ coswx sin wy sin wz
sin wy sin wx cos wy cos wx cos wy
3
7
7
5
It shall be noted that the rotation matrix around the second axis, y, has
opposed sign with respect to the other two rotations since it is performed
aligning the z axis on the x axis. This results in a shift in the signs of the ma￾trix elements, as the reader might want to easily verify by deriving the three
intermediate reference frame rotations.
Extrinsic rotations (i.e., rotations about the axes xyz of the original co￾ordinate system, which is assumed to remain inertially fixed) follow the same
rules and mathematical formulations of the intrinsic ones. The only differ￾ence is the way in which the elemental rotations are named and associated
to an axis. Moreover, any extrinsic rotation is equivalent to an intrinsic rota￾tion by the same angles but with inverted order of elemental rotations and
vice versa (e.g., with reference to Fig. 5.1, the equivalent extrinsic rotations
would have been z-y-x).
The determination of the Euler angles from the DCM is mathematically
cumbersome, as one would need to take care of inverse trigonometry and
multiple solutions. Moreover, the inverse transformation is not always
possible since a singularity condition exists, and it is usually denoted as gimbal
lock condition [1]. The different sets of Euler angles are singular for different
values of the second rotation angle, w2, depending on the fact that the in￾dexes are all different (i.e., TaiteBryan angles), or the first and third indexes
214 Aureliano Rivolta et al.coincide (i.e., proper Euler angles). In the TaiteBryan angles, the singularity
condition is w2 ¼ ð2n þ1Þ p=2, while for the proper Euler angles, the sin￾gularity occurs when w2 ¼ n p. Therefore, Euler angles could be easily
used in GNC functions if the spacecraft dynamics were always bounded
with rotations far from the singularity conditions. However, since the space￾craft motion is generally not bounded, the attitude kinematics should be able
to switch between a proper Euler angles sequence and a TaiteBryan angles
sequence in order to avoid the singularity conditions on w2.
From these remarks, it is evident that Euler angles have a clear physical
meaning, and they are a minimal attitude parametrization having only three
independent components. They are very convenient for visualization pur￾poses, but they are numerically time-consuming and have singularities not
suitable for GNC applications. Moreover, the rule of consecutive rotations,
although existing, is hard to be implemented due to its complexity.
Euler axis and angle
With reference to Fig. 5.1, we can further notice that the same result (i.e., 1
and 2 switch places and 3 goes to the opposite side) could have been ob￾tained with a 180 degrees rotation about an axis perfectly aligned with
the bisector plane between face 1 and 2 and parallel to face 3. This result
is quite general since any number of consecutive rotations around any axis
can be expressed in terms of a single rotation around a single axis. The
axis and the angle take the name of Euler axis and Euler angle. The naming
is not casual, as this is often referred to as Euler’s theorem.
From matrix algebra, it is known that real, orthogonal matrices have one
unit eigenvalue, to which we associate the eigenvector e:
Ae ¼ 1e
Therefore, vector e does not change due to the rotation represented by
matrix A. This is possible only if the rotation occurs around axis e, which is
the Euler axis. The rotation amplitude around this axis is called Euler angle,
f.
The number of components to represent the spacecraft attitude using the
Euler axis and angle is four, and thus this is not a minimal attitude represen￾tation. Indeed, one component is not independent given the unit norm of
the Euler axis.
The DCM can thus be expressed in terms of the Euler axis e ¼
f e1 e2 e3 gT and Euler angle f as follows:
Attitude dynamics 215A ¼ I3 cos f 
2
6
6
4
0 e3 e2
e3 0 e1
e2 e1 0
3
7
7
5
sin f
þ ð1  cos fÞ
2
6
6
4
e
2
1 e1e2 e1e3
e1e2 e
2
2 e2e3
e1e3 e2e3 e
2
3
3
7
5.
The inverse operation is also possible, given the rotation matrix A eval￾uate Euler axis and angle as:
f ¼ cos1

1
2
ðtrðAÞ  1Þ

2
6
6
6
6
6
6
6
6
4
e1 ¼ A23  A32
2 sinðfÞ
e2 ¼ A31  A13
2 sinðfÞ
e3 ¼ A12  A21
2 sinðfÞ
3
7
7
7
7
7
7
7
7
5
where Aij is the component of the A matrix at the i-th row and j-th column.
It is remarked that the direct transformation, from Euler axis and angle to
the attitude matrix, is always possible, while the inverse transformation is not
always defined. The Euler axis is not defined when sinðfÞ ¼ 0; which cor￾responds to n  180 degrees rotations. In fact, there might be two 180 de￾grees rotations around different axes with the same effect, resulting in the
singularity condition for the Euler axis and angle representation.
It is also remarked that the inverse trigonometric function cos1 returns
two possible values of the Euler angle (i.e.,  f), which consequently pro￾vide two different axes (i.e.,  e). Note that this is actually different from
the singularity condition, since we are always looking at the same axis,
once from the positive and once from the negative direction, and to each
condition we associate the same rotation angle with opposite sign. This is
physically the same condition.
Furthermore, the reader can verify that this form respects the periodicity
of the angle, as any addition of 360 degrees would give the same result. This
implies that given an axis, there are infinite angles possible, and thus when
216 Aureliano Rivolta et al.inverting the operation, one must set some limits like (0 degrees, 360 de￾grees) or (180 degrees, þ180 degrees).
Any rotation composed by a generic number of elemental rotations is al￾ways referred to a Euler axis and angle. This is the building block of attitude
kinematics, since if we “sum” several rotations, we end up with a final axis
and angle representing the whole chain. However, this can be done only a￾posteriori given the final and initial conditions, since there is no easy way to
determine the accumulation process for the sequence of rotations.
Quaternions
Since it is not straightforward to accumulate successive rotations using only
Euler axis and angle parametrization (i.e., without passing from the DCM),
and because the existence of the singularity condition, a closely related ob￾ject comes into play: unitary quaternions.
Quaternions have been introduced by William Rowan Hamilton in
1843 and are a mathematical tool that extend the complex algebra into
three-dimensions, whose rule of multiplication happens to have a great
connection with SO(3). Thus, they are powerful to represent rotations
and to develop attitude kinematics for GNC applications. In fact, it has
been found that unitary quaternions, q; can be used to represent rotations
and can be quite effective and efficient. It is possible to link a unitary quater￾nion with the Euler angle and Euler axis with the following formula:
q ¼
( q1:3
q4
)
¼
8
>>>>><
>>>>>:
q1
q2
q3
q4
9
>>>>>=
>>>>>;
¼
8
>><
>>:
e sin
w
2
cos
w
2
9
>>=
>>;
where we have used the convention that puts the scalar quaternion
component, q4, in the fourth position, which is more comfortable when
dealing with rotations. Mathematically, the scalar quaternion component is
the real part of the quaternion and would be usually placed first, also ac￾cording to the quaternion definition made by Hamilton with the scalar
component at the beginning of the vector. Note that in this case, the scalar
component is usually denoted as q0:
It is worth noticing here that, depending on the textbook or the appli￾cation, the quaternion definition may vary. Unfortunately, the derived for￾mulas and the associated mathematical operations are different according to
Attitude dynamics 217the used convention. Thus, we shall be very careful in understanding which
quaternion convention shall be used in agreement with the formulas that are
in use. A mistake in the selection of the proper quaternion convention to use
(i.e., scalar first or scalar last) will induce computation errors leading to
wrong GNC execution. The scalar last convention used in this book derives
from the heritage of classical spacecraft attitude references, and it is very
frequent in spacecraft GNC applications. This is not true for many different
applications, and some computing libraries dealing with quaternion algebra
use the quaternion first convention. The reader is strongly encouraged to al￾ways verify and spend time on the quaternion convention that is in use
before using any third-party function or library.
The unitary condition that allows quaternions to represent attitude is:
q2 ¼ qT
1:3q1:3 þ q
2
4 ¼ 1 ¼ q
2
1 þ q
2
2 þ q
2
3 þ q
2
4 ¼ eT e

sin
w
2
2
þ

cos
w
2
2
The number of components to represent the spacecraft attitude using
quaternions is four, and thus also this parametrization is not a minimal atti￾tude representation. Only three quaternion components are associated to
the independent rotation parameters, and they can be used to perform the
calculations. The fourth component can be always obtained imposing the
unit norm quaternion constraint.
Through the quaternion definition, it is possible to obtain the relation
with the DCM as follows:
A ¼
2
6
6
4
1  2

q
2
2 þ q
2
3
 2ðq1q2 þ q3q4Þ 2ðq1q3  q2q4Þ
2ðq1q2  q3q4Þ 1  2

q
2
1 þ q
2
3
 2ðq2q3 þ q1q4Þ
2ðq1q3 þ q2q4Þ 2ðq2q3  q1q4Þ 1  2

q
2
1 þ q
2
2

3
7
5
To recover the quaternions from the DCM, there are few possibilities
like passing from the Euler axis or using directly the components of the
DCM. In the latter case, one should be aware that it needs to consider cases
where one or more components of the quaternion are null or close to zero.
However, quaternions have no singular condition, since if a component
vanishes, it is always possible to compute the inverse relations by exploiting
different DCM components, which will be different from zero due to the
normalization constraint. For example, if q4 is different from zero, we
may write:
218 Aureliano Rivolta et al.2
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
4
q1 ¼ A23  A32
4q4
q2 ¼ A31  A13
4q4
q3 ¼ A12  A21
4q4
q4 ¼ 
1
2
ð1 þ A11 þ A22 þ A33Þ
1
2
3
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
5
The inverse relations for the other components obtained from the main
diagonal of A can be found in many literature references [1,4]. In order to
minimize the numerical errors in the GNC functions, we may select the one
with the maximum value associated to the term with the sign ambiguity
(i.e., ).
Note that the sign ambiguity has the same explanation given for the
Euler axis and angle case. We are always looking at the same axis, once
from the positive and once from the negative direction, and to each condi￾tion, we associate the same rotation angle with opposite sign. Thus, a change
in sign of the quaternion is transparent for the physical attitude representa￾tion: þq and q represent the same orientation in space. To avoid numer￾ical problems and feedback control issues (e.g., unwinding phenomena), it is
suggested to always enforce numerical continuity in the quaternion values.
Namely, if the GNC functions would set to output an abrupt sign change in
the quaternions, it is always better to manually change the sign of the new
quaternion values to preserve the continuity with the previous ones.
Successive rotations
The most useful property of unitary quaternions applied to rotations is a
multiplication rule that allows to obtain another quaternion representing
the overall rotation resulting from two consecutive elemental rotations.
The quaternion group is closed with respect to this multiplication meaning
that multiplying two unitary quaternions leads to another unitary quater￾nion. As usual, the multiplicative formula to express a sequence of two
consecutive rotations combines the quaternion components in the reversed
order of rotations. Given a first rotation represented by quaternion q, a sec￾ond rotation represented by quaternion q0
, the overall rotation is repre￾sented by quaternion q00 given by:
Attitude dynamics 219q00 ¼ q0  q ¼
 " 

q0
1:3
	 q0
1:3
q0 T
1:3 0
#
þ I4q
0
4
!
q
¼
2
6
6
6
6
4
q0
4 q0
3 q0
2 q0
1
q
0
3 q0
4 q
0
1 q
0
2
q0
2 q0
1 q0
4 q0
3
q0
1 q0
2 q0
3 q0
4
3
7
7
5
q
where 
q0
1:3
	
is the cross-product matrix containing the components of the
vector part of the quaternion, I4 is the 4  4 identity matrix, and it has been
used in the matrix form of the quaternion multiplication operation.
As one would expect, it is possible to chain any number of rotations in
the same way we chained DCM for successive rotations. The operation can
be easily inverted using the inverse operation that takes the form of a slightly
different matrix [1]. It should be noted that we can always express the inverse
rotation using the conjugate of the quaternion, where only the vector part,
q1:3, is changed in sign: this is the easiest way to invert a quaternion rotation.
Another interesting aspect that can be exploited is that there exists another
matrix form where the two original quaternions, q and q0
, can be swapped
without changing the results [1].
Relative quaternion
Quaternion multiplication allows to define the relative quaternion between
two different attitude states represented by two quaternions. This operation
is very useful to define relative attitude states and to define the error quater￾nion with respect to a reference state. The latter is very useful in attitude esti￾mation and control to define an error difference relative to a desired attitude
state.
The relative quaternion can be defined as:
dq ¼
( d q1:3
d q4
)
¼ q  q1
ref ¼
8
<
:
c


qref 
q
qT
ref q
)
;
where c


qref 
is a 3  4 matrix defined as:
c


qref 
¼ 
I3 qref4 
h
qref1:3
i
qref1:3
	
:
220 Aureliano Rivolta et al.If d q is normalized and it is close to the identity quaternion, then
d q1:3za

2 and d q4z1, where a is a vector of small angle rotations. As
q approaches qref , then d q1:3 and a both approach zero.
It shall be remarked that the quaternions are not the unique mathemat￾ical parametrization that can connect with Euler axis and angle. Some alter￾natives like the Gibbs and Rodrigues vectors exist [1,4], However, the
quaternions have a larger number of advantages with respect to the other
attitude parametrizations and to the drawbacks. For this reason, they are
widely used in GNC applications, and they are the go-to formulation in
most space engineering references.
Few important aspects of quaternions made them appealing for the GNC
community: absence of trigonometric functions for most applications,
absence of singularity in critical areas, possibility to easily chain successive ro￾tations, easy normalization, and continuity numerical verification. Essen￾tially, quaternions are more computationally friendly than other attitude
parametrizations. Their main drawback is related to their poor physical
meaning, and, therefore, their use is not intuitive. However, this is a prob￾lem for the human user and not for the GNC system. Typically, a simple
conversion from quaternions to Euler angles solves this problem and allows
to visualize and understand the spacecraft attitude.
Further details about quaternion algebra can be found in the appendix
Chapter 16eMathematical and Geometrical Rules. Moreover, the reader
is invited to deepen study about quaternion properties and rules in Ref. [1].
Attitude variation in time
Previous sections discussed the way in which the orientation of a spacecraft
in space is represented and mathematically parametrized. Now it is time to
address how attitude changes in time, introducing the concept of the angular
velocity or angular rate vector.
Intuitively, we can think about the angular velocity by considering a disk
rotating around its normal axis. We know that the variation in time of the
angle that describes the system is equal to the velocity of rotation. In general,
the angular velocity is represented by a vector that is characterized by a di￾rection and an intensity. In the disk case, we have that the angular velocity
can assume one orientation in space and infinite positive or negative inten￾sities. Conventionally, the positive direction is taken counterclockwise, and
if one uses the right-hand rule, we can easily see that taking the vector orien￾tation as the thumb leaves the fingers pointing in the rotation direction. If
Attitude dynamics 221another disk is mounted on the first one with a different axis of rotation,
then the velocity of any points of its surface requires the knowledge of
the velocity of the first disk. If we chain three disks with perpendicular
axes, we obtain what is often referred to as a mechanical gyroscope, figured
in Fig. 5.2, and the overall velocity vector shall be described in three dimen￾sions, given the fact that now infinite orientations in space are possible.
More formally, the attitude variation in time can be described consid￾ering the time variation of the fundamental attitude representation:
A_ ðtÞ ¼ lim
Dt/0
Aðt þ DtÞ  AðtÞ
Dt ¼ lim
Dt/0

h
Dbqb
IJK
i
Dt
AðtÞ;
where we remind that A ¼ bAIJK describes the rotation from the inertial
frame to the spacecraft body one, and Dbqb
IJK is a small angle rotation vector
that is contained inside the cross-product matrix. The rotation is performed
in the interval of time Dt. Note that the subscripts b and IJK mean that the
small angle rotation is related to the rotation from frame IJK to frame b, and
the superscript b means that the rotation angle is represented in body frame b.
Figure 5.2 Gyroscope.
222 Aureliano Rivolta et al.The rotation angle is small since the time variation is computed in the limit
that Dt goes to 0; it is expressed in b because the difference Aðt þDtÞ AðtÞ
can be represented by a differential rotation from frame b at time t to frame b
at time t þ Dt, and these two frames coincide for Dt going to 0. Moreover,
the previous kinematic relation does not distinguish between the situations
where frame IJK or frame b or both frames are rotating in an absolute sense;
it only cares about the relative rotation between the two frames.
Angular velocity
At this point, we can define the angular velocity vector:
b
ub
IJKðtÞh lim
Dt/0
Dbqb
IJK
Dt ;
noting that the angular rate is related to the rotation from a reference
frame to another one, and it is always expressed in one reference frame.
In this case, the angular velocity describes the time variation of the rotation
from frame IJK to frame b, and it is mathematically expressed with the vector
components in the frame b. It shall be noted that the physical quantity does
not depend on the frame in which it is expressed. Indeed, the angular veloc￾ity vector represents a physical vector in space relating instantaneous succes￾sive rotations of a reference frame with respect to another, but it can be
expressed in whichever reference frame. For example, we can mathemati￾cally express the previous angular velocity vector in the inertial frame as:
b
uIJK
IJK ¼ IJKAbb
ub
IJK:
The relation between the two vectors is given by the DCM whose vari￾ation in time is a function of the angular velocity itself. The fact that the
magnitude of the angular velocity does not change when looking at it
from the two frames is intrinsic in the orthonormality property of the
DCM. De facto, the norm of the angular velocity between two frames is
a scalar and thus invariant between two frames.
In order to simplify the discussion, we will omit the subscripts, unless it is
necessary to specify the reference frames involved in the attitude kinematics.
In general, we will consider the rotation from frame IJK to frame b as the
nominal direct rotation (i.e., the rotation of the spacecraft body frame
with respect to the inertial one: A ¼ bAIJK). Therefore, we can rewrite
the previous expression as:
uIJK ¼ ATub
.
Attitude dynamics 223The fundamental kinematics relation can be written in terms of the
angular velocity as:
A_ ðtÞ ¼ lim
Dt/0

h
Dbqb
IJK
i
Dt
AðtÞ¼
ub
ðtÞ
	
AðtÞ.
With some algebraic manipulations, we can also use the angular velocity
expressed in inertial frame as:
A_ ðtÞ¼  
ub
ðtÞ
	
AðtÞ¼AðtÞ

uIJKðtÞ
	
:
Moreover, we can derive the kinematics for the inverse rotation from the
frame b to frame IJK, by taking the transpose of the fundamental kinematics
relation and remembering that the cross-product matrix is skew symmetric:
A_ TðÞ¼ t ATð Þt

ub
ð Þt 
	
5A_ bIJK ¼ AbIJKð Þt
h
ub
IJKb tð Þ
i
The frame labels are always arbitrary, so we can exchange the labels IJK
and b in this expression to get:
A_ IJKb ¼ AIJKb
ð Þt
h
uIJK
b IJK tð Þ
i
5A_ ðÞ¼ t Að Þt
h
uIJK
b IJK tð Þ
i
:
Hence, comparing this expression with the fundamental kinematics
equation in inertial frame, we can see that:
b
uIJK
IJK ¼  IJKuIJK
b ;
where we found the obvious result that the rotational rate of frame IJK with
respect to frame b is the negative of the rate of frame b with respect to frame
IJK. Although we derived this as a relationship of the components in frame
IJK, the properties of orthogonal transformations show that it must be true
for the components in any frame:
bub
IJK ¼  IJKub
b.
Angular velocities can be summed, and they have all the common vector
properties. However, we must take care of the reference frame in which the
addition operation is performed. To make an example, let’s take three refer￾ence frames, p, q, and r, which are in relative motion with angular velocities
r
uq and
q
up. We can compute the overall angular velocity between r and p,
expressed in the final reference frame, r, as:
r
ur
p ¼ r
ur
q þ r
Aq


q
uq
p

¼ r
ur
q þ
q
ur
p;
224 Aureliano Rivolta et al.The central side of this equation is more useful in applications, since we
usually have the angular rates measured in different reference frames. But the
right-hand side shows that the angular velocity of the motion of frame r rela￾tive to frame p is just the vector sum of angular velocity of the motion of r
relative to q, and the angular velocity of the motion of q relative to p, pro￾vided that they are expressed in the same reference frame. In this case, they
are all expressed in r; but the result is valid in any existing reference frame.
Euler angles kinematics
Specializing the attitude kinematics for different attitude parametrizations,
we can see how the angular velocity relates to Euler angles and quaternions.
Looking again at the mechanical gyroscope in Fig. 5.2, it is possible to see
that the way the disks are mounted closely resembles the three rotations
of the Euler angles triplets. The variation in time of the Euler angles can
be related to the angular velocity of the body by differentiation of the Euler
angles relations, obtaining the following expression for the x-y-z sequence:
ub ¼
8
>><
>>:
u1
u2
u3
9
>>=
>>;
¼
2
6
6
4
cos wy cos wz sin wz 0
cos wy sin wz cos wz 0
sin wy 0 1
3
7
7
5
8
>>>>><
>>>>>:
w_ x
w_ y
w_ z
9
>>>>>=
>>>>>;
Inverting the relation gives:
8
>>>>><
>>>>>:
w_ x
w_ y
w_ z
9
>>>>>=
>>>>>;
¼ 1
cos wy
2
6
6
4
cos wz sin wz 0
cos wy sin wz cos wy cos wz 0
sin wy cos wz sin wy sin wz cos wy
3
7
7
5
ub
Such relation is nonlinear and suffers from a singularity. When wy ¼ 
90 degrees, we have that the derivative is infinite and any hope to relate the
two velocities is lost. This condition is related with the gimbal lock phenom￾enon, which is also present in mechanical gyroscopes: when this occurs, the
two Euler angles wx and wz insist on the same axis and the DCM becomes a
rotation matrix around axis y function of an angle wx þ wz.
For all these reasons, Euler angles are not convenient for spacecraft GNC
application, and they should be used only for visualization purposes. In fact,
if we want to use Euler angles for computation, we must bear in mind that
Attitude dynamics 225every Euler angle sequence has a singularity. Euler angles are popular in
aircraft GNC applications, since the singularity problem might be overcome
by the fact that the envelope of possible rotations for an airplane is usually
limited; this is not true for satellites that usually span the whole rotation
space.
Quaternions kinematics
Quaternion offers a simpler and singularity-free relation between quaternion
derivative and angular velocity of the reference frame:
q_ ¼ 1
2
"


ub

	 ub
ubT 0
#
q
The only issue in using this formulation to integrate the attitude evolu￾tion in time is that the operation of numerical integration does not enforce
the unitarity of the quaternion. Then, at each numerical integration step, the
quaternion normalization shall be enforced. This is mathematically trivial
and simpler than in the case of DCM. In fact, the direct integration of the
DCM derivative does not preserve the DCM properties, and orthonormality
must be enforced at each integration step. For this and all the other reasons
discussed in this section, quaternions are commonly preferred for computa￾tion in any GNC system.
It is often more convenient to integrate the quaternion kinematics in a
different form:
q_ ¼ 1
2
"
I3q4 þ ½q1:3
qT
1:3
#
ub
;
which can also be easily inverted to obtain the angular velocity as a func￾tion of the derivative of the quaternion:
ub ¼ 2 kqk2 ½I3q4  ½q1:3 q1:3 q_ ;
where the norm of the quaternion is unitary, kqk ¼ 1. Thus, it is over￾abundant in the previous equations and cab be omitted.
It should be noted that the previous equations link the derivative of the
quaternion with respect to the angular velocity described in one of
the two frames (i.e., the body frame). It is entirely possible to rewrite the
formula in terms of the angular velocity expressed in the other reference
frame [1]. Then, it is an arbitrary choice the linking of the quaternion to
that angular velocity in that way and, in general, the convention used to
226 Aureliano Rivolta et al.link a quaternion and the angular velocity must be consistent and
specified, as few variants are possible. More details are available in the appen￾dix Chapter 16 e Mathematical and Geometrical Rules, and in the sug￾gested references [1].
In this book, the notation q is associated to the DCM, A. Hence, this
quaternion represents the rotation of the spacecraft body frame with respect
to the inertial one (i.e., the rotation from IJK to b). However, the reader is
invited to note that this is the not unique possibility, and other assumptions
must be always declared.
Attitude dynamics
We now focus the discussion on attitude dynamics, first defining the
inertia parameters influencing the attitude equations of motion and then
deriving them from the fundamental mechanical quantity in rotational dy￾namics: the angular momentum. The section also contains some discussion
on attitude stability and attitude dynamics in spinning conditions. Finally,
the contributions of environmental torques in the attitude dynamics is math￾ematically discussed.
Inertia matrix
When we study the motion of a rigid body, we typically define one funda￾mental physical property that is called mass and it is usually sufficient to
describe the inertia of the body along its linear motion. When we talk about
rigid body rotations, this is no longer enough, as a rigid body is never a point
mass, but a continuous distribution of mass. Different mass distributions give
different inertia properties to objects, and they have impact in the way they
are moving in space.
Let us assume a scalar function rðrÞ that denotes the density of the rigid
body, and it is solely a function of the spatial coordinate r of a reference
frame attached to the body. For now, let us assume that this function is
continuous and can characterize the whole body. Later, we will extend
the concept in a simpler engineering way.
Given the density function, we can determine the system mass using an
integral over the volume V of the object.
m ¼
Z
V
rðrÞdV
Attitude dynamics 227Now we can determine the first ðcÞ and second ðIÞ moment of inertia as
follows:
c ¼
Z
V
r rðrÞdV
I ¼
Z
V

r
2
I3  r 5 r

rðrÞdV
where the symbol 5 represents the tensor product, or outer product, be￾tween two vectors. The second moment of inertia is the most important for
attitude dynamics, and it is usually referred to as inertia tensor or inertia matrix.
The inertia tensor is a 3  3 symmetric matrix. The terms along the di￾agonal are called inertia moments or moments of inertia, while the off-diagonal
terms are called inertia products. Inertia moments are always positive, while
there is no general rule for the inertia products. The reader should consider
that the term moment of inertia can be used in other engineering fields with
slightly different meanings, often referring to the component of the inertia
tensor about the rotation axis in use, or to the largest inertia tensor
component.
The inertia tensor has been constructed from the origin of a reference
frame along its axes. This inherently means that differently oriented frames
or with different origins would give different results; thus, we must specify
the origin and the reference axes used to compute the inertia matrix. To
convert the inertia tensor from a reference frame to a different one, we could
substitute the rototranslation transformations, needed to relate two generic
reference frames, and obtain a complex formula. However, there are
some engineering tricks that simplify the problem and can be rather easy
to be applied. For these engineering solutions, we assume that the density
of the rigid body is constant rðrÞ ¼ r.
The first trick is the change in orientation of the reference frame to
compute the inertia matrix. If we pre- and post-multiply the inertia tensor
by a DCM and its transpose, we can express the body moment of inertia in
any reference frame with the same origin:
I2 ¼ 2A1 I1 2AT
1 ¼ 2A1 I1 1A2
The second is the translation of the origin making use of the parallel axis
theorem, which is sometimes referred to with the names of Huygens and
228 Aureliano Rivolta et al.Steiner. With this theorem, we can translate the moment of inertia from one
reference to a parallel one by using the origin’s displacement vector r12:
I2 ¼ I1 þ m

kr12k2
I3  r12 5 r12
¼ I1 þ m

kr12k2
I3  r12r
T
12
.
The reader might be more familiar with the moment of inertia transport
around a single axis. Assuming a translation orthogonal to z with displace￾ment d ¼ 
dx dy
T , the parallel axis theorem reads:
Iz2 ¼ Iz1 þ m d2 ¼ Iz1 þ m


d2
x þ d2
y

Now we have all the tools needed to address the inertia matrix in any
reference frame; however, depending on the situation, there are some refer￾ence frames that are more useful than others.
Looking at the definition of the first moment of inertia, we can clearly
see that there is a specific origin of the reference frame where the first
moment of inertia is null. This represents the rotational center of the
body, and if we leave the body spinning in an empty space, this point will
be the only point not changing position in time. This is the Center of Mass
(CoM) of the body. Under a different perspective, we can also state that
such a point minimizes the inertia of the system and would take less effort
to spin the body if it rotates around that point.
Defining the body reference frame’s origin in the CoM of the spacecraft
is common practice when dealing with satellites, as we will see later; but this
is not the only choice we can make for the body reference frame. Recalling
the property of rotation of the inertia tensor, we have seen that we can rotate
the reference frames in any direction; this means that we can also find a
particular orientation for which the inertia matrix is diagonal. This is true
because the inertia matrix is symmetric and positive definite, so we can al￾ways find an orientation that exposes its eigenvalues along the main diago￾nal. Thus, we can solve a standard eigenvalue problem for the matrix I,
finding a rotation matrix whose rows are composed by the eigenvectors
associated to the eigenvalues of I. The found reference frame is aligned
with the principal axes of inertia of the body, and it will be used later to
simplify dynamical equations. The principal inertia frame is therefore a refer￾ence frame with origin in the center of mass of the rigid body and such that
all inertia products are equal to zero. The elements on the main diagonal are
the eigenvalues of the inertia tensor, and they are referred to as principal mo￾ments of inertia, Ix, Iy, and Iz.
Attitude dynamics 229Rigid body dynamics
Spacecraft attitude dynamics is based on the theory of rigid body dynamics,
since the spacecraft can be typically modeled as a rigid body. If some flexible
elements are present, or the spacecraft is inherently flexible, the attitude dy￾namics can include the flexible terms as discussed in the Chapter 3 e The
Space Environment.
Angular momentum
Angular momentum is a vector quantity that connects the angular velocity
of a rigid body and its moments of inertia, pretty much like linear mo￾mentum links mass and velocity of a rigid body. Angular momentum is a
conserved quantity, since the total angular momentum of a closed system
(i.e., no external torque is applied) remains constant. Torque can be defined
as the rate of change of angular momentum, analogous to force for the linear
momentum. In these regards, the inertia matrix has a key role in this, as two
bodies with different moments of inertia would need different torques to
achieve the same variation of the angular rate. This can intuitively be repre￾sented by a light wooden door and a security fire barrier door: the lighter
one requires less effort to be opened or closed, since it has a lower moment
of inertia with respect to the hinges. Namely, the larger the inertia values,
the higher the required torque to impose a rotation to an object.
The angular momentum of a rigid body b is defined referring to a refer￾ence frame attached to the rigid body and moving with it. Indeed, unlike
linear momentum, angular momentum depends on where the origin is cho￾sen. Assuming a body-fixed reference frame with origin, O, we can
compute the angular momentum over the volume of the body as:
hb ¼
Z
V
r  rðrÞ v dV;
where v is the velocity of any infinitesimal particle of the body. Solving the
integral and using the definition of first and second moment of inertia of the
body, the angular momentum can be expressed as:
hb ¼  vO  c þ I ub
where vO is the velocity of the origin of the reference system attached to the
rigid body, and ub the angular rate of the body frame with respect to the
inertial one expressed in body frame.
230 Aureliano Rivolta et al.By choosing the origin O coincident with the center of mass of the sys￾tem, we know that c vanishes and the angular momentum is simplified as:
hb ¼ I ub
.
Rotational kinetic energy
Whenever there is an object in motion, we can associate it with the concept
of energy, and in particular kinetic energy. As for the angular momentum,
there exists the rotational counterpart of the linear kinetic energy. Analo￾gously, the rotational kinetic energy is constant for a closed system with
no internal energy dissipation. In fact, in the absence of external disturbances
and torque fields capable of inducing energy to the system, kinetic energy is
a scalar constant. This applies to extended bodies that can rotate in space.
The rotational kinetic energy, Tu, is given by:
Tu ¼ 1
2
ubT
I ub
;
where both the angular rate and the inertia matrix are computed in a
reference frame with the origin in the center of mass of the system. In case of
external torques, we could link them to the variation in time of the kinetic
energy.
For a given inertia matrix, kinetic energy, and angular momentum of the
body, we can define the so-called inertia ellipsoid, kinetic energy ellipsoid,
and angular momentum ellipsoid [1,4]. A complete discussion on these
geometrical entities is out of the scope of this book, and it can be found
in literature. However, they are powerful visualization tools to understand
and bound the attitude dynamics of a rigid body in space. In fact, the angular
momentum ellipsoid must intersect the kinetic energy ellipsoid at least in
one point in order to represent a real motion. If no energy dissipation exists
and no torque is applied, both kinetic energy and angular momentum must
be constant. For a given Tu and h, the attitude dynamics must evolve in such
a way that angular velocity vector identifies the intersection of the kinetic
energy ellipsoid with the angular momentum ellipsoid. Indeed, the angular
velocity must be compatible with the energy level and with the angular mo￾mentum defined by the initial conditions of motion. The intersection of the
kinetic energy ellipsoid with the angular momentum ellipsoid generates two
lines, called polhodes [4]. This can be also visualized on the invariant plane,
which is the fixed plane containing the terminal point of vector ub
, because
of the conservation of the projection of ub over h for a torque-free motion
Attitude dynamics 231with no energy dissipation. The line traced by the angular velocity on the
invariant plane is in general not closed, it is called herpolhode [1].
From polhodes and herpolhode analyses, we derive the fundamental
result that a stable rotational motion is possible only around the maximum
or minimum principal moment of inertia axis. In fact, if the angular velocity
is slightly shifted from the maximum moment of inertia axis or from the
minimum moment of inertia axis, it will remain confined in a region close
to the axis, while a slight shift from the intermediate moment of inertia axis
would cause a dramatic departure from the original condition. It is a well￾known result that spin stabilization should always be about the principal
axis with the largest or smallest principal moment of inertia, known as the
major or minor principal axis [1].
Note that the conservation of angular momentum occurs if no external
forces are applied, but the kinetic energy is constant only if also no internal
dissipation is present. In the case internal forces (e.g., due to flexibility) dissi￾pate the system’s energy, the rotational energy will decrease to its minimum
value of h2

IMax, resulting in a stable rotation about a major principal axis
with moment of inertia IMax. Thus, for practical applications, only the prin￾cipal axis with maximum moment of inertia shall be used as a stable spinning
axis of the spacecraft. If the desired spin axis is a minor axis, energy dissipa￾tion will induce an undesirable rotation about an axis perpendicular to the
preferred one. This unwanted spin condition was unfortunately verified in
history with the Explorer 1, the first Earth satellite launched by the United
States.
Euler equation
We can exploit Lagrange formulation to derive a set of complete equations
of motion exclusively for a rotating body in space. First, we set the funda￾mental equation for rigid body motion in inertial frame, i:
dhi
dt ¼ t
i
;
where t
i are the external torques expressed in inertial frame. However, it is
more convenient to derive the dynamical equations as observed in the body
reference frame. By using the attitude matrix, A ¼ bAi, and deriving with
respect to time, we get:
AT d
dt

I ub

þ
d
dt
AT $

I ub

¼ t
i
232 Aureliano Rivolta et al.Recalling the time variation equation for the DCM, A_ T ¼ AT 
ub

	
,
we get:
AT d
dt

Iub

þ AT
ub

	
$

Iub

¼ ATt
b
;
where we also used the external torques in the body frame, which are
handier for GNC applications.
Finally, by simplifying the equation above, we get:
d
dt
hb ¼ t
b  
ub

	 I ub

;
or in a simpler notation:
h_b
þ ub  hb ¼ t
b
This formulation is often referred to as Euler equation and relates the
angular momentum to the external torques applied to the body. It should
be noted that there might be cases where the inertia of the system is not fixed
in time and the time derivative of the angular velocity depends also on the
time variation of the inertia of the system. In the case of constant inertia, the
angular velocity of the spacecraft is directly related to the external torques as:
u_ b ¼ I
1
t
b  ub  I ub
	
:
Another important consideration of Euler equation is that in absence of
external actions, a rigid body does not see its angular velocity magnitude
change, but it might see its direction changing in time, thanks to the
nonlinear term ub  hb. In fact, without external torques, the kinetic en￾ergy of a rigid body with no internal dissipation is a scalar invariant of the
system. We can look at it in the following way:
d
dt
Tu ¼ ubT d
dt

hb

¼ uT
b

t
b  
ub

	 I ub
	 ¼ uT
b t
b
since the dot product of a cross product is null. However, kinetic energy
is scalar, and this means that the angular velocity direction can freely change
in time.
As previously hinted, it is possible to simplify Euler equations if we ex￾press it in the principal axis reference frame. Let us use the common notation
ub ¼ 
ux uy uz
T , t
b ¼ 
tx ty tz
T and I ¼ diag Ix Iy Iz
,
in order to get:
Attitude dynamics 2338
>>>><
>>>>:
Ix u_ x þ 
Iz  Iy

uyuz ¼ tx
Iy u_ y þ ðIx  IzÞuxuz ¼ ty
Iz u_ z þ 
Iy  Ix

uxuy ¼ tz
In these equations, if the coupling term vanishes, then the rotation
around one axis will be driven only by the torque around the same axis.
For the sake of simplicity and to gain some insight on the mathematical
model, we can assume a torque-free motion, t
b ¼ 0, and rearrange the
Euler equations in the principal inertia axes:
8
>>>><
>>>>:
u_ x
u_ y
u_ z
9
>>>>=
>>>>;
¼
2
6
6
6
6
6
6
6
6
4
Iy  Iz
Ix
uyuz
Iz  Ix
Iy
uxuz
Ix  Iy
Iz
uxuy
3
7
7
7
7
7
7
7
7
5
¼
2
6
6
4
K1 uyuz
K2 uxuz
K3 uxuy
3
7
7
5
where K1; K2; and K3 are the so-called inertia ratios. This nonlinear
formulation explains better the relation between the angular velocities of
different axes. As an example, if we assume Ix ¼ Iy, we have that u_ z ¼ 0
and this transforms the first two line of the equation in two harmonic oscil￾lators whose period is given by inertia ratio and the nominal angular velocity
of the third axis. This is one of the few cases where an analytical solution
exists [4]. Another would be the “sphere” case where the nonlinear term
nullifies, thanks to the symmetry, resulting in a trivial dynamical solution.
Even the case in which only one angular rate component is different from
zero, results in a very simple dynamics and all the coupling terms are null.
This case is called simple spin, and it is very relevant for practical applications
and spin stabilization techniques [1]. However, the reader should notice that
the simple spin stays with all the nonlinear terms equal to zero only in the
ideal case; a small perturbation bringing the angular velocity also on the
other principal axes would lead to a more complex triaxial dynamics.
Attitude dynamics of a satellite is then described by joining Euler equa￾tions for attitude dynamics, and an attitude parameterization to propagate
the attitude kinematics. In fact, on a satellite, we have torques influencing
directly the dynamics and induce changes in the components of angular ve￾locity. By adopting one attitude parameterization, we can, knowing the
angular velocity, calculate the attitude parameters that indicate the orienta￾tion of the satellite in space and that allow to evaluate the position￾234 Aureliano Rivolta et al.dependent torques. In Euler equations, it is therefore required to assign
initial conditions for angular velocity, while in attitude parameterization,
we must assign the initial satellite attitude.
It is relevant to remark that the use of the principal axis reference frame is
not particularly convenient for numerical integration of the attitude dy￾namics and for GNC applications, since a computer can easily deal with a
full 3  3 inertia tensor. However, the principal reference frame is very use￾ful for theoretical investigations on the attitude motion and for stability
analyses.
Attitude stability
One important aspect when looking at the dynamics of a rotating body in
space is the stability of rotation around a predefined angular velocity. To
investigate stability, let us differentiate the torque-free motion equations
in principal axes to obtain the equations of three coupled nonlinear har￾monic oscillators:
8
>>>>><
>>>>>:
u€x ¼


K1K2u2
z þ K1K3u2
y

ux
u€y ¼ 
K2K3u2
x þ K1K2u2
z

uy
u€z ¼


K1K3u2
y þ K2K3u2
x

uz
If we assume to have a nonzero reference velocity ub such that ub ¼
ub þ dub and u_ b ¼ _ dub, we can study the dynamical stability of the sys￾tem. To be stable, we must have dub always bounded; hence, the associated
nonlinear oscillators must have the terms in brackets always negative. This
highly depends on the inertia ratios (i.e., the signs of K1; K2, and K3) and
ub itself. Hence, results may differ from one satellite to another due to
inertia properties and mission profile. However, if we limit ourselves to
the first order terms and assume ub aligned with one of the principal axes,
we can find some interesting outcomes.
From Table 5.1 representing three relevant perturbed simple spin cases,
we can extract one important information: there will be always at least one
unstable direction of rotation given any satellite. If we assume, for example,
Ix > Iy > Iz, then we would have K1; K3 > 0 and K2 < 0 meaning that
rotation around the intermediate axis, Iy, would be unstable since
K1K3 > 0. This result is independent from the order of the principal inertias
components, as the reader might want to check independently.
Attitude dynamics 235The stability analysis can be further expanded by taking into account also
the kinematics of the satellite with quaternions. Let us restrict the reasoning
to small variations around a reference configuration under a constant rota￾tion (i.e., q ¼ f0; 0; 0; 1gT). Let’s apply a small perturbation such that
qT
1:3q1:3  q4x1, which represents small angular variation to the attitude.
Limiting to the first order terms, we obtain the following expression, where
the constant factor 1=2 has been neglected because of the variational focus of
this discussion:
q_ 1:3 ¼ ub
q4  ub  q1:3xdub  ub  q1:3:
Then, differentiating with respect to time gives:
q€1:3 ¼ _ dub  ub  q_ 1:3:
If we expand to first order, recalling ub ¼ ub þ dub
, and we substitute
dub in terms of q1:3 and q_ 1:3 from the quaternion kinematics, we get the
following:
q€1:3 ¼
2
6
6
4
0 ðK1 þ 1Þuz ðK1  1Þuy
ðK2  1Þuz 0 ðK2 þ 1Þux
ðK3 þ 1Þuy ðK3  1Þux 0
3
7
7
5
q_ 1:3
þ
2
6
6
6
4
K1

uz
2  uy
2 K1uxuy K1uxuz
K2uxuy K2

ux
2  uz
2 K2uyuz
K3uxuz K3uyuz K3

uy
2  ux
2
3
7
7
7
5
q1:3 þ
2
6
6
4
K1uyuz
K2uxuz
K3uxuy
3
7
7
5:
This expression represents a forced linear second-order system whose sta￾bility can be checked with the classical theoretical criteria. The previous rep￾resents a general case, but we can extract some useful information if we limit
ourselves to a simple spin condition around the x axis. Let us assume ux ¼
ux þ dux; uy ¼ duy; uz ¼ duz to obtain the following expression:
2
6
6
4
Ix 0 0
0 Iy 0
0 0 Iz
3
7
7
5
q€1:3 þ 
Iz þ Iy  Ix

ux
2
6
6
4
00 0
0 0 1
01 0
3
7
7
5
q_ 1:3 þ ux
2
2
6
6
4
00 0
0 ðIx  IzÞ 0
0 0 
Ix  Iy

3
7
7
5
q1:3 ¼ 0
From this expression, we can already see that around the x axis, there is
no dynamical action. Hence, a small perturbation would cause a drift along
that axis. More interesting is the stability of the other two axis. We can
achieve static stability if the rightmost term is positive; hence, when Ix >
236 Aureliano Rivolta et al.Table 5.1 Attitude stability of torque-free motion.
ux ¼
ux þ dux;
uy ¼ duy;
uz ¼ duz
ux ¼ dux;
uy ¼
uy þ duy;
uz ¼ duz
ux ¼ dux;
uy ¼ duy;
uz ¼
uz þ duz
u€xy0 du€xy
K1K3uy
2
dux du€xy
K1K2uz
2
dux
du€yy
K2K3ux
2
duy u€yy0 du€yy
K1K2uz
2
duy
du€zy
K2K3ux
2
duz du€zy
K1K3uy
2
duz u€zy0
Stable condition:
K2K3 < 0
Stable condition:
K1K3 < 0
Stable condition:
K1K2 < 0
Attitude dynamics 237Iz and Ix > Iy (i.e., K2 < 0; K3 > 0). This is only possible if Ix is the
maximum moment of inertia of the system.
The previous result does not count all the possibilities for attitude stabil￾ity as one could restrict to only the second and third directions (i.e., y and z)
and compute the characteristic equation of order 4 to find dynamical
stability:
det
8
<
:
2
4 Iys
2 þ ux
2
ðIx  IzÞ 
Iz þ Iy  Ix

uxs

Iz þ Iy  Ix

uxsIzs
2
þ ux
2
Ix  Iy

#) ¼ 0
IyIzs
4 þ s
2
ux
2
I
2
x þ 2IyIz  IxIz  IyIx

þ ðIx  IzÞ

Ix  Iy

ux
4 ¼ 0;
where s is the auxiliary variable.
From the previous equations of fourth degree, we can have acceptable
results for stability only if the following conditions are verified:
• IyIz > 0
• 
I2
x þ2IyIz IxIz IyIx
0
• ðIx IzÞ

Ix Iy
0
• 
I2
x þ 2IyIz  IxIz  IyIx
2  4IyIzðIx IzÞ

Ix Iy
0
The first is always true and the third requires Ix to be the major or minor
moment of inertia of the system. The other two conditions show that not all
the values and ratios for the moments of inertia are allowed to have stability.
We can rewrite the stability equation in terms of K2 and K3 as follows:
 s
ux
4
þ ð1  K2K3Þ
 s
ux
2
 K2K3 ¼ 0
Giving the following requirements for stability:
• K2K3 < 1
• K2K3 < 0
• ð1 þ K2K3Þ
2 > 0
According to the definition of the inertia matrix, we can also state Ki < 1
with i ¼ 1; 2; 3. Looking at the second requirement, it is straightforward to
see that it indicates the second and fourth quadrant of the K2; K3 space, as
shown in Fig. 5.3. This encompasses also the first requirement as that would
include an area comprised between two rectangular hyperbolas on first and
third quadrant. Lastly, the third one restricts the ratios out of the hyperbolas
238 Aureliano Rivolta et al.of the second and fourth quadrant, depicted in Fig. 5.3. However, the latter
is not very relevant for practical applications. Recalling the statical stability
conclusion taken previously (i.e., Ix > Iz and Ix > Iy

, we can also identify
that condition in terms of K2; K3: K2 < 0 and K3 > 0, which implies that
only the second quadrant is also statically stable.
Dual spin dynamics
Dual spin dynamics describes the motion of a spacecraft containing an inter￾nal rotating mass, which can be spun independently from the main body.
This is relevant because we might be interested in achieving a stable condi￾tion regardless the moment of inertia of the spinning axis and the angular
rate of the spacecraft. Moreover, dual spin dynamics introduces the concept
of internal rotating devices that set the theoretical foundations for attitude
dynamics control with angular momentum exchange actuators, which
will be discussed in Chapter 7 e Actuators.
Let’s assume a spacecraft containing an internal rotating element that can
rotate relatively to the z axis of the principal axes body reference frame. The
overall angular momentum of the system becomes:
hb ¼ I ub þ Ir ur ¼ Ixux bx þ Iyuy by þ ðIzuz þ IrurÞbz;
Figure 5.3 Attitude stability graph.
Attitude dynamics 239where the moments of inertia of the spacecraft include the inertia of the
rotating mass, Ir, and ur is the relative velocity of the rotor around the z axis.
At this point, we can rewrite the Euler equations in principal inertia axes by
using the new definition for the system’s angular momentum:
8
>>>>>>>>>>><
>>>>>>>>>>>:
Ix u_ x þ 
Iz  Iy

uyuz þ Iruruy ¼ tx
Iy u_ y þ ðIx  IzÞuxuz  Irurux ¼ ty
Iz u_ z þ 
Iy  Ix

uxuy þ Iru_ r ¼ tz
Iru_ r ¼ tr
;
where we added one degree of freedom to the system, and, thus, the fourth
equation is required to describe the motion of the internal rotating element,
which is driven by the relative torque between the rotor and spacecraft, tr.
The stability analysis of the dual spin attitude dynamics can be carried out
as in the simple spin case, and the interested reader might find the complete
derivation in the suggested references [2,4]. However, the main conclusions
are relevant for GNC applications. Indeed, dual spin satellites can achieve a
stable motion even if rotating around an axis that is not the maximum inertia
axis. Generally, if the satellite angular velocity and the rotor angular velocity
have the same sign, the ensemble of stable solutions is increased. On the con￾trary, a counterspinning rotor may reduce the set of potentially stable
conditions.
The previous considerations are particularly relevant if the internal
rotating mass is operated with a constant angular rate. They can be extended
to the case in which the rotor is accelerated to continuously vary its angular
rate. In this case, the stability conditions can be defined only for each instant
of time, losing their significance. However, this condition is even more rele￾vant for modern GNC, since it allows an active attitude control through the
action on the rotating element. In fact, the internal torque applied to the
rotor is by reaction transferred to the spacecraft, with an exchange of angular
momentum between the main body and the internal mass. As said, this is the
fundamental concept behind momentum exchange actuators.
Now it is important to generalize and extend the previous equations to a
number of n internal rotating masses aligned with some directions in the
body reference frame. The angular momentum can be expressed as:
hb ¼ Iub þ hb
rotors ¼ Iub þ R hr
rotors;
240 Aureliano Rivolta et al.where R is a 3  n matrix, whose columns represent the direction of the axis
of rotation of the internal rotors in the body frame, and hr
rotors is a column
vector with n elements representing the angular momentum of each rotor
around its spin axis. Note that the moment of inertia tensor of the spacecraft
includes the inertia of the internal rotating elements. Hence, hr
rotors and
hb
rotors represent the relative angular momentum of the rotors with respect to
the spacecraft body. It is relevant to note that hr
rotors and hb
rotors may not have
the same magnitude because R is generally not an orthogonal matrix. The
expression of the matrix R as a function of the configuration of the internal
rotating masses, and the way in which it is used for attitude control will be
presented in Chapter 7 e Actuators.
At this point, we can specialize the Euler equation to the case of n inter￾nal rotating elements as:
u_ b ¼ I
1
t
b  t
b
rotors  ub  
I ub þ hb
rotors	;
where t
b
rotors is the torque applied to the rotors and it has the negative sign
because of the Newton’s actionereaction principle.
Environmental torques
Satellites orbiting in space are subjected to external disturbances due to the
space environment, as it has been discussed in Chapter 3 e The Space Envi￾ronment. In this section, the effects of the most relevant environmental per￾turbations are specialized for spacecraft attitude dynamics. Indeed, the
environmental torques influencing the Euler equation are described. The
section is focused on Earth-orbiting spacecraft, but the discussion can be
easily generalized to any other environmental condition.
Gravity gradient torque
Gravity gradient is an environmental torque due to a gravitational field,
which is present whenever we have a body that is nonsymmetrical. This tor￾que is commonly the largest perturbation contribution for any spacecraft
orbiting in the vicinity of a massive celestial object. Since this torque applies
to all bodies characterized by mass with finite dimensions, it also affects
planets, moons, and other celestial bodies as well. It is in fact this kind of ac￾tion that keeps some moons tidally locked to their orbiting planet.
The gravity gradient does not depend on the irregularities in the
nonspherical gravitational field, since it is only caused by the fact that the
gravitational attraction affects any mass particle of an extended rigid body.
Attitude dynamics 241In the case, the body is not symmetric, the summation of the gravity forces
over the entire body results in a torque about the center of mass. The actual
gravity gradient contribution would depend on the real nonspherical gravity
field, but it is usually adequate to approximate the gravity field as spherically
symmetric for computing gravity gradient torques in GNC applications.
Hence, we will derive the gravity gradient torque on a satellite orbiting
only one attractor that is characterized by a spherical and symmetrical
mass distribution. The satellite is composed by a single rigid body, and its
size is considerably smaller than the distance from the primary center of mass.
Let’s divide the spacecraft body into infinitesimal mass elements, dm,
which are individually subject to the gravitational attraction of the central
planet. The induced torque with respect to the center of mass of the space￾craft can be computed from an integral sum over all infinitesimal masses:
t
i
g ¼ m
Z
M
r 

rgc þ r


rgc þ r


3 dm
where we have evaluated the torque cross product for any infinitesimal mass
in position r with respect to center of mass of the spacecraft, which has a
position vector rgc relative to the central attractor. The reference frame for
the integration has the origin in the center of mass of the body, thus
R
M
r dm ¼ 0. Moreover, it should be noted that r  rgc is the only nonnull
contribution, and, consequently, the gravity gradient is null on the local
vertical (i.e., in the direction parallel to rgc).
If we expand in a power series the term 
rgc þ rk3
; considering the as￾sumptions made before (i.e., krk  
rgc

), we obtain that the net torque
around the center of mass is:
t
i
g ¼  3m

rgc


5rgc 
2
4
0
@
Z
M
r 5 r dm
1
A $ rgc
3
5:
Recalling the definition of second moment of inertia, we can substitute
the outer product directly and obtain the general:
t
i
g ¼ 3m

rgc


3
rgc

rgc




I
rgc

rgc



So, we now have the possibility to define the gravity gradient in the in￾ertial reference frame, given the center of mass position, rgc, and the inertia
242 Aureliano Rivolta et al.tensor of the body about the center of mass, I. We can also notice that the
magnitude of the gravity gradient torque is inversely proportional to the
cube of the distance from the center of the central body, its direction is
perpendicular to the radius vector of the center of mass position, and it van￾ishes if the radius vector is along any principal axis of inertia. Thus, it should
be clear that the gravity gradient is an attitude-dependent torque.
It is very convenient to express this torque in the body reference frame.
Then, we apply a rotation by the attitude matrix, A, to t
i
g and we can express
torque in the body fixed frame. If we define c ¼ A rgc
krgck
, we get:
t
b
g ¼ 3m

rgc


3 c  ðI cÞ:
The vector c contains the direction cosines of the local vertical direction
as seen in the body reference frame, and it can be seen as part of the DCM
that links local-vertical-local-horizontal (LVLH) frame with respect to the
inertial one. Indeed, c can be also computed by rotating the x-axis of the
LVLH in the body reference frame. The previous expression can be further
expanded if we choose the principal axes as the body reference frame and, in
this case, we obtain:
t
b
g ¼ 3m

rgc


3
2
6
6
4

Iz  Iy

cycz
ðIx  IzÞcxcz 
Iy  Ix

cxcy
3
7
7
5:
From this useful expression, we see that a perfectly spherical body would
not be affected by the gravity gradient. Tidally locked moons are more
oblate and ellipsoidal rather than spherical, and this contributes to keeping
them with a stable attitude with respect to the main attractor.
The gravity gradient can enhance or reduce the stability of the system.
Let’s assume an LVLH moving frame, for simplicity in a circular orbit,
and let the x body axis be aligned with the radial zenith direction (i.e.,
yaw axis), and the z axis parallel to the orbital angular momentum (i.e., pitch
axis). Then, we can limit to the first-order expansion getting for small angles
around x, y, and z:
Attitude dynamics 243t
b
g ¼ 3m

rgc


3
2
6
6
4
0
ðIx  IzÞ day


Iy  Ix

daz
3
7
7
5:
Then, assuming an angular velocity with nominal component on the z
axis, we would have that for the third equation of motion:
da€z ¼ 3m

rgc


3K3daz
In this case, if we have K3 < 0, the system would be bounded in this di￾rection as well. This result can be generalized stating that the equilibrium at
zero roll and pitch is a stable equilibrium if the x axis (i.e., yaw axis) is the
smallest principal moment. Hence, the gravity gradient torque will tend
to align a spacecraft with its principal axis of minimum inertia aligned
with the radial zenith (or nadir) vector, and it is sometimes used for passive
stabilization of spacecraft attitude dynamics. Note that this torque does not
depend on the yaw angle. Further insights in gravitational stability can be
found in Ref. [4].
Magnetic torque
If a satellite is orbiting a planetary body with a permanent magnetic field, Bb
;
and it has a nonzero magnetic dipole moment, mb
m, this induces a net torque
on the satellite as follows:
t
b
m ¼ mb
m  Bb
where we have expressed all the quantities in the body reference frame.
Magnetic moments can arise due to electronics equipment on board the
satellite, parasitic currents, and magnetization of ferromagnetic materials as
well. In general, the fundamental source of a magnetic dipole is a current
loop.
Depending on the level of precision required, the magnetic field can be
estimated using a simple dipole model or using a proper magnetic model, as
described in the Chapter 3 e The Space Environment. For example, a
simplified geomagnetic field can be computed as function of the distance
from the Earth center as:
244 Aureliano Rivolta et al.Bgeo ¼  mm 
rgc


2
6
6
6
4
3 sin fg cos fg coslg
3 sin fg cos fg sinlg
3 sin2
fg  1
3
7
7
7
5
where fg is the latitude, lg is the longitude, mm is the Earth’s dipole strength

w 8  1022 A m2

, and the resulting magnetic field is expressed in a
geomagnetic reference frame, which has to be rotated in body frame to
compute the magnetic perturbation torque.
Aerodynamic torque
Atmospheres are constituted by gaseous elements that bound a planetary
body, and their interactions with a moving body can be described by fluid
dynamics. For orbiting satellites, the atmosphere usually has a low influence,
and at relatively high altitudes, it has actually no effect. When a satellite lies
in a low orbit or, in general, passes through the upper parts of the atmo￾sphere, it is influenced by the surrounding gas particles. The main effect
of the spacecraftegas interaction is atmospheric drag, since lift is typically
almost null, except for very particular missions. The drag can slow down
a satellite up to deorbit it, and, in some cases, it can be exploited to actively
control the orbits.
For what concern attitude dynamics, aerodynamic torques arise when￾ever a body has a relative motion with respect to a fluid, even a rarefied
one like in the upper atmosphere. A net influence on the attitude is possible
if the center of aerodynamic pressure has a relative position with respect to
the spacecraft’s center of mass, rcpa. In this way, the drag produces a torque
that perturbs the rotational motion:
t
b
d ¼ rcpa  f b
d.
The aerodynamic drag force can be computed as:
f b
d ¼ 1
2
CdrSk vk v;
where we used the air density, r, which is the main function of the altitude,
a drag coefficient, Cd; the area of the surface exposed to the fluid, S; and the
relative velocity between the spacecraft and the atmosphere, v. The aero￾dynamic drag torque is computed from the drag force vector, considering
the position vector of the center of pressure in the spacecraft body frame.
The drag coefficient value is commonly set equal to w2, which is the value
Attitude dynamics 245for a flat plate. In fact, the aerodynamic drag torque is practically computed
by summing up all the drag contributions of each spacecraft flat surface. Very
simple applications may assume the spacecraft as composed by a single flat
surface, while more complex models may use a polyhedral discretization of
the spacecraft shape. Experimental analyses are needed if the atmospheric
drag shall be estimated with high accuracy.
The major characteristic of aerodynamic drag is that it is always opposed
to the velocity with respect to the atmosphere. Hence, a proper relative ve￾locity computation with respect to the atmosphere of a rotating body must
be performed and not be neglected [1]. Further details about atmospheric
drag and atmosphere models are discussed in the Chapter 3 e The Space
Environment.
Solar radiation pressure torque
Pretty much like for atmospheric drag, spacecraft attitude is also perturbed
by the luminous radiation coming from the Sun. Light can behave like a
wave or like a particle, and when these particles interact with bodies having
specific optical properties, a momentum transfer can occur. The entity of the
force of the sunlight hitting a body is extremely low, but it remains in effect
for every satellite that is not in shadow. In low Earth orbit, the effect of solar
radiation pressure (SRP) is dominated by aerodynamics, but SRP torques
will generally prevail over aerodynamic torques in higher altitude orbits.
Like for the atmospheric case, the resulting force is computed with an inte￾gral over the surfaces exposed to the Sun radiation and depending on the
application point with respect to the center of mass, we could have a net tor￾que on the satellite.
If we analyze the incoming radiation on a surface, we can exploit the par￾ticle interpretation of light to deal with these particles hitting the surface.
The infinitesimal force df b
s is a function of the momentum exchange and
it can be determined as:
8
>>>>>>>><
>>>>>>>>:
df b
s ¼ p $ xðaÞcos abs dA
psrp ¼ SF
c
cos a ¼ bs $ nbA
xðaÞ ¼ 1
2
ðsignðcos aÞ þ 1Þ
246 Aureliano Rivolta et al.where we have determined the force per unit area as function of the in￾tensity of the pressure p, the direction opposite to the one of the traveling
photons bs (i.e., satellite-Sun direction), and an impact angle given by the dot
product with the normal direction of the infinitesimal surface nbA. Note that
the overall SRP is computed integrating the system of equations over the
spacecraft’s surfaces. It should be noted that the coefficient xðaÞ enforces the
fact that if a surface is not lighted up (i.e., cos a < 0), the net force should be
zero.
The underlying assumption of the previous equations was that all mo￾mentum is transferred to the body (i.e., absorbed radiation), which is rather
idealistic and not representative of the reality of electromagnetic radiation
hitting a surface. In fact, depending on the material of the surface, we could
experience a total absorption, a total transmission, a specular reflection, or,
more generally, a diffuse reflection. Thus, not all the incoming radiation
is absorbed, but the overall incoming radiation is divided into fractions
that experience the four aforementioned possibilities:
sabsorb þ sdiffuse þ sspecular þ stransmit ¼ 1;
and obviously they shall sum up to one.
Only absorption and reflection contribute to the overall momentum
transmission. Thus, with the current assumptions, the infinitesimal SRP
force on a generic elemental surface of the spacecraft is expressed as:
df b
s ¼  p $ xðaÞcos a

sabsorb þ sdiffuse
bs
þ
2
3
sdiffuse þ 2sspecular cos a

nbA

dA
The net force is computed through an integral over the considered
exposed area, and the net torque is given by the cross product with the cen￾ter of luminous pressure location in body reference frame:
8
>><
>>:
t
b
s ¼ rcps  f b
s
rcps ¼
R
xðaÞcos a r dA
R
xðaÞcos a dA
;
It should be noted that the surface has been assumed to be convex or flat,
as concavities might complicate the formulation and would request more
analysis and self-shadowing considerations. Note that reflected light from
the planetary bodies, called albedo, can be significant if very precise
Attitude dynamics 247dynamical modeling is required. Further details about SRP are discussed in
the Chapter 3 e The Space Environment.
Three-body problem attitude dynamics
Whenever the spacecraft is subject to a 3BP dynamical environment,
the attitude motion is influenced by both the primary attractors, as in the
case of the orbital motion described in the Chapter 4 e Orbital Dynamics.
The main peculiarity of the 3BP attitude dynamics is the presence of the
two-gravity gradient torques that deeply characterize the attitude motion
in the 3BP. Attitude dynamics (i.e., coupled orbiteattitude dynamics) in
three-body environment is getting an increased attention for GNC applica￾tions, since modern space missions will be often set in 3BP environments,
such as the Cislunar space, or the SuneEarth system.
Euler equations are formulated to include the gravity torques exerted by
the two primary attractors, which can be computed as the gravity gradient
torque defined in the section about environmental torques. Moreover,
the equations of attitude motion may further include the most relevant per￾turbations in the orbital environment. For example, SRP torque and the
gravity gradient torques of other celestial bodies are commonly included
to accurately model 3BP attitude dynamics [6]. The resulting Euler dynam￾ical equations for the attitude dynamics in three-body environment are
expressed as:
8
>>>>>>>>>>>><
>>>>>>>>>>>>:
Ix u_ x þ

Iz  Iy

uyuz ¼
Iz  Iy

"
3ð1  mÞ

r  r1


3lylz þ
3 m

r  r2


3hyhz
#
þ tx
Iy u_ y þðIx  IzÞuxuz ¼ðIx  IzÞ
"
3ð1  mÞ

r  r1


3lxlz þ
3 m

r  r2


3hxhz
#
þ ty
Iz u_ z þ

Iy  Ix

uxuy ¼
Iy  Ix

"
3ð1  mÞ

r  r1


3lxly þ
3 m

r  r2


3hxhy
#
þ tz
where li are the direction cosines in the body reference frame of the unit
position vector from the first primary to the spacecraft; hi are those related
with the unit position vector from the second primary to the spacecraft; ti are
other external torques acting on the spacecraft. The other quantities were
introduced in the Chapter 4dOrbital Dynamics: r refers to the spacecraft
248 Aureliano Rivolta et al.body position vector; r1 and r2 are the primaries position from the three￾body system’s barycenter; and m is the mass ratio of the 3BP primaries.
Attitude dynamics in 3BP allows to investigate periodic orbiteattitude
motions in three-body environments and to analyze the orbiteattitude
coupling in these dynamical regimes. Further details can be found in dedi￾cated reference studies [6e11].
Relative attitude dynamics
Analogously to the case of translational dynamics, relative attitude dy￾namics refers to the description of the attitude motion of one body with
respect to a rotating reference frame. Such relative dynamics is quite com￾mon in missions involving rendezvous and docking, formation-flying, on￾orbit servicing, and proximity operations, which are common applications
in modern spacecraft GNC.
Let’s assume a spacecraft whose body frame is indicated with C, and
another reference frame that can be attached to a different orbiting space￾craft, or to a fictitious point following a trajectory in space. This second
reference frame is indicated with T. Then, we define the attitude kinematics
in terms of quaternions, qC and qT, relating the inertial reference frame with
C and T. The relative attitude kinematics is defined by exploiting the rela￾tive quaternion definition as:
dq ¼ qC  q1
T ¼
( cðqTÞ qC
qT
T qC
)
;
where cðqTÞ is the 3  4 matrix defined in the relative quaternion kine￾matics section. Note that the relative quaternion kinematics follows the same
rules of the kinematics of absolute quaternions.
The rotation matrix P that transforms a vector from the reference frame
T to the frame C can be expressed in terms of the relative quaternion dq as:
PðdqÞ ¼
2
6
6
4
1  2

dq
2
2 þ dq
2
3
 2ðdq1dq2  dq3dq4Þ 2ðdq1dq3 þ dq2dq4Þ
2ðdq1dq2 þ dq3dq4Þ 1  2

dq
2
1 þ dq
2
3
 2ðdq2dq3  dq1dq4Þ
2ðdq1dq3  dq2dq4Þ 2ðdq2dq3 þ dq1dq4Þ 1  2

dq
2
1 þ dq
2
2

3
7
5:
The relative angular velocity between the two reference frames can be
expressed in the frame C as:
Attitude dynamics 249duC ¼ uC  P uT ;
where uC and uT are the angular rates of the two reference frames C and T
expressed in the respective reference frames.
At this point, the relative attitude dynamics of the reference frame C
with respect to the reference frame T can be expressed in C as:
du_ C ¼ I
1
C

 
duC

	
IC duC  
duC

	
IC P uT þ IC

duC

	
P uT
 
P uT

	
IC duC þ t
C  P PT IC P  IT

I
1
T

t
T
 
uT

	
ITuT 
þ 
uT

	PT IC P  IT

uT 	
 P tT 
;
where IC and IT are the inertia tensors of the two reference frames in
principal axes; t
C and t
T are the external torque vectors acting on the rigid
bodies, respectively, expressed in C and T.
Relative attitude dynamics can be used in relative GNC applications to
derive GNC functions directly under a relative perspective. Its formulation is
very useful in modern spacecraft missions, which are more and more
directed toward relative and close proximity applications, formations flying,
rendezvous, and docking. Further considerations may be found in specific
reference studies [12,13].
Multibody spacecraft dynamics
For most applications, a satellite can be modeled as a rigid single body.
However, there are modern applications where this is no longer possible. If
the satellite has long flexible components (e.g., solar panels and radiators) or
has movable appendages (e.g., robotic arms, booms, or antennas), the
assumption is not valid anymore. In some cases, it is possible to estimate a
model of the forces and torques on the flexible and movable elements to
be applied at interfaces with the main body. This simplified approach is
possible for moving elements and flexible appendages in the case of a very
massive base (e.g., space station). If these secondary masses are not so
different from the main body ones, the effects of appendages and flexible el￾ements can be quite important, and the spacecraft has to be modeled with a
multibody approach.
One common movable appendage is a robotic arm installed on the
spacecraft body. For one robotic arm only made by revolute joints, one
can refer to Refs. [14,15]. In this case, the center of mass is a key factor to
describe all the positions of the single elements. In fact, a multibody satellite
250 Aureliano Rivolta et al.has the center of mass and center of rotation still coincident, meaning that
position and attitude of the base depend on the rest of the elements as
well. Another modeling approach is to use a EulereLagrange formulation
that can be applied to a single chain of rigid bodies. In this case, the
exchanged forces are sequentially applied in one direction and then resolved
in the opposite direction to estimate all the relevant forcing contributions. A
further approach consists in generalizing the concept of bodies chained
together in multiple branches and enforcing the center of mass and rotation
properties. More complex cases with closed networks of bodies may require
further investigations and the possible usage of a more general multibody
solver [16,17]. It should be noted that the robotic arm might affect only a
small portion of a satellite mission: no satellite should be moving around
with a robotic element fully operative if it is not the time to use it.
Flexible appendages usually require a finite element model analysis to es￾timate frequencies. Then, this information is integrated as an external torque
applied to the system, as described in the Chapter 3 e The Space Environ￾ment. However, if the flexible elements need be closely integrated with the
spacecraft model, this is still possible with a multibody approach. In this case,
the flexible appendages are modeled as discretized elements, linked to the
main body with joints, dampers, and springs, inducing equivalent forces
and flexible dynamics in the rigid system. The discretization level influences
the representativity of the flexible dynamics, and it is directly responsible of
the computational load to simulate the system behavior.
Other interesting sources of disturbances for attitude dynamics are the
mass expulsion or aggregation events. The most common is the loss of
mass due to the expulsion of material through the propulsive subsystem.
This is often modeled as an equivalent force, and the mass expulsion is rarely
described with a multibody approach. However, this can be done to accu￾rately represent the time history of the center of mass’ position. In fact, the
propellant temporal variation can be combined with the propellant and fluid
sloshing inside the satellite. These terms can be modeled through a series of
masses and multibody elements that can mimic the sloshing frequencies and
the propellant expulsion.
In general, attitude dynamics is strictly related with movable parts, flex￾ible elements, and internal fluids. Thus, accurate modeling of attitude dy￾namics requires dedicated multibody flexible models of the system. The
reader is invited to deepen this topic on the suggested references and to
find further details in the Chapter 3 e The Space Environment.
Attitude dynamics 251References
[1] F.L. Markley, J.L. Crassidis, Fundamentals of Spacecraft Attitude Determination and
Control, Space Technology Library, Springer, New York, 2014.
[2] P.C. Hughes, Spacecraft Attitude Dynamics, Dover Publications Inc., New York,
2004.
[3] V.A. Chobotov, Spacecraft Attitude Dynamics and Control, Orbit Book Co, 1991.
[4] J.R. Wertz, Spacecraft Attitude Determination and Control, vol. 73, Springer Science
& Business Media, New York, 1978.
[5] M.H. Kaplan, Modern Spacecraft Dynamics and Control, Wiley, New York, 1976.
[6] A. Colagrossi, M. Lavagna, Preliminary results on the dynamics of large and flexible
space structures in Halo orbits, Acta Astronautica 134 (2017) 355e367, https://
doi.org/10.1016/j.actaastro.2017.02.020.
[7] A. Colagrossi, M. Lavagna, Dynamical analysis of rendezvous and docking with very
large space infrastructures in non-keplerian orbits, CEAS Space Journal 10 (1) (2018)
87e99, https://doi.org/10.1007/s12567-017-0174-4.
[8] D. Guzzetti, K.C. Howell, Natural periodic orbit-attitude behaviors for rigid bodies in
three-body periodic orbits, Acta Astronautica 130 (1) (2017) 97e113, https://doi.org/
10.1016/j.actaastro.2016.06.025.
[9] D. Guzzetti, K.C. Howell, Attitude dynamics in the circular restricted three-body
problem, Astrodynamics 2 (2) (2018) 87e119, https://doi.org/10.1007/s42064-
017-0012-7.
[10] F. Colombi, A. Colagrossi, M. Lavagna, Floquet modes and stability analysis of peri￾odic orbit-attitude solutions along EartheMoon halo orbits, Celestial Mechanics
and Dynamical Astronomy 133 (34) (2021), https://doi.org/10.1007/s10569-021-
10030-y.
[11] A. Colagrossi, V. Pesce, L. Bucci, et al., Guidance, navigation and control for 6DOF
rendezvous in Cislunar multi-body environment, Aerospace Science and Technology
114 (2021) 106751, https://doi.org/10.1016/j.ast.2021.106751.
[12] G.Q. Xing, S.A. Parvez, Alternate forms of relative attitude kinematics and dynamics
equations, in: 2001 Flight Mechanics Symposium, Greenbelt, Maryland, USA, 19e21
June, 2001, pp. 83e97. https://ntrs.nasa.gov/archive/nasa/casi.ntrs. nasa.gov/
20010084965.pdf.
[13] S.-G. Kim, et al., Kalman filtering for relative spacecraft attitude and position
estimation, Journal of Guidance, Control, and Dynamics 30 (1) (2007) 133e143.
[14] K. Yoshida, B. Wilcox, Space Robots, Springer handbook of robotics, 2008,
pp. 1031e1063.
[15] K. Yoshida, Achievements in space robotics, IEEE Robotics and Automation Maga￾zine 16 (4) (2009) 20e28.
[16] A.A. Shabana, Dynamics of Multibody Systems, Cambridge university press, 2003.
[17] A.A. Shabana, Flexible multibody dynamics: review of past and recent developments,
Multibody System Dynamics 1 (2) (1997) 189e222.
252 Aureliano Rivolta et al.CHAPTER SIX
Sensors
Andrea Colagrossi1
, Vincenzo Pesce2
, Stefano Silvestrini1
,
David Gonzalez-Arjona3
, Pablo Hermosin4
, Matteo Battilana5
1
Politecnico di Milano, Milan, Italy
2
Airbus D&S Advanced Studies, Toulouse, France
3
GMV Aerospace & Defence, Madrid, Spain
4
Deimos Space, Madrid, Spain
5
OHB Italia S.p.A., Milan, Italy
Sensors on-board a spacecraft are the source for any information, measure￾ment, or data used by the guidance, navigation, and control (GNC) system
to accomplish its task. In analogy with our human experience, they are the
sensory organs (e.g., eyes, ears, nose, etc.) sensing the external environment
to acquire information needed for the GNC operations. A proper GNC
design shall select and arrange the sensors on the spacecraft system in a
way that all the desired quantities are properly measured. In doing so, the
GNC designer shall know, understand, and correctly model the sensors to
support its design process. This chapter is dedicated to briefly present all
the major sensor typologies for spacecraft GNC applications, to discuss their
operating principles, to highlight their peculiarities, to categorize the avail￾able components according to their performances, and to discuss the most
relevant modeling techniques and rules.
The content of this chapter is structured as follows:
• Sensor modeling for GNC. In this section, the sensor modeling techniques
are presented, discussing the main implementation principles of the most
common numerical models to include the sensor behavior in the GNC
design, analysis, verification, and validation phases. The main error sour￾ces and their modeling are introduced, together with the most typical
sensor faults. Moreover, this section contains some elements of
metrology, and it explains some basic principles of statistics and random
variables representation.
• Orbit sensors. This section presents the Global Navigation Satellite System
(GNSS) and the ground-based sensors for orbit GNC. Their main
operating principles and the available performance are discussed. A
simple GNSS sensor model implementation in MATLAB/Simulink is
included in this section.
Modern Spacecraft Guidance, Navigation, and Control
ISBN: 978-0-323-90916-7
https://doi.org/10.1016/B978-0-323-90916-7.00006-8
© 2023 Elsevier Inc.
All rights reserved. 253 j• Attitude sensors. This section introduces the main typologies of sensors for
attitude GNC. For each of them, it presents the main characteristics and
the operational principles. The available performance of the different
attitude sensors is compared, and an example Sun sensor model imple￾mented in MATLAB/Simulink is also described.
• Inertial sensors. Accelerometers and gyroscopes are presented in this sec￾tion. Their peculiar error sources are listed and presented, together
with the available performance according to the quality grade of the
sensor. A brief introduction to the Allan variance (AVAR) representation
of their random errors is included. The chapter is concluded with a sim￾ple example of a MATLAB/Simulink implementation of a gyroscope
model.
• Electro-optical sensors. This section introduces the sensors with a vision￾based sensing capacity, such as cameras and Light Detection and
Ranging (LIDAR) systems. The two typologies, respectively, represent
the class of passive and active electro-optical sensors. Their applicability
range and their design principles are briefly discussed.
• Altimeters. In this section, the concept of altimetry is introduced and the
most relevant typologies of altimeters for spacecraft applications are dis￾cussed. A mathematical altimeter model is also presented at the end of
this section.
Sensor modeling for GNC
Correct sensor modeling is of utmost importance for GNC applica￾tions and design. Indeed, algorithms development and testing shall rely on
proper sensor models to have a truthful representation of the available mea￾surements. Moreover, some estimation filters are based on measurement
models that are capable to include the terms to be estimated. Thus, we
need to understand what the model of a sensor is, how it is built, and
how it is used along the GNC design and verification processes.
A sensor is an electronical device exploiting a physical principle to mea￾sure a certain physical quantity, such as the angular velocity, the position of
the spacecraft, or the position of a celestial body, among the others. The
external reality is sensed by the sensor’s detector, elaborated by the sensor
processing units, and communicated to the GNC system via electrical sig￾nals, which can be analogic or digital, even if modern spacecraft applications
are almost uniquely based on digital components. Along this entire process,
the measured physical quantity is inevitably distorted and modified with
254 Andrea Colagrossi et al.respect to the reality, and a good sensor model shall be able to represent these
deviations, together with all the effects due to the sensing activities. We are
going to mathematically refer to this as:
xð Þt ¼ xð Þt þ εð Þt ; (6.1)
where xð Þt is the measured quantity, xðtÞ is the real-world true quantity, and
εð Þt is the summation of all the sensing process errors and effects.
A sensor model is an abstraction of the actual sensing process converting
the physical quantity into the electrical output, and it is implemented for a
precise purpose with specific objectives. In fact, there exist different types of
sensor models: operational, behavioral, functional, and performance models
are the most common.
Operational sensor models are used to describe and represent how the
sensor is operated and interfaced with the rest of the GNC system, in terms
of commands, operational modes, and interfaces with other components.
Behavioral models reproduce the global behavior of the sensor, including
transitions between modes, response to inputs, and evolution of the outputs.
However, behavioral models do not model the internal processes of the
sensor, but they describe an averaged transient or steady-state behavior.
Functional sensor models are established to serve as input for detailed ana￾lyses and accurate performance simulations. They outline all the internal
functions executed along the sensor processing, being representative of
the sensor actual temporal performances for realistic output profiles. The
complete equipment acquisition chain is typically modeled, from signal
transduction and conditioning to digitalization and formatting. Functional
models can be representative of real input and output data formats, but
they are not required to include different operational modes. Consequently,
more functional models may be necessary to simulate the system in its entire
operational domain, with all its different modes. Performance sensor models
represent the way in which the sensor operates and interacts with the GNC
system, in terms of performances, consumed resources, and physical limita￾tions. Thus, they are not focused on the operations, functions, and behaviors
of the sensor, but on the implications the performance of the sensor has on
the surrounding system. They are used to verify how the GNC system
works, highlighting potential bottlenecks of the design, given the perfor￾mance of the selected components. Performance models use equivalent
generic mathematical models, and they are commonly modeling only the
principal and the most influent characteristics of the sensors.
Sensors 255Functional and performance sensor models are the most used for GNC
design, analysis, simulation, and verification. In fact, they respectively allow
to assess the detailed functionalities and the overall performance of any
element of the system. Moreover, specific analyses and verification proced￾ures may require a combination of the features of the aforementioned sensor
models. For example, an operational-functional sensor model can be used to
verify with great accuracy a GNC subsystem in diverse operative modes. In
addition, there are very specific and application-oriented sensor models for
telemetry and telecommand (TMTC),i.e., models to generate sensor telem￾etry packets or react to telecommands, or for failure mode, effects, and crit￾icality analysis (FMECA) analyses, i.e., models to simulate faults or effects
due to failures.
Sensor model’s interfaces need to be defined according to the specific
type of model in use and considering the desired application. The interfaces
of the sensor model determine the input/output of the system simulator,
which is used for GNC design and verification, and their fidelity level shall
be selected accordingly. In fact, the sensor model’s interfaces may be formed
by representative engineering data or by the raw sensor data. The former are
numeric values, whose data format is not relevant for the specific applica￾tion, and they are directly used by the algorithms in the mathematical for￾mulas. The latter are representative of the raw values, as communicated
by the real sensor hardware with a specific data format. Thus, they need
to be processed and converted in the desired format for the following oper￾ations. For this reason, raw sensor data interfaces are typically used when the
complete GNC verification is of interest, with particular focus on the veri￾fication of GNC software components. Alternatively, engineering data are
handy when the GNC design is on-going, and the analyses are focused
more on the GNC algorithms performance than on the final development
and implementation.
Sensor models are exploited both in accelerated and in real-time simu￾lators. Accelerated simulations typically support the early development
and verification stages, while the real-time models are integrated in dedi￾cated testing benches to verify the latest hardware and software develop￾ments, as will be extensively discussed in Chapter 12 e GNC Verification
and Validation. It is convenient to implement a model having in mind
both applications, since it is very common to port the model from the accel￾erated simulation environment (e.g., MATLAB/Simulink) to the real-time
one. In these regards, the requirements for the real-time model (e.g.,
compatibility with auto-coding techniques, compatibility with real-time
256 Andrea Colagrossi et al.target and execution) should be considered since the beginning of the devel￾opment in the accelerated simulation environment. The two typologies of
simulated models shall be validated together to confirm that they produce
the same results, and they have the same temporal evolution. In particular,
the execution order of the accelerated simulation shall be carefully checked
to ensure coherence with the real-time application. This last point may be
facilitated if the sensor model is developed using atomic unit blocks [1] in
accordance with the real sensor processing steps.
Like any other part of a GNC system, the sensor models shall be vali￾dated, meaning that they shall be truly representative of the real sensor
component. The validation campaign shall be focused both on the short￾time and on the long-time evolution of the sensing process errors and effects,
noting that the long-time ones have a deeper impact on the GNC perfor￾mance. Ideally, the validation should also address the variation of the sensor
behavior with the external environment (e.g., temperature, pressure, accel￾eration state). A sensor model is typically developed exploiting the data
available in the datasheets and in the documentation provided by the pro￾ducer. However, in the later stages of the GNC development and verifica￾tion, the model parameters must be updated in accordance with real
measured sensor data. Note that the data obtained from the exact flight
model of the sensor installed on the spacecraft should be used for a thorough
and comprehensive validation campaign.
The primary use of the sensor models is the support of GNC design and
verification emulating the presence of the sensors to be installed on-board.
However, the sensor models are also directly used in the GNC blocks. For
instance, guidance functions to calibrate or initialize sensors, navigation fil￾ters measurement models, control methods to reduce effects disturbing a
particular sensor rely on a correct modeling of the sensor measurements.
Hence, as will be discussed in Part 2 e Spacecraft GNC, it is common to
use dedicated sensor models or specific sensor variables directly inside the
GNC functions.
Elements of metrology
Sensors convert the physical quantity to measure into an electrical signal
following a predefined sequence of transduction and processing steps, which
Sensors 257is denoted as sensor acquisition chain. It depends on the actual implementa￾tion of the specific sensor, but it is generally composed by:
• Transduction.
• Conditioning.
• Analog-to-digital (AD) conversion.
• Calibration and transmission.
Transduction is the process of converting the physical property into the
corresponding electrical signal. Conditioning is needed to process the trans￾duced sensor signals into a form that can be converted to digital values, and it
is typically composed by signal filtering, amplification and shaping, and line￾arization. AD conversion allows the digitalization of the conditioned electri￾cal signals by converting the analog input voltage or current to a digital
number representing the magnitude of the voltage or current. Then, the
digital signal can be calibrated to convert back the electrical data into the
equivalent physical quantity that has been measured. Finally, the calibrated
digital signals are encoded and formatted to reduce transmission errors and to
guarantee compatibility with the communication protocol of the sensor.
Fig. 6.1 summarizes a generic sensor acquisition chain. Note that sensors
for space applications commonly transmit their data by exploiting typical
communication interfaces, such as Universal [Synchronous and] Asynchro￾nous Receiver-Transmitter (U[S]ART), Serial Peripheral Interface (SPI),
Inter-Integrated Circuit (I2C), Controller Area Network (CAN), etc.
Sensors can measure absolute quantities or differential ones. In the first
case, which is the most common for spacecraft applications, the sensor is
designed to seek the “true” value of the physical quantity to measure. While,
in the case of differential sensors, the measurement is performed to seek a
deviation with respect to a “reference” value. This is done to minimize sys￾tematic errors, which are affecting both the reference and the differential
measurements. Note that in absolute sensors, the measurement error is the
deviation between the obtained measurement result and the true value,
while differential sensors have the errors affecting the difference between
Figure 6.1 Sensor acquisition chain.
258 Andrea Colagrossi et al.the reference and actual measurements. As a result, good differential mea￾surements can be obtained even with a system of poor quality. Anyhow,
the following discussion will be focused on absolute sensors.
Measurement errors, εð Þt , are impossible to be exactly known, but they
can be assessed under a statistical perspective. Thus, we shall introduce the
concept of measurement uncertainty, which gives us information about
the amount of measurement error that is likely to occur. The measurement
uncertainty is defined as a “nonnegative parameter characterizing the disper￾sion of the quantity values being attributed to the measured physical quan￾tity” [2]. In fact, the measurement result is a random variable, which is
described by a probability density function that is typically bell-shaped
(i.e., normal statistical distribution). An ensemble of more measurement
results is centered at a certain statistical average value and dispersed according
to a statistical standard deviation (or variance). These two quantities are asso￾ciated to two concepts about sensors: accuracy and precision.
The output of the sensor is the measure, xð Þt ; which is, by definition,
different from the real measured quantity. The closer the measure is to
the real world, the more accurate the sensor is. Indeed, the accuracy of a
sensor is how close the measurement is with respect to truth (i.e., the dis￾tance of the statistical average value with respect to the true value). The pre￾cision of a sensor is the reproducibility with which a measurement is made
(i.e., the dispersion of the normal distribution, related to the statistical stan￾dard deviation). We shall not confuse the definitions of these two concepts,
visually represented in Fig. 6.2. Note that for each realization of the mea￾surement, there is a single resulting error value, which relates each measure
to the actual value according to Eq. (6.1). Hence, the statistical quantities
behind accuracy and precision combine themselves identifying the interval
containing the measurement result values.
In general, the main concepts characterizing the sensors are:
• Accuracy. The mean difference that will exist between the actual value
and the indicated value at the output of the sensor.
• Precision. The degree of reproducibility of a measurement, which is asso￾ciated to closeness between measured quantity values obtained by repli￾cate measurements on the same quantity.
• Sensitivity. The minimum input of the physical parameter that will create
a detectable output change, which is associated to the slope of the input￾to-output characteristic curve (i.e., output change for a given change in
the input).
Sensors 259• Range. The maximum and minimum values of the applied parameter
that will be measured.
• Resolution. The smallest detectable incremental change of input param￾eter that will be detected in the output signal.
• Offset (bias). The output that will exist when it should be zero.
• Linearity. The deviation the actual measured curve of a sensor will have
from the ideal input-to-output linear characteristic curve.
• Hysteresis. The difference the actual measured curve of a sensor will have
as a function of the input variation direction.
• Response time. The time required for a sensor output to change from its
previous state to a final settled value within a tolerance band of the cor￾rect new value.
• Dynamic linearity. The ability of a sensor to follow rapid changes in the
input physical parameter.
All the previous concepts characterize the behavior of the sensor, and
they shall be included in a proper sensor model.
Inferring from the previous discussion, we understand how precision is a
description of random errors (e.g., noise, instabilities) and accuracy is a
description of systematic errors (e.g., offset, imperfect calibrations). Before
entering the details of both error typologies, we shall focus on the funda￾mentals of probability and stochastic processes, and on the systematic errors
induced by a wrong calibration.
Figure 6.2 Sensor accuracy and precision.
260 Andrea Colagrossi et al.Probability and stochastic processes
Random errors require a statistical interpretation to be understood, and the
fundamental concept behind this is the probability. By definition, the prob￾ability of an event A to occur is defined by how likely this event is to happen
and it can be generally defined as:
PðAÞ ¼ number of times A occurs
total number of occurrences:
However, the probability of a given event A to occur can be also linked
to an event B that happened before. In this case, we talk about conditional
probability of A given B and we can define it as:
PðAjBÞ ¼ PðA; BÞ
PðBÞ
where PðA; BÞ is the joint probability of A and B and it describes the
probability that both A and B occur.
Random variables
Another very important concept to introduce when dealing with the statis￾tical interpretation of random errors is the one of random variable. A
random variable is a mathematical description of the outcome of random
events. In a broader sense, it can be seen as a variable mapping a set of
random events to a set of real values. The most interesting thing about
random variables is that they have associated properties very useful in the
domain of probability and statistics. In particular, one of the most important
quantities associated to a random variable is the probability distribution func￾tion (PDF), defined as:
FXðxÞ ¼ PðX  xÞ
with, in this case, X being a generic random variable and x a nonrandom
variable or constant. Similarly, the probability density function (pdf) can be
defined as:
fXðxÞ ¼ dFXðxÞ
dx :
Also for random variables, conditional quantities can be defined, given
that a certain event A has occurred:
FXðxjAÞ ¼ PðX  xjAÞ;
fXðxjAÞ ¼ dFXðxjAÞ
dx :
Sensors 261In order to quantify the average value of a given random variable over a
large number of experiments, it is necessary to introduce the concept of ex￾pected value. The expected value of a random variable X, or mean of X, is
defined as:
EðXÞ ¼ m ¼ 1
N
Xm
i¼1
Aini ¼
Z
N
N
xfXðxÞdx
where N is the number of total experiments, m is the total number of
possible different outcomes, and Ai is a given event occurring ni times. Please
recall that fXðxÞ is the pdf of X. Using the definition of expected value, it is
possible to also define the concept of variance. The variance of a random
variable is a measure of how a given random variable will vary from its
expected value or mean. The variance of a given random variable X is
defined as:
s2
X ¼ E

ðX  mÞ
2
¼
Z
N
N
ðx  mÞ
2
fXðxÞdx
where sX is also known as standard deviation of a random variable.
In general, a random variable X can be defined as Xw
m; s2

, having
mean m and variance s2.
Different types of random variables and PDFs exist and have been cate￾gorized in statistical literature [3]. Here, we will recall the most important
ones for spacecraft GNC applications.
Uniform random variables
A uniform random variable has, by definition, a pdf that is constant between
two limits a;b. In practical terms, the random variable X has an equal prob￾ability of assuming any value in the interval defined by the pdf limits and
zero probability outside the interval. In a mathematical way, it is defined as:
fXðxÞ ¼
8
<
:
1
b  a
x ˛ ½a;b
0 otherwise
A graphical representation of a uniform distribution is shown in Fig. 6.3.
262 Andrea Colagrossi et al.Gaussian random variables
A random variable is defined Gaussian or normal if its pdf is expressed as:
fXðxÞ ¼ 1
s ffiffiffiffiffi
2p p e

ðxmÞ2
2s2

The graphical representation of a zero-mean Gaussian normal distribu￾tion with unitary variance is reported in Fig. 6.4.
An important consideration about Gaussian random variables is that,
with this distribution, the variable will have 68% of probability to assume
a value:
X ¼ m  1s
In other words, there will be 68% odds for the variable to lie within one
standard deviation from the mean, 95% of odds to lie within two standard
deviations from the mean, etc. It is a normal practice to define the error
as being specified at 1s, or, more conservatively, at 3s, or whichever level.
Recalling Fig. 6.2, it can also be interpreted as the likelihood for the error to
assume that value. As an applicative example, if the designer models the
random error as a constant noise with its 3s value, it means that it will over￾estimate the actual error 99.7% of the times.
Figure 6.3 Uniform distribution.
Sensors 263Stochastic processes
The variation of a random variable in time can be represented through a sto￾chastic process. A stochastic process XðtÞ describes the variation in time of a
random variable X. As previously done for a random variable, PDF, pdf and
expected value of a stochastic process can be defined. In particular, the PDF
takes the form of:
FXðx; tÞ ¼ PðXðtÞ  xÞ
and for the pdf:
fXðx; tÞ ¼ dFXðx; tÞ
dx :
Similarly:
EðXðtÞÞ ¼ m ¼
Z
N
N
xfXðx; tÞdx
s2
X ¼ E

ðX  mÞðX  mÞ
T 
¼
Z
N
N
ðx  mÞðx  mÞ
T fXðx; tÞdx
While talking about stochastic processes, if a random variable at a given
time t1 is not dependent on its value at another instant of time t2, we call this
stochastic process as white noise. Otherwise, we talk about colored noise,
-4 -2 0 2 4
x
0
0.1
0.2
0.3
0.4
pdf(x)
pdf
1
2
3
Figure 6.4 Gaussian or normal distribution.
264 Andrea Colagrossi et al.with different types of colors depending on the stochastic process power
spectrum. These concepts will be deepened in the following of this chapter,
when discussing about sensor noise and random errors. Moreover, the reader
is invited to extend its knowledge on statistical methods in literature refer￾ences [3,4] and in the appendix Chapter 16 e Mathematical and Geomet￾rical Rules.
Sensor calibration
Sensor calibration is crucial for GNC applications, since a good calibration
campaign can minimize most of the systematic errors, improving the sys￾tem’s accuracy up to the best nominal accuracy of the selected sensors. It
should be remarked that the usage of accurate sensors without a proper cali￾bration is a huge mistake under the engineering perspective and a waste of
resources under the programmatic perspective. Sensor calibration is the
comparison of measurement values delivered by the sensor with those of a
calibration reference standard. Strictly speaking the calibration definition
does not include the adjustments to improve the measurement accuracy,
but it is commonly implied that the calibrating adjustments are performed
along the calibration procedures. Spacecraft sensors are calibrated to remove
statistical biases introduced by mounting errors, axis misalignments, temper￾ature dependencies, geometrical distortions, environmental influences, scale
factors, nonlinearities, and other potential sources of systematic errors. A
complete calibration can be very complex, and a trade-off shall be per￾formed between achievable accuracy and calibration effort. Note that a per￾fect calibration is practically not achievable because of the intrinsic finite
accuracy of the calibration reference standard and the finite precision of
the sensor. Moreover, it is suggested to have a calibration effort that is
coherent and balanced with the precision of the sensor, the overall accuracy
of the other sensors on the spacecraft, and the required accuracy of the GNC
system.
The calibration shall be performed on-ground during the GNC devel￾opment, especially for those errors related with the assembly and integration
phases (e.g., misalignments, distortions). However, any calibration is not
perpetual, and successive recalibrations shall be performed at prescribed in￾tervals of time. If this is very common and standardized for Earth applica￾tions, the same is not true for spacecraft due to the physical inaccessibility
of the platform. So, we should integrate calibration standards on-board or
use the known space environment e or the spacecraft dynamics e as
Sensors 265calibrating references. In any case, on-board sensor calibration is suggested
for those applications looking for a high accuracy. It can be performed at
discrete intervals, or it can be continuously executed. Navigation and esti￾mation functions are capable to quantify biases on-board to recalibrate the
sensors, as will be discussed in Chapter 9 e Navigation and in the on￾board sensor calibration of Chapter 14 e Applicative GNC Cases and
Examples.
Errors modeling
Sensor models for GNC applications are based on mathematical models of
the processes along the sensor acquisition chain. They take as input a simu￾lated physical signal, and they are set to output the sensor measurements.
The format and the characteristics of the output depend on the typology
of sensor model, which also influences the way in which the internal pro￾cesses are modeled. As said, the most complete functional models include
almost every step of the acquisition chain, as shown for a generic functional
sensor model in Fig. 6.5. Note that other typologies of sensor models may be
composed by equivalent subsets of the blocks used for a functional model.
With reference to Fig. 6.5, the most relevant systematic and random er￾ror sources for spacecraft sensors are:
• Bias or zero offset errors.
• Scale factor errors.
• Noise or random fluctuations errors.
• Quantization or resolution errors.
• Misalignment and nonorthogonality errors.
Moreover, other sensor processing phenomena exist, and even if they
cannot be defined as errors, they shall be included in proper sensor models:
• Time delays and latencies.
• Maximum range or output saturation.
• Output temporal discretization.
The sensor acquisition chain is also influenced by the environment (e.g.,
temperature, acceleration, radiations, etc.). The environmental influences
Figure 6.5 Generic functional sensor model example.
266 Andrea Colagrossi et al.are not immediately evident from the previous discussion, since the changes
in the external environmental conditions affect the sensor output in an in￾direct way. That is, the previously listed error terms are dependent from
the external environment. For example, the bias and the scale factor errors
may be dependent from the accelerations, the noise may vary as a function of
the temperature, or other similar dependencies. In general, the cross talk be￾tween potentially interacting physical quantities (e.g., acceleration, magnetic
field, angular velocity, temperature, etc.) shall be carefully investigated and
accounted during the implementation of the sensor models.
Sensor models may be also influenced by additional aspects, such as ag￾ing, contamination from pollutant, light source reflections, and occultations.
Thus, also these effects shall be modeled and considered, if relevant for the
specific application.
Finally, note that sensors whose processing is dependent from the time
(e.g., GNSS sensors) may be subject to indirect errors because of clock inac￾curacies or time deviations with respect to the universal timing.
The most relevant error terms are briefly described in the followings,
whose modeling numerical parameters are commonly found in the datasheet
of the sensor.
Bias
Measurement bias is a systematic error that set an offset in the output signal
with respect to the actual physical value. Typically, bias randomly varies at
each start-up of the sensor, and it is influenced by the external environment.
It is assumed to be constant or slowly varying in time, and its temporal fluc￾tuations are categorized within the random error sources. It is one of the er￾ror sources most prone to be minimized, thanks to calibration.
Its mathematical model is:
u ¼ u þ b;
where b is randomly selected for each simulation around the nominal value
stated in the sensor’s datasheet.
Scale factor errors
Scale factor errors are a class of systematic errors that are proportional to the
magnitude of the input signal. Scale factor errors may be of linear, nonlinear,
or asymmetric type. Linear scale factors (or just scale factors) introduce a
nonunitary slope coefficient between output and input. Nonlinear scale
Sensors 267factors are proportional to the square, or higher order terms, of the input,
and they let the output curve deviate from a straight line. Asymmetry scale
factors are proportional to the absolute value of the input, and they create an
angle in the output curve close to the zero value. Scale factors may be influ￾enced by the external environment, especially temperature, and should be
modeled in the entire operative range of the sensor. Calibration techniques
are effective in reducing scale factor errors.
Scale factor models can be mathematically described as:
u ¼ u þ SFu þ SFNu2 þ SFAjuj;
where SF, SFN, andSFA, are, respectively, the linear scale factor, nonlinear
scale factor, and asymmetry scale factor coefficients. These coefficients are
usually expressed in parts per million, PPM. Note that 1 PPM corresponds
to 106 ¼ 0.0001% of the input value.
Noise and random errors
Random errors are nonsystematic errors that influence any sensor, since they
are intrinsically related to the stochastic nature existing in real-world appli￾cations. Because of their fundamental property, they are impossible to be
fully compensated and a residual stochastic measurement error is present
in any measure. In fact, the only way to reduce the effects of random errors
is to average the measure from a large set of measurements. This is not always
possible, since this procedure introduces a delay in the measurement process￾ing that may be not acceptable for the specific GNC application. We will
refer to noise alternatively to random error or stochastic process. In general,
noise is used as a generic term to indicate any undesired errors generated by a
stochastic process.
Random errors shall be described in terms of their statistical parameters,
since a deterministic description is ontologically not possible. They can be of
various typologies, but they are always characterized by an unpredictable and
not replicable time evolution. Thus, they are associated to a standard devi￾ation, s, or variance, s2, but they commonly have null average because con￾stant errors are taken into account together with bias errors. The probability
distribution of random measurement errors is typically well approximated by
a Gaussian normal distribution since, according to the central limit theorem,
they are the result of the sum of many independent random variables. This
can also be seen in Fig. 6.6, where a noise signal with s ¼ 3 is sampled for
100 s at 100 Hz. From the figure it can be seen how the noise signal samples
268 Andrea Colagrossi et al.are well fitted by a normal distribution with the same standard deviation. As
a result, w68% of the samples are within the s interval (i.e., ½ 3; 3), while
w99:7% of them are contained in the 3 s interval (i.e., ½ 9; þ9). Indeed,
almost all the samples have an absolute value lower than 10.
Random errors are also associated with different frequencies of the sto￾chastic process behind them, and their resulting output can be generally
identified by analyzing their power spectrum. A signal whose spectrum
has equal power (i.e., intensity) within any equal interval of frequencies is
defined as white noise; its power spectral density is constant. White noise
is the most common noise source in sensor measurements, since it is usually
introduced by the electronic sensor processing. However, there exist other
random errors with a frequency spectrum that is not constant. They are
defined as colored noises, and according to the shape of their power spectral
density, they are associated with a color. For instance, pink noise has a power
spectrum which decreases linearly in the logarithmic scale, while blue noise
increases. Other colors may be defined, but they cannot be generalized. The
most common noises that are relevant in sensor modeling are:
Figure 6.6 Noise signal with s ¼ 3.
Sensors 269• White noise.
• Pink noise, or flicker noise, power spectral density decreases proportion￾ally to 1=f , where f is the frequency.
• Brown noise, or Brownian noise, or red noise or also identified as
random walk noise power spectral density decreases proportionally to
1
	
f 2, and it is the noise associated with the random walk errors affecting
many digital sensors. Brownian noise can be generated with temporal
integration of white noise.
An example of these noise sources with s ¼ 10 is reported in Fig. 6.7, in
terms of their signal sampled for 1000 s at 100 Hz, and their power spectral
density.
Noise modeling shall exploit random number generators from a normal
distribution, defining the standard deviation and a parameter, usually
denoted as seed, to initialize the random generator. Note that seed values
shall be different between different components in the model, and there
should be the possibility to change their value at each simulation to avoid
simulating always an identical scenario. The plain normal random generator
can model a white noise source. Filtering the random number generator’s
output can be used to simulate colored noise. For example, a low-pass filter
with a power roll-off of 3 dB per octave (i.e., the signal power reduces by a
factor of 2 every time the frequency doubles) can be applied to a random
number generator to model a pink noise. Similarly, a low-pass filter with
a power roll-off of 6 dB per octave can be used to model a brown noise.
Figure 6.7 White, pink, and brown noise and their power spectral densities.
270 Andrea Colagrossi et al.The low-pass filter should be set with a cut-off frequency at 3 dB as low as
possible in order to be applied on the entire frequency spectrum. The cut-off
frequency may be slightly varied to precisely tune the noise frequency con￾tent. Note that brown noise can be also modeled with a time integrator
placed at the output of the random number generator. This is commonly
done to model bias instabilities and fluctuations in scale factor errors.
Example noise models are shown in Fig. 6.8.
Noise amplitude is tuned by varying the standard deviation in the
random number generator. However, sensor datasheets do not frequently
report this value, and the fine tuning of the sensor model shall be supported
by sensor characterization testing activities. This is especially true for colored
noise terms. Noise density is more often reported on the datasheets. In fact,
the actual noise amplitude frequently depends on the sampling time of the
sensor. Let’s assume the noise amplitude, A, expressed in the units of the
measured quantity, u, then the standard deviation of the normal random
numbers shall be:
s ¼ A u.
The noise amplitude density, D, is measured in units over the square root
of the frequency, f (i.e., u= ffiffiffiffiffiffi
Hz p ), and it can be related to the amplitude as:
A u ¼ D
ffiffiffi
f
2
r
¼ D
ffiffiffiffiffiffiffi
2Ts
p ;
where Ts is the sampling time of the sensor.
Figure 6.8 Noise models.
Sensors 271Random errors with uniform distribution
The Gaussian normal distribution is not the one for all PDF, since stochastic
processes may be distributed according to different PDFs. As said, Gaussian
distribution is important for engineering applications because of the central
limit theorem, which states that, when measuring real-world data, the
different measured values tend to produce a final distribution that is approx￾imately normal. Generally, the more a measurement is like the sum of inde￾pendent variables with equal influence on the result, the more normality it
exhibits. Indeed, we can often regard a single measured real-world data
value as the weighted average of many small independent effects.
However, there are situations in which this condition does not hold, and
the random errors shall not be modeled by exploiting the normal distribu￾tion. Binomial distribution, Poisson distribution, uniform distribution,
exponential distribution, and the Weibull distribution are examples of alter￾native PDFs. The former two are often used to represent the statistical dis￾tribution of discrete data, while the latter applies to continuous valued data
[4]. They are often used in various specialized applications, but the most
relevant among them for spacecraft GNC is the uniform distribution.
The uniform distribution was introduced before in the random variables
section, and it is used to represent those data in which every value within a
certain interval has the same probability to occur. For instance, the position
of the center of mass during the design process of a spacecraft will be typi￾cally assumed to fall inside a box with uniform distribution, since any point
within the acceptability range has the same probability to occur. Similarly,
the uncertainties on the values of other geometrical or inertia properties
of the spacecraft are commonly represented with a uniform distribution.
In the same way, if the GNC design considers an initial condition for the
spacecraft attitude dynamics after the deployment from the launcher, these
are typically uniform in terms of the attitude states. In fact, all the rotations of
the body frame with respect to the inertial one are possible.
In general, for any random variable, the GNC designer shall select the
proper PDF. As a rule of thumb, measured real-world data are normally
distributed, while the uncertainties in the system parameters or the un￾known initial conditions are uniformly distributed within the acceptability
ranges.
Quantization errors
Quantization error is a systematic error resulting from the difference be￾tween the continuous input value and its quantized output, and it is like
272 Andrea Colagrossi et al.round-off and truncation errors. This error is intrinsically associated with the
AD conversion that maps the input values from a continuous set to the
output values in a countable set, often with a finite number of elements.
The quantization error is linked to the resolution of the sensor. Namely, a
high-resolution sensor has a small quantization error. Indeed, the maximum
quantization error is smaller than the resolution interval of the output, which
is associated to the least significant bit representing the smallest variation that
can be represented digitally:
LSB ¼ FSR
2NBIT
where FSR is the full-scale range of the sensor, and NBIT is the number of
bits (i.e., the resolution) used in the AD converter to represent the sensor’s
output. Quantization errors are typically not corrected, and the discrete
values of the output are directly elaborated by the GNC system, which is
designed to operate on digital values.
Fig. 6.9 shows a convenient model block to simulate quantization errors.
Misalignment and nonorthogonality errors
Misalignment and nonorthogonality errors are systematic errors due to
mounting errors of the sensor, internal misalignment in the sensor’s axes,
or nonorthogonality between the different axes of an N-dimensional sensor.
These errors can be easily minimized via ground calibration during the
testing phase on the integrated spacecraft. However, residual and unknown
misalignment and nonorthogonality are anyway present in the sensor mea￾surements. Misalignment makes a measure to be not correctly associated to a
nominal reference axis. Nonorthogonality determines a cross-axes sensi￾tivity, since a physical quantity along an axis has nonzero spurious measured
components also on the other axes of the sensor. Moreover, the nonortho￾gonality errors typically account also for the cross-axes electrical interference
between the different axes of the sensors.
Figure 6.9 Quantization error model.
Sensors 273Misalignment and nonorthogonality errors are mathematically repre￾sented by multiplying the physical signal by rotation, R, and nonorthogonal,
O, matrices, respectively:
u ¼ ORu.
The rotation matrix, R, is an orthonormal matrix rotating the physical
signal into the sensor misaligned axes by a set of random error angles. These
misalignment angles are usually very small (i.e., m), especially if the sensor is
carefully calibrated. The nonorthogonal O matrix may be computed by
multiplying a lower-triangular matrix with a symmetric one [5]; they result
in a matrix with almost unitary components on the diagonal and small
random values on the lower and the upper nonsymmetric triangular blocks.
The small random values are in the order of the nonorthogonality or cross￾axes errors, which are commonly expressed in percent units (i.e., 5% corre￾sponding to about 0.05 cross-axes contribution).
Output saturation, temporal discretization, and latencies
Sensor’s outputs are also characterized by saturation, temporal discretization,
and time delay, or latency, with respect to the physical input.
Output saturation is simply related to the maximum dynamic range of
the sensor: an input value larger (or smaller) than the maximum (or mini￾mum) range saturates the sensor’s output. It can be modeled by including
a saturation in the sensor model. Output saturation should not create prob￾lems in GNC application, since sensors are usually selected to have a greater
dynamic range with respect to the expected dynamic ranges of the measur￾able quantities.
Temporal discretization of the output is due to the discrete time opera￾tions of a real GNC system, which interrogates the sensor at discrete intervals
of time. Thus, this phenomenon can be modeled by maintaining a constant
output between two discrete time intervals. Temporal discretization fre￾quency of the measurements shall be compatible with the intended oper￾ating frequency of the GNC.
Latency is due to the internal processing, and it is typically quantified
with ground testing. This effect can be modeled including a delay in the
sensor model, and it is particularly relevant for applications with stringent
synchronization requirements or with many sensors sampled at different in￾stants of time.
Fig. 6.10 shows common model blocks used to represent these effects.
274 Andrea Colagrossi et al.Sensor faults
Sensor faults have a critical impact on the GNC system. A faulty
sensing unit may introduce wrong measurements in the GNC loop, leading
to navigation errors bringing the system off the reference state. Similarly, the
loss of a sensor may bring the spacecraft in a critical error state, where the
complete functionality of the spacecraft may be not guaranteed. For these
reasons, the GNC design shall take into account possible sensor faults, and
it shall comply with unexpected on-board failures. Ideally, these undesired
events shall be detected by the GNC itself, which shall also react to minimize
their impact on the whole spacecraft. These points will be addressed in
Chapter 11 e FDIR Development Approaches in Space Systems, but
here a brief summary of the most common typologies of sensor faults is
reported.
Sensor faults are classified and listed according to their impact on the sen￾sor’s output [6,7]. The most common are:
• Spike fault. Spikes are observed in the output of the sensor.
• Erratic fault. Noise of the sensor output significantly increases above the
usual value.
• Drift fault. The output of the sensor keeps increasing or decreasing from
nominal state.
• Hardover/bias fault. The output of the sensor has a sudden increase or
decrease with respect to the nominal state.
Figure 6.10 Latency, output saturation, and temporal discretization.
Sensors 275• Data loss fault. The output of the sensor has time gaps when no data are
available.
• Stuck fault. The sensor’s output gets stuck at a fixed value.
Fig. 6.11 reports their typical appearance in a generic sensor’s output.
It shall be noted that sensor models shall be also capable to reproduce the
possible faults that may occur while on orbit. Hence, sensor faults need to be
simulated in order to reproduce some failure scenarios that resembles real￾life faults and failures by utilizing the concept of fault injection into the
simulated system.
Orbit sensors
Orbit sensors are used to measure position and velocity of a satellite by
using different signals and technologies. When position and velocity mea￾surements are available, they can be used to estimate the current orbital state
and, possibly, to propagate the spacecraft position forward in time. Orbit
Figure 6.11 Typical sensor faults appearance, adapted from Colagrossi and Lavagna
[7].
276 Andrea Colagrossi et al.sensors belong to two main typologies: on-board or on-ground. The former
enables autonomous GNC, since the measurements are directly available on
the spacecraft, while the latter requires the ground support, with the upload
of the measured position and velocity during the telecommunication
windows.
The orbit sensors a given spacecraft can carry strongly depend on the
mission and the spacecraft itself. For instance, the use of GNSS receivers is
not useful for a Mars mission since GNSS satellites can only provide their
signals to receivers below GNSS orbits (except for very weak signals), but
it would provide a great solution for orbit determination for low Earth orbit
(LEO) satellites. Therefore, when selecting the sensors suite for a given sat￾ellite, it is essential to have in mind the operational orbit and characteristics
of the spacecraft. As a general consideration, on-board orbit sensors (e.g.,
GNSS) provide a higher level of autonomy with respect to on-ground sen￾sors at the cost of limited applicability domain. In fact, on-board sensors are
usually limited to Earth-orbit scenarios where the lower complexity of the
mission and the available technologies allow for precise and autonomous
orbit determination. On the contrary, the complexity to enable interplane￾tary orbit determination usually drives the sensor selection toward on￾ground solutions. In fact, they are general and not limited to Earth scenarios,
but they add operational costs, delays, and lack in autonomy.
Thus, the different types of orbit sensors can be classified depending on
the autonomy and the applicability range of the navigation solutions that can
be obtained by using them. In this section, on-board GNSS sensors and on￾ground orbit determination with ground station networks (GSNs), along
with their corresponding sensor technologies are discussed.
GNSS sensors
GNSS sensors allow a satellite or, generally speaking, any object that is
below the GNSS satellites orbits (e.g., a smartphone on Earth surface) to
determine its position by using the signals generated by the GNSS constel￾lation satellites next to the ephemerides of those satellites.
GNSS basics
GNSS refers to a constellation of satellites that provides signals to receptors
(that can be on land, sea, air, or even in space) with information of position
and time for them to being able to determine their location. Taking into ac￾count the time it takes to signals to go from the emitting satellites in the
constellation to the receptors and knowing their detailed position, it is
Sensors 277possible to obtain a range measurement between the emitter and the recep￾tor. If enough signals are received, the GNSS receptor can estimate the state.
There are different sets of constellations that provide global coverage, from
which we can remark:
• GPS [8]: GPS is the oldest and more known GNSS constellation. It was
designed and built, and it is currently operated and maintained by the US
Department of Defense. It consists of 24 satellites, spread in 6 different
orbital planes with four satellites each. The orbits semimajor axis is
26,578 km, and they have an inclination of 55.
• GLONASS [9]: GLONASS is the GNSS managed by the Russian Space
Forces, and it is operated by the Ministry of Defense of the Russian
Federation. It consists of 21 satellites divided in 3 planes with seven sat￾ellites each. Satellites operate in nearly circular orbits with a semimajor
axis of 25,510 km and an inclination angle of 64.8.
• GALILEO [10]: GALILEO is the GNSS satellite constellation from the
European Union and the European Space Agency with the objective of
providing a very high-accuracy global positioning system under civilian
control. The GALILEO constellation consists of 30 satellites in medium
Earth orbit (MEO) orbit in three orbital planes with 9 satellites per orbit
(plus one spare). Orbits are quasicircular with a semimajor axis of
29,600 km and 56 of inclination.
• BEIDOU [11]: BEIDOU is the satellite constellation from China. It
consists of 35 different satellites, divided in different planes and orbit re￾gimes. From the 35 satellites in the constellation, 8 are in geostationary
regime (five in geostationary orbit [GEO] orbit and other three in in￾clined GEO) and the other 27 are MEO satellites that allow for complete
coverage.
Apart from the global satellite positioning constellation, there are other
systems that provide regional coverage in order to increase the accuracy
and improve the performance of the global navigation systems, such as
EGNOS or QZSS.
EGNOS is a European regional satellite-based augmentation system that
uses GNSS measurements taken by accurately located reference stations
deployed across Europe to improve the reliability and the accuracy of the
GNSS positioning data [10].
QZSS or “Quasi-Zenith Satellite System” is a regional augmentation
system for the AsiaePacific region, especially focused on Japan, which is
the developing country of the system. The QZSS system consists of 4
278 Andrea Colagrossi et al.satellites in inclined GEOs that allow a complete regional coverage and
enhancement of GNSS [12].
GNSS signals
The main objective of a GNSS satellite is to transmit a signal that is then
received by a user and interpreted to extract position and velocity informa￾tion. The transmitted signal has a frequency in the radio spectrum of about
1.2 and 1.6 GHz (L1 ¼ 1.575 GHz, L2 ¼ 1.243 GHz, L5 ¼ 1.176 GHz)
with a peculiar code modulation. In fact, pseudorandom noise code modu￾lation is used on the harmonic radio wave (carrier). As the name suggests,
this modulation has no evident pattern and it consists of a defined random
sequence of zeros and ones, repeated at a given time interval and it serves
as ranging code. Furthermore, a broadcast navigation message is transmitted
along with the ranging code but at a lower rate. This navigation message
provides information on the orbit and clocks of the transmitting satellites.
More information can be found in Ref. [13].
The receiving user can interpret the GNSS signal data and extract three
types of measurements:
• Pseudorange: given the time of the receiver clock at signal reception tR
and the time of satellite clock at signal transmission tT , their difference
scaled by the speed of light c can be used to construct a range
measurement:
P ¼ cðtR  tT Þc
• Carrier phase: a direct measurement of the signal phase can be used as
more precise measurement. First, the code modulation has to be
removed to recover raw phase, then, the phase should be tracked to re￾cord the number of cycles. Phase information is usually more precise than
pseudorange, but its initial value generates an integer ambiguity NR. If
the phase tracking is lost, the carrier phase measurements exhibit a cycle
slip. A simple measurement equation considering the phase of the
receiver FR and the phase of the transmitted signal FT is:
F ¼ FRðtRÞ  FT ðtRÞ þ NT
R
• Doppler: the well-known Doppler effect causes a change in the received
frequency. A direct measure of this change provides information on the
line-of-sight velocity.
Sensors 279In this chapter, a simple introduction to GNSS signals is provided. For
additional details on the GNSS measurements modeling, including all the
relevant error effects, please refer to Chapter 9 e Navigation.
GNSS receivers
A GNSS receiver is typically mounted in LEO satellites to perform orbit
determination. The GNSS receiver can provide position, velocity, and
timing data (among others, such as pseudorange and carrier phase informa￾tion depending on the specific receiver) that allows tracking the satellite state
along the orbit. Satellites in other orbital regimes such as MEO or GEO can
make use of GNSS receivers [14], and there have been different projects to
study the possibility of using GNSS signals to perform navigation around the
Moon, even though the precision is not as high as the one for receivers in
LEO orbit and below [15].
The GNSS receivers incorporate an antenna to get the signal provided
by the different GPS satellites. In principle, having three satellites in view
would be enough for the receiver to determine the exact position in
three-dimensional (3D) space, see Fig. 6.12. The received signals include
Figure 6.12 Triangulation scheme from three different satellites.
280 Andrea Colagrossi et al.the exact timestamp of when they were generated. Therefore, by consid￾ering the generation time and the reception one, it is possible to determine
the distance between the GNSS satellite that transmitted the signal and the
receiver. If at least three satellites are in view of the receiver, by means of
triangulation, it is possible to determine the position of the satellite with a
few meters error. In modern GNSS navigation, a minimum of four satellites
is usually considered to perform orbit determination.
It is important to mention that, in order for a spacecraft to being able to
determine the distance with respect to the GNSS satellite, it is mandatory to
know the position of the GNSS satellite itself. A set of ground stations is
constantly monitoring and obtaining orbit determination solutions of the
GNSS satellites. These orbital data are stored by using numerical parameters,
and they are available on the GNSS satellites in the GNSS ephemerides and
almanacs data. The ephemerides are broadcasted by the GNSS satellites in
near real time, and they are updated at a frequency of few hours. The ephe￾merides allow the receiver to determine its position with respect to the sat￾ellite of the constellation in view.
However, there is an extra factor to be taken into account when deter￾mining the position from GNSS satellites: clock errors. GNSS satellites are
equipped with high precision atomic clocks to maintain tracking of time,
but receivers cannot be equipped with these types of clocks, since it would
make them extremely expensive. For this reason, it is necessary to have a
fourth satellite in view of the receiver to solve for the extra variable, time,
and provide with an accurate solution of the localization problem.
GNSS accuracy
The accuracy of GNSS receivers is strongly related to the orbital regime of
the spacecraft. For LEO satellites, the use of GPS can provide orbital deter￾mination solutions with errors in the order of few meters. For MEO, high
Earth orbit (HEO), and GEO satellites, the accuracy is reduced up to tens of
meters, and for GNSS-based orbit determination around the Moon, accu￾racy is in the order of hundreds of meters or even few km, depending on
the geometry of the mission and the characteristics of the spacecraft. A sum￾mary of the expected accuracy is reported in Table 6.1.
Multiconstellation GNSS receivers
Multiconstellation GNSS receivers can get and process signals coming from
different GNSS constellations (i.e., GPS, GALILEO, GLONASS, etc.) to
determine the spacecraft state. A multiconstellation GNSS receiver has the
Sensors 281advantage of having a greater number of satellites in view with respect to a
single constellation receiver. With the extra information provided by these
new satellites, the solution obtained is not only more accurate but also more
robust, since it is able to provide information even if the signal from a certain
satellite is blocked by the environment (e.g., parts of the spacecraft blocking
the antennas line of sight, Earth, etc.).
As opposed to older single constellation GNSS receivers (e.g., GPS re￾ceivers), in which four satellites in view are required to provide a solution,
the multiconstellation receivers require five satellites to be in view. Namely,
four of them are required to solve the position-time problem, and the extra
satellite is needed to calculate the time difference between two
constellations.
Table 6.2 summarizes the strengths and weaknesses of GNSS sensors
for spacecraft orbit determination. As already discussed, GNSS offers
high-accuracy measurements and autonomy capabilities. Furthermore, the
development for Earth-base applications offers several solutions and a
consolidated hardware design. On the contrary, the position of the GNSS
constellation satellites poses an intrinsic limit to the applicability of such
technology to orbits higher than GEO band.
GNSS sensor model
GNSS sensor models are based on the Earth-centered inertial (ECI) to
Earth-centered Earth-fixed (ECEF) reference frame conversion. The true
Table 6.1 Typical GNSS accuracy.
Scenario GNSS accuracydOrder of magnitude
LEO 100 m
MEOeHEOeGEO 102 m
Moon 103  104 m
Table 6.2 GNSS strengths and weaknesses.
Strengths Weaknesses
High accuracy Limited applicability regions (i.e., GNSS
constellations shall be in view)
Extensive development
Consolidated hardware design
Possibility of autonomous on-board
use
282 Andrea Colagrossi et al.inertial position and velocity, generated in an orbital propagator, are first
affected by a digital white noise and a drift brown noise, representative for
the internal GNSS signal electronic processing. Then, they are converted
in the Earth-fixed reference, which is the GNSS reference frame. A clock
model is also present, accounting for internal clock errors. All these quanti￾ties are delayed by a variable time latency and sent to output. The velocity
measurement is typically further delayed with respect to the position one;
this effect is included in the model as a dedicated velocity latency. An
example GNSS sensor model implementation in MATLAB/Simulink is
shown in Fig. 6.13.
Ground-based orbit determination
Ground-based orbit determination techniques are based on measurements
performed by ground stations on the spacecraft. This method usually relies
on the use of GSN, a set of ground-based antennas transmitting radio fre￾quency signals to the spacecraft. The most common measurements derived
from the processing of these signals are:
• Range: a measure of the range between a GSN station and the user space￾craft. Similarly, to GNSS measurements, the range is obtained consid￾ering the time it takes for a radio signal to travel from the GSN station
to the spacecraft and back to the station.
• Doppler: it represents a direct measurement of line-of-sight velocity of a
spacecraft relative to a tracking antenna. Please note that doppler mea￾surements don’t provide any information on position or velocity normal
to the line-of-sight [16]. Furthermore, the radio signals can be processed
in different ways:
Figure 6.13 GNSS sensor model.
Sensors 283• One-way: the spacecraft generates a downlink signal that is trans￾mitted to the GSN. The frequency of the signal is then compared,
on ground, against a locally generated frequency.
• Two-way: the GSN transmits a signal to the spacecraft. Then, the spacecraft
generates and downlinks a signal with a phase coherent with the received
signal. Finally, the GSN compares the received frequency with the same
reference frequency from which the uplink was generated.
• Three-way: the spacecraft is tracked by two stationsdone using a two￾way mode while the other using a one-way mode.
Please, keep in mind that two-way mode is usually employed for space￾craft navigation.
The basic radiometric measurements provided by the GSN can be also
augmented by exploiting the following measurements:
• Very Long Baseline Interferometry (VLBI)dD-DOR: even if it is not
considered as a basic measurement obtained by processing a radio signal,
GSN has provided VLBI data since 1980 [17]. The concept of VLBI (or
D-DOR) is to measure angular separation between a spacecraft and an
extragalactic radio source (quasars or galactic nuclei). This is done by pro￾cessing the radio waves coming from an extragalactic object (ideally close
to the spacecraft) and from the spacecraft, in two tracking stations that
have a large physical separation. By differentiating the delays of the
two incoming signals, the angular separation between the extragalactic
source and the spacecraft, in the direction perpendicular to the baseline,
can be obtained.
• Optical data: usually obtained from a scientific camera available on-board,
optical data provide a measure of the direction of a vector from the
spacecraft to a target body (e.g., planet, small body). The measured di￾rection can be combined with other range measurements to obtain a
complete 3D position of the spacecraft. Angular accuracy of 10 mrad is
expected.
• Altimetry: an altimeter provides a measure of the distance between the
spacecraft and a target body (e.g., planet, small body). When combined
with optical data, altimetry measurements can allow for a complete 3D
positioning of the spacecraft. Its operational envelope, however, is
limited to distances very close to target body, and, therefore, it is only
marginally useful for ground-based spacecraft orbit determination.
284 Andrea Colagrossi et al.In the case of on-ground orbit sensors, the needed infrastructure is usu￾ally divided into ground and space segments. This is different with respect to
on-board sensors, as the GNSS receivers, which allow obtaining an orbit
determination solution without involving ground in the loop.
Ground segment
The ground segment englobes all the ground-based elements of the infra￾structure required to perform orbit determination, such as ground stations,
mission control, ground network connecting the elements or terminals.
GSNs, such as Deep Space Network from NASA, or ESTRACK from
ESA, provide links between the satellites in orbit and the teams on ground.
They are in charge of sending and receiving signals with command, infor￾mation of spacecraft status as well as signals dedicated to navigation purposes
[18]. Moreover, the ground segment also includes all the navigation func￾tions to perform orbit determination and process the data to obtain space￾craft position and velocity estimates.
Space segment
Apart from the ground stations on Earth, extra elements are required, in this
case on the spacecraft itself, to perform the orbit determination process.
Typically, this element is the transponder for two-way range observables.
The transponder on-board receives the signals generated by the ground sta￾tions, demodulates it, and transmitted it back to ground, using phase mod￾ulation on the downlink carrier, making it a signal coherent with the uplink
but shifted in frequency.
Ground-based orbit determination accuracy
The typical accuracy of the presented ground-based measurements is re￾ported in Table 6.3.
VLBI clearly improves the overall orbit determination accuracy based
only on range and doppler measurements. Optical data are not equally ac￾curate, but provide an additional measurement to retrieve a 3D position.
Finally, the use of altimeter improves significantly the position accuracy,
but it is limited to close-proximity operations.
Finally, Table 6.4 summarizes strengths and weaknesses of the sensors for
ground-based spacecraft orbit determination. As discussed before, ground￾based sensors offer high-accuracy measurements in a wide range of possible
applicative scenario. However, these solutions imply limited autonomy and
communication delays along with a significant operational cost.
Sensors 285Attitude sensors
Attitude sensors are used to measure reference directions in the space￾craft body frame, which are then compared with the on-board stored defi￾nition of the same directions in the inertial frame. In this way, it is possible to
determine the attitude of the spacecraft body frame with respect to the
inertial one, as will be discussed in the attitude determination section of
Chapter 9 e Navigation.
Many directions could be taken as references, even if the most common
attitude sensors measure well-known environmental quantities: star posi￾tions, Earth center or limb, Sun direction, or Earth’s magnetic field. In
fact, there exist four types of sensors that are typically used in attitude deter￾mination and control. They are listed below in an approximated order of
accuracy:
• Magnetometers.
• Sun sensors.
• Horizon sensors.
• Star sensors.
The following sections describe the different technologies available for
each type of sensors, together with the main characteristics, advantages,
and drawbacks.
Table 6.3 Typical ground-based orbit determination accuracy.
Measurement Measurement accuracydOrder of magnitude
Range 100 m
Doppler 103m
s
VLBI 101 nrad
Optical data 104 nrad
Altimetry 102 mddependent on the relative distance
Table 6.4 Ground-based OD strengths and weaknesses.
Strengths Weaknesses
High accuracy Limited autonomy
Extensive applicability High cost
Communication delays
286 Andrea Colagrossi et al.Magnetometers
Magnetometers are a very common type of attitude sensors, flying on most
of the satellites in LEO, while they are rarely used in MEO and practically
nonpresent in GEO. Similarly, they are not used for interplanetary orbits.
This is due to the decreasing of the Earth’s internal magnetic field with
the square of distance from its center. Thus, for spacecraft orbiting at larger
distance from the Earth, the magnetic field is less convenient for both atti￾tude estimation, due to the increased relative error of the sensor, and control,
due to the lower ratio of torque over actuator mass. Moreover, magnetom￾eters are also rarely employed in missions around other celestial bodies with a
strong magnetic field, since the knowledge of these environments is too
poor to have a reliable exploitation of magnetic measurements and torques.
Magnetometers do not provide a direct attitude information or estima￾tion, but they only measure the surrounding magnetic field in magnitude
and direction. Since this is a single vector, the satellite state is not fully
observable, and it is necessary to combine this measurement with other sour￾ces of information to derive the complete attitude. This can be done in
several ways, usually using a subset of the below options:
• Other attitude sensor measurements, as Earth sensors or Sun sensors.
• A magnetic field model provided the satellite position is known, either
by orbit propagation or estimation using a GNSS [19,20].
• Gyro measurements, together with attitude propagation and other
observation techniques.
Beside for estimation of the attitude, the magnetometers are used as well
to properly drive magnetic actuators (i.e., magnetorquers in Chapter 7 e
Actuators), since the magnetic torque is the function of both the satellite
magnetic dipole and the local magnetic field. Hence, a spacecraft with mag￾netic actuation shall have on-board measurements of the surrounding mag￾netic field. Note that an on-board stored magnetic field model is not needed
to compute magnetic torque commands.
Another use of magnetometers is to provide a coarse angular rate estima￾tion by time derivation of the computed magnetic field unit vector [21].
This operation is usually performed in combination with other sensors, again
due to the observability problem of the satellite state.
Magnetometers for attitude measurements are those of vector type,
which are capable to measure the vector components of a magnetic field.
In fact, they are typically composed by at least three orthogonal single￾Sensors 287axis magnetometers, as in Fig. 6.14. The most common typologies of vector
magnetometers for space applications are:
• Magnetoresistive sensors, made of a nickeleiron alloy with a high mag￾netic permeability, whose electrical resistance varies with a change in
magnetic field. They have a very quick response time, but their accuracy
is moderate, ranging from 1 to few degrees in direction, and 10 to 50 nT
of resolution.
• Fluxgate magnetometers, made of magnetically susceptible cores wrap￾ped by two coils of wire as shown in Fig. 6.15. One coil is connected
to an alternating electric current, which drives the cores through oppo￾site alternating cycles of magnetic saturation. If no external magnetic field
is present, the fields in the two cores cancel each other and the induced
field in the secondary sensing coil would be zero. However, when the
cores are exposed to a background field, the one in alignment with
the external field has an increased magnetic induction. The contrary hap￾pens in the core opposite to the background field. In this way, an alter￾nating electric signal could be induced in the second coil to be measured
by a detector. Specifically, the voltage at the secondary coil is the deriv￾ative of the flux of the magnetic field vector. In order to achieve mean￾ingful output, the two cores shall reach magnetic saturation during the
z
x
y
Bext
Figure 6.14 Three-axis magnetometer.
288 Andrea Colagrossi et al.alternating cycle. Hence, the driving current in the primary coil shall
consider the expected value of the external magnetic field. Fluxgate
magnetometers are the most common for spacecraft applications, since
they are relatively small, lightweight, with no moving parts, and inex￾pensive. They have a quick response time and a good accuracy in the or￾der of 0.1 in direction, with a resolution of 0:1 to 10 nT.
• Microelectromechanical systems (MEMSs) magnetometers for very
small-scale applications. This typology of sensor is usually operated by
detecting the effects of the Lorentz force or the quantum mechanics
effects of the electron tunneling. These sensors are extremely light and
power efficient, but they are less accurate with respect to fluxgate
magnetometers, with an accuracy in the order of 1.
Although the accuracy of the measured magnetic field direction is not
incredibly high (e.g., ranging approximately from 0.1 to several degrees,
depending on the technology used), they are very reliable sensors. Thus,
they are typically used in magnetic angular rate damping safe modes (cfr.
Chapter 14 e Applicative GNC Cases and Examples). Another reason for
their popularity among GNC systems is that they are quite affordable in
terms of costs and on-board resources, compared to other satellite
equipment.
The magnetic field measured by the sensor is the composition of Earth
magnetic field and the magnetic field generated by the satellite itself. For
Figure 6.15 Fluxgate magnetometer.
Sensors 289this reason, magnetometers accommodation must be properly studied in or￾der to guarantee a level of magnetic cleanliness better or comparable to the
sensor performance. Magnetometers can be accommodated both internally
and externally to the satellite body, possibly on a boom to increase the dis￾tance between the sensor and the satellite body. This is to take advantage of
the 1	
r
3 falloff of a magnetic dipole field.
The internal magnetometers accommodation shall be done in a part of
the satellite distant from magnetic sources (e.g., attitude control torquers, di￾poles, ferromagnetic materials, power lines, current loops in solar arrays,
electric motors, etc.). As a rule of thumb, a local magnetic field has to be
avoided comparable to the magnetometer bias, in order not to reduce the
sensor accuracy. As a mitigation action, it is possible to calibrate the sensor
to compensate for this error. However, it is difficult to estimate the actual
disturbance while on orbit, since it can be different from what is measured
on ground.
If the magnetometer is mounted externally, the sensor is exposed to a
more severe space environment. In this case, the main criticalities are the
wider range of temperature to be coped with and the increased radiation
flux. The shielding to achieve a reduced level of radiation is typically not
a problem for analog space qualified sensors, while it may be more problem￾atic for digital sensors or, in general, for commercial components.
Special care is needed to guarantee the compatibility of magnetometers
measurement to the use of magnetorquers, which produce a strong and var￾iable local magnetic field, as described in Chapter 7 e Actuators. Indeed,
when magnetorquers are activated, they generate a magnetic dipole that
can easily saturate the magnetometer (i.e., the generated magnetic field is
higher than the magnetometer full scale). This can be solved by scheduling
the use of magnetometers and magnetorquers at different times, such that
the magnetorquers are commanded with a certain duty cycle and the mag￾netometers measurements are not acquired at the same time. Again, as a rule
of thumb, the time distance between the magnetorquers actuation and the
magnetic measurements should be at least three times the magnetorquers
characteristic time to allow enough magnetic dipole attenuation.
If the saturation of the measurements is not a problem, the known local
magnetic field generated by the magnetorquers can be compensated in the
magnetometer’s output.
Table 6.5 summarizes the strengths and weaknesses of magnetometers.
290 Andrea Colagrossi et al.Sun sensors
A Sun sensor is a device that senses the direction of the Sun with respect to
the sensor reference frame.
The Sun sensor is operated based on the entry of light into a thin slit or a
pinhole on top of a chamber whose bottom part is lined with a group of
light-sensitive cells. The chamber casts an image of the aperture on the de￾tector. The cells at the bottom measure the distance of the image from a
centerline and determine the refraction angle by using the chamber height.
The receptive cells convert the incoming photons into electrons and,
thus, voltages, which are in turn converted into a digital signal. When
two groups of light-sensitive cells are placed perpendicular to each other,
the direction of the Sun with reference to the sensor axes, and consequently
the spacecraft body frame, can be calculated.
The design of a Sun sensor system for any spacecraft application must
provide acceptable physical characteristics, meet performance specifications,
and cope with interference sources and environmental conditions while
minimizing penalties to spacecraft design and performance. Physical charac￾teristics include size, weight, and power requirements. The major perfor￾mance parameters are accuracy, stability of the measurement, field of
view, transfer function characteristics, and resolution. Interference sources
include sunlight reflected from Earth and other planetary bodies, reflection
from spacecraft surfaces, and spacecraft electromagnetic fields [22]. In partic￾ular, Earth albedo determines a significant disturbance in the Sun sensor
measurements, and it shall be calibrated in the GNC algorithms to achieve
the full sensor performance. Hence, GNC functions shall be capable to es￾timate the incoming light radiation from the Earth to be subtracted from the
sensor measurements.
Table 6.5 Magnetometers strengths and weaknesses.
Strengths Weaknesses
Reliable Poor accuracy (0.5e5 approximately)
Affordable Measurement influenced by satellite
magnetic cleanliness
Measurement always available on the
orbit
Not suited for orbits above LEO
Used both for attitude estimation and
magnetic torquers driving
No direct attitude information
Sensors 291The purpose of this chapter is to highlight the most important character￾istic that a GNC engineer needs to consider when designing a system entail￾ing Sun sensors. Here, we limit the description to sensors that indicate the
orientation of the Sun with respect to a known reference frame. The orien￾tation is sensed by detecting the intensity difference between radiation
arriving from the solid angle subtended by the Sun boundaries and the
rest of the radiation reaching the sensor from the adjacent regions surround￾ing the sensor’s field of view.
Sun sensors are usually classified into three types:
1. Analog sensor whose output signal is a continuous function of the angle
of incidence.
a. Coarse Sun sensors (CSSs).
b. Fine Sun sensors (FSSs).
2. Digital sensor that produces encoded discrete output of the function of
the angle of incidence.
3. Sun presence sensor that provides a constant output signal when the sun
is in field of view.
Analog sun sensors
The analog Sun sensors deliver a continuous function based on the incident
radiation. The analog sensors are furtherly classified in CSSs and FSSs.
Coarse sun sensors
These types of analog sensors measure the amount of incident light without
using windows nor projections. Incident light flux is proportional to the
cosine of the angle between the sun and the normal vector of the light￾sensitive cell, which allows us to calculate the angle of incidence of the solar
vector. With reference to Fig. 6.16, the equation simply reads:
J ¼ Js cosðaÞ
where J is the solar intensity at the sensor, Js is the Sun flux light constant,
and a is the incidence angle between the light direction and the normal to
the sensor.
Solar sensors of this type only use one photodiode, and the electric cur￾rent they create is used to deduce the angle of incidence. At this point, it is
insightful to think of the solar panels as a particular type of CSSs because of
their capability to generate current following the cosine law mentioned
before.
292 Andrea Colagrossi et al.If we assume the Sun as a light point source identified by the sb unit vec￾tor from the spacecraft to the Sun, the output of a CSS mounted on the face
A, whose normal is identified by nA, is [23]:
IA ¼
( ImaxðnA$sbÞ for nA$sb > 0
0 for nA$sb < 0
where I is the CSS output current. Let us now assume that we have another
sensor on the other side of the spacecraft, namely on face -A, whose normal
is identified by nA, then:
IA ¼
( Imax;AðnA$sbÞ¼ImaxðnA$sbÞ for  nA$sb > 0
0 for  nA$sb < 0
Hence, we can write:
IA  IA ¼ ImaxðnA $ sbÞ; cnA$sb
Adapting the exhaustive example in Ref. [23], given the above relation￾ships, if we equip the spacecraft with at least 6 not coplanar Sun sensors, 
ni; nj; nk:
2
6
6
4
Ii  Ii
Ij  Ij
Ik  Ik
3
7
7
5 ¼ Imax
2
6
6
4
ni$sb
nj$sb
nk$sb
3
7
7
5 ¼ Imax
2
6
6
6
4
nT
i
nT
j
nT
k
3
7
7
5
sb
Figure 6.16 Lambert cosine law.
Sensors 293The Sun unit vector can be computed as:
sb ¼ 1
Imax
2
6
6
6
4
nT
i
nT
j
nT
k
3
7
7
5
12
6
6
4
Ii  Ii
Ij  Ij
Ik  Ik
3
7
7
5
These sensors are very sensitive to variations in temperature, which can
cause differences in the current generated, and the estimated angle is directly
proportional to this current, leading to imprecise readings of the angle of the
solar vector. They are not very precise when the incident angle is close to
perpendicular. For this and other reasons, coarse sensors are not as accurate
as fine sensors.
Fine sun sensors
In Fig. 6.17, which represents a single-axis fine analog Sun sensor, two
photosensitive elements are placed close to each other. The Sun rays are
collimated or deviated to form an apparent image on the elements. Each
element outputs an electrical current of different intensity based on the
Sun direction. The difference between the current outputs developed across
the two detector elements yields the sensor output. Whenever the two cur￾rents are equal, meaning that the Sun illumination on the two elements is
equal, the sensor output is zero and the sensor reached the null point,
with the Sun perpendicular to the sensor.
Figure 6.17 Analog Sun sensor.
294 Andrea Colagrossi et al.Digital Sun sensors
In Fig. 6.18, the working principle of a digital Sun sensor is schematized.
The Sun is imaged as a line across an array of separate elements. Each
element produces a 1 or 0 binary bit in the multichannel output, depending
on whether light reaches the element through the mask and whether the
sensor’s output in each channel exceeds threshold values established in asso￾ciated circuitry. The binary number assigned to the channel identifies the
position of the light imaged on the array of elements. The increased number
of photosensitive units makes them more sensitive, increasing the accuracy
of the sensor. Modern digital Sun sensors exploit multipixel optical detectors
to further increase the sensor accuracy.
As a GNC engineer, an important step is the modeling of the sensors as a
mathematical equation. We have seen that the Sun’s relative position is
sensed with respect to the spacecraft body frame. This unit vector, called
Sun measurement vector, is output by the sensor in the body reference
frame. To determine the spacecraft attitude, it is necessary to determine
the rotation between a known reference frame and the body reference frame
bAi
.
Thus, the sensor can be modeled, according to sensor modeling section,
as:
s
b
ð Þ¼t bAis
i
ðÞþt εð Þt ;
where sb is the Sun vector in the body frame, and sI is the Sun vector in the
inertial reference frame, which is typically adopted as reference and ε the
expected sensor errors. At this point, it becomes clear that an attitude esti￾mation algorithm that uses the Sun sensors measurements requires the
Figure 6.18 Digital Sun sensor.
Sensors 295knowledge of the position of the Sun with respect to a known reference
frame, which is typically an inertial one. Such information can be retrieved
from Sun ephemerides or from a simplified model of the Sun motion with
respect to the spacecraft orbital reference frame [24].
To summarize, the most important qualitative characteristics of the
various types of Sun sensors is reported in Table 6.6.
In general, Sun sensors can be quite accurate, i.e., roughly <0.01, but
high-resolution FSSs can reach up to 1 arcmin resolution. Unfortunately,
especially for LEO orbits, they are subject to occultation during eclipse
times. For this reason, when designing a system based on Sun sensors, it is
remarkably important to consider the shortage provoked by the loss of
this signal without degrading the GNC performance (e.g., using an alterna￾tive sensor or propagating the attitude state with a gyroscope). Furthermore,
Sun sensors need clear fields of view.
Table 6.7 summarizes the strengths and weaknesses of Sun sensors.
Sun presence sensors
Analog and digital Sun sensors are more complex compared to the Sun pres￾ence sensor, which delivers a simple binary output. Indeed, Sun presence
sensors are only capable to detect if the Sun is in front of the sensor, within
a certain angle, or not. This sensor typology may be helpful to implement
fast Sun searching or Sun avoidance algorithms.
Sun sensor model
Sun sensor models are based on a modeling approach rotating the ideal
spacecraft-to-Sun unit vector in the sensor reference frame, aligned with
Table 6.6 Types of Sun sensors.
Type Features
Coarse Sun
Sensors
It only provides the relative intensity of the incident light
rays according to the cosine law.
Fine Sun sensors Digital • Digital output
• No analog detection circuitry
• Less noise
• More power consumption
Analog • Analog output
• Less power consumption
296 Andrea Colagrossi et al.its line of sight. In the case the Sun is within the sensor’s field of view, the
Sun vector is processed adding observation errors affecting both the Sun an￾gles and the luminous intensity. The angles are affected by brown electronic
noise, distortions due to geometrical aberrations, and scale factor errors.
Finally, the Sun vector is converted in the output data format, as described
in the sensor datasheet, thanks to some geometrical transformations. The
possible luminous disturbance introduced by the Earth’s albedo is also
modeled. An example digital Sun sensor model implementation in MAT￾LAB/Simulink is shown in Fig. 6.19. A similar modeling approach can be
also used to model Earth horizon sensors or Star sensors. In the latter case,
the Star sensors can estimate the complete attitude of the spacecraft, by
comparing the visible stars with their positions saved in a star catalog, as
will be discussed in the star sensors section. Thus, the star sensor model shall
also include the star catalog, the star matching process, with possible identi￾fication errors, and the final attitude reconstruction.
Table 6.7 Sun sensors strengths and weaknesses.
Strengths Weaknesses
Reliable Not working during eclipses
Affordable No direct attitude information
It can be used in a large portion of the
Solar System
Affected by perturbing light sources
Good accuracy
Figure 6.19 Sun sensor model.
Sensors 297Horizon sensors
Horizon sensors (often referred specifically to Earth sensors) are infrared de￾vices that can detect the discontinuity in temperature between the deep
space and the Earth (or planetary) atmosphere. An important task that
required considerable effort during the historical development of these types
of sensors is the determination of the best spectral region for defining the
space-to-Earth discontinuity and providing robustness to disturbance radia￾tion. Most frequently, sensors use the Earth’s radiation in the infrared spec￾trum (from 2 to 30mm) and, in particular, within the narrow 14e16mm
[23,25]. The reasons why horizon sensors for Earth limb detection are often
centered in the above range are:
• The variation between maximum and minimum radiance is smaller
compared to the visible spectral band.
• When imaging the Earth in the infrared spectrum, the terminator line on
the Earth surface vanishes. This is because the difference between night
and day temperature is negligible with respect to the absolute tempera￾ture scale (i.e., with reference to the absolute zero).
• Imaging in the infrared spectral band prevents the loss of signal during
eclipses.
Earth presents a finite size and cannot be interpreted as a point because
the approximation would just be too erroneous. Indeed, the solid angle sub￾tended by the Earth is roughly 3:9 steradians at 500 km altitude, compared
to the approximation of the Sun, which extends for nearly 7$ 105 stera￾dians [26]. In general, the most important parts of a horizon sensor are the
infrared optical system, including the spectral filter, and the focal plane
where radiance detectors are placed, e.g., thermistors or thermopiles, as
show in Fig. 6.20.
Horizon sensors are classified into two distinct typologies:
1. Static sensors: they are mounted fixed on the spacecraft in predetermined
body axes directions. For this reason, this kind of sensors is dedicated to
spacecraft that have always (or for a large part of the time) the Earth
within the sensor field of view. A typical end-to-end pipeline of the
sensor processing is shown in Fig. 6.21.
2. Scanning sensors: they are composed of a moving detector, whose field￾of-view (FOV) scans the Earth. Scanners are sensors that either me￾chanically, electronically, or passively (on a rotating vehicle) scan a large
volume of object space with a scan pattern fixed relative to the sensor or
vehicle [26].
298 Andrea Colagrossi et al.The accuracy of horizon sensors ranges from 0.1 to 0.5 [23,26].
As already mentioned, the Earth sensor delivers a measurement of the
relative attitude between the Earth and the spacecraft. Given the shape of
the Earth (circular as a first approximation), the output of a horizon sensor
inherently possesses an ambiguity in the yaw angle. In other words, the rota￾tion around the radial axis of the comoving local-vertical-local-horizontal
(LVLH) frame (cfr. Chapter 2 e Reference Frames and Planetary Models)
Figure 6.20 Schematic of a horizon sensor.
Figure 6.21 Workflow of Earth horizon sensor functioning.
Sensors 299is not determined. Only, roll and pitch angles can be estimated by the ho￾rizon sensor. In its simplest form, the model of an Earth horizon sensor reads:
x
 ¼
"
fb;E
qb;E
#
¼
"
fb;LVLH
qb;LVLH #
þ
"
aLVLH;E
bLVLH;E
#
þ ε;
where fb;LVLH and qb;LVLH are the true roll and pitch attitude of the sat￾ellite, i.e., the spacecraft body frame with respect to the LVLH frame;
aLVLH;E and bLVLH;E are the angles between the Earth’s horizon and the
LVLH frame. Finally, ε is the measurement error. For circular orbits and
under the assumption of a spherical Earth, the angles between the Earth
horizon and the LVLH comoving orbital frame are constant and equal to:
aLVLH;E ¼ bLVLH;E ¼ p  sin1

 RE
RE þ h

where RE is the Earth radius and h is the orbital altitude.
Table 6.8 summarizes the strengths and weaknesses of horizon sensors.
Star sensors
Star sensors (or star trackers) are devices that image the celestial sphere and
determine the attitude of the spacecraft with respect to the inertial reference
frame, where the positions of the stars are cataloged. Star sensors are basically
optical cameras, see Fig. 6.22, which use detectors to react at the incoming
light from the stars. The stars’ directions are extrapolated from the image
plane to the spacecraft body-fixed reference frame. Each star ephemeris is
stored in a preloaded catalog; hence, the correspondence between the
imaged stars and database ones delivers an estimation of the spacecraft atti￾tude. Indeed, by measuring more independent directions, star sensors can
Table 6.8 Horizon sensors strengths and weaknesses.
Strengths Weaknesses
Roll and pitch attitude
information
It works well in the vicinity of planets or, in
general, for planetary pointing mission (e.g.,
Earth nadir pointing)
Good accuracy Complex calibration of spectral region
Not affected by eclipses Not complete attitude information
300 Andrea Colagrossi et al.completely solve the attitude problem without the need of other primary
sensors. This process and the relevant determination algorithms to work
out the attitude problem are detailed in Chapter 9 e Navigation.
According to Ref. [27], a star sensor comprises an imaging function, a
detecting function, and a data processing function. The imaging function
collects photons from objects in the field of view of the sensor and focuses
them on a detecting element. This element converts the photons into an
electrical signal that is then subject to some processing to produce the sensor
output. International space standards [27] thoroughly define the classifica￾tion and capabilities of different star sensors. Hereby, a brief summary on
the most important capabilities of star sensors is reported:
Figure 6.22 Schematic of star sensor elements [27].
Sensors 301• Cartography: this function entails the capability of delivering the star po￾sition and measurement date for each detection. Star position is identified
in the sensor reference frame, whose rotation with respect to the space￾craft is known.
• Autonomous attitude determination: this function entails the capability of
delivering the orientation of the sensor reference frame with respect to
the adopted inertial reference frame. According to ECSS [27], the sensors
implementing such functionality should deliver a validity flag of the
determined attitude. This capability is often referred as the lost-in-space
problem solution. Initial attitude acquisition computes at least three cen￾troids for the brightest clusters of pixels, representative of stars. A set of
descriptors for these detections groups, comprising brightness and arc
lengths are generated and used in the pattern searching algorithms to
match the detections with known stars.
• Star tracking: this function entails the capability of delivering the position
of selected stars with respect to a sensor-attached reference frame. This
capability does not imply to autonomously identify the stars to be tracked
or explicitly identified by the unit. Indeed, the initial selection of the star
images to be tracked is not autonomous and must be done offline.
However, it maintains the identification of each star image and correctly
updates the coordinates of each star image as it moves across the detector
due to the angular motion of the sensor. In this way, it allows for faster
attitude problem solutions by comparison with respect to previously
known attitude states.
Stars are highly accurate references and nearly independent by the orbit
position. Furthermore, they are generally available everywhere in the sky.
For these reasons, star sensors are among the best attitude sensors in terms
of accuracy, which falls below few arcseconds in the sensor boresight direc￾tion and slightly larger errors for rotations around the boresight axis. Never￾theless, the increased accuracy comes with considerable cost, in terms of mass
and power consumption with respect to Sun and horizon sensors. Star sen￾sors require time in solving the initial attitude problem from a lost-in-space
condition, and they are generally slower than other attitude sensors. In fact,
during maneuvers, there might be the need of attitude propagation with gy￾roscopes, since star sensors could lose the attitude solution if large slew rates
are present. Moreover, star sensors are delicate since they are disturbed or
302 Andrea Colagrossi et al.even damaged if their field of view is directed to an intense light source (e.g.,
the Sun or the Earth). For this reason, they are typically equipped with pro￾tecting baffles and need to be covered if they are pointed to the luminous
object. Finally, their optical elements shall be protected from contaminants,
such as thruster plumes.
The geometric modeling of a star sensor resembles the pinhole camera
model, which will be thoroughly discussed in Chapter 9 e Navigation.
For the sake of clarity, it is here reported the founding relationship of a
generic point pinhole projection, as in Fig. 6.23.
Whenever a star is imaged, a block of pixels is illuminated due to the op￾tics being slightly defocused, hence yielding a point spread function distribu￾tion rather than a unique pixel. A centroiding algorithm determines the
pixel location of the star by calculating a weighted average of the pixels’
brightness composing the block. The resulting detection accuracy depends
on the sensor, the star brightness, the exposure time, and various errors
related to the implementation of the optics [23]. For a GNC engineer,
not strictly involved in the manufacturing of these sensors, it is important
Figure 6.23 Star sensor modeling under the assumption of pinhole camera. The refer￾ence frame x, y, z is the sensor frame; u,v is the image frame and f is the focal length.
Sensors 303to obtain all the data (e.g., from the supplier) to characterize the sensor per￾formance. A generic measured star vector s, namely the unit vector from the
spacecraft to the identified star, can be computed with reference to Fig. 6.23
as:
s ¼ 1 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi

f 2 þ ðu  u0Þ
2 þ ðv  v0Þ
2 q 
2
6
6
4
u  u0
v  v0
f
3
7
7
5
þ ε
where ε is the measurement error. The star catalog used in a star sensor is a
critical variable that largely affects the accuracy of the sensor. Typically,
sensors offer an end-to-end pipeline depending on the capability the sensor
provides, as mentioned before (e.g., cartography, star tracking, attitude
determination). Nevertheless, it is interesting to report how the number of
stars influences the sensor output. To make a proper attitude determination,
we may need at least N ¼ 3/4 stars to be identified in the image. The more
objects are identified, the more robust to random errors our estimation will
be. The probability of finding at least N stars in the sensor field of view can
be assumed as a Poisson distribution [23]:
PðNÞ ¼ e
Navg
NN
avg
N!
where Navg is the average number of stars we expect in the FOV. The
average number of stars in FOV can be determined by the FOV angle and
the number of catalog stars Ncatalog, knowing that the size of the celestial
sphere is 4p sr:
Navg ¼ Ncatalog$FOV2
4p
This means that the probability of finding at least N stars in the FOV is
influenced by the number of stars in the catalog and the instrument FOV.
Given a certain value of average number of stars in FOV, the probability
of finding and detecting at least N stars in the FOV is represented in
Fig. 6.24.
For instance, with reference to Fig. 6.24, the probability of finding at
least N ¼ 5 stars with an average of Navg ¼ 8 stars in FOV is 90%. The
number of catalog stars or the required FOV can be determined as:
304 Andrea Colagrossi et al.FOV ¼
ffiffiffiffiffiffiffiffiffiffiffiffiffiffi
4pNavg
Ncatalog s
Ncatalog ¼ 4pNavg
FOV2
To solve this trade-off, we could introduce a constraint on the resolution
of the sensor, which limits the FOV for a given detector array, namely the
number of pixels utilized for the image representation. Let us go through an
example: roughly speaking, if we have a star sensor with FOV angle equal to
20 and a detector of 1024 pixels, we obtain a resolution of
ε ¼ FOV
npx z 0:02 
px. We may obtain subpixels resolution depending on
the centroiding algorithm that can achieve accuracy of g ¼ 0:1 px width.
In this case, εcentroid ¼ gε. The final accuracy of the pointing direction de￾pends on the number of stars in the FOV [28], namely N ¼ 5 in this
example, as:
accuracy ¼ ε
ffiffiffiffiffiffiffiffi
ðNÞ p ¼ FOV
npx
ffiffiffiffiffiffiffiffi
ðNÞ p z 30 arcsec
Figure 6.24 Number of detected stars in FOV for different average number of stars in
FOV, linearly dependent from the number of catalog stars.
Sensors 305Or, with centroiding accuracy g ¼ 0:1 px:
accuracy ¼ εcentroid ffiffiffiffiffiffiffiffi
ðNÞ p z 3 arcsec
Table 6.9 summarizes the strengths and weaknesses of star sensors.
Performance comparison
Table 6.10 summarizes the typical orders of magnitude of the performance
for each presented attitude sensor. Obviously, this is only a rough guideline.
A GNC engineer should go through the specifications and the datasheets of
each component to acquire precise indications on the actual performance
data.
Inertial sensors
Inertial sensors are used to transduce inertial forces into electrical sig￾nals, to measure the specific forces e i.e., accelerations e and the angular
rates experienced by them and, consequently, by the bodies on which
they are installed. Inertial sensors sensing linear acceleration are referred to
as accelerometers, while the angular motion is sensed by sensors denoted
as gyroscopes. A single accelerometer, or gyroscope, is capable to measure
the associated quantity along one axis. Thus, a set of three inertial sensors
along orthogonal directions is needed to measure the whole 3D quantity,
and it is commonly defined as Inertial Reference Unit (IMU). When triaxial
accelerations and angular velocities are provided by a single component, this
is referred to as IMU, which is a six-axis sensor containing three orthogonal
Table 6.9 Star sensors strengths and weaknesses.
Strengths Weaknesses
Extremely accurate Mass and volume
Provide complete attitude
information
Complexity and high cost
Wide applicability across the
Solar System
Must avoid luminous objects (e.g., the Sun)
Requires time to acquire the initial attitude state
from a lost-in-space condition
306 Andrea Colagrossi et al.accelerometers and three orthogonal gyroscopes. Sometimes, IMUs can be
also equipped with three orthogonal magnetometers (cfr. Section Magne￾tometers), and, in this case, they are denoted as nine-axis IMU.
Two basic typologies of inertial sensors exist: the “gimballed” and the
“strapdown.” The former was the first original application of inertial sensors
technology, which uses stable platform techniques, where the inertial sensors
are mounted on a stable platform and are mechanically isolated from the
motion of the vehicle. In this case, triads of accelerometers and gyroscopes
are suspended by a system of three gimbals keeping the platform in a fixed
orientation with respect to the inertial space. This can be achieved by
exploiting conservation laws or with a gyro-stabilized mechanized system.
In mechanized gimballed system, the stabilization is guaranteed by three
integrating gyros, whose output is proportional to the rotation angles to
which the sensors are subjected. Their measurements are used in a feedback
cycle commanding null-seeking servomotors, which drive each gimbal to
maintain a constant orientation in inertial space. Gimballed inertial sensors
directly measure inertial accelerations, and, thus, the displacement from
the initial position is computed integrating twice with respect to time. Anal￾ogously, the body rotations are immediately retrieved from the gimbal’s an￾gles with respect to the platform supports. Despite the very high accuracy
that is possible to achieve with this typology of inertial sensors, their techno￾logical complexity ties down their usage to systems requiring extremely pre￾cise measurements for prolonged time, such as ships and submarines. Purely
gimbal sensors are practically unrealistic due to the requirement to have
almost null friction in the bearings, while mechanized ones have a consider￾able impact on mass, volume, power, costs, and maintenance of the system.
Moreover, gimballed systems are affected by the gimbal lock, which happens
Table 6.10 Typical order of magnitude of the performance for each presented
attitude sensor.
Sensor Range of performance
Magnetometer 0.5e5
Sun sensors 0.001e1
Horizon sensors 0.1e0.5
Star sensors 1 arcsece1 arcmin
Sensors 307when the axis of two of the gimbals are driven in the same direction, losing
one degree of freedom on the 3D isolation capability (also experienced by
the Apollo 11 Moon mission [29]). This problem may be overcome by using
a fourth gimbal or by performing dedicated reset rotations. Both solutions
further increase the complexity of gimballed inertial sensors.
For all these reasons, from the early 1970s [30,31], the inertial sensors
technology was pushed toward alternative, simpler, gimballess inertial sen￾sors. The basic idea is to rigidly attach, or “strap down”, gyroscopes and ac￾celerometers directly to the system body, using the gyroscope information to
compute the current attitude of the body and, then, generate a coordinate
transformation that operates on the accelerometer data to give acceleration
resolved into inertial axes. In effect, this results in a “mathematical
gimbal set,” replacing the mechanical one. The theoretical aspects behind
strapdown inertial sensors are two: the measurement of acceleration in
body-fixed coordinates and the determination of the orientation of the
body-fixed reference frame with respect to inertial one from gyro informa￾tion. Strapdown accelerometers measure real inertial acceleration, but they
resolve it in body-fixed axes. Thus, apparent accelerations arise interpreting
these components in the noninertial reference frame. In general, strapdown
systems demand for increased computing capabilities, since the attitude
transformation computations have to be carried out at a very high frequency.
The lack of the inertial platform let the body-mounted instruments experi￾ence both the angular and linear motions of the system and most of its vi￾brations. Moreover, these instruments are subject to the entire maneuver
envelope of the spacecraft, and not only to the residual drift rotations of
the gyro-stabilized platform. For these reasons, they shall be capable to
detect much higher rates of turn, while maintaining good drift accuracy
values. Consequently, very broad and linear dynamics range is mandatory
for this kind of inertial sensors. Despite these minor drawbacks, strapdown
inertial sensors are now widely used in spacecraft applications, and with
the current on-board computing capacities, they are a fully mature technol￾ogy, with performance almost comparable to the gimballed systems.
Gyroscopes measure the changes in vehicle attitude or its angular rate
with respect to an inertial reference frame. Accelerometers, however, are
not capable to distinguish among the total acceleration of the vehicle with
respect to inertial space, and that caused by the presence of a gravitational
field. The output of these sensors is the difference between the true
308 Andrea Colagrossi et al.acceleration in space and the acceleration due to gravity. Namely, the
nongravitational force per unit mass exerted on the instrument:
ab
¼ bAi

r€ gðrÞ

(6.2)
where the superscript b indicates that it is measured in the body reference
frame, r is the inertial position vector of the accelerometer, gðrÞ is the
position-dependent gravitational acceleration, and bAi is the direction
cosine matrix rotating a vector from the inertial to the body reference frame.
Hence, in free-fall orbiting applications, accelerating due to of the gravity of
celestial bodies only, an ideal accelerometer placed at the center of gravity of
the spacecraft would measure zero. Then, to compute the total acceleration
acting on the body, which is needed to propagate its motion, a gravitational
field model shall be used to correct accelerometer measurements with
gravity accelerations. The navigation functions, discussed in Chapter 9 e
Navigation, exploiting strapdown inertial sensors measurements shall
combine body rotation estimation, reference frame transformation, gravi￾tational acceleration evaluation, translational and rotational coupling
correction, and dynamics integration, as in Fig. 6.25.
Accelerometer’s technology is well established since many decades, and it
is based on mechanical sensors or solid-state ones. Despite the construction
principle of these sensors, they are usually based on Newton’s second law of
motion to measure the force acting on a small mass, known as a proof or
seismic mass, which is contained within the vehicle, and it is typically con￾nected via a spring or an oscillating arm to the case of the instrument. When
Figure 6.25 Functional components of a navigation system based on inertial sensors.
Sensors 309the instrument is subjected to an acceleration along its sensitive axis, the
proof mass tends to respond to the change in movement according to its
own inertia. A transducer is designed to sense the relative movements be￾tween the proof mass and the sensor case, converting them in calibrated
electric signals proportional to the nongravitational forces acting on the
body. As already said, an accelerometer freely orbiting around a celestial
body would output a zero measurement, since both the case and the proof
mass experience a common influence of the surrounding gravitational field.
In this case, the acceleration of the instrument with respect to an inertial
reference frame is a ¼ r€¼ g; and the specific force is zero in accordance
with Eq. (6.2). The principles of operation of accelerometers depend on the
construction technology, which can be based on: force-feedback pendulum,
optical fiber pendulum, vibratory quartz crystal technology [32], acoustic
wave resonator on piezoelectric cantilever beam [33], silicon-based
pendulum [34], interferometry [35], optical waveguides and Bragg gratings
[36]. In recent years, MEMS technology began to be popular for inertial
sensors. This construction principle will be discussed in the following,
together with gyroscope MEMS technology, but high-accuracy accelerom￾eters will continue to incorporate mechanical sensors, with some use of reso￾nant devices [32].
Gyroscope’s technology is typically divided in two broad classes: rate
gyros that read angular rates and rate-integrating gyros that measure inte￾grated rates or angular displacements. The most basic gyroscope construction
principle is based on the angular momentum conservation principle of a
wheel, or rotor, spinning at high speed. In this case, the instrument contains
a spinning mass, whose angular momentum vector, coincident with the axis
of spin of the rotor, remains fixed in the inertial reference frame. When the
sensor is subjected to a rotation along its sensitive axis, a precession displace￾ment between the instrument case and the spinning axis is sensed by a trans￾ducer converting it in a calibrated electric signal. In alternative, the
precession principle can be also applied to accurately measure the rotation
rates, by applying a torque to maintain the angular momentum of the proof
mass fixed in the body frame. Then, the measurement of this torque pro￾vides measurements of the angular velocity of the instrument, according to:
t
b
¼ bub
i  hb
; (6.3)
where hb is the gyro’s angular momentum, bub
i is the angular rate of the
body with respect to the inertial reference frame, and t
b is the output torque
310 Andrea Colagrossi et al.measured in body frame. Single-axis gyros sense only one direction of the
torque, and the other reaction torque is provided by mechanical constraints
on the orthogonal axis. Very accurate spinning mass gyros are single-axis
floated devices, where the rotor is contained in a case that is immersed in
a buoyancy fluid to reduce the load on the gimbal bearings [32]. Two-axis
gyros are called dry tuned-rotor gyros (DTGs) because they are not floated.
They have two input axes which are mutually orthogonal, and which lie in a
plane which is perpendicular to the spin axis of the gyroscope. The rotor
deflection is sensed on both axes, and it is controlled electromagnetically
according to Eq. (6.3). DTGs have come very close to the performance of
single-axis floated gyros, but never achieved performance equivalent to the
best floated gyros [37]. However, they are simpler, rugged, and less prone to
failures.
Other typologies of gyroscopes are based on direct rate sensing on
viscous coupling between fluids and masses [32]; vibration motion deflection
due to Coriolis apparent forces, where a vibration element (e.g., a string, a
hollow cylinder, a rod, a tuning fork, a hemispherical dome) is present to
sense rotation-induced deflections; optical interferometry and Sagnac effect.
Coriolis vibratory gyros, especially in the tuning fork version, are funda￾mental for the size reduction of gyroscopes, and the realization of silicon
solid-state or MEMS sensors. They will be discussed in the following. Op￾tical gyroscopes allow extremely high performance and accuracy since they
measure optical length differences within a circular waveguide. In fact, when
light travels in opposite directions (clockwise and anticlockwise) around an
enclosed ring, differences arise in the apparent optical length of the two
paths when the ring is rotated about an axis perpendicular to the plane con￾taining the ring itself. The path differences can be practically detected as a
phase shift, but, even in this case, the angular differences are extremely small
[23]. To overcome this practical problem, interferometric fiber optic gyros
and ring laser gyros have been ideated. The former use many turns of optical
fiber to magnify the phase shift difference, the latter replace the phase mea￾surement by a frequency difference measurement between two counterpro￾pagating resonant laser beams. Despite their potential, optical sensors are not
widespread in spacecraft applications since they require maintenance to
overcome optical degradation, they are power consuming, they lose detec￾tion capability for very slow rotation rates, and they have a complex imple￾mentation to achieve good performance.
Recent technology developments allowed simpler, smaller, lighter,
lower power consuming, and lower cost inertial sensors. These features
Sensors 311are all positive in spacecraft applications, but they become fundamentals for
small satellites and CubeSats (cfr. section CubeSats in Chapter 15 e Modern
Spacecraft GNC), and they are possible, thanks to MEMS sensors [38,39].
MEMS sensors are packaged similarly to other integrated circuits, with a sin￾gle part containing inertial sensors for multiple axes. They are produced with
chemical etching and batch processing techniques, and they were recently
qualified for operations in the space radiation environment. The major
drawbacks of MEMS sensors are related with their short lifetime and
reduced performance, compared to other inertial sensors. In fact, size reduc￾tion is commonly related to a decrease in sensitivity and an increase in noise.
MEMS sensors are made of silicon wafers or piezoelectric quartz layers, and
they are based on the same physical principles of the classical inertial sensors.
MEMS gyroscopes exploit the Coriolis acceleration effect on vibrating proof
masses to detect angular rotation, while MEMS accelerometers exploit
miniaturized pendulum displacements or microresonators vibration fre￾quency changes to detect linear acceleration. An array of MEMS
sensors may be integrated into a single chip to provide multiple independent
measurements of inertial motion. Moreover, single-chip implementations of
six-axis, or nine-axis, IMUs have become common, guaranteeing a vast
reduction in volume, negligible power consumption, and the ability to carry
out a complete characterization of the unit in a single operation.
Typical error sources
Every inertial sensor is subject to errors which limit their measurement ac￾curacy. The applications of these instruments in spacecraft shall consider
their common error sources in order to minimize their impact on the
GNC functions. Moreover, a proper GNC design shall rely on a proper
sensor modeling that considers all the relevant errors affecting the measure￾ments. The error sources of inertial sensors can be categorized in four classes:
• Deterministic (or constant) errors, which are repeatable. They can be
determined and corrected by calibration.
• Temperature-induced errors, which can be determined and corrected by
thermal calibration.
• Switch-on to switch-on errors, which are stochastic processes but stays
constant for any single run. They can be corrected with on-board cali￾bration estimation techniques, discussed in Chapter 14 e Applicative
GNC Cases and Examples.
312 Andrea Colagrossi et al.• In-run stochastic variations errors, which should be modeled as stochastic
processes varying throughout the measurement run. In-run stochastic
variations with slow dynamics can be corrected with on-board calibra￾tion estimation techniques. Stochastic errors with a fast dynamics (i.e.,
random noise) cannot be corrected.
Typical error sources depend on the specific type of sensor. However,
the major ones are in common to all of them.
Bias errors are related to a nonnull sensor output, which is present even in
the absence of an applied input. They are typically expressed in units of de￾grees per hour (=h) for gyroscopes, and milli-g or micro-g (mg; mg) for
accelerometers.
Bias errors in both gyroscopes and accelerometers can be further broken
down into more error components:
• Constant bias: fixed bias term in every measurement of the sensor. It can
be corrected by calibration of the sensor.
• Bias repeatability (switch-on to switch on bias): bias term varying at every
sensor powerup. It remains constant until next switch-on. It can be
corrected by in-run calibration with bis estimation techniques. A high
bias repeatability guarantees a faster convergence of the estimation filters
between distinct runs of the sensor.
• Temperature-dependent bias: bias term depending on the operating temper￾ature of the sensor within the specified temperature range. It can be cor￾rected by implementing a thermal model of the sensor and taking into
account temperature measurements of the instrument.
Mechanical gyroscopes are also affected by acceleration-dependent bias (i.e.,
g-dependent bias), which is proportional to the magnitude of the applied ac￾celeration. Such errors arise because of mass unbalance and asymmetry, due
to imperfections caused by the fabrication process. They are expressed by
means of coefficients having units of degrees per hour per g (=h=g).
Bias instability errors are related to an in-run bias drift with stochastic evo￾lution, which can be characterized in terms of variance and process time.
Bias instability has an impact on the long-term integration of sensor’s out￾puts. It is expressed in units of degrees per hour (=h) for gyroscopes, and
micro-g (mg) for accelerometers. It is defined with the AVAR method,
which is introduced in the following dedicated section. Bias instability de￾termines continuous fluctuations in the bias offset, which can be estimated
on-board to improve motion propagation performance.
Random walk errors are pure stochastic processes associated to the charac￾teristic of the intrinsic noise of the sensor. Integration of the random walk
Sensors 313noises in the measurements leads to a random walk in the final solution.
They can be estimated by the AVAR method, which is introduced in
(cfr. Section AVAR). Noise errors are defined according to the noise vari￾ance trend with respect to the averaging time.
• Angle random walk (ARW)/Velocity random walk (VRW) errors are high￾frequency noises, and they can be observed as the short-term varia￾tions in the output. ARW is defined for gyroscopes, while VRW is
defined for accelerometers. Integrating the sensor outputs, these terms
cause random errors in angle/velocity estimation with a distribution that
is proportional to the square root of the elapsed time. Thus, these errors
will increase the longer integration and provide a fundamental limitation,
together with bias instability, to any angle/velocity measurement that
relies only on inertial sensors. They are expressed in units of degrees/
meters per second per square root of hour (= ffiffiffi
h
p ; m=s= ffiffiffi
h
p or mg= ffiffiffiffiffiffi
Hz p ).
Note that, VRW can be also expressed in units of micro-g per square root
of Hertz.
• Rate random walk (RRW) errors are long-term changes to the bias offset,
which are randomly distributed over very long time. The time scale over
which these changes occur can be defined by the RRW and allow for
on-board recalibration of the sensor.
Random walk errors are classified in terms of characteristic time, and
they are further differentiated from those associated with bias instability
because of the different temporal properties, as analyzed in the power spec￾tral density of the sensor stochastic processes.
Scale factor errors affect the ratio relating the change in the output signal to
a change in the input to be measured. It is the measure of the gradient of the
best straight line that can be fitted by the method of least squares to the ex￾pected sensor output signal, against input inertial signal over the full dynamic
range at ambient temperature. Scale factor errors are commonly expressed as
a ratio of output error to input quantity, in parts per million (ppm) or per￾centage. Additional errors arise from the nonlinearity of the scale factor with
respect to the least squares linear fitting, and from its asymmetry with respect
to opposite direction inputs.
Scale factor ratios are typically not constant and may fluctuate during in￾run operations. Scale factor instability is an additional source of errors.
Cross-coupling errors determine spurious outputs resulting from sensor
sensitivity to accelerations or angular rates about axes orthogonal to the
input axis. Such errors arise through nonorthogonality of the sensor axes.
314 Andrea Colagrossi et al.They are expressed as parts per mission (ppm) of the applied input. They can
be corrected by calibration being repeatable deterministic errors.
Misalignment errors are related to a mechanical mounting error of the
sensor triad with respect to the nominal body frame. The sensor outputs
have couplings with respect to different body axes inputs. They are
expressed in units of milliradians (mrad), and they are difficult to be distin￾guished with respect to cross-coupling errors. They can be corrected by cali￾bration being repeatable deterministic errors.
Other than the previous sources of error, inertial sensors are characterized
by other limitations, such as:
Input range limits associated to the maximum input values that can be
meaningfully measured.
Output quantization associated to the mapping of a continuous signal into
a discrete one and dependent on the analog to digital conversion resolution.
Latency associated to the sensor processing time, which determines a
nonzero elapsed time between the input sensing and its output generation.
Moreover, inertial sensors are also affected by extrinsic errors due to the
estimation processes elaborating inertial sensors outputs, as seen in Fig. 6.25.
For instance, an imprecise model of the gravitation field may lead to motion
propagation errors. Similarly, numerical computation errors may also affect
the precision of propagated position, velocity, or attitude vectors. However,
these latter errors are associated to the navigation functions and not directly
to the inertial sensor itself. Fig. 6.26 summarizes the main sources of errors
described in this section.
Inertial sensors performances
Inertial sensors are classified into various performance grades according to
their typical accuracy levels, which are divided in four main performance
categories:
• Consumer grade.
• Industrial grade.
• Tactical grade.
• Navigation grade.
These categories are mainly subdivided according to the in-run bias sta￾bility of the sensor, as the in-run bias stability plays such a large role in deter￾mining inertial navigation performance. In fact, a low value of the bias drift
enables the application of inertial sensors in high-end market segments. The
performance grades, associated to the available sensor technologies, are
Sensors 315reported in Figs. 6.27 and 6.28 [40,41]. Given the different performance of
the sensors, the order of magnitude for position and angle accuracy estima￾tion, after 1h of motion propagation, is reported in Table 6.11.
Figure 6.26 Inertial sensor errors.
Figure 6.27 Gyroscope technologies and performance grades.
316 Andrea Colagrossi et al.Allan variance and statistical error representation
Inertial sensors are affected by both repeatable deterministic errors and sto￾chastic random errors. The former can be eliminated or reduced, thanks to
standard sensor calibration techniques, while the latter are more difficult to
be compensated, unless complex statistical estimation techniques are used.
However, in general, it is almost impossible to completely remove their
impact on the motion propagation performance.
In-run stochastic variations are due to temperature, aging, or mechanical
stress on the system. Furthermore, electronic noise, interactions with the
external environment, and transduction interferences are additional issues
generating random errors on inertial sensors output. Thus, given this broad
range of physical phenomena, stochastic error sources have different charac￾teristic times, filling a complete frequency spectrum. In fact, they appear on
the output as a noise or a slow change of parameters in time. The contribu￾tion of these errors at a specific time cannot be precisely predicted, but the
analysis of these stochastic processes in inertial sensors is possible. According
Figure 6.28 Accelerometer technologies and performance grades.
Table 6.11 Sensor grades and navigation performance after 1h of propagation.
Sensor grade Angle accuracy () Position accuracy (km)
Consumer grade >50 >1000
Industrial 5e50 100e1000
Tactical 0.1e5 1e100
Navigation <0.1 <1
Sensors 317to the international IEEE standard 952e1997 [42], two analysis methods are
available, but the AVAR method is the most widely used. AVAR is the
method of analysis of stochastic processes in a time domain, and it describes
the intrinsic variance of a signal as a function of averaging time. It can eval￾uate the real performance of inertial sensors in relation to the effects of bias
instability, ARW and RRW. Note that, often the AVAR term is also used
to refer to its square root.
To compute the AVAR, we have to follow the following steps [40]:
1. Data collection: sample the output data, for a steady-state input condition,
from the sensor at interval Ts to obtain a long sequence of consecutive N￾point data.
2. Data clustering: divide the N-point data into K clusters, with each cluster
having the length of M-point data.
3. Data averaging: average the data in each K-th cluster.
aKðMÞ ¼ 1
M
X
M
i¼1
aKðiÞ
4. Calculate variance: take the difference in average between successive clus￾ters. There must be enough data for at least nine bins, otherwise the re￾sults obtained begin to lose their significance. The AVAR is defined as
the mean value of the square of the difference of adjacent time averages
from a time series as a function of averaging time, multiple of the sample
time, s ¼ mTs, and it is expressed as:
s2
AllanðsÞ ¼ 1
2ðK  1Þ
K
X1
K¼1
½aKþ1ðMÞ  aKðMÞ2
A typical Allan plot for inertial sensors is shown in Fig. 6.29, in which the
values of the root AVAR are plotted against the averaging interval, s, in log￾log form. Different types of random processes cause slopes with different
gradients to appear on the plot, and they also are correlated with different
averaging times, and therefore correspond to different locations on the Allan
plot. The basic noise terms are ARW, RRW, bias instability, quantization
noise, and drift rate ramp. In addition, the sinusoidal noise and exponentially
correlated noise can also be identified on the plot.
As shown in Fig. 6.29, the electronic quantization white noise is charac￾terized on the AVAR plot as a slope with gradient equal to 1. The magni￾tude of this noise can be read off the slope line at s ¼ ffiffiffi
3 p : This noise is
strictly due to the digital nature of the sensors. The random walk
318 Andrea Colagrossi et al.measurement for sensor noise, such as the ARW for gyros and VRW for ac￾celerometers, can be obtained directly by reading the slope line at s ¼ 1.
These noise terms are all characterized by a white noise spectrum on the
output. Bias instability is due to low frequency bias fluctuations, which
are characterized by 1=f noise or flicker noise spectrum, where f is the cutoff
frequency of the sensor output. Bias instability appears on the plot as a
plateau around the minimum. The flat region of the plot can be examined
to estimate the limit of the bias instability, as well as the cutoff frequency of
the underlying flicker noise. The RRW indicates a random walk with a
very long correlation time. It is represented on the AVAR plot by a slope
of þ1=2. The magnitude of this noise, K, can be read off the slope line
at s ¼ 3. For long, but finite time intervals, this is more of a deterministic
error rather than a random noise. Its presence in the data may indicate a
very slow monotonic change in the sensor properties, and its magnitude
can be obtained from the slope line at s ¼ ffiffiffi
2
p :
If it can be assumed that the existing random processes are all statistically
independent, then it can be shown that the Allan variance at any given t is
the sum of Allan variances due to the individual random processes at the
same s:
s2
AllanðsÞ ¼ s2
ARW ðsÞ þ s2
QuantðsÞ þ s2
BiasInstðsÞ þ s2
RRW ðsÞ þ /
Thus, estimating the amplitude of a given random noise in any region of
the AVAR requires a knowledge of the amplitudes of the other random
Figure 6.29 Example Allan variance analysis results adapted from [42].
Sensors 319noises in the same region. Fig. 6.30 reports the individual AVAR contribu￾tions of the main random processes discussed above.
Note that, the computation of AVAR needs a finite number of clusters
that can be generated from the raw data measurements of the sensors.
Depending on the size of these clusters, the AVAR can identify any noise
term that is affecting the data sensor. It is important to mention that the esti￾mation accuracy of the AVAR for a given t depends on the number of in￾dependent clusters within the data set. The bigger the number of
independent clusters, the better the estimation accuracy.
All the stochastic errors contribute to accumulate errors, with an
increasing standard deviation, along the motion propagation. If a continuous
bias estimation were possible, the propagation errors would theoretically
approach zero, in absence of other noncalibrated errors. However, this is
not feasible, and finite time periodic calibrations are the best viable solution.
The frequency of these in-run on-board calibrations can be selected from
the AVAR analyses. In fact, calibrating at least before the bias stability char￾acteristic time makes ARW dominant and drift negligible. Given the time
interval at which we can effectively recalibrate, we find out from the
AVAR graph the statistical estimate of the propagation error. For example,
Figure 6.30 Individual Allan variance contributions adapted from Ref. [42].
320 Andrea Colagrossi et al.assuming the root of the AVAR of a tactical grade MEMS gyroscope at s ¼
2700s being sAllan ¼ 1:3 =h ¼ 361 m=s, and propagating the motion
along a 45 min ¼ 2700 s window (e.g., an LEO eclipse period), the statis￾tical propagation error would be εq ¼ 0:9747 degRMS.
As said, two main parameters represent the quality of inertial sensors.
They are the ARW and the bias for gyroscopes, and the VRW and bias
for accelerometers. Noting that bias and scale-factor drifts are much larger
than noise contributions, Table 6.12 reports random walk ad bias values
for typical inertial sensors.
Remind that inertial sensor units are note standardized, and different
conversion factors are very useful to be known. Working with the square
root of time, converting between hours and seconds is a factor of 60 instead
of 3600: 60 ffiffi
s p ¼ ffiffiffi
h
p . Similarly, accelerations can be expressed in mg or in
the SI m=s=s, and 1mgz 105m
	
s
	
s. Thus, for example, a VRW of X mg= ffiffiffiffiffiffi
Hz p zX 6  104m
	
s
	 ffiffiffi
h
p :
Gyroscope model
A general gyroscope model including all the relevant sensor’s errors is:
uðtÞ¼ðI3 þ SFÞOR utrueðtÞ þ bðtÞ þ hðtÞ.
An example of this model implementation in MATLAB/Simulink is
shown in Fig. 6.31. A similar structure can be extended of other sensor
models, such as accelerometers or magnetometers. The implementation of
the individual error sources would be the same in all the sensor models
affected by the same errors. Note that bias and noise terms can also be
Table 6.12 Typical random walk noise and bias values for inertial sensors.
Sensor grade
Gyro bias
(
=h)
ARW noise
(
= ffiffiffi
h p ) Acc bias (mg)
VRW noise
(mg= ffiffiffiffiffiffi
Hz p )
Consumer
grade
>50 >0.5 >50,000 >100
Industrial 5e50 0.1e0.5 1000e50,000 10e100
Tactical 0.1e5 0.05e0.1 10e1000 1e10
Navigation <0.1 <0.05 <10 <1
Sensors 321multiplied by the scale factors, misalignment, and nonorthogonality errors
(i.e., ðI3 þSFÞOR). It is just a matter of their definition and implementa￾tion. In Chapter 14dApplicative GNC Cases and Examples, the other
formulation is used to simplify the sensor calibration equations.
Electro-optical sensors
For unmanned missions, spacecraft GNC requires a level of autonomy
that can only be provided, thanks to dedicated on-board GNC including
electro-optical sensor suites. In fact, the measurements taken by this kind
of sensors enable autonomous navigation, providing on-board data that
are fundamental to have the spacecraft estimating its state.
To achieve the high level of autonomy and reliability required in today’s
space missions, navigation making use of high-accuracy measurements, to be
processed on-board at high frequency, is mandatory in critical operations.
The mission concept and the navigation technique will drive the selection
of different sensor suites.
In general, the term electro-optical indicates all the instruments capable
of collecting reflected or emitted radiations in a certain range of the electro￾magnetic spectrum. In modern spacecraft applications, almost exclusively
visible (0.37e0.75 mm) and infrared (0.75e1000 mm) bands are used, and
the most common sensors are cameras (monocular and stereo) or LIDAR
systems.
Figure 6.31 Gyroscope model.
322 Andrea Colagrossi et al.Cameras
Cameras are based on passive electro-optical sensors that collect incoming
light waves (visible or infrared) and traduce them into signals which allow
to produce an image. The two main types of electro-optical sensors
employed by modern cameras are the charge-coupled device (CCD) and
the active-pixel sensor (complementary metal oxide semiconductor
(CMOS)). Without entering into technical details, both CCD and
CMOS are composed by arrays of silicon photosites, also known as pixels,
that convert collected photons into electrical signal. In a CCD sensor,
each photosite is an analog device and the charge is transported across the
chip and read at one corner of the array. An AD converter is used to convert
the analog signal into a digital value. On the other hand, CMOS sensors rely
on one or more transistors at each photosite that amplify and move the
charge using more traditional wires. The main difference in terms of perfor￾mance can be summarized here:
• CCD sensors are superior to CMOS for what concerns high-quality,
low-noise images.
• Light sensitivity of a CMOS chip tends to be lower, as many of the pho￾tons hit the transistors instead of the photosite.
• CCD sensors require much higher power than an equivalent CMOS
sensor (up to 100 times more).
Another important classification while referring to imaging sensors is the
type of shutter adopted. The shutter is the device (mechanical or electric)
allowing light to hit the sensor for a given amount of time (i.e., exposure
time). Two main types of shutters can be identified: rolling and global. Roll￾ing shutters expose sensor rows sequentially from top to bottom, while for
global shutters, all the pixels of the sensors are exposed at the same time. For
fast dynamics navigation scenario, it is generally preferred global (snapshot)
shutter mode as rolling mode introduces many artifacts shifting in the image
(smearing effect), and global shutter avoids preprocessing compensation.
When the camera is moving very fast or spinning with respect to the target,
with a roller shutter, the image is distorted because different lines can capture
different times of the scene, generating a “moving picture.” One classical
example of this undesired phenomenon is obtained while imaging the rotor
of a helicopter. The rotor blades would appear to be unnaturally swept back
due to the rolling shutter.
The optical lens (or a group of lenses) will complete the camera assembly.
A lens is characterized by a set of two main parameters:
Sensors 323• Focal length: it determines the magnification of the image projection
onto the image plane. It is also inversely proportional to the camera
FOV, i.e., longer focal length will correspond to narrower FOV.
• Aperture: it determines the amount of light hitting the camera sensor.
Finally, a very important figure of merit, especially for space applications
is the signal-to-noise ratio (SNR). The SNR represents a quantitative value
describing the quality of a measurement. As the name suggests, SNR is ob￾tained as a ratio between the measured signal and the overall measured noise.
High values of noise imply very good measurement of the target object, i.e.,
the incoming signal is very strong with respect to the overall noise. On the
contrary, low SNR can produce invalid measurements and consequent
target undetectability. This is the case, for example, of very far objects having
a very low signal measured by the sensor. In fact, the incoming signal directly
depends on the photon flux hitting the sensor (therefore on the integration
time, sensor quantum efficiency, and lens optical transmittance). On the
other hand, the sources of noise are almost exclusively dependent on the
physical characteristics of the sensor. The main noise sources are summarized
in Table 6.13.
Table 6.13 Typical noise sources.
Noise Description Unit
Read noise Inherent to the process
of converting charge
carriers into a voltage
signal for
quantification, and
analog-to-digital
conversion.
e
Dark current Represents the level of
thermally generated
electrons, directly
dependent on
exposure time and
temperature.
e
s
Signal shot noise Inherent natural
variation of the
incident photon flux.
e
s
Sky/background noise Overall optical noise of
the system, composed
by the electronic
noise in the sensor,
and undesired stray
light.
e
s
324 Andrea Colagrossi et al.Applicability
Camera systems have the advantage of being inexpensive, passive, compact,
and power efficient. Furthermore, they provide images at high frame rates
that are readily interpretable by human operators for improved situational
awareness. Cameras are typically usable at ranges of a few centimeters up
to around 100 m, with the exact range being determined by the interplay
among the camera imaging resolution, field of view size, physical dimen￾sions of visual targets, and the employed features (i.e., centroid, shape, refer￾ence points). On the downside, their image output should be processed by
complex algorithms for extracting cues guiding the estimation of spacecraft
state. These algorithms can have low robustness and are often computation￾ally demanding. Camera-based approaches should also deal with foreground
segmentation in order to isolate the relevant sensory input from its poten￾tially confusing background. Furthermore, to operate in low light condi￾tions, camera sensors have to depend on light emitted from external
sources. Thermal cameras have also been proposed to avoid illumination
problems or exploited as aide to the main optical system even though
they offer much lower accuracy [43]. Approaches using a single camera
are referred to as monocular. However, the low cost of camera units permits
pose estimation using two or even more such sensors, giving rise to ap￾proaches referred to as binocular or multiocular, respectively. A list example
of vision-based navigation scenarios may include planetary approach appli￾cation, satellite servicing, active debris removal, Descent and Landing sce￾nario (high or low dynamics), general rendezvous, and docking
application or rovers’ navigation (localization and mapping). In most of
the missions, the navigation cameras will provide a gray-scale image in the
visible wavelength. Depending on the FOV of the camera, we will refer
to Narrow-Angle Cameras (NACs) or Wide-Angle Cameras (WACs).
We refer to NAC when the optics design provides an FOV in the range
of 1e10. On some occasions, but is not very common, a Medium-Angle
Camera (MAC) may be defined, with FOV in between 10 and 30. Finally,
a WAC usually has an FOV larger than 20. NAC will be used when the
target is very far from the observer. Having a smaller FOV implies to have
a larger target apparent dimension on the camera sensor. This is useful at
far range, but it can become problematic at close range when the target
may occupy all the FOV dimension or high accuracy pointing is necessary
to keep it in view. WAC will be used for medium to close distances. The
closer the target is, the wider the FOV may be necessary to satisfy target ob￾ject or surface visibility inside the FOV. A larger FOV will also be considered
Sensors 325in certain scenarios where the target has fast dynamics and crosses the detec￾tor. In this case, a larger FOV allows to capture the streak of the target in one
or more consecutive images granting navigation data extraction. We shall
also note that wide FOV, as for instance 50 or 70 introduces high image
distortion. The narrower the field of view, the larger the baffle design is
needed. Baffle cone will protect the optics and image from light sources
outside of the FOV, generating undesired stray lights. A WAC or NAC
camera will normally offer not only images in visible wavelength but also
in many cases, it also covers near-infrared. When the mission accomplish￾ment will require operations in eclipse or poor illumination conditions,
either active illuminance beam is needed or Thermal Infrared (TIR) cam￾eras. Finally, different studies are also analyzing the utilization of Multispec￾tral or Hyperspectral cameras for navigation [44]. Visible and TIR is the
most convenient combination, while hyperspectral cameras may better facil￾itate a reused concept of instrument to be used both for navigation and for
scientific purposes as characterization or different science observations. For
rovers’ navigation or for close operations where 3D information is required,
stereovision cameras are selected. Stereo cameras are composed by two op￾tical heads aligned, temporally synchronized and with certain distance sep￾aration granting overlap of the FOV. In certain missions, the images will
only be acquired on-board while information extraction process is per￾formed on ground, because of the on-board computing constraints. On￾board autonomy is mandatory for critical operations, such as scenarios
involving fast dynamics or huge delays and latency in communication that
would make ground operations impossible. As a clear example, ground op￾erations are impossible if the spacecraft GNC is dealing with descent and
landing operations on a small body, which requires to extract data from im￾ages at the slowest frequency of 1 frame per second, and the spacecraft to or
from ground communication takes 9 min. The on-board processing in that
case is mandatory, under a big level of autonomy, and it requires fast image
acquisition by navigation cameras, as well as on-board camera image correc￾tions (preprocessing), before the data extraction. Ground operations may ac￾quire raw images and perform the image preprocessing correction offline to
have a more accurate output, while for on-board processing, these correc￾tions should be applied on the fly. The image preprocessing corrections
include radiometric and geometric calibration. Radiometric calibration is
performed to produce an image that ideally would correspond to a perfect
detector while the geometric calibration corrects distortions produced by
the finite-aperture optics and motion. Optionally, it is also possible to
326 Andrea Colagrossi et al.validate the images in order to detect (and discard) “contaminated” images
that may degrade the optical navigation performance. In fact, processing
only the best shots improve both the navigation accuracy and the robustness.
The low-level image correction functionalities should be, for example, in
charge, but not limited to, of the defective pixel correction, photoresponse
nonuniformity correction, dark signal correction, background noise reduc￾tion due to ionizing particle events or others, motion or aberration correc￾tion, and the focal length scale factor calibration. The preprocessing
functions should be considered in the sensor suite selection. The navigation
cameras should also provide certain metadata together with the images, for
the proper identification and relevant information used in the navigation
processing. These metadata include health status, self-tests, configuration
options, thermal measurements, and very important, a time stamp of the im￾age. There are several camera operation parameters that should be configu￾rable for the proper operation, such as integration time, window position
and size, start of integration, and acquisition options as binning, cropping,
or even image stacking (stacking improves the SNR and help faint objects
detection in trade-off configuration with integration time). The resolution
in pixels vary and should be traded-off in between the need for large amount
of information and the computational effort that would require processing
it. Typical pixel resolutions trade-off selection uses images of 2048 
2048 or 1024  1024 pixels. Among the most interesting parameter to
consider in the camera selection is the pixel size, image area, frame rate,
quantum efficiency, noise, modulation transfer function (MTF), environ￾mental endurance, and shutter property.
A navigation camera for space shall provide good SNR (high sensitivity,
low noise), fast frame rates, high pixel count, and low power consumption,
as well as being cost-effective production. Both the rolling shutter artifacts as
well as the global shutter drawbacks can be compensated, but this means
adding logic and complexity, translated in cost.
Design
A navigation camera design shall encompass the following steps:
• Image sensors selection. The sensor size has to be selected according to
the required accuracy, considering the mission scenario and desired nav￾igation performance.
Sensors 327• SNR analysis and magnitude detectability. Given the target characteris￾tics and the mission scenarios, an evaluation of the object magnitude and
of the resulting SNR is necessary to guarantee observability.
• Optical design. It is the process of selecting and assembling optical com￾ponents to satisfy the lens requirements. This step is necessary when
commercial lenses are not available for the desired application.
• Stray light assessment and baffle design. Light sources (e.g., Sun, planets)
can generate undesired stray light hitting the sensor, degrading imaging,
and consequently, navigation performance. For this reason, the stray light
sources should be identified for the given mission profile and a proper
baffle should be designed to limit this undesired effect. In fact, baffles
are mechanical systems that, through a series of internal reflections, can
shield the incoming stray lights.
• Thermal design. Camera working domain must be ensured through
proper thermal regulation systems to guarantee expected performance.
Additional mechanical features as pointing structures may not be directly
related to the camera but to the assembly in the satellite, either under the
responsibility of the satellite bus platform or under the GNC or AOCS
responsible.
Table 6.14 summarizes the strength and weakness of cameras:
LIDAR
LIDAR is a type of electro-optical sensor that use beam-steering devices to
actively direct a laser beam in particular directions and rely on different phys￾ical principles (namely triangulation, phase shift, or time-of-flight) to mea￾sure range. An example of the working principle of scanning LIDARs is
represented in Fig. 6.32.
Table 6.14 Cameras strengths and weaknesses.
Strengths Weaknesses
Reliable Highly sensible to illumination
conditions
Affordable Not robust to the presence of celestial
body in the field of view
Low power consumption
Low hardware complexity
Can be used for supervised applications
328 Andrea Colagrossi et al.The primary advantage of laser-based sensors is that they offer highly ac￾curate output, which is often combined with a large operating range.
Depending on their operating principle, their operating range is between
a few meters (triangulation) to several kilometers (time-of-flight). The oper￾ating principle also influences the sensor speed, i.e., the number of point
measurements that can be accumulated per second. Besides taking longer
to complete a scan, a low scanning speed also implies that measurements
can be distorted due to the relative motion between the sensor and the target
during the scan. This, however, is overcome by the recently introduced flash
(or detector array) LIDARs, which achieve high frame rates by emitting
light pulses within their entire field of view, bypassing scanning. The work￾ing principle for this kind of LIDARs is depicted in Fig. 6.33.
Laser scanners readily provide 3D measurements which are also insensi￾tive to illumination changes and shadows. Their primary drawbacks are that
they are expensive, bulkier, less power efficient, and have a lower resolution
and a small field of view. Moreover, they imply higher computational cost
to process a bigger amount of data, usually point clouds. These drawbacks
are particularly true for flash LIDARs, which require many times more
instantaneous power than scanning LIDARs because they need to divide
the power across many detectors of the pixel array, but they don’t have
any moving parts. This division limits practical combinations of their range,
FOV size, and resolution. As a general guideline, flash LIDARS are better
suited to scenarios involving faster objects within a smaller volume. It is
also noted here that a small field of view might in turn constrain a chaser’s
approach trajectory toward a target spacecraft. A summary of the main ad￾vantages and drawbacks is reported in Table 6.15.
Figure 6.32 Scanning LIDAR.
Sensors 329Altimeters
Satellite altimetry was developed in the early 60s, and it has generally
been used to provide accurate measurements of the shape of a planetary sur￾face. This kind of measurement can be widely applied to oceanography,
geodesy, and geophysics. The altimeter working principle is to measure
the travel time of an electromagnetic signal from the spacecraft to the plan￾etary surface and back. This is common to all different kinds of altimeters,
but the properties of the signal can infer its class: single beam, multibeam,
or scanning synthetic aperture system. Furthermore, the operating frequency
of the instrument implies a further classification, i.e., radar and laser. For sci￾ence applications, scanning and multibeam systems are widely used. On the
Figure 6.33 Flash LIDAR.
Table 6.15 LIDAR strengths and weaknesses.
Strengths Weaknesses
Robust to operations with poor
illumination conditions
High cost
Easy segmentation High power consumption
3D position measurements Complex hardware
High computational cost
330 Andrea Colagrossi et al.contrary, in the GNC domain, mostly single beam altimeters are adopted. In
this chapter, the main characteristics of single beam radar and laser altimeters
are presented.
Altimetry principles
The objective of satellite altimetry is to measure the range between the sat￾ellite and the planet surface. A primary design parameter of an altimeter sys￾tem is the area on the planet surface over which the range from the altimeter
to the reference surface is measured. Intuitively, this can be approximated as
the antenna footprint. The footprint of an antenna is traditionally defined, in
a beam-limited sense, as the area on the target surface within the field of view
subtended by the beamwidth of the antenna gain pattern. Thus, narrow
beams have a higher accuracy, but they would require very large antennae
that are not viable for space missions. Moreover, this kind of functional
mode is more sensible to mispointing. In a pulse-limited configuration, the
same results can be achieved with an antenna with a smaller diameter.
This is possible because the return pulse is dictated by the length of the emit￾ting pulse as shown in Fig. 6.34. In other words, the radiated phase front
meets the scattering surface over an area that is limited by the width of
the transmitted pulse.
Figure 6.34 Beam-limited (left) and pulse-limited (right) footprint.
Sensors 331All the radar altimeters flown in space are pulse-limited, except for laser
altimeters that are usually beam-limited due to their higher working
frequency.
Radar and laser altimeters
The main difference between radar and laser altimeter is their working fre￾quency. Both approaches have their strength and weakness that are summa￾rized in Table 6.16.
As previously detailed, radar altimeters have a larger footprint with
respect to laser altimeters. This implies a lower “horizontal” resolution
but a comparable “vertical” accuracy. It is important to consider that radar
altimeters do not suffer of attenuation in the presence of atmosphere. This
is usually relevant for Earth applications (laser altimeters are weather depen￾dents), but it may be neglected for some space applications. Size and mass are
comparable, but radar antennae are usually larger and heavier but with a
limited power consumption.
While several past Moon and Mars missions relied on radar altimeters
[45,46], the current trend is to move toward laser-based sensors, such as LI￾DARs [47]. Despite the kind of altimeters, some aspects directly related to
GNC can be highlighted. An advantage of using altimeters as additional sen￾sors is that altitude measurements can be continuously collected without
sunlight or visibility restrictions. However, an altimeter provides measure￾ments relative to the surface, which may have an unknown height above
the planet’s center of mass; this is particularly true for small-body and un￾known targets. In these cases, a shape model needs to be estimated or
updated simultaneously with the spacecraft’s orbit during the initial
approach phase. Note that altimeters are extremely useful in GNC for
Table 6.16 Radar versus laser altimeter.
Radar altimeter Laser altimeter
Footprint km level m level
Vertical accuracy Tens of centimeters Tens of centimeters
Atmospheric
Attenuation
Yes No
Size and mass Higher Lower
Power consumption Lower Higher
332 Andrea Colagrossi et al.landing applications, since in this case, the relative distance with respect to
the surface is the fundamental quantity to measure.
Altimeter model
A simple model of a single beam altimeter can be implemented by consid￾ering a single ray hitting a spherical surface of a planet or an astral body. A
simplified ray-tracing algorithm can be employed to find the intersection
between the altimeter beam and the spherical body’s surface. Finding inter￾section points between a ray and a sphere is a known problem, and it can be
tackled by solving a quadratic equation:
At
2 þ Bt þ C ¼ 0;
with:
A ¼ d$d
B ¼ 2p$d
C ¼ p$p  R2
where d is the direction of the ray, p is the vector from the origin of the ray
to the center of the sphere, t is the length of the ray, and R is the radius of the
body. This quadratic equation has two solutions, corresponding to the two
points on the sphere as in Fig. 6.35.
Furthermore, the determinant of the quadratic equation
(D ¼ B2  4AC) helps identifying three different cases:
• D < 0: there is no intersection with the sphere.
• D ¼ 0: there is only one solution of the equation, i.e., the ray is tangent
to the sphere surface.
• D > 0: there are two solutions corresponding to the two segments SP1
and SP2 with respect to the sensor position S.
The 3D points in the planet centered frame can be computed as:
P1 ¼ p þ d*SP1
P2 ¼ p þ d*SP2
In order to determine which point is actually observed, the projections of
the two vectors onto the beam direction are compared and the smallest one
is taken as observed point.
Sensors 333An alternative approach exploits a more complex model, considering the
actual texture and roughness of the surface of the planet. This is done by per￾forming a ray tracing with a 3D model of the observed body. This operation
cannot be described by a simple mathematical model, and ad hoc solutions
should be implemented.
References
[1] Karris, S.T., Introduction to Simulink with Engineering Applications, Orchard
Publications.
[2] International Vocabulary of MetrologyeBasic and General Concepts and Associated
Terms, JCGM, 2012. : http://www.bipm.org/en/publications/guides/vim.html.
[3] J. Morrison, Statistics for Engineers: An Introduction, John Wiley & Sons, 2009.
[4] W.J. DeCoursey, Statistics and Probability for Engineering Applications with Micro￾soft Excel, Newnes - Elsevier, 2003.
[5] T. Forsberg, N. Grip, N. Sabourova, Non-Iterative Calibration for Accelerometers
With Three Non-orthogonal Axes and Cross-Axis Interference, 2012.
[6] S.U. Jan, Y.D. Lee, J. Shin, I. Koo, Sensor fault classification based on support vector
machine and statistical time-domain features, IEEE Access 5 (2017) 8682e8690.
[7] A. Colagrossi, M. Lavagna, Fault tolerant attitude and orbit determination system for
small satellite platforms, Aerospace 9 (2022) 46, https://doi.org/10.3390/
aerospace9020046.
[8] https://www.gps.gov/.
[9] https://www.glonass-iac.ru/en/about_glonass/.
Figure 6.35 Ray-sphere intersection.
334 Andrea Colagrossi et al.[10] https://www.gsc-europa.eu/.
[11] http://en.beidou.gov.cn/.
[12] https://qzss.go.jp/en/.
[13] P.J. Teunissen, O. Montenbruck (Eds.), Springer Handbook of Global Navigation Sat￾ellite Systems, 10, Springer International Publishing, New York, NY, USA, 2017,
pp. 978e983.
[14] H. Liu, X. Cheng, G. Tang, J. Peng, GNSS performance research for MEO, GEO, and
HEO, in: China Satellite Navigation Conference, Springer, Singapore, May 2017,
pp. 37e45.
[15] A. Delépaut, P. Giordano, J. Ventura-Traveset, D. Blonski, M. Schönfeldt,
P. Schoonejans, R. Walker, Use of GNSS for lunar missions and plans for lunar in￾orbit development, Advances in Space Research 66 (12) (2020) 2739e2756.
[16] J. Miller, Planetary Spacecraft Navigation, Springer International Publishing, 2019.
[17] D.W. Curkendall, J.S. Border, Delta-DOR: the one-nanoradian navigation measure￾ment system of the deep space networkdhistory, architecture, and componentry, The
Interplanetary Network Progress Report 42 (2013) 193.
[18] Y. Doat, M. Lanucara, P.M. Besso, T. Beck, G. Lorenzo, M. Butkowic, ESA tracking
networkeA European asset, in: 2018 SpaceOps Conference, 2018, p. 2306.
[19] J.D. Searcy, H.J. Pernicka, Magnetometer-only attitude determination using novel
two-step Kalman filter approach, Journal of Guidance, Control, and Dynamics 35
(6) (2012) 1693e1701.
[20] S. Carletta, P. Teofilatto, M. Salim Farissi, A magnetometer-only attitude determina￾tion strategy for small satellites: design of the algorithm and hardware-in-the-loop
testing, Aerospace 7 (1) (2020) 3.
[21] P. Tortora, Y. Oshman, F. Santoni, Spacecraft angular rate estimation from magne￾tometer data only using an analytic predictor, Journal of Guidance, Control, and Dy￾namics 27 (3) (2004) 365e373.
[22] NASA, Space Vehicle Design Criteria: Spacecraft Sun Sensors, NASA SP-8047, 1970.
[23] F.L. Markley, J.L. Crassidis, Fundamentals of Spacecraft Attitude Determination and
Control, Space Technology Library, Springer, New York, NY, 2014.
[24] B.O. Sunde (MSc. thesis), Sensor Modelling and Attitude Determination for Micro￾satellite, 90, Norwegian University of Science and Technology, 2005.
[25] NASA, Space Vehicle Design Criteria: Spacecraft Earth Horizon Sensors, NASA SP￾8033, 1969.
[26] J.R. Wertz, Spacecraft Attitude Determination and Control, Kluwer Academic, Dor￾drecht, 1978.
[27] European Cooperation for Space Standardization, ECSS-E-ST-60-20C Rev. 2 e Star
Sensors Terminology and Performance Specification, ESA Requirements and Stan￾dards Division, 2019.
[28] C.C. Liebe, Star trackers for attitude determination, IEEE Aerospace and Electronic
Systems Magazine 10 (6) (1995) 10e16, https://doi.org/10.1109/62.387971.
[29] D. Hoag, Apollo Guidance and Navigation Considerations of Apollo IMU Gimbal
Lock, MIT Instrumentation Laboratory Document E-1344, 1963.
[30] A.D. King, Inertial Navigation e Forty Years of Evolution, 1998.
[31] T.F. Wiener, Theoretical Analysis of Gimballess Inertial Reference Equipment Using
Delta-Modulated Instruments (MIT Ph.D. thesis), 1962.
[32] D.H. Titterton, J.L. Weston, Strapdown Inertial Navigation Technology, second ed.,
The institution of Electrical Engineers, 2004.
[33] D.F. Parker, G.A. Maugin, Recent Developments in Surface Acoustic Waves, Springer
Verlag, 1988.
Sensors 335[34] S. Middlehoek, S.A. Audet, Silicon Sensors, Academic Press, 1989.
[35] M. Young, Optics and Lasers, Springer Verlag, 1992.
[36] A.D. Kersey, T.A. Berkoff, W.W. Morsey, Fibre-grating based strain sensor with phase
sensitive detection, in: Proceedings 1st European Conference on Smart Structures and
Materials, 1992.
[37] S. Merhav, Aerospace Sensor Systems and Applications, Springer, New York, 1962.
[38] N. Barbour, Inertial navigation sensors, NATO RTO lecture series-232, Advances in
Navigation Sensors and Integration Technology (2003).
[39] N. Barbour, R. Anderson, J. Connelly, et al., Inertial MEMS system applications,
NATO RTO lecture series-232, Advances in Navigation Sensors and Integration
Technology (2003).
[40] Y. Dong, MEMS inertial navigation systems for aircraft, in: MEMS for Automotive
and Aerospace Applications, Woodhead Publishing, 2013.
[41] G. Langfelder, M. Bestetti, M. Gadola, Silicon MEMS inertial sensors evolution over a
quarter century, Journal of Micromechanics and Microengineering 31 (2021).
[42] IEEE Standard Specification Format Guide and Test Procedure for Single-Axis Inter￾ferometric Fiber Optic Gyros, IEEE Std 952-1997, 1998.
[43] G.B. Palmerini, Combining thermal and visual imaging in spacecraft proximity oper￾ations, in: 2014 13th International Conference on Control Automation Robotics &
Vision (ICARCV), IEEE, December 2014, pp. 383e388.
[44] D. Rondao, N. Aouf, M.A. Richardson, O. Dubois-Matra, Benchmarking of local
feature detectors and descriptors for multispectral relative navigation in space, Acta
Astronautica 172 (2020) 100e122.
[45] B.D. Pollard, C.W. Chen, A radar terminal descent sensor for the mars science labo￾ratory mission, in: 2009 IEEE Aerospace Conference. IEEE, 2009.
[46] R.D. Braun, R.M. Manning., Mars exploration entry, descent and landing challenges,
in: 2006 IEEE Aerospace Conference. IEEE, 2006.
[47] T.P. Setterfield, et al., LiDAR-inertial Based Navigation and Mapping for Precision
Landing, 2021.
[48] ECSS-E-ST-60-20C Rev. 2, Stars Sensors Terminology and Performance
Specification.
[49] M.E. Pittelkau, Sensors for attitude determination, in: R. Blockley, W. Shyy (Eds.),
Encyclopedia of Aerospace Engineering, Wiley, Chichester, 2010.
336 Andrea Colagrossi et al.CHAPTER SEVEN
Actuators
Andrea Colagrossi1
, Lisa Whittle2
, Vincenzo Pesce3
,
Stefano Silvestrini1
, Matteo Battilana4
1
Politecnico di Milano, Milan, Italy
2
Asteroid Exploration, Leiden, the Netherlands
3
Airbus D&S Advanced Studies, Toulouse, France
4
OHB Italia S.p.A., Milan, Italy
Actuators are the ultimate elements of the guidance, navigation, and control
(GNC) chain, executing forces and torques as commanded by the control
section. They are the components physically injecting the output of the
GNC into the dynamics in a way that the spacecraft can reach the desired
reference state. With the usual human metaphor, actuators are the body parts
allowing us to move around the world and to accomplish tasks (e.g., legs,
arms, hands, etc.). The GNC design shall select and configure the actuators
on the spacecraft, such that all the computed control forces and torques are
correctly applied on the dynamics, both translational and rotational. For
these reasons, the GNC designer shall know, understand, and correctly
model the actuators to support its design process. This chapter is dedicated
to briefly present all the major actuator typologies for spacecraft GNC appli￾cations, to discuss their operating principles, to highlight their peculiarities,
strengths, and weaknesses, to categorize the available components according
to their performances, and to discuss the most relevant modeling techniques
and rules.
This chapter is structured as follows:
• Actuator modeling for GNC. In this section, the actuator modeling tech￾niques are presented, discussing the main implementation principles of
the most common numerical models to include the actuators behavior
in the GNC design, analysis, verification, and validation phases. The
principles of errors modeling and the most common actuators faults
are also introduced.
• Thrusters. This section presents the main operating principles and the
main component assemblies of thrusters for space applications, it intro￾duces the concept of thrust management actuation functions, and it
shows a simple thruster model implementation in MATLAB/Simulink.
Modern Spacecraft Guidance, Navigation, and Control
ISBN: 978-0-323-90916-7
https://doi.org/10.1016/B978-0-323-90916-7.00007-X
© 2023 Elsevier Inc.
All rights reserved. 337 j• Reaction wheels. This section introduces the reaction wheels, and it pre￾sents the main characteristics of these actuation components. Friction
and microvibrations affecting the dynamics of reaction wheels are briefly
discussed, together with the actuation functions to operate multiple re￾action wheels assemblies. An example reaction wheels model imple￾mented in MATLAB/Simulink is also described.
• Control moment gyros. In this section, control moment gyros (CMGs) are
presented and compared with reaction wheels as alternative angular mo￾mentum exchange devices. Their operating principles and functional
characteristics are also discussed.
• Magnetorquers. This section describes the magnetic actuators for spacecraft
applications, including their main limitations to guarantee a complete
three-axis controllability. Alternative magnetorquers assemblies are
presented, and a simple MATLAB/Simulink model implementation is
shown at the end of the section.
Actuator modeling for GNC
Correct actuator modeling is fundamental for GNC applications. In
fact, algorithms testing shall rely on proper actuator models to have a truthful
representation of the available control forces and torques. Moreover, the
control laws shall be designed and implemented to positively exploit the
on-board actuation capabilities. Then, proper actuator models are needed
to outline the best actuation functions and to minimize the impact of actu￾ator’s limitations on the GNC system. Consequently, we shall learn what the
model of an actuator is, how it is built, and how it is used during the GNC
design and verification processes. The following discussion will repeat, for
reader’s convenience, some concepts already introduced in the sensor
modeling section of Chapter 6 e Sensors, but it will underline those con￾cepts that are peculiar for the actuator modeling.
An actuator is a component exploiting a physical principle to apply a
force or a torque on the spacecraft while on orbit. Given the characteristics
of the space environment, the methods to do so are limited with respect to
what is available on the Earth. They are mainly based on momentum ex￾change and conservation principles, electromagnetic interactions, and fluid
management.
The first method is by far the most used and relevant for space applica￾tions. Specifically, momentum exchange devices can put a mass in rotations
to generate reaction torques, as in reaction wheels, or CMGs, but they can
338 Andrea Colagrossi et al.also accelerate a mass along a certain direction, producing a force in the
opposite one, as in the case of thrusters. Note that space propulsions and
thrusters are based on Newton’s third law of action-reaction, which has
been used by Newton himself to derive the law of conservation of mo￾mentum. Moreover, thrusters can be even used to generate torques if
they have an offset with respect to the Center of Mass (CoM) of the
spacecraft.
Components based on electromagnetic interaction principles are
commonly applied to generate a control torque on spacecraft orbiting
around planets with a magnetic field, like in the case of magnetorquers. It
shall be noted that electromagnetic thrusters exploit electromagnetism to
accelerate ions to create a force. Hence, they belong to the class of mo￾mentum conservation actuators, despite their name might be misleading.
Finally, fluid management actuators can be used to dissipate spacecraft
energy by means of internal viscous forces. However, their applications
are very rare, and often limited just to nutation damping [1].
Some applications also exploited large external spacecraft surfaces to
generate forces or torques by using solar radiation or aerodynamics pressure.
The former is based on momentum exchange between the spacecraft and
the electromagnetic radiation, the latter uses aerodynamic surfaces to
actively control lift and drag values. However, both methods are not very
common, and they have limited applicability range [2e5].
The actuator receives a command by the control block, after the actua￾tion function processing, and it elaborates it to operate its internal compo￾nent to generate the desired forces and torques. In modern spacecraft
applications, the command interface is commonly digital, and the internal
processing units convert the commands in analogic electrical signals for
the final actuation (e.g., motor speed, valve opening status, and current
intensity). During the whole process, the desired status is inevitably distorted
and modified with respect to the commanded one. Moreover, internal
frictions, electrical resistance, oscillations, vibrations, and other spurious
effects further disturb the actuator’s output. A proper actuator model shall
be able to represent these deviations. We are going to mathematically refer
to this as:
f

ðÞ¼ t fðÞþt εfð Þt ; (7.1)
t

ðÞ¼ t tðÞþt εtð Þt ; (7.2)
Actuators 339where fðtÞ and tðtÞ are the actuated force and torque, fðtÞ and tðtÞ are the
quantities commanded by the GNC system, εfð Þt and εtð Þt are the respective
overall errors and spurious effects.
An actuator model is a mathematic representation of the actuation pro￾cess converting the desired command into the physical output generating
the force or the torque. It is developed for a specific modeling purpose,
and, in fact, there exist two main types of actuator models: functional and
performance models.
Functional actuator models are implemented to serve as input for
detailed analyses and accurate simulations. They describe each internal func￾tion and physical phenomena along the actuation processing, and they are
representative of the actuator dynamics for realistic output profiles. The
complete equipment elaboration chain is typically modeled, from command
acquisition to internal element operations and dynamics. Functional models
are used to accurately simulate the actuator dynamics to estimate the impact
on the spacecraft motion. In addition, they allow to estimate if the actuator is
correctly operated inside the prescribed ranges.
Performance actuator models represent the way in which the actuator
generate forces and torques, including the main limitations and errors.
Moreover, they quantify the consumed resources in order to support the sys￾tem design process. Primarily, for what concern the power budget and the
propellant mass budget. In fact, differently from sensors, the actuators have a
close relation between the actuation intensity and the resource consump￾tion. Hence, it is crucial to model the impact of a certain command to
the actuators on the power and mass budgets. Performance models are
used to verify how the GNC system works, highlighting the impact on
the resources of the whole spacecraft. They are also useful to discover
possible bottlenecks of the GNC design given the performance and the
maximum operative limits of the selected actuators. Performance models
use equivalent generic mathematical models, and they commonly model
only the principal and the most influent limitations of the actuators.
In analogy with sensor models, actuator models’ interfaces need to be
defined according to the specific type of model in use and to its specific
application. In fact, actuator models are exploited in accelerated simulators
for design and development, but they are also used in real-time test benches
for verification purposes. In the first case, equivalent engineering data inter￾faces are enough, while in the second application scenario, the model input/
output should be as close as possible to the real ones. Notwithstanding, it is
340 Andrea Colagrossi et al.suggested to implement an actuator model having in mind all its possible ap￾plications, since it is very common to port the model from the accelerated
simulation environment (e.g., MATLAB/Simulink) to the real-time one.
Finally, we shall consider that even actuator models shall be validated, mean￾ing that they shall be truly representative of the real actuator behaviors.
Errors modeling
Actuator models for GNC applications are based on mathematical models of
the internal dynamics governing the actuation principle, including all the
main limitations and errors existing inside the actuator components. They
take as input the commands elaborated by the control and actuation func￾tions, and they provide as output the resulting forces or torques. The latter
are then set as input for the block simulating the spacecraft dynamics.
The format and the characteristics of the input depend on the typology
of actuator model, which also influence the way in which the internal pro￾cesses are modeled. As said, the most complete functional models receive the
input as the real components would do, and they include almost every
dynamical phenomenon characterizing the actuator. A generic functional
actuator model is shown in Fig. 7.1.
Actuator models are strongly dependent on the specific component, in
fact the internal dynamics is specific for each actuator type. For instance, re￾action wheels models include the dynamics of the electric motor, with its
control unit, friction, vibrations, and other disturbances. Or, correspond￾ingly, thruster models consider fluidic valves operations and the thermogas
dynamics of the propellant. Although, in general, latencies, offset errors,
misalignments, and actuator saturation are modeled for any actuator. The er￾rors due to the specific dynamical evolution are included in the actuator
model by inserting the disturbance effects into the internal dynamics block.
Note that actuator commands come in discrete time as computed from
the GNC, then the internal dynamics block converts it in continuous time
for the input in the spacecraft dynamics. In fact, the actuator output is a real
physical quantity existing in continuous time. Despite this, the command
Figure 7.1 Generic functional actuator model.
Actuators 341discretization and the temporal evolution of the internal dynamics may
induce a discrete-like actuation output. For instance, the concept of mini￾mum torque or force pulse is related to this effect, and the shortest actuation
time is a finite value larger than the minimum possible bit.
Actuator modeling is based on a solid knowledge of the physics behind
the actuation principles. Indeed, electric motor dynamics, dynamic and static
friction, electromagnetic induction, thermochemical processes, vibrations
and rotor balance, fluid dynamics, and so on are just some of the physical
effects influencing the internal actuator dynamics. For each specific func￾tional actuator model, we shall understand all the main principles and phys￾ical laws governing the actuators.
Performance models do not typically include the internal dynamics, and
the ideal forces and torques to be actuated are just processed adding a direct
realization of the specific dynamically induced errors. Moreover, the main
actuation limitations are included as well, as shown in Fig. 7.2. Performance
models are used to quantify the active consumption of resources by the ac￾tuators. In fact, these components are commonly the most demanding for
the GNC system in terms of resource budgets. Their consumption is strictly
related to the actuation intensity, and, thus, performance models include
resource consumption models that compute the resource spent for a given
commanded force or torquedfor instance, the electric power need, the
propellant mass flow, or the current intensity. Note that resource consump￾tion models can also be included in the functional actuator models, which
are, in this case, referred to as functional-performance models.
Actuator faults
Actuator faults have a huge impact on the GNC functionalities and even on
the spacecraft lifetime. In fact, it is more difficult to guarantee many degrees
of redundancy on the actuators, than on the sensors. Failed actuators may
lead to a partial loss of the controllability or, in the worst cases, to the loss
of the entire mission. To minimize these risks, we should include as many
Figure 7.2 Generic performance actuator model.
342 Andrea Colagrossi et al.redundancies as possible, but we shall also include degraded control modes
that can exploit the remaining operational components to achieve at least a
survival model stabilization. Then, the knowledge of typical actuator faults is
fundamental to properly deal with the GNC design in faulty conditions.
A failed actuator is commonly switched off and removed from the opera￾tional actuation set, but the faulty units can be difficult to be identified. In fact,
the actuator forces and torques are not directly sensed back or measured by the
GNC, and, unless the component has an internal error feedback indicator, the
failure shall be detected from anomalies in the spacecraft dynamics [6e8].
The actuator faults modeling is strongly dependent from the specific
actuator and its internal dynamics, and it is difficult to generalize the fault
behaviors as done for the sensors in Chapter 6 e Sensors. Typical actuator
faults are commonly related to premature wear on mechanical components,
such as bearings, valves, gimbals, or gearboxes. Even electrical elements are
susceptible to faults. For example, electric motors or, in general, solenoids
(i.e., magnetorquers) may be affected by low resistance fault, due to over￾heating, physical damage, or degradation of the insulation of the coil wind￾ings. Then, insufficient isolation between the windings or conductors may
lead to short circuits and, eventually, to complete failure. Similarly, these
components can be generally affected by overheating, electrical or mechan￾ical overload, which irreversibly damage the actuator unit. The results of
these damages in the actuation output can be categorized in:
• Decreased actuation force or torque.
• Increased bias force or torque.
• Oscillatory and irregular force or torque.
• Continuous generation of actuation force or torque.
• Failure to respond to control signals.
The last two faulty conditions typically determine the loss of the compo￾nent that shall be switched off and excluded from the actuation control func￾tions. The first three may be dealt with dedicated control techniques.
To make a practical example of actuator faults, momentum exchange
devices are considered. In particular, we focus on reaction wheels. They
are the most common actuators for spacecraft attitude control, and they
are also among the spacecraft components more prone to fail. Indeed, at least
one degree of redundancy is always included with these actuators. The most
typical reaction wheels faults are:
• Random increase in reaction wheel motor current. This is typically due
to some hardware level failure in the motor driver unit, and it determines
sudden variations of control torque.
Actuators 343• Increase in friction or vibrations. This is the most common fault due to
the wear of bearing material over time or due to some problems in the
lubrications of the component. The result is an increased torque bias
and torque noise.
• Bus voltage failure at high speed. This fault may take place when the bus
voltage is low and a large back electromotive force is present because the
reaction wheel motor is operating at a high speed. This fault limits the
motor current and, consequently, the motor torque.
• Torque oscillations and sudden steps at low frequency. This is due to var￾iable lubricant dynamics and to bearing nonlinear friction when the re￾action wheels are operated at low speed.
Actuator faults need to be simulated in order to reproduce some failure
scenarios that resembles real-life faults and failures by utilizing the concept of
fault injection into the simulated system. Thus, actuator models shall be
capable to reproduce the possible faults that may occur while on orbit
with the purpose to design and analyze GNC systems with fault detection
and recovery capabilities.
Thrusters
In order to control the spacecraft position, to launch a body in space,
or to maneuver from an orbit to another, we need a control force. This con￾trol force is generated from the acceleration of mass through the nozzle of a
propulsion system, which results in an equal and opposite force e as dictated
by Newton’s third law. This force is defined as thrust, and it is generated by
an actuator denoted as thruster. The propulsion subsystem is needed for po￾sition and orbit control purposes, but also for attitude control. Indeed, thrust
can be generated with a lever arm with respect to the spacecraft’s CoM.
There are a few design factors that must be well-accounted for the propul￾sion subsystem design process, which will heavily depend on the specific
mission. Perhaps one of the most pertinent ways to interpret the perfor￾mance of the propulsion system is in terms of the velocity increment capa￾bility, referred to as the Delta-V or DV. This is computed using
Tsiolkovsky’s rocket equation:
DV ¼ Ispg lnmi
mf

where mf ¼ m0  mp is the final spacecraft mass, m0 is the initial mass, mp
is the mass of propellant on-board, g is Earth’s gravitational acceleration, and
344 Andrea Colagrossi et al.Isp is the specific impulse of the thruster. Specific impulse is a key design
parameter in thruster design e it is the ratio of the thrust, F, to the weight
flow rate of thruster propellant, mg_ . This value conveys how efficiently the
fuel is turned into thrust by the propulsion system.
Isp ¼ F
mg_
where m_ is the mass flow rate.
For preliminary design purposes, an alternate form of this equation is
often used, which allows the calculation of the mass of fuel needed for a
desired DV.
mp ¼
2
6
4
e

DV
Ispg

 1
3
7
5 ¼ m0
2
6
4
1  e

DV
Ispg
3
7
5
The total DV mission requirement will incorporate all operational as￾pects such as: orbital insertion, maneuvers, and corrections, in addition to
attitude control. For more complex, safety critical missions, there may also
be additional constraints such as Collision Avoidance Maneuvers (CAMs)
that must also be allocated for within the DV budget. A thruster with
high Isp will therefore use less propellant. Other important performance re￾quirements may include propulsion operating pressure, thruster redundancy,
and propellant mass. Constraints may be imposed due to the physical limi￾tations of the spacecraft design, with respect to thruster position and orien￾tation. For instance, plume impingement, described in Chapter 3 e The
Space Environment, is a critical concern for many missions (especially where
optical instruments are involved), so there could be some limitations in terms
of thruster configurations, and this may consequently impact propulsion
performance.
Thrusters assembly
In broad terms, propulsion is generally divided into three subcategories: cold
gas, chemical, or electric propulsion. Alternatives such as solar sails, nuclear,
etc., will not be covered here but are also worth mentioning [9e11]. Cold
gas propulsion systems are the simplest of all: consisting of a controlled, pres￾surized gas and a nozzle. Cold gas has a low performance but is favored when
simplicity is the priority, in addition to low precision needs. Chemical pro￾pulsion usually involves a chemical reaction, and it can include the following
Actuators 345subcategories: liquid, solid, and hybrid, depending on the state of the pro￾pellant. In general, when referring to solid systems, the term motor is used,
whereas liquid or hybrid systems are referred to as thrusters or engines. Chem￾ical propulsion is the most widely used within the space industry, since
different levels of performance can be achieved using a variety of propellants
and mixing ratios (e.g., monopropellant, bipropellant, or hybrid) [12].
Finally, electric propulsion works by accelerating the mass to a high speed
using electrostatic or electromagnetic fields. Since electric thrusters have a
higher Isp, they typically offer greater fuel efficiency (i.e., fuel consumption
is lower) than chemical propulsion options, but offer lower thrust capability
due to their limited power. A brief overview of these options is given in Ta￾ble 7.1; however, a more comprehensive review of each propulsion type and
their specific advantages and disadvantages is detailed in Ref. [12].
Table 7.1 Overview of the main propulsion types.
Propulsion
type Typical Isp (s) Uses Strengths Weaknesses
Cold gas 30e70 Attitude control,
orbit
maneuvers,
and station
keeping
Simplicity,
reliability,
very
inexpensive
Low
performance,
weight of
system
Solid 280e300 Orbit insertion Simplicity,
reliability,
inexpensive
Nonadjustable
performance,
safety
concerns
Liquid Monopropellant:
220e240
Bipropellant:
305e310
Orbit insertion
(bipropellant
only), attitude
control, orbit
maneuvers,
and station
keeping
High/very high
performance
Complexity,
toxic (some
propellant
combinations)
Hybrid 250e340 Orbit insertion,
orbit
maneuvers,
and station
keeping
Safety,
throttable
nontoxic
Requires
oxidizer fuel
system,
heavier
Electric 300e3000 Orbit insertion
(apogee burn
only), orbit
maneuvers,
and station
keeping
High
performance,
low thrust
Complexity,
higher
development
costs
346 Andrea Colagrossi et al.Thrust management and actuation function
As previously discussed, in order to control the spacecraft, a propulsion sub￾system is necessary to perform the required actuation. The relationship be￾tween the GNC subsystem, actuators, and other subsystems is depicted in
Fig. 7.3. The GNC subsystem (comprising Guidance, Navigation, and Con￾trol functions) will output the required force and torque commanded by the
controller, and this will be used by the Thrust Management Function
(TMF), which will compute the corresponding thruster activations and
on-times. This information can subsequently be used to command the
thrusters on-board the spacecraft. The realized forces and torques will alter
the spacecraft dynamics in order to achieve the desired command (in posi￾tion and/or attitude).
The TMF is a critical component of the GNC subsystem, and its func￾tional scheme is represented in Fig. 7.4. Its purpose is to translate the
controller commanded forces and torques into the corresponding com￾mands for each individual thruster. The position controller commands
forces, while the attitude controller requests torque e this being the case
for all three axes, which results in a 6 Degree of Freedom (DoF) control
capability. The output of the function will consist of a series of “on/off”
commands, depending on the thruster’s position and orientation in relation
to the spacecraft’s CoM at a given moment.
Figure 7.3 Schematic of closed-loop system and relationship between GNC and
thrusters.
Actuators 347The output of the TMF is used directly by the actuators, but there are
some important limitations introduced by the thruster hardware, namely
[13]:
• Coupling of forces and torques due to the thruster layout (usually due to
accommodation and/or redundancy constraints) means it is not always
possible to use dedicated thrusters for specific axis control, instead a
more complex mapping of thrusters is required.
• On/off nature of certain thrusters means that the thrust output can, in
some cases, be either nominal or zero e although some types of thrusters
ensure a certain throttle threshold is maintained.
For an ideal thruster configuration, for which there is a clear correlation
between each thruster and the control of an individual axes in both force and
torque, a “look-up” table may be used. The purpose of this type of table is to
provide the mapping between each thruster and the specific control com￾mands. Unfortunately, this method will only be valid for simple thruster
configurations, where the CoM is fixed throughout operation. Another
drawback of this approach is that it will not be the optimal solution e
with respect to fuel consumption nor precision. One benefit of this approach
is the speed and relatively small CPU requirements, although this can
quickly change when redundancy constraints are applied, as an additional ta￾ble must be added for all possible failure scenarios, as discussed in Ref. [13].
To illustrate the relationship between thrusters and their corresponding
control authority, let us consider a relatively simple thruster configuration
example. It consists of eight thrusters that will provide 5 DoF control of
the spacecraft.
Fig. 7.5 shows the thruster layout relative to the origin (note this location
differs from the CoM location, which is important for subsequent analysis).
Each thruster is mounted at an angle of 60 degrees azimuth, f, and 0 degrees
Figure 7.4 Schematic of an example TMF to compute thruster on-times.
348 Andrea Colagrossi et al.elevation, q; with varying orientations to cover the required DoFs. The ar￾row indicates the plume direction of the thruster, where the resulting thrust
direction vector is acting in the opposite direction toward the spacecraft
body. For the direction vector definition detailed in Table 7.2, note that
both angles are defined in radians.
Figure 7.5 An example of a 5 DoF thruster configuration.
Table 7.2 Example thruster configuration data.
Thruster Position [m] Direction [L]
1 1 1 2 cosðqÞ$cosðfÞ cosðqÞ$sinðfÞ sinðqÞ
2 1 1 0 cosðqÞ$cosðfÞ cosðqÞ$sinðfÞ sinðqÞ
3 1 1 2 cosðqÞ$cosðfÞ cosðqÞ$sinðfÞ sinðqÞ
4 1 1 0 cosðqÞ$cosðfÞ cosðqÞ$sinðfÞ sinðqÞ
5 1 1 2 cosðqÞ$cosðfÞ cosðqÞ$sinðfÞ sinðqÞ
6 1 10 cosðqÞ$cosðfÞ cosðqÞ$sinðfÞ sinðqÞ
7 1 1 2 cosðqÞ$cosðfÞ cosðqÞ$sinðfÞ sinðqÞ
8 1 1 0 cosðqÞ$cosðfÞ cosðqÞ$sinðfÞ sinðqÞ
Actuators 349This configuration can easily be adapted to a look-up table approach
due to the fact that the orientation of the thrusters corresponds directly
to each axis of control. This is in part due to the zero-elevation angle,
but also resulting from the CoM being located equally between the
thrusters and also assuming that this location does not change during
operation. Referring to Table 7.3, it is possible to see the direct correlation
between each thruster and each axis of control. Note that control in the Fz
direction is not possible due to the elevation angle of the thrusters
being zero.
This relatively simple and direct correlation is not always the case for a
number of reasons, some of which have been mentioned and therefore it
can be a little more difficult to directly interpret which thrusters are activated
for which control action. For this reason, on-board computation is neces￾sary, and this is performed using linear programming techniques, using an
algorithm known as the Simplex [14].
The Simplex algorithm allows you to compute the normalized open
ratios of each thruster, y, and from this you may compute the on-time
ton (in seconds) for each thruster, using the thruster sample time, ts. The
on-time will be limited by the minimum possible thrust duration, which
will depend on the characteristics of the thruster itself; specifically, the
Minimum Impulse Bit (MIB). The MIB is the minimum achievable
pulse duration at a certain thrust level and therefore dictates the precision
of the thrusters:
ton ¼ y$ts
where ton and y will consist of the same number of elements as the number
of thrusters, n.
Table 7.3 Example of simplified thruster activation “look-up” table.
Thruster activated
12345678
Fx xxxx
Fy xx xx
Fz
Tx xx xx
Ty xx xx
Tz x x
350 Andrea Colagrossi et al.The thruster allocation problem for n thrusters can therefore be defined
as such:
2
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
4
F1x F2x
F1y F2y
F3x F4x
F3y F4y
/ Fnx
/ Fny
F1z F2z
T1x T2x
F3z F4z
T3x T4x
/ Fnz
/ Tnx
T1y T2y
T1z T2z
T3y T4y
T3z T4z
/ Tny
/ Tnz
3
7
7
7
7
7
7
7
7
7
7
7
7
5
2
6
6
6
6
6
6
6
6
6
6
6
6
6
4
y1
y2
y3
y4
«
yn
3
7
7
7
7
7
7
7
7
7
7
7
5
¼ a
2
6
6
6
6
6
6
6
6
6
6
6
4
Fx
Fy
Fz
Tx
Ty
Tz
3
7
7
7
7
7
7
7
7
5
s ¼ 
FxFyFzTxTyTz
T
where the torsor, s, generated by the thrusters is defined in x; y; z com￾ponents for the force, Fi and torque, Ti: The normalized open ratios, yi  1,
are given for each thruster. A scaling factor, a, is used as part of the opti￾mization criteria, where the cost function, J, is defined as a minimal fuel
problem, while maximizing the scaling factor, a.
Jmax ¼ ðc1y1 þ c2y2 þ c3y3 þ cnynÞ þ caa
where ciði ¼ 1 : nÞ is a coefficient denoting propellant consumption and ca is
a weighting factor [13].
From this Simplex optimization procedure, the open ratios for a given
torsor command, scmd; are computed. Once you have the open ratios and
on-times, you may subsequently compute the realized output torsor,
srealized. One of the steps in the “mapping” between thrusters and the cor￾responding torsors is to generate the influence matrix (or mixing matrix),
Ainf . This matrix relationship shows us the relationship between each
thruster and each DoF.
srealized ¼ Ainf $y
In order to compute Ainf ; which is a 6  n matrix, we must first define a
position vector ri ¼ ½xyz
T and a direction vector di ¼ ½uvw
T such as
those specified in the example given in Table 7.2. We must also define
the thruster position taking into account the CoM location, where:
pi ¼ ri  rCoM ¼ 
Px Py Pz
T
Actuators 351Ainf ¼
2
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
4
u1
jd1j
u2
jd2j
u3
jd3j / un
jdnj
v1
jd1j
v2
jd2j
v3
jd3j / vn
jdnj
w1
jd1j
w2
jd2j
w3
jd3j / wn
jdnj
Px1 
u1
jd1j Px2 
u2
jd2j Px3 
u3
jd3j / Pxn 
un
jdnj
Py1 
v1
jd1j Py2 
v2
jd2j Py3 
v3
jd3j / Pyn 
vn
jdnj
Pz1 
w1
jd1j Pz2 
w2
jd2j Pz3 
w3
jd3j / Pzn 
wn
jdnj
3
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
5
The error in the realized torsor, serror, is then simply:
serror ¼ scmd  Ainf $y ¼ 
FxerrorFyerrorFzerrorTxerrorTyerrorTzerrorT
where serror is a column vector of dimension 6  1.
Use of the Simplex algorithm on-board requires precise knowledge of
the CoM at all points in flight. If this is inaccurate, large errors will be
evident between the commanded and realized torsors. Errors in the realized
torsor will result in trajectory deviations and, most likely, unnecessary fuel
consumption. The error can be due to many reasons, some of which are
physical issues, such as: bias misalignments incurred during the mounting
of the thrusters, discrepancies in the maximum force output by each thruster,
or the specified Isp due to manufacturing error margins. Errors in the thruster
MIB may also have a significant impact on performance, as the MIB corre￾sponds to the minimum torque that can be commanded to the spacecraft.
Uncertainties in the spacecraft mass and inertia can also negatively impact
the thrust vector realization e especially if the CoM is inaccurate. The thrust
duration (specified by ton) is also an important source of error as there are
usually delays in the thrust realization time, which should always be incor￾porated into the GNC simulations to assess the impact on performance.
Thruster timing issues may also be a result of thruster failures, such as
when they are stuck on or off e for instance, when a valve becomes blocked
in place. This is a critical issue that must be dealt with swiftly and normally
with help of the FDIR functions on-board. If the thrusters cannot be recon￾figured after a failure and mission safety is threatened, a CAM may be
executed. Additional complexities occur when effects such as fuel sloshing
352 Andrea Colagrossi et al.and flexible modes impact the dynamic behavior of the spacecraft. Again,
these can alter physical properties such as the CoM, which will in turn
lead to thrust vector errors. Proper thruster performance is only guaranteed
if all these uncertainties are well understood and incorporated into the both
the propulsion and GNC subsystem design process. This involves accurate
modeling of all errors within the closed-loop system, so their impact can
be fully understood, but also to enable design of a robust controller that is
able to compensate for some of these effects. Evidently, there will always
remain an element of uncertainty, but the task is to minimize this wherever
possible.
Table 7.4 summarizes the strengths and weaknesses of thrusters.
Thrusters model
A detailed functional thruster model shall consider the specific thruster ty￾pology. In the case of a simplified thruster model, the main effects can be
modeled as in the example reported in Fig. 7.6. The input command is
directly the desired thrust value, which is then processed to include the la￾tency and the switching dynamics induced by the fluidics and the ignition
Table 7.4 Thrusters strengths and weaknesses.
Strengths Weaknesses
Possibility to generate forces Complex equipment with fluidics
and fuel tanks
Large torques available Large power demand
Net external torque Fuel required (e.g., mass, sloshing,
center of mass variation)
Three axis-control possible Forces and torques poorly (or non-)
throttleable
Figure 7.6 Example thruster model.
Actuators 353system. In fact, two low-pass filters are present to model the noninstantons
variations of the thrust, both in the switching on and in the switching off
dynamics of the thruster. Then, the thrust is scaled according to the thrust
efficiency factor, it is limited by a saturation range, and it is modulated
with a temporal discretization. The latter reproduces the digital nature of
the thruster control electronics, and it helps in modeling the minimum
thrusting interval. Moreover, the thrust is biased in a way that the minimum
thrust value is greater than zero when the thruster is active. Similarly, the
force has a nonlinear scale factor error proportional to the command magni￾tude. When a thrust is commanded, the output is also disturbed with a pink
noise random error. Note that when the thruster is not active, the output
force is zero. Finally, the thrust magnitude is converted in a force vector
considering the mounting axis, with mounting errors. The propellant con￾sumption model is proportional to the actual thrusting force.
Reaction wheels
Reaction wheels are the most common and versatile actuator to con￾trol the spacecraft rotational state. They are used almost on any orbit and sat￾ellite class for precise attitude control, both for nominal modes and in some
architectures, for safe modes. Their working principle is based on the inter￾nal angular momentum exchange between the satellite main body and the
wheels themselves. The overall angular momentum of the spacecraft is:
hb ¼ Iub þ hb
wheels;
where I is the moment of inertia tensor of the spacecraft including the inertia
of the wheels. Then, hb
wheels represents the relative angular momentum of the
wheels along their spin axes with respect to the spacecraft body. If no
external torque is applied, the conservation of angular momentum reads as:
h_b
¼ 0/Iu_ b ¼ h_b
wheels: (7.3)
In the previous equation, without loss of generality, the inertia of the
spacecraft has been assumed to be constant, and the spacecraft to be in simple
rotation around one of its principal inertia axes.
The change in the wheel’s angular momentum is due to the torque
directly applied on the wheel by the driving electric motor and by the dis￾turbing loss effects:
_
hwheel ¼ Iwheel u_ wheel ¼ twheel ¼ tmotor  tloss;
354 Andrea Colagrossi et al.where Iwheel is the flywheel inertia, u_ wheel is the change of relative wheel’s
speed with respect to the spacecraft body, and t is a torque about the spin axis
of the wheel. The subscript “motor” indicates the motor torque, and “loss”
indicates the loss torque (i.e., the sum of the friction torque and all the other
losses, which will be detailed in the followings). Note that the torque applied
on the wheel enters the spacecraft dynamics with the negative sign, as in Eq.
(7.3). The reaction wheels exploit Newton’s third law of motion of action￾reaction. In fact, twheel is an internal torque and the reaction wheels cannot
exchange a net angular momentum externally with the environment. In
addition to the reaction torque, the angular momentum stored in the fly￾wheels, hb
wheels; enters in the attitude dynamics being an additional contri￾bution in the angular momentum of the spacecraft. Reaction wheels can be
used also as momentum wheels: this indicates a way of using wheels not to
exchange torque but as momentum storage. This means that the wheel is
kept at constant speed, as in dual spin satellites.
Reaction wheels assembly
The reaction wheels are physically composed by a flywheel mounted on a
bearing assembly and put in motion by an electrical motor. The motor is
driven by the wheel electronics which interfaces with the satellite for telem￾etry, telecommand, and power. The bearing is composed by a shaft, ball
bearings, and lubricant for durability and friction reduction. Reaction
wheels with hybrid bearings without lubricant are becoming more popular
in modern applications. Moreover, there have been studies on magnetic
levitation bearings, but operational applications seem still unpractical.
In terms of configuration, the flywheel assembly e which is composed by
the flywheel, the bearing, the motor, and a mechanical case e can either be
mounted on top of the wheel drive electronics e which is composed by the
power management and the electronics to process command, drive the mo￾tor, and generate telemetries e or separately. Usually, smaller wheels come in
an integrated assembly, while on larger wheels, a separated electronic can be
more convenient to optimize accommodation on the satellite. In these
regards, the flywheel assembly introduces on the satellite a mechanical distur￾bance, as discussed in the internal perturbation section of Chapter 6 e Sen￾sors, while the wheel drive electronics is one the most thermally dissipative
units. This is especially true during wheel braking due to the conversion of
mechanical energy in thermal energy. Some reaction wheel models are sealed
to maintain a vacuum in the flywheel assembly in order to avoid any possible
Actuators 355contamination of the bearings and higher friction levels when the wheel is
operated on ground for testing purposes.
Knowledge of the flywheel speed is needed to properly drive the wheel.
The most common technologies involve rotary encoders based on:
• Optical detectors, reading markers on the flywheel.
• Hall effect sensors, where permanent magnets are placed opportunely on
the flywheel to generate a pulse when crossing a motor pole.
Optical detectors and Hall effect sensors generate a pulse train that is used
for the speed estimation, although this is a complex task since there are
several error sources:
• During the estimation period, the wheel speed can vary due to the appli￾cation of a torque.
• The optical markers and magnets are not perfectly equally spaced on the
flywheel, thus introducing a mechanical jitter in the signal reading even
at constant speed. When the wheel performs multiple rotations during a
sampling period, it is possible to use the same marker to measure the rota￾tion period and remove the contribution of the mechanical jitter. At low
speeds, this is not possible.
• Electrical jitter can be introduced by the optical detector or Hall effect
sensor’s acquisition chains.
The speed estimation can be performed by the on-board computer,
which receives the pulse train, or directly by the wheel electronics. The first
option is common in wheels with analogic interfaces, while the second in
wheel with a digital interface.
Reaction wheels electronics could be equipped with an internal control
loop that regulates the wheel speed and torque compensating for errors
introduced by the motor or variations in the friction. This is commonly
done in digital components. Otherwise, this functionality can be imple￾mented directly in the GNC algorithms for analogic actuators, which are
commonly just commanded in desired torque. The most common motor
control logics are based on a cascade of proportional integral (PI) controllers.
They regulate motor voltage and current to achieve the desired speed and
torque. This method improves the actuator performance minimizing the de￾viations between desired and actual reaction wheel torque.
From an operational point of view, there are several aspects to be consid￾ered. When the reaction wheel is not spun for a long period on ground, the
lubricant accumulates inside the bearing because of the gravity. Since the
lubricant is not uniformly distributed, there is an increase of friction due
to direct metal to metal contact between the ball bearing and the cage.
356 Andrea Colagrossi et al.Operations of the wheel at high speed for several hours allow to recover the
nominal behavior and performance of the wheel. This operation is called
run-in, and it is needed before any test on ground where the nominal per￾formance of the wheel is needed. Manufactures provide recommendations
on how to perform the run-in.
Run-in is typically needed after release from the launcher since the lubri￾cant is usually not uniformly distributed after launch and the friction torque
is very high. Lubricants introduce constraints on the minimal operative tem￾perature. After long periods of inactivity in orbit, the wheel bearing could
reach temperatures below this threshold. It is therefore necessary to heat
the wheel, either using the satellite thermal control or switching on and
keeping in standby the wheel itself. Reaction wheels with hybrid bearings
without lubricant, despite higher friction, are less complex and do not
require these dedicated operations.
Wheels are life limited in terms of number of revolutions (e.g., typical
value: 100e1000 million revolutions) and zero-crossing events (e.g., typical
value: 10e100 thousand). A zero-crossing is defined as a change of rotation
direction (i.e., from clockwise to anticlockwise or vice versa), since for a
short instant of time, the wheel has zero speed. Under this condition, the
friction in the wheel increases and the wheel experiences a small mechanical
shock, which could create an audible sound on ground and disturb the sat￾ellite attitude in orbit. There are several strategies to limit the occurrence or
effect of zero-crossing (e.g., null-space controller) or to limit their effect
(e.g., cross-traveler controller). In general, it is a good practice to operate
the wheel imposing a bias in the nominal spin rate. Indeed, operations of re￾action wheels at low speed shall be avoided. At low-speed reaction, wheel
performance is worse, both for friction instabilities and for the difficulty to
estimate the wheel speed and, therefore, the momentum.
Friction and microvibrations
Friction has a major impact on wheel performance and power consumption.
The complete description of internal friction is a complex task, but the main
characteristics can be outlined with a brief introduction to the tribology.
Friction in reaction wheel bearings is described by four main terms:
• Coulomb friction is a constant opposing force independent of velocity.
• Viscous friction is proportional to velocity, and it is zero when velocity is
null.
• Stiction is defined as the torque required to start a motion from rest, and
it is greater than the Coulomb dynamic friction.
Actuators 357• Stribeck effect is associated to the continuous passage from static to dy￾namic friction. It describes the decreasing of friction for an increasing ve￾locity at low spin rates. It is generally modeled with an exponential
function.
A combination of stiction, Stribeck, Coulomb, and viscous friction terms
is commonly referred to as General Kinetic Friction (GKF) [15]. The GKF
model may approximate the real friction torque with a degree of confiden￾tiality of 90% [16], and it is shown in Fig. 7.7. Note that the computed fric￾tion term enters the wheel dynamics in the loss term with a negative sign.
Moreover, to avoid discontinuities in the force at zero spin rate, the negative
and positive stiction points can be connected with a steep straight line with
finite slope, as proposed by Karnopp [17].
Friction instabilities can occur at any speed regime and are a
performance-limiting factor for missions with high pointing requirements.
There are three main types of instabilities:
• Friction jumps. This can be seen as a form of friction coefficient insta￾bility, usually happening at high-speed regimes, due to mechanical
instability of the bearing. The friction can change by a few mNm for a
period of several hours. From an attitude point of view, this is equivalent
to a step disturbance force.
• Oil jogs. This is a sudden change of friction in the shape of a spike due
to accumulation of lubricant between the ball bearing and the cage.
Figure 7.7 General kinetic friction model.
358 Andrea Colagrossi et al.The friction can change by a few mNm for a period of few seconds.
From an attitude point of view, this is equivalent to an impulse distur￾bance force.
• Torque noise. This is the superimposed effect of several contributors
(e.g., bearing imperfections, ripple noise or other forms of electrical noise
in the motor, electromagnetic compatibility disturbances, etc.). Given its
high-frequency contribution, it has usually no major effect on the sat￾ellite dynamics, although it injects noise in the wheel speed estimation
process and therefore in the control loop. Adequate low-pass filtering
technics shall be implemented.
As any mechanism on a satellite, reaction wheels are a source of mechan￾ical disturbance and vibrations. Therefore, they are usually placed away from
sensitive elements like payloads. There are three main types of disturbance,
often referred with the collective term of microvibrations.
• Static imbalance acts as an in-plane centrifugal force due to the instan￾taneous rotation axis not passing through the flywheel CoM. This force
is proportional to the square of the wheel speed. The application of this
force results in a torque also proportional to the distance from the wheel
to the CoM of the spacecraft. In SI units, static imbalance is measured in
kg m, even if it is usually given in g cm [18,19].
• Dynamic imbalance acts as a disturbance torque due to misalignment be￾tween the instantaneous rotation axis and the flywheel principal axis of
inertia. This torque is proportional to the square of the wheel speed. It
is a radial torque, constant in the wheel frame, but rotating with angular
velocity uwheel in the spacecraft frame. In SI units, dynamic imbalance is
measured in kg m2, even if it is usually expressed in g cm2 [18,19].
• Other sources of high frequency disturbance, such as motor noise,
bearing disturbances, friction instabilities, etc., are sometimes referred
directly as microvibrations. Although these contributors are of small
magnitude, there are amplification effects due to the wheel resonance
modes. There are three main modes:
• axial translational mode of the flywheel.
• parallel rocking mode, rocking the flywheel parallelly to the shaft.
• antiparallel rocking mode, rocking the flywheel opposite to the shaft.
These perturbing terms directly enter the spacecraft dynamics, as gener￾ated by the reaction wheels, and do not directly affect their dynamics.
Generally, their impact might be reduced with a proper accommodation
on-board and with dedicated control techniques.
Actuators 359The reaction wheel microvibration spectrum can be visualized in water￾falls plots, showing the magnitude of the disturbance at different frequency
for different rotating speeds, as in Fig. 7.8. Static and dynamic imbalances are
partially corrected by the manufacturer balancing the wheel. This is per￾formed by correcting the inertia properties of the flywheel (e.g., by screwing
in appropriate locations additional small masses). Note that it is not possible
to completely remove the imbalance, since a lot of phenomena play a role:
change of properties and shape after sealing of the wheel, deformations due
to temperature changes, centrifugal forces at the different rotation speed,
mechanical testing, transportation, launch, etc. Further details on these
points are also described in Chapter 3 e The Space Environment.
Multiple reaction wheels actuation function
To have three-axis controllability of the satellite, it is needed to have at least
three wheels active, usually forming a tern aligned as the satellite reference
frame. Since wheels are prone to failures, it is common to have four or more
wheels on the satellite, either in cold or hot redundancy. The most efficient
configuration is when the wheels are placed in a pyramidal configuration.
When the wheels are used in hot redundancy, there is an additional DoF
that can be used to minimize the power consumption, limit occurrence of
the zero-cross, thanks to the null-space theory, or reduce microvibrations
with lower nominal spin rates. This is a desired feature for high pointing per￾formance satellites. Therefore, there are satellites with five (or more) wheels
in order to preserve this capability even in presence of a failure.
Figure 7.8 Reaction wheels waterfall plot.
360 Andrea Colagrossi et al.Multiple reaction wheels assemblies are defined according to the config￾uration matrix, R, introduced in Chapter 5 e Attitude Dynamics:
hb
wheels ¼ Rhr
wheels;
where R is a 3  n matrix, whose columns represent the direction of the axis
of rotation of the internal rotors in the body frame, and hr
wheels is a column
vector with n elements representing the angular momentum of each of the n
rotors around its spin axis:
hr
wheels ¼ ½hwheel1hwheel2/hwheeln
T ¼ ½Iwheel1uwheel1Iwheel2uwheel2/Iwheelnuwheeln
T
The configuration matrix R is composed by the column unit vectors
expressing the spin axes’ directions, rwi
, in the spacecraft body frame:
R ¼ ½rw1 rw2 rw3 / rwn :
It is reminded that hr
wheels and hb
wheels may not have the same magnitude
because R is generally not an orthogonal matrix.
In order to compute the multiple wheels actuation, we need to invert the
configuration matrix to transform a desired body frame angular momentum
or torque vector into the wheel frame. In this way, we can command each
reaction wheel to achieve the desired torque and angular momentum (i.e.,
spin rate). This is very easy in the case there are only three reaction wheels.
Indeed, R would be a 3  3 invertible matrix and the specific actuation
commands could be computed as:
hr
wheels ¼ R1 hb
cmd
t
r
wheels ¼ R1t
b
cmd;
where hb
cmd and t
b
cmd are, respectively, the desired angular momentum and
torque commanded by the GNC in the body frame. Note that R is
invertible because the three wheels shall not lie in a single plane to guarantee
the three-axis controllability. Hence, the spin axes’ directions form a
configuration matrix with full rank.
In the practical case with n > 3, there is no unique way to distribute the
angular momentum and torque among the different reaction wheels. The
most common solutions for the actuation function are the pseudoinverse
law and the minimax method [20]. The former is by far the simplest and
most used distribution method, and it uses the pseudoinverse, or Mooree
Penrose generalized inverse, of R to compute the actuation commands as:
hr
wheels ¼ Ry hb
cmd
Actuators 361with
Ry ¼ RT
RRT1
:
The pseudoinverse method for distributing torque or angular mo￾mentum among redundant reaction wheels minimizes the Euclidean
norm of the torque or momentum vector in the wheel frame. Namely, it
minimizes the sum of the squares of the individual wheel torques or angular
momenta. This condition is optimal under an energy perspective, but it does
not allow to use the full capability of the reaction wheel array. In the case a
different actuation goal is sought, an alternative distribution law shall be
used. In general, the pseudoinverse law is relatively simple to be imple￾mented, and it is a good compromise for most GNC applications.
The configuration matrix depends on the assembly configuration of the
reaction wheels, which is strongly related to the specific mission require￾ments. However, most of the spacecraft have four reaction wheels config￾ured in a pyramidal layout or in a three-axes-and-diagonal layout. In the
first case, the spin axes of the reaction wheels are oriented along the four
side edges of a square pyramid, while in the latter, three rotors are aligned
with the principal axes of the spacecraft and the fourth one has equal com￾ponents along the three axes. In any of the two cases, a failure does not
compromise the three-axis controllability.
The configuration matrix of a pyramidal assembly aligned with the x and
y axes, inclined of 30 degrees with respect to the xy plane is:
Rp ¼
2
6
6
6
6
6
6
6
4

ffiffiffi
3 p
2
ffiffiffi
3 p
2
0 0
1
2
1
2
0 0

ffiffiffi
3 p
2
ffiffiffi
3 p
2
1
2
1
2
3
7
7
7
7
7
7
7
5
;
while, in the case of the three-axes-and-diagonal layout, the configuration
matrix takes the form of:
Rt ¼
2
6
6
6
6
6
6
6
4
100
1
ffiffiffi
3 p
010
1
ffiffiffi
3 p
001
1
ffiffiffi
3 p
3
7
7
7
7
7
7
7
5
:
362 Andrea Colagrossi et al.Note that in the case a reaction wheel fails and the GNC shall exclude it
from the actuation function, the configuration matrix shall be modified
removing the column associated with the failed component.
Reaction wheels performance
Reaction wheels are characterized by two key parameters: maximum torque
and stored momentum capacity. The maximum torque indicated by the
supplier is usually the motor torque. The reaction torque can be computed
based on the friction torque, and it depends on the wheel speed and torque
direction (e.g., while breaking, the reaction torque takes the same sign of the
friction torque). The combination of the maximum reaction torque of the
wheels projected in a certain direction is the control authority around that
axis, and it contributes to the satellite agility (i.e., the capability to perform
slews in a certain time). It is measured in mNm and can vary a lot with
the size of the wheel, from 0.1 mNm up to 1 Nm, as order of magnitude.
The upper limit comes from engineering constraints, since to generate high
torques, there are high power consumptions and dissipations. If higher tor￾ques are needed, it is more convenient to use the Control Momentum
Gyros, described in the next section. The momentum capacity indicates
the maximum angular momentum that can be stored in the reaction wheels.
It is measured in Nms and can vary a lot with the size of the wheel, from
0.1 mNms up to 200 Nm, as order of magnitude. From the reaction wheel
capacity, it is possible to compute for how long a certain torque can be sus￾tained before reaching the maximum speed, which is called saturation, since
the wheel cannot provide anymore torque in that direction. Maximum rota￾tional speeds are typically in the range from 1000 to 6000 RPM.
It shall be remarked that operating the wheel at high nominal angular
rates makes the wheel more power consuming for the same torque level,
the microvibrations are higher, and the actuator is more easily saturated.
Similarly, low speeds are not suggested for zero-crossing events and friction
irregularities. Hence, reaction wheels shall be nominally operated in the
middle of their speed range.
The angular momentum stored in the reaction wheels evolves in time
because of external disturbances and control dynamics. Secular disturbances,
as well as not symmetric control actions, may lead to momentum accumu￾lation or momentum build-up. To avoid saturation of the reaction wheels,
these need to be periodically offloaded, or desaturated, by actuators that
can exchange momentum externally (i.e., magnetorquers or thrusters).
These secondary actuators provide a net torque that is capable to counteract
Actuators 363the reaction torque due to the momentum unloading (i.e., wheel braking).
Hence, secondary actuators are mandatory to be used together with reaction
wheels, or momentum exchange actuators, because they allow to recover
from saturation in order to operate the wheels for indefinite times.
Table 7.5 summarizes the strengths and weaknesses of reaction wheels.
Reaction wheels model
A reaction wheel with digital motor controller is commanded in terms of
desired torque and speed. Then, the dedicated motor control unit regulates
voltage and current to achieve the commanded values, with feedback on the
output torque and speed. An example of this reaction wheel model in
MATLAB/Simulink is shown in Fig. 7.9. Specifically, this model contains
three main subblocks: reaction wheel motor controller, imbalance model,
and friction model.
Table 7.5 Reaction wheels strengths and weaknesses.
Strengths Weaknesses
Precise torque delivery Complex equipment with moving parts and
relatively low reliability
Three axis-control possible Need to be desaturated since it cannot
generate external torques
Several architectures available Several operational constraints (i.e., zero￾crossing, low speed, maximum speed,
temperature, run-in)
Can be properly oriented to
optimize the control authority
Limited maximum torque and momentum
capacity due to mass and power constraints
Source of mechanical disturbance (i.e.,
microvibrations)
Figure 7.9 Reaction wheel model.
364 Andrea Colagrossi et al.The reaction wheel motor is modeled as a brushless direct current motor,
which is very common for reaction wheels. The motor control logic is a
classical cascade of PI controllers. As shown in Fig. 7.10, the motor control
unit has an inner torque (current) loop and an outer speed loop. The two PI
controllers are implemented in each loop to provide fast response and zero
steady-state error with respect to the input commands: reference speed and
torque. A controlled reaction wheel is capable to guarantee the desired con￾trol torque by compensating friction. Hence, it can greatly improve the
spacecraft control performance. It shall be noted that the motor controller
has a larger control bandwidth on torque, rather than on speed. As a result,
the torque is the primary control set-point with a faster settling to the desired
torque level. The output is limited by the torque dynamic saturation box
that is defined in terms of torque-speed range.
Static and dynamic imbalances are modeled, and they inject perturbation
forces and torques directly in the spacecraft dynamics. Thus, the reaction
wheel dynamics is not directly dependent on these terms. Although, the
control torque is affected by random variations due to the torque ripple
and to the bearing disturbances. The friction model is based on the GKF
model, including Coulomb and viscous terms. The zero-velocity crossing
is characterized by stiction and the Karnopp model, with Stribeck effect
in the dead zone. The power consumption model is proportional to motor
torque and speed.
The reaction wheels dynamics is represented as:
h_ b
wheels: ¼ Rh_ r
wheels ¼ R

tmotorðtÞ þ tbearingðtÞ  tfrictionðuwheelsÞ

;
where R is the wheel configuration matrix, including mounting errors, with
respect to the spacecraft body frame. The reaction wheel dynamics is then
coupled with the spacecraft dynamics, as discussed in Chapter 5 e Attitude
Dynamics.
Figure 7.10 Reaction wheel motor controller.
Actuators 365Control moment gyros
CMGs belong to the class of actuators for attitude control based on the
exchange of angular momentum with the spacecraft. Different from reaction
wheels, the angular momentum exchange is not achieved by varying the
spin rate of the actuator, but by changing the orientation of the spinning
axis with respect to the spacecraft body axes. Thus, CMGs generate a torque
by gyroscopic effect.
A control moment gyro is constituted by a rotating mass spinning at a
constant rate about a gimbaled spin axis. The CMG actuation torque is
generated by commanding a gimbal rotation around one axis orthogonal
to the spin axis of the rotor, and it is directed along the axis orthogonal to
both gimbal and spin axes, as in Fig. 7.11. Note that the spacecraft experi￾ence the reaction torque, which is opposite to this. The magnitude of the
CMG torque, tCMG, depends upon the spin rate of the rotor and the rota￾tion rate of the gimbal axis as:
tCMG ¼ ICMGuCMG
	
	
	
s_
	
	
	 ¼ ICMGuCMG _
qGjg  sj ¼ ICMGuCMG _
qG;
where ICMG is the moment of inertia of the control moment gyro’s rotor
about the spin axis, s. uCMG is the spin rate of the CMG and _
qG is the gimbal
rotation rate, around the gimbal axis, g.
Figure 7.11 CMG scheme for two GMGs with opposite gimbal axes.
366 Andrea Colagrossi et al.At least three single-gimbal CMGs are needed to provide three-axis con￾trol of a spacecraft, and the combined effect of a system of n single-gimbal
CMG can be expressed as:
tCMG ¼ Xn
j¼1

ICMGj
uCMGj
_
qGj
gj  sj

¼ Cq_ G;
where C is the CMG angular momentum configuration 3  n matrix, and
q_ G is a column vector with n elements, containing the gimbal rotation rates
of each CMG. The configuration matrix C is time variable since it depends
on the time evolution of the spin axes directions around the fixed gimbal
axes. If all the CMGs have the same moment of inertia and spin rate, the
configuration matrix C can be expressed as C ¼ ICMGuCMGCG; where the
matrix CG is only dependent from the gimbal and spin axes orientation.
Assuming four CMGs in a pyramidal configuration as in Fig. 7.12, CG is
expressed in the body frame as:
CG ¼
2
6
6
6
6
4
cosbcosqG1 sinqG2
sinqG1 cosbsinqG2
sinbcos qG1 sinbsinqG2
cosbcosqG3 sinqG4
sinqG3 cosbcosqG4
sinbcosqG3 sinbsinqG4
3
7
7
7
7
5
;
Figure 7.12 Pyramidal 4 CMGs configuration.
Actuators 367where the gimbal angles qGj are zero when the spin axes lie on the plane
containing the base of the pyramid.
The torque generated by CMGs is generally higher than those ob￾tained with reaction wheels of comparable dimension, and the CMGs
are also more efficient under an energy perspective to produce large tor￾ques. However, the variation of the actuator configuration due to the
rotating gimbal axis leads to a more complex actuation law and some sin￾gularity problems arise for specific CMG configuration conditions. When
a singular configuration occurs, all the available torques lie in a plane,
resulting in a loss of control authority about the axis perpendicular to
the singular plane. Several methods to avoid singular configurations
have been studied [20e24]. In general, four or more CMGs are needed
to avoid passing through the singular points.
CMGs with variable spin rate of the rotor, combining the features of re￾action wheels and CMGs, have been investigated, but they are not
commonly employed [25,26]. Similarly, CMGs with two gimbal axes
have been developed, but they are mechanically complex and the version
with a single gimbal axis is by far the most used [26]. Current technology
of CMGs allows maximum gimbal rates in the range 0.2e2 rad=s, resulting
in maximum allowable torques in the range 0.1e1000 Nm. As a rule of
thumb, CMGs are more power efficient than reaction wheels, when the
moments of inertia of the spacecraft to be controlled are larger than
101 kgm2
. Generally, when the required torque is larger than 0.1e0.5
Nm, a CMG shall be used. Table 7.6 summarizes strengths and weaknesses
of CMGs [27].
Table 7.6 CMG strengths and weaknesses.
Strengths Weaknesses
Large maximum allowable torques Existence of singular configurations
Large specific torque per stored
angular momentum
Mechanically complex
Power efficient for large spacecraft Large volume per stored angular
momentum
Three axis-control possible Complex actuation laws
Need to be desaturated since it cannot
generate external torques
Source of mechanical disturbance (i.e.,
microvibrations)
368 Andrea Colagrossi et al.Magnetorquers
Magnetorquers, or magnetic torquers, working principle is based on
the electromagnetic interaction with a surrounding magnetic field. These
actuators generate a magnetic dipole moment, m; which is capable to pro￾duce a control torque as:
tMAG ¼ m  B; (7.4)
where B is the magnetic field vector interfaced with the magnetorquers. The
magnitude of the magnetic torque is thus strongly dependent from the in￾tensity of the external magnetic field, which is a typical limit for the range of
application of these actuators. As a matter of fact, magnetic torquers are
mainly used in low Earth orbit, where the geomagnetic field’s intensity is in
the order of 25e50 nT (cfr. Chapter 3 e The Space Environment). Rare
applications of magnetorquers in high Earth orbits, sometimes up to the
geosynchronous altitude [28], are diminished in the available torque values
by the low intensity of the Earth’s magnetic field, which decreases with the
inverse cube of the distance from the center of the Earth. Obviously,
magnetorquers cannot be used around celestial bodies without magnetic
field, and their application in space regions where the magnetic field is not
well understood can lead to unpredictable behavior.
The simplest method to generate a controllable magnetic dipole moment
is by exploiting electromagnetic coils according to the Ampere’s circuital
law, which relates the magnetic dipole value to the current flowing in the
coils. An electric current of I amperes along a planar loop of area A produces
a magnetic dipole moment with magnitude m ¼ IA. The direction of the
dipole is perpendicular to the plane of the loop, according to the right￾hand rule. If the electromagnetic coils are composed by several loops,
they are denoted as solenoids, and the elemental dipoles of the N loops
are linearly superimposed resulting in an overall magnetic dipole moment
with magnitude.
m ¼ NIA: (7.5)
The units for the dipole moment are Am2
. When m is in Am2 and the
magnetic field is specified in Tesla, Eq. (7.4) gives the torque in Nm. The
dipole moment formula is a linear function of the current flowing in the
electromagnetic coil, the area, and the number of the loops. However,
considering realistic current values, large areas or many loops are required
to produce the dipole moments needed by the majority of spacecraft. For
Actuators 369this reason, magnetorquers adopt dedicated construction strategies to
achieve acceptable actuation levels.
Magnetorquers assembly
Magnetic torquers assemblies are designed to optimize the dipole moment
value for a given amount of current. Three main magnetorquers construc￾tion approaches exist:
• Air-core magnetorquers are the immediate application of the basic
principle behind electromagnetic coil actuation. A conductive wire is
shaped to form multiple loops around a nonconductive support, usually
integrated inside or on the side panels of the spacecraft. Eq. (7.4) can be
used to compute the exact dipole value for this typology of magne￾torquers. Hence, air-core magnetorquers design tends to maximize the
available area encompassed by the coil, and the number of superimposed
loops.
• Torque rods are the most efficient magnetorquers assemblies. They are
composed by a conductive wire wound around a ferromagnetic core
which is magnetized when excited by the coil. The core is typically
made of materials with very high magnetic permeability (e.g., nickel
or cobalt alloys) to reduce power consumption and actuator bulk for a
given generated magnetic dipole. The presence of the ferromagnetic
element allows to produce a greater dipole moment. However, the
magnetization curves of the core material saturate at a low intensity of
the applied magnetic field, and they are characterized by both nonline￾arities and hysteresis. The latter is responsible for a residual magnetic coil
that is present even when the coil is turned off, unless a proper demag￾netizing procedure is executed. In general, the magnetic dipole moment
value of a torque rod is difficult to be accurately predicted given the pres￾ence of the ferromagnetic core, whose permeability is dependent from
the intensity of the magnetic field. Thus, Eq. (7.4) is not applicable for
torque rods, and the cumulative dipole, sum of the solenoid term and
the core’s magnetization one, shall be computed as:
mtr ¼ NIA þ VcMðmr; I; GÞ;
where Vc is the volume of the core, and Mðmr; I; GÞ is its magnetiza￾tion, which is a function of the relative permeability of the material, mr,
the current intensity in the coil, and the geometry of the core, repre￾sented by the geometric parameter G [29]. A dipole curve of a generic
370 Andrea Colagrossi et al.torque rod is shown in Fig. 7.13. Commercial torque rods have a residual
dipole typically less than 1% of the saturation value, and the linear
actuation range is at least 80% of the maximum dipole capacity [30].
Torque rods can commonly generate a dipole of 0.1e3 Am2 per 1 mA
of current. Note that an air-core would require NA ¼ 1000 m2 to
achieve a dipole of 1 Am2/mA.
• Printed circuit board (PCB)-embedded coils are magnetorquers assem￾blies fully integrated in the spacecraft components. They are realized
creating a spiral trace inside the PCBs of the on-board electronics,
typically the solar panels one. The spiral wire is substituted by copper
traces in the electronic boards, whose shape is a square spiral on a plane.
These magnetorquers are advantageous since their minimal impact on
the satellite volumes. However, due to the limits in the board con￾struction and the possible presence of other electronical circuits and
components, the maximum magnetic dipole value is severely con￾strained. Furthermore, the low resistance of the copper traces causes high
Figure 7.13 Generic torque rod magnetic dipole curve.
Actuators 371current, resulting in a high-power consumption for a given magnetic
dipole value. This last drawback can be reduced, thanks to modern PCB
technology, which is capable to realize multilayer coil traces inside the
electronic boards, increasing the number of available loops for a given
area of the board. This specific magnetorquer assembly is suitable for
applications in small satellites with stringent mass and volume constraints.
Eq. (7.2) is just an approximation of the actual dipole generated by the
PCB-embedded magnetorquers. In this case, an average area between
the inner and the outer loop of the printed coil, Apcb, and the number of
traces forming complete loops, Npcb, shall be used in the magnetic dipole
formula. This approximation gives acceptable results as long as the
number of spiral traces is not too high (e.g., Npcb < 40), otherwise a series
term superimposing the Lorentz forces generated by any single segment
of the copper traces shall be considered [29].
Magnetorquers actuation function
Magnetorquers are actuated by letting a current flow inside the conductive
coils. To achieve the desired dipole moment, the current shall be controlled
to coincide with the prescribed value. This is typically achieved with a feed￾back current control exploiting current measurements from amperometers
on the magnetorquer power supply lines. As an alternative, the magnetor￾quers can be also controlled in terms of supply voltages, for example, by
exploiting a PWM voltage regulator. In this last case, the coil resistance shall
be known, and, since the resistance of a conductive element varies with the
temperature, a voltage control with resistance or temperature feedback may
be needed.
In many cases, the actuation laws used on-board shall be as simple as
possible. Thus, they are typically based on Eq. (7.5), despite the presence
of torque rods with magnetic cores. In very simple applications, the current
is not feedback controlled, allowing current fluctuations due to supply
voltage or coil temperature variations. In all these cases, the magnetic actu￾ation will be affected by errors with respect to the ideal control law. Hence,
the spacecraft GNC shall account for these deviations between computed
and actuated torques.
In general, the actuation function of magnetorquers needs to know the
local magnetic field, since the magnetic torque is function of both the satel￾lite magnetic dipole and the surrounding magnetic field. Thus, a spacecraft
with magnetic actuators shall be equipped with magnetometers to guarantee
372 Andrea Colagrossi et al.the on-board magnetic measurements, as discussed in Chapter 6 e Sensors.
Particular attention shall be paid to avoid interferences between the control
action of magnetorquers and the magnetometers measurements.
Magnetorquers performance
Typically, magnetorquers applications use three torquers producing mag￾netic dipole moments on orthogonal axes. Additional magnetorquers can
be used to provide additional actuation capabilities, given that the total mag￾netic dipole is a vector sum of the contributions of the single torquers.
Instead, redundancy is commonly guaranteed inside any single torquer,
thanks to dual or multiple independent conductive windings. The set of
magnetic torquers used in a spacecraft can combine the different construc￾tion approaches described before. A typical solution is composed by an air
core torquer, with two orthogonal torque rods lying in the plane of the large
coil, as seen in Fig. 7.14. In this case, the magnetic dipole of the air core is
along one axis orthogonal to the ones of the torque rods. The dipole mo￾ments of the three elements have the same order of magnitude because
the large area of the air core torquer balances the ferromagnetic material in￾side the torque rods. Very small spacecraft may use permanent magnets in
place of electromagnetic coils to achieve a passive stabilization with respect
to the surrounding magnetic environment.
Typical applications of magnetorquers are initial satellite spin dumping,
also known as detumbling, and reaction wheels or CMGs stored
Figure 7.14 Common three magnetorquers set.
Actuators 373momentum dumping. In these cases, magnetic torques are particularly effec￾tive in generating a dissipative torque capable to dump the angular mo￾mentum. They can be also conveniently used as a redundant actuation
system, in case of a failure in the primary actuators. Small and very simple
satellites may even use magnetorquers as primary actuators for attitude stabi￾lization and pointing. However, the available performance cannot be
compared to other actuation methods. In fact, a significant disadvantage is
that the magnetic torques are constrained to lie in the plane orthogonal to
the magnetic field, as is evident from Eq. (7.4), so only two out of three
axes can be controlled at a given time instant. Full three-axis controllability
is potentially available e in an integral sense e over a complete orbit. How￾ever, this is only true if the spacecraft’s orbital plane does not coincide with
the geomagnetic equatorial plane and does not contain the magnetic poles
[31]. The geomagnetic field irregularities and its rotation with the Earth in￾troduces many harmonics in the magnetic field evolution along the orbit.
Thus, simulations involving magnetic control should be at least 24 h in
length, ensuring that all the frequencies of the magnetic environment har￾monics are accounted in the control design [32]. Undesirable magnetic di￾poles inside the spacecraft lead to magnetic disturbance torques, and, even if
they are generally few orders of magnitude smaller than the magnetorquers
ones, they shall be considered as well in the magnetic control design.
Notwithstanding the problems and limitations, magnetorquers have
many advantages. They are lightweight; they do not require any propellant
consumption; they produce a pure torque, without spurious forces perturb￾ing the spacecraft’s orbit; they have no moving parts, resulting in a high reli￾ability and eliminating internal microvibrations. Their typical applications in
near-Earth orbits allow to produce magnetic control torques ranging from
2 106 to 0.05 Nm, since commercially available torquers provide dipole
moments from 0.1 to 1000 Am2
. Table 7.7 resumes strengths and weak￾nesses of magnetorquers.
Table 7.7 Magnetorquers strengths and weaknesses.
Strengths Weaknesses
Lightweight Small torques
Energy efficient Torque constrained to lie in a plane
Reliable Required presence of an external
magnetic field
No orbital perturbation or
microvibrations
Instantaneous three-axis control not
possible
Efficient in generating dissipative
torques
374 Andrea Colagrossi et al.Magnetorquers model
An example magnetorquer model implementation in MATLAB/Simulink
is reported in Fig. 7.15. The input command is a PWM voltage, including
resolution, saturation, and noise effects. The voltage applied to the electric
coil composing the magnetorquer results in a current, which is a function
of the temperature-dependent magnetorquer’s resistance. A simplified ther￾mal model of the actuator is included to represent the resistance variation
with the temperature. The latter has a periodic oscillation with the orbital
period, and it is dependent from the actuation intensity. Finally, the magne￾tization of the magnetorquer’s core is modeled including the hysteresis and
the magnetic nonlinearity. The power consumption model is proportional
to the input voltage and flowing current.
References
[1] F.L. Markley, J.L. Crassidis, Fundamentals of Spacecraft Attitude Determination and
Control, STL, 2015.
[2] V.J. Modi, K. Kumar, Attitude control of satellites using the solar radiation pressure,
Journal of Spacecraft and Rockets 9 (9) (1972) 711e713.
[3] Les Johnson, et al., Solar sails: technology and demonstration status, International Jour￾nal of Aeronautical and Space Sciences 13 (4) (2012) 421e427.
[4] R. Sun, et al., Roto-translational spacecraft formation control using aerody
namic forces, Journal of Guidance, Control, and Dynamics 40 (10) (2017)
2556e2568.
[5] K.C. Pande, R. Venkatachalam, On optimal aerodynamic attitude control of
spacecraft, Acta Astronautica 6 (11) (1979) 1351e1359.
[6] H.A. Talebi, K. Khorasani, T. Siamak, A recurrent neural-network-based sensor and
actuator fault detection and isolation for nonlinear systems with application to the sat￾ellite’s attitude control subsystem, IEEE Transactions on Neural Networks 20 (1)
(2008) 45e60.
Figure 7.15 Example magnetorquer model.
Actuators 375[7] A. Rahimi, K. Dev Kumar, H. Alighanbari, Fault detection and isolation of control
moment gyros for satellite attitude control subsystem, Mechanical Systems and Signal
Processing 135 (2020) 106419.
[8] I. Gueddi, et al., Fault detection and isolation of spacecraft thrusters using an extended
principal component analysis to interval data, International Journal of Control, Auto￾mation and Systems 15 (2) (2017) 776e789.
[9] M.J.L. Turner, Rocket and Spacecraft Propulsion: Principles, Practice and New
Developments, Springer, 2009.
[10] W. Emrich Jr., Principles of Nuclear Rocket Propulsion, Elsevier, 2016.
[11] G. Garbe, An overview of NASA’s solar sail propulsion project, in: 39th AIAA/
ASME/SAE/ASEE Joint Propulsion Conference and Exhibit, 2003.
[12] J.R. Wertz, J. Wiley, Larson, Space Mission Analysis and Design, third ed., Space
Technology Library, Springer, 2005.
[13] W. Fehse, Automated Rendezvous and Docking of Spacecraft, Cambridge University
Press, 2003.
[14] W. Press, S. Teukolsky, W. Vetterling, B. Flannery, Numerical Recipes in C, Cam￾bridge University Press, Cambridge, UK, 1992.
[15] B. Armstrong-Helouvry, Control of Machines with Friction, Kluwer, Boston, MA,
1992, 1991.
[16] L. Marton, B. Lantos, Modeling, identification, and compensation of stick-slip friction,
IEEE Transactions on Industrial Electronics 54 (1) (2007).
[17] D. Karnopp, Computer simulation of slip-stick friction in mechanical dynamic
systems, Journal of Dynamic Systems, Measurement, and Control 107H1I (1985)
100e103.
[18] ISO 21940-11:2016 e Mechanical Vibration d Rotor Balancing d Part 11: Proced￾ures and Tolerances for Rotors with Rigid Behaviour.
[19] ISO 1940-1:2003 e Mechanical Vibration d Balance Quality Requirements for Ro￾tors in a Constant (Rigid) State d Part 1: Specification and Verification of Balance
Tolerances.
[20] H. Kurokawa, Survey of theory and steering laws of single-gimbal control moment
gyros, Journal of Guidance, Control, and Dynamics 30 (5) (2007) 1331e1340.
[21] G. Margulies, J.N. Aubrun, Geometric theory of single-gimbal control moment gyro
systems, Journal of the Astronautical Sciences 26 (2) (1978) 221e238.
[22] B. Wie, Singularity analysis and visualization for single-gimbal control moment gyro
systems, Journal of Guidance, Control, and Dynamics 27 (2) (2004) 271e282.
[23] L. Jones, R. Zeledon, M.A. Peck, Generalized framework for linearly constrained con￾trol moment gyro steering, Journal of Guidance, Control, and Dynamics 35 (4) (2012)
1094e1103.
[24] B. Wie, Singularity escape/avoidance steering logic for control moment gyro systems,
Journal of Guidance, Control, and Dynamics 28 (5) (2005) 948e956.
[25] B. Wie, Space Vehicle Dynamics and Control, second ed., AIAA, Ames, 2008.
[26] F.A. Leve, B.J. Hamilton, M.A. Peck, Spacecraft Momentum Control Systems,
Springer International, 2015.
[27] R. Votel, D. Sinclair, Comparison of control moment gyros and reaction wheels for
small earth-observing satellites, in: Proceedings of the 26th Annual AIAA/USU Con￾ference on Small Satellites, 2012.
[28] D. Desiderio, M. Lovera, S. Pautonnier, R. Drai, Magnetic momentum management
for a geostationary satellite platform, in: Proceedings of the 47th IEEE Conference on
Decision and Control, Cancun, 2008, pp. 1243e1248.
[29] N. Bellini, Magnetic Actuators for Nanosatellite Attitude Control, Alma Mater Stu￾diorum Universita di Bologna, 2014.
376 Andrea Colagrossi et al.[30] F. Landis Markley, J.L. Crassidis, Fundamentals of Spacecraft Attitude Determination
and Control, Space Technology Library: Springer, 2014.
[31] S.P. Bhat, A.S. Dham, Controllability of spacecraft attitude under magnetic actuation,
in: Proceedings of the 42nd IEEE Conference on Decision and Control, Maui, 2003,
pp. 2383e2388.
[32] A. Colagrossi, M. Lavagna, Fully magnetic attitude control subsystem for picosat
platforms, Advances in Space Research 62 (12) (2018) 3383e3397.
Actuators 377This page intentionally left blankPART TWO
Spacecraft GNC
379jThis page intentionally left blankCHAPTER EIGHT
Guidance
Thomas Peters1
, Stefano Silvestrini2
, Andrea Colagrossi2
,
Vincenzo Pesce3
1
GMV Aerospace & Defence, Madrid, Spain
2
Politecnico di Milano, Milan, Italy
3
Airbus D&S Advanced Studies, Toulouse, France
What is guidance?
Since the early ages of humanity development, the first activity that
has engaged individuals is to generate plans. Let us imagine a person who
leaves the shelter to fulfill the objective of “living life.” The first decision
to be made is the selection of a desired place to visit. It can either be a forest
to go hunting, for our primitive ancestors, or to the office, in our daily life,
or simply a nice place to be in, such as a mountain, a park, or a beach. Imme￾diately after, the person would need to think of a way to get to the target
place by planning the journey. Generally, people would think of interme￾diate places they expect to visit while being on-track on their way. At this
stage, it does not really matter what can happen in between. This simple
example illustrates the concept of guidance in its pure essence. Although
the difference between guidance and control is sometimes blurred, the
research community agrees that the act of planning the places to visit and
generating the desired path between them is what we refer as guidance. A
good way to distinguish the domains is to think of guidance as an activity
performed beforehand that does not necessarily take into account unfore￾seen events that may happen.
Nevertheless, as real life is truly complicated, this is not always true. The
guidance concept referring to the generation of paths to follow can be
updated as our journey prosecutes. Let us go back to the example of a person
“living life”: let us assume that the individual wanted to reach the desired
place using a bicycle; unfortunately, the bike has a flat tire, thus the person
is forced to take the car. In the original plan, the human being would have
cycled through the center of the city, but this is no longer possible with the
car due to circulation restrictions in the old town. The individual, while
making the decision of changing the transportation system, regenerates a
Modern Spacecraft Guidance, Navigation, and Control
ISBN: 978-0-323-90916-7
https://doi.org/10.1016/B978-0-323-90916-7.00008-1
© 2023 Elsevier Inc.
All rights reserved. 381 jplan according to such unexpected event. This is what is often referred as
adaptive guidance, meaning that the agent is capable of reshaping its plans ac￾cording to what it is currently experiencing.
In technical terms, guidance refers to the determination of the desired
travel path, commonly referred as trajectory in the space domain, from
the spacecraft current state to a designated target one, being either a position,
an orientation, or a given orbit. Guidance entails also the desired changes in
velocity necessary to follow the defined path.
The interface with the other core modules of navigation and control is
quite intuitive. The guidance system generates the intended plan, which is
constantly compared to the navigation output to let the system understand
whether it is in its correct state at the current time. The control uses such
comparison to synthesize the actions to correct any, inevitable, mismatch
between where we would like the spacecraft to be and where it actually
is. On the other hand, especially in adaptive applications, the guidance in￾terrogates the navigation to acquire the current state to generate new plans
based on the real status of the journey.
With these concepts in mind, we have all the tools to start diving into the
technicalities of the guidance system and algorithms.
This chapter is composed by the following sections:
• On-board versus ground-based guidance. The guidance system is the formal
discriminant between attitude and orbit control system (AOCS) and
guidance, navigation, and control (GNC). This section explores the dif￾ferences in the implementation philosophies.
• Guidance applications. This section explores the guidance system design
process from the understanding of the dynamical system to the descrip￾tion of different guidance techniques. It covers critical topics such as
optimal control, interpolation, and two applicative cases, namely rendez￾vous guidance and attitude guidance.
• Guidance implementation best practices. A series of best practice tips and
checks is collected in this section, giving a more practical perspective
on the implementation of guidance algorithms.
On-board versus ground-based guidance
A space mission consists of the ground segment and the space segment.
The space segment is the spacecraft, which itself consists of the spacecraft bus
and the payload. Fig. 8.1 shows these elements of the space system and the
relations between them. Controlling and operating a spacecraft is a task
382 Thomas Peters et al.shared between the ground segment and the space segment. The level of on￾board autonomy determines the capabilities of the space segment to control
its own orbit and attitude to fulfill the mission needs.
In general, as described in Chapter 1 e Introduction, on-ground activ￾ities rely on significantly higher computational power compared to on￾board resources. Specific to the guidance system, this means that the ground
segment can use more complete models of the spacecraft dynamics and sen￾sors, more sophisticated filtering techniques to obtain a guidance solution,
and more detailed dynamics models for computing maneuvers. Maneuvers
can be computed on ground using optimization techniques that may be pro￾hibitively expensive to implement on-board or using techniques that require
human supervision to ensure that the maneuvering solution is acceptable.
Moreover, the capabilities guidance systems based on the on-ground
segment is highly dependent on the number of ground stations, ground
link frequencies, and delays. For instance, rendezvous missions may require
autonomous abort capabilities for the close proximity operations that may
not be achievable with ground-based systems [1].
Figure 8.1 Elements of a space system.
Guidance 383As discussed in Chapter 1 e Introduction, the increased level of auton￾omy also requires more time and effort to be spent on the development,
verification, and validation of the software, which increases the cost of the
on-board software. Nevertheless, it is safe to claim that the reduction of
the cost of operation is expected to be greater than the increased cost of
the software development [2].
For the sake of completeness, referring to Chapter 1 e Introduction, we
report again the nomenclature definition of on-board autonomy. The Eu￾ropean ECSS Space Segment Operability Standard provides a definition of
on-board autonomy [3]: “On-board autonomy management addresses all aspects
of on-board autonomous functions that provide the space segment with the capability
to continue mission operations and to survive critical situations without relying on
ground segment intervention.”
Finally, the reasons for increasing the level of on-board autonomy are the
following, which are coherent with what explained for the entire GNC sys￾tem in Chapter 1 e Introduction:
- It reduces the complexity of ground operations.
- It implies that the ground segment no longer has direct control over on￾board operations that may be critical to the survival of the spacecraft [4].
- It reduces personnel requirements on ground (possibly single-shift), may
reduce propellant cost and allows for more precise timing of on-board
events [2].
- It avoids limited communication windows and/or large communication
delays, such as, for example, planetary sample return missions.
- It reacts promptly to unexpected events, such as, for example, detection
of an imminent collision and trajectory replanning.
The guidance function often plays a key role in the development of on￾board autonomy, as the guidance function is in charge of defining the
behavior of the system at medium to long time scales. The guidance can
abstractly define plans (here defined as a sequence of maneuvers and trajec￾tories with a clearly defined objective to change the state of the space system
into another desired state) that determine what actions the space segment
will perform. The guidance can encode alternative plans and recovery plans
that can be activated when a change in the environment is detected that calls
for a different course of action than what was encoded in the original plan.
The guidance performs an abstraction step, encoding specific maneuvers and
trajectories as more abstract elements in a set of available behaviors of the
space system as a whole (see also Section Guidance modes). Additional layers
of abstract reasoning can be added that interact with the guidance (and the
384 Thomas Peters et al.navigation) to ensure that the system can adapt to changing situations
autonomously.
Guidance applications
This section covers the technicalities of the development of a guidance
system. The design process is described, mentioning the most common
techniques to define the guidance system and algorithms. Moreover, the
interaction between the guidance module and the spacecraft at system level
is investigated, from requirements definition to architectures.
Design process
This section describes the technical design process of the guidance system. It
entails the critical steps to develop effective and successful algorithms, from
the understanding of the dynamical system to the core concept of optimiza￾tion. Finally, two guidance applicative cases are described to demonstrate
how the theoretical concepts turn into practice.
General design approach
The objectives of the guidance design can be different for different phases of
the design process. During the initial phases of the mission design, the tasks
of the guidance are closely related to the mission analysis. Feasible trajec￾tories that satisfy the objectives are defined, and the DV’s that are required
to follow the trajectory are calculated to establish a preliminary DV budget.
These DV’s are in some sense ideal because the calculation does not take into
account the navigation uncertainty or the actuation errors. The effects of
these uncertainties and errors are absorbed into margins on the DV budget.
Furthermore, during the initial stage of the design, the needs and con￾straints of the system are explored, and these are eventually encoded into re￾quirements on the design of the system. For the guidance functions, the
development focuses on lower-level utility functions that can be tested inde￾pendently and early in the process. These functions may be reused from
other projects, and specific special purpose functions may be built that cover
the peculiarities of the specific mission. For example, for rendezvous and for￾mation flying, function libraries that can be reused may include free-flying
trajectory propagation functions, impulsive maneuver computation func￾tions, forced motion, and attitude pointing functions.
The definition of guidance functions needs to start with a fundamental
understanding of the dynamics. The dynamics of rendezvous from the point
Guidance 385of view of the development of a guidance function is discussed in Section
Understanding the dynamical system, as well as algorithms for relative trajec￾tory propagation. Algorithms for impulsive, forced motion, and attitude ma￾neuver computation functions are explored in Sections Impulsive
maneuvers and trajectories, Forced motion, and Application: Attitude guid￾ance. Section Design of a guidance function briefly discusses how and what
type of requirements may be defined for a guidance function.
Understanding the dynamical system
To start the design of the guidance function, it is crucial to develop an un￾derstanding of the dynamics and the operating state of the system for which
the guidance function is developed. Mission analysis leads to the identifica￾tion of the principal dynamical effects and disturbances to take into account
into the dynamical model.
From a practical point of view, the selection of the level of accuracy of
the dynamical model for the guidance depends on a number of factors. The
most important of factors are: short-term versus long-term propagation,
available computational power, navigation and actuation accuracy, and
the frequency of maneuver application. Consistency of the dynamical model
between the GNC can be beneficial from the perspective of verification and
validation, especially if the exact same implementation of the dynamics is
used. If the maneuvers are spaced close together, then the propagation
arcs are short, and lower accuracy models can be sufficient. For on-board
applications, computational resources may be limited, and this may drive to￾ward using lower-accuracy dynamical models within the guidance. If the
navigation accuracy is low, then the guidance cannot expect to provide
high-accuracy results and the dynamical model used in the guidance can
be rather simple. Lastly, if the maneuver application errors are expected to
be large, then it is not necessary to compute highly accurate maneuvers,
and the guidance dynamics models can be simplified. The guidance function
often needs to be able to handle different levels of navigation accuracy in
addition to the peculiarities of the control function and the actuators.
Recent articles [5] have suggested taking a mixed approach. In this approach,
the guidance first computes the desired reference trajectory during prespe￾cified intervals with discrete changes at the boundaries of these intervals.
A high-accuracy dynamical model is used to propagate the desired reference
trajectory during these intervals. A lower accuracy dynamical model is used
to compute the maneuvers required to perform the changes at the bound￾aries of the intervals.
386 Thomas Peters et al.Guidance representations
The representation of the state vector within the guidance software depends
on the needs of other subsystems, on the comprehensibility to human users
that check and verify the software, and possible performance impacts of the
representation. From the point of view of verification and validation, it is
desirable to use the same representation for the GNC functions. As a min￾imum, it must be ensured that the interfaces between these elements use the
exact same representation of the state vector.
The guidance is responsible for providing the reference trajectory to the
other GNC functions. A wide variety of models and representations is avail￾able, and it is the task of the GNC engineer to select the most suitable rep￾resentation of the reference trajectory for the application at hand. It may be
desirable to have a consistent formulation of the dynamical model between
the GNC functions, although the internal representation inside each of these
functions can be different from the output representation. A common
approach for translational dynamics is to make use of a full nonlinear refer￾ence trajectory and a state transition matrix to compute small trajectory cor￾rections close to the reference. In this case, it is desirable to ensure that the
dynamical model used for the full nonlinear trajectory is consistent with the
linear model used for the state transition matrix, at least for the major
dynamical effects. The need for linearization may also form an important
driver in the selection of parameters to represent the trajectory. The kine￾matics of certain sets of parameters can be affected by nonlinear effects to
a greater or lesser extent. In other cases, the transformation between certain
representations may suffer more from nonlinear effects, while the dynamics
are affected less. A judicious choice of parameters and a careful consideration
of what aspects of the dynamical system to linearize can lead to great im￾provements in the accuracy of models. See Ref. [6] for a thorough discussion
of nonlinear effects in both orbital and attitude dynamics.
For attitude guidance, the following representations can be considered
(cfr. Chapter 5 e Attitude):
- Direction cosine matrix. The direction cosine matrix provides an un￾ambiguous and easy to understand representation of the rotation that is
free from singularities, but it uses many more parameters than are strictly
required to provide the attitude information.
- Euler angles. The Euler angles are another example of an easy-to-un￾derstand representation of the attitude information that uses the mini￾mum number of parameters (3). Difficulties arise because the Euler angles
contain singularities and because multiple (12) sets of Euler angles exist.
Guidance 387Care must be taken firstly to avoid these singularities by choosing the
right operating point and secondly to use the same definition of the angles
throughout the system.
- Axis-angle and Euler vector. The axis-angle and Euler vector systems are
variations of the same idea. In the case of axis-angle representation, the
rotation axis e and the rotation angle w are provided to unambiguously
represent the attitude. In the case of the Euler vector, the rotation axis is
multiplied by the rotation angle. In this case, the topology of the space
can be represented by a ball of radius p in which opposite points on the
sphere are identified.
- Quaternions. Unit quaternions (quaternions of length one) are
commonly used to represent rotations. Quaternions contain a scalar part
q4 equal to the cosine of half the rotation angle, and a vector part q1:3
equal to the sine of half the rotation angle times the rotation axis. The
advantage of quaternions is that they require a minimum number of op￾erations to perform the rotation operation, and only multiplication, addi￾tion, and subtraction are used. The downside of quaternions is that they
are more difficult to understand. In addition, there is some ambiguity in
the definition of the order of the elements of the quaternion: scalar first or
scalar last.
- Rodrigues parameters/Gibbs vector. The Rodrigues parameters or Gibbs
vector is a three-element vector that is obtained by dividing the vector
part of the quaternion by the scalar part of the quaternion, q1:3
q4 . This means
that the Rodrigues parameters are equal to the tangent of half the rotation
angle times the rotation axis. The Rodrigues parameters are singular
when the rotation angle is equal to p.
- Modified Rodrigues parameters. The modified Rodrigues parameters
are a stereographic projection of the sphere of unit quaternions onto a
three-dimensional plane. This leads to the following expression for the
modified Rodrigues parameters p ¼ q1:3
1þq4
. The modified Rodrigues pa￾rameters are equal to etan w
4. The modified Rodrigues parameters move
the singularity to a rotation through an angle of 2p. This is not necessarily
a problem as a rotation through an angle of is 2p equivalent to the
rotation through an angle 0.
A comprehensive survey of attitude representations can be found in
Ref. [7]. This reference provides kinematics equations for all attitude repre￾sentations listed above and includes a discussion of attitude errors.
388 Thomas Peters et al.Reference [8] (page 181e183) provides a topological analysis of the
Euler angles to demonstrate the location and the nature of the singularities.
References [7,9] provide a full list of all possible combinations of Euler an￾gles, and Ref. [9] provides some options and considerations for handling or
avoiding singularities.
Useful references for the unit quaternions are [10,11]. Ref. [11] uses a
slightly different notation for the quaternions but provides useful insight
into the construction of rotation sequences using quaternions. Ref. [10] pro￾vides extensive discussions on quaternions and their relationship to rotation
matrices. This reference is mainly focused on navigation filters, but it con￾tains useful ideas and mathematical expressions for attitude guidance
development.
Refs. [7,12] provide discussions of the Rodrigues parameters and the
modified Rodrigues parameters. Ref. [12] additionally provides geometrical
insight into how the Rodrigues parameters are obtained and provides several
useful generalizations.
A wide variety of parameterizations are available for modeling orbital
motion.
- Cartesian state. The inertial Cartesian state is easily understood and can be
used directly to perform geometrical calculations (such as, for example,
calculation of direction vectors or range) in a straightforward manner.
The inertial Cartesian state can be used to model the orbital motion
directly, but there are some disadvantages with respect to orbital ele￾ments. If a numerical integration scheme is used, then the step size gener￾ally needs to be smaller for the Cartesian state than for other
representation. The values of the components of the Cartesian state
tend to vary more rapidly than orbital elements, such that more parame￾ters may be required to represent the evolution of the trajectory.
- (Modified) Keplerian orbital elements. The (modified) Kepler elements
have an easy geometrical meaning and are treated in nearly all introduc￾tory texts on astrodynamics. In an unperturbed orbit, the orbital elements
are constant, and in a perturbed orbit, the elements tend to vary slowly.
This makes the orbital elements easy to represent using a relatively small
number of parameters. This advantage applies to all orbital element sets.
The main disadvantage of the Keplerian orbital elements is that singular￾ities exist for zero eccentricity and zero inclination. Despite this disadvan￾tage, the Keplerian elements are commonly used to represent orbit
information.
Guidance 389- Equinoctial elements. The set of equinoctial elements is nonsingular for
small eccentricities and inclinations. The equinoctial elements can easily
be obtained from the (modified) Keplerian elements, but the meaning
of each of the individual elements is a little harder to understand when
compared to the Kepler elements.
- Modified equinoctial elements. The set of modified equinoctial elements
is nonsingular for all eccentricities and inclinations. This set is therefore
suitable for any orbit. In particular, the modified equinoctial elements
are commonly used for low-thrust escape trajectories.
- Delaunay elements. The Delaunay elements are a canonical set of orbital
elements. This means that the variational equations take on a particularly
simple form and perturbation calculations are greatly simplified.
- Poincaré elements. The Poincaré elements are a canonical set of elements
that is nonsingular for small eccentricities and inclinations.
Ref. [13] provides an overview of the different sets of orbital elements
and a discussion of the advantages and disadvantages of each of these sets
including the availability of the variational equations for each of these sets.
A distinction needs to be made between the internal representation of the
guidance reference and the representation of the orbit data that the guidance
provides to other functions. It can be beneficial to internally represent the
reference orbit in terms of one of the many sets of orbital elements and pre￾sent the Cartesian state to other functions. In this case, the guidance needs to
contain transformation functions that can transform between different rep￾resentations of the orbit.
Linearized relative motion models have many different applications
including the launch vehicle guidance, midcourse correction maneuver
calculation for interplanetary trajectories, orbit control and formation flying,
and rendezvous. In recent years, rendezvous and formation flying have
driven the development of many different theories for relative motion.
Reference [14] provides a recent survey of relative motion models and in￾cludes flow diagrams that explain how these models work. One key obser￾vation is that while linearized orbital elements themselves do not suffer
greatly from errors due to linearization, the transformation between Carte￾sian state vector and orbital elements itself does. This insight has led to the
development of theories that use a full nonlinear transformation between
the Cartesian state vector and the relative orbital elements, and a linear dy￾namics model for the relative orbital elements. These models combine the
advantages of the linear models with the accuracy provided by using the
nonlinear transformations.
390 Thomas Peters et al.Optimization
Many guidance problems attempt to formulate an optimal planning for the
system to be controlled. The optimal planning minimizes or maximizes
some form of cost function that can be expressed as a function of the state
variables, the control inputs, and or the time. The guidance provides a plan￾ning that maximizes the performance of the system to be controlled or that
minimizes the amount of resources needed to follow such a plan. Some ex￾amples of optimization problems that occur in space engineering are the
following:
- To find the steering program that maximizes the amount of payload a
launch vehicle can deliver to a specified orbit.
- To find the burn program that maximizes the change in semimajor axis
for a spacecraft with a single electric propulsion thruster operating with
constant thrust.
- To find the sequence of impulsive maneuvers that minimizes the amount
of propellant required to perform an orbit transfer.
- To find the steering program for reaction wheels that minimizes the
amount of energy used to perform a slew maneuver.
Aerospace optimization problems often feature constraints, which may
either be equality constraints or inequality constraints. Initial and terminal
conditions can be viewed as equality constraints, and so can the dynamical
equations in general. Some examples of inequality constraints are:
- The dynamical pressure on a launch vehicle must remain below a certain
value.
- The angle between the boresight of a star tracker and the Sun direction
must remain greater than a certain value during slew maneuvers.
Many optimization problems that occur in space engineering are
nonlinear and require iterative methods to solve. This poses several problems
for on-board implementation. Firstly, the methods can be computationally
expensive, and this can be a problem for space-qualified processors that
generally have less processing power than on-ground processors. Secondly,
the intermediate solutions provided by the algorithm may not satisfy all the
constraints, and this means that the intermediate solutions are not feasible.
Thirdly, the iterative method may not converge to a (globally) optimal so￾lution at all. In such cases, it may be preferable to rely on off-line trajectory
planning methods that can use ground-based computational resources and
operator supervision to check the correctness and feasibility of the solution.
The solution of the optimal planning problem consists of the time history
of the state vector and the control variables. This approach highlights a
Guidance 391difference between the traditional objectives of a guidance function versus
the objectives of a control function. The guidance function provides an
open-loop feedforward trajectory, while the control function constructs
the feedback required locally to drive the solution to the desired terminal
point. Fig. 8.2 illustrates this idea. The guidance function constructs an
optimal time history of the control variables, whereas the control function
constructs optimal feedback that is applicable to each point in the domain.
Optimization methods typically have more free parameters than are
required by the degrees of freedom that are determined by the (equality)
constraints. The problem is typically underconstrained, and this freedom is
exploited to search for an optimum. For example, in a fixed-time orbit
transfer problem, there are three constraints for the initial position and three
for the terminal position, while the time of flight is fixed. In this case, the six
parameters that form the solution (2  3, namely the initial and the ter￾minal velocity) are fully determined. If the initial and/or the terminal
time are left free, then the total DV can potentially be minimized by chang￾ing the maneuver times.
Classical formulation of the optimal control problem
Optimization generally involves iteratively approximating the cost function
by a quadratic function and finding the minimum of this approximation. A
case of one-dimensional minimization is illustrated in Fig. 8.3. The uncon￾strained minimum occurs when the first derivative of the function is equal to
Figure 8.2 Open-loop, feedforward optimization versus closed-loop, feedback optimi￾zation. Adapted from M. Kelly, An introduction to trajectory optimization: how to do your
own direct collocation, SIAM Review 59 (4) (2017) 849e904.
392 Thomas Peters et al.zero. The figure also shows what happens if a constraint is present. In this
case, the constraint is x  C. The minimum lies on the constraint and the
constraint is active. Note that if the constraint would be x > C, then the
original minimum would be found, and the constraint would be inactive.
In the classical development of optimization of a dynamical system, the
calculus of variations is used [15]. The cost function can be presented in the
Lagrange, Bolza, or Mayer form. These formulations are equivalent [16].
The development of the optimal control by Ref. [17] is followed here.
The system is described by the following differential equations:
x_ ¼ fðx; u; tÞ
The cost functional is presented in Bolza form as follows:
J ¼ f

xf ; tf

þ
Ztf
t0
Lðx; u; sÞds
In this equation, f is the terminal penalty term and L is the Lagrangian
term of the cost function (see Ref. [17], page 50). The dynamics equations
are treated as constraints in the optimization function. The classical approach
to this problem appends the constraints to the cost function using a vector of
Lagrange multipliers l.
J ¼ f þ
Ztf
t0
h
L þ lT

f  x_
ids
Figure 8.3 The optimum corresponds to a zero of the first derivative of the function f.
Guidance 393Define the Hamiltonian H ¼ L þ lT f and integrate by parts to obtain
the following expression:
J ¼ f  lT
f xf þ lT
0 x0 þ
Ztf
t0
"
H þ l_ T
x
#
ds
The next step is to take the first variation of this expression. The first
variation examines the behavior of solutions close to the current solution.
In other words, the first variation examines how the cost function changes
because of small changes in the state vector and the control variables. These
small changes in the state or the control are expressed by introducing the
symbol d. That is to say, a small change in, for example, the control inputs
is expressed as du.
dJ ¼
vf
vxf
 lT
f

dxf þ lT
0 dx0 þ
Ztf
t0
" vH
vx þ l_ T
!
dx þ
vH
vu
du
#
ds
For an optimal solution, dJ ¼ 0. From this condition, the following set
of equations are obtained.
The adjoint equations:
l_ T ¼  vH
vx
The transversality or boundary conditions:
lT
f ¼ vf
vxf
vf
vtf
þ Hf ¼ 0
The control equations:
vH
vu ¼ vL
vu  lT vf
vu ¼ 0
These are necessary conditions for an optimum to occur. To obtain the
sufficient conditions for an optimum, the second variation needs to be
examined. In this case, the Hessian matrix (the matrix of second derivatives)
of the cost function and the constraints needs to be positive semidefinite.
394 Thomas Peters et al.The classical approach using calculus of variations has some drawbacks,
and modern approaches to optimization and optimal control use a somewhat
different approach (see Ref. [18]).
Indirect methods versus direct methods
Optimization techniques are generally divided into two categories, direct
and indirect methods. Typically, direct methods attempt to construct a
sequence of approximations to the optimal solution such that the cost func￾tion is minimized. Given a generic cost function FðxÞ, a direct optimization
algorithm iteratively constructs a sequence of points x1; x2;/; xopt such that
Fðx1Þ > Fðx2Þ > / > F

xopt
. Indirect methods on the other hand oper￾ate by finding a root (that is, a zero crossing) of the necessary conditions for
an optimum, F0
ðxÞ ¼ 0. Direct methods generally do not require the
formulation and solution of the adjoint equations, the control equations,
or the transversality conditions.
Trajectory optimization methods
Many different methods are in use for performing trajectory optimization.
There are several introductory books that provide in-depth descriptions of
the most common methods, such as, for example, Refs. [19,20]. Some of
the more common trajectory optimization methods are:
- Primer vector. The primer vector method integrates the adjoint equations
to find the optimal control inputs. The primer vector method is often
used to find optimal low thrust and impulsive transfers. See
Refs. [19,21,22] for more details on this method.
- Collocation methods. Collocation methods determine an approximate
solution by enforcing the condition that the dynamics equations are satis￾fied at certain given points called the collocation nodes or points. Collo￾cation methods typically discretize time to produces a mesh, and a
parameterization for the state vector and the control variables (for
example, piecewise polynomials) for each segment. Ref. [19] provides
an example of trajectory optimization using a collocation method that
uses Hermite polynomials to represent the state vector history and the
control variables.
- Pseudospectral methods. Pseudospectral methods use orthogonal basis
functions to parameterize the trajectory. An example of basis functions are
the Chebyshev polynomials. The solution is found by finding the deriv￾atives of the trajectory in terms of the parameters and ensuring that the
derivatives agree with the differential equation at a specified set of nodes.
Guidance 395In contrast to the collocation method which uses basis functions valid for
each segment, the pseudospectral methods tend to use global basis func￾tion over the entire interval [19,20,23].
- Shooting method. The shooting method iteratively refines an initial guess
by finding the solution to the initial value problem (for example, by
means of trajectory integration) and updating the initial guess until the so￾lution satisfies the boundary conditions.
- Multiple shooting method. The multiple shooting method divides the
interval over which the solution is sought into a set of segments and ap￾plies the shooting method for each interval. In this case, the method is
iterated until the states at the start and end of each segment are matched.
As an example, Ref. [24] uses the multiple shooting method to determine
Lissajous orbits in the three-body problem.
A simple example
This section presents a simple example of optimization using a linear system
with a quadratic cost function of the control variables. The system is general,
and it is assumed that the control is continuous. The linear system is given
by:
x_ ¼ Ax þ Bu
The system is solved using the state transition matrix Fðt; t0Þ. The gen￾eral solution of the system is now given by:
xðtÞ ¼ Fðt; t0Þx0 þ
Zt
t0
Fðt; sÞBðsÞuðsÞds
First, divide the transfer interval into N segments. Assume that the con￾trol vector is constant over each segment. The dynamical equations can be
written as follows:
xf ¼ F
tf ; t0

x0 þX
N
i¼1
Siui; Si ¼ F
tf ; tiþ1
 Ztiþ1
ti
Fðt; sÞBð Þs ds
The matrices Si are found through integration. The dynamical equations
can be rewritten by bringing the control inputs to the left-hand side, and the
terminal state to the right-hand side.
X
N
i¼1
Siui ¼ xf  F
tf ; t0

x0
396 Thomas Peters et al.The problem can now been put into a form that is suitable for optimi￾zation using the classical method by putting the control variables in a column
vector u ¼ 
uT
1 / uT
i / uT
N
	T . The optimization problem can
be stated as follows. Minimize:
J ¼ uTQu
Subject to:
Au ¼ b
where A ¼ ½ S1 / Si / SN  and b ¼ xf  F
tf ; t0

x0. The
Lagrangian for this problem is:
L ¼ uTQu þ lT ðAu  bÞ
To find the optimum, the first derivatives of the Lagrangian are set to
zero, and the following set of equations is found:
vL
vu ¼ Qu þ ATl ¼ 0
vL
vl ¼ Au  b ¼ 0
These equations can be put into matrix form:
"
Q AT
A 0 #" u
l
#
¼
"
0
b
#
The solution for the control vector is found by solving the system of
equations through block matrix inversion:
u ¼ Q1AT 
AQ1
AT 1
b
This solution method produces a discrete approximation to the contin￾uous optimal control input that needs to be applied to drive the system from
its initial state x0 to its final state xf . As mentioned, optimal control is mostly
used to generate guidance profiles. Nevertheless, one can appreciate how
such formulation is often used in the whole aerospace world. For instance,
the reader is suggested to compare the general formulation hereby presented
with some important control laws described in Chapter 10 e Control, e.g.,
linear quadratic regulator.
Guidance 397Interpolation
Interpolation methods are commonly used to represent functions on-board
the spacecraft. For example, interpolation methods can be used when
optimal trajectories are computed on-ground and control variable histories
need to be uploaded to the spacecraft. Another example is the representation
of ephemerides of the spacecraft, the Sun, the planets, or other celestial
bodies on-board the spacecraft. The objective of interpolation is to reduce
the amount of parameter data to be uploaded to the spacecraft.
The subject of interpolation and approximation is vast, and this section is
only intended to provide a brief overview of several commonly used
methods. In the past, lunar and planetary ephemerides were provided in
tabulated format and interpolation and approximation techniques were
used extensively to obtain new data points based on the set of tabulated
data points. Personal computers (if available) had limited computational po￾wer, and it was important to limit the number of calculations to obtain a
result. At present, powerful personal computers with internet access are
widely available and the relative importance of reducing the number of cal￾culations has decreased. The internet allows rapid dissemination of up-to￾date ephemeris data.
Computational resources of satellites tend to be reduced, and at the same
time, the ability to transmit and store data is limited. If on-ground calcula￾tion of the trajectory is preferred, then the reference trajectory and control
inputs need to be uploaded to the spacecraft. It is desirable to ensure that the
trajectory is represented in such a way that the amount of data to transmit is
as small as possible for a given level of accuracy.
The reference trajectory can be represented in a variety of ways. These
representations have in common that they rely on a tabulated set of param￾eters that form an approximation of the reference trajectory. Desirable char￾acteristics that influence the selection of the type of parameters are the
number of parameters required to represent the solution with a certain de￾gree of accuracy and the accuracy over the approximation interval.
Interpolation generally makes use of tabulated data. Classical interpola￾tion methods operate on data presented in tables with the argument in
the first column and the function value in the second column. The tables
are organized such that the steps of the argument are of equal size. In the
classical approach, finite differences of the tabulated values are calculated,
as shown in Table 8.1. In this table, the indices of the argument and the
function are indicated by subscripted integers. The indices of the uneven dif￾ferences are multiples of one half, to indicate that these differences are taken
398 Thomas Peters et al.between the integer indices, while the even differences have integer values.
The order of the differences is indicated by means of a superscript.
Interpolation formulas
The classical methods of interpolation operate on the tabulated function as
shown in Table 8.1. The classical methods are polynomial approximations
that fit a polynomial through several points in the table. The first derivative
is generally not continuous at the start and end of each interval, but the
interpolation error is bounded. These methods define the fraction s˛
½0; 1 of the interpolation interval as follows:
si ¼ t  ti
tiþ1  ti
The interpolation formulas for the classical methods are shown in
Table 8.2.
Inverse interpolation
Inverse interpolation is the process of finding the argument for a specific
function value. Inverse interpolation can be used to find, for example, the
time of eclipse entry or exit or the times at which a ground station becomes
visible. Bessel’s formula can used to perform inverse interpolation. The
interpolation equation is put into the following form:
sd1
2
¼ fs  f0  B2
d2
0 þ d2
1

 B3d3
1
2
þ B4
d4
0 þ d4
1

þ .
Table 8.1 Tabulated data and finite differences.
Argument Function
Difference
1st 2nd 3rd 4th
t2 f2 d2
2
d3
2 d3
3
2
t1 f1 d2
1 d4
1
d1
2 d3
1
2
t0 f0 d2
0 d4
0
d1
2 d3
1
2
t1 f1 d2
1 d4
1
d3
2 d3
3
2
t2 f2 d2
2
Guidance 399In the first step of the iteration, the terms B2, B3, and B4 are set to zero to
obtain a first approximation of s. In successive iteration steps, the value of s is
used to compute B2, B3, and B4 and refine the estimate until the process
converges.
Spline interpolation
Splines are extensively used for interpolation in general to interpolate func￾tions. A spline is a piecewise polynomial that can be used to parameterize
curves. Splines tend to have (at least) continuity of the first derivative, but
continuity of the second derivative can be enforced. Authors in Ref. [19]
Table 8.2 Interpolation methods for tabulated data.
Method Formula
Nearest
fs ¼
8
>><
>>:
f0 0  s <
1
2
f1
1
2  s < 1
Linear fs ¼ f0 þ sd1
2
Quadratic fs ¼ f0 þ

d1
2
1
2 ð1 sÞd2
0

s
Lagrange
second order
fs ¼ 1
2 f1

s2 s
 þ f0

1 s2
 þ 1
2f1

s2 þs

Everett fs ¼ f0 þ sd1
2
þ E2
0d2
0 þ E2
1d2
1 þ E4
0d4
0 þ E4
1d4
1 þ .
E2
0 ¼ 1
6
sðs  1Þðs  2Þ
E2
1 ¼ 1
6
ðs þ 1Þsðs  1Þ
E4
0 ¼  1
120 ðs þ 1Þsðs  1Þðs  2Þðs  3Þ
E4
1 ¼  1
120 ðs þ 2Þðs þ 1Þsðs  1Þðs  2Þ
Bessel fs ¼ f0 þ sd1
2
þ B2

d2
0 þd2
1
 þ B3d3
1
2
þ B4

d4
0 þd4
1
 þ .
B2 ¼ 1
4
sðs  1Þ
B3 ¼ 1
6
sðs  1Þ

s  1
2

B4 ¼ 1
48 ðs þ 1Þsðs  1Þðs  2Þ
400 Thomas Peters et al.provide an example of how splines can be used in collocation method for
trajectory optimization. The basic Hermite spline is defined as follows:
f ðtÞ ¼
8
>>>>>>>><
>>>>>>>>:
C0ðtÞ t˛½t0; t1
.
CiðtÞ t˛ðti; tiþ1
.
Cn1ðtÞ t˛ðtn1; tn
In this equation, the piecewise polynomials are third-order polynomial
functions of the argument, as follows:
CiðsiÞ ¼ ai þ bisi þ cis2
i þ dis3
i
The argument for the interpolation s is defined in each interval as:
si ¼ t  ti
hi
; hi ¼ tiþ1  ti
The conditions for each of the segment are as follows. Firstly, the func￾tion value at the start and end of the interval needs to be equal to the func￾tion to be interpolated:
CiðtiÞ ¼ fi; i ¼ 1;.; n  1
Ciðtiþ1Þ ¼ fiþ1; i ¼ 1; .; n  1
The first and second derivatives need to be constant:
C0
iðtiþ1Þ ¼ C0
iþ1ðtiþ1Þ; i ¼ 1; .; n  2
C00
i ðtiþ1Þ ¼ C00
iþ1ðtiþ1Þ; i ¼ 1;.; n  2
The second derivative of the spline is continuous and varies linearly over
each interval. Fig. 8.4 shows an image of the evolution of the second deriv￾ative of the spline over each interval.
The general expression for the polynomial on each segment can be
found as:
CiðtÞ¼  f 00
i
ðt  tiþ1Þ
3
6hi
þ f 00
iþ1
ðt  tiÞ
3
6hi
þ

fiþ1  f 00
iþ1
h2
i
6
 t  ti
hi


fi  f 00
i
h2
i
6
 t  tiþ1
hi
Guidance 401This equation is generally implemented in matrix form such that all co￾efficients for the spline are found simultaneously.
Application: rendezvous guidance
The described methods are valid across all the space scenarios. The role of
the GNC engineer is to understand and select suitable dynamical models
and constraints to generate relevant guidance profiles. The focus of this
chapter is the development of guidance functions for formation flying and
rendezvous, and the description of the dynamics is briefly revisited with
the objective to develop an intuitive understanding of the relative motion
and the maneuvers that impact the relative motion. Although the focus is
on rendezvous, the same methods can be used for orbit maintenance of a
single satellite around its reference position. In addition, the state transition
matrix methods and maneuvers that are described below can also be used to
calculate trajectory correction maneuvers for interplanetary trajectories.
Relative motion for rendezvous guidance applications
Rendezvous and formation flying depend heavily on orbital mechanics, and
the basic solution for propagating the state of a satellite in orbit around a
spherical body can be expressed as a composition of functions as follows:
x1 ¼ 

bðt1Þ + kðt1; t0Þ + b
1ðt0Þ

ðx0Þ
The function b expressed the Cartesian coordinates in inertial space as a
function of the orbital elements, and the function k provides the solution of
Figure 8.4 Hermite spline interpolation with continuous second derivative.
402 Thomas Peters et al.Kepler’s equation as detailed in Chapter 4 e Orbital Dynamics. This equa￾tion can be linearized to study the relative motion around the reference
orbit.
dx1 ¼ Bðt1ÞKðt1; t0ÞB1ðt0Þdx0
The rotation to the local vertical, local horizontal frame can be absorbed
into the matrix B. To understand the dynamics more intuitively, it is useful
to start with the relative dynamics around a circular orbit. In the following
discussion, the d indicating infinitesimal changes is dropped for the state
vector.
x_ ¼ Ax þ Bu
The state vector is composed of position and velocity elements and the
matrix A is similarly built up from smaller submatrices. Focusing on the ho￾mogeneous part:
2
4
r_
v_
3
5 ¼
"
0 I
G 2U
#" r
v
#
In the local-vertical-local-horizontal (LVLH) frame (see Chapter 2 e
Reference Systems and Planetary Models), the matrix G contains the accel￾erations due to the gravity gradient, centrifugal, and Euler force. In a circular
orbit, the angular velocity is constant, and the Euler force is equal to zero.
The matrix U is the skew-symmetric matrix of the angular velocity of the
reference frame. For a circular orbit, the matrix A is explicitly given by:
Ai:p: ¼
2
6
6
6
6
6
4
00 1 0
00 0 1
00 0 2n
0 3n
2 2n 0
3
7
7
7
7
7
5
; Ao:p: ¼
" 0 1
n
2 0
#
The parameter n appearing in the matrix is the orbital rate, given by:
n ¼
ffiffiffiffiffiffi
m
R3
r
¼ 2p
T
This is a homogeneous system of equations with constant coefficients.
One method to solve the equations of relative motion is to decompose
Guidance 403the matrix A into the Jordan canonical form. This method provides a direct
insight into the nature of the underlying dynamics.
J ¼ P1AP
For a circular orbit, the Jordan decomposition of the in-plane dynamics
matrix turns out to be:
Pi:p: ¼
2
6
6
6
6
6
6
4
0 12 0
100 1
3
2
n 0 0 2n
0 0 n 0
3
7
7
7
7
7
7
5
; P1
i:p:
¼
2
6
6
6
6
6
4
0 4 2n1 0
10 0 2n1
00 0 n1
0 3 2n1 0
3
7
7
7
7
7
5
; Ji:p: ¼
2
6
6
6
6
6
6
4
0 00 0
3
2
n 00 0
0 00 n
0 0 n 0
3
7
7
7
7
7
7
5
Similarly, the Jordan decomposition of the out-of-plane dynamics ma￾trix is:
Po:p: ¼
"
0 1
n 0
#
; P1
o:p: ¼
" 0 1
n1 0
#
; Jo:p: ¼
" 0 n
n 0
#
The state transition matrix is found by performing a matrix
exponentiation:
Fðt1; t0Þ ¼ Pe
JDt
P1
The exponentiation of the Jordan matrices leads to the following expres￾sions for the in-plane and out-of-plane motions:
e
Ji:p:
Dt ¼
2
6
6
6
6
6
6
4
100 0
3
2
nDt 10 0
0 0 cos nDt sin nDt
0 0 sin nDt cos nDt
3
7
7
7
7
7
7
5
; e
Jo:p:
Dt
¼
" cos nDt sin nDt
sin nDt cos nDt
#
404 Thomas Peters et al.At this point, the dynamics of rendezvous and formation flying can be
understood in simple terms. The first observation is that in the local vertical,
local horizontal frame, the in-plane and the out-of-plane motions are
uncoupled. The out-of-plane motion has an eigenvalue ni with algebraic
multiplicity two (that is, the eigenvalue occurs twice) and geometric multi￾plicity two (that is, two independent eigenvectors exist). The in-plane mo￾tion also has an eigenvalue ni with geometric and algebraic multiplicity, and
an eigenvalue 0 with geometric multiplicity two and algebraic multiplicity
one, meaning that only one independent eigenvector exists. In the Jordan
form, an additional generalized eigenvector is found, along with a coupling
factor 3
2 n.
The out-of-plane motion is a simple oscillation, while the in-plane mo￾tion is a combination of an oscillation and a drifting motion. The in-plane
oscillation manifests itself as a 2  1 ellipse, with initial conditions equal
to 1 on the positive z-axis with a velocity 2n in the positive x-direction,
or initial position 2 on the positive x-axis with a velocity n in the negative
z-direction. The drifting motion requires zero velocity for positions on the
x-axis. In other words, positions on the x-axis are neutrally stable. Initial
conditions with a positive z coordinate equal to 1 require a velocity of 3
2 n
in the positive x-direction. Fig. 8.5 graphically shows the motions associated
with the natural modes of the system. The initial conditions associated with
the modes are taken from the matrix P.
Fig. 8.5 identifies the modes as the semimajor axis/mean longitude
mode, the eccentricity vector mode, and the inclination vector mode.
The Jordan decomposition shows how the in-plane modes are related. First
consider a chaser that starts at an altitude of 1. If the velocity in the positive
x-direction is equal to 3
2 n, then the semimajor axis mode is excited, but the
eccentricity mode is not. On the other hand, if the velocity in the x￾direction is equal to 2n, then the first eccentricity mode is excited, but the
semimajor axis mode is not. In addition, when the semimajor axis mode
is excited, the mean longitude starts to increase. Next, let’s consider a chaser
Figure 8.5 In-plane and out-of-plane natural dynamics modes.
Guidance 405located at a position 2 on the x-axis. If the velocity in the negative z￾direction is equal to zero, then the mean-longitude mode is excited, and
the chaser remains on the x-axis. If the velocity in the negative z￾direction is equal to n, then the second eccentricity mode is excited, but
the mean longitude mode is not.
To make the link with the orbital elements more explicit, it’s possible to
decompose the submatrix involving sines and cosines of the transfer time us￾ing the angle sum and difference identities for the sine and cosine. This pro￾cedure leads to a matrix that only contains sines and cosines of the initial
time, and a second matrix that only contains sines and cosines of the terminal
time:
"
cos nDt sin nDt
sin nDt cos nDt
#
¼
"
cos nt1 sin nt1
sin nt1 cos nt1
#" cos nt0 sin nt0
sin nt0 cos nt0
#
This leads to the following decomposition of the in-plane state transition
matrix:
Bi:p: ¼
2
6
6
6
6
6
6
4
0 1 2 cos nt1 2 sin nt1
1 0 sin nt1 cos nt1
3
2
n 0 2n sin nt1 2n cos nt1
0 0 n cos nt1 n sin nt1
3
7
7
7
7
7
7
5
;
B1
i:p: ¼
2
6
6
6
6
6
4
0 4 2n1 0
10 0 2n1
0 3 sin nt0 2n1 sin nt0 n1
cos nt0
0 3 cos nt0 2n1
cos nt0 n1 sin nt0
3
7
7
7
7
7
5
;
Ki:p: ¼
2
6
6
6
6
6
6
4
1 3
2
nðt1  t0Þ 0 0
0 1 00
0 0 10
0 0 01
3
7
7
7
7
7
7
5
406 Thomas Peters et al.Similarly, the decomposition of the out-of-plane state transition matrix is
given by:
Bo:p: ¼
" sin nt1 cos nt1
n cos nt1 n sin nt1
#
; B1
o:p: ¼
"
sin nt0 n1
cos nt0
cos nt0 n1 sin nt0
#
; Ko:p:
¼
"
1 0
0 1 #
The in-plane and the out-of-plane matrices K are now constant, except
for the coupling factor 3
2 nðt1 t0Þ. This indicates that the linear transforma￾tion defined by the matrix B maps a vector of trajectory constants to the
relative Cartesian state. The matrix B1 maps the Cartesian state to a vec￾tor of trajectory constants that are related to the orbital elements, cfr.
Chapter 4 e Orbital Dynamics. In particular, the rotation by an angle
nDt in the matrix e
JDt is replaced by time-dependent transformations in
the matrix B. This implies that the Cartesian modal excitations associated
with the eccentricity vector and the inclination vector modes are in fact
fixed with respect to inertial space. Small changes in these orbital elements
cause the shape or orientation of the orbit to be modified with respect to
inertial space. The matrix B is not unique, just as the Keplerian orbital el￾ements are not the only possible set of trajectory constants. In the current
decomposition, the vector of orbital elements differences is labeled as fol￾lows: semimajor axis, mean longitude, x component of the eccentricity
vector, z component of the eccentricity vector, x component of the incli￾nation vector, and z component of the inclination vector.
da ¼ ½ da dl dex dez dix diz 
The dynamics discussed above are a limit case that occurs when eccen￾tricity goes to zero. The family of solutions is continuous in the parameter e,
the eccentricity. This means that the insights from this elementary discussion
can be applied to the general problem of rendezvous and formation flying
around an elliptical orbit. The most straightforward approach to obtain
the full solution for the relative motion is to linearize the solution for the
Kepler orbit directly (see Refs. [25,26]). Solving the equations of relative
motion around an elliptical orbit directly is more challenging, as the dy￾namics matrix A becomes a function of time (see Refs. [26,27]).
In the past two decades, a lot of effort has been spent on including per￾turbations into the state transition matrix, such as, for example, J2 and other
Guidance 407nonspherical terms, air drag, and solar radiation pressure [28e30]. The solu￾tion methods and the solutions found for the state transition matrix are
closely related to the development of analytical or semianalytical theories
of satellite motions and often introduce additional linear transformations
to capture the dynamical effects of the perturbations [30]. Such theories of
relative motion by their nature require more computational effort than
the simpler theories that only retain the central term of the gravity field.
This understanding of the relative dynamics close to a reference orbit
generalizes to an understanding of the behavior of orbits in general. More
specifically, the relative dynamics illustrate that spacecraft in lower orbits
move faster with respect to higher orbits and vice versa, and that the relative
velocity to first order is equal to 3
2 n times the difference in altitude. Changes
in the eccentricity lead to a 2  1 elliptical oscillation around the refer￾ence orbit. This geometrical construction, the guiding center approxima￾tion, has been used in Ref. [31] to study the near-circular orbits that
prevail in the solar system. The out-of-plane oscillations indicate that the
orientation of the orbit can be changed by rotating the orbital plane around
two perpendicular axes.
The behavior of the relative solutions also provides insight in the evolu￾tion of uncertainty. The matrix Ki:p: shows that the semimajor axis and the
mean longitude are coupled. This means that if there is uncertainty in the
estimation of the semimajor axis, then the uncertainty in the mean longitude
will increase over time. The uncertainties of the other elements remain con￾stant in time for this simple model of the dynamics. Fig. 8.6 shows how this
works graphically. The uncertainty is represented as an ellipsoid. The initial
uncertainty is represented as a gray sphere, which stretches and rotates into
Figure 8.6 Evolution of uncertainty.
408 Thomas Peters et al.an ellipsoid. The combination of rotation and stretching is such that the pro￾jection on the z-axis remains unchanged.
Another important observation to make is that the solutions are linear.
This observation may seem trivial, but it does allow certain operations and
conceptual tools to be applied that cannot be used in nonlinear systems.
The most important thing to realize is that relative trajectories can freely
be added and subtracted. This can be done to create new relative trajectories,
but also to change the origin of the reference frame. In the field of rendez￾vous, the origin of the LVLH reference frame is usually placed in the center
of mass of the target spacecraft. This is a convenient selection because the
target spacecraft does not perform any translation maneuvers and therefore
remains exactly in the reference orbit. It can be convenient to select a refer￾ence orbit that is not linked to any specific spacecraft. For example, in a for￾mation of multiple satellites, the reference orbit can be close to the center of
the formation. Relative trajectories between each of the members of the for￾mation can then be examined by means of subtracting the trajectory of the
spacecraft that forms the desired origin of the reference frame.
Although the focus of this discussion has been on guidance for rendez￾vous and formation flying, the state transition matrix for the relative state
also has applications to, among others, correction maneuvers for interplan￾etary trajectories, orbit determination, trajectory optimization, analysis of
launch vehicle dispersions, constellation management, collocation and con￾trol of geostationary satellites. The linearization around a circular orbit in a
corotating frame has been used extensively in celestial mechanics, see
Ref. [31].
Effect of velocity impulses
For rendezvous operations, the level of acceleration available from the
thrusters is (usually) large enough that desired changes in the velocity can
be achieved in a small fraction of the orbital period. This means that the
changes in the velocity are essentially impulsive. Impulsive changes in the
velocity lead to changes in the evolution of the state vector, and these
changes in the evolution of the state vector can be exploited in the design
of maneuvers and trajectories for the rendezvous guidance. Fig. 8.7 shows
the effect of velocity impulses on the evolution of the in-plane relative dy￾namics. The application of velocity impulses can be understood by inspect￾ing the inverse matrix B1
i:p:
. A tangential impulse directly affects the
differential semimajor axis and the eccentricity vector, but it does not
Guidance 409directly change the mean longitude. However, the change in semimajor axis
immediately starts affecting the mean longitude through the coupling factor
3
2 n. This leads to a backward drift that is equal to 6p
n times the DV per orbit.
A radial impulse directly affects the mean longitude and the eccentricity vec￾tor, but it does not change the semimajor axis. The resulting trajectory is a
2  1 ellipse that reaches its farthest point at a distance of 4
n times the DV
after half an orbital period (Table 8.3).
Radial and tangential impulses are the basic building blocks of an in￾plane rendezvous guidance, which compares tangential and radial impulses
in terms of their effectiveness in changing the dimensions of the relative tra￾jectory. The tangential impulse is more effective overall in the sense that less
DV is required to affect the change, but the change in the trajectory takes
longer to establish. The tangential maneuver also induces along-track drift,
which can be beneficial if the objective is to alter the drift rate, but it can also
lead to potential risks. An example of such a risk is the inability to perform a
maneuver that is aimed to stop the drift due to thruster failure. This drift
could in turn lead to collision.
Out-of-plane maneuvers only affect the out-of-plane motion. The out￾of-plane motion is a simple harmonic oscillation, and the harmonic oscilla￾tion can be controlled by means of impulsive maneuvers occurring at the
nodes.
Impulsive maneuvers and trajectories
This section describes a set of maneuvers that can be used to perform rendez￾vous. The cotangential transfer, the periodic transfer, and the drift modula￾tion transfer generalize the Hohmann transfer, the radial hop, and the
tangential hop to make these maneuvers more broadly applicable, while pre￾serving the essential characteristics and objectives of these maneuvers. For
these three maneuvers, the simplification to the special cases is presented
together with the more general algorithm.
Figure 8.7 Effect of tangential and radial velocity impulses.
410 Thomas Peters et al.Two-point transfer The two-point transfer maneuver is used to find a
transfer trajectory between an initial state vector and a terminal state vector
that are given at a fixed initial and final time (which means that the transfer
time is fixed). The two-point transfer algorithm is based on inversion of a
submatrix of the state transition matrix. Assume a time interval with marked
times 0, 1, 2, and 3, where time 0 is the start of the interval, time 3 is the end
of the interval, and impulsive maneuvers occur at time 1 and time 2. The
evolution of the state vector can then be written as:
x3 ¼ F2/3
 
F1/2
 
F0/1x0 þ
" 0
Dv1
#! þ
" 0
Dv2
#!
This equation is rearranged to the following expression by bringing the
impulsive maneuvers to the left-hand side, and the initial and terminal states
to the right-hand side and expanding the state transition matrix into position
and velocity submatrices.
"
Frr Frv
Fvr Fvv #
1/2
" 0
Dv1
#
þ
" 0
Dv2
#
¼ x*
2; x*
2 ¼ F1
2/3x3  F0/2x0
The right-hand side is the state defect at time 2. This equation can be
written more compactly by concatenating the impulsive maneuvers into a
single vector:
"
Frv;1/2 0
Fvv;1/2 I3
#"Dv1
Dv2
#
¼ x*
2
Table 8.3 Comparison of tangential versus radial impulses as means to affect
trajectory changes.
Characteristic Tangential Radial
Maximum along-track
distance
6p
n DV 4
n DV
Time to reach maximum
along-track distance
T 1
2 T
Maximum altitude 4
n DV 1
n DV
Time to reach maximum
altitude
1
2 T 1
4 T
Presence of along-track
drift
Yes No
Guidance 411Inversion of the matrix now leads to the solution for the impulsive
maneuvers:
"
Dv1
Dv2
#
¼
2
4
F1
rv;1/2 0
Fvv;1/2F1
rv;1/2 I3
#" r
*
2
v*
2
#
The matrix Fvv;1/2 is:
Fvv;ip ¼
"
3 þ 4 cos nDt 2 sin nDt
2 sin nDt cos nDt
#
; Fvv;op ¼ cos nDt
The inverse matrix F1
rv;1/2 for rendezvous in a circular reference orbit
is:
F1
rv;ip ¼ n
D
" sin nDt 2 þ 2 cos nDt
2  2 cos nDt 4 sin nDt  3nDt
#
; F1
rv;op ¼ n
sin nDt
The value of the in-plane determinant (scaled by the orbital rate) is:
D ¼ 8ð1  cos nDtÞ  3nDt sin nDt
Both the in-plane matrix and the out-of-plane matrix contain a denom￾inator that can become zero. At these points, a singularity occurs in the al￾gorithm. Fig. 8.8 shows a plot of the in-plane determinant as a function of
time. The in-plane matrix becomes singular for transfer times that are integer
multiples of the orbital period. Another singularity occurs at a value of about
1.406 times the orbital period.
The out-of-plane matrix becomes singular at integer multiples of the
orbital period, and at integer multiples, plus one half of an orbital period.
Cotangential (Hohmann) transfer The cotangential transfer is used to
modify the altitude of a trajectory using two impulses parallel to V-bar.
The cotangential transfer for circular orbits is a modification of the algorithm
presented in Ref. [32] for elliptical orbits. The modification is the result of
letting the eccentricity go to zero. The basic algorithm is briefly described
here. The algorithm uses the following set of transfer parameters:
DC1 ¼ da2  da1; DC2 ¼ dez;2  dez;1; DC3 ¼ dex;2  dex;1
These transfer parameters define two polynomials that govern the evo￾lution of the z-coordinate in the LVLH frame, and that can be used to deter￾mine the cotangential transfer.
412 Thomas Peters et al.P1 ¼ DC1 þ DC2 cos nt1 þ DC3 sin nt1
P2 ¼ DC2 sin nt1  DC3 cos nt1
The polynomials P1 and P2 define the sine and the cosine of the transfer
angle as follows:
sin nDt ¼ 2P1P2
P2
1 þ P2
2
; cos nDt ¼ P2
2  P2
1
P2
1 þ P2
2
The DV’s required for the transfer can be found from the following
expressions:
Dvx;1 ¼ 1
4
n
ðDCsÞ
2
P1
; Dvx;2 ¼ 1
2
nDC1  Dvx;1
The parameter DCs that occurs in the expression for the DV is defined
based on the following relation:
ðDCsÞ
2 ¼ ðDC2Þ
2 þ ðDC3Þ
2  ðDC1Þ
2
The cotangential transfer can be simplified to a Hohmann transfer by
assuming that the transfer maneuver only changes the semimajor axis of
the orbit and leaves the eccentricity unchanged. In this case, the polynomials
governing the transfer simplify to:
P1 ¼ DC1 ¼ da2  da1; P2 ¼ 0
Figure 8.8 Two-point transfer algorithm singularities due to zeros in in-plane determi￾nant D.
Guidance 413The sine and the cosine of the transfer angle become 0 and 1, respec￾tively, indicating that the transfer duration is half an orbital period:
sin nDt ¼ 0; cos nDt ¼ 10nDt ¼ p
The velocity impulses required at the start and end of the transfer are
equal to one quarter times the orbital rate times the difference in semimajor
axis, as expected:
Dvx;1 ¼ 1
4
nðda2  da1Þ; Dvx;2 ¼ 1
4
nðda2  da1Þ
The cotangential transfer is a generalization of the Hohmann transfer and
can be used as a replacement of the Hohmann transfer in an autonomous on￾board guidance. In this situation, the guidance can compute the transfer
based on initial conditions that are not ideal for the Hohmann transfer
(that is, a lower orbit that is not exactly circular).
Trajectory-crossing maneuver The development of the cotangential
transfer maneuver algorithm leads to the observation that this algorithm
can become singular when the initial and final trajectories intersect. It is use￾ful to inspect visually the behavior of the z-coordinate and the velocity in the
z-direction to understand the crossing maneuver. Fig. 8.9 shows the
behavior of the z-coordinate as a function of the parameters that have
been identified so far.
The parameter Cm and the angle a that are shown in Fig. 8.9 are defined
as follows:
ðCmÞ
2 ¼ ðC2Þ
2 þ ðC3Þ
2
a ¼ tan1
ðC3; C2Þ
Crossings occur when the radius of the circle defined by Cm is larger than
the vertical offset of the circle C1. If this is the case, then the locations of the
crossings can be found from the following expressions:
sin nt1 ¼ DC2DCs þ DC1DC3
ðDCmÞ
2 ; cos nt1 ¼ DC3DCs  DC1DC2
ðDCmÞ
2
sin nt2 ¼ DC2DCs  DC1DC3
ðDCmÞ
2 ; cos nt2 ¼ DC3DCs þ DC1DC2
ðDCmÞ
2
The following DV’s must be applied at the crossing points.
414 Thomas Peters et al.Dv1;ip ¼ n
2
4
1
2
DC1
DCs
3
5; Dv2;ip ¼ n
2
4
1
2
DC1
DCs
3
5
The subscripts “1” and “2” indicate the crossing to which each DV cor￾responds. If there is no crossing, it can still be useful to perform a DV that
cancels the relative drift at the point of closest approach. In Fig. 8.9, this is
one of the points at which the z-coordinate reaches its maximum or mini￾mum value. To select the correct point, the following expressions are used.
cos nt ¼ sgnðDC1Þ
DC2
DCs
; sin nt ¼ sgnðDC1Þ
DC3
DCs
Figure 8.9 Geometry of trajectory crossings. Adapted from T.V. Peters, R. Noomen, Linear
cotangential transfers and safe orbits for elliptic orbit rendezvous, Journal of Guidance,
Control, and Dynamics 44 (2020) (4) 732e748.
Guidance 415The DV simply cancels the drift:
Dvip ¼ n
2
4
1
2
DC1
0
3
5
The trajectory-crossing maneuver can be used to recompute and replace
the second impulse of the cotangential transfer. For an autonomous on￾board guidance system, this can be beneficial because it can mitigate the
impact of trajectory dispersions that occur as a consequence of navigation
and actuation errors and the limited accuracy of the guidance dynamics
model.
Periodic (radial hop) transfer The periodic transfer maneuver for circular
orbits is based on a similar algorithm presented in Ref. [33] modified in two
ways. It has been adapted to circular orbits, and in addition, it has been made
possible to include a trajectory drift after the transfer is completed. That is to
say, the algorithm makes it possible to transfer from one drifting trajectory to
another drifting trajectory by means of a transfer trajectory that is itself drift￾free. The tangential components of the first and the second maneuvers are
fully determined by the initial and terminal difference in semimajor axis.
Dvx;1 ¼ 1
2
nda1; Dvx;2 ¼ 1
2
nda2
The tangential component of the DV causes changes in the mean longi￾tude and the components of the eccentricity vector that need to be taken
into account in the calculation of the transfer. The matrix B1
i:p: provides
the expression for the elements, considering the tangential component of
the DV.
dlþ
1 ¼ dl1; de
þ
x;1 ¼ dex;1  2 sin nt1n1Dvx;1; de
þ
z;1
¼ dez;1  2 cos nt1n1Dvx;1
Next, the transfer parameters K1, K2, and K3 are formed:
K1 ¼ 1
2

dl2  dlþ
1

; K2 ¼ dex;2  de
þ
x;1; K3 ¼ 
dez;2  de
þ
z;1

Transfer polynomials are defined similarly to the cotangential transfer.
P1 ¼ K1 þ K2 cos nt1 þ K3 sin nt1
P2 ¼ K2 sin nt1  K3 cos nt1  da2
416 Thomas Peters et al.The expressions for the sine and cosine of the transfer angle in terms of
these polynomials are the same for the nondrifting transfer as for the cotan￾gential transfer.
sin nDt ¼ 2P1P2
P2
1 þ P2
2
; cos nDt ¼ P2
2  P2
1
P2
1 þ P2
2
The radial component of the first and the second DV can be found from
the following expressions:
Dvz;2 ¼ n
P1 þ da2 sin nDt
1  cos nDt ; Dvz;1 ¼ nK1  Dvz;2
The in-plane DV vectors contain the tangential and the radial compo￾nents of the DV provided above:
Dv1;ip ¼
"
Dvx;1
Dvz;1
#
; Dv2;ip ¼
"
Dvx;2
Dvz;2
#
The nondrifting transfer can be simplified to the radial hop. In this case,
the differences in semimajor axis at the start and at the end of the trajectory
are equal to zero, and the tangential components of the first and second DV
are both equal to zero. The transfer polynomials are simplified to the
following form:
P1 ¼ K1 ¼ 1
2
ðdl2  dl1Þ; P2 ¼ 0
This means that the sine and cosine of the transfer angle are 0 and 1,
respectively, meaning that the transfer angle is equal to half an orbital period.
sin nDt ¼ 0; cos nDt ¼ 10nDt ¼ p
The radial components of the DV are equal to one quarter times the
orbital rate times the difference in mean anomaly:
Dvz;1 ¼ 1
4
nðdl2  dl1Þ; Dvz;2 ¼ 1
4
nðdl2  dl1Þ
The periodic transfer generalizes the radial hop such that it can be used
in situations in which the initial conditions are not strictly defined as an
along-track displacement. The algorithm can effectively cancel an initial
drift, and it can handle initial perturbations of the eccentricity vector by
design. Similar to the cotangential transfer, the crossing maneuver can be
used as a replacement for the second DV. This allows a guidance function
to compute a single impulsive maneuver at a time, and it allows the chaser
Guidance 417to mitigate the effects of trajectory errors that may occur because of naviga￾tion or actuation errors during the transfer by removing the drift at the end
of the transfer.
Drift modulation (tangential hop) transfer Drift modulation alters the
along-track distance in a transfer by means of tangential impulses that are
spaced in integer multiples of the orbital period. The drift modulation ma￾neuver is a generalization of the tangential hop transfer in the sense that the
initial orbital altitude (i.e., semimajor axis) can be nonzero. The first maneu￾ver occurs at time t1, and the second maneuver occurs at time t1 þ NT. Dur￾ing the N orbital periods of transfer time, the mean-longitude changes by
the following amount if no maneuvers are applied:
dlf ¼  3pNda1
If the chaser is initially located at a mean longitude dl1 and is required to
move to a mean longitude dl1, then the maneuver needs to perform the
following change in mean longitude:
Dl ¼ dl2  dl1  dlf
The DV’s required for this change can be deduced from Fig. 8.7, and are
equal to:
Dvx;1 ¼  n
6pN
Dl; Dvx;2 ¼ Dvx;1
The drift modulation maneuver can be simplified to the tangential hop
by setting the initial difference in semimajor axis to zero. The other equa￾tions remain unchanged.
Multiple impulse transfer The multiple-impulse maneuver transfer is a
minimum norm solution over the squares of two or more DV’s. The deri￾vation of this algorithm is straightforward and can be compared to the simple
optimization example in Section A simple example. The terminal state is
written as the sum of the contributions of the DV’s and the initial state,
all propagated to the terminal state using the state transition matrix.
xf ¼ X
Nman
i¼1
Ftman;i/tf
" 0
Dvi
#
þ Ft0/tf
x0
418 Thomas Peters et al.These equations can be rewritten as an overdetermined system by rear￾ranging terms:
"
Frv;t
man;1/t
f / Frv;tman;N/tf
Fvv;t
man;1/t
f / Fvv;tman;N/tf
#
|fflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflffl{zfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflffl}
A;3N6
2
6
6
4
Dv1
«
DvN
3
7
7
5
|fflfflffl{zfflfflffl}
x;3N1
¼ xf  Ft0/t1x0
|fflfflfflfflfflfflfflfflfflffl{zfflfflfflfflfflfflfflfflfflffl}
b;61
The solution for the DV’s is the minimum norm solution, which is
related to the least-squares solution for overdetermined systems:
x ¼ A

AAT 1
b
The solution can be recomputed before each maneuver is applied by
updating the system and removing the maneuvers that have already been
executed. For the final two maneuvers, the system becomes fully deter￾mined, and the solution becomes equal to the two-point transfer solution.
Out-of-plane maneuver The out-of-plane oscillation can be controlled
by means of a two-point transfer described in Section Two-point transfer,
but it can also be controlled by waiting for the next node to occur and
applying a single maneuver there. The out-of-plane motion is parameterized
with the components of the inclination vector, and the algorithm uses the
differences between the initial and the final desired inclination vector
elements.
Dix ¼ dix;2  dix;1; Diz ¼ diz;2  diz;1
The cosine and the sine of the location of the node are found from the
following expression.
cos nt1 ¼ Dix
Di
; sin nt1 ¼ Diz
Di
The magnitude of the inclination vector appears in the denominator.
Di ¼
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
ðDixÞ
2 þ ðDizÞ
2
q
The second node crossing occurs half an orbital period after the first node
crossing.
t2 ¼ t1 þ
1
2
T
Guidance 419The DV required at the node is equal and opposite to the velocity at the
node crossing. More specifically, the following expression provides the DV.
Dvy;1 ¼ nðDix cos nt1 þ Diz sin nt1Þ; Dvy;2 ¼ Dvy;1
Forced motion
The strategy for the development of the forced motion guidance is to specify
a trajectory and then to compute the feed-forward acceleration required to
follow the trajectory.
The forced motion during terminal rendezvous is governed by the same
general relative dynamics equations:
2
4
r_
v_
3
5 ¼
"
0 I3
G 2U
#" r
v
#
þ
"
0
I3
#
u
where u is the feed-forward control term. This control acceleration is split
into an acceleration uc compensating for the gravity gradient and fictitious
accelerations, and an acceleration uk that defines the kinematic accelerations
that are required to follow the forced motion trajectory.
2
4
r_
v_
3
5 ¼
"
0 I3
G 2U
#" r
v
#
þ
"
0
I3
#
ðuc þ ukÞ
The acceleration compensating for the gravity gradient and the fictitious
accelerations can be found from the lower part of the dynamics matrix.
uc ¼ ½ G 2U 
"
r
v
#
In an ideal setting, the compensating acceleration completely cancels out
the gravity gradient and the fictitious accelerations and only the kinematic
accelerations required to follow the trajectory remain.
2
4
r_
v_
3
5 ¼
"
0 I3
G 2U
#" r
v
#

"
0 0
G 2U
#" r
v
#
þ
"
0
I3
#
uk ¼
¼
"
0 I3
0 0 #" r
v
#
þ
"
0
I3
#
uk
420 Thomas Peters et al.The compensation for the dynamical effects cannot be expected to be
perfect, for several reasons. The compensation depends on the dynamical
model, and the guidance model of the dynamics is a simplification of the
true dynamics. The compensation depends on the estimated relative state,
and this estimated state contains estimation errors. The resulting errors in
the feed-forward acceleration provided by the guidance need to be compen￾sated for by the control function.
As an example, consider a forced motion transfer between an initial and a
terminal position, with initial and terminal velocities equal to zero.
rðt0Þ ¼ r0; vðt0Þ ¼ 0; rðt1Þ ¼ r1; vðt1Þ ¼ 0
A very simple method of performing the forced motion is to assume that
the motion starts and ends with an impulsive maneuver, and the velocity
during the transfer is constant. In this case, the position and velocity during
the transfer are given by:
rðÞ¼ t r0 þ ðr1  r0Þ t
ttrf
; vðÞ¼ð t r1  r0Þ 1
ttrf
The acceleration required to compensate the gravity gradient and the
fictitious accelerations is found by evaluating the expression for uc for
each point of the trajectory.
A more sophisticated example assumes that the chaser performs a simul￾taneous fly around and radial maneuver. In this case, the position vector is
decomposed into a scalar distance and a unit direction vector, both of which
are functions of time.
rðtÞ ¼ rðtÞerðtÞ
In this expression, the scalar distance r is the magnitude of the position
vector, and the direction vector er points in the direction of the position
vector.
r ¼ jjrjj; er ¼ r
jjrjj
The direction of the initial position vector is taken as the reference direc￾tion, and a one-axis rotation is applied to rotate the initial direction vector to
the terminal direction vector.
erðtÞ ¼ RðqðtÞÞe0 ¼ qe0q1
Guidance 421The rotation quaternion, the angular velocity, and the angular accelera￾tion are determined from the following expression:
q tðÞ¼
2
6
6
4
ea sin
1
2
að Þt
cos
1
2
að Þt
3
7
7
5; uðÞ¼ t a_ð Þt ea; u_ ðÞ¼ t a€ð Þt ea
The rotation angle af and rotation axis ea can be found from the dot
product and the cross product of the initial and the terminal direction
vectors:
cos af ¼ e0$e1; easin af ¼ e0  e1
Now assumptions need to be made on the shape of the functions rðtÞ and
aðtÞ, subject to the following conditions:
rðt0Þ ¼ r0; rðt1Þ ¼ r1; aðt0Þ ¼ 0; aðt1Þ ¼ af
As in the first example, the functions could simply be linear interpola￾tions between the initial and the final value of the function, but it is also
possible to use different types of functions, such as, for example, a cubic Her￾mite spline. Letting s ¼ t
ttrf
:
rðtÞ ¼ 
2s3  3s2 þ 1

r0 þ 
 2s3 þ 3s2
r1
aðtÞ ¼ 
 2s3 þ 3s2
af
The cubic Hermite spline has the advantage that the user can specify the
initial and the terminal rate of change of the functions, and in this case, the
initial and terminal rates of change are set to zero. This means that there are
no discontinuities in velocity at the start and end of the forced motion tra￾jectory, and thus no impulsive DV’s are required. The cubic Hermite spline
can also be differentiated easily, meaning that the velocity of the reference
trajectory and the kinematic feed-forward acceleration required to follow
the trajectory can also easily be found. The expression for the velocity
and the acceleration along the trajectory is as follows:
r_ðtÞ ¼ r_ðtÞerðtÞ þ rðtÞuðtÞ  erðtÞ
r€ðtÞ ¼ r€ðtÞerðtÞ þ 2r_ðtÞuðtÞ  erðtÞ þ rðtÞu_ ðtÞ  erðtÞ
þ rðtÞuðtÞ  ðuðtÞ  erðtÞÞ
422 Thomas Peters et al.The acceleration required to compensate the gravity gradient and the
fictitious accelerations is again found by evaluating the expression for uc
for each point of the trajectory.
Application: attitude guidance
Attitude guidance for rendezvous provides reference attitude profiles in
terms of the orientation quaternion and the angular velocity. If a feed￾forward torque is also requested, Euler’s equation can be used to compute
this feed-forward torque based on the inertia matrix of the chaser, the
angular acceleration, and the angular velocity.
t ¼ Iu_ þ u  ðIuÞ
In some cases, it is necessary to compose rotations. For example, the nav￾igation may provide the relative state with respect to the LVLH frame. The
attitude guidance may then compute a target-pointing quaternion that pro￾vides the required chaser orientation with respect to the LVLH frame. It may
be required to provide the chaser orientation with respect to the inertial
frame. The composition operation for quaternions, angular velocity, and
angular acceleration is given by the following set of equations.
CqA¼CqBBqA
AuC
C ¼ AuC
B þ BuC
C
Au_ C
C ¼ Au_ C
B þ Au_ C
C þ AuC
B  AuC
C
In this section, a number of basic algorithms are described that are useful
for attitude guidance. These algorithms include one- and two-axis pointing,
quaternion reorientation, and the LVLH frame orientation with respect to
the inertial frame.
One-axis pointing
One-axis pointing can be achieved by forming the shortest-arc quaternion
from a reference axis to the desired pointing direction. The one-axis point￾ing quaternion is formed as:
q ¼ p
jjpjj; p ¼
 e1  e2
1 þ e1$e2
!
Quaternions use the sine and cosine of half of the rotation angle instead
of the full rotation angle. Fig. 8.10 shows how the one-axis pointing
Guidance 423quaternion is obtained geometrically. Adding the vector e2 to vector e1 leads
to a vector that is at an angle 1
2 a with respect to vector e1.
The nonnormalized quaternion p is formed using the dot product and
the cross product of the vectors e1 and e1 þ e2.
p ¼
 
e1  ðe1 þ e2Þ
e1$ðe1 þ e2Þ
!
¼
 
e1  e1 þ e1  e2
e1$e1 þ e1$e2
!
¼
 e1  e2
1 þ e1$e2
!
¼
 sin ae3
1 þ cos a
!
The unit vector e3 is perpendicular to both vector e1 and e2. The norm
of this quaternion is equal to:
jjpjj ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
2ð1 þ cos aÞ p
The normalized quaternion turns out to contain the sine and cosine of
half the rotation angle, as expected.
q ¼ 1 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
2ð1 þ cos aÞ p
0
@
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
1  cos
2 a
p
e3
1 þ cos a
1
A
¼ 1
ffiffiffi
2 p
 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
1  cos a p e3
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
1 þ cos a p
!
¼
0
BB@
sin
1
2
ae3
cos
1
2
a
1
CCA
The angular velocity associated with the quaternion is found from the
quaternion derivative and the quaternion conjugate, namely:
u ¼ 2qq_ *
Figure 8.10 Rotation geometry.
424 Thomas Peters et al.The quaternion q is obtained by normalizing the quaternion p, such that
the quaternion derivative of q can be found:
q_ ¼ 1
kpk
d
dt p þ p
d
dt
1
kpk ¼ p_
kpk 
 
p
kpk
$ p_
kpk
!
p
kpk
The derivative of the quaternion p is found from the derivatives of the
unit vectors on which it is based:
p_¼
2
4
e_ 1  e2 þ e1  e_ 2
e_ 1$e2 þ e1$e_ 2
3
5
Similarly, the angular acceleration vector can be found by differentiating
the expression for the angular velocity.
u_ ¼ 2qq€ * þ 2q_q_
*
The derivative of the quaternion conjugate is found from the expression:
q_
* ¼  q*qq_ *
The second derivative of the normalized quaternion q can be found from
the nonnormalized quaternion as follows.
q€¼ p€
kpk  2
 
p
kpk
$ p_
kpk
!
p_
kpk 
( p_
kpk
$ p_
kpk
!
 3
 
p
kpk
$ p_
kpk
!

 
p
kpk
$ p_
kpk
!
þ
 
p
kpk
$ p€
kpk
!) p
kpk
Finally, the second derivative of the nonnormalized quaternion p is
found from the unit vectors and their derivatives.
p€¼
2
4
e€1  e2 þ 2e_ 1  e_ 2 þ e1  e€2
e€1$e2 þ 2e_ 1$e_ 2 þ e1$e€2
3
5
As an example, consider the quaternion that rotates the x-axis from the
base frame to a position vector r. In this case:
e1 ¼
2
6
6
4
1
0
0
3
7
7
5; e2 ¼ r
krk
Guidance 425e_ 1 ¼
2
6
6
4
0
0
0
3
7
7
5; e_ 2 ¼ v
krk 

e2$ v
krk

e2
e€1 ¼
2
6
6
4
0
0
0
3
7
7
5; e€2 ¼ 1
krk

a  2ðv$e2Þe_ 2 

a$e2 þ v$e_ 2

e2

Two-axis pointing
Two-axis pointing is useful when a spacecraft needs to point the principal
axis in a certain direction while minimizing the angle between a secondary
axis and a specific secondary direction. For example, a chaser spacecraft may
need to point a camera in the direction of a point of interest while mini￾mizing the angle between the solar panel normal and the Sun direction.
The algorithm makes use of an extended vector normalization algorithm
that provides the first and second rate of change of the unit vector that are
used to obtain the angular velocity and the angular acceleration.
The algorithm takes the first pointing vector r1 and the secondary point￾ing vector r2 and forms the cross product. The vector r3 is perpendicular to
both r1 and r2. The velocity and acceleration vectors associated with the first
and the second pointing vectors are used to find the first and second rate of
change of the vector r3.
r3 ¼ r1  r2
v3 ¼ v1  r2 þ r1  v2
a3 ¼ a1  r2 þ 2v1  v2 þ r1  a2
The extended normalization algorithm is used to find the unit vector e1
and its derivatives e_ 1 and e€1, and the unit vector e3 and its derivatives e_ 3 and
e€3. The unit vector ex is identified with the vector e1, while the unit vector
ez is identified with the vector e3. The unit vector ey is obtained from:
ey ¼ ez  ex
e_ y ¼ e_ z  ex þ ez  e_ x
e€y ¼ e€z  ex þ 2e_ z  e_ x þ ez  e€x
426 Thomas Peters et al.The angular velocity vector is found from the following expressions:
ux ¼ 1
2

e_ y $ ez  eye_ z

uy ¼ 1
2

 e_ x $ ez þ exe_ z

uz ¼ 1
2

e_ x $ ey  exe_ y

The angular acceleration vector is found from similar expressions:
u_ x ¼ 1
2

e€y $ ez  eye€z

u_ y ¼ 1
2

 e€x $ ez þ exe€z

u_ z ¼ 1
2

e€x $ ey  exe€y

Extended vector normalization The extended vector normalization
computes the unit vector, as well as the rate of change and the second
rate of change of an input vector v, and its first and second derivatives v_
and v€: First, the input vector is normalized:
ev ¼ v
kvk
Next, the auxiliary parameters u_ and u€ are formed:
u_ ¼ v_
kvk
; u€ ¼ v€
kvk
;
Using these expressions, the first and second rate of change of the unit
vector are formed by removing the component of the derivative vectors
that lie along the unit vector:
e_ v ¼ u_ 

u_ $ ev

ev
e€v ¼ u€  2

u_ $ ev

e_ v 

u€$ ev þ u_ $ e_v

ev
Guidance 427Reorientation
For the reorientation guidance, the algorithm in Ref. [34] can be used. This
algorithm provides an interpolation between an initial attitude state (consist￾ing of a quaternion and an angular velocity) to a terminal attitude state per￾formed in a given amount of time. For an effective reorientation, the
difference between the initial and the desired quaternion is formed; this is
the error quaternion. The error quaternion is interpolated from the initial
value to zero within the desired reorientation time. At each time step of
the transfer, the attitude guidance computes the reference attitude as the
desired quaternion multiplied by the error quaternion. In doing so, the
reference attitude trajectory is equal to the initial orientation at the start of
the transfer and equal to the final attitude at the end of the transfer.
Four interpolation coefficients q4, u1, u2, and u3 are generated as
follows:
q4 ¼ qa
u1 ¼ 1
3
uattrf
u2 ¼ logexp1
3
uattrf *
q
*
a qb

exp1
3
ubttrf *
u3 ¼ 1
3
ubttrf
The superscript * indicates the quaternion conjugate. The quaternion
exponent and logarithm are defined as follows:
expð Þ¼ v qv ¼
 
ev sin w
cos w
!
; ev ¼ v
jvj
; w ¼ jvj
logðqvÞ ¼ v
The quaternion is given by a scalar component and a vector component,
cfr. Chapter 5 e Attitude Dynamics:
q ¼
( q1: 3
q4
)
428 Thomas Peters et al.The quaternion logarithm outputs the following vector:
v ¼ weq; eq ¼ q
jqj
; w ¼ 2 tan1
ð

q1: 3

; q4Þ
The following interpolating polynomials are defined:
b1 ¼ 1  ð1  sÞ
3
b2 ¼ 3s2  2s3
b3 ¼ s3
The interpolated quaternion is given by the following function of the
four interpolation coefficients q4, u1, u2, and u3:
q ¼ q4 expðu1b1Þexpðu2b2Þexpðu3b3Þ
The first and second derivatives of these expressions are used to construct
the angular velocity and angular acceleration. The feed-forward torque is
computed using the already presented equation t ¼ Iu_ þ u  ðIuÞ:
Quaternion rotation: LVLH, PQW, and RSW
The rotation from the inertial frame to the LVLH frame is composed by a
sequence of rotations. The relationship between the Earth-centered inertial
(ECI) frame and the LVLH frame has been presented in Chapter 2 e Refer￾ence systems. Here, we present a quaternion perspective on the rotation,
which is useful for the generation of guidance profiles. The first set of rota￾tions rotates the inertial frame to the LVLH frame at perigee. The LVLH
frame used in this first rotation is the comoving frame LVLH-based
Gm;n;p, in which, differently from Di;j;k, the radial direction toward the
attracting body is called z axis, whereas the y axis is opposite to the angular
momentum vector (please refer to Chapter 2 e Reference systems). The
first three rotations through the angles U, i, and u is the familiar orbit rota￾tion sequence [11]. The two rotations through the angle p
2 aim to make the
y-axis point toward the negative orbital angular momentum vector and the
z-axis of the frame toward the center of the Earth.
pAI ¼ Rz
p
2

Ry

p
2

RzðuÞRxðiÞRzðUÞ
The rotation to the LVLH frame is obtained by performing a final rota￾tion through the true anomaly.
LVLH AI ¼ RyðwÞRI/p
Guidance 429This rotation sequence can be written as a quaternion as follows, where
again the first three components are the vectorial part as q ¼
( q1 : 3
q4
)
.
LVLH qI ¼
2
6
6
6
6
6
4
q1
q2
q3
q4
3
7
7
7
7
7
5
The elements of this quaternion are:
q1 ¼  cos
i
2
cos
1
2
ðU þ u þ wÞ þ cos
i
2
sin
1
2
ðU þ u þ wÞ
þ sin
i
2
cos
1
2
ðU  u  wÞ þ sin
i
2
sin
1
2
ðU  u  wÞ
q2 ¼  cos
i
2
cos
1
2
ðU þ u þ wÞ  cos
i
2
sin
1
2
ðU þ u þ wÞ
 sin
i
2
cos
1
2
ðU  u  wÞ þ sin
i
2
sin
1
2
ðU  u  wÞ
q3 ¼ cos
i
2
cos
1
2
ðU þ u þ wÞ þ cos
i
2
sin
1
2
ðU þ u þ wÞ
 sin
i
2
cos
1
2
ðU  u  wÞ þ sin
i
2
sin
1
2
ðU  u  wÞ
q4 ¼ cos
i
2
cos
1
2
ðU þ u þ wÞ  cos
i
2
sin
1
2
ðU þ u þ wÞ
þ sin
i
2
cos
1
2
ðU  u  wÞ þ sin
i
2
sin
1
2
ðU  u  wÞ
The two rotations through the angle p
2 complicate the expression for the
quaternion considerably. The quaternion that encodes the rotation from the
inertial frame to the perifocal frame is:
PQW qI ¼
2
6
6
6
6
6
6
6
6
6
6
6
4
sin
i
2
cos
1
2
ðU  uÞ
sin
i
2
sin
1
2
ðU  uÞ
cos
i
2
sin
1
2
ðU þ uÞ
cos
i
2
cos
1
2
ðU þ uÞ
3
7
7
7
7
7
7
7
7
7
7
7
5
430 Thomas Peters et al.The rotation from the inertial frame to the radial, tangential normal
(RSW) frame Di;j;k (please refer to Chapter 2 e Reference systems) is given
by:
RSW qI ¼
2
6
6
6
6
6
6
6
6
6
6
6
4
sin
i
2
cos
1
2
ðU  u  wÞ
sin
i
2
sin
1
2
ðU  u  wÞ
cos
i
2
sin
1
2
ðU þ u þ wÞ
cos
i
2
cos
1
2
ðU þ u þ wÞ
3
7
7
7
7
7
7
7
7
7
7
7
5
In the RSW frame, the x-axis points radially outward, the z-axis points
in the direction of the orbital angular momentum vector, and the y-axis
completes the right-handed frame.
Design of a guidance function
This section explores the design of a guidance function at system level. It
covers the generation and derivation of requirements to the architecture
definition.
Identification of guidance requirements
The design of the guidance is an iterative process that typically begins with
the identification of requirements for the guidance. The requirements
specify the organization, functionalities, and the performance of the guid￾ance function. The set of requirements serves as a starting point for designing
and implementing the guidance function. The requirements for the guid￾ance can be grouped into sets that cover the following domains:
• Functional
B Division into functional elements.
B Specification of functions to be performed by the guidance.
B Specification of modes contained in the guidance.
B Constraints to be taken into account by the guidance.
B Specification of types of maneuvers to be considered.
B Safety.
• Performance
B Safety.
B Propellant or DV consumption.
B Margins with respect to available actuator forces and torques.
B CPU load.
B Accuracy.
Guidance 431The functional requirements define the capabilities of the guidance.
Functional requirements divide the guidance into functional elements. For
rendezvous guidance, such elements could be, for example, impulsive guid￾ance, forced motion guidance, and attitude guidance, safety monitoring, and
others. The functional requirements may also specify the functions that the
guidance needs to perform. For rendezvous, this could be, for example, per￾forming a sequence of maneuvers to approach the target, perform target
pointing, etc. The functional requirements may specify the modes that
need to be present within the guidance. The guidance modes are discussed
more in detail in Section Guidance modes. The functional requirements
may also specify constraints to be taken into account by the guidance,
such as not pointing instruments or radiator panels toward the Sun, or point￾ing Solar panels toward the Sun. Another aspect that may be covered by this
kind of requirements is the type of maneuvers that need to be considered.
This could include, for example, collision avoidance maneuvers or maneu￾vers to enter a passively safe formation. The functional requirements can also
cover certain aspects of safety. For rendezvous, this may include, for
example, requirements on using passively safe trajectories during the
approach or requirements that state that the trajectory needs to remain
safe even if any of the impulsive DV’s cannot be applied.
Performance requirements, as the name implies, define the performance
of the guidance in terms of numerical values. Safety performance require￾ments could, for example, require a safe relative trajectory to remain
collision-free for a certain number of days, or it could specify a margin
around the nominal trajectory that the chaser cannot leave. Requirements
can also be set on propellant consumption and the magnitude of maneuvers.
For example, the long-range rendezvous may be required to consume less
than a certain amount of propellant. Performance requirements may also
specify the margins that need to be respected with respect to the maximum
forces and torques available from the actuators in order to leave sufficient
margin for the control. For example, feed-forward torque may be required
to be less than 70% of the total torque available from the reaction wheels.
The performance requirements may also specify the central processing
unit (CPU) load that the guidance function cannot exceed, for example,
10% of the total maximum CPU load. Such requirements may require tests
to be performed on representative hardware; in this case, running the soft￾ware on a space-qualified CPU. Accuracy requirements can be related to
safety, for example, if a requirement states that the chaser at arrival after a
two DV transfer needs to have an accuracy, that is better than a certain
432 Thomas Peters et al.percentage of the distance of the arrival point to the target. This would allow
the design of the guidance trajectory to become robust to uncertainty in the
navigation solution when the transfer is calculated, to uncertainties in the
dynamical model used, and to errors in the maneuver execution. Another
example could be the accuracy with which Sun pointing is achieved from
the guidance perspective. In this case, a functional requirement may specify
that a Sun ephemeris is present in the guidance, and a performance require￾ment may specify the required angular accuracy of the ephemeris. These
performance requirements are closely related to the creation of (pointing)
error budgets and the allocation of allowable maximum errors to each of
the components of the error budget. Reference [2] contains an extensive
discussion on how to create pointing error budgets and specifically how
the process of creating the error budget is related to modeling and analyzing
the system as a whole. The process of creating an error budget is divided
into the following steps:
1. Modeling the system and identifying all error sources.
2. Characterization of each of the error sources (magnitude, type of
distribution).
3. Combining all error sources to form the overall system error.
The system modeling and the identification of the error sources includes
a determination of the sensitivity of the overall system error to each of the
error components. The combination of all error sources into an overall sys￾tem error can be a challenging task, and Monte Carlo simulations or worst￾case analyses may be required to determine whether the performance of the
system as a whole is sufficient. For a rendezvous mission, the performance
accuracy may be determined by the overall error at docking. A Monte Carlo
test campaign may need to be run that varies parameters such as sensor and
actuator misalignments, uncertainties in the level of thrust available for each
thruster, uncertainties in the mass properties of the chaser, uncertainties in
the level of perturbations (e.g., vibration frequencies of the solar panels, pro￾pellant slosh), and many others. Different performance metrics may apply to
different phases of the mission. From the guidance perspective, the main
impact that the guidance can have is in the accuracy of the models that
are used to perform the calculations. Secondary impacts of the guidance
on the performance accuracy are the smoothness of the profiles provided
by the guidance and the provision of feed-forward terms. Returning to
the example of the Sun-pointing accuracy, it can be observed that the
Sun-pointing accuracy depends on the accuracy of the orbit determination,
the accuracy of the on-board clock, the overall attitude pointing accuracy,
Guidance 433which may depend on as well as the accuracy of the ephemeris model. If the
guidance includes the ephemeris model, then the guidance can only influ￾ence the Sun-pointing accuracy through the accuracy of the ephemeris
model. From the point of view of the guidance, it makes sense to adjust
the accuracy of the ephemeris to be in line with the errors expected for
the other components of the error budget.
Finally, the requirements need to indicate how the requirements are
verified. Requirements can be verified in the following ways:
- Test.
- Inspection.
- Analysis.
- Review of design.
The most useful method of verification is through testing. Testing of the
guidance can be performed at the level of single utility functions, modes,
the entire guidance function, and the guidance function as integrated within
the overall GNC software. Performance requirements are generally testable.
Inspection of the design can verify whether certain functionalities are present
such as, for example, the ability to go to a safe configuration. Analysis as a
method of verification can be useful if direct testing is not practical. For
example, if a requirement specifies long-term safety after a sequence of ma￾neuvers, then it may be impractical to run a GNC simulator (which operates
at the frequency of the GNC) for the duration of the desired interval in a
Monte Carlo campaign, because this would require too much computation
time. It may be more convenient to determine the terminal conditions after
the sequence of maneuvers and to use a stand-alone orbit propagator to
analyze the safety. Finally, a review of the design (usually in the form of writ￾ten documentation) can be used to verify certain types of requirements. It
may, for example, be the case that a functional requirement states that the
guidance needs to calculate the ephemeris of the Sun; this can be verified
by means of checking the design documentation.
Guidance modes
A mode is a configuration of the (sub)system in a certain state that is char￾acterized by the active functions or enabled functional capabilities. The
mode of the system specifies the behavior of the system or subsystem. For
rendezvous and formation flying, the guidance may need to perform
different functions during different parts of the mission. Fig. 8.11 shows
how the guidance function for rendezvous can be divided into different do￾mains (translation, attitude, and special functions) and into different modes.
434 Thomas Peters et al.Each of these modes has a different objective, and different combinations of
translation, attitude, and guidance modes can be available during different
phase of the mission. For example, the translation guidance can provide a
set of impulsive maneuvers during a mode that is aimed at maintaining a spe￾cific trajectory, while the attitude guidance may switch between target
pointing mode and DV pointing mode as the maneuvers need to be
executed.
The different guidance modes give the guidance the capability to have
different behaviors that apply to different types of situations. This flexibility
to adapt its behavior to the environment and to the current objectives enable
the overall GNC system to operate with a higher degree of autonomy.
From the perspective of design, development, validation, and verifica￾tion, it is also advantageous to break down the guidance into distinct func￾tional modes because each of the modes represents a smaller, simpler
functional unit that can be tested independently from the other modes.
The simple division into modes that is shown in Fig. 8.11 does not indi￾cate very well how data and commands flow through the guidance model.
The architecture of the guidance provides a high-level view of the way the
guidance operates and is the subject of the next section.
Architecture
Fig. 8.12 shows a generic design for the guidance architecture. A guidance
mode manager manages the lower-level guidance modes, responding to the
GNC mode manager. Pre- and postprocessing blocks are present to perform
calculations that are applicable to all the modes. For example, assume that all
modes require the current orientation of the chaser with respect to the
Figure 8.11 Guidance function divided into translation, attitude, and special guidance
functions, each with distinct modes.
Guidance 435LVLH frame. Also, assume that the input to the guidance provides the
orientation with respect to the inertial frame and the orientation of the
LVLH frame with respect to the inertial frame. The preprocessing function
would then contain the functions required to compute the orientation of the
chaser with respect to the LVLH frame from the input. The preprocessing
function also ensures that the correct information is available to each of
the modes, and the postprocessing ensures that the output of the guidance
is padded if necessary. It is possible, for example, that not all modes require
exactly the same input or produce the same output. In this case, the prepro￾cessing ensures that the correct input data are provided to each of the modes.
The postprocessing block can pass the outputs that are not provided by spe￾cific modes, if required. For example, the impulsive translational guidance
does not provide feed-forward accelerations, while the forced motion guid￾ance does. The postprocessing function ensures that the output of the overall
guidance function contains all the possible outputs that the modes can pro￾vide. When the impulsive guidance modes are active, the postprocessing
function may fill the feed-forward acceleration with zeroes.
The postprocessing function may also contain functions that apply to
some of the modes, but not to all. In such cases, some freedom exists in
determining where best to place the respective functions. For example,
free-flying trajectory propagation for the generation of reference trajectories
may apply to the impulsive guidance modes, but not to forced motion guid￾ance modes. In this case, the trajectory propagation could be incorporated
inside each of the modes, or a free-flying trajectory propagation can be
incorporated inside the postprocessing with an activation switch that ensures
that it is only active during the impulsive maneuvering modes. This example
should illustrate that the guidance architectural design is a useful conceptual
Figure 8.12 Guidance architecture indicating internal flow of data.
436 Thomas Peters et al.tool, but that on occasion, practical design considerations should ensure that
the most convenient organization of the functions of the guidance is chosen.
As such, the guidance architectural design should help to make the guidance
as easy to understand as possible.
Function library
The algorithms described in Section Design process can be implemented
into function libraries that can in turn be used to construct the guidance.
Taking a generic impulsive maneuver calculation as an example, a generic
maneuver calculation command could look as follows:
½t; Dv ¼ manoeuvreðm;R; t; da;.Þ
In this expression, the gravitational parameter m, the orbital radius R, the
maneuver time, and the differential orbital elements occur. This choice of
input parameters is to some extent arbitrary. The maneuver calculations
all rely on the orbital rate n rather than directly on the gravitational param￾eter and the orbital radius. This means that the calculation of the orbital rate
could also be removed from the maneuver calculation and moved to some
preprocessing function.
n ¼
ffiffiffiffiffiffi
m
R3
r
In this case, the calculation required to obtain the orbital rate is fairly sim￾ple, and the computational cost of performing this operation within the ma￾neuver calculation is small. On the other hand, the orbital rate is also used in
trajectory propagation functions that use the output of the maneuver calcu￾lations to propagate a reference trajectory. Placing the calculation of the
orbital rate inside a preprocessing function ensures that the orbital rate is
used consistently throughout the whole guidance and ensures that the num￾ber of mathematical operations inside the guidance is reduced. For more
complex types of intermediate results, it may be worth the effort to ensure
that these calculations are performed only once.
The maneuver calculation algorithms are broadly similar in the sense that
all of them output at the very least a DV. On the other hand, some of the
impulsive maneuver calculation algorithms also output the time of applica￾tion of the maneuver. It is recommended to ensure that all maneuver calcu￾lation functions have broadly similar interfaces.
Guidance 437Guidance implementation best practices
The following recommendations are provided for the implementation
of guidance functions. These recommendations are based on the overall sug￾gestions that have been provided throughout this chapter.
• Ensure consistency of dynamics and state representations with N and C.
• Define the guidance architecture.
• Define clear interfaces with the other functional elements in the GNC
software. Ensure that the interfaces are frozen early in the design and
ensure that any changes are propagated throughout the full GNC.
• Perform early integration of the full GNC to ensure that the interfaces
are consistent and that the full GNC runs correctly without errors
(even if the full GNC is not complete yet).
• Ensure that all code contains a commented description of the function
behavior, its inputs, and its outputs.
• Ensure that the function is clearly commented to ensure that other de￾velopers can easily understand what each line of code does.
• Break down functions into smaller function blocks.
• Reuse library functions whenever possible.
• Perform unit testing on smaller functions to ensure these functions
behave as expected. Example of unit testing would be to perform nu￾merical differentiation to obtain the rate of change of certain parameters
to check the analytical expressions. For example, (angular) velocity can
be checked by numerically differentiating the corresponding position
vector/quaternion.
• Ensure that the accuracy of the guidance dynamics models is sufficient to
achieve the mission goals.
• Ensure that the accuracy of the guidance dynamics models do not exceed
the accuracy that can be provided by the rest of the functions in the
GNC system.
References
[1] D.K. Geller, Orbital rendezvous: when is autonomy required? Journal of Guidance,
Control, and Dynamics 30 (4) (2007) 974e981.
[2] J.R. Wertz, W.J. Larson, D. Klungle, in: Space Mission Analysis and Design, vol 8,
Torrance, Microcosm, 1999.
[3] https://www.h2020-ergo.eu/project/background-on-autonomy-software-frame￾works/autonomy-in-space-systems/.
[4] P. Grandjean, T. Pesquet, A.M.M. Muxi, M.C. Charmeau, What on-board autonomy
means for ground operations: an autonomy demonstrator conceptual design, in: Space
OPS 2004 Conference, 2004, p. 267.
438 Thomas Peters et al.[5] M. Chernick, S. D’Amico, New closed-form solutions for optimal impulsive control
of spacecraft relative motion, Journal of Guidance, Control, and Dynamics 41 (2)
(2018) 301e319.
[6] J.L. Junkins, P. Singla, How nonlinear is it? A tutorial on nonlinearity of orbit and atti￾tude dynamics, Journal of the Astronautical Sciences 52 (1) (2004) 7e60.
[7] M.D. Shuster, A survey of attitude representations, Navigation 8 (9) (1993) 439e517.
[8] J.L. Synge, A. Schild, Tensor calculus, in: Tensor Calculus, University of Toronto
Press, 2020.
[9] P.C. Hughes, Spacecraft Attitude Dynamics, Courier Corporation, 2012.
[10] J. Sola, Quaternion Kinematics for the Error-State Kalman Filter, 2017 arXiv preprint
arXiv:1711.02508.
[11] J.B. Kuipers, Quaternions and Rotation Sequences: A Primer with Applications to Or￾bits, Aerospace, and Virtual Reality, Princeton University Press, 1999.
[12] H. Schaub, J.L. Junkins, Stereographic orientation parameters for attitude dynamics: a
generalization of the Rodrigues parameters, Journal of the Astronautical Sciences 44 (1)
(1996) 1e19.
[13] G.R. Hintz, Survey of orbit element sets, Journal of Guidance, Control, and Dynamics
31 (3) (2008) 785e790.
[14] J. Sullivan, S. Grimberg, S. D’Amico, Comprehensive survey and assessment of space￾craft relative motion dynamics models, Journal of Guidance, Control, and Dynamics
40 (8) (2017) 1837e1859.
[15] W. Fleming, R. Rishel, The simplest problem in calculus of variations, in: Determin￾istic and Stochastic Optimal Control, Springer, New York, NY, 1975, pp. 1e19.
[16] W.H. Fleming, R.W. Rishel, Deterministic and Stochastic Optimal Control, vol 1,
Springer Science & Business Media, 2012.
[17] A.E. Bryson, Y.C. Ho, Applied Optimal Control: Optimization, Estimation, and
Control, Routledge, 2018.
[18] D. Liberzon, Switching in Systems and Control, vol 190, Birkhauser, Boston, 2003.
[19] B.A. Conway (Ed.), Spacecraft Trajectory Optimization, vol 29, Cambridge Univer￾sity Press, 2010.
[20] J.T. Betts, Survey of numerical methods for trajectory optimization, Journal of Guid￾ance, Control, and Dynamics 21 (2) (1998) 193e207.
[21] D.F. Lawden, Interplanetary rocket trajectories, Advances in Space Science 1 (1959)
1e53.
[22] D.J. Jezewski, H.L. Rozendaal, An efficient method for calculating optimal free-space
n-impulse trajectories, AIAA Journal 6 (11) (1968) 2160e2165.
[23] B. Fornberg, A Practical Guide to Pseudospectral Methods (No. 1), Cambridge Uni￾versity Press, 1998.
[24] K.C. Howell, H.J. Pernicka, Numerical determination of Lissajous trajectories in the
restricted three-body problem, Celestial Mechanics 41 (1) (1987) 107e124.
[25] O. Montenbruck, E. Gill, F. Lutze, Satellite orbits: models, methods, and applications,
Applied Mechanics Reviews 55 (2) (2002) B27eB28.
[26] K.T. Alfriend, S.R. Vadali, P. Gurfil, J.P. How, L. Breger, Spacecraft Formation
Flying: Dynamics, Control and Navigation, vol 2, Elsevier, 2009.
[27] K. Yamanaka, F. Ankersen, New state transition matrix for relative motion on an arbi￾trary elliptical orbit, Journal of Guidance, Control, and Dynamics 25 (1) (2002) 60e66.
[28] K. Yamada, M. Kimura, T. Shima, S. Yoshikawa, New state transition matrix for for￾mation flying in J2-perturbed elliptic orbits, Journal of Guidance, Control, and Dy￾namics 35 (2) (2012) 536e547.
[29] A.W. Koenig, T. Guffanti, S. D’Amico, New state transition matrices for relative mo￾tion of spacecraft formations in perturbed orbits, in: AIAA/AAS Astrodynamics
Specialist Conference, 2016, p. 5635.
Guidance 439[30] D.W. Gim, K.T. Alfriend, State transition matrix of relative motion for the perturbed
noncircular reference orbit, Journal of Guidance, Control, and Dynamics 26 (6) (2003)
956e971.
[31] C.D. Murray, S.F. Dermott, Solar System Dynamics, Cambridge University Press,
1999.
[32] T.V. Peters, R. Noomen, Linear cotangential transfers and safe orbits for elliptic orbit
rendezvous, Journal of Guidance, Control, and Dynamics 44 (4) (2020) 732e748.
[33] T.V. Peters, R. Noomen, P. Colmenarejo, Analytical solutions to two-impulse non￾drifting transfer problems for rendezvous in elliptical orbits, Journal of Guidance, Con￾trol, and Dynamics 37 (3) (2014) 775e788.
[34] M.J. Kim, M.S. Kim, S.Y. Shin, A general construction scheme for unit quaternion
curves with simple high order derivatives, in: Proceedings of the 22nd Annual Confer￾ence on Computer Graphics and Interactive Techniques, September 1995,
pp. 369e376.
[35] M. Kelly, An introduction to trajectory optimization: how to do your own direct
collocation, SIAM Review 59 (4) (2017) 849e904.
440 Thomas Peters et al.CHAPTER NINE
Navigation
Vincenzo Pesce1
, Pablo Hermosin2
, Aureliano Rivolta3
,
Shyam Bhaskaran4
, Stefano Silvestrini5
, Andrea Colagrossi5
1
Airbus D&S Advanced Studies, Toulouse, France
2
Deimos Space, Madrid, Spain
3
D-Orbit, Fino Mornasco, Italy
4
NASA Jet Propulsion Laboratory, Pasadena, CA, United States
5
Politecnico di Milano, Milan, Italy
What is navigation?
The next concept of the guidance, navigation, and control (GNC)
chain to be introduced is navigation. Going back to our person with a
plan on where to go and what to do, it is of primarily importance for the
success of the task to know and understand the current location. For human
beings, it is natural and relatively effortless to establish where they are. In
general, they can process sensorial information, like tactile and visual percep￾tion along with previous knowledge and experience, to correctly know their
location. For example, our memory and our capacity of virtual abstraction
allow us to establish how far from a wall we are with a certain degree of un￾certainty. Similarly, our vestibular system provides our brain with informa￾tion about our motion, allowing a person to discern the body orientation
and spatial position. In addition, we can consider the localization task of a
person in its environment, in various human ages. Before the establishment
of cartography, people would find aid in the surroundings to locate them￾selves (e.g., moss or Stella Polaris to identify the North). The discovery of
the compass and its use strongly improved human navigation ability since
the 11th century. Most recently, with the advent of global positioning sys￾tem (GPS) and modern smartphones, the localization task has become very
easy and extremely precise. These examples clarify and simplify the concept
of navigation, i.e., processing sensorial information together with experience
and knowledge of the environment to perform a localization task. This defi￾nition is valid also for spacecraft navigation. In fact, sensors and models of the
environment (i.e., dynamical models) are used to estimate the state, rota￾tional and/or translational, of the spacecraft. This process can either be
done on-board, commonly called autonomous navigation, or on-ground
Modern Spacecraft Guidance, Navigation, and Control
ISBN: 978-0-323-90916-7
https://doi.org/10.1016/B978-0-323-90916-7.00009-3
© 2023 Elsevier Inc.
All rights reserved. 441 jby a team of trained specialists. The availability of sensors, their accuracy, and
modeling are fundamental for a precise state estimation also for a spacecraft.
Another important role is played by the knowledge of the environment and
the capacity of describing the spacecraft motion with equations. In fact, the
accuracy of a dynamical model actively influences the navigation perfor￾mance. It is important to underline that both sensors and dynamical models
are giving uncertain and stochastic inputs. The goal of the navigation is to
process and combine in a clever way this information in order to find a pre￾cise and accurate, but still uncertain, spacecraft’s state estimation. Navigation
has to provide the spacecraft’s state information to the control functions for a
comparison with the guidance output. Clearly, if the state is not correctly
estimated by the navigation algorithms, this error immediately leads to a
wrong control action on the spacecraft and, therefore, to a large discrepancy
with respect to the initial plan. With these notions in mind, we have the ba￾sics to start exploring the technicalities of navigation algorithms and
functions.
This chapter is composed by the following sections:
• Sequential and parameters estimation filtering techniques. In this section, the
working principle and derivation of the main sequential filters for space
application are detailed. Linear and nonlinear estimation techniques are
introduced for standard state estimation. Moreover, these formulations
are extended to the special case of parameters estimation.
• Batch estimation filtering techniques. This section starts with an explanation
of the least squares filter, followed by the inclusion of dynamic effects and
observation errors and, finally, the concepts of data fusion with a priori
information, which constitute the base for the different filters that will
be explained afterward. A detailed section on the typical problems that
can arise during trajectory reconstruction is also included.
• Absolute orbit navigation. This section has the purpose of introducing the
basics of global navigation satellite system (GNSS) and its observables
and how to use them to perform absolute spacecraft navigation. Further￾more, it introduces absolute navigation exploiting pulsars line-of-sight
(LOS) measurements, particularly useful for interplanetary scenarios.
Finally, the most important techniques and instruments to perform
ground-based orbit determination (OD) are introduced.
• Absolute attitude navigation. Common attitude estimation techniques are
presented and detailed in this section.
442 Vincenzo Pesce et al.• Relative navigation. This section discusses the basic principle of relative
navigation offering an overview of the possible approaches that can be
adopted while designing a navigation filter for this kind of application.
• Image processing techniques. The most important algorithms to perform im￾age processing useful to spacecraft navigation are detailed in this section.
Segmentation techniques, 2D, 3D, and multiview methods are intro￾duced with a description on how and when to use this kind of measure￾ments in a navigation filter.
• Navigation budgets. In this section, the influence of the navigation on the
overall GNC chain is described and the estimation accuracy can affect the
other GNC components.
• Navigation implementation best practice. A series of best practice tips and
checks is collected in this section, giving a more practical perspective
on the implementation of navigation algorithms.
On-board versus ground-based navigation
Spacecraft navigation involves several different elements (e.g., sensors,
actuators, dynamical model, measurement model, filter), but the navigation
filter is undoubtedly its core. In an ideal world, the state of a certain quantity
could be known exactly by relying on perfect dynamical model or extraor￾dinarily precise sensors. In real world, the same state is described by approx￾imate models and the available sensors produce measurements with not
negligible errors. Our only option is to combine, in the best possible way,
these uncertain quantities. In statistic and dynamical system theory, a filter
combines a set of uncertain measurements and a prediction of the dynamical
evolution of the spacecraft (according to an uncertain dynamical model) to
obtain the best possible estimate of the spacecraft’s state vector. Two main
approaches are usually adopted when dealing with spacecraft navigation:
• Sequential filtering. The state vector is sequentially updated at each time
step given a single-step measurement and the state predicted by the
dynamical model. Sequential filters are usually adopted for on-board
spacecraft navigation.
• Batch filtering. The state vector is updated taking into account a set of
measurements collected during a given time window. This approach is
commonly used for on-ground spacecraft navigation.
The difference between sequential and batch filtering is not the only
distinctive factor between on-board and on-ground spacecraft navigation.
Navigation 443In general, the following aspects can be considered as differentiating charac￾teristics between the two approaches:
• Precision. On-ground navigation techniques are usually more accurate
since more precise dynamical and measurement models are available. In
fact, the computational power is not constrained by stringent hardware
limitations typical of space missions. As defined above, typically on￾ground solutions are associated to batch filters that are intended to
reconstruct a complete spacecraft state during a trajectory arc. The
reconstruction of the trajectory usually involves a huge amount of data
coming from different sensors that are merged to obtain the navigation
solution. The fact that large amount of data can be employed leads to
higher accuracy in the solution. In contrast, on-board navigation is
constrained by the data that can be processed in real time by the on￾board system. Therefore, the solution associated with on-board
filtering techniques is usually less accurate than the reconstructed tra￾jectory on-ground.
• Communication delays. The delay in the communication with a spacecraft
is also a key factor when deciding if the navigation solution can be ob￾tained on-board or if it is better to rely on on-ground estimations to
update the spacecraft state. For instance, during interplanetary legs of a
mission to an outer planet, relying on on-ground OD solutions is not a
problem since the navigation solution is needed at a very low frequency
and large delays in communication are not critical. On the other hand, in
a mission involving close proximity operations around an asteroid such as
landing, low altitude flyby, or sample recollection, it may be more
interesting to opt for a navigation solution calculated on-board, since the
delay in communications would be unacceptable for such a critical phase.
In these situations, having the navigation calculated on-ground would
not allow for the fast response required from the environment: the re￾action time when performing an avoidance maneuver during a landing
phase might be in the order of seconds whereas the delay in commu￾nications with Earth would be, best-case scenario, in the order of mi￾nutes in deep space missions.
• Cost. Ground operations and, therefore, on-ground navigation have a
cost which is nonnegligible in a space mission. On the other hand, on￾board navigation usually implies costs related to the technological
development of a dedicated navigation solution in terms of additional
hardware and algorithms.
444 Vincenzo Pesce et al.• Spacecraft hardware complexity. On-board navigation usually relies on
additional sensors that have to guarantee the sufficient accuracy to
perform navigation. As an example, we can mention cameras for
approaching a small body [1]. The presence of additional sensors increases
the hardware complexity of the spacecraft and directly influences the
spacecraft design at system level.
When deciding between on-board or on-ground OD, there is not an ab￾solute answer and a trade-off, taking into account all the presented relevant
factors, needs to be carried out.
Sequential filters
Sequential filters belong to a category of estimators that provide a state
vector estimate, using measurements available at a specific instant of time.
Sequential filters are typically used for on-board spacecraft navigation, espe￾cially when dealing with relative scenarios, e.g., formation flying (FF),
rendezvous, and landing. Due to the limited computational power available
on-board, a single set of measurements, corresponding to the last available
time step, is processed instead of a “batch” of consecutive measurements.
Given an initial state vector, the knowledge of its dynamical evolution is
used to predict the state vector at a next step. This predicted state is then
updated given the measurements collected at the current time step. The
measurements predicted through the measurement model (also called obser￾vation model) are compared to the actual measurements to produce the filter
estimate. The best estimate is finally fed as input for the propagation at the
following step, and the process can sequentially continue. Fig. 9.1 shows the
high-level schematic of a generic sequential estimator.
Figure 9.1 Sequential filterdhigh-level schematic.
Navigation 445This chapter starts with a conceptual explanation of the working princi￾ple of sequential filters, followed by a theoretical discussion on the most
common sequential estimators.
Working principle
Before presenting the mathematical formulation of the most common
sequential filters, a practical discussion on the filtering steps is deemed neces￾sary. The working principle of sequential filters can be explained by consid￾ering a simple example. Let’s take a spacecraft orbiting a distant exoplanet.
The spacecraft has to determine its 2D position x ¼ ½X; Y (for sake of
simplicity), using noisy measurements and relying on an uncertain descrip￾tion of its orbital motion. It is important to clarify that the information on
the exact position of the spacecraft is not available; therefore, its state can
be described only using a probability distribution function (e.g., a Gaussian
distribution) with mean m, being its best estimate, and variance s, represent￾ing its uncertainty, as shown in Fig. 9.2.
The filtering process is composed by two main steps:
• Prediction step. Using the best knowledge of the exoplanet environment,
it is possible to propagate the best state estimate (distribution mean) and
the state uncertainty (distribution covariance - please note that while
variance is a statistical quantity referring to a single variable, covariance
provides information on how two variables are related to one another)
using a dynamical model f ðxÞ. It is important, while propagating the state
uncertainty, to consider how the unmodeled effects can affect this
Figure 9.2 Sequential filterdprediction step.
446 Vincenzo Pesce et al.propagation. This is done by adding to the propagated covariance the so
called “process noise” Q. This step is graphically depicted in Fig. 9.2. Af￾ter this step, a new predicted state is available with its associated covari￾ance that is usually larger than the initial one due to the unmodeled
dynamical effects.
• Update step. Once the predicted state is available, it is possible to compute
the expected measurement value. In this simple example, the predicted
measurement is directly the predicted position, but, in general, the ex￾pected measurements have to be obtained by relying on a measurement
model, hðxÞ. The measurement model (or sensor model) is a function
that provides the expected sensor output given a certain state. The ex￾pected (or predicted) measurements and the actual sensor readings, y,
along with their uncertainties, are then merged, given the propagated
state, to find the best estimate of the state. The way two probability dis￾tributions are combined is by multiplying them together, obtaining the
overlapping region of the two probability distributions as in Fig. 9.3.
The result of this final step is another probability distribution that is a lot
more precise than either of the two previous estimates. The mean of this dis￾tribution is the most likely estimate and, therefore, the best guess of the
spacecraft state.
Sequential filters for spacecraft navigation
The previous description of the working principle of a sequential estimator is
general, but several specific algorithmic solutions exist to perform the predic￾tion and update steps of a sequential estimator. In this section, the most com￾mon sequential estimators used for spacecraft navigation are described.
Figure 9.3 Sequential filterdupdate step.
Navigation 447Kalman filter
The most widely used and known filtering technique is certainly the Kalman
filter (KF) [2,3]. It takes its name from Rudolf E. Kalman, a pioneer of mod￾ern estimation theory, and it has been extensively used in space applications,
including the navigation filter of the Apollo project. The main assumption
behind the KF is that both state evolution and measurements can be
described using linear models. This is usually not the case for real-life appli￾cations, but a linear approximation may be sufficient to reach the required
estimation accuracy. In this paragraph, the standard form of discrete-time
KF is presented.
Let’s consider a linear discrete-time system:
xk ¼ Fk1xk1 þ Gk1uk1 þ wk1
yk ¼ Hkxk þ vk
In the above equation, xk is state vector, representing the variables that
have to be estimated, uk is the control input applied to the system, and yk
is the sensors’ output. The quantities wk and vk represent the process and
measurement noises, with associated covariance matrices Qk and Rk.
They describe the uncertainty related to the adopted dynamical and mea￾surement models. Finally, Fk, Gk, and Hk are the state-transition, the
model-input, and the measurement model matrices. Given the estimate of
the state at the previous step bxk1, the best estimate at the current step is ob￾tained by first propagating the state using the dynamical model:
bx
k ¼ Fk1bxþ
k1 þ Gk1uk1:
This is the state prediction step of the KF. Please note that bxþ represents
the a-posteriori best estimate: the expected value of xt; conditioned on all
the measurements up to time t. Instead, bx is the a priori estimate: the ex￾pected value of xt conditioned on all the measurements up to time t 1. Us￾ing classical probability theory [4], the covariance of a linear discrete-time
system can be propagated as:
P
k ¼ Fk1Pþ
k1FT
k1 þ Qk1:
This is the covariance prediction step of the KF. Recalling the concepts
introduced before, the prediction step provides a probability distribution
of a predicted state, taking into account the dynamical model uncertainties
and all the unmodeled effects represented by the matrix Qk1.
448 Vincenzo Pesce et al.The next step is to derive the update step, according to the available mea￾surements yk. Without entering into the theoretical details of the derivation,
the state and covariance update step can be expressed as:
bxþ
k ¼ bx
k þ Kk

yk  Hkbx
k

Pþ
k ¼ ðI  KkHkÞP
k1
with Kk being the KF gain matrix, derived as:
Kk ¼ P
k HT
k

HkP
k HT
k þ Rk
1
:
It is worth underlying that there is not any assumption on the Gaussian
nature of process and measurements noises, wk and vk. It results that the KF
is an optimal filter when the noise is Gaussian, zero-mean, uncorrelated, and
white [3], but it is still the best linear estimator if the Gaussian assumption
does not hold. To strengthen once more the working principle of KFs, a
graphical example of prediction and update steps of a one-dimensional state
distribution is represented in Fig. 9.4.
In the figure on the left side, the prediction step is depicted. bxþ
k1, the
estimate of the state at time k  1 and its corresponding covariance Pþ
k1
are propagated according to the dynamical model Fk1 and its uncertainty
Qk1. This step leads to a new predicted state bx
k with its associated covari￾ance P
k . The effects of the dynamical uncertainties Qk1 are highlighted by
drawing the covariance with and without this term. As expected, the uncer￾tainties and all the unmodeled effects of the dynamical model spread the
curve and, therefore, increase the overall state uncertainty. In the right
figure, instead, the update step is represented. The predicted state bx
k and
its covariance P
k are combined with the measurements yk and the associated
Figure 9.4 Kalman filterd1D example of prediction (left) and update (right) steps.
Navigation 449uncertainty Rk to obtain the best state estimate bxþ
k and state covariance Pþ
k .
The state estimate covariance Pþ
k is the result of the combination of two
gaussian curves, namely the predicted covariance P
k and the measurement
covariance Rk.
HN filter
For linear systems with process and measurement noise represented by a
zero-mean Gaussian distribution, KF is the minimum variance estimator.
In other words, the KF represents the optimal estimator when the model
is linear and the noise Gaussian. However, to satisfy these assumptions and
to guarantee a good tuning of the filter, the mean of wk and vk and their
covariance Qk and Rk have to be known. Properly tuning these parameters
is usually a difficult task. This is especially true for real applications where the
model uncertainty is unknown and difficult to estimate. In the case of non￾Gaussian noise, nonlinear system or if the tuning is off nominal, a filter that
minimizes the worst-case estimation error rather than the variance of the
estimation error could outperform the KF. This kind of filter is called H￾N filter or also minimax filter. It minimizes the 1-norm of the estimation
error, and it does not make any assumption about the statistics of the process
and measurement noise [5]. The formulation of the H-N filter is very
similar to the one of the KF. In fact, the prediction step is performed in
the same way, but, instead, a slightly different expression of the Kalman
gain Kk is derived. In particular, Kk has to be chosen such that
jjTewjjN < 1
w, where Tew represents the difference between the predicted
and real state and w is a tuning parameter. The derived expression for Kk is:
Kk ¼ P
k

I  wP
k þ HT
k R1
k HkP
k
1
HT
k R1
k :
Please note that the performance of the H-N filter is more robust to
model and sensor uncertainties but usually worse with respect to KF if work￾ing in nominal condition. Moreover, it is sensitive to the selection of the
tuning parameter w. This kind of filter is the best option when dealing
with very uncertain systems and time-varying dynamics, offering a robust
alternative to KF.
Extended Kalman filter
KF and H-N filter are linear filters that can be used when the dynamics un￾derlying the investigated phenomenon is linear. However, linear systems are
only approximations of more complex nonlinear dynamics. When the
450 Vincenzo Pesce et al.behavior of a system cannot be described by a linear function, linear filters
are no longer adequate. In all these cases, nonlinear estimators, such as the
extended Kalman filter (EKF), shall be employed. A common approach
to nonlinear state estimation is to use a modified version of the standard
KF to cope with the nonlinearities in the dynamical equations. This is the
so-called EKF [6]. The idea behind the EKF is straightforward. In practice,
the nonlinear system is linearized around the current state estimate, and the
following state estimate is obtained from the linearized system. In this sec￾tion, the discrete-time EKF is presented. Let’s consider the nonlinear model:
xk ¼ fk1ðxk1; uk1; wk1Þ
yk ¼ hkðxk; vkÞ
with, as before, xk the state vector, uk the control input, wk and the vk
the process and measurement noises, with associated covariance matrices, Qk
and Rk, and yk the measurement output. fk and hk are the functions
describing the state dynamics and observation model. Performing local line￾arization around the state estimate, the following algorithm is obtained:
bx
k ¼ fk1

bxþ
k1; uk1; 0

P
k ¼ Fk1Pþ
k1FT
k1 þ Qk1
Kk ¼ P
k HT
k

HkP
k HT
k þ Rk
1
bxþ
k ¼ bx
k þ Kk

yk  h

bx
k ; 0

Pþ
k ¼ ðI  KkHkÞP
k1
where the state-transition matrix and observation covariance are derived as:
Fk1 ¼ vfk1
vx




x^þ
k1
Hk1 ¼ vhk1
vx




x^
k
:
Please note that the propagation of the state is still nonlinear and the line￾arized state-transition matrices Fk1 and Hk1 are exploited for covariance
propagation. The EKF is the standard approach for state estimation and nav￾igation filters. However, the main drawback of this kind of filter is that,
relying on linearization for state covariance and mean propagation, it is
Navigation 451usually difficult to tune. Nonlinearities may introduce bias in dynamical or
measurement equations by altering the noise distributions, yielding to sub￾optimal performance or divergence. This is especially true for highly
nonlinear systems.
Unscented Kalman filter
The main alternative to the EKF is the unscented Kalman filter (UKF) [7].
This filter avoids the local linearization used by the EKF, and it uses an un￾scented transformation to propagate the mean and covariance of the state.
Unscented transform better describes the result of a given nonlinear transfor￾mation applied to a probability distribution by performing a weighted sam￾pling to compute mean and covariance. In fact, an unscented transform does
not use the mean and covariance of a Gaussian distribution to perform a
nonlinear transformation, but it exploits a set of points extracted from a dis￾tribution with the same mean and covariance. In this way, the full nonlinear
function can be applied directly to this set of points, also called sigma points.
Therefore, each sigma point is propagated in a nonlinear fashion and a new
set of propagated points is obtained. This new set represents a new distribu￾tion, and, therefore, a new mean and covariance can be computed without
relying on local linearization and on linearized state-transition matrices. A
very simple 2D example is depicted in Fig. 9.6. Let’s consider a nonlinear
system with additive noise:
xk ¼ fk1ðxk1; uk1Þ þ wk1
yk ¼ hkðxkÞ þ vk
Figure 9.5 Sigma points distribution.
452 Vincenzo Pesce et al.The prediction step is performed by considering 2n sigma points, where
n is the dimension of the state vector. The sigma points exðiÞ are selected ac￾cording to:
bxðiÞ
k1 ¼ bxþ
k1 þ exðiÞ i ¼ 1; .; 2n
exðiÞ ¼  ffiffiffiffiffiffiffiffiffiffiffiffi
nPþ
k1
q 
T
i
i ¼ 1; .; n
exðnþiÞ ¼   ffiffiffiffiffiffiffiffiffiffiffiffi
nPþ
k1
q 
T
i
i ¼ 1; .; n
Please note that the sigma points are extracted considering two subsets as
in Fig. 9.5.
The set of sigma points is then propagated using the dynamical model:
bxðiÞ
k ¼ fk1

bxðiÞ
k1; uk1

:
Then, these 2n vectors can be combined to obtain the a priori state es￾timate and its covariance:
bx
k ¼ 1
2n
X
2n
i¼1
bxðiÞ
k
P
k ¼ 1
2n
X
2n
i¼1

bxðiÞ
k  bx
k
bxðiÞ
k  bx
k
T þ Qk1:
Figure 9.6 Unscented Transformd2D example of state and covariance propagation
and approximation.
Navigation 453In a similar way, the update step is performed. First, other 2n sigma points
are selected based on the a priori estimate:
bxðiÞ
k1 ¼ bx
k þ exðiÞ i ¼ 1;.; 2n
exðiÞ ¼  ffiffiffiffiffiffiffiffiffi
nP
k
p T
i i ¼ 1;.; n
exðnþiÞ ¼   ffiffiffiffiffiffiffiffiffi
nP
k
p T
i i ¼ 1; .; n
Note that for a faster algorithm, the sigma points obtained before can be
used for this step, but this will result in degraded performance. At this point,
the observation model is used to predict the measurements:
byðiÞ
k ¼ hk

bxðiÞ
k

:
Finally, the predicted measurement covariance and the cross covariance
can be computed:
Py ¼ 1
2n
X
2n
i¼1

byðiÞ
k  by
k
byðiÞ
k  by
k
T
þ Rk1
Pxy ¼ 1
2n
X
2n
i¼1

bxðiÞ
k  bx
k
byðiÞ
k  by
k
T :
This leads to the a posteriori state estimate:
bxþ
k ¼ bx
k þ Kkðyk  bykÞ
Pþ
k ¼ P
k  KkPyKT
k
Kk ¼ PxyP1
y :
The presented formulation is valid under the assumption of additive
noise. If this assumption is not valid, a different formulation has to be derived
[5]. The UKF presents some advantages with respect to the EKF and over￾come its intrinsic limitations. In fact, the computation of Jacobians is not
required in this case. However, computing the propagation of 2n sigma
points can be computationally demanding in case of complex system dy￾namics. Usually, UKF is preferred when the adopted dynamical model is
not very complex.
454 Vincenzo Pesce et al.Particle filter
Particle filters (PFs) represent an alternative to EKF and UKF. They were
first introduced in 1993 [8] with the name of bootstrap filter. The key
idea underlying the PF is to approximate the filtering density function as
a weighted set of samples, also called particles. Its representation is funda￾mentally different from the one used in the KF, where a specific functional
form of the density function is assumed, and the estimate is then represented
by the quantities (the mean and the covariance) parameterizing this density.
In the PF, the filtering density is represented as a set of random samples
approximately distributed according to this density. PF’s working principle
is similar to the one of the UKF, since it is based on the propagation of a set
of points via known nonlinear equations and, successively, on the combina￾tion of the results to estimate the state and state uncertainty. However, in the
PF, the points are chosen according to a stochastic sampling, whereas in the
UKF, the points are chosen deterministically. In fact, UKF relies on the un￾scented transform and on a deterministic choice of the sigma points. More￾over, in PF, the posterior distribution of the state is not assumed to be
Gaussian as done in a classical UKF where mean and covariance are
employed to describe the posterior Gaussian distribution. For these reasons,
PF usually relies on a much higher number of points if compared to the
UKF, resulting in a higher computational load. As before, a generic
nonlinear system can be described as:
xk ¼ fk1ðxk1; uk1; wk1Þ
yk ¼ hkðxk; vkÞ
For PF, the Bayesian approach to nonlinear state estimation is intro￾duced. The aim of this strategy is to compute or approximate the posterior
distribution of the state, given the observations. In particular, the Bayesian
recursive solution to compute the posterior distribution ðpðxkj y1:kÞÞ of
the state, given past observation, is expressed as:
Initialization: pðx0jYk1Þ ¼ pðx0Þ
Prediction: pðxkjYk1Þ ¼ Z
pðxkjxk1Þpðxk1jYk1Þdxk1
Correction: pðxkjYkÞ ¼ pðykjxkÞpðxkjYk1Þ
R
pðykjxk1ÞpðxkjYk1Þ
with Yk ¼ y1:k:
Navigation 455For a general case, there isn’t an explicit solution for this integral. How￾ever, for a linear system with Gaussian noises, the classical KF recursive form
provides the solution for the presented Bayesian problem. For a generic
nonlinear system, with non-Gaussian noises, it is necessary to rely on numer￾ical approximations. PFs offer a tool to approximately solve the recursion for
a generic system. In particular, M random points (particles) are generated at
the beginning of the estimation, based on the initial probability density func￾tion (pdf) of the state. In fact, it is reasonable to approximate the pdf as sum
of d and in particular:
pðxkjYkÞxbpðxkjYkÞ ¼ 1
M
X
M
i¼1
d

xk  xk;i

where xk;i are the particles extracted from the true conditional density.
Therefore, the recursive algorithm can be derived as follows:
Initialization: pðx0Þx 1
M
X
M
i¼1
d

xk  xk;i

Estimation : bpðxk1jYk1Þx 1
M
X
M
i¼1
d

xk1  xk1;i

Prediction: pðxkjYk1Þx 1
M
X
M
i¼1
d

xk  xk;i

Correction: pðxkjYkÞ ¼ X
M
i¼1
qi
d

xk  xk;i

where xk;i ¼ f

xk1;i; wk1;i

, wk1;iwpðwk1Þ and qi ¼ pðykjxk;iÞ
PM
i¼1
pðykjxk;iÞ
.
Note that the second set of points, xk;i is extracted from the already
defined grid and the particles are propagated according to the nonlinear dy￾namics of the system f . The term qi indicates the relative probability of each
particle, and it can be seen as a weight. The sum of all the weights is equal to
1. It is important to underline that, if resampling is not performed, the PF
would end to a set of independent simulations, each one with its own
weight or probability. Most likely, the so-called sample depletion would
occur. This means that, not having any feedback from the observation,
456 Vincenzo Pesce et al.the result would be to have all the weights tending to zero, except for one
almost equal to 1. The high value of the weight does not mean that the esti￾mated state is close to the real one but just that one sequence in the set of
particles is more likely that the others. Resampling introduces the feedback
from the observation and guarantees that the good state estimation does not
disappear. A scheme graphically summarizing the main steps of a PF is dis￾played in Fig. 9.7.
Like the UKF, the PF method does not rely on any local linearization
technique and do not have any constraint on the noise distribution. This
flexibility can be very useful in several applications in which the EKF
does not perform well (highly nonlinearities involved). However, all these
advantages have a cost. In fact, the bottleneck of the PF is its computational
load [9]. If we think at the EKF, only one function evaluation of f ðxk; wkÞ
and hðxk; vkÞ is required at each time step (note that if the Jacobian is not
analytically available, more than one evaluation of these functions is
needed). Per contra, M evaluations are needed with PF. This can become
very demanding in systems with highly nonlinear and complicated dynamics
Figure 9.7 Particle filterdscheme.
Navigation 457and sampling with a high number of particles. This is one of the reasons why
PF has never been practically implemented on any spacecraft. Summarizing,
the PF overcomes the intrinsic limitations of the EKF and UKF, but the
computational cost is much higher. In general, PF can be used when the
Gaussian approximation of the posterior distribution is not acceptable
(e.g., multimodal distributions) and when high computational power is
available.
Parameters estimation
Sequential filters are typically used to estimate the states of a dynamical sys￾tem. However, this kind of filters can be used also to estimate unknown pa￾rameters. This approach can be exploited for spacecraft navigation
techniques when uncertain spacecraft parameters need to be estimated.
State augmentation for parameter estimation
The approach to estimate unknown parameters is similar to the one that it
has already been presented for classical state estimation. However, the pa￾rameters to be estimated shall be included in the so-called augmented states.
Let’s consider the usual nonlinear model:
xk ¼ fk1ðxk1; uk1; wk1Þ
yk ¼ hkðxk; vkÞ:
A parameter vector p can be introduced in both state propagation and
measurement prediction step as follows:
xk ¼ fk1ðxk1; uk1; wk1; pÞ
yk ¼ hkðxk; vk; pÞ:
In order to be able to estimate the parameter vector p, the state vector has
to be augmented:
x0
¼
"
xk
pk
#
:
The augmented system model is now evolving according to the
following equations:
x0
k ¼ fk1

x0
k1; uk1; wk1

yk ¼ hk

x0
k; vk

:
458 Vincenzo Pesce et al.Please note that if the parameter is constant, its first derivative will be set
to 0 and this equation will describe its dynamical evolution according to
fk1. All the presented filtering methods can be applied to solve this estima￾tion problem, despite the augmentation of the state with the vector
parameter.
Bias estimator
A classical parameter estimation case is represented by bias estimation prob￾lem. Spacecraft navigation usually involves the use of biased measurements.
Bias is systematic error affecting a given measurement and in its simpler
forms can be a random constant or a random ramp. When dealing with a
bias modeled as a random constant, the estimation procedure is exactly
the one described before: add the bias as state vector, include it in the mea￾surement equation as an additional term to the considered measurement,
and propagate a constant parameter (i.e., first derivative to 0 - refer to
Chapter 14 - Applicative GNC Cases and Examples for further details).
Please keep in mind that, in order to converge, the initial state plus the
associated initial covariance should be of the same order of magnitude as
the expected bias (e.g., if a bias in the position measurement in the order
of 1m is expected and the initial parameter value is 0, the d of P0 should
be at least 1m). On the other hand, if the bias is a random ramp (this may
be the case of clock bias drift for GNSS signals), the dynamics has to be
modified. In particular, the rate of change of the parameters is, in this
case, a random constant, and, therefore, the second derivative of the param￾eter has to be set to 0. An example of bias estimation is shown in Chapter 14
- Applicative GNC Cases and Examples.
Use of consider statesdSchmidteKalman filter
In some cases, the inclusion of unknown parameters in the state vector may
not be a recommended practice. In fact, even if a sequential estimator ig￾nores the uncertainty that such parameters introduce, its covariance can
become overly optimistic. This is a known problem called filter smugness.
Unmodeled errors during the filtering procedure can have a big impact in
the filter performance and even lead to divergence of the solution. In space
navigation, there are several parameters (e.g., drag coefficients, SPR area,
sensor, and actuators biases), both in the dynamics and the measurements
models, which can be considered as constant (but unknown) in the OD
process.
Navigation 459One of the most common algorithmic solutions to this problem was pro￾posed by Schmidt [10]. Schmidt’s approach was to perform the update step
of a subset of state (solve-for states) while maintaining the covariance of all the
states, including the states not involved in the update step (consider states). In
this configuration, only the solve-for states are estimated. This kind of filter is
also known as reduced-order filter, and it has been developed to reduce the
computational effort of navigation filters estimating only a subset of the state.
Consider filtering is a very efficient way of evaluating the effect of the un￾certainty of some parameters in the estimation solution without having to
extend the state vector variable and, therefore, reducing considerably the
number of operations to be performed during the filtering process.
The general formulation considering a discrete linear system is derived in
this paragraph. Let’s consider a linear discrete-time system (without control
action for sake of simplicity):
xk ¼ Fk1xk1 þ wk1
yk ¼ Hkxk þ vk:
This linear system can be rewritten considering solve-for states xk and
consider state xk as:
"
xk
xk
#
¼
"
Fk1 0
0 Fk1
#" xk1
xk1
#
þ
"
wk1
wk1
#
yk ¼
h
Hk Hk
i
"
xk
xk
#
þ vk:
Note how, even if the consider state is not estimated, its effect is taken into
account in the equations by “polluting” the estimation of xk.
Similarly, the estimation error covariance Pk can be partitioned as
follows:
Pk ¼
"
Pk S
ST Pk
#
And the resulting Kalman gain for the solve-for states takes the expression:
Kk ¼

P
k HT
k þ S
k H
T
k
	
a1
k :
460 Vincenzo Pesce et al.where ak is defined as:
ak ¼ HkP
k HT
k þ HkS
k H
T
k þ Hk

S
k
THT
k þ HkP

k H
T
k þ Rk:
The SchmidteKalman filter formulations include a dynamical
propagation:
bx

k ¼ Fk1bx
þ
k1:
Similarly, for the covariance:
P
k ¼ Fk1Pþ
k1FT
k1 þ Qk1
P

k ¼ Fk1P
þ
k1F
T
k1 þ Qk1
S
k ¼ Fk1Sþ
k1F
T
k1:
The best estimate for the solve-for states is then obtained by performing
the state and covariance update step and it can be expressed as:
bx
þ
k ¼ bx

k þ Kk

yk  Hkbx

k

Pþ
k ¼ ðI  KkHkÞP
k1  KkHk

S
k
T
Sþ
k ¼ ðI  KkHkÞS
k  KkHkP

k
P
þ
k ¼ P

k :
Summarizing, SchmidteKalman filters can be used to avoid filter smug￾ness in presence of unknown parameters in the dynamical or observation
model. This is done by updating only a subset of state (solve-for states) while
maintaining the covariance of all the states, including the parameters that are
not estimated. In this way, the effect of the uncertainty of these parameters is
take into account during the estimation procedure without augmenting the
state vector, reducing the overall computational effort.
Batch estimation
In contrast to sequential filtering techniques presented in the previous
sections, batch filters cover a different set of filtering techniques that will be
explained in this chapter.
Batch filters are typically used when performing trajectory reconstruc￾tion, thus postflight analysis in which all the information and available
Navigation 461measurements are taken into account and fused, in order to properly deter￾mine the trajectory, a particular spacecraft (S/C) has followed during a given
period of time. This process is usually carried out on-ground since the
computational load is too high to be performed on-board.
Least squares
The least squares solution is the classical method used to find the best fit of a
given set of data points by minimizing the sum of the squares of the
computed residuals with respect to the estimated values. In space navigation,
the target is to minimize the measurement residuals, thus the differences be￾tween the real measurements coming into the navigation filter from the
different sensors in the S/C and the estimated values of those measurements
are generated using the internal models by navigation.
The estimated measurements are generally represented as:
y ¼ Hx þ v
where y is the measurement value(s), x is the vector of length n including
navigation variables (typically S/C position, velocity, mass, and any extra
variable/parameter included in the navigation process, as mentioned in the
section above), and H represents the measurement model: the different
equations that relate the navigation variables in x and combine them with
other known parameters to generate the estimated measurement. The
vector v refers to the observation error. Therefore, the idea behind the least
squares is to find the x that minimizes the following:
JðxÞ ¼ 1
2
v
T
v ¼ 1
2
Xm
i¼1
v
T
i vi ¼ 1
2
ðy  HxÞ
Tðy  HxÞ
with m being the number of measurements. In order to find the minima
for the quadratic function of x expressed above, two conditions must be ful￾filled, the first derivative must be equal to zero and the second derivative
needs to be positive:
dJ
dx
¼ 0
dxT d2J
dx2 dx ¼ dxTHTHdx > 0
for any dxs0.
462 Vincenzo Pesce et al.Solution of the first equation leads to Ref. [11]:

HTH
bx ¼ HT
y
Being HTH an nxn matrix, if it is full rank (rank n), it will be positive
definite and the best estimate for x is:
bx ¼ 
HTH1
HT
y ¼ H1
y
In case there are more equations (m) than variables (n), it means that H is
an mxn matrix and, therefore, HTH an mxm matrix. In this case, there are
infinite solutions for x, and the minimum norm solution can be selected:
bx ¼ 
HTH1
HT
y
where 
HTH1
HT is the so-called pseudoinverse of H.
Dynamic effects
During the estimation process in space environment, the dynamical effects
also need to be taken into account. In the formulation presented in the pre￾vious section, the least squares solution allows determining the best x estima￾tion at a given epoch in terms of minimizing the sum of the squares of the
residuals. However, the dynamics of the S/C in orbit cannot be neglected,
since typically the measurements are not always referred to the same epoch
but distributed along a trajectory arc. Therefore, each measurement yk is
related to a different value of the state vector at time k:
yk ¼ Hkxk þ vk
This means that, given m different measurements distributed along a tra￾jectory arc, each one referred to a different epoch, during the estimation
process, m different state vectors are defined, since the position and velocity
of the S/C evolve along time according to the dynamics of the orbit. There￾fore, it is required to express all the measurements related to the same point
of the orbit, so all of them referred to the same state vector. This allows using
the least squares formulation to estimate x at a particular point in the orbit,
which typically is the starting epoch of the considered trajectory arc. In order
to perform this step, the state transition matrix (STM) is employed.
The dynamics of a spacecraft in orbit around a given body, including
perturbation effects, follows nonlinear relationships:
x_ðtÞ ¼ AðtÞxðtÞ
Navigation 463with xðt0Þ ¼ x0. If a reference trajectory reasonably close to the true one
is available, it is possible to linearize the problem. The general solution of this
linearized system can be expressed via the STM:
xðtÞ ¼ Fðt; tiÞxðtiÞ
where Fðt; tiÞ is the STM relating the states at a given epoch ti with the
states at t. Since the value at t0 is available, every point can be related to this
one:
xðtÞ ¼ Fðt; t0Þxðt0Þ ¼ Fðt; t0Þx0
Being the STM:
Fðt; t0Þ ¼ vx
vx0
Therefore, the STM can be then used to link the observations to the
same epoch, t0, in order to apply the least squares algorithm and obtain
the estimation of the state vector at the beginning of the considered trajec￾tory arc:
yk ¼ Hkxk þ vkzk ¼ HkFðt; t0Þxðt0Þ þ vk
So, given a trajectory arc, the steps to perform the estimation of the state
vector are as follows:
• Calculation of the STMs between measurement epochs
• Generation of estimated measurement according to the measurement
models presented in the navigation algorithms
• Reference all the measurements to the initial epoch of the arc using the
STMs, so all of them are related to xðt0Þ
• Estimate the state vector at t0 using the least squares methods to obtain
bxðt0Þ
• Propagation of bxðt0Þ form t0 to the final time of the trajectory arc tf to
obtain the solution of the state vector (and other navigation variables)
along it.
This last propagation can be performed either using the STMs or a nu￾merical propagator. In strongly nonlinear environments, using the STM
could reduce the accuracy of the solution at the end of the arc.
Effect of observation errors
The least squares method presented up to now does not take into account
any observation errors or a priori information of the parameters to be esti￾mated. Up to this point, it has been assumed that all measurements have
the same level of uncertainty. However, in the most general case, some
464 Vincenzo Pesce et al.measurements will probably be more reliable than others. Therefore, the
observations with higher level of confidence should be given a higher
weight or preference during the estimation process to obtain the best
possible estimate with the available information. Typically, the confidence
level of the measurements is given by the observation error: lower observa￾tion errors imply higher confidence in measurements and vice versa.
Regarding the effect of the observation errors in the estimation, the problem
is stated as follows:
yk ¼ Hk$xk þ vk
E

vv
T
¼ R ¼
2
6
6
4
R11 / R1m
« 1 «
Rm1 / Rmm
3
7
7
5
Usually, the observation errors are not correlated, therefore Rij ¼ 0 for
isj, but this is not required in the formulation and in the general case it can
be assumed that Rijs0. Therefore, the cost function to be minimized is
then:
JðxÞ ¼ 1
2
v
T
v ¼ v
TR1
v
By computing the first derivate with respect to x and equaling it to zero
to obtain the best estimate of x:
bx ¼ 
HTR1H1
HTR1
y
It is clear for the previous equation that in order for this method to work,
the matrix R cannot be singular, so observations cannot be perfect. Luckily,
real-world observations have always some errors associated, so the user needs
to take care of relating a nonnull error to every measurement in the formu￾lation. The associated estimation error covariance is also affected by the
observation errors in the following way:
P ¼ E

ðbx  xÞðbx  xÞ
T 
¼ 
HTR1H1
In order to propagate the covariance matrix, by looking at the definition,
it can be seen that:
PðtÞ ¼ E

ðbxðtÞ  xÞðbxðtÞ  xÞ
T 
¼ E

Fðt; tiÞðxðtiÞ  xÞðxðtiÞ  xÞ
TFðt; tiÞ
T 
PðtÞ ¼ Fðt; tiÞPðtiÞFðt; tiÞ
T
Navigation 465Inclusion of a priori information data
If a priori information is present, new observations can be used to update it.
A simple graphical representation of this concept is shown in Fig. 9.8. This
allows improving the estimation in a recursive way without the need of
rerunning the algorithm from the beginning each time a new measurement
is available. In trajectory reconstruction, this can be implemented by
dividing the trajectory in arcs and using the solution of the previous arc as
a priori information. So, assuming an a priori estimate and associated estima￾tion error covariance is available:
bx0 ¼ EðxÞ
P0 ¼ E

ðx  bx0Þðx  bx0Þ
T 
The idea is to being able to update the estimation without the need of
computing again all the past observations from the previous step to redo
the calculations, just by adding a new batch of measurements taken since
the last solution was obtained:
yk ¼ Hkxk1 þ vk
bxk ¼ xk1 þ Kkðyk  Hkxk1Þ
So, the new estimation is obtained using the previous estimate and the
new measurements. The matrix Kk is the so-called estimator gain matrix
and ðyk Hkxk1Þ is the measurement residual used to correct the a priori
information with the observations of the new arc. The value of Kk is chosen
to minimize the sum of the variances of the estimation errors at k:
Jk ¼ E

ðx1  bx1Þ
2
þ E

ðx2  bx2Þ
2
þ / þ E

ðxn  bxnÞ
2
¼ TrðPkÞ
Figure 9.8 Inclusion of a priori information.
466 Vincenzo Pesce et al.By differentiating the previous equation and setting it to zero, the value
of Kk that minimizes Jk is obtained as:
Kk ¼ Pk1HT
k

HkPk1HT
k þ Rk
1
Next to the update of the state, the covariance of the estimation error can
also be updated recursively with the equation (to check the mathematical
formulation that leads to it, the reader is invited to check Ref. [5]):
Pk ¼ ðI þ KkHkÞPk1ðI þ KkHkÞ
T þ KkRkKT
k
where Rk is the covariance matrix of the observations as defined above.
Therefore, according to the above, starting form an a priori estimation and
its associated covariance, the new estimate can be obtained recursively by
computing first the Kk matrix and using it to correct the previous values of
bxk and Pk.
Problems in batch orbit determination
Different issues may arise during the estimation process. A hint of some of
these problems is presented in this section.
Presence of nonlinearities
The techniques presented up to this point refer to linear systems. However,
real systems are nonlinear by nature, linear systems do not really exist.
Therefore, even if these techniques can still be applied to real systems,
they are limited by how much the studied system can be approximated by
a linear one. If a particular system is close enough to linear, linear estimation
techniques will approach well and the estimation results will be valid.
If the effect of nonlinearities is nonnegligible, extra errors can be injected
into the process due to the use of the STM to propagate the covariance ma￾trix, the state, and also to refer the different measurements at different times
to the same epoch. In order to overcome and/or mitigate these effects, a nu￾merical propagator can be used to propagate the states after the update
instead of using the STM. In this way, the nonlinearities of the dynamics
will be maintained by the propagator if the STM is not able to do so.
However, for the situations in which the use of the STM is mandatory,
like the propagation of the covariance or referring the measurements to the
same epoch, the alternative could be reducing the length of the arc to which
the batch is applied, in order to reduce the effect of the nonlinearities that
cannot be captured by the STM.
Navigation 467Incorrect a priori statistics and unmodeled parameters
The use of incorrect a priori statistics to initialize the filter leads to conver￾gence problems in some cases since the uncertainty level of the initial esti￾mate does not correspond to reality. This means that, if the associated
covariance of the estimation error shows that the confidence level of the so￾lution is high, but, in reality, the estimate is much further from the real so￾lution, the filtering process will tend to trust the a priori solution more than
it should. This can reach a point in which good observables are discarded
since the filter assumes that its current solution has a confidence level higher
than the one of the new measurements. This level of confidence of the a
priori solution of the estimate is hard to know since the “real world” is
not known (that is why navigation filters are needed). Therefore, a detailed
analysis is required to assess the level of error of the a priori solution.
Apart from this, the effect of unmodeled parameters also has a big impact
in the convergence of the filtering process. If the estimated world modeled
by navigation does not take into account a major contributor in the evolu￾tion of the spacecraft dynamics, the filter will not be able to accurately track
the dynamics internally, and there will be a discrepancy between the evolu￾tion of the real position and the estimated one.
It is important to mention here that the fact of ignoring the effect of a
parameter has more impact than knowing it exist and associate a high uncer￾tainty to it. For example, knowing that a parameter has an effect on the dy￾namics (e.g., solar radiation pressure - SRP) but, if due to the available data,
it is not possible to model it correctly, can be mitigated by associating a
higher uncertainty to it. This would result in higher uncertainty in the esti￾mate solution, but it will not likely lead to a divergence in the filtering pro￾cess. However, ignoring the fact that SRP is present in the dynamics would
make the filter to trust too much its internal propagation, since the associated
uncertainty would be very low. In this latter case, the filter would converge
to a wrong solution, but without knowing it is wrong, which could lead to
divergence in the navigation.
Numerical problems
Due to the finite precision of computers, numerical problems may arise dur￾ing the filtering process, especially related to the covariance properties.
Computational errors can lead to the loss of symmetry of the covariance ma￾trix or its positive definite nature. This kind of errors could produce the
divergence of the filtering process.
468 Vincenzo Pesce et al.In order to prevent and mitigate the limited precision of the calculations,
alternative filtering algorithms can be used. These are related to different
ways of decomposing and factorizing the covariance matrix, helping toward
the robustness of the algorithm by keeping the characteristics of the covari￾ance matrix throughout the whole filtering process.
Square root information filter
Square root filters present improved numerical precision and stability, which
are very useful for bad-conditioned problems. The idea behind square root
filters is to replace the covariance matrix and use its square root instead dur￾ing the recursive process of OD. In this way, the algorithm will assure the
positive semidefiniteness of the error covariance. So instead of Pk, the up￾date and propagation steps explained above will be performed over the ma￾trix Sk:
Pk ¼ ffiffiffiffiffi
Pk
p ffiffiffiffiffi
Pk
p T ¼ SkST
k
Since the covariance square root is not uniquely defined, the common
practice is to use a specific formulation of Sk that is attractive for the algo￾rithm implementation, such as upper or lower triangular matrices. This re￾duces the amount of computation and storage when implementing the
algorithm.
If the square root decomposition is applied to the inverse of the covari￾ance matrix, the information matrix, the resulting algorithm is the so-called
Square Root Information Filter (SRIF), widely used in orbit reconstruction
procedures due to its numerical precision and stability:
P1
k ¼ ST
k S1
k
The algorithms for the SRIF exploit the properties of orthogonal trans￾formations to perform the update and the propagation of the state and square
root information matrix. The filter mechanization works with z and S, with
z related to x as detailed below:
x ¼ S1
z
The update step of the filtering process with additional observation(s) is
performed by applying a series of orthogonal transformations T (for more
details on the orthogonal transformations, the reader is invited to check
[11,12]):
Navigation 469T
"
Sk zk
Hk yk
#
¼
"
Sbk bzk
0 ek
#
With ek the observation residual,^representing the updated variables and:
Sbkbxk ¼ bzk
Pk ¼ Sb1
k SbT
k
Then the propagation step is performed by making use of the STM:
Sk ¼ SjF1
tk; tj

zk ¼ SkF1
tk; tj

bxj
U-D filter
In alternative to the SRIF formulation, the U-D covariance factorization ex￾presses the covariance matrix as:
Pk ¼ UkDkUT
k
with Uk an upper triangular matrix and Dk a diagonal one. The U-D fil￾ter shares the properties of the SRIF filter in terms of numerical stability and
accuracy and the fact that assures the positiveness of the covariance. On top
of that, since no square root operations are necessary, it is computationally
more efficient although this affirmation strictly depends on the number of
state variables and measurements: when the number of measurements is
very large, the difference in performance is considerably reduced.
Please note that the derivation of the UD algorithms can be done by
including the definition of Pk as upper triangular and diagonal matrices
into the least squares equations and making use of the characteristics of these
matrices. For a complete derivation, the reader is suggested to check [13].
Absolute orbit navigation
Absolute orbit navigation functions estimate the translational orbital
states of the spacecraft, in order to know the current spacecraft position
and velocity, and possibly propagate the future states by exploiting the
orbital dynamics laws.
470 Vincenzo Pesce et al.GNSS spacecraft navigation
Absolute orbit navigation often exploits the GNSS constellations to estimate
the orbital state of the spacecraft. The main concepts of GNSS sensors and
their measurements are introduced in Chapter 6 - Sensors. GNSS refers to a
constellation of satellites around the Earth providing signals and, therefore,
position and velocity information to a “user” receiving them. In this section,
GNSS observables and how to use them inside a navigation filter are
detailed.
GNSS observables
The GNSS observables are the pseudorange, the carrier phase, and the
Doppler measurements, and they are detailed in the following sections.
Pseudorange
The pseudorange represents the distance between the GNSS satellite at the
time of the emission of the signal and the receiver antenna measured at the
time of reception. Assuming no errors, the pseudorange er would be equal to
the geometric distance:
er ¼ cðtR  tT Þ ¼ rðtR; tT Þ
Being c the speed of light, tR the time, f the clock receiver, and tT the
time of the transmitter clock. However, in practice, the pseudorange is
not equal to the geometrical distance due to different factors, such as the er￾rors in the clocks, the effect of the atmosphere, Earth tides, multipath effects,
and relativistic effects. Therefore, the real pseudorange observable is given
by the expression:
er ¼ rðtR; tT Þ  cðdtR  dtT Þ þ diono þ dtropo þ dtide þ dpath þ drel þ ε
where dt represents the clock errors, diono and dtropo the effect of the iono￾sphere and troposphere in the signal transmission, dtide the errors associated
to the Earth tides, dpath the multipath effects, and drel the relativistic effects.
The other nonmodeled errors are represented by ε. All the effects in the
previous equation are briefly explained in a dedicated section below.
Carrier phase
The carrier phase measures the phase of the received satellite signal with
respect to the carrier phase generated in the receiver at the reception
time. It represents a measurement of the distance between emitter and re￾ceptor given in cycle units of the carrier frequency. So, the observable is
Navigation 471obtained by shifting the generated signal carrier phase to match it with the
received carrier phase from the satellite. Carrier phase measurements are
generally much more precise than pseudorange measurements, since it can
be tracked with a precision in the order of the millimeters. However, there
are two key points that must be taken into account:
• Phase ambiguity. Adding an arbitrary constant integer number of cycles to
the transmitted carrier signal would result in the same measured phase.
Different methods based on conditional adjustment theory have been
developed in the last decades to solve the phase ambiguity problem.
For a detail description of such methods, the reader is invited to check
Chapter 8 of Ref. [14].
• Cycle slip. Phase must be tracked continuously since a gap in the tracking
of the phase over time would change the value of the phase ambiguity.
Assuming no errors and vacuum medium for the transmission, the
measured phase F follows the expression:
F ¼ FRðtRÞ  FT ðtRÞ þ NT
R
where FR is the phase of the receiver, FT is the phase of the received
signal from the satellite, and NT
R is the ambiguity between satellite and
receiver. Taking into account the relationship between the speed of light
c, wavelength l, and frequency f : c ¼ lf ; and accounting for all the errors
as in the pseudorange case, the carrier phase measurement model is as
follows:
lF ¼ rðtR; tT Þ  cðdtR  dtT Þ þ lNT
R  diono þ dtropo þ dtide
þ dpath þ drel þ ε
The negative sign of the ionosphere effect is due to the fact that the
ionosphere advances the phase signal transmission, whereas, in case of
the pseudorange signal, the ionospheric effect delays it (so the sign in the
pseudorange equation above is positive). For a more detailed explanation on
the ionospheric effects in pseudorange and phase measurements, the reader is
invited to check Ref. [14].
Doppler measurements
Doppler measurements are based on the physical phenomenon that shifts the
frequency of a signal due to the fact that the emitter moves toward or away
from the receiver. The Doppler shift can be used as an independent observ￾able to provide direct observation of the instantaneous range rate in the
472 Vincenzo Pesce et al.direction defined by the vector emitterereceptor. Since the original fre￾quency of the emitter is replicated in the GNSS receiver, the shift between
this last one and the real received signal can be measured. Of course, the er￾rors in clocks need to be accounted for in the measurement equation, as
expressed below.
The observable model of the Doppler shift is given by Ref. [14]:
D ¼ drðtR; tT Þ
ldt  f
dðdtR  dtT Þ
dt þ df þ ε
where df is the frequency correction due to relativistic effects. The atmo￾sphere effects have no contribution to errors in the case of Doppler
measurements.
Error effects
In this section, a brief summary of the errors inducted in the pseudorange,
phase, and Doppler equations defined before is presented.
Ionospheric effects
As mentioned before, the ionosphere affects differently the pseudorange and
the phase measurements. Whereas the pseudorange is delayed by the free
electrons in the ionosphere, the phase is advanced. This different behavior
is modeled by using different signs when including the ionosphere in the
pseudorange and phase equations, respectively.
The effect of the ionosphere is not constant in time, and its magnitude
also depends on the frequency of the signals. It can be measured by the
following expression [15]:
diono ¼ 40:3
cf 2 $TEC
where TEC is the Total Electron Content in the zenith direction.
The ionospheric delay (or advance) effect can be eliminated by
combining the GNSS phase measurements.
Tropospheric effects
The tropospheric effect, in opposition to the ionospheric one, does not
depend on the frequency of the signals. The troposphere has a refraction ef￾fect on the signals which is dependent on the elevation: the lower the eleva￾tion, the bigger the path the signal needs to go through the troposphere and,
therefore, the higher the effect.
Navigation 473The tropospheric effect has two components, the dry and the wet
contributions. The dry effect is the one that contributes the most, about
80%e90% approximately; whereas the wet one related to the amount of
water in the atmosphere accounts for the rest of tropospheric refraction.
Relativistic effects
Effects due to Einstein’s General and Special Relativity theories need to be
taken into account in the GNSS measurement equations due to the different
velocities between the receiver and the emitter clock as well as the effect of
gravity, since clocks on Earth surface are closer to a massive body than the
ones on orbit around it. Furthermore, the eccentricity of the orbits as well
as the Earth rotation have a nonnegligible effect on the GNSS observables.
Due to these effects, there is a mismatch between clocks in the order of
several tens of microseconds which, translated to distances using the speed of
light, implies that not correcting for relativity effects could add errors in posi￾tioning in the order of tens of km.
Earth tidal effects
These effects are consequence of the Earth deformation due to the gravity
forces from the Sun and the Moon, and the effect of the ocean tide loads
on the Earth surface. This deformation implies some displacements of the
Earth surface that, in case GPSs, can be different among the different regions
due to the variations in the Earth structure. For regional systems, as the ones
mentioned in the beginning of this chapter, these effects could be neglected
since the differences in displacements are not that important.
Multipath effects
Multipath effects are more related to the local environment of the receiver
antenna since, due to the local geometry, it can be possible that the signal is
received via different paths due to reflections. In order to mitigate the inter￾ferences associated to this effect, the design of the antennas to take into ac￾count side lobes geometry is important.
A nice overview of all the possible errors to be taken into account in the
measurement model formulation or to be compensated while performing
position estimation and their magnitude is collected in Ref. [16] and sum￾marized here in Table 9.1.
474 Vincenzo Pesce et al.GNSS navigation approaches
GNSS is widely adopted and well-established for terrestrial and airborne
navigation. In this paragraph, instead, we will focus on how to apply the
same concepts to spacecraft navigation. The main difference between
Earth-based applications and spacecraft navigation is that, in general, the
motion of a spacecraft can be predicted with good accuracy, while, on Earth,
the motion of a generic GNSS user is often nondeterministic and prone to
quick changes. For this reason, while pure kinematics approaches are used
for Earth-based positioning algorithms (precise point positioning [PPP]),
dynamical approaches are suggested while dealing with spacecraft. In fact,
the knowledge of the dynamical system allows to reduce the overall number
of estimation parameters and to propagate the spacecraft trajectory also when
limited or no GNSS signals are available. Three main approaches are adop￾ted and discussed here:
• Precise orbit determination (POD). Ground-based method used to estimate
the spacecraft position with the highest possible accuracy.
• Real-time navigation. The spacecraft position is estimated using real-time
measurements on-board.
• Relative GNSS navigation. Two or more spacecraft in close proximity are
considered and their GNSS measurements are fused together to improve
Table 9.1 Typical GNSS errors and uncertainty.
Error Magnitude Uncertainty
Satellite Center of mass position e 2.5 cm
Antenna phase center
offset
0.5e3 m 10 cm
Phase center variations 5e15 mm 0.2e1 mm
Clock offset <1 ms 2 cm
Relativistic clock effects 10e20 m
Differential code biases <15 ns 0.1e1 ns
Atmosphere Troposphere 2.3 m 5 mm
Ionosphere <30 m <1 m
Dynamics Solid earth tide <0.4 m 1 mm
Ocean tides 1e10 cm 1e2 mm
Pole tide 25 mm e
Atmospheric drag <1.5 mm e
Receiver Phase center offset 5e15 cm e
Phase center variations <3 cm 1e2 mm
Others Phase wind-up 10 cm e
Navigation 475relative navigation accuracy. This process can be performed on-ground
or on-board in real-time.
The details of each approach are discussed in the following paragraph,
but a first distinction can be done in terms of achievable performance.
Fig. 9.9 shows the achievable accuracy for each of the GNSS navigation
approaches.
From Fig. 9.9, the advantage of having an on-ground processing is
evident as well as the fact that differential GNSS processing offers a high￾accuracy solution. In this paragraph, an introduction to the most common
positioning method is presented, and then, the peculiarities of spacecraft
navigation are detailed.
Precise point positioning
PPP is one of the most common techniques for GNSS-based positioning.
This method, introduced in 1997 [17], uses dual-frequency, pseudorange,
and carrier-phase observations along with precise satellite orbit and clock
to produce a PPP. PPP does not require simultaneous observations and ex￾ploits precise carrier-phase observations in addition to the pseudoranges.
Most of the error sources listed in the previous paragraph are taken into ac￾count, i.e., carrier-phase ambiguities, tropospheric propagation delay, Earth
tides, ocean tides, satellite and receiver antenna offsets, and carrier-phase
windup. Furthermore, carrier-phase is subject to cycle slip that has to be
considered along with the previously mentioned effects, leading to slow
PPP convergence. For ground-based applications, PPP can provide accu￾racies in the order of few centimeters (1-sigma) [16]. This method is mostly
used for Earth-based application, and, therefore, it will not be detailed here.
Additional information and an accurate description can be found in
Ref. [16].
Figure 9.9 GNSS Navigation approaches and their accuracy.
476 Vincenzo Pesce et al.Precise orbit determination
POD is a powerful method that allows to localize a spacecraft with high ac￾curacy. Being a ground-based approach, it can exploit all the computational
capabilities and processing resources to provide highly precise estimations.
Nowadays, GNSS observations allow for OD of accuracy at maximum
1 cm 3D root-mean-square error (RMSE) for position [16]. The working
principle of POD technique is similar to the one used for PPP but
combining it with sophisticated spacecraft dynamics models. Also in this
case, all the errors listed before must be considered and estimated. This in￾cludes, among others, relativistic clock and range corrections, phase center
offsets and variations of the GNSS satellite and of the receiving antenna,
phase delays and phase wind-up effects. It must be noted that the spacecraft
dynamics describes the motion of the center of mass of the spacecraft while
all the GNSS signals are referred to the antenna reference point. For this
reason, the relative position between the GNSS antenna and the center of
mass should be known with extreme accuracy. This is not always an easy
task and internal perturbations (see Chapter 3 - The Space Environment)
should be modeled accurately. Furthermore, another important aspect is
the time-tagging and synchronization of the measurements. Given the
high velocities of a satellite orbiting the Earth, receiver and GNSS system
time should be known with a high degree of precision. The most common
approach to provide a POD solution is to use a batch method. Usually, a
weighted least square estimator is employed to estimate all the dynamical pa￾rameters of the spacecraft (e.g., SRP area, drag coefficient, empirical accel￾erations) and GNSS observation model parameters (e.g., clock corrections,
carrier phase ambiguities). Recalling the classical least square estimator
formula:
JðxÞ ¼ 1
2
v
T
v ¼ 1
2
Xm
i¼1
v
T
i vi ¼ 1
2
ðy  HxÞ
Tðy  HxÞ
In this case, y are the GNSS observables, H a complex measurement
model, and x vector including all the navigation parameters. While
designing x, spacecraft and GNSS parameters should be considered. Usually,
the following formulation is used:
x ¼ ½T; D;B
with T ¼ ½cdt1;.; cdtn
T , vector containing the receiver clock offset pa￾rameters for n measurements, D ¼ 
r0; v0; CD; CR;aemp1;.;aempn
T ,
Navigation 477vector containing the initial position and velocity of the spacecraft, drag and
SRP coefficients and empirical accelerations accounting for unmodeled
effects, B ¼ ½b1;.;bn
T vector containing the carrier-phase ambiguities for
n measurement instants. The number of variables and parameters included in
x is an indicator of the high complexity of the measurement model in H.
Not having computational constraints, very long measurement vectors can
be considered (one or more days) increasing the final estimation accuracy.
Real-time navigation
GNSS signals can be used also to enhance the autonomous navigation capa￾bilities of a spacecraft. In fact, they can be employed as additional measure￾ments to perform on-board spacecraft navigation, combined with a
sequential filter. The working principle is very simple, and it is based on a
classical sequential filter approach. In fact, a dynamical model is used to
propagate the spacecraft state, and GNSS measurements are used to update
the predicted spacecraft state. Usually, the dynamical model used on-board is
much simpler than the one employed for POD, being the computational re￾sources limited by the spacecraft avionics. A classical nonlinear EKF is often
implemented to perform real-time navigation. Similar to POD solution,
additional dynamical and clock biases can be added to the state vector and
estimated inside the filter as parameters. For this reason, a SchmidteEKF
can be designed to deal with state and parameters estimation. Furthermore,
an empirical acceleration term can be added to the classical gravitational (and
nongravitational) accelerations to account for nonmodeled dynamical ef￾fects. The dynamical evolution of this term is not treated as a constant
parameter, but it is usually modeled as exponentially correlated random
variable:
aemp k ¼ e
t
kt
k1
s aemp k1
with s being a “damping” tunable term.
For what concerns the observation model, two main approaches are usu￾ally employed:
• GNSS-processed measurements. The GNSS receiver processes the raw
GNSS measurements providing position information to the KF. In this
way, the measurement equation is very simple, and the filter and
GNSS positioning algorithms are decoupled. No clock estimation is
needed, and no GNSS position knowledge is required. However, with
this approach, signal information is lost in the receiver kinematic
478 Vincenzo Pesce et al.estimation and the precision of the solution is limited (around 5 m 3D
RMSE for position - [16]). Furthermore, since the receiver kinematic
positioning algorithm requires at least four GNSS signals to produce a
valid measurement, real-time navigation is not possible when this con￾dition is not satisfied.
• GNSS raw measurements. The GNSS raw measurements are directly used
as measurements inside the KF. In this case, the observation model has to
include the classical light-time corrected geometric relative distance
formulation. Moreover, the GNSS satellite positions have to be known
(e.g., through broadcast ephemeris) along with their clock biases.
Ionospheric path delays should also be considered and corrected if
ionosphere-free combinations [18] are not implemented. When dealing
with carrier-phase measurements, it is important to estimate the ambi￾guities related to each GNSS satellite as additional parameters, highly
increasing the computational cost and algorithmic complexity. The
achievable results with this method are in the order of 0.5/1m 3D RMSE
for position [16].
The selection of one of the two models strongly depends on the desired
accuracy of the estimation algorithm and on the computational capabilities
available on-board.
GNSS-INS integration GNSS measurements can also be used, in real-time,
combined with an Inertial Navigation System (INS). An INS is a navigation
system exploiting an IMU (see Chapter 6 - Sensors) to compute position,
velocity, and attitude of a spacecraft. Even though INS short-term errors
are small, they tend to drift in time, accumulating errors and quickly degrad￾ing the measurement accuracy (Chapter 6 - Sensors). For this reason, GNSS
and INS are often used together to take advantage of the long-term stability
typical of GNSS systems. In the other hand, INS can also compensate for
partial unobservability of GNSS satellites, propagating the spacecraft state
without having to rely on GNSS measurements. Depending on the type
of GNSS measurements processing (i.e., GNSS-processed measurements
or GNSS raw measurements), the GNSS-INS integration architecture is
called loosely or tightly coupled. The considerations drawn before for the
two architectures, in terms of precision, computational complexity and
model complexity are also valid for GNSS-INS integration. For the sake
of clarity, the high-level schematic of the two approaches is reported in
Fig. 9.10.
Navigation 479In the loosely coupled architecture, the GNSS receiver provides directly
position and velocity measurements. The difference between GNSS and
INS position and velocity measurements are used inside an EKF to estimate
the error in the state vector dx which is fed to the INS block to remove
eventual drifts. On the contrary, for a tightly coupled architecture, the
GNSS provides the raw measurements (pseudorange in this case) that are
compared to the one measured by the INS to compute the state vector error,
thanks to an EKF. The estimated state error is used to compensate the INS
long-term errors.
Relative GNSS navigation
The benefit of having two or more spacecraft orbiting in close proximity is
that differential GNSS techniques can be employed. In fact, several common
sources of error can be canceled out when processing differential measure￾ments. This is the case of ionospheric path delays, GNSS orbits, and clock
errors. Also, carrier-phase ambiguities are easier to be resolved for differential
GNSS measurements. Cm-level accuracy can be achieved exploiting this
kind of algorithms. An important aspect to consider while implementing
differential GNSS algorithms is the synchronization of GNSS measure￾ments. In fact, proper synchronization is of vital importance to be able to
correctly cancel all the common errors. Desynchronization would lead to
highly degraded performance. Both on-ground POD and real-time naviga￾tion using nonlinear KFs are possible with differential GNSS. The imple￾mentation details resemble the ones discussed throughout the section.
Further details can be found in Ref. [16].
Pulsar-based spacecraft navigation
The estimation of the spacecraft state (position and velocity) with respect to
an inertial frame is a difficult task, especially for missions far from low Earth
Figure 9.10 GNSS-INS architecture: loosely coupled (left) and tightly coupled (right).
480 Vincenzo Pesce et al.orbit where no GNSS signals are available. In these cases, the navigation so￾lution typically needs to rely on radiometric techniques that provide a direct
range and/or range rate measurement in the LOS direction. Radiometrics
are heavily affected by delays, particularly for exploration missions to outer
planets, asteroids, or comets, and, on top of that, the cost of using the ground
stations of the Deep Space Network is considerably high taking into account
the high demand for its services. In order to mitigate these problems, it is
possible to use pulsar as measurements to obtain a navigation solution
with respect to an inertial reference frame in the Solar System. This would
help not only to improve the spacecraft state knowledge but also to increase
the autonomy level for exploration missions that are limited by the round￾trip communications delay with Earth.
Pulsars are neutron stars in a rapid rotation state generating electromag￾netic pulses due to the conservation of their angular momentum during the
collapse of the star. Young pulsars tend to rotate with very high rotation pe￾riods in the order of milliseconds, whereas the rotation of the older ones is of
several seconds. The main characteristic of pulsars is the great stability and
predictability of their rotation period. By analyzing the orientation, pulse
frequency, and pulse shape, the received signals can be uniquely associated
to a known pulsar in a catalog. The algorithm is based on Time of Arrival
(TOA) observables: the received signal is compared to an internal catalog
that contains the predicted one at the Solar System Barycenter (SSB). The
differences in arrival time between the predicted at the SSB and the actual
one on-board can be easily translated to a range distance from SSB to space￾craft in the direction of the pulsar by multiplying it by the speed of light.
This also required the knowledge of the pulsar coordinates in a known refer￾ence frame (like ICRF) to determine the direction in which the range mea￾surement is projected. Since pulsars are very far from the Solar System, it can
be assumed that their direction seen from the SSB is the same as the one
observed from the spacecraft.
Therefore, in theory, using only a given and already known catalog on￾board to compare the arrival signals, the spacecraft can autonomously
compute its state with respect to the SSB, especially if different pulsars are
observed, which would provide range measurements along different direc￾tions (Fig. 9.11).
The navigation measurement model is then relying on an a priori state
solution, generally coming from an internal propagator, and some extra pul￾sar known characteristics:
Navigation 481rangeSSBS=C ¼ c$

tSSB  tS=C
	
¼ f

rS=C; bn; DP;VP
	
where rS=C is the spacecraft position vector, bn is the unit vector representing
the direction of the pulsar with respect to the SSB, and DP and VP are the
known position and proper motion of the pulsar with respect to the SSB.
Even if the effect of the proper motion is very small compared to the other
terms in the equations, it can be included for high-precision modeling of the
pulsar measurement. The extended expression of the function is [19]:
f

rS=C; bn; DP;VP
	
¼ nbi$rSC  r2
S=C
2D0
þ

bn$rS=C
	2
2D0
þ
rS=C$VPDtN
DP

ðbn$VPDtN Þ

bn$rS=C
	
DP
 b$rS=C
DP
þ
ðbn$bÞ

bn$rS=C
	
DP
þ
2mSun
c2 ln 

bn$rS=C þ rS=C
bn$b þ b þ 1

Clock errors
The errors in the on-board clock will directly affect the navigation solution.
Therefore, they need to be included in the navigation measurement model
to track the behavior of the real clock. The lack of modeling of the clock
parameter evolution can lead to very large errors that would be translated
Figure 9.11 Pulsar-Based navigation scheme.
482 Vincenzo Pesce et al.to spacecraft position errors via the residuals in the filtering process. The
clock errors affecting the measurements consist of three main contributions:
• Clock bias. This can be considered as a constant error present during a
complete simulation. This error affects all the received measurement in
the same way, leading to a TOA bias that will translate into a spacecraft
distance bias with respect to the SSB. The effect of the clock bias can be
mitigated and reduced to the minimum via ground calibration.
• Clock drift. These errors are related to the short-term instabilities of the
clock. They are not random, and its characteristics time scales are in the
same order of the duration of a single observation. Therefore, they will
change between measurements and cannot be considered constant, and
for this reason, it is mandatory to model them during the navigation
process. Clock drifts evolution can be modeled using a quadratic
expression with time in which the three coefficients need to be esti￾mated. The estimation of these coefficients would allow tracking the
behavior of the lock errors, keeping them from polluting the navigation
solution.
• Clock jitter. These are high-frequency random errors with lower order of
magnitude than the bias and drift. As the previous ones, these errors will
affect the pulsar measurements, but they cannot be modeled due to their
random nature. They are taken into account into the navigation pro￾cedure as measurement noise.
The need to estimate the extra parameters of the clock implies that extra
measurements are required for the system to be completely observable.
Typically, at least four different measurements are needed.
Ephemerides error
Finally, there is an extra aspect to be taken into account with pulsar naviga￾tion: the effect of the ephemerides error. As mentioned before, pulsar obser￾vations provide a range measurement from the SSB to the spacecraft by
comparing the received signal on-board with the expected one in the
SSB. However, if the spacecraft is orbiting a body with limited ephemerides
knowledge, they must be taken into account into the filtering process. Typi￾cally, navigation filters predict the spacecraft position with respect to a cen￾tral body. Therefore, an error in the position of that central body with
respect to the SSB needs to be accounted for into the measurement model.
Missing this point would imply that the ephemerides error is translated to
spacecraft relative position error via the residuals in the navigation filter.
Navigation 483Ground-based orbit determination
OD is the process by which tracking data is used to compute the spacecraft’s
orbital states. It is inherently a navigation process, but since it is performed
on-ground and not on-board, the common terminology refers to it as
“ground-based OD.” In absolute OD, the spacecraft’s position and velocity
are computed relative to a Solar System body in an absolute sense, rather
than relative to other moving spacecraft. The body for which the orbit is
referred to depends on the type and phase of the mission. For example,
the trajectory of a spacecraft traveling to Mars will first be determined rela￾tive to Earth for launch and initial acquisition. After it leaves the Earth’s vi￾cinity, the orbit will be computed relative to the Sun or the barycenter of the
Solar System, and finally, as the spacecraft enters the vicinity of Mars, the
orbit will be computed relative to Mars itself.
The OD process itself is fundamentally a nonlinear least squares problem.
First, there are the nonlinear equations of motion that describe the space￾craft’s orbit. Then, there are observational data which have a nonlinear rela￾tionship between its value and the orbit. The goal is to adjust the orbit (and
parameters associated with the orbit and the data) in a least squares sense to
minimize the difference between the predicted and actual value of the ob￾servations (called the residuals). The method typically used in the ground
OD process is the batch filter, as described earlier, linearizing around a pre￾determined reference trajectory. The use of the batch filter is preferred, us￾ing a factorization method like UD, due to its superior ability to easily
remove outlier data points.
The data types used for OD vary depending on the type of mission. For
satellites orbiting the Earth and in Earth’s vicinity, the use of the GNSS
constellation, using the pseudorange observations, is very common as was
described earlier. For spacecraft operating at lunar distances and beyond,
however, the observation data are different. In this case, the primary data
used to determine their orbits are two-way radio signals sent from antennas
on the ground. The spacecraft is equipped with a transponder that receives,
then coherently retransmits the radio signal back to the ground antenna.
This radio signal provides two pieces of information: the LOS velocity of
the spacecraft relative to the station (Doppler data) and the LOS range.
Additional data types which provide complimentary pieces of information
to Doppler and range include Delta Differential One-way Range
(DDOR) and optical images from a camera. Because the OD process is al￾ways a correction to an a priori orbit, either from a previously designed
484 Vincenzo Pesce et al.reference orbit or from a previous orbit solution, there is usually not observ￾ability issues, and any one data type by itself can be used to refine the a priori
orbit. For all missions, Doppler and range are always used, with DDOR be￾ing used more sparingly and optical data primarily used in situations where
the ephemerides of the target Solar System body is highly uncertain. Each of
these data types will now be described in a little more detail.
The LOS velocity is obtained by exploiting the well-known Doppler ef￾fect. The frequency of the signal received by the spacecraft will be Doppler
shifted away from the signal sent by the station due to the velocity of the
spacecraft toward or away from the station; as the spacecraft coherently turns
the signal around and sends it back to the station, it will be Doppler shifted
again. The relationship between the change in frequency and LOS velocity
is computed as v_ ¼ 2f
c , where c is the speed of light. In practice, the Doppler
shift at the station is obtained by mixing the known frequency sent against
the received frequency; this mixing measures the accumulated change in
phase of the transmitted signal relative to the received one. Over a specified
interval of time, called the count time, the accumulated phase is divided by
the count time to get the velocity change. Typically, the hardware performs
the accumulation at 10 Hz, but for most applications, the data are com￾pressed to 60 s to both reduce the amount of data and the point-to-point
noise in the data. Also, for deep space applications, the majority of the space￾craft operate in the X-band frequency range, although there is still limited
use of S-band, and for some higher precision applications, Ka-band. The
range is determined by measuring the time it takes for a known signal to
be received after it has been sent to the spacecraft. The shift in phase of
the return signal relative to the signal transmitted to the spacecraft, modulus
an unknown number of cycles of the signal itself, is proportional to the LOS
range.
Delta Differential One-way Range (DDOR) is an interferometric data
type. For these data, the spacecraft sends a ranging tone that is simulta￾neously received by two different tracking stations spaced far apart. The
delay in the signal received by one of the stations relative to the other pro￾vides information about the angle of the spacecraft relative to the baseline
between them. The additional Delta in the DDOR measurement comes
from not only measuring the delay of the spacecraft signal but also from a
quasar located nearby in the sky. A quasar, or quasistellar radio source, is
an extremely luminous active galactic nucleus powered by a black hole; qua￾sars emit large amounts of energy in the form of electromagnetic radiation,
Navigation 485including in the radio spectrum. By doubly differencing the spacecraft delay
and the quasar delay, the measurement then becomes the angular separation
of the spacecraft from the quasar. This double differencing is used because it
removes the common sources of error of the measurement arising from at￾mospheric effects. The information content of DDOR is the angle of the
spacecraft in the plane-of-sky, which is complementary to the LOS informa￾tion content in Doppler and range data.
The third data type commonly used in deep space applications is optical
data. This is typically obtained from an onboard camera taking images of So￾lar System bodies against a star background. The image of the target body
can be a point source that is, the angular extent of the body extends less
than a camera pixel (like stars), or resolved, where its extent is greater
than a pixel (for example, the Moon as seen from Earth). In either case,
methods are used to obtain the precise center of the body, called centerfind￾ing. When stars are in the camera field-of-view, centerfinding is done on the
stars as well, and if at least two stars are available, the exact inertial pointing
direction of the camera can be computed. The center of brightness of the
body then provides a measure of the inertial LOS direction of the body rela￾tive to the spacecraft, and thus provides another data source that is comple￾mentary to Doppler, range, and DDOR. Optical data are most often used
when the orbit knowledge of the target body itself is poorly known, such
as the outer planets, planetary satellites, asteroids, and comets. From the
above, it can be seen that each type of tracking data provides information
along certain dimensions, but individually is not enough to compute the
complete state of the spacecraft. By complete state, we mean (in Cartesian
space) the three components of position and three components of velocity
which describe the state of the spacecraft, relative to the Solar System
body in question. Furthermore, typically, the filter will also estimate
many other parameters; these include dynamic parameters which affect
the motion of the spacecraft (e.g., the solar pressure force acting on the
spacecraft, delta-v associated with thruster firings, gravitational effects), as
well as parameters that affect the data (e.g., range delays, effects of atmo￾spheric media on the tracking data). In most cases, the filter will also include
consider parameters; these are parameters which are not adjusted in the filter
but contribute to the overall uncertainty of the filtered solution. The “state”
in a filter setup thus describes all the parameters estimated and considered in
the filter. For an example of the complete filter list in a standard interplan￾etary OD filter, see Table 9.2.
486 Vincenzo Pesce et al.For ground-based OD, it is often advantageous to use the linearized form
of the batch filter (as described above); this method allows straightforward
editing of measurements, as well as performing multiple variations on the fil￾ter parameters. The variations often can be quite numerous as it is very
important to ensure that the filter has converged on the correct solution. Ex￾amples of these variations include, but are not limited to, the following:
• The span of time covered by a batch filter estimate, called the “data arc”.
Typically, the orbit estimate for the current time in a deep space mission
will include multiple filter runs using varying lengths of data arcs; for
example, in an interplanetary cruise scenario, long arcs of many months,
medium arcs of a few weeks to a month, and short arcs of days to a few
weeks will be used to compute solutions and compared for consistency.
Also varied will be types of data included, where the estimate is done us￾ing each data type described above individually and in different combi￾nations. This is done to ensure that any given data are not corrupted by
some unknown bias, which might lead to a bad state estimate. Another
variation is the choice of data weighting, where each data type is assigned
a different absolute weight or adjusted relative to each other.
• A priori sigma on the state parameters. For example, tight values might
be used if a specific parameter is well known, but a variation where the a
priori sigma is loosened up to let the filter solve the parameters to the best
fit value which may be outside the a priori uncertainty if the initial guess
was incorrect. Given the above variations, the OD solution is evaluated
carefully to decide on the set of parameters and variations which give the
Table 9.2 Filter list example in a standard orbit determination filter.
Parameter Estimated or considered
State (position and velocity) Estimated
Gravitational parameters (e.g., mass, spherical
harmonic coefficients) of central body
Estimated
Solar radiation pressure (overall scale factor or
specular and reflectivity values of specific
components, like solar panels)
Estimated
Maneuvers Estimated
Attitude control thruster firings (e.g., momentum
wheel desaturation events)
Estimated
Atmospheric radio signal transmission media delay
parameters (due to Earth’s troposphere and
ionosphere)
Considered
Earth orientation parameters Considered
Navigation 487best filter solution. The solution evaluation is often an art, and it is based
on the following criteria:
• The residuals of the tracking data used in the solution should display
no significant signatures or trends. The postfit tracking data residuals
should display a random scatter about a near zero mean.
• All residual outliers must be removed from the data set used in the
solution.
• The data weights should not be less than the observed scatter in the data.
• The estimated parameters should be a sufficient set to accurately model
the trajectory and media.
• All the data used in the solution should be sensitive at the appropriate
levels to the dynamic and media model errors.
• The corrections to the estimated parameters should make physical sense
(e.g., gravitational parameters should not solve out to negative values).
• The a priori uncertainties should be of the appropriate magnitude, in
other words, the ratio of the corrections to the parameters to the a priori
sigma should not be greater than about 3.
• The scatter of solutions with the variations should be statistically consis￾tent with each other. If not, every attempt should be made to explain the
discrepancy, such as examining for unmodeled biases in the data.
Absolute attitude navigation
Attitude navigation, also known as attitude determination, is the task
of determining the current attitude state of the satellite for controlling and
maneuvering it where necessary. This requires the use of attitude sensors
and algorithms that are often custom made for a satellite, as it has strong de￾pendencies from most of the other subsystems. First, let us clarify that all the
sensors used to determine the attitude states are based on direction measure￾ments, even though sometimes angles are used, but the underlying concept
is the same. Even with off the shelf star sensors, which are capable to inde￾pendently estimate the full attitude of the spacecraft, we are sure that they
work by determining the directions of many stars before computing the
result. What they do is comparing the stars they see in the sensor reference
frame to a database containing their reference directions in inertial frame.
The same process holds for other sensors like magnetometers or sun sensors
presented in the Chapter 6 - Sensors: they measure a direction in the sensor
frame, which is then rotated by a known mounting angle in the body frame,
to be eventually compared with the reference direction in inertial frame.
488 Vincenzo Pesce et al.The latter is often orbit-dependent; hence, a proper orbital determination is
crucial to have a reliable attitude reference. Another important point is that
at least two different direction measurements are necessary to estimate the
complete attitude state. If we fix one direction, we have infinite rotation
around that direction that the satellite can take; thus, we need to fix at least
another direction that has a significant projection perpendicular to the first
direction. This becomes visually clear if we think to a dice, which is also
visually represented in the Chapter 5 - Attitude Dynamics. If we “measure”
the face 1 to be on top of the dice (i.e., we determine that the face with
figure 1 has its normal direction pointing upward), we have four possible
orientations that are compatible with this measured condition. We can
completely fix the full three-dimensional attitude state if we measure where
the face 3 is, for example. However, if we manage to measure the face 6, we
know we will not have a full attitude estimation, as figure 1 and 6 are in two
opposite faces, and the two directions would be actually the same with
opposite sign.
The problem of computing the attitude state from direction measure￾ments is typically referred to as static attitude determination, since it is based
on geometrical relations between measurements taken in the same instant
of time. Static attitude determination has no connection with the attitude
dynamics, and different time instants may have uncorrelated attitude solu￾tions. This is the fundamental attitude determination method, but it is not
robust with respect to measurement errors and uncertainties. For these rea￾sons, static attitude determination is typically complemented with some
filtering techniques, which are sometimes referred to as dynamic attitude deter￾mination. In fact, these methods use the knowledge of the motion of the
spacecraft to accumulate a history of past measurements.
Triad
The simplest attitude determination process requires two direction measure￾ments in the form of unit vector. Indeed, attitude determination requires
finding three independent quantities, such as any minimal parameterization
of the attitude matrix. Hence, let us assume to measure, for example, the di￾rection of the sun, bs
b
, and of the magnetic field, bbb
. Since the two vectors
change in time depending on the orbit and the day of the year, it is almost
impossible to have them perpendicular; hence, a simple way would be to
determine other two auxiliary unit vectors starting from these two measure￾ments. The aim of the algorithm is to find the DCM, A ¼ b
Ai, which
Navigation 489rotates the inertial sun direction bs
i and magnetic field direction bbi
in the
body reference frame:
8
<
:
bs
b ¼ Abs
i
bbb
¼ Abbi (9.1)
If we construct two vectors set as follows:
8
>>>>>>>>>>>>>><
>>>>>>>>>>>>>>:
bv
b ¼ bbb
 bs
b



bbb
 bs
b




bv
i ¼ bbi
 bs
i



bbi
 bs
i




bk
b
¼ bv
b  bbb
bk
i
¼ bv
i
 bbi
: (9.2)
We now have all the elements to determine the DCM. In fact, we just
constructed a new reference frame using bbb
; bv
b
, and bk
b
whose relationship
with the inertial reference is by construction:

bbb bk
b bv
b

¼ A

bbi bk
i bv
i
 (9.3)
The simplest way to solve the problem would be:
A ¼ 
bbb bk
b bv
b
 bbi bk
i bv
i
T
; (9.4)
since by construction 
bbb bk
b bv
b

and 
bbi bk
i bv
i

are DCMs.
This operation, however, does not take into account the orthogonality
and normality requirements for the solution. Indeed, the solution A is ob￾tained by numerical means and on-board computers might have not enough
precision for the later usage in the GNC scheme. On the other hand, if we
make use of a different attitude parametrizations (i.e., Euler angles, Euler
axis, quaternions, etc.), the enforcement of the mathematical constraints is
easier, but the solution becomes more complex as shown in the next section.
There is a drawback in using this simple formulation, and it is related to
measurement noise. If we have an error (note that real measurements are all
affected by errors) in bs
b and bbb
, this would affect both bk
b
and bv
b
. The only
490 Vincenzo Pesce et al.way to improve the solution is to either add more measures or a filtering
process:
8
>>>>><
>>>>>:
bsn
b ¼ f

bs1
b
;bs2
b
; /;bsn
b

bbm
b
¼ f

bb1
b
; bb2
b
;/; bbn
b
	/
bve
b ¼ bbm
b
 bsn
b






bbm
b
 bsn
b






sbv
b
bke
b
¼ bve
b  bbm
b
sbk
b
(9.5)
Wahba problem
We have seen a solution using only two measurements assumed to be
equally precise. This is often not the case, as sensors may have very different
precision levels, or more than two information are available at the same time.
The generalization of this problem is often called Wahba problem [20], first
posed by Grace Wahba in 1965, aiming to find a DCM such that minimizes
a certain cost function.
Let us identify n body measured directions bvj
b with j going from 1 to n
and their inertial counterparts bvj
i
, the cost function is the following:
J ¼ 1
2
Xn
j¼1
xjjjbvj
b  Abvj
i
jj2 (9.6)
where the weights xj can help to discriminate and differently weight the
available measurements.
The TRIAD method enforced the measurements to give orthogonal re￾sults, but some easy solutions to the Wahba problem might not give as
output a real DCM. For example, we might construct two matrices that
have n columns, one for each measure, and use the pseudoinverse (noted
with the y) to have a least squares solution:
8
><
>:

bvj
b

¼ A

bvj
i

A ¼ 
bvj
b
bvj
i
y
; with j ¼ 1: n (9.7)
In this case, we have that the minimum number of independent nonpar￾allel measures is three, to allow the inverted matrix to have rank 3. By incor￾porating the xj, we would have a weighted least square solution. These
solutions do not enforce A to be orthogonal, and thus an orthogonalization
procedure would have to be put in place. In fact, the inversion of a
Navigation 491nonsquare matrix using a pseudoinverse cannot generate a perfect inverse;
hence, the outcome will, in general, not be an orthogonal matrix represent￾ing the DCM. Well-known orthogonalization techniques are the Grame
Schmidt projection and the Householder reflection, but other options exist.
The interested reader can find the algorithms in most linear algebra books,
like Ref. [21].
Algorithms for solving the Wahba problem are divided into two groups.
Some of them solve for the attitude matrix directly, and others solve for the
quaternion representation of the attitude matrix. Quaternion solutions have
proven to be much more useful in practice, and they are common standard
in modern GNC applications.
SVD method
The first formal solution of the Wahba problem is the Singular Value
Decomposition (SVD) method to estimate directly the DCM. We can
rewrite the cost function (sometimes referred to as loss function) as follows:
J ¼ Xn
j¼1
xj  tr
ABT
; (9.8)
where we have defined the matrix B as follows:
B ¼ Xn
j¼1
xjbvj
b

bvj
i
T
: (9.9)
This matrix can be decomposed through the SVD, and its left and right
matrices can be coupled to get A:
8
<
:
B ¼ SVDT
A ¼ S diagð½ 1 1 detð Þð S detð ÞÞ Þ D DT
(9.10)
An alternative solution would be:
A ¼ B

BTB
0:5 (9.11)
That requires B to be rank 3, meaning to have at least three measure￾ments. In cases when only two measurements are available, it is possible
to exploit the same procedure used in the TRIAD and still find a solution
with this method.
492 Vincenzo Pesce et al.Davenport q-method
A nicer way to solve the Wahba problem bypassing the passage from DCM
to simpler attitude representations is to use directly one of these attitude rep￾resentation for the estimation. The simplest and most common way is to use
quaternions. The first method of this kind is the one proposed by Davenport
[22].
Let us identify n measured directions bvj
b with j going from 1 to n. Our
goal is to find qe such that the following expression is true for all n
measurements:
bvj
b ¼ A

q
wÞ
bvj
i
: (9.12)
Given any possible qe, we have that the reprojection error, ej, for the j-th
measurement is:
ej ¼ 1  
bvj
b
T
A

q
wÞ
bvj
i (9.13)
The total error of the set would be:
e ¼ Xn
j¼1
ej ¼ n Xn
j¼1

bvj
b
T
A

eq

bvj
i

: (9.14)
We can express A as the multiplication of two 4  4 matrices function of
qe ¼ 
q1:3
T
q4
T; and treat the measured and reference directions as uni￾tary quaternions with null real part:
ej ¼ 1 
8
><
>:
bvj
b
0
9
>=
>;
T2
6
4
½q1:3 
T þ I3q4 q1:3
T
q1:3
T
q4
3
7
5
2
6
4
½q1:3 
T þ I3q4 q1:3
T
q1:3
T
q4
3
7
5
8
<
:
bvj
i
0
9
=
;:
(9.15)
By virtue of quaternion multiplication properties, we get:
ej ¼ 1 
8
<
:
q1:3
q4
9
=
;
T2
4

bvj
b
 bvj
b
bvj
bT 0
3
5
2
4

bvj
i
 bvj
i
bvj
iT 0
3
5
8
<
:
q1:3
q4
9
=
;
(9.16)
Navigation 493The total error of the set would be:
e ¼ n 
8
<
:
q1:3
q4
9
=
;
T
Q
8
<
:
q1:3
q4
9
=
; ¼ n  q
w TQqw ¼ n

1  q
w T
1
n
Qqw

¼ q
w TðI4n  QÞq
w; (9.17)
with:
Q ¼ Xn
j¼1
Qj ¼ Xn
j¼1
2
6
4

bvj
i
bvj
i

þ bvj
b
5bvj
i bvj
b  bvj
i

bvj
i  bvj
b
T 
bvj
b
T bvj
i
3
7
5: (9.18)
From this, it is clear that finding the minimum of e means finding the
maximum of qeTQqe; hence, find the unitary qe that maximize this
expression.
If we find an eigenpair 
lk; qlk
	
of Q such that Qqlk ¼ lkqlk
, and we
take our estimation qe ¼ qlk
, we have that the error would be:
e ¼ n  qT
lk
Qqlk ¼ n  lk: (9.19)
From this result, we reckon that the minimum error corresponds to a so￾lution that is equal to the eigenvector of the maximum eigenvalue of Q,
lmax: qe ¼ qlmax.
This approach can also take into account a weighting factor xj for each
pair of measures and references in a simple way:
e ¼ Xn
j¼1
xjej
,Xn
j¼1
xj
/Q ¼ Xn
j¼1
xjQj (9.20)
We can also notice how this solution can become computationally not
efficient as Q grows larger with the number of measures or weights. The
most computationally friendly formulation would use instead Q ¼ 1
n Q
with also Pxj ¼ 1; so that the elements of Q lies approximately in the range
½ 1 1 .
It should be noted that it is possible to use this algorithm even in the two
measurements case, even though it might be more computationally intense
than the quality of the result it can provide.
494 Vincenzo Pesce et al.Historically speaking, matrix Q has been called by Shuster, the Daven￾port’s matrix as the algorithm was first introduced by Paul Davenport. Shus￾ter himself then developed the following method to make the algorithm
computationally faster. In the Shuster’s method, the matrix Q is computed
in a slightly different procedure, which is here reported for clarity as it can be
computationally more efficient:
Q ¼
"
C  I3 trðBÞ z
zT trðBÞ
#
; (9.21)
with B the same matrix defined before and:
8
>>>>>>>>>><
>>>>>>>>>>:
z ¼ Xn
j¼1
xj

bvj
b  bvj
i

B ¼ Xn
j¼1
xj bvj
b 
bvj
i
T
C ¼ B þ BT
(9.22)
The final result is the same (i.e., qe ¼ qlmax), but this form was used for the
development of the QUaternion EStimation (QUEST) algorithm.
QUEST method
The Davenport method to solve Wahba problem is robust and well suited
for many applications, although it might be relatively expensive in terms
of computational effort. A faster solution is the QUEST method developed
by Shuster [23]. QUEST algorithm has become the most widely used algo￾rithm for solving Wahba problem in modern GNC applications. QUEST
algorithm is computationally efficient since it allows to avoid the iterative
operations on 4  4 matrices required by Davenport’s q-method. Indeed,
it is based on iterative scalar formulas followed by straightforward matrix
multiplications. QUEST solution is based in solving the characteristic equa￾tion of Q, which is theoretically not the best way to solve eigenvalue prob￾lems. Therefore, QUEST is in principle less robust than q-method.
However, it has proven to be extremely robust in practice.
Navigation 495Using the eigenvector and eigenvalue relations, we have:
8
<
:
ðC  I3trð ÞÞ B q1:3 þ zq4 ¼ lmaxq1:3
zTq1:3 þ trð Þ B q4 ¼ lmaxq4
(9.23)
Due to the construction of matrix Q, we know that the largest eigen￾value can be approximated as lmaxy Pn
j¼1
xj ¼ l0. Hence, Shuster proposed
to solve numerically with a NewtoneRapson method the characteristic
equation to find the exact value of lmax with a starting solution equal to l0.
If we substitute the first equation of (9.23) into the second equation, we
get:

trð Þ B zT ðC  I3ðlmax þ trð ÞÞÞ B 1
z  lmax
q4 ¼ 0; (9.24)
which admits solutions for lmax. Note that if q4 ¼ 0, the matrix
ððlmax þtrðBÞÞI3 CÞ is singular, meaning that 180 rotations give prob￾lems to this algorithm. To solve this issue, Shuster proposed the method
of sequential rotations to avoid this singularity. Further details on the
QUEST algorithm and on the method of sequential rotations may be found
in Ref. [24].
The strength of the QUEST algorithm goes in the quick convergence of
an iterative NewtoneRaphson scheme to solve Eq. (9.24) for lmax using l0
as first guess. Few iterations are necessary, and sometimes a single iteration is
sufficient. Moreover, the approximation lmax ¼ l0 is adequate in many
cases. The characteristic equation has an analytic solution, but this solution
is slower, no more accurate, and sometimes less reliable than the Newtone
Raphson iteration.
When the value of lmax is known, the optimal estimated quaternion
takes the form:
qe ¼
( adjððlmax þ trðBÞÞI3  CÞz
detððlmax þ trðBÞÞI3  CÞ
)
;
which has to be normalized and enforced to be continuous between two
consecutive solutions. Indeed, the quaternion solution may abruptly change
sign, and this shall be avoided by forcing a sign change to preserve numerical
continuity with the previous instant of time. However, it shall be reminded
that two quaternions with opposite signs refer to the same physical attitude
state, as discussed in the Chapter 5 - Attitude Dynamics.
496 Vincenzo Pesce et al.Estimation of angular velocity
Many attitude control schemes require the estimation of the angular velocity
of the satellite, in addition to the determination of the attitude state. This can
be attained in different ways depending on the available sensors. If the sat￾ellite is equipped with a gyroscope, there is possibility to have a direct mea￾surement; however, gyroscopes are often subject to effects that degrade their
performances. The most common problem is a low frequency, almost static,
bias error (i.e., bias instability) that can be disastrous for the attitude control.
Moreover, there might be the case in which no direct angular rate measure￾ment is available. In all these cases, the estimation of spacecraft’s true angular
velocity shall be implemented in the attitude navigation functions of a mod￾ern GNC subsystem.
Low-cost microelectromechanical system gyroscopes exhibit low￾frequency bias instability dependent in a nonlinear, often hysteretic, fashion
with temperature and other environmental effects. Also, vibration-induced
errors can be accounted for; however, these might be less important during
nominal operation once in orbit. In general, if we look at the full spectrum of
gyroscope measurements, which has been discussed in the Chapter 6 -
Sensors, we notice disturbance errors and noises at different frequencies
downgrading the GNC system’s performance, as discussed in the Chapter 10 -
Control. The low-frequency errors can be estimated if the gyroscope’s
measurements are inserted in a filter that has estimation capabilities in that fre￾quency range. One possibility is to use one of the attitude estimation methods
presented before and confront the variation in time of the estimated attitude
with the raw measurement from the gyroscope. In this way, a sequential filter
can estimate the gyroscope’s bias. Another possibility is to insert the angular
rate measurements of the gyroscope in an estimation filter based on the
dynamical model of the satellite. In this case, the filter uses the Euler equations
and the attitude kinematics to estimate the gyroscope errors. This approach
requires a good knowledge of the system, of the external disturbances, and
of the commanded actuation. The first possibility, exploiting a filter based
on the sensor model, requires less input from the rest of the system and can
be quite independent. As one can imagine, the modeling of the entire dynam￾ical system of a satellite, would need information on the inertia of the system,
as well as on the control torques that are currently used, which are function of
the estimation itself. Instead, if we use a filter that is based on the modeling
errors of the sensors (e.g., bias instability, random walks, etc.), this information
is no longer needed.
Navigation 497If a gyroscope is not present on the satellite, it is still possible to estimate
the angular velocity using other sensor measurements. Indeed, once the atti￾tude is estimated, it is possible to use differentiation to estimate the angular
velocity using past and current measurements. This method suffers from
high-frequency noise by nature, because of the differentiation operations,
and from low-frequency estimation errors, if the original measurement
has low update time. A common practice is to use a high-pass filter that
in the low-frequency range behaves as a differentiator, plus a low-pass filter
to eliminate the high-frequency noise. However, the tuning of such pass￾band filter is not trivial, and it requires a lot of effort along the GNC design.
In Fig. 9.12, a simple low-pass filter is presented. If we take the transfer
function between output and input, we have:
y
u ¼ K
K þ s
(9.25)
which is a low-pass filter of the first order with cut-off frequency of K,
expressed in rad=s (i.e., a cut-off frequency of 100 Hz results in K ¼ 2p
100rad=s). This means that the amplitude of the signal u is preserved up to
the cut-off frequency, and then it is attenuated afterward with a 20 dB per
decade slope. However, we can also take as output y_, which is the derivative
of y, hence if we multiply by s, we get:
y_
u_
¼ K
K þ s
(9.26)
Hence, in the low-frequency portion (i.e., below the cutoff frequency),
the signal y_ can be considered equal to u_. In the high-frequency range, this
no longer holds true, and, in practice, there will be noise in the high fre￾quency, like for every differentiation application. From what has been
shown, it is straightforward to combine a high pass filter with a lowpass filter
to reduce the noise of the differentiator getting something like:
z
u ¼ Klp
Klp þ s
s
Khp þ s
¼ Klps
KlpKhp þ 
Khp þ Klp
s þ s
2 (9.27)
Figure 9.12 First-order low-pass and high-pass filter.
498 Vincenzo Pesce et al.which is a second-order pass-band filter that requires a proper tuning in
order to obtain the desired result.
Kalman filtering
We have seen that estimating attitude states and angular velocity is possible,
and many navigation solutions and possibilities are available. One common
theme is to filter and propagate the measurements and the estimated states to
achieve the required update rate, which is linked to the system frequency
and error rejection in the complete control loop. The most common tech￾nique used in these cases is the KF, previously introduced for absolute orbit
navigation. Moreover, Kalman filtering allows improving the stability of the
static attitude solution and it allows to estimate unknown quantities and er￾rors (i.e., bias, misalignment, etc.) to improve the overall attitude navigation
performance. In general, these techniques are part of the so-called dynamic
attitude determination.
If we take the time propagation of the attitude kinematics, as seen in the
Chapter 5 - Attitude Dynamics, we can derive a KF around that model to
improve the attitude estimation. However, we have seen that such time up￾dates depend on the kinematic parametrizations we use for attitude repre￾sentation, and in any case, these updates will be nonlinear. This imposes
the necessity to use the nonlinear KFs such as the EKF or the UKF [25].
If the computing capacity of the hardware allows for it, also PFs can be used.
In attitude estimation, a further distinction can be made based on the
underlining functioning of the EKF. The straightforward implementation
of an EKF would see the attitude error defined as a difference between
the true and estimated kinematic objects. The simplest solution would be
to use Euler angles, but their variation in time is susceptible of singularity,
thus they are not recommended for this application. In fact, in modern
GNC applications, quaternions are commonly used; however, there are
some issues to be addressed. Formulating the attitude error with quaternions
as a difference is an operation that does not belong to the unitary quaternion
space (i.e., addition is not internal in the unitary quaternion group, as the
difference between two unitary quaternions is not in general a unitary
quaternion). Hence, it is often preferred to formulate the EKF considering
the error to be a quaternion multiplication. This distinction leads to the two
main approach: additive EKF (AEKF) or multiplicative EKF (MEKF) [26].
The AEKF neglects the quaternion normalization condition and treats the
four components of the quaternion as independent parameters. The
Navigation 499MEKF represents the true attitude as the quaternion product of an error
quaternion with the best estimated quaternion: q ¼ dq  qe, and all of
them are normalized unit quaternions. Globally, the MEKF requires less
computation resources because it has a lower dimensions covariance matrix,
and it also satisfies the mathematical unitary constraint of quaternion rota￾tions. Hence, the MEKF is by far the most used approach for Kalman
filtering in modern attitude determination applications.
Another issue is the propagation and inversion of a quaternion covari￾ance. Namely, the four components of a quaternion are not independent,
and, thus, the covariance of a quaternion is rank 3 instead of 4. This poses
some issues as in the EKF, the covariance of the state is propagated and
used in computations. Keeping its rank consistent is not trivial. To solve
this issue, one might prefer the use of an UKF where the covariance is
computed directly from a subset of propagated states based upon the previ￾ous step covariance. During filtering operations, the covariance is computed
on perfectly unitary quaternions, since every integration or propagation step
has to be normalized anyway, and it can retain all its information without
causing divergence. However, UKF is commonly more expensive in terms
of computational resources.
A common Kalman filtering approach would be to filter only part of the
quaternion component, namely the vector part q1:3, inherently assuming a
small error approach. This, of course, cannot be applied directly to the atti￾tude quaternion, as this can assume all possible values. Hence, the filter must
be set in a relative error formulation. This means that the KF has to be
modeled on the error of estimate. Let us consider the case for MEKF, where
we use a gyroscope measure to generate a forward integrator estimate for the
attitude quaternion, qe ¼
n
qeT
1:3eq4
oT
. Such integrator uses the gyroscope
measure, ug, and the estimated bias, beg. In the latter term, we can include
offsets and random walks, as well as any low-frequency error source we
can think of. The bias estimation can be further expanded to consider de￾pendency on acceleration or temperature, but here these will be omitted
for the sake of simplicity. The kinematics of the true attitude parameters is
expressed as:
500 Vincenzo Pesce et al.8
>>>><
>>>>:
u ¼ ug  b
w
g
2q_ 1:3 ¼ uq4  u  q1:3
2q_
4 ¼ u$q1:3
In this case, the forward integrator will always diverge as it does not take
directly into account any attitude measure. The concept at the very core of
the MEKF is to define a quaternion error, dq, through quaternion multipli￾cation between the real value q and the estimated value qe:
( dq1:3
dq4
)
¼ q  qe1 ¼
2
6
4
I3eq4 


qe1:3

qe1:3
qe1:3
T eq4
3
7
5q:
The same reasoning can be applied to the angular velocity error as du ¼
u  ue. The error variations in time are then given by the following
expression:
8
>>>>><
>>>>>:
du_ ¼ b_ g
dq_ 1:3 ¼ 1
2
du  u
w dq1:3dq_
4 ¼ 0
Then, we can construct a KF using the state x ¼
n
dqT
1:3 bT
g
oT
, since
we can assume dq4/1 if sufficiently close to the real quaternion q. In this
way, we can use the assumption that the model error covariance Qk is a 6 6
matrix that includes the expected bias error covariance. Less trivial is the
setting of the covariance related to dq1:3, as the model error is theoretically
related only to the small angle assumption. The KF would not be complete
without the measurements that will increase the understanding of the error
and, thus, provide a full-fledged estimation of the attitude. There are two
common alternatives depending on the sensors available: one is to exploit
the complete attitude estimation in quaternion form of a star tracker; the
other is to exploit different direction measurements like Sun, magnetic field,
Earth horizon, and so on, to be first processed by a static attitude determi￾nation method. Then, the measurement model has to be written in such
a form that it can be easily referred to the error component dq1:3 (i.e., no
Navigation 501dependency on beg is expected). When dealing with vector measurements, it
is important to also have the inertial directions available, in order to
construct the estimated directions in body frame by using A

qe

.
At every iteration step, the KF estimates both dq1:3 and beg. Hence, the
output of the propagation can be updated with the first, remembering the
assumption dq4/1, and the angular velocity of the gyroscope can be
updated using the bias estimate. Important care should be taken in the inte￾grator initialization, as there are two ways to deal with this problem: one is to
reset the integrator at every step (i.e., starting from the latest best estimate);
the other is to let the integrator run without inserting the new best estimate
in the integration phase. It is clear that the two approaches are quite different
and can leave to a different result. In the first formulation, dq1:3 is set to zero
in the prediction step, as the integrator is assumed to be unbiased (i.e., cor￾rected with previous step before the integration); in the second case, this no
longer holds true and the whole propagation evolution has to be considered.
Moreover, in the latter formulation, there is a higher risk of integration
divergence. The reader is invited to deepen the knowledge about Kalman
filtering for attitude determination in Refs. [24,26,27].
Complementary filter
It is possible to greatly simplify the structure of the attitude determination
filter by using a simple proportional integral (PI) transfer function on the er￾ror dq1:3 to obtain a complementary filter [28e30]. In general, a KF based
on a nonlinear model is time varying and requires nontrivial computations.
Thus, if computational effort, simplicity, and tunability is of great concern,
using a complementary filter might be the best solution. This filter is simpler
to implement, tune, and does not require solving linear systems or store
covariance matrices, although it may introduce some delays if not well
balanced.
In Fig. 9.13, the simplified scheme for a complementary filter that uses a
gyroscope measure ug and a static attitude determination quaternion
Figure 9.13 Complementary filter scheme.
502 Vincenzo Pesce et al.estimate qst is presented. Note that the static attitude determination can also
be replaced by a star sensor’s output. The quaternion error dq is computed
using the static estimation and the propagated quaternion estimate qe. The
latter is computed by integration of the gyroscope measurement plus the
bias estimate bg, which is the result of a simple proportional and integral
control on the vector part of the quaternion error dq. A simplified mathe￾matical formulation is proposed here:
8
>>>>>>>>>>><
>>>>>>>>>>>:
u
w ¼ ug þ bg
_
q
w ¼ 1
2
2
6
6
4

h
u
w

i
u
w
u
wT
0
3
7
7
5
qw
bg ¼ Cðdq1:3Þ ¼ Kpdq1:3 þ Ki
Z
dq1:3
This is the resulting simplified model whose dynamics is given by the
weights Kp and Ki. These values allow to set a high-pass filter on the gyro￾scope measures that cuts off their low-frequency content (e.g., bias and
random walk) and take instead the low frequency of the derivative of the
measurements. This permits to cut off the high-frequency errors in the mea￾surements as well. By delaying qe, we can also consider delays in the reference
estimated quaternion by other means, which may be interesting in case of
star tracker with significant time delay. In fact, in the complementary filter
loop, it matters most that the error is computed by comparison of the fore￾cast and the measurement with time coherence. Hence, if we delay the esti￾mation of 1s and we insert a measure with 1s delay, the result will still hold
regardless of the delay, although some limitations may apply depending on
the sensors used. Another interesting feature of this filter is that it is possible
to raise the attitude estimation frequency up to the gyroscope frequency.
This means that if a gyroscope has a 10 Hz update frequency, and the static
attitude determination has 2 Hz update rate, the output of the filter will be at
10 Hz. Depending on the frequency difference, the final result may vary,
and a dedicated analysis on the filter design is always needed.
If we linearize the system in terms of dq1:3, we can determine the cut-off
frequency and the delay in the measurements as:
ucutoff x Kp
Ki þ 1
:
Navigation 503If we assure Ki  Kp, the latter is the dominant factor, and it becomes
easy to set the cut-off frequency of the filter in such a way that it combines
well with the rest of the GNC system.
Relative navigation
The word navigation usually refers to absolute spacecraft navigation,
i.e., the problem of localizing itself with respect to a known inertial refer￾ence frame. In this chapter, the concept of relative navigation is introduced.
Relative navigation can be seen as the problem of finding the relative loca￾tion and attitude of two different space objects’ reference frames (i.e., chaser
and target). This kind of navigation is of interest to a variety of applications,
namely FF, rendezvous and docking (RVD), on-orbit servicing (O-OS) of
functional satellites or space station, and active debris removal (ADR).
Indeed, in such mission scenarios, the on-board processing unit of one
spacecraft must be able to autonomously estimate its relative state with
respect to the other, ensuring both high accuracy and update rates. Thus,
it shall be able to satisfy control requirements and minimize collision risks.
Depending on the category of target, different application scenario can be
identified [31]. Table 9.3 reports different possible mission scenarios with
the associated chaser and target hardware for each case.
In the actively cooperative target case, both chaser and target have the
knowledge of their own position and they exchange information by means
of a communication link. In this case, the navigation performance is usually
very high, and this solution can be applied to FF and O-OS scenarios in
which high accuracy is required. In some cases, the target may also be coop￾erating in a passive way, through artificial markers on the spacecraft body
that can be detected and tracked by the chaser spacecraft. Also in this
case, very accurate relative navigation can be performed. When dealing
with uncooperative targets, the navigation performance inevitably degrades
because of the lack of information provided by the target spacecraft. For this
scenario, passive or active sensors have to be used along with advanced soft￾ware techniques to derive a relative state estimate. Specific attention is also
addressed to the case of uncooperative targets which are particularly difficult
to approach. In fact, the lack of any a priori knowledge of the target body
and the high uncertainty on its motions make the relative navigation prob￾lem particularly difficult to tackle. Consequently, advanced, ad hoc, techno￾logical, and algorithmic solutions shall be envisaged. With regards to the
technological aspects, electro-optical sensors have been identified as the
504 Vincenzo Pesce et al.best option for relative navigation purposes when close-proximity maneu￾vers (e.g., RVD) toward uncooperative targets are required [31]. In partic￾ular, either active LIght Detection And Ranging (LIDAR) systems or passive
monocular and stereo cameras can be used. The selection of the navigation
sensor must consider the resources available on-board in terms of mass, elec￾trical and processing power, on one side, the mission scenario and the costs
to be sustained for design and development of the satellite system, on the
other side.
From the navigation filter implementation point of view, the difference
between absolute and relative estimation is not substantial. However, some
alternatives exist while designing a relative navigation filter. The first
possible choice concerns the filter architecture. In fact, especially when
dealing with multiple spacecraft (FF), there are two possible strategies:
centralized or decentralized filters. A centralized filter estimates the state
of all the accessible spacecraft performing propagation and measurements
update using only a single filter. In this case, all the measurements are sent
from each spacecraft to a single processor. The main drawback of this archi￾tecture is that when the number of satellites is high, the state vector size be￾comes significant, and this implies a critical increase of the computational
load. In a decentralized approach, each spacecraft performs its own state esti￾mation. Then, the solutions are sent to a “master” spacecraft that performs
an estimation of the entire formation. In this case, the computational load
does not depend on the size of the formation.
Table 9.3 Relative navigation scenarios.
Target category Chaser hardware
Target
hardware Mission scenario
Actively cooperative RF/GPS antennas RF/GPS
antennas
FF, O-OS, RVD
Passively cooperative Relative sensors
(e.g., cameras,
LIDAR)
Artificial
markers
FF, O-OS, RVD
Uncooperative
known
Relative sensors e ADR, O-OS, RVD
Uncooperative
unknown
Relative sensors e ADR, small-body
approach
Navigation 505The choice of the dynamical propagation can also affect the overall rela￾tive navigation filter performance. In fact, the relative dynamics of two
spacecraft can be described by using relative or absolute formulations (cfr.
Chapter 4 - Orbital Dynamics and Chapter 5 - Attitude Dynamics). Also
in this case, the choice between relying on a relative formulation rather
than on an absolute one strictly depends on the kind of problem, sensors
adopted, and performance to be achieved. Three main different approaches
can be considered:
• Absolute representation. Generally speaking, absolute propagators are more
reliable and configurable for high-fidelity propagation (possibility to
include models for drag, SRP, ephemerides of other gravitational bodies,
relativistic effects, etc.). This choice is preferable when high performance
is required or when most of the measurements are absolute.
• Relative representation. Classical relative dynamics formulations rely on
simple equations (even providing closed-form solutions) but with the
cost of stringent assumptions. When the underlying assumptions of these
models (usually circular orbits and close distance) are satisfied, relative
formulations for describing the dynamics are preferred. This is also true
when most of the measurements are relative and the requirement on
relative state estimation accuracy is not so rigid.
• Absolute/relative representation. In this case, the dynamical propagation is
done in an absolute sense, but the covariance is propagated using the cor￾responding relative formulation (see Ref. [32] for a detailed description).
Mathematically this formulation is equivalent to the absolute one, but
computational considerations can be carried out. In fact, the absolute
representation shows lower computational load and higher precision
for covariance matrix propagation with respect to an absolute/relative
formulation [32]. On the other hand, when mostly relative measure￾ments are used, the absolute/relative version of the measurement updates
is preferred.
To give a practical example, let’s assume to have a rendezvous scenario in
which a certain sensor (e.g., camera, LIDAR) gives measurement of relative
position between the chaser spacecraft and the target. In this case, a sequen￾tial filter can be used with the following parameters:
• Centralized filter. If the target is uncooperative, this is the only option
because no information can be exchanged between the two spacecraft.
Furthermore, for RDV scenarios, this approach is preferred since, often,
only one of the two spacecraft (the target) can actively maneuver. There￾fore, all the information is stored and available to take a decision.
506 Vincenzo Pesce et al.• State vector. As previously explained, two main approaches exist. In this
specific case, the state vector can be expressed as:
• Absolute representation: x ¼ ½pC; vC; pT; vT
T where pC; vC are the
position and velocity of the chaser and pT; vT of the target expressed
in an inertial reference frame.
• Relative representation: x ¼ 
pC R; vC R
T where pC R; vC R are the
relative position and velocity of the target with respect to the chaser
reference frame.
• Dynamical model. The dynamical model for the state propagation can be
relative (e.g., ClohessyeWiltshire equation - see Chapter 4 - Orbital Dy￾namics) or absolute (e.g., Newton’s law - see Chapter 4 - Orbital Dy￾namics). The choice of the appropriate model is discussed before, but
it is highly dependent on the selection of the state vector representation.
Image processing techniques
Cameras are usually used as sensors for spacecraft navigation, especially
for relative scenarios, being lightweight and relatively cheap. This kind of
active sensor provides an image as output that has to be processed to be
used by the navigation filter. This is valid for spacecraft navigation but
also for all the other possible applications involving cameras. Also for this
reason, image processing is an active and broad research field. The objective
of this book is to give an overview of the most common techniques and al￾gorithms used in the space domain and to categorize them depending on the
potential application.
Image representation
Usually, a mathematical model is used to represent and describe an image.
For most of spacecraft navigation applications, a scalar function is sufficient
to describe a monochromatic image. If we consider our eye or a camera
sensor, an image is inherently two dimensional. A simple way of represent￾ing an image is through a continuous function f ðx; yÞ corresponding to the
brightness at each image point (with x and y are the coordinates of the image
plane). A simple example is shown in Fig. 9.14. This 2D intensity image is
the result of a perspective projection of the 3D scene.
Navigation 507Segmentation
The continuous function describing an image can, then, be processed to
extract useful image properties. One of the most common image processing
techniques is called segmentation. The segmentation process consists in par￾titioning an image into meaningful regions. This technique is very useful for
space applications where a bright object (e.g., a satellite) has to be distin￾guished from the starry background.
Autonomous segmentation can be a very difficult task for common com￾puter vision applications, but it is less demanding when dealing with simpler
space images, where the background is considerably different from the
observed target. The most common approaches to segmentations are:
• Local methods - pixel based.
• Global methods - region based.
The pixel-based approach works by detecting the edges within an image
and then linking them to create a uniform boundary. The region-based
approach searches for pixels with common features and groups them into re￾gions of uniformity.
Local methods
Local methods work by detecting changes of intensity in the image. These
methods perform checks to detect the presence of a change across each pixel
within an image array. Thus, only local information is used, and the general
properties of the whole region are not considered. A good local segmenta￾tion algorithm has to rely on a precise edge detector, usually based on
gradient operators (for more details, see Ref. [33]).
Figure 9.14 Image representation.
508 Vincenzo Pesce et al.Global methods
Global methods work by grouping together pixels with common features
into regions of uniformity. These methods perform well with high contrast
images of an uncluttered scene (i.e., space images). However, they can be
computationally expensive for more complex scenarios. Furthermore,
global methods tend to generally be less sensitive to noise than local ap￾proaches [33]. One of the most common techniques for space application
is called thresholding. The idea behind this global method is simple: replace
each pixel in an image with a black pixel if the pixel intensity value is lower
than a given threshold T. The value of T can be a constant global value
depending only on the intensity value of pixel, or it can be updated auto￾matically. One of the most common automatic thresholding techniques is
called Otsu’s method [34], and it determines the threshold automatically
by minimizing the intraclass intensity variance. An example of segmentation
using local thresholding with Niblack method [35] (center) or the global
Otsu’s method (right) is shown in Fig. 9.15.
Fig. 9.15 shows how global methods are usually preferable for space ap￾plications since the output is much more uniform and robust to local noise.
2D shape representation
Image segmentation offers a useful tool to define homogeneous regions of
an image. However, in most of the cases, it is necessary to identify and
describe a given 2D shape. In general, a 3D object can be represented in a
2D plane and a 2D analysis can be performed on a single image. This sim￾plifies the general case of a 3D object reconstruction where multiple images
are necessary. Several methods exist to represent a 2D shape, and some of
Figure 9.15 Image Segmentationdoriginal image (left), local method (center), global
method (right).
Navigation 509them are tailored for specific applications. These approaches can be very use￾ful for space application when, for example, an image of the target should be
matched with a given database. In this paragraph, an overview of the main
categories of 2D descriptors is presented.
Contour-based shape representation
Mathematical tools have been developed in computer vision to describe
contour and boundaries. These descriptors can be of different forms:
Chain codes
In a simple form, a boundary can be represented by a “chain” of connected
steps of known direction and length. These steps take the form of unit-size
line segments with a given orientation. This definition of chain code was
first provided by Freeman [36].
Geometric boundary-based features
The output of chain codes process can be used to derive simple geometrical
features. Horizontal, vertical, and diagonal elements can be derived depend￾ing on their orientation. This allows to derive the closed-boundary length or
perimeter of the 2D shape. In a similar way, the area of the shape can be
determined, summing the single vector contributions. Finally, a shape factor
parameter can be derived as the ratio between the parameters square and the
area. This dimensionless parameter (therefore scale invariant) is useful to
measure the elongation of the shape.
Fourier transforms
Another way of describing boundaries is through Fourier transforms. In fact,
a complex function can be obtained by assuming to travel along a closed
curve with a constant speed. If this speed is chosen such that a complete rev￾olution is performed in time 2p, Fourier transforms can be applied on the
obtained period function. The obtained Fourier descriptors can be invariant
to translation and rotation in particular cases (see Refs. [37,38]).
Region-based shape representation
For more complex shapes and objects, region-based representation can be
used.
510 Vincenzo Pesce et al.Scalar region descriptors
Very simple heuristic descriptors can be employed to describe a given region
of an image. These include the area of a given region, its horizontal and ver￾tical projections, its eccentricity or elongatedness, and its direction. Other
heuristic descriptors can be also defined or combined, such as rectangularity,
being the ration between the region area and the area of a bounding rect￾angle, or the shape factor described before.
Moments
A very common way to describe regions is by using moment representation.
This method interprets an image as a pdf of a 2D random variable. Papoulis
[39] proposed to use moments that are statistical quantities to describe the
2D random variable. A generic moment of order ðp þqÞ can be described as:
mpq ¼
ZN
N
ZN
N
xp
yq
f ðx; yÞ dxdy
where f ðx; yÞ is the pixel brightness and x and y the pixel coordinates. Please
notice that this quantity varies depending on scaling, translation, and rota￾tion. Central moments, on the other hand, are translation invariant quan￾tities and are expresses as:
mpqc ¼
ZN
N
ZN
N
ðx  xcÞ
p
ðy  ycÞ
q
f ðx; yÞdxdy:
Finally, scale-invariant moment can be found by scaling the central mo￾ments. A nice discussion on moment invariance is given by Ref. [40].
Applicative case - circular object detection
An applicative case to detect circular objects is discussed in this section.
Centroid detection
Centroid detection techniques are usually used when approaching a far
target such as an asteroid, a satellite, or even a planet. In fact, from the po￾sition of the centroid in the image, line-of-side measurement can be recov￾ered and used by a navigation filter. The centroid position of an object can
be recovered by exploiting chain code techniques [41] or, more often,
combining zero and first-order moments. With this technique, often called
Navigation 511Center of Mass technique, the x0 and y0 coordinates of a centroid can be ob￾tained as:
x0
¼ m10
m00
y0 ¼ m01
m00
:
In a similar way, Weighted Center of Mass technique combines zero and
first-order moments, but weighting them depending on the image
brightness.
x0 ¼
R N
N
R N
N xf ðx; yÞW dx dy
R N
N
R N
N f ðx; yÞW dx dy y0 ¼
R N
N
R N
N yf ðx; yÞW dx dy
R N
N
R N
N f ðx; yÞW dx dy
with W being an intensity-dependent weighting function that can be
modeled as W ¼ f p. The exponent p can be chosen as any real positive
number greater or equal to one.
These two simple method and more advanced ones (i.e., Spath algorithm
and Hough transform) are presented and compared in Ref. [42].
Limb detection and fitting
In most of the cases, when approaching a celestial body, its shape may not be
entirely illuminated by the Sun. This results in capturing only a portion of a
circle. In this scenario, before applying centroid detection algorithms, some
refinements are necessary. A possible approach is to detect the object limb
and to fit it to circles and ellipses and only then compute its centroid. The
points belonging to the limb are simply found with an edge-detection algo￾rithm that can be further optimized to take into account atmosphere and
local shape of the planet (a very nice description is given in Ref. [43]).
The next step is to fit the limb points to a curve: this can be done in several
ways, but the two main categories are based on geometrical or algebraic rep￾resentation of the fitting error. A recent paper by Christian [18] offers a very
detailed description of the main curve fitting algorithms and proposes its
own horizon navigation algorithm without the need of any conic fit.
3D vision
2D representation is extremely useful and applied for a wide range of sce￾narios in space. However, especially when dealing with close proximity op￾erations, 3D information of an image became crucial and necessary to
correctly perform proximity navigation. 3D vision is usually a very complex
and active research field. This paragraph does not pretend to be a complete
512 Vincenzo Pesce et al.guide to 3D vision, but it provides the most important concepts and tools to
understand 3D vision and it presents few basic algorithms.
While dealing with 3D vision, two main cases may be discussed:
• Reconstruction. Retrieve 3D information of an object by processing a set
of images.
• Recognition. A priori information of an object is used to perform model￾based matching.
Both are treated in this paragraph after an introduction on the main 3D
geometry concepts.
Projective geometry
Projective geometry is a set of mathematical tools to describe multiple view
geometry. It is used to describe the relations between the 3D points in the
scene, their projections on the camera, and the relations among multiple
camera projections of a 3D scene. Projective geometry represents the essen￾tial mathematical foundation for 3D vision.
Homography
A homography is a projective transformation between two planes or, alter￾natively, a mapping between two planar projections of an image. In other
words, homographies are simple image transformations that describe the
relative motion between two images, when the camera (or the observed ob￾ject) moves. It is the simplest kind of transformation that describes the 2D
relationship between two images. Homography can be mathematically
described by a 3D transformation in a homogeneous coordinates space
and can be expressed as:
s
2
6
6
4
x0
y0
1
3
7
7
5 ¼ H
2
6
6
4
x
y
1
3
7
7
5
where H allows to transform a 2D point ½x; y
T into an image point ½x0
; y0

T .
Several types of homography exist, but the most important ones are sum￾marized in Table 9.4.
It is important to underline that each homography can be decomposed as
H ¼ HPHAHS where HPHA represents an affine transformation while HS
represents a metric (also called Euclidean) transformation.
Navigation 513Table 9.4 Projective transformations.
Transformation 2D example
Projective
Affine
Similarity
Metric/Euclidian
514 Vincenzo Pesce et al.Point correspondence-based homography estimation
Given the set of point correspondence between and after the transformation
½xi; yi
T and 
x0
i
; y0
i
T , there exist several methods to estimate the corre￾sponding homography. In an ideal case, where perfect correspondence exists
and there is no noise in the measurement, the system is linear and admits a
closed form solution. In reality, since the measurements always have a
certain level of noise, an optimal estimation problem has to be solved.
Maximum likelihood estimation The estimation problem can be solved
by an optimal statistical approach like a maximum likelihood estimation.
In this case, the image points are assumed to be random variables with
Gaussian distributions, and the objective is to minimize the reprojection er￾ror. This kind of optimization process is nonlinear and nonconvex, causing
the presence of several local minima. For this reason, a good initial estimate is
necessary to guarantee good convergence. The most common algorithm to
provide an initial guess and then locally applying maximum likelihood esti￾mation is called LevenbergeMarquardt algorithm [44].
Robust estimation Sometimes, the assumptions of Gaussian noise intro￾duced to perform maximum likelihood estimation do not hold. In these
cases, a robust estimator has to be adopted. The standard for robust estima￾tion is the RANSAC algorithm and more details can be found in Ref. [45].
Pinhole camera model
The pinhole camera model approximates the perspective projection of a 3D
scene onto a 2D image. In this mathematical formulation, the camera aper￾ture is a point, and lenses, distortion, and blurring are not considered. In
other words, all the undistorted ray passes through a point (pinhole), and
they are projected onto the focal plane as in Fig. 9.16.
In reality, the pinhole location does not physically exist and, as conse￾quence, the physical camera focal plane and the “apparent” focal plane
used by the pinhole model will not be coincident as in Fig. 9.18.
This is due to the fact that a camera is usually composed of an optical as￾sembly, consisting of multiple lenses in front of the camera sensor. For this
reason, the arriving rays of light don’t pass through a single point as in the
ideal model. To better explain this concept and clarify the pinhole model
approximation for a real camera, some optics concepts have to be introduced
[18]. The main elements of an optical assembly, considering a recent double
Gauss lens, are depicted in Fig. 9.17 and can be summarized as follows:
Navigation 515• Lens aperture (dashed black line). It refers to the opening of the lens’ dia￾phragm through which light passes. This is usually a metallic leaf struc￾ture controlling the amount of light which reaches the sensor.
• Entrance pupil (solid blue line). It refers to the optical image of the physical
aperture, as seen from the object side of the lens. Its location is found by
continuation of the incoming ray of light (solid yellow line) until it
Figure 9.16 Pinhole Camera Model inspired by Ref. [18].
Figure 9.17 Optical assembly schematic.
516 Vincenzo Pesce et al.intersects the optical axis. Its size, instead, is found by continuation of the
incoming light rays (light yellow area) to the entrance pupil location.
• Exit pupil (solid blue line). It refers to the optical image of the physical
aperture, as seen from the camera side of the lens. Its location is found
by back propagating the ray of light (solid yellow line) until it intersects
the optical axis. Its size, instead, is found by back propagating the ex￾tremes of the light rays (light yellow area) from the focal plane until
the exit pupil location.
• Rear nodal point. It refers to the point on the optical axis where the
departing ray crosses the optical axis. The departing ray is a ray with
the same slope of the incident ray (first segment on the right of the solid
yellow line) but starting from the intersection point between the focal
plane and the ray of light (see Fig. 9.18).
Fig. 9.17 shows how the apparent pinhole location for an observer
outside the camera is the entrance pupil. On the other hand, the center of
perspective for an observer inside the camera is at the exit pupil. However,
this latter point cannot be used to construct the pinhole camera model since
the slope of the rays entering the optical assembly is usually different from
the slope of the rays exiting the optical assembly. For this reason, the rear
nodal point has been previously introduced, being a point on the optical
axis where the slope of the exiting ray is the same of entering one. At this
Figure 9.18 Apparent Pinhole and Image Plane, inspired by [18].
Navigation 517point, it is clear that to construct the pinhole model for a real camera, the
geometries of the inside and of the outside of the camera have to be sepa￾rated as in Fig. 9.18. That, an apparent pinhole location can be obtained
by overlapping the entrance pupil and the rear nodal point. Usually, the in￾side geometry of the camera can be abstracted, and the camera model is
derived in terms of image plane. The image plane is an artificial plane parallel
to the focal plane, lying in front of the camera’s center of projection. A com￾mon convention is to place it at unit dept along the camera optical axis.
Given a 3D point in an arbitrary world coordinate system PW , the first
step is to transform from arbitrary world coordinate system to camera￾centered coordinate system PC. This transformation can be written as:
PC ¼ RðPW  tÞ
where R and t describe the rotation and translation, respectively. The
composed matrix ½Rjt is also called extrinsic camera calibration matrix.
Expressing everything in homogeneous coordinates, we obtain:
PC ¼
"
R Rt
0 1 #
PW
A second transformation goes from the camera-centered coordinate sys￾tem PC to image plane coordinates 
up;vp

. Given a 3D point in the camera
coordinate system PC ¼ ½XC; YC;ZC, the pinhole relationship can be
expressed as:
up ¼ XCf
ZC
; vp ¼ YCf
ZC
where f is the focal length. The conversion from the image plane co￾ordinates to pixel coordinates is usually performed through an affine
transformation. The relationship can be expressed as:
u ¼ f
mx
up þ u0; v ¼ f
my
vp þ v0
where ½u0;v0 are the coordinates of the focal’s plane principal point ([0, 0] is
the coordinate system centered in the focal plane) and h
mx; my
i
the x and y
coordinates of the distance between two pixel centers. This relationship can
be easily rewritten in homogeneous coordinates as:
518 Vincenzo Pesce et al.2
6
6
4
u
v
1
3
7
7
5 ¼
2
6
6
4
ax g u0
0 ay v0
001
3
7
7
5
2
6
6
4
up
vp
1
3
7
7
5
Or simply x ¼ Kxp, with ax ¼ f =mx, ay ¼ f
.
my and g the skew coef￾ficient between x and y axis. The matrix K ¼
2
6
6
4
ax g u0
0 ay v0
001
3
7
7
5
is also called
intrinsic camera calibration matrix.
The pinhole camera projection model in full generality is a combination
of the previously described transformations and can be rewritten as:
2
6
6
4
u
v
1
3
7
7
5 ¼ K
2
6
6
6
6
4
100
010
001
0
0
0
3
7
7
7
7
5
"
R Rt
0 1 #
PW ¼ K½Rj  RtPW
with K½Rj Rt ¼ M, being the projection or camera matrix.
Summarizing, this model describes the relationship between a 3D point
in an arbitrary world coordinate system PW and their two projections in im￾age plane pixel coordinates ½u;v. This is done by first converting PW into
camera-centered coordinate system PC through the extrinsic camera calibration
matrix. Then, the pinhole relationship is used to obtain the 2D projections in
image plane coordinates 
up;vp

that are finally converted in pixel coordi￾nates using the intrinsic camera calibration matrix.
Camera calibration from a known scene
Camera calibration from a known scene is a similar problem to homography
estimation, both being homogeneous linear systems subject to noisy mea￾surements. Also in this case, the point correspondences are assumed to be
known and the camera calibration matrix can be obtained by applying sim￾ple linear estimation [46] or by computing the maximum likelihood
estimated.
Navigation 519Multiple views scene reconstruction
Usually, to retrieve 3D information using 2D images and without the pre￾vious knowledge of the object being observed, multiple views of the same
object are necessary. A simple example is represented in Fig. 9.19.
Triangulation
The simplest case, also called triangulation, is when the camera calibration K
and the image points ½u;v
i are given and the objective is to compute the 3D
scene points PW . Triangulation resembles once again the homography esti￾mation or the camera calibration matrix estimation problem. Also in this
case, the computation of the scene points PW closest to all the reprojected
image points ½u;v
i can be carried out through a maximum likelihood esti￾mation that minimizes the reprojection error.
Projective reconstruction
If both camera calibration K and scene points PW are unknown, the prob￾lem is more complex, and we talk about projective reconstruction. To solve
this problem, several images, with their corresponding scene points and
camera calibration matrices are needed. Usually, a first estimate of the cam￾era calibration matrix can be obtained by imposing epipolar constraints (in
the case of two-views geometry), and then, this first rough estimate of the
camera calibration matrix is used to estimate the scene points. This first guess
for both calibration matrix and scene points is then used as the initial guess
Figure 9.19 Multiple views geometry.
520 Vincenzo Pesce et al.for a nonlinear least square algorithm called bundle adjustment [47]. For
more details, please refer to Ref. [48].
Pose estimation
When speaking of vision-based spacecraft relative navigation, the most com￾mon applicative scenario is monocular pose estimation. Monocular pose
estimation consists in estimating the relative pose of a target spacecraft
with respect to a “chaser” spacecraft by relying on 2D images. Contrary
to triangulation where the 2D points correspondences are known and the
3D points have to be estimated, in this case, the observer pose should be esti￾mated given a set of 2D points and the corresponding 3D points. The pose
estimation method consists in solving a Perspective-n-Points problem.
Several methods have been developed during the last decades, and a good
overview is given by Pasqualetto [49].
3D vision summary
In this section, several concepts are introduced and a summary, dividing the
different methods in subcategories, is here presented to provide the reader
with a clear overall picture. Table 9.5 collects all the different methodologies
presented in the section, divided depending on their application.
Two-views geometry
Similar to the human visual system, also for space application, it is common
to deal with two-views geometry. It is important to underline that this is not
only the case of stereovision, when two cameras are used, but also when a
single camera allows for 3D reconstruction comparing two different views.
Epipolar geometry
An example of two-views geometry is given in Fig. 9.20.
The two optical centers are connected by the baseline that intersects the
image planes in the epipoles. An epipolar plane can be defined by considering
any given 3D scene point PW and the two corresponding rays from the op￾tical centers. Let x1 and x2 be the projections of a 3D point onto the two
camera planes, respectively, an algebraic epipolar constraint can be formu￾lated [50] as:
xT
2 Fx1 ¼ 0:
Navigation 521Table 9.5 3D Vision summary.
2D to 2D transformation 3D scene to 2D image
Multiple 2D images
to 3D scene
Method Homography Camera calibration Triangulation Projective
reconstruction
Pose
estimation
Known ½xi; yiT , x0i; y0iT PW , ½u;vi, ½Rj  Rt K, ½u;vi ½u; vi PW , ½u; vi, K
Solve-for H K PW K, PW ½Rj  Rt
522 Vincenzo Pesce et al.The matrix F is called fundamental matrix, and it is very important since it
captures the information between a pair of corresponding points in the two
cameras.
At this point, recalling the relation between image plane coordinates and
pixel coordinates, for each given camera view, we have:
x1 ¼ K1
1 xp1 and x2 ¼ K1
2 xp2.
Substituting the previous expression into the epipolar constraint
x2F x1 ¼ 0, we obtain:
xC
T
2 ExC1 ¼ 0
where E ¼ R*½t is the essential matrix. A nice property of the essential
matrix is that it has rank two and its two nonzero singular values are equal.
This means that the singular values of the essential matrix are invariant to an
orthogonal transformation matrix.
Fundamental and essential matrices have the same purpose, i.e., given a
2D point in one image, they allow to constraint the epipolar line on which
the corresponding 2D point in the second image lays. In other words, they
both relate corresponding points between a pair of images. The difference
between the two is that the fundamental matrix does it in pixel coordinates,
while the essential matrix does it using image coordinates. For this reason,
the fundamental matrix can be seen as a generalization of the essential matrix
when the calibrated camera assumption doesn’t hold.
Figure 9.20 Epipolar geometry.
Navigation 523Relative motion of a camera
The relative motion of a camera given two views can be computed with the
following steps (please note that this equivalent to the projective
reconstruction):
• Compute the fundamental (or essential if the camera is calibrated) matrix
from point correspondences.
• Compute the camera matrices M1 and M2 (please refer to pinhole cam￾era model).
• Given the points correspondence in the two images, compute the 3D
point in space that produces the two image points.
Fundamental matrix estimation
The fundamental matrix, given two views, can be estimated knowing at least
seven point correspondences. This is because epipolar geometry has seven
degrees of freedom. The nine components of the matrix F are subject to
two constraints (a scale factor and that detðFÞ ¼ 0), and, therefore, seven
free parameters have to be found. If seven correspondences between two
images are available, the epipolar problem can be found through the
nonlinear seven-point algorithm. On the other hand, if eight points are
available, the solution becomes linear.
Eight-point algorithm A simple linear algorithm can be used if there are
eight or more point pairs ðx1i
; x2iÞ that allow to solve the system
xT
2 F x1 ¼ 0. This problem can be expressed as xT
2 Fx1 ¼ 
xT
2 5x1

f ¼ 0 where 5 is the Kronecker product and f ¼ ½F11; F21;.; F23; F33
If eight correspondences are available, the presented system admits a single
solution. Please keep in mind that the obtained F is nonsingular in general,
and therefore, a singular matrix Fb can be computed decomposing the
fundamental matrix by SVD: F ¼ UDVT and setting the smallest value
of the diagonal matrix D to zero. Given the modified Db , the new singular
fundamental matrix Fb can be composed back as Fb ¼ UDVb T.
Seven-point algorithm If only seven point-correspondences are available,
the system admits two solutions f and f0 satisfying

uT
2 5u1

f ¼ 
uT
2 5u1

f0 ¼ 0. The main principle of the seven-point al￾gorithm is to find the points that satisfy the constraint detðFÞ ¼ 0. The
complete derivation of the algorithm is out of the scope of this book and
can be found in Ref. [48].
524 Vincenzo Pesce et al.Camera matrix and 3D point computation
The camera matrices M1 and M2 can be directly computed from the funda￾mental matrix. However, the fundamental matrix determines the pair of
camera matrices at best up to a 3D projective transformation. This ambiguity
can be solved, and different methods have been developed to this purpose.
Please refer to Ref. [46] for a detailed derivation. Once the camera matrices
are known, the position of the 3D point can be retrieved. However, also in
this case, the same ambiguity arises. In other words, the whole scene can be
reconstructed up to a 3D homography. Numerical methods have been
developed to determine the intersection of the rays corresponding to the
two cameras and more detailed can be found in Ref. [46].
Stereo correspondence
So far, we have understood the importance of finding reliable point corre￾spondences between two images to retrieve 3D information. In this para￾graph, an overview on how these correspondences are identified is
presented. Even though there exist other stereo correspondence methods
(e.g., correlation based), the most widely applied method uses features￾based correspondence. A feature is a salient point in the image that can be
identified across different frames. Examples of feature points are edges, lines,
corners, and so on. Several methods exist to extract these feature points, and
the most important are detailed in Ref. [51]. Without entering into the algo￾rithmic details, one of the most classical approaches to solve stereo corre￾spondence is the Pollard-Mayhew-Frisby (PMF) method [52]. Given two
sets of feature points, the PMF algorithm produces the best correspondences
by first enforcing the epipolar constraint between the two images. The score
of a match is incremented if other possible matches are found that do not
violate a disparity gradient limit. The disparity gradient is an indication of
the relative disparity (i.e., difference of the location of an object seen by
two different views) between two pairs of points.
Application cases - from subpixel to resolved object
The image processing techniques that are introduced in this chapter can be
applied during different phases of spacecraft missions. In this section, a clas￾sification depending on the size of the target (in pixel) in the camera frame is
provided. Please note that the pixel size on the sensor cannot directly be
related to the relative distance if the sensor characteristics are not known.
Navigation 525Subpixel
When the target is very far from the observer or if it is very small, the
apparent size of the object on the camera sensor can be equal or less than
one pixel. In this case, the only measurement that can be retrieved is the
line of sight of the target, described by the 2D coordinates on the camera
plane. It is important to underline that, in this case, it is necessary to have
a signal-to-noise ratio of the target high enough to obtain a valid measure￾ment and to distinguish the object from background noise. Another aspect
to take into account is that, in this scenario, it is not always easy to discrim￾inate between the target and a star in the background. For this reason, it is
usually important to collect multiple subsequent frames to distinguish an
artificial object from the starry background. In fact, if active pointing is avail￾able, the target object will result in a dot of few pixels while the stars will
move uniformly in the background. On the contrary, if active pointing is
not available, the target object will produce another streak that will most
likely have a different orientation with respect to the stars. An artistic and
simplified representation of the two scenarios is reported in Fig. 9.21.
Few tenths of pixels
If the target object is sufficiently close or big, its projection on the camera
sensor can be large enough to perform some basic image processing tech￾niques. Even if the object projection is few tenths of pixels wide, only
LOS information can be retrieved from an image. To this purpose, slightly
more accurate algorithms can be used, and basic centroid and limb detection
algorithms can be applied.
Figure 9.21 Far object detectiondactive pointing (left), nonactive pointing (right).
526 Vincenzo Pesce et al.Resolved object
When the characteristics of the object are clearly identifiable and the object
is resolved in the camera sensor, several techniques can be exploited to
extract not only LOS but also pose information. Depending on the type
of target, different approaches can be adopted.
Known object
When the object is known, model-based algorithms are usually employed.
For simple shapes, the preferred approach is a 2D shape matching technique
that can provide accurate pose measurement. When the object is complex, a
full 3D model matching technique should be implemented. In this case, the
obtained 2D descriptors are matched against the correspond descriptor of the
reference 3D model. Once the 2D-3D correspondence is obtained, the pose
can be retrieved [53]. Similarly, in the case of relative navigation around a
known planet (or moon), the observed features and landmarks observed
on the surface can be matched with a known database.
Unknown object
When the object is unknown or information about the approached object
cannot be used, different techniques should be employed. One possibility
is to rely on stereo vision algorithm [54], able to extract 3D information pro￾cessing only 2D images acquired with a known baseline. Another possibility
is to use Simultaneous Localization and Mapping (SLAM) techniques [55].
As the name suggests, SLAM is a powerful tool to perform localization while
building a map of the environment. While this method is extremely com￾mon in robotics applications, its use in space application has been limited
by the significant computational effort. Moreover, good initialization or
loop closure [56] is necessary to achieve satisfactory accuracy and both not
easily accessible in space applications. In the case of planetary navigation,
if the spacecraft is too close to the surface and, therefore, it cannot distinguish
any landmark in the available database, feature-tracking techniques are
adopted (see Chapter 14 - Applicative GNC Cases and Examples for
more details).
Image processing and spacecraft navigation
In the previous sections, some useful instruments to process images have
been introduced. The information acquired by processing an image with
the presented methodologies has to be used by the navigation filter to
improve the knowledge of the spacecraft state. Also in this case, two main
Navigation 527approaches exist, and we will refer to them as loosely coupled or tightly coupled
architecture.
Loosely coupled. Position and attitude information are computed by an
image processing algorithm prior to the navigation filter, and only pose mea￾surement is fed to the navigation. In this way, the filter is not aware of the
preprocessing of the image, but it processes only the derived pose
information.
Tightly coupled. Centroids, feature points, landmarks, or other image
characteristics are directly used as inputs to the navigation filter as measure￾ments. The filter processes this information to provide a state estimate.
Loosely coupled architecture is preferred when the robustness of the im￾age processing algorithm is challenged by the scenario (e.g., fast relative dy￾namics) leading to highly variable measurements as input to the filter. On
the contrary, not many image processingebased pose estimation algorithms
provide an indication of the accuracy of the provided solution, leading to a
very uncertain value of the measurement covariance and, therefore, low fil￾ter robustness if used in combination to loosely coupled architectures. How￾ever, tightly coupled methods usually need to process a high number of
measurements (e.g., feature points) increasing the overall filter computa￾tional complexity. Furthermore, the resulting measurement equation is usu￾ally more complex, having to describe the relationship between the state and
the image features. The choice of the best navigation filter architecture is
highly dependent on the scenario, on the kind of image processing tech￾niques applied, and on the available hardware resources, and a general
rule of thumb does not exist. The choice should be based on the general
considerations drawn before, considering the specific application.
Navigation budgets
During spacecraft navigation design process, the performance of a nav￾igation filter has to be evaluated. In particular, three elements are usually
used to characterize navigation performance:
• Estimation error.
• Robustness to modeled uncertainties and neglected effects.
• Convergence.
These parameters are valid for both batch and sequential navigation
filters.
528 Vincenzo Pesce et al.Estimation error and filter robustness
With the term “estimation error”, we define the error between the esti￾mated state bx and the reference true state value, x. At a given time instant
k, it can be expressed as:
ek ¼ xk  bxþ
k :
While evaluating the performance of a navigation filter, this quantity is
not sufficient for a probabilistic analysis of the filter accuracy. For this reason,
Monte Carlo campaigns are usually run to assess navigation performance and
filter robustness to uncertain parameters and unmodeled effects. This kind of
analyses allows to assess the estimator performance, usually described by the
RMSE, which is defined as:
RMSEMC ¼
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
1
M
X
M
i¼1
eT
k;i
ek;i
vuut
with M being the number of total Monte Carlo simulations. The RMSE
is widely adopted as performance parameter because it is the best approxima￾tion of the standard deviation of the estimation error. Dealing with proba￾bilistic analysis, the RMSE is the most useful metric to characterize
navigation performance. Please, keep in mind that the RMSE exists also
for a single filter run where the summation is performed over the simulation
time and not over the Monte Carlo runs. In this case, the RMSE takes the
form of RMSE ¼
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
1
T
P
T
i¼1
eT
k;i
ek;i
s
with T being the simulation time. This
metric can be used, once the filter has converged, to evaluate the steady￾state estimation error, but it does not capture the statistical properties and
performance of the filter, being computed over a single run.
Similarly, it is possible to define another metric that describes the mean
error rather than the standard deviation. This parameter is usually called
average Euclidian error or mean absolute error (MAE) and it can be
expressed as:
MAE ¼ 1
M
X
M
i¼1
ffiffiffiffiffiffiffiffiffiffiffiffi
eT
k;i
ek;i
q
:
MAE offers a more immediate and practical concept of error, describing
an average absolute error, but it is seldomly used for statistical and probabi￾listic analysis, during navigation filter characterization.
Navigation 529Please note that, due to the stochastic nature of the filter formulation, in
theory, it would not be necessary to perform a Monte Carlo campaign to
evaluate the statistical properties of a filter. By definition, in fact, the covari￾ance of the estimation error already embeds the information of the probabil￾ity distribution of the filter error, i.e., Pi;i ¼ diag
s2
i;i
	
with si;i being the
estimation error standard deviation for each state. Strictly speaking, this is
true for an ideal linear KF, when the system and observation models and
their uncertainties are exactly known. In this case, the estimation covariance
converges to a steady-state value that bounds the overall estimation error:
RMSE < 3 ffiffiffiffiffiffi
Pi;i
p . In real cases, with nonlinear models, uncertain dynam￾ical and observation models, the steady-state convergence property of the
filter does not hold. However, a common practice with sequential filter is
to plot the 3 ffiffiffiffiffiffi
Pi;i
p curves (corresponding to the 3s bound) along
with the estimation error for a single run of the filter. In fact, if the filter
is properly tuned, these curves allow to have a preliminary quantitative
idea of the maximum expected estimation error. On the other hand, they
can also be used to check the consistency of the filter tuning for a given sce￾nario. In other words, for a given Monte Carlo campaign, it can be assumed
that RMSEMCzsi;i ¼ ffiffiffiffiffiffi
Pi;i
p . A simple example of a generic EKF Monte
Carlo campaign of 50 runs and the corresponding 3 ffiffiffiffiffiffi
Pi;i
p curves is re￾ported in Fig. 9.22.
It can be observed that the estimation error is bounded by the  3 ffiffiffiffiffiffi
Pi;i
p
curves for the complete duration of the simulation. Once again, these curves
Figure 9.22 50 runs Monte Carlo campaign.
530 Vincenzo Pesce et al.allow to have a preliminary evaluation of the maximum estimation error
achievable for a given scenario. Please keep in mind that Monte Carlo anal￾ysis is still necessary to validate the filter in a probabilistic sense.
Convergence
The definition of convergence for a sequential or a batch filter is conceptu￾ally different. In general, a navigation filter reaches convergence if the esti￾mate error is lower than a threshold. In a batch filter, this evaluation is
performed for each algorithm iteration and used as stopping condition. In
a sequential filter, the convergence is achieved slowly, processing measure￾ments at each instant of time and, therefore, gradually improving the estima￾tion error. A graphical representation of this difference is depicted in
Fig. 9.23.
The convergence threshold can be imposed directly on the estimation
error or on the observation residual. During the design phase or postprocess￾ing analysis, it is common to use the estimation error as reference. However,
for on-board applications, the estimation error cannot be determined being
the “true” spacecraft state not available. For sequential filters, a common
practice is to evaluate the speed of convergence in a qualitative way. This
qualitative characterization is usually sufficient for most of the spacecraft
navigation applications. However, more rigorous ways of quantifying the
convergence of a filter exist. These techniques can be used for on-board
application. Since the “true” spacecraft state is not available, the observation
residual can be used to perform a convergence check. In particular, the
observation normalized residual is computed as:
Figure 9.23 Convergence for batch and sequential filter.
Navigation 531rn ¼ yk  h

bx
k ; 0

sv
with yk being the sensor output, hk the observation model function, and
sv the measurement noise standard deviation. Convergence is achieved for
3  rn  3. To give a more practical interpretation of this constraint, it is
important to remind that the observation residual quantifies the error be￾tween the actual measurement and the measurement predicted by the filter.
If the state is estimated correctly (i.e., the estimation error is low), the mea￾surement model will provide a predicted measurement very close to the cur￾rent value, and, therefore, the observation residual will be small. On the
contrary, if the estimation error is high, this will directly result in a large dif￾ference between the measurement and its predicted value and, therefore, in
a large value of the observation normalized residual. The exact same princi￾ple can be used on-board to detect filter divergence and consequently reset
the estimation process. Please, keep in mind that this criterion fails if some of
the filter states are not observable. In this case, the direct measurement of a
given state is not available and, therefore, the state can converge to a value
that is far from its true value but still minimizing the measurement residual.
Therefore, the residual will eventually be inside the convergence threshold,
but the value of estimation error may be very high.
Effect on the GNC chain
During real spacecraft operations, the “true” state of the spacecraft is un￾known. The navigation is the functional block of the GNC chain that esti￾mates this value and provides this information to the guidance, control, and
mode manager. Let’s recall the high-level working principle of a GNC with
the help of Fig. 9.24.
Figure 9.24 GNC chain.
532 Vincenzo Pesce et al.Given a guidance profile and the current spacecraft best estimate pro￾vided by the navigation, the control tries to bring the spacecraft as close as
possible to the guidance reference trajectory. If we imagine an ideal
controller, without any actuator limitation, capable of instantaneously set
to zero the error between the estimated state and the reference one, there
would be still a residual error due to the navigation performance. With
this simple example, it’s clear that the navigation poses an intrinsic limit to
the accuracy of the whole GNC system. Moreover, high error in the nav￾igation can lead to actuator saturation even in conditions when it would
not be necessary, leading to uncontrollability of the spacecraft. Finally, it’s
easy to imagine the dramatic consequences of undetected filter divergence
on the entire mission.
Another potentially fatal outcome of poor navigation performance
would be caused by its interaction with the mode manager. In fact, if a given
mode is triggered due to wrong state estimation, this could affect the good
behavior of the GNC system and jeopardize the mission success.
Navigation implementation best practices
In this chapter, the main practical aspects to take into account while
designing and implementing a navigation filter are described.
How to choose the right sequential filter?
There isn’t a rule of thumb to select the best sequential filter for a given
application, but some aspects may be taken into account while designing
spacecraft navigation algorithms:
• Computational constraints. Most of the time, the selection of a given
sequential estimator is driven by the available computational power. In
general, a more accurate estimator implies a higher computational cost,
e.g., PFs. However, the available computational power of a spacecraft
is usually limited. For this reason, the computational cost of a given so￾lution is, most of the time, the main driver while performing a navigation
architecture tradeoff.
• Dynamical and observation model. Another critical aspect to consider while
designing a navigation filter is to analyze the different available dynamical
and observation models, understanding their complexity and accuracy.
In particular, if the dynamical or observation models are nonlinear, the
choice of the navigation filter will be limited to nonlinear estimators.
Moreover, the complexity of a model will drive the selection of a given
Navigation 533estimator. In fact, if the selected dynamical model is very complex, the
UKF may not be the best option as it propagates the dynamics for a given
number of sigma points and not just once, as done by a standard EKF.
Design, implementation, tuning, and useful checks for
sequential filters
In this section, the most important parameters to take into account for a
proper design, implementation, and tuning of a sequential estimator are
detailed. Furthermore, some useful checks to be performed in order to assess
the filter performance are presented.
General design considerations
While designing a navigation filter, some general aspects can be considered:
• State vector. The first quantity to define during the implementation of a
sequential estimator is the state vector. The state vector collects all the
states that have to be estimated, and it has to be carefully selected. A
nice feature of sequential estimators is their capability of estimating states
that are not directly measurable, e.g., it is possible to estimate velocity by
only measuring position. However, it is very important to consider if the
elements of the state vector are observable. By definition, an unobserv￾able state is one about which no information may be obtained through
the observation model, given the available measurements. If a given state
is unobservable, its filter estimate will not converge to a meaningful so￾lution. For this reason, it is important to evaluate the observability of the
state vector elements considering the available measurements and obser￾vation model.
• Dynamical and observation model. In general, it is preferable to select the
best models available to describe the dynamical evolution of the state.
Still, it is important to take into account their computational load. A sim￾ple example is given by the dynamical propagation of a spacecraft orbit￾ing around a given body. The simplest way of describing its motion is by
using the Kepler’s equation, solution of the restricted two-body prob￾lem. Of course, considering other gravitational attractors and other
sources of perturbation (Chapter 3 - The Space Environment) would
significantly improve the precision of the state estimate but with a much
higher computational load. For this reason, the selection of the appro￾priate dynamical and observation models is strictly related to the required
navigation performance. As generic consideration, recalling the working
principle of sequential estimators, if the required navigation performance
534 Vincenzo Pesce et al.is much higher (i.e., small estimation error) than the expected mea￾surement accuracy, the dynamical model precision must be in the same
order of magnitude of the required performance. On the contrary, if the
expected measurement error is small, it is possible to relax the constraint
on the dynamical model.
• Filter update frequency. The filter working frequency and the dynamical
propagation frequency are usually coincident. In particular, the dynamics
update has to guarantee a smooth state transition between one time step
and the following one. Having measurements available at higher fre￾quency than the one of the dynamical propagation would imply losing
the measurement information (if measurement averaging or buffering
is not performed). Depending on the navigation filter application, an
appropriate update frequency has to be selected. Fast dynamical environ￾ments will, in general, require a higher update frequency.
• Measurement and their time delay. Dealing with multiple sensors may lead
to have measurements available at different time instants. A sequential fil￾ter can usually deal with multiple frequency measurements, but the algo￾rithmic complexity may significantly increase. For real application, the
latency of the measurements is very important. In general, measurements
need to be processed at the time they are taken, considering their latency.
This is usually done by backward propagating the state vector from filter
time to measurement time tm, using the dynamical model. The state at tm
is then used to compute the predicted measurement and measurement
covariance at tm.
Implementation workflow
The main steps to correctly implement a sequential estimator are presented
as follows:
• Define the state vector.
• Implement the model for state dynamical propagation. Please note that if
the dynamical model is continuous, a state nonlinear discrete propagation
has to be implemented. This is usually done by using discrete time inte￾grators such as RungeeKutta.
• Compute the STM and propagate the state covariance. Please keep in
mind that the expression of the STM for linear systems is immediate.
However, for nonlinear estimators, it has to be numerically or analyti￾cally computed.
• Implement the measurement model for all the available sensors.
Navigation 535• Implement sequential estimator formulae for covariance update and state
estimation. If we consider Kalman estimators (KF, EKF, UKF), different
ways of performing the measurement update step exist (e.g., Joseph for￾mula, UD factorization). It is important to select the one ensuring filter
stability. For more details, please refer to Refs. [2,26].
Implementation efficiency
To improve sequential filter efficiency, some best practices can be followed:
• Sequential measurements. If we recall the KF gain computation, Kk ¼
P
k HT
k

HkP
k HT
k þ Rk
1
, we can notice that this implies a computa￾tional expensive matrix inversion. If the measurements are not corre￾lated, Rk is diagonal by construction (if not, it can be diagonalized by
Cholesky decomposition). In this particular case, the matrix inversion
of Rk can be replaced by a scalar division of the diagonal elements of Rk:
• Joseph form. The use of the Joseph form is a common practice while
implementing sequential filters. The main benefit of this approach is
that it ensures the positive semidefiniteness of the estimation error
covariance matrix at the cost of slightly higher computational effort. Jo￾seph form update can be written as:
Pþ
k ¼ ðI  KkHkÞP
k1/Pþ
k
¼ ðI  KkHkÞP
k1ðI  KkHkÞ
T þ KkRkKT
k
• Covariance factorization. This operation usually reduces the arithmetic op￾erations for state and measurement covariance update. The most used
covariance matrix factorization method is the UDU technique. The ben￾efits of this method are particularly evident when the state vector is large
and, therefore, numerical issues are likely to occur. UDU factorizations
are necessary for on-board implementations being numerically stable and
computational efficient. The precise derivation of UDU factorization for
state and measurement covariance update will not be presented here (the
reader can see Ref. [32] for the detailed implementation), but the generic
formulas are recalled:
P
k ¼ U
k D
k UT
k ¼ Fk1Uþ
k1Dþ
k1UþT
k1FT
k1 þ Qk1
and for the measurement update step:
Pþ
k ¼ Uþ
k Dþ
k UþT
k ¼ ðI  KkHkÞU
k1D
k1UT
k1
with Kk ¼ U
k D
k UT
k HT
k

HkU
k D
k UT
k HT
k þ Rk
1
.
536 Vincenzo Pesce et al.How to choose the right batch filter?
Even if batch filters techniques are different than the ones employed in
sequential estimation, the same high-level principles can be applied in the
design and implementation of both types of filters. There are of course small
differences that are presented below:
• Computational constraints. The main difference is the fact that computa￾tional constraints are typically not an issue for batch estimation tech￾niques. As have been mentioned during the navigation chapter in this
book, batch filters are usually employed for trajectory reconstruction
on-ground. Therefore, the computational constraints inherent to on￾board estimation techniques are not present, and, for that reason, batch
estimators usually include more complex dynamical and measurement
models, as well as higher number of variables and parameters in the state
vector.
• Dynamical and measurement models. As stated above, since computational
constraints are not an issue with batch filtering techniques on-ground,
the dynamical and measurement models selected for trajectory recon￾struction are typically very high detailed, taking into account a higher
number of parameters to model the different source of errors for a given
trajectory and, therefore, targeting a higher precision solution. In any
case, when selecting the dynamical and measurement modeling, it is
important to have a correct balance among all the elements in the
filtering process for a given scenario: even if there are no computational
constraints, it probably makes no sense to include very detail models of
perturbations that are negligible in a concrete situation (e.g., modeling
Martian zonals and tesserals in an interplanetary trajectory).
• Partial derivatives calculation. Batch filters require the propagation of the
measurements to the same epoch in order to proceed with the state up￾date step, as explained before. For this reason, it is important to assure
that the partial derivatives to generate the STM are correctly calculated
for the complete trajectory arc that is reconstructed. When partial deriv￾atives are calculated numerically, the d applied to the independent vari￾able needs to be adapted to the dynamical environment: for example,
when calculating the derivative with respect to a position component,
let’s say “x,” the dx for an interplanetary arc can be in the order of
10 km (have in mind that 10 km are a very small position variation for
interplanetary distances that are in the order of hundreds of million
km). But, if we are reconstructing descent trajectory to an asteroid,
Navigation 53710 km can be the order of magnitude of the asteroid size. Therefore, in
this second situation, the dx can only be in the order of several meters,
instead of km. The calculation of partial derivatives is a key factor in
batch filtering techniques and a common cause of divergence in the filter
if not done properly.
Implementation workflow
In this paragraph, the main steps to correctly implement a batch estimator are
presented.
• Define the state vector, including all parameters deemed necessary for the
models required in the trajectory reconstruction.
• Implement the model for state dynamical propagation. Trajectory recon￾struction models are usually more complex and require higher number of
parameters for implementation.
• Implement the measurement model for all the available sensors.
• Compute the STM and propagate measurements to refer them to the
same epoch.
• Implement batch estimator formulae for covariance update and state esti￾mation. The selection of the estimator needs to take into account the
possible numerical problems that can arise during the filtering process.
• Propagate the state and the covariance until the end of the trajectory arc
reconstructed using the numerical propagator and the STM, respectively.
Navigation filters tuning
Tuning usually represents the hardest task while designing a navigation filter.
For a person approaching navigation filters for the first time, tuning may
seem “art” driven by experience. However, if the theoretical principles
introduced are clear, some general rules and checks may be identified to
properly tuning an estimator:
• Select initial state value. If no data are available, it is common practice to
randomly select the initial state from a normal distribution with s
extracted from the state covariance matrix P0.
• Choose the appropriate values for process and measurements covariance matrices.
Conceptually, it may be useful to think about the process and measure￾ment covariance as two parameters to weight how much the filter trusts
the dynamical model or the measurements. In general, the selection of
the measurement covariance matrix R is quite straightforward if the
sensor sensitivity is known. In fact, R contains the variance of the avail￾able measurements. The selection of the process covariance matrix Q can
538 Vincenzo Pesce et al.be slightly more complicated. For preflight detailed design studies, the
“real world” is simulated, so the expected error of the filter dynamical
model with respect to the “real” dynamics can be computed. This is
the first iteration value that a filter designer should select as Q. When
the “real-world” simulator is available, it is also possible to run the
mission simulation many times, generating an ensemble of parallel re￾sults, performing a Monte Carlo analysis. On the other hand, during and
after the actual mission, it is not possible to know the “real” state.
Therefore, the value of Q cannot be determined beforehand, but it can
be selected iteratively based on the best knowledge of the environment
and dynamical model uncertainties.
• Perform a first check of the dynamical model. Run in parallel the “real-world”
model and the filter without performing any measurement update (i.e.,
pure propagation), using the same initial condition and check the state
difference. This check is useful to verify if the dynamical model inside the
filter is implemented correctly, and it also gives an indication of the
process error covariance. Once a value for Q is selected, this step can be
repeated, propagating also the state covariance with
P
k ¼ Fk1Pþ
k1FT
k1 þ Qk1 and check if the error between the “real￾world” state and filter propagation state is bounded by the 3s of P
k .
This check provides a first indication on the goodness of the tuning of Q.
This is an important step to avoid the phenomenon of filter smugness. As
explained before, if the value of Q is too small, the resulting P may be
too optimistic. In this condition, the filter starts rejecting measurements
while trusting only its dynamical model. This may result in stability
problems especially for real-world applications.
• Perform a check on the observation model. Run the filter update step only, us￾ing the “real” state to compute the measurement. Check the error be￾tween the real and predicted measurements (i.e., innovation) and see if
it is bounded by the selected R matrix.
• Perform a final check on the estimation error. It is common practice to plot the
state error (with respect to the “real” state) along with the 3s of Pþ
k . In
general, a good tuning guarantees that the estimation error is always
bounded by the 3s curves.
• Check residuals. The difference between “real-world” measurements and
“estimated world” measurements are the residuals. If trajectory recon￾struction has been performed correctly, residuals should present a flat
behavior with average values in the order of the measurement noise and
Navigation 539centered around zero, which would imply that the measurement has
been modeled correctly and estimated state is close to “real-world” state.
If residuals present drifts, or are centered around a different value than
zero, this implies that there is a nonmodeled effect in the filtering process,
such a bias or an error source that is not taken into account.
References
[1] V. Pesce, A.A. Agha-mohammadi, M. Lavagna, Autonomous navigation & mapping
of small bodies, in: 2018 IEEE Aerospace Conference, IEEE, March 2018, pp. 1e10.
[2] R.E. Kalman, A new approach to linear filtering and prediction problems, Journal of
Basic Engineering 82 (1) (1960) 35e45, https://doi.org/10.1115/1.3662552.
[3] R.E. Kalman, R.S. Bucy, New results in linear filtering and prediction theory, Journal
of Basic Engineering 83 (1) (1961) 95e108, https://doi.org/10.1115/1.3658902.
[4] T. Pappas, A. Laub, N. Sandell, On the numerical solution of the discrete-time alge￾braic Riccati equation, IEEE Transactions on Automatic Control 25 (4) (1980)
631e641.
[5] D. Simon, Optimal State Estimation: Kalman, H Infinity, and Nonlinear Approaches,
John Wiley & Sons, 2006, https://doi.org/10.5860/choice.44-3334.
[6] J. Bellantoni, K. Dodge, A square root formulation of the Kalman-Schmidt filter,
AIAA Journal 5 (7) (1967) 1309e1314, https://doi.org/10.2514/6.1967-90.
[7] E.A. Wan, R. Van Der Merwe, The unscented Kalman filter for nonlinear estimation,
in: Adaptive Systems for Signal Processing, Communications, and Control Symposium
2000. AS-SPCC. The IEEE 2000, IEEE, 2000, pp. 153e158.
[8] N.J. Gordon, D.J. Salmond, A.F. Smith, Novel approach to nonlinear/non- Gaussian
Bayesian state estimation, in: IEE Proceedings F (Radar and Signal Processing), vol
140, IET, 1993, pp. 107e113, https://doi.org/10.1049/ip-f-2.1993.0015.
[9] F. Gustafsson, Particle filter theory and practice with positioning applications, IEEE
Aerospace and Electronic Systems Magazine 25 (7) (2010) 53e82, https://doi.org/
10.1109/maes.2010.5546308.
[10] S.F. Schmidt, Application of state-space methods to navigation problems, Advances in
Control Systems 3 (1966) 293e340. Elsevier.
[11] B.D. Tapley, B.E. Schutz, G.H. Born, Statistical Orbit Determination, 2004.
[12] G.J. Bierman, Factorization Methods for Discrete Sequential Estimation, Academic
Press, 1977.
[13] P.S. Maybeck, Stochastic Models, Estimation, and Control, Academic Press, 1979.
[14] G. Xu, GPS. Theory, Algorithms and Applications, second ed., Springer, 2007.
[15] J.A. Klobuchar, Ionospheric time-delay algorithm for single-frequency GPS users,
IEEE Transactions on Aerospace and Electronic Systems (3) (1987) 325e331.
[16] A. Hauschild, Basic Observation Equations, in: Handbook of Global Navigation Sat￾ellite Systems, in: P.J. Teunissen, O. Montenbruck (Eds.), Springer Handbook of
Global Navigation Satellite Systems, vol 10, Springer International Publishing, New
York, NY, USA, 2017, pp. 561e582.
[17] J.F. Zumberge, M.B. Heflin, D.C. Jefferson, M.M. Watkins, F.H. Webb, Precise point
positioning for the efficient and robust analysis of GPS data from large networks, Jour￾nal of Geophysical Research: Solid Earth 102 (B3) (1997) 5005e5017.
[18] J.A. Christian, A tutorial on horizon-based optical navigation and attitude determina￾tion with space imaging systems, IEEE Access 9 (2021) 19819e19853.
[19] S.I. Sheikh, D.J. Pines, P.S. Ray, K.S. Wood, M.N. Lovellette, M.T. Wolff, Spacecraft
navigation using X-ray pulsars, Journal of Guidance, Control, and Dynamics 29 (2006)
49e63.
540 Vincenzo Pesce et al.[20] G. Wahba, A least squares estimate of satellite attitude, SIAM Review 7 (3) (1965),
409-409.
[21] G.H. Golub, C.F. Van Loan, Matrix Computations, JHU Press, 2013.
[22] J.E. Keat, Analysis of least-squares attitude determination routine DOAOP, Technical
Report CSC/TM-77/6034, Computer Sciences Corporation (February 1977),
https://doi.org/10.5281/ZENODO.32291.
[23] M.D. Shuster, The QUEST for better attitudes, Journal of the Astronautical Sciences
54 (3) (2006) 657e683.
[24] F.L. Markley, J.L. Crassidis, Fundamentals of Spacecraft Attitude Determination and
Control, Space Technology Library, Springer, New York, 2014.
[25] V. Pesce, M.F. Haydar, M. Lavagna, M. Lovera, Comparison of filtering techniques for
relative attitude estimation of uncooperative space objects, Aerospace Science and
Technology 84 (2019) 318e328.
[26] F.L. Markley, Multiplicative vs. additive filtering for spacecraft attitude determination,
Dynamics and Control of Systems and Structures in Space 467e474 (2004) 48.
[27] E.J. Lefferts, F. Landis Markley, M.D. Shuster, Kalman filtering for spacecraft attitude
estimation, Journal of Guidance, Control, and Dynamics 5 (5) (1982) 417e429.
[28] R. Mahony, T. Hamel, J.-M. Pflimlin, Complementary filter design on the special
orthogonal group SO (3), in: Proceedings of the 44th IEEE Conference on Decision
and Control, IEEE, 2005.
[29] R. Mahony, T. Hamel, J.-M. Pflimlin, Nonlinear complementary filters on the special
orthogonal group, IEEE Transactions on Automatic Control 53 (5) (2008)
1203e1218.
[30] A. Colagrossi, M. Lavagna, Fault tolerant attitude and orbit determination system for
small satellite platforms, Aerospace 9 (2022) 46, https://doi.org/10.3390/
aerospace9020046.
[31] R. Opromolla, G. Fasano, G. Rufino, M. Grassi, A review of cooperative and unco￾operative spacecraft pose determination techniques for close-proximity operations,
Progress in Aerospace Sciences 93 (2017) 53e72, https://doi.org/10.1016/
j.paerosci.2017.07.001.
[32] J.R. Carpenter, C.N. D’Souza, Navigation Filter Best Practices, 2018.
[33] G.J. Awcock, T. Ray, Applied Image Processing, Macmillan International Higher Ed￾ucation, 1995.
[34] N. Otsu, A threshold selection method from gray-level histograms, IEEE transactions
on Systems, Man, and Cybernetics 9 (1) (1979) 62e66.
[35] W. Niblack, An Introduction to Digital Image Processing, Strandberg Publishing
Company, 1985.
[36] H. Freeman, On the encoding of arbitrary geometric configurations, IRE Transactions
on Electronic Computers 2 (1961) 260e268.
[37] T.P. Wallace, P.A. Wintz, An efficient three-dimensional aircraft recognition algo￾rithm using normalized Fourier descriptors, Computer Graphics and Image Processing
13 (2) (1980) 99e126.
[38] T. Pavlidis, F. Ali, Computer recognition of handwritten numerals by polygonal
approximations, IEEE Transactions on Systems, Man, and Cybernetics 6 (1975)
610e614.
[39] A. Papoulis, S.U. Pillai, Probability, Random Variables, and Stochastic Processes,
McGraw-Hill, Boston, MA, 1991.
[40] M. Savini, Moments in image analysis, Alta Frequenza 57 (2) (1988) 145e152.
[41] P.W. Kitchin, A. Pugh, Processing of binary images, in: Robot Vision, Springer, Ber￾lin, Heidelberg, 1983, pp. 21e42.
[42] R. Gohane, S. Adatrao, M. Mittal, Comparison of various centroiding algorithms to
determine the centroids of circular marks in images, in: 2016 International Conference
Navigation 541on Computing, Analytics and Security Trends (CAST), IEEE, December 2016,
pp. 162e166.
[43] J.A. Christian, Accurate planetary limb localization for image-based spacecraft
navigation, Journal of Spacecraft and Rockets 54 (3) (2017) 708e730.
[44] W.H. Press, S.A. Keukolsky, W.T. Vettering, B.P. Flannery, Levenberg-Marquardt
Method. Numerical Recipes in C: The Art of Scientific Computation, 1992,
pp. 542e547.
[45] M.A. Fischler, R.C. Bolles, Random sample consensus: a paradigm for model fitting
with applications to image analysis and automated cartography, Communications of
the ACM 24 (6) (1981) 381e395.
[46] R. Hartley, A. Zisserman, Projective geometry and transformations of 2D. Multiple
View Geometry in Computer Vision, 2003.
[47] B. Triggs, P.F. McLauchlan, R.I. Hartley, A.W. Fitzgibbon, Bundle adjustmentda
modern synthesis, in: International Workshop on Vision Algorithms, Springer, Berlin,
Heidelberg, September 1999, pp. 298e372.
[48] M. Sonka, V. Hlavac, R. Boyle, Image Processing, Analysis, and Machine Vision,
Cengage Learning, 2014.
[49] L.P. Cassinis, R. Fonod, E. Gill, Review of the robustness and applicability of monoc￾ular pose estimation systems for relative navigation with an uncooperative spacecraft,
Progress in Aerospace Sciences 110 (2019) 100548.
[50] H.C. Longuet-Higgins, A computer algorithm for reconstructing a scene from two
projections, Nature 293 (5828) (1981) 133e135.
[51] D. Jiang, J. Yi, Comparison and study of classic feature point detection algorithm, in:
2012 International Conference on Computer Science and Service System, IEEE,
August 2012, pp. 2307e2309.
[52] S.B. Pollard, J.E. Mayhew, J.P. Frisby, PMF: a stereo correspondence algorithm using a
disparity gradient limit, Perception 14 (4) (1985) 449e470.
[53] V. Pesce, R. Opromolla, S. Sarno, M. Lavagna, M. Grassi, Autonomous relative nav￾igation around uncooperative spacecraft based on a single camera, Aerospace Science
and Technology 84 (2019) 1070e1080.
[54] V. Pesce, M. Lavagna, R. Bevilacqua, Stereovision-based pose and inertia estimation of
unknown and uncooperative space objects, Advances in Space Research 59 (1) (2017)
236e251.
[55] H. Durrant-Whyte, D. Rye, E. Nebot, Localization of autonomous guided vehicles,
Robotics Research (1996) 613e625.
[56] B. Williams, M. Cummins, J. Neira, P. Newman, I. Reid, J. Tardos, A comparison of 
loop closing techniques in monocular SLAM, Robotics and Autonomous Systems 57
(12) (2009) 1188e1197.
542 Vincenzo Pesce et al.CHAPTER TEN
Control
Francesco Cavenago1
, Aureliano Rivolta2
, Emanuele Paolini2
,
Francesco Sanfedino3
, Andrea Colagrossi4
, Stefano Silvestrini4
,
Vincenzo Pesce5
1
Leonardo, Milan, Italy
2
D-Orbit, Fino Mornasco, Italy
3
ISAE-SUPAERO, Toulouse, France
4
Politecnico di Milano, Milan, Italy
5
Airbus D&S Advanced Studies, Toulouse, France
What is control?
Control is the last word closing the GNC acronym, as it is the last con￾ceptual block in the guidance, navigation, and control loop. Let us consider
again our person going outside the shelter, planning the way and acknowl￾edging the current location, aiming to reach the final destination. This task
can be completed if the person starts walking and maintains the actual path
on the desired one. Thus, the individual shall control the motion command￾ing actions to legs and arms. The body will start moving maintaining the up￾right posture and interacting with the external environment. The latter
influences the real movements, as a wind from the back may result in longer
steps for a given push on the feet or, on the contrary, walking uphill requires
stronger commands to the leg to maintain the desired path and pace. This is
natural for everyone, but it is a complex task involving the deviation of the
navigation estimation of the current state with respect to the guidance plan.
Moreover, it entails the computation of the control actions to track the
desired path and recover possible drifts, calculating the commands to apply
forces and torques on the body dynamics. The example of a walking person
allowed also to have a simple visualization of the main functions related with
control.
In the same example, an additional control loop is present, despite it is
less evident. In fact, maintaining the upright posture, the person uses
different state measurement and commands other actions to preserve the
orientation of the body. In this case, the desired state is not a trajectory,
but a single reference point. This GNC loop is dedicated to keep a static
orientation state, over a dynamic reference tracking. The whole human
Modern Spacecraft Guidance, Navigation, and Control
ISBN: 978-0-323-90916-7
https://doi.org/10.1016/B978-0-323-90916-7.00010-X
© 2023 Elsevier Inc.
All rights reserved. 543 jbody dynamics is obviously coupled, but the ability to separate the two con￾trol effects is based on the higher frequency of the equilibrium control loop
with respect to the translational one. This is not an easy task, but the con￾cepts to master multiple degrees of freedom control will be learnt across
this chapter, since it is extremely relevant for a spacecraft traveling across
the space, as it is for a person exploring the Earth (just remembering the
rocking motion of our first walking experiences).
Control is not only the computation of actions to reduce the errors with
respect to a certain number of desired states but it is also the correct evalu￾ation of the commands to be applied to generate forces and torques. Even if
the formers are the main tasks of what is generally defined a controller, and the
latter are those associated with an actuator, the proper control design shall
consider both. In fact, control functions shall contain specific instructions,
or actuation functions, to translate and send the control commands to the
actuators. For example, imagine the modifications to apply in the control
block if our walking person wants to reach the destination by riding a bicycle
or driving a car. Furthermore, the specifications of the actuators affect the
controller design, such as, among the others, the maximum intensity of
the computed control actions shall be within the limits of the actuators:
our person cannot run faster than the training allows.
Control has to command to the spacecraft’s actuators the actions to
maintain the current state close to the desired on. Clearly, if the control ac￾tion is not properly computed by the control algorithms, or if it is badly
actuated, the discrepancy between the navigation estimated state and the
guidance reference trajectory will tend to increase.
With these notions in mind, we have the basics to start exploring the
technicalities of control algorithms and functions.
This chapter is composed by the following sections:
• Control design. In this section, a comprehensive description of the control
design process is given. It includes the control design process both for the
state space and frequency domain. Furthermore, an introduction to
nonlinear control design is presented.
• Review of control methods. This section presents a review of the most pop￾ular control techniques, from Proportional-Integral-Derivative (PID)
control to Linear Quadratic Regulator (LQR). The content covers also
adaptive and robust control basics, and it includes Model Predictive
Control (MPC) and Sliding Mode Control (SMC).
• Control budget. This section covers the typical budgets to account for dur￾ing control system design, with reference to space standards.
544 Francesco Cavenago et al.• Control implementation best practice. A series of best practice tips and checks
is collected in this section, giving a more practical perspective on the
implementation of control algorithms.
Control design
In this section, some of the main methods and techniques to address a
control problem are reviewed. In the first part, the properties of feedback
and the general objective of the control are presented. Then, the attention
is focused on linear time-invariant (LTI) systems, and the design in the fre￾quency domain and in the state space is discussed. Finally, some tools are
introduced to deal with nonlinear systems. Note that this chapter is not
meant to cover exhaustively all the mentioned control topics, but it provides
an overview and the basis to use it. The reader is invited to refer to the
specialized books, cited along the text, for a further deepening of the subject.
Basic terminology
This short paragraph provides the readers the terminology and basic notions
necessary to understand the concepts reported in this chapter. Further details
can be found in the AppendixdA2.
• Plant. The system to be controlled will be often called plant. It can be
modeled in the time domain, i.e., as function of the time variable t, using
the state space representation. If the plant is LTI, it can also be modeled in
the frequency domain, i.e., as function of the generalized frequency s
(complex variable), through the mathematical framework of the transfer
function. Time invariance means that the system is not a direct function
of the time, namely t does not appear explicitly in the equations.
• State. The state of a system is a set of variables which are able to represent
the condition of the system. Known the values of these variables at a
certain time instant and the time evolution of the input, the dynamic
behavior of the system can be determined. In a mechanical system, po￾sition and velocity are typically used as state variables.
• Transfer function. Let us consider an LTI system and imagine it as a process,
whose output is affected by some input. The transfer function is the
mathematical mean to describe the relation between the input and the
output. It is usually determined as the ratio between the Laplace trans￾form of the output and the input with initial condition zero, where
the Laplace transform is an integral transform used to pass from the
Control 545time domain to the frequency domain, i.e., from the time variable t to
the generalized frequency s.
• Zeros and poles. When a system can be modeled as a rational transfer func￾tion, the roots (generally complex number) of the numerator and de￾nominator are called zeros and poles, respectively. The dynamic
behavior of the system is strictly related to these quantities. In particular,
as it will be shown later, the stability of the system depends on the posi￾tion of the poles in the complex plane.
• SISO. The acronym SISO stands for single-input single-output.
Therefore, a SISO system is a process with only one input and one
output.
• MIMO. The acronym MIMO stands for multi-input multi-output.
Therefore, a MIMO system is a process showing more than one input
and output.
Properties of feedback control
Spacecraft control can be achieved by implementing either open-loop or
closed-loop (negative feedback) schemes. Looking at the block diagram rep￾resentation in Fig. 10.1, it can be noted that, in the open-loop schemes (a),
the control action u is independent of the actual response of the system y and
does not rely on any measurements. The maneuver is predetermined, and
the control action is usually computed solving an optimal control problem.
This procedure is performed on ground and then the control commands are
sent to the spacecraft for the execution. Once determined, the control is not
affected by the actual behavior of the system, and consequently the open￾Figure 10.1 Open- and closed-loop schemes, where y is the reference signal, u is the
control action, and y is the system response. (a) Open-loop scheme. (b) Closed-loop
scheme.
546 Francesco Cavenago et al.loop strategies result to be quite sensitive to uncertainty in the model param￾eters and disturbances. The activities performed to generate off-line solu￾tions for the control profile fall into the definition of guidance, as
discussed in the previous chapter. A good knowledge of the system and
the environment is necessary to achieve satisfactory performance.
Conversely, in feedback schemes (Fig. 10.1b), the controlled variable is
measured, and the control command is computed based on the difference
between its value and a reference one. Basically, feedback control is a reac￾tive strategy: whenever a deviation from the desired behavior occurs, a
corrective action is exerted on the system. This results in a very interesting
robust performance in the presence of model uncertainty and unknown dis￾turbances. An error in the regulated signal introduced by these nonidealities
can be sensed and compensated (or partially compensated) by the control.
This is one of the key properties of closed-loop strategies and one of the rea￾sons why they are widely used for spacecraft control.
Another important use of feedback is to modify the dynamics of the
controlled system in such a way to satisfy the application needs. For example,
the responsiveness and the response damping of the plant can be changed
through the closure of a feedback loop and a proper tuning of the control
parameters. An unstable system can even be stabilized. Thanks to this prop￾erty, it is possible to shape the behavior of a system (although with some lim￾itations which will be discussed in the following) to achieve the desired
performance. Nevertheless, one must bear in mind that there is also the
other side of the coin. Indeed, when two or more systems are intercon￾nected in a cycle through feedback, their dynamics is strongly coupled,
i.e., each system influences the others. The closed-loop behavior can
become counterintuitive, difficult to predict, and, potentially, instabilities
can arise. Moreover, feedback injects measurement noise into the system,
which can lead to undesired effects if not treated properly (e.g., through
filtering). For this reason, formal methods and tools are necessary to design
and analyze a feedback control, and some of them will be presented in the
following paragraphs.
Control objective and performance
An important step toward a well-designed control system is the definition of
the performance required to accomplish the task. Consider the general con￾trol scheme reported in the block diagram of Fig. 10.2. The variables y and y
are the reference and controlled signals, respectively, and u is the control
Control 547command. Finally, d and n are the disturbance acting on the system and the
noise on the measurements, respectively. Basically, the objective of the con￾trol is to achieve y ¼ y rejecting disturbance and noise and limiting the con￾trol action. Note that the reference can be constant or vary in time. The
former case is called regulation control, while the latter one is the tracking
control. This general objective can be expressed in a more formal way by
defining some requirements and performance the control system shall meet:
• Closed-loop stability
• Static and dynamic performance: steady-state error, rise time, settling
time, overshoot
• Disturbance attenuation
• Measurement noise filtering
• Robustness to uncertainty
Each property is now briefly discussed.
Closed-loop stability
Consider a solution of a dynamic system xn

t; xn;0

with initial condition
xn;0 and imagine to perturb the initial condition xp;0. The nominal solution
xn

t; xn;0

is stable if the perturbed one, xp

t; xp;0

, stays close to it for all
the time instants. In a more formal way, xn

t; xn;0

is stable if for all ε >
0, there exists a d > 0 such that:

xn;0  xp;0

 < d //
xn

t; xn;0

 xp

t; xp;0

 < ε for all t > 0:
(10.1)
Clearly, a solution that is not stable is unstable, i.e., a perturbed solution
moves away from the nominal one indefinitely. A special case is when the
nominal solution is an equilibrium solution. In this circumstance, it is simply
said that the equilibrium point is stable.
Figure 10.2 General closed-loop system, where y is the reference signal, e is the control
error, u is the control action, y is the system response, d is the load disturbance, and n is
the noise measurement.
548 Francesco Cavenago et al.If Eq. (10.1) is satisfied, and the following condition is also verified:
lim
t/N

xn

t; xn;0
  xp

t; xp;0

 ¼ 0; cxp;0 :

xn;0  xp;0

 < d;
(10.2)
The solution is said to be asymptotically stable. This additional condition
means that a perturbed solution converges to the nominal one as t ap￾proaches infinity for a xp;0 sufficiently close to xn;0. Depending on the
domain of applicability, a solution can be locally asymptotically stable or
globally asymptotically stable. In the former case, a perturbed solution is
attracted to the nominal one only if xp;0 lies in a limited domain around
xn;0, while, in the latter one, it converges for any initial condition.
When a feedback loop is closed, the stability of the system must be
analyzed and verified. It will be shown that, for an LTI closed-loop system,
it is sufficient to study the closed-loop poles. For the asymptotic stability, all
the poles have to lie in the left-half complex plane, i.e., the real part must be
negative. In this case, the stability is a property of the system. Indeed, it is
possible to talk about the stability of the system rather than the stability of
a solution or of an equilibrium point. In case of nonlinear system, Lyapunov
theorem will be introduced to analyze the stability of an equilibrium point.
Static and dynamic performance
The capability of the closed-loop system to follow a reference signal is usu￾ally expressed in terms of steady-state error (static performance) and transient
behavior (dynamic performance). The main performance measures are rep￾resented in Fig. 10.3.
Figure 10.3 Time performance representation.
Control 549The steady-state error is the error between the reference and the
controlled signal after the initial transient. During the design phase, it is usu￾ally evaluated looking at the response to some test reference signals, such as
step input and ramp input. Ideally, the steady-state error should be zero.
However, in practice, it never happens due to noise in the measurements,
quantization, uncertainty in the model, and disturbances. Typically, the spe￾cific application requires a certain level of final accuracy which can be spec￾ified as a maximum steady-state error.
During the transient, the controlled variable passes from one steady state
to another, and its dynamic behavior must satisfy some responsiveness and
damping requirements. Generally, the responsiveness of the system is eval￾uated in terms of rise time, which is the amount of time required by the
output to go from 10% to 90% of its final value. The damping of the
closed-loop response is expressed in terms of overshoot and settling time.
The former one quantifies the maximum deviation of the controlled vari￾able from its steady-state value, and it is usually defined as a percentage of
the final value. Note that it is assumed that, in the subsequent time instants,
the variable does not exceed the steady-state value more than this initial
transient. The settling time is the amount of time required by the signal
to stay within some percentage of the final value (typically, 1%, 2%, or
5%). This dynamic performance is commonly evaluated looking at the
response of the closed-loop system to a step input. In general, this perfor￾mance depends on the size of the step, except for the linear system, for
which the dynamic performance is independent of it.
Disturbance and measurement noise rejection
Disturbance and measurement noise rejection expresses the capability of the
closed-loop system to attenuate the effects of these perturbations on the
response, and thus to obtain satisfactory tracking performance. It will be
shown that guaranteeing these properties means to impose a certain shape
to the system transfer function, which describes the relation between the
reference and the output variable. In particular, the so-called open-loop
transfer function (i.e., the transfer function between the reference and
controlled variable opening the control loop) must have high gain at low
frequency to attenuate disturbance on the plant and low gain at high fre￾quency to filter noise on the feedback line. This aspect will be discussed
more in detail later in this chapter.
550 Francesco Cavenago et al.Robustness to uncertainty
A well-designed control system must ensure that closed-loop system behaves
satisfactorily not only in the nominal condition but also in the presence of
model uncertainty and/or variation of some parameters. This means that,
even in off-nominal scenarios, the stability must be guaranteed, and the static
and dynamic performance must not deviate excessively from the nominal
one. Clearly, the closed-loop system cannot be robust to any perturbation.
The control designer should evaluate and quantify the expected uncertainty
and parameters variation and perform analyses to assess the behavior of the
closed-loop system for these perturbations. It is possible to define some sta￾bility margins, which provide good indications about the robustness of the
closed-loop system, even if they cannot guarantee it. They will be presented
in section Chapter 10 e Control e Stability and stability margin.
Controllability
As declared previously, the objective of the control is to modify the behavior
of a system in such a way to obtain the desired response. To achieve this goal,
the control input must be able to influence the state of the system, but to
what extent is this possible? To answer this question, controllability of the
system must be analyzed. A system is said to be controllable if there exists
a suitable control signal that can move the state from any initial condition
to any final condition in a finite time. How is this property verified?
Consider a general linear time-invariant system in state-space formulation:
x_ ¼ Ax þ Bu; (10.3)
where x is the n  1 vector of the state, u is the m  1 vector of the input, A
is the n  n dynamics matrix, and B is the n  m control matrix. The state
Eq. (10.3) is controllable if the n  m controllability matrix:
W¼ 
B AB A2
B / An1
B
 (10.4)
has rank equal to n. In the following, it will be shown that there is an
important connection between the controllability and the design of state
feedback control law. In particular, if a system is controllable, it is possible to
modify via feedback all the eigenvalues of the dynamics matrix A, and thus
to shape the transient behavior of the system according to the needs.
Control 551Control design in frequency domain
The first techniques to design a controller, that are presented, are developed
in the frequency domain. Frequency domain modeling is a powerful tool to
analyze the closed-loop behavior of an LTI system. It provides significant in￾sights into the properties of the system, such as stability, robustness, and
attenuation of disturbances. Having in mind the general feedback scheme
in Fig. 10.2, the idea is to represent the system in terms of inputeoutput re￾lations between the variables, and then study their frequency response. To
this aim, Laplace transform is used to move from the time domain in the var￾iable t to the frequency domain in the variable s, which is called generalized
frequency. Afterward, the inputeoutput relation is described by the so￾called transfer function, which is defined as the ratio of the Laplace trans￾forms of the output and the input when the initial state is zero. From the
analysis of the transfer functions, it is possible to investigate the stability of
the system, and understand how the controlled variable, the error, and the
control action (i.e., output) are affected by the reference signal, the distur￾bances, and the noise (i.e., input). In the following, methods and techniques
are presented for SISO systems, for which initially were developed. The re￾view of the concepts reported in this section and the notation is mainly based
on Refs. [1,2], which are excellent reference books for the reader who wants
to deepen the control design based on the transfer functions.
Stability and stability margins
The primary requirement a control designer has to satisfy is the stability,
which is typically verified by the analysis of the roots of the characteristic
polynomial. With reference to Fig. 10.4, where CðsÞ is the transfer function
of the controller and PðsÞ is the transfer function of the controlled plant, the
relation between the Laplace transforms of the reference YðsÞ and the output
variable YðsÞ, i.e., the closed-loop transfer function, is expressed as:
Y
Y ¼ PC
1 þ PC ¼ L
1 þ L ¼ NL
NL þ DL
; (10.5)
Figure 10.4 General closed-loop system, where CðsÞ is the controller transfer function,
PðsÞ is the plant transfer function, y is the reference signal, e is the control error, u is the
control action, y is the system response, d is the load disturbance, and n is the noise
measurement.
552 Francesco Cavenago et al.where L ¼ PC is the so-called open-loop transfer function, NL and DL are
the numerator and the denominator of L, respectively. Hereafter, the
dependance on the generalized frequency s is omitted for simplicity. The
characteristic polynomial of the closed-loop system is computed as follows:
l ¼ NL þ DL. (10.6)
The closed-loop system is asymptotically stable if all the roots of the
characteristic polynomial, also called poles of the system, are in the left
half-plane (L.H.P.) of the complex plane, namely they have negative real
part. The poles correspond to the eigenvalues of the state-space dynamics
matrix A.
The analysis of the characteristic polynomial is quite straightforward and
says if the controlled system is stable or not. However, a designer is interested
in collecting more information on the stability which can provide a useful
guide for the design of the control, like how far the system is from instability
or how much it is robust to perturbations. Basically, it is important to define
some margins of the stability. To this aim, a key result is the Nyquist stability
criterion, which is briefly recalled here as it is most often used in practice,
and thus without going into the more formal definition and all the theoret￾ical details. For a more complete discussion, refer to Ref. [1].
The Nyquist criterion is based on the Nyquist plot of the loop transfer
function L ¼ PC. It is recalled that the Nyquist plot is a polar diagram in
the complex plane representing the frequency response of a transfer func￾tion. The curve is traced from u ¼ 0 to u ¼ þN, with u being the fre￾quency, and then the part symmetric to the real axis is added. Denoting
by Pd the number of poles of L in the right half-plane (R.H.P.) and by N
the number of net encirclements of the diagram around the 1 point of
the real axis (counted positive counterclockwise), the Nyquist criterion states
that the closed-loop system is asymptotically stable if Pd ¼ N (winding number con￾dition) and the diagram does not pass through the -1 point (critical point).
The Nyquist criterion requires that the curve does not intersect the real
axis in the critical point. What if it happens? A very simple test example is
proposed to answer this question. An open-loop transfer function L is
considered, which results in a closed-loop transfer function with two domi￾nant complex conjugate poles in the L.H.P. close to the imaginary axis. The
Nyquist curve of L, the dominant complex conjugate poles (cross markers),
and step response of the closed-loop system are reported in Fig. 10.5a. The
transfer function is then multiplied by a factor 3, and the resulting plots are
reported in Fig. 10.5b. Finally, the initial transfer function is multiplied by a
Control 553factor 5, and the associated plot are in Fig. 10.5c. As the Nyquist curve ap￾proaches the critical point, the dominant complex poles approach the imag￾inary axis, and the time response shows increased oscillation. When the
curve passes exactly through the 1 point, the complex poles lie on the
imaginary axis, and, in this case, the time response shows a pure oscillatory
behavior. Potentially, the system could become even unstable depending on
the multiplicity of the poles at the origin.
Therefore, one of the key messages of the Nyquist theorem is to avoid
the critical point 1. Some measures can be introduced to characterize
how close the Nyquist curve is to this point, and thus to express the degree
of stability of the system. The most obvious one is the direct computation of
the shortest distance between the curve and the critical point (see Fig. 10.6).
Figure 10.5 Behavior of the system when the Nyquist curve approaches the critical
point. (a) Nyquist curve of the transfer function L, dominant poles, and time response
of the closed-loop system. (b) Nyquist curve of the transfer function 3L, dominant poles,
and time response of the closed-loop system. (c) Nyquist curve of the transfer function
5L, dominant poles, and time response of the closed-loop system.
554 Francesco Cavenago et al.This distance is called stability margin or modulus margin and is computed as
follows:
sm ¼ min
u ðjj1 þ LðjuÞjjÞ; (10.7)
or, in decibel, as:
sm ¼ max
u ð  20 log10ðjj1 þ LðjuÞjjÞ: (10.8)
Other margins can also be defined based on the observation that an in￾crease of the controller gain expands the Nyquist curve radially, and an in￾crease of the phase turns it clockwise. One might wonder what is the
amount of gain or phase that makes the Nyquist curve pass through the crit￾ical point, and consequently the system unstable. The answer to this ques￾tion defines the so-called gain margin and phase margin.
The gain margin is defined as the smallest gain causing instability that can
be provided to the closed-loop system. It can be derived from the Nyquist
plot as the inverse of the distance between the origin and the intersection of
the curve with the negative real axis between 0 and 1 (Fig. 10.6). In case of
multiple intersections, the closest to the critical point is considered. The
intersection can be found evaluating the gain of the loop transfer function
at the so-called phase crossover frequency, i.e., the frequency at which
Figure 10.6 Graphical illustration of the stability margin sm, gain margin gm, and phase
margin fm.
Control 555the phase is 180. Therefore, denoting by gm the gain margin, it is
computed as follows:
gm ¼ 1






L

jupc	





; (10.9)
where upc is the phase crossover frequency. As for the modulus margin, the
gain margin is sometimes computed in decibel as
gm ¼ 20 log10





L

jupc	





	
.
The phase margin can be visualized in the Nyquist plot as the angle be￾tween the negative real axis and the line passing through the origin and the
intersection between the curve and the unit half-circle below the real axis
(Fig. 10.6). It is the amount of phase necessary to reach the stability limit.
Also in this case, if the curve intersects the half-circle multiple times, the
intersection closest to the critical point is considered. In mathematical terms,
the phase margin fm is defined as:
fm ¼ 180 þ arg
L

jugc		; (10.10)
where ugc is the gain crossover frequency, namely the frequency at which
the modulus of the loop transfer function is equal to 1 (or 0 dB).
Typically, the use of the gain and phase margins is more widespread
because they have a clear representation in the Bode plot of the loop transfer
function (Fig. 10.7), which has been a popular tool for the control design.
Indeed, from the Bode plot, it is easy to see at what frequency the phase
is 180, and then, the gain margin is the inverse of the gain at that fre￾quency. Similarly, it is possible to identify the frequency at which the
loop transfer function crosses the 0 dB line, and the phase margin is simply
the phase at that frequency plus 180. However, the reader should keep in
mind that gain and phase margins could not guarantee the robustness of the
system. Situations can arise in which although these margins are satisfied, the
response of the system shows undesired oscillations. For this reason, it is best
practice to define the robustness of the closed-loop through all the three
margins, i.e., gain, phase, and modulus margins.
Generally, the system considered for the control design is not exactly the
actual system due to the presence of uncertainties and effects that are not easy
to model. Taking as example the specific case of a satellite, consider the dy￾namic couplings due to flexible appendages or sloshing of fuel mass. These
perturbations/unmodeled dynamics can cause significant deviations from
556 Francesco Cavenago et al.the nominal behavior. Moreover, a satellite is usually required to operate in
different conditions along the entire mission (variation of mass and inertia
properties). Consequently, providing sufficiently high margins is essential
for a robust control design. Recommended values in the European Coop￾eration for Space Standardization (ECSS) standards [3,4] are phase margin
fm  30, gain margin gm  2 (in decibel,  6 dB), and modulus margin
sm  0:5 (in decibel,  6 dB).
Sometimes, another margin is defined and specified, which is called delay
margin. It quantifies the minimum delay that makes the controlled system to
become unstable. The delay margin is computed as follows:
dm ¼
180 þ arg
L

jugc		
ugc
p
180: (10.11)
Sensitivity functions
The analysis in the frequency domain is based on the study of the relation
between the input and the output of a system, which is well-described by
mathematical framework of the transfer function. Considering the block
Figure 10.7 Representation of the gain margin gm and phase margin fm on the Bode
plot.
Control 557diagram of the closed-loop system in Fig. 10.4, the reference signal y, the
load disturbance d, and the measurement noise n can be defined as the
external input to the system, while the controlled variable y, the error e,
and the control action u are the output. The transfer functions describing
the relations among them are reported in Table 10.1.
It can be noted that some transfer functions in Table 10.1 are repeated
more than once. Basically, most of the time, the frequency analysis of a
closed-loop system focuses on a subset, which is known as the Gang of
four [1]:
S ¼ 1
1 þ PC ¼ 1
1 þ L
T ¼ PC
1 þ PC ¼ L
1 þ L (10.12)
PS ¼ P
1 þ PC ¼ P
1 þ L
CS ¼ C
1 þ PC ¼ C
1 þ L
The transfer functions S and T are called sensitivity function and complemen￾tary sensitivity function, respectively, while PS and CS are the load sensitivity
function and noise sensitivity function. These four functions are particularly use￾ful to study and understand the performance of the closed-loop system. The
closed-loop response y and the control error z can be related to the sensi￾tivity functions as follows:
y ¼ Ty þ PSd  Tn; (10.13)
z ¼ y  y ¼ ð1  TÞy  PSd þ Tn: (10.14)
Analyzing Eqs. (10.13) and (10.14), some reasoning can be made. First, a
comparison between Eq. (10.13) and the open-loop response, y ¼ PCy þ Pd,
highlights some of the properties of feedback control discussed in section
Chapter 10 e Control e Properties of feedback control. It can be noted
that the open-loop control has no effect on the disturbance which acts on
the system without attenuation. Conversely, in Eq. (10.13), the disturbance
is multiplied by the sensitivity function which can be properly shaped for
good rejection. A drawback of feedback scheme is the injection of
Table 10.1 Transfer functions of the closed-loop system in Fig. 10.4.
yeu
y PC
1þPC
1
1þPC
C
1þPC
d P
1þPC P
1þPC PC
1þPC n PC
1þPC 1
1þPC C
1þPC
558 Francesco Cavenago et al.measurement noise in the system. As regards the response to the setpoint, both
control schemes can be used to improve it. It will be shown later that feedback
and feedforward control can be combined to achieve better performance of the
system: feedback is typically used to increase robustness and attenuate distur￾bance, while feedforward term is added for better tracking performance. A sec￾ond reasoning starts from Eq. (10.14). Ideally, the controller should achieve
z ¼ 0 . Focusing on the first two terms of the equation, i.e., setpoint and
disturbance responses, a zero control error means shaping the sensitivity func￾tion and the complementary sensitivity function in such a way to have Tz 1
and Sz0. It is recalled that S þ T ¼ 1, and thus these two conditions agree
and can be met in the same frequency range. However, when the analysis is
expanded including the noise, a proper rejection of this disturbance implies
Tz0 (or equivalently Sz1). This simple analysis reveals the main feature of
feedback design: a trade-off between opposite control objectives must be al￾ways performed. Fortunately, an application usually requires satisfying the con￾trol objectives over different frequency range. For instance, most of the time,
the designer is interested in having good tracking and disturbance rejection per￾formance at low frequency and noise attenuation at high frequency. How the
sensitivity functions should be shaped to achieve these goals is explained in
more detail in the following paragraphs.
Before proceeding further, the internal stability of the system is briefly
discussed. In the previous paragraph, it has been shown that the stability
can be studied looking at the poles of the closed-loop transfer function
(i.e., T). Note that, since the transfer functions are often polynomials in s,
the numerator and denominator could have a common factor, which is
canceled. For example, when the loop transfer function L is computed as
the product of P and C, pole/zero cancellation can occur. Sometimes this
is just an algebraic simplification, but there are also situations in which this
cancellation hides potential issues of the system. If the pole/zero cancellation
involves an unstable pole, it can happen that 1 þ L has no unstable roots, but
one of the sensitivity functions might be unstable. Consequently, it is clear
the importance to verify the stability of all the transfer functions of the sys￾tem. If all the transfer functions are stable, the system is said to be internally
stable. Another recommendation that can be derived is to avoid cancellation
of unstable poles when designing the controller.
Response to setpoint
The response of the system to the reference signal is captured by the com￾plementary sensitivity function T. In order to provide zero control error, it
Control 559has been noted that T should be z1 , but this cannot be achieved over the
entire frequency range. Generally, an application requires good tracking per￾formance up to a certain frequency which defines the bandwidth of the
controller, denoted by ub. Inside the bandwidth, the relation Tz 1 is veri￾fied (at the frequency identifying the bandwidth, jjTjj ¼ 1ffiffi
2
p ( 3 dB)).
Typically, the complementary sensitivity function takes the shape of a
low-pass filter with unit zero frequency gain. Note that satisfying the con￾dition Tz1 can be seen as a requirement for the loop transfer function L.
Indeed, it is equivalent to ask for a gain of L as large as possible.
For some applications, it could be necessary to have a steady-state
tracking error equal to zero (at least ideally). To this aim, the rule is that L
shall have at least one integrator for each integrator of the reference signal.
Imagine having L ¼ eL

s
nL , with eLð0Þs0 and nL an integer number  1;
and a setpoint y ¼ 1=s
ny , with ny an integer number  1 , using the final
value theorem for Laplace transforms [2]:
lim
t/NeðtÞ ¼ lim
s/0
seðsÞ ¼ lim
s/0
s

1  L
1 þ L

y ¼ lim
s/0
s
s
nLny
snL þ L
w (10.15)
The tracking error is zero only if nL  ny.
Some important parameters of the complementary sensitivity function
are the bandwidth and the resonant peak value, which is computed as
MT ¼ max
u








TðjuÞ








(or MT ¼ jjTðjuÞkN in terms of infinity norm).
Sometimes, specifications are expressed in terms of these characteristics
because they are strictly related to the performance in the time domain.
Indeed, larger bandwidth results in a faster response to setpoint, and the reso￾nant peak value provides a measure of the overshoot, i.e., higher the reso￾nant peak in frequency domain, larger the overshoot in the time domain.
To get some further insight into the relation between the time and the fre￾quency response, consider as example the following complementary sensi￾tivity function:
T ¼ u2
n
s
2 þ 2xuns þ u2
n
; (10.16)
which represents a second-order system. The parameter un is the natural
frequency and x is the damping. For a second-order system, it is possible to
560 Francesco Cavenago et al.write some relations between these parameters and the characteristics of the
response in the time domain (to a step input) and in the frequency domain.
These relations are reported in Table 10.2. The variable j is computed as
j ¼ cos1x.
An increase of the bandwidth means an increase of the natural frequency
(given x), which results in a decrease of the rise and settling time. An increase
of the damping means a decrease of the resonant peak, and consequently a
limited overshoot. A graphical illustration is given in Fig. 10.8.
Disturbance rejection
It has been shown that feedback loop introduces an attenuation of the
disturbance acting on the system through the sensitivity function S. To
this aim, the gain of S should be as low as possible over the expected fre￾quency range of the disturbance. Indeed, the attenuation is effective only
in the frequency range in which the gain of S is lower than 1. On the other
hand, disturbances with frequency over which the gain of S is greater than 1
are amplified. The (lowest) frequency at which jjSjj ¼ 1 is a parameter of the
sensitivity function, and it is called sensitivity crossover frequency, usc.
Bandwidth, gain crossover frequency, and sensitivity crossover frequency
are related to each other, and usually usc  ugc  ub (for system with
fm ¼ 60 deg, they all coincide). Typically, the controller is required to
reject disturbances that are at low frequency, and thus the requirement of
Sz0 at low frequency is in accordance with the requirement of Tz 1
for good tracking performance since T þ S ¼ 1.
Another important parameter, which characterizes the system response
to disturbance, is the peak of the sensitivity function, Ms. This value provides
a measure of the maximum amplification of the disturbance. It is computed
as Ms ¼ max
u








SðjuÞ








(or Ms ¼ jjSðjuÞkN in terms of infinity norm). Note
Table 10.2 Properties of the step response and frequency response for a second￾order system.
Time domain Frequency domain
Trise ¼ e
j
tanj
un
Sovershoot ¼ e
 px
ffiffiffiffiffiffi
1x2 p
Tsettlingz4:6
xun
ub ¼ un
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
1  2x2
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi

1  2x22
þ 1
r q
MT ¼
(
1
2x
ffiffiffiffiffiffiffiffiffiffiffiffi
1  x2
q 
; x  ffiffiffi
2 p =2
N=A; x > ffiffiffi
2 p =2
Control 561that looking for the maximum of 1
jj1þLðjuÞjj corresponds to searching the
minimum of jj1 þLðjuÞjj, which is exactly the stability modulus. Conse￾quently, it is possible to write Ms ¼ 1
sm
, which reveals that the peak of the
sensitivity function is also a measure of robustness of the system. Generally,
reasonable values for MS should be lower than 2 (or 6 dB).
Observing that low gain of the sensitivity function means high gain of
the loop transfer function L, the transfer function PS, from d to y, can be
simplified at low frequency as:
PS ¼ P
1 þ L
zP
L ¼ 1
C: (10.17)
From Eq. (10.17), it is evident that high gains of the controller are bene￾ficial for the disturbance attenuation. Often, an integrator is added to the
controller to improve the performance. Indeed, the integral action guaran￾tees that the steady-state error due to a constant disturbance goes to zero.
This can be easily seen applying the final value theorem to a step response:
lim
t/NedðtÞ ¼ lim
s/0
sPS
1
s
¼ lim
s/0
s
T
C
1
s
¼ lim
s/0
T
C; (10.18)
where ed is the error due to the disturbance. Since Tð0Þ ¼ 1 is required for
setpoint tracking purposes, lims/0
T
C is equal to zero, and thus edðtÞ/ 0 as t/
N, only if Cð0Þ/N as s/0. This means that the controller shall have an
integral term 1
s
. Note that the introduction of an integrator does not come
without drawbacks. Indeed, attention must be paid to the stability of the
system since this term introduces a 90-deg phase shift, which tends to reduce
(a) (b)
Figure 10.8 Second-order step response to vary natural frequency (left) and damping
(right).
562 Francesco Cavenago et al.the phase margin. Moreover, windup phenomenon can occur which results
in an increase of the error and large transient (if not treated properly) when
the actuators saturate. In section Chapter 10 e Control e Review of control
methods, these issues will be further discussed and possible solutions to the
windup will be proposed.
Noise measurement rejection
One of the drawbacks of the feedback scheme, that has been highlighted, is
the injection in the system of the noise due to the measurements, which is
detrimental for the performance. Noise n is usually introduced as a high fre￾quency disturbance which affects both the controlled variable y and the con￾trol action u.
The relation between y and n is given by the complementary sensitivity
function T. It has been already shown that, at low frequency, jjTjj shall be
close to 1 for a good setpoint tracking, and this is achieved for high gain of
the loop transfer function L. On the other hand, for an effective noise
filtering, jjTjj should be as low as possible at high frequency. This condition
is met by shaping L in such a way to have low gain at high frequency.
Indeed, when jjLjj  1, the complementary sensitivity function can be
approximated as TzL.
Measurement noise can be critical also for the control variable because it
causes wear and saturation of the actuators due to the induced rapid varia￾tions of the action. The response of u to the noise n is captured by the noise
sensitivity function CS. Since Tz0 is required at high frequency, the
modulus of sensitivity function S will be close to 1. Therefore, the noise
sensitivity function can be approximated as CSzC. As expected, noise is
amplified by high controller gains, and thus imposes a limitation on them.
From the formula, it is also clear the importance of filtering possible deriv￾ative action in such a way C goes to zero for high frequency.
Loop-shaping design
Stability analysis through Nyquist theorem and margins has been shown to
be based on the study of the loop transfer function L. The shape of the sensi￾tivity functions, and thus their characteristics, depends directly on properties
of L as well. Hence, it can be concluded that the desired behavior of the
closed-loop system can be achieved by properly shaping the open-loop trans￾fer function. This is an important result because, first, it is easier to reason on
L than on the closed-loop sensitivity functions, then, the control designer can
see immediately the effects of changes in the controller (L ¼ PC).
Control 563From the analysis of the sensitivity functions, it has been understood that
the loop transfer function shall have high gain at low frequency to guarantee
good tracking performance and load disturbance attenuation, and low gain
at high frequency for limiting the effects of measurement noise. The selec￾tion of the slope at low frequency is based on the type of disturbance and
reference. It has been explained that L shall have at least one integrator
for each integrator of the reference in order to have zero steady-state error.
Similarly, an integral action shall be included in the controller to effectively
reject a constant disturbance. At high frequency, typically, a slope, or roll-off
rate, equal or greater than 2 (i.e., 40 dB/decade on the Bode plot) is
desirable. So far, it is not very clear the shape that L should have around
the crossover frequency. A fast transition from the high gain at low fre￾quency to the low gain at high frequency could seem attractive. Instead,
the slope in the crossover frequency range shall be limited to guarantee
adequate robustness properties. As suggested in Ref. [1], the reason can be
easily understood considering a minimum phase system, i.e., a system
without time delay or poles and zeros in the R.H.P. For these systems,
the phase curve can be derived directly from the gain curve of the Bode
plot. In particular, in the range in which the slope n is constant, the phase
curve has constant value wn p
2. Therefore, the phase margin for these sys￾tems can be computed as:
fm z 180 þ 90ngc; (10.19)
where ngc is the constant slope around the crossover frequency. From this
relation, it is evident that a slope greater than 1.67 is necessary to have at
least a phase margin of 30 deg. Typically, L is shaped in such a way to have a
slope of 1 around the crossover frequency. At this point, the typical shape
of the open-loop transfer function is well-defined and reported in Fig. 10.9.
Loop-shaping design is an iterative procedure. The open-loop transfer
function is shaped in order to meet all the requirements of the application,
selecting the gain crossover frequency and adding poles and zeros. The prop￾erties of the closed-loop systems are analyzed in terms of stability margins,
resonant and sensitivity peaks, bandwidth, etc. If the result is not satisfactory,
the L is reshaped to improve it. Generally, the loop-shaping technique is
very suitable for SISO systems or system with one input and multiple out￾puts. As regards the MIMO systems, sometimes, they can be reduced to
different SISO systems, which, then, can be treated as explained. When
this procedure cannot be performed, other design strategies could be
564 Francesco Cavenago et al.more suitable. Some of the presented concepts in the frequency domain can
be extended to MIMO systems [2]. Alternatively, the design of the
controller can be developed in the time domain using the state space repre￾sentation. This latter approach will be presented in section Chapter 10 e
Control e Control design in state space.
To conclude this paragraph on the loop-shaping design, a simple
example is provided. Consider the single axis attitude control problem.
The dynamics of the system is:
I€
q ¼ tc þ td; (10.20)
where I is the inertia, q is the controlled angle, tc is the commanded torque,
and td is a disturbance torque. Moving in the frequency domain through the
Laplace transform, the transfer function of the system is:
P ¼ 1
Is2 (10.21)
As a first attempt, a simple proportional controller is considered. There￾fore, the open-loop transfer function is L ¼ k
Is
2, where k is the controller
gain. Clearly, this solution is not adequate. Indeed, the system is not asymp￾totically stable. A zero is added to the controller leading to:
L ¼ k
ðs þ zcÞ
Is2 : (10.22)
Assume that the inertia is equal to 10 kgm2 and the requirements for the
controller impose a crossover frequency of at least 5 rad/s. In order to
Figure 10.9 Typical shape of the open-loop transfer function LðsÞ:
Control 565provide robustness to the system, the zero is chosen to be one decade before
of the crossover frequency, zc ¼ 1. A zero in the L.H.P. smaller than the
crossover frequency provides an increase of the phase which is beneficial
for the phase margin. Afterward, a gain k ¼ 50 is set in order to achieve
ugc ¼ 5 rad/s. The gain curve of the open-loop transfer function shows
an initial slope equal to 2 due to the double integrator, and then, the slope
decreases to 1 around the crossover frequency, thanks to the zero. To
improve the rejection to noise, a pole pc can be added to the controller:
L ¼ k ðs þ zcÞ
ðs þ pcÞ
1
Is2: (10.23)
The pole is selected equal to 25. In this way, the slope of L at high fre￾quency (roll-off rate) becomes 2, increasing the filtering action of high fre￾quency disturbance. To guarantee ugc ¼ 5 rad/s, the gain k is increased to
1250. Fig. 10.10 reports the Bode plots of the open-loop transfer function,
(a) (b)
(c)
Figure 10.10 Open-loop transfer function (a), complementary sensitivity function (b),
and sensitivity function (c) of the single axis attitude example.
566 Francesco Cavenago et al.the sensitivity function, and the complementary sensitivity function. Basi￾cally, the designed controller is a proportional-derivative (PD) controller
with a first-order filter. Applying the final value theorem, it can be observed
that the error on the controlled variable due to a constant disturbance does
not go to zero. To achieve zero steady-state error in this situation, one shall
add an integral action and reshape the open-loop transfer function accord￾ingly to guarantee stability and good performance (it is not sufficient to
introduce just an integrator 1
s in the controller because the system would
become unstable). The modification of L to include the integral action is
left to the reader.
Feedforward design
Once the feedback has been designed, a feedforward term can be added to
improve the response of the system. Indeed, these two strategies are comple￾mentary. On one hand, feedback provides robustness to model uncertainties
and rejection of unknown disturbance, but it needs the appearance of an er￾ror, and thus it acts only after the effects of disturbance or setpoint variation
show up. It is a reactive control. On the other hand, feedforward can take
corrective actions before disturbances have affected the system, in a predic￾tive way, and it is typically used to obtain a better response to reference
signal and to attenuate measurable disturbance. However, it requires a
very accurate model. Therefore, one strategy compensates the drawback
of the other and vice versa. The combination of feedback and feedforward
is called two degrees of freedom control.
In order to show how to design a feedforward, consider the block
scheme reported in Fig. 10.11, which includes the feedback loop and two
feedforward blocks described by the transfer functions Fy and Fd. Both func￾tions provide as output a feedforward term to the control action. The former
one receives as input the reference signal, while the latter one receives as
input the measurable disturbance. The process transfer function P is split
into two transfer functions, P1 and P2, to highlight where the measurable
Figure 10.11 Feedback loop with feedforward terms, where FyðsÞ and FdðsÞ are the
reference and disturbance feedforward blocks, respectively.
Control 567disturbance enters in the system. The relation between the Laplace trans￾forms of the output and the reference variable is:
Y ¼ PC þ PFy
1 þ PC
Y ¼ 
1 þ S

PFy  1
Y: (10.24)
A perfect tracking means that Y ¼ Y. To this aim, either the sensitivity
function S or the term 
PFy 1

should be as small as possible. An ideal
tracking would be obtained choosing:
Fy ¼ 1
P
; (10.25)
i.e., using the inverse of the plant model.
A similar procedure can be used to design the feedforward term for
attenuating the disturbance effects on the output:
Y ¼ P2  FdP1P2
1 þ PC
D ¼ SP2ð1  FdP1ÞD: (10.26)
Similar to the previous case, a good disturbance rejection is achieved
ensuring either the sensitivity function (as already seen in the loop shaping
design) or the term ð1 FdP1Þ as small as possible. Ideally, this second con￾dition results in:
Fd ¼ 1
P1
: (10.27)
The procedure to design the feedforward control seems quite straightfor￾ward. However, it requires the inversion of the plant model (or part of it),
and this process has some important implications to notice. Some issues
can arise when the model presents delays, R.H.P. zeros, and a number of
poles higher than the zeros. Delays in the inverse mean prediction, which
cannot be performed accurately. The inversion of R.H.P. zeros is clearly crit￾ical because it would introduce instability in the system. Higher poles than
zeros imply differentiation in the inverse, which requires smooth reference
and can cause noise amplification. To solve these issues, approximations of
the process model shall be used (e.g., focusing only on some frequency range,
adding low pass filtering to the inverse, substituting R.H.P. zeros with L.H.P.
zeros, etc.). In Ref. [1], these problems related to feedforward design are dis￾cussed more thoroughly with examples, and some means of constructing
approximate inverses are proposed. Finally, as already pointed out, the
knowledge of the model could be poor leading to nonsatisfactory perfor￾mance. For this reason, it is preferable to use feedforward in combination
with feedback, which increases the robustness to uncertainty in the system.
568 Francesco Cavenago et al.Control design in the state space
So far, the control design in the frequency domain, based on the so-called
classical control theory, has been presented. These techniques were particu￾larly popular in the 40s and 50s, and they are still attractive for SISO systems
(and MIMO systems, which can be reduced to several SISOs). The analysis
of the sensitivity functions provides a deep insight of the characteristics of the
closed-loop system, and their features can be directly related to the time
behavior. For this reason, performance and robustness specifications are
often provided in frequency domain [3,4]. In the 60s and 70s, another
important paradigm for the control design emerged, based on the represen￾tation of the system dynamics in the time domain by state equations. A key
feature of the state-space approach is its natural applicability to MIMO sys￾tems. Moreover, it is particularly suitable for optimization. Feedback control
law can be obtained directly optimizing a certain performance index. In the
following, some time-domain techniques for controller synthesis are
presented.
Stability analysis in state space
The stability analysis of an LTI system modeled in state space is straightfor￾ward. Consider the generic dynamic system:
x_ ¼ Ax; xð0Þ ¼ x0 (10.28)
where x is the n  1 vector of the state, and A is the n  n dynamics matrix.
The stability of the system (10.28) is studied looking at the eigenvalues of
the dynamics matrix A, which are the roots of the characteristic polynomial
computed as:
l ¼ detðsIn  AÞ. (10.29)
The system in Eq. (10.28) is stable if and only if all the eigenvalues of the
matrix A have nonpositive real part, and the geometric multiplicity of any
eigenvalue with zero real part is equal to the associated algebraic multiplicity.
The system is asymptotically stable if and only if all the eigenvalues have a
strictly negative real part. Finally, the system is unstable if any eigenvalue
has a strictly positive real part, or a zero real part and the geometric multi￾plicity are less than the algebraic one. Note that the eigenvalues of the matrix
A correspond exactly to the poles of the closed-loop transfer function in the
frequency domain.
Control 569State feedback control law
In order to study the state feedback controller, consider the generic state
space equation:
x_ ¼ Ax þ Bu;
y ¼ Cx þ Du; (10.30)
where x is the n  1 vector of the state, u is the m  1 vector of the input, A
is the n  n dynamics matrix, B is the n  m control matrix, C is the p n
sensor matrix, and D is the p  m direct term. Note that, most of the time,
models do not have the direct term, meaning that the output variables are
not influenced by the control input. For this reason, in the following, the
direct term is set to zero.
Assuming to have all the state available, the state feedback control law
takes the following form:
u ¼  Kx; (10.31)
where K is a m  n matrix containing the controller gains. Consequently,
the closed-loop state equations become:
x_ ¼ ðA  BKÞx;
y ¼ Cx: (10.32)
The matrix ðABKÞ represents the new dynamics matrix of the system.
The controller in this form, typically called regulator, can be used to shape
the transient response for nonzero initial conditions and to attenuate external
disturbance to keep the zero-equilibrium state. Later, it will be discussed
how to introduce steady-state tracking of a reference.
Pole placement
As already mentioned, the first objective of the controller is to guarantee the
stability of the system, and this can be achieved ensuring that all the eigen￾values of ðABKÞ have strictly negative real part. Along with this goal, a
designer is required to satisfy some performance in terms of response, such
as rise time, overshoot, and settling time. Transient behavior of a dynamic
system is closely related to its poles, namely the eigenvalues of the dynamics
matrix. Therefore, one way to shape the response in order to obtain the
desired transient characteristics is to move the poles of the system by a proper
tuning of the gain matrix. This method is called pole placement. It is impor￾tant to note that this technique requires the availability of the full state and
570 Francesco Cavenago et al.the controllability of the open-loop state equations (i.e., of the pair ðA;BÞ)
to arbitrarily place the closed-loop eigenvalues.
In the pole placement method, the gains of the controller are selected
such that:
detðsIn  A þ BKÞ ¼ l*; (10.33)
where l* is the desired characteristic polynomial. To illustrate the proced￾ure, consider the following example.
As introduced in Chapter 4 e Orbital Dynamics, the relative motion of a
chaser with respect to a target on a circular orbit about the Earth can be
expressed in the target local-vertical-local-horizontal (LVLH) frame with
the ClohessyeWiltshireeHill equations:
d€x  3n2dx  2ndy_ ¼ ux;
d€yþ2ndx_ ¼ uy;
d€zþn2
dz ¼ uz
(10.34)
where n is the orbital rate of the target, and ux; uy; uz are the control
actions in the three directions. The LVLH frame is defined with the x-axis
pointing out from the Earth to the target spacecraft, the z-axis is normal to
the orbital plane, and the y-axis completes the right-handed frame. The
motion along the direction orthogonal to the orbital plane is decoupled
from the dynamics in the radial and transverse directions. Consequently, two
sets of state space equations are considered for the control design:
x_ ¼ Axx þ Bxu ¼
2
6
6
6
6
6
6
6
6
4
0 1 00
3n
2 0 02n
0 0 01
0 2n 0 0
3
7
7
7
7
7
7
7
7
5
x þ
2
6
6
6
6
6
6
6
6
4
0 0
1 0
0 0
0 1
3
7
7
7
7
7
7
7
7
5
u;
z_ ¼ Azz þ Bzuz ¼
2
4
0 1
n
2 0
3
5z þ
2
4
0
1
3
5uz;
(10.35)
Control 571where x ¼
h
dx dx_ dy dy_
iT
, u ¼ 
ux uy
T
, and z ¼
h
d z dz_
iT
.
Both systems are controllable. First, the control of the out-of-plane motion
is addressed, and the following control action is used:
uz ¼  kzz; (10.36)
where kz ¼ ½kz1 kz2 is a row vector of gains. The characteristic polynomial
of the closed-loop system can be computed as follows:
detðsI Az þ BzkzÞ ¼ s
2
þkz2s þ n2
þkz1; (10.37)
In order to achieve the desired closed-loop dynamics, the following
characteristic polynomial is prescribed:
l* ¼ s
2þ2xuns þ u2
n; (10.38)
Representing a second-order system with damping x and natural fre￾quency un. It is recalled that these parameters are strictly related to the
time performance of the response, as reported in Table 10.2 and shown in
Fig. 10.8. Selected x and un to have the desired behavior, the gains of the
control can be easily derived accordingly:
kz1¼ u2
n  n2
;
kz2 ¼ 2xun: (10.39)
The gains selection for the in-plane dynamics is a bit more complex since
it is a MIMO system. The control action takes the following form:
u ¼  Kx ¼ "
k11 k12 k13 k14
k21 k22 k23 k24 #
x; (10.40)
where K is the control gain matrix. The corresponding closed-loop dy￾namics matrix becomes:
A  BK ¼
2
6
6
6
6
6
4
0 1 00
3n2  k11 k12 k13 2n  k14
0 0 01
k21 2n  k22 k23 k24
3
7
7
7
7
7
5
(10.41)
The number of controller gains is higher than are needed to place the
poles at the desired location. Therefore, different solutions are possible.
One of them is to choose some gains in order to simplify the dynamics
572 Francesco Cavenago et al.matrix, and then, to set the remaining ones in order to have the required
eigenvalues. For instance, the following initial tuning can be performed:
k13 ¼ k21 ¼ 0; k22 ¼ 2n; k14 ¼ 2n; (10.42)
Then, the resulting dynamics matrix is:
A  BK ¼
2
6
6
6
6
6
4
0 100
3n2  k11 k12 0 0
0 001
0 0 k23 k24
3
7
7
7
7
7
5
; (10.43)
and the associated characteristic polynomial can be computed as:
detðsIn  A þ BKÞ ¼ 
s
2 þ k12s  3n2 þ k11s
2 þ k24s þ k23
(10.44)
At this point, the desired pole placement can be achieved by imposing
the following relation:

s
2 þ k12s  3n2 þ k11s
2 þ k24s þ k23
¼ 
s
2 þ 2x1un1s þ un1
 
s
2 þ 2x2un2s þ un2
(10.45)
where the damping x1 and x2 and the natural frequencies un1 and un2 are
chosen to satisfy certain time performance in a similar way to what has been
done previously. For example, one could set two conjugate poles signifi￾cantly faster than the other two in such a way to have the closed-loop
dynamics dominated by these latter ones, and thus a second-order domi￾nant response. However, it must be pointed out that moving poles very far
from the original ones require high control gains, which could cause
amplification of measurement noise and saturation/wear of actuators.
When high-order systems are considered, the procedure to place the
poles, illustrated in the example, is not very efficient. A way to simplify it
is to formulate the state equation in the controllable canonical form. In
particular, considering the SISO system, the dynamics should be expressed
by the following equations:
x_ CF ¼ ACFxCF þ bCFu;
yCF ¼ cCFxCF; (10.46)
Control 573where:
ACF ¼
2
6
6
6
6
6
6
6
6
6
6
6
6
4
0 1 / 0 0
0 0 / 0 0
« « 1 « «
0 0 / 1 0
0 0 / 0 1
an an1 / a2 a1
3
7
7
7
7
7
7
7
7
7
7
7
7
5
; bCF ¼
2
6
6
6
6
6
6
6
6
6
6
6
6
4
0
0
«
0
0
1
3
7
7
7
7
7
7
7
7
7
7
7
7
5
; (10.47)
cCF ¼ ½ c1 c2 / cn1 cn :
The elements of the last row of the dynamics matrix ACF correspond to
the coefficients of the characteristic polynomial of the system:
lCF ¼ s
n þ a1s
n1 þ a2s
n2 þ / þ an1s þ an. (10.48)
If the full state controller
u ¼  kCFxCF ¼ ½ kCF;1 kCF;2 / kCF;n1 kCF;n xCF (10.49)
is considered, the closed-loop dynamics matrix becomes:
ACF  bCFkCF ¼
2
6
6
6
6
6
6
6
6
6
6
6
6
4
0 1 / 0 0
0 0 / 0 0
« « 1 « «
0 0 / 1 0
0 0 / 0 1


kCF;1 þ an
 

kCF;2 þ an1
 / 

kCF;n1 þ a2
 

kCF;n þ a1

3
7
7
7
7
7
7
7
7
7
7
7
7
5
;
(10.50)
And the associated characteristic polynomial is:
lCF ¼ s
n þ 
kCF;n þ a1

s
n1 þ 
kCF;n1 þ a2

s
n2 þ /
þ 
kCF;2 þ an1

s þ 
kCF;1 þ an

. (10.51)
Imagine having selected the locations of the poles, the desired character￾istic polynomial can be written as follows:
l* ¼ s
n þ a1s
n1 þ a2s
n2 þ / þ an1s þ an. (10.52)
574 Francesco Cavenago et al.The controller gains that transform Eq. (10.51) into Eq. (10.52) can be
computed by equating the polynomial:
8
>>>>>>>><
>>>>>>>>:
kCF;1 ¼ an  an
kCF;2 ¼ an1  an1
«
kCF;n1 ¼ a2  a2
kCF;n ¼ a1  a1
(10.53)
The procedure with the controllable canonical form is quite straightfor￾ward. However, the systems are rarely in this form. Generally, the original
state-space formulation is transformed to the canonical form through a
linear, nonsingular matrix T:
xCF ¼ Tx: (10.54)
The dynamics matrix of the original system, A, b, and c are consequently
transformed as follows:
ACF ¼ TAT1; bCF ¼ Tb;
cCF ¼ cT1
: (10.55)
Afterward, the controller can be designed following the procedure pre￾viously explained, and the control action for the original state-space formu￾lation can be determined as:
u ¼  kCFxCF ¼ kCFTx. (10.56)
Considering the relations in Eq. (10.55), the relation between the
controllability matrix W of the original system and the controllability matrix
WCF of the transformed one can be derived, and used to compute the trans￾formation matrix:
WCF ¼ TW
T ¼ WCFW1; (10.57)
Control 575where:
WCF ¼
2
6
6
6
6
6
6
6
6
4
an1 an2 / a1 1
an2 an3 / 1 0
« « 0 « «
a1 1 / 0 0
1 0 / 0 0
3
7
7
7
7
7
7
7
7
5
1
: (10.58)
Hence, the control gain vector k for the original state-space formulation
is expressed as:
k ¼ kCFWCFW1; (10.59)
which is called BasseGura formula. A multiple-input version of the
controllable canonical form is also possible, even if the procedure is much
more complicated and is beyond the scope of the book. Once accomplished,
the derivation of the state feedback control gains is similar to the one pre￾sented. The interested reader can refer to Refs. [5,6].
Thanks to the pole placement method, it is possible to the move the
poles of a controllable system to any location shaping the closed-loop
response as desired. However, there are some issues in this technique. As
seen in the example on the relative translational dynamics, in a MIMO sys￾tem, the designer has to select more control gains than are needed to place
the poles. From one hand, these additional parameters provide an increased
flexibility in the design. Indeed, not only the poles can be moved to the
desired location but also other requirements can be satisfied at the same
time. For instance, in the example, they have been chosen to simplify the
control structure. In the MATLAB function place, they are used to minimize
the sensitivity of the closed-loop poles to perturbations in A or B. On the
other hand, this flexibility results in an indeterminate control solution due
to the fact that the desired poles can be achieved with different gain sets,
and thus it can be difficult to understand which is the best way to choose
them. Moreover, the desirable location for the closed-loop poles may not
be known exactly. Finally, with the pole placement method, it is not easy
to balance the performance of the system with the control effort required
to achieve it. These disadvantages can be overcome by using an alternative
technique for the selection of the gains based on optimizing a cost function:
576 Francesco Cavenago et al.the LQR. This control strategy will be discussed in section Chapter 10 e
Control e Review of control methods.
Before proceeding further, a final observation is made. It has been
explained that for pole placement, the controllability of the system is
required. What happens if the pair ðA;BÞ is not controllable? It can be
shown that, through a proper change of variables, it is possible to separate
the part of the system that is controllable from the one that it is not. The
eigenvalues of the former one can be moved designing a stabilizing
controller as explained, while the uncontrollable eigenvalues will remain
as closed-loop eigenvalues. Consequently, if the uncontrollable eigenvalues
have negative real parts, the closed-loop system will be stable, and the pair
ðA;BÞ (or the open-loop system) is called stabilizable. On the other hand, if
the uncontrollable eigenvalues have positive real parts, the closed-loop sys￾tem will be unstable.
Pole placement for first-, second-, and high-order systems
Linear first- and second-order systems play an important role in control en￾gineering for different reasons. First, simple relations can be found between
the position of the poles and the transient response of the system to a step.
This information is very useful for the selection of the control gains. Then,
first- and second-order systems can be used to approximate high-order ones
to some extent.
For first-order system, the transient behavior is described by a single
eigenvalue. Considering a stable system, the step response is governed by
a decaying exponential with time constant s, which is the inverse of the
eigenvalue (see Fig. 10.12). The smaller the time constant, the faster the
response (i.e., the smaller the rise time). Also, the settling time is related
to the eigenvalue, and, especially, it can be estimated as w4:6s. Therefore,
the desired response can be shaped just modifying this single eigenvalue.
On the other hand, the second-order dynamics is characterized by a pair
of eigenvalues. In general, they can be expressed as xun 	 un
ffiffiffiffiffiffiffiffiffiffiffiffi
x2  1 p ,
with x and un being the damping and the natural frequency. The first
parameter determines the shape of the response, the other one the speed
(i.e., the larger un, the faster the response). Depending on the damping,
the system can be:
• Overdamped. x > 1, real and distinct eigenvalues, slowest transient
response.
Control 577• Critically damped. x ¼ 1, real and equal eigenvalues, fastest transient
response without overshoot.
• Underdamped. 0 < x < 1, complex conjugate eigenvalues, faster transient
response (than previous cases) with oscillation and overshoot.
• Undamped. x ¼ 0, complex conjugate eigenvalues on imaginary axis,
response with undamped oscillation.
• Unstable. x < 0, at least one eigenvalue with positive real part, unstable
response.
The relations between the time performance and the parameters x and
un have been already introduced, and they are reported in Table 10.2
and illustrated in Fig. 10.8. As shown in the example of the previous para￾graph, the control gains can be tuned to have the desired damping and nat￾ural frequency, and consequently the desired transient behavior.
The other reason why first- and second-order systems are important for
the control design lies in the fact that high-order systems can be approxi￾mated by them. Indeed, high-order response are often characterized by
some dominant eigenvalues, which are the ones closest to the imaginary
axis or, in case of multiple eigenvalues at the same distance, with the lowest
damping ratio. Moreover, high-order response can also be shaped to behave
as a first- or second-order system. In this case, the designer has to specify the
dominant eigenvalues, to meet the requirements, and the location of the
remaining ones. As a rule of thumb, these latter one should be 10 times
further from the imaginary axis than the dominant eigenvalues. However,
this strategy should be applied carefully. Indeed, the further the closed￾loop poles from the original ones, the higher the control gains, and
Figure 10.12 First-order response to a step.
578 Francesco Cavenago et al.consequently the higher the risk of saturation or wear of actuators. A trade￾off must be sought.
Feedforward term
In the previous discussion, it has been shown that the transient behavior of
the system can be shaped with a proper tuning of the state-space controller
matrix K (e.g., via pole placement or LQR) in order to achieve the desired
time performance. Nevertheless, it has not been discussed yet how to guar￾antee a good steady-state tracking, which is typically a required feature of the
controller. Indeed, the controller in the form of Eq. (10.31) enables to
modify the dynamics of the system, but the steady-state value is not directly
controlled. To this aim, a feedforward term can be added to the control
input, which becomes:
u ¼  Kx þ Kff y; (10.60)
where Kff is the m  p feedforward gain matrix, and y is the p  1 constant
reference vector. Consequently, the closed-loop system can be expressed as:
x_ ¼ ðA  BKÞx þ BKff y;
y ¼ Cx; (10.61)
where it can be immediately observed that the additional term does not
affect the position of the poles of the system, which is determined only by
ðA BKÞ. Therefore, feedback and feedforward can be designed inde￾pendently. The gain matrix K is selected to guarantee the stability and a
certain transient response, while Kff is chosen to have the desired steady￾state value. In particular, at equilibrium, Eq. (10.61) becomes:
0 ¼ ðA  BKÞxe þ BKff y;
ye ¼ Cxe; (10.62)
and, consequently,
ye ¼  CðA  BKÞ
1
BKff y: (10.63)
Note that if the control gain K is designed in order to have an asymptot￾ically stable closed-loop system, the nonsingularity of the matrix ðA BKÞ is
guaranteed. At this point, imposing that ye ¼ y, the following relation is
obtained:
CðA  BKÞ
1
BKff ¼ I; (10.64)
Control 579and thus, assuming p ¼ m (i.e., the number of input equals to the num￾ber of output), the feedforward gain matrix can be computed as:
Kff ¼  
CðA  BKÞ
1
B
1
: (10.65)
If the number of inputs is higher than the output (m > p), the Mooree
Penrose pseudoinverse is used instead of the inverse. In conclusion, a control
law as in Eq. (10.60) with a proper selection of the matrices K and Kff en￾ables to modify the dynamics of the system satisfying both steady-state and
transient performance objectives.
Integral action
Feedforward term has been introduced to obtain the desired steady-state
behavior. However, this method requires accurate knowledge of the system
model for a good calibration of Kff . Uncertainties, parameter variations, or
approximation may cause nonnegligible deviation from the target perfor￾mance. An alternative approach to design a more robust controller with
steady-state tracking is to add an integral action to the control input. The
control system uses an integrator to provide zero steady-state error, and
very accurate model is not necessary anymore. The integral action is intro￾duced augmenting the nominal state equations to include the state xI, whose
time derivative is equal to:
x_ I ¼ y  y; (10.66)
In this way, the augmented state equations become:
2
6
4
x_
x_ I
3
7
5 ¼
2
4
A 0
C 0
3
5
2
4 x
xI
3
5 þ
2
4
B
0
3
5u 
2
4
0
I
3
5y;
y ¼ Cx: (10.67)
Given the augmented system, the state-space control law can be written
as:
u ¼  Kx  KIxI; (10.68)
and, consequently, the closed-loop dynamics is:
2
6
4 x_
x_ I
3
7
5 ¼
2
4
A  BK BKI
C 0
3
5
2
4 x
xI
3
5 
2
4
0
I
3
5y:
y ¼ Cx (10.69)
580 Francesco Cavenago et al.At this point, the control problem for the augmented system shall be
addressed, and the gains K and KI shall be selected in such a way to have
an asymptotically stable response. In this way, at equilibrium, x_ I ¼ 0, and
thus the output is equal to the reference realizing zero steady-state error.
As a last remark, note that integral action and feedforward term can be com￾bined. The former one guarantees constant disturbance rejection and zero
steady-state error even in case of uncertainties in model parameters. The
latter one generally improves the transient response to reference signal.
Limitations to control performance
When a control is designed, it is important to be aware of the intrinsic lim￾itations that can be imposed by some properties of the system. This topic has
been thoroughly addressed in Refs. [1,7]. In this paragraph, some of the
main results are summarized. In particular, first, the Bode’s integral formula
is reviewed. It shows, through an analysis of the sensitivity function, that
certain performance of the closed-loop system cannot be improved over a
wide range of frequency. Afterward, the limits due to delays, and zeros
and poles in the R.H.P. are discussed.
Bode’s integral formula
The sensitivity function provides information about the performance and
robustness of the system. In particular, it quantifies the capability of the sys￾tem of attenuating disturbances. It is recalled that good disturbance rejection
is achieved with low gain of the sensitivity function. Moreover, the peak of
the sensitivity function is related to the modulus margin, and thus it is a mea￾sure of the robustness of the feedback system. A control designer is interested
in decreasing the sensitivity function gain, including the peak, as much as
possible over a wide range of frequency. However, Bode proved that there
are limitations in achieving this goal. Indeed, for a system internally stable
and a L such that lims/NsL ¼ 0, the following relation holds:
Z
N
0
log












SðjuÞ












du ¼
Z
N
0
log
1
jj1 þ LðjuÞjj du ¼ p
Xpk; (10.70)
where pk are poles in the R.H.P. The relation in Eq. (10.70) means that the
area under the curve logjjSðjuÞjj is constant. Consequently, if the gain of
the sensitivity function is decreased for some frequencies to improve
disturbance attenuation, it increases, limiting or canceling the effect of the
Control 581controller, for other frequencies. This effect is called waterbed effect.
Therefore, if a control designer wants a very small sensitivity function at
certain frequency, the cost of having an amplification of the disturbance over
other frequency has to be paid. The situation is even worse for an unstable
system, which has a sensitivity larger than a stable one.
Bode’s integral formula confirms the nature of the control design, already
highlighted previously. The control designer must look for a balance be￾tween conflicting objectives and different performance over the frequency
range.
Nonminimum phase systems
Nonminimum phase systems are characterized by the presence of delays, and
R.H.P. poles and zeros. These components impose severe constraints on the
selection of the gain crossover frequency. For this reason, the control design
of nonminimum phase systems is more complex. To understand the restric￾tions due to nonminimum phase components, some illustrative examples are
presented.
Consider a nonminimum phase transfer function P which can be
factored as:
P ¼ PmpPnp; (10.71)
where Pmp has all the poles and zeros in the L.H.P, while Pnp has all the
nonminimum phase features, and it is chosen to have 


PnpðjuÞ



 ¼ 1 and
negative phase. Assume to have a stabilizing controller C without zeros and
poles in the R.H.P. Note that the gain curve of the loop transfer function
L ¼ PC corresponds to the gain curve of the minimum phase function
PmpC because Pnp has unit gain over all the frequency. Now consider the
case of the presence of an R.H.P. zero represented by Pnp ¼ sþz sþz , with z >
0. Recalling that for a minimum phase transfer function the phase curve can
be derived directly from the gain curve as n p
2, if a phase margin fm is
required, the following inequality must be satisfied:
argPnp
jugc
¼ 2 arctanugc
z
	
 p  fm þ ngc
p
2
; (10.72)
582 Francesco Cavenago et al.where ugc is the gain crossover frequency and ngc is the gain crossover slope.
From Eq. (10.72), it can be seen that a zero in the R.H.P. limits the
achievable value of the gain crossover frequency which shall satisfy:
ugc  ztan
0
@
p  fm þ ngc
p
2
2
1
A: (10.73)
Note also that slow zeros cause lower gain crossover frequency than fast
zeros.
Time delays impose a similar limitation to the gain crossover frequency.
Consider Pnp ¼ ess, which represents a pure delay s in frequency domain.
In this case, the inequality to be satisfied is:
ugcs  p  fm þ ngc
p
2
: (10.74)
Consequently, the maximum achievable gain crossover frequency is
limited as follows:
ugc 
p  fm þ ngc
p
2
s : (10.75)
The larger the delay, the lower the gain crossover frequency.
On the other hand, controlling an unstable system, i.e., with poles in the
R.H.P, requires larger bandwidth, and thus higher gain crossover frequency.
Assume to have Pnp ¼ sþp
sp, with p being a positive value. If a margin fm is
specified for the application, the phase of the nonminimum transfer function
shall be:
argPnp
jugc
¼ 2atan p
ugc
 p  fm þ ngc
p
2
; (10.76)
and thus
ugc  p
tan
0
@
p  fm þ ngcp
2
2
1
A
: (10.77)
Eq. (10.77) shows that, in order to stabilize and control robustly an un￾stable system, a high gain crossover frequency is necessary, especially in the
case of fast poles. As expected, the control of an unstable system is
Control 583challenging and requires not only a large bandwidth of the control, but also
of actuators and sensors.
These simple examples should have made clear the difficulties of control￾ling nonminimum phase systems, due to the restrictions imposed by delays,
and R.H.P. poles and zeros. Delay and R.H.P. zeros limit the responsiveness
of the closed-loop system. Conversely, the unstable poles require large
bandwidth, and thus a very responsive system. Note that the poles are strictly
related to the dynamics of the system, and thus the only way to change them
is a feedback loop or a redesign of the system. On the other hand, the zeros
depend on the how sensors and actuators are integrated in the system.
Therefore, adding or moving these elements can modify the position of
the zeros, simplifying the control design. Delays are usually introduced in
the communication and computation processes. If high control performance
is required, the computing and communication systems shall be designed in
such a way to minimize the delays.
An introduction to control design for nonlinear systems
The methods and techniques presented so far have been developed for linear
systems. However, most of the real applications imply nonlinear dynamics.
A question could naturally arise: Can these tools be extended for the control
design of a nonlinear system? The answer is yes. The idea is to approximate
or convert the nonlinear dynamics to a linear one in such a way to use the
previously explained techniques. Following this path, the linearization, gain
scheduling, and feedback linearization techniques will be presented.
An alternative approach is the design of the control directly considering
the nonlinear system. As for the linear counterpart, it is important to have
methods to study the stability of the closed-loop dynamics. To this aim,
the Lyapunov stability theorem involving the so-called Lyapunov functions
will be introduced. Lyapunov theorem is a powerful tool, which can be used
not only to study the stability but also to design a stabilizing controller.
This section provides only few tools and concepts to deal with nonlinear
systems, and it is far from covering exhaustively the topic. Some other con￾trol methods will be reviewed in the next chapter. However, the reader is
invited to deepen the subject through specialized books such as Refs. [8,9].
Linearization
In control engineering, very often a nonlinear system is approximated by a
linearized model around an equilibrium condition of interest. The local
behavior is studied, the controller is designed to operate and keep the system
584 Francesco Cavenago et al.in the region of validity of linearization, and the performance is then verified
by simulating the closed-loop nonlinear model. For example, in a three-axis
stabilized spacecraft, the nonlinear attitude dynamics can be linearized
around the nominal orientation and a controller can be designed to keep
it, allowing only small variation around the equilibrium point. To illustrate
the procedure, consider the following general nonlinear system in state
space:
x_ ¼ fðx; uÞ;
y ¼ hðx; uÞ; (10.78)
where fðÞ is a n  1 nonlinear vector function describing the dynamics, and
hðÞ is a p  1 nonlinear vector function expressing the relation between the
state and output vectors. Assume that an equilibrium solution of the
nonlinear system in Eq. (10.78) is given by xe and ue. The linearized model
around the equilibrium point is:
dx_ ¼ Adx þ Bdu;
dy ¼ Cdx þ Ddu; (10.79)
where the state-space matrices are the Jacobians of the nonlinear functions
fðÞ and hðÞ evaluated in the equilibrium point:
A ¼ df
dx




x¼xe;u¼ue
B ¼ df
du




x¼xe;u¼ue
C ¼ dh
dx




x¼xe;u¼ue
D ¼ dh
du




x¼xe;u¼ue
(10.80)
and where dx ¼ x  xe, du ¼ u  ue, and dy ¼ y  hðxe; ueÞ. Linear
state-space equations in Eq. (10.79) approximate the nonlinear dynamics in
Eq. (10.78) locally, i.e., around the equilibrium solution. An important the￾orem, called Lyapunov’s indirect method [9], guarantees that if the linear￾ized system is asymptotically stable, i.e., all the eigenvalues of the matrix
A have negative real part, the equilibrium point xe is locally asymptotically
stable for the nonlinear system. On the other hand, if the linearized system is
unstable, i.e., any eigenvalue of A has positive real part, the equilibrium
point xe is unstable. Nothing can be said if any eigenvalue is on the imag￾inary axis. The controller for the nonlinear dynamics can be now designed
using the techniques for linear system presented in the previous sections.
Control 585Gain scheduling
Linearization is effective if the system operates close to the equilibrium point.
Indeed, the stability is guaranteed only locally, and, in any case, the perfor￾mance can deteriorate significantly for large variations. A technique that has
been proposed to overcome this limitation is the gain scheduling. The idea is
to linearize the nonlinear model around different equilibrium points, or
operating points, to design a controller based on linear control theory for
each point, and, finally, to merge the developed controllers in a single one
whose parameters change depending on the values of some selected quanti￾ties called scheduling variables (e.g., reference or measured variables).
As suggested in Refs. [8,10], the design procedure for gain scheduling
can be split into four main steps:
1. Derive a linear parameter-varying model from the nonlinear one. This
can be achieved through the classical Jacobian linearization about a
family of equilibrium points parametrized by the scheduling variables. An
alternative approach is the quasi-linear parameter-varying (quasi-LPV)
scheduling, in which the nonlinearities are represented as time-varying
parameters, used as scheduling variables.
2. Design the controllers for the linear parameter-varying model using
linear control methods. A family of controllers for the plant can be
derived directly or it can be the result of an interpolation of the con￾trollers designed at isolated values of the scheduling variables.
3. Implement the family of controllers in such a way that the gains changes
with the current values of the selected scheduling variables, and for fixed
value of the parameters, some desirable performance are achieved.
4. Assess the performance. Local stability and system properties could be
investigated analytically (e.g., studying the linearized system at each equi￾librium points). On the other hand, the assessment of nonlocal perfor￾mance requires the simulation of the nonlinear closed-loop model.
In this paragraph, only the main concepts behind the gain scheduling are
summarized. The reader who wants to deepen the knowledge of this tech￾nique can refer to Refs. [8,10], where a full description of gain scheduling
along with the mathematics can be found.
Feedback linearization
An alternative approach to transform the nonlinear dynamics into an equiv￾alent linear one is the so-called feedback linearization. The idea is to use an
inner control loop which linearizes the nonlinear system and introduces a
transformed input, whose relationship with the output is linear. Afterward,
586 Francesco Cavenago et al.techniques for linear system can be exploited to design the outer loop, which
completes the control system. Sometimes a transformation of the state vari￾ables is necessary along with the change of the input in order to linearize the
system. The general theory of feedback linearization is out of the scope of
this book, and the interested reader can refer to Refs. [8,9] for a thorough
explanation. As an illustrative example, only the application of feedback
linearization to the class of mechanical systems of the form:
MðcÞc€ þ C

c;c_
	
¼ BðcÞu (10.81)
is proposed here since it is relatively frequent, and it is considered relevant in
the context of spacecraft control. The n  1 vector c is the configuration of
the mechanical system, MðcÞ is the n  n configuration-dependent inertia
matrix, the n  1 vector C

c;c_
	
includes Coriolis, centrifugal, and other
nonlinear terms, BðcÞ is the n  m input matrix, and the m  1 vector u is
the usual control action. Assuming n ¼ m, the nonlinear model in Eq.
(10.81) can be transformed into the linear one choosing:
u ¼ BðcÞ
1

MðcÞn þ C

c;c_
		; (10.82)
where n is the transformed input. The resulting closed-loop system
becomes:
MðcÞc€ ¼ MðcÞn; (10.83)
and, consequently,
c€ ¼ n; (10.84)
which is a linear system. Linear control theory can be now used to design the
control law for outer loop with input n: Note that, in contrast to lineari￾zation, no approximations have been introduced. However, an exact
cancellation of nonlinearities is achieved only with perfect knowledge of the
system model, which is almost impossible to have. Typically, uncertainties
introduce perturbations which deteriorate the control performance with
respect to the ideal case. If the level of uncertainties is high, adaptive control
scheme can be integrated to feedback linearization to improve system
response. As a final remark, feedback linearization should be used carefully.
First, generally, not all the nonlinear systems can be linearized via feedback,
as explained in Refs. [8,9]. Then, even if a system is linearizable, some
nonlinear terms may be beneficial, and thus canceling them out should be
avoided.
Control 587Stability analysis for nonlinear systems
Previous techniques are based on the idea of reducing in some way the
nonlinear system to a linear one (or a family of linear ones), and then
applying tools for linear system to design the control. A different approach
consists in the synthesis of the control considering the nonlinear model
directly. For this purpose, an important result to study the stability is the Lya￾punov’s direct method [9]. This theorem is inspired by a simple physical
observation: if the total energy is continuously dissipated, a system must
eventually reach an equilibrium point.
To introduce the theorem, consider the system:
x_ ¼ fðxÞ: (10.85)
A scalar energy-like function VðxÞ, called Lyapunov function, is defined.
This function is characterized by some properties. First, it has to be positive
definite, i.e., VðxÞ > 0 for xs0 and Vð0Þ ¼ 0; and have a continuous first
derivative. Then, its derivative along trajectories, V_ ðxÞ, is negative semidefin￾ite, i.e., V_ ðxÞ  0 for xs0. Lyapunov’s direct method states that if there exists
a Lyapunov function for the system in Eq. (10.85), and V_ ðxÞ is strictly negative
(V_ ðxÞ < 0 for xs0), the equilibrium point at the origin is asymptotically
stable. More precisely, if the conditions are satisfied only locally, it is said
that the equilibrium is locally asymptotically stable. If the additional condition
VðxÞ/N as jjxjj/N is met, the asymptotic stability is global. In many cases,
it is quite hard to satisfy Lyapunov conditions directly because it is not easy to
find a Lyapunov function such that V_ ðxÞ < 0, and only V_ ðxÞ  0 can be
shown. However, thanks to another theorem, the LaSalle invariant set
theorem [8], it is possible to prove the asymptotic stability also for these situ￾ations. In particular, let us assume V_ ðxÞ  0 over the entire state space and
VðxÞ/N as jjxjj/N, and denote by R the set of points for which
V_ ðxÞ ¼ 0 and by M the largest invariant set in R. LaSalle theorem states
that all solutions globally asymptotically stable converge to M as t/ N.
From this theorem, an important, and frequently used, corollary is derived
and states that if R contains no other trajectories than the trivial on x ¼ 0,
the equilibrium point in the origin is asymptotically stable.
Lyapunov’s direct method is primarily an important tool to study the
stability of a nonlinear system. However, it is also very useful to design sta￾bilizing controllers uðxÞ. There are two main approaches based on trial-and￾error procedure. In the first technique, a certain form of the control input is
chosen, and then the Lyapunov theorem is used to prove the stability of the
588 Francesco Cavenago et al.closed-loop system. In the second technique, a Lyapunov function is hy￾pothesized, and then a controller is designed to realize it and make sure
V_ ðxÞ < 0 (or V_ ðxÞ  0 with LaSalle conditions). An example of both
methods will be proposed in the next section.
Attitude regulation example
Consider the attitude dynamics of a satellite, whose describing equations are
nonlinear:
Iu_ þ u  Iu ¼ t: (10.86)
The 3  3 inertia matrix is denoted by I, the angular velocity by u, and
the control torques by t. For the example, a diagonal inertia matrix is
assumed, and the goal of the control is to reorient the satellite from an initial
attitude to a final one. The first control law that is considered uses Euler an￾gles wx, wy, and wz as attitude parameters, and it is based on the linearization
of the dynamics around the equilibrium point wx ¼ wy ¼ wz ¼ 0. The
linearized model becomes:
Ix w€x ¼ tx;
Iy w€
y ¼ ty;
Iz w€
z ¼ tz;
(10.87)
Basically, the initial nonlinear control problem is transformed into three
single-axis control problem similar to the example case considered for loop
shaping. Therefore, the control law can be designed in an analogous fashion
via loop shaping (or, alternatively, via pole placement). In particular, a PD
controller as in Eq. (10.22) is considered, and thus the closed-loop system is:
Ixw€
x ¼ Kpx
wx  wx

 Kvxw_
x;
Iy w€
y ¼ Kpy
wy  wy

 Kvyw_
y;
Iz w€
z ¼ Kpz
wz  wz

 Kvzw_
z;
(10.88)
where wx, wy, and wz are the setpoints for the Euler angles, and Kp* and Kv*
are the proportional and derivative gains. The control parameters shall be
selected to have a stable system and certain desired response. Since a line￾arization procedure has been followed, the stability and good performance
are guaranteed only locally around the equilibrium point. To appreciate this
fact, another control law, which can ensure global asymptotic stability, is
Control 589introduced for comparison. In this case, the quaternion parameterization is
used, and the following controller is assumed:
t ¼  2HTKpdq1:3  Kvu; (10.89)
leading to the closed-loop dynamics:
Iu_ þ u  Iu ¼ 2HTKpdq1:3  Kvu; (10.90)
where dq1:3 is the vector part of the quaternion error, Kp and Kv are 3 3
diagonal matrices containing positive control gains, and H is the 3 3 matrix
mapping u into dq_ 1:3, namely:
dq_ 1:3 ¼ 1
2
Hu ¼ 1
2
dq1:3

þ dq4I3

u: (10.91)
The variable dq4 is the scalar part of the quaternion error. Note that the
considered quaternion error dynamics assumes that the setpoint is constant.
In order to prove the stability of the closed-loop system, the following
candidate Lyapunov function is defined:
V ¼ 1
2
uTIu þ 2dqT
1:3Kpdq1:3; (10.92)
which is positive definite. The time derivative can be computed as follows:
V_ ¼ uTIu_ þ 4dqT
1:3Kpdq_ 1:3
¼ uT
u  Iu þ 2HTKpdq1:3 þ Kvu

þ 2dqT
1:3KpHu; (10.93)
where the closed-loop dynamics in Eq. (10.90) and the quaternion error
dynamics in Eq. (10.91) have been used in the derivation. Expanding
Eq. (10.93), it is obtained:
V_ ¼  uTKvu  0; (10.94)
which means that V is a negative semide _ finite function. Indeed, V_ ¼ 0 if
u ¼ 0, but dq1:3 could be potentially anything. However, from the dy￾namics in Eq. (10.90), it can be observed that the condition V_ ¼ 0, and thus
u ¼ 0, can be maintained by the system only if dq1:3 ¼ 0. Therefore,
applying LaSalle theorem, it is possible to conclude that the origin u ¼ 0,
dq1:3 ¼ 0 is asymptotically stable. The controller in Eq. (10.89) can reorient
the spacecraft to a desired orientation starting from any initial orientation.
The attitude control examples are further discussed in Chapter 14 e
Applicative GNC cases and examples.
590 Francesco Cavenago et al.The two control laws are compared in simulation considering the
following parameters: Ix ¼ 900 kg/m2
, Iy ¼ 500 kg/m2
, Iz ¼ 650 kg/m2
,
Kpx ¼ 900, Kpy ¼ 500, Kpz ¼ 650, Kvx ¼ 1440, Kvy ¼ 800, and
Kpz ¼ 1040. An approach similar to the one used in Ref. [11] for the com￾parison of some basic attitude control law is followed, and two test case sce￾narios are presented. In the first one, a small attitude maneuver is
commanded as a step in the Euler angles (f ¼ wx ¼ 7 deg, q ¼ wy ¼ 4
deg, and j ¼ wz ¼ 2 deg). The results of the simulations are reported in
Fig. 10.13. It can be seen that the two controllers provide very similar
behavior and reach zero steady-state error. As expected, the linearized model
is a good approximation of the nonlinear dynamics close to the equilibrium
point. The story is different if a large reorientation of the spacecraft is
required. Fig. 10.14 shows the response of the closed-loop system to a larger
step: f ¼ 70 deg, q ¼ 40 deg, and j ¼ 20 deg. It is evident the superior￾ity of the quaternion-based controller which guarantees a well-behaved
response also in this scenario. This is because the design of the controller
took into account the nonlinear nature of the dynamics, and a solution
ensuring global asymptotic stability has been found. On the other hand,
the controller based on linearization has been developed on an approxima￾tion of the dynamics, which is good enough only around the equilibrium
point. As soon as a large deviation is requested, the performance deteriorates.
Other control laws based on quaternions can be designed for attitude
regulation, which guarantee global asymptotic stability. For instance, in
Ref. [12], Lyapunov theorem is used to derive a class of nonlinear PD con￾trollers. A candidate Lyapunov function is defined as:
(a) (b)
Figure 10.13 Comparison between linearization-based controller with Euler angle er￾ror (a) and nonlinear quaternion-based controller (b). Small attitude maneuver.
Control 591V ¼ 1
2
uTIu þ 2kUðdq4Þ; (10.94)
where k > 0 is a control parameter and Uðdq4Þ is a nonnegative function
which is zero in dq4 ¼ 	1. In order to guarantee global asymptotic stability,
the following control law is derived:
t ¼ 2k vUðdq4Þ
vdq4
dq1:3  Kvu: (10.95)
Different controller can be developed depending on the selection of the
function Uðdq4Þ. Note that the asymptotically stable equilibrium points
change with Uðdq4Þ as well. For example, if Uðdq4Þ ¼ 1  dq2
4, the
controller becomes:
t ¼  2kdq1:3dq4  Kvu; (10.96)
and the asymptotically stable equilibrium points are dq4 ¼ 	1, while
the unstable one is dq4 ¼ 0. In Ref. [12], other selection of Uðdq4Þ is
proposed.
Review of control methods
This section presents a brief review of the most useful control methods
for GNC applications. Specifically, PID control, LQR, adaptive controllers,
robust controllers, MPC, and SMC are discussed.
(a) (b)
Figure 10.14 Comparison between linearization-based controller with Euler angle er￾ror (a) and nonlinear quaternion-based controller (b). Large attitude maneuver.
592 Francesco Cavenago et al.PID control
PID are certainly the most widespread controllers both on ground, in indus￾try, and in space, on satellites. Their name recalls the three basic terms mak￾ing up the control action: the proportional term (P), the integral term (I),
and the derivative term (D). Their popularity is due to several factors.
They can be used to control a variety of dynamic systems, spanning from
low-order to high-order, and from linear to nonlinear. Control parameters
are few and relatively simple to set, and automatic tuning methods are avail￾able. They do not rely on very accurate mathematical models, which are
typically necessary for advanced control strategies and whose development
and parameters identification require time and resources. Moreover, note
that, sometimes, the control quality of advanced strategies is limited by
the performance of sensors, actuators, or communication system, and thus
they may not provide significant advantages with respect to PID. Finally,
PID are often exploited in hierarchical control architecture as low-level
controllers.
The ideal PID control action u takes the following form:
u ¼ kpe þ ki
Zt
0
eðsÞds þ kd
de
dt (10.97)
where e is the error between the reference y and the controlled variable y, kp
is the proportional gain, ki is the integral gain, and kd is the derivative gain.
Control laws can be designed also considering only some of the three terms
in Eq. (10.97). For example, it is possible to have P, I, PI, or PD controllers.
Let consider one term at the time to understand what contribution each
term provides. The control scheme in Fig. 10.15 is used in support of the
discussion.
The proportional term realizes an algebraic relation between the control
input and the current control error. As soon as the system deviates from the
Figure 10.15 General feedback control scheme. C(s) is the controller transfer function,
P(s) is the plant transfer function, y is the reference signal, y is the controlled variable, u
is the control action, d is the load disturbance, and n is the measurement noise.
Control 593reference behavior, a corrective action is applied. However, in general, the
proportional term is not sufficient to reach zero steady-state error. Indeed,
assuming Pð0Þ ¼ consts0, a proportional controller CðsÞ ¼ kp, a constant
reference and disturbance of amplitude Ay and Ad, respectively, and neglect￾ing the noise, the steady-state error can be computed with the final value
theorem and results to be:
lim
t/Ne ¼ lim
s/0
se ¼ Ay
1 þ kpPð0Þ
 Pð0ÞAd
1 þ kpPð0Þ
: (10.98)
where s is the generalized frequency introduced in Chapter 10 e Control e
Control design (see also Appendix e A2 for an introduction to Laplace
transform). From Eq. (10.98), it is evident that the steady-state error does not
go to zero and depends on the amplitude of the input, and the gain of the
proportional controller. In particular, the larger the control parameter, the
smaller the error. Nevertheless, it is important to bear in mind that,
increasing too much kp leads to noise amplification and can make the system
become oscillatory, even unstable.
As discussed in the section Chapter 10 e Control e Control design, a
way to guarantee a zero steady-state error, for a step variation of the refer￾ence and the disturbance, is the introduction of an integral action. The trans￾fer function of a PI controller is CðsÞ ¼ kp
ð1þTisÞ
Tis , with Ti ¼ kp
ki
, and thus
Eq. (10.98) becomes:
lim
t/Ne ¼ lim
s/0
se ¼ lim
s/0
AyTis
Tis þ kpð1 þ TisÞPð0Þ
 Pð0ÞAdTis
Tis þ kpð1 þ TisÞPð0Þ
¼ 0: (10.99)
This result can also be proved in a more general way [1]. Assume that u
and e converges at steady state to an equilibrium point u ¼ ue and e ¼ ee.
The control action can be written as:
ue ¼ kpee þ ki lim
t/N
Zt
0
eðsÞds (10.100)
The only way to have the right-hand side finite is that eðtÞ converges to
zero, and consequently ee ¼ 0: Note that no assumptions about linearity or
time invariance has been made, and only the existence of an equilibrium
point at steady-state has been assumed.
594 Francesco Cavenago et al.Increasing the integral gain improves reference tracking and disturbance
attenuation, but, as before, an excessive increase can lead to oscillations of
the response. Notice that there are also other drawbacks in using the integral
term. First, it introduces a 90-deg phase shift, which could destabilize the
system. Then, it can cause the so-called integrator windup. This phenome￾non occurs when an actuator saturates. The feedback loop is broken, and the
system evolves in open loop. The error is generally nonzero, and the integral
term tends to increase. Consequently, the control action may become very
large, and the control signal remains saturated. It may take a long time before
the control action and the integral term return to values useful for a proper
control, and this causes large transient. In order to avoid this issue, anti￾windup strategies shall be implemented. The easiest solution is to “switch
off” the integral action when an actuator saturates. To this aim, either spe￾cific devices can be used to monitor the status of the actuator, or the output
of the controller is saturated (e.g., via software). This latter strategy does not
require additional sensors, but the limits shall correspond as much as possible
to the limits of the actuator in order to guarantee the antiwindup and, at the
same time, to fully exploit the actuation system. Note that windup is related
to the use of an integral action regardless of the specific control law (i.e.,
PID, LQR, etc.) In Ref. [1], an example of an antiwindup method for
output feedback controllers can be found along with a different antiwindup
implementation for PID.
The last term in a PID control law is the derivative one, which provides a
sort of predictive action. To appreciate this, the control action in Eq. (10.97)
is rewritten as:
u ¼ kp

e þ Td
de
dt
þ
kp
Ti
Zt
0
eðsÞds ¼ kpepd þ
kp
Ti
Zt
0
eðsÞds (10.101)
where Td ¼ kd
kp
, and the variable epd ¼ e þ Td
de
dt can be interpreted as a
prediction of the error at time t þ Td. Generally, the derivative action in￾troduces some damping in the system. This can be clearly seen in the
spacecraft single-axis control problem, where a simple proportional term is
not sufficient for asymptotic stability and a derivative action is necessary (see
section Chapter 10 e Control e Control design e Loop-shaping design).
When implementing the derivative term, it is important to take into account
that measurement noise, usually at high frequency, will be amplified causing
Control 595saturation and/or wear of the actuators. Therefore, a low-pass filter is usually
associated to this term. The Laplace transform of Eq. (10.97) becomes:
uðsÞ ¼ kp
0
B@
1 þ
1
sTi
þ
Tds
1 þ
Td
N
s
1
CA
eðsÞ; (10.102)
where N usually varies between 5 and 20.
The parameters of the PID can be tuned in several ways. For LTI
systems, both loop-shaping and pole placement techniques, presented in
section Chapter 10 e Control e Control design, can be used. For a first￾order dynamics, a PI is sufficient to move the closed-loop poles to the
desired location, while, in case of a second-order system, PID controller is
necessary. PI, PD, or PID can be also used with high-order systems, with
the limitation that only dominant poles can be placed. Even nonlinear dy￾namics can be controlled with PID control laws through linearization tech￾niques or directly (see section Chapter 10 e Control e Control design). For
the stability analysis, Lyapunov and LaSalle theorems can be used. The tun￾ing of the gains can be performed also through empirical methods such as
Ziegler and Nichols’ method [13], or relay feedback, as explained in
Ref. [1].
Linear quadratic regulator
In section Chapter 10 e Control e Control design, the pole placement
method has been presented to select the gains of a state feedback controller,
and some shortcomings of this technique have been highlighted. In partic￾ular, in case of MIMO systems, the parameters are more than are needed to
move the eigenvalues, and thus it is not always easy to tune the controller, or
to understand which is the best solution. Moreover, a balance between the
required performance and the magnitude of the control input is often
difficult.
In order to overcome these limitations, optimal control has been devel￾oped. The idea is formulating the control problem as an optimization prob￾lem, which can indeed capture the fundamental trade-off between
regulation performance and control effort. The most popular optimal con￾trol problem is the LQR, whose main results for LTI systems are reviewed in
the following. For a more in-depth study and all the mathematical proofs,
the reader is invited to refer to Refs. [2,5], where extension to linear
time-varying systems is also covered.
596 Francesco Cavenago et al.Finite-horizon linear quadratic regulator
Consider the LTI system in the state space:
x_ ¼ Ax þ Bu; xð0Þ ¼ x0 (10.103)
And the control input in the following form:
u ¼  Kx: (10.104)
The control gain matrix K is determined minimizing the following cost
function:
I ¼
Ztf
0
xTQx þ uTRu dt þ xT
f Zxf ; (10.105)
where Q, R, and Z are weighting symmetric matrices, with Q and Z
positive semidefinite and R positive definite, and xf ¼ x

tf

, with tf being
the final time of the interval of interest. It can be proved that the control
input minimizing the cost function in Eq. (10.105) is:
u ¼  Kx ¼ R1
BTSx; (10.106)
where S is a positive definite, symmetric matrix given by the differential
Riccati equation:
S_ ¼ SA þ ATS  SBR1BTS þ Q; S

tf

¼ Z; (10.107)
which is solved backward in time from the final condition to obtain the
matrix S for the entire time interval. Note that S varies in time, and thus the
final control law is linear time varying.
The design process consists in selecting iteratively the weighting matrices
Q, R, and Z, starting from a guess, and simulating the closed-loop response.
If the performance is not satisfactory, the weighting matrices are changed,
and the process repeated until the desired objectives are achieved. The
cost function in Eq. (10.105) describes mathematically the design trade-off
between the control effort and the closed-loop performance. If the weight￾ing matrices are selected in such a way to penalize more the state than the
control, the closed-loop system will move rapidly to the equilibrium point
at the origin, but it will require a high control effort. On the other hand, if
the quadratic term involving the input is larger than the one of the state, the
control energy will be limited, but the regulation performance will be poor.
Typically, diagonal matrices are used as weights. The diagonal elements
describe how much each state and control input contribute to the overall
Control 597cost. When a particular state or input is wanted to be penalized, the associ￾ated diagonal element is chosen larger than the other ones.
Infinite-horizon linear quadratic regulator
If the restriction of having a finite final time tf is removed, the LQR prob￾lem is simplified. Indeed, the cost function becomes:
I ¼
Z
N
0
xTQx þ uTRu dt; (10.108)
and the control action takes the same form as in Eq. (10.106), but the
matrix S is constant (for LTI systems) and can be found as solution of the
algebraic Riccati equation:
SA þ ATS  SBR1
BTS þ Q ¼ 0: (10.109)
It is worth mentioning an interesting property of this control law. It can
be proved that if the pair (A, B) is stabilizable, and the pair ( ffiffiffiffi
Qp ; A) is
observable, then, there exists only a unique solution S of Eq. (10.109),
and the closed-loop system is asymptotically stable. This is a remarkable
property considering the difficulties of designing a stabilizing controller
for large MIMO systems. Finally, it is recalled that feedforward input and
integral action can be added to both finite- and infinite-horizon LQR con￾trol laws for steady-state tracking, as explained in section Chapter 10 e
Control e Control design e Control design in state space.
Linear quadratic Gaussian control
When the state feedback control has been introduced, it has been assumed
that the full state is available. However, in practice, it can happen that only a
subset of the state vector can be measured. In these situations, can state feed￾back control be implemented? The answer is yes. Indeed, in some cases, the
accessible subset can be used to estimate the nonmeasurable one through an
observer. Consider the usual dynamics in state space:
x_ ¼ Ax þ Bu; y ¼ Cx. (10.110)
The equation of the linear observer takes the following form:
_
ex ¼ Aex þ Bu þ L

y  Cex

; (10.111)
598 Francesco Cavenago et al.where ex is the estimated state vector, and L is the observer gain matrix. From
Eqs. (10.110) and (10.111), the dynamics of the observation error dx can be
derived as:
dx_ ¼ x_  _
ex ¼ ðA  LCÞdx: (10.112)
The error goes to zero if L is selected in such a way that all the eigenvalues
of the matrix A  LC have negative real part. Note that L can be selected
using the pole placement method explained in section Chapter 10 e
Control e Control design e Control design in state space. Indeed, the
observer design problem can be seen as a state feedback control problem
(i.e., find K so that A  BK has given eigenvalues) with AT instead of A,
CT instead of B, and LT instead of K. Like the control problem, the system
must be observable in order to arbitrarily locate the eigenvalues of A LC.
The feedback control law is now introduced using the estimate of the
state:
u ¼  Kex; (10.113)
and thus, the dynamics in Eq. (10.111) becomes:
x_ ¼ Ax  BKex ¼ ðA  BKÞx þ BKdx: (10.114)
Consequently, the closed-loop system is governed by:
2
4 x_
dx_
3
5 ¼
"
A  BK BK
0 A  LC #" x
dx
#
; (10.115)
and its characteristic polynomial can be computed as:
lðsÞ ¼ detðsI  A þ BKÞdetðsI  A þ LCÞ. (10.116)
Eq. (10.116) reveals that the design of the control and the observer can
be carried out independently. Indeed, the poles of the controller do not
affect the poles of the observer (and vice versa), and, given asymptotically
stable controller and observer, their interconnection is asymptotically stable.
This result is known as separation principle. Consequently, one is free to
design first the observer, and then the control law, which receives as input
the estimated state vector as in Eq. (10.113), or vice versa.
Previously, it has been explained that pole placement can be used for the
selection of the observer gain matrix L, but this is not the only method. For a
fast convergence of the state reconstruction, observer poles should be located
deep in the left-half complex plane. Generally, this means having the gain
matrix L large, which makes the observer sensitive to measurement noise.
Control 599A compromise between the speed of reconstruction and the immunity to
noise is desirable and should be sought. To this aim, consider the system
in Eq. (10.110), to which process noise v and measurement noise w have
been added:
x_ ¼ Ax þ Bu þ v; (10.117)
y ¼ Cx þ w.
with x0 ¼ Efxð0Þg. It is assumed that both v and w are Gaussian white
noise with zero mean and covariance Pv and Pw, respectively. Moreover,
process and measurement noise are uncorrelated. The full state vector is
reconstructed through an observer as in Eq. (10.111). It can be proved
that the following observer gain matrix:
L ¼ PdxCTP1
w ; (10.118)
with Pdx ¼ E

dxdxT satisfying the Riccati equation:
APdx þ PdxAT  PdxCTP1
w CPdx þ Pv ¼ 0; (10.119)
minimizes the observation mean square error. This optimal observer is
known as KalmaneBucy filter. Note that there is an analogy between the
optimal observer and the optimal regulator. Eq. (10.119) is analogous to
Eq. (10.109), with AT4A, CT4B, Pdx4S, Pw4Q, and Pv4 R.
The control law resulting from the combination of optimal observer and
LQR is called linear quadratic Gaussian control, and it is:
u ¼  Kex ¼ R1BTSex (10.120)
where ex is obtained from the estimator in Eq. (10.111) with the gain matrix
in Eq. (10.118).
Adaptive control
Among several modern control strategies that can be applied to satellites
control, an interesting one is adaptive control. With adaptive control, it is
intended a control paradigm where the controller is modified in real time
to fulfill some tasks and respond to the real system behavior.
The most common application of adaptive control sees a fixed controller
structure with weights that are changed as the system responds to its inputs.
In general, such controllers are nonlinear and may prove difficult to analyze.
There are many categories of adaptive controllers, and a complete over￾view is out of the scope of the book. However, a brief introduction to the
600 Francesco Cavenago et al.first two basics forms alongside with the limitations and challenges related to
these controllers is presented. The key concept in adaptive controllers is the
ability to control a system and trying to make the closed-loop system
respond like a reference model. In this way, it is possible to select the
response time, steady-state error, and other parameters and design
the controller in such a way that the closed-loop real system behaves in
the desired way.
The first two basic forms are the Model Reference Adaptive Control
(MRAC) and the Adaptive Dynamical Inversion (ADI), which can be
seen, depending on the classification, as an indirect MRAC. The first
approach is meant to adapt the control gains to follow the reference model
while the second is meant to estimate the parameters of the system and
follow the reference model.
First, let’s define a linear scalar reference model that the adaptive control￾lers are going to follow:
x_m ¼ amxm þ bmr; (10.121)
where the state is xm, the reference r, and the system parameters am and bm.
We will use a scalar system for clarity; however, this can be generalized for
larger scale systems. If we want the system state to converge to the reference,
the parameters can be set as am ¼ bm ¼ l and the first order linear
system is obtained:
x_m ¼ lðr  xmÞ; (10.122)
which is a simple lowpass filter of the first order with cutoff equal to l if l >
0. Now let the real system be:
x_ ¼ a x þ b u; (10.123)
where u is the control action. The error that the controllers will try to
minimize is defined as:
e ¼ x  xm. (10.124)
Model reference adaptive control
In the MRAC paradigm, the goal is to estimate the control weights that
allow the real system to track the desired system. The controller form is as
follows:
u ¼ bkxx þ bkrr. (10.125)
Control 601Substituting in the real system, we get:
x_ ¼ 
a þ bbkx

x þ 
bbkr

r: (10.126)
Hence, the error would vanish when a þ b bkx ¼ am ¼ l and b bkr ¼
bm ¼ l. If a and b are perfectly known, there is the need to use an adaptive
controller; however, the real system properties might be difficult to estimate,
prone to error, or changing in time. The goal of adaptive controllers is to
face such problematics. In MRAC terms, the estimated control gains should
evolve in time to match the theoretical best gains, defined as follows:
8
>><
>>:
kx ¼ l þ a
b
kr ¼ l
b
; (10.127)
that are function of the real system variables a and b. If we substitute this
into the error dynamics, the following equation is obtained:
e_ ¼  le þ bDkrr þ bDkx; (10.128)
where Dkr ¼ bkr  kr and Dkx ¼ bkx  kx. Indeed, if these are null, the
error falls to zero according to l. Another important aspect to consider is the
time evolution of the adaptive gains. A Lyapunov function can be con￾structed, derived with respect to time, and then set to be negative. This
procedure is often used in adaptive controllers to guarantee stability and find
the parameters update laws. Let’s define the function as follows:
L ¼ 1
2
e
2 þ
1
2
jbj

Dk2
r
gr
þ
Dk2
x
gx

; (10.129)
where the constant positive weights gr and gx set the rate of adaptation of
the controller gains. From Eq. (10.129), the function is always positive and
increasing with its variables (i.e., the three errors). Deriving the function and
assuming that the ideal gains are static 
D_
kx x _bkx
!
, we get that to use
Barbalat’s lemma and prove stability, the control gain update must be:
8
>><
>>:
bkx
_ ¼ gx e x signðbÞ
bkr
_ ¼ gr e r signðbÞ
; (10.130)
602 Francesco Cavenago et al.which would give L_ ¼ le2 < 0. It should be noted that the sign of the
mapping of the control action to the real state must be known beforehand,
otherwise the MRAC does not converge. This is not surprising since most of
the classical controllers require this minimum knowledge.
Adaptive dynamical inversion
The ADI for of an adaptive controller is meant to directly estimate the sys￾tem parameters a and b instead of the control gains. The control law then
becomes:
u ¼ 1
bb
ððam  baÞx þ bmrÞ ¼ 1
bb
ððl þ baÞx þ lrÞ. (10.131)
The reader should see the analogies with the MRAC control law and its
parameters. Following the same procedure discussed in the previous section,
the derivative of the error is obtained as:
e_ ¼  le  Dax  Dbu; (10.132)
where Da ¼ ba  a and Db ¼ bb  b. The parameters of the real system, like
for the MRAC case, are fixed in time. Again, a Lyapunov function is
selected as:
L ¼ 1
2
e
2 þ
1
2
Da2
ga
þ
Db2
gb

; (10.133)
with adaptive rate gains ga and gb. Letting the derivative to be negative, as
before, the parameter estimation is:
8
><
>:ba
_
¼ ga e xbb
_
¼ gb e u. (10.134)
The main difference with the MRAC is that in ADI attention must be
paid to sign crossing of bb, since the control action tends to infinity as
bb/0.
Both controllers depend on the state, error, and reference or control ac￾tion. The error is computed comparing the estimated state with the refer￾ence state; hence, it is always needed to propagate the reference model
based on the current input reference. This process is computationally
more expensive than fixing the controller in the first place, but it can in￾crease the applicability range and even the system robustness.
Control 603Additional parameters estimation
Adaptive controllers can also be used to estimate system parameters.
Defining the new system as:
x_ ¼ ax þ bu þ wTFðxÞ; (10.135)
with w and FðxÞ being the parameters and their basis functions, respectively.
The control laws and the updates can be derived as follows.
For the MRAC:
8
<
:
u ¼ bkxx þ bkrr þ wbT
FðxÞ
w_ ¼ GweFðxÞ signðbÞ ; (10.136)
while for the ADI:
8
>><
>>:
u ¼ 1
bb

 ðl þ baÞx þ lr  wbT
FðxÞ
	
w_ ¼ GweFðxÞ. (10.137)
The nominal gains/parameters updates are kept equal.
Convergence of parameters
Both ADI and MRAC solutions, as other adaptive paradigms, do not guar￾antee convergence of parameters unless a persistent excitation is applied on
the system. Even in cases where perfect measurements are available, the esti￾mated parameters converge to their true values only with specific classes of
reference signals.
Stability does not imply convergence to the real values, but a bounded
convergence is expected. The result is expected as estimating parameters
of a dynamical system requires a reference signal capable of exciting a
response dependent on the said parameters. This applies also to adaptive
controls where a state observer is used to estimate the uncertain parameters.
In general, it is not wise to use an adaptive controller to estimate the sys￾tem parameters, but this information is not always needed in order to have a
stable system with prescribed performance.
Adaptive control issues
Both ADI and MRAC parameter update equations rely on the state deter￾mination. Since measurements are always affected by noise, it is straightfor￾ward to see that noise can negatively affect the variation of the parameters;
604 Francesco Cavenago et al.hence, a common solution is to apply a dead-zone to the error. In this case,
the tracking error e will never reach zero but will converge to a bounded
zone. The limit of the dead-zone should be determined taking into account
the noise content of the measured state. In general, the source of instability at
higher frequencies is a static nonmodeled bias.
It is important to underline that, like classical techniques, also adaptive
control can suffer from windup effect. In fact, the parameters are estimated
through an integration process. Classical antiwindup techniques should be
adopted while applying adaptive control.
Robust control
When the system is too complex to analyze (and simplification with uncer￾tainties are necessary) or has uncertainties that are not easily solved by gain
scheduling or other classical approaches, a robust control technique should
be adopted to achieve satisfactory performance.
Contrary to adaptive controllers, in robust control, the gains are evalu￾ated a priori and usually do not change adapting to the measures and
response of the system. Hence, the problematics of adaptive controllers
are avoided. The first introduced methodology is the HN (H infinity) con￾trol that can be implemented also in a structured approach. In this case, HN
tuning techniques, like loop shaping, are applied to determine the weights of
a PID controller. The second is the m synthesis that uses HN paradigm
specializing it for uncertainties in MIMO systems.
H-infinity
The HN (H-infinity) methods can determine a controller with prescribed
performances, also in the frequency domain. The name comes from the
norm of a transfer function that belongs to the Hardy space (HN) and is
defined as follows:
jjGðjuÞjjN ¼ sup
u˛ℝ

max
i
li

GðjuÞGðjuÞ
T
	
. (10.138)
In simpler terms, it is defined as the least upper bound over all real fre￾quencies u of the Euclidean norm of GðjuÞ, here expressed as the
maximum singular value of a transfer function matrix GðjuÞ. Let us stress
the fact that this norm must be computed, at least theoretically, over the
whole frequency spectrum.
First, let’ s consider a linear system plant of state x, measures y, control
action u, and performance z. Performances must be written in a way that
Control 605the control goal is to minimize them and is up to the designer to shape them
according to requirements.
8
>>><
>>>:
x_ ¼ AðjuÞx þ BðjuÞu
y ¼ CyðjuÞx þ DyðjuÞu
z ¼ CzðjuÞx þ DzðjuÞu
; (10.139)
where the frequency dependency has been explicitly considered. We can
then enforce a control law in the form:
u ¼ KðjuÞy. (10.140)
Then, we would have the performance expressed as follows:
z ¼ 
Cz þ DzK

In  DyK
1
Cy

x ¼ FtðjuÞx; (10.141)
where z is function of a frequency-dependent matrix often called Linear
Fractional Transformation (LFT) and the state. For this example, we have
assumed to have null reference and the principal task is to bring to zero the
state, but, of course, the same approach can be generalized without any issue.
Then the goal is to find KðjuÞ such that jjFtðjuÞjjN is minimized. This
transforms the control problem into an optimization problem. Uncon￾strained optimization could potentially lead to complex forms of KðjuÞ,
while structured version would possibly reach poorer minimization of
jjFtðjuÞjjN in absolute value. On the other hand, nonstructured HN may
exhibit a complex structure not well suited for online applications; hence,
order reduction is often used to derive suboptimal solutions.
The keen reader should have already seen that minimizing Ft de facto
minimizes the influence of the state over the performance; hence, if the sys￾tem is stable, so will be the performances. There is an underlying assumption
that jjFtðjuÞjjN < 1 in order to have stability as well.
Up to now, the discussion was not related nor referenced to robustness,
but only to performance and state. The extension is quite trivial and shows
the real application of HN, with some of its inherent limitations. Let us
modify the system dynamics to account for (unmodeled) disturbances, w:
x_ ¼ AðjuÞx þ BðjuÞu þ BwðjuÞw. (10.142)
The performance would be now expressed as a function of the
disturbances:
606 Francesco Cavenago et al.z ¼

Cz þ DzK

In  DyK
1
Cy
	

juIn  A  BK
I  DyK
1
Cy
	1
Bww ¼ FtðjuÞw.
(10.143)
Minimizing jjFtðjuÞjjN guarantees that, over all possible frequencies, the
performance z is not (less) influenced by the disturbs w. If Ft is an appro￾priate LFT, it is sufficient to have jjFtðjuÞjjN < 1 to achieve stability.
Note that, uncontrollable or unobservable system would not easily pass
this test.
The computation of the norm or the values of KðjuÞ is out of the scope
of the book, but a detailed derivation can be found in. On the other hand, it
is important to focus on BwðjuÞ that maps the disturbs to the state dynamics.
The derivation of BwðjuÞ requires a good knowledge of the system and
greatly affects the determination of the control law. It should be stressed
that a poor modeling would lead to undesirable results. Moreover, measure￾ment noises or actuators errors can be easily included in the disturbances
term.
The structured version of the HN has been already used for space appli￾cations in the notable example of the Rosetta mission where it has been
applied for thruster maneuvers after a failure in the propulsive subsystem
had been found.
Mu-control
Mu-synthesis can be seen as an extension of the H-infinity synthesis for
MIMO plants with statical or dynamical uncertainties. The name refers to
the letter often used to represent the H-infinity robust performance and is
a key figure in understanding the effects of the uncertainties in the closed￾loop system.
The m term gives an indication of the effects of the uncertainties on the
system output. for a given m, the peak gain of the system transfer function
stays below m (in normalized units) for uncertainties up to 1
=m of the uncer￾tainties introduced in the transfer function. In general, a value below 1 is
preferred. If the analysis shows m extremely high or even infinity, it means
that the system, with the current gains, is not able to guarantee stability in
the full range of the considered uncertainties.
Like the H-infinity case, even m is a function of frequency; hence, the
peak value in the frequency domain shall be considered. Even with modern
algorithms, it is not easy to compute the exact value in the whole frequency
domain, and, often, minimum and maximum boundaries are the only
Control 607quantities that can be obtained. Still, important information can be extracted
through this method.
One of the most popular ways to use mu-synthesis is the D-K iteration
algorithm consisting in iterations of h-infinity and m-evaluation.
First, the control gain K (u ¼ Ky) over the nominal system with no un￾certainties is estimated using h-infinity technique, making sure it minimizes
the closed-loop gain.
Then, the robust performance m, according to the uncertainties esti￾mated in the plant, is estimated. The value of m is then scaled (D-scaling)
as the scaled h-infinity performance. The obtained quantity is a function
of the uncertainties and of the control gain K.
Finally, the K-step, as the name suggest, aims at finding a new K that
minimizes the scaled h-infinity performance computed in the previous step.
The process is repeated numerically until convergence to a stable
condition.
Since the algorithm is a continuous iteration of h-infinity plus evalua￾tion, if not constrained, it can generate complex gain structures. For this
reason, also for the mu-control, it is possible to adopt a structured approach,
thus simplifying the controller structure. This is an advantageous solution for
real-time controller used in context where computational power is limited,
like on-board of a spacecraft.
Robust adaptive controllers
Robust controllers permit to generate control laws that are robust to disturbs
and uncertainties in the system, often resulting in complex and computa￾tionally expensive algorithms. Sometimes, gains are computed beforehand,
and, in general, they are not modified during operations, resulting in cases
where the consumption is higher than needed. On the other hand, adaptive
controllers can react in real time to changes in the model but are not specif￾ically targeted to disturbance or uncertainties rejection as they usually force
the system to follow a predetermined behavior.
A new class of adaptive controllers can be defined as those controllers
that modifies the gains (or the structure) of the control law to guarantee
robustness in cases where the system is uncertain or complex (bounded) dis￾turbs are present.
Typically, this can be achieved by a Lyapunov function, where the pro￾cess must take into account disturbs and uncertainties and, in the end, will be
able to relate the gain update in time with the state of the system. The pro￾cess is quite similar to the one used for adaptive controllers, but the aim is the
608 Francesco Cavenago et al.one of the robust controllers. There are several examples in literature of this
kind of controllers, each with a different approach or way to execute the task
or to counteract specific uncertainties. See for a broader overview.
Model predictive control
The review of the most common control methods has covered important
topics such as model-free feedback control, unconstrained optimal regulator,
and adaptive control. The benefits and drawbacks of the mentioned ap￾proaches have been thoroughly discussed in the previous sections. MPC rep￾resents a synthesis of the above strategies: it is an optimization-based control
scheme that merges the advantage of constrained optimization and feedback
control. Due to its optimization-based foundations, MPC is often used to
synthesize guidance, coupled with a low-level controller to track the desired
control profile.
The rationale behind this type of control lies on the inherent limitations
of offline optimal control. By definition, the classical optimal control prob￾lem is based on an analytical cost function and dynamical model, which are
used to determine and plan the control sequence to be executed. Obviously,
the more the dynamical model is adherent to reality, the more we can be
confident that the offline control sequence, if executed in real operations,
will drive the spacecraft to the desired target state, optimizing the cost func￾tion. Sticking to the familiar terms introduced in the chapter, the optimal
control approach does not present any feedback, i.e., it can be seen as an
open-loop controller. Nevertheless, we understood how feedback is a crit￾ical feature for the effective control of a generic plant. MPC is essentially a
constrained receding horizon optimization approach to plan control actions
following optimal control problems solved sequentially and iteratively at
each timestep DtMPC.
The optimization covers Ns time steps, which results in Ns control in￾puts, or Nm if the control horizon is shorter. In rigorous terms, Ns denotes
the length of the prediction horizon or output horizon, and Nm denotes the
length of the control horizon or input horizon (Nm  Ns), as shown in
Fig. 10.16. When Ns ¼ N, we refer to this as the infinite horizon problem,
and similarly, when Ns is finite, as a finite horizon problem. Only the first
computed control is executed, and, at the next time step, the planner solves
the optimization problem again based on the actual current state. In its
simplest form, the objective function used in MPC seeks the minimization
of the quadratic difference between the target state, ex , and the plant state, xk
Control 609at each time step, and a quadratic term representing the control effort, simi￾larly to Eq. (10.105) here reported for a generic control objective not limited
to regulation:
I ¼
Ztf
0

x  ex
T
Q

x ex

þ uTRudt þ

xf  exf
T
Z

xf exf

where Q, R, and Z are weighting symmetric matrices, with Q and Z
positive semidefinite and R positive definite, and xf ¼ x

tf
 ¼ xkþN,
with tf ¼ Ns$DtMPC being the final time of the interval of interest, also
known as the prediction horizon (Fig. 10.17). For practical application and
Figure 10.16 Receding horizon scheme: only the first control action is executed.
Figure 10.17 Example of collision avoidance constraint.
610 Francesco Cavenago et al.solution, optimal control is casted into linear or nonlinear programming. For
this reason, the discrete form is much more useful and reads:
J ðxk; ukÞ ¼ 
xkþN  exk
T
Z

xkþN exk

þ
N
X1
i¼1

xkþi  exk
T
S

xkþi exk

þ
N
X1
i¼0
uT
kþi
Rukþi
(10.146)
where Z is the weighting (or penalty) on the final time step. The weighting
on the final state variation Z is formed from the discrete-time algebraic
Riccati equation, as in the unconstrained LQR, and it is typically enforced
to guarantee the stability of the closed-loop system.
The overall performance of an MPC is strongly linked with the selection
of its three fundamental parameters. The specific numerical values are
strongly dependent on the mission requirements and scenario. Nevertheless,
we can draw insights to help in the MPC tuning process.
• Prediction horizon. The prediction (or receding) horizon
tf ¼ Ns$DtMPC defines how far ahead in the future the controller seeks
to optimize the evolution of the controlled dynamics. In general, a low
value yields a controller unable to take advantage of the long-term dy￾namics evolution to find the optimal control. On the contrary, a large
prediction horizon leads to an excessive computational time that may be
unnecessary in terms of optimality, jeopardizing the actual feasibility of
the on-board implementation.
• Sampling time. The sampling time DtMPC defines the time span between
two successive optimizations with feedback signals or states. A small value
is always desirable in terms of accuracy, as a faster update can better repre￾sent the dynamics evolution and to modulate the control action more
precisely if needed. However, keeping constant the prediction horizon,
a smaller sampling time implies a larger dimension of the optimization
vector. Since the optimization computational time depends on the prob￾lem size, a small sampling time may be prohibitive for on-board
implementation.
• Control horizon. The control horizon indicates for how many sampling
steps the control resulting from the solved optimal problem is applied,
before restarting the optimization to update the control profile. The
Control 611most robust option is to recompute the control every sampling time, to
deal with unpredicted changes in the external conditions as soon as
possible. However, longer control horizons relax the frequency at which
the on-board computer needs to recompute the control profile, relieving
computational effort that could be allocated to other tasks.
The dynamical model functions as a constraint between successive plan
states. Hence the optimal control problem reads:
minu J ðxk; ukÞ
subject to xkþiþ1 ¼ f ðxkþi; ukþiÞ; i ¼ 1;.; Ns (10.147)
where the dynamics is encoded into the constraint, in which each state of the
receding horizon is linked to the previous one in the sequence, i.e., the i
pedix. The cost function minimization may be subject to different con￾straints. The most common in space applications are hereby listed:
• Actuator control action constraint. Typically, maximum or minimum admis￾sible control is enforced by constraining the vector value within a convex
domain, defined as:
umin < ui < umax
It is important to remark that this is a convex constraint due to its vecto￾rial nature. The domain is convex entailing a hypercube with no holes. This
constraint is conceptually different from limiting the minimum and
maximum absolute value of the actuation [14].
To understand this, let us go through an example: imagine we have a
robot with 1 degree of freedom to be controlled with a maximum acceler￾ation 1 m
s
2 and a maximum deceleration 0:5 m
s
2 . Then we would enforce
the convex control action constraint as 0:5 m
s2 < ui < 1 m
s
2 . The lower
bound is used to define the negative value. There is only no limit on the
minimum impulse the throttle can deliver. Let us now imagine the situation
in which the maximum acceleration and deceleration absolute value limit is
1 m
s
2 , but the minimum acceleration and deceleration we can get is con￾strained to 104m
s
2 , absolute value. This means that the acceptable control
would be: 1 m
s
2 < ui < 104m
s2 or 1 m
s
2 < ui < 104m
s
2 , which is not a
convex constraint.
• Collision avoidance constraint. The collision avoidance constraint refers to
the imposition of given distance from a certain static or moving entity
throughout the optimization path. The easiest way to picture this
constraint is to think of a trajectory that needs to keep a certain minimum
612 Francesco Cavenago et al.distance from an obstacle, such as another spacecraft. Unfortunately, this
constraint is concave; hence, it must be treated carefully (see use case sce￾nario in [Chapter 14dApplicative GNC cases and examples]).
1  
xkþi  xo
kþi
T
CTPC
xkþi  xo
kþi

< 0; i ¼ 1; ::; N
C ¼
"
I3
03
#
where the superscript o refers to the keep-out-zone is an ellipsoid centered on
the obstacle and expressed by its quadratic form with the positive semi￾definite matrix P . If the keep-out-zone is a sphere, the quadratic form is
simply a symmetric matrix P ¼ r
2I3 where r is the spherical safe region
radius.
Up to now, it is evident how MPC resembles the LQR scheme. Indeed,
even though MPC can optimize a generic cost function, it is true that, in its
simplest form, MPC can be thought as a constrained version of the classical
LQR with finite time horizon. Indeed, as described for the LQR, the cost
function describes mathematically the design trade-off between the control
effort and the target reaching performance. If the target state is penalized
more than the control, the closed-loop system will move rapidly toward
the target state, but it will require a high control effort. On the other
hand, if the quadratic term involving the input is larger than the one of
the target states, the control energy will be limited, but the plant may
take long time to reach the target state.
Again, diagonal matrices are used as weights. The diagonal elements
describe how much each state and control input contribute to the overall
cost. When a particular distance to target state or control input needs to
be penalized, the associated diagonal element is chosen larger than the other
ones. For this reason, it is also common to normalize the weights choosing
the identity matrix as one of the weights (Q or R).
The MPC algorithms mainly differ for the selection of the objective
function and the different dynamical models. Since MPC is a control strat￾egy designed to be executed on-board, the applications strive to reduce the
computational complexity of the finite-time receding horizon optimization.
The most common MPC alternatives, in terms of objectives and constraints,
are reported in Table 10.3:
Control 613Let us go through an example on how to design a simple MPC for rela￾tive trajectory control or rendezvous. We want to design an MPC scheme
that controls the trajectory of a spacecraft with respect to a target in nearly
circular orbits. The cost function we want to optimize is quadratic on the
control effort and on the distance to the final state. The spacecraft is subject
to the presented ClohessyeWiltshire dynamical model (see Chapter 4 e
Orbital dynamics e Relative dynamics) and has a maximum thrust
constraint.
In order to solve efficiently the constrained optimal control problem, we
seek to express the whole cost function as a function of the input control,
which represents the decision variable of the optimization. If the collision
avoidance constraint is not enforced, the MPC reduces to a linearly con￾strained quadratic optimization problem. Hence, the problem can be recast
into Quadratic Programming formulation, using Eq. (10.146) as basis. The
quadratic programming formulation for the MPC can be rewritten as:
minUk
1
2
UkQUk þ HUk
subject to VUk < W
where Uk ¼ ½uk; .; ukþNs1 is a stacked vector containing the decision
variables for the optimization problem, namely the control action for each
discretization time step. The dynamics is inserted directly into the cost
function using the linearized ClohessyeWhiltshire model and its state
transition matrix (cfr. Chapter 4 e Orbital Dynamics e Relative Dynamics).
Indeed, one can write the compact form using the state transition matrix and
comprising the stacked vectors for all the Ns time instants:
Xk ¼ Jxk þ UUk
Table 10.3 MPC algorithms alternatives.
Cost function Dynamical model Constraints Solution
Norm-1 linear Linear Linear Linear programming
Quadratic Linear None Explicit (cfr. LQR)
Quadratic Linear Linear Quadratic programming
Nonlinear Nonlinear Nonlinear Nonlinear programming
614 Francesco Cavenago et al.where the relevant matrices can be derived from mathematical manipula￾tions of the stacked form of Eqs. (10.146)e(10.147):
J¼ ½Fðtkþ1; tkÞ; Fðtkþ2; tkÞ;.; FðtkþN ; tkÞT
U ¼
2
6
6
6
6
6
4
Fðtkþ1; tkÞB 0 / 0
Fðtkþ2; tkÞB Fðtkþ2; tkþ1ÞB / 0
« « 1 «
FðtkþNs
; tkÞB FðtkþNs
; tkþ1

B / F
tkþNs
; tkþNs1

B
3
7
7
7
7
7
5
and
Q ¼ 2L1 þ 2UTL2U
H ¼ 2xT
k JTL2U  2GT
k L3U  2x
wT
k ZL4U
L1 ¼
2
6
6
6
6
6
6
6
4
R 0 / 0
0 R / 0
« « 1 «
0 0 / R
3
7
7
7
7
7
7
7
5
˛R 3Ns3Ns
;
L2 ¼
2
6
6
6
6
6
6
6
4
S 0 / 0
0 S / 0
« « 1 «
0 0 / Z
3
7
7
7
7
7
7
7
5
˛R 6Ns6Ns
L3 ¼
2
6
6
6
6
6
6
6
4
S 0 / 0
0 S / 0
« « 1 «
0 0 / 0
3
7
7
7
7
7
7
7
5
˛R 6Ns6Ns
;
L4 ¼ ½ 0 0 / I6  ˛R 66Ns
Control 615W ¼
"
Umax
Umin #
˛R 6Ns1
;
V ¼
"
I3Ns
I3Ns
#
˛R 6Ns3Ns
Finally, the vector Gk is a stacked vector containing the desired state for
each time step of the receding horizon (it can be fixed to the final position or
moving along a trajectory). The problem in this form can be solved at each
time step with different algorithms falling within the large domain of func￾tion minimization, e.g., interior point, gradient descent, etc.
Robust model predictive control
Although MPC optimizes the control sequence repeatedly, its efficacy is
largely influenced by the accuracy of the dynamical model representation.
Robust variants of MPC try to include bounded disturbance while mini￾mizing the cost function and reaching the objectives. A nonexhaustive list
of robust approaches to MPC is given below. Essentially, they differ in
the representation of the uncertainties affecting the system [15].
Different uncertainty sets have been proposed in the literature in the
context of MPC and are mostly based on time-domain representations.
Frequency-domain descriptions of uncertainty are not suitable for the
formulation of robust MPC because MPC is primarily a time-domain tech￾nique. A nonexhaustive list of techniques for robust MPC is reported here
[15]:
• Impulse/step response.
• Structured feedback uncertainty.
• Multiplant description.
• Bounded input disturbances.
The exhaustive discussion on these advanced methods is left to the reader
[15], since it is beyond the scope of this book.
Sliding mode control
SMC is a nonlinear control method that computes the control action from a
set of admissible functions. The objective of the control is to drive the system
to slide on a surface, defined in the phase space, which is representing the
system’s target behavior. The state feedback control law is not a continuous
function of time, but it switches from a continuous control structure to
another one according to the system state with respect to the sliding surface
(i.e., if the states are above or below the surface). Thus, SMC can be cate￾gorized in the class of the variable structure control methods.
616 Francesco Cavenago et al.To visualize the concept of SMC, we can imagine a relay-based control
system, where the relays are electrically operated switches that are used to
implement logical on-off control actions. The on-off controls can be
regarded as primordial variable structure control strategies, which established
the theory behind SMC.
A generic SMC operation can be divided in two distinct phases: reaching
phase and sliding phase. The former sees the system approaching the sliding
surface by exploiting one continuous control structure (e.g., a switch that is
always on, in the relay-based simplified analogy). The latter takes place
when the sliding surface is reached. Then, the discontinuous controller
forces the states to slide toward the set point (i.e., the origin in the phase
space). This behavior is shown in Fig. 10.18.
Let’s consider a second-order nonlinear system:
€x ¼ f

x; x_
	
þ u;
where u is the control input, which is designed to make the system reaching
a desired state, xref . We can define the sliding surface, s, as:
s ¼ Dx_ þ k Dx;
where k is a scalar and Dx ¼ x  xref is the control error. If we force the
system to stay on the sliding surface, the SMC can be derived by setting s_ ¼ 0:
For example, in the problem of spacecraft attitude control, we may
define the sliding surface as:
s ¼ du þ kdq1:3;
where du is the angular rate error, and dq1:3 is the vectorial part of the error
quaternion.
Imposing s_ ¼ 0, we obtain:
s_ ¼ u_  u_ ref þ
1
2
k HðdqÞdu
¼ u_  u_ ref þ
1
2
k

dq4du þ dq1:3  
u þ uref ;
where we used the quaternion attitude kinematics rules.
Thus, to control the spacecraft dynamics:
u_ ¼  I
1½ðu  IuÞ  t;
The control torque can be derived as:
t ¼ I

u_ ref  1
2
k

dq4du þ dq1:3  
u þ uref 
þ ðu  IuÞ .
Control 617The SMC has the advantage of not being very sensible to the uncer￾tainties on system parameters, and it provides stability with respect to
modeling unknowns. Moreover, it allows to reduce the modeling order
of the dynamics, it guarantees finite convergence time, and it provides a
convenient control profile for systems with on-off actuators (e.g., thrusters).
In general, SMC offers a simple and robust control action, which is suitable
for online real-time applications with limited computing capabilities.
However, its main weakness is related to the chattering, which is due to
implementation imperfections. Indeed, the switching control structure
makes the system to chatter in a close neighborhood of the sliding surface.
This is particularly problematic for highly accurate systems and for spacecraft
with flexible appendages and internal sloshing. Chattering can be reduced
through the use of dead bands or boundary layers around the sliding surface.
In alternative, filtered sliding mode or higher order SMCs may be used to
alleviate the chattering effect. Chattering can be visualized along the sliding
surface in Fig. 10.18.
Control budgets
Once a spacecraft control design is finalized by using one of the tech￾niques recalled in this chapter, a control budget is needed in order to predict
the actual behavior of the spacecraft in closed loop. In particular, there are
three ways to characterize a control design:
• Stability of the system in nominal conditions.
• Performance of the system in nominal conditions.
Figure 10.18 Sliding mode control operation. Reaching phase and sliding phase are
visible.
618 Francesco Cavenago et al.• Stability and performance robustness in face of modeled parametric un￾certainties and neglected dynamics.
According to stability, common industrial practice is to use the tradi￾tional stability margins (gain, phase, delay) to verify the robustness of the
closed-loop system. However, the use of these classical tools is justified
when a hypothesis of decoupling (or small coupling) among control axis
stays and allows the control engineer to deal with axis-by-axis SISO synthe￾sis. This condition is not always verified, especially when large flexible ap￾pendages, like solar arrays, are installed on the main spacecraft hub. In
these cases, a complex MIMO system has to be considered, for which clas￾sical stability margins cannot provide a complete understanding of the system
robustness, while the modulus margin can result more appropriate.
When dealing with spacecraft control performance, we generally refer to
a set of requirements imposed by the nature of the mission. A LEO obser￾vation mission generally demands a high agility (cfr. Chapter 1 e Introduc￾tion) in order to guarantee a high ground coverage rate for instance. This
means that the satellite has to be able to make fast slew maneuvers that
impose to reduce the controller settling time and maximize the available im￾aging window. On the other hand, when very tight pointing performances
are demanded for long observations of outer space objects, like exoplanet,
the level of pointing accuracy makes the set of performance even more chal￾lenging as for the case of the new generation of space telescope as the James
Webb platform, launched in December 2021. For these missions, the same
attitude control system can be a source of image perturbation. The reaction
wheels used for coarse attitude control can in fact suffer from imbalances,
ball bearing, and motor imperfections, as seen in Chapter 3 e The Space
Environment e Internal Perturbations, that propagate through the space￾craft structure all the way to the scientific payload, causing an irremediable
loss of information in the high frequency bandwidth.
For these reasons, the European Space Agency (ESA) made an effort to
overcome the individual industrial inhouse methods and propose common
guidelines and practice to evaluate the control pointing budget.
The ECSS Control Performance Standard [16] and the ESA Pointing
Error Engineering Handbook [17] define a framework for control perfor￾mance for any space system, including the space segment, the ground
segment, and the launch service segment. These documents can be applied
to evaluate the stability and performance of closed-loop algorithms with a set
of prescribed indexes. Due to the already evocated importance of pointing
performance, most of these documents are based on the definition of the
Control 619pointing error. Common practice is to analyze the error at each instant t of a
time domain observation, while performance can be defined on a window
time Dt as well. This is important, for instance, when performance has to
be bounded to guarantee a correspondent level of image or communication
quality by relying on the performance indexes to the payload integration
time.
In the same way, a stability time Dts can be defined to evaluate the stability
of the control algorithms by comparing the relative error on different obser￾vations of time window Dt.
Fig. 10.19 shows an example of windowed time and stability time for an
observation time span.
Notice that pointing performance and stability can be defined not only
for the attitude control system generally related to the spacecraft main body
but also for payload elements, like antennas for high-accuracy pointing. In
case of large and flexible spacecraft, in fact, flexible appendages connected
to the rigid main body could experience a degradation of the pointing
requirement due to the excitation of their natural modes.
Let consider now a generic spacecraft for which pointing error has to be
determined. Following ESA standards, we can distinguish:
• Absolute knowledge error (AKE). Difference between the actual parameter
(main body attitude, payload attitude, etc.) and the known (measured or
estimated) parameter in a specified reference frame.
• Absolute performance error (APE). Difference between the target (com￾manded) parameter (main body attitude, payload attitude, etc.) and the
actual parameter in a specified reference frame.
• Mean knowledge error (MKE). Mean value of the AKE over a specified
time interval Dt.
Figure 10.19 Example of window time and stability time for definition of pointing er￾rors [16,17].
620 Francesco Cavenago et al.• Mean performance error (MPE). Mean value of the APE over a specified
time interval Dt.
• Relative knowledge error (RKE). Difference between the APE at a given
time within a time interval Dt and the MKE over the same time interval.
• Relative performance error (RPE). Difference between the APE at a given
time within a time interval Dt and the MPE over the same time interval.
• Knowledge drift error (KDE). Difference between MKEs taken over two
time intervals separated by a specified time Dts within a single observa￾tion period.
• Performance drift error (PDE). Difference between MPEs taken over two
time intervals separated by a specified time Dts within a single observa￾tion period.
• Knowledge reproducibility error (KRE). Difference between MKEs taken
over two time intervals separated by a specified time Dts within different
observation periods.
• Performance reproducibility error (PRE). Difference between MPEs taken
over two time intervals separated by a specified time Dts within different
observation periods.
The definition of these pointing errors allows space control engineers to
make accurate prediction of worst-case configurations both in linear and
nonlinear domain. In linear domain, frequency analyses are possible by
considering the statistical description of all possible error sources (i.e., sensor
noises, external orbital perturbations, internal disturbances like solar array
drive mechanism driving signal, etc.) and the propagation of the disturbance
to the pointing error through the system. If, in fact, an LTI transfer function
HðjuÞ of the plant from the error source to the pointing error is available, as
for the vast majority of space missions, where the spacecraft rates are gener￾ally kept very low, the probability distribution of the pointing error (see
Chapter 12 - GNC Verification and Validation - Statistical methods]) is pro￾vided by the linear combination of the probability distribution of each error
source trough the linear plant.
The variance of an error source s2
es described as random processes is, in
fact, related to its power spectral density (PSD) PesðuÞ:
s2
es ¼ 1
2p
Z
N
0
PesðuÞdu
Control 621The PSD of the output error PoeðuÞ depends on the transformation of
PesðuÞ through the system HðjuÞ:
Poeð Þ¼ u jHð Þj ju Pesð Þ u
The variance of the output error signal s2
oe is thus computed from its
PSD PoeðuÞ:
s2
oe ¼ 1
2p
Z
N
0
PoeðuÞdu
Moreover, it is possible to translate the pointing indexes defined in time
domain also in frequency domain by expressing them as PSD weighting
function Fmetric. Simplified rational approximations eFmetric, used for control
synthesis and analysis, such that FmetricðuÞy
eFmetricðsÞ


2
, where s ¼ ju,
were proposed by Ref. [18] and recalled in Ref. [17]. Table 10.4 resumes
the set of rational approximation of pointing weighting functions.
Another performance related to pointing error is the tranquillization time.
The tranquillization time is generally related to the time duration needed
before achieving a specified level of pointing performance or angular rate.
An example is provided by the oscillation of a large flexible structure, like
a telecommunication antenna, induced by a slew maneuver or a reaction
wheel offloading. The attitude control system in this case is forced to reduce
this oscillation to an admitted value within the imposed tranquillization
time.
Pointing performance is not the unique criterium to take into account
for a spacecraft control design. Another important parameter limiting the
achievable ideal performances is the actuation authority, which means the
maximum available command reachable by the set of chosen actuators.
For this reason, when designing an attitude control system, for instance, it
is important to verify that in the predicted worst-case configuration, the
spacecraft will not ask for a control signal bigger than the saturation value
of its actuators. If this is the case, a complementary solution has to be found
by punctually using an alternative set of actuators. Common ways to desa￾turate the reaction wheels is to employ magnetometers on CubeSat plat￾forms or chemical thrusters (mainly dedicated to orbital control) on bigger
satellites.
622 Francesco Cavenago et al.Table 10.4 Rational approximations of pointing weighting functions [17,19].
Error index Metric Rational weighting function
eFmetricðsÞ
APE Absolute
eFAðs;DtÞ ¼ 1
RPE Windowed
variance
eFWVðs;DtÞ ¼ sDtðsDt þ
ffiffiffiffiffi
12
p Þ
ðsDtÞ
2 þ 6ðsDtÞ þ 12
MPE Windowed mean
eFWMðs;DtÞ ¼ 2ðsDt þ 6Þ
ðsDtÞ
2 þ 6ðsDtÞ þ 12
PDE, PRE Windowed mean
stability
eFWMSðs;Dt;DtsÞ ¼
eFWMðs;DtÞ 2s
DtsðsDts þ 6Þ
ðsDtsÞ
2 þ 6ðsDtsÞ þ 12
Control 623Noise coming from sensor measurements or actuator signals should also
be attenuated above the control bandwidth in order to not introduce a high
frequency undamped error.
All these performances are generally concurrent, and a good compromise
among pointing performance, control level, and noise attenuation has to be
found. The optimality point is, of course, driven by sensors and actuators
quality that bound the achievable ideal performance.
The last point to be checked in a control design is the stability and per￾formance robustness when parametric or dynamical uncertainties affect the
system. Parametric uncertainties are generally related to mechanical proper￾ties of the plant like a misknowledge on the value of the mass and inertia due
to unavoidable mismatch between preliminary and final spacecraft design.
Another example is the error made in the computation of the frequencies
and damping of the natural modes of the structure based on finite element
theory and used for control synthesis. On the other hand, dynamical uncer￾tainties are related to unmodeled dynamics like neglected high frequency
dynamics in actuator models.
If the state-space matrices of an LTI can be written as polynomial or
rational functions of the uncertainties, an equivalent LFT of the system
can be easily derived. Let consider the following partition of the nominal
LTI plant PðsÞ:
PðsÞ ¼
"
P11 P12
P21 P22 #
and D being the block of uncertainties. The lower F lðPðsÞ;DÞ and up￾per LFT F uðPðsÞ;DÞ are defined as:
F lðPðsÞ;DÞ ¼ P11 þ P12DðI  P22DÞ
1
P21
F uðPðsÞ;DÞ ¼ P22 þ P21DðI  P11DÞ
1
P12
and shown in Fig. 10.20, where u and y are the classical system inputs
and outputs, while w and z are the inputs and outputs to the modeled un￾certainties in the D block.
The size of the smallest perturbation D˛D which brings a pole of the
interconnection on the imaginary axis at frequency u is:
kðuÞ ¼ min
D˛D
fsðDÞ: detðI  PðjuÞDÞ ¼ 0g
624 Francesco Cavenago et al.with sðDÞ maximum singular value of the D block.
The structured singular value mDðPðjuÞÞ is defined as:
mDðPðjuÞÞ ¼ 1
kðuÞ
The robustness margin is finally defined as the size of the smallest pertur￾bation D˛D which brings a pole of the LFT interconnection on the imag￾inary axis:
Mr ¼ min
u kðuÞ ¼ min
u
1
mDðPðjuÞÞ ¼ 1
max
u mDðPðjuÞÞ
The definition of the structured singular value helps in the evaluation of
the robustness of both stability and performance of the system by considering
in the analysis the right input/output channels of the LFT interconnection.
The biggest advantage of using mu-analysis for performance robustness is
to fast detect worst-case scenarios by avoiding time expensive Monte Carlo’s
simulations that can miss very rare critical configurations.
For an extensive understanding of m theory, the reader is invited to refer
to Ref. [20]. Recent developments of m theory have enhanced the way of
evaluating the stability and system performance of MIMO system with a
complex set of parametric and dynamical uncertainties [21].
The final step to evaluate a control budget is to validate the system on a
high-fidelity simulator which takes into account all possible nonlinearities
not considered in the control synthesis. In this case, Monte Carlo’s simula￾tion campaigns are generally the most widespread validation and verification
practice across the industry (see Chapter 12 eGNC verification and
validation).
Figure 10.20 Lower (a) and upper (b) LFT standard forms.
Control 625Control implementation best practices
The steps to go from algorithms theory to actual software implemen￾tation are nontrivial and deserve a special mention. The software implemen￾tation is a necessary step for a complete Attitude and Orbit Control System
(AOCS) and is meant to connect algorithms to hardware. As we are talking
about software, one should always have in mind that there are several stan￾dards based on the language the code is written and can be helpful in
designing any part of an AOCS software. Here, we will focus on general
concepts, while recommendations as language specificity (e.g., C code,
ADA code, etc.) or certifications might be taken from general available
resources.
First, start from the control functional architecture definition, collecting
inputs from requirements and other considerations made at system level.
Then, draft the code components and start defining the interfaces with
the rest of the AOCS code, as data transfer and availability are paramount.
Always have a full AOCS suite simulation available to test the control
scheme with the rest of the system and with the dynamical representation
of actuators, sensors, and the satellite as a whole, depending on the accuracy
level available at the time of development.
In the development process, add and test all functionalities and build
regression tests to be sure that an update is not jeopardizing previously estab￾lished features.
Especially in the control area, weights management is paramount. Con￾trollers’ weights are deeply dependent on the system they are supposed to
control; hence, a change in inertia, pointing request, or actuators behavior
would likely trigger a reweighting, especially during fast-paced projects.
Hence, it is always a good idea to have reduced order models to test the con￾trollers in a fast way before updating weights with a more robust procedure.
Another issue that can trigger a reweight is a change in navigation or guid￾ance as this can change the system response in frequency, that is why it is
always good to make periodic testing of the whole AOCS suite.
The rule number one for the implementation of an effective control is to
reason always in discrete form. There is almost no space application that can
run so fast to make the continuous theory work efficiently: always code and
reason in discrete form.
Finally, some general remarks to take for code implementation. A useful
code is functional, readable, and maintainable, a good code is also optimized,
reusable, and configurable/flexible.
626 Francesco Cavenago et al.The code shall be well documented (comments and algorithm docu￾mentation) and organized in a clear way so that more people can contribute
to it. Break the code in functional blocks and in smaller functions especially
if it is possible to reuse them as in a library of functions. Do not exaggerate in
nesting functions, too many levels would make the code unreadable and
thus not maintainable.
In this paragraph, some recommendations for the design of a control sys￾tem are summarized. They have been already introduced along the chapter,
but they are schematically reported here to the benefit of the reader.
The very initial step for the control design is the study of the system to be
controlled and the analysis of the performance required by the specific appli￾cation. The dynamic model can provide a first guide for the selection of the
control technique and can reveal possible limitations. Indeed, bear in mind
that a control system is not only the control law. Computational resources,
available electronics, and selection of sensors and actuators affect significantly
the final performance. It has been shown that delays, sampling frequency,
which can be seen as a sort of delay, presence of R.H.P. zeros, which is
related to the position of sensors and actuators, and noise impose a limitation
on the choice of the gains, and thus on the bandwidth. Moreover, the over￾all accuracy and repeatability is clearly affected by accuracy and repeatability
of each element. Sometimes it is possible to select these components and try
to optimize the design to achieve the specified performance. Other times,
they are imposed by other constraints on the system or project. A model
should be developed to describe the dynamics and include these effects.
For the synthesis and update of the control, a control-oriented model could
be more useful than an extremely detailed one (which should be used
instead for validation) since it enables faster analyses and evaluations. In
this model, only some features of the dynamics, which mostly affect the con￾trol performance, are modeled, and this selection must be done carefully. To
understand better this point, an example is given. Consider the flexibility of
a system, e.g., appendages or solar panels in a satellite. The designer could
decide to neglect it in the model and synthetize a controller with a certain
large bandwidth guaranteeing very good performance. When tested on a
more realistic simulation environment, it could turn out that the closed￾loop behavior is actually unstable. This is because flexibility imposes a lim￾itation on the achievable control bandwidth. Should therefore the designer
model as many flexible modes as possible? Not necessary, probably the main
limitation is due to the first resonant frequency and modeling it would pro￾vide sufficient information to improve the control design. Control-oriented
Control 627model should capture all the essential dynamic features which impose some
fundamental constraints to the control.
As mentioned previously in the chapter, stability of the closed-loop sys￾tem is the first objective of the controller. To this aim, different methods
have been reviewed, such as Nyquist criterion or the analysis of the
poles/eigenvalues for linear system and Lyapunov and LaSalle theorems
for nonlinear ones. When checking the stability, keep in mind that the
response of the system to each input shall be verified, and not only to the
setpoint. Indeed, in section Chapter 10 e Control e Control design e
Control design in frequency domain, it has been shown that even if the
transfer function between the setpoint and the controlled variable could
be stable, the other functions among the Gang of four may be not. For
example, this could happen if an unstable pole is canceled by the controller.
The complementary sensitivity function might be stable, but the unstable
pole would remain in one of the other functions. From this observation,
the following recommendation is recalled: cancellation of unstable poles
should be avoided, and stability of all the transfer functions should be
checked (internal stability), or, in general, the response to each identified
input of the system.
Realistic simulation environment is often used to validate the controller
before implementing it on the hardware. However, even if a very realistic
simulator is available, uncertainties and unmodeled dynamics are always pre￾sent in the real system. Therefore, the design of the controller should be
developed in such a way to guarantee a certain robustness. Some stability
margins have been introduced for this purpose (see Chapter 10 e Control
e Control design e Control design in frequency domain e Stability and sta￾bility margins), and reasonable values for them are recalled hereafter:
• Phase margin: fm  30.
• Gain margin: gm  2 (in decibel,  6 dB).
• Modulus margin: sm  0:5 (in decibel,  6 dB, or, equivalently, peak
of the sensitivity function MS  6 dB).
When designing the control in the frequency domain, especially using
loop-shaping technique or PI/PD/PID, the zeros of the controller are usu￾ally placed half a decade or a decade before the selected gain crossover fre￾quency. Indeed, L.H.P. zeros provide an increase of the phase which can be
beneficial to improve the gain margin.
Along with stability and robustness, some applications may require very
challenging steady-state accuracy. Adding an integrator in the control law
628 Francesco Cavenago et al.can help meet this requirement. Indeed, integral term provides good steady￾state tracking performance and rejection of constant disturbance. Clearly,
the introduction of this action must be handled properly. Stability could
be negatively affected, and antiwindup techniques shall be implemented
to avoid the build-up of the error due to actuators’ saturation.
Once designed the feedback control, it may happen that the perfor￾mance of closed-loop system is still not satisfactory, especially in terms of
tracking. To improve the system response, the designer could try to add a
feedforward action, on the setpoint or/and on the disturbance, if measur￾able. It is recalled that this solution relies on the knowledge of the model,
and thus a good identification of the parameters is recommended to increase
its effectiveness.
As last remarks, it is important to always remember the trade-off nature
of the control design. Indeed, designing a control system is basically seeking
for a good balance between conflicting goals, taking into consideration the
intrinsic limitations/constraints of the system.
References
[1] K.J. Åström, R.M. Murray, Feedback Systems: An Introduction for Scientists and En￾gineers, second ed., Princeton University Press, 2021.
[2] S. Skogestad, I. Postlethwaite, Multivariable Feedback Control: Analysis and Design,
Wiley, New York, 2007.
[3] ECSS-E-ST-60-10C, “Space Engineering e Control Performance”, Noordwijk,
2008.
[4] ECSS-E-HB-60-10A, “Space Engineering e Control Performance Guidelines”,
Noordwijk, 2010.
[5] W.J. Rugh, Linear System Theory, Prentice Hall, 1996.
[6] T. Kailath, Linear Systems, vol 156, Prentice Hall, Englewood Cliffs, NJ, 1980.
[7] K.J. Åström, Limitations on control system performance, European Journal of Control
6 (1) (2000) 2e20.
[8] H.K. Khalil, Nonlinear Systems, third ed., Patience Hall, 2002.
[9] J.-J.E. Slotine, W. Li, Applied Nonlinear Control, vol 199, Prentice Hall, Englewood
Cliffs, NJ, 1991. No. 1.
[10] W.J. Rugh, J.S. Shamma, Research on gain scheduling, Automatica 36 (10) (2000)
1401e1425.
[11] M.J. Sidi, Spacecraft Dynamics and Control: A Practical Engineering Approach, vol 7,
Cambridge University Press, 1997.
[12] O.-E. Fjellstad, T.I. Fossen, Quaternion Feedback Regulation of Underwater
Vehicles, 3rd IEEE Conference on Control Application, 1994.
[13] J.G. Ziegler, N.B. Nichols, et al., Optimum settings for automatic controllers, Trans￾actions of the American Society of Mechanical Engineers 64 (11) (1942) 759e768.
[14] S. Silvestrini, J. Prinetto, G. Zanotti, M. Lavagna, Design of robust passively safe rela￾tive trajectories for uncooperative debris imaging in preparation to removal, AAS/
AIAAAstrodynamics Specialist Conference (2020) 1e18.
[15] A. Bemporad, M. Morari, Robust model predictive control: a survey, in: A. Garulli,
A. Tesi (Eds.), Robustness in Identification and Control. Lecture Notes in Control
Control 629and Information Sciences, vol 245, Springer, London, 1999, https://doi.org/10.1007/
BFb0109870.
[16] European Space Agency, “ECSS-E-HB-60-10A e control performance guidelines”,
Technical Report, 2010.
[17] European Space Agency, “ESA pointing error engineering handbook, Handbook
ESSB-HB-E-003”, Technical Report, 2011.
[18] M.E. Pittelkau, Pointing error definitions, metrics, and algorithms, Advances in the
Astronautical Sciences 116 (2003) 901e920.
[19] T. Ott, W. Fichter, S. Bennani, S. Winkler, Precision pointing HN control design for
absolute, window-, and stability-time errors, CEAS Space Journal 4 (2013) 13e30,
https://doi.org/10.1007/s12567-012-0028-z.
[20] K. Zhou, J. Doyle, K. Glover, Robust and Optimal Control, Prentice Hall, Upper
Saddle River, NJ, 1996.
[21] C. Roos, Systems Modeling, Analysis and Control (SMAC) toolbox: an insight into
the robustness analysis library, in: Proceedings of the IEEE Multiconference on Sys￾tems and Control, Hyderabad, India, August 2013, pp. 176e181.
630 Francesco Cavenago et al.CHAPTER ELEVEN
FDIR development approaches in
space systems
Massimo Tipaldi1
, Stefano Silvestrini2
, Vincenzo Pesce3
,
Andrea Colagrossi2
1
University of Sannio, Benevento, Italy
2
Politecnico di Milano, Milan, Italy
3
Airbus D&S Advanced Studies, Toulouse, France
This chapter presents technical solutions and industrial processes used by the
Space Industry to design, develop, test, and operate health (or failure) manage￾ment systems, which are needed to devise and implement space missions with
the required levels of dependability and safety (the former concerned with
the ability of the spacecraft to deliver the intended service, while the latter
more focused on functions that, if lost or degraded, can result into space
mission loss) [1,2].
As shown later in this chapter, the design of health management systems
needs the identification of potential risks that can threaten the main mission
objectives, the assessment of their impacts on the spacecraft functions and
services (both qualitative as well as quantitative), and the definition of miti￾gation means to prevent these risks from occurring. Space missions usually
have to perform their tasks remotely under extreme environmental condi￾tions and deliver high-quality services, sometimes for decades without inter￾ruption. On-board units and equipment operate in such extreme conditions
with cutting-edge technologies. It is intuitively clear that dependability and
safety are important design drivers for most types of space missions, as degra￾dation in the quality of services is typically regarded as unacceptable.
Health management systems act as supervisory entities and ensure that
the mission objectives and constraints are met, and that the spacecraft is pro￾tected from failures leading to a service deterioration or even worst to the
spacecraft loss. The survival of the spacecraft has generally priority over its
service availability. Health management systems monitor and process streams
of observations in order to detect, isolate, and, if necessary, react to events
and anomalies occurring inside the spacecraft.
In the Space Industry, health (or failure) management is commonly
referred to as Failure (or Fault) Detection, Isolation and Recovery (FDIR, note
Modern Spacecraft Guidance, Navigation, and Control
ISBN: 978-0-323-90916-7
https://doi.org/10.1016/B978-0-323-90916-7.00011-1
© 2023 Elsevier Inc.
All rights reserved. 631 jthat “F” can stand for fault (state) or failure (event) indistinctively), and it is
regarded as a complex system engineering discipline [1e3]. FDIR system
development is addressed since the very beginning of any space mission
design [4] and plays a relevant role in the definition of their reliability,
availability, and safety objectives. If not correctly managed, the develop￾ment and testing of FDIR capabilities can cause project schedule delays
and cost overruns [5].
Space is actually a harsh and challenging environment, where it is abso￾lutely necessary to provide spacecraft with adequate hardening. First, very
stringent quality requirements for the design and testing processes of the
spacecraft have to be met [6]. But this is not sufficient to address depend￾ability and safety requirements. Thus, FDIR systems have to be engineered
and developed in order to provide specific functionality, able to handle sit￾uations when the abovementioned risks can become reality.
In this chapter, both technical and programmatic FDIR strategies are
presented along with their strong connection with the wider concept of
on-board autonomy, which is becoming the key point in the design of
new-generation spacecrafts. Today’s rapid progress in on-board computa￾tional power supports the transfer of FDIR functions from the ground to
the flight segment and the enhancement of the spacecraft on-board auton￾omy [3,7]. FDIR system capabilities are usually interwoven with all other
features of the system, and this is one of the main causes of FDIR system
design complexity [1,2]. The European Space Agency (ESA) has recognized
the system-level role of the FDIR. In this regard, in 2016, the SAVOIR￾FDIR working group was established with the aim of harmonizing the vo￾cabulary, the practices, and the expectations related to the design of the
FDIR components within a system perspective, see Ref. [8].
The overall chapter is inspired by FDIR systems designed for ESA mis￾sions; however, the presentation is maintained at a proper level of detail so
that its contents are in line with the FDIR practices adopted by other space
agencies. FDIR is mentioned in several European Cooperation for Space
Standardization (ECSS) documents. However, such ECSS standards do
not provide guidelines on how to design, implement, and test FDIR systems
and do not describe the interfaces with the other engineering disciplines
(e.g., Reliability, Availability, Maintainability, and Safety, software [SW],
and operations). Such information is spread in different ECSS documents,
and it is difficult to have a comprehensive overview of FDIR system devel￾opment processes. This chapter tries to solve such issue; for more details,
readers are encouraged to refer to the SAVOIR FDIR Handbook [8].
632 Massimo Tipaldi et al.The content of this chapter is structured as follows:
• FDIR in space missions, terms, and definitions. This section provides an
overview on FDIR systems and the related terminology. It also includes
an introduction to FDIR specifically targeted to space missions.
• Current FDIR system development process and industrial practices. In this sec￾tion, the most relevant current industrial approaches and technical solu￾tions used to design, develop, test, and operate FDIR systems are
outlined.
• FDIR system hierarchical architecture and operational concepts. This section
briefly explains FDIR system hierarchical architecture.
• FDIR system implementation in European space missions. The most relevant
FDIR system implementations according to European standards are
introduced in this section.
• FDIR system verification and validation approach. This section summarizes
and highlights the most relevant FDIR system verification and validation
approaches.
• FDIR concept and functional architecture in GNC applications: a short overview.
In this section, the concept and functional architecture of FDIR tech￾niques for spacecraft guidance, navigation, and control (GNC) applica￾tions are detailed.
FDIR in space missions, terms, and definitions
In current and upcoming space missions, the need of designing space￾craft with a high level of on-board autonomy is emerging [3,9]. This trend is
particularly evident for spacecraft operating in challenging contexts, which
feature deep-space exploration systems or critical operational phases, such
as automated maneuvers for space rendezvous. From an operational point
of view, on-board autonomy can be regarded as migration of functionality
from the ground segment to the flight segment [10]. The implementation of
on-board autonomy depends on the specific mission requirements and con￾straints and can therefore vary between a very low level of autonomy (which
implies a relevant involvement of the ground segment in space mission op￾erations) to a high level of autonomy (whereby, most of the functions are
performed on-board [7]). As shown in Refs. [3,10] and in line with
Ref. [7], on-board autonomy can be associated to the following application
fields:
• Intelligent sensing. The ability to infer system state from the environmental
sensor data.
FDIR development approaches 633• Mission planning and execution. The process of planning and executing
both nominal and contingency mission operations satisfying temporal
and resource constraints.
• On-board FDIR. The ability of on-board detecting, isolating, and
recovering from failure situations.
• Distributed decision-making. Effective cooperation among independent
autonomous spacecraft in order to achieve common goals.
Drivers for increased on-board autonomy are the improvement of space￾craft dependability [1,4,5], the need to overcome long communication de￾lays and outages [11], and the reduction of costs in ground segment
operations [12]. This way, important requirements can be fulfilled, such as
continuous mission product generation on board, real-time spacecraft con￾trol outside ground contact, maximization of mission objectives in relation
to the available on-board resources, and robust operations in the presence of
on-board failures and context uncertainty.
The need of designing more and more autonomous and dependable mis￾sions is the main factor leading toward the enhancement of spacecraft FDIR
systems and their related architecture. FDIR systems act as supervisory con￾trollers, preventing the spacecraft behavior from the undesired scenarios.
FDIR systems are basically featured by the following capabilities [1,2]:
• Detection. The determination of the presence of faults in a system and
their times of occurrence.
• Isolation. The determination of their location, type, and severity.
• Recovery. The process of choosing the best action to recover from the
anomaly condition (for instance, by selecting the most adequate space￾craft reconfiguration, which is determined by the remaining healthy
components).
FDIR requirements have to be scaled and deployed between the flight
and the ground segments according to some factors, such as mission type
and objectives, spacecraft orbit and ground visibility profile, operations con￾cepts, communication bandwidth, and latency [1e3]. Moreover, important
constraints (e.g., robustness, reactive detection, quick isolation/identifica￾tion, and limited on-board resources - central processing unit (CPU) and
memory) on FDIR solutions have to be taken into account.
FDIR system conception and implementation in a space system can be a
rather complex field, since the analysis of spacecraft failures can extend to
very sophisticated considerations. The cause of malfunctions could be one
or more failed components, incorrect control actions, or external distur￾bances, which impact system operations. In complex, heterogeneous systems
634 Massimo Tipaldi et al.with large numbers of interacting physical components, the effects of faults
can propagate through the boundaries of many subsystems and can result in
diverse fault symptoms. FDIR information processing and physical compo￾nents are tightly integrated and intertwined; therefore, the structure and
properties of physical spacecraft components determine the functions to
be implemented by the FDIR systems.
To give further insights into the FDIR complexity, the FDIR system
design strongly depends on the chosen spacecraft operational concept
[1,8]. In this regard, FDIR systems can be shaped between two extremes,
i.e., having a straightforward on-board FDIR implementation (where
only vital elements are checked on board, the related recovery is completely
performed by the ground) or making use of a more sophisticated on-board
FDIR design (where failures are identified at the lowest level possible and
solved autonomously by the spacecraft and the ground intervention is
reduced to the minimum). In making this choice, it is necessary to make
a trade-off analysis by taking into account different criteria, such as, mission
outage risks, on-board software (OBSW) development costs, hardware
(HW) redundancy costs.
Indeed, FDIR systems have to be carefully designed in order to exploit
recurrent and reusable approaches throughout the different missions. It is
also necessary to assess how to implement their failure management and re￾covery capabilities, e.g., via HW or via the OBSW, the latter being the
application SW running on the main spacecraft on-board computer
(OBC). As better clarified later in this chapter, the OBSW plays a relevant
role in the implementation of FDIR system capabilities. The decision as
to whether FDIR functions are to be implemented, i.e., via HW or
OBSW functions, is of prime importance: the advantage of the OBSW
lies in the fact that OBSW offers in-flight modification capability [13].
Current FDIR systems perform system monitoring through the available
on-board observations, diagnose off-nominal conditions, and initiate the re￾covery procedures, for which the purpose is to restore the spacecraft oper￾ation to nominal conditions (if feasible), to a degraded operation (if possible),
or, as a last resort, to simply put the spacecraft into a known safe configura￾tion [14,15] (where further investigations are carried out by the ground sta￾tion). Possible recoveries are the retry operation, the unit reboot, and the
switch to either a redundant unit or to a completely redundant string (in
case of no failure identification). To avoid the loss of platform functions
mandatory for the mission, the redundancy concept has to be such that
the functionality for which the failure can lead to mission loss is to be
FDIR development approaches 635protected by independent redundant alternatives [1e3]. Hot redundancy
can be adopted for such vital spacecraft functions.
Another interesting aspect in the development of FDIR systems is to un￾derstand which spacecraft subsystems and units are more likely to be affected
by failures and the corresponding impact on the overall mission. This analysis
is fundamental for the FDIR system functionality definition and can support
project programmatic/system-level decisions, e.g., where to allocate the
budget foreseen for the FDIR system development. In this regard, we can
mention the study by Tafazoli [16], where on-orbit spacecraft failures
from 1980 to 2005 were reviewed. As reported in Ref. [16], most of the fail￾ures affected the Altitude and Orbit Control (AOCS) and the Power subsys￾tem, in particular: AOCS (32%), Power (27%), Command and Data
Handling (15%), Telemetry (TM), Tracking and Command (12%), and
other subsystems (14%).
Terms and definitions
Finally, a few relevant terms used in the FDIR realm are hereafter explained
(an exhaustive list can be found in Ref. [8]):
• Anomaly. Any deviation from the expected situation.
• Criticality. Combined measure of the severity of a failure mode and its
probability of occurrence.
• Dependability. The extent to which the fulfillment of a required function
can be justifiably trusted.
• Failure. The event resulting in an item being no longer able to perform its
required function.
• Failure cause. The presumed cause associated to a given failure mode.
• Failure effect. Consequence of an assumed item failure mode on the oper￾ation, function, or status of the item.
• Failure isolation. Functionality to isolate the failed unit or subsystem, to
avoid failure propagation and deterioration of the impacted equipment.
• Failure mode. Mechanism through which a failure occurs.
• Failure mode, effects, and criticality analysis (FMECA). Analysis by which
each potential failure mode in a product (or function or process) is
analyzed to determine its effects, and then classified according to its
criticality.
• Fault. State of an item characterized by inability to perform as required.
• Functional chain. Set of HW and/or SW units operating together to
achieve a given subset of closely related functions of a system.
636 Massimo Tipaldi et al.• On-board autonomy. Capability of the space segment to manage nominal
or contingency operations without ground segment intervention for a
given period of time.
• Redundancy. Existence of more than one means for performing a given
function with the intention of increasing dependability.
• Safe mode. Spacecraft operating mode guaranteeing the spacecraft safety
that can be autonomously sustained for an indefinite period of time
(or at least for a period of time significantly longer that the ground reac￾tion time) and in which basic spacecraft functions, including permanent
communications with ground, are available to the operators to perform
the recovery procedures.
• Safety. State where an acceptable level of risk is not exceeded (risks
related to, e.g., fatality, damage to the main functions of a flight system
itself, damage to launcher HW or launch site facilities).
• Service. Functional element of the space system that provides a number of
closely related functions that can be remotely operated.
Most of the definitions are taken from the ECSS standards, for instance,
see Refs. [7,17,18] and Ref. [19].
Current FDIR system development process and
industrial practices
This paragraph outlines the current industrial approaches and practices
used to conceive, design, implement, test, and operate FDIR systems.
Fig. 11.1 shows the different phases featuring the FDIR system development
and their relationship with the spacecraft project phases. The following ma￾jor steps are identified [20]:
• Study phase. It includes the identification of autonomy needs, system￾level requirements, and ground segment constraints. This steps also in￾cludes the definition of the preliminary FDIR concept on a mission level.
• Definition phase and the early development phase. It includes the definition of
the FDIR system for the required mission (e.g., identification of failures
on system/subsystem/unit levels), the definition of the overall FDIR sys￾tem architecture (FDIR hierarchy and dependencies), the definition of
the FDIR functions, and their mapping versus HW or/and SW
elements.
• Implementation and testing phase. It includes the FDIR system detailed
design, implementation, and testing.
• In-orbit phase. It includes the FDIR system maintenance and operations.
FDIR development approaches 637It is evident that FDIR system discipline has to be regarded as a broad
system-level activity and requires in-depth knowledge of space system engi￾neering. The study and the definition phases are fundamental for the devel￾opment of FDIR systems from both a technical and programmatic
standpoint. As shown in Fig. 11.1, FDIR system requirements and functions
stem from the mission/high-level system needs and constraints and the
outcome of the Fault Tree Analysis (FTA) and FMECA. FTA and FMECA
results are often combined for the FDIR system functionality definition.
FTA is a deductive analysis where top-level failures (e.g., loss of power or
loss of fuel) are addressed and all the basic faults that can lead to such states
are identified. This process results in a tree-shaped diagram. The identified
failure scenarios need to be managed by the FDIR system. FMECA is an
inductive analysis, and it computes the casual effects on the system of a given
Figure 11.1 FDIR system development versus spacecraft project phases.
638 Massimo Tipaldi et al.fault combination. Examples of fault-tree diagrams can be found in Ref. [6].
For any identified relevant failure modes in the FMECA, which are not
already covered by the FDIR functions derived from the FTA, additional
FDIR functions are defined (bottom-up approach). After specifying all
the FDIR functions, the implementation into the OBSW and/or HW units
is performed, followed by a testing of all the implemented FDIR require￾ments. During the operational phase, the FDIR system capabilities can be
tuned and even enhanced, thanks to the lessons learnt from the spacecraft
operations in its final environment and the availability of flight data [21,22].
FDIR system hierarchical architecture and operational
concepts
Current European space missions usually implement the FDIR sys￾tems via a hierarchical architecture [8,20,23]. A typical example of such
layered architecture is shown in Fig. 11.2 and consists of the following layers:
• Level 0. Unit failure autonomously detected and recovered within the
unit itself and reported to the supervision level (which is usually the
OBSW). Examples of level 0 failures are short currents, overvoltage,
and data bus failures.
Figure 11.2 FDIR system hierarchical structure.
FDIR development approaches 639• Level 1. Unit failure detected and recovered by the supervising OBSW,
which can command, e.g., the unit reset. They can be recovered by
resorting to the redundant path. As for the fault detection, the OBSW
has to monitor unit data, e.g., against specific thresholds.
• Level 2. Functional chain (i.e., subsystem/system) level failure detected
via anomalous performance parameters by the OBSW. The recovery ac￾tion is also performed by the OBSW. Level 2 failures are usually caused
by the propagation of undetected/unsolved unit failures. Subsystem/
system-level data checks and functional monitoring characterize this
level. Examples of Level 2 failures are the spacecraft orientation outside
the operational range and its anomalous angular rate.
• Level 3. Major failure in the OBC Processor Module, detected either by
the OBSW or by a supervising equipment (e.g., the Reconfiguration
Module [13,15]). Examples of Level 3 failures are: processor undervolt￾age, starvation/crash of the OBSW detected by missed refresh of the
watchdog, invalid instruction, or memory access.
• Level 4. Major spacecraft failure detected at HW level by the Reconfigura￾tion Module. Examples are: major battery discharge, sun intrusion through
the optical payload field of view, and excessively long thruster firing.
The abovementioned FDIR system design consists in allocating FDIR
functionality into the levels of the FDIR hierarchical architecture. As a mat￾ter of fact, failures are usually deployed along five hierarchical levels and are
characterized by a specific severity, the function(s) involved in their detec￾tion, and the recovery sequence. The highest FDIR level is usually in charge
of the correct execution of vital functions of the spacecraft, whereas lower￾level hierarchies operate at unit level. A higher level is triggered by the adja￾cent lower level, only when the latter is not able to solve/isolate a fault. In
such a case, FDIR functions allocated into the higher level can perform the
related recovery action by exploiting functions implemented by the next
lower level.
Most of the FDIR functions are implemented by the OBSW [1e3]. The
operational concept of a typical spacecraft includes one or more safe mode
configurations. They can represent the ultimate reaction to spacecraft severe
anomalies. Indeed, safe modes can be entered when the on-board FDIR sys￾tem is not able to solve critical on-board failure conditions (such as a severe
spacecraft attitude excursion outside the operational range) or by means of
specific telecommands (TCs) sent from the ground segment. The spacecraft
can remain in this mode without ground segment intervention for a speci￾fied period of time. During the safe mode, the communication link to the
640 Massimo Tipaldi et al.ground segment, a specific power supply profile, and thermal survival func￾tions for relevant equipment are maintained, whereas all nonessential on￾board functions are powered off or disabled. The recovery of the spacecraft
from safe mode to nominal mode needs to be commanded by ground.
FDIR Level 3 anomalies are usually related to the spacecraft OBC, which
executes the central OBSW. At this level, failure management consists in
executing an OBC reset, specific reconfiguration procedures, and a transi￾tion into safe mode as appropriate.
FDIR system implementation in European Space
missions
FDIR functions deployed into Level 1 and Level 2 are completely
handled by the OBSW. As highlighted in Refs. [1,2,8], FDIR systems in
European Space projects are usually implemented via the Packet Utilization
Standard (PUS) services (ECSS-E-ST-70-41CdTM and TC packet utiliza￾tion [19]). Such standard addresses the role of both the flight and ground seg￾ments in implementing FDIR systems.
Generally speaking, the PUS defines the operational model of a space￾craft, which consists of a set of extensible services that can be invoked
through a service request (TC source packet), with such an invocation
resulting in the generation of zero or more service reports (TM source
packets). Among the other things, the PUS addresses the FDIR operational
concepts and provides a set of services that allows the standardization of the
failure management between ESA missions. In particular, the following ser￾vices concern the FDIR functionality: the On-board Monitoring PUS Ser￾vice 12, the On-board Event Reporting PUS Service 5, and the On-board
EventeAction PUS Service 19. The latter triggers some on-board actions
that can be a single TC, the execution of a command sequence (PUS Service
21), or the execution of an On-Board Command Procedure (OBCP, PUS
Service 18 [24]). Avoidance of multiple recovery execution for simultaneous
occurrence of multiple related failures is achieved by the combination of
PUS service 12 parameter monitoring items into a single “functional moni￾toring” which issues a dedicated event report triggering the single recovery.
PUS-based FDIR systems are industrially mastered and established
within the current industrial spacecraft development processes [2,19]. More￾over, being based on configuration tables (and thus, modifiable at run-time
via TC source packets without the need of patching the whole OBSW), the
PUS services can offer some flexibility to the overall FDIR system during
FDIR development approaches 641both the ground testing and the spacecraft operational life. For instance, the
monitored item thresholds and the list of on-board actions to be triggered (in
case of threshold violations) are implemented via configuration tables and
can easily be updated during the space mission operational phase.
The PUS standard can be also tailored in order to accommodate mission￾specific requirements [3,19]. However, the overall FDIR concept is based
on a threshold monitoring mechanism, and this can imply some limitations
in the diagnostics capabilities of the resulting FDIR system. Indeed,
threshold-based diagnostic routines process symptoms in isolation, which
may result in incorrect diagnoses or contradictory deductions. Limitations
of current FDIR solutions adopted in Space Industry are addressed in
Ref. [25], where model-based FDIR solutions are explored.
FDIR system verification and validation approach
Before being operated, FDIR systems need to be verified and validated
on-ground by using simulators and different spacecraft engineering models
[1,2,8,26]. Traditional system-level testing basically aims at confirming that
each command works as expected, each functional and performance require￾ment has been met, and that all sequences of commands that will probably be
used during the mission work. Each requirement must have a corresponding
verification requirement, which dictates the test, analysis, review of design, or
inspection procedure that will be used to verify the corresponding require￾ment. Such approaches have also been proved to be quite effective for the
FDIR systems so far [27]. Most of the FDIR systems functions are imple￾mented by the OBSW; therefore, FDIR system verification and validation ac￾tivities are intertwined with the ones concerning the OBSW.
OBSW requirements derived from FDIR requirements and corre￾sponding SW artifacts normally undergo a well-defined OBSW verifica￾tion and validation process, see Ref. [28]. Once all the HW and SW items
concurring at the implementation of system-level FDIR requirements
have been verified and integrated, FDIR requirements are globally veri￾fied at system level [8,26,28].
FDIR concept and functional architecture in GNC
applications: a short overview
A large body of literature and industrial applications of fault-tolerant
GNC solutions is available. Such solutions have been applied to different
642 Massimo Tipaldi et al.contests, such as precise formation flying [29,30], small body descent and
landing missions [31], deep space missions [32], and reentry modules [33].
Depending on mission and system-level requirements, different FDIR ap￾proaches have been conceived, designed, and implemented. Generally
speaking, the main objectives of a fault-tolerant GNC are [34]:
• Early detection and diagnosis of anomalies, i.e., detection delay should be
minimized.
• Good ability to discriminate between different failures (isolation).
• Good robustness to various noise and uncertainties sources, and their
propagation through the system.
• High sensitivity and performance, i.e., high detection rate and low false
alarm rate.
In most GNC systems endowed with FDIR capabilities, failures and re￾coveries are allocated into the levels of the FDIR hierarchical architecture as
shown in Fig. 11.2 [30,32,35]. Moreover, specific FDIR modes are designed
and incorporated in the GNC system to handle critical failure conditions. An
interesting case is the PROBA 3 mission [30], which is devoted to the
demonstration of precise formation flying technology: the safe mode is asso￾ciated to safe trajectories (where no formation orbit control for long periods
of time is required), while the collision avoidance mode corresponds to drift￾ing orbits (designed with the objective of avoiding threatening collisions).
More precisely, the safe mode is close to the classical safe mode of a single
satellite and is designed to ensure no collision with the other satellites of
the formation, whereas CAM is a fail-operational mode, wherein the space￾craft attempts to recover autonomously its operational conditions [35].
In fault-tolerant GNC systems, autonomous failure management capa￾bilities are intertwined with on-board mission planning and execution
[3,33,36]. From an architectural standpoint, this means that fault-tolerant
GNC systems include three main functional modules [33,36,37]: the
Mission and Vehicle (or Spacecraft) Manager (MVM), the GNC Manager,
and the GNC module itself (see Fig. 11.3). In particular:
• The MVM is responsible for the accomplishment of the mission goals by
programming the vehicle activity plans and monitoring their executions.
It defines the sequences of phases, modes, and maneuvers along with the
scheduling of equipment for such modes. It also implements the TC/TM
interface with the ground segment.
• The GNC Manager receives the commands from the MVM, manages
the execution of the corresponding GNC functions/modes, and reports
their execution to the MVM. Such module also includes the event￾FDIR development approaches 643triggering function, which is in charge of generating relevant mission￾level events (e.g., parachute deployment).
• The GNC module provides all the GNC algorithms needed in the
different phases. Moreover, it implements the functional interfaces to￾ward the sensors (e.g., camera, GPS receiver, gyroscope) and actuators
(e.g., thruster, reaction wheel, magneto-torquer). Based on the current
mode, the corresponding algorithms, sensors, and actuators are enabled.
The overall system is in charge of the execution of the various GNC
modes, the switching between modes, the assignment of resources to each
mode, the detection of failures and reconfiguration after failures, the
high-level monitoring of GNC functions and of the vehicle state. FDIR ca￾pabilities can be allocated throughout the abovementioned blocks (see
Fig. 11.3, only as an example). Unit-level FDIR capabilities can be allocated
Figure 11.3 Fault-tolerant GNC functional architecture.
644 Massimo Tipaldi et al.into the GNC module itself, while mission-level FDIR can be provided by
the MVM module. In this regard, if needed, mission objectives can change
as a result of a mission-level recovery action, e.g., the reshape of a new
reentry trajectory for a high or medium lift-to-drag ratio vehicle as reported
by Ref. [34].
References
[1] M. Tipaldi, B. Bruenjes, Survey on fault detection, isolation, and recovery strategies in
the space domain, Journal of Aerospace Information Systems 12 (2) (2015) 235e256.
[2] X. Olive, FDI (R) for satellites: how to deal with high availability and robustness in the
space domain? International Journal of Applied Mathematics and Computer Science
22 (2012) 99e107.
[3] M. Tipaldi, L. Glielmo, A survey on model-based mission planning and execution for
autonomous spacecraft, IEEE Systems Journal 12 (4) (2017) 3893e3905.
[4] M. Tipaldi, B. Bruenjes, Spacecraft health monitoring and management systems, in:
IEEE Metrology for Aerospace (MetroAeroSpace), 2014, pp. 68e72, 2014.
[5] L.M. Fesq, Current fault management trends in NASA’s planetary spacecraft, in: IEEE
Aerospace Conference, 2009, pp. 1e9, 2009.
[6] Space mission analysis and design, in: J.R. Wertz, W.J. Larson (Eds.), 3rd Space Tech￾nology Series, third ed., Microcosm Press and Kluwer Academic Publishers (Jointly),
Boston MA, 1999.
[7] ECSS-E-ST-70-11C space engineeringdspace segment operability, European Coop￾eration for Space Standardization Standard, 2008.
[8] SAVOIR-FDIR Handbook, European Space Agency, 2019. https://essr.esa.int.
[9] A. Jonsson, R.A. Morris, L. Pedersen, Autonomy in space: current capabilities and 
future challenge, AI Magazine 28 (4) (2007), 27-27.
[10] T. Grant, A.O. Soler, A. Bos, U. Brauer, M. Neerinex, M. Wolff, Space autonomy as
migration of functionality: the Mars case, in: 2nd IEEE International Conference on
Space Mission Challenges for Information Technology, SMC-IT’06, 2006, pp. 1e7.
[11] R. Sterritt, C.A. Rouff, M.G. Hinchey, J.L. Rash, W. Truszkowski, Next generation
system and software architectures: challenges from future NASA exploration missions,
Science of Computer Programming 61 (1) (2006) 48e57.
[12] J. van der Ha, Trends in cost-effective mission operations, Acta Astronautica 52 (2e6)
(2003) 337e342.
[13] M. Tipaldi, C. Legendre, O. Koopmann, M. Ferraguto, R. Wenker, G. D’Angelo,
Development strategies for the satellite flight software on-board Meteosat Third
Generation, Acta Astronautica 145 (2018) 482e491.
[14] V. Nardone, A. Santone, M. Tipaldi, D. Liuzza, L. Glielmo, Model checking tech￾niques applied to satellite operational mode management, IEEE Systems Journal 13
(1) (2018) 1018e1029.
[15] M. Tipaldi, M. Witzmann, M. Ferraguto, L. Glielmo, An approach for geostationary
satellite mode management, IFAC-PapersOnLine 50 (1) (2017) 7241e7246.
[16] M. Tafazoli, A study of on-orbit spacecraft failures, Acta Astronautica 64 (2e3) (2009)
195e205.
[17] ECSS-S-ST-00-01C e Glossary of Terms, European Cooperation for Space Standard￾ization Standard, 2012.
[18] ECSS-Q-ST-30-02C e Failure Modes, Effects (And Criticality) Analysis (FMEA/
FMECA), European Cooperation for Space Standardization Standard, 2009.
[19] ECSS-E-ST-70-41C e Telemetry and Telecommand Packet Utilization, European
Cooperation for Space Standardization Standard, 2016.
FDIR development approaches 645[20] R. Gessner, B. Kosters, A. Hefler, R. Eilenberger, J. Hartmann, M. Schmidt, Hierar￾chical FDIR concepts in S/C systems, in: Space OPS 2004 Conference, 2004,
pp. 1e11, 2009.
[21] M. Tipaldi, L. Feruglio, P. Denis, G. D’Angelo, On applying AI-driven flight data
analysis for operational spacecraft model-based diagnostics, Annual Reviews in Control
49 (2020) 197e211.
[22] J.A. Martínez-Heras, A. Donati, Enhanced telemetry monitoring with novelty
detection, AI Magazine 35 (4) (2019) 37e46.
[23] A. Wander, R. Förstner, Innovative Fault Detection, Isolation and Recovery Strategies
On-Board Spacecraft: State of the Art and Research Challenges, Deutsche Gesellschaft
fur Luft-und Raumfahrt-Lilienthal-Oberth eV, 2013. €
[24] M. Tipaldi, M. Ferraguto, T. Ogando, G. Camatto, T. Wittrock, B. Bruenjes,
L. Glielmo, Spacecraft autonomy and reliability in MTG satellite via On-board Con￾trol Procedures, in: 2015 IEEE Metrology for Aerospace (MetroAeroSpace), 2015,
pp. 155e159.
[25] J. Marzat, H. Piet-Lahanier, F. Damongeot, E. Walter, Model-based fault diagnosis for
aerospace systems: a survey, Journal of Aerospace Engineering 226 (10) (2012)
1329e1360.
[26] M. Zoppi, M. Tipaldi, A. Di Cerbo, Cross-model verification of the electrical power
subsystem in space projects, Measurement 122 (2018) 473e483.
[27] K. Reinholtz, K. Patel, Testing autonomous systems for deep space exploration, IEEE
Aerospace and Electronic Systems Magazine 23 (9) (2008) 22e27.
[28] ECSS-E-ST-40C e Software, European Cooperation for Space Standardization Stan￾dard, 2009.
[29] G. Di Mauro, M. Lawn, R. Bevilacqua, Survey on guidance navigation and control
requirements for spacecraft formation-flying missions, Journal of Guidance, Control,
and Dynamics 41 (3) (2018) 581e602.
[30] J.S. Llorente, A. Agenjo, C. Carrascosa, C. de Negueruela, A. Mestreau-Garreau,
A. Cropp, A. Santovincenzo, PROBA-3: precise formation flying demonstration
mission, Acta Astronautica 82 (1) (2013) 38e46.
[31] D. Ge, P. Cui, S. Zhu, Recent development of autonomous GNC technologies for
small celestial body descent and landing, Progress in Aerospace Sciences 110 (2019).
[32] A. Zolghadri, D. Henry, J. Cieslak, D. Efimov, P. Goupil, Fault Diagnosis and Fault￾Tolerant Control and Guidance for Aerospace Vehicles, Springer, London, UK, 2014.
[33] F. Cacciatore, et al., The design of the GNC of the Re-entry module of space rider, in:
European Conference for Aeronautics and Space Sciences, EUCASS, 2019.
[34] A. Zolghadri, Advanced model-based FDIR techniques for aerospace systems: today
challenges and opportunities, Progress in Aerospace Sciences 53 (2012) 18e29.
[35] L. Pirson, J. Christy, B. Udrea, ICC2 study: GNC development in formation flying,
IFAC Proceedings Volumes 40 (7) (2007) 828e833.
[36] M. Jankovic, J. Paul, F. Kirchner, GNC architecture for autonomous robotic capture
of a non-cooperative target: preliminary concept design, Advances in Space Research
57 (8) (2016) 1715e1736.
[37] W.H. Fehse, Control tasks in automatic rendezvous and docking of spacecraft, in: 1999
European Control Conference, ECC, 1999, pp. 4842e4848.
646 Massimo Tipaldi et al.CHAPTER TWELVE
GNC verification and validation
Francesco Pace1
, Emanuele Paolini2
, Francesco Sanfedino3
,
Daniel Alazard3
, Andrea Colagrossi4
, Vincenzo Pesce5
,
Stefano Silvestrini4
1
GMV Aerospace & Defence, Madrid, Spain
2
D-Orbit, Fino Mornasco, Italy
3
ISAE-SUPAERO, Toulouse, France
4
Politecnico di Milano, Milan, Italy
5
Airbus D&S Advanced Studies, Toulouse, France
This chapter presents an overview of the key concepts regarding guidance,
navigation, and control (GNC) verification and validation procedures.
Model-in-the-loop (MIL), software-in-the-loop (SIL), processor-in-the￾loop (PIL), and hardware-in-the-loop (HIL) tests are presented from
GNC modeling and simulator development. Autocoding and different veri￾fication activities, including requirements, code standards, and coverage
verification are discussed. Finally, in-orbit testing and all the activities aiming
to verify correct high-level, in-orbit functionalities, performances, and op￾erations of the system are introduced.
The content of this chapter is structured as follows:
• Why it is important? This section introduces the main concepts and defi￾nitions of GNC verification and validation (V&V) procedures. Their
importance in the GNC design and implementation phase is highlighted.
• Statistical methods. In this section, the most relevant statistical methods to
conduct successful and representative GNC V&V campaigns are
outlined.
• MIL test. This section introduces the concept of MIL test. High-level
guidelines for GNC algorithms modeling, including architectures and
implementation rules, are described. MIL verification activities are then
detailed for this test phase.
• SIL/PIL test. Similarly, SIL and PIL tests are introduced. Standard guide￾lines for autocoding are presented along with verification activities at SIL
and PIL level.
Modern Spacecraft Guidance, Navigation, and Control
ISBN: 978-0-323-90916-7
https://doi.org/10.1016/B978-0-323-90916-7.00012-3
© 2023 Elsevier Inc.
All rights reserved. 647 j• HIL test. This section summarizes and highlights the most relevant steps
to be followed during HIL test and its main objectives. Examples of hard￾ware and software HIL verification are discussed.
• In-orbit test. In this section, the concept of in-orbit testing for system
functionalities, performance, and operations verification is detailed.
Why it is important?
As in all industrial process, the GNC system after a preliminary design
phase needs a consolidation through a V&V phase.
This phase is one the most important in a spacecraft design cycle since it
provides the certificate that the product will finally work as specified by its
requirement list and will assure the accomplishment of the mission by
providing the same degradation of performance in case of predicted
anomalies.
Following the definitions provided by the glossary of terms of the Euro￾pean Cooperation for Space Standardization (ECSS) [1]:
• “(A) verification process [.] demonstrates through the provision of objective ev￾idence that the product is designed and produced according to its specifications and
the agreed deviations and waivers, and is free of defects A waiver can arise as an
output of the verification process. Verification can be accomplished by one or more
of the following methods: analysis (including similarity), test, inspection, review of
design.”
• “(A) validation process [.] demonstrates that the product is able to accomplish
its intended use in the intended operational environment. Verification is a prereq￾uisite for validation.”
Note that a “waiver (is a) formal authorization to accept products which during
production, or after having been submitted to inspection or tests, are found to depart
from specified requirements. Deviation is an a priori decision whereas waiver is an
a posteriori decision with respect to the production phase.”
Validation is achieved when the product meets the needs linked to its use
(i.e., level of pointing performance requested by the client). If these needs
are systematically translated into requirements in the verification process,
their achievement automatically brings the validation process to its
fulfillment.
The “Satellite attitude and orbit control system (AOCS) requirements”
document provided by the ECSS [2] provided some guidelines on how to
standardize the GNC requirements by covering the following areas:
648 Francesco Pace et al.• Attitude estimation.
• Attitude guidance.
• Attitude control.
• Orbit control.
• Orbit estimation (or navigation).
• Acquisition and maintenance of a safe attitude in emergency cases and
return to nominal mission upon command.
For missions where pointing performance constraints spacecraft design,
as for Earth observation or Science, the ECSS formalizes a list of pointing
requirements [3,4], which have been detailed in Chapter 10 - Control.
For the GNC system, V&V is an incremental process applied to each of
the following GNC development/realization steps:
• MIL simulation.
• SIL simulation.
• PIL simulation.
• HIL simulation.
• In-orbit test (IOT).
The principle of these steps is to progressively move from the system
modeling environment to the real-world implementation. The latter one
has, in fact, to deal with software limits due to the translation into real￾time code, processor maximum achievable performance, unavoidable
mismatch between plant/sensors/actuators models and real hardware, and
in-orbit environment as well.
One of the most widespread tools used for GNC prototyping and simu￾lation is MATLAB/Simulink where multiphysics nonlinear simulators can
be developed to validate guidance and control laws.
General practice is to start with very simple models at the beginning of a
project, which capture the main dynamics for the preliminary dimensioning
of the sensors/actuators according to the maximum expected control/tor￾ques. In this spirit, if the linearity hypothesis is justified, as in the majority
of spacecraft missions where the maximum spacecraft speed rates are very
small, linear models or a family of linear models (for different mission control
phases) can be derived with the advantage of disposing of a huge amount of
control techniques for which stability and performance robustness can be
analytically proven in frequency domain by avoiding time-consuming
time simulations. For instance, as seen in Chapter 10 - Control, different
metrics are, in fact, available to validate stability of a control design: from
the classical ones as gain, phase, delay, and modulus margin to more recent
as the structured singular values theory [5].
GNC verification and validation 649For spacecraft with large and flexible structures (like big antennas), a rigid
body approximation is not sufficient to correctly predict and guarantee the
stability and performance of the real system. It is then important to validate
the GNC models with accurate finite element structural models.
Once preliminary control laws are verified on linear-based plants, a vali￾dation in a high-fidelity nonlinear simulator is always needed. In this case,
finer models are used to simulate not only the plant, for which nonlinear
terms (as Coriolis or centrifugal forces) are not neglected this time but also
the sensor/actuator dynamics and the environmental conditions. In this
phase, for instance, actuator/sensor strong nonlinearities (such as saturations,
dead-zones, and hysteresis) are taken into account together with high￾fidelity models of orbital and attitude perturbations (gravity gradient torque,
solar pressure, atmospheric drag, etc.).
If the plant linear hypothesis is confirmed and the control design avoids
strong linearities, like saturations by limiting, for example, the maximum
control signal before entering into the nonlinear behavior, the linear￾based model can be sufficient to validate the design. On the other hand, if
stability and/or performance drop to unacceptable level, a control redesign
is needed taking into account neglected dynamics or unpredicted behaviors.
If nonlinearities cannot be absolutely neglected, then, a nonlinear controller
has to be synthesized as shown, for instance, in Chapter 10 - Control.
The widespread way to validate a nonlinear model simulator in industry
is to use Monte Carlo simulations where a probability distribution function
(PDF) is associated to key parameters for which a fixed level of misknowl￾edge (i.e., manufacturing imperfections for mechanical parameters) or statis￾tical nature (i.e., actuator/sensor noises and perturbation) is defined. The
counterpart of Monte Carlo simulations is the compromise between
coverage of the parameter’s space and simulation time. The risk is to not
detect possible critical configurations corresponding to very rare events, fall￾ing beyond the 3s of the parameter PDF. To overcome this issue, an alter￾native way is to use advanced techniques which are able to fast isolate worst￾case configurations that can be then tested in the high-fidelity full linear
simulator, like the already cited structured singular values computation algo￾rithms (also known as m-analysis) in linear domain or based on integral
quadratic constraints (IQCs) [6] in nonlinear domain.
Once the MIL validation phase is finalized, the next step is the SIL vali￾dation, where now the synthetized controller is translated in embedded-like
code, in most of the cases in C/Cþþ or JAVA language. However, all the
other elements of the MIL test are kept in the MIL environment. This
650 Francesco Pace et al.means, for example, that if the sensors/actuators, the environment, and the
plant are implemented in a Simulink model, the controller/estimator is
incorporated in an S-function where a conversion in C code of the control
model is available. The code translation is now an automatized operation
(autocoding): by following some rules in building the simulation model,
the user can obtain the equivalent embedded-like code in a straightforward
way.
If differences with respect to MIL test rise and do not meet the level of
acceptable degradation, the reason has to be deeply investigated in order to
go back to the modeling step and make the due modifications.
The following step of the V&V process is the PIL test, where the previ￾ous controller code is actually embedded in a dedicated processor whose
performance is generally comparable to the ones of the final spacecraft
on-board computer (OBC). This test allows the GNC engineers to verify
that the synthetized controller can be run on a processor with limited per￾formance compared to an on-ground computer. An example of critical test
is the one involving complicated estimation and navigation algorithms
where a huge number of system states are involved, vision-based routines
or convex-optimization guidance algorithms where the processor has to
run several optimizations without introducing destabilizing delays.
The final on-ground validation phase consists of the HIL test, where the
real plant and/or the sensors/actuators are interfaced with the control loop
running on the embedded processor.
For spacecraft applications, it is generally complicated to replicate on￾ground the same conditions as in the Space. If some environmental param￾eters can be emulated as void condition, or Sun radiation, the microgravity
condition cannot be by-passed in any way. The hardware elements that are
generally tested in an HIL facility are then sensors and actuators like reaction
wheels, while the spacecraft dynamics is simulated on a real-time platform.
The commands to the actuators are then analogically sent by the real-time
software simulating both the plant and the environment and computed by
the control unit processor.
The final step of V&V activity is carried out when the spacecraft is on￾orbit. All the hardware can now be verified in the operational conditions,
and the expected system performance can be measured and compared to
the mission requirements.
All the steps presented in this introduction, and extended in the
following sections, do not proceed in a sequential way since several iterations
are often needed before satisfying all the tests without coming back to pre￾vious steps.
GNC verification and validation 651In space history, the Hubble Space Telescope experience provides a clear
example of how a V&V process can be invalidated in a very late phase of the
project when unmodeled phenomena are not taken into account from the
beginning of the GNC design. When the first version of the AOCS
controller was implemented, an unexpected level of oscillation of the solar
panel was observed on-orbit that was responsible of a degradation of the
pointing requirement and consequently of the imaging quality. It was
then discovered that this phenomenon was due to the thermal stress induced
in the solar panels when the satellite was passing into eclipse. A new
controller was then redesigned on-ground and sent to the spacecraft, and
new solar arrays were installed during the first servicing mission [7].
Statistical methods
Before detailing the V&V steps of a GNC system, it is necessary to
introduce the statistical methods necessary to perform such activity. In
modeling the GNC system, designers shall take into account several uncer￾tainties: mass and inertia values, eigenfrequencies and damping ratios for the
flexible appendages, sensor noises, etc. All the physical parameters that can
potentially have an impact on the performance of the system shall be taken
into consideration with their associated statistical representation. The
modeling of these effects involves the statistical interpretation of the phe￾nomena, mainly to understand if the designer is dealing with a stochastic
disturbance or, instead, a deterministic uncertainty. The word “stochastic”
comes from the Greek stokhos, meaning “aim, guess”: therefore, stochastic
refers to something randomic, in its own happening or in the amplitude
of the phenomenon. In spacecraft GNC, this is the case of random errors
on sensors, for example. On the other side, examples of limited uncertainties
can be bias or low-frequency errors, or even the deviation of mass properties
respect to the measured values.
Moreover, the variation over time of a low-frequency error can be asso￾ciated to well-known periodic phenomena, such as the variation with tem￾perature, which will periodically vary during an orbit in low Earth orbit
(LEO) because of the alternation between sunlight and eclipse. Therefore,
the most appropriate way to represent this kind of uncertainty is through
a sinusoidal variation with period equal to the orbital period and amplitude
specified by supplier data. If the amplitude of this variation is not well
known, then a statistical consideration shall be carried out.
652 Francesco Pace et al.Other type of errors can be treated in a very similar way. For example,
sensor misalignments due to actual mounting on the spacecraft, or even mis￾alignments measurement residuals, can be represented by a number that will
be constant in time but defined randomly at simulation start with its associ￾ated 3s value (see Chapter 6 - Sensors).
The same goes for scale factors: they can be typically addressed as a
Gaussian distribution in a well-defined range, for example, mean3s value.
On the other hand, it can be more realistic to consider bias errors as picked
randomly in a uniform distribution (see Chapter 6 - Sensors).
It can be well understood at this point that running a few simulations
with error values set in a predefined way - randomly chosen in their possible
range with their given distribution - is not fully representative. Indeed, in
this way, just a limited number of random cases will be analyzed, and the
obtained performance in this nominal subset is just a partial indication of
the overall system performance. To have an extensive verification cycle at
simulation level, stochastic analysis shall be performed to test the robustness
of the GNC algorithms to the variation of external and internal conditions.
To this extent, Monte Carlo analysis is performed, where a batch of simu￾lations is run for the same scenario, scattering initial conditions in the appro￾priate range and through the appropriate distribution.
Table 12.1 shows an example of a typical approach when dealing with a
Monte Carlo analysis. For example, considering the first simulation set
dealing with the release from launcher conditions, in order to simulate cor￾rect damping of angular rates and Sun-pointing acquisition, two different
statistical representations will be considered:
• Initial attitude scattering: Sampled according to a uniform distribution
since the satellite can have whichever attitude indifferently at launcher
release.
• Satellite angular rate: Sampled according to a Gaussian distribution over a
zero mean with the standard deviation value provided by the launcher
manufacturer itself.
The previous considerations about sensors errors modeling shall be
applied choosing the most appropriate statistical representation for each error
contributor. The number of simulations for each scenario reported here is
1000 and is found targeting a failure probability (f) of 0.3% and a confidence
level (C) of 95% using the following formula [8,9]:
N: of simulations ¼ lnð1  CÞ
lnð1  f Þ
GNC verification and validation 653Table 12.1 Example Monte Carlo analysis schedule.
Simulation
AOCS
mode
Number of
simulations
Initial conditions
Attitude Angular rate Position in orbit Sensors noise
1. Release from
launcher
Safe 1000 0e360, uniform
distribution
0  X/s 3s on
each axis
0e360, uniform
distribution
Gaussian, errors
from datasheets
2. Image
acquisition
Nominal 1000 Deviation from
target: X,
uniform
distribution
Nominal  X/s
3s on each axis
0e360, uniform
distribution
Gaussian, errors
from datasheets
.
654 Francesco Pace et al.With the selected values for C and f, it is obtained a number of simulations of
997, then rounded up to 1000.
Other variables can be scattered either, such as the initial position in orbit
or the mass and inertia values. Obviously, uncertainties representation re￾flects also in defining the uncertainty domain over which the GNC and
especially the controller behavior is investigated, in terms of stability and
margins: the more uncertainties, the wider the uncertain domain over which
the controller stability shall be verified. For this reason, it can be convenient
to not consider a very high number of variables to be scattered, and even￾tually complete the assessment with worst-case scenarios for a more compre￾hensive treatment of the extreme, but yet realistic, cases (worst-case analysis,
WCA).
All the considerations done so far allow the GNC designer to better
model the errors involved, and by doing so, to evaluate the system perfor￾mance in a broader and more realistic way: the performance shall be then
evaluated against requirements to assess whether the system meets the
specifications.
Indeed, requirements involving the GNC subsystem will typically
include statistical considerations in order to correctly assess the verification.
For example, a requirement could state:
“The two-axis error between the actual and the target payload boresight
direction shall be less than 100 arcsec 99% of the time.”
In general terms, the probability is expressed as a fraction or a percentage,
while the expression ns is used only when a Gaussian distribution applies, as
the concept of standard deviation does not provide additional information in
a uniform distribution. The same requirement could be expressed in other
forms, but the rationale behind it remains the same: considering the physical
quantity X and a maximum value Xmax, the probability of X being smaller
than Xmax is constrained to be higher than a certain value P:
probðjXj < XmaxÞ  P
This kind of high-level requirements is typically addressed through bud￾gets: the contributing errors shall be identified and then characterized based
on their statistical classification, usually summing up biases together and
treating separately random errors with their standard deviations. Then, a
root sum square can be considered in order to have a final result. A deeper
discussion on control budgets is presented in Chapter 10 - Control.
GNC verification and validation 655MIL test
Nowadays a baseline method to prototype space GNC software algo￾rithms is to develop a simulator in MATLAB/Simulink environment
following a model-based component approach. The models are validated
in an MIL environment where the GNC algorithms are tested in closed
loop with a simulation of the mission environment and spacecraft subsystems.
The Simulink GNC models are then autocoded (by means of automatic
techniques and tools), and the generated code is validated in real-time test
benches where a prequalification testing campaign is performed to provide
the GNC software ready for integration into an on-board software
(OBSW) for complete software qualification. This development approach
allows a fast GNC software design, V&V process that grants a reduction in
the cost and time for producing a flight GNC software for a mission. The
autocoding process is a fundamental step to be executed between MIL and
SIL test. In this book, we will refer to autocoding during the description
of the MIL test since, during this phase, it is crucial to develop models that
are ready to be autocoded.
The code used in the space OBSW (e.g., mainly C or ADA) is very often
categorized as critical by software standards (e.g., category B critical software
as per ECSS [10]) due to the particular environment where it operates. Thus,
specific aspects of the software development and verification shall be clearly
defined and analyzed as well as the quality of the code produced according
to software standards. This last aspect is particularly important if OBSW code
is generated by automatic code generation tools and techniques starting from
MIL environments.
Modeling of AOCS/GNC algorithms
The development of GNC algorithms follows a model-based design
approach. This means that the complete GNC subsystem is implemented
in a single design platform that allows the engineers or software developers
to create visual simulation models of the complete system and check the
proper working of the GNC algorithms before the implementation of the
correspondent code (automatically generated or hand-written).
The most common testing platform used for GNC algorithms develop￾ment is the MATLAB/Simulink environment. MATLAB is widely used
since it allows fast prototyping and powerful analysis tools and functions.
656 Francesco Pace et al.Moreover, reuse of Simulink models already validated in other projects is
extensively encouraged, as per model-based engineering philosophy.
The MATLAB/Simulink implementation could evolve in flight code
using the autocoding tool chain, ensuring the compatibility between the
design at GNC model level with the design at application software
(ASW) level (i.e., code). This means that the GNC models allow capturing
the core behavior of the final software product, description and verification
already at specification level. In addition, it allows the developers to follow a
smooth verification of the algorithms considering that the GNC models
have been completely specified in terms of algorithms, interface, and param￾eters, and also tested and validated at unit, integration, and functional levels
in the Simulink environment, allowing its reuse at ASW level. Please note
that we refer to unit test when individual modules are tested individually
in isolation, integration test if the different modules are tested working
together, and functional tests when the whole system behavior is tested as
per defined requirements.
The models play a fundamental role in the GNC development since the
requirements and architectural design specification are captured and sup￾ported from early stages in MATLAB/Simulink simulators (e.g., 3 DoF sim￾ulators where only translational propagation of the vehicle is considered, and
basic laws are implemented for the mission environment) that can be
executed and provide feedback to the engineers for consolidation of
GNC and mission requirements. Further developments can use the 3 DoF
simulator as starting point to generate a full 6 DoF simulator with the com￾plete GNC algorithms for attitude and translational control and more high￾fidelity models of the mission environment and hardware units involved like
sensors or actuators.
Architecture
The GNC algorithms are designed and implemented into MATLAB/Simu￾link environment in a functional engineering simulator (FES) or so-called
MIL. This environment accounts for the GNC models (mainly guidance,
navigation, control and vehicle management) and also for real-world models
that provide the representative context for the validation of the GNC algo￾rithms. The real-world includes models that are relevant for the GNC
development and verification activities such as:
• Mission environment and perturbations (see Chapter 3 - The space
environment).
• Attitude dynamics propagation (see Chapter 5 - Attitude dynamics).
GNC verification and validation 657• Translational dynamics propagation (see Chapter 4 - Orbital dynamics).
• Sensors (see Chapter 6 - Sensors).
• Actuators (see Chapter 7 - Actuators).
• Equipment (affecting directly GNC like solar array drive mechanisms,
deployment mechanisms, appendages, etc.).
Other equipment like thermal models, power models, telemetry/tele￾command (TM/TC), transmitters, etc., are not generally modeled in the
FES environment since they do not provide added values for the develop￾ment of GNC algorithms and correspondent V&V activities.
In order to apply the model-based design and autocoding methodology,
the MIL simulator shall clearly define separated subsystems for the GNC and
the real-world models. Before the next V&V phase (SIL), the GNC will be
autocoded (into typically C or ADA), integrated into the OBSW, and
executed on-board during mission, while the real-world models are ele￾ments used only on-ground facilities for GNC testing and verification
purposes.
Typical architecture for MIL simulator is represented in Fig. 12.1.
The real-world models, simulating the environment and the sensor ex￾pected behavior, provide the sensor measurements to the OBSW. These
measurements are preprocessed inside the OBSW and fed to the GNC.
The GNC block receives the measurements, executes the respective
GNC functions and provides actuators commands to guarantee the desired
performance. These commands are sent back to the real-world where the
actuators models generate the actuations considering hardware modeling as￾pects. The spacecraft dynamics is then executed and generates the state
Figure 12.1 Typical MIL simulator architecture.
658 Francesco Pace et al.vector information (e.g., position, velocity, attitude quaternion, and angular
rates) used by sensor models to carry out the measurements for the next
execution cycle.
Please note that often a dynamics and kinematic environment (DKE)
model is considered as including the environment, perturbation, and dy￾namics propagation models of the spacecraft. On the other hand, the
GNC model is the ASW that will be executed on-board together with
the complete OBSW. Even if only GNC block will be autocoded, a
good practice is to implement in the FES environment also simplified
models of the OBSW functions that are relevant for GNC correct behavior
(e.g., OBSW in and OBSW out as in Fig. 12.1) that allow preparing the
GNC input vector data for execution of a step of the algorithms (like crea￾tion of measurements’ buffers, units conversion, routing of signals, etc.) and
prepare the GNC output vector data to be sent to real-world models.
Avionics delays
The MIL environment is the first testing facility where the GNC is devel￾oped. The autocoding methodology allows generation of the code that
will be ported incrementally to more space representative environments
like PIL, HIL, or ATB (Avionics Test Bench). Thus, an important aspect
of the MIL modeling is to consider already at early development stages
the delays that will be faced when avionics equipment (i.e., hardware ele￾ments) is integrated in facilities like ATB. Delays are typically generated
by the commanding and communication algorithms of the OBSW (e.g.,
OBSW scheduling function to command actuators during the execution cy￾cle, encoding/decoding functions, etc.) and physical delays of the signal
manipulation and transmission to the hardware elements. Thus, the control
algorithms shall be developed to be robust enough to cope with these avi￾onics delays and the GNC shall be validated considering the worst case of
delays already at MIL level. An important aspect in modeling the avionics
delays is that in Simulink implementation, the delay introduced shall be
deterministic to guarantee a repetitive behavior of the GNC algorithms to￾ward WCA.
Multirate
The GNC architectural design is generally organized by functionalities, typi￾cally a block for navigation, guidance, control algorithms and management
logics. Even if this approach is compatible with autocoding, the most opti￾mized approach is to organize the GNC according to execution frequency
GNC verification and validation 659of the functions and set the Simulink options for tasking and sample time to
treat each discrete rate as separated task. The management of the multi￾tasking and multirate factors will determinate the software integration
approach of the generated code with the OBSW and the real-time operating
system (RTOS). Note that, in the OBSW, all sample times shall be an
integer multiple of the model’s fixed step size. Following the rates organiza￾tion approach, clear separated functions will be directly generated from
autocoding associated with each execution rate of the GNC models.
Then, the management of integration and scheduling of the production
code with the rest of OBSW is responsibility of the software integrator.
In fact, these factors will affect the scheduling implementation of the basic
software, which is the part of the code that manages the low-level function￾alities or basic services like scheduling, data interchange between modules,
etc. This way, the GNC software, which has been divided into different
functional units (previously identified), will be controlled by the OBSW
and the on-board RTOS.
Tunable parameters
In Simulink environment, the GNC models are configured via parameters
that will determine the tuning of the GNC itself. These parameters can
be modified and updated in the MATLAB workspace to execute different
tests during simulations campaign. The same mechanism is desirable for
the auto-generated GNC software where the OBSW should provide func￾tions or a method to update the mission parameters. When generating the
code, if not specified otherwise, the GNC parameters will be hard-coded.
This aspect generates the need to define the parameters as tunable in the
Simulink environment to have the possibility for updates also in the gener￾ated code. A typical approach in GNC development is to group parameters
as tunable and nontunable sets. This solution allows to quickly identify
which parameters shall be mapped to variables in the code with the possibil￾ity of updates from OBSW functions that provide the capability to modify
specific memory areas of the data pool (group of data that can be accessed
from OBSW functions). These parameters shall be set as tunable in the
MATLAB/Simulink environment (see MATLAB help for tunability [11]).
Strictly speaking, autocoding is not part of the MIL test (where only MAT￾LAB/Simulink simulation are run). However, MIL models shall be devel￾oped following autocoding best practices to avoid useless iterations on the
models’ design. For this reason, the most important aspects in MIL modeling
660 Francesco Pace et al.toward automatic generation of the GNC software are resumed in the
following points:
• Clear and separated interfaces must be defined between the real-world
and the OBSW models.
• Interfaces of GNC block shall define size, data type, and sample time. All
these properties of the inport and outport blocks shall be explicitly
defined. No Simulink inherited (1) settings shall be used.
• The Simulink simulator must use discrete solver and time steps. The
GNC software will be embedded into an OBSW executed in an
OBC working at discrete times.
• Explicit definition of tunable parameters.
• Not use of mask initialization function.
• Architectural organization of GNC as per frequency.
Requirements tracing
The GNC requirements drive the models development and implementa￾tion. A set of user requirements is specified at the beginning of the software
lifecycle, and it is used to describe the complete behavior of the algorithms
implemented by the models. Frequently, the models developed in MAT￾LAB/Simulink are used as a requirement specification itself due to the
ease of generating simulations (open loop and closed loop) that demonstrate
the correct implementation of the algorithms.
In this context, the MATLAB/Simulink environment is used for model
development and for the verification of the models’ requirements. Simulink
can be extended with add-on products for verification, validation, and
testing activities that enable a continuous testing and verification throughout
the development process.
The requirements typically stored and managed by a tool (e.g., DOORs)
can be linked to the correspondent model implementation in Simulink. The
link shall track univocally the requirements ID with the related models (e.g.,
textual link, hyperlink, etc.). A modeling verification tool may be used to
define and manage the links created in the Simulink models and to verify
their validity.
GNC optimization
At this step of the FES development, some preliminary work of identifica￾tion and analysis of the Simulink subsystems containing the main GNC
modules and their interfaces with the rest of systems (e.g., OBSW and
real-world) shall be performed, as shown in the example reported in
Fig. 12.2.
GNC verification and validation 661The optimization of the architecture of GNC consists of the following
main activities:
• Identification of the functions that define the GNC and setting them as
reference models or atomic subsystems. The GNC ASW design is started
by creating a root class representing the overall GNC system, and then it
is decomposed into smaller pieces according to the simulator architecture
and following the autocoding methodology inherited from the use of the
autocoding tool (e.g., Embedded Coder [12]).
• The isolation of the generated code functions is based on:
o Isolation of main functionalities.
o Isolation of computational critical elements (to easily test computa￾tional bottlenecks).
• Limitation of the generated code size per function and module (code
file). A maximum number of basic blocks shall be defined in order to
limit the code size for each function (control metric).
• Identification of the working rate and frequency of each component.
• Identification and definition of the interfaces of each component.
• Code specification using autocoding tool (e.g., Embedded Coder [12])
properties inside of the selected Simulink subsystems (where previously
have been defined/declared the variables, data structures, scaling for￾mulas, function calls, tasks, etc.).
Figure 12.2 Example of GNC decomposition and functions identification.
662 Francesco Pace et al.Modeling rules
The use of autocoding techniques to generate code from a model-based
development (e.g., via MATLAB/Simulink) implies the use of rules and
guidelines to guarantee the quality and compliance of the produced code
with the required standards. Again, this is not necessarily part of the MIL
test, but it is reported here as a fundamental step during MIL models
generation.
The guidelines for the GNC modeling in MATLAB/Simulink may be
grouped into two categories:
1. Modeling architectural and design rules
This group defines the rules/guidelines that need to be followed at
architectural and design level of the GNC subsystem. These rules
allow the automation of the real-time validation process in an inte￾grated environment and ease the porting of the generated code to the
SIL and PIL test setups without significant modification of the
Simulink models and guaranteeing architectural mapping between
the Simulink models and the produced code.
2. Modeling implementation rules (coding and style)
This group defines rules/guidelines that need to be followed by the
Simulink implementation of the GNC models. These rules prevent
errors, language-specific pitfalls, nonoptimized statements,
forbidden constructs, complexity restrictions, and readability. These
rules primarily increase the reliability of the validation process and
allow the generation of optimized code.
These modeling rules shall be taken into account from the starting of the
GNC development (as they imply architectural constraints, development
strategies, etc.). Moreover, these rules must guarantee that the proper level
of numerical accuracy is obtained in the generated code. In order to do it,
the requirements and guidelines shall be checked and implemented through
the use of a checking rule tool (e.g., Simulink Check toolbox [13]), which
permits to define coding style and rules and performs automatic checks of
the Simulink models (e.g., through the Model Advisor [14]). For more de￾tails, please refer to Chapter 18 - Autocoding best practices.
Verification activities at MIL level
The main activities related to the GNC modeling V&V are listed below:
• Algorithms V&V.
• Requirements verification.
GNC verification and validation 663• Modeling standards verification.
• Model coverage verification.
• Profiling of the models.
Algorithms verification and validation
The functional validation of the GNC algorithms is performed in MIL envi￾ronment via specific tests, sensitivity analysis, or Monte Carlo analysis. This
validation is performed against the GNC requirements. Please see specific
section on Statistical Methods.
Requirements verification
The requirement verification activities for the GNC software are executed
at two levels:
• Models requirement verification.
• Code requirements verification.
Models requirement verification
The requirements that have been used to the drive the development of the
software shall be verified in the models implementation in Simulink envi￾ronment. The following steps are considered:
1. Link the requirements to Simulink models.
2. Verify the requirement trace from Simulink models.
The requirements implemented in the Simulink models shall be verified.
A traceability matrix or a report shall be created to assess the requirements
that have been considered in the Simulink implementation. A modeling
tool may be used to generate automatically the traceability matrix and verify
the requirements coverage at model level.
Code requirement verification
The requirements that have driven the software design at model level in
Simulink environment shall be maintained in the production code gener￾ated. The same steps used for models requirement verification are considered
but at code level:
1. Link the requirements to production code. The requirements, in this
case, shall be linked to the correspondent implementation in the gener￾ated code. The link previously defined at model level during design and
implementation shall be maintained at code level. The code generator
tool shall provide the capability to keep the track of the requirement dur￾ing automatic code generation.
664 Francesco Pace et al.2. Verify the requirement trace from production code. The requirements
implemented in the production code generated shall be verified. As
before, a traceability matrix or a report shall be created to assess the re￾quirements that have been considered in the production code. A coding
tool or directly the code generation tool may be used to generate auto￾matically the traceability matrix and verify the requirements coverage at
code level.
Models profiling
A preliminary model profiling may be also performed on MATLAB/Simu￾link to obtain raw numbers (mainly relative numbers between trade-off so￾lutions), and then, these parameters will be used in the GNC algorithm
trade-offs and implementation solutions. Profiling the algorithms will help
in finding potential bottlenecks from a computational point of view, and
it is a preliminary analysis for performing an optimization in the implemen￾tation of the models if any issue is detected. This analysis will provide a pre￾liminary estimation of the CPU consumption of the GNC algorithms.
Modeling standards verification
The development of GNC software shall be compliant with requirements,
and at the same time, it must consider also design and implementation as￾pects for guaranteeing a smooth and easy code generation using autocoding
techniques.
A set of rules and/or restrictions at modeling level can be defined or
tailored from standards for specific mission to ensure later generation of
high-quality code. V&V activities shall be performed on the Simulink
models to assure that the modeling guidelines have been respected at design
and implementation level.
The verification of modeling rules and standard on the Simulink models
can be performed since the beginning of the software design phases support￾ing the models’ development for the autocoding. The following activities
are defined for modeling rules verification:
1. Select the rules or standards to be verified. The rules and standard to be
verified at model level are specified (or agreed with the customer) for the
particular project. Predefined standards may be used or even project spe￾cific rules may be defined. Among the most common coding standards,
we can find:
GNC verification and validation 665• Motor Industry Software Reliability Association (MISRA) [15]: a set
of C/Cþþ coding guidelines ensuring code safety, security, and reli￾ability in embedded system software.
• MathWorks Automotive Advisory Board (MAAB) [16]: a set of
modeling guidelines for the usage of MATLAB, Simulink, Stateflow,
and Embedded Coder.
2. Run the checks on the models. The rules and standard are verified over
the Simulink models running the scripts that implement the check of the
rules. A modeling verification tool is typically used to run automatically
the checks specified.
3. Analyze the report of pass/fail checks. A report detailing the rules passed
and failed during verification is produced and analyzed in order to assess
the models compliance with the rules and standard selected. A modeling
verification tool typically generates reports from the checks run.
4. Update the design/implementation to correct the checks failed. The
failed checks drive the software designer to update and modify of the
Simulink models affected. These updates may be performed manually
(e.g., typical design updates that require human analysis) or automatic
scripts may be also provided by the modeling verification tool (e.g.,
typical implementation updates that are well identified).
5. Rerun the checks. After the models updates, the checks of the rules are
run again to verify the correct modifications. The process can be repeated
till the rules and standard checks are totally passed or justified.
Model coverage verification
Unit tests, integration tests, and validation tests are defined to validate the
GNC algorithms implementation from functional and interfaces point of
view. The model coverage is also an important aspect in model validation
since it provides the evidence of how many modules and subsystems have
been really executed during testing campaign. On this aspect, the percentage
of model coverage has to be agreed with the quality standards to be followed
in the GNC development.
Anyway, when possible, 100% of model coverage is desirable since it is a
considerably useful intermediate step to reach the 100% of the generated
code coverage. In fact, definition of the coverage tests for the models is setup
directly in MATLAB/Simulink environment and can be totally reused to
verify code coverage in SIL simulations.
666 Francesco Pace et al.Model coverage is considered to be reached by cumulative coverage per￾centage all over the unit, integration, and validation tests executed in MIL
configuration.
The verification of model coverage can be performed according to the
following steps:
1. Select the coverage type to be verified. The type of coverage analysis to
be performed over the Simulink models (e.g., decisions, conditions,
MC/DC, etc.) is specified and agreed with the customer. A modeling
verification tool is typically used for model coverage that is configured
to execute the specific coverage analysis selected.
2. Run the coverage on the models. The tests defined for the Simulink
models (e.g., unit, integration, or validation tests) are executed. The
modeling verification tool instruments the models to get the coverage re￾sults for the tests run.
3. Analyze the report of coverage. A report detailing the percentage of the
models covered by the tests (for the type of coverage specified) is pro￾duced and analyzed. The modeling verification tool typically generates
reports that can show directly in the Simulink implementation the
blocks/paths covered.
4. Add tests to increase coverage if not target percentage. If the target per￾centage (to be agreed with the customer) of model coverage is not
reached, new tests shall be defined. The analysis of the coverage report
drives a definition of new set of data and tests to force the execution
of all the uncovered blocks contained in the models. Thus, additional
tests are created in Simulink environment (MIL).
5. Rerun the model coverage for the additional tests. The additional tests
are run, and the model coverage is verified again (e.g., cumulative
coverage analysis). If 100% of coverage is not reached, yet the process
can be repeated till the model coverage is 100% (passed by tests or justi￾fied) or target percentage is reached.
SIL/PIL test
As already mentioned in the previous section, typical GNC software
design, development, and verification strategy is based on autocoding of
the GNC MATLAB/Simulink models in order to generate code optimized
for embedded systems. After GNC algorithms verification at model level,
the autocoding is performed and testing of the GNC generated code is
executed in the SIL environment aiming to verify that the GNC code
GNC verification and validation 667behaves like the models. The following step in the verification process is to
execute the code in a PIL test bench that computes the GNC code into
OBC to verify performance and real-time aspects of the software. The
following sections describe the V&V activities performed in SIL and PIL
environments.
Autocoding
The GNC development strategy is part of an integrated, coherent, and in￾cremental approach based on the chain MIL / Autocoding / SIL / PIL
/ HIL that allows porting the GNC algorithms from Simulink simulators
to hardware-embedded systems (Fig. 12.3) in a consistent and incremental
process.
Autocoding of MIL-validated GNC models is performed to produce
code and start the GNC software V&V process. An SIL environment is
the first step where the generated code is functionally tested by integrating
it into the MIL simulator in MATLAB/Simulink environment before going
to the PIL or HIL test benches. The objective of the SIL environment is to
verify that the generated code functionally behaves in the same way (apart
numerical accuracy) with respect to the algorithms implemented by the
models. Further step in GNC software validation is to execute the code
in a PIL test bench in an OBC to verify performance and real-time aspects
of the software.
This V&V approach chain can provide very productive support during
the development phases and possibility to test requirements already at early
and intermediate design phases. This approach allows fast iterations and
feedback and the possibility to correct design problems from the beginning
of software development minimizing the required effort.
Figure 12.3 Porting GNC models to embedded systems.
668 Francesco Pace et al.The autocoding methodology shall reflect all the design, development,
verification, and validation aspects of the software lifecycle, in particular,
for GNC software, where the autocoding techniques and tools are involved.
Fig. 12.4 shows the main activities related with autocoding that have to be
performed on the GNC software from the design to validation phases start￾ing from requirements down to model and finally to code in order to pro￾duce flight software.
Autocoding activities are considered at three levels: requirements, Simu￾link models, and production code. Most of the steps have been already
described for MIL test but are summarized here for the sake of clarity:
1. Requirements:
o Support Simulink models implementation. The GNC requirements
drive the models’ development and implementation.
o Trace the requirements to Simulink models. The GNC requirements
are generally stored in a database, and they must be traced to the
correspondent Simulink models to justify the implementation.
o Trace the requirements to code: The GNC requirements must be
traced also to the code generated automatically from the models.
2. Simulink models:
Figure 12.4 GNC software autocoding methodology main activities.
GNC verification and validation 669o Trace Simulink models back to requirements. The Simulink models
must be traced back to the correspondent set of requirements that
justify the implementation.
o Verify requirements. Verification of the requirements trace down to
Simulink implementation must be produced.
o Verify modeling rules. The GNC model-based development shall
follow several rules and guidelines for allowing the compatibility of
the Simulink models with the autocoding process for guaranteeing the
quality and compliance of the produced code with the required
standards. Verification of the modeling rules in Simulink imple￾mentation shall be produced (statics analysis on models). Reports can
be generated for the Simulink models to assess compliance with rules
and standards.
o Verify model coverage. The GNC models implementation shall be
verified by tests (dynamic analysis on models). These tests are focused
to validate the algorithms, but tests shall be also specified to reach a
target percentage of model coverage.
o Generate code. The Simulink GNC models are converted automati￾cally to production code (e.g., C or ADA). A code generator tool is
properly configured to generate an optimized production code
(e.g., metrics, memory, complexity, readability, etc.). A code genera￾tion report may be also generated to support the models architectural
mapping and traceability to code.
3. Production code:
o Trace code to models and requirements. The code generated must be
traced back to the correspondent Simulink models and back to the set
of requirements that justify the implementation.
o Verify codedSIL. The behavior of GNC code generated shall be
maintained with respect to the Simulink models. The same software
tests performed first at model level are then executed at code level
through SIL configuration (embedding the code generated automat￾ically into the FES simulator as S-Function) to verify the correct
generation of the code (same tests result for models and code).
o Verify code standard. The GNC code shall guarantee the metrics and
efficiency of the code generated via autocoding. The verification of a
coding standard shall be produced for this purpose.
o Verify code coverage. The GNC code shall be tested and typically
100% of code coverage shall be reached as requested by the standards
for flight software (e.g., ECSS [10]).
670 Francesco Pace et al.o Verify code performancedPIL. The real-time and profiling charac￾teristics (e.g., schedulability, memory budget, worst execution time,
etc.) of the GNC-generated code are verified by PIL tests. A specific
target shall be selected to run the generated code in the PIL
configuration.
Please note that the steps above are defined to generate prequalified
GNC flight software. For testing or demonstrating purposes where the
GNC software is only executed in ground facilities, some steps may be
relaxed and shall be agreed with the costumer based on project needs and
budget.
Moreover, settings of code generator and Simulink subsystem options
shall be agreed with the GNC software integrator. The way the OBSW ex￾ecutes the GNC affects the interfaces and the functions to be generated
depending on frequencies (i.e., scheduling of the functions based on rates
where a single-entry point function is generated for each rate) and manage￾ment of GNC input/output vector and tunable parameters (i.e., way to up￾date the data pool that refers to GNC data).
Software-in-the-loop
When autocoding is used, the GNC V&V is based on a stepwise approach
starting from MIL to SIL, porting the Simulink models to code. The GNC
software is produced from the models according to the code generator (e.g.,
Embedded Coder [12]) settings selected for the project that in general must
be agreed with OBSW integrator. Typically, an SIL block is generated as
well from autocoding process. This block is a Simulink S-function config￾ured to execute the generated code so that the GNC can be computed in
close loop, as shown in Fig. 12.5. This S-function can be automatically in￾tegrated into the MIL simulator (replacing the GNC model or executed in
parallel) to verify that the generated code provides the same results as the
original Simulink model. The new simulator containing the S-function is
executed using the complete MIL simulator inputs (including real-world),
and the results are compared with respect to the reference results obtained
during the validation campaign of the MIL.
Processor-in-the-loop
After SIL testing, an additional step in the GNC software validation is to
execute the code in a PIL environment. The GNC-generated code is inte￾grated into a software which implements functions related with GNC
GNC verification and validation 671execution (i.e., preparing the GNC input vector data from measurements,
execute the GNC step function, and prepare the GNC output data for com￾manding). This ASW is compiled using the same flags and options that will
be then used for complete OBSW. These settings must be iterated and
agreed with the OBSW integrator. The compiled binary image is loaded
in a RTOS (e.g., RTEMS [17]) that runs on the real OBC (e.g., LEON
board, ARM based processor, etc.dSee Chapter 13 - On-board implemen￾tation) or even on a target processor simulator (e.g., TSIM, TS, etc.) that
allow the emulation of different real processors behavior. The PIL test bench
allows testing the software in flight realistic conditions regarding the space
representative processor and with simulated environmental conditions that
could also be autocoded from FES/MIL (e.g., DKE, actuators, sensors,
etc.) and ported to a real-time environment, as in Fig. 12.6. The PIL is
the first test bench used to perform the integration between the GNC soft￾ware (autocoded) and the data handling and execution management soft￾ware (hand-made code).
Verification activities at SIL level
The main activities related to the AOCS/GNC modeling V&V are listed
below:
• Code functional verification.
• Requirements verification.
• Code standards verification.
• Code coverage verification.
Figure 12.5 From MIL to SIL.
672 Francesco Pace et al.Code functional verification
The GNC production code follows a development totally dependent of the
model design in term of specification, design, coding, unitary test, integra￾tion test, functional and performance validation, since it is based on autocod￾ing tools (e.g., Embedded Coder [12]).
Considering autocoding and model-based design for GNC software, all
these tests are performed first at model level and then they have to be
executed also at code level as well through SIL (embedding the code gener￾ated automatically into the Simulink simulator). Currently, no code gener￾ation tool can guarantee that code generated from MATLAB/Simulink
behaves (at least from functional point of view) exactly the same of the
model, avoiding in this way the execution of unit and integration tests on
the generated code (as required by software standards [10]).
The GNC software tests are defined and executed to validate the models
in an MIL configuration in MATLAB/Simulink environment. The same
tests, models, and additional test environment can be autocoded and then
executed in SIL configuration. The SIL allows the verification of the code
functionalities, interface, and coverage. A set of reference tests are selected
from MIL simulations (e.g., typically specific cases from Monte Carlo anal￾ysis) and executed in SIL environment. Reference outputs from MIL execu￾tion are compared against the SIL results, as in Fig. 12.7. If the outputs
difference is less that a defined threshold, the generation of the code is
considered successful.
Figure 12.6 PIL environment configuration.
GNC verification and validation 673A threshold shall be considered in the comparison of results of MIL
versus SIL since numerical accuracy is different between models and code.
A final set of validation tests is also ported from SIL to PIL.
Requirements verification
The requirements that have driven the software design at model level in
Simulink environment shall be maintained in the production code gener￾ated. Thus, requirements verification activities are also performed at code
level in the same way they were verified at model level.
Code standards verification
Coding standards and metrics can be verified on the GNC code generated
automatically from Matlab/Simulink models. Applicable standards shall be
agreed with the client in the context of a project, but MISRA-C 2012
[15] is often proposed to be the standard that guarantees the metrics and ef￾ficiency of the code generated via autocoding. In fact, this version of the
MISRA-C standard includes a number of improvements that can reduce
the cost and complexity of compliance while aiding consistent and safe
use of C in critical system. Moreover MISRA-C 2012 includes MISRA
AC AGCdGuidelines for the application of MISRA-C 2004 in the context
of automatic code generation.
Figure 12.7 GNC software verification in SIL (MIL vs. SIL).
674 Francesco Pace et al.The verification of coding rules and standard on the auto-generated pro￾duction code is executed according to the following steps:
1. Select the rules or standards to be verified. The rules and standard to be
verified at code level are specified (or agreed with the customer) for the
particular project.
2. Run the checks on the generated code. The code standard is verified
over the generated code via a static analysis. A coding verification tool
is typically used to run automatically the checks to verify the rules of
the standard.
3. Analyze the report of pass/fail checks. A report detailing the rules passed
and failed during verification is produced and analyzed in order to assess
the code compliance with the rules and standard selected. A coding veri￾fication tool typically generates reports directly in the code pointing out
(e.g., with colors, markers, underlines, etc.) the lines that do not comply
with the standard.
4. Update the Simulink model design/implementation to correct the
checks failed. The failed checks drive the software designer to identify
and update the implementation of the Simulink models that generated
those lines or to update the configuration and settings of the code gener￾ator tool to produce a better optimized code compliant with the
standard.
5. Regenerate the code from Simulink models. The code is generated again
after the update of the Simulink models and/or update of code generator
tool settings. The autocoding process is applied, and the code is
produced.
6. Rerun the checks. The rules are run again over the new code to verify
the correct updates, and the process can be repeated till the rules and
standard checks are totally passed or justified.
Code coverage verification
The code coverage analysis is performed based on MIL to SIL conversion
approach that guarantees that the algorithms of the GNC are correctly con￾verted to production code by the code generator tool (i.e., validation tests
passed at SIL level) and coverage that is tested at model level can be assessed
also at code level. The tests defined in Simulink environment to assess model
coverage are reused in SIL configuration to verify the percentage of code
coverage. This approach allows reusing tests defined at MIL configuration
and verify the efficiency of the code generator tools and/or settings. The
percentage of code to be covered depends on the category of the code
GNC verification and validation 675generated and shall be agreed with the customer. For example, according to
ECSS standards [10], if code is declared as category B, the 100% of the code
coverage must be reached and this means that all the code statements and
branches must be covered. But this level of coverage may be relaxed for
code used just at test environment levels on ground (i.e., prototype code).
The verification of code coverage can be performed according to the
same steps detailed for model coverage verification.
Verification activities at PIL level
The PIL test benches allow to test the software in space representative pro￾cessor and with simulated environmental conditions. The PIL testing is the
first real-time test bench where the final GNC flight software will be used in
real-time closed-loop operation.
The main objective of the PIL campaign is to functionally verify the
implementation of GNC software generated via autocoding techniques in
a real-time closed-loop test against the requirements, mainly for perfor￾mance, safety, robustness, and real-time aspects. Thus, the following activ￾ities are considered for PIL tests campaign:
• Assess the GNC algorithms robustness to variations in floating point
implementations using real processor (simulated or hardware board),
real-time OS, and cross-compiler.
• Assess code performance: computational load and memory and code size.
• Identify and check time margins in the data communication and algo￾rithm execution on the real processor.
• Assess the algorithm’s robustness to delays coming from synchronization
between real-world and GNC application.
• Confirm that the integration of the GNC code inside the real-time OS
of the OBC has been correctly performed.
• Testing behavior that cannot be tested in a modeling environment (for
instance, to check optimized code, ANSI compatibilities, overflow pro￾tections, etc.).
Comparison of the performance results with results from the SIL testing
campaign is a further validation milestone since it provides verification that
the flight software implementation is compliant to the user requirements in a
real-time environment using real or representative processor.
676 Francesco Pace et al.HIL test
The final on-ground validation step is represented by the HIL test.
Contrary to PIL test, where only the GNC software is running on represen￾tative hardware, during HIL test, real equipment, such as sensors/actuators,
is interfaced with the software running on the embedded processor.
Before the HIL test, different, sequential tests are implemented allowing
to verify the hardware correct behavior:
• Interface and functional tests (IFTs). The hardware equipment to be
tested is connected to the OBC and to the power supply to switch the
equipment on and command its basic functionalities in an open-loop
setup.
• Functional after integration (FAI). The hardware equipment is tested
once it is integrated on the spacecraft flight model, therefore involving
flight OBC, flight power control unit and flight connections that are
supposed to be not disconnected in the following of the AIV campaign,
otherwise the test is invalid.
• Full functional tests (FFTs). It is aimed at being a quick verification of the
correct basic functionalities of all AOCS/GNC equipment once the
spacecraft has completed its integration and can be repeated several times
after each major event that could have a potential impact on the satellite
(mechanical loads test, thermal vacuum chamber test, transportation to
the launch site, etc.).
• HIL. It is a verification technique involving a GNC software or equip￾ment to be tested within a representative environment, in order to eval￾uate its performance in a closed-loop scenario with real hardware
equipment.
Therefore, IFT, FAI, and FFT differ from the HIL tests for being tests
performed on the hardware equipment without having a complete
closed-loop scenario. Indeed, in hardware tests rather than HIL, no electrical
ground support equipment (EGSE) simulating the environment and the
plant is involved; therefore, the scope and target of these tests is limited to
hardware functional behavior. As a consequence, HIL tests are necessary
for a wider and more appropriate verification of performance requirements,
as described in the following paragraphs.
In AOCS/GNC applications, HIL tests are used for two main purposes:
verification of sensors or actuators in a closed loop, and, more often, verifi￾cation of GNC software in a closed loop with representative hardware. The
first kind of HIL test is performed with the real sensor or actuator
GNC verification and validation 677engineering model or even flight model and testing its functionalities. Per￾formances and interfaces with the platform and the software running on the
OBC through a closed loop typically composed of the unit itself, the OBC
with the software, power suppliers, and an EGSE to simulate plant dy￾namics, environment, and missing equipment are verified. This kind of
test is performed in order to anticipate the verification of the hardware
and its interfaces with the system and the software, to avoid costly iterations,
since bug-fixing is cheaper, the earlier the bugs are spotted, and thus their
resolution can be applied in the process. On the other hand, the second
kind of HIL refers to a similar setup but used for a different purpose: in
this case, in fact, the unit under test is the GNC software itself, in a closed
loop with the OBC (where the software runs), power suppliers, real hard￾ware sensors, actuators, plant dynamics, and TM/TC interfaces, and of
course appropriate wiring. This kind of test is performed to verify appro￾priate behavior and performance of the GNC algorithms in complete
end-to-end scenarios, typically analyzing all the AOCS modes and stimu￾lating every possible transition between them. Therefore, for HIL related
to hardware verification, the added value respect to the previous verification
(MIL, SIL, and PIL) can be found in verifying the correctness of interfaces
between the hardware under test and the system being simulated, including
the software interfaces for complex equipment such as star trackers or GNSS
receivers, i.e., the ability of the platform software to correctly command the
equipment and retrieve its telemetry, and sensors or actuators performances.
For the HIL aimed at verifying the GNC software, the added value relies in
the verification of complete scenarios in a flight-like configuration that in￾cludes different features not present at model-level (run of the flight code on
real OBC, integration with the system software, compiling, .) nor at SIL/
PIL level (interface with real, representative hardware, integration with the
system software, dynamic scenarios instead of predefined input/outputs).
From the description provided so far, it should result clear that HIL
testing is performed in real time, so that operations are executed or simulated
in scenarios as close as possible to reality. Therefore, such a test becomes
implicitly a verification of the correct execution timing of the tasks of all
the equipment involved with its relevant software.
Examples of HIL testing for hardware verification
As mentioned, HIL test is used for equipment performance and interface
verification to anticipate every possible aspect of the verification cycle that
678 Francesco Pace et al.can cause impactful issues in the project. As an example of a GNC verifica￾tion framework, one common HIL test is the performance test of GNSS re￾ceivers with a GNSS constellation simulators. The test setup, thought here
for an Engineering Model, is depicted in Fig. 12.8: the Telemetry and Tele￾command (TMTC) line of the receiver is connected to the OBC, where the
spacecraft software runs, and the power line is connected to a common lab￾oratory power supplier. The constellation simulator is connected through
RF to the receiver; therefore, the antenna is by-passed, but this typically
doesn’t prevent the test to be representative, since antennas are passive com￾ponents; the OBC is connected to a TMTC EGSE that permits to send tele￾commands to the system and retrieve telemetries, constituting therefore the
ManeMachine Interface (MMI).
In this case, a predefined scenario is loaded into the constellation simu￾lator, indicating the position in orbit of the spacecraft and its attitude during
time, so that realistic visibility of the antennas toward GNSS spacecrafts can
be simulated. At the end of the simulation, it will be easy to compare the
true orbital position of the spacecraft (i.e., the one loaded in the scenario)
versus the estimated one by the GNSS receiver, available as telemetry
through the OBC. Therefore, this kind of test is extremely useful to evaluate
actual performance of the GNSS receiver in realistic scenario and is
frequently used by GNSS receiver producers to verify the performance of
their product during the qualification campaign.
Another typical HIL test is the verification of the star tracker in the loop:
in this case, a simulator is needed, in order to represent the stars in the sky as
can be seen by the star tracker field of view. With this setup, it is possible to
Figure 12.8 Example GNSS receivers HIL test set-up.
GNC verification and validation 679conduct open-loop tests, or, if the star simulator is dynamic, even closed￾loop tests but with predefined scenarios (predefined attitudes vs. time).
For more complex and more exhaustive tests, an AOCS Special Check￾Out Equipment (SCOE) capable of simulating the dynamics of the satellite
should be included in the loop, so that complete end-to-end scenarios could
be simulated, involving a dynamically evolving scenario according to the
control action, where the star tracker EGSE takes the “real” quaternion
simulated by the AOCS SCOE dynamics model and convert it into a video
of the stars in the sky to be perceived by the star tracker itself, that will pro￾vide, in this way, an attitude solution as though it was in orbit in flight
conditions.
Examples of HIL testing for software verification
A typical setup to verify the GNC software is shown in the schematics in
Fig. 12.9: the GNC software runs on the OBC that is connected to real sen￾sors and actuators (or only some of them) providing control commands to
actuators and receiving sensors measurements and telemetries, and to the
TMTC EGSE through which the test conductor can send telecommands
to the software and retrieve telemetries. A power supplier and appropriate
wiring complete the setup.
Figure 12.9 Example GNC software HIL test set-up.
680 Francesco Pace et al.For this architecture, spacecraft dynamics, the environment, and sensors
and actuators interfaces are carefully modeled to allow representative closed￾loop simulations. In details, the main blocks are:
• The software simulation part, composed of the DKE models, and sensors
and actuators models of the ones that are not interfaced at hardware level
with the GNC software. The dynamics and kinematics represent the
plant behavior of the spacecraft in terms of attitude motion and linear
motion, while the environment models represent Earth gravity model,
Sun and Moon position propagation, the action of disturbances such as
atmospheric drag, solar pressure, magnetic interferences, occultation of
sensors field of view, etc. On the other hand, sensors models are aimed
to reproduce the realistic behavior of boarded sensors for which the hard￾ware is not connected to the OBC (see Chapter 7 - Actuators). Similarly,
actuators models represent how the real actuators treat the command sig￾nals to provide a final control action acting on the plant dynamics, thus
including, for example, in the case of a reaction wheel, jitter, ripple, fric￾tion, stiction, etc. (see Chapter 7 - Actuators).
• The hardware interface part manages the signals frequency, since the
models in the software simulation part can run at whichever frequency
is desired, but then a real-time conversion is needed. This is done for
all the sensor/actuators for which the hardware is not connected to the
OBC. Then, the software signals of sensors and actuators models are
transformed in their equivalent physical signal sent to the proper elec￾trical connector in order to allow a flight-like connection between the
OBC and the equipment. In the case of sensors, signals will be sent from
the hardware interface to the OBC, while in the case of actuators,
command signals from the OBC will be retrieved by the hardware
interface to be used for impacting the plant dynamics. In this phase, also
the proper telecommunication protocol is simulated in order to feed the
flight software of the spacecraft with signals as realistic as possible.
• Real hardware sensor and actuators are used to stimulate the GNC soft￾ware with representative signals and commands. In this case, the hard￾ware interface is not needed since the real hardware is directly used
and interfaced with the OBC.
• The MMI, that is the graphic interface, visible on the screen of a com￾puter, through which the test conductor can command initial conditions
for the simulation, equipment switch on and off, adjust parameters, and
see in real time the behavior of the simulated spacecraft in terms of atti￾tude, angular rate, orbital position and velocity, etc., and the answer of
the sensors. Moreover, a log of data is typically allowed for
postprocessing.
GNC verification and validation 681This test setup is extremely useful for the verification of GNC software
on-ground, since complete end-to-end scenarios, including real hardware,
can be simulated. Therefore, it is possible to verify the behavior of the
GNC software in complete nominal and operative scenarios, in safe
mode, the detumbling after release from launcher, and all the transitions be￾tween the different modes. Moreover, all the FDIR transitions can be tested
if appropriate triggering of the events is possible between the OBC and the
DKE. Indeed, the DKE can be required to include equipment complete fail￾ures or even signal conditioning features in order to perform error injections,
therefore triggering data validation algorithms or higher level FDIR func￾tions (see Chapter 11 - FDIR development approaches in space systems).
It is well known that sometimes the interaction between the GNC soft￾ware and the system software can be tricky: extensive documentation and
proficient teams’ involvement could be not enough to ensure the correct
functioning of all the aspects in the most exotic, unlikely cases. Thus, it is
of utmost importance to test the correct integration of the GNC software
with the system software to ensure adequate working of all the functions
in all the scenarios, and this can be easily done in this test set-up, since
the flight software runs on the OBC, therefore involving the integrated
version of the system software and GNC software.
In-orbit test
IOT involves the complete mission system, including the spacecraft
flight model, with the aim to verify correct high-level, in-orbit functional￾ities, performances, and operations of the system. It is generally divided into:
• Satellite commissioning. To verify the functionality of the space segment,
i.e., the platform and the payload. This includes the Launch and Early
Operation (LEOP) phase, where nominal functionalities of all the sub￾systems are checked; once the LEOP is concluded, also the redundant
equipment functionalities are checked and the expected performance
deeply verified.
• Cal-Val. To calibrate and validate the payload and its products, typically
ending with a geometrical calibration, that for LEO Earth observation
mission can be respect to ground targets (ground control points).
• End-to-end verification. To validate the system performance, i.e.,
including the ground segment. Therefore, in this phase, the complete
system chain is verified, from user submission request, handling, planning
of operations, acquisitions, downloading and processing up to the level of
products required.
682 Francesco Pace et al.The GNC subsystem is mainly involved in the first part of the IOT but
plays an important role also for the Cal-Val. During the satellite commis￾sioning, all GNC equipment are verified again to assess their operability
and performance in the real flight environment. GNC software should
not experience major “environmental” differences from the tests performed
on-ground with a GNC/AOCS SCOE, since from the software point of
view, a simulated environment makes no difference to the real one (if the
simulation is appropriate).
During the IOT stage, some high-level requirements are verified, that it
was not possible to verify before: indeed, there are cases for which an appro￾priate ground testing is simply not possible, or sometimes too expensive, so
appropriate analysis is performed to demonstrate the GNC design complies
to the requirements, but actual, complete verification can be carried out
only once the spacecraft is in orbit. It is the case, for example, of the evalu￾ation of the pointing performance of the satellite, that is mostly a system per￾formance verification rather than an AOCS one, but it is out of doubt that
AOCS plays a fundamental role in achieving the final result through its com￾plete design since the very beginning of a project, being attitude pointing
performance one of the major design drivers obviously. Another typical
case is orbit control performance: typically, a maximum deviation from
the reference orbit is specified, or sometimes the maximum deviation of
the ground track with respect to its nominal reference. Analyses are carried
out throughout the development of the project to demonstrate the system is
capable of achieving those performances, but no ground test is possible to
actually verify the compliance to such a requirement. Therefore, the IOT
involving all the orbit control chain is of utmost importance: from ground
control to correctly propagate the real orbit of the satellite in order to
plan the maneuver and to command firing start and duration (if not
computed autonomously on-board), to the real firing of thrusters on￾board the spacecraft impacting satellite dynamics, and to the attitude control
during burns.
References
[1] European Cooperation for Space Standardization (ECSS), ECSS system: glossary of
terms, Technical Reports (2012). ECSS-S-ST-00-01C.
[2] European Cooperation for Space Standardization (ECSS), Satellite attitude and orbit
control system (AOCS) requirements, Technical Reports (2013). ECSS-E-ST-60-
30C.
[3] European Cooperation for Space Standardization (ECSS), Control performance
guidelines, Technical Reports (2010). ECSS-E-HB-60-10A.
GNC verification and validation 683[4] European Cooperation for Space Standardization (ECSS), ESA pointing error engi￾neering handbook, Handbook, Technical Reports (2011). ESSB-HB-E-003.
[5] A. PACKARD, J. DOYLE, The complex structured singular value, Automatica 29 (1)
(1993) 71e109.
[6] A. Megretski, A. Rantzer, System analysis via integral quadratic constraints, IEEE
Transactions on Automatic Control 42 (6) (1997) 819e830.
[7] C.L. Foster, M.L. Tinker, G.S. Nurre, W.A. Till, Solar-array-induced disturbance of
the Hubble space telescope pointing system, Journal of Spacecraft and Rockets 32 (4)
(1995) 634e644.
[8] J.M. Hanson, B.B. Beard, Applying Monte Carlo simulation to launch vehicle design
and requirements verification, Journal of Spacecraft and Rockets 49 (1) (2012)
136e144.
[9] J.M. Hanson, B.B. Beard, NASA TP-2010-216447, 2010. http://ntrs.nasa.gov/
archive/nasa/casi.ntrs.nasa.gov/20100038453_2010042045.pdf. Accessed 04 Aug
2022.
[10] European Cooperation for Space Standardization (ECSS), Software, Technical Re￾ports (2009). ECSS-E-ST-40C.
[11] https://www.mathworks.com/help/sldrt/ug/tune-block-parameters-and-matlab￾variables.html.
[12] https://www.mathworks.com/products/embedded-coder.html.
[13] https://www.mathworks.com/products/simulink-check.html.
[14] https://www.mathworks.com/help/simulink/ug/select-and-run-model-advisor￾checks.html.
[15] R. Bagnara, A. Bagnara, P.M. Hill, The MISRA C coding standard and its role in the
development and analysis of safety-and security-critical embedded software, in: Inter￾national Static Analysis Symposium, Springer, Cham, August 2018, pp. 5e23.
[16] MathWorks Automotive Advisory Board Guide, Controller Style Guidelines for Pro￾duction Intent Using MATLAB, Simulink and Stateflow, Version 1.00, MathWorks,
April 2001.
[17] https://www.rtems.org/.
684 Francesco Pace et al.CHAPTER THIRTEEN
On-board implementation
David Gonzalez-Arjona1
, Vincenzo Pesce2
, Andrea Colagrossi3
,
Stefano Silvestrini3
1
GMV Aerospace & Defence, Madrid, Spain
2
Airbus D&S Advanced Studies, Toulouse, France
3
Politecnico di Milano, Milan, Italy
This chapter presents an overview of the possible on-board architectures for
guidance, navigation, and control (GNC) algorithms. First, the most impor￾tant avionics alternatives for on-board spacecraft implementation are intro￾duced. General processors, digital signal processors (DSPs), graphical
processing unit (GPU), field programmable gate array (FPGA) and their his￾torical background, application-specific integrated circuit (ASIC), and
system-on-chip (SoC) are described, highlighting strengths and weaknesses
of each alternative. A detailed discussion on alternative accommodations of
the GNC functions into the on-board software (SW) is presented, making
use of practical examples. Finally, different architectures for on-board imple￾mentation are discussed and the main verification techniques for on-board
solutions are presented.
The content of this chapter is structured as follows:
• Spacecraft avionics. This section introduces the main alternatives for space￾craft avionics. Different components for on-board implementation are
critically detailed.
• On-board processing avionics. In this section, the most relevant components,
specific for on-board implementation are presented. Alternative ac￾commodations of the GNC functions into the on-board SW are
discussed.
• On-board implementation alternatives. This section summarizes and high￾lights the most relevant architectural alternatives beyond the central pro￾cessing unit (CPU)-based approach, including hardware (HW)
accelerators.
• On-board implementation and verification. In this section, the main steps to
verify the on-board implementation are discussed. Profiling, technical
budgets, and schedulability analysis are presented along with others
verification steps.
Modern Spacecraft Guidance, Navigation, and Control
ISBN: 978-0-323-90916-7
https://doi.org/10.1016/B978-0-323-90916-7.00013-5
© 2023 Elsevier Inc.
All rights reserved. 685 jSpacecraft avionics
As current and future space exploration missions are getting bolder, so
do the requirements on the GNC algorithms and subsequently on their on￾board implementation in the avionics modules and on the associated data in￾terfaces. The avionics used in spacecraft and satellites are based on multiple
subsystems, such as thermal control electronics, electrical power, mecha￾nisms, telecommunication, attitude and orbit control, central processor,
on-board data handling (DH), etc., all interconnected with on-board buses
and networks. Placed within this high-level on-board system architecture,
the “high-performance computing” subsystem will be of utmost importance
for certain future space missions such as active debris removal, target bodies
approach, descent and landing or rendezvous applications, just to name
some. Such a subsystem must process in real time the inputs coming from
the sensors of the spacecraft by utilizing dedicated “payload SW or HW”
units. The future of on-board computers (OBCs) can benefit a lot by study￾ing and developing high-performance solutions to support advanced and
complex GNC of the spacecraft.
Considering the whole GNC chain, navigation is certainly the most
demanding element in terms of computational resources. This is especially
true if complex sensor modeling (e.g., image processing, light detection
and ranging [LIDAR] processing) is involved. For this reason, the HW of
navigation processor or coprocessor should be carefully selected. Different
options exist and they may appear under different names, sometimes using
proprietary nomenclature being developed by certain companies, but, in
general, we can gather the processing devices in four big technologies: gen￾eral purpose processors/microcontrollers, DSPs, GPUs, FPGA, or specific ad
hoc electronic circuit. Among other technologies that will be partially
covered by the above general classification, we might find other HW func￾tions specialized such as video processing units, image signal processor, arti￾ficial intelligence (AI) engines, neural processing unit, programmable logic
device, tensor processing unit, etc. These specialized options are not pre￾sented in detail in this chapter, but it is important to underline that they
are feasible options that can be analyzed for specific coprocessing tasks.
Furthermore, we will not cover either the processing functions that are
not implemented as HW devices, such as emulators, simulators, virtual ma￾chines, interpreters, or other virtual processing functions. Fig. 13.1 summa￾rizes the main HW processor/coprocessor options that are detailed in the
following paragraphs.
686 David Gonzalez-Arjona et al.General-purpose processor or microcontroller
A processor is a predefined chip architecture that executes sequentially a
program that is defined by SW sentences. It is the most common approach
and is well known to the public, as they are core part of computers or mobile
phones as one of the best examples. The processor HW includes arithmetic
units, internal registers, buses, memory access, and different execution pipe￾line steps fixed and standardized for each defined processor architecture and
version. The engineer programs the SW sentences using a fixed and standard
predefined set of instructions. Different SW abstraction languages can be
used to create the programs to be executed in the HW processor. An SW
compiler is used to translate higher-level SW languages into the low-level
set of instructions accepted by the processor/microcontroller HW architec￾ture pipeline. An operating system might be used to govern the processor
Figure 13.1 Different general on-board processing architecture options.
On-board implementation 687behavior and configure the different peripheral HW that might connect to
the processor to extend functions or memory capabilities. It is not needed to
count on an operating system though to execute a program. When no oper￾ating system is used, we refer to bare metal application SW. An operating
system might be general purpose or specific, and among some of the specific
versions, it is very important to highlight the real-time operating systems that
are used for critical operations such as the GNC functions for a spacecraft,
satellite, or, back on Earth, for automotive. A real-time operating system
will ensure that different tasks of the SW to execute, being part of the
same application or different ones, will always consume a known amount
of time or the task will be canceled if the time is exceeded. This is done
to manage other tasks which criticality (or due to engineer decision) might
not wait. The architecture of a processor defines the number of execution
steps of the HW units, the communication buses, the data-word widths,
and the memory accesses among others. We might find multiprocessor
and multicore versions. A dual-core, quad-core or generally multicore op￾tions are those that incorporates more than one identical HW central pro￾cessing block in the processor. Each core will nominally count on their
specific low-level random access memory (RAM) level 1 (with the level
defining memory hierarchy), dedicated to the core, but may share RAM
level 2 or 3 with the rest of the cores. A multiprocessor, as the name indi￾cates, consists of different processors (multicore or unicore) interconnected
by communication buses and sharing some higher-level resources such as
peripherals of memory RAM of level 2, 3, or beyond. The general￾purpose processor counts with powerful and precise floating-point opera￾tion units for complex mathematical operations at high-bit resolution.
The general-purpose processor or microcontroller unit (MCU) is usually
the “brain” core part of the mission on-board system (on-board SW
[OBSW], DH, command and control) and will execute GNC or attitude
and orbit control system (AOCS) as an application software.
Digital signal processor
DSP is a microprocessor specifically designed to process digital signals. Dig￾ital signal applications require real-time data processing over an input stream
of digital values (or previously digitalized from an analog signal). The data
nature is based on signals such as video, audio, images, or global navigation
satellite system signals, which may require complex or time-consuming
mathematical operations. A DSP, being more specific than a general￾688 David Gonzalez-Arjona et al.purpose processor allows some of these complex mathematical operations
in one clock cycle, and, as an example, it is very common to execute
multiply-add-accumulate operations, in one clock cycle allowing much
faster execution times than a normal processor. DSP can be used for math￾ematical operations without a physical digital signal being processed but just
an algorithmic solution. However, most of the processing advantage is
gained, thanks to the processing in streaming. Therefore, if the functions
include many branch-decision statement, the DSP is not really providing
any acceleration advantage and will in fact not facilitate function control
in the same way a processor can do. The DSP can be used as main processor
of the avionics architecture, but it would eventually be more devoted as a
coprocessor implementing functions such as convolutions, correlations, fil￾ters, downsamplings, or discrete transformations. A DSP board may include
more than one DSP core, interconnected by means of function control logic
and memory accesses, like the network-on-chip architecture. To program
the DSP functions, a dedicated library of functions in SW is used, potentially
as an extension of known processor SW languages such as C.
Graphical processing unit
GPU is another microprocessor specialization, in this case fully devoted to
image and video processing, providing multiple processing elements
(arithmetic-logic unit) managed by an execution unit and connecting to
memory blocks independently and with the capacity to be parallelizable.
The programming of GPU nodes execution is made in specific SW language
(CUDA is a well-known example) and combines set of data plus instruction
in the same statement or execution thread rather than a separation of pro￾cessing instruction that will use data from other sources. This is one of the
programming differences versus a general-purpose processor. Counting
with multiple processing units and data channels, it allows complex opera￾tions over vast amount of data as it is a video engine in a very fast response
compared to normal processors. The drawback comes on the power con￾sumption that is also much higher than general processors.
Field programmable gate array
FPGA is an embedded chip, a digital processing component that provides an
HW architecture that can be programmed to describe a specific HW
component. An FPGA is a programmable and reconfigurable HW device
for implementing digital systems, from low-level components to complete
On-board implementation 689SoC and board-level designs. The FPGA is an HW matrix of logic gates
implementing different functions that can be interconnected selecting
different routes that are programmable. An FPGA developer will: “Program
the physical HW of the device rather than write SW to run on a predefined HW (pro￾cessor, DSP, or another device).” When programming an FPGA, you have to
abandon all preconceived notion of a sequential SW and think in terms of a
digital and parallelizable paradigm. As already described, general-purpose
processors, embedded processors, GPUs, and DSPs are a fixed HW compo￾nent where a dedicated SW is programmed and executed in the HW,
following a set of rules to exploit the available HW and the fixed function￾ality it can provide. In an FPGA, the HW component itself is programmed,
as well as the digital functions you want your HW will have, and the inter￾connections and processing rules are created. In other words, a general￾purpose processor can be programmed with the desired functions and rules.
Similarly, a GPU or a DSP can be programmed, and you can also create an
HW component in the FPGA that afterward can execute SW created by
others. FPGAs are sometimes also used in the development process of device
prototype. This is done before manufacturing the final fixed design to create
an ASIC of a processor component. Some FPGA technology can be reprog￾rammed many times while an ASIC is fixed and cannot. The different FPGA
technologies include flash-based FPGAs, antifuse, and SRAM-based
FPGAs. Antifuse FPGAs are one-time programmable devices. SRAM￾based are fully reprogrammable and flash-based might be reprogrammable
up to a number of times. Flash-based FPGAs are nonvolatile devices that
retain the programmed HW functionality even if reset or power cycled,
while for SRAM-based FPGA, the configured functionality should be pro￾grammed each time a reset or power-off/on happens as it is based on volatile
technology. To program FPGAs, it is used a hardware description language
(HDL), which resembles to a SW but with key differences. In fact, an HDL
describes HW using SW-like coding, but FPGA programming involves ar￾chitecture definition, functionality definition, and physical constraints,
including timing, routing, input/output interfaces, pin-out of the chip to
specific parts of the defined function, interconnection of embedded HW
blocks in the FPGA logic, and even voltage-level decisions or pull-up/
pull-down configuration of pins. The FPGA programming allows imple￾menting different functions that will work in parallel, either if they interact
among them or not. The functions can be implemented in a pipeline of
interconnected parallel partial executions of functions. The FPGA is nor￾mally used as coprocessors to accelerate certain functions or to implement
690 David Gonzalez-Arjona et al.fault-tolerant softcore general-purpose processors in their logic such as Leon
processors, RISC-V, Microblaze, or NIOS to name some.
FPGAs in space: history, present, and future
A review of the utilization of FPGA in space segment is crucial to understand
the flight heritage and the target applications in the past, in the present, and
the evolution toward the future. One of the most adopted FPGA technol￾ogies in space satellites and missions is the FPGA by Microsemi. Their anti￾fuse technology (as well as previous other FPGA on-time programmable
solutions) allowed for a technological step forward in the utilization of
FPGAs in space. Microsemi [1] FPGA portfolio for space includes antifuse
RTXS-SU and RTAX series, flash-based rad-tol RT ProASIC3, and the
larger device RTG4 and has a new product for high performance such as
the RT PolarFire. RTSX-SU has flight heritage since 2005 in missions
such as the Mars Reconnaissance Orbiter. RTAX are widely used in
many missions, with flight heritage since 2007 in missions such as the
Mars Science Lab Curiosity rover. RT-ProASIC3 has flight heritage since
2013, being the first flash-based RT FPGA in space, in missions such as
NASA IRIS. Other missions using RTSX-SU include GPS 2R-M Pro￾gram, New Horizons, SAR-Lupe 1 and 2, Galileo GIOVE-A, and TerrSar
X. RTAX-S is on-board COSMO SkyMed 1 and Mars Phoenix.
Many FPGAs are used for mass memory controller and implementation
of interfaces protocols with a good example of the many implementations of
SpaceWire links and SpaceWire routers in FPGA [2]. Exomars 2022 OBC1
[3] includes two (four due to redundancy) RTAX2000S for Interface,
Reconfiguration, and Memory Module, including Mass Memory control.
The ESA-OBC1 manages the whole ExoMars 2022 mission during Cruise,
EDL, and Mars Surface Operation phases running the whole Mission Soft￾ware [4]. Utilization of Microsemi for relatively large capacity and high￾performance needs involves the utilization of the latest devices such as the
RTG4 that is a flash-based FPGA with reconfiguration capabilities up to a
certain number of cycles (w300). Being relatively new component, there
is not enough information on flight heritage at the time of the elaboration
of this book. It is being incorporated though in different on-going missions
such as in ESA mission HERA being interfaces and spacewire router
controller of the main OBC avionics or in the RVS3000-3D [5e9] pose
estimation high-performance in-orbit computing platform that includes
LIDAR and image processing into a single box including the RTG4 as
On-board implementation 691the main processing device to cope with LIDAR data extraction and algo￾rithms execution using it. This single box is a solution for real-time calcula￾tion of 6DOF information with the application of iterative closest point
algorithm and including matching between LIDAR scans and target CAD
model.
Xilinx devices provide an alternative for space usage, implementing
SRAM-based FPGA technology. In the Venus Express Monitoring Camera
(VMC) and the Dawn Framing Camera [6], the Xilinx FPGAs were used for
image-data compression. Virtex4QV is used for Data Processing Unit
(DPU) functions such as the implementation of a LEON2 processor core
running the RTEMS RTOS and application-specific coprocessor for image
processing. The Framing Camera DPU is based on a similar FPGA-based
DPU designed for the ESA’s VMC. In the ESA’s Solar Orbiter, multipro￾cessor architecture is implemented for high-performance floating-point
computations in the PHI instrument [7] for scientific analysis using single in￾struction, multiple data (SIMD) architecture as an accelerator within its
DPU. This DPU is based on LEON processor and two Xilinx
XQR4VSX55 to execute RTE inversion.
Xilinx FPGAs have leveraged the FPGA utilization from performing a
predominantly flight ASIC prototyping role to being designed into and
flown in projects like the Mars lander and rovers [10]. Xilinx rad-tol or
rad-hard (RH) FPGA based on SRAM technology might be more suscep￾tible to single-event upsets (SEUs) but are the key devices to include HW￾acceleration capabilities for high-performance applications to cope with
high frequency of operation requirements.
Recently, in the Mars2020 rover (Perseverance), NASA includes HW￾accelerator board in the Vision Compute Element [11], including the
Virtex5-QV as the Computer Vision Accelerator Card to aid in landing nav￾igation and autonomous driving on the Martian surface executing accelera￾tion part implementing certain stereo and visual tasks such as image
rectification, filtering, detection, and matching. It is necessary for the core
execution of the Terrain-Relative Navigation and the Lander Vision System
comparing on-board pregenerated map with the captured images of the
landing site during descent to compute relative position of rover to ground.
In the latest years, there is a new vendor that is fully dedicated to the
development and commercialization of space RH FPGA in Europe, the
company NanoXplore from France. Their portfolio offers SRAM-based
fully protected RH FPGA such as NG-MEDIUM, NG-LARGE, NG￾ULTRA, and ULTRA300, being the NG-ULTRA a SoC product
692 David Gonzalez-Arjona et al.embedding the European DAHLIA processor based on quad-core ARM.
This is a very new technology with only some components qualified, as
the case of the NG-MEDIUM and the on-going NG-LARGE and with
yet no flight heritage.
New SRAM-based FPGAs in the market are not always being devel￾oped as a RH technology product by design but as a radiation-tolerance de￾vice taking advantage of the new fabric-nodes capabilities. Therefore, there
is a potential path to flight for commercial FPGA devices that offers future
missions a significant boost in capability compared to existing systems. Kin￾tex Ultrascaleþ, and, in particular, the KU060 is one of those rad-tolerant
devices examples which are being included for different new processing re￾quirements in space domain as a coprocessor suitable for implementing
different high-speed communication protocols based on optical links or
deployment of complex in-flight deep learning solutions as in Ref. [12].
These kinds of devices pave the way in between a full RH chip and the
risk of using a commercial one, as no risk would seem considered for critical
operations. More examples for this kind of “New Space” approach for on￾boarding FPGAs which are not fully or none RH protected can be found in
Ref. [13] where missions using CubeSat, mostly for low Earth orbit (LEO)
noncritical operations, benefit from the utilization of SoC FPGA-based
computers which are not available yet in RH technologies.
Application-specific integrated circuit
ASIC is a dedicated HW design that, using building blocks or HW submod￾ules, reproduces a particular HW function in an integrated semiconductor.
The final outcome is a specific HW chip. A general-purpose processor is, in
reality, an ASIC. The goal of ASIC production is the creation of the proces￾sor chip itself and not the programming of a function that would execute in
that processor later. The ASIC does not exist before the HW functions we
want to implement are designed, being more specific than an FPGA. The
FPGA HW itself exists, it provides matrix of interconnectable logic gates,
and we design and program how to use the FPGA general HW to create
specific HW functions. In the case of an ASIC, there is no programmable
HW because there is, in fact, no HW. The engineers define what that
HW will be (e.g., a processor, an FPGA, a DSP, or power control regulator).
Understanding the application-specific concept, the reader must then realize
also another big difference with FPGA technologies which is that FPGA
might be reprogrammable, and ASIC will not.
On-board implementation 693System-on-chip
In the last years, the combined use of SoC-integrated HW processing solu￾tions is gaining more and more relevance. SoC combines most of the advan￾tages described above in the other processing options by integrating multiple
HW parts into a single device (e.g., Processor plus FPGA or DSP). Simply
integrating the processor and FPGA components into a single SoC FPGA
potentially reduces system power by 10% to 30%. The Inputs/Outputs (I/
Os) that carry the signals between devices, often at higher voltages, are
one of the most power-hungry functions in an application. Therefore, the
SoC architecture provides fast intrachip communication between all HW
components and low power/size. By relying on tightly coupled accelerators,
peripherals, and processors, the engineers can develop efficient HW/SW
coprocessing solutions for a variety of signal processing and GNC tech￾niques. This SoC solution increases the flexibility during implementation,
but the HW production into space format is more challenging than sepa￾rated options. In principle, the SoC architecture can support all kinds of ac￾celerators, including FPGA, DSP, GPU, or even multicore. Overall,
implementing sophisticated GNC (moreover if involves AI or computer
vision algorithms) on embedded platforms, regardless of their FPGA- or
GPU- or DSP-based HW, is a very challenging task. Porting or designing
the entire algorithm on an accelerator (especially FPGA or GPU) is neither
efficient nor feasible (in a reasonable amount of development time). In
particular, a small part of the algorithm pertains to infrequent high-level de￾cision/control operations and complicated sequential functions, which are
not worth accelerating. These parts are better to be executed on a low￾power general purpose processor, which moreover, increases the flexibility
of the design both at run-time and design-time. Therefore, the potential to
combine the strengths of dedicated HW accelerators with flexible general￾purpose processor is the main reason of today’s trend to use embedded SoC
technologies.
On-board processing avionics
Electronic components and spacecraft avionics need special protection
when exposed to the harsh space environment. In particular, processors for
space are required to be tolerant to radiation and environmental effects such
as total ionizing dose (TID), latch-up events, SEU, single-event transient,
single-event functional interrupt, and temperature cycles. As an example,
694 David Gonzalez-Arjona et al.tolerance to radiation TID should be 100e300 kRad for geostationary orbit
and beyond and 10e50 kRad for some LEO mission. Another reliability
issue is the complete and permanent failure of a processor or a critical sub￾component. The avionics processing shall deal with temporal upset or fail￾ures, avoid propagation of error to other equipment, modules, or system,
and prevent from permanent damages or failures. The problem is that
most of the available avionics processing devices and integrated systems￾on-chip cannot offer high tolerance to environmental conditions (radiation
effects, temperature ranges, pressure, vibration .) and offer high￾performance capabilities at the same time. The space environment and the
mission concepts impose restrictions or difficulties to design an avionics ar￾chitecture or select a processing component to make extensive data process￾ing tasks on-board of a spacecraft considering technology that withstand the
mission’s environment (temperature, vacuum, radiation, and fault￾tolerance). Reliability is a must not only for operations that are critical or
risky but also considering catastrophic failure that would imply the loss of
the component. Contrary to Earth applications (automotive, trains, data
centers, etc.), the component launched into space will, in the majority of
the cases, not be repaired or replaced. Therefore, for all these reasons, the
space-qualified portfolio of high-performance processing solutions is quite
limited, considering real-time critical operations for GNC, DH, OBSW,
communications or for sensor data processing in flight, also including data
compression. Critical autonomous on-board navigation concepts based on
navigation camera images are one of those scenarios that may require consid￾erable on-board avionics processing capabilities. Those solutions, targeting
different navigation scenarios such as descent and landing into small bodies,
satellite servicing, or rendezvous operations, require architectures and pro￾cessing technology above the standard space-qualified processors. The stan￾dard for current missions in Europe is to adopt fault-tolerant space processors
such as the dual-core LEON3 or the quad-core LEON4 for SW solutions.
These processors represent already a big advantage compared to previously
available processors, but they still might require additional and dedicated co￾processors based on large high-performance devices such as dedicated DSPs,
GPUs, SRAM-based FPGAs, or even dedicated ASIC to perform digital
signal processing over acquired images.
In addition to environmental constraints, power consumption is a
limiting factor in space, targeting on-board processors consuming 10e
20 Watts, or up to 50 Watts at the very limit. This restricts also power￾hungry solutions unless strictly necessary. The main design objective is to
On-board implementation 695select processing avionics technology offering a good trade-off of perfor￾mance per Watt with adequate processing architecture.
Historically, the majority of space missions have relied on rad-tolerant
and RH IBM PowerPC and Gaisler LEON CPUs. They can be imple￾mented either as softcores (e.g., in an FPGA) or as hard intellectual property
on ASIC. Due to their subpar processing speed, softcores can only serve as a
secondary solution for HW/SW codesign.
Space processors can be divided into commercial off-the-shelf rugged￾ized, fabricated on dedicated RH processes, and the ones that are radiation
hardened by design (RHBD), i.e., RH is achieved by design techniques in
the layout, circuit, logic, and architecture areas, designed as ASIC and fabri￾cated on commercial complementary metal oxide semiconductor (CMOS)
processes. Most RHBD processors are based on the success for European
LEON processor architecture. During the last years, the evolution is drasti￾cally oriented toward providing better performances, including other archi￾tectures such as ARM or RISC-V processors. Lately, one of the most
interesting concepts is the use of SoC or heterogeneous processing platforms
including different processing technologies such as multicore processors
combined with FPGA, GPU, or dedicated HW engines floating-point units
(FPUs), SIMD, or even AI-dedicated blocks.
New concepts and new versions of onboard processors for space applica￾tion are continuously being developed, and only the most important ones
are collected into a not exhaustive list that, however, will give the reader in￾formation about producers and specific products:
• SPARC V7 ERC32 and TSC695Fl. Made by Atmel in France, origi￾nally a three-chip set, it is now a single chip CPU. It has been used in
many satellites and systems in Europe and elsewhere. It achieves 12
MIPS/6 MFLOPS at very low power (0.3W for the core excluding
I/O). It has been used by several companies to develop their dedicated
single-board computers.
• Atmel LEON2 AT697. It provides a major step forward from the
SPARC V7 processor. It is a LEON2 SPARC V8 processor based on
IP core provided by Aeroflex Gaisler. The chip includes the processor,
memory interface, and a PCI interface and executes at 70e80 MHz.
Several LEON3-based SoC have been developed recently by different
companies and with different design architectures.
• LEON4. It can be utilized in both asymmetric multiprocessing and sym￾metric multiprocessing (SMP) configurations. A typical four-processor
system implemented as a 65 nm ASIC is targeted to be capable of
696 David Gonzalez-Arjona et al.delivering up to 4300 Dhrystone MIPS at 800 MHz. The processor
provides HW support for cache coherency, processor enumeration, and
SMP interrupt steering.
Accommodation of GNC functions into the on-board SW
The avionics architecture distinguishes different SW process agents in the ac￾commodation of the GNC system: central OBSW, DH SW, GNC or
AOCS functions, sensor management, Telemetry and Telecommand
(TMTC), and security functions. In terms of HW avionics trade-off, one
first architectural decision is on the deployment of the GNC functions,
combined into the instantiation of OBSW and Navigation (GNC) in
different processors or in one unique single processor with both
functionalities.
There are several deployment options, but the trade-off is restricted at
functional level on the following two options as in Fig. 13.2.
• Option A. OBC SW and DH in dedicated processor and GNC offloaded
in a coprocessor. The selection of the instantiation of the OBC tasks and
system DH is running on a dedicated processor that might be simpler
while the GNC runs in a dedicated coprocessor device with better
performances.
• Option B. OBC, DH, and GNC are deployed into a unique processing
system.
The two architectures offer advantages and drawbacks, and the choice
must consider the mission needs. In fact, with only one processor as in Op￾tion B, there is a risk of overloading the processor with all the SW tasks, and
due to the high criticality of OBC tasks, there is a risk of not isolating GNC
functions so to lose execution step processes, or image frames in case of
Figure 13.2 Example of processors identification for OBC and GNC functions.
On-board implementation 697optical navigation. The Option B could count on a powerful single-core or
multicore processor gathering all the platform SW functionalities including
OBC, DH, and GNC. Moreover, it can simplify architectural number of el￾ements, considering that the SW tasks need CPU load enough for both
OBC and GNC executions. The problematic part still remains in the isola￾tion of critical functions. A safe solution is to isolate the OBC and DH func￾tion from the GNC concept, as in Option A. For many missions though, the
performances and CPU load may not be very exigent, and it is not necessary
a powerful processor to reach the performance requirements for the OBC
and DH functions. Navigation coprocessor performance requirements are
relaxed in Option A having a dedicated HW.
This is the very general and very first avionics architecture decision, af￾terward, it is needed to explore in more detail the options for a GNC/Nav￾igation coprocessor trade-off and which avionics technology to use. At
system level, the trade-off for the GNC coprocessor might be based on
the combination of different processing technologies as the ones presented
at the beginning of this chapter, processors, DSP, GPU, ASIC, and FPGA.
In the architectural trade-off at technology level, we may concur then
that a good candidate avionics processing solution would be based either
in a microprocessor or a combination of a processor and an HW accelerator.
The trade-off at system level for architecture of the GNC processing avi￾onics would then be based on three configurations as in Fig. 13.3:
• Architecture A. Pure SW solution in space-grade powerful processor
• Architecture B. HW/SW solution in space-grade powerful processor and
high-performance HW accelerator
• Architecture C. HW/SW solution integrated chip including space-grade
HW accelerator þ processor embedded hard IPs
Let’s analyze this example as a potential exercise for the architectural de￾cisions for the GNC accommodation into a specific on-board implementa￾tion to satisfy the mission requirements in terms of real-time capabilities,
operation deadlines, and important technical budgets such as power
consumption:
Figure 13.3 Example of system-level architectures.
698 David Gonzalez-Arjona et al.Architecture A. The Pure SW solution in space-grade powerful processor
has the advantages of including only one device which in terms of power
consumption is potentially consuming less energy than two devices of
equivalent power consumption characteristics. Besides, there is no partition￾ing of task between devices, and hence there is no intercommunication
needed. The disadvantages are that the CPU load will be very high, close
to the 100%, in order to satisfy GNC performances and considering the
available space-grade devices the total system frequency will be lower
than a solution based on a coprocessor offloading consuming tasks. On
top of the performances constrains, if only utilizing one processor, this means
that all the interfaces with the rest of the system will have to be managed in
the processor at the same time of the algorithms execution, and therefore
there is less available CPU load for the algorithms.
Architecture B. HW/SW solution in space-grade powerful processor and
high-performance HW accelerator improves the performances of the pure
SW solution as it offloads algorithm consuming tasks into a dedicated device.
HW acceleration of a coprocessor device is utilized to achieve high￾frequency performances. Moreover, the HW accelerator coprocessor pro￾vides programmable routing which allows flexibility for implementing all
the needed interfaces, communication, and arbiter of data without impact￾ing in the system performance (again offloading the communication part
from the SW processor). In terms of fault-tolerance, the HW accelerator
will be devoted to specific tasks (e.g., image processing) which are time
consuming. Being instantiated in a different device with respect to the nav￾igation filter and other GNC functions, this architecture provides an auto￾matic isolation of functionalities to protect propagation of subsystem
errors into the GNC chain. The main drawback of this configuration is
that power consumption increases compared to the full SW solution as there
are now two elements instead of one.
Finally, the third option is the Architecture C. HW/SW solution inte￾grated chip including space-grade HW accelerator þ processor embedded
hard IPs. This solution provides the best performances as in the Architecture
B with low power consumption and data interchange as in Architecture A.
This solution gets the good points from the two previous options. There is
not yet any space-grade SoC qualified, but there are some in the near future
roadmap considering FPGA accelerators (considering book writing time),
the NG-ULTRA from NanoXplore or the radiation-tolerant RFSoC,
Zynq, or Versal ACAP from Xilinx. The fact of having only one device
is translated into less power consumption that having two separated devices
On-board implementation 699(of similar power consumption footprint) and less data exchange (that sup￾ports again less power consumption). There is still the possibility of HW ac￾celeration to achieve high-frequency performance and offload SW
processor, reduce data management, isolate functions, and provide flexibility
for interfaces.
Besides studying and developing high-performance subsystems, an
important challenge is to connect the new module to the remaining com￾ponents of the avionics architecture. In this direction, the Space AVionics
Open Interface aRchitecture (SAVOIR) initiative studies and analyses the
architecture of space avionics in order to federate the space community to
cooperate and improve the way that they build avionics subsystems. The
output of SAVOIR is a standard for developing avionics and interfaces for
different space missions by considering them as reuseable products and by
adapting to a development-oriented philosophy. It translates into a more
competitive framework for the European community with increased cost￾efficiency and functionality for on-board building blocks.
On-board implementation alternatives
As we have already seen, some architectural alternatives can be iden￾tified beyond the CPU-based approach. In fact, modern advanced image
processing systems and complex GNC algorithms mandate the design of
new generation space avionics to include HW accelerators, e.g., FPGAs,
GPUs, or multicore very long instruction word (VLIW) DSP processors.
On-board implementation alternatives shall look for the proper architecture
selection based on certain assumptions considering previous similar imple￾mentations, state-of-the-art for processing architectures, and mission restric￾tions. The trade-off analysis shall rate different quantitative and qualitative
parameters such as:
• Development cost/time.
• HW cost.
• HW transistor area.
• Overall execution time.
• Overall GNC performances.
• Flexibility and Scalability.
• System mass and power.
• Future roadmap.
The first attempt to address the architecture alternatives investigation
regarding high level avionics architecture is to combine different HW
700 David Gonzalez-Arjona et al.components to grant performances, reliability and functional mapping. In
the previous section, three alternatives were identified considering a generic
HW accelerators. In this section, different architectures alternatives are
detailed considering different HW acceleration alternatives.
Multiple processors
This approach (Fig. 13.4 e left) relies mostly on SW parallelization to accel￾erate performance. Communication between processors could be imple￾mented using message passing or shared memory libraries
depending on the specifics of the interconnection network. Generally,
performance-wise, an architecture based on few processors cannot compete
with platforms that make use of HW-based optimization/customization.
The performance might be limited due to synchronization delays among
processors and due to inherent inefficiencies of the general-purpose pro￾gramming model of each processor. Moreover, it is very important to
note the significantly lower performance of the space-grade processors
compared to commercial ones. As an example, a profiled specific image pro￾cessing C/Cþþ implementations of feature extraction and tracking on a
Leon2 system (50 MHz space-grade processor) using 8-bit 1024  1024
pixel images shows that the performance obtained is w80x lower than a
commercial Intel Pentium 4 at 3.00 GHz (80e150 s vs. 1e2 s per image,
the elapsed time also depends on the utilized FPU).
Processor and multiple DSPs
The performance of the general-purpose processor can be enhanced by
coupling it to a number of DSP cores as in Fig. 13.4 e right. Due to their
SIMD and customized instruction set architecture, the DSP cores are more
efficient than the CPU in digital signal processing, e.g., convolutions on im￾age, in a stream data flow. Generally speaking, if the algorithm to be opti￾mized requires a sample rate below few kilohertz, then a single-channel
implementation with a DSP might be a good choice. However, as sample
Figure 13.4 Multiprocessor (left) and processor with multi-DPS (right) architecture.
On-board implementation 701rates increase beyond a couple of megahertz, or if the system requires more
than a single channel, or the number of DSPs should be proportionally
increased, then such a system might struggle to capture, process, and output
the data due to the many shared resources, buses, and even delays by the
central processor itself.
FPGA
To overcome the performance limitations described above for processors
and DSPs, we can make use of distinguished computational models, like
the FPGA, which is intrinsically even more parallel than the previous solu￾tions. Several possible architectures exist and some of them are presented
here (Fig. 13.5).
Single FPGA
A single FPGA architecture can be employed. In this way, by exploiting a
variety of parallelization and HW design techniques, we can significantly
accelerate the intensive tasks (e.g., image processing algorithms). On the
downside, sequential parts of the algorithm will perform the same or worse
on FPGA than running on a processor. Moreover, we note that the available
FPGA resources are limited, and the floating-point operations might not be
the best fit for FPGAs (in general, the GNC system relies on a certain num￾ber of floating-point operations to achieve the required accuracy). Given
these limitations and the increased development time on FPGAs, building
a complete system might be done more efficiently when combining the
FPGA and the CPU capabilities (parts of the algorithms running on a serial
processor, others designed on FPGA depending on their amenability to HW
acceleration). This solution is particularly suitable if the full system fits in a
single FPGA chip (i.e., CPU plus FPGA logic tightly coupled in the same
chip).
Figure 13.5 FPGA-based architectures.
702 David Gonzalez-Arjona et al.Multi-FPGA
This multi-FPGA design (i.e., 2-FPGAs) is a simple solution to overcome
the limited resources of an FPGA device. Two devices provide more re￾sources to map bigger systems including more complex functions. On the
downside, the interconnection between boards or devices creates new prob￾lems; the speed and reliability of the communication requires considerable
design time, while the cost, size, and power consumption increase
(compared to single-FPGA).
FPGA and hard-IP processor
In this design, we assume two devices, one FPGA and one processor. The
partitioning of the system into SW-based functions (e.g., main flow control)
and FPGA-based functions (e.g., parallelized to achieve faster execution) ac￾cording to multiple design criteria (coming from the specifics of the HW and
the requirements of the application) can bring very good results both in
terms of performance and development cost/time. Data transfer between
HW modules and processor is a very challenging task in this approach.
FPGA including softcore processor
With this solution, where the CPU is implemented as a softcore by using the
FPGA logic, we combine the advantages of a single-device architecture and
the advantages of the CPU-FPGA coprocessing. The main drawback is that
a softcore provides considerably lower performance than an embedded hard
processor (or an ASIC implementation). Additionally, the softcore processor
utilizes a lot of FPGA resources, especially for its FPU, and hence, we limit
even more the space available for implementing accelerators.
FPGA and FPGA including softcore processor
With this double-device approach, we essentially use two FPGAs, one dedi￾cated to accelerators and one to the soft-IP processor. It offers more re￾sources for the HW accelerators; however, it inherits the disadvantages of
the double-FPGA solution described above and the low-performance of
the softcore.
System-on-chip
One of the most promising architectures is represented by the SoC. As
already discussed, it has the advantages of multiple HW architectures but
with fast communications between HW components and low power and
size.
On-board implementation 703FPGA SoC
A SoC including FPGA integrates the SW programmability of a processor
with the HW programmability of an FPGA. Conceptually, the chip is
divided between two areas: the “Programmable/FPGA Logic/Fabric,”
which is equivalent to a conventional FPGA, and the “Processor/Microcon￾troller System,” which includes the CPU and the peripheral units. The hard
IP processor inside the SoC is surrounded by hard IP peripherals, which can
provide low-power and fast-access to the external RAM, storage devices,
communication I/O, and most importantly, to the FPGA logic of the
chip. On the FPGA side, we can implement VHDL/Verilog accelerators
to speed-up intensive algorithms. Hence, the FPGA SoC allows for flexible
and scalable designs with reduced power dissipation and increased
performance.
DSP or GPU SoCs
An SoC can also be constituted by a GPU or DSP, and, in this way, it in￾tegrates the SW programmability of the CPU with the more specialized
SW programmability of a DSP VLIW processor or a GPU. More precisely,
the CPU and its peripherals are connected to a number of “DSP cores” (1 to
8) or smaller “CUDA cores” (e.g., up to 256), all placed within the same
chip. The cores take advantage of their SIMD and/or VLIW architecture
to accelerate the execution of repetitive instructions like those issued
when processing 1D, 2D, or higher dimensionality signals. The CPU and
the acceleration cores (DSP or GPU) are connected to a number of periph￾erals (very similar structure to the one mentioned above for the FPGA SoC),
which include hard IPs for I/O, or even for accelerating common functions
(e.g., image compression) to boost the I/O of the chip at relatively low￾power and high-speed performance. The DSP- and GPU-based SoC rely
on C/Cþþ language to program, which is generally considered easier/faster
than the VHDL programming of an FPGA, however, at the cost of increased
power-performance ratio.
ASIC
ASIC is a dedicated HW design reproducing a particular HW function in an
integrated semiconductor. The main advantages of ASICs versus FPGAs are
speed and power consumption. ASICs offer more opportunities for optimi￾zations on speed and low power consumption techniques. ASICs also allow
implementation of analogue circuits but at the price of high nonrecurring
engineering cost and lack of designing flexibility (increased development
cost, both for SW tools and manufacturing, decreased flexibility in redesign
and implementation phases).
704 David Gonzalez-Arjona et al.ARM-based ASIC CPU
Arm-based ASIC CPU can accommodate FPGAs, and this architectural so￾lution can provide more than 1000 MIPS even with single-core execution.
However, they are still one order of magnitude slower than architectures
including one or more high-performance HW accelerators. Therefore, in
general, high-performance avionics architectures must be designed using
HW accelerators.
On-board implementation and verification
Independently from the on-board avionics HW selected, the actual
on-board implementation shall be based on the SW concept design or the
HW/SW codesign of the different functions of the GNC. These functions
are integrated into the spacecraft (platform bus controller) infrastructure
components considering the OBC, the existing coprocessors, the mission
control system, DH, sensor management functions, and ground station
interfacing.
HW/SW codesign is based on concurrent development approach for
both HW and SW functions at the same time. One of the most important
tasks is the partitioning of the system functions in order to assess the fulfil￾ment of requirements by HW acceleration while maintaining critical
decision-making control in SW.
The programming and documentation standards applicable to the proj￾ect shall be followed during the implementation production phase, starting
from a first review, analysis, and tailoring when needed. Commonly in
Europe, under ESA programs, the applicable standards are the European
Cooperation for Space Standardization (ECSS).
The implementation and verification process will depend on the criti￾cality level evaluated for the subsystem and mission. The ECSS define, for
instance, the SW criticality category A, B, C, or D based on whether a failure
in the module to develop may cause a human death, mission failure, partial
mission failure, system or subsystem failure, and what is the impact of a non￾recoverable failure in the SW if it means losing the mission purposes. High￾est criticalities A or B will involve extra verification and quality assurance/
product assurance activities. One example for high-criticality SW is the
implementation of an independent SW validation and verification campaign
to be performed by a third-party company different than the developer one.
The on-board implementation shall also encompass the following design
decisions beyond the pure GNC functionality and interfaces:
On-board implementation 705• Identify target avionics processing HW for the mission.
• Identify representative developments boards equivalent to the final
selected HW.
• Analysis on the need of processor plus coprocessor architectures (com￾plex functions offload to coprocessor, main functions remain in
processor).
• Identification of coding language (in processor and coprocessor).
• Identification of operating system (commonly real-time operating
system).
• Analysis on the need of SW isolation (TSP techniques for time-space
partitions, hypervisor).
• Schedulability analysis (frequency and latencies for each defined function
tasks, including execution time deadlines).
• Mathematical libraries or other third-party modules to be used (qualified
already is preferred).
• Technical budgets (CPU-load, memory utilization, HW programmable
resources, power consumption).
• Clocking scheme and synchronization of elements (on-board time
propagation).
One of the first implementation tasks for on-board applications is the
feasibility analysis and design of real-time system. The GNC might be
already designed and even a prototype is implemented (for instance, using
mathematical programming languages) defining the needed functionality,
but from that prototype till the current on-board implementation, several
adaptation steps are needed. The final flight SW shall work in a real environ￾ment, considering real HW timing, delays, interlocks, data resources access,
in accordance with the true time (actual time) of real-world events, dy￾namics, and kinematics. It shall also operate to acquire sensor values and
to command actuators to control the spacecraft in the specified and needed
response time.
The implementation onto the target HW platform shall include pure
GNC algorithmic functions and additional functions such as sensors man￾agement, AOCS, TMTC dedicated manager to interface GNC functions,
state machine with operational and nonoperational mission modes for the
GNC SW, data storage manager, interfaces definition with other SW func￾tions or OBSW or external HW units, fault detection, isolation, and recov￾ery (FDIR) function or support to main system FDIR (providing flags or
measurements) and in some cases specific sensor data processing functions.
One example of dedicated sensor data processing function is, for optical
706 David Gonzalez-Arjona et al.navigation solutions, represented by computer-vision algorithms that extract
navigation features from images. This is a nonnegligible complex task that
may require a dedicated SW task and predefined rates, or execution sepa￾rated from main pure GNC navigation filter. Not all these functions may
be present when developing a mathematical model of the GNC function￾ality in tools like Simulink or Matlab but shall be present in the final imple￾mentation onto the selected processing avionics, and they should be
properly designed and orchestrated.
A first SW version of the GNC solution can be prototyped and used in
the SIL test campaign (see Chapter 12 e GNC verification and validation).
This SW version, that may still run in a general-purpose desktop PC or
laptop, is used for profiling analysis. The code is compiled adding different
debugging options that will add profiling instrumentalized code to get
different execution and memory usage figures. On one hand, the code is
used to evaluate the memory needed and the data quantity being inter￾changed (impacting memory access or input/output communication buses
load). Secondly, this code is used to evaluate the performances onto the
selected final flight HW avionics processing system. For example, if the
execution time is violated, then a more powerful device is needed, or it
should be considered to add a coprocessor to offload the processing system.
Matlab or C implementation can be used for profiling. This prototype code
for profiling might serve as the initial version of the final implementation,
some parts would need adaptations, additions, modifications, recoding, or
porting to a different language for HW development or DSP/GPU coding
if a coprocessor is used.
Thanks to the profiling, a more robust decision on the avionics process￾ing elements is taken. On the other hand, it may happen that the avionic
components selection is specified by the client at requirements level, and,
in this case, the task is to design and adapt the GNC solution and implemen￾tation to the requirements, considering the selected platform. In any of the
two scenarios, the flight avionics are identified and a more refined design and
test, in the form of feasibility analysis and schedulability analysis can be per￾formed. In case of implementing the GNC (all or main part) in SW targeting
a space processor, we can extrapolate performances metrics of the prototype
onto the flight computer. From several processors and from what the client
configures of system clocks and CPU load margins, performance values can
be obtained in millions of instructions per second. Dhrystone million in￾structions per second (DMIP) is the Dhrystone benchmarking of various
functionalities executed on the processor to obtain times and give a
On-board implementation 707comparable value. Another benchmark that is beginning to be widely used
is the CoreMark. The advantage of this benchmark is that it produces a
single-number score allowing users to make quick comparisons between
processors. Knowing the performance of the prototype and knowing the
HW performances of the processor used during a test analysis, the developer
can compare the benchmarking figures on two different processors with the
execution time of the prototype code. If, for instance, a test of the prototype
GNC SW on a Leon3 core with a performance of 106 DMIPs and it takes
2 s, it can be extrapolated that on a Leon4 core with a performance of 425
DMIPs and a requirement for 50% of CPU load margin (212 DMIPs equiv￾alent), the time of your code would take about 1 s for that same function.
These numbers are very theoretical and should be used as first rough indi￾cation especially in comparisons of processors with very different architec￾tures (e.g., an Intel OctaCore and an Arduino processors). It should also
be considered if the code is executed on one operating system or another,
due to the overhead it could add. Nevertheless, it can be used as first feasi￾bility analysis that can be used for a schedulability analysis by the SW engi￾neers of the system. If available, an emulator of the target flight processor can
be used to run the application SW instead of the actual processor or a repre￾sentative processor with similar characteristics to derive further analysis.
Another important aspect to consider during on-board avionics verification
and testing is the selection of a proper margin philosophy. This is needed to
ensure more resources and time than currently needed, to still have margin
in case some SW parts are still on-going or new functionalities are included.
The margin philosophy can be applied in SW as a CPU load percentage, as
an execution time percentage penalty, as a memory utilization margin, or as
a communication bus load margin. In HW solutions like FPGA-based, the
margins are applied to the FPGA-utilized resources to implement a function
and clock frequency margin.
A necessary analysis during the validation of on-board avionics is the
schedulability analysis. The schedulability analysis consists of the definition
of each piece of SW task periodicity, latency, and execution time, based
on the real events timing in the environment and in accordance with all
the tasks to be executed in the processor. For each task, a periodicity of
execution time before changing to another task is defined. The functions
of the tasks do not explicitly require executing in one periodicity execution
window; therefore, the task functions can be executed in two time slots,
providing half the full function time (as soon as does not create a misalign￾ment problem or non-atomic execution problem).
708 David Gonzalez-Arjona et al.The proof of the correct behavior and performances of the on-board
implementation is provided, thanks to the Validation and Verification
(V&V) campaign. In this context, we will use the term Validation to identify
tests, analysis, inspection, or review of the implementation with respect to
the requirements. The Verification, instead, is the process to verify and
prove that the results of the SW implementation functions are correct
with respect to the specifications and inputs of the system/subsystem/
module.
The final on-board implementation may follow a dedicated hand￾written coding or techniques for automatic code generation (autocoding)
from an architectural model. For hand-written coding process, a technical
specification should be adopted and followed. Moreover, it is possible and
even convenient to use the architectural or mathematical model prototype
as a reference. For autocoding approach, the original models should be
properly configured or modified with certain restrictions and characteristics
to allow the autocoding for real-time SW solution of critical nature as the
GNC. In both hand-written or autocoding versions, the implementation
shall consider the timing and synchronization mechanism. During this
task, dedicated SW engineers should take the leading role for the coding
of each SW unit, documentation, unitary verification, and build procedures
to compile and link SW units. Once the code is implemented for the first
time into its final version, a first GNC functional verification might be
accomplished, thanks to a processor-in-the-loop (PIL) (see Chapter 12 e
GNC verification and validation) campaign. The PIL verification might
only involve the application SW and a representative processor HW, nor￾mally not yet the final flight HW. Other HW elements such as sensors or
actuators might still not be present in a PIL campaign, and values will be pro￾vided to the processor and the SW functions in the processor, thanks to an
SW simulator or an HW emulator, in a representative equivalent way as if
the actual sensors and actuators were connected. The interface with the
SW simulator or HW emulator might not be the final actual interface
with sensors and actuators, but the data volume and periodicity/latencies
should be the same or representative of the final conditions. PIL campaign
extends pure SIL functional verification including proper management
functions, including timing and performance metrics verification, and func￾tional nominal tests plus robustness cases introducing errors into the system
to verify its response in those conditions, as per the specification defined.
The application SW implementation and its PIL V&V may take into ac￾count the sensor data input volume, the number of sensors interfaced, the
On-board implementation 709frequency of each sensor data transferred, and its communication band￾width. The output of the GNC application SW implemented shall consider
the needed frequency and processing time latency for each epoch time step
of the GNC function execution. The GNC itself might include different
subfunctions that will be organized in the operating system in different tasks
at different frequency. If navigation and control functions are scheduled at
different rates, navigation shall consider output propagation to interface
with the control and vice versa for every execution of the highest frequency
task. If sensor data are not received at navigation and control frequency rate,
again, proper propagation of navigation output shall be considered. A func￾tion to manage potential problems in the SW execution shall be designed
and implemented considering different errors and associated risks during
the code execution and considering HW malfunctioning of the processor,
the OBSW, or the sensors/actuators suite. The OBSW might include this
kind of functions, normally under the FDIR module (see Chapter 11 e
FDIR development approaches in space systems). The GNC application
SW shall either implement total FDIR for GNC or support to central
SW FDIR.
The V&V activities to be performed should follow the agreement and
description provided in a system or SW V&V plans documents. The Valida￾tion task should include a statement of compliance to the technical specifi￾cation and baseline/derived system/subsystem requirements. Proper
identification and traceability of V&V proof shall be documented. The veri￾fication activities shall include internal reviews on technical documents, re￾views on design and code, inspection on received and developed items. The
verification activities in the on-board implementation shall also include
actual testing covering unitary and integration test cases, system test cases,
validation and acceptance test cases, test coverage review, and test results re￾view and analysis.
Test cases shall be determined to cover the compliance to requirements
and specification. The test cases include input data, expected output data,
internal modifications or events triggered, and test procedures. The test cases
shall cover algorithmic functionality and performance metrics. For the
developed SW or FPGA code, the test cases shall also verify the agreed
code coverage percentage (depending on project or agreement with client
it might be 90%, 99.7%, or 100%). For the code coverage, a profiled code
is executed during the test campaigns to prove that every SW or FPGA
code line is executed under the V&V requirements conditions.
710 David Gonzalez-Arjona et al.The unit testing is the execution of test cases to validate isolated and in￾dividual pieces of SW code, functions, or subsystem. It may include white
box and black box test, i.e., tests knowing the content of the functions to
verify and tests modules where only input and outputs are known by the
verification team. Different SW simulation or debugging tools shall be
used for these purposes. As well as for the rest of the test campaign, the uni￾tary and integration tests shall be repeatable and automated.
Integration tests will be executed after unitary test or even in parallel.
Integration tests are normally designed in an incremental manner, having
the purpose of gathering in subsequent tests the V&V of an incremental
combination and interaction of different previously verified unitary func￾tions, SW components, HW components, or both. To build this incremen￾tal process, stubs or wrappers can be used with the focus of providing all the
interfacing connections to the modules under test but without adding func￾tionalities that might not yet be verified at the same time to allow isolate the
V&V incremental purposes.
A special testing case campaign is the regression testing. It should be
applied after a modification on an already validated SW, module, subsystem
or system, repeating test cases or adding new ones to verify that after the
changes the tests are still in line with the V&V requirements and that they
do not create other undesired effects.
The final V&V of the whole on-board implementation is performed
lately by system test campaign that include all the SW and HW functions
of the subsystem as a black box test covering all the requirements and testing
scenarios as defined and agreed in the plans and specification of subsystem. A
subset of system test campaign might be defined as the acceptance tests,
which are defined by customer for the approval and acceptance of the
implementation delivery output product. Please refer to HW-in-the-loop
HIL approach (see Chapter 12 e GNC verification and validation) for
the specific accommodation of System tests using target HW processing de￾vices, real interfaces, real sensors, and in a relevant environment, scenario,
and conditions with respect to the mission.
References
[1] https://www.microsemi.com/.
[2] SpaceWire Proceedings, in: http://2018.spacewire-conference.org/downloads/
2018SpWProceedingsnew.pdf, 2018.
[3] Exomars 2022 Mission, https://directory.eoportal.org/web/eoportal/satellite￾missions/e/exomars-2022.
On-board implementation 711[4] Exomars Control Center. https://www.gmv.com/en/Company/Communication/
News/2019/06/ExomarsCC.html.
[5] Experience Summary on Microsemi RTG4 Designs, SEFUW: SpacE FPGA Users
Workshop, fourth ed., Johannes both, Edgar Kolbe.
[6] H. Sierks, H.U. Keller, R. Jaumann, et al., The Dawn framing camera, Space Science
Reviews 163 (2011) 263e327, https://doi.org/10.1007/s11214-011-9745-4.
[7] J.P. Cobos Carrascosa, B. Aparicio del Moral, J.L. Ramos Mas, M. Balaguer,
A.C. Lopez Jiménez, J.C. del Toro Iniesta, The RTE inversion on FPGA aboard 
the solar orbiter PHI instrument, in: Proceedings Volume 9913, vol 991342, Software
and Cyberinfrastructure for Astronomy IV, 2016, https://doi.org/10.1117/
12.2232332.
[8] P. Bajanaru, R. Domingo, D. Gonzalez-Arjona, F.A. Stancu, C. Onofrei,
M. Marugan, R. Chamoso, C.G. Mihalache, Reconfigurable Co-processor for Space￾craft Autonomous Navigation”, European Workshop on On-Board Data Processing
(OBDP2021), ESA-ESTEC, The Netherlands, 14e17 June 2021.
[9] P. Bajanaru, D. Gonzalez-Arjona, F.A. Stancu, A. Alexe, D. Gogu, S. Sincan,
O. Dubois-Matra, J. Alves, S. Vijendran, On-board complex image-processing based
on FPGA acceleration for autonomous navigation in space, in: European Workshop
on On-Board Data Processing (OBDP2019), ESA-ESTEC, The Netherlands,
25e27 February 2019.
[10] Fall, Xcell Journal, Xilinx, FPGAs on Mars, David Ratter, Field Applications Engineer,
Un Horizons Electronics, 2004.
[11] Mars 2020 Perseverance Landing Press Kit. https://www.jpl.nasa.gov/news/press_
kits/mars_2020/landing/mission/spacecraft/perseverance_rover/.
[12] D. Gogu, F. Stancu, A. Pastor, D. Fortun, D. Gonzalez-Arjona, O. Muler, €
M. Barbelian, V. Pana, Boosting Autonomous Navigation Solution Based on Deep
Learning Using New Rad-Tol Kintex Ultrascale FPGA”, European Workshop on
On-Board Data Processing (OBDP2021), ESA-ESTEC, The Netherlands, 14e17
June 2021.
[13] State-of-the-Art Small Spacecraft Technology Small Spacecraft Systems Virtual Insti￾tute Ames Research Center, Moffett Field, California, October 2020. NASA/
TPd2020e5008734.
712 David Gonzalez-Arjona et al.PART THREE
AI and modern
applications
713jThis page intentionally left blankCHAPTER FOURTEEN
Applicative GNC cases and
examples
Stefano Silvestrini1
, Andrea Colagrossi1
, Emanuele Paolini2
,
Aureliano Rivolta2
, Andrea Capannolo1
, Vincenzo Pesce3
,
Shyam Bhaskaran4
, Francesco Sanfedino5
, Daniel Alazard6
1
Politecnico di Milano, Milan, Italy
2
D-Orbit, Fino Mornasco, Italy
3
Airbus D&S Advanced Studies, Toulouse, France
4
NASA Jet Propulsion Laboratory, Pasadena, CA, United States
5
ISAE-SUPAERO, Toulouse, France
6
ISAE-SUPAERO, Toulouse, France
The chapter presents a set of applicative guidance, navigation, and control
(GNC) examples and use cases covering the topics of GNC that are of rele￾vance for practical and modern applications. The content described here
serves to decline the founding concepts covered in the previous parts of
the book to different applicative cases, showing an end-to-end workflow
to design the GNC system, or a part of it.
The proposed examples cover orbital and attitude control system (ACS)
design, relative GNC applications, methods for on-board sensor processing,
techniques for missions flying around irregular Solar System bodies, and
planetary landing. Moreover, an example Attitude and Orbit Control Sys￾tem (AOCS) design process is used to introduce the chapter and to apply
the GNC design methods, from requirements to preliminary design.
The covered topics span the entire applicative spectrum of modern
spacecraft GNC, and, for this reason, the different sections of this chapter
belong to different domains and have a broad variety of terminology and
theoretical concepts. The reader is invited to read each section as an auton￾omous block, linking the presented concepts to the referenced parts of the
book. Furthermore, the list of covered applications is obviously not exhaus￾tive but contains those examples that are deemed to be more relevant for the
modern challenges faced, on a day-by-day basis by the spacecraft GNC
engineers.
The content of this chapter is structured as follows:
• AOCS design. This section summarizes the GNC design process, intro￾duced in Chapter 1 e Introduction and discussed along the whole
Modern Spacecraft Guidance, Navigation, and Control
ISBN: 978-0-323-90916-7
https://doi.org/10.1016/B978-0-323-90916-7.00014-7
© 2023 Elsevier Inc.
All rights reserved. 715 jbook, with an applicative example on an AOCS. The system-level trade￾offs, the AOCS modes, and the definition of the control types are dis￾cussed. The section is concluded with some comments on the selection
of sensors and on the sizing of actuators for the example AOCS design.
• Orbital control systems. In this section, the most relevant orbital control
methods are discussed, differentiating between impulsive and low￾thrust control. The most common orbital maneuvers are
presented, together with a brief section on the Lambert’s problem for
orbital targeting applications. Finally, the fundamental principles behind
low-thrust trajectory design with optimal control methods and station￾keeping for orbital maintenance are introduced.
• Attitude control systems. This section presents some of the most useful
methods to deal with spacecraft attitude control, such as detumbling,
one-axis pointing, and three-axis pointing. Specific control techniques
with reaction wheels and magnetorquers are presented, including a short
section on reaction wheels desaturation. An applicative emergency solar
panels pointing control is proposed, and a robust attitude control to deal
with flexible appendages is preliminary designed at the end of the
section.
• Relative GNC. This section presents some techniques to deal with GNC
systems for relative and proximity operations. Trajectory design, guid￾ance, and control strategies are discussed. Finally, an example operative
case of a rendezvous in cislunar space is presented.
• On-board sensor processing. Some methods for on-board sensor processing
are discussed in this section, with particular focus on failure detection,
isolation, and recovery (FDIR) applications. Moreover, two applicative
examples to be performed on-board for autonomous sensor calibration
and Global Navigation Satellite System-Inertial Navigation System
(GNSS-INS) orbit determination are presented.
• Irregular Solar System bodies fly around. This section discusses the most rele￾vant GNC aspects related with the fly around of irregular Solar System
objects.
• GNC for planetary landing. This section proposes an entire GNC system to
deal with the problem of safely landing a spacecraft on the surface of a
planet. The focus of the section is on the powered descent phase, and
it does not account for the planetary atmosphere.
716 Stefano Silvestrini et al.AOCS design
GNC is a wide terminology that has several major fields of application
and can be used for any controlled dynamic system implying the functions of
estimating the state, provide a reference, and control the estimated state to
follow the reference one. On the other hand, the term AOCS is specific
to spacecraft design: it is commonly used when the orbit guidance is not per￾formed on-board, which is the case for standard low Earth orbit (LEO) and
geostationary Earth orbit missions. When used in relation to spacecraft, the
term GNC is typically used for the on-board segment when the satellite po￾sition is controlled in closed loop, for instance, in case of rendezvous and for￾mation flying.
Regardless the specific terminology, the concept behind GNC and
AOCS is analogous, and the processes to design a GNC system or an
AOCS are closely related and follow the same steps. This section discusses
the process to design and define the AOCS subsystem for a generic Earth￾orbiting spacecraft. However, the same approach and concepts can be easily
applied and extended to any GNC subsystem for modern spacecraft
applications.
AOCS design process and subsystem architecture
The AOCS design process is iterative and involves the following steps, sum￾marized in Fig. 14.1:
• Definition of high-level requirements with system engineering, starting
from mission and payload requirements, and including all the high-level
functionalities of the spacecraft that involve the AOCS subsystem, such
as operative states, required accuracies, stability, etc. This includes also
support to the definition of budgets for pointing accuracy, orbit control
precision, and mass-volume allocation. The output of this phase is a set of
requirements providing a clear idea of what the AOCS subsystem is
called to do.
Figure 14.1 AOCS design process.
Applicative GNC cases and examples 717• Evaluation of criticalities possibly impacting high-level system design.
Relevant disturbances, how required orbital and attitude states impact
the subsystem, what is needed to achieve the required performances,
interfaces, impact on mission operations, constraints imposed to the
overall system and to the other subsystems, etc.
• Trade-offs with system engineering. This will be deepened in this sec￾tion, and it could result in new possible requirements or requirements
change for AOCS design.
• Definition of AOCS modes, subdivision of tasks among them, and
outline of the AOCS state machine, which will be further discussed later
in this section.
• Definition of detailed subsystem requirements for each AOCS mode.
• Selection of control types for each mode, in order to fulfill the relevant
and applicable requirements.
• Iteration of the previous steps.
• Selection of hardware (HW) and software (SW) algorithms.
Once the high-level design is completed, then the detailed design can
further proceed with the following steps:
• Design and development of the AOCS SW functions and assessment of
the available performances in nominal and nonnominal cases, sensitivity,
and robustness analysis.
• Verification, validation, and testing, both at HW and SW level.
The AOCS design shall consider the structure of the entire subsystem,
which is typically formalized and detailed in an AOCS architecture. A
typical AOCS architecture is shown in Fig. 14.2. The plant dynamics, in
terms of instantaneous orbital and attitude states, velocity and angular rate,
is sampled by sensors, whose data feed the navigation block that computes
the estimated state of the satellite through data merging and filtering tech￾niques, discussed in Chapter 9 e Navigation. The guidance is in charge
of providing the desired state of the spacecraft, as outlined in Chapter 8 e
Guidance, and the difference between the guided state and the navigated
one feeds the controller, presented in Chapter 10 e Control, whose aim
is to reduce this difference, so that the orbital and attitude states can reach
or follow the desired targets. Telemetries and telecommands (TCs) from
ground can eventually provide additional information in the loop, for
example, in the case of guidance profiles loaded by ground, or when the
configuration of the controller needs to be changed through updatable pa￾rameters and flags. Note that a proper GNC subsystem has its main differ￾ence with respect to an AOCS in this part, since the guidance profiles are
718 Stefano Silvestrini et al.always computed on-board, and they are not uploaded with TC. The
computed control output feeds the actuators, whose action has an impact
on the spacecraft plant dynamics, together with the disturbing actions of in￾ternal and external factors characterizing the space environment, presented
in Chapter 3 e The Space Environment. Sensors and actuators data are
an input also for the FDIR function that checks those data to mark each
one as valid or not valid and autonomously decide which are the best nav￾igation and control strategies based on data and component availability or
unavailability. Higher level FDIR blocks can also check for major anomalies
as, for example, a not correct Sun pointing or an actuator failure, leading to
the possibility of an AOCS mode transition (Fig. 14.2).
Evaluation of criticalities
Right after the definition of the high-level requirements the AOCS shall
fulfill, it is good practice to study how the overall system architecture im￾pacts the AOCS design and vice versa, how the latter can impact or impose
constraints on the system or other subsystems design. For example, if the
payload has a high power demand, and thus large deployable solar arrays
are foreseen by system high-level design, the AOCS designers should derive
constraints for the structural design, in a way to limit the frequency of reso￾nance of the panels to be 10 times larger than the desired control bandwidth.
Evaluation of environmental disturbances is also important to understand if
major design drivers can arise. For instance, drag can highly affect the dura￾tion of missions in LEOs. Therefore, outlining suitable low-drag attitude
Figure 14.2 AOCS architecture.
Applicative GNC cases and examples 719states for the nonoperative phases of the mission can be vital to reduce the
number of maneuvers to raise the altitude of the orbit in order to compen￾sate for the atmospheric decay, which typically has a huge impact on the
propellant to be carried on-board.
These are just two examples: evaluation of criticalities is very mission￾specific, and it shall be evaluated case by case, under a system engineering
point of view.
System-level trade-offs
When designing an AOCS system, it is of utmost importance to perform
the necessary trade-offs with system engineering to decide high-level fea￾tures and, through an iterative process, freeze the overall spacecraft config￾uration, satisfying the imposed high-level requirements and minimizing the
impact of the criticalities on the mission. One of the main trade-offs is to
decide the orbital and attitude states of the spacecraft during the mission:
indeed, if on one side the dynamical states during payload operations are
constrained by the payload itself, the same could be not true for other
mission phases and alternative AOCS modes. Hence, in many cases, there
is room to decide, for instance, if it is better to keep the satellite always in
operative state, aligning the solar panels to the Sun, thanks to the action
of the solar arrays drive mechanisms (SADMs), or to rotate the entire space￾craft to point the panels toward the Sun. The latter option could lead to
smaller solar arrays, save the mass and the cost of the SADM, and bring
higher flexibility, but with the drawback of more complex operations and
higher spacecraft maneuverability.
These design choices really depend on a case-by-case basis, so that it is
not possible to provide a single answer that is always valid. What a GNC
designer shall understand is to perform the correct preliminary design ana￾lyses, taking into consideration all the possible factors, criticalities, and con￾straints. This process clearly has a broad range, well outside the GNC
subsystem itself, in order to make the most correct design choices for the
mission and avoid undesirable major changes in the architecture at a later
stage of design. Another typical example of high-level trade-off is
ground-based guidance versus an autonomous one; namely, the selection
of an AOCS or a GNC subsystem. Similarly, a ground-based orbit control
strategy versus an autonomous orbital station-keeping control, or even the
choice of the control methods, or the algorithms for the different AOCS
modes are other examples of high-level trade-offs.
720 Stefano Silvestrini et al.A good approach to perform these design trade-offs is to summarize the
pros and cons of each different option in a table and assign a vote for each
one and for each of their relevant design feature. Table 14.1 shows an
example of this design trade-off approach, where three alternative design
options are compared: each of them is assigned a vote from 0 to 1 for
each relevant feature. Note that each feature is differently weighted on
the final sum, based on the real impact that it has on the spacecraft and
on the mission. The option with the highest weighted mark is the best
from an overall point of view. This means that it will not be at the same
time the cheapest solution, the simplest at a technical level, the less impact￾ing on the operations side, etc., but it is the one that from a global point of
view brings the more advantages with, at the same time, the most acceptable
drawbacks.
It shall be noted that this criteria matrix-based design is strongly affected
by the weights and the policies to assign the votes that are inserted in the
trade-off matrix, together with the features that are accounted in the
trade-off process. Hence, the definition of the criteria matrix itself is a crucial
part of the design, it cannot be generalized to different missions and it shall
be agreed and discussed at system level.
Definition of AOCS modes
An important aspect of AOCS design is the division of tasks among different
modes. GNC functions shall be tailored and tuned to achieve specific goals
for the spacecraft, and this leads to the importance of having different nav￾igation, guidance, and control functions depending on the AOCS mode.
Thus, different specific AOCS modes can be implemented to facilitate the
accomplishment of any task the spacecraft is called to carry out in each of
Table 14.1 Design criteria matrix.
Weight Option 1 Option 2 Option 3
Feature A (i.e., impact
on operations)
20 0 1 0.4
Feature B (i.e., impact
on interfaces)
30 0.6 1 0.8
Feature C (i.e., tech
effort to implement
it)
10 1 0.3 1
Feature D (i.e., cost) 40 0.7 0.5 1
Total 56 73 82
Applicative GNC cases and examples 721its operative phases. For example, a safe mode only uses the most reliable
HW available on-board and needs very simple SW functions, with the
acceptable drawback of a rough pointing, typically with the solar panels to￾ward the Sun to recharge the batteries. On the other hand, an operative
mode shall achieve the pointing performance required by the mission and
by the payload. Therefore, it is important that the involved HW and
GNC functions are appropriate to achieve that goal. For these reasons,
the operative modes mostly drive the AOCS cost, while the safe modes
impose reliability and efficiency requirements on the components and on
the GNC SW. Examples of typical AOCS modes are reported in Table 14.2,
together with their main tasks and characteristics.
AOCS modes can differ from system modes, sometimes called system
states: when the spacecraft is in operative state, AOCS could be in stand￾by mode, or in operative, or in orbit control mode. Typically, when the
spacecraft goes into safe state, it drives AOCS to go in safe mode, but the
vice versa is not always recommended. In general, the transitions between
the different modes are regulated according to a finite-state machine (FSM).
An FSM is a mathematical model of an abstract machine describing the
behavior of an automated system, such as a complete AOCS/GNC subsys￾tem with multiple modes, or an entire spacecraft system. An FSM can be in
exactly one of a finite number of states at any given time, and it changes
from one state to another in response to some inputs; the change from
one state to another is called a transition. Transitions can be autonomous,
automatic, or commanded from ground. Note that automatic typically refers
to transitions that follow very strict boundaries defining the scope and the
parameters of the transition. In this case, the automatic transitions happen
according to a well-defined set of predefined events. Autonomous transi￾tions are performed according to a decision of the system, which learns
and adapts to dynamic environments, and evolves as the environment
around it changes. These concepts are discussed with more details in Chapter
1 e Introduction. An FSM is defined by a list of its states, its initial state, and
the inputs that trigger each transition. Fig. 14.3 shows a simplified example
of an FSM of a satellite, including typical nonnominal FDIR transitions.
Definition of control types
Once the AOCS modes have been established and detailed, and the require￾ments for each of them have been finalized, control types can be individually
selected for each mode. The aim of AOCS and GNC is to overcome both
722 Stefano Silvestrini et al.Table 14.2 Typical AOCS modes.
AOCS mode Tasks Characteristics
Safe hold
mode
• Detumble the satellite
• Point the solar panels
toward the Sun
• Most reliable hardware shall be
used
• Power consumption shall be
minimized
• Rough pointing is acceptable
• It shall be completely
autonomous
Stand-by
mode
• Point the solar panels
toward the Sun
• Point antennas toward the
Earth (i.e., ground station)
• Minimize drag during
nonoperative phases
• Point radiators to deep space for
thermal control
• Others depending on the
mission
• Nominal hardware should be
involved (i.e., more complex
than in safe mode)
• Improved pointing
performance with respect to safe
mode, but it could be worse
than in operative mode
• It is typically autonomous
• GNC functions should be
different from the ones used in
safe mode
Operative
mode
• Accomplish the main goal
and satisfy the primary
requirements of the mission
(e.g., image acquisition, antenna
pointing, .)
• Most precise hardware is
involved
• Most precise pointing is
achieved, using complex
filtering or control techniques
• It is typically ground-assisted
Orbit
control
mode
• Perform orbital maneuvers
• Point and stabilize the
thrusters in the desired direction
• Propulsion is involved
• Precise and stable pointing is
achieved
• Thrust parasitic torques shall be
counteracted
• It is typically ground-assisted
Transfer
mode
• Control the attitude and
the orbit during long transfers
(e.g., along geostationary
transfer orbits, or interplanetary
orbits)
• Propulsion is involved
• Precise and stable pointing is
achieved
• Thrust parasitic torques shall be
counteracted
• It is typically autonomous
• Thermal and power
requirements shall be fulfilled
Mission
mode
• Achieve particular goals
and targets of the mission
• Various
Applicative GNC cases and examples 723internal and external disturbance torques and to appropriately control the
spacecraft dynamics to achieve the mission goals. Control types can be
mainly divided into passive and active.
Passive control techniques are those in which the spacecraft is inherently
stable; therefore, no GNC control action is required. Examples of these kind
are spin stabilization, where stability of the spinning axis in the inertial frame
is granted, thanks to the conservation of angular momentum; gravity
gradient stabilization, where elongated spacecrafts are stabilized along the
local vertical direction, thanks to the different action of the gravity on the
portion of satellite closer to Earth with respect to the farther ones; magnetic
stabilization through the use of permanent magnets; frozen orbit stabiliza￾tion, where the orbital state variations are minimized, thanks to a proper se￾lection of the orbital parameters; Earth oblateness Sun aspect angle
stabilization, where the orbital precession is controlled by selecting the
orbital inclination in a way to minimize the apparent Sun motion with
respect to the orbital plane (e.g., Sun-synchronous orbit). However, passive
control techniques can achieve only rough accuracy, and they also impose
strong constraints on the space of admissible dynamical states.
Thus, the most precise missions will certainly require for active control
techniques, where the spacecraft orbital and attitude states are controlled
by means of actuators that provide controlled forces and torques on the plant
dynamics. Active orbital control can be used to impose boundary limits on
the orbital parameters to perform station-keeping, or it can change the
spacecraft orbit to achieve orbital transfers or to modify the spacecraft
ground tracks. Analogously, it can be used to perform relative orbital control
Figure 14.3 AOCS state machine and mode transitions.
724 Stefano Silvestrini et al.during rendezvous or formation flying missions. Active attitude control is
commonly used to control the directions of the spacecraft axes, and it can
be momentum biased, controlling one or more axes, or zero momentum,
controlling the three spacecraft’s axes. The active attitude control definition
depends on the resulting momentum created on the satellite. Momentum￾biased techniques use momentum wheels to create a momentum vector that
inherently stabilize an axis of the satellite, which will be the one with the
sensors or the payload to operate, and it is often used for local vertical
(i.e., nadir) pointing or other static pointing modes. Zero momentum has
no restriction on the pointing that can be achieved; it can provide fast slews
since no momentum vector shall be rotated, and it normally reaches the
highest accuracy since it is able to quickly react to any disturbance. Howev￾er, it needs attitude information on all the three axes, and it is usually the
most expensive type of control. A zero-momentum configuration can be
reached indifferently with thrusters, reaction wheels, magnetic torquers,
or control moment gyros (CMGs). The specific actuator to be used shall
be evaluated case by case, considering the necessary torque and momentum
storage during the required slews, the lifetime (e.g., thrusters are limited by
propellant, wheels, and CMG mainly by bearings duration), the costs, etc.
The most basic controller to achieve active control is of proportional
type, as explained in Chapter 10 e Control. In this case, the proportional
gain Kp can be selected in order to limit the steady-state errors to the desired
value:
Kpy D=ε;
where D is the disturbance term and ε the desired steady-state error. Kp also
defines the controller bandwidth that is given for the attitude control case by:
uny
ffiffiffiffiffiffiffiffiffi
Kp

I
q
given I the inertia of the spacecraft. The bandwidth defines the frequency at
which the control action starts to be less effective (i.e., the control authority
will be effective from 0 frequency up to the bandwidth), and it can be easily
generalized for the orbital control case. A derivative action can be added to
increase the control stability, keeping the same steady-state accuracy, by
increasing the state damping that will slow down the response of the
controlled system. Moreover, the steady-state error can be further decreased
with the addition of an integral term in the controller, coming at the cost of
reduced stability margins. Table 14.3 summarizes how AOCS requirements
Applicative GNC cases and examples 725can impact on the architectural choices of the attitude control subsystem and
on the attitude control types.
Sensors selection and actuators sizing
Sensor selection comes from reverse engineering of the pointing and control
budgets of the spacecraft. Indeed, sensor errors in terms of bias, low￾frequency noise, and temporal noise provide an important figure of evalua￾tion for AOCS design. In fact, these errors contribute to navigation error
that is one of the contributors to the Attitude Knowledge Error (AKE) in
the pointing and control budget. Note that, for the attitude sensor, the errors
are commonly summed up in the NEA, the Noise Equivalent Angle.
For a preliminary error assessment, the GNC designer can make a resid￾ual sum of squares of the sensor errors, and then it can estimate the naviga￾tion error as:
Nav Err ¼ RSSffiffi
n p
where n is the number of sensors used in hot redundancy. Nav Err could be
worse in the case of nonorthogonality between the sensors’ lines of sight, but
this effect is typically negligible up to 70 degrees of angular separation be￾tween lines of sight (e.g., degradation could be 1-2 arcsec when the angle
between lines of sight is 70 degrees, but then raises exponentially for smaller
angles). Then, the navigation error sums up with other contributors in the
pointing budget (i.e., thermomechanical deformations, misalignments, .)
to compute the AKE. Therefore, sensor selection is typically performed
backwards starting from the required AKE, splitting it among its contribu￾tors, including the navigation error. In this way, a value for the sensor errors
can be found to be compared with suppliers’ specifications. As it can be
guessed, this is an iterative process since other contributions, even from other
subsystems, are involved.
Coarse sensors are widely used for AOCS rough control modes or for
temporary backup solutions. In modern space missions, these sensors may
be used as state acquisition sensors even in operative modes. Coarse Sun sen￾sors, magnetometers, microelectromechanical system inertial sensors, and
commercial GNSS receivers are examples of this category. When dealing
with these sensors, it is important to accurately address noise as accurately
as possible, in order to achieve the desired performance. Moreover, since
they are frequently used in small satellite or low-cost missions, also mass￾726 Stefano Silvestrini et al.Table 14.3 AOCS requirements and architectural choices for attitude determination
and control.
Requirements
Effects on attitude
determination Effects on attitude control
Pointing error >
5 degrees
If gravity gradient (GG)
stabilization is used,
there is no need for
attitude
determination
Otherwise, Sun
sensors and
magnetometers are
adequate.
Depending on the mission
pointing modes, passive
control could be feasible,
even with GG
stabilization, leading to
major cost savings.
Pointing error from
1 to 5 degrees
Sun sensors,
magnetometers, and
horizon sensors are
adequate.
GG stabilization would be
too rough. Spin
stabilization is feasible if
the mission needs an
inertially fixed attitude.
Active control could be
needed; in the case
magnetic torquers are
viable, the wheels are not
required.
Pointing error from
0.1 to 1 degrees
Accurate attitude
determination
needed: coarse sensors
are not viable. There
is the need for star
trackers, or horizon
sensors, and
gyroscopes depending
on the mission.
Passive control is not
possible.
Both momentum bias
and zero momentum are
viable.
Typical actuators are
reaction wheels, with
magnetic torquers or
thrusters for momentum
unloading and coarse
control.
Pointing error <0.1
degrees
Star trackers and
accurate gyroscopes
are necessary.
Three-axis zero￾momentum control is
needed. Control of
minor disturbances, such
as flexible modes and
sloshing is very
important. Complex
GNC algorithms are
necessary.
(Continued)
Applicative GNC cases and examples 727volume considerations are important, as well as radiation tolerance, especially
if commercial components designed for ground applications are under
evaluation.
Magnetic torquers are typically used for desaturation of momentum ex￾change actuators, and for magnetic detumbling of the satellite after release
from the launcher. In such a case, the sizing is performed against the total
angular momentum to be dissipated by the torquers in a prescribed amount
of time, which is safely allowed by the spacecraft’s batteries before entering a
critical condition. Magnetic torquers are typically used in a duty cycle with
magnetometers: when reaching the maximum duty cycle, torquers are
switched off to leave enough time for dipole discharging and subsequent
magnetometers data acquisition. This is to avoid magnetic interference, as
discussed in Chapter 7 e Actuators. Table 14.4 reports a one-axis example
Table 14.3 AOCS requirements and architectural choices for attitude determination
and control.dcont'd
Requirements
Effects on attitude
determination Effects on attitude control
Angular Rates <
1 degrees/s
None Reaction wheels are usually
sufficient, depending on
spacecraft inertia.
Rates >1 degree/s Star trackers may be
not adequate.
CMG or thrusters could be
necessary for slews.
Table 14.4 Example magnetorquer sizing.
Parameter Value Unit measure
Orbital altitude 500 km
Mean magnetic field, B 30 mT
Spacecraft Inertia, I 300 kgm2
Time allowed for
detumbling, Tall
4 Orbits
Duty cycle with
magnetic torquer
switched off, DC
25 % of control cycle dedicated to discharge
magnetic torque dipole and read
magnetometer data
Design margin, M 20 %
Angular rate at release, u 2.5 /s at 3s from launcher user manual
Momentum to be
damped, H
13.08 Nms (H¼Iu)
Orbital period, T 5674 s
Time for damping, td 12,483 s (td ¼ Tall$T$½ð100  DC  MÞ =
100)
Needed torque, C 0.001048 Nm (C ¼ H/td)
Magnetic dipole, m 35 Am2 (m ¼ C/B)
728 Stefano Silvestrini et al.of magnetic torquer sizing against detumbling of initial angular rates of an
LEO spacecraft. Note that design margin, M, is meant here to account for
variability of preliminary data such as inertia of the spacecraft, but also for
the fact that the control torques are constrained to lie on the plane perpen￾dicular to the local magnetic field direction.
Reaction wheels sizing is typically performed against agility require￾ments, which are associated to the maximum slew rates that can be achieved
by the AOCS. A simple way is to consider bangebang profiles for the atti￾tude maneuvers, where 60%e70% of the maximum torque from reaction
wheels is used, leaving the rest for disturbance compensation. Assuming q
as the slew angle, u_ as the desired angular acceleration, and tTOT as the total
maneuvering time, a maximum torque profile leads to:
q
2
¼ 1
2
u_
tTOT
2
2
/tTOT ¼ 2
ffiffiffi
q
u_
r
or u_ ¼ 4q
t
2
TOT
;
where half of the slew angle is covered in half of the prescribed time. For
example, consider the following typical requirement: “The spacecraft shall
be able to perform 90 degrees slews in less than 3 minutes.” This leads to a
required angular acceleration of 0.011/s2 or 1.9e4 rad/s2
. Assuming to
leave 30% of the available torque for disturbance compensation, and
assuming an inertia of 300 kgm2
, it is obtained that a control torque of 0.058
Nm is required to comply with the requirement. Note that gyroscopic ef￾fects have been neglected, as it is reasonable to assume as far as the angular
rates during the slews are not substantially high.
Thrusters can be used for orbit control or attitude control, and some￾times even for both. When thrusters are used for orbit control, then a
trade-off between the DV to be delivered in a given amount of time (i.e.,
the need for larger thrusters to minimize time) versus the accuracy on the
final orbit to reach (i.e., the need for smaller thrusters to maximize accuracy)
shall be done. Typically, accuracy is more important than allocated time for
orbital maneuvers; so, there is a wide tendency on using thrusts below 5 N,
that is helpful also on the attitude control side, since parasitic torques during
thrusters firing are typically relevant, as explained in Chapter 3 e The Space
Environment. When thrusters are used for attitude control, then a sizing for
a detumbling or a fast slew is typically performed. Assuming an inertia of
300 kgm2
, and an angular rate at release of 2.5/s on the same axis, then a
momentum of 13.08 Nms shall be dissipated through the action of thrusters
(cfr. Table 14.4). If a requirement asks for a maximum detumbling time of
Applicative GNC cases and examples 729two minutes, this turns in a request for a constant torque of 0.109 Nm. The
needed thrust, F, can be computed recalling that, for two symmetric
thrusters creating nominally a pure torque, t; around the axis:
t ¼ 2Fd/F ¼ t
2d
where d is the arm between the application point of the thrust and center of
mass of the satellite. So, to conclude the example, assuming an arm of 30 cm,
two symmetric thrusters able to provide at least 0.182 N of thrust each are
required.
CMGs are momentum exchange devices in which the spinning rotor is
placed on a gimbal that can be rotated in the direction orthogonal to the
spin. In this way, the momentum vector is changed in direction, resulting
in a gyroscopic torque. Depending on the CMG model, the spin speed of
the rotor can be either fixed or variable, and it can be rotated around one
or two axes. Sizing of CMGs is a bit more elaborated to be treated here;
however, it is widely discussed in Ref. [1].
Orbital control system
Orbital control is a broad term referring to control theory applied on
the orbital dynamics. The goal of the orbital control system is to manage the
orbital state to control the position and velocity of the spacecraft. As it was
discussed in Chapter 4 e Orbital Dynamics, a body in space is always mov￾ing under the action of gravitational forces, which make practically impos￾sible to have a static position control. Indeed, the spacecraft position and
velocity are continuously changing in time as the spacecraft moves along
its orbit. Thus, position control in space has always to be considered under
a dynamical perspective, defining the control variables on the six orbital
states of the spacecraft.
It shall be noted that often orbital control is not performed in closed
loop. Many orbital maneuvers can be performed in open loop, and they
are usually computed on-ground. Thus, many classical spacecrafts are just
equipped with an AOCS subsystem, and the orbital control errors are pro￾gressively fixed by means of progressive correction maneuvers (e.g., trajec￾tory correction maneuvers during interplanetary transfers). However, it shall
be noted that the control budget allocated for correction maneuvers is
remarkably smaller than the one for primary orbital insertion or orbit change
maneuvers. Hence, the open-loop control shall not be confused with a
730 Stefano Silvestrini et al.rough trial and error approach, since the typical spacecraft constraints leaves
no room for orbital control errors. Even if the open-loop orbital control
with the main GNC functions demanded to the ground segment (e.g.,
ground-based orbit determination, guidance and trajectory optimization,
maneuver computation) is common for the largest orbital control opera￾tions, closed-loop system and on-board orbital GNC are not extremely un￾common. Moreover, they are becoming more popular for modern
spacecraft, which are looking for increased autonomy and lower operating
burden, and they are necessary whenever the real-time operations make
the delay imposed by ground support not acceptable.
Despite the differences in the aforementioned approaches, the funda￾mental rules behind orbital control remain the same, and they can be applied
to any of the previous cases. For this reason, this section preliminarily pre￾sents some of the most common and useful applicative examples about
orbital control, regardless from the closed-loop or open-loop implementa￾tion, and from the location where these techniques are computed. Given the
broad theory behind orbital control, the reader is strongly encouraged to
deepen these concepts in the suggested literature references [51e54].
Impulsive and low-thrust maneuvers
Orbital control methods are strongly influenced by the performance of the
thrusters used to actuate orbital control commands. In particular, the avail￾able thrust level divides between impulsive and low-thrust maneuvers.
In the first case, the thrusting force is so high that the acceleration applied
to the spacecraft determines a velocity variation that is approximately instan￾taneous. That is, at a particular point in the orbit, the spacecraft changes the
velocity from v1 to v2. Reminding that an orbit is fully defined by the po￾sition and the velocity vectors, an impulsive maneuver makes the spacecraft
dynamics to evolve from the current orbit to another one sharing a common
point with the first. The change in velocity is given by:
Dv ¼ v2  v1.
An important parameter of the maneuver is the magnitude of the veloc￾ity change:
Dv ¼ kDvk;
which is a measure of the fuel consumption, and it is referred to as
“delta-v.”
Applicative GNC cases and examples 731Minimum fuel maneuvers require minimum Dv; as discussed in Chapter
7 e Actuators. Even if the fuel consumption is very important, the time of
flight (TOF) (i.e., time required to complete a maneuver) shall not be over￾looked. Obviously, impulsive maneuvers have TOF ¼ 0, but complete
orbital maneuvers may require more than one impulse. In this case, the
overall TOF is not zero, and it accounts for the coasting phases to reach
the location where the maneuvers shall be executed. It is not uncommon
that a minimum Dv transfer has a nonoptimal TOF, and a compromise be￾tween these two parameters is frequently required in orbital control
applications.
This trade-off is not only valid for impulsive maneuvers but also it can be
generalized to any kind of orbital control system. Indeed, the same concepts
apply to low-thrust maneuvers, where the maneuver is not impulsive
anymore (i.e., TOF s 0), and the Dv is applied over a finite orbital arc, since
the propulsive subsystem has a limited thrust level that produces a small con￾trol acceleration on the spacecraft dynamics. Hence, the velocity variation is
continuous over the thrusting phase, and the orbital change is not related
with a single location, but it distributed over the entire maneuvering
time. Note that, strictly speaking, the low-thrust maneuver is only associated
to the time when the thrusters are active, and the spacecraft is continuously
changing its orbital state. However, the overall low-thrust orbital control
makes use of both thrusting phases and coasting phases. The two are alter￾nated, and the latter is typically exploited to optimize the effectiveness of
the former. Indeed, the optimization of low-thrust orbital control is dedi￾cated to select the best switching events to change between the two alterna￾tive phases.
Low-thrust control force is included in the spacecraft orbital dynamics as
a perturbation force, since it can be considered smaller than the main grav￾itational attraction. Hence, the methods to deal with low trust orbital con￾trol are based on the theory of orbital perturbations, which has been
presented in Chapter 4 e Orbital Dynamics. A common low-thrust design
tool is based on the Gaussian variation of parameters equations. In particular,
the equations for the semimajor axis da
dt, the eccentricity de
dt, and the inclina￾tion di
dt are useful to understand the main impact of the orbital control force f
in terms of its components in 
br; qb; hb

: f r; f q; f h.
Note that no maneuver is really impulsive in the practice, but the
method for impulsive maneuvers is valid whenever the thrusting time is
much smaller than the orbital period (i.e., tmaneuver  TÞ. If the thrusting
732 Stefano Silvestrini et al.time is finite, the difference with respect to the ideal impulsive case can be
accounted by considering the gravity losses. However, the impulsive ma￾neuvers approximation gives acceptable results for many design and analysis
purposes. On the contrary, low-thrust maneuver approach shall be only used
when the thrusting time is long, and the control force is continuously
applied over a finite arc of the orbit.
Orbital maneuvers
With the term orbital maneuvers, we classically refer to impulsive orbital
maneuvers. At first, we will list and discuss some of the most common ty￾pologies of elementary maneuvers to have an insight on the fundamental
concepts behind this topic. Then, the most general type of orbital maneuvers
is presented, discussing the required solution of the Lambert’s problem.
Coplanar maneuvers
Coplanar maneuvers affect the shape of the orbit in the orbital plane, and
thus they are used to modify and control the semimajor axis, a, the eccen￾tricity, e, and the argument of periapsis, u.
The simplest and the most common coplanar maneuvers only consider
tangential velocity changes. Namely, these maneuvers only change the ve￾locity magnitude but not its direction. Thus, in general, the same position
state will correspond in the new orbit to a different true anomaly, associated
to another periapsis (i.e., argument of periapsis is changed). This is not
happening if the tangential maneuver is applied in a point where the velocity
is perpendicular to the orbital radius, and, recalling from the orbital dy￾namics equations, this occurs in circular orbits, or at periapsis and apoapsis
of a generic orbit. Indeed, any tangential velocity change on a circular orbit
results in that point becoming either periapsis or apoapsis of the new orbit.
Accordingly, for an elliptical orbit, any tangential maneuver at periapsis re￾sults in a change of the height of apoapsis, while at apoapsis, it results in a
change in the altitude of periapsis. Moreover, if we want to transform an
elliptical orbit into a circular one using a tangential transfer, we can only
do so at periapsis or apoapsis. Summarizing, a single tangential maneuver
can only change the shape and dimension of the orbit (i.e., a and e) if per￾formed in an apsidal point, while it can change shape, dimension, and orien￾tation if executed in any other point.
Applicative GNC cases and examples 733Assuming the tangential maneuver is performed when the radius vector
is, r; the cost to perform the maneuver can be computed as:
Dv ¼
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
m

2
r
 1
a2
s 

ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
m

2
r
 1
a1
s 
;
where a1 and a2 are, respectively, the semimajor axes of the first and the
second orbit. Note that if Dv < 0, the two terms in the previous equation
shall be switched to get Dv > 0. In fact, a negative Dv means that the orbital
velocity is decreased, but the maneuver is always associated to an active
impulsive thrust. Hence, there is always a fuel consumption, and the only
difference is the opposite thrusting direction. For this reason, the Dv is
defined as a positive quantity.
If the original and the desired orbit have no point in common, a single
maneuver would not suffice to reach the final orbital state. Indeed, in this
case, an intermediate transfer orbit is needed to connect the two orbits. As
a consequence, the spacecraft shall be controlled to move from the first to
the transfer orbit, then a coasting phase is included until the spacecraft rea￾ches the following maneuver point to get into the final orbit or into a further
transfer orbit. The number of maneuvers to reach a desired orbital state is not
constrained, and it is typically an output of the spacecraft trajectory design
and optimization activities. The most common multiple maneuvers strate￾gies are:
• Bitangent elliptic maneuver, with two maneuvering points.
• Bielliptic maneuver, with three maneuvering points.
Note that these maneuvering strategies assume the orbits to have the
same line of apsides. The first one includes a special case, which is the Hoh￾mann transfer. The Hohmann transfer is a bitangent maneuver between two
coplanar circular orbits, and it can be proven that it is the minimum Dv
double-impulse maneuver between coplanar circular orbits [52].
The Hohmann transfer consists of two tangential maneuvers: a circular to
elliptical transfer followed by an elliptical to circular transfer. That is, a trans￾fer from the first orbit to the final orbit is obtained through an elliptical
transfer orbit with semimajor axis defined as:
at ¼ r1 þ r2
2 ;
734 Stefano Silvestrini et al.where r1 is the radius of the departure circular orbit, and r2 is the radius of the
final one. The total velocity change for the Hohmann transfer is:
Dv ¼
ffiffiffi
m
r2
r

ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
m
2
r2
 1
at
s 
þ
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
m
2
r1
 1
at
s 

ffiffiffi
m
r1
r
¼
ffiffiffi
m
r2
r 
1 
ffiffiffiffiffiffiffiffiffiffiffiffiffi
2r1
r1 þ r2
r 	
þ
ffiffiffi
m
r1
r  ffiffiffiffiffiffiffiffiffiffiffiffiffi
2r2
r1 þ r2
r
 1
	
:
The TOF for the Hohmann maneuver is half the period of the transfer
ellipse.
Other coplanar maneuvers are possible, which are not limited to be
tangent, but they can include variations in the velocity direction. In fact,
by applying a thrust nonparallel to the velocity vector, it is possible to change
the orientation of the orbital velocity. This opens to secant coplanar maneu￾vers, where the first and the final orbits have a cross intersection, and to ma￾neuvers capable to change only the orientation of the orbit. Further details
can be found in Refs. [52e54].
Plane change maneuvers
Other than the orbital geometry, and the orientation of the orbit in its plane,
the orbital control may be intended to change the orientation of the orbital
plane in the three-dimensional space. It is possible to control the orbital
plane and the orbital geometry together, or the orbital plane alone. In this
last case, the orbital control shall simply rotate the velocity vector about
the position vector, in a way that the energy and the angular momentum
of the orbit are unchanged.
If position and velocity vectors are perpendicular to each other, the ve￾locity variation for a pure plane change is given by:
Dv ¼ 2v sin
q
2
;
where q is the rotation angle of the orbital velocity. Note that the Dv can be
extremely high, and the plane change is typically one of the most fuel
consuming orbital control maneuver to be performed by the GNC system.
Therefore, if possible, the plane change should be performed as far as
possible from the central attractor, where the orbital velocity reaches the
minimum values.
In general, a plane change will alter both inclination and right ascension
of the ascending node. If a pure inclination change is needed, the plane
Applicative GNC cases and examples 735change shall occur where the orbit crosses the equatorial plane. In generic
case, the complete understanding of the maneuver is based on the spherical
trigonometry to evaluate the velocity rotation angle and the maneuver loca￾tion to achieve the desired final orbital plane. Moreover, it shall be noted
that if position and velocity vector are not, respectively, perpendicular,
the pure plane change Dv is only influenced by the transversal velocity
component.
It is worth noting a very relevant application of the plane change maneu￾ver, which is the acquisition of the equatorial orbital plane. In fact, when a
spacecraft is injected into orbit using a launcher, the point of orbital insertion
is roughly above the launch site. Given the fact that the orbital plane must
contain the center of the Earth and the insertion point, the minimum orbital
inclination is approximately equal to the latitude of the launch site. There￾fore, it is very difficult to launch a spacecraft directly into an equatorial orbit,
unless the launch site is very close to the equator.
As said, if the orbit control has to change the size, shape, and plane of the
orbit, a combination of the previous maneuvers is required. However, it
shall be analyzed on a case-by-case basis, and it cannot be generalized. In
general, such complex orbital maneuvers undergo a trajectory design and
optimization process. The methods and the fundamental concepts behind
orbital control optimization will be discussed in the following section about
low-thrust trajectory design.
Lambert’s problem
The most general type of orbital maneuvers connects a departure point to a
final point. If the two points are not coincident, a transfer orbit shall be
found. The orbital control system shall be capable to inject the spacecraft
from the orbit containing the first point to the transfer one and then to ac￾quire the final point when the transfer orbit reaches it. In general, the trans￾fer orbit is not known and the GNC subsystem (i.e., the guidance functions)
shall be capable to compute it.
The problem of finding the transfer orbit given two position vectors and
imposing the TOF to travel between them is known as Lambert’s problem.
This problem basically consists of finding the orbit required to achieve a
given transit time between two position vectors. It shall be noted that the
Lambert’s problem is only intended to find the transfer orbit satisfying the
imposed position and time requirements, and it does not compute the neces￾sary orbital control maneuvers. It is a crucial tool for GNC applications dedi￾cated to orbital control, far-range rendezvous, and position targeting, but it
736 Stefano Silvestrini et al.is also a fundamental element to solve preliminary orbit determination prob￾lems (i.e., given two observations with an interval of time between them,
determine the compatible orbit).
We know that an orbit is fully defined once the position and velocity
vectors are both specified. Thus, if we know the initial and the final position
vectors (i.e., r1 and r2), we can find either the initial or the final velocity (i.e.,
v1 or v2), although v1 is more interesting for an orbital control system. In
fact, this is the required spacecraft velocity at position r1 and time t1, in order
to get at the desired position r2 at time t2 ¼ t1 þ TOF. According to the
theorem of Lambert, the TOF from r1 to r2 is independent of the orbit’s
eccentricity and depends only on the sum, r1 þ r2, of the magnitudes of
the position vectors, the semimajor axis, a, and the length, c; of the chord
joining r1 and r2. It is noteworthy that the orbital period and the specific
mechanical energy are also independent of the eccentricity. Moreover,
two alternative solutions are available: one is prograde (i.e., 0 < i < 90)
and the other is retrograde (i.e., 90 < i < 180). Generally, the prograde
one is selected because most of spacecraft orbits are prograde and the maneu￾vering cost associated to this case is usually lower; although, the length of the
transfer arc can be a further driver to select the most suitable alternative.
Different solutions to Lambert’s problem are available and can be found
in literature, and the reader is invited to read them in Refs. [51,54].
Low-thrust trajectory design
Low-thrust trajectory design wants to find a controlled trajectory that allows
to reach a final point, from a departure orbital state, in a given interval of
time. The difference with respect to the Lambert’s problem is that the solu￾tion includes a control force and outlines the maneuvers to stay on the
desired low-thrust trajectory. The control force is limited by the maximum
thrust level, and the trajectory can be subject to additional constraints. Thus,
the low-thrust maneuvers are commonly evaluated by solving a constrained
optimization problem. Indeed, the low-thrust orbital control is a typical
application of the optimal control theory and, to have a complete under￾standing of the matter, the reader is invited to familiarize with Hamiltonian
formulations, Lagrange multipliers, and optimal control theory [55]. Note
that the methods introduced here for low-thrust trajectory design and opti￾mization can also be generalized and applied to impulsive maneuvers and
classical orbital control systems.
Applicative GNC cases and examples 737The fundamental idea behind optimal control theory, applied to the
orbital control problem, is to form the Hamiltonian of the system and eval￾uate the partial derivatives to compute the optimal solution for a desired set
of cost functions. The Hamiltonian combines the state equations to the cost
functions. Given that a typical orbital control problem has more cost func￾tions, the Hamiltonian merges all the cost functions and equations of motion
into a single, one-dimensional solution space. The state equations determine
the dynamics and the boundaries of the system. These can be natural (e.g.,
gravity) or physical constraints (e.g., maximum thruster force). However,
further constraints and restrictions can be included into the problem (e.g.,
keep-out zones). The cost functions, or performance indices, assess the opti￾mality of the problem weighting certain conditions, which can be terminal
(e.g., miss distance from a location) or cumulative (e.g., fuel usage, TOF).
The weights and the cost function themselves may be a function of time
or states. The overall optimization process is mathematically intensive and
sometimes requires “human” reasoning to get to the proper solution.
Thus, it is not easy to compute such a solution on-board, and these kind
of orbital control systems are commonly ground-assisted.
The velocity change is accumulated In time during the thrusting phases.
DvLT is the total velocity variation imparted by the thrust force during the
elapsed control time, tf :
DvLT ¼
Z
tf
0
aLT
1 þ m_s t
dt:
where aLT is the spacecraft acceleration, as imposed by the control thrust.
The specific propellant mass flow rate, m_s; is the actual mass flow rate divided
by the initial mass of the vehicle; this value is negative for an active pro￾pellant consumption.
The low-thrust design solution defines the time history of the control
force (i.e., the control acceleration) in a way that the spacecraft can reach
the desired final state, satisfying the imposed constraints and minimizing
the set of cost function, through the Hamiltonian of the system. The overall
solution can include both thrusted arcs and coasting phases, where the dy￾namics is naturally left to evolve under the influence of the environmental
forces. The switching between the two alternative phases can be used to bet￾ter shape the optimal solution of the control problem, as further discussed in
the suggested references [55].
738 Stefano Silvestrini et al.The methods typically used to solve and optimize a constrained low￾thrust orbital control problem are:
• Direct methods, which use a discretization of the trajectory in multiple
path points and approximate the control with simple functions (e.g.,
constant, linear, polynomial, etc.) in each discretized arc. These methods
perform a direct transcription of the optimal control problem and
approximate the infinite-dimensional problem by a finite-dimensional
one to solve it with nonlinear programming (NLP) algorithms. They
exploit well-established and robust numerical methods, and they easily
converge to a solution. However, they involve many parameters, and
they are computationally intensive.
• Indirect methods, which are based on variational calculus and reduce the
optimal control problem to a boundary value problem (BVP). These
methods have a solid theoretical foundation, determining a limited num￾ber of parameters and a fast computation of the solution. However, they
are poorly robust, and they are difficult to converge. In the presence of
constraints, the optimal control solution is usually found applying the
Pontryagin’s maximum principle.
• Heuristic methods, which are based on laws inspired by nature and expe￾rience. These methods determine an optimal solution by iteratively
trying to improve a candidate solution with respect to a given measure
of quality, defined by a cost function. They make few or no assumptions
about the problem, and they can search large spaces of candidate solu￾tions, thanks to the modern computational capabilities. However, they
do not guarantee either feasibility or optimality, and they commonly
fail in understanding how close to optimality a particular feasible solution
is. Different typologies of heuristic optimization algorithm exist, but the
evolutionary and the particle swarm ones are the most suitable for orbital
control.
It shall be reminded that low-thrust orbital control optimization is diffi￾cult to be computed on-board, especially if indirect and heuristic methods
are used. In fact, they commonly require the supervision of an experienced
GNC engineer. Direct methods are the most suitable for on-board applica￾tions, which are possible, thanks to the performance of modern on-board
computers. Notwithstanding, the ground-based trajectory optimization is
still the standard approach for orbital control systems. This is generally
true for both low-thrust and impulsive-maneuver trajectories. Further de￾tails on the optimal control problem are discussed in Chapter 8 e Guidance.
Applicative GNC cases and examples 739Fig. 14.4 shows an example orbit-raising maneuver performed with a
low-thrust orbital control system. The solution optimizes the fuel consump￾tion, and it is found with an indirect method and a bangebang control logic.
Namely, the thruster is fully active along the thrusting arcs and switched off
during the coasting phases. In this example, the thrusting direction is
assumed to be always parallel to the spacecraft velocity vector. However,
the optimization problem can also evaluate the best thrusting direction to
further optimize the solution.
Station-keeping
In the previous section, the orbital control system was used and applied to
control the spacecraft dynamics along orbital transfers and targeting applica￾tions. However, the on-board orbital control systems are also used to main￾tain the spacecraft on the nominal operational orbit, counteracting the
effects of environmental perturbations. This task is normally denoted as
station-keeping, and it is an orbital control application that can be fully
Figure 14.4 Orbit-raising low-thrust trajectory solution.
740 Stefano Silvestrini et al.implemented on-board with a certain level of autonomy. In fact, differently
for other orbital control problems, it is easier to define a feedback control
loop on the errors with respect to the target Keplerian parameters and let
the spacecraft compute the necessary maneuvers to maintain the desired
orbital state. However, as always, there exists the possibility to have a
ground-based GNC implementation, and the control commands are simply
uploaded to the spacecraft.
Station-keeping is commonly not continuously executed, but it is peri￾odically activated when the orbital state errors go out of the predefined
limits, commonly defined as station-keeping box. Thus, the station￾keeping control is applied with a dead band around the reference state.
The station-keeping depends on the operational orbit, and it is related
with the mission requirements since only few orbital elements may be of in￾terest for the specific application. With reference to Earth-based spacecraft,
the most common station-keeping orbital controls are:
• Drag compensation control is used in LEOs, and it is particularly relevant
for space stations and below 400 km of altitude. In this case, the station￾keeping is dedicated to control the orbital altitude, especially the peri￾center’s one, to avoid a shortening of the orbital period and a premature
orbital decay with a catastrophic impact with the atmosphere. The DvSK
for altitude maintenance is strongly dependent from the orbital radius
and from the mass and the drag coefficient of the spacecraft (i.e., ballistic
coefficient).
• Ground track maintenance is used to control the spacecraft passages over
certain regions of the Earth, in a way to maintain a fixed and repeatable
ground track, and the orbital period synchronous with the Earth’s rota￾tion. This station-keeping shall counteract also the faintest atmospheric
drag and the luni-solar perturbation with effect on the orbital inclination.
The latter is particularly important for Sun-synchronous orbits, which
may require a DvSK in the order of 1e2 m=s per year to maintain a
constant inclination.
• Geostationary NortheSouth control is used to maintain the orbital plane
inclination of geostationary orbits, which is perturbed by luni-solar
attraction. The DvSK needed to compensate for this perturbation
maintaining the orbital inclination on the equatorial plane is about 50 m/
s per year.
• Geostationary EasteWest control is applied to keep the orbital period
synchronous with the Earth’ rotation and to keep a small orbital eccen￾tricity. The former effect is due to the perturbations of the nonspherical
Applicative GNC cases and examples 741Earth, the latter is primarily due to the solar radiation pressure. The Easte
West station-keeping is less fuel consuming than the NortheSouth one.
In this case, DvSK is in the order of 5 m/s per year.
• Lagrangian point station-keeping is applied in most of three-body
problem orbits, since their stability is usually weak, especially when the
orbit is about the collinear libration points (i.e., L1, L2, and L3). In this
case, the orbital control is dedicated to cancel the unstable drifting
component of the periodic dynamics (i.e., unstable manifold) to maintain
the spacecraft on the prescribed trajectory. The DvSK is typically very
low, with an average value around 1 m/s per year.
• Relative station-keeping is applied for constellation and formation flying
maintenance. This is a very specific orbital control dedicated to maintain
the relative positions of the different elements in a constellation or a
formation. However, the latter is commonly dealt with relative dynamics
control, and it is managed by a dedicated GNC system. On the contrary,
constellation maintenance is performed with a station-keeping action on
each spacecraft element. The specifications and the cost (i.e., DvSK) of
this station-keeping are dependent from the application, and it is hard to
generalize their discussion. Thus, constellation maintenance station￾keeping shall be analyzed on a case-by-case basis.
The fuel required to perform the station-keeping shall be accurately
computed, since it influences the lifetime of the mission. Its quantity is
dependent on the specific station-keeping orbital control to be imple￾mented, and on the accuracy of the control (i.e., dimension of the
station-keeping box). However, the station-keeping has a low impact on
the other system budgets since it has a low frequency of operations and
does not require complex computations. Differently from the attitude con￾trol, the execution of station-keeping commands is so infrequent that can be
managed by a very basic on-board processor. Thus, if a spacecraft is capable
to autonomously estimate its orbital status, it is very convenient to also
implement autonomous station-keeping. Moreover, gravity has an excep￾tional short-term orbital control capacity. Then, if the orbital control system
fails, the ground would easily determine that the satellite is slowly drifting
from its assigned slot, and there would be enough time to fix the problem.
Attitude control system
Attitude control exploits the fundamental of feedback control systems,
discussed in Chapter 10 e Control, to be applied on the attitude dynamics.
742 Stefano Silvestrini et al.Accordingly, the guidance and navigation functions use the fundamental
principles discussed in the main chapters of this book in order to provide
the reference pointing and the best attitude estimates. In this section,
some attitude control methods are applied to solve the most common space￾craft attitude problems.
Detumbling
Detumbling a spacecraft means to reduce its angular velocity to zero or to
acceptable spin rate levels. Typically, detumbling can be triggered after
the detachment from the deployer at the end of the launch, or in specific
mission phases, or during emergency modes. For these reasons, the detum￾bling control should be as simple as possible, in order to be robust and suit￾able for any contingency operation.
Classic
The simplest way to stop the motion of a satellite is to apply a torque pro￾portional to the angular velocity, opposite in sign. Let’s assume to have the
following candidate Lyapunov function:
L ¼ 1
2


ub
T I ub
Taking its derivative, substituting in the Euler equation presented in
Chapter 5 e Attitude Dynamics, and remembering that the dot product
of a cross product is null, we have:
L_ ¼ 

ub
T
t
b
Hence, if we set t
b ¼ kub
, we would have L_  0 for any angular ve￾locity, and the closed-loop system results to be stable. Of course, if we
include external disturbances in the analysis, we would have convergence
to a bounded area, provided that disturbances have a maximum known
value.
The problem of this simple control law is that it requires a precise and
unbiased angular speed estimation. Considering that most satellite embarks
a gyroscope, this could be an issue only during off-nominal or initial detum￾bling operations, when it is not guaranteed that gyroscope’s bias is correctly
rejected, especially for small cost-effective satellites. This is the reason why
another popular detumbling control strategy is instead commonly used in
small LEO satellites: the B-dot [47].
Applicative GNC cases and examples 743B-dot
The B-dot algorithm is very popular in LEO missions that embark magnetic
torquers. The name comes from the symbol B_ representing the time deriv￾ative of the magnetic field measured by a magnetometer on-board the sat￾ellite. The reason why this control method is very important will be soon
clear.
Recalling Chapter 3 e The Space Environment, the magnetic field of
the Earth, or other planets, can couple with currents flowing on-board
the satellite producing a magnetic torque on the satellite itself. This is the
working principle of magnetic torquers: t
b ¼ m  Bb ¼  Bb  m.
If we are capable to compute a magnetic dipole moment, m, somehow
related to the angular velocity of the satellite, we would achieve something
quite close to the classic detumbling case. Let us then analyze the reason why
B_ is related to this:
Bb ¼ bAiBi
ðxÞ.
Namely, the measured magnetic field depends on the local magnetic
field direction and intensity, and on the spacecraft attitude. Note that the
local magnetic field is dependent on the spacecraft position, x, and thus it
varies along the orbit as well. If we take the time derivative of the magnetic
field vector, we would have:
B_
b
¼ bAiB_
i
ðxÞ  ub  bAiBi
ðxÞ.
In detumbling conditions, the angular velocity of the spacecraft is
sensibly high and we could neglect the variation of the local magnetic field
due to the orbital motion:
B_
b
x  ub  bAiBi
ðxÞ¼ub  Bb
Hence, as desired, B_
b is mainly function of ub
; and we can implement a
detumbling control law based on magnetic measurements only. Indeed, Bb
is the magnetic field sensed by the on-board magnetometers, and its deriv￾ative can be computed with a finite difference approach. If we substitute this
result in the control magnetic dipole moment, to be actuated by magnetic
torquers, we can prove convergence to zero velocity:
m ¼  k B_
b
744 Stefano Silvestrini et al.Hence, using the previous candidate Lyapunov function:
L_ ¼ 

ub
T
t
b ¼ 

ub
T
 
Bb  kB_
b
!
¼ k


ub
T

Bb  Bb  ub

;
which leads to:
L_ ¼ k


ub
T
Bb

2
ub
In order to have L_  0, we need k > 0. This is because

Bb

2 ¼ 
Bb

Bb


is not a positive definite matrix. In fact, we can express
it as:

Bb

2
¼  
Bb


2
I3 þ Bb


Bb
T;
where the diagonal elements are the most relevant. Moreover, the matrix

Bb

2 changes over time, as the satellite is moving along the orbit, but the
sign won’t change as it is proportional to the norm of the magnetic field.
The B-dot detumbling control law allows to reduce the absolute angular
velocity down to a value of the same order of magnitude as the orbit rate.
Moreover, it allows to achieve this result with only magnetic components
(i.e., magnetometers and magnetorquers) and with a simple GNC architec￾ture. This method has proven to be strongly reliable and effective, and it
became a standard for LEO spacecraft with magnetic actuators. Since the de￾rivative of the magnetic field is commonly numerically computed, a filter
could be employed to reduce the noise levels. Moreover, the B-dot is often
implemented as a bangebang control law, as explained in Ref. [48]. Note
that to avoid feedback from the torquers on the magnetometers, the compu￾tation of the magnetic field derivative should be done during periods in
which the magnetorquers are not actuated. Thus, the sensing and the actu￾ation operations shall be decoupled in time, as also suggested in Chapter 6 e
Sensors. Fig. 14.5 shows an example Monte Carlo analysis, with 100 runs, of
a B-dot detumbling phase for a satellite in Earth orbit.
One-axis pointing
In many mission modes, it is required to point one axis of the satellite in one
direction. This can happen in both the simple Sun pointing mode and in
other special cases. The scope of the single-axis pointing control mode is
to point one axis toward a single target, meaning that we want one direction
of the satellite to coincide with something we want to look at. This can be
Applicative GNC cases and examples 745either the Sun, the Earth, an astronomical object, another satellite, or any￾thing else. The one-axis pointing guidance has been presented in Chapter
8 e Guidance using quaternions; this section discusses the one-axis pointing
attitude control exploiting the pointing error angle.
One-axis attitude control requires just two directions of the torque, t
b,
since the rotation around the target direction is not defined. We can define
the pointing error angle as:
e ¼ cos1

bs
b $ pbb

;
where pbb is the direction in body frame of the target we want to point, and
bs
b is the spacecraft axis we want to align with the target. Thus, we want to
minimize such error by controlling the satellite attitude toward the condi￾tion in which bs
b is aligned with pbb
:
Let us assume, for the sake of simplicity, a reduced dynamical model
where the angular velocities are low (i.e., the nonlinear terms of Euler equa￾tions can be neglected), and the attitude is expressed through a small-angle
approximation with respect to the principal axes of the satellite. This is
equivalent to linearize the attitude dynamics with respect to the reference
Figure 14.5 Monte Carlo analysis of B-dot detumbling.
746 Stefano Silvestrini et al.target-pointing condition. To improve clarity, we also assume bs
b ¼ bx, but
any other generic axis in body frame would be suitable. We can then express
the target pointing direction in the reference frame of the axis of the satellite,
using the small-angle approximation [48]:
pbb ¼ bAi pbi ¼ ðI3  ½dwÞ pbi
;
where dw are the small error angles in the spacecraft body frame, with
respect to the principal axes.
Hence:
bs
b $ pbb ¼ bxTðI3  ½dwÞ pbi ¼ 
1 wz wy

pbi
From which:
e ¼ cos1
 1 wz wy

pbi

.
The pointing error angle is minimized if wy and wz go to zero, confirm￾ing our assumption that only two axes need to be controlled in order to keep
the pointing. The dynamical evolution of the reduced system will then be:
8
><
>:
Iyw€y ¼ ty
Izw€z ¼ tz
.
This is a second-order system, and we can then express the control tor￾que as:
ty ¼  kpywy  kdyw_ y;
giving:
Iyw€y þ kdyw_ y þ kpywy ¼ 0.
which is a harmonic oscillator with well-known properties. Without kdyw_ y,
the system would be undamped and, thus, not stable; hence, the need for a
derivative term is evident. Given the inertia of the system, the tuning of the
proportional-derivative (PD) controller is straightforward.
Let us try to generalize more the concept now. Take the following
candidate Lyapunov function:
L ¼ 1
2


ub
T I ub þ
1
2
kpe
2
Applicative GNC cases and examples 747where kp > 0, and the error is instead taken as e ¼ 1  bs
b
$pbb
, in order to
avoid complications due to trigonometry. Its derivative is:
e_¼bs
b
$


ub  pbb

¼ ub
$


pbb bs
b

The derivative of the Lyapunov function is:
L_ ¼ 

ub
T
t
b þ kpee_ ¼ 

ub
T
t
b þ kpe


ub
T

pbb bs
b

¼ 

ub
T

t
b þ kpe


pbb bs
b
.
Let us define the cross product as a variable, closely linked to the error
between directions:
hb ¼ pbb  bs
b
Then, to achieve asymptotical stability 
L_  0

, we would need to
have:
t
b ¼  kdub  kpe hb
:
This requires the knowledge of ub
, which is not always available. There
are a few options to be used, for example, we could use an approximation
simply using the derivative of hb
; which is closely related to the angular ve￾locity. If we wish to be more rigorous, we could use the following control
law:
t
b ¼  kdhb  h_ b
 kpe hb
:
Substituting into the derivative of the Lyapunov function:
L_ ¼ kd


ub
T
 
 hb  h_b
!
Since h_b ¼ ub  hb ¼ hb  ub
, we have:
L_ ¼ kd


ub
T
hb

2
ub
:
That should satisfy the request for stability with kd > 0. Instead, we
could also have used pbb  _
pbb
, as the implications would not change in the￾ory. However, by definition, hb tends to zero as pbb
/bs
b
, while 
pbb

2
would not go to zero as it will approach 
bs
b

2
, which still does not have
maximum rank.
748 Stefano Silvestrini et al.The single-axis pointing control allows to steer the satellite in one direc￾tion, and as such can be quite robust and used, for example, in safe modes to
point solar panels toward the Sun. In this case, the Sun direction measure￾ments in body frame are needed in order to estimate the control torque
required to align the prescribed body direction with the Sun. For small sat￾ellites, this might also be performed using magnetorquers, which would also
require magnetic field estimation. However, the magnetic application of this
control law would reduce the performance of the controller, since the com￾mand to the torquers depends on the cross product of the magnetic field, as
will be discussed in the followings. This results in only one axis to be fully
controllable and pointed.
Note that this control law is fully applicable to maneuver a spacecraft to a
fixed attitude while driving the angular velocity to zero. It can be extended
to also approximate the pointing control to quasiinertial reference direc￾tions. However, if the target pointing direction is moving, the controller
shall be modified to include a reference time-varying attitude trajectory to
be tracked. Further details can be found in many literature references discus￾sing the attitude-tracking control [48].
Maximize secondary target
Single-axis pointing allows to point a single axis toward a target direction
while keeping relative freedom to rotate around the target axis. This leaves
open the possibility to make use of this degree of freedom to maximize the
pointing of another axis. Clearly, it will not be possible to execute a perfect
pointing with two axes if the angle between target directions is different
from the angle of the body axes.
This implies that there is a way to minimize the error of a secondary
target direction, but this will rarely be null. The control in this case can
be easily derived, as one just need to project the secondary body axes direc￾tion and the secondary target direction on the primary target plane and,
then, compute the relative angle. Once the angle between the two projected
secondary directions is known, a simple additional PD controller can deter￾mine the secondary torque, which has to be aligned with the primary body
axis direction. This additional secondary control action can be included dur￾ing the primary orientation maneuver or after the primary target has been
acquired. Chapter 8 e Guidance presents a dedicated two-axis pointing
guidance algorithm.
Applicative GNC cases and examples 749Three-axis pointing
In the cases, where thesatellite attitude has to be fully controlled, without leav￾ing anything to chances, it is recommended to exploit a full three-axis control
technique, possibly using quaternions, although several alternative options are
available. Theoretically, three-axis attitude control pointing is not possible,
even with quaternions, since any kinematic parametrizations with three com￾ponents have singularities and sets with more components (e.g., quaternions)
have duality issues (e.g., quaternion unwinding). However, under a practical
viewpoint, it is possible to derive stable three-axis control laws.
Let us consider a candidate Lyapunov function:
L ¼ 1
4


ub
T Iub þ gq
1
2


d qT
1:3 d q1:3

þ gq
1
2
ð1  dq4Þ
2
where with dq1:3 and dq4 we, respectively, consider the vector and the scalar
components of the quaternion error, and gq > 0. The quaternion error is
defined as the relative quaternion with respect to the target attitude
quaternion, qt ¼
n
qT
1:3t q4t
oT
, and the estimated attitude, qe, following
the quaternion multiplication rule:
( dq1:3
dq4
)
¼
8
><
>:
cðqtÞ qe
qT
t qe
9
>=
>; ¼
" I3 q4t 
h
q1:3t
i
q1:3t
qT
1:3t q4t
#
qe
The evolution in time of the error is given by the following:
2 dq_
1:3 ¼ dq4ub þ 
dq1:3

ub
2 _ dq4 ¼  d qT
1:3ub
.
The derivative of the candidate Lyapunov function is:
L_ ¼ 1
2


ub
T
t
b þ gq dq T
1:3d q_ 1:3  gqð1  dq4Þ _ dq4
¼ 1
2
h

ub
T
t
b þ gqdq T
1:3ðdq4 þ ½dq1:3Þub
þ gqð1  dq4Þd q T
1:3ub
i
¼ 1
2
h

ub
T
t
b þ gqd q T
1:3ub
i
:
If we use the following control torque:
t
b ¼  gqdq1:3  guub
750 Stefano Silvestrini et al.We would have:
L_ ¼  gu
1
2

ub


2
;
which is negative at the condition that gu > 0, guaranteeing the stability of
the closed-loop system. However, this control low does not guarantee the
shortest path to the final target state, which is an issue if
dq4 < 0 ði:e:; unwinding phenomenonÞ Thus, a slightly modified control
law is suggested to guarantee the shorter path to reach the desired equilib￾rium point:
t
b ¼  gq signðdq4Þ dq1:3  guub
;
which is the PD control to achieve three-axis attitude stabilization.
This is certainly true for static inertial pointing ub ¼ 0; however, this
does not apply in the most general case, as convergence might be reduced
or not guaranteed over the complete attitude phase space. Hence, the con￾trol law described before is valid for inertial pointing, while in the attitude￾tracking case, we need to modify the analysis. Indeed, we need to impose
the dynamics to follow a desired time-varying trajectory.
Let’s modify the candidate Lyapunov function as:
L ¼ 1
4


ub  ut
T I


ub  ut

þ gq
1
2


d qT
1:3 d q1:3

þ gq
1
2
ð1  dq4Þ
2
;
where ut is the target angular velocity in body frame. Under the assumption
of u_ tx0 we obtain:
L_x1
2


ub  ut
T h
t
b þ gq d q1:3  ub  I ub
i
Hence, the proper control law is:
t
b ¼  gq signðdq4Þ dq1:3  gu


ub  ut

þ ub  I ub
:
That is indeed a PD controller in terms of quaternions to achieve a tracking
attitude three-axis pointing. The keen reader should have noticed that we
could have neglected the nonlinear term of the Lyapunov function
uT
t


ub I ub

; whose influence disappears as ub
/ut. In the presented
formulation, this term is anyway present; however, it might be relevant only
for high angular rate, which is generally rare.
The term signðdq4Þ dq1:3 avoids unwinding and instability, reminding
that the direction cosine matrix (DCM) is quadratic in terms of quaternions,
Applicative GNC cases and examples 751such as a positive and a negative quaternion give the same attitude. Howev￾er, it should be noted that the proportional term would be null at 180 de￾grees error ði:e:; dq4 ¼ 0Þ. Hence, to be rigorous in the control, one should
include at least a modified sign function of dq4 that is positive for dq40 and
negative otherwise.
Two loops
Readers familiar with other vehicle control techniques might easily see that
there is also another way to deal with the three-axis attitude control prob￾lem, which is to divide the control function in two smaller concatenated
loops.
If we only consider the attitude problem, we can write the Lyapunov
function as:
L ¼ 1
2
gq


d qT
1:3 d q1:3

þ
1
2
gqð1  dq4Þ
2
/L_ ¼ gq d qT
1:3


ub  ut

.
Thus, if we guarantee that ub
/ut  gqsignðdq4Þ dq1:3 ¼ ur, we
guarantee convergence of the attitude loop. Hence, going back to the dy￾namics problem and taking this additional candidate Lyapunov function:
L ¼ 1
2


ub  ur
T
I


ub  ur

;
we can derive it with respect to time obtaining:
L_ ¼ 

ub  ur
T I

u_ b  u_ r

¼ 

ub  ur
T
t
b  ub  I ub  I u_ r

.
Thus, the following control law allows the dynamic loop to converge to
the desired velocity:
t
b ¼ ub  I ub þ I u_ r  gu


ub  ur

This control law is quite general, and it can be used for any ur profile. If
we substitute the expression of ur, we get:
t
b ¼ ub  I ub þ I u_ r  gu


ub  ut

 gugqsignðdq4Þ dq1:3;
which is pretty similar to the one we discussed in the previous section. In
practical terms, u_ r could be computed via numerical derivation, instead of
evaluating its elements, or, in some cases, it could be neglected similarly to
ub  Iub
.
752 Stefano Silvestrini et al.As for what concerns the weights of the PD controller, it is straightfor￾ward to use a small-angle approximation to apply the classic control theory,
which has been presented in Chapter 10 e Control. If the two loops strategy
is implemented, then it would be wise to set the cut-off frequency of the
inner dynamic loop at least one decade higher than the one of the outer ki￾nematic loop, in a way to reduce cross-effects.
Effects of disturbances
All these control examples have so far neglected the existence of distur￾bances, but these are always present. As previously mentioned, if the distur￾bances and the perturbations do not sum up over time, and their magnitude
is reasonably smaller than the control action; then, the previous control laws
should be sufficient. However, in many cases, the disturbances happen to
have a continuous, nonnull action that would set the steady-state control er￾ror to a static nonzero value.
A common strategy in this case is to introduce in the controller an inte￾gral term based either on the angular velocity error or on the attitude error.
To better visualize these two alternative possibilities, let us consider the two￾loop scenario. If we place the integral term on the dynamic loop, it will
reject only static disturbances given by the space environment; while, if
we place it on the outer kinematic loop, it might also reduce the errors
induced by the time-varying target reference signals.
Introducing integral terms in the control loop should be done with care,
since they introduce delays that may reduce performances and control stabil￾ity. This is especially true in those cases where the angular velocity of the
target reference is high and time-varying. An example could be a ground sta￾tion pointing case, where the satellite must quickly swipe to correctly point
the antenna to guarantee communications. Moreover, since the integral ac￾tion accumulates over time, proper saturations, resets, and antiwindup stra￾tegies must be implemented in the proportional-integral-derivative control
algorithm.
Control with reaction wheels
Reaction wheels are used to control the spacecraft attitude by exchanging
angular momentum with the satellite. Thus, they do not produce an
external torque, since they are based on acceleration and deceleration of
spinning rotors. Usually, when the nominal spin rate of the rotor is not
maintained on a nonzero reference value, the actuator is denoted as reaction
Applicative GNC cases and examples 753wheel; alternatively, when a nonzero offset spin rate is desired, the actuator is
called inertia wheel. The latter is commonly used when a dual-spin attitude
stabilization is sought (cfr. Chapter 5 e Attitude Dynamics). In some cases,
the distinction between the two categories is not evident, and all these ac￾tuators can be classified as reaction wheels.
The general problem of control angular exchange devices can be
modeled by writing the appropriate set of Euler equations, including the ef￾fects of the n actuators in the expression of the angular momentum:
hb ¼ I ub þ hb
rotors ¼ I ub þ R hr
rotors;
where R is the 3  n configuration matrix introduced in Chapter 7 e
Actuators, and hr
rotors is a column vector with n elements representing the
angular momentum of each reaction wheel.
Assuming the term I ub is considering the presence of the rotors with no
relative velocity, and that t
b represents the disturbance torque, the attitude
dynamics becomes:
I u_ b þ ub  I ub þ I_ ub þ R h _ r
rotors þ R h_r
rotors þ ub  R hr
rotors ¼ t
b
;
and we need to include the equations of the relative dynamics of the
rotors:
R h _ r
rotors þ R h_r
rotors ¼ R tr
rotors;
where t
r
rotors is a column vector with n elements representing the torques
applied on each wheel.
The terms in the attitude dynamics equations depend on the specific
actuator in use:
• I_ ub is present only for CMGs, and it can be neglected if their inertia is
small compared to the spacecraft one. Note that this term is also present
when internal moving masses or inertia variations are present (e.g., fuel
consumption, sloshing, robotic arms, etc.)
• R h _ r
rotors exists only for CMGs, and it indicates the configuration vari￾ation in the spacecraft body frame. With reference to Chapter 7 e Ac￾tuators, the configuration matrix variation has been expressed for the
CMGs as C q_ G:
• R h_r
rotors is the spin rate variation term. It exists for reaction and inertia
wheels, and it is usually zero for CMGs, since they commonly have con￾stant spin rate.
754 Stefano Silvestrini et al.• ub  R hr
rotors exists for any actuator, and it represents the rotor’s
angular momentum coupling with the angular rates of the spacecraft.
To solve the control problem, we can group these four terms in the con￾trol torque term as:
t
b
control ¼  I_ ub  R h _ r
rotors  R h_ r
rotors  ub  R hr
rotors:
When the desired control torque to be commanded has been computed,
the previous equation can be used to solve the effective actuation actions to
be sent to the specific actuators in use. For instance, let’s assume to have only
reaction wheels with same spinning inertia, Irotors ; we can write:
8
>>>>><
>>>>>:
I u_ b þ ub  I ub ¼ t
b þ t
b
control
t
b
control ¼ R h_ r
rotors  ub  R hr
rotors
h_ r
rotors ¼ Irotors u_ rotors ¼ t
r
rotors
:
Any control design technique discussed in Chapter 10 e Control can be
used to calculate t
b
control after which t
r
rotors can be evaluated as:
8
><
>:
R h_r
rotors ¼ t
b
control  ub  R hr
rotors
h_r
rotors ¼ Ry


t
b
control þ ub  R hr
rotors ;
where Ry is the pseudoinverse of R, as discussed in Chapter 7 e Actuators.
Then, the command to be actuated on the wheels is simply available as:
t
r
rotors ¼  Ry


t
b
control þ ub  R hr
rotors
;
where we neglected the loss torques on the rotors, or we assumed the re￾action wheels to be equipped with a motor controller unit that is capable to
achieve the desired t
r
rotors regardless of the internal friction and disturbances.
Desaturation
Looking at the equations for reaction wheels and, in general, for momentum
exchange actuators, we may notice that they do not generate any external
torque, but they exchange angular momentum with the spacecraft main
body by means of internal torques, t
r
rotors.
The torque t
r
rotors is, in general, provided by an electric motor that has its
typical operational curve, which is a function of its angular speed. Despite
Applicative GNC cases and examples 755the variability of electric motor characteristic, it is commonly seen that there
is a spin rate for which the available torque falls to zero. This is called satu￾ration speed, and, when the rotor reaches this speed, the motor can provide
no additional torque in the direction of the increasing spin rate. Hence, it
requires a special desaturation mechanism to make it again fully operational.
In general, momentum exchange actuators are operated in order to keep
them within the speed range for which the available maximum torque of the
electric motor is approximately constant. In this way, the actuator can be
modeled as a linear device if commanded by a current in the armature. If
the control torque is more or less periodic, the actuator shall be sized in a
way to be always maintained within its linear functioning regime. If the con￾trol torque is the combination of a periodic component and a secular
component (i.e., to balance a nonsymmetric external perturbation), it will
be inevitable to reach the saturation speed. In the case the secular compo￾nent of disturbances is persistent, several desaturation maneuvers are
required and they shall be scheduled within the sequence of routine opera￾tions. Moreover, the reader is invited to notice how angular exchange actu￾ators are not suitable for detumbling or angular momentum dumping
control. Indeed, the satellite spin rates would be accumulated in the rotors,
leading to the wheel saturation.
Desaturation, or momentum dumping, or momentum unloading mech￾anisms must apply a net external torque to the satellite; therefore, they are
based on thrusters or on magnetic torquers. Then, the desaturation control
torque is designed to dump-out the excessive angular momentum stored in
the rotors:
t
b
control ¼  k hb
rotors.
This torque is actuated by the external torque devices, while the angular
momentum exchange actuators are unloaded.
The desaturation control law can also be continuously active to dump
excess momentum during the mission control modes. In this case, two
cascade control loops are present: the main attitude stabilization loop and
a lower priority loop with the task of desaturating the momentum exchange
actuators. The former uses the momentum exchange devices, while their
momentum is simultaneously regulated by the second control loop acting
on the external torque actuators (i.e., magnetorquers, thrusters, etc.) [46].
756 Stefano Silvestrini et al.Control with magnetorquers
Satellites in LEOs can make extensive use of magnetic actuators, coupling
with the magnetic field, to give rise to an external torque. The advantage
is their reduced mass, low costs, and potentially infinite control action.
However, there are some drawbacks that limit their functionalities, as dis￾cussed in Chapter 7 e Actuators. Indeed, these actuators can only work
when strong magnetic fields are available, they cannot produce full three￾axis stabilization, and they require magnetic measurements that can be influ￾enced by their own actuation.
We can write the torque generated by such actuators as:
tMAG ¼ m  B ¼ ½B m.
The goal would be to define a rule to command the magnetic dipole m
and achieve the required control torque tcontrol. All the previous quantities
are expressed in body frame, but the frame superscript has been omitted for
conciseness. ½B is the cross product matrix, which is singular and, thus, it
cannot be inverted. This reflects the fact that it is not possible to provide
three independent components of the magnetic control torque because of
the cross-product operation.
A possible solution to this problem would be to compute the magnetic
dipole as:
m ¼ 1
kBk2 ½B tcontrol
In fact, substituting in the control torque expression, we get:
tMAG ¼  1
kBk2 ½B
2 tcontrol
and the matrix ½B
2 can be rewritten in a way that would give:
tMAG ¼ tcontrol  BBT
kBk2 tcontrol:
where the outer product matrix BBT divided twice by the norm projects the
desired control torque on the plane orthogonal to B. Thus, with this control
method, the useless part of the desired control torque (i.e., the one that is in
the direction of BÞ is canceled out. Note that, in this way, the magnetic
control is equal to the desired one only if the desired control, tcontrol, is
really orthogonal to B. In general, if magnetorquers are the main control
actuators of a satellite, it is suggested to create a control law without passing
Applicative GNC cases and examples 757by the general control torque definition. In such a way, the control law
specializes for the magnetic actuators and the effectiveness of such a control
is improved [49].
Let’s assume a single-axis pointing with maximization of a secondary axis
along a different axis of the spacecraft. In particular, we would like to align
the nadir direction (i.e., r) with the x-axis of the principal body frame, and
the velocity vector with the body y-axis. The control law is the PD one dis￾cussed for the single-axis pointing. Note that the main pointing direction is
not inertially fixed and, thus, the derivative error is computed with respect
to orbital angular rate, in order to maintain the x-axis pointing to the Earth.
The secondary direction (i.e., v) is generally not orthogonal to the main one,
but as described before, the secondary control loop minimizes the error
angle between the secondary directions in the plane orthogonal to the pri￾mary one. Fig. 14.6 reports an example of this single-axis pointing control
with magnetic actuators. In particular, the spacecraft in the example is orbit￾ing on a 600 km Sun-synchronous orbit, it has a mass of 1.5 kg, and uses
three magnetic torquers with maximum available dipole of 0.5 Am2
. The
magnetic control is able to dissipate the initial angular rates and orient the
primary axis in about 2 h. The steady-state error with respect to nadir is
in the order of 10 degrees.
Figure 14.6 Single-axis magnetic control example.
758 Stefano Silvestrini et al.Solar panels pointing
Solar panels pointing is a crucial task for an ACS, and it must be guaranteed
even after multiple failures have occurred on-board. In these regards, it is
possible to directly exploit the solar arrays as coarse Sun sensors to align
the spacecraft to the Sun and achieve a single-axis Sun pointing, with the
actuators only providing a torque along two axes in the plane orthogonal
to the normal direction of the solar panels. The Sun direction estimation ex￾ploits the current/voltage sensing capacity of the electrical power subsystem
to measure the Sun angle with respect to the arrays normal. It shall be noted
that common spacecraft have the solar arrays deployed along a single body
axis, with all the solar cells lying in a single plane. Hence, the complete
Sun direction vector cannot be estimated from the electric measurements,
and the Sun error axis is not known.
With these limiting assumptions, it is anyway possible to implement a
GNC system that is capable to acquire the Sun and orient the solar arrays
in a way to maximize the electric power generation. The estimation algo￾rithms are based on the cosine law for the solar cells, also presented in
Chapter 6 e Sensors, and on a time-average for signal smoothing. The con￾trol loop is a classic PD law, which exploits a sequenced pulsed modulation
to select the correct axis to rotate the spacecraft and align the solar arrays,
despite the true error axis is not known. Fig. 14.7 reports the Sun acquisition
and panels alignment with this simple and reliable pulsed sequential PD con￾trol law. The complete description of an example of this ACS is discussed in
Ref. [50].
Robust attitude control of a spacecraft with two rotating
flexible solar arrays
In this applicative GNC example, it is shown how to model a flexible space￾craft with two rotating solar arrays and how to synthetize an ACS, robust to
parameter uncertainties.
Let consider the spacecraft S C in Fig. 14.8. The spacecraft is composed
of:
• the main body B with its center of gravity B, its reference point Ob, and
its body frame R b,
• two symmetrical flexible solar arrays A 1 and A 2 connected to B at the
points P1 and P2, respectively, through a revolute joint. Ai, Oai
, and R ai
are the center of gravity, the reference point, and the body frame of A i
(i ¼ 1; 2).
Applicative GNC cases and examples 759The angular configurations of the two solar panels are symmetrical: q1 ¼
q and q2 ¼ q. In Fig. 14.8, R ai
ð0Þ and R ai
ðqÞ represent two geometric
configurations of ℛai for the nominal configuration (qi ¼ 0) and for a given
angle qi. 
DS C
B
1
R b
ðs; qÞ is the model of the spacecraft at the center of gravity B
of the main body B and projected in the main body frame axes R b for a
given angular configuration q, that is the 6  6 transfer between:
• the resultant external wrench h
Wext=B;B
i
ℛb
(six components: three
forces and three torques) applied to B at the point B,
• the dual vector of acceleration of point B
h
x€B
i
R b
(six components: three
translations, three rotations).
Each revolute joint i adds in the model a single-input single-output
(SISO) channel between:
• the torque ui applied by B to A i around xai inside the revolute joint,
• the relative acceleration d€qi of A i w.r.t. B around xai
.
Figure 14.7 Solar panels pointing with pulsed sequential proportional-derivative con￾trol [50].
760 Stefano Silvestrini et al.To hold the angular configuration of A i w.r.t. B at the value qi, the
driving mechanism inside the revolute joint is modeled as a simple stiffness
kiðNm =radÞ, a viscous friction fiðNms =radÞ, and an internal disturbing tor￾que piðNmÞ:
ui ¼  kidqi  fid_
qi þ pi
Substructuring modeling
The spacecraft can be modeled in a multibody philosophy by assembling
three different models corresponding to its building substructures. The
approach we use is the two-input two-output Port (TITOP) framework
[2,3].
Figure 14.8 Spacecraft with two flexible rotating solar arrays.
Applicative GNC cases and examples 761Let us consider a flexible body L i as in Fig. 14.9 connected to a parent
structure L i1 at the point P and to a child structure L iþ1 at the point C.
The resulting TITOP model DL i
PCðsÞ, schematized in Fig. 14.9, is a 12  12
linear dynamic model function of the Laplace variable s whose inputs are:
• WL iþ1=L i;C: the 6  1 wrench (forces and torques) applied by the body
L iþ1 to L i at point C;
• x€P: the 6  1 inertial acceleration (linear and angular) imposed by the
parent body L i1 at point P to L i;
and the conjugated outputs are:
• x€C: the 6  1 components of the inertial acceleration of point C;
• WL i=L i1;P: the 6  1 wrench applied by L i to the parent structure
L i1 at point P.
All these input/output variables are projected in the body frame.
An extension of this basic TITOP model can be easily done for bodies
with multiple child nodes [4].
Many elementary structures (rigid bodies, beams, plates, etc.), complex
flexible bodies (finite element models, liquid sloshing, etc.), and mechanisms
(reaction wheels, solar array drive mechanisms, robotic arms, etc.) can be
modeled in this approach. A user-friendly MATLAB/Simulink toolbox
has been developed, the Satellite Dynamics Toolbox library [5,6] that
(A)
(B)
Figure 14.9 TITOP scheme and nomenclature for a generic flexible appendage L i.
762 Stefano Silvestrini et al.integrates all these elements and allows an easy assembling of a complex mul￾tibody space system.
Main body
The inverse multiport TITOP model h
DB
P1;P2;.;Pn
i
R b
1 of a rigid body B
with several attachment points P1; P2; .; Pn and center of mass B is shown
in Fig. 14.10.
Here the matrices ½sPiB
ℛb represent the kinematic model between point
Pi and B:
½sPiB
R b
¼
2
4
I3 *

PiB !
03x3 I3
3
5
where *

PiB !
is the skew-symmetric matrix associated with the vector
PiB !. If PiB ! ¼
2
6
6
4
x
y
z
3
7
7
5
R i
, where R i is an inertial frame, then:
h
*

PiB !i
R i
¼
2
6
6
4
0 z y
z 0 x
y x 0
3
7
7
5
R i
Figure 14.10 Multiport inverse TITOP model of a rigid body.
Applicative GNC cases and examples 763By referring to Fig. 14.11, the following data (all expressed in the body
frame ℛb) are used for the current case study:
• geometry (in m): 
OP !1
	
R b
¼ ½ 0:4 1:4 0:5 
T ,

OP !2
	
R b
¼ ½ 0:4 1:4 0 
T ,

OB !	
ℛb
¼ ½ 0:35 1:5 0:5 
T
• mass: mB ¼ 1000 kg
• 3  3 inertia tensor at B:

J
B
B

ℛb ¼
2
6
6
4
75 1 2
1 40 1
2 1 80
3
7
7
5


kg m2

Flexible solar array with revolute joint
Let us consider the flexible body A connected to a parent body P through
a revolute joint at a point P in Fig. 14.12. The 7  7 TITOP model of this
system is composed of:
• The 6  6 channels from the absolute acceleration twist of the point P to
the wrench applied by the body A on the parent body, expressed in the
parent body frame R p,
• The 1  1 channel from the driving torque applied inside the revolute
joint to the relative acceleration of the joint.
By referring to Fig. 14.12, the following parameters can be defined:
• R a: the body frame attached to A ,
• R p: the body frame attached to P ,
• ra: the direction of the revolute joint axis and era a unitary vector along
this direction,
Figure 14.11 Main body geometry.
764 Stefano Silvestrini et al.• q: the angular configuration of the revolute joint: ℛa is obtained from
R p by a rotation of q around ra,
• O and G: the reference point and the center of mass of body A ,
• Cm: the driving torque which can be applied inside the revolute joint by
an external driving system,
• €q: the relative angular acceleration of the body side shaft with reference
to the parent side shaft,
•
h
x€P
i
R p
¼
"
aP
u_
#
R p
: the absolute acceleration twist (6  1) of point P,
expressed in R p,
•
h
WA =;P
i
R p
¼
"
FA =;P
WA =;P
#
R p
: the wrench (6  1) applied by the body
A on the parent body, at point P, expressed in R p.
The TITOP dynamic model of the assembled system of flexible body
and revolute joint is denoted as 
GA þr P ðsÞ
17
R p , and it is represented by
the block diagram in Fig. 14.13.
The detailed TITOP model is provided in Fig. 14.14. The following pa￾rameters of the flexible appendage are needed:
• Frequencies ui and damping ratio zi (i ¼ 1;.; N) of the N flexible
modes
Figure 14.12 Schematic view of a flexible body with revolute joint.
Applicative GNC cases and examples 765• The Nx6 matrix of modal participation factor LP with respect to point P
• The residual mass DA
P0 of the body A at point P
For the revolute joint, the following parameters have to be defined:
• Jr: Inertia of the output shaft.
• DCMz: Direction cosine matrix which defines a new frame ℛz such that
the z-(third) axis of the new frame R z is aligned with the revolute joint
axis direction.
• RðqÞ: Direction cosine matrix between R a and R p. This matrix can
be parametrized with the tangent of the quarter angle: s ¼ tan
q
4

to derive a linear fractional transformation when q is a varying
parameter [7].
Figure 14.13 TITOP model of a flexible body with revolute joint.
Figure 14.14 Internal dynamics of TITOP model of a flexible body with revolute joint.
766 Stefano Silvestrini et al.In the study case, the flexible appendages are the two identical solar ar￾rays A 1 and A 2. A 1 is shown in Fig. 14.15 and its data are:
•

Oa1A1
!	
R a1
¼ ½ 2:07 0 0 
T ðmÞ;

Oa1P1
!	
R ai
¼ ½ 000 
T ðmÞ
• Mass: mA 1 ¼ 43 ðkgÞ
• Inertia tensor at A1:
h
J
A 1
A1
i
R a1
¼
2
6
6
4
17 0 0
0 62 0
0 0 80
3
7
7
5


kg m2

• Vector of frequencies: u ¼ ½ 5:6 19:3 35:4  rad=s
• Common damping ratio for the flexible modes: z ¼ 0:005
• Modal participation factors:
2
6
6
6
6
4
0 0
0 0
0 0
5:12003:842:970
12:5 0
0 0
2:51 0
3
7
7
7
5
ð ffiffiffiffiffi
kg p ; m ffiffiffiffiffi
kg p Þ
Figure 14.15 Assembled spacecraft in TITOP framework.
Applicative GNC cases and examples 767The revolute axis direction of A 1 is ½ra1
ℛa1 ¼ ½ 100 
T , while for
A 2 is ½ra2
R a2 ¼½100 
T .
Assembling of the whole spacecraft
The assembled spacecraft in TITOP framework is shown in Fig. 14.15. Note
that the in-joint stiffness and friction ki and fi model a solar array drive
mechanism.
For the numerical application: k1 ¼ k2 ¼ 50000 Nm=rad, f1 ¼ f2 ¼
100 Nms=rad.
Moreover, the exogenous inputs p1 and p2 represent the harmonic
disturbance induced by the driving mechanisms.
Fig. 14.16 shows the Bode diagram of the transfer function between the
3  1 vector of external torques h
Wext=B ;P3
i
R b
f4 : 6g applied at the center
of mass of the central body P3 and the angular accelerations h
x€P3
i
ℛb
f4 : 6g
of point P3: Notice that the system dynamics varies according to the para￾metric uncertainties listed in Table 14.5. In MATLAB, this parameter can
be declared as ureal, thanks to the Robust Control Toolbox [8].
Robust attitude control synthesis
In this section, we show how to synthesize a robust ACS in order to meet
some pointing and stability requirement in face of all system uncertainties.
The ACS architecture is shown in Fig. 14.17.
The basic idea is to use the combined measurements of a gyroscope
(GYRO) and a star tracker (SST) to drive three control reaction wheels ori￾ented in the three directions of the main body axes.
In Fig. 14.17, we can distinguish the following parameters:
• Spacecraft dynamics h
DS C
P3
i
R b
ðs;D; siÞ is the uncertain model of the
spacecraft showed in Fig. 14.15, where the blocks D and si include all
uncertainties in Table 14.5.
• GYRO is the dynamical model of the gyro:
GYRO ¼ 400p
s þ 400
I3
• SST is the dynamical model of the star tracker:
SST ¼ 16p
s þ 16p
I3
768 Stefano Silvestrini et al.Figure 14.16 Bode diagram of the transfer h
Wext=B ;P3
i
R b
f4 : 6g among the external
torques and the angular acceleration of the spacecraft.
Table 14.5 Parametric uncertainties.
Parameter Notation Nominal value Uncertainty
Main body mass mB 1000 kg  20%
Main body inertia x-axis 
J
B
B
xx
ℛb
75 kg m2  20%
Main body inertia y-axis 
J
B
B
yy
R b
40 kg m2  20%
Main body inertia z-axis 
J
B
B
zz
R b
80 kg m2  20%
Solar arrays first mode
frequency
u
A i
1
5:6 rad=s  20%
Solar arrays second
mode frequency
u
A i
2
19:3 rad=s  20%
Solar arrays third mode
frequency
u
A i
3
35:4 rad=s  20%
Solar arrays rotations si ¼ tan qi
4 0 ½1O1
Applicative GNC cases and examples 769• Gyro noise, whose amplitude spectral density (ASD) is modeled with the
weighting filter:
WGYRO
n ¼ 1e
5
I3
rad
s
= ffiffiffiffiffiffi
Hz p
• Star tracker noise, whose ASD is modeled with the weighting filter:
WSST
n ¼ 1e
4
I3
rad
ffiffiffiffiffiffi
Hz p
• Reaction wheel dynamics:
RW¼ ð200pÞ
2
s2 þ 1:4$200p þ ð200pÞ
2I3
• ACS loop delay is modeled as a second-order Pade of time delay
dtAOCS ¼ 0:01 s:
DELAY ¼ PADEðdtAOCS; 2ÞI3
• The weighting filter WEXT normalizes the input external torques to their
expected upper bound:
WEXT ¼
2
6
6
4
0:03 0 0
0 0:01 0
000:02
3
7
7
5
ðN mÞ
Figure 14.17 ACS architecture.
770 Stefano Silvestrini et al.• The weighting filter WAPE normalizes the spacecraft attitude error
QS C and overbounds the expected absolute performance error (APE):
WAPE ¼
2
6
6
6
6
6
6
6
4
0:01p
180
0 0
0 0:01p 180 0
0 0 0:05p 180
3
7
7
7
7
7
7
7
5
1


rad1
The chosen ACS controller structure is a decentralized PD controller
with a low-pass filter per axis.
The parameters to be tuned are thus the proportional gains Kx
p , Ky
p , and
Kz
p , the derivative gains Kx
v , Ky
v , and Kz
v , and the cut-off frequencies of the
three low-pass filters wx, wy, and wz (Fig. 14.18).
Figure 14.18 ACS control law K_ACS.
Applicative GNC cases and examples 771The optimization problem can be expressed in a robust control frame￾work as:
n
Kb x
p ; Kb y
p; Kb z
p ; Kb x
v; Kb y
v; Kb z
v; wbx
; wby
; wbz
o
¼ min
KACS
Jc
¼ min
KACS
max
D;si














P2
6
4en
GYRO
en
SST
3
7
5/T
ðs;D; si; KACSÞ














2
Such that:
8
>><
>>:
g1 ¼ max
D;si





Pe
Text/QeS C ðs;D; si; KACSÞ





N
< 1
g2 ¼ max
D;si
kPText/Tðs;D; si; KACSÞkN < 1:5
The optimization criterium min KACS
Jc minimizes the H 2-norm (variance)
from the normalized noise of both SST (neSST) and GYRO (neGYRO) to
the input torque T of the spacecraft in order to minimize the amplification
of the sensor noise to the actuation effort.
The hard constraint g1 translates in the sense of H N-norm the require￾ment on the demanded APE pointing performance in face of the expected
input external disturbance.
The second hard constraint g2 imposes finally an H N-norm of the
sensitivity function smaller than 1.5, that ensures:
• A modulus margin bigger than 1
g1
¼ 0:666,
• A gain margin bigger than g1
g11 ¼ 3 ð6 dBÞ,
• A phase margin bigger than 2 arcsin 1
2g1
¼ 38:9 degree.
Notice that the optimization problem has also to guarantee an optimal
solution valid for the whole set of parametric uncertainties.
The routine systune available in the MATLAB Robust Control Toolbox
[8] and based on the nonsmooth optimization algorithm [9,10] allows to
easily solve this optimization problem.
The results are provided in Table 14.6. We see that the variance of the
noise has been reduced while satisfying both constraints on pointing require￾ment and sensitivity function by coping with all system uncertainties.
772 Stefano Silvestrini et al.With systune we can also recover the worst-case configuration, that
means the values of the set of uncertain parameters for which we obtain
the worst performance. Table 14.7 resumes their values:
Moreover, we can verify that the two constraints on pointing perfor￾mance and sensitivity function are both verified by looking at the singular
values of:
• The transfer Pe
Text/QeS C 

s;D; si; Kb ACS
of the optimized plant for the
pointing requirement in Fig. 14.19.
• The transfer PText/T


s;D; si; Kb ACS of the optimized plant for the
sensitivity requirement in Fig. 14.20.
We can notice that the H N-norm stays below 1 for the pointing
requirement and below 1.5 for the sensitivity requirement.
We can finally verify the classical SISO stability margins by opening the
closed loop in correspondence of the system input torque T. Fig. 14.21
shows the three Nichols plot for the diagonal terms of the transfer between
input torque and spacecraft attitude angles.
One can check that the axis-per-axis stability margins (gain margins and
phase margins) are largely better than the conservative lower bounds
induced from sensitivity function requirement.
Table 14.6 ACS optimization result.
bJ c gb1 gb2 Kbx
p Kby
p Kbz
p Kbx
v Kby
v Kbz
v wb x wb y wb z
0.042 1.00 1.00 172.43 57.72 22.99 163.80 102.93 33.31 11.11 0.98 1.71
Table 14.7 Worst-case configuration.
Parameter Nominal value Uncertainty Worst-case value
mB 1000 kg  20% 800 kg

J
B
B
xx
ℛb
75 kg m2  20% 60 kg m2

J
B
B
yy
R b
40 kg m2  20% 32 kg m2

J
B
B
zz
R b
80 kg m2  20% 64 kg m2
u
A i
1
5:6 rad=s  20% 4:48 rad=s
u
A i
2
19:3 rad=s  20% 23:16 rad=s
u
A i
3
35:4 rad=s  20% 42:48 rad=s
si ¼ tan qi
4 0 ½1 O1 1
Applicative GNC cases and examples 773Figure 14.19 Pointing requirement verification.
Figure 14.20 Sensitivity requirement verification.
774 Stefano Silvestrini et al.Relative GNC
Relative GNC applications are dedicated to control the motion of a
spacecraft relatively to other orbiting objects. The GNC functions are based
on the relative dynamics equations presented in Chapter 4 e Orbital Dy￾namics. The relative GNC is commonly applied to proximity operations,
such as rendezvous and docking, fly around, on-orbit inspection, and on￾orbit servicing; to formation flying and to any other application that impose
any requirement on the relative states between two or more spacecraft.
Relative dynamics applications typically require real-time operations and
a great autonomy level on the spacecraft. Thus, they cannot be assisted from
ground and they commonly require all the GNC functions to be imple￾mented on-board. For this reason, relative spacecraft dynamics was the first
application of fully space-based GNC systems, and most of the develop￾ments for spacecraft autonomy were motivated by the requirements of prox￾imity operations in space.
Guidance for relative and proximity maneuvers
The recent advances in spacecraft GNC unlocked daring missions involving
orbital maneuvers in close proximity. Despite the first human-in-the-loop
rendezvous missions date back to the 1960s, the enabling technology that
now allows such missions is the development of autonomous GNC systems.
Indeed, due to the close relative distances and the need for prompt reactions,
impose the spacecraft to be capable of taking decisions rapidly and
Figure 14.21 Nichols plots of the three spacecraft attitude axes.
Applicative GNC cases and examples 775autonomously. As discussed in Chapter 9 e Navigation, the navigation re￾quires dedicated sensors to perform relative and proximity operations. On
the other hand, the control system typically relies on the same actuators
used for other phases of the missions or at least the same type. Finally, as dis￾cussed in Chapter 8 e Guidance, the guidance system can be tailored to
derive optimal trajectories in a relative scenario. It is important to remark
that, from the algorithms point of view, all the algorithms can be applied
in the absolute scenario as in the relative one, providing that the constraints
and capabilities of the system are the same for both.
In order to design effective maneuvers and proximity operations, it is
critical to exploit the natural dynamics of the system. Hence, the design pro￾cess is highly dependent on the trajectory design. In this section, we will go
through some examples of potential strategies to design trajectories and al￾gorithms for relative maneuvers with multiple agents.
Trajectory design and sensors selection
The trajectory design is highly dependent on the requirements of the
mission. For instance, let us assume we want to fly around an object and
perform images acquisition and perform optical navigation with respect to
the target. Moreover, the design of the relative distances and attitude is
dependent on the sensors adopted on-board, as discussed in Chapter 9 e
Navigation. With respect to the selection of vision-based sensors, a nonex￾haustive set of specific criteria for monocular or stereo camera is:
• Operational range. The first consideration to be made concerns the size of
the spacecraft, that constrains not only the available volume for the in￾strument but also more importantly the baseline between the camera’s
axes, to be exploited for stereovision if selected. Such baseline b can be
in the order of 30 cm (e.g., CubeSat), drastically reducing the operational
range of the instrument. The disparity computed as difference of the two
stereo frames is inversely proportional to the distance from the target. An
estimation of the operational range of a stereo camera can be done
computing the error on the target distance:
z ¼ f $b
d
where b is the baseline, f the focal length, and d the disparity. For example,
with b ¼ 30 cm; f ¼ 100 mm, and a pixel of 10 mm; a disparity of 1 pixel
corresponds to an estimated distance of 3000 m, while a disparity of two
776 Stefano Silvestrini et al.pixels corresponds to an estimated distance of 1500 m, causing a potential
error of 1:5 km when at 3000 m from the target. In other words, in this case,
the operational range of a stereo camera is very limited.
• Resolution. The resolution depends on the array size and distance from
the target. For the stereo camera, there’s the additional constraint of
the Field of View (FoV) superposition.
• Data type. A stereo camera gives the possibility to directly retrieve 3D
data, whereas the monocular camera delivers only 2D. It has to be
noticed that data from monocular cameras can be elaborated on￾ground and 3D information can be extracted as well with standard im￾age processing algorithms.
To have full visibility of the target, relative motion of the chaser needs to
be exploited. The relative trajectories must be passively safe; hence, natural
motion shall be explored to achieve relative orbits, which do not threaten
the safety of the image target phase. The imposed criteria to run the selection
of the imaging relative trajectories are:
• Passive safety compliance that can be achieved.
• Variance of geometrical coverage with respect to target attitude motion which
shall be minimized.
• Sun-phase angle and FoV acquisition during target pointing operations. FoV
acquisition is intended as the objects, beside the target, that fall within the
FoV (Sun, Earth, etc.).
One common approach for relative inspection is to exploit in-plane mo￾tion of the chaser around the target (cfr. Chapter 4 e Orbital Dynamics).
Using an in-plane motion, the relative orbit can be designed to be bounded
and centered on the target. This makes trajectory design easier to handle.
Nevertheless, constraining the trajectory to lay on a plane can be risky in
terms of target coverage. If the target attitude motion is not known, planar
motion may not be sufficient for the complete imaging accomplishment.
For instance, a target spinning along the h-bar would prevent the chaser
from imaging the faces directed in the h-bar direction. Moreover, the rela￾tive orbit crosses the v-bar twice in its natural motion, as shown in
Fig. 14.22. Such shortcoming may be solved by inserting an across-track
component, i.e., out-of-plane motion, as shown in Fig. 14.22. An additional
step, which synthesizes the advantages of cross-track motion is to foresee
passive trajectories that drift along the v-bar coupled with a cross-track mo￾tion component. In this way, the full coverage of the target can always be
guaranteed, given the range of relative attitude during the inspection phase.
Applicative GNC cases and examples 777Therefore, as far the relative trajectory possible strategies are concerned,
three alternatives are valuable for consideration:
• In-plane relative motion. Two v-bar crossing weakening passive safety and
not robust to resonant attitude motion.
• Out-of-plane relative motion. Increased target coverage but Earth in FOV
when the trajectory is centered on the target.
• Drifting relative motion. Complete target coverage regardless of attitude
motion and FOV acquisition and occultation limited.
As reported in Chapter 4 e Orbital Dynamics, in the section about rela￾tive dynamics, the relative orbital elements (ROEs) can be used to design
relative trajectories efficiently and effectively. As already mentioned, such
parametrization allows to have a direct control of the relative trajectory ge￾ometry by using the invariant ROE. It is worth remarking that this approach
is equivalent to the consolidated parametrization of absolute orbits: a specific
orbit is identified by the orbital elements and not the inertial state.
For this reason, here a use case to design relative trajectories based on the
definition of ROE is reported. Let us go back to the example where we
want to fly around a target.
Figure 14.22 Target relative trajectory design. Planar de s 0 (left), out-of-plane di s 0
(middle), drifting da s 0 (right).
778 Stefano Silvestrini et al.A planar fly around where an elliptical relative orbit is generated by the
difference in eccentricity, i.e., de s0: A relative drift can be imposed by a
difference in the semimajor axis, which determines the relative velocity.
The planar motion may be restrictive in terms of imaging coverage.
Another solution is to introduce an out-of-plane motion by inserting a
difference in the inclination between the chaser and the target. The relative
drift is achieved as above. The differential J2 perturbation is dependent on
the true difference in inclination, Di, which corresponds to dix, hence we
would like to have the relative inclination vector only with diy component.
Recalling section relative dynamics in Chapter 4 e Orbital Dynamics, to
make sure that passive safety is achieved, we impose that the maximum radial
distance is achieved when the across-track distance vanishes. In other words,
we impose that when the spacecraft crosses the target orbital plane, the radial
distance is maximum. To achieve this, the orbits are design imposing de and
di parallel.
A summary of the strategy for increasing the outcome of the proximity
phase entails (please refer to Chapter 4):
• The planar trajectory (de s 0) is too restrictive for imaging; hence,
cross-track component (di s 0) is necessary.
• To avoid differential J2-perturbation, we need to impose dix ¼ 0.
• To ensure safety, we need de ==di thus constraining the dex ¼ 0.
• To achieve relative drift da s 0 determined by the desired relative drift
rate ada ¼ 2ddrift
3Tdriftn.
Guidance and control strategies
The guidance and control strategy to be deployed on-board can be different.
They are linked to the mission requirements and the capabilities that the
spacecraft need to possess. In this section, few alternatives are presented
and critically discussed.
Impulsive
The impulsive guidance has been described thoroughly in Chapter 8 e
Guidance. The reader is suggested to refer to that chapter for the mathe￾matics of the algorithm. The idea is to calculate the required transfer trajec￾tory between an initial state vector and a terminal state vector that are given
at a fixed initial and final time. This means that the transfer time is fixed.
Generally speaking, the transfer cost is larger for lower TOF. Hence, the
mission design requires a trade-off between transfer time and the Dv cost.
Applicative GNC cases and examples 779Fig. 14.1e14.3 shows different transfer trajectory, for an example, initial
condition of 2 km relative distance along each axis and initial velocity of
dv0 ¼ ½20; 20; 5 m
s .
The transfer time is fixed. Fig. 14.23 shows how the transfer trajectory
changes as the fixed TOF increases. In particular, it is important to highlight
that, as the transfer time becomes larger (e.g., five times the orbital period),
the relative transfer exploits more the natural motion to reduce the cost.
Indeed, a drifting trajectory is initiated when the transfer time is set to
tf ¼ 5Torb. In this example, the increased transfer time allows for a Dv
cost saving of w10% for tf ¼ 0:5Torb and w20% for tf ¼ 5Torb with respect
to tf ¼ 0:05Torb.
The two-point impulsive maneuver is a fast algorithm to compute ideal
trajectory. As discussed in Chapter 8 e Guidance, it relies on the state￾transition matrix of the employed dynamical model; hence, it is not robust
to unmodeled perturbances. A possible solution is to recalculate the arc at a
given frequency and employ a multitransfer strategy based on the actual esti￾mated state on-board.
Artificial potential field
An alternative fast and autonomous strategy for on-board guidance and con￾trol is the artificial potential field (APF) technique [11e13]. The guidance
strategy relies on artificial potential functions designed in the ROEs space
in R6.
Figure 14.23 Two-point transfer for different transfer time.
780 Stefano Silvestrini et al.The idea is to build a point-wise global potential based on the contribu￾tion of attractive and repulsive potential sources, namely the target relative
orbits and any other satellite located in close neighboring areas. The attrac￾tive potential is directly expressed in terms of ROEs, those being a conve￾nient way to express relative orbits geometry. Indeed, a set of
ROEs uniquely define one particular formation configuration, i.e., space￾craft relative positions. On the other hand, the natural way to express the
vicinity between two satellites is using the Cartesian distance, expressed in
the local-vertical-local-horizontal reference frame in this particular applica￾tion. The output of the guidance, for each satellite, is what we call guidance
state and indicate as dcg. The guidance algorithm forces the following dy￾namics for each satellite i:
_ dcg ¼  VFglb
where Fglb is the global potential:
VFglb ¼ VFa þ VFr
where Fa is the attractive potential, whereas Fr is the repulsive one.
The reconfiguration objective is to drive the satellites to a predefined
relative configuration, expressed in term of ROEs. The set of ROE to be
achieved is called reference state and indicated as dcr. The attractive contribu￾tion to the global potential is determined as:
FaðdcÞ ¼ 1
2
xa



dcg  dcr



2
The gradient in the guidance ROE space is defined as:
Vdcg
ð $ Þ ¼  v
vda
; v
vdl; v
vdex
; v
vdey
; v
vdix
; v
vdiy

g
Consequently, the dynamic contribution given by the attractive poten￾tial is:
Vdcg ¼ xa

dcg  dcr

Active collision avoidance
The repulsive potential is useful to calculate the trajectory in presence of
other satellites, avoiding collision between agents. As previously stated, to
achieve an efficient active collision avoidance maneuver, the potential is
Applicative GNC cases and examples 781best representative in terms of the Cartesian state x in the Hill frame, where
the metric distance is defined. Given two satellites, i and j, respectively, the
repulsive potential to be computed for satellite i is defined as:
Frij ¼
8
>><
>>:
1
2
xre

d2
ij
h if dij < dlim
0 if dij < dlim
where dlim is the threshold distance beyond which the collision maneuver is
not required, x; h are tuning coefficients. The gradient of the potential is
calculated using the chain rule, which involves the coordinate trans￾formation from Cartesian state x to ROE dc :
Vdcg
Frij ¼ VxFrij$J
x
dc
where Jx
dc is the Jacobian of the coordinate transformation; please refer to
Chapter 4 e Orbital Dynamics, in the section about relative dynamics. The
gradient in the Cartesian space is defined as:
Vxð $ Þ ¼  v
vx
;
v
vy
; v
vz

Hence, the gradient of the repulsive potential between agents i and j,
below the threshold, can be expressed as:
Vdcg
Frij ¼  xr
h
e

d2
ij
h $


xi  xj

$J
x
dc
The repulsive potential takes into account all the mutual distance be￾tween the neighboring spacecraft.
Tracking controller
The output of the guidance algorithm is a set of ROE, which may differ
from the target reference ones. To guarantee that the forced guidance dy￾namics is followed, a feedback control law is employed. The control law
is derived using the Lyapunov stability theorem. In the centralized architec￾ture, the leader processes the guidance loop for the entire formation as well
as the calculation of the control input for each satellite, which is then actu￾ated by each agent. The current error between the desired guidance state
and true state, for the entire formation, is:
edc ¼ dcg  dc
782 Stefano Silvestrini et al.its temporal evolution can be described as:
edc_ ¼ dc_ g  dc_ ¼ ðVFa þ VFrÞðAdc þ BuÞ
If we introduce the following positive semidefinite Lyapunov function:
V ¼ 1
2
e
T
dcedc/V_ ¼ e
T
dce_dc
V_ ¼

dcg  dc
$½ðVFa þ VFr þ Adc þ BuÞ
The control term can be solved to make the derivative of the Lyapunov
function negative. The aim is to drive the derivative to the term  e
T
dce,
which is always negative. Hence, the following control law is derived:
u ¼ B1
hdcg  dc
 ðVFa þ VFrÞ  Adci
In this way, the derivative of the Lyapunov function is negative semide￾finite, vanishing only when dc ¼ dcr, which is within the validity of the
Lyapunov theorem.
Two main drawbacks can be identified for the APF algorithm:
• The APF may lead to instability due to the active-reactive nature of the
algorithm. Nevertheless, user-defined parameters need to be tuned,
tailored to the scenarios, to deliver acceptable maneuvers and control
actions. Moreover, it is a continuous control law that may introduce
operational constraints.
• The APF does not exploit in a predictive manner the knowledge of the
dynamics. It is a real-time algorithm with no optimization capabilities.
This may lead to excessive Dv, being intrinsically suboptimal. Further￾more, the transfer time is not fixed and cannot be estimated a priori.
An example maneuver using APF is reported in Fig. 14.24. The cost to
perform such maneuver is comparable to the two-point impulsive maneuver
for a transfer time longer than w20 orbital periods. The continuous control
action is shown in Fig. 14.25. One can clearly see that, due to the second￾order differential equation that governs the guidance, the control is oscilla￾tory at convergence.
Model Predictive Control
Model predictive control (MPC) is a guidance and control strategy that
combines optimization and feedback control. This type of controller has
been described in Chapter 10 e Control. Moreover, the example of a
Applicative GNC cases and examples 783-400 -2000 200 400
z [m]
4000
2000
APF Controlled Formation Reconfiguration
y [m]
0
2000
-2000
x [m]
0
-4000 -2000
Spacecraft
Target
Figure 14.24 Example of APF relative maneuver from w2000 m to along-track hold
point.
0 5 10 15
Orbit [-]
-4
-3
-2
-1
0
1
2
u [m/s2
]
10-4 Control Action
ux
uy
uz
Figure 14.25 Control action for the example APF maneuver. The oscillatory behavior is
visible at convergence.
784 Stefano Silvestrini et al.controller for a relative maneuver has already been introduced in the same
chapter, in case the optimal control problem could be casted into quadratic
programming. In that example, we have seen how an optimal transfer can be
solved by the MPC with dynamical and maximum thrust constraint. Here,
we describe an example in which the problem has some nonlinear con￾straints. In particular, we will deal with the collision avoidance constraint,
which is concave and quadratic.
The discretized cost function takes the form (cfr. Chapter 10 e Control):
J ðxk; ukÞ ¼ 
xkþN  exk
T
Z

xkþN exk

þ
N
X1
i¼1

xkþi  exk
T
S

xkþi exk

þ
N
X1
i¼0
uT
kþi
Rukþi
where the final state xf ¼ x


tf
 ¼ xkþN , with tf ¼ Ns$DtMPC, in which
the prediction horizon and the sampling time are introduced, namely Ns and
DtMPC.
The collision avoidance constraint with respect to one obstacle can be
expressed as:
1  

xkþi  xo
kþi
T
CTPC

xkþi  xo
kþi

< 0; i ¼ 1; ::; N (14.1)
C ¼
"
I3
03
#
where the superscript o refers to the keep-out-zone is an ellipsoid centered
on the obstacle and expressed by its quadratic form with the positive semi￾definite matrix P. If the keep-out-zone is a sphere, the quadratic form is sim￾ply a symmetric matrix P ¼ r
2I3, where r is the spherical safe region
radius. The constraint is quadratic and nonconvex. The former characteristic
prevents the problem to be recast into quadratic programming, which would
significantly reduce the computational time. The latter turns the formulation
into a nonconvex optimization. Convex programming is faster and guaran￾tees the identification of global minima. For this reason, the following sec￾tion presents the derivation to transform the collision avoidance constraint
into a convex constraint [14,15]. Rearranging the term
exo;kþi ¼ C


xkþi xo
kþi
 in Eq. (14.1), the constraint can be written:
1 exo;kþi
T Pexo;kþi < 0; i ¼ 1; ::; N
Applicative GNC cases and examples 785The idea is to approximate the concave set of feasible positions into a
convex set, which contains the original set. In other words, the spherical
keep-out-zone is approximated by a plane tangent to the sphere and perpen￾dicular to the line of sight of the two agents. We assume to constrain the
search space based on the nominal trajectory from the previous solution,
here referred to as exo;k




0
with subscript 0. This is necessary to turn the
constraint into an affine convex expression. These nominal values are
assumed to be known and are not variables in the optimization. Therefore,
the plane perpendicular to the vector exo;k




0
¼

ex




0
;ey




0
; ez




0
	
and tangent to
the sphere at instant k can be written as:
exo;k




0
0
@exo  r



exo;k




0




exo;k




0
1
A þeyo;k




0
0
@eyo  r



exo;k




0




eyo;k




0
1
A
þ ezo;k




0
0
@ezo  r



exo;k




0




ezo;k




0
1
A ¼ 0
(14.2)
The feasible position belongs to the semispace bounded by the identified
plane. By reworking Eq. (14.2) and introducing the inequality indication,
the compact form of the constraint at time step k is:
exo;k




0
exo;k 	 r



exo;k




0




where only exo;k is the optimization variable. The nominal trajectory
exo;k




0
represents an initial guess for the actual trajectory exo;k and is used to
convexify the collision-avoidance constraint. The closer the nominal trajec￾tory is to the actual trajectory, the more accurate the convex program will
be. The nominal trajectory plays an important role in the iterative methods
for convex programming, which are beyond the scope of this book.
The optimal control problem reduces to a convex one:
minu J ðxk; ukÞ
subject to xkþiþ1 ¼ f ðxkþi; ukþiÞ; i ¼ 1; .; Ns
786 Stefano Silvestrini et al.

xkþij
0  xo
kþi


0
TCTPC

xkþi  xo
kþi

	 r



exo;k




0




where again the nominal trajectory xkþij
0 comes from the previous solution
of the optimization step.
Optimal control
When dealing with relative dynamics and proximity operations, safety con￾straints, keep-out zones, and trajectory corridors usually impose the most
stringent requirements to the GNC design. However, there is still left the
possibility to optimize the relative GNC solution. The most common opti￾mization goals are the time optimal, the fuel optimal, and the energy optimal
GNC. The main differences exist in the formulation of the cost function.
In this section, an energy optimal guidance and control algorithm is pre￾sented to deal with the relative orbit and attitude dynamics of a chaser with
respect to the target object:
x€c ¼ x€þ ac
du_ C
c ¼ du_ C þ ac;
where ac and ac are the translational and the rotational control acceleration
vectors, which are added to the relative natural dynamics to get the
controlled relative dynamics. The relative orbit and attitude dynamics are
expressed by means of the equations presented in Chapter 4 Orbital Dy￾namics and in Chapter 5 e Attitude Dynamics.
The energy optimal rendezvous problem can be solved because the dy￾namics of the chaser is controlled by a control variable:
u ¼
"
aCx
aCxmax
; aCy
aCymax
; aCz
aCzmax
; aC1
aC1max
; aC2
aC2max
; aC3
aC3max#T
which is representative of the 6 DoF normalized control accelerations,
respectively, defined in the inertial frame and in the chaser body-fixed
frame. The six control components are bounded: 1  u  1:
Many solutions of optimal control problems applied to spacecraft dy￾namics are based on indirect methods, relying on analytical relations. As dis￾cussed in the low-thrust trajectory design section, the conditions for
optimality require the solution of a two-point BVP. It is well known that
indirect methods ensure rapid convergence of good starting guesses, but
most of the difficulties are related to the high sensitivity to the initial costates.
Applicative GNC cases and examples 787Indeed, the selection of a good initial guess for the costates is difficult and
time consuming. For the applicative example discussed in this section, given
the interest in exploiting these functions on-board, a more robust method is
used: the optimal relative GNC problem is solved with direct methods,
parametrizing only the control variable and converting the optimal control
problem into an NLP problem, with a direct transcription process. Direct
methods require often a large computation effort, but they are usually robust
and can accommodate path constraints [56].
The solution of a generic NLP problem is a vector of n variables, p, that
minimizes a scalar objective function:
min
p
FðpÞ
subject to m equality or inequality constraints:
bl  cðpÞ  bu;
and bounds:
pl  p  pu:
The equality constraints are obtained imposing bl ¼ bu: With direct
methods, the differential dynamic constraints of the indirect optimal relative
GNC problem are converted into a set of algebraic constraints.
The optimality in terms of minimum energy control (i.e., minimum
quadratic) is achieved defining the scalar cost function as:
FðpÞ ¼ 1
2
Z
tf
t0
ujp
TðtÞujpðtÞdt:
The cost function is numerically integrated over the maneuver time from
the control parametrization functions, knowing just the value of p. A con￾strained minimization algorithm can be then used to solve the NLP problem
associated with the direct transcription of the optimal control. The initial
guess for the parameters in the vector p can be random, normally distributed
within the bounds for the parameters. The complete relative trajectory path
can be discretized in multiple arcs connected by patch points; for each of
them, the energy optimal problem can be solved to find the best trajectory
with the associated control vector.
The control action can be parametrized by means of polynomials up to
the third degree and Fourier series up to the fourth order. The limitations in
the degree of the expansions are motivated to limit the number of the design
788 Stefano Silvestrini et al.parameters and, thus, the dimension of the NLP problem for potential on￾board application. For example, the control parametrization with a second￾degree polynomial for the translational control and with a fourth-order
Fourier series for the rotation control results in:
acðtÞ ¼ a0 þ a1
 t
tref 
þ a2
 t
tref 2
aCðtÞ ¼ a0
2 þX
4
k¼1

ak cos
ks
t
tref 
þ bk sin
ks
t
tref 	;
where ai, ai, bi, and t are 3  1 parameters vectors defined, respectively, in
the inertial and in the chaser reference frame. These parameters compose the
vector of unknown variables:
p ¼ 
ai; ai; bi; s; tf

;
to be found solving the problem in NLP. The reference time, tref , is
needed to nondimensionalize the time, t, in the parametrized control func￾tions. The choice of a reference time equal to the TOF is suggested for com￾mon applications. Note that alternative control parameterizations can be
used, but the one discussed in this section guarantees a good compromise
between robustness and fast convergence of the guidance and control algo￾rithm for this applicative example.
The constraints are obtained from numerical integration of the
controlled relative dynamics and are imposed in the optimal control prob￾lem. The keep-out zones and trajectory corridors can be enforced by means
of penalties in the cost function or added as further constraints along the tra￾jectory path points.
In any case, the relative states at the end of the relative trajectory have to
satisfy the imposed boundary conditions at the final time.
Rendezvous in cislunar space
A modern applicative use case of the methods discussed in this section is the
rendezvous in cislunar space, which has been proposed as ideal location to
deal with space stations beyond Earth orbit. The on-orbit operations of a
complex and, possibly, modular space system in lunar vicinity require auton￾omous relative GNC capabilities, to perform rendezvous and docking be￾tween uncrewed spacecraft in such peculiar space environment. Indeed,
the cislunar space dynamics can be described exploiting a restricted three￾Applicative GNC cases and examples 789body problem modeling approach, including the gravitational attraction of
the Earth and the Moon, and the perturbations due to the Sun [56,66].
This section presents some applicative result, for an example, rendezvous
scenario with a passively cooperative target orbiting on a lunar Lagrangian
point 2 (L2) Near Rectilinear Halo Orbit, with an orbital period of almost
seven days and a periselene altitude in the order of 3000 km [56]. The ter￾minal rendezvous operations can be macroscopically divided into three
phases identified by the order-of-magnitude of the relative distances be￾tween chaser and target:
• Far-range rendezvous, from w10,000 km to a 100 km distance.
• Close-range rendezvous, from 100 km to 1 km distance.
• Final approach rendezvous, from 1 km up to docking with the target.
During far-range rendezvous, the chaser is controlled in absolute posi￾tion, with open-loop impulsive maneuvers for orbit control. In particular,
the guidance and the control functions solve a Lambert-like problem to
reach the desired hold-point before the close-range phase. The goal of
the far-range rendezvous is to reach a final state relative to the target space￾craft. Hence, it is also exploited to accurately phase the two spacecraft before
the close-range rendezvous. In this phase, the chaser attitude state is
completely decoupled from the one of the targets, and it is controlled in ab￾solute dynamics to satisfy the chaser system requirements.
The relative GNC starts to be effective from the close-range phase,
which begins with a departure from a holding-point. The position of the
chaser is controlled relatively to the one of the targets, and impulsive relative
orbital control maneuvers are used. The attitude state is still decoupled from
the target rotational motion; however, the orientation of the chaser is
defined to satisfy relative navigation requirements.
The final approach rendezvous is entirely within the domain of a
coupled 6 DoF relative GNC, which can be designed and optimized with
the optimal control method discussed in the previous section. The low rela￾tive distances between chaser and target require continuous closed-loop
forced translation for safety reasons. During the whole final approach
rendezvous, the attitude control is entirely coupled with the position control
in order to satisfy navigation (e.g., camera pointing) and docking (e.g., dock￾ing port alignment) requirements.
The relative navigation functions can be established on vision-based
techniques. This is applicable after the close-range rendezvous phase, since
short distances are needed to resolve the target in the sensor frame with
the desired resolution to apply precise image processing techniques. The
790 Stefano Silvestrini et al.navigation algorithm assumes that the only available data are provided by
two cameras placed on the chaser. Its architecture is tightly coupled, since
the measurements are directly processed by the navigation filter. The filter
processes the features extracted by the two cameras to compute the relative
target/chaser position and attitude. Since the observation model depends on
both position and attitude of the target spacecraft, the navigation filter has to
be coupled and nonlinear: an extended Kalman filter (EKF) can be used for
this purpose [56]. Figs. 14.26e14.28 report some example results of the
applicative rendezvous scenario in cislunar space.
On-board sensor processing
On-board sensors satisfy the primary sensing capacity to feed the
whole GNC loop, starting from the navigation functions. The GNC system
shall be thus capable to read and process their data, in order to have them
ready and properly elaborated for the following GNC purposes.
Fig. 14.29 shows a possible on-board sensor processing scheme, which is
required to gather the sensor signals, interpret them according to structured
data formats, and convert the signals into a value to be used by the GNC
system [57].
Figure 14.26 Close-range rendezvous final part: arrival at the keep-out sphere holding
point (HP2), with failures and passive safety enforcement. None of the trajectories enter
inside the KOS.
Applicative GNC cases and examples 791The on-board sensor processing is directly interfaced with sensors out￾puts, which are provided as introduced in Chapter 6 e Sensors. This
GNC SW component includes the drivers to receive and correctly interpret
the measurements from the HW peripheral components, the mathematical
operations to scale and convert the measurements in the proper reference
frame with correct dimensional units, the low-pass filters for those compo￾nents without an embedded signal filtering, and the measurement correction
functions. The measurements correction functions should contain all those
Figure 14.27 Close-range rendezvous trajectory with continuous thrust.
Figure 14.28 Navigation errors: final approach rendezvous at w200 m from the target.
(A) Relative position navigation error. (B) Relative attitude navigation error.
792 Stefano Silvestrini et al.operations needed to make the signal ready for the following estimation and
GNC blocks. For instance, magnetometers can be compensated for the
known dipole of the magnetic actuators, accelerometers are corrected for
the gravitational and for the rotation induced accelerations, Sun sensors
measurements are converted into Sun direction unit vectors and corrected
for Earth’s albedo, and similar operation are performed according to the spe￾cific sensor typology. Eventually, the measurements sent to the GNC can be
processed by a redundant sensor manager, which selects, among the available
sensor data, the best and not failed one in an active redundancy operation
principles (cfr. Chapter 1 e Introduction).
The best measurement can be selected by analyzing the time running
variance of the signals. In fact, the variance information of a given signal is
directly dependent from the variance of the measured quantity, which is
related to its dynamical evolution, and from the variance added by the mea￾surement and acquisition chain. Since the measured quantity is the same for
all the redundant sensors of a given typology, two redundant sensors have a
different variance only because of distinct measurement and acquisition er￾rors. In general, a higher variance is associated to larger stochastic errors in
the measurements:
uM ¼ uk ¼ bestðu1; .; un; .; uNÞ:
1
S
X
S
i¼1
skðtSþ1iÞ
<
1
S
X
S
i¼1
sjðtSþ1iÞ cjsk˛f1;.; n; .; Ng;
Figure 14.29 On-board sensor processing scheme [57].
Applicative GNC cases and examples 793where snðtSþ1iÞ is the running variance at the ðS þ 1  iÞ-th sample of
time of the n-th sensor scalar measurement, which is computed on the last S
samples as:
snðtsÞ ¼ 1
S
X
S
i¼1
u
2
nðtSþ1iÞ  "
1
S
X
S
i¼1
unðtSþ1iÞ
#2
¼ 1
S
X
S
i¼1
u
2
nðtSþ1iÞ  m2
nðtSÞ;
where mnðtSÞ is the running mean on the last S samples of time:
mnðtSÞ ¼ 1
S
X
S
i¼1
unðtSþ1iÞ;
and tS is the time associated with the S-th sample, since the sensor mea￾surements are available at discrete samples of time. Hence, the best measure￾ment is associated to the sensor with the lowest running mean of the
variance on the last S samples of time.
The failed sensor measurements are identified by the sensor’s failure
detection and isolation (FDI) algorithms, and they are immediately excluded
from the pool of available measurements to be selected by the redundant
sensor manager.
Sensor failure detection, isolation, and recovery
FDI functions at component level typically operate on sensor signals
after low-pass filtering, as shown in Fig. 14.29. Thus, the failure detection
is performed on the raw filtered sensor measurements and can be based
on statistical analysis on the incoming signal. These functions operate on
the low-pass filtered data in order to have a uniform behavior among sensors
with and without embedded low-pass filtering.
The FDI algorithm shall be designed and calibrated in order to detect the
most common typologies of sensor faults: spike faults, erratic faults, drift
faults, hardover/bias faults, data loss faults, and stuck faults [57], which
have presented in Chapter 6 e Sensors. The complexity in detecting these
faults is related to the dynamical evolution of the nominal sensor signals
along a generic spacecraft dynamics. In fact, in general, none of the sensor
outputs has a steady-state constant value, and the detection algorithms
should be capable of detecting a variation that is not compatible with a
feasible dynamical state of the spacecraft. For example, spacecraft nominal
794 Stefano Silvestrini et al.rotations are bounded below maximum angular rates. Similarly, the acceler￾ations are limited by the environment and by the maximum actuator forces
and torques. Thus, there exists a maximum feasible time variation of the
sensor signal that can be used to distinguish realistic measurements from
faulty ones. The risk of marking real measurements as faulty ones (e.g.,
the spacecraft is really experiencing a nonnominal attitude dynamics) shall
be minimized at system level, by exploiting the system-level failure detec￾tion functions (i.e., FDIR system), which are designed to compare more
spacecraft components from different subsystems, and to detect dangerous
conditions for the entire spacecraft. Note that the design approach should
be as conservative as possible, preferring to detect false failures, rather than
having failure propagation in the GNC system.
The failure detection algorithms at component level could be based on
the running variance and running mean of the sensor signals. The running
variances are used to detect the common sensor faults, while the running
mean is applied to detect the presence of a valid sensor output. For this pur￾pose, the sensor driver sets the sensor measurements equal to 0 if the sensor
data are not received or received as corrupted packets.
A sensor is said to be nonfaulty if the running mean of the running vari￾ance is greater than zero and smaller than a given threshold, sn:
min 
1
S
X
S
i¼1
snðtSþ1iÞ
!
> 0 ^ max 
1
S
X
S
i¼1
snðtSþ1iÞ
!
< sn
The running mean of the variance is used to smooth the failure detection
response and neglect confined errors in the signal. If the sensor measurement
has multiple vector components, this relation is applied to each component.
If these conditions are not respected, the failure is detected. For example, if
the minimum component is equal to zero, the sensor has a stuck fault. If the
maximum component is above the threshold, the other faults can be present:
a high variance with fluctuations can indicate an erratic fault, short and
repeated peaks in the variance can indicate spike faults, a single short peak
in the variance can indicate a hardover fault. Drift faults are more difficult
to be detected unless the drift is very fast. In this case, the variance has a sig￾nificant constant increase with respect to nominal values. The variance
threshold, sn, is specific for any sensor, and it shall be calibrated by ground
and in-orbit testing. Note that the selection of the sn value is crucial to the
proper operation of the FDI function.
Applicative GNC cases and examples 795A sensor is said to be operative if the square of the running is greater than
zero. Thus, a sensor sends valid outputs if:
min

m2
nðtSÞ

> 0:
If this condition is not respected for a prolonged time, the sensor is
completely off. On the contrary, if the condition is not respected for short
and close intervals of time, a data loss fault may be present.
If a failure is detected in a sensor, the redundant component manager is
commanded to use the redundant sensors, and the outputs of the failed
component are blocked. Then, isolation and recovery actions are executed
in order to classify and identify the fault and, if possible, recover the faulty
unit. Note that the switch to the redundant components is anyway a recover
action at system level (cfr. Chapter 11 e FDIR Development Approaches in
Space Systems). Some example failure detection outputs are shown in
Fig. 14.30.
Autonomous on-board sensor calibration
Autonomous on-board sensor calibration is an operation that is used to es￾timate unknown error quantities to improve the GNC estimation perfor￾mance. Indeed, the estimation and the knowledge of sensor bias errors,
scale factors misalignment, nonorthogonality, and other low-frequency er￾rors are crucial to achieve excellent accuracy in the navigation functions (cfr.
Chapter 6 e Sensors).
Autonomous on-board sensor calibration shall be performed since most
of the low-frequency errors are not constant and fluctuate in time, due to
thermal variations, ageing, and change in the environmental conditions.
Thus, despite of great importance, the ground characterization and calibra￾tion of the GNC system is usually not enough to achieve the required nav￾igation and control performance. The latter can properly estimate
misalignment and nonorthogonality errors but fails in estimating unstable
bias and other error drifts.
As said, a sensor is calibrated when all the deterministic, systematic, and
the low-frequency drifting errors are removed from the available measure￾ments. The estimation of sensor errors can be performed by exploiting
different alternative methods; both batch approaches [58] and sequential
filtering [59] can be used for sensor calibration. The traditional on-orbit cali￾bration approach uses the EKF discussed in Chapter 9 e Navigation, but
different batch processes have been also developed to be periodically
executed along the spacecraft timeline.
796 Stefano Silvestrini et al.The sensors that are most commonly calibrated on-board are the inertial
sensors, such as gyroscopes and accelerometers, and magnetometers. Other
sensor types rely more on ground calibration to estimate misalignments,
constant scale factors, and nonlinearities. The calibration model for a
Figure 14.30 Sensor Faults and failure detection examples [57].
Applicative GNC cases and examples 797three-axis gyroscope or accelerometer often includes a set of three biases and
a 3  3 scale factor/nonorthogonality matrix containing three scale factors
and 6 nonorthogonality errors, for a total of 12 calibration parameters.
The bias would imply a constant offset in the measurements, but we
know that this offset actually drifts in time. As discussed in Chapter 6 e Sen￾sors, this bias instability is commonly modeled using random walk processes.
Mathematically, for the gyroscope case, this would result in:
u

ðÞ¼ð t I3 þ SÞ½uðÞþt bu þ hu; with b_ u ¼ hb;
where S is an unknown fully populated matrix of scale factors (i.e., the
diagonal elements) and nonorthogonality errors (i.e., the off-diagonal ele￾ments), bu is the bias, and hb the random process noise describing the bias
instability. An orthogonal misalignment matrix could be included in the
model to account for the mounting misalignment, which is, however,
typically calibrated on-ground. Note that the previous equation includes the
noise term, hu, condensing the random stochastic errors in the measure￾ments, which are, however, not estimated in the calibration process. In most
cases, the bias fluctuation occurs slowly over many orbits. The other cali￾bration parameters can vary as well, but typically not as fast as the bias.
Hence, if a batch estimation process is used, the on-board calibration should
be performed every few hours.
Magnetometer calibration is often accomplished using batch methods
[60,61], even if real-time sequential methods have been proposed and devel￾oped [62]. Similar to inertial sensors, magnetometers are also calibrated for
biases, scale factor, and nonorthogonality errors. A common mathematical
calibration model is:
BðtÞ¼ðI3 þ SÞ½BðtÞ þ bB þ hB;
where the error terms are analogous to the previous gyroscope case. Also in
this case, an orthogonal misalignment matrix could be included in the model
if mounting errors are not ground calibrated. The magnetometer calibration
problem would be easily solvable with an accurate a priori attitude estimate,
even if this is generally not the case. Fortunately, the norms of the body
magnetic measurements and geomagnetic-reference vectors provide an
attitude-independent scalar observation to calibrate the magnetometer.
Let’s now discuss a practical applicative example of a possible gyroscope
and magnetometer calibration to be performed on-board. Exploiting the
previous sensor measurement models, the measured quantities can be
798 Stefano Silvestrini et al.calibrated with two dedicated sequential iterative real-time algorithms. Both
of them are suitable for a computationally efficient on-board implementa￾tion, which can also be used in small satellite missions. The gyroscope is
only calibrated for the bias, accounting for its instability, thanks to the
angular velocity bias estimation performed with a complementary filter
[63]. The magnetometer measures are unbiased and corrected for scale fac￾tors and nonorthogonality errors, thanks to a sequential centered iterative
algorithm [62]. Specifically, the calibrated quantities become:
uCðtÞ ¼ u ðtÞ  beu;
BCðtÞ ¼ 
I3 þ Se
!1
BðtÞ  beB;
where beu, Se, and beB are the estimated error terms. Note that, to further
improve the computational efficiency, the measurement model can be
directly defined with the inverse of the matrix ðI3 þSÞ, in a way to not
perform the inverse operation in the calibration step. Indeed, in this case, the
calibration algorithms directly estimate the elements of the inverse matrix,
and the calibration step becomes:
BCðtÞ ¼ 
I3 þ Se
!
BðtÞ  beB:
This numerical trick is also valid for the gyroscope model with scale fac￾tors and nonorthogonality errors, even if it is of minor importance and
optional. Indeed, both the measurement models can be found in existing
literature methods. Further details about these calibration methods can be
found in the cited literature references.
The autonomous on-board sensor calibration is also particularly useful
when the FDIR function detects a fault in the system and imposes a recovery
action by commanding a system reconfiguration and recalibration. In this
case, the previous calibration data shall be discarded and reinitialized to cali￾brate the new redundant sensor components. In fact, whenever the system is
reconfigured, the last calibration data involved in the reconfiguration shall
be substituted. This operation is performed by the GNC system manager,
and there is a settling time before design performances are reestablished.
Thus, the mission manager shall consider the needed transient time in order
to properly operate the system with full performance. Fig. 14.31 shows an
example autonomous on-board sensor calibration with a recalibration event.
Applicative GNC cases and examples 799It shall be noticed how the switch to a redundant sensor with large measure￾ment offset bias, at t ¼ 1000 s; is compensated with a system reconfigura￾tion and autonomous recalibration completed in less than 15 min. Similarly,
the initial on-board calibration from unknown bias values at t ¼ 0 s is
completed in approximately the same amount of time [57].
GNSS-INS integration for on-board orbit determination
Orbit determination can be performed on-board, thanks to many different
techniques and sensors, as discussed in Chapter 6 e Sensors and Chapter 9 e
Navigation. Earth-orbiting spacecraft commonly take advantage of GNSS
sensors to perform orbital state measurements. These measurements can
also be exploited in real-time, combined with an INS based on a set of ac￾celerometers contained inside an inertial measurement unit (IMU, cfr.
Chapter 6 e Sensors), to provide improved orbital determination perfor￾mance. In particular, the GNSS-INS orbit determination system provides
the long-term stability typical of GNSS systems, but it can also compensate
for partial unobservability of GNSS satellites, propagating the spacecraft state
Figure 14.31 On-board calibration with a system reconfiguration and autonomous
recalibration [57].
800 Stefano Silvestrini et al.without having to rely on GNSS measurements only. As discussed in
Chapter 9 e Navigation, GNSS-INS integration can be made exploiting
loosely or tightly coupled architectures.
Moreover, an improved on-board orbit determination system can
further increase the INS-only propagation by exploiting a refined on￾board orbital propagator. In this case, the orbit determination system can
be operated in two modes that are identical in terms of outputs but are
differentiated at measurement level, according to position and velocity sour￾ces. In this case, orbit determination would be intrinsically working with
two alternative measurement sections [57]:
• Orbit determination with GNSS and accelerometer measurements,
which requires the complete availability of all the orbit determination
sensors. In this mode, the measurements of the IMU are combined in
a navigation filter (e.g., Kalman filter) to improve position and velocity
estimates and to estimate the accelerometer (e.g., bias) and gravitational
model errors.
• Orbit determination with orbital propagator and accelerometer measure￾ments, which requires a valid estimate for position and velocity, either
from the previous step of the orbit determination or from ground knowl￾edge of the current orbital state (e.g., two-line element - TLE update). In
this case, the navigation filter should be modified in terms of measure￾ment models and covariance properties with respect to the previous
mode. Moreover, the estimation of accelerometers errors would be not
updated in this mode, and the orbital propagator outputs are combined
with statically calibrated IMU measurements to continue the orbit
determination process.
The navigation filter states shall include all the sensor errors to be esti￾mated to calibrate the available measurements, as discussed in the section
about autonomous on-board sensor calibration. For example, assuming to
calibrate only the accelerometer for the bias error, the calibrated acceleration
vector would be:
aCðtÞ ¼aðtÞ  bea:
Let’s consider an applicative GNC example of an on-board orbit
determination system based on an EKF, which has been introduced in
Chapter 9 e Navigation. The example orbit determination system exploits
a GNSS-INS integration in a loosely coupled architecture: accelerometer
readings are used to propagate the inertial orbital state vector generating
the INS preliminary estimate, while GNSS position and velocity solutions
Applicative GNC cases and examples 801are compared with the INS estimate to generate a measurement error signal.
The measurement error signal is fed to the EKF, which outputs an updated
estimate of the position and velocity error, as well as the bias term estimate.
Eventually, the output of the EKF is used to correct the INS preliminary es￾timate, whereas the bias term is fed back to the integration block of the
accelerometer measurements. In the case the GNSS is experiencing an
outage period or a fault, the on-board orbit propagator is used as synthetic
measurement element for the INS input. The orbit propagator includes at￾mospheric drag and J2 perturbation effects, and it performs dead reckoning
of the orbital state as soon the GNSS measurements are lost. In this case, the
EKF exploits a different measurement model and covariance matrix with
respect to the nominal mode with GNS-INS integration. Obviously, the
approximate orbital model introduces propagation errors, and an inherent
position drift cannot be avoided. However, the coupling with the EKF helps
in accounting for the orbital error dynamics, and it determines a slower
divergence rate with respect to a pure on-board orbital propagation
including the same perturbation terms. Fig. 14.32 reports an example orbit
determination solution for a low Earth-orbiting satellite. Specifically, the
three-axis position error between the estimated position and the real one
is shown [57].
Figure 14.32 Three-axis position error for an on-board orbit determination system with
a loosely coupled GNSS-INS integration [57].
802 Stefano Silvestrini et al.Irregular solar system bodies fly around
GNC around small bodies of the Solar System represent a challenge
for many aspects. First, the small mass makes the prediction of the spacecraft
orbit more difficult, as perturbations like solar radiation pressure (SRP), and
gravitational pull by planets or other nearby objects generate a force compa￾rable to that of the small body itself. As the spacecraft moves nearby the ob￾ject, local shape irregularities start to have a visible effect on the deviation of
orbits, thus making the navigation around the body even more difficult.
Also, there are control-related issues, as the very weak gravity exerted by
small celestial bodies requires minimal changes in velocity to perform large
relative displacements. This means that an error in the direction of the ma￾neuver, or in its magnitude, may lead to the escape from the asteroid/comet,
or a collision on its surface.
These aspects are further exacerbated if we consider that most of the
knowledge about the small bodies parameters derives from on-ground ob￾servations, and the accuracy of the measurements and of the reconstructed
parameters (shape, spin, etc.) is often not enough to safely perform proximity
operations. Therefore, differently from missions to planetary systems, it is
required an estimation not only of the state of the spacecraft but also of
the asteroid/comet physical parameters. Reducing the uncertainties of the
system becomes more relevant as the spacecraft is required to move closer
to the target body, and the complexity and number of measurements and
estimations increases as well. Therefore, navigation strategies strongly
depend on the distance from the objects and on the specific mission
objectives.
At sufficiently large distance, irregularities of the gravity field, caused by
the uneven shape of the attractor, are negligible. Furthermore, the motion of
the attractor’s center of mass is reconstructed from on-ground observations
in a sufficiently accurate manner. Hence, the navigation of the spacecraft can
resort to techniques used for deep space, interplanetary trajectories,
leveraging radiometric measurements such as range, doppler, and delta￾differential one-way ranging (DDOR) [16]. Also, the set of measurements
can be augmented with a centroid tracking from spacecraft camera’s images.
At reduced altitudes from the attractor’s surface, the gravity field irregu￾larities become the major natural source of perturbations and require an ac￾curate characterization through the reconstruction of the attractor’s shape
and physical properties. On-ground observations of small objects often do
not consent a sufficiently accurate reconstruction of such properties, and
Applicative GNC cases and examples 803in situ measurements must be performed. The small body’s parameters and
the evolution of the spacecraft state are intimately related quantities; there￾fore, the orbit determination filter must embed all of them simultaneously.
In particular, far-range orbits can be exploited to reconstruct the parameters
of the attractor more accurately and reduce uncertainties, thanks to the
milder influence on the spacecraft trajectory.
The reconstruction of such parameters is made possible through dedi￾cated measurements from the spacecraft, leveraging cameras, or ranging in￾struments (such as Light Detection and Ranging [LIDAR] or laser range
finder).
Through cameras, it is possible to perform stereo-photoclinometry
[17,18], a technique that, though several images and the identification on
landmarks (craters or other features) can reconstruct the shape of the
body, as well as its albedo. Another noteworthy image-based technique is
the silhouette and shadow carving, successfully executed for Rosetta mission
[19,20], where a control volume is gradually carved where images don’t
show the presence of the object (silhouette carving) or where a shadow in￾dicates a change in the surface slope (shadow carving). It is worth
mentioning that this technique is generally less accurate, and stereo￾photoclinometry may be performed afterward to refine the shape of the
object.
Ranging instruments provide local measurements of the distance from
the object surface. By collecting several measurements, it is possible to
reconstruct the shape of the attractor (provided a good knowledge of the
spacecraft trajectory).
The same measurements (ranging and landmarks tracking) are then
exploited for orbit determination, given the higher accuracy of the attrac￾tor’s parameters, at closer distances. This procedure can be performed
sequentially to further improve the characterization of the small body and
reduce the navigation errors of the spacecraft.
The described approach has been used for past mission toward small ob￾jects of the Solar System. It is the case of the NEAR Shoemaker probe,
directed to the asteroid Eros, which performed a sequential reduction of
orbital altitude to gradually improve the asteroid’s parameters accuracy,
leveraging radiometric measurements, laser ranging, and landmarks tracking
[21]. In particular, a global initial mapping was performed at a distance about
200 km for preliminary refinement of the parameters and the definition of
the landmarks set, leveraging the DSN radiometric tracking for orbit deter￾mination. Then, operative orbits at 50 km (polar) and at 35 km (retrograde)
804 Stefano Silvestrini et al.were exploited to fulfill mission objectives, while providing further images
and range measurements to refine the shape and spin of the target until the
final landing on its surface. The orbit determination filter comprised a full set
of 359 parameters to estimate, including spacecraft state, Eros’s gravitational
coefficients, spin axis and magnitude, landmarks position, etc., leading to
position errors of the order of tens of meters at best.
The experience of the NEAR Shoemaker probe highlighted the neces￾sity of an autonomous navigation of the spacecraft for the final descent phase
on a small body, given the too long time needed for communication with
ground, up-to-date data upload back to the spacecraft, which may take
several hours [22]. First autonomous GNC attempts have been introduced
in the Hayabusa 1 and Hayabusa 2 missions, respectively, directed toward
the asteroids Itokawa and Ryugu [23,24]. The two spacecraft leveraged a
Target Marker Tracking technique, making use of an artificial landmark
dropped onto the asteroid’s surface during the descent phase. The marker
is designed to serve as an artificial bright spot, to be tracked through image
acquisition and allow the reconstruction of the relative motion also in
adverse illumination conditions. Through the marker, the spacecraft could
nullify their relative motion with respect to the surface, to enable the sample
collection at touchdown.
Another recent example of autonomous navigation near an asteroid is
represented by the OSIRIS-Rex mission, targeting the asteroid Bennu
[25]. Like Hayabusa missions, the spacecraft performed a descent and touch￾down, with collection of sampled from the asteroid surface. Again, autono￾mous navigation is exploited; however, the autonomous phase was here
longer, from around 4 h prior to the touchdown. Furthermore, the space￾craft did not rely on artificial objects tracking as Hayabusa: a LIDAR was
mounted as primary measurement for the autonomous navigation. The
original plan was to use the LIDAR as the primary instrument for the
descent and touchdown, and a Natural Feature Tracking (NFT) algorithm
was developed as a backup solution (to be used with Navigation Camera im￾ages) [26]. However, after arrival at the asteroid, it was found that in order to
achieve a safe sample collection, the spacecraft accuracy at touchdown
needed to be on the order of a few meters, and the LIDAR-based approach
could not achieve that level of accuracy. Thus, the NFT method was
selected to be the primary and was successfully used to gather the sample.
Fig. 14.33 shows some example fly around trajectories around irregular
Solar System minor bodies [64,65].
Applicative GNC cases and examples 805GNC for planetary landing
Planetary landing is, without any doubt, one of the most critical tasks
that to be performed during a space mission. The landing sequence is usually
composed by an orbiting phase followed by the Entry, Descent, and Landing
(EDL) phase. The EDL is usually considered a mission critical phase: a failure
at this stage would imply, with high probability, the complete loss of the
spacecraft. Despite of the relatively large number of successful missions since
the Apollo program, landing is complex and difficult, as denoted by the
recent failure of the European Space Agency lander module Schiaparelli
on Mars [27].
The landing sequence is characterized by multiple flight phases and high
uncertainties. The last phase of a landing sequence is usually called powered
descent (PD), and, at this stage, the GNC system must be able to deal with
accumulated errors until touchdown. An example of a classical landing pro￾file is depicted in Fig. 14.34. The sequence begins with a deorbit burn, fol￾lowed by a coast phase. The coast phase ends near the periapsis when the
powered descent phase starts and terminates with touchdown.
In this section, the main GNC algorithmic alternatives and implementa￾tion challenges are summarized with a focus to powered descent phase.
Planetary landing guidance
Formulation
The powered descent phase typically starts at a few hundreds of kilometers
relative to surface. For this reason, it can be assumed that the lander is subject
to uniform gravity. Furthermore, aerodynamic forces are negligible
compared to the retrorocket. In fact, the eventual presence of atmosphere
could be negligible due to the relative low velocity (w100 m/s) and shape
of the spacecraft. Consequently, the three-dimensional translational
Figure 14.33 Example irregular Solar System bodies fly around trajectories.
806 Stefano Silvestrini et al.dynamics expressed in a Ground Reference System can be described by a set
of equations:
8
>>>>>><
>>>>>>:
r_ ¼ v
v_ ¼ T
m
þ g
m_ ¼ kTk
Ispg0
where r and v are the position and velocity vectors, T is the engine
thrust, g is the constant acceleration of gravity vector of the planet, Isp the
specific impulse of the engine, and g0 the standard gravity acceleration at
sea level. In order to set an optimization problem, the following initial
and final states can be set:
8
>>>>>>>>>>><
>>>>>>>>>>>:
rðt0Þ ¼ r0
vðt0Þ ¼ v0
mðt0Þ ¼ m0
r


tf

¼ rf
v


tf

¼ vf
Figure 14.34 Example of landing profile.
Applicative GNC cases and examples 807In general, the local terrain characteristics should be taken into account
to avoid potential hazards on the planet surface. In a realistic mission, sensors
can be utilized to obtain the digital terrain model and to discriminate be￾tween safe and unsafe landing sites and possible hazards along the trajectory
(i.e., craters and hills). There are two main alternatives to deal with terrain
constraints: constraint embedded optimization strategy and the waypoint￾based scheme. The first strategy formulation includes the hazardous terrain
as constraint in the optimization problem, and, in this way, hazards are
autonomously avoided. In the waypoint-based method, waypoints along
the descent trajectory are defined. In this way, these selected waypoints force
the flight path to avoid hazards. Waypoints can be determined in advance
on the reference trajectory. The introduction of waypoints to reach along
the trajectory implies a smaller difference between the guidance trajectory
and reference solution at the cost of frequent maneuvers and therefore a
higher fuel consumption. Furthermore, the thrust limitations given by the
engine characteristics have to be included as:
T1  kTk  T2
with T1 and T2 being the minimum and maximum available thrust.
Minimum fuel consumption is usually the adopted performance index.
Several ways exist to express this index as cost function to be minimized.
Some of them are:
J ¼ m


tf

J ¼
Z
tf
0
kTkdt
J ¼ 1
2
Z
tf
0
aTadt
J ¼ tf
with a ¼ T=m and tf the final time, parameter to be determined by the
guidance law. Having introduced dynamical equations, cost function, and
typical constraints, the unified optimal powered descent guidance or trajec￾tory planning problem is given in this section.
808 Stefano Silvestrini et al.Guidance algorithms
Some of the main analytical and numerical guidance algorithms usually used
to solve this optimization problem are introduced [28].
Polynomial method
The polynomial method is an analytical model adopted also by the Apollo
lander [29]. The basic idea is to simplify the thrust acceleration profile and
describing it as a polynomial of flight time. A quadratic thrust acceleration
profile is assumed as:
aðsÞ ¼ c0 þ c1s þ c2s2 s˛

t; tf

:
By considering the terminal position, and the velocity and acceleration
constraints, analytical expressions of the acceleration in line with the current
and terminal states can be derived:
aðtÞ ¼ 12
t2
go


rf  r  vtgo
 6
tgo


vf  v

þ af (14.3)
where tgo ¼ tf  t is defined as the time-to-go. Please see Refs. [28,30] for
the complete derivation. As implied in Eq. (14.1), the current thrust ac￾celeration can be determined by current and final states. Thrust bounds are
not taken explicitly into account with this kind of formulation, but a
saturation function can be introduced to meet the thruster constraints.
Potential field method
The potential field method combines APF method and Lyapunov stability
theory to perform both pin-point landing while avoiding possible hazards.
In particular, a Lyapunov function can be constructed considering a contribu￾tion of a state function Vs and a potential function Vp as in Eqs. (14.2)e(14.4).
V ¼ Vs þ Vp (14.4)
Vs ¼
h
r
T  r
T
f ; v
T  v
T
f
i
P
h
r
T  r
T
f ; v
T  v
T
f
iT
(14.5)
Vp ¼ Xn
i¼1
ejrcijexp



rT  rT
ci 
Hðr  rciÞ
s2
i
	
(14.6)
where P and e are parameters to be tuned to shape the descent trajectory, rci
is the position of local obstacles and hazards to be avoided, H is a constant
Applicative GNC cases and examples 809matrix to calculate the square of the horizontal distance between the lander
and the hazard center, and s is a positive shape parameter.
Zero-effort-miss/zero-effort-velocity method
The zero-effort-miss/zero-effort-velocity (ZEM/ZEV) method is a feed￾back guidance law. It solves the guidance command with the energy optimal
cost function J ¼ 1
2
R tf
0 aTadt to meet the position and velocity constraints.
ZEM and ZEV represent the position and velocity deviations between the
lander and the landing site if no control force is exerted:
ZEVðtÞ ¼ vf 
2
4vðtÞ þ
Z
tf
t
gðsÞds
3
5
ZEMðtÞ ¼ rf 
2
4rðtÞ þ tgov þ
Z
tf
t


tf  s

ds
3
5
The expression for ZEM and ZEV, combined with the cost function,
allows to derive an analytical expression of optimal acceleration ag :
ag ¼ 6
t2
go
ZEM  2
tgo
ZEV
Please note that the solution of this equation in the optimal control
framework is quite complicated because it implies the solution of a quadratic
equation with respect to tgo. A possible alternative approach is to add a
constraint on the altitude component of the thrust acceleration vector and
to solve for tgo. Similar to the polynomial method, the saturation function
is introduced to take into account the thrust limit.
Pseudospectral method
The pseudospectral method (PSM) is a generic approach to solve the optimal
control problem when dealing with NLP problem. The original pinpoint
landing problem can be translated into an NLP by approximating both state
and control variables simultaneously at a series of collocations using interpo￾lating polynomials. This allows to rewrite the cost function, dynamics, and
constraints into algebraic equalities or inequalities. These discretized expres￾sions define an NLP problem that can be solved by PSM. The solution is an
approximate solution to the original continuous optimal control problem.
The detailed formulation is described in Ref. [28].
810 Stefano Silvestrini et al.Convex optimization method
Problems with convex objective functions, linear equality constraints, and
convex inequality constraints can be solved by means of convex optimi￾zation techniques. This kind of problem is very advantageous because it
does not require an initial guess of the optimization variables and it pro￾vides fast convergence and polynomial time complexity. The original
landing problem can be rewritten in a convex form also making use of
lossless convexification techniques and expressing the problem constraints
in a convex form. This kind of guidance method was proposed also for
Mars landing [31].
Sensors and navigation
During a planetary landing, it is of extreme importance to accurately know
the lander position with respect to the planet’s surface. This task is performed
by exploiting different sensors and a navigation filter [32]. Also in this sce￾nario, two types of sensors are available: passive imaging or active range
sensing. The pros and cons of these two alternatives are similar to the
ones detailed in Chapter 9 - Navigation while describing relative navigation
alternatives. Passive sensors such as visible cameras are a mature technology
that has the advantage of low power consumption, limited mass and volume.
Depending on the camera characteristics, navigation measurements with
different level of accuracy can be provided from any altitude during a land￾ing sequence. The main drawback of passive sensors is that they require, in
general, good illumination conditions and cannot operate in the dark. On
the contrary, active range sensing like LIDAR or altimeters can operate un￾der any illumination conditions. The main drawback of this relatively green
technology for space applications is that they have a limited operating range
and, in general, high-power consumption. This represents a constraint on
the altitude at which navigation measurements can be made available.
From the navigation filter point of view, the main difference is represented
by the kind of information provided by the approach: global or local posi￾tion estimation. Global position estimation provides the best estimate of the
absolute position of the lander with respect to a global coordinate system
attached to a planet surface map available before landing. In this way, it is
possible to maintain a controlled position with respect to a desired landing
site, specified on the surface map. In contrast, local position estimation pro￾vides the best position estimate with respect to a map of the landing site
made onboard, during landing. This local map is usually more accurate,
but it cannot, in general, be correlated to the global map and, therefore,
Applicative GNC cases and examples 811the absolute position cannot be improved by using local approaches.
Comparing subsequent local position, relative velocity with respect to the
terrain can be computed. Finally, a further classification can be made
depending on the structure of the algorithm, distinguishing between correla￾tion and pattern-matching approaches. For passive imagers, the correlation step
is performed by correlating the acquired image with an onboard map (that
can be the previous step). This is done measuring the similarity between the
current image and the map value. For active range sensors, the approach is
similar, but, instead of images, elevation maps or contours are correlated.
Correlation is a common 2D signal processing operation and, therefore, it
is possible to implement it on field-programmable gate array to allow for
fast computation. However, they have the disadvantage that the surface
data must be rectified. The rectification is a process that removes the scale
and perspective differences between two sets of data.
This step causes a direct coupling between errors in the position estimate
derived from correlation and the state estimate use to reorient the surface
data (correlated measurements and states used in a filter may affect its stabil￾ity). A different approach is represented by pattern-matching methods.
Instead of correlating patch of surface, this kind of algorithms tries to match
landmarks between map and surface data. Landmarks are locations that can
be extracted reliably such as craters. Therefore, while for correlation, the
map and surface data are directly compared, in pattern matching, landmarks
are first extracted from the surface data and map, respectively, and then
compared. Given this high-level classification, some of the most common
approaches can be summarized as in Ref. [32].
• Crater pattern matching [33]. This pattern-matching algorithm provides an
absolute position estimation by using surface craters as landmarks. These
landmarks are extracted in the map and collected into a database. During
landing, craters features are detected and compared to the landmarks
present in the database. When a match is obtained, the absolute lander
position can be estimated. One major advantage of using craters as
landmarks, compared to other approaches where unknown features are
used, is that craters can be recognized by their intrinsic characteristics
which are highly independent of the illumination conditions.
• Scale-invariant feature transform (SIFT) descriptor matching [34]. SIFT descrip￾tors [35] are commonly used in image processing techniques and can be
extracted from imagery that do not have craters. The process is similar to
the crater pattern-matching technique, but a different landmark defini￾tion is used (SIFT descriptors vs. craters). A main drawback is that SIFT
812 Stefano Silvestrini et al.descriptors are sensible to illumination and viewing angle. For this
reason, important constraints in the generation of the database as the
need to recreate images comparable to those to be captured by the on￾board camera. The simulation SW needs not only to be quite realistic but
also, more importantly, the surface data have to be available with an
extreme level of detail.
• Image to map correlation [36]. This method uses correlation to compare
descent images directly to a previously obtained image of the landing
site (e.g., taken from an orbiter). The image has to be rectified first to
match the scale and orientation of the previously obtained image and
then the correlation step is performed.
• Descent image motion estimation [37]. In this method, during the descent
phase, subsequent images are correlated between each other in order
to estimate the velocity of the lander relative to the surface. The rectifi￾cation process is not necessary if the images are acquired fast enough.
• Structure from motion [38]. The concept of this technique is very similar to
the Descent Image Motion Estimation. The main difference is that not
only velocity but also position and attitude of the lander are estimated.
This is possible but only up to an unknown scale factor that has to be
resolved in a different way (e.g., with an altimeter).
• Shape signature pattern matching [39]. While dealing with active ranging
sensors, shape signatures can be used as landmarks. In fact, they are sur￾face landmarks based on local surface shape that can be used for a pattern￾matching approach. Shape signatures are extracted from a previously
available digital elevation map (DEM) and correlated with surface data
(e.g., range image available from a LIDAR).
• Range image to DEM correlation [40]. In this case, a DEM is created from a
single or multiple range images and then rotated into the map frame
before correlation. The two available DEMs are then correlated to esti￾mate the position.
• Altimeter to DEM correlation [41]. The approach is very similar to the pre￾vious one. The main difference is that instead of a DEM to DEM, an
elevation data to DEM correlation is performed. Elevation data are
generated by exploiting only the data coming from the altimeter.
• Consecutive range image correlation [42]. Similar to image processing tech￾niques, two consecutive range images are rotated into the map frame
and correlated between each other. This correlation gives an indication
in the change of position of the lander.
Applicative GNC cases and examples 813Hazard avoidance
All the unmanned landing sequences involve a hazard avoidance method. In
particular, autonomous algorithms need to be employed in order to discrim￾inate between a safe and a hazardous patch of the terrain. This process is
based on the evaluation of specific characteristics of the planet surface
such as: slope of the terrain, surface roughness, and safe landing area size.
Hazard maps can be generated according to various criteria that are
mission-dependent and based on available sensors. General methods for
vision-based hazard map generation are based on intensity-based algorithms
[43] that determine the surface roughness based on pixel standard deviation.
Also LIDARs can be used to generate hazard maps. This is done by exploit￾ing the DEM available after the processing of multiple range images. The
derived DEM is used to extract slope and roughness characteristics of the
terrain using a least-squares plane fitting algorithm [44]. Finally, the hazard
map can also be the product of multiple sensor processing [45]. In fact, a
fuzzy logic methodology for fusing sensed data can be adopted to generate
a multisensors hazard map. Once a hazard map is generated, a new landing
site can be selected according to different criteria. A common strategy is to
generate a cost function that selects the landing site that has minimal landing
incidence angle and roughness landing while keeping the lander away from
detected hazards.
References
[1] B. Hamilton, Sizing and steering CMG arrays for agile spacecraft, ESA GNC 2017
Conference.
[2] D. Alazard, et al., Two-input two-output port model for mechanical systems, in: AIAA
Guidance, Navigation, and Control Conference, 2015.
[3] D. Alazard, F. Sanfedino, A short course on TITOP models for space system
modelling, IFAC-PapersOnLine 54 (12) (2021) 7e13.
[4] F. Sanfedino, D. Alazard, Pommier-Budinger, Valérie, A. Falcoz, F. Boquet, Finite
element based N-Port model for preliminary design of multibody systems, Journal
of Sound and Vibration 415 (2018) 128e146. ISSN 0022-460X.
[5] D. Alazard, F. Sanfedino, Satellite dynamics toolbox for preliminary design phase, in:
43rd Annual AAS Guidance and Control Conference, 30 January 2020 - 5 February
2020 (Breckenridge, United States), 2020.
[6] D. Alazard, F. Sanfedino, Satellite Dynamics Toolbox Library (SDTlib) - User’s
Guide,” Tech. Rep, Institut Supérieur del’Aéronautique et de l’Espace, 2021.
https://nextcloud.isae.fr/index.php/s/oPQjcytZMxL27a5 (Accessed April 6 2021).
[7] N. Guy, D. Alazard, C. Cumer, C. Charbonnel, Dynamic modeling and analysis of
spacecraft with variable tilt of flexible appendages, Journal of Dynamic Systems, Mea￾surement, and Control 136 (2) (2014) 021020.
[8] G. Balas, R. Chiang, A. Packard, M. Safonov, Robust Control Toolbox User’s Guide,
The Math Works, Inc., Tech. Rep, 2007.
814 Stefano Silvestrini et al.[9] P. Apkarian, P. Gahinet, C. Buhr, Multi-model, multi-objective tuning of fixed￾structure controllers, in: 2014 European Control Conference (ECC). IEEE, 2014,
pp. 856e861.
[10] P. Apkarian, M.N. Dao, D. Noll, Parametric robust structured control design, IEEE
Transactions on Automatic Control 60 (7) (2015) 1857e1869.
[11] S. Silvestrini, M. Lavagna, Neural-aided GNC reconfiguration algorithm for distrib￾uted space system: development and PIL test, Advances in Space Research 67 (5)
(2021) 1490e1505.
[12] L.M. Steindorf, S. D’Amico, J. Scharnagl, F. Kempf, K. Schilling, Constrained low￾thrust satellite formation-flying using relative orbit elements, in: 27th AAS/AIAA
Space Flight Mechanics Meeting, 160, February 2017, pp. 3563e3583.
[13] C.M. Saaj, V. Lappas, V. Gazi, Spacecraft swarm navigation and control using artificial
potential field and sliding mode control, in: 2006 IEEE International Conference on
Industrial Technology, IEEE, December 2006, pp. 2646e2651.
[14] D. Morgan, S.J. Chung, F.Y. Hadaegh, Model predictive control of swarms of space￾craft using sequential convex programming, Journal of Guidance, Control, and Dy￾namics 37 (6) (2014) 1725e1740, https://doi.org/10.2514/1.G000218.
[15] S. Silvestrini, M. Lavagna, Neural-based predictive control for safe autonomous space￾craft relative maneuvers, Journal of Guidance, Control, and Dynamics 44 (12) (2021)
2303e2310.
[16] D.W. Curkendall, J.S. Border, Delta-DOR: the one-nanoradian navigation measure￾ment system of the deep space networkdhistory, architecture, and componentry, The
Interplanetary Network Progress Report 42 (2013) 193.
[17] R.W. Gaskell, O.S. Barnouin, D.J. Scheeres, et al., Characterizing and navigating small
bodies with imaging data, Meteoritics and Planetary Science 43 (6) (2008) 1049e1061.
[18] O.S. Barnouin, R. Gaskell, E. Kahn, et al., Assessing the Quality of Topography from
Stereo-Photoclinometry, Asteroids Comets Meteors, 2014.
[19] R. Pardo de Santayana, M. Lauer, Optical measurements for rosetta navigation near
the comet, International Symposium on Space Flight Dynamics (2015).
[20] M. Lauer, S. Kielbassa, R. Pardo, Optical Measurements for Attitude Control and
Shape Reconstruction at the Rosetta Flyby of Asteroid Lutetia, International Sympo￾sium on Space Flight Dynamics, 2012.
[21] B.G. Williams, Technical challenges and results for navigation of NEAR Shoemaker,
Johns Hopkins APL Technical Digest 23 (1) (2002) 34e45.
[22] S. Bhaskaran, S. Nandi, S. Broschart, et al., Small body landings using autonomous on￾board optical navigation, Journal of the Astronautical Sciences 58 (3) (2011) 409e427.
[23] M. Uo, K. Shirakawa, T. Hasimoto, Hayabusa touching-down to Itokawa￾autonomous guidance and navigation, The Journal of Space Technology and Science
22 (1) (2006) 32e41.
[24] N. Ogawa, F. Terui, Y. Fuyuto, et al., Image-based autonomous navigation of Hay￾abusa2 using artificial landmarks: the design and brief in-flight results of the first landing
on asteroid Ryugu, Astrodynamics 4 (2) (2020) 89e103.
[25] B. Williams, P. Antreasian, E. Carranza, et al., OSIRIS-REx flight dynamics and nav￾igation design, Space Science Reviews 214 (4) (2018) 1e43.
[26] D.A. Lorenz, R. Olds, A. May, et al., Lessons learned from OSIRIS-Rex autonomous
navigation using natural feature tracking, IEEE Aerospace Conference (2017) 1e12.
[27] T. Tolker-Nielsen, EXOMARS 2016-Schiaparelli Anomaly Inquiry, 2017.
[28] X. Liu, S. Li, M. Xin, Comparison of powered descent guidance laws for planetary
pin-point landing, Acta Astronautica (2021).
[29] A.R. Klumpp, Apollo lunar descent guidance, Automatica 10 (2) (1974) 133e146.
Applicative GNC cases and examples 815[30] Z.-yu Song, et al., Survey of autonomous guidance methods for powered planetary
landing, Frontiers of Information Technology & Electronic Engineering 21 (5)
(2020) 652e674.
[31] B. Acikmese, S.R. Ploen, Convex programming approach to powered descent guid￾ance for mars landing, Journal of Guidance, Control, and Dynamics 30 (5) (2007)
1353e1366.
[32] A.E. Johnson, J.F. Montgomery, Overview of terrain relative navigation approaches
for precise lunar landing, in: 2008 IEEE Aerospace Conference. IEEE, 2008.
[33] Y. Cheng, A. Ansar, Landmark based position estimation for pinpoint landing on mars,
in: Proceedings of the 2005 IEEE International Conference on Robotics and Automa￾tion. IEEE, 2005.
[34] N. Trawny, et al., Vision-aided inertial navigation for pin-point landing using obser￾vations of mapped landmarks, Journal of Field Robotics 24 (5) (2007) 357e378.
[35] D.G. Lowe, Object recognition from local scale-invariant features, in: Proceedings of
the Seventh IEEE International Conference on Computer Vision, 2, IEEE, 1999.
[36] J.R. Carr, J.S. Sobek, Digital scene matching area correlator (DSMAC), Image Process￾ing For Missile Guidance 238 (1980). International Society for Optics and Photonics.
[37] A. Johnson, et al., Design through operation of an image-based velocity estimation sys￾tem for Mars landing, International Journal of Computer Vision 74 (3) (2007)
319e341.
[38] H.C. Longuet-Higgins, A computer algorithm for reconstructing a scene from two
projections, Nature 293 (5828) (1981) 133e135.
[39] A. Frome, et al., Recognizing objects in range data using regional point descriptors, in:
European Conference on Computer Vision. Springer, Berlin, Heidelberg, 2004.
[40] B. Sabata, J.K. Aggarwal, Estimation of motion from a pair of range images: a review,
CVGIP: Image Understanding 54 (3) (1991) 309e324.
[41] J.P. Golden, Terrain contour matching (TERCOM): a cruise missile guidance aid, Im￾age processing for missile guidance 238 (1980). International Society for Optics and
Photonics.
[42] A.E. Johnson, A. Miguel San Martin, Motion estimation from laser ranging for auton￾omous comet landing, in: Proceedings 2000 ICRA. Millennium Conference. IEEE
International Conference on Robotics and Automation. Symposia Proceedings (Cat.
No. 00CH37065), 1, IEEE, 2000.
[43] Y. Cheng, et al., Passive Imaging Based Hazard Avoidance for Spacecraft Safe Landing,
2001.
[44] A.E. Johnson, et al., Lidar-based hazard avoidance for safe landing on Mars, Journal of
Guidance, Control, and Dynamics 25 (6) (2002) 1091e1099.
[45] A. Howard, H. Seraji, Multi-sensor terrain classification for safe spacecraft landing,
IEEE Transactions on Aerospace and Electronic Systems 40 (4) (2004) 1122e1131.
[46] J.F. Trégouët, D. Arzelier, D. Peaucelle, et al., Reaction wheels desaturation using
magnetorquers and static input allocation, IEEE Transactions on Control Systems
Technology 23 (2) (March 2015) 525e539, https://doi.org/10.1109/
TCST.2014.2326037.
[47] A.C. Stickler, K.T. Alfriend, Elementary magnetic attitude control system, Journal of
Spacecraft and Rockets 13 (5) (1976) 282e287.
[48] F.L. Markley, J.L. Crassidis, Fundamentals of Spacecraft Attitude Determination and
Control, Space Technology Library, Springer, New York, 2014.
[49] A. Colagrossi, M. Lavagna, Fully magnetic attitude control subsystem for picosat
platforms, Advances in Space Research 62 (2018) 3383e3397.
[50] A. Colagrossi, M. Lavagna, A spacecraft attitude determination and control algorithm
for solar arrays pointing leveraging Sun angle and angular rates measurements, Algo￾rithms 15 (2022) 29, https://doi.org/10.3390/a15020029.
816 Stefano Silvestrini et al.[51] A.H.J. De Ruiter, C.J. Damaren, J.R. Forbes, Spacecraft Dynamics and Control: An
Introduction, John Wiley & Sons, 2013.
[52] H. Curtis, Orbital Mechanics for Engineering Students, Elsevier, 2005.
[53] M.J. Sidi, Spacecraft Dynamics and Control: A Practical Engineering Approach, Cam￾bridge University Press, 1997.
[54] D.A. Vallado, Fundamentals of Astrodynamics and Applications, 12, Springer Science
& Business Media, 2001.
[55] J.M. Longuski, J.J. Guzman, J.E. Prussing, Optimal Control with Aerospace
Applications, Microcosm Press, Springer, 2014.
[56] A. Colagrossi, V. Pesce, L. Bucci, et al., Guidance, navigation and control for 6DOF
rendezvous in Cislunar multi-body environment, Aerospace Science and Technology
114 (2021) 106751.
[57] A. Colagrossi, M. Lavagna, Fault tolerant attitude and orbit determination system for
small satellite platforms, Aerospace 9 (2022) 46.
[58] R. Pandiyan, A. Solaiappan, N. Malik, A one step batch filter for estimating gyroscope
calibration parameters using star vectors, in: AIAA/AAS Astrodynamics Specialist Con￾ference and Exhibit. Providence, AIAA 04-4858, 2004.
[59] M.E. Pittelkau, Kalman filtering for spacecraft system alignment calibration, Journal of
Guidance, Control, and Dynamics 24 (6) (2001).
[60] R. Alonso, M.D. Shuster, Complete linear attitude-independent magnetometer
calibration, Journal of the Astronautical Sciences 50 (4) (2002) 477e490.
[61] R. Alonso, M.D. Shuster, TWOSTEP: a fast robust algorithm for attitude￾independent magnetometer-bias determination, Journal of the Astronautical Sciences
50 (4) (2002) 433e451.
[62] J.L. Crassidis, K.L. Lai, R.R. Harman, Real-time attitude-independent three-axis
magnetometer calibration, Journal of Guidance, Control, and Dynamics 28 (1)
(2005) 115e120.
[63] R. Mahony, T. Hamel, J.M. Pflimlin, Nonlinear complementary filters on the special
orthogonal group, IEEE Transactions on Automatic Control 53 (2008) 1203e1218.
[64] A. Colagrossi, et al., Dynamical evolution about asteroids with high fidelity gravity
field and perturbations modeling, in: 2015 AAS/AIAA Astrodynamics Specialist Con￾ference. Univelt, 2016.
[65] A. Colagrossi, F. Ferrari, M. Lavagna, Coupled dynamics analysis around asteroids by
means of accurate shape and perturbations modeling, in: 66th International Astronau￾tical Congress (IAC 2015). Curran Associates, 2015.
[66] A. Colagrossi, M. Lavagna, Dynamical analysis of rendezvous and docking with very
large space infrastructures in non-Keplerian orbits, CEAS Space Journal 10 (1)
(2018) 87e99, https://doi.org/10.1007/s12567-017-0174-4.
Applicative GNC cases and examples 817This page intentionally left blankCHAPTER FIFTEEN
Modern Spacecraft GNC
Stefano Silvestrini1
, Lorenzo Pasqualetto Cassinis2
, Robert Hinz3
,
David Gonzalez-Arjona4
, Massimo Tipaldi5
, Pierluigi Visconti6
,
Filippo Corradino6
, Vincenzo Pesce7
, Andrea Colagrossi1
1
Politecnico di Milano, Milan, Italy
2
TU Delft, Delft, the Netherlands
3
Deimos Space, Madrid, Spain
4
GMV Aerospace & Defence, Madrid, Spain
5
University of Sannio, Benevento, Italy
6
Tyvak International, Turin, Italy
7
Airbus D&S Advanced Studies, Toulouse, France
The following chapter gives an overview on modern techniques for guid￾ance, navigation, and control (GNC). In particular, an overview of artificial
intelligence (AI) techniques is provided in light of a tailored application to
the space domain. Thanks to their enormous success in a great variety of ap￾plications and fields, modern AI techniques can be found in almost every
aspect of science and engineering as well as everyday life. AI enables the
automation of tasks previously limited to humans, even surpassing human
performance on many tasks. Consequently, the terms AI, machine learning
(ML), and deep learning (DL) are nowadays ubiquitous and are often used
interchangeably to describe computer systems which are designed to act
in an intelligent way. Among the modern applications, a thorough descrip￾tion of innovative methods for GNC failure (or fault) detection, isolation,
and recovery (FDIR) is presented, highlighting the latest novelties. Finally,
the emerging topic of CubeSats and nanosatellites, in general, is treated by
underlining the peculiar challenges that such missions pose.
In detail, this chapter is composed by the following sections:
• AI in space e Introduction. This section presents the basics and funda￾mental concepts of AI and DL, with a particular attention to space￾related applications.
• AI and navigation. This section extends the fundamentals of AI described
in the first section to convolutional neural networks (CNNs)-based sys￾tems for space navigation.
Modern Spacecraft Guidance, Navigation, and Control
ISBN: 978-0-323-90916-7
https://doi.org/10.1016/B978-0-323-90916-7.00015-9
© 2023 Elsevier Inc.
All rights reserved. 819 j• Validation of AI-based systems e Introduction. The section presents the chal￾lenges linked to the validation of AI-based systems. In particular, the
problem of sparsity of real space-born imagery and the necessity of large
data sets for ANN/DL-based methods is tackled. Then, the section
discusses the procedures for the generation of laboratory and synthetic
images and the challenges of training on synthetic datasets.
• Reinforcement learning. This section presents an overview of reinforcement
learning paradigm for AI-based systems.
• AI use cases. The section presents a set of use cases of AI-based GNC
systems at research level. This section should be used as an up-to-date
literature survey.
• AI on-board processors. The section presents the avionics hardware (HW)
processing solutions targeting specifically AI demanding applications
such as multiprocessors, video processor units (VPUs), LPGPU, FPGA,
VITIS-XILINX versus INTEL, DSP, and the link to the development
frameworks that might include autocoding or deployment libraries for
different processing elements modules of the execution neuronal
network (convolution engines, max-pooling, etc.).
• Innovative techniques for highly autonomous FDIR in GNC applications. The
section presents the FDIR system evolution foreseen in the next years,
which includes model-based FDIR system, in terms of innovative
technical solution and its workflow. Moreover, advanced control engi￾neering methods, together with ML-based techniques for innovative
GNC applications are presented.
• Small satellites/CubeSats. This section intends to provide a practical
outlook on GNC and Attitude Determination and Control System
(ADCS) subsystems in nanosatellites, especially to designers coming
from academia or larger spacecraft. The section goes over a brief over￾view of CubeSats missions and their state-of-the-art, in order to intro￾duce this class of platform should the reader not be familiar with it. Then,
it extensively analyzes the limitations related to the HW which can be
employed in CubeSats for Altitude and Orbit Control (AOCS)/ADCS,
first from a higher-level perspective (volumes, redundancy, rad-hard vs.
commercial, etc.). Finally, it provides an outlook on the practical chal￾lenges related to sizing and design trade-offs, for a low Earth orbit (LEO)
mission and for an interplanetary mission with propulsion, as well as
verification and testing, looking also at typical requirements and how to
approach their compliance and verification.
820 Stefano Silvestrini et al.AI in spacedIntroduction
Introduction
AI, ML, DL, and ANN: What is the difference?
The terms AI, ML, and DL are currently present in most of technological
discussions in different engineering fields. Moreover, they are often mutu￾ally replaced to describe computer systems which are designed to act in an
intelligent way. While these terms are closely linked, with DL and artificial
neural networks (ANNs) forming part of ML, which in turn is considered a
subset of AI (Fig. 15.1), it is useful to understand the key distinctions be￾tween them:
• AI. It is a branch of computer science which is concerned with the the￾ory and development of systems which are capable of performing tasks
normally requiring human intelligence. This does include systems which
emulate human intelligence based on fixed rules and data bases, like
knowledge graphs and expert systems, but also ML systems which are
capable of modifying themselves when exposed to new data.
• ML. It is, therefore, generally considered a subset of AI. It is commonly
defined as the field of study that gives computers the ability to learn
without being explicitly programmed [1].1 A more formal definition
of the types of algorithms studied in the field of ML is given by Ref. [2]:
A computer program is said to learn from experience E with respect to some class
of tasks T and performance measure P, if its performance at tasks in T, as
measured by P, improves with experience E.
An ML algorithm generally learns by solving an optimization problem, typically by
minimizing the error or maximizing the likelihood of its predictions being true,
with the performance of the algorithm being measured by a task-dependent
objective function.
• DL. It is a subfield of ML concerned with ANNs, or more precisely, deep
neural networks (DNNs), which consist of ANN with more than two
layers. ANNs are ML models inspired by the biological neural networks
that constitute animal brains. Although conceptually around for over
half a century, they only gained importance over the last decade due to
their high computational demands. DNNs are setting new records in
1 This definition paraphrases a quote from Arthur Samuel, a pioneer of artificial intelligence research:
“Programming computers to learn from experience should eventually eliminate the need for much
[.] programming effort.” [1].
Modern Spacecraft GNC 821accuracy for many important problems, such as image recognition, sound
recognition, recommender systems, and natural language processing.
Since the term AI is extremely wide and its boundaries often blurred, this
book will focus on ML and DL methods.
Learning paradigms: supervised, unsupervised, and
reinforcement learning
ML scenarios can be categorized depending on the task to be solved and the
data available to both train and test the learning algorithm. The three main
categories are supervised, unsupervised, and reinforcement learning, which
are summarized in the following alongside the most common tasks they
are associated with.
• Supervised learning. A supervised learning algorithm receives a training
data set consisting of labeled examples, where for each given input,
the true output is provided. After the learning phase, the algorithm
makes predictions on unseen data. This is the most common setup in
regression and classification problems, as illustrated in Fig. 15.2.
1. Classification. In classification problems, the aim is to assign a discrete
value or class label to each input. Typical examples include spam
detection, where the algorithm determines whether an email should
be considered spam or not, and image classification, where class labels
are assigned to each image depending on their content (e.g., if they
show a car, a plane, or a boat). Fault detection can also be framed
as a classification problem, where, for example, from a number of
telemetry parameters, the correct or faulty behavior of a spacecraft
is determined.
Figure 15.1 Relation between AI, ML, and DL.
822 Stefano Silvestrini et al.2. Regression. In regression problems, the task is to predict a real valued
output for each input. Typical regression examples include stock
market and house price prediction, where a price is predicted on
the basis of input features like number of rooms and the area of a
house.
A detailed description of supervised learning is given in the next section
where linear and logistic regression is introduced for regression and classifi￾cation tasks.
• Unsupervised learning. In unsupervised learning, training is performed on
unlabeled training data. This means that during training, the correct or
true output for the given input is unknown. In general, this makes it
difficult to quantitatively evaluate the performance. The learning algo￾rithm is used to automatically find patterns and structure in the data. Ap￾plications include clustering, where the objective is to partition the
dataset into homogeneous subsets, and dimensionality reduction
methods such as principal component analysis (PCA) [3], where a
lower-dimensional representation of high-dimensional input data is
found (Fig. 15.3). The k-means algorithm is described below as an
example for a widely used unsupervised learning method.
• Reinforcement learning. In reinforcement learning, an algorithm learns
from trial and error. In contrast to supervised and unsupervised learning,
there is no clear separation between the training and testing phases.
Instead, the learning algorithm, called agent, actively interacts with the
environment and receives an immediate reward for its actions. The
learning objective is to maximize the overall reward over a number of
Figure 15.2 Supervised learning tasks: classification and regression.
Modern Spacecraft GNC 823actions. Reinforcement learning has, for example, been used to teach
computers how to play the game of Go, defeating the world champion
[4]. A detailed introduction to reinforcement learning is given in Chapter
15 e Modern Spacecraft GNCdReinforcement Learning (Fig. 15.4).
The following sections of this chapter will give an overview of the basic
concepts and methods in ML which are necessary to understand modern
DL-based AI applications. The first section describes the k-means algorithm
for clustering as an example for unsupervised learning. Then, three ML
models of stepwise increasing complexity are used to introduce techniques,
concepts, and typical tasks of supervised learning: model representation,
parameter learning, and generalization properties are described for linear
regression. Logistic regression is then presented as a nonlinear model for binary
Figure 15.4 Reinforcement learning.
Figure 15.3 Unsupervised learning tasks: clustering and dimensionality reduction.
824 Stefano Silvestrini et al.classification tasks and prepares the ground for the description of ANN. The
multilayer perceptron (MLP), a basic DL model, is finally used to describe multi￾class classification and the backpropagation learning algorithm for ANNs.
Finally, CNNs and recurrent neural networks (RNNs) are introduced as
modern DL architectures for computer vision (CV) and sequence tasks,
respectively.
Unsupervised learning: k-means clustering
A common unsupervised learning problem is clustering, where the aim is to
partition a given unlabeled dataset D ¼ 
xð1Þ
; xð2Þ
; .; xðmÞ
 of m samples
x˛Rd into a number of k coherent subsets or clusters S ¼ ðS1; S2;.; SkÞ.
One of the most popular methods for clustering is the k-means algorithm
[5], which aims at minimizing the within-class variance,
argmin
S
X
k
i¼1
X
x˛Si
kx  mik2
where mi is the mean of all points in Si. Beside the input dataset D, the
number k of desired clusters has to be provided to the algorithm.
k-mean consists of two iterative steps, the cluster assignment step and the
update step, preceded by an initialization step which is only executed once:
1. Initialization: k preliminary clusters are defined, for example, by
randomly choosing k samples x as preliminary cluster means. All samples
are then assigned to the cluster represented by the closest preliminary
cluster mean, defined by the Euclidean distance.
2. In the cluster assignment step, the distance of each sample x to the number
of k means m of all clusters is calculated, and x is assigned to the cluster
corresponding to the closest cluster mean.
3. In the update step, the cluster mean is updated taking into account the as￾signments from step 1.
Steps 1 and 2 are repeated until the cluster means and, therefore, the clus￾ter assignments do not change any further. k-means is not guaranteed to find
the optimal partition since it can get stuck in local optima, and the final result
may depend on the particular initialization. For this reason, it is a common
practice to execute k-means multiple times with varying starting conditions
(Fig. 15.5).
Modern Spacecraft GNC 825Supervised learning: regression and classification
Linear regression
Model representation
Linear regression is the simplest regression algorithm and a classic example
for the concepts and notation involved in supervised learning. Given a
training data set of m samples:
D ¼ xð1Þ
; yð1Þ

;

xð2Þ
; yð2Þ

;.;ðxðmÞ
; yðmÞ
Þ

where for each input vector x˛RN , the corresponding output y˛ R is
included and a family of linear hypotheses hwðxÞ : X/Y;
hwðxÞ ¼ w0 þ w1x1 þ w2x2 þ . þ wN xN (15.1)
where each particular hypothesis is defined by a parameter vector w˛ RNþ1,
the task of linear regression is it to find the hypothesis which best describes
the dataset D.
Cost function for regression
This corresponds to finding the parameter values w for which the error
between the given ground truth (GT) values y and the model predictions
by ¼ hðxÞ is minimized. The error for a given training example ðxðiÞ
; yðiÞ
Þ
is given by the loss function. For linear regression, it is defined by the squared
error:
LðiÞ
ðw0; w1Þ ¼ 
hw

xðiÞ

 yðiÞ
2
The performance on the whole training set is calculated by the cost func￾tion, also called the error function or objective function, which for linear
Figure 15.5 Three processing iterations of K-means clustering. Black stars mark the
cluster means, and their position update is illustrated by the black tracks.
826 Stefano Silvestrini et al.regression is the average error over the whole data set, defined by the mean
squared error (MSE) JðwÞ ¼ 1
2m
Pm
i¼1
ðhwðxðiÞ
Þ  yðiÞ
Þ
2
.
By using the squared error, it is guaranteed that the result is always pos￾itive regardless of the sign of the predicted and target values. While the
choice of the cost function depends on the problem at hand, MSE loss works
well for most (not only linear) regression problems.
The objective is to find the hypothesis, i.e., the model parameters w,
which minimize JðwÞ:
argmin w
JðwÞ
Parameter learning: gradient descent
Although the optimization problem for linear regression with MSE can be
solved analytically using the normal equation, here we will introduce and
focus on gradient descent (GD), a more general numerical approach which
forms the basis for parameter learning in many other ML models, including
ANNs and DL problems. Nevertheless, there exist several alternatives for
numerical optimization methods, such as:
• Newton and GausseNewton methods.
• LevenbergeMarquardt algorithm.
• Conjugate gradient.
The detailed description of each method goes beyond the scope of this
book, but it is important to remark that the methods have common basis
and, above all, similar implementations. Indeed, the LevenbergeMarquardt
curve-fitting algorithm can be regarded as a combination of GD method and
GausseNewton. The behavior of LevenbergeMarquardt algorithm resem￾bles the GD method when the weights are far from their optimal values and
acts more like the GausseNewton method when the weights are close to
their optimal value.
Going back to GD, to illustrate the idea behind it, we will use the simpli￾fied case of N ¼ 1 and w0 ¼ 0, for which the hypothesis reduces to hwðxÞ ¼
w1x1 and can be represented by a straight line through the origin, with w1
controlling the slope of the line. In this case, the cost function is a quadratic
polynomial in w1, shown in Fig. 15.6.
GD uses the gradient VJðwÞ ¼  vJ
vw0
; vJ
vw1
; .; vJ
vwN
T
of the cost function
with respect to the model parameters in order to systematically update the
Modern Spacecraft GNC 827parameter values and to gradually approach a minimum of the cost function.
This is illustrated in Fig. 15.6 for the simplified hypothesis: starting from an
initial value of parameter w1, GD determines an increment Dw1 for which
the error decreases, i.e., Jðw1 þDw1ÞhJðw1Þ. This corresponds to moving
down the slope of Jðw1Þ. Since the direction of the steepest positive slope
is given by the partial derivative vJ
vw1
, the update is done in the opposite di￾rection, w0
1 ¼ w1  h v
vw1
JðwÞ, where h is called the learning rate which de￾termines the step width and is a hyperparameter which has to be chosen
manually. This update is repeated until reaching a minimum of the cost
function. For convex functions like the MSE cost function used in linear
regression, GD reaches the global minimum. For different, nonconvex
cost functions with local minima, this is, however, not guaranteed
(Fig. 15.7).
In the general N-dimensional case, the update for w0
0 and w0
k ðk  1Þ is
given by:
w0
0 ¼ w0  a
1
m
Xm
i¼1

hw

xðiÞ

 yðiÞ

w0
k ¼ wk  a
1
m
Xm
i¼1
hw

xðiÞ

 yðiÞ

xðiÞ

(15.2)
which, using the gradient, can be written as w0 ¼ w  a VJðwÞ.
Feature engineering and polynomial regression
The linear hypothesis in Eq. (15.1) can easily be extended to capture more
complex, nonlinear problems through the addition of nonlinear features or
feature combinations. For example, for a two-dimensional (2D) input x ¼
ðx1; x2Þ, we can define new features x3 ¼ ffiffiffiffi
x1
p or x4 ¼ x1x2 and add these
Figure 15.6 Linear regression and gradient descent.
828 Stefano Silvestrini et al.to our hypothesis. The manual process of creating new features is called
feature engineering and ideally involves previous domain knowledge about
the problem at hand. A common, systematic way of increasing model
complexity are polynomial features, which use polynomial combinations of
the features with degree less than or equal to the specified degree. For
example, for a 2D input x ¼ ðx1; x2Þ, the two-degree polynomial features
are 1; x1; x2; x1x2; x2
1; x2
2, resulting in the hypothesis:
hwðxÞ ¼ w0 þ w1x1 þ w2x2 þ w3x1x2 þ w4 x
2
1 þ w5 x
2
2 (15.3)
Generalization: under- and overfitting, training, test, and validation set
During training, optimization is performed with the objective to reduce the
error on the training set. It is, however, not guaranteed that a model which
works well on the training data will perform equally well on new data.
Instead, a test set of previously unseen data is used to assess the final perfor￾mance and generalization of the trained model. In order to make valid state￾ments on the generalization capabilities, train and test sets have to meet
certain properties: they have to be independent from each other, meaning
that they cannot share data points; and it should be safe to assume that
both data sets are drawn from the same probability distribution.
By comparing the error on the training set with the test (also called
generalization) error, it can be determined if the model generalizes well,
or if it is under- or overfitting the data (Fig. 15.8):
• Underfitting. Both the training and test errors are high, as the model does
not account for relevant information present in the training set. The
model is said to have high bias/low variance because the assumptions the
model is based on are too rigid and prevent it from capturing the variance
in the data.
Figure 15.7 Gradient descent, local and global minima.
Modern Spacecraft GNC 829• Overfitting. The gap between test and training error is large. The model
learns properties and patterns which are very specific to the training data,
leading to a small training error. It, however, fails to generalize to the un￾seen test data, yielding a large test error. This corresponds to low bias/high
variance.
The propensity to over- or underfit is captured by the model capacity,
which can be loosely defined as a model’s ability to approximate complex
problems and fit a variety of functions. In the polynomial regression example
above, the model capacity increases with the degree of the added polyno￾mial features: the higher the degree, the more variation can be captured
by the model. In general, in order for a model to perform well, its capacity
has to match the complexity of the specific task: a low-capacity model is un￾able to solve a complex problem (Fig. 15.8, top left), while on the other
hand, a high-capacity model may fit the specific data too closely
(Fig. 15.8, top right). This property of the model is called the biasevariance
trade-off (Fig. 15.8, bottom) [6].
In addition to the trainable parameters or weights, a model is further
defined by its hyperparameters: parameters which are not inferred during
model training but are concerned with the learning algorithm’s behavior
(e.g., the learning rate a for GD) or the model selection, like the type or
structure of the model (e.g., the degree in polynomial regression). Just as
the training set has to be separate from the test set, a distinct validation set
has to be used to assess the performance of the model during the tuning
of the hyperparameters in order to guarantee that the model generalizes
well to unseen data.
Figure 15.8 Relationship between model capacity and error.
830 Stefano Silvestrini et al.Logistic regression for binary classification
Model representation
In classification problems, the target variable or class label y which is to be
predicted has a discrete value used to distinguish between two (binary clas￾sification) or more (multiclass classification) classes. Classical examples for
classification problems include sentiment analysis, anomaly detection (e.g.,
fraud detection), or image classification (e.g., distinguish between cats and
dogs, classification of handwritten digits). Binary classification can also be
used for fault detection, where given some sensor output x, the objective
is to determine if a spacecraft is working correctly (y ¼ 0) or deviates
from its nominal performance (y ¼ 1).
Despite the slightly misleading name, logistic regression is not used for
regression problems, but is one of the most popular and basic ML algorithms
for classification. The name merely originates from its similarities to linear
regression and from the use of the logistic function. Instead of directly calcu￾lating the binary class (0,1) for each input, the idea behind logistic regression
is to (1) predict the conditional probability Pðyjx; wÞ of label y being 1 given
the input features x and the model parameters w and (2) applying a threshold
to the probability value in order to predict the discrete class label, i.e.,
by ¼
( 1 if Pðy ¼ 1jx; wÞ  0:5
0 if Pðy ¼ 1jx; wÞ < 0:5
In order to obtain probability values between 0 and 1, logistic regression
uses the linear hypothesis seen for linear regression,
z ¼ w0 þ w1x1 þ w2x2 þ . þ wNxN ; (15.4)
and applies the sigmoid function (also called logistic function, hence the
name logistic regression). The sigmoid function (Fig. 15.12) is defined as
sðzÞ ¼ 1
1þez and maps any real value into the range 0e1. The model hy￾pothesis for logistic regression is thus given by:
hwðxÞ ¼ sðw0 þ w1x1 þ w2x2 þ. þ wN xN Þ ¼ sðzÞ (15.5)
By defining an additional constant feature x0 ¼ 1, logistic regression
can be presented in a vectorized formulation. Given the n-dimensional
feature vector x ¼ ½ x0 x1 . xn 
T and the parameter or weight vec￾tor w ¼ ½ w0 w1 . wn 
T , the input to the logistic function, z ¼
w0 þ w1x1 þ . þ wnxn, can be vectorized to z ¼ wT x, and the model
equation for logistic regression can be written as:
hwðxÞ ¼ s

w
T x

: (15.6)
Modern Spacecraft GNC 831In order to illustrate the idea behind logistic regression, note that sðzÞ 
0:5 for z  0 and sðzÞ < 0:5 for z < 0, and thus:
by ¼
( 1 if z  0
0 if z < 0
In a 2D (N ¼ 2) binary classification example, this means that any
example with features x1 and x2 which satisfy the equation w0þ w1x1þ
w2x2  0 will result in a hypothesis prediction by ¼ 1. The straight line
defined by w0 þ w1x1 þ w2x2 ¼ 0 is called the decision boundary as it sepa￾rates the two regions for which hwðxÞ predicts either class 0 or 1. In higher
dimensional problems, the decision boundary is formed by a hyperplane.
More complex models with nonlinear decision boundaries can be gener￾ated by adding polynomial features analogous to the approach seen earlier
for polynomial regression. For example, by adding quadratic terms to Eq.
(15.5),
hwðxÞ ¼ s

w0 þ w1x1 þ w2x2 þ w3x
2
1 þ w4x
2
2

the decision boundary can now take on more complex shapes. For illus￾tration, parameter values w0 ¼ 1; w1 ¼ w2 ¼ 0; w3 ¼ w4 ¼ 1 result in a
decision boundary defined by the circle equation x2
1 þ x2
2 ¼ 1 shown in
Fig. 15.9. More complex decision boundaries are possible adding higher
degree polynomial features.
The decision boundary defined above is no property of the data set but of
the model hypothesis, and hence of parameters which have to be learned
from the training data. As seen for linear regression, this is done by solving
an optimization problem involving an adequate loss function.
Figure 15.9 Classification with linear and nonlinear decision boundary.
832 Stefano Silvestrini et al.Cost function for binary classification
Because the nonlinearity of the logistic regression hypothesis hwðxÞ renders
the MSE cost function used for linear regression to be nonlinear and non￾convex, the binary cross-entropy loss function is used instead, given by:
L

hw

xðiÞ

; yðiÞ

¼
8
<
:
log
hw

xðiÞ
;
log
1  hw

xðiÞ
;
yðiÞ ¼ 1
yðiÞ ¼ 0
(15.7)
In the case of true label yðiÞ ¼ 1, L goes to infinity for hw/0, strongly
penalizing an incorrect prediction, whereas the loss disappears (L ¼ 0) for
hw ¼ 1. Analogously, penalization is inverted for yðiÞ ¼ 0, as shown in
Fig. 15.10.
As for linear regression, the complete cost function is defined as the sum
over all training samples. For that purpose, function Eq. (15.7) can be simpli￾fied into a single equation:
JðwÞ¼  1
m
Xm
i¼1

yðiÞ log
hw

xðiÞ
 þ 
1  yðiÞ

log
1  hw

xðiÞ
 
(15.8)
By multiplying the two logarithmic terms by yðiÞ and ð1 yðiÞ
Þ, respec￾tively, only the one corresponding to the specific true class label yðiÞ will add
to the total cost. The binary cross-entropy loss is one of the standard loss
functions used for classification problems.
In contrast to the MSE loss function for linear regression, there is no
closed form to determine the optimal parameters using Eq. (15.8), and
numerical methods like GD have to be used. The GD update equations
for logistic regression are the same as Eq. (15.2) for linear regression, where
Figure 15.10 Binary cross-entropy loss.
Modern Spacecraft GNC 833hw now represents the hypothesis for logistic regression. Logistic regression
models tend to overfit the data, particularly in high-dimensional settings. For
this reason, regularization methods are often used to prevent the model from
fitting too closely to the training data.
Artificial neural networks for multiclass classification
ANNs are the state-of-the-art for many ML problems. They are able to
learn complex nonlinear hypotheses, for example, in nonlinear classification
problems. One of the strengths of ANNs lies in their capability to automat￾ically learn abstract feature representations of the input data, removing the
need for manual feature engineering.
As seen in the previous sections, manual feature generation like the addi￾tion of polynomial features is a common and effective way to increase model
complexity. However, in addition to increasing the tendency for overfitting,
in practice, this method might not always be feasible, especially for problems
which already come with a big number of input features, since depending on
the order of polynomials to add the total number of features may increase
drastically. Just by considering the addition of second-degree polynomial
terms, the number of features increases roughly quadratically. Depending
on the number of initial features and the data to process, this can become
computationally infeasible.
As we will see in more detail discussing networks topologies, this is espe￾cially limiting for CV problems like image classification, where the input
consists of whole images, or more precisely, the input features are given
by the intensity values of each image pixel. For an image of size
100  100, including only second-order polynomial features will result in
millions of features, and it is not guaranteed that the increase in complexity
will be sufficient. As we will see, ANNs can deal with a large input feature
space by successively learning more and more abstract features automatically.
Universal approximation theorem
The founding theorem that proves the capability of ANNs to automatically
learn abstract feature representations of the input data is the so-called univer￾sal approximation theorem. The classical form reads:
Let f : R /R be a nonconstant, bounded, and continuous function (called the
activation function). Let Im denote the m-dimensional unit hypercube ½0; 1
m. The
space of real-valued continuous functions on Im is denoted by CðImÞ. Then, given
any ε > 0 and any function f ˛CðImÞ, there exists an integer N; real constants
vi;bi˛R , and real vectors wi˛Rm; c i ¼ 1; .; N, such that we may define:
834 Stefano Silvestrini et al.FðxÞ ¼ X
N
i¼1
vif

w
T
i x þ bi

as an approximate realization of the function f , that is:
jFðxÞ  f ðxÞj < ε; c x˛Im
Roughly speaking, the theorem states that there is always a neural
network architecture (number of layers, weights, and biases) to approximate
a given function to a desired accuracy.
Model representation
The name artificial neuronal network derives from the fact that it consists of
networks of interconnected nodes, analogous to biological neurons in the
brain. The neurons in an ANN are organized in layers. In the classic
ANN model called MLP, neurons belonging to the same layer receive in￾puts from all the neurons of the previous layer and send their output to
each neuron of the following layer (Fig. 15.11). The MLP is a feedforward
ANNdthe flow from layer to layer always goes in the same directiondand
it is fully connected, since every neuron is connected to every neuron in the
next layer.
Figure 15.11 Multilayer perceptron/Fully Connected Neural Network with three layers.
The b
ð2Þ
0 represents the bias of the second layer (often referred as first activation
neuron).
Modern Spacecraft GNC 835The first layer of an ANN, which consists of the input features, is called
the input layer, and accordingly, the last layer, which returns the final results,
is called the output layer. All the intermediate layers are hidden layers, since in
contrast to the input and output layer, where (in the case of supervised
learning) we can compare the value of each node with its true value given
in the training set, the true values for hidden layers are unknown. When
counting the number of layers, the input layer is commonly not taken
into account, and therefore an ANN with one input, one hidden, and
one output layer is referred to as two-layer network. An ANN with one
or more hidden layers is called a DNN. Analogously, a network without
hidden layer is called a shallow neural network.
Fig. 15.11 shows a two-layer MLP for binary classification as an example,
with the input layer representing kð1Þ input features, one hidden layer with
kð2Þ units, and kð3Þ units in the output layer for the classification output. The
parameters characterizing a MLP are the following:
• N - The number of layers or depth of the network.
• kðlÞ - The number of units in layer l.
• gðzÞ - The nonlinear activation function applied to each unit (e.g., lo￾gistic function sðzÞ).
• wðlÞ
i - The kðl1Þ
-dimensional parameter or weight vector of unit i in
layer l with elements wðlÞ
ij .
• b
ðlÞ
i - The bias parameter of unit i in layer l.
• z
ðlÞ
i - The kðlÞ
-dimensional input vector to unit i in layer l.
• a
ðlÞ
i - Activation, i.e., scalar output of unit i in layer l. All outputs of layer l
are summarized in the kðlÞ
-dimensional activation vector aðlÞ
. To facili￾tate a generalized notation, we define að0Þ ¼ x and aðLÞ ¼ y.
The input vector z to each unit is calculated from the vector of activa￾tions of all units of the previous layer,
z
ðlÞ
i ¼ wðlÞ
i a
ðl1Þ þ b
ðlÞ
i
The activations of unit i in layer j are then calculated applying the acti￾vation function:
a
ðlÞ
i ¼ g

z
ðlÞ
i

With respect to Eq. (15.5), here the logistic function s has been substituted
by the more general nonlinear activation function gðzÞ. If the logistic
836 Stefano Silvestrini et al.function is used as an activation function, each unit acts like a logistic re￾gressor with inputs being the activations of all units of the previous layer.
Hence, logistic regression can be viewed as a shallow, one-layer neural
network. In practice, for ANNs, the logistic function s is often replaced by
different nonlinear activation functions (Fig. 15.12). Some of the most com￾mon functions are:
• The sigmoid or logistic function (Fig. 15.12, left) maps values to the range
ð0; 1Þ and is the default activation function when the output is inter￾preted as a probability, e.g., the probability of corresponding to a given
class in a classification task.
• The hyperbolic tangent (Fig. 15.12, center has a shape similar to the sigmoid
function, but is zero-centered, returning values in the range between 1
and 1. It is also used in binary classification tasks.
• The rectified linear unit (ReLU) activation function (Fig. 15.12, right)
has become an extremely popular activation function for hidden units
in DNNs and especially for CNNs, due to a series of advantages:
compared to the sigmoid function, computation is more efficient, it pro￾vides better gradient propagation, and mitigates the problem of vanishing
gradients which will be discussed later.
• The softmax activation function can be seen as a generalization of the lo￾gistic function to multiple dimensions and is defined as:
sðzÞi ¼ e
zi
PK
k¼1ezk
It is commonly used in the output layer of a multiclass classification neu￾ral network in order to normalize the output to a probability distribution
over the predicted output classes since it guarantees that the sum over all class
probabilities adds up to 1.
Figure 15.12 Common activation function.
Modern Spacecraft GNC 837The notation of the neural network equations can be further simplified
by defining the weight matrix WðlÞ containing all the weights which define
the connections between layer l and l  1: Thus, column i of matrix WðlÞ
corresponds to the parameter vector wðlÞ
i which contains the weights con￾necting all units in layer l  1 with unit i in layer l. The equations summa￾rizing all operations in layer l can then be written as:
zðlÞ ¼ WðlÞT aðl1Þ þ b
ðlÞ
aðlÞ ¼ g

zðlÞ

WðlÞ has dimensions 
kðl1Þ þ1
  kðlÞ
, where “þ1” corresponds to the
bias unit which is added to the dimension of layer l  1.
Cost function for multiclass classification
As mentioned before, the choice of the loss function depends on the specific
ML problem. In the example of linear regression, the mean square error was
used; for binary classification using logistic regression, binary cross entropy
was introduced. For the ANN, we will use multiclass classification with
the categorical cross entropy as an example.
Where in binary classification the model prediction was restricted to two
classes, labeled 0 or 1, in multiclass classification, the output labels corre￾spond to K classes, where K  3. The neural network represents these clas￾ses by K output units, resulting in a K-dimensional output vector by ¼
hwðxÞ ˛RK. Using the softmax activation function in the output layer,
the sum over all vector elements is 1, and thus each element yk can be inter￾preted as the probability of belonging to class k:
The categorical cross-entropy cost function for this case is calculated from the
GT labels y and the predicted values by and is defined as:
Jð y; by;WÞ ¼  1
m
Xm
t¼1
X
K
k¼1

y
ðtÞ
k log
by
ðtÞ
k

þ 
1  y
ðtÞ
k

log
1  by
ðtÞ
k
 
where the subscript k indicates the k-th vector component and t indicates
the training sample. In other words, the total categorical cross-entropy cost is
obtained by summing over the binary cross-entropy cost of all K output
units.
838 Stefano Silvestrini et al.ANN parameter learning: backpropagation and gradient descent
Training of an ANN follows the same steps as seen earlier for linear and lo￾gistic regression: firstly, it requires the definition of a cost function which
matches the problem in question and defines the optimization objective, fol￾lowed by the optimization procedure itself, e.g., using GD. The main dif￾ference regarding ANNs is the increased complexity of the computation
steps involved. The objective is to find the weights W which minimize
the cost function, argmin
W
Jð y; by;WÞ, which can be achieved through iter￾ating the following steps:
1. For a given training sample ðxðtÞ
; yðtÞ
Þ, perform the model computations
to obtain output by. For a feedforward ANN, this step is called forward
propagation since calculations are performed layer by layer and informa￾tion is propagated forward through the network.
2. Calculate the scalar loss or error Jð y; by;WÞ.
3. Use GD to update the model weights. To this end, we need to calculate
the changes in the total error connected to changes in each single weight
of the network, given by the partial derivatives v
vwðlÞ
ij
Jð y; by; WÞ, where
wðlÞ
ij denotes the weight between neuron j of the previous layer l 1
and neuron i of the current layer l.
The last step poses the biggest challenge when it comes neuronal net￾works. The deep structure of an ANN means that the output or activation
of each hidden unit does affect many units in the downstream layers, and
therefore contributes to the total cost through many separate paths. In order
to combine all these effects, an efficient and systematic method for the
computation of the partial derivatives is required. The development of the
backward propagation (or short, backprop) algorithm as an efficient method to
calculate these loss derivatives was one of the major reasons for the increasing
interest in ANNs in the 1980s [7]. Backward propagation calculates the loss
derivatives for all hidden units with respect to their activation a, from where
it is easy to get the loss derivatives of the weights going into the hidden unit.
In the forward pass, calculations follow the following schematic
sequence:
x/zð1Þ
/a
ð1Þ ¼ s

zð1Þ

/zð2Þ
/a
ð2Þ
/./y ¼ a
ðLÞ
/Jðy; wÞ
In backpropagation, this order is reversed, and the changes of the error
function with respect to the unit output y of the last layer is calculated first,
then with respect to the unit input of the last layer, from where the changes
Modern Spacecraft GNC 839of the error function with respect to the weights are obtained. From there,
the process is repeated sequentially for the previous layers (where the unit
outputs are the activations), until reaching the first hidden layer:
vJ
vy
¼ vJ
vaðLÞ
/
vJ
vzðLÞ
Y
vJ
vwðLÞ
ij
/ vJ
va
ðL1Þ /
vJ
vzðL1Þ
Y
vJ
vwðL1Þ
ij
/./ vJ
vað1Þ
/
vJ
vzðLÞ
Y
vJ
vwð1Þ
ij
In this way, backpropagation traces the separate contributions to the er￾ror starting at the back, i.e., at the output layer, passing through the network
layer by layer.
Backpropagation is based on the repeated application of the chain rule of
calculus, which states that for a real number x and two functions g and f
which map from a real number to a real number and are linked by y ¼
gðxÞ and z ¼ f ðgðxÞÞ ¼ f ðyÞ, the derivative of z with respect to x can be
obtained by dz
dx ¼ dz
dy
dy
dx. As a consequence, backpropagation requires both
the loss function and the activation function to be differentiable.
The following example illustrates the calculations for any two units cho￾sen from subsequent layers: the output layer l and a hidden layer l 1, indi￾cated by the superscripts. The subscripts j and i run over all units of layer l
and l  1, respectively.
The calculations involved are:
1. Apply the chain rule to calculate the derivative of the loss with respect to
the total input received by unit j,
vJ
vz
ðlÞ
j
¼ daðlÞ
j
dzðlÞ
j
vJ
va
ðlÞ
j
¼ a
ðlÞ
j
	
1  a
ðlÞ
j

 vJ
va
ðlÞ
j
where we assumed that the derivative of the logistic unit a ¼ sðzÞ is da
dz ¼
að1aÞ. vJ
va
ðlÞ
j
is the derivative of the loss with reference to the activation of
unit j in layer l.
840 Stefano Silvestrini et al.2. To get vJ
vwðlÞ
ij
, we observe that z
ðlÞ
j is a linear function of the weights wðlÞ
ij
and the outputs of the previous layer, a
ðl1Þ
i . Again, we apply the chain
rule:
vJ
vwðlÞ
ij
¼ vz
ðlÞ
j
vwðlÞ
ij
vJ
vz
ðlÞ
j
¼ a
ðl1Þ
i
vJ
vz
ðlÞ
j
where vJ
vz
ðlÞ
j
has already been calculated in step 1.
This can be repeated for all hidden layers. In order to backpropagate
from layer l to l  1, we substitute l by l  1 in step 1 and observe that
we can determine the change of the error depending on the changes in
the output of unit i in layer l  1 by summing over all outgoing connections
of unit i:
vJ
va
ðl1Þ
i
¼
X
j
dzðlÞ
j
daðl1Þ
i
vJ
vz
ðlÞ
j
¼ X
i
wðlÞ
ij
vJ
vz
ðlÞ
j
Here,
dzðlÞ
j
daðl1Þ
i
characterizes the change of the total input to unit j with the
changes in the output of unit i, which is simply the weight connecting unit i
and j. The second term, vJ
vz
ðlÞ
j
, is known from step 1. The weight update for
GD is then given by:
DwðlÞ
ij ¼  h $ vJ
vwðlÞ
ij
¼ h $a
ðl1Þ
i
vJ
vz
ðlÞ
j
where h is the learning rate, a user-defined coefficient, as already noted.
Vanishing or exploding gradients pose a problem when training a DNN
with gradient-based learning methods and backpropagation [8,9]. Since
weights are updated proportionally to the partial derivative of the error
function with respect to the current weight, the learning process can
come to a rest if the gradient becomes very small (vanishing gradient) or
become unstable for very large gradients (exploding gradient). In each layer,
the weight updates are obtained from the gradients calculated from all later
layers using the chain rule, effectively involving the multiplication of the
gradients of those later layers. Thus, if gradients are smaller than 1, the result￾ing weight update gets smaller with each layer, leading to an exponential
Modern Spacecraft GNC 841decay of the weight updates and preventing any learning progress in the
earlier layers. The opposite effect of an exponential increase of the weight
update can occur for gradients greater than 1.
Various solutions such as gradient clipping (i.e., restricting maximum
gradient values to a fixed threshold), weight regularization, and alternative
or modified activation functions have been proposed and are used to prevent
vanishing and exploding gradients [9]. In residual networks, skip connec￾tions pass gradient information from a deeper layer directly to a nonadjacent
previous layer, thus helping maintain signal propagation even in deeper net￾works [10]. For RNNs, which are especially affected by the problem as we
will see later in the chapter, special architectures like the long short-term
memory (LSTM) have been developed to prevent vanishing gradients [11].
GD is used to train neural networks in an iterative manner, with weight
updates performed through repeated forward-backpropagation passes of the
available training samples. Depending on the specific application, computa￾tional capacity, and data availability, different training strategies are typically
applied which differ in the number of samples in each update step.
In batch learning or batch GD, the weight update is only executed after all
the input-target data have been presented to the network. One complete
presentation of the training dataset is typically called an epoch. The forward
and backward pass is performed one after each epoch. In batch learning, the
system is not capable of continuous learning while doing. The training data￾set consists of all the available data. This generally takes a lot of time and
computational effort, given the typical dataset sizes. For this reason, batch
learning is generally performed on-ground. The system that is trained
with batch learning first learns offline and then is deployed and runs without
updating itself: it just applies what it has learnt.
Mini-batch learning is a variation of full batch learning, where the update is
performed on subsets of the complete dataset, and thus each epoch consists
of a number of forward-backpropagation passes. Mini-batch GD is widely
used when the number of samples in the training dataset is very big and it
becomes infeasible to perform the computations needed for the parameter
update, which involve the calculation and storage of the cost function and
its gradients, on the whole set at once. Stochastic gradient descent (SGD) is a
special case of mini-batch learning with a batch size of one sample.
In incremental learning, often referred to as online learning, the system is
trained continuously as new data instances become available. They could
be clustered in mini-batches or come as standalone datum using SGD. On￾line learning systems are tuned to set how fast they should adapt to incoming
842 Stefano Silvestrini et al.data: typically, such parameter is again referred to as learning rate. A high
learning rate means that the system reacts immediately to new data, by
adapting itself quickly. However, a high learning rate means that the system
will also tend to forget and replace the old data. On the other hand, a low
learning rate makes the system stiffer, meaning that it will learn more slowly.
Also, the system will be less sensitive to noise present in the new data or to
mini-batches containing nonrepresentative data points, such as outliers. In
addition, Lyapunov-based methods are very suitable for incremental
learning due to their inherent stepwise trajectory evaluation of the stability
of the learning rule.
Types of artificial neural networks
While the MLP represents the most basic type of neural network, based on
one-dimensional (1D) input vectors and feedforward operations, other
network architectures exist for specific applications. For instance, another
popular feedforward network is the radial basis function neural networks
(RBFNNs).
Two of the most important and widely used type of ANNs are CNNs
for 2D input data, i.e., images, and RNNs, which are used for data repre￾senting sequences like time series or text sentences. CNN and RNN will
be introduced in the following.
Radial basis function neural network
An RBFNN is a single-layer shallow network, whose neurons are Gaussian
functions. Such network architecture possesses a quick learning process,
which makes it suitable for online dynamics identification and reconstruc￾tion. The highlights of the mathematical expression of the RBFNN are re￾ported here for clarity.
For a generic state input x˛Rn; the components of the output vector
g˛Rj of the network is:
glðxÞ ¼ Xm
i¼1
wijFiðxÞ
In a compact form, the output of the network can be expressed as:
gðxÞ ¼WTFðxÞ
where W ¼ ½wil for i ¼ 1;.;m and l ¼ 1; :::; j is the trained weight matrix
and FðxÞ ¼ ½F1ðxÞF2ðxÞ.FmðxÞT is the vector containing the output of
Modern Spacecraft GNC 843the radial basis functions (RBFs), evaluated at the current system state.
RBFNN is used in classification, function approximation, time series pre￾diction problems, etc. The RBF network learns to designate the input to a
center, and the output layer combines the outputs of the RBF and weight
parameters to perform classification or inference. RBFs are suitable for
classification, function approximation, and time series prediction problems.
Typically, the RBF network has a simpler structure and a much faster
training process with respect to MLP, due to the inherent capability of
approximating nonlinear functions using shallow architecture. As one could
note, the main difference of the RBFNN with respect to the MLP is that the
kernel neuron is a nonlinear function of the information flow, instead of
linear: in other words, the actual input to the layer is the nonlinear radial
function FðxÞ evaluated at the input data x, most commonly Gaussian ones.
The most used radial-basis function that can be used and that are found in
space applications are [12e14]:
• Gaussian FðrÞ ¼ e
ðrcÞ2
2s2 .
• FðrÞ ¼ 1
ðs2þr2Þ
a.
• Linear FðrÞ ¼ r.
• Thin-plate spline FðrÞ ¼ r
2lnðrÞ.
• Logistic function FðrÞ ¼ 1
1þe
ðr=s2Þq
.
where r is the distance from the origin, c is the center of the RBF, s is a
control parameter to tune the smoothness of the basis function, and q is a
generic bias. The number of neurons is application-dependent, and it shall
be selected by trading-off the training time and approximation, especially for
incremental learning applications. The same consideration holds for the
parameters h ¼ 1
s; which impacts the shape of the Gaussian functions. A high
value for h sharpens the Gaussian bell shape, whereas a low value spreads it
on the real space. On one hand, a narrow Gaussian function increases the
responsiveness of the RBF network, on the other hand, in case of limited
overlapping of the neuronal functions due to too narrow Gaussian bells, the
output of the network vanishes. Hence, ideally, the parameter h is selected
based on the order of magnitude of the exponential argument in the
Gaussian function. The output of the neural network hidden layer, namely
the radial functions evaluation, is normalized:
FnormðxÞ ¼ FðxÞ
Pm
i¼1FiðxÞ
844 Stefano Silvestrini et al.The classic RBF network presents an inherent localized characteristic;
whereas, the normalized RBF network exhibits good generalization prop￾erties, which decreases the curse of dimensionality that occurs with classic
RBFNN.
Convolutional neural networks
CV is one of the areas which has benefited most from the recent advances in
DL. Most of state-of-the-art techniques for CV tasks like image recognition
or classification and object detection are based on DL approaches and form
the basis for applications for autonomous navigation and self-driving cars or
internet image searches. Typical CV problems are:
• Image classification. It determines if the input image contains a certain
object.
• Object detection. It determines the position of one or several objects in the
input image, see Fig. 15.13.
• Image segmentation. It partitions the input image into different regions,
e.g., foreground and background regions, see Fig. 15.14A and B (cfr.
Chapter 9 e Navigation).
Figure 15.13 Object detection example. A bounding box indicates the position of the
detected body satellite.
Modern Spacecraft GNC 845One of the challenges of CV problems is the size of the input features and
the number of parameters involved, which can make the application of a
fully connected neural network, like the MLP to an image classification
task, infeasible. For example, a three channel RGB image of size
Figure 15.14 Image segmentation example. Colors indicate different entities of the
image. Red: spacecraft; blue: deep space; green: Earth. Refer to Ref. [15] for a compre￾hensive dataset for training deep learning models.
846 Stefano Silvestrini et al.1000  1000 can be flattened into a 1D input vector with three million
(1000  1000  3) elements. Feeding this input feature into a neural
network with 1000 hidden units in the first layer will result in a weight ma￾trix with three billion parameters. A neural network of this size will not only
be prone to overfitting, but it will also impose unrealistic computational and
memory requirements.
In CNNs, this problem is solved using convolution operations, which
are the fundamental building blocks of CNNs. In the following, we will first
define the convolution operation, give an example of how convolution fil￾ters can extract image features, and finally show how they are used in a
CNN.
In the context of CNNs, the convolution for a given 2D input image I
and a 2D filter (also called kernel) K is given by2
:
Cði; jÞ¼ðI *KÞði; jÞ ¼ X
m
X
n
Iði  m; j  nÞKðm; nÞ
where * is the convolution operator, and m and n run over all values that
lead to legal subscripts of Iðim; j nÞ and Kðm; nÞ. Indices i and j refer to
the pixel position in the input image, while indices m and n refer to the filter.
The result is again a 2D output image, in the context of CNNs commonly
called feature map, whose height and width depend on the size of the input
image and the filter, as well as additional hyperparameters to be discussed
below. The operation is illustrated in Fig. 15.15 for a 6  6 input image and
a 3  3 filter: the filter is applied to the input image as a sliding window,
starting at the top left corner of the input image. Overlapping filter and input
Figure 15.15 Convolution for vertical edge detection.
2
P
Note that in the field of Machine Learning, often the related cross-correlation function Cði; jÞ ¼
m
P
n
Iði þm; j þnÞKðm; nÞ is implemented and called convolution. For a detailed explanation see Ref.
[17].
Modern Spacecraft GNC 847indices are multiplied element-wise, and the sum of the resulting nine values
is stored at indices (1,1) of the output image. The next element, (2,1), is
obtained by repeating the calculation after sliding the filter one pixel
downwards, and analogously for all elements of the output image.
Fig. 15.15 illustrates how convolution filters are able to extract visual fea￾tures like vertical edges. The vertical edge in the input image, defined by the
simultaneous drop from pixel intensity 9 to 0, results in high values/high in￾tensities in the corresponding columns of the resulting feature map.
While the filter in our example was designed manually, one of the
strengths of DNNs is the ability to learn the filter parameters automatically,
and to extract more and more abstract representations of the input data with
every hidden layer. In the context of CV tasks, these levels of abstraction
correspond to the detection of simple visual features like edges corners or
blobs in the first layer, to parts of objects in the next, to complete objects
the deeper we get into the neural network [16], as illustrated in Fig. 15.16.
Figure 15.16 High- and low-level features. Adapted from H. Lee, R. Grosse, R. Ranganath,
A.Y. Ng, Unsupervised learning of hierarchical representations with convolutional deep
belief networks, Communications of the ACM, 54 (10) (2011), 95e103. https://doi.org/10.
1145/2001269.2001295; M.Z. Asghar, M. Abbas, K. Zeeshan, P. Kotilainen, T.
Ham€ al € ainen, Assessment of deep learning methodology for self-organizing 5G networks, €
Applied Sciences 9 (15) (2019) 2975. https://doi.org/10.3390/app9152975.
848 Stefano Silvestrini et al.The output dimension of a f  f convolution filter applied to a n n
input image is given by k ¼ ðn f þ1Þ ðn f þ1Þ (starting at the upper
right corner of the image, the filter can be shifted ðn f þ1Þ-times in each
dimension before reaching the right/bottom edge of the image). This means
that the output of the operation is smaller than the original input, which can
become problematic when convolutions are applied sequentially like in a
multilayered neural network. In addition, pixels close to the corner and
edges of the input image enter less calculations than those at the center.
These issues can be avoided by padding the input image, i.e., by adding a
fixed number p of rows/columns to each side of the input image before per￾forming the convolution. These added rows and columns can contain a
fixed constant value (constant padding, with the special case of zero padding),
but they can also replicate or mirror the image values at the edges (replication
and mirror padding). In order to determine the number of rows and columns
to be added, a common padding scheme, called same convolution, uses p ¼ f 1
2
to produce an output image of the same size as the input. Commonly,
convolution without padding (p ¼ 0) is called valid convolution. Since the fil￾ter size f is generally chosen to be an odd number, p takes on integer values.
A second parameter which controls image convolution is the stride s,
which defines the number of pixels by which the filter is shifted after
each convolution operation. For example, with s ¼ 2, the filter will
move from column (or row) 1 to 3, omitting column (row) 2. Thus, the
stride roughly decreases the output size by a factor 1
s in each dimension.
The exact formula for the output dimension including padding p and stride
s is given by:
k ¼

n þ 2p  f
s
þ 1



n þ 2p  f
s
þ 1

Here, the floor operator z is used to account for cases in which the frac￾tion is not an integer value. Both the stride and the padding parameters are
hyperparameters of a CNN and thus are chosen when deciding the specific
neural network architecture.
The convolution operation is not limited to gray-scale images but can
easily be generalized to images with multiple channels like RGB images.
An input image of height h and width w is then defined by a three￾dimensional matrix of size h  w  c, where c defines the number of chan￾nels, e.g., c ¼ 3 for a three-channel RGB image. The convolution filter also
becomes three-dimensional with size f  f  c, where the number of
Modern Spacecraft GNC 849channels c is the same for the input image and the filter. As illustrated in
Fig. 15.17, convolution is then performed by moving the three￾dimensional filter over the width and height of the input image, just as
for the 2D case, multiplying the overlapping image and filter indices, which
now include indices corresponding to all channels, and finally summing up
all the f $f $c obtained values. Like for the case of 2D input image and filter,
the result is a 2D feature map.
In a CNN, convolution filters represent the equivalent of the weight
matrices of a fully connected neural network, containing the parameters
learned during training. In general, each layer of a CNN is made up of mul￾tiple such filters each of which can extract different image features and
generate a corresponding feature map, also called activation map. The final
output of each filter is obtained by the addition of a bias parameter and
element-wise application of the nonlinear activation function, with the
ReLU activation being a common choice in CNNs. If the layer contains
F filters, the output of the layer is the F generated feature maps, stacked
together in a f  f  F array (Fig. 15.18). Each layer can thus be character￾ized by:
• The width and height of the convolution filters.
Figure 15.17 Convolution over volumes.
Figure 15.18 The results from multiple filters are stacked.
850 Stefano Silvestrini et al.• The number of input channels and output channels. The number of
channels of a layer must match the number of channels of its input.
• The hyperparameters of the convolution operation: padding and stride.
In addition to convolution layers, a CNN may also include other types of
neural network layers, the most common being pooling layers and fully con￾nected layers.
Pooling layers are often introduced after a convolutional layer in order to
reduce the number of parameters by downsampling the output of the pre￾vious convolution layer before passing it to the next. It can also have the ef￾fect of making the detected features more robust. The most common form
of pooling in CNNs is max pooling: the max pooling filter of size F is moved
over the input image or feature map with a step width defined by the stride s,
and for each F  F filter location, only the maximum value of the input is
retained in the output map (Fig. 15.19). The stride s is commonly set equal
to the filter size, s ¼ F. However, overlapping pooling where s < F is also
possible. Average pooling instead calculates the average value for the respective
patches of the feature map.
In contrast to the convolution filters, padding is usually not applied for
the pooling operation. Pooling is done independently for each input chan￾nel, meaning that the number of channels of the pooling output is the same
as for the input. Since pooling is done using fixed operations (max or mean),
pooling layers do not add additional trainable parameters to the network.
Fully connected layers can be included in a CNN if the task objective re￾quires it, for example, when the final output is a single numeric value or a
1D vector, as is the case in image classification. If present, they are therefore
usually added as the last layers of the network. The 1D input vector for a
fully connected layer which immediately follows a CNN or pooling layer
is typically created by flattening the 2D feature map.
Parameter sharing and sparsity of connections. As mentioned at the beginning
of the section, one of the advantages of CNNs when compared to fully
Figure 15.19 Max pooling.
Modern Spacecraft GNC 851connected networks is the reduction in the total number of parameters
involved. The output of a convolutional network layer with three 5
5-dimensional filters which takes a 64  64  3-dimensional input image
will have dimensions ð64 5 þ1Þð64 5 þ1Þ  3 ¼ 60  60  3.
While in this situation, a fully connected layer taking in the 64 64
3 ¼ 12288 input features and having an equivalent number of 60  60
3 ¼ 3600 units will result in a weight matrix containing
3600  12288 ¼ 44236800 parameters, the convolutional layer will
contain only ð5 5 þ1Þ  3 ¼ 78 parameters, independent of the size of
the input image. This reduction in the number of parameters can be attrib￾uted to two characteristics of CNNs: parameter sharing and sparsity of connec￾tions. Parameter sharing greatly reduces the number of parameters by
using the same filter in all the regions of the image (using the same filter
while sliding over the image), instead of learning a different set of parameters
for every location. Sparsity of connections means that in a convolutional
layer, each input feature is generally only used in a number of f  f
calculations. In contrast, in a dense, fully connected layer, the input to
each hidden unit is calculated from all the input features. Differently to fully
connected neural networks, where the size of the weight matrices depends
on both the number of input features and the number of units in the layer, in
a CNN, the number of parameters in the filters does not depend on the
input dimension.
In the following, we will give a short overview of how the presented
operations are used to construct neural networks for the CV tasks of image
classification, image segmentation, and object detection.
Image classification networks
One of the classic and most influential DNN architectures to combine the
basic elements of CNNs such as convolutions, max pooling, and fully con￾nected layer is AlexNet [19]. In 2012, AlexNet achieved ground-breaking
performances for image classification in the ImageNet LSVRC-2012 chal￾lenge, boosting the use of DL techniques for CV and serving as a starting
point for many modern developments.
The architecture of this classification network is shown in Fig. 15.20, de￾tailing the filter parameters and resulting sizes of the feature maps. AlexNet
consists of five convolutional layers for feature extraction and three fully
connected layers responsible for the classification. The first two convolu￾tional layers are followed by overlapping max pooling, reducing the height
and width of the resulting feature maps. While no pooling is performed
852 Stefano Silvestrini et al.Figure 15.20 AlexNet architecture.
Modern Spacecraft GNC 853between the third, fourth, and fifth convolutional layers, the fifth convolu￾tional layer is followed by a max pooling layer, the output of which goes
into a series of two fully connected layers. The output layer, containing
1000 units corresponding to the 1000 class labels in the ILSVRC-2012 data￾set [20], uses the softmax function to calculate the class probabilities. ReLU
nonlinearity is applied after all the convolution and fully connected layers.
Image segmentation networks
Image segmentation can be thought of as a pixel-wise classification task. In
semantic segmentation, each image pixel is assigned a corresponding class, thus
labeling, for example, if a pixel belongs to a certain object in the image, the
background or the foreground. Instance segmentation goes one step further by
determining not only the pixel class but also different instances or objects of
the same class in the image. For example, where the task of semantic seg￾mentation is to determine if a certain pixel belongs to any satellite, instance
segmentation in addition distinguishes to which of multiple satellites present
in the image the pixel belongs. Since image segmentation makes predictions
for each pixel of the input image, the output is a segmentation map with a one￾to-one correspondence between pixels in the input image and in the seg￾mentation map.
A popular approach for semantic image segmentation are fully convolu￾tional models, meaning that they only contain convolutional layers and
additional up-/downsampling layers (e.g., pooling layers), and which are
often based on an encoder/decoder structure [21]: the encoder network
downsamples the spatial resolution of the input and creates lower￾resolution feature mappings which facilitate the classification task; the
decoder network then upsamples the feature representations into a full￾resolution segmentation map. Additional shortcuts, called skip connections,
transfer information from layers of the encoder network to later layers of
the decoder network, skipping some of the downsampling and upsampling
steps in order to recover location detail which is lost during the sampling
steps.
Fig. 15.21 illustrates the approach for a very popular segmentation
network architecture, the U-Net [22]. The name originates from the sym￾metrical u-shaped structure of the network, where the left, descending path
represents the encoder subnetwork while the right ascending path corre￾sponds to the decoder network. The encoder follows the typical architecture
854 Stefano Silvestrini et al.of a convolutional network, repeatedly applying combined convolution￾pooling blocks consisting of two 3  3 convolutions, followed by a
ReLU activation function and a 2  2 max pooling filter, yielding feature
maps of less and less resolution but a higher number of channels. Conversely,
every step in the decoder path consists of an upsampling convolution of the
feature map, application of the skip connection by concatenation of the
upsampled feature map with the corresponding feature map from the down￾sampling path, a 2  2 convolution which halves the number of feature
channels, and two 3  3 convolutions, each followed by a ReLU activation.
The final layer uses a 1  1 convolution to reduce the 64-dimensional
feature vector corresponding to each pixel to the desired number of classes.
Note that due to the use of valid convolutions, the segmentation map is
smaller than the input image and only contains the pixels for which the
full context is available in the input image.
Figure 15.21 The original U-net architecture for image segmentation from Ref. [22]
(example for 32  32 pixels in the lowest resolution). Each blue box corresponds to a
multichannel feature map. The number of channels is denoted on top of the box.
The x-y-size is provided at the lower left edge of the box. White boxes represent copied
feature maps. The arrows denote the different operations. Adapted from Y. Cai, L. Qian,
Y. Fan, L. Zhang, H. Huang, X. Ding, An automatic trough line identification method based
on improved UNet, Atmospheric Research, 264 (2021), 105839, ISSN 0169-8095. https://doi.
org/10.1016/j.atmosres.2021.105839.
Modern Spacecraft GNC 855Object detection network
In object detection, the task is to determine the location and type of objects
in a given image. For that purpose, object detectors return a bounding box
for each detected object, alongside with the object category and the classi￾fication confidence. Common object detection models perform this task in
three steps: region selection, feature extraction, and classification. While in
principle this can be achieved by scanning the image using multiscale sliding
windows and performing image classification on the corresponding image
regions, this approach is computationally very expensive especially when
based on DNN techniques, and more efficient methods are used which
can be divided into two generic DL object detection frameworks [24]:
• The region proposal-based framework replicates the traditional pipeline by
using two-stage detectors: in the first step, deep image features are
extracted from the whole image and used to find approximate image
regions. The second step then performs classification and bounding box
regression on the proposed regions. Implementations of this approach
include R-CNN [25], faster R-CNN [26], and mask R-CNN [27]. The
R in the acronym stands for regional to highlight the segmentation
approach this architecture uses to generate the output.
• The regression/classification-based framework, which includes one-stage de￾tectors such as YOLO (“You Only Look Once”) [28], SSD (Single Shot
MultiBox Detector) [29], and RetinaNet [30] that predict object
bounding boxes without the region proposal step.
While region proposal-based techniques typically perform better than
the regression/classification-based methods, the latter are computationally
more efficient. In the following, the YOLO one-stage detector will be
used as an example to illustrate the functioning of DL-based object detection
(Fig. 15.22).
The idea behind YOLO is to simultaneously predict multiple bounding
boxes and their respective class probabilities using a single CNN. First,
YOLO divides the input image into an S  S grid. For each grid cell, it
then predicts a number of B bounding boxes, each of which is defined by
five values: the x and y coordinates which represent the center of the box
relative to the grid cell, the width w and height h of the box, and the con￾fidence score. In addition, C class probabilities are predicted for each grid
cell. The output is encoded in an S  S  ðB * 5 þCÞ-dimensional
tensor.
In the YOLO network, shown in Fig. 15.23 for parameters S ¼ 7, B ¼ 2,
and C ¼ 20; feature extraction is performed by 24 convolutional layers
856 Stefano Silvestrini et al.Figure 15.22 YOLO divides the image into a grid, and then for each grid cell predicts a predefined number of bounding boxes, as well as a
confidence score for each of those boxes, and the class probabilities [28]. Adapted from Y. Yin, H. Li, W. Fu. Faster-YOLO: an accurate and faster
object detection method, Digital Signal Processing, 102 (2020), 102756. https://doi.org/10.1016/j.dsp.2020.102756.
Modern Spacecraft GNC 857Figure 15.23 Architecture of the original YOLO Object detection network [28]. Adapted from H. Maudi Lathifah et al., Fast and accurate fish
classification from underwater video using you only look once, IOP Conference Series: Materials Science and Engineering 982 (2020) 012003.
858 Stefano Silvestrini et al.followed by two fully connected layers. 1  1 convolutional layers are used
to reduce the feature space from preceding layers. Fully connected layers
then use the extracted features to predict the output probabilities and
bounding box coordinates. The final result of the network is the 7 
7  30 output tensor.
Recurrent neural networks
We have seen how feedforward, fully connected neural networks can be
used to solve classification and regression tasks involving fixed-size input
vectors, and how CNNs tackle complex image-related tasks. Both ap￾proaches, however, are insufficient to tackle problems involving timeseries
and sequence data, which require the ability to model temporal dynamics
and long-term interactions. Sequence data are ubiquitous and come in a
great variety of forms, from audio and video data, to written sentences
and DNA sequences.
In ML, tasks involving sequences are commonly categorized by the
length of the input and output sequences (Fig. 15.24):
• Many-to-one. It maps a sequence of inputs to a single output. This scheme
can be used, for example, for the classification of sequences such as senti￾ment classification, which determines if an input sentence is a positive or
negative expression.
• One-to-many. It generates an output sequence given a single input. A
possible application is the automatic generation of image captions, where
a single image is mapped to an output sentence.
• Many-to-many. An input sequence is mapped to an output sequence of
the same size. For example, in video classification or video activity recog￾nition, each frame of the image sequence is mapped to a corresponding
label.
Figure 15.24 Sequence tasks.
Modern Spacecraft GNC 859• Many-to-many, using an encoderedecoder structure for sequence-to-sequence
learning. This scheme is used for machine translation where an input sen￾tence in the original language is first encoded and then decoded into the
destination language. The original and translated sentence do not have to
be of the same length.
• One-to-one. If both the input and output sequences have length one, in￾puts can be considered independently without any interactions. This
scheme includes, for example, MLP-based classification.
In order to process sequence data efficiently, at each timestep, informa￾tion from past (and possibly future) timesteps has to be available. RNNs
tackle this problem by passing the activation from one timestep to the
next. Let us consider a task where given an input sequence consisting of
input vectors x1; x2; .; xt, we want to predict the output sequence
y1; y2;.; yt
. In an RNN, at time step t, the input vector xt is passed to a
hidden network layer and the activations of the layer’s units and the pre￾dicted output value yt are calculated. In contrast to a feedforward network,
however, the network layer also receives the hidden state vector ht1 con￾taining the activations of the previous timestep as an additional input. The
updated hidden state ht and the output yt are obtained as:
ht ¼ shðWxxt þ Uhht1 þ bhÞ
yt ¼ sy

Wyht þ by

where Wy;Wh; Uh are parameter matrices, bh; by bias parameter vectors,
and sh and sy activation functions. The hidden state is initialized as h0 ¼ 0.
RNNs are often shown in the form of a compressed diagram in
Fig. 15.25 left, where the feedback of the hidden state vector is depicted
as a recurrent connection. The involved forward computations can also be
Figure 15.25 Diagram for a one-unit recurrent neural network. Compressed diagram
on the left and the unfold version of it on the right.
860 Stefano Silvestrini et al.represented for each timestep separately, or unfolded in time, making explicit
the input, hidden state, and output at each step (Fig. 15.25, right). Through
the recurrent link, the output at each timestep effectively depends on all the
previous inputs xt0 (with t
0  t). Since the same parameters (matrices
Wy; Wh; Uh and biases bh; by) are used at each time step, RNNs can be
viewed as very deep feedforward networks where each timestep corresponds
to one layer and all the layers share the same weights.
Backpropagation through time [33e35] is used to compute the derivatives
of the total error with respect to all the states h and all the parameters in the
unfolded RNN analogously to a feedforward network, and GD is used for
optimization.
Although they have been very successfully used to model complex dy￾namic systems, training RNNs has proved to be difficult due to the problem
of vanishing or exploding gradients described earlier. Since the backpropagated
gradients either grow or shrink at each time step, over many time steps, they
can become very large (explode) or tend toward zero (vanish).
Nonlinear autoregressive exogenous model
The nonlinear autoregressive exogenous (NARX) model is a simple recur￾rent structure that uses the feedback coming from the output layer. The
NARX model is based on the linear autoregressive exogenous (ARX)
model, which is commonly used in time-series modeling. The defining
equation for the NARX model is:
yk ¼ N ðyk1; yk2; .; ykn; uk1; uk2; .; uknÞ
where y is the network output and u is the exogenous input, as shown in
Fig. 15.26. Basically, it means that the next value of the dependent output
signal y is regressed on previous values of the output signal and previous
values of an independent (exogenous) input signal. It is important to remark
that, for a one step delay NARX, the defining equation takes the form of an
autonomous dynamical system.
Figure 15.26 Schematic of the nonlinear autoregressive exogenous model.
Modern Spacecraft GNC 861Hopfield neural networks
The formulation of the Hopfield neural network (HNN) is due to Hopfield
[36], but the formulation by Abe [37] is reportedly the most suited for
combinatorial optimization problems, which is of great interest in the space
domain. For this reason, here the most recent architecture is reported. A
schematic of the network architecture is shown in Fig. 15.27.
In synthesis, the dynamics of the i-th out of N neurons is written as:
dpi
dt ¼ X
N
j¼1
wijsj  bi
where pi is the total input of the i-th neuron, wij and bi are parameters
corresponding, respectively, to the synaptic efficiency associated with the
connection from neuron j to neuron i, and the bias of the neuron i. The
term si is basically the equivalent of the activation function:
si ¼ ci tanh pi
b
where b > 0 is a user-defined coefficient, while ci is the user-defined
amplitude of the activation function.
The recurrent structure of the network entails a dynamic of the neurons;
hence, it would be more correct to refer to pðtÞ and sðtÞ, function of time or
any other independent variable.
An important property of the network, which will be further discussed in
the application for parameter identification, is that Lyapunov stability
Figure 15.27 Schematic of the Hopfield neural network.
862 Stefano Silvestrini et al.theorem can be used to guarantee its stability. Indeed, since a Lyapunov
function exists, the only possible long-term behavior of the neurons is to
asymptotically approach a point that belongs to the set of fixed points,
meaning where dV
dt ¼ 0, being V the Lyapunov function of the system,
in the form:
V ¼  1
2
X
N
i¼1
X
N
j¼1
wijsisj þX
N
i¼1
bisi ¼ 1
2
s
TWs þ s
T b
where the right-hand term is expressed in compact form, with s vector of s
neuron states, b the bias vector. A remarkable property of the network, in
fact, is that trajectories always remain within the hypercube   ci; ci½ as long
as the initial values belong to the hypercube too [38]. For implementation
purposes, the discrete version of the HNN is typically employed [39,40].
Long short-term memory
In order to solve the issues of vanishing gradients, more complex RNN var￾iants have been developed. One of the first and widely used architecture is
the LSTM network [11]. An LSTM uses a special hidden unit able to store
inputs over many time steps and acting as long-time memory. This memory
cell is connected to itself at the next timestep, thus copying its own real￾valued state and accumulating the external signal. Another hidden unit,
the forget gate, which learns to decide when to clear the content of the mem￾ory, is used as a multiplicatively gate of this self-connection.
The equations describing the LSTM implement this idea using the acti￾vation vector of the forget gate ft; the activation vector of the input/update
gate it; the activation vector of output gate ot; the cell input activation vector
ect; and the cell state vector ct:
ft ¼ sg

Wf xt þ Uf ht1 þ bf

it ¼ sgðWixt þ Uiht1 þ biÞ
ot ¼ sgðWoxt þ Uoht1 þ boÞ
ect ¼ scðWcxt þ Ucht1 þ bcÞ
ct ¼ ft+ct1 þ it+ect
ht ¼ ot+scðctÞ
Modern Spacecraft GNC 863Here, sg and sc are the sigmoid and hyperbolic tangent activation func￾tion, and the operator + denotes the element-wise product. The initial
values are h0 ¼ 0 and c0 ¼ 0. Each of the gates ft, it and ot learns its
own set of parameters calculated from the input xt and the previous hidden
state ht1. The use of the sigmoid activation function in the calculation of
the gate vectors means that their element values will lie within the range
[0,1] and will often be approximately 0 or 1, thus either blocking the gate
or letting the corresponding input elements pass. The forget and update
gates decide how and which elements of the previous cell state vector
ct1 and the input activation vector or “candidate cell state” ect enter the
updated cell state ct. Finally, the new activation or hidden state ht is calcu￾lated from the updated cell state, filtered by output gate ot. Thanks to the
gating mechanism, which allows the LSTM to let the cell state vector ct
pass unaffected over many timesteps, information can be stored over a
long time. LSTM computations are illustrated in Fig. 15.28.
For learning very complex functions, various RNNs can be stacked
together to form deep RNNs. Each layer in such a network has its own
set of parameters, while all units of the same layer (in the unrolled view
of the network) share the same parameters. The hidden state hðlÞ
t in layer l
at timestep t is then calculated not only from the hidden state at the previous
timestep, hðlÞ
t1, but also from the hidden state from the layer below, hðl1Þ t .
Due to the temporal dimension, training only one RNN layer can already
be computationally expensive. For this reason, deep RNNs remain rather
shallow in practice when compared to feedforward neural networks, which
very often have a great number of layers.
Figure 15.28 Schematic illustration of the LSTM unit.
864 Stefano Silvestrini et al.Applications scenarios and AI challenges
The section presented a wide range of theoretical background that is essen￾tial for a space engineer who would like to dive into the AI domain. As
remarked throughout the discussion, the described methods are valid across
different domains; hence, it is quite hard to delineate a clear correspondence
between methods and specific space-related applications.
Most of the embedded systems have been designed based on linear
algebra and linearization. This is true also for the space technology.
Although the linear design has served our purposes very well in the past,
it imposes constraints and limitations on the potential of current technology
for more demanding space missions.
Nature and generally universe has a nonlinear behavior. Putting linear
systems into a nonlinear environment requires a lot of effort and resources
from the engineers to tune it. As we have seen, a lot of concepts upon sta￾bility, observability, etc., requires the knowledge of linearized system and,
above all, they guarantee the properties of the real system only within the
validity of the linearization.
Nonlinear systems increase the capabilities of the technology, and new
attributes emerge from its implementation. Of course, attention is required
to enhance the capabilities that serve the objectives of the mission without
inserting useless complications. Autonomous spacecraft GNC systems can
truly benefit from this approach. Certainly, among those, navigation and
control can be enhanced from online deployment of AI-based systems.
Indeed, the demand of highly accurate navigation and control in a nonlinear
and unpredictable harsh environment including time constraints compels
the designers to consider alternative methodologies and concepts. One of
these ideas is to use adaptive systems with nonlinear elements. AI can be
thought as a particular kind of nonlinear adaptive system. The way it can
be adopted is strongly dependent on the technology level and the current
knowledge. For instance, AI techniques could allow the spacecraft to
achieve highly accurate relative navigation when arriving to an unknown
target. The most interesting application in that field are proximity operations
around an asteroid or uncooperative target, relative pose estimation around
an uncontrolled satellite, pinpoint landing on the asteroid or the Moon.
To perform online ML from a controls perspective toward a model￾based ML setting, one needs to be able to construct models from data via
system identification. The GNC system relies on mathematical model of
the environment to calculate the estimated states and planned control.
Modern Spacecraft GNC 865The accuracy and adaptivity of the algorithms are pursued by implementing
online learning based on AI techniques. This allows the agent to learn the
surrounding environment as it flies, refining its mathematical representation
on-board. The refinement increases the accuracy of the model, on which
GNC is synthesized on-board, but also it captures variation of the environ￾ment, enhancing the adaptivity of the algorithm. The system identification
modeling accuracy when used in a closed-loop setting needs the under￾standing of the trade-off between the number of samples needed to build
reliable models and the performance degradation due to coarse modeling.
However, there are some unresolved challenges to apply AI algorithms
on GNC systems, for instance, inadequate data sets for training, the theoret￾ical understanding and modeling of the behavior of the AI system, the
generalization of the learned features to different scenarios, and its validation.
If the verification of such system is covered by existing European Cooper￾ation for Space Standardization (ECSS) standards (as in Refs. [41e44]), their
validation is much more complex. It is then important that the selection of
an AI technique shall consider the objective of the qualification of the com￾plete system, especially in the context of critical application.
Another challenge is related to the need of AI techniques in terms of
processing and memory. If the processing and memory resources available
on-board are constantly increasing, the AI techniques may still need some
optimization to be executed on-board spacecraft.
Finally, we can frame two additional limitations of the current status of
AI and ML for space applications:
• The trade-off between adaptivity and robustness in the design of the
GNC system. On one hand, we are trying to design ML systems that
evolve continuously by learning via the interaction with the dynamical
and physical environment. On the other hand, they should pursue
optimized solutions that are robust, explainable, and secure.
• The AI and ML algorithms borrowed from data science often lack in ef￾ficiency, robustness, and interpretation coming from a purely data-drive
approach. The foundation of classical GNC theory instead lies in the
mapping of physics into the model-based design concept.
In this section, we try to summarize guidelines and schematized typical
approaches found in literature. In Table 15.1, a summary of ANN types is
presented, highlighting the most relevant field of application. Obviously,
the table is not exhaustive and reports the common trend in the adoption
of particular network types.
866 Stefano Silvestrini et al.Artificial intelligence and navigation
Introduction to pose estimation
Chapter 9 e Navigation introduced the framework for vision-based
relative navigation around both cooperative and uncooperative targets,
highlighting the challenges involved in on-orbit servicing and active debris
Table 15.1 Summary of most common ANN architecture used in space dynamics,
guidance, navigation, and control domain. The training type is supervised (S),
unsupervised (U), and reinforcement learning (R).
Network
type Architecture
Learning
paradigm Training algorithm Space application
Feedforward MLP S/R Backpropagation Dynamics
approximation,
value-function
approximation
RBFNN S/U/R Backpropagation
Lyapunov
K-means
clustering
Dynamics
approximation,
regression, time-series
prediction
AE U Backpropagation Dimensionality
reduction, state-space
modeling, data
encoding, anomaly
detection
CNN S Backpropagation Feature detection,
object detection,
image classification,
image-based
regression, vision￾based navigation
Recurrent NARX S/R Backpropagation
through time
Dynamics
approximation,
time-series prediction
HNN S Backpropagation
through time
Combinatorial
optimization, system
identification
LSTM S/R Backpropagation
through time
Time-series prediction,
dynamics
approximation,
generic function
approximation
through time
Modern Spacecraft GNC 867removal missions [45,46]. Specifically, it was highlighted that if the target
satellite is not functional and/or not able to aid the relative navigation
(i.e., uncooperative), the estimation of the relative pose by the active servicer
spacecraft can represent a critical task. In this context, pose estimation sys￾tems based solely on a monocular camera are recently becoming an attractive
alternative to systems based on active sensors or stereo cameras, due to their
reduced mass, power consumption, and system complexity [47]. However,
given the low signal-to-noise ratio (SNR) and the high contrast which char￾acterize space images, a significant effort is still required to comply with most
of the demanding requirements for a robust and accurate monocular-based
navigation system [48]. Notably, the navigation system cannot rely on
known visual markers, as they are typically not installed on an uncooperative
target. As already detailed in Chapter 9 e Navigation, the extraction of vi￾sual features is an essential step in the pose estimation process, and advanced
image processing (IP) techniques are required to extract keypoints (or inter￾est points), corners, and/or edges on the target body. In model-based
methods, the detected features are then matched with predefined features
on an offline wireframe 3D model of the target to solve for the relative
pose. In other words, a reliable detection of key features under adverse
orbital conditions is highly desirable to guarantee safe operations around
an uncooperative spacecraft.
Despite recent advancements in the field, standard IP techniques gener￾ally lack feature detection robustness when applied to space images. From a
pose initialization standpoint, the extraction of target features can, in fact, be
jeopardized by external factors, such as adverse illumination conditions, low
SNR, and the Earth in the background (Fig. 15.29), as well as by target￾specific factors, such as the presence of complex textures and features on
the target body. At the same time, feature tracking could be complicated
by variations of the illumination conditions due to varying Sun-camera ge￾ometries, especially when combined with unexpected reflections from
different parts of the target body. Moreover, most of IP methods are based
on the image gradient, detecting textured-rich features or highly visible parts
of the target silhouette. As such, the detected features are image-specific and
can vary in number and typology depending on the image histogram. In
other words, most of these techniques cannot accommodate an offline
feature selection step, which translates into a computationally expensive
image-to-model correspondence process to ensure that each detected 2D
feature is matched with its 3D counterpart on the available wireframe model
of the target object [49].
868 Stefano Silvestrini et al.In this context, AI-based pose estimation architectures are standing out
in recent years as a valid and robust alternative to the techniques so far
described, mostly because of the strict requirements on the robustness of
visual-based relative navigation systems during close-proximity operations
around uncooperative targets. Despite most of these methods were already
implemented and validated for Earth-based systems, their scalability to space,
i.e., their performance in space scenarios, is still under investigation.
AI-based relative pose estimation
Recent advances in CV for pose estimation in terrestrial applications have
relied on the quickly evolving domain of ML to enable unprecedented ef￾ficacy across several applications. Among all the DL techniques described in
Figure 15.29 Example showing poor detections in images with adverse illumination
and background texture using standard IP algorithms. For a correct reference dataset,
please refer to Ref. [50].
Modern Spacecraft GNC 869Chapter 15 e Modern Spacecraft GNC e AI in space e Introduction,
CNNs stand out as the most viable solution for visual-based systems, mostly
due to their capability to process visual data in form of images.
The implementation of CNNs for monocular pose estimation in space
has already become an attractive solution in recent years, also thanks to
the creation of the Spacecraft PosE Estimation Dataset (SPEED) [51], a data￾base of highly representative synthetic images of PRISMA’s TANGO space￾craft made publicly available by Stanford’s Space Rendezvous Laboratory
and applicable to train and test different network architectures.
A high-level schematic of a typical CNN architecture is shown in
Fig. 15.30. The first and core building block is represented by the convolu￾tional layer, formed by a fixed number of weight filters which convolve the
input image to return feature maps. Generally, a convolution layer uses mul￾tiple weight filters on the image. As such, the output is a 3D volume of 2D
feature maps. These feature maps are then downsampled by the pooling
layer in order to progressively reduce the spatial size of the feature maps,
thus reducing the number of parameters and improving the network robust￾ness against overfitting. By cascading convolutional layers with pooling
layers in series, the output of the so-called feature learning step is a list of
feature maps of lower size than the input image. Fully connected layers
(i.e., an MLP neural network) are then generally used to classify the image
given the input feature maps.
The interesting aspect of CNNs is that the internal representations that
express the relationship between two feature maps are automatically gener￾ated. As already mentioned, CNNs are capable of extracting abstract repre￾sentations at unintuitive levels of information in the images to compose
high-level information. Therefore, CNNs have been successful in tackling
some of the challenges faced by IP systems, where a higher interpretability
of the information is required. These include, among others, robustness
against:
• viewpoint variation.
• scale variation, deformation, and occlusion.
• illumination conditions.
• background clutter.
Altogether, these are claimed to be the main advantages of CNNs over
standard IP algorithms for relative pose estimation [47,52,53]. Notably,
CNNs for vision tasks are most often trained offline in a supervised manner,
wherein training images are fed to the network and the appropriate convo￾lutional and activation weights are estimated to reduce the loss. This
870 Stefano Silvestrini et al.Figure 15.30 High-level schematic of a generic CNN architecture.
Modern Spacecraft GNC 871guarantees that there is no need to correlate the offline images with the im￾ages taken in orbit, as it usually occurs in the feature-matching step of stan￾dard keypoints-based methods (cfr. Chapter 9 e Navigation). Nevertheless,
CNNs present some drawbacks. First, CNN-based methods require accu￾rate training that typically comprise a wide dataset and high computational
power to perform the learning effectively. Moreover, despite the CNN
generalization capabilities, the dataset needs to be validated to a certain
extent with respect to real images. Finally, dedicated HWs, such as graphics
processing units (GPUs) and VPUs (cfr. Chapter 15 e Modern Spacecraft
GNC e AI On-board Processors), are typically required to achieve the
desired inference time when the application is deployed on-board
(Fig. 15.31).
From a high-level perspective, there are two possible pose estimation
systems based on CNNs. These are compared in Fig. 15.32. In each of
them, the first essential step is represented by an object detection network
(e.g., Faster R-CNN [26], R-FCN [54], or MobileNet-based [55]) placed
before the main CNN. The CNNs employed in these detection architec￾tures solve two problems:
1. Type I: regression of bounding box coordinates.
2. Type II: classification of the object class (when more targets could be in
the camera FoV).
This is done in order to detect the target object in the image and crop a
region of interest (ROI) around it. For monocular pose estimation in space,
this step is crucial as ROI cropping allows robustness to scale, variation, and
background textures.
In Type I systems, the cropped ROI is fed into a keypoint detection
network. These CNNs keep only the feature learning step of Fig. 15.30
and directly output a set of feature maps without classifying the object.
These so-called heatmaps are detected around preselected features on the
Figure 15.31 Example of heatmaps [48].
872 Stefano Silvestrini et al.target object, such as corners or interest points. The 2D pixel coordinates of
the heatmap’s peak intensity characterize the predicted feature location, with
the intensity and the shape indicating the confidence of locating the corre￾sponding keypoint at this position, i.e., the prediction accuracy.
Notably, the selection of the specific CNN architecture will drive the
achievable keypoints detection accuracy and robustness. Some architectures,
such as the Hourglass [56] and the U-Net [22], perform a downsampling of
the input followed in series by an upsampling, in order to detect features at
different scales. However, recent advancements in the field demonstrated
that by using parallel subnetworks across multiple resolutions, rather than
multiresolution serial stages, the CNN can manage to maintain a richer
feature representation, facilitating more accurate and precise heatmaps.
For this reason, the HRNet [57] architecture currently represents the
state-of-the-art in keypoint detection.
Once the preselected keypoints are detected by the CNN, the extracted
keypoints are ultimately fed to a standard perspective-n-point (PnP) solver
(cfr. Chapter 9 e Navigation) together with their body coordinates, which
are made available through the wireframe 3D model of the target body.
Figure 15.32 Implementation of CNNs for relative pose estimation. Two system archi￾tectures are typically used in which the CNN is either used to detect keypoints (Type I)
or to directly infer the relative pose (Type II).
Modern Spacecraft GNC 873Conversely, Type II systems (also called end-to-end systems) predict the
full relative pose vector directly from the input image, based on either clas￾sification or regression following the feature learning step (see Fig. 15.30).
Classification formulations discretize the pose space and use the fully con￾nected layers to convert the feature maps into a confidence score for each
possible pose vector. On the other hand, the regression formulation aims
to learn a nonlinear mapping that directly regresses the six pose variables.
Pose classification formulation has been utilized in terrestrial applications
[58] as well as for uncooperative spacecraft [59], generally using the AlexNet
[19] or VGG16 [60] CNN architectures. On the other hand, the regression
formulation has been used most often in terrestrial applications [61,62].
Initially, end-to-end CNNs were more commonly exploited for the
pose estimation of uncooperative spacecraft [59,63e65]. However, since
the pose accuracies of these systems proved to be lower than the accuracies
returned by standard PnP solvers, especially in the estimation of the relative
attitude, systems based on keypoints-detection recently emerged as the
preferred option. Specifically, average orientation errors of 1:31  2:24o
were achieved by keypoints-based methods as opposed to the average orien￾tation errors of 9:76o  18:51o achieved by end-to-end methods. These av￾erages were computed across test images of the TANGO spacecraft as part of
the SPEED challenge [51].
Notably, another advantage of keypoints-based methods resides in their
capability to return both the 2D location of the detected features (CNN
output) and the full relative pose (PnP output). Consequently, they can
guarantee a much more flexible interface with the navigation filter, as dis￾cussed in the next section.
Interface with navigation and uncertainty estimate
The AI-based methods discussed in the previous section can provide an es￾timate of the relative pose for a static monocular image. This initial estimate
of the relative pose of the target spacecraft with respect to the servicer space￾craft does not require a priori information of the relative state and can there￾fore be exploited in lost-in-space scenarios. Due to their computationally
expensive IP, these pose initialization routines are, however, not well suited
to produce estimates at the high frequencies usually required during close
proximity operations. Therefore, a navigation filter is typically used in com￾bination with the camera measurements and the pose estimates in order to
return relative state solutions at high frequencies [66]. The internal dynamics
874 Stefano Silvestrini et al.of the filter can improve the accuracy of the predicted relative state from
measurements and allow a more robust pose tracking while estimating the
relative translational and rotational velocities.
As already discussed in the previous section, one of the major differences
between end-to-end and keypoints-based pose estimation systems resides in
the intermediate estimates that can be output at each estimation step. In a
keypoints-based system (Type I), both keypoints location and relative
pose can be estimated by cascading an AI-based keypoints detector with a
standard PnP solver. Conversely, only an estimate of the relative pose can
be output by an end-to-end system (Type II). As a result, the selection of
the pose estimation system will drive the selection of the type of navigation
filter.
From a high-level perspective, two different navigation architectures are
normally exploited in the framework of relative pose estimation (Fig. 15.33).
As discussed in Chapter 9 e Navigation, a tightly coupled architecture, where
the features are directly processed by the navigation filter as measurements,
and a loosely coupled architecture, in which the relative pose is directly fed to
the filter as pseudo-measurement. For each of these types, several navigation
filters can be adopted, cfr. Chapter 9 e Navigation. The reader is referred to
Ref. [48] for a more comprehensive overview. Remarkably, as detailed in
Chapter 9 e Navigation, recent implementations adopted a multiplicative
extended Kalman filter (MEKF) based on modified Rodrigues parameters
to overcome the covariance instabilities resulting from using quaternions
as attitude representation [67]. A three-element error parametrization a,
Figure 15.33 Overview of the three different interfaces between the CNN, the PnP
solver, and the navigation filter.
Modern Spacecraft GNC 875expressed in terms of quaternions, is propagated and corrected inside the fil￾ter to return an estimate of the attitude error. At each estimation step, this
error estimate is used to update a reference quaternion and is reset to zero
for the next iteration. Notably, the reset step prevents the attitude error
parametrization from reaching singularities, which generally occur for large
angles. Assuming a typical state vector for relative pose estimation:
x ¼
0
BBBBB@
r
v
q
u
1
CCCCCA
The propagation steps follow the derivation described in Chapter 4 e
Orbital Dynamics, Chapter 5 e Attitude Dynamics and Chapter 9 e
Navigation. In an MEKF, the correction steps are identical to the standard
Kalman filter formulation (cfr. Chapter 9 e Navigation):
bxþ
k ¼ bx
k þ Kk

yk  h

bx
k ; 0

where bx
k represents the state propagated by the filter internal dynamics, Kk
is the Kalman gain, yk is the measurements vector, and h

bx
k ; 0
 is the
nonlinear model of the measurements as a function of the propagated state.
As described in Chapter 9 e Navigation, in a loosely coupled filter, the
measurements are directly represented by the relative pose between the
servicer and the target spacecraft. In this case, a pseudo-measurements vector
is derived by transforming the relative quaternion set into the desired atti￾tude error a that represents a useful variable to work with:
dqy ¼ qy  qb*
k /a ¼ 4
dq1:3
1 þ dq4
where  denotes the quaternion product, qy is the quaternion measure￾ment, and qb
k
* represents the estimated quaternion conjugate at the pre￾vious step, namely qb
k . The measurements update equation then becomes
simply:
yk ¼ Hkxk þ vk ¼
"
I3 03 03 03
03 03 I3 03
#
bx
k þ vk
876 Stefano Silvestrini et al.where the Jacobian Hk represents the linearization of the measurements
model h

bx
k ; 0

. Conversely, in a tightly coupled filter, the measurements
are represented by the pixel coordinates of the detected features, and the
measurements update equation can be written as:
yk ¼ Hkxk þ vk ¼ 
Hr;i 02n3 Ha;i 02n3 «««« Hr;n 02n3 Ha;n 02n3

bx
k þ vk
where the partial derivatives of the 2n pixel coordinates of the detected n
features have to be computed with respect to the filter state, significantly
increasing the computational burden.
In the tightly coupled filter, the measurement covariance matrix R is a
block diagonal matrix constructed with the covariances of each detected
feature:
R ¼ ½C11Cn
If a keypoints regression architecture (Type I) is chosen at a pose estima￾tion level, a covariance matrix can be derived for each detected feature, tak￾ing advantage of their shape by associating small and large covariances to
highly symmetrical and largely asymmetrical heatmaps, respectively. Conse￾quently, a more representative statistical information can be associated to the
filter measurements and improve the overall filter robustness.
Notably, the prediction accuracy returned by the CNN for each heat￾map can also be used to discard outliers, allowing a more reliable set of mea￾surements handled by the navigation filter.
Conversely, in the loosely coupled filter, the measurements matrix R
represents the uncertainty in the pose estimation step, and hence it cannot
be directly related to the CNN heatmaps. In case a keypoints-based
CNN is exploited together with a standard PnP solver (Type I), no statistical
information can be easily retrieved from the pose estimation, and hence a
constant covariance is usually chosen based on the pose estimation accuracy
observed for the validation or test datasets. If on the other hand an end-to￾end CNN is used (Type II), the single CNN confidence returned for each
estimated pose cannot be easily associated to each element of the relative po￾sition and attitude. To compensate for this lack of statistical information,
recent implementations [68] accommodated an error prediction network af￾ter the main end-to-end CNN which rejects wrong pose estimates. As such,
inaccurate measurements can be rejected prior to the navigation step and a
constant measurements matrix R can be used without undermining filter
robustness.
Modern Spacecraft GNC 877Use case scenario: keypoints regression architecture
An important application of AI-based pose estimation systems for close￾proximity operations around a target is when the target is uncooperative
and tumbling, requiring a highly accurate and robust pose estimation system.
From a navigation filter perspective, a loosely coupled approach is usually
preferred for a tumbling target, due to the fact that the fast relative dynamics
could jeopardize feature tracking and return highly variable measurements
to the filter. However, the fact that it is generally hard to obtain a represen￾tative covariance matrix for the pseudo-measurements becomes critical
when filter robustness is demanded. Remarkably, the adoption of a
keypoints-based CNN system can overcome the challenges in feature
tracking by guaranteeing the detection of a constant, predefined set of fea￾tures. Moreover, the CNN heatmaps can be used to derive a measurements
covariance matrix and improve filter robustness, see Fig. 15.34.
In this context, this section describes the main steps of a keypoints-based
CNN pose estimation system required for the pose and features initialization
of the navigation filter prior to tracking [69]. The European Space Agency’s
(ESA’s) Envisat spacecraft is selected as a use case scenario, as Envisat has
been identified as the single most risk-inducing piece of space debris in
Figure 15.34 Heatmaps illustration for an accurate (left), slightly inaccurate (center),
and inaccurate (right) detection of a typical CNN. The displayed ellipses are derived
from the computed covariances by assuming the confidence intervals 1 s ¼ 0:68
and 1 s ¼ 0:99.
878 Stefano Silvestrini et al.multiple independent studies [70,71]. Fig. 15.35 illustrates the main steps
together with the intermediate outputs of each subsystem. The corners of
the Envisat body and of the specific absorption rate antenna are selected
as trainable features for the CNN as well as 3D points in the PnP solver.
These keypoints are chosen since they are more invariant to surface degra￾dation than richer features on the target body. Notice that since the tasks
associated to the object detection network go beyond the scope of this sec￾tion, the following description assumes that an ROI has already been crop￾ped around the target spacecraft.
Keypoints detection network e training, testing, and inference
The selected keypoints-based HRNet is trained offline in a supervised way
on w10.000 synthetic images of Envisat. Ideally, illumination conditions as
well as camera views and image noise should be optimized in order to guar￾antee a complete and representative dataset of the tumbling target. During
training, the validation dataset is used beside the training one to compute
the validation losses and avoid overfitting. The network is trained for a total
of 210 epochs with the Adam optimizer [73]. A decaying learning rate with
initial value of 103 and decaying factor of 0.1 is used to optimize the final
tuning of the network’s weights. Finally, the network performance after
training can be assessed with the test dataset. A ratio of w70%, w15%,
and w15% is usually chosen for training, validation, and testing, respec￾tively. After the offline phase, the CNN can be used to perform keypoints
inference on previously unseen images of Envisat. Fig. 15.36 shows two of
the heatmaps detected by the HRNet architecture for a sample monocular
image of Envisat, whereas Fig. 15.37 shows the pixel location of the 12 key￾points, extracted from each heatmap by computing the coordinates of their
peak intensity. Notably, accurate detections are characterized by heatmaps in
which the peak location can be easily computed from the R channel of the
RGB output image. For the selected monocular image of Envisat, the mean
detection accuracy across all the 12 keypoints amounts to 0.67 pixels, with a
maximum detection error of 1.6 pixels. Furthermore, one key advantage of
relying on CNNs for feature detection can be found in the capability of
learning the relative position between features which are not visible due
to adverse illumination and/or occulted by other parts of the target.
Covariance computation
To derive a covariance matrix for each feature directly from the heatmaps
detected by the CNN, the first step is to obtain a statistical population
Modern Spacecraft GNC 879Figure 15.35 Overview of the keypoints-based CNN system and its interface with the state estimator. Adapted from L. Pasqualetto Cassinis, A.
Menicucci, E. Gill, I. Ahrns, M. Sanchez-Gestido, On-ground validation of a CNN-based monocular pose estimation system for uncooperative
spacecraft: bridging domain shift in rendezvous scenarios, Acta Astronautica, 196 (2022) 123e138. https://doi.org/10.1016/j.actaastro.2022.04.
002.
880 Stefano Silvestrini et al.around the heatmap’s peak. This is done by thresholding each heatmap im￾age so that only the x- and y-locations of heatmap’s pixels are extracted. Sec￾ondly, each pixel within the population is given a normalized weight based
on the gray intensity at its location. This is done in order to give more
weight to pixels which are particularly bright and close to the peak, and
less weight to pixels which are very faint and far from the peak. Finally,
the obtained statistical population of each feature is used to compute the
weighted covariance between x, y and consequently the covariance matrix
Figure 15.36 Example of heatmaps output for two accurate HRNet detections.
Modern Spacecraft GNC 881Ci for each feature. As all the detected heatmaps represent accurate detec￾tions, their associated covariances are nearly diagonal and characterized by
diagonal elements of w1e2 pixels. For the first and last features, this corre￾sponds to the following covariance matrices:
C1 ¼ ½1:97 0:14 0:14 2:11; C12 ¼ ½1:65 0:02 0:02 1:56
PnP solver for state filter initialization
The pixel coordinates of the 12 detected features are fed into a standard PnP
solver together with their 3D body coordinates and the camera intrinsic pa￾rameters to solve for the initial relative pose between the monocular camera
and Envisat. Due to the high pixel accuracies obtained in the CNN-based
features detection step, accurate results are achieved at pose estimation level.
Specifically, an error of 0.3 m and 0.5 degrees is obtained for the norm of the
relative position and for the Euler axis-angle, respectively.
State estimator
The relative pose estimated by the PnP solver, together with assumed values
for the translational and rotational velocities, is used as initial guess x0 for the
navigation filter. The estimated x,y pixel coordinates of the 12 preselected
features are instead concatenated into a 2n measurements column vector
Figure 15.37 Pixel location of the 12 detected Envisat keypoints. As it can be seen,
partially occluded corners are still detected by the CNN, thanks to its capability to infer
the geometrical relation between each corner.
882 Stefano Silvestrini et al.z. Likewise, the feature covariances Ci are concatenated into the block￾diagonal measurement matrix R:
R ¼ ½ð1:97 0:14 0:14 2:11 Þ1ð1:65 0:02 0:02 1:56 Þ
After initialization, the filter estimates the full relative state by propa￾gating the relative pose and correcting it with the measured features. Notice
that the single covariance can differ for each feature at a given time step as
well as vary over time. As a result, a heatmaps-derived covariance matrix
can capture the statistical distribution of the measured features and improve
the measurements update step of the navigation filter.
Validation of AI-based systems
In the previous sections of Chapter 15dModern GNC, the validation
of AI-based pose estimation architectures was introduced as an offlinee
online process in which synthetic datasets, representative of a 3D model
of the target, were used to train, validate, and test the CNNs (offline phase)
prior to the inference of the relative pose on a sequence of images (online
phase). Overall, such synthetic validation consists in assessing the pose estima￾tion accuracy of the AI-based system on synthetic images that were previ￾ously unseen by the CNN in the offline phase. However, a more
representative on-ground validation of the CNNs’ performance shall be
sought to test the system robustness against representative images of the
target spacecraft. Due to a lack of large datasets of actual space imagery, these
images are usually generated in laboratory environments which recreate
space-like illumination conditions.
At the time of writing, several laboratory setups exist to recreate rendez￾vous approaches around a mockup of a target space object (i.e., asteroid,
moon surface, or spacecraft) with a monocular camera [74], i.e., the Testbed
for Rendezvous and Optical Navigation (TRON) at Stanford University
[51], the GNC Rendezvous, Approach and Landing Simulator (GRALS)
at the European Space Research and Technology Centre (ESTEC) [75],
the European Proximity Operations Simulator (EPOS) at the German
Aerospace Agency (DLR) [76], the Platform-art facility at GMV [77], and
the ARGOS facility at Politecnico di Milano [78,79]. In these setups, the
on-ground validation is achieved by establishing a calibration framework
to associate to each generated image a representative estimate (GT) of the
relative pose between the adopted monocular camera and a mock-up of
Modern Spacecraft GNC 883the target. This GT pose is then compared to the AI-based estimate to assess
the accuracy and robustness of the pose estimation architecture.
In this context, a fundamental challenge arises from the need to bridge
the quality gap between the synthetic renderings and the lab￾representative images. If a synthetic dataset used to train the adopted
CNN fails in representing the textures of the target mockup as well as the
specific illumination in the laboratory setup, the performance on lab￾generated images will, in fact, result in inaccurate pose estimates. To over￾come this, recent works addressed the impact of augmented synthetic data￾sets on the CNN performance in either lab-generated or space-based
imagery [15,50,68,69,72,80]. These augmented datasets are built on a back￾bone of purely synthetic images of the target by adding noise, randomized
and real Earth background, and randomized textures of the target model.
CNN validation e methods and metrics
In relation to Fig. 15.38, the on-ground validation can be seen as a result of
several intermediate procedures aimed at establishing a comparative frame￾work between the estimated and true quantities.
Figure 15.38 High-level overview of the on-ground validation of the relative naviga￾tion framework.
884 Stefano Silvestrini et al.The first step usually seen in the current setups consists in the calibration
of the laboratory environment. In open-loop tests, this is done in order to be
able to accurately estimate the true relative pose between the monocular
camera and the target mock-up. In closed-loop tests, however, the calibra￾tion of the camera with respect to its robotic arm (hand-eye calibration) is
additionally required. This is crucial if the motion of the robotic arm shall
be determined which moves the camera at the desired relative pose from
the target mock-up.
Once the setup is calibrated, the actual image acquisition procedures can
be executed, and each generated image can be associated to its true relative
pose. A laboratory dataset of static images as well as a continuous rendezvous
trajectory sequence can be recreated, depending on the main objective of
the validation. Typically, datasets are recreated first to validate the CNN
performance at a pose estimation level. Once the CNN accuracy is assessed,
the full navigation framework can then be validated in open/closed loop
against the representative images of a rendezvous trajectory.
Camera intrinsic calibration
The first step of the calibration procedure consists of the estimation of the
camera intrinsic parameters, such as the focal length, the principal point,
and the tangential and radial distortion coefficients. This is generally accom￾plished by taking images of known markers, such as Haruko-based chess￾board or traditional chessboard, with different camera views and solving a
standard PnP problem, in which the intrinsic camera parameters and the
relative poses between each camera view and the chessboard are the
unknowns.
Camera-to-mockup extrinsic calibration
The extrinsic calibration consists of accurately estimating the relative pose
between the adopted monocular camera and the mockup of the target ob￾ject. This is achieved through the calibration of each object with respect to a
fixed reference frame within the laboratory environment.
From a high-level perspective, most of the current calibration procedures
carried out prior to open-loop tests can be described through Fig. 15.39,
which represents the GRALS calibration setup adopted in Ref. [72]. The
setups are constituted of the following elements: (a) a scaled mockup of
the target object; (b) a monocular camera mounted on a robotic arm, and
(c) a tracking system used to track objects with retroreflective/IR markers
and to provide estimates of their pose with respect to a user-defined refer￾ence frame.
Modern Spacecraft GNC 885The mockup of the Envisat spacecraft is calibrated with respect to a
monocular camera mounted on a KUKA robotic arm. The reference GT
of the relative pose is estimated by calibrating both objects with respect to
the fixed reference frame of the VICON tracking system, which is used
to track objects within the laboratory environment through a set of IR cam￾eras. The procedure usually consists of the following steps:
• Camera-to-laboratory calibration, in which the camera is extrinsically
calibrated with respect to a fixed reference frame, usually the tracker
frame or the robot frame (VICON tracking system and KUKA robots in
Fig. 15.39).
• Mockup-to-laboratory calibration, in which the target mockup is cali￾brated with respect to the same fixed reference frames.
• Camera-to-mockup calibration, in which the relative pose between the
two objects can be obtained through the selected fixed reference frame.
Closed-loop hand-eye calibration
Several hand-eye algorithms exist in literature to calibrate a camera with
respect to a generic robotic arm [81], each of them handling the problem
in different ways. However, the two inputs to all of them consists of:
• Camera extrinsic parameters for each chessboard image, i.e., relative pose
of the camera with respect to the chessboard frame from the intrinsic cali￾bration step.
Figure 15.39 Representation of the ESTEC GRALS calibration setup followed prior to
the image acquisition step [72].
886 Stefano Silvestrini et al.• Telemetry recordings of the end effector pose with respect to the robot
frame for each of the chessboard images.
Once the hand-eye transformation is estimated, the accuracy of the es￾timate can be assessed by computing the reprojection error of each chess￾board corners from image i to image j¼iþ1. Referring to Fig. 15.40, this
is achieved by first expressing the 3D location of each point rk;i in the camera
frame when the camera is in the i-th location. Then, by using the estimated
hand-eye transformation CeT and the transformation eiejT to go from the
end effector ei to the end effector ej, the 3D location rk;j in the camera frame
when the camera is in the j-th location can be found and, consequently, the
point reprojection in image j:
rj ¼ ðCeTÞ
1
eiejTCeTOITri
Error metrics
In case a keypoints-based CNN is used (Type 1), the keypoints detection
performance can be assessed in terms of root mean squared error between
the GT and the x, y coordinates of the extracted features, which is computed
as:
RMSE ¼
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
Pntot
i¼1
h
xGT;i  xi
2 þ
	
yGT;i  yi

2i
ntot
vuut
Figure 15.40 Transformation required to reproject a point from image i to image
j ¼ i þ 1 through the hand-eye calibration. The transformation labeled in red repre￾sents the solution of the hand-eye calibration, whereas the transformation labeled in
green expresses the relative pose between two different end effector configurations.
Modern Spacecraft GNC 887Conversely, two separate error metrics are adopted in the evaluation of
the pose estimation performance [51]. Firstly, the translational error between
the estimated relative position bt
C and the GT t
C
GT is computed as:
ET ¼ 
t
C
GT bt
C

This metric is also applied for the translational and rotational velocities
estimated in the navigation filter. Secondly, the attitude accuracy is
measured in terms of the Euler axis-angle error between the estimated
quaternion qb and the GT qGT :
b ¼ ðbs bv Þ ¼ qGT  qb
ER ¼ ðjbsjÞ
Training augmentation techniques
Referring to Fig. 15.41, the first step of the currently adopted pipelines for
the datasets augmentation and randomization [68,72,80] consists in gener￾ating ideal synthetic images of a CAD model of the target. Generally, the
Azimuth and Elevation of the Sun are randomly varied around the ideal
camera-Sun relative position, in order to recreate favorable as well as
more adverse illumination conditions. Next, a randomization pipeline is
introduced which adds the following effects to the rendering:
• Texture randomization. This is performed in order to increase the CNN
robustness against texture variations between the synthetic and labora￾tory mockup of the target.
• Light randomization. Additional lights are introduced in random locations,
aside from the main Sun illumination, in order to increase the CNN
robustness against the illumination conditions recreated in the laboratory
setup
• Background randomization. Random scenes are used as image background
in order to increase the CNN robustness against the laboratory environ￾ment. Specifically, external disturbance sources in the lab are likely to re￾turn nonzero pixel values in the image background, leading to inaccurate
CNN detections in case the training dataset would consist of only black
backgrounds.
Following the software (SW) rendering, an additional pipeline is used to
further augment the generated images. This is performed by introducing the
Earth in the background in some of the images and by corrupting the images
with the following noise models:
888 Stefano Silvestrini et al.Figure 15.41 High-level schematic of an image augmentation pipeline. Adapted from L. Pasqualetto Cassinis, A. Menicucci, E. Gill, I. Ahrns, M.
Sanchez-Gestido, On-ground validation of a CNN-based monocular pose estimation system for uncooperative spacecraft: bridging domain shift in
rendezvous scenarios, Acta Astronautica, 196 (2022) 123e138. https://doi.org/10.1016/j.actaastro.2022.04.002.
Modern Spacecraft GNC 889• Gaussian, shot, impulse, and speckle noise.
• Gaussian, defocus, motion, and zoom blurs.
• Spatter, color jitter, and random erase.
Use case scenario e validation of keypoints detection
accuracy
In Type-I pose estimation systems, the system performance on the labora￾tory dataset can be evaluated at both keypoints detection and pose estima￾tion levels. To show the importance of dataset randomization in the
training phase, the keypoints detection network, trained with the random￾ized training dataset, is compared with the keypoints detection of the same
CNN trained on a subset of the augmented dataset, characterized only by
the Earth in the background and noise. This is shown in Fig. 15.42 for a sam￾ple image. Due to a lack of background, light, and texture randomization in
the training dataset, the CNN trained only on the partially augmented data￾set is overfitted on the textures learned on the synthetic Envisat model. As a
result, the network cannot associate the correct texture to each feature, and
the detected keypoints are randomly scattered around the image
(Fig. 15.42A). Conversely, the CNN trained on the randomized dataset
proves to be more robust against variations in texture and light between
the synthetic and the lab images, inferring the correct shape of the mockup
and detecting most of the keypoints in the correct location (Fig. 15.42B).
This improved robustness is mostly linked to the capability of the CNN
to learn shapes rather than textures, which can be traced back to the textures’
randomization step included in the augmentation and randomization pipe￾line. Remarkably, the features are detected even without a high synthetic￾lab representativeness, showing the CNN capability to transfer to images
which considerably differ from the training ones.
Reinforcement learning
The classification for ML approaches is composed by three categories
that depend on the nature of the feedback available to the learning system.
They are supervised learning, unsupervised learning, and reinforcement
learning, as already discussed previously.
Nowadays research in the field of ML is focused especially on supervised
learning. It exploits a training set of examples provided by an external super￾visor; all these examples are description of a situation in a specific environ￾ment, intended as the correct action that the system must take when it finds
890 Stefano Silvestrini et al.itself in a particular state. The final objective of training an agent with super￾vised learning is the achievement of the agent awareness, thanks to whom
the agent is capable to act correctly also in situations that are not present
in the training set. This is a very powerful way to solve problems like image
recognition, but it is not so adequate for learning from interaction. Indeed,
Figure 15.42 Impact of light, textures, and background randomization on the CNN
detection performance for a sample laboratory image of the Envisat mockup [72].
Notably, the randomization of the training dataset improves the CNN robustness
against different light, texture, and background conditions.
Modern Spacecraft GNC 891in interactive problems, it is almost always impossible to obtain a training set
of the desired behavior for all the situations in which the agent could act. In
these kinds of problems, the best way for the agent to learn is doing from its
own experience. The methodology called unsupervised learning is aimed to
find structures hidden in collections of unlabeled data. Therefore, if for su￾pervised learning the agent is fed by example inputs and desired outputs, in
unsupervised learning, the agent is left on its own to find the structure in its
inputs because no a priori knowledge is presented as outputs.
Apart from these two methods that seem to exhaustively classify the ML
paradigms, the reinforcement learning is the last component of this picture.
Reinforcement learning is an AI paradigm that consists in learning what to
do, how to map situations to actions, to maximize a numerical reward signal.
The learner is not told which actions to take, but instead must discover
which actions yield the most reward by trying them [82]. A founding
concept of reinforcement learning is the Markov decision process (MDP),
summarized below.
MDP: The MDP is a discrete-time stochastic control process that does
not possess any memory. It was theorized by Bellman in the ‘1950s by
extending the concept of Markov chains, proposed by the Russian mathe￾matician Markov. The MDP presents the problem of decision control as a
sequential decision process in which, at each time instant, when the process
is in a given state, the decision maker takes an action that moves the system
to a new state. A particular finite MDP is defined by its state and action sets
and by the one-step dynamics of the environment. The transition probabil￾ity between the two states depends only on the particular action-state pair
and not on past states, because of the absence of memory, and can be asso￾ciated to a scalar reward that establishes the goodness of the action taken in
that particular state.
Differently from unsupervised learning, it tries to maximize a reward
instead of finding hidden structures from a set of given data. Therefore, rein￾forcement learning can be defined as a tool aimed to learn a policy in order
to maximize a numerical reward. The two important characteristics of this
method are the trial-and-error search and the reward, and both of them
distinguish it from the other methods. In fact, the agent, or learner, of the
problem at the beginning does not know which actions to take, indeed its
task becomes to discover which are the actions that yield the greatest reward
value. The actions taken may affect not only the immediate reward but also
the future development of the problem and then all the sequence of rewards.
Reinforcement learning is one of the most common methods used to solve
892 Stefano Silvestrini et al.MDP problems both fully and partially observable. The final goal is to find a
policy capable to select the right action to take when the agent is in a partic￾ular state. Policies may also be found with evolutionary methods, but they
are capable to achieve a feasible solution only when the search space is small,
otherwise the optimization becomes computationally intractable. MDPs
have three aspects: sensation, action, and goal. Indeed, the agent is called
to sense the state in its environment and therefore to take an action that af￾fects the state itself, to achieve the goal or goals of the agent in that specific
environment. One of the most challenging features of reinforcement
learning that differentiates it from the others kind of learning is the trade￾off between exploration and exploitation. Logically, to obtain a good
reward, an agent should prefer actions already tried in the past that have
been found to be effective for the final reward value. But, on the contrary,
to find such kind of actions, the same agent should explore actions that it has
never selected before. Therefore, at each step, the agent has the dilemma of
either exploiting already experienced situations with sure results or to
explore new situations to find better actions for the future. The
exploitation-exploration trade-off, then, must be considered as an agent
that wants to try a variety of actions and progressively favor the ones that
appear to work better.
The agent typically needs to explore the environment in order to learn a
proper optimal policy, which determines the required action at a given
perceived state. At the same time, the agent needs to exploit such informa￾tion to actually carry out the task. In the space domain, and especially in on￾line applications, the balance must be shifted toward exploitation, for
practical reasons. Another distinction that ought to be made is between
model-free and model-based reinforcement learning techniques, as shown
in Table 15.2. Model-based methods rely on planning as their primary
component, while model-free methods primarily rely on learning. Although
Table 15.2 Model-based versus model-free reinforcement learning.
Model-free Model-based
Unknown system dynamics Learnt system dynamics
The agent is not able to make
predictions
The agent exploits predictive planning
Extensive need for exploration Minimal need for exploration
Lower computational cost while
executing
Higher computational cost while
executing
Modern Spacecraft GNC 893there are real differences between these two kinds of methods, there are also
great similarities. We call environmental model whatever information the
agent can use to make predictions on what will be the reaction of the envi￾ronment to a certain action. For the reasons above, the model-based
approach seems to be beneficial in the context of spacecraft guidance and
control, as it merges the advantage of analytical base models, learning, and
planning.
It is important to report some of the key concepts of reinforcement
learning:
• Policy. It defines the learning agent’s way of behaving at a given time.
Practically, it can be considered as a map from the states to the actions
that can be taken in an environment. It can be a simple function or a
very complex element that requires extensive computations. In general,
a policy is a stochastic element that specifies the probability to take an ac￾tion when the agent is in a defined state.
• Reward. At each time step, the environment sends to the reinforcement
learning agent a scalar number called the reward. The agent’s objective is
to maximize the total reward, and thus the reward function is a mathe￾matical representation of what is good or bad for the agent in an imme￾diate sense; it is the primary reason based on which the policy changes
over time. In general, the reward function depends on the state of the
environment and on the actions taken.
• Value function. The value function determines what is good in the long
run. It represents the total amount of reward that an agent can expect
to accumulate in the future, starting from the state in which it is
computed. Whereas rewards are the immediate desirability of the state,
the values are the long-term desirability of states after considering the
states that are likely to follow and the rewards achievable in those states,
i.e., a state may yield a low reward but still have a high value because it is
followed by other states that bring higher rewards.
• Model. The model of the environment is the element that simulates the
real behavior of the environment. It is used as a planning method by
which an action can be decided, considering possible future situations
before the agent experiences them. Reinforcement learning methods
that use prebuilt environment models are called model-based methods,
otherwise they are model-free methods.
The standard reinforcement learning theory states that an agent can
obtain a policy, which provides the mapping between a state x˛ X, where
X is the set of possible states, to an action a˛A where A is the set of possible
894 Stefano Silvestrini et al.actions. The dynamics of the agent is basically represented by a transition
probability pðxkþ1jxk;akÞ from one state to another at a given time step.
In general, the learnt policy can be deterministic pðxkÞ or stochastic
pðakjxkÞ, meaning that the control action follows a conditional probability
distribution across the states. Every time the agent performs an action, it re￾ceives a reward rðxk;akÞ: the ultimate goal of the agent is to maximize the
accumulated discounted reward R ¼ P
N
i¼k
gikrðxi;aiÞ from a given time
step k to the end of the horizon N which could be N ¼ N in infinite ho￾rizon. The user-defined coefficient g is the tunable discount parameter to
define how the agent pursues future rewards. As mentioned, the value func￾tion Vp is the total amount of reward an agent can expect to accumulate in
the future, at a given state. Note that the value function is obviously associ￾ated to a policy:
VðpðxkÞÞ ¼ E½Rjxk;ak ¼ pðxkÞ
In most of the reinforcement learning applications, a very important
concept is the action-value function Qp:
Qpðxk;akÞ ¼ rðxk;akÞ þ g
X
xkþ1
pðxkþ1jxk;akÞVpðxkþ1Þ
in which the remarkable difference with the value function is the fact that
the action-value function refers to the expected cumulative reward at a
certain state, given a certain action. The optimal policy is the one that
maximizes the value function pe ¼ argmaxpVpðxkÞ.
The reinforcement learning problem has been tackled using several ap￾proaches, which can be divided into two main categories: the policy-based
methods and the value-based methods. The former ones search for the pol￾icy that behaves correctly in a specific environment; the latter ones try to
value the utility of taking a particular action at a specific state [83e90].
Most of the literature tends to identify model-based approaches as the third
cluster of this classification, but we reckon it is a higher-level distinction.
Therefore, it has been discussed beforehand.
Several methods have been proposed to solve these problems, and they
are typically divided into Monte Carlo (MC) methods, dynamic program￾ming (DP), and temporal difference (TD) methods. Nevertheless, the latter
methods are typically blended in the most successful RL algorithms, mean￾ing that the best-performing algorithms combine the advantage of MC, DP,
Modern Spacecraft GNC 895and TD methods. Although the spectrum of RL algorithms is very wide and
fast growing, we try to categorize them hierarchically in Fig. 15.43. Later in
the chapter, the most used RL algorithms in space research are presented.
A remarkable take-home message is that reinforcement learning has orig￾inally been developed for discrete MDP. This limitation, which is not solved
for many RL methods, implies the necessity of discretizing the problem into
a system with finite number of actions. This is sometimes hard to grasp in a
domain in which the variables are typically continuous in space and time
(think about the states or the control action) or often discretized in time
for implementation. Thus, the application of reinforcement learning re￾quires smart ways to treat the problem and dedicated recasting of the prob￾lem itself. A further clustering for the methods is presented in Table 15.3 and
described below:
Figure 15.43 Taxonomy of reinforcement learning algorithms.
Table 15.3 Value-based versus policy-based.
Value-based Policy-based
Q-learning, value iteration Advantage actor þ critic, cross-entropy methods,
deep deterministic policy gradient, proximal policy
optimization
Explicit exploration Innate exploration and stochasticity
Evaluates states and actions Easier for continuous control
Easier to train off-policy Compatible with supervised learning
896 Stefano Silvestrini et al.• Value-based methods. These methods seek to find optimal value function
V and action-value function Q, from which the optimal policy p is
directly derived.
• Policy-based methods. These methods search for the optimal policy p*
directly, which provides a feasible framework for continuous control.
An additional distinction in reinforcement learning is on-policy and off￾policy. On-policy methods attempt to evaluate or improve the policy that is
used to make decisions during training; whereas off-policy methods evaluate
or improve a policy different from the one used to generate the data, i.e., the
experience.
Deep reinforcement learning algorithms
Q-Learning and deep Q-learning network
Q-learning and its DL extension is among the most used algorithms for rein￾forcement learning. It is a TD, value-based method that considers not only
the state but also the Q function, or so-called action-value function. As
mentioned before, the Q function, or action-value function, represents
the expected return (total reward), given a certain state and action.
Q-learning approaches are based on the optimization of the action-value
function Q, based on the Bellman optimality equation for Q:
Q*ðxk;akÞ ¼ maxpQðxk;akÞ
p* ¼ argmaxpQ*ðxk;akÞ
Q*ðxk;akÞ ¼ E

rðxk;akÞ þ gmaxakþ1Qðxkþ1;akþ1Þ

Hence, the method resolves in finding and approximating the optimal
action-value function from which to derive the optimal policy. The original
method was developed by Watkins [91]: given a certain learning rate h, the
next estimation of the action-value function can be calculated as:
Qkþ1 ¼ ð1  hÞQkðxk;akÞ þ h½rðxk;akÞ þ gQkðxkþ1;akÞ
It is important to remark that Q-learning can only deal with MDPs with
discretized states and action spaces. Q-learning is a simple yet effective algo￾rithm to create a tabular guidance for our spacecraft. Nevertheless, if the
number of states and actions increases, the tabular format to encode the
learning becomes rapidly intractable [92]. Deep Q-learning network is the
extension of Q-learning in which the Q-function is incapsulated in an
ANN. The experience is built up by the agent while playing different
Modern Spacecraft GNC 897episodes, meaning repeating the same task over and over to become
acquainted with the environment. During such episodes (we can think of
an episode as a single simulation of a spacecraft task: landing, orbital control,
etc.), the agent takes actions according to an ε-greedy policy. The ε-greedy
policy yields a random action with probability ε, otherwise it takes the action
that maximizes the Q-value function. The ε value is typically varied
throughout the episodes, in such a way that the agent begins to rely on
the Q-function only once the ANN starts approximating it well. Indeed,
the most common ε evolution is an exponential decay:
ε ¼ εf þ 
εi  εf

e
gDt
where εi, εf are the initial and final values of the probability, g is the decay
rate, and Dt is the current time step.
Pragmatically, this means that the agent randomly explores the environ￾ment at the beginning of its experience, whereas it exploits the knowledge at
the end of its experience. It is rather clear that the choice of ε is a critical step
in setting up the RL framework.
The main components of the deep Q-network (DQN) architecture are
(see Fig. 15.44):
• Q-network. The network represents the agent action-value function. This
network is constantly updated, and it is responsible to yield the optimal
action in a given state. Formally, it is the extension of the table for Q￾learning. At each time step, the Q-network outputs the Q-value for a
given state and action.
• Target network. The network is used to approximate the Q-value, but it is
updated only once in a while. At the beginning, the target network is
equal to the Q-network: the latter is updated at each time step, whereas
the former is reset equal to the Q-network only after a given number of
Figure 15.44 DQN schematic architecture.
898 Stefano Silvestrini et al.time steps. At each time step, the target network takes the next state and
predicts the best Q-value out of all actions that could be undertaken from
that given state.
• Experience replay. The experience replay represents the storage of training
data. The agent takes an action and receives a reward. Such information
tuple is saved as an experience. Why do we need to store experience if
we can update the training at each action undertaken? The reason
why it is necessary to create a memory database is due to the inherent
training procedure of ANNs. These mathematical architectures require
a batch of data to train efficiently and effectively; thus, it is beneficial
that each time the network updates itself, it does it on a batch of expe￾rience rather than a single state-action-reward value.
Advantage actor-critic network
The actor-critic algorithm is a policy-based architecture that aims at opti￾mizing directly the policy to be followed. As stated, these methods are
well suited for continuous and stochastic problems. Furthermore, they usu￾ally converge faster than value-based methods. The actor-critic method tries
to merge the two types of reinforcement learning methodologies, synthetiz￾ing the benefits and limiting the drawbacks of both. The breakthrough idea
of actor-critic is to split the model in two: one for computing an action based
on a state and another one to estimate the state-action value function (Q￾function).
The actor takes as input the state and outputs the best action. It essentially
controls how the agent behaves by learning the optimal policy (policy￾based). The critic, on the other hand, evaluates the action by computing
the value function (value-based). Those two models participate in a game
where they both get better in their own role as the time passes. Allegedly,
the result is that both the actor and the critic increase their performance as
the learning proceeds.
In synthesis, the two main components (see Fig. 15.45) act as follows:
• Actor. The actor is a function approximator, most commonly an ANN,
and its task is to produce the best action for a given state. Indeed, the
agent takes as input the state and yields the optimal action (based on
the current training status) as output. Overall, it controls the agent
behavior by learning the optimal policy.
• Critic. The critic is again a function approximator, most commonly an
ANN, which takes as input the environment and the action by the actor,
concatenates them, and outputs the action value (Q-value) for the given
pair. Basically, it evaluates the action taken by the agent while computing
the action-value function.
Modern Spacecraft GNC 899The training of the two networks is performed separately and exploits
the gradient ascent to update the weights and biases of both the actor and
the critic network. Then, during the training process, the actor learns to pro￾duce better actions while the critic learns to evaluate better those actions.
The update can happen both at the end of each time step, in this case, it
is defined as TD-0 learning, or at the end of the episode, TD-n learning.
To improve the actor-critic method, two more algorithms have been
developed: A2C e Advantage Actor Critic and A3C e Asynchronous
Advantage Actor Critic. Regarding the A2C, a new element e the advan￾tage value e is introduced subtracting from the action-value function the
value function.
Aðxk;akÞ ¼ Qwðsk;akÞ  Vwðxk;akÞ
The advantage function represents how much better an action is
compared to all the others at a given state; it is different from the value func￾tion that instead captures how good it is to be at this state. Exploiting the
Bellman equation, it is possible to write the advantage function Aðx; aÞ
only in dependence of the value-function:
Aðxk;akÞ ¼ E½rt þ 1 þ gVðxkþ1Þ  VvðxkÞ ¼ rkþ1 þ gVvðxkþ1Þ  VvðxkÞ
In this way, the critic network, instead of learning directly the Q-values,
learns the A-values; it means that the evaluation of an action is not only
based on how good it is but also based on how much better it can be.
The direct consequence is the reduction of the high variance of the policy
at each update and, therefore, the stabilization of the entire learning model.
As mentioned before, the parameters update may happen in two moments.
As TD-0 is defined, the A2C algorithm updates the networks parameters at
Figure 15.45 A2C schematic architecture.
900 Stefano Silvestrini et al.each time step; this kind of learning is an on-policy learning because the
behavior policy is equal to the update policy. Instead, here as TD-n is
defined, the A2C algorithm in which the optimization step is taken only
at the end of each episode. In this case, the learning is off-policy because
the agent learns when the episode is concluded, and therefore the update
and behavior policies are different.
The A3C algorithm was released by DeepMind in 2016 [93]; thanks to
its simplicity, robustness, and speed for standard RL tasks, A3C made policy
gradients and methods such as DQN obsolete. The difference with A2C is
the addition of the asynchronous part: it is characterized by multiple inde￾pendent agents, where each is defined by its own parameters, interacts
with a different copy of the environment, and does it in parallel to the
others. In this way, they can explore a bigger part of the state-action space
in much less time. The different networks are trained in parallel and update
periodically a global network. The term asynchronous comes from the fact
that the update does not happen simultaneously, and when it happens, all
the agents reset their parameters to those of the global network; then,
they continue their independent exploration and training until the next up￾date. As can be seen, the information not only is shared from the agents to
the global network but also among the agents themselves, thus leading to a
better and more complete results.
Proximal policy optimization
The proximal policy optimization (PPO) algorithm was introduced by the
OpenAI team in 2017 and quickly became one of the most popular RL
methods usurping the deep Q-learning method. It involves collecting a
small batch of experiences interacting with the environment and using
that batch to update its decision-making policy. Once the policy is updated
with this batch, the experiences are thrown away and a newer batch is
collected with the newly updated policy. This is the reason why it is an
“on-policy learning” approach where the experience samples collected are
only useful for updating the current policy once.
The key contribution of PPO is ensuring that a new update of the policy
does not change it too much from the previous policy. This leads to less vari￾ance in training at the cost of some bias but ensures smoother training and
also makes sure the agent does not go down an unrecoverable path of taking
senseless actions.
Modern Spacecraft GNC 901Although a detailed explanation of the method is outside the scope of
this book, a glimpse on the implementation highlights, especially in the
space domain is given hereby [85,87,90].
The PPO method is derived from the trust region policy optimization
optimization process by accounting for the policy adjustment constraint
with a clipped objective function. The objective function used with PPO
can be expressed in terms of the probability ratio given by:
pkðqÞ ¼ pqðukjxkÞ
pqold ðukjxkÞ
where q indicated the hyperparameters of the policy estimate. The actual
PPO objective can be written using a clipping function, a wrapper mathe￾matical function that maps a series of data on a bounded domain:
JðqÞ ¼ E½min½pkðqÞ; clipðpkðqÞ; 1  ε; 1 þ εÞApðxk; ukÞ
This clipped objective function ensures that the policy does not change
drastically between updates. In practice, policy gradient algorithms update
the policy using a batch of trajectories collected by interaction with the envi￾ronment. A schematic of the PPO architecture is shown in Fig. 15.46.
Model-based reinforcement Learning
Model-based reinforcement learning techniques may be the easiest concept
to grasp for engineers working in the space domain. Indeed, as mentioned at
the beginning of the section, such method tries to exploit, build, or learn a
model of the environment (what we generally call dynamics) in order to
generate predictive control and guidance based on the learnt representation
Figure 15.46 PPO schematic architecture.
902 Stefano Silvestrini et al.of the surrounding world [13,94e99]. In general, we can detect two impor￾tant features for such approach:
• Predictive models can generalize well enough to generate experiences
based on the estimated model rather than the true model.
• Propagations of initial errors inherently present in the learnt environ￾ment make long-horizon model prediction unreliable.
The concept of model-based reinforcement learning represents the
bridging idea that connects classical approaches such as optimal control to
reinforcement learning. Indeed, if we think the reward as a cost function and
the actions as control inputs, we can clearly understand how the two para￾digms refer to the same problem.
Inverse reinforcement learning
Inverse reinforcement learning is a task and method of learning an agent’s
objectives, values, or rewards by observing its behavior. In more traditional
terms, this means estimating the cost function or the future state (transla￾tional or attitude) trajectory of an observed spacecraft only processing mea￾surements. It is important to remark that, in dynamical system theory (cfr.
Appendix A2), the term trajectory represents the set of points in state space
that are the future states resulting from a given initial state. This observation
strengthens the analogy between reinforcement learning and optimal con￾trol, and consequently between inverse reinforcement learning and inverse
optimal control.
In general, one can look at inverse reinforcement learning as a frame￾work answering the following [83]:
1. Model the expert’s observed behavior as the solution of an MDP whose
reward function is not known.
2. Initialize the parameterized form of the reward function using any given
features (linearly weighted sum of feature values, distribution over re￾wards, or other).
3. Solve the MDP with the current reward function to generate the learned
behavior or policy.
4. Update the optimization parameters to minimize the divergence be￾tween the observed behavior (or policy) and the learned behavior
(policy).
5. Repeat the previous two steps till the divergence is reduced to a desired
level.
A very brief introduction to two of the most common methods, namely
feature-matching approach and maximum entropy is hereby given.
Modern Spacecraft GNC 903Feature-matching approaches
In general, the cost function of an optimal control problem for trajectory
planning in the horizon ðt; TÞ can be described as the summation of a
running intermediate cost and the terminal state penalty. The cost function
can be recast into a feature-based expression where the cost is a linear com￾bination of f nonlinear features. In principle, each state-control pair can
represent a feature. In this method, the optimizer is described as an optimi￾zation over a linear combination of features f, which represent cumulative
cost along feasible trajectories and terminal state penalty. The feasible trajec￾tories are those respecting optimization constraint and dynamics: the set of
state-control pairs represents a policy p, borrowing a term from the rein￾forcement learning world. Using such approach, the cost function can be
rewritten [99]:
w ¼ 
w1; w2; .; wf ; wT
T ; mðpÞ ¼
2
6
4
T
X1
t
fðxt; utÞg1;.;f
fT ðxT Þ
3
7
5/cost : J
¼ w
T $mðpÞ
(15.9)
The above formulation is necessary to introduce and discuss the feature￾matching approach for inverse reinforcement learning.
The concept of inverse reinforcement learning is to estimate a cost func￾tion that delivers an optimal trajectory compatible with an expert demon￾strated trajectory, called ge ¼ fðxt; utÞgT
t for simplicity. Let us assume the
example where the demonstrated trajectory is the reconfiguration path fol￾lowed by the neighboring agents of a spacecraft formation flying mission.
The estimated cost function translates into trajectories through the applica￾tion of an optimal control problem. Such optimal control problem can be
thought as the guidance profile of each agent. It is important to note that
the expert cost function, parametric in the set of features, is not known,
but we assume the demonstration to be optimal for the estimated one.
Each trajectory is generated by a policy p, which characterizes the state￾control pairs at each instant in time, ideally. In detail, given a set of No ob￾servations of the demonstrated trajectory Deg ¼ fðxi; uiÞgNo
i¼1, we need to
find a cost function J , under which the demonstrated trajectory looks
optimal according to the estimated cost function. It means that the demon￾strated trajectory is the result of an optimization of a certain cost function
904 Stefano Silvestrini et al.that we want to estimate, namely the expert cost function. The feature￾matching approach solves for the weights in Eq. (15.1) by attempting to
match the cumulative feature cost demonstrated by the expert under the
optimal policy pe and the policy p* based on the estimated cost function.
The FMA can be expressed in compact form:
J

ge

pe

< J ðgjpÞ/w
T $m

pe

< w
T $mðpÞ; cg (15.10)
where it is stated that the demonstrated trajectory is optimal with respect to
the estimated cost function.
The demonstrated trajectory owns significant information about the
structure of the cost function; hence, the algorithm significantly benefits if
the discrepancy between the estimated optimal trajectory and the expert
one is integrated in the optimization [94e96,100].
Loss augmentation represents a cost gap structured margin:
L egðpÞ ¼ X
No
i¼1



xei  xi




2
:
By inserting the loss augmentation in Eq. (15.10), we obtain the expres￾sion for the FMA for IRL:
minwjjwjj2
subject to w
T $ m

pe

< w
T $mðpÞ  L egðpÞ (15.11)
The form of Eq. (15.11) represents a convex optimization. Nevertheless,
the set of policies the algorithm sweeps is theoretically not finite. This makes
the optimization intractable, in particular, for computational constraints of
several interesting applications in spacecraft GNC. We may suppose that
there exists a policy p* that minimizes the right-hand side of the constraints
in Eq. (15.11). Then, the constraints in Eq. (15.11) can be written as
wT mðpÞ < minp wT mðpÞ  L egðpÞ without any loss of generality.
We can place the constraint into the cost function. This yields an uncon￾strained optimization, which can be solved using gradient-based algorithms:
minw
h
2
jjwjj2 þ
 
w
T m

pe

 minp
(
w
T mðpÞ  L egðpÞ
)!
Modern Spacecraft GNC 905where h is a user-defined coefficient. The FMA-IRL is a nested optimi￾zation problem. The outer loop is unconstrained, whereas the inner loop,
which is a path-planning optimization, may be constrained, both linearly
and nonlinearly.
Maximum entropy
IRL is essentially an ill-posed problem because multiple reward functions
can explain the expert’s behavior. The maximum margin utilized in the
feature-matching approach introduces a bias into the learned reward func￾tion. To avoid this bias, multiple methods take recourse to the maximum
entropy principle [89,91] to obtain a distribution over behaviors, parameter￾ized by the reward function weights. According to this principle, the distri￾bution that maximizes the entropy makes minimal commitments beyond
the constraints and is least wrong. In general terms, the methods utilized
in literature differ in the distribution whose entropy is used to generate
the predictions. The most common selection of methods covers the entropy
distribution over trajectories (demonstrated observations) or distribution
over policies [83].
AI use cases
This section presents a set of applicative scenarios at research level. The
aim of the section is to demonstrate the development of advanced and inno￾vative GNC systems arising from the fundamental content present earlier.
The reader is advised to go through this section as if it was a research liter￾ature survey on innovative AI-based GNC systems.
Neural dynamics reconstruction through neural networks
The capability of using ANN to approximate the underlying dynamics of a
spacecraft is used to enhance the on-board model accuracy and flexibility to
provide the spacecraft with a higher degree of autonomy. There are different
approaches that could be adopted to tackle the system identification and dy￾namics reconstruction task. In the following section, the three analyzed
methods are described. The three methods employ the ANN model at
different integration levels. The different approaches can be clustered in:
• Fully neural dynamics learning.
• Dynamics acceleration reconstruction.
• Parametric dynamics reconstruction.
906 Stefano Silvestrini et al.Fully neural dynamics learning
The dynamical model of a system delivers the derivative of the system state,
given the actual system state and external input. Such inputeoutput struc￾ture can be fully approximated by an ANN model. The dynamics are
entirely encapsulated in the weights and biases of the ANN. The neural
network is stimulated by the actual state and the external output. In turn,
the time derivative of the state, or simply the system state at the next discre￾tization step, is yielded as output, as shown in Fig. 15.47:
x_ ¼ Nðx; uÞ/xkþ1 ¼ Neðxk; ukÞ
The method relies on the universal approximation theorem since it as￾sumes that there exists an ANN that approximates the dynamical function
with a predefined approximation error. The training set is simply composed
of inputeoutput pairs, where the input is a stacked vector of the system state
and control vectors. The dynamics reconstruction based solely on ANNs
largely benefits from the employment of RNNs, rather than simpler feed￾forward networks.
The fully neural dynamics learning employs an ANN for encapsulating
the whole dynamics reconstruction. Let us assume having a system that
evolves according to the following equation:
x_ ¼ fðx; uÞ
Figure 15.47 Two-layer MLP for dynamics identification.
Modern Spacecraft GNC 907Furthermore, it is assumed that the observation is equal to the state for
the sake of simplicity. The algorithm can easily be extended to different
measurement models by introducing the measurement function hðxÞ or its
linear matrix version H. The system dynamics can be learnt using an artificial
RNN trained by the standard backpropagation algorithm [13]. One effec￾tive strategy is to leverage the physics of the problem in order to obtain a
representation, which needs solely some parameters to be fit. Another
approach is to couple the neural network with an estimation algorithm to
reconstruct only the perturbation terms, taking as basis the linearized natural
dynamics. For this example, an RNN is chosen as the neural network archi￾tecture. Its simple architecture and brief evaluation time make it a suitable
architecture for on-board applications. Recurrent networks have the capa￾bility of handling time-series data efficiently. The connections between neu￾rons form a directed graph, which allows an internal state memory. This
enables the network to exhibit temporal dynamic behaviors. When dealing
with dynamics identification, it is crucial to exploit the temporal evolution
of the states; hence, RNN shows superior performances with respect to
MLP. In detail, two recurrent networks are proposed to tackle the system
identification problem, cfr. Chapter 15 e Modern Spacecraft GNC e AI
in space e Introduction. Namely:
• Layer-recurrent neural network.
• Nonlinear autoregressive network with exogenous inputs (NARX).
It is important to remark that the NARX model uses control action as
inputs and state as output, given a certain n-delay of the training data
[13]. The NARX network is particularly suited for the dynamics reconstruc￾tion task, being able to make predictions when used in a closed-loop archi￾tecture. Although less performant than RNN, the system dynamics can also
be learnt using a feedforward neural network trained by standard backpro￾pagation algorithm [96]. In this example, a two-layer network is employed,
namely one hidden layer as sketched in Fig. 15.47. A hyperbolic tangent is
used as the activation function for the hidden layer, whereas a rectified linear
unit (ReLU) is used as a neural activation function for the output layer.
The dynamics of the spacecraft can be learnt as a discrete model. The
downside of such strategy, especially in terms of implementation is that
the ANN is associated with a fundamental time step of discretization. In
an operative scenario, this could be the sampling frequency of the navigation
system. Nevertheless, it could be the case in which the navigation measure￾ments frequency is much higher than the required planning one.
908 Stefano Silvestrini et al.This generates a discrepancy between the model to be learned and the
model employed in trajectory generation. However, a too fine sampling
in a restricted region negatively affects the generalization capability of the
network. The dynamical model can be represented as:
xkþ1 ¼ fTs
ðxk; ukÞ
where the transition matrix is associated to the sampling time Ts, as stated.
These considerations fall into a more fundamental discussion on the
importance of dataset generation for DL purposes. As described in Chapter
15 e Modern Spacecraft GNC e AI in space e Introduction, the whole ML
and DL domain is data-driven. In simple words, this means that the better
the data (samples, distribution, generalization, etc.), the better the perfor￾mance we could expect.
The model is learned using backpropagation. Let us adopt the well￾established LevenbergeMarquardt algorithm for minimizing:
minw
X
i

Ne Tðx; u; wÞ  ykþ1


2
where Ne is the ANN model (function approximator) at the current learning
step, hence the dependency on the weights w. The vector y is the obser￾vation vector.
Dynamics acceleration reconstruction
The second method uses the capability of the ANNs to approximate an un￾known function. It is wise to exploit every analytical knowledge we may
have of the environment. Nevertheless, most of the time, the analytical
models encompass linearization and do not model perturbations, either
because they are analytically complex or simply unknown. For this reason,
in this example, a radial basis function neural network aided adaptive
extended Kalman filter (RBFNN-AEKF) for state and disturbance estima￾tion is developed. RBFNNs are selected for their simple structure and suit￾ability for fast online training. The neural network estimates the unmodeled
terms which are fed to the EKF as an additional term to the state and covari￾ance prediction step. Finally, a recursive form of the adaptive EKF is
employed to limit the overall computational cost. The idea is to combine
classical techniques with modern AI-based ones by the combination of mis￾modeling estimation by the RBFNN together with the adaptive formula￾tion of the EKF, providing a robust, accurate, and computationally
Modern Spacecraft GNC 909efficient navigation filter that can be initialized and run on-board. In brief,
the method can be summarized into three keypoints:
• The AI filter uses the RBFNN to learn and output an estimate of the
disturbance/mismodeled terms that is used in the EKF to deliver a better
predicted estimate.
• The robustness of the filter is guaranteed through the adaptation step.
The combination of an RBFNN and a filter can lead to a very wrong
state estimation if the RBFNN estimates diverge or converge to a wrong
value; hence, the adaptivity guarantees the robustness of the navigation
algorithm.
• The RBFNN learning is fully performed online. This means that no
prior knowledge or learning must be performed beforehand. This
dramatically increases the flexibility of the algorithm.
The neural network estimates the disturbances acting on the system,
which are then adjunct in the prediction step of the filter (cfr. Chapter 9
e Navigation). The filter architecture is sketched Fig. 15.48. The innova￾tion term is used to carry out the adaptivity task. Whereas, the residual
term, considering the estimation state at step k, is fed into the online learning
algorithm of the network’s weights. The system dynamics, considering the
process noise, is assumed to be described as:
x_ ¼ f ðx; uÞ þ w
Alongside, the measurements are assumed to be perturbed by white noise
as:
zmeas ¼ Inx þ v
Normally, an observation function, often nonlinear, is introduced, as
explained in Chapter 9 e Navigation. In this example, we assume that
Figure 15.48 Schematics of ANN-aided adaptive extended Kalman filter.
910 Stefano Silvestrini et al.the measurement matrix H ¼ In or, more general, the measurement model
hðxÞ ¼ x. In other words, the state is assumed to be completely observable
for the sake of derivation, but the approach is applicable to partially observ￾able state and to nonlinear measurement models.
As explained in Chapter 15 e Modern GNC e AI in space, the RBFNN
is a popular network topology [14], which has the capability of universal
approximation. Due to its simple structure and much quicker learning pro￾cess, it stands out compared to the classic MLP, especially for function
approximation applications. The neurons of RBF are nonlinear Gaussian
function; hence, a shallow network can be used with the same results of
MLP. Hence, we will employ a light network for this example, consisting
of one input, one hidden, and one output layer. The input layer processes
the state vector bxk1 ¼ ½x1; x2;.; xn
T , where k  1 is the time instant.
The hidden layer performs a nonlinear mapping of the input, whereas the
output layer is a linear combination of the nonlinear hidden neurons trans￾formed into the resultant output space. The output space is the disturbance
vector db ¼ ½d1; d2;.; dn
T . An RBFNN is used to estimate the unmod￾eled disturbances, as well as the nonlinearities present in the system dy￾namics. The network has a three-layers structure, comprising an input,
output, and hidden layer. For the sake of derivation, we call x˛Rn the input
vector.
It is hereby remarked that the vector x is employed to derive the
network structure: in the following sections, the distinction between state
vector and estimated state will be described and treated accordingly.
Similar to the input vector; F˛Rm is the hidden layer vector and i the
associated index, d is the output vector and i the associated index. Essen￾tially, the hidden layer evaluates a set of m RBFs which are chosen as
centered-Gaussian expression:
FðxÞ ¼ ehðjjxcijjÞ2
; ci ¼ 1: m (15.12)
where m is the number of neurons and ci is the randomly selected center for
neuron i. The number of neurons m is a user-defined parameter: its value is
application-dependent, and it shall be selected by trading-off the recon￾struction accuracy and the computational time. The same consideration
holds for the parameter h, which impacts the shape of the Gaussian func￾tions. As already discussed, a high value for h sharpens the Gaussian bell
shape, whereas a low value spreads it on the real space. On one hand, a
narrow Gaussian function increases the responsiveness of the RBF network,
Modern Spacecraft GNC 911on the other hand, in case of limited overlapping of the neuronal functions
due to too narrow Gaussian bells, the output of the network vanishes.
Hence, ideally, the parameter h is selected based on the order of magnitude
of the exponential argument in Eq. (15.12). The output of the neural
network hidden layer, namely the radial functions evaluation, is normalized.
In a compact form, the output of the network can be expressed as:
dðxÞ ¼WTFðxÞ
where W ¼ ½wil for i ¼ 1, ., m and l ¼ 1, ., j is the trained weight
matrix, and FðxÞ¼½F1ðxÞF2ðxÞFmðxÞT is the vector containing the
output of the RBFs, evaluated at the current system state. The dynamical
model can be described by a set of nonlinear differential equations:
x_ ¼ f ðxÞ þ dext (15.13)
where the term dext is representative of the unknown disturbance acceler￾ation that is added to the known dynamics function f ðxÞ. In particular, the
disturbance term gathers the contribution of all the environmental pertur￾bations and unmodeled terms. These uncertainties need to be estimated
online. Hence, an online learning algorithm, which drives the update of the
weights, is required. The weights update law is derived to guarantee the
stability of the estimation algorithm and neural dynamics, hereby defined as
the evolution of the weight matrix in time.
In the following mathematical derivation, we make use of the universal
approximation theorem for neural networks that guarantees the existence of
a set of ideal weights W that approximates a function with a bounded arbi￾trary approximation error. Such weights are unknown; hence, the algorithm
is designed to obtain an estimate cW of the ideal weights by performing on￾line learning. The neural network learning algorithm relies on the estima￾tion error dynamics, targeting convergence, and stability of the estimated
weights matrix cW evolution toward the ideal weights and the error e, calcu￾lated in the EKF. The symbol (^) is used to refer to estimated quantities, as
described in Chapter 1 e Introduction. To derive the error dynamics, let
us assume the actual system dynamics is described by Eq. (15.13), where
dext is the unknown external disturbance term. The actual system dynamics
can be rewritten as the following equation, assuming to include all the
nonlinear terms into dðxÞ, which is the vector-valued function equivalent
to the RBFNN output vector:
912 Stefano Silvestrini et al.x_ ¼ Ax þ dðxÞ
where the term d(x) captures all the nonlinearities together with the un￾known disturbances external to the system, namely
dðxÞ ¼ f ðxÞ  Ax þ dext. The matrix A is a stable, potentially time￾varying, matrix representing the linear term, if any, of the original dy￾namics expression in Eq. (15.13).
The expression of the continuous single-step Kalman filter can be writ￾ten as (cfr. Chapter 9 e Navigation):
dbx
dt ¼ A$bx þ bdðbxÞ þ KkHðx  bxÞ
where bd is the estimated function using the radial-basis function neural
network, Kk is the time-varying gain matrix of the Kalman filter (subscript k
stands for the referred time step), and H is the observation matrix. Consider
that the continuous form is employed for the sake of derivation, in fact, the
learning rule is then discretized for the actual implementation. The error
dynamics can be derived as:
e ¼ x  bx
e_ ¼ x_  dbx
dt ¼ dðxÞ  bdðbxÞþðA  KkHÞe
Invoking the universal approximation theorem for neural networks, we
can assume there exists an ideal approximation of the disturbance term d(x):
dðxÞ ¼WTFðxÞ þ ε
where W is the neural weights matrix, FðxÞ is the vector-valued function
resulting from the evaluation of the Gaussian functions contained in each
neuron of the RBFNN, ε is a bounded arbitrary approximation error.
Consequently, the error in estimation can be written as:
dðxÞ  bdðbxÞ ¼ WTFðxÞ þ ε  cW
T
FðbxÞ
by adding and subtracting the term W ¼ FðbxÞ and performing few
mathematical manipulations, the above equation can be expressed as:
ed ¼fW
T
FðbxÞ þ εj
Modern Spacecraft GNC 913where ed ¼ d  bd; fW ¼ W  cW, and the bounded term εj ¼ ε þ W$
½FðxÞ FðbxÞ. The aim of the learning rule is to drive the dynamics error to
zero, as well as forcing the weights to converge to the ideal ones. The
weights update rule f_
W is derived to guarantee the stability and convergence
of the estimation algorithm:
V ¼ 1
2
tr	
xW
gTfW


þ h
2
eTe (15.14)
where tr($) is the trace operator, x, h > 0 are user-defined coefficients. The
derivative of the Lyapunov function can be written as:
V_ ¼ tr	
xW
gTfW_ 

þ heTe_
¼ tr	
xW
gTf_
W


þ heT
	
W
gTFðbxÞ þ ε0 þ ðA  KkHÞe


¼ tr	
xW
gTf_
W


þ heTW
gTFðbxÞ þ heTε0 þ heTðA  KkHÞe
¼ tr	
xW
gTf_
Wþ hW
gTFðbxÞeT


þ heTε0 þ heTðA  KkHÞe
¼ tr	
W
gT
	
xf_
Wþ hFðbxÞeT


 þ heTε0 þ heTðA  KkHÞe < 0 (15.15)
If we recall the manipulation of fW ¼ W  cW / fW_ ¼ c_
W, we can
derive the update rule for the weights such that the stability and convergence
of the estimation is guaranteed by the Lyapunov theorem. The expression
reads:
c_
W ¼ h
x
T
FðbxÞeT
Inserting this derivative c_
W; the expression for the derivative of the Lya￾punov function in Eq. (15.14) reduces to the stability of the error estimation
of the extended Kalman filter. The error term represents the residual
914 Stefano Silvestrini et al.between estimated and actual output of the observed system: in practical
terms, the expression is the innovation of the estimation filter. The εj
term is a bounded term that derives from the universal approximation the￾orem of ANNs that states that the term ε can be arbitrarily small. In practice,
it represents an upper boundary for the derivative of the Lyapunov function.
In case of linear systems, the term (AKkH) grants asymptotic stability of
the Kalman filter if A is reachable and H is observable. In case of nonlinear
systems, this is not always true. However, it has been proved that the esti￾mation error of an EKF is exponentially bounded if:
• A is nonsingular for every t  0.
• there exist real constants p1; p2 > 0 such that p1$I  Pk  p2$I where
Pk is the estimated state covariance matrix.
• the initial estimation error satisfies jjbx0  x0jj < ε and the process and
measurements covariance matrices are bounded.
where bx0 and x0 are the estimated and true state vector at the initial step.
Given the EKF asymptotic stability with exponential decaying error under
the aforementioned conditions, i.e., the derivative of the Lyapunov function
of the estimation error is negative, Eq. (15.15) is verified and hence the
stability of the estimator is guaranteed.
The weights update rule can be discretized using a first-order Euler
method, assuming the measurements interval is small enough:
cWkþ1 ¼ jcWk þ hc_
Wk ¼ jcWk þ h
h
x FðbxkÞeT
k
where k is the time step index, j is a user-defined relaxation factor, and
h ¼ tkþ1  tk is the time interval between two consecutive measurements.
Parametric dynamics reconstruction
The third method is developed under the framework of parameter recon￾struction. Basically, the ANN is employed to refine the uncertain parameters
of a given dynamical model. This method is particularly suitable when the
uncertain environment influences primal system constants (e.g., inertia pa￾rameters, spherical harmonics, and drag coefficients). In the example re￾ported in this book, the method is developed using an RNN to estimate
the spherical harmonic expansion coefficients of irregular bodies that popu￾Modern Spacecraft GNC 915late the Solar System. Such method is very fast and computationally light
with respect to traditional algorithms for parameters estimation. Moreover,
given the physical knowledge of the parameters to be reconstructed, the
method has a very promising scientific outcome. For instance, the gravity
expansion of asteroids and planets can be approximated online while flying,
delivering a rough shape reconstruction of the body. Nevertheless, many ap￾plications overlap with the disturbance reconstruction approach in which
the disturbance function to approximate is a constant parameter, as assumed
in many estimation algorithms, such as the well-established Kalman filter.
For this reason, many researchers used MLP neural networks to carry out
the task. For instance, Chu et al. [101] proposed a deep network MLP to
estimate inertia parameters. The angular rates and control torque of com￾bined spacecraft are set as the input of a DNN model, and conversely, the
inertia tensor is then set as the output. Training the MLP model refers to
the process extracting higher abstract feature, i.e., the inertia tensor
[101,102].
Another approach to solve the parametric reconstruction is to use an
RNN. In particular, HNNs are investigated in Refs. [39,40]. The core of
the algorithm is the following: if the dynamical model (cfr. Chapter 10 e
Control and Appendix A2) is reformulated into linear-in-parameters
form, the identification problem can be reformulated as an optimization
problem:
y ¼ AðxÞ$c
In particular, defining a general prediction error e ¼ y  A$c*, the
resulting combinatorial optimization problem is:
min
C

sup
t

1
2
eT $ e

where y typically corresponds to measurements, A is the linear-in-parameter
matrix, and c* is the estimated parameter vector [40].
The HNN, as presented in Chapter 15 e Modern Spacecraft GNC e AI
in spacedIntroduction can be used to solve these types of combinatorial
problems. Recalling the network fundamental equation:
ds
dt ¼ 1
b DðWs þ bÞ
916 Stefano Silvestrini et al.where we can exploit the fact that the neural network can be adapted to
represent the problem of our interest. Indeed, if we define the weight matrix
as W ¼ ATA and the bias vector as b ¼ Ws0 þ ATy, we can establish a
direct link between the system identification problem and the dynamics of
the network. The application of the HNN to the solution of the optimiza￾tion problem benefits from the existence of a network Lyapunov function
that guarantees stability of the network, cfr. Chapter 15 e Modern GNC
e AI in space.
Convolutional neural networks for planetary landing
The use of AI in scenarios for the moon or planetary landing is still at an early
stage, and few works exist in literature concerning image-based navigation
with AI. The presented solutions are all based on a supervised learning
approach. Images with different lighting and surface viewing conditions
are used for training. One idea is to substitute classical IP algorithms,
providing a first estimate of the lander state (e.g., pose or altitude and posi￾tion), which can be later refined by means of a navigation filter. Similar ap￾proaches have been implemented in the robotic field, where pretrained on a
large dataset, they estimate the absolute camera pose in a scene. In a landing
scenario, the knowledge of the landing area can be exploited, if available.
Therefore, a CNN (cfr. Chapter 15 e Modern Spacecraft GNC e AI in
space e Introduction) can be trained with an appropriate dataset of synthetic
images of the landing area at different relative poses and illumination condi￾tions. The CNN is used to extract features that are then passed to a fully con￾nected layer, which performs a regression and outputs directly the absolute
camera pose. The regression task can be executed by an LSTM. The CNN￾LSTM has proven excellent performance and is very well developed for IP
and model prediction. The use of a recurrent network brings the advantage
of also retrieving time-series information. This can allow estimating also the
velocity of the lander. According to an extensive review of the applications,
one can make a general distinction between two macromethods:
• Hybrid approaches. They utilize CNNs for processing images, extracting
features, classifying or regressing the state at the initial condition, but
they are always coupled with traditional IP or navigation algorithms
(e.g., PnP, feature tracking).
• End-to-end approaches. They are developed to complete the whole visual
odometry (VO) pipeline, from the image input to the state-estimate
output.
Modern Spacecraft GNC 917As an interesting example, although not directly applied to space systems,
the technique presented in Ref. [103] relies on an end-to-end learning for
estimating the pose of an unmanned aerial vehicle during landing. In partic￾ular, the global position and orientation of the robot is the final output of the
AI architecture. The AI system processes two kinds of inputs: images and
measurements from an inertial measurement unit (IMU). The architecture
comprises a CNN that takes as input streams of images and acts as a feature
extractor. Such CNN is built starting from ResNet18, pretrained on the
ImageNet dataset. An LSTM processes the IMU measurements, which
are available at a higher frequency than images. An intermediate fully con￾nected layer fuses the inertial and visual features coming from the CNN and
the LSTM. Then, such vector is passed to the core LSTM, along with the
previous hidden state, allowing to model the dynamics and connections be￾tween sequences of features. Finally, a fully connected layer maps the feature
to the desired pose output.
Similarly, the architecture proposed by Furfaro et al. [104] comprises a
CNN and an LSTM. The final output of the AI system is a thrust profile
to control the spacecraft landing. The CNN input consists in three subse￾quent static images. Such choice is motivated by the need of retrieving
some dynamical information. The whole VO pipeline has been learnt
completely in the work by Wang [105]. The approach proposed exploits
a DL system based on a monocular VO algorithm to estimate poses from
raw RGB images. Since it is trained and deployed in an end-to-end manner,
it infers poses directly from a sequence of raw RGB images without adopt￾ing any module of the conventional VO pipeline. The AI system comprises
the CNN that automatically learns an effective feature representation for the
VO problem, but also a recurrent network, which implicitly models sequen￾tial dynamics and relations. The final output is the absolute pose of the
vehicle. This architecture differs from the one presented in Ref. [103]
because here two consecutive frames are stacked together and only images
are considered as inputs.
A hybrid approach, specifically developed for lunar landing is presented
by Refs. [106,107] and readapted by Refs. [108,109]. The approach is based
on the work by Silburt et al. [110]: a DL approach is used to identify lunar
craters, in particular an Unet-CNN, is used for input images segmentation,
as shown in Fig. 15.49. Some traditional navigation strategies are based on
lunar craters matching; therefore, the AI method is investigated as part of
a hybrid approach, as in Refs. [106,107] where a RANSAC-based nearest
neighbor algorithm is used for matching the detected craters to database
918 Stefano Silvestrini et al.ones. The advantage of such a hybrid approach is to combine a crater detec￾tion more robust to illumination conditions and the reliability of a traditional
pose estimation pipeline. An example of input image and output mask is
shown in Fig. 15.50. This is a powerful technique for absolute navigation
where database objects can be used for learning. The state estimation re￾quires a navigation filter or feature postprocessing, such as computation of
essential matrix, retrieval of relative vectors, to complete the navigation
pipeline.
Figure 15.49 Convolutional neural network architecture, based on Unet [110]. Boxes
represent cross sections of sets of square feature maps.
Figure 15.50 Input image and output mask from the CNN.
Modern Spacecraft GNC 919A qualitative summary of the most promising methods is reported in
Table 15.4: Summary of neural-aided methods for optical navigation for
planetary and lunar landing. IP stands for image processing and represents
the necessity for a hybrid method to be implemented (e.g., matching, PnP).
Deep reinforcement learning for uncooperative objects fly
around and planetary exploration
An active research field is to use reinforcement learning and meta￾reinforcement learning (meta-RL) to create an adaptive guidance and con￾trol system. Deep reinforcement learning has been used to generate auton￾omous guidance and control during proximity operations and landing
trajectories [92,111,112]. Reinforcement learning has been used to generate
autonomous trajectory planning for different scopes. Pesce et al. [113], Pic￾cinin et al. [114], and Chan et al. [115] analyzed the autonomous mapping of
asteroids using DQN, Neural Fitted Q as value-based methods. Federici
et al. [116] proposed an actor-critic PPO framework for real-time optimal
spacecraft guidance during terminal rendezvous maneuvers, in presence of
both operational constraints and stochastic effects, such as an inaccurate
knowledge of the initial spacecraft state and the presence of random in￾flight disturbances.
Brandonisio et al. [111] proposed a guidance and control law to perform
the inspection of an uncooperative spacecraft. Two of the most common
reinforcement learning methods described earlier are used, namely DQN
and A2C methods. State-action value functions are approximated using
ANNs: in particular, simple MLPs are employed. A discrete action space
is maintained, whereas the state space is continuous. Transfer learning
(TL) is also applied to facilitate training on more complex tests. One of
the TL techniques consists of pretraining the RL agent on a simpler task
before training on the main task. In the paper, the various tasks are repre￾sented by increasing complexities of the reward models. Many researchers
claim a superior performance of policy-based methods. Among those,
Table 15.4 Summary of neural-aided methods for optical navigation for planetary
and lunar landing. IP stands for image processing and represents the necessity
for a hybrid method to be implemented (e.g., matching, PnP).
Type Accuracy Training needs Robustness Adaptability
CNN þ IP e Hybrid High Medium High Medium
CNN þ RNN e E2E Medium High High High
920 Stefano Silvestrini et al.PPO and derivatives is one of the most adopted schemes [111,116e118]. To
improve the stability and robustness of the agent in different scenario con￾ditions, a formulation of PPO, but not only, exploiting RNNs is commonly
exploited. As anticipated in Chapter 15 e Modern GNC e AI in space e
Introduction, the capability of recurrent layers to store past states informa￾tion may strongly affect the agent safe trajectories planning and faster getting
to the mission goals. In addition, training an RNN is beneficial to refine the
agent’s environmental conditions sensitivity, which works in favor of the
agent’s robustness, regardless of the specific operational environment. The
work in Ref. [119] proposes a guidance strategy for spacecraft proximity
tracking operations leveraging deep reinforcement learning. In Ref. [119],
the distributed distributional deep deterministic policy gradient (D4PG) al￾gorithm is used. Such algorithm operates in continuous state and action
spaces, and it has a deterministic output. The D4PG algorithm is an exten￾sion of the actor-critic algorithm.
Meta-reinforcement learning
The robustness to uncertain spacecraft model and environment is a crucial
topic in the development of autonomous systems. This aspect is very chal￾lenging when it comes to reinforcement learning methods. Neural networks
learn well within the training distributions, but they generally fail when per￾forming extrapolation outside the training distribution [120]. This may pose
a risk of instability of the guidance law when the spacecraft experiences states
that are outside the training distribution envelope. Several researchers
[117,118,120] claim that sampling inefficiency is another weakness of tradi￾tional reinforcement learning: a large amount of experience is needed to
learn even the simple tasks. In Ref. [121], the authors propose a reinforce￾ment learning framework to control a spacecraft around a small celestial
body with unknown gravity field. In particular, the hovering task is inves￾tigated. The authors perform a direct policy search with a genetic algorithm
to obtain controller policies with high utility. The policy architecture used is
a simple MLP.
Recent advancements on meta-RL have aimed at addressing these
weaknesses of the traditional framework. Reinforcement meta-learning
trains the policy agent on a distribution of environments or MDPs. This
forces the agent to experience and learn multiple, and different, situations.
Consequently, the system tends to converge faster to quasioptimal solutions.
Recent works claim superior performance of the meta-RL with respect
to classical RL when uncertain environments and actuator failures are
Modern Spacecraft GNC 921considered [117,118,120]. Gaudet et al. [117,118] developed a guidance law
based on meta-RL which is able to perform a six degrees-of-freedom mars
landing. Moreover, in Ref. [118], meta-RL is used to create a guidance law
for hovering on irregularly shaped asteroids using light detection and ranging
(LIDAR) sensor data.
In certain works, the different environments are called tasks: the tasks can
be thought of the ensemble of potential situations, nominal and nonnomi￾nal, one can expect the agent to experience. For instance, in the application
of meta-RL for planetary and asteroid landing, the tasks range from landing
with engine failures to large mass variation or highly corrupted navigation
and unknown dynamics.
In Li [122], a meta-RL framework is employed for relative trajectory
planning between spacecraft. The training trajectories are divided as sub￾training samples and fake testing samples. The meta-reinforced agent is
trained by alternating training and testing phases. To this end, the gradient
information of the meta learner is obtained through a combination of the
results on the training subsets and the performance on the fake testing sam￾ples. The authors in Ref. [122] claim that this approach forces the agent to
explicitly take account of the potential testing performance into consider￾ation. In this way, the overfitting phenomenon, potentially arising using
few training trajectories, is reduced.
In most of the works, as for traditional reinforcement learning applica￾tions, meta-RL policy is optimized using PPO, both the policy and value
function implementing recurrent layers in their networks. Using RNNs re￾sults in creating agents that can adapt more easily to uncertain environments,
yielding a much more robust guidance policy compared with classical rein￾forcement learning. If we examine a particular scenario such as planetary
landing, recalling what was described in Chapter 15 e Modern GNC e
AI in space e Introduction, it is easier to understand how recurrent layers
result in an adaptive agent. During the training to generate an autonomous
landing agent, the next observation depends not only on the state and action
but also on the GT agent mass and any external forces acting on the agent at
each step. Consequently, during training, the recurrent layers force their
hidden states to evolve differently depending on the observations acquired
from the environment during the trajectory, which is governed by the ac￾tions output by the policy. Specifically, the trained policy’s hidden state cap￾tures unobserved information such as external forces or agent mass that are
useful in minimizing the cost function. Obviously, this holds for any sce￾nario one could be interested in, even not related to space operations.
922 Stefano Silvestrini et al.AI on-board processors
Modern GNC algorithms, implementing advanced techniques and
exploiting computationally expensive AI-based methods, demand the
development of dedicated avionics solutions. In fact, a standard processor,
being single core, dual-core, or quad-core, will struggle on executions of
neuronal networks with many layers, with large connectivity among layers
and with increasing data vectors being passed from layer to layer. For this
reason, specific AI processing avionics try to boost the utilization of many
processing units in parallel with extensive data utilization and hence with
large access to memory units in the minimum time possible. In general, it
exists an analogy between ML techniques and computer-vision algorithm,
using many convolution filters. For this reason, the selection of the architec￾ture and avionics components for AI can follow a similar approach used for
vision-based navigation solutions.
First, it’s necessary to distinguish between on-ground and on-board plat￾forms. On-ground solutions are used for the training process of the neural
network, and, on the other hand, on-board platforms are used for the AI so￾lution execution. In this way, the AI method guarantees high-performance
and limited power consumption on-board being extensively trained on￾ground, taking advantage of very powerful methodologies that are so
energy-hungry in terms of power consumption that could never be selected
for on-board executions (not even in rovers with nuclear energy source).
Most of the AI solutions on-ground try to exploit the utilization of
GPUs (see Chapter 13 e On-board implementation). In space, the options
for GPUs, with enough environmentally induced failures protection and
reduced power consumptions are very hard to find, but it is interesting to
consider solutions as soft-core GPUs implemented in FPGA for space.
The use of standard GPUs is generally discarded for its use on-board due
to their high-power dissipation, but recent developments (e.g., Nvidia
Tegra X1 GPU SoC) are trying to provide solutions focused on power ef￾ficiency for embedded applications. None of these GPU-based alternatives is
yet accepted for in-flight space applications at the time of writing of this
book.
A very interesting deviation from GPUs, with specific objective for using
it on Vision or AI solutions, is represented by chips based on multiple VPUs
interconnected and combined with LEON processor (e.g., Movidius
Myriad and Myriad2). A VPU is a type of microprocessor designed to pro￾cess visual data and may include interfaces for direct streaming of image
Modern Spacecraft GNC 923sensor data. A VPU is aimed at accelerating IP and CV algorithms. Due to
the efficient vector (parallel) processing architectures and memory layouts
that are required to effectively process image data, VPUs are typically also
suitable for efficiently implementing ML and AI inference tasks. In fact,
the previously mentioned Myriad 2 was designed primarily as a vision pro￾cessing device, with HW support for various IP functions (e.g., Harris, me￾dian and edge filters, up/down scalers), but it also proved to be very effective
at running CNNs (i.e., it was chosen by ESA for deployment as the AI infer￾ence engine on the HyperScout-2 hyperspectral payload, which forms part
of FSat-1 currently in orbit). VPUs are designed to provide ultralow power
capabilities, without compromising performance. In general, VPUs are not
intended to be the primary processor in a system, but to act as an accelerator,
or coprocessor. VPUs are built for parallel processing, and their performance
depends on the fact that visual data come in 2D arrays (at least) and that
vision functions in general exhibit massive data parallelism.
Other alternative solutions are based on FPGA (see Chapter 13 e On￾board implementation) with specific deployment of convolutional engines
in the frame of AI-based IP solutions and interconnections in FPGA logic.
These kernels are suited for FPGA implementation, making use of the hard
blocks of its embedded DSPs, explicitly built for fast mathematics operations.
FPGA offers different advantages over the vastly used GPUs for DL. Both
HW solutions allow the possibility to use many cores or instances of function
to exploit parallelism. GPUs where first conceived for render and display
graphics or video, and for DL deployment might present some limitations.
The FPGA is a blank device, and the HW can be programmed by means
of the configuration of the programmable logic gates, functions, and rout￾ing, and, therefore, it offers a lot of flexibility. It provides excellent perfor￾mances at the advantage of much lower power consumption than GPUs.
Several other functions can also be added, as cryptosecure blocks, or
different communication interfaces, or sensor fusion. The FPGA can imple￾ment protocols and low-level interfaces layers for multiple standards, and,
therefore, it can embed multiple sensors in one-chip interface. Moreover,
it provides the extra capability of implementing in the FPGA logic the pre￾processing or acquisition synchronization and sensor fusion, which facilitates
certain AI applications using multiple inputs from various sensors (e.g., cam￾eras, LIDAR, RADAR, Sun Sensor, or IMU) for the same application.
Similarly, the FPGA can manage different memory units, can devote inter￾nal FPGA blocks for buffering data, and can implement functions to over￾come the I/O bottlenecks problems that might affect AI systems
performances where large amount of data is used.
924 Stefano Silvestrini et al.There are different attempts to create FPGA modules reusable for
different CNN architectures designs or implementation deployment.
Frameworks are being developed to allow an AI engineer to use Python,
C, or Cþþ and typical known AI frameworks at high level to pass to an
automatic process inferring the solution onto the deployment HW board,
for instance, using high-level synthesis tools to create FPGA solutions. Tools
such as Mathworks provide AI framework with a final autocoding steps tar￾geting GPUs or FPGAs. Xilinx, the major FPGA vendor in the world, pro￾vide Delphi Deep Neural Network Development Kit (DNNDK) to help AI
developers on the deployment of their solutions in Xilinx FPGAs using
these DNNDK library.
Few examples are described hereafter. For instance, Xilinx is betting on
heterogeneous HW platforms with dedicated AI engines such as the brand￾new Versal AI cores Series FPGA [123] and the Vitis SW tool [124] to pro￾gram them. Nevertheless, these solutions are not offered for space. FINN
framework [125] is also provided by Xilinx, more generic than Vitis
although only targeting quantized neuronal networks and more as a space
exploration of acceleration possibilities in FPGA for the DNN inference.
Moreover, as presented in Ref. [126], DNNDK is a full-stack DL SDK
for the deep learning processor unit provided now by Xilinx. It provides
a full-stack solution for DL inference application development in a unified
solution for DNN inference applications by providing pruning, quantiza￾tion, compilation, optimization, and runtime support. The framework pro￾vides a complete set of optimized tool chains, including compression,
compilation, and runtime and overcomes one of the high-level program￾mers’ drawbacks by providing a lightweight C/Cþþ programming applica￾tion programming interface (API) to make it simple for users without FPGA
knowledge to develop DL inference applications by providing a set of light￾weight C/Cþþ APIs while abstracting away the nature of underlying
FPGA device.
Innovative techniques for highly autonomous FDIR in
GNC applications
This section presents technical solutions and development processes
for implementing highly autonomous on-board FDIR systems, with a
particular focus on GNC applications. As shown in the Chapter 11 e
FDIR Development Approaches in Space Systems, generally speaking,
FDIR systems act as supervisory controllers and ensure that the mission ob￾jectives and dependability/safety requirements are met, so that spacecraft
Modern Spacecraft GNC 925(S/C) are protected from failures leading to a service deterioration or even
worst to the mission loss [127,128]. The survival of the spacecraft has gener￾ally priority over its service availability. FDIR systems monitor and process
streams of observations in order to detect, isolate, and, if necessary, react to
events and anomalies occurring inside the spacecraft [129].
FDIR system conception, design, implementation, verification, and vali￾dation are very complex tasks [127]. They strongly depend on both system￾level and operational requirements (such as the S/C operational modes and
mission phases [128]). Moreover, there is also a strong connection between
FDIR systems and S/C on-board autonomy, which is becoming the key￾point in the design of future space missions [130,131].
Today’s rapid progress in on-board resources (i.e., memories and
computational power) is actually fostering the transfer of FDIR functions
from the ground to the flight segment, and thus the enhancement of on￾board autonomous failure management capabilities [131,132]. This section
describes innovative approaches and solutions for on-board FDIR systems
that are likely to be implemented within a short/medium term (or at least
industrial efforts and interests driven by the space agencies would prove
this statement [137,138]) in order to address the limitations of currently
used FDIR solutions [127,128] and the needs of future space missions. First,
we discuss the evolution of FDIR systems in the upcoming years and high￾light all the limitations of currently used FDIR systems and the needs of
future space missions. In particular, model-based and data-driven (also called
soft-computing) FDIR systems are introduced. As shown later, they can
provide the capabilities of processing anomalous observations in spite of un￾certainties and partial observability in order to estimate the system health sta￾tus and determine the most appropriate corrective action [135,139e141].
After that, the central part of this section presents advanced FDIR solutions
for GNC applications. More specifically, we address both model-based and
data-driven approaches. The former includes control theory solutions (e.g.,
observer-based methods) to generate residuals for the failure detection and
isolation [139,140]. On the other hand, when no explicit dynamical model
is available, system knowledge boils down to historical and/or real-time data
measurements, which can be used to, e.g., train classifiers with the aim of
assigning newly measured variables to classes representative of healthy or
faulty behaviors [139,141]. AI and ML solutions fall in the data-driven cate￾gory. Finally, we explain the impact of a model-based approach on the
FDIR system development, and then we outline the major challenges for
the actual industrial implementation of model-based and data-driven
FDIR systems.
926 Stefano Silvestrini et al.FDIR system evolution in the next years
FDIR system conception and implementation in a space system can be a
rather complex field, since the analysis of S/C failures can extend to very so￾phisticated considerations. The cause of malfunctions could be one or more
failed components, incorrect control actions, or external disturbances, which
impact system operations [128,142,143]. In complex, heterogeneous sys￾tems with large numbers of interacting physical components, the effects of
faults can propagate through the boundaries of many subsystems and can
result in diverse fault symptoms. FDIR information processing and physical
components are tightly integrated and intertwined; therefore, the structure
and properties of physical S/C components determine the functions to be
implemented by an FDIR system.
The level of complexity of FDIR systems has been addressed by the
space agencies, the industry, and the academia since long time. For instance,
in Ref. [144], we can find a list of findings and recommendations emerged
during a NASA workshop held in 2008. The following topics were mainly
discussed: (i) FDIR system architectures; (ii) FDIR system development
practices, processes, and tools; (iii) FDIR system verification and validation.
During such workshop, there was a general agreement that FDIR systems in
space missions are limited not only by technology but also by a lack of
emphasis in both system engineering and programmatic dimensions.
Current FDIR system development processes and technical solutions
have shown some relevant technological and development limitations. As
for the former, we have to highlight that the lack of proper system-level
development approaches causes serious discontinuities throughout all the
project phases and hampers the process of a stable and consistent FDIR
design [127,144]. In this regard, model-based system engineering (MBSE)
paradigm can be of great help for managing complexity, maintaining consis￾tency, and assuring traceability during the overall FDIR system develop￾ment. MBSE is different from engineering with models. Indeed, MBSE is
a system engineering approach centered on evolving system models (and
not on documents), which serve as the sole source of truth about the system.
It comprises system specification, design, validation, and configuration man￾agement [145]. A central role is played by the FDIR system toolset environ￾ment, which should provide a seamless support throughout the different
FDIR development phases. Tool integration can be facilitated through
work on common terminology/taxonomy, metrics, and interface specifica￾tions. Ideally, such toolset would be available for early behavioral modeling
Modern Spacecraft GNC 927of FDIR systems and would then be used for FDIR design, implementation,
and testing [143,146].
As shown in the Chapter 11 e FDIR Development Approaches in Space
Systems, the Packet Utilization Standard (PUS) [133] addresses the FDIR
operational concepts in current ESA missions and, among other things, pro￾vides a set of services that allows the standardization of the fault management
for ESA missions. Such FDIR PUS services encompass both on-board
monitoring and recovery action capabilities, and thus allow the spacecraft
to react to predefined events and subsequently select a recovery routine
from a given set of options accordingly. The established FDIR principles
constitute a good level of robustness for traditional satellites, are industrially
mastered and established within the development process.
However, such traditional (PUS-based) FDIR systems have important
limitations, especially for upcoming space missions, which demand on￾board high-rich autonomous FDIR capabilities. For instance, the traditional
FDIR solutions are not able to cope with the partial observability of the sys￾tem. In particular, simple diagnostic (threshold-based) routines process
symptoms in isolation, which may result in incorrect diagnoses or contradic￾tory deductions [127,134,135]. One prominent example is the Mars Express
mission: due to a nonresolvable memory failure, it suffered from repeated
safe mode transitions, which resulted in a suspension of science operations
[136].
In general, the following shortcomings of traditional (PUS-based) FDIR
systems can be highlighted [134,147]:
• The PUS services dedicated to the FDIR are generally good at detecting
“single” failures but limited in isolation capabilities and struggling when
multiple faults combine in an even nonforeseen behavior. Even though
different levels of monitoring thresholds and check types can be defined
(e.g., expected-value-checking, limit-checking, and delta-checking), the
overall PUS-based FDIR mechanisms process symptoms in isolations,
which can result in incorrect diagnoses or contradictory deductions.
• They do not exhibit any prediction capabilities, not being able to detect
early deviations from nominal behaviors of S/C components, which may
result in an upcoming failure or a novelty [148].
• Another drawback of PUS-based FDIR mechanisms is the difficulty in
managing failures at system level. This issue is a direct consequence of
their limitation in isolation capabilities.
As per today, the above-mentioned limitations of the current FDIR so￾lutions are partially addressed by tailoring the PUS standard. However,
928 Stefano Silvestrini et al.despite providing the capability of monitoring on-board functions, the
concept is still based on a threshold monitoring mechanism.
In order to cope with all these issues of current FDIR systems and offer
new failure management capabilities to the upcoming space missions, new
directions have to be explored, such as model-based and data-driven (sup￾ported by models, if needed) diagnostics solutions. Unlike current FDIR
systems, they should provide the capabilities of predicting and detecting
anomalies in the behavior of a satellite at unit, subsystem, and system level
and isolating the related root cause. Such solutions can be combined with
industrially consolidated FDIR approaches with the aim of reducing the
number of safe mode events, increasing the S/C operational time, and
limiting the overall operational cost.
In the field of FDIR for space missions, several studies have also been
conducted utilizing both data-driven and model-based methods, see
Refs. [139e141,149]. Even though these studies represent a significant
step toward more robust and autonomous on-board FDIR systems for space
missions, it is relevant that the only actual in-flight study in this domain was
the remote agent experiment aboard Deep Space One [150]. Thus, even if
the studies using model-based and data-driven methods both in the space
sector and in other fields show encouraging results, there is still a lack of un￾derstanding of how these methods can be robustly integrated in on-board
S/C FDIR systems. In Ref. [135], the reasons for such a widening gap be￾tween the advanced scientific FDIR methods being developed by the aca￾demic community and technological solutions demanded by the aerospace
industry are discussed. Major problems can be found in the lack of an effec￾tive development process for maturing on-board implementations of
advanced FDIR systems as well as verification and validation (V&V) aspects.
In the remaining part of this section, we present some approaches of both
model-based and data-driven FDIR systems for GNC applications, and
then we propose a possible development approach for data-driven FDIR
systems. Finally, the major challenges for the industrial implementation of
advanced FDIR systems are discussed.
Model-based methods for implementing FDIR systems in
GNC applications
In literature, as for GNC applications, the fault detection and isolation func￾tionality of FDIR systems is often referred to as fault detection and diagnosis
(FDD), while the recovery functionality can be called either fault-tolerant
control (FTC) or fault-tolerant guidance (FTG), see Refs. [134,135]. FTC
Modern Spacecraft GNC 929functions aim at providing a degraded level of performance in the faulty sit￾uations, while FTG means on board reshaping of the mission objectives in
case of critical faulty conditions.
The basic idea of model-based FDIR consists of using control engineer￾ing approaches for assessing residuals (fault-indicating signals) generated from
the comparison of the system measurements with their estimates. Model￾based FDIR solutions fall into the more general analytical redundancy
approach, which, contrary to the HW redundancy, it is advantageous in
terms of cost and space savings and in dealing with the inherent complexity
of GNC applications [135].
Residual generation uses a model of the system in which the control ac￾tions sent to the actuators and the system/plant outputs as measured by the
sensors are injected to predict the behavior of the system and compare this
prediction to the actual behavior, see Fig. 15.51. This way, it is possible to
calculate quantitative indices of the presence of faults. Such indices are called
residuals. Different methods can be used for the design of the residual gen￾erators. For instance, robust control techniques for estimating the fault sig￾nals are an appealing approach, thanks to their ability to handle model
uncertainties and disturbances [159e161]. The objective of such robust con￾trol techniques is to make the residuals sensitive to one or more faults, while
at the same time making them insensitive to, e.g., uncertain disturbance ef￾fects acting upon the system being monitored [134]. Observer-based ap￾proaches are also one of the most popular among FDI design techniques,
in particular, Luenberger observers for the reconstruction of the state
Figure 15.51 Model-based FDIR system architecture for GNC applications. Derived from
I. Hwang, S. Kim, Y. Kim, C.E. Seah, A survey of fault detection, isolation, and reconfigu￾ration methods, IEEE Transactions on Control Systems Technology 18 (3) (2010) 636e653.
930 Stefano Silvestrini et al.variables under deterministic hypotheses and Kalman filtering for the state
estimation in a stochastic context [162,163].
In fault-free situations, the residuals are normally close to zero. On the
other hand, they deviate from zero after the occurrence of faults to which
they are sensitive. There is also the need for a residual evaluation strategy
to translate the time behavior of a residual into a Boolean decision function.
This usually requires the usage of thresholds or tests of statistical hypotheses.
Any given residual may be sensitive to one or more faults. As a consequence,
a decision logic following residual evaluation can be needed to provide addi￾tional insight into the system behavior, and thus help isolating the fault
[139].
The next step following the design of an FDD system would be the defi￾nition of proper recovery/reconfiguration strategies. The general objective
is firstly to ensure continuous safe operation of the system and secondly to
keep some performance level in fault situations. As shown in Ref. [140],
reconfiguration solutions can be classified into two main categories: multiple
model and adaptive control-based approaches. As for the former, a set of
parallel models is used to formulate the system under normal operating
mode and under various fault conditions. A corresponding controller is
designed for each of these models. Thanks to a proper switching mechanism
and with the support of the FDD, the mode of the system at each time step is
determined and the associated controller is activated. Another common
approach in reconfigurable control is to utilize an adaptive controller
approach, which means updating (or computing new) controller parameters,
following the typical design paradigm of adaptive control.
Fig. 15.52 presents a classification of the various model-based FDIR
techniques, which can be used in the FDIR blocks as shown in
Fig. 15.51. Model-based FDIR systems are much more sensitive and
much more specific than the PUS threshold approaches, e.g., early detection
of anomalous behaviors, fewer false alarms, large benefit in dynamic sce￾narios such as station-keeping maneuvers [141,161]. Moreover, they
combine failure detection and isolation and allow the design of fault￾tolerant systems. However, as shown later, some issues have to be solved
in order to implement model-based techniques on-board spacecraft.
Data-driven techniques for implementing FDIR systems in
GNC applications
When explicit high-fidelity dynamic models are unavailable, data-driven
techniques can be used to implement FDI capabilities in GNC applications.
Modern Spacecraft GNC 931In other words, data-driven methodologies represent one main alternative
to model-based ones for implementing FDIR systems. For instance, space￾craft flight data can be exploited to build regression models (used for failure
detection) and classifiers (used for failure isolation) [127,140].
AI- and ML-based approaches seem to be very suitable to implement
very effective diagnostics capabilities in space applications [139,141,164].
In particular, such techniques can provide the capability of detecting incip￾ient fault, which would enable the definition of preventive actions. As
shown in Ref. [148], symptoms of incipient faults may be observed in the
monitored parameters even when they evolve within their threshold
bounds. Preventive maintenance can be important in view of critical mission
phases, such as S/C rendezvous as well as entry, descent, and landing
operations.
The aging or degradation level of a component can be assessed, and pre￾ventive maintenance can be triggered to increase the level of confidence in
the success of upcoming critical mission phases. The added value of ML
techniques comes from their capability of processing combinations of pa￾rameters. For instance, even though each parameter value is in its nominal
range, their combination can present some anomalous conditions, which
is a symptom of an aging/degradation stage of a specific component.
Autoencoders and RNNs can be used for implementing such advanced
anomaly detection capabilities [166]. Generally speaking, ML algorithms
can deal with multiple parameters at the same time, thereby modeling their
Figure 15.52 Classification of model-based FDIR techniques [140].
932 Stefano Silvestrini et al.joint behavior and patterns. Classification and pattern recognition tech￾niques can be powerful tools for the enhancement of the fault isolation task.
As for the FDI functionality implementation, the following data-driven
approaches/techniques can be adopted: pattern recognition, support vector
machine, ANNs, PCA, and (dynamic) Bayesian networks [141,164]. For
instance:
• ANNs do not use any a priori knowledge about the system domain.
They exploit sample data to discover patterns and relationships hidden
in such data as well as to extract and process relevant features applicable
to the problem at hand. ANNs are mostly used for pattern recognition
(in both time-series and multidimensional data such as images) and for
controlling highly nonlinear systems. An interesting ANN-based FTC
solution applied to a Mars entry vehicle can be found in Ref. [167].
• Bayesian networks can be used to identify the system state based on prior
and likelihood beliefs in a set of system variables. They provide a means
to model uncertainty and partial knowledge in the observation domain.
Dynamic Bayesian networks can express dynamic behavior of a system
over discrete time steps and can be used for designing and implementing
highly autonomous FDIR systems [169].
As far as the recovery functionality is concerned, it should be considered
that this usually requires a deep understanding of the underlying system.
Expert systems can be used to implement such recovery functions [147].
Expert systems are used to emulate the decision-making ability of human
experts. More specifically, knowledge-based expert systems use logical rules
to guide such decision process with the support of effective searching algo￾rithms in order to automate the exploration of the hypothesis space. Deep
reinforcement learning approaches can also be used for GNC applications,
in particular, for learning a policy mapping (both healthy and faulty) states
to actions, see Refs. [87,168].
For more information about the usage of data-driven FDIR approaches,
the reader can refer to different surveys available in the literature [149,165].
Fig. 15.53 shows a possible data-driven based architecture for FDIR systems
in GNC applications and basically highlights how the different FDIR func￾tions in GNC applications can be implemented via data-driven solutions. In
particular, the FDI blocks can be implemented by using both classifiers and
regressors. Classifiers perform the task of predicting a discrete class label. In
particular, classes from labeled datasets can be built and used to train such
classification models, which are then adopted to assign newly (unseen) oper￾ational conditions to classes representative of healthy or faulty behaviors. On
Modern Spacecraft GNC 933the other hand, regression is the task of predicting a continuous quantity.
Regressors are statistical models (trained on the process data) and can be
used for the prediction of upcoming failure conditions [139,148]: they
can use redundancy in the process history to predict the values of variables
and generate residuals by comparing predictions to measured values. The re￾covery function can be implemented via expert systems.
Development workflow for data-driven FDIR systems
In this paragraph, we show a possible development workflow for data￾driven/ML-based FDIR modules in space systems, including GNC applica￾tions. The presented workflow is designed in a way to guarantee the full
harmonization with traditional FDIR system development processes
[127,138].
Fig. 15.54 shows the proposed workflow for developing ML-based
FDIR solutions and integrating them into space systems, considering the
current FDIR system development process and the need of establishing
the above-mentioned data engineering approach. The overall workflow,
named ML-based FDIR workflow, can be based on the union of four
subworkflows:
• ML development subworkflow (step #1, #2, and #3 of Fig. 15.54):
Starting from the raw data, such subworkflow generates as output a
trained ML-based FDIR module, incorporating FDIR functionalities
tailored to, e.g., the specific GNC application.
Figure 15.53 Data-driven system FDIR architecture for GNC applications. Derived from
J. Marzat, H. Piet-Lahanier, F. Damongeot, E. Walter, Model-based fault diagnosis for
aerospace systems: a survey, Journal of Aerospace Engineering 226 (10) (2012) 1329e1360;
I. Hwang, S. Kim, Y. Kim, C.E. Seah, A survey of fault detection, isolation, and reconfigu￾ration methods, IEEE Transactions on Control Systems Technology 18 (3) (2010) 636e653.
934 Stefano Silvestrini et al.• ML deployment workflow (step #3 and #4 of Fig. 15.54): Starting from
the trained ML-based FDIR module, such subworkflow optimizes it and
generates an SW module, named deployed module, suitable to run in
embedded platforms.
• ML testing subworkflow (step #5 and #6 of Fig. 15.54): Starting from
the deployed ML-based FDIR module, such subworkflow verifies and
validates the module on the target platform, after being integrated into
the hosting on-board SW (OBSW). This workflow generates the veri￾fied and validated ML-based FDIR module.
• ML operational subworkflow (step #7 of Fig. 15.54): The verified and
validated ML-based FDIR module is used during the actual S/C oper￾ational phase. Flight data instances can be collected and used to enhance
the FDIR products.
ML-based FDIR approaches rely on data. This means that the same ML
model architecture can be applied to capture system(s)/subsystem(s)
behavior on different missions, provided that it is trained with the specific
representative mission data. Therefore, an ML-based workflow can be
more easily applied and iterated to develop FDIR solutions to address similar
Figure 15.54 Development workflow for ML-based FDIR systems.
Modern Spacecraft GNC 935use cases on different missions. This would enable a higher generalization of
the workflow and scalability of ML-based FDIR solutions.
ML-based FDIR solutions may not be as interpretable as traditional ap￾proaches based on thresholds, especially when DL is applied. However, such
solutions have the advantage that the input data used for training and testing
the models/algorithms are known. This means that it is possible to charac￾terize the performance of the model and its validity domain.
Finally, it is worth highlighting that the achieved performance depends
on the data availability and their representativeness of the faulty conditions
in GNC applications. Data from assembly integration and test (AIT) activ￾ities and from the real spacecraft operations can be used. If high-fidelity sim￾ulators are available [158], additional synthetic datasets can be produced and
adopted for training, validating, and testing ML-based FDIR algorithms.
Challenges and next steps for the industrial implementation
of advanced FDIR systems
Two major obstacles can be identified for the implementation of advanced
FDIR modules in space systems, including GNC applications: the definition
of a proper V&V process and the deployment of model-based/data-driven
FDIR solutions on space qualified computers.
The V&V process definition of both model-based and data-driven FDIR
systems is a topic of paramount importance toward the adoption of such al￾gorithms in space missions, where safety and reliability aspects are strongly
considered [127,147]. Traditional V&V techniques [151,152] do not scale
to on-board high-rich autonomous systems, since optimization and
model-based algorithms are at their core [153]. More specifically, the inad￾equacy of traditional V&V techniques is due to the fact that advanced FDIR
systems are made up of AI/ML algorithms and models describing the
domain on which the reasoning is performed and the engine/framework
for such models to work [154]. Such algorithms and models tend to be
very sensitive to the environment, and one should explore the behavior
of the system over a vast range of plausible conditions in order to demon￾strate their robustness. As a consequence, it becomes necessary to employ
more advanced and emerging V&V techniques, which are largely based
on analytical methods.
The three main approaches toward the deployment of reliable advanced
FDIR systems in space missions are [147]:
• Formal verification. The concept of mathematically proving that an algo￾rithm meets its specification [155,156].
936 Stefano Silvestrini et al.• Runtime verification. The concept of monitoring at run-time the execu￾tion of, e.g., AI/ML algorithms.
• Iterative approach. The concept of accepting the deployment of an algo￾rithm verified with traditional methodologies, and then tuning confi￾dence thresholds (e.g., thresholds for classification problems) over time,
as more knowledge is gained in the operational environment.
The latter approach recalls a V&V philosophy in which the examination
of the FDIR system is performed up to its acceptance review (with accept￾able open risks). Afterward, further periodic V&V examinations can be car￾ried out during the actual operational phase by exploiting flight data
extracted from the S/C telemetry streams.
Both model-based and data-driven FDIR solutions must be integrated
into the OBSW and deployed into S/C on-board computers. In this regard,
two constraints must be taken into account:
• The ECSS SW requirements for the criticality category B must be ful￾filled [152,158].
• Space-grade processor modules are featured by limited processing power
and memory resources [137].
As for terrestrial applications, and in case of ML models, there are
different ways of performing the conversion of such models into deployable
SW source code. For instance, one can use an automatic code generator pro￾vided by many commercial tools to convert a trained neural network into
source code, ready to be compiled and linked to the host application [157].
The development of advanced FDIR systems in space projects (including
GNC applications) has lagged terrestrial applications for several reasons:
space-qualified computers have significantly less processing power than their
terrestrial equivalents, while space reliability requirements are very stringent.
As for ML models, powerful frameworks now exist to design and train
network models as well as automated tools to deploy trained inference
models on a range of HW targets. However, these tools are aimed at terres￾trial HW devices, which are significantly more powerful than the current
generation of radiation hardened space processors, e.g., LEON processor
family, meaning that these tools are not able to target these processors
[137]. In other words, even if the usage of automatic code generator tools
for space projects is important to foster advanced FDIR applications on￾board, such tools must fulfill the ECSS SW standard requirements and
take into account the limitation of the space-grade processor modules (cen￾tral processing unit [CPU] and memory).
Modern Spacecraft GNC 937The analysis reported in Ref. [157] of the available automatic code
generator tools for ML models shows that even if they are suitable for terres￾trial application, they have some relevant issues for their application to space
projects. For instance, as for AI/ML algorithm coding, TensorFlow-Lite has
a library overhead not compatible with the memory capabilities of current
space processor modules, while MatLab C Coder generates Cþþ code,
yet it has significant runtime library dependencies of a size comparable to
TensorFlow-Lite. An interesting solution is offered by the TFMin library
that has been recently developed at the Surrey Space Center, Surrey Univer￾sity. As shown in Ref. [157], TFMin supports the currently used space-grade
processors and allows converting a TensorFlow graph within a Python script
into a Cþþ implementation with only standard library dependencies. This
conversion is done verbatim, so the Cþþ version is mathematically equiv￾alent to the TensorFlow. Unlike the standard Cþþ implementation of
TensorFlow (which is also available), the binaries produced by TFMin do
not have dependencies on large-shared object libraries. TensorFlow opera￾tions are converted into Cþþ by using a dictionary, which can be extended
if necessary. TFMin also computes the memory and CPU metrics of the
deployable SW modules, thus allowing the quick analysis of different
network topologies and the effects of changes to, e.g., the instruction and
data cache sizes.
Small satellites/CubeSats
This section provides a practical outlook on GNC and ADCS subsys￾tems design for nanosatellites. The content is tailored to designers coming
from academia or larger spacecraft. The topics described here represent a
particular declination of the general ones described in Part I and Part II of
the book.
Introduction
The process of miniaturization in the space industry started in the 70s and
soon demonstrated the capability of obtaining satellites able to achieve the
same scientific and technological objectives while reducing mass and cost
at launch. Satellites weighing tons of kilograms were gradually substituted
with S/C below 500 kg (small satellites). In the following decades, this trend
strengthened, confirming the potentiality of very small platforms up to the
cm-scale in space exploration.
938 Stefano Silvestrini et al.Table 15.5 summarizes the clear classification provided by the Nasa Small
Spacecraft Technology Program [170] of the various platforms depending
on their wet mass at launch.
Just in 2019, almost 400 satellites with mass below 600 kg have been
launched, making up 11% of all the mass launched in orbit that year
[171]. However, it is important to mention that more than 60% of all the
small satellites launched since 2012 are CubeSats.
The CubeSats are a particular category of small satellites, made up with
multiple cubic modules of about 10 cm side. They were initially developed
in 1999 by Stanford University and California Polytechnic State University
to perform technology demonstration and scientific research in LEOs. The
idea was to create a simple platform, similar to Sputnik, to be used by grad￾uate students and able to host major subsystems such as batteries, solar panels,
and communication systems [172].
The CubeSat platform was quickly adopted by main institutions around
the world: other universities, companies, and governments started exploiting
this design because it was flexible enough to cover different mission objec￾tives while maintaining a common architecture. In fact, the key to the suc￾cess of these satellites lies in the standardization of the design: precise
specifications are available for the designers to create a CubeSat which is
compatible with most of the deployers. Table 15.6 provides an overview
of the different configurations mostly used nowadays, together with some
figures useful in the design of the ADCS of the CubeSats.
Table 15.5 Small satellites classification.
Category Mass range
Small satellite 500e180 kg
Minisatellite 180e100 kg
Microsatellite 100e10 kg
Nanosatellite 10e1 kg
Picosatellite 1e0.1 kg
Femtosatellite 0.09e0.01 kg
Table 15.6 CubeSat standard form factors.
Form factor Envelope Mass Max inertia (at deployment)
1U 100  100  100 mm 1.33 kg 0.002 kg m2
3U 100  100  340 mm 4 kg 0.042 kg m2
6U XL 226  100  366 mm 12 kg 0.185 kg m2
12U XL 226  226  366 mm 25 kg 0.385 kg m2
Modern Spacecraft GNC 939Since the first launch in 2003, the number of CubeSats launched per year
has exponentially grown, leading to a total of more than 1550 satellites by
mid-2021 (see Fig. 15.55 from Ref. [173]).
Most of the launched CubeSats have a 3U form factor and are employed
for Earth observation and technology demonstration. However, these plat￾forms are proving to be flexible and reliable, while still being cost-effective
and for this reason the trend is expected to be confirmed for the following
years.
Hardware limitations
The main difference which we encounter HW-wise on nanosatellites, with
respect to their larger counterparts, is the widespread use of electronic com￾ponents or even modules/subsystems not originally rated for space use, but
rather for lower standards, such as industrial, automotive, and only some￾times military or aerospace. This is a double-edged sword: on one hand, it
opens up to an immense variety of choice and miniaturized technologies,
while on the other hand, the performance of these devices in the space envi￾ronment is hard to predict and often time-limited.
This section describes the main limitations connected to CubeSat HW,
from miniaturization to size and mass, pointing performance, and thrusters.
Figure 15.55 Trend of launched CubeSats.
940 Stefano Silvestrini et al.The burden of miniaturization
One of the main causes of commercial off-the-shelf (COTS) components
failure in nanosatellites is radiation susceptibility; thermal issues due to
tighter operative ranges or cycling can be an important factor, but they
are easy and overall cheap to predict, test, and mitigatedthe same cannot
be said about radiation; more and more emphasis is being put on this aspect
recently, especially in the view of interplanetary CubeSat missions [170]. It
must be said that this compromise of flying nonrad-hard or in any case
nonspace-rated components has been precisely what enabled the CubeSat
and nanosatellite field, in general, to come into being and flourish as it
did. It would be hard to imagine a faster “miniaturization revolution” in
the space industry which would not thread this path of commercial, non￾qualified electronics.
As of 2022, approaching almost 20 years since the first CubeSat launch, a
significant amount of data has been amassed on the in-orbit behavior of
several of these components and new subsystems, some of which can now
be considered de-facto space-qualified by virtue of their flight heritage.
Therefore, the issue of flying new components is now quite reduced even
in the CubeSat world e although it’s not always easy to recover information
on qualification status or flight heritage for every item.
Even for components with flight heritage, and due primarily to cost and
lead time constraints, nanosatellite manufacturers will very rarely procure
rad-hard options, rather looking into rad-tolerant architectures or just
accepting the relative risk. This often results in spacecraft having a relatively
limited lifetime (in the order of months to a few years) or more generally to
experience performance degradation in orbit, as some subsystems may
accrue damage or experience, in time, uncorrectable faults.
Size and mass limitation
Another factor which contributes to the limited lifetime and/or perfor￾mance of nanosatellite systems is certainly the limited mass and volume
budget, even taking into account the advantages brought by miniaturization.
A first handicap brought by these constraints is the unsuitability of higher
performance or ruggedized components due to their excessive bulk. Some￾times, the state-of-the-art technology for a certain device simply is not or
cannot be miniaturized enough for a sensible nanosatellite application; for
instance, ring laser gyros (RLGs) are not yet available in CubeSat-friendly
formats, and therefore designers usually need to make do with much less￾performant microelectromechanical system (MEMS) rate sensors. Other
Modern Spacecraft GNC 941times, manufacturing quality simply can’t scale well enough with size: a clear
example being represented by reaction wheels. These need very high￾quality bearings and ultraprecise balancing; the smaller the wheel, the higher
the impact of the absolute machining and balancing tolerance limits reach￾able by current technology, and therefore the lower the attainable quality.
Furthermore, smaller wheels require higher rotational speeds, which in
turn accelerate wear and tear of the component. Finally, the smaller the
component, the higher its sensitivity to defects, damages, and contamina￾tion, which can accrue during manufacturing, AIT, launch, and in-orbit
operation.
A second matter to deal with is the concept of redundancy. While Cube￾Sats can and do employ varying degrees of redundancy at component level,
it is quite rare to see significant redundancies at module level and even less at
subsystem level. In general, the trade-off needle tends to swing more toward
lower mass/volume and few fully redundant items. Still, among all the sub￾systems, ADCS can often enjoy a certain degree of resilience, with multiple
sensors and actuators enabling at least a “graceful degradation” if any single
fault is encountered. Nevertheless, important compromises need to be taken
in selecting an architecture, in particular, for what concerns star tracker heads
and reaction wheels.
Having multiple star tracker heads increases sky coverage and the likeli￾hood that at least one head has a clear view of the starfield, unobtruded by
the Earth or solar glare. On the other hand, star tracker heads are among the
bulkiest modules in a CubeSat, especially when accounting for their baffles.
While larger platforms with 3þ heads are not unusual, most nanosatellites
shipping star trackers will have at most two heads, and often just a single one.
Reaction wheels (cfr. Chapter 7 e Actuators) can traditionally be
mounted in four wheels tetrahedron or three wheels orthogonal configura￾tions. The former still allows full three-axis control if one wheel fails and
furthermore allows angular momentum redistribution if all four wheels
are operational. However, this arrangement can be geometrically awkward,
the canted wheels reduce the packing efficiency of the spacecraft and require
a larger volume. Most of the time, this forces the designers to employ smaller
wheels than could otherwise be used in the orthogonal configuration. The
trade-off is therefore often played on the emphasis given to the robustness
and quality of the single wheel versus the resiliency of the whole subsystem.
Both solutions are well represented among commercial platforms.
Finally, it is worth noticing that an additional nonengineering factor can
further exacerbate the described issues: system cost. CubeSats have been
942 Stefano Silvestrini et al.brought forward as low-cost and high-risk platforms to broaden the access to
space, and therefore often these programs run on very tight budgets; this can
easily prevent the employment of highest tier components or redundancy
even in the rare instances in which the envelope constraints would allow it.
Pointing performances
Nanosatellites are often employed in LEO missions which are very dynamic
with respect to attitude control. Most CubeSats need to perform Sun￾pointing phases to maximize their power input, ground tracking during
ground stations passes to enable the use of directive antennas and improve
link budget, local-vertical-local-horizontal (LVLH)-fixed or Earth￾centered inertial (ECI)-fixed attitudes depending on their payload and
mission requirements, and so on, sometimes all in a single orbit. For instance,
this is very much different from a GEO spacecraft, which can mostly adopt a
single attitude for the whole duration of its operational lifetime, and for
which sensor placement can be well optimized by design.
The large field of view taken by the Earth limb in LEO, the extremely
varied attitudes, and the limited number of sensors available in a CubeSat
(especially star tracker heads), all conspire against the consistency of attitude
knowledge and, consequently, pointing performance. Depending on the
vehicle attitudes, HW configurations, and ambient conditions, the actual
performance can be degraded even by two orders of magnitude or more
when conditions are unfavorable, with respect to the ideal case.
Therefore, in missions requiring high pointing precision, matching the
specifications of the attitude determination sensors and filters response to
the requirements is not sufficient to guarantee adequate performance in
orbit. The chance and impact of not having consistent fixes due to Earth
or Sun occlusion or glare need to be carefully evaluated during the design
and verification phase, at the very least computing pointing performances
for daylight and eclipse, and better yet with a full sensor access/visibility
analysis, taking into account the actual orbit and mission attitudes. Note
that the lighting conditions in LEO are time-changing also for Sun￾synchronous orbits (SSOs), so these analyses shall not be restricted to an in￾dividual period, but possibly to be repeated for different times of the year.
Thrusters
The field of nanosatellite propulsion has enjoyed in recent years an
outstanding growth and diversification of available solutions, especially in
the field of electrical propulsion. Mainly due to the favorable power to
Modern Spacecraft GNC 943mass ratio of CubeSats, niche technologies such as field-emission
electric propulsion (FEEP) or radio-frequency thruster (RFT), traditionally
unsuitable for main propulsion in larger spacecraft, are finding fertile ground
for application on nanosatellites [170].
While early CubeSats didn’t usually employ propulsion, and still only a
minority of these spacecraft ship thrusters, the need for this subsystem has
been growing lately, driven in particular by the requirements of commercial
constellations deployment (rephasing, orbit maintenance, etc.) or proximity
operations missions.
Installing a thruster module in a nanosatellite poses a series of challenges
to the ADCS and interfaces design which need not be underestimated:
• The most important criticality is given by parasitic torques. Many pro￾pulsion modules for CubeSats, especially in the case of electric propul￾sion (EP), only offer axial main thrust, with no gimballing or thrust
vectoring ability. This means that any misalignment of the thrust axis
with the center of mass will induce parasitic torques on the spacecraft.
These torques must be absorbed and compensated by the ADCS actua￾tors, e.g., instantaneously by reaction wheels and long-term (possibly
considering also thruster duty cycling) by magnetorquers. Note that due
to the typical mechanical workmanship tolerances in CubeSats, it’s not
unusual to have misalignments in the range of 0.1 mm and of 0.1 de￾grees. To these one must add the uncertainty in the center of mass po￾sition and in the actual thrust axis with respect to the thruster reference
axis. For cold or warm gas systems, in which the generated thrusts are
greater, the effect can be even greater, and unmitigated parasitic torques
can reach values in the mNm range, which can be quite challenging to
compensate.
• Throttleability is not a typical feature of nanosatellite propulsion systems,
for both EP and chemical propulsion. Control algorithms are best
designed assuming no continuous thrust control, but rather ON-OFF
or at best pulse-width modulation (PWM) if the module supports it.
Moreover, many systems require preheating/preconditioning phases
before a firing or might only support firings of a certain maximum
duration due to thermal or other design constraints. These limitations
shall be explored when selecting a thruster and considered in its control
logic.
• Many propulsion modules designed for CubeSats can only be mounted
in specific orientations and accommodations, which can prevent their
application on some form factors. For instance, there’s a large number
944 Stefano Silvestrini et al.of modules which exploit the “tuna can” volumes on the -Z faces e this
is basically an additional volume which protrudes from the basic CubeSat
shape and fits within the dispenser pusher plate springs [176]. While this
is an excellent way to save volume, it is mostly practical for 3U vehicles,
since the tuna can volumes are not centered on the Z axis for 6U or 12U
form factors. While mounting multiple modules in parallel can be a
viable option, thrust imbalances, misalignments, and synchronization
among the various modules must be considered.
COTS components
One of the novel approaches brought to the space industry by CubeSats and
nanosatellites, in general, is the large use of COTS components, often also
coming from different industrial sectors.
The defining feature of a COTS item is that it’s procured “as is,” and not
tailored to the specific application. If coming from a different industrial
sector entirely, it could even not be designed for use in space, with all the
performance and reliability implications which this can entail. However,
this doesn’t mean at all that these components can’t be flight proven, i.e.,
at technology readiness level (TRL) 9. There is plenty of COTS not orig￾inally designed for space which have now flown on several CubeSat mis￾sions, even to the point of becoming a de-facto standard [170]. This
section will strive to provide a set of guidelines to the aspiring CubeSat
manufacturer, component by component, which are equally valuable in
both selecting a COTS component for their application, or in drafting up
the specifications for a custom development.
COTS or custom?
The choice between using COTS or developing and qualifying a custom
subsystem naturally depends on a wide array of factors, such as budget,
schedule, know-how availability, scale of the required production, product
TRL, and so on. Note that most of these factors are purely programmatic,
although there certainly are cases in which this trade-off is driven by the un￾availability of COTS which meet the required performances; this tends to
occur less and less as the subsystems market matures and is more frequent
in more niche or varied applications such as propulsion.
Due to these constraints, universities and very small companies will tend
to rely on readily available (and potentially flight proven) subsystems,
focusing instead on integrating them into a single platform. Larger com￾panies, as they grow, will usually be able to spend some research and
Modern Spacecraft GNC 945development resources into developing their own custom avionics and stan￾dard platform, optimizing their design in order to be able to accommodate a
wide array of payloads. This allows to reduce as much as possible both the
nonrecurrent engineering and the recurrent production costs for all the sub￾sequent missions, besides granting a higher level of control on the supply
chain and the production schedule. Beyond the initial investment, and for
large enough production volumes, the “make versus buy” trade-off inevi￾tably tends more toward the former.
There are, however, several exceptions to these generic remarks, espe￾cially for ADCS/GNC subsystems. Some components, due to the high level
of background technology and know-how involved, are bought as COTS
by most all CubeSat integratorsdthis includes, for instance, GPS receivers
or IMUs. On the other hand, some other components such as magnetor￾quers are easily manufacturable with optimized specifications by any
integrator.
Magnetometers
Magnetometers are among the most widespread sensors used in CubeSats.
The wide availability of cheap and compact IC-size COTS, coming from
all kinds of industrial sectors, makes it especially easy to integrate these sen￾sors into a CubeSat.
Moreover, the information they provide, on the local magnetic field, is
the basis for both the simplest and crudest attitude control systems (pure
magnetic pointing with magnetorquers), as well as the more sophisticated
ADCS, in order to effectively implement magnetic desaturation techniques
and augment the attitude determination filters.
Several technologies exist, from the cheapest but noisiest magnetoresis￾tive sensors up to the higher performing magnetoinductive and fluxgate
magnetometers.
Regardless of the specific technology, the key design parameters to look
for in a magnetometer are quite standard:
• Sensitivity, which determines how precise a sensor can be and therefore
the minimum achievable angular resolution of the measurements.
• Noise characteristics, which includes intrinsic noise floor, nonlinearities,
stability, orthogonality, temperature susceptibility, etc. All of these met￾rics impact on the quality of the measurement and can limit both its ac￾curacy and precision. Besides the information reported in the datasheet,
there is no substitute for a good noise characterization campaign in a
representative installation.
946 Stefano Silvestrini et al.Range is also important, i.e., the sensor needs to not saturate in the Earth
magnetic field (þ/ 1G is enough); however, the vast majority of magne￾tometers suitable for spacecraft use are already designed with geomagnetic
sensing as a target application and are thus typically compliant with this
requirement.
Besides the intrinsic characteristics and ideal performance, however, a
key issue with most magnetometers is the environmental noise which de￾rives by their application within a spacecraft. It’s no coincidence that scien￾tific magnetometers on interplanetary probes are mounted on very long
booms to keep them away from the main bus. Spacecraft, and especially
small- and tight-packed ones (such as CubeSats), are very noisy environ￾ments, due to a plethora of effects, such as hard and soft iron magnetization
of the structure and components, or the fields induced by power buses, cur￾rent loops, and electronic devices.
The following are examples of noise sources which generate a field of
0.1 G (thus on the same order of magnitude as the geomagnetic field in
LEO):
• A wire carrying 1 A current at 2 cm distance.
• A single 0.1 Am2 air-core magnetorquer with a radius of 5 cm, w12 cm
down its axis.
• A single 1 Am2 iron-core rod magnetorquer at w20 cm distance, along
its boresight.
All of these are totally plausible configurations which can be encountered
in a CubeSat.
Not only these sources of noise can be significant but also they are chal￾lenging to filter, having components which are attitude-dependent, time￾dependent, and generally hard to predict.
The set of strategies which can be employed to limit or mitigate this form
of noise is known as magnetic cleanliness; in particular, good practices on
power harnesses (e.g., twisted pairs, low-dipole layout of solar arrays, etc.)
is of paramount importance in CubeSats.
Sun sensors and earth sensors
These classes of sensors are able to detect either the Sun direction or the
Earth limb to a precision typically in the order of 1 degree. They are
employed as coarse attitude sensors, either as backup, or sometimes even
as cheap alternatives, with respect to finer sensors such as star trackers.
Modern Spacecraft GNC 947There is a wide variety of options available for the CubeSat market, both
in terms of individual products, of performance, and of technologies
employed.
• Cosine detectors are very simple devices, which estimate the solar inci￾dence angle based on the cosine-like response of a photocell. More
such sensors on differently oriented surfaces of the spacecraft are required
to fully reconstruct the solar direction angle. Sometimes the power￾generating PV cells themselves can be used to reconstruct solar direc￾tion information with this technique.
• Position-sensitive devices/quadrant detectors instead provide a full
reconstruction of the solar angle, by either shining the sunlight through a
pinhole or slit over an isotropic detector, or by employing special
anisotropic detectors.
• Visible/infrared cameras are based on proper imagers, with a set of optics
and an imaging detector. They can be used both for Sun and Earth detec￾tion. Infrared horizon sensors have the advantage of working both in
sunlight and eclipse.
• Horizon-crossing indicators only provide, as the name tells, a binary
information which changes when the Earth limb crosses their field of
view. They are typically based on pyroelectric sensors or
microbolometers.
Depending on the selected technology and complexity of the sensor,
there is a significant span along the performance versus size/power/cost
spectrum, from quite coarse >1 deg resolution IC-size detectors up to
proper cameras offering 0.1 deg accuracy.
While a good Earth sensor might be an excellent choice, especially for
missions requiring prolonged nadir pointing, the great advantage of using
Sun sensors is that, in contingency situations, they can provide the primary
information required to expose the solar arrays to sunlight and therefore
keep the vehicle charged.
Typically, for this application as a backup or complementary sensor, even
a few degrees of precision are enough (even five degrees of pointing error
only result in <1% of cosine losses on the solar arrays)dit is instead more
important to be able to support a sufficient number of them on the various
faces of the vehicle, so as to possibly always have the knowledge of where
the Sun is, no matter the attitude.
In ingesting the data provided by these sensors, one should pay close
attention to the effect of the Earth albedo, which in LEO can reach a
very significant fraction (same order of magnitude) of the direct solar
radiation.
948 Stefano Silvestrini et al.Another important aspect to consider is the field of view of the detector,
in order to have as much coverage as possible with the fewest sensors. For
multisensor applications, ideally the FOV needs to be wide enough to merge
with the ones mounted on different faces, in order not to create “blind
spots.”
Star trackers
Among the subsystems covered in this section, star trackers are certainly
among the most sophisticated and expensive. They are, however, basically
the only available sensor option which enables subdegree pointing accuracy.
Good quality star trackers can provide attitude knowledge down to a few
arcseconds, even on CubeSats.
Star tracker design is dominated by delicate technical trade-offs; the
objective is to have a compact visible imager which can consistently and
accurately image, detect, and identify stars in its field of view, in a sufficient
number to generate an attitude estimation.
Technological constraints on the detector sensitivity and noise character￾istic, practical requirements on the exposure time, and the minimum star
magnitude which needs to be captured, all play together to impose a lower
bound on the minimum geometrical aperture that the optics can have.
While this limit is certainly fuzzy, it’s rare to see star trackers with an aperture
much smaller than a couple of centimeters. While this is not particularly
large even for a CubeSat, one needs to also consider the size of the baffle,
which is of paramount importance to cut out sunlight and earthshine stray
light, and often has a volume comparable, if not greater, to the star camera
itself. In the end, there’s a definite trade-off between the volume dedicated
to these sensors and their performance, in particular, in terms of exclusion
angles.
The key performance metrics of a star tracker are:
• Accuracy that should be expressed in arcseconds at least across-boresight
and about-boresight (the two figures are typically even one order of
magnitude apart).
• Field of view, which goes hand in hand with sensitivity (minimum star
magnitude detectable). These two parameters dictate the probability of
having enough stars in a single frame to generate a solution. One of
the solutions to the size issue of star trackers could be to limit the search
to the brightest stars, and thus ship a smaller optics; however, this requires
a larger FOV and increases the probability of having the Sun or the Earth
in it. For this reason, most manufacturers settle on FOVs in the 10e
20 degrees range [170], and image stars down to the sixth magnitude.
Modern Spacecraft GNC 949• Exclusion angles with the Sun, Moon, and Earth limb. This is the min￾imum angle from the boresight that these objects must have in order not
to introduce excessive stray light (and thus make an attitude solution
impossible). This is mostly a function of the baffle geometry, and there’s
a definite trade-off between smaller baffles and better exclusion angles.
On the matter of exclusion angles, this fits into the broader topic of star
tracker access, i.e., the amount of time over an orbit in which the star
trackers can achieve a solution. The GNC designer shall do well to perform
a visibility analysis, taking into account the evolution of the mission atti￾tudes, the placement of the star trackers on the vehicle, and the exclusion
angles, to determine whether the star trackers will be able to perform as ex￾pected, and how long the “blackout” periods in which no solution is
possible might be. Note that while the Sun usually mandates the largest
exclusion angle, it’s still basically a point source; CubeSats are most often
employed in LEO, where the Earth limb will carve away more than 30%
of the celestial sphere at any time, even before considering any exclusion
angle. So, star tracker access might be even more sensitive to Earth exclusion
angles than to the Sun ones.
Star trackers can also be quite sensitive to temperaturedwhile the elec￾tronics may be rated to operative temperatures well in the 80C range, the
exponential increase in thermal noise on the detector can impair its ability to
detect faint stars at much lower temperature. It’s always important to always
obtain from the manufacturer the operative temperature range at which the
star tracker can still achieve attitude fixes.
Inertial sensors
CubeSats ship a wide array of inertial sensors, from pure gyro packages to
full-fledged 6-DOF IMUs. Due to the very specialized nature of these com￾ponents, they’re almost invariably procured as COTS. Focusing on gyro￾scopes, which are by far the most used sensors, there are two main
technologies available: fiber-optic gyros and MEMSs e the former offering
higher performance, the latter higher miniaturization and lower cost. The
miniaturization of even more sophisticated technologies, such as RLGs, is
unfortunately not advanced enough to allow their application on CubeSats
[174].
Star trackers can have blackout periods due to exclusion angle violations,
and, in general, provide lower frequency attitude information. It can very
well be, therefore, that a CubeSat attitude knowledge performance is not
really limited by the star tracker, but by the IMU/Gyro package. An
950 Stefano Silvestrini et al.arcsecond-level ST fix at 1 Hz, with occasional minute-long blackouts,
won’t do much good if the gyroscopes precision and bias stability can’t
maintain that level of accuracy in between fixes.
The key design parameters to look for in an IMU are (cfr. Chapter 6 e
Sensors):
• Random walk noise: It is strictly related to the single-measurement pre￾cision of the device and is the limiting factor on shorter timescales (e.g.,
in-between consecutive ST fixes).
• Bias instability: It is related with the amount the intrinsic sensor bias drifts
over a given period; this ultimately limits the accuracy of the measure￾ment over longer timescales, whenever no external measurements can
contribute to estimate the bias (e.g., during an ST blackout).
• Temperature sensitivity: It is related with the amount the sensor perfor￾mance figures degrade or vary with temperature. This effect can be
particularly severe for MEMS devices and must be taken into account
for CubeSat applications, in which the LEO sunlight/eclipse cycle is
very likely to induce appreciable cyclical temperature fluctuations in
the avionics.
On the matter of accelerometers, these are naturally only really required
in case of on-board propulsion. A good sensitivity is required to measure the
tiny accelerations imparted by CubeSat propulsion systems. Warm and cold
gas systems will generate accelerations in the 105 to 103 g range, which
may or may not be detectable with sufficient resolution by a MEMS accel￾erometer, depending on the model, while EP systems, generating down to
106 or 107 g will most likely be undetectable by direct measurement, and
indirect methods on longer timescales, e.g., from GNSS position fixes,
might be required to close the loop.
A final word must be spent on potential issues stemming from helium
susceptibility in MEMS [175,176]. Some MEMS devices can be either
temporarily disabled or have their biases disproportionately amplified
beyond standard specs, if exposed to sufficient concentrations of helium.
It is believed that the helium, given its very small atomic radius, is able to
diffuse into the device cavities (which are usually under vacuum) and inter￾fere with the MEMS oscillator movement [175,176]. A CubeSat might be
subject to an appreciable concentration of helium when inside the launch
vehicle fairing, as some launch campaigns require helium purges or pressur￾izations of the fairing volume. Fortunately, the effect is usually reversible
once the vehicle is exposed to vacuum, though over a timescale which
can be in the order of days.
Modern Spacecraft GNC 951GNSS receivers
This is yet another class of very specialized items for which procuring COTS
receivers is almost a must. Fortunately, power and size are now miniaturized
enough for the available industrial solutions that the technology is already
“CubeSat-ready” in terms of these specs. There are a few widely adopted
solutions in the market which have accumulated very significant space
heritage.
A trade-off which the designer might have to face is the selection of
which GNSS systems and bands to support, spanning from just GPS L1
up to the whole suite of GPS, GLONASS, Galileo, BeiDou, etc. This is
basically a trade-off between component cost and availability of visible sat￾ellites in orbit. With a good antenna, even the lower end of this spectrum
typically provides more than enough visibility in orbit to get consistent fixes.
Note that GPS receivers are subject to the COCOM limits, which nor￾mally prevent their use above speeds of 600 m/s [177]; this would result in a
very unpleasant surprise, manifesting itself only once in orbit. It’s therefore
of paramount importance to apply for the proper licensing which allows to
buy and use receivers without COCOM limitation.
Finally, an extra practical recommendation is to pair the GNSS receiver
with a high-quality GNSS antenna (they come with an integrated low-noise
amplifier) and to mount said antenna on a good ground plane, with good
visibility to space considering the mission attitudes; remember that GNSS
signals are very low intensity signals, practically buried in the noise floor,
and any receiver system is therefore extra susceptible to electromagnetic
interference issues or link budget degradation.
An argument could be made on the need, in general, for a GNSS
receiver on a CubeSat, given the availability of TLEs. These constitute
another good quality absolute position information source, and furthermore
they are free. The error given by TLEs is typically well below 103 m, and
although this is one to two orders of magnitude worse than that provided
by a GNSS receiver, the APE component it introduces in pointing tasks
won’t usually impact more than 0.1 deg for ground tracking and even less
for LVLH attitudes. The RPE components will similarly be quite small,
given that the TLE error is slow varying along an orbit. Except for missions
with propulsion, or particularly stringent pointing or position knowledge re￾quirements, TLEs will therefore provide sufficient precision.
The use of TLEs, however, comes with two quite significant caveats:
• The first, and most obvious, is the need to constantly update this knowl￾edge on-board through uplinks and to propagate on-board the last
known TLE via a SGP4 propagator. If the TLEs are not updated from
ground, the position knowledge will inevitably drift.
952 Stefano Silvestrini et al.• The second issue pertains to LEOP. Rideshare launches are becoming
more and more prevalent, with tens if not hundreds of different vehicles
deployed on the same orbit, and they’re typically a cheap launch oppor￾tunity for CubeSats. However, this makes it harder and harder to distin￾guish just which TLE is the one belonging to one’s CubeSat among all
the objects released in that particular launch. Without an on-board
GNSS receiver to provide an independent fix against which to verify
all published TLEs, all one can do is wait for the natural separation and
follow a tedious process of elimination, for instance, by tracking the
different objects with ground stations and checking which TLE best
matches the Doppler shift of the RF signal. Until then, one can expect to
get very poor RF links with the spacecraft.
These reasons alone might well induce the designer to include a GNSS
receiver even when it wouldn’t be strictly required by position knowledge
requirements.
Reaction wheels
The technology behind reaction wheels is deceptively plain: they are not
much more than brushless direct current (BLDC) motors with a high inertia
rotor, controlled either in speed or torque (or both). However, even in
larger spacecraft, reaction wheels are very delicate components, which pre￾sent a large variety of possible failure modes, and require particular care in
their design, manufacturing, testing, and handling. Most of the issues associ￾ated with reaction wheels are due to the fact that they necessarily host mov￾ing partsdand specifically, fast-moving parts. In a CubeSat, the reaction
wheels will very easily be the only moving parts in the vehicle, besides
one-shot deployment mechanisms.
Not all CubeSat missions require reaction wheels, though virtually all
modern commercial platforms use them. If they are required, it is very high￾ly recommended to select high TRL, robust, and well-qualified reaction
wheels.
The main design parameters when selecting a set of reaction wheels are
just two (cfr. Chapter 7 e Actuators):
• Momentum capacity. It fundamentally drives the maximum slew rate
attainable by the spacecraft and the maximum storable momentum
induced from external torques before saturation (and mandatory
offloading).
Modern Spacecraft GNC 953• Peak torque. It drives the maximum angular acceleration and must be
considered in combination with thrusters and other actuators, as well
as control requirements, to guarantee sufficient control authority.
For most missions, the momentum capacity will be the most critical
figure. Disregarding special agility applications, the most demanding of
the standard slew maneuvers which a spacecraft can perform in LEO is typi￾cally ground-tracking, for instance, to point a directional antenna toward a
ground station. Considering a worst-case orbital altitude of 300 km, which is
the lowest a CubeSat can expect to be operational at for any significant
amount of time, the maximum required slew rate is about 1.5 deg/s (for a
90 elevation pass). Using a 2x or 3x margin factor, it is therefore typically
acceptable to aim at 3e5 deg/s maximum slew rate on any single axis. The
resulting momentum requirement will depend naturally on the spacecraft
moments of inertia: a small 1U (if it needs wheels at all) can accept much
less than 1 mNms, while 3U and 6U CubeSat are typically satisfied with
wheels in the 5 to 10 mNms class; 12U with large deployables might
need up to 50 mNms to attain full agility.
Most CubeSat-size COTS reaction wheels indeed cover this range, with
products spread along the spectrum from 2 to 100 mNms, at maximum
rotor speeds of a few thousand RPMs.
As mentioned, peak torque is typically not the limiting factor in selecting
a reaction wheel, and most CubeSat COTS attain 1 to 20 mNm. For most
CubeSat wheels, the ratio between momentum capacity and peak torque is
in the ballpark of 10 s, which is therefore also the characteristic timescale for
a full spin-up from stationary to saturation. Note that, due to the torque
characteristic of BLDCs, the actual motor torque will tend to decrease lin￾early with the wheel speed, so that peak torque is only achieved at low
speeds.
Other secondary reaction wheel specs which can be relevant to the sys￾tem design are the rotor static/dynamic unbalance, and consequently jitter
performance. This is especially important for applications requiring high sta￾bility, such as long exposure, or narrow FOV imaging.
Finally, of course, one should select a wheel with good power efficiency,
acceptable mass and envelope, and, above all, adequate lifetime qualification.
As already mentioned, reaction wheels are prone to various failure modes
and shall be considered as one of the critical/limiting items when assessing
the design lifetime of a CubeSat. We present here a concise, though not
exhaustive, list of the main pitfalls and criticalities which designers need to
know about when dealing with these components:
954 Stefano Silvestrini et al.• Balancing. As said, balancing is very important when assessing jitter. More
in general, though, the balancing of a reaction wheel also determines to
an extent the level of stress and wear on its axle and bearings, and there￾fore its lifetime. Balancing a CubeSat reaction wheel rotor is a very
specialized process and requires attaining very tight tolerances, given
the size of the parts involved. A wheel with a flatter form factor, thus
with a higher inertia rotor, might be more efficient in achieving high
momentum storage at moderate wheel speeds and rotor masses, but it
will be harder to balance and keep in alignment, given the shorter
axle. On the contrary, taller rotors can be supported and balanced
more easily, but it will be less mass- and energy-efficient.
• Zero-crossing. Commanding a reaction wheel at very low speeds is gener￾ally undesirable due to a number of reasons, from increased jitter, stress,
and nonlinearities due to stiction, to higher currents given the reduced
counter-electromotive force, and even to singularities in certain BLDC
controllers exploiting back EMF. For this reason, wheel speed control
algorithms should strive to minimize the number of zero-crossing events.
It is, for instance, a good practice to set deadbands on the desaturation
control, in order not to bring the wheels speed excessively toward zero
and force a lot of zero-crossing events to occur.
• Inductive kickback/recirculation. Switching the windings of the BLDCs on
and off will naturally cause inductive kickbacks, as the current in the
windings can’t change instantaneously due to their inductance, and the
counter-electromotive force can itself induce voltages in the coils.
Virtually all BLDC controllers nowadays make use of flyback diodes and
resistors to dissipate these currents or to induce braking torques when
required, so this issue is typically not of particular concern for the COTS
user. Some designs can also support regenerative braking, i.e., converting
the flywheel mechanical energy into electrical energy which is pushed
back into the supply lines. While this could be in principle beneficial for
the power budget, it would need to be supported by the EPS, since not
all buses can support generator loads; actually, most battery-based
CubeSat EPS are ill-equipped to support such functionality and using
regenerative braking could generate undesirably high voltages and noise
on the main bus, and potentially even damage other subsystems. One
should therefore pay extra care in matching the EPS capabilities with the
reaction wheels control circuitry requirements.
Modern Spacecraft GNC 955Magnetic torquers
More than any other subsystem presented in this section, magnetic torquers
are the ones for which even a first-time CubeSat manufacturer might look
into the option of producing them in house. While there are, of course, a
large number of commercially available magnetorquers from various Cube￾Sat and subsystems manufacturers, built and tested to high quality standards,
they are essentially nothing more than simple solenoids, there’s really no “se￾cret sauce” to them. Buying a COTS version can surely save time and
manpower but will typically not save cost.
There are mainly three kinds of magnetorquers:
• Vacuum core. They are typically solenoids with a large (and mostly empty)
cross-sectional area and short lengthdthey are the easiest to design and
assemble, though they offer a lower performance density (in terms of
volume, mass, and power). Among their advantages they offer a simpler
control, being their output moment quite linear with the supplied
current, and while bulky they can often fit around other components or
be run along the edges of the structure. They tend to be used on smaller
form factor CubeSats.
• Printed circuit board (PCB)-embedded torquers. They are sets of spiral traces
embedded into the vehicle PCBs and acting as planar solenoids. They
offer the lowest profile and even the possibility to integrate them in
the internal layers of solar panel PCBAs. Due to intrinsic limitations
given by the number of PCB layers and the trace resistance, they can
offer only very limited authority and are therefore usually not seen in de￾signs larger than a 1U.
• Ferromagnetic core torquers. They are rod-shaped solenoids wound around a
cylindrical core of soft ferromagnetic material, which significantly boosts
the generated magnetic moment. The drawback is a slightly more
complex control, in order to keep the residual magnetization of the core
monitored. Given their highest performance density with respect to the
other designs, they have become the de-facto standard for most com￾mercial magnetorquers. COTS are available from 0.1 Am2 up to even
50 Am2 and beyond (for micro- and mini-platforms).
Magnetorquers have a single main design parameter, which is the mag￾netic moment they can generate, measured in Am2
. As secondary parame￾ters, the designer should take care to match their electrical requirements to
the EPS/magnetorquer driver design, since they require a minimum supply
voltage to reach the design magnetic moment, and they shall be typically
piloted in current.
956 Stefano Silvestrini et al.For detumbling and desaturation tasks, the required control authority for
a magnetorquer is constrained on its lower bound by the maximum allowed
detumbling time and the maximum expected external disturbance torque.
In the former case, the allowed detumbling time is limited by the avail￾able time from separation before the spacecraft needs to achieve a stable
attitudede.g., Sun pointing; for CubeSats, ideally the spacecraft should
be able to be power positive even when tumbling, so more often than
not the detumbling time is fixed at a more arbitrary/practical threshold,
which can be in the order of a few tens of minutes to few hours for higher
performance CubeSats, and a few days for lower performance ones (e.g.,
educational 1Us). A target value in the ballpark of 104 seconds is an accept￾able starting point, though aiming at something closer to 103 seconds, if the
power allows it, is preferable. The other figures one needs to calculate the
required control authority are the CubeSat moment of inertia and the tum￾bling rate at deployment. While the former can be easily derived from design
information, the latter depends on several factors, such as the deployment
method, the CubeSat form factor, the distance between the geometric cen￾ter and center of mass, the dispenser tolerances, the launch vehicle condi￾tions at deployment, etc. Deployment from a dispenser can typically
induce tumble rates of less than 1 deg/s to 10 deg/s, while hand deployment
by astronauts and cosmonauts from the ISS have been shown to induce rates
even in excess of 200 deg/s [178] e although this is somewhat of an edge
case.
Now, the characteristic time of the detumbling phase can be easily
shown by dimensional analysis to be proportional to the following:
sw kIuk
km  Bk
w kIuk
kmkkBk
where the numerator terms are the tensor of inertia and the angular velocity,
while the denominator terms are the magnetic moment and the geomag￾netic field.
This proportionality is valid up to a constant term including the orbit
averaging of the magnetic field value, the variations and cosine losses of
the magnetorquer effect, and the efficacy of the detumbling algorithm
employed (cfr. Chapter 10 e Control and Chapter 14 e Applicative
GNC Cases and Examples). An intuition for this formula is that the numer￾ator is the angular momentum to dump, while the denominator is an esti￾mate of the maximum torque which can be generated at any time; a
good detumbling algorithm will achieve an average torque not much smaller
Modern Spacecraft GNC 957than thisdmaybe 50% of it when averaging over the orbit, but surely within
the same order of magnitude.
Let’s assume reference CubeSats moment of inertia figures from
Table 15.6 and a reference value of 10 deg/s initial tumble rate. Let’s
furthermore assume a conservative 200 mG reference magnetic field value
(typical low bound in LEOd[179]). With 1 h target detumbling time,
we can calculate the ballpark magnetic moment required, reported in
Table 15.7:
Moving on to the maximum external disturbance torque, this is the ef￾fect which needs to be counteracted by the torquers to allow for reaction
wheels desaturation. Estimating the sources of this torque can be tricky
and is in general very dependent on the specific CubeSat form factor, archi￾tecture, and design. Short of a detailed torque budget, however, some ball￾park estimates can still be achieved, assuming worst-case figures. The main
contributions are:
• Magnetic, from the residual dipole of the spacecraft, and its varying com￾ponents due to power lines, harness, and solar arrays; this is effectively a
“noise” which needs to be added to the magnetorquers effect. Magnetic
cleanliness practices can be employed to minimize this noise, including
degaussing, using twisted pairs in power harnessing, avoiding current
loops in the boards layout, avoiding the use of ferromagnetic materials,
etc. [180]. Still, a residual dipole in the ballpark of 102 A m2 (inducing
up to 106 Nm) would not be unusual. In this sense, for instance, sizing
the magnetorquers for a 1U just based on the detumbling requirement
presented previously could result in undersized torquers and an excessive
residual dipole versus magnetorquer moment ratio.
• Aerodynamic, from asymmetrical effects of thermospheric drag in LEO.
This is highly dependent not only on the CubeSat geometry but also on
its orbital altitude and current solar cycle activity. It can be as low as
1010 Nm for small symmetrical CubeSat at high altitudes in periods
of solar minimum, as well as up to 105 Nm for large CubeSats with
extensive deployable appendages at ISS altitudes during solar maximum.
Table 15.7 Estimate of magnetic moment for CubeSat detumbling.
Form factor Required magnetic moment for detumbling
1U 0.005 A m2
3U 0.10 A m2
6U XL 0.45 A m2
12U XL 0.94 A m2
958 Stefano Silvestrini et al.• Radiative, given by the effects of absorbed and reflected incoming radi￾ation, as well as emitted thermal radiation, and dependent on the space￾craft geometry and variation of surface optical coefficients. This is
typically significant only for CubeSats with deployable arrays, whenever
large asymmetrical sections of these are shadowed and would still be well
below 106 Nm.
• Gravitational, given by the effect of the gravity gradient. Except for
CubeSats with very large deployable solar arrays, this contribution will
always be well below 106 Nm, with more typical values around 107
Nm.
The available magnetic moment should be at least one order of magni￾tude greater than the RMS of the disturbance torques, assuming worst-case
magnetic field intensity (200 mG in LEO) [179]:
m > 10 ktdistk
kBmink
In general, for smaller vehicles, the uncertainty on the residual dipole will
be the limiting factor for determining the minimum magnetorquer author￾ity, while for larger vehicles, the detumbling torque is already more than
enough to also overcome any disturbance torque (Table 15.8).
On the subject of piloting the torquers, a simple bangebang control with
a central deadband usually grants sufficient performance for most applica￾tions, i.e., detumbling and wheel desaturation, which have loose actuation
accuracy requirements and slow dynamics (even in the order of 102
or
103 seconds), see Chapter 10 e Control. The designer shall take into ac￾count that using current modulation schemes can introduce switching losses
(for PWM or pulse-density modulation) or regulation losses (for linear cur￾rent regulation from a constant voltage source), which in naive implemen￾tations could even offset the increased efficiency provided by more
sophisticated control laws. Unless magnetic actuation is used as the primary
attitude control source, or in other special cases in which more accurate
Table 15.8 Recommended magnetorquer for standard CubeSats.
Form factor Recommended magnetorquer
1U 0.10 A m2 (2 uNm)
3U 0.10 A m2 (2 uNm)
6U XL 0.50 A m2 (10 uNm)
12U XL 1.00 A m2 (20 uNm)
Modern Spacecraft GNC 959magnetic pointing/control requirements are present, the improvement in
performance introduced by modulating the current in the rods may not
be worth the added complexity; simplicity and robustness are typically
preferred features when dealing with magnetorquers. This is not to say
that more sophisticated control laws can’t be implemented effectively, but
rather that satisfactory results can already be achieved with the simplest
approach.
On the other hand, it is important to foresee at least some amount of pe￾riodic switching of the magnetorquers, in particular, to avoid disturbing the
already noisy magnetometers measurements. It is, therefore, a common
practice to periodically alternate between a magnetorquer actuation win￾dow, in which the required magnetorquers can be powered, and then a
magnetometer measurement window, in which all magnetorquers are
depowered and the magnetometers are sampled. The selection of the period
and duration of these windows needs to maximize magnetorquers duty cy￾cle, while also allowing for enough time to perform and average the
required measurements, and at a sufficient rate to capture the highest fre￾quency magnetic field variation which one expects to see (driven chiefly
by the maximum expected tumble rate).
GNC system example
This section aims at giving to the reader an example of a possible CubeSats
GNC architecture stemming from the suggestions provided above in this
chapter. In particular, it will focus on the specific case of the ADCS of a
LEO CubeSat. Starting from a list of high-level specifications, the overall ar￾chitecture of the GNC subsystem will be presented, providing some details
on the accommodation and on the various figures related to the different
sensors and actuators selected for the spacecraft.
It is important to mention that this section will not provide details on the
verification of the high-level requirements used to derive the architecture.
However, as thoroughly discussed in Chapter 12 e GNC Verification
and Validation, the aspiring CubeSat manufacturer shall always verify each
requirement with the correct method and so ensure the suitability of the
selected design with the mission.
Table 15.9 reports the specifications/requirements of the example Cube￾Sat applicable to the ADCS.
Considering all the various requirements applicable to the ADCS, a pre￾liminary architecture of the CubeSat ADCS can be derived.
960 Stefano Silvestrini et al.Table 15.9 Specifications and requirements of the example CubeSat applicable to
the ADCS.
ID Requirement
EXP-REQ-1 The CubeSat shall be compliant with the standard 3U form factor
EXP-REQ-2 The payload boresight shall be directed as ZP axis on the CubeSat
body-fixed reference frame (see Fig. 15.56)
EXP-REQ-3 The solar panels main direction shall be directed as YP axis on the
CubeSat body-fixed reference frame (see Fig. 15.56)
EXP-REQ-4 The S-band antenna boresight shall be directed as YM axis on the
CubeSat body-fixed reference frame (see Fig. 15.56)
EXP-REQ-5 The CubeSat shall be able to autonomously perform detumbling
in less than 1 h starting from an angular rate initial condition of
5 deg/s
EXP-REQ-6 While in Sun pointing, the ADCS shall be able to maintain the
absolute pointing error of the orthogonal vector of the solar
array with respect to the Sun-S/C vector lower than 5 deg
with 99.7% probability at 90% confidence level
EXP-REQ-7 During payload operations, the ADCS shall be able to maintain
the absolute pointing error of the payload boresight vector
with respect to the nadir vector lower than 1 deg with 99.7%
probability at 90% confidence level
EXP-REQ-8 During payload operations, the ADCS shall be able to guarantee a
relative pointing error of the payload boresight vector below
0.1 deg over 100 ms time window with 99.7% probability at
90% confidence level
EXP-REQ-9 During communication windows, the ADCS shall be able to
maintain the absolute pointing error of the S-band antenna
boresight vector with respect to the ground station-S/C vector
lower than 2 deg with 99.7% probability at 90% confidence
level
EXP-REQ-10 The CubeSat shall be designed to operate in a Sun-synchronous
orbit with altitude of 550 km and LTDN of 10:30
Figure 15.56 Example CubeSat architecture constraints.
Modern Spacecraft GNC 961Here it follows a list of useful components on-board the spacecraft in or￾der to satisfy the various requirements:
• An IMU is needed on-board the CubeSat to measure the body rates of
the vehicle at the deploy as well as during nominal mission.
• At least three reaction wheels are needed to perform three-axis stabilized
attitude control during nominal mission and spacecraft detumbling.
• A set of magnetometers can be exploited to obtain a rough estimate of
the attitude of the vehicle. This could serve as the main source of attitude
determination during degraded states (contingency modes) or can be
used in conjunction with more precise sensors during nominal mission.
• At least three magnetorquers are needed to perform RWs desaturation.
Moreover, they could be used to perform attitude control during
degraded states (contingency modes).
• A set of Sun sensors are useful to obtain a rough estimate of the relative
position of the Sun in the body frame. This could serve as the main atti￾tude determination sensor during degraded states (contingency modes)
or can be used in conjunction with more precise sensors during nominal
mission.
• More precise attitude sensors such as star trackers or horizon sensors are
needed in order to fulfill the pointing requirements of the mission.
• A GNSS receiver module needs to be mounted on the spacecraft to have
inertial position and velocity knowledge, useful in all the pointing modes
related with PL and S-band operations.
• Finally, a dedicated PCBA able to interface with all the various sensors
and actuators is needed, together with a processor running the ADCS al￾gorithms. This could be the same processor used for the on-board data
handling or, in some cases, a dedicated piece of HW for specific and
demanding applications.
The technology of the sensors/actuators, the number of modules and
their accommodation need to be optimized considering various factors:
• The mass budget of the vehicle.
• The power budget of the spacecraft.
• The various pointing constraints and accommodation constraint of the
different components versus the available surface of the spacecraft.
• The thermal analysis and the operative/nonoperative temperature ranges
of the components.
• The operative ranges of the different modules with respect to the pre￾dicted mission scenario.
• The available budget of the mission.
962 Stefano Silvestrini et al.The diagram in Fig. 15.57 reports a possible architecture for the ADCS
of the LEO 3U CubeSat under consideration. It is important to mention
that this is not the only one possible architecture, and the reader should
only consider it as a guideline. However, due to the standardization of the
CubeSat platform and the level of maturity of technology exploited, the so￾lution proposed will not deviate much from the possible alternatives.
Inertial measurement unit
The selected IMU is based on three-axes gyro MEMS, for a very miniatur￾ized module. It is usually mounted in the central part of the vehicle, paying
attention to its alignment with the body axes. Below are some reference
figures:
• Range: 400/s.
• Bias instability: 0.3/h.
• Angular random walk: 0.15/h^0.5.
• Bias error over temperature: 9/h.
Sun sensors
Being a secondary sensor used for contingency scenarios, full coverage is
preferred with respect to resolution. In fact, six photodiode-based Sun sen￾sors are considered for the CubeSat. They are very small in size so to be
placed on each external face of the vehicle. In this way, it is always possible
to completely reconstruct the information of the relative position of the Sun
with respect to the body frame. It is important to pay attention to the orien￾tation of the sensor with respect to the body frame as well as to not mount
them in shadowed areas.
Figure 15.57 CubeSat ADCS architecture example.
Modern Spacecraft GNC 963Hereunder, the main figures related to the selected Sun sensors:
• Range: 75.
• Resolution: 2.7.
Magnetometers
The LEO CubeSat under consideration is also equipped with six three-axes
magnetometers needed for the reconstruction of the Earth magnetic field,
useful for desaturation algorithms as well as for very simple control algo￾rithms (e.g., B-dot, see Chapter 10 e Control and Chapter 14 e Applicative
GNC Cases and Examples).
It is a good practice to place at least one sensor per each vehicle face,
mounted externally, with their reference frame aligned with the body frame
and as far as possible from the main perturbing components (battery module,
torque rods, and reaction wheels).
Sensor fusion and automatic calibration using Earth magnetic models are
suggested to the reader in order to obtain a more reliable and robust mea￾surement, see Chapter 14 e Applicative GNC Cases and Examples.
The main specifications of the selected magnetometers are:
- Range: 1 G.
- Resolution: 0.73 mG.
Star trackers
In order to fulfill the pointing requirements during PL operations and S￾band sessions, a set of star trackers is exploited. A good practice is to use
two star trackers, orthogonally mounted one to each other (so to reduce
the around-boresight error) and facing away from the Sun during Sun￾pointing modes as well as facing away from the Earth limb during PL oper￾ations. Typical figures related to star trackers for small CubeSats are:
• FOV: 10  20.
• Accuracy cross-boresight: 0.01 (3-sigma).
• Accuracy around-boresight: 0.05 (3-sigma).
• Sky coverage: >95%.
• Occlusion angle with the Sun: 70 (from boresight).
• Occlusion angle with the Earth limb: 35 (from boresight).
Thus, a possible configuration for the CubeSat would be to mount one
star tracker on the ZM face with the boresight directed as -Z axis and the
other star tracker mounted on the XM face with the boresight laying on
the XZ plane, tilted 15 away from -X toward -Z (see Fig. 15.58).
In this way, at least one star tracker would be always able to face the dark
space during both Sun-pointing modes and PL operations.
964 Stefano Silvestrini et al.GNSS receiver
In a LEO CubeSat, the inertial knowledge is very beneficial, especially dur￾ing ground target modes or nadir-pointing modes when the spacecraft is
equipped with star trackers instead of Earth sensors. Therefore, a GNSS
receiver is integrated in the vehicle to get information of position and veloc￾ity in ECEF coordinates.
Common figures for a GNSS receiver are listed below:
• Signal tracking: GPS L1.
• Position accuracy: 1.5 m RMS.
• Velocity accuracy: 0.03 m/s RMS.
• Time accuracy: 20 ns RMS.
Particular attention shall be placed on the orientation of the GPS antenna
which shall always face away from the Earth in order to optimize its visibility
toward the GPS constellation. Thus, in the CubeSat under consideration, it
can be mounted on the XM face with its boresight aligned with the -X axis.
Reaction wheels
In order to actively control all the three axes of the spacecraft, a set of three
orthogonally mounted reaction wheels is employed in the vehicle.
No redundancy is selected in this case for few reasons:
• Mass and volume limitations of a 3U CubeSat usually do not allow for
redundant modules.
• Power limitations of a 3U CubeSat typically limits the possibility of hav￾ing hot redundancies.
• Typical lifetime for CubeSat missions is in the order of months, and the
associated risk is usually higher with respect to other kind of missions: the
risk of having only three wheels can usually be accepted.
The reaction wheels are mounted on the central part of the vehicle,
paying attention to align them with the body axes.
Figure 15.58 Star trackers orientation on example CubeSat.
Modern Spacecraft GNC 965They need to be properly selected, depending on the mission scenario,
the available power, mass and volume, the required robustness, and espe￾cially the required stability. Below are few specifications of possible wheels
for a 3U CubeSat:
• Speed range: 13,000 rpm.
• Maximum torque: 2.5 mNm.
• Maximum momentum: 15 mNms.
Magnetorquers
Reaction wheels alone are not enough and a secondary set of actuators, able
to dump away the stored momentum, is needed. In LEO CubeSat, it is very
popular to have coils or magnetic torquers which are capable of creating a
torque able to desaturate the flying wheels. They are very simple actuators
and usually quite reliable; therefore, it is enough to have three of them,
orthogonally mounted and possibly aligned with the reaction wheel axes.
As shown above in this chapter, a typical figure for a 3U CubeSat torque
rod is:
• Magnetic momentum: 0.1 A m2
.
Verification and testing limitations
The following section gives a tailored nanosatellite perspective on the con￾tent thoroughly described in Chapter 10 e Control and Chapter 12 e GNC
Verification and Validation.
V&V processes have always been a fundamental basis for all the space
missions up to the advent of the CubeSats. In fact, if on one hand, the nano￾satellites are revolutionizing the space industry, on the other hand, they are
also moving it toward a riskier direction. When speaking about CubeSats,
mission failure is actually an option: this is mainly due to the fact that the
actors involved in this type of missions (universities and small companies)
are usually more focused on the development rather than the verification
and testing. As a consequence, considering more than 250 CubeSats
launched in the last years, about 50% didn’t succeed in their mission objec￾tives [181]. Over time, the platforms are gaining flight heritage and so the
companies which are specialized in this space domain. As a result, the infant
mortality of the launched CubeSats passed from 100% in 2002 to 23.3% in
2018 [182]. This is also due to the consolidation of processes and procedures
able to lower the risk of mission failure in the CubeSat industry.
The first important element needed during the definition of a space
mission which is also a good starting point for V&V is a comprehensive
966 Stefano Silvestrini et al.set of mission requirements and system requirements, together with mission
objectives and goals.
Specifically, for the ADCS, several references are available in literature
which can be used to derive engineering requirements (e.g., Tailored
ECSS Engineering Standards for In-Orbit Demonstration CubeSat Projects
[152]). Pointing requirements are among the most discussed because there is
a high degree of unrealistic expectations. Pointing performances of large sci￾ence missions are not representative of generic bus performances, and they
would require ad hoc sensors and solutions to be achieved. Moreover, sim￾ple specifications in terms of allowed pointing errors are not enough and a
well-written requirement shall be able to completely specify all the scenarios
under regulation. This is also a benefit during V&V, serving as guideline for
the testing procedures.
A satisfactory pointing requirement would at least contain, see Chapter
10 e Control and Chapter 12 e GNC Verification and Validation:
• Indications on the type of error being regulated, such as absolute point￾ing error, relative pointing error, absolute knowledge error, etc. [153].
• The mission phase during which it is expected to be satisfied (e.g., during
PL operations, during Sun pointing).
• The reference frame in which the error is expressed.
• The allowed pointing error and, in case of relative errors, the related time
window.
• The probability level associated to the pointing error.
• The confidence level associated to the pointing error and its probability.
Moreover, it is suggested to express the confidence level in percentile
terms rather than sigma terms, due to the non-Gaussian behavior of the
functions described.
Last but not least, each requirement shall be characterized by one or
more verification methods, intended to be used during the project to vali￾date the system. The most important verification methods available are listed
below [183]:
• Analysis. Theoretical or empirical evaluations are used to validate the
requirement in the target scenario. It falls under the analysis category
also the verification by similarity, which exploits the flight heritage of
the component to demonstrate its applicability to the mission.
• Review of design. Approved design documents and technical material can
be used to verify requirements when they are able to unambiguously
show that the requirement is met.
Modern Spacecraft GNC 967• Inspection. It can be used for the verification of physical properties or
other aspects of the mission (e.g., SW) which can be reviewed without
the need of additional equipment or testing HW.
• Test. It is the verification method used when measurements of perfor￾mances and functional properties of the system or its components are
possible in a simulated environment. It usually requires ground support
equipment when performed in laboratories. Demonstration in orbit
also falls under the category of verification by testing.
It is very easy to understand that the most representative and explanatory
verification method is by test, which shall always be preferred when possible.
However, testing the satellite HW and SW in a representative environment
can be very challenging and costly.
This is also applicable to the ADCS of CubeSat: verification of ADCS
performances on nanosatellites is mainly performed by analysis and demon￾stration for recurrent platforms. In fact, testing the complete subsystem on￾ground with techniques such as hardware-in-the-loop is particularly expen￾sive, complex, and time-demanding. Most of the time it’s just not worth it,
especially without in-orbit data to validate it. However, there are several
other means to be used in order to mitigate the risk of failure in-orbit. Here￾after, few of them are presented and briefly described.
Software-in-the-loop
The ADCS SW can be validated before launch, thanks to dedicated
software-in-the-loop testing campaigns. Basically, the flight code is wrapped
into a truth model able to recreate all the interfaces of the GNC SW. It sim￾ulates the S/C dynamics, the environment, and the behavior of all the
various sensors and actuators. Then, thanks to MC simulations, the flight
SW is validated against nominal and not nominal conditions to spot any
possible bug or nonconformance. Usually, different mission scenarios are
simulated. Among them:
• All the contingency modes of the ADCS to ensure its capability to isolate
any failure and stabilize in a reduced configuration.
• The Sun-pointing modes, so to verify the correct behavior of the plat￾form in pointing the solar panels to the Sun in a reliable manner.
• The various payload-pointing modes, considering also ground target￾pointing modes for the communication system during the downlink
sessions.
968 Stefano Silvestrini et al.The results of all these simulations are also very beneficial during the
verification of the mission and system requirements, being the result of dedi￾cated analyses on the ADCS.
Hardware performance tests
As mentioned before, overall ADCS tests used to characterize the behavior
and the associated performances of the entire system are quite challenging
and usually they are not affordable from the small CubeSat manufacturers.
Nevertheless, being able to measure the associated characteristics of the
various components of the ADCS system is definitely mandatory to ensure
their compatibility with the mission.
For this reason, a series of tests can be performed on the HW:
• Star trackers. The performances of a star camera can be characterized
before launch, thanks to a dedicated campaign on-ground, where the
sensor is exposed for a prolonged time to the night sky of a rural area. In
this way, the sensor, the associated algorithm, and the star catalog are
tested measuring the number of matches and the related accuracy. A
good practice is to have two sensors placed in a known configuration,
using the first one as the source of truth while the second being under
characterization. Another important aspect to consider during ground
testing and verification of optical instruments is related to the mechanical
misalignments with respect to the body reference frame. Preflight cali￾bration and alignment procedures (e.g., geometric laser alignment) can
be adopted; however, they are usually not performed during CubeSats
assembly and integration. In fact, any calibration on-ground e while
valuable e would be invalidated by launch vibrations. It is surely
important for on-ground calibrations to run pre- and postvibe alignment
tests, to assess the impact of the environmental campaign. On the other
hand, it’s paramount to prepare a plan for in-orbit calibration. These
considerations are also valid for optical payloads, which tends to impose
severe pointing requirements to the platform.
• Magnetometers. Dedicated calibration campaigns are needed for this kind
of sensors, which are usually cheap and affected by biases and misalign￾ments with respect to the declared reference frame. A possible perfor￾mance test can consist of the acquisition of a sufficient number of
readings from the magnetometer, in various system configurations (to
ensure no EMC issues) and then the comparison with an external reliable
and accurate probe. In this way, the biases associated with the sensor can
be estimated and considered in the postprocessing SW.
Modern Spacecraft GNC 969• Sun sensors. Also, the Sun sensors are usually small components affected
by biases and misalignments. Therefore, dedicated calibration campaigns
are beneficial, with the aim to characterize the bias error in the sensor
measurement. Furthermore, one of the main issues with the Sun sensors
is related with the detection of false measurements related to the Earth
albedo or other light sources. Thus, if the sensor provides info on the in￾tensity level of the incident light, multiple tests can be performed under
the sunlight in order to characterize the minimum and the maximum
threshold for the detection of true readings (please consider the atmo￾sphere absorption and scattering in the solar irradiance at the Earth sur￾face with respect to the level the satellite will actually foresee in orbit).
• Reaction wheels. These actuators are usually prone to failure in-orbit due
to their nature. In fact, mechanisms in space are always analyzed with
particular care because they tend to fail with prolonged use. Accelerated
life-time testing is crucial in the characterization of the failure modes
related to these actuators in-orbit. Examples of possible tests are: thermal
cycling, vibrations, wheel speed cycling, and zero-crossing. Another
important aspect related to the reaction wheels performances is the static
and dynamic unbalance of the flying wheel which could impact on the
spacecraft relative pointing error. A six-axis Kistler table can be exploited
on-ground during a dedicated testing campaign to characterize the wheel
behavior [184].
Hardware functional tests
If the HW performance tests are able to characterize the various components
of the ADCS, they are usually not able to verify the overall system and to
assess any incompatibility between the different modules. For this reason,
the CubeSat manufacturer shall always consider dedicated HW functional
tests in the verification plan. Hereunder, some possible functional tests to
be performed before launch:
• Polarity tests. It is of paramount importance in the ADCS system to take
care about the polarity of the sensors and actuators. In fact, it can be very
easy to correctly align the component reference frame with the body￾fixed reference frame without respecting the correct directions. For
example, the torque rods could be aligned with the body reference
frame, but their polarity could be erroneous simply due to swapped
electrical wires. Thus, dedicated polarity checks can be exploited to
highlight assembly and/or configuration issues before launch.
970 Stefano Silvestrini et al.• Day-in-the-life test. It is a very good practice to run a prolonged test of the
overall ADCS and system SW, running on the target HW, to spot
possible bugs in the flight SW and related configurations. In fact, even
if the sensors and the actuators are not subjected to the actual scenario
that they will encounter during the mission, it is usually possible to
test at this stage the various logics and mechanisms related to the GNC
state machines, the FDIRs, and other parts more related to sensors post￾processing and health checks.
Hardware-in-the-loop
Sometimes, SW testing and components testing is not enough, for example,
due to the very complicated nature of the mission (e.g., formation flying,
rendezvous, and docking). In these cases, very particular and dedicated
ground equipment is needed. Off-loading systems, able to simulate a
force-less and torque-less environment, exist in many universities and
research centers; however, they are usually limited in terms of HW that
can be host, dimensions, mass, and volume.
They are usually based on air bearings, mechanical devices able to create
a thin film of air between two surfaces in relative motion, thus reducing the
friction between moving parts by several orders of magnitude. Depending
on the degrees of freedom available in the simulator, they can be divided
in mainly three categories [185]:
• Planar systems, used to recreate a force-less environment which can be
useful in simulating the orbital dynamics during rendezvous and docking.
• Rotational systems for the test and validation of the ADCS.
• Combination systems able to provide to the payload 5 DOFs: all the
possible movements of a rigid body except for the translations normal
to the testbed floor. In this way, they recreate the environment needed
during formation flying experiments.
References
[1] A.L. Samuel, Some studies in machine learning using the game of checkers, IBM
Journal of Research and Development 3 (3) (1959) 210e229, https://doi.org/
10.1147/rd.33.0210.
[2] T.M. Mitchell, Machine Learning, 1997, https://doi.org/10.1109/ICDAR.2019.
00014.
[3] I.T. Jolliffe, Graphical representation of data using principal components, Principal
Component Analysis (2002) 78e110.
[4] D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez,
D. Hassabis, Mastering the game of Go without human knowledge, Nature 550
(7676) (2017) 354e359, https://doi.org/10.1038/nature24270.
Modern Spacecraft GNC 971[5] J. MacQueen, Some methods for classification and analysis of multivariate
observations, Berkeley Symposium on Mathematical Statistics and Probability 1
(14) (1967) 281e297, https://doi.org/10.1007/s11665-016-2173-6.
[6] V. Vapnik, The Nature of Statistical Learning Theory, Springer-Verlag, New York,
2000, ISBN 978-1-4757-3264-1.
[7] D.E. Rumelhart, G.E. Hintont, Learning representations by back-propagating errors,
Cognitive Modeling (2) (2019) 3e6, https://doi.org/10.7551/mitpress/
1888.003.0013.
[8] Y. Bengio, P. Simard, P. Frasconi, Learning long-term dependencies with gradient
descent is difficult, IEEE Transactions on Neural Networks 5 (2) (1994) 157e166,
https://doi.org/10.1109/72.279181.
[9] R. Pascanu, T. Mikolov, Y. Bengio, On the difficulty of training recurrent neural
networks, 30th International Conference on Machine Learning, ICML 2013
(PART 3) (2013) 2347e2355.
[10] K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition,
ProceedingseIEEE Computer Society Conference on Computer Vision and Pattern
Recognition (2016) 770e778, https://doi.org/10.1109/CVPR.2016.90.
[11] S. Hochreiter, J. Schmidhuber, Long short-term memory, Neural Computation 9 (8)
(1997) 1735e1780, https://doi.org/10.1162/neco.1997.9.8.1735.
[12] S. Silvestrini, M. Lavagna, Neural-aided GNC reconfiguration algorithm for distrib￾uted space system: development and PIL test, Advances in Space Research 67 (5)
(2021) 1490e1505, https://doi.org/10.1016/j.asr.2020.12.014.
[13] S. Silvestrini, M. Lavagna, Neural-based predictive control for safe autonomous
spacecraft relative maneuvers, Journal of Guidance, Control, and Dynamics 44
(2021) 2303e2310, https://doi.org/10.2514/1.G005481.
[14] V. Pesce, S. Silvestrini, M. Lavagna, Radial basis function neural network aided adap￾tive extended Kalman filter for spacecraft relative navigation, Aerospace Science and
Technology 96 (2020) 105527, https://doi.org/10.1016/j.ast.2019.105527.
[15] M. Bechini, et al., Tango Spacecraft Dataset for Region of Interest Estimation and
Semantic Segmentation, 2022, https://doi.org/10.5281/zenodo.6507863, 1e1.
[16] H. Lee, R. Grosse, R. Ranganath, A.Y. Ng, Unsupervised learning of hierarchical
representations with convolutional deep belief networks, Communications of the
ACM 54 (10) (2011) 95e103, https://doi.org/10.1145/2001269.2001295.
[17] I. Goodfellow, Y. Bengio, A. Courville, Deep Learning, MIT Press, 2016.
[18] M.Z. Asghar, M. Abbas, K. Zeeshan, P. Kotilainen, T. H€am€al€ainen, Assessment of
deep learning methodology for self-organizing 5G networks, Applied Sciences 9
(15) (2019) 2975, https://doi.org/10.3390/app9152975.
[19] A. Krizhevsky, I. Sutskever, G.E. Hinton, ImageNet classification with deep convo￾lutional neural networks, Communications of the ACM 60 (6) (2012) 84e90,
https://doi.org/10.1145/3065386.
[20] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, et al., Imagenet large
scale visual recognition challenge, International Journal of Computer Vision 115 (3)
(2015) 211e252.
[21] E. Shelhamer, J. Long, T. Darrell, Fully convolutional networks for semantic
segmentation, IEEE Transactions on Pattern Analysis and Machine Intelligence 39
(4) (2017) 640e651, https://doi.org/10.1109/TPAMI.2016.2572683.
[22] O. Ronneberger, P. Fischer, T. Brox, U-net: convolutional networks for biomedical
image segmentation, Medical Image Computing and Computer-Assisted
InterventioneMICCAI (2015) 234e241, https://doi.org/10.1007/978-3-319-
24574-4_28.
972 Stefano Silvestrini et al.[23] Y. Cai, L. Qian, Y. Fan, L. Zhang, H. Huang, X. Ding, An automatic trough line
identification method based on improved UNet, Atmospheric Research 264
(2021) 105839, https://doi.org/10.1016/j.atmosres.2021.105839. ISSN 0169-8095.
[24] Z.Q. Zhao, P. Zheng, S.T. Xu, X. Wu, Object detection with deep learning: a
review, IEEE Transactions on Neural Networks and Learning Systems 30 (11)
(2019) 3212e3232, https://doi.org/10.1109/TNNLS.2018.2876865.
[25] R. Girshick, J. Donahue, T. Darrell, J. Malik, Rich feature hierarchies for accurate
object detection and semantic segmentation, in: Proceedings of the IEEE Computer
Society Conference on Computer Vision and Pattern Recognition, 2014,
pp. 580e587, https://doi.org/10.1109/CVPR.2014.81.
[26] S. Ren, K. He, R. Girshick, J. Sun, Faster R-CNN: towards real-time object detec￾tion with region proposal networks, IEEE Transactions on Pattern Analysis and Ma￾chine Intelligence 39 (6) (2017) 1137e1149, https://doi.org/10.1109/
TPAMI.2016.2577031.
[27] K. He, G. Gkioxari, P. Dollar, R. Girshick, Mask R-CNN, Proceedings of the IEEE
International Conference on Computer Vision (2017) 2980e2988, https://doi.org/
10.1109/ICCV.2017.322.
[28] J. Redmon, S. Divvala, R. Girshick, A. Farhadi, You only look once: unified, real￾time object detection, in: 2016 IEEE Conference on Computer Vision and Pattern
Recognition, 2016, pp. 779e788, https://doi.org/10.1109/CVPR.2016.91.
[29] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.Y. Fu, A.C. Berg, SSD: sin￾gle shot multibox detector, Lecture Notes in Computer Science (2016) 21e37,
https://doi.org/10.1007/978-3-319-46448-0_2, 9905 LNCS.
[30] T.Y. Lin, P. Goyal, R. Girshick, K. He, P. Dollar, Focal loss for dense object
detection, IEEE Transactions on Pattern Analysis and Machine Intelligence 42 (2)
(2020) 318e327. https://doi.norg/10.1109/TPAMI.2018.2858826.
[31] Y. Yin, H. Li, W. Fu, Faster-YOLO: an accurate and faster object detection method,
Digital Signal Processing 102 (2020) 102756, https://doi.org/10.1016/
j.dsp.2020.102756.
[32] H. Maudi Lathifah, et al., Fast and accurate fish classification from underwater video
using you only look once, IOP Conference Series: Materials Science and Engineering
982 (2020) 012003.
[33] M. Mozer, A focused backpropagation algorithm for temporal pattern recognition,
Complex Systems 3 (1989) 349e381.
[34] A.J. Robinson, F. Fallside, The utility driven dynamic error propagation network,
IEEE Conference (Neural Information Processing Systems) (1987).
[35] P.J. Werbos, Generalization of backpropagation with application to a recurrent gas
market model, Neural Networks 1 (4) (1988) 339e356, https://doi.org/10.1016/
0893-6080(88)90007-X.
[36] J.J. Hopfield, Neurons with graded response have collective computational properties
like those of two-state neurons, in: Proceedings of the National Academy of Sciences
81, 1984, pp. 3088e3092, 10.
[37] Abe, Theories on the Hopfield neural networks, International 1989 Joint Conference
on Neural Networks 1 (1989) 557e564.
[38] M. Atencia, G. Joya, F. Sandoval, Parametric Identification of Robotic Systems with
Stable Time-Varying Hopfield Networks Neural Computing and Applications, vol
13, 2004, pp. 270e280.
[39] Y. Hernandez-Solano, M. Atencia, G. Joya, F. Sandoval, A discrete gradient method
to enhance the numerical behaviour of Hopfield networks, Neurocomputing 164 (C)
(2015) 45e55.
Modern Spacecraft GNC 973[40] A. Pasquale, S. Silvestrini, A. Capannolo, P. Lunghi, M. Lavagna, Small bodies non￾uniform gravity field on-board learning through Hopfield Neural Networks, Plane￾tary and Space Science (2022) 105425.
[41] European Cooperation for Space Standardization, ECSS-E-ST-40CeSoftware,
ECSS secretariat, ESA-ESTEC, The Netherlands
[42] European Cooperation for Space Standardization, ECSS-Q-ST-80CeSoftware
Product Assurance, ECSS Secretariat, ESA-ESTEC, The Netherlands
[43] European Cooperation for Space Standardization, ECSS-E-ST-60-10CeControl
Performance, ECSS Secretariat, ESA-ESTEC, The Netherlands
[44] European Cooperation for Space Standardization, ECSS-E-ST-60-02CeASIC and
FPGA Development, ECSS secretariat, ESA-ESTEC, The Netherlands
[45] A. Tatsch, N. Fitz-Coy, S. Gladun, On-orbit servicing: a brief survey, in: Proceedings
of the 2006 Performance Metrics for Intelligent Systems Workshop, 2006,
pp. 21e23.
[46] M. Wieser, H. Richard, G. Hausmann, J.-C. Meyer, S. Jaekel, M. Lavagna,
R. Biesbroek, e.Deorbit Mission: OHB Debris Removal Concepts. ASTRA 2015-
13th Symposium on Advanced Space Technologies in Robotics and Automation,
Noordwijk, 2015.
[47] S. Sharma, J. Ventura, S. D’Amico, Robust model-based monocular pose initializa￾tion for noncooperative spacecraft rendezvous, Journal of Spacecraft and Rockets 55
(2018) 1e16, https://doi.org/10.2514/1.A34124.
[48] L. Pasqualetto Cassinis, R. Fonod, E. Gill, Review of the robustness and applicability
of monocular pose estimation systems for relative navigation with an uncooperative
spacecraft, Progress in Aerospace Sciences 110 (2019), https://doi.org/10.1016/
j.paerosci.2019.05.008.
[49] S. D’Amico, M. Benn, J. Jorgensen, Pose estimation of an uncooperative spacecraft
from actual space imagery, International Journal of Space Science and Engineering
2 (2014) 171e189, https://doi.org/10.1504/IJSPACESE.2014.060600.
[50] M. Bechini, et al., Tango Spacecraft Wireframe Dataset Model for Line Segments
Detection, 2022.
[51] M. Kisantal, S. Sharma, T.H. Park, D. Izzo, M. Martens, S. D’Amico, Satellite pose
estimation challenge: dataset, competition design and results, IEEE Transactions on
Aerospace and Electronic Systems (2020), https://doi.org/10.1109/
TAES.2020.2989063.
[52] D. Rondao, N. Aouf, Multi-view monocular pose estimation for spacecraft relative
navigation. 2018 AIAA guidance, navigation, and control conference, Kissimmee
(2018), https://doi.org/10.2514/6.2018-2100.
[53] V. Capuano, S.R. Alimo, A.Q. Ho, S. Chung, Robust Features Extraction for On￾Board Monocular-Based Spacecraft Pose Acquisition, AIAA Scitech 2019 Forum,
San Diego, CA, USA, 2019, https://doi.org/10.2514/6.2019-2005.
[54] J. Dai, Y. Li, K. He, J. Sun, R-FCN: object detection via region-based fully convolu￾tional networks, Advances in Neural Information Processing Systems (2016)
379e387.
[55] A.G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand, et al.,
Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applica￾tions, 2017. ArXiv Preprint. doi:arXiv:1704.04861.
[56] A. Newell, K. Yang, J. Deng, Stacked Hourglass networks for human pose estima￾tion, in: B. Leibe, J. Matas, N. Sebe, M. Welling (Eds.), Computer VisioneECCV
2016, vol 9912, Springer, Cham, 2016, pp. 483e499.
[57] K. Sun, B. Xiao, D. Liu, J. Wang, Deep high-resolution representation learning for
human pose estimation, in: 2019 IEEE Conference on Computer Vision and Pattern
Recognition, IEEE, Long Beach, CA, USA, 2019.
974 Stefano Silvestrini et al.[58] H. Su, C. Qi, Y. Li, L. Guidas, Render for CNN: viewpoint estimation in images
using CNNs, Proceedings of the IEEE International Conference on Computer
(2015) 2686e2694.
[59] S. Sharma, C. Beierle, S. D’Amico, Pose estimation for non-cooperative spacecraft
rendezvous using convolutional neural networks, in: IEEE Aerospace Conference,
IEEE, Big Sky, MT, USA, 2018, https://doi.org/10.1109/AERO.2018.8396425.
[60] K. Simonyan, A. Zisserman, Very Deep Convolutional Networks for Large-Scale
Image Recognition, 2014 arXiv preprint arXiv:1409.1556.
[61] S. Mahendra, H. Ali, R. Vidal, 3D pose regression using convolutional neural
networks, Proceedings of the IEEE International Conference on Computer Vision
(2017) 2174e2182.
[62] A. Kendall, M. Grimes, R. Cipolla, Posenet: a convolutional network for real-time 6-
DOF camera relocalization, Proceedings of the IEEE International Conference on
Computer Vision (2015) 2938e2946.
[63] S. Sharma, S. D’Amico, Pose estimation for non-cooperative spacecraft rendezvous
using neural networks, in: 29th AAS/AIAA Space Flight Mechanics Meeting,
IEEE, Ka’anapali, HI, USA, 2019, https://doi.org/10.1109/AERO.2018.8396425.
[64] J.F. Shi, S. Ulrich, S. Ruel, Cubesat simulation and detection using monocular cam￾era images and convolutional neural networks, 2018 AIAA Guidance, Navigation,
and Control Conference (2018), https://doi.org/10.2514/6.2018-1604. Kissimmee.
[65] S. Sonawani, R. Alimo, R. Detry, D. Jeong, A. Hess, H. Ben Amor, Assistive relative
pose estimation for on-orbit assembly using convolutional neural networks, AIAA
Scitech 2020 Forum (2020), https://doi.org/10.1109/AERO.2018.8396425.
Orlando.
[66] S. Sharma, S. D’Amico, Reduced-Dynamics Pose Estimation for Non-cooperative
Spacecraft Rendezvous Using Monocular Vision. 38th AAS Guidance and Control
Conference, 2017. Breckenridge.
[67] F.L. Markley, Attitude error representations for Kalman filtering, Journal of Guid￾ance, Control, and Dynamics 26 (2003) 311e317, https://doi.org/10.2514/2.5048.
[68] K. Black, S. Shankar, D. Fonseka, J. Deutsch, A. Dhir, M. Akella, Real-time, flight￾ready, non-cooperative spacecraft pose estimation using monocular imagery, in: 31st
AAS/AIAA Space Flight Mechanics Meeting, 2021.
[69] L. Pasqualetto Cassinis, R. Fonod, E. Gill, I. Ahrns, J. Gil-Fernandez, Evaluation of
tightly- and loosely-coupled approaches in CNN-based pose estimation systems for
uncooperative spacecraft, Acta Astronautica 182 (2021) 189e202, https://doi.org/
10.1016/j.actaastro.2021.01.035.
[70] C. Wiedermann, S. Flegel, M. Mockel, J. Gelhaus, V. Braun, C. Kebschull,
P. Vorsmann, Cost estimation of active debris removal, in: 63rd International Astro￾nautical Congress, 2012. Naples, Italy.
[71] H. Schaub, L. Jasper, P. Anderson, D. McKnight, Cost and risk assessment for space￾craft operation decisions caused by the space debris environment, Acta Astronautica
(2015) 66e79.
[72] L. Pasqualetto Cassinis, A. Menicucci, E. Gill, I. Ahrns, M. Sanchez-Gestido, On￾ground validation of a CNN-based monocular pose estimation system for uncooper￾ative spacecraft: bridging domain shift in rendezvous scenarios, Acta Astronautica 196
(2022) 123e138, https://doi.org/10.1016/j.actaastro.2022.04.002.
[73] D.P. Kingma, J. Ba, Adam: a method for stochastic optimization, in: 3rd International
Conference for Learning Representations, 2015, https://doi.org/10.2514/6.2018-
2100. San Diego, CA, USA.
[74] M. Wilde, C. Clark, M. Romano, Historical survey of kinematic and dynamic space￾craft simulators for laboratory experimentation of on-orbit proximity maneuvers,
Modern Spacecraft GNC 975Progress in Aerospace Sciences 110 (2019), https://doi.org/10.1016/
j.paerosci.2019.100552.
[75] M. Zwick, I. Huertas, L. Gerdes, G. Ortega, Orgl - ESA’s test facility for approach
and contact operations in orbital and planetary environments. International Sympo￾sium on Artificial Intelligence, Robotics and Automation in Space, Madrid, 2018.
[76] H. Kruger, S. Theil, Tron - hardware-in-the-loop test facility for lunar descent and 
landing optical navigation, in: IFAC-ACA 2010 Automatic Control in Aerospace,
2010.
[77] V. Dubanchet, B. Romero, K.N. Gregertsen, H. Austad, K. Gancet, et al., EROSS
Project e European Autonomous Robotic Vehicle for On-Orbit Servicing.
I-SAIRAS Virtual Conference, 2020.
[78] M. Piccinin, S. Silvestrini, G. Zanotti, A. Brandonisio, P. Lunghi, M. Lavagna,
ARGOS: calibrated facility for Image based Relative Navigation technologies on
ground verification and testing, in: 72nd International Astronautical Congress (IAC
2021, 2021, pp. 1e11.
[79] S. Silvestrini, P. Lunghi, M. Piccinin, G. Zanotti, M. Lavagna, Experimental valida￾tion of synthetic training set for deep learning vision-based navigation systems for lu￾nar landing, in: 71st International Astronautical Congress, IAC 2020, 2020, pp. 1e10.
[80] T.H. Park, S. Sharma, S. D’Amico, Towards Robust Learning-Based Pose Estimation
of Noncooperative Spacecraft, AAS/AIAA Astrodynamics Specialist Conference,
Portland, 2019.
[81] I. Ali, O. Suominem, A. Gotchev, E. Ruiz Morales, Methods for simultaneous robot￾world-hand-eye calibration: a comparative study, Sensors 19 (2019) 2837.
[82] R.S. Sutton, A.G. Barto, Reinforcement Learning: An Introduction, 2017, p. 10884,
https://doi.org/10.1016/S1364-6613(99)01331-5.
[83] L. Arora, A. Dutta, Reinforcement learning for sequential low-thrust orbit raising
problem, AIAA Scitech 2020 Forum 1 (PartF(January)) (2020) 1e15, https://
doi.org/10.2514/6.2020-2186.
[84] A. Brandonisio, Deep Reinforcement Learning to Enhance Fly-Around Guidance
for Uncooperative Space Objects Smart Imaging, 2020.
[85] A. Brandonisio, Sensitivity analysis of adaptive guidance via deep reinforcement
learning for uncooperative space, AAS/AIAA Astrodynamics Specialist Conference
(2021) 1e20.
[86] L. Federici, B. Benedikter, A. Zavoli, Machine learning techniques for autonomous
spacecraft guidance during proximity operations, AIAA Scitech 2021 Forum (2021)
1e18, https://doi.org/10.2514/1.a35076.
[87] B. Gaudet, R. Linares, R. Furfaro, Deep reinforcement learning for six degree-of￾freedom planetary landing, Advances in Space Research 65 (7) (2020) 1723e1741,
https://doi.org/10.1016/j.asr.2019.12.030.
[88] M.L. Greene, C. Riano-Rios, R. Bevilacqua, N.G. Fitz-Coy, W.E. Dixon, Approx￾imate optimal orbit transfer of non-cooperative debris, AIAA Scitech 2020 Forum 1
(PartF(January)) (2020) 1e13, https://doi.org/10.2514/6.2020-1823.
[89] E.T. Jaynes, Information theory and statistical mechanics, Physics Reviews 106 (1957)
620e630.
[90] S. Levine, V. Koltun, Learning complex neural network policies with trajectory
optimization, Proceedings of the 31st International Conference on Machine Learning
32 (2014) 829e837. http://machinelearning.wustl.edu/mlpapers/papers/
icml2014c2_levine14%5Cnpapers3://publication/uuid/0A6E5CB6-EB7C-4E25-
8A0A-57697C1224BD.
[91] C.J. Watkins, P. Dayan, Q-learning, Machine Learning 8 (3e4) (1992) 279e292.
[92] A. Brandonisio, Deep Reinforcement Learning to Enhance Fly-Around Guidance
for Uncooperative Space Objects Smart Imaging, Politecnico di Milano, 2020.
976 Stefano Silvestrini et al.[93] V. Mnih, et al., Asynchronous methods for deep reinforcement learning, Proceedings
of the 33rd International Conference on Machine Learning, PMLR 48 (2016)
1928e1937.
[94] N.D. Ratliff, J.A. Bagnell, M.A. Zinkevich, Maximum margin planning, in: 23rd In￾ternational Conference on Machine Learning, 2006, pp. 729e736, https://doi.org/
10.1145/1143844.1143936.
[95] N.D. Ratliff, D. Silver, J.A. Bagnell, Learning to search: functional gradient tech￾niques for imitation learning, Autonomous Robots 27 (1) (2009) 25e53, https://
doi.org/10.1007/s10514-009-9121-3.
[96] S. Silvestrini, M. Lavagna, Model-based reinforcement learning for distributed path
planning, Advanced Space Technologies for Robotics and Automation (2019) 0e7.
[97] S. Silvestrini, M. Lavagna, Relative trajectories identification in distributed spacecraft
formation collision-free maneuvers using neural-reconstructed dynamics, AIAA Sci￾tech 2020 Forum (2020) 1e14, https://doi.org/10.2514/6.2020-1918.
[98] B. Taskar, C. Guestrin, D. Koller, Max-margin Markov networks, in: Advances in
Neural Information Processing Systems, 2004.
[99] P. Abbeel, A.Y. Ng, Apprenticeship learning via inverse reinforcement learning,
Twenty-First International Conference on Machine Learning-ICML 1 (2004),
https://doi.org/10.1145/1015330.1015430.
[100] S. Silvestrini, M. Lavagna, Inverse reinforcement learning for collision avoidance and
trajectory prediction in distributed reconfigurations, in: 70th International Astronau￾tical Congress, IAC 2019, 2019, pp. 1e6.
[101] W. Chu, S. Wu, Z. Wu, Y. Wang, Least square based ensemble deep learning for
inertia tensor identification of combined spacecraft, Aerospace Science and Technol￾ogy 106 (2020) 106189, https://doi.org/10.1016/j.ast.2020.106189.
[102] W. Chu, S. Wu, X. He, Y. Liu, Deep learning-based inertia tensor identification of
the combined spacecraft, Journal of Aerospace Engineering 234 (2) (2020)
1356e1366, https://doi.org/10.1177/0954410020904555.
[103] F. Baldini, A. Anandkumar, R.M. Murray, Learning Pose Estimation for UAV
Autonomous Navigation and Landing Using Visual-Inertial Sensor Data,” 2020
American Control Conference, 2020. URL, http://arxiv.org/abs/1912.04527.
[104] R. Furfaro, I. Bloise, M. Orlandelli, P. Di Lizia, F. Topputo, R. Linares, Deep
learning for autonomous lunar landing, in: AAS/AIAA Astrodynamics Specialist
Conference, 2018.
[105] S. Wang, R. Clark, H. Wen, N. Trigoni, DeepVO: towards end-to-end visual
odometry with deep recurrent convolutional neural networks, Proceedings-IEEE In￾ternational Conference on Robotics and Automation (2017) 2043e2050, https://
doi.org/10.1109/ICRA.2017.7989236.
[106] L. Downes, T.J. Steiner, J.P. How, Deep learning crater detection for lunar terrain
relative navigation, AIAA Scitech 2020 Forum (2020) 1e12, https://doi.org/
10.2514/6.2020-1838.
[107] L.M. Downes, T.J. Steiner, J.P. How, Lunar terrain relative navigation using a con￾volutional neural network for visual crater detection, in: 2020 American Control
Conference (ACC), 2020, pp. 4448e4453, https://doi.org/10.23919/
ACC45564.2020.9147595.
[108] S. Silvestrini, P. Lunghi, M. Piccinin, G. Zanotti, M. Lavagna, Artificial intelligence
techniques in autonomous vision-based navigation system for lunar landing, in: 71st
International Astronautical Congress, 2020, pp. 12e14.
[109] S. Silvestrini, M. Piccinin, G. Zanotti, A. Brandonisio, I. Bloise, L. Feruglio,
M. Varile, Optical navigation for lunar landing based on convolutional neural
network crater detector, Aerospace Science and Technology 123 (2022) 107503.
Modern Spacecraft GNC 977[110] A. Silburt, M. Ali-Dib, C. Zhu, A. Jackson, D. Valencia, Y. Kissin, D. Tamayo,
K. Menou, Lunar crater identification via deep learning, Icarus 317 (2019) 27e38,
https://doi.org/10.1016/j.icarus.2018.06.022.
[111] A. Brandonisio, M. Lavagna, D. Guzzetti, Reinforcement learning for uncooperative
space objects smart imaging path-planning, Journal of the Astronautical Sciences
(2021), https://doi.org/10.1007/s40295-021-00288-7. URL, https://link.springer.
com/10.1007/s40295-021-00288-7.
[112] G. Ciabatti, S. Daftry, R. Capobianco, Autonomous planetary landing via deep rein￾forcement learning and transfer learning, IEEE Computer Society Conference on
Computer Vision and Pattern Recognition Workshops (2021) 2031e2038,
https://doi.org/10.1109/CVPRW53098.2021.00231.
[113] V. Pesce, A.A. Agha-Mohammadi, M. Lavagna, Autonomous navigation & mapping
of small bodies, IEEE Aerospace Conference Proceedings (2018) 1e10, https://
doi.org/10.1109/AERO.2018.8396797.
[114] M. Piccinin, P. Lunghi, M. Lavagna, Deep reinforcement learning-based policy for
autonomous imaging planning of small celestial bodies mapping, Aerospace Science
and Technology 120 (2022) 107224, https://doi.org/10.1016/j.ast.2021.107224.
[115] D.M. Chan, A.A. Agha-Mohammadi, Autonomous imaging and mapping of small
bodies using deep reinforcement learning, IEEE Aerospace Conference Proceedings
(2019), https://doi.org/10.1109/AERO.2019.8742147.
[116] L. Federici, B. Benedikter, A. Zavoli, Deep learning techniques for autonomous
spacecraft guidance during proximity operations, Journal of Spacecraft and Rockets
58 (6) (2021) 1e18, https://doi.org/10.2514/1.A35076.
[117] B. Gaudet, R. Linares, R. Furfaro, Adaptive guidance and integrated navigation with
reinforcement meta-learning, Acta Astronautica 169 (2020) 180e190, https://
doi.org/10.1016/j.actaastro.2020.01.007.
[118] B. Gaudet, R. Linares, R. Furfaro, Six degree-of-freedom body-fixed hovering over
unmapped asteroids via LIDAR altimetry and reinforcement meta-learning, Acta
Astronautica 172 (February) (2020) 90e99, https://doi.org/10.1016/
j.actaastro.2020.03.026.
[119] K. Hovell, S. Ulrich, Deep reinforcement learning for spacecraft proximity operations
guidance, Journal of Spacecraft and Rockets 58 (2) (2021) 254e264, https://doi.org/
10.2514/1.A34838.
[120] A. Scorsoglio, A. D’Ambrosio, L. Ghilardi, B. Gaudet, F. Curti, R. Furfaro, Image￾based deep reinforcement meta-learning for autonomous lunar landing, Journal of
Spacecraft and Rockets (May) (2021) 1e13, https://doi.org/10.2514/1.a35072.
[121] S. Willis, D. Izzo, D. Hennes, Reinforcement learning for spacecraft maneuvering
near small bodies, AAS/AIAA Space Flight Mechanics Meeting 158 (2016)
1351e1368.
[122] H. Li, Q. Gao, Y. Dong, Y. Deng, Spacecraft relative trajectory planning based on
meta-learning, IEEE Transactions on Aerospace and Electronic Systems 57 (5)
(2021) 3118e3131, https://doi.org/10.1109/TAES.2021.3071226.
[123] Versal AI Core Series VCK190 Evaluation Kit. https://www.xilinx.com/products/
boards-and-kits/vck190.html.
[124] Xilinx VITIS AI. Adaptable and Real-Time AI Inference Acceleration. https://
www.xilinx.com/products/design-tools/vitis/vitis-ai.html.
[125] FINN Framework. https://xilinx.github.io/finn/.
[126] DNNDK User Guide. https://www.xilinx.com/support/documentation/user_
guides/ug1327-dnndk-user-guide.pdf.
[127] M. Tipaldi, B. Bruenjes, Survey on fault detection, isolation, and recovery strategies
in the space domain, Journal of Aerospace Information Systems 12 (2) (2015)
235e256.
978 Stefano Silvestrini et al.[128] X. Olive, FDI (R) for satellites: how to deal with high availability and robustness in
the space domain? International Journal of Applied Mathematics and Computer Sci￾ence 22 (2012) 99e107.
[129] M. Tipaldi, B. Bruenjes, Spacecraft health monitoring and management systems, in:
2014 IEEE Metrology for Aerospace (MetroAeroSpace), 2014, pp. 68e72.
[130] M. Tipaldi, L. Glielmo, A survey on model-based mission planning and execution for
autonomous spacecraft, IEEE Systems Journal 12 (4) (2017) 3893e3905.
[131] A. Jonsson, R.A. Morris, L. Pedersen, Autonomy in space: current capabilities and 
future challenge, AI Magazine 28 (4) (2007), 27-27.
[132] ECSS-E-ST-70-11C Space EngineeringdSpace Segment Operability, European
Cooperation for Space Standardization Standard, 2008.
[133] ECSS-E-ST-70-41C e Telemetry and Telecommand Packet Utilization, European
Cooperation for Space Standardization Standard, 2016.
[134] A. Zolghadri, D. Henry, J. Cieslak, D. Efimov, P. Goupil, Fault Diagnosis and Fault￾Tolerant Control and Guidance for Aerospace Vehicles, Springer, London, UK,
2014.
[135] A. Zolghadri, Advanced model-based FDIR techniques for aerospace systems: today
challenges and opportunities, Progress in Aerospace Sciences 53 (2012) 18e29.
[136] D. Lakey, M. Eiblmaier, M. Denis, B.T. de Sousa, R. Porta, M. Shaw, T. Francisco,
Multi-mission end-to-end OBCP configuration control, in: SpaceOps 2012 Confer￾ence, 2012.
[137] G. Furano, et al., Towards the use of artificial intelligence on the edge in space sys￾tems: challenges and opportunities, IEEE Aerospace and Electronic Systems Maga￾zine 35 (12) (2020) 44e56.
[138] SAVOIR-FDIR Handbook, European Space Agency, 2019. https://essr.esa.int.
[139] J. Marzat, H. Piet-Lahanier, F. Damongeot, E. Walter, Model-based fault diagnosis
for aerospace systems: a survey, Journal of Aerospace Engineering 226 (10) (2012)
1329e1360.
[140] I. Hwang, S. Kim, Y. Kim, C.E. Seah, A survey of fault detection, isolation, and
reconfiguration methods, IEEE Transactions on Control Systems Technology 18
(3) (2010) 636e653.
[141] A. Wander, R. Forstner, Innovative fault detection, isolation and recovery on-board
spacecraft: study and implementation using cognitive automation, in: IEEE Confer￾ence on Control and Fault-Tolerant Systems (SysTol), 2013, pp. 336e341.
[142] M. Tafazoli, A study of on-orbit spacecraft failures, Acta Astronautica 64 (2e3) (2009)
195e205.
[143] L. Troiano, M. Tipaldi, A. Di Cerbo, M. Hoping, D. De Pasquale, B. Bruenjes, Sat￾ellite FDIR practices using timed failure propagation graphs, in: Proceedings of the
International Astronautical Congress, IAC, 2012, pp. 8524e8531.
[144] L.M. Fesq, Current fault management trends in NASA’s planetary spacecraft, in: 2009
IEEE Aerospace Conference, 2009, pp. 1e9.
[145] A.M. Madni, M. Sievers, Model-based systems engineering: motivation, current sta￾tus, and research opportunities, Systems Engineering 21 (3) (2018) 172e190.
[146] B. Bittner, M. Bozzano, A. Cimatti, R. De Ferluc, M. Gario, A. Guiotto,
Y. Yushtein, An integrated process for FDIR design in aerospace, in: 4th Interna￾tional Symposium on Model Based Safety Assessment, IMBSA, 2014, pp. 82e95.
[147] M. Tipaldi, L. Feruglio, P. Denis, G. D’Angelo, On applying AI-driven flight data
analysis for operational spacecraft model-based diagnostics, Annual Reviews in Con￾trol 49 (2020) 197e211.
[148] J.A. Martínez-Heras, A. Donati, Enhanced telemetry monitoring with novelty
detection, AI Magazine 35 (4) (2019) 37e46.
Modern Spacecraft GNC 979[149] S. Jaekel, B. Scholz, Utilizing artificial intelligence to achieve a robust architecture for
future robotic spacecraft, in: Proceedings of the IEEE Aerospace Conference, 2015,
pp. 1e14.
[150] N. Muscettola, P. Nayak, B. Pell, B. Wiliams, Remote agent: to boldly go where no
AI system has gone before, Artificial Intelligence 103 (1e2) (1998) 5e47.
[151] ECSS-E-ST-40C eSoftware, European Cooperation for Space Standardization
Standard, 2009.
[152] M. Tipaldi, C. Legendre, O. Koopmann, M. Ferraguto, R. Wenker, G. D’Angelo,
Development strategies for the satellite flight software on-board Meteosat Third
Generation, Acta Astronautica 145 (2018) 482e491.
[153] K. Reinholtz, K. Patel, Testing autonomous systems for deep space exploration, IEEE
Aerospace and Electronic Systems Magazine 23 (9) (2008) 22e27.
[154] G. Brat, E. Denney, D. Giannakopoulou, J. Frank, A. Jonsson, Verification of auton￾omous systems for space applications, in: Proceedings of the IEEE Aerospace Confer￾ence, 2006, pp. 1e11.
[155] V. Nardone, A. Santone, M. Tipaldi, D. Liuzza, L. Glielmo, Model checking tech￾niques applied to satellite operational mode management, IEEE Systems Journal 13
(1) (2018) 1018e1029.
[156] P. Van Wesel, A. Goodloe, Challenges in the Verification of Reinforcement
Learning Algorithms, NASA Langley Research Center, Hampton, VA, United
States), 2017. Technical Report.
[157] P. Blacker, C.P. Bridges, S. Hadfield, Rapid prototyping of deep learning models on
radiation hardened CPUs, in: Proceedings of the NASA/ESA Conference on Adap￾tive Hardware and Systems, AHS), 2019, pp. 25e32.
[158] M. Zoppi, M. Tipaldi, A. Di Cerbo, Cross-model verification of the electrical power
subsystem in space projects, Measurement 122 (2018) 473e483.
[159] R. Patton, F. Uppal, S. Simani, B. Polle, Robust FDI applied to thruster faults of a
satellite system, Control Engineering Practice 18 (9) (2010) 1093e1109.
[160] A. Falcoz, D. Henry, A. Zolghadri A, Robust fault diagnosis for atmospheric re-entry
vehicles: a case study, IEEE Transactions on Systems, Man, and Cybernetics-Part A:
Systems and Humans 40 (5) (2010) 886e899 (2010).
[161] R. Fonod, D. Henry, C. Charbonnel, E. Bornschlegl, D. Losa, S. Bennani, Robust
FDI for fault-tolerant thrust allocation with application to spacecraft rendezvous,
Control Engineering Practice 42 (2015) (2015) 12e27.
[162] H. Alwi, C. Edwards, A. Marcos, FDI for a Mars orbiting satellite based on a sliding
mode observer scheme, in: Proceedings of the IEEE Conference on Control and
Fault-Tolerant Systems, SysTol’10, 2010.
[163] N. Tudoroiu, K. Khorasani, Satellite fault diagnosis using a bank of interacting Kal￾man filters, IEEE Transactions on Aerospace and Electronic Systems 43 (4) (2008)
1334e1350.
[164] J.G. Meß, F. Dannemann, F. Greif, Techniques of artificial intelligence for space
applications-A survey, in: Proceedings of the European Workshop on On-Board
Data Processing, ESA OBDP2019), 2019.
[165] H. Henna, H. Toubakh, M.R. Kafi, M. Sauyed-Mouchaweh, Towards fault-tolerant
strategy in satellite attitude control systems: a review, Proceedings of the Annual Con￾ference of the PHM Society 12 (1) (2020), 14-14.
[166] L. Guo, N. Li, F. Jia, Y. Lei, J. Lin, A recurrent neural network based health indicator
for remaining useful life prediction of bearings, Neurocomputing 240 (2017)
98e109.
[167] Y. Huang, S. Li, J. Sun, Mars entry fault-tolerant control via neural network and
structure adaptive model inversion, Advances in Space Research 63 (1) (2019)
557e571.
980 Stefano Silvestrini et al.[168] K. Hovell, S. Ulrich, On deep reinforcement learning for spacecraft guidance, in:
Proceedings of the AIAA Scitech 2020 Forum, 2020.
[169] D. Codetta-Raiteri, L. Portinale, Dynamic Bayesian networks for fault detection,
identification, and recovery in autonomous spacecraft, IEEE Transactions on Systems,
Man, and Cybernetics: Systems 45 (1) (2014) 13e24.
[170] NASA Small Spacecraft Systems Virtual Institute, “State-of-the-Art Small Spacecraft
Technology”, October 2020.
[171] Bryce and Space Technology, “Smallsats by the Numbers 2020”, 2020.
[172] Space News, Cubist Movement, 2012.
[173] E. Kulu, Nanosats Database, www.nanosats.eu.
[174] H.-P. Chung, S.-H. Chang, C.-L. Hsieh, S.-L. Yang, Y.-H. Chen, Cubesat compat￾ible fiber-optic gyroscope, in: Opto-Electronics and Communications Conference
(OECC), 2020, pp. 1e3, 2020.
[175] S. Douglas, J. Mitchell, S. Lee, Output drifting of vacuum packaged MEMS sensors
due to room temperature helium exposure, Journal of Sensor Technology 3 (2013)
101e109.
[176] S. Douglas, “Analysis of: MEMS Oscillator Sensitivity to Helium (Helium Kills
iPhones) YouTube Video”, Linkedin, 2019. https://www.linkedin.com/pulse/
analysis-mems-oscillator-sensitivity-helium-kills-iphones-doug-sparks/.
[177] Office of the Federal Register, Foreign Availability Determination Procedures and
Criteria, 2015. Title 15 Part 768.7.
[178] N.A.S.A./R. SciNews, “Cosmonauts Deploy Nanosatellites from outside the ISS”,
2017. https://www.youtube.com/watch?v¼-hutA7In7GA.
[179] D.T. Gerhardt, E. Scott, Passive magnetic attitude control for Cubesat spacecraft, in:
24th Annual AIAA/USU Conference on Small Satellites, 2010.
[180] A. Lassakeur, C. Underwood, Magnetic cleanliness program on Cubesats for
improved attitude stability, in: 2019 9th International Conference on Recent Ad￾vances in Space Technologies, RAST), 2019, pp. 123e129.
[181] A. Alanazi, J. Straub, “Statistical Analysis of Cubesat Mission Failure”, 32nd Annual
AIAA/USU Conference on Small Satellites, 2018.
[182] T. Villela, C.A. Costa, A.M. Brand~ao, F.T. Bueno, Towards the thousandth CubeSat:
a statistical overview, International Journal of Aerospace Engineering 2019 (2019).
Article ID 5063145.
[183] ECSS Secretariat, Space EngineeringeVerification, ECSS-E-ST-10-02C, March
2009.
[184] J. Shields, C. Pong, K. Lo, L. Jones, S. Mohan, C. Marom, I. McKinley, W. Wilson
and L. Andrade, “Characterization of Cubesat reaction wheel assemblies”, JoSS, Vol.
6, No. 1, pp. 565e580
[185] J.L. Schwartz, M.A. Peck, C.D. Hall, Historical review of air- bearing spacecraft
simulators, Journal of Guidance, Control, and Dynamics 26 (4) (2003) 513e522.
Further reading
[1] T. CubeSat Program, Cal poly SLO, Cubesat design specification, In Review 14 (2020).
[2] ESA, Tailored ECSS Engineering Standards for In-Orbit Demonstration Cubesat Pro￾jects, TEC-SY/128/2013/SPD/RW, Issue 1 Rev 3, November 2016.
[3] ESA, ESA Pointing Error Engineering Handbook, ESSB-HB-E-003, Issue 1 Rev. 0,
July 2011.
Modern Spacecraft GNC 981This page intentionally left blankCHAPTER SIXTEEN
Mathematical and geometrical
rules
Andrea Capannolo1
, Aureliano Rivolta2
, Andrea Colagrossi3
,
Vincenzo Pesce3
, Stefano Silvestrini1
1
Politecnico di Milano, Milan, Italy
2
D-Orbit, Fino Mornasco, Italy
3
Airbus D&S Advanced Studies, Toulouse, France
Mathematical and geometrical rules are the underlying basis for any engi￾neering application. This section summarizes and reports some of the
most useful mathematical and geometrical rules for guidance, navigation,
and control (GNC) applications. In particular, matrix, vector, and quater￾nion algebra are discussed, together with some basic concepts of statistics.
Finally, the expressions of the matrices to perform the rotation from the
Earth-centered inertial (ECI) to the Earth-centered Earth-fixed (ECEF)
are reported.
Matrix algebra
In mathematics, a matrix is a rectangular array of numbers arranged in
rows and columns. A matrix is defined as:
A ¼
2
6
6
6
6
6
6
6
4
a11 a12
a21 a22
/ a1n
/ a2n
« «
am1 am2
1 «
/ amn
3
7
7
7
7
7
7
5
;
which is a matrix with m horizontal rows and n vertical column, and it is
often referred to as a m  n matrix. Each element of a matrix is often
denoted by a variable with two subscripts, i; j, indicating the row and the
column, respectively. Note that a row vector is a 1  n matrix, and a column
vector is a m  1 matrix.
Modern Spacecraft Guidance, Navigation, and Control
ISBN: 978-0-323-90916-7
https://doi.org/10.1016/B978-0-323-90916-7.00016-0
© 2023 Elsevier Inc.
All rights reserved. 983 jDifferent fundamental operations are defined for matrices, and they
compose the matrix algebra. The most basic ones are:
• Matrix addition. The sum A þ B of two m  n matrices A and B is calcu￾lated entry-wise:
ðA þ BÞi;j ¼ aij þ bij:
The subtraction operation is analogously defined with the negative sign.
Note that matrix addition/subtraction is defined only for matrices of the
same size.
• Scalar multiplication. The product of a scalar c and a matrix A is computed
by multiplying every entry of A by c:
cA ¼ 
c aij
.
• Matrix transpose. The transpose of an m  n matrix A is the n m matrix
AT formed by turning rows into columns and vice versa:
AT ¼ 
aji
.
This section is intended to be a preliminary introduction to matrix
algebra. The reader is invited to deepen the topic in [1].
Square matrices
A matrix is said to be square if it has the same number of rows and columns
(i.e., a matrix n  n), and the entries aii form the main diagonal of a square
matrix.
Some special square matrices can be defined:
• Upper triangular matrix. A matrix with all the elements below the main di￾agonal equal to zero.
• Lower triangular matrix. A matrix with all the elements above the main di￾agonal equal to zero.
• Diagonal matrix. A matrix with all the elements outside the main diagonal
equal to zero.
• Identity matrix. A diagonal matrix in which all the diagonal elements are
equal to 1. It is indicated with the symbol In; with n as the matrix size
(i.e., n  n). It is called identity matrix because a matrix multiplied by
the identity matrix is unchanged.
• Symmetric matrix. A matrix that is equal to its transpose: A ¼ AT.
• Skew-symmetric matrix. A matrix that is equal to the negative of its trans￾pose: A ¼ AT.
984 Andrea Capannolo et al.Matrix multiplication
Given two matrices A and B, the matrix C is defined as multiplication of A
and B if its components satisfy the following relation:
cij ¼
X
k
aikbkj (16.1)
where c;a;b represent the scalar elements of the matrices C; A; B,
respectively. From Eq. (16.1), it is observed that the single element cij is the
result of a scalar product between a row of matrix A, and a column of matrix
B, which must be of the same length. Hence, the number of columns of A
shall be equal to the number of rows of B. Therefore, the multiplication of a
matrix m  n and a matrix n  p produces a matrix of dimensions m p.
Properties
Differently from the scalar product, the matrix multiplication is a noncom￾mutative operation Eq. (16.2):
ABsBA (16.2)
However, it preserves the associativity and the distributivity properties,
namely Eq. (16.3) and (16.4):
ðABÞC ¼ AðBCÞ (16.3)
AðB þ CÞ ¼ AB þ AC (16.4)
The matrix multiplication can be transposed by transposing each matrix
of the multiplication and inverting their order:
ðABÞ
u ¼ BuAu (16.5)
If A and B have complex elements, the complex conjugates of the multi￾plication are equivalent to the multiplication of complex conjugates of the
single matrices:
ðABÞ
* ¼ A*B* (16.6)
Combining Eqs. (16.5) and (16.6), the conjugate transpose of the matrix
multiplication satisfies the following equivalence:
ðABÞ
z ¼ Bz
Az (16.7)
where z indicates the conjugate transpose operation.
Mathematical and geometrical rules 985Additional properties characterize the matrix multiplication in the spe￾cific case of square matrices. As said, the identity matrix In represent the
neutral element of the multiplication, as:
A In ¼ In A ¼ A (16.8)
Powers of the matrix A can be computed as sequential multiplications of
itself, namely:
Ak ¼ AA/A (16.9)
If A and B are square, the determinant can be defined for both. Such sca￾lar quantity is a commutative parameter, in fact:
detðABÞ ¼ detðBAÞ ¼ detðAÞdetðBÞ ¼ detðBÞdetðAÞ (16.10)
The same rule applies for the trace:
trðABÞ ¼ trðBAÞ (16.11)
Matrix inversion
The inverse of a square matrix A, labeled as A1, is a matrix such that the
following relation holds:
AA1 ¼ A1
A ¼ In (16.12)
A necessary and sufficient condition for matrix A to be invertible is to be
nonsingular, i.e., to have a nonnull determinant:
detðAÞs0 (16.13)
Analytical computation
The inverse matrix A1 can be computed through an analytical formula.
Given the matrix A, the cofactor matrix cof ðAÞ can be computed such
that:
cof ðAÞij ¼ ð1Þ
iþj
Mij (16.14)
where Mij is the minor corresponding to the i-th row and j-th column of
matrix A, i.e., the determinant of matrix A after i-th row and j-th column
has been removed.
Then, the adjugate matrix is defined as the transpose of the cofactor
matrix:
adjðAÞ ¼ cof ðAÞ
u (16.15)
986 Andrea Capannolo et al.and the inverse matrix is finally expressed as Eq. (16.16) and (16.17):
A1 ¼ 1
detðAÞ
adjðAÞ (16.16)
The inverse of a matrix product can be computed, similarly to the trans￾pose of Eq. (16.5), as:
ðABÞ
1 ¼ B1
A1
: (16.17)
Frobenius norm
The Frobenius norm of a matrix A belongs to the group of entry-wise matrix
norms. The general p-norm of A reads:
k Akp;p ¼
 Xn
i¼1
Xm
j¼1

aij


p
!1=p
(16.18)
where m and n are the two dimensions of the matrix A.
The Frobenius norm, or simply the matrix norm, is then obtained from
Eq. (16.18) by setting p ¼ 2, and reads:
k Ak2;2 ¼
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
Xn
i¼1
Xm
j¼1

aij


2
vuut (16.19)
The norm of Eq. (16.19) can be also expressed in alternate forms, namely
Eq. (16.20):
k Ak2;2 ¼
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
tr
AyA
q 
¼
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
min
X
fn;mg
i¼1
s2
i ðAÞ
vuut (16.20)
where Ay represents the conjugate transpose matrix of A, and si is its i-th
singular value, obtained through the singular value decomposition (SVD),
which is introduced in the following of this section.
Matrix rank
The rank of a matrix A, rankðAÞ, represents the maximum number of lin￾early independent columns (and rows) of A. If a matrix ðn nÞ has n linearly
independent rows or columns, it is called a full-rank matrix. Rectangular
matrices can have (at most) a rank equal to the smallest of its two dimensions.
Mathematical and geometrical rules 987A basic approach to compute the rank of a matrix is to reduce it to its
echelon form, through sequential Gaussian eliminations. In the context of nu￾merical computation, other approaches are adopted. Through SVD, it is
possible to determine the rank of a matrix by identifying the number of non￾null singular values. Such approach, although not the most efficient, repre￾sents the most numerically stable approach. Alternatively, other matrix
decomposition can be leveraged to exploit a faster computation of the
rank, such as the rank-revealing QR factorization [1].
Eigenvectors
The term eigenpair refers to the couple of a scalar eigenvector l and its related
eigenvector v. These quantities refer to vector field transformation, but they
can easily be associated to linear algebra if we consider a transformation on
itself. Hence, the linear transformation that any square matrix can represent.
An eigenvector of a square matrix A of dimensions n  n is:
Avi ¼ livi (16.21)
where the index i goes from 1 to n. This can be referred to as the eige￾nequation. Should be noted that we implicitly took vi as a column vector;
however, this can work also for row vectors as well, in this case, we would
have:
uiA ¼ kiui (16.22)
where ui is a 1  n vector. In this case, the eigenpair is given by ðki; uiÞ and
ui is referred to as the left eigenvector, while vi is the right eigenvector. This
can be clearly associated with the left and right multiplication concept. For
most applications, such as the GNC ones, the right eigenvectors are
preferred. It should be noted that uisvT
i ; however, it is equal to the right
eigenvector of AT .
The eigenequation can be found in a different form:
ðA  InliÞvi ¼ 0 (16.23)
From this form, we can deduce that the matrix ðA InliÞ must be sin￾gular. Hence, if we impose:
detðA  InlÞ ¼ 0 (16.24)
we obtain an equation in l of order n, which is called characteristic equation
or characteristic polynomial. Solving it allows to determine all the n
988 Andrea Capannolo et al.eigenvalues of A. Being the equation an n order polynomial, it is also
possible to write it as:
detðA  InlÞ¼ðl1  lÞðl2  lÞ.ðli  lÞ.ðln  lÞ (16.25)
where the eigenvalues are clearly visible. It should be noted that there is
room for complex results, always in conjugate pairs if matrix A is real. To
each eigenvalue li, it is possible to associate an eigenspace made of eigen￾vectors that satisfy the eigenequation, taking the null vector as well. If more
than one nonnull eigenvectors can be associated to li, we have a geometrical
multiplicity case.
This shouldn’t be a surprise: if we determine the eigenvalue of an n n
identity matrix, we know that all the eigenvalues are equal to 1, and each
column of the matrix is an eigenvector. Namely, the identity matrix In
has n identical eigenvalues and n linearly independent eigenvectors associ￾ated to it. Any vector parallel to one of the n directions given by the columns
still satisfies the eigenequation. Indeed, if we multiply by any scalar quantity
the eigenequation, the result won’t change. Hence, there are potentially
infinite eigenvectors. If we want to identify one eigenpair, for the sake of
understanding and for the computational use of the eigenvectors, we could
select the only one with unitary norm. This, of course, doesn’t apply to the
case where a geometrical multiplicity happens.
A useful way to reduce the computation of eigenvalues could be to
exploit some properties:
8
>>>><
>>>>:
trð Þ¼ A Xn
i¼1
aii ¼ Xn
i¼1
l i
detð Þ¼ A Yn
i¼1
li
(16.26)
Knowing all eigenvalues of a matrix can also be used to infer some char￾acteristics of A. For example, if even one eigenvalue is null, then the deter￾minant of A is null, the matrix is not invertible, and its rank is not maximum.
The eigenpairs of a matrix can also be used to diagonalize it. If we define
a diagonal matrix, L, and a matrix, V; which, respectively, collect all the n
eigenvalues and n eigenvectors (i.e., one per eigenspace, preferably unitary),
we can generalize the eigenequation as:
A ¼ VLV1 (16.27)
Mathematical and geometrical rules 989That means that we can always find a transformation V that links any
matrix with a diagonal version composed by its eigenvalues.
If a matrix A is Hermitian, or real and symmetric, all its eigenvalues are
real. The relation between Hermitian matrices and their eigenvalue is
further deepened also for positive-definite, semipositive-definite, and their
negative counterparts, as the resulting eigenvalues would be ðl > 0Þ,
ðl  0Þ, ðl < 0Þ, and ðl  0Þ, respectively.
It is also possible to link the eigenvalues of a matrix A to the eigenvalue
of closely related matrices. For example, any power Ak matrix would have
lk eigenvectors. Limitations may apply for singular matrices. Another link
can be seen when adding an identity matrix, in fact, A þ gI has eigenvalues
that are all l þ g. By extension, if we create a polynomial of A, the resulting
eigenvalues will have value equal to the polynomial result of the eigenvec￾tors of A.
Singular value decomposition
As we have seen before, it exists a decomposition of a square matrix A such
that A ¼ VLV1 where V is a collection of linearly independent eigenvec￾tors and L is the diagonal matrix of the eigenvalues of A. This is valid for
square matrices, but we can find another decomposition for which this con￾dition is not required.
The SVD is related to the polar decomposition and can be seen as a
generalization of the factorization made using eigenvalues and eigenvectors.
Given a m  n matrix, Amn, which can be complex, its SVD is:
Amn ¼ SmmVmnDz
nn (16.28)
where Smm and Dnn are singular, possibly complex, square matrices.
Vmn is a diagonal rectangular matrix, and with z, it has been indicated the
Hermitian conjugate transposition. If Amn is real, then Smm and Dnn are
also orthogonal and z is replaced by a simple transposition. In literature, the
notation USVz is also used to indicate the SVD.
The diagonal of Vmn is composed by the so-called singular values, and
any null entries of this list would reduce by 1 the rank of Amn. The columns
of Smm and Dnn are, respectively, the left and right singular vectors of
Amn. Geometrically speaking, the sequence of operations is a rotation or
reflection 
Dz
nn
	
, followed by a scaling ðVmnÞ and ending with another
rotation or reflection ðSmmÞ.
990 Andrea Capannolo et al.There is indeed a striking similarity with the eigenvalue decomposition;
however, it should be noted that singular values and eigenvalues are not
identical except for diagonal matrices. The definition of singular values, vi, is:
( Amnsi ¼ vidi
Az
mndi ¼ visi
(16.29)
where si and di are the left and right singular vectors belonging to Smm and
Dnn , and vi is the i-th singular values of Amn. The SVD can also be
written in terms of outer product, meaning that we can also write:
Amn ¼ Xn
i¼1
visi5di; (16.30)
which basically means that we can divide Amn into the sum of matrices
obtained by weighted outer products, whose bases are the vectors in Smm
and Dnn .
It should be remarked that there is no rule for the order of the singular
values and the same applies for singular vectors. Hence, the decomposition is
not unique unless some order is put in the values.
The SVD can be used also to facilitate the computation of the pseudoin￾verse of a matrix, in fact:
Ay
mn ¼ 
SmmVmnDz
nn
y ¼ Dnn Vy
mnSz
mm (16.31)
where the pseudoinverse of a diagonal matrix is much easier to compute
than the one of a full complete matrix.
Moreover, we can link the SVD to linear minimization. For example,
minðAxÞ with x ¼ 1 means that the solution is a right singular vector of
A; di; such that its singular value vi is the smallest of all of them.
Vector identities
Vectors are geometric objects that have magnitude (or length) and di￾rection, and they are used to represent geometrical or physical quantities. In
matrix notation, a vector is a matrix with just one row (i.e., row vector) or
one column (i.e., column vector). Vectors can be manipulated by different
operators to obtain different results. Some common examples are the norm,
the dot product, and the cross product. These have also an easily visualizable
geometrical interpretation.
Mathematical and geometrical rules 991Vector norm
The L2 norm of a vector v is:
k v2 k ¼ ffiffiffiffiffiffiffiffi
vT v p (16.32)
And is equivalent to the length of the vector. If we take a vector and
multiply by the inverse of its norm, we will obtain a vector with unitary
norm (i.e., length) often referred to as unit vector.
The operation under the square root operator is seen as the multiplica￾tion of the transpose of the vector by itself or, in general, it is the projection
of a vector on itself. This projection operation is the dot product.
Dot product
The dot product between a vector v and a vector u is:
v $ u ¼ v
T u ¼ Xn
i¼1
viui (16.33)
which represents the projection of one vector onto the other. It can be easily
seen that v$u ¼ u$v, the result is a scalar. The dot product exists only
between vector of the same dimensionality. If u is a unitary vector ub, it
means that the dot product gives the projection of v along the direction ub,
meaning that the result is given by the length of v and the cosine of the angle
between the two directions. In other words:
cos w ¼ v$u
k v kk u k ¼ bv$ub (16.34)
Hence, the dot product is connected to the angle between two unitary
vectors.
The dot product relates to the angle between two directions; however,
this angle is computed in the plane formed by the two vectors, if the
vectors are orthogonal, the dot product would be null, in fact, if vtu,
then vT u ¼ 0.
Cross product
The operation that instead moves out of the plane is the cross product. The
cross product of u and v is:
k ¼ v  u ¼ ½vu ¼
2
6
6
4
0 v3 v2
v3 0 v1
v2 v1 0
3
7
7
5
u (16.35)
992 Andrea Capannolo et al.As you can see, this is the cross product in ℝ3. The result is still a tridi￾mensional vector that by definition is orthogonal to the first two: ktv and
ktu. Looking closer, it is also reasonable to expect that v  v ¼ 0 and, in
general, that if u k v; v  u ¼ 0. Hence:
ðv  uÞ $ v ¼ ðv  uÞ$u ¼ 0 (16.36)
It should be noted that unlike the dot product, the cross product is
anticommutative, meaning that v  u ¼ u  v. In fact, if we just take
k1 ¼ v2u3e v3u2 and k1 ¼ u2v3e u3v2, it is clear that are opposite in
sign. This is not a surprise as ½v is skew-symmetric; hence,
½v
T ¼ ½v. Using the matrix form, we can also state:
v  u ¼ ½vu ¼ ½uv ¼ u  v (16.37)
Another property of the cross product is that it is addition distributive,
v  ðu þkÞ ¼ v  u þ v  k, and indifferent to a scalar multiplication
mðv uÞ ¼ðmvÞ  u ¼ v  ðmuÞ. If we apply a matrix transformation,
we have:
ðAvÞðAuÞ ¼ detðAÞðAÞ
T
v  u (16.38)
If A is a rotation matrix (i.e., unitary determinant, with transpose and in￾verse coincide), then applying a rotation to both vectors would apply the
same rotation to their cross product: ðAvÞðAuÞ ¼ A ðv uÞ:
The shape of the cross matrix is in line with the ijk multiplication rule
commonly used in rotation representation. If we take three unit vectors
in a tridimensional cartesian reference frame ðbx; by; bzÞ, thus orthogonal,
we have that bz ¼ bx  by but also by  bx ¼ bz and so on.
Like for the dot product, also the cross product can relate to the angle
between two vectors. In the orthogonal unit vector case mentioned above,
the resulting vector will always have a unitary norm which is the highest we
can have. Let us take an example and use k ¼ bx  bs where
bs ¼ f cos w sin w 0 gT , which is a vector displaced from bx of an angle
w. The result is k ¼ f 0 0 sin w gT ¼ bzsin w. As expected, if w ¼ p
2,
we would go back to the previous orthogonal case. In the general case:
sin wbk ¼ v  u
k v kk u k (16.39)
Another geometrical interpretation of the cross product is that the norm
of a cross product identifies the area of the parallelogram generated on the
ðv; uÞ plane by the two vectors.
Mathematical and geometrical rules 993Dot and cross product share also combined identities besides those
shown above. For instance:
k v  uk2 ¼k vk2 k uk2  ðv$uÞ
2 (16.40)
That can easily be verified using trigonometry and the relations
mentioned above.
If we take three vectors a; b; and c, we have:
a $ ðb  cÞ ¼ b$ðc  aÞ ¼ c$ða  bÞ; (16.41)
thanks to the multiplication rule mentioned above. But also:
a  b  c ¼ bða $ cÞ  cða $ bÞ; (16.42)
or:
ða  bÞða  cÞ¼ða $ ðb  cÞÞa: (16.43)
Outer product
Another useful vector operator is the outer product that is not bounded by
size like the cross product. The outer product of two vectors u and v is a
matrix whose elements are the multiplication of each element of u and v
in such a way that the i; j-th component of the matrix is equal to uivj.
u 5v ¼ u vT (16.44)
If the two vectors have the same dimensions, it follows that
detðu 5vÞ ¼ 0, but in any case, the outer product matrix has rank 1. As
one can see, the matrix version of the product is the inverse of the dot prod￾uct; moreover, it is easy to see that:
trðu 5vÞ ¼ u$v (16.45)
This operation is not commutative, however:
ðu 5 vÞ ¼ ðv5uÞ
T : (16.46)
The outer product is also associative and indifferent to scalar, as the cross
product.
Quaternion algebra
Quaternions have been introduced in Chapter 5 e Attitude Dy￾namics, where they were closely linked to the attitude representation, but
they were also necessary for the attitude determination of Chapter 9 e Nav￾igation. In these chapters, it has been used a specific multiplication rule;
however, this is not unique as it will be clear in this section.
994 Andrea Capannolo et al.Quaternions have been introduced by William Rowan Hamilton in
1843 and are a mathematical tool that extend the complex algebra into three
dimensions. Quaternions are extremely powerful to represent rotations and
to deal with spacecraft attitude in GNC applications. A quaternion has a vec￾tor part, q1:3, and a scalar part, q4:
q ¼
( q1:3
q4
)
¼
8
>>>>><
>>>>>:
q1
q2
q3
q4
9
>>>>>=
>>>>>;
It is worth noticing here that, depending on the textbook or the appli￾cation, the quaternion definition may vary. Sometimes the scalar part is
placed first, and it is noted as q0. Thus, there are two quaternion conven￾tions: scalar first and scalar last. The latter is used in this book, with the scalar
part in the fourth position. Unfortunately, the derived formulas and the
associated mathematical operations are different according to the used
convention. The reader is strongly encouraged to always verify and spend
time on the quaternion convention that is in use before using any third￾party function, library, or formula.
At this point, we can introduce the Hamiltonian left and right quater￾nion products, in matrix multiplication form:
8
>>>>>>>>>>>>>>>>>>>>>>>>><
>>>>>>>>>>>>>>>>>>>>>>>>>:

q


¼
2
6
6
6
6
6
6
6
6
4
q4 q3 q2 q1
q3 q4 q1 q2
q2 q1 q4 q3
q1 q2 q3 q4
3
7
7
7
7
7
7
7
7
5

qþ


¼
2
6
6
6
6
6
6
6
6
4
q4 q3 q2 q1
q3 q4 q1 q2
q2 q1 q4 q3
q1 q2 q3 q4
3
7
7
7
7
7
7
7
7
5
(16.47)
Mathematical and geometrical rules 995and we link these matrices to the quaternion multiplication convention:
qc ¼ qa  qb ¼ 
qa



qb ¼ 
qb
þ


qa (16.48)
It should be noted that we choose to follow this convention, but we
could have simply decided to use the opposite. This would have implied
different mathematical relations.
From the matrix multiplication form, it follows clearly that, regardless of
the multiplication order, we can always rearrange the operators. This comes
in handy when we have to determine Jacobians for functions to be mini￾mized, or when we analyze a specific rotational link in a long kinematic
chain. For example:
qd ¼ qa  qb  qc ¼ 
qa


qb



qc ¼ 
qa


qc
þ


qb ¼ 
qc
þ

qb
þ


qa
(16.49)
Here we have also used the properties of the quaternion multiplication,
presented in matrix form:
8
>>>>>>>><
>>>>>>>>:
qa



qb



¼ 
qa


qb



hqa
þ


qb
þ

i
¼ 
qa
þ

qb
þ


qa
þ


qb



¼ 
qb


qa



hqa



qb
þ

i
¼ 
qb
þ

qa
þ


(16.50)
So far, we haven’t used the transposition operator on the matrices, and
there is a reason for that: transposing one of the two multiplication matrix
forms generates the counterrotation. Looking carefully at the off-diagonal
components of the two multiplication matrices, being skew-symmetric,
the transposition can be seen as an inversion of signs of the vector part of
the quaternion. This means that it is equivalent to apply a multiplication
for the conjugate quaternion:
q* ¼
( q1:3
q4
)
;
which represents the same rotation but in opposite verse. Hence, it is clear
that:

q

T 
q


¼ I4: (16.51)
996 Andrea Capannolo et al.As a result, we can derive the matrix inverse as:

q

1 ¼ 
q

T ¼ 
q*


; (16.52)
where we have assumed the quaternion to have unit norm, as usually done
in attitude applications. From these rules, we can also identify the quaternion
division and further extend our capability to manipulate the rotation chains:
qd ¼ 
qa


qb



qc/ qc ¼ 
qb


T 
qa


T
qd: (16.53)
Even in this case, it is possible to manipulate the chain to obtain different
possibilities. It is, however, not possible to exchange qa and qd with the two
operators used so far. New matrix forms need to be included:
8
>>>>>>>>>>>>>>>>>>>>>>>>><
>>>>>>>>>>>>>>>>>>>>>>>>>:

qT


¼
2
6
6
6
6
6
6
6
6
4
q4 q3 q2 q1
q3 q4 q1 q2
q2 q1 q4 q3
q1 q2 q3 q4
3
7
7
7
7
7
7
7
7
5

qþT


¼
2
6
6
6
6
6
6
6
6
4
q4 q3 q2 q1
q3 q4 q1 q2
q2 q1 q4 q3
q1 q2 q3 q4
3
7
7
7
7
7
7
7
7
5
(16.54)
These matrices are no longer completely skew-symmetric, and the main
diagonal has partially changed sign as well. The transposition operation is still
maintained equal to the inversion for these matrices, moreover:

qT

T ¼ 
qþT

 (16.55)
But also, the interesting relation:

qþT


q ¼ 
qT


q ¼ q0 (16.56)
where q0 is the null rotation vector: q0 ¼ f 00 01 gT .
Mathematical and geometrical rules 997Going back to our chain, we can now write:
qc ¼ 
qb


T 
qa


T
qd ¼ 
qb


T 
qd
T


qa ¼ 
qd
T

qa



qb
¼ 
qd
T

qb
þ


qa
(16.57)
From which also follows:
( 
qa
T


¼ 
qb


qa
T

qb
þ



qa
þT


¼ 
qb
þ

qa
þT

qb


 (16.58)
And:
8
<
:

qa
þT

qb


T 
qa
T


¼ 
qb
þ



qa
T

qb
þ

T 
qa
þT


¼ 
qb



(16.59)
Or:
8
<
:

qa
þT

qb


T ¼ 
qb
þ

qa
þT



qa
T

qb
þ

T ¼ 
qb


qa
T


(16.60)
That gives us, for example:
qd ¼ 
qa


qc
þ


qb ¼ 
qc
T

qa
þ

T 
qc
þT

qc
þ


qb ¼ 
qc
T

qa
þ

T
q*
b
(16.61)
where:

qa
þT

qa
þ


¼ 
qa
T

qa



¼ conjðqaÞ ¼ qa
* (16.62)
Is, of course, the matrix that transform any quaternion in its conjugate.
Quaternion from two directions
If the problem we are analyzing is not related to a long chain of rotation, but
it is more closely related to attitude representation and estimation, what is
the best way to determine a quaternion from two directions?
It is indeed possible to determine a quaternion such that the correspond￾ing rotation move one vector onto the other. Since just a couple of vectors is
not enough to determine attitude, there exist infinite rotations that can bring
one vector onto the other, but it is possible to estimate quickly the shortest
route.
998 Andrea Capannolo et al.First, using the cross product of the two vectors, it is possible to deter￾mine the Euler axis, meaning that the rotation we seek is perpendicular to
both vectors and will bring one to the other. Then, we just need to estimate
the angle between the two vectors. Mathematically, if v2 ¼ Aðq21Þv1, we
need to perform the following steps:
8
>>>>>>>><
>>>>>>>>:
e ¼ v2  v1
k v2  v1 k
w ¼ cos1
ðv2$v1Þ
qr ¼
8
<
:
e sinðw=2Þ
cosðw=2Þ
9
=
;
(16.63)
Note that using the cosine can give good results for most application;
however, a more general procedure would see w ¼ tan1


kv2v1k
v2$v1

¼
atan2

kv2v1k
kv2kkv1k; v2$v1
kv2kkv1k

. Indeed, numerical stability should be considered
as well.
It should be noted that, in general, qr does not coincide with q21, as any
multiplication for a quaternion with Euler axis coincident with v2 will not
compromise the projection of v1 onto v2. This can be verified if we
compute the relative quaternion:
qr ¼ 
qr
þ

T
q21 (16.64)
Then, it will be easy to verify that q1:3r

sin
cos1ðq4rÞ

is equal to v2.
Please pay attention that this last procedure does not take into account
the quaternion equivalence qr ¼ qr. A more robust way would be
q1:3r
,
sin 
tan1
 
kq1:3r
k
q4r
!! or, if one prefers computational efficiency
over trigonometry, k q1:3r k sign
q4r
	
.
Quaternions are extremely important in many GNC applications, and
the reader is invited to extend its knowledge about quaternions and quater￾nion algebra in [2].
Mathematical and geometrical rules 999Basics of statistics
Statistics is a collection of methods for collecting, displaying,
analyzing, and drawing conclusions from data. It is fundamental for GNC
applications since it may be applied both for processing the GNC functional
data and for analyzing the results and the outputs during the GNC design,
verification, testing, and operations. This brief section only introduces
some basic concepts of statistics, which are also discussed in Chapter 6 e
Sensors. However, for a thorough study on the topic, the reader is invited
to refer to the suggested reference [3,4].
Scalar statistics parameters
Given a random variable y, it is possible to define its expected value (or mean)
as:
m ¼ EðyÞ ¼
Z
N
N
yf ðyÞdy (16.65)
where f ðyÞ represents the probability density function of the random variable y.
The variance is defined as the expected value of the quadratic difference
between the population of y and its mean value, namely:
s2 ¼ varðyÞ ¼ Eðy  mÞ
2 (16.66)
The square root of the variance is known as standard deviation:
s ¼
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
ðEðy  mÞ
2
Þ
q
(16.67)
For two variables yi and yj, the covariance is defined as follows:
sij ¼ cov
yi; yj
	
¼ E
h
ðyi  mi
Þ

yj  mj
	i (16.68)
The covariance can be standardized by dividing it by the single stan￾dard deviation of the two variables. Such quantity is called correlation and
reads:
rij ¼ corr
yi; yj
	
¼ sij
sisj
(16.69)
1000 Andrea Capannolo et al.Vector and matrix forms of statistic quantities
Consider a random vector y collecting N random variables yi, such that:
y ¼
0
BB@
y1
«
yN
1
CCA
(16.70)
then, the expected value of the vector y is the vector of expected values of
its elements:
EðyÞ ¼
0
BB@
Eðy1Þ
«
EðyNÞ
1
CCA ¼ m (16.71)
The covariances of the y elements can be collected in a matrix form, also
known as covariance matrix:
S ¼ covðyÞ ¼
2
6
6
6
6
6
6
6
4
s11 s12 / s1N
s21 s22 / s2N
«
sN1
«
sN2
1
/
«
sNN
3
7
7
7
7
7
7
5
(16.72)
where sij are the covariances, defined in Eq. (16.68), while sii ¼ s2
i are the
variances, as per Eq. (16.66). Notice that, due to the definition of the
covariance, it results that sij ¼ sji. Hence, the covariance matrix is sym￾metric. Furthermore, if the y random variables are continuous and there are
no linear relations among them, the covariance matrix is positive definite. In
case linear relationships are present, the matrix is positive semidefinite.
From the expression of Eq. (16.69), it is possible to define the correlation
matrix:
P ¼
2
6
6
6
6
6
6
4
1 r12 / r1N
r21 1 / r2N
«
rN1
«
rN2
«
/ 1
3
7
7
7
7
7
5
(16.73)
P can be directly computed in matrix form from the covariance matrix S as:
P ¼ D1SD1 (16.74)
Mathematical and geometrical rules 1001with D ¼ diagðs1; s2;/; sN Þ.
By analogy with Eq. (16.71), the expected value of a random matrix Y is
defined as the matrix of the expected values of its elements, namely:
EðYÞ ¼
2
6
6
6
6
6
6
4
Eðy11Þ Eðy12Þ / Eðy1N Þ
Eðy21Þ Eðy22Þ / Eðy2N Þ
«
EðyN1Þ
«
EðyN2Þ
«
/ EðyNNÞ
3
7
7
7
7
7
5
: (16.75)
Hence, the covariance matrix S, defined in Eq. (16.72), can be also
expressed as:
S ¼ E

ðy  mÞðy  mÞ
T 
: (16.76)
It is possible to obtain a meaningful measure of the distance between y
and m by considering the variance and the covariance of each element yi
of the variables vector. Such measure is the standardized distance, also called
Mahalanobis distance [5], and reads:
Std:Dist: ¼ ðy  mÞ
TS1ðy  mÞ (16.77)
where the term S1 standardizes the yi variables, so that they will have
means equal to 0 and variances equal to 1. In this way, they become
uncorrelated.
ECI-ECEF transformation
The transformation between the ECI (geocentric celestial reference frame -
GCRF) and the ECEF (international terrestrial reference frame - ITRF) reference
frames is performed through a series of rotations that are known as Earth
orientation model. An introductory discussion about this transformation is
described in Chapter 2 e Reference Systems and Planetary Models.
The position, velocity, and acceleration conversions take the form of:
rECI ¼ PðtÞNðtÞ RðtÞ WðtÞ rECEF (16.78)
vECI ¼ PðtÞNðtÞ RðtÞ ðWðtÞ vECEF þ uE  rPEFÞ (16.79)
aECI ¼ PðtÞNðtÞ RðtÞ ½WðtÞ aECEF þ uE  ðuE  rPEFÞ þ 2uE  vPEF
(16.80)
1002 Andrea Capannolo et al.with:
rPEF ¼WðtÞrECEF vPEF ¼ WðtÞvECEF
where P and N are the precession-nutation matrices of date t, R is the
sidereal-rotation matrix of date t, W is the polar motion matrix of date t, and
uE represents the rotation rate of the Earth. Before expressing these rotation
matrices, please refer to Table 16.1 for a list of the relevant parameters to
express the rotations, which are defined according to the IAU-76/FK5
Reduction. All the used coefficients are distributed by the International
Earth Rotation and Reference Systems Service (IERS) [6].
Polar motion
The rotation matrix W from the ECEF to the Pseudo-Earth Fixed frame is
expressed as:
W ¼ Rx

yp
	
Ry

xp

where xp and yp are the angular displacements of the true pole with respect
to the International Reference Pole. Notice that the change in these values
over one week is significant enough to require updates. Moreover, it is also
Table 16.1 List of relevant parameters for ECI/ECEF rotations.
xp, yp
Angular displacements of the true pole with respect to the
international reference pole
qGAST1982 Greenwich apparent sidereal time
qGMST Greenwich mean sidereal time
TTT Terrestrial time
UTC Coordinated universal Time
TAI International atomic Time
DJ1980 Nutation in longitude
Dε1980 Nutation in obliquity
dDJ1980 EOP corrections for the nutation in longitude
dDε1980 EOP corrections for the nutation in obliquity
ε1980 Mean obliquity of the ecliptic
z; Q; z Precession angles
Mean anomaly of the moon
M1 Mean anomaly of the sun
Mean argument of latitude of the moon
D1 Mean elongation from the sun
RAAN of the mean lunar orbit measured on the ecliptic.
Mathematical and geometrical rules 1003hard to accurately predict value over long periods because the pole motion
has yet to be completely understood.
Sidereal time
The rotation matrix R is the sidereal-rotation matrix of date:
R ¼ RzðqGAST1982Þ
where qGAST1982 is the Greenwich apparent sidereal time, computed from
the mean sidereal time using the equation of the equinoxes:
qGAST ¼ qGMST þ Eqequinox
Nutation
The first step is to determine the mean obliquity of the ecliptic from:
ε1980 ¼ 84381:44800  46:8150TTT  0:00059T2
TT þ 0:001813T3
TT
TTT is the Terrestrial Time, and it is related to other times as follows:
UTC ¼ UT1  DUT1
TAI ¼ UTC þ DAT
TT ¼ TAI þ 32:184s
TTT ¼ JDTT  2 451545
36525
where TAI is the International Atomic Time and DAT and DUT1 are available
from the EOP data. DAT is always an integer number and is constant until
changed whereas DUT1 changes continuously in time, as discussed in
Chapter 2 e Reference Systems and Planetary Models.
Then the Delaunay parameters (or arguments), which account for the
luni-solar nutation, are estimated with r ¼ 360 :
M1 ¼ 357:529 109 18 þ ð99r þ 359:050 291 1ÞTTT  0:0001537T2
TT
þ 3:8e
8T3
TT
1004 Andrea Capannolo et al.D1 ¼ 297:850 195 47 þ ð1236r þ 307:111 446 9ÞTTT
 0:0017696T2
TT þ 1:831e
6T3
TT
The nutation in longitude DJ1980 and in obliquity Dε1980 is evaluated
through trigonometric series:
DJ1980 ¼ X
106
i¼1
ðAi þ BiTTT Þsin
api

Dε1980 ¼ X
106
i¼1
ðCi þ DiTTT Þcos
api

To ensure compatibility with the GCRF, EOP corrections
(dDε1980; dDJ1980) are applied, obtaining:
ε1980 ¼ ε1980 þ Dε1980 þ dDε1980
DJ1980 ¼ DJ1980 þ dDJ1980
Finally, the transformation matrix is computed as:
N ¼ Rxðε1980ÞRzðDJ1980ÞRxðε1980Þ
Precession
The combined effects of precession are represented by the angles z; Q, and
z:
z ¼ 2306:218100TTT þ 0:301 88T2
TT þ 0:017 998T3
TT
Q ¼ 2004:310900TTT  0:426 65T2
TT  0:041 833T3
TT
z ¼ 2306:218100TTT þ 1:094 68T2
TT þ 0:018 203T3
TT
The complete precession transformation matrix is:
P ¼ RzðzÞ RyðQÞ RzðzÞ
Mathematical and geometrical rules 1005References
[1] D. Norman, D. Wolczuk, Introduction to Linear Algebra for Science and Engineering,
Pearson Education, 2012.
[2] F.L. Markley, J.L. Crassidis, Fundamentals of Spacecraft Attitude Determination and
Control, Space Technology Library, Springer, New York, 2014.
[3] J. Morrison, Statistics for Engineers: An Introduction, John Wiley & Sons, 2009.
[4] W.J. DeCoursey, Statistics and Probability for Engineering Applications with Microsoft
Excel, Newnes - Elsevier, 2003.
[5] P.C. Mahalanobis, On the Generalized Distance in Statistics, National Institute of Sci￾ence of India, 1936.
[6] https://www.iers.org/IERS/EN/DataProducts/EarthOrientationData/eop.html.
1006 Andrea Capannolo et al.CHAPTER SEVENTEEN
Dynamical systems theory
Francesco Cavenago1
, Andrea Colagrossi2
, Stefano Silvestrini2
,
Vincenzo Pesce3
1
Leonardo, Milan, Italy
2
Politecnico di Milano, Milan, Italy
3
Airbus D&S Advanced Studies, Toulouse, France
Modeling is typically the first step to be taken when the dynamics of a system
is analyzed, and control and estimation algorithms need to be developed for
spacecraft guidance, navigation, and control (GNC) applications. Several
formulations exist, which can be more or less suitable depending on the sit￾uations and the scope of the system model. In this appendix, the primary
modeling approaches used throughout this book are reviewed:
• State-space formulation.
• Discrete-time systems.
• Transfer functions.
This appendix chapter is intended to provide a brief overview of the
fundamental concepts about dynamical systems theory, which is an essential
topic for system modeling and GNC applications. The reader is strongly
encouraged to extend knowledge about it in the suggested literature refer￾ences [1e7].
State-space models
In state-space formulation, the time evolution of the system is
described by the so-called state variables. Their name derives from the fact
that they are able to characterize the condition, or state, of the system. Given
the state at a certain instant of time and the inputs at the same instant, the
time evolution of the system can be determined. In particular, this is formal￾ized through a set of first-order differential equations in the following form:
x_ ¼ fðx; u; tÞ;
xðt0Þ ¼ x0;
y ¼ hðx; u; tÞ;
(17.1)
Modern Spacecraft Guidance, Navigation, and Control
ISBN: 978-0-323-90916-7
https://doi.org/10.1016/B978-0-323-90916-7.00017-2
© 2023 Elsevier Inc.
All rights reserved. 1007 jwhere f and h are n  1 and p  1 vector functions, sufficiently differen￾tiable, x is the n  1 state vector, u is a m  1 vector collecting the input to
the system, and y is a p  1 vector gathering the output or measured signals.
The dimension n of the state vector represents the order of the model. The
system in Eq. (17.1) is time-varying, namely the dynamics functions
explicitly depend on time. If this dependency is dropped, the model is said to
be time-invariant. Another classification can be made according to the
number of input and output. A system is called single-input-single-output
(SISO) when m ¼ p ¼ 1, while it is called multi-input-multi-output
(MIMO) if m > 1 and p > 1. The combination of the two previous alter￾natives is also possible (i.e., SIMO and MISO), and it is analogously defined.
A special class of systems, which is a subset of the general Eq. (17.1), is
one of the linear systems. For this class, the state-space equations are
expressed as follows:
x_ ¼ Ax þ Bu;
xðt0Þ ¼ x0;
y ¼ Cx þ Du;
(17.2)
where A is the n  n dynamics matrix, B is the n  m control matrix, C is
the p  n sensor matrix, and D is the p  m direct term. In linear time￾varying system, these matrices depend on time, and the solution to Eq.
(17.2) is given by:
xðtÞ ¼ Vðt; t0Þx0 þ
Zt
t0
Vðt; sÞBðsÞuðsÞds; (17.3)
where V is the state-transition matrix, whose properties are:
Vðt0; t0Þ ¼ I;
Vðt0; tÞ ¼ V1ðt; t0Þ;
Vðt2; t0Þ ¼ Vðt2; t1ÞVðt1; t0Þ;
V_ ðt; t0Þ ¼ AVðt; t0Þ.
(17.4)
If the matrices A, B, C, and D do not depend on time, the system is
called linear time-invariant (LTI), and the solution becomes:
xðtÞ ¼ e
Aðtt0Þ
x0 þ
Zt
t0
e
AðtsÞ
BuðsÞds; (17.5)
where eAðtt0Þ and eAðtsÞ are exponential matrices.
1008 Francesco Cavenago et al.The conversion from a n-th order differential equation to a state-space
model is possible. Let’s consider the following SISO system:
dny
dtn þ an1
dn1y
dtn1 þ an2
dn2y
dtn2 þ ::: þ a1
dy
dt þ a0y ¼ u. (17.6)
A state-space vector can be defined as:
x ¼
2
6
6
6
6
6
6
6
6
6
6
6
6
6
4
dn1
y

dtn1
dn2
y

dtn2
«
dy=dt
y
3
7
7
7
7
7
7
7
7
7
7
7
7
7
5
; (17.7)
and, thus, the state-space model is:
x_ ¼
2
6
6
6
6
6
6
6
6
6
6
6
6
4
an1 an2 / a1 a0
1 0 / 0 0
0 1 / 0 0
« « 1 « «
0 0 / 1 0
3
7
7
7
7
7
7
7
7
7
7
7
7
5
x þ
2
6
6
6
6
6
6
6
6
6
6
6
6
4
1
0
0
«
0
3
7
7
7
7
7
7
7
7
7
7
7
7
5
u;
y ¼ ½ 000 / 1 x.
(17.8)
Discrete-time systems
With the advent of digital computer, discrete-time systems have
become more and more important for the implementation of estimation
and control algorithms in GNC applications. Indeed, analog signals from
the sensors are transformed to digital numbers through an analog-to-digital
converter. Then, a computer is used to process the data for the GNC pur￾poses. Finally, digital-to-analog converters transform back digital numbers to
Dynamical systems theory 1009analog signals to be provided to the system. A generic discrete-time system
can be written as:
xkþ1 ¼ fðxk; uk; tkÞ;
xðt0Þ ¼ x0;
yk ¼ hðxk; uk; tkÞ;
(17.9)
where k stands for the current instant of time.
The classifications and most of the concepts for continuous systems can
be directly extended to discrete-time ones. Focusing on LTI systems, and
assuming to use a zero-order hold system for sampling, the propagation of
the state at the different sampling time can be derived by Eq. (17.5). Indeed,
selecting as initial time a generic sampling instant kT, and kT þ T the sub￾sequent instant, it is possible to write:
xkþ1 ¼ e
ATxk þ
kT
Z
þT
kT
e
AðTþkTsÞ
Bds uk; (17.10)
where T is the sampling period. Introducing b ¼ T þ kT  s, Eq. (17.10)
becomes:
xkþ1 ¼ e
ATxk þ
Z
T
0
e
AbBdb uk; (17.11)
and, consequently, it turns out that the equation of the complete LTI
discrete-time system takes a form similar to Eq. (17.2):
xkþ1 ¼ Axe k þ Bue k;
xðt0Þ ¼ x0;
yk ¼ Cxk þ Duk;
(17.12)
with
Ae ¼ e
AT; Be ¼
Z
T
0
e
AbBdb. (17.13)
The matrices C and D remain unchanged with respect to the
continuous-time case. Note that the derivation of Eqs. (17.10)e(17.11) is
valid assuming that the input uk is constant in the sampling interval, as it
1010 Francesco Cavenago et al.is when zero-order hold system is used (i.e., one of the most common sam￾pling techniques).
As a final remark, it is recalled that an LTI discrete-time system is asymp￾totically stable if all the eigenvalues of the matrix Ae have modulus lower
than 1.
Transfer functions
A very powerful approach to study a dynamic system is the frequency
domain modeling, which is the foundation of classical control theory. The
basic idea is to look at the response of the system to sinusoidal and expo￾nential signals. Modeling in the frequency domain provides a deep insight
of the behavior of the system, as shown in the section control design in
Chapter 10 - Control, and avoids the use of complex differential equations.
Indeed, the relations are algebraic, which makes them easier to manipulate.
For LTI systems, the mathematical tool used to describe the relation be￾tween an input and an output in the frequency domain is the transfer func￾tion. This can be determined in different ways, but the most common one
is the ratio between the Laplace transforms of the output and the input
when the initial conditions are zero. Before recalling the definition of
the Laplace transform, it is noted that one of the aspects, which has
made transfer functions very popular, is the possibility to represent them
graphically through Bode and Nyquist plots, which provide particularly
useful information about the properties of the dynamics, as explained in
section control design in Chapter 10 - Control.
Laplace transform is used to convert a function in a real variable, in the
case of dynamical systems typically the time, to a function in a complex var￾iable, s, usually called generalized frequency. Given a function fðtÞ in the
time domain, its Laplace transform is defined by:
LðfðtÞÞ ¼ FðsÞ ¼ Z
N
0
estfðtÞdt; ReðsÞ > s0. (17.14)
From this definition, some important properties of the Laplace transform
can be derived, which are briefly recalled here:
• Lða1f 1ðtÞ þa2f 2ðtÞÞ ¼ a1Lðf 1ðtÞÞ þ a2Lðf 2ðtÞÞ
• LðeatfðtÞÞ ¼ Fðs aÞ
• Lðfðt sÞÞ ¼ essFðsÞ; for s > 0
Dynamical systems theory 1011• L
 R t
0 fðsÞds
!
¼ 1
s FðsÞ
• L

dfðtÞ
dt 
¼ sFðsÞ  fð0Þ
Note that the last relation becomes simpler if the initial state is zero.
Indeed, the Laplace transform of the time derivative can be obtained simply
by multiplying the Laplace transform of fðtÞ by s.
In order to show how to define a transfer function by using the Laplace
transform, consider the following linear system:
dny
dtn þ an1
dn1y
dtn1 þ ::: þ a0y ¼ bm
dmu
dtm þ bm1
dm1u
dtm1 þ ::: þ b0u;
(17.15)
where u and y are the input and output, respectively. The transfer function
between u and y is computed by passing in the Laplace domain, i.e., by
applying the relation for the time derivative, and assuming zero initial
conditions. Consequently, Eq. (17.15) results in:

s
n þ an1s
n1 þ ::: þ a0

YðsÞ ¼ 
bms
m þ bm1s
m1 þ ::: þ b0

UðsÞ.
(17.16)
where UðsÞ and YðsÞ are the Laplace transforms of the input and output,
respectively. At this point, the transfer function PðsÞ is simply the ratio
between UðsÞ and YðsÞ:
PðsÞ ¼ YðsÞ
UðsÞ
¼ bms
m þ bm1s
m1 þ ::: þ b0
sn þ an1sn1 þ ::: þ a0
. (17.17)
Transfer functions are characterized by three main features, which are the
zero-frequency gain, the poles, and the zeros. Taking Eq. (17.17) as
example, the gain is given by the magnitude of the transfer function at
s ¼ 0, i.e., Pð0Þ ¼ b0
a0
, and it represents the ratio between the output and
the input at steady state. The poles are the roots of the polynomial at the de￾nominator. They are intrinsic characteristics of the system and determine its
behavior (cfr. Table 2 in Section Control design in Chapter 10 - Control)
and stability. In particular, the transfer function is stable if all its poles have
negative real part. Finally, the zeros are the roots of the polynomial at the
numerator. They affect the transient response of the system, and, if they
have positive real part, they impose limitations to the maximum control
1012 Francesco Cavenago et al.bandwidth that can be obtained (cfr. Section Limitations to control perfor￾mance in Chapter 10 - Control). The location of the zeros in the complex
plane depends on how sensors and actuators are integrated in the system, and
thus modification to the design can move the zeros, potentially simplifying
the control synthesis.
The transfer function between input and output can be found also start￾ing from the state-space formulation. Consider Eq. (17.2) for the LTI case,
moving to the Laplace domain, the following relations are obtained:
sXðsÞ  xð0Þ ¼ AXðsÞ þ BUðsÞ;
YðsÞ ¼ CXðsÞ þ DUðsÞ. (17.18)
Substituting XðsÞ, isolated from the first row, in the second row, the
output equation results to be:
YðsÞ ¼ 
CðsI  AÞ
1
B þ D
UðsÞ þ CðsI  AÞ
1
xð0Þ. (17.19)
In the special case in which xð0Þ ¼ 0, Eq. (17.19) becomes:
YðsÞ ¼ 
CðsI  AÞ
1
B þ D
UðsÞ; (17.20)
and, thus, the transfer function PðsÞ is:
PðsÞ ¼ 
CðsI  AÞ
1
B þ D
. (17.21)
For MIMO systems, PðsÞ is a matrix collecting all the transfer functions
between each input and output. On the other hand, for SISO systems, PðsÞ
becomes a scalar and can be written as PðsÞ ¼ YðsÞ
UðsÞ
.
Transfer functions are often used in combination with block diagram
representations to study dynamic systems, especially closed-loop systems.
Exploiting block diagram algebra, it is possible to easily derive the output
resulting from interconnected systems. To show this, consider the linear sys￾tems reported in Fig. 17.1.
In Fig. 17.1A, two systems, described by the transfer functions P1ðsÞ and
P2ðsÞ, are connected in series, and the relation between the input u and the
output y can be derived as follows:
y ¼ P2v ¼ P2ðP1uÞ. (17.22)
Therefore, the overall transfer function of the series is P ¼ P2P1, namely
the product of the transfer functions of the two systems.
Consider now Fig. 17.1B, which shows a parallel connection between
the systems. The output of the interconnection results to be:
Dynamical systems theory 1013y ¼ P1u þ P2u ¼ ðP1 þ P2Þu; (17.23)
and thus, the transfer function between the input and the output is sim￾ply the sum of the transfer functions, i.e., P ¼ P1 þ P2.
Finally, in Fig. 17.1C, a negative feedback system is reported. In this case,
the output can be computed as:
y ¼ P1e ¼ P1ðu  P2yÞ; (17.24)
and consequently:
y ¼ P1
1 þ P1P2
u. (17.25)
From Eq. (17.25), it is evident that the overall transfer function is P ¼ P1
1þP1P2
. These simple operations can be used to compute transfer functions
in more complex systems.
To conclude this part, the transfer functions for some common LTI sys￾tems are listed:
• Integrator: y_ ¼ u / P ¼ 1
s
.
• Differentiator: y ¼ u_ / P ¼ s.
• Double integrator: €y ¼ u / P ¼ 1
s2.
Figure 17.1 Interconnection of linear systems. In (A), two transfer functions are con￾nected in series. In (B), two transfer functions are connected in parallel. In (C), two trans￾fer functions create a feedback loop.
1014 Francesco Cavenago et al.• First-order system: y_ þ ay ¼ u / P ¼ 1
sþa
.
• Second-order system: €y þ 2xuny_ þ u2
ny ¼ u / P ¼ 1 s2þ2xunsþu2
n
.
• Time delay: yðtÞ ¼ uðt sÞ / P ¼ ess.
References
[1] N.S. Nise, Control Systems Engineering, John Wiley & Sons, Inc., 2011.
[2] G.F. Franklin, D.J. Powell, A. Emami-Naeini, Feedback Control of Dynamic Systems,
Pearson, 2015.
[3] A. Tewari, Modern Control Design with MATLAB and SIMULINK, John Wiley &
Sons, Inc., 2002.
[4] K.J. Åström, R.M. Murray, Feedback Systems: An Introduction for Scientists and En￾gineers, second ed., Princeton University Press, 2021.
[5] W.J. Rugh, Linear System Theory, Prentice-Hall, Inc., 1996.
[6] T. Kailath, Linear Systems, vol. 156, Prentice-Hall, Englewood Cliffs, NJ, 1980.
[7] H.K. Khalil, Nonlinear Systems, third ed., Patience Hall, 2002.
Dynamical systems theory 1015This page intentionally left blankCHAPTER EIGHTEEN
Autocoding best practices
Francesco Pace1
, Vincenzo Pesce2
, Andrea Colagrossi3
,
Stefano Silvestrini3
1
GMV Aerospace & Defence, Madrid, Spain
2
Airbus D&S Advanced Studies, Toulouse, France
3
Politecnico di Milano, Milan, Italy
Automated code generation or autocoding is more and more used in mod￾ern spacecraft guidance, navigation, and control (GNC), and it is almost
becoming a baseline process for the GNC flight software (SW) application.
The purpose of this appendix chapter is to provide modeling rules and
guidelines to develop GNC models using MATLAB/Simulink in order to
ensure the generated code being functionally correct, compliant with the
existing standards as well as readable, reusable, and maintainable.
The content of this appendix chapter has to be intended together with
the development, verification, and validation processes of the GNC subsys￾tem, which are discussed in the core parts of this book. In particular, the
reader is invited to combine the information contained in this appendix
with those presented in Chapter 12 - GNC Verification and Validation.
List of main architectural and implementation rules
The development described for the GNC system follows a SW life￾cycle that uses autocoding techniques to generate code from MATLAB/
Simulink models. Thus, the GNC model-based development shall follow
several rules and guidelines for allowing the compatibility of the Simulink
models with the autocoding process. Usually, autocoding rules are
project-specific; however, some baseline guidelines can be defined derived
from experience and autocoding standards [1]. It is strongly recommended
to exercise the autocoding from the beginning of GNC SW development
and then continue to test the autocoding on a regular basis.
Modeling rules for autocoding may be grouped into two categories:
• Modeling architectural and design rules defining the rules and guidelines
that need to be followed at architectural and design level of the
GNC subsystem models. These rules lead to efficiently port the code
Modern Spacecraft Guidance, Navigation, and Control
ISBN: 978-0-323-90916-7
https://doi.org/10.1016/B978-0-323-90916-7.00018-4
© 2023 Elsevier Inc.
All rights reserved. 1017 jto the validation and verification environments, and they guarantee
architectural mapping.
• Modeling implementation rules defining the proper coding and implemen￾tation style to be followed by the Simulink GNC models. These rules
prevent errors, language-specific pitfalls, nonoptimized statements,
forbidden constructs, complexity restrictions, and readability in the
generated code.
Architectural rules
For GNC modeling in a MATLAB/Simulink Functional Engineering
Simulator (FES), the main architectural and design rules shall focus on the
following aspects:
• Architectural division between GNC on-board software (OBSW) models and
real-world (RW) models. The GNC receives the measurements from the
RW, executes its algorithms, and provides commands back to the RW
models closing the simulation loop. These two parts (OBSW and
RW) must be clearly separated in the FES since only OBSW models
will be autocoded for being embedded in a target space processor. It is
recommended to keep the complete GNC system in a single block.
• Clear definition of interfaces between the RW and the OBSW. The interfaces
between the RW and the OBSW shall be specified, and, in particular,
the following signal characteristics must be defined (e.g., not inherited
by Simulink):
• Type
• Dimension
• Sample time
The following architectural rules shall be respected:
• Avoid algebraic loops inside OBSW chain.
• Include a unit delay block between the OBSW models and the RW.
• Set the sample time by subsystem properties of atomic block.
• The time used inside the GNC OBSW shall be passed as input via a “dig￾ital clock” block.
• Delays that simulate deterministic computation and transmission of mea￾surements to GNC or commands from GNC to actuators shall be placed
at top-level in a unique place.
Moreover, it is recommended to:
1018 Francesco Pace et al.• Include models to simulate OBSW pre- and postprocessing operations
(e.g., signal routing, rate transitions, pre- and postprocessing of signals,
etc.) before and after GNC SW execution.
• Give univocal names to input and output signals.
• Organize the GNC modules according to their sample rate, grouping
functions with the same sample time.
• Identify the main GNC functions and set them as atomic blocks to
generate the corresponding C code functions. In this way, it is possible
to guarantee the architectural mapping in the generated code.
Implementation rules
On the other hand, it is very important to clearly define low-level imple￾mentation rules that allow for a more standardized and error-free autocoding
process. These guidelines can be divided into three main categories, depend￾ing on their applicability:
• Mandatory. In this category, there are all the essential guidelines to be fol￾lowed. They are intended to ensure the correct behavior of the code
generation process, without unexpected errors and corresponding to
the origin model. If these rules are not followed, the autocoded block
output can be inconsistent or inaccurate.
• Strongly recommended. Rules that are recognized as good practice but not
mandatory. Intended to ensure code reliability and representativeness of
the original model. If not followed, the quality of the final code can
decrease.
• Recommended. Guidelines that are recommended to improve the model
diagram but not critical for the final code behavior.
In this chapter, only the main guidelines are detailed.
Mandatory
• Set the “Ensure data integrity during data transfer” parameter and
“Ensure deterministic data transfer (maximum delay),” when rate￾transition block is used (see Fig. 18.1).
• Avoid rate-transition blocks in atomic library subsystems.
• Avoid mask initialization commands. In fact, the variable initialized in
this way are hardcoded in the autocoded model and not accessible in
real time.
• Group and identify tunable and nontunable parameters for each mask
present in the model (see Fig. 18.2). In the MATLAB environment, a
tunable parameter is a parameter that can be changed without
Autocoding best practices 1019recompiling the model (or while running a simulation). Thus, tunable
parameters can be accessed and updated in real time.
• Use simple mathematical expressions when tunable parameters are
involved.
Figure 18.1 Rate-transition guidelines.
Figure 18.2 Tunable and nontunable parameters.
1020 Francesco Pace et al.• Do not set as tunable parameters the delay or sample time in the Simulink
blocks.
• Use external input to define index or initial conditions if tunable param￾eters are involved.
• Do not use callbacks in user-defined models.
• Protect all the division operation against the division by zero.
• Use only discrete models in the GNC SW.
• Define as atomic blocks the main functions of the GNC module. Use of
atomic subsystems to define the functions and modules maximizes the
architectural mapping between Simulink models and the produced C
code. Avoid inherited sample times (see Fig. 18.3).
• Use univocal names for the atomic blocks defined in the model. Do not
use reserved C words or operators or symbols for naming of the atomic
Figure 18.3 Atomic subsystem.
Autocoding best practices 1021blocks. Names of variables, in-port, out-port, bus objects, signals, and
atomic blocks (as well as Stateflow variables and constant names) shall not
use reserved C language words, operator, nor symbols.
• Use discrete data types (e.g., boolean, uint8) for parameters or variables
that define discrete states (i.e., indexes, flags)
• Define the initial value of blocks with internal states.
• Do not use Global “From/GoTo” blocks between the GNC OBSW
and the RW.
• When using nested enabled subsystems and the same output signal is
passed from a lower-level to a higher-level subsystem, the option
“Output when disabled” of the out-port shall have the same settings
(reset/held) throughout all the subsystems levels.
• The output of a triggered subsystem shall not be used if system is not
enabled. A switch outside the block should be implemented.
• Avoid unconnected signals in the model. This can cause functional errors
and problems with Embedded Coder. Use the “Terminator” block if
necessary.
• Include a function header for all the implemented functions.
• Avoid performing logical operations with numerical operation blocks.
• Set the library blocks (e.g., mathematical, GNC models, etc.) as atomic
subsystems, with explicitly specified interfaces for data type and
dimensions.
• Set the “Criteria for passing first input” on the switch block as “u2w¼0”
if the threshold signal (i.e., u2) is of Boolean type.
• Define all the data types for the parameters that are not of double data
type (e.g., index, flags, events, enumerated, etc.).
• Do not use variable size signals in GNC OBSW.
Strongly recommended
• Avoid the definition of input/output signals of library models through a
bus. In fact, each bus object shall be defined during the autocoding pro￾cess, and this increases the effort in preparing the models.
• Set the option “Saturate on integer overflow” for all the blocks that pro￾vide this option (e.g., Data Type Conversion, Difference, etc.) as in
Fig. 18.4.
• Avoid mux blocks and use vector concatenate instead, when possible.
• Use “From/GoTo” only within the same local view.
1022 Francesco Pace et al.Recommended
• Adopt a naming convention for all the blocks of the model.
• Define the name of all the signals entering an atomic subsystem.
• Label all the signal lines for improved traceability.
• Minimize the use of “Math Function” blocks for exponential operations.
• Avoid the usage of C “S-Function” blocks. Correspondent source C
code and Target Language Compiler files shall be used to generate
OBSW code.
Configuration parameters setup
Another important aspect before starting the autocoding process is to
correctly set the Simulink Configuration Parameters. In this paragraph, the
most important suggested parameters corresponding to the main fields are
summarized.
Figure 18.4 Saturate on integer overflow.
Autocoding best practices 1023Figure 18.5 Solver.
Figure 18.6 Diagnostics.
1024 Francesco Pace et al.Figure 18.7 Data validity.
Figure 18.8 Connectivity.
Autocoding best practices 1025• Solver. Use fixed-step solver and unselect “Treat each discrete rate as
separate task” as in Fig. 18.5.
• Diagnostic. Set parameters “Algebraic loop” and “Minimize algebraic
loop” to error. See Fig. 18.6.
• Data validity. Set “Underspecified data types” to warning, “Inf or NaN
block output” to error, and “Duplicate data store names” to error as in
Fig. 18.7.
• Connectivity. Set “Signal label mismatch” to warning, “Element name
mismatch” and “Nonbus signals treated as bus signals” to error, and
“Bus signal treated as vector” to warning as in Fig. 18.8.
Reference
[1] Guidelines for Automatic Code Generation for AOCS/GNC Flight SW Handbook,
ESA SAVOIR Working Group, 2021.
1026 Francesco Pace et al.Index
Note: ‘Page numbers followed by “f ” indicate figures and “t” indicates tables’.
A
A3C. See Asynchronous Advantage Actor
Critic (A3C)
Abramson model, 111e112
Absolute attitude navigation, 488e504
complementary filter, 502e504
Kalman filtering, 499e502
triad, 489e491
Wahba problem, 491e496
Absolute knowledge error (AKE), 620
Absolute orbit navigation, 470e488
GNSS spacecraft navigation, 471e480
Absolute performance error (APE), 620,
771
Absolute representation, 506e507
Acceleration-dependent bias, 313
Accelerometers, 306e310, 321e322
ACG. See Automated Code Generation
(ACG)
ACS. See Attitude control system (ACS)
Activation function, 834e835
Active debris removal (ADR), 504
Active redundancy configuration, 24
Actor-critic network, 899e901
Actuation functions, 339e340
magnetorquers, 372e373
multiple reaction wheels, 360e363
thrust management and, 347e353
Actuator (s), 16, 337, 544
control action constraint, 612
control moment gyros, 366e368
faults, 342e344
magnetorquers, 369e375
misalignments, 433e434
modeling for GNC, 338e344
errors modeling, 341e342
generic functional actuator model,
341f
generic performance actuator model,
342f
reaction wheels, 354e365
thrusters, 344e354
Adaptive control, 600e605. See also
Robust control
adaptive dynamical inversion, 603
additional parameters estimation, 604
convergence of parameters, 604
issues, 604e605
MRAC, 601e603
Adaptive Dynamical Inversion (ADI), 601,
603
ADCS. See Attitude Determination and
Control System (ADCS)
Additive EKF (AEKF), 499e500
Adjoint equations, 394
ADR. See Active debris removal (ADR)
Advantage Actor Critic (A2C), 900e901
Aerodynamic drag force, 245e246
Aerodynamic torque, 245e246
Aerospace optimization, 391
Agent algorithm, 823e824
AI. See Artificial intelligence (AI)
AIT. See Assembly Integration and Test
(AIT)
AIV/AIT. See Assembly Integration and
Verification/Assembly Integration
and Test (AIV/AIT)
AKE. See Attitude knowledge error (AKE)
Albedo, 247e248
emission, 93e94
Alexeev’s model, 99
AlexNet, 852e854
Allan variance (AVAR), 254, 317e321
random walk noise and bias values for
inertial sensors, 321t
Altimeters, 254, 330e334
altimetry principles, 331e332
model, 333e334
radar and laser altimeters, 332e333
radar vs. laser altimeter, 332t
Altimetry, 284
Altitude and Orbit Control system
(AOCS), 14, 636, 820
AOCS/GNC algorithms, 656e663
1027 jAltitude and Orbit Control system (AOCS)
(Continued )
architecture, 657e659
avionics delays, 659
GNC optimization, 661e662
modeling rules, 663
multirate, 659e660
requirements tracing, 661
tunable parameters, 660e661
Ampere’s circuital law, 369
Amplitude spectral density (ASD), 770
Analog sensor, 292
Analog sun sensors, 292e294
CSS, 292e294
FSS, 294
Analytical redundancy, 24
Angle random walk errors (ARW errors),
314
Angular acceleration, 422
vector, 427
Angular momentum, 230e231, 240e241
ellipsoid, 231e232
of rigid body, 230
Angular rate vector, 221
Angular velocity, 221e227, 422, 424
vector, 427
ANNs. See Artificial neural networks
(ANNs)
AOCS. See Altitude and Orbit Control
system (AOCS); Attitude and orbit
control system (AOCS)
APE. See Absolute performance error
(APE)
APF. See Artificial potential field (APF)
API. See Application programming
interface (API)
Application programming interface (API),
925
Application software level (ASW level),
657
Application-specific integrated circuit
(ASIC), 685, 693, 704e705
ARM-based ASIC CPU, 703e704
Architectural rules, 1018e1019
configuration parameters setup,
1023e1026
mandatory, 1019e1022
atomic subsystem, 1021f
rate-transition guidelines, 1020f
tunable and nontunable parameters,
1020f
recommended, 1023
strongly recommended, 1022
Argument of periapsis, 159
Artificial intelligence (AI), 686, 819
AI-based architectures, 4
and navigation, 867e883
on-board processors, 923e925
in space, 821e866
AI, ML, DL, and ANN, 821e822
applications scenarios and AI
challenges, 865e866
learning paradigms, 822e825
supervised learning, 826e843
types of artificial neural networks,
843e864
unsupervised learning, 825
use cases, 906e922
Artificial neural networks (ANNs),
821e822, 835. See also
Convolutional neural networks
(CNNs)
architecture used in space dynamics,
guidance, navigation, and control
domain, 867t
cost function for multiclass classification,
838
model representation, 835e838
for multiclass classification, 834e843
parameter learning, 839e843
types of, 843e864
universal approximation theorem,
834e835
Artificial potential field (APF), 780e783
active collision avoidance, 781e782
tracking controller, 782e783
ARW errors. See Angle random walk
errors (ARW errors)
ARX model. See Autoregressive
exogenous model (ARX model)
Ascending node rotation, right ascension
of, 66
ASD. See Amplitude spectral density
(ASD)
1028 IndexASIC. See Application-specific integrated
circuit (ASIC)
Assembly Integration and Test (AIT), 5,
936
Assembly Integration and Verification/
Assembly Integration and Test
(AIV/AIT), 5
ASW level. See Application software level
(ASW level)
Asymmetry scale factors, 267e268
Asymptotically stable solution, 549
Asynchronous Advantage Actor Critic
(A3C), 900e901
ATB. See Avionics Test Bench (ATB)
Atmospheres, 245
Atmospheric drag, 86e89
Atmospheric models, 88, 99
Atomic blocks, 1021
Attitude and orbit control system (AOCS),
4e5, 382, 626, 715e730
control types, 722e726
evaluation of criticalities, 719e720
modes, 721e722
sensors selection and actuators sizing,
726e730
and subsystem architecture, 717e719
system-level trade-offs, 720e721
criteria matrix, 721t
Attitude control system (ACS), 715e716,
742e773
control with magnetorquers, 757e758
control with reaction wheels, 753e756
detumbling, 743e745
effects of disturbances, 753
one-axis pointing, 745e749
robust attitude control of spacecraft with
two rotating flexible solar arrays,
759e773
solar panels pointing, 759, 760f
three-axis pointing, 750e753
Attitude Determination and Control
System (ADCS), 14e15, 820
Attitude dynamics, 9, 207e208, 227e248
attitude kinematics, 208e227
attitude stability, 235e239
dual spin dynamics, 239e241
environmental torques, 241e248
inertia matrix, 227e229
multibody spacecraft dynamics,
250e251
relative attitude dynamics, 249e250
rigid body dynamics, 230e235
of satellite, 234e235
three-body problem, 248e249
Attitude guidance, 423e431
one-axis pointing, 423e426
two-axis pointing, 426e427
Attitude kinematics, 208e227
attitude variation in time, 221e227
direction cosine matrix, 210e212
Euler angles, 212e215
Euler axis and angle, 215e217
quaternions, 217e221
Attitude knowledge error (AKE), 726
Attitude matrix, 232
Attitude navigation, 488e489
Attitude regulation example, 589e592
Attitude sensors, 286e306. See also Orbit
sensors; Electro-optical sensors;
Global navigation satellite system
sensors (GNSS sensors); Inertial
sensors; Sun sensors
horizon sensors, 298e300
magnetometers, 287e290
performance comparison, 306
typical order of magnitude of
performance for presented attitude
sensor, 307t
star sensors, 300e306
sun sensors, 291e297
Attitude sensors, 254
Attitude stability, 235e239
attitude stability of torque-free motion,
237t
Attitude variation in time, 221e227
angular velocity, 223e225
Euler angles kinematics, 225e226
quaternions kinematics, 226e227
Augmented states, 458
Augmented system model, 458
Autocoding, 8
architectural and implementation rules,
1017e1026
methodology, 668e671
Index 1029Automated Code Generation (ACG), 8,
1017
Automatic attitude control systems, 12
Automation, 31
Autonomicity, 31
Autonomous attitude determination, 302
Autonomous navigation, 441e442
Autonomous on-board sensor calibration,
796e800
Autonomous segmentation, 508
Autonomy, 31
Autoregressive exogenous model (ARX
model), 861
Auxiliary satellite body coordinate
systems, 62e63
AVAR. See Allan variance (AVAR)
Average pooling, 851
Avionics, 686
on-board processing, 694e700
spacecraft, 686e694
Avionics Test Bench (ATB), 659
Axis-angle, 388
Azimuth, 59
B
B-dot, 744e745, 746f
Background randomization, 888
Backpropagation, 839e843
Backward propagation, 839
Balancing, 955
Ballistic coefficient, 87
Barker’s equation, 149
BasseGura formula, 576
Batch estimation, 461e470
dynamic effects, 463e464
inclusion of priori information data,
466e467
least squares, 462e463
effect of observation errors, 464e465
problems in batch orbit determination,
467e469
square root information filter, 469e470
U-D filter, 470
Batch filtering, 443
Batch filters, 461e462
Batch learning, 842
Batch orbit determination
incorrect priori statistics and unmodeled
parameters, 468
numerical problems, 468e469
presence of nonlinearities, 467
problems in, 467e469
Bayesian approach, 455
Bayesian networks, 933
Bayesian problem, 456
Beam-limited sense, 331
Behavioral models, 255
BEIDOU, 278
Bessel functions, 171
Bias, 267
biasevariance trade-off model, 830
errors, 313
estimator, 459
instability, 951
errors, 313
repeatability, 313
Binary classification
cost function for, 834e843
logistic regression for, 831e834
Binary cross-entropy loss function, 833
BiriaeRusseleVinti method, 201
BLDC motors. See Brushless direct current
motors (BLDC motors)
Block redundant configuration, 24e25
Bode plot, 556
Bode’s integral formula, 581e582
Boundary value problem (BVP), 739
Brillouin sphere, 171
Broucke STM, 201
Brown noise, 270
Brownian noise, 270
Brushless direct current motors (BLDC
motors), 953
Bundle adjustment, 520e521
C
Calibration techniques, 267e268
Cameras, 254, 323e328, 507
applicability, 325e327
calibration, 519
camera-based approaches, 325e327
camera-to-mockup extrinsic calibration,
885e886
design, 327e328
1030 Indexintrinsic calibration, 885
matrix, 525
noise sources, 324t
relative motion of, 524e525
strengths and weaknesses, 328t
systems, 325e327
CAMs. See Collision Avoidance
Maneuvers (CAMs)
CAN. See Controller Area Network
(CAN)
Cannonball model, 90
Cardan angles, 213
Carrier phase, 471e472
measurements, 279
Cartesian models, 198
Cartesian orbital elements mapping,
203e204
Cartesian space, 781e782
Cartesian state, 389
Cartography, 302
Categorical cross-entropy cost function,
838
Celestial Intermediate Origin approach,
64e65
Celestial Intermediate Pole (CIP), 64
Celestial pole offsets, 65
Center of Mass (CoM), 229, 338e339
technique, 511e512
variation, 115e116
Central limit theorem, 272
Central processing unit (CPU), 432e433
Centralized filters, 505e506
Centroid detection, 511e512
Centroiding algorithm, 303e304
CFD. See Computational fluid dynamics
(CFD)
Chain codes, 510
Charge-coupled device (CCD), 323
Chebyshev coefficients, 96
Chebyshev interpolation, 97
Chebyshev polynomials, 96
Chronometers, 3
CIP. See Celestial Intermediate Pole (CIP)
CIRA models, 88
Circular object detection, 511e512
centroid detection, 511e512
limb detection and fitting, 512
Circular orbits, 142, 148e149
linearized equations of motion for nearly,
183e187
Circular relative orbit, 186e187
Circular Restricted Three-Body Problem
(CRTBP), 162e164, 167e169
Cislunar space, 161, 248
Classical control theory, 569
Classical equinox-based transformation,
64e65
Classical least square estimator formula,
477
Classical spacecraft GNC, brief historical
review of, 10e13
Clock bias, 483
Clock drift, 483
Clock errors, 482e483
Clock jitter, 483
ClohessyeWiltshire model (CeW
model), 183e184, 200, 203e204
ClohessyeWiltshireeHill equations,
571e572
Closed-loop
dynamics, 580
hand-eye calibration, 886e887
response, 558
stability, 548e549
system, 730e731
CMGs. See Control moment gyros
(CMGs)
CN. See Criticality number (CN)
CNNs. See Convolutional neural
networks (CNNs)
Coarse Sun sensors (CSS), 292e294
Coefficients computation, 96
Cold gas propulsion systems, 345
Cold redundancy design, 24
Collinear Lagrangian Points, 164
Collision avoidance constraint, 612e613
Collision Avoidance Maneuvers (CAMs),
345
Collocation methods, 395
CoM. See Center of Mass (CoM)
Commercial off-the-shelf (COTS), 941
components, 945e960
GNSS receivers, 952e953
inertial sensors, 950e951
Index 1031Commercial off-the-shelf (COTS)
(Continued )
magnetic torquers, 956e960
magnetometers, 946e947
or custom, 945e946
reaction wheels, 953e955
star trackers, 949e950
sun sensors and earth sensors, 947e949
Communication interfaces, 258
Complementary filter, 502e504
Complementary metal oxide
semiconductor (CMOS), 323
Complementary sensitivity function, 558
Computational constraints, 533, 537
Computational errors, 468
Computational fluid dynamics (CFD),
111e112
Computational power, 32e33
Computer vision (CV), 824e825
Concentric coplanar absolute orbit,
185e186
Conics, geometrical classification of,
140e143
Connectivity, 1025f, 1026
Constant bias, 313
Construct functional block diagram, 27
Consumer grade, 315
Continuation process, 166
Continuous single-step Kalman filter, 913
Contour-based shape representation, 510
Control, 16, 543e545
budgets, 618e625
design, 545e592
basic terminology, 545e546
in frequency domain, 552e568
for nonlinear systems, 584e592
properties of feedback control,
546e547
in state space, 569e581
error, 558
gain, 579
horizon, 611e612
implementation best practices, 626e629
limitations to control performance,
581e584
objective and performance, 547e551
closed-loop stability, 548e549
disturbance and measurement noise
rejection, 550
robustness to uncertainty, 551
static and dynamic performance,
549e550
review, 592e618
Control moment gyros (CMGs), 338, 363,
366e368, 724e725
pyramidal 4 CMGs configuration, 367f
strengths and weaknesses, 368t
Controllability, 551
Controllability matrix, 575e576
Controller, 544
Controller Area Network (CAN), 258
Convergence, 531e532
threshold, 531e532
Convex optimization method, 811
Convolution filters, 850e851
Convolutional neural networks (CNNs),
819, 845e859
image classification networks, 852e854
image segmentation networks, 854e855
object detection network, 856e859
for planetary landing, 917e920
validation, 884e888
camera intrinsic calibration, 885
camera-to-mockup extrinsic
calibration, 885e886
closed-loop hand-eye calibration,
886e887
error metrics, 887e888
Coordinate reference systems, 53e63
geocentric earth-fixed coordinate system,
55e57
geocentric equatorial coordinate system,
54e55
heliocentric coordinate system, 53e54
lunar coordinate systems, 59e60
satellite-based coordinate systems, 61e62
three-body synodic and inertial
coordinate systems, 60e61
LCROT, 60e61
topocentric coordinate systems, 57e59
topocentric equatorial, 57
topocentric horizon, 57e59
Coordinate reference systems, 45
Coordinate transformations, 45, 63e68
1032 IndexECI to ECEF, 64e65
ECI to PQW, 66e67
ECI to RSW, 67e68
Coordinated Universal Time (UTC), 70
Coordinates of pole, 65
Coordinates transformation, 193e195
Coplanar maneuvers, 733e735
Coriolis vibratory gyros, 311
Correction process, 166e167
Cosine detectors, 948
Cosmic velocities, 143e146
Cost function, 826e827, 833
for binary classification, 834e843
for multiclass classification, 838
Cotangential transfer, 412e414
COTS. See Commercial off-the-shelf
(COTS)
Coulomb friction, 357
Coupled Ordinary Differential Equations,
107
Covariance
computation, 879e882
factorization of sequential filters, 536
prediction, 448
Cowell’s formulation, 154e155
CPU. See Central processing unit (CPU)
Crater pattern matching algorithm, 812
Criticality number (CN), 28
Cross product operation, 38e39
Cross-coupling errors, 314e315
CRTBP. See Circular Restricted Three￾Body Problem (CRTBP)
CSS. See Coarse Sun sensors (CSS)
CubeSats, 938e971
Cubic Hermite spline, 422
Customer requirements, 36e37
CV. See Computer vision (CV)
CeW model. See ClohessyeWiltshire
model (CeW model)
Cycle slip, 472
D
D4PG algorithm. See Distributed
distributional deep deterministic
policy gradient algorithm (D4PG
algorithm)
Data arc, 487
Data averaging, 318
Data clustering, 318
Data collection, 318
Data handling (DH), 686
Data loss fault, 275
Data processing unit (DPU), 692
Data validity, 1025f, 1026
Data-driven techniques for implementing
FDIR systems in GNC
applications, 931e934
Davenport method, 495
Davenport q-method, 493e495
Day-in-the-life test, 971
DCM. See Direction Cosine Matrix
(DCM)
Decentralized filters, 505
Decision boundary, 832
Decision-making method, 634
Declination, 55
Deep learning (DL), 819, 821e822
Deep neural networks (DNNs), 821e822
Deep Q-learning network, 897e899
Deep Q-network (DQN), 898e899
Deep reinforcement learning
algorithms, 897e903
advantage actor-critic network,
899e901
model-based reinforcement learning,
902e903
PPO algorithm, 901e902
Q-learning and deep Q-learning
network, 897e899
for uncooperative objects fly around and
planetary exploration, 920e922
meta-reinforcement learning,
921e922
Deep Space Network, 285
Degree of Freedom control (DoF control),
347
Delaunay elements, 390
Delay margin, 557
Delphi Deep Neural Network
Development Kit (DNNDK), 925
Delta Differential One-way Range
(DDOR), 484e485
Desaturation control, 755e756
Detection, 634
Index 1033Detection number (DN), 28
Detumbling, 373e374, 743e745
B-dot, 744e745
classic, 743
Development workflow for data-driven
FDIR systems, 934e936
Deviation angle, 114e115
DH. See Data handling (DH)
Dhrystone million instructions per second
(DMIP), 707e708
Diagnostic parameters, 1024f, 1026
Diagonal matrix, 984
Digital elevation map (DEM), 813
Digital sensor, 292
Digital signal processors (DSPs), 685,
688e689
Digital Sun sensors, 295e296
Direct methods, 395, 739
Direction Cosine Matrix (DCM), 208,
210e212, 387
Discrete parameters modeling, example of,
103e106
Discrete-time systems, 1009e1011
Distributed distributional deep
deterministic policy gradient
algorithm (D4PG algorithm),
920e921
Distributed parameters, 102
example of distributed parameters
modeling, 106e108
Disturbance, 550
rejection, 561e563
DKE model. See Dynamics and kinematic
environment model (DKE model)
DL. See Deep learning (DL)
DLR. See German Aerospace Agency
(DLR)
Doppler, 279, 283e284
measurements, 472e473
DP. See Dynamic programming (DP)
Drag coefficient (cD), 86
Drag compensation control, 741
Drift fault, 275
Drift modulation transfer, 418
Dry tuned-rotor gyros (DTGs), 310e311
Dual spin dynamics, 239e241
Dynamic attitude determination, 489, 499
Dynamic imbalances, 121, 359
Dynamic programming (DP), 895e896
Dynamical equations, 232, 396
Dynamical models, 507, 533e534, 537
Dynamical system, 386
discrete-time systems, 1009e1011
state-space models, 1007e1009
theory, 8
transfer functions, 1011e1015
Dynamical time, 69
Dynamics acceleration reconstruction,
909e915
Dynamics and kinematic environment
model (DKE model), 659
E
Earth Gravitational Models (EGMs), 47
Earth Gravity Model 08 (EGM-08),
84e85
Earth Gravity Model 96 (EGM-96), 84
Earth magnetic field, 117
Earth models, 45e53. See also Planetary
models
geoid and geopotential models, 52e53
position representation, 48e52
Earth orientation model, 64e65, 1002
Earth Orientation Parameters (EOPs), 65
Earth rotation angle, 64
Earth sensors, 947e949
Earth-based methods, 3
Earth-centered Earth-fixed (ECEF), 52,
64e65, 282e283
ECI to, 64e65
reference frame conversion, 983
spherical coordinates, 56e57
Earth-centered inertial (ECI), 52,
282e283, 983
ECI-ECEF transformation, 1002e1005
nutation, 1004e1005
polar motion, 1003e1004
precession, 1005
relevant parameters for ECI/ECEF
rotations, 1003t
sidereal time, 1004
ECI-fixed attitudes, 943
frame, 429
to PQW, 66e67
1034 Indexto RSW, 67e68
spherical coordinates, 55
Earth’s equator, 54
Earth’s radius, 46
Earth’s rotational velocity, 47
East, North, Zenith (ENZ), 59
East longitude, 57
Eccentric anomaly, 150e151
Eccentricity, 157
vector, 134e135
Eclipse, 92e93
EGNOS, 278
Eigenvectors, 988e990
Eight-point algorithm, 524
Electric propulsion (EP), 944
Electrical ground support equipment
(EGSE), 677
Electrical jitter, 356
Electro-optical sensors, 254, 322e329.
See also Inertial sensors; Attitude
sensors; Global navigation satellite
system sensors (GNSS sensors);
Orbit sensors; Sun sensors
cameras, 323e328
LIDAR, 328e329
Electromagnetic disturbances, 117e118
Electromagnetic induction, 342
Elevation, 59
Ellipsoidal model (ELL), 172e173
Elliptic orbits, 150e151
Elliptic Restricted Three-Body Problem
(ERTBP), 162, 164e166,
169e170
Embedded hard processor, 703
End-to-end
approaches, 917
systems, 874
Energetic analysis, 143e146
Energy-matching condition, 196e198
Entry, Descent, and Landing (EDL), 806
Environment, 16e17
Environmental torques, 241e248
aerodynamic torque, 245e246
gravity gradient torque, 241e244
magnetic torque, 244e245
solar radiation pressure torque, 246e248
Ephemerides, 95e97
Chebyshev interpolation, 97
Chebyshev polynomials, 96
coefficients computation, 96
error, 483
Epipolar geometry, 521e523
ε-greedy policy, 897e898
Equations of motion, linearization of,
177e182
Equatorial coordinate system (ECI), 57
Equilateral Lagrangian Points, 164
Equinoctial elements, 390
Erratic fault, 275
Error
bias, 267
function, 826e827
metrics, 887e888
misalignment and nonorthogonality,
273e274
modeling, 266e274
noise and random, 268e272
random errors with uniform
distribution, 272
output saturation, temporal discretization,
and latencies, 274
quantization, 272e273
scale factor, 267e268
Essential matrix, 523
Estimation error, 529e531
Estimator gain matrix, 466
ESTRACK, 285
Euler angles, 212e217, 387e388
kinematics, 225e226
Euler axis, 212, 215e217
Euler dynamical equations, 248e249
Euler equation, 232e235, 248e249, 388,
497, 743
Euler’s equation, 423
Euler’s theorem, 215
European Cooperation for Space
Standardization (ECSS), 97,
556e557, 632, 648, 705, 866
standards, 97
European ECSS Space Segment
Operability Standard, 35, 384
European Improved Gravity model of
Earth by New techniques 04
(EIGEN-GL04C), 84
Index 1035European Proximity Operations Simulator
(EPOS), 883e884
European Space Agency (ESA), 619, 632,
878e879
European space missions, implementation
in, 641e642
European Space Research and
Technology Centre (ESTEC),
883e884
Experience replay, 899
Exploding gradients, 841e842
Exponential model, 88e89
Extended Kalman filter (EKF), 450e452
Extended normalization algorithm, 426
Extended vector normalization, 427
External perturbations, 77, 79e97. See also
Internal perturbations
atmospheric drag, 86e89
ephemerides, 95e97
gravitational models, 84e85
gravity field of central body, 80e84
magnetic field, 85e86
modeling guidelines, 97e100
atmospheric models, 99
gravity, 97e98
magnetic field, 98e99
solar radiation, 99e100
third-body perturbation, 100
modeling guidelines, 77
solar radiation pressure, 89e94
third-body perturbation, 94e95
Extrinsic camera calibration matrix,
518e519
F
FAI. See Functional after integration (FAI)
Failure Detection, Isolation and Recovery
system (FDIR system), 631e632,
706e707, 716, 819
challenges and next steps for industrial
implementation of advanced FDIR
systems, 936e938
concept and functional architecture in
GNC applications, 642e645
data-driven techniques for implementing
FDIR systems in GNC applications,
931e934
development process and industrial
practices, 637e639
development workflow for data-driven
FDIR systems, 934e936
hierarchical architecture and operational
concepts, 639e641, 639f
implementation in European space
missions, 641e642
innovative techniques for highly
autonomous FDIR in GNC
applications, 820, 925e938
model-based methods for implementing
FDIR systems in GNC applications,
929e931
in space missions, terms, and definitions,
633e637
system, 17
conception, 27
evolution, 927e929
hierarchical architecture, 639e641
terms and definitions, 636e637
verification and validation approach, 642
Failure detection and isolation (FDI), 794
Failure detection method, 28
Failure mode effect, 28
Failure Mode Effects and Criticality
Analysis (FMECA), 27, 636
analysis approach, 27
Fault detection and diagnosis (FDD),
929e930
Fault Tree Analysis (FTA), 27, 638e639
Fault-tolerant control (FTC), 929e930
Fault-tolerant guidance (FTG), 929e930
Feature engineering, 828e829
Feature-matching approaches, 904e906
Feedback control, properties of, 546e547
Feedback linearization, 586e587
Feedforward
design, 567e568
term, 579e580
torque, 423
Ferromagnetic core torquers, 956
Field programmable gate array (FPGA),
689e691, 702e703
and hard-IP processor, 703
multi-FPGA, 703
single, 702
1036 Indexsoftcore processor, 703
in space, 691e693
Field-of-view scans (FOV scans), 298, 777
Filter robustness, 529e531
Filter smugness, 459
Filtering process, 446e447
Fine Sun sensors (FSS), 292, 294
Finite elements methods (FEMs), 86, 103
Finite State Machine (FSM), 30, 722
Finite-horizon linear quadratic regulator,
597e598
First-order differential equations,
1007e1008
Flexibility of internal perturbations,
101e111
Flexible appendages, 101e102, 251
Flexible spacecraft, 759
Flicker noise, 270
Fluxgate magnetometers, 288e289
Forced motion, 420e423
Formation flying (FF), 445
Forward propagation, 839
Fourier transforms, 510
François Vieta’s Method, 149
Frequency domain
control design in, 552e568
feedforward design, 567e568
loop-shaping design, 563e567
sensitivity functions, 557e563
stability and stability margins, 552e557
Friction
jumps, 358
and microvibrations, 357e360
general kinetic friction model, 358f
reaction wheels waterfall plot, 360f
Frobenius norm, 987
Froude number, 111e112
Full functional tests (FFTs), 677
Fully neural dynamics learning, 907e909
Functional actuator models, 340
Functional after integration (FAI), 677
Functional engineering simulator (FES),
657e658, 1018
Functional models, 255
Functional requirements, 432
Functional sensor models, 256
Fundamental matrix, 521
estimation, 524
eight-point algorithm, 524
seven-point algorithm, 524
G
Gain
crossover frequency, 583
curve of open-loop transfer function,
565e566
margin, 555e556
scheduling, 586
Galileo, 147, 278
GAM STM, 201
Gang of four, 558
Gauss Variational Equation, 199
Gaussian random variables, 263
Gaussian Variation of Parameters
(Gaussian VOPs), 155e159
GausseNewton method, 827
Gemini 6 spacecraft, 12e13
General Kinetic Friction (GKF), 358
Generalization test, 829e830
Generalized frequency, 1011
Generic discrete-time system, 1009e1010
Geocentric Celestial Reference Frame
(GCRF), 55
Geocentric Earth-fixed coordinate system,
55e57
Geocentric equatorial coordinate system,
54e55
Geocentric latitude, 50, 57
Geodesy, 46
Geodetic latitude, 50
Geoid models, 52e53
Geoid’s undulation, 52
Geometric boundary-based features, 510
Geopotential models, 52e53
Geostationary Earth orbit (GEO), 79e80,
280
Geostationary EasteWest control,
741e742
Geostationary NortheSouth control, 741
Geosynchronous/geostationary orbits
(GEO), 147, 278
German Aerospace Agency (DLR),
883e884
GimeAlfriend STM, 201
Index 1037Global methods, 509
Global navigation satellite system sensors
(GNSS sensors), 47, 253, 277e283.
See also Orbit sensors; Attitude
sensors; Electro-optical sensors; Sun
sensors
accuracy, 281, 282t
basics, 277e279
error effects, 473e474
Earth tidal effects, 474
Ionospheric effects, 473
Multipath effects, 474
Relativistic effects, 474
Tropospheric effects, 473e474
typical GNSS errors and uncertainty,
475t
GNSS-processed measurements,
478e479
ground-based orbit determination,
484e488
model, 282e283
multiconstellation GNSS receivers,
281e282
navigation approaches, 475e480
precise orbit determination, 477e478
precise point positioning, 476
real-time navigation, 478e480
observables, 471e473
carrier phase, 471e472
Doppler measurements, 472e473
pseudorange, 471
pulsar-based spacecraft navigation,
480e483
raw measurements, 479
receivers, 280e281, 952e953, 965
signals, 279e280
spacecraft navigation, 471e480
Global Navigation Satellite System￾Inertial Navigation System
(GNSS-INS), 716
integration, 479e480
architecture, 480
for on-board orbit determination,
800e802
Global navigation systems, 278
Global Positioning System (GPS), 57, 147,
278, 441e442
GLONASS, 147, 278
GMT. See Greenwich mean time (GMT)
GNC. See Guidance, Navigation, and
Control (GNC)
GNC Rendezvous, Approach and
Landing Simulator (GRALS),
883e884
GPUs. See Graphics processing units
(GPUs)
Gradient descent (GD), 827, 839e843
Graphics processing units (GPUs), 685,
689, 870e872
Gravitational field, 82
Gravitational models, 84e85
Gravitational potential, 80
Gravity field of central body, 80e84
Gravity gradient torque, 241e244
Greenwich mean time (GMT), 70
Ground segment, 285
Ground station networks (GSNs), 277,
285
Ground track maintenance, 741
Ground truth (GT), 826
Ground-based control system, 32e35
Ground-based guidance, 382e385
Ground-based navigation, 443e445
Ground-based orbit determination,
484e488
accuracy, 285
ground-based OD strengths and
weaknesses, 286t
ground-based orbit determination
accuracy, 286t
filter list example in standard orbit
determination filter, 487t
techniques, 283e285
ground segment, 285
ground-based orbit determination
accuracy, 285
space segment, 285
Guidance, 15, 381e382
applications, 385e437
design of guidance function, 431e437
design process, 385e431
attitude guidance, 423e431
and control strategy, 779e789
artificial potential field, 780e783
1038 Indeximpulsive, 779e780
model predictive control, 783e787
optimal control, 787e789
design of guidance function, 431e437
architecture, 435e437
function library, 437
guidance modes, 434e435
identification of guidance
requirements, 431e434
design process, 385e431
general design approach, 385e386
guidance representations, 387e390
implementation best practices, 438
interpolation, 398e402
modes, 434e435
on-board vs. ground-based guidance,
382e385
optimization, 391e397
classical formulation of optimal control
problem, 392e395
indirect methods vs. direct methods,
395
trajectory optimization methods,
395e396
rendezvous guidance, 402e423
system, 382
understanding dynamical system, 386
Guidance, Navigation, and Control
(GNC), 3e4, 73e75, 124e126,
212, 253, 337, 382, 441e442, 633,
648e652, 715, 819, 983, 1007,
1017
AI
in space, 821e866
on-board processors, 923e925
use cases, 906e922
algorithms, 685
anomalies, 26e28
architecture, 15e37
attitude control system, 742e773
COTS components, 945e960
design process, 18e20
effects
on dynamics and, 108e111, 116e117
on GNC chain, 532e533
innovative techniques for highly
autonomous FDIR in GNC
applications, 925e938
irregular solar system bodies fly around,
803e805
MIL test, 656e667
mode management, 22, 29e35
automation, autonomy, and
autonomicity, 31
mode transition and finite state
machine, 30
on-board vs. ground-based, 32e35,
35te36t
model-based, 1017
notation rules, 38e42
notation table, 39
on-board sensor processing, 791e802
orbital control system, 730e742
for planetary landing, 806e814
planetary landing guidance, 806e814
preliminary design, 36e37
reinforcement learning, 890e906
relative, 775e791
requirements, 20e21
operational requirements, 20
performance requirements, 21
verification requirements, 21
sensor modeling for, 254e274
elements of metrology, 257e260
errors modeling, 266e274
probability and stochastic processes,
261e265
random variables, 261e263
sensor calibration, 265e266
stochastic processes, 264e265
SIL/PIL test, 667e676
small satellites/CubeSats, 938e971
statistical methods, 652e655
subsystem design, 18e26, 1017
GNC modes, 21e22
mission life cycle, 25t
mission phases, 25e26
steps, 19te20t
system redundancy, 24e25
system, 77e78, 257
example, 960e966
GNSS receiver, 965
inertial measurement unit, 963
magnetometers, 964
magnetorquers, 966
reaction wheels, 965e966
Index 1039Guidance, Navigation, and Control (GNC)
(Continued )
star trackers, 964
sun sensors, 963e964
terminology, 13e15
types of artificial neural networks,
843e864
validation of AI-based systems, 883e890
verification activities at MIL level,
663e667
verification and testing limitations,
966e971
hardware functional tests, 970e971
hardware performance tests, 969e970
hardware-in-the-loop, 971
software-in-the-loop, 968e969
Gyroscope (GYRO), 306e309, 768
model, 321e322
technology, 310e311
H
H-infinity, 605e607
HN filter, 450
Hall effect sensors, 356
Hardover/bias fault, 275
Hardware (HW), 635
algorithm, 718
performance tests, 969e970
process, 820
Hardware description language (HDL),
689e691
Hardware-in-the-loop tests (HIL tests),
647, 677e682, 971
for hardware verification, 678e680
for software verification, 680e682
Hazard avoidance method, 814
Health management systems, 631
Heatmaps, 872e873
Heliocentric coordinate system, 53e54
Hermite spline, 400e401
Herpolhode, 231e232
Heuristic methods, 739
Hidden layers, 836
High Earth orbit (HEO), 281
HilleClohessyeWiltshire model (HCV),
200
Homography, 513
projective transformations, 514t
Hopfield neural network (HNN),
862e863
Horizon sensors, 298e300
strengths and weaknesses, 300t
Horizon-crossing indicators, 948
Hot redundancy configuration, 24
Hubble Space Telescope, 652
Hybrid approaches, 917
Hydrostatic equations, 87e88
Hyperbolic orbits, 152
Hyperbolic tangent, 837
Hyperbolic trajectories, 142
Hyperparameters, 830
I
Ideal gas law, 87e88
Identity matrix, 984
Image classification networks, 852e854
Image processing (IP), 527e528,
867e868
segmentation, 507
global methods, 509
local methods, 508e509
and spacecraft navigation, 527e528
from subpixel to resolved object,
525e527
few tenths of pixels, 526
resolved object, 527
subpixel, 526
techniques, 507e528
3D vision, 512e521
two-views geometry, 521e525
2D shape representation, 509e512
Image segmentation, 509e510
networks, 854e855
Implementation rules, 1019e1023
configuration parameters setup,
1023e1026
mandatory, 1019e1022
recommended, 1023
strongly recommended, 1022
Impulsive guidance, 779e780
Impulsive maneuvers, 410e420, 731e733
Impulsive shots, 187
Impulsive trajectories, 410e420
In-orbit test (IOT), 649, 682e683
1040 IndexIn-plane state transition matrix, 406
In-run stochastic variations, 317e318
Inclination, 157e158
rotation, 66
Inclusion of priori information data,
466e467
Incremental learning, 842e843
Indirect methods, 395, 739
Inductive kickback/recirculation, 955
Industrial grade, 315
Inertia ellipsoid, 231e232
Inertia matrix, 227e229, 238e239
Inertia moments, 228
Inertia tensor, 228
Inertia wheel, 753e754
Inertial coordinate systems, 60e61
Inertial Measurement Unit (IMU),
306e307, 918, 963
Inertial Navigation System (INS),
479
Inertial sensors, 254, 306e322, 950e951.
See also Sun sensors; Attitude
sensors; Electro-optical sensors;
Global navigation satellite system
sensors (GNSS sensors); Orbit
sensors
Allan variance and statistical error
representation, 317e321
error sources, 312e315
gyroscope model, 321e322
performances, 315e316
sensor grades and navigation
performance after 1h of propagation,
317t
technology, 308
Infinite-horizon linear quadratic regulator,
598
Infrared (IR), 93e94
emission, 93e94
radiation, 93e94
Initial attitude scattering, 653
Input layer, 836
Input range limits, 315
Integral action, 580e581
Integral quadratic constraints (IQCs), 650
Integrals of motion, 134e136
eccentricity vector, 134e135
specific angular momentum, 134
specific energy, 135e136
Inter-Integrated Circuit (I2C), 258
Interface and functional tests (IFTs), 677
Internal geomagnetic field, 99
Internal Geomagnetic Field Model
(IGRF), 47
Internal perturbations, 77e78, 100e122
electromagnetic disturbances,
117e118
flexibility, 101e111
effects on dynamics and GNC,
108e111
example of discrete parameters
modeling, 103e106
example of distributed parameters
modeling, 106e108
internal vibrations, 118e121
reaction wheel jitter, 119e121
modeling guidelines, 78, 123e124
parasitic forces and torques due to plume
impingement, 121e122
parasitic forces and torques during
thrusters firing, 113e117
center of mass variation, 115e116
deviation angle, 114e115
effects on dynamics and GNC,
116e117
thrust magnitude accuracy, 116
sloshing, 111e113
thermal snap, 122
Internal vibrations, 118e121
International Association of
Geomagnetism and Aeronomy
(IAGA), 86
International Astronomical Union (IAU),
53e54
International Atomic Time (TAI), 69e70,
1002
International Celestial Reference Frame
(ICRF), 53e54
International Earth Rotation and
Reference Systems Service
(IERS), 55
International Geomagnetic Reference
Field (IGRF), 85
International standards, 123
Index 1041International Terrestrial Reference Frame
(ITRF), 55e56
Interplanetary reference system, 53e54
Interpolation, 398e402
coefficients, 428
formulas, 399
inverse, 399e400
methods for tabulated data, 400t
spline, 400e402
tabulated data and finite differences, 399t
Inverse interpolation, 399e400
Inverse matrix, 412
Inverse reinforcement learning, 903e906
feature-matching approaches, 904e906
maximum entropy, 906
Irregular solar system bodies, 170e174,
803e805
ellipsoidal model, 172e173
mass concentration model, 173
POL, 174
SHE model, 170e171
Irregular solar system bodies, 132
Isolation, 634
J
J2-perturbed relative dynamics, 189e190
J2000, 55
Jacchia models, 88e89
Jacobian matrix, 168
Jerome Cardan’s Method, 149
Jitter, 119e120
Joint Gravity Model-3 (JGM-3), 84
Joseph form of sequential filters, 536
Julian dates (JD), 45, 71e73
K
K-means
algorithm, 823, 921
clustering, 825
Kalman filter(ing) (KF), 448e450,
499e502
approach, 500e501
KalmaneBucy filter, 600
Karl Stumpff’s Method, 149
Karnopp model, 365
Keep-out-zone, 785
Keplerian orbital elements, 389
Keplerian orbital motion, 78
Kepler’s First Law of Planetary Motion,
137
Kepler’s second law of planetary motion,
136
Keypoints detection network, 879
Keypoints-based CNN, 877
KGD STM, 201
Kinetic energyellipsoid, 231e232
Knowledge drift error (KDE), 621
Knowledge reproducibility error (KRE),
621
Known object, 527
L
Lagrange equation, 103e104
Lagrange point, 132
Lagrangian formalism, 106
Lagrangian function, 104
Lagrangian points, 163
station-keeping control, 741e742
Lambert’s problem, 736e737
Landmarks, 3
Laplace transform, 1011
Laser altimeters, 332e333
Laser scanners, 329
Laser-based sensors, 332e333
Latencies, 274
Latency, 315
Latitude, 48e49
Launchand Early Operation (LEOP), 682
Layer-recurrent neural network, 908
LCI. See Lunar-Centered Inertial (LCI)
LCROT. See Lunar Centered ROTating
(LCROT)
Learning rate, 827e828
Least squares, 462e463
Legendre’s polynomials, 81, 171
Length of Day, 65
LEO. See Low Earth orbit (LEO)
LEON processor, 923e924
LevenbergeMarquardt algorithm, 827,
909, 515
LevenbergeMarquardt curve-fitting
algorithm, 827
Light detection and ranging (LIDAR),
328e329, 804, 921e922
1042 Indexprocessing, 686
strengths and weaknesses, 330t
systems, 254, 504e505
Light randomization, 888
Limb detection, 512
Limb fitting, 512
Linear discrete-time system, 448
Linear Fractional Transformation (LFT),
606
Linear Quadratic Regulator (LQR), 544,
596e600
finite-horizon linear quadratic regulator,
597e598
infinite-horizon linear quadratic
regulator, 598
linear quadratic Gaussian control,
598e600
Linear regression, 826e830, 833
cost function for regression,
826e827
feature engineering and polynomial
regression, 828e829
generalization, 829e830
model representation, 826
parameter learning, 827e828
Linear scale factors, 267e268
Linear system, 396
Linear time-invariant systems (LTI
systems), 545, 1008, 1011
Linear-based model, 650
Linearization, 584e585
of equations of motion, 177e182
process, 180
Linearized equations of motion, 179
for nearly circular orbits, 183e187
Linearized relative dynamics, true anomaly
parametrization in, 179e182
Linearized relative motion models, 390
Load sensitivity function, 558
Local methods, 508e509
Local Vertical, Local Horizontal (LVLH),
61, 175, 243, 299e300, 429e431
frame, 403, 571e572
LVLH-fixed attitudes, 943
Logistic function. See Sigmoid function
Logistic regression, 824e825
for binary classification, 831e834
cost function for binary classification,
833e834
model representation, 831e832
Long short-term memory (LSTM), 842,
863e864
Longitude, 48e49
Loop-shaping design, 563e567
Loosely coupled architecture, 527e528
Loss augmentation, 905
Low Earth orbit (LEO), 14, 79e80, 147,
277, 652, 693, 717, 820
Low-thrust maneuvers, 731e733
Low-thrust trajectory design, 737e740
orbit-raising low-thrust trajectory
solution, 740f
Lower triangular matrix, 984
Luna-3 soviet space probe, 11
Lunar Centered ROTating (LCROT),
60e61
Lunar coordinate systems, 59e60
mean earth/polar axis, 59
PA, 59e60
Lunar-Centered Inertial (LCI), 59
Lyapunov functions, 584, 588, 743,
913e914
Lyapunov stability
theorem, 782
theory, 809e810
Lyapunov theorem, 591e592
Lyapunov’s indirect method, 585
M
Machine learning (ML), 819, 821e822
Magnetic dipole moments, 373
Magnetic field, 85e86, 98e99
Magnetic moment, 956
Magnetic potential, 85
Magnetic torque, 244e245
Magnetic torquers, 956e960
Magnetometers, 287e290, 321e322,
946e947, 964, 969
calibration, 798
strengths and weaknesses, 291t
Magnetoresistive sensors, 288
Magnetorquers, 338, 369e375, 966
actuation function, 372e373
assembly, 370e372
Index 1043Magnetorquers (Continued )
control, 757e758
single-axis magnetic control example,
758f
model, 375, 375f
performance, 373e374
Mahalanobis distance. See Standardized
distance
Maneuver calculation algorithms, 437
ManeMachine Interface (MMI),
678e679
Maritime navigation, 10e11
Markov decision process (MDP), 892
MasCon. See Mass Concentration
(MasCon)
Mass Concentration (MasCon), 173
Mass concentration model, 173
Mass-spring mechanical models, 111e112
Mathematical altimeter model, 254
Mathematical gimbal set, 308
Mathematical tools, 510
MathWorks Automotive Advisory Board
(MAAB), 666
MATLAB/Simulink environment, 375,
660e661, 1017
Matrix/matrices, 38
algebra, 983e991
eigenvectors, 988e990
frobenius norm, 987
matrix inversion, 986e987
matrix multiplication, 985e986
matrix rank, 987e988
singular value decomposition,
990e991
square matrices, 984
inversion, 986e987
analytical computation, 986e987
multiplication, 985e986
properties, 985e986
rank, 987e988
Max pooling, 851
Maximum entropy, 906
Maximum likelihood estimation, 515
MBSE paradigm. See Model-based system
engineering paradigm (MBSE
paradigm)
MCU. See Microcontroller unit (MCU)
MDP. See Markov decision process
(MDP)
Mean absolute error (MAE), 529
Mean anomaly, 137
Mean earth/polar axis, 59
Mean Earth/Polar Axis reference system
(ME reference system), 59
Mean Earth/Rotation Axis system (MER
system), 59
Mean equator of Date frame (MOD
frame), 64
Mean knowledge error (MKE), 620
Mean performance error (MPE), 621
Mean sea level (MSL), 52
Mean squared error (MSE), 826e827
Measurement bias, 267
Measurement errors, 259
Measurement models, 537
Measurement noise, 563
rejection, 550
Mechanical gyroscopes, 313
Medium Earth orbits (MEO), 147e148,
278, 280
Medium-Angle Camera (MAC),
325e327
MEKF. See Multiplicative EKF (MEKF);
Multiplicative extended Kalman
filter (MEKF)
Meta-reinforcement learning (meta-RL),
920e922
Metrology, elements of, 257e260
Microcontroller unit (MCU), 687e688
Microelectromechanical systems (MEMS),
289, 941e942
MIMO. See Multi-input-multi-output
(MIMO)
Mini-batch learning, 842
Minimum Impulse Bit (MIB), 350
Misalignment errors, 273e274, 315
MISRA. See Motor Industry Software
Reliability Association (MISRA)
Mission and Spacecraft Management
system (MSM system), 17
Mission and Vehicle Management
(MVM), 17
Mission and vehicle manager, 643e644
Mission phases, 25e26
1044 IndexMission requirements, 36e37
MKE. See Mean knowledge error (MKE)
ML. See Machine learning (ML)
MMI. See ManeMachine Interface
(MMI)
MOD frame. See Mean equator of Date
frame (MOD frame)
Modal Coordinates, 108
Mode manager, 33e34
Model capacity, 830
Model Predictive Control (MPC), 544,
609e616, 783e787
Model Reference Adaptive Control
(MRAC), 601e603
Model-based methods for implementing
FDIR systems in GNC
applications, 929e931
Model-based reinforcement learning,
902e903
Model-based system engineering
paradigm (MBSE paradigm),
927e928
Model-in-the-loop (MIL test), 647,
656e667
modeling of AOCS/GNC algorithms,
656e663
verification activities at, 663e667
algorithms verification and validation,
664
model coverage verification, 666e667
modeling standards verification,
665e666
models profiling, 665
requirements verification, 664e665
Modeling, 1007
Modern spacecraft GNC, 3e10
Modified equinoctial elements, 390
Modified Julian Date (MJD), 72
Modified Rodrigues parameters, 388
Moments of inertia, 228
Momentum capacity, 953
Monte Carlo methods (MC methods),
895e896
analysis, 653
simulations, 650
MooreePenrose generalized inverse,
361e362
Motion, integrals of, 134e136
Motor Industry Software Reliability
Association (MISRA), 666
MPC. See Model Predictive Control
(MPC)
MPE. See Mean performance error (MPE)
MRAC. See Model Reference Adaptive
Control (MRAC)
MSE. See Mean squared error (MSE)
MSL. See Mean sea level (MSL)
MSM system. See Mission and Spacecraft
Management system (MSM
system)
Mu-control, 607e608
Multi-input-multi-output (MIMO),
1007e1008
Multibody spacecraft dynamics, 250e251
Multiconstellation GNSS receivers,
281e282
GNSS strengths and weaknesses, 282t
Multilayer perceptron (MLP), 824e825,
835
Multiple impulse transfer, 418e419
Multiple shooting method, 396
Multiplicative EKF (MEKF), 499e500
Multiplicative extended Kalman filter
(MEKF), 875e876
MVM. See Mission and Vehicle
Management (MVM)
N
Narrow-Angle Cameras (NAC), 325e327
Navigation, 10, 16, 441e443
absolute attitude navigation, 488e504
absolute orbit navigation, 470e488
AI and, 867e883
AI-based relative pose estimation,
869e874
interface with navigation and
uncertainty estimate, 874e877
keypoints regression architecture,
878e883
pose estimation, 867e869
batch estimation, 461e470
budgets, 528e533
convergence, 531e532
effect on GNC chain, 532e533
Index 1045Navigation (Continued )
estimation error and filter robustness,
529e531
camera design, 327e328
constellations, 147
filters tuning, 538e540
grade, 315
image processing techniques, 507e528
implementation best practices,
533e540
design, implementation, tuning, and
useful checks for sequential filters,
534e536
navigation filters tuning, 538e540
right batch filter, 537e538
right sequential filter, 533e534
measurement model, 481e482
on-board vs. ground-based navigation,
443e445
relative navigation, 504e507
sequential filters, 445e461
Net force, 247
Neural dynamics reconstruction through
neural networks, 906e917
dynamics acceleration reconstruction,
909e915
fully neural dynamics learning, 907e909
parametric dynamics reconstruction,
915e917
Newton’s laws, 131
Newton’s third law of motion, 342,
354e355
Nichols plot, 773
Noise
amplitude, 271
density, 271
errors, 268e272, 313e314
measurement rejection, 563
modeling, 270e271
sensitivity function, 558
Nondimensional equations of dynamics,
165
Nondrifting transfer, 417
Nonlinear autoregressive exogenous
model (NARX model), 861, 908
Nonlinear least square algorithm,
520e521
Nonlinear programming algorithm (NLP
algorithm), 739
Nonlinear scale factors, 267e268
Nonlinear systems
attitude regulation example, 589e592
control design for, 584e592
feedback linearization, 586e587
gain scheduling, 586
linearization, 584e585
stability analysis for nonlinear systems,
588e589
Nonlinearities, presence of, 467
Nonminimum phase systems, 582e584
Nonminimum phase transfer function,
582e583
Nonnormalized quaternion, 424
Nonorthogonality errors, 273e274
Normalized Stokes coefficients, 82
North, East, Down (NED), 58
Notation rules, 38e42
Notation table, 39
NRLMSISE-00 model, 99
Nutation, 64
Nyquist criterion, 553
Nyquist curve, 553e554
O
Object detection network, 856e859
Objective function, 826e827
Observation errors, effect of, 464e465
Observation model, 533e534
Observer gain matrix, 600
Ocean tides, 84
Oil jogs, 358e359
On-board autonomy, 633e634
On-board computers (OBCs), 635, 651,
686
On-board control system, 32e35
On-board guidance, 382e385
On-board implementation process
on-board implementation alternatives,
700e705
ASIC, 704e705
FPGA, 702e703
multiple processors, 701
processor and multiple DSPs, 701e702
system-on-chip, 703e704
1046 Indexon-board processing avionics, 694e700
spacecraft avionics, 686e694
and verification, 705e711
On-board navigation, 443e445
On-board orbit sensors, 276e277
On-board processing avionics, 694e700
accommodation of GNC functions into
on-board SW, 697e700
On-board processors, 820
On-board sensor processing, 716,
791e802
autonomous on-board sensor calibration,
796e800, 800f
GNSS-INS integration for on-board
orbit determination, 800e802
sensor failure detection, isolation, and
recovery, 794e796
On-board software (OBSW), 635, 656,
687e688, 935
accommodation of GNC functions into,
697e700
processors identification for OBC and
GNC functions, 697f
system-level architectures, 698f
models, 1018
On-ground orbit sensors, 276e277
One-axis pointing, 423e426, 745e749
maximize secondary target, 749
One-way radio signals, 284
Online learning, 842e843
Open-loop transfer function, 550,
552e554, 564
Operational sensor models, 255
Optical data, 284
Optimization methods, 392, 395
Orbit sensors, 253, 276e285. See also
Global navigation satellite system
sensors (GNSS sensors); Attitude
sensors; Electro-optical sensors;
Inertial sensors; Sun sensors
GNSS sensors, 277e283
ground-based orbit determination,
283e285
Orbital control systems, 716, 730e742
impulsive and low-thrust maneuvers,
731e733
low-thrust trajectory design, 737e740
orbital maneuvers, 733e737
station-keeping, 740e742
Orbital dynamics, 9, 207
irregular solar system bodies, 170e174
relative orbital dynamics, 174e204
three-body problem, 161e170
two-body problem, 132e160
Orbital elements, 136e138
Orbital maneuvers, 733e737
coplanar maneuvers, 733e735
Lambert’s problem, 736e737
plane change maneuvers, 735e736
Orbital period, 148e153
Orbital perturbations, 154e159
analytical approach, 155e159
argument of periapsis, 159
eccentricity, 157
inclination, 157e158
right ascension of ascending node, 158
semimajor axis, 156
true anomaly, 159
numerical approach, 154e155
Orbital regimes, 280
Orbits
attitude, 12
determination, 285, 800e801
operative classification of, 146e148
Ordinary differential equations, 178
Otsu’s method, 509
Out-of-plane
maneuver, 419e420
motion, 405
oscillation, 405
state transition matrix, 407
Output layer, 836
Output quantization, 315
Output saturation, 274
Over-fit, 830
P
Packet Utilization Standard (PUS),
640e641, 928
Parabolic orbits, 142, 149
Parallel axis theorem, 228e229
Parameters estimation, 458e461
state augmentation for, 458e459
bias estimator, 459
Index 1047Parameters estimation (Continued )
use of consider states, 459e461
Parametric dynamics reconstruction,
915e917
Parametrization methods, 212
Parasitic forces
during thrusters firing, 113e117
and torques due to plume impingement,
121e122
Partial derivatives
calculation, 537e538
equations, 102e103
Particle filters (PFs), 455e458
Particles, 455
Passive control techniques, 724
Passive safety, 196e198
Peak torque, 954
Pendulum, 111e112
Performance drift error (PDE), 621
Performance models, 340, 342
Performance reproducibility error (PRE),
621
Performance requirements, 432e433
Performance sensor models, 256
Pericenter rotation, argument of, 67
Perifocal coordinate systems, 61
Periodic transfer, 416e418
Perturbation sources, 77e78, 125
Perturbed relative dynamics with relative
orbital elements, 198e200
Phase ambiguity, 472
Phase crossover frequency, 555e556
Phase margin, 556, 564
Pinhole camera model, 515e519
camera calibration from known scene,
519
Pink noise, 270
Pitch axis, 62
Pixels
few tenths of, 526
pixel-based approach, 508
Plane, 136
Planetary bodies, 247e248
Planetary ephemerides, 95
Planetary landing guidance, 806e814
formulation, 806e808
guidance algorithms, 809e811
convex optimization method, 811
polynomial method, 809
potential field method, 809e810
pseudospectral method, 810
zero-effort-miss/zero-effort-velocity
method, 810
hazard avoidance, 814
sensors and navigation, 811e813
Planetary models, 45, 73. See also Earth
models
coordinate transformations, 63e68
earth and, 46e53
GNC, 73e75
time, 69e73
Plume impingement, parasitic forces and
torques due to, 121e122
PnP solver for state filter initialization, 882
Poincaré elements, 390
Point correspondence-based homography
estimation, 515
maximum likelihood estimation, 515
robust estimation, 515
Pointing
control, 749
error, 619e620
Polar motion, 64
Polarity tests, 970
Pole placement, 570e577
for first-, second-, and high-order
systems, 577e579
Polhodes, 231e232
Policy-based methods, 897
Polyhedral Model (POL), 174
Polynomial method, 809
Pooling layers, 851
Pose estimation, 521, 867e869
Position-sensitive devices/quadrant
detectors, 948
Potential field method, 809e810
Powered descent (PD), 806
PQW, 61, 429e431
ECI to, 66e67
PRE. See Performance reproducibility
error (PRE)
Precession, 64e65
Precise orbit determination (POD), 475,
477e478
1048 IndexPrecise point positioning algorithms (PPP
algorithms), 475e476
Prediction horizon, 611
Preliminary design, 36e37
Primer vector, 395
Principal Axes reference system (PA
reference system), 60
Principal component analysis (PCA), 823
Printed circuit board (PCB), 371e372
PCB-embedded torquers, 956
Probability, 261e265
Probability distribution function (PDF),
261, 650
Probability number (PN), 28
Process noise, 446e447
Processor-in-the-loop (PIL), 647,
671e672, 709e710
verification activities at, 676
Project Requirements Document, 18e20
Projective geometry, 513e515
homography, 513
point correspondence-based homography
estimation, 515
Projective reconstruction, 520e521
Proper Euler angles, 213
Proper sensor models, 266
Proportional integral controllers (PI
controllers), 356, 502
Proportional-derivative controller (PD
controller), 566e567, 747
Proportional-Integral-Derivative control
(PID control), 544, 593e596
Propulsion subsystem design, 344
Proximal policy optimization algorithm
(PPO algorithm), 901e902
Pseudo-Earth Fixed frame (PEF frame), 64
“Pseudo” Newtonian inertial system, 54
Pseudoinertial systems, 55
Pseudoinverse method, 362
Pseudorange, 471
measurements, 279
Pseudospectral method (PSM), 395e396,
810
Pulsar-based spacecraft navigation,
480e483
clock errors, 482e483
ephemerides error, 483
Pulse-width modulation (PWM), 944
PUS. See Packet Utilization Standard
(PUS)
Q
Q-learning, 897e899
Q-network, 898
Quadratic Volterra model (QV model),
200
Quantization errors, 272e273
Quasi-Zenith Satellite System (QZSS),
278e279
Quasisingular relative orbital elements,
191e192
QUaternion EStimation (QUEST),
495e496
Quaternions, 212, 217e221, 388,
423e424
algebra, 994e999
from two directions, 998e999
angular velocity, 221e227
kinematics, 226e227
logarithm, 429
relative, 220e221
rotation, 429e431
successive rotations, 219e220
R
R2BP. See Restricted Two-Body
Problem (R2BP)
Rad-hard (RH), 692
Radar altimeters, 332e333
Radial basis function neural network aided
adaptive extended Kalman filter
(RBFNN-AEKF), 909e910
Radial basis function neural networks
(RBFNNs), 843e845
Radial basis functions (RBFs), 843
Radial distance, 55
Radial impulses, 410
Random access memory (RAM),
687e688
Random errors, 261, 268e272
with uniform distribution, 272
Random variables, 261e263
Gaussian random variables, 263
uniform random variables, 262
Index 1049Random walk
errors, 313e314
noise, 951
Range, 283
RANSAC algorithm, 515
Rate random walk errors (RRW errors),
314
Reaction wheel jitter, 119e121
Reaction wheels, 354e365, 953e955,
965e966, 970
assembly, 355e357
control with, 753e756
desaturation, 716, 755e756
friction and microvibrations, 357e360
model, 364e365, 364f
multiple reaction wheels actuation
function, 360e363
performance, 363e364
strengths and weaknesses, 364t
Real-time navigation, 475, 478e480
GNSS-INS integration, 479e480
Relative GNSS navigation, 480
Real-time operating system (RTOS),
659e660
Real-world models (RW models), 1018
Recovery, 634
Rectangular coordinate system, 53
Rectified linear unit activation function
(ReLU activation function), 837,
908
Recurrent neural networks (RNNs),
824e825, 859e864
HNN, 862e863
LSTM, 863e864
NARX model, 861
Red noise, 270
Reduced-order linear lateral sloshing
models, 111e112
Reference systems, 73
coordinate reference systems, 53e63
coordinate transformations, 63e68
earth and planetary models, 46e53
GNC, 73e75
time, 69e73
Reflectivity coefficient (CR), 91
Region of interest (ROI), 872
Region proposal-based framework, 856
Region-based shape representation,
510e511
moments, 511
scalar region descriptors, 511
Regression/classification-based
framework, 856
Reinforcement learning, 823e824,
890e906, 920
deep reinforcement learning algorithms,
897e903
inverse reinforcement learning, 903e906
model-based vs. model-free, 893t
Relative attitude dynamics, 249e250
Relative attitude kinematics, 249
Relative dynamics modeling
comparison of, 200e204
Cartesian and relative orbital elements
mapping, 203e204
circular sun-synchronous LEO with
perigee altitude, 202t
fixed relative motion geometry with
small separation, 201t
using relative orbital elements, 190e200
coordinates transformation, 193e195
energy-matching condition and passive
safety, 196e198
perturbed relative dynamics with
relative orbital elements, 198e200
relative motion geometry, 195e196
Relative GNC, 775e791
guidance and control strategies,
779e789
guidance for relative and proximity
maneuvers, 775e776
rendezvous in cislunar space, 789e791
trajectory design and sensors selection,
776e779
Relative GNSS navigation, 475e476
Relative knowledge error (RKE), 621
Relative motion
of camera, 524e525
geometry, 195e196
for rendezvous guidance applications,
402e409
Relative navigation, 504e507
scenarios, 505t
Relative orbital dynamics, 132, 174e204
1050 Indexlinearization of equations of motion,
177e182
true anomaly parametrization in
linearized relative dynamics,
179e182
linearized equations of motion for nearly
circular orbits, 183e187
analysis and characteristic of
unperturbed motion, 184e187
Relative orbital elements (ROEs), 778
mapping, 203e204
perturbed relative dynamics with,
198e200
relative dynamics modeling using,
190e200
Relative performance error (RPE), 621
Relative quaternion, 220e221
Relative representation, 506e507
Relative wind velocity (vrel), 87
Rendezvous and docking (RVD), 504
Rendezvous guidance, 402e423
forced motion, 420e423
impulsive maneuvers and trajectories,
410e420
cotangential transfer, 412e414
drift modulation transfer, 418
multiple impulse transfer, 418e419
out-of-plane maneuver, 419e420
periodic transfer, 416e418
trajectory-crossing maneuver,
414e416
two-point transfer, 411e412
relative motion for rendezvous guidance
applications, 402e409
effect of velocity impulses, 409e410
Rendezvous in cislunar space, 789e791
Reorientation guidance, 428e429
Requirements verification, 664e665
code requirement verification, 664e665
models requirement verification, 664
Residual generation, 930e931
Resolved object, 527
known object, 527
unknown object, 527
Restricted Three-Body Problem (RTBP),
162
periodic motion in, 166e170
Restricted Two-Body Problem (R2BP),
134, 137
RetinaNet, 856
Retrofire attitude, 12
RH. See Rad-hard (RH)
Right ascension, 55
of ascending node, 158
Right batch filter, 537e538
implementation workflow, 538
Right sequential filter, 533e534
Rigid body dynamics, 230e235
angular momentum, 230e231
Euler equation, 232e235
rotational kinetic energy, 231e232
Ring laser gyros (RLGs), 941e942
RitzeGalerkin approximation, 102e103
RKE. See Relative knowledge error
(RKE)
RNNs. See Recurrent neural networks
(RNNs)
Robust attitude control of spacecraft,
759e773
robust attitude control synthesis,
768e773
substructuring modeling, 761e768
assembling of whole spacecraft, 768
flexible solar array with revolute joint,
764e768
main body, 763e764, 764f
Robust control, 605e609
H-infinity, 605e607
Mu-control, 607e608
robust adaptive controllers, 608e609
robust model predictive control, 616
Robust estimation, 515
Robustness margin, 625
Robustness to uncertainty, 551
Rodrigues’ formula, 81
Rodrigues parameters, 388e389
ROEs. See Relative orbital elements
(ROEs)
ROI. See Region of interest (ROI)
Roll axis, 62
Roll-pitch-yaw axes, 62
Root-mean-square error (RMSE), 477
Rotation matrix, 274
Rotation quaternion, 422
Index 1051Rotation sequence, 63e64
Rotational kinetic energy, 231e232
RPE. See Relative performance error
(RPE)
RRW errors. See Rate random walk errors
(RRW errors)
RSW, 61e62, 429e431
ECI to, 67e68
reference frame, 68
RTBP. See Restricted Three-Body
Problem (RTBP)
RTOS. See Real-time operating system
(RTOS)
Rule-of-thumb, 98
RVD. See Rendezvous and docking
(RVD)
RW models. See Real-world models (RW
models)
S
S/C. See Spacecraft (S/C)
SADMs. See Solar arrays drive mechanisms
(SADMs)
Sample depletion, 456e457
Sampling time, 611
Satellite-based coordinate systems, 61e62
perifocal coordinate systems, PQW, 61
satellite body coordinate systems, b1b2b3,
62e63
auxiliary satellite body coordinate
systems, 62e63
satellite coordinate system, RSW, 61e62
Satellites, 71, 241, 280
altimetry, 330e331
angular rate, 653
body coordinate systems, 62e63
body reference frame, 62
coordinate system, 61e62
Saturation, 363
SAVOIR. See Space Avionics Open
Interface Architecture (SAVOIR)
Scalar region descriptors, 511
Scale factors, 267e268
errors, 267e268, 314
instability, 314
models, 268
ratios, 314
Scale-invariant feature transform (SIFT),
812e813
Scanning sensors, 298
Schmidt coefficients, 85
SchmidteKalman filter, 459e461
formulations, 461
SchweigharteSedwick model, 201
SCOE. See Special Check-Out
Equipment (SCOE)
Second Cosmic Velocity, 146
Sectorial Harmonics, 82
Segmentation, 507
Selenocentric coordinates, 59
Semimajor axis, 156
Sensitivity
crossover frequency, 561
functions, 557e563, 581e582
disturbance rejection, 561e563
noise measurement rejection, 563
response to setpoint, 559e561
Sensor(s), 16, 433e434, 649
acquisition chain, 266e267
altimeters, 330e334
attitude sensors, 286e306
calibration, 265e266
electro-optical sensors, 322e329
faults, 275e276, 795
inertial sensors, 306e322
modeling for GNC, 253e274
models, 255e257, 267, 321e322,
340e341
interfaces, 256
orbit sensors, 276e285
selection and actuators sizing, 726e730
magnetorquer sizing, 728t
Separation principle, 599
Sequential filtering, 443
Sequential filters, 445e461
design, implementation, tuning, and
useful checks for, 534e536
general design considerations,
534e535
implementation efficiency, 536
implementation workflow, 535e536
parameters estimation, 458e461
for spacecraft navigation, 447e458
working principle, 446e447
1052 IndexSequential measurements, 536
Serial Peripheral Interface (SPI), 258
Seven-point algorithm, 524
Severity number (SN), 28
Sextants, 3
SEZ. See South, East, Zenith (SEZ)
SGD. See Stochastic gradient descent
(SGD)
Shallow neural network, 836
SHE model. See Spherical Harmonics
Expansion model (SHE model)
Shooting method, 396
Shuster, 495
Sidereal time, 64, 69
SIFT. See Scale-invariant feature transform
(SIFT)
Sigma points, 452
Sigmoid function, 831, 837
Signal-to-noise ratio (SNR), 324,
867e868
Simple spin, 234
Simplex algorithm, 350
Simulink Configuration Parameters,
1023e1026
Simulink GNC models, 656
Simultaneous Localization and Mapping
(SLAM), 527
Single instruction, multiple data (SIMD),
692
Single Shot MultiBox Detector (SSD),
856
Single-event upsets (SEUs), 692
Single-input single-output channel (SISO
channel), 760, 1007e1008
Singular Value Decomposition (SVD),
492, 987, 990e991
Skew-symmetric matrix, 984
Sliding Mode Control (SMC), 544,
616e618
Slosh motion, 112e113
Sloshing, 111e113
Small bodies, 170
Small satellites/CubeSats, 938e971
hardware limitations, 940e945
burden of miniaturization, 941
pointing performances, 943
size and mass limitation, 941e943
thrusters, 943e945
SMP. See Symmetric multiprocessing
(SMP)
SN. See Severity number (SN)
SoC. See System-on-chip (SoC)
Softmax activation function, 837
Software (SW), 632, 685, 1017
algorithm, 718
design process, 36
development process, 36
rendering, 888e890
Software Requirements Document,
36e37
Software Verification and Validation plan,
36e37
Software-in-the-loop (SIL), 647, 671,
968e969
SIL/PIL test, 667e676
autocoding, 668e671
processor-in-the-loop, 671e672
software-in-the-loop, 671
verification activities at SIL level,
672e676
verification activities at, 672e676
code coverage verification, 675e676
code functional verification, 673e674
code standards verification, 674e675
requirements verification, 674
SOI. See Sphere of influence (SOI)
Solar arrays, 104
Solar arrays drive mechanisms (SADMs),
718e719
Solar flux, 90
Solar panels pointing, 759
Solar radiation, 93e94, 99e100
Solar radiation pressure (SRP), 77, 89e94,
246
Albedo and infrared emission, 93e94
eclipse, 92e93
torque, 246e248
Solar System Barycenter (SSB), 481
Solar time, 69
Solution method, 397
Solver, 1024, 1024f
South, East, Zenith (SEZ), 58
Space
AI in, 821e866
Index 1053Space (Continued )
craftsystem engineers, 4e5
industry, 631
mission, 382e383
segment, 285, 382e383
system, 34
Space Avionics Open Interface
Architecture (SAVOIR), 700
Space environment, 124
external perturbations, 79e97
modeling guidelines, 97e100
GNC, 124e126
internal perturbations, 100e122
modeling guidelines, 123e124
models, 126
perturbation sources, 78
Spacecraft (S/C), 925e926
attitude, 209
dynamics, 230
avionics, 686e694
application-specific integrated circuit,
693
digital signal processor, 688e689
field programmable gate array,
689e691
general-purpose processor or
microcontroller, 687e688
graphical processing unit, 689
system-on-chip, 694
control, 546e547
navigation, 443, 527e528
design process, 528
EKF, 450e452
HN filter, 450
KF, 448e450
PF, 455e458
sequential filters for, 447e458
UKF, 452e454
Spacecraft PosE Estimation Dataset
(SPEED), 870
Spacecrafts, 113e114
sensors, 265
Spaceflight, 3
Special Check-Out Equipment (SCOE),
679e680
Special orthogonal matrices, 210
Specific angular momentum, 134
Specific energy, 135e136
Specific orbital energy, 135e136
Speed estimation, 356
Sphere of influence (SOI), 160
Spherical Harmonics Expansion model
(SHE model), 81, 170e171
SPI. See Serial Peripheral Interface (SPI)
Spike fault, 275
Spline interpolation, 400e402
Square matrices, 984
Square Root Information Filter (SRIF),
469e470
SSD. See Single Shot MultiBox Detector
(SSD)
SSOs. See Sun-synchronous orbits (SSOs)
Stability, 552e557
analysis, 563
of dual spin attitude dynamics, 240
for nonlinear systems, 588e589
in state space, 569
equation, 238
margins, 552e557
time, 620
Standard deviation, 1000
Standard gravitational parameter, 134
Standardized distance, 1002
Stars, 302e303
sensors, 300e306
strengths and weaknesses, 306t
trackers, 768, 949e950, 964, 969
tracking, 302
State estimator, 882e883
State feedback control law, 570
State filter initialization, PnP solver for,
882
State prediction, 448
State Transition Matrix (STM), 167e168,
404, 407e408, 463
State variables, 1007e1008
State vector, 507
State-space control law, 580
State-space equations, 1008
State-space models, 1007e1009
State-space vector, 1009
State-transition matrix, 1008
Static and dynamic performance,
549e550
1054 IndexStatic attitude determination, 489
Static imbalance, 359
Static sensors, 298
Station-keeping control, 740e742
Stationary coplanar elliptical relative orbit,
187
Statistical error representation, 317e321
Statistics, 1000
basics of, 1000e1002
scalar statistics parameters, 1000
vector and matrix forms of statistic
quantities, 1001e1002
Steady-state error, 550
Stereo camera, 776e777
Stiction, 357
Stochastic gradient descent (SGD), 842
Stokes coefficients, 81, 171
Strapdown accelerometers, 308
Stribeck effect, 358
Structured singular value, 625
Stuck fault, 276
Sub-Earth point, 59
Subpixel, 526
Sun presence sensors, 296
Sun sensors, 291e297, 947e949,
963e964, 970. See also Orbit
sensors; Attitude sensors; Electro￾optical sensors; Global navigation
satellite system sensors (GNSS
sensors); Inertial sensors
analog sun sensors, 292e294
digital, 295e296
model, 296e297
strengths and weaknesses, 297t
sun presence sensors, 296
types of, 296t
Sun-synchronous orbits (SSOs), 148, 943
SuneEarth SOI borders, 161
SuneEarth system, 248
Supervised learning, 826e843
algorithm, 822e823
artificial neural networks for multiclass
classification, 834e843
linear regression, 826e830
logistic regression for binary classification,
831e834
SVD. See Singular Value Decomposition
(SVD)
Symmetric matrix, 984
Symmetric multiprocessing (SMP),
696e697
System definition, 27
System modeling, 433e434
System redundancy, 24e25
System-on-chip (SoC), 685, 694,
703e704
DSP or GPU SoCs, 704
FPGA, 704
T
Tactical grade, 315
Tailoring process, 20
TaiteBryan angles, 213
Tangential impulses, 410
Target network, 898e899
Technology readiness level 9 (TRL 9),
945
Telecommands (TCs), 640e641,
718e719
Telemetry (TM), 636
Telemetry/telecommand transmitters
(TM/TC transmitters), 658,
678e679
Temperature sensitivity, 951
Temperature-dependent bias, 313
Temporal difference method (TD
method), 895e896
Temporal discretization, 274
Terrestrial Time (TTT), 1004
Test error, 829
Testbed for Rendezvous and Optical
Navigation (TRON), 883e884
Texture randomization, 888
Thermal Infrared cameras (TIR cameras),
325e327
Thermal snap, 122
Thermochemical processes, 342
Third Cosmic Velocity, 146
Third-body perturbation, 94e95
modeling guidelines, 100
Three-axis pointing, 750e753
two loops, 752e753
Index 1055Three-body problem (3BP), 132,
161e170. See also Two-body
problem
attitude dynamics, 248e249
circular restricted three-body problem,
162e164
elliptic restricted three-body problem,
164e166
environments, 248
periodic motion in restricted three-body
problem, 166e170
circular restricted three-body problem,
167e169
elliptic restricted three-body problem,
169e170
Three-body synodic coordinate systems,
60e61
Three-dimension (3D), 280e281
point computation, 525
space, 280e281
vision, 512e521
multiple views scene reconstruction,
520e521
pinhole camera model, 515e519
pose estimation, 521
projective geometry, 513e515
projective reconstruction,
520e521
triangulation, 520
Three-element error parametrization,
875e876
Three-way radio signals, 284
Threshold-based diagnostic routines
process symptoms, 642
Throttleability, 944
Thrust magnitude accuracy, 116
Thrust Management Function (TMF),
347e353
example thruster configuration data, 349t
schematic of closed-loop system, 347f
thrusters strengths and weaknesses, 353t
Thrusters, 344e354, 729e730, 943e945
assembly, 345e346
firing, parasitic forces and torques during,
113e117
model, 353e354, 353f
plumes, 302e303
thrust management and actuation
function, 347e353
Tightly coupled architecture, 527e528
Time, 45, 69e73
Julian dates, 71e73
universal time, 70e71
Time accuracy, 73e74
Time delays, 583
Time intervals, 73
Time laws, 148e153
Time of Arrival (TOA), 481
Time of flight (TOF), 732
Topocentric coordinate systems, 57e59
Topocentric declination, 57
Topocentric equatorial coordinate
systems, 57
Topocentric horizon coordinate systems,
57e59
Topocentric reference spherical
coordinates, 59
Topocentric right ascension, 57
Torques, 230
noise, 359
during thrusters firing, 113e117
Total Electron Content (TEC), 473
Total ionizing dose (TID), 694e695
Training error, 829
Training set, 829e830
Trajectory design, 776e779
Trajectory optimization methods,
395e396
Trajectory-crossing maneuver, 414e416
Transduction, 258
Transfer functions, 1011e1015
of closed-loop system, 557e558
interconnection of linear systems, 1014f
Transfer learning (TL), 920e921
Transfer polynomials, 416
Transformation matrices, 63
Triad, 470e488
Triangulation, 520
True anomaly, 151, 159
parametrization in linearized relative
dynamics, 179e182
True of Date frame (TOD frame), 64
Tsiolkovsky’s rocket equation, 344
Tuning for sequential filters, 534e536
1056 IndexTwo degrees of freedom control, 567
Two-axis gyros, 310e311
Two-axis pointing, 426e427
extended vector normalization, 427
quaternion rotation, 429e431
reorientation, 428e429
Two-body problem, 132e160. See also
Three-body problem (3BP)
energetic analysis and cosmic velocities,
143e146
geometrical classification of conics,
140e143
integrals of motion and orbital elements,
134e140
integrals of motion, 134e136
orbital elements, 136e138
TLE, 139e140
operative classification of orbits, 146e148
geosynchronous/geostationary orbits,
147
low earth orbits, 147
MEO, 147e148
SSO, 148
orbital perturbations, 154e159
time laws and orbital period,
148e153
circular orbits, 148e149
elliptic orbits, 150e151
hyperbolic orbits, 152
parabolic orbits, 149
time law solution methods, 154t
universal time law, 152e153
validity range of, 160
Two-body problem, 131
Two-dimension (2D), 828e829
input, 828e829
schematization of array, 106
shape representation, 509e512
applicative case, 511e512
chain codes, 510
contour-based shape representation,
510
fourier transforms, 510
geometric boundary-based features,
510
region-based shape representation,
510e511
Two-input two-output Port (TITOP),
761
Two-Line Elements (TLEs), 139e140
characteristic parameters of conics, 144t
Two-point transfer, 411e412
Two-views geometry, 521e525
epipolar geometry, 521e523
relative motion of camera, 524e525
camera matrix and 3D point
computation, 525
fundamental matrix estimation, 524
stereo correspondence, 525
Two-way radio signals, 284
U
U-D filter, 470
Underfit, 830
Uniform distribution, random errors with,
272
Uniform random variables, 262
Unit quaternions, 388
Universal [Synchronous and]
Asynchronous Receiver￾Transmitter (U[S]ART), 258
Universal approximation theorem,
834e835, 906, 912e913
Universal Time (UT1), 65
Universal time, 70e71
law, 152e153
Unknown object, 527
Unperturbed motion
analysis and characteristic of, 184e187
circular relative orbit, 186e187
comparison of relative dynamics
modeling, 200e204
concentric coplanar absolute orbit,
185e186
impulsive shots, 187
impulsive motion in linearized relative
dynamics for nearly circular orbits,
189t
J2-perturbed relative dynamics, 189e190
relative dynamics modeling using relative
orbital elements, 190e200
stationary coplanar elliptical relative orbit,
187
Unscented Kalman filter (UKF), 452e454
Index 1057Unsupervised learning, 823, 825
Upper triangular matrix, 984
US Standard Atmosphere, 88
User Requirements Document, 36e37
UTC. See Coordinated Universal Time
(UTC)
V
Vacuum core, 956
Validation
of AI-based systems, 883e890
CNN validation, 884e888
training augmentation techniques,
888e890
validation of keypoints detection
accuracy, 890
process, 648
of ROE formulation, 203
Value-based methods, 897
Vanishing gradients, 841e842
Variance, 318
Vectors, 38
identities, 991e994
cross product, 992e994
dot product, 992
outer product, 994
vector norm, 992
Velocity impulses
effect of, 409e410
comparison of tangential vs. radial
impulses as means to affect trajectory
changes, 411t
Velocity random walk errors (VRW
errors), 314
Venus express monitoring camera (VMC),
692
Verification and validation process (V&V
process), 663, 929
Verification process, 648
Very Long Baseline InterferometrydD￾DOR (VLBIdD-DOR), 284
Very long instruction word (VLIW), 700
Video processor units (VPUs), 820
microprocessor, 923e924
Viscous friction, 357
Visible/infrared cameras, 948
W
Wahba problem, 491e496
davenport q-method, 493e495
QUEST method, 495e496
SVD method, 492
Waterfall plot, 118e119
Weights update rule, 915
WGS-84 model, 46e47
White noise, 270
Wide-Angle Cameras (WAC), 325e327
Worst-case analysis (WCA), 655
X
Xilinx, 925
Y
YamanakaeAnkersen STM, 201
YaneAlfriend nonlinear theory, 201
Yaw axis, 62
Yaw-pitch-roll angles, 213
You Only Look Once (YOLO), 856
Z
Zero-crossing, 357, 955
Zero-effort-miss/zero-effort-velocity
method (ZEM/ZEV method),
810
Zero-elevation angle, 350
Zonal harmonics, 82
1058 Index
