Undergraduate Lecture Notes in Physics
Ravinder R. Puri
Modern 
Thermodynamics 
and Statistical 
Mechanics
A Comprehensive FoundationUndergraduate Lecture Notes in Physics 
Series Editors 
Neil Ashby, University of Colorado, Boulder, CO, USA 
William Brantley, Department of Physics, Furman University, Greenville, SC, USA 
Matthew Deady, Physics Program, Bard College, Annandale-on-Hudson, 
NY, USA 
Michael Fowler, Department of Physics, University of Virginia, Charlottesville, 
VA, USA 
Morten Hjorth-Jensen, Department of Physics, University of Oslo, Oslo, Norway 
Michael Inglis, Department of Physical Sciences, SUNY Suffolk County 
Community College, Selden, NY, USA 
Barry Luokkala , Department of Physics, Carnegie Mellon University, Pittsburgh, 
PA, USAUndergraduate Lecture Notes in Physics (ULNP) publishes authoritative texts 
covering topics throughout pure and applied physics. Each title in the series is suitable 
as a basis for undergraduate instruction, typically containing practice problems, 
worked examples, chapter summaries, and suggestions for further reading. 
ULNP titles must provide at least one of the following:
. An exceptionally clear and concise treatment of a standard undergraduate subject.
. A solid undergraduate-level introduction to a graduate, advanced, or non-standard 
subject.
. A novel perspective or an unusual approach to teaching a subject. 
ULNP especially encourages new, original, and idiosyncratic approaches to physics 
teaching at the undergraduate level. 
The purpose of ULNP is to provide intriguing, absorbing books that will continue to 
be the reader’s preferred reference throughout their academic career.Ravinder R. Puri 
Modern Thermodynamics 
and Statistical Mechanics 
A Comprehensive FoundationRavinder R. Puri 
Indian Institute of Technology 
Gandhinagar, Gujarat, India 
ISSN 2192-4791 ISSN 2192-4805 (electronic) 
Undergraduate Lecture Notes in Physics 
ISBN 978-3-031-54312-8 ISBN 978-3-031-54310-4 (eBook) 
https://doi.org/10.1007/978-3-031-54310-4 
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2024 
This work is subject to copyright. All rights are solely and exclusively licensed by the Publisher, whether 
the whole or part of the material is concerned, specifically the rights of translation, reprinting, reuse 
of illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way, and 
transmission or information storage and retrieval, electronic adaptation, computer software, or by similar 
or dissimilar methodology now known or hereafter developed. 
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication 
does not imply, even in the absence of a specific statement, that such names are exempt from the relevant 
protective laws and regulations and therefore free for general use. 
The publisher, the authors and the editors are safe to assume that the advice and information in this book 
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or 
the editors give a warranty, expressed or implied, with respect to the material contained herein or for any 
errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional 
claims in published maps and institutional affiliations. 
This Springer imprint is published by the registered company Springer Nature Switzerland AG 
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland 
Paper in this product is recyclable.Dedicated to 
my students 
who make me learn constantlyPreface 
There are a number of books on thermodynamics and statistical mechanics at different 
levels. Then why this one? This book intends to put together in one place the funda￾mentals of thermodynamics and statistical mechanics for the students of physics by 
presenting the subjects in a way different from the existing texts. 
In the books on statistical mechanics, thermodynamics is generally given at most 
a cursory glance. It is covered comprehensively in this book. Indeed, since statis￾tical mechanics is the microscopic theory of thermodynamics, placing it alongside 
thermodynamics helps in providing a clearer and complete view of the subject. 
Furthermore, fundamentals of thermodynamics are generally presented either in 
the traditional way in terms of the laws of thermodynamics or in Callen’s postulatory 
form. This book presents both the approaches. For, the postulatory approach is built on 
the concept of entropy which emerges from the traditional approach. The traditional 
approach in that sense prepares one to understand and appreciate the postulatory 
approach better. The postulatory approach in turn provides a natural connection 
between thermodynamics and statistical mechanics. 
After introducing the fundamentals of thermodynamics in first two chapters we 
turn to developing the concepts and methods of equilibrium statistical mechanics. 
We begin with the kinetic theory in Chap. 3. Though it is discussed routinely in 
the texts on statistical mechanics, this book provides a glimpse in to its historical 
developments too. 
The kinetic theory leads to coupled time-dependent integro-differential equa￾tions finding whose asymptotic solution to describe equilibrium thermodynamic 
phenomena is generally a formidable task. Boltzmann’s insight provided a way of 
linking thermodynamics with microscopic description without the need of solving 
those equations. It laid the foundation of modern statistical mechanics which links 
the two descriptions by means of the concept of statistical entropy. The book traces 
in Chap. 4 the development of Boltzmann’s thought process as it emerges from his 
paper wherein he introduced the concept of what he called permutability measure as 
the mechanical analog of thermodynamic entropy. 
Boltzmann’s formalism applies to systems of non-interacting molecules. The 
general statistical mechanical formalism is developed in Chap. 5 by introducing the
viiviii Preface
concept of statistical entropy. It is based on Shannon’s information theoretic entropy. 
We construct the statistical entropy in terms of the phase space distribution function 
for classical systems and in terms of the probability of occupation of energy levels 
for quantum system. Since it depends on the probability of occupation of energy 
levels and not on the transition probabilities between them, the use of density matrix 
formalism is unnecessary. Based on the principle of maximum entropy, the classical 
and statistical entropies for systems in thermodynamic equilibrium are derived in 
Chap. 6 and their relation with thermodynamics established. 
The phase space equilibrium statistical entropy is used in Chap. 7 to study 
system of non-interacting molecules in free space, including their internal degrees 
of freedom, as well as when the gas is in the gravitational field near the surface of 
earth. The equations of state for the freely evolving non-interacting gas obtained in 
this way are same as the empirical equations of state for the ideal classical gas. 
The theory of non-interacting quantum gases in free space, called ideal quantum 
gases, is developed in Chap. 8. The concept of distinguishable and indistinguishable 
particles is introduced. The quantum theory of distinguishable particles is shown to 
be equivalent with the classical gas. The indistinguishable particles are categorized 
as Bosons and Fermions. 
The theory of ideal Fermi gas at low temperature is outlined in Chap. 9. The 
thermodynamics of ideal Bose gas is studied in Chap. 10 where the phenomenon of 
Bose-Einstein condensation is studied in detail. 
Chapter 11 is devoted to the thermodynamic theory of the phase transitions and 
critical phenomena. 
Having studied ideal gases, the interaction between the molecules in the gas is 
included in Chap. 12. The equation for the simplest model of an interacting classical 
gas namely the Van der Waals gas is derived and analyzed as a microscopic model 
of phase transition and critical phenomenon. 
Except for reference to time-dependence in classical formalism in the kinetic 
theory chapter, the statistical mechanical formalism till Chap. 12 is to understand the 
equilibrium properties, constructed based on the principle of maximum entropy. It is 
evidently desirable to ascertain that the equilibrium state so obtained is approached 
asymptotically as the solution of appropriate equation describing the evolution of the 
state. That issue is addressed for quantum systems in the Chaps. 13 and 14. Since 
the quantum mechanical state of a system interacting with others is described by 
the density matrix, Chap. 13 develops the density matrix formalism. The evolution 
equation for the density matrix of a system interacting weakly with a reservoir, called 
the master equation, is presented in Chap. 14 and shown to have same asymptotic 
solution as is predicted by equilibrium statistical mechanics. 
Some mathematical topics necessary for the purpose of the book are summarized 
in the appendices.Preface ix
I would like to take this opportunity to thank Mr. Akshat Khanna for helping me 
with drawing figures. I am thankful to the faculty at the Indian Institute of Technology 
Gandhinagar, in particular Prof. Rishi Narain Singh, for helpful discussions and 
encouragement. Special thanks to Prof. Rajat Moona, director Indian Institute of 
Technology Gandhinagar for providing invaluable support. 
Gandhinagar, India Ravinder R. PuriContents 
1 Fundamentals of Thermodynamics-I ............................ 1 
1.1 Brief History ............................................ 2 
1.2 Carnot Engine ........................................... 5 
1.2.1 Absolute Temperature ............................. 7 
1.2.2 Entropy ......................................... 12 
1.3 Laws of Thermodynamics ................................. 14 
1.3.1 Zeroth Law ...................................... 14 
1.3.2 First Law ........................................ 15 
1.3.3 Second Law ...................................... 16 
1.3.4 Third Law ....................................... 24 
1.4 Ideal Gas Equations of State ............................... 25 
1.4.1 Internal Energy of Ideal Gas ........................ 26 
1.5 A Cyclic Process to Realize Carnot Engine ................... 28 
1.5.1 Entropy of Ideal Gas .............................. 32 
1.6 Van der Waals Equation of State ............................ 33 
References .................................................... 36 
2 Fundamentals of Thermodynamics-II ........................... 37 
2.1 Postulates of Thermodynamics ............................. 38 
2.1.1 First Postulate .................................... 39 
2.1.2 Second Postulate ................................. 39 
2.1.3 Third Postulate ................................... 39 
2.1.4 Fourth Postulate .................................. 40 
2.1.5 Examining Admissible Forms of S(U, V, N ) ......... 40 
2.1.6 Connection with the Laws of Thermodynamics ........ 42 
2.2 Justification of Definitions of Intensive Parameters ............ 45 
2.2.1 Temperature ..................................... 45 
2.2.2 Pressure ......................................... 46 
2.2.3 Chemical Potential ................................ 47 
2.3 Equations of State ........................................ 47 
2.4 Euler Equation ........................................... 49
xixii Contents
2.5 Gibbs–Duhem Relation ................................... 49 
2.6 Thermodynamic Potentials ................................ 51 
2.6.1 Helmholtz Potential ............................... 52 
2.6.2 Gibbs Potential ................................... 53 
2.6.3 Enthalpy ........................................ 54 
2.6.4 Grand Potential ................................... 54 
2.7 Massieu Functions ........................................ 55 
2.8 Maxwell Relations ....................................... 57 
2.9 Independent Thermodynamic Observables ................... 59 
2.10 Stability from Maximum Entropy Principle .................. 65 
2.11 Stability from Minimum Energy Principle ................... 70 
2.12 Stability in Terms of Thermodynamic Potentials .............. 73 
2.12.1 Helmholtz Potential ............................... 73 
2.12.2 Enthalpy ........................................ 74 
2.12.3 Gibbs Potential ................................... 75 
2.13 Thermodynamic Potentials: Alternative Formulation .......... 77 
2.13.1 System Interacting with Heat Reservoir .............. 77 
2.13.2 System Interacting with Heat and Pressure 
Reservoirs ....................................... 79 
2.13.3 System Interacting with Pressure Reservoir ........... 81 
2.13.4 Exergy .......................................... 82 
2.14 Second Equation of State .................................. 83 
2.14.1 P Linear in T .................................... 86 
2.15 Joule–Thomson Process ................................... 90 
References .................................................... 93 
3 Kinetic Theory ................................................ 95 
3.1 Early Kinetic Theory ..................................... 95 
3.2 Maxwell Distribution ..................................... 96 
3.3 Phase Space Distribution Function .......................... 104 
3.3.1 Liouville’s Theorem ............................... 106 
3.3.2 Reduced Distribution Functions ..................... 108 
3.4 Boltzmann Equation: Single-Particle Phase Space 
Approach ............................................... 115 
3.5 Scattering ............................................... 118 
3.6 BBGKY Hierarchy ....................................... 122 
3.7 Boltzmann Equation from BBGKY Hierarchy ................ 129 
3.8 The H-Theorem .......................................... 134 
3.9 Equilibrium Distribution .................................. 136 
References .................................................... 138Contents xiii
4 Boltzmann Entropy ........................................... 139 
4.1 Discrete Energy Levels .................................... 139 
4.1.1 Connection of Discrete Model 
with Thermodynamics ............................. 147 
4.2 Continuous Distribution of Energy .......................... 149 
4.3 Distribution of Velocities .................................. 151 
4.4 Relation Between Thermodynamic and Boltzmann 
Entropies ............................................... 153 
4.5 Planck’s Distribution ...................................... 155 
4.6 Bose Statistics ........................................... 157 
4.7 Einstein’s Quantum Theory of Ideal Gas ..................... 160 
4.7.1 Indistinguishable Molecules ........................ 161 
4.7.2 Distinguishable Molecules ......................... 162 
4.7.3 Distribution of Light Quanta ....................... 163 
4.8 Distribution of Particles Obeying Exclusion Principle .......... 164 
References .................................................... 165 
5 Shannon and Statistical Entropies .............................. 167 
5.1 Shannon Entropy ......................................... 167 
5.1.1 Discrete Probabilities .............................. 168 
5.1.2 Continuous Probabilities ........................... 170 
5.2 Maximum Entropy ....................................... 173 
5.2.1 Discrete Variables ................................ 173 
5.2.2 Continuous Variable ............................... 175 
5.3 Statistical Entropy ........................................ 176 
5.3.1 Classical Systems ................................. 176 
5.3.2 Quantum Systems ................................ 177 
References .................................................... 178 
6 Equilibrium Distributions ..................................... 179 
6.1 Principle of Maximum Entropy ............................. 179 
6.2 Systems Having Fixed Number of Particles .................. 180 
6.2.1 Microcanonical Ensemble .......................... 183 
6.2.2 Canonical Ensemble .............................. 184 
6.3 Grand Canonical Ensemble ................................ 188 
6.4 Relation with Thermodynamics ............................ 193 
6.4.1 Zeroth Law of Thermodynamics .................... 193 
6.4.2 First Law of Thermodynamics ...................... 195 
6.4.3 Second Law of Thermodynamics .................... 196 
6.4.4 Third Law of Thermodynamics ..................... 198 
6.5 Thermodynamic Potentials in Terms of Partition Functions ..... 198xiv Contents
7 Non-interacting Classical Gas .................................. 201 
7.1 Thermodynamics Using Canonical Ensemble ................. 201 
7.1.1 Position Distribution Function ...................... 203 
7.1.2 Free Non-interacting Particles: Ideal Gas ............. 204 
7.2 Thermodynamics Using Grand Canonical Ensemble ........... 207 
7.3 Equipartition Theorem .................................... 208 
7.4 Internal Motion .......................................... 209 
7.4.1 Rotational Motion ................................ 210 
7.4.2 Vibrational Motion ................................ 214 
7.5 Gas in Gravitational Field ................................. 215 
7.5.1 Temperature Gradient ............................. 218 
7.6 Gibbs Paradox ........................................... 221 
References .................................................... 224 
8 Ideal Quantum Gases .......................................... 225 
8.1 Canonical Partition Function ............................... 226 
8.1.1 Configurational Degeneracy ........................ 227 
8.2 Distinguishable Particles .................................. 229 
8.2.1 Classical Ideal Gas ................................ 229 
8.3 Quantum Particles ........................................ 231 
8.4 Grand Canonical Partition Function ......................... 234 
8.4.1 Classical Particles ................................. 234 
8.4.2 Quantum Particles ................................ 234 
8.4.3 Classical Limit of Quantum Distributions ............ 240 
8.5 Single Particle Energy Levels in Free Space .................. 241 
8.5.1 Determining Density of States ...................... 241 
8.6 Thermodynamics of Ideal Classical Gas ..................... 246 
8.6.1 Translational Motion .............................. 246 
8.6.2 Internal Motion ................................... 247 
8.7 Thermodynamics of Quantum Gases ........................ 255 
8.8 Quantum Corrections to the Classical Limit .................. 259 
References .................................................... 262 
9 Ideal Fermi Gas ............................................... 263 
9.1 Fermi Gas at Zero Temperature ............................. 263 
9.2 Fermi Gas at Low Temperature ............................. 267 
10 Ideal Bose Gas ................................................ 275 
10.1 Bose Gas ................................................ 275 
10.1.1 Conditions for BEC ............................... 280 
10.1.2 Thermodynamic Properties ......................... 281 
10.1.3 BEC as a Phenomenon of Phase Transition ........... 288 
10.2 Gas of Photons ........................................... 291 
10.2.1 Thermodynamic Properties ......................... 292 
References .................................................... 295Contents xv
11 Phase Transitions and Critical Phenomena ...................... 297 
11.1 Phase Equilibrium ........................................ 297 
11.1.1 Triple Point ...................................... 298 
11.1.2 P − v Isotherms in Coexistence Region .............. 299 
11.1.3 Lever Rule ....................................... 301 
11.2 Equation of State in Coexistence Region ..................... 302 
11.3 First-Order Phase Transition ............................... 303 
11.3.1 Entropy Discontinuity ............................. 303 
11.3.2 Energy Discontinuity .............................. 304 
11.3.3 Latent Heat ...................................... 305 
11.3.4 Clapeyron–Clausius Equation ...................... 305 
11.4 Critical Phenomenon ..................................... 306 
11.4.1 Critical Exponents ................................ 308 
12 Interacting Classical Gas ...................................... 317 
12.1 Virial Expansion ......................................... 317 
12.2 Van der Waals Equation of State ............................ 322 
12.3 Critical Point ............................................ 324 
12.3.1 Law of Corresponding States ....................... 325 
12.4 P − v Isotherms ......................................... 326 
12.5 Gas–Liquid Transition .................................... 330 
12.6 Critical Exponents for van der Waals Fluid ................... 334 
References .................................................... 339 
13 Density Operator Formalism .................................. 341 
13.1 Density Matrix ........................................... 341 
13.2 Quantum Entropy ........................................ 344 
13.3 Equilibrium Density Matrix ................................ 346 
13.4 Standard Distributions .................................... 348 
13.4.1 Microcanonical Ensemble .......................... 349 
13.4.2 Canonical Ensemble .............................. 349 
13.4.3 Grand Canonical Ensemble ........................ 350 
13.5 Equilibrium Density Matrix of Harmonic Oscillators .......... 351 
13.6 Time Evolution of Entropy ................................ 352 
Reference ..................................................... 353 
14 Quantum Master Equation ..................................... 355 
14.1 Master Equation ......................................... 355 
14.2 Steady State Solution ..................................... 359 
14.3 Harmonic Oscillator Interacting with Reservoir 
of Harmonic Oscillators: Exact Solution ..................... 361 
References .................................................... 364xvi Contents
Appendix A: Some Relations Involving Partial Derivatives ............ 365 
Appendix B: Legendre Transform .................................. 369 
Appendix C: Concave and Convex Functions ........................ 377 
Appendix D: Some Combinatorics Formulas ......................... 379 
Appendix E: Cubic Equation ....................................... 385 
Appendix F: Thermodynamic Properties of Blackbody Radiation ..... 387 
Appendix G: Harmonic Oscillator Number and Coherent States ....... 389 
Appendix H: Some Mathematical Formulas .......................... 393 
Bibliography ...................................................... 395 
Index ............................................................. 397Chapter 1 
Fundamentals of Thermodynamics-I 
A theory is the more impressive the greater the simplicity of its 
premises is, the more different kinds of things it relates and the 
more extended is its area of applicability. Therefore the deep 
impression which the classical thermodynamics made upon me. 
It is the only physical theory of universal content concerning 
which I am convinced that, within the framework of the 
applicability of its basic concepts, it will never be overthrown. 
—Albert Einstein 
If someone points out to you that your pet theory of the universe 
is in disagreement with Maxwells equations then so much the 
worse for Maxwell’s equations. If it is found to be contradicted 
by observation well, these experimentalists do bungle things 
sometimes. But if your theory is found to be against the second 
law of thermodynamics I can give you no hope; there is nothing 
for it but to collapse in deepest humiliation. 
—Arthur Eddington 
Thermodynamics is a funny subject. The first time you go 
through it, you don’t understand it at all. The second time you 
go through it, you think you understand it, except for one or two 
points. The third time you go through it, you know you don’t 
understand it, but by that time you are so used to the subject, it 
doesn’t bother you anymore. 
—Arnold Sommerfeld 
The quotations above underline the character of thermodynamics: robust and tricky. 
As expressed in first two quotations, why this unwavering faith in the robustness of 
thermodynamics? And, as alluded to in the third quotation, why is it tricky? 
The edifice of thermodynamics draws its robustness from the strength of the pillars 
of the postulates it stands upon: conservation of energy and the impossibility of heat 
flowing on its own from a cold to a hot body even though it is allowed by energy 
conservation. The edifice can crumble only if either of these pillars weakens. Can 
that happen? Our firm belief is: it can not. 
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4_1 
12 1 Fundamentals of Thermodynamics-I
The origin of the challenges faced in applying thermodynamics, according to 
Feynman ([ 1], pp. 44–49), lies in the non-unique choice of independent variables 
from among several possible to describe a thermodynamic transformation. Indeed it is 
tricky to negotiate the maze of equations to describe a thermodynamic phenomenon. 
Thermodynamics was developed to understand the thermal properties of macro￾scopic systems at a time when the atomic theory was not in vogue. It describes 
systems in contact with its surroundings with which it may exchange heat and work. 
It identifies the state of a macroscopic system in terms of amazingly small number of 
variables when in equilibrium with its environment: pressure, density, and tempera￾ture. It builds relationships between the change in variables between different states 
of equilibria under thermodynamic transformations. Since the principles on which 
they are based, as asserted in the beginning of this chapter, are kind of “immortal”, so 
are those relations. Thermodynamics as such describes systems in thermodynamic 
equilibrium and not how it is achieved when the conditions are altered. In that sense 
thermodynamics is said to be thermostatics. Study of time-dependent behavior of 
macrosystems is the subject of non-equilibrium thermodynamics. 
Even after the atomic theory started growing its roots raising the possibility of 
describing macroscopic systems in terms of the motion of their constituent molecules 
governed by Newtonian laws, the problem of providing mechanical theory of ther￾modynamics was challenging. For, since the number of molecules in a macroscopic 
body may be as large as .∼ 1020, there is no way to construct and solve that many 
Newton’s equations. Even if, by some magic, we construct and solve those equa￾tions, what do we do with the solution? How do we identify temperature and heat to 
relate the solution with thermodynamics? The mechanical description did not seem 
to have place for heat and hotness. Clearly, different concepts were required to relate 
mechanical and thermodynamic descriptions leading to the emergence of the kinetic 
theory followed by the theory of statistical mechanics. 
We begin by outlining the fundamentals of thermodynamics, presented in two 
ways: one is the traditional approach and the other the axiomatic one. The tradi￾tional approach presented in this chapter is meant to describe the basic concepts of 
thermodynamics along with their origin. The axiomatic approach, presented in the 
next chapter, builds upon those concepts. It provides natural connection between 
thermodynamics and statistical mechanics. 
Apart from using number of molecules as a fixed parameter in this chapter and a 
variable in Chap. 2, the theory of thermodynamics is described without any reference 
to the molecular motion. Starting with the kinetic theory in Chap. 3, the mechanical 
theory is developed in the rest of the chapters. 
1.1 Brief History 
We describe briefly the main historical developments which shaped thermodynamics 
in its present form. For detailed history see, for example, [ 2, 3]. 
What is heat was a question which engaged people since ancient times. It was 
regarded by philosophers as an element. Later it came to be regarded as a fluid, a1.1 Brief History 3
belief which continued for a long time. That fluid was named Caloric by Guyton de 
Morveau in 1787. According to this view, two bodies, one hotter than the other, attain 
same temperature on contact with each other due to the flow of Caloric fluid from 
the hotter to the colder body. However, various experiments showed that heat is not 
a fluid but is a form of energy. Other forms of energy, like mechanical and electrical, 
can be converted to heat and vice versa. For example, generation of heat during the 
motion of an object on a rough surface is a common experience. Churning of a fluid 
also results in an increase in its temperature. These are the examples of conversion 
of mechanical energy to heat. The traditional unit of heat is Calorie, defined as the 
amount of heat required to raise the temperature of one gram of water by. 1. 
◦C at the 
pressure of one atmosphere. In a number of experiments, Joule in 1843 determined 
the amount of mechanical work needed to raise the temperature of water by.1◦ C at 
the atmospheric pressure and thus found the ratio.J = W/Q between the amount of 
work.W required to produce the amount of heat. Q. The standardized modern value 
of. J , called the mechanical equivalent of heat, is.J = 4.186J/calorie. 
Besides the concept of heat, interest was also in quantitative understanding of 
how the density of a gas changes under variation of pressure and temperature. The 
experiments in that direction showed that every gas when dilute, called an ideal 
gas, obeys following laws: (1) Boyle’s law (1662). According to it, the pressure 
.P of a fixed mass of an ideal gas at constant temperature is inversely proportional 
to its volume . V: .PV = constant. (2) Charles’s law (1787). According to it, when 
the pressure of a fixed mass of an ideal gas is kept constant then its volume is 
directly proportional to its temperature. T on the Kelvin scale:.V/T = constant where 
.T is the Kelvin temperature related with the temperature .Tcelsius in Celsius by the 
relation .T = Tcelsius + 273.15. (3) Gay-Lussac’s law (1802). According to it, when 
the volume of a fixed mass of an ideal gas is kept constant then its pressure is directly 
proportional to its temperature, i.e..P/T = constant. (4) Combined gas law (Émile 
Clapeyron, 1834) obtained by combining three afore-stated laws:.PV = kT , where 
. k is a constant whose value depends on the mass of the gas. Invoking the notion of 
the molecular composition of gases which came much later, the combined gas law 
for a sufficiently dilute gas, called the ideal gas law, for a gas consisting of one kind 
of molecules is now written as 
.PV = nRT or PV = NkBT =⇒ R = NkB/n ≡ NAkB, (1.1) 
where in the first form. n is the number of moles of the gas,. R is the gas constant and 
in the second form .N is the number of molecules in the gas, .kB is the Boltzmann 
constant. The number .NA, called Avogadro’s number, is the number of molecules 
per mole. The values of the constants in (1.1) are 
. R = 8.315 joule/mole K = 1.986 cal/mole K
NA = 6.022 × 1023 molecules/mol,
kB = 1.38 × 10−16 erg/K = 8.617 × 10−5 eV/K. (1.2)4 1 Fundamentals of Thermodynamics-I
The symbol. R for the gas constant was used first by Clapeyron. The thermodynamic 
state of the gas of given mass is thus specified in terms of its pressure, volume, 
and temperature. Equation (1.1), depicting relation between pressure, volume, and 
temperature, is called the equation of state of an ideal gas. It, however, does not 
determine relation of those quantities with heat and work put into the gas. In that 
sense the equation of state does not provide complete description of thermodynamic 
properties of a gas. 
The questions raised above regarding relationship between the thermodynamic 
state variables, work and heat, were of crucial importance in designing efficient 
steam engines. The interest in steam engines has its origin in the discovery in 1698 
by Thomas Savery of a steam-powered pump. Since then the design of steam engine 
underwent several changes culminating in a design by James Watt in 1763 which was 
later used for making railroad locomotives. Finding ways of improving efficiency of 
engines was a challenging problem. There was, however, very little systematic work 
in that direction till the work of Sadi Carnot in 1824. His work, published as a book 
entitled (translation of the original French title) Reflections on the Motive Power of 
Fire [ 4], laid the foundation for building modern thermodynamics. In Sect. 1.2, we 
outline Carnot’s visualization of the working of an engine, its efficiency, and the way 
it leads to the concept of entropy using the terminology summarized below: 
1. Heat is considered a form of energy. It can be converted to work, and in turn can 
be produced by consuming work. 
2. Work and heat together obey law of conservation of energy. 
3. The state of a thermodynamic system having a fixed number of moles of different 
kinds of molecules is characterized in terms of the set of thermodynamic param￾eters or thermodynamic state variables: pressure. P, volume. V, and temperature 
. T . The formalism can be extended to systems in which number of moles of one 
or the other kind is not fixed. 
4. The energy of a system has a unique value for a given thermodynamic state of 
the system. 
5. The state of a thermodynamic system which does not change with time is called 
the state of thermodynamic equilibrium. It is assumed that, when disturbed, the 
system will attain an equilibrium state in time called its relaxation time. The 
systems of interest here are the ones whose relaxation times are much smaller 
than the time scale of observation. 
6. The state variables in the state of equilibrium are not independent. The relation￾ship between them is known as the equation of state. The laws of thermodynamics 
do not specify the equation of state; it has to be determined empirically or by 
other theoretical means. Recall that the equation of state of an ideal gas, deter￾mined empirically, is given by (1.1). A widely employed equation of state of a 
non-ideal gas is the van der Waals equation of state (see Sect. 1.6). 
7. The state of a system changes when the external conditions are changed. When 
its state changes, the system is said to undergo thermodynamic transformation. 
The laws of thermodynamics, four in number, specify what state of equilibrium 
does the system attain when the external conditions are changed. They do not1.2 Carnot Engine 5
specify the rate at which the system transits from one to the other equilibrium 
state. In this sense, what we call thermodynamics is truly speaking thermostatics. 
8. If the state variables change so slowly that the system can be assumed to be in 
thermodynamic equilibrium at any instant then the transformation of the system 
is said to be quasi-static. 
9. If the transformation is carried such that it is possible to retrace the steps from 
its final to the initial state by reversing the external conditions then it is called 
reversible. Else the transformation is called irreversible. A reversible transfor￾mation is quasi-static but not all quasi-static transformations are reversible. 
10. If the transformation is such that the system does not exchange heat with its 
surroundings then the transformation is said to be adiabatic: from the Greek a 
(not)+dia (through)+bainein (to go) (see [ 1], pp. 39–45). It may be mentioned 
that the meaning of adiabatic transformation in mechanics is different. 
11. A transformation in which temperature of the system remains unchanged is called 
isothermal. 
12. A transformation in which pressure of the system remains unchanged is called 
isobaric. 
13. A thermal or heat reservoir is a system so large that addition or removal of a 
finite amount of heat from it does not change its temperature. The thermodynamic 
processes in a heat reservoir are reversible. 
14. If a transformation is such that it restores the system to its initial state then it is 
called cyclic. 
1.2 Carnot Engine 
The Fig. 1.1 depicts schematic operation of a Carnot engine. In it, the gas in a specified 
state (that is having specified values of.P, V, T ) receives an amount.Qh of heat from 
a thermal reservoir at temperature . Th, converts a part of it to work . W, rejects the 
remaining into a heat reservoir at temperature .Tc (.Tc < Th) and returns to its initial 
Fig. 1.1 Carnot engine6 1 Fundamentals of Thermodynamics-I
state. The working fluid thus undergoes a cyclic process. It is assumed that the process 
is reversible. An example of realization of Carnot’s engine is discussed in Sect. 1.5. 
To find efficiency of the engine note that, according to the principle of conservation 
of energy, the work produced in one cycle of the process is the difference in the amount 
of heat absorbed and the heat given out: 
.W = Qh − Qc. (1.3) 
Hence efficiency . η, defined as the ratio of work .W produced by the engine to the 
amount of heat.Qh received by it, is given by 
.η = W
Qh
= 1 − Qc
Qh
. (1.4) 
The expression for efficiency given above is based only on the definition of efficiency 
and the principle of conservation of energy. It holds not only when the processes in 
the engine depicted in the Fig. 1.1 are reversible but also when they are irreversible. 
Whereas the value of . η depends on the details of the processes in case they are 
irreversible, we will see that the expression (1.4) for efficiency of a Carnot engine in 
case the processes are reversible reduces to the form (1.16) which depends only on 
the temperatures.Th and.Tc and not on the details of the processes involved. 
Since the Carnot engine depicted in Fig. 1.1 is assumed reversible, by definition 
of a reversible process, the reversal of the processes in it would lead to the reversed 
Carnot engine in which the directions of the flow of heat and work are reversed (see 
Fig. 1.2) which means, operating in the reverse direction, work .W is put into the 
engine while it draws amount.Qc of heat from the reservoir at lower temperature. Tc
and deposits the amount .Qh in the reservoir at temperature .Th higher than . Tc. The 
engine in reverse operation thus acts as a refrigerator. The reverse Carnot engine is 
therefore also called Carnot refrigerator. 
Fig. 1.2 Reverse Carnot 
engine or Carnot refrigerator1.2 Carnot Engine 7
Next we describe how the concepts of absolute temperature and entropy arise 
from the analysis of combinations of Carnot engines operating in forward and reverse 
directions. 
1.2.1 Absolute Temperature 
We prove the following proposition and show how the concepts of absolute temper￾ature and entropy emerge therefrom: 
If it is assumed that heat cannot be transported from a cold to a hot reservoir without 
doing any work then 
1. No engine is more efficient than reversible Carnot engine. 
2. All reversible Carnot engines operating between same reservoirs have same effi￾ciency. 
This implies that the efficiency of a reversible Carnot engine is (a) independent of 
what the operating fluid is and (b) independent of the details of the thermodynamic 
processes inside the engine. 
It may be mentioned that Carnot assumed heat to be a massless fluid, a concept 
which is since abandoned. The analysis given below is essentially due to Clausius 
(in 1850s) based on Carnot’s work. 
To prove the propositions above, consider two engines operating as shown in 
Fig. 1.3. The engine on left (numbered 1) need not be reversible whereas the one 
on the right (numbered 2) is reversible Carnot engine operating in reverse direction. 
The engine 1 absorbs the amount .Qh of heat from the reservoir at temperature .Θh, 
performs work. W, and deposits the amount.Qc into the reservoir at temperature. Θc
(.Θh > Θc). The work produced by first engine is used as input to the engine 2 which 
uses it to absorb heat.Q,
c from the low-temperature reservoir and deposit heat.Q,
h in 
the high-temperature reservoir. Assume that the efficiency of engine 1 is.η1 and that 
of engine 2 is. η2. Clearly.η1 = W/Qh. Engine 2 is operating in the reverse direction. 
Fig. 1.3 .Θh > Θc. The 
engine on left (numbered 1) 
need not be reversible 
whereas the one on the right 
(numbered 2) is reversible 
Carnot engine operating in 
reverse direction8 1 Fundamentals of Thermodynamics-I
Since it is reversible its efficiency is obtained simply by reversing the directions of 
flow of work and heat. It then follows that.η2 = W/Q,
h. 
Now, contrary to the proposition to be proved, assume that the efficiency of pos￾sibly irreversible engine is more than that of the reversible one, i.e..η1 > η2 so that 
.
W
Qh
>
W
Q,
h
=⇒ Q,
h − Qh > 0. (1.5) 
Clearly, net work done in the process is zero and the operating fluids in the two 
engines are left in their initial corresponding states. Hence, due to conservation of 
energy, net amount of heat absorbed must also be zero so that 
.Qh + Q,
c = Q,
h + Qc. (1.6) 
On invoking (1.5) this yields 
.Q,
c − Qc > 0. (1.7) 
The condition.Q,
h − Qh > 0 in (1.5) means that a net amount of heat is deposited in 
the high-temperature reservoir whereas the condition .Q,
c − Qc > 0 in (1.7) means 
that a net amount of heat is drawn from the low-temperature reservoir. Since no work 
is done externally and, since the operating fluids are left in their initial states at the 
end of the cycle, the internal energy of the operating fluid is also unchanged. The 
conclusion drawn above then means that a net amount of heat has been drawn from 
the colder reservoir and delivered to the hotter one without performing any work. This 
is contrary to our experience. Hence, the assumption on which the said conclusion is 
based, namely, that the efficiency of possibly irreversible engine is greater than that 
of the reversible one is erroneous. We have thus proved that.η1 /> η2. 
Next we show that it is possible to have .η1 ≤ η2. Assuming that to be the case, 
it is readily seen that the conditions (1.5) and (1.7) would then reverse and read 
.Q,
h − Qh ≤ 0,.Q,
c − Qc ≤ 0, respectively. These conditions state that a net amount 
of heat is drawn from the hotter reservoir and delivered to the colder one without 
performing any work. This is an acceptable situation. We thus conclude that. η1 ≤ η2
where .η2 is the efficiency of the reversible Carnot engine and .η1 that of the engine 
which may or may not be reversible. This proves the first of the two propositions 
listed above. 
To prove the second of the said two propositions, assume that the engine 1 is also 
reversible. Since the inequality .η1 ≤ η2 proved above applies when engine number 
1 is any engine, it is applicable also when that engine is reversible. Now, if engine 
number 1 is reversible, it can be operated in the reverse direction. We therefore reverse 
the operations in Fig. 1.3 to get Fig. 1.4. The role of.η1 and.η2 is now interchanged. 
The arguments similar to those for arriving at the result .η1 ≤ η2 in case of the 
operations in Fig. 1.3 would lead to the conclusion .η2 ≤ η1. Thus when both the 
engines are reversible, one having efficiency .η1 and the other .η2 then we find that 
both the inequalities, viz., .η1 ≤ η2 and .η2 ≤ η1 should hold simultaneously, which1.2 Carnot Engine 9
Fig. 1.4 .Θh > Θc. Recall 
that engine number 2 in 
Fig. 1.3 is reversible but that 
numbered 1 need not be. 
When engine number 1 in 
Fig. 1.3 is also reversible 
then the operations in that 
figure can be reversed to get 
this one 
is possible only if.η1 = η2. We have thus proved the second proposition, namely, all 
reversible Carnot engines operating between same reservoirs have same efficiency. 
What the result derived above means is: Consider a reversible cyclic process oper￾ating between reservoirs at temperatures.Θh and.Θc (.Θh > Θc), drawing an amount 
.Qh of heat from the reservoir at temperature.Θh, performing work.W and depositing 
the amount.Qc of heat in the reservoir at temperature.Θc. Consider another reversible 
cyclic process operating between same reservoirs drawing a different amount.Q,
h of 
heat from the reservoir at temperature.Θh, performing different amount.W, of work 
and depositing different amount.Q,
c of heat into the reservoir at temperature.Θc. The 
result derived above, namely, the efficiency of all reversible Carnot engines operating 
between same reservoirs is same, on invoking (1.4), implies 
.
Qc
Qh
= Q,
c
Q,
h
. (1.8) 
Referring, for example, to the process depicted by the closed cycle .ABCDA in 
Fig. 1.10, we may consider a different closed cycle.A,
B,
C,
D,
A, in which the values 
of pressure and volume at the primed points are different from the corresponding 
unprimed ones but the primed cycle having the values of the temperatures.Th and. Tc
along the two isotherms same as the corresponding values on the unprimed cycle. 
The values.Q,
h and.Q,
c of the heat drawn and the heat deposited and the work output 
.W, in the primed cycle will be different from the corresponding quantities . Qh, Qc
and.W in the unprimed cycle but they will be such that (1.8) holds. 
In arriving at the conclusions above, no reference has been made to the equation 
of state of the operating fluid or to the processes employed. Hence the conclusion 
that the efficiency of all reversible Carnot engines is same depends neither on the 
working fluid, nor on its initial state, and nor on the details of the process. Hence, 
it follows that the efficiency of a reversible Carnot engine can be a function only of 
the remaining parameters in the process, namely, the temperatures.Θh and.Θc of the 
two reservoirs. We therefore let 
.1 − η ≡ Qc
Qh
= f (Θh, Θc), (1.9)10 1 Fundamentals of Thermodynamics-I
Fig. 1.5 The engine 1 is 
equivalent with the combined 
operation of the engines 2 
and 3 (.Θ1 > Θ2 > Θ3). All 
engines are reversible 
where. f (Θh, Θc) at this stage is an arbitrary function of its arguments. Since.η ≤ 1, 
. f (Θh, Θc) ≥ 0. Thus if a Carnot engine operates between reservoirs at temperature 
.Θa and .Θb .(Θa > Θb) drawing heat .Qa from the reservoirs at .Θa and depositing 
heat.Qb into the reservoirs at.Θb then 
.
Qb
Qa
= f (Θa, Θb), Θa > Θb. (1.10) 
The form of the function may be determined as follows. 
Since the function . f (Θa, Θb) is universal we can consider any process conve￾nient for its determination. To that end we consider the combination of Carnot 
cycles depicted in Fig. 1.5 which is self-explanatory. All the engines in the figure 
are reversible with .Θ1 > Θ2 > Θ3. The figure depicts three engines: (1) engine 1 
which absorbs heat .Qh from the reservoir at temperature .Θ1, deposits heat .Qc into 
the reservoir at temperature.Θ2, and generates work.W12; (2) engine 2 which absorbs 
heat.Qh from the reservoir at temperature.Θ1, deposits heat.Q3 into the reservoir at 
temperature.Θ3, and generates work.W13; (3) engine 3 which absorbs heat.Q3 from 
the reservoir at temperature .Θ3, deposits heat .Qc into the reservoir at temperature 
.Θ2 by absorbing work.W23. Since engine 3 draws as much heat from the reservoir at 
temperature.Θ3 as the engine 2 deposits in it, the combination of the engines 2 and 3 
may be considered as operating effectively between the reservoirs at the temperatures 
.Θ1 and .Θ2 which draws heat .Qh from the reservoir at .Θ1 and deposit heat .Qc into 
the reservoir at .Θ2. The combined operation of the engines 2 and 3 is thus same as 
that of engine 1. 
Now, the work generated by the combination of the engines 2 and 3 is evidently 
.W13 − W23. Using the principle of conservation of energy we have.W13 = Qh − Q3, 
.W23 = Qc − Q3 and hence the work.W12 generated by the engine 1 may be written 
as 
.W12 = Qh − Qc = (Qh − Q3) + (Q3 − Qc) = W13 − W23. (1.11)1.2 Carnot Engine 11
Thus the engine 1 generates as much work as the combination of the engines 2 and 
3. Since we have already shown that the combination of the engines 2 and 3 operates 
effectively between the same reservoirs as does the engine 1 and draws/deposits the 
same amount of heat from/into each of the said reservoirs as does the engine 1, it 
follows that the engine 1 is equivalent with the combined operation of the engines 2 
and 3. Now, 
.
Qc
Qh
= Q3
Qh
/ ( Q3
Qc
)
. (1.12) 
Each of the ratio of the quantities of heat in the equation above is between the 
quantities of heat drawn/deposited in the reservoirs in one or the other Carnot cycle. 
We can therefore use the relation (1.10) in (1.12) to obtain 
. f (Θ1, Θ2) = f (Θ1, Θ3)
f (Θ2, Θ3)
. (1.13) 
There is no.Θ3 on the left side. Hence.Θ3 must cancel in the right side. This can be 
achieved if. f (Θa, Θb) = g(Θb)/g(Θa). With.θ ≡ g(Θ), (1.9) reads 
.
Qc
Qh
= θ2
θ1
. (1.14) 
The quantity. θ is called the absolute temperature. Since the relation above is univer￾sal, one way of fixing the value of. θ in terms of measured temperature is to consider 
a Carnot cycle with such operating fluid and transformations corresponding to which 
we can evaluate.Qc/Qh analytically exactly to determine thereby. θ in terms of mea￾sured temperatures. In Sect. 1.5, we have considered one such process taking ideal 
gas as the operating fluid. We have shown that.Qc/Qh = Tc/Th where. T is temper￾ature on the Kelvin scale. Hence, for a reversible Carnot engine operating with any 
fluid and process, 
.
Qh
Th
= Qc
Tc
. (1.15) 
We refer to the equation above as Carnot’s formula. Feynman (see [ 1], pp. 44– 
49) calls (1.15) the center of universe of thermodynamics just as Force = mass . ×
acceleration is the center of universe of mechanics. According to him, the relation 
(1.15) is all to thermodynamics as Force = mass.× acceleration is all to mechanics! 
On using (1.15), the expression (1.9) for the efficiency of the Carnot engine 
operating between heat reservoirs at temperatures.Th and.Tc reads 
.η = 1 − Tc
Th
, Th > Tc. (1.16) 
The efficiency can be unity if.Tc = 0 or.Th = ∞. Since.0 ≤ η ≤ 1,.T ≥ 0.12 1 Fundamentals of Thermodynamics-I
To underline the significance of (1.15), note that if .Q (.Q > 0) is the amount of 
heat delivered by the system to the reservoir then we may equivalently say that. −Q
is the amount of heat received by the system. The relation (1.15) for the reversible 
cyclic process may then be rewritten as 
.Qh/Th + (−Qc/Tc) = 0. (1.17) 
This states that, if .Q is the amount of heat absorbed reversibly by the system at 
temperature. T then in the reversible cyclic process involving two heat reservoirs, the 
sum of.Q/T is zero. 
1.2.2 Entropy 
Equation (1.17) shows that the quantity .Q/T is a constant in the reversible Carnot 
cycle. It is called entropy of the system. Entropy is generally denoted by the letter 
. S: 
.S = Q
T , Q absorbed reversibly at temperature T. (1.18) 
The name entropy was coined by Clausius in 1868. It is derived from the combination 
of English “en” meaning inside and Greek “trop. e˜” meaning transformation to indicate 
that it describes some transformation taking place inside the system. Explaining his 
reason for choosing to name.Q/T as entropy, Clausius states that he wanted to choose 
such a name which is as close as possible to energy. It is believed that he chose. S as 
the symbol for entropy to honor Sadi Carnot as it is the first letter of his first name. 
On using (1.18) in (1.17) we see that total change in entropy of the system in a 
reversible Carnot cycle is zero: 
.ΔSsys ≡ Qh/Th + (−Qc/Tc) = 0. (1.19) 
The equation above gives change in entropy of the working fluid in a reversible Carnot 
cycle exchanging heat with reservoirs at temperatures.Th and. Tc. Let us find change 
in entropy of the reservoirs. To that end note that, by definition, a heat reservoir 
absorbs or gives away heat reversibly. Hence, since it gives away the amount.Qh at 
temperature. Th, change in entropy of the hotter heat reservoir is.−Qh/Th. Similarly 
change in entropy of the colder heat reservoir is .Qc/Tc. We call the two reservoirs 
together as constituting the environment. Hence, change in entropy of the environment 
during the process in question is 
.ΔSenv ≡ −Qh/Th + Qc/Tc = 0. (1.20)1.2 Carnot Engine 13
Fig. 1.6 Engine operating 
between the reservoirs at 
temperatures.Th and.Tc by 
irreversible cyclic process. It 
draws heat.Qh from the 
reservoir at temperature. Th, 
performs work.W,
, and 
releases heat.Q,
c into the 
reservoir at temperature. Tc
Total change in entropy of the combined system of the environment and the fluid in 
the reversible Carnot engine is 
.ΔSsys + ΔSenv = 0, reversible process. (1.21) 
The system under consideration and its environment together are said to constitute 
the universe. The equation above shows that there is no change in entropy of the 
universe in a reversible Carnot cycle. 
Next we find change in the value of .Q/T in an irreversible Carnot-type cycle. 
To that end, consider an engine operating cyclically by some irreversible process, 
drawing heat .Qh from the reservoir at temperature .Th and depositing heat .Q,
c into 
the reservoir at temperature.Tc by generating work.W, (see Fig. 1.6). The efficiency 
of the process is .ηirr. We have shown that .ηirr is less than the efficiency . η of a 
reversible Carnot engine operating between same reservoirs drawing same amount 
of heat from hot reservoir. With .ηirr = W,
/Qh = (Qh − Q,
c)/Qh, and . η given by 
(1.16), the inequality.ηirr < η yields 
.
Qh
Th
− Q,
c
Tc
< 0, irreversible cyclic process. (1.22) 
This shows that there is net loss of the quantity.Q/T in an irreversible cyclic process. 
It should be emphasized that if the amount .Q of heat absorbed by the system at 
temperature .T is by an irreversible process then .Q/T is not the change in entropy 
of the system. 
However, even when the system absorbs and gives away heat irreversibly from 
the reservoirs, the heat absorbed or given away by a heat reservoir is a reversible 
process for the reservoir. Hence.−Qi/Ti is the change in entropy of the reservoirs if 
it gives away the amount of heat.Qi while remaining at the temperature. Ti all through 
the process. In the case of the process under discussion in which the reservoir at 
temperature.Th gives away the amount.Qh and the one at.Tc receives the amount. Q,
c
of heat, total change in entropy of the two reservoirs which constitute the environment 
is given by 
.ΔSenv ≡ −Qh/Th + Q,
c/Tc > 0, (1.23)14 1 Fundamentals of Thermodynamics-I
where last inequality is due to (1.22). This shows that entropy of environment 
increases when the system coupled with it performs irreversible processes. 
The significance of.Q/T in an irreversible process lies, as proved next, in the fact 
that it is a measure of the reduction in the amount of work generated by an irreversible 
process compared with that generated in a reversible process operating between same 
heat reservoirs and drawing the same amount of heat. It is called the lost work. To that 
end, note that the work generated by irreversible engine is.W, = Qh − Q,
c whereas 
the work generated by the reversible engine is.W = Qh − Qc =. Qh(1 − Qc/Qh) =
.Qh(1 − Tc/Th). It is straightforward to see that 
.W, − W = Tc
( Qh
Th
− Q,
c
Tc
)
< 0, (1.24) 
where the last inequality is by virtue of (1.22). This shows that the reduction in the 
value of.Q/T in an irreversible cyclic process is a measure of the loss of work that 
could have been available were the process reversible. For another way of describing 
the lost work, recall (1.23) to rewrite (1.24) as 
.W, = W − TcΔSenv. (1.25) 
Thus increase in entropy of the environment may be considered as the measure of 
the lost work. 
We will derive the equivalent of.Q/T for a general transformation as part of the 
second law of thermodynamics. 
1.3 Laws of Thermodynamics 
In this section we list the laws of thermodynamics. 
1.3.1 Zeroth Law 
After the formulation of three laws of thermodynamics to be listed below, the need 
for stating now named zeroth law was realized. It was apparent that logically the said 
law should be stated before the other three already formulated and numbered laws. 
Hence the name. The zeroth law states that 
If a system. A is in thermal equilibrium with. B and also separately with. C then. B
and. C are in thermal equilibrium with each other. 
To see the consequences of this law, assume that .PA, VA are the pressure and 
volume that specify the state of the system. A and.PB, VB are those for the system. B
when it is in thermal equilibrium with. A. The equilibrium between the two systems 
implies that the two sets of variables are related. Let that relationship be expressed1.3 Laws of Thermodynamics 15
in the form .PA = f (VA, PB, VB). Similarly, when .A is also in thermal equilibrium 
with .C then we will have the relationship .PA = f (VA, PC, VC) between the state 
variables of. A and. C. Consequently we arrive at the equation 
. f (VA, PB, VB) = f (VA, PC, VC). (1.26) 
Note that the relationship above is arrived at by assuming .A to be in thermal equi￾librium with .B and with . C. Now, according to the law stated above, .B and .C must 
also be in thermal equilibrium with each other. Hence, there must be a relationship 
between the state variables of.B and. C. Equation (1.26) will be the desired relation 
provided it is independent of.VA because the equilibrium condition between the sys￾tems.B and.C cannot depend on the variables of any other system. That will be the 
case if. f (VA, P, V ) is of the form 
. f (VA, P, V ) = g(P, V )h1(VA) + h2(VA). (1.27) 
On using this, (1.26) reduces to 
.g(PB, VB) = g(PC, VC). (1.28) 
This shows that there exists a function .g(P, V ) which has the same value for the 
systems in thermal equilibrium. We call that function temperature. T˜:.T˜ = g(P, V ). 
The last equation defines the equation of state. However neither this law nor the other 
laws of thermodynamics determine the form of the function.g(P, V ). We know the 
equation of state under some special conditions on the fluids. For example, for an ideal 
gas, we know that the equation of state is.T = PV/NkB where. T is the temperature 
on the Kelvin scale. In this case.T˜ = T and.g(P, V ) = PV/NkB. A different form 
of.g(P, V) would result if the gas is not ideal. 
1.3.2 First Law 
The first law is the statement of conservation of energy. It states that the internal 
energy.U of a thermodynamic system is a state function such that 
If .δQ is the amount of heat absorbed and .δW the amount of work done by the 
system in an arbitrary transformation then change.δU in its internal energy is given 
by 
.δU = δQ − δW. (1.29) 
The amount of heat absorbed and the work done by the system to transform from 
one state to another depends not only on the initial and final states, but also on the 
path that the transformation follows in the space of state variables. To indicate the 
said path dependence, the amount of heat absorbed and the work done by the system16 1 Fundamentals of Thermodynamics-I
in an infinitesimal transformation are denoted generally by.d Q¯ and.dW¯ , respectively. 
The differentials.d Q¯ and.dW¯ are imperfect (see also Sect. 2.8). 
However, .U is a state function in the sense that it has a unique value for the 
system in a given state. Hence, the change in it during a transformation is simply 
the difference in its values in the final and the initial states, independent of the path 
that the transformation follows in the space of state variables. Infinitesimal change in 
internal energy is therefore denoted by .dU, a perfect differential. The infinitesimal 
form of the first law therefore reads 
.dU =d Q¯ −dW¯ . (1.30) 
Though change in the internal energy is due to transfer of heat and/or work, the 
internal energy cannot be partitioned as heat and work energies. 
The work may consist of several components each caused by change in some 
macroscopic control parameter, say,. ξi (.i = 1, 2,... m) so that 
.dW¯ = −Σm
i=1
Fidξi . (1.31) 
The.Fi is the “force” associated with the change in. ξi . The negative sign in (1.31) is 
because .dW¯ in (1.30) is work performed by the system whereas .Fidξi is the work 
performed on it by the force. Fi . 
In particular, if the volume .V is the only macroscopic control parameter then 
.dW¯ = PdV where.P is the pressure and (1.30) reads 
.dU =d Q¯ − PdV. (1.32) 
The gas gains energy when its volume decreases and loses energy when its volume 
increases. 
1.3.3 Second Law 
The first law is the statement of conservation of energy. It is, however, not sufficient 
to determine the permissible thermodynamic processes. For example, if two bodies 
at different temperatures are placed in contact, the first law does not rule out the 
possibility of transfer of heat from cold to hot body on its own, a process we never 
observe. The second law, to be stated below, determines permissible processes in 
terms of the concept of entropy. 
There are two equivalent ways of stating the second law: 
1. Kelvin statement: There does not exist any thermodynamic transformation whose 
sole effect is to extract heat from a heat reservoir and convert it entirely into work.1.3 Laws of Thermodynamics 17
Fig. 1.7 The figure shows the solid line path from .A to .B divided into segments. Though not 
shown the dotted path is divided similarly. The ith segment is connected with the reservoir .Ri at 
temperature.Ti which in turn is connected to a reversible Carnot engine operating between.Ri and 
another reservoir at temperature.T0 generating work.dW¯ i . Though not shown in the figure, similar 
construction is assumed for all points on the solid as well as dotted return path in the figure 
2. Clausius statement: There does not exist any thermodynamic transformation 
whose sole effect is to extract heat from a body at lower temperature and deliver 
it to the one at higher temperature. 
We do not address the question of showing equivalence of the two statements (see, 
for example, [Huang]). 
In Sect. 1.2, we used the Clausius statement to arrive at the concept of entropy and 
its properties in a reversible cyclic process in which flow of heat into the system or 
out of it involved only two reservoirs at different temperatures. We generalize those 
considerations to an arbitrary quasi-static cyclic transformation in which the system 
may be at different temperatures during the transformation. 
To that end, referring to Fig. 1.7, consider a quasi-static cyclic process that takes 
the system from the state represented by. A to that represented by.B along the solid 
line path and back to .A along the dotted line path. Divide the paths from .A to . B
and also from .B to . A, in infinitesimal elements. Let .Ti be the temperature of the 
system at the point . i on the path, as if in equilibrium with a reservoir .Ri at that 
temperature. From. i it evolves to the neighboring state as if by drawing the amount 
of heat .d Q¯ i from the reservoir .Ri while performing work .dW¯ (s)
i . The change in the 
internal energy .dUi in the infinitesimal transformation at the point . i on the path is 
then, according to the first law, given by 
.dUi =d Q¯ i −dW¯ (s)
i . (1.33) 
Now, imagine a reversible Carnot engine operating between the reservoir.Ri and the 
reservoir .R0 which is at some fixed temperature .T0 (.T0 > Ti for all . i) such that it18 1 Fundamentals of Thermodynamics-I
draws an amount of heat .d Q¯ 0
i from .R0 and delivers the amount of heat .d Q¯ i to . Ri
while producing work.dW¯ i for all.i = A → B → A so that 
.dW¯ i =d Q¯ 0
i −d Q¯ i . (1.34) 
Since the Carnot engine between .Ri and .R0 is reversible, Carnot’s formula (1.15) 
holds so that 
.
d Q¯ i
Ti
= d Q¯ 0
i
T0
. (1.35) 
Summing over all. i we get 
.
Σ
i=A→B→A
d Q¯ i
Ti
= Σ
i=A→B→A
d Q¯ 0
i
T0
. (1.36) 
In the limit of the number.N of points becoming infinitely large, we can convert the 
summations to integrals to get 
.
{ d Q¯
T = 1
T0
{
d Q¯ 0
i ≡ Q0
T0
, (1.37) 
where .Q0 is total amount of heat drawn from the reservoir at temperature .T0 when 
the process completes a cycle. The closed integral is from. A to. B along the solid line 
path and then back to. A along the dotted line path. In the following we show that. Q0
must be negative. 
To that end, add (1.33) and (1.34) to get 
.dUi =d Q¯ 0
i −dW¯ (s)
i −dW¯ i . (1.38) 
Sum this over.i = A → B → A and note that 
1. Since, while summing over .i = A → B → A, the system starts from .A and 
returns to it, the change in its internal energy is zero: 
.
Σ
i=A→B→A
dUi = 0. (1.39) 
2. Total work done by the cyclic process in going from .A to .B and returning back 
to. A, together with the work done by all the Carnot engines, is 
.WT = Σ
i=A→B→A
[
dW¯ i +dW¯ (s)
i
]
. (1.40)1.3 Laws of Thermodynamics 19
Hence summation of (1.38) over. i along with the use of Equations (1.39) and (1.40) 
and conversion of summation over. i to integral yield 
.WT =
{
d Q¯ 0
i ≡ Q0. (1.41) 
We can understand this result by describing the process depicted in Fig. 1.7 as follows: 
While evolving from the point . i to the neighboring point, the system receives 
the amount .d Q¯ i of heat from the reservoir .Ri which is the same as the heat that . Ri
receives from the Carnot engine, imagined to be connected to it. We can therefore 
say that all the heat given away by the Carnot engines is received by the system 
under consideration. The combination, consisting of the system under considerations, 
the reservoirs .R,
is, and the Carnot engines constitute the entire system exchanging 
amount .Q0 of heat with the reservoir at temperature .T0 through the Carnot engines 
connected to it. 
As regards work, total work done by the entire system is evidently .WT , the sum 
of the work done by the Carnot engines and that by the system under consideration 
while evolving cyclically from. A to. B and back to. A. 
At the end of the cyclic process, each part of the entire system returns to its initial 
state. Hence, depending on the sign of.Q0, and due to the relation.WT = Q0 derived 
in (1.41), the overall process in the entire system interacting with the reservoir at 
temperature .T0 is equivalent with one or the other process in Fig. 1.8. The process 
depicted on the left in that figure represents overall process in Fig. 1.7 in case.Q0 > 0. 
It describes a cyclic process in which the amount .Q0 of heat is extracted from the 
reservoir at temperature.T0 and converted entirely to work without any other change. 
Such a process is ruled out by the second law. 
On the other hand, the process depicted on the right in Fig. 1.8 represents overall 
process in Fig. 1.7 in case.Q0 < 0. It describes a cyclic process in which the amount 
of work .WT is converted entirely into heat which is deposited in the reservoir at 
temperature. T0. Such a process is not ruled out by the second law. Consequently due 
to (1.37) we must have 
.
{ d Q¯
T ≤ 0. (1.42) 
This is a form of the second law of thermodynamics. 
Fig. 1.8 Figure on the left 
depicts the overall process of 
Fig. 1.7 when.Q0 > 0 and 
that on the right when 
.Q0 < 020 1 Fundamentals of Thermodynamics-I
We now show that the equality in the equation above holds if the process is 
reversible. To that end, note that if the process is reversible then its reverse is described 
by the reversal of signs of heat and work flows. Hence the condition equivalent with 
(1.42) for the reversed process will be obtained by the transformation . d Q¯ → −d Q¯
leading to the equation 
. −
{ d Q¯
T ≤ 0, if the process is reversible and is reversed. (1.43) 
Equations (1.42) and (1.43) can be satisfied simultaneously if 
.
{ d Q¯
T = 0, reversible closed path. (1.44) 
It is straightforward to prove that (1.44) implies 
.
{ B
A
d Q¯
T is independent of path between A and B if reversible. (1.45) 
To prove this, refer to Fig. 1.7 to write (1.44) as 
.
[{
A to B along solid path
+
{
B to A along dotted path]
d Q¯
T = 0. (1.46) 
If the process is reversible then. B to. A can be reversed in which case 
. [{
B to A along dotted path]
d Q¯
T = − [{
A to B along dotted path]
d Q¯
T .
(1.47) 
On substituting this in (1.46) we see that 
. [{
A to B along solid path]
d Q¯
T =
[{
A to B along dotted path]
d Q¯
T .
(1.48) 
Since, for a given reversible solid path the choice of the dotted path is arbitrary, it 
follows that the value of the integral of.d Q¯ /T on a reversible path does not depend 
on the path. It depends only on the end points. This proves (1.45). This in turn means 
that.d Q¯ /T on a reversible path is a perfect differential which we denote by.dS: 
.dS = d Q¯
T , along reversible path. (1.49)1.3 Laws of Thermodynamics 21
Fig. 1.9 The process from B 
to A along the path I is 
reversible whereas that from 
A to B along the path II is 
irreversible 
Hence, with.O as any reference point, the quantity 
.S(A) =
{ A
O
d Q¯
T , along reversible path, (1.50) 
depends only on the state . A. The .S(A) is called entropy of the state . A. Since it 
depends only on the state variables characterizing a state, entropy is a state variable. 
The change in entropy in going from. A to. B is given by 
.S(B) − S(A) =
{ B
A
d Q¯
T , along reversible path. (1.51) 
Now, assume that the path from. B to. A is reversible but that from. A to. B is irreversible 
(see Fig. 1.9). Equation (1.42) then reads 
.
[{
along reversible path I
+
{
along irreversible path II]
d Q¯
T
< 0. (1.52) 
Since path . I is reversible, the first integral is nothing but .S(A) − S(B) leading 
thereby to the inequality 
.
{
A→B
d Q¯
T
< S(B) − S(A), irreversible path from A to B. (1.53) 
This may also be rewritten as 
.
{
A→B irr
d Q¯
T
<
{
A→B rev
d Q¯
T . (1.54) 
This shows that the change in.d Q¯ /T over an irreversible path between two states is 
less than that on any reversible path between same states. 
Some Consequences of Second Law 
1. Consider a system interacting with a reservoir, drawing the amount .d Q¯ of heat 
from it at temperature. T by reversible or irreversible process. The quantity. d Q¯ /T
for the system therefore may or may not stand for change in its entropy. However, 
the processes inside a reservoir are reversible. Hence, since .d Q¯ is the amount of22 1 Fundamentals of Thermodynamics-I
heat given out by it at temperature. T ,.−d Q¯ /T stands for the change in entropy of 
the reservoir. Since all the reservoirs from which the system draws heat in going 
from state .A to state .B constitute its environment, it follows that the change in 
entropy of the environment is given by 
.ΔSenv = − { B
A
d Q¯
T . (1.55) 
On substituting this in (1.53) it follows that, as the state of the system changes 
from. A to. B, 
.ΔSuniverse ≡ ΔSenv + ΔSsys ≥ 0, ΔSsys ≡ S(B) − S(A). (1.56) 
The equation above shows that entropy of the universe never decreases. 
2. Assume that the system is thermally isolated. In that case it does not exchange 
heat with its environment, i.e. .d Q¯ = 0. Hence .ΔSenv = 0 as a consequence of 
which it follows from (1.56) that, as the system transforms from state . A to state 
. B, its entropy cannot decrease: 
.S(B) − S(A) ≥ 0, thermally isolated system. (1.57) 
The system in question may be the universe itself which is evidently thermally 
isolated. Like the conclusion drawn from (1.56), the equation above when applied 
to the universe shows that the entropy of universe never decreases. 
3. Consider a thermally isolated system in some state . A. Relax some of its con￾straints. Equation (1.57) shows that it will evolve to the state. B whose entropy is 
more than that in the state. A. However, subject to the relaxed constraints, if there 
is another state. C available whose entropy is more than that in the state. A then it 
will evolve to. C. Continuing this argument we see that a thermally isolated system 
would evolve to the state of maximum entropy consistent with the constraints on 
it. This is called the principle of maximum entropy. This principle will constitute 
one of the postulates of the postulatory approach to thermodynamics outlined in 
Chap. 2. 
4. Consider a reversible process which takes a system from state. A to state. B. From 
the first law we know that the change in internal energy of the system is given by 
.dU =d Q¯ −dW¯ rev = T dSsys −dW¯ rev, (1.58) 
where the second equation is due to the fact that the process is reversible so that 
.d Q¯ = T dSsys. The change in the internal energy in going from .A to .B is given 
by 
.UB − UA =
{ B
A
[
T dSsys −dW¯ rev]
, reversible path. (1.59)1.3 Laws of Thermodynamics 23
Consider another process which connects the same two states as in the said 
reversible process but now by an irreversible path so that 
.dU =d Q¯ −dW¯ irrev. (1.60) 
Since the process is irreversible, .d Q¯ /= T dS. The change in internal energy in 
going from the state. B to the state. A in this case would be 
.UB − UA =
{
A→B irrev
[d Q¯ −dW¯ irrev] . (1.61) 
Since internal energy is a state variable, the value of .UB − UA is same whether 
the process is reversible or not. Hence, on equating (1.59) and (1.61) it follows 
that 
.Wlost =
{ B
A
T dSsys −
{
A→B, irrev
d Q¯ , (1.62) 
where 
.Wlost = Wrev − Wirrev, (1.63) 
with.Wrev denoting the work done along the reversible path, 
.Wrev =
{ B
A
dW¯ rev, (1.64) 
and 
.Wirrev =
{
A→B irrev
dW¯ irrev (1.65) 
is the work done when transformation is irreversible. The difference between the 
said two works is the lost work denoted by .Wlost. In particular, if the process is 
isothermal then. T can be taken into or out of the integral so that 
. Wlost = T
[{ B
A
dSsys −
{
A→B irrev
d Q¯
T
]
= T (
ΔSsys + ΔSenv)
≡ TΔSuniverse, (1.66) 
where the second equation is due to (1.55). By virtue of (1.56), .ΔSuniverse > 0. 
The equation above relates lost work in an isothermal irreversible process with 
change in entropy of the universe.24 1 Fundamentals of Thermodynamics-I
5. If the work done is only by change of volume, then (1.58) for a reversible process 
reduces to 
.dU = T dS − PdV, (1.67) 
where the quantities in the equation above are for the system under observation. 
6. Let a system undergo thermodynamic transformation from some state. A to. B by 
a process which may be irreversible. In that case we cannot evaluate change in 
its entropy by using the formula in (1.51) as that is applicable when the process 
is reversible. However, since entropy is a state function, we can imagine some 
reversible process connecting the states in question and evaluate entropy using 
(1.51). 
7. We know that an adiabatic process is defined as the one which does not involve 
exchange of heat with the environment. We also know that.dq¯ = T dS if the pro￾cess is reversible. Hence entropy is unchanged in a reversible adiabatic process. 
Such a process is called isentropic. However, .d Q¯ /= T dS if the process is irre￾versible. Hence an irreversible adiabatic process is not isentropic. An example of 
irreversible adiabatic process is free expansion of a gas. The change in entropy in 
this case for an ideal gas is evaluated in Ex. 1.1. 
The second law determines the change in entropy during a transformation and hence 
determines the value of entropy in a given state up to an arbitrary constant. That 
arbitrary constant is fixed by the third law. 
1.3.4 Third Law 
The second law determines change in entropy but not its absolute value. Entropy can 
be assigned absolute value in any state by assigning it a value in a particular state. 
Third law achieves that end by asserting that 
The entropy of any system at.T = 0 is zero. 
This is Planck’s formulation of the Third law. It is stronger version of Nernst’s heat 
theorem, formulated in 1905, according to which the change in entropy is zero as 
.T → 0: 
.LtT→0ΔS = 0. (1.68) 
It is equivalent with the statement that entropy is independent of external parame￾ters, i.e. .S(T, x1) = S(T, x2) as .T → 0 where .x1, x2 are different sets of values of 
external parameters. Nernst theorem, on its own or combined with the assumption 
of boundedness of the derivative of entropy with respect to temperature at .T = 0, 
predicts vanishing of several physical quantities (see the exercises below which will 
need use of Maxwell relations compiled in (2.98)). An interesting consequence of it, 
not elaborated here, is the question of unattainability of.T = 0 (see [Callen]).1.4 Ideal Gas Equations of State 25
The applicability and limitations of the third law are, however, understood best 
in the framework of quantum statistical mechanics (see Sect. 6.4.4). 
Exercises 
Ex. 1.1. Show that in adiabatic free expansion of a gas 
.ΔU = 0, adiabatic free expansion. (1.69) 
Hint: An adiabatically expanding gas does not exchange heat with its sur￾roundings so that.ΔQ = 0. Since expansion is free, it does not perform any 
work even. Consequently (1.69) follows using first law. 
Ex. 1.2. Show that, as a consequence of (1.68), as .T → 0, (i) .αP → 0 where . αP
is the coefficient of isobaric thermal expansion defined in (2.111), (ii) 
.(∂ P/∂T )V → 0. Hint: Use Maxwell relations . (∂V/∂T )P = −(∂ S/∂ P)T
and.(∂ P/∂T )V = (∂ S/∂V)T given in (2.98). 
Ex. 1.3. Consider a reversible process. The heat capacities at constant volume 
and that at constant pressure are given, in terms of entropy, by . CV =
T (∂ S/∂T )V (see (2.101)) and.CP = T (∂ S/∂T )P (see (2.107)). Show that 
.CV ,CP → 0 as.T → 0 if, in addition to (1.68) it is assumed that. (∂ S/∂T )V
and.(∂ S/∂T )P are bounded as.T → 0. 
1.4 Ideal Gas Equations of State 
The zeroth law tells us that, at thermodynamic equilibrium, there exists a relation￾ship between the thermodynamic variables.P, V, T . It is called the equation of state. 
However, that law, or even the other laws put together, cannot determine the equation 
of state for any gas. That equation must be found either phenomenologically or by 
some theory like statistical mechanics. As mentioned circa (1.2), the said equation of 
state does not provide complete description of a system in thermodynamic equilib￾rium. We will formally define an equation of state in Chap. 2 and show that complete 
thermodynamic description of a one component system (i.e. a system composed of 
one kind of molecules) is provided by two independent equations of state. We there￾fore need to construct second equation of state for the ideal gas. The second equation 
of state we construct is the relation between.U, V, T . 
Like the equation of state relating.P, V, T , the second equation of state must also 
be determined either phenomenologically or theoretically. We address the question of 
constructing the second equation of state in detail in Sect. 2.14 and find that, though 
the two equations of state are independent, the thermodynamic relations impose 
consistency requirement on them.26 1 Fundamentals of Thermodynamics-I
In the following subsection, we outline the phenomenological approach to derive 
the additional equation of state.U = U(V, T ) obeyed by an ideal gas. 
1.4.1 Internal Energy of Ideal Gas 
The first law of thermodynamics determines the change in the internal energy . U
of a substance when it is supplied heat and work. The question is: can that law or 
its combination with other laws determine .U as a function of the thermodynamic 
state variables? To answer that question note that, since.P, V, T are related by some 
equation of state,.U may be expressed as a function of two of the three said variables. 
Let.U = U(V, T ). Invoking the first law (1.32) we have 
.
(∂U
∂T
)
V
=
(∂ Q
∂T
)
V
≡ CV , (1.70) 
where, by definition, 
.CV =
(∂ Q
∂T
)
V
(1.71) 
is the heat capacity at constant volume. 
To determine dependence of internal energy on volume, Joule conducted following 
experiment. He took a vessel, having conducting walls, divided into two parts, one 
part was kept in the state of vacuum and the other had air in it at high pressure. 
The two parts were separated by an immovable partition which had an opening with 
a stopcock. The vessel was immersed in water at the same temperature as air and 
stopcock opened to allow air to expand. At equilibrium air fills the whole volume 
of the vessel. Since gas does no external work while expanding, any change in its 
internal energy will result in its exchanging heat with water thereby changing its 
temperature. No change in temperature of water was observed which showed that 
the internal energy of air when it occupied a part of the volume of the box is same as 
when it occupied its whole volume. This established independence of internal energy 
of ideal gas on volume. However, doubts arose as to what if change in temperature 
of the gas is too small to have been observed due to much lower heat capacity 
of the gas compared with that of the vessel and water. More accurate experiments 
were conceptualized and performed by Thomson and Joule (in 1845) which involved 
direct measurement of temperature of the gas (see Sect. 2.15). Those experiments 
confirmed the finding of Joule’s experiment. 
As a result of the experiments, we conclude that internal energy of an ideal gas 
is independent of volume. It is also known experimentally that the heat capacity of 
ideal gas is independent of temperature. Consequently.CV is a constant so that (1.70) 
leads to the following expression for internal energy:1.4 Ideal Gas Equations of State 27
.U(V, T ) = CV T, (1.72) 
where integration constant has been taken as zero. 
Of interest is also the heat capacity.CP at constant pressure: 
.CP =
(∂ Q
∂T
)
P
. (1.73) 
Invoking the first law (1.32) we see that 
.
(∂U
∂T
)
P
= CP − P
(∂V
∂T
)
P
. (1.74) 
On using (1.1) and (1.72) the equation above may be rewritten as 
.CP − CV = NkB. (1.75) 
In terms of the parameter. γ , called adiabatic constant, defined by 
.γ = CP
CV
, (1.76) 
Equation (1.75) yields 
.CV = cNkB, c = 1
γ − 1
. (1.77) 
Using this, the expression (1.72) for.U assumes the form 
.U = cNkBT. (1.78) 
The physics meaning of the constant . c is best appreciated in the framework of sta￾tistical mechanics (see Sect. 7.4). We will see that.c = 3/2 for a monatomic gas 
.γ = 5
3
, ideal monatomic gases. (1.79) 
The multi-atom molecules have internal degrees of freedom too, like rotation and 
vibration which contribute to the value of. c, evaluated in Sect. 7.4. 
Summary 
An ideal gas is described by following two equations of state: 
.PV = NkBT, U = cNkBT, c = 1
γ − 1
, γ = CP
CV
. (1.80)28 1 Fundamentals of Thermodynamics-I
We apply the results derived above to a cyclic process to realize the Carnot engine 
with ideal gas as the working fluid. We find the efficiency of the process and show 
that it agrees with Carnot’s formula. In the exercises at the end of the chapter, we 
evaluate efficiency of the said cyclic process with non-ideal gases as the working 
fluid to confirm Carnot’s formula. 
1.5 A Cyclic Process to Realize Carnot Engine 
Consider the cyclic process depicted in Fig. 1.10. The working fluid in it can be any 
gas—ideal or non-ideal. For now we assume the gas to be ideal. Cases of non-ideal 
gases obeying particular equations of state as also the case of a gas obeying arbitrary 
equation of state as a working fluid are discussed in the exercises at the end of the 
chapter. The gas is initially in equilibrium at temperature .Th and its pressure and 
volume .Pa, Va are represented by the point .A on the .P − V diagram. Let the gas 
expand isothermally to volume.Vb with.Pb as its pressure. This state is represented by 
the point. B on the.P − V diagram. The temperature is kept constant by keeping the 
gas in contact with a heat reservoir at the desired temperature. As the gas expands, it 
does work against pressure and loses internal energy. The temperature of the gas is 
maintained at constant value by the heat it receives from the heat reservoir in contact 
with it. We denote by.Qh the amount of heat absorbed. 
At .B the gas is isolated from the heat reservoir. It expands further but without 
exchanging heat with the environment. This is adiabatic expansion. It continues till 
its volume and pressure become.Vc and.Pc (point. C on the.P − V diagram). Let its 
temperature at. C be. Tc. 
At. C it is brought in contact with the reservoir at temperature.Tc and compressed 
isothermally till its volume and pressure become .Pd , Vd (point .D on the . P − V
diagram). It gains energy as its volume decreases but it gives away heat energy to 
Fig. 1.10 .P − V diagram of 
a cyclic process to realize 
Carnot engine with.Th > Tc. 
The processes are assumed 
to be reversible 
Adiabatic 
Adiabatic1.5 A Cyclic Process to Realize Carnot Engine 29
the reservoir so that its temperature is maintained at constant value. Tc. We denote by 
.Qc the amount of heat it loses to the reservoir. 
At .D it is again isolated and compressed adiabatically till its pressure, volume, 
and temperature attain their initial values.Pa,.Va, and. Th. Since the process from. D
to. A is adiabatic, no heat is exchanged with the surroundings. 
All the processes in the said cycle are carried reversibly. The gas absorbs the 
amount.Qh of heat along the isothermal path.AB and gives out the amount.Qc along 
the isothermal path.C D. Since the transformations along.BC and.D A are adiabatic, 
no heat is absorbed or given out along these segments. The cyclic process depicted in 
Fig. 1.10 is therefore equivalent with the Carnot engine operating between two heat 
reservoirs, absorbing heat .Qh from the reservoir at temperature .Th and depositing 
heat.Qc into the reservoir at temperature. Tc. Invoking the laws of thermodynamics, 
we show that Carnot’s engine formula (1.15) holds. 
The amount of heat absorbed along .AB may be evaluated using the first law 
in (1.32) along with the equations of state (1.80). Since temperature has the con￾stant value .Th along.AB, (1.80) reduces to.P = NkBTh/V, and.dU = 0, which on 
substitution in (1.32) yields 
.dQ = NkBTh
dV
V . (1.81) 
On integrating between initial and final volumes.Va and.Vb, the heat absorbed turns 
out to be given by 
.Qh = NkBThln(Vb/Va). (1.82) 
The same procedure applied along the segment.C D on which the temperature has the 
constant value.Tc and volume varies from.Vc to.Vd leads to the following expression 
for the heat received by the gas: 
.Q,
c = NkBTcln(Vd /Vc). (1.83) 
Since.Vd < Vc, the heat absorbed by the gas is negative, which means that a positive 
amount of heat is delivered to the reservoir. Hence the amount of heat delivered to 
the reservoir at temperature.Tc is 
.Qc = −Q,
c = NkBTcln(Vc/Vd ). (1.84) 
We have thus evaluated heat absorbed along.AB and that lost along.C D. 
Consider now the transformation along .BC. Since it is adiabatic, it does not 
involve exchange of heat, i.e. .d Q¯ = 0. The first law (1.32) then reduces to . dU +
PdV = 0 which, on using the equations of state (1.80), reads 
.
dT
T + (γ − 1)
dV
V = 0. (1.85)30 1 Fundamentals of Thermodynamics-I
On integrating the equation above we obtain 
.T Vγ −1 = constant. (1.86) 
The relation between .P and . V, derived by using first equation in (1.80) to express 
. T in terms of.P and. V, reads 
.PVγ = constant. (1.87) 
Similarly, on expressing.V in terms of.P and. T , (1.86) leads to the relation 
.T P−ν = constant ν = γ − 1
γ . (1.88) 
Equations (1.86)–(1.88) are equivalent descriptions of a reversible adiabatic process, 
called adiabatic equations of state. 
On applying (1.86) to the path.BC we get 
.
(Vb
Vc
)γ −1
= Tc
Th
. (1.89) 
In similar manner, the adiabatic transformation along.D A gives 
.
(Vd
Va
)γ −1
= Th
Tc
. (1.90) 
On comparing (1.89) and (1.90) it is seen that 
.
Vc
Vd
= Vb
Va
. (1.91) 
Use of the relation above in (1.82) and (1.84) leads to 
.
Qh
Th
= Qc
Tc
. (1.92) 
This is same as the Carnot engine formula (1.15). 
To find efficiency of the process under consideration from first principles note 
that total work done by the gas in the cycle, due to first law, is 
.W =
{
(d Q¯ − dU) =
{
d Q¯ , (1.93) 
where second equation is due to the fact that change in internal energy in a cyclic 
process is zero. Now1.5 A Cyclic Process to Realize Carnot Engine 31
.
{
d Q¯ =
[{ B
A
+
{ C
B
+
{ D
C
+
{ A
D
]
d Q¯ . (1.94) 
Since no heat is exchanged on adiabatic paths.BC and.D A, (1.94) yields 
.
{
d Q¯ =
[{ B
A
+
{ D
C
]
d Q¯ = Qh − Qc. (1.95) 
Substitution of this in (1.93) gives 
.W = Qh − Qc. (1.96) 
The relation .W = Qh − Qc derived above is independent of the equation of state 
obeyed by the working fluid. It is a consequence of the law of conservation of energy 
and is same as the formula of work output in the Carnot engine. Using (1.92), effi￾ciency is given by 
.η = W
Q h
= 1 − Qc
Qh
= 1 − Tc
Th
. (1.97) 
We have thus demonstrated realization of Carnot engine with an ideal gas as the work￾ing fluid. We will confirm the Carnot engine formula (1.92) for arbitrary equation of 
state in the exercises. 
Summary 
The adiabatic equations of state of the ideal gas are 
. T Vγ −1 = constant, PVγ = constant,
T P−ν = constant, ν = γ − 1
γ . (1.98) 
Exercises 
Ex. 1.4. Find change in entropy of an ideal gas when it expands isothermally at 
temperature. T from volume.V1 to.V2. What is the lost work? Hint: Change 
in internal energy of the ideal gas in isothermal expansion is zero. Hence, 
due to first law, when gas expands reversibly from volume .V1 to .V2 at 
temperature. T , change in its entropy is 
.ΔSgas = 1
T
{ V2
V1
PdV = NkB
{ V2
V1
dV
V = NkBln(V2/V1). (1.99) 
Since expansion is isothermic, the reservoir receives as much heat as is lost 
by the gas due to which change in entropy of the reservoir is.−ΔSgas so that32 1 Fundamentals of Thermodynamics-I
change in the entropy of universe is zero. Consequently there is no work 
loss in the process. 
Ex. 1.5. Find change in entropy of the gas and that of the environment in Joule’s 
experiment described in Sect. 1.4.1 in which gas expands irreversibly from 
volume .V1 to .V2. Find also the amount of lost work. Hint: There is no 
change in temperature and internal energy of the gas in Joule’s experiment. 
Hence change in entropy of the gas in the irreversible process in question 
is same as that in isothermic reversible expansion from .V1 to .V2 which 
is given by (1.99). However, since system does not exchange heat with 
the environment, change in entropy of the environment is zero. Change in 
entropy of universe in this case being.ΔSgas, lost work is.TΔSgas. 
1.5.1 Entropy of Ideal Gas 
Let .N molecules of an ideal gas be in equilibrium in the state .A characterized by 
.(PA, VA, TA). Consider a reversible process which takes it to the equilibrium state. B
characterized by.(PB, VB, TB). The process being reversible is described by the form 
of the first law in (1.67) which, on invoking the equations of state in (1.80), assumes 
the form 
.dS = NkB
(
c
dU
U +
dV
V
)
. (1.100) 
On integrating the equation above, we get 
.S = NkB
{
cln(U) + ln(V)
}
+ K, (1.101) 
where.K is the integration constant. It plays no role in computing entropy change in 
going from state. A to state. B as in that case 
.SB − SA = NkB
{
cln(UB/UA) + ln(VB/VA)
}
. (1.102) 
Determination of absolute value of entropy in a state would, of course, require knowl￾edge of . K. In principle, it may be determined by the condition .S = 0 at .T = 0. 
However, the ideal gas law is not applicable at low temperatures. The integration 
constant should therefore be determined by other considerations. We will revisit this 
question in Ex. 2.4.1.6 Van der Waals Equation of State 33
1.6 Van der Waals Equation of State 
The assumption that the gases are ideal cannot describe all relevant experimental 
observations. The search for the law for non-ideal gases faced several failed attempts 
till van der Waals derived one in his Ph.D. thesis in 1873 which goes by his name. It 
won him the Nobel Prize in 1910. 
As we saw above, thermodynamics was developed as an independent subject. 
However, with the discovery of the concept of atom, the connection of thermody￾namics with mechanics started getting attention leading to the emergence of what is 
known as the kinetic theory, outlined in Chap. 3. The attempts to find the equation 
of state for a real gas were based mainly on the kinetic theory. 
The equation of state for a real gas derived by van der Waals was also based on 
the kinetic theory and the virial theorem. Remarkably, as we will see in Chap. 12, 
it emerges as the leading order correction to the ideal gas law in statistical mechan￾ics with smallness of the molecular volume compared with the volume occupied 
per molecule as the smallness parameter. Here we give standard phenomenological 
derivation of the equation, obtained by introducing following modifications in the 
ideal gas law: 
1. It is assumed that the molecules are not point particles but are hard spheres. As 
a result, they cannot come closer than a certain distance. This results in each 
molecule excluding some volume, say . b, from the total volume .V occupied by 
the gas. Hence if.N is the number of molecules in the gas then the volume available 
effectively to it is.V − Nb. It was argued that the ideal gas law should therefore 
be modified to replace.V by.V − Nb. 
2. The molecules attract each other when separated by distances greater than the 
molecular radius . r0. The force vanishes when separation between them is large. 
Assuming that the molecules are distributed uniformly, each molecule in the 
interior is acted upon by forces on all sides resulting in net zero force. However, 
the layer near a boundary surface has no molecules on its boundary side. The layers 
near the boundary surfaces therefore experience a net inward force resulting in 
reduction of pressure. The force on a molecule is proportional to the number 
density.N/V and the number of molecules in the layer next to a bounding surface 
is also proportional to .N/V . This causes net reduction of pressure proportional 
to.(N/V )2 which must be subtracted from the pressure appearing in the ideal gas 
law. 
Under the suggested modifications, the ideal gas law assumes the form 
.P = NkBT
V − Nb − a
(V/N)2 , (1.103) 
where . a is the proportionality constant referred to in the item 2 above. In terms of 
the specific volume.v = V/N, (1.103) reads34 1 Fundamentals of Thermodynamics-I
.P = kBT
v − b − a
v2 . (1.104) 
This is the equation of state derived by van der Waals. We will discuss its properties 
in Chap. 12. As mentioned before, in addition to the equation of state relating pres￾sure, volume, and temperature, complete description of thermodynamic properties 
requires also the knowledge of its internal energy as a function of the state variables. 
We derived the expression for internal energy of an ideal gas empirically. Based 
on phenomenological considerations in Sect. 2.14 and on the theory of statistical 
mechanics in Sect. 12.2, it will be shown that the internal energy per molecule of the 
van der Waals gas is 
.u = ckBT − a
v
. (1.105) 
Summary 
The equations of state describing the van der Waals gas are 
.P = kBT
v − b − a
v2 , u = ckBT − a
v
, (1.106) 
where. v is volume per molecule and. u is the internal energy per molecule. 
In this chapter we presented traditional formulation of thermodynamics. In the next 
chapter we present the axiomatic approach. 
Exercises 
Ex. 1.6. (a) Show that the .T − S diagram corresponding to the .P − V diagram 
in Fig. 1.10 is given by Fig. 1.11. (b) Show that the heat absorbed in the 
process is the area bound by the rectangle .ABEF and that released in 
Fig. 1.11 .T − S diagram 
corresponding to the. P − V
diagram in Fig. 1.101.6 Van der Waals Equation of State 35
the process is the area bound by the rectangle.CDFE. (c) Hence find the 
efficiency of the process and confirm Carnot’s formula. 
Ex. 1.7. Show that the adiabatic equation of state of van der Waals gas undergoing 
reversible adiabatic transformation is 
.(v − b)T c = constant. (1.107) 
Hint: Since .d Q¯ = 0 in an adiabatic process, integrate the equation. d Q¯ =
Pdv + du = 0 where.P and. u are given by (1.106). 
Ex. 1.8. Consider the cyclic transformation depicted in Fig. 1.10. Assuming the 
operating fluid to be van der Waals gas described by the equations of state 
(1.106), verify Carnot engine formula (1.92). Hint: The amount .Qh of 
heat absorbed in going from .A to .B at the fixed temperature .Th and the 
amount .Qc given out in going from .C to .D at the fixed temperature . Tc
are obtained by integrating .d Q¯ = N(du + Pdv) with .P and . u given by 
(1.106): 
. Qh = N
{ B
A
(du + Pdv) = NkBTh {ln(vB − b) − ln(vA − b)},
Qc = −N
{ D
C
(du + Pdv) = NkBTc {ln(vC − b) − ln(vD − b)}.
(1.108) 
Along the adiabats.BC and.D A (1.107) holds 
.(vB − b)T c
h = (vC − b)T c
c , (vD − b)T c
c = (vA − b)T c
h . (1.109) 
Rewrite .(vB − b) in the first equation in (1.108) using the expression 
for .(vB − b) in the first equation in (1.109), and rewrite .(vD − b) in the 
second equation in (1.108) using the expression for.(vD − b)in the second 
equation in (1.109) to show that.Qh/Th = Qc/Tc. 
Ex. 1.9. Verify the Carnot formula (1.15) when the working gas in the cyclic trans￾formation depicted in Fig. 1.10 obeys following equations of state: 
.P = T f (V) + g(V), U = − {
g(V) + Φ(T ), (1.110) 
where . f (V), .g(V) are some functions of volume and .Φ(T ) some func￾tion of temperature. Hint: From (2.247) we know that the amount of heat 
absorbed when system undergoes isothermal transformation at tempera￾ture.Th from volume.VA to.VB is 
.QAB = Th (I(VB) − I(VA)), I(V) =
{
f (V)dV. (1.111)36 1 Fundamentals of Thermodynamics-I
The.QAB ≡ Qh is the heat absorbed in the isothermal process from. A to. B. 
Also, from (2.240) it follows that under reversible adiabatic transformation 
from.(VB, Th) to.(VC, Tc) we have the relation 
.(I(VC) − I(VB)) + (J (Tc) − J (Th)) = 0, J (T ) =
{ dΦ(T )
T . (1.112) 
Similarly 
. QC D = Tc (I(VC) − I(VD)),
(I(VA) − I(VD)) + (J (Th) − J (Tc)) = 0. (1.113) 
The .QC D ≡ Qc is the heat lost in the isothermal process from .C to . D. 
On comparing (1.112) and the second equation in (1.113) it follows that 
.I(VB) − I(VA) = I(VC) − I(VD) due to which the comparison of the 
expression (1.111) for.Qh and the first expression in (1.113) for heat lost 
.Qc confirms (1.15). 
Ex. 1.10. Verify the Carnot engine formula (1.15) when the working gas in the 
cyclic transformation depicted in Fig. 1.10 obeys arbitrary equations of 
state. Hint: Since the transformation along.AB is at constant temperature 
.Th and that along .C D is at constant temperature .Tc heat absorbed along 
.AB and that given out along.C D is 
.Qh = Th(SB − SA), Qc = Tc(SC − SD), (1.114) 
where.SA, SB, SC, SD stand for entropy at.A, B,C, D. Since the processes 
along.BC and.D A are isentropic, 
.SC = SB, SA = SD. (1.115) 
On combining (1.114) and (1.115) follows the Carnot engine formula 
(1.15). 
References 
1. R.P. Feynman, Feynman Lectures on Physics, vol. 1 (Addisson-Wesely Publications, 1964) 
2. I. Müller, A History of Thermodynamics (Springer, 2007) 
3. G.S. Girolami, J. Chem. Eng. Data 65 298 (2020) 
4. Sadi Carnot Reflections on the Motive Power of Fire and other papers on the second law of 
thermodynamics by É. Clapeyron, R. Clausius edited with an introduction by E. Mendoza (Dover 
Publications, 1988)Chapter 2 
Fundamentals of Thermodynamics-II 
The laws of thermodynamics are empirical. They, however, lead to the concept of 
entropy, entirely alien to common experience, their other ingredients—temperature, 
heat, pressure, energy—being intuitive. It is the law regarding change in entropy, 
along with the law of conservation of energy, which characterize permissible ther￾modynamic processes. The postulatory approach to thermodynamics adopts entropy 
as the fundamental entity characterizing thermodynamic state of a system as a func￾tion of its energy, volume, and number of particles. The partial derivatives of entropy 
with respect to energy, volume, and number of particles define the thermodynamic 
state variables temperature, pressure, and (to be introduced) chemical potential. Since 
it treats entropy as a function of quantities which characterize a mechanical system 
as well, the postulatory approach facilitates a natural way of establishing connection 
between thermodynamics and mechanics if only one could construct mechanical 
counterpart of thermodynamic entropy. We will construct mechanical counterpart 
of thermodynamic entropy in different ways in the subsequent chapters to establish 
connection between thermodynamics and mechanics. 
The postulatory approach is due to Callen [Callen]. Before describing it, we 
summarize essential terminology. 
1. Let . x be a parameter which has value .xA in system .A and .xB in system . B. Let 
the said two systems be combined to form one system. If the value of . x in the 
composite system is.xA + xB then. x is called an extensive parameter. For example, 
volume, number of moles of a molecule are extensive parameters. 
2. If a function. f (x1, x2,..., xn) of. n variables.x1, x2,..., xn is such that, for any 
constant. λ, 
. f (λx1, λx2,..., λxn) = λm f (x1, x2,..., xn), (2.1) 
then. f (x1, x2,..., xn) is called homogeneous of degree. m. Its partial derivatives 
obey the relation 
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4_2 
3738 2 Fundamentals of Thermodynamics-II
.
Σn
i=1
xi
∂ f
∂xi
= m f. (2.2) 
This is Euler’s theorem on homogeneous functions. 
A homogeneous function of degree zero is called intensive. 
3. A system enclosed by walls that keep fixed its volume and mole numbers of all 
its components, and does not allow it to exchange energy (both heat and work) 
with its surroundings is called closed. 
1
4. A system consisting of two or more subsystems is said to be composite. 
5. A system which is macroscopically homogeneous, isotropic, electrically neutral, 
and large enough so that surface effects can be neglected and not acted upon by 
external forces is called a simple system. 
Exercises 
Ex. 2.1. Prove Euler’s theorem on homogeneous functions (2.2). Hint: Due to its 
definition (2.1), a homogeneous function of degree .m in . n variables may 
be expressed in the form 
. f (x1, x2,..., xn)
= Σ
i1,i2,...,in
ai1i2,...in xi1
1 xi2
2 ··· xin
n δ(i1 + i2 +···+ in − m). (2.3) 
Using the form of. f (x1, x2,..., xn) above, the desired relation (2.2) follows 
immediately. 
2.1 Postulates of Thermodynamics 
In this approach, the terms work and energy carry the commonly understood meaning. 
Heat defined as the difference between the increase in energy of a system and work 
done on it: 
.d Q¯ = dU +dW¯ . (2.4) 
Note that our notation .dW¯ stands for the work done by the system so that the work 
done on the system is.−dW¯ .
1 An alternative terminology is to call the systems, named closed here, as isolated. The closed 
systems in the said alternative terminology are the ones which can exchange only matter with its 
surroundings. 2.1 Postulates of Thermodynamics 39
2.1.1 First Postulate 
There exist particular states of simple systems, called equilibrium states, which are 
macroscopically characterized completely by internal energy. U, the volume. V, and 
the numbers.N1, N2,..., Nr of molecules of its chemical components. 
This postulate conceptualizes only the existence of an equilibrium state but pro￾vides no means of characterizing and determining it. Those questions are addressed 
by the second and third postulates. 
2.1.2 Second Postulate 
There exists a function, called entropy. S, of the extensive parameters of any composite 
system defined for all equilibrium states and having the following property: When 
an internal constraint in a composite system is removed, the values assumed by the 
extensive parameters in the absence of that constraint are those that maximize the 
entropy over the manifold of constrained equilibrium states. 
This postulate provides a means for characterizing an equilibrium state in terms 
of a function called entropy but evaluation of that function would require knowledge 
of its properties which is the question answered by the third postulate. 
2.1.3 Third Postulate 
The entropy of a composite system has following properties: 
1. The entropy of a composite system is sum of the entropies of its constituent sub￾systems. 
2. Entropy is a single-valued, continuous, and differentiable function of its argu￾ments and is a monotonically increasing function of energy. 
Some consequences of this postulate are 
1. Since entropy is assumed to be a function of extensive parameters and since 
by virtue of first postulate, the extensive parameters characterizing a system are 
internal energy . U, volume . V, and the numbers .N1, N2,..., Nr of molecules of 
the chemical components constituting it, we have 
.S = S(U, V,{Ni}r), {Ni}r ≡ N1, N2,..., Nr. (2.5) 
We will see that all thermodynamic properties emerge from the knowledge of 
the functional form of entropy. Hence (2.5) is called the entropic fundamental 
equation of thermodynamics.40 2 Fundamentals of Thermodynamics-II
2. Since entropy of a composite system is sum of the entropies of its constituent 
subsystems, it follows that .S(U, V,{Ni}r) is a homogeneous function of order 
one in its independent variables (see Ex. 2.2): 
.S(λU, λV,{λNi}r). = λS(U, V,{Ni}r) (2.6) 
3. The property of increasing monotonicity with respect to energy implies 
.
( ∂S
∂U
)
V,{Ni}r
> 0. (2.7) 
4. Properties of single valuedness, continuity, differentiability, and monotonicity 
with respect to.U imply that the function.S = S(U, V,{Ni}r) can be inverted to 
express.U as a function of.S, V,{Ni}r: 
.U = U(S, V,{Ni}r). (2.8) 
This is the inverse of the entropic fundamental equation and is called the energetic 
fundamental equation of thermodynamics. 
Exercises 
Ex. 2.2. Show that the postulate that the entropy .S of a system is sum of the 
entropies of its subsystems implies (2.6). Hint: Due to additivity of . S, 
.S(U, V,{Ni}r) = S(U/k, V/k,{Ni /k}r) + k times. = kS(U/k,
V/k,.{Ni/k}r) so that.S(U/k, V/k,{Ni /k}r) = S(U, V,{Ni}r)/k. 
2.1.4 Fourth Postulate 
The entropy of any system vanishes in the state for which 
.
(∂U
∂S
)
V,{Ni}r
= 0. (2.9) 
We will see that this is equivalent with the third law of thermodynamics. 
2.1.5 Examining Admissible Forms of . S(U, V, N)
The postulates restrict the admissible functional forms of .S(U, V, N). In order to 
find whether a given.S(U, V, N) is in admissible form, apart from its continuity and 
differentiability, we need to examine whether it satisfies three conditions: (1) The2.1 Postulates of Thermodynamics 41
extensivity condition (2.6), (2) the condition (2.7) of monotonicity of. S with respect 
to . U, and (3) the condition (2.9). These conditions restrict the functional form of 
.S(U, V, N). However, additional restrictions arise from the requirements of stability 
of the equilibrium state which restrict further the form of.S(U, V, N): 
1. We will see that .(∂S/∂V )U,N = P/T . The stability demands .P to be pos￾itive [Landau and Lifshitz]. For, positive .P means .(∂S/∂V )U,N > 0, i.e. . S
increases if the body expands. The expansion is not uncontrolled as the stabil￾ity is achieved by its prevention by the surroundings. On the other hand, . P < 0
means.(∂S/∂V )U,N < 0, i.e.. S would increases even as the body contracts spon￾taneously leading to instability. The possibility of existence of negative pressure 
though is not ruled out in metastable states. Since we are concerned only with 
states of stable equilibrium, we would demand .P > 0 which is equivalent with 
demanding 
.
( ∂S
∂V
)
U,N
> 0. (2.10) 
2. The stability conditions (2.141) 
. 
∂2 S
∂U2 < 0, ∂2 S
∂V2 < 0,
( ∂2 S
∂U2
) ( ∂2 S
∂V2
)
−
( ∂2 S
∂U∂V
)2
> 0
derived in Sect. 2.10 also place restrictions on the form of.S(U, V, N). 
Exercises 
Ex. 2.3. Assume that the fundamental entropic equation of some thermodynamic 
system is given by 
.S(U, V, N) = AUaVbNc
, (2.11) 
where .A is a constant. Find the restrictions on the values of the constants 
.a, b, c: (1) arising from the postulates and (2) from the stability conditions. 
Hint: (1) The extensivity condition (2.6) evidently requires.a + b + c = 1. 
The monotonicity condition (2.7) will be satisfied if.a > 0. The condition 
(2.9) of fourth postulate demands .a < 1. The restrictions on the values of 
.a, b, c due to postulates therefore are: 
.a + b + c = 1, 0 < a < 1. (2.12) 
(2) The condition (2.10) demands.b > 0. The stability condition. ∂2 S/∂U2 <
0 will be satisfied if .a(1 − a) > 0, i.e. if .0 < a < 1. This is same as the 
one arrived at by postulate based considerations. The stability condition 
.∂2 S/∂V2 < 0 will be satisfied if.b(1 − b) > 0, i.e. if.0 < b < 1. The sta￾bility condition .(∂2 S/∂U2)(∂2 S/∂V2) − (∂2 S/∂U∂V )2 > 0 will be sat-42 2 Fundamentals of Thermodynamics-II
isfied if .a + b < 1. Since .c = 1 − a − b, it follows that .0 < c < 1. Thus 
.S(U, V, N) in (2.11) will be an admissible expression for entropy if 
.a + b + c = 1, 0 < a < 1, 0 < b < 1 0 < c < 1. (2.13) 
Ex. 2.4. We found that the first law of thermodynamics, along with the equations of 
state of an ideal gas lead to the expression (1.101) for entropy of an ideal 
gas as the function of.U, V with.K therein being an unknown constant. If 
we consider. S as a function also of.N then that constant must be considered 
a function of.N and (1.101) should be rewritten as 
.S(U, V, N) = NkB
{
cln(U) + ln(V) + f (N)
}
. (2.14) 
Show that.S(U, V, N) is extensive if 
. f (N) = −(c + 1)ln(N) + A, (2.15) 
where .A is an unknown constant. It cannot be determined by thermody￾namic considerations. Its value follows naturally in statistical mechanical 
formalism. Hint: Show that the extensivity property (2.6) will be obeyed if 
. f (λN) − f (N) = −(c + 1)ln(λ). Let.N = 1 to get the desired result with 
.A = f (1) as an arbitrary constant. With. f (N) given by (2.15), (2.14) may 
be rewritten as 
.S(U, V, N) = NkB
(
ln(uc
v) + A
)
, u = U/N, v = V/N. (2.16) 
2.1.6 Connection with the Laws of Thermodynamics 
The connection of the postulatory approach with the laws of thermodynamics is 
established as follows. 
Invoking (2.8) we have 
. dU =
(∂U
∂S
)
V,{Ni}
dS +
(∂U
∂V
)
S,{Ni}
dV +Σr
j=1
( ∂U
∂Nj
)
S,V,{Ni/= j}
dNj .
(2.17)2.1 Postulates of Thermodynamics 43
Define 
. T =
(∂U
∂S
)
V,{Ni}
: Temperature,
P = − (∂U
∂V
)
S,{Ni}
: Pressure,
μj =
( ∂U
∂Nj
)
S,V,{Ni/= j}
: Chemical potential of jth component,
(2.18) 
to rewrite (2.17) as 
.dU = T dS − PdV +Σr
j=1
μjdNj . (2.19) 
At this stage, the definitions of temperature, pressure and chemical potential given 
in (2.18) are without justification. Though comparison of (2.19) with the first law of 
thermodynamics for constant .Nj would lead to the identification of .P and .T with 
the partial derivatives as in (2.18), their justification within the postulatory frame￾work will be provided in the sections to follow. For now we proceed by assuming 
correctness of the identifications in (2.18). 
The expressions in (2.18) show that .T, P, μj are intensive parameters. In many 
situations it is one or more intensive parameters which are experimentally controlled. 
It is then convenient to choose the relevant controllable intensive parameters as 
independent variables. In Sect. 2.6 we will carry the task of transforming one or more 
independent extensive parameter to appropriate intensive parameters as independent 
variables. 
If the number of molecules of each component is fixed then .dNj = 0 for all . j
and (2.19) reduces to (1.67) wherein the first term is identified as the amount of heat 
absorbed by the system and the second term as the mechanical work done by it. In 
case the number of molecules changes, the applicable equation is (2.19). We may 
identify the last term therein as the “chemical work”. The chemical potential may be 
viewed as the increase in energy of the system due to addition of a molecule keeping 
its entropy and volume constant. To distinguish different kinds of works, we denote 
the mechanical wok by.Wm and the chemical work by.Wc. With 
.dW¯ c ≡ Σr
j=1
μjdNj, (2.20) 
the (2.19) assumes the form 
.dU = T dS −dW¯ m +dW¯ c. (2.21)44 2 Fundamentals of Thermodynamics-II
For further insight into the meaning of chemical potential, including its relation with 
thermodynamic potentials, see [ 1, 2]. 
The relations in (2.18) define intensive variables in terms of the partial derivatives 
of .U(S, V,.{Nj}r). We use the relations between partial derivatives derived in the 
Appendix A to express the intensive variables defined in (2.18) in terms of the partial 
derivatives of.S(U, V,.{Nj}r). 
1. Invoking (A.8) with .x → U, .y → V, .z → S therein and by keeping the .Ni’s 
fixed in all partial derivatives, we get 
.
( ∂S
∂U
)
V,{Ni}
=
{(∂U
∂S
)
V,{Ni}
}−1
= 1
T . (2.22) 
2. Invoke (A.9) with .x → U, .y → V, .z → S therein keeping the .Ni’s constant in 
all partial derivatives to obtain 
.
(∂U
∂S
)
V,{Ni}
( ∂S
∂V
)
U,{Ni}
(∂V
∂U
)
S,{Ni}
= −1. (2.23) 
Recall (2.18) and (2.22) to get 
.
( ∂S
∂V
)
U,{Ni}
= P
T . (2.24) 
3. Invoke (A.9) with.x → U,.y → Nj ,.z → S therein and keep.V,{Ni/= j} constant 
in all partial derivatives, to obtain 
.
(∂U
∂S
)
V,{Ni}
(∂Nj
∂U
)
S,V,{Ni/= j}
( ∂S
∂Nj
)
U,V,{Ni/= j}
= −1. (2.25) 
The use of (2.18) and (2.22) in the equation above yields 
.
( ∂S
∂Nj
)
U,V,{Ni/= j}
= −μj
T . (2.26) 
Summary 
The intensive parameters in entropic representation are: 
.
1
T =
( ∂S
∂U
)
V,{Ni}
, P
T =
( ∂S
∂V
)
U,{Ni}
, μj
T = − ( ∂S
∂Nj
)
U,V,{Ni/= j}
. (2.27) 
Next we justify the definitions of various intensive parameters in (2.18).2.2 Justification of Definitions of Intensive Parameters 45
2.2 Justification of Definitions of Intensive Parameters 
2.2.1 Temperature 
Consider an isolated cylinder containing a gas. It is partitioned into two parts which 
are, to begin with, separated by a partition which does not allow flow of heat, work 
and gas from one part to the other. Let the internal energy, volume and the number of 
molecules in one part be denoted by.U1, V1, N1 and let.U2, V2, N2 be the correspond￾ing quantities in the other part. Now, change the partition so that it allows exchange 
of heat between the two parts but it is still rigid and also does not allow exchange 
of gas. Since the system is isolated, the total energy.UT = U1 + U2 is conserved so 
that 
.dUT = dU1 + dU2 = 0, dV1 = dV2 = 0, dN1 = dN2 = 0. (2.28) 
The entropy.ST of the system is sum of the entropies.S1 and.S2 of its parts: 
.S = S1(U1, V1, N1) + S2(U2, V2, N2). (2.29) 
Using (2.28) it follows that 
.dST = ∂S1
∂U1
dU1 +
∂S2
∂U2
dU2 =
( 1
T1
− 1
T2
)
dU1. (2.30) 
The state of equilibrium of the system corresponds to maximum entropy. Hence, at 
equilibrium.dST = 0, as a result (2.30) yields 
.
( 1
T1
)
equ.
=
( 1
T2
)
equ.
. (2.31) 
This shows that the quantity .T which may have different values for two systems 
when isolated from each other, equalizes when the systems exchange heat. Since the 
quantity that equalizes on exchange of heat is temperature, the identification of. T as 
temperature suggested in (2.18) is justified. 
Further justification is provided by showing that the equilibrium is achieved by 
flow of heat from the part having higher. T to the one of lower. T . To that end note that, 
by postulate, entropy never decreases, it follow that .ΔST ≥ 0. The relation (2.30) 
then yields 
.ΔST =
( 1
T1
− 1
T2
)
ΔU1 ≥ 0. (2.32) 
This shows that if .T1 ≥ T2 then we must have .ΔU1 ≤ 0. Since .ΔU1 denotes the 
amount of energy received by the system numbered 1, non-positivity of.ΔU1 implies46 2 Fundamentals of Thermodynamics-II
that system numbered 1 gives out energy which in the present case is heat energy 
as no other form of energy exchange is allowed by assumption. Since .T1 ≥ T2 it 
follows that heat flows from the system having higher value of .T to the one at the 
lower value. This is consistent with our understanding of temperature. 
2.2.2 Pressure 
Continuing the consideration of the system discussed in the last subsection, let the 
partition between the two parts allow, in addition to the exchange of heat, also the 
exchange of work. In other words, the partition is no longer rigid, it can move. In 
this case, in addition to the conservation of total internal energy, the condition of 
conservation of volume also applies so that 
.dUT = dU1 + dU2 = 0, dV = dV1 + dV2 = 0, dN1 = dN2 = 0. (2.33) 
Hence 
. dST = ∂S1
∂U1
dU1 +
∂S2
∂U2
dU2 +
∂S1
∂V1
dV1 +
∂S2
∂V2
dV2
=
( 1
T1
− 1
T2
)
dU1 +
( P1
T1
− P2
T2
)
dV1, (2.34) 
where use has been made of (2.27) in writing the last line. Since.dST = 0 at equilib￾rium, we see that the equation above yields 
.
( 1
T1
)
equ.
=
( 1
T2
)
equ.
,
( P1
T1
)
equ.
=
( P2
T2
)
equ.
. (2.35) 
This shows that, at equilibrium,. T and.P both equalize: 
.(T1)equ. = (T2)equ. , (P1)equ. = (P2)equ. . (2.36) 
Since in the present case we have allowed exchange of heat as well as that of work and, 
as argued circa (2.31), the equalization of. T is due to exchange of heat, equalization 
of. P is due to exchange of work. Since the quantity that equalizes due to exchange of 
work is pressure, we see that identification of.P as pressure suggested in the (2.18) 
is justified. 
We have considered the consequences of allowing exchange of heat alone and the 
exchange of heat and work together. Allowing exchange of work alone leads to an 
indeterminate problem (see [Callen] for details).2.3 Equations of State 47
2.2.3 Chemical Potential 
To find the consequences of exchange of matter, consider again the system discussed 
in last two subsections. Let the partition between the two parts allow, in addition to 
the exchange of heat, also the exchange of matter but not of work. In other words, the 
partition is rigid. In this case, in addition to the conservation of total internal energy, 
the condition of conservation of number of molecules also applies so that 
.dUT = dU1 + dU2 = 0, dN1 + dN2 = 0, dV1 = dV2 = 0. (2.37) 
Hence 
. dST = ∂S1
∂U1
dU1 +
∂S2
∂U2
dU2 +
∂S1
∂N1
dN1 +
∂S2
∂N2
dN2
=
( 1
T1
− 1
T2
)
dU1 −
(μ1
T1
− μ2
T2
)
dN1, (2.38) 
where use has been made of (2.27) in writing the last line. Since.dST = 0 at equilib￾rium, we see that the equation above yields 
.
( 1
T1
)
equ.
=
( 1
T2
)
equ.
,
(μ1
T1
)
equ.
=
(μ2
T2
)
equ.
. (2.39) 
This shows that, at equilibrium,. T and. μ both equalize: 
.(T1)equ. = (T2)equ. , (μ1)equ. = (μ2)equ. . (2.40) 
Since in the present case we have allowed exchange of heat as well as that of matter 
and, as argued circa (2.31), the equalization of. T is due to exchange of heat, equal￾ization of . μ is due to exchange of matter. Since the quantity that equalizes due to 
exchange of matter is chemical potential, we see that identification of. μ as chemical 
potential suggested in (2.18) is justified. 
2.3 Equations of State 
The relations in (2.18) express intensive parameters in terms of independent extensive 
variables.S, V,{Nj}: 
.T = T (S, V,{Nj}), P = P(S, V,{Nj}), μi = μi(S, V,{Nj}). (2.41) 
The equations expressing intensive parameters in terms of independent extensive 
variables are known as the equations of state. The equations of state in (2.41) arise48 2 Fundamentals of Thermodynamics-II
in energy representation in which (.S, V,{Nj}) are independent variables. We can 
instead work in the entropy representation in which (.U, V,{Nj}) are independent 
variables and the corresponding intensive parameters are defined by (2.27). The 
equations of state in entropy representation therefore read 
. 
1
T = 1
T
(
U, V,{Nj}
)
, P
T = P
T
(
U, V,{Nj}
)
, μi
T = μi
T
(
U, V,{Nj}
)
.
(2.42) 
As mentioned before, thermodynamics does not determine equations of state. 
The relations .P = P(V, T ), .U = U(V, T ) commonly called equations of state 
are not in the forms (2.41) or (2.42). The equations of state will be said to be in 
“proper form” if written as in (2.41) or in (2.42). 
Exercises 
Ex. 2.5. Consider the fundamental entropic relation (2.11) in which the parameters 
.a, b, c obey (2.13). Find the three equations of state. 
Ex. 2.6. Consider two systems, named . 1 and . 2, described by the fundamental 
entropic relation (2.11) in which the parameters.a, b, c obey the conditions 
in (2.13). Let .Si(Ui, Vi, Ni) denote entropy of the .ith system . (i = 1, 2)
when isolated from each other. If the systems are allowed to exchange only 
heat then show that their internal energies when equilibrium is reached are 
given by 
. U1 = U
[
1 +
(V2
V1
)b/(1−a) ( N2
N1
)c/(1−a)
]−1
,
U2 = U
[
1 +
(V1
V2
)b/(1−a) ( N1
N2
)c/(1−a)
]−1
. (2.43) 
Hint: Extremize total entropy .S = S1(U1, V1, N1) + S2(U2, V2, N2) sub￾ject to the constraint.U1 + U2 = U. 
Ex. 2.7. Rewrite the equations of state (1.80) for an ideal gas in proper form. Hint: 
Since second of those equations relates .U and . T , the proper form of the 
equations must be entropic form. Indeed, the two equations of state may be 
rewritten in the entropic forms.P/T = NkB/V,.1/T = cNkB/U. 
Ex. 2.8. Write the equations of state (1.106) of van der Waals gas in proper 
form. Hint: The proper form of the energy equation is . 1/T = ckBv/
(a + uv). Use this to rewrite the .P-equation as . P/T = kB/(v − b) −
ackB/(av + uv2).2.5 Gibbs–Duhem Relation 49
2.4 Euler Equation 
An important consequence of extensivity of entropy (or equivalently of inter￾nal energy) is the so-called Euler equation. To derive it, recall from (2.6) that 
.S(U, V,{Ni}r) is a homogeneous function of .(U, V,{Ni}r) of degree one. Hence, 
due to (2.2) with.m = 1, we have 
.S = U
( ∂S
∂U
)
V,{Ni}
+ V
( ∂S
∂V
)
S,{Ni}
+Σr
j=1
Nj
( ∂S
∂U
)
U,V,{Ni/= j}
. (2.44) 
Invoking the relations (2.27) between intensive parameters and the partial derivatives 
of. S, (2.44) assumes the form 
.S = U
T +
PV
T −Σ
j
Njμj
T . (2.45) 
On rearrangement of its terms, the equation above may be rewritten as 
.U = ST − PV +Σ
j
Njμj . (2.46) 
The equation above may also be arrived at by starting with the property of homo￾geneity of.U with respect to the independent variables.S, V,{Ni}r: 
.U(λS, λV,{λNi}r) = λU(S, V,{Ni}r). (2.47) 
Equation (2.45) or its equivalent (2.46) is known as the Euler equation. 
2.5 Gibbs–Duhem Relation 
The Gibbs–Duhem relation is the relation between intensive variables. To derive it, 
note that (2.46) implies 
.dU = {T dS − PdV +Σ
j
μjdNj}+{SdT − VdP +Σ
j
Njdμj}. (2.48) 
On recalling (2.19), we see that the left side of the equation above is equal to the first 
bracketed term on its right side. The second bracketed term must therefore be zero: 
.SdT − VdP +Σ
j
Njdμj = 0. (2.49)50 2 Fundamentals of Thermodynamics-II
This is known as the Gibbs–Duhem relation. It is straightforward to see that, in the 
entropy representation, the Gibbs–Duhem relation reads 
.Ud
( 1
T
)
+ Vd
( P
T
)
−Σ
j
Njd
(μj
T
)
= 0. (2.50) 
The Gibbs–Duhem relation shows that the intensive parameters are not independent. 
Thus in a system having. r types of chemical components, there are. r chemical poten￾tials which along with temperature and pressure constitute .r + 2 intensive param￾eters. However, because of the Gibbs–Duhem relation, the number of independent 
parameters reduces to .r + 1. The number of independent intensive parameters is 
known as the number of thermodynamic degrees of freedom. We thus see that the 
number of thermodynamic degrees of freedom of an .r-component system is .r + 1. 
Accordingly, the number of independent equations of state for single component 
system is two. 
Though we do not illustrate it here, the Gibbs–Duhem relation is useful in deter￾mining the fundamental thermodynamic equation from the knowledge of the equa￾tions of state. 
Exercises 
Ex. 2.9. Using the two equations of state of an ideal gas in (1.80), show that its 
third equation of state is given by (.u = U/N,.v = V/N) 
.
μ
T = −kB
(
ln(uc
v) + B
)
, (2.51) 
where. B is a constant. Hint: Rewrite the said two equations of state in the 
form of entropic equations of state:.P/T = kB/v,.1/T = ckB/u and use 
them in the entropic Gibbs–Duhem relation (2.50) to get 
.d
( μ
T
)
= kB
{
cud
(1
u
)
+ vd
(1
v
)} . (2.52) 
Integration of the equation above yields the desired result (2.51). 
Ex. 2.10. Using Euler equation, show that the entropy and chemical potential of the 
ideal gas are related by 
.
S
N + μ
T = kB(c + 1). (2.53) 
Hence show that the expression (2.16) for entropy and expression (2.51) 
for . μ for an ideal gas are consistent with (2.53) if the constants . A and . B
in the said two expression are such that.A − B = c + 1. 
Ex. 2.11. Consider the two equations of state given by (2.242) and (2.243). Show 
that the third equation of state is (.Φ(T )/N → Φ(T ))2.6 Thermodynamic Potentials 51
.
μ
T =
{
v
(
f ,
(v) + g,
(v)
T
)
dv +
{
Φ(T )d(1/T ) + C, (2.54) 
where .C is a constant and .F,
(x) ≡ dF(x)/dx. Hint: Using the said two 
equations of state, the entropic Gibbs–Duhem relation (2.50) reads 
. d (μ/T ) =
(
vg(v) −
{
g(v)dv + Φ(T )
)
d(1/T )
+ v
(
f ,
(v) + g,
(v)
T
)
dv
=
({
vg,
(v)dv
)
d(1/T ) + Φ(T )d(1/T )
+ v
(
f ,
(v) + g,
(v)
T
)
dv
= d
{{
v
(
f ,
(v) + g,
(v)
T
)
dv
}
+ Φ(T )d(1/T ). (2.55) 
Integration of this leads to the desired result (2.54). 
2.6 Thermodynamic Potentials 
Entropy and energy are functions of extensive variables. However, the control param￾eters in experiments are often intensive variables: temperature and pressure. It is then 
more convenient to work with functions having one or more intensive parameters 
as independent variables. In the following, we study the theory of transformation of 
the energy function to the functions in which one or more of the extensive variables 
characterizing the energy function are replaced by the corresponding intensive vari￾ables. We find also the extremum principle in terms of the transformed functions that 
enables one to identify the equilibrium state in each case. 
Recall that an intensive variable is the derivative of the energy function. U(S, V, N)
with respect to one of its arguments. The transformation of .U to a function in 
which an extensive variable characterizing.U is replaced by the corresponding inten￾sive variable is mathematically therefore a Legendre transformation, summarized in 
Appendix B. For, it is the transformation of a function. f (x) of. x to the function. G(s)
of its slope.s = d f (x)/dx defined by 
.G(s) = f (x(s)) − sx(s), (2.56) 
called the Legendre transform of. f (x). 
We use the concept of Legendre transform to generate from the energy function 
.U(S, V,{Ni}) the thermodynamic functions, also called thermodynamic potentials,52 2 Fundamentals of Thermodynamics-II
which are functions of combinations of one or more of the intensive and extensive 
variables. Their physics origin will be examined in Sect. 2.13. For simplicity, we 
consider one component systems. 
2.6.1 Helmholtz Potential 
We know that.T = ∂U(S, V, N)/∂S. Hence the Legendre transform of. U(S, V, N)
with respect to . S is the function .F(T, V, N) having . T in place of . S as the variable 
which, on invoking (2.56), is given by 
.F(T, V, N) = U(S, V, N) − T S. (2.57) 
The function.F(T, V, S) is called Helmholtz Potential or Free Energy. 
The definition (2.57) implies 
.dF(T, V, N) = dU(S, V, N) − T dS − SdT. (2.58) 
On using (2.19), the equation above assumes the form 
.dF(T, V, N) = −SdT − PdV + μdN. (2.59) 
Hence it follows that 
.S = − (∂F
∂T
)
V,N
, P = − (∂F
∂V
)
N,T
, μ =
(∂F
∂N
)
V,T
. (2.60) 
Knowing .F(T, V, N), the relations above provide a means of evaluating pressure, 
entropy, and chemical potential. 
Let us examine how.F(T, V, N) changes in an arbitrary isothermal process. We 
assume fixed . N. From the second law of thermodynamics expressed in the form 
(1.53) we know that, if. T is constant all through the process, then the amount.ΔQ of 
heat absorbed by the system in going from the state . A to .B along an arbitrary path 
is such that 
.ΔQ ≤ TΔS, T constant, (2.61) 
where.ΔS ≡ S(B) − S(A) is the difference in the entropy of the state. B and that of 
. A. Now, for constant. T , (2.58) implies 
.ΔF(T, V, N) = ΔU(S, V, N) − TΔS ≤ ΔU(S, V, N) − ΔQ, (2.62)2.6 Thermodynamic Potentials 53
where the inequality is by virtue of (2.61). Since.ΔT = ΔN = 0, the first law gives 
.ΔU(S, V, N) − ΔQ = −PΔV which on substitution in (2.62) leads to the inequal￾ity 
.ΔF(T, V, N) ≤ −PΔV. (2.63) 
For.ΔV = 0 this reduces to 
.ΔF(T, V, N) ≤ 0. (2.64) 
We have thus shown that Helmholtz free energy never increases in an isothermal 
process if the volume and the particle number are also kept constant. 
2.6.2 Gibbs Potential 
Consider the transformation from the set of variables.(S, V, N) characterizing.U to 
the variables.(T, P, N) where.T = ∂U/∂S,.P = −∂U/∂V . Extending the relation 
(2.56) defining single variable Legendre transform to two variables, the Legendre 
transform of.U(S, V, N) under.S → T ,.V → P is 
.G(T, P, N) = U(S, V, N) − T S + PV. (2.65) 
The function.G(T, P, N)is called the Gibbs potential or Gibbs free energy. Invoking 
Euler’s equation (2.46), it can be seen that.G(T, P, N) is expressible in terms of the 
chemical potential by the relation 
.G(T, P, N) = Nμ. (2.66) 
On using (2.19) for.dU, (2.65) leads to 
.dG(T, P, N) = −SdT + VdP + μdN. (2.67) 
Hence it follows that 
.S = − (∂G
∂T
)
P,N
, V =
(∂G
∂P
)
T,N
, μ =
(∂G
∂N
)
T,P
. (2.68) 
Knowing .G(T, P, N), the relations above provide a means of evaluating volume, 
entropy, and the chemical potential. 
By the arguments similar to those leading to (2.64), it can be shown that 
.ΔG ≤ 0, constant T, P, N. (2.69)54 2 Fundamentals of Thermodynamics-II
It states that the Gibbs free energy never increases in an isothermal process if pressure 
and number of moles are also kept constant. 
2.6.3 Enthalpy 
Consider the transformation from the set of variables .(S, V, N) characterizing 
.U to the variables .(S, P, N), where .P = −∂U/∂V . The Legendre transform of 
.U(S, V, N) under the transformation.V → P is 
.H(S, P, N) = U(S, V, N) + PV. (2.70) 
The function.H(S, P, N) is called the enthalpy. 
Due to first law, (2.70) gives, for constant. N, 
.ΔH = ΔQ + VΔP. (2.71) 
This shows that, in an isobaric process, .ΔH = ΔQ, i.e. change in enthalpy in an 
isobaric process is the heat absorbed when.N is constant. Enthalpy is therefore also 
called heat function. 
With.dU given by (2.19), the expression for.dH reads 
.dH(S, P, N) = T dS + VdP + μdN. (2.72) 
Hence it follows that 
.T =
(∂H
∂S
)
P,N
, V =
(∂H
∂P
)
S,N
, μ =
(∂H
∂N
)
S,P
. (2.73) 
Knowing.H(S, P, N), the relations above provide a means of evaluating temperature, 
volume, and the chemical potential. 
By the arguments similar to those leading to (2.64), it can be shown that 
.ΔH ≤ 0, constant S, P, N. (2.74) 
This states that in a process in which .S, P, N are kept constant, enthalpy never 
increases. 
2.6.4 Grand Potential 
Consider the transformation from the set of variables.(S, V, N) characterizing.U to 
the variables.(T, V, μ). The Legendre transform of.U(S, V, N) under. (S, V, N) →
(T, V, μ) evidently is2.7 Massieu Functions 55
.Ω(T, V, μ) = U(S, V, N) − T S − μN. (2.75) 
The function .Ω(T, V, μ) is called the the grand potential. Due to Euler equation, 
(2.75) may be rewritten as 
.Ω = −PV. (2.76) 
Invoking (2.19) for.dU, the expression (2.75) yields 
.dΩ(T, V, μ) = −SdT − PdV − Ndμ. (2.77) 
It then follows that 
.S = − (∂Ω
∂T
)
V,μ
, P = − (∂Ω
∂V
)
T,μ
, N = − (∂Ω
∂μ )
T,V
. (2.78) 
Knowing .Ω(T, V, μ), the relations above provide a means of evaluating entropy, 
pressure, and molecular number. 
2.7 Massieu Functions 
In the foregoing we constructed various thermodynamic potentials as Legendre 
transforms of the energy function .U(S, V, N). Another set of potentials, called 
Massieu functions, can be constructed as Legendre transforms of the entropy function 
.S(U, V, N): 
1. Since .(∂S/∂U)V,N = 1/T , the Legendre transform of .S(U, V, N) with respect 
to.U would be 
.Ψ (1/T, V, N) = S(U, V, N) − U
1
T . (2.79) 
This is often called the Massieu function. Clearly 
.dΨ (1/T, V, N) = −Ud
1
T +
P
T
dV − μ
T
dN. (2.80) 
2. Since.(∂S/∂V )U,N = P/T , the Legendre transform of.S(U, V, N) with respect 
to.V would be 
.Ξ(U, P/T, N) = S(U, V, N) − V
P
T . (2.81)56 2 Fundamentals of Thermodynamics-II
Its differential form is 
.dΞ(U, P/T, N) = 1
T
dU − Vd
P
T − μ
T
dN. (2.82) 
3. Since.(∂S/∂N)U,V = −μ/T , the Legendre transform of.S(U, V, N) with respect 
to.N would be 
.Θ(U, V, μ/T ) = S(U, V, N) + N μ
T . (2.83) 
Its differential form is 
.dΘ = 1
T
dU +
P
T
dV + Nd μ
T . (2.84) 
4. The Legendre transform of.S(U, V, N) with respect to.U and.V is 
.Φ(1/T, P/T, N) = S(U, V, N) − U
1
T − V
P
T . (2.85) 
This is often called Planck’s function. Its differential form is 
.dΦ = −Ud
1
T − Vd
P
T − μ
T
dN. (2.86) 
5. The Legendre transform of.S(U, V, N) with respect to.U and.N is 
.K(1/T, V, μ/T ) = S(U, V, N) − U
1
T + N μ
T . (2.87) 
This is often called Kramer function. Its differential form is 
.dK = −Ud
1
T +
P
T
dV + Nd μ
T . (2.88) 
6. The Legendre transform of.S(U, V, N) with respect to.V and.N is 
.Γ (U, P/T, μ/T ) = S(U, V, N) − V
P
T + N μ
T . (2.89) 
Its differential form is 
.dΓ = 1
T
dU − Vd
P
T + Nd μ
T . (2.90)2.8 Maxwell Relations 57
Historically, the Massieu functions were introduced in 1869 which was before the 
advent of the thermodynamic potentials by Gibbs (1873) and Helmholtz (1882). 
However, it is the thermodynamic potentials which are widely used. 
2.8 Maxwell Relations 
We know that .U and . S are state functions. Being their Legendre transforms, so are 
the thermodynamic potentials and the Massieu functions. We will show that this fact 
leads to several relations between the derivatives of the state functions and those of 
the intensive parameters with respect to each other. They prove useful in identifying 
useful relations between thermodynamic observables. 
To find the said relations, consider the function. f ({xi}r) of. r independent variables 
.(x1, x2,..., xr) ≡ ({xi}r). We say that.d f ({xi}r) is a perfect or exact differential if 
the integral, 
.I =
{
A→B
d f, (2.91) 
between the points . A and .B in the space of the said variables is independent of the 
path of integration. In that case.d f is expressible as 
.d f = Σr
i=1
∂ f
∂xi
dxi . (2.92) 
If the integral (2.91) depends on the path of integration, then .d f ({xi}r) is called 
imperfect or inexact differential. 
Now, let it be given that 
.d f = Σr
i=1
Mi({xi}r)dxi . (2.93) 
If.d f is a perfect differential, the comparison of (2.93) with (2.92) shows that in that 
case 
.Mi = ∂ f
∂xi
. (2.94) 
This clearly implies and 
.
∂Mi
∂x j
= ∂Mj
∂xi
. (2.95)58 2 Fundamentals of Thermodynamics-II
Now let . f ({xi}r) be a function of thermodynamic variables .{xi}r. If . f ({xi}r) is a 
state function, then we know that change in its value in a transformation from the 
state .A to the state . B, described by the integral (2.91), is independent of the path 
along which the variables change. Hence .d f is a perfect differential if . f ({xi}r) is 
a state function. Consequently, the coefficients of the .dxi’s in the expression of . d f
must obey the relations (2.95). 
Since . U, . S, the thermodynamic potentials and the Massieu functions are state 
functions, we apply the relations (2.95) to their differential forms. 
Several thermodynamic transformations of widespread interest are those which 
leave unchanged the number of molecules of each kind. If we characterize the ther￾modynamic properties in terms of.U(S, V ) then, with.N constant, 
.dU(S, V ) = T dS − PdV. (2.96) 
In this case, we can construct three thermodynamic potentials which are the Legendre 
transforms of.U(S, V ) one with respect to. S, second with respect to. V, and the third 
with respect to both . S and . V, called the Helmholtz potential, the enthalpy, and the 
Gibbs potential defined in Sect. 2.6. Since we are assuming .N to be constant their 
differential forms are given by 
. dF(T, V ) = −SdT − PdV,
dH(S, P) = T dS + VdP,
dG(T, P) = −SdT + VdP. (2.97) 
On applying the condition (2.95) to (2.96) and to each of the three expressions in 
(2.97), follow the relations 
. (∂T
∂V
)
S
= − (∂P
∂S
)
V
,
( ∂S
∂V
)
T
=
(∂P
∂T
)
V
,
(∂T
∂P
)
S
=
(∂V
∂S
)
P
,
( ∂S
∂P
)
T
= − (∂V
∂T
)
P
, (2.98) 
called the Maxwell relations. 
Similar relations can be derived corresponding to differential forms of various 
Massieu functions. One such relation that we will need follows from (2.80) reading 
.
(∂U
∂V
)
T
= − (∂P/T
∂1/T
)
V
. (2.99) 
We will refer to the Maxwell relations corresponding to the Massieu functions as 
entropic Maxwell relations.2.9 Independent Thermodynamic Observables 59
Next we show that, along with the relations between the partial derivatives derived 
in Appendix A, the Maxwell relations are useful in expressing various thermody￾namic quantities in terms of the set of three independent thermodynamic observables 
introduced next. 
2.9 Independent Thermodynamic Observables 
The first derivatives of energy .U (or those of the entropy . S) give the intensive 
quantities .T, P, μ. Their second derivatives yield thermodynamic observables. For 
example, consider a system of fixed number of molecules so that its energy is a 
function of.S, V . The second derivatives of.U with respect to.S, V are 
.
(∂2U
∂S2
)
V
=
(∂T
∂S
)
V
=
[( ∂S
∂T
)
V
]−1
= T
CV
, (2.100) 
where 
.CV =
(∂Q
∂T
)
V
= T
( ∂S
∂T
)
V
=
(∂U
∂T
)
V
(2.101) 
is the heat capacity at constant volume. Next, 
.
(∂2U
∂V2
)
S
= − (∂P
∂V
)
S
= − [(∂V
∂P
)
S
]−1
= 1
VκS
, (2.102) 
where 
.κS = − 1
V
(∂V
∂P
)
S
(2.103) 
is the isentropic or adiabatic compressibility. Finally 
.
∂2U
∂V∂S =
(∂T
∂V
)
S
=
[(∂V
∂T
)
S
]−1
= 1
VαS
, (2.104) 
where 
.αS = 1
V
(∂V
∂T
)
S
(2.105) 
is the isentropic or adiabatic coefficient of thermal expansion. 
The thermodynamic quantities in general are formed by the partial derivatives 
between two of the variables from the set.U, S, V, T, P keeping one of the others a60 2 Fundamentals of Thermodynamics-II
constant. It can be seen that there are 30 such derivatives. Using Maxwell relations 
and the identities between partial derivatives, it turns out that not all of them are 
independent. In fact all those derivatives can be expressed in terms of the set of 
three derivatives defining .(CV , κS, αS), called the fundamental set. However, the 
fundamental set involves keeping an extensive variable constant. In practice, it is often 
more convenient to hold an intensive variable under control. It is therefore useful 
to adopt a set having independent second partial derivatives of a thermodynamic 
potential with respect to intensive parameters as the independent set. In view of this, 
being a function of intensive variables.T, P, the Gibbs potential.G(T, P) becomes a 
natural choice for defining independent observables. Its three second derivatives are 
.
(∂2G
∂T 2
)
P
= − ( ∂S
∂T
)
P
= −CP
T , (2.106) 
where 
.CP =
(∂Q
∂T
)
P
= T
( ∂S
∂T
)
P
(2.107) 
is the specific heat at constant pressure. Next, 
.
(∂2G
∂P2
)
T
=
(∂V
∂P
)
T
= −VκT , (2.108) 
where 
.κT = − 1
V
(∂V
∂P
)
T
(2.109) 
is the isothermal compressibility. Finally 
.
∂2G
∂T ∂P =
(∂V
∂T
)
P
= VαP , (2.110) 
where 
.αP = 1
V
(∂V
∂T
)
P
(2.111) 
is the coefficient of isobaric thermal expansion. 
The set.(CP , κT , αP ) is called the primary set. Using the Maxwell relations and 
the relations between partial derivatives derived in Appendix A, all the derivatives 
between two of the variables from the set.U, S, V, T, P keeping one of the others a 
constant can be expressed in terms of the primary set.(CP , κT , αP ).2.9 Independent Thermodynamic Observables 61
Complete list of all the second derivatives of.U, S, V, T, P in terms of independent 
second derivatives is compiled in [ 3], and is reproduced in [ 4]. 
In the following, we derive relations between the observables in the primary set 
.(CP , κT , αP ) and those in the the fundamental set.(CV , κS, αS). 
1. To derive the expression for .CV in terms of the primary set, write its definition 
(2.101) in terms of the Jacobian: 
. CV = T
∂(S, V )
∂(T, V ) = T
∂(S, V )
∂(T, P)
∂(T, P)
∂(T, V )
= T det
⎛
⎜
⎜
⎜
⎜
⎝
( ∂S
∂T
)
P
( ∂S
∂P
)
T
(∂V
∂T
)
P
(∂V
∂P
)
T
⎞
⎟
⎟
⎟
⎟
⎠
(∂P
∂V
)
T
= T det
⎛
⎜
⎜
⎜
⎜
⎝
( ∂S
∂T
)
P
−
(∂V
∂T
)
P
(∂V
∂T
)
P
(∂V
∂P
)
T
⎞
⎟
⎟
⎟
⎟
⎠
(∂P
∂V
)
T
, (2.112) 
where the fourth Maxwell relation in (2.98) has been used in writing the last 
equation. It then follows that 
.CV = CP − V T
κT
α2
P . (2.113) 
This expresses.CV in the fundamental set in terms of the primary set. 
2. To express adiabatic compressibility .κS in terms of the primary set, write its 
expression (2.103) in terms of the Jacobian: 
. κS = − 1
V
∂(V, S)
∂(P, S) = − 1
V
∂(V, S)
∂(P, T )
∂(P, T )
∂(P, S)
= − 1
V
det
⎛
⎜
⎜
⎜
⎜
⎝
(∂V
∂P
)
T
(∂V
∂T
)
P
( ∂S
∂P
)
T
( ∂S
∂T
)
P
⎞
⎟
⎟
⎟
⎟
⎠
(∂T
∂S
)
P
= − 1
V
det
⎛
⎜
⎜
⎜
⎜
⎝
(∂V
∂P
)
T
(∂V
∂T
)
P
−
(∂V
∂T
)
P
( ∂S
∂T
)
P
⎞
⎟
⎟
⎟
⎟
⎠
(∂T
∂S
)
P
, (2.114)62 2 Fundamentals of Thermodynamics-II
where the fourth Maxwell relation in (2.98) has been used in writing the last 
equation. It then follows that 
.κS = κT − V T
CP
α2
P . (2.115) 
This expresses.κS in the fundamental set in terms of the primary set. 
3. To obtain the adiabatic expansion coefficient in terms of the primary set, write its 
definition (2.105) in terms of the Jacobian: 
. αS = 1
V
∂(V, S)
∂(T, S) = 1
V
∂(V, S)
∂(T, P)
∂(T, P)
∂(T, S)
= 1
V
det
⎛
⎜
⎜
⎜
⎜
⎝
(∂V
∂T
)
P
(∂V
∂P
)
T
( ∂S
∂T
)
P
( ∂S
∂P
)
T
⎞
⎟
⎟
⎟
⎟
⎠
(∂P
∂S
)
T
= 1
V
[(∂V
∂T
)
P
−
( ∂S
∂T
)
P
(∂V
∂P
)
T
(∂P
∂S
)
T
]
= 1
V
[(∂V
∂T
)
P
+
( ∂S
∂T
)
P
(∂V
∂P
)
T
(∂T
∂V
)
P
]
, (2.116) 
where the fourth Maxwell relation in (2.98) has been used in writing the last 
equation. It then follows that 
.αS = αP − CP κT
V TαP
. (2.117) 
This expresses.αS in the fundamental set in terms of the primary set. 
Some other useful relations between the observables in the primary and the funda￾mental sets are 
1. The ratio.CP /CV is given by 
. 
CP
CV
= ∂(S, P)
∂(T, P)
∂(T, V )
∂(S, V ) = ∂(S, P)
∂(S, V )
∂(T, V )
∂(T, P) =
(∂P
∂V
)
S
(∂V
∂P
)
T
= κT
κS
. (2.118) 
2. To obtain.αP /αS, rewrite (2.117) as 
.αS = αP
(
1 − CP κT
V Tα2
P
)
= − αPCV
CP − CV
, (2.119)2.9 Independent Thermodynamic Observables 63
where the second equation is due to (2.113). This yields 
.
αP
αS
= 1 − CP
CV
. (2.120) 
Using (2.118), the equation above can be written in terms of.κT /κS: 
.
αP
αS
= 1 − κT
κS
. (2.121) 
3. Using (2.113) to write .CP in (2.119) in terms of .CV , we get the first of the 
equations below: 
.αS = − CV κT
V TαP
= − CP κS
V TαP
. (2.122) 
The second equation is due to the use of (2.118) in the first one. For an alternative 
derivation of (2.122) see Ex. 2.18. 
4. A parameter of interest in certain applications is Grüneisen parameter: 
.Γ = V
(∂P
∂U
)
V
. (2.123) 
This can be rewritten as (see Ex. 2.19) 
.Γ = −V
T
(∂T
∂V
)
S
= − 1
TαS
. (2.124) 
Using (2.122) in (2.124) we obtain first of the equations, 
.Γ = VαP
CP κS
= VαP
CV κT
. (2.125) 
The second equation is due to the use of (2.118) in the first one. The equation 
above is a widely used form of. Γ . 
Exercises 
Ex. 2.12. Show that 
.
(∂T
∂P
)
V
= κT
αP
. (2.126) 
Hint: Use the cyclic rule (A.9).64 2 Fundamentals of Thermodynamics-II
Ex. 2.13. Show that 
.
( ∂S
∂V
)
T
= αP
κT
. (2.127) 
Hint: Use second of the Maxwell relation in (2.98) and use (2.126). 
Ex. 2.14. Show that 
.
( ∂S
∂V
)
P
= CP
T VαP
. (2.128) 
Hint: Note that.(∂S/∂V )P = (∂S/∂T )P (∂T/∂V)P . 
Ex. 2.15. Show that 
.
( ∂S
∂P
)
V
= CV
T κTαP
. (2.129) 
Hint: Note that.(∂S/∂P)V = (∂S/∂T )V (∂T/∂P)V and use (2.127). 
Ex. 2.16. Show that 
.
( ∂S
∂P
)
T
= −VαP . (2.130) 
Hint: Use fourth of the Maxwell relations in (2.98). 
Ex. 2.17. Derive the so-called.T dS equations: 
. T dS = CV dT +
TαP
κT
dV,
T dS = CP dT − V TαP dP,
T dS = CP
VαP
dV +
CV κT
αP
dP. (2.131) 
Since .T dS is the amount of heat absorbed in a reversible process, the 
.T dS equations are useful in determining the heat absorbed in a reversible 
process in terms of measurable quantities when the system is described in 
terms of different combinations of two independent variables from the set 
of three state variables .(P, V, T ). Hint: Let .S = S(α, β) so that . dS =
(∂S/∂α)βdα + (∂S/∂β)αdβ where .(α, β) = (T, V ), .(α, β) = (T, P), 
.(α, β) = (V, P), respectively, in the three equations above. The desired 
results are obtained by invoking equations (2.127)–(2.130). 
Ex. 2.18. Derive (2.122) using the cyclic rule (A.9). 
Ex. 2.19. Show that 
.
(∂P
∂U
)
V
= − 1
T
(∂T
∂V
)
S
. (2.132)2.10 Stability from Maximum Entropy Principle 65
Hint: Note that .(∂P/∂U)V = (∂P/∂S)V (∂S/∂U)V = (∂P/∂S)V /T . 
The desired result is obtained by the use of first Maxwell relation in (2.98). 
2.10 Stability from Maximum Entropy Principle 
In Sect. 2.2, we applied the principle of maximum entropy to find the equilibrium 
values of the thermodynamic variables when one or the other internal constraint in 
an isolated system is removed. The condition used for the purpose was the extremum 
condition .δST = 0. However, the said condition does not ensure that the state is of 
maximum entropy. Whether the extremum is a minimum or a maximum depends on 
whether the second-order change in the function is positive or negative at the position 
of the extremum. The condition .δST = 0 will correspond to maximum entropy if 
.δ2 ST < 0, called the stability condition. Assuming fixed number of molecules, in 
the following we examine the consequences of the stability condition. 
Like in Sect. 2.2, we begin by considering an isolated system consisting of two 
subsystems separated by a rigid wall which does not allow exchange of heat as well. 
When exchange of heat is allowed and the partition is made movable, we showed 
in Sect. 2.2.2 that the condition .δST = 0 .(ST = S1(U1, V1) + S2(U2, V2)) leads to 
equalization of temperature and pressure of the subsystem. We examine now the 
second-order variation.δ2 ST in total entropy. It is given by 
.δ2 ST = 1
2
Σ
i=1,2
[
∂2 Si
∂U2
i
(δUi)
2 + 2
∂2 Si
∂Ui∂Vi
(δUi)(δVi) +
∂2 Si
∂V2
i
(δVi)
2
]
,(2.133) 
where it is understood that the derivatives are evaluated at the position of the 
extremum. Using (2.33), the equation above reduces to 
.δ2 ST = ∂2 S1
∂U2
1
(δU1)
2 + 2
∂2 S1
∂U1∂V1
(δU1)(δV1) +
∂2 S1
∂V2
1
(δV1)
2
. (2.134) 
Doing away with the subscript . 1 on various quantities, (2.134) may be rewritten in 
the following useful form: 
.δ2 ST = (
δU δV
)
Aˆ
⎛
⎝
δU
δV
⎞
⎠ , (2.135) 
where. Aˆ is a real symmetric matrix given by66 2 Fundamentals of Thermodynamics-II
.Aˆ =
⎛
⎜
⎜
⎜
⎝
∂2 S
∂U2
∂2 S
∂U∂V
∂2 S
∂U∂V
∂2 S
∂V2
⎞
⎟
⎟
⎟
⎠ ≡
⎛
⎝
a11 a12
a12 a22
⎞
⎠ . (2.136) 
The condition.δ2 ST < 0 for.ST to be maximum then reads 
.
(
δU δV
)
Aˆ
⎛
⎝
δU
δV
⎞
⎠ < 0. (2.137) 
This will hold if the eigenvalues.λ1,2 of. Aˆ, given by 
.λ1,2 = 1
2
(
a11 + a22 ±
/
(a11 + a22)2 − 4(a11a22 − a2
12)
)
, (2.138) 
are negative. To find conditions on the .ai j’s under which .λ1,2 < 0, note that, being 
equal to.(a11 − a22)2 + 4a2
12, the factor under the radical sign is positive. Hence, the 
roots are real as they should be due to the fact that .Aˆ is real symmetric. The roots 
will be negative if their sum is negative and the product positive. Since the sum of 
the roots of a matrix is its trace and their product its determinant, it follows that the 
roots of. Aˆ in (2.137) will be negative if 
.a11 + a22 < 0, a11a22 − a2
12 > 0. (2.139) 
For satisfaction of the second condition above,.a11a22 should be positive which will 
be the case if.a11 and.a22 have same sign. Hence, due to first condition above,.a11 and 
.a22 should be negative. Thus, the condition for .Aˆ to have real negative eigenvalues 
is 
.a11 < 0, a22 < 0, a11a22 − a2
12 > 0. (2.140) 
With.ai j given by (2.136), it follows that.δ2 ST < 0 if 
. ( ∂2 S
∂U2
)
V
< 0,
( ∂2 S
∂V2
)
U
< 0,
( ∂2 S
∂U2
)
V
( ∂2 S
∂V2
)
U
−
( ∂2 S
∂U∂V
)2
> 0. (2.141) 
These are the conditions for the equilibrium state to be stable. Let us examine the 
consequences of the conditions above on the observables of the system. 
1. We examine first the consequences of the first of the stability conditions in (2.141). 
To that end, we have2.10 Stability from Maximum Entropy Principle 67
.
( ∂2 S
∂U2
)
V
=
(∂1/T
∂U
)
V
= − 1
T 2
(∂T
∂U
)
V
= − 1
T 2CV
. (2.142) 
Hence, in order to satisfy the first condition in (2.141) we should have 
.CV > 0. (2.143) 
2. Next, we examine the third condition in (2.141). We have 
. 
∂2 S
∂U2
∂2 S
∂V2 −
( ∂2 S
∂U∂V
)2
= ∂(∂S/∂U, ∂S/∂V )
∂(U, V ) = ∂(1/T, P/T )
∂(U, V ) .
(2.144) 
Now 
. 
∂(1/T, P/T )
∂(U, V ) = ∂(1/T, P/T )
∂(T, V)
∂(T, V)
∂(U, V) = − 1
T 2
(∂P/T
∂V
)
T
(∂T
∂U
)
V
= 1
V T 3CV κT
. (2.145) 
On substituting (2.145) in (2.144) and due to (2.143), we see that the last condition 
in (2.141) shall be satisfied if 
.κT ≡ − 1
V
(∂V
∂P
)
T
> 0. (2.146) 
This shows that 
.
(∂V
∂P
)
T
< 0, (2.147) 
i.e. volume always decreases with increase in pressure. 
3. We have examined the consequences of the first and the third stability conditions 
in (2.141). We examine now the remaining, namely, the second condition. We will 
see that it does not lead to any new restriction on the properties of the observables. 
We have 
.
( ∂2 S
∂V2
)
U
=
(∂P/T
∂V
)
U
= ∂(P/T, U)
∂(V, U) . (2.148) 
Rewrite the Jacobian above as68 2 Fundamentals of Thermodynamics-II
. 
∂(P/T, U)
∂(V, U) = ∂(P/T, U)
∂(V, T )
∂(V, T )
∂(V, U)
=
⎛
⎜
⎜
⎜
⎜
⎝
(∂P/T
∂V
)
T
(∂P/T
∂T
)
V
(∂U
∂V
)
T
(∂U
∂T
)
V
⎞
⎟
⎟
⎟
⎟
⎠
(∂T
∂U
)
V
. (2.149) 
Invoking the entropic Maxwell relation (2.99) and with 
.
(∂P/T
∂V
)
T
= 1
T
(∂P
∂V
)
T
= − 1
V T κT
, (2.150) 
we obtain 
.
( ∂2 S
∂V2
)
U
= ∂(P/T, U)
∂(V, U) = − [
1
V T κT
+
1
T 2CV
(∂U
∂V
)2
T
]
. (2.151) 
Since, as a consequence of other two stability conditions, .CV > 0, .κT > 0, we 
see that 
.
( ∂2 S
∂V2
)
U
< 0. (2.152) 
The second condition is thus satisfied once the other two are. 
We can express the derivative on the right side of (2.151) in terms of the primary 
set. To that end, recall the first law to get 
.
(∂U
∂V
)
T
= T
( ∂S
∂V
)
T
− P. (2.153) 
Using the cyclic rule we have 
.
( ∂S
∂V
)
T
= − CV
V TαS
. (2.154) 
Substitute this in (2.153) and the resulting equation in (2.151) to obtain 
.
( ∂2 S
∂V2
)
U
= − [
1
V T κT
+
1
T 2CV
(
P +
CV
VαS
)2
]
< 0. (2.155) 
The adiabatic expansion coefficient .αS is given in terms of the primary set by 
(2.117).2.10 Stability from Maximum Entropy Principle 69
4. We examined the third conditions in (2.141) without evaluating the mixed second 
derivative therein separately. We now evaluate the mixed derivative of. S and verify 
that the result obtained by using it is same as the one derived before. To that end, 
we have 
. 
∂2 S
∂V∂U =
(∂1/T
∂V
)
U
= − 1
T 2
(∂T
∂V
)
U
= − 1
T 2
∂(T, U)
∂(V, U)
= − 1
T 2
∂(T, U)
∂(T, V )
∂(T, V )
∂(V, U) = 1
T 2CV
(∂U
∂V
)
T
, (2.156) 
where .(∂U/∂V )T is given by (2.153). On using the equation above, along with 
(2.142) and (2.151) to evaluate the left side in (2.144), it may be verified that the 
result so obtained agrees, as it must, with the directly derived result (2.145). 
Summary 
The extremum of entropy will be a stable maximum if 
.CV > 0, κT > 0. (2.157) 
Some consequences of the conditions above are 
1. It is readily seen that, when applied to the relation (2.113) for .CP − CV , the 
conditions (2.157) lead to the inequality 
.CP > CV > 0. (2.158) 
This states that the heat capacity at constant pressure is always greater than that 
at constant volume. This is expected intuitively as entire supplied heat energy is 
used in raising temperature of the substance when kept at constant volume but 
part of it is used in the work that system performs as its volume increases when 
pressure is kept constant. 
2. Since, due to (2.158),.CP /CV > 0, the relation (2.118) implies.κT /κS > 0. But, 
due to (2.157),.κT > 0. Hence.κS > 0. Consequently, (2.115) leads to the inequal￾ity 
.κT > κS > 0. (2.159) 
3. Due to (2.158) and (2.159), the relation (2.122) yields 
.αPαS < 0. (2.160)70 2 Fundamentals of Thermodynamics-II
In Sect. 2.11, we show that maximum entropy principle is equivalent with the 
minimum energy principle. 
Exercises 
Ex. 2.20. Show that 
.
(∂P/T
∂T
)
V
= − 1
T 2
(
P − TαP
κT
)
. (2.161) 
Ex. 2.21. Show that 
.
∂2 S
∂U∂V = 1
CV
(∂P/T
∂T
)
V
. (2.162) 
2.11 Stability from Minimum Energy Principle 
We formulated the maximum entropy principle by assuming that total energy, volume, 
and the number of particles remain unchanged when two subsystems constituting an 
isolated system are allowed to exchange energy and the partition between them is 
movable. We consider now the thermodynamic process between two subsystems such 
that their total entropy and volume remain unchanged. We show that the equilibrium 
state of such a system corresponds to the state of minimum total energy.UT: 
.UT = U1 + U2, (2.163) 
where.Ui is the internal energy of the.ith system (.i = 1, 2), when 
.S1 + S2 = constant, V1 + V2 = constant. (2.164) 
From (2.163), along with the use of (2.164), it follows that 
. δUT =
(∂U1
∂S1
− ∂U2
∂S2
)
δS1 +
(∂U1
∂V1
− ∂U2
∂V2
)
δV1
= (T1 − T2) δS1 + (P1 − P2) δV1. (2.165) 
From maximum entropy principle we know that, at equilibrium,.T1 = T2,.P1 = P2. 
Hence it follows that, at equilibrium, .δUT = 0, i.e. the energy is extremum. To 
establish that the extremum is a minimum, we examine the second variation . δ2UT
given by2.11 Stability from Minimum Energy Principle 71
. δ2
UT = 1
2
Σ
i=1,2
[
∂2Ui
∂S2
i
(δSi)
2 + 2
∂2Ui
∂Si∂Vi
(δSi)(δVi) +
∂2Ui
∂V2
i
(δVi)
2
]
= ∂2U1
∂S2
1
(δS1)
2 + 2
∂2U1
∂S1∂V1
(δS1)(δV1) +
∂2U1
∂V2
1
(δV1)
2
, (2.166) 
where in writing the second line we have invoked the equality of corresponding 
derivatives of two subsystems at equilibrium and (2.164). 
Doing away with the subscript. 1 on various quantities, the equation above can be 
rewritten in following useful form: 
.δ2
UT = (
δS δV
)
Bˆ
⎛
⎝
δS
δV
⎞
⎠ , (2.167) 
where. Bˆ is a real symmetric matrix given by 
.Bˆ =
⎛
⎜
⎜
⎜
⎝
∂2U
∂S2
∂2U
∂S∂V
∂2U
∂S∂V
∂2U
∂V2
⎞
⎟
⎟
⎟
⎠ ≡
⎛
⎝
b11 b12
b12 b22
⎞
⎠ . (2.168) 
The condition.δ2UT > 0 for.UT to be minimum then reads 
.
(
(δS)2 (δV)2
)
Bˆ
⎛
⎝
(δS)2
(δV)2
⎞
⎠ > 0. (2.169) 
The condition (2.169) will hold if the eigenvalues.λ1,2 of. Bˆ, given by (2.138) (with 
the.ai j’s therein replaced by the.bi j’s) are positive. To find the conditions on the.bi j’s 
under which.λ1,2 > 0, recall from the discussion circa (2.138) that the roots are real. 
The roots will be positive if the sum as well as the product of the eigenvalues is 
positive which will be the case if the trace and the determinant of. Bˆ are positive: 
.b11 + b22 > 0, b11b22 − b2
12 > 0. (2.170) 
Clearly, if the second condition above is to be satisfied, .b11b22 should be positive 
which will be the case if .b11 and .b22 have same sign which in turn, due to the first 
condition above, requires.b11 and.b22 to be positive. The condition for. Bˆ to have real 
positive eigenvalues therefore is 
.b11 > 0, b22 > 0, b11b22 − b2
12 > 0. (2.171)72 2 Fundamentals of Thermodynamics-II
With.bi j given by (2.168), the equations above read 
. (∂2U
∂S2
)
V
> 0,
(∂2U
∂V2
)
S
> 0,
(∂2U
∂S2
) (∂2U
∂V2
)
−
( ∂2U
∂S∂V
)2
> 0. (2.172) 
These are the conditions for .U(S, V ) to be a minimum at the values of .(S, T ) at 
which.δU = 0. 
We leave it to the exercises to show that the inequalities in (2.172) are satisfied 
under the same conditions under which entropy is maximum. This shows that the 
principle of maximum entropy is equivalent with that of minimum energy. 
Next we consider a system interacting with one or more reservoirs and show that 
the state of equilibrium of the system is determined by some extremum principle on 
an appropriately chosen Legendre transform of energy or entropy. 
Exercises 
Ex. 2.22. Show that 
.
(∂2U
∂S2
)
V
= T
CV
. (2.173) 
Since the positivity of.CV has been shown to hold due to entropy maximum 
principle, it follows that the first inequality in (2.172) is satisfied. 
Ex. 2.23. Show that 
.
(∂2U
∂V2
)
S
= 1
VκS
. (2.174) 
Since the positivity of.κS has been shown to hold due to entropy maximum 
principle, it follows that the second inequality in (2.172) is satisfied. 
Ex. 2.24. Show that 
.
∂2U
∂S∂V = − TαP
CV κT
. (2.175) 
Ex. 2.25. Prove the equation below by expressing its left side as a Jacobian 
. (∂2U
∂S2
)
V
(∂2U
∂V2
)
S
−
( ∂2U
∂S∂V
)2
= − ( ∂S
∂T
)−1
V
(∂P
∂V
)
T
= T
VκTCV
. (2.176)2.12 Stability in Terms of Thermodynamic Potentials 73
Since the positivity of.CV and.κT has been shown to hold due to entropy 
maximum principle, it follows that the last inequality in (2.172) is satisfied. 
Ex. 2.26. Establish the correctness of (2.176) by evaluating its left side using the 
expressions (2.173)–(2.175). 
2.12 Stability in Terms of Thermodynamic Potentials 
In the problems formulated in terms of thermodynamic potentials, it is desirable to 
know as to how those functions behave at thermodynamic equilibrium, i.e. whether 
they too possess an extremum at equilibrium. The answer to that question requires 
evaluation of the function’s second partial derivatives with respect to its arguments. 
Since thermodynamic potentials are Legendre transforms of energy .U(S, V ) with 
respect to one or the other variable or both, the second derivatives of the potential 
in question can be expressed in terms of the second derivatives of .U(S, V ) using 
the results derived in Appendix B, and deduce therefrom the nature of the second 
derivatives of the potential invoking the conditions (2.172) on the second derivatives 
of .U(S, V ) at equilibrium. In this section, we apply the said procedure to examine 
the nature of second-order variation of the Helmholtz and Gibbs potentials and that 
of enthalpy. We will see that the nature of variation of the potentials is different with 
respect to extensive and intensive variables. 
2.12.1 Helmholtz Potential 
The Helmholtz potential.F(T, V) is the Legendre transform of.U(S, V ) with respect 
to. S. Invoking the results derived in Appendix B.1 we have 
.
(∂2 F(T, V )
∂T 2
)
V
= − [(∂2U(S, V )
∂S2
)
V
]−1
< 0, (2.177) 
.
(∂2 F(T, V)
∂V2
)
T
=
(∂2U
∂S2
)−1 (
∂2U
∂S2
∂2U
∂V2 −
( ∂2U
∂S∂V
)2
)
> 0, (2.178) 
. 
∂2 F(T, V)
∂T 2
∂2 F(T, V)
∂V2 −
(∂2 F(T, V )
∂T ∂V
)2
= − (∂2U
∂S2
)−1 (∂2U
∂V2
)
< 0. (2.179) 
The inequalities in the equations above are due to the stability conditions (2.172) on 
.U(S, V ). The mixed second-order derivative of.F(T, V) is74 2 Fundamentals of Thermodynamics-II
.
∂2 F(T, V)
∂T ∂V =
(∂2U
∂S2
)−1 ( ∂2U
∂S∂V
)
. (2.180) 
This does not have a definite sign (see (Ex. 2.27)). 
We see that .F(T, V ) is a convex function with respect to its extensive variable 
.V but is concave with respect to its intensive variable . T . See Appendix C for the 
concept of concave and convex functions. 
Exercises 
Ex. 2.27. Using (2.60) show that 
. (∂2 F
∂V2
)
T
= 1
VκT
,
(∂2 F
∂T 2
)
V
= −CV
T
∂2 F(T, V)
∂T ∂V = −αP
κT
. (2.181) 
Show that the sign of the mixed second derivative above is indefinite. 
Ex. 2.28. Prove the equation below by expressing its left side as a Jacobian 
.
∂2 F(T, V)
∂T 2
∂2 F(T, V)
∂V2 −
(∂2 F(T, V)
∂T ∂V
)2
= − CP
T VκT
. (2.182) 
Show that it would hold, as it must, if its left side is evaluated using instead 
the expressions derived in (2.181). 
Ex. 2.29. Verify that the expressions in (2.181) and (2.182) satisfy the corresponding 
equations (2.177)–(2.180) in terms of the derivatives of.U(S, V ). 
2.12.2 Enthalpy 
Enthalpy.H(S, P) is the Legendre transform of.U(S, V ) with respect to. V. Invoking 
the results derived in Appendix B.1 we have 
.
(∂2 H(S, P)
∂P2
)
S
= − [(∂2U(S, V )
∂V2
)
S
]−1
< 0, (2.183) 
.
(∂2 H(S, P)
∂S2
)
P
=
(∂2U
∂V2
)−1 (
∂2U
∂V2
∂2U
∂S2 −
( ∂2U
∂S∂V
)2
)
> 0, (2.184)2.12 Stability in Terms of Thermodynamic Potentials 75
. 
∂2 H(S, P)
∂P2
∂2 H(S, P)
∂S2 −
(∂2 H(S, P)
∂P∂S
)2
= − (∂2U
∂V2
)−1 (∂2U
∂S2
)
< 0. (2.185) 
The inequalities in the equations above are due to the stability conditions on . U
derived in Sect. 2.11. The mixed second-order derivative of.H(S, P) is 
.
∂2 H(S, P)
∂P∂S =
(∂2U
∂V2
)−1 ( ∂2U
∂V∂S
)
. (2.186) 
This does not have a definite sign (see (Ex. 2.30)). 
We see that.H(S, P) is a convex function with respect to its extensive variable. S
but is concave with respect to its intensive variable. P. 
Exercises 
Ex. 2.30. Using (2.73) show that 
. (∂2 H
∂P2
)
S
= −VκS,
(∂2 H
∂S2
)
P
= T
CP
∂2 H
∂S∂P = V TαP
CP
. (2.187) 
Show that the mixed derivative above does not have a definite sign. 
Ex. 2.31. Prove the equation below by expressing its left side as a Jacobian 
.
∂2 H(S, P)
∂S2
∂2 H(S, P)
∂P2 −
(∂2 H(S, P)
∂S∂P
)2
= −κT V T
CP
. (2.188) 
Show that it would hold, as it must, if its left side is evaluated using instead 
the expressions derived in (2.187). 
Ex. 2.32. Verify that the expressions in (2.187) and (2.188) satisfy the corresponding 
equations (2.183)–(2.186) in terms of the derivatives of.U(S, V ). 
2.12.3 Gibbs Potential 
Gibbs potential.G(T, P) is the Legendre transform of.U(S, V ) with respect to both 
of its variables,. S and. V. Invoking the results derived in Appendix B.2 we have76 2 Fundamentals of Thermodynamics-II
.
(∂2G(T, P)
∂T 2
)
P
= − (∂2U
∂V2
)[
∂2U
∂S2
∂2U
∂V2 −
( ∂2U
∂S∂V
)2
]−1
< 0, (2.189) 
.
(∂2G(T, P)
∂P2
)
T
= − (∂2U
∂S2
)[
∂2U
∂S2
∂2U
∂V2 −
( ∂2U
∂S∂V
)2
]−1
< 0, (2.190) 
. (∂2G(T, P)
∂T 2
)
P
(∂2G(T, P)
∂P2
)
T
−
(∂2G(T, P)
∂T ∂P
)2
=
[(∂2U
∂S2
)
V
(∂2U
∂V2
)
S
−
( ∂2U
∂S∂V
)2
]−1
> 0, (2.191) 
.
∂2G(T, P)
∂T ∂P =
( ∂2U
∂S∂V
)[
∂2U
∂S2
∂2U
∂V2 −
( ∂2U
∂S∂V
)2
]−1
< 0. (2.192) 
The inequalities in the equations above are due to the stability conditions on. U derived 
in Sect. 2.11. The function .G(T, P) is convex with respect to both its variables 
which are intensive. Also, unlike the mixed second derivative of .F(T, V) and that 
of.H(S, P), the mixed second derivative of.G(T, P) has definite sign. 
Exercises 
Ex. 2.33. Using (2.56) show that 
. (∂2G
∂P2
)
T
= −VκT ,
(∂2G
∂T 2
)
P
= −CP
T
∂2G
∂T ∂P = VαP . (2.193) 
Show that the mixed derivative above does not have a definite sign. 
Ex. 2.34. Prove the equation below by expressing its left side as a Jacobian 
.
∂2G
∂T 2
∂2G
∂P2 −
( ∂2G
∂T ∂P
)2
= V CV κT
T . (2.194) 
Show that it would hold, as it must, if its left side is evaluated using instead 
the expressions derived in (2.193). 
Ex. 2.35. Verify that the expressions in (2.193) and (2.194) satisfy the corresponding 
equations (2.189)–(2.192) in terms of the derivatives of.U(S, V ).2.13 Thermodynamic Potentials: Alternative Formulation 77
2.13 Thermodynamic Potentials: Alternative Formulation 
We introduced the thermodynamic potentials as the Legendre transforms of the 
energy function .U(S, V, N). One may ask: to what physical situations they cor￾respond to. In this section, we address that question for a system of fixed number of 
particles and show that a thermodynamic potential describes a system in equilibrium 
with a reservoir of heat or pressure or both. We find also the maximum or available 
work that can be extracted from such a system and introduce the concept of exergy. 
2.13.1 System Interacting with Heat Reservoir 
Consider a system .A interacting with the heat reservoir .R maintained at a constant 
temperature. T0. The two systems exchange only heat while their individual volumes 
remain unchanged. Let.δQ be the amount of heat drawn by. A from. R and let.δWe be 
the external work performed by . A. By external work we mean the work other than 
that associated with the change of volume of the system. Since its volume remains 
constant, the change in the internal energy.U of. A is given by 
.δU = δQ − δWe. (2.195) 
The amount of heat.δQ drawn by. A is the amount lost by. R. Since .R is a reservoir 
at temperature . T0, the heat lost by it is .δQ = −T0δSR where .δSR is change in its 
entropy. Equation (2.195) then assumes the form 
.δU = −T0δSR − δWe. (2.196) 
Let . S denote the entropy of .A and .ST = S + SR total entropy of .A and . R. The 
equation above can then be rewritten as 
. − T0δST = δ(F0 + We), (2.197) 
where 
.F0 = U − T0 S. (2.198) 
The function.F0 is analogous to but not same as the Helmholtz potential because. T
in.F0 has fixed value. T0, the temperature of the reservoir. 
Since the system and the reservoir together are isolated and there is no entropy 
change associated with the execution of the outside work, .δST ≥ 0. Consequently 
(2.197) leads to the inequality 
.δWe ≤ −δF0. (2.199)78 2 Fundamentals of Thermodynamics-II
When no external work is performed, the (2.197) reduces to 
. − T0δST = δF0. (2.200) 
The state of stable thermodynamic equilibrium is reached when.δST = 0,.δ2 ST < 0, 
i.e. when 
.δF0 = 0, δ2F0 > 0. (2.201) 
Let us examine the conditions above. 
Since it has been assumed that the volume does not change, considering it a 
function of.S, V , the definition (2.198) of.F0 yields 
.δF0 =
[(∂U
∂S
)
V
− T0
]
δS. (2.202) 
This shows that the first condition in (2.201) will be satisfied if equilibrium temper￾ature of the system.T = (∂U/∂S)V is same as that of the reservoir. 
Next, (2.198) yields 
.δ2F0 = 1
2
(∂2U
∂S2
)
V
(δS)
2 = 1
2
(∂T
∂S
)
V
(δS)
2 = T0
2CV
(δS)
2
. (2.203) 
Since .CV > 0, we see that .δ2F0 > 0, i.e. the extremum of .F0 is a minimum if the 
volume of the system is unchanged. See also Ex. 2.36. 
Exercises 
Ex. 2.36. Considering.F0 a function of.(V, T ) show that when.δV = 0, the temper￾ature of the system at equilibrium is .T = T0 and .δ2F0 > 0. Hint: Since 
.δV = 0, 
.δF0 =
{(∂U
∂T
)
V
− T0
( ∂S
∂T
)
V
}
δT = CV
(
1 − T0
T
)
δT. (2.204) 
Hence the extremization condition requires.δF0 = 0. To prove the second 
part, show that at.T = T0, 
.δ2F0 = CV
2T0
(δT )
2
. (2.205) 
Verify that the equation above is equivalent with (2.203).2.13 Thermodynamic Potentials: Alternative Formulation 79
2.13.2 System Interacting with Heat and Pressure Reservoirs 
Consider a system. A interacting with the reservoir. R maintained at a constant tem￾perature.T0 and constant pressure.P0. The two systems exchange heat and also change 
volume keeping total volume fixed. Let.δQ be the amount of heat drawn by. A from 
. R. Let.δV be the change in the volume of. A. Since it occurs at the constant pressure 
.P0 of the reservoir and if .δWe is the external work performed by . A, the change in 
the internal energy.U of. A is given by 
.δU = δQ − P0δV − δWe. (2.206) 
With.δQ = −T0δSR = −T0δ(ST − S), the equation above yields 
. − T0δST = δ(G0 + We), (2.207) 
where 
.G0 = U − T0 S + P0V. (2.208) 
The function .G0 is analogous to but not the same as the Gibbs potential because 
.T and .P in .G0 have fixed values .T0 and .P0, the temperature and pressure of the 
reservoir. 
Since system and reservoir together are isolated and there is no entropy change 
associated with the execution of the outside work, .δST ≥ 0. Consequently (2.207) 
leads to the inequality 
.δWe ≤ −δG0. (2.209) 
When no external work is performed, (2.207) reads 
. − T0δST = δG0. (2.210) 
The state of stable equilibrium corresponds to.δST = 0,.δ2 ST < 0 leading to, because 
of (2.210), the following equilibrium conditions on.G0: 
.δG0 = 0, δ2G0 > 0. (2.211) 
Next we examine the conditions (2.211). 
With .G0 given by (2.208), considered a function of .(V, T ), we see by invoking 
the first law that 
.
(∂G0
∂T
)
V
= (T − T0)
( ∂S
∂T
)
V
, (2.212)80 2 Fundamentals of Thermodynamics-II
and 
. (∂G0
∂V
)
T
=
(∂U
∂V
)
T
− T0
( ∂S
∂V
)
T
+ P0
= (T − T0)
( ∂S
∂V
)
T
+ (P0 − P). (2.213) 
The equations above show that the first condition of equilibrium in (2.211), 
.δG0 =
(∂G0
∂T
)
V
δT +
(∂G0
∂V
)
T
δV = 0, (2.214) 
will be satisfied when the system temperature .T and pressure .P are same, respec￾tively, as the reservoir temperature.T0 and pressure.P0. 
To examine the stability condition in (2.211), we have 
. δ2G0 = 1
2
[(∂2G0
∂T 2
)
V
(δT )
2 + 2
∂2G0
∂T ∂V (δT )(δV) +
(∂2G0
∂V2
)
T
(δV)
2
]
,
(2.215) 
where it is understood that the derivatives are to be evaluated at equilibrium. Using 
(2.212) and (2.213) we obtain 
. (∂2G0
∂T 2
)
V
=
( ∂S
∂T
)
V
+ (T − T0)
(∂2 S
∂T 2
)
V
,
(∂2G0
∂V2
)
T
= − (∂P
∂V
)
T
+ (T − T0)
(∂2 S
∂V2
)
T
,
∂2G0
∂T ∂V = (T − T0)
∂2 S
∂T ∂V . (2.216) 
Whereas the last equation follows effortlessly from (2.212), the use of second 
Maxwell relation in (2.98) is needed to get the same from (2.213). Substitute in 
(2.215) the equations above evaluated at the equilibrium values.T = T0,.P = P0 of 
temperature and pressure to get 
.δ2G0 = 1
2
[
CV
T (δT )
2 −
(∂P
∂V
)
T
(δV)
2
]
. (2.217) 
We know that.(∂P/∂V)T < 0. Hence.δ2G0 > 0, i.e..G0 is minimum in the equilib￾rium state characterized by temperature and pressure equal to those of the reservoir. 
In the study of the critical phenomena, we will see that the critical point corre￾sponds to.(∂P/∂V)T = 0. The expression (2.217) shows that in that case. δ2G0 = 0
at the critical point along the isotherm passing through it. The stability in that case 
is determined by higher order terms in the expansion of.G0 in powers of.δT and.δV.2.13 Thermodynamic Potentials: Alternative Formulation 81
In the study of the critical phenomena, we will need terms up to fourth order when 
.δT = 0. The next two higher order terms when.δT = 0 are 
.δ3G0 + δ4G0 =
[ 1
3!
(∂3G0
∂V3
)
T
(δV)
3 +
1
4!
(∂4G0
∂V4
)
T
(δV)
4
]
. (2.218) 
The right side of the equation can be evaluated using (2.216) and the resulting expres￾sion substituted in (2.218) when.(T, P) = (T0, P0) to get 
.δ3G0 + δ4G0 = −(δV)3
3!
(∂2P
∂V2
)
T
− (δV)4
4!
(∂3P
∂V3
)
T
. (2.219) 
We thus have at hand.dG0 up to fourth order in.δV along an isotherm passing through 
the equilibrium point. 
2.13.3 System Interacting with Pressure Reservoir 
Consider a system interacting with a pressure reservoir maintained at pressure . P0
producing work .δWe. There is no exchange of heat between the system and the 
reservoir. The change in its internal energy is then given by 
.δU = −P0δV − δWe. (2.220) 
This implies 
.δWe = −δH0, (2.221) 
where 
.H0 = U + P0V. (2.222) 
Since there is no exchange of heat,.δU = −PδV so that 
.δH0 = (P0 − P)δV. (2.223) 
This shows that .δH0 = 0, i.e. .H0 has the extremum when pressure of the system is 
same as that of the reservoir. To examine the nature of the extremum, we evaluate 
.δ2H0: 
.δ2H0 = −1
2
(∂P
∂V
)
S
(δV)2. (2.224)82 2 Fundamentals of Thermodynamics-II
We know that .(∂P/∂V )S < 0. Hence .δ2H0 > 0. This shows that the extremum of 
.H0 is a minimum when the system undergoes isentropic transformation at constant 
pressure. 
The function .H0 is analogous to but not the same as the enthalpy because .P in 
.H0 has fixed value.P0, the pressure of the reservoir. 
2.13.4 Exergy 
We have found expressions for maximum work available from a system interacting 
with reservoirs of various kinds. The system cannot perform any work when in 
equilibrium with the reservoirs it is interacting with. The equilibrium state of the 
system is therefore called the dead state. 
A quantity of interest in several applications is the amount of available work from 
a system in a given state as it approaches the dead state. It is called exergy. It is the 
combination of the Greek words “ex” (meaning from) and “ergon” (meaning work). 
It was coined by Zoran Rant in 1956. See [ 5] for introduction to the concept of exergy 
and some examples. 
We list below expression for exergy when the system interacts with only a heat 
reservoir and when it interacts with the heat and pressure reservoirs. 
1. Equation (2.199) shows that the maximum available work when the system is in 
contact with a heat reservoir at temperature.T0 is 
.δWemax = −δU + T0δS. (2.225) 
Let.U, S denote, respectively, the internal energy and entropy when the system is 
brought in contact with the reservoir and .U0, S0 the corresponding values when 
it attains equilibrium. The maximum possible work output while it attains equi￾librium, obtained by integrating (2.225), is 
.XE F = (U − U0) − (S − S0)T0. (2.226) 
The .XE F is therefore the exergy for a system undergoing thermodynamic trans￾formation while in contact with a reservoir at temperature. T0. 
2. Equation (2.209) shows that the maximum available work when the system is in 
contact with a heat reservoir at temperature.T0 and a pressure reservoir at pressure 
.P0 is given by 
.δWemax = −δU + T0δS − P0δV. (2.227) 
Let .U, S, V denote, respectively, the internal energy, entropy, and temperature 
when the system is brought in contact with the reservoir and .U0, S0, V0 their 
values at equilibrium. Integration of (2.225) gives2.14 Second Equation of State 83
.XEG = (U − U0) − (S − S0)T0 + (V − V0)P0. (2.228) 
The.XEG is therefore the exergy of the system while it undergoes thermodynamic 
transformation remaining in contact with the heat reservoir at temperature.T0 and 
the pressure reservoir at pressure.P0. 
Exercises 
Ex. 2.37. Show that the exergy of the ideal gas interacting with a heat reservoir at 
temperature.T0 is given by 
.XE F = NkBc [(T − T0) − T0ln(T/T0)] , (2.229) 
where. c is the heat capacity per molecule at constant volume. 
Ex. 2.38. Show that the exergy of the ideal gas interacting with heat and pressure 
reservoirs at temperature.T0 and pressure.P0 is given by 
. XEG = NkB
[
c(T − T0) +
( P0
P
T − T0
)
+(c + 1)T0ln ( T
T0
)
− T0ln ( P
P0
)]
. (2.230) 
2.14 Second Equation of State 
We know that, for one component system, we require three equations of state of 
which two are independent. The familiar equation of state is.P = P(V, T ). We call 
it first equation of state. An additional equation of state is therefore required for 
complete thermodynamic description. The additional equation of state is often the 
energy.U = U(V, T ) as a function of.(V, T ). We call it the second equation of state. 
Though they are independent, the Maxwell relations lead to consistency condition 
between them. In this section, we derive the said consistency condition and also the 
expressions for entropy and chemical potential as functions of.(V, T ) assuming fixed 
. N. The first equation of state.P = P(V, T ) is assumed to be known. 
1. Recall the entropic Maxwell relation (2.99): 
.
(∂U
∂V
)
T
= T
(∂P
∂T
)
V
− P. (2.231)84 2 Fundamentals of Thermodynamics-II
Formal integration of the equation above gives 
.U(V, T ) =
{ {
T
(∂P
∂T
)
V
− P
}
dV + Φ(T ), (2.232) 
where the unknown function.Φ(T ) cannot be determined by first equation of state. 
It must be constructed independently. It is not difficult to see that it is related with 
the heat capacity at constant volume.CV : 
. CV (V, T ) ≡
(∂U
∂T
)
V
=
{
T
(∂2P
∂T 2
)
V
dV + Φ,
(T ), Φ,
(T ) = dΦ(T )
dT .
(2.233) 
The function.Φ(T ) can thus be constructed from the data of.CV as a function of 
.(V, T ). It is also readily seen that 
.
(∂CV (V, T )
∂V
)
T
= T
(∂2P
∂T 2
)
V
. (2.234) 
Equation (2.232) is the second equation of state which expresses internal energy 
.U as a function of .(V, T ). The first term in it is determined by the equation of 
state .P = P(V, T ) whereas the second term, namely, .Φ(T ), is independent of 
the first. As shown in (2.233),.Φ(T ) may be obtained from the knowledge of the 
heat capacity.CV (V, T ). 
2. Knowing the two equations of state, we may compute entropy as a function of 
.(V, T ) as follows. The formal integration of second Maxwell relation in (2.98) 
yields 
.S(V, T ) =
{ (∂P
∂T
)
V
dV + F(T ), (2.235) 
where .F(T ) is an unknown function. It may be expressed in terms of .Φ(T ), 
the function appearing in the equation of state (2.232) for .U(V, T ), by using 
.T (∂S/∂T )V = CV = (∂U/∂T )V so that 
.F,
(T ) = Φ,
(T )
T . (2.236) 
This is the desired relation expressing.F(T ) in terms of.Φ(T ). 
3. To evaluate the chemical potential, substitute (2.232) and (2.235) for.U and. S in 
Euler’s relation (2.46) to get 
.μ(V, T ) = 1
N
{{
V
(∂P
∂V
)
T
dV + Φ(T ) − T F(T )
}
. (2.237)2.14 Second Equation of State 85
The same result may be arrived at by integrating the energetic or entropic Gibbs– 
Duhem relation (see Exs. 2.40 and 2.41). 
Next, we address some questions of importance in applications: (a) determining 
amount of heat absorbed in an isothermal process, (b) determining adiabatic equation 
of state in a reversible transformation, and (c) determining change in temperature of 
adiabatically freely expanding gas. 
(a) The amount of heat absorbed by the system while going from state. A ≡ (VA, T0)
to the state.B ≡ (VB, T0) at constant temperature.T0 along a reversible path is 
.QAB = T0
{ B
A
dS = T0 [I(VB, T0) − I(VA, T0)] , (2.238) 
where use has been made of (2.235) with 
.I(V, T ) =
{ (∂P
∂T
)
V
dV. (2.239) 
Some examples are discussed in Sect. 2.14.1 and in the exercises. 
(b) A reversible adiabatic process is one in which entropy does not change. Hence 
the relation between .V and . T in such a process is obtained by equating .S(V, T ) in 
(2.235) to a constant to get 
.
{ (∂P
∂T
)
V
dV + F(T ) = S0. (2.240) 
Some examples are discussed in Sect. 2.14.1 and in the exercises. 
(c) Consider a gas expanding freely adiabatically, confined initially to volume . VA
at temperature .TA. Its temperature .TB when it is in equilibrium at volume .VB may 
be found by recalling from (1.69) that its internal energy remains unchanged during 
such a process. Using (2.232), this implies 
.Δ
[{ {
T
(∂P
∂T
)
V
− P
}
dV
]
+ ΔΦ(T ) = 0. (2.241) 
As an illustration, we apply the results derived above to systems described by the 
equation of state linear in. T .86 2 Fundamentals of Thermodynamics-II
2.14.1 .P Linear in . T
Let.P be of the form 
.P = f (V)T + g(V). (2.242) 
1. Expressions (2.232), (2.233), respectively, for.U,CV then read 
.U(V, T ) = − {
g(V)dV + Φ(T ), (2.243) 
.CV = dΦ(T )
dT , (2.244) 
which shows that.CV is independent of. V. 
2. Invoking (2.235), entropy may be seen to be given by 
.S(V, T ) =
{
f (V)dV + F(T ). (2.245) 
3. Use of (2.237) leads to the following expression for. μ: 
.μ(V, T ) = 1
N
{{
V {
T f ,
(V) + g,
(V)
}
dV + Φ(T ) − T F(T )
}
.(2.246) 
4. The amount of heat absorbed when system transforms isothermally at temperature 
.T0 from the state of volume .VA to that of volume .VB, given by (2.238), in the 
present case is 
.QAB = T0
{ VB
VA
f (V)dV. (2.247) 
5. In case the transformation is adiabatic in which the initial state of the system is 
.A ≡ (VA, TA) and the final state is .B ≡ (VB, TB) then the governing equation 
(2.240) reduces to 
.
{ VB
VA
f (V)dV +
{ TB
TA
Φ,
(T )
T
dT = S0. (2.248) 
6. If volume and temperature of the gas initially are.(VA, TA) and it undergoes free 
adiabatic expansion to acquire the values.(VB, TB) then the condition (1.69), with 
.U in the present case given by (2.243), leads to2.14 Second Equation of State 87
.
{ VB
VA
g(V)dV = Φ(TB) − Φ(TA). (2.249) 
We apply the results derived above to an ideal gas and the van der Waals gas which 
are special cases of (2.242). 
Ideal Gas 
Consider first the ideal gas. It is a special case of (2.242) with 
. f (V) = NkB/V, g(V) = 0. (2.250) 
Evaluated in the following are various thermodynamic quantities. 
1. First we need to specify.Φ(T ). As discussed in Sect. 1.4.1, the experimental data 
shows independence of .CV on .V as well as on . T . We see from (2.244) that the 
.V-independence of.CV emerges even as an outcome of the consistency condition 
between the equation of state.P = P(V, T ), and the equation determining internal 
energy. However, we have to take recourse to experiments or statistical mechanics 
to establish the .T -independence of .CV which in turn means .T -independence of 
.dΦ(T )/dT . Either way, it is found that .CV for an ideal gas is given by (1.77). 
This corresponds to 
.Φ(T ) = NkBcT, c = 1/(γ − 1). (2.251) 
Using (2.236), the function.F(T ) turns out to be given by 
.F(T ) = NkBcln(T ) + K, (2.252) 
where.K is a constant. 
2. Using (2.251), the expression (2.243) for internal energy reads 
.U(V, T ) = NkBcT. (2.253) 
3. With.F(T ) as in (2.236), the expression (2.245) for entropy reduces to 
.S(V, T ) = NkB (ln(V) + cln(T ) + K). (2.254) 
4. Equation (2.246) for chemical potential yields 
.μ(V, T ) = −kBT (ln(V) + cln(T ) + C), (2.255) 
where. C is a constant. By writing. T in the logarithmic term in the equation above 
in terms of. U, it is not difficult to see that this is same as (2.51) derived by solving 
the Gibbs–Duhem equation.88 2 Fundamentals of Thermodynamics-II
5. The formula (2.247) leads to the following expressions for heat absorbed in a 
reversible isothermal process at temperature. T0: 
.QAB = NkBT0ln(VB/VA). (2.256) 
6. Due to (2.240), the adiabatic equation of state turns out to be given by 
. T Vγ−1 = constant,
between.V and. T in an adiabatic process. 
7. Using (2.249) we see that the temperature of an ideal gas does not change on free 
adiabatic expansion which is in agreement with observations. 
van der Waals Gas 
The van der Waals gas is a special case of (2.242) with 
. f (v) = kB
v − b
, g(v) = − a
v2 . (2.257) 
1. We can determine .Φ(T ) as follows. Verify that (2.243) in the present case leads 
to the following expression for internal energy per molecule: 
.u(V, T ) = −a
v
+ Φ(T )/N. (2.258) 
On comparing (2.257) and (2.250) we see that the van der Waals gas behaves as 
the ideal gas in the limit.v → ∞. We may therefore expect the expression (2.258) 
for .U for the van der Waals gas to reduce to (2.253) for the ideal gas in the said 
limit. Since .Φ(T ) is independent of . V, that would be the case if .Φ(T ) in the 
present case is same as that in (2.251) for the ideal gas. Expression (2.258) then 
reads 
.u(v, T ) = −a
v
+ ckBT. (2.259) 
2. Expression (2.245) for entropy per molecule reads 
.s(v, T ) = kB {ln(v − b) + cln(T ) + K}. (2.260) 
3. Equation (2.246) for chemical potential assumes the form 
.μ(v, T ) = −kBT
{
ln(v − b) − b
v − b + cln(T ) + C
}
− 2a
v . (2.261)2.14 Second Equation of State 89
4. Using (2.247), the heat absorbed in a reversible isothermal transformation at 
temperature.T0 may be seen to be given by 
.QAB = NkB[ln{(vB − b)/(vA − b)}]. (2.262) 
5. The adiabatic equation of state (2.240) reads 
.T (v − b)
γ−1 = constant. (2.263) 
6. Using (2.249) we see that the initial and final volumes and temperature in adiabatic 
free expansion are related by 
.TB − TA = a
ckB
( 1
vB
− 1
vA
)
. (2.264) 
Exercises 
Ex. 2.39. If.F(T ) and.Φ(T ) are related by (2.236) then show that 
. {
F(T )dT = FT − Φ(T ), {
Φ(T )d(1/T ) = 1
T (Φ(T ) − FT ).
(2.265) 
Ex. 2.40. Derive (2.237) by integration of the energetic Gibbs–Duhem relation. 
Hint: Consider .P a function of .(V, T ) so that . dP = (∂P/∂V )T dV +
(∂P/∂T )V dT . Also, carry the integration in the expression (2.235) for. S
by parts and show that 
.dμ = d
({
V
(∂P
∂V
)
T
dV
)
− F(T )dT. (2.266) 
Make use of the first equation in (2.265) to arrive at the desired result. 
Ex. 2.41. Derive (2.237) by integration of the entropic Gibbs–Duhem relation. Hint: 
Follow the procedure analogous to that outlined in the Ex. 2.40 and make 
use of the second equation in (2.265). 
Ex. 2.42. Assuming .P(V, T ) to be of the form (2.242) which is linear in .T and 
assuming that .Φ(T ) is also linear in . T : .Φ(T ) = CT , find change in 
entropy in free adiabatic expansion when gas expands from equilibrium 
state.(VA, TA) to.(VB, TB). Hint: Use (2.249) to show that.TB is given by 
.TB = TA +
1
C
{ VB
VA
g(V)dV. (2.267)90 2 Fundamentals of Thermodynamics-II
Using (2.245), change in entropy is 
.ΔS =
{ VB
VA
f (V)dV + Cln(TB/TA), (2.268) 
where.TB is as in (2.267). 
Ex. 2.43. Consider the equation of state having the form 
.P = f1(T ) + g1(V), (2.269) 
with.CV given by 
.CV = f3(T )V + f4(T ). (2.270) 
(a) Show that the equations above are consistent provided 
. f3(T ) = T
d2 f1(T )
dT 2 . (2.271) 
(b) Show that 
. Φ(T ) =
{
f4(T )dT + K,
U(V, T ) = V T 2 d f1(T )/T
dT +
{
f4(T )dT
−
{
g1(V)dV + K. (2.272) 
Ex. 2.44. Derive (2.246) from entropic Gibbs–Duhem relation. Hint: Assuming. P =
P(V, T ), write .dP = (∂P/∂V )T dV + (∂P/∂T )V dT in the entropic 
Gibbs–Duhem relation (2.50) for single component. Invoke (2.232) too. 
2.15 Joule–Thomson Process 
We conclude the thermodynamics part by discussing an important experiment, called 
Joule–Thomson processwhich showed that internal energy of ideal gas is independent 
of volume. The experiment consisted of a thermally insulated cylinder, partitioned 
into two parts separated by porous plug. Gas in one part is at higher pressure .P1 at 
volume.V1 from which it is forced to seep through the porous plug to the part at the 
lower pressure.P2 at volume.V2. The aim is to find change in temperature of the gas,2.15 Joule–Thomson Process 91
if any, at the end of the process when gas in high-pressure part is pushed completely 
into the low-pressure one. 
Let.U1 be internal energy of the gas in the beginning of the process and.U2 that at 
the end. The work .P1V1 is performed on the gas in pushing it through the plug and 
.P2V2 the work done by it while expanding against pressure.P2 to occupy volume.V2. 
The porous plug slows down the speed of gas molecules to practically zero. Since 
there is no exchange of heat with the surrounding, conservation of energy implies 
.U2 = U1 + P1V1 − P2V2. (2.273) 
This shows that.U2 + P2V2 = U1 + P1V1, i.e. enthalpy.H ≡ U + PV is conserved 
during the process. The change in temperature due to change in pressure is then 
determined by the equation 
.dT =
(∂T
∂P
)
H
dP. (2.274) 
We need to convert the partial derivative in the equation above to measurable quan￾tities. To that end, use to cyclic rule to show that 
.
(∂T
∂P
)
H
= −(∂H/∂P)T
(∂H/∂T )P
. (2.275) 
From the expression (2.72) for.dH we have 
.
(∂H
∂T
)
P
= T
( ∂S
∂T
)
P
= CP . (2.276) 
This determines the denominator in (2.275). The numerator therein can be evaluated 
as follows: 
.
(∂H
∂P
)
T
= T
( ∂S
∂P
)
T
+ V = − (∂V
∂T
)
P
+ V, (2.277) 
where second equation is due to fourth Maxwell relation in (2.98). Substitute (2.276) 
and (2.277) in (2.275) to get 
.
(∂T
∂P
)
H
= 1
CP
{
T
(∂V
∂T
)
P
− V
}
. (2.278) 
This can also be written as 
.
(∂T
∂P
)
H
= V
CP
(TαP − 1), (2.279) 
where.αP is the coefficient of isobaric thermal expansion.92 2 Fundamentals of Thermodynamics-II
Equation (2.278) shows that, for the ideal gas, 
.
(∂T
∂P
)
H
= 0, ideal gas. (2.280) 
No change in temperature is predicted and none was observed, when the operating 
gas in the process is the ideal gas. 
Change in temperature is expected to be observed for non-ideal gases. Equation 
(2.278) shows that temperature will decrease as the pressure decreases if the right 
side therein is positive and temperature will increase as the pressure decreases if the 
right side therein is negative. The temperature .Tinv at which the right side changes 
sign is called the inversion temperature. It is the solution of the equation 
.T
(∂V
∂T
)
P
− V = 0. (2.281) 
Let us estimate the inversion temperature for the van der Waals gas. Using its equation 
of state (1.104), (2.281) for the van der Waals gas leads to following expression for 
the inversion temperature: 
.Tinv = 2a(v − b)2
kBbv2 . (2.282) 
Substitute this in the equation of state (1.104) to get 
.Pv2 − 2av
b + 3a = 0. (2.283) 
This is solved by 
.v = a
bP (
1 ±
/
1 − 3b2P
a
)
. (2.284) 
Substitute this in (2.282) to obtain 
.Tinv = 2a
9bkB
(
2 ±
/
1 − 3b2P
a
)2
. (2.285) 
This shows that there will not be any inversion temperature if .P > a/3b2 and that 
there will be two inversion temperatures if .P < a/3b2. Between the two inversion 
points,.(∂T/∂P)H > 0 whereas.(∂T/∂P)H < 0 outside the inversion points. Thus 
the gas will cool as it is pushed from higher to lower pressure between the twoReferences 93
inversion points, and heat outside of them. For low pressures such that.bP/a << 1, 
the higher inversion temperature is given by 
.Tinv ≈ 2a
bkB
. (2.286) 
As argued in [Landau and Lifshitz], the lower inversion temperature for small. P may 
not occur due to condensation of gas into liquid at the pressures and temperatures in 
question. 
References 
1. G. Cook, R.H. Dickerson, Am. J. Phys. 63, 737 (1995) 
2. R. Baierlein, Am. J. Phys. 69, 483 (2001) 
3. F.D. Stacey, Geophys. Surv. 3, 175 (1977) 
4. D.L. Anderson, Theory of the Earth (Blackwell Scientific Publications, 1989). http://resolver. 
caltech.edu/CaltechBook:1989.001 
5. M.J. Moran, H.N. Shapiri, D.D. Boettner, M.B. Bailey, Fundamentals of Engineering Thermo￾dynamics (Wiley, 2018)Chapter 3 
Kinetic Theory 
Heat has for long been attributed to random molecular motion or agitation. The 
attempts to find quantitative relation between heat and random molecular motion led 
to the kinetic theory of gases, a forerunner of statistical mechanics. It describes the 
state of a gas of molecules in terms of distribution functions of its molecular positions 
and momenta in phase space, their time evolution being governed by the laws of 
mechanics. Linking mechanical description with thermodynamics is fundamentally 
challenging for one because the mechanical evolution is time-reversal symmetric, 
whereas the macroscopic bodies evolve irreversibly in time. The arrow of time can 
emerge in the mechanical description evidently under certain assumptions. Another 
is identifying thermodynamic quantities with mechanical ones. In this chapter, we 
describe how those ends are achieved by the kinetic theory. 
3.1 Early Kinetic Theory 
For a comprehensive account of early kinetic theory, see Truesdell [ 1]. 
The history of the kinetic theory may be traced back to the treatise on hydro￾dynamics by Daniel Bernoulli published in 1738. He considered gas contained in a 
cylinder fitted with a movable piston and modeled the gas as an elastic fluid consisting 
of spherical balls moving rapidly with speed. u. He calculated change in pressure as 
the piston moved and showed that, at constant temperature, pressure is (i) inversely 
proportional to volume and (ii) directly proportional to the square of the speed. u of 
the particles. However, Bernoulli’s work was ignored in then prevailing firm belief 
in the caloric theory of heat. 
The interest in Bernoulli’s model was revived circa 1820 by John Herapath. Hera￾path took momentum as the measure of temperature. This hypothesis, like Bernoulli’s 
approach, though led him to the ideal gas equation, but was found inconsistent with 
several other known results. J. P. Joule, based on experimental evidence, established 
in 1847 that heat was not a fluid but a form of energy and found the relationship 
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4_3 
9596 3 Kinetic Theory
between heat and kinetic energy. Using the theory of Herapath, he derived relation￾ship between heat and kinetic energy in 1851. 
The next important development was due to John James Waterston in 1851. His 
work, however, remained unrecognized. The concepts similar to Waterston’s were 
advanced by Karl Krönig in 1856. He assumed that a particle constituting gas moves 
uniformly in a straight line until it changes direction on elastic collision with another 
particle or with the walls of the container. It led Rudolf Clausius to introduce the 
concept of mean free path which is the average distance traveled by a sphere between 
two successive collisions and showed that the mean free path. l is given by 
.l = 3
4nπd2 , (3.1) 
where. n is the number of molecules per unit volume and. d is the diameter of the sphere 
modeling the molecule. There was no way of ascertaining the value of the mean free 
path using the formula above as experimental measurement of the quantities in it was 
out of question. It was his desire to link the length of mean free path with observables 
that prompted Maxwell to formulate his now well-known theory in [ 2]. 
As observed by Truesdell [ 1], early kinetic theory culminated in Maxwell’s said 
paper. It will therefore be appropriate to begin discussion of the kinetic theory with 
Maxwell’s paper [ 2]. 
3.2 Maxwell Distribution 
Maxwell abandoned the assumption of uniform motion and introduced the concept 
of random distribution of velocity among the molecules and went on to derive the 
probability function describing distribution of the velocity among molecules. In fact, 
as can be seen from the following excerpt from his paper [ 2], it is (3.1) that Maxwell 
had in mind while deriving the said distribution function: 
Mr. Clausius has determined the mean length of path in terms of the average dis￾tance of particles and distance between the centers of two particles when collision 
takes place. We have at present no means of ascertaining either of these distances, 
but certain phenomena, such as the internal friction of gases, the conduction of heat 
through a gas, and the diffusion of one gas through another, seem to indicate the pos￾sibility of determining accurately the mean length of path which a particle describes 
between two successive collisions. In order to lay foundation of such investigations 
on strict mechanical principles, I shall demonstrate the laws of motion of an indefi￾nite number of small, hard, and perfectly elastic spheres acting on one another only 
during impact. 
Furthermore, he states, Instead of saying that the particles are hard, spherical, 
and elastic, we may if we please say that the particles are centers of force, of which 
the action is insensible except at a certain small distance, when it appears suddenly 
as a repulsive force of very great intensity. It is evident that either assumption will3.2 Maxwell Distribution 97
lead to the same result. For the sake of avoiding the repetition of a long phrase about 
these repulsive forces, I shall proceed upon the assumption of perfectly spherical 
bodies. 
Maxwell abandoned the concept of uniform motion and assumed that if a large 
number of particles are moving in a perfectly elastic vessel then collisions would take 
place among them altering their velocities such that, after large number of collisions, 
the kinetic energy will be divided among them according to some regular law. He 
derived the formula for average number of particles whose velocities lie in the interval 
between. v and.v + dv as follows. 
To derive the said law, one starts with the assumption that the velocity of particles 
is a random variable whose distribution is governed by some probability distribution 
function and that there is no correlation between the motion of different particles. 
The probability distribution function of all particles then is the product of distri￾bution function of each particle, same for every particle. Let . F(v) ≡ F(vx , vy , vz)
be the single-particle distribution function so that .F(v)dvxdvydvz is the probabil￾ity that the velocity of the particle lies in the interval .(v, v + dv). The distribution 
function .F(v) is thus the probability per unit volume of the velocity space, or the 
probability density. Maxwell observed that the existence of velocity .vx does not in 
any way affect that of the velocities .vy or .vz since these are all at right angles and 
independent. One can therefore write.F(v) as the product of same function. f (vμ) in 
three directions: .F(vx , vy , vz) = f (vx ) f (vy ) f (vz). Hence the probability that the 
velocity of a particle lies in.(v, v + dv) is given by 
.F(v)d3
v = f (vx ) f (vy ) f (vz)d3
v, d3
v = dvxdvydvz. (3.2) 
Normalization of probability to unity demands 
.
{
F(v)d3
v = 1, −∞ ≤ vx , vy , vz ≤ ∞. (3.3) 
Accordingly, if.N is the number of molecules in the gas then the number per unit vol￾ume in.(v, v + dv), denoted by.n(v), will be.N F(v) so that the number of molecules 
in the said velocity interval would be 
.n(v)d3
v = N F(v)d3
v. (3.4) 
The problem at hand is to determine . f (vμ). Maxwell determined it using simple 
symmetry arguments. Since choice of the direction of the coordinate axes is arbitrary, 
the probability .F(v)d3v should depend only on the magnitude of . v, which means 
the following equation should hold: 
. f (vx ) f (vy ) f (vz) = φ(v2
x + v2
x + v2
x ). (3.5)98 3 Kinetic Theory
This functional equation is solved by 
. f (w) = B exp(−Aw2
), (3.6) 
where.A, B are constants. Using the form (3.6) of. f (w) in (3.2), we get 
.F(v) = C exp{−A(v2
x + v2
y + v2
z )}, (3.7) 
where. C is determined by the normalization condition (3.3): 
.C
{
exp{−A(v2
x + v2
y + v2
z )} d3
v = 1. (3.8) 
Convergence of the integral requires .A > 0. The integral above may be expressed 
as a product of three identical integrals and evaluated invoking the identity (H.7) to 
obtain 
. {
exp{−A(v2
x + v2
y + v2
z )} d3
v =
({ ∞
−∞
exp(−Aw2
)dw
)3
=
( π
A
)3/2
.
(3.9) 
On substituting this in (3.8) follows the expression for. C: 
.C =
( A
π
)3/2
. (3.10) 
Hence the velocity distribution function.F(v) reads 
.F(v) =
( A
π
)3/2
exp(−Av2
). (3.11) 
It is called the Maxwell distribution. Accordingly, recalling (3.4), the number of 
molecules in.(v, v + dv) will be 
.dN(v) ≡ n(v)d3
v = N
( A
π
)3/2
exp(−Av2
)d3
v. (3.12) 
The question that remains to be answered is: what is. A? The answer to it is provided 
by (3.31) which expresses. A in terms of temperature and the mass of the molecule. 
We will see that it is arrived at by deriving the equation of state by using Maxwell’s 
distribution and comparing it with the well-known ideal gas equation of state. 
The test of correctness of (3.11) lies in its ability to predict correctly the values 
of the observables. Let.G(v), a function of. v, be an observable. Since. v is a random 
variable whose distribution is governed by .F(v), the observed value of .G(v) is its 
average over.F(v), denoted by.⟨G(v)⟩ and given by3.2 Maxwell Distribution 99
.⟨G(v)⟩ = {
G(v)F(v) d3
v. (3.13) 
In particular, like .F(v), let .G(v) also be a function of . v alone. The integrand in 
(3.13) in that case is independent of the angle. It can then be evaluated conveniently 
in spherical polar coordinates .(v, θ, φ) (.0 ≤ v ≤ ∞, .0 ≤ θ ≤ π, .0 ≤ φ ≤ 2π) with 
.d3v = v2 sin(θ)dvdθdφ. The integration over the angles can be performed to obtain 
.⟨G(v)⟩ = 4π
{ ∞
0
G(v)F(v)v2
dv. (3.14) 
Using the identity (H.8) it is straightforward to see that 
.⟨v⟩ =
2
√πA
, ⟨v2
⟩ =
3
2A. (3.15) 
On eliminating. A between the equations above we obtain 
.⟨v2
⟩ = (3π/8)⟨v⟩
2
. (3.16) 
Also, due to equivalence of different Cartesian components of the velocity, 
.⟨v2
x ⟩=⟨v2
y ⟩=⟨v2
z ⟩ = ⟨v2⟩
3 = 1
2A. (3.17) 
Using his velocity distribution, Maxwell derived a number of results some of which 
of our interest are summarized below: 
1. Consider a system consisting of.N particles of one kind, called the system I, and 
.N, of another, called the system II. The distribution of the velocities in system I 
is described by (3.11), and that in II by 
.FI I(v) =
( B
π
)3/2
exp(−Bv2
). (3.18) 
The problem addressed by Maxwell is: What is the number of pairs of particles, 
one each from the two systems, whose relative velocity is. V? 
To find the said number, note that the probability of a molecule of system I to have 
velocity in the interval.(v, v + dv) is.F(v)d3v and for given. v, the probability of 
a molecule of system II to have velocity in the interval .(v + V, v + V + dV) is 
.FI I(v + V)d3V. Hence the probability of having a pair of molecules, one from 
the system I to have velocity in the vicinity of . v and another from II to have 
velocity in the vicinity of.v + V is 
.S(v, v + V)d3
vd3V = F(v)FI I(v + V)d3
vd3
V. (3.19)100 3 Kinetic Theory
The number of pairs having relative velocity in the vicinity of. V is then given by 
integrating the expression above over the velocity. v: 
.R(V)d3V = N N,
[{
F(v)F,
(v + V)d3
v
]
d3
V. (3.20) 
We leave it as an exercise to show that 
.R(V) = N N,
( AB
π(A + B)
)3/2
exp{−ABV2
/(A + B)}. (3.21) 
The distribution function for the relative velocities is thus of the same form as 
that for the velocities. 
Having shown, as above, that the distribution of relative velocities follows his law, 
Maxwell deduced that even the distribution of the compounded velocities of two 
systems follows the same law. For, if.v1 is the velocity of a molecule in system I 
and .v2 that of a molecule in system II, the result derived above shows that their 
relative velocity .V = v2 − v1 is distributed according to Maxwell distribution. 
Since reversing direction of velocity does not change distribution, on changing 
.v1 to .−v1, the distribution does not change. Consequently, since on changing 
.v1 → −v1,.V = v2 − v1 → v2 + v1 the distribution of. V does not change. Hence 
the compounded velocity of particles of two systems is also distributed according 
to Maxwell distribution. 
2. If two systems of particles move in the same vessel then their mean kinetic energy 
will become same. We summarize below key points of Maxwell’s derivation for 
historical reason though it is known to be erroneous. 
Let system I consist of molecules of mass .m1 and II those of mass .m2 having 
distribution of velocities described, respectively, by (3.11) and (3.18). Maxwell 
considered collision between a molecules of system I moving with velocity.v1 with 
a molecule of system II moving with velocity.v2 such that.v1 · v2 = 0. Denoting 
by.v,
1 and.v,
2 the particle velocities after collision, Maxwell proved that 
.m1⟨v,
1⟩
2 − m2⟨v,
2⟩
2 =
(m1 − m2
m1 + m2
)2
(
m1⟨v1⟩
2 − m2⟨v2⟩
2)
. (3.22) 
This shows that the quantity .m1⟨v1⟩2 − m2⟨v2⟩2 reduces after each collision by 
same factor and would become zero after a large number of collisions so that, 
after a large number of collisions, 
.m1⟨v1⟩
2 = m2⟨v2⟩
2
. (3.23) 
The equation above may be written in terms of average kinetic energy of the 
molecules by recalling (3.16):3.2 Maxwell Distribution 101
.
1
2
m1⟨v2
1 ⟩ =
1
2
m2⟨v2
2 ⟩. (3.24) 
This shows that two different kinds of molecules in a gas attain same kinetic energy 
after a large number of collisions. Same argument when extended to mixture of 
several different kinds of molecules would prove that all the molecules in the 
mixture acquire same average kinetic energy. 
The derivation outlined above considers the velocities of the colliding particles to 
be orthogonal and hence is not general. Secondly, if the role of the initial and final 
velocities is interchanged, the collision will result in increase in the difference 
in the kinetic energy of the particles. Hence Maxwell’s proof of the proposition 
that the difference in the kinetic energy of the colliding particles of two gases 
decreases is untenable. 
3. The formalism outlined above does not provide any link between Maxwell’s 
distribution and thermodynamics. That link is established by deriving equation 
of state using Maxwell’s distribution. The said derivation proceeds by showing 
that the pressure on the walls of the vessel of volume. V, assumed to be perfectly 
reflecting, containing uniformly distributed gas of.N molecules of mass. m is given 
by 
.P = mN
3V ⟨v2
⟩ =
2N
3V u, (3.25) 
where. u in the second equation is the average kinetic energy per molecule: 
.u = m
2 ⟨v2
⟩. (3.26) 
Deviating from the proof given by Maxwell, we derive the desired result in a 
simpler way as follows. Consider an area .ΔA on the wall of the vessel of vol￾ume.V containing.N molecules of a gas distributed homogeneously. Choose the 
coordinate system such that the said area is perpendicular to the.x-axis. The pres￾sure is the force per unit area in the direction perpendicular to the surface. In 
the present case, it is caused by the impact of the molecules moving in positive 
.x-direction. The number of molecules moving in the positive .x-direction and 
hitting .ΔA in time .Δt are those which are contained in the cylinder of length 
.v+xΔt with .ΔA as its base, where .v+x is the speed of a molecule in the posi￾tive.x-direction. The volume of the said cylinder is.ΔV = v+x (Δt)(ΔA) so that 
the number of molecules in it is.ΔV(N/V ) = v+x (Δt)(ΔA)(N/V). Now, each 
molecule strikes the wall with momentum.mv+x and, since the wall is assumed to 
be perfectly reflecting, it reflects back with same momentum so that.2mv+x is the 
change in momentum due to each molecular strike. Consequently, total change 
in momentum in time.Δt is.2mv2
+x (Δt)(ΔA)(N/V). Hence the force exerted on 
the area .ΔA is .Fx = 2mv2
+x (ΔA)(N/V ) so that average force on the wall per 
unit area, i.e. pressure is given by102 3 Kinetic Theory
.P = 2mN
V ⟨v2
+x ⟩. (3.27) 
We know that.⟨v2
x ⟩=⟨v2⟩/3 and.⟨v2
+x ⟩=⟨v2
x ⟩/2. On substituting these relations 
in (3.27) we get the desired result (3.25). 
Consider two gases at same temperature, pressure and having same volume, one 
consisting of.N1 molecules of mass.m1 and the other consisting of.N2 molecules 
of mass.m2. Using (3.25) it follows that in that case 
.m1N1⟨v2
1 ⟩ = m2N2⟨v2
2 ⟩. (3.28) 
If we invoke Avogadro’s hypothesis according to which equal volumes of gases 
at same temperature and pressure contain same number of molecules then in the 
equation above.N1 = N2 ≡ N so that 
.m1⟨v2
1 ⟩ = m2⟨v2
2 ⟩ ≡ m⟨v2
⟩. (3.29) 
This means that the kinetic energy per particle is same for all gases at same 
temperature and pressure. Hence, under assumed ideal conditions, all gases obey 
(3.25) with same. u. The said equation will be the same as the ideal gas law if 
.u = 3
2
kBT. (3.30) 
The relation above between the average kinetic energy per molecule and tempera￾ture for any ideal gas establishes the desired link between microscopic description 
of the gas with its thermodynamic one. 
If the velocity distribution is assumed to be described by Maxwell’s distribution 
(3.11) then we know that.⟨v2⟩is given by (3.15). On combining (3.15) with (3.30), 
the value of. A in Maxwell’s distribution formula turns out to be given by 
.A = m
2kBT . (3.31) 
The Maxwell distribution formula (3.11) then reads 
.F(v) =
( m
2πkBT
)3/2
exp{−mv2
/(2kBT )}. (3.32) 
This is the well-known form of Maxwell distribution. 
The relation (3.29) above has been arrived at as a consequence of Avogadro’s 
hypothesis applied to (3.28) arising due to equality of pressure of two kinds of 
molecules constituting a gas. The relation (3.29) is same as the relation (3.24) 
which according to Maxwell’s derivation is the result of a large number of colli￾sions. Maxwell assumed its validity and applied it to (3.28) to show that. N1 = N2
and thus claimed to prove Avogadro’s hypothesis. However, as we have remarked3.2 Maxwell Distribution 103
before, Maxwell’s derivation of (3.24) is erroneous and therefore his claim of 
proving Avogadro’s hypothesis does not stand. It is known that (3.29) cannot 
be established within the framework of the kinetic theory and therefore proof of 
Avogadro’s hypothesis cannot come from it (see [ 1]). 
Generalization of Maxwell’s concept of velocity distribution function to the phase 
space distribution function. Introduced next, and its evolution according to the laws 
of mechanics forms the basis of the kinetic theory. 
Exercises 
Ex. 3.1. Derive (3.21) from (3.20). Hint: Express .v + V in Cartesian components 
to write .(v + V)2 = (vx + Vx )2 + (vy + Vy )2 + (vz + Vz)2 and carry the 
integration in (3.20) using (H.7). 
Ex. 3.2. Show using (3.21) that the mean relative speed is the square root of the sum 
of the squares of the mean speeds of the two systems. 
Ex. 3.3. A molecule is moving with velocity. v in a gas of.N molecules described by 
Maxwell’s law. (1) Show that the number of molecules having speed in the 
interval.(w, w + dw) with respect to the moving molecule is 
. n(w)dw = Nw
v
/ A
π
[
exp{−A(v − w)2
} − exp{−A(v + w)2
}
]
dw.
(3.33) 
(2) Show that the integral of (3.33) over .w is . N, as it should be. This is 
one of Maxwell’s propositions in [ 2]. Hint: (1) The velocity of the molecule 
moving with velocity. w with respect to the molecule moving with velocity 
. v is.u = v − w. The number of molecules in the interval.(u, u + du) is 
.n(u)d3
u = N
( A
π
)3/2
exp(−Au · u)d3
u. (3.34) 
We have.u · u = v2 + w2 − 2vw cos(θ) where. θ is the angle between. v and 
.w and, since . v is fixed, .d3u = d3w = w2 sin(θ)dθdφdw. Integrate (3.34) 
over . θ and . φ to get the desired result. (2) The said integral can be carried 
by proving the identity 
.I =
{ ∞
0
x
(
exp{−α(x − a)
2
} − exp{α(x + a)
2
}
)
dx = a
/ π
α. (3.35) 
This can be proved by changing the variable of integration in the second 
integral in (3.35) to.y = −x and showing that 
.I =
{ ∞
−∞
x exp{−α(x − a)
2
}dx, (3.36)104 3 Kinetic Theory
from which follows the desired result on changing the variable . x of inte￾gration to.y = x − a. Interestingly, assuming the integral of (3.33) over . w
to be. N, Maxwell states whence the following mathematical result which is 
the one in (3.35). 
3.3 Phase Space Distribution Function 
The kinetic theory treats the gas as a collection of large number .N of molecules 
modeled as point particles moving under the influence of mutual interaction and 
possibly some external force. The walls of the container are assumed to be perfectly 
reflecting. In what follows we will assume the gas as consisting of molecules of 
same kind. The mechanical state of a molecule may be described by a point in the 
six-dimensional space formed by three components of its position and corresponding 
three components of its momentum as the axes, called single-particle phase space 
or .μ-space. We denote by .(ri, pi) the phase space coordinates of the .ith molecule. 
The volume element around the point.(ri, pi) in the said phase space will be denoted 
by 
.dμi = d3
rid3
pi . (3.37) 
The mechanical state of a molecule is described by a point in the .μ-space and the 
state of.N molecules is represented by.N points in it. 
Alternatively, the state of the system of.N molecules may be described as a point 
in the .6N-dimensional phase space, called the .Γ space, formed by .3N position 
components and.3N momentum components of.N molecules. We denote a point in 
the.Γ space by.{ri, pi}N : 
.{ri, pi}N ≡ (r1, r2,..., rN ; p1, p2,..., pN ), (3.38) 
where .ri denotes the position and .pi the momentum of the .ith (.i = 1, 2,..., N) 
molecule. The volume element around the point.{ri, pi}N will be denoted by 
.dτN = |
N
i=1
d3
rid3
pi ≡ |
N
i=1
dμi . (3.39) 
In what follows, unless stated otherwise, we will describe the state of the system in 
the.6N-dimensional.Γ space. 
As the molecules move under mutual and external forces, the point in the phase 
space traverses a trajectory. That trajectory can, in principle, be determined by solving 
coupled equations of motion for each of the .6N variables .({ri, pi}N ) if the inter￾molecular potential, the external forces, and the initial position and momenta of each 
molecule are known. Since .N for macroscopic systems is very large (.N ∼ 1020 or3.3 Phase Space Distribution Function 105
more), it is not possible to specify the initial position and momentum of each and 
every molecule and not possible to solve the equations even when the potentials are 
known. However, we have seen that the macroscopic properties are characterized in 
terms of a small number of thermodynamic variables. The knowledge of the position 
and momentum of each molecule is therefore unnecessary and appropriate small 
number of microscopic functions should be constructed instead to relate with the 
thermodynamic quantities. 
To that end, let us assume that no external force is applied on the gas so that the 
change of position of its representative point in the.Γ space and hence its change of 
state is caused only by collisions between molecules. The time between collisions 
is generally of the order of.10−8 sec., whereas the time scale of observation is much 
larger. We can then say that the observed value of a dynamical quantity is the average 
of that quantity over the positions and momenta of the molecules during the time of 
observation. 
To evaluate the said average, we consider all possible molecular states subject 
to the macroscopic conditions on the system. We call those states the admissible 
microstates. Let.N be the number of the said states. Since each state is represented 
by a point in the .Γ space, all the admissible microstates will be represented by . N
points. Let.dNi be the number of points in the volume element.dτN around. {ri, pi}N
so that .dNi /N stands for the probability that a state lies in .dτN at .{ri, pi}N . The 
probability of a point to be in.dτN around.{ri, pi}N per unit phase space volume, i.e. 
the probability density at.{ri, pi}N is.(1/N )(dNi /dτN ). We assume that the numbers 
. N ,.dNi are large enough to enable one to consider.dNi /N a continuous function of 
.{ri, pi}N and define, 
. fN ({ri, pi}N ;t) = 1
N
dNi
dτN
, (3.40) 
called the phase space probability distribution function or simply the distribution 
function. Due to the definition (3.40), the quantity 
.dw = fN ({ri, pi}N ;t) dτN (3.41) 
is same as the probability .dNi /N that a state lies in .dτN at .{ri, pi}N . Its defining 
relation (3.40) shows that. fN ({ri, pi}N ;t) obeys the desired normalization condition 
for a probability distribution: 
.
{
fN ({ri, pi}N ;t) dτN = 1, (3.42) 
where the integration is over the entire phase space. The number of states in.dτN at 
.{ri, pi}N is 
.dNi = N fN ({ri, pi}N ;t) dτN . (3.43)106 3 Kinetic Theory
The average of the function.A({ri, pi}N ) of coordinates and momenta of.N particles, 
denoted by.⟨A({ri, pi}N ;t)⟩, is given by 
.⟨A({ri, pi}N ;t)⟩ = {
A({ri, pi}N ) fN ({ri, pi}N ;t)dτN . (3.44) 
The thermodynamic properties are expressed in terms of the averages of suitably 
identified observables. 
The time evolution of. fN ({ri, pi}N ;t)is governed by Liouville’s equation derived 
next. 
3.3.1 Liouville’s Theorem 
Proved next, Liouville’s theorem states that 
.
d fN
dt = 0. (3.45) 
Equation (3.45) is called Liouville’s equation. For convenience we have suppressed 
and will keep doing so wherever there is no ambiguity, the argument of. fN . 
To prove (3.45), it is convenient to rewrite the position variables as . {qi}3N ≡
(q1, q2,..., q3N ) and corresponding momenta as.{pi}3N ≡ (p1, p2,...., p3N ). The 
sets.{qi} and.{pi) are canonically conjugate: 
.{qi, pj} = δi j, (3.46) 
where.{A, B} denotes the Poisson bracket of.A, B defined by 
.{A, B} = Σ
3N
i=1
[ ∂ A
∂qi
∂B
∂ pi
− ∂ A
∂ pi
∂B
∂qi
]
. (3.47) 
The distribution function in changed notation is written as 
. fN ({qi, pi}3N ;t) ≡ fN ({ri, pi}N ;t}), {qi, pi}n ≡ ({qi}n,{pi}n). (3.48) 
The phase space volume element in changed notation reads 
.dτN = |
3N
i=1
dqid pi . (3.49) 
We determine time evolution of. fN assuming that the molecular evolution is governed 
by the Hamiltonian.HN ≡ HN ({qi, pi}3N ).3.3 Phase Space Distribution Function 107
We know that the evolution of the position and the momentum under the action 
of.HN is governed by Hamilton’s equations 
.q˙i = ∂HN
∂ pi
, p˙i = −∂HN
∂qi
, (3.50) 
where “dot” on a symbol denotes derivative of that symbol with respect to time. 
Hence, in time. δt, the.{qi, pi} evolve to.{q,
i, p,
i} where 
.q,
i = qi + ˙qi δt, p,
i = pi + ˙pi δt. (3.51) 
As a consequence, all the points within the volume element.dτN at.{qi, pi}3N evolve 
to occupy the volume element .dτ ,
N at .{q,
i, p,
i}3N and . fN ({qi, pi};t) evolves to 
. fN ({q,
i, p,
i};t + δt). Since the number of points in a volume element is given by 
(3.43), the fact that there are same number of points in .dτN and .dτ ,
N leads to the 
relation 
. fN ({q,
i, p,
i}3N ;t + δt)dτ ,
N = fN ({qi, pi}3N ;t)dτN . (3.52) 
We will show that.dτ ,
N = dτN . To that end, recall the following results (see Ex. 3.4): 
(1) Under Hamiltonian evolution, canonically conjugate variables evolve to canoni￾cally conjugate variables, i.e. the time evolution is a canonical transformation and (2) 
the phase space volume element is invariant under canonical transformation. Since 
transformation .dτN → dτ ,
N is caused by Hamiltonian evolution, due to (1), it is a 
canonical transformation. Hence, being related by a canonical transformation, due 
to (2),.dτN = dτ ,
N . Consequently (3.52) reduces to 
. fN ({q,
i, p,
i}3N ;t + δt) = fN ({qi, pi}3N ;t). (3.53) 
Due to (3.51), the equation above implies 
.
Σ
3N
i=1
[
∂ fN
∂qi
q˙i +
∂ fN
∂ pi
p˙i
]
+
∂ fN
∂t = 0. (3.54) 
Since 
.
d fN
dt = Σ
3N
i=1
[
∂ fN
∂qi
q˙i +
∂ fN
∂ pi
p˙i
]
+
∂ fN
∂t , (3.55) 
(3.54) is same as the form (3.45) of Liouville’s equation. 
Using Hamilton’s equations (3.50), (3.54) can be rewritten as108 3 Kinetic Theory
.
∂ fN
∂t = Σ
3N
i=1
[
∂HN
∂qi
∂ fN
∂ pi
− ∂HN
∂ pi
∂ fN
∂qi
]
≡ {HN , fN }. (3.56) 
Equation (3.56) is another form of Liouville’s theorem. In terms of .{ri, pi}, (3.56) 
assumes the form 
.
∂ fN
∂t = Σ
N
i=1
(
∇ri HN · ∇pi fN − ∇pi HN · ∇ri fN
)
, (3.57) 
where 
. ∇ri A = ∂ A
∂xi
ex +
∂ A
∂yi
ey +
∂ A
∂zi
ez,
∇pi A = ∂ A
∂ pxi
ex +
∂ A
∂ pyi
ey +
∂ A
∂ pzi
ez, (3.58) 
the.ex , ey , ez being unit Cartesian vectors. 
The Liouville equation determines time evolution of the distribution function of 
all particles. However, several physical properties are determined in terms of reduced 
distribution functions introduced next. 
3.3.2 Reduced Distribution Functions 
The distribution function. fN ({ri, pi}N ;t) is the probability that.N molecules are in 
the vicinity of the point .{ri, pi}N in the phase space. However, we will see that for 
the study of thermodynamic properties we need to know the probability distribution 
function of a small number of particles called reduced distribution functions. 
Consider the question: what is the probability density for the.kth molecule to be in 
the vicinity of.(r, p) in phase space irrespective of the phase space position of other 
molecules? It is evidently given by integrating over the phase space coordinates of 
all the molecules while keeping that of the.kth one fixed at.(r, p): 
. ˜f1k (r, p;t) = ⟨δ(3)
(rk − r)δ(3)
(pk − p)⟩, (3.59) 
where average is over. fN ({ri, pi}N ;t) so that 
. ˜f1k (r, p;t) =
{
fN ({ri, pi}N ;t)δ(3)
(rk − r)δ(3)
(pk − p)
|
N
i=1
dμi
=
{
fN ({ri, pi}N ;t)
|
N
i/=k
dμi, (rk , pk ) = (r, p). (3.60)3.3 Phase Space Distribution Function 109
Since the molecules are identical and the system is assumed to be homogeneous, 
. fN ({ri, pi}N ;t) is symmetric under the exchange of molecules. Consequently the 
average in (3.60) is independent of the label. k identifying the molecule, and can be 
rewritten in the following form taking.k = 1, 
. ˜f1(r1, p1;t) =
{
fN ({ri, pi};t)
|
N
i=2
dμi . (3.61) 
Because of the normalization condition (3.42) on. fN , it follows that 
.
{
˜f1(r, p;t) d3
rd3
p = 1. (3.62) 
The function. ˜f1(r, p;t) defined in (3.59) is the probability density for finding the. kth
molecule, i.e. a particular molecule in the vicinity of.(r, p). The probability density 
for any of the .N molecule to be in the vicinity of .(r, p) is obtained by summing 
(3.59) over all. k: 
. f1(r, p;t) = Σ
N
k=1
❬
δ(3)
(rk − r)δ(3)
(pk − p)
❭
. (3.63) 
Hence 
. f1(r, p;t) = N ˜f1(r, p;t). (3.64) 
Due to (3.62) the normalization condition on. f1(r, p;t) is 
.
{
f1(r, p;t) d3
rd3
p = N. (3.65) 
The function. f1(r, p;t)is called reduced one-particle distribution function or simply 
one-particle distribution function. Evidently, the average number of molecules in the 
volume element.d3rd3p is 
.dn(r, p) = f1(r, p;t)d3
rd3
p. (3.66) 
We will see the usefulness of . f1(r, p;t) in evaluating averages of single molecule 
observables. 
We know that the distribution function. fN ({ri, pi}N ;t) determines, by means of 
(3.44), the average of any function.A({ri, pi}N ) of phase space coordinates. However, 
several physical properties of interest are averages of functions which depend on the 
phase space coordinates of single molecule. For example, the kinetic energy. p2
k /2m
of the.kth molecule. It is a function only of the momentum of the.kth molecule. The110 3 Kinetic Theory
average of the function.A1(rk , pk ) of the phase space coordinates of the.kth molecule 
may be evaluated as follows: 
. ⟨A1(rk , pk ;t)⟩ = {
A1(rk , pk ) fN ({ri, pi}N ;t)
|
N
i=1
dμi
=
{
A1(rk , pk )
⎡
⎣
{
fN ({ri, pi}N ;t)
|
N
i/=k
dμi
⎤
⎦ dμk
=
{
A1(rk , pk ) ˜f1(rk , pk ;t)dμk , (3.67) 
where . ˜f1(r, p;t) is as in (3.61). Hence the average of the sum of.A1(rk , pk ) over. k
is given by 
.
Σ
N
k=1
⟨A1(rk , pk ;t)⟩ = N⟨A1(r, p;t)⟩ = {
A1(r, p) f1(r, p;t) d3
rd3
p, (3.68) 
where. f1(r, p;t) is as in (3.64). 
Similarly, to evaluate the average of the function.A2(r j, rk , pj, pk ) dependent on 
the phase space coordinates of two molecules, we define joint probability of finding 
. jth molecule in the vicinity of .(r, p) and simultaneously the .kth molecule in the 
vicinity of.(r,
, p,
): 
. ˜f2 jk (r, r,
, p, p,
;t)
= Σ
N
j/=k=1
Σ
N
k=1
❬
δ(3)
(r j − r)δ(3)
(rk − r,
)δ(3)
(pj − p)δ(3)
(pk − p,
)
❭
, (3.69) 
where the average is with respect to . fN ({ri, pi}N ;t). Due to symmetry of 
. fN ({ri, pi}N ;t) under exchange of molecules,. ˜f2 jk is independent of. j, k. We there￾fore let. j = 1,.k = 2 to rewrite (3.69) as 
. ˜f2(r1, r2, p1, p2;t) =
{
fN ({ri, pi}N ;t)
|
N
i=3
dμi . (3.70) 
The average of.A2(r j, rk , pj, pk ) is given by 
.
❬
A2(r j, rk , pj, pk ;t)
❭
=
{
A2(r j, rk , pj, pk ) fN ({ri, pi}N ;t)
|
N
i=1
dμi3.3 Phase Space Distribution Function 111
=
{
A2(r j , rk , pj , pk )
⎡
⎣ fN ({ri , pi}N ;t)
|
N
i/= j,k 
dμi 
⎤
⎦ dμj dμk 
=
{
A2(r j , rk , pj , pk ) ˜f2(r j , rk , pj , pk ;t)dμj dμk , (3.71) 
where 
. ˜f2(r j, rk , pj, pk ;t) =
{
fN ({ri, pi}N ;t)
|
N
i/= j,k
dμi . (3.72) 
It then follows that 
. Σ
N
j/=k=1
Σ
N
k=1
⟨A2(r j, rk , pj, pk ;t)⟩ = N(N − 1)⟨A2(r1, r2, p1, p2;t)⟩
=
{
A2(r1, r2, p1, p2) f2(r1, r2, p1, p2;t)dμ1dμ2, (3.73) 
where.N(N − 1) is the result of the sum over. j /= k. That sum being the number of 
pairs of different indices. j, k that can be chosen from the set of.N numbers and 
. f2(r1, r2, p1, p2;t) = N(N − 1) ˜f2(r1, r2, p1, p2;t) (3.74) 
is called reduced two-particle distribution function or simply two-particle distribu￾tion function, or two-particle correlation function. 
In general, due to symmetry of. fN under the exchange of molecules, the average 
of a function of . s distinct phase space points, .As(ri1 ,... ris , .pi1 ,... pis ) (. i1 /= i2 /=
... /= is) is independent of the labels.i1,...,is so that 
. ˜fs(ri1 ,..., ris , pi1 ,..., pis ;t) ≡ ˜fs({ri, pi}s;t)
=
{
fN ({ri, pi}N ;t)
|
N
i=s+1
dμi . (3.75) 
As a consequence of this, we have 
. ❬
As(ri1 ,... ris , pi1 ,... pis ;t)
❭
=
{
As({ri, pi}s) ˜fs({ri, pi}s;t)
|s
i=1
dμi
≡ ⟨As({ri, pi}s;t)⟩. (3.76)112 3 Kinetic Theory
This leads to 
. Σ
N
i1/=i2/=.../=is=1
❬
As(ri1 ,... ris , pi1 ,... pis )
❭
= N!
(N − s)!
⟨As({ri, pi}s;t)⟩
=
{
As({ri, pi}s) fs({ri, pi}s;t)
|s
i=1
dμi, (3.77) 
where.N!/(N − s)! is the result of the sum over.i1 /= i2 /= ... /= is. That sum being 
the number of ways of choosing. s different numbers.i1,i2,...,is from the set of. N
numbers and 
. fs({ri, pi}s;t) = N!
(N − s)!
˜fs({ri, pi}s;t) (3.78) 
is called reduced s-particle distribution function or simply s-particle distribution 
function or s-particle correlation function. It stands for the probability density of 
finding . s molecules, one each in the vicinity of .(ri1 , pi1 ), .(ri2 , pi2 ), . . ., .(ris , pis ), 
irrespective of the phase space position of the remaining molecules. 
The task of the kinetic theory is to determine . fs({ri, pi}s;t) by constructing 
and solving the equation obeyed by it. We will see that several thermodynamic 
quantities can be expressed as averages involving one-particle distribution function 
. f1(r, p;t). By working in the single-particle six-dimensional phase space, we first 
outline the method to derive under certain approximations a closed-form equation for 
. f1(r, p;t), the so-called Boltzmann equation. We then work in the.N-particle phase 
space and derive a hierarchy of equations, known as the BBGKY hierarchy, which 
is an integro-differential equation determining time evolution of . fs({ri, pi}s;t) in 
terms of. fs+1({ri, pi}s+1;t), followed by its reduction to the Boltzmann equation. 
Exercises 
Ex. 3.4. Show that the phase space volume element is invariant under a canonical 
transformation. Hint: Let the system be described by . n generalized coor￾dinates .{qi}n ≡ (q1, q2,..., qn) and momenta .{pi}n ≡ (p1, p2,..., pn). 
Let . ˜
ξ be the column constituted by .2n elements .ξm = qm, .ξm+n = pm, 
.m = 1, 2,..., n. Consider the transformation to a new set of coordinates 
and momenta.({Qi}n,{Pi}n) defined by invertible relations 
.Qi = Qi({qi},{pi}, t), Pi = Pi({qi},{pi}, t). (3.79) 
Let . η˜ be the column having .2n elements .ηm = Qm, .ηm+n = Pm, . m =
1, 2,..., n. The transformation (3.79) may then be written as3.3 Phase Space Distribution Function 113
.ηi = ηi({ξi}), i = 1, 2,..., 2n. (3.80) 
Let.Mˆ denote the.2n × 2n matrix formed by.Mi j as its elements: 
.Mi j = ∂ηi
∂ξ j
. (3.81) 
It is known that the transformation (3.79) will be canonical if the following 
condition holds: 
.Mˆ JˆMˆ T = Mˆ T JˆMˆ = Jˆ, (3.82) 
where.MT is the transpose of.Mˆ and. Jˆ is the.2n × 2n anti-symmetric matrix 
defined by 
.Jˆ =
( Oˆ n ˆIn
− ˆIn Oˆ n
)
, (3.83) 
with.Oˆ n denoting.n × n null matrix and. ˆIn the.n × n identity matrix. 
The volume element.dτ in the phase space constituted by. {ξi} ≡ ({qi},{pi})
is 
.dτ = |n
i=1
dqid pi . ≡ |
2n
i=1
dξi . (3.84) 
Under the transformation (3.80),.dτ →.dτ , where 
.dτ , = |n
i=1
dQidPi . ≡ |
2n
i=1
dηi = J dΓ , (3.85) 
the.J being the Jacobian of transformation: 
.J = |
|det(Mˆ )
|
|, (3.86) 
and.Mˆ is as in (3.81). The determinant of (3.82) is 
.{det(Mˆ )}
2
det(Jˆ) = det(Jˆ). (3.87) 
Since .det(Jˆ) /= 0, it follows that .
|
|det(Mˆ )
|
| = 1. Hence the desired result: 
.dτ , = dτ .114 3 Kinetic Theory
Ex. 3.5. Show that the time evolution governed by Hamiltonian is a canonical trans￾formation. Hint: This may be proved by invoking the property of invariance 
of Poisson bracket under canonical transformation. Using Hamilton’s equa￾tions written in terms of the Poisson bracket (.q˙ = {q, H}, .p˙ = {p, H}), 
we have 
.q(t + δt) = q(t) + {q, H}δt, p(t + δt) = p(t) + {p, H}δt. (3.88) 
From the equations above it follows that 
. {q(t + δt), p(t + δt)}
= {q(t), p(t)} + [{q, {p, H}} + {{q, H}, p}] δt. (3.89) 
The term multiplying.δt in the equation above may be rewritten as 
.{q, {p, H}} + {{q, H}, p}={q, {p, H}} + {p, {H, q}}. (3.90) 
Invoking Jacobi’s identity: 
.{A, {B, C}} + {C, {A, B}} + {B, {C, A}} = 0, (3.91) 
we have 
.{q, {p, H}} + {H, {q, p}} + {p, {H, q}} = 0, (3.92) 
which on combining with (3.90) yields 
.{q, {p, H}} + {{q, H}, p} = −{H, {q, p}} = 0, (3.93) 
where last equation is due to the fact that.{q, p} = 1. Substitution of (3.93) 
in (3.89) gives 
.{q(t + δt), p(t + δt)}={q(t), p(t)} = 1. (3.94) 
Thus the Poisson bracket between position and momentum at time . t + δt
is same as that at time . t, i.e. the Poisson bracket is invariant under time 
evolution. This establishes the desired result, namely, the time evolution 
governed by Hamiltonian is a canonical transformation.3.4 Boltzmann Equation: Single-Particle Phase Space Approach 115
3.4 Boltzmann Equation: Single-Particle Phase Space 
Approach 
Consider the single-particle six-dimensional phase space. The state of motion of each 
molecule is described by a point in this space and that of.N molecules by.N points. 
To begin with, we consider the gas of non-interacting molecules. The molecules 
may, however, be acted upon by external potential.U(r). The Hamiltonian governing 
the evolution of the system is then given by 
.HN ({ri, pi}N ) ≡ Σ
N
i=1
h(ri, pi), h(ri, pi) = 1
2m p2
i + U(ri). (3.95) 
Under.HN , each particle evolves independent of the other. Starting from Liouville’s 
equation, we have shown in Sect. 3.6 that the one-particle distribution function obeys 
the equation 
.
∂ f1(r, p;t)
∂t
= ∇rh · ∇p f1 − ∇ph · ∇r f1 ≡ {
h(r, p), f1(r, p;t)
}
. (3.96) 
This determines time evolution of. f1(r, p;t) when there is no inter-molecular inter￾action. 
The inter-molecular interaction in the present formalism is included assuming that 
it causes scattering of molecules. The theory based on actual form of inter-molecular 
interaction will be outlined in Sect. 3.6. Due to scattering, the molecules may enter 
or leave a phase space volume element. The number of molecules in a phase space 
volume element then will no longer be constant and .d f1/dt will no longer be zero. 
The effect of inter-molecular interaction may therefore be accounted for by including 
in.d f1/dt the contribution from scattering and rewriting it as 
.
d f1(r, p;t)
dt =
(∂ f1(r, p;t)
∂t
)
coll
. (3.97) 
Consequently, due to collisions, (3.96) changes to 
.
∂ f1
∂t − {
h(r, p), f1(r, p;t)
}
=
(∂ f1(r, p;t)
∂t
)
coll
. (3.98) 
The Poisson bracket term, which describes evolution of non-interacting molecules 
in the equation above, is called the streaming term. 
The collision term may be evaluated if the gas is sufficiently dilute to enable one 
to treat collisions only as binary. Assuming that to be the case, consider collision 
between a molecule of momentum .p, and another of momentum . p,
1, both in the 
vicinity of . r. Let their momenta after scattering be . p and . p1, respectively. Assume116 3 Kinetic Theory
the collision to be elastic so that total momentum and kinetic energy of the molecules 
before and after scattering is same: 
.p + p1 = p, + p,
1, p2 + p2
1 = p,2 + p,2
1 . (3.99) 
We denote this scattering process by.(p,
, p,
1) →.(p, p1) and its reverse by. (p, p1) →
.(p,
, p,
1). 
Knowing the inter-molecular force, one can in principle evaluate using the micro￾scopic theory the rate of transition.W(p, p1|p,
, p,
1) of the process.(p,
, p,
1) →.(p, p1). 
Our interest is in determining in terms of the said transition rate, the rate at which 
the number of molecules of given momenta change due to scattering. To that end, 
note that the number of pairs of molecules in the vicinity of . r, one of which 
has momentum in the vicinity of .p, and another has that in the vicinity of . p,
1, is 
.F(r, p,
, p,
1;t)d3p,
d3p,
1 where .F(r, p,
, p,
1;t) ≡. f2(r, r, p,
, p,
1;t). Hence the rate at 
which the process .(p,
, p,
1) →.(p, p1) generates a molecule in the vicinity of . p and 
another in the vicinity of.p1 is 
. R+(p, p1)d3
p,
d3
p,
1d3
pd3
p1
= W(p, p1|p,
, p,
1)F(r, p,
, p,
1;t)δ(4)
(P − P,
)d3
p,
d3
p,
1d3
pd3
p1, (3.100) 
where, with.P = p + p1,.E = (p2 + p2
1)/2m, the delta-function 
.δ(4)
(P − P,
) ≡ δ(3)
(P − P,
)δ(E − E,
) (3.101) 
restricts the values of the momenta only to those which are allowed by the conserva￾tion conditions (3.99). Hence the rate at which the molecules emerge with momentum 
in the vicinity of. p is 
.
(∂ f1(r, p;t)
∂t
)
+
=
{
R+(p, p1)d3
p,
d3
p,
1d3
p1. (3.102) 
Similarly, the rate of the reverse scattering.(p, p1) →.(p,
, p,
1) is 
. R−(p, p1)d3
p,
d3
p,
1d3
pd3
p1
= W(p,
, p,
1|p, p1)F(r, p, p1;t)δ(4)
(P, − P)d3
p,
d3
p,
1d3
pd3
p1, (3.103) 
so that the rate at which molecules having momentum in the vicinity of. p are lost is 
.
(∂ f1(r, p;t)
∂t
)
−
=
{
R−(p, p1)d3
p,
d3
p,
1d3
p1. (3.104) 
Net rate of change of the number of molecules having momentum in the vicinity of 
. p due to collisions therefore is3.4 Boltzmann Equation: Single-Particle Phase Space Approach 117
.
(∂ f1(r, p;t)
∂t
)
coll
=
(∂ f1(r, p;t)
∂t
)
+
−
(∂ f1(r, p;t)
∂t
)
−
. (3.105) 
It is known that, due to time-reversal symmetry, 
.W(p,
, p,
1|p, p1) = W(p, p1|p,
, p,
1). (3.106) 
Substitution of (3.102) and (3.104) in (3.105), along with the use of (3.106), yields 
the collision integral, 
. (∂ f1(r, p;t)
∂t
)
coll
=
{ [(F(r, p,
, p,
1;t) − F(r, p, p1;t)
)
×W(p, p1|p,
, p,
1)δ(4)
(P − P,
)
]
d3
p,
d3
p,
1d3
p1.
(3.107) 
The expression above is exact for a sufficiently dilute gas. However, it is not useful as 
it stands because it has in it the unknown function.F(r, p, p1;t) which characterizes 
correlation between the momenta of two molecules. 
To get a closed-form equation, Boltzmann approximated the correlation function 
.F(r, p, p1;t) by the product of single-particle distribution functions: 
.F(r, p, p1;t) ≈ f1(r, p;t) f1(r, p1;t). (3.108) 
This is called the assumption of molecular chaos. Equation (3.107) then reads 
. (∂ f1(r, p;t)
∂t
)
coll
=
{ [( f1(p,
) f1(p,
1) − f1(p) f1(p1)
)
× W(p, p1|p,
, p,
1)δ(4)
(P − P,
)
]
d3
p,
d3
p,
1d3
p1,
(3.109) 
where for ease of writing we have suppressed . r and . t in the argument of . f1 under 
the integral above and written. f1(p) ≡ f1(r, p;t). On substituting (3.109) in (3.98) 
we obtain closed-form equation for. f1(p): 
. 
∂ f1
∂t − {
h(r, p), f1(p)
}
=
{ [( f1(p,
) f1(p,
1) − f1(p) f1(p1)
)
× W(p, p1|p,
, p,
1)δ(4)
(P − P,
)
]
d3
p,
d3
p,
1d3
p1. (3.110) 
The non-linear integro-differential (3.110) is called the Boltzmann transport equation 
or simply the Boltzmann equation. A useful way of writing the scattering integral118 3 Kinetic Theory
(3.109) is to express the transition rate in terms of the scattering cross section. Using 
the said relation, derived in (3.125), (3.110) assumes the form 
. 
∂ f1
∂t
+ p
m · ∇r f1 − ∇rU(r) · ∇p f1
= 1
m
{
|p − p1|
(
f1(p,
) f1(p,
1) − f1(p) f1(p1)
) dσ
dΩ
dΩd3
p1, (3.111) 
where .dσ/dΩ is the differential scattering cross section. Note that .(p,
, p,
1) in the 
equation above are determined in terms of .(p, p1) by conservation of energy and 
momentum. 
In Sect. 3.6, we will derive (3.111) making explicit use of inter-particle potential. 
To that end, we recall first some relevant elements of the theory of elastic scattering. 
3.5 Scattering 
Consider elastic collision between two particles, one initially stationary at the origin 
of the coordinate system, called the target, and the other moving toward it, starting far 
away from it with velocity. v. Assuming the interaction to vanish at large separation 
between the particles, the trajectory of the incident particle shall be straight line in 
the direction of . v when it is far away from the target. Let us take the line drawn 
parallel to. v and passing through the target as the.z-axis and the direction of. v as the 
positive .z-direction (see Fig. 3.1). Choose two directions orthogonal to each other 
and to the .z-direction as the other two coordinate axes, . x and . y, of the Cartesian 
system. We denote the distance of the incoming particle from the .z-axis when it is 
far away from the target, called the impact parameter, by. b. It is the closest distance 
between the incident particle and the target in the absence of interaction between 
them. Draw a circle of radius . b passing through the particle with the center of the 
circle on the.z-axis and its plane perpendicular to it. The azimuthal angle. φ that the 
line joining the particle with the center of the circle makes with the .x-axis denotes 
the particle position on the circle. 
Fig. 3.1 Schematic 
depiction of scattering 
O3.5 Scattering 119
The asymptotic position of the incident particle before it comes close to the target 
is specified by the impact parameter. b and the azimuthal angle. φ. 
Due to its interaction with the target, the trajectory of the incident particle deflects 
and the particle scattered as it approaches the target. Since we are assuming no 
interaction when the separation between the particles is large, asymptotic trajectory 
of the scattered particle is a straight line. The asymptotic position of the scattered 
particle is described by the angles .(θ, φ) where . θ is the angle that the asymptotic 
trajectory of the scattered particle makes with the.z-axis and. φ is its azimuthal angle, 
same as the incident azimuthal angle if the potential is central which is assumed to 
be the case. The asymptotic position of the particle after scattering is related with its 
asymptotic position before scattering and its energy. Knowing the potential, . (θ, φ)
can be calculated using the equations of motion. 
Consider now the situation wherein, not one, but a stream of particles, all having 
initial velocity . v, is incident on a stationary target. The flux . I of particles, defined 
as the number of particles passing per unit time per unit area perpendicular to its 
direction of propagation, is evidently 
.I = |v|ninc(r, v), (3.112) 
where.ninc(r, v) is number of particles per unit volume in the incident beam. 
Consider circles of radii . b and .b + db with their planes perpendicular to the .z￾axis and their common center on that axis. Consider the region between those circles 
bound by the parts of the radii whose azimuthal angles are . φ and .φ + dφ. The area 
.dσ(b, φ) of the said region evidently is 
.dσ(b, φ) = b db dφ, (3.113) 
and the number of particles crossing it per unit time is.I dσ(b, φ). All those particles 
are scattered within the solid angle.dΩ(θ, φ) at.(θ, φ) where 
.dΩ(θ, φ) = sin(θ)dθdφ. (3.114) 
Let the number of particles scattered per unit time per unit solid angle surrounding 
.(θ, φ), called the scattered flux, be.Ns(θ, φ) so that the number of particles scattered 
into .dΩ(θ, φ) is .Ns(θ, φ)dΩ(θ, φ). Since the particles scattered into .dΩ are those 
which were in the area.dσ(b, φ) in the incident beam, we must have 
.Ns(θ, φ)dΩ(θ, φ) = I dσ(b, φ). (3.115) 
The ratio.Ns(θ, φ)/I of the scattered flux to the incident flux. I is called the differen￾tial scattering cross section or simply the differential cross section. The expression 
(3.115) shows that 
.
Ns(θ, φ)
I = dσ
dΩ . (3.116)120 3 Kinetic Theory
The differential cross section is thus given by.dσ/dΩ. It has the units of area. 
We can also define total scattering cross section.σT: 
.σT =
{ dσ
dΩ
dΩ. (3.117) 
It has the units of area. 
We can generalize the considerations above to the case of the target not initially 
stationary but moving initially with velocity. v1. That end is achieved easily by work￾ing in the rest frame of the target. The expression (3.112) for the incident flux then 
gets changed to 
.I = |v − v1|ninc(r, v). (3.118) 
Hence, invoking (3.115) with . I given by (3.118), the number of particles scattered 
from.dσ into.dΩ is 
.Ns(θ, φ)dΩ = |v − v1|ninc(r, v)dσ. (3.119) 
The results above may be generalized to the case of incident particles having distri￾bution of velocities described by the phase space distribution function. f1(r, p;t) so 
that.ninc(r, v) =. f1(r, p;t)d3p yielding 
.I = |v − v1| f1(r, p;t)d3
p, (3.120) 
and 
.Ns(θ, φ)dΩ = |v − v1| f1(r, p;t)d3
pdσ. (3.121) 
Next, consider a dilute gas having a distribution of molecular velocities. The gas 
is assumed sufficiently dilute so that only binary collisions are important. Consider 
collisions between molecules of velocity . v and . v1. The (3.121) gives the rate of 
scattering of molecules of velocity.v = p/m in the vicinity of. r into.dΩ if there is a 
molecule with velocity.v1 also in the vicinity of. r. In the present case, the probability 
that a molecule in the vicinity of . r has velocity in the vicinity of .v1 = p1/m is 
. f1(r, p1;t)d3rd3p. Hence the rate of scattering into.dΩ in the present case is given 
by multiplying (3.121) by the said probability: 
.Ns(θ, φ)dΩ = |v − v1| f1(r, p;t) f1(r, p1;t)d3
rd3
pd3
p1dσ. (3.122) 
The assumption that the distribution of the velocities of the target and the inci￾dent particles is independent is inherent in the derivation of the expression above 
and is behind the product form . f1(r, p;t) f1(r, p1;t) of the distribution functions. 
However, the two velocities need not be distributed independently. To account for 
that possibility, replace . f1(r, p;t) f1(r, p1;t) by two-particle distribution function3.5 Scattering 121
. f2(r, r, p, p1;t) ≡.F(r, p, p1;t) to rewrite (3.122) as 
.Ns(θ, φ)dΩ = |v − v1|F(r, p, p1;t)d3
rd3
pd3
p1dσ. (3.123) 
Now, if the molecules of momenta in the vicinities of . p and .p1 collide and emerge 
as having momenta in the vicinities of.p, and.p,
1 then, in terms of the transition rate, 
the number of molecule in the vicinities of.p, and.p,
1 is 
. Ns(θ, φ)dΩ = W(p,
, p,
1|p, p1)F(r, p, p1;t)δ(4)
(P − P,
)
×d3
rd3
pd3
p1d3
p,
d3
p,
1. (3.124) 
On equating (3.123) and (3.124) follows the relation, 
.|v − v1|
dσ
dΩ
dΩ = W(p,
, p,
1|p, p1)δ(4)
(P − P,
)d3
p,
d3
p,
1, (3.125) 
relating transition rate with the scattering cross section. 
We derive next the Boltzmann equation working in.N-particles phase space. 
Exercises 
Ex. 3.6. Let a particle of mass .m1 moving with velocity .v1 collide elastically with 
another one of mass .m2 moving with velocity . v2. Show that their relative 
velocity before and after collision has same magnitude. In other words, the 
relative velocity in binary collision is rotated without change in its magni￾tude. Since relative velocity and relative momentum are proportional to each 
other when .m1 = m2, we say that, the relative momentum of equal mass 
particles gets rotated without change in its magnitude in elastic collision. 
Hint: Let .R = (m1r1 + m2r2)/M (.M = m1 + m2) denote the position of 
the center of mass of the particles and.r = r1 − r2 their relative position so 
that 
.r1 = R + m2
M
r, r2 = R − m1
M
r. (3.126) 
Total momentum and kinetic energy before collision are given by 
.P = m1r˙1 + m2r˙2 ≡ MR˙ , T = 1
2M
P2 + μ
2
v˙ 2
, (3.127) 
where.μ = m1m2/M is the reduced mass and.v = r˙1 − r˙2 is relative veloc￾ity. The kinetic energy after collision is given by 
.T , = 1
2M
P,2 + μ
2
v˙,2
. (3.128)122 3 Kinetic Theory
Since momentum and kinetic energy remain constant in elastic collision, 
(the prime on a symbol stands for its value after collision), 
.P, = P, T , = T, (3.129) 
it follows that 
.v2 = v,2
. (3.130) 
Hence the desired result. 
3.6 BBGKY Hierarchy 
Starting from Liouville’s equation for the phase space evolution of the distribution 
function . fN ({ri, pi}N ;t) of all .N molecules, in this section, we derive equation 
governing the evolution of.s-particle distribution function. fs({ri, pi}s;t). We will see 
that the evolution equation for. fs is coupled with. fs+1. We will use the hierarchy of the 
said equations to derive the Boltzmann equation under appropriate approximations. 
To that end, we consider to begin with the gas of non-interacting molecules. The 
molecules may, however, be acted upon by an external force. The Hamiltonian . HN
governing the evolution of the system is then given by (3.95). Substitute .HN given 
therein in Liouville’s equation (3.56) and integrate over all .ri, pi , excluding .i = 1, 
to get 
.
∂ ˜f1(r1, p1;t)
∂t = Σ
N
i=1
{
{h(ri, pi), fN }
|
k/=1
dμk . (3.131) 
Consider the.i = 1 term in the equation above. It involves the Poisson bracket, 
. {h(r1, p1), fN }
=
[
∇r1 h(r1, p1) · ∇p1 fN − ∇p1 h(r1, p1) · ∇r1 fN
]
. (3.132) 
Since . h in the equation above and the derivatives therein are independent of the 
variables of integration, we can shift the integration entirely on the function . fN as 
that is the only function in the integrand in (3.131) depending on the variables of 
integration to obtain 
. {
{h(r1, p1), fN }
|
k/=1
dμk =
{
h(r1, p1), {
fN
|
k/=1
dμk
}
= {h(r1, p1), ˜f1(r1, p1)}. (3.133)3.6 BBGKY Hierarchy 123
Consider now a term in (3.131) for.i /= 1: 
. {
{h(ri, pi), fN }
|
k/=1
dμk
=
{ [
∇ri h · ∇pi fN − ∇pi h · ∇ri fN
]
dμi
|
k/=1,i
dμk . (3.134) 
Invoking the identity 
.
{
V
F · ∇ψ dV =
{
S
ψF · n dS −
{
V
ψ∇ · F dV, (3.135) 
where. S is the surface enclosing the volume.V and. n is the unit vector normal to the 
surface element .dS. Application of (3.135) to the integration over the momentum 
space volume in the first term in (3.134) gives 
. {
∇ri h · ∇pi fN d3
pi
=
{
S
fN∇ri h · n dS −
{
fN∇pi · ∇ri h d3
pi . (3.136) 
Since integration is over entire phase space, the surface. S is at infinity and hence the 
value of. fN in the first term in (3.136) is for.pi at infinity. The contribution from the 
surface integral in (3.136) will be zero if it is assumed that. fN → 0 when.|pi|→∞. 
Consequently (3.136) reduces to 
.
{
∇ri h · ∇pi fN d3
pi = − {
fN∇pi · ∇ri h d3
pi . (3.137) 
Evaluating the second term on the right-hand side in (3.134) in similar way by 
assuming. fN → 0 as.|ri|→∞, we get 
.
{
∇pi h · ∇ri fN d3
ri = − {
fN∇ri · ∇pi h d3
ri . (3.138) 
The right sides of (3.137) and (3.138) are same. Hence, on substituting (3.137) and 
(3.138) in (3.134) it follows that 
.
{
{h(ri, pi), fN }
|
k/=1
dμk = 0, i /= 1. (3.139) 
Substitute (3.133) and (3.139) in (3.131) to get124 3 Kinetic Theory
.
∂ ˜f1(r, p)
∂t = {h(r, p), ˜f1(r, p)}. (3.140) 
Multiply the equation above by.N and use (3.64) to transform it to the equation for 
. f1(r, p;t): 
.
∂ f1(r, p;t)
∂t − {h(r, p), f1(r, p;t)} = 0. (3.141) 
This is the equation for computing single-particle distribution function in the absence 
of mutual interaction between molecules. 
We can similarly derive the equation for. fs corresponding to.HN given by (3.95) 
by integrating Liouville’s (3.56) over.ri, pi for.i = s + 1,s + 2,..., N to get 
.
∂ ˜fs({ri, pi}s;t)
∂t = Σ
N
i=1
{
{h(ri, pi), fN }
|
k≥s+1
dμk . (3.142) 
Consider the Poisson bracket for an.i ≤ s term in the equation above: 
. {h(ri, pi), fN }
=
[
∇ri h(ri, pi) · ∇pi fN − ∇pi h(ri, pi) · ∇ri fN
]
, i ≤ s. (3.143) 
Since. h in the equation above and the derivatives are independent of the variables of 
integration, we can write 
. {
{h(ri, pi), fN }
|
k≥s+1
dμk
=
{
h(ri, pi), {
fN
|
k≥s+1
dμk
}
= {h(ri, pi), ˜fs({ri, pi}s;t)}, i ≤ s. (3.144) 
Consider next the Poisson bracket for an .i ≥ s + 1 term in (3.142). Following the 
steps leading to (3.139), it is straightforward to show that the contribution due to 
such terms vanishes: 
.
{
{h(ri, pi), fN }
|
k≥s+1
dμk = 0, i ≥ s + 1. (3.145) 
Substitute (3.144) and (3.145) in (3.142) to get the following equation for. ˜fs: 
.
∂ ˜fs({ri, pi}s;t)
∂t = Σs
i=1
{h(ri, pi), ˜fs}. (3.146)3.6 BBGKY Hierarchy 125
Multiply the equation above by .N!/(N − s)! and use (3.78) to transform it to the 
equation for. fs: 
.
∂ fs({ri, pi}s;t)
∂t = Σs
i=1
{h(ri, pi), fs}. (3.147) 
This is the closed-form equation for the s-particle distribution function in the absence 
of interaction between the molecules. 
Next let us assume that the molecules interact mutually. Assuming the mutual 
interaction to be two body and dependent only on the distance between molecules, 
the Hamiltonian of the system may be written as 
.HN = Σ
N
i=1
h(ri, pi) +
1
2
Σ
N
i/= j=1
W(|ri − r j|), (3.148) 
where .h(ri, pi) is as in (3.95) and.W(|ri − r j|) is the interaction potential between 
the.ith and the. jth molecule. It will turn out to be convenient to write the double sum 
in (3.148) as 
. Σ
N
i/= j=1
W(|ri − r j|) =
⎛
⎝ Σs
i/= j=1
+ Σ
N
i/= j=s+1
+2
Σs
i=1
Σ
N
j=s+1
⎞
⎠ W(|ri − r j|).
(3.149) 
This equation is the result of breaking the sum over.i, j form. 1 to.N into two parts, 
. 1 to. s plus.s + 1 to. N, and writing the double sum over.i, j as 
.
⎡
⎣
Σs
i=1
Σ
N
j=s+1
+ Σ
N
i=s+1
Σs
j=1
⎤
⎦ W(|ri − r j|) = 2
Σs
i=1
Σ
N
j=s+1
W(|ri − r j|), (3.150) 
obtained by interchanging. i and. j in the second sum and noting that.W(|ri − r j|) is 
unchanged under the exchange of. i and. j. 
To derive equation for. fs we integrate the Liouville equation (3.56) over. s + 1,s +
2,..., N. Equation (3.146) gives the result of integration when.W = 0. Denoting the 
contribution from the mutual interaction term by. Is, 
.Is = 1
2
Σ
N
i/= j=1
{
{W(|ri − r j|), fN }
|
k≥s+1
d3
rkd3
pk , (3.151) 
the equation for. ˜fs assumes the form126 3 Kinetic Theory
.
∂ ˜fs({ri, pi}s;t)
∂t = Σs
i=1
{h(ri, pi), ˜fs} + Is. (3.152) 
Since.W(|ri − r j|) is independent of momenta, we have 
. {W(|ri − r j|), fN }=∇ri W(|ri − r j|) · ∇pi fN + ∇r j W(|ri − r j|) · ∇pj fN .
(3.153) 
We evaluate.Is by using the identity 
.
{
F(r) · ∇p f (r, p) d3
p = − {
f (r, p)∇p · F(r) d3
p = 0, (3.154) 
arrived at by invoking the identity (3.135) and the assumption that the surface terms 
do not contribute. 
To evaluate. Is, use the breakup of the sum as in (3.149) to write.Is in (3.151) as 
.Is = Is1 + Is2 + Is3, (3.155) 
where 
.Is1 = 1
2
Σs
i/= j=1
{
{W(|ri − r j|), fN }
|
k≥s+1
dμk , (3.156) 
.Is2 = 1
2
Σ
N
i/= j=s+1
{
{W(|ri − r j|), fN }
|
k≥s+1
dμk , (3.157) 
.Is3 = Σs
i=1
Σ
N
j=s+1
{
{W(|ri − r j|), fN }
|
k≥s+1
dμk . (3.158) 
The.Isk can be evaluated as follows. 
1. Consider.Is1. The summation over.i, j in it is from. 1 to. s whereas the integration is 
over the phase space coordinates.rk , pk for.k ≥ s + 1. The integration in (3.156) 
can therefore be performed only over. fN to obtain 
.Is1 = 1
2
Σs
i/= j=1
{W(|ri − r j|), ˜fs}. (3.159) 
2. To evaluate.Is2 we write the commutator in it using (3.153) so that3.6 BBGKY Hierarchy 127
. Is2 = 1
2
Σ
N
i/= j=s+1
{ [
∇ri W(|ri − r j|) · ∇pi fN
+∇r j W(|ri − r j|) · ∇pj fN
]
.
|
k≥s+1
dμk (3.160) 
Since.i, j are both greater than.s + 1, the momenta with respect to which deriva￾tives in (3.160) are carried are same as those which are integrated. Hence, invoking 
(3.154) 
.Is2 = 0. (3.161) 
3. Using (3.153) (3.158) for.Is3 reads 
. Is3 = Σs
i=1
Σ
N
j=s+1
{ [
∇ri W(|ri − r j|) · ∇pi fN
+∇r j W(|ri − r j|) · ∇pj fN
] |
k≥s+1
dμk . (3.162) 
Note that the momenta with respect to which the derivatives in the second term 
in (3.162) are carried are same as the ones which are integrated. Hence the con￾tribution from the second term vanishes due to (3.154) reducing.Is3 to 
.Is3 = Σs
i=1
Σ
N
j=s+1
{
∇ri W(|ri − r j|) · ∇pi fN
|
k≥s+1
dμk . (3.163) 
This may be rewritten as 
. Is3 = Σs
i=1
Σ
N
j=s+1
{
∇ri W(|ri − r j|) · ∇pi fN
|
k≥s+1
dμk
= Σs
i=1
Σ
N
j=s+1
{ [
∇ri W(|ri − r j|) · ∇pi
{
fN
|
k≥s+1,k/= j
dμk
]
dμj .
(3.164) 
The integration of . fN in the equation above is over all phase space variables 
except over.(rl, pl) (.l = 1, 2,...s) and.l = j (. j ≥ s + 1). Hence 
.
{
fN ({ri, pi}N ;t) |
k≥s+1,k/= j
dμk = ˜fs+1({ri, pi}s, r j, pj;t). (3.165)128 3 Kinetic Theory
Substitute this in (3.164) and use the symmetry of. fN under exchange of particles 
to get 
. Is3 = Σs
i=1
Σ
N
j=s+1
{
∇ri W(|ri − r j|) · ∇pi ˜fs+1({ri, pi}s, r j, pj;t) dμj
= (N − s)
Σs
i=1
{
∇ri W(|ri − rs+1|) · ∇pi ˜fs+1 dμs+1. (3.166) 
Substitute (3.159), (3.161), and (3.166) in (3.155) to get 
. Is = 1
2
Σs
i/= j=1
{
W(|ri − r j|), ˜fs
}
+(N − s)
Σs
i=1
{
∇ri W(|ri − rs+1|) · ∇pi ˜fs+1({ri, pi}s+1;t)dμs+1.
(3.167) 
Substitute (3.167) in (3.152), multiply the resulting equation by .N!/(N − s)! and 
invoke the relation (3.78) to arrive at the following equation for the.s-particle distri￾bution function: 
.
∂ fs
∂t −
{
Hs, fs
}
= Σs
i=1
{
∇ri W(|ri − rs+1|) · ∇pi fs+1dμs+1, (3.168) 
where 
.Hs = Σs
i=1
h(ri, pi) +
1
2
Σs
i/= j=1
W(|ri − r j|). (3.169) 
Consider the equation for. f1. Since.s = 1, there is no.i /= j term in the sum over. i, j
in the expression (3.169) for.Hs. Hence the interaction term will not appear in.Hs in 
the equation for. f1 obtained from (3.168) by taking.s = 1: 
.
∂ f1
∂t −
{
h(r, p), f1
}
=
{
∇rW(|r − r1|) · ∇p f2 dμ1. (3.170) 
The equation for. f1 is thus different from the equations for. fs (.s ≥ 2) in that it does 
not have the commutator with the interaction potential term in it. 
The chain of equations (3.169) and (3.170), relating the evolution of . fs . (s =
1, 2,..., N) with . fs+1, is called the Bogoliubov–Born–Green–Kirkwood–Yvon 
(BBGKY) hierarchy. The determination of . f1 thus requires solving .N equations,3.7 Boltzmann Equation from BBGKY Hierarchy 129
i.e. as many equations as the number of particles! It is therefore not of help till the 
chain of equations is terminated at an early step. 
In the following we describe conditions under which the BBGKY hierarchy can 
be terminated at the equation for. f2 to obtain the Boltzmann equation. 
3.7 Boltzmann Equation from BBGKY Hierarchy 
The Boltzmann equation (3.110) is a closed-form equation for . f1(r, p;t). On the 
other hand, the equation (3.170) for. f1(r, p;t) is the first in the BBGKY hierarchy. 
It is coupled with. f2 whose evolution is governed by (3.168) corresponding to.s = 2: 
.
∂ f2
∂t −
{
H2, f2
}
= Σ
2
i=1
{
∇ri W(|ri − r3|) · ∇pi f3 dμ3. (3.171) 
The equation for. f2 above is coupled with. f3. By considering relative magnitude of 
various terms in (3.171) under certain assumptions, we will show that the integral on 
the right containing. f3 can be ignored. To that end note that each term in the equation 
for. fs has dimensions of. fs/time. 
The explicit expression of the streaming term in (3.171) is 
. {
H2, f2
}
= Σ
i=1,2
[
∇riU(ri) · ∇pi f2 − 1
m pi · ∇ri f2
+ ∇ri W(|r1 − r2|) · ∇pi f2
]
. (3.172) 
For simplicity we assume .U(r) = 0 and estimate relative magnitude of various 
terms in (3.171) based on the following considerations: (1) We consider such inter￾molecular potentials which are short ranged in the sense that they are appreciable 
over distances .r0 ∼ 10−8 cm, i.e. on the atomic scale. This will exclude potentials 
such as Coulomb potential which would require different treatment. (2) Typical speed 
. v of the molecules in a gas at room temperature is.∼ 104 cm s−1. 
Since, as observed before, each term in the equation for . fs has dimensions of 
. fs/time, we determine in the following the time scale on which each term makes 
dominant contribution. 
1. Consider the terms involving inter-molecular potential.W(|r|) in (3.172): 
.Ic = ∇ri W(|r1 − r2|) · ∇pi f2, i = 1, 2. (3.173) 
Clearly, dominant contribution to .Ic comes from distances over which inter￾molecular potential .W(|r|) varies appreciably. Due to the assumptions listed 
circa (3.172), the distance over which .W(|r|) varies appreciably is its range 
.r0 ∼ 10−8 cm and the molecules move with typical speed.v ∼ 104 cm s−1. Hence130 3 Kinetic Theory
dominant contribution to.Ic is on the time scale.τc where 
.τc ∼ r0/v ∼ 10−12 sec. (3.174) 
Evidently.τc is the time that the particle takes to traverse the interaction region or 
the duration of collision. 
2. We now estimate the time scale on which the integral on the right side of (3.171) 
makes dominant contribution. Note that whereas the left side of (3.171) has . f2, 
the integral on its right has . f3. To estimate relative magnitude of the . f2 and . f3
terms in the equation, we recall the defining relation: 
. ˜f2(r1, r2, p1, p2;t) =
{
˜f3(r1, r2, r3, p1, p2, p3;t) dμ3 =⇒
{
f3 dμ3 = (N − 2) f2 ≈ N f2. (3.175) 
Since. f2 is independent of. r3, we can write 
. f2 = 1
V
{
f2d3
r3. (3.176) 
The expression (3.175) may then be rewritten as 
.
{
f3 d3
r3d3
p3 = N
V
{
f2d3
r3. (3.177) 
Using this we can approximate the integral in (3.171) by 
. Iint =
{
∇ri W(|ri − r3|) · ∇pi f3 d3
r3d3
p3
∼ N
V
{
∇ri W(|ri − r3|) · ∇pi f2d3
r3, i = 1, 2. (3.178) 
Due to the assumptions listed below (3.172), the volume integral above is restricted 
to. r 3
0 . Recalling also the definition (3.173) of. Ic, we can write 
.Iint ∼ N
V r 3
0 Ic. (3.179) 
Since dominant contribution to.Ic is on the time scale. τc, it follows that the time 
scale.τint on which.Iint is dominant given by 
.τint ∼ V
N r−3
0 τc ∼ 104
τc, (3.180)3.7 Boltzmann Equation from BBGKY Hierarchy 131
where we have taken.N/V ≈ 1020 cm−3. This shows that 
.τint >> τc. (3.181) 
We thus see that the contribution from the integral term in (3.171) is much smaller 
than that from the inter-molecular potential term in .{H2, f2} and can be neglected 
thereby reducing (3.171) to the form 
.
∂ f2
∂t −
{
H2, f2
}
= 0. (3.182) 
Since the dominant term in it is.∼ 1/τc, the. f2 reaches equilibrium on the time scale 
of. τc. We show next that the time scale on which. f1 evolves is.∼ τint which, due to 
(3.181) is much longer than. τc. 
To that end, recall equation (3.170) for. f1, rewritten as (for.U(r) = 0) 
.
∂ f1(r, p;t)
∂t − 1
m p · ∇r f1 =
(∂ f1
∂t
)
coll, (3.183) 
where 
.
(∂ f1
∂t
)
coll =
{
∇rW(|r − r1|) · ∇p f2(r, r1, p, p1;t) dμ1. (3.184) 
By using the same arguments as were used for estimating the integral in the equation 
for . f2, it can be seen that the contribution of the integral term is .1/τint given by 
(3.180). Hence, due to the absence of inter-molecular interaction in the streaming 
term which amounts to absence of .1/τc contribution, the dominant contribution to 
(3.183) comes from the integral term. The time evolution of . f1 is therefore on the 
time scale of.τint. Since.τint >> τc where.τc is the scale of evolution of. f2, it follows 
that . f2 reaches equilibrium on the time scale .τc much shorter than the scale .τint on 
which. f1 would do so. Hence, for.t >> τc we can take.∂ f2/∂t = 0 reducing (3.182) 
to (.U(r) = 0) 
.
Σ
i=1,2
[ 1
m pi · ∇ri f2 − ∇ri W(|r1 − r2|) · ∇pi f2
]
= 0. (3.185) 
Since.∇r2W(|r1 − r2|) = −∇r1W(|r1 − r2|), we can rewrite (3.185) as 
.
1
m
Σ
i=1,2
pi · ∇ri f2 = ∇r1W(|r1 − r2|) ·
(
∇p1 − ∇p2
)
f2. (3.186) 
We use (3.186) to evaluate the collision term (3.184) by rewriting it as132 3 Kinetic Theory
.
(∂ f1
∂t
)
coll =
{
∇rW(|r − r1|) ·
(
∇p − ∇p1
)
f2 dμ1. (3.187) 
This is obtained by adding.−∇p1 f2 under the integral in (3.184) as its contribution, 
by virtue of (3.154), is zero. On using (3.186), (3.187) reads 
.
(∂ f1(r, p;t)
∂t
)
coll = 1
m
{ (
p · ∇r + p1 · ∇r1
)
f2 dμ1. (3.188) 
It will not be appropriate to apply the assumption of molecular chaos to express. f2
as the product of two . f ,
1s. For, the integration over space in (3.188) involves not 
only the scattering region but also the region in which the particles interact where 
the assumption of molecular chaos is unlikely to hold. We therefore need to separate 
the said two regions. 
Invoking the assumption that the range of .W(|ri − r j|) is . r0, we can assume 
.W(|r˜|) = 0 for .|r˜| > |r0| and thereby restrict integration in (3.188) to the region 
bound by.|r0|: 
.
(∂ f1(r, p;t)
∂t
)
coll = 1
m
{
|r1|<|r0|
(
p · ∇r + p1 · ∇r1
)
f2 dμ1. (3.189) 
To evaluate the integral above, it is useful to work in the center of mass coordinate 
system: 
.R = r + r1
2 , r˜ = r − r1, V = R˙ , v˜ = ˙
r˜. (3.190) 
The integrand in (3.189) in the transformed variables reads 
. (
p · ∇r + p1 · ∇r1
)
f2 =
(
V · ∇R + v˜ · ∇r˜
)
f2(R, r˜, P, p˜;t)
≈ v˜ · ∇r˜ f2(R, r˜, P, p˜;t), (3.191) 
where the second line is the result of the expectation that the center of mass motion 
is much slower than that of the relative coordinates. Substitute (3.191) in (3.189) to 
obtain 
.
(∂ f1
∂t
)
coll =
{
d3
p1
{
|r1|<|r0|
v˜ · ∇r˜ f2 d3
r1. (3.192) 
To evaluate the integral above, we work in the coordinate system in which the direc￾tion. v˜ is the.z-axis (see Fig. 3.2) so that (3.192) assumes the form.3.7 Boltzmann Equation from BBGKY Hierarchy 133
Fig. 3.2 Scattering of two 
particles in the rest frame of 
one at rest at. O. The region 
inside the sphere of radius 
.|r0| centered at.O is the 
interaction region 
O 
.
(∂ f1
∂t
)
coll =
{
d3
p1
{
|r1|<|r0|
|v − v1|
∂ f2
∂z
d3
r1, (3.193) 
The plane perpendicular to the direction of propagation is characterized by the impact 
parameter . b and the angle . φ. The volume element in the said coordinate system is 
.d3r1 = b db.dφ. dz. The particle at rest is shown at the center of the sphere.S0 of radius 
.|r0|. The region inside.S0 is the interaction region. The incoming particle meets the 
sphere .S0 at . z1, enters the interaction region and leaves it from the point .z2 on the 
sphere. Since integration of (3.193) is restricted to the interior of the sphere . S0, the 
integration over. z can be performed to get 
.
(∂ f1
∂t
)
coll =
{
d3
p1|v − v1|
{ (
f2(z2) − f2(z1)
)
b db dφ, (3.194) 
where . f2(z1) is the function of the momenta of the particles before scattering and 
. f2(z2) that after scattering. Invoking the expression (3.113) for.dσ, (3.194) assumes 
the form 
. (∂ f1
∂t
)
coll
= 1
m
{
|p − p1|
(
f2(z2) − f2(z1)
) dσ
dΩ
dΩd3
p1. (3.195) 
The points.z1,z2 are the ones at which the particle enters and leaves the interaction 
region outside which the assumption of molecular chaos contained in (3.108) is 
expected to hold: 
. f2(z1) = f1(r, p;t) f1(r, p1;t), f2(z2) = f1(r, p,
;t) f1(r, p,
1;t). (3.196) 
In writing the equations above we have replaced.r,
1 and.r,
2 by. r assuming that. f1 does 
not vary on the scale. r0. On using (3.196), (3.195) reduces to the collision integral in 
the Boltzmann (3.111). We have thus shown that, under appropriate assumptions, the134 3 Kinetic Theory
equation (3.170) for. f1(r, p;t) can be decoupled from the rest of the chain resulting 
in the Boltzmann equation derived before by working in one-particle phase space. 
Next, we derive the equilibrium solution of the Boltzmann equation. 
3.8 The H-Theorem 
The BBGKY equations determine time evolution of the distribution functions. The 
system would approach an equilibrium state as .t → ∞. That state is described by 
the asymptotic solution of those equations. In particular, as.t → ∞ the one-particle 
distribution function. f1(r, p;t) approaches the solution of the equation 
.
∂ f1(r, p;t)
∂t = 0. (3.197) 
Assuming no external force,.∂ f1(r, p;t)/∂t satisfies (3.111) with.U(r) = 0. We see 
that, for (3.197) to hold in this case, it is sufficient that . f1 be a function of . p alone, 
say. f0(p), such that 
. f0(p,
) f0(p,
1) − f0(p) f0(p1) = 0. (3.198) 
However, the questions that may be asked are: Is (3.198) also a necessary condition? 
Does the solution. f1(r, p;t) of the Boltzmann equation approach. f0(p) as.t → ∞? 
What is the solution of (3.197) when.U(r) /= 0? 
The answer to first two questions above turns out to be in the affirmative. The 
proof is based on the examination of the behavior of the following functional under 
time evolution, 
.H =
{
f1(r, p;t) ln( f1(r, p;t)) d3
rd3
p, (3.199) 
called the Boltzmann’s H-Function, or simply the H-function. The answers to the said 
two questions are the consequences of the.H-theorem which states that, if. f1(r, p;t)
obeys the Boltzmann equation (3.111) (or equivalently (3.110)) then 
.
dH
dt
≤ 0. (3.200)3.8 The H-Theorem 135
Proof: The time-derivative of (3.199) reads 
. 
dH
dt =
{ ∂ f1(r, p;t)
∂t (1 + ln( f1(r, p;t))) d3
rd3
p
=
{ ∂ f1(r, p;t)
∂t
ln( f1(r, p;t)) d3
rd3
p, (3.201) 
where the last line is due to the fact that 
.
{ ∂ f1(r, p;t)
∂t
d3
rd3
p = d
dt
{
f1(r, p;t) d3
rd3
p = 0. (3.202) 
The second equation above is due to the normalization condition (3.65). On invoking 
(3.110), (3.201) assumes the form 
. 
dH
dt =
{
ln( f1(p))W(p,
, p,
1|p, p1)δ(4) (
P, − P
)
×
(
f1(p,
) f1(p,
1) − f1(p) f1(p1)
)
d3
rd3
pd3
p,
d3
p1d3
p,
1, (3.203) 
where we have dropped the .r, t from the argument of . f1 and used the fact that, by 
using the identity (3.135), the contribution from the Poisson bracket term vanishes. 
Interchange .p1 ↔ p in (3.203). The only term that changes due to this is the 
logarithmic term. Add the resulting equation and (3.203) to get 
. 
dH
dt = 1
2
{
ln(
f1(p) f1(p1)
)
W(p,
, p,
1|p, p1)δ(4) (
P, − P
)
×
[( f1(p,
) f1(p,
1) − f1(p) f1(p1)
)] d3
rd3
pd3
p,
d3
p1d3
p,
1. (3.204) 
Interchange .p, ↔ p and .p,
1 ↔ p1. Make use of the relation . W(p, p1|p,
, p,
1) =
.W(p,
, p,
1|p, p1), add the resulting equation and (3.204) to get 
. 
dH
dt = −1
4
{
W(p,
, p,
1|p, p1)δ(4) (
P, − P
)
×
(
ln(x) − ln(y)
)
(x − y) d3
rd3
pd3
p,
d3
p1d3
p,
1, (3.205) 
where 
.x = f1(p,
) f1(p,
1), y = f1(p) f1(p1). (3.206) 
Clearly, the integrand is always positive. Hence follows the desired result (3.200). 
This shows that, as the system evolves,.H decreases monotonically and will approach 
the constant value for such. f1 for which.dH/dt = 0.136 3 Kinetic Theory
The.H-theorem thus asserts that the one-particle phase space distribution evolves 
monotonically, i.e. irreversibly to a steady-state form thereby breaking time-reversal 
symmetry. This is in contrast with time-reversal symmetry of the .N-particle distri￾bution function which obeys the Liouville equation exhibiting that symmetry. How 
is the time-reversal symmetry broken in going from time-reversal symmetric Liou￾ville’s equation to Boltzmann’s one-particle equation? Is it because of operation of 
phase space integration involved in obtaining one-particle distribution function from 
the.N-particles one? It does not appear to be so because the said operation does not 
break time-reversal symmetry. The reason for time acquiring a preferred direction 
appears to be rooted in the assumption of molecular chaos. There are however subtle 
issues involved in identifying the source of irreversibility which we do not address 
(see for example [Huang], [Kardar]). 
The equation (3.205) shows that the necessary and sufficient condition for 
.dH/dt = 0 to hold is.x − y = 0. On restoring. r in the argument of. f1 and denoting 
by. f0(r, p) the function for which.dH/dt = 0, the condition.x = y, with.x, y given 
by (3.206), reads 
. f0(r, p,
) f0(r, p,
1) = f0(r, p) f0(r, p1). (3.207) 
Next we find the function solving (3.207). 
3.9 Equilibrium Distribution 
Take the logarithm of (3.207) to get 
.ln(
f0(r, p,
)
)
+ ln(
f0(r, p,
1)
)
= ln(
f0(r, p)
)
+ ln(
f0(r, p1)
)
. (3.208) 
On one side of the equation above we have the quantities before collision and on 
the other side are the same quantities after collision. Hence (3.208) is in the form of 
a conservation law. This implies that .ln(
f0(r, p)
)
is a combination of independent 
constants of motion, say,.C1(r, p),C2(r, p), . . . ,Cn(r, p): 
.ln(
f0(r, p)
)
= Σn
k=1
Ck (r, p). (3.209) 
Let us consider first the case of the gas which is not acted upon by any external force. 
The distribution function . f0 in that case will be independent of . r reducing (3.208) 
thereby to (3.198). 
Consider a monatomic gas. The constants of motion in this case are the kinetic 
energy and three components of momentum. The right side of (3.209) is then an 
arbitrary sum of the said two constants whereby it reads3.9 Equilibrium Distribution 137
.ln(
f0(p)
)
= −D (p − p0)
2 + ln(B), (3.210) 
where. B,. D,.p0 are constants. This implies 
. f0(p) = B exp (
−D (p − p0)
2)
. (3.211) 
The normalization condition (3.65) demands 
.
{
B exp (
−D (p − p0)
2)
d3
rd3
p = N. (3.212) 
The average momentum of a molecule is then given by 
.⟨p⟩ =
B
N
{
p exp (
−D (p − p0)
2) d3
rd3
p = p0. (3.213) 
Assuming the gas has no translational motion as a whole,.p0 = 0, so that 
. f0(p) = B exp (
−Dp2)
. (3.214) 
On integrating this over the volume occupied by the gas we obtain the distribution 
function for the momentum, expressed in terms of the velocity: 
.F(v) = C exp (
−Av2)
. (3.215) 
This is same as the expression (3.7) for Maxwell distribution of velocities. Its rela￾tionship with thermodynamics has been discussed in Sect. 3.2. 
The equilibrium distribution function (3.211) is for a gas not subject to any external 
force. Let us consider a gas in the external potential .U(r). In that case, we know 
that.C = p2/2m + U(r) is the only constant of motion. The equilibrium distribution 
function (3.209) is then reads 
. f0(r, p) = B exp {
−D (
p2
/2m + U(r)
)} . (3.216) 
That the time-independent distribution function . f0(r, p) is indeed the equilibrium 
solution of the Boltzmann equation (3.111) can be ascertained by noting that, since 
. f0(r, p) solves (3.207) it reduces the collision term in (3.111) to zero. It is straight￾forward to check that, with. f0(r, p) given by (3.216), the streaming term in (3.111) 
is also zero: 
.
p
m · ∇r f0 − ∇rU(r) · ∇p f0(r, p) = 0, (3.217) 
Hence. f0(r, p) in (3.216) is indeed the equilibrium solution of (3.111).138 3 Kinetic Theory
We will see that the equilibrium solutions derived above in the framework of the 
kinetic theory are same as those arrived at in Chap. 7 by means of the methods of 
statistical mechanics. 
Exercises 
Ex. 3.7. Show that an arbitrary sum of .p2/2m and the components .px , py , pz of 
momentum can be expressed in the form appearing on the right side of 
(3.210). 
References 
1. C. Truesdel, Archives for History of Exact Sciences 30.XII.1975, vol. 15 (1975), pp. 1–66. https:// 
www.jstor.org/stable/41133440 
2. J.C. Maxwell, Philos. Mag. 19, 19–32, 20, 21–37 (1860)Chapter 4 
Boltzmann Entropy 
As outlined in Chap. 3, the kinetic theory makes explicit use of the laws of mechanics 
requiring thereby knowledge of inter-particle interaction. Under several conditions 
on the inter-particle interaction and the assumption of molecular chaos, we arrived at 
non-linear Boltzmann’s single-particle integro-differential equation. We saw that the 
state of thermal equilibrium of the gas in that case corresponds to that single-particle 
distribution function for which Boltzmann’s .H-function attains its minimum. Sub￾sequently, in [ 1], Boltzmann showed that, rather than solving a kinetic equation ...it 
is possible to calculate the state of the equilibrium of heat by finding the probability 
of the different possible states of the system. The initial state in most cases is bound 
to be highly improbable and from it the system will always rapidly approach a more 
probable state until it finally reaches the most probable state, i.e. that of the heat 
equilibrium. His said approach, outlined in this chapter, led to the concept of what is 
now called Boltzmann entropy which formed the basis for determining the state of 
thermal equilibrium without the use of the knowledge of the inter-particle potential 
and without the use of the mechanical equations of motion. 
We begin with Boltzmann’s said paper [ 1] which laid the foundation for erecting 
the edifice of modern statistical mechanics and follow it up by demonstrating some 
of its important applications. 
4.1 Discrete Energy Levels 
Boltzmann considered a gas of .N molecules assuming that the kinetic energy of 
each molecule is capable of having discretely spaced values.nε (.n = 0, 1, 2,..., P) 
with the remark that this assumption does not correspond to any realistic mechanical 
model, but it is easier to handle mathematically and the actual problem is solved by 
letting.ε → 0,.P → ∞. 
The molecules are identified by numbering them from . 1 to . N. Let .Ek denote 
the energy of the .kth molecule where .Ek can be any of the possible values . nε
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4_4 
139140 4 Boltzmann Entropy
(.n = 0, 1, 2,..., P). The set .(E1, E2,..., EN ) denoting energy of the molecules 
numbered . 1 to .N is called a configuration (called complexion by Boltzmann). Dis￾tinct permutations of the.Ek ’s denote distinct configurations. All distinct configura￾tions in which there are.nk molecules having energy.εk irrespective of the identity of 
the molecules are said to constitute a state. Thus a state is characterized by ordered 
set of numbers.(n0, n1,..., nP ) in which.nk is the number of molecules in the level 
of energy.kε (.k = 0, 1,..., P) irrespective of the identity of the molecules such that 
.
Σ
P
k=0
nk = N. (4.1) 
The number .nk is the occupation number of the energy level . kε. To determine the 
number of states and configurations, we can look upon the molecules, assumed to be 
distinguishable, as distinguishable boxes. A molecule in the state of energy .kε can 
be looked upon as a box having. k identical balls in it. Since.Pε is the highest level of 
energy of a molecule, the number .P would correspond to the maximum number of 
balls that can be placed in a box. In this way, the problem of determining the number 
of states and configurations of the molecules reduces to the combinatorial problem 
of distribution of identical balls in distinguishable boxes addressed in Appendix D. 
The number of configurations .D(N, P,{nk }P ) corresponding to the state 
.(n0, n1,..., nP ) is given by (D.4): 
.D(N, P,{nk }P ) = N!
n0!n1! ..., nP !
, Σ
P
k=0
nk = N, (4.2) 
whereas total number of configuration, given by (D.9), is 
.Total number of configurations = (P + 1)N . (4.3) 
As an example, consider three atoms each having two energy levels .(0, ε). With 
.n0 + n1 = 3, the possible states are.(n0, n1) :.(3, 0), (2, 1), (1, 2), (0, 3). The distinct 
configurations corresponding to each of the said states are listed in Table 4.1. It 
may be verified that the number of configurations corresponding to each state and 
total number of configurations are in accordance with the formulas (4.2) and (4.3), 
respectively, with.P = 1,.N = 3. 
In the discussion so far, only restriction placed on identifying states has been 
total number of atoms. A macroscopic state of a gas is characterized not only by the 
number of atoms, but also by energy.U which in the present case is evidently 
.U = ε
Σ
P
k=0
knk ≡ εL, L = Σ
P
k=0
knk . (4.4)4.1 Discrete Energy Levels 141
Table 4.1 States and corresponding configurations for three atoms having two levels of energy 
.0, ε. The.nk is the number of atoms in the level of energy.kε and.Ep is the energy of the.pth atom 
State Configurations 
(.n0, n1) . (E1, E2, E3)
(3, 0) (0, 0, 0) 
.(2, 1) . (ε, 0, 0), (0, ε, 0), (0, 0, ε)
.(1, 2) . (ε, ε, 0), (ε, 0, ε), (0, ε, ε)
.(0, 3) . (ε, ε, ε)
We can therefore say that a microscopic state of the gas of.N molecules, each having 
.P + 1 energy levels.kε (.k = 0, 1,... P) and total energy.Lε, is characterized by the 
sets of the.n,
k s satisfying 
.
Σ
P
k=0
nk = N, L = Σ
P
k=0
knk . (4.5) 
Though in the example tabulated in Table 4.1 different states have different total 
energy, in general, as the example discussed next shows, there would be several 
different states corresponding to same energy but the number of configurations for 
different states of same energy may or may not be same (see also Ex. 4.1). 
Boltzmann postulated that the state of thermal equilibrium of a gas is charac￾terized by that set of occupation numbers.n,
k s which satisfy (4.5) and correspond to 
largest number of configurations. 
For illustration, we take the example discussed by Boltzmann [ 1]. He considered 
a system of seven atoms, each of which can have energy ranging in unit steps from. 0
to.7ε such that total energy of the system is. 7ε. In the notation above,. N = P = L =
7. Table 4.2 lists possible states and the number .D(N, P,{nk }P ) of configurations 
corresponding to each of them, calculated using (4.2). 
The example considered is a special case of (4.5) corresponding to.L = P. In that 
case, as shown in Appendix D, following results hold: 
1. For a given number .N of atoms each having .P + 1 energy levels .kε . (k =
0, 1,..., P) and total energy .Lε such that .L ≤ P, total number of configura￾tion.D(N, P, L ≤ P) is given by (D.23): 
.P(N, L) ≡ D(N, P, L ≤ P) = (N + L − 1)!
L!(N − 1)! , L ≤ P. (4.6) 
It is independent of. P. This result is applicable to the example under consideration 
as in the present case.L = P = 7. The expression above yields.P(7, 7) = 1716. 
This is same as the sum of the number of configurations corresponding to different 
states tabulated in Table 4.2.142 4 Boltzmann Entropy
Table 4.2 States and configurations for seven atoms which can have energies.kε (.k = 0, 1,..., 7), 
.nk is number of atoms having energy. kε, total energy being. 7ε
State Number of configurations 
(.n0, n1, n2, n3, n4, n5, n6, n7) . D(7, 7,{nk }P )
(6, 0, 0, 0, 0, 0, 0, 1) 7 
(5, 1, 0, 0, 0, 0, 1, 0) 42 
(5, 0, 1, 0, 0, 1, 0, 0) 42 
(5, 0, 0, 1, 1, 0, 0, 0) 42 
(4, 2, 0, 0, 0, 1, 0, 0) 105 
(4, 1, 1, 0, 1, 0, 0, 0) 210 
(4, 0, 2, 1, 0, 0, 0, 0) 105 
(4, 1, 0, 2, 0, 0, 0, 0) 105 
(3, 3, 0, 0, 1, 0, 0, 0) 140 
(3, 2, 1, 1, 0, 0, 0, 0) 420 
(3, 1, 3, 0, 0, 0, 0, 0) 140 
(2, 4, 0, 1, 0, 0, 0, 0) 105 
(2, 3, 2, 0, 0, 0, 0, 0) 210 
(1, 5, 1, 0, 0, 0, 0, 0) 42 
(0, 7, 0, 0, 0, 0, 0, 0) 1 
2. Number of configurations in which.n0 is the number of atoms having zero energy, 
denoted by.C(N, L, n0) (.n0 = 0, 1,..., N − 1), is 
.C(N, L; n0) = (L − 1)!
(L − N + n0)!(N − n0 − 1)!
N Cn0 . (4.7) 
In the present case, with.N = L = 7, we see that 
(a) When .n0 = 6, .C(7, 7, 6) = 7. This is same as the number of configurations 
listed in Table 4.2 corresponding to the state having six molecules in the state 
of zero energy. 
(b) When.n0 = 5,.C(7, 7, 5) = 126. This is same as the the number of configu￾rations listed in Table 4.2 corresponding to three states having five atoms in 
the state of zero energy. 
(c) When.n0 = 4,.C(7, 7, 4) = 525. This is same as the number of configurations 
listed in Table 4.2 corresponding to four states having four atoms in the state 
of zero energy. 
(d) When.n0 = 3,.C(7, 7, 3) = 700. This is same as the number of configurations 
listed in Table 4.2 corresponding to three states having three atoms in the state 
of zero energy.4.1 Discrete Energy Levels 143
(e) When.n0 = 2,.C(7, 7, 2) = 315. This is same as the number of configurations 
listed in Table 4.2 corresponding to two states having two atoms in the state 
of zero energy. 
(f) When.n0 = 1,.C(7, 7, 1) = 42. This is same as the number of configurations 
listed in Table 4.2 corresponding to the state having one atom in the state of 
zero energy. 
(g) When.n0 = 0,.C(7, 7, 0) = 1. This is same as the number listed in Table 4.2 
corresponding to the state having no atom in the state of zero energy. 
Since the state of thermodynamic equilibrium corresponds to the one having maxi￾mum number of configurations, the interest is in determining the state corresponding 
to maximum number of configurations. We see that the maximum number of con￾figurations in the example under consideration correspond to the state 
.(n0, n1, n2, n3, n4, n5, n6, n7) = (3, 2, 1, 1, 0, 0, 0, 0). (4.8) 
It is, however, not possible to determine the state having maximum number of con￾figurations in the direct way used in the simple example above as real systems are 
very large. Exploiting the largeness of the system, Boltzmann devised the following 
method to determine the state of thermal equilibrium. 
Boltzmann determined the set of values of the .n,
k s which maximizes 
.D(N, P,{nk }P ) in (4.2) subject to the conditions in (4.5) by maximizing logarithm 
of.D(N, P,{nk }P ), 
.ln(D(N, P,{nk }P )) = ln(N!) −Σ
P
k=0
ln(nk !), (4.9) 
using Lagrange’s method of undetermined multipliers (see Sect. 5.2) to incorporate 
the constraints in (4.5) so that the desired set of.n,
k s is one which maximizes 
.F({nk }) = ln(D(N, P,{nk }P )) −Σ
P
k=0
(α + kγ) nk , (4.10) 
where.α, γ are the Lagrange multipliers. The. α term is due to the normalization con￾dition and the. γ term is due to the condition on total energy. Since, in a large system, 
the numbers.N, nk are large, the logarithms of their factorials may be approximated 
by Stirling’s formula (H.6) so that 
.ln(D(N, P,{nk }P )) = Nln(N) − N −Σ
P
k=0
{nk ln(nk ) − nk }, (4.11) 
which on substitution in (4.10) reduces.F({nk }) to the form144 4 Boltzmann Entropy
.F({nk }) = Nln(N) − N −Σ
P
k=0
(ln(nk ) − 1 + α + kγ) nk . (4.12) 
The extremization condition.∂F/∂nk = 0 yields 
.ln(nk ) + α + kγ = 0. (4.13) 
This determines the values of the.n,
k s which extremize.F({nk }): 
.nk = Axk
, A = exp(−α), x = exp(−γ). (4.14) 
The Lagrange multipliers.α, γ are determined in terms of the known quantities. N, L
by substituting (4.14) in the conditions (4.5) on the. nk ’s. 
The normalization condition in (4.5) yields 
.A = N(1 − x)
1 − x P+1 , (4.15) 
whereas the expression for. L therein reads 
.L = Σ
P
k=0
knk = A
Σ
P
k=0
kxk = Ax
d
dx
[
1 − x P+1
1 − x
]
. (4.16) 
We leave it as an exercise to show that, with .A given by (4.15), (4.16) leads to 
the polynomial equation of degree .P + 2 in . x ((4.36) in Ex. 4.2). Since . x by its 
definition in (4.14) is positive, only positive roots of (4.36) are acceptable. Boltzmann 
showed that (4.36) has only one positive real root. Noting also that the maximum 
kinetic energy .Pε of an atom is much larger than its mean kinetic energy .Lε/N so 
that .P >> L/N, he showed that the said positive root of (4.36) lies in the interval 
.(0, 1). Thus the unique positive root of (4.36) determines. x which is one of the two 
unknowns. The other unknown. A is obtained using its expression (4.15) in terms of 
. x. The. nk ’s in (4.14) then turn out to be given by 
.nk = N(1 − x)
1 − x P+1 xk
, (4.17) 
where . x is real positive solution of (4.36) which, as mentioned before, has been 
shown to be unique by Boltzmann. 
Since, as discussed above, the situations of interest correspond to .P >> 1 in 
which case (4.15) and (4.16) reduce, respectively, to 
.A = N(1 − x), (4.18) 
and4.1 Discrete Energy Levels 145
.L = N x
1 − x =⇒ x = L
L + N . (4.19) 
The equation above is a simple expression for . x in terms of the known quantities, 
.N, L. 
With. A given by (4.18) and. x by (4.19), the expression (4.17) for the. nk ’s which 
maximize.D(N, P,{nk }P ) for.P >> 1 reads 
.nk = N(1 − x)xk
. (4.20) 
This expresses the. nk ’s in terms of the known quantities.N, L. 
The maximum number of configurations, denoted by.Pmax, is obtained by substi￾tuting the.n,
k s given by (4.20) in (4.11): 
.ln(Pmax) = −N
(
ln(1 − x) + x
1 − x
ln(x)
)
. (4.21) 
Use (4.19) to write. x in the equation above in terms of.L, N to get 
.ln(Pmax) = (N + L)ln(N + L) − Lln(L) − Nln(N). (4.22) 
We have thus at hand the formula for.Pmax in terms of the known quantities. 
Boltzmann noted that the expression (4.22) for .Pmax is same as the expression 
for the number of configurations of the system of .N molecules of total energy .Lε. 
For, recall that the number of configurations corresponding to energy.Lε of.N atoms 
is given by.P(N, L) in (4.6) provided .L ≤ P where .Pε is the highest energy of an 
atom. Since .P is assumed to be large in the derivation of (4.22), formula (4.6) for 
.P(N, L) is applicable in the present case. Furthermore, (4.22) has been arrived at by 
applying Stirling’s approximation assuming.N, L to be large. It is straightforward to 
see that .ln(P(N, L)) with .P(N, L) as in (4.6) is same as .ln(Pmax) in (4.22) under 
Stirling’s approximation. Hence, under Stirling’s approximation on.P(N, L)), 
.ln(Pmax) = ln(P(N, L)), (4.23) 
where .P(N, L)) is the number of configurations corresponding to total energy . Lε
of.N atoms. 
Boltzmann analyzed his example presented above in the light of his results derived 
by maximizing the number of configurations of a specified value of energy. In his 
example, .N = L = P = 7 and the state with maximum number of configurations 
is given by (4.8). He solved (4.36) numerically for .N = L = P = 7 to obtain . x =
0.5078125. Note that this value is close to the value .x = 0.5 that will be obtained 
using . x in (4.19) for .P >> 1 even though in the present case .P = 7, not at all a 
large number. Boltzmann evaluated the . nk ’s using (4.17). We reproduce below his 
results displaying in bracket the corresponding values of the. nk ’s obtained using the 
expressions in (4.20) for.nk and. x applicable for large. P:146 4 Boltzmann Entropy
. n0 = 3.4535(3.5), n1 = 1.7574(1.75), n2 = 0.8943(0.875),
n3 = 0.4551(0.4375), n4 = 0.2316(0.2187), n5 = 0.1178(0.10937),
n6 = 0.0599(0.05468), n7 = 0.0304(0.02734). (4.24) 
Boltzmann observed that, since.N, P in the example under consideration are small, 
the agreement of the values of the . nk ’s in (4.24), based on the assumption of large 
numbers, with the corresponding exact values in (4.8) is hardly expected. Neverthe￾less, on comparing the two by taking the nearest integral value for each.nk in (4.24) 
except for.n3 whose value though is less than.0.5 but is approximated as. 1, we get 
.n0 = 3, n1 = 2, n2 = n3 = 1, n4 = n5 = n6 = n7 = 0. (4.25) 
These values agree with the exact result in (4.8). 
Boltzmann considered next the example taking.N = 7,.L = 19,.P = ∞ and used 
(4.20) to evaluate the .n,
k s. He found that, except for approximating .n5 = 1 though 
its value is 0.389, the approximation of the.n,
k by the nearest integers yields correct 
values of the.n,
k s which maximize. P. 
Following the examples outlined above, Boltzmann states that the formula (4.20) 
determines the .n,
k s within one or two units of the true values even for small values 
of .P, N and that, since in the mechanical theory of heat we deal with extremely 
large number of molecules, these small differences disappear and the approximate 
formula provides an exact solution of the problem. He determined also the form of 
the formula (4.20) when average molecular energy is much higher than the separation 
. ε between the consecutive energy levels as follows. 
When separation. ε between consecutive energies is very small compared with the 
average kinetic energy .u ≡ Lε/N, the expression (4.20) for the number of atoms 
having energy.kε can be approximated by 
.nk = Nε
u + ε
(
1 + ε
u
)−k
≈ Nε
u exp(−kε/u). (4.26) 
Concluding at this point the discussion of discrete energy model, Boltzmann remarks: 
to achieve a mechanical theory of heat, these formulas must be developed further, 
particularly through the introduction of differentials and some additional consider￾ations. 
Before outlining in Sect. 4.2 Boltzmann’s treatment of continuous molecular 
motion in terms of number of configurations for continuous variables which led 
to the notion of entropy named after him, we carry further the discussion of the 
discrete model to establish its link with thermodynamics.4.1 Discrete Energy Levels 147
4.1.1 Connection of Discrete Model with Thermodynamics 
Boltzmann did not pursue the discrete model any further and went on to consider 
the continuum limit.ε → 0. In Sect. 4.3, we will see how he used his discrete model 
results to construct the position and velocity distribution of molecules and established 
connection with thermodynamics by relating the function, he called the permutability 
measure, with thermodynamic entropy. For the present, we investigate the thermo￾dynamic properties of the collection of molecules having discrete energy levels by 
adopting the definition (4.77) of Boltzmann’s entropy for the discrete case in terms 
of the number .P of configurations subject to the constraints (4.5). Its connection 
with thermodynamics is established by that entropy given by (4.78) corresponding 
to the maximum value.Pmax of. P, through the equations (4.79): 
.SB,max = kBln(Pmax),
1
T = ∂SB,max
∂U . (4.27) 
Due to quantum mechanics, discrete models are no more fictitious as they appeared 
at Boltzmann’s time. 
1. In terms of energy per atom given by 
.u = Lε
N , (4.28) 
the relation (4.19) for. x reads 
.x = u
u + ε
. (4.29) 
The energy per atom can therefore be written in terms of. x as 
.u = xε
1 − x
. (4.30) 
2. Using (4.29), the expression (4.20) for.nk may be rewritten as 
.nk = Nε
u + ε
( u
u + ε
)k
. (4.31) 
3. Recalling (4.21) for.ln(Pmax) and on writing. x therein in terms of. u as in (4.29), 
the expression (4.27) for entropy reads 
.SB,max = N kB
[(1 + u
ε
)
ln (
1 + u
ε
)
− u
ε
ln (u
ε
)] . (4.32)148 4 Boltzmann Entropy
This would reduce to Planck’s expression for entropy of the oscillators of fre￾quency. ν in the walls of a blackbody cavity if.ε = hν where. h is Planck’s constant 
(see Sect. 4.5). 
4. With .SB,max given by (4.32), the relation (4.27) between .SB,max and temperature 
yields following expression for. u in terms of. T : 
.u = ε
exp(ε/kBT ) − 1
. (4.33) 
This expresses average molecular energy in terms of temperature. It is same as 
Planck’s blackbody law (4.85) if.ε = hν. 
5. Substitute (4.33) in (4.29) to obtain. x in terms of. T : 
.x = exp(−ε/kBT ). (4.34) 
On substituting this in (4.20) (or (4.33) in (4.31)), the number of molecules having 
energy.kε turns out to be given by 
.nk = N(1 − exp(−ε/kBT )) exp(−kε/kBT ). (4.35) 
We thus have the expression for a microscopic quantity, the number of molecules 
in an energy level, in terms of the thermodynamic one, namely, temperature when 
the molecular gas is in thermal equilibrium, establishing thereby the desired link 
between statistical mechanical and thermodynamic descriptions. 
Ex. 4.1. Consider a system of three atoms each having energy levels 
.kε (.k = 0, 1, 2). Find its states and corresponding configurations for total 
energy .U = 2ε. Hint: The states corresponding to total energy .2ε are 
.(n0, n1, n2) ≡ (2, 0, 1), (1, 2, 0). There are thus two states correspond￾ing to same energy. The configurations comprising the state .(2, 0, 1) are 
.(2ε, 0, 0), (0, 2ε, 0), (0, 0, 2ε), and those corresponding to .(1, 2, 0) are 
.(0, ε, ε) .(ε, 0, ε), .(ε, ε, 0). Note that the number of configurations found 
for each set of .(n0, n1, n2) are consistent with the formula (4.2) and total 
number of configurations is consistent with the formula (4.6). 
Ex. 4.2. Show that (4.16) leads to the equation 
.(N p − L)x p+2 − (N p + N − L)x p+1 + (L + N) = 0. (4.36) 
Ex. 4.3. Show that maximum Boltzmann entropy of the discrete model at tempera￾ture. T is given by 
.SB,max = N
[ u
T − kBln {1 − exp(−ε/kBT )}
]
. (4.37)4.2 Continuous Distribution of Energy 149
4.2 Continuous Distribution of Energy 
Boltzmann used the results derived for energy varying in equally spaced discrete 
steps to continuous energy values as follows. 
Let energy. E assume continuously varying values from. 0 to.∞. Divide energy in 
small intervals of length. ε each. Let. f (E) denote the number of atoms per unit energy 
interval in the vicinity of. E. The number.nk of atoms in the interval.(kε, (k + 1)ε) is 
then given by 
.nk = ε f (kε). (4.38) 
Using this, the normalization condition (4.1) reads 
.ε
Σ∞
k=0
f (kε) = N. (4.39) 
Taking limit .ε → 0 and invoking the definition of Riemann integral, the equation 
above reduces to 
.
{ ∞
0
f (E)dE = N. (4.40) 
Similarly, with.U = N u, the expression (4.4) reads 
.ε
Σ∞
k=0
kε f (kε) = N u. (4.41) 
In the continuum limit.ε → 0 this evidently reduces to 
.
{ ∞
0
E f (E)dE = N u. (4.42) 
Next, we find the continuum limit representation of the number of configurations for 
a given set of values of the.n,
k s. 
The expression (4.11) for the logarithm of the number of configurations 
.D(N, P,{nk }P ) → P, with.nk therein given by (4.38), assumes the form150 4 Boltzmann Entropy
. ln(P) = Nln(N) − N − ε
Σ∞
k=0
{
f (kε)ln(ε f (kε)) − f (kε)
}
= Nln(N) − N − ε
Σ∞
k=0
{
f (kε)ln( f (kε)) − f (kε)
}
−ε
Σ∞
k=0
f (kε)ln(ε)
= Nln(N) − ε
Σ∞
k=0
f (kε)ln( f (kε)) − Nln(ε), (4.43) 
where last line is due to (4.39). In the continuum limit.ε → 0, (4.43) reads 
.ln(P) = Nln(N) −
{ ∞
0
f (E) ln( f (E))dE − NLtε→0ln(ε). (4.44) 
This shows that .ln(P) blows up as .ε → 0. However, the equilibrium distribution 
corresponds to that . f (E) which maximizes .ln(P) subject to the conditions (4.39) 
and (4.41). Since its extremization is not changed by addition of constants, we can 
ignore the additive constants in the expression (4.44) for.ln(P), including the. ε term 
which though blows up but is a constant, and extremize instead the quantity 
.Ω = − { ∞
0
f (E) ln( f (E))dE, (4.45) 
with respect to. f (E) subject to the conditions (4.40), and (4.42): 
.
{ ∞
0
f (E)dE = N,
{ ∞
0
E f (E)dE = N u. (4.46) 
The .Ω defined in (4.45) extends to energy distribution the notion of permutability 
measure of Boltzmann introduced for velocity distribution (see (4.58)). The said 
extremization can be carried using the method of Lagrange multipliers (see Sect. 5.2). 
Presently, it involves extremizing 
.F =
{ ∞
0
{ f (E) ln( f (E)) + α f (E) + γE f (E)} dE, (4.47) 
where .α, γ are Lagrange multipliers. The extremum is attained by varying . f (E)
such that.δF = 0 leading to the equation 
.1 + ln( f (E)) + α + γE = 0. (4.48)4.3 Distribution of Velocities 151
This is solved by 
. fmax(E) = A exp(−γE). (4.49) 
Using the conditions in (4.46),. A and. γ are evaluated so that 
. fmax(E) = N
u exp(−E/u). (4.50) 
We have thus at hand the equilibrium distribution of continuously varying energy, 
obtained by extremizing the quantity.Ω defined in (4.45). The extremized value. Ωmax
of.Ω is the value of.Ω corresponding to the. f (E) that extremizes it: 
.Ωmax = − { ∞
0
fmax(E) ln( fmax(E))dE, (4.51) 
where. fmax(E) is as in (4.50). Evaluation of the integral above yields 
.Ωmax = N(1 + ln(u) − ln(N)), (4.52) 
which on use of (4.44) by ignoring the blowing up term therein shows that 
.ln(Pmax) = N(1 + ln(u)). (4.53) 
Recalling the definition of entropy.SB,max in (4.27) we get 
.SB,max = kBln(Pmax) = N kB(1 + ln(u)). (4.54) 
Invoking the relation between temperature and entropy in (4.27), we obtain.u = kBT . 
We can verify that (4.54) is same as the expression (4.32) for .SB,max arrived at by 
assuming small separation . ε between energy in the limit .ε → 0. For, in the limit 
.ε → 0, (4.32) reduces to 
.SB,max = N kB (1 + ln(u)) − N kBLtε→0ln(ε). (4.55) 
This is same as (4.54) if the blowing up last term in it is ignored which is in accordance 
with the fact that that term has been ignored even while arriving at (4.54). 
4.3 Distribution of Velocities 
Boltzmann considered next the problem of determining distribution of molecular 
velocities. He began by assuming each component of velocity varying discretely: 
the .x, y,z components .vx , vy , vz of the velocity take values .vx = kx εx , .vy = ky εy ,152 4 Boltzmann Entropy
.vz = kzεz (.−pμ ≤ kμ ≤ pμ,.μ = x, y,z). The number of configurations.P in which 
there are.nkx , nky , nkz number of molecules having the.x, y,z components of velocity 
given, respectively, by.vx = kx εx ,.vy = ky εy ,.vz = kzεx is 
.P = N!
⎛
⎝ |px
kx=−px
nkx ! |py
ky=−py
nky ! |pz
kz=−pz
nkz !
⎞
⎠
−1
. (4.56) 
Proceeding in the same manner as described in Sect. 4.2, he goes over to the con￾tinuum limit by defining the function . f (v) ≡ f (vx , vy , vz) which is the number of 
molecules per unit velocity interval in the vicinity of. v so that 
.nkx ,ky ,kz = εx εy εz f (kxvx , kyvy , kzvz) (4.57) 
is the number of molecules having components of velocity in the intervals. (kx εx , (kx +
1)εx ),.(ky εy , (ky + 1)εy ),.(kzεz, (kz + 1)εz), respectively. As done in Sect. 4.2, it can 
be shown that, apart from additive constants,.ln(P) is same as.Ω where 
.Ω = − {
f (v)ln{ f (v)}d3
v. (4.58) 
Boltzmann calls.Ω the permutability measure. We call the related quantity 
.SB = kBΩ, (4.59) 
the Boltzmann entropy. 
The state of thermodynamic equilibrium corresponds to such . f (v) which maxi￾mizes (4.58) subject to the normalization constraint 
.
{
f (v)d3
v = N, (4.60) 
and the constraint on total kinetic energy 
.
m
2
{
v2 f (v)d3
v = U ≡ N u. (4.61) 
Invoking the method of Lagrange multipliers the equilibrium distribution may be 
seen to be given by 
. fmax(v) = A exp(−mv2
γ), (4.62) 
where the constants .A, γ are determined by the conditions (4.60) and (4.61). The 
velocity distribution function . f (v) in (4.62) is same as the Maxwell distribution 
derived differently. It is straightforward to verify that4.4 Relation Between Thermodynamic and Boltzmann Entropies 153
.γ = 3
4u
, A = N
( 3m
4πu
)3/2
, (4.63) 
so that the equilibrium distribution assumes the form 
. fmax(v) = N
( 3m
4πu
)3/2
exp(−3mv2
/4u). (4.64) 
This is Boltzmann’s velocity distribution. He then states that complete description 
of gas is provided not by velocity distribution alone but it must also include the 
distribution of the positions of molecules. We outline next his method of obtaining 
the said complete distribution and the way he uses it to establish connection of his 
theory with thermodynamics. 
4.4 Relation Between Thermodynamic and Boltzmann 
Entropies 
Boltzmann introduced the function . f (r, v) ≡ . f (x, y,z; vx , vy , vz) which is such 
that. f (r, v)d3rd3v gives the number of atoms positioned in the vicinity of. r having 
velocity in the vicinity of. v. The equilibrium distribution is obtained by maximizing 
the permutability measure.Ω defined by generalizing its definition (4.58) for velocity 
distribution: 
.Ω = − {
f (r, v)ln{ f (r, v)}d3
rd3
v. (4.65) 
subject to the normalization condition 
.
{
f (r, v)d3
rd3
v = N, (4.66) 
and the condition on total kinetic energy 
.
m
2
{
v2 f (r, v)d3
rd3
v = U. (4.67) 
By following the method of Lagrange’s multipliers, it is straightforward to show that 
the said. f (r, v) is given by 
. fmax(r, v) = N
V
( 3m
4πu
)3/2
exp(−3mv2
/4u). (4.68)154 4 Boltzmann Entropy
Verify that the kinetic energy per molecule is correctly given by 
.
m
2 ⟨v2
⟩ = u. (4.69) 
The permutability measure.Ω in (4.65) corresponding to its maximizing distribution 
(4.68) can be seen to be given by 
.Ωmax = N
(3
2
ln(u) + ln(V)
)
− Nln(N) +
3N
2 (ln(4π/3m) + 1). (4.70) 
To connect his formalism with thermodynamics, Boltzmann recalls the thermody￾namic relation 
.dQ = Ndu + PdV, (4.71) 
and the ideal gas law.PV = 2N u/3 to obtain 
.
{ dQ
u = 2N
3
(3
2
ln(u) + ln(V)
)
+ C, (4.72) 
where. C is a constant. Noting that the bracketed terms in (4.70) and (4.72) are same 
and the term outside the bracket in (4.70) is a constant, with a proper choice of. C in 
(4.72), one can write 
.
{ dQ
u = 2
3
Ωmax. (4.73) 
Boltzmann identifies the left side of (4.73) as thermodynamic entropy and hence 
arrives at the conclusion that the permutability measure .Ωmax is 3/2 times the ther￾modynamic entropy at equilibrium. Invoking the relation.u = (3/2)kBT for an ideal 
gas, (4.73) may be written in terms of the standard definition.dSth = dQ/T of ther￾modynamic entropy as 
.Sth = kBΩmax. (4.74) 
Thus the Boltzmann entropy defined in (4.59) corresponding to maximum. Ω, 
.SB,max = kBΩmax, (4.75) 
provides link with the thermodynamic entropy. Using (4.70) the equation above reads 
.SB,max = N kB
{3
2
ln (U
N
)
+ ln ( V
N
)
+
3
2
ln ( 4π
3m
)
+
3
2
}
. (4.76)4.5 Planck’s Distribution 155
This shows that the Boltzmann entropy is extensive. The thermodynamic entropy 
(4.72), on the other hand, is not extensive unless the constant .C therein is chosen 
appropriately. Since it is extensive, it does not suffer from the Gibbs paradox dis￾cussed in Sect. 7.6. 
Since .Ω is the continuous limit form of the logarithm of discrete number .P of 
configurations, the expression (4.59) of Boltzmann’s entropy can be generalized to 
systems having discrete energy levels by defining Boltzmann entropy as 
.SB = kBln(P). (4.77) 
The.SB corresponding to.Pmax, denoted by.SB,max: 
.SB,max = kBln(Pmax), (4.78) 
provides link with the thermodynamic entropy: 
.Sth = SB,max =⇒
1
T = ∂SB,max
∂U . (4.79) 
We have used (4.78) and (4.79) in Sect. 4.1.1 to investigate connection between 
Boltzmann’s discrete energy level model of molecules and thermodynamics. In the 
following, we outline some important applications of the said relations. 
It may be mentioned that Boltzmann entropy is widely written as .S = kln(W). 
This is how it is inscribed even on his tombstone. However, though Boltzmann did 
introduce the symbol.W in his paper, he never used it. Besides,.W in his paper is the 
probability of occupation of a state and not the number of configurations. The said 
form got stuck in popular memory after it was used first by Planck in his paper on 
blackbody radiation [ 2]. 
4.5 Planck’s Distribution 
In his theory of blackbody radiation [ 2], Planck assumed that the atoms in the walls 
of the cavity behave as oscillators which absorb and emit radiation having energy in 
integral multiples of some basic unit. ε and that the energy density.Uν (T ) of radiation 
at frequency . ν in the cavity at temperature .T is related with the average energy . uν
of an oscillator at the same frequency by the relation, with .ρνdν standing for the 
number of radiation modes per unit volume in the interval.(ν, ν + dν), 
.Uν (T ) = ρνuν (T ), ρν = 8πν2
c3 . (4.80) 
This relation is based on the classical theory of interaction of radiation with an atom. 
Planck evaluated.uν (T ) in terms of entropy of the system of oscillators as follows.156 4 Boltzmann Entropy
If.N is the number of oscillators,.nk the number of oscillators having energy. kε, 
and.Pε total energy of the oscillators, then maximum energy that each oscillator can 
have is.Pε and hence 
.
Σ
P
k=0
nk = N, Σ
P
k=0
knk = P. (4.81) 
Planck defined entropy as 
.SP = kBln(W) + constant, (4.82) 
where .W is the probability of the configuration in which.N atoms have energy .Pε. 
Now,.W = R/J where.J is total number of configurations which is a constant and 
.R is the number of configuration of .N atoms having energy .Pε. Since entropy is 
defined up to the addition of a constant, the expression (4.82) may be rewritten as 
.SP = kBln(R). (4.83) 
The number.R is same as.P(N, L) given by (4.6), with.L = P therein. 
The .R in Planck’s definition of entropy is the number of all configurations cor￾responding to energy .Pε whereas in Boltzmann’s definition (4.78) of entropy, the 
number of configurations considered are only those which correspond to the state 
from among all the states of energy .Pε for which the number of configurations is 
maximum. As noted in (4.23), both give same result under Stirling’s approximation. 
Planck’s entropy is therefore same as Boltzmann entropy in (4.32) in which . u is 
given in terms of temperature by (4.33). Using known empirical laws of blackbody 
radiation, Planck showed that entropy of the oscillator must be a function of.u/ν: 
.SP = f
(u
ν
)
. (4.84) 
On comparing (4.32) and (4.84) it follows that . ε must be proportional to . ν. Hence, 
with.ε = hν, where. h is a constant known now as Planck’s constant. Consequently, 
the expression (4.33) for energy reads 
.uν (T ) = hν
exp(hν/kBT ) − 1
. (4.85) 
Substitution of (4.85) in (4.80) yields Planck’s law of blackbody radiation. 
See [ 3] for discussion of relationship between Planck’s and Boltzmann entropies.4.6 Bose Statistics 157
4.6 Bose Statistics 
Bose re-derived in [ 4] Planck’s formula in an entirely different way. In contrast with 
the approach of Planck which is based on determining the radiation energy in terms 
of the energy of oscillators in the walls of the cavity, approach of Bose as outlined 
below does not require the intermediary of said oscillators and therefore neither of the 
relation (4.80) between energy of the oscillators and the electromagnetic field energy 
in the cavity. In fact, Bose considered this as the triumph of his theory stating All 
existing derivations make use of the relation between the radiation density and mean 
energy of an oscillator (relation (4.80) in the present case) and they make assumptions 
concerning the number of degrees of freedom of ether as exemplified in the above 
equation (the factor.ρν in (4.80)). This factor, however, could be deduced only from 
the classical theory. This is the unsatisfactory point of all derivations and it is not 
surprising that again and again efforts are made which try to give a derivation free of 
this logical deficiency. The unsatisfactory feature of Planck’s and other derivations 
Bose mentioned in the statement quoted above from his paper were highlighted by 
him also in the covering letter he mailed to Einstein along with the manuscript of 
his paper stating: You will see that I have tried to deduce the coefficient.8πν2/c3 in 
Planck’s Law independent of the classical electrodynamics. He requested Einstein 
to arrange for its publication if he finds worth it. 
Following Einstein’s 1905 hypothesis to explain the photoelectric effect, Bose 
considered radiation inside a blackbody as a gas of quanta (named photons by G.N. 
Lewis in 1926) in which energy of a quantum of frequency. ν is.Eν = hν. In accor￾dance with the electromagnetic theory, the magnitude of momentum of the quantum 
of energy .hν is .hν/c in the direction of its propagation. He assumed that the state 
of a quantum is described by its phase space coordinates constituted by its position 
having components.(x, y,z) and momentum having components.(px , py , pz) where 
.p2
x + p2
x + p2
x =
(hν
c
)2
. (4.86) 
He considered the phase space of the quanta in frequency interval.(ν, ν + dν). The 
volume of the said phase space is evidently .dων = VdVν where .V is the spatial 
volume of the region in which the quanta move and .dVν is the volume of the shell 
between the spheres of radii.hν/c and.h(ν + dν)/c given by 
.dVν = 4π
(hν
c
)2 (h
c
)
dν. (4.87) 
Hence 
.dων = 4πVν2
(h
c
)3
dν. (4.88)158 4 Boltzmann Entropy
Bose divided.dων into cells of volume.h3 each. 1 Taking into account two directions 
of polarization, the number.Pν of the phase space cells available to the quanta in the 
frequency interval.(ν, ν + dν) is.2dων /h3: 
.Pν = 8πV
c3 ν2
dν. (4.89) 
Bose evaluated entropy of the system of quanta by following Boltzmann’s approach 
by counting the number of ways of distributing the quanta in the cells. To that 
end, each cell is considered as a box into which quanta are distributed. There is no 
restriction on the number of quanta that a box can contain. Hence, if.nkν is the number 
of boxes that contain. k quanta (.k = 0, 1,...,∞) then the number of configurations 
is given, invoking (4.2), by 
.Pν = Pν !
n0ν !n1ν !···, Pν = Σ∞
k=0
nkν . (4.90) 
The energy.Uν of the gas of quanta of frequency. ν is 
.Uν = hν
Σ∞
k=0
knkν . (4.91) 
Total number of ways of distributing the quanta of all frequencies is 
.P = |∞
ν=0
Pν . (4.92) 
With.Pν given by (4.90), the equation above in Stirling’s approximation yields 
.ln(P) = Σ
ν
[
Pν ln(Pν ) −Σ
k
nkν ln(nkν )
]
. (4.93) 
The.ln(P) above is maximized under the constraints 
.U = Σ
ν
Uν = h
Σ
ν
ν
Σ∞
k=0
knkν , Pν = Σ∞
k=0
nkν , (4.94)
1 It may be mentioned that the idea of dividing phase space into cells was invoked earlier by 
Sackur and Tetrode to derive formula for entropy of the ideal gas which helped them determine the 
undetermined constant in the thermodynamic expression for entropy (see Sect. 7.1.2). 4.6 Bose Statistics 159
where.U is total energy of the gas. Using Lagrange’s method of undetermined mul￾tipliers, it is straightforward to see that the .nkν ’s which maximize (4.92) subject to 
the constraint (4.94) are given by 
.nkν = Aν exp(−kβhν). (4.95) 
Due to second constraint in (4.94), 
.Aν = Pν {1 − exp(−βhν)}, (4.96) 
so that 
.nkν = Pν (1 − exp(−βhν)) exp(−kβhν). (4.97) 
The.ln(Pmax) is obtained by substituting (4.97) in (4.93) so that, due to (4.27), 
.SB,max = Σ
ν
SνB,max, (4.98) 
where.SνB,max is entropy of the quanta of frequency. ν given by 
.SνB = kB
[
βUν − Pν ln(1 − exp(−βhν))]
. (4.99) 
Due to second equation in (4.27) it is straightforward to see that.β = 1/kBT . 
With.nkν as in (4.97) and.β = 1/kBT , it may be verified that 
1. The number of quanta of frequency. ν is 
.Nν = Σ∞
k=0
knkν = Pν
exp(hν/kBT ) − 1
. (4.100) 
2. The energy.Uν of the quanta in the frequency interval.(ν, ν + dν) is 
.Uν = hνNν = hνPν
exp(hν/kBT ) − 1
. (4.101) 
In his paper, Bose mentions number of quanta as a constraint but, without specifying 
any reason, does not use it. We know that the reason for the absence of constraint on 
the number of quanta is due to the fact that their number is not conserved because 
the quanta are continuously created and annihilated. However, as we will see, while 
applying Bose’s formalism to material particles, Einstein uses the said constraint. 
As stated in the beginning of this section, Bose mailed to Einstein the manuscript 
of his paper, written in English, with a request to arrange for its translation and 
publication, if found worth it, in Zeitschrift für Physik. Einstein, impressed by the160 4 Boltzmann Entropy
idea in the paper, himself translated it and sent it for publication in Bose’s name 
with the comment: In my opinion Bose’s derivation of Planck’s formula signifies an 
important advance. The method used also yields the quantum theory of the ideal gas, 
as I will work out in detail elsewhere. 
Einstein submitted his paper [ 5] within 2 weeks after receiving Bose’s paper. The 
paper of Bose and that of Einstein drew widespread criticism for using the distribution 
law of indistinguishable objects in distinguishable boxes thereby treating, without 
stating, the light quanta in the case of Bose and material particles in Einstein’s case 
as indistinguishable particles (see [ 6]). The concept of indistinguishable particles 
was non-existent at the time. Einstein acknowledged this lapse in his second paper 
[ 7] submitted about 6 months later stating therein: 
Mr. Ehrenfest and other colleagues have faulted Bose’s theory of radiation and my analogous 
one for ideal gases for not treating quanta, or molecules, as statistically mutually indepen￾dent structures, without specifically pointing out this circumstance in our papers. This is 
entirely correct. If one treats the quanta as statistically independent of one another in their 
localizations, one arrives at Wien’s radiation law; if one treats gas molecules analogously, 
one arrives at the classical equation of state for ideal gases. Even if one otherwise proceeds 
exactly as Bose and I have done. Here I will compare both considerations for gases in order 
to clearly bring out differences and to be able to compare our results easily with those of the 
theory of independent molecules. 
That the indistinguishability is a puzzling aspect was recognized by Einstein 
while stating later in the same paper by referring to the formula (4.106) for number 
of configurations or complexions treating particles as indistinguishable: 
... the formula indirectly expresses a certain hypothesis about an initially completely puzzling 
mutual influence of the molecules.... 
We outline next the theory mentioned by Einstein in his cited comments. 
4.7 Einstein’s Quantum Theory of Ideal Gas 
Einstein developed the quantum theory of ideal gas by using Bose’s method of 
dividing phase space volume into cells as follows. 
Consider the gas of molecules in a container of volume . V. Consider molecules 
having energy in the interval.(E, E + ΔE). Assume the motion to be non-relativistic 
so that the relation between energy and the magnitude. p of momentum of a molecule 
is .E = p2/2m. Let the magnitude of corresponding momenta be in the interval 
.(p, p + Δp). The volume of the phase space occupied by these molecules is the 
product of the spatial volume .V and the volume .4π p2Δp of the spherical shell 
between the spheres of radii . p and .p + Δp so that the volume of the phase space 
traversed by these molecules is 
.Δω = (2πV)(2m)
3/2
√EΔE. (4.102)4.7 Einstein’s Quantum Theory of Ideal Gas 161
Divide the phase space into cells of volume.h3 each. The number of cells in the phase 
space volume.Δω then is 
.PE = 2πV
h3 (2m)
3/2
√EΔE. (4.103) 
Let .NE be the number of molecules in the interval .(E, E + ΔE). Let .PE denote 
the number of configurations for distribution of .NE molecules in .PE cells. The 
number.PE will depend on whether the molecules are treated as indistinguishable or 
distinguishable. In any case, total number of configurations for all energies is 
.P = |
E
PE, (4.104) 
and the entropy is.S = kBln(P). The equilibrium state is obtained by maximizing. S
with respect to variation in.NE subject to the conditions 
.N = Σ
E
NE , U = Σ
E
E NE , (4.105) 
where.N is total number of molecules. 
In his first paper [ 5] Einstein adopted Bose’s method to determine the number 
of configurations, namely, by grouping the cells by the number of molecules they 
contain and finding the number of boxes in each group that maximize. P. 
In his second paper, Einstein adopted a different approach to evaluate .P which 
could be applied to the system of indistinguishable as well as that of distinguishable 
particles. We outline below the said approach for the cases of (1) indistinguishable 
molecules and (2) distinguishable molecules, and (3) revisit Bose’s system of light 
quanta and (4) extend it to the gas of distinguishable particles obeying exclusion 
principle. 
4.7.1 Indistinguishable Molecules 
The number of configurations resulting from distribution of .NE indistinguishable 
objects in.PE distinguishable boxes is given, recalling (D.23), by 
.PE = (NE + PE − 1)!
(PE − 1)!NE ! . (4.106) 
Using Stirling’s approximation for the logarithm of the factorials in (4.106), the 
expression for entropy reads162 4 Boltzmann Entropy
.S = kB
Σ
E
[(NE + PE )ln(NE + PE ) − PE ln(PE ) − NE ln(NE )] . (4.107) 
Invoking Lagrange’s method of multipliers, it is straightforward to see that the value 
of.NE that maximizes. S, subject to the constraints (4.105), is 
.NE = PE
exp(α + βE) − 1
. (4.108) 
With.NE given by (4.108), (4.107) for entropy reduces to 
.S = kB(αN + βU) − kB
Σ
E
PEln{1 − exp(−α − βE)}. (4.109) 
Using.1/T = (∂S/∂U)V,N follows the relation.β = 1/kBT . Hence, with.PE given 
by (4.103), the number of molecules per unit energy interval in the vicinity of . E
.(nE = NE /ΔE) turns out to be given by 
.nE = 2πV(2m)3/2h−3
√E
exp(α + βE) − 1 , β = 1/kBT. (4.110) 
This is Einstein’s formula for an ideal quantum gas of indistinguishable molecules. 
This is also called Bose–Einstein distribution. We will study the thermodynamics 
of the gas described by it in Chap. 10. 
4.7.2 Distinguishable Molecules 
In case the molecules are distinguishable, the number of ways of distributing . NE
molecules in .PE cells may be determined as follows. Note that there are .PE ways 
of distributing a molecule among.PE cells. Since the molecules are independent and 
distinguishable, total number of ways of distributing .NE molecules would be the 
product of the individual number of ways which is.(PE )NE (see 8.2.1 for alternative 
derivation). Hence the number of distributions for all energy intervals is 
.P1 = |
E
P NE
E . (4.111) 
On multiplying this by the number of ways of choosing.NE molecules from among 
.N follows the expression for the number of configurations: 
.P = |
E
P NE
E
( N!
|
E NE !
)
. (4.112)4.7 Einstein’s Quantum Theory of Ideal Gas 163
The expression.S = kBln(P) for entropy in Stirling’s approximation reads 
.S = kB
Σ
E
[NE ln(PE) − NE ln(NE )] + kB Nln(N). (4.113) 
The expression for.NE which maximizes (4.113) subject to the conditions in (4.105) 
reads 
.NE = PE exp(−α − βE). (4.114) 
Substitution of this in first condition in (4.105), with.PE as in (4.103), yields 
.N = Σ
E
PE exp(−α − βE) ≡ exp(−α)V Z, (4.115) 
where 
. Z = 2π
h3 (2m)
3/2Σ
E
√E exp(−βE)ΔE
= 2π
h3 (2m)
3/2
{ ∞
0
√E exp(−βE) dE = (2πm/h2
β)
3/2
. (4.116) 
Substitute (4.114) in (4.113) for entropy to get 
.S = kB{Nln(V) + Nln(Z) + Uβ}, (4.117) 
Using.1/T = (∂S/∂U)V,N we get.β = 1/kBT , and using.P/T = (∂S/∂V )U,N we 
obtain 
.PV = N kBT, (4.118) 
which is the equation of state of an ideal classical gas. 
4.7.3 Distribution of Light Quanta 
Planck’s law of blackbody radiation was derived in Sect. 4.6 using Bose’s method 
of counting the number of different ways of distributing identical quanta in phase 
space cells. We re-derive that law now applying Einstein’s method of counting the 
distributions. 
To that end, recall from Sect. 4.6 that the number .Pν of cells in the phase space 
of the light quanta in the frequency interval .(ν, ν + dν) is given by (4.89) and the 
number of quanta in those cells is denoted by .Nν . In Einstein’s formulation, the 
number .Pν of ways of distributing those .Nν indistinguishable quanta in .Pν cells is164 4 Boltzmann Entropy
given by (4.106) with.PE → Pν ,.NE → Nν therein: 
.Pν = (Nν + Pν − 1)!
(Pν − 1)!Nν ! , (4.119) 
whereas the entropy in Stirling’s approximation is 
.S = kB
Σ
ν
[(Nν + Pν )ln(Nν + Pν ) − Pν ln(Pν ) − Nν ln(Nν )] . (4.120) 
The equilibrium distribution is found by maximizing. S subject to: 
.U = h
Σ∞
ν=0
νNν . (4.121) 
In the present case, there is no condition on total number of quanta because they are 
continuously created and absorbed in the wall. The values of the.Nν ’s for which. S is 
maximum with respect to variation of.Nν , subject to the condition (4.121) is 
.Nν = Pν
exp(βhν) − 1
. (4.122) 
With.β = 1/kBT this is same result as has been derived by Bose’s method. 
4.8 Distribution of Particles Obeying Exclusion Principle 
We can apply Bose’s concept of dividing the phase space into cells of volume . h3
to determine distribution of indistinguishable particles obeying exclusion principle, 
i.e. particles which are such that only one of them can occupy a state. That being the 
case, the number of configurations of .NE such particles in .PE cells in the interval 
.(E, E + ΔE) of energy would be the number of ways one can choose.NE cells from 
among the.PE to accommodate.NE molecules. It is given by 
.PE = PE !
(PE − NE )!NE !
. (4.123) 
The entropy in Stirling’s approximation in this case is 
.S = kB
Σ
E
[PE ln(PE ) − (PE − NE )ln(PE − NE ) − NE ln(NE )] . (4.124) 
Invoking Lagrange’s method of multipliers, the.NE which maximizes. S above subject 
to the conditions (4.105) turns out to be given byReferences 165
.NE = PE
exp(α + βE) + 1
. (4.125) 
Substitution of this in (4.124) results in the following expression for entropy: 
.S = kB(αN + βU) + kB
Σ
E
PE ln{1 + exp(−α − βE)}. (4.126) 
Applying relation.1/T = ∂S/∂U we see that.β = 1/(kBT ). The resulting distribu￾tion is called Fermi–Dirac distribution. We will study the thermodynamics of the gas 
described by it in Chap. 9. 
References 
1. L. Boltzmann, K. Akademie der Wissenschaften Mathematisch-Natyrwissen Classe. Abt. II, 
LXXVI, 1877, 373–435 (Wien. Ber. 1877 76, 373–435). Reprinted in Wiss. Abhandlungen, 
Vol. II, reprint 42, pp. 164–233, Barth, Lepzig, 1909). English translation with commentary by 
K. Sharp, F. Matschinsky, Entropy, 17, 1971–2009 (2015) 
2. M. Planck, Ann. der Phys. 4 553 (1901) 
3. M. Nauenberg, Am. J. Phys. 84 709 (2016) 
4. S.N. Bose, Zeitschrift für Physik 27, 384 (1924). English translation with commentary by O. 
Theimer, B. Ram, Am. J. Phys. 44, 1057 (1976) 
5. A. Einstein, Zeitschrift für Physik 22, 261 (1924). English translation in Cpllected Papers of 
Albert Einstein 
6. M. Delbruck, J. Chem. Edu. 57, 467 (1980) 
7. A. Einstein, Zeitschrift für Physik 22, 261 (1924). English translation in Cpllected Papers of 
Albert EinsteinChapter 5 
Shannon and Statistical Entropies 
In Chap. 2, we saw that the thermodynamic variables are expressible in terms of 
various partial derivatives of entropy. The link between mechanical and thermo￾dynamic descriptions may therefore be established by identifying suitably defined 
mechanical entropy, i.e. entropy defined in terms of mechanical variables with ther￾modynamic entropy. In Chap. 4, we saw that identification of Boltzmann entropy with 
thermodynamic entropy provides the desired link when particles are non-interacting. 
We will see that entropy for systems of.N interacting particles, identifiable with ther￾modynamic entropy, is Gibbs entropy [ 1] defined in terms of.N-particle phase space 
distribution function. The Boltzmann entropy for the gas of .N molecules on the 
other hand is in terms of single-particle distribution function. It does not depend on 
inter-particle interaction even when inter-particle interaction is present and does not 
correspond to thermodynamic entropy in the presence of inter-particle interaction [ 2]. 
Since it is constructed in terms of phase space distribution function, Gibbs entropy 
cannot describe quantum systems as there is no concept of phase space in quantum 
mechanics. The quantum von Neumann entropy, introduced in Chap. 13, serves the 
desired purpose. A simpler approach, adequate for describing widely encountered 
thermodynamic systems, is Shannon entropy [ 3] (see also [Balian] and [ 4]). Its origin 
is in the information theory and is applicable to any situation described statistically. 
In this chapter, we introduce the concept of Shannon entropy for discrete as well as 
continuous probabilities using which we define entropy for quantum and classical 
mechanical systems called the statistical entropy. We will see that the entropy so 
defined in terms of continuous probabilities is same as Gibbs entropy. 
5.1 Shannon Entropy 
In this section, we introduce the concept of Shannon entropy for discrete as well as 
for continuous probabilities. 
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4_5 
167168 5 Shannon and Statistical Entropies
5.1.1 Discrete Probabilities 
Let .x be a random variable capable of assuming .n discretely spaced values 
.{x1, x2,..., xn}. Let.p(xk ) be the probability that the value realized in some event is 
. xk . The probabilities are such that.0 ≤ p(xk ) ≤ 1 and 
.
Σn
k=1
pk = 1, pk ≡ p(xk ). (5.1) 
If .pi < pj then the occurrence of .xi in repeated experiments is rarer than that of 
. x j . In other words, occurrence of .xi is more uncertain than that of . x j . Hence the 
occurrence of. xi may be viewed as removing greater uncertainty or contributing more 
to the information about . x than the occurrence of . x j . Accordingly, it is postulated 
that the gain in information on observing the realization of the value. xi of the random 
variable. x is a function of the probability of the occurrence of that value. It is denoted 
by.I(pi). From the discussion above we see that.I(pi) > I(pj) if.pi < pj . 
Now, consider two random variables,. x and. y where. x is as above and. y takes. m
values.{y1, y2,..., ym} with probabilities.{q1, q2,..., qm} where.qk ≡ q(yk ). Let. x
and. y be independent so that the joint probability of observation of the value.xi of. x
and .yk of . y in an event is .piqk . The information gain due to the said observation is 
.I(piqk ). Since they are independent, the information gained by the said joint event 
must be the sum .I(pi) + I(qk ) of the information gained from the occurrence of 
those events individually. Hence follows the relation 
.I(piqk ) = I(pi) + I(qk ). (5.2) 
This equation is solved by.I(p) = k,
ln(p) where. k, is a constant. Since information 
is to be a positive quantity and .0 ≤ p ≤ 1, .k, must be negative. The .I(p) is then 
defined as 
.I(p) = −kln(p), k > 0. (5.3) 
The constant. k is arbitrary and only defines the scale for the measurement of infor￾mation. 
Average gain in information in a large number of realizations of. x is clearly 
.S({pi}n) ≡ S(p1, p2,..., pn) = −k
Σn
i=1
pi ln(pi), (5.4) 
with.0ln(0) = 0. The.S({pi}n) is called Shannon entropy associated with the proba￾bility distribution.p1, p2,..., pn.5.1 Shannon Entropy 169
We list below some properties of.S({pi}n). 
1. It follows immediately from its expression (5.4) that entropy is positive. 
2. If .pk = 1 for some . k, .pj = 0 .(j /= k) so that .S({pi}n) = 0. This means, since 
there is no uncertainty about an outcome when the variable can take only one 
value (.xk in the present example), there is no gain in information when that value 
is realized. 
3. If all the outcomes occur with equal probability then .pi = 1/n and the corre￾sponding entropy is 
.S({pi}n) = −k
n
Σn
i=1
ln (1
n
)
= kln(n). (5.5) 
In Sect. 5.2, we will show that this is the maximum entropy for an.n-valued random 
variable. Hence, for a random variable which can assume. n values, 
.0 ≤ S({pi}n) ≤ kln(n). (5.6) 
4. It can be shown that .S({pi}n) is a concave function in the sense elaborated in 
Appendix C. It has been shown therein that a function is concave if its second 
derivative is negative (see C.9)). We prove the concavity of.S({pi}n) by examining 
its second derivative. 
Consider.F(x) defined by 
.F(x) = −xln(x), x ≥ 0. (5.7) 
Since .d2F(x)/dx 2 = −1/x < 0 for .x > 0, it follows that .F(x) is concave. 
Rewrite the expression (5.4) for Shannon entropy as 
.S({pi}n) = Σn
i=1
Fi(pi), Fi(pi) = −kpi ln(pi). (5.8) 
The.Fi(pi)/k is same as the function.F(x) defined in (5.7) with.x → pi . Hence 
.Fi(pi) is concave. This shows that each term in the summation in (5.8) is concave 
whereby it follows that.S({pi}n) is concave which proves our assertion. 
Being concave, each.Fi(pi) obeys the inequality (C.5) due to which, 
.Fi(λpi + (1 − λ)qi) ≥ λF(pi) + (1 − λ)F(qi), 0 ≤ λ ≤ 1. (5.9) 
On using this in (5.8) follows the inequality 
.S({λpi + (1 − λ)qi}n) ≥ λS({pi}n) + (1 − λ)S({qi}n). (5.10)170 5 Shannon and Statistical Entropies
To understand the physics meaning of the inequality above, consider two sources, 
say. A and. B, emitting same particles in one of the. n states. Let the probability with 
which the particles are emitted in the state labeled. i by the source. A be.pi and that 
for the particles emitted by the source. B be. qi (.i = 1, 2,..., n). The entropy of the 
particles emitted by. A is.S({pi}n) and that of the particles emitted by. B is.S({qi}n). 
Assume that the sources .A and .B are emitting particles with rate .rA and . rB, 
respectively. The fraction of particles coming from the source. A in time. t will be 
.λ = rA/(rA + rB) and that from. B in the same time will be.rB/(rA + rB) ≡ 1 − λ. 
Hence the probability of finding a particle in the state labeled. i from the mixture of 
the emitted particles is evidently.λpi + (1 − λ)qi . The left side of the inequality 
(5.10) is the entropy corresponding to the said probability. On the other hand, if 
the particles were not mixed then the average entropy of the particles emitted by 
the two sources would have been.λS({pi}n) + (1 − λ)S({qi}n) which is the right 
side of the inequality (5.10). 
The inequality (5.10) thus shows that if two probabilities .{pi}n and .{qi}n are 
mixed then the entropy of the mixture is higher than the average entropy of 
individual probabilities. In other words, the uncertainty of finding an object in the 
mixture increases than that when it is in the group it originally belonged to. This 
is intuitively understandable as well. 
In general, if .{p(j)
i }n .(j = 1, 2,..., k) are . k probability distributions all for the 
same random variable. x then 
.S
⎛
⎝Σ
k
j=1
λj{p(j)
i }n
⎞
⎠ ≥ Σ
k
j=1
λj S
(
{p(j)
i }n
)
, Σ
k
j=1
λj = 1. (5.11) 
This will prove useful in proving the second law of thermodynamics. 
5.1.2 Continuous Probabilities 
The concept of Shannon entropy for random variables assuming discrete values can 
be extended to the ones assuming continuous values as follows (see also [ 4]). 
Let . x be a real random variable which assumes values in the domain .[a, b]. Let 
.p(x) be the probability density such that 
.dw = p(x)dx (5.12) 
is the probability that the value of. x is in.(x, x + dx) with 
.
{ b
a
p(x) dx = 1. (5.13)5.1 Shannon Entropy 171
Shannon generalized the expression (5.4) of entropy for discrete variables to con￾tinuous ones in straightforward manner by replacing discrete probabilities by the 
continuous one and the summation by integral to define the entropy associated with 
the probability density.p(x) as 
.S(p(x)) = −k
{ b
a
p(x)ln(p(x)) dx. (5.14) 
However, as we will see, if standard mathematical method is followed to convert a 
discrete sum to an integral in the limit of the discrete variable assuming continuous 
values then extra blowing up term appears in the resulting expression so obtained. 
To that end, we relate the problem of continuous valued random variable with that 
of a discrete variable as follows. Divide the interval.a ≤ x ≤ b into. n bins of length 
. E each by the points .a = x0, x1,..., xn = b where .E = (b − a)/n with .n → ∞, 
.E → 0 but .nE = b − a remaining finite. Denote by . fi the probability that . x takes 
value in the bin.(xi−1, xi) (.i = 1, 2,..., n). Using (5.12), the probability. fi can be 
expressed in terms of the probability density.p(x) as 
. fi = Ep(xi), i = 1, 2,..., n. (5.15) 
The set . f1, f2,..., fn defines probability distribution for a random variable which 
takes discrete values, each lying in one or the other bin defined above. The Shannon 
entropy corresponding to the said set is therefore given by 
. S = −k
Σn
i=1
fi ln( fi) = −k
Σn
i=1
Ep(xi)ln(Ep(xi))
= −k
Σn
i=1
Ep(xi)[ln(p(xi)) + ln(E)] . (5.16) 
Invoking the definition of Riemann integral, 
.LtE→0
(
E
Σn
i=1
F(xi)
)
=
{ b
a
F(x) dx, (5.17) 
we have 
. LtE→0
(
E
Σn
i=1
p(xi)ln(p(xi)))
=
{ b
a
p(x)ln(p(x)) dx,
LtE→0
(
E
Σn
i=1
p(xi)
)
=
{ b
a
p(x) dx = 1, (5.18)172 5 Shannon and Statistical Entropies
where last equation is due to the normalization condition (5.13). Consequently, in 
the limit.E → 0, (5.16) reduces to 
.S(p(x)) = −k
{ b
a
p(x)ln(p(x)) dx − kLtE→0ln(E). (5.19) 
The first term in the expression above is same as Shannon’s expression (5.14) but the 
second term blows as .E → 0. Since it does not depend on .p(x), that term will not 
matter if interest is in the difference in entropy associated with different probability 
densities. Else (5.14) can be understood as the expression for entropy associated with 
the probability density of a continuous valued random variable with the second term 
in (5.19) as its zero. 
Equation (5.14) is taken as the definition of Shannon entropy when the random 
variable takes continuous values. 
It must, however, be pointed out that .S(p(x)) does not share all the properties 
of the entropy of a discrete valued random variable. Some such important differing 
properties are 
1. Unlike.S({pi}n),.S(p(x)) need not be positive (see Ex. 5.1). 
2. .S({pi}n) does not change under transformation of. x. However,.S(p(x)) may not 
be invariant under transformation of. x. For, let. x be transformed to. y by the relation 
.x = x(y) so that the distribution.p(x) transforms to.q(y) = p(x(y)) such that 
.p(x)dx = q(y)dy = q(y)
|
|
|
|
dy
dx
|
|
|
|
dx. (5.20) 
It is straightforward to see that 
. S(p(x)) = −k
{ b
a
p(x)ln(p(x)) dx
= −k
{
q(y)ln(q(y)) dy − k
{
q(y)ln(|dy/dx|) dy
= S(q(y)) − k
{
q(y)ln(|dy/dx|) dy. (5.21) 
This shows that entropy of the distribution obtained by transformation of the 
random variable need not be same as that for the distribution of the original 
variable. See Exercises 5.3 and 5.4 for examples. 
Exercises 
Ex. 5. 1. Show that the entropy for the exponential distribution function 
.p(x) = λ exp(−λx), λ > 0, 0 ≤ x ≤ ∞ (5.22) 
is given by.S = k(1 − ln(λ)). This becomes negative for.λ > e.5.2 Maximum Entropy 173
Ex. 5. 2. Show that the entropy for the distribution function 
.p(x) = Ax 2 exp(−αx 2
), α > 0 0 ≤ x ≤ ∞, A = 4
/α3
π (5.23) 
is given by 
.S/k = γ +
1
2
ln (π
α
)
− 1
2
, (5.24) 
where. γ is Euler’s constant. Hint: You may need to use the formula 
.
{ ∞
0
x 2 ln(x 2
) exp(−αx 2
)dx = 1
4
/ π
α3 (2 − γ − ln(4α)). (5.25) 
Ex. 5. 3. Show that.S(p(x)) = S(p(x + a)), where. a is a constant. This shows that 
entropy is invariant under translation of the random variable. 
Ex. 5. 4. Show that the entropy .S(q(y)) for .q(y) where .y = ax is related with the 
entropy for.S(p(x)) where.q(y) = p(x(y)) by the relation 
.S(q(y)) = S(p(x)) + kln(|a|). (5.26) 
This shows that entropy is not invariant under the given transformation. 
5.2 Maximum Entropy 
We will see that a problem of interest in statistical mechanics is to find the probability 
distribution for which entropy is maximum subject to chosen constraints on the 
moments of the random variables. In view of that we outline the method of evaluating 
maximum entropy separately for discrete and continuous probabilities. 
5.2.1 Discrete Variables 
Consider a random variable. x capable of taking. n values according to the probabilities 
.{pi}n. The. pi’s are subject to the normalization condition (5.1) and possibly additional 
. r conditions: 
.⟨Am(x)⟩ ≡ Σn
i=1
Am(xi)pi = Cm, m = 1, 2,...,r, (5.27) 
where.Am(x) is a function of the random variable. x and.Cm a given constant. We find 
the extremum of.−S({pi}n)/k, subject to the normalization condition (5.1) and the174 5 Shannon and Statistical Entropies
constraints in (5.27), by the method of Lagrange multipliers. It consists of finding, 
as a function of the. pi’s, the extremum of.F({pi}n) defined by 
.F({pi}n) = − S({pi}n)
k + α0
Σ
i
pi +Σr
m=1
αm⟨Am(x)⟩, (5.28) 
where the . αi’s are so-called Lagrange multipliers. The extremum of .F({pi}n) is 
determined by the solution of the equations, 
.
∂F({pi}n)
∂ pi
= 0, i = 1, 2,..., n. (5.29) 
With.F({pi}n) as in (5.28) wherein.S({pi}n) is given by (5.4), (5.29) yields 
.1 + ln(pi) + α0 + Σr
m=1
αm Am(xi) = 0. (5.30) 
This is solved by 
.pi = C exp(
−Σr
m=1
αm Am(xi)
)
, (5.31) 
where.C = exp(−1 − α0) is independent of. i. Using the normalization condition,. C
turns out to be given by 
.C−1 = Σn
i=1
exp(
−Σr
m=1
αm Am(xi)
)
. (5.32) 
The.αm’s are determined by (5.27) defining the constraints. 
Equation (5.31) is the desired result determining the probabilities for which 
.S({pi}n) is extremum subject to the normalization condition and the constraints 
(5.27). Though not shown here, the extremum is in fact a maximum. We will refer 
to the extremum condition on. S as the condition of its maximum. 
As an example, assume that the normalization condition is the only constraint. 
The probabilities which maximize .S({pi}n) in this case are given by (5.31) with 
.αm = 0 so that .pi = C. With .C given by (5.32) we get .pi = 1/n. Thus, if there is 
no constraint other than the normalization, the maximum entropy is obtained when 
all the outcomes occur with equal probability.5.2 Maximum Entropy 175
5.2.2 Continuous Variable 
Let. x be a random variable taking continuously varying values in the domain. [a, b]
according to the probability distribution.p(x). The.p(x) is subject to the normaliza￾tion condition (5.13) and possibly. r other conditions, 
.⟨Am(x)⟩ ≡ { b
a
Am(x)p(x) dx = C,
m m = 1, 2,...,r. (5.33) 
To determine.p(x)for which entropy.S(p(x)), defined in (5.14), is maximum subject 
to the conditions (5.13) and (5.33), we follow the method of Lagrange multipliers 
which involves finding the extremum of the function 
.F(p(x)) = − S
k + α0
{ b
a
p(x) dx + Σr
m=1
αm⟨Am(x)⟩, (5.34) 
where. αi’s are the Lagrange multipliers. The extremum is determined by the solution 
of the equation 
.
∂F(p(x))
∂ p(x) = 0. (5.35) 
For.F(p(x)) defined in (5.34), with.S(p(x)) as in (5.14), (5.35) yields 
.1 + ln(p(x)) + α0 +Σr
m=1
αm Am(x) = 0. (5.36) 
This is solved by 
.p(x) = C exp(
−Σr
m=1
αm Am(x)
)
, (5.37) 
where. C is independent of. x, determined by the normalization condition as 
.C−1 =
{ b
a
exp(
−Σr
m=1
αm Am(x)
)
dx. (5.38) 
The.αm’s are determined by (5.33) defining the constraints. 
As an example, let the probability distribution be subject to no constraint other than 
the normalization. Maximum entropy is then given by (5.37) with.αm = 0 yielding 
.p(x) = C, where from (5.38) we get .C = 1/(b − a). Thus the distribution giving 
maximum entropy subject to no constraint other than the normalization is uniform. 
Based on the concept of Shannon entropy, we introduce that of statistical entropy 
of a dynamical system.176 5 Shannon and Statistical Entropies
Exercises 
Ex. 5. 5. Let . x be a random variable assuming values in the interval .[0,∞]. Show 
that among all the distributions having given value. a of the average.⟨x⟩, the 
exponential distribution 
.p(x) = 1
a exp(−x/a) (5.39) 
has maximum entropy. 
Ex. 5. 6. Let. x be a random variable assuming values in the interval.(−∞,∞). Show 
that among all the distributions having given value. a of the average.⟨x⟩ of 
. x and the variance.σ2 = ⟨x 2⟩−⟨x⟩2 the Gaussian distribution 
.p(x) = 1
√
2πσ2 exp{−(x − a)
2
/(2σ2
)} (5.40) 
has maximum entropy. 
5.3 Statistical Entropy 
As discussed in Sect. 3.3, the observed value of an observable is the average over 
its values in the microstates which the system passes through during the time of 
observation. However, every microstate may not be visited with same frequency. 
Following Gibbs, we represent the set of microstates as a collection or an ensemble 
in which a microstate is represented as many number of times as it occurs during the 
process of time averaging. Different external conditions define different ensembles. 
Thermodynamic properties of a system are described in terms of the probabilities with 
which its microstates are occupied. Construction of the probabilities characterizing 
a system in thermodynamic equilibrium is based on the concept of statistical entropy 
introduced next, separately for quantum and the classical systems. 
5.3.1 Classical Systems 
Consider a system of.N particles described, in the notation of Chap. 3, by the Hamil￾tonian.H({ri, pi}N ). Recall also from that chapter that the mechanical state of such 
a system is described by the phase space distribution function . fN ({ri, pi}N ;t) in 
terms of which the average value of an observable.O(r, p) is given by 
.⟨O(t)⟩ = {
O({ri, pi}N ) fN ({ri, pi}N ;t)dτN , (5.41)5.3 Statistical Entropy 177
with 
.dτN = dτ ,
N
N!h3N , dτ ,
N = |
N
i=1
d3
rid3
pi, (5.42) 
where . h is Planck’s constant and the factor .N! is included in case .N particles con￾stituting the system are identical. Note that, in contrast with.dτN above, the averages 
have been defined in Chap. 3 by taking .dτ ,
N as the volume element. The factor . N!
in the volume element given above was conjectured for resolving Gibbs’ paradox, 
discussed in Sect. 7.6. We will see that, in appropriate limit, the quantum theoretic 
formalism reduces to that based on the phase space formalism when the phase space 
volume element is taken as in (5.42). The normalization condition on. fN ({ri, pi}N ;t)
accordingly reads 
.
{
fN ({ri, pi}N )dτN = 1. (5.43) 
The Shannon entropy corresponding to. fN ({ri, pi}N ;t) is 
.SN ( fN ) = −kB
{
fN ({ri, pi}N ;t)ln( fN ({ri, pi}N ;t)) dτN . (5.44) 
The constant. kB, arbitrary at this stage, is determined by comparing the predictions 
based on entropy defined above with the corresponding ones of thermodynamics. 
The.kB will turn out to be same as the Boltzmann constant. 
The entropy defined above constitutes the basis for determining thermodynamics 
of a system in terms of the probability distribution which in turn is determined by 
the Hamiltonian governing its motion linking thereby statistical mechanical and the 
thermodynamic descriptions. It is called the statistical entropy of classical systems. 
5.3.2 Quantum Systems 
To link the mechanical and the thermodynamic descriptions, we introduced above 
the notion of statistical entropy. It is in terms of the phase space distribution function 
which is a function of the positions and momenta of the particles constituting the 
system. However, since position and momentum of a particle cannot be assigned 
precise values simultaneously in the quantum theory, the mechanical state of a particle 
in quantum theory cannot be characterized in terms of its position and momentum. 
Hence, the concept of phase space distribution function does not exist in quantum 
theory. We therefore need a different approach, described below, to identify the 
quantum analog of the phase space statistical entropy. 
To that end, consider a quantum system of.N particles described by the Hamilto￾nian.HˆN (a letter with caret on it represents an operator). Let. {|Ei N ⟩} ≡ |E1N ⟩, |E2N ⟩,...
be the eigenstates of.HˆN corresponding to the energies.E1N , E2N ,.... At any instant 
of time, the system will be in the state of one of the said energies. As it evolves,178 5 Shannon and Statistical Entropies
let.pmN denote the probability that it is found in the state of energy.EmN . Statistical 
mechanics describes the thermodynamic properties of the system in terms of the set 
of probabilities.{pmN } ≡ p1N , p2N ,.... 
The link between statistical mechanics and thermodynamics is established by the 
Shannon entropy associated with the probabilities.{pmN }: 
.SN ({pi N }) = −kB
Σ
m
pmN ln(pmN ), (5.45) 
with 
.
Σ
m
pmN = 1. (5.46) 
The.SN defined in (5.45) is statistical entropy of quantum systems. We will see that 
the expression (5.45) for entropy is same as the von Neumann entropy introduced in 
Chap. 13. 
The phase space distribution and the quantum probabilities depend on time if the 
system is not in equilibrium. We addressed the question of time evolution of the phase 
space distributions in Chap. 3 on the kinetic theory. The question of time evolution 
of the quantum probabilities is addressed briefly in Chaps. 13 and 14. Our interest 
is, however, in the equilibrium state. It is described by the probabilities obtained 
as the solution of the time-dependent equations in the limit .t → ∞. That approach 
to determine the equilibrium state is generally a formidable task. However, as we 
saw in Chap. 4, Boltzmann showed that the equilibrium state of the non-interacting 
gas can be obtained without solving any time-dependent equation as the one which 
maximizes the entropy defined by him. The statistical entropy is for any system 
including the ones consisting of interacting molecules. The equilibrium state of a 
macroscopic system in general is postulated to be the one in which its statistical 
entropy is maximum. In Chap. 6, we construct equilibrium states under different 
external constraints based on the postulate of maximum statistical entropy. 
References 
1. J.W. Gibbs, Elementary Principles in Statistical Mechanics (Dover Publications, 2014. First 
published by Yale University Press, 1902) 
2. E.T. Jaynes, Am. J. Phys. 33, 391 (1965) 
3. C.E. Shannon, Bell Syst. Tech. J. 27, 379 (1948) 
4. T.M. Cover, J.A. Thomas, Elements of Information Theory (John Wiley & Sons, 2006)Chapter 6 
Equilibrium Distributions 
In Chap. 5 we introduced statistical entropy defined in terms of probabilities of 
molecular distribution in the energy levels. The energy levels may be discrete or 
continuous. In this chapter we find the said probability distributions when the system 
attains thermodynamic equilibrium subject to constraints on it. The probability dis￾tribution in question for a system in the state of equilibrium is determined based on 
the principle of maximum entropy. The entropy so obtained is identified as the ther￾modynamic entropy. This enables one to establish relationship between statistical 
mechanical and thermodynamic descriptions. 
6.1 Principle of Maximum Entropy 
In Chap. 5 we introduced the concept of statistical entropy in terms of the phase 
space distribution function for classical systems and the probabilities of occupation 
of energy levels when the system is quantized. The evolution of the said probabilities 
is governed by relevant equations of motion and it is expected that the distributions 
approaches a definite limit, called the equilibrium distribution, as.t → ∞. The ther￾modynamic properties derived from the statistical entropy corresponding to the said 
equilibrium distribution are expected to match with the thermodynamic predictions 
in the so-called thermodynamic limit.N → ∞,.V → ∞,.N/V remaining finite. 
As we noted in the kinetic theory, the approach based on determining the equilib￾rium distribution as the.t → ∞ limit of time-dependent distribution is, however, not 
simple and in fact may not always be possible to work with. Going by the fact that 
the state of thermodynamic equilibrium is one in which thermodynamic entropy is 
maximum, it is envisaged that it would be the state of maximum statistical entropy 
too. Accordingly, the equilibrium distribution is determined using the postulate of 
maximum entropy: 
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4_6 
179180 6 Equilibrium Distributions
The state of thermal equilibrium is described by such probability distribution of 
microstates for which the statistical entropy is maximum subject to the constraints 
on the system. 
The constraints of general interest are the ones pertaining to whether the system 
exchanges energy and/or particles with its environment. Those constraints define 
three types of ensembles: 
1. Microcanonical ensemble. It represents a system which is isolated and exchanges 
neither energy nor particles with the environment. 
2. Canonical ensemble. It represents a system which exchanges energy but not par￾ticles with the environment. 
3. Grand Canonical ensemble. It represents a system which exchanges energy as 
well as particles with the environment. 
In the following sections we derive the probabilities for each of the above-mentioned 
ensembles. We treat separately the systems having fixed number of particles and the 
ones which exchange particles with the environment. 
6.2 Systems Having Fixed Number of Particles 
Following Chap. 5, 
1. We denote by .|E1N ⟨, E2N ⟨,... the energy eigenstates of the Hamiltonian . HˆN
governing the evolution of the quantum system of .N particles and by .pmN the 
probability of occupation of.|EmN ⟨. 
2. A classical system of.N particles whose evolution is governed by the Hamiltonian 
.H({ri, pi}N ) is described by the phase space distribution function. fN ({ri, pi}N ). 
Accordingly, the averages are defined by 
1. In the quantum formalism, the average for a fixed number of particles of an 
operator.Oˆ (caret on a symbol denotes operator) commuting with the Hamiltonian 
is given by 
.⟨Oˆ⟨N = Σ
m
pmN ⟨EmN |Oˆ|EmN ⟨, quantum systems. (6.1) 
The general case of an arbitrary.Oˆ is addressed in Chap. 13 in terms of the density 
matrix formalism. 
2. The average of a phase space function .O({ri, pi}N ) in the classical theory for 
fixed number of particles is given by 
.⟨O⟨N =
{
fN ({ri, pi}N )O({ri, pi}N ) dτN , classical systems. (6.2)6.2 Systems Having Fixed Number of Particles 181
In particular the expressions for entropy for the two kinds of systems are: 
1. The quantum statistical entropy for fixed number of particles is 
.SN = −kB
Σ
m
pmN ln(pmN ). (6.3) 
2. The classical statistical entropy for fixed number of particles is 
.SN = −kB
{
fN ({ri, pi}N )ln( fN ({ri, pi}N )) dτN . (6.4) 
We extremize.SN subject to the normalization of the probabilities: 
.
Σ
m
pmN = 1, quantum systems, (6.5) 
.
{
fN ({ri, pi}N ) dτN = 1, classical systems. (6.6) 
and the constraints 
.⟨Aˆ(k)
⟨ ≡ Σ
m
pmN A(k)
mN ≡ Ck , k = 1, 2,...,r, (6.7) 
where.Aˆ(k)
’s are assumed to commute with the Hamiltonian of the system, the.Ck ’s 
are constants and 
.A(k)
mN = ⟨EmN |Aˆ(k)
|EmN ⟨. (6.8) 
For the classical system, the constraints are given by the equations 
.⟨A(k)
({ri, pi}N ⟨ = Ck , k = 1, 2,...,r. (6.9) 
Invoking the results derived in Sect. 5.2, the probability distribution which maximizes 
the statistical entropy for the quantum systems may be seen to be given by 
.pmN = 1
ZN
exp (
−Σr
k=1
αk A(k)
mN )
. (6.10) 
The normalization condition (6.5) for quantum systems gives 
.ZN = Σ
m
exp (
−Σr
k=1
αk A(k)
mN )
. (6.11)182 6 Equilibrium Distributions
The.ZN is called the.N-particle quantum partition function. 
The phase space distribution function which maximizes the classical statistical 
entropy reads 
. fN ({ri, pi}N ) = 1
ZN
exp (
−Σr
k=1
αk A(k)
({ri, pi}N )
)
. (6.12) 
The normalization condition (6.6) for classical systems leads to 
.ZN =
{
exp (
−Σr
k=1
αk A(k)
({ri, pi}N
)
dτN . (6.13) 
The.ZN is the classical partition function. 
In the following we list some consequences following from the form of the equi￾librium probabilities. We will work with the quantum formalism as the corresponding 
classical results follow by replacing the quantum averages by the classical ones. 
1. It is readily seen that 
.⟨Aˆ(k)
⟨=−
∂ln(ZN )
∂αk
, k = 1, 2,...,r. (6.14) 
The Lagrange multipliers.{αk } can be determined in terms of given constant values 
of.{⟨Ak ⟨} by inverting the equations above. 
2. We leave it as an exercise to show that the expression (6.3) for entropy assumes 
the form 
.
SN
kB
= Σr
k=1
αkCk + ln(ZN ), Ck ≡ ⟨Aˆ(k)
⟨. (6.15) 
Due to (6.14), it is readily seen that.S/kB is the Legendre transform of.ln(ZN ) with 
respect to the.αk ’s to the corresponding conjugate variables.Ck ’s. This implies 
.αk = 1
kB
∂SN
∂Ck
. (6.16) 
This may alternatively be obtained by partial differentiation of (6.15) with respect 
to.Ck keeping.αk ’s fixed and noting that.ZN is a function of the.αk ’s. 
3. It is straightforward to see that 
.⟨Aˆ(k)2
⟨ =
1
ZN
∂2ZN
∂α2
k
, k = 1, 2,...,r. (6.17) 
We leave it as an exercise to show that the variance in the measurement of.Aˆ k is 
given by6.2 Systems Having Fixed Number of Particles 183
.σ2
k ≡ ⟨Aˆ(k)2
⟨−⟨Aˆ(k)
⟨
2 = ∂2ln(ZN )
∂α2
k
. (6.18) 
We use the results derived above to construct ensembles for systems with fixed num￾ber of particles, namely, microcanonical and canonical ensembles. 
Exercises 
Ex. 6.1. Show that for.pmN as in (6.10), the expression (6.3) for entropy is given by 
(6.15). 
Ex. 6.2. Show that 
.⟨Aˆ(k)
j Aˆ(k)
k ⟨−⟨Aˆ(k)
j ⟨⟨Aˆ(k)
k ⟨ =
∂2ln(ZN )
∂αjαk
. (6.19) 
For. j = k we recover (6.18). 
6.2.1 Microcanonical Ensemble 
The microcanonical ensemble describes an isolated system. It is characterized by 
a constant number of particles whereas its energy .E is given to lie in some small 
interval (.E0 − Δ, E0 + Δ) about a fixed value .E0. Since in this case, apart from 
the normalization condition, there is no other constraint,.αk = 0. Consequently, the 
general equilibrium distributions (6.10) and (6.12) lead to the following results for 
quantum and classical systems: 
1. With.αk = 0 the (6.12) for classical systems reduces to 
. fN ({ri, pi}N ) = 1
ZN
, (6.20) 
where.ZN is given by (6.13) in which the integral is to be carried on the part of 
the phase space for which energy .E lies in the interval .(E0 − Δ, E0 + Δ) so 
that if.Γ is the volume of the said part then 
.ZN =
{
E0−Δ≤E≤E0+Δ
dτN = Γ. (6.21) 
The.ZN above is the classical microcanonical partition function. The equilibrium 
phase space distribution for the microcanonical ensemble is thus given by 
. fN ({ri, pi}N ) = 1
Γ , E0 − Δ ≤ E ≤ E0 + Δ. (6.22)184 6 Equilibrium Distributions
On substituting this in (6.4), the expression for entropy for a classical system 
described by microcanonical ensemble reads 
.SN = kBln(Γ ). (6.23) 
2. For quantum systems, with.αk = 0, (6.10) reduces to 
.pmN = 1
ZN
, (6.24) 
where .ZN , given by (6.11), is a sum over states in the energy interval . (E0 −
Δ, E0 + Δ). If.W is the number of states in the said interval then 
.ZN = W. (6.25) 
The.ZN above is the quantum microcanonical partition function. On substituting 
this in (6.3), the expression for entropy for quantum systems reads 
.SN = kBln(W). (6.26) 
The number of states.W is analogous to the phase space volume.Γ accessible to 
a classical system in the interval.(E0 − Δ, E0 + Δ) of energy. 
6.2.2 Canonical Ensemble 
The canonical ensemble is defined as the one in which the system exchanges energy 
but not particles with the surroundings. Hence, apart from the normalization con￾ditions, the constraint under which entropy is to be maximized is the value .U of 
internal energy, given for quantum systems by 
.U = ⟨HˆN ⟨ = Σ
m
EmN pmN , (6.27) 
where.HˆN is the system Hamiltonian and the second equation is due to the fact that 
.|EmN ⟨ is the eigenstate of.HˆN corresponding to energy.EmN : 
.HˆN |EmN ⟨ = EmN |EmN ⟨. (6.28) 
The corresponding constraint for classical systems is 
.U =
{
HN ({ri, pi}N ) fN ({ri, pi}N ) dτN , (6.29) 
where.H({ri, pi}N ) is classical Hamiltonian.6.2 Systems Having Fixed Number of Particles 185
The equilibrium distribution for quantum systems is then given by (6.10) with 
.Aˆ(1) = HˆN , .αk = 0 (.k /= 1). Also, due to (6.28), the definition (6.8) of .A(1)
mN gives 
.A(1)
mN = EmN . Hence, with.α1 → β, (6.10) assumes the form 
.pmN = 1
ZN
exp (
− βEmN )
, (6.30) 
where, due to (6.11), 
.ZN = Σ
m
exp (−βEmN ). (6.31) 
The.ZN above is the quantum canonical partition function. 
The equilibrium distribution for classical systems may similarly be shown to be 
given by 
. fN ({ri, pi}N ) = 1
ZN
exp{−βHN ({ri, pi}N )}, (6.32) 
where 
.ZN =
{
exp {−βHN ({ri, pi}N )} dτN . (6.33) 
The.ZN above is the classical canonical partition function. In the following we derive 
some relations expressing physical quantities in terms of .ZN assuming the system 
to be quantum. Analogous relations hold in the phase space description. 
1. It is straightforward to see that 
.U = −∂ln(ZN )
∂β , (6.34) 
for quantum as well as classical systems. Since. U is extensive, the equation above 
shows that .ln(ZN ) must be extensive. Inversion of (6.34) gives undetermined 
Lagrange multiplier. β in terms of the internal energy. U. 
2. Using (6.30), the expression (6.3) for entropy reads 
.SN = kB (βU + ln(ZN )), (6.35) 
for quantum as well as classical systems. 
3. We derive the expression for pressure in terms of .ZN . To that end, recall the 
well-known expression for pressure, 
.P = −∂E
∂V , (6.36) 
where.E is energy and.V the volume. Assume that the energy of the gas at some 
instance of time is.Em,N so that the pressure at that instance is186 6 Equilibrium Distributions
.PmN = −∂EmN
∂V . (6.37) 
The average pressure would be 
. P = Σ
m
pmN Pm,N = −Σ
m
pm,N
∂Em,N
∂V
= − 1
ZN
Σ
m
exp(−βEm,N )
∂Em,N
∂V
= 1
βZN
∂
∂V
Σ
m
exp(−βEm,N ) = 1
βZN
∂ZN
∂V . (6.38) 
We thus see that 
.P = 1
β
∂ln(ZN )
∂V . (6.39) 
This is the expression for pressure in terms of the canonical partition function. 
See also Sect. 6.4.2 for an alternative derivation. 
4. A measure of fluctuations in the measurement of energy is its variance. Invoking 
(6.18) we have 
.ΔE2 ≡ ⟨E2
⟨−⟨E⟨
2 = ∂2ln(ZN )
∂β2 . (6.40) 
Some consequences of the relation above are: 
(a) Due to (6.34), (6.40) may be rewritten as 
.ΔE2 = kBT 2 ∂U
∂T = kBT 2
CV . (6.41) 
This relates fluctuations in energy with the heat capacity. 
(b) Since.ΔE2 ≥ 0 it follows from (6.40) that 
.
∂2ln(ZN )
∂β2 ≥ 0. (6.42) 
(c) On dividing (6.40) by.N2 we have 
.
ΔE2
N2 = 1
N2
∂2ln(ZN )
∂β2 . (6.43) 
As argued circa (6.34),.ln(ZN ) is extensive and hence is proportional to. N. 
The equation above therefore shows that fluctuation in the measurement of 
energy per particle, .ΔE/N, is proportional to .1/
√N. Hence, for large . N, 
fluctuations in energy may be ignored.6.2 Systems Having Fixed Number of Particles 187
(d) Invoking (6.34), rewrite (6.40) as 
.ΔE2 = −∂U
∂β . (6.44) 
Since.ΔE2 ≥ 0, it follows that 
.
∂U
∂β ≤ 0. (6.45) 
This shows that the internal energy is a decreasing function of. β. The equality 
holds when.ΔE = 0: 
.
∂U
∂β = 0, if ΔE = 0. (6.46) 
Hence .U is independent of . β in the absence of randomness. We will show 
that .β = 1/kBT where .T is the temperature of the system. We therefore 
see that the concept of temperature is related with randomness. In particular 
we will see that for a non-interacting free classical gas, .U = 3N/2β. The 
equation (6.44) in that case leads to 
.ΔE2 = 3N
2
k2
BT 2
. (6.47) 
This equation relates temperature directly with energy fluctuations in an 
ideal classical gas. Clearly, .T = 0 if .ΔE = 0 though the applicability of 
ideal gas law is questionable at low temperatures. 
Exercises 
Ex. 6.3. (a) Given that, besides the normalization condition, the probability distri￾bution is constrained by specified average values .U and .P of energy and 
pressure, show that the probability that maximizes entropy is 
.pmN = 1
Zi N
exp (−βEmN − γPmN ), (6.48) 
.Zi N = Σ
m
exp (−βEmN − γPmN ), (6.49) 
where.Pm,N is as in (6.37). This is called isobaric-isothermal distribution. 
Hint: Recall from (6.38) that pressure is average of.Pm,N .188 6 Equilibrium Distributions
(b) Show that the entropy corresponding to the probabilities in (6.49) is 
.S = kB (βU + γP + ln(Zi N )). (6.50) 
6.3 Grand Canonical Ensemble 
The grand canonical ensemble describes systems which, in addition to exchanging 
energy with the environment, exchange also the particles. The number of particles 
then also becomes a variable. We adopt following notation for describing systems in 
grand canonical ensemble: 
1. In a quantum system, the occupation probability of the state .|Em,N ⟨ when .N is 
variable will be denoted by .pm(N). The argument .N of .pm(N) is to distinguish 
the probabilities for varying number of particles from those for fixed .N which 
have been symbolized by.pmN . 
2. In a classical system, .N-particle probability density in the vicinity of . {ri, pi}N
in case the particle number is varying will be denoted by . f ({ri, pi}N , N). The 
.N in the argument of . f is to distinguish the distribution for varying number of 
particles from the one for fixed.N which has been symbolized by. fN ({ri, pi}N ). 
3. The average .⟨Oˆ⟨ of an operator . Oˆ, commuting with the Hamiltonian, in the 
present case is given by 
.⟨Oˆ⟨ = Σ∞
N=0
Σ
m
pm(N)⟨EmN |Oˆ|EmN ⟨. (6.51) 
4. The average of a phase space distribution function .O({ri, pi}N ) in the classical 
description is given by 
.⟨O({ri, pi})⟨ = Σ∞
N=0
{
f ({ri, pi}N , N)O({ri, pi}) dτN . (6.52) 
5. Statistical entropy for varying.N for quantum systems is 
.S = −kB
Σ∞
N=0
Σ
m
pm(N)ln(pm(N)). (6.53) 
6. Statistical entropy for varying.N for classical systems is 
.S = −kB
Σ∞
N=0
{
f ({ri, pi}N , N)ln{ f ({ri, pi}N , N)} dτN . (6.54)6.3 Grand Canonical Ensemble 189
7. The normalization condition for quantum probabilities reads 
.
Σ∞
N=0
Σ
m
pm(N) = 1. (6.55) 
8. The normalization condition for classical probability distribution is 
.
Σ∞
N=0
{
f ({ri, pi}N , N) dτN = 1. (6.56) 
The equilibrium probability distribution in the grand canonical ensemble is one 
which maximizes entropy subject to its normalization condition, the average values 
of internal energy, and the number of molecules which in the quantum formalism are 
.U = ⟨HˆN ⟨ = Σ∞
N=0
Σ
m
EmN pm(N), (6.57) 
and 
.N¯ = ⟨Nˆ ⟨ = Σ∞
N=0
Σ
m
N pm(N). (6.58) 
Following the general procedure outlined in Sect. 5.2, it is straightforward to see that 
the.pm(N) which maximizes entropy is given by 
.pm(N) = 1
ZG
exp (−βEmN + αN), (6.59) 
where.α, β are Lagrange multipliers and.ZG is the quantum grand canonical partition 
function defined by 
.ZG = Σ∞
N=0
Σ
m
exp (−βEmN + αN). (6.60) 
The equation above is the result of the normalization condition. 
The equilibrium distribution function for classical systems is 
. f ({ri, pi}N ; N) = 1
ZG
exp {−βHN ({ri, pi}N ) + αN}, (6.61) 
where the grand partition function is190 6 Equilibrium Distributions
.ZG = Σ∞
N=0
{
exp {−βHN ({ri, pi}N ) + αN} dτN . (6.62) 
The.ZG above is the classical grand canonical partition function. In the following we 
consider quantum systems. The results for the classical systems follow by replacing 
the quantum averages by classical ones. 
1. It is straightforward to see that the internal energy is given by 
.U = −∂ln(ZG)
∂β . (6.63) 
2. The average number of molecules is 
.N¯ = ∂ln(ZG)
∂α . (6.64) 
The Lagrange multipliers.α, β can be determined as functions of.U, N¯ by inverting 
the equations (6.63) and (6.64). 
3. A useful relation between.ZN and.ZG is obtained by noting that, with.ZN given 
by (6.31) and (6.33) respectively for quantum and classical systems, the grand 
partition function.ZG in (6.60) for quantum systems, as well as that in (6.62) for 
classical systems can be written as 
.ZG = Σ∞
N=0
exp(αN)ZN = Σ∞
N=0
zN ZN , (6.65) 
where 
.z = exp(α) (6.66) 
is called the fugacity. From (6.65) follows the inverse relation 
.ZN = 1
N!
∂N ZG
∂zN
|
|
|
|
z=0
. (6.67) 
This express.ZN in terms of.ZG. 
4. The expression for pressure may be derived in the same way as has been done to 
arrive at the one in (6.39) for the canonical ensemble. The resulting expression 
for pressure is same as the one in (6.39) with.ZN therein replaced by.ZG: 
.P = 1
β
∂ln(ZG)
∂V . (6.68) 
Now,.ln(ZN ) and.ln(ZG) are extensive quantities but with a difference: Whereas 
.ln(ZN ) is a function of two extensive variables, namely, number of particles6.3 Grand Canonical Ensemble 191
.N and volume . V, .ln(ZG) is a function of only one extensive variable, namely, 
. V. For, as shown in (6.65), .ZG is obtained from .ZN by summation over . N. 
Hence .ln(ZG) must be of the form .ln(ZG) = V f (β, α) so that . ∂ln(ZG)/∂V =
f (β, α) = ln(ZG)/V. Hence 
.P = 1
βV
ln(ZG). (6.69) 
5. The expression for variance in the measurement of energy can be derived in the 
same manner as in its derivation for canonical ensemble in (6.40). The resulting 
expression is same as that in (6.40) with.ZN therein replaced by.ZG: 
.ΔE2 = ∂2ln(ZG)
∂β2 = −∂U
∂β . (6.70) 
The consequences of these relations have been discussed circa (6.40). 
6. The expression for variance in the measurement of number of molecules, obtained 
using (6.17), reads 
.ΔN2 ≡ ⟨N2
⟨−⟨N⟨
2 = ∂2ln(ZG)
∂α2 . (6.71) 
Since.ΔN2 ≥ 0 it follows that 
.
∂2ln(ZG)
∂α2 ≥ 0. (6.72) 
On using (6.64), (6.71) may be rewritten as 
.ΔN2 = ∂N¯
∂α . (6.73) 
The quantity .ΔN/N¯ serves as a measure of fluctuations in the number of 
molecules relative to the mean. N¯ . From (6.71) we have 
.
ΔN2
N¯ 2 = 1
N¯ 2
∂2ln(ZG)
∂α2 . (6.74) 
Since .ln(ZG) ∼ V and .V/N¯ is a constant in the thermodynamic limit . V →
∞, N¯ → ∞, it follows that .ΔN/N¯ ∼ (N¯ )−1/2. Thus fluctuation in the number 
of molecules is negligible in the thermodynamic limit. 
In particular, we will see that, for a non-interacting free classical gas,. ∂N¯ /∂α = N¯
which on substitution in (6.73) yields 
.ΔN2 = N¯ . (6.75)192 6 Equilibrium Distributions
This shows that variance in the number distribution of a non-interacting clas￾sical gas is same as its mean. This is the defining characteristic of the Poisson 
distribution. Hence the number distribution in an ideal classical gas is Poissonian. 
7. A relation of much importance exists between the number fluctuations and isother￾mal compressibility. To derive it, divide (6.73) by.N¯ 2 to obtain 
. 
ΔN2
N¯ 2 = 1
N¯
(∂N¯
∂α )
V,T
(∂ln(ZG)
∂α )−1
V,T
, = 1
βN V¯
(∂N¯
∂α )
V,T
(∂P
∂α )−1
V,T
= 1
βV
V
N¯
(∂N¯ /V
∂P
)
V,T
, (6.76) 
where (6.64) has been used to write an .N¯ in the denominator in first equation, 
(6.69) has been recalled to write.ln(ZG) in terms of pressure in the second equa￾tion, and (A.10) has been invoked to write the last equation. In terms of the specific 
volume.v = V/N¯ , (6.76) reads 
.
ΔN2
N¯ 2 = − 1
βN¯
( ∂v
∂P
)
T
= kBT
V
κT , (6.77) 
where.κT is isothermal compressibility defined in (2.110). The expression above 
may be derived alternatively by using Gibbs–Duhem equation (see 6.3). 
8. On substituting (6.59) in (6.53) follows the expression for entropy: 
.S = kB
(
βU − αN¯ + ln(ZG)
)
. (6.78) 
Invoking (6.69) for.ln(ZG) in terms of the pressure. P, we get 
.S = kB
(
βU − αN¯ + βPV )
. (6.79) 
We will show that.kB is Boltzmann’s constant,.β = 1/kBT and.α = βμ where. μ
is chemical potential. Consequently, (6.79) may be rewritten as 
.S = 1
T
U − μ
T
N¯ +
P
T
V. (6.80) 
This is Euler’s thermodynamic equation with.N therein replaced by. N¯ . 
While arriving at (6.80), we compared the statistical mechanical expression (6.79) for 
. S with Euler’s equation and, based on the assumption that. S in (6.80) is same as the 
thermodynamic entropy, we deduced the expressions for the Lagrange multipliers 
.β, α in terms of temperature and the chemical potential. Next we show that the 
assumed equivalence indeed holds. 
Ex. 6.4. Derive (6.77) using Gibbs–Duhem relation. Hint: With .v = V/N¯ , 
.α = βμ rewrite (6.73) as6.4 Relation with Thermodynamics 193
. 
ΔN2
N¯ 2 = V
βN¯ 2
(∂N¯ /V
∂μ )
V,T
= − 1
βV
(∂v
∂μ)
T
= − 1
βV
( ∂v
∂P
)
T
(∂P
∂μ )
T
. (6.81) 
Using Gibbs–Duhem relation (2.49) 
.sdT − vdP + dμ = 0, (6.82) 
we have.(∂P/∂μ)T = 1/v which on substitution in (6.81) would lead 
to the desired result (6.77). 
6.4 Relation with Thermodynamics 
In this section we establish the relationship of statistical description with thermo￾dynamics by using the standard distributions introduced above. It may appear that 
we may need to use one or the other canonical ensemble depending on the system 
under consideration i.e. depending on whether energy and particle numbers are given 
as exactly known or as averages. However, as shown above, in the thermodynamic 
limit, fluctuations in energy and number of particles are negligibly small. Hence, in 
that limit, whether an observable value is given exactly or as an average would lead 
to the same result. In other words, the three ensembles would lead to the same results 
in the thermodynamic limit. We may therefore choose any of the three ensembles per 
our convenience. In what follows we work with the canonical ensemble. See [Balian] 
for further details. 
6.4.1 Zeroth Law of Thermodynamics 
Recall that the zeroth law of thermodynamics states that if two bodies are separately 
in thermal equilibrium with a third body then they are in thermal equilibrium with 
one another. This law defines temperature as the quantity that is equalized between 
bodies in thermal equilibrium with each other. 
Using the zeroth law, we will show that. β is a decreasing function of temperature. 
To that end, let the probabilities of occupation of the energy eigenstates of systems 
. 1 and. 2 be given by (we drop the index indicating the number of particles) 
.p(k)
m = 1
Zk
exp (
−βk E(k)
m
)
, Zk = Σ
m
exp (
−βk E(k)
m
)
, k = 1, 2. (6.83)194 6 Equilibrium Distributions
The combined probability when the systems are not interacting is 
.p(c)
m,n = p(1)
m p(2)
n . (6.84) 
The systems interact when they are brought together. The energy levels of the com￾bined system are obtained by taking account of the interaction potential between 
them. Let.{E(c)
M } be the energy eigenstates of the combined system so that the prob￾ability of occupation of the state of energy.E(c)
M is given by 
.p(c)
M = 1
Z exp (
−βE(c)
M
)
, Z = Σ
M
exp (
−βE(c)
M
)
. (6.85) 
If the interaction is weak then energy eigenvalues of the interacting system will be 
only negligibly different from the sum of their energies when not interacting. We 
therefore let.E(c)
M ≈ E(1) m + E(2) n and rewrite (6.85) as 
.p(c)
m,n ≈ 1
Z exp (
−β
(
E(1)
m + E(2)
n
)) , Z = Σ
m,n
exp (
−β
(
E(1)
m + E(2)
n
)) . (6.86) 
This may be rewritten as 
.p(c)
m,n =
( 1
Z,
1
exp (
−βE(1)
m
)
) ( 1
Z,
2
exp (
−βE(2)
n
)
)
, (6.87) 
where 
.Z,
k = Σ
m
exp (
−βE(k)
m
)
. (6.88) 
Equations (6.87) show that the two systems attain the same value of the parameter 
. β after attaining equilibrium on interaction with each other. Since the equilibrium is 
caused only due to exchange of energy and thermodynamic quantity that attains the 
same value due to the exchange of energy is temperature, the parameter . β may be 
identified with temperature. 
The manner in which . β is related with temperature may be deduced by noting 
that, since the two systems together are isolated, their total internal energy does not 
change on interaction, i.e. 
.U1 + U2 = U,
1 + U,
2. (6.89) 
Hence if the internal energy of one increases then that of the other decreases. Also, 
from (6.45) we know that .∂U/∂β ≤ 0 i.e. .U is a decreasing function of . β. This 
implies that the . β value of that system increases whose energy after the interaction 
is smaller. Since the temperature of a body goes down when it loses energy, we see 
that. β has reciprocal relationship with temperature.6.4 Relation with Thermodynamics 195
6.4.2 First Law of Thermodynamics 
Recall the first law of thermodynamics stated in (1.29): 
. δU = δQ − δW,
where .δQ is the amount of heat absorbed and .δW the amount of work done by the 
system. To establish this law using statistical mechanical formalism we start with 
the expression (6.29) of internal energy and obtain 
.δU = Σ
m
(pmN δEmN + EmN δ pmN ). (6.90) 
A comparison of last two equations suggests that we may identify the amount of heat 
received by the system as 
.δQ = Σ
m
EmN δ pmN , (6.91) 
and the amount of work done by it as 
.δW = −Σ
m
pmN δEmN . (6.92) 
In the following we elaborate the meaning of (6.91) and (6.92). 
1. The (6.91) shows that the heat exchange is related with the change in probability 
distribution between energy levels of the system, i.e. it is the redistribution of 
population among energy levels which leads to change in the heat content of a 
body. The relations derived above are independent of any specific form of.pm,N . 
If the system is described by the canonical ensemble then it is straightforward to 
see that, due to change only in the parameter. β, 
. δQ = Σ
m
EmN
∂ pmN
∂β δβ =
(
∂
∂β
Σ
m
EmN pmN)
δβ
= ∂U
∂β δβ, (6.93) 
where the second equation is due to the fact that.Em,N is not a function of. β. On 
recalling (6.44), the equation above reads 
.δQ = −ΔE2
δβ. (6.94) 
This shows that the amount of heat exchanged is related with the variance in 
energy. We will see that .β ∼ 1/T . Hence increase in temperature is caused by 
the absorption of heat.196 6 Equilibrium Distributions
We have thus been able to express heat in terms of the statistical mechanical 
theoretic entities. 
2. The expression (6.92) for the work done by the system shows that the work is 
related with the change in the energy levels of the system. That change is caused 
by the changes in external parameters.{ξk } on which energy depends. For example, 
one such parameter could be the volume. Similarly change in the applied fields like 
the electromagnetic, gravitational, etc. would result in the change in the energy 
levels. Hence, considering energy a function of.{ξk }, we have 
.δEmN ({ξk }) = Σ
k
Fk
mN δξk , (6.95) 
where 
.Fk
mN = ∂EmN ({ξk })
∂ξk
. (6.96) 
On substituting this in (6.92) the expression for work done reads 
.δW = −Σ
k
Gk δξk , Gk = Σ
m
Fk
mN pmN . (6.97) 
For example, if .ξ = V where .V is the volume then corresponding .F is pressure 
.P = −⟨∂EmN /∂V⟨ and.δW = PδV. 
6.4.3 Second Law of Thermodynamics 
In the following we arrive at the second law of thermodynamics by starting with the 
statistical description. The statistical entropy will turn out to be proportional to the 
thermodynamic entropy. This will also enable us to find functional relation between 
. β and temperature. Recall that, while comparing statistical theory with the zeroth 
law of thermodynamics, we found that. β is related inversely with temperature but it 
does not determine the function relating them. 
The change in statistical entropy in canonical ensemble description is 
. δS = −kB
Σ
m
(1 + ln(pmN )) δ pmN
= −kB
Σ
m
(1 − βEmN − ln(ZN )) δ pmN
= kBβ
Σ
m
EmN δ pmN − kB (1 − ln(ZN ))
Σ
m
δ pmN
= kBβδQ − kB (1 − ln(ZN ))
Σ
m
δ pmN , (6.98)6.4 Relation with Thermodynamics 197
where use has been made of the definition (6.91) of.δQ. Due to 
.
Σ
m
pmN = 1 =⇒ Σ
m
δ pmN = 0, (6.99) 
the (6.98) reduces to 
.δS = kBβδQ. (6.100) 
Recall that the change.δSth in the thermodynamic entropy of a system when it receives 
the amount.δQ of heat reversibly at temperature. T is given by.δSth = δQ/T which 
on comparison with (6.100) shows that the statistical and the thermal entropies are 
proportional to each other. If we demand that the statistical entropy be identical with 
the thermodynamic entropy then we arrive at the relation.β = 1/kBT . The constant 
.kB is fixed by the choice of the temperature scale. If the unit of temperature is chosen 
to be Kelvin then .kB turns out to be the Boltzmann’s constant. Assuming that to be 
the case we are led to the following relations: 
.kB = Boltzmann’s constant, β = 1
kBT . (6.101) 
This determines the Lagrange multiplier .β in terms of a physical characteristic, 
namely, temperature. 
Having identified statistical entropy . S as the thermodynamic entropy, we can 
legitimately equate its expression (6.79) with Euler’s equation to arrive at the relation 
.α = βμ, (6.102) 
where. μ is the chemical potential. 
Having identified the statistical entropy with the thermodynamic one, we need to 
show that the entropy of an isolated system never decreases. That assertion has been 
proved in Sect. 13.6. Using it, the second law (1.53) may be arrived at by statistical 
mechanical considerations as follows. Since the system and reservoir together are 
isolated, their combined entropy increases: 
.dS + dSR ≥ 0, (6.103) 
where .dS stands for the change in entropy of the system and .dSR is that for the 
reservoir. We know that if .dQ is the amount of heat transmitted from the reservoir 
to the system at temperature. T then change in its entropy is 
.dSR = −dQ
T . (6.104) 
Substitution of (6.104) in (6.103) leads to the second law (1.53).198 6 Equilibrium Distributions
6.4.4 Third Law of Thermodynamics 
Recall that the third law defines the scale for measuring entropy by asserting that 
entropy vanishes at absolute zero. 
In order to see how it follows from statistical considerations, rewrite.pmN for the 
canonical ensemble in the form 
.pmN = exp(−βEmN )
Σ
m exp(−βEmN ) = exp(−β(EmN − E0N ))
Σ
m exp(−β(EmN − E0N )), (6.105) 
where .E0N is the ground state energy so that.EmN > E0N for.m /= 0. If the ground 
state is non-degenerate then, in the limit .T → 0, the equation above shows that 
.pmN = δm0 which on substitution in the (6.3) for entropy yields.S = 0. If the ground 
state is degenerate with .W as the number of states then .S = ln(W). Consequently, 
the entropy per unit volume is 
.s = 1
V
ln(W) → 0, V → ∞, (6.106) 
provided.W does not grow faster than.exp(V). Thus the statistical description leads 
to the third law. 
6.5 Thermodynamic Potentials in Terms of Partition 
Functions 
In this section we derive relations between the thermodynamic potentials and the 
partition functions. 
1. With. β given by (6.101), the expression (6.35) for entropy in the canonical ensem￾ble reads (with.SN → S) 
.T S = U + β−1
ln(ZN ). (6.107) 
Since we have identified the statistical entropy as the thermodynamic entropy, the 
expression above for statistical entropy should be same as the expression (2.57) 
for the thermodynamic entropy in terms of the Helmholtz free energy. F(T, V, N)
leading to the following relation between the canonical partition function.ZN and 
.F(T, V, N): 
.F(T, V, N) = −β−1
ln(ZN ). (6.108) 
The equations in (2.60) now assume the form6.5 Thermodynamic Potentials in Terms of Partition Functions 199
. S =
(∂β−1ln(ZN )
∂T
)
V,N
, P = β−1
(∂ln(ZN )
∂V
)
N,T
,
μ = −β−1
(∂ln(ZN )
∂N
)
V,T
. (6.109) 
2. With. β,. α given by (6.101) and (6.102), rewrite (6.78) as 
.ST = U − μN + β−1
ln(ZG). (6.110) 
On comparing this with the expression for entropy in terms of the grand potential 
.Ω(T, V, μ) in (2.75) we see that the entropy therein will be same as that in the 
equation above if 
.Ω(T, V, μ) = −β−1
ln(ZG) = −PV, (6.111) 
where last equation is due to (6.68). We see that.Ω in (6.111) has the form (2.76) 
as it should. 
The (2.78) now read 
. S =
(∂β−1ln(ZG)
∂T
)
V,μ
, P = β−1
(∂ln(ZG)
∂P
)
T,μ
,
N = β−1
(∂ln(ZG)
∂N
)
T,V
. (6.112) 
3. The Gibbs potential defined in (2.65) may be written in terms of the Helmholtz 
potential as 
.G(T, P, N) = F(T, V, N) + PV. (6.113) 
Using (6.108) follows the expression of the Gibbs potential in terms of the partition 
function.ZN : 
.G(T, P, N) = −β−1
ln(ZN ) + PV. (6.114) 
Exercises 
Ex. 6.5. Using (2.16) for entropy of an ideal gas in (6.107), show that 
.ln(ZN ) = N {ln(V) − cln(β) − ln(N) + B}, (6.115) 
where.B = cln(c) + A − c is a constant. With.c = 3/2, this is same as. ZN
derived in (7.18) using the theory of statistical mechanics if the factor . N!
therein is approximated using Stirling’s approximation and the constant.B200 6 Equilibrium Distributions
in (6.115) is identified with the corresponding term therein. For, as we know, 
the constant. B cannot be determined by thermodynamics. 
Ex. 6.6. Compare the expression (6.50) of entropy in terms of.Zi N , with the expres￾sion (2.65) of.G(T, P, N) to show that if the undetermined Lagrange mul￾tiplies. γ in (6.50) is 
.γ = βV, (6.116) 
then 
.G(T, P, N) = −β−1
ln(Zi N ). (6.117) 
Consequently, the expression (6.49) for the isobaric-isothermal distribution 
assumes the form 
.pmN = 1
Zi
exp (−βEmN − βPmN V). (6.118)Chapter 7 
Non-interacting Classical Gas 
In this chapter we study thermodynamics of classical gas of non-interacting 
molecules, including their internal motion, using the equilibrium phase space dis￾tribution derived in Chap. 6. We show that, when internal motion is excluded, the 
thermodynamic properties of the gas, predicted by statistical mechanics, are same as 
those of the ideal thermodynamic gas. A useful outcome of the phase space approach 
is the equipartition theorem which is helpful in finding the internal energy of non￾interacting gas for certain types of Hamiltonians. We investigate also thermodynamic 
properties of non-interacting gas in the gravitational field near the surface of the earth. 
7.1 Thermodynamics Using Canonical Ensemble 
Consider a gas of.N molecules whose evolution in classical description is governed 
by the Hamiltonian .HN ({ri, pi}N ). Recall from Chap. 6 that its state of thermal 
equilibrium is described by the canonical phase space distribution function (6.32): 
. fN ({ri, pi}N ) = 1
ZN
exp {−βHN ({ri, pi}N )}, β = 1/kBT, (7.1) 
with the canonical partition function.ZN given by (6.33): 
.ZN =
{
exp {−βHN ({ri, pi}N )} dτN . (7.2) 
We assume.HN to be of the form 
.HN ({{ri, pi}N }) = Σ
N
i=1
p2
i
2m + V({ri}N ), (7.3) 
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4_7 
201202 7 Non-interacting Classical Gas
where .V({ri}N ) ≡ V(r1, r2 ..., rN ) is the potential which includes the interaction 
potential between the particles and that arising from external forces. Using (7.3), the 
expression for.ZN reads 
. ZN = 1
N!h3N
|
N
i=1
[{
exp(
− β
2m p2
i
)
d3
pi
] {
exp (−βV({ri}N )) d3N r
= 1
N!h3N
[{
exp(
− β
2m p2
)
d3
p
]N {
exp (−βV({ri}N )) d3N r.
(7.4) 
The momentum integral can be performed using the identity (3.9) to get 
.ZN = 1
N!
λ−3N
T
{
exp (−βV({ri}N )) d3N r, (7.5) 
where.λT defined by 
.λT = h
√2πmkBT (7.6) 
is called the thermal wavelength. The significance of.λT and its name will be brought 
out in Sect. 7.1.2. 
It is generally not possible to evaluate the integral in (7.5) analytically in the 
presence of interaction between the molecules. It can be evaluated if the particles are 
non-interacting, subject possibly to the external forces. Assuming that the external 
forces are described by the potential .v(r) and that there is no mutual molecular 
interaction, the potential.V({ri}N ) reduces to 
.V({ri}N ) = Σ
N
i=1
v(ri), (7.7) 
so that 
. {
exp (−βV({ri}N )) d3N r = |
N
i=1
{
exp (−βv(ri)) d3
ri
=
({
exp (−βv(r)) d3
r
)N
. (7.8) 
The.ZN in (7.5) then assumes the form 
.ZN = 1
N!
λ−3N
T
({
exp (−βv(r)) d3
r
)N
. (7.9)7.1 Thermodynamics Using Canonical Ensemble 203
With.V({ri}N ) as in (7.7), the phase space distribution function reads 
. fN ({ri, pi}N ) = 1
ZN
|
N
i=1
exp {
−β
( p2
i
2m + v(ri)
)} . (7.10) 
We use the phase space distribution of molecules to find the probability distribution 
of their positions. 
7.1.1 Position Distribution Function 
Often one is interested in the spatial properties of the gas irrespective of their 
momenta. Such properties are described by the distribution function of the molecular 
positions obtained by integrating the phase space distribution over their momenta as 
follows. 
The probability density.ρ˜({ri}N ) of finding molecules in the vicinity of.{ri} irre￾spective of their momenta evidently is 
.ρ˜({ri}N ) =
{
fN ({ri, pi}N ) d3Np. (7.11) 
With. f ({ri, pi}N ) given by (7.10), the integral over the momenta in the integral above 
can be carried as in (7.4). Using also (7.9) for.ZN we have 
.ρ˜({ri}N ) = C˜
|
N
i=1
exp (−βv(ri)), (7.12) 
where 
.C˜ −1 =
{ |
N
i=1
exp (−βv(ri)) d3Nr =
({
exp (−βv(r)) d3
r
)N
. (7.13) 
The expression (7.12) for.ρ˜({ri}N ) may be rewritten as 
.ρ˜({ri}N ) = |
N
i=1
C exp (−βv(ri)), (7.14) 
where 
.C−1 =
{
exp (−βv(r)) d3
r. (7.15)204 7 Non-interacting Classical Gas
The equation (7.14) is the probability density for finding molecules numbered 
.1, 2,..., N in the vicinity of .r1, r2,..., rN respectively. It is a product of .N func￾tions each depending on the position of a particular molecule. The .ith factor in the 
product in (7.14) then stands for the probability density of finding the .ith molecule 
in the vicinity of. ri . Hence the probability density for finding a particular molecule 
in the vicinity of. r is 
.ρ(r) = C exp (−βv(r)). (7.16) 
The probability density will be independent of position if .v(r) is independent of . r
in which case system is homogeneous. 
We study first the thermodynamics of the gas when.v(r) = 0 and follow it up by 
discussion of the issues that arise when.v(r) /= 0 by working out the problem of the 
gas in the gravitational field near the surface of the earth. 
7.1.2 Free Non-interacting Particles: Ideal Gas 
If the molecules are non-interacting and there is no external force on them then 
.V(r) = 0, so that the phase space distribution function (7.10) reduces to 
. f ({ri, pi}N ) = 1
ZN
|
N
i=1
exp(
−β p2
i
2m
)
(7.17) 
with.ZN given by (7.9) with.v(r) = 0. The value of the space integral therein in that 
case is. V, the volume of the system, so that 
.ZN = Z N
1
N!
, (7.18) 
where, with.λT given by (7.6), 
.Z1 = Vλ−3
T . (7.19) 
The.Z1 is the single particle partition function. 
With.ZN as in (7.18), the expressions for various thermodynamic quantities are: 
1. Pressure is given by 
.P = 1
β
∂ln(ZN )
∂V = N
V
kBT. (7.20) 
This is same as the first equations of state of the ideal gas given in (1.80).7.1 Thermodynamics Using Canonical Ensemble 205
2. The expression for internal energy.U reads 
.U = −∂ln(ZN )
∂β = 3N
2
kBT. (7.21) 
This is same as the second equation of state of the ideal gas given in (1.80) 
provided .c = 3/2 therein. The particular value of . c is the result of considering 
only the three translational degrees of freedom of the molecules. Its value will 
change on inclusion of other degrees of freedom. The evaluation of.U including 
the rotational and vibrational motions has been carried in Sect. 7.4. 
3. We can now provide interpretation of what has been called the thermal wavelength 
.λT. Recall that the De Broglie wavelength of a particle having kinetic energy . E
is given by .λDB = h/
√2m E. Since average energy of a molecule in the gas at 
temperature. T is.3kBT/2, the De Broglie wavelength corresponding to that energy 
is .λDB = h/
√3mkBT . Clearly, .λT ∼ λDB. The thermal wavelength .λT is thus a 
measure of the De Broglie wavelength of molecules in the gas at temperature 
. T . We will see that it sets scale for the validity of the ideal gas approximation, 
as well as for applicability of the classical theory beyond which quantum theory 
must be used even when the particles are non-interacting. The role played by 
.λT in determining the limit of applicability of ideal gas law will be brought out, 
following the equation (7.23), by showing that ideal gas entropy becomes negative 
if average separation between the molecules is less than approximately. 0.435λT
and in Sect. 8.8 by showing that the classical theory needs quantum corrections 
if.λT far exceeds average separation between the molecules. 
4. From (7.21) it follows that the heat capacity at constant volume is 
.CV ≡
(∂U
∂T
)
V
= 3N kB
2 . (7.22) 
This is same as the.CV in (1.77) with.c = 3/2 therein. 
5. Substitute the expressions (7.18) and (7.21) for.ZN and.U in the equation (6.35) 
for entropy and use Stirling’s approximation to obtain 
.SN = N kB
[
5
2 + ln ( V
N
)
+
3
2
ln (U
N
)
+
3
2
ln (4πm
3h2
)] . (7.23) 
This is known as Sackur–Tetrode equation [ 1, 2]. It is same as the one derived in 
(2.16) using thermodynamic consideration if we take .c = 3/2 and set .A therein 
equal to the constant term in (7.23). The reason for taking .c = 3/2 has been 
explained circa (7.21). However, as has been mentioned before, thermodynamics 
cannot determine. A. 
The.SN in (7.23) need not be always positive. To see the condition under which it 
becomes negative, use (7.21), and the definition (7.6) of the thermal wavelength 
.λT to rewrite it in form206 7 Non-interacting Classical Gas
.SN = N kB
[
5
2 + ln ( V
Nλ3
T
)] . (7.24) 
This shows that.SN < 0 if 
.
V
N
< λ3
T exp(−5/2) = 0.082λ3
T. (7.25) 
Since .V/N is the volume per particle, its cube root is a measure of distance 
between the particles. Hence (7.25) shows that.SN will become negative if average 
separation between the molecules is less than about .0.435λT. Since the thermal 
wavelength is a measure of molecular De Broglie wavelength corresponding to 
average thermal energy, the said condition means that entropy will become neg￾ative as the De Broglie waves of molecules start overlapping. That is when the 
quantum effects start showing up and the classical theory begins to break down. 
Sackur and Tetrode derived (7.23) independently in 1911–12, well before the 
advent of the quantum theory in 1925–26. Yet Planck’s constant. h, a purely quan￾tum theoretic entity, appears in the expression in question. The. h was “born", of 
course, in 1900 in Planck’s paper on blackbody radiation, but not the quantum 
machinery employed today to derive (7.23). Sackur and Tetrode derived it by 
dividing the phase space in cells of volume .h3 and by following Boltzmann’s 
approach to arrive at the equilibrium distribution (see [ 3] for details of the deriva￾tions and references therein to related papers). As has been outlined in Chap. 4, 
similar approach was followed in 1924 by Bose to re-derive Planck’s law and by 
Einstein to formulate quantum theory of ideal gas. The difference between the 
distributions derived by Bose and Einstein and the one derived by Sackur and 
Tetrode lies in treating the molecules as indistinguishable by Bose and Einstein 
and as distinguishable by Sackur and Tetrode. 
Since it is the difference in entropy that is of practical interest, the constant 
in . S would appear to be unmeasurable and in fact, immaterial. It is however 
remarkable that Sackur and Tetrode could devise and conduct experiments to 
determine the absolute value of . S to confirm the correctness of the value of 
the constant in question. For details of the experiments of Sackur and Tetrode 
see [ 3]. The meaning of measurement of absolute entropy and other experimental 
verifications of Sackur–Tetrode equation is discussed in [ 4]. 
6. The chemical potential. μ, determined using (6.109), is given by 
.
μ
T = −kB
[
ln ( V
N
)
+
3
2
ln (U
N
)
+
3
2
ln (4πm
3h2
)] . (7.26) 
Verify that the constant in the expression (7.23) for. S and that in (7.26) for. μ obey 
the relation derived in (2.5) with.c = 3/2 therein.7.2 Thermodynamics Using Grand Canonical Ensemble 207
We have thus shown that the canonical ensemble of the gas of free particles has all 
the characteristics of the ideal thermodynamic gas. 
Next we treat the classical gas by grand canonical ensemble and show that its 
predictions for free non-interacting gas are the same as the ones arrived at by treating 
it in the framework of the canonical ensemble. 
7.2 Thermodynamics Using Grand Canonical Ensemble 
We evaluate the grand canonical partition function.ZG using its expression (6.65) in 
terms of.ZN : 
.ZG = Σ∞
N=0
exp(αN)ZN . (7.27) 
Substituting the expression (7.18) for.ZN in the equation above we obtain 
.ln(ZG) = exp(α)Z1 = V
λ3
T
exp(α). (7.28) 
The thermodynamic properties predicted by the equation above are: 
1. Using (6.64), the average number of particles is given by 
.N¯ = ∂ln(ZG)
∂α = ln(ZG). (7.29) 
2. Invoking (6.63) we get 
.U = −∂ln(ZG)
∂β = 3kBT
2
ln(ZG). (7.30) 
On using (7.29) in the equation above we obtain 
.U = 3kBT
2
N¯ . (7.31) 
We see that the.U in the equation above is same as the one derived in (7.21) using 
canonical distribution function with.N → N¯ . 
3. Using (6.69), the expression for pressure reads 
.P = 1
βV
ln(ZG) = N¯
V
kBT. (7.32) 
This is same as the ideal gas law (7.20) with.N therein replaced by. N¯ .208 7 Non-interacting Classical Gas
4. To derive expression for chemical potential, combine (7.28) and (7.29), with 
.α = βμ, to get 
.
μ
T = −kB
[
ln ( V
N¯
)
+
3
2
ln (U
N¯
)
+
3
2
ln (4πm
3h2
)] . (7.33) 
The expression for . μ above is same as that in (7.26) obtained in the framework 
of canonical ensemble provided.N therein is identified as. N¯ . 
5. The expression for entropy may be obtained using the relation (2.53) between 
entropy and chemical potential of the ideal gas. The resulting equation will turn 
out to be the same as that in (7.23), which has been derived using canonical 
ensemble, if.N therein is replaced by. N¯ . 
We see that the results derived using the grand canonical partition function are the 
same as the corresponding ones obtained by using the canonical partition function if 
fixed number.N in the results of the canonical ensemble are replaced by the average 
number . N¯ . In Chap. 6 we have shown that the fluctuations in the average value 
of an observable about its average varies as .1/
√N. Hence interchange of .N¯ and 
.N is justified for large .N which is anyway the requirement for the applicability of 
thermodynamics. 
7.3 Equipartition Theorem 
In several situations, the single particle Hamiltonian is expressible as 
. H1({Qi},{Pi},{qi},{pi}) = Σ
l
j=1
Aj P2
j +Σm
k=1
Bk Q2
k +Σn
i=1
Ci({qi})p2
i ,
(7.34) 
where the generalized momenta .{Pi} are canonically conjugate to the coordinates 
.{Qi} and the momenta .{pi} are canonically conjugate to the .{qi}. The sets of the 
generalized coordinates.{Qi} and.{qi} are independent of each other. The coefficients 
.Ai’s and the . Bi’s are constants whereas the . Ci’s may be functions of the . qi’s. Note 
that the. qi’s appear only as part of the coefficients multiplying.p2
i ’s. We will see that 
the Hamiltonian of the rotational motion of the molecules is of the form of the last 
term in (7.34). 
The equilibrium state of the system governed by this Hamiltonian and interacting 
with a thermal reservoir at temperature. T is 
. fN = 1
ZN
exp(−NβH1). (7.35)7.4 Internal Motion 209
where.ZN is given by (7.18) with.Z1 therein in the present case being 
. Z1 = |n
i=1
{ bi
ai
dqi
{ ∞
−∞
exp{−βCi({qi})p2
i }d pi
×|
l
j=1
{ ∞
−∞
exp(−βAj P2
j )dPj
|m
k=1
{ ∞
−∞
exp(−βBk Q2
k )dQk . (7.36) 
Transform to the variables.p˜i = √β pi ,.P˜j = √βPj ,.Q˜ k = √βQk so that the expres￾sion above reduces to 
. Z1 = β−(l+m+n)/2 |n
i=1
{ bi
ai
dqi
{ ∞
−∞
exp{−Ci({qi})p˜
2
i }d p˜i
×|
l
j=1
{ ∞
−∞
exp(−Aj P˜ 2
j )dP˜j
|m
k=1
{ ∞
−∞
exp(−Bk Q˜ 2
k )dQ˜ k . (7.37) 
The term multiplying.β− f/2 ( f = (l + m + n)/2)is independent of. β. Hence internal 
energy per particle is given by. (u = U/N)
.u = −∂ln(Z1)
∂β = (l + m + n)
kBT
2 . (7.38) 
This shows that each term in (7.34) contributes.kBT/2 to internal energy per particle. 
This is called the equipartition theorem. 
7.4 Internal Motion 
We have so far considered only the translational motion of the molecules. The 
molecules, however, have internal structure made of atoms bound together. The 
atoms vibrate and rotate contributing thereby to the molecular energy. We construct 
the partition function to include the said motion, called the internal molecular motion. 
To that end, consider a molecule consisting of . n atoms. The molecular energy 
consists of three parts: the translational motion of its center of mass and the rotational 
and vibrational motions of its atoms. As the first approximation, it is assumed that 
the displacement of atoms from their equilibrium position while vibrating is so small 
that it can be ignored while considering their rotational motion. We will therefore 
assume that the relative position of the atoms does not change while rotating. The 
said three contributions to the energy of the molecule are then independent of each 
other permitting us to write its Hamiltonian as the sum of the Hamiltonians: .Htrans,210 7 Non-interacting Classical Gas
.Hrot,.Hvib corresponding respectively to the translational motion of its center of mass, 
its rotational motion as a rigid body and the vibrational motion: 
.H = Htrans + Hrot + Hvib. (7.39) 
The partition function then reads 
.ZN = 1
N!
Z N
1 , Z1 = Ztrans,1Zrot,1Zvib,1. (7.40) 
In writing the contributions to the molecular energy, we have ignored contribu￾tions from electronic transitions within atoms. Those transitions, however, cannot 
be described in terms of the phase space distribution function, requiring instead the 
quantum theoretic treatment to be taken up in Sect. 8.6.2 
The partition function.Ztrans,1 is for free evolution of the molecular center of mass 
which is same as.Z1 in (7.19). 
In the following we evaluate the contributions from the rotational and vibrational 
motions. 
7.4.1 Rotational Motion 
As stated above, the molecule is assumed to act as a rigid rotor. It has three axes 
of rotation except when the molecule is diatomic, or when atoms in a polyatomic 
molecule are arranged linearly in which case rotation is not possible about the line 
joining them so that the number of axes of rotation becomes two. We evaluate first 
the partition function for a diatomic molecule. 
Rotational Motion: Diatomic Molecules 
The Lagrangian of a system of two atoms of mass.mi at the positions.Ri . (i = 1, 2)
with respect to an arbitrarily chosen origin is 
.L = 1
2
Σ
2
i=1
miR˙ 2
i . (7.41) 
It is convenient to work in the coordinate system centered at the center of mass 
(COM). R where 
.R = 1
M
Σ
2
i=1
miRi, M = Σ
2
i=1
mi, (7.42)7.4 Internal Motion 211
Let. r denote the relative position of the atoms with respect to each other: 
.r = R1 − R2. (7.43) 
The (7.42) and (7.43) yield 
.R1 = R + m2
M
r, R2 = R − m1
M
r. (7.44) 
Since relative position of the atoms is assumed to remain unchanged we have 
.|r| = a, (7.45) 
where. a is the magnitude of separation between the atoms. 
On substituting (7.44) in (7.41), the Lagrangian reads 
.L = M
2
R˙ 2 + μ
2
r˙
2
, μ = m1m2
M . (7.46) 
The . μ is the reduced mass of the molecule. The Lagrangian (7.46) shows that the 
center of mass executes free translational motion. Hence its contribution to internal 
energy per molecule is 
.utrans = 3
2
kBT. (7.47) 
However, evolution of the relative atomic position vector . r, described by the 
Lagrangian 
.Lrot = μ
2
r˙
2 (7.48) 
is constrained by the condition (7.45) of constancy of separation between them. Since 
the motion under the said constraint is rotational, the corresponding Lagrangian 
is called the rotational Lagrangian. That constraint can be incorporated in the 
Lagrangian by working in the spherical polar coordinates. To that end, let.θ, φ be the 
polar angles of. r so that 
.r˙ = ˙r er + r ˙
θ eθ + r sin(θ)φ˙ eφ, (7.49) 
where. er,. eθ,.eφ are orthonormal unit vectors along the radial and the angular direc￾tions. Since.r = a all through the motion, the equation above reduces to 
.r˙ = a
(
θ˙ eθ + sin(θ)φ˙ eφ
)
. (7.50)212 7 Non-interacting Classical Gas
Substitute this in (7.48) to get 
.Lrot = a2μ
2
(
θ˙2 + sin2
(θ)φ˙2)
. (7.51) 
The momenta.pθ,.pφ conjugate respectively to. θ and. φ are 
.pθ = ∂L
∂ ˙
θ = I θ˙. pφ = ∂L
∂φ˙ = I sin2
(θ)φ˙, I = μa2
. (7.52) 
The . I is the moment of inertia of the molecule. Consequently, the Hamiltonian 
corresponding to the Lagrangian (7.51) turns out to be given by 
.Hrot = 1
2I
(
p2
θ +
1
sin2(θ)
p2
φ
)
, (7.53) 
called the rotational Hamiltonian. The Hamiltonian above can be written in terms of 
the angular momentum, 
.L = r × p, (7.54) 
as 
.Hrot = 1
2I
L2
, L2 = L · L. (7.55) 
This form will be found useful in the study of the quantum theory of diatomic rotation. 
The proof of (7.55) is left as an exercise. 
The single molecule partition function corresponding to (7.53) is 
.Zrot1 = 1
h2
{
exp {
−βHrot(θ, φ; pθ, pφ
)
}dθdφd pθd pφ, (7.56) 
where.0 ≤ φ ≤ 2π,.0 ≤ θ ≤ π,.−∞ ≤ pφ ≤ ∞,.−∞ ≤ pθ ≤ ∞. The evaluation of 
the integral above yields 
.Zrot1 = 8Iπ2
h2 kBT. (7.57) 
The internal energy per molecule due to rotational motion is 
.urot = −∂ln(Zrot,1)
∂β = kBT. (7.58)7.4 Internal Motion 213
The .Hrot in (7.53) is of the form of the Hamiltonian (7.34) with .l = m = 0, .n = 2. 
Hence, the result derived above is in accordance with that of the equipartition theorem 
in (7.38). 
Rotational Motion: Polyatomic Molecules 
Consider a molecule constituted by . n atoms. In case the atoms are arranged on a 
line, the molecule is called linear. Like a diatomic molecule, such a molecule has 
two axes of rotation whereby the contribution to internal energy per molecule is the 
same as that for a diatomic one: 
.urot = kBT, linear polyatomic molecules. (7.59) 
If the gas is made of non-linear molecules, we can evaluate the contribution of rotation 
to internal energy as follows. 
We treat a polyatomic molecule as a rigid body, denoting the principal components 
of its moment of inertia by.Ij (. j = 1, 2, 3) and the Euler angles with respect to the 
principal moment of inertia axes by .(θ, φ, ψ). The Hamiltonian of the molecule is 
then given by 
. Hrot = 1
2I1 sin2(φ)
{
(pθ − pψ cos(φ)) cos(ψ) − pφ sin(φ)sin(ψ)
}2
1
2I2 sin2(φ)
{
(pθ − pψ cos(φ))sin(ψ) − pφ sin(φ) cos(ψ)
}2 +
1
2I3
p2
ψ.
(7.60) 
We can evaluate .Z1 in (7.37) with.H1 = Hrot by transforming to.p˜μ = √β pμ (. μ =
θ, φ, ψ) and show, like we did in proving the equipartition theorem, that 
.urot = 3
2
kBT, non-linear polyatomic molecules. (7.61) 
Else, we can transform the combination of momenta in the curly brackets, along with 
.pψ in the last term in (7.60), to three new momenta to reduce.Hrot to the form (7.34) 
with.l = m = 0,.n = 3 and apply the equipartition theorem to arrive at (7.61). 
Since there are two axes of rotation in a linear molecule and three in a polyatomic 
molecule, we can say that rotation around each axis contributes.kBT/2 to the thermal 
energy. 
In terms of the components.Lk (.k = 1, 2, 3) of the angular momentum along the 
principal axes, the rotational Hamiltonian assumes the form 
.Hrot = 1
2I1
L2
1 +
1
2I2
L2
2 +
1
2I3
L2
3. (7.62)214 7 Non-interacting Classical Gas
This form of the Hamiltonian turns out to be useful in the quantum mechanical treat￾ment of the problem carried in Chap. 8. 
Summary 
The energy per molecule in the ideal gas from translational and rotational motions 
is 
. utrans+rot = 5kBT
2 , diatomic and linear polyatomic molecules,
utrans+rot = 3kBT, polyatomic molecules. (7.63) 
Next we determine the contribution of vibrations to energy. 
7.4.2 Vibrational Motion 
The number of degrees of freedom of a molecule made of. n atoms is.3n. There are 
three translational degrees of freedom associated with the motion of its center of 
mass. A linear molecule has two degrees of rotational freedom so that remaining 
.3n − 5 degrees of freedom are vibrational. If the molecule is not linear, it has three 
axes of rotation and hence three rotational degrees of freedom. The remaining. 3n − 6
are the degrees of vibrational motion. 
Consider a diatomic molecule. Per the discussion above, it has one vibrational 
degree of freedom corresponding to the vibrational motion along the line joining the 
atoms. It is governed by the Hamiltonian: 
.Hvib = p2
η
2μ
+ μω2
2 η2
, (7.64) 
where . η is the displacement from the equilibrium position of the atoms and .pη is 
the corresponding momentum. This is of the form of the Hamiltonian (7.34) with 
.l = m = 1, .n = 0. Hence, invoking the equipartition theorem formula (7.38), the 
contribution to internal energy per molecule due to the vibrational Hamiltonian (7.64) 
is 
.uvib = kBT, diatomic molecules. (7.65) 
Thus each vibrational mode contributes .kBT to the thermal energy. There being 
.3n − 5 modes of vibration in a linear molecule of . n atoms, the vibrational thermal 
energy per molecule of the gas constituted by such molecules is 
.uvib = (3n − 5)kBT, linear polyatomic molecules of n atoms. (7.66)7.5 Gas in Gravitational Field 215
In case the molecule of. n atoms is not linear, it has.3n − 6 vibrational modes. Hence 
the vibrational thermal energy per molecule of the gas constituted by such molecules 
is 
.uvib = 3(n − 2)kBT, non-linear molecules of n atoms. (7.67) 
Putting together all the contributions, the energy per molecule consisting of. n atoms 
constituting an ideal gas is 
. u =
(
3n − 5
2
)
kBT, gas of linear molecules,
u = 3(n − 1)kBT, gas of non-linear molecules. (7.68) 
This leads to the following expressions for the heat capacity per molecule at constant 
volume: 
. cV =
(
3n − 5
2
)
kB, gas of linear molecules,
cV = 3(n − 1)kB, gas of non-linear molecules. (7.69) 
The experimentally observed value of heat capacity is not only temperature dependent 
but is also much lower than the value predicted above till the temperature is very 
high. Answer to the question of the reason of said discrepancy is provided by the 
quantum theoretical treatment, presented in Sect. 8.6.2. 
7.5 Gas in Gravitational Field 
Consider a gas of .N molecules of mass . m, enclosed in a box of base area .A and 
height .H placed near the surface of earth. With . g denoting the acceleration due to 
gravity. the Hamiltonian of the system is 
.H(r, p) = 1
2m
Σ
N
i=1
p2
i + mgΣ
N
i=1
zi, 0 ≤ zi ≤ H, (7.70) 
where. zi denotes the height of the.ith molecule above the bottom of the box. We study 
the thermodynamics of the gas in canonical ensemble formalisms assuming that 
there is no variation in temperature with height. The effect of temperature gradient 
is discussed in Sect. 7.5.1. 
The canonical partition function corresponding to the Hamiltonian (7.70) is given 
by (7.9) with 
.v(r) = mgz, 0 ≤ z ≤ H, (7.71)216 7 Non-interacting Classical Gas
so that, with.λT as in (7.6), 
.ZN = Z N
1
N!
, Z1 = AH
ξ
λ−3
T (1 − exp(−ξ)), (7.72) 
where 
.ξ = mgHβ. (7.73) 
Various thermodynamic quantities resulting from.ZN in (7.72) are: 
1. Invoking (6.34), energy of the gas is found to be given by 
.U = N kBT
[
5
2 − ξ
exp(ξ) − 1
]
. (7.74) 
This shows that (i) when.ξ << 1 then.U → 3N kBT/2. This will be the case when 
. T is high or.mgH is low. (ii) In the opposite limit,.ξ >> 1,.U → 5N kBT/2. 
2. Using (6.35) it can be shown that the entropy of the gas is 
. SN = N kB
[
7
2 − ξ
exp(ξ) − 1 + ln (1 − exp(−ξ)) − 5
2
ln(ξ)
+ ln ( V
N
)
+
3
2
ln(K)
]
, (7.75) 
where.V = AH is the volume of the box and 
.K = 2πm2gH
h2 . (7.76) 
The free gas limit.g → 0 of.SN can be evaluated conveniently by rewriting (7.75) 
in the form 
. SN = N kB
[
7
2 − ξ exp(ξ)
exp(ξ) − 1 + ln (exp(ξ) − 1
ξ
)
+ ln ( V
N
)
+
3
2
ln (2πm
h2β
) ]. (7.77) 
It is straightforward to show that, in the limit.g → 0, i.e..ξ → 0, (7.77) reduces to 
the free gas entropy formula (7.23). The entropy becomes negative for the values 
of . ξ less than the value .ξm which is determined by the solution of .SN (ξm) = 0. 
As discussed circa (7.24), the negativity of entropy is attributed to the failure of 
phase space formalism at low temperatures and/or high densities. 
3. The probability density of finding a molecule in the vicinity of. r is given by (7.16) 
with.v(r) therein in the present case is given by (7.71) so that7.5 Gas in Gravitational Field 217
.ρ(r) = C exp (−mgβz) = ξ exp (−mgβz)
V(1 − exp(−ξ)), V = AH. (7.78) 
Some quantities related with.ρ(r) are: 
a) Since.ρ(r)dxdydz is the probability of finding a molecule in the vicinity of. r, 
.p(z)dz =
[{
ρ(r)dxdy
]
dz (7.79) 
is the probability of finding a molecule in.(z,z + dz). Using (7.78) for.ρ(r), (7.79) 
gives 
.p(z) = ξ exp (−mgβz)
H(1 − exp(−ξ)). (7.80) 
Equivalently, the number of molecules in.(z,z + δz) is given by 
.δn¯(z) = N p(z)δz. (7.81) 
4. Since the gas is inhomogeneous in the .z-direction, its pressure varies with . z. 
We therefore consider gas in the cylinder constituted by the region between . z
and .z + δz, its base area being . A. The pressure due to molecules within the 
cylinder moving in the.z-direction is the pressure.P(z) at. z. It can be evaluated 
using (3.27) by replacing.⟨v2
+x ⟩ therein by.⟨v2
+z⟩, and noting that the number of 
particles in the present case is.δn¯(z): 
.P(z) = 2m δn¯(z)
δV ⟨v2
+z⟩, δV = Aδz. (7.82) 
It is straightforward to see that.2m⟨v2
+z⟩ = kBT . Recall also (7.81) to show that 
(7.82) leads to the following expression for pressure at the height . z above the 
earth’s surface: 
.P(z) = P(0) exp(−mgz/kBT ), P(0) = Nmg
A(1 − exp(−ξ)), (7.83) 
.P(0) being pressure at.z = 0. This is called the barometric formula. In the limit 
.g → 0, the expression above reduces to.P = N kBT/V which is independent of. z
and same as for free non-interacting gas. An alternative approach for determining 
pressure is presented in Sect. 7.5.1. 
5. The average pressure is given by 
.P¯ = 1
H
{ H
0
P(z) dz = N
V
kBT. (7.84)218 7 Non-interacting Classical Gas
We see that the gas in the gravitational field obeys the equation of state of a non￾interacting free gas if the pressure in that equation is replaced by the average 
pressure of the gas in the gravitational field. 
See also [ 5– 8] for thermodynamics of a column of ideal gas ignoring temperature 
gradient. 
7.5.1 Temperature Gradient 
A useful application of the problem addressed above, namely, that of a gas in gravita￾tional field near the surface of earth is to the study of the earth’s atmosphere. However, 
in our formalism so far we have assumed that there is no temperature gradient in 
the gas column as a function of the height, an assumption which does not hold in 
the case of earth’s atmosphere because we know that the temperature decreases with 
height. In the following we show how temperature gradient can be incorporated in the 
theory. We will see that significant temperature change takes place at high altitudes. 
Since the earth’s atmosphere is unbounded from above, the formulas derived 
above for finite height.H assuming uniform temperature apply to earth’s atmosphere 
in the limit .H → ∞. In particular, the (7.80) for the probability per unit height of 
finding a molecule in the vicinity of . z and the equation (7.83) for pressure assume 
the form 
.p(z) = mg
kBT exp (−mgβz), (7.85) 
and 
.P(z) = P(0) exp(−mgz/kBT ), P(0) = Nmg
A . (7.86) 
Recall that we derived the formulas above based on the molecular distribution pre￾dicted by statistical mechanics for the gas at uniform temperature. The statistical 
mechanics formalism as it stands cannot account for temperature gradient in its dis￾tribution function. A different approach, presented below, is therefore required when 
temperature is varying through the height of the gas column. 
To that end, consider the gas in the volume of the cylinder formed by the region 
between the cross-sectional planes of the cylindrical container between the heights 
. z and.z + δz. The pressure of the gas on the plane at. z is the sum of pressure on the 
plane at .z + δz and the weight per unit area of the column of gas between the two 
planes: 
.P(z) = P(z + δz) + mgδn¯(z)/A, (7.87)7.5 Gas in Gravitational Field 219
where.δn¯(z) is average number of molecules in the cylinder. For small. δz, the gas in 
the volume of the cylinder in question can be considered to be at uniform temperature 
.T (z) at the height. z. Consequently the ideal gas law will apply locally so that 
.P(z)(Aδz) = δn¯(z)kBT (z). (7.88) 
On eliminating.δn¯(z) between (7.87) and (7.88 ) we get 
.
P(z + δz) − P(z)
δz = −mg
P(z)
kBT (z)
. (7.89) 
This leads to the following differential equation for.P(z): 
.
dP(z)
dz = −mg
P(z)
kBT (z)
. (7.90) 
If.T (z) is independent of. z the solution of (7.90) would be 
.P(z) = P(0) exp(−mgz/kBT ). (7.91) 
The constant .P(0), which clearly is the pressure at .z = 0, can be found by noting 
that, since the formula above is for uniform temperature, the equation (7.81) for 
.δn(z) would apply. Use the said formula with.H → ∞, to get 
.δn¯(0) = Nmg
kBT
δz. (7.92) 
Substitute this in (7.88) to obtain 
.P(0) = Nmg
A . (7.93) 
The expression (7.91) derived in a different way for the case of uniform temperature 
is the same as that in (7.86) derived by statistical mechanics approach. 
The solution of (7.90) requires knowledge of the functional form of.T (z). It may 
be derived by observing that, in the state of equilibrium, there is no net transfer of 
heat through the column of the gas but there is an exchange of molecules between the 
neighboring layers. The assumption of no net transfer of heat means it is transmitted 
only from the heated earth surface and that the same amount of heat is received by 
earth from sun all the time. It ignores the direct absorption and emission of heat 
by gas molecules, as also the effects due to the presence of moisture. Consequently 
thermodynamic processes operative at equilibrium may be assumed to be adiabatic. 
This implies the temperature .T (z) and pressure .P(z) are such that . T (z)P−ν (z) =
constant where.ν = (γ − 1)/γ,.γ = Cp/CV (see (1.88)) so that220 7 Non-interacting Classical Gas
.T (z)P−ν (z) = constant, ν = γ − 1
γ . (7.94) 
On differentiating the equation above we obtain 
.
dT (z)
dz = νT (z)
P(z)
dP(z)
dz . (7.95) 
Invoking (7.90) this reduces to 
.
dT (z)
dz = −r, r = mgν
kB
. (7.96) 
This shows that temperature decreases linearly by.r K per unit length and 
.T (z) = T (0) − r z. (7.97) 
The rate. r has been evaluated in Exercise 7.3 for some commonly employed values 
of .m and . γ. It predicts a reduction of about .0.0097 K per meter above the surface 
of earth. The observed value of. r is.≈ 0.0065 K per meter up to about .11 Km. The 
discrepancy in the theoretical and observed values of . r is evidently attributable to 
various assumptions which have been made to arrive at (7.95). 
The pressure, obtained by substituting (7.97) in (7.94), is 
.P(z) = P(0)
(
1 − r
T0
z
)1/ν
. (7.98) 
This gives pressure at height. z above the surface of earth. 
For further details see [ 7– 9]. 
Exercises 
Ex. 7. 1. Let .P(0) denote the atmospheric pressure at the sea level. Assuming 
.P(0) = 1 atmosphere, show that the molecular mass per unit area at sea 
level is approximately 1 kg/.cm2, given.g = 980 cm s−2. 
Ex. 7. 2. Show that the average height of a molecule in earth’s atmosphere is 
.kBT/mg. 
Ex. 7. 3. Calculate . r defined in (7.95) assuming the mass .m of the molecules in 
the atmosphere to be 28.96 atomic mass unit and the adiabatic constant 
.γ = 1.4. Hint: Rewrite . r in the form .r = (mc2)(g/c2kB)(γ/(γ − 1)) and 
use the following units conversion relations and the values of the constants: 
.(amu)c2 = 931.4 Mev, .kB = 8.617 × 10−5 eV/K, .g = 980 cm s−2, . c =
3 × 1010 cm s−1.7.6 Gibbs Paradox 221
7.6 Gibbs Paradox 
Gibbs paradox is concerned with paradoxical conclusions which follow in the theory 
of mixing of ideal gases if the quantum factor, 
.QN = N!h3N , (7.99) 
appearing in the definition (5.42) of the phase space volume element is ignored. We 
call it the quantum factor because, as brought out in Sect. 8.4.3, it owes its origin to 
the quantum theory. However, as we will see below, the crucial factor in .QN is . N!
which was conjectured by Gibbs much before the advent of the quantum theory. 
To that end note that if the phase space volume element (5.42) is defined without 
the quantum factor.QN then the partition function for the ideal gas of.N molecules 
will be 
.Z˜ N = QN ZN , (7.100) 
where .ZN is the partition function (7.18) for the same gas including the quantum 
factor in the definition of phase space volume element. Since the multiplying factor 
.QN does not change the internal energy, it follows using the expression (6.35) for 
entropy that the entropy .S˜N corresponding to .Z˜ N is related with the entropy . SN
corresponding to.ZN by the relation 
.S˜N = kB
(
βU˜ + ln(Z˜ N )
)
= kBln(QN ) + SN . (7.101) 
Consider two boxes each containing an ideal gas at the same density and temperature. 
One of the boxes is of volume .V1 and contains .N1 molecules of a gas of mass .m1, 
whereas the volume of the other box is.V2 and has.N2 molecules of mass.m2. Their 
entropy corresponding to.ZN is 
.SNk = Nk kB
[
5
2 + ln ( Vk
Nk
)
+
3
2
ln (Uk
Nk
)
+
3
2
ln (4πmk
3h2
)] . (7.102) 
Let the gases mix and attain the state of equilibrium. The quantity of interest is the 
change in entropy of the gas after mixing. We compute that change with and without 
the quantum factor .QN separately for the case of two gases consisting of the same 
type of molecules and that for the gases consisting of different types of molecules. 
Gases Consisting of Same Type of Molecules 
The entropy of each of the two gases before mixing in this case is given by (7.102) 
with.m1 = m2 = m. After mixing it is (.N = N1 + N2,.V = V1 + V2)222 7 Non-interacting Classical Gas
.SN = N kB
[
5
2 + ln ( V
N
)
+
3
2
ln (U
N
)
+
3
2
ln (4πm
3h2
)] . (7.103) 
Since the gases before and after mixing have the same number density, and temper￾ature, we have (.k = 1, 2) 
.
Vk
Nk
= V
N , Uk
Nk
= U
N . (7.104) 
It is then straightforward to see that change in entropy after mixing is 
.ΔS = SN − (SN1 + SN2 ) = 0. (7.105) 
This shows that change in entropy of a gas, initially in two containers at same number 
densities and temperature, remains unchanged when mixed if the quantum factor. QN
is included in defining the phase space volume. 
Now, using (7.101) the change in entropy when the quantum factor is not included 
may be seen to be given by 
.ΔS˜ = S˜N − (S˜N1 + S˜N2 ) = kB{ln(QN /(QN1 QN2 )} + ΔS. (7.106) 
Using (7.105) for.ΔS and the expression for.QN in (7.99) under Stirling’s approxi￾mation, the equation above yields 
. ΔS˜ = kB {N1ln(N/N1) + N2ln(N/N2)}
≡ kB {N1ln(V/V1) + N2ln(V/V2)} > 0, (7.107) 
where second equation is due to (7.104) whereby .N/Nk = V/Vk . The equation 
(7.107) shows that entropy of a gas, initially in two containers at same number 
density and temperature, increases after mixing if the quantum factor is excluded 
from the definition of the phase space volume. 
The conclusion arrived at following (7.107) is unacceptable. For, consider the gas 
in the volume .V consisting of only one kind of molecules, .N in number. We can 
imagine that the said state has been arrived at by starting with the same gas molecules 
in two containers of volume.V1 and.V2, each containing.N1 and.N2 molecules at the 
same density and temperature such that.V = V1 + V2,.N = N1 + N2. The equation 
(7.107) shows that entropy after mixing will depend on the choice of the numbers 
.N1, N2. This is absurd because it means the entropy depends on the history of how 
the state has been arrived at whereas entropy is a function of state and not of how 
the state has been arrived at. This is known as Gibbs paradox. 
We see that the paradox arises if the quantum factor is not included in the definition 
of the phase space volume. There is no paradox if that factor is included in the 
definition of the phase space volume as in that case, as shown in (7.105), there is no 
change in entropy after mixing.7.6 Gibbs Paradox 223
The paradoxical conclusion may be traced to the fact that, as is clear from its 
expression (7.102), . S is extensive. On the other hand, due to the factor .QN , the .S˜N
in (7.23) is not. Inclusion of the factor .QN has the effect of generating expression 
for entropy having the desired property of extensivity. 
The crucial part in that factor behind the difference in the results of with and 
without it is, of course, .N!. Gibbs conjectured it to resolve the paradox. The other 
constant factor in.QN comes from the quantum theory alone. 
The quantum factor must therefore be included in the definition of the phase space 
volume. 
We evaluate change in entropy when two dissimilar gases are mixed and show 
that change in entropy then is the same, irrespective of whether or not the quantum 
factor is included in the definition of the phase space volume. 
Gases Consisting of Dissimilar Molecules 
The entropy of two gases before mixing is given by (7.102) when the quantum factor 
is included in the definition of the phase space volume. After mixing, the gases 
occupy the combined volume .V but are still identifiable differently because they 
consist of different molecules. The entropy of the mixture is the sum of the entropies 
of each of them. The entropy .Sk of the gas numbered . k in the mixture is given by 
(7.102) with.Vk → V .(k = 1, 2). The change in entropy after mixing therefore is 
.ΔS = (S1(V) + S2(V)) − (S1(V1) + S2(V2)). (7.108) 
It is straightforward to show that 
.ΔS = kB
[
N1ln ( V
V1
)
+ N2ln ( V
V2
)] > 0. (7.109) 
On the other hand, when the quantum factor is not included then change in entropy 
is given, following (7.101), by 
.ΔS˜ = S˜N − (S˜N1 + S˜N2 ) = kB{ln(Q,
N /(QN1 QN2 )} + ΔS, (7.110) 
where.Q,
N is the quantum factor after mixing. Recall that the.N! in.QN is to account 
for the symmetry under exchange of particles of the gas. Since the molecules of 
the two gases are distinguishable even after mixing, the exchange symmetry is only 
between the molecules of one type so that.Q,
N = QN1 QN2 . This show that.ΔS˜ = ΔS. 
We thus see that entropy after mixing of two gases consisting of dissimilar molecules 
increases by the same amount whether or not the quantum factor is included in the 
definition of the phase space volume.224 7 Non-interacting Classical Gas
References 
1. H. Tetrode, Ann. der Phys. 38 434 (1912) 
2. O. Sackur, Ann. der Phys. 40 67 (1913) 
3. W. Grimus (2013), arxiV:1112.3748v2 [physics.hist-ph] 
4. J.P. Fransisco, E. Pérez, Eur. J. Phys. 36, 055033 (2015) 
5. P.T. Landsberg, J. Dunning-Davies, D. Pollard, Am. J. Phys. 62, 712 (1994) 
6. H.-C. Kim, G. Kang, J. Korean Phys. Soc. 69, 1597 (2016) 
7. M.N. Berberan-Santos, E.N. Bodunov, L. Pogliani, Am. J. Phys. 65, 404 (1997) 
8. G. Lente, K. Ösz, Chem. Texts 6, 13 (2020). https://doi.org/10.1007/s40828-020-0111-6 
9. E.N. Bodunov, G.G. Khokhlov, J. Phhys, Conf. Ser. 2131, 022053 (2021)Chapter 8 
Ideal Quantum Gases 
Based on the principle of maximum entropy, we developed in Chap. 6 the classical 
phase space, as well as the quantum theoretic formalisms of statistical mechanics. 
Using the phase space formalism, we studied in Chap. 7 the equilibrium statistical 
thermodynamics of a non-interacting gas. We investigate now the consequences of the 
quantum theoretic formalism when applied to free non-interacting gases, called ideal 
quantum gases. The probability distribution in quantum theoretic formalism depends 
on whether or not the molecules are distinguishable. Accordingly we will derive the 
expressions for the probability distributions treating molecules as (i) distinguishable, 
(ii) indistinguishable Fermi particles, and (iii) indistinguishable Bose particles. 
The equilibrium distributions for Fermi and the Bose gases will turn out to be the 
same as the corresponding ones derived in Chap. 4 using the approach based on the 
Boltzmann entropy. We will see that, in the so-called classical limit, the Fermi as 
well as the Bose distributions reduce to the classical phase space distribution derived 
in Chap. 6. We discuss thermodynamics of non-interacting Fermi gas in Chap. 9 and 
that of the Bose gas in Chap. 10. 
In this chapter we study thermodynamics of the gas of distinguishable molecules 
including their internal motion. We will see that when the molecules are considered 
distinguishable and their internal motion is excluded, the properties of the gas are the 
same as those predicted by the phase space method. However, the thermodynamic 
properties associated with the internal motion when treated quantum mechanically, 
turn out to be vastly different from the ones predicted by the phase space approach 
in Chap. 7. 
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4_8 
225226 8 Ideal Quantum Gases
8.1 Canonical Partition Function 
Recall that a system of .N particles in the quantum formalism is described by the 
probability of occupation of its collective energy levels .{En,N }. Since the particles 
are non-interacting, their collective energy will be the sum of energies of individual 
particles. To find possible values of collective energy, let.E1, E2,..., EK be.K possi￾ble single particle energy levels. The number of energy levels can even be infinite. 
Let .{ni} ≡ n1, n2,..., nK be the number of particles occupying levels of energies 
.E1, E2,..., EK respectively. A particular set of values of.{ni},
s defines the collective 
energy.En,N by the relation 
.En,N ≡ En1,n2,...,nK ;N ≡ E{ni};N = Σ
K
i=1
ni Ei, Σ
K
i=1
ni = N. (8.1) 
Following essentially the terminology introduced in Chap. 6, the. nk ’s are referred to as 
the occupation numbers and a particular set.{ni} of the values of the.n,
is defines a state 
of the system. If the particles are indistinguishable, there is only one way to choose 
. k particles to occupy the energy level. Ek . A particular set.{ni} of the values of the. n,
is
then characterizes uniquely a state of the system. On the other hand, distinguishable 
particles can be labeled. In that case same number.nk occupying the energy level. Ek
can be realized by placing differently labeled particles in it thereby characterizing 
different states of same energy corresponding to same particular set of values of.{ni}. 
Following the terminology introduced in Chap. 6, we call those different realizations 
as different configurations corresponding to the same set.{ni}. We denote by.g({nk }), 
called the configurational degeneracy, the number of configurations corresponding 
to the state characterized by the given set.{nk }. 
Consider the defining relation (6.31) for the partition function.ZN . The sum over 
states of different energies therein in the present case is the sum over different sets 
of values of.{nk }. In view of the discussion above it assumes the form 
.ZN = Σ
{ni}
g({ni}) exp(
−β
Σ
K
i=1
ni Ei
)
δ
(
Σ
K
i=1
ni − N
)
. (8.2) 
The.δ(x) (.δ(0) = 1,.δ(x) = 0 for.x /= 0) under the summation ensures that the total 
number of particles in all the levels equals the given number . N. The sum may be 
carried by choosing first, say, a number .n1 between . 0 and . N, then the number . n2
which, in order to ensure that .n1 + n2 ≤ N, must lie between . 0 and .N − n1, then 
the number.n3 which, in order to ensure that.n1 + n2 + n3 ≤ N, must lie between. 0
and.N − n1 − n2 and so on till.nK−1 is chosen from the interval. (0, N − n1 − n2 −
···− nK−2). The remaining number.nk is given by.nk = N − n1 − n2 −··· nK−1. 
The degeneracy factor.g({ni}) for indistinguishable particles is one. We evaluate 
it next for distinguishable particles.8.1 Canonical Partition Function 227
8.1.1 Configurational Degeneracy 
Before evaluating.g({ni}) we illustrate the concept of configurational degeneracy by 
a couple of simple examples. 
Assume that the possible values of energy of a particle are .E1 and. E2. Consider a 
system of two such identical particles labeled .A and . B. They can be placed in the 
said two levels in the following ways (see Fig. 8.1): 
1. Both the particles can be in the level of energy.E1 (Fig. 8.1(i)). The energy of the 
system in this case is .2E1 and the corresponding state is characterized by the set 
of occupation numbers .(n1, n2) = (2, 0). Since mutual permutation of particles 
in this case does not lead to distinct configuration, the state of energy.2E1 has no 
configurational degeneracy. 
2. Both the particles can be in the level of energy .E2 (Fig. 8.1(ii)). The energy of 
the system in this case is.2E2 and the corresponding state is characterized by the 
set of occupation numbers .(n1, n2) = (0, 2). Since mutual permutation of the 
particles does not result in any distinct configuration, the state of energy.2E2 has 
no configurational degeneracy. 
3. One particle can be in the state of energy.E1 and the other in that of energy. E2. The 
energy of the system then is.E1 + E2 characterized by set of occupation numbers 
.(n1, n2) = (1, 1). However, in this case the particle .A can be in .E1 and .B in . E2
(Fig. 8.1(iii)), or the particle .B can be in .E1 and .A in .E2 (Fig. 8.1(iv)). The said 
two ways of placing the particles are two distinct configurations corresponding to 
the same set .(1, 1) of the occupation numbers .(n1, n2). The state of said energy 
therefore has configurational degeneracy equal to two. 
As another example, let three particles labeled.A, B,C be distributed in two levels 
of energies.E1 and. E2. The number of distinct distributions, depicted in Fig. 8.2, are: 
1. All particles can be in the level of energy.E1 (Fig. 8.2(i)) so that the energy of the 
system is .3E1 characterized by the set of occupation numbers .(n1, n2) = (3, 0). 
Since it has only one configuration, the said state has no configurational degen￾eracy. 
Fig. 8.1 Distribution of two 
distinguishable particles in 
two levels 
(i) (ii) 
(iii) (iv) 
A 
A 
A 
A 
B 
B 
B 
B228 8 Ideal Quantum Gases
(i) (ii) 
(iii) (iv) 
A 
A 
B 
B 
(v) 
(vi) (vii) (viii) 
C 
C 
AA 
A 
AA 
A 
B 
B 
B 
B 
B 
B 
C 
CC 
C 
CC 
Fig. 8.2 Distribution of three distinguishable particles in two levels 
2. All particles can be in the level of energy .E2 (Fig. 8.2(ii)) so that the energy 
of the system is .3E2 characterized by the set of occupation numbers . (n1, n2) =
(0, 3). Since it has only one configuration, the said state has no configurational 
degeneracy. 
3. One particle (. C or. B or. A) can be in the level of energy.E2 and the remaining two 
in the level of energy.E1 (Fig. 8.2(iii)–(v)). The energy of the system in this cases 
is .2E1 + E2 corresponding to the occupation numbers .(n1, n2) = (2, 1). Since it 
has three configurations, the said state has three-fold configurational degeneracy. 
4. One particle (. C or. B or. A) can be in the level of energy.E1 and the remaining two 
in the level of energy. E2 (Fig. 8.2(vi)–(viii)). The energy of the system in this cases 
is .E1 + 2E2 corresponding to the occupation numbers .(n1, n2) = (1, 2). Since it 
has three configurations, the said state has three-fold configurational degeneracy. 
To evaluate the degeneracy factor for distinguishable particles in general, consider 
the set of occupation numbers.(n1, n2,..., nK ). If the molecules are distinguishable 
then, following the arguments similar to those given in Appendix D for selecting 
boxes, the number of ways of choosing the given set of numbers is 
.G({ni}) = N!
n1!n2!··· nK !
δ
(
Σ
K
i=1
ni − N
)
. (8.3) 
At the end, however, the fact that the particles are identical is invoked to argue that 
permutation of the particles does not lead to a new state. The desired degeneracy 
is therefore obtained by dividing the degeneracy factor in (8.3), which has been 
obtained assuming the particles to be distinguishable, by the number .N! of their 
permutations to get8.2 Distinguishable Particles 229
.g({ni}) = G({ni})
N! = 1
n1!n2!··· nK !
δ
(
Σ
K
i=1
ni − N
)
. (8.4) 
We use the expression for.g({ni}) derived above to evaluate the partition function of 
distinguishable particles. 
8.2 Distinguishable Particles 
On using (8.4) the partition function (8.2) reads 
.ZNC = 1
N!
Σ
{ni}
N!
n1!n2!··· nK !
x n1
1 x n2
2 ··· x nK
K δ
(
Σ
K
i=1
ni − N
)
, (8.5) 
where 
.xi = exp(−βEi). (8.6) 
The sum on the right side in (8.5) is the multinomial sum which can be evaluated 
using the multinomial summation formula (D.8) to obtain 
.ZNC = 1
N!
(
Σ
K
i=1
xi
)N
. (8.7) 
This shows that 
.ZNC = 1
N!
Z N
1C, (8.8) 
i.e. apart from the multiplying factor of .1/N!, the .N-particle partition function of 
distinguishable particles is a product of single particle partition functions. 
We have thus at hand an analytic expression for the canonical partition function 
of non-interacting distinguishable particles in terms of single particle energies. In 
the following we explore its thermodynamic predictions. 
8.2.1 Classical Ideal Gas 
We will see that the partition function (8.7) predicts same thermodynamic properties 
as does the partition function corresponding to the phase space distribution function of 
the classical gas of non-interacting molecules studied in Chap. 7. Since their partition230 8 Ideal Quantum Gases
function describes thermodynamic properties of the classical gas, the distinguishable 
particles are often said to be classical particles. 
The distinguishability of particles in a non-interacting classical gas can be under￾stood if we recall from the discussion following (7.21) that the classical description 
is valid if the thermal wavelength of the particles is smaller than their average sepa￾ration and that the thermal wavelength is a measure of their de Broglie wavelength. 
The de Broglie wavelength smaller than the separation between particles means their 
de Broglie waves do not overlap which means they can be distinguished. For further 
discussion see Sect. 8.4. 
With.En,N given by (8.1), the probability (6.30) in the present case reads 
.pNC({n j}) = g({n j})
ZNC
Π
K
j=1
x
n j
j . (8.9) 
This stands for the joint probability of finding .n j particles in the energy level . E j
(. j = 1, 2,..., K). Some consequences of interest of (8.9) are: 
1. The probability.pNC(ni) of finding.ni particles in the energy level. Ei , irrespective 
of numbers in other levels, by definition is 
.pNC(ni) = Σ
{n j /=ni}
pNC({n j}). (8.10) 
The notation.{n j /= ni}stands for the set.(n1, n2,..., ni−1, ni+1,..., nK ), i.e. for 
the set of the.n,
js excluding.n j = ni . Recalling (8.9) we have 
. Σ
{n j /=ni}
pNC({n j}) = x ni
i
ni !ZNC
Σ
{n j /=ni}
Π
K
j/=i
x
n j
j
n j !
, Σ
K
j/=i
n j = N − ni .
(8.11) 
On carrying the multinomial sum in the equation above, the .pNC(ni) in (8.10) 
turns out to be given by 
.pNC(ni) = x ni
i
ni !(N − ni)!ZNC
⎛
⎝Σ
K
j/=i
x j
⎞
⎠
N−ni
. (8.12) 
Recalling the expression (8.7) for.ZNC, the equation above reads 
.pNC(ni) = x ni
i N!
ni !(N − ni)!
⎛
⎝Σ
K
j/=i
x j
⎞
⎠
N−ni (
Σ
K
k=1
xk
)−N
. (8.13) 
Verify that the sum of.pNC(ni) over.ni is unity, as it should be.8.3 Quantum Particles 231
2. Average number of particles in the level of energy. Ei is, by definition, 
.n¯iC = Σ
ni
ni pNC(ni). (8.14) 
We leave it as an exercise to show that 
.n¯iC = N xi
(ΣK
i=1 xi
). (8.15) 
Exercises 
Ex. 8.1. Using the formula for configurational degeneracy, show that the number of 
ways of distributing.N distinguishable molecules in.K distinct energy levels 
is .K N . This is the same as the result arrived at in Sect. 4.7.2 in a different 
way. Hint: The desired result is obtained by summing the degeneracy factor 
(8.3) over the. nk ’s and using the multinomial formula. 
8.3 Quantum Particles 
If identical particles are considered indistinguishable even for the purpose of distri￾bution in energy levels, they are called quantum particles. That is because the concept 
of indistinguishability arises in the quantum theory. The configurational degeneracy 
in the quantum case is.g({ni}) = 1. There are, however, restrictions on the number of 
particles that can occupy the same energy level based on the following classification: 
1. Bosons: Those are the particles having zero or integral spin quantum number. A 
level may be occupied by any number of bosons. Hence .ni can take all values 
between. 0 and.N so that the partition function.ZN B for Bosons is same as.ZN in 
(8.2) with.g({ni}) = 1: 
.ZN B = Σ
{ni}
exp(
−β
Σ
K
i=1
ni Ei
)
δ
(
Σ
K
i=1
ni − N
)
. (8.16) 
Unlike the case of classical particles, the sum above cannot be expressed in closed 
analytic form in general. 
2. Fermions: Those are the particles having half-odd integral spin quantum number. 
There cannot be more than one Fermion in any level. Hence possible values of. ni
for Fermions are.ni = 0, 1. Consequently the partition function.ZN F for Fermions 
is obtained by restricting the values of the . ni’s in (8.2) to .(0, 1) so that, with 
.g({ni}) = 1,232 8 Ideal Quantum Gases
.ZN F = Σ
{ni=0,1}
exp(
−β
Σ
K
i=1
ni Ei
)
δ
(
Σ
K
i=1
ni − N
)
. (8.17) 
Unlike the case of classical particles, the sum above cannot be expressed in the 
closed analytic form in general. 
Though, as stated above, we cannot construct.ZN analytically for a quantum gas, as 
shown below, analytic expression for the grand canonical partition function can be 
derived for the gas of quantum particles. 
Exercises 
Ex. 8.2. Derive the canonical partition function for.N bosons distributed in levels of 
energy.±E. Hint: The expression (8.16) for the canonical partition function 
for.N Bosons in the present case reads 
. ZN B = Σ
N
n2=0
Σ
N
n1=0
exp{−β(−n1ε + n2ε)}δ(n1 + n2 − N)
= exp(−βNε)
Σ
N
n1=0
exp(2βn1ε)
= exp{β(N + 1)ε} − exp{−β(N + 1)ε)}
exp(βε) − exp(−βε) . (8.18) 
Ex. 8.3. Consider the gas of non-interacting particles having single particle energy 
levels .E1, E2,..., EK . Determine the canonical partition function for the 
systems of (i) one particle and (ii) two particles for the case of Bose as 
well as Fermi particles. The desired results here are derived in Ex. 8.7 by 
starting from the grand canonical partition function. Hint: The canonical 
partition function for Bosons is given by (8.16). If there is only one particle, 
the possible values of.{ni} are.ni = 1,.nk = 0 for.k /= i so that 
.Z1B = Σ
K
i=1
exp(−βEi). (8.19) 
For two particles, the sum in (8.16) is expressible in the form 
.Z2B = Σ
K
i=1
exp(−2βEi) + Σ
K
i< j=1
exp{−β(Ei + E j)}. (8.20) 
The first term in the equation above corresponds to two particles occupying 
the same state and the second term is for the particles occupying different 
states. Since interchange of particles in different states does not change the 
state, the sum in the second term is restricted to retain only one of the terms8.3 Quantum Particles 233
symmetric under the exchange of the labels .i, j. Equation (8.20) may be 
rewritten as 
.Z2B = ΣK
i=1
exp(−2βEi) +
1
2
⎛
⎝ΣK
i,j=1
exp{−β(Ei + E j)} −ΣK
i=1
exp(−2βEi)
⎞
⎠ . (8.21) 
Hence 
.Z2B = 1
2
(
Σ
K
i=1
exp(−βEi)
)2
+
1
2
Σ
K
i=1
exp(−2βEi). (8.22) 
The canonical partition function for Fermions is given by (8.17). If there 
is only one particle, the possible values of.{ni} in it are.ni = 1,.nk = 0 for 
.k /= i. Hence 
.Z1F = Σ
K
i=1
exp(−βEi). (8.23) 
Since two Fermions cannot occupy the same state, the partition function 
for two Fermions will have only the terms corresponding to two particles 
occupying different energy levels so that 
.Z2F = Σ
K
i< j=1
exp{−β(Ei + E j)}. (8.24) 
This may be rewritten as 
.Z2F = 1
2
(
Σ
K
i=1
exp(−βEi)
)2
− 1
2
Σ
K
i=1
exp(−2βEi). (8.25) 
Note that, unlike the classical gas, apart from the factor.1/N!, the.N particle 
partition function for Bosons and Fermions is not a product of correspond￾ing single particle partition functions. 
Ex. 8.4. Using the partition functions derived in Ex. 8.3 find the energy of systems 
of one and two Bosons and Fermions.234 8 Ideal Quantum Gases
8.4 Grand Canonical Partition Function 
We derive expressions for the grand canonical partition functions of the classical and 
quantum particles by expressing it in terms of the canonical partition function using 
(6.65). 
8.4.1 Classical Particles 
On substituting the expression (8.7) for the classical partition function.ZNC in (6.65) 
the classical grand partition function is found to be given by 
. ZGC = Σ∞
N=0
exp(αN)
N!
(
Σ
K
i=1
exp(−βEi)
)N
= exp(
exp(α)
Σ
K
i=1
exp(−βEi)
)
. (8.26) 
Hence 
.ln(ZGC) = exp(α)
Σ
K
i=1
exp(−βEi). (8.27) 
It is straightforward to see that the average number of particles is 
.N¯ ≡ ∂ln(ZGC)
∂α = ln(ZGC). (8.28) 
We will evaluate (8.27) in Sect. 8.6 for the gas of particles in free space and show 
that it leads to the thermodynamic properties of an ideal gas. 
8.4.2 Quantum Particles 
On substituting in (6.65) the expression (8.2) for .ZN with .g({ni}) = 1, the grand 
canonical partition function of quantum particles reads 
.ZG Q = Σ∞
N=0
Σ
{ni}
exp(αN) exp(
−β
Σ
K
i=1
ni Ei
)
δ
(
Σ
K
i=1
ni − N
)
. (8.29)8.4 Grand Canonical Partition Function 235
It is shown in Ex. 8.5 that the equation above is reducible to the form 
.ZG Q = Σ
{∞}
{nk }={0}
Π
K
j=1
exp {
−n j(βE j − α)
}
. (8.30) 
The probability for the system to have .N particles, and energy .En,N is given by 
(6.59). In the present case, with.En,N as in (8.1), the said probability is 
.pQ({n j}, N) = exp(Nα)
ZG Q
Π
K
j=1
exp(−βn j E j). (8.31) 
This is the joint probability for the system to have .N particles of which .ni are in 
the single particle energy level .Ei (.i = 1, 2,..., K). We apply the results above to 
systems of Bosons and those of Fermions. 
Bosons 
1. Since in this case there is no restriction on the values of the. ni’s, the (8.30) reads 
(.α = μβ), 
.ZG B = Π
K
j=1
Σ∞
n j=0
exp [
−β
{
E j − μ
}
n j
]
. (8.32) 
If.μ < E j for all. j, which means if.μ < E1 where .E1 is the single particle ground 
state energy, then each of the sums in the equation above is convergent and can 
be carried to yield 
.ZG B = Π
K
j=1
[
1 − exp {
−β(E j − μ
)} ]−1
, μ < E1. (8.33) 
Hence 
.ln(ZG B) = −Σ
K
j=1
ln [
1 − exp {
−β
(
E j − μ
)}], μ < E1. (8.34) 
We have thus at hand an analytic expression for the grand partition function for a 
gas of non-interacting bosons. 
2. The occupation probability (8.31) for bosons reads 
.pB({n j}, N) = exp(Nα)
ZG B
Π
K
j=1
exp(−βn j E j). (8.35)236 8 Ideal Quantum Gases
3. The probability .pB(ni) for the system to have .ni bosons in the level of energy 
. Ei , irrespective of the numbers in other levels and the number of bosons is, by 
definition, 
.pB(ni) = Σ∞
N=0
Σ
{n j /=ni}
pB({n j}, N), (8.36) 
where the sum over the occupation numbers excludes that over the occupation 
number.ni of the level of energy. Ei whose probability of occupation is sought. We 
leave it as an exercise to show that 
.pB(ni) = exp (−β(Ei − μ)ni)
(
1 − exp{−β(Ei − μ)}
)
. (8.37) 
4. Average number of particles in energy level. Ei is 
.n¯i B = Σ∞
ni=0
ni pB(ni) = 1
exp{β(Ei − μ)} − 1
, (8.38) 
where the summation has been carried using (8.37) for.pB(ni). 
Fermions 
1. For fermions,.ni = 0, 1. Hence, with.α = μβ, (8.30) reads 
.ZG F = Π
K
i=1
Σ
ni=0,1
exp {−β (Ei − μ) ni}. (8.39) 
On carrying each of the summations above we get 
.ZG F = Π
K
i=1
[
1 + exp {−β(Ei − μ)}
]
. (8.40) 
Hence 
.ln(ZG F ) = Σ
K
i=1
ln [
1 + exp {−β (Ei − μ)}
]
. (8.41) 
We thus have at hand an analytic expression for the grand partition function for a 
gas of non-interacting fermions. 
2. The occupation probability (8.31) for fermions reads 
.pF ({ni}, N) = exp(Nα)
ZG F
Π
K
j=1
exp(−βn j E j). (8.42)8.4 Grand Canonical Partition Function 237
3. The probability to have. ni (.ni = 0, 1) fermions in the level of energy. Ei irrespective 
of numbers in other levels and total number is given by 
.pF (ni) = exp {−β(Ei − μ)ni}
1 + exp{−β(Ei − μ)}
, ni = 0, 1. (8.43) 
Proof of the equation above is left as an exercise. 
4. Average number of fermions in the energy level. Ei is given by 
.n¯i F = Σ
ni
ni pF (ni) = 1
exp{β(Ei − μ)} + 1
. (8.44) 
Summary 
The grand partition function, the probability to have .ni particles in the energy level 
. Ei and average number of particles in that level for Bosons and Fermions are given 
respectively by (.z = exp(α) = exp(μβ)) 
.ln(ZGη) = −η
Σ
K
i=1
ln {1 − ηz exp (−βEi)}, (8.45) 
.pη(ni) = exp {−β(Ei − μ)ni}
[
1 − η exp{−β(Ei − μ)}
]η , (8.46) 
.n¯iη = [exp{β(Ei − μ)} − η]
−1
, (8.47) 
where.η = 1 gives corresponding quantity for Bosons, and.η = −1 that for Fermions 
with the understanding that .ni = 0, 1 for Fermions whereas .ni is unrestricted for 
Bosons. 
Exercises 
Ex. 8.5. Show that 
. Σ∞
N=0
Σ
n1,n2,n3
zN x n1
1 x n2
2 x n3
3 δ (N − n1 − n2 − n3)
= Σ∞
n1=0
Σ∞
n2=0
Σ∞
n3=0
(zx1)
n1 (zx2)
n2 (zx3)
n3 . (8.48) 
Hint: We have238 8 Ideal Quantum Gases
. I ≡ Σ∞
N=0
Σ
n1,n2,n3
zN x n1
1 x n2
2 x n3
3 δ (N − n1 − n2 − n3)
= Σ∞
N=0
Σ
N
n1=0
N
Σ−n1
n2=0
N−
Σn1−n2
n3=0
zN x n1
1 x n2
2 x n3
3 δ (N − n1 − n2 − n3)
= Σ∞
n1=0
Σ∞
N=n1
N
Σ−n1
n2=0
N−
Σn1−n2
n3=0
zN x n1
1 x n2
2 x n3
3 δ (N − n1 − n2 − n3). (8.49) 
Let.N − n1 → N in the sum over.N to rewrite the equation above as 
. I = Σ∞
n1=0
Σ∞
N=0
Σ
N
n2=0
N
Σ−n2
n3=0
zN+n1 x n1
1 x n2
2 x n3
3 δ (N − n2 − n3)
= Σ∞
n1=0
Σ∞
n2=0
Σ∞
N=n2
N
Σ−n2
n3=0
zN (zx1)
n1 x n2
2 x n3
3 δ (N − n2 − n3). (8.50) 
Let.N − n2 → N in the sum over.N to rewrite the equation above as 
. I = Σ∞
n1=0
Σ∞
n2=0
Σ∞
N=0
Σ
N
n3=0
zN (zx1)
n1 (zx2)
n2 x n3
3 δ (N − n3)
= Σ∞
n1=0
Σ∞
n2=0
Σ∞
n3=0
(zx1)
n1 (zx2)
n2 (zx3)
n3 . (8.51) 
The procedure outlined above may be generalized to an arbitrary number 
of. ni’s to get the identity (8.30). 
Ex. 8.6. Consider a system of.N Bosons distributed in levels of energy.±E. (a) Using 
the expression for.ZN B derived in Ex. 8.2, construct the corresponding grand 
canonical function.ZG B. (b) Derive.ZG B directly using the general formula 
for the grand partition function for Bosons. Hint: (a) The grand partition 
function is given by (with.α = μβ) 
.ZG B = Σ∞
N=0
exp(μβN)ZN B = Z
exp(βE) − exp(−βE)
, (8.52) 
where 
. Z = Σ∞
N=0
[
exp(βE) exp{(E + μ)Nβ}
− exp(−βE) exp{−(E − μ)Nβ}
]
. (8.53)8.4 Grand Canonical Partition Function 239
First sum above will converge only if.μ < −E, in which case second sum will 
also converge. This is in accordance with the general result that the chemical 
potential of non-interacting Boson gas is less than the single particle ground 
state energy (see (8.33)). We let.μ → −|μ| so that.μ > E to obtain 
.Z = exp(βE) − exp(−βE}
[1 − exp{−(|μ| − E)β}][1 − exp{−(|μ| + E)β}]. (8.54) 
Substitution of the equation above in (8.52) yields the desired expression: 
.ZG B = 1
[1 − exp{−(|μ| − E)}][1 − exp{−(|μ| + E)β}]. (8.55) 
General formula for Bosonic grand partition function is given by (8.45) 
for .η = 1. It will yield the same result as in (8.55) with .E1 = −E, . E2 = E
and.μ → −|μ|. 
Ex. 8.7. Consider the gas of non-interacting particles having single particle energy 
levels.E1, E2,..., EK . Starting from the grand canonical partition function, 
determine the canonical partition function for the systems of (i) one particle 
and (ii) two particles for the case of Bose as well as Fermi particles. The 
desired results here are derived directly in Ex. 8.3 using the definition of 
the canonical partition function. Hint: Recall that 
.ZG(z) = Σ∞
N=0
zN ZN , ZN = 1
N!
dN ZG
dzN
|
|
|
|
z=0
. (8.56) 
The grand canonical partition function for free Bosons and Fermions is 
given by (8.45): 
.ln(ZGη) = −η
Σ
K
i=1
ln {1 − ηz exp (−βEi)}. (8.57) 
Note that 
.ZGη(0) = 1. (8.58) 
With.ZG(z) → ZGη(z), use (8.56) to evaluate the canonical partition func￾tion.ZNη for different values of. N. 
(i).N = 1. In this case 
.Z1η = dZGη(z)
dz
|
|
|
|
z=0
= ZGη(z)
dlnZGη(z)
dz
|
|
|
|
z=0
= Σ
K
i=1
exp(−βEi). (8.59)240 8 Ideal Quantum Gases
(ii).N = 2. In this case 
. Z2η = 1
2
d2ZGη(z)
dz2
|
|
|
|
z=0
= 1
2
d
dz
[
ZGη(z)
dlnZGη(z)
dz
] |
|
|
|
z=0
= 1
2
[
ZGη(z)
(dlnZGη(z)
dz
)2
+ Zη(z)
d2lnZGη(z)
dz2
] |
|
|
|
z=0
= 1
2
⎡
⎣
(
Σ
K
i=1
exp(−βEi)
)2
+ η
Σ
K
i=1
exp(−2βEi)
⎤
⎦ . (8.60) 
The results derived above are the same as those derived in (Ex. 8.3). 
8.4.3 Classical Limit of Quantum Distributions 
When.z << 1 then, under the approximation.ln(1 + x) ≈ x for.x << 1 and noting 
that.η2 = 1, (8.45) reduces to 
.ln(ZGη) = exp(α)
Σ
K
i=1
exp(−βEi). (8.61) 
This is same as the grand canonical partition function (8.27) of the classical gas. 
Hence, both the quantum distributions reduce to the classical one under the condition 
.z << 1. To understand its meaning in terms of observables, recall the expression 
(8.28) for the average number of particles in the classical gas to recast the condition 
.z << 1 in the form 
.N¯ << Σ
i
exp(−βEi). (8.62) 
Written in this form, the condition under which quantum gases behave like a classical 
gas is useful for relating it with observable entities. We will discuss the meaning of 
(8.62) in Sect. 8.8 for gas in free space. 
We thus see that it is not that there are two categories of particles: distinguishable 
and indistinguishable. The particles are fundamentally indistinguishable. It is only 
under certain conditions, like the one in (8.62), that their thermodynamic behavior 
is akin to that of distinguishable particles. As was pointed out in Sect. 8.2.1 and will 
be brought out again in Sect. 8.8 by examining the condition (8.62) when particles 
are in free space, the distinguishability shows up when the thermal wavelength of 
particles, a measure of their de Broglie wavelength, becomes smaller than their 
average separation.8.5 Single Particle Energy Levels in Free Space 241
Next we determine single particle energy levels in free space and find explicit 
expressions for the partition functions of different classes of particles. 
8.5 Single Particle Energy Levels in Free Space 
In this section we address the problem of evaluating the sum over energy levels in 
(8.45) for the gas of non-interacting molecules in a box of large volume. The energy 
levels of a particle in a box are discrete. However, in the limit of large volume, the 
separation between successive energy levels turns out to be so small that the discrete 
sum may be transformed, to good approximation, to an integral by the replacements, 
.Ei → E, Σ
i
f (Ei) →
{
f (E)D(E)dE, (8.63) 
where .D(E), called the density of states, denotes the number of states in the unit 
interval of energy. The problem, addressed below, then reduces to finding . D(E)
which depends on (i) the functional relationship between energy and momentum and 
(ii) the dimensionality of the system. 
8.5.1 Determining Density of States 
Let us assume that energy is related with momentum by the relation 
.E = E(p), p = p(E), p ≡ |p|. (8.64) 
For example, 
1. For a particle of mass.m moving in free space with non-relativistic speed, 
.E(p) = p2
2m . (8.65) 
2. For a particle of mass.m moving in free space with relativistic speed, 
.E(p) =
/
p2c2 + m2
0c4. (8.66) 
3. In ultra-relativistic limit .m0c2 << pc which corresponds to the particle energy 
being much greater than its rest mass energy, (8.66) reduces to 
.E(p) = pc. (8.67)242 8 Ideal Quantum Gases
4. The relation (8.67) applies also to photons as they are massless. 
We find density of states for motion in different dimensional spaces. 
Density of States in Three-Dimensional Motion 
Consider a particle moving in a box whose three sides are of length . Lx , Ly , Lz
respectively. The wave function .ψ(r) of such a particle obeying periodic boundary 
conditions, 
. ψ(0, y,z) = ψ(Lx , y,z), ψ(x, 0,z) = ψ(x, Ly ,z),
ψ(x, y, 0) = ψ(x, y, Lz) (8.68) 
is known to be given by 
.ψ(r) = C exp(ip · r/h), C = 1
/Lx Ly Lz
, (8.69) 
where, due to (8.68), 
.px = nx
Lx
h, py = ny
Ly
h, pz = nz
Lz
h, (8.70) 
with.nx , ny , nz = 0, ±1, ±2 .... 
Consider the problem of evaluating sum over. i of some function. f (Ei). The sum￾mation index . i stands for different states. In the present case, the states are labeled 
by the numbers.(nx , ny , nz) due to which sum over. i is that over.(nx , ny , nz): 
.I = Σ
i
f (Ei) ≡ Σ
nx ,ny ,nz
f (nx , ny , nz). (8.71) 
For large .(nx , ny , nz), the separation between successive levels becomes small 
enough to permit replacement of sum by integral: 
. Σ
nx ,ny ,nz
f (nx , ny , nz) =
{ ∞
−∞
dnx
{ ∞
−∞
dny
{ ∞
−∞
f (nx , ny , nz)dnz
= Lx Ly Lz
h3
{ ∞
−∞
d px
{ ∞
−∞
d py
{ ∞
−∞
f (px , py , pz)d pz,
(8.72) 
where the second line is due to (8.70). The sum over.(nx , ny , nz) is thus transformed 
to an integral by means of the relation,8.5 Single Particle Energy Levels in Free Space 243
.
Σ
nx ,ny ,nz
f (nx , ny , nz) = V
h3
{
f (px , py , pz) d3 p, (8.73) 
where.V is the volume of the box. 
We are interested in evaluating the sum (8.71) where. f (px , py , pz)is a function of 
energy. E which, in turn, is a function of.p ≡ |p|. The integral over the momentum in 
(8.73) is then evaluated by transforming it to that over. E as follows. In spherical polar 
coordinates in the momentum space, we have.d3 p = p2d p sin(θ)dθdφ, (.0 ≤ θ < π, 
.0 ≤ φ < 2π,.0 ≤ p ≤ ∞) the angular integration in (8.73) can be performed leading 
to 
. 
V
h3
{
f (px , py , pz) d3 p = 4πV
h3
{ ∞
0
f (E(p)) p2
d p =
{ ∞
0
f (E) D(E)dE,
(8.74) 
where we have transformed integration over momentum to that over energy with the 
density of states given by 
.D(E) =
(4πV
h3
) (p2 d p
dE
)
. (8.75) 
We evaluate below the expression above for the density of states for various com￾monly encountered functional forms of.p(E). 
1. For non-relativistic motion of a free particle of mass . m, the use of the relation 
(8.65) between. E and. p in (8.75) yields 
.D(E) = A
√E, A = 2πV
(2m
h2
)3/2
. (8.76) 
2. For a massless particle, or for particles moving with relativistic speed, with. p(E)
given by (8.67), (8.75) yields 
.D(E) = 4πV
h3c3 E
2
. (8.77) 
Similar relation is obeyed by phonons in an isotropic solid but with. c replaced by 
the velocity.cs of sound. 
Density of States in Two-Dimensional Motion 
If a particle is constrained to move in two-dimensional space, say, in the . x–y
plane, then it is described by the wave function (8.69) but with .r = xex + yey , 
.C = 1/
/Lx Ly and.p = px ex + py ey with.(px , py ) given in terms of integers. nx , ny
as in (8.70). The summation over .nx , ny is then approximated by the integral as 
follows:244 8 Ideal Quantum Gases
. Σ
nx ,ny
f (nx , ny ) = Lx Ly
h2
{ ∞
−∞
d py
{ ∞
−∞
f (px , py )d px
= σ
h2
{
f (px , py ) d2 p, (8.78) 
where.σ = Lx Ly is the area of the region occupied by the gas. The. f (px , py ) in our 
case shall be a function of .E(p), .p ≡ |p|. With .d2 p = pd pdφ, (.0 ≤ φ < 2π), the 
angular integration in (8.78) can be performed to obtain 
.
Σ
nx ,ny
f (E(p)) = 2πσ
h2
{ ∞
0
f (E(p)) p d p ≡
{ ∞
0
f (E) D(E)dE, (8.79) 
with the density of states given by 
.D(E) =
(2πσ
h2
) (p
d p
dE
)
. (8.80) 
1. For non-relativistic motion of a free particle of mass. m, with.p(E) given by (8.65), 
(8.80) yields 
.D(E) = 2mπσ
h2 . (8.81) 
The density of states in this case is independent of energy. 
2. For a massless particle, or for the particles moving with relativistic speed, the 
.p(E) is given by (8.67) on substituting which in (8.80) we obtain 
.D(E) = 2πσ
c2h2 E. (8.82) 
Density of States in One-Dimensional Motion 
If a particle is constrained to move in one dimension, say, along the.x-axis. (0 ≤ x ≤
L), then it is described by the wave function (8.69) but with .r = xex , .C = √1/L, 
.p = pex with.p = hn/L. The summation over . n may then be approximated by the 
integral as follows: 
. Σ
n
f (n) = L
h
{ ∞
−∞
f (E) d p = 2L
h
{ ∞
0
f (E(p)) d p
=
{ ∞
0
f (E) D(E)dE, (8.83)8.5 Single Particle Energy Levels in Free Space 245
with the density of states given by 
.D(E) =
(2L
h
) (d p
dE
)
. (8.84) 
For non-relativistic motion of a free particle of mass. m, the use of the relation (8.65) 
between. E and. p in (8.80) yields 
.D(E) =
/2m
h2 LE
−1/2
. (8.85) 
Summary 
The sum over states of a function of closely spaced discrete energies is converted to 
an integral by the relation: 
.
Σ
i
f (Ei) =
{
f (E)D(E)dE, (8.86) 
where.D(E) is the density of states given for different spatial dimensions by 
.D(E) = Ad pd−1 d p
dE
, (8.87) 
where. d is the dimension of space in which particles are moving with 
.A3 = 4πV
h3 , A2 = 2πσ
h2 , A1 = 2L
h . (8.88) 
In the expressions above. V ,. σ,. L are respectively the volume, area, and length of space 
in which particles move. Several widely encountered energy-momentum relations 
are of the form: 
.E = Cn pn. (8.89) 
The expression (8.87) then reads 
.Dnd (E) = And E
(d−n)/n, And = Ad
nCd/n n
. (8.90) 
This is the density of states for a.d-dimensional system when the energy-momentum 
relation is of the form (8.89). The expressions for .Dnd for the values of .(n, d) of 
common interest are tabulated in Table 8.1. 
We apply the results derived above to investigate thermodynamic properties of 
classical and quantum gases in free space.246 8 Ideal Quantum Gases
Table 8.1 Density of states.Dnd given by (8.90) for different motion types and spatial dimensions 
Motion type Spatial Dimension .E = Cn pn . Dnd
Non-Relativistic 3 .
p2
2m . 2πV
(2m
h2
)3/2 √E
Ultra-Relativistic 3 .cp . 
4πV
h3c3 E2
Non-Relativistic 2 .
p2
2m . 
2mπσ
h2
Ultra-Relativistic 2 .cp . 
2πσ
h2c2 E
Non-Relativistic 1 .
p2
2m . / 2m
h2 LE−1/2
Ultra-Relativistic 1 .cp . 
2L
hc
8.6 Thermodynamics of Ideal Classical Gas 
We studied the thermodynamics of the gas of free non-interacting molecules in 
Chap. 7 in phase space formalism. In Sects. 8.1 and 8.4 we derived expressions for 
the canonical and grand canonical partition functions in the quantum formalism. In 
this section we investigate thermodynamics of the gas of non-interacting molecules 
in a box of large volume in the quantum formalism assuming the molecules to be 
distinguishable. We will see that, if the internal motion of the molecules is ignored, 
then the quantum formalism is equivalent with the phase space formalism. However, 
the quantum treatment of the internal degrees of freedom leads to results at variance 
with those predicted by the phase space approach. 
8.6.1 Translational Motion 
The partition function of the gas of.N free non-interacting distinguishable molecules 
is given by (8.7). If the molecules are in a large three-dimensional box then the 
sum can be replaced by an integral using the correspondence (8.86) if the molecular 
speeds are non-relativistic: 
.
Σ
i
exp(−βEi) =
{ ∞
0
exp(−βE)D(E)dE = V
λ3
T
, (8.91) 
where in writing the second equation we have used the expression (8.76) for .D(E)
and (7.6) of thermal wavelength .λT. On combining this with (8.7) we see that the 
resulting partition function is same as (7.18) derived using phase space approach.8.6 Thermodynamics of Ideal Classical Gas 247
Similarly, on using (8.91), in (8.27) we get the same grand partition function as the 
expression (7.28) for the grand partition function derived using the method of phase 
space distribution function. 
8.6.2 Internal Motion 
We have constructed the partition function for the translational motion of molecules. 
We construct now the partition function taking in to account their internal motion. 
To that end, we need to know the molecular energy levels. We assume that they are 
constituted by two components: the energies.{Etrans
i } due to the translational motion of 
the molecular center of mass and.{Eint
i } due to its internal motion. The internal motion 
could be rotational, vibrational, or even electronic transitions between atomic levels. 
The single particle energy levels are then specified in terms of two indices, one 
referring to the kinetic energy, and the other to the internal energy: 
.Ei j = E
trans
i + E
int
j , i = 1, 2,...; j = 1, 2,..., M, (8.92) 
where we have assumed that there are .M internal energy levels. We construct the 
partition function using (8.7) which involves finding the sum over the energy states. 
Since the energy states are now identified by two indices, the sum therein reads 
.
Σ
i
Σ
M
j=1
exp(−βEi j) =
(
Σ
i
exp(−βEtrans
i )
) ⎛
⎝Σ
M
j=1
exp(−βEint
j )
⎞
⎠ . (8.93) 
Consequently the partition function (8.7) assumes the form 
.ZNC = Ztrans
NC Zint
NC. (8.94) 
The translational motion has been investigated in the Sect. 8.6.1 above. 
The partition function for the internal motion is 
.Zint
NC =
⎛
⎝Σ
M
j=1
exp(−βEint
j )
⎞
⎠
N
. (8.95) 
In the following we evaluate the partition function.Zint
NC in (8.95) for internal motion 
of polyatomic molecules. 
As discussed in Sect. 7.4, the internal energy of a molecule in its phase space 
description consists of contributions from its rotational and the vibrational degrees 
of freedom. Since they do not admit phase space description, the electronic transitions 
inside the atoms could not be included in the evaluation of the partition function by248 8 Ideal Quantum Gases
phase space approach. We now include the energy of electronic transitions within the 
atoms, calling it the electronic energy. The molecular energy levels are consequently 
expressed in terms of three indices, one each for rotational, vibrational, and electronic 
energy levels: 
.E
int
ijk = E
rot
i + E
vib
j + E
elect
k . (8.96) 
The partition function (8.95) for internal energy consequently reads 
.Zint
NC = (Zrot1Zvib1Zelect1)N , (8.97) 
where 
. Zrot1 = Σ
i
exp (
−βErot
i
)
, Zvib1 = Σ
j
exp (
−βEvib
j
)
,
Zelect1 = Σ
k
exp (
−βEelect
k
) (8.98) 
are single molecule partition functions. In the following we evaluate.Zrot1 and. Zvib1
for a diatomic as well as for polyatomic molecules and show that they are very much 
different from their counterparts evaluated using the phase space approach. We also 
evaluate.Zelect1 for a two-level system. 
Rotational Motion: Diatomic Molecules 
The classical Hamiltonian of a diatomic molecule describing its rotational motion is 
given by (7.55). The quantum Hamiltonian corresponding to it is 
.Hˆrot = 1
2I
Lˆ 2
. (8.99) 
We know that the eigenvalues of the angular momentum operator.Lˆ 2 are. h2L(L + 1)
where.L = 0, 1,... ∞. Hence the rotational energy levels of the molecule are 
.EL = 1
2I
h2L(L + 1). (8.100) 
The eigenvalue of.Lˆ 2 corresponding to. L is.2L + 1-fold degenerate. Hence the single 
particle partition function is 
.Zrot1 = Σ∞
L=0
(2L + 1) exp{−αL(L + 1)}, α = h2β
2I . (8.101) 
It is not possible to perform the sum above analytically. However, we can see that, 
with the partition function given by (8.101), the internal energy is no longer pro-8.6 Thermodynamics of Ideal Classical Gas 249
portional to .T and consequently heat capacity is temperature dependent. We can 
study temperature dependence of .Zrot1 by evaluating it approximately in the limit 
of low and high temperatures in comparison with what is called the characteristic 
temperature .Θr of rotation. To define it, note that the separation between nearest 
levels is 
.EL+1 − EL = h2(L + 1)
I . (8.102) 
The characteristic temperature.Θr of rotation is defined as half the temperature equiv￾alent of the smallest rotational transition energy: 
.Θr = 1
2kB
(E1 − E0) = h2
2I kB
. (8.103) 
The .Θr is a measure of minimum thermal energy required to induce a transition 
between rotational levels. Using (8.103), the rotational partition function (8.101) 
may be rewritten as 
.Zrot1 = Σ∞
L=0
(2L + 1) exp{−(Θr /T )L(L + 1)}. (8.104) 
We consider two cases: (1).T << Θr and (2).T >> Θr. 
1. Consider the case .T << Θr. In this case only a small number of terms will 
contribute to the sum in (8.104). Higher the value of.Θr /T , smaller is the number 
of terms contributing significantly to the said sum. For example, for Hydrogen 
molecule,.Θr ≈ 85.3 K. It may be seen that in that case first three terms in the sum 
would contribute to within .0.1% even at room temperature .T = 300 K. On the 
other hand, much lower temperatures are required to get similar accuracy from 
similar number of terms for molecules like .O2, N2,CO, NO for which the value 
of .Θr is in the range .2 − 3 K. In case .Θr /T is so high that contribution from 
.L ≥ 1 becomes insignificant,.Zrot1 = 1 which being independent of temperature 
does not contribute to the heat capacity. In this case average thermal energy. kBT
is not enough to excite even the lowest rotational level. 
2. In case.T >> Θr, we can treat. L as a continuous variable and replace the sum in 
(8.104) by an integral so that 
.Zrot1 =
{ ∞
0
(2x + 1) exp{−(Θr /T )x(x + 1)}dx = T
Θr
. (8.105) 
The integral above has been carried by changing the variable of integration from. x
to.y = x(x + 1). Clearly, the energy per molecule in this case is.kBT and the heat 
capacity per molecule is. kB, which is same as when the gas is treated classically. 
In this case average thermal energy.kBT is good enough to excite even the higher250 8 Ideal Quantum Gases
Fig. 8.3 Heat capacity per 
molecule.cdiat/kB of the gas 
of diatomic molecules as a 
function of. T/Θr
rotational levels. We thus see that the classical limit is achieved when temperature 
is high enough for the thermal energy to excite high energy levels. 
Figure 8.3 is a plot of .cdiat/kB, where .cdiat is rotational specific heat per molecule 
of the gas of diatomic molecules, as a function of normalized temperature . T/Θr
evaluated by numerical computation of the relevant series. 
It exhibits the predicted limiting behavior of.cdiat namely it approaches. 0 as. T → 0
and approaches.kB as.T → ∞. The.cdiat, however, is not a monotonic function of. T ; 
it exhibits a maximum from which it decreases to approach the classical limit. This 
is called Schottky anomaly or Schottky hump. We will see similar non-monotonic 
behavior of the heat capacity in cases where the energy spectrum is non-linear. 
Rotational Motion: Polyatomic Molecules 
The classical Hamiltonian describing rotation of a molecule is given by (7.62). Its 
quantum analog is [ 1] 
.Hˆrot = 1
2I1
Lˆ 2
1 +
1
2I1
Lˆ 2
2 +
1
2I3
Lˆ 2
3. (8.106) 
We restrict our attention to spherical molecules defined as the ones for which . I1 =
I2 = I3 ≡ I so that (8.106) reduces to 
.Hˆrot = 1
2I
Lˆ 2
, Lˆ 2 = Lˆ 2
1 + Lˆ 2
2 + Lˆ 2
3. (8.107) 
This is of the form (8.99) of a diatomic molecule. Its energy levels are given by 
(8.100). This similarity between diatomic, and the spherically symmetric molecule 
in the quantum theory makes one wonder: if so, what leads to different heat capac￾ities of the two? For, in classical treatment, we saw that the energy per molecule of 
a diatomic gas is .kBT whereas it is .3kBT/2 for a non-linear polyatomic gas. The 
difference lies in the fact that the eigenvalue of .Lˆ 2 corresponding to . L in a spher-8.6 Thermodynamics of Ideal Classical Gas 251
Fig. 8.4 Heat capacity per 
molecule.cpoly/kB of gas of 
spherical polyatomic 
molecules as a function of 
. T/Θr
ical molecule is .(2L + 1)2-fold degenerate [ 1]. Recall that the said degeneracy in 
a diatomic molecule is.2L + 1-fold. Hence single particle partition function for the 
gas of spherical molecules is 
.Zrot1 = Σ∞
L=0
(2L + 1)
2 exp{−(Θr /T )L(L + 1)). (8.108) 
We can study the limiting cases of low and high temperatures in the same way as 
we did for the gas of diatomic molecules. In particular, if temperature is high so that 
.Θr /T << 1 then the sum in (8.108) can be approximated by an integral so that 
.Zrot1 =
{ ∞
0
(2x + 1)
2 exp(−αx(x + 1))dx ≈
( 2I
h2β
)3/2
. (8.109) 
This shows that energy per molecule is .3kBT/2 which is same as that when the 
polyatomic gas is treated classically. We once again see that the quantum and clas￾sical predictions agree in the high-temperature limit. Figure 8.4 is a plot of.cpoly/kB, 
where.cpoly is rotational specific heat per molecule of the gas of spherical polyatomic 
molecules, as a function of normalized temperature .T/Θr evaluated by numerical 
computation of the relevant series. It exhibits the predicted limiting behavior of. cpoly
namely it approaches . 0 as .T → 0 and approaches .3kB/2 as .T → ∞. Like the gas 
of diatomic molecules the heat capacity in the present case also exhibits Schottky 
anomaly i.e..cpoly is not monotonic as a function of. T . 
See [ 2] for detailed study of temperature dependence of heat capacity of methane, 
which is a spherical top, along with experimental data. 
Vibrational Motion 
We construct the partition function for the vibrational motion of atoms constituting 
a molecule assuming the constituent atoms to be non-identical. Such molecules are252 8 Ideal Quantum Gases
called heteronuclear. The molecules consisting of identical atoms, called homonu￾clear, require different treatment, not undertaken here, because of the quantum the￾oretic requirement of definite parity of the wave function under the exchange of 
identical atoms. 
The classical Hamiltonian describing vibration of atoms of mass. μ with frequency 
. ω along the line joining them is given by (7.64). The corresponding quantum Hamil￾tonian is 
.Hˆvib = pˆ2
η
2μ
+ μω2
2 ηˆ
2
. (8.110) 
The energy eigenvalues of the Hamiltonian above are known to be given by 
.E
vib
n = hω
(
n +
1
2
)
, n = 0, 1,...,∞. (8.111) 
Hence the partition function for the said vibrational motion is 
.Zvib,ω = Σ∞
n=0
exp {−hωβ(n + 1/2)} = 1
2sinh(βhω/2)
. (8.112) 
The corresponding energy and the heat capacity are 
.Uvib,ω = hω
2
coth(βhω/2), (8.113) 
and 
.Cvib,ω = kB
(βhω
2
)2
cosech2
(βhω/2). (8.114) 
This shows that the heat capacity is temperature dependent. In the limit.βhω >> 1, 
.Cvib,ω → kB which is the classical result. 
As discussed in Sect. 7.4.2, there is one vibrational mode in a diatomic molecule 
and .3N − 6 in a polyatomic molecule consisting of .N ≥ 3 atoms. Total contribu￾tion from the vibrational modes will be the sum of contributions from all those modes. 
Electronic Transitions 
Consider an atom modeled as the one in which an electron can make transitions 
between only two levels of energies. 0 and.E > 0. Its partition function is evidently 
.Zelect1 = 1 + exp(−βE). (8.115)8.6 Thermodynamics of Ideal Classical Gas 253
Fig. 8.5 Heat capacity per 
atom.celect/kB of a system of 
two-level atoms as a function 
of. kBT/E
We leave it as an exercise to show that energy and heat capacity per atom of system 
of such atoms are given by 
.uelect = E exp(−βE)
1 + exp(−βE)
, (8.116) 
.
celect
kB
= (E/2kBT )
2
sech2
(E/2kBT ). (8.117) 
Figure 8.5 depicts.celect/kB as a function of.kBT/E. It exhibits maximum at. kBT/E ≈
0.416 which is approximately the value solving the equation 
.
kBT
E = (1/2)tanh(E/2kBT ). (8.118) 
We once again witness Schottky anomaly in the behavior of the heat capacity as a 
function of. T similar to that observed in the rotational motion. 
Exercises 
Ex. 8.8. .N distinguishable non-interacting particles of mass .m are moving in one￾dimensional zero potential between infinite potential walls at .x = 0 and 
.x = L at temperature. T . The single particle energy levels are given by 
.En = E0n2
, E0 = π2h2
2m L2 n = 1, 2,... (8.119)254 8 Ideal Quantum Gases
Fig. 8.6 Heat capacity per 
particle.cbox/kB of the gas of 
particles in an infinitely deep 
potential well as a function 
of. kBT/E0
Construct the partition function and evaluate it in the limits of. E0 << kBT
and.E0 >> kBT . Hint: The single particle partition function is 
.Z1 = Σ∞
n=1
exp(−βE0n2
). (8.120) 
This sum cannot be evaluated analytically exactly. In case.E0 << kBT , the 
sum can be approximated by an integral: 
.Z1 ≈
{ ∞
0
exp(−βE0x 2
) dx − 1 = 1
2
/ π
E0β . (8.121) 
At high temperatures the energy per particle is therefore.kBT/2. In the oppo￾site limit.E0 >> kBT , dominant contribution comes from.n = 1 whereby 
.Z1 = exp(−βE0). (8.122) 
The energy per particle is therefore. E0. This is understandable as the particles 
tend to occupy the lowest energy level.E0 as.T → 0. Figure 8.6 is a plot of 
scaled heat capacity per particle.cbox/kB as a function of.kBT/E0 obtained 
by numerical computation of the relevant series. Like other systems we 
encountered having non-linear spectrum, the heat capacity in this case too 
exhibits Schottky anomaly. 
Ex. 8.9. Find the entropy of the system having two levels of energy:. 0 and.E > 0.8.7 Thermodynamics of Quantum Gases 255
8.7 Thermodynamics of Quantum Gases 
We now consider a gas of indistinguishable non-interacting atoms in three￾dimensional free space. As mentioned before, we do not have closed-form analytic 
expression for the canonical partition function of such a gas but have it for its grand 
canonical partition function, given in (8.45). We therefore investigate thermodynamic 
properties of such a gas working with its grand canonical partition function. 
1. The grand partition function.ZGη is defined in (8.45) in terms of a sum over single 
particle energies. We will see that for a Bosonic gas, above some critical value 
of.Nλ3
T/V at which.z ≡ exp(α) = 1, one needs to separate the ground state term 
before replacing the rest of the discrete sum by the integral. Bearing in mind 
that .η = 1 corresponds to the system of Bosons, we rewrite (8.45) for all . z as 
(assuming.E1 = 0) 
.ln(ZGη) = −η
Σ
k/=1
ln{1 − ηz exp(−βEk )} − ln(1 − z)δη1. (8.123) 
Since removing a point from the range of integration does not change its value, 
we invoke (8.86) to replace the sum by the integral to get 
. ln(ZGη) = −η
{ ∞
0
D(E){ln{1 − ηz exp(−βE)}dE − ln(1 − z)δη1
= −η
A
β3/2
{ ∞
0
√x ln{1 − ηz exp(−x)}dx − ln(1 − z)δη1,
(8.124) 
where we have recalled (8.76) defining.D(E) and changed the variable of integra￾tion from. E to.x = βE. On integrating (8.124) by parts we obtain 
.ln(ZGη) = 2A
3β3/2
{ ∞
0
x 3/2 dx
z−1 exp(x) − η − ln(1 − z)δη1. (8.125) 
2. Invoking (6.69), the expression for pressure reads 
.P = 2A
3β5/2V
{ ∞
0
x 3/2 dx
z−1 exp(x) − η − 1
βV
ln(1 − z)δη1. (8.126) 
It will be shown that a significant contribution from the second term comes from 
.1 − z ≈ 1/V . Hence.ln(1 − z)/V ∼ −ln(V)/V → 0 as.V → ∞ leading to the 
following equation for pressure 
.P = 2A
3β5/2V
{ ∞
0
x 3/2 dx
z−1 exp(x) − η . (8.127)256 8 Ideal Quantum Gases
3. Using (6.63), the internal energy may be seen to be given by 
.U = A
β5/2
{ ∞
0
x 3/2dx
z−1 exp(x) − η . (8.128) 
The fact that it corresponds to the zero-energy state, the second term in (8.125) 
does not contribute to internal energy. 
4. Recalling (6.64) with .ln(Zη) as in (8.124), the average number of particles may 
be seen to be given by 
.N¯ = A
β3/2
{ ∞
0
√xdx
z−1 exp(x) − η
+
z
1 − z
δη1. (8.129) 
5. On comparing (8.127) and (8.128) we get 
.PV = 2
3
U. (8.130) 
This relation holds for all non-interacting gases including Bosonic, Fermionic as 
well as the classical gas. 
6. The average number of particles .n¯iη in energy level . Ei is given by (8.47). In the 
continuum limit in free space,. Ei stands for energy corresponding to momentum 
. p so that the average number of particles having momentum . p corresponding to 
energy. E would be 
.n¯η(p) = [exp{β(E(p) − μ)} − η]
−1
. (8.131) 
Hence the number of particles.nη(E)ΔE having energy. E in energy interval. (E, E +
dE) would be 
.nη(E)dE = nη(p)d3 p, (8.132) 
so that 
.nη(E) = D(E)
exp{β(E − μ)} − η
. (8.133) 
For gas consisting of molecules moving in three-dimensional space with non￾relativistic speeds, .D(E) is given by (8.76). In that case, (8.133) reduces to the 
Bose–Einstein distribution (4.110), for.η = 1 and to the Fermi–Dirac distribution 
(4.125) for.η = −1. 
7. Equation (8.130) is the relation between. P,. V and. U. It is not the equation of state 
because the equations of state are relations between.P, V, N¯ and. T , and. U, V, N¯
and. T . Those are obtained, in principle, by inverting (8.129) to express. z in terms 
of . N¯ , and .T and substituting . z so obtained in other thermodynamic quantities8.7 Thermodynamics of Quantum Gases 257
which are functions of. z. That is generally a formidable task. We will derive the 
equations of state in the limiting case of small. z. 
When .z < 1, we can rewrite various quantities derived above in terms of the 
polylogarithm function defined by 
.Lip(x) = Σ∞
k=1
xk
k p . (8.134) 
To that end, recall the expression (7.6) for.λT and (8.76) for. A, to obtain 
.
A
β3/2 = 2V
√π
λ−3
T . (8.135) 
We use also the identity, proved in the exercises, 
.
{ ∞
0
x pdx
z−1 exp(x) − η = ηΓ(p + 1)g(η)
p+1(z), (8.136) 
where 
.g(η)
p (z) = Σ∞
k=1
(ηz)k
k p (8.137) 
is evidently in the form (8.134) of the polylogarithmic function. It is then straight￾forward to see that: 
1. The expression (8.125) for.ln(ZGη) may be rewritten as 
.ln(ZGη) = ηV
λ3
T
g(η)
5/2(z) − ln(1 − z)δη1. (8.138) 
2. Equation (8.126) for pressure assumes the form 
.P = η
βλ3
T
g(η)
5/2(z) − 1
βV
ln(1 − z)δη1. (8.139) 
3. The expression (8.128) for internal energy.U reads 
.U = 3ηV
2βλ3
T
g(η)
5/2(z). (8.140) 
4. Equation (8.129) for average number of particles reduces to 
.N¯ = ηV
λ3
T
g(η)
3/2(z) +
z
1 − z
δη1. (8.141)258 8 Ideal Quantum Gases
In Sect. 8.4.3 we saw that the Bose as well as the Fermi gas behaves as a classical 
gas when.z << 1 which we called the classical limit. In the following we compute 
quantum corrections to the classical limit. 
See [ 3] for computing fugacity using Mathematica functions. 
Exercises 
Ex. 8.10. Prove (8.136). Hint: 
. { ∞
0
x pdx
z−1 exp(x) − η =
{ ∞
0
x p z exp(−x)dx
1 − zη exp(−x)
.
= η
Σ∞
k=0
(ηz)
k+1
{ ∞
0
x p exp{−x(k + 1)}dx.
(8.142) 
Recalling the integral representation (H.3) of.Γ-function it is straightfor￾ward to reduce this to the form in (8.136). 
Ex. 8.11. Show that 
.
dgp(z)
dz = z−1gp−1(z), gp(z) ≡ g(1)
p (z). (8.143) 
Ex. 8.12. In a .d-dimensional system in which the energy-momentum relation is 
given by (8.89) and the corresponding density of states by (8.90), show 
that the equations for.ln(ZGη),. U,.N¯ and.P assume the form 
.ln(ZGη) = n
d
And
βd/n
{ ∞
0
x d/ndx
z−1 exp(x) − η − ln(1 − z)δη1. (8.144) 
.U = And
β(d+n)/n
{ ∞
0
x d/ndx
z−1 exp(x) − η
. (8.145) 
.N¯ = And
βd/n
{ ∞
0
x(d−n)/ndx
z−1 exp(x) − η
. (8.146) 
.PVd = n
d
U, (8.147) 
where .Vd = V in.3-d,.Vd = σ in.2 − d and.Vd = L in.1 − d systems. In 
terms of the.g(η)
p (z) function, the expressions above read 
.ln(ZGη) = nη
d
And
βd/n Γ((d/n) + 1)g(η)
(d/n)+1(z) − ln(1 − z)δη1. (8.148)8.8 Quantum Corrections to the Classical Limit 259
.U = And η
β(d/n)+1 Γ((d/n) + 1)g(η)
(d/n)+1(z). (8.149) 
.N¯ = And η
βd/n Γ(d/n)g(η)
d/n(z). (8.150) 
Ex. 8.13. Show that the adiabatic equation of state for the ideal quantum gas is 
.PV(n+d)/d
d = constant. (8.151) 
Since the relation above for adiabatic transformations holds for any non￾interacting gas in free space, we see that for a given value of . n and . d it 
is same for all gases. In particular, for the gas of molecules moving with 
non-relativistic speeds in three dimensions, .n = 2, .d = 3 in which case 
the relation (8.151) is same as that in (1.87) for classical gas. However 
the relation between.P and. T and that between. T and.V under adiabatic 
transformation cannot be determined unless the equation of state is known. 
Furthermore, whereas .5/3 in the relation.PV5/3 = constant for the clas￾sical gas is equal to .γ ≡ CP /CV , it is not so in general. This has been 
demonstrated by evaluation of.CP /CV in (9.63) for the Fermi gas at low 
temperature and for the Bose gas in (10.48). 
Hint: In an adiabatic process, entropy and number of particles are con￾stants. Hence the first law of thermodynamics in this case reduces to 
.dU + PdV = 0. Use (8.147) to get the desired result. 
Ex. 8.14. Show that fugacity of the.2 − d non-relativistic quantum gas is given by 
.zη = η
{
1 − exp(−ηβN¯ β/A22)
}
, A22 = 2mπσ
h2 , (8.152) 
where.z−1 is the fugacity of the Fermi gas and.z1 that of the Bose gas. Note 
that (8.152) determines. z in terms of.N¯ and. T . Its substitution in (8.145) 
would determine . U, which in turn when combined with (8.147) would 
determine .PVd in terms of . N¯ , and .T yielding thereby the equations of 
state. Hint: For.2-dimensional non-relativistic gas.n = d = 2. The desired 
result follows by straightforward integration of (8.146). 
8.8 Quantum Corrections to the Classical Limit 
In Sect. 8.4.3 we showed that the quantum grand partition function reduces to the 
classical one under the condition (8.62). That condition is written in terms of sum 
over energy levels. For molecules in free space, that sum has been evaluated in (8.91) 
using which the said condition reads260 8 Ideal Quantum Gases
.λT << ( V
N¯
)1/3
or
N¯
V
( h2
2πmkBT
)3/2
<< 1. (8.153) 
Now,.V/N¯ is the volume per particle. Its cube root is a measure of distance between 
the particles. Hence (8.153) states that the condition under which quantum gases 
behave as a classical gas is valid if the thermal wavelength of the particles is much 
smaller than the distance between them, i.e. since thermal wavelength is a measure 
of their de Broglie wavelength, if there is no significant overlap between De Broglie 
waves of the particles. Equivalently, the second form of the condition in (8.153) 
shows that the classical limit will hold if the particle density .N/V is low or/and 
temperature. T is high. 
In this section we evaluate quantum corrections to the classical limit. To that end, 
it is useful to write the condition (8.153) as.z0 << 1 where 
.z0 = N¯
V
λ3
T, z0 << 1. (8.154) 
As stated before, the first step in the study of thermodynamic properties when system 
is described by grand canonical partition function is to invert the (8.141) to express. z
in terms of the average number.N¯ of particles. Presently we invert it assuming. z takes 
values close to those for which classical limit is achieved. Since classical results are 
obtained in the limit .z → 0 and the parameter .z0 defined above is a measure of the 
closeness of. z to the classical limit, we expand. z in powers of. z0: 
.z = Σ∞
j=1
ajzj
0 (8.155) 
and determine the coefficients of expansion by substituting. z in the expression (8.141) 
for . N¯ . Since the second term therein contributes when . z is close to unity and our 
interest at present is in the values of. z close to zero, we can ignore the second term 
in (8.141) to rewrite it as 
.z0 = ηg(η)
3/2(z), (8.156) 
where the definition (8.154) of .z0 has been used. Substitute the expression (8.155) 
for. z in the series representation (8.137) of.g(η)
p (z) to get 
. z0 = Σ∞
j=1
ajzj
0 + η
√8
Σ∞
i,j=1
aiajz
i+ j
0 +
1
√27
Σ∞
i,j,k=1
aiajak z
i+ j+k
0 +···
(8.157)8.8 Quantum Corrections to the Classical Limit 261
Retaining terms up to.z3
0 we have 
.(a1 − 1)z0 +
(
a2 + η
√8
a2
1
)
z2
0 +
(
a3 + η
√2
a1a2 + a3
1
√27)
z3
0 = 0. (8.158) 
Equating to zero the coefficient of various powers of.z0 in (8.158) we get 
.a1 = 1, a2 = − η
√8
, a3 = 1
4 − 1
3
√3
. (8.159) 
Hence, to order. z3
0, 
.z = z0 − η
√8
z2
0 +
(1
4 − 1
3
√3
)
z3
0. (8.160) 
Substitute this in the (8.140) for.U retaining terms up to.z3 to get 
. U = 3N¯
2z0β
[
z + η
4
√2
z2 +
1
9
√3
z3
]
= 3N¯
2β
[
1 +
(
a2 + η
4
√2
)
z0 +
(
a3 + η
2
√2
a2 +
1
9
√3
)
z2
0
]
. (8.161) 
Recalling the values of.a2, a3 derived in (8.159) this reduces to 
.U = 3N k¯ BT
2
[
1 − η
4
√2
z0 +
(1
8 − 2
9
√3
)
z2
0
]
. (8.162) 
The first term in the equation above gives energy of a classical system. The second 
term is correction to the classical value. Since Fermi gas corresponds to.η = −1, it 
shows that the energy of the Fermi gas is more than that of the classical gas of same 
density and at same temperature. On the other hand, since the Bose gas corresponds 
to .η = 1, we see that energy of the Bose gas is less than that of classical gas of 
same density and at same temperature. Substitution of (8.162) in the relation (8.130) 
between.PV and.U leads to the following equation of state correct up to. z2
0: 
.PV = N k¯ BT
[
1 − η
4
√2
z0 +
(1
8 − 2
9
√3
)
z2
0
]
. (8.163) 
This shows that, other parameters remaining same, the pressure of Fermi gas is more 
than that of the classical gas whereas the pressure of Bose gas is less than that of the 
classical gas. 
The fact that the internal energy and the pressure of the Fermi gas is more than 
that of the classical gas may be understood by recalling that no two Fermi particles 
can occupy same state whereas there is no restriction on the number of classical262 8 Ideal Quantum Gases
particles that can be placed in same state as a consequence of which the number of 
Fermi particles in higher energy states is more than the number of classical particles. 
It may be verified that the (8.162) for.U leads to the following expression for the 
heat capacity at constant volume: 
. 
CV
kB N¯ = 3
2
[
1 + η
8
√2
z0 −
(1
4 − 4
9
√3
)
z2
0
]
= 3
2
[
1 + 0.0884ηz0 + 0.0066z2
0
]
. (8.164) 
The same procedure can be extended to obtain higher order quantum corrections to 
the classical limit. 
For a fixed .N¯ /V, the expansion in powers of .z0 employed above is basically an 
expansion in terms of .1/T , i.e. it is a high temperature expansion. We found that 
in that limit Fermi and Bose gases approach the same limit, namely, the classical 
gas. We will see that the Fermi and the Bose gases behave vastly differently at low 
temperatures. 
References 
1. W. Gordy, R.L. Cook, Microwave Molecular Spectroscopy (Wiley, 1984) 
2. A. Yu Zakharov, A.V. Leont’eva, A. Yu Prokhorov, IOP Conf. Series: Mat. Sci. Eng. 441, 012060 
(2018) 
3. B. Cowan, J. Loe, Temp. Phys. 197, 412 (2019)Chapter 9 
Ideal Fermi Gas 
In this chapter we investigate the properties of the gas of free non-interacting Fermi 
particles at low temperatures. 
9.1 Fermi Gas at Zero Temperature 
Consider the gas of free fermions having spin quantum number. S. They can be dis￾tinguished by .2S + 1 spin projection quantum numbers .mS = −S, −S + 1,..., S. 
Since an energy level can not be occupied by two Fermions having same value of 
.ms it follows that each free single particle energy level can be occupied by at most 
.2S + 1 Fermions, each characterized by one of the .2S + 1 different values of .mS. 
Since the density of states .D(E) is evaluated for single particle occupancy, the spin 
of the particles in the gas containing particles having all possible values of .mS can 
be accounted for by multiplying.D(E) by.2S + 1, i.e. by the correspondence 
.D(E) → (2S + 1)D(E). (9.1) 
For the sake of simplicity, we assume that all the Fermions in the gas have same 
value of .mS so that an energy level can be occupied by only one Fermion. Since 
the occupancy of a level then is same as .2S + 1 when .S = 0, such a system is also 
called a system of “spinless” Fermions. The results for the finite value of spin may 
be obtained from the ones for the .S = 0 case by changing the density of states per 
the correspondence in (9.1). 
Let the gas be at.T = 0. It will then be in its ground state. If.N is the number of 
Fermions in the gas and .EF is the energy of the highest occupied energy level then 
we must have 
.N =
{ EF
0
D(E)dE. (9.2) 
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4_9 
263264 9 Ideal Fermi Gas
If the motion is non-relativistic and in three spatial dimensions, then (9.2) assumes 
the form 
.N = A
{ EF
0
√E dE = 2A
3
E
3/2
F , (9.3) 
where we have invoked (8.76) for the density of states.D(E) for free non-relativistic 
particles in three spatial dimensions. The highest possible energy .EF is called the 
Fermi energy. It corresponds to the temperature 
.TF = EF
kB
(9.4) 
called Fermi temperature. The internal energy is given by 
.U =
{ EF
0
ED(E)dE = 2A
5
E
5/2
F . (9.5) 
The last two equations lead to the relation 
.U = 3
5
NEF . (9.6) 
On combining this with the exact expression (8.130) relating .PV with .U in any 
non-interacting gas follows the equation of state 
.PV = 2
5
EF N (9.7) 
of the gas of free non-interacting Fermions at .T = 0. We see that the energy and 
pressure of the Fermi gas are finite at.T = 0. That is because two fermions in same 
state cannot occupy same energy level and hence they are forced to occupy distinct 
higher energy states as their number increases leading to finite energy, and pressure. 
Its entropy, however, will be shown to be zero at.T = 0 (see (9.48)), as it should be. 
It is instructive to calculate .EF for the gas of electrons in a solid. Since . S = 1/2
for electrons, with. A given by (8.76) and due to the correspondence (9.1), the (9.3) 
reads 
.
N
V = 8π(2m)3/2
3 h3 E
3/2
F . (9.8) 
This shows that 
.EF =
[( N
V
)2/3 1
2mc2
] [( 3
π
)2/3 (hc)2
4
]
. (9.9)9.1 Fermi Gas at Zero Temperature 265
On using.(hc)2 ≈ 1.54 × 10−8(eV)2 − cm2,.2mc2 ≈ 1MeV, (9.9) yields 
.EF = 3.72 × 10−15eV − cm2
( N
V
)2/3
, (9.10) 
where .V is in .cm3. In solids .N/V is generally in the range .1022 − 1023/cm3. The 
value of.EF therefore is few electron volts. Since.kB ≈ 8.6 × 10−5eV/K, the Fermi 
temperature is .∼ 104 − 105 K. The working temperatures, being much lower than 
the Fermi temperature, may be taken as close to.T = 0. 
The expressions for . N, . U, and .P derived above for .T = 0 without recourse to 
statistical mechanical formalism, as shown next, follow also using it. 
1. The probability that a fermion in an ideal Fermi gas occupies energy level . E is 
given, recalling (8.43), by 
.pF (E) = 1
exp (β(E − μ)) + 1
. (9.11) 
In the limit.T → 0, 
.pF (E) = 1 if E < μ, pF (E) = 0 if E > μ. (9.12) 
This shows that at.T = 0 the highest value of energy of the fermions is. μ which 
is therefore the Fermi energy of the system: 
.μ = EF , T = 0. (9.13) 
2. Recalling (8.129), the number of particles is 
.N = A
{ ∞
0
√E dE
exp (β(E − μ)) + 1 = A
{ μ
0
√E dE, β → ∞. (9.14) 
This is same as (9.3). 
3. Invoking (8.128), internal energy is 
.U = A
{ ∞
0
E3/2 dE
exp (β(E − μ)) + 1 = A
{ μ
0
E3/2 dE, β → ∞. (9.15) 
This is same as (9.5). 
4. Recall the expression (8.127) for. P. Note that it has been obtained by changing the 
variable of integration from. E to.x = βE. Carry the integral in the limit. β → ∞
after transforming. x back to. E to get 
.P = 4A
15 V
E
5/2
F = 2N
5 V
EF , (9.16)266 9 Ideal Fermi Gas
where we have invoked (9.3) in writing the last equality. The equation above is 
the same as (9.7). 
We have thus at hand the thermodynamic quantities for the ideal Fermi gas at.T = 0. 
Next we evaluate finite temperature corrections to its.T = 0 behavior. 
Exercises 
Ex. 9. 1. A non-interacting Fermi gas of. N particles of mass. m is in one-dimensional 
zero potential between infinite potential walls at .x = 0 and .x = L at 
.T = 0. The single particle energy levels are given by 
.En = E0n2
, E0 = π2h2
2m L2 n = 1, 2,... (9.17) 
(a) Find the maximum occupied energy level. (b) Find the Fermi energy. 
(c) Find total energy of the system. 
Ex. 9. 2. Find the Fermi energy of a three-dimensional ultra-relativistic (.E = pc) 
ideal Fermi gas at.T = 0. 
Ex. 9. 3. The energy levels of the one-dimensional harmonic oscillator of frequency 
. ω are given by .En = hω(n + 1/2) (.n = 0, 1, 2, . . .) in which .N identi￾cal non-interacting Fermions are to be distributed. (i) What is the Fermi 
energy of the system? (ii) What is total energy of the system? 
Ex. 9. 4. The energy levels of an isotropic two-dimensional harmonic oscillator 
of frequency . ω are given by .En ≡ En1,n2 = hω(n1 + n2 + 1), (. n1, n2 =
0, 1, 2, . . .) in which .N identical non-interacting fermions are to be dis￾tributed. (i) How many Fermions can be placed in the levels of energy 
.EM = hω(M + 1)? (ii) What is the total number of Fermions if, starting 
from.E0, all the levels up to the level of energy.EM are occupied? (iii) If 
Fermions occupy all the levels up to the levels of energy .EM then what 
is the energy of the system? Hint: The energy is determined by the sum 
.n1 + n2, and the states obtained by interchanging distinct .n1 and .n2 are 
different. Hence the degeneracy of the level of energy.En is given by the 
number of ways of writing . n as the sum of two positive integers. That 
number can be seen to be. n + 1
Ex. 9. 5. The energy levels of an isotropic three-dimensional harmonic oscillator 
of frequency . ω are given by .En ≡ En1,n2,n3 = hω(n1 + n2 + n3 + 3/2), 
(.n1, n2, n3 = 0, 1, 2, . . .) in which .N identical non-interacting fermions 
are to be distributed. (i) How many Fermions can be placed in the levels of 
energy.EM = hω(M + 3/2)? (ii) What is the total number of Fermions if, 
starting from.E0, all the levels up to the level of energy.EM are occupied? 
(iii) If Fermions occupy all the levels up to the levels of energy.EM then 
what is the energy of the system? Hint: The energy is determined by9.2 Fermi Gas at Low Temperature 267
the sum .n1 + n2 + n3, and the states obtained by interchanging distinct 
.n1, n2, n3 are different. Hence the degeneracy of the level of energy . En
is given by the number of different ways of writing. n as the sum of three 
positive integers. That number is.(n + 1)(n + 2)/2. 
Ex. 9. 6. Show that the Fermi energy and total energy of a .d-dimensional ideal 
Fermi gas obeying the energy-momentum relation (8.89) and having . N¯
average number of molecules of mass.m is given at.T = 0 by 
. EF =
( N¯
And
d
n
)n/d
,
U = A−n/d n
d + n
( N d¯
n
)(d+n)/d
, (9.18) 
where.And is as in (8.90). 
9.2 Fermi Gas at Low Temperature 
The study of thermodynamic properties of the ideal Fermi gas involves evaluating 
integrals of the type 
.I =
{ ∞
0
φ(E) dE
1 + exp (β(E − μ))
. (9.19) 
We rewrite the integral above as 
. I =
{ μ
0
exp (−β(E − μ)) φ(E) dE
1 + exp (−β(E − μ)) +
{ ∞
μ
φ(E) dE
1 + exp (β(E − μ))
=
{ μ
0
φ(E) dE −
{ μ
0
φ(E) dE
1 + exp (−β(E − μ))
+
{ ∞
μ
φ(E) dE
1 + exp (β(E − μ))
. (9.20) 
Change the variable of integration in the last two integrals to .x = β(E − μ). The 
limits of second integral then are.x = 0 corresponding to.E = μ and.x = −βμ cor￾responding to.E = 0. We assume. T to be close to zero so that.β >> 1. Consequently, 
with.x = −βμ ≈ −∞, followed by the transformation.x → −x, (9.20) assumes the 
form 
.I =
{ μ
0
φ(E) dE + J, (9.21) 
where268 9 Ideal Fermi Gas
. J = 1
β
{ ∞
0
1
1 + exp(x)
[
φ
(
μ + x
β
)
− φ
(
μ − x
β
)]
dx
= 2
β
Σ∞
n=1
1
(2n − 1)!
d2n−1φ(μ)
dμ2n−1
{ ∞
0
dx
1 + exp(x)
( x
β
)2n−1
, (9.22) 
.
d2n−1φ(μ)
dμ2n−1 ≡ d2n−1φ(E)
dE2n−1
|
|
|
|
E=μ
. (9.23) 
Evaluate (9.22) invoking the identity (H.14) and substitute the resulting expression 
in (9.21) to obtain 
.I =
{ μ
0
φ(E) dE + 2
Σ∞
n=1
[
(kBT )
2n d2n−1φ(μ)
dμ2n−1
(
1 − 2−2n+1)
ζ (2n)
]
. (9.24) 
The (9.24) is called the Sommerfeld expansion. The first term which is independent of 
. T gives the properties of the Fermi gas at.T = 0 already studied. We find corrections 
to the.T = 0 behavior by expressing (9.24) in powers of. z0: 
.z0 = kBT/EF . (9.25) 
The expansion of thermodynamic quantities in terms of.z0 will determine their behav￾ior for temperatures which are such that.kBT << EF . 
The functions.φ(E) of our interest are of the form 
.φ(E) = AEm+1/2
. (9.26) 
The expression (9.24), with.I → Im, may then be rewritten as 
.Im = 2A
2m + 3
μ(2m+3)/2
[
1 +Σ∞
n=1
amn z2n
]
, (9.27) 
where 
.z = kBT/μ, (9.28) 
and 
.amn = 2Γ(m + 5/2)
Γ(m − 2n + 5/2)
(
1 − 2−2n+1)
ζ (2n). (9.29) 
It is convenient to express (9.27) in the form9.2 Fermi Gas at Low Temperature 269
.Im = 2A
2m + 3
E
(2m+3)/2
F
(z0
z
)(2m+3)/2 [
1 +Σ∞
n=1
amn z2n
]
. (9.30) 
We evaluate .U and .N¯ using (8.128) and (8.129) with .η = −1 and . z = exp(βμ)
therein. Clearly, the integral in the expression for .U is then same as (9.19) cor￾responding to .φ(E) = AE3/2 and that in the expression for .N¯ is same as (9.19) 
corresponding to.φ(E) = AE1/2 with. A as in (8.76) so that 
.N¯ ≡ I0 = 2A
3
E
3/2
F
(z0
z
)3/2 [
1 +Σ∞
n=1
a0n z2n
]
, (9.31) 
and 
.U ≡ I1 = 2A
5
E
5/2
F
(z0
z
)5/2 [
1 +Σ∞
n=1
a1n z2n
]
, (9.32) 
with 
. a0n = 2Γ(5/2)
Γ(5/2 − 2n)
(
1 − 2−2n+1)
ζ (2n),
a1n = 2Γ(7/2)
Γ(7/2 − 2n)
(
1 − 2−2n+1)
ζ (2n). (9.33) 
Use (9.3) to rewrite (9.31) and (9.32) as 
.z
[
1 +Σ∞
n=1
a0n z2n
]−2/3
= z0, (9.34) 
and 
.U = 3
5
N¯ EF
(z0
z
)5/2 [
1 +Σ∞
n=1
a1n z2n
]
. (9.35) 
Assuming.z0 << 1, we express. z in powers of. z0, solve (9.34) up to the desired power 
of.z0 and substitute the resulting expression of. z in (9.35) to determine energy. The 
(9.34) shows that.z/z0 has only even powers of. z. Hence the expansion of. z in terms 
of.z0 must be of the form 
.z = z0
(
1 +Σ∞
k=1
c2k+1z2k
0
)
. (9.36)270 9 Ideal Fermi Gas
The .c2k+1 are the unknowns to be determined by substituting (9.36) in (9.34) and 
equating like powers of. z0. 
Recalling the definitions (9.25), (9.28) of.z0,z the expression for chemical poten￾tial reads 
.μ = EF
(
1 +Σ∞
k=1
c2k+1z2k
0
)−1
. (9.37) 
We derive corrections to the .T = 0 behavior of the Fermi gas retaining terms up to 
second order in.z2
0 in the series in the expression (9.36) for. z. 
First-Order Corrections 
The first-order correction to the .T = 0 behavior is obtained by keeping the lowest 
order term in the series in (9.36): 
.z = z0(1 + c3z2
0). (9.38) 
Substitute this in (9.34) retaining terms up to.z3
0 to get 
.(c3 − (2/3)a01)z3
0 = 0. (9.39) 
This determines the unknown coefficient. c3: 
.c3 = 2
3
a01. (9.40) 
Substitution of this in (9.38) yields the expression for. z valid up to. z3
0: 
.z = z0(1 + (2/3)a01z2
0). (9.41) 
Energy is obtained by using the expression for. z above in (9.35) and retaining terms 
up to. z3
0: 
.U = 3
5
N¯ EF
(
1 + (a11 − (5/3)a01)z2
0
)
. (9.42) 
Invoking the expressions in (9.33) for.a01, a11 with.ζ (2) = π2/6, we have 
.a01 = π2
8 , a11 = 5π2
8 (9.43) 
so that9.2 Fermi Gas at Low Temperature 271
.U = 3N¯ EF
5
[
1 +
5π2
12 (kBT
EF
)2
]
. (9.44) 
Invoking (9.37), the chemical potential is given by 
.μ = EF
[
1 − π2
12 (kBT
EF
)2
]
. (9.45) 
We have thus at hand the expressions for energy and chemical potential to the low￾est order in temperature relative to the Fermi temperature. We derive below other 
thermodynamic characteristics of the Fermi gas to the said order of approximation. 
1. Pressure.P may be obtained by using the relation (8.130) which determines it in 
terms of .U and . V. On substituting in that relation the expression (9.44) for .U
follows the equation of state 
.PV = 2N¯ EF
5
[
1 +
5π2
12 (kBT
EF
)2
]
. (9.46) 
The first term on the right side above gives the equation of state (9.7) for the Fermi 
gas at zero temperature whereas the second term is the lowest order correction to 
the zero temperature term. 
2. The specific heat at constant volume is given by 
.
CV
N k¯ B
= 1
kBN¯
∂U
∂T = π2
2
kBT
EF
. (9.47) 
This shows that the specific heat goes to zero linearly as.T → 0. 
3. Invoking Euler’s relation, the entropy of the Fermi gas in low-temperature limit 
may be shown to be given by 
.
S
N k¯ B
= π2
2
kBT
EF
. (9.48) 
This equation rightly predicts.S → 0 as.T → 0. 
4. Recalling (9.8) whereby .EF ∼ V −2/3, it follows that .T and .V in an adiabatic 
process (.S = constant) are related by 
.V2/3T = constant. (9.49)272 9 Ideal Fermi Gas
The relation between. P and. V in an adiabatic process can be found by expressing 
.PV in (9.46) in terms of. S (see (9.68)). Since.EF ∼ V −2/3, the said equation for 
constant. S yields 
.PV5/3 = constant. (9.50) 
On combining (9.49) and (9.50) we get .T P−2/5 = constant. The adiabatic rela￾tions between the pairs of .P, V, T derived above for the Fermi gas in low tem￾perature limit are same as the corresponding ones for an ideal monoatomic gas. 
However, whereas the exponents in the said relations in the classical gas are 
related with .CP /CV , the exponents in the present case, though their values are 
same as the corresponding ones in the classical gas, have no relation with. CP /CV
(see Ex. 9.8). 
Second-Order Correction 
The second-order correction is obtained by terminating the series in (9.36) at. z4
0: 
.z = z0(1 + c3z2
0 + c5z4
0). (9.51) 
This determines. z up to. z5
0. Substitute this in (9.34) retaining terms to order.z5
0 to get 
.(c3 − (2/3)a01)z2
0 + D5z4
0 = 0, (9.52) 
where 
.D5 = c5 −
(
2c3a01 +
2
3
a02 − 5
9
a2
01)
. (9.53) 
The coefficient of .z2
0 is zero due to (9.40). Equating to zero the coefficient of . z4
0
determines . c5. The value of .a01 needed for evaluating .c5 is given in (9.43) and that 
of.a02 obtained using (9.33), with.ζ (4) = π4/90, is 
.a02 = 7π4
640 . (9.54) 
The value of.c5 turns out to be given by 
.c5 = 7π4
360 . (9.55) 
Recalling (9.37), the expression for the chemical potential reads 
.μ = EF
[
1 − π2
12 (kBT
EF
)2
− π4
80 (kBT
EF
)4
]
. (9.56)9.2 Fermi Gas at Low Temperature 273
The average energy is evaluated by substituting (9.51) in (9.35) to obtain 
.U = 3N¯ EF
5
[
1 +
5π2
12 (kBT
EF
)2
+ I4z4
0
]
, (9.57) 
where 
.I4 = a12 − a11c3
2 +
35c2
3
8 − 5c5
2 . (9.58) 
The.a11 is as in (9.43). Using (9.33), the values of.a12 may be shown to be given by 
.a11 = 5π2
8 , a12 = −7π4
384 . (9.59) 
It then follows that 
.U = 3N¯ EF
5
[
1 +
5π2
12 (kBT
EF
)2
− π4
16 (kBT
EF
)4
]
. (9.60) 
The equations above provide means of evaluating various thermodynamic quantities. 
Exercises 
Ex. 9. 7. Show that the fundamental energetic equation for the gas of Fermions, in 
the first order of low-temperature approximation is 
.U = 3N¯ EF
5
[
1 +
5
3π2
( S
N k¯ B
)2
]
. (9.61) 
Hint: Use (9.48) to express.kBT/EF in terms of. S. 
Ex. 9. 8. (a) Show that for the gas of Fermions in the first order of low temperature 
approximation, 
.P
(∂V
∂T
)
P
= 2
5
[
1 +
π2
3
(kBT
EF
)2
]
CV . (9.62) 
(b) Use the result above to show that 
.
CP
CV
= 1 +
π2
3
(kBT
EF
)2
. (9.63)274 9 Ideal Fermi Gas
Hint: (a) Differentiate (9.46) with respect to .T at constant .P using 
.(∂EF /∂T )P = (∂V/∂T )P (dEF /dV ) and recall from (9.8)) that . EF =
CV −2/3 (. C is a constant) so that 
.
dEF
dV = −2EF
3V . (9.64) 
Recall also the expression (9.47) for .CV . (b) Use first law of thermody￾namics and the relation (8.130) to show that 
.Cp = 5P
2
(∂V
∂T
)
P
. (9.65) 
Ex. 9. 9. Show that the isothermal compressibility of the gas of Fermions in the 
first order of low-temperature approximation is given by 
.κT = 3V
2N¯ EF
[
1 − π2
12 (kBT
EF
)2
]
, (9.66) 
where.κT is defined in (2.110). Hint: Differentiate (9.46) with respect to 
.V at constant. T using (9.64). 
Ex. 9. 10. Show that the isentropic compressibility of the gas of Fermions in the 
first order of low-temperature approximation is given by 
.κS = 3V
2N¯ EF
[
1 − 5π2
12 (kBT
EF
)2
]
, (9.67) 
where.κS is defined in (2.103). Hint: Use (9.48) to express.kBT/EF in the 
expression (9.46) for.PV in terms of. S: 
.PV = 2N¯ EF
5
[
1 +
5
3π2
( S
N k¯ B
)2
]
. (9.68) 
Differentiate this with respect to.V at constant. S using (9.64).Chapter 10 
Ideal Bose Gas 
In this chapter we investigate properties of the gas of free non-interacting Bosons. 
We will see that at low temperatures it exhibits the phenomenon of condensation of 
macroscopic number of Bosons to the zero-energy state, called the Bose–Einstein 
condensation. The relation of the phenomenon of the Bose–Einstein condensation 
with that of the phase transitions is explored. 
10.1 Bose Gas 
Since .z < 1 for an ideal Bose gas, its average particle density is given by (8.141) 
with.η = 1 therein: 
.n¯ ≡ N¯
V = λ−3
T g3/2(z) +
1
V
z
1 − z
≡ ¯ne + ¯n0, (10.1) 
where.g(1)
3/2(z) has been written as.g3/2(z) for convenience and 
.n¯ e = λ−3
T g3/2(z), n¯0 = 1
V
z
1 − z
. (10.2) 
The .n¯0 is the number density in the zero-energy ground state, and .n¯ e stands for the 
number density in the excited states. We address below the question of inverting 
(10.1) to obtain. z in terms of. n¯ and. T . 
If the second term in (10.1) is ignored then.n¯ e = ¯n so that 
.λ3
T n¯ = g3/2(z). (10.3) 
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4_10 
275276 10 Ideal Bose Gas
Fig. 10.1 .g3/2(z) and 
.g5/2(z) as functions of. z
The function.g3/2(z) is monotonically increasing and is bounded for.0 ≤ z ≤ 1 (see 
Fig. 10.1), its maximum value in the said interval being 
.g3/2(1) = 2.612 ... (10.4) 
Equation (10.3) determines the fugacity . z for specified values of . n¯ and . T . The 
maximum value .z = 1 will be reached for such values of . n¯ and .λ3
T for which the 
product.n¯λ3
T attains the value.g3/2(1), called the critical value.(n¯λ3
T)c: 
.(n¯λ3
T)c = g3/2(1). (10.5) 
Since.g3/2(z) is monotonically increasing, (10.3) shows that if.n¯λ3
T is increased then 
. z must increase. Since the right side of (10.3) attains maximum value for .z = 1, it 
follows that there is no value of . z for which (10.3) can be satisfied if the values 
of . n¯ and .λ3
T are such that .n¯λ3
T > g3/2(1). This is clearly an unacceptable situation 
because, in principle, .n¯λ3
T can be made arbitrarily large. We will see that inclusion 
of the second term in (10.1), ignored in writing (10.3), provides correct description. 
To that end, recall that (10.3) is obtained if the discrete sum in the expression 
(8.45) for the grand partition function is replaced by integration. Such a replacement 
is justified for high values of energy. Hence, if the population in lower energy levels 
is insignificant, the sum may be replaced by the integral. In order to incorporate the 
situations in which lower energy levels may be significantly populated, we evaluate 
that sum by splitting the energy levels into three groups: (i) zero-energy ground level, 
(ii) starting from the first excited state, the group consisting of a finite number.P of 
levels and (iii) the rest of the levels to write the average particle number as 
.N¯ = N¯ 0 +Σ
P
k=1
N¯ k + Σ
k>P
N¯ k , (10.6)10.1 Bose Gas 277
where.N¯ 0 is average number of particles in the state of zero energy and.N¯ k is that in 
the state of energy. Ek . The last sum can be replaced by an integral whose contribution 
will be same as in (10.3) because removal of a small number of points does not change 
the integral so that 
.n¯ = 1
λ3
T
g3/2(z) +
N¯ 0
V +
1
V
Σ
P
k=1
N¯ k . (10.7) 
Now, from (8.38) we know that (with.n¯ k B → N¯ k ) 
.N¯ 0 = z
1 − z
, N¯ k = z exp(−βEk )
1 − z exp(−βEk )
, Ek /= 0. (10.8) 
The average occupation numbers.{N¯ k } corresponding to.Ek /= 0 are clearly finite for 
any. z. Hence the last term in (10.7) would approach zero as.V → ∞. However, the 
average occupation number .N¯ 0 of the ground state increases indefinitely as . z → 1
and may become so large as to make the number density in the ground state, 
.n¯0 = N¯ 0
V = z
V(1 − z)
, (10.9) 
finite even for macroscopic volumes. It is therefore sufficient to retain only the . N¯ 0
term from the discrete summation part reducing it to the anticipated form (10.1), 
rewritten as 
.n¯λ3
T = g3/2(z) + λ3
Tn¯0, n¯0 = N¯ 0
V = z
V(1 − z)
. (10.10) 
This determines. z for a specified value of.n¯λ3
T. For the values of.n¯λ3
T < g3/2(1), we 
know that.z < 1. The factor.z/(1 − z)in that case is finite and hence. z/(V (1 − z)) →
0 in the thermodynamic limit .V → ∞ so that .n¯0 = 0, .n¯ e = ¯n. The gas is then said 
to be in the normal phase: 
. n¯0 = 0, n¯ e = ¯n
n¯λ3
T = g3/2(z), n¯λ3
T < g3/2(1), normal phase. (10.11) 
The thermodynamic properties of the gas in the normal phase are determined by 
evaluating. z by solving the second of the equations above for the specified values of 
. n¯ and. T . 
The factor.z/(V(1 − z)) would contribute significantly when 
.
z
1 − z ∼ V, which implies z ∼ 1 − 1
V . (10.12)278 10 Ideal Bose Gas
The values of.z ∼ 1 − 1/V are said to be in the vicinity of.z = 1. We know that when 
.n¯λ3
T → (n¯λ3
T)c,.z → 1 so that. z lies in the vicinity of.z = 1, making the ground state 
number density.n¯0 non-zero. The. z remains in the vicinity of. 1 even as.n¯λ3
T increases 
beyond.(n¯λ3
T)c. Since.z ≈ 1 in the vicinity of.z = 1,.g3/2(z) ≈ g3/2(1). Hence, when 
.n¯λ3
T > (n¯λ3
T)c the occupation number of the ground state, determined by letting 
.g3/2(z) = g3/2(1) in (10.10), is 
.
n¯0
n¯ = 1 − (n¯λ3
T)
−1g3/2(1), n¯λ3
T > g3/2(1). (10.13) 
This shows that, out of total number density. n¯, the number density.n¯ e in the excited 
state is 
.
n¯ e
n¯ = (n¯λ3
T)
−1g3/2(1), n¯λ3
T > g3/2(1), (10.14) 
The last two equations give the fraction of molecules in the zero energy, and the 
excited states when.n¯λ3
T > g3/2(1). 
We see that at the critical point, the ground state number density becomes finite 
and keeps increasing as the value of the parameter .n¯λ3
T increases beyond .g3/2(1). 
The phenomenon of the Bose gas making transition from the normal state in which 
.n¯0 = 0 to the one in which.n¯0 acquires macroscopic value is called the Bose–Einstein 
condensation (BEC). The region defined by the condition.n¯λ3
T > g3/2(1) is referred 
to as the condensation region. As .n¯λ3
T → ∞, .n¯ e/n¯ → 0 and .n¯0/n¯ → 1, i.e. all the 
molecules condense to the zero-energy state. The gas is then said to be in the con￾densed phase. For finite values of .nλ3
T > g3/2(1), it is a mixture of the condensed 
and the normal phase, called the condensate. 
Summary 
The value of the parameter .n¯λ3
T defines two phases of the Bose gas. When . n¯λ3
T <
g3/2(1), the ground state of energy zero has no macroscopic number of molecules in it. 
This is called the normal phase. When.n¯λ3
T = g3/2(1), called the critical value of. n¯λ3
T
denoted by.(n¯λ3
T)c, the ground state starts occupying macroscopic population which 
continues to increase as the value of.n¯λ3
T increases beyond.g3/2(1). The phenomenon 
of the Bose gas making transition from the normal phase in which the ground state 
population density .n¯0 = 0 to the one in which .n¯0 acquires macroscopic value is 
called the Bose–Einstein condensation. The entire number density resides in the 
ground state as .n¯λ3
T → ∞. This is called the condensed phase. The phase of the 
gas corresponding to finite values of .n¯λ3
T > g3/2(1) is called the condensate. The 
equations determining the number of molecules in various phases are: 
Normal Phase. n¯λ3
T < g3/2(1)
.n¯0 = 0, n¯ e = ¯n, n¯λ3
T = g3/2(z). (10.15)10.1 Bose Gas 279
Condensate. n¯λ3
T > g3/2(1)
.
n¯0
n¯ = 1 − (n¯λ3
T)
−1g3/2(1), n¯ e
n¯ = (n¯λ3
T)
−1g3/2(1). (10.16) 
Condensed Phase. n¯λ3
T → ∞
.
n¯0
n¯ = 1, n¯ e
n¯ = 0. (10.17) 
Let us determine how.n¯0 varies when the gas is compressed at constant temperature 
and how it varies when it is cooled keeping density fixed. 
1. If gas in the normal phase is compressed keeping temperature fixed at .T then . n¯
would increase till its critical value.n¯ c at which.(n¯λ3
T)c = ¯ncλ3
T ≡ g3/2(1) so that 
.n¯ c = λ−3
T g3/2(1). (10.18) 
The.n¯ c is called the critical density corresponding to a specified. T . The gas is in 
the normal phase for.n¯ < n¯ c so that the value of.n¯0 in the normal phase given by 
the first equation in (10.15) holds for.n¯ < n¯ c: 
.n¯0 = 0, n¯ < n¯ c, normal phase. (10.19) 
For.λ3
T > n¯ c, the ground state occupancy is determined by (10.16) which, on using 
(10.18), reads 
.
n¯0
n¯ = 1 − n¯ c
n¯ , n¯ > n¯ c, condensate. (10.20) 
In terms of the number.N¯ 0 of molecules in the ground state, and their total number 
. N¯ , the equation above assumes the form 
.
N¯ 0
N¯ = 1 − n¯ c
n¯ , n¯ > n¯ c, condensate. (10.21) 
Equations (10.19) and (10.20) determine the ground state population as a function 
of density at a fixed temperature. We see that the ground state population remains 
zero for densities less than the critical density but starts acquiring finite values at 
the critical value and keeps increasing as the density is increased further. 
2. If the gas in the normal phase is cooled keeping the density fixed at . n¯ it will 
remain in normal phase till temperature attains the value . Tc, called the critical 
temperature for the specified value of . n¯, at which .(n¯λ3
T)c = ¯nλ3
Tc ≡ g3/2(1), i.e. 
when 
.λ3
Tc = ¯n−1g3/2(1). (10.22)280 10 Ideal Bose Gas
Hence, due to (10.15), 
.n¯0 = 0, T > Tc, normal phase. (10.23) 
For .λ3
T > λ3
Tc
, the ground state occupancy is determined by (10.16) which, on 
using (10.22) reads 
.
n¯0
n¯ = 1 −
( T
Tc
)3/2
, T < Tc, condensate. (10.24) 
In terms of the number.N¯ 0 of particles in the ground state, and their total number 
. N, the equation above reads 
.
N¯ 0
N¯ = 1 −
( T
Tc
)3/2
, T < Tc, condensate. (10.25) 
Equations (10.23) and (10.25) determine the ground state population as a function 
of temperature above and below the critical temperature at a fixed density. We 
see that the ground state population remains zero for temperatures higher than 
the critical temperature but starts acquiring finite values at the critical value and 
keeps increasing as temperature is lowered further. 
In Sect. 10.1.3 we will see that the BEC may be viewed as a phenomenon of phase 
transition. 
The BEC is the phenomenon of condensation of the molecules in the momentum 
space. However, falling under gravity, the condensed phase would separate from the 
normal phase in real space. See [ 1] and references therein for the theory of Bose gas 
under gravity. 
Though predicted in 1924, the experimental realization of BEC had to wait for 
technological advancements to create low density gases and low temperatures. First 
BEC was observed in 1995 in the gas of Rb-87 atoms at the critical temperature 
170nK at the number density of about .2.5 × 1012/c.c. [ 2]. It was soon followed by 
its observation in Na atoms at the critical temperature.2μK at the number density of 
about.1014/c.c. [ 3]. 
10.1.1 Conditions for BEC 
The occurrence of BEC is the result of non-solvability of the (10.3) for.g3/2(z)in terms 
of the parameter.n¯λ3
T under the restriction.0 ≤ z ≤ 1 on the values of. z. The reason 
for it is that .g3/2(z) is monotonically increasing and bounded at .z = 1. As a result, 
.g3/2(z) has maximum value.g3/2(1) in the desired range.0 ≤ z ≤ 1 whereas there is 
no bound on the values of .n¯λ3
T. No such problem would arise if in place of .g3/2(z)10.1 Bose Gas 281
there were another function unbounded at.z = 1. To look for situations in which said 
possibility may be realized, recall that the relation (10.3) is for three-dimensional non￾relativistic Bose gas. Let us examine the equations for.n¯λ3
T in different dimensional 
spaces obeying different energy-momentum relations. 
To that end, recall that the average number of particles in .d-dimensional Bose 
gas in which energy is related with momentum by the relation.E = Cn pn is given by 
(8.150): 
. N¯ = And
βd/n Γ (d/n)gd/n(z),
where.And is as in (8.90). The BEC will occur if.gd/n(1) is bounded. If.gd/n(1) is not 
bounded,.N¯ in the equation above can take values without restriction so that BEC will 
not occur if.gd/n(1) is unbounded. We know that.gd/n(1) is bounded when. d/n > 1
else it is not. We thus see that the condition for BEC to occur is .d/n > 1. It is, 
of course, satisfied for .3-dimensional non-relativistic Bose gas. However, for two￾dimensional non-relativistic Bose gas .d = 2, n = 2 so that .d/n = 1. Hence BEC 
will not occur in a two-dimensional non-relativistic Bose gas. On the other hand, for 
two-dimensional ultra-relativistic Bose gas.d = 2, n = 1 so that.d/n > 1 and hence 
such a gas will exhibit BEC. 
For Bose gas of photons in a blackbody cavity.d = 3, n = 1 so that the condition 
.d/n > 1 for BEC to occur is satisfied. It, however, can not exhibit BEC for different 
reasons. For, recall that the fugacity is.z = exp(α) where. α is the Lagrange multiplier 
for imposing the restriction on the average number of particles while maximizing 
entropy. In case the average number of particles cannot be specified, the correspond￾ing Lagrange multiplier . α is zero so that .z = 1. For such gases therefore there is 
no question of determining . z as a function of temperature and density and hence 
those gases will not exhibit BEC. That is the case with the photon gas in a blackbody 
cavity because the photons in the cavity are created and absorbed continuously by 
the oscillators in the walls of the cavity due to which it is not possible to specify the 
photon number. Hence photon gas in a blackbody cannot exhibit BEC. 
However, though the restriction on the average photon number does not apply to 
photons in a blackbody, it is possible to create conditions in which that restriction 
applies making . z vary. Such conditions have been conceptualized and BEC of gas 
of photons realized experimentally. See for example [ 4, 5]. 
10.1.2 Thermodynamic Properties 
We showed that the state of the Bose gas makes transition from normal to the con￾densate phase when its temperature and density are such that the parameter . n¯λ3
T
exceeds the value.g3/2(1). We now study its thermodynamic properties in those two 
phases. To that end, since.z < 1 for the Bose gas, we use the expressions for various282 10 Ideal Bose Gas
thermodynamic quantities derived in Sect. 8.7 for.z < 1 corresponding to.η = 1 with 
.g(1)
p (z) → gp(z). 
1. Consider the expression (8.139) for pressure: 
.P = 1
βλ3
T
g5/2(z) − 1
βV
ln(1 − z). (10.26) 
When the gas is in the normal phase,. z is not in the vicinity of. 1 so that the second 
term in (10.26) goes to zero in the thermodynamic limit. On the other hand, when 
. z is in the vicinity of . 1, .(1/V )ln(1 − z) → 0 as .V → ∞ whereby the second 
term in (10.26) vanishes in the condensate as well. Recalling that .z = 1 in the 
condensate, (10.26) reduces to 
. P = 1
βλ3
T
g5/2(z), λ3
Tn¯ < g3/2(1), normal phase,
P = 1
βλ3
T
g5/2(1), λ3
Tn¯ > g3/2(1), condensate, (10.27) 
where from the tabulated values 
.g5/2(1) = 1.341 ... (10.28) 
Equation (10.27) shows that the pressure of the condensate is independent of . n¯. 
Consequently, its isothermal compressibility.κT (defined in (2.110)) is infinity in 
the condensate including at the critical point when approached from the conden￾sate side. It is shown in Ex. 10.4 that .κT → ∞ even when the critical point is 
approached from the normal phase side. 
In the normal phase, dependence of pressure on. n¯ comes from the dependence of 
. z on. n¯ (see Ex. 10.3). 
On using the expression (7.6) for .λT , the second equation in (10.27) may be 
rewritten as 
.P = (kBT )
5/2
(2πm
h2
)3/2
g5/2(1), condensate. (10.29) 
This is the equation of state for the BEC. 
2. On combining (10.15) and (10.27) we obtain 
.P = N kBT
V
g5/2(z)
g3/2(z)
, normal phase. (10.30) 
Since .g5/2(z) ≤ g3/2(z) (see Fig. 10.1), we see that the pressure exerted by the 
Bose gas in the normal phase is always less than that exerted by the classical gas 
at same density and temperature. Recall that we arrived at the same conclusion10.1 Bose Gas 283
by expressing .P as a power series in.n¯λ3
T in (8.163). In particular, at the critical 
temperature. Tc, 
.P = N kBTc
V
g5/2(1)
g3/2(1) ≈ 0.513 N kBTc
V . (10.31) 
This shows that the pressure of the Bose gas at the critical temperature is about 
half of that of the classical gas at the same temperature and density. 
3. Recall the expression (8.140) for the internal energy. U: 
.U = 3V
2βλ3
T
g5/2(z). (10.32) 
By the same arguments as were used to arrive at (10.27) we get 
. U = 3V
2βλ3
T
g5/2(z), λ3
Tn¯ < g3/2(1), normal phase,
U = 3V
2βλ3
T
g5/2(1), λ3
Tn¯ > g3/2(1), condensate. (10.33) 
4. Consider the Bose gas at fixed number density . n¯ and vary its temperature. The 
transition between normal phase and the condensate then occurs at the critical 
temperature. Tc. Using (10.33), the heat capacity at constant volume and number 
in the normal phase turns out to be 
.CV = 3kBV
2λ3
T
(5
2
g5/2(z) + g3/2(z)
kBβ
1
z
( ∂z
∂T
)
V
)
, T > Tc, (10.34) 
where we have used the identity (8.143). Use (10.15), and (10.54) to reduce the 
equation above to the form 
.
CV
kB N = 3
4
(5g5/2(z)
g3/2(z) − 3g3/2(z)
g1/2(z)
)
, T > Tc. (10.35) 
The value of.CV at the critical point is obtained by taking the limit.z → 1 of the 
expression above. Since.gp(1) is finite for.p > 1 and.g1/2(1) → ∞ as.z → 1, the 
expression above yields 
.
CV
kB N
|
|
|
|
Tc+0
= 15
4
g5/2(1)
g3/2(1) ≈ 1.925. (10.36) 
This is the value of the specific heat at the critical temperature when approached 
from above. 
Next, the derivative of.CV with respect to. T may be seen to be given by284 10 Ideal Bose Gas
. 
1
kB N
∂CV
∂T =
[
15
4
(
1 − g5/2(z)g1/2(z)
g2
3/2(z)
)
−9
4
(
1 − g3/2(z)g−1/2(z)
g2
1/2(z)
)]
1
z
( ∂z
∂T
)
V
. (10.37) 
Using (10.54) and the fact that .gp(1) is finite if .p > 1, .g1/2(1) → ∞, the first 
term in (10.37) in the limit.z → 1 reduces to 
.
15
4
(
1 − g5/2(z)g1/2(z)
g2
3/2(z)
)
1
z
( ∂z
∂T
)
V
→ 45
8Tc
g5/2(1)
g3/2(1) ≈ 2.888
Tc
. (10.38) 
In the limit.z → 1, the second term in (10.37) reads 
. −9
4
(
1 − g3/2(z)g−1/2(z)
g2
1/2(z)
)
1
z
( ∂z
∂T
)
V
→ −27Tc
8
Ltz→1
(
g2
3/2(z)g−1/2(z)
g3
1/2(z)
)
. (10.39) 
The functions .g±1/2(1) are not finite. We can, however, evaluate the expression 
above by using the asymptotic forms of those functions: 
. g1/2(exp(α)) = √π (−α)−1/2
,
g−1/2(exp(α)) =
√π
2 (−α)−3/2
, α → 0. (10.40) 
It is readily seen that the expression (10.39) then reduces to 
. − 27Tc
8
Ltz→1
(
g2
3/2(z)g−1/2(z)
g3
1/2(z)
)
= − 27
16π
g2
3/2(1) ≈ −3.665. (10.41) 
On substituting (10.38) and (10.41) in (10.37) we obtain 
.
1
kBN
∂CV
∂T
|
|
|
Tc+0
≈ −0.778
Tc
. (10.42) 
This is the slope of the .CV curve as a function of temperature at .T = Tc on the 
normal side of the gas. 
5. We now evaluate .CV when .T < Tc. Invoking (10.33) for .λ3
Tn¯ < g3/2(1) it is 
straightforward to see that 
.
CV
kB N = 15
4n¯λ3
T
g5/2(1). T ≤ Tc. (10.43)10.1 Bose Gas 285
Since.λT ∼ T −1/2, this shows that.CV ∼ T 3/2 as.T → 0. Recall from (9.47) that 
in a Fermi gas.CV ∼ T as.T → 0. 
At the critical point,.(n¯λT)c = g3/2(1). Hence, the value of.CV at.Tc on the con￾densate side is given by 
.
CV
kB N
|
|
|
Tc−0
= 15
4
g5/2(1)
g3/2(1) ≈ 1.925. (10.44) 
This is the value of specific heat at the critical temperature when approached 
from below. It is same as that in (10.36) for.CV at.Tc + 0. Thus the specific heat 
is continuous at the critical point. 
On differentiating (10.43) with respect to. T we obtain 
.
1
kB N
∂CV
∂T = 45
8T n¯λ3
T
g5/2(1), T ≤ Tc. (10.45) 
Since.(n¯λT)c = g3/2(1), at the transition point, 
.
1
kB N
∂CV
∂T
|
|
|
Tc−0
= 45
8Tc
g5/2(1)
g3/2(1) ≈ 2.89
Tc
. (10.46) 
On comparing this with (10.42) we see that 
.
∂CV
∂T
|
|
|
Tc−0
/=
∂CV
∂T
|
|
|
Tc+0
. (10.47) 
This shows that the slope of the specific heat curve as a function of .T is not 
continuous at the transition point as is exhibited also by the plot of.CV /N kB as a 
function of.T/Tc in Fig. 10.2. 
6. Invoking the identity (2.118) for the ratio of the specific heat at constant pres￾sure to that at constant volume and recalling the expressions (10.57), (10.58) for 
isothermal and isentropic compressibilities we obtain 
Fig. 10.2 Specific heat of 
Bose gas as a function of 
temperature286 10 Ideal Bose Gas
.
CP
CV
= κT
κS
= 5
3
g5/2(z)g1/2(z)
g2
3/2(z) . (10.48) 
In the classical limit characterized by .z << 1 it is straightforward to see by 
keeping the lowest order term in the summation defining .gp(z) that . Γ = 5/3
which is the known classical value. 
7. The relations derived in Ex. 10.7 between pairs of .(P, V, T ) for the Bose gas 
undergoing adiabatic transformation are same as those for the classical gas. How￾ever, the exponents therein are not related with.CP /CV , derived in (10.48) for the 
Bose gas, as they are in the classical gas (see also the discussion circa (8.151)). 
8. Recalling (2.76) and (8.130), the grand potential for the Bose gas reads 
.Ω(T, V, μ) = −2
3
U. (10.49) 
Invoking the expression (10.33) for. U, we obtain 
. Ω = − V
βλ3
T
g5/2(z), λ3
Tn¯ < g3/2(1), normal phase,
Ω = − V
βλ3
T
g5/2(1), λ3
Tn¯ > g3/2(1), condensate. (10.50) 
We use these results to derive expression for the entropy of the Bose gas. 
9. Recall from (2.78) the relation, 
.S = − (∂Ω
∂T
)
V,μ
, (10.51) 
to show using the expression (10.50) for.Ω(T, V, μ) that 
. 
S
kBN = 1
n¯λ3
T
(5
2
g5/2(z) − μβg3/2(z)
)
= 5
2
g5/2(z)
g3/2(z) − μβ,
= 5
2
g5/2(z)
g3/2(z) − ln(z) normal phase,
S
kBN = 5
2n¯λ3
T
g5/2(1) condensate. (10.52) 
We leave the derivation of the expressions above as an exercise. It is readily seen 
that. S in (10.52) in the condensate can be written as 
.ST = 5
2
PV = 5
3
U, condensate. (10.53)10.1 Bose Gas 287
Since.μ = 0 in the condensate, the relation above is consistent with Euler’s equa￾tion. 
Exercises 
Ex. 10.1. Show that 
.
1
z
( ∂z
∂T
)
V,N
= − 3g3/2(z)
2T g1/2(z)
. (10.54) 
Hint: Differentiate second equation in (10.15) with respect to. T . 
Ex. 10.2. Show that 
.
1
z
( ∂z
∂T
)
P,N
= − 5
2T
g5/2(z)
g3/2(z)
. (10.55) 
Hint: Use (10.27). 
Ex. 10.3. Show that 
.
1
z
( ∂z
∂V
)
T,N
= − g3/2(z)
V g1/2(z)
. (10.56) 
Hint: Use (10.15). 
Ex. 10.4. Show that the isothermal compressibility .κT (defined in (2.110)) for a 
Bose gas in normal phase is given by 
.κT = β
n¯
g1/2(z)
g3/2(z)
. (10.57) 
Since .g1/2(z) → ∞ as .z → 1, this shows that .κT → ∞ as the transi￾tion point is approached from the normal phase side. It has been shown 
circa (10.28) that.κT → ∞ as the transition point is approached from the 
condensate side as well. Hint: Differentiate (10.27) with respect to .V at 
constant.N, T and use (10.56). 
Ex. 10.5. Show that the isentropic compressibility.κS (defined in (2.103)) of Bose 
gas in normal phase is given by 
.κS = 3β
5n¯
g3/2(z)
g5/2(z)
. (10.58) 
Hint: Since. S is constant, (10.52) shows that, at constant. N,. z = constant
for the gas in the normal phase. Hence partial derivatives at constant. S and 
.N are equivalent with those at constant . z. Eliminate . β between (10.15) 
and (10.27) to rewrite the expression for.P in terms of.V and. z:288 10 Ideal Bose Gas
.P =
( h2
2πm
)2/3 ( N
V g3/2(z)
)5/3
g5/2(z). (10.59) 
Use also (10.56). 
Ex. 10.6. Derive (10.52) using (10.51). Hint: Note that the derivative in (10.51) is 
to be carried keeping. μ fixed. Since.z = exp(μβ), 
. (∂gp(z)
∂T
)
V,μ
= −kBβ2
(∂gp(z)
∂z
)
V,μ
( ∂z
∂β )
V,μ
= −kBβ2
μgp−1.
(10.60) 
Ex. 10.7. Show that with . S given by (10.52), .T (∂ S/∂T )N,V leads to the same 
expression for.U as in (10.33). 
Ex. 10.8. Show that the equations of state for an adiabatic transformation of the 
Bose gas are 
.T P−2/5 = constant, T V2/3 = constant. (10.61) 
Hint: Since .S and .N are constants in an adiabatic process, (10.52) 
shows that .z = constant for the gas in normal state. It then follows 
from (10.27) that .T P−2/5 = constant in both phases. Recall (8.151) 
(.PV5/3 = constant) to derive the other result above. 
Ex. 10.9. Consider a two-dimensional ultra-relativistic Bose gas having average 
number . n¯ of particles per unit area. Show that, unlike the case of two￾dimensional non-relativistic gas, the two-dimensional ultra-relativistic 
gas exhibits BEC and find the critical temperature. Tc. 
Hint: The number density per unit area in two-dimensional ultra￾relativistic Bose gas, given by (8.150) corresponding to.d = 2, n = 1 is 
.n¯ = 2π
h2c2β2 g2(z) (10.62) 
The maximum possible value. 1 of. z shall be reached when 
.
nh¯ 2c2β2
2π = g2(1) = π2
6 . (10.63) 
This will therefore have no solution when.nh¯ 2c2β2/2π>π2/6. 
10.1.3 BEC as a Phenomenon of Phase Transition 
Note: Reader may skip this subsection in first reading and return to it after going 
through the chapter on phase transitions.10.1 Bose Gas 289
The BEC exhibits the features of second as well as first-order phase transitions. 
For, the behavior of the population in the ground state in a BE gas remaining finite 
below a critical temperature and vanishing suddenly thereat to remain zero for higher 
temperatures is reminiscent of the behavior of the order parameter characteristic of a 
second-order phase transition. The compressibility of the BE gas going to infinity at 
the transition temperature (See Ex. 10.4) is also a characteristic of the second-order 
phase transition. 
However, as we will show below, the BE transition involves absorption or release 
of the latent heat, a characteristic of the first-order phase transition. To that end we 
investigate the characteristics of.P − v (.v = 1/n¯) isotherms and the.P − T coexis￾tence curve. 
Consider the behavior of.P as a function of the specific volume.v ≡ 1/n¯ at some 
fixed temperatures. T . We know that the condensation region is characterized by such 
values of.v, T for which.λ3
T/v ≥ g3/2(1). Hence, for a given. T , the specific volume. v
in the condensation region is such that.v ≤ g−1
3/2(1)λ3
T whereby the maximum value 
.vmax turns out to be 
.vmax = g−1
3/2(1)λ3
T. (10.64) 
Now, as the expression (10.27) shows, pressure in the condensate for a given. T does 
not depend on . v. Hence an isotherm on the .P − v plot in the condensation region 
will be a line parallel to the .v-axis extending from .v = 0 to .vmax. We can express 
.vmax in terms of.P by eliminating. β between (10.64) and the second equation for. P
in (10.27), valid in the condensation region, leading to 
.Pv5/3 max = h2
2πm
g5/2(1)
g
5/3
3/2 (1)
. (10.65) 
Thus, at a given temperature, the.P − v plot in the condensation region at any pressure 
.P extends from.v = 0 to.vmax where.vmax is determined by (10.65). This is depicted 
in Fig. 10.3 where the dashed curve is the plot of .vmax given by (10.65). It is called 
the coexistence curve because it is the locus of the meeting points of the isotherms 
in the normal and the condensate phases. Referring to the .T = T1 isotherm in the 
figure, the system is in condensed phase at. A where .v = 0 and in the normal phase 
at.B where.v = vmax. It is a mixture of the two phases, which we have been calling 
condensate, for any other. v between. A and. B. The part of the isotherm corresponding 
to .v>vmax is determined by the first equation in (10.27) in which . z is determined 
implicitly by the (10.15). The part of an isotherm in the condensate region, such as 
.AB in Figure 10.3, resembles the plot of liquid–gas phase transition (see Fig. 12.4) 
wherein the part of the isotherms in the region where liquid and gas phases coexist 
is a straight line parallel to the.v-axis. 
We can determine the fraction of the condensed and the normal phases for any. v
in the condensate region by the lever rule (11.7). According to that rule, if.v1 is the 
specific volume of one phase, and.v2 that of the other at a given temperature then the290 10 Ideal Bose Gas
Fig. 10.3 .P − v diagram of 
Bose gas. The dashed curve 
is the plot of.vmax given by 
(10.65) 
fractions of the two phases having combined specific volume. v is given by 
. f1 = v2 − v
v2 − v1
, f2 = v − v1
v2 − v1
.
To apply this rule in the present case, consider the .P − v isotherm at temperature 
.T1 in Figure 10.3. Let the index . 1 in the expression above stand for the condensed 
phase and. 2 for the normal phase so that 
. fcond = vB − v
vB − vA
, fnormal = v − vA
vB − vA
, vB = vmax = λ3
T
g3/2(1)
, (10.66) 
and.vA = 0. It then follows that 
. fcond = vB − v
vB
, fnormal = v
vB
. (10.67) 
We can evaluate also the difference in entropies at the points .A and .B noting that 
entropy.SA in the condensed phase at. A is zero, and entropy.SB in the normal phase 
at. B, evaluated using (10.52), is given by 
.
SB
kBN = 5vmax
2λ3
T
g5/2(1) = 5
2
g5/2(1)
g3/2(1)
. (10.68) 
The second equation above is due to (10.64). Hence difference between the normal 
and the condensed state entropies per molecule is 
.Δs = (SB − SA)/N = 5
2
g5/2(1)
g3/2(1)
kB. (10.69)10.2 Gas of Photons 291
Since the transition occurs at a fixed temperature, the change in entropy is accompa￾nied by the heat exchange called the latent heat. L given by 
.L = T Δs = 5
2
g5/2(1)
g3/2(1)
kBT. (10.70) 
The presence of latent heat is a signature of first-order phase transition. To establish 
the consistency, we determine the latent heat also using the Clapeyron–Clausius 
equation (11.26) which relates latent heat with the slope of the .P − T coexistence 
curve. 
The functional relation between. P and. T at the transition point defines the. P − T
coexistence curve. The Clapeyron–Clausius equation (11.26) relating latent heat to 
the slope of the.P − T coexistence curve in the preset case reads 
.L = T (vB − vA)
(dP
dT
)
coex
. (10.71) 
The slope of the .P − T coexistence curve is determined by (10.27) relating .P and 
. T in the condensate: 
.
dP
dT = 5kB
2λ3
T
g5/2(1). (10.72) 
Combine this with (10.71) with.vA = 0,.vB = vmax to get (10.70). This establishes the 
consistency of the interpretation of the.P − v isotherms and the.P − T coexistence 
curve in BEC as the first-order phase transition. 
10.2 Gas of Photons 
By the gas of photons we mean quanta of electromagnetic (e.m.) radiation inside a 
blackbody at some temperature. T. A photon is the quantum of a mode of the em field 
wave characterized by the wave vector. k and one of the two directions of polarization 
.e1k, e2k for each value of . k. The state of a photon is therefore characterized by 
the parameter .k ≡ (k, eik) (.i = 1, 2). We denote by .Ek the energy of the photon in 
the state characterized by . k. The equilibrium state of the gas of photons inside a 
blackbody is characterized by average energy without any restriction on the number 
of photons. For, photons in the cavity are continuously being absorbed and emitted 
by the atoms in the walls of the cavity due to which their number cannot be specified, 
neither as exact nor as an average. The spin quantum number of a photon is 1. Hence 
photons are Bosons. The partition function .Z P of the gas of photons is therefore 
Bosonic given by (8.45) with.α = 0:292 10 Ideal Bose Gas
.ln(Z P ) = −Σ
k
ln{1 − exp(−βEk )}. (10.73) 
The parameter . α is put equal to zero because it is the Lagrange multiplier corre￾sponding to the constraint on the average number of particles which is absent in the 
present case. The probability of having.nk photons of energy.Ek is given by (8.46): 
.p(nk ) = (1 − exp(−βEk )) exp (−βEknk ). (10.74) 
Photons are massless obeying the energy-momentum relation 
.E = pc. (10.75) 
We therefore convert the sum to an integral by using the expression (8.77) for the 
density of states for a massless particle by the correspondence 
.
Σ
k
f (E(k)) →
{ ∞
0
f (E) D(E) dE, D(E) = 2
4πV E2
h3c3 . (10.76) 
The expression for the density of states .D(E) above differs from the one given in 
(8.77) by multiplication by the factor of two to account for two directions of the field 
polarization. 
In the following we use the correspondence above to investigate the thermody￾namic properties of the gas of photons. See also [ 6]. 
10.2.1 Thermodynamic Properties 
In Appendix F we have derived thermodynamic properties of the blackbody radiation 
by starting from the phenomenological Stefan–Boltzmann law. In the following we 
derive those properties by using the formalism of statistical mechanics and find that, 
it not only reproduces the results derived using the said law, but also yields expression 
for the phenomenological Stefan–Boltzmann constant in terms of the fundamental 
constants. 
1. Following the procedure outlined in Sect. 8.7, we convert the sum in (10.73) 
defining.ln(Z P )to the integral with.D(E) given by (10.76), perform the integration 
by parts and transform the variable of integration. E to.x = βE to obtain 
.ln(Z P ) = 8πV
3h3c3β3
{ ∞
0
x 3 dx
exp(x) − 1
. (10.77) 
On using (H.12) to carry the integral above we get10.2 Gas of Photons 293
.ln(Z P ) = 8π5V
45h3c3β3 . (10.78) 
2. The pressure of the photon gas is given by 
.P = 1
βV
ln(Z P ) = 8π5k4
B
45h3c3 T 4
. (10.79) 
This shows that, since.(∂ P/∂V)T = 0, the isothermal compressibility.κT , defined 
in (2.110), is infinitely large for photon gas, or as is argued in [ 6], one must say 
it does not exist because the identity .(∂V/∂ P)T = 1/(∂ P/∂V)T does not hold 
when its left side is zero. 
3. The internal energy of the photon gas is 
.U = −∂ln(Z P )
∂β = 8π5k4
BV
15h3c3 T 4
. (10.80) 
The intensity. I of radiation coming out from a small opening from the blackbody 
cavity is.I = cU/4V so that, with.U given by (10.80), we have 
.I = σ (kB T )
4
, σ = 2π5
15h3c2 . (10.81) 
This is the well-known Stefan–Boltzmann law where .σ is Stefan–Boltzmann 
constant. That constant is included in thermodynamics as an unknown to be 
determined experimentally. In the statistical mechanical formalism we see that it 
emerges naturally and is a function only of the fundamental constants. c and. h. 
4. On comparing (10.79) and (10.80) it is straightforward to see that 
.PV = 1
3
U. (10.82) 
It is same as the relation arrived in (F.5) by following the Stefan–Boltzmann law. 
It is also consistent with the general formula (8.147) as in the present case the 
system is three-dimensional and due to the energy-momentum relation (10.75) 
for photons,.n = 1. Compare (10.82) with the corresponding relation (8.130) for 
massive quantum particles to note the difference of the factor of. 2. On substituting 
in (10.82) the expression (10.80) for. U, we recover the expression (10.79) for. P. 
5. The adiabatic equation of state for the photon gas is given by (8.151) with. d = 3
and due to (10.75),.n = 1 therein: 
.PV4/3 = constant. (10.83) 
6. Invoking (10.80), the specific heat at constant volume turns out to be294 10 Ideal Bose Gas
.
CV
kBV = 1
kBV
∂U
∂T = 32π5k3
B
15h3c3 T 3
. (10.84) 
Note that in the photon gas, which is the gas of massless bosons, the specific heat 
.CV ∼ T 3 as.T → 0 whereas.CV ∼ T 3/2 for a massive Bosonic gas (see (10.43)). 
7. Using the identity (H.1), the average number of photons in the level of energy. Ek
may be shown to be given by 
.N¯ k = Σ∞
nk=1
nk p(nk ) = 1
exp(βεk ) − 1
. (10.85) 
Average number of photons per unit volume in all the states is 
.
N¯
V ≡ 1
V
Σ
k
exp(−βEk )
1 − exp(−βεk ) = 8πk3
BT 3
h3c3
{ ∞
0
x 2dx
exp(x) − 1
. (10.86) 
Invoking the identity (H.12) we get 
.
N¯
V = 8πk3
BT 3
h3c3 Γ (3)ζ (3) = 1.202
16πk3
B
h3c3 T 3
. (10.87) 
8. The expression for entropy, evaluated using Euler’s equation with.μ = 0 therein 
for the gas of photons, reads 
.
S
kBV = 32π5k3
B
45h3c3 T 3
. (10.88) 
The.T 3 dependence of.S/V in the equation above is consistent with that arrived 
in (F.4) by Stefan–Boltzmann law. 
9. To determine fluctuations in the number of photons in the mode . k we evaluate 
.⟨N2
k ⟩ using the identity (H.1) to get 
.⟨N2
k ⟩ = Σ∞
nk=0
n2
k p(nk ) = exp(−βEk )(1 + exp(−βEk ))
(1 − exp(−βEk ))2 . (10.89) 
Derivation of the equation above is left as an exercise. It then follows that the 
variance in the number of photons in the state. k is 
.⟨N2
k ⟩−⟨Nk ⟩
2 = exp(−βEk )
(1 − exp(−βEk ))2 . (10.90) 
The variance in total number of photons isReferences 295
.⟨N2
⟩−⟨N⟩
2 = 8πk3
BT 3V
h3c3
{ ∞
0
x 2 exp(−x)dx
(1 − exp(−x))2 . (10.91) 
Invoking the identity (H.13), we obtain 
.⟨N2
⟩−⟨N⟩
2 = 8π3k3
BV
3h3c3 T 3
. (10.92) 
This shows that the fluctuations in the number of photons is finite. Now recall 
the result obtained following (10.79) namely .κT is infinitely large (or does not 
exist) for the photon gas using which we see that the equation (6.77) relating 
number fluctuations with isothermal compressibility predicts that number fluc￾tuations must be infinitely large (or do not exit). The question of the origin of 
incompatibility of the said results has been traced in [ 6] to the inapplicability 
of the derivation of (6.77) when applied to the photon gas. For, note that the 
derivation of (6.77) involves differentiating average number .N¯ of particles with 
respect to. α which, being zero for photon gas, is put equal to zero while evaluating 
. N¯ . Consequently .N¯ has no . α dependence left in it. Alternatively, note that we 
get the factor .1/(∂ P/∂α)V,T in (6.76) on way to the derivation of (6.77). Since 
.(∂ P/∂α)V,T = 0 for photon gas, the derivation becomes questionable for photon 
gas. For further discussion see [ 6]. 
References 
1. R.K. Bhaduri, W. van Dijk, Phys. Lett. A 380, 2480 (2016) 
2. M.H. Anderson, J.R. Ensher, M.R. Mathews, C.E. Wieman, E.A. Cornell, Science 269, 198 
(1995) 
3. K.B. Davis, M.-O. Mewes, M.R. Andrews, N.J. van Druten, D.S. Durfee, D.M. Kurn, W. Ketterle, 
Phys. Rev. Lett. 75, 3969 (1995) 
4. J. Klaers, J. Schmitt, F. Vewinger, M. Weitz, Nature 468, 545 (2010) 
5. J. Klaers, M. Weitz, (2012) arXiv:1210.7707v1 [cond-mat.quant-gas] 
6. H.S. Leff, Am. J. Phys. 83, 362 (2015)Chapter 11
Phase Transitions and Critical
Phenomena
Transformation of a substance between its solid, liquid, and gaseous forms is a
common experience. In this chapter, we study the thermodynamic description of the
said transformations called the phenomenon of phase transitions. Introduced also is
the concept of the critical phenomenon.
11.1 Phase Equilibrium
It is observed that at certain values of pressure and temperature a homogeneous
substance may separate into two homogeneous parts of different densities in contact
with each other. The coexisting parts of a substance in contact with each other having
different densities are called its phases. The gaseous, liquid, and solid forms of matter
in that sense are its different phases. The phenomenon of separation of a homogeneous
substance into its different phases is called the phenomenon of phase transition. The
conditions under which the phase transition may occur can be determined as follows.
We label the two coexisting phases as phases 1 and 2. Since they are in equilibrium,
their pressure, and temperature, denoted by .(P0, T0), must be same. In addition,
since the molecules are exchanged between two phases, the condition of equilibrium
requires their chemical potentials also to equalize leading to the equation
.μ1(P0, T0) = μ2(P0, T0), (11.1)
where .μi is the chemical potential of the .ith phase (.i = 1, 2). Comparing this with
(2.66), we see that the relation above implies
.g1(P0, T0) = g2(P0, T0), (11.2)
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2024
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4_11
297298 11 Phase Transitions and Critical Phenomena
Fig. 11.1 P-T coexistence
curve
Phase
Phase
B
C
where
.gi(P, T ) = Gi(P, T )
Ni
, (11.3)
is Gibbs potential per molecule of the.ith phase. The two phases coexist only at the
values of pressure and temperature related by (11.2). It describes a curve in the.P − T
plane along which the two phases coexist. It is called the.P − T coexistence curve,
depicted in Fig. 11.1. Though the.P − T coexistence curve is shown as terminating in
the figure, it may not. When it does, the point of its termination is called the critical
point. The temperature .Tc at that point is called the critical temperature, and the
corresponding pressure.Pc the critical pressure. To see when the.P − T coexistence
curve can terminate, consider the coexistence curve in Fig. 11.1 terminating at.C. The
substance is homogeneous at pressures and temperatures greater than.Pc and.Tc. This
can happen if the two phases have same symmetry in their microscopic structure. On
the other hand, if the two phases are of different symmetry, they can not constitute a
homogeneous system thereby ruling out terminating .P − T coexistence curve. An
example of non-terminating.P − T curve is that of the solid-liquid phase transition
because molecules in a solid are arranged periodically but not in the liquid. The
liquid-gas phase transition, on the other hand, is described by a terminating.P − T
coexistence curve because both have non-periodic arrangement of molecules.
The.P − T coexistence curve therefore either does not terminate, or it terminates
at the point of intersection of coexistence curves of other phases.
11.1.1 Triple Point
We have obtained the condition under which two phases coexist. We can similarly
derive the conditions required for the existence of three phases in equilibrium. Those11.1 Phase Equilibrium 299
Fig. 11.2 P-T coexistence
curves for three phases
Liquid
Gas
Solid
A
C
conditions evidently are same pressure .P0 and temperature .T0 in the three phases
and the equality of their chemical potentials:
.μ1(P0, T0) = μ2(P0, T0) = μ3(P0, T0). (11.4)
These are two simultaneous equations in two unknowns and hence define a point in the
.P − T plane. At the said point, called the triple point, three phases coexist. Clearly,
there can not be more than three coexisting phases of a substance as that would require
simultaneously satisfying three equations in two unknowns, the problem which has
no solution. Fig. 11.2 depicts coexistence curves for solid–liquid–gas transition, each
for equilibrium between two of the three phases. The gas–liquid coexistence curve
terminates at the critical point C but the liquid–solid curve does not except at the
triple point.A.
The critical point of water occurs approximately at.373.9 ◦C, and 217.7 atm. Its
triple point occurs approximately at.0.01 ◦C, and.6.03 × 10−3 atm.
We construct next the.P − v coexistence curve and determine the fraction of each
phase in the coexistence region.
11.1.2 .P − v Isotherms in Coexistence Region
We restrict our attention to the case when the .P − T coexistence curve terminates.
Consider the point.B on the.P − T coexistence curve in Fig. 11.1 having coordinates
.(TB, PB). We examine the nature of the .P − v (.v = V/N is the specific volume)
isotherm at temperature.TB. To that end, consider the point.A1 on the said isotherm
on the .P − v diagram in Fig. 11.3. As pressure is decreased keeping temperature
fixed at.TB, the.P − v values would trace the dashed curve on which there is one-to￾one relation between.P and.v and therefore the system is homogeneous till pressure300 11 Phase Transitions and Critical Phenomena
Fig. 11.3 Solid curve in the
plot is the.P − v coexistence
curve
A
B
A1
A2
Phase Phase
D
reaches the value .PB (point .A on the dashed isotherm) which is the value of the
pressure corresponding to the temperature .TB on the .P − T coexistence curve. We
know that the equation of state corresponding to .(TB, PB) is solved by two values
of.v. Hence, at .A the system separates into two parts of different specific volumes
.v1, and .v2 where .v1 is the specific volume at the point.A and .v2 that at the point.B
at the same pressure.PB. For.v>v2, the system follows the dashed curve on which
there is one-to-one relation between .P and .v. Hence, for each temperature on the
.P − T coexistence curve, there is a pair of points, one in the state of phase 1 and the
other in phase 2. Join the points in phase 1 on different isotherms, and also those in
phase 2. At the critical point on the.P − T coexistence curve, (point.C in Fig. 11.1),
the two solutions merge. Hence, the said two curves in the .P − v plot merge at the
temperature .TC corresponding to the critical point .C. The result is the solid curve
depicted in Fig. 11.3, called the .P − v coexistence curve. Similar curve is obtained
for the .T − v plot called the .T − v coexistence curve. The region bound by the
coexistence curve is called the region of coexistence of the two phases.
As described above, the curve.A1 ABA2 in Fig. 11.3 depicts the part of the isotherm
corresponding to some temperature on the.P − T isotherm. The parts.A1A, and.B A2
are determined by the given equation of state and describe homogeneous system. The
straight line part.AB is the part of the isotherm in the coexistence region. The system
at.A is in phase 1 having specific volume .v1 and is in phase 2 at.B having specific
volume .v2. It is in mixed state for the values of .v lying between .v1, and .v2. We
will address the question of finding the equation of state in the coexistence region in
Sect. 11.2. For now, we determine the fraction of the two phases when the specific
volume of the system is in the coexistence region.11.1 Phase Equilibrium 301
11.1.3 Lever Rule
In order to find the proportion of the amount of the two phases in the mixed state, let.v
be the specific volume of the system, represented by the point.D on the line.AB in the
coexistence region. Let.V be the volume of the system, and.N the number of particles
in it. Let.Vi and .Ni be the volume and the number of molecules in the .ith phase at
.D so that .vi = Vi /Ni is the specific volume of the .ith phase with .V = V1 + V2,
.N = N1 + N2. We then have
.v ≡ V
N = V1 + V2
N = f1v1 + f2v2, (11.5)
where. fi = Ni /N is the fraction of the substance in the.ith phase with
. f1 + f2 = 1, fi = Ni
N . (11.6)
Equations (11.5) and (11.6) lead to the following expression for. fi for the state of
specific volume.v:
. f1 = v2 − v
v2 − v1
, f2 = v − v1
v2 − v1
. (11.7)
This is called the lever rule. It determines the fraction of the number of molecules in
the phases.1, and.2 when their combined specific volume is.v.
Using the lever rule, we can evaluate energy and entropy in the region of coexis￾tence as follows.
Referring to Fig. 11.3, we evaluate energy of the system in the state described by
the point.D. Let.U be the energy of the system so that its specific energy is.u = U/N.
Let .Ui be the energy of the phase .i component at the point .D so that the specific
energy of the.ith phase component in the mixture of the phases at.D is.ui = Ui/Ni .
Due to additivity of energy, it is straightforward to show that
.u = f1u1 + f2u2, (11.8)
where. fi is given by the lever rule (11.7).
Like energy, due to additivity of entropy, the specific entropy of the system is
given by
.s = f1s1 + f2s2, (11.9)
where.si is specific entropy of the.ith phase component.302 11 Phase Transitions and Critical Phenomena
11.2 Equation of State in Coexistence Region
An equation of state is the relation between .P, v, T of a single phase system. The
system in the coexistence region, on the other hand, is a mixture of two phases. In
this section, we outline the procedure for obtaining the equation of state, energy, and
entropy for the system in the coexistence region.
To determine the equation of state in the region of coexistence, referring to
Fig. 11.3, let .A1ABA2 therein be the .P − v isotherm corresponding to tempera￾ture.T meeting the coexistence curve at the points.A and.B. Since pressure is same
at all points on.AB, the equation of state in the region of coexistence corresponding
to temperature.T would be
.P(v, T ) = π(T ), (11.10)
where
.π(T ) = P(v1(T ), T ) = P(v2(T ), T ). (11.11)
Determination of the equation of state therefore requires knowledge of the specific
volumes.v1(T ), v2(T ) corresponding to the points.A and .B at which the isotherm
in question meets the coexistence curve. Those are determined by two equations
relating.v1(T ), and.v2(T ). One is their defining relation: the equality of pressure at
.A and.B,
.P(v1, T ) = P(v2, T ), (11.12)
and the other is the equality of the chemical potentials at.A and.B:.μA = μB. Note
that, since the system is in single phase at.A, and at.B where its specific volumes are
.v1,.v2, the.P(vi, T ) in (11.12) is determined by the single phase equation of state.
The second relation between .v1(T ), and .v2(T ) emerging from the equality of
.μA and .μB is obtained by integrating the Gibbs–Duhem relation (2.49) along the
isotherm joining.A and.B on which it reduces to.dμ = vdP so that
.μB − μA =
 B
A
vdP. (11.13)
Since.μA = μB, the equation above yields
.
 B
A
vdP ≡
 v2
v1
v
dP
dv
dv = 0. (11.14)
The expressions (11.12) and (11.14) are evaluated using single phase given equation
of state. They determine two unknowns,.v1 and.v2, as the function of.T and hence,11.3 First-Order Phase Transition 303
due to (11.11),.π(T ) which on substitution in (11.10) gives the equation of state in
the region of coexistence.
The evaluation of .v1, v2 using (11.14) thus requires knowledge of single phase
equation of state. In Chap. 12, we will outline method of solving (11.14) when the
equation of state is the van der Waals equation. We will introduce the concept of
critical point in Sect. 11.4 and find the equation of state in the region of coexistence
in its vicinity.
11.3 First-Order Phase Transition
We have seen that the intensive variables, .P, T, μ, are same for the two coexisting
phases but their specific volumes are different. Since, due to (2.66),.μ = g where.g
is specific Gibbs potential, on replacing.μ by.g in the Gibbs–Duhem relation (2.49)
or by invoking (2.68), we have
.v =
 ∂g
∂ P
 
T
, s = − ∂g
∂T
 
P
. (11.15)
Since the value of.v, and as we will see, also of.s, for the two coexisting phases are
different, it follows that, though.g(T, P) is continuous at the transition points on the
coexistence curve, its first derivatives are not. The phase transition, characterized by
continuity of the specific Gibbs potential but discontinuity of its first derivatives, is
called first-order phase transition. Discontinuity in entropy is manifested, as we will
see in the Sect. 11.3.3, in absorption or release of heat, called the latent heat, when
the substance transforms from one phase to the other.
In Sect. 11.4, we will come across transitions in which specific Gibbs potential as
well as its first derivatives are continuous but some of its second derivatives exhibit
singularity. Such a transition is called second-order phase transition. Note that, since
the first derivatives of.g(T, P) are continuous, the entropy of the coexisting phases
is same and hence there is no transfer of latent heat. In view of this, the phase
transitions which involve transfer of latent heat are called first order, and all the
others continuous-phase transitions.
11.3.1 Entropy Discontinuity
We determine the difference in entropy of the two coexisting phases. To that end,
consider the system at fixed pressure.P0 on its.P − T coexistence curve. Let.μ1(T )
be the chemical potential of phase 1, and.μ2(T ) that of phase 2 at temperature.T . Let
.T0 be the temperature corresponding to.P0 on the.P − T coexistence curve. The con￾dition of coexistence implies.μ1(T0) = μ2(T0). We know that the equilibrium state
for given.P, T corresponds to the minimum of the Gibbs potential (see Sect. 2.6.2).304 11 Phase Transitions and Critical Phenomena
Hence, due to equality of specific Gibbs potential and chemical potential, it follows
that the equilibrium state is one in which.μ is minimum. Since, at the given pressure
.P0, the system is in phase 1 below.T0, and in phase 2 above it, and the equilibrium
state is one of lower chemical potential, we have
.μ1(T0 − δT ) − μ2(T0 − δT ) < 0, in phase 1,
μ2(T0 + δT ) − μ1(T0 + δT ) < 0, in phase 2. (11.16)
Since pressure is assumed to be constant, these equations imply
. −
 ∂μ1
∂T
 
P0
< −
 ∂μ2
∂T
 
P0
. (11.17)
Due to the second equation in (11.15), the inequality above is same as
.s1 < s2, (11.18)
where .si is the entropy per molecule in the .ith phase. This shows that the specific
entropy in the phase at lower temperature is less than that at higher temperature close
to the coexistence curve. This is what is expected intuitively too.
11.3.2 Energy Discontinuity
The internal energy also undergoes jump at phase transition. It can be evaluated by
invoking the entropic Gibbs–Duhem equation (2.50) for .d(μ/T ) and noting that
equality of.μ on two sides of a point on the .P − T coexistence curve also implies
equality of.μ/T so that
.u1d(1/T ) + v1d(P/T ) = u2d(1/T ) + v2d(P/T ). (11.19)
This leads to the equation
.u2 − u1 = (v2 − v1)
 
T
 dP
dT
 
coex
− P
 
, (11.20)
which expresses jump in energy at the phase transition point in terms of the slope of
the.P − T coexistence curve.11.3 First-Order Phase Transition 305
11.3.3 Latent Heat
We will show that the system absorbs or releases heat during first-order phase transi￾tion. To that end, note that since phase transition takes place at a constant temperature,
the amount of heat.L absorbed per molecule by the system while transforming from
phase 1 to phase 2, obtained by integrating the equation.dq = T ds is given by
.L = T (s2 − s1), L ≡ q2 − q1. (11.21)
Since, due to (11.18), .s1 < s2, we see that.L > 0, i.e. heat is absorbed while trans￾forming from phase 1 to phase 2 when phase 2 is on the higher side of temperature of
the.P − T coexistence curve. Since temperature of the system does not change while
it absorbs the said heat, it is called the latent heat. Conversely, while transforming
from phase 2 to phase 1,.L < 0, i.e. latent heat is released. Hence, for example, heat
is absorbed when liquid changes to gas, and is released in the reverse process.
11.3.4 Clapeyron–Clausius Equation
The Clapeyron–Clausius equation expresses slope of the .P − T coexistence curve
in terms of the latent heat, and the difference in the specific volumes of the substance
in two phases. It enables the determination of change in transition temperature due
to the change in pressure in terms of the said measurable quantities. Referring to
Fig. 11.4, let.A1 and.A2 be the points at.(T, P) on the.P − T coexistence curve, one
on its phase 1 side, and the other on the side of the phase 2. Similarly, let.B1 and.B2
be the points at.(T + dT, P + dP) on its two sides. Due to (11.1), we have
.μA1 (P, T ) = μA2 (P, T ),
μB1 (P + dP, T + dT ) = μB2 (P + dP, T + dT ). (11.22)
Fig. 11.4 Plot for deriving
Clapeyron–Clausius
equation
Phase
Phase306 11 Phase Transitions and Critical Phenomena
On subtracting the two equations above, we obtain
.dμA1 (P, T ) = dμA2 (P, T ). (11.23)
Invoking Gibbs–Duhem relation this leads to
. − s1dT + v1dP = −s2dT + v2dP. (11.24)
This relates the slope of the .P − T curve with the change in entropy of the two
phases:
.s2 − s1 = (v2 − v1)
 dP
dT
 
coex
. (11.25)
On substituting in this the expression (11.21) relating change in entropy with the
latent heat follows the Clapeyron–Clausius equation
.
 dP
dT
 
coex
= L
T (v2 − v1)
. (11.26)
This relates latent heat to the change in pressure and transition temperature of the two
coexisting phases. In particular, if phase.2 is gas, and phase.1 is liquid then, as argued
circa (11.21), latent heat is positive, and so is.v2 − v1 because the specific volume
of gas is always greater than that of the liquid. Hence,.dP/dT > 0. This means the
transition temperature from liquid to gas will increase as pressure increases.
11.4 Critical Phenomenon
Fig. 11.5 depicts some .P − v isotherms. An isotherm for .T > Tc describes single
homogeneous state. It is therefore a continuous curve each point of which is a point
of stable equilibrium conforming to the stability requirement.(∂ P/∂v)T < 0. On the
other hand, a part of an isotherm for.T < Tc lies in one phase and the other in the
other phase. As an example, consider the isotherm in the Fig. 11.5 for temperature
.T1 < Tc. Its part in phase 1 meets the coexistence curve at the point .A, and that in
phase 2 meets the coexistence curve at.B. The said points are at same pressure and
temperature but have different specific volumes, .v1 and and .v2, respectively. Since
the points.A and.B are on the stable parts of isotherms describing one homogeneous
system or the other,.(∂ P/∂v)T < 0 at.A as well as at.B. The part of the isotherm at
.A should therefore continue to fall for.v ≥ vA, and that at.B should continue to rise
for.v ≤ vB. Since the points.A and.B to be joined by the isotherm have same value
of.P, the falling part of the isotherm inside the region of coexistence should reach a
minimum, and the rising one a maximum to enable them to join continuously. Let.A1
and.B1 in the figure be the points where.(∂ P/∂v)T = 0. The isotherm has minimum11.4 Critical Phenomenon 307
Fig. 11.5 P-v isotherms,
coexistence curve (solid),
and spinodal curve (dashed)
A B
A1
B1
C
at.A1 and the maximum at.B1. A part of the dashed curve in Fig. 11.5 joins the points
of minima, and the other joins the points of maxima of different isotherms. The two
meet at the critical point, marked .C in the figure, which is at the maximum of the
coexistence curve. The dashed curve is called the spinodal curve. We examine the
stability of the system on the spinodal curve on which, by construction,
.
 ∂ P
∂v 
T
= 0, on spinodal curve. (11.27)
Note that, since.C is the point of maximum of the spinodal curve,
.
 ∂2P
∂v2
 
T
= 0, at C. (11.28)
To examine stability, we first choose an appropriate thermodynamic potential to
describe the system. Since the control parameters presently are temperature and
pressure, we look upon the system as interacting with the heat reservoir at temperature
.T0, and the pressure reservoir at pressure .P0. As shown in Sect. 2.13.2, the state of
equilibrium of the system in this case is the one at which.G0 attains minimum value.
It has been shown therein that, at equilibrium, the temperature and pressure of the
system attain the same values as those of the respective reservoirs, and that the
equilibrium state is stable if.δ2G0 > 0 where .δ2G0 is second-order variation in .G0
given, to second order in the variation in .V, T by (2.217). Since we are interested
in the condition of stability as we move along an isotherm the stability condition
(2.217) when.δT = 0 reads
. −
 ∂ P
∂V
 
T
(δV)
2 > 0. (11.29)308 11 Phase Transitions and Critical Phenomena
Since our interest is in the stability at the points where .∂ P/∂V = 0, the condition
above is not satisfied at the said points. We therefore need to examine the higher order
terms. The next higher terms, namely the terms of order.(δV)3, and.(δV)4 have been
evaluated in (2.219) under the conditions.∂ P/∂V = 0, and .δT = 0 leading to the
following stability criterion:
.
 1
3!
 ∂2P
∂V2
 
T
+
1
4!
 ∂3P
∂V3
 
T
(δV)
 
(δV)
3 < 0. (11.30)
The sign of the first term on the left side in the inequality above depends on the sign
of.δV and hence it can not be satisfied except when the condition
.
 ∂2P
∂V2
 
T
= 0, (11.31)
also holds in which case (11.30) reduces to
.
 ∂3P
∂V3
 
T
(δV)
4 < 0, (11.32)
which is independent of the sign of.δV. The point where, along with .∂ P/∂V = 0,
(11.31) holds is the critical point, which is point .C in Fig. 11.5. It is the point of
inflexion of the isotherm corresponding to the critical temperature .Tc. It follows
from (11.32) that the critical point will be stable if
.
 ∂3P
∂V3
 
T
< 0. (11.33)
To summarize: the critical point is characterized by following conditions:
.
 ∂ P
∂V
 
T
= 0,
 ∂2P
∂V2
 
T
= 0,
 ∂3P
∂V3
 
T
< 0, at T = Tc, V = Vc.
(11.34)
Using the conditions above we examine the behavior of the thermodynamic quantities
in the vicinity of the critical point.
11.4.1 Critical Exponents
To examine the behavior of the system in the vicinity of the critical point, we define
the scaled variables.τ, η, p corresponding to.T, v, P by the relations11.4 Critical Phenomenon 309
.τ = T − Tc
Tc
, η = v − vc
vc
, p = P − Pc
Pc
, (11.35)
where.xc denotes the value of.x at the critical point. In terms of the scaled variables,
the equations in (11.34) assume the form:
.
 ∂p
∂η 
τ
= 0,
 ∂2 p
∂η2
 
τ
= 0,
 ∂3 p
∂η3
 
τ
< 0, at τ = 0, η = 0. (11.36)
The critical exponents determine how the value of a thermodynamic quantity varies
in the neighborhood of the critical point. For example, let. f (τ ) be the thermodynamic
quantity expressed as a function of deviation.τ of temperature from its critical value.
Then.λ defined by (see [Stanley])
.λ = Ltτ→0
ln( f (τ ))
ln(τ ) , (11.37)
is called the critical point exponent associated with . f (τ ). The relation (11.37) is
often written as
. f (τ ) ∼ τ λ. (11.38)
The critical point exponents showing dependence of a thermodynamic quantity on
the deviation of a specific volume from that at the critical point is similarly defined
as
. f (η) ∼ ημ. (11.39)
The interest in critical point exponents is due to the fact that they possess certain
universal properties independent of the detailed nature of interaction or the equation
of state.
Some critical exponents of interest in fluids are defined as follows (in the following
.p = 0 except in the last equation):
. cv ∼ τ −α, τ> 0, η = 0,
cv ∼ (−τ )−α 
τ < 0, η = 0
ηg − ηl ∼ (−τ )β , τ< 0,
κT ∼ (τ )−γ , τ> 0, η = 0,
κT ∼ (−τ )−γ 
, τ< 0, η = ηg or η = ηl,
p ∼ ηδ
, τ = 0. (11.40)
In the following, we discuss a simple approach to the theory of critical exponents
(see [Landau and Lifshitz] and [Stanley] for further details).310 11 Phase Transitions and Critical Phenomena
To evaluate the exponents defined above, consider pressure a function of .v, T
and expand it in Taylor series at the critical point.vc, Tc. Retaining the lowest order
contribution, we have
.p(η, τ ) = Aτ − 2Bτ η − (4/3)Cη3
, (11.41)
based on the following rationale: Due to the first two conditions in (11.36), there
is no term in .η and .η2. Retained in (11.41) is the lowest power.η3 of.η. The other
third-order terms, namely.ητ 2 and.τ η2, not retained in writing (11.41) is due to the
assumption that they are smaller than the .τ η term in (11.41), respectively, by the
smallness factors.τ and.η (see [Landau and Lifshitz]). However, in the study of the
equation of state of the van der Waals gas we will see that the term.η2τ ignored within
the same order of approximation, as also the higher order term.η3τ , contribute to the
observables to the same order in powers of.η as does (11.41).
The chosen form of the constants is for later convenience. Next, we determine the
signs of the constants in (11.41). Due to the last relation in (11.36), we must have
.C > 0. (11.42)
Also, the system is homogeneous when.τ > 0; hence, we must have.∂p/∂η < 0 for
all.τ > 0 which implies
.B > 0. (11.43)
We have shown circa (11.58) that
.A > 0. (11.44)
We derive next the expressions for specific energy, and entropy corresponding to
.p(η, τ ) in (11.41).
To evaluate energy, rewrite (2.232) expressing energy in terms of pressure and
temperature in the present notation:
.u(η, τ ) = Pcvc
 
(1 + τ ) ∂p
∂τ 
η
− (p + 1)
 
dη + φ(τ ). (11.45)
It then follows that
.u(η, τ ) = Pcvc
 
(A − 1)η − Bη2 +
Cη4
3
 
+ φ(τ ). (11.46)
To evaluate entropy, recall (2.235) and rewrite it in the present notation:11.4 Critical Phenomenon 311
.s(η, τ ) = Pcvc
Tc
 ∂p
∂τ 
η
dη + ψ(τ ), (11.47)
where, due to (2.236),
.
dφ(τ )
dτ = Tc(1 + τ )
dψ(τ )
dτ . (11.48)
Evaluation of (11.47) yields
.s(η, τ ) = Pcvc
Tc
 
Aη − Bη2 
+ ψ(τ ). (11.49)
The expressions above are for single phase region. The equation of state and other
thermodynamic quantities in the two-phase region are derived next.
1. The equation of state in the region of coexistence corresponding to that in the
single phase region is given by (11.10). In terms of the scaled variables, it reads
.p(η, τ ) = p(ηg,τ) ≡ p(ηl, τ ), (11.50)
where.ηl, ηg are the scaled specific volumes of the two phases in equilibrium: we
have changed the nomenclature of the two phases, labeling the lower density state
as.g in place of.2, and the higher density state .l in place of.1, with .l indicating
the liquid phase and .g the gas phase. Equation (11.50) requires determination
of.ηg, ηl using the conditions (11.12) and (11.14). The condition (11.14) in the
present case reads
.
 B
A
vdP = vcPc
 B
A
(1 + η)d p = vcPc
 B
A
ηd p = 0, (11.51)
where the second equation is due to the fact that the value of.P at the limits of
integration are same. Now, with.p(η, τ ) given by (11.41),
.
 B
A
ηd p =
 ηg
ηl
η
d p
dη
dη = − ηg
ηl
η
 
2Bτ + 4Cη2 
dη = 0. (11.52)
This yields
.(η2
g − η2
l )
 
Bτ + C(η2
g + η2
l )
 
= 0. (11.53)
The second equation resulting from (11.50) is
.(ηg − ηl)
 
Bτ +
2C
3
 
η2
g + η2
l + ηgηl)
 
 
= 0. (11.54)312 11 Phase Transitions and Critical Phenomena
The.ηg = ηl solution of (11.53) is
.ηl = −ηg. (11.55)
This shows that the specific volumes at which phase transition occurs are placed
symmetrically about the critical specific volume .vc. On substituting (11.55) in
(11.54), we obtain
.Bτ +
2C
3 η2
g = 0. (11.56)
This implies
.η2
g = −3B
2C τ, τ < 0, (11.57)
and
.p(ηg,τ) = p(ηl,τ) = Aτ. (11.58)
Note that.τ < 0,.p < 0 in the coexistence region. Hence, for the equation above to
hold, we must have.A > 0. On combining the results above with (11.50) follows
the equation of state in the region of coexistence:
.p(η, τ ) = Aτ. (11.59)
2. If.η is the specific volume in the coexistence region, then the fractions. fg, fl of
the substance in gas and liquid states are given by the lever rule (11.7) which in
terms of the scaled variables reads
. fl = ηg − η
ηg − ηl
, fg = η − ηl
ηg − ηl
. (11.60)
3. Invoking (11.8), energy in the coexistence region for system of total specific
volume.v is given by
.u = flul + fgug, (11.61)
where the fraction. fi of the substance in the.ith phase is given by (11.60),.ul, ug
are given by (11.46), with.η → ηl , and.η → ηg, respectively.
4. Invoking (11.9), entropy in the coexistence region for system of total specific
volume.v is given by
.s = flsl + fgsg, (11.62)11.4 Critical Phenomenon 313
where the fraction. fi of the substance in the .ith phase is given by (11.60),.sl ,.sg
are given by (11.49) with.η → ηl ,.η → ηg, respectively.
The critical exponents may now be evaluated as follows.
1. Let the critical point be approached along the isochore (the path of constant .v)
.η = 0 from above. The internal energy in that case is given by (11.46), and the
specific heat at constant volume.cv at.η = 0 turns out to be given by
.cv ≡
 ∂u
∂T
 
v=vc
= 1
Tc
 ∂u
∂τ 
η=0
= 1
Tc
dφ(τ )
dτ , T > Tc. (11.63)
The behavior of .cv in the vicinity of the critical point is thus determined by
the functional form of.φ(T ). For several gases.φ(T ) ∼ T in which case .cv is a
constant and hence.α = 0.
2. To evaluate .α we compute .cv using the expression (11.61) for energy in the
coexistence region by taking .η = 0 therein. With .ηl = −ηg (see (11.55)), the
expressions in (11.60) for the fractions in the two phases in equilibrium at.τ = 0
reduce to
. fl = fg = 1
2
. (11.64)
Equation (11.61) for energy then reads
.u = (ul + ug)/2. (11.65)
Evaluation of.ul, ug using (11.46) with .η → ηl , .η → ηg, respectively, and also
the relations (11.55), and (11.57) yields
.u = 3B2Pcvc
2C
 
τ +
1
2
τ 2
 
+ φ(τ ). (11.66)
Hence
.cv = 1
Tc
 3B2Pcvc
2C (1 + τ ) +
dφ(τ )
dτ
 
, T < Tc. (11.67)
On comparing this with the expression (11.63) for.cv for.τ > 0, we see that .cv
exhibits finite jump at.τ = 0. If.φ(T ) ∼ T , then the expression above shows that
.α = 0.
We will see that the equation of state of van der Waals gas can be approximated
by the form in (11.41) in which .A, B,C are given by (12.69). We will also
investigate its critical properties in higher order approximation. The .cv in the
coexistence region, obtained in higher order approximation, will be shown to
agree with the expression (11.67) of .cv only up to the terms of order .τ 0. This314 11 Phase Transitions and Critical Phenomena
suggests that contribution to the linear terms in .τ in .cv arises also from some
higher order terms ignored in approximating.p(η, τ ) by (11.41).
3. Evaluation of .β, defined in (11.40), requires determination of .ηg − ηl . In the
present case, recalling (11.55) and (11.57),
.ηg − ηl = 2ηg = 2
 3B
2C
√−τ. (11.68)
This shows that.β = 1/2.
4. To determine.γ , we have
.κT = −1
v
 ∂v
∂ P
 
T
= − 1
Pc(1 + η) ∂η
∂p
 
τ
. (11.69)
Using (11.41), we get
.
 ∂η
∂p
 
τ
= − 1
2Bτ + 4Cη2 . (11.70)
On substituting this in (11.69), it follows that, at the critical point.η = 0,
.κT = 1
2B Pc
(τ )−1
, T > Tc. (11.71)
Hence .γ = 1. This shows that .κT diverges at the critical point when it is
approached from its higher temperature side.
5. To find.γ 
, we need to evaluate (11.69) at.η = ηg. With.(∂η/∂p)τ given by (11.70)
we have at.η = ηg,
.
 ∂η
∂p
 
τ
= 1
4Bτ
, (11.72)
where (11.57) has been used. Substitution of this in (11.69) yields
.κT = 1
4B Pc(1 + ηg)
(−τ )−1
, τ< 0. (11.73)
This shows that .γ = 1 i.e. .κT diverges at the critical point also when it is
approached from its lower temperature side.
Furthermore, since.ηg → 0 as.τ → 0, we see that
.
κT (T > Tc)
κT (T < Tc) = 2. (11.74)11.4 Critical Phenomenon 315
6. To evaluate.δ, note from (11.41) that, at the critical point.τ = 0,
.p = −4C
3 η3
. (11.75)
This shows that.δ = 3.
The theory of critical exponents discussed above is independent of any particu￾lar equation of state. In Chap. 12, we will evaluate those exponents for the system
described by van der Waals equation and show that they are same as the ones obtained
above.
The values of the critical exponents derived above are not in agreement with their
observed values. The reason behind that failure can be understood best in the frame￾work of statistical mechanics. To that end, recall (6.77) which relates fluctuations in
the number of particles,. N/N, with the isothermal compressibility.κT . As shown in
equations (11.71) and (11.73),.κT diverges at the critical point which means there are
infinitely large fluctuations in the particle number. We know that the thermodynamic
quantities are averages over statistical mechanical probability distributions. The ther￾modynamic relations, including the equations of state are the relations between the
averages. They hold as long as the number fluctuations are negligibly small. Since
the number fluctuations are infinitely large at the critical point, the applicability of
the equations of state, including that of (11.41) on which the theory of critical phe￾nomena outlined above is based, is questionable. The failure of the theory above of
critical indices is therefore not surprising. The theory which describes the critical
phenomena accurately is the renormalization group theory due to K. G. Wilson for
which he was awarded the Nobel Prize in 1982. Its discussion is beyond the scope
of this book.Chapter 12 
Interacting Classical Gas 
The assumption that the molecules of a gas do not interact though models a number 
of systems, there are situations of practical interest which the assumption in question 
leaves out. For example, the phenomenon of phase transition, discussed in Chap. 11, 
can not be explained by the equation of state of a non-interacting gas. In this chapter, 
we introduce a systematic way of treating interaction between molecules of a classical 
gas by expressing its equation of state as an expansion in terms of its number density. 
We restrict our attention to terms up to second order in the number density. The first￾order terms describe the familiar ideal gas. The equation of state obtained by keeping 
terms up to second order in the number density turns out to be the van der Waals 
equation. We will see how that equation captures the essence of the gas–liquid phase 
transition. 
12.1 Virial Expansion 
Consider a gas of.N atoms contained in the volume.V at temperature. T . The expres￾sion of pressure.P as an expansion in powers of.N/V in the form 
.P = N kBT
V
{
1 +
N
V
B2(T ) +
( N
V
)2
B3(T ) +···}
, (12.1) 
is known as the virial expansion. The temperature-dependent coefficient .Bi(T ) is 
known as the.ith virial coefficients. The first term in the expansion gives the equation 
of state of an ideal gas. The virial expansion is the expansion in powers of the number 
density. For small densities, the lowest order correction to the ideal gas equation is 
obtained by ignoring the.B3(T ) and higher coefficient terms so that 
.P = N kBT
V
(
1 +
N
V
B2(T )
)
. (12.2) 
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4_12 
317318 12 Interacting Classical Gas
At the temperature .TB at which .B2(T ) = 0 the equation above reduces to the ideal 
gas equation. It is called the Boyle temperature: 
.B2(TB) = 0, TB: Boyle temperature. (12.3) 
Statistical mechanics determines the virial coefficients in terms of the microscopic 
interaction between the atoms. In the following, we outline a formal approach to 
seek that end. 
To obtain the virial expansion, recall that the partition function of a classical gas of 
.N particles is given by (7.5) in which.V(r) is the potential energy of the particles. We 
assume that the inter-particle potential .V({ri}N ) is a function only of the distances 
between the atoms expressible in the form 
.V({ri}N ) = ∑
N
i< j=1
V(|ri − r j|) ≡ ∑
N
i< j=1
Vi j, Vi j ≡ V(|ri − r j|). (12.4) 
Substitution of the equation above in (7.5) yields 
.ln(ZN ) − ln(ZN F ) = ln
⎛
⎝
1
V N
∫ ⊓
N
i< j=1
exp (
−βVi j )
d3N r
⎞
⎠ , (12.5) 
where .ZN F stands for the free particle partition function given in (7.18). Introduce 
the so-called Meyer function 
. fi j = exp (
−βVi j )
− 1, (12.6) 
to rewrite (12.5) as 
.ln(ZN ) − ln(ZN F ) = ln ⟨ ⊓
N
i< j=1
(1 + fi j)
⟩
, (12.7) 
where.⟨A(r)⟩ denotes the average of.A(r) defined by 
.⟨A(r)⟩ =
1
V N
∫
A(r) d3N r. (12.8) 
Clearly, if. c is a constant then.⟨c⟩ = c. Write (12.7) in the form 
.
⟨ ⊓
N
i< j=1
(1 + fi j)
⟩
= 1 +
⟨ ∑
N
i< j=1
fi j⟩
+ x, (12.9)12.1 Virial Expansion 319
where. x represents the average over products of the. f '
i js: 
.x =
⟨∑
i< j
∑
k<l
fi j fkl +∑
i< j
∑
k<l
∑
m<n
fi j fkl fmn +···⟩
. (12.10) 
Using (12.9) rewrite (12.7) as 
.ln(ZN ) − ln(ZN F ) = ln(
1 +
⟨ ∑
N
i< j=1
fi j⟩
+ x
)
. (12.11) 
We assume that the interaction between atoms is very weak and is effective only 
when two atoms come very close to each other and that.Vi j → 0 as.|ri − r j|→∞. 
As a consequence, we see that . fi j → 0 as .|ri − r j|→∞. Furthermore, the gas is 
assumed to be of so low density that not more than two atoms at a time are close 
enough for effective interaction. The contribution of the products of . fi j terms is 
consequently small compared with the single . fi j term in (12.11). We therefore use 
the expansion.ln(1 + y) = y − y2/2 +··· and ignore the terms involving products 
of the. f '
i js to arrive at the following approximate form of (12.11): 
. ln(ZN ) − ln(ZN F ) =
⟨ ∑
N
i< j=1
fi j⟩
= 1
V N
∑
N
i< j=1
∫ {
exp(−βVi j) − 1
} ⊓
i
d3
ri . (12.12) 
Since .Vi j depends only on the positions .ri and . r j , we can separate the integration 
over the positions. ri and.r j of the pair of atoms at. ri and.r j from the rest to write 
.
⊓
k
d3
rk = d3
rid3
rj
⊓
k/=i,j
d3
rk . (12.13) 
Furthermore, since .Vi j depends only on .|ri − r j| and the positions are variables of 
integration, the integral (12.12) is same for all pairs of atoms. The summation over 
.i, j in (12.12) is therefore over all possible pairs. There being.N atoms, the number of 
independent pairs that can be formed, assuming.N >> 1, are.N(N − 1)/2 ≈ N2/2. 
Hence (12.12) assumes the form 
. ln(ZN ) − ln(ZN F )
= N2
2 V N
∫ {
exp(−βV(|ri − r j|)) − 1
}
d3
rid3
r j
⊓
k/=i,j
d3
rk
= N2
2 V2
∫ {
exp(−βV(|ri − r j|)) − 1
}
d3
rid3
r j, (12.14)320 12 Interacting Classical Gas
where in writing the last line we have used the fact that the product over . k /= i, j
excludes two positions. ri and.r j leaving integration over remaining.N − 2 positions 
as a result of which 
.
∫ ⊓
k/=i,j
d3
rk = V N−2
. (12.15) 
To evaluate the remaining integral in (12.14), transform.(ri, r j)to the relative and cen￾ter of mass coordinates.(r, R) with.r = ri − r j ,.R = (ri + r j)/2 to rewrite (12.14) 
as 
.ln(ZN ) − ln(ZN F ) = N2
2 V2
∫ {
exp(−βV(r)) − 1
}
d3
rd3
R. (12.16) 
The integration over. R gives.V so that 
.ln(ZN ) − ln(ZN F ) = − N2
V
B2(T ), (12.17) 
where.B2(T ) is the second virial coefficient: 
.B2(T ) = 2π
∫ ∞
0
{
1 − exp(−βV(r))}
r 2
dr. (12.18) 
That.B2(T ) defined above is the second virial coefficient may be ascertained by dif￾ferentiating (12.17) with respect to. V keeping. T constant and recalling the expression 
(6.39) for pressure and (7.18) for .ZN F to get (12.2) confirming thereby that . B2(T )
in (12.18) is indeed the second virial coefficient. We have thus obtained the expres￾sion for the second virial coefficient in terms of the interaction potential between the 
atoms when the gas is sufficiently rare. The higher order contributions are obtained 
by the method of so-called cluster expansion discussion of which is beyond the scope 
of this book (see [Landau and Lifshitz], [Huang], [Pathria]). 
The detailed functional form of.B2(T ) depends, of course, on the functional form 
of.V(r). However, certain characteristic features of.V(r) are: to prevent collapse of 
atoms in to each other, the interaction should be repulsive at short separation between 
atoms, going to infinity as.r → 0. The interaction is attractive after certain distance 
between atoms, going to zero as their separation increases and has a minimum at the 
stable equilibrium separation of the atoms. A typical form of .V(r) is shown in the 
Fig. 12.1. 
For.V(r) depicted in Fig. 12.1, we rewrite.B2(T ) in (12.18) as 
.B2(T ) = 2π
(∫ d
0
+
∫ ∞
d
){
1 − exp(−βV(r))}
r 2
dr. (12.19)12.1 Virial Expansion 321
Fig. 12.1 Typical 
inter-atomic potential 
If temperature is high such that.β|V(r)| << 1 for.r > d, the integrand in the second 
integral above is close to zero. The dominant contribution to.B2(T ) then comes from 
the first integral which is positive due to the fact that .V(r) > 0 for .r < d. Hence, 
.B2(T ) > 0 at high temperatures. On the other hand, if. T is small then.βV(r) is large 
and positive for.r < d but large and negative for.r > d. The dominant contribution 
to .B2(T ) in this case therefore comes from the second integral in (12.19) which is 
negative. Hence .B2(T ) < 0 at low temperatures. Since .B2(T ) changes sign as . T
varies from low to high values, .B2(TB) = 0 for some temperature .TB. This shows 
that the gas has a Boyle temperature as defined in (12.3). 
As regards explicit functional forms of potentials, a widely used inter-atomic 
potential is the so-called Lennard–Jones potential: 
.V(r) = 4V0
[(d
r
)12
−
(d
r
)6
]
. (12.20) 
The properties of .B2(T ) as a function of .T for different choices of the parameters 
.d, V0 have been studied in the literature. 
Widely used also is the simpler form of.V(r), the hardcore potential depicted in 
Fig. 12.2: 
.V(r) = ∞, r ≤ d, V(r) = −U(r), r ≥ d, (12.21) 
where.U(r) ≥ 0 and approaches zero as.r → ∞. The. d is the distance of the closest 
approach of atoms. 
On using this in (12.19), we get 
.B2(T ) = b − 2π
∫ ∞
d
{
exp(βU(r)) − 1
}
r 2
dr, (12.22) 
.b = 2πd3
3 . (12.23)322 12 Interacting Classical Gas
Fig. 12.2 Hardcore 
potential (12.21) 
We evaluate .B2(T ) making further assumptions about .U(r) leading to the van der 
Waals equation of state. 
12.2 Van der Waals Equation of State 
Assuming .U(r)β << 1, expand the exponential in (12.22) to first order in .U(r) to 
obtain 
.B(T ) = b − 2πβ ∫ ∞
d
U(r)r 2
dr. (12.24) 
Assuming the integral in the equation above is finite: 
.
∫ ∞
d
U(r)r 2
dr = a
2π , (12.25) 
we get 
.B2(T ) = b − βa. (12.26) 
Equation (12.17) then reads 
.ln(ZN ) − ln(ZN F ) = N2
V (−b + aβ). (12.27) 
The parameter . b may be related with the volume occupied by a molecule. For, 
if we think of the molecules as hard spheres of radii . r0, then the distance of the 
closest approach between two molecules, denoted in the definition (12.21) of the 
intermolecular potential by . d, would be .d = 2r0. In terms of . r0, . b in (12.23) is 
.b = 16πr 3
0 /3 which is four times the volume occupied by a molecule which is known 
to be the average excluded volume per molecule in the gas of a large number of 
molecules.12.2 Van der Waals Equation of State 323
We could ignore the contribution from the products of the. fi j under the assumption 
that the gas is sufficiently rare. It means the volume per atom.V/N is much larger than 
the molecular volume .∼ b, i.e. .N b/V << 1 so that the approximation . −N b/V ≈
ln(1 − N b/V ) holds enabling us to rewrite (12.27) as 
.ln(ZN ) − ln(ZN F ) = Nln(1 − N b/V ) +
N2
V βa. (12.28) 
In terms of the specific volume.v = V/N, this reads 
.ln(ZN ) − ln(ZN F ) = N
[
ln(v − b) − ln(v) + aβ
v
]
. (12.29) 
This is the canonical partition function.ZN for an interacting gas under the approx￾imations detailed while arriving at it. Since, as we will show, this leads to the van 
der Waals equation of state, we call it the partition function for the van der Waals 
gas. Using .ZN F the expression (7.18) for the .N-particle partition function for a 
non-interacting gas, along with the use of Stirling’s approximation, (12.29) reads 
.ln(ZN ) = N
[
ln(v − b) − 3
2
ln(β) + aβ
v − 3
2
ln(w) + 1
]
, (12.30) 
where 
.w = h2
2πm . (12.31) 
The parameter. a, defined by (12.25), depends on the specific form of.U(r). A form 
of.U(r) often used is the van der Waals potential: 
.U(r) = U0
(r0
r
)6
. (12.32) 
The.−U(r) is the attractive dipole interaction potential between neutral atoms. The 
hardcore potential (12.21) with .U(r) given by (12.32) is also called the Sutherland 
potential. 
We study next the thermodynamics of the system using the expression (12.30) for 
.ZN . 
1. Using (6.39) with.ZN given by (12.29), the equation of state turns out to be given 
by 
.P = kBT
v − b − a
v2 , v ≥ b. (12.33)324 12 Interacting Classical Gas
This is the van der Waals equation for a non-ideal gas derived here from first 
principles. A phenomenological derivation of this equation has been outlined in 
Sect. 1.6. 
2. The expression for specific energy reads 
.u = 3
2
kBT − a
v
. (12.34) 
This reduces to the ideal gas equation, as it must, when.a = 0, i.e. when there is 
no interaction. 
Recall that, starting from van der Waals equation of state, we derived in (2.258) 
the expression for energy using thermodynamic relations. That equation has in it 
the unknown function .Φ(T ) which can not be determined by thermodynamics. 
We, however, could deduce it by demanding that the limit in which van der Waals 
gas reduces to the ideal gas, so should its specific heat. We see that the result 
so arrived at in (2.259) is in agreement with (12.34) which is an outcome of the 
microscopic theory. 
3. The expression for specific entropy is 
. s = kB
N (βU + ln(ZN ))
= kB
[
ln(v − b) − 3
2
ln(β) − 3
2
ln(w) +
5
2
]
. (12.35) 
4. The specific Gibbs potential, which is same as the chemical potential, is 
. μ = G(P, T )/N = −kBT
N
ln(ZN ) + Pv
= kBT
[ v
v − b − ln(v − b) +
3
2
ln(β) +
3
2
ln(w) − 1
]
− 2a
v , (12.36) 
where (6.114) has been recalled to express.G(P, T ) in terms of.ZN . 
Next, we study consequences of the equation of state (12.33). See also [ 1]. 
12.3 Critical Point 
Recall from Sect. 11.4 that the point .vc, Pc on the isotherm corresponding to tem￾perature.Tc which is such that 
.(∂P/∂v)Tc = (∂2P/∂v2
)Tc = 0, (12.37)12.3 Critical Point 325
is called the critical point. The temperature for which the equations above hold is 
called the critical temperature . Tc. We know that there is no such point for an ideal 
gas. We show that the critical point exists for the van der Waals equation of state. 
To that end, use the equation of state (12.33) to evaluate the derivatives in the two 
equations in (12.37) to get 
.
∂P
∂v = − kBT
(v − b)2 +
2a
v3 = 0, ∂2P
∂v2 = 2kBT
(v − b)3 − 6a
v4 = 0. (12.38) 
It is straightforward to solve the equations above. Let the solution be denoted by 
.(vc, Tc), which on substitution in (12.33) determines.Pc resulting in the expressions: 
.Tc = 8
27
a
kBb
, vc = 3b, Pc = a
27b2 . (12.39) 
It may be verified that 
.Z ≡ Pcvc
kBTc
= 3
8
. (12.40) 
The .Z is known as the compression parameter. We see that, according to van der 
Waals model, .Z has same value for all gases. However, the experimental values of 
.Z are somewhat lower than the predicted value .3/8 and not same for all gases (see 
[Stanley] for tabulated values of. Z for various gases). 
The critical values depend on the parameters .(a, b) which are different for dif￾ferent systems. We show below that the equation of state assumes the form which is 
independent of system-specific parameters.(a, b) if written in terms of the quantities 
scaled by respective critical values. 
12.3.1 Law of Corresponding States 
Define.(P
~,~v, T
~) by the relations 
.P
~ = P
Pc
, ~v = v
vc
, T
~ = T
Tc
, (12.41) 
where.(Tc, vc, Pc) are as in (12.39). On using (12.41) and (12.39) the van der Waals 
equation (12.33) assumes the form 
.P
~ = 8
3
T
~
~v − 1/3 − 3
~v2 , v˜ ≥ 1/3. (12.42)326 12 Interacting Classical Gas
The equation of state above, written in terms of the scaled variables, has no material￾specific parameter. It is known as the law of corresponding states. 
Exercises 
Ex. 12.1. In terms of the reduced variables defined in (12.41) show that the partition 
function.ZN and energy assume the forms: 
.ln(ZN ) = N
[
ln(3v˜ − 1) +
3
2
ln(T˜) +
9
8
1
v˜T˜ + C
]
, (12.43) 
where 
.C = ln(vc/3) +
3
2
ln(kBTc) − 3
2
ln(w) + 1, (12.44) 
.u = 3kBTc
2
(
− 3
4v˜ + T˜
)
. (12.45) 
12.4 .P − v Isotherms 
Some isotherms in the.P − v plane obeying the van der Waals equation (12.33) are 
displayed in Fig. 12.3. Note that the isotherms for temperatures .T > Tc are mono￾tonically decreasing functions of . v, whereas each isotherm for .T < Tc exhibits a 
minimum and a maximum. The isotherm corresponding to .T = Tc has a point of 
inflexion at .(vc, Pc). In the following, we extract the said features of the isotherms 
from the equation of state. 
To that end, it is convenient to work with the scaled form (12.42) of the equation 
of state, rewritten in terms of the variable. x related with. ~v by 
.x = ~v − 1/3, x ≥ 0, (12.46) 
where the condition on . x is due to that on . v˜ (see (12.42)). The equation of state 
(12.42) then reads 
.P
~ = 8
3
T
~
x − 3
(x + 1/3)2 . (12.47)12.4 P − v Isotherms 327
Fig. 12.3 .P − v isotherms 
obeying van der Waals 
equation 
For a fixed. T
~, position of the extrema of a.P − v curve is determined by the roots of 
.dP
~/dx = 0 which is the cubic equation 
.x 3 + (1 − α)x 2 + x
3 +
1
27 = 0, (12.48) 
where 
.α = 9
4T
~. (12.49) 
Let the roots of (12.48) be.x1, x2, x3. The roots have the following properties: 
1. We know that, if. z is a root of a real polynomial then so is. z∗. It implies that, since 
(12.48) is real, either.x1, x2, x3 are all real or one of them is real and the other two 
complex conjugate of each other. 
2. The roots obey the following relations, 
. x1 + x2 + x3 = −coefficient of x 2 = α − 1,
x1(x2 + x3) + x2x3 = coefficient of x = 1
3
x1x2x3 = −coefficient of x 0 = − 1
27. (12.50) 
The formulas for finding the roots of a cubic are summarized in the Appendix E. We 
use the results presented therein to find the roots of (12.48). 
1. Comparing (12.48) with the standard form (E.1) of the cubic we have 
.a2 = 1 − α ≡ 1 − 9
4T
~, a1 = 1
3
, a0 = 1
27. (12.51)328 12 Interacting Classical Gas
Hence the parameters. p and. q, defined in (E.2), are 
.p = a1 − 1
3
a2
2 = α
3
(2 − α), (12.52) 
and 
. q = a0 − 1
3
a1a2 +
2
27a3
2
= − α
27(2α2 − 6α + 3). (12.53) 
2. On substituting the expressions (12.52), (12.53) for.p, q in the definition (E.4) of 
the discriminant. Δ, which determines the nature of the roots, 
.Δ = 1
4
q2 +
1
27 p3
, (12.54) 
we get 
.Δ = α2
12 (
1 − 1
T
~
)
= 27
64T
~2
(
1 − 1
T
~
)
. (12.55) 
Recall from the Appendix E that 
. Δ < 0 =⇒ roots are real
Δ = 0 =⇒ roots are real, two roots being equal
Δ > 0 =⇒ one root is real and other two are complex conjugate pair.
We discuss the question of locating roots for each of the cases above separately. 
.Δ = 0:. Critical Temperature Isotherm
With.Δ given by (12.55), we see that 
.Δ = 0 when T
~ = 1 =⇒ T = Tc. (12.56) 
Hence .α ≡ 9/(4T˜) = 9/4, which on substitution in (12.51), (12.52) and (12.53) 
gives 
.a2 − 5
4
, p = − 3
16, q = 1
32 . (12.57) 
To evaluate the roots, we compute first the quantities.A, B defined in (E.3): 
.A = B ≡ −q
2 = − 1
64. (12.58)12.4 P − v Isotherms 329
The roots, found using (E.5) are given by 
. x1 = 2A1/3 − 1
3
a2 = − 1
12
x2 = x3 = −A1/3 − 1
3
a2 = 2
3 (12.59) 
The root . x1, being negative, falls outside the acceptable values of . x which must be 
positive. Since.x = ~v − 1/3, it follows that the roots.x2, x3 correspond to.~v = 1, i.e. 
.v = vc. 
We see that one of the roots is negative and the other two are positive and equal 
to each other, located at .v = vc. This implies, since the admissible values of . x are 
positive, the.P − v isotherm corresponding to temperature.T = Tc has. ∂P/∂v = 0
only at.v = vc. The said root being a repeated root, implies.∂2P/∂v2 = 0 at.v = vc. 
Thus, the.P − v isotherm corresponding to temperature.T = Tc must have point of 
inflexion at.v = vc. This explains the behavior of the isotherm at.T = Tc in Fig. 12.3. 
. Δ > 0 : T > Tc
The expression (12.55) shows that .Δ > 0 if .T
~ > 1, i.e. if .T > Tc. As discussed 
in the Appendix E, for .Δ > 0, one of the roots, say . x1, is real and the others are 
complex conjugate of each other. The expression in (12.50) for the product of the roots 
shows that.x1x2x3 = −1/27 < 0 which, due to.x3 = x∗
2 , means. x1|x2|
2 = −1/27 <
0, i.e. the real root is negative which is unphysical. Thus none of the three roots is 
physically acceptable. Consequently the .P − v plot is expected to be monotonic. 
This is consistent with the .P − v isotherms for temperatures .T > Tc depicted in 
Fig. 12.3. 
. Δ < 0 : T < Tc
Equation (12.55) shows that.Δ < 0 if.T
~ < 1, i.e. if.T < Tc . Since.Δ < 0, the roots 
are all real. Due to (12.50), .x1x2x3 = −1/27 < 0. Hence at least one of the roots, 
say . x1, is negative and the roots .x2, x3 can either be both positive or both negative. 
Being negative,.x1 is unphysical. Furthermore, since.T
~ < 1,.α − 1 = 9/4T
~ − 1 > 0. 
It therefore follows from (12.50) that the sum of the roots is positive. Hence all 
the roots can not be negative implying thereby that, since .x1 < 0, we must have 
.x2, x3 > 0. 
We thus see that the .P − v isotherms corresponding to .T < Tc have extrema at 
physically acceptable positions .x2, x3. Now, from the expression (12.47) for .P
~ as 
a function of . x we see that (i) .P
~ is a continuous function of . x, (ii) .P
~ → ∞ as 
.x → 0+, (iii).P
~ → 0 as.x → ∞. Hence, one of the extrema should be a minimum 
and the other a maximum. Consequently the .P − v isotherms for .T < Tc should 
be as shown in the Fig. 12.3. In Sect. 12.5 we discuss how these isotherms predict 
gas–liquid transition.330 12 Interacting Classical Gas
12.5 Gas–Liquid Transition 
We know that the ideal gas equation does not predict the familiar phenomenon of 
phase transition. We will show that it is predicted by the van der Waals equation 
even though it is derived assuming smallness of the molecular density, a condition 
not satisfied by the liquid state. 
The expectation that the van der Waals equation can predict phase transition is 
supported by the fact that the .P − v isotherms of van der Waals gas in Fig. 12.3 
are qualitatively the same as those in Fig. 11.5. The van der Waals gas serves as a 
microscopic model for the thermodynamics of phase transition. Since the van der 
Waals model is not universal, the quantitative results derived from it too are limited 
in their scope. 
To understand the phenomenon of phase transition predicted by the van der Waals 
model, refer to Fig. 12.3. We see that.dP/dv < 0 on the isotherms for.T > Tc. This 
behavior is analogous to that exhibited by an ideal gas and is consistent with the 
principles of thermodynamics. 
On the other hand, the isotherms for.T < Tc exhibit a minimum and a maximum. 
One such isotherm is drawn in Fig. 12.4. The parts .AC and .EG in it exhibit physi￾cally acceptable variation of pressure with volume, namely, .dP/dv < 0. However, 
.d p/dv > 0 on the segment.C E which is an unacceptable behavior and hence system 
can not be stable in the states lying on the said segment. The segment.C E is therefore 
said to be an unstable branch of the.P − v isotherm. 
We see that, for .P such that .PC < P < PA (.PX denotes pressure at the point . X
on the .P − v diagram), there are three values of . v on the same .T < Tc isotherm, 
one on the unstable branch .C E and the other two on the stable branches .AC and 
.EG. This is illustrated in Fig. 12.4 in which the points. B,. D,. F on the same isotherm 
Fig. 12.4 Maxwell construction12.5 Gas–Liquid Transition 331
are at the same pressure .PB. The three values of the specific volume solving van 
der Waals equation for the pressure.PB are:.vD corresponding to the point.D on the 
unstable branch .C E; .vB and .vF corresponding to the points .B and .F on the two 
stable branches.AC and.EG. Since the point.D is on the unstable branch, the stable 
equilibrium states of the system at pressure .PB correspond to the points .B and . F. 
We can therefore say that the system separates in to two homogeneous components 
or phases, one having specific volume .vB and the other .vF (.vX denotes specific 
volume at the point. X on the.P − v diagram). However, the two phases can not be at 
equilibrium with each other at all such pairs of points as it would mean that the two 
phases can coexist at any.PB lying in.(PC, PA) for a given. T which is absurd. There 
can be only one value of pressure for a given. T at which the two phases can coexist. 
To find the said pressure, we recall that the coexistence of the phases requires not 
only equality of pressure and temperature, but that of their chemical potentials too. 
Hence only such pairs of points .B, F can be in equilibrium at which the chemical 
potential is same. 
To locate the pair of points at which the chemical potential is same, referring to 
Fig. 12.4, assume that the pair of points .(B, F) on it is the pair in thermodynamic 
equilibrium. The equality of chemical potentials at such two points has been shown 
to lead to the equation (11.14) determining the specific volumes in equilibrium. We 
outline a graphical method of solving that equation. 
The condition (11.14) of thermodynamic equilibrium in the present case between 
the coexisting phases at. B and.F reads 
.
∫ vF
vB
v
dP
dv
dv = 0. (12.60) 
The integration is to be carried along the isotherm on which the points lie, including 
its unstable part. In the present case it is along the curve .BCDEF. The equation 
above can be solved graphically by noting that it implies equality of areas of the two 
shaded regions in the plot. To see that, carry the integration in (12.60) by parts to get 
(.PF = PB) 
. ∫ vF
vB
v
dP
dv
dv = vP
|
|
|
F
B −
∫ vF
vB
Pdv = PB(vF − vB) −
∫ vF
vB
Pdv
=
[
PB(vD − vB) −
∫ vD
vB
Pdv
]
+
[
PB(vF − vD) −
∫ vF
vD
Pdv
]
= 0.
(12.61) 
Hence 
.PB(vD − vB) −
∫ vD
vB
Pdv =
∫ vF
vD
Pdv − PB(vF − vD). (12.62) 
Clearly, the two sides in the equation above are the two shaded areas in Fig. 12.4.332 12 Interacting Classical Gas
Fig. 12.5 The solid curve is 
the coexistence curve and the 
dashed curve is the spinodal 
curve. The region bound by 
the solid curve is the 
coexistence region 
B 
C 
D 
E 
F 
J 
K 
L 
M 
N 
The procedure outlined above to find the pressure at which two phases coexist is 
called Maxwell construction. The pair of points so identified are the ones at which 
the two phases coexist (points .B and .F in Fig. 12.4). They are called the transition 
points. Note that (i) the specific volume.vB at. B on the stable part.AC is closer to the 
distance of closest approach. b between the atoms than the specific volume.vF at the 
point. F at the same pressure. Hence the state of the system represented by the points 
on the segment.AC is relatively dense, (ii) the .∂P/∂v is very steep on the segment 
.AC suggesting that points on the said segment represent the state of the system which 
is not easily compressible. These are the characteristics of a liquid. Hence the points 
on the segment.AC are said to represent the liquid phase. On the other hand, (i) the 
specific volume .vF of the system at the point .F on the segment .EG, at which the 
pressure is same as that at . B, is much higher than .vB, (ii) the .∂P/∂v is relatively 
small suggesting that the system in the said state can be compressed relatively easily. 
These are the characteristics of a gas. The state of the system on the points on the 
segment.EG is therefore said to be gaseous phase. The van der Waals equation thus 
predicts the liquid phase even though it is derived assuming the system to be of low 
density. 
At. F the system is completely in the gaseous state, whereas at. B it is completely in 
the liquid state. We denote by.(vl, vg) the specific volumes, respectively, in the liquid 
and the gas phases in equilibrium with each other. At any other specific volume . v
between the two, the system is a mixture of the liquid and the gas phases. The fractions 
. fl, fg of the phases, respectively, in the liquid and the gas state is given by the lever 
rule: 
. fl = vg − v
vg − vl
, fg = v − vl
vg − vl
. (12.63) 
We can use the Maxwell construction to identify for each isotherm the pair of 
points at which the fluid can coexist in liquid and gas phases. In Fig. 12.5 we have 
drawn a couple of isotherms and joined the pairs of points on each of them corre￾sponding to the coexisting phases by straight lines. The two phases merge in to one12.5 Gas–Liquid Transition 333
at the critical temperature . Tc. We also join the transition points in the liquid phase 
and those in the gas phase by solid curves which meet at the critical point. It is the 
coexistence curve predicted in Sect. 11.1.2 based on thermodynamic considerations. 
The region bound by the curve is the region of coexistence in which the gas and the 
liquid phases coexist. 
Going back to Fig. 12.4 in which points. B and. F constitute the pair in equilibrium, 
note that there is part .BC of the isotherm below the point .B on the liquid side and 
the part .E F above the point .F on the gaseous side on which, in accordance with 
thermodynamics, .P is a monotonically decreasing function of . v. These parts are, 
however, metastable. For, recall that the point .B and . F, respectively, on the parts 
.AC and .EG on the isotherm are the only points of stable equilibrium on the said 
segments. If the liquid is expanded sufficiently slowly near. B, one can go past it. The 
liquid is then said to be superheated. Similarly, one can go past. F if gas is compressed 
sufficiently slowly near it. The gas is then said to be supercooled. As argued above, 
being metastable, the superheated and supercooled states are short lived. 
Join the points of minima of different isotherms (for example points .B and . J
corresponding to .T1 and .T2 in Fig. 12.5), and the points of maxima (for example 
points .E and .M corresponding to .T1 and .T2 in the figure). The curve joining those 
points is shown by the dotted line. It is the spinodal curve predicted based on general 
thermodynamic considerations as well (see Sect. 11.4). 
We thus see that the qualitative features of phase transition of the van der Waals 
gas agree with those predicted based on general thermodynamic considerations. We 
derive next the critical exponents based on the van der Waals equation of state. 
Exercises 
Ex. 12.2. Show that the pressure given by the van der Waals equation of state (12.47) 
is positive for all. T and. v if 
.T >
27
32
Tc. (12.64) 
The pressure can become negative for certain values of .T, v for .T not 
obeying (12.64). Note that negative pressure is predicted for the values of 
. T lower than. Tc. Hence the arguments leading to the identification of the 
parts of the .P − v plot for .T < Tc as metastable hold also for showing 
that the negative pressure part is metastable. Hint: Rewrite (12.47) as 
.P˜ = 8T˜
3x(x + 1/3)2
(
x 2 + ((2/3) − (9/8T˜))x + 1/9
)
. (12.65) 
.P˜ will be positive if the quadratic in the equation above is positive which 
will be the case if the roots of the quadratic are complex, i.e. if its discrim￾inant is negative.334 12 Interacting Classical Gas
Ex. 12.3. Show that the integral in (12.25) will be finite if .U(r) decreases faster 
than .1/r 3 for large . r. Hint: Let .U(r) ∼ 1/r n for large . r and carry the 
integral to get the desired result. 
12.6 Critical Exponents for van der Waals Fluid 
Whereas the theory of phase transition in Chap. 11 does not assume any particular 
form of the equation of state, the theory of critical exponents developed in (11.4) is 
based on the approximate form (11.41) of the equation of state in the vicinity of the 
critical point. We show below that the van der Waals equation can be reduced to the 
said form. As a result the critical exponents computed in 11.4 hold for the van der 
Walls fluid. We confirm those results without reducing the van der Waals equation 
of state to the form (11.41). 
In terms of the variables defined in (11.35), the equation of state (12.42) assumes 
the form 
.p + 1 = 4(1 + τ )
1 + 3η/2 − 3
(1 + η)2 . (12.66) 
On expanding the right hand side of (12.66) about.η = 0,.τ = 0 and ignoring the. τη2
term for the reasons mentioned circa (11.41), the expression for. p up to.η3 reduces 
to 
.p(η, τ ) = 4τ
(
1 − 3
2
η
)
− 3
2
η3
. (12.67) 
Similarly, in terms of the variables defined in (11.35) and invoking also (12.39),. u in 
(12.34) up to.η4 reads 
. u = −a
v
+
3kBT
2 = −9
8
kBTc(1 + η)
−1 +
3kBT
2
= 9
8
kBTc(η − η2 + η3 − η4
) +
3
2
kBTcτ +
3
8
kBTc. (12.68) 
Equation (12.66) for .p(τ , η) is of the form (11.41) with the parameters . A, B,C
therein given by 
.A = 4, B = 3, C = 9/8. (12.69) 
The results derived in Sect. 11.4.1 are therefore applicable to the present system With 
.A, B,C as in (12.69), the said results yield: 
1. Equation (11.46) for. u in single phase region in the present case yields12.6 Critical Exponents for van der Waals Fluid 335
.u(η, τ ) = 9kBTc
8
{
η − η2 + η4
8
}
+ φ(τ ), (12.70) 
where we take 
.φ(τ ) = 3
2
kBTcτ +
3
8
kBTc. (12.71) 
However, comparison of (12.70) with (12.68) shows that they agree only up to 
. η2. The reason for said discrepancy lies in ignoring .τηk (.k = 2, 3) terms, linear 
in . τ , in the expansion (12.67). As can be seen from (11.45), they contribute . ηk
(.k = 3, 4) terms to energy. When added to already present.η4 term in (12.70) and 
the addition of the new.η3 term to it gives results in agreement with (12.68). For 
consistency we must therefore retain.τη2,.τη3 terms in the expansion (12.67). 
We proceed nevertheless by assuming (12.67) to hold. Hence the results derived 
below are reliable only up to . η2. We will outline method of obtaining results 
reliable up to.η4 in the sequel. We will see that the inclusion of additional terms 
though changes numerical value of the heat capacity, it does not alter the critical 
exponents. 
2. Equations (11.63) for .cv when .T > Tc, (11.67) for .cv when .T < Tc, (11.68) for 
.ηg − ηl , (11.71) for .κT when .T > Tc, (11.73) for .κT when .T < Tc and (11.75) 
for variation of . p as a function of . η on the critical isotherm in the present case 
read 
. cv = 3kB
2 , T > Tc,
cv = 6kB − 9kB
2 |τ |, T < Tc,
ηg − ηl = 4
√−τ , T < Tc
κT = 1
6Pc
(τ )
−1
, T > Tc,
κT = 1
12Pc
(−τ )
−1
, T < Tc,
p = −3
2
η3
, τ = 0, (12.72) 
so that 
.α = α' = 0, β = 1
2
, γ = γ' = 1, δ = 3. (12.73) 
Due to the reasons mentioned following (12.70), the coefficient of. τ in the expres￾sion of.cv when.T < Tc is not reliable. Higher order approximation predicts.cv as 
in (12.91) which has same constant term as.cv for.T < Tc in (12.72) but different 
coefficient for. τ .336 12 Interacting Classical Gas
3. Equations (11.55) and (11.57) for. ηg,.ηl in the present case read 
.η2
g = −4τ , ηl = −ηg. (12.74) 
4. Using (11.59), the equation of state in the coexistence region is 
.p(η, τ ) = 4τ . (12.75) 
The results above are based on the expansion (12.67). Its fallacies have been pointed 
out in the discussion circa (12.70). To make amends, we address afresh the question of 
determining. ηg,. ηl . A method of evaluating.ηg − ηg in terms of difference in entropy 
per molecule in the coexisting liquid and gas phases is described in [ 2]. We however 
follow the method of [ 3] to evaluate thermodynamic observables in the coexistence 
region. 
In [ 3], the quantities .ρ˜g and .ρ˜l defined below have been evaluated as a series in 
.
√−τ where 
.ρ˜ = 1
v˜ ≡ 1
1 + η
, (12.76) 
.ρ˜g = 1
v˜g
≡ 1
1 + ηg
, ρ˜l = 1
v˜l
≡ 1
1 + ηl
. (12.77) 
It has been shown that, with 
.x = √−τ , τ ≤ 0, (12.78) 
to order. x 4, 
. ρ˜g = 1 + α1x + α2x 2 + α3x 3 + α4x 4
,
ρ˜l = 1 − α1x + α2x 2 − α3x 3 + (α4 − β)x 4
, (12.79) 
where 
.α1 = −2, α2 = 2
5
, α3 = 13
25
α4 = .207, β = .092. (12.80) 
We use the expressions above to derive various thermodynamic quantities in the 
coexistence region. 
1. We compute first the internal energy. In terms of the scaled density . ρ˜ defined in 
(12.76), the expression (12.45) for internal energy reads12.6 Critical Exponents for van der Waals Fluid 337
.u(T, ρ) = −9kBTc
8 ρ˜ +
3kBT
2 . (12.81) 
As a consequence, the internal energy at gas–liquid equilibrium state is 
.u(T, ρ) = fgug + flul = −9kBTc
8
(
fgρ˜g + flρ˜l
)
+
3kBT
2 , (12.82) 
where . fg,. fl are determined by the lever rule (zzlivr4). We assume that the total 
specific volume. v is equal to the critical volume. vc, i.e..ρ = 1/vc ≡ ρc. The. fg, fl
in (11.7) in that case, rewritten in terms of the density, are 
. fg = vc − vl
vg − vl
= 1 − ˜vl
v˜g
− ˜vl
= ρg
ρ˜l − 1
ρ˜l − ˜ρg
,
fl = vg − vc
vg − vl
= v˜g − 1
v˜g
− ˜vl
= ρl
1 − ˜ρg
ρ˜l − ˜ρg
. (12.83) 
On using the identities above it is straightforward to see that 
. fgρ˜g + flρ˜l = ˜ρg + ˜ρl − ˜ρgρ˜l . (12.84) 
On using this, the expression (12.82) for internal energy for.ρ = ρc reads 
.u(ρc, T ) = −9kBTc
8
(
ρ˜g + ˜ρl − ˜ρgρ˜l
)
+
3kBT
2 . (12.85) 
Recalling (12.79) we obtain 
. ρ˜gρ˜l = {(1 + α2x 2 + α4x 4)
+ (
α1x + α3x 3)}
× {(1 + α2x 2 + α4x 4)
− (
α1x + α3x 3)
− βx 4}
= (
1 + α2x 2 + α4x 4)2 − (
α1x + α3x 3)2
−βx 4 {(1 + α2x 2 + α4x 4)
+ (
α1x + α3x 3)} . (12.86) 
On retaining terms up to. x 4, the equation above reduces to 
.ρ˜gρ˜l = 1 + (2α2 − α2
1)x 2 + (2α4 + α2
2 − 2α1α3 − β)x 4
. (12.87)338 12 Interacting Classical Gas
Also 
.ρ˜g + ˜ρl = 2(1 + α2x 2 + α4x 4
) − βx 4
. (12.88) 
Substitution of (12.87) and (12.88) in (12.85) gives 
.u(T, ρc) = −9kBTc
8
(
1 + α2
1x 2 − (α2
2 − 2α1α3)x 4)
+
3kBT
2 . (12.89) 
On using (12.80) the equation above reads 
.u(T, ρc) = 9kBTc
2
(
τ +
14
25τ 2
)
+
3kBTc
2 τ +
3kBTc
8 (12.90) 
This is internal energy in the coexistence region when total volume of the fluid is 
equal to the critical volume. 
2. The specific heat per molecule for.v = vc in the coexistence region is given by 
. cv ≡ 1
Tc
du(T, ρc)
dτ = kB
(
6 +
126
25 τ
)
= kB
(
6 − 126
25 |τ |
)
, τ ≤ 0. (12.91) 
The constant term in the equation above is same as that in the expression for.cv for 
.T < Tc in (12.72) but the.τ -dependent terms in the two equations are different. 
3. To evaluate compressibility.κT for.T < Tc, differentiate (12.42) and rewrite it in 
terms of. ρ˜ to obtain 
.
(
∂P˜
∂v˜
)
T
=−˜ρ2
(
8T˜
3 (1 − 3ρ˜)
−2 − 6ρ˜
)
. (12.92) 
We need to evaluate (12.92) for .ρ = ρg. To that end, invoke (12.79) to write . ρg
to order.x 2 as 
.ρg = 1 + f (x), f (x) = −2x +
2
5
x 2
, (12.93) 
so that, for.ρ˜ = ˜ρg, (12.92) may be rewritten as 
. (
∂P˜
∂v˜
)
T
= −6ρ2
g
(
8T˜
3 (1 − f (x)/2)
−2 − (1 + f (x)))
= −12x 2
. (12.94)References 339
It then follows that 
.κT ≡ − 1
Pcv˜
( ∂v˜
∂P˜
)
T
= 1
12Pc
(−τ )
−1
, T < Tc. (12.95) 
This is same as the expression for.κT in (12.72) for.T < Tc. 
4. Invoking (12.79) it is straightforward to see that, to the leading order, 
.ηg − ηl = 4
√−τ , T < Tc. (12.96) 
This is same as the expression for.ηg − ηl in (12.72) for.T < Tc. 
Exercises 
Ex. 12.4. Show that the equation of state of the van der Waals fluid in the gas–liquid 
coexistence region is given by 
.P˜ = ˜ρgρ˜l
(
3 − (ρ˜g + ˜ρl)
)
. (12.97) 
Hint: Write the van der Waals equation of state in terms of the density: 
.P˜(ρ˜, T˜) = 8T˜ ρ˜
3 − ˜ρ − 3ρ˜
2
. (12.98) 
Use the equation.P˜(ρ˜g, T˜) = P˜(ρ˜l, T˜) characterizing the gas–liquid coex￾istence region to express. T˜ in terms of.ρ˜l, ρ˜g: 
.T˜ = (ρ˜l + ˜ρg)(3 − ˜ρl)(3 − ˜ρg). (12.99) 
Substitute this in (12.98) with.ρ˜ = ˜ρl or.ρ˜ = ˜ρg to get the desired result. 
References 
1. D.C. Johnson, 5 Feb. 2014. arXiv:1402.1205v1 [cond-mat.soft] 
2. J. Lekner, Am. J. Phys. 50, 161 (1982) 
3. M.N. Berberan-Santos, E.N. Bodunov, L. Pogliani, J. Math. Chem. 43, 1437 (2008)Chapter 13 
Density Operator Formalism 
The occupation probabilities of energy levels of a macroscopic system in thermody￾namic equilibrium are independent of time. The formalism of equilibrium statistical 
mechanics we presented could therefore be based on the occupation probabilities of 
energy levels. Those probabilities, however, change in time as the system evolves 
starting from an arbitrary initial state. That change takes place due to transitions 
between the energy levels. Hence time evolution of a system cannot be described 
only in terms of the probabilities of occupation of energy levels. In other words the 
probabilities of occupation of energy levels do not characterize the state of the system 
completely. A complete description of the state must include transition probabilities 
as well. We know that the state of an isolated system is characterized completely 
by a vector in the Hilbert space. The systems of interest in statistical mechanics are, 
however, not isolated; they interact with reservoirs. In this chapter we develop the 
formalism to characterize the state of an interacting system, called the density matrix 
formalism. We link the mechanical and the thermodynamic descriptions by quantum 
entropy. We show that the state of thermodynamic equilibrium so predicted is same 
as the one arrived at by working solely with energy levels occupation probabilities. 
The time-dependent aspects are discussed in Chap. 14. 
The Sects. 13.1 and 13.2 essentially summarize the results the details of which 
may be found in [ 1]. 
13.1 Density Matrix 
An isolated system in quantum mechanics is described by a vector in the Hilbert 
space whereas the state of a system interacting with other systems is described by 
the density matrix defined as follows (see [ 1] for the origin of the definition). 
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4_13 
341342 13 Density Operator Formalism
Consider an isolated system whose states are described by vectors in an .n￾dimensional Hilbert space, spanned by orthonormal basis vectors . |a1⟩, |a2⟩,...,
.|an⟩ so that any state vector.|ψ⟩ can be represented as a linear superposition, 
.|ψ⟩ = ∑n
i=1
ci|ai⟩, ⟨ai|aj⟩ = δi j, ci = ⟨ai|ψ⟩. (13.1) 
However, if the system interacts with other systems then its state is represented 
by .n × n density matrix, also called density operator. Denoted by . ρˆ, it is a linear 
combination of the operators.|ai⟩⟨aj|.(i, j = 1, 2,... n): 
.ρˆ = ∑
i,j
ρi j|ai⟩⟨aj|, ρi j = ⟨ai| ˆρ|aj⟩. (13.2) 
Some properties of. ρˆ are: 
1. . ρˆ is hermitian: 
.ρˆ = ˆρ† =⇒ ρi j = ρ∗
ji . (13.3) 
2. As a consequence of its hermiticity, the eigenvalues . λi , .(i = 1, 2,..., n) of . ρˆ
are real and the corresponding eigenvectors orthonormal: 
.ρˆ|λi⟩ = λi|λi⟩, λi = λ∗
i , ⟨λi|λj⟩ = δi j . (13.4) 
3. The trace of. ρˆ is unity: 
.Tr(ρˆ) = 1, (13.5) 
where .Tr(Aˆ) stands for the trace of . Aˆ. Since the sum of the eigenvalues of a 
matrix equals its trace, we have 
.
∑n
i=1
λi = 1. (13.6) 
4. The density matrix is positive: 
.ρˆ ≥ 0, (13.7) 
in the sense that .⟨ψ| ˆρ|ψ⟩ ≥ 0 for all .|ψ⟩. Since positivity of a matrix implies 
positivity of its eigenvalues, we have 
.λi ≥ 0. (13.8) 
Due to this and the relation (13.6), it follows that 
.0 ≤ λi ≤ 1. (13.9)13.1 Density Matrix 343
5. Since it is hermitian,. ρˆ admits the spectral decomposition: 
.ρˆ = ∑n
k=1
λk |λk ⟩⟨λk |. (13.10) 
Consequently, if. f (x) is a function such that. f (λk ) is finite, then 
. f (ρˆ) = ∑n
k=1
f (λk )|λk ⟩⟨λk |. (13.11) 
6. Due to (13.11) we have 
.ρˆ
2 = ∑n
k=1
λ2
k |λk ⟩⟨λk |. (13.12) 
By virtue of (13.9),.λ2
k ≤ λk . Hence 
.ρˆ
2 ≤ ∑n
k=1
λk |λk ⟩⟨λk |= ˆρ, i.e. ρˆ
2 ≤ ˆρ. (13.13) 
In particular this implies 
.Tr(ρˆ
2
) ≤ 1. (13.14) 
The equality will hold if one of the eigenvalues of . ρˆ is unity and all the others 
are zero. The. ρˆ in that case is expressible in the form 
.ρˆ = |Ψ⟩⟨Ψ|, (13.15) 
where.|Ψ⟩ is normalized to unity. The system is then said to be in a pure state. If 
(13.13) does not hold with equality, the state of the system is said to be a mixed 
state. 
7. Let the state of the system be described by the density matrix . ρˆ. The average 
value of a system operator. Aˆ, denoted by.⟨Aˆ⟩, is given by 
.⟨Aˆ⟩ = Tr(Aˆρˆ). (13.16) 
8. If the system is in the state described by the density matrix. ρˆ then.⟨ψ| ˆρ|ψ⟩ is the 
probability for it to be in the state.|ψ⟩. 
9. Time evolution of . ρˆ under the action of the Hamiltonian .Hˆ is governed by the 
equation 
.ih
dρˆ(t)
dt =
[
Hˆ , ρˆ(t)
]
, (13.17) 
known as the Liouville–von Neumann equation. Its formal solution reads344 13 Density Operator Formalism
.ρˆ(t) = Uˆ (t)ρˆ(0)Uˆ †
(t), Uˆ (t) = exp(−iHt ˆ /h). (13.18) 
The operator.Uˆ (t) is the unitary time-evolution operator. 
10. Consider a system composed of two subsystems. A and. B in which. A lies in an.n￾dimensional Hilbert space and. B in an.m-dimensional one. Let. |a1⟩, |a2⟩,..., |an⟩
be the orthonormal basis vectors of .A and .|b1⟩, |b2⟩,...., |bm⟩ those of . B. The 
density matrix of the combined system, denoted by.ρˆ
(A+B)
, is given by 
.ρˆ
(A+B) = ∑n
i,j=1
∑m
k,l=1
cik,jl|ai, bk ⟩⟨aj, bl|, (13.19) 
where .|a, b⟩ stands for the tensor product of the state .|a⟩ of . A and the state . |b⟩
of. B. 
11. If a system composed of two subsystems .A and .B is described by the density 
matrix .ρˆ
(A+B) then the density matrix .ρˆ
(A) of .A alone and .ρˆ
(B) of .B alone are 
given by 
.ρˆ
(A) = TrB(ρˆ
(A+B)
), ρˆ
(B) = TrA(ρˆ
(A+B)
), (13.20) 
where .TrB is trace only over the states of the subsystem.B and.TrA is that only 
over the states of the subsystem. A. They are called partial traces. 
Next we introduce the notion of quantum entropy. 
13.2 Quantum Entropy 
Consider a system described by.n × n density matrix. ρˆ. From the properties of. ρˆlisted 
above, we know that the probability of finding the system in the state.|λk ⟩is.⟨λk | ˆρ|λk ⟩. 
We may consider the eigenvalues .λk of . ρˆ as random outcomes with probability 
.⟨λk | ˆρ|λk ⟩ of some hypothetical measurement process. The Shannon entropy of the 
distribution.{⟨λk | ˆρ|λk ⟩} is evidently 
.S(ρˆ) = −kB
∑n
k=1
⟨λk | ˆρ|λk ⟩ln(⟨λk | ˆρ|λk ⟩) = −kB
∑n
k=1
λk ln(λk ), (13.21) 
where, due to (13.4), .⟨λk | ˆρ|λk ⟩ = λk . Invoking (13.11), it is straightforward to see 
that the expression above for entropy may be written as 
.S(ρˆ) = −kBTr{ ˆρ ln(ρˆ)} (13.22) 
called von Neumann entropy.13.2 Quantum Entropy 345
Some properties of Von Neumann entropy are 
1. Let. 
ˆ
ρ˜ be obtained from. ρˆ by a unitary transformation. Uˆ : 
.
ˆ
ρ˜ = Uˆ †
ρˆUˆ , Uˆ Uˆ † = Uˆ †
Uˆ = I. (13.23) 
The entropy of the system in terms of. 
ˆ
ρ˜ is 
.S˜(ˆ
ρ˜) = −kBTr(ˆ
ρ˜ ln(ˆ
ρ˜)) = −kBTr {
Uˆ †
ρˆUˆ ln(Uˆ †
ρˆUˆ )
}
. (13.24) 
Using the relation 
.F(Uˆ †AˆUˆ ) = Uˆ †F(Aˆ)Uˆ , (13.25) 
and the cyclic property of trace (.Tr(Aˆ BˆCˆ) = Tr(Cˆ Aˆ Bˆ) = Tr(BˆCˆ Aˆ)), (13.24) 
reduces to 
.S˜(ˆ
ρ˜) = −kBTr {
Uˆ †
ρˆ ln(ρˆ)Uˆ
}
= −kBTr {
ρˆ ln(ρˆ)
}
= S(ρˆ). (13.26) 
This shows that the entropy remains unchanged under unitary transformation of 
the density matrix. 
2. If . ρˆ represents a pure state .|Ψ⟩ then .ρˆ = |Ψ⟩⟨Ψ|. In this case .λ1 = 1, .λk = 0, 
.k /= 1 so that, on invoking (13.21), 
.S(ρˆ) = 0. (13.27) 
Thus the entropy of a pure state is zero. 
3. If.ρˆ = I/n, i.e. if all the states have equal probability of occupation without any 
correlation among them then (13.22) yields 
.S(ρˆ) = kBln(n). (13.28) 
It can be shown that.ρˆ = I/n is the state of maximum entropy leading thereby to 
the inequality 
.0 ≤ S(ρˆ) ≤ kBln(n). (13.29) 
This is analogous to the property of Shannon entropy. 
4. The quantum joint entropy of a system consisting of subsystems. A and. B is given 
by (13.22) with. ρˆ identified as the density matrix.ρˆ
(A+B) of the combined system 
of. A and. B. 
5. If.ρˆ
(A) is the density matrix of system. A and.ρˆ
(B) that of system. B then 
.S(ρˆ
(A) ⊗ ˆρ(B)
) = S(ρˆ
(A)
) + S(ρˆ
(B)
). (13.30)346 13 Density Operator Formalism
To prove this, assume that the system .A is .n-dimensional and that the eigen￾values of its density matrix .ρˆ
(A) are .λ1, λ2,..., λn. Similarly, assume that the 
system. B is.m-dimensional and that the eigenvalues of its density matrix.ρˆ
(B) are 
.μ1, μ2,..., μm. The eigenvalues of the tensor product matrix .ρˆ
(A) ⊗ ˆρ(B) would 
be.λiμj ,.(i = 1, 2,... n; j = 1, 2,..., m). The entropy of the combined system 
may then be written as 
. S
(
ρˆ
(A) ⊗ ˆρ(B)
)
= ∑n
j=1
∑m
k=1
λjμk ln(λjμk )
= ∑n
j=1
λj ln(λj)
∑m
k=1
μk +∑m
k=1
μk ln(μk )
∑n
j=1
λj
= ∑n
j=1
λj ln(λj) +∑m
k=1
μk ln(μk ), (13.31) 
where we have used the fact that the sum of the eigenvalues of a density matrix 
is unity. The last equation above is the sum of the entropies of the system. A and 
. B proving thereby (13.30). 
6. It can be shown that.S(ρˆ)) is concave in the sense that 
.S( f ρˆ1 + (1 − f )ρˆ2) ≥ f S(ρˆ1) + (1 − f )S(ρˆ2). (13.32) 
In general 
.S
(
∑
k
i=1
fiρˆi
)
≥ ∑
k
i=1
fi S
(
ρˆi
)
, ∑
k
i=1
fi = 1. (13.33) 
The quantum statistical mechanics is built on identifying von Neumann entropy as 
the statistical mechanical entropy. 
13.3 Equilibrium Density Matrix 
The properties of a system in thermodynamic equilibrium are described by the density 
matrix constructed according to the following postulate: 
The density matrix of a system in thermodynamic equilibrium is one that maximizes 
the von Neumann entropy subject to the constraints on it.13.3 Equilibrium Density Matrix 347
We construct the equilibrium density matrix. ρˆ by maximizing von Neumann entropy 
defined in (13.22) subject to the following constraints: 
1. The trace of. ρˆ is unity: 
.Tr(ρˆ) = 1. (13.34) 
This constraint is always present. 
2. Average values of certain set of observables.Aˆ k (.k = 1, 2,... m) is equal to some 
specified values: 
.⟨Aˆ k ⟩ ≡ Tr(Aˆ kρˆ) = ck . (13.35) 
Invoking the method of Lagrange multipliers, the desired . ρˆ is obtained as the one 
which extremizes 
. F(ρˆ) = S
kB
− α0Tr(ρˆ) −∑m
k=1
αkTr (
Aˆ kρˆ
)
= −Tr [
ρˆ
(
ln(ρˆ) + α0 +∑m
k=1
αk Aˆ k
)
]
, (13.36) 
where.{αk } are Lagrange multipliers. The extremum of.F(ρˆ) is obtained by the con￾dition .δF ≡ F(ρˆ + δρˆ) − F(ρˆ) = 0. Now, if .Xˆ is a matrix then . δXˆ 2 = (δXˆ)Xˆ +
Xˆ(δXˆ) /= 2Xˆ δXˆ /= 2(δXˆ)Xˆ . However, because of the cyclic property of trace, 
.Tr (
δXˆ 2
)
= Tr (
(δXˆ)Xˆ + Xˆ(δXˆ)
)
= 2Tr (
Xˆ δXˆ
)
= 2Tr (
(δXˆ)Xˆ
)
. In general 
.δXˆ m = ∑m
k=1
Xˆ m−k
(δXˆ)Xˆ k−1
, (13.37) 
so that 
.Tr (
δXˆ m
)
= mTr (
Xˆ m−1
δXˆ
)
= mTr (
δXˆ Xˆ m−1
)
. (13.38) 
Consequently, if. f (x) is expressible in terms of the powers of. x then 
.Tr (
δ f
(
Xˆ
)) = Tr
⎛
⎝δXˆ
d f
(
Xˆ
)
dXˆ
⎞
⎠ = Tr
⎛
⎝
d f
(
Xˆ
)
dXˆ δXˆ
⎞
⎠ . (13.39) 
On using the property above, the condition.δF(ρˆ) = 0, with.F(ρˆ) given by (13.36), 
leads to the equation 
.Tr [
δρˆ
(
ln(ρˆ) + 1 + α0 +∑m
k=1
αk Aˆ k
)
]
= 0. (13.40)348 13 Density Operator Formalism
If the equation above is to hold for an arbitrary. δρˆ, we must have 
.ln(ρˆ) + 1 + α0 +∑m
k=1
αk Aˆ k = 0. (13.41) 
The solution of the equation above is evidently 
.ρˆ = 1
Z exp(
−
∑m
k=1
αk Aˆ k
)
, (13.42) 
where.Z ≡ exp(α0 + 1) is determined by the condition.Tr(ρˆ) = 1: 
.Z = Tr [
exp(
−
∑m
k=1
αk Aˆ k
)] . (13.43) 
The function.Z({αk }) is the partition function. 
Next we derive expressions for the standard quantum distributions obtained before 
by the Gibbs–Shannon entropy approach. 
13.4 Standard Distributions 
The variables of interest from the point of view of thermodynamics application are 
energy and the number of particles. Derived below are equilibrium density matrices 
obtained from the general form (13.42) by specifying the said quantities determin￾istically or statistically in terms of their averages. 
As in Sect. 5.3.2, we denote the Hamiltonian of the system for a fixed number 
.N of particles by.HˆN and its eigenstates and eigenvalues respectively by.|EmN ⟩ and 
.EmN . The probability of finding the system in the state .|EmN ⟩, denoted by .pmN , is 
given in terms of the density matrix by 
.pmN = ⟨EmN | ˆρ|EmN ⟩. (13.44) 
The theory of equilibrium statistical mechanics has been developed in earlier chapters 
in terms of .pmN by determining it for various ensembles using the principle of 
maximum entropy. We will show how those results follow from the general theory 
developed in terms of the density matrix.13.4 Standard Distributions 349
13.4.1 Microcanonical Ensemble 
Consider a system having fixed number.N of particles and energy.E specified to lie 
in the range .E0 ≤ E ≤ E0 + Δ. Recall that the ensemble describing such a system 
is called microcanonical. In this case, only constraint on the density matrix that 
maximizes entropy is on its trace. It is a special case of (13.42) with.αk = 0 (.k ≥ 1) 
so that 
.ρˆ = I
Z , (13.45) 
where .E0 ≤ EmN ≤ E0 + Δ. If .W is the number of states in the said interval, then 
the trace condition on. ρˆ leads to 
.Z = Tr(I) = ∑
m
⟨EmN |I|EmN ⟩ = W. (13.46) 
Hence the density matrix describing microcanonical ensemble is 
.ρˆ = I
W . (13.47) 
The probability of occupation of the level of energy.EmN is given, invoking (13.44), 
by 
.pmN = 1
W . (13.48) 
This is same as the expression (6.25) derived without use of the density matrix 
formalism. 
13.4.2 Canonical Ensemble 
When the number of particles in the system is fixed, but energy is specified in terms 
of average value then, apart from the trace condition, the constraint on the density 
matrix for maximizing entropy is 
.⟨HˆN ⟩ ≡ Tr(HˆN ρˆ) = U. (13.49) 
We know that the ensemble of such systems is called canonical ensemble. The equi￾librium density matrix then is the special case of (13.42) with .α1 → β, . Aˆ1 → HˆN
and.αk = 0 for.k > 1: 
.ρˆ = 1
ZN
exp(−βHˆN ), (13.50)350 13 Density Operator Formalism
and the partition function.ZN is 
.ZN = Tr(
exp(−βHˆN )
)
. (13.51) 
The probability of occupation of level.|EmN ⟩ is given by 
.pmN = 1
ZN
exp(−βEmN ). (13.52) 
This is same as the expression derived in (6.30) for canonical ensemble without the 
use of the density matrix formalism. 
13.4.3 Grand Canonical Ensemble 
For a system in which the number of particles as well as energy are given as aver￾ages then, apart from the trace condition, the constraints on the density matrix for 
maximizing the entropy are 
.⟨Hˆ⟩ ≡ Tr(Hˆ ρˆ) = U, ⟨Nˆ ⟩ ≡ Tr(Nˆ ρˆ) = N¯ , (13.53) 
where.Nˆ is the number operator which is such that 
.Nˆ |EmN ⟩ = N|EmN ⟩. (13.54) 
Recall that the ensemble of such systems is called grand canonical ensemble. The 
equilibrium density matrix in the present case is the special case of (13.42) with 
.α1 → β,.Aˆ1 → Hˆ ;.α2 → −α,.Aˆ2 → Nˆ , and.αk = 0 for.k > 2: 
.ρˆ = 1
ZG
exp(−βHˆ + αNˆ ), (13.55) 
and the partition function.ZG is 
.ZG = Tr(
exp(−βHˆ + αNˆ )
)
. (13.56) 
Occupation probability of the state.|EmN ⟩, obtained using (13.44) is 
.pm(N) = 1
ZG
exp(−βEmN + αN). (13.57)13.5 Equilibrium Density Matrix of Harmonic Oscillators 351
This is same as the corresponding expression derived in (6.59) without using the 
density matrix formalism. As stated in Sect. 6.3, change in notation from .pmN to 
.pm(N) is to distinguish the probabilities for varying number of particles from those 
for fixed. N. 
The density matrix formalism thus leads to same standard distributions as were 
obtained using Gibbs–Shannon entropy. In Sect. 6.4 we used those distributions to 
establish relationship between the thermodynamic and statistical descriptions. The 
new aspect introduced by the density matrix description is the time evolution. In 
Sect. 13.6 we will show that the time evolution of entropy is consistent with the 
second law. For now we construct partition function for quantum harmonic oscillators 
which will be useful in the master equation formalism developed in Chap. 14. 
13.5 Equilibrium Density Matrix of Harmonic Oscillators 
A harmonic oscillator (h.o.) of frequency. ω is described by the Hamiltonian (taking 
its ground state energy.hω/2 as the zero of energy) 
.Hˆ = hωaˆ †
aˆ, [ ˆa, aˆ †
] = 1. (13.58) 
Invoking (13.50), the equilibrium density matrix of the h.o. in contact with a heat 
reservoir at temperature. T reads 
.ρˆ = 1
Z exp(−βhωaˆ †
aˆ), Z = Tr [
exp(−βhωaˆ †
aˆ)
]
. (13.59) 
Carrying trace in the basis of the number states (see Appendix G), the partition 
function. Z reads 
. Z = ∑∞
n=0
⟨n| exp(−βhωaˆ †
aˆ)|n⟩ = ∑∞
n=0
exp(−βhωn)
= 1
1 − exp(−βhω)
. (13.60) 
The probability that the oscillator is in the state.|n⟩ is 
.pn = 1
Z exp(−βhωn). (13.61) 
Energy of the oscillator is 
.U = hω
exp(βhω) − 1
. (13.62)352 13 Density Operator Formalism
Exercises 
Ex. 13. 1. Consider a system of.N non-interacting harmonic oscillators of frequency 
. ω at temperature. T , each described by the Hamiltonian (13.58). Show that 
the probability that an oscillator is in the coherent state.|α⟩ is 
.p(α) = 1
Z exp{−(1 − exp(−βhω))|α|
2
}. (13.63) 
Hint: Use (G.6). 
13.6 Time Evolution of Entropy 
Recall from (13.18) that, under the action of a Hamiltonian, the time evolution of the 
density matrix is governed by a unitary operator. Hence entropy at time. t is given by 
.S(ρˆ(t)) = kBTr {
ρˆ(t)ln(ρˆ(t))}
= S(ρˆ(0)), (13.64) 
where last line is the consequence of (13.26) according to which entropy of two 
density matrices related by unitary transformation is same. 
Thus entropy would remain unchanged as a function of time if the evolution is 
governed by a Hamiltonian. However, as we know, the molecular motion in macro￾scopic systems can be modeled as random. It may be described by assuming that the 
molecular evolution is governed by a Hamiltonian chosen randomly from a set of 
Hamiltonians.{Hˆj} with probabilities.{ f j} (see [Balian]). The density matrix at time 
. t may therefore be written as 
.ρˆ(t) = ∑
i
fiUˆi(t)ρˆ(0)Uˆ †
i (t), ∑
k
i=1
fi = 1, (13.65) 
where.Uˆ j(t) is as in (13.18) with.Hˆ → Hˆj . Hence the entropy at time. t is 
.S
(
ρˆ(t)
)
= S
(
∑
i
fiUˆi(t)ρˆ(0)Uˆ †
i (t)
)
. (13.66) 
Recalling the inequality in (13.33) follows the relationReference 353
. S
(
∑
i
fiUˆ j(t)ρˆ(0)Uˆ †
j (t)
)
≥ ∑
k
i=1
fi S
(
Uˆ j(t)ρˆ(0)Uˆ †
j (t)
)
= ∑
k
i=1
fi S
(
ρˆ(0)
)
, (13.67) 
where the last line is due to (13.26) leading finally to the inequality 
.S(ρˆ(t)) ≥ S(ρˆ(0)). (13.68) 
We thus see that entropy under random interaction cannot decrease. Though we have 
derived the result by assuming the Hamiltonian to be time independent in which case 
the time-evolution operator.Uˆ (t) is given by (13.18), the derivation invokes only the 
unitarity of .Uˆ which will hold even when .Hˆ is time dependent though the form of 
.Uˆ (t) will then be different from that in (13.18). 
Reference 
1. R.R. Puri, Non-Relativistic Quantum Mechanics (Cambridge University Press, 2017)Chapter 14 
Quantum Master Equation 
The statistical mechanical equilibrium distribution is derived assuming maximum 
entropy principle. But the applicability of that principle must be ascertained by 
demonstrating that the asymptotic solution of the equation for the density matrix of a 
macroscopic system interacting with a reservoir is the one predicted by the maximum 
entropy principle. Starting from the equation of evolution of the density matrix of a 
system interacting with a thermal reservoir, called the master equation, in this chapter 
we show that it indeed approaches the canonical form in the asymptotic limit. The 
master equation is derived assuming weak interaction between the reservoirs and 
the system, an assumption which was used also to establish the relation between 
statistical mechanics and thermodynamics in Sect. 6.4. 
14.1 Master Equation 
Starting from the equation of evolution of the density matrix of the composite system, 
consisting of the system of interest, named. A, interacting with a reservoir, named. R, 
in this section we present the equation of evolution of the system of interest alone 
under various assumptions. See [ 1] for the details of the derivation. 
Consider a system. A coupled to a reservoir of harmonic oscillators such that the 
composite system is described by the Hamiltonian 
.Hˆ = HˆA + HˆR + HˆAR. (14.1) 
Various terms in the expression above are: 
1. .HˆA is the Hamiltonian of the system. 
2. .HˆR is the Hamiltonian of the reservoir, assumed to consist of harmonic oscil￾lators of frequencies .(ω1, ω2, . . .) ≡ {ωk } described by the harmonic oscillator 
annihilation and creation operators.{ ˆck , cˆ
†
k } obeying the commutation relation 
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4_14 
355356 14 Quantum Master Equation
.[ ˆck , cˆ
†
p] = δkp. (14.2) 
The.HˆR is given by 
.HˆR = h
∑
k
ωk cˆ
†
k ck . (14.3) 
Modeling the reservoir as a collection of harmonic oscillators captures several 
real situations. For example, we know that the electromagnetic field is described 
as a collection of harmonic oscillators. It acts as a reservoir for atoms in free 
space. 
3. The Hamiltonian.HˆAR describes the interaction of the system with the reservoir. 
It is assumed to be of the form 
.HˆAR = h
∑
k
(
gck Aˆ†
cˆk + g∗
ck cˆ
†
k Aˆ
)
, (14.4) 
where. Aˆ is a system operator such that 
.[HˆA, Aˆ]=−hωa Aˆ. (14.5) 
We rewrite the equation above by introducing the notion of a “superoperator”. Like 
an operator acts on a vector to transform it to another vector, a superoperator acts 
on an operator to transform it to another operator. We distinguish a superoperator 
from an operator by representing it by two carets on a letter. For example, the 
equation 
.
ˆ
Oˆ Aˆ = Bˆ (14.6) 
defines the superoperator .
ˆ
Oˆ which acting on some operator .Aˆ transforms it to 
another operator . Bˆ. Let .
ˆ
Hˆ A be the superoperator defined by its action on an 
operator.Pˆ by the equation 
.
ˆ
Hˆ A Pˆ = (h)
−1
[HˆA, Pˆ]. (14.7) 
In terms of.
ˆ
Hˆ A, (14.5) assumes the form 
.
ˆ
Hˆ A Aˆ = −ωa Aˆ. (14.8) 
The evolution of the density matrix .ρˆ(A+R)
(t) of the composite system is governed 
by the equation14.1 Master Equation 357
. ˙
ρˆ
(A+R)
(t) = (ih)
−1
[Hˆ , ρˆ
(A+R)
(t)]. (14.9) 
Our interest is in the dynamics of the system alone, described by the density matrix 
.ρˆ(A)
(t). It is related with the density matrix .ρˆ(A+R)
(t) of the composite system by 
the relation 
.ρˆ
(A)
(t) = TrR[ ˆρ(A+R)
(t)], (14.10) 
with.TrR standing for trace over the reservoir operators. 
The equation for the time evolution of .ρˆ(A)
(t) may in principle be derived by 
taking trace of the equation (14.9) for the density matrix of the composite system 
over the reservoir operators under the following initial conditions: 
1. The oscillators constituting the reservoir are assumed to be in the state of thermal 
equilibrium at temperature . T . Recalling that the density matrix of an oscillator 
in equilibrium with a reservoir at temperature . T is given by (13.59), the density 
matrix of the reservoir is readily seen to be 
.ρˆ
(R)
(0) = ∏
k
(1 − exp(−βhωk )) exp (
−βhωk cˆ
†
k cˆk
)
. (14.11) 
2. The system and the reservoir are assumed to be decoupled at.t = 0: 
.ρˆ
(A+R)
(0) = ˆρ(A)
(0) ⊗ ˆρ(R)
(0). (14.12) 
However, except for some special systems, like the system consisting of one or more 
harmonic oscillators, it is not possible to derive an exact equation for.ρˆ(A)
(t) starting 
from (14.9) for the composite system. Assuming weak system-reservoir interaction, 
it is derived under the so-called Born-Markov approximation outlined below: 
1. Equation (14.9) is solved perturbatively to the second order in the system-reservoir 
coupling constant. This is called Born approximation. 
2. It is assumed that the system and bath are uncorrelated at all times and that the 
state of the bath remains unchanged during the evolution, i.e. the density matrix 
of the combined system at time. t is 
.ρˆ
(A+R)
(t) = ˆρ(A)
(t) ⊗ ˆρ(R)
(0). (14.13) 
3. It is assumed that the reservoir correlation time is much shorter than the time of 
observation. This usually requires the reservoir to have non-denumerably infinite 
number of degrees of freedom. In the present case it amounts to assuming that the 
reservoir oscillators’ frequencies are spaced so closely that their distribution may358 14 Quantum Master Equation
be described in terms of the density of frequencies.h(ω) enabling one to replace 
sum over frequencies by integral: 
.
∑
k
f (ωk ) →
∫
h(ω) f (ω)dω. (14.14) 
On the said time scale of observation the system loses the memory of its past. 
This is called Markov approximation. 
The equation of evolution of .ρˆ(A)
(t) under the conditions stated above turns out to 
be given by 
.
dρ(ˆ t)
dt = ˆ
Wˆ Aρ(ˆ t), (14.15) 
where, for notational convenience, we have removed the superscript .A on . ρˆ(A)
(t)
and introduced the superoperator. ˆ
Wˆ A defined by 
. ˆ
Wˆ Aρ(ˆ t) = (ih)
−1
[Hˆ A, ρ(ˆ t)] + iΔ1[Aˆ†Aˆ, ρ(ˆ t)] − iΔ2[Aˆ Aˆ†
, ρ(ˆ t)]
+ γ (n¯ + 1)
(
2Aˆρ(ˆ t)Aˆ† − Aˆ†Aˆρ(ˆ t) − ˆρ(t)Aˆ†Aˆ
)
+ γ n¯
(
2Aˆ†
ρ(ˆ t)Aˆ − Aˆ Aˆ†
ρ(ˆ t) − ˆρ(t)Aˆ Aˆ†
)
, (14.16) 
where 
.n¯ = 1
exp(hωaβ) − 1 (14.17) 
is the average number of reservoir oscillators at frequency.ωa defined in (14.5), 
.γ = π|gck |
2
h(ωk )δ(ωk − ωa), (14.18) 
.Δ1 = P
∑
k
|gck |
2
ωa − ωk
(n¯(ωk ) + 1), Δ2 = P
∑
k
|gck |
2
ωa − ωk
n¯(ωk ), (14.19) 
where.P denotes the principal part. 
Equation (14.15) is the so-called master equation for the density matrix of a 
system interacting with a thermal reservoir in the Born-Markov approximation. The 
meaning of various terms in it is: 
1. First term on the right side of (14.16) describes evolution of the density matrix in 
the absence of its interaction with the reservoir.14.2 Steady State Solution 359
2. Verify invoking the defining equation (14.5) that 
.
[
Hˆ A, Aˆ†Aˆ
]
=
[
Hˆ A, Aˆ Aˆ†
]
= 0. (14.20) 
The.Δ1,2 terms therefore cause shift in the energy levels of the system due to its 
interaction with the reservoir. These terms are much smaller than the energies of 
non-interacting system and are often ignored. 
3. The last two terms cause damping of the operator averages. They are responsible 
for driving the system toward the state of equilibrium. 
Some properties of the equation (14.15) and its solution are: 
1. On taking the trace of (14.15) it may be verified that 
.
dTr{ ˆρ(t)}
dt = 0 =⇒ Tr{ ˆρ(t)} = Tr{ ˆρ(0)} = 1. (14.21) 
This shows that (14.15) conserves trace of. ρˆ, as it must. 
2. Let.ρˆλ be an eigenoperator of. ˆ
Wˆ A corresponding to the eigenvalue. λ in the sense 
that 
. ˆ
Wˆ Aρˆλ = λρˆλ. (14.22) 
If the eigenvalues are distinct, the solution of (14.15) can be written as 
.ρ(ˆ t) = ∑
λ
ρˆλ exp(λt). (14.23) 
It can be shown that one of the eigenvalues is zero whereas the real part of all the 
others is negative. Hence, in the limit.t → ∞,.ρ(ˆ t) → ˆρ0. 
The density matrix, denoted by.ρˆss ≡ ˆρ0, corresponding to the zero eigenvalue is 
called the steady-state density matrix. That is the state reached by the system as 
.t → ∞. It may be mentioned that similar conclusion is reached even when the 
eigenvalues are repeated. 
In the following we determine the steady-state solution of (14.15). 
14.2 Steady State Solution 
As discussed above, the steady-state density matrix .ρˆss of (14.15) is the solution 
corresponding to the zero eigenvalue of. ˆ
Wˆ Aρˆλ: 
. ˆ
Wˆ Aρˆss = 0. (14.24)360 14 Quantum Master Equation
We show that the equation above is solved by 
.ρˆss = 1
Z exp(−β Hˆ A), Z = Tr{exp(−β Hˆ A}. (14.25) 
To that end, recall (14.20) where it is shown that.Aˆ†Aˆ and.Aˆ Aˆ† commute with.Hˆ A. 
Hence with.ρˆ → ˆρss in (14.16), first three terms therein give a vanishing contribution. 
To show that the remaining two terms therein, the damping terms, also reduce to zero 
when.ρˆ → ˆρss, we need the identity 
.Aˆ(β) ≡ exp(−β Hˆ A)Aˆ exp(β Hˆ A) = n¯ + 1
n¯ Aˆ. (14.26) 
To prove this, differentiate (14.26) with respect to. β by the chain rule of differentiation 
but without changing the order of.Hˆ A and. Aˆ to get 
. 
dAˆ(β)
dβ = − exp(−β Hˆ A)
[
Hˆ A, Aˆ
]
exp(β Hˆ A)
= hωa exp(−β Hˆ A)Aˆ exp(β Hˆ A) = hωa Aˆ(β), (14.27) 
where second equation is due to (14.5). This is solved by 
.Aˆ(β) = exp(hβω)Aˆ. (14.28) 
From the definition (14.17) of. n¯ we have 
. exp(hβωa) = n¯ + 1
n¯ . (14.29) 
Substitution of this in (14.28) gives the desired result (14.26). The hermitian conju￾gation of (14.28) with.β → −β gives 
.Aˆ†
(−β) = exp(−hβω)Aˆ† = n¯
n¯ + 1
Aˆ†
. (14.30) 
This is same as 
. exp(−β Hˆ A)Aˆ† exp(β Hˆ A) ≡ Aˆ†
(−β) = n¯
n¯ + 1
Aˆ†
. (14.31) 
Now, with.ρ(ˆ t) → ˆρss, rewrite the damping part in (14.16) as14.3 Harmonic Oscillator Interacting with Reservoir of Harmonic … 361
. (n¯ + 1)
(
2AˆρˆssAˆ† − Aˆ†Aˆρˆss − ˆρssAˆ†Aˆ
)
+ ¯n
(
2Aˆ†
ρˆssAˆ − Aˆ Aˆ†
ρˆss − ˆρssAˆ Aˆ†
)
=
[
(n¯ + 1)AˆρˆssAˆ† − ¯nAˆ Aˆ†
ρˆss]
+
[
n¯ Aˆ†
ρˆssAˆ − (n¯ + 1)Aˆ†Aˆρˆss]
+ h.c.,
(14.32) 
where.h.c. stands for hermitian conjugate. Consider first term on the right side of the 
equation above with.ρˆss given by (14.25): 
. (n¯ + 1)AˆρˆssAˆ† − ¯nAˆ Aˆ†
ρˆss
= 1
Z
[
(n¯ + 1)Aˆ exp(−β Hˆ A)Aˆ† − ¯nAˆ Aˆ† exp(−β Hˆ A)
]
= 1
Z
[
(n¯ + 1)Aˆ Aˆ†
(−β) − ¯nAˆ Aˆ†
]
exp(−β Hˆ A) = 0, (14.33) 
where last equation is due to (14.31). We can in this way show that each term in 
(14.32) vanishes. 
We have thus demonstrated that the equilibrium state of a system interact￾ing weakly with a thermal reservoir is, in accordance with statistical mechanics, 
described by the canonical density matrix having the same temperature as that of the 
reservoir. 
We discuss next an exactly solvable model which is that of a harmonic oscillator 
interacting with the reservoir of harmonic oscillators. 
14.3 Harmonic Oscillator Interacting with Reservoir 
of Harmonic Oscillators: Exact Solution 
We consider a harmonic oscillator of frequency .ωa interacting with a reservoir of 
harmonic oscillators. The Hamiltonian of the system is given by (14.1) with 
.Hˆ A = hωaaˆ †
aˆ, (14.34) 
where .aˆ, aˆ † are the oscillator annihilation and creation operators obeying the com￾mutation relation 
.[ ˆa, aˆ †
] = 1. (14.35) 
The operator. Aˆ in the system-reservoir interaction Hamiltonian (14.4) is assumed to 
be. aˆ: 
.Aˆ = ˆa. (14.36)362 14 Quantum Master Equation
Clearly, with .Hˆ A given by (14.34) and .Aˆ by (14.36), the relation (14.5) is obeyed. 
In Born-Markov approximation, the density matrix .ρ(ˆ t) of the oscillator obeys the 
master equation (14.15). Ignoring the level-shift terms therein, in the present case it 
assumes the form 
. 
dρ(ˆ t)
dt = −iωa[ ˆa†
aˆ, ρ(ˆ t)]
+γ (n¯ + 1)
(
2aˆρ(ˆ t)aˆ † − ˆa†
aˆρ(ˆ t) − ˆρ(t)aˆ †
aˆ
)
+γ n¯
(
2aˆ †
ρ(ˆ t)aˆ − ˆaaˆ †
ρ(ˆ t) − ˆρ(t)aˆaˆ †)
, (14.37) 
and the corresponding steady-state solution (14.25) reads 
.ρˆss = 1
Z exp(−βhωaaˆ †
aˆ), Z = 1
1 − exp(−βhωa)
. (14.38) 
This is same as the solution (13.59) arrived at by the theory of equilibrium statistical 
mechanics. 
The exact equation of evolution of the density matrix of the oscillator is also 
known. It will enable us to understand various approximations leading to its form 
(14.37). 
The exact expression for the density matrix of the oscillator at time. t in the coherent 
states representation is given by (see [ 2] for the derivation of the equation below and 
Appendix G for coherent states representation) 
.ρ(α, α∗, t) = 1
πχ(t)
∫
exp [
−| f (t)αo − α|
2
/χ (t)
]
ρ(α0, α∗
0 , 0)d2
α0,(14.39) 
where .ρ(α, α∗, t) = ⟨α| ˆρ(t)|α⟩, is the density matrix of the oscillator at time . t in 
the coherent state .|α⟩ and .ρ(α0, α∗
0 , 0) that at .t = 0 in the coherent state .|α0⟩. The 
functions. f (t) and.χ (t) in (14.39) are: 
. f (t) = 1
2π
∫
C
exp(−izt)
η(z)
dz, χ(t) = ∑
k
| fk |
2
/μk , (14.40) 
where 
. fk (t) = gk
2π
∫
C
exp(−izt)
(z − ωk )η(z)
, η(z) = ωa − z +∑
k
|gk |
2
ωk − z
. (14.41) 
and 
.μk = 1 − exp(−βhωk ). (14.42)14.3 Harmonic Oscillator Interacting with Reservoir of Harmonic … 363
The path. C of integration in (14.41) is the line parallel to the real z-axis lying above 
the singularities of the integrand. The equation of evolution of.ρ(α, α∗, t) turns out 
to be given by 
. 
dρ(α, α∗, t)
dt = − [{χ (A + A∗) − dχ
dt
} ∂2ρ
∂α∂α∗ + A∂(αρ)
∂α + A∗ ∂(α∗ρ)
∂α∗
]
,
(14.43) 
where 
.A = 1
f (t)
d f (t)
dt . (14.44) 
Equation (14.43) is in the form of the Fokker–Planck equation but with time￾dependent coefficients. If the coefficients in (14.43) are independent of time, it would 
describe a Markov process, else it describes a non-Markov process. We will see that 
the coefficients in (14.43) become independent of time under the approximations 
similar to the Born-Markov approximation which led to the master equation (14.37). 
The nature of time evolution of.ρ(α, α∗, t) is determined by that of the functions 
. f (t) and.χ (t). The defining equation (14.40) of. f (t)shows that its behavior depends 
on the singularities of.1/η(z). The expression (14.41) of.η(z) shows that it will have 
isolated zeros if the number of oscillators in the reservoir is finite. Those zeros lie on 
the real axis. In that case . f (t) shall be a sum of the terms having time dependence 
of the form .exp(−izi t) where .zi is a zero of .η(z). The . fk (t) also will have similar 
behavior. It is then straightforward to see that under the operation of time reversal 
.t → −t,. f (−t) = f ∗(t),. fk (−t) = f ∗
k (t) due to which.χ (−t) = χ (t). Also, under 
time reversal,.α → α∗. It follows that (14.43) governing the evolution of the density 
matrix is invariant under time reversal. In other words, the evolution is reversible. 
Hence, the reservoir consisting of finite number of degrees of freedom cannot give 
rise to irreversible behavior needed for approach to an equilibrium state. 
On the other hand, in the thermodynamic limit.N → ∞, the spacing between the 
zeros of.η(z) becomes vanishingly small enabling one to describe their distribution 
by a density function.h(ω) and to replace, as in (14.14), sum over. k by the integral. 
The function.η(z) will then have branch cut along the real z-axis. In that case, under 
Born-Markov type of approximation, it has been shown that, 
. f (t) = exp(−(γ + iωa)t), χ (t) = (n¯ + 1)(1 − exp(−2γ t)). (14.45) 
Using the equations above, it can be seen that when .t → ∞, .ρ(α, α∗, t) in (14.39) 
approaches.ρˆss given by 
.ρˆss = 1
n¯ + 1 exp{−|α|
2
/(n¯ + 1)}. (14.46)364 14 Quantum Master Equation
This is same as the canonical equilibrium density matrix in the coherent states rep￾resentation derived in (13.63). 
With. f (t), χ (t) given by (14.45), (14.43) reduces to 
. 
dρ(α, α∗, t)
dt = iωa
(∂(αρ)
∂α − ∂(α∗ρ)
∂α∗
)
+γ
[
2(n¯ + 1)
∂2ρ
∂α∂α∗ + ∂(αρ)
∂α + ∂(α∗ρ)
∂α∗
]
. (14.47) 
Invoking (G.14), (G.15) it may be verified that, in the coherent states representation, 
the operator equation (14.37) assumes the form (14.47). 
We see that the time-reversal breaks down and the evolution is irreversible if the 
reservoir has non-denumerably infinite number of degrees of freedom. The exact 
solution for the density matrix for an arbitrary number of oscillators interacting with 
a bath of harmonic oscillators is derived in [ 3]. It too predicts canonical form for the 
equilibrium density matrix of the system of oscillators under the assumptions similar 
to those under which the single oscillator described above does. 
We have thus achieved the desired objective of demonstrating that, for certain 
form of weak system-reservoir interaction, the asymptotic solution of the equation 
for the density matrix of a macroscopic system is the one predicted by the maximum 
entropy principle. 
Exercises 
Ex. 14.1. Invoking (G.14), (G.15) show that (14.37) assumes the form (14.47) in the 
coherent states representation. 
References 
1. R.R. Puri, Mathematical Methods of Quantum Optics (Springer, 2001) 
2. R.R. Puri, S.V. Lawande, Phys. Lett. 62A 143 (1977) 
3. R.R. Puri, S.V. Lawande, Phys. Lett. 62A 143 (1977)Appendix A 
Some Relations Involving Partial Derivatives 
In this appendix we derive some relations between the partial derivatives of func￾tions under the transformations of the independent set of variables. The said task is 
facilitated by the use of the Jacobian notation. 
Let.u(x, y), v(x, y) be the functions of independent variables.(x, y). The Jacobian 
of.(u, v) with respect to.(x, y) is defined by 
. 
∂(u, v)
∂(x, y) = det 
⎛
⎜
⎜
⎜
⎝
∂u 
∂x 
∂u 
∂y 
∂v
∂x 
∂v
∂y 
⎞
⎟
⎟
⎟
⎠ , (A.1) 
where it is understood that . y is constant in .∂/∂x, and . x is constant in .∂/∂y. Some 
consequences of the definition (A.1) are: 
1. It follows from (A.1) that 
. 
∂(x, y)
∂(x, y) = 1. (A.2) 
2. It is straightforward to verify that 
. 
∂(u, v)
∂(x, y) = −∂(u, v)
∂(y, x)
, ∂(u, v)
∂(x, y) = −∂(v, u)
∂(x, y)
. (A.3) 
3. The partial derivative.∂u/∂x can be written in terms of the Jacobian as 
. 
∂u 
∂x = ∂(u, y)
∂(x, y)
. (A.4) 
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer 
Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4 
365 366 Appendix A: Some Relations Involving Partial Derivatives 
4. If the set of independent variables.(x, y) is transformed to the independent vari￾ables.(w,z) then it can be shown that 
. 
∂(u, v)
∂(x, y) = ∂(u, v)
∂(w,z)
∂(w,z)
∂(x, y)
. (A.5) 
This relation may be established by noting that, as functions of the transformed 
variables.(w,z), the differentials of. u and. v read 
.du = ∂u 
∂w
dw +
∂u 
∂z 
dz, dv = ∂v
∂w
dw +
∂v
∂z 
dz, (A.6) 
where it is understood that. z is constant in.∂/∂w, and.w is constant in.∂/∂z. We 
can therefore rewrite.∂(u, v)/∂(x, y) as 
. 
∂(u, v)
∂(x, y) = det 
⎛
⎜
⎜
⎜
⎝
∂u 
∂w
∂w
∂x +
∂u 
∂z 
∂z 
∂x 
∂u 
∂w
∂w
∂y 
+
∂u 
∂z 
∂z 
∂y 
∂v
∂w
∂w
∂x +
∂v
∂z 
∂z 
∂x 
∂v
∂w
∂w
∂y 
+
∂v
∂z 
∂z 
∂y 
⎞
⎟
⎟
⎟
⎠
= det 
⎡
⎢
⎢
⎢
⎣
⎛
⎜
⎜
⎜
⎝
∂u 
∂w
∂u 
∂z 
∂v
∂w
∂v
∂z 
⎞
⎟
⎟
⎟
⎠
⎛
⎜
⎜
⎜
⎝
∂w
∂x 
∂w
∂y 
∂z 
∂x 
∂z 
∂y 
⎞
⎟
⎟
⎟
⎠
⎤
⎥
⎥
⎥
⎦
= det 
⎛
⎜
⎜
⎜
⎝
∂u 
∂w
∂u 
∂z 
∂v
∂w
∂v
∂z 
⎞
⎟
⎟
⎟
⎠
det 
⎛
⎜
⎜
⎜
⎝
∂w
∂x 
∂w
∂y 
∂z 
∂x 
∂z 
∂y 
⎞
⎟
⎟
⎟
⎠
= ∂(u, v)
∂(w,z)
∂(w,z)
∂(x, y)
. (A.7) 
5. Using (A.2) and (A.5) we can write 
.1 = ∂(x, y)
∂(x, y) = ∂(x, y)
∂(z, y)
∂(z, y)
∂(x, y) =
(∂x 
∂z
)
y
( ∂z 
∂x
)
y 
. (A.8) 
This is also called the chain rule. Appendix A: Some Relations Involving Partial Derivatives 367 
6. We have 
. 1 = ∂(x, y)
∂(x, y) = ∂(x, y)
∂(z, y)
∂(z, y)
∂(z, x)
∂(z, x)
∂(x, y) = −∂(x, y)
∂(z, y)
∂(y,z)
∂(x,z)
∂(z, x)
∂(y, x)
= − (∂x 
∂z
)
y
(∂y 
∂x
)
z
( ∂z 
∂y
)
x 
, (A.9) 
where (A.3) has been invoked to write the third equation. Equation (A.9) is also 
called the cyclic rule. 
7. Consider the variables.(x, y,z, w) two of which are independent. We can write 
. (∂x 
∂y
)
w
= ∂(x, w)
∂(y, w) = ∂(x, w)
∂(z, w)
∂(z, w)
∂(y, w)
=
(∂x 
∂z
)
w
( ∂z 
∂y
)
w
. (A.10) Appendix B 
Legendre Transform 
Consider the function.y = f (x). Denote the slope of the tangent to it at the point. x 
by.s(x): 
.s(x) = d f (x)
dx . (B.1) 
Assume .s(x) to be a monotonic function of . x. In many applications it is required 
to describe the behavior of . f (x) in terms of its slope. A straightforward way to 
construct such a description could be to invert (B.1) to express . x in terms of . s and 
rewrite. f (x) in terms of. s to get the function. ˜f (s) in terms of. s, i.e. 
. ˜f (s) = f (x(s)). (B.2) 
This procedure, however, leads to problems when one wants to invert the relation. 
To see that, consider the function. f (x) defined by 
. f (x) = x 2 
2 , (B.3) 
so that 
.s = d f (x)
dx = x. (B.4) 
Replace. x by. s in (B.3) to obtain 
. ˜f (s) ≡ f (x(s)) = s2 
2 . (B.5) 
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer 
Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4 
369 370 Appendix B: Legendre Transform 
Let us now construct the inverse of. ˜f (s) = s2/2. We know that.s = d f (x)/dx and 
. ˜f (s) = f (x(s)). Hence 
. 
d f (x)
dx = d f (x(s))
ds 
ds 
dx =⇒ s = d ˜f (s)
ds 
ds 
dx 
. (B.6) 
Presently . ˜f (s) = s2/2. Hence .s = sds/dx which means .s = x + a where . a is a 
constant. We therefore get the inverse transformation of. ˜f (s) as. f (x) = ˜f (s(x)) =
(x + a)2/2 which is different from the function. f (x) = x 2/2 which was transformed 
to. ˜f (s). Indeed, if 
. f1(x) = (x + a)2 
2 , then s = d f1(x)
dx = x + a. (B.7) 
Hence . ˜f1(s) = s2/2. Thus both . f (x) and . f1(x) lead to the same function . ˜f (s) =
s2/2 in terms of their slope. Hence, if we are given . ˜f (s) = s2/2, we cannot say 
whether it corresponds to. f (x) or to. f1(x). 
We thus conclude that if . f (x) is transformed to . ˜f (s) such that . ˜f (s) = f (x(s))
then the inverse of the transformation from the variable. s to. x need not give. f (x). 
The reason for non-uniqueness may be traced to (B.6) which, for the purpose of 
constructing inverse transform, determines the relation between. x and. s as a solution 
of a differential equation (equation for.ds/dx) relating. s and. x and hence its solution 
is determined up to an arbitrary constant which is fixed by specifying some condition 
on the relationship. Different constants define curves parallel to each other as a result 
of which, knowing only the slope of tangents to them, it is not possible to say to which 
curve they belong. 
The said ambiguity is removed if we note that the intercept on a coordinate axis 
of a tangent to the curve . f (x) is different from that of a tangent of the same slope 
to the curve. f1(x) parallel to it. We therefore define the intercepts of the tangents on 
the .y-axis as the intended function of slope of .y = f (x). In order to find the said 
intercept, consider the curve .y = f (x) depicted in Fig. B.1. The tangent to it at the 
point .P ≡ (x, y) ≡ (x, f (x)) has slope . s. It intercepts the .y-axis at . Q. We know 
that the intercept of a line of slope.m passing through the point.(x1, y1) is.y1 − mx1. 
In the present case.(x1, y1) ≡ (x, y) ≡.(x, f (x)) and.m ≡ d f (x)/dx = s. Denoting 
the intercept.OQ of the tangent on the.y-axis by.G(s) we therefore have 
.G(s) = f (x(s)) − sx(s). (B.8) 
In the equation above,.x(s) stands for the expression of. x in terms of. s obtained by 
inverting the defining equation (B.1) of. s. The function.G(s) is called the Legendre 
transform of. f (x). Appendix B: Legendre Transform 371 
Fig. B.1 Legendre 
transformation 
Equation (B.8) yields 
. dG(s) = d f (x(s)) − sdx − x(s)ds = d f (x)
dx dx − sdx − x(s)ds 
= sdx − sdx − x(s)ds = −x(s)ds. (B.9) 
Hence 
. 
dG(s)
ds = −x. (B.10) 
This exhibits symmetry between. f (x) and its Legendre transform.G(s) in the sense 
that whereas the argument . s of .G(s) is slope of . f (x), the argument . x of . f (x) is 
negative of the slope of.G(s). 
Rewrite (B.8) as 
. f (x) = G(s(x)) + xs(x). (B.11) 
Noting that .−x is slope of .G(s), we see that the right side in the equation above is 
the Legendre transform of .G(s) which transforms it to the function of . x which is 
same as the function of which.G(s) is the Legendre transform. We can say that. f (x)
is the inverse of its Legendre transform.G(s). 
To demonstrate that the Legendre transforms of two functions, which may have 
same functional form in terms of their slope, are different, we return to the function 
. f1(x) defined in (B.7). It is straightforward to see that its Legendre transform is 
.G1(s) = −s2 
2 + sa. (B.12) 372 Appendix B: Legendre Transform 
Thus, unlike. ˜f1(x(s)), the Legendre transforms of. f1(x) depends on. a. The Legendre 
transform of . f (x) = x 2/2 which corresponds to the .a = 0 case of . f1(x) is thus 
different from that of. f1(x) corresponding to.a /= 0. Let us confirm that the inverse 
of.G1(s) in (B.12) is indeed the function. f1(x) in (B.7). To that end, using. s = x + a 
to express. s in terms of. x to obtain 
.G1(s(x)) + s(x)x = (x + a)2 
2 = f1(x). (B.13) 
This confirms our expectation. See also [ 1]. 
B.1 Relations Between Second Derivatives of a Function 
and Its Legendre Transform: Single Variable 
Transform 
Consider the function. f (x, y) of two variables. Let us construct the Legendre trans￾form.G(s, y) of. f (x, y) with respect to the variable. x with 
.s =
(∂ f (x, y)
∂x
)
y 
, (B.14) 
.G(s, y) = f (x(s), y) − sx, (B.15) 
.dG(s, y) = −xds +
(∂ f (x, y)
∂y
)
x 
dy, (B.16) 
and 
.x = − (∂G(s, y)
∂s
)
y 
. (B.17) 
In certain applications it is desired to express second partial derivatives of . G(s, y)
with respect to.s, y in terms of those of. f (x, y) with respect to.x, y. In the following 
we evaluate the said derivatives. 
1. Evaluation of.(∂2G(s, y)/∂s2)y . To that end, differentiate (B.17) with respect to 
. s keeping. y fixed to get Appendix B: Legendre Transform 373 
. (∂2G(s, y)
∂s2
)
y 
= − (∂x 
∂s
)
y 
= − [( ∂s 
∂x
)
y
]−1 
= − [(∂2 f (x, y)
∂x 2
)
y
]−1 
, (B.18) 
where in writing the last equation we have invoked (B.14). This is the desired 
relationship. In particular, it shows that the sign of.(∂2G(s, y)/∂s2)y is opposite 
to that of.(∂2 f (x, y)/∂x 2)y . 
2. Evaluation of.(∂2G(s, y)/∂y2)s. Equation (B.16) yields 
.
(∂G(s, y)
∂y
)
s 
=
(∂ f (x, y)
∂y
)
x 
. (B.19) 
Differentiate this with respect to. y keeping. s constant to get 
.
(∂2G(s, y)
∂y2
)
s 
=
[ ∂
∂y
(∂ f (x, y)
∂y
)
x
]
s 
≡ ∂((∂ f /∂y)x ,s)
(y,s) . (B.20) 
Evaluate the right-hand side above using 
. 
∂((∂ f /∂y)x ,s)
∂(y,s) = ∂((∂ f /∂y)x ,s)
∂(y, x)
∂(y, x)
∂(y,s)
, (B.21) 
and substitute the resulting expression in (B.20) to obtain 
.
(∂2G(s, y)
∂y2
)
s 
=
(∂2 f 
∂x 2
)−1 (
∂2 f 
∂x 2 
∂2 f 
∂y2 −
( ∂2 f 
∂x∂y
)2
)
. (B.22) 
3. Evaluation of .∂2G(s, y)/∂y∂s. Differentiate (B.19) with respect to . s keeping . y 
constant to obtain 
. 
∂2G(s, y)
∂s∂y =
[ ∂
∂s
(∂ f (x, y)
∂y
)
x
]
y 
= ∂((∂ f /∂y)x , y)
∂(s, y) . (B.23) 
Evaluate the right-hand side of the equation above using 
. 
∂((∂ f /∂y)x , y)
∂(s, y) = ∂((∂ f /∂y)x , y)
∂(x, y)
∂(x, y)
∂(s, y)
, (B.24) 
and substitute the resulting expression in (B.23) to get 
. 
∂2G(s, y)
∂s∂y =
(∂2 f (x, y)
∂x 2
)−1 (∂2 f (x, y)
∂x∂y
)
. (B.25) 374 Appendix B: Legendre Transform 
4. On combining (B.18), (B.22), (B.25) to get 
. 
∂2G(s, y)
∂s2 
∂2G(s, y)
∂y2 −
(∂2G(s, y)
∂s∂y
)2 
= − (∂2 f 
∂x 2
)−1 (∂2 f 
∂y2
)
. (B.26) 
We have thus at hand the relationship between the second derivatives of a function 
of two variables and those of its Legendre transforms with respect to one variable. 
We consider next the said relationships when both the variables are Legendre trans￾formed. 
B.2 Relations Between Second Derivatives of a Function 
and Its Legendre Transform: Two Variables 
Transformation 
To that end we again consider the function. f (x, y) and define 
.s =
(∂ f (x, y)
∂x
)
y 
, t =
(∂ f (x, y)
∂y
)
x 
. (B.27) 
The Legendre transform of. f (x, y) with respect to both the variables is defined by 
.G(s, t) = f (x, y) − xs − t y, (B.28) 
so that 
.dG(s, t) = −xds − ydt, (B.29) 
and 
.x = − (∂G(s, t)
∂s
)
t 
, y = − (∂G(s, t)
∂t
)
s 
. (B.30) 
The relationships between the second derivatives of.G(s, t) and. f (x, y) with respect 
to their respective arguments can be derived as follows. 
1. To evaluate of .∂2G/∂s2, differentiate first equation in (B.30) with respect to . s 
keeping. t fixed to get 
.
(∂2G 
∂s2
)
t 
= − (∂x 
∂s
)
t 
= − [( ∂s 
∂x
)
t
]−1 
. (B.31) Appendix B: Legendre Transform 375 
We can write 
.
( ∂s 
∂x
)
t 
= ∂(s, t)
∂(x, t) = ∂(s, t)
∂(x, y)
∂(x, y)
∂(x, t)
. (B.32) 
On evaluating the right-hand side above and substituting it in (B.31) we obtain 
.
(∂2G 
∂s2
)
t 
= − (∂2 f 
∂y2
)[
∂2 f 
∂x 2 
∂2 f 
∂y2 −
( ∂2 f 
∂x∂y
)2
]−1 
. (B.33) 
2. In similar way it can be shown that 
.
(∂2G 
∂t 2
)
s 
= − (∂2 f 
∂x 2
)[
∂2 f 
∂x 2 
∂2 f 
∂y2 −
( ∂2 f 
∂x∂y
)2
]−1 
. (B.34) 
3. Similarly the expression for.∂2G/∂s∂t turns out to be given by 
. 
∂2G 
∂s∂t =
( ∂2 f 
∂x∂y
)[
∂2 f 
∂x 2 
∂2 f 
∂y2 −
( ∂2 f 
∂x∂y
)2
]−1 
. (B.35) 
4. On combining (B.33), (B.34), (B.35) follows the relation 
. (∂2G 
∂s2
)
t
(∂2G 
∂t 2
)
s 
−
( ∂2G 
∂s∂t
)2 
=
[(∂2 f 
∂x 2
)
y
(∂2 f 
∂y2
)
x 
−
( ∂2 f 
∂x∂y
)2
]−1 
. (B.36) 
Reference 
1. R.K.P. Zia, E.F. Redish, S.R. McKay, Am. J. Phys. 77, 614 (2009) Appendix C 
Concave and Convex Functions 
A function . f1(x) which is such that its value at any point . c lying between .[a, b] is 
higher than that on the line joining the said two points is called a concave function. 
A function. f2(x) which is such that its value at any point. c lying between. [a, b]
is lower than that on the line joining the said two points is called a convex function. 
Referring to Fig. C.1, consider the point. A at.x = a, and the point. B at.x = b on 
the curves.y = f1(x) and.y = f2(x). Let. P be the point on the curves at.x = c lying 
between .A and .B so that the coordinates of . A, .B and .P are .(a, fi (a)), . (b, fi (b))
and.(c, fi (c)), (.i = 1, 2). The point.Q lies at.x = c on the line joining. A and. B, its 
coordinates being.(c, yc) where 
.yc = c − a 
b − a 
( fi (b) − fi (a)) + fi (a). (C.1) 
The conditions of concavity and convexity then read 
. f1(c) ≥ c − a 
b − a 
( f1(b) − f1(a)) + f1(a), (C.2) 
and 
. f2(c) ≤ c − a 
b − a 
( f2(b) − f2(a)) + f2(a). (C.3) 
A useful way of writing the conditions above is to write. c as 
.c = (1 − θ)a + θb, 0 ≤ θ ≤ 1. (C.4) 
The (C.2) and (C.3) then assume the form 
. f1((1 − θ)a + θb) ≥ (1 − θ) f1(a) + θ f1(b), (C.5) 
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer 
Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4 
377 378 Appendix C: Concave and Convex Functions 
Fig. C.1 The figure on the left depicts a concave function. f1(x) whereas that on the right depicts 
a convex function. f2(x)
and 
. f2((1 − θ)a + θb) ≤ (1 − θ) f2(a) + θ f2(b). (C.6) 
The question is, given a function, how to determine whether it is concave or convex 
in a given domain. The answer to it is provided by the criterion based on the sign of 
the second derivative of. fi (x). To that end consider the concave function. f1(x). Let 
.a = x,.b = x + δx in (C.5) to obtain 
. f1(x + θδx) ≥ f1(x) + θ( f1(x + δx) − f1(x)). (C.7) 
Taylor expand. f1(x + θδx) and. f1(x + δx) − f1(x) to get 
.(δx)
2 θ(1 − θ)
d2 f1(x)
dx 2 ≤ 0. (C.8) 
Since.0 ≤ θ ≤ 1 it follows that, if. f1(x) is concave then 
. 
d2 f1(x)
dx 2 ≤ 0. (C.9) 
It can similarly be shown that if. f2(x) is convex then 
. 
d2 f2(x)
dx 2 ≥ 0. (C.10) 
Though we do not prove it, the converse of the results proved above also hold. Appendix D 
Some Combinatorics Formulas 
In this appendix we address the problem of finding the number of different ways of 
distributing . L identical objects, called balls, in .N distinguishable boxes subject to 
the condition that not more than .P balls are in one box. This means the maximum 
number of balls that can be accommodated in .N boxes is when each is filled to its 
capacity of holding.P balls i.e. we must ave 
.L ≤ N P. (D.1) 
Clearly, there is only one way of distribution when.L = N P. 
Let the boxes be numbered .1, 2,..., N and let .pi denote the number of balls in 
the.ith box such that 
. ∑
N
i=1 
pi = L , 0 ≤ pi ≤ P. (D.2) 
The set.(p1, p2,..., pN ) denotes an ordered set in which there are.pi balls in the. ith 
box. Since the boxes are distinguishable, the set obtained by interchange of .pi and 
.pk (.pi /= pk ) is to be counted as a different set. The number of different sets of the 
values of the. pi’s satisfying the condition above, called configurations, are different 
ways of distributing. L balls in.N boxes such that there are at most. P balls in one box. 
We determine the number of configurations, denoted by.D(N , P, L), as follows. 
Since exchange of balls between the boxes having the same number of balls does 
not lead to a new set, we identify the boxes having the same number of balls as one 
group including the group having zero number. The number of distinct configurations 
is obtained as the number of different ways of choosing the boxes for each group. 
To compute the said number, let .nk be the number of boxes having same number . k 
of balls where, since maximum possible number of balls in a box is . P, . k can take 
values.(k = 0, 1, 2,... , P) such that 
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer 
Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4 
379 380 Appendix D: Some Combinatorics Formulas 
. ∑
P
k=0 
nk = N , ∑
P
k=0 
knk = L . (D.3) 
The desired number of configurations is obtained by counting first the number of ways 
in which we can choose the set of numbers.(n0, n1,..., nP ) ≡ {nk }P . Since the boxes 
are distinguishable, the number of ways of choosing a particular set. (n0, n1,..., nP )
may be obtained by choosing first.n0 boxes from.N boxes, followed by choosing. n1 
from the remaining.N − n0 and so on. The said number, denoted by. D(N , P,{nk }P )
is given by 
. D(N, P,{nk }P )
= N Cn0 
N−n0 Cn1 
N−n0−n1 Cn2 ··· N−n0−n1−···−nP−2 CnP−1 
= N!
n0!n1!n2!··· nP !
, ∑
P
k=0 
nk = N . (D.4) 
Total number of balls contained in the set.{nk }P is evidently 
.M({nk }P ) = ∑
P
k=0 
knk . (D.5) 
Different sets.{nk }P of the values of the. nk ’s, all satisfying the summation condition 
in (D.4), would yield different values of .M({nk }P ). Hence the value of . M({nk }P )
above need not be the number. L of the balls desired to be distributed. 
The desired number.D(N , P, L) is given by summing.D(N , P,{nk }P ) over those 
values of the. nk ’s which satisfy, in addition to the summation condition in (D.4), also 
the condition (D.5) with.M({nk }P ) = L: 
.D(N , P, L) = ∑
{nk }P 
D(N , P,{nk }P ), ∑
P
k=0 
nk = N , ∑
P
k=0 
knk = L . (D.6) 
The maximum possible value of . L is .Lmax = N P. Before outlining the procedure 
for evaluating (D.6), we find the sum of the number of distributions.D(N, P) for all 
possible values of. L up to its maximum possible value.N P. It is given by summing 
.D(N , P,{nk }P ) over all values of the. nk ’s satisfying the first summation condition, 
but not the second condition in (D.6): 
. DT(N , P) ≡ ∑
{nk }P 
D(N , P,{nk }P ) = ∑
{nk }P 
N!
n0!n1!n2!··· nP !
, ∑
P
k=0 
nk = N .
(D.7) Appendix D: Some Combinatorics Formulas 381 
To evaluate the expression above, invoke the multinomial summation formula 
. (x0 + x1 + x2 + ··· + xP )N 
= ∑
{nk }P 
N!
n0!n1!n2!··· nP !
x n0 
0 x n1 
1 ··· x nP 
P , ∑
P
k=0 
nk = N . (D.8) 
The choice .xk = 1 for all . k reduces the right-hand side of (D.8) to that in (D.7) 
yielding 
.DT(N , P) = (P + 1)N . (D.9) 
This is, as stated before, the sum of the number of ways of distributing .M balls 
(.M = 0, 1, 2,... , N P) in .N boxes such that each box can have at most .P balls in 
it. 
Our interest, however, is in the number of ways of distributing .L balls. That 
number is obtained by restricting the summation over those sets of values of.n'
k s for 
which (D.5) holds with.M = L. That end can be achieved by noting that if in (D.8) 
we let.xk = xk then 
. (
1 + x + x 2 + ··· + x P )N = ∑
{nk }P 
N !
n0!n1!n2!··· nP !
x n1+2n2+···PnP 
≡ ∑
{nk }P 
D(N, P,{nk }P )x M({nk }P )
. (D.10) 
Clearly, the coefficient of .x M({nk }P ) for .M({nk }P ) = L is the desired number 
.D(N , P, L): 
.D(N , P, L) = the coefficient of x L in f (x), (D.11) 
where. f (x) is the function on the left side of (D.10), called the generating function, 
. f (x) = (
1 + x + x 2 + ··· + x P )N . (D.12) 
The coefficient of.x L in. f (x) is 
.coefficient of x L in f(x) = 1 
L!
dL f (x)
dx L
|
|
|
|
x=0 
. (D.13) 
Hence 
.D(N , P, L) = 1 
L!
dL f (x)
dx L
|
|
|
|
x=0 
. (D.14) 382 Appendix D: Some Combinatorics Formulas 
Some properties of.D(N , P, L) are: 
1. If the number. L of balls to be distributed is less than the maximum number. P that 
can be accommodated in a box then, since maximum available number of balls is 
. L,.P in. f (x) can be replaced by. L: 
. f (x) = (
1 + x + ··· + x L )N . (D.15) 
In particular, if.L = 1, 
. f (x) = (1 + x)N . (D.16) 
Invoking (D.14), it is straightforward to see that 
.D(N , P, 1) = N . (D.17) 
This is consistent with the fact that if one ball is to be placed in one of the . N 
boxes, there are.N ways of choosing the box. 
2. When .L = N P, the only term in . f (x) that contributes in the expression (D.14) 
for.D(N , P, L) is the highest power term.x NP leading to 
.D(N, P, N P) = 1. (D.18) 
This is consistent with the fact that there is only one way to place.NP balls in. N 
boxes, namely, to place maximum of.P balls in each box. 
3. Since the maximum number of balls that can be placed in the said boxes is.N P, 
we must have 
.D(N , P, L) = 0, L ≥ NP + 1. (D.19) 
This can be seen to be consistent with the expression (D.14) of .D(N, P, L) as 
the maximum power of. x in. f (x) in (D.12) is.N P. 
4. Total number of distributions summed over all values of. L is given by 
.DT(N , P) = ∑
N P
L=0 
D(N , P, L) = ∑∞
L=0 
D(N , P, L), (D.20) 
where the last equation is due to (D.19). On using the expression (D.14) for 
.D(N, P, L), (D.20) assumes the form 
.DT(N , P) = [
exp(d/dx)
]
f (x)
|
|
|
x=0 
= f (x + 1)
|
|
|
x=0 
= (P + 1)N . (D.21) 
This is same as the result derived in (D.9) by another method. Appendix D: Some Combinatorics Formulas 383 
For present we evaluate.D(N, P, L) in (D.14). 
Evaluation of. D(N , P, L)
Let.L ≤ P. As shown in (D.14),.D(N , P, L) is the.Lth derivative of. f (x) at.x = 0. 
Since the .Lth derivative of .x L+k (.k ≥ 1) at .x = 0 is zero, the .x L+k (.k ≥ 1) terms 
will not contribute to the .Lth derivative of . f (x) at .x = 0. Due the assumption that 
.P ≥ L, we can therefore replace the polynomial of degree. P in the expression (D.12) 
of. f (x) by an infinite series to rewrite it as 
. f (x) = (1 − x)
−N , (D.22) 
which on substitution in (D.14) yields 
.D(N , P, L ≤ P) = (N + L − 1)!
L!(N − 1)! . (D.23) 
This is the number of ways of distributing. L indistinguishable balls in.N distinguish￾able boxes in each of which.P balls can be placed when.L ≤ P. 
The expression (D.23) may alternatively be arrived at as follows: Represent . L 
balls by points on a line and draw.N − 1 vertical lines at arbitrary positions between 
the points partitioning . L points in .N groups (see Fig. D.1). The space between the 
.(l − 1)th and the .lth partitions is the .lth box and the number .nl of points in that 
space is the number of balls in the .lth box. We thus have .L + N − 1 objects which 
we call positions from which we choose .N − 1 objects or positions to place . N − 1 
partitions. The number of ways of distributing. L balls in.N boxes may then be viewed 
as the number of ways of picking.N − 1 positions for the partitions from. N + L − 1 
positions. That number, given by. N+L−1CN−1, is same as the expression in (D.23). 
Since we do not need it, we do not evaluate.D(N , P, L) for.P < L.
box box box box 
Fig. D.1 Figure to evaluate.D(N, L, P),.P ≥ L 384 Appendix D: Some Combinatorics Formulas 
Exercises 
Ex. D. 1 Show that the number of ways of distributing . L identical balls in .N dis￾tinguishable boxes which can accommodate any number of balls such that 
there is at least one ball in a box is 
.D1(N , L) = (L − 1)!
(N − 1)!(L − N )!
. (D.24) 
Hint: One straightforward way of arriving at the formula above is to place 
one ball in each box so that the problem reduces to finding number of ways 
of distributing.L − N identical balls in.N boxes which is given by (D.23) 
with. L therein replaced by.L − N. Another way is to put.n0 = 0 in (D.8) 
so that 
. (x1 + x2 + ··· + xP )N 
= ∑
{nk }P 
N!
n0!n1!n2!··· nP !
x n1 
1 ··· x nP 
P , ∑
P
k=1 
nk = N . (D.25) 
Let.xk = xk so that the equation above reduces to 
. (
x + x 2 + ··· + x P )N 
= ∑
{nk }P 
N!
n0!n1!n2!··· nP !
x n1+2n2+···PnP , ∑
P
k=1 
nk = N . (D.26) 
The desired result is obtained by using (D.14) with. f (x) therein given by 
the left-hand side of (D.26) with.P → ∞: 
. f (x) = x N (1 − x)
−N . (D.27) 
Ex. D. 2 Show that the number of ways of distributing. L identical balls in.N distin￾guishable boxes which can accommodate any number of balls when there 
is given number.n0 of boxes having no ball is 
.C(N, L; n0) = (L − 1)!
(L − N + n0)!(N − n0 − 1)!
N Cn0 . (D.28) 
Hint: Since there are .n0 boxes having no ball, the problem reduces to 
finding number of ways of distributing. L balls in remaining.N − n0 boxes 
such that there is at least one ball in each of them. This number is given 
by (D.24) with.N → N − n0. The desired result (D.28) follows by noting 
that.n0 boxes can be chosen in. N Cn0 ways. Appendix E 
Cubic Equation 
Consider the cubic equation 
.x 3 + a2x 2 + a1x + a0 = 0, (E.1) 
where. ai ’s are real. Define 
.p = a1 − 1 
3 
a2 
2 , q = a0 − 1 
3 
a1a2 +
2 
27 a3 
2 , (E.2) 
and 
.A = −q 
2 + √
Δ, B = −q 
2 − √
Δ, (E.3) 
where 
.Δ = q2 
4 + p3 
27 . (E.4) 
The roots of (E.1) may then be shown to be given by 
. x1 = A1/3 + B1/3 − 1 
3 
a2,
x2 = A1/3 + B1/3 
2 + i
√
3 
A1/3 − B1/3 
2 − 1 
3 
a2 
x3 = A1/3 + B1/3 
2 − i
√
3 
A1/3 − B1/3 
2 − 1 
3 
a2. (E.5) 
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer 
Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4 
385 386 Appendix E: Cubic Equation 
The nature of the roots depends on the sign of.Δ as follows: 
1. If .Δ = 0 then (E.3) shows that .A, B are real such that .A = B. It then follows 
from (E.5) that in that case the roots are real and.x2 = x3 i.e. two of the roots are 
the same. 
2. If.Δ < 0 then (E.3) shows that. A and.B are complex and are such that.B = A∗. 
In that case.A1/3 + B1/3 is real and.A1/3 − B1/3 is imaginary. Hence (E.5) shows 
that all the three roots are real. 
3. If.Δ > 0 then (E.3) shows that. A and. B are real. In that case.A1/3 ± B1/3 are real. 
Hence (E.5) shows that.y1 is real and.y2, y3 are complex such that.y3 = y∗
2 . Appendix F 
Thermodynamic Properties of Blackbody 
Radiation 
The Blackbody radiation is characterized by the Stefan–Boltzmann law according 
to which the electromagnetic field energy inside a blackbody of volume .V kept at 
temperature. T is given by 
.U = αVT 4 
, α = 4σ/c, (F.1) 
where . σ is Stefan–Boltzmann constant. Starting from (F.1), we derive expressions 
for various thermodynamic quantities: 
1. The specific heat at constant volume is 
.CV = 4αVT 3 
. (F.2) 
2. Invert (F.1) to express. T in terms of. U: 
.T =
( U 
αV
)1/4 
(F.3) 
and integrate .(∂S/∂U)V,N = 1/T under the condition .S = 0 when .U = 0 to 
obtain 
.S = 4 
3 
α1/4 U3/4 V 1/4 
. (F.4) 
3. Using.(∂S/∂V )U,N = P/T , this leads to the following expression for pressure: 
.P = U 
3V . (F.5) 
4. Similarly, the relation.(∂S/∂N )U,V = μ/T implies.μ = 0. 
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer 
Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4 
387 Appendix G 
Harmonic Oscillator Number and Coherent 
States 
The set of operators. aˆ,. aˆ †, obeying the commutation relations 
.[ ˆa, aˆ †
] = 1, (G.1) 
along with. N ˆ = ˆa†a ˆ are said to be harmonic oscillator (h.o.) operators. Of interest to 
us are two sets of basis states in the Hilbert space of states on which these operators 
act: (a) the number states and (b) coherent states. 
Number States 
The number states.|n⟩ are the eigenstates of.aˆ †aˆ: 
.aˆ †
aˆ|n⟩, n = 0, 1, 2,... (G.2) 
The number states constitute complete orthonormal set: 
. ∑∞
n=0 
|n⟩⟨n| = I, ⟨m|n⟩ = δmn. (G.3) 
The action of. aˆ,.aˆ † on.|n⟩ is given by 
.aˆ|n⟩ = √n|n − 1⟩, aˆ †
|n⟩ = √
n + 1|n + 1⟩. (G.4) 
Since acting on a number state,. a ˆ generates the state of lower number and.aˆ † generates 
that of higher number, . a ˆ is called the h.o. annihilation and .aˆ † the creation operator 
respectively. 
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer 
Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4 
389 390 Appendix G: Harmonic Oscillator Number and Coherent States 
Coherent States 
A coherent state.|α⟩ is the eigenstates of the annihilation operator: 
.aˆ|α⟩ = α|α⟩, (G.5) 
where. α is a complex number. The right normalizable eigenstates of.aˆ † do not exist. 
The expression of.|α⟩ in terms of the number states is given by 
.|α⟩ = exp(−|α|
2 /2)
∑∞
m=0 
αm 
√m!
|m⟩. (G.6) 
Some properties of the coherent states and the representation of operators in terms 
of them are: 
1. The coherent states obey the completeness relation 
. 
1 
π
∫
|α⟩⟨α|d2 α = I. (G.7) 
2. The coherent states are not orthonormal. For, invoking (G.6) it is readily seen that 
.⟨β|α⟩ = exp(−(|α|
2 + |β|
2 )/2 + β∗α). (G.8) 
3. Using (G.6) it can be seen that 
. aˆ †
|α⟩ = exp(−|α|
2 /2)
∑∞
m=0 
√m + 1αm 
√m! |m + 1⟩
= exp(−|α|
2 /2)
∑∞
m=0 
mαm−1 
√m! |m⟩. (G.9) 
This may be rewritten as 
.aˆ †
|α⟩ = exp(−|α|
2 /2)
∂
∂α exp(|α|
2 /2)|α⟩. (G.10) 
4. If. ρˆ is a function of the h.o. operators then 
.ρ(α, α∗) = ⟨α| ˆρ|α⟩ (G.11) 
is the coherent states representation of. ρˆ. Appendix G: Harmonic Oscillator Number and Coherent States 391 
5. It is straightforward to see that the coherent states representations of. ρˆa ˆ and. aˆ † ρˆ
in terms of the coherent states are 
.⟨α| ˆρaˆ|α⟩ = αρ(α, α∗), ⟨α| ˆa† ρˆ|α⟩ = α∗ρ(α, α∗). (G.12) 
6. To derive the coherent states representations of. ρˆaˆ †, recall (G.10) to write 
. ⟨α| ˆρaˆ †
|α⟩ = exp(−|α|
2 /2)⟨α| ˆρ|
∂
∂α exp(|α|
2 /2)|α⟩
= exp(−|α|
2 ){exp(|α|
2 /2)}⟨α| ˆρ|
∂
∂α exp(|α|
2 /2)|α⟩
= exp(−|α|
2 )
∂
∂α exp(|α|
2 )⟨α| ˆρ|α⟩. (G.13) 
The last equation is due to the fact that since.exp(|α|
2/2)⟨α| is a function only of 
.α∗, it is like a constant for derivative with respect to. α. Hence 
.⟨α| ˆρaˆ †
|α⟩ = (
α∗ +
∂
∂α)
ρ(α, α∗). (G.14) 
7. Similarly it can be shown that 
.⟨α| ˆa ρˆ|α⟩ = (
α +
∂
∂α∗
)
ρ(α, α∗). (G.15) Appendix H 
Some Mathematical Formulas 
•
. ∑∞
n=0 
nk exp(−nx) = (−)
k dk 
dxk ∑∞
n=0 
exp(−nx)
= (−)
k dk 
dxk (1 − exp(−x))−1 
. (H.1) 
• The Gamma function.Γ (z) is defined by 
.Γ (z + 1) = zΓ (z), Γ (1) = 1. (H.2) 
.Γ (z) =
∫ ∞
0 
xz−1 exp(−x)dx, Re(z) > 0. (H.3) 
If.m is a positive integer or zero then 
.Γ (m + 1) = m!, 1 
Γ (−m) → 0. (H.4) 
.Γ
(1 
2
)
= √π. (H.5) 
• The approximate value of.N! when.N >> 1 is given by 
.ln(N!) = Nln(N ) − N . (H.6) 
This is Stirling’s approximation in its simplest form. 
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer 
Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4 
393 394 Appendix H: Some Mathematical Formulas 
• If.Re(α) > 0, 
.
∫ ∞
−∞
exp(−αx 2 + βx)dx =
/ π
α
exp(β2 /4α), (H.7) 
.
∫ ∞
0 
xm exp(−αx 2 )dx = 1 
2
√
αm+1 
Γ
(m 
2 +
1 
2
)
. (H.8) 
• The Riemann zeta function, denoted by.ζ(p), is defined by 
.ζ(p) = ∑∞
k=1 
1 
k p , Re(p) > 1. (H.9) 
Some values of.ζ(2 p) (p = 1, 2, 3) are: 
.ζ(2) = π2 
6 , ζ(4) = π4 
90 , ζ(6) = π6 
945 . (H.10) 
Some values of.ζ(2 p + 1) (p = 1, 2, 3) are: 
.ζ(3) = 1.202, ζ(5) = 1.036, ζ(7) = 1.008. (H.11) 
•
.
∫ ∞
0 
x p dx 
exp(x) − 1 = Γ (p + 1)ζ(p + 1). (H.12) 
• p > 1 
.
∫ ∞
0 
x p exp(x)dx 
(exp(x) − 1)2 = Γ (p + 1)ζ(p). (H.13) 
• p > 1 
.
∫ ∞
0 
x p−1dx 
exp(x) + 1 = (
1 − 2−p+1)
Γ (p)ζ(p). (H.14) Bibliography 
1. Balian Roger, From Microphysics to Macrophysics, Volume I (Springer-Verlag, 2007). 
2. Balian Roger, From Microphysics to Macrophysics, Volume II (Springer-Verlag, 2007). 
3. Callen Herbert B. Thermodynamics and an Introduction to Thermostatics (Wiley, 1985). 
4. Huang Kerson Statistical Mechanics (John Wiley & Sons, 1987). 
5. Kardar Mehran Statistical Physics of Particles (Cambridge University Press, 2007). 
6. Landau L.D., and Lifshitz E.M. Statistical Physics Part 1 (Elsevier, 2014). 
7. Pathria R.K. Statistical Mechanics (Buuterworth-Heinamann, 1996). 
8. H.E. Stanley Introduction to Phase Transitions and Critical Phenomena (Oxford University 
Press, 1971). 
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer 
Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4 
395 Index 
A 
Absolute temperature, 11 
Adiabatic constant, 27 
Available work, 82 
B 
Barometric formula, 217 
Bogoliubov–Born–Green–Kirkwood–Yvon 
hierarchy, 128 
Boltzmann entropy, 152 
Boltzmann equation, 117 
Born-Markov approximation, 357, 363 
Bose–Einstein 
condensate, 278 
condensation, 278 
Bose–Einstein distribution, 162, 256 
Boyle temperature, 318 
C 
Canonical ensemble 
classical 
ideal gas, 204 
entropy, 185 
quantum 
ideal classical gas, 229 
ideal quantum gases, 231 
Carnot engine, 5 
efficiency, 11 
formula, 11 
with any gas, 36 
with ideal classical gas, 28 
with van der Waals gas, 35 
Chemical potential, 43 
Bose gas, 275 
classical gas, 50, 206, 208 
Fermi gas at low temperature, 272 
Fermi gas at zero temperature, 265 
Clapeyron–Clausius equation, 306 
Classical particles, 230 
Coexistence region, 300 
equation of state, 303, 312 
Collision integral, 117 
Compression parameter, 325 
Concave functions, 377 
Configurational degeneracy, 226 
Convex functions, 377 
Critical exponents, 309 
van der Waals fluid, 334 
Critical point, 298 
D 
Dead state, 82 
Degrees of freedom, thermodynamic, 50 
Density matrix, 342 
Density of states, 241 
E 
Energy, relation with partition functions, 
185, 190 
Ensemble, 176 
canonical, 180 
grand canonical, 180 
microcanonical, 180 
Enthalpy, 54 
Entropy, 12 
Boltzmann, 139 
discrete energies, 155 
phase space distribution, 155 
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer 
Nature Switzerland AG 2024 
R. R. Puri, Modern Thermodynamics and Statistical Mechanics, Undergraduate Lecture 
Notes in Physics, https://doi.org/10.1007/978-3-031-54310-4 
397 398 Index 
Bose gas, 286 
Fermi gas at low temperature, 271 
Shannon 
concavity, 169 
continuous variables, 171 
discrete variables, 168 
statistical, 176 
classical, 176 
quantum, 177 
thermodynamic, 12 
time evolution, 352 
von Neumann, 344 
Equations of state, 47 
adiabatic 
classical gas, 30 
photon gas, 293 
quantum gas, 259 
Bose–Einstein condensate, 282 
classical gas, 27 
Fermi gas at low temperature, 271 
Fermi gas at zero temperature, 264 
proper form, 48 
van der Waals gas, 33, 323 
Equipartition theorem, 209 
Euler equation, 49 
Exact differential, 57 
Exergy, 82 
Extensive parameters, 37 
F 
Fermi–Dirac distribution, 165, 256 
Fermi energy, 264 
Fermi temperature, 264 
Free expansion, 25 
Fugacity, 190 
Fundamental equation 
energetic, 40 
entropic, 39 
G 
Generating function, 381 
Gibbs–Duhem relation, 49 
Gibbs free energy, potential, 53 
Gibbs paradox, 222 
Grand canonical ensemble 
classical 
ideal gas, 207 
quantum 
ideal classical gas, 234 
ideal quantum gases, 237 
Grüneisen parameter, 63 
H 
Hardcore potential, 321 
Heat capacity 
Fermi gas at low temperature, 271 
Bose gas, 283 
classical gas, 27 
electronic, two-level system, 253 
particles in a box, quantum, 253 
photon gas, 293 
Rotational 
diatomic molecules, classical, 212 
diatomic molecules, quantum, 250 
polyatomic molecules, classical, 213 
polyatomic molecules, quantum, 251 
Vibrational 
classical, 215 
quantum, 252 
Heat function, 54 
Heat Theorem, 24 
Helmholtz free energy, potential, 52 
H-Function, 134 
Homogeneous functions, Euler’s theorem, 
38 
H-Theorem, 135 
I 
Ideal classical gas under gravity 
Barometric formula, 217 
canonical partition function, 216 
temperature gradient, 220 
Impact parameter, 118 
Intensive parameters, 38 
Inversion temperature, 92 
van der Waals gas, 92 
Isobaric-isothermal distribution, 187, 200 
J 
Jacobian, 365 
Joule–Thomson process, 90 
L 
Lagrange multipliers, method of, 174 
Latent heat, 305 
Legendre transform, 370 
Lennard-Jones potential, 321 
Liouville’s theorem, 106, 107 
Lost work, 14 
M 
Massieu Functions, 55 Index 399 
Master equation, 358 
Maximum statistical entropy, postulate, 179 
Maxwell construction, 332 
Maxwell distribution, 98, 102 
Maxwell relations, 58 
Meyer function, 318 
Molecular chaos, assumption of, 117 
Multinomial summation formula, 381 
P 
Partition function, 182 
canonical 
classical, 185 
quantum, 185 
grand canonical 
classical, 190 
quantum, 189 
microcanonical 
classical, 183 
quantum, 184 
Perfect differential, 57 
Phase space distribution function, 105 
reduced, 109 
Phase transition 
continuous, 303 
first order, 303 
in Bose–Einstein condensation, 288 
lever rule, 301 
.P − −T coexistence curve, 298 
.P − −v coexistence curve, 300 
Planck’s law, 156 
Pressure 
in terms of canonical partition function, 
186 
in terms of grand canonical partition func￾tion, 191 
Q 
Quantum particles, 231 
R 
Riemann zeta function, 394 
S 
Sackur–Tetrode equation, 205 
Scattering cross section 
differential, 119 
total, 120 
Schottky anomaly, hump, 250, 251, 253, 254 
Second equation of state, 83 
Sommerfeld expansion, 268 
Spinodal curve, 307 
State variables, thermodynamic, 4 
Stefan–Boltzmann law, 387 
Stirling’s approximation, 393 
Streaming term, 115 
Sutherland potential, 323 
T 
TdS equations, 64 
Thermal wavelength, 202 
Thermodynamic limit, 179 
Thermodynamic observables 
fundamental set, 60 
primary set, 60 
Thermodynamic potentials, 51 
alternative formulation, 77 
Enthalpy, 54 
Gibbs Potential, 53 
grand potential, 54 
Helmholtz Potential, 52 
relation with partition functions, 198 
Thermodynamic stability 
from maximum entropy principle, 65 
from minimum energy principle, 70 
in terms of thermodynamic potentials, 73 
Transformation 
adiabatic, 5 
cyclic, 5 
isentropic, 24 
isobaric, 5 
isothermal, 5 
reversible, 5 
Triple point, 299 
V 
Van der Waals gas 
critical point, 324 
equations of state, 33, 323 
gas-liquid transition, 330 
law of corresponding states, 326 
partition function, 323 
Virial expansion, 317 
