“Programming in Python is an invaluable skill for psychology researchers,
for both making experiments and analysing the resulting data”.
Christopher R Madan, author of Memories That Matter: How We
Remember Important Things, Academia and the World Beyond book series
on post-PhD careers, and An Introduction to MATLAB for Behavioral
Researchers
Praise for previous edition
“An easy-to-read introduction. In a humorous style it introduces the reader
to programming in Python, picking them up where they are as experimental
psychologists. Very useful indeed!”
Ulrich von Hecker, Reader, Cardiff University, UK
“Edwin Dalmaijer provides an intuitive introduction into psychological
experimentation using Python libraries co-developed by the author himself.
Well-structured and easy to read, this book will quickly have you
programming, running, and analysing your own experiments using open,
modern tools”.
Tomas Knapen, Assistant Professor Cognitive Neuroscience, Vrije
Universiteit Amsterdam, The Netherlands
“Python is fast becoming the lingua franca of scientific research, and this
excellent and highly accessible book fills a much-needed gap for
experimental psychologists. The strong focus on developing genuinely
useful experimental code, and the comprehensive examples included, make
it an outstandingly useful resource not just for students, but for seasoned
researchers as well. Certainly the best (and funniest!) introduction to Python
I’ve come across”.
Matt Wall, Imaging Scientist, Imperial College London, UKPYTHON FOR EXPERIMENTAL
PSYCHOLOGISTS
Python for Experimental Psychologists equips researchers who have no
prior programming experience with the essential knowledge to
independently script experiments and analyses in the programming
language Python. This book offers an excellent introduction, whether you
are an undergraduate, a PhD candidate, or an established researcher.
This updated edition is on Python 3 (the most current version). It starts
by teaching the fundamentals of programming in Python and then offers
several chapters on scripting experiments (displaying stimuli, obtaining and
logging user input, precision timing, etc.) using the popular PsychoPy
package. The remainder of the book is dedicated to data analysis and
includes chapters on reading/writing to text files, time series, eye tracking,
data visualisation, and statistics.
Access to a companion website enriches the learning experience with
colour figures, example stimuli, datasets, scripts, and a portable Windows
installation of Python. This book assumes no prior knowledge, and its
informal and accessible tone helps readers with backgrounds in
experimental psychology and cognitive neuroscience to quickly understand
Python. It serves as a useful resource not only for researchers in these fields
but also for lecturers instructing on methodology and data analysis.
Python for Experimental Psychologists demystifies programming
complexities and empowers researchers to proficiently conduct experiments
and analyse their results.
Dr Edwin S. Dalmaijer is a Lecturer (Assistant Professor) at the
University of Bristol. He holds a DPhil from the University of Oxford, was
a postdoc at the University of Cambridge, and has authored Python
libraries, standalone software packages, teaching materials, and research
articles.PYTHON FOR EXPERIMENTAL
PSYCHOLOGISTS
A fun way of learning how to code your
experiments and analyses
Second Edition
Edwin S. Dalmaijer
With contributions from Rebecca J. Hirst and
Jonathan W. PeirceCover image: Getty Images © Prateek Chaurasia Second edition published 2025
by Routledge
4 Park Square, Milton Park, Abingdon, Oxon OX14 4RN
and by Routledge
605 Third Avenue, New York, NY 10158
Routledge is an imprint of the Taylor & Francis Group, an informa business © 2025 Edwin S.
Dalmaijer
With contributions from Rebecca J. Hirst and Jonathan W. Peirce The right of Edwin S. Dalmaijer to
be identified as author of this work has been asserted in accordance with sections 77 and 78 of the
Copyright, Designs and Patents Act 1988.
All rights reserved. No part of this book may be reprinted or reproduced or utilised in any form or by
any electronic, mechanical, or other means, now known or hereafter invented, including
photocopying and recording, or in any information storage or retrieval system, without permission in
writing from the publishers.
Trademark notice: Product or corporate names may be trademarks or registered trademarks, and are
used only for identification and explanation without intent to infringe.
First edition published 2017 by Routledge
British Library Cataloguing-in-Publication Data A catalogue record for this book is available from
the British Library Library of Congress Cataloging-in-Publication Data Names: Dalmaijer, Edwin
S., 1990– author.
Title: Python for experimental psychologists : a fun way of learning how to code your experiments
and analyses / Edwin S. Dalmeijer.
Description: 2. | Abingdon, Oxon ; New York, NY : Routledge, 2025. |
Includes bibliographical references and index.
Identifiers: LCCN 2024027209 | ISBN 9781032004808 (hardback) | ISBN
9781032000459 (paperback) | ISBN 9781003174332 (ebook) Subjects: LCSH: Psychology,
Experimental—Data processing. | Psychology, Experimental—Research—Computer programs. |
Python (Computer program language) Classification: LCC BF39.5 .D35 2025 | DDC 150.285/5133
—dc23/eng/20240703
LC record available at https://lccn.loc.gov/2024027209
ISBN: 9781032004808 (hbk)
ISBN: 9781032000459 (pbk)
ISBN: 9781003174332 (ebk)
DOI: 10.4324/9781003174332
Typeset in Galliard
by codeMantraAccess the Instructor and Student Resources: www.routledge.com/cw/dalmaijerCONTENTS
About this book
About Python
About the authors
1 Python
2 Variable Types
Make Some Noise
3 Creating and Presenting Stimuli
4 Processing Responses
Make Some Noise
5 Scripting an Experiment
Make Some Noise
6 Analysing Behavioural Data
7 Analysing Traces
8 Eye Tracking
9 Common Statistical Tests
Getting HelpAcknowledgements
References
IndexABOUT THIS BOOK
This work is for researchers in Experimental Psychology and Cognitive
Neuroscience, who have no previous experience with Python or
programming. It is suitable for students and staff and aims to provide a
basic working proficiency in Python. After working your way through this
book, you will have the knowledge and skills required to code experiments
and analyses.
A major problem in Psychology education is that students have very
little exposure to programming, even though most academic and industry
jobs involve scripting experiments and data analyses. As a consequence,
people spend a lot of time on manual data processing: selecting, sorting,
and moving data from one spreadsheet to another. This is an unfortunate
waste of time! If you want to work in psychological science and adjacent
fields, but don’t know how to code (yet), this book might just save a few
years of your life.
This book will teach you about installing Python, variables and
functions, displaying stimuli, making sounds, response collection, eye
tracking, trial structure, randomisation, loading files, combining data, doing
statistics, computational modelling, visualising data, creating publication￾ready figures, and more!ABOUT PYTHON
Python is an amazing programming language, originally developed by
Guido van Rossum, and improved and maintained by a large global
community. It sports an easily readable syntax, a huge user base, and
extensive functionality. It can be used for almost anything, including basic
calculations, detecting, and visualising black holes, live streaming your
hamster to the internet, and much, much more. Python is at the optimum of
usability and functionality, which means that you can learn how to do
actually useful stuff relatively quickly.ABOUT THE AUTHORS
Edwin S. Dalmaijer holds an undergraduate degree in Psychology from
Utrecht University in the Netherlands, where he also started (but never
officially finished) an MSc degree in Neuroscience and Cognition. He read
for a DPhil in Experimental Psychology at the University of Oxford, then
spent four years as post-doctoral Research Associate at the University of
Cambridge, and currently works as a Lecturer (Assistant Professor) at the
University of Bristol. Edwin writes software, teaches Python workshops,
and is on a desperate quest to teach his cat to code.
Rebecca J. Hirst completed her undergraduate degree in Psychology and
Cognitive Neuroscience and MSc in Psychology Research Methods at the
University of Nottingham, where she then obtained a PhD in Psychology.
She currently works as Science Officer at Open Science Tools and as
Postdoctoral Researcher at Trinity College, Dublin.
Jonathan W. Peirce is a neuroscientist, programmer, and dad. He holds an
undergraduate degree in Psychology from St Andrews University and a PhD
in Neuroscience from the University of Cambridge. After a postdoctoral
appointment at New York University, Jon was an Assistant, Associate, and
now Full Professor at the University of Nottingham. He is well known for
writing PsychoPy, free and easy software for psychology experiments that
is used in labs and classrooms all over the world. He is also the founder and
CEO of Open Science Tools.1
PYTHON
DOI: 10.4324/9781003174332-1
Python is a programming language. Not just any programming language, it’s
currently one of the most popular in the world. It’s used all over science and
industry because it’s easy to use, versatile, and has a cool name. You might be
leafing through this book thinking “Why should I invest in learning Python?” (Or
you might have pirated this book online and are now thinking “Why should I
keep reading this?”). Here are some answers to that question:
Python could be beneficial to your career. In Psychology, there are many tools,
like E-Prime and Presentation, that come with their own obscure programming
languages. These will be perfectly able to do most of what you want in your
research. However, you might find it hard to find employers who are interested in
your obscure skill. If you care about your CV, it could be better to learn a
language that more labs and companies are familiar with. Python is widely
adopted in academia, and even more so outside of it, for example in data science.
Being well versed in Python is thus likely to improve your employability!
One of the reasons Python is so popular is that it is very versatile. You can use
it to make computer games, do machine learning, and run websites. As a
researcher, this versatility means that you will be able to use Python to code your
experiments and automated analyses of your data. In addition, you could use it to
spy on co-workers through a webcam (Stop stealing my lunch, Karen!) or to do
exciting computer vision projects.
Another reason for Python’s popularity is its easy-of-use. Python scripts are
readable. Very readable. So readable, in fact, that some people say that reading
them is like reading English. While that is definitely an exaggeration, script
readability is one of Python’s strong points. It helps new users to pick up the
language relatively quickly.
Python’s popularity is a benefit in itself, because its large user base makes it
more likely to continue to be supported and that you can find help online. If you
run into an issue, there is a big chance someone else had the same problem, andthey might have already solved it for you. One great thing about the internet is
that it’s full of programming resources. Simply search for your problem (usually
by copying an error message into a search engine), and you are very likely to find
the solution on websites like Stack Overflow or programming forums.
Obviously, there are also downsides to using Python. Experienced
programmers will point out that it is a relatively slow language, and they have a
point: compared to “proper” programming languages like C and C++, Python is
sluggish. Fortunately, this isn’t typically a problem, because Python is still faster
than you need in most cases. Even when speed is an issue, for example when
processing lots of data, some clever soul will have found a way to solve them.
The NumPy library, which you will learn about later, is an example of this: it was
written in C, but it makes calculations in Python super fast.
Despite its appeal, some people will move on to other languages after learning
Python. Yet, even for them, Python was a good first language to learn the core
concepts of programming.
In sum, Python is great for beginners and for those who like a versatile
and user-friendly programming language.
Oh, did we mention? Python is free. It is open-source, which means that its
source code is public. Everyone can read it, improve on it, and download the
software without having to pay anything.
1.1 Installation
Python can be installed on a lot of different operating systems. These include
Windows, macOS, and almost every version of Linux. You can find installers on
python.org, and most Linux systems will likely have it pre-installed. Before you
start downloading stuff, read on to know what to install.
1.1.1 Versions
There are a few different versions of Python. Although they are similar, it does
matter which one you install. At the time of writing, Python 3 is the current major
version. There are several minor versions in use, like Python 3.10, 3.9, and 3.8,
each with some additional functionality. Finally, there are different patches under
the minor versions (like 3.10.5 or 3.8.10), each fixing bugs or improving security.
In the grand scheme of things, the differences between these versions are
relatively subtle and should not break any code. You should be able to run the
scripts in this book on any version from Python 3.7 and up, but they might break
under Python 4 (but it might be a long while before that is released).
Out in the wild, you might encounter software written in or for Python 2, for
which support officially ended on 1 January 2020. This is increasingly rare, but aconsequence of how the Python ecosystem works: it extends beyond just the basic
programming language, in the form of external packages or libraries. These are
collections of code that can do specific things, like help create cognitive
experiments. Libraries that were developed for Python 2 do not always play nice
with Python 3. Some of them have not been updated, because they were written
by enthusiasts who have stopped maintaining them or who are too busy to
perform a time-consuming upgrade. Remember that these people are volunteers
who have work, partners, children, friends, and lives. These are widely regarded
as more important than upgrading a Python library.
In sum, you should aim to download a Python 3 version. The specific minor
version (e.g. 3.9 or 3.12) is less important, so just go with the newest version
available on your platform. If you already know that you might be working with
external packages that do not work with specific Python versions, use that
information to guide your decision. However, if an older package would force
you to download Python 2.7, you might want to think about finding an
alternative, as the rest of the world is now well and truly upgraded.
1.1.2 Dependencies
There are external packages that extend Python’s functionality. Some of these
external packages run without any further ado. You install them, and they are
ready to use. Other require additional external packages to be installed. (This
rabbit hole can go rather deep, but we’ll aim to keep it as simple as possible!)
When one package requires another, this is a dependency for that package. In
this book, you will use the following external packages:
SciPy scipy.org A collection of libraries for science. Useful
for statistics and distributions
NumPy numpy.org Does fast calculations on multi-dimensional
arrays
Matplotlib matplotlib.org Advanced and versatile data visualisation
PyGaze pygaze.org Toolbox for eye-tracking experiments, with
an easy syntax. Depends on PyGame and/or
PsychoPy
PyGame pygame.org Amazing package for game development.
Perfect for experimenters, who basically
Name Website Descriptionmake boring games
PsychoPy psychopy.org Designed for psychophysics experiments;
has impeccable timing and great
functionality. Depends on pyglet and/or
PyGame, and on Python Imaging Library
(PIL) and NumPy, and many more
PIL, now
Pillow
python￾pillow.org
PIL (which lives on by the name of Pillow)
can be used for computer vision and images
pyglet pyglet.org Package for OpenGL multimedia. Required
by PsychoPy, which in turn is required for
PyGaze
If you are installing Python from the python.org website, you will need to
install the listed packages too. You can do so with a tool called “pip”.
Alternatively, “Anaconda” is a Python distribution that comes with many
packages pre-installed. Both options are further detailed in the next sections.
1.1.3 Anaconda
Instead of installing Python, and then installing all required external packages
separately, you could opt for installing Anaconda. This is a product developed by
a company named Anaconda (used to be known as Continuum Analytics), and
free for students, academics, and hobbyists; but commercial users might be
required to obtain a paid subscription. Before downloading the free version, you
should read the Anaconda Terms of Service to make sure that you are eligible.
Several of the packages that this book will introduce, like PsychoPy and
PyGame, are not a part of Anaconda. These will have to be installed separately.
Name Website DescriptionFIGURE 1.1 This is an example of an Anaconda you should not download
1.1.4 WinPython
WinPython (winpython.github.io) is a Windows-only solution that saves you from
having to bother with installing dependencies for this book. This beautiful piece
of work includes a lot of the packages required in this book and has the bonus
advantage of being portable. That means you can copy it to a USB or external
hard drive and run it from there. This is a great feature if you are a student, suffer
from a restrictive IT department, or do not want to install Python on all computers
you use. You can use it “anyplace, anywhere, anytime” (Kerner et al., 1984).
Another amazing WinPython feature is that there is a modified version that
comes with all the dependencies you need for this book. You can download it
from the companion website.
1.1.5 PsychoPy
Yet another option is to install the PsychoPy standalone package from
www.psychopy.org. In addition to being an experiment builder, this is also a
Python distribution that comes with most of the packages you will need for this
book pre-installed.
1.1.6 Installing Packages with Pip
Several of the options listed above require that you install additional packages in
order to fully use this book. The largest platform for Python packages is the
Python Package Index, or PyPI for short. Other packages might be self-hosted bytheir developer or hosted on GitHub. One easy tool to download and install
packages from these places is pip. This is a command line tool, which means you
can use it through the Command Prompt on Windows or through the Terminal on
Linux and macOS.
After you’ve installed Python, open a command prompt or terminal. If you’ve
installed Anaconda, use its launcher to start the Anaconda Command Prompt
specifically! To install the NumPy package, simply type the following:
python -m pip install numpy
Or, if you’re on Linux, use:
python3 -m pip install numpy
This should check if NumPy is already installed. If it isn’t, then it should
download the NumPy package and install it for your Python installation.
If you are working on a computer with several parallel installations of Python,
the above commands might not be specific enough. In order to install packages
into the right Python installation, you might have to specify its version number.
On Linux and maxOS, you can do so like this if you would like to install the
package NumPy for your Python 3.12 installation specifically:
python3.12 -m pip install numpy
On Windows, you would instead use:
py -3.12 -m pip install numpy
Note that all of the above commands should be executed in the (Anaconda)
Command Prompt or Terminal. In case something goes wrong there, and you
can’t troubleshoot the issue, there is another option you could try. This is to find
the Python installation that you are wanting to install a package in, and running
its python programme (e.g. “python.exe” on Windows). This will open a Python
interpreter, in which you can type Python code. To install a package in an
interpreter, use the following Python code:
import subprocess, sys
subprocess.call([sys.executable, "-m", "pip", \
⌴⌴⌴⌴"install", "numpy"])
This is a slightly roundabout way, in which you use the Python installation of
your choice to call itself, and then use its own pip to install a new package (in this
case NumPy). This is intended as a last resort, if none of the options listed above
worked for you.1.2 Terminal and Interpreter
Even now that you have an installation up-and-running, you might still have no
clue where to start. Time to get hands-on!
First, you should find the “Terminal”. This is called the “Command Prompt”
on Windows, but we will be referring to that as “terminal” too, for simplicity.
Whatever operating system you use, you can find the terminal (or command
prompt) in the list of installed software. On Windows, hit the Start button, then go
to “All Programmes”. On Apple’s macOS, open the finder and click on
Applications. On Linux, things vary between distributions, but you can usually
access an overview of installed applications by clicking on an icon in the dock
(e.g., on Ubuntu it’s the icon with a 9-square grid).
FIGURE 1.2 This is a Python interpreter
Alternatively, you can find the terminal by searching for it. On Windows, use
the search field in the Start menu/bar (remember to type “command prompt”). On
macOS, use Spotlight. On Linux, use whatever search option your distro has (e.g.
on Ubuntu, you can find one under “Activities” or in the applications overview).
The terminal looks like a window with minimal text. The background colour is
black on Windows and Linux and white on macOS (unless you default settings
were changed). The first line might indicate your user name and/or location (e.g.
“C:”, which is a folder on your computer).
Now that you have opened a terminal, you can type python (or python3 on
some Linux distributions) and then press Enter. This should access a Python
interpreter. You can check if it worked by reading the text that has nowappeared. It should mention “Python”, your version number and the current date
and time. You should make sure the version number starts with a “3”.
If you installed PsychoPy Standalone, Anaconda, or WinPython, accessing
Python interpreters works slightly differently. On PsychoPy Standalone, run the
application from your operating system, and then launch a new code editor
window (running the code should happen in an interpreter). If you are using
WinPython, simply open the WinPython folder and open WinPython
Interpreter.exe. With Anaconda, start Anaconda Command Prompt from the
Anaconda launcher.
In the first chapters of this book, you will primarily use the interpreter. It’s a
great tool to get to know the basic concepts. Once you get to the point of writing
actual scripts, the book will switch to using a script editor.
1.3 Editor
A script editor is a bit like Open/LibreOffice Writer or Microsoft Word: it allows
you to write text and typically has features that make this easier (such as syntax
highlighting). Code editors can be very complex or very simple. In fact, you
could write scripts using Notepad on Windows (or equivalent simple text editors
on other platforms).
If you installed basic Python, it automatically comes with IDLE, the
Integrated DeveLopment Environment. This is a simple editor but works just
fine. There are also more generic editors, like Notepad++, a wonderful open￾source editor that is simple and easy to use; Microsoft’s Visual Studio, a more
complex but well-equipped platform (just make sure that free Community Edition
is licensed for your purposes); and JetBrain’s PyCharm, another more advanced
editor (the Community Edition is open source and licensed to use for almost all
purposes). A rather exceptional code editor for Python is Spyder. It works on all
platforms and is actually included with both Anaconda and WinPython. So if you
have installed either of those, you already have it.
Spyder has some very useful options. First, it sports a familiar interface for
people with experience in Matlab, or with R Studio, the NetBeans IDE (for Java,
PHP, C, and C++), or with the Java Editor. This is also an advantage for novice
programmers, who will later be able to switch to other editors more comfortably.
Another advantage is that Spyder has its own built-in interpreters (called
consoles). This means you write and run scripts within Spyder, which is a feature
you might come to find useful. Finally, Spyder is highly customisable. I usually
set the editor’s background colour to black, for extra nerd credibility. And on
Wednesdays, I set the text colour to pink.One of the most important reasons for using a more advanced code editor is
their code introspection. While you type, your editor checks your code for errors.
It will also automatically provide documentation for the functions you are typing.
Spyder does all these things and is free and open source!
FIGURE 1.3 This is the Spyder code editor. It would have been in a cool colour scheme, but
you can only see the greyscale version2
VARIABLE TYPES
DOI: 10.4324/9781003174332-2
Variables are very important in programming. Before learning about what
they are and how to use them, perhaps it would be good to get some
intuitive feeling for them. In the following chapters, you will play around
with all sorts of variable types to get a hang of things.
2.1 Numbers
Numbers can be represented in different ways. The most notable difference
is between integers and floating points. An integer is a number without a
fractional part, for example, 10, 0, or −5. A floating point, or float, is a
number with a fractional part, such as 1.23, −99.9, or 1.0.
Let’s start with the good news: you won’t normally have to worry about
the distinction between 1.0 and 1. In addition, unlike some other languages,
Python isn’t particularly fussy about numerical data types. This means it
will understand that when you divide two integers, say 3/2, you expect the
fraction 1.5 to be the outcome. From this perspective, it seems like you
don’t have to care about integers or float!
Now the bad news: the difference between integers and floats is actually
important, and Python won’t always behave as you expect. There are many
reasons for this, including that integer divisions do not always automatically
result in floats, and that floats are actually more complex than they seem
(it’s not just 1.5 to a computer!). Furthermore, sometimes floats just aren’t
appropriate. For example, when creating images or presenting on a
computer screen, there is no such thing as half a pixel. Such indivisible
units shouldn’t typically be represented with floats.The above might be a bit confusing, and we won’t go into the details to
avoid further confusion. The point for now is to be aware of what type of
numerical value you’re using.
2.1.1 Integers
Let’s start actually using these concepts. Fire up a Python interpreter and
start typing:
1 + 3
Expected result, right? 1 + 3 = 4. Now let’s try subtraction:
5 - 3
3 - 5
This should also be an expected result to you. Five minus three does indeed
equal two. And three minus five equals minus two. Let’s move on:
3 * 2
Brilliant, Python can do multiplication. Would it be able to do
exponentiation as well? Let’s try 3
2
(the square of three, or three to the
power of two):
3 ** 2
The syntax might seem a bit weird, with the double asterisk. You might be
used to exponentiating with a circumflex, ^, for example in spreadsheet
editors (LibreOffice Calc or Microsoft Excel) or Matlab. In Python, the
circumflex is used as a different operator (you will learn about it later on),
so don’t use it for exponentiation!
All right, now let’s check out division:
5 / 3
From version 3, Python automatically switches to floats if the answer to a
division is a fraction. That’s why you’re getting 1.6666666666666667. In
many circumstances, this is exactly what you want.
In some circumstances, you might like to be more exact. Specifically,
five divided by three is one, with a remainder of two. To get this result, you
can use Python’s integer division:5 // 3
When you use the double division operator, Python throws away the
remainder. In this case, that leaves you with 1. To report the remainder, use
the % operator:
5 % 3
So 5 // 3 = 1, and 5 % 3 = 2. But also 5 / 3 = 1.6666666666666667, which is
a float. Let’s look at those next!
2.1.2 Floats
We want to calculate how much 5 / 3 is, but we would like the answer to be
an approximation rather than an exact answer. For this, we can use floats:
5.0 / 3.0
Boom! 5.0 / 3.0 = 1.6666666666666667. A cool thing about floats is that
they are contagious. If you use only one in your calculation, the answer will
automatically be a float. Example:
5 / 3.0
One thing to note about floats is that they are imprecise. For example,
consider the sum (5/3)*2. Think about what the outcome should be and then
run the code:
(5.0 / 3.0) * 2.0
Note that the answer is 3.3333333333333335 (note the 5 in the end). Maybe
this doesn’t rouse your suspicion, because it could be that things are
rounded in between: 5.0 / 3.0 is 1.6666666666666667 and then
1.6666666666666667 * 2 = 3.3333333333333335. Now consider that the
above is the same as 10/3. So an equivalent is
10.0 / 3.0
This still results in 3.3333333333333335! If you’re not a computer, you
probably expected the outcome to be 3.3333333333333333. This
discrepancy comes from the fact that floats are only approximations of
numbers. Storing numbers with a high precision puts a high demand on acomputer’s memory. Hence, people have developed clever compromises
that store numbers with decent (but not exact!) precision, without requiring
too much memory. As a consequence, floats are not always the exact
number you think they ought to be.
Now that you understand what a float is, you can use them in
exponentiation. Why is that useful? Consider the following:
3.0 ** 2
9 ** 0.5
Did that blow your mind? The square root of a number can be written in
exponent notation! This is SO exciting!
Remember the Pythagorean theorem? In a right-angle triangle, the
square of the hypotenuse (side opposite the right angle) is equal to the
summed squares of the other two sides. You can write this as a
2 + b
2 = c
2
.
The square root of c
2 will give you the length of the hypotenuse, so you can
write c = √(a
2 + b
2). Let’s say a = 3.0 and b = 4.0 and try this in Python:
(3.0**2 + 4.0**2) ** 0.5
BOOM! You got this number thing down!
2.2 Assigning Variables
Variables are a key concept in programming. In fact, variables form the
building blocks of all your future scripts. They act like labels that you can
assign to underlying data. Variable names can contain letters (upper and
lower case), some characters (such as underscores), and numbers; but they
must always start with a letter. For example, you can make a variable with
name test to refer to the number 5, like so
test = 5
You can now use this variable to do all sorts of freaky stuff. You could, for
example, use it in calculations:
test - 3
test + 5
test + testAs you can see, using it in calculations does not actually change the
variable. If you would want to reassign it a different value, simply overwrite
it:
test = 4
If you want to know the current value of a variable, simply type its name in
the interpreter and press Enter.
test
You can also change variables by referencing themselves:
a = 2
a = a + 1
You can even create new variables based on the values of others!
a = 2
b = 3
c = a + b
You can make it even more confusing and define one variable by using
another:
a = 2
b = a
Be wary that both variables (a and b) now could point to the very same data
(2). This may seem like an unimportant side note now, but it will prove to
be important when you learn about lists.
2.3 Booleans
Booleans are named after the logician George Bool, who approached logic
as though it was a type of algebra. He formalised the logical operations that
we now know as AND, OR, and NOT. Logic operations can produce one of
two results: True or False, which can also be denoted as 1 and 0.
These operations are built into practically all electronic circuits and are
an essential part of programming. It is imperative that you learn how to
implement them and that you sacrifice a goat to George Bool to honour his
legacy. (Note: don’t actually sacrifice a goat. Goats are amazing animalsand should be left alive. If you feel like sacrificing something, please
sacrifice some lettuce to a goat. In Bool’s honour, of course.)
Before you go on to start your own lettuce-sacrificing Bool fan club, you
should probably find out how Booleans work. Type the following into an
interpreter:
a = 1
b = 1
a == b
The result should be True, indicating that the variables point to equal
values. Note that while “=” means “assign this value to this variable name”,
“==” means “equals”. This is different from what you are used to, because
normally “=” means “equals” and “==” does not mean anything. It is
important to remember this difference, because you will at some point write
“a = b” where you intended to write “a == b” and that mistake will likely
crash your script. (This is not a dunk on you; experienced programmers do
this all the time.) Let’s move on:
a = 1
b = 2
a == b
The result is now False. We could also ask Python whether a “does not
equal” b:
a != b
This is True, because a and b do not point to equal values. You can also
directly use True or False in your code:
a = True
b = False
c = True
This allows you to use logic operators, such as AND (&) and OR (|):
a & b
a | b
The first tests whether both variables are True and returns True if they are.
The second tests if either variable is True and returns True if one or both
are. There is another operator, the exclusive or (XOR, ^), which testswhether two Booleans are the same and returns True only if they are
different:
a = True
b = False
c = True
a ^ b
a ^ c
The XOR operation is True for the first test (a ^ b), but not for the second
(a ^ c). Contrast this with the OR, which is True in both cases:
a | b
a | c
Note that Booleans can be used with normal mathematical operators, but
then the values True and False will be interpreted as 1 and 0.
True + True
True - True
True + False
3 * True
In most contexts, these operations do not make a lot of sense: Multiplying
True by three does not make it any more True.
Another cool thing about Python is that you can use English words to do
the same things as the symbolic operators. You can check if variables are
equal:
a = 1
b = 2
a is b
a is not b
You can also use written logical operators:
a = True
b = False
a and b
a or b
not a
2.4 LettersSome situations call for using text, for example when you want to present
instructions to participants. In Python, a text is referred to as a string. These
are defined by using either single or double quotation marks. Python also
provides a number of built-in functions to easily manipulate strings, as you
will soon see!
2.4.1 Strings
Time to define your first string. Type the following into an interpreter:
a = "Hello World!"
b = 'Hello World!'
Although you have used two different kinds of quotation marks, the
resulting strings are identical:
a == b
The advantage of being able to use more than one type of quotation mark is
that you can use the other within the string:
a = "Programming is 'fun'..."
There are more characters that you can use within strings. Some of these are
useful for formatting:
a = "I love newlines.\nI wish I could marry one.\n\nSwoon..."
b = "TABS\tARE\tAWESOME\t!"
When rendered, \n produces a return (or a “newline”), and \t a tab (a bit of
whitespace).
You can use mathematical operators to combine strings:
a = "spo"
b = "on"
a + b
Or to multiply them:
a = "lala"
10 * a
But not to subtract or divide them, because that would not make any sense.2.4.2 String Functions
Functions have not been explained yet, but you will get to know them quite
intimately later on. A function is a collection of code that will make your
computer do something specific. Some functions are standalone things; you
can call them at any time without having to do anything more than typing
their name. One such function is print, which will simply show a value in
the interpreter:
print("Hello world!")
This may not look very useful to you now, but you will learn to appreciate
it.
Some functions are not independent, like print, but are associated with
a certain type of variable. Strings, for example, have a few of these built-in
functions. Programmers sometimes refer to these built-ins as methods. A
few examples:
a = "I love farts!"
b = "get away from me, stinky person."
a.lower()
a.upper()
b.capitalize()
The lower method will make all letters in a string lowercase, whereas the
upper method will make them all uppercase. This is great if you want to
emphasise things, or if you’re trying to talk to someone who doesn’t speak
the same language. The capitalize method will make only the first
character uppercase.
Some other funky string stuff:
a = "test"
a.center(10)
a.count("t")
a.replace("s", "x")
As you could see, the center method adds spaces to the front and back of
your string to centre the original string, and the number (10) indicates the
resulting string’s intended length. The count method counts the number of
occurrences of "t", or anything else you would like to count. The replacemethod can be used to replace one part of the string by another. This is very
useful if you want to convert files and need to change file names:
a = "example.jpg"
b = a.replace(".jpg", ".png")
print(b)
2.4.3 String Formatting
One thing you might have tried is combining a string with a number:
a = "I'm number "
b = 1
a + b
You will have faced a TypeError, because you can’t combine strings and
integers in this way. There are other ways to make this work, though. You
could use the str function, to turn your number into a string:
a + str(b)
This works but will turn into a hassle once things get complicated:
a = "Every "
b = " days, I brush my "
c = ". I like this."
a + str(30) + b + "finger nails" + c
A better alternative is to use string formatting. This allows you to put
placeholders in your strings that can later be filled with values. To replace
the previous example:
a = "Every {} days, I brush my {}. I like this."
print(a)
You can recognise the placeholders by the curly brackets, {}. Let’s try
filling them out:
a.format(30, "finger nails")
The format function after the string allows you to replace the string’s curly
brackets with actual values. The values are provided between round
brackets.Using curly brackets allows you to pass any type of variable to the
format function, and it will be added to the string in a default way. You can
exert a bit more control over this, by specifying what type of variable you
want to incorporate into your string. For example, you can force only
integers to be allowed by using the {:d} notation:
"The number is {:d}".format(2)
Note that this will not work with other variable types, not even floats:
"The number is {:d}".format("two")
"The number is {:d}".format(2.0)
You can use similar tricks to format fractions in strings. For example, you
might want to present a percentage with one or two decimals. You can do
this using {:.1f} or {:.2f}, respectively:
"The percentage is {:.1f}%".format(10.126)
"The percentage is {:.2f}%".format(10.126)
A typical use case for this is using print to send yourself messages while an
analysis is running. For example, you might want to report when a new data
file is loaded or what the number of lines in that file is.
2.5 Sets
Up until now, you have only seen single values (although strings can be
seen as a collection of individual characters). Sometimes it can be useful to
combine values together in a single set.
Think about a reaction-time experiment: a researcher collects one
response time in every trial. If you want to calculate the median response
time, it would be useful to collect all individual response times in a single
variable, rather than having one separate variable for each individual
response time. This allows for easier access and calculations.
Now imagine the researcher was also using an eye tracker. This device
can measure pupil size. It will produce lots of data; sometimes over 1,000
data points per second! If you want to store all these in a manageable
fashion, you simply cannot use a single variable per data point. It would be
more efficient to store all data points from one trial in a set. Of course, with
lots of trials, it could even be inefficient to use a single variable per trial. So
you will want to store the data sets of every trial into another set. You thenend up with a set (of all trials) that contains more sets (each of a single
trial), each of which contain a lot of data points (each data point being the
pupil size sometime during a trial). This is called nesting, and that feeling
of confusion you have right now will subside.
You can easily see this escalate, for example if the researcher decides to
add electroencephalography (EEG) recordings. With over 64 electrodes,
thousands of data points per trial, and hundreds of trials, you will end up
with sets of sets of sets of data! This “big data” might seem overwhelming
now, but you will get a grip on it later on. First you will need to learn about
the basic building blocks of Big Data: variables that can hold multiple
values.
2.5.1 Lists
Although some terms in programming might seem a bit weird, the name of
the list variable is quite self-explanatory. A list is simply a list of other
values. Remember how a variable is a reference to a value? A list is a
reference to a bunch of values. These values can be integers, floats, strings,
or any other variable type. Let’s see this in practice:
a = ['one', 'two', 'three']
The variable a is now a list (you can recognise it by the square brackets)
that contains the values "one", "two", and "three". If you want to use one
of the values, you will have to use its index. The index of a value is its
position in the list. That sounds simple enough, but Python has a little quirk
that could throw you off at first: it starts counting at 0. That means the index
number of the first value is 0. The index of the second value is 1, the index
of the third is 2, etc. To refer to a particular index, use the variable name
and the index between square brackets:
print(a)
print(a[0])
print(a[1])
print(a[2])
Simple enough, right? So why would Python start counting at 0? Well, it
makes sense on multiple levels. One of the reasons is that it allows you to
index by counting backwards. Let’s see what happens if we use −1 as an
index number:print(a[-1])
It accesses the last value! Counting backwards from 0 allows you to index
from the end of the list rather than from the beginning. There are situations
in which this can be very useful! (There are also situations in which
counting from 0 can be confusing. Ultimately, it’s just a design decision,
and not all programming languages follow zero-based indexing. That
doesn’t stop programmers from having strong opinions, though. If you’re
bored and want to start something, go to your favourite social media
platform and profess a strong like or dislike for 0-based or 1-based
indexing.)
Apart from accessing one index at a time, you can also index a whole
slice. You can do so by using the index of the first value you want to access,
a colon, and the index of the value after the last value you want to access.
For example, a[0:3] means “the values in variable a from index 0 to index
3 (not inclusive!)”:
a = [4, 5, 6, 7, 8, 9]
print(a[0:3])
Something you will see a lot later on is the concept of nested lists. A nested
list is a list that is contained by another list:
a = [ [10, 20, 30] ]
The first index of this lists contains the value of the nested list: [10, 20,
30]. This nested list can also be indexed:
print(a[0])
print(a[0][0])
print(a[0][1])
print(a[0][2])
Nesting can go on forever, but it is highly unlikely that you would want to
do that. An example of where nested lists are useful is in the numeric
representation of an image. You could represent the colour of each pixel by
a list of three values: one for red, one for green, and one for blue. You could
represent every horizontal line in the image as a list of nested [R, G, B] lists
(one for each pixel). You could put all these line-lists in a single list, which
would then be a good representation of the entire image.The following is an example of a 3 × 3 pixel image of a white (255, 255,
255) plus (‘+’) on a grey (128, 128, 128) background:
[[ [128,128,128], [255,255,255], [128,128,128] ],
⌴[ [255,255,255], [255,255,255], [255,255,255] ],
⌴[ [128,128,128], [255,255,255], [128,128,128] ]]
You could think of such a construction as a matrix. (Although be careful
with that terminology, as it can have a specific technical meaning. Here it’s
used in the more general sense.) You will learn about how to create and use
these a bit later on.
Lists, like strings, have a few built-in functions that can be used to
manipulate them. For example, the index method can find the index of a
value in a list:
a = ['a', 'b', 'c']
a.index('b')
There is also a method to reverse the order of a list:
a.reverse()
print(a)
If you want to remove values from a list, there are two methods to choose
from. The remove method allows you to choose a value, of which the first
occurrence should be removed. The pop method allows you to choose an
index, of which the value will be removed.
a = [10, 20, 30, 40]
a.remove(20)
print(a)
a.pop(0)
print(a)
Of course, there are methods to add values to a list as well. The first of
these is the append method, which allows you to add values to a list:
a = [10, 20, 30]
a.append(40)
print(a)
Another list-expanding method is the extend method. This is intended for
joining two lists together:a = [10, 20, 30]
b = [40, 50, 60]
a.extend(b)
print(a)
If you think append and extend seem to do the same thing, and are
interchangeable, you would be wrong. Have a look at the following
example:
a = [10, 20, 30]
b = [10, 20, 30]
c = [40, 50, 60]
a.append(c)
b.extend(c)
print(a)
print(b)
As you can see, the append method nested the second (c) list within first list
(a), whereas the extend method combined two lists (b and c) into a single
one.
At this point, it would be good to remember what was explained about
the nature of Python variables (see the Assigning Variables chapter): they
are not the values, they merely reference values. Let’s look at the following
example:
a = [1, 2, 3]
b = a
print(a)
print(b)
Both variables point to the exact same value. Neither of them contains a
unique copy of [1, 2, 3]. Now look at what happens if you change one:
a.append(4)
a.extend([5,6])
print(a)
print(b)
Both a and b changed! Ahh! This is probably not the kind of behaviour you
expected, nor that you would typically like to see. So just one more time,
for the people in the back: variables are references to values, and thus
changing the underlying values can affect more than one variable!In programming, we say that lists are mutable. This means that you can
change them if you want to. This also means that they can be accidentally
changed, like in the example above, so be careful!
There are ways to get around this issue. For example, you could use a
mathematical operator to extend a list:
a = [1, 2, 3]
b = a
a = a + [4, 5, 6]
print(a)
print(b)
Another alternative is to use the copy function, which we have to import
from the copy module (more on importing will follow later, just go with it
at this point). This will force Python to make a copy of the underlying
value, instead of having both variables point towards the same underlying
value:
from copy import copy
a = [1, 2, 3]
b = copy(a)
a.append(4)
print(a)
print(b)
2.5.2 Tuples
Lists are great, but you have seen some of the risks of using them on the
previous page: they are susceptible to accidental mutation. Although you
now know ways to avoid accidental changing, they do require you to pay
attention. If only there was some kind of list that cannot be changed, to
prevent you from accidentally changing it altogether…
Well, it must be your lucky day! Look no further, because here is the
immutable list-like variable: the tuple. You can create them by writing
values in between round brackets:
a = ('one', 'two', 'three')
print(a)Although it looks like a list, walks like a list, and smells like a list, it
definitely is not like a list! Just try appending something:
a.append('four')
Oh no, an error! Maybe you could change one of its values?
a[0] = 'zero'
HA! Puny mortal! You cannot touch it! The only thing you can do is
completely overwrite it:
a = ('zero', 'two', 'three')
The take-home message here is that lists can be changed, but tuples cannot.
However, all variables can be overwritten by simply redefining them. There
are further similarities between tuples and lists, namely in the count and
index methods:
a = [1, 1, 2, 3]
b = (1, 1, 2, 3)
a.count(1)
b.count(1)
a.index(2)
b.index(2)
So, when should you use tuples, and when lists? It is mostly up to personal
preference. In general, people use tuples when they know the values they
contain should remain constant. For example, the resolution of a computer
display should probably be the same throughout an experiment and maybe
the size of a particular stimulus too.
2.5.3 Arrays
All right, so now that you can make a list of values, let’s do some
calculations with them! Try adding one to a list of numbers:
a = [5, 6, 7]
a + 1Oh, that’s awkward…. You got an error, because lists do not work like that!
If you want to add one to each value in your list, you are going to have to
do it value by value:
a[0] = a[0] + 1
a[1] = a[1] + 1
a[2] += 1
print(a)
Two points to note here. The first is that “a[0] = a[0] + 1” is the same
thing as “a[0] += 1”. (The second option is just quicker to write.) The
other point is that manually adding one to each value is a hassle. It seems
like little work if you only have three values in your list, but imagine doing
this for an entire EEG dataset! Programming is supposed to make your life
easier, not to enable you to do manual labour in a cooler way.
Computations that involve a whole line of numbers are sometimes called
array calculations, and they can make your life very easy. To do them in
Python, you need to get acquainted with NumPy (Harris et al., 2020;
Oliphant, 2007).
NumPy is what people call an external package or library. It is not
included with the basic installation of Python and is created and maintained
by volunteers. Anyone can make external packages, and a lot of useful ones
are available. Think of them as apps on your phone: they were not there
when you first got it, but you can download them to add functionality. This
is both the beauty and the Achilles’ heal of Python: external packages can
be really useful, but they can also be hard to find, and some are an absolute
pain to install.
Fortunately, there are Python installations that contain all of the main
scientific libraries. They are called Anaconda, PsychoPy, and WinPython.
The instructions in the first chapter of this book should have helped you
download one of these. If you are using these installations, please do read
on. If not, make sure you install NumPy before you go on to the next
chapter!
2.5.4 NumPy Arrays
All right, time to create your first array. NumPy arrays can contain any
type of value you would like. They are very similar to lists in that sense.However, unlike lists, each array can only hold values of the same type: so
no mixing integers and strings, for example.
You can do calculations with NumPy arrays that contain numbers or that
contain nested NumPy arrays that contain numbers. You can easily make a
NumPy array out of a list:
import numpy
a = [1, 2, 3]
b = numpy.array(a)
print(b)
You can now use this array to do calculations with, like adding a value to all
elements at once:
b += 1
print(b)
You can index NumPy arrays in the same way that you index lists:
b[0] += 1
b[1:3] += 10
print(b)
Great! Now see what happens when you try other mathematical operations:
a = numpy.array([1, 2, 3, 4])
a - 2
a * 3
a / 2.0
You can even do this using two (or more) arrays:
a = numpy.array([1, 2, 3])
b = numpy.array([2, 4, 6])
a + b
b - a
a * b
b / a
One very important thing to note here is that the way these calculations are
performed is per point: a*b is equivalent to a[0]*b[0]; a[1]*b[1];
a[2]*b[2]. That this is an element-wise and not a matrix multiplication canbe confusing to some people. For example, if you’ve previously worked
with Matlab (a programming language to which NumPy is similar in a lot of
ways), you might expect the default for a*b to be a matrix multiplication.
There isn’t necessarily a better default option here; it’s just different.
There are tons of other cool things you can do with NumPy. These won’t
be discussed right now, but you will get a chance to play with NumPy in
later chapters.
2.5.5 Dictionaries
The final set you should learn about is called a dictionary, which is known
by the abbreviation dict within Python itself. You can think of a dict like an
actual dictionary, in that it has keys that can be used to look up a value,
much like words in a dictionary can be used to look up their meaning, for
example, in an English-Dutch dictionary the key “monkey” points to the
value “aapje”, and the key “banana” points to the value “banaan”. (You’ll
thank me for this highly practical example if you ever visit Amsterdam.)
In Python, these examples in a dict would look like the following:
english_dutch = {'monkey':'aapje', 'banana':'banaan'}
You can recognise the dict by its curly brackets and by the colon between a
key and its associated value. As for lists and typles, you use commas to
separate the entries.
A dict is somewhat like a list, in the sense that it is a variable that can
hold more than one value at a time. However, the way you index these
values is quite different! Take a look at this:
a = {0:1, 1:2, 2:3}
b = [1, 2, 3]
print(a[0], b[0])
print(a[1], b[1])
print(a[2], b[2])
Currently, variable a (a dict, recognise it by the curly brackets) seems like a
more elaborate version of variable b (a list). However, there is one big
difference: in a list you can access values by using their index number,
whereas in a dict this index is called a key. And keys can be any number or
string you would like them to be! Next example:a = {'banana':1, 'horse':2, 19:1, 3:'cookie'}
print(a['banana'])
print(a['horse'])
print(a[3])
print(a[19])
Cool, right? You can also add new entries to your dict after creating it:
a['answer'] = 42
print(a)
Using dicts can be very useful, for example if you want to store all data
from one participant into the same variable. You could create a dict with
keys “RT” for the response times and “accuracy” to indicate whether a
response was correct. Or you could create a dict for all data, with keys for
every participant. Each of these keys could point to the aforementioned
dicts for single participants, which had keys for all your measures:
data = {}
data['subject-1'] = {'RT':[300, 256, 115], 'acc':[1, 1, 0]}
data['subject-2'] = {'RT':[400, 512, 268], 'acc':[1, 0, 1]}
As you can see, dicts can contain any kind of value, including other (nested)
dicts.
2.6 Classes
Before we go on to the good stuff, there is one more type of variable that
you need to know. This is a very important one and a fundamental part of
the Python language.
Take a step back from programming for a second. If there is a window,
take a look outside. If not, try to find better accommodation, because
working without windows is awful. Can you see a car? And maybe another?
If you can’t, just imagine two different cars. (But don’t make them too
different!) The two cars are obviously similar: they both have four wheels, a
steering wheel, a motor, windows, etc. However, they are also obviously
different: they might have different colours, different types of wheels,
different motors, and so on.
You could think of the cars as two instances of the same class. They
were built by using the same general blueprint that dictates wheels go on
the bottom, lights on the front and the back, and that the steering wheelshould be inside (preferably at the front). However, the cars were built
using different types of wheels, different shapes of lights, and different
types of steering wheels (one could be covered in leather, and the other in
pink fluf). The blueprint is a car’s definition, whereas a car is a specific
realisation of the blueprint.
If you understand this example, you understand the basic principle of
object-oriented programming. In this style of programming, we would
refer to the blueprint as a class and to a specific car as an instance.
Instances can also be referred to as objects, hence the name “object￾oriented”.
In programming, objects can have properties and methods. Properties
are internal variables that define an individual instance’s settings (think of a
car’s colour). Methods are internal functions that determine what each
instance of a class can do (think of a car’s ability to drive).
In Python, all variable types are essentially objects. That is a bit of trivia
you will not likely use when programming, but it comes in handy when you
want to impress people at a dinner party:
Nerd 1: “I am such a programmer, I am acing Java.”
Nerd 2: “Screw Java, I’m learning Go – did you know Google made
that?”
Nerd 3: “I learned C++ in just 21 days!”
You: “Pfft, C++ is just a silly way to make C object-oriented. Did
you know Python was designed to be object-oriented? All variable
types are really just objects.”
(Be careful not to do this when more experienced programmers are around.
Escape by pointing somewhere, asking “Is that R2D2?”, and then making a
run for it.)
Python and most external packages offer really useful classes that can do
just about anything. Displaying stuff on the screen? There’s a class for that.
Registering keyboard input? There’s a class for that. Communicating to an
eye tracker? There’s a class for that. In the next chapters, we will explore all
of these.
2.7 FunctionsRemember how you were promised that after learning about classes, you
would get to do fun stuff? That was a lie. You need to learn about functions
first. These aren’t really a type of variable, but they are in a way. You don’t
have to worry about what they are precisely, but you should know that
functions are a very important part of any programming language.
A function is nothing more than a collection of code that does a specific
thing or a few specific things. If you think that’s a pretty vague definition,
you’re absolutely right. You can think about functions as descriptions of a
task, such as building a bird house. Such a task requires input, like materials
(wood, nails, and glue) and specifications (the house’s dimensions). It also
has an output: a bird house. The function itself would be a description of
how to build the bird house.
A common example of a real-life function is a cooking recipe. A recipe
tells you how to make a specific meal. Its inputs are ingredients, and its
output is your dinner. Let’s look at how the recipe for mashed potatoes is
defined:
make mash
inputs:
5 potatoes, 1 clove of garlic, 6 teaspoons of oregano
output:
mash
procedure:
1. mince garlic
2. wash potatoes
3. peel potatoes
4. boil potatoes for 20 minutes
5. mash potatoes
6. add garlic and oregano to mash
7. stir mash
As you might have noticed, some of the individual steps could be defined as
functions too. For example, the function “boil potatoes” has inputs (peeled
potatoes, water, and a pan), outputs (boiled potatoes and hot water), and a
procedure (“fill pan with water, put pan on stove, heat stove, wait for 20minutes”). This can happen in programming too: some functions will call
upon others to work.
As an exercise, let’s see how you could define the function to make mash
in Python:
def make_mash(n_potatoes, n_garlic=1, n_oregano=6):
⌴⌴⌴⌴potatoes = get_potatoes(n_potatoes)
⌴⌴⌴⌴garlic = get_garlic(n_garlic)
⌴⌴⌴⌴oregano = get_oregano(n_oregano)
⌴⌴⌴⌴garlic = chop(garlic)
⌴⌴⌴⌴potatoes = wash(potatoes)
⌴⌴⌴⌴potatoes = peel(potatoes)
⌴⌴⌴⌴potatoes = boil(potatoes, duration=20)
⌴⌴⌴⌴mash = smash(potatoes)
⌴⌴⌴⌴ingredients = [mash, garlic, oregano]
⌴⌴⌴⌴mash = stir(ingredients)
⌴⌴⌴⌴return mash
This might seem a bit weird to you, and it is. But there are a few things you
should note. The first important thing is a general observation: the function
make_mash calls on several other functions (e.g. get_potatoes and stir),
which have not been defined and are not part of the basic Python language.
For now, just assume that they are defined somewhere else.
Another important thing to note is how a function is defined in Python. A
function definition always begins with def. This is followed by the
functions name, in this case make_mash. The function name is always
followed by a set of round brackets. Within those brackets, inputs are
defined. These inputs are called arguments, and you will get back to those
later. The final part of the function definition is a colon, :.
All of the code that is part of a function is indented. You will learn more
about indentation in the If Statements section. For now, all you need to
know is that Python recognises all code that is part of a function by its
offset with regard to the function definition. The offset is four spaces in
front of each line of code that is part of the function.
At the end of the code, the function returns a variable: mash. This is the
output of a function, and it can be a single variable or a list of variables.Output variables can be numbers, strings, lists, tuples, classes, or even other
functions.
Using a function is referred to as calling a function. The general syntax
is like this:
output = function(input)
As an example, this is the syntax to call the make_mash function:
mash = make_mash(5, n_garlic=1, n_oregano=6)
This will call the make_mash function with input of five potatoes, one clove
of garlic, and six teaspoons of oregano. The output will be stored in a
variable named mash.
2.7.1 Arguments
Arguments are an important part of using functions, although they are not a
requirement. In theory, you could define a function that has no input
arguments. Arguments are variables whose names are defined within a
function definition. In the make_mash function, there is one argument:
n_potatoes. (We will get back to n_garlic and n_oregano in a bit.)
n_potatoes was created in the following line:
def make_mash(n_potatoes, n_garlic=1, n_oregano=6):
You might wonder why there is no value associated with n_potatoes, like
n_garlic and n_oregano. This is because the value is only assigned when
make_mash is called. If you want n_potatoes to be five, you call the
make_mash function like this:
mash = make_mash(5, n_garlic=1, n_oregano=6)
If you are really hungry and want to make mash with 10 potatoes, you call
the make_mash function like this:
mash = make_mash(10, n_garlic=1, n_oregano=6)
The value of n_potatoes is only assigned when you call the make_mash
function. This means it can be different every time. This is a crucial aspect
of functions: they help you automate a task but allow flexibility witharguments. You can use the same function to make very little or a whole lot
of mash, only by changing the arguments’ values.
In programming, providing values for arguments is often referred to as
passing an argument. Importantly, a call to a function will result in an
error if you do not pass all arguments.
2.7.2 Keyword Arguments
Keyword arguments are basically the same thing as arguments, with one
important exception: they have a default value. You can assign this default
value in the function definition, as was done with n_garlic and n_oregano
in the make_mash function:
def make_mash(n_potatoes, n_garlic=1, n_oregano=6):
The practical benefit of using keyword arguments is that you don’t have to
assign their values when you call a function. For example, the following
two calls to the make_mash function are equivalent:
mash = make_mash(5, n_garlic=1, n_oregano=6)
mash = make_mash(5)
As a result of having a default value, if you don’t pass any keyword
arguments, it will not cause an error. This is in contrast to arguments: if you
don’t specify an argument when calling a function, you do get an error.
It is useful to define sensible keyword arguments when you write
function definitions. This allows you to call the function without having to
bother with specifying every little detail, but it does keep the option to
bother with details open. In the make_mash example, this means that you
could rely on the default amount of garlic (1 clove), but if you really like it
(and don’t mind smelling of it), you could also throw in 6 cloves:
mash = make_mash(5, n_garlic=6)
Of course, mash is a silly example, but you will encounter more practical
examples of keyword arguments later in this book. When you do, think
about what type of argument you would have used. In addition, you might
want to think about whether you could only use keyword arguments. Is
there a benefit of using arguments?2.7.3 Local and Global Variables
Variables (including arguments and keyword arguments) are local to the
function that they were created in. That means that the variable potatoes
can be used throughout the entire make_mash function, but not outside of it.
This might sound trivial, but it’s not.
If you want a variable that was created within a function to be accessible
from outside the function (i.e. in the rest of your script), you have to return
it. This is why the definition of the make_mash function ends with return
mash. If this last line was not there, the function would have no output.
Consequently, you would not be able to use mash.
The reason that variables are local to a function is that they would
otherwise crowd your work space. Imagine a complicated function that
would use 100 variables within. If you have a script in which you call this
complicated function, you would have to make sure that none of your own
variables share a name with those created within the complicated function.
If one does, it will be overwritten, and your script might start behaving
weirdly.
Another option to share variables between your script and the insides of
functions is to declare variables global. This means variables will be
recognised in your script and also within functions. This is not
recommended, unless you have a good reason to do so. To declare a
variable global, include the following line in your script:
global mash
And the following in your function definition (don’t forget the indentation
with four spaces):
⌴⌴⌴⌴global mash
In general, it is recommended to be very careful with declaring global
variables. The cleaner and clearer option is to explicitly return the variables
that you need from inside a function.
2.7.4 Create Your First Function
After learning about functions, it’s time to define one yourself! This is an
important moment in your personal programming history, so savour it. Inthe Interpreter, type the following line:
def hello_world():
After typing the line, hit Enter and type the following line (don’t forget to
start the next line with four spaces!):
⌴⌴⌴⌴print('Hello World!')
Hit Enter twice and maybe a few times more for good measure. Now call
your own function by typing:
hello_world()
If you did everything correctly, "Hello World!" should have appeared in
the Interpreter. That was the result of your very first function! Congrats!
What you just did is to define a function named hello_world, which
takes no inputs and produces no outputs. It simply prints "Hello World!"
to the Interpreter.
2.7.5 Create Your Second Function
Let’s make things more exciting. Let’s create a function that does take an
input! You could create a function that prints "Hello World!" a specified
number of times. An argument within the function definition could be used
to allow you to specify how many times the function should print "Hello
World!", like so:
def hello_world(N):
where N is the amount of "Hello World!". As you might remember from
the chapter on Strings, you can multiply a single string by an integer
number to reproduce them. You can capitalise on this in your new function:
⌴⌴⌴⌴print(N * 'Hello World! ')
Now hit Enter twice and call the function!
hello_world(5)
You can also try to test the limits of your computer:hello_world(10)
hello_world(100)
hello_world(100000)
2.7.6 Create Your Third Function
As a final exercise in function definition, let’s create a function that not
only takes input but also produces output! This function will move beyond
the “Hello World!” examples from before and will actually do something
useful: check if a value is equal to 42.
The function will be named is_this_the_answer, and the input
argument will be named number. Type the following in the Interpreter and
hit Enter:
def is_this_the_answer(number):
Now, the crucial part of the function is to check if the input is equal to 42.
As you might remember from the section on Booleans, you can use a
double is-equal sign to compare to variables. The result will be True if the
variables are equal or False when they are not.
⌴⌴⌴⌴result = number == 42
result is a Boolean that indicates whether number was equal to 42. The
only thing left to do is to return result.
⌴⌴⌴⌴return result
Hit Enter twice and test your function:
is_this_the_answer(7)
is_this_the_answer(3.50)
is_this_the_answer(42)
is_this_the_answer('kittens')
You can also assign the returned value to a new variable:
result = is_this_the_answer(42)
print(result)
Note that you do not have to use the same variable name that you used
within the function. You can use any variable name you want! So the
following code is equally valid:a = is_this_the_answer(42)
print(a)
Pretty neat, huh?MAKE SOME NOISE
DOI: 10.4324/9781003174332-3
After learning about all those variable types, it’s time to do something
cooler! In this random intermezzo, you will learn how to make visual noise.
Random Numbers
In the previous chapters, you learned how to use NumPy arrays. But there is
more to NumPy than just array calculations! There is a beautiful random
module that allows you to generate random numbers:
import numpy
numpy.random.rand()
numpy.random.rand()
numpy.random.rand()
Just try it a few times, to make sure the numbers are actually random. If you
do recognise a pattern, you might actually be right. A computer’s random
numbers are produced by an algorithm that depends on a fixed number, a
seed. You can provide your own seed and see what happens:
numpy.random.seed(seed=14)
numpy.random.rand()
numpy.random.rand()
numpy.random.rand()
Seems to do the same, right? Now provide the exact same seed and do it
again:
numpy.random.seed(seed=14)
numpy.random.rand()
numpy.random.rand()
numpy.random.rand()The exact same “random” numbers came out! Why is this relevant?
Because it is important to realise that there is no such thing as truly random
numbers in a computer. They are pseudo-random. Whether this is a
problem depends on the circumstances. If you’re wanting to run a gambling
website, having predictable “random” numbers might not be wise…. But if
you’re just using them to create some visual static (like below), their
pseudo-random is just fine.
Noise
Visual noise is the grey snow you see when an old television isn’t set to a
proper channel. It is the visual analogue of the feeling you have in your arm
after sleeping on it. The individual snowflakes range from completely white
to completely black. If we assign values to these colours, we could say
white corresponds to 1 and black to 0. All numbers between 0 and 1
correspond to some shade of grey.
Using NumPy’s rand function, we can actually create a field of random
numbers. To do so, we only have to provide the width and height of this
field. Let’s try this with a field of 5-by-5 positions:
noise = numpy.random.rand(5, 5)
print(noise)
You can check the dimensions of a NumPy array by looking at its shape
property:
noise.shape
Of course, grey noise is a little boring. Why not make it coloured? You
might know that computers encode colours with three values: their red
component, their green component, and their blue component. If we want to
make a numerical representation of coloured noise, we will need to create
three random numbers per pixel. (A pixel is one coloured unit on your
screen: a combination of red, green, and blue.)
Although this may sound like a difficult problem, it’s surprisingly easy
to code. You can simply add another dimension in NumPy’s rand function:
rgb_noise = numpy.random.rand(5, 5, 3)
print(rgb_noise)Your field of 5-by-5 random pixels now has a depth of 3. This depth
represents the red, green, and blue values of each pixel.
Matplotlib
Now you know how to make a numerical representation of visual noise,
let’s turn it into an image! To do this, we will use Matplotlib (Hunter, 2007).
This is a library that can do very advanced plotting. For now, we will only
use its pyplot module. This contains an imshow function, which can
translate a field of numbers to an image.
To create the visual noise, you can use the same approach as before, but
now with a bigger field. What about 500-by-500 pixels?
import numpy
from matplotlib import pyplot
noise = numpy.random.rand(500, 500, 3)
pyplot.imshow(noise)
pyplot.show()
The last function shows the figure you made in an interactive window. If
you want, you can save it to your disk. Maybe show it to your grandmother.
“Look, granny, I can do programming!”
- “That’s nice, honey.”3
CREATING AND PRESENTING STIMULI
DOI: 10.4324/9781003174332-4
In this chapter, you will learn how to create some basic stimuli (text, shapes,
images) and how to present these on a computer display. You’ll also learn how to
manipulate images using some external libraries and how to make stimuli
“dynamic” (i.e. moving and interactive). To do this, you will write scripts in
which you will use classes from a package known as PsychoPy (Peirce, 2007,
2009).
PsychoPy can do pretty much anything you could need in a psychological
experiment. This includes presenting stimuli on a monitor; producing sound;
collecting responses from keyboards, computer mice, joysticks, and controllers;
communicating with eye trackers; logging data; and accurately timing events. It is
notable that other packages do exist for similar purposes, such as PyGaze
(Dalmaijer et al., 2014). Which package you choose is entirely up to you (or your
teacher, if you’re using this book in a course module). In this chapter, we’re going
to focus on PsychoPy, but the skills you learn here will help in extending your
knowledge enough to also try other packages!
Without delving too deep into software architecture, it is worth noting that
PsychoPy is built on top of a few other external packages (dependencies). This
means that it requires other packages to do what it does. For this reason, we
recommend installing standalone PsychoPy to create your first experiment. This
can be downloaded from https://www.psychopy.org/download.html (see Chapter
1 for installation instructions).
This isn’t to say that you can’t use PsychoPy in the other environments
introduced earlier in this book. For lots of reasons, many programmers prefer
those environments rather than PsychoPy’s inbuilt “Coder view” (introduced
shortly). Alternative environments offer lot more features and functionality
compared to PsychoPy Coder, but they also typically require that you install a
number of dependencies and configure your environment. Standalone PsychoPy
comes pre-equipped with most packages that you will need for a psychologyexperiment (including PyGaze!). This is why we like using PsychoPy Coder for
teaching: it saves a lot of time in setting up in the classroom.
3.1 Scripts
Unlike in previous chapters, where you punched some lines into an interpreter, in
this chapter you are going to create scripts to do your bidding. A script is nothing
more than a collection of lines, which will be executed one by one.
Programming languages that run scripts per line are called interpreted
languages. These differ from compiled languages, which pre-translate the entire
script before actually running it. Generally speaking, compiled languages are
quicker to run, but interpreted languages have other benefits. For example, scripts
written in an interpreted language could rewrite themselves while running. Think
about that while you read Stephen Hawking’s warning on artificial intelligence
(TL; DR: scary self-redesigning AIs will make humans obsolete).
Nowadays, most programming languages can be implemented both as
interpreted or compiled, so it’s not really a language-specific feature any longer.
Also, you could probably think of a way in which compiled languages could
rewrite themselves to also kill the human race. The real lesson here is that you
shouldn’t worry about the distinction between interpreted and compiled
languages too much!
3.2 The PsychoPy Coder View
When you first open PsychoPy, you will see three open windows: Builder view,
Runner view, and Coder View. In this book, we are going to focus on Coder View.
(For making experiments in Builder, see Peirce et al., 2022). The Coder view is
shown in Figure 3.1, it is made up of three sections, the Shelf, Source Assistance,
and Editor.FIGURE 3.1 This is PsychoPy Coder's interface
The Editor window is the most important of these sections; it is where we will
write our python scripts. To start a new script, you can select the new document
icon (if you hover over this, it will read “create new experiment file”). This will
create a new script in the Editor window named “untitled.py”. The “.py”
extension indicates that this is a python file. In general, it is a good idea to save
this with a new, unique, name before starting. Let’s save it as “stimuli.py”.
Below the Editor window is the Shelf. This Shelf consists of two tabs, the
Shell and the Output tab. The Shell is a place where you can type Python code to
test it out. However, variables created in the shell are not saved to a “global”
workspace. That is, unlike other development environments, you cannot access
variables created in your script in Editor from Shell, nor vice versa. The Output
tab is where any output (including important error messages!) will be generated
when you run your scripts.Finally, the Source Assistant window also consists of two tabs. The Structure
tab is intended to help us navigate large scripts, by showing us the functions and
classes that we have created in one condensed location. The File Browser tab is
intended to help us navigate where our current directory is. In this chapter, we
will focus less on the Source Assistant window – but it is good to know it is there.
3.3 The Window
Most experiments will involve presenting something on the screen. In order to
present visual stimuli on screen, we need a place for them to be drawn, this is
known as the “Window”. Note that the Window need not have the same
properties as the screen. A window can be smaller than your screen, for instance.
To set up your window in PsychoPy, you’ll need to start by importing the relevant
“module” from the PsychoPy library:
from psychopy import visual
psychopy.visual is a module that contains a wide breadth of visual stimuli, from
shapes to random dot kinematograms. Most importantly, the visual module
contains what we need to make a Window for drawing things in, the rather aptly
named “Window” class. Right, let’s make a window:
win = visual.Window(size=[1024, 768], fullscr=False,
⌴⌴⌴⌴units='pix', color=(0,0,0),
⌴⌴⌴⌴colorSpace='rgb', screen=0)
Here we have added several arguments to the window (in this book, we may refer
to arguments and parameters interchangeably, they essentially mean an
option/setting of the object we are creating):
size: size of our Window, in width and height.
fullscr: if the Window is fullscreen or not. It is highly recommended that
you set this to False whilst developing your experiment. If you set this to
True, and you have not yet enabled a way of escaping your experiment, it
becomes very easy to get trapped in your study (an infinite hell no
researcher wishes to endure).
units: The units to use for the window. Here we are using pixels; however,
it is worth noting that we could have used any number of units, and the unit
we choose will be inherited by all visual stimuli we draw to this window
(unless we otherwise state it in the “unit” parameter of that stimulus).
color and colorSpace: What colour to use for the window and what colour
space. (A note on colour spaces will follow in a minute.)screen: Which screen to present the window in, with numbering starting
from 0 (and counting up to the number of screens you have). This means
you could easily have a multiscreen experiment: you would just need to
make several windows with different screen numbers and then present
visual stimuli in those different screens!
It is also worth noting that we can have the line of code where we create our
window span over several lines. This works fine long as there is a level of
indentation for lines that follow the first. (As before, one level of indentation
equates to four spaces. More on indentation follows later in this chapter!) Press
run on your stimuli.py file. You should see, very briefly, a grey window appear
and then disappear – magical.
We’ve thrown in some lingo here: “Package”, “Module”, and “Class”. You can
consider Python packages as having a hierarchical structure. For instance,
“psychopy” is the package; it sits at the top of the hierarchy. PsychoPy contains
modules for doing different things, e.g. the “visual” module for drawing visual
things, the “sound” module for anything to do with sound. These modules can be
accessed using the dot operator, e.g. psychopy.visual or psychopy.sound.
Alternatively, you can directly import those modules, using from psychopy
import visual, sound. Each module has a number of “classes”. For instance,
visual contains things like Window, ShapeStim, and Image. Each class has its
own attributes and methods. For instance, an Image object has the attributes pos,
size, and image (for the position, size, image file to use in that object). It will
also have the methods .setPos(), .setSize() and .setImage(). Each allows
you to reset the attributes of the object. Several of these methods will come in
handy later, when we want to update the attributes of an object dynamically in
time.
3.3.1 Units and Colours in PsychoPy Windows
As you might have noticed, the Window class requires you to specify units. In
this case, we set it to 'pix', which stands for ‘pixels’. This is a straightforward
mapping, as pixels are a unit that your computer and monitor are familiar with.
However, using pixels comes with the caveat that it can result in stimuli of a
different physical size between monitors (the size of a pixel varies monitor to
monitor, depending on the screen’s resolution).
When selecting what unit to use for your stimuli, ask yourself this question: do
I need my stimuli to have the same physical size across monitors, or the same
relative size? More often than not, the same relative size is fine (i.e. same picture
could be presented on a widescreen gaming monitor or a small tablet, and itwould be scaled according to the screen size). However in some psychophysical
studies, we need the same physical size. This is usually because we need to know
the size of something as it falls on the retina.
Units to use if you require the same physical size of stimulus across monitors
include centimetres and degrees of visual angle. However, these units require
PsychoPy to know exactly how many pixels can fit into a centimetre on your
monitor and how far a participant is sitting from the monitor. If you are using
PsychoPy Coder view, you can provide this information using Monitor Centre. If
you are using another development environment (e.g. Spyder), you can set up
your own monitor by importing PsychoPy’s monitors module and then specify
that monitor in the window so that it can use units like centimetres and degrees of
visual angle:
from psychopy import visual, monitors
# set up the monitor
mon = monitors.Monitor('labMonitor', width=1280,
⌴⌴⌴⌴distance=57, gamma=None)
# make a window to draw things in
win = visual.Window(size=[1024, 768], fullscr=False,
⌴⌴⌴⌴units='pix', color=(0,0,0), colorSpace='rgb',
⌴⌴⌴⌴screen=0, monitor=mon)
If your experiment will be satisfied with the same relative size of stimulus across
monitors. PsychoPy offers height or normalised units:
Height units correspond to the height of your window: 1 unit of height is the
total distance from the bottom to the top of the window, −0.5 is the bottom
edge of the window, and 0.5 is the top edge of the window. If you imagine a
perfect square that is as wide as it is tall, −0.5 would be the left edge of that
square, and 0.5 the right edge of that square.
Normalised units range between −1 and 1 and represent relative distances.
On a monitor with a resolution of 1920 × 1080 pixels, a horizontal distance
of −1 (left edge of the monitor) to 0 (monitor centre) will correspond to 960
pixels. On a monitor with a resolution of 1024 × 768, the same horizontal
distance will correspond to 512 pixels.
In this book, you will always use pixels. The upside is that this is the most
conventional and straightforward unit of distance on a computer monitor. The
downside is that pixels are specific to your monitor: a stimulus with a size of 200
pixels will have a different size in centimetres on two different monitors, because
pixel sizes differ between monitors. Fortunately, you can measure how wide yourmonitor is and calculate the amount of pixels per centimetre. From that, you can
calculate a stimulus’ size in centimetres and ultimately its size in visual angle
(using the distance between participant and monitor).
Another important aspect of PsychoPy is that it uses a different colour space,
which determines how colours are defined. Typically, monitors produce colour
with values for red, green, and blue that range from 0 to 255.
In PsychoPy, colours can also be defined as values for red, green, and blue.
However, these values range between −1 and 1. The logic behind this is that
colours can be represented as deviations from grey, which is defined as (0,0,0).
Some additional examples: (−1, −1, −1) is black, (1, 1, 1) is white, and (1, −1, −1)
is red.
PsychoPy also offers alternative colour spaces: colours can be defined as a
combination of their hue, saturation, and value; or in a colour space that speaks to
the specifics of human colour perception. If you want to know more, you can read
PsychoPy’s colour documentation pages
(www.psychopy.org/general/colours.html).
In this book, you will use the default colour space: RGB with values between
−1 and 1. Though sometimes we might also refer to named colours (e.g. “red”).
As per usual, if you find yourself confused about these things, just go with it.
Although colour spaces are a fascinating topic to elaborate on, they are beyond
the scope of this book.
3.4 Comments
If you want to make reusable code, comments are essential. You may have
noticed here that we’ve added some lines that start with the # symbol. This is a
single-line comment. Comments add human-readable information to your script
but is ignored by the computer when your code is run.
Consider comments as love notes to future you and to other researchers who
might need to figure out what your code was supposed to do. You could have the
most elaborate script in the world that achieves modern wonders, but if there are
no comments, chances are no one will ever use it. That’s because they will have
no idea what past you was thinking and doing on each line of code. There are two
types of comments you can add to your code:
# single-line comments: a quick note!
You can write several consecutive lines of comments, as long as each line starts
with #. If you prefer, you can also write several lines into a multi-line comment,
using three quotation marks to open the comment and another three to close it:'''
Multi-line comments.
Useful for a summary of your script at the start of your code. For
example:
Experiment: My first python script
Author: Codey McCodeFace
Date: 25/06/2022
'''
Single-line comments are typically for quick notes on what a part of your script is
doing, for example “make a window”. Multi-line comments give more detail
about a part of your code, such as a summary at the start of your script or as a
“doc string” (something that describes what a particular function or thing does).
3.5 Make Some Text
When learning a new language, the first thing budding programmers typically do
is learn to print “Hello World” in the output. It therefore seems only appropriate
that the first visual stimulus we learn to present is a text stimulus! To make and
draw our text stimulus, let’s write:
# make a textbox
textbox = visual.TextBox2(
⌴⌴⌴⌴win,
⌴⌴⌴⌴text='Hello world',
⌴⌴⌴⌴pos=(0, 0),
⌴⌴⌴⌴letterHeight=20,
⌴⌴⌴⌴alignment='center'
⌴⌴⌴⌴)
# draw the textbox
textbox.draw()
# flip the window (make stimuli visible)
win.flip()
Here we are using the TextBox2 Class to make a textbox object. Alternatives in
PsychoPy include TextStim (an easy, but less feature rich way to make text, for
instance you cannot specify text alignment with TextStim) and TextBox (the
predecessor of the new and improved TextBox2). The neat thing about TextBox2
is that it can not only be used to present text, but it can also be used to gather
typed responses (we will get to that in Chapter 4!).
Now run your script! You probably saw some text, although very, very briefly.
We need a way to pause the window for a fixed amount of time. For this, we use
the core module. Add it to your list of imports and then use core.wait(2) toindicate the amount of time, in seconds, we wish to pause the window for. Your
script should look like this:
from psychopy import visual, core
# make a window to draw things in
win = visual.Window(size=[1024, 768], fullscr=False,
⌴⌴⌴⌴units='pix', color=(0,0,0), colorSpace='rgb',
⌴⌴⌴⌴screen=0)
# make a textbox
textbox = visual.TextBox2(
⌴⌴⌴⌴win,
⌴⌴⌴⌴text='Hello world',
⌴⌴⌴⌴pos=(0, 0),
⌴⌴⌴⌴letterHeight=20,
⌴⌴⌴⌴alignment='center'
⌴⌴⌴⌴)
# draw the textbox
textbox.draw()
# flip the window (make stimuli visible)
win.flip()
# pause the window
core.wait(2)
3.4.1 Understanding win.flip()
win.flip() is the most important command to understand in your stimulus
presentation script. Here’s the thing: the timing of visual stimulus presentation is
always going to be constrained by the limits of our monitor. Most monitors will
have a set refresh rate of 60 Hz, which means the screen can “refresh” itself once
every 16.66 ms (ish). The win.flip() function is the most important command
for drawing visual stimuli, because it sets up what will be presented on the next
monitor refresh.
Your computer operates on a buffer system. When you call .draw(), it lines up
a visual stimulus in the back buffer, ready to be drawn. When you then call
win.flip(), it brings the stimulus to the front so that it can become visible on the
monitor.
Drawn stimuli do not appear straight away when you call win.flip(). Instead.
the command waits until the next refresh of your screen to initiate. This impacts
the way in which we can present visual stimuli. First, we can only present visual
stimuli for intervals that fall in the limits of our refresh rate. On a 60-Hz monitor,
you can present something for 16.67 ms or 33.33 ms, but there is no way to
present something of 20 ms; this is just not possible. Another factor to consider isthat if your computer is under high processing demands, or if we line up too much
code to be executed between frames, it can cause your computer to “drop”
frames. This means that the interval between screen refreshes can be longer than
expected, which can cause your stimuli to either be presented for longer than
expected or to be presented at an offset.
It is important to check the reliability of your system’s frame rate before
running an experiment. PsychoPy will try to do this for you, by measuring the
time interval between frame onsets. If this time exceeds what is expected (on the
basis of your computer’s refresh rate), PsychoPy will warn you in the Output
window. If you’d like to quickly test the reliability of your screens frame rate, you
can look inside the Demos drop-down menu in PsychoPy Coder and select timing
> timebyframes.py. (If it is your first time opening this section, you might need to
“unpack” demos first.) This will create you a figure like the one shown in Figure
3.2. In an ideal world, you want no frames to be dropped (left panel) and a nice
narrow distribution around the expected interval, i.e. around 16.67 ms for 60 Hz
monitors (right panel).
FIGURE 3.2 In the left window, frame duration (in milliseconds) is plotted against frame
number, and we see that it's close to 17 ms for each frame. In the right window, we can see the
histogram of the values in the left plot
A handy feature of PsychoPy’s window is that it has an attribute checkTiming,
which by default is True. This means that your window is recording the intervals
between each frame refresh and checking them against the expected refresh rate
of your monitor (which is estimated by measuring the intervals between a seriesof blank frames at the start of your experiment). If an interval is substantially
longer than expected, this indicates that frames might be dropping, and you will
see a warning about that in your Output window:
8.4776⌴⌴⌴⌴⌴WARNING⌴⌴⌴⌴⌴Couldn't measure a consistent frame rate!
⌴⌴- Is your graphics card set to sync to vertical blank?
⌴⌴- Are you running other processes on your computer?
9.7576⌴⌴⌴⌴⌴WARNING⌴⌴⌴⌴⌴t of last frame was 1280.40ms (=1/0)
9.8314⌴⌴⌴⌴⌴WARNING⌴⌴⌴⌴⌴t of last frame was 20.15ms (=1/49)
9.9332⌴⌴⌴⌴⌴WARNING⌴⌴⌴⌴⌴t of last frame was 21.09ms (=1/47)
10.1900⌴⌴⌴⌴⌴WARNING⌴⌴⌴⌴⌴t of last frame was 27.58ms (=1/36)
In general, warning messages do not mean that your experiment won’t run, but
they do indicate useful information that might impact the performance of your
script. In this case, dropping frames could mean that the timing of the stimulus
presentation is less accurate than it could be. If timing is important in your
experiment, do make sure to check!
3.5 Throwing Shapes
Sorry, this section is not about dance moves. Rather, it’s about making another
kind of useful stimulus: basic shapes. In PsychoPy, simple shapes (like circles and
rectangles) actually have their own class in the visual module. More complex
shapes can be created given a set of vertices, which means that the number of
shapes you can make is actually infinite, so long as you know the vertices! Try
this:
from psychopy import visual, core
# make a window to draw things in
win = visual.Window(size=[1024, 768], fullscr=False,
⌴⌴⌴⌴units='pix', color=(0,0,0), colorSpace='rgb',
⌴⌴⌴⌴screen=0)
# make a textbox
textbox = visual.TextBox2(
⌴⌴⌴⌴win,
⌴⌴⌴⌴text='Hello world',
⌴⌴⌴⌴pos=(0, 0),
⌴⌴⌴⌴letterHeight=20,
⌴⌴⌴⌴alignment='center'
⌴⌴⌴⌴)
# make some shapes
circle = visual.Circle(win, size=20, pos=[-300, 0],
⌴⌴⌴⌴lineColor='white', fillColor='lightGrey')square = visual.Rect(win, size=[20, 20], pos=[0, 0],
⌴⌴⌴⌴lineColor='white', fillColor='hotpink')
arrowVert = [(-40,5), (-40,-5), (-20,-5),
⌴⌴⌴⌴(-20,-10), (0,0), (-20,10), (-20,5)]
arrow = visual.ShapeStim(win, vertices=arrowVert,
⌴⌴⌴⌴fillColor='darkred', lineColor='red',
⌴⌴⌴⌴size=2, pos=[300, 0])
# draw your shapes
circle.draw()
square.draw()
arrow.draw()
# draw the textbox
textbox.draw()
# flip the window (make stimuli visible)
win.flip()
# pause the window
core.wait(2)
Lovely! Notice how even though our window is in RGB space, we can still use
named colours (e.g. “hotpink” and “red”), as these will be recognised regardless
of the window’s colorSpace.
Now, if you drew your shapes and textbox in the order we did above, you
probably noticed that the pink square overlapped the “Hello world” text. This is
important: the order in which you call the .draw() method on each object will
determine the order in which they are drawn. Later-drawn stimuli are overlaid on
top of earlier-drawn stimuli. If you want overlapping stimuli to still be semi￾visible, you can manipulate the opacity of each image using the opacity
argument, which takes a value between 0 (fully transparent) and 1 (fully opaque).
Try setting the opacity of the square to be 0.5, run the script again, and see what
happens!
3.6 Presenting Images
Images can be drawn like any other stimulus, as long as you have an image in an
appropriate format. PsychoPy will take all common image formats (tiff, png,
jpeg, bmp etc.). Find yourself an image, in our example we will use beach.jpg.
Images are created using the ImageStim class in the visual module like so:
# make an image stimulus
beach = visual.ImageStim(win, image='beach.jpg',
⌴⌴⌴⌴flipHoriz=True, pos=(0, 200), size=(200, 140))Add the above code to your script (after creating the shapes, but before drawing
them). When choosing the size of the image, you’ll typically want to keep the
original image’s aspect ratio, so it’s not squashed or stretched when we present it.
If we do not provide a size parameter, the original image size will be used.
Next, add a call to the ImageStim’s draw method to your script. You can place
this after the draw calls for your shapes:
# draw the image stimulus
beach.draw()
If you run the script, the image should be visible on your screen!
3.6.1 Adding Masks to Images Using Numpy Arrays
Sometimes you want to manipulate images before presenting them. Perhaps the
simplest way to manipulate an image is to apply a mask. Images created using
ImageStim can have various sorts of masks applied to them. By default, the
attribute mask is set to None. However, we could consider one of the following
masks:
Named masks: 'circle', 'gauss', or 'raisedCos'.
The name of an image. The mask image should be the same size as your
original image. Black parts of the mask image will completely mask the
original image, white parts will leave the image visible, and shades of grey
will do something in between. This is useful for applying masks to specific
regions of an image at different alpha levels (alpha effectively determines
the opacity of an image on a pixel-by-pixel basis).
A NumPy array ranging from −1 (image pixel fully transparent/invisible) to
1 (image pixel fully opaque/visible).
NumPy and visual noise have already been introduced in the first Make Some
Noise chapter. Here is a wonderful chance to apply those skills by creating a
mask for our image!
Ensure that you have numpy imported at the start of your script. You then want
to create a NumPy array of random values between −1 and 1. This array should
have the same shape as your image (width and height) and can then be used as
mask parameter for your ImageStim.
At the top of your script, import NumPy:
# import the numpy library
# in this example, it is referred to as np
import numpy as npThen replace the lines in which you previously created an ImageStim with the
following:
# Make an array of pseudo-random numbers,
# with a size that matches the ImageStim.
myMask = np.random.rand(200,140)
# Transform the numbers from range [0 to 1]
# to range [0 to 2].
myMask = myMask * 2
# Transform the numbers from range [0 to 2]
# to range [-1 to 1].
myMask = myMask - 1
# make an image stimulus - apply the mask
beach = visual.ImageStim(win, image='beach.jpg',
⌴⌴⌴⌴flipHoriz=True, pos=(0, 200), size=(200, 140),
⌴⌴⌴⌴mask=myMask)
Now when you run your script, you should see your image with a noise mask
applied to it. By making a mask with values ranging from −1 to 1, you’ve
manipulated the alpha of each pixel. Pixels with an alpha of −1 are fully
transparent and pixels with an alpha of 1 are fully opaque.
3.6.2 Blurring Images Using Python Imaging Library
When presenting an image, you might want to manipulate the image in various
ways. For example, we might want to blur the image quality and see how that
impacts visual search or image identification. In Python, we can manipulate
images using the external package known as the Python Imaging Library or PIL.
(PIL was maintained under that name by Fredrik Lundh and contributors until
2011; and a fork named Pillow has been maintained since 2010 by Alex Clark
and contributors.) PIL comes as part of standalone PsychoPy, but if you are using
an alternative development environment, you will need to install it before
continuing this section. (See https://python-pillow.org and then follow the link to
the documentation pages for installation instructions.)
First you’ll need to import several classes from the PIL, so add this to the top
of your script along with the imports:
from PIL import Image, ImageFilter
Next, we want to open the image and apply a Gaussian filter.
# open original image
oriImage = Image.open('beach.jpg')# applying a GaussianBlur filter
gaussImage = oriImage.filter(
⌴⌴⌴⌴ImageFilter.GaussianBlur(50))
Here, 50 corresponds to the level of blur and specifically with the radius of the
blur applied. You could then directly feed your gaussImage into an ImageStim:
# make an image stimulus - using the blurry image
blurry_beach = visual.ImageStim(win, image=gaussImage,
⌴⌴⌴⌴flipHoriz=True, pos=(0, -200), size=(200, 140),
⌴⌴⌴⌴mask=None)
As always, add blurry_beach.draw() to your set of draw commands in order to
see the blurry beach.
One common use of Python for experimental psychologists is to generate the
stimuli for experiments. If you wanted to create a set of images with different blur
levels, you could use variations of the above code. To save each blurred image,
you could use its save function:
# save this image
gaussImage.save('blurry_beach.jpg')
You could even use a loop to generate large sets of images, which we will learn
about in a moment.
3.6 Making Many Stimuli
In some circumstances, we want to present many stimuli on the screen at once.
For example, a visual search task could present a large number of letters on the
screen, with one target letter (“L”) embedded among many distractors (“T”s).
Now, we know how to make one letter using TextBox2 (see Section 3.4 if you
forgot). In theory, we could just copy and paste this many times and manually edit
each TextBox2 instance’s position to be different. However, this isn’t really very
efficient, requires a tonne of manual work, and results in ugly and unmaintainable
code (editing 50 lines of stimulus positions isn’t quick!). In order to achieve this
more efficiently, we need to know two things: how to set a stimulus to a random
location and how to use loops.
3.6.1 Creating Stimuli in Random Locations
Setting a stimulus to a random location is another chance to practise using the
NumPy library. NumPy has a number of functions that we can use for
randomisation and housed within its random module. These include shuffle (to
shuffle the order of elements in a list), choice (to randomly pick an element froma list or array), and randint (to generate a random integer between specified
values). Using randint, we will be able to create a random value for our
horizontal (x) and vertical (y) coordinates, but within a known bound. To set the
position of a stimulus to be in a random position, we could use:
# import a named method from a module
from numpy.random import randint
# the minimum and maximum coordinates
min_xy = -200
max_xy = 200
# generate a pseudo-random location
rand_pos = (randint(min_xy, max_xy),
⌴⌴⌴⌴⌴⌴⌴⌴randint(min_xy, max_xy))
# make a textbox for the random location
randloc_textbox = visual.TextBox2(
⌴⌴⌴⌴win,
⌴⌴⌴⌴text='T',
⌴⌴⌴⌴pos=rand_pos,
⌴⌴⌴⌴letterHeight=20,
⌴⌴⌴⌴alignment='center'
⌴⌴⌴⌴)
Here, we first import a function from the NumPy library, randint; we then
specify the minimum and maximum values for our x and y coordinates, min_xy
and max_xy (this example assumes that we want the same bounds along the x and
y axes). Then, we use randint(min_xy, max_xy) to specify a random value for
both the x and y coordinates of the text stimulus.
With the above code, we can create a text stimulus in a random location. To
complete our search task, we now need to know how to create several stimuli, all
in different locations.
3.6.2 For Loops
In Python, there are several ways of repeating something a specific number of
times. The simplest approach is to use the range() function. Whilst we practice
different loop methods, let’s make a separate .py script from our stimuli.py file.
Create a new file and call it loops.py. Try typing this in a script and running it to
see what happens:
for i in range(0, 5):
⌴⌴⌴⌴print(i)Hopefully, if you look in your Output window, you will see the numbers 0, 1, 2,
3, 4 printed sequentially. Note that this does not include the number 5, as range
counts from a starting point (0) to a non-inclusive end (5). This makes sense in
the context of index numbers: a list with five items has indices 0, 1, 2, 3, and 4:
exactly the numbers generated by range!
You can simplify the above code a little bit, by relying on range’s default
starting point. As this is 0, you could simply type:
for i in range(5):
⌴⌴⌴⌴print(i)
The range function creates a range instance. While it is not quite the same as a
list, you could consider it similar to a list for our current purposes. In Python, we
can loop through anything that is “iterable”, such as ranges, lists, and object with
several elements. Try the following:
for letter in 'abc':
⌴⌴⌴⌴print(letter)
Hopefully, you saw “a”, “b”, and “c” printed in your output window. A string has
several characters in it, so it is iterable, with each iteration of the loop
corresponding to one character. Now try this:
for animal in ['cat', 'dog', 'mouse']:
⌴⌴⌴⌴print(animal)
Hopefully, you saw “cat”, “dog”, and “mouse” printed in your output window. A
list also has several elements in it, so it is iterable, with each iteration of the loop
corresponding to one element in the list.
In the examples until now, you looped through values. It is also possible to get
the index number of each value alongside. You can do this by using the
enumerate function:
for i, animal in enumerate(['cat', 'dog', 'mouse']):
⌴⌴⌴⌴print(i, animal)
Hopefully you saw:
0 cat
1 dog
2 mouse
Using enumerate, you can get both the index and the value of the current element
at each iteration of your for loop. We don’t actually need the enumerate() function
for our current example, but it is very useful to know in general!One question you may have is “what is i?” in these loop situations. The answer
is that i is commonly used as a variable that indicates an index number in a for
loop. However, this is just a convention. The name you choose for your variable
is entirely arbitrary, and you could make it anything you’d like:
for henk, animal in enumerate(['cat', 'dog', 'mouse']):
⌴⌴⌴⌴print(henk, animal)
This behaves in the same way, but now i is called henk. The key here is to use a
value that makes sense to you, future you, and future people that you share your
code with. With this in mind, you could consider adopting the typical convention
of using i and then using j in nested for loops:
for i in range(3):
⌴⌴⌴⌴for j in range(5):
⌴⌴⌴⌴⌴⌴⌴⌴print(i, j)
3.6.3 Indentation
In Python, indentation is an integral part of your code. Without it, for loops and
other functionality will not work. For instance, try the following:
for i in range(5):
print(i)
If all went well, then all didn’t go well and you saw the following error message:
IndentationError: expected an indented block
This indicates that we are missing the required indentation, which produced an
error message. Now try the following:
for i in range(5):
⌴⌴⌴⌴print(i)
⌴⌴⌴⌴print('loop complete')
This didn’t produce an error message, but you saw the phrase “loop complete”
printed out every single loop. This likely wasn’t the intention of the code, and
instead, the programmer must have forgotten to deindent that specific line. They
probably meant to write this:
for i in range(5):
⌴⌴⌴⌴print(i)
print('loop complete')One “indent” can be indicated by a tab or by spaces (typically people use four
spaces per indent). Which you use depends on your preferences and/or on your
code editor’s settings. Although indentation is generally considered a matter of
personal preference, there are some things that you should take into account.
The first thing to know is that you should never mix indentation types. Use
tabs OR spaces, but never both within the same code. This causes an error
(“TabError: inconsistent use of tabs and spaces in indentation”). In addition,
Python Enhancement Proposal 666 (www.python.org/dev/peps/pep-0666/)
suggests that people who mix up indentation deserve an electric shock from a
cattle prod.
A more gentle guideline is provided in Python Enhancement Proposal (PEP 8,
www.python.org/dev/peps/pep-0008/#tabs-or-spaces), which suggests using
spaces should be preferred. This was written by Guido van Rossum, the original
creator of Python. While that is perhaps an authority you might want to follow,
you could also throw the entire style guide in the bin and just do what you like. In
short, style guides and conventions improve code readability, but they’re not
mandatory. (For an example of unfollowed style guidelines, look no further than
this book. We inconsistently use under_score and camelCase variable names,
like philistines!)
Python reads code that is on different indentation levels as separate blocks.
With every indent you include before a line, you effectively nest it within earlier
lines. Try to predict what the next code will print:
for i in range(5):
⌴⌴⌴⌴for letter in 'abc':
⌴⌴⌴⌴⌴⌴⌴⌴print(i, letter)
In the current state, it would print:
0 a
0 b
0 c
1 a
1 b
1 c
2 a
2 b
2 c
3 a
3 b
3 c
4 a
4 b
4 cThis is because the number corresponds to the outer loop value, i, and the letter
corresponds to the inner loop value, letter. You can see that we have two nested
blocks here, one corresponding to the first (outer) loop and one corresponding to
the second (inner) loop.
3.6.4 While Loops
Another approach to looping is to keep going until some “condition” has been
achieved. For instance, imagine we want to continuously add something to a list
and then stop once the list has the length we desire:
# make an empty list
myList = []
# use a while loop to keep going until a condition is met
while len(myList) < 10:
⌴⌴⌴⌴myList.append('na')
print(myList)
print('BATMAN!')
OK, so we could have just used a for loop that iterated ten times. The while loop
offers no benefit here, but it is just an introduction. While loops are convenient
when you don’t know the number of iterations you need, but you do know the
exit condition. For example, imagine you want to keep going for a set period of
time, rather than a specific number of iterations:
from psychopy import core
# make a clock
clock = core.Clock()
# create an integer to use as a counter
a = 0
# keep a loop going for 3 seconds
while clock.getTime() < 3:
⌴⌴⌴⌴# increment the counter
⌴⌴⌴⌴a+= 1
print(a)
Be careful with while loops. First in the example above, you’ll notice the printed
value of the counter (a) was very high! (Rebecca’s computer managed 947097
iterations, and Edwin’s absolutely smashed that with 4341881. Did yours do
better?) If we tried to print something on every iteration of the while loop, your
PsychoPy might have become unresponsive due to the high volume of data to
print.Another (and more important!) reason to be careful with while loops is that it
is very easy to accidentally end up trapped in an infinite loop. This happens when
the exit condition is never met. For example, let’s imagine we’re flipping a coin,
and we want to keep a loop going until we get a “heads”:
from numpy.random import choice
# a list with two values
coin = ['heads', 'tails']
# start without a result
result = None
# create an integer to count the number of flips
nTries = 0
# keep going until we have a "heads" result
while result != 'heads':
⌴⌴⌴⌴# flip the coin
⌴⌴⌴⌴result = choice(coin)
⌴⌴⌴⌴# increment the attempts
⌴⌴⌴⌴nTries += 1
# print the counter
print(nTries)
Run the example several times and see how many iterations it runs on each.
Before we run the code, we don’t actually know how many iterations it will take
until we get a “heads” result.
Now imagine playing with your dodgy mate Dave. Unbeknownst to others, he
has a weighted coin; and he’s always keen to bet that it will land on tails at least
ten times in a row. Dave has recently learned how to code and is hoping to
continue his scam in Python. He writes the following code:
from numpy.random import choice
# a list with two values
coin = ['heads', 'tails']
# start without a result
result = None
# create an integer to count the number of flips
nTries = 0
# keep going until we have a "heads" result
while result != 'heads':⌴⌴⌴⌴# flip the coin
⌴⌴⌴⌴result = choice(coin, p=[0.0, 1.0])
⌴⌴⌴⌴# increment the attempts
⌴⌴⌴⌴nTries += 1
# print the counter
print(nTries)
When Dodgy Dave runs this code, his computer freezes. What he didn’t account
for is that his weighted coin never ends up on heads. The loop will thus keep
going forever! While this serves Dave right, an infinite loop can really mess with
experiments and other code.
One way to avoid infinite loops is to use a condition that you know will be met
at some point, preferably in the near future. Another is to build in a break clause
that will kill the loop after a set number of iterations:
⌴⌴⌴⌴if nTries > 10:
⌴⌴⌴⌴⌴⌴⌴⌴break
which would break the while loop after ten attempts. Here we’ve also referred to
another kind of statement, an if statement. We will use these more in the next
chapter!
3.6.5 Using Loops to Generate Many Stimuli
Back to the task at hand, you can now return to your stimuli.py file and leave the
loops.py file to one side. We will need two loops to achieve our goal of making
several stimuli and drawing them simultaneously. First, we need a loop to create
our list of stimuli:
# specify the minimum and maximum xy coordinates
min_xy = -200
max_xy = 200
# how many letters we want
nLetters = 5
# an empty list (our letters will be added to this)
myLetters = []
# a loop that repeats nLetters times
for i in range(nLetters):
⌴⌴⌴⌴# generate a pseudo-random location
⌴⌴⌴⌴rand_pos = (randint(min_xy, max_xy),
⌴⌴⌴⌴⌴⌴⌴⌴randint(min_xy, max_xy))⌴⌴⌴⌴# make a textbox for the random location
⌴⌴⌴⌴randloc_textbox = visual.TextBox2(
⌴⌴⌴⌴⌴⌴⌴⌴win,
⌴⌴⌴⌴⌴⌴⌴⌴text='T',
⌴⌴⌴⌴⌴⌴⌴⌴pos=rand_pos,
⌴⌴⌴⌴⌴⌴⌴⌴letterHeight=20,
⌴⌴⌴⌴⌴⌴⌴⌴alignment='center'
⌴⌴⌴⌴⌴⌴⌴⌴)
⌴⌴⌴⌴# add the textbox to the list
⌴⌴⌴⌴myLetters.append(randloc_textbox)
Then, rather than calling .draw() once, we need to loop through the list of stimuli
to draw each element:
# loop through the list of letters to draw them
for letter in myLetters:
⌴⌴⌴⌴letter.draw()
And there you have it, a large number of stimuli drawn at once, try it with larger
numbers, hopefully you can now see the immense value of loops in reducing the
time it would have taken to make many stimuli.
3.6.5 Element Array Stim
If you tried the previous example with a very large number of stimuli, you might
have noticed this put your computer under some demand. Maybe you even
received warnings in your Output regarding dropped frames! This first approach
was certainly a good introduction to loops, and it typically works for a smaller
number of varied stimuli. However, there is a more efficient way of showing a set
of stimuli.
This approach is to use ElementArrayStim, which allows you to specify many
stimuli to be drawn simultaneously, without dropping a frame. The way that this
works is by specifying a large number of objects that are the same shape (e.g. a
square), but that vary on some parameter e.g. orientation, size, or location. You
can specify a specific shape or an image as a texture. For instance:
# specify the number of stimuli to use
nStim = 100
# generate a list of random coordinates
xys = []
for i in range(nStim):
⌴⌴⌴⌴xys.append([randint(-200, 200),
⌴⌴⌴⌴⌴⌴⌴⌴randint(-200, 200)])# make an element array stim
multiStim = visual.ElementArrayStim(win,
⌴⌴⌴⌴elementTex='beach.jpg',
⌴⌴⌴⌴elementMask=None,
⌴⌴⌴⌴nElements=nStim,
⌴⌴⌴⌴sizes=[20, 20],
⌴⌴⌴⌴xys=xys)
This would create a stimulus array of 100 beach pictures, each in a random
location. You could draw all 100 images with a single call to multiStim.draw().
What’s cool about this is that you can change the properties of the elements in
your ElementArrayStim all at once! For example, try:
# repeat 5 times
for i in range(5):
⌴⌴⌴⌴# list of random values ranging from 1
⌴⌴⌴⌴# to and 360, with length nStim
⌴⌴⌴⌴oris = randint(1,360,nStim)
⌴⌴⌴⌴# use the list to set the orientations
⌴⌴⌴⌴# of elements in multiStim
⌴⌴⌴⌴multiStim.setOris(oris)
⌴⌴⌴⌴# draw the stimulus
⌴⌴⌴⌴multiStim.draw()
⌴⌴⌴⌴win.flip()
⌴⌴⌴⌴core.wait(1.0)
If this went well, you saw many beaches, and each changed orientation five times
in a row. If you’d like a more chaotic display, change the number of repeats to 50
and the waiting time to 0.1.
If you are a vision scientist with an interest in random dot kinematograms, the
ElementArrayStim might seem like an appealing class to you. You’ll be delighted
to know that the DotStim class is designed especially for this purpose and allows
you to control many more aspects of dot motion.
3.7 Timing Visual Stimuli by Frames
We mentioned that the duration for which we can present stimuli is inherently
constrained by our monitor’s frame rate; it is impossible to present something for
half a frame! Because of that, the core.wait() method isn’t exactly fool proof.
We could write core.wait(0.02) and this would actually present for 33 ms on a
60 Hz monitor, not 20 ms. Oops!
To present stimuli by frames, we can use our new knowledge of for loops.
Only this time, instead of looping through trials, we loop through frames. Imagineyou have an immature sense of humour and want to present a set of Ts for 420
milliseconds. On a 60-Hz monitor, this would correspond to 60 frames/second *
0.42 seconds = 25.2 frames. As we’ve discussed, it’s impossible to present stimuli
for a partial frame, so we’ll need to round the presentation time to the nearest
integer. (You could also consistently round up or down, depending on your
preferences.)
To calculate the number of frames to present our stimulus and calculate how
far off we would be, we could use:
# the intended stimulus duration in seconds
desired_time = 0.420
# monitor frame rate
framerate = 60
# compute the time per frame in seconds
frametime = 1.0 / framerate
# total frames required to get close to desired times
nFrames = round(desired_time*framerate)
# print how far off we will be
print('Stimulus will be presented for {} frames'.format(
⌴⌴⌴⌴nFrames))
print('Actual time will be {:.3f} seconds'.format(
⌴⌴⌴⌴nFrames*frametime))
We can then use this number of frames in a loop to present our stimulus. So,
instead of:
for letter in myLetters:
⌴⌴⌴⌴letter.draw()
win.flip()
core.wait(0.420)
We could use:
# run through the desired number of frames
for frameN in range(nFrames):
⌴⌴⌴⌴# draw all letters
⌴⌴⌴⌴for letter in myLetters:
⌴⌴⌴⌴⌴⌴⌴⌴letter.draw()
⌴⌴⌴⌴# show the letters
⌴⌴⌴⌴win.flip()Notice how, here, we replace core.wait(0.420) with a for loop that iterates
through a number of frames. In this way, we know the exact amount of times a
stimulus is presented for and therefore have better control over timing.
We also used a for loop to draw all of the stimuli on each frame. An alternative
way of doing this is to use the .setAutoDraw() function. This allows us to
automatically draw stimuli: .setAutoDraw(True) effectively means “keep drawing
on every win.flip() until I say otherwise”. You can stop the automatic drawing by
calling .setAutoDraw(False). Using this approach, we don’t actually have to keep
calling the .draw()method. In our script, we would use:
# set all the letters to automatically draw
# on every screen refresh
for letter in myLetters:
⌴⌴⌴⌴letter.setAutoDraw(True)
# flip the window for the desired number of frames
for frameN in range(nFrames):
⌴⌴⌴⌴win.flip()
# stop auto-drawing the letters
for letter in myLetters:
⌴⌴⌴⌴letter.setAutoDraw(False)
3.8 Making Dynamic Stimuli
Now that you know how to present stimuli for a set number of frames, a cool
thing we can do next is to change their properties frame-by-frame. In this way, we
can make things move, grow, and spin dynamically in time. Let’s wind back a bit
to a single stimulus, rather than a large number of stimuli. Make yourself a basic
circle:
# make a circle
circle = visual.Circle(win, size=20,
⌴⌴⌴⌴pos = [-500, 0], lineColor='white',
⌴⌴⌴⌴fillColor='lightGrey')
You can change the attributes of Python instances after you’ve created them, by
specifically naming that attribute. For example, circle.size=80 would update the
size attribute to a value of 80. Some objects have methods that are built into the
class itself. Some examples in PsychoPy include:
circle.setPos() to set the position of the circle
circle.setSize() to set the size of the circle
circle.setFillColor() to set the fill colour of the circleIn PsychoPy’s classes, changing stimulus attributes also changes what they look
like on screen. If you would like to move the newly created circle across the
screen, you could do so by updating its position every frame:
# specify the total frames we want to present
nFrames = 100
# how many pixels to move per frame
pixels_per_frame = 10
# starting x coordinate of the movement
circle_x = -500
# set the circle to draw automatically on every frame
circle.setAutoDraw(True)
# iterate through the specified frames
for frameN in range(nFrames):
⌴⌴⌴⌴# update the x value
⌴⌴⌴⌴circle_x += pixels_per_frame
⌴⌴⌴⌴# set the circle position
⌴⌴⌴⌴circle.setPos([circle_x, 0])
⌴⌴⌴⌴# flip the window
⌴⌴⌴⌴win.flip()
# disable the circle auto-draw
circle.setAutoDraw(False)
This approach can be used to generate dynamic stimuli without needing a video.
It has the advantage of being highly flexible and not that resource intensive. For
example, we could make a stimulus change based on the location of the mouse
cursor! (See the next chapter for that type of dark magic.)
If you do have a video to show, you can present it using the visual.MovieStim
class.
3.9 Comments (again)
Your scripts are gradually becoming longer and more complicated, so this is a
good time to really stress the importance of comments. As you’ve seen, a
comment is one or more lines that are ignored by Python. You can add them as
little notes to yourself or to other people (who might be using your scripts at one
point).
While writing code, you might be confident that you can remember what
you did and why. You will not. Even though the code is right there, you’ll find
yourself staring at your screen, wondering what the bleep you did.This will be a very frustrating experience, because of three reasons:
1. You have code that works, and you want to change it slightly. This should
be easy and should not take too much time: YOU wrote this! However,
without comments, you actually have no clue what the code does. You now
need to spend ages on figuring it out. AGAIN!
2. Because you can’t quite figure out what you did exactly, you make
assumptions about what/why you might have done when you wrote the
code. This makes you more prone to making mistakes and leaves you with
broken scripts and/or lots of debugging effort.
3. You realise that your past self-implemented something in a very clever way,
which you now struggle to comprehend. This makes you realise that your
cognitive skills are ever declining. Also, because your uncommented code is
only a few weeks old, you realise the decline is very rapid. You’re getting
old, fast.
By not commenting your code, you are faced with frustration, potentially
flawed scripts, and an unpleasant insight into your own mortality.
Comments make scripts much longer, even though there is absolutely no extra
functionality. However, comments ensure you’ll continue to understand your code
weeks, months, or years from now. That will be a huge time-saver! (Well worth
all the effort of typing comments!)4
PROCESSING RESPONSES
DOI: 10.4324/9781003174332-5
Almost every computer-based experiment in psychology and cognitive
neuroscience requires participants to respond in one way or another. The
most common instrument to collect these responses is the computer
keyboard. In the following chapters, you will learn how to collect and
process keypresses.
4.1 Are Peripherals Accurate Enough?
Some researchers claim that keyboards are too slow for their purposes, as
they require “millisecond accuracy”. Because it is important to know your
tools, this chapter will investigate this claim.
In most operating systems, peripherals (keyboards, mouses, joysticks,
game controllers etc.) are polled at a certain rate. Polling a device means
checking its state: are any of the keys or buttons pressed, or is there
movement along any of the axes? The polling rate determines how often an
operating system checks for new input. If the polling rate is 60 Hz, the
keyboard will be checked roughly every 17 milliseconds. If a key is pressed
2 milliseconds after the last ‘poll’, it will take another 15 milliseconds for it
to be picked up.
Traditionally, the polling rate of keyboards and mice was 60 Hz,
matching the standard display refresh rate. This makes sense: if the display
is updated only once every 17 milliseconds, why should you check for input
more than that? The input is used to update the display, so polling devices
twice every display refresh will result in one redundant poll.
An example: Imagine your mouse is at screen coordinate (10,10) at time
0 ms (this coincides with the latest screen refresh). Now you move yourmouse, which is polled at a rate of 120 Hz. The mouse was registered to be
at point (15,15) at time 8 ms and at point (20,20) at time 17 ms. The display
is updated to show the mouse cursor at coordinate (20,20) at time 17 ms.
The data from time 8 ms is disregarded for the updating of the monitor,
because it’s old data. This means that polling the mouse at a higher rate than
the monitor refresh is effectively useless.
Clearly, the engineers who thought this up were efficient but not research
psychologist. If you’re interested in human ergonomics and would like to
see a high-resolution mouse trajectory, can you still use standard computer
peripherals?
Most modern peripherals are connected via USB. Most operating
systems poll the USB port at a rate of 125 Hz (every 8 milliseconds). This
means you’ll have an average timing error of 4 milliseconds. Some extra
inaccuracy is added by further delays, e.g. in the signal from your input
device having to travel to the computer, and within the computer’s
processes that make sure the input reaches your experiment software.
Such inaccuracy can be reduced by using software that polls the USB
port more often (drivers) and with specialised hardware that can handle
this. Some consumer-grade hardware and software can boost the polling
rate to (over) 1,000 Hz. That’s one data point every millisecond! Such
devices are popular among gamers, who think they might avoid getting shot
in their virtual heads if their keyboard registers their key-bashing a
millisecond or two quicker.
There are researchers who argue that one simply cannot investigate
short-lived mental processes with timing imprecisions of several
milliseconds. Therefore, they buy expensive devices (often connected in
more intricate ways than USB) with extremely high polling rates to achieve
millisecond or sub-millisecond accuracy.
So, are they right? “Yes” in principle but also probably “no” in practice.
Just like computers, participants are not free from timing imprecision. In
fact, people are so inconsistent that we need many trials to accurately
measure the distribution of their response times. This human timing
inaccuracy is much higher than the timing inaccuracy of computer
peripherals! This means that using keyboards is perfectly fine in most
experimental designs (Damian, 2010). (For a more in-depth discussion,
please read the cited paper.)4.2 Keyboard Input
Now that you know you can use the keyboard in experiments, it is time to
explore how to actually do it. Get started with a new, empty experiment:
create a new folder and create a new script, let’s call this script
“responses.py”.
In this example, we will simply present participants with letters on the
screen and ask them to press the corresponding key on the keyboard. To get
started, let’s present a random letter on the screen. We know how to present
a letter (Section 3.4), we even learned how to set the position of that letter
to be in a random location using randint, which you might recall was part
of NumPy’s random module. This time, we will again use the random
module, but now we want to randomly choose a letter from a list of letters
and then use that in the text field of our textbox. That will look like this:
# import modules
from psychopy import visual, core, event
from numpy.random import choice
# make a window
win = visual.Window([1024, 768], fullscr=False,
⌴⌴⌴⌴units='pix')
# make a list of vowels
vowels = ['a', 'e', 'i', 'o', 'u']
# randomly choose a letter from that list
this_letter = choice(vowels)
# make a textbox and use the selected letter in the text field
textbox = visual.TextBox2(
⌴⌴⌴⌴win,
⌴⌴⌴⌴text=this_letter,
⌴⌴⌴⌴pos=(0, 0),
⌴⌴⌴⌴letterHeight=20,
⌴⌴⌴⌴alignment='center'
⌴⌴⌴⌴)
# draw the textbox
textbox.draw()
win.flip()
core.wait(2)Hopefully, you saw a random letter from your list appear on the screen!
OK, so now we can show the letter we want to gather a keyboard response.
That means we don’t want to just show the textbox for two seconds using
core.wait(2), but we want to leave the stimulus on screen until a keypress
has been made.
4.2.1 Waiting for Keyboard Input
In PsychoPy, there are two ways of gathering a keyboard response. The first
is easy but not the most precise for response time measurements. This
method uses PsychoPy’s event module, so add event to modules that you
import from PsychoPy. Then, rather than using core.wait(2), we will
replace this with a command to wait for a keypress event:
# wait for a keypress event
keys = event.waitKeys(keyList=['a', 'e', 'i', 'o', 'u'])
print(keys)
With event.waitKeys(keyList=['a', 'e', 'i', 'o', 'u']), the
argument keyList indicates a list of keys to be watched. If we do not
provide this argument, PsychoPy will respond to any key that is pressed. If
you look in your Output window, you should see the name of the key that
you just pressed.
The event module is an easy way to watch for keypress events, but it
isn’t the best for gathering response times. The reason for this is that the
polling of the keyboard in the event module is synchronous to the main
thread, meaning that polling occurs on every frame refresh. The other thing
is that the event module only detects key-down events (when a key is
pressed); sometimes it might be useful to watch for key-up events too
(when a key stops being pressed). This allows us to access other properties,
such as keypress duration or if a key is currently being pressed (i.e. when a
key-down event occurred, but a key-up event has not yet occurred). The
second method for watching for keypress responses is using the hardware
module. To do this, we first add another import to the start of our script:
from psychopy.hardware import keyboard
Then, we make an instance of a Keyboard object:# make an instance of a keyboard
kb = keyboard.Keyboard()
Finally, we replace our event.waitKeys with kb.waitKeys:
keys = kb.waitKeys(keyList = ['a', 'e', 'i', 'o', 'u'])
print(keys)
The behaviour probably felt the same as the previous method. However, this
time the information printed to your Output window probably seemed less
intuitive compared with the keyname we saw with the last method. The
Output returned would have read:
[<psychopy.hardware.keyboard.KeyPress object at
0x000002C8BC074100>]
This is a list (we can tell by the outer square brackets); however, it is a
list containing a PsychoPy Object. This Object is a Keypress Object. To
investigate it further, we can try the following:
print(dir(keys[0]))
Note that we need to use keys[0] to index the first KeyPress Object in the
list. The dir() method allows us to inspect the attributes and methods
available to a particular python object. In this case, the Output would have
looked like the below:
['__class__', '__delattr__', '__dict__', '__dir__', '__doc__',
'__eq__', '__format__', '__ge__', '__getattribute__', '__gt__',
'__hash__', '__init__', '__init_subclass__', '__le__',
'__lt__',
'__module__', '__ne__', '__new__', '__reduce__',
'__reduce_ex__',
'__repr__', '__setattr__', '__sizeof__', '__slotnames__',
'__str__',
'__subclasshook__', '__weakref__', 'code', 'duration', 'name',
'rt',
'tDown']
There are a number of methods here that start with an underscore; this is
generally used by developers to indicate that a method is to be used for
internal use, rather than by the users. Notably, we see a few attributes that
are relevant to us:
Name: the name of the key that was pressed.rt: the response time of the keypress relative to the last time the clock
within the Keyboard instance was reset.
duration: the duration of the keypress event (i.e. the time from the
key-down event to the key up event).
tDown: the time of the key-down event relative to the global clock.
Given this information, we know that we can return the name of the key
that was pressed and the response time of that keypress using:
print(keys[0].name, keys[0].rt)
4.2.3 Understanding the “Zero Point” of Keyboard Response
Times
Often in psychology experiments, we present the participant with a series of
events, not just a single letter. For instance, we might present a fixation
point and then a letter. It is important to consider where you want the zero
point of your response time to be within your experiment. In our example,
we present a fixation point and then a letter. Do we want our reaction time
to be relative to the onset of the letter? Or do we want to allow participants
to respond before the letter? In which case, the zero point would be the
onset of the fixation. To talk this through, let’s add a simple fixation cross to
our experiment by making a second text stimulus.
# make a fixation cross
fixation = visual.TextBox2(
⌴⌴⌴⌴win,
⌴⌴⌴⌴text='+',
⌴⌴⌴⌴pos=(0, 0),
⌴⌴⌴⌴letterHeight=20,
⌴⌴⌴⌴alignment='center'
⌴⌴⌴⌴)
And drawing it for 1 second in advance of our letter:
# draw the fixation for 1 second
fixation.draw()
win.flip()
core.wait(1)
# draw the text
textbox.draw()win.flip()
# wait until a response
keys = kb.waitKeys(keyList = ['a', 'e', 'i', 'o', 'u'])
We need to think about when we want our response time to start. At this
point, we would want to reset the clock using kb.clock.reset() and clear
the keyboard event buffer of any previous events with kb.clearEvents().
Imagine we want our zero point to be the onset of the fixation. We could
use:
# draw the fixation
fixation.draw()
# reset the keyboard clock
kb.clock.reset()
# clear the event buffer
kb.clearEvents()
win.flip()
But recall that our visual stimulus doesn’t actually become physically
visible until the window has actually flipped. So, for an even more precise
clock reset, we could use:
# draw the fixation
fixation.draw()
# reset the keyboard clock (when the window flips)
win.callOnFlip(kb.clock.reset)
# clear the event buffer(when the window flips)
win.callOnFlip(kb.clearEvents)
win.flip()
This second example used the win.callOnFlip() function.
win.callOnFlip() will line up a function to be executed when the window
flips, rather than executing it immediately. Here, we give it the name of the
function to line up, kb.clock.reset, without the () after it (which would
usually execute the function immediately).
In addition to setting our zero point, we want to add an additional
argument to our waitKeys() method:
keys = kb.waitKeys(keyList=['a', 'e', 'i', 'o', 'u'], \
⌴⌴⌴⌴clear=False)clear is an argument that, by default, is set to True, indicating that all
previous events are cleared at this point. This isn’t ideal if we want to
capture key events that occurred prior to the point at which we started
waiting, so we set clear=False. This will mean that we capture any events
from the point at which we explicitly cleared the event buffer, using
kb.clearEvents(), to the current point in our script.
4.2.2 Fetching Keyboard Input without Waiting
Sometimes we might have an experiment where we want to present stimuli
for a set amount of time and capture keyboard responses that occur within
that time, but we don’t want to pause at the end of every trial until a
keypress has been made. For this example, we use a slight variant of what
we have already learned:
keys = kb.getKeys(keyList=['a', 'e', 'i', 'o', 'u'], \
⌴⌴⌴⌴clear=False)
Using getKeys() instead of waitKeys() will capture keypress responses
that occurred since the event buffer was cleared, but it won’t halt the
experiment until a keypress is made. Now, if you just tried replacing the
waitKeys() method with getKeys() in your existing script, you were
probably greeted with an error message (if you did not press a key fast
enough):
print(keys[0].name, keys[0].rt)
IndexError: list index out of range
The error message list index out of range means that we tried to index a list
(in this case keys); however, the list does not contain enough elements for
us to retrieve something at that index, that is keys[0]. If you did not make a
keypress fast enough, the keys list will be empty, [], meaning it has no
zeroth element, and keys[0] will not work. And so, we need to build in
some kind of conditional, to only print if a key has been pressed. We could
use:
if len(keys)>0:
⌴⌴⌴⌴print(keys[0].name, keys[0].rt)In Python, the method len() returns the length of a list. In this case, we are
checking “Is the length of my keys greater than 0? If yes, print the key
name and rt”. Another, slightly neater approach we could use in this case is:
if keys:
⌴⌴⌴⌴print(keys[0].name, keys[0].rt)
When applied to a list, this is testing the same thing, that is, if keys will
return True only if the list contains elements. These are some rather specific
first examples of If statements in the wild; let’s practise using If statements
in a simpler context-response contingent feedback.
4.3 If Statements
If statements are an important building block of almost all software. People
use if statements to run code that is specific to a certain occasion, for
example to turn on the heating in a room when the temperature is low (e.g.
below 15 degrees Celsius) or turn off the heating when the temperature is
comfortable (e.g. above 20 degrees). You could even incorporate a third
option: to turn on the air conditioning when the temperature is too high (e.g.
above 25 degrees).
In experimental psychology, you can use if statements when you want
your experiment to do one thing when a participant’s response is correct,
but something else if it is not. To see this first hand, use the following code
to gather your keypress response after you present your letter:
if keys and keys[0].name == this_letter:
⌴⌴⌴⌴print('Correct!')
else:
⌴⌴⌴⌴print('Incorrect')
You should recognise the double “is equal to” sign (==) from the chapter on
Booleans. It makes what programmers call a conditional statement, which
always results in a Boolean. In other words, the outcome can either be True
or False, but nothing else. So, keys[0].name == this_letter: means “if
the variable keys[0].name has the same value as the variable this_letter,
then execute the code in the following lines”.
What code is in the following lines is determined by indentation: the
amount of whitespace before each line of code (recall that we were
introduced to this in the context of for loops previously). In this example,you hopefully see the word “Correct!” appear in the Output window when
you select the correct letter key, and the word “Incorrect” appears in the
Output window when you select the incorrect letter key.
Note that the rules on indentation that we learned in the last chapter for
For loops also apply for any conditional statement (such as If statements).
Indentation indicates the conditional statement to which a line of code
belongs.
Now you know how to use a conditional statement to print feedback, you
could use it to present feedback to your participant. Make another text
stimulus that will be used to present feedback:
# make some text for feedback
feedback = visual.TextBox2(
⌴⌴⌴⌴win,
⌴⌴⌴⌴text='',
⌴⌴⌴⌴pos=(0, 0),
⌴⌴⌴⌴letterHeight=20,
⌴⌴⌴⌴alignment='center'
⌴⌴⌴⌴)
Then, after your keypress response, use a conditional statement to set the
text and present the feedback:
# set the text based on the response
if keys and keys[0].name == this_letter:
⌴⌴⌴⌴feedback.setText('Correct!')
else:
⌴⌴⌴⌴feedback.setText('Incorrect')
# present the feedback
feedback.draw()
win.flip()
core.wait(2)
It is worth noting here that key names are case sensitive. So, if you
accidentally used uppercase values for your vowels ([‘A’, ‘E’, ‘I’, ‘O’,
‘U’]), then you may have been told that you were incorrect here. Another
handy tip is that you can convert string values between upper and lower
case using .lower() and .upper(). So, if you did use uppercase letters as
your stimuli, and this was intentional, make sure to use if keys[0].name
== this_letter.lower(): in your if statement.4.4 Typed Responses
A useful thing about TextBox2 is that it can be used not only to present text
but also to gather typed responses. It can be useful to ask participants to
type an open response. For instance, imagine we present them with a
picture and then ask them to recall everything that they remember about
that picture. We know how to present a picture (from Chapter 3) but what
about gathering typed responses? TextBox2 has the attribute editable which
indicates if the text in the object should be editable by the participant. If set
to True, the participant will be presented with a textbox that they can edit:
# make some text for feedback
textinput = visual.TextBox2(
⌴⌴⌴⌴win,
⌴⌴⌴⌴text='',
⌴⌴⌴⌴pos=(0, 0),
⌴⌴⌴⌴letterHeight=20,
⌴⌴⌴⌴alignment='center',
⌴⌴⌴⌴editable = True
⌴⌴⌴⌴)
Now, the only thing is that in order for the participant to see the text they
type dynamically changing, you can’t just use core.wait(2) to halt the
screen; because this literally halts the screen, we wouldn’t see dynamically
changing text. This is another instance where it is important to present and
update stimuli based on frames. So, start by making an editable text
stimulus:
# make an editable textbox
textinput = visual.TextBox2(
⌴⌴⌴⌴win,
⌴⌴⌴⌴text='',
⌴⌴⌴⌴pos=(0, 0),
⌴⌴⌴⌴letterHeight=20,
⌴⌴⌴⌴alignment='center',
⌴⌴⌴⌴editable = True
⌴⌴⌴⌴)
# set the textbox to draw automatically on every win.flip
textinput.setAutoDraw(True)
# how many frames do we present for
nFrames = 300# draw the textinput
for frameN in range(nFrames):
⌴⌴⌴⌴win.flip()
What’s nice about this is because you can dynamically check the text typed
into the textbox (in this case through checking textinput.text), you can
continuously check the characteristics of the typed string. For instance, you
might want to display a character count or check if a keyword has been
typed. Let’s imagine we are looking out for the keyword “banana” and you
want to change the colour of the text to be green if the keyword is typed.
Update your code slightly to watch for a keyword:
# how many frames do we present for
nFrames = 300
keyword = 'banana'
# draw the textinput
for frameN in range(nFrames):
⌴⌴⌴⌴# check if the typed input contains the keyword
⌴⌴⌴⌴if keyword in textinput.text:
⌴⌴⌴⌴⌴⌴⌴⌴textinput.setColor('green')
⌴⌴⌴⌴else:
⌴⌴⌴⌴⌴⌴⌴⌴textinput.setColor('white')
⌴⌴⌴⌴win.flip()
Hopefully you saw your text turn green once you type the word “banana”!
4.5 Mouse Responses
Although most psychology experiments use keyboards for their response
modality, there are many neat things about mouse responses that can be
used to make some very cool experiments. First, mouse responses (in
PsychoPy) also translate to touch responses on touch screen devices.
Second, mouse responses not only have click behaviour, but they also have
trajectories. This means you can make things track the mouse, or store the
movement paths from the mouse. Third, you can use the mouse to create
cool interactive effects, such as hover effects. To make an instance of a
mouse object, we can use the event module:
# make a mouse (it will use win by default)
mouse = event.Mouse()
Then let’s make a shape stimulus:# make a shape to track the mouse
square = visual.ShapeStim(win,
⌴⌴⌴⌴vertices=[[20, 20], [-20, 20], \
⌴⌴⌴⌴⌴⌴⌴⌴[-20, -20], [20, -20]], \
⌴⌴⌴⌴fillColor='darkred', \
⌴⌴⌴⌴size=2, \
⌴⌴⌴⌴pos=[300,0],
⌴⌴⌴⌴lineColor='red')
OK, let’s consider how we could make this simple square interact with our
mouse.
4.5.1 Fetching the Current Mouse Position
Fetching the current mouse position is easy. You can use mouse.getPos(),
which will return an (x,y) pair indicating current location in the window’s
unit space. Try adding:
nFrames = 100
square.setAutoDraw(True)
for frame in range(nFrames):
⌴⌴⌴⌴print(mouse.getPos())
⌴⌴⌴⌴win.flip()
Hopefully, you saw a pair of (x,y) coordinates returned repeatedly in the
Output window; this indicates the current mouse position. Now we know
we can get the mouse position, we could make the square track the mouse.
For example:
# set the square to be in the position of the mouse
for frame in range(nFrames):
⌴⌴⌴⌴square.setPos(mouse.getPos())
⌴⌴⌴⌴win.flip()
Alternatively, we could check if the mouse is hovering on something. Try
this:
for frame in range(nFrames):
⌴⌴⌴⌴if square.contains(mouse.getPos()):
⌴⌴⌴⌴⌴⌴⌴⌴square.setColor('green')
⌴⌴⌴⌴else:
⌴⌴⌴⌴⌴⌴⌴⌴square.setColor('darkred')
⌴⌴⌴⌴win.flip()The contains() method is something that lives in most stimuli in the visual
class; it returns True if a given (x,y) coordinate falls within that stimulus’
border. In this case, we’ve checked the current mouse location in the square.
If yes, we set the colour of the square to be green. Otherwise, we set the
colour of the square to be red.
4.5.2 Check the Status of the Mouse Buttons
There are a few different reasons that we might want to check the mouse
status. First, your mouse will typically have three buttons, a left button,
right button, and central scroller (which can also be used as a button). We
can check the status of these at any point using
mouse.getPressed(): this will return a list of three elements
indicating if the mouse is currently pressed in 1 or not 0.
mouse.isPressedIn(x): this will return a binary value indicating if
the mouse is currently pressed in an object (x) or not.
Together these can be pretty powerful. At a simple level, we could make a
trial/loop end on a mouse click:
for frame in range(nFrames):
⌴⌴⌴⌴if square.contains(mouse.getPos()):
⌴⌴⌴⌴⌴⌴⌴⌴square.setColor('green')
⌴⌴⌴⌴else:
⌴⌴⌴⌴⌴⌴⌴⌴square.setColor('darkred')
⌴⌴⌴⌴win.flip()
⌴⌴⌴⌴# end the loop early if the mouse is clicked
⌴⌴⌴⌴if sum(mouse.getPressed())>0:
⌴⌴⌴⌴⌴⌴⌴⌴break
Note that unless we reset the colour of the square at the end of this loop, it
will stay green (because the trial/loop ended with the mouse in the square).
Following this, we could make a stimulus change location when it is
clicked, which would be the building blocks for a drag and drop task. For
instance, try this:
for frame in range(nFrames):
⌴⌴⌴⌴# if the mouse is pressed in the square
⌴⌴⌴⌴if mouse.isPressedIn(square):⌴⌴⌴⌴⌴⌴⌴⌴# set the square to be the location of the mouse
⌴⌴⌴⌴⌴⌴⌴⌴square.setPos(mouse.getPos())
⌴⌴⌴⌴win.flip()
This works! But it is a little clunky, if you move your mouse too fast, it can
sometimes be possible that your mouse cursor “escapes” the shape which
makes the dragging behaviour sticky. Instead, let’s try this:
# a boolean to indicate if a drag is currently
# in process
dragging = False
for frame in range(nFrames):
⌴⌴⌴⌴# if the mouse is pressed in the draggable,
⌴⌴⌴⌴# drag begins
⌴⌴⌴⌴if mouse.isPressedIn(square):
⌴⌴⌴⌴⌴⌴⌴⌴dragging = True
⌴⌴⌴⌴# if drag in progress, set the draggable
⌴⌴⌴⌴# to mouse location
⌴⌴⌴⌴if dragging:
⌴⌴⌴⌴⌴⌴⌴⌴square.setPos(mouse.getPos())
⌴⌴⌴⌴# if no mouse button is pressed in, the drag
⌴⌴⌴⌴# is over
⌴⌴⌴⌴if sum(mouse.getPressed())==0:
⌴⌴⌴⌴⌴⌴⌴⌴dragging = False
⌴⌴⌴⌴win.flip()
In this example, we add a bit more code, but it does make the behaviour
smoother. Specifically, we use isPressedIn() and getPressed() in
combination with one another to determine (a) when a drag starts (which is
when the mouse is pressed in the square) and (b) when a drag ends (which
is when there are no mouse buttons pressed down at all). Remember that
getPressed() returns a list of three values, which will be [0, 0, 0] when
nothing is pressed in (which sums up to 0, or to a value up to 3 is buttons
are pressed).
4.5.4 Check for Mouse Scroll Behaviour
Sometimes we might want our participants to be able to scroll a stimulus.
To do this, we need two things: our stimulus (which will scroll) and ourmouse (which will do the scrolling). We can fetch the travel of the mouse
wheel since the last call using getWheelRel(); this will return an (x,y)
value indicating direction of change (however for most standard mice, only
the y coordinate will change). Positive values indicate upward movements,
negative values indicate downward movements, and zero values indicate no
movements. Using this, we can change the position of the stimulus:
# starting y pos for the square
squarey = 0
for frame in range(nFrames):
⌴⌴⌴⌴# fetch the current mouse direction and
⌴⌴⌴⌴# move 10 pixels * mouse direction
⌴⌴⌴⌴squarey += 10 * mouse.getWheelRel()[1]
⌴⌴⌴⌴# set square position
⌴⌴⌴⌴square.setPos([300, squarey])
⌴⌴⌴⌴win.flip()
In this example, we first set the starting y coordinate of our stimulus
(squarey); then, we fetch the direction of the mouse wheel along the y axis
mouse.getWheelRel()[1]. We multiply this by 10 (this will end up being
10 pixels multiplied by a negative or positive value). We then add this value
to the current squarey and set the position of the square using that updating
y value square.setPos([300, squarey].
4.6 Using While Loops with the Mouse
We were introduced to while loops in the last chapter, and we were warned
of their potential perils (i.e. the risk of becoming stuck in a loop). However,
mouse responses might be a good example when a while loop is
appropriate. Let’s imagine we want to continue presenting stimuli, until the
mouse is inside the square. In this instance, we want to keep going, and
keep checking, until some condition has been met. For this, we use a while
loop.
while not square.contains(mouse.getPos()):
⌴⌴⌴⌴win.flip()
In this example, we continuously check if the mouse is in the square. If not,
we continue. Let’s complicate things by nesting a while within a for loop.
(You can just do this. Nobody will stop you.) For example, we might wantto make the square bounce to a random location when it is touched, and we
might want to do this ten times:
from numpy.random import randint
# repeat 10 times
for i in range(10):
⌴⌴⌴⌴# while the mouse is not in the square
⌴⌴⌴⌴while not square.contains(mouse.getPos()):
⌴⌴⌴⌴⌴⌴⌴⌴# flip the window (do nothing)
⌴⌴⌴⌴⌴⌴⌴⌴win.flip()
⌴⌴⌴⌴# change the square position to a random
⌴⌴⌴⌴# location
⌴⌴⌴⌴square.setPos([randint(-200, 200), \
⌴⌴⌴⌴⌴⌴⌴⌴randint(-200, 200)])
In this example, we have a while loop nested inside a for loop. What
matters is the level of indentation. Because the win.flip() is one level of
indent relative to the while loop, we know that this statement belongs to
that loop. Then, because the square.setPos([randint(-200, 200),
randint(-200, 200)]) is one level of intent relative to the for loop (at the
same level as the “while”), we know this is to be executed in the for loop. If
you got your indent wrong here, for example setting the square position in
the while loop, you would soon know about it, as you’d have a very quickly
jumping square, changing positions on every frame!
Fabulous! You should now know the basics (and some more advanced
tips!) of gathering keyboard responses, typed responses, and using the
mouse in various ways. You also now have two Frankenstein scripts of
various techniques for presenting stimuli (stimuli.py) and gathering
responses (responses.py). At this point, we’re probably about ready to put
this all together into an experiment!MAKE SOME NOISE
DOI: 10.4324/9781003174332-6
Welcome to another random intermezzo! In this chapter, you will learn how
to construct your own sounds, how to play them via PyGame, and how to
save them to a file. There are two upsides to this. First, you can show the
file you created to your loved ones, and they will be so proud of you!
Second, you can make a lot of noise while making the file. Let’s hope you
are a student, working in a computer lab, with access to functional speakers.
What Is Sound?
Good question! Sound is caused by vibrating air (or water, or any other
medium that can move your eardrums), which results in movement of the
tympanic membrane in your ear that is ultimately translated to neural
activity in the cochlea. When something vibrates between 20 and 20,000
times per second, it produces a sound that humans can hear (although many
humans are not able to hear the full spectrum equally well). The amount of
vibrations per second is called the frequency. The extend to which the
membrane is stretched is called the amplitude.
In order to make sound with your computer, you need to be able to make
a signal that goes up and down with a certain amplitude, at a frequency
between 20 and 20,000 times per second.
Sinusoid and Noise
You might remember such a signal from secondary school maths. If you
don’t, here’s a spoiler: it’s a sinusoid. You can create one using NumPy. To
do so, you need a range of numbers between 0 and 2π (i.e. two times the
number pi or roughly 6.3). You use 2 pi, because it is the width of a single
sine wave. NumPy’s sin function can turn that range of numbers into an
actual wave. Type the following code into an Interpreter:import numpy
# create a range of numbers between 0 and 2 pi
x = numpy.arange(0, 2*numpy.pi, 0.01)
# create a sine wave
sine = numpy.sin(x)
Now that you created a sine wave, you can visualise it by using Matplotlib:
from matplotlib import pyplot
# plot the sine wave
pyplot.plot(x, sine)
pyplot.show()
Looks cool, right? But not quite cool enough… Let’s make some actual
NOISE!
# create a bunch of random numbers
# (with the same length as the sine wave)
noise = numpy.random.rand(len(sine))
# compare the sinusoid and the noise
pyplot.plot(sine)
pyplot.plot(noise)
pyplot.show()
For the next bit, let’s concentrate on the sine wave to learn about the basics
of digital sounds. If you look at the y-axis, you can see that the sine wave’s
maximum is 1 and its minimum is −1. That means its amplitude is 1. This is
a little low for a sound, so you will need to adjust it. Simply multiply the
sine by 16383, which should be high enough:
sine = sine * 16383
pyplot.plot(x, sine)
pyplot.show()
The wave still looks the same, but the y-axis has changed: the wave’s
amplitude is a lot higher now! Now turn your attention to the sound’s
frequency.
When you created the x variable, you used NumPy’s arange function.
This creates a range of numbers between a starting point (0) and an ending
point (2*pi), with a certain step size. The higher the step size, the fewer
points there will be in the wave. We call this number of points the amount
of samples. Let’s see what sampling does to a wave’s shape:high = numpy.arange(0, 2*numpy.pi, 0.01)
mid = numpy.arange(0, 2*numpy.pi, 0.5)
low = numpy.arange(0, 2*numpy.pi, 2)
pyplot.plot(high, numpy.sin(high))
pyplot.plot(mid, numpy.sin(mid))
pyplot.plot(low, numpy.sin(low))
pyplot.show()
As you can see, the higher the step size (thus the fewer samples), the poorer
the representation of the sine wave becomes. Fortunately, your computer
has more than enough computing power to deal with high numbers of
samples, so this shouldn’t be a problem. We call the amount of samples per
second the sampling rate, and it can go up to several millions on fancy
systems! For this example, we will stick to 48,000, which is just about
enough to cover all sounds that a human can actually hear.
Open a new file in a script editor and call it make_sound.py. For this to
work, you need to import some libraries. NumPy is one of them, to create
the waves. To actually turn them into sound, you’ll need two more: PyGame
and wave. PyGame is mostly used for game development, but we can use its
mixer module. This allows you to make sounds out of the sound waves that
you create with NumPy. wave is a Python module that allows you to create
.wav files. We will come back to that later. For now, just put this at the
beginning of your script:
import wave
import numpy
import pygame
First, you should define the constants that you just learned about:
# maximal sound amplitude and sampling rate
MAXAMP = 16383
SAMPLERATE = 48000
You will also need to set the amount of channels. Let’s go for mono now,
which is one channel. This will make the same sound come out of all
speakers.
# mono
NCHANNELS = 1Now you need to decide what your sound’s length and frequency should be.
Let’s go for a three-second sound of 1,000 vibrations per second (= 1,000
Herz):
# sound length (seconds) and frequency (Herz)
SOUNDLEN = 3.0
SOUNDFREQ = 1000
Time for a few quick calculations: if your sound has a length of three
seconds and a frequency of 1,000 Herz, that means your sound will contain
3 * 1000 = 3,000 cycles:
# calculate the total amount of cycles
ncycles = SOUNDLEN * SOUNDFREQ
The sound will be sampled with 48,000 samples per second, so your entire
sound will consist of three seconds * 48,000 samples = 144,000 samples. In
every cycle, there will thus be 144,000 samples / 3,000 cycles = 48 samples
per cycle (spc).
# calculate the total amount of samples
nsamples = SOUNDLEN * SAMPLERATE
# calculate the number of samples per cycle
spc = nsamples / ncycles
Now that you know the amount of samples per second, you can calculate
the step size for each cycle. Remember that a single vibration was made out
of numbers between 0 and 2*pi, and that the step size determined the
wave’s representation. Let’s make that range and the associated sine wave:
# the stepsize is the distance between samples within a cycle
# (divide the range by the amount of samples per cycle)
stepsize = (2*numpy.pi) / spc
# create a range of numbers between 0 and 2*pi
x = numpy.arange(0, 2*numpy.pi, stepsize)
# make a sine wave out of the range
sine = numpy.sin(x)
The next step is to crank up the sine wave’s amplitude:
# increase the sine wave's amplitude
sine = sine * MAXAMPNow that you have created a single cycle (that’s one vibration), you can
simply repeat it to create a longer sound. After all, a sound is nothing more
than a series of vibrations! To repeat the sound, you can use NumPy’s tile
function. This allows you to provide an array (your sine wave) and the
number of times you want it repeated (an integer):
# repeat the sine wave!
allsines = numpy.tile(sine, int(ncycles))
If you want to see if this works, simply plot it:
from matplotlib import pyplot
pyplot.plot(numpy.tile(sine, 4))
pyplot.plot(numpy.tile(sine, 2))
pyplot.plot(sine)
pyplot.show()
Numbers to Sound
You currently have a series of 3,000 cycles of a wave. The entire array
contains 144,000 numbers and represents a three-second long sound with a
frequency of 1,000 cycles per second. That’s impressive. Time to make an
actual sound out of that representation!
To make a sound, you can use PyGame’s mixer module. This
conveniently allows you to turn a NumPy array (such as the allsines
vector that you just created) into a mixer.Sound instance. You’ll have to
initialise the mixer module first:
# initialise the mixer module
# (it requires the sampling rate and the number of channels)
pygame.mixer.init(frequency=SAMPLERATE, channels=NCHANNELS)
# now create a sound out of the allsines vector
tone = pygame.mixer.Sound(allsines.astype('int16'))
You might be confused by the allsines.astype('int16') bit. It turns all
numbers in allsines into 16-bit integers, which is the format that PyGame
needs.
To play the sound, use its play method:
# play the sinusoid sound
tone.play()Run the script (if you haven’t yet) and enjoy your beautiful, self-made, pure
tone!
As promised, let’s briefly return to noise. Noise is actually a bit easier to
make. First, simply create an array of random numbers with the length of
the amount of samples in your sound (using the same sound length and the
same sampling rate):
# create a series of random numbers
noise = numpy.random.rand(int(SOUNDLEN * SAMPLERATE))
The sine wave’s values were between −1 and 1, whereas the noise’s values
are now between 0 and 1. To correct this, multiply all noise by 2 (so the
values are between 0 and 2) and then subtract 1 (so the values are between
−1 and 1):
# correct the value range (-1 to 1)
noise = (noise * 2) - 1
Now you can set the correct amplitude, as you did with the sine wave:
# increase the noise's amplitude
noise = noise * MAXAMP
And all that is left to do now is to turn it into an actual sound!
# turn the noise vector into a sound
whitenoise = pygame.mixer.Sound(noise.astype('int16'))
# play the noise sound
whitenoise.play()
Pretty cool, eh? Maybe you should turn up your computer’s volume, so that
everyone around you can enjoy the sounds you just created.
Naturally, you want to share your work with your loved ones.
Regrettably, PyGame’s sounds are constructed in temporary memory, so
you can’t save them to a file directly. Because it would be such a shame for
your family and friends to miss the opportunity to hear your beautiful noise,
let’s learn how to save your sound to a file you can share.
First, you need to open a new file. In this case, you need to open two:
one for the sinusoid (the pure tone) and one for the noise. To do this, you
can use the wave module’s open function. This function requires a file name(a string that ends with ‘.wav’) and a letter indicating the opened files’
mode (use 'w' for ‘write’).
# open new wave file objects
tonefile = wave.open('pure_tone.wav', 'w')
noisefile = wave.open('noise.wav', 'w')
Now you need to set some parameters. These are the frame rate, which is
the sampling rate (you defined that earlier), the number of channels (also
defined earlier), and the sample width (set this to 2 and don’t think about
it):
# set parameters for the pure tone
tonefile.setframerate(SAMPLERATE)
tonefile.setnchannels(NCHANNELS)
tonefile.setsampwidth(2)
# set the same parameters for the noise
noisefile.setframerate(SAMPLERATE)
noisefile.setnchannels(NCHANNELS)
noisefile.setsampwidth(2)
Now that the wave files know what kind of sound they are getting, you can
write the sound to them. However, they require the sound to be in a specific
format. This format is a raw buffer, which is basically a string of bytes (this
means nothing to humans, but computers can read it). You can get the buffer
from mixer.Sound objects, by using their get_buffer method. This buffer
contains a byte representation of itself in its raw property. You should write
precisely that to the files:
# get buffers
tonebuffer = tone.get_raw()
noisebuffer = whitenoise.get_raw()
# write raw buffer to the wave file
tonefile.writeframesraw(tonebuffer)
noisefile.writeframesraw(noisebuffer)
The only thing that’s left to do now is neatly close the two wave file
objects, by using their close method.
# neatly close the wave file objects
tonefile.close()
noisefile.close()If you run your script, you should now see two new files in the same folder
that contains your script file (make_sound.py). They should be named
‘pure_tone.wav’ and ‘noise.wav’, and you should be able to play them with
a media player.
This is still a relatively simple script, but it can be a good start for you to
create more funky sounds. By simply changing SOUNDFREQ, you can already
change the frequency of the pure tone. Try to think of some more ways to
mess with it! (For jokes, change numpy.sin into numpy.tan and enjoy.)<i>from psychopy import visual, core, event</i> <i>from
psychopy.hardware import keyboard</i>
<i># make a window</i>
<i>win = visual.Window(size=[1024, 768], \</i> ⌴⌴⌴⌴<i>fullscr=False,
units='pix', color=(0,0,0), \</i> ⌴⌴⌴⌴<i>colorSpace='rgb', screen=0)</i>
<i># make a keyboard instance</i> <i>kb = keyboard.Keyboard()</i>
<i># a fixation point</i> <i>fixation = visual.TextBox2(</i>
⌴⌴⌴⌴<i>win</i>,
⌴⌴⌴⌴<i>text='+'</i>,
⌴⌴⌴⌴<i>pos=(0, 0)</i>,
⌴⌴⌴⌴<i>letterHeight=20</i>, ⌴⌴⌴⌴<i>alignment='center'</i> <i>)</i>
<i># an arrow for our cue</i> <i>arrowVert = [[-20, 5], [-20, -5], [0, -5], \
</i> ⌴⌴⌴⌴<i>[0, -10], [20, 0], [0, 10], [0, 5]]</i>
<i>cue = visual.ShapeStim(win, vertices=arrowVert, \</i>
⌴⌴⌴⌴<i>fillColor='darkred', size=2, pos=[0, 0], \</i>
⌴⌴⌴⌴<i>lineColor='red')</i>
<i># a circle for our target</i> <i>target = visual.Circle(win, size=20, pos=
[-300, 0], \</i> ⌴⌴⌴⌴<i>lineColor='white', fillColor='lightGrey')</i>
<i># draw the fixation</i> <i>fixation.draw()</i>
<span id="p83" aria-label="83. " epub:type="pagebreak" role="doc￾pagebreak"/><i>win.flip()</i> <i>core.wait(1.5)</i>
<i># draw the cue</i>
<i>cue.draw()</i><i>win.flip()</i>
<i>core.wait(0.05)</i>
<i># draw the target</i> <i>target.draw()</i>
<i>win.flip()</i>
<i># wait for a response</i> <i>keys = kb.waitKeys(keyList=['left', 'right',
'escape'])</i>
<i># time, in seconds, we want</i> <i>desired_time = 1.5</i>
<i># monitor frame rate</i> <i>framerate = 60</i>
<i># total frames required to get close to desired times</i> <i>totalframes =
int((framerate/1.0)*desired_time)</i>
<i># print how far off we will be</i> <i>print('Stimulus will be presented
for ', \</i> ⌴⌴⌴⌴<i>totalframes, ' frames')</i> <i>print('Actual time will
be ', totalframes/framerate)</i>
<i>for frameN in range(totalframes):</i> ⌴⌴⌴⌴<i>fixation.draw()</i>
⌴⌴⌴⌴<i>win.flip()</i>
<i>def secs2frames(desired_time, framerate=60):</i> ⌴⌴⌴⌴<i>'''</i>
⌴⌴⌴⌴<i>A function to convert desired time in seconds</i> ⌴⌴⌴⌴<i>to
frames</i>
⌴⌴⌴⌴<i>Input:</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>desired_time (float) - desired time in seconds</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>framerate (int) - screen refresh rate</i>
⌴⌴⌴⌴<i>Output:</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>nFrames (int) - the number of frames required</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i>to present as close as possible to desired</i>⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i>time in seconds.</i> ⌴⌴⌴⌴<i>'''</i>
⌴⌴⌴⌴<i># total frames required to get close to desired</i> ⌴⌴⌴⌴<i>#
times</i>
⌴⌴⌴⌴<i>nFrames = int((framerate/1.0)*desired_time)</i>
⌴⌴⌴⌴<i>return nFrames</i>
<i>print(secs2frames.__doc__)</i>
<i># get the desired number of frames</i> <i>fixTime = secs2frames(1.5)
</i> <i>cueTime = secs2frames(0.05)</i> <i>totalframes = fixTime +
cueTime</i>
<i># loop through frames for the trial (not including</i> <i># target time)
</i>
<i>for frameN in range(totalframes):</i>
<span id="p85" aria-label="85. " epub:type="pagebreak" role="doc￾pagebreak"/>⌴⌴⌴⌴<i>if frameN < fixTime:</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i># if
frameN is between 0 and fixTime -</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i># draw the
fixation</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i>fixation.setAutoDraw(True)</i>
⌴⌴⌴⌴<i>elif fixTime <= frameN < totalframes:</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i>#
undraw the fixation</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i>fixation.setAutoDraw(False)
</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i># if frameN is between fixTime and</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i># totalframes- draw the cue</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>cue.setAutoDraw(True)</i>
⌴⌴⌴⌴<i>win.flip()</i>
<i># undraw the cue, draw the target</i> <i>cue.setAutoDraw(False)</i>
<i>target.setAutoDraw(True)</i> <i>win.flip()</i>
<i># wait for a response</i> <i>keys = kb.waitKeys(keyList=['left', 'right', \
</i> ⌴⌴⌴⌴<i>'escape'])</i>
<i>target.setAutoDraw(False)</i><i>for frameN in range(totalframes):</i>
⌴⌴⌴⌴<i>if frameN < fixTime:</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i># if frameN is
between 0 and fixTime -</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i># draw the fixation</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>fixation.setAutoDraw(True)</i>
⌴⌴⌴⌴<i>elif frameN == fixTime:</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i># reset clock
and clear past keyboard</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i># events at fixation
offset</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i>win.callOnFlip(kb.clock.reset)</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>win.callOnFlip(kb.clearEvents)</i>
⌴⌴⌴⌴<i>elif fixTime <= frameN < totalframes:</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i>#
undraw the fixation</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i>fixation.setAutoDraw(False)
</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i># if frameN is between fixTime and</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i># totalframes- draw the cue</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>cue.setAutoDraw(True)</i> <span id="p86" aria￾label="86. " epub:type="pagebreak" role="doc￾pagebreak"/>⌴⌴⌴⌴<i>win.flip()</i>
<i>if keys and keys[0].name == 'escape':</i> ⌴⌴⌴⌴<i>core.quit()</i>
<i>trial_info = {'cue_ori':90, 'target_x': -300, \</i>
⌴⌴⌴⌴<i>'corr_ans':'left'}</i>
<i># a list of 2 trials - we probably want more!</i> <i>trials = [ \</i>
⌴⌴⌴⌴<i>{'cue_ori': 0, 'target_x':-300, \</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>'corr_ans':'left'}, \</i> ⌴⌴⌴⌴<i>{'cue_ori':180,
'target_x': 300, \</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i>'corr_ans':'right'}, \</i>
⌴⌴⌴⌴<i>]</i>
<i># loop through our list of trials</i> <i>for trial in trials:</i>
⌴⌴⌴⌴<i># update stimuli for this trial</i>
⌴⌴⌴⌴<i>cue.setOri(trial['cue_ori'])</i>
⌴⌴⌴⌴<i>target.setPos([trial['target_x'], 0])</i><span id="p87" aria-label="87. " epub:type="pagebreak" role="doc￾pagebreak"/>⌴⌴⌴⌴<i># present out stimuli</i> ⌴⌴⌴⌴<i>for frameN in
range(totalframes):</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>if frameN < fixTime:</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i>fixation.setAutoDraw(True)</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>elif frameN == fixTime:</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i># reset the clock and clear past</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i># keyboard events</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i>win.callOnFlip(kb.clock.reset)</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i>win.callOnFlip(kb.clearEvents)</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>elif fixTime <= frameN < totalframes:</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i># undraw the fixation</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i>fixation.setAutoDraw(False)</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i># draw the cue</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i>cue.setAutoDraw(True)</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>win.flip()</i>
⌴⌴⌴⌴<i># undraw the cue, draw the target</i>
⌴⌴⌴⌴<i>cue.setAutoDraw(False)</i>
⌴⌴⌴⌴<i>target.setAutoDraw(True)</i> ⌴⌴⌴⌴<i>win.flip()</i>
⌴⌴⌴⌴<i># wait for a response</i> ⌴⌴⌴⌴<i>keys =
kb.waitKeys(keyList=['left', 'right', \</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i>'escape'],
clear=False)</i>
⌴⌴⌴⌴<i># undraw the target</i> ⌴⌴⌴⌴<i>target.setAutoDraw(False)
</i>
⌴⌴⌴⌴<i># end if escape key pressed</i> ⌴⌴⌴⌴<i>if keys and
keys[0].name == 'escape':</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i>core.quit()</i>
<i># a list of 2 trials - we probably want more!</i> <i>trials =[ \</i>⌴⌴⌴⌴<i>{'cue_ori': 0, 'target_x':-300, \</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>'corr_ans':'left', 'soa':0.5}, \</i> ⌴⌴⌴⌴<i>
{'cue_ori':180, 'target_x': 300, '\</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i>corr_ans':'right',
'soa':1}, \</i> ⌴⌴⌴⌴<i>]</i>
⌴⌴⌴⌴<i># set the soa</i> ⌴⌴⌴⌴<i>soa = secs2frames(trial['soa'])</i>
⌴⌴⌴⌴<i>totalframes = fixTime + cueTime + soa</i>
⌴⌴⌴⌴<i># present our stimuli</i> ⌴⌴⌴⌴<i>for frameN in
range(totalframes):</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>if frameN < fixTime:</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i>fixation.setAutoDraw(True)</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>elif frameN == fixTime:</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i># reset the clock and clear past</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i># keyboard events</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i>win.callOnFlip(kb.clock.reset)</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i>win.callOnFlip(kb.clearEvents)</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>elif fixTime <= frameN < fixTime + cueTime:</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i># undraw the fixation</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i>fixation.setAutoDraw(False)</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i># draw the cue</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i>cue.setAutoDraw(True)</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>elif fixTime + cueTime <= frameN < totalframes:</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i># draw the fixation</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i>fixation.setAutoDraw(True)</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i># undraw the cue</i>
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴<i>cue.setAutoDraw(False)</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>win.flip()</i>
⌴⌴⌴⌴<i># undraw the cue, draw the target</i>
⌴⌴⌴⌴<i>target.setAutoDraw(True)</i> ⌴⌴⌴⌴<i>win.flip()</i>⌴⌴⌴⌴<i># wait for a response</i> ⌴⌴⌴⌴<i>keys =
kb.waitKeys(keyList=['left', 'right', \</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i>'escape'],
clear=False)</i> ⌴⌴⌴⌴<i>target.setAutoDraw(False)</i>
⌴⌴⌴⌴<i>fixation.setAutoDraw(False)</i>
<i>from psychopy import visual, core, event, data</i>
<i>conditions = data.importConditions('conditions.xlsx')</i>
<i>print(conditions)</i>
<i># import spreadsheet of trials</i> <i>conditions =
data.importConditions('conditions.xlsx')</i>
<i># make a trial handler</i> <i>trials = data.TrialHandler(trialList =
conditions</i>, ⌴⌴⌴⌴<i>nReps = 5, method = 'random')</i>
<i>thisExp = data.ExperimentHandler(</i>
⌴⌴⌴⌴<i>name='Best_Posner_Ever'</i>,
⌴⌴⌴⌴<i>dataFileName='output')</i>
<i>thisExp.addLoop(trials)</i>
⌴⌴⌴⌴<i># save the data</i> ⌴⌴⌴⌴<i>thisExp.addData('key_pressed',
keys[0].name)</i> ⌴⌴⌴⌴<i>thisExp.addData('key_rt', keys[0].rt)</i>
⌴⌴⌴⌴<i>thisExp.nextEntry()</i>
<i># a dictionary to handle global info</i> <i>expInfo = {</i>
⌴⌴⌴⌴<i>'fixTime': 1</i>, ⌴⌴⌴⌴<i>'cueTime':0.5</i> <i>}</i>
⌴⌴⌴⌴<i># get the desired number of frames</i> ⌴⌴⌴⌴<i>fixTime =
secs2frames(expInfo['fixTime'])</i> ⌴⌴⌴⌴<i>cueTime =
secs2frames(expInfo['cueTime'])</i>
<i>thisExp = data.ExperimentHandler(</i> ⌴⌴⌴⌴<i>name =
'Best_Posner_Ever'</i>, ⌴⌴⌴⌴<i>extraInfo=expInfo</i>,
⌴⌴⌴⌴<i>dataFileName = 'output')</i>
<i>from psychopy import visual, core, event, data, gui</i><i># a dictionary to handle global info</i> <i>expInfo = {</i>
⌴⌴⌴⌴<i>'fixTime': 1</i>, ⌴⌴⌴⌴<i>'cueTime':0.5</i>,
⌴⌴⌴⌴<i>'participant':''</i>, ⌴⌴⌴⌴<i>'session':''</i>, ⌴⌴⌴⌴<i>'group':
['A', 'B']</i>, ⌴⌴⌴⌴<i>'corrected vision':False</i> <i>}</i>
<i># present the dictionary as a pop up dialogue box</i> <i>dlg =
gui.DlgFromDict(expInfo)</i>
<i># check if the user pressed OK</i> <i>if not dlg.OK:</i>
⌴⌴⌴⌴<i>core.quit()</i>
<i># check if the user pressed OK</i> <i>if not dlg.OK:</i>
⌴⌴⌴⌴<i>core.quit()</i>
<span id="p93" aria-label="93. " epub:type="pagebreak" role="doc￾pagebreak"/><i># add date string to expInfo</i> <i># (not editable in dlg
box)</i> <i>expInfo['datestr'] = data.getDateStr()</i>
<i>thisExp = data.ExperimentHandler( \</i> ⌴⌴⌴⌴<i>name =
'Best_Posner_Ever', \</i> ⌴⌴⌴⌴<i>extraInfo=expInfo, \</i>
⌴⌴⌴⌴<i>dataFileName= \</i>
⌴⌴⌴⌴<i>'data/{participant}_{datestr}'.format(**expInfo), \</i>
⌴⌴⌴⌴<i>)</i>
⌴⌴⌴⌴<i># score accuracy</i> ⌴⌴⌴⌴<i>if keys[0].name ==
trial['corr_ans']:</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i>correct = 1</i> ⌴⌴⌴⌴<i>else:</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>correct = 0</i>
<i>thisExp.addData('correct', correct)</i>
<i># some feedback text</i> <i>feedback = visual.TextBox2(</i>
⌴⌴⌴⌴<i>win</i>,
⌴⌴⌴⌴<i>text=''</i>,⌴⌴⌴⌴<i>pos=(0, 0)</i>,
⌴⌴⌴⌴<i>letterHeight=20</i>, <span id="p94" aria-label="94. "
epub:type="pagebreak" role="doc￾pagebreak"/>⌴⌴⌴⌴<i>alignment='center'</i>, ⌴⌴⌴⌴<i>color =
'white'</i> ⌴⌴⌴⌴<i>)</i>
⌴⌴⌴⌴<i># score accuracy</i> ⌴⌴⌴⌴<i>if keys[0].name ==
trial['corr_ans']:</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i>correct = 1</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>feedback.setText('Correct!')</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>feedback.setColor('green')</i> ⌴⌴⌴⌴<i>else:</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>correct = 0</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>feedback.setText('Incorrect')</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>feedback.setColor('red')</i>
⌴⌴⌴⌴<i># show the feedback</i> ⌴⌴⌴⌴<i>for frameN in
range(feedbackFrames):</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>feedback.setAutoDraw(True)</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>win.flip()</i> ⌴⌴⌴⌴<i>feedback.setAutoDraw(False)
</i>
<i># import spreadsheet of trials</i> <i>blocksheet =
data.importConditions('blocks.xlsx')</i>
<i># make a trial handler for the blocks</i> <i>blocks =
data.TrialHandler(trialList=blocksheet, \</i> ⌴⌴⌴⌴<i>nReps=1,
method='random')</i>
<i># give this block of trials to the experiment handler</i>
<i>thisExp.addLoop(blocks)</i>
<i>for block in blocks:</i> ⌴⌴⌴⌴<i># import spreadsheet of trials</i>
⌴⌴⌴⌴<i>conditions = data.importConditions(block['blockfile'])</i>
⌴⌴⌴⌴<i># make a trial handler</i> ⌴⌴⌴⌴<i>trials =
data.TrialHandler(trialList=conditions, \</i> ⌴⌴⌴⌴⌴⌴⌴⌴<i>nReps=5,
method='random')</i>⌴⌴⌴⌴<i># give this block of trials to the experiment handler</i>
⌴⌴⌴⌴<i>thisExp.addLoop(trials)</i>
⌴⌴⌴⌴<i># set the opacity of the cue for this block</i>
⌴⌴⌴⌴<i>cue.setOpacity(block['cueopacity'])</i>
<i># make a trial handler for the blocks</i> <i>blocks =
data.TrialHandler(trialList=blocksheet</i>, ⌴⌴⌴⌴<i>nReps=1,
method='sequential')</i>
<i># import spreadsheet of trials</i> <i>blocksheet =
data.importConditions(</i>
⌴⌴⌴⌴<i>'blocks{group}.xlsx'.format(**expInfo))</i>
<i># a message to present between blocks</i> <i>blockintro =
visual.TextBox2( \</i> ⌴⌴⌴⌴<i>win, \</i>
⌴⌴⌴⌴<i>text='You will now start the next block\n ' \</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>+ 'use the arrow keys to respond to the ' \</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>+ 'location of the target\n press space ' \</i>
⌴⌴⌴⌴⌴⌴⌴⌴<i>+ 'to start', \</i> ⌴⌴⌴⌴<i>pos=(0, 0), \</i>
⌴⌴⌴⌴<i>letterHeight=20, \</i> ⌴⌴⌴⌴<i>alignment='center', \</i>
⌴⌴⌴⌴<i>color = 'white', \</i> ⌴⌴⌴⌴<i>)</i>
<span id="p97" aria-label="97. " epub:type="pagebreak" role="doc￾pagebreak"/>from psychopy import visual, core, event, data, gui from
psychopy.hardware import keyboard
def secs2frames(desired_time, framerate=60): ⌴⌴⌴⌴'''
⌴⌴⌴⌴A function to convert desired time in seconds ⌴⌴⌴⌴to frames
⌴⌴⌴⌴Input:
⌴⌴⌴⌴⌴⌴⌴⌴desired_time (float) - desired time in seconds
⌴⌴⌴⌴⌴⌴⌴⌴framerate (int) - screen refresh rate
⌴⌴⌴⌴Output:⌴⌴⌴⌴⌴⌴⌴⌴nFrames (int) - the number of frames required
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴to present as close as possible to desired
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴time in seconds.
⌴⌴⌴⌴'''
⌴⌴⌴⌴# total frames required to get close to desired ⌴⌴⌴⌴# times
⌴⌴⌴⌴nFrames = int((framerate/1.0)*desired_time) ⌴⌴⌴⌴return
nFrames
# a dictionary to handle global info expInfo = {
⌴⌴⌴⌴'fixTime': 1,
⌴⌴⌴⌴'cueTime':0.5,
⌴⌴⌴⌴'feedbackTime': 0.5,
⌴⌴⌴⌴'participant':'',
⌴⌴⌴⌴'session':'',
⌴⌴⌴⌴'group':['A', 'B'],
⌴⌴⌴⌴'corrected vision':False
⌴⌴⌴⌴}
# present the dictionary as a pop up dialogue box dlg =
gui.DlgFromDict(expInfo)
# check if the user pressed OK
if not dlg.OK:
⌴⌴⌴⌴core.quit()
# make a windowwin = visual.Window(size=[1024, 768], \ ⌴⌴⌴⌴fullscr=False, units='pix',
color=(0,0,0), \ ⌴⌴⌴⌴colorSpace='rgb', screen=0)
# make a keyboard instance
kb = keyboard.Keyboard()
# a fixation point
fixation = visual.TextBox2(
⌴⌴⌴⌴win,
<span id="p98" aria-label="98. " epub:type="pagebreak" role="doc￾pagebreak"/>⌴⌴⌴⌴text='+', ⌴⌴⌴⌴pos=(0, 0),
⌴⌴⌴⌴letterHeight=20,
⌴⌴⌴⌴alignment='center'
)
# an arrow for our cue
arrowVert = [[-20, 5], [-20, -5], [0, -5], \ ⌴⌴⌴⌴[0, -10], [20, 0], [0, 10], [0,
5]]
cue = visual.ShapeStim(win, vertices=arrowVert, \
⌴⌴⌴⌴fillColor='darkred', size=2, pos=[0, 0], \ ⌴⌴⌴⌴lineColor='red')
# a circle for our target
target = visual.Circle(win, size=20, pos=[-300, 0], \
⌴⌴⌴⌴lineColor='white', fillColor='lightGrey')
# some feedback text
feedback = visual.TextBox2(⌴⌴⌴⌴win,
⌴⌴⌴⌴text='',
⌴⌴⌴⌴pos=(0, 0),
⌴⌴⌴⌴letterHeight=20,
⌴⌴⌴⌴alignment='center',
⌴⌴⌴⌴color = 'white'
⌴⌴⌴⌴)
# a message to present between blocks blockintro = visual.TextBox2( \
⌴⌴⌴⌴win, \
⌴⌴⌴⌴text='You will now start the next block\n ' \ ⌴⌴⌴⌴⌴⌴⌴⌴+ 'use
the arrow keys to respond to the ' \ ⌴⌴⌴⌴⌴⌴⌴⌴+ 'location of the target\n
press space ' \ ⌴⌴⌴⌴⌴⌴⌴⌴+ 'to start', \
⌴⌴⌴⌴pos=(0, 0), \
⌴⌴⌴⌴letterHeight=20, \
⌴⌴⌴⌴alignment='center', \
⌴⌴⌴⌴color = 'white', \
⌴⌴⌴⌴)
# add date string to expInfo
# (not editable in dlg box)
expInfo['datestr'] = data.getDateStr()
# make an experiment handlerthisExp = data.ExperimentHandler( \ ⌴⌴⌴⌴name = 'Best_Posner_Ever', \
⌴⌴⌴⌴extraInfo=expInfo, \
⌴⌴⌴⌴dataFileName= \
⌴⌴⌴⌴'data/{participant}_{datestr}'.format(**expInfo), \ ⌴⌴⌴⌴)
<span id="p99" aria-label="99. " epub:type="pagebreak" role="doc￾pagebreak"/># import spreadsheet of trials blocksheet =
data.importConditions(
⌴⌴⌴⌴'blocks{group}.xlsx'.format(**expInfo))
# make a trial handler for the blocks blocks =
data.TrialHandler(trialList=blocksheet, ⌴⌴⌴⌴nReps=1,
method='sequential')
# give this block of trials to the experiment handler
thisExp.addLoop(blocks)
# add trials to the experiment handler for each block for block in blocks:
⌴⌴⌴⌴# show the block start message
⌴⌴⌴⌴blockintro.draw()
⌴⌴⌴⌴win.flip()
⌴⌴⌴⌴# wait for the participant to press space to start ⌴⌴⌴⌴keys =
kb.waitKeys(keyList=['space'], clear=True)
⌴⌴⌴⌴# import spreadsheet of trials
⌴⌴⌴⌴conditions = data.importConditions(block['blockfile'])
⌴⌴⌴⌴# make a trial handler⌴⌴⌴⌴trials = data.TrialHandler(trialList=conditions, \
⌴⌴⌴⌴⌴⌴⌴⌴nReps=5, method='random')
⌴⌴⌴⌴# give this block of trials to the experiment handler
⌴⌴⌴⌴thisExp.addLoop(trials)
⌴⌴⌴⌴# set the opacity of the cue for this block
⌴⌴⌴⌴cue.setOpacity(block['cueopacity'])
⌴⌴⌴⌴# loop through our list of trials ⌴⌴⌴⌴for trial in trials:
⌴⌴⌴⌴⌴⌴⌴⌴# get the desired number of frames ⌴⌴⌴⌴⌴⌴⌴⌴fixTime
= secs2frames(expInfo['fixTime']) ⌴⌴⌴⌴⌴⌴⌴⌴cueTime =
secs2frames(expInfo['cueTime']) ⌴⌴⌴⌴⌴⌴⌴⌴feedbackFrames =
secs2frames(expInfo['feedbackTime']) ⌴⌴⌴⌴⌴⌴⌴⌴# set the soa
⌴⌴⌴⌴⌴⌴⌴⌴soa = secs2frames(trial['soa']) ⌴⌴⌴⌴⌴⌴⌴⌴totalframes =
fixTime + cueTime + soa + feedbackFrames
⌴⌴⌴⌴⌴⌴⌴⌴# update stimuli for this trial
⌴⌴⌴⌴⌴⌴⌴⌴cue.setOri(trial['cue_ori'])
⌴⌴⌴⌴⌴⌴⌴⌴target.setPos([trial['target_x'], 0])
⌴⌴⌴⌴⌴⌴⌴⌴# present our stimuli
<span id="p100" aria-label="100. " epub:type="pagebreak" role="doc￾pagebreak"/>⌴⌴⌴⌴⌴⌴⌴⌴for frameN in range(totalframes):
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴if frameN < fixTime:
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴fixation.setAutoDraw(True)
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴elif frameN == fixTime:
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴# reset the clock and clear past
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴# keyboard events
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴win.callOnFlip(kb.clock.reset)
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴win.callOnFlip(kb.clearEvents)⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴elif fixTime <= frameN < fixTime + cueTime:
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴# undraw the fixation
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴fixation.setAutoDraw(False)
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴# draw the cue
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴cue.setAutoDraw(True)
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴elif fixTime + cueTime <= frameN < totalframes:
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴# draw the fixation
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴fixation.setAutoDraw(True)
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴# undraw the cue
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴cue.setAutoDraw(False)
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴win.flip()
⌴⌴⌴⌴⌴⌴⌴⌴# undraw the cue, draw the target
⌴⌴⌴⌴⌴⌴⌴⌴target.setAutoDraw(True)
⌴⌴⌴⌴⌴⌴⌴⌴win.flip()
⌴⌴⌴⌴⌴⌴⌴⌴# wait for a response
⌴⌴⌴⌴⌴⌴⌴⌴keys = kb.waitKeys(keyList=['left', 'right', \
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴'escape'], clear=False)
⌴⌴⌴⌴⌴⌴⌴⌴target.setAutoDraw(False)
⌴⌴⌴⌴⌴⌴⌴⌴fixation.setAutoDraw(False)
⌴⌴⌴⌴⌴⌴⌴⌴# end if escape key pressed ⌴⌴⌴⌴⌴⌴⌴⌴if keys and
keys[0].name == 'escape': ⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴core.quit()
⌴⌴⌴⌴⌴⌴⌴⌴# score accuracy
⌴⌴⌴⌴⌴⌴⌴⌴if keys[0].name == trial['corr_ans']:
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴correct = 1
⌴⌴⌴⌴⌴⌴⌴⌴else:⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴correct = 0
⌴⌴⌴⌴⌴⌴⌴⌴# save the data
⌴⌴⌴⌴⌴⌴⌴⌴thisExp.addData('key_pressed', keys[0].name)
⌴⌴⌴⌴⌴⌴⌴⌴thisExp.addData('key_rt', keys[0].rt)
⌴⌴⌴⌴⌴⌴⌴⌴thisExp.addData('correct', correct)
⌴⌴⌴⌴⌴⌴⌴⌴thisExp.nextEntry()
<span id="p101" aria-label="101. " epub:type="pagebreak" role="doc￾pagebreak"/>⌴⌴⌴⌴⌴⌴⌴⌴# score accuracy ⌴⌴⌴⌴⌴⌴⌴⌴if
keys[0].name == trial['corr_ans']: ⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴correct = 1
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴feedback.setText('Correct!')
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴feedback.setColor('green') ⌴⌴⌴⌴⌴⌴⌴⌴else:
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴correct = 0
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴feedback.setText('Incorrect')
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴feedback.setColor('red')
⌴⌴⌴⌴⌴⌴⌴⌴# show the feedback
⌴⌴⌴⌴⌴⌴⌴⌴ frameN in range(feedbackFrames):
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴feedback.setAutoDraw(True)
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴win.flip()
⌴⌴⌴⌴⌴⌴⌴⌴feedback.setAutoDraw(False)
5.7 Understanding the Data
After you’ve done a run through of your task, you’ll notice a folder called
“data” in the directory where your experiment.py is saved. This folder is
where your data will be saved. You’ll notice three file types saved:
.csv: Your experimental data – each row will be a trial and each
column a variable..psydat: A file type ideal for batch processing of data with Python
scripts can even be used to recreate csv and excel files!
.log: A chronological, timestamped log of everything that happened in
your experiment.
We’re going to open the .csv file. This file will contain one row per trial and
a column per variable. You’ll notice a few variables that are stored by
default from the trial handler:
.thisN – the current trial number within our blocks loop.
.thisRepN – the current repetition of our blocks loop.
.thisTrialN – the current trial number within our trials loop.
.thisIndex – the original row index of our trial within our spreadsheet.
Of particular interest to us is the “correct”, “key_rt”, and “condition”
column. These will provide the data we need to address our research
question. We could in theory just eyeball the data in Excel; however,
another, widely used, use for Python is data analysis – so let’s move on to
how to analyse data in Python!MAKE SOME NOISE
DOI: 10.4324/9781003174332-8
In this chapter, you’ll learn how to make a musical instrument out of a
joystick or game controller. If you don’t have one of those, you can also use
the keyboard. Although this might seem like a weak excuse to make some
noise, it will actually be a very good programming exercise. If you also
manage to annoy the people around you with obnoxious sound, that’s just a
bonus!
Turning your joystick or keyboard into a musical instrument won’t
require you to be a modern-day MacGyver. Instead, you can write a script
that responds to a button press by making a sound. That’s not to say this is
easy: Writing a script that responds to events requires some abstract
thinking.
Before you start with the fun stuff, create a new folder. Within that
folder, create a new Python script and name it “constants.py”. Open it in an
editor to define some defaults:
# Set the display type to 'pygame'
DISPTYPE = 'pygame'
# Make sure that the DISPSIZE matches your monitor resolution!
DISPSIZE = (1920, 1080)
Do You Have A Joystick?
First, let’s clarify the terminology. The term “joystick” in a strict sense
applies to devices that have a pivoting stick that allows users to fly an
aeroplane or helicopter. In a broader sense, the term “joystick” often also
applies to any gaming controller. In this chapter, the term “joystick” will
refer to this broader class of input devices. Joysticks are not only useful for
playing computer games but can also be used in psychological research.
A lot of joysticks have two control sticks (mini-joysticks) that each
cover two axes (movement directions), a couple of buttons, and a hat.That’s not a fancy top hat, a baseball cap, or something that was knitted by
your grandmother. For joysticks, a hat is a special button that you can push
in four directions. If you ever owned a GameBoy, you might recall the four￾point button that controlled your movement. That button was a “hat”.
Some joysticks will also carry “balls”. (In a previous edition, this
parenthetical hinted at how some people might see the humour in “joysticks
with balls” but then someone left a review on the website of a major web
retailer to point out how this book and its author were “immature”. So now
I feel self-conscious about making childish and unprofessional jokes.) The
concept behind these is very similar to that of an old computer mouse: You
can roll a ball, and the joystick will convert the roll into a movement in a
two-dimensional plane.
Another cool thing about joysticks is that some offer a “rumble” feature.
It allows programmers to make the controller vibrate to give vibrotactile
feedback. You can find this feature in games, for example if you ram a car
or shoot a gun; but you can also use it to give feedback to participants in
your psychological experiment.
In this chapter, the focus is on the joystick’s buttons. If you don’t have a
joystick, you can substitute the buttons with the number keys.
Using a Joystick
Programming for a joystick is easier than you might think, and it is very
similar to using the mouse or a keyboard through PyGaze or PsychoPy.
There are a few libraries that offer excellent functionality for joysticks,
including PyGame, PyGaze, and PsychoPy. In this chapter, PyGaze is used
for no particular reason at all. It’s a nice library, and it offers everything you
need for this project to work. Make sure you install it if you haven’t yet, by
running the following in a terminal or command prompt:
python -m pip install python-pygaze
In Python, you can import the Joystick class from PyGaze’s joystick
module:
from pygaze.joystick import Joystick
You could then initialise a joystick object called js:
js = Joystick()PyGaze will automatically detect and engage the first joystick attached to
your computer. Obviously, this only works if one is actually plugged in.
After initialising the joystick, you can poll the buttons with a single
function:
js.get_joybuttons()
You can specify a list of allowed buttons and a response timeout in
milliseconds:
button, presstime = js.get_joybuttons(joybuttonlist=[0,4,6], \
⌴⌴⌴⌴timeout=3000)
The get_joybuttons method will return which button was pressed and at
what time it was pushed. In the above example, button is an integer that
indicates what button was pressed or None when no button was pressed.
presstime will be a float with a timestamp that is relative to when PyGaze
was imported.
If you have a joystick at your disposal, now would be the time to start
coding. In the same folder as the constants.py you created a bit earlier,
create a new Python script. You could call it “noisemaker_joystick.py”.
Start by importing the Joystick and the Sound classes:
from pygaze.joystick import Joystick
from pygaze.sound import Sound
from pygaze.display import Display
Now you want to initialise a Joystick instance to be able to use it as an input
device. You should also initialise a Display. This isn’t strictly necessary but
is for the sake of consistency with the keyboard implementation (which
does require a Display to be active).
# initialise a Display instance
disp = Display()
# create a Joystick instance
# ('dev' is short for 'device')
dev = Joystick()
The next step is to create a function that checks if any buttons were pressed.
The function’s input should be the device that you want it to use, which is
the joystick. The function’s output should be the number of the button thatwas pressed (or None when no button was pressed). You might wonder why
you would want to create a custom function for this, while the Joystick
class’s get_joybutton does almost exactly the same thing. There is no
programming-related reason to do it, but it’s a good practice exercise!
As you might remember from the Functions chapter, a function
definition always starts with def, followed by the function’s name, then the
inputs between round brackets, and it ends with a colon. Like so:
# definition of a function to get user input
def get_input(device):
The code that makes up the function should be indented, preferably by four
spaces per line. It should check whether a button is pressed, but with a low
timeout:
⌴⌴⌴⌴# wait for a button press for about 10 ms
⌴⌴⌴⌴button, presstime = device.get_joybutton(timeout=10)
The result should be returned as an output:
⌴⌴⌴⌴# return the button number (or None)
⌴⌴⌴⌴return button
That’s it for now. Skip over the next chapter on using a keyboard and
continue with the chapter on Playing Sounds On Button Presses.
Using a Keyboard
If you don’t have a joystick at hand, you can use your keyboard instead.
Here, PyGaze’s Keyboard class is used to interact with the keyboard. You
can import the Keyboard class from PyGaze’s keyboard module:
from pygaze.keyboard import Keyboard
To initialise an instance of the class, you can use the following:
kb = Keyboard()
As with the Joystick class, you can specify a default key list and timeout.
You can use the range function to generate a list of the numbers between 0
and 10 (not inclusive of the end point!), which are the names for the number
keys. Because the Keyboard class requires a list of strings to be passed askey names, you should convert the generated numbers to strings. You can
do this with the map function, which can apply a function of your choice to
an entire list at once. You also need the str function, which can convert
numeric values into strings. Combining the two, you could do the
following:
numbers = range(0, 10)
stringnumbers = map(str, numbers)
kb = Keyboard(keylist=stringnumbers)
This would produce a Keyboard instance that only allows you to press the
number keys. (Note: These are not the numpad keys, but the numbers
aligned towards the top of your keyboard!)
Let’s start programming to implement the above example. In the same
folder as the constants.py script that you created a bit earlier, create a new
Python script. You can name it “noisemaker_keyboard.py”. First, import the
Keyboard and Sound classes
from pygaze.keyboard import Keyboard
from pygaze.sound import Sound
You should also import the Display class, because the Keyboard only works
if there is an active Display (this is not true for the Joystick and Sound
classes, by the way).
from pygaze.display import Display
Time to initialise a Display and a Keyboard instance. Remember, the
Keyboard instance should only respond to number keys!
# initialise a Display instance
# (required for the Keyboard to work)
disp = Display()
# create a range of numbers
numbers = range(0,10)
# turn the numbers from integer values into strings
numbers = list(map(str, numbers))
# create a Keyboard instance
dev = Keyboard(keylist=numbers)
The next step is to create a function that checks if any keys were pressed.
The function’s input should be the device that you want it to use, which isthe keyboard. The function’s output should be the number of the key that
was pressed (or None when no key was pressed). You might wonder why
you would want to create a custom function for this, while the Keyboard
class’s get_key does almost exactly the same thing. There is no
programming-related reason to do it, but it’s a good practice exercise!
As you might remember from the Functions chapter, a function
definition always starts with def, followed by the function’s name, then the
inputs between round brackets, and it ends with a colon. Like so:
# definition of a function to get user input
def get_input(device):
The code that makes up the function should be indented, preferably by four
spaces per line. It should check whether a button is pressed, but with a low
timeout:
⌴⌴⌴⌴# wait for a button press for about 10 ms
⌴⌴⌴⌴key, presstime = device.get_key(timeout=10)
The result will be a key name, or None. A key name will be a string, and it
will be one of the number keys. In this function, you want the output to be
an integer value. So you should convert the key name (a string) into a
number. You can do this by using the int function, which turns numeric
values (including strings that hold only numbers) into integers.
Unfortunately, the int function will produce an error when you ask it to
convert a None, because a None is not a numeric value. This means you
should check whether the value of the key variable is not None, before
converting it to an integer:
⌴⌴⌴⌴# check if a key was pressed
⌴⌴⌴⌴# (this results in a value that is not None)
⌴⌴⌴⌴if key is not None:
⌴⌴⌴⌴ ⌴⌴⌴⌴# convert the key name (a string) into an integer
⌴⌴⌴⌴ ⌴⌴⌴⌴ key = int(key)
⌴⌴⌴⌴# return the key name (or None)
⌴⌴⌴⌴return key
This lays the ground works for the next bit: making noises when keys are
pressed!
Playing Sounds on Button PressesSounds from musical instruments comprise a main tone and its overtones,
with the relative contributions of each determining the sound’s timbre (also
referred to as tone colour). This book is a bit of a philistine and shall
proceed to completely ignore the concept of timbre. Instead, we will use
pure tones. These are sounds with only a main note, without harmonics or
other overtones.
As you know, sounds are the vibrations of air (or a different medium).
Sounds can be characterised by their frequency: the amount of vibrations
that occur per second. The frequencies of a few musical notes are listed
below (rounded to the nearest integer). You can use them to create Sound
instances that can play a certain note.
A4 440
B4 494
C5 523
D5 587
E5 659
F5 698
G5 784
A5 880
B5 988
Let’s start with a single note: A4 or 440 Herz. You can specify this
frequency by using the Sound class’s freq keyword argument. A pure tone
is a sine wave, so you should use a sinusoid oscillator when creating the
Sound instance (specified by the osc keyword argument). You can use the
length keyword argument to specify the sound’s duration in milliseconds.
In addition, you can use the attack and decay keywords to specify the
fade-in and fade-out times in milliseconds. An attack of 10 milliseconds
means that the sound will take 10 milliseconds to reach its peak volume,
Keynote Frequency (Hz)and a decay of 10 milliseconds means that the sound will take 10
milliseconds to go from peak volume down to no volume.
As an example, think of a Sound with a length of 100 milliseconds, an
attack of 10 milliseconds, and a decay of 10 milliseconds. The sound will
take 10 milliseconds to build up to full volume, then play at full volume for
80 milliseconds, and will then reduce to no volume during the final 10
milliseconds.
Now initialise a Sound instance in your script to create A4 notes with a
duration of 250 milliseconds:
a4 = Sound(osc='sine', freq=440, length=250, \
⌴⌴⌴⌴attack=10, decay=10)
The following step is to monitor whether button presses occur and then play
the sound whenever they do. A while loop is perfect for this! As you might
remember, a while loop can run indefinitely. You can make it stop by
flipping its associated Boolean variable from True to False. You could use
the following while loop in your script:
# run a while loop until stopped
stop = False
while not stop:
Within the loop, you should check whether a button is pressed. Then you
should decide whether to play a sound or not, depending on whether a
button was pressed or not. You can do this by using the get_input function
you defined earlier:
⌴⌴⌴⌴# check if a button was pressed
⌴⌴⌴⌴number = get_input(dev)
⌴⌴⌴⌴# if a button was pressed, number will not be None
⌴⌴⌴⌴if number is not None:
⌴⌴⌴⌴⌴⌴⌴⌴# if a button was pressed, play the sound
⌴⌴⌴⌴⌴⌴⌴⌴ a4.play()
This loop could go on forever, because you never specified when it should
stop! To mend this, you could make the loop stop if the 0 button is pressed.
Change the contents of the while loop to the following:
⌴⌴⌴⌴# check if a button was pressed
⌴⌴⌴⌴number = get_input(dev)
⌴⌴⌴⌴# if a button was pressed, number will not be None⌴⌴⌴⌴if number is not None:
⌴⌴⌴⌴⌴⌴⌴⌴# check if number is 0
⌴⌴⌴⌴⌴⌴⌴⌴if number == 0:
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴# make the while loop stop if number is 0
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴ stop = True
⌴⌴⌴⌴⌴⌴⌴⌴# if the number is not 0, play the sound
⌴⌴⌴⌴⌴⌴⌴⌴else:
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴a4.play()
That should do it! Your while loop will keep looping through the code that
is indented. This code will first check if a button is pressed by using the
get_input function. It will set the number variable to None if no key was
pressed or to the number of the button that was pressed. The first if
statement will first check if the number variable is not None. If it is None, the
code will simply move to the next loop of the while loop. If number is not
None, the next if statement will check if the number was 0. If it was, then the
stop variable is set to True, which will make the while loop stop at the start
of its next iteration. If number was not 0, the sound will be played.
There is one final thing to do before you try to run this code. It is crucial
that you close the Display, otherwise it might stay on when your script stops
running:
# close the Display
disp.close()
Now run the script and punch the buttons to make some noise! (Press the
button that’s numbered 0 to stop.)
Unexpected Instrument
The script you created in the previous chapter might have bored you quite
quickly, because it can only produce a single note. To make it a bit more
exciting, you can change the script to make it play a different note for every
button.
To do this, you should first create a whole bunch of different Sounds.
The quickest way to do this is by creating a set of all the sound frequencies
that you want to use. You can define these in a dict, where you can use the
button numbers as the dict’s keys. Replace the lines where you defined the
a4 variable in the previous chapter, by the following:# create a dict with the frequency for each button
freqs = {1:440, 2:494, 3:523, 4:587, 5:659,
⌴⌴⌴⌴6:698, 7:784, 8:880, 9:988}
Now that you specified all the frequencies, it’s time to create a Sound
instance for each frequency. To do this, you could use a for loop to loop
through the freqs dict’s keys. You can use the dict’s keys method to
generate a list of all key names. The best way of storing the Sound instances
is in a dict with the same keys as the freqs dict. Add the following code to
your script, directly after the lines where you define the freqs variable:
# create an empty dict for the sounds
sounds = {}
# loop through the keys of the freqs dict
for button in freqs.keys():
⌴⌴⌴⌴# create a new Sound instance with the right frequency
⌴⌴⌴⌴sounds[button] = Sound(osc='sine', freq=freqs[button], \
⌴⌴⌴⌴⌴⌴⌴⌴length=250, attack=10, decay=10)
Now only one thing needs to be changed to make your script work. The
current script still references the a4 variable, even though you’ve replaced
that by the sounds variable. To fix this, replace the a4.play() line by the
following:
⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴⌴sounds[number].play()
This uses the pressed button’s number to pick the right Sound from the
sounds dict and plays it. Run your script to test it out!6
ANALYSING BEHAVIOURAL DATA
DOI: 10.4324/9781003174332-9
Now that you have a nice dataset from Chapter 5, it’s time to learn how to analyse
it. Almost all analyses go through the same steps: reading raw data, reducing it to
a more usable format, computing statistics (calculating means, standard
deviations, maybe fitting some models), and making pretty graphs.
In this chapter, you will start by analysing the behavioural data from your own
experiment. In the next chapter, you will turn to trace analyses. (e.g. for
pupillometry, electroencephalography, grip force, movement velocity).
6.1 Analysis Plan
You can get a dataset by downloading the example data file from the companion
website. Your focus should be on the difference between the valid (cue and target
on the same location) and the invalid (cue and target on different locations)
conditions. You have two variables of interest: reaction time and accuracy.
Before starting to code, you should always take a step back to think things
through. In this analysis, you’ll need to extract data from a text file. You can read
this data line by line, with each line representing a single trial. That’s not ideal: it
would be easier to have the data organised per variable rather than per trial so that
you can compute e.g. a mean over the whole variable. Hence, you need to convert
the data that is organised with an array per variable. For example, all reaction
times would then be in one long list.
Once you have a single array for each variable, you can start selecting trials. In
your cueing task, you have a “validity” variable for each trial. This was 1 (valid)
or 0 (invalid) and can thus be used to select all valid trials. You also have an
“accuracy” variable, which was 1 (correct) or 0 (incorrect), and can thus be used
to select all correct trials. You could combine these to compute the average
response times for valid and correct trials and compare it with the averages for
invalid and correct trials.After selecting the correct trials, you can calculate descriptive statistics: mean,
standard deviation, and standard error of the mean. You could also opt for
calculating a median instead of a mean (more on that later).
Once you have calculated the means (for reaction times and accuracy) per
condition (valid and invalid), you can average these over the entire sample (i.e.
your group of participants). In addition, you could do statistical tests to see
whether there is a difference between the conditions.
After calculating the group mean and standard error of the mean, you can use
these values to draw a nice graph. Additionally, you can add the results of your
statistics to show whether there is a statistically significant difference.
6.2 Extracting Data
It’s good to separate your analysis completely from your experiment, in terms of
code organisation. Start by creating a new folder, and a new script that you could
name analysis.py. In your new folder, create a folder called data and copy your
data file(s) to the new data folder.
Now open analysis.py in an editor and write the following:
import os
import numpy
from matplotlib import pyplot
from scipy.stats import ttest_rel
By now, you should already be familiar with NumPy. If you read the Make Some
Noise chapters, you will also have seen Matplotlib. You can use NumPy to read
and process your data, Matplotlib to plot them and ttest_rel from SciPy’s stats
module to do a related-samples t-test.
The other module, os, is useful to do stuff that relates to the operating system.
This includes folder and file management, which is very useful when you’re
dealing with data files. Let’s start by making your script recognise the current
folder:
# get the path to the current folder
DIR = os.path.dirname(os.path.abspath(__file__))
That looks confusing, so let’s break it down. __file__ is a special variable. You
don’t have to create it, Python does that for you. It contains a path to the Python
script file. This could be, for example, ‘C:\example\analysis.py’. The inner (and
thus the first!) function you use on __file__ is abspath, which transforms the
path into an absolute path. Paths can be defined in two ways: relative and
absolute. A relative path would be “the folder that contains the folder that this
script is in” (“.\.\this_script.py”), whereas absolute is“C:\top_level\second_level\this_script.py”. You can’t assume __file__ refers to
an absolute path, so you use abspath to ensure that you’re not dealing with a
relative path.
The second function is dirname. This takes the path to a file and strips the
file’s name out of it. What you are left with is the path to the folder that contains
the script file. If the file path was ‘C:\example\analysis.py’, dirname will turn that
into ‘C:\example’.
Why do you do this? Well, you need the path to the data folder! You can
construct this by combining the name to the script’s folder and ‘data’:
DATADIR = os.path.join(DIR, 'data')
The join function takes all individual strings that you pass and turns them into a
path that makes sense to your operating system. If your directory was
‘C:\example’, the above line will turn that into ‘C:\example\data’.
To construct the name of your data file, you can use the same function:
# construct the name of your data file
datafile = os.path.join(DATADIR, 'example.txt')
Change ‘example.txt’ to the name of your own data file (you placed it in the data
folder earlier). Now that you have the path to your data file, you can finally load
its contents:
# load the raw contents of the data file
raw = numpy.loadtxt(datafile, dtype=str, unpack=True)
The loadtxt function takes the contents of a file, which is one big string, and
parses this. Parsing means to analyse a string, in this case to extract relevant
information (data in rows and columns). loadtxt needs the name of the file that
you want to read, for obvious reasons. The first keyword argument you pass is
dtype, which specifies the data type. You set it to str (for ‘string’), because some
of the data in your file is formatted as a string (the header, for example).
Choosing a numeric data type would result in errors with this string content. This
also means that all numbers in your data file will be loaded as strings, but you can
fix this later on.
The second keyword you passed is unpack, which tells loadtxt to transpose
the data in your file. This means that your data is rotated by 90 degrees. The
result is that your data’s columns become rows and rows become columns. This
means that your data is no longer ordered per trial (as in the data file’s lines), but
per variable. So all reaction times are in one array, and all accuracies in another,
and so on.Run the script within your Editor, to an interpreter. In Spyder, open a new
interpreter: click ‘Consoles’ in the menu, then click ‘New console’. Now click
‘Run’ in the menu, then ‘Run’ to execute in the current Python interpreter. In
IDLE, select ‘Run’ in the menu, then ‘Run Module’.
Now, in the interpreter (=console), type raw and press Enter. You should see a
NumPy array. Now type raw[0] and press Enter. This should also print a NumPy
array (the first within the variable raw) that contains the string 'fixonset' and
then a whole bunch of numbers. These are the timestamps of the onset of the
fixation screen in each trial. Finally, type raw[11] and press Enter. This prints a
single NumPy array with the string 'RT' and the reaction times for all trials.
The current format is a bit unwieldy: a single NumPy array that contains 12
other NumPy arrays (one for each variable you logged in the experiment). The
most annoying thing is that the name of each variable is embedded among values
in each NumPy array.
So let’s think of a better format: how about a dict, with an informative key for
every variable that you logged? Something like:
data = {'fixonset':array(['5485', '9575', ..., '1188518',
'1191807'],
⌴⌴⌴⌴...,
⌴⌴⌴⌴'RT':array(['690', '748', ..., '689', '689']}
That would make sense, right? You could simply type data['RT'] to get all
reaction times. The first step is to create an empty dict:
# create new empty dict
data = {}
Now, you could manually convert the NumPy array raw into the dict data. That
would take you quite a few lines and a lot of copy-pasting code. Alternatively,
you could loop through all NumPy arrays within raw by using a for loop:
# loop through all arrays in raw
for i in range(len(raw)):
On each iteration of this for loop, i will be the index number of a NumPy array
within raw. The first value of every NumPy array in raw is the name of a variable,
so raw[i][0] will be a different name in each iteration. Include print(raw[i][0])
to see for yourself:
# loop through all arrays in raw
for i in range(len(raw)):
⌴⌴⌴⌴print(raw[i][0])You could use raw[i][0] as keys in your data dict. The rest of each array in raw
contains the data. In code, raw[i][1:] means “all values in raw[i] from the
second index until the end”. To create your data dict, use the following for loop:
for i in range(len(raw)):
⌴⌴⌴⌴# the first index of each array is the variable name
⌴⌴⌴⌴varname = raw[i][0]
⌴⌴⌴⌴# the rest of the array is the data
⌴⌴⌴⌴values = raw[i][1:]
⌴⌴⌴⌴# create a new entry in the data dict
⌴⌴⌴⌴# and make it hold the values
⌴⌴⌴⌴data[varname] = values
Run the script in your editor, using a console. Then, in the console, type data and
press Enter. You should see a massive amount of numbers. This means that you
probably did it right! In the console, type data['RT'] and press Enter. You should
see a NumPy array with all reaction times. However, all of them are still string
values. If you want to do calculations with them, you have to convert them to
numbers.
Besides the NumPy arrays with numbers-as-strings, there are also arrays with
meaningful string data (the location of the cue, for example). Those should not be
converted to floats. In fact, trying to do so will result in an error. The easiest
solution is to loop through all arrays and simply try if you can convert their
values into numbers. If you can, that’s great. If you can’t, then just don’t convert
them.
To try something, and to do something else if it fails, you can use Python’s
try-except statements. These can be used to try one thing and do a different thing
when the thing you tried first caused an Exception (= an error). You could
implement this in your for loop.
for i in range(len(raw)):
⌴⌴⌴⌴# the first index of each array is the variable name
⌴⌴⌴⌴varname = raw[i][0]
⌴⌴⌴⌴# try to convert the values to numbers
⌴⌴⌴⌴try:
⌴⌴⌴⌴ ⌴⌴⌴⌴ values = raw[i][1:].astype(float)
⌴⌴⌴⌴# if conversion to numbers fails, do not convert
⌴⌴⌴⌴except:
⌴⌴⌴⌴ ⌴⌴⌴⌴ values = raw[i][1:]
⌴⌴⌴⌴# create a new entry in the data dict
⌴⌴⌴⌴# and make it hold the values
⌴⌴⌴⌴data[varname] = values
NumPy arrays have an astype method that can change the data type of all the
values in the array. If you have an array of numbers that are formatted likestrings, you can convert them to floating point numbers by using astype(float).
However, using the same on an array of strings (that are not numbers) will raise
an Exception.
In the above code, you first try to convert all values in an array to floats. This
will raise an Exception if there are non-numerical strings in the array. In that case,
the code under the try statement fails, and the code under the except statement is
run instead.
If you copy the for loop into analysis.py (instead of the for loop on the
previous page!) and run the script, you should be able to type data['RT'] in the
console. Unlike before, it should now contain numerical values rather than
strings. Score!
6.3 Selecting Data
Now that you have all your data in a manageable format, it’s time to start
organising it according to your conditions. You have two important factors: the
stimulus onset asynchrony (SOA), which was either 100 ms or 900 ms; and the
validity, which was either 1 (valid) or 0 (invalid).
You would like to be able to select four groups: 100 ms, valid; 100 ms, invalid;
900 ms, valid; and 900 ms, invalid. As you can see, these depend on two different
variables: data['soa'] can be either 100 or 900, and data['valid'] either 1 or
0.
To make a selection based on the content of a variable, you can use the
operators that you learned about in the Boolean chapter. To select all valid trials,
you can use the following:
valid = data['valid'] == 1
This will create a variable valid, which will be a Boolean array. That’s a fancy
term for a collection of True and False values. Here, you compare the array
data['valid'] with the integer 1. The result will be a Boolean array with the
same shape as data['valid']. It will be True for every value of data['valid']
that is equal to 1 and False where data['valid'] is not 1. For example, if
data['valid'] was [1, 0, 1, 0], the Boolean array created above would be
[True, False, True, False].
You can use Boolean array to select values from NumPy arrays:
data['RT'][valid]
This will select only the values in an array for which the corresponding value (at
the same index) in the Boolean array is True. In this case, that means you select
only the reaction times from valid trials. For example, if valid was [True,False, True, False], and data['RT'] was [512, 535, 505, 570], then
data['RT'][valid] would be [512, 505].
Now make some Boolean arrays for your data by adding the following code to
your analysis.py script:
# make Boolean arrays for valid and invalid trials
sel = {}
sel['valid'] = data['valid'] == 1
sel['invalid'] = data['valid'] == 0
# make Boolean arrays for 100 and 900 ms SOAs
sel[100] = data['soa'] == 100
sel[900] = data['soa'] == 900
After running analysis.py again, you can calculate the average accuracy
(proportion of correct responses) of each condition! In the interpreter, type:
numpy.mean(data['correct'][sel['valid']])
numpy.mean(data['correct'][sel['invalid']])
Those are the means of all valid and all invalid trials. You can also combine
multiple Boolean arrays, for example to select only the valid trials with a 100-ms
SOA:
numpy.mean(data['correct'][sel[100] & sel['valid']])
numpy.mean(data['correct'][sel[100] & sel['invalid']])
In the next section, you will find out how to calculate means, medians, standard
deviations, and standard errors.
6.4 Averaging Data
In the previous section, you made Boolean arrays that could select four groups:
100 ms, valid; 100 ms, invalid; 900 ms, valid; and 900 ms, invalid. This was
useful to compute the means for these groups, and you could use the same
approach to calculate other descriptive statistics, like the standard deviation and
standard error of the mean. (Pedantic remark: that last one isn’t actually a
descriptive statistic, as it tells you something about the sampling process, and not
just about the distribution of your data!)
Note that some of these descriptives work best for normally distributed data,
which yours might not be! In fact, neither accuracy nor response time is typically
normally distributed at the individual level. So before computing the descriptives,
let’s go down the rabbit hole a little bit:
The accuracy per trial has two potential values: 1 (correct) and 0 (incorrect).
This type of data is referred to as dichotomous or binary. You can calculate a
mean of all of these ones and zeros and that will give you the proportion ofcorrect responses. However, it would not be appropriate to calculate a standard
deviation or the standard error of the mean in the ways that you are used to.
While we could calculate binomial proportion confidence intervals, we are in fact
choosing to simply not calculate the standard deviation or error for each
individual participant’s error rate (you will be able to do so for the whole group
later on).
Reaction times are a different story, and the correct way of analysing them can
be debated. The reason for this is that reaction times are typically not normally
distributed. This makes sense: a reaction time cannot be lower than 0, but it can
always be longer (to infinity, and perhaps beyond?). In most datasets, the
distribution of reaction times has a positive skew, i.e. a longer tail on the right.
Why does this matter? Well, if you calculate a mean, it identifies the centre of
a non-skewed distribution. So when you calculate a mean of a skewed
distribution, it might not correctly represent its centre. Instead, the mean will be
pulled towards the tail.
One alternative option is to calculate a median. This is the value that is in the
centre when you make an ordered list of all the reaction times and can be a better
reflection of the centre of a skewed distribution.
A more fancy alternative is to fit an ExGaussian distribution to your reaction
time data. This is a combination of a normal distribution and an exponential
decay function, so it matches the typical profile of a distribution of reaction times.
The ExGaussian provides you with a centre parameter (equivalent to the mean)
and a deviation parameter (equivalent to the standard deviation). The downside of
using an ExGaussion fit is that you need a lot of data for a good parameter
estimation.
For simplicity’s sake, here you can calculate a median and then use the regular
way of calculating the standard deviation and the standard error. These will do a
decent job on most datasets, and in these example datasets, they will work very
well indeed. That’s because the examples were completely fabricated by sampling
random numbers from a normal distribution. Note that this was done only for
teaching purposes! Fabricating data for other purposes is widely considered to be
naughty.
Let’s return to the actual programming. You stuck all your Boolean arrays in a
single dict, so you can loop through them a bit easier. You can do this by creating
two for loops: one to go through the SOA conditions and one nested loop to go
through the validity conditions:
# loop through all SOAs
for soa in [100, 900]:
⌴⌴⌴⌴# loop through all validities
⌴⌴⌴⌴for val in ['valid', 'invalid']:Within these for loops, you can calculate all the descriptives you need:
⌴⌴⌴⌴⌴⌴⌴⌴# calculate statistics
⌴⌴⌴⌴⌴⌴⌴⌴rt_m = numpy.median(data['RT'][sel[soa] & sel[val]])
⌴⌴⌴⌴⌴⌴⌴⌴rt_sd = numpy.std(data['RT'][sel[soa] & sel[val]])
⌴⌴⌴⌴⌴⌴⌴⌴rt_sem = rt_sd / numpy.sqrt(len(data['RT'][sel[soa] &
sel[val]]))
⌴⌴⌴⌴⌴⌴⌴⌴acc_m = numpy.mean(data['correct'][sel[soa] & sel[val]])
⌴⌴⌴⌴⌴⌴⌴⌴# report statistics
⌴⌴⌴⌴⌴⌴⌴⌴print('condition %d ms SOA, %s:' % (soa, val))
⌴⌴⌴⌴⌴⌴⌴⌴print('median RT=%.2f, SD=%.2f, SEM=%.2f' % (rt_m, rt_sd,
rt_sem))
⌴⌴⌴⌴⌴⌴⌴⌴print('proportion correct=%.2f\n' % (acc_m))
Calculating medians, standard deviations, and means is easy: a single NumPy
function can take care of it. The standard error of the mean is a bit more unclear,
perhaps. The standard error of the mean can be calculated by dividing the
standard deviation by the square root of the number of observations (trials, in this
case). You can count the number of samples by using the len function, which
gives you the number of values in a NumPy array. The square root can be
calculated with NumPy’s sqrt function.
As it is now, you simply print the results to an interpreter. That is useful for
you, because you can read them there, but it is less useful to your computer.
Because you keep overwriting the same variable names, the results of your
calculations do not persist. That’s annoying, because you will need them later on
(for plotting, for example).
A nice solution is to store the descriptives that you calculated in a dictionary.
Add the following code before the outer (SOA) for loop:
# create an empty dict to hold descriptives
descr = {}
This creates an empty dictionary. It makes sense to order the data per SOA and
then per validity (because we are primarily interested in the difference between
the valid and invalid conditions within each SOA condition). This means that the
descr dict should have two keys, each with two new dicts: 100 and 900. The
easier way to achieve this is by adding the following directly after the for soa
in [100, 900]: line:
⌴⌴⌴⌴# create a new empty dict within the descr dict
⌴⌴⌴⌴descr[soa] = {}
Now within the second for loop, after for val in ['valid', 'invalid']:, add
code to add yet another dict to descr (this time with keys for each validity
condition):⌴⌴⌴⌴⌴⌴⌴⌴# nest another empty dict within descr
⌴⌴⌴⌴⌴⌴⌴⌴descr[soa][val] = {}
Finally, after calculating the values, you can now store them. After line acc_m =
numpy.mean(data['correct'][sel[soa] & sel[val]]:, add:
⌴⌴⌴⌴⌴⌴⌴⌴# store the calculated values in descr
⌴⌴⌴⌴⌴⌴⌴⌴descr[soa][val]['rt_m'] = rt_m
⌴⌴⌴⌴⌴⌴⌴⌴descr[soa][val]['rt_sd'] = rt_sd
⌴⌴⌴⌴⌴⌴⌴⌴descr[soa][val]['rt_sem'] = rt_sem
⌴⌴⌴⌴⌴⌴⌴⌴descr[soa][val]['acc_m'] = acc_m
Run your current script within an Editor. In the Interpreter, you can now type, for
example descr[100]['valid'] (and Enter) to get all measures for the 100 ms
SOA and valid condition.
Nesting dicts in dicts within dicts might not always be the best option for a
flexible data analysis. Other ways include storing data in a multi-dimensional
NumPy array, with a dimension for each factor (SOA and validity). You will get
to know this method in a later chapter, when you can run through data from
multiple participants.
6.5 Plotting Data
Now that you calculated the mean and standard error of the mean for a single
participant, you can plot them. Matplotlib’s pyplot library provides a whole
range of functions to create high-quality graphs. The amount of customisation
options might be a little overwhelming at first, but you’ll get used to it.
The recipe for a graph is quite straightforward: you start with creating a new
(empty) figure, then you draw the means and standard errors for each condition,
and you end by adding axis labels and a legend.
Let’s start with creating a new figure. Matplotlib has a very useful function to
create figures with one or more subplots in them. You can create one subplot for
the 100-ms SOA and one for 900 ms. You can add the following lines to
analysis.py. Make sure to add them add the very end and without indentation!
# create a new figure with two subplots
fig, (ax100, ax900) = pyplot.subplots(nrows=1, ncols=2, \
⌴⌴⌴⌴sharey=True, figsize=(12.0, 6.8), dpi=200.0)
The subplots function creates a single figure, with multiple axes. In Matplotlib,
a figure is the background that contains a single or multiple subplots. Each
subplot is called an axis. The axes can be used to plot data.
When you call the subplots function, you can pass a number of keywords. Two
of the keywords determine the amount of axes (subplots): nrows is the number ofhorizontal rows of plots and ncols is the number of vertical columns of plots.
You asked for one row and two columns, which results in two plots next to one
another. Further keywords are concerned with the lay-out. sharey and sharex are
Booleans that indicate whether all subplots should have the same y- and x-axis.
figsize determines the size of the figure (the background containing all subplots)
in inches, while dpi determines the amount of dots (pixels) per inch. A figure of
12.0 inches wide and 6.8 inches high, with a DPI of 200, results in a figure of
12.0 * 200 = 2,400 pixels wide and 6.8 * 200 = 1,360 pixels high.
You can create a bar plot. Before you start, it is important that you know how
wide your bars are going to be and how much distance you want between them.
Matplotlib considers the x-axis in a bar plot to be no different from the x-axis in a
scatter plot, which means that you can define the start and width of each bar in
numbers. For example, your bars could be 0.4 wide, and the distance between
them could be 0.1.
# define the bar plot parameters
width = 0.4
intdist = 0.1
While drawing bars, you will need to update the starting position of the next bar.
For example, if you draw the first at 0.1, you will want to draw the second on 0.6.
That is the position of the first bar, plus its width, plus the distance between bars.
# define the starting position (left edge) of the first bar
barpos = 0.1
The final thing to decide is which colour you want to use for which condition.
You can store these in a dict. Matplotlib recognises all sorts of colour formats:
built-in colour abbreviations (e.g. ‘b’ for blue, or ‘g’ for green), RGB guns with
values between 0 and 1 (e.g. (1,0,0) for red), html colour names (e.g. ‘red’,
‘burlywood’, or ‘charteuse’), and hex values (e.g. ‘#ff69b4’ for hot pink).
# define the bar colours
cols = {'valid':'#4e9a06', 'invalid':'#ce5c00'}
Time to plot your results. Create a new for loop, to go through the validity
conditions:
for val in ['valid', 'invalid']:
Within the for loop, draw a bar by using the axis’ bar method. This requires the
starting point of the bar, its height, and its width. The width and position were
already determined. The height is determined by the data (that’s the median RT
here). You can also pass a value to create error bars by using the yerr keyword.Usually, you want this to be the standard error. Finally, you can also define a
label, which can be any string. Labels appear in the legend.
⌴⌴⌴⌴# draw the 100 ms SOA median reaction time
⌴⌴⌴⌴ax100.bar(barpos, descr[100][val]['rt_m'], \
⌴⌴⌴⌴⌴⌴⌴⌴width=width, yerr=descr[100][val]['rt_sem'], \
⌴⌴⌴⌴⌴⌴⌴⌴color=cols[val], ecolor='black', label=val, \
⌴⌴⌴⌴⌴⌴⌴⌴align="edge")
You should also do this for the 900-ms SOA:
⌴⌴⌴⌴# draw the 900 ms SOA median reaction time
⌴⌴⌴⌴ax900.bar(barpos, descr[900][val]['rt_m'], \
⌴⌴⌴⌴⌴⌴⌴⌴width=width, yerr=descr[900][val]['rt_sem'], \
⌴⌴⌴⌴⌴⌴⌴⌴color=cols[val], ecolor='black', label=val, \
⌴⌴⌴⌴⌴⌴⌴⌴align="edge")
After drawing the bars, you should update the position of the next bars. If you
neglect this, all bars will be drawn on top of each other!
⌴⌴⌴⌴# update the bar position
⌴⌴⌴⌴barpos += width + intdist
After drawing the data within a for loop, you should make the plots more clear.
Start by adding a y-axis label (only for the first subplot, because both plots have
the same y-axis). Add the following line, but without indentation!
# add y-axis label to the left plot
ax100.set_ylabel('median reaction time (ms)')
You can add a legend simply by calling each axis’ legend method. This adds a
legend to the figure, listing only the data that you explicitly labelled. You can
choose the position yourself or have it automatically set to the best position. The
position label is a combination of 'upper', 'center', or 'lower' to indicate the
horizontal position and ‘left’, ‘center’ or ‘right’ for the horizontal position. It can
also be 'best' to auto-select the best fitting location (Matlplotlib will try to avoid
drawing the legend on top of anything else).
# add a legend to the right axis
ax900.legend(loc='upper right')
Because you added a legend, the x-axis becomes unnecessary (they both note the
SOA). You can hide it by using the following code:
# hide x-axes
ax100.get_xaxis().set_visible(False)
ax900.get_xaxis().set_visible(False)Finally, you can set the scale in which you want to show the graph. You could set
the x-axis to run from 0 to the next bar position (leaving equal space left and
right). The y-axis could run from 100 to 1,000, which is the range where reaction
times are normally in.
FIGURE 6.1 This is what a bar plot of the reaction times for the valid (light) and invalid (dark)
conditions looks like. The left panel is with an SOA of 100 milliseconds, and the right panel for
an SOA of 900 milliseconds.
# set x-axis limits
ax100.set_xlim([0, barpos])
ax900.set_xlim([0, barpos])
# set y-axis limits
ax100.set_ylim([100, 1000])
ax900.set_ylim([100, 1000])Now the only thing left to do is to save your figure. You can do this by calling the
figure’s savefig method. This will create an image in the same folder as the
script:
# save the figure
fig.savefig('reaction_times.png')
Cool. Cool, cool, cool. Run the current analysis.py and enjoy the plot. If you run
into errors, track back and check where you made a mistake.
6.6 Combining Datasets
Now that you have the code to read, process, and plot an individual participant’s
data, you can start thinking about doing the same for a group of participants. You
can download an example dataset of ten participants from the companion website.
In essence, you could simply take your current code to analyse one participant’s
data and put it in a for loop to analyse multiple participants in a row.
With a for loop, you can run through all participants. For each participant, you
calculate the values you need: median reaction time and accuracy for each
condition. You should store these values in a variable so that you can use them to
calculate group statistics later on.
While going through all participants, you will be creating a bar graph for each.
At the end, you will also create a graph for the group. This quickly amounts to a
lot of figures, which makes it worthwhile to neatly store them in a separate folder
to prevent cluttering. Let’s start by creating a new folder, using code.
Open analysis.py (you created it in the previous chapters). Add the following
code directly after the DATADIR = os.path.join(DIR, ‘data’) line:
# construct a path to the output directory
OUTDIR = os.path.join(DIR, 'output')
This will construct the path to your output directory, for example
‘C:\example\output’. This folder will not exist the first time you run your script,
so you will need to make it. You can do this by using the os module’s mkdir
function. However, if you think ahead a bit, you will realise that the output
directory will exist after you ran the script once. Calling mkdir to create a folder
that already exists will result in an error. Therefore, you should include a line to
check whether the output directory does not exist yet. You can use the os
module’s isdir function for that:
# check if the output folder does not exist
if not os.path.isdir(OUTDIR):
⌴⌴⌴⌴# only create an output directory if it doesn't exist yet
⌴⌴⌴⌴os.mkdir(OUTDIR)Because you will be creating a lot of plots for individual participants, it is a good
idea to separate those from the group average plots. You could create a new folder
for all individual participants’ output:
# construct a path to the individual output directory
IOUTDIR = os.path.join(OUTDIR, 'individual')
# check if the individual output folder exists
if not os.path.isdir(IOUTDIR):
⌴⌴⌴⌴# create an individual output directory
⌴⌴⌴⌴os.mkdir(IOUTDIR)
Now that you took care of the folder infrastructure, let’s get on with the actual
analysis. First, you need to create a single variable that can hold data for all ten
participants. For each participant, there will be two conditions, each with two
levels: SOA with 100 ms and 900 ms and validity with valid and invalid. For each
of these conditions, and for each of the participants, you will have two values: the
median reaction time and the proportion of correct responses.
You could stick all of those values in dicts (one for each participant), nested in
other dicts (one for each SOA condition), nested in some more dicts (one for each
validity condition), and nested in even more dicts (one for RT and one for
accuracy). But that seems like quite a complicated mess, and it will not be
optimal for further calculations due to a lack of flexibility.
Instead, you would rather have all data in arrays, where you can indicate what
values to incorporate in a calculation. For example, sometimes you might want to
access all participants’ median reaction times only in the valid condition, but of
both SOA conditions. Or you might want to have a look at the reaction times of
only the first five participants.
To make this possible, you could create two empty multi-dimensional NumPy
arrays. This sounds complicated, but it comes down to the following: for each
factor, you need a dimension in your NumPy array; plus one additional one for
the participant numbers.
For a single subject, you can visualise this as a two-dimensional “sheet” of
four values:
100 ms SOA 500 560
900 ms SOA 550 500
Valid InvalidYou can imagine the collection of participants’ data as a stack of sheets, each
containing similar numbers to the example above. In this stack, the first
dimension is the validity, the second is the SOA, and the third is the participant
number. The first two dimensions will have a depth of two (100 ms and 900 ms,
or valid and invalid), whereas the third dimension will have a depth of ten (10
participants).
In Python, you can create such a stack by creating a multi-dimensional NumPy
array. Initially, this will be full of zeros, but you will fill it up with data as you run
through all participants. Create two such arrays, one for reaction times and one
for accuracy:
# define the number of participants
N = 10
# create an empty multi-dimensional array to store data
all_rt = numpy.zeros((2, 2, N))
all_acc = numpy.zeros((2, 2, N))
Add the above code directly after the os.mkdir(IOUTDIR) line. NumPy’s zeros
function can be used to create multi-dimensional arrays filled with zeros.
Now that you have variables to store data in, it’s time to loop through all
participants. Directly after the above code, add a new for loop:
# loop through all participant numbers
for pnr in range(0, N):
range(0, N) will create a collection of all numbers from 0 to 9. These are all
participant numbers, and the for loop will run through all of them, using pnr as
the variable that points to the participant number.
The next step is very important. To make the for loop work, increase the
indentation of all code below the for loop by one indent (one tab or four
spaces, depending on your preference). In Spyder, select the block of code and
press the Tab key. In IDLE, select the block of code and press the Ctrl and ] keys
at the same time.
If you did everything correctly, all analysis code from reading a data file
until saving a bar graph is now indented. This means the for loop will run
through all of it. That’s great, because you want it to read, process, and plot the
data of every participant in a row. There are a few more adjustments to make in
the current code, though.
The first is in constructing the data file’s name. The current line is:
⌴⌴⌴⌴datafile = os.path.join(DATADIR, 'example.txt')
But it should refer to the current participant number. Therefore, change it to this:⌴⌴⌴⌴datafile = os.path.join(DATADIR, 'pp{}.txt'.format(pnr))
You should recognise the notation 'pp{}.txt', which is a string with a
placeholder. It is replaced by pnr, which is the participant number in each
iteration of the for loop. Thus, using this notation will make sure that you read a
new data file on each iteration of the for loop.
Another change you should make is in the line that saves the figure. It
currently is:
⌴⌴⌴⌴fig.savefig('reaction_times.png')
If you leave it like this, you will simply overwrite the same figure on each
iteration of the for loop. Instead, you should incorporate the participant number in
the file name. In addition, you could save the individual graph in the folder for
individual graphs (IOUTDIR). Change the above line to the following lines:
⌴⌴⌴⌴savefilename = os.path.join(IOUTDIR, \
⌴⌴⌴⌴⌴⌴⌴⌴'reaction_times_{}.png'.format(pnr))
⌴⌴⌴⌴fig.savefig(savefilename)
⌴⌴⌴⌴pyplot.close(fig)
That last line, pyplot.close(fig), ensures that the plotting library (Matplotlib)
closes the figure. This is necessary, because open plots take up space in your
computer’s temporary memory. If you leave too many figures open, Matplotlib
will run out of available memory, and your script will crash.
There is one more addition required to the current code. You need to store the
median reaction time and accuracy for each participant in the multi-dimensional
NumPy arrays you created before. Directly after the above code (to save and
close the figure), add the following:
⌴⌴⌴⌴# store all median reaction times
⌴⌴⌴⌴all_rt[0, 0, pnr] = descr[100]['valid']['rt_m']
⌴⌴⌴⌴all_rt[1, 0, pnr] = descr[100]['invalid']['rt_m']
⌴⌴⌴⌴all_rt[0, 1, pnr] = descr[900]['valid']['rt_m']
⌴⌴⌴⌴all_rt[1, 1, pnr] = descr[900]['invalid']['rt_m']
⌴⌴⌴⌴# store all proportion corrects
⌴⌴⌴⌴all_acc[0, 0, pnr] = descr[100]['valid']['acc_m']
⌴⌴⌴⌴all_acc[1, 0, pnr] = descr[100]['invalid']['acc_m']
⌴⌴⌴⌴all_acc[0, 1, pnr] = descr[900]['valid']['acc_m']
⌴⌴⌴⌴all_acc[1, 1, pnr] = descr[900]['invalid']['acc_m']
To see how the multi-dimensional NumPy arrays help you, you can run the
current script in an Editor (to the current Interpreter/console). After running, in
the Interpreter type descr[100]['valid']['rt_m']; descr[100]['invalid']
['rt_m'] and hit Enter. This prints out the median reaction times for the lastparticipant, for the 100 ms SOA, and the valid and invalid conditions. Now type
all_rt[:,0,9]. Translated to English, this means “from the all_rt variable, take
all values in the first dimension (the colon, :, means ‘all’), and the first position
(index 0) in the second dimension, and on the tenth position (index 9) in the third
dimension”. The first dimension indicated the validity (0=valid, 1=invalid). The
second indicated the SOA (0=100 ms, 1=900 ms), and the third indicated the
participant number. Thus all_rt[0,0,9] contains the same values as descr[100]
['valid']['rt_m'].
Because of the flexible nature in which you can access values in NumPy
arrays, they are ideal to calculate averages. To average all reaction times in the
100 ms SOA and valid cue condition, simply type the following in the Interpreter:
numpy.mean(all_rt[0,0,:])
You could also calculate the average reaction time in both the valid and invalid
conditions, in the 100-ms SOA condition:
numpy.mean(all_rt[:,0,:])
Or in the 900-ms condition:
numpy.mean(all_rt[:,1,:])
Or the same of only the first five participants:
numpy.mean(all_rt[:,1,0:5])
You can also calculate the means of both the valid 100-ms and the valid 900-ms
conditions at the same time, by using the mean function’s axis keyword. Do so by
specifying the number of the axis you want to calculate the averages of. That’s
the second (with index number 1) in the following selection:
numpy.mean(all_rt[0, :, :], axis=1)
Now that you played around with the data for a bit, it’s time to return to your
analysis.py script. You could calculate four means and four standard errors of the
mean, and you could visualise these in a clear way. One way of visualising the
means is to plot two lines: one for the valid condition and one for the invalid.
Each line will have two points: one at 100 ms and one at 900 ms. In this way, the
interaction effect (on reaction time and accuracy) between SOA and validity will
be represented the clearest. If you do not quite follow, the graph you produce in
the end will hopefully clear things up.
All the way at the end of analysis.py, without indentation, include the
following code:# create a new figure with a two subplots
fig, (rt_ax, acc_ax) = pyplot.subplots(nrows=2, \
⌴⌴⌴⌴sharex=True, figsize=(12.0, 6.8), dpi=200.0)
One of the subplots will present the reaction times, and the other will present the
accuracy. These plots will have a few things in common: the x-axis and the
colouring. The x-axis will represent the SOA, so there will be two values: 100 ms
and 900 ms. You can choose the colours for valid and invalid yourself, by
replacing the hex values (e.g. '#4e9a06' for green) in the code below:
# the x-axis will be the SOAs
x = [100, 900]
# the colours the valid and invalid conditions
cols = {'valid':'#4e9a06', 'invalid':'#ce5c00'}
Now it’s time to plot the actual values as lines. There are two plots: one for
reaction times and one for accuracy. Each will show two lines: one for valid and
one for invalid. Each line will be drawn between two values: one for 100 ms and
one for 900 ms. These will be calculated by NumPy’s mean function, using the
axis keyword (as before). You also need the standard error of the mean to create
error bars. (Because this is a sample standard error, you use the square root of the
amount of participants minus one.) Add the following code:
# the y-axes will be the valid and invalid means
rt_valid = numpy.mean(all_rt[0, :, :], axis=1)
rt_invalid = numpy.mean(all_rt[1, :, :], axis=1)
# calculate the SEM (=SD/sqrt(N-1))
rt_valid_sem = numpy.std(all_rt[0,:,:], axis=1) \
⌴⌴⌴⌴/ numpy.sqrt(N - 1)
rt_invalid_sem = numpy.std(all_rt[1,:,:], axis=1) \
⌴⌴⌴⌴⌴/ numpy.sqrt(N - 1)
You can plot a line with error bars by using each axis’ errorbar method. This
requires a few arguments, of which the most important are the x values and y
values (to indicate where to draw a line and where the error bars should be). In
addition, the errorbar method requires the values that indicate the size of the
error bars (yerr), the colour of the line (color), and the colour of the error bars
(ecolor). Of course, you can also provide a label to indicate what the line
describes:
# plot the means for valid and invalid as lines,
# including error bars for the standard error of the mean
rt_ax.errorbar(x, rt_valid, yerr=rt_valid_sem, \
⌴⌴⌴⌴color=cols['valid'], ecolor='black', label='valid')
rt_ax.errorbar(x, rt_invalid, yerr=rt_invalid_sem, \
⌴⌴⌴⌴color=cols['invalid'], ecolor='black', label='invalid')Finally, you need to clarify the plot: add a label to the y axis and put in a legend:
# add y-axis label
rt_ax.set_ylabel('reaction time (ms)')
# add legend
rt_ax.legend(loc='upper right')
After averaging and plotting the reaction times, you can do the same for the
accuracy. First, calculate means and standard errors of the means:
# calculate the accuracy means
acc_valid = numpy.mean(all_acc[0, :, :], axis=1)
acc_invalid = numpy.mean(all_acc[1, :, :], axis=1)
# calculate the SEM (=SD/sqrt(N-1))
acc_valid_sem = numpy.std(all_acc[0,:,:], axis=1) \
⌴⌴⌴⌴/ numpy.sqrt(N - 1)
acc_invalid_sem = numpy.std(all_acc[1,:,:], axis=1) \
⌴⌴⌴⌴/ numpy.sqrt(N - 1)
Then plot lines with error bars:
# plot the means for valid and invalid as lines,
# including error bars for the standard error of the mean
acc_ax.errorbar(x, acc_valid, yerr=acc_valid_sem, \
⌴⌴⌴⌴color=cols['valid'], ecolor='black', label='valid')
acc_ax.errorbar(x, acc_invalid, yerr=acc_invalid_sem, \
⌴⌴⌴⌴color=cols['invalid'], ecolor='black', label='invalid')
And add labels to both axes:
# add axis labels
acc_ax.set_xlabel('stimulus onset asynchrony (ms)')
acc_ax.set_ylabel('proportion correct')
Finally, set the limits of the x-axis. You want the axis to include both 100 and 900
ms, so a lower limit of 0 and an upper limit of 1000 seem appropriate. The x-axes
of both subplots are coupled, so you only have to change one to change both:
# set x limits
acc_ax.set_xlim([0, 1000])
Now add the code to save the figure:
# save the figure as a PNG image
savefilename = os.path.join(OUTDIR, 'averages.png')
fig.savefig(savefilename)
Now run the script, and BOOM! You created ten individual bar plots and a line
plot for the group averages.FIGURE 6.2 If you followed the instructions, this is what your graph of the data should look
like.
One thing to note for the future: because it is easier, you calculated the
between-participants standard error of the mean. However, the comparisons you
will make in the next chapter will test within-participant differences between the
conditions. Therefore, computing and plotting the within-participants standard
error of the mean would have been a more appropriate.
6.7 Statistical Testing
The comparisons you would like to make are within each SOA, between the valid
and the invalid condition.Officially, with a design like this, you should do a repeated-measures analysis
of variance (ANOVA) with SOA and validity as factors (each with two levels).
This test could demonstrate a significant main effect of validity and/or of SOA,
and it could show a significant interaction effect between the two. If you find
such a significant effect, you could also compare individual cells (pairs of groups
you can make from the factors and levels). For example, you could test whether
there was a significant difference in reaction times between the valid and invalid
conditions within the 100 millisecond SOA condition. Importantly, if the
repeated-measures ANOVA did not show any significant effects, it might be
inappropriate to do such follow-up tests (provided you don’t have a good reason
to do so, for example a very strong hypothesis).
Also, before even doing the repeated-measures ANOVA, you should check
whether all of its underlying assumptions are met. For example, the variances in
all cells should be equal, and you could test for this using Mauchly’s test of
sphericity.
(Please note that some stats nerds might propose a different analysis, such as a
linear mixed-effects model or something else entirely. When in doubt, consult a
search engine. When still in doubt after that, consult a statistician.)
For now, you can be a rebel and completely ignore the rules. Instead, you
could do two related-samples t-tests. One to test if the reaction times to valid cues
and invalid cues are different in the 100-ms SOA condition and another to test if
reaction times to valid and invalid cues are different in the 900-ms SOA
condition.
You should not take this as advice to not do appropriate statistics! The reason
for not doing a more appropriate test is that this chapter is not on statistics. You’re
reading this to be able to get started with Python programming, not to get
acquainted with the ins and outs of within-participant statistical testing. (That
said: Chapter 9 is on statistics so leaf on through if you’re curious!)
Now back to what you were doing: related-samples t-tests in Python. Open the
analysis.py script from the previous chapters. To perform a related-samples t-test,
you can use the ttest_rel function from SciPy’s stats module. This function
requires two arguments: one NumPy array of data in one condition and another
NumPy array of data from the other condition. This could be, for example, the
reaction times from the valid condition and the reaction times from the invalid
condition.
ttest_rel will calculate and return a t-statistic and a p-value. For those not in
the know: the t-statistic indicates how far apart two distributions are, and the p￾value indicates how likely it is to find a more extreme t-statistic than you did
(assuming there is no difference between the distributions).In your case, one array will contain valid reaction times and the other will be
of invalid reaction times, split out according to SOA. Add the following lines to
the end of analysis.py:
# perform two related-samples t-test
t100, p100 = ttest_rel(all_rt[0,0,:], all_rt[1,0,:])
t900, p900 = ttest_rel(all_rt[0,1,:], all_rt[1,1,:])
In addition, add code to report the values:
print('\nstats report:')
print('SOA 100ms, valid vs invalid: ' + \
⌴⌴⌴⌴‚t={:.2f}, p={:.3f}'.format(t100, p100))
print(‚SOA 900ms, valid vs invalid: ‚ + \
⌴⌴⌴⌴‚t={:.2f}, p={:.3f}'.format(t900, p900))
Of course, you can do the same for the accuracy:
t100, p100 = ttest_rel(all_acc[0,0,:], all_acc[1,0,:])
t900, p900 = ttest_rel(all_acc[0,1,:], all_acc[1,1,:])
print('SOA 100ms, valid vs invalid: ' + \
⌴⌴⌴⌴'t={:.2f}, p={:.3f}'.format(t100, p100))
print('SOA 900ms, valid vs invalid: ' + \
⌴⌴⌴⌴'t={:.2f}, p={:.3f}'.format(t900, p900))
If this was real, you would have demonstrated the facilitatory effects of
exogenous attention: lower reaction times and higher accuracy after a valid cue
that was presented 100 milliseconds prior to a target. If the stimulus-onset
asynchrony was 900 milliseconds, the results would be opposite: longer reaction
times and lower accuracy. This is inhibition of return. (Please remember that this
data was completely fabricated for educational purposes; don’t expect such strong
effects in actual experiments!)
If you’d like some more practice, a nice exercise would be to employ what
you’ve learned in this chapter on the data you generated in the previous chapter.7
ANALYSING TRACES
DOI: 10.4324/9781003174332-10
Now that you know how to analyse reaction time and accuracy data, it’s time to
move on to something a bit more complicated: trace analysis. A trace can be any
type of data that you collect continuously: pupil size, EEG, fMRI, force output,
movement velocity, and so on. It doesn’t really matter where the trace comes
from, the basic steps of the analysis are always the same: you collect the traces
for individual trials, average them per condition, and then test when the traces are
different between conditions.
7.1 Pupil Size
In this chapter, you will use an example dataset of pupillometry measurements.
You can download it from the companion website. Put this file in a new empty
folder.
The data was collected in a very straightforward experimental design:
participants looked at a computer monitor that had a grey fixation dot. Every few
seconds the display changed from black to white or vice versa.
The effect of lighting on pupil size is rather strong: the pupil contracts when
the eyes are exposed to bright light, and it dilates when there is little light. The
pupil is a bit slow to respond, though. Usually, a change in pupil size becomes
apparent after about half a second (or a little under).
The data in the example file was collected with an EyeLink 1000 (SR
Research Ltd). This is an eye tracker: a fancy camera that can recognise and
follow eyes and can measure the diameter (and surface area) of pupils. The
EyeLink 1000 operates at 1,000 Hz, which means that it provides one snapshot of
the pupil diameter every millisecond.
7.2 PyGaze AnalyserTo read the EyeLink’s data file, you can use PyGaze Analyser. You can download
the package from the companion website. After downloading the zipped archive,
unzip it and copy the folder called “pygazeanalyser” to your new analysis folder
(where the example data file is in too).
PyGaze Analyser is currently a relatively simple library that can extract data
from files produced by eye trackers of several manufacturers. In addition, it
provides functions for high-level plotting of gaze fixation data, which can
produce fancy pictures. You will encounter these in a later chapter.
7.3 Read Eye-Tracker Data
You currently have two things in your new analysis folder: the example data file
(ED_pupil.asc) and the pygazeanalyser folder. Now add another file: an empty
Python script that you could name analysis.py. Open analysis.py in a script
Editor. Start by importing the relevant libraries and functions:
import numpy
from matplotlib import pyplot
from scipy.stats import ttest_rel
from pygazeanalyser.edfreader import read_edf
You should recognise the first three from the last chapters. The fourth one is new,
and it is specifically designed to read data from EyeLink files. These files have a
.edf extension, which is why the function is called read_edf. The data file you
have has a .asc extension. This is a converted EDF file; it contains the same data,
but in a more readable format. (So, confusingly, the function named “read_edf”
actually reads asc files.)
Trace data files often consist of at least two types of data. The first type is
samples. In this case, they contain gaze location, pupil diameter, and a
timestamp. The second type of data is events. These are numbers or strings with
information that appear between the samples. Usually, they indicate that
something happened in the experiment (e.g. that a stimulus appeared) and provide
anchors within the data file. Without these, you wouldn’t have known at what
point in the experiment the samples were collected.
In the current data file, there are four events of interest. The first indicates the
start of a trial: PUPIL_TRIALSTART, colour='black'. It can also end with
'white'. The colour indicates the colour on the monitor during that trial. The
second kind of event was logged about 200 milliseconds before the monitor
changed colour: baseline_start. The third event was pupdata_start. It was
logged when the monitor changed colour. Finally, the event pupdata_stop was
logged 2.5 seconds after the monitor changed colour.The read_edf function takes at least two arguments: the name of (or path to)
the data file and the event that indicated a trial start. This does not need to be a
full event. In your case, you can pass PUPIL_TRIALSTART and neglect the second
bit (that indicated the colour and was not the same for every trial). You can also
pass the event that indicated the end of a trial. If you do not provide this,
read_edf will continue reading until it encounters the next trial start. By not
passing the ending event, you risk reading irrelevant data. Add the following code
to your analysis.py:
# read data file
data = read_edf('ED_pupil.asc', 'PUPIL_TRIALSTART', \
⌴⌴⌴⌴stop='pupdata_stop')
This reads the file and stores its contents in a new variable (data). This variable
is quite large and quite complex, so an explanation is in order. data is a list that
contains values of single trials (one trial per index). In this case, there were 50
trials, so len(data)==50. You can refer to a single trial by using data[i], where
i is the trial number.
Each single trial is represented by a dict. These dicts always have the same six
keys. The first are 'trackertime' and 'time'. Both of these are NumPy arrays
that contain the timestamps of all data samples. The timestamps in
'trackertime' are in the time that the eye tracker reported. The timestamps in
'time' start at 0 in every trial.
The next three keys are 'x', 'y', and 'size'. These are all NumPy arrays.
'x' contains samples of the horizontal gaze position and 'y' of the vertical gaze
position (these are measured in the monitor’s pixels). 'size' contains samples of
the pupil size. These can represent either the pupil surface area or the pupil
diamater (which depends on the EyeLink’s settings during testing). Pupil size was
measured in arbitrary units, which are relative to the specific setup and
participant. Note that these units are relative; they don’t directly map onto
anything in the real world, and you typically can’t compare them between
participants.
Finally, there is the 'events' key. This refers to another dict, which contains
the following keys: 'Sfix' (indicates fixation start), 'Efix' (indicates fixation
end), 'Sblk' (indicates the start of a blink), 'Eblk' (indicates the end of a blink),
'Ssac' (indicates the start of a saccade), and 'Esac' (indicates the end of a
saccade). All these events are lists that contain a timestamp and data that is
specific to the event (saccade starting and ending location, and duration, for
example). The last key in the 'events' dict is the 'msg' key. This contains a list
of logged messages and their timestamps.Let’s look at the 'msg' key a bit closer. Run the current analysis.py (with only
the imports and the read_edf call) in an Editor, with the output to an Interpreter.
Now type the following into the Interpeter:
print(data[0]['events']['msg'])
If you did everything correctly, you should see the following:
[[476461, 'PUPIL_TRIALSTART, colour=black\n'], [476461,
'baseline_start\n'], [476661, 'pupdata_start\n']]
As you can see, this is a list of all logged events. Each event is a list itself,
containing a timestamp (in trackertime!) and the actual message.
7.4 Plot Your First Trace
Now that you know the format of your data, it’s time to plot your first trace! Type
the following into the Interpreter:
pyplot.plot(data[0]['size'], 'o')
pyplot.show()
This plots the pupil size in the first trial and marks every sample with a circle
marker ('o'). In the graph, you see a lot of samples (2701, to be precise). They
show an increase in pupil size, which is what you expected based on the previous
chapter (where you saw that the first trial was of a black screen).FIGURE 7.1 This is what your first trace should look like
You can check what happened in the trial, by typing the following into the
Interpreter:
data[0]['events']['msg'][0]
This shows the logged event that signals the trial start and the screen colour
(‘black’). The other two events in this trial signal the start of the baseline period
(during which the monitor was still white) and the exact time at which the
monitor changed colour. You can see them by typing the following into the
Interpreter:data[0]['events']['msg'][1]
data[0]['events']['msg'][2]
You can also save their timestamps, by typing the following into the Interpreter:
t1, msg = data[0]['events']['msg'][1]
t2, msg = data[0]['events']['msg'][2]
The variables t1 and t2 each contain timestamps in tracker time. So now you
know when events happened, but you don’t know what pupil size samples
correspond with those timestamps yet. For that, you need to know how to index
the data[0]['size'] array. To find out which samples you need, you can use
data[0]['trackertime'] to check at which index numbers your timestamps
occur. These index numbers can then be used to select samples from data[0]
['size']. With NumPy’s where function, you can find the index numbers for
which a certain logical statement is True. Type this into the Interpreter:
numpy.where(data[0]['trackertime'] == t1)
The output format is a bit weird: it’s a tuple that contains a NumPy array, which
in turn contains all indices for which data[0]['trackertime']==t1. To store
this value, use the following in the Interpreter:
t1i = numpy.where(data[0]['trackertime'] == t1)[0][0]
t2i = numpy.where(data[0]['trackertime'] == t2)[0][0]
The variables t1i and t2i now refer to the index number of sample arrays
('time', 'trackertime', 'x', 'y', and 'size') that correspond to t1
(baseline start) and t2 (monitor change). You can use these indices to select the
baseline and the pupil response to a monitor change. Type the following in the
Interpreter:
baseline = data[0]['size'][t1i:t2i]
trace = data[0]['size'][t2i:]
It was mentioned before that the pupil size is in arbitrary units. This is of little
use, because you don’t know what they mean. In theory, you could recalculate the
arbitrary units to millimetres, but only if you can compare your data with data
recorded from an artificial pupil in the same setup. In that case, you would know
the exact size of the artificial pupil in millimetres. Because you would measure its
size in arbitrary units, you would know what the mapping between millimetres
and arbitrary units was.
However, you don’t have to use an artificial eye. Pupil size is known to
fluctuate over time and usually decreases quite dramatically during the course of
most (boring) experiments. Therefore, researchers often calculate the proportionalchange in pupil size within each trial. This is the pupil size divided by the average
(or median) pupil size during a baseline period. It reflects the relative increase or
decrease in pupil size compared to the baseline. You can calculate this by typing
the following line in the Interpreter and hitting Enter.
prop_trace = trace / numpy.median(baseline)
Now plot this trace by typing the following lines into the Interpreter. The '-' in
the first line indicates that the data should be drawn as a line.
pyplot.plot(prop_trace, '-')
pyplot.show()
That’s your first pupil trace; go brag about it on social media!FIGURE 7.2 This is what a proportional increase in pupil size looks like
7.5 Averaging Traces
The next step is to loop through all traces and collect all pupil responses to
changes in monitor luminance. These changes were light-to-dark in black screen
trials and dark-to-light in white screen trials. Open your analysis.py from the
previous chapter in an Editor. Add the following lines:
# create a new dict to contain traces
traces = {'black':[], 'white':[]}
This creates a new dict with two keys. Each key contains an empty list. You can
use a for loop to run through all trials. For each trial, you could calculate theproportional pupil change and add it to the appropriate list. Start with the for loop
that goes through all trials:
# loop through all trials
n_trials = len(data)
for i in range(n_trials):
For each trial, start by checking the first event. From this event, you can
determine the trial type: if 'black' was in the event’s message, the trial was a
bright-to-dark monitor change. If 'white' was in the event’s message, the trial
was a dark-to-light change.
⌴⌴⌴⌴# check the trial type
⌴⌴⌴⌴t0, msg = data[i]['events']['msg'][0]
⌴⌴⌴⌴if 'black' in msg:
⌴⌴⌴⌴⌴⌴⌴⌴trialtype = 'black'
⌴⌴⌴⌴elif 'white' in msg:
⌴⌴⌴⌴⌴⌴⌴⌴trialtype = 'white'
Now, as you did in the previous chapter, you need to check the times of the
baseline start and the actual monitor change. You also need the index numbers
that correspond to those timestamps (this is the same as in the Plot Your First
Trace section).
⌴⌴⌴⌴# get the timestamps of baseline and monitor change
⌴⌴⌴⌴t1, msg = data[i]['events']['msg'][1]
⌴⌴⌴⌴t2, msg = data[i]['events']['msg'][2]
⌴⌴⌴⌴# turn the timestamps into index numbers
⌴⌴⌴⌴t1i = numpy.where(data[i]['trackertime'] == t1)[0][0]
⌴⌴⌴⌴t2i = numpy.where(data[i]['trackertime'] == t2)[0][0]
The next step, as in the previous section, is to separate the baseline and the rest of
the pupil trace. There is one little extra, though: you should cut the trace a bit
short. Every pupil size trace will contain around 2,500 samples (excluding the
baseline). Due to sampling and timing variability, sometimes there will be a bit
more and sometimes a bit less. Later on, when you get to averaging traces, it will
be important that all traces have the same length.
In order to make sure this is the case, you can cut the length of each trace
down to 2,000. This corresponds with two seconds, and that is more than enough
time to see the pupillary light reflex. Add the following code to your analysis.py:
⌴⌴⌴⌴# get the baseline trace
⌴⌴⌴⌴baseline = data[i]['size'][t1i:t2i]
⌴⌴⌴⌴# get the pupil change trace (2000 samples)
⌴⌴⌴⌴trace = data[i]['size'][t2i:t2i+2000]The baseline is from t1i to t2i, which is the same as before. The actual trace
starts at t2i, just like before. This time, however, it ends at t2i+2000. This is
exactly 2,000 samples after it begins, to ensure that all traces will be of that same
length.
Now that you have the baseline and the actual trace, divide the trace by the
median of the baseline. This will result in a trace that reflects the proportional
change in pupil size.
⌴⌴⌴⌴# divide the pupil trace by the baseline median
⌴⌴⌴⌴trace = trace / numpy.median(baseline)
The only thing that’s left to do in the for loop is to add the trace for this trial to the
appropriate list:
⌴⌴⌴⌴# add the trace to the list for this trial type
⌴⌴⌴⌴traces[trialtype].append(trace)
When the for loop is completed, you are left with two lists that contain all trials
for trials with black-to-white and white-to-black monitor changes. Because
NumPy arrays are easier to work with, it would be good to- convert these lists to
NumPy arrays. You can do this with NumPy’s array function. Add the following
code at the end of analysis.py, without any indentation:
# convert lists to NumPy arrays
traces['black'] = numpy.array(traces['black'])
traces['white'] = numpy.array(traces['white'])
There are a few cool things you can do now that the lists of traces are turned into
arrays. The first is to calculate the average trace. For this, it is important to
understand the way in which your traces are stored. They are in a multi￾dimensional NumPy array, with the first axis being all trial numbers and the
second being all sample numbers. To calculate the average trace, you should
average over all trials, but not over all timepoints. That is you have to average
each trial’s timepoint 1 and each trial’s timepoint 2, all the way to each trial’s
timepoint 2,000. The array that contains all 2,000 of these averages is the average
trace.
Using NumPy, you don’t have to calculate 2,000 averages individually.
Instead, you can simply use the mean function’s axis keyword to indicate that you
want to calculate the averages of all points in the first dimension of your trace
array. Example:
numpy.mean(traces['black'], axis=0)This produces an average trace just like the one discussed above. The trace has
2,000 values, each of which is an average of all samples at an index. For example,
the value at index 5 (that’s the sixth value!) is the average of all black trials’ sixth
samples. This average trace characterises the average pupillary light response to a
light-to-dark transition of the computer monitor.
You can use NumPy’s std function in the same way:
numpy.std(traces['black'], axis=0)
Instead of the average, this gives you the standard deviation of all traces. If you
divide this trace by the square root of the number of trials, you end up with the
standard error of the mean for each timepoint. This tells you roughly how reliable
your estimate of the average is across time. This should be relatively constant, so
seeing large deviations at some points might require a closer look at your data!
The len function can tell you how much trials there are in each array. As
mentioned before, by dividing the standard deviation by the square root of the
number of trials, you can calculate the standard error of the mean. Add the
following code to your analysis.py, to calculate the average traces of both the
black and white condition and their standard errors. As per usual, you can store
these in a dict for easy access:
# create an empty dict to contain mean and SEM
avgs = {'black':{}, 'white':{}}
# loop through both conditions
for con in ['black', 'white']:
⌴⌴⌴⌴# calculate the number of trials in this condition
⌴⌴⌴⌴n_trials = len(traces[con])
⌴⌴⌴⌴# calculate the average trace in this condition
⌴⌴⌴⌴avgs[con]['M'] = numpy.mean(traces[con], axis=0)
⌴⌴⌴⌴# calculate the standard deviation in this condition
⌴⌴⌴⌴sd = numpy.std(traces[con], axis=0)
⌴⌴⌴⌴# calculate the standard error in this condition
⌴⌴⌴⌴avgs[con]['SEM'] = sd / numpy.sqrt(n_trials)
As with the mean and std functions, you can also use the axis keyword in the
ttest_rel function to perform multiple tests at once. Use this to check at which
time points the pupil’s response to a light-to-dark change is significantly different
from the pupil’s response to a dark-to-light change:
# do a t-test on every timepoint
t, p = ttest_rel(traces['black'], traces['white'], axis=0)
Because you just did 2,000 t-tests, you cannot simply use a p-value significance
cut-off (alpha) of 0.05. The idea behind an alpha of 0.05 is that you accept that in
case of a null effect, there is still a 5% of your p-value being “statisticallysignificant”. With 2,000 tests, each with an alpha of 5%, you would expect at
least 100 significant differences to occur even under a null effect.
Instead, you could use a Bonferroni correction. This requires you to divide
alpha by the number of tests you performed so that the overall chance of an
accidental error is still only 5%.
# Bonferroni-corrected alpha
alpha = 0.05 / len(t)
You consider differences to be significant only when their t-test’s p-value is
below the new alpha level. That is, where p<alpha, the 'black' and 'white'
traces are actually different from each other.
The next step is to create a pretty plot. First, define the colour of each
condition and create a new figure with a single axis (that’s what a subplot is
called in Matplotlib):
# define the plotting colours
cols = {'black':'#204a87', 'white':'#c4a000'}
# create a new figure with a single axis
fig, ax = pyplot.subplots(figsize=(9.6,5.4), dpi=200.0)
Next, loop through the conditions with a for loop:
# loop through the conditions
for con in ['black', 'white']:FIGURE 7.3 This is what the average traces should look like. The blue line indicates the
average pupillary response to a light-dark luminance transition, and the yellow line indicates the
average pupillary response to a dark-to-light luminance transition. Shading around the lines
indicates the standard error of the mean, and the grey shading indicates where the lines differ
significantly from each other (point-wise related-samples t-tests, Bonferroni corrected)
For each condition, plot the average trace. You can also plot a shaded area, by
using the axis’ fill_between method. This method requires you to put in x values
(the numbers 0–1999 in this case: the elapsed time since a monitor change in
milliseconds) as well as two y values. The first array of y values will be the mean
trace plus the standard error of the mean trace. The second will be the mean trace
minus the standard error of the mean trace. By specifying the alpha keyword, you
can set the transparency: a value of 1 means completely opaque, whereas a valueof 0 means invisible. (Note that this alpha is completely different from the
significance threshold discussed earlier!) Add the following code in the for loop:
⌴⌴⌴⌴# create x-values
⌴⌴⌴⌴x = numpy.arange(len(avgs[con]['M']))
⌴⌴⌴⌴# plot the mean trace
⌴⌴⌴⌴ax.plot(x, avgs[con]['M'], '-', color=cols[con], \
⌴⌴⌴⌴⌴⌴⌴⌴label=con)
⌴⌴⌴⌴# plot the standard error of the mean shading
⌴⌴⌴⌴y1 = avgs[con]['M'] + avgs[con]['SEM']
⌴⌴⌴⌴y2 = avgs[con]['M'] - avgs[con]['SEM']
⌴⌴⌴⌴ax.fill_between(x, y1, y2, color=cols[con], alpha=0.3)
FIGURE 7.4 This is what happens when something goes wrong when you're trying to plot a
trace. Or when a participant's eye explodes during testing. Either way: Oops!
The last thing to plot is a shaded area that indicates where the two traces differ
significantly from each other. You can do this using the same fill_between
method that you used to indicate the standard error of the mean. The function has
a where keyword that will make sure the shading is only drawn at locations where
a conditional statement is True, for example when p < 0.05.
To do this, you need to know the limits of your y axis. Let’s set those at 0 and
2 (the proportional change in pupil size will likely be between those numbers).
You can use these to create the top and bottom y traces. The bottom trace will
simply be an array of all zeros. The top trace will be an array of all 2s.# create y arrays
y1 = numpy.zeros(len(x))
y2 = numpy.ones(len(x)) * 2
# shade significant difference between traces
ax.fill_between(x, y1, y2, where=p<alpha, \
⌴⌴⌴⌴color='#babdb6', alpha=0.2)
Now finish the plot by setting the labels and limits of the axes and by adding a
legend:
# set axis limits
ax.set_xlim([0, 2000])
ax.set_ylim([0, 2])
# set axis labels
ax.set_xlabel('time (ms)')
ax.set_ylabel('proportional pupil size change')
# add legend
ax.legend(loc='upper left')
And finally save the figure:
fig.savefig('pupil_traces.png')8
EYE TRACKING
DOI: 10.4324/9781003174332-11
Eye tracking is a popular technique in experimental psychology and cognitive
neuroscience. It is applied to humans, other primates, and even to some non￾primate animals. (That’s no joke, see for example a study in rats by Wallace and
colleagues (2013) – the videos in the supplementary materials are amazing!) Eye
tracking usually involves pointing a camera at someone’s face and using it to
estimate where they are looking at.
Eye tracking offers a lot of things to measure: where people look (fixations),
how people move their eyes (saccadic trajectories), how quickly they do it
(saccadic response time and velocity), and how big their pupils are
(pupillometry). These metrics can give us insight into many things, including
what people attend to, how motivated they are, and how attentive they are during
tasks. Some eye-movement characteristics are affected in unique ways by a
variety of diseases and disorders and can provide early diagnostic information or
deeper insight into patients’ conditions. This is reflected by a half-witty variation
on an age-old cliché that you see in some papers and talks:
Not the eyes, but eye movements are the window to the soul.
Eye movements are not only of interest in science and medicine but also in
usability testing and marketing. Usability experts like to record the eye
movements of people while they are using websites and graphical user interfaces.
Eye-movement patterns can tell experts how intuitive an interface is. Marketing
professionals employ the same methods but are more interested in whether people
see their advertisements, products, and brand names.
Another application of eye tracking is in software engineering. Eye movement
characteristics are relatively unique and can be combined to form a finger (eye?)
print that is specific to a user. Techniques have been developed to recognise
people by their eye movements, and some experts think this technique can replace
passwords in the future. In addition, eye movements can be used to navigate a
computer’s operating system, which can be an assistive technology for those whoneed it and to people who play video games. Eye tracking is also a promising
addition to virtual reality headsets, as it allows for more realistic rendering of a
virtual environment.
8.1 The Basics
When you look at an image, you will show (mostly) three types of eye
movements: fixations, saccades, and blinks. Blinks happen when you close your
eyelids and see nothing. Saccades occur when you quickly move your eyes.
When you do, your vision is largely suppressed (if it wasn’t, you would see a blur
during saccades). Fixations are the times when your eyes stay relatively still, and
you can actually see what you are looking at.
Because most of your conscious vision happens during fixations, a lot of
research focusses on them. Most researchers assume that when you look at
something, that something is also what you attend to. This means that mapping
where you are (or have been) looking at can provide crucial information about
what draws your attention.
The most simple experiment you could do is to show participants an image
and to simultaneously record their gazing behaviour. Afterwards, you can map
where participants looked, and that will hopefully tell you what parts of the image
were interesting to a human observer.
To record participants’ gaze behaviour, you need an eye tracker. This is
nothing more than a camera with a filter, some infrared lights, and software that
can do quick image processing through algorithmic magic. The concept is simple:
the infrared lights illuminate your face, while the camera makes a snapshot of
your eyes. Image processing software then tries to find your pupil and the
reflection of the infrared light on your cornea (the front part of your eye). When
you look around, the corneal reflection is relatively constant, but the pupil moves
with your gaze. Using the difference between the pupil and the corneal reflection,
and settings derived from a calibration, an algorithm can convert the location of
your pupil within your eye to your point-of-regard on the computer monitor. In
other words, the eye tracker manages to estimate where you are looking.
8.2 Creating an Eye-Tracking Experiment
In this chapter, you are going to script a simple eye-tracking experiment. It will
show images, each for a couple of seconds, and it will record eye movements
while the images are being shown. The idea is to get you acquainted with the
basics of recording and analysing fixation behaviour.
8.2.1 MaterialsTo see this kind of eye tracking in practice, you need two things: an eye tracker
and some images. Example images can be downloaded from the companion
website, but you are also welcome to use your own holiday snaps. An eye tracker
might be harder to come by, but don’t worry if you don’t have one: PyGaze offers
a dummy mode that allows you to use the mouse cursor to simulate eye
movements.
A data file will be produced through your experiment, but an example will also
be available if you don’t have an eye tracker. The example data and analysis
software can be downloaded from the companion website. More on that later.
FIGURE 8.1 This is one of the example images. It's a picture I took during a holiday on Texel,
one of the islands north of the Netherlands. Where do you expect most fixations to occur?
8.2.2 Constants.py
The first step of any experiment is to create a file that contains the settings of
your experiment. Create a new folder and create a new Python script in it. Name
the script ‘constants.py’ and add the following code:
# The DISPTYPE can be either 'pygame' or 'psychopy'
DISPTYPE = 'pygame'
# The DISPSIZE should match your monitor's resolution!
DISPSIZE = (1024, 768)
Now on to a new constant: TRACKERTYPE, which establishes the type of eye
tracker that you will be using. This can be a specific brand of supported eyetrackers, or one of two dummy substitutes. At the time of writing, PyGaze
supports Alea Technologies’ Intelligaze systems ('alea'), SR Research’s
EyeLink systems ('eyelink'), EyeLogic trackers ('eyelogic'), the EyeTribe
tracker ('eyetribe'), GazePoint trackers and their OpenGaze API ('opengaze'),
SensoMotoric Instruments’ systems ('smi'), and Tobii’s systems ('tobii').
There is also a dummy mode that allows you to simulate eye movements with the
mouse ('dummy'), and there is a really simply dummy mode ('dumbdummy') that
provides bogus values. In this example, the TRACKERTYPE will be set to
'eyelink'. Please change this to whatever type of tracker you actually wish to
use.
# Set the TRACKERTYPE to the brand you use
TRACKERTYPE = 'eyelink'
Another constant you should add is DUMMYMODE. This is a Boolean that allows you
to easily test your scripts without an eye tracker having to be attached. Setting
DUMMYMODE to True does the same thing as setting TRACKERTYPE to 'dummy'.
# DUMMYMODE should be True if no tracker is attached
DUMMYMODE = False
Let’s set the default foreground and background colour for the experiment:
# Foreground colour set to white
FGC = (255, 255, 255)
# Background colour set to black
BGC = (0, 0, 0)
You should also think about timing. In the experiment you are about to create,
there will be a presentation of a fixation mark, followed by the presentation of an
image. Two seconds of fixation followed by ten seconds of gazing seem
appropriate:
# Fixation mark time (milliseconds)
FIXTIME = 2000
# Image time (milliseconds)
IMGTIME = 10000
Finally, let’s turn to the images. Download them from the companion website (if
you hadn’t already) or use your own. Wherever you got them from, make sure to
copy them to a folder named ‘images’. This folder should be located within the
same folder as where your ‘constants.py’ is. Make sure you get the folder
locations right, because this is crucial!
The following bits are going to be file and folder management, not unlike the
things you’ve seen before. To do this, you will need the os module. So start byimporting it:
import os
Let’s get the path to the folder that contains your scripts. You can do this by
getting the absolute path (by using the abspath function) to the current script (this
is stored in the __file__ variable, which Python automatically creates when you
run the script). You can get the folder’s name with the dirname function (folders
are also called directories):
# Get the path to the current folder
DIR = os.path.dirname(os.path.abspath(__file__))
Now let’s construct the name of the image folder. You can create it by combining
the current folder’s path (associated with the DIR variable) and the string
'images'. You can do this using the join function, which automatically uses the
correct directory separator (this is a backward slash in Windows but can differ
between operating systems):
# Get the path to the image folder
IMGDIR = os.path.join(DIR, 'images')
The last thing you should do is get a list of the file names of your images. You
don’t have to construct this list yourself. Instead, you can use the listdir
function to get a list of all files in a directory:
# Get a list of all image names
IMGNAMES = os.listdir(IMGDIR)
Note that this function creates a list of all files, including files that are not images.
Make sure that there are only actual image files in your ‘images’ folder to prevent
any unwelcome crashes! (These could occur if you try to present a non-image
file.)
As a final trick, you can sort the image names to be sorted in alphabetical
order by using the list’s sort method:
# Sort IMGNAMES in alphabetical order
IMGNAMES.sort()
8.2.3 Screens
Time to start coding the experiment. You will need the Display class to interact
with the monitor, the Screen class to create stimuli, the Keyboard class to monitor
key presses, the EyeTracker class to interact with the eye tracker, and the
libtime module to tell the time. You will also need the os module to deal withthe image files, and some of the constants you defined. In the same folder as
your constants.py script, create a new Python script and name it ‘experiment.py’.
Start by importing the classes you need:
import os
from constants import *
from pygaze.display import Display
from pygaze.screen import Screen
from pygaze.keyboard import Keyboard
from pygaze.eyetracker import EyeTracker
import pygaze.libtime as timer
Now, to get things started, you can initialise a Display and a Keyboard instance:
# Initialise a Display to interact with the monitor
disp = Display()
# Initialise a Keyboard to collect key presses
kb = Keyboard(keylist=None, timeout=None)
In the experiment, you only need a few different Screens: one with task
instructions, one with a central fixation mark, and one to draw the images on.
Let’s start with the instructions:
# Create a Screen for the image task instructions
inscr = Screen()
inscr.draw_text(text='Please look at the images. \
⌴⌴⌴⌴\n\n(Press any key to begin)', fontsize=24)
Next is the fixation Screen. You can show this between the images, to allow
people some rest. It also standardises the starting fixation position. People will
typically start with a central gaze when the images are preceded by a central
fixation mark.
# Create a Screen with a central fixation cross
fixscr = Screen()
fixscr.draw_fixation(fixtype='cross', diameter=8)
The last Screen is the one you can use to draw images on. Earlier, you learned
that drawing during timing-critical phases of the experiment is a bad idea. One
solution is to draw all possible Screens before the experiment begins. Another
option is to draw the Screens at the start of each trial, during a preparation phase.
In this case, you could draw the image on a Screen at the start of each trial.
Timing isn’t critical there yet, as participants will still be looking at the fixation
mark (a few milliseconds more or less of that isn’t going to have an impact on
their behaviour).For now, simply create an empty Screen. You can draw the images later:
# Create a Screen to draw images on later
imgscr = Screen()
8.2.4 The EyeTracker Class
PyGaze offers a unified class to communicate with eye trackers of different
manufacturers, all with the same functions. This is useful, as it means you don’t
have to reprogram your experiments every time you want to use a different eye
tracker.
The name of this class is, rather unimaginatively, the EyeTracker class. It’s
part of the equally unoriginally named eyetracker module. The class offers a
relatively simple way to communicate with an eye tracker. It allows you to start
recording and pause recording, and it can send messages to the log file (e.g. to
signal the onset of image presentation).
In addition, the EyeTracker class allows you to access samples while its
recording. This means that you can know where a participant is looking (with the
sample method) or how big their pupils are (with the pupil_size method). There
are also methods to wait for the starts and ends of saccades, fixations, and blinks.
For example, the wait_for_fixation_start will wait for a fixation to start and
return the starting time and position. These methods allow you to make your
experiments contingent on your participants’ eye movements.
Finally, the EyeTracker class offers methods that allow you to calibrate the
eye tracker and to check whether a calibration is still accurate. An eye tracker’s
estimate of where someone looks is based on parameters that differ between
people and between experimental setups. Therefore, devices need to be calibrated
to each individual participant. To start a calibration routine, you need only call an
EyeTracker instance’s calibrate method.
Throughout the experiment, you can check whether a calibration is still
accurate by using the drift_correct method. This offers one keyword argument,
pos, which determines the position of a fixation target. The drift_correct
method will show a fixation target, wait for a participant to look at it (indicated
by the participant pressing the Space bar), and will the method then check
whether the tracker’s gaze position estimate is near the fixation target. If it is
within a certain range, then the tracker’s calibration is still fine.
Calibrations can suffer from drift over time, which can cause them to become
inaccurate. Therefore, it is important to check whether a calibration is still
accurate throughout an experiment. How often is subject to personal preference,
participant compliance, and the quality of your setup. When accuracy is of utmostimportance, you could call drift_correct every trial. You could also call it every
20 or so trials, if you are more confident in your setup.
Initialising a new EyeTracker instance requires you to pass the active Display
as an argument. This is because the EyeTracker needs to know where it can
display its calibration routine. Add the following to your experiment.py script:
# Initialise a new EyeTracker
tracker = EyeTracker(disp)
# Calibrate the eye tracker
tracker.calibrate()
This will initialise a connection with your eye tracker and then calibrate it at the
start of your experiment.
After the calibration, you could show the instructions to your experiment. You
could also do this before you calibrate the system. This depends on your personal
preference and maybe on how much faith you have in your participant’s memory.
# Feed the instructions to the Display
disp.fill(inscr)
# Show the instructions
disp.show()
# Wait until the participant presses any key
# (Allowing them to read the instructions at their own pace)
kb.get_key()
8.2.5 Single Trial
A single trial in this experiment should show a fixation, followed by an image,
and it should record eye movements throughout. Before showing the image, you
need to make sure that the eye tracker is recording data. You also need to signal
(in the data file) when the image was visible and which image it was (this helps
you to make sense of the data afterwards).
Before you can show the image, you need to load it from its file and draw it on
a Screen. As an example, just take the first image from the IMGNAMES (that’s list of
all images you created earlier). You can load and draw it using the imgscr
instance’s draw_image method. This requires the full path to an image, which you
can construct using the os.path module’s join method:
# Choose the first image for now
imgname = IMGNAMES[0]
# Construct the path to the image
imgpath = os.path.join(IMGDIR, imgname)# Draw the image on imgscr
# (clear imgscr first, to be sure it's clean)
imgscr.clear()
imgscr.draw_image(imgpath)
That’s it for the preparation. Now let’s get this trial on the road! Start by asking
the tracker to start recording gaze data:
# Start recording gaze data
tracker.start_recording()
If you’re using an EyeLink, you can use the EyeTracker class’ status_msg
method to display the name of this trial’s image on the EyeLink computer. This is
a different computer from the one that is presenting the experiment, and it allows
a researcher to monitor a participant’s eye movements in real time. In the bottom
right, it also displays a ‘status message’, which can be set by the experiment
script:
# Display a status message on the EyeLink computer
# (EyeLink only; doesn't do anything for other brands)
tracker.status_msg('Trial with {} image'.format(imgname))
Next, log a message to the tracker to indicate that the trial has started:
# Log trial start
tracker.log('TRIALSTART')
Now, time to actually present something. The fixation Screen should be shown
first. It’s important to log the onset of each new Screen to the log file, so you can
make sense of your gaze data afterwards. If you don’t log anything, all you have
at the end of the experiment is a large heap of data, with no clues about what was
on the screen when that data was collected!
# Feed the fixation Screen to the Display
disp.fill(fixscr)
# Update the monitor to show the fixation mark
disp.show()
# Log the fixation onset to the gaze data file
tracker.log('fixation_onset')
# Wait for the right duration
timer.pause(FIXTIME)
The exact same principle applies to the image Screen:
# Feed the image Screen to the Display
disp.fill(imgscr)
# Update the monitor to show the image
disp.show()# Log the image onset to the gaze data file
# Include the image name in the message!
tracker.log('image_onset, imgname{}'.format(imgname))
# Wait for the right duration
timer.pause(IMGTIME)
After showing the image, you should clear the display. You can do this by calling
its fill method to fill the Display with the current background colour. Then call
its show method to update the monitor and make sure to record the image’s offset
in the log file:
# Clear the Display
disp.fill()
# Update the monitor to show a blank screen
disp.show()
# Log the image offset
tracker.log('image_offset')
That’s the end of the trial. You can pause the recording of gaze data by calling the
tracker instance’s stop_recording method.
# Log the end of the trial
tracker.log('TRIALEND')
# Pause recording
tracker.stop_recording()
At the end of your experiment script, you might want to notify the participant that
they are finished. You can recycle the instructions Screen for this:
# Clear the instructions Screen
inscr.clear()
# Write a new message
inscr.draw_text(text='All done!', fontsize=24)
# Feed the new message to the Display
disp.fill(inscr)
# Show the message
disp.show()
# Wait until the participant presses any key
# (Allowing them to read at their own pace)
kb.get_key()
After the message, make sure to close the connection to the eye tracker by calling
the EyeTracker instance’s close method:
# Close the connection to the eye tracker
# (This will also close the log file!)
tracker.close()
The final thing to do is to close the Display:# Close the Display
disp.close()
If you want to, you can run the current script to show a single image and record
your own gaze data. In the next section, you’ll learn how to modify the current
script to show all your images in one long slide show.
8.2.6 Whole Experiment
You want your experiment to run through all images in your ‘images’ folder
(IMGDIR). You have a list that contains all their names, IMGNAMES, and you have a
script to do eye tracking on a single image. All you need to do now is to run
through the list of images and make your code run for each image.
You might recall the For Loop chapter section, where you used a for loop to
cycle through a list of trials. In the current experiment, you can use the same
approach. The first thing to do is to replace the following part of your script:
# Choose the first image for now
imgname = IMGNAMES[0]
This only selects the first image, but you want it to run through all images in a for
loop. Replace the above two lines by the following:
# Loop through all image names
for imgname in IMGNAMES:
As you might remember, indentation is really important when using for loops.
Every line of code that needs to be run within the loop needs to be indented by
one unit of indentation more than the for loop. You might also remember that the
preferred unit of indentation is four spaces.
In your script, increase the indentation of every line from
⌴⌴⌴⌴imgpath = os.path.join(IMGDIR, imgname)
to (and including!)
⌴⌴⌴⌴tracker.stop_recording()
The lines from inscr.clear() should not be indented nor should any line be
before the for loop.
With this relatively minor change, you’ve made your experiment work with all
your images. Note that the experiment takes about 12 seconds per image so make
sure that you don’t include too many of them. Or do! Include your entire vacation
album, if you have an afternoon to waste.8.3 Processing Gaze Data
In this chapter, you can learn how to visualise fixation data. If you had an eye
tracker at your disposal, you can make your own data from the experiment in the
previous chapter. If you didn’t have an eye tracker, you can download a sample
dataset from the companion website.
As in the Analysing Traces chapter, you can use the PyGaze Analyser library
to extract data from a data file. In the chapter on trace analysis, you focussed on
pupil size, and you used logged events to separate out the data from several
conditions. In this chapter, you will learn about a different type of logged events:
fixations.
Fixations occur when people hold their eyes relatively stable. Most conscious
vision happens during fixations, and a lot of animals (including humans) tend to
fixate their gaze on whatever has their interest.
In this example, a participant was allowed to look at several images. The
participant’s fixations can tell you about what parts of each image piqued their
interest. Because this is highly exploratory research, you won’t have to go into
statistics here. Instead, your task is to visualise the participants’ gaze behaviour in
several ways. (Do note that this is not a general advice. Always ask for the
statistics behind visualisations!)
Gaze data visualisations provide qualitative rather than quantitative evidence
and should not be interpreted with too much confidence. However, visualisations
are rather useful to guide further quantitative research, and they are popular in
marketing and usability research. Therefore, it’s good to learn how to create
them!
In this section, it will be assumed that you worked your way through the
previous sections, in which you created an experiment that showed images to
participants. It is required that you are using the same images and the same
constants.py script.
If you are using the example data file, make sure to download the example
images for this chapter from the companion website. Place these images in a
folder called “images”. In addition, create a new Python script and name it
constants.py. Add the following code:
import os
# The DISPTYPE can be either 'pygame' or 'psychopy'
DISPTYPE = 'pygame'
# The DISPSIZE should match your monitor's resolution!
DISPSIZE = (1024, 768)
# Set the TRACKERTYPE to the brand you use
TRACKERTYPE = 'eyelink'# DUMMYMODE should be True if no tracker is attached
DUMMYMODE = False
# Foreground colour set to white
FGC = (255, 255, 255)
# Background colour set to black
BGC = (0, 0, 0)
# Fixation mark time (milliseconds)
FIXTIME = 2000
# Image time (milliseconds)
IMGTIME = 10000
# Get the path to the current folder
DIR = os.path.dirname(os.path.abspath(__file__))
# Get the path to the image folder
IMGDIR = os.path.join(DIR, 'images')
# Get a list of all image names
IMGNAMES = os.listdir(IMGDIR)
# Sort IMGNAMES in alphabetical order
IMGNAMES.sort()
Note that this is the exact same constants.py as in the previous chapter.
8.3.1 Extracting Gaze Data
Gaze data files are enormous, usually with anything between 60 and 1,000
samples for every second of data collection. Manually processing these files is a
complete nightmare. Never do it! Instead, use programming libraries to do the
work for you.
One of the libraries you could use is PyGaze Analyser. This is a relatively
simple library that can read data from several types of eye trackers. You can
download PyGaze Analyser from the companion website.
After downloading pygazeanalyser.zip, extract its contents, and copy it to the
same folder as where constants.py is saved. This is crucial!
If you haven’t done this yet, now would also be the time to download the
example data file. Make sure that you copy it to the same folder as where
constants.py is located.
The next step is to start programming. In the same folder as where
constants.py is located, open a new script. You can name it ‘analysis.py’.
The contents of your folder should now be:
images (folder that contains all images used in the experiment)
pygazeanalyser (folder that contains PyGaze Analyser)
default.asc (gaze data file)
constants.py (script with all constants)experiment.py (only if you did previous chapter)
analysis.py (empty for now)
Open analysis.py in an Editor and start by importing the relevant libraries. You
will need the os module to handle files and folders. You will also need to import
the constants. From PyGaze Analyser, you will need the gazeplotter module
and the correct reader. In this example, the read_edf function from the
edfreader module will be used, which is for EyeLink files. If you have a
different (supported) tracker, use its reader instead. Finally, whatever you used,
you also need the close function from Matplotlib’s pyplot module.
import os
from constants import *
from pygazeanalyser.edfreader import read_edf
from pygazeanalyser import gazeplotter
from matplotlib.pyplot import close
Your script will create and save quite a lot of data visualisations, which will be
stored in separate image files. It’s a good idea to stick all of them in a separate
folder to keep things organised. You could name that folder 'output' and
construct the path using the DIR constant and the os.path module’s join
function:
# Construct the name of the output directory
OUTPUTDIR = os.path.join(DIR, 'output')
You don’t have to go through the effort of manually creating a new folder.
Instead, you can create a new one using the mkdir function from the os module.
One downside of using mkdir is that it causes an error if you try to make a new
folder when that folder already exists. To prevent any kind of accidents, it’s good
practice to find out whether the folder you were about to make already exists. You
can do this with the os.path module’s isdir function. Use the following code in
your script to combine these functions:
# Check if the output directory exists yet
if not os.path.isdir(OUTPUTDIR):
⌴⌴⌴⌴# If the output directory does not exist yet, make it
⌴⌴⌴⌴os.mkdir(OUTPUTDIR)
If the output folder already exists, os.path.isdir will return True. The if
statement used here will only run if False is returned, though, due to the use of
not. Thus, if no output directory exists, mkdir will create one.Time to actually read the data. You can do this using the read_edf function; or
any of the other supported trackers’ reader functions, depending on what data file
you have. They all return the same data structure, so if you need, you can simply
substitute read_edf in the following example:
# Read the data
data = read_edf('default.asc', 'image_onset', \
⌴⌴⌴⌴stop='image_offset')
The read_edf function requires two input arguments: the name of the data file
and a string that indicates what event signalled the start of a trial. This does not
have to be the actual start of a trial; it can also be the start of the period within a
trial that you want to extract. In addition, you can also pass the keyword argument
stop. This allows you to specify the string that indicates what event signalled the
end of a trial.
In your data file (which is named default if you didn’t specify a file name),
the event that indicates the onset of an image is 'image_onset'. There was more
to that string (it also included the presented image’s name), but you don’t have to
specify a full event string for read_edf to work. Finally, the event that signalled
the image’s offset was 'image_offset'.
The read_edf function returned a variable that you named data. This variable
is a list of all trials that were extracted from the data file. Each trial is represented
by a dict. Within each trial dict, there are six different keys: 'x' and 'y' for the
horizontal and vertical gaze position, 'size' for the pupil size, 'trackertime'
and 'time' for the absolute and relative time, and 'events' for all detected and
logged events.
With the exception of 'events', all keys point to NumPy arrays that contain
data samples. How to process these is the topic of the Analysing Traces chapter.
The 'events' key points to another dict, which has seven keys. These keys are
'Sfix' and 'Efix' for fixation starts and ends, 'Ssac' and 'Esac' for saccade
starts and ends, 'Sblk' and 'Eblk' for blink starts and ends, and 'msg' for
logged messages.
Each of the 'events' keys points to a list. Each of these lists contains even
more lists! What those lists contain depends on which event you look at. For
example, the 'msg' key points to a list that contains lists for every event that was
logged. Each individual event list consists of a timestamp and of the actual
message. One individual list within the 'msg' list could look like this example:
[399495, 'image_onset\n'].
Of importance here is the 'Efix' key. This points to a list of lists, where each
individual list represents a fixation end. Each fixation end is a list that contains
the start time, the end time, the duration, the ending x position, and the ending yposition of a fixation. One such an individual list could look like this: [399928,
400063, 136, 327.5, 371.1].
The quickest way to get a feeling for what is in the data is by running your
current script within a code editor’s console (for example within Spyder). After
loading the data by running your script, you can print several event lists. For
example, you could print all messages from the first trial (at index 0):
print(data[0]['events']['msg'])
You could also print all fixation end events from the second trial (at index 1):
print(data[1]['events']['Efix'])
For now, you don’t have to become familiar with the “events” lists too intimately.
Instead, you can rely on several visualisation functions to do the work for you.
More about that in the next chapter!
8.3.2 Processing Gaze Data
Before running through all trials, you need to know how many there are. To check
how many trials there are in the data variable, you can use the len function:
# Get the amount of trials in this dataset
ntrials = len(data)
Now you can use a for loop to run through all of the trials:
# Loop through all trials
for trialnr in range(ntrials):
Note that all code following the for loop will be indented!
The first thing you need is the name of the image that was presented in a trial.
In the experiment, you simply ran through the list of images you produced in the
constants. You sorted this list in alphabetical order, which means that the list’s
order will be the same in the experiment and in the analysis. You can use this to
your advantage, by simply using the trial number to index the list of image
names:
⌴⌴⌴⌴# Get the image name
⌴⌴⌴⌴imgname = IMGNAMES[trialnr]
You also need the path to the image file, because some of the plotting functions
can use the actual image in their visualisations. You can construct the path to each
image file by using the IMGDIR constant and the image’s name:⌴⌴⌴⌴# Get the path to the image
⌴⌴⌴⌴imgpath = os.path.join(IMGDIR, imgname)
Now for the actual data, you need the fixations. As mentioned before, these are
stored in the 'events' dict of each trial, specifically as a list that is associated
with the 'Efix' key. You can access it like you would any other dict:
⌴⌴⌴⌴# Get the fixations in this trial
⌴⌴⌴⌴fixations = data[trialnr]['events']['Efix']
Remember, in the experiment you used a central fixation mark before each image
was presented. This means that the initial fixation on each image will be in the
centre, precisely where the fixation mark was. Because of this, the first fixation
does not reflect a participant’s response to the image and maybe you should get
rid of it. You can remove it by popping it out of the fixations list. To do so, use
the list’s pop method to remove the fixation at index 0:
⌴⌴⌴⌴# Delete the first fixation
⌴⌴⌴⌴fixations.pop(0)
In addition to the fixations, you can also get the x and y coordinates of each
sample. These are associated with the 'x' and 'y' keys of each trial’s dict.
Accessing them is really easy:
⌴⌴⌴⌴# Get the raw x and y gaze coordinates
⌴⌴⌴⌴x = data[trialnr]['x']
⌴⌴⌴⌴y = data[trialnr]['y']
8.3.3 Analysing Fixations
It’s time to finally plot something! Let’s start by plotting all the collected (raw)
samples on the presented image. Having a look at your raw data is always a good
idea. It should provide you with a rough idea of your data quality, especially
about how much drift there was. In the example figure, you can already
somewhat see fixations and saccades (and blinks, if the samples suddenly jump to
the bottom of the image).
If you want to save the image, you need to create a path to the intended save
file’s location first. To do so, you can construct a new name for the raw data plot,
for example by using the stimulus image’s name:
⌴⌴⌴⌴savename = 'raw_{}'.format(imgname)
Then you need to combine the raw data plot’s name with the output directory:
⌴⌴⌴⌴savepath = os.path.join(OUTPUTDIR, savename)Finally, you can call the draw_raw function from the gazeplotter module. This
function requires three arguments: the x coordinates of your raw samples (from
your x variable), the y coordinates of your raw samples (from your y variable),
and the size of the original display (form your DISPSIZE constant).
In addition, you can specify two keyword arguments. The first is imagefile,
which allows you to specify the image on which your raw samples were
collected. This image will be the background on which the raw samples are
plotted. If you don’t specify an image, a black background will be used instead.
The second keyword argument is savefilename, which allows you to indicate
where you want to save the produced plot. If you don’t specify a name (or None),
no plot will be saved.
FIGURE 8.2 These are the raw samples (grey dots) superimposed on the image they were
collected with
To create a plot of your raw samples and save it in the output directory, use the
following code:
⌴⌴⌴⌴fig = gazeplotter.draw_raw(x, y, DISPSIZE, \
⌴⌴⌴⌴⌴⌴⌴⌴imagefile=imgpath, savefilename=savepath)
The draw_raw (and all other plotting functions in this chapter) returns a
Matplotlib figure instance. You can use it to further manipulate your plot, and youcan close it by using the close function from Matplotlib’s pyplot module:
⌴⌴⌴⌴close(fig)
Regularly closing your figures is good practice. Keeping too many open will
flood your memory, which will cause your script to crash!
Now, let’s move on to something more fancy: time to plot the fixations on an
image! Fixations can be representing as (transparent) dots on the original image.
You can create such a plot with the gazeplotter module’s draw_fixations
function. It requires two arguments: the fixations (a list of 'Efix' events) and the
display size.
FIGURE 8.3 These are the fixations (grey circles) superimposed on the image they were
collected with
You can also specify some keyword arguments. These include the imagefile
and savefilename, which work in the same way as they did with the draw_raw
function. In addition, you can use the durationsize keyword to specify a
Boolean. If set to True, dots will be sized according to how long a fixation was:
the longer a fixation, the larger a dot will be. If set to durationsize is set to
False, all dots will have the same size. A similar keyword argument is
durationcolour, which also requires a Boolean. If you set it to True, longerfixations will have a “hotter” colour. If durationcolour is set to False, all dots
will be green. For an example, see the figure.
For this plot, you should also create a name and a path for the intended save
file. After doing so, you can create the plot by using the aforementioned
draw_fixations function. As before, close the figure after creating and saving it:
⌴⌴⌴⌴# Plot the fixations
⌴⌴⌴⌴savename = 'fixations_{}'.format(imgname)
⌴⌴⌴⌴savepath = os.path.join(OUTPUTDIR, savename)
⌴⌴⌴⌴fig = gazeplotter.draw_fixations(fixations, DISPSIZE, \
⌴⌴⌴⌴⌴⌴⌴⌴durationsize=True, durationcolour=False, \
⌴⌴⌴⌴⌴⌴⌴⌴imagefile=imgpath, savefilename=savepath)
⌴⌴⌴⌴close(fig)
The final plot is the most fancy one: a heatmap. This visualisation is rather
popular in eye-tracking research, primarily because it looks really pretty. The idea
is that you represent areas where fixations were denser with hotter colours. You
can also weigh in the duration of fixations, to make long fixations count more
than short fixations. The result is a visualisation that can instantly tell you where
fixations occurred most (see the example figure).
FIGURE 8.4 This is a heatmap of the fixations superimposed on the image they were collected
withTo draw a heatmap, you can use the draw_heatmap function from the
gazeplotter module. It requires the same two arguments as the draw_fixations
function: a list of 'Efix' events, and the display size.
The draw_heatmap function can take four keywords, of which two are the
same as for the draw_raw and draw_fixation functions: imagefile to specify the
original image and savefilename to store the produced heatmap. Another
keyword is alpha, which allows you to set the transparency of the heatmap that
will be superimposed on the image. If set to 0, the heatmap will be fully
transparent, and if set to 1, the heatmap will be completely opaque. The default
value is 0.5. The final keyword is durationweight, which requires a Boolean. If
you set it to True, the duration of fixations will be weighted into the heatmap
construction, with longer fixations being assigned more weight. If set to False,
all fixations will be treated as equally important. The default value is True.
To draw and save a heatmap, and to close it again afterwards, use the
following code:
⌴⌴⌴⌴# Plot a heatmap
⌴⌴⌴⌴savename = 'heatmap_{}'.format(imgname)
⌴⌴⌴⌴savepath = os.path.join(OUTPUTDIR, savename)
⌴⌴⌴⌴fig = gazeplotter.draw_heatmap(fixations, DISPSIZE, \
⌴⌴⌴⌴⌴⌴⌴⌴imagefile=imgpath, savefilename=savepath)
⌴⌴⌴⌴close(fig)
And with that, your script should be finished. Run it to loop through all trials,
creating three data visualisations per trial. When the script finishes, you can
admire all of these plots in the output folder.
The example images include a screenshot of a documentation website. The
text on that webpage was clearly being scanned by the participant. You can see
this in the raw data plot and in the fixation plot, where fixations land on
consecutive parts of the text. Interestingly, people rarely fixate all words in a
sentence and instead skip common words that they can read from the corner of
their eye.FIGURE 8.5 Raw gaze samples (grey dots) on a screenshot of a documentation website. You
can see that the participant followed the text with their eyes. Note how the overlap is not one￾to-one, especially in the central-right part of the image. This indicates some drift occurred,
reducing the quality of the data. This is very commonFIGURE 8.6 Fixations (grey circles) on a holiday picture. I took this picture in Barcelona,
where a woman was posing with a street performer. You can see how most fixations landed on
faces, and a few on the hands of the major actors in the pictureFIGURE 8.7 Heatmap on a picture of a scientific conference. This picture was taken at the
European Conference on Eye Movements in 2013, where a bunch of nerds was discussing some
software. Curiously, the fixations concentrated mostly on the douche on the right, and not on
the most handsome bastard in the centre
There were quite a few pictures with faces in the examples. The fixation plots
and heatmaps for these tell a clear story: our participant liked to look at faces.
This is a common pattern, and you can see it in most humans who are allowed to
look at a picture freely. The affinity for faces is not set in stone, though. If you
ask a participant to look for your keys in a picture, it’s likely they will pay a lot
less attention to the faces in it.
The final example highlighted here is of a building at night. It is the Van Unnik
building, on Utrecht University’s campus. Most of it was decommissioned in
2014, but it was my place of work at the time this picture was taken. The top-right
window used to be my office.
What’s interesting about the visualisation is that the fixations are concentrated
on the lighter parts of the image. This reflects a very common tendency in human
gazing behaviour: differences in contrast are very potent in grasping our attention.
In this image, the lights in the offices, in the university logo, and on the street
contrast with the generally dark background. Our eyes are drawn to these parts.Don’t go away thinking that our eyes are like moths, though! If the contrast was
inverted, participants would have been looking at the dark parts against a
generally light background.
FIGURE 8.8 Fixations (green dots) on picture of an ugly building at night. Fixations are
concentrated around the high-contrast areas in the picture
One final thing to note here is that it is somewhat unusual to create heatmaps
from a single participant’s viewing data. It was great for teaching purposes, but
normally one would collect fixations from a larger group of participants. When
testing participants, it’s usually the more, the merrier.9
COMMON STATISTICAL TESTS
DOI: 10.4324/9781003174332-12
9.1 UGH Boring
Yes, statistics can be boring. It’s also super important to know about:
statistics can contextualise findings and inform policy. Most importantly,
finding “significant” statistics can make you feel good about yourself and
your decision to become a researcher.
This chapter is not intended as a comprehensive class in advanced
statistics. It just provides some basics and then tells you how to implement
the most common tests of differences and relations in Python. More
complex options exist, but they are beyond the scope of this book. If you
are interested in doing advanced statistics, you could look at the statsmodels
and scikit-learn packages.
9.1.1 Variance and Error
Before we tackle statistical tests, let’s do a quick overview of some basics
that you might have forgotten or just never learned about in the first place.
These include variance, error, and p-values. What follows is a quick
overview. You can skip it if you like (the next important header is “9.2 T￾tests”). However, this might not be wise. I cannot begin to tell you how
many students on the Natural Sciences Tripos at Cambridge never bothered
to show up to my stats classes because they “knew it from before”, only to
score quite poorly on my exceedingly straightforward exam. Their
colleagues, blessed with very little in the way of prior mathematical or
statistical background, ended up doing rather well. Hubris, it turns out,
comes before the fail.Warnings aside, let’s dig in. In nature, individuals have the annoying
habit of being different from each other. This is apparent when you measure
people’s height, blood concentrations of various substances, or even the
number of toes, tentacles, or testicles within the same species. That last one
was the topic of an incomprehensibly timed joke in a talk at a
pharmacology conference that I was lucky enough to attend, with the
punchline coming down to the average person having one testicle. While
accurate for some (hi fellow testicular cancer survivors!), it is also
inaccurate for the majority of people. This is true for most means: they
indicate the centre of a distribution (provided it’s symmetrical), but many or
most individuals will not abide by this mean. Instead, they vary around the
mean, with some scoring substantially to slightly lower and others scoring
slightly to substantially higher.
In a normal distribution (that bell-shaped curve), the mean is in the
middle of the distribution. For example, when the Dutch Central Bureau for
Statistics (CBS) studied the average height of people in the Netherlands in
2021, they found men born after 1970 reported a mean of 184 cm (that’s
about 6 ft if you don’t speak metric) and women of 171 cm (about 5 ft 7 in)
(Reep, 2021). Everyone deviates from this mean: half of men are shorter
than 184 and the other is taller; and the same is true for women.
Just as we can compute a mean, we can compute how much individuals
are expected to deviate from the mean. We call this the variance of a
distribution. It is defined as the mean squared distance between each
individual and the mean of all individuals. For example, if three friends are
156, 171, and 186 cm tall, their mean height is 171 cm. Their distances
from this mean are −15, 0, and 15. This averages out to 0, which is
annoying; but their squared distances from the mean are 225, 0, and 225.
The variance is the mean of these squared distances, which is 150.
A highly related concept is the standard deviation, which is just the
square root of the variance. For our example of the three friends, the
standard deviation would thus be just over 12 cm. The variance and the
standard deviation are properties of a distribution: if you measured all
women in the Netherlands, you would be able to calculate their mean height
and its variance.
Because we’re lazy cost-effective, we rarely measure everyone in a
population. Instead, we take a sample of individuals from a larger
population. Even if we take a completely representative sample, it won’talways accurately reflect the population. For example, if I take the three
friends from before, their mean height happened to accurately reflect that of
Dutch women. However, this will not be true for any random sample of
three out of that population. Imagine taking thousands of three-women
samples and computing the mean height for each sample. These means
would form their own distribution: the centre would be on the population
mean, but there would also be substantial variance.
Now imagine taking a sample of 3,000 women. This is a much larger
sample than the three women from before, so intuitively you might already
think that the mean height of this sample is closer to the mean height of the
whole population. If you again take thousands of 3,000-women samples and
again compute the mean height for each sample, they would again form a
distribution. As before, the centre of this distribution of means would be on
the population mean. However, this time the variance of the distribution of
sample means would be smaller.
It turns out that the variance of these sample means is directly related to
the variance of the population and can be computed by dividing the
population variance by the number of individuals in your sample. WOW!
We can use this to estimate the standard error of the mean, which we
compute as the standard deviation of a sample divided by the square root of
the sample size.
In sum, we can measure traits like the height of individuals in a
population. There will be a mean height, which reflects the centre of a
normal distribution. These will also be variance around this mean, which
reflects how much individuals vary. High standard deviations mean lots of
variance, whereas low standard deviation means individuals are relatively
similar. Means and standard deviations are properties of the population.
Instead of measuring the whole population, we can take samples of
individuals from a population. These samples are imperfect, but their means
should converge on the population mean. The larger samples get, the closer
they are likely to be to the population mean. This is quantified by the
standard error of the mean, which is computed by dividing a sample’s
standard deviation by the square root of the sample’s size (i.e. the number
of individuals in that sample). The standard error of the mean is a property
of the sampling process.
9.1.2 When Is Something Surprising?Now that we know the terminology, we should take a step back and think
about some of the big questions. For example, if Taylor Swift were to move
to the Netherlands, would she stand out in a crowd of her peers? According
to a quick search on the internet, Swift is 180 cm tall. (According to
personal observations at concerts, she looked about 3 cm tall, but this might
have been affected by viewing distance. They were fantastic concerts
regardless!) According to the CBS, women born in the Netherlands in 1989
are 169.8 cm tall on average. This means Swift is 10.2 cm taller than the
average Dutch woman. Does this mean she would stand out?
Intuitively, you would probably answer “Well, that depends…” because
you might feel that while Swift is taller than the average, we don’t quite
know the spread around this average. Let’s assume the standard deviation is
13 centimetres (because we’re talking about Taylor Swift, but also because
that’s the actual number). This means Swift falls within a single standard
deviation from the mean. More precisely, assuming a normal distribution,
22% of Dutch women born in 1989 would be taller than her. This means
Swift is tall but also that every fourth or fifth Dutch woman would be taller,
and hence she wouldn’t quite stand out in a crowd.
Now forget about the potential move and compare Swift to her country
of origin. According to a publication by the National Centre for Health
Statistics in the United States, the mean height of women aged 20–29 in the
years 2015–2018 was 162.6 cm with a standard deviation of about 10 cm
(Fryar et al., 2021). Again assuming a normal distribution, this would mean
Swift was among the tallest 4% of women in her age bracket! Hence, she
would likely stand out in a crowd of her peers.
We can rephrase the above to sound more stats-y: “Under the assumption
that women in the USA have a mean height of 162.6 cm with a standard
deviation of 10 cm, the probability of observing someone with height 180
cm or taller is 4%.” This is not too far away from a p-value, which will be
introduced shortly.
Whether finding someone as tall as Taylor Swift is surprising depends on
your interpretation of 4%. Perhaps you wouldn’t find this practically
significant: you might see hundreds of people when walking through busy
streets and thus plenty of tall women among them. (Similarly, people do
hundreds of studies, some are bound to show larger effects.) More
generally, a 4% chance of winning the lottery would feel like a lot, whereas
a 4% chance of improvement after surgery would likely feelunderwhelming. (Similarly, the level of evidence from studies should be
high if important policy will be decided on it.)
9.2 T-tests
Some of the most basic questions in science are about differences: “I can
hold my breath for a few minutes; is that better than others?”, “Are the
brains of cats smaller than those of dogs?”, or “I’ve recently started on a
new drug; are my poops bigger now?”. These questions often come down to
the more generic questions of: “Is my measurement different from what I
expected?” and “Is group A different from group B?”
One way to address the above questions is by using t-tests. These
formalise what a difference is and when we consider it “statistically
significant”. There are different flavours of t-tests, each with their own
specific purpose. What is common among all of them is computing a t￾value and comparing this t-value to a t-distribution. If a t-value is very
extreme, we could consider it “significant”.
A t-distribution looks a lot like a normal distribution, but it comes with
an exciting addition: degrees of freedom. Under infinite degrees of
freedom, the t-distribution tends towards the standard normal distribution
(with a mean of 0, and a standard deviation of 1). However, as the degrees
of freedom decrease, the tails of a t-distribution come up. This means more
extreme values are more probable under fewer degrees of freedom.
I hear you thinking: what are degrees of freedom? Let’s say you’re
estimating the variance of a sample like we did a little while ago. You used
a number of independent observations to do so, for example the heights of
individuals in your sample. You also used another parameter to compute the
variance, namely the average height. The degrees of freedom for the
variance are the number of observations minus the one parameter you used
to compute it. In other words, the degrees of freedom for a parameter
estimate are n – k, i.e. the sample size minus the number of parameters used
to compute the parameter. For t-tests, this will be n – 1.
9.2.1 What Is a p-Value?
Using the t-distribution and a computed t-value, you can compute a p￾value. This value reflects the probability of finding your observed t-value or
a more extreme one, assuming that the null hypothesis is true. (The nullhypothesis here is that there is no difference, which would mean t-values
are expected to be distributed around 0.)
The p-value is NOT the probability that your hypothesis is true. It is also
NOT the probability of finding your data by chance. The p-value of a single
study is also NOT akin to an effect size or level of evidence (i.e. lower does
not mean “bigger difference” or “more evidence”).
Once more, for the people in the back (and the overconfident students
who skipped classes and underperformed on my exams): “The p-value is
the probability of observing a t-value that is as high or more extreme than
the observed t-value, under the assumption that the null hypothesis is true”.
When the null hypothesis is true, p-values are uniformly distributed: they
are just as likely to be 0.01 as they are to be 0.50 or 0.99. When the
alternative hypothesis is true, then p-values are skewed: they are now more
likely to be towards 0, then they are to be towards 1. How skewed they are
depends on the magnitude of the difference.
If someone says a result is “statistically significant”, what they really
mean is that their p-value was lower than some arbitrary threshold. Often,
this is set at 0.05. If the null hypothesis is true, p-values are uniformly
distributed between 0 and 1, and thus there is a 5% chance that the p-value
is 0.05 or lower. However, if the null hypothesis is not true, p-values are
skewed, and thus, the chance that a p-value is lower than 0.05 is larger than
5%. How much larger depends on the effect size, with very small
differences only increasing the chances by a little bit.
Another important factor is sample size. Increasing the sample size will
decrease the standard error of the mean, which in turn increases the t-value
(you will see why in the next sections), and it also increases the degrees of
freedom. Both of these factors will further skew the distribution of p-values.
9.2.2 One-Sample t-test
Imagine you have measurements from a single sample of individuals, and
you also have a very specific hypothesis about what these should be. For
example, you might be the CEO of a cooperation that has systematically
dumped chemical waste in lakes around your factories, and as a
consequence people in local communities have accused you of poisoning
their drinking water. Oops! As a consequence of the tap water quality, local
residents have turned to bottled water. You saw this business opportunityand branched out to siphoning public water reserves into your own
production of bottled water. Unfortunately, residents now complain that
your bottles are leaching microplastics into the water they contain, and that
this is harmful to them and their offspring. Not this again!
Fortunately, you’re quite sure that your chemicals in the tap water and
the microplastics in your bottled water are totally safe! You just have to run
a quick study to confirm this. People are complaining that their babies’ birth
weights have substantially dropped since you started poisoning their water
and then started selling them potentially dodgy water. You, on the other
hand, think there is nothing wrong with poisoning enriching local lakes and
commercial bottles of water. You thus ask a local hospital to produce their
anonymised records of birth weights in the last year. You also know that the
average birth weight was 3499 grams at 40 weeks’ gestation (Duryea et al.,
2014) in the wider population. Your question is thus: is the distribution of
birth weights different from the national average?
You vaguely recall the one-sample t-test from that one statistics unit in
the MBA you mostly blustered through. This was a test that allowed you to
compare a sample of observations (baby weights) to an expected mean
(3499 grams). This tests first computes a t-value by subtracting the expected
mean from the observed mean. You could consider this your signal: the real
difference you’ve observed between your data and your expectation. This
signal is then divided by the standard error of the mean (sample standard
deviation divided by the square root of the number of observations in your
sample). You could consider your noise: expected uncertainty in your
sample. In some ways, the t-value is thus a bit like a signal-to-noise ratio. In
other words, it quantifies whether the difference you observe is larger than
the magnitude of differences you might expect anyway.
You ask the nerds from your IT department to code this in Python. They
use NumPy and SciPy’s stats module and offer you the following:
from scipy.stats import ttest_1samp
# These are the weights for 10 babies born at
# 40 weeks in the local hospital.
baby_weights = [2530, 3095, 3323, 3404, 3297, \
⌴⌴⌴⌴2986, 2442, 3288, 3219, 2822]
# Test if the collection of weights could be
# different from the population mean.
t, p = ttest_1samp(baby_weights, 3499)print(t, p)
A-oh… That t-value of −4.26 suggests that babies were indeed born smaller
than the national average, and that p-value of 0.002 is “statistically
significant”. Under the assumption that local babies weigh just as much as
the general population, this suggests finding a t-value like the one you just
observed or even more extreme is quite unlikely.
Seems like you might have some explaining to do after all! Use your
money to wipe your tears, claim the sample is too small, and maybe invite a
high-powered judge on a vacation in case the townsfolk ever take you to
court.
9.2.3 Related-samples t-test
New example! Pretend you’re running an editor, and you’ve developed an
intervention that makes academics more likely to submit their manuscripts
in time. You’ve tracked a number of writers’ previous book delays, and
you’re curious to know if they have benefited from your intervention on the
delay for their next book. You thus have two measurements for each writer:
number of days delay pre-intervention and number of days delay post￾intervention:
import numpy
# Collected data from 10 writers before and
# after the intervention.
pre = numpy.array([366, 298, 654, 712, 378, \
⌴⌴⌴⌴453, 11, 343, 777, 827])
post = numpy.array([452, 559, 435, 380, 278, \
⌴⌴⌴⌴296, -2, 414, 636, 692])
Now you can test if the post-intervention delays are different from the post￾intervention delays! You can do so using a related-samples t-test:
from scipy.stats import ttest_rel
t, p = ttest_rel(pre, post)
print(t, p)
Disappointingly, your intervention does not seem to have worked: the t￾value is 1.25 and the p-value is 0.243…. Maybe your sample was too smallor maybe academics are just incorrigible optimists who take on too much
work and then fail to do it all in the time they over-optimistically estimated
all that work would take.
(Frankly, the only unrealistic thing about this example is that one of the
writers got their manuscript in two days before the deadline. On a highly
related note: Sorry, Adam!)
At this point, you might wonder how this related-samples t-test actually
works. It’s inner workings rely on the fact that your data come from
repeated measurements within the same individuals. (We call this a within￾participant design.) This means you can compute a difference score
between each of these measurements:
# Compute the difference between delays before
# and after your intervention.
difference = pre - post
This difference is a single collection of observed values. Your null
hypothesis is that there is no difference, so you expect the average
difference to be 0. As you’ve just learned, you could use a 1-sample t-test to
test if the differences are different from 0:
t, p = ttest_1samp(difference, 0.0)
print(t, p)
What?! Those are the exact same values as before!! So it turns out that a
related-samples t-test is actually just a one-sample t-test in a trench coat!
9.2.4 Independent-Samples t-test
Previously, we only had to compare a single sample to an expected mean, or
we cleverly used relations in the data to come up with a single set of
differences from two measurements within a sample. Now let’s turn to a
slightly more complicated problem: differences between two different
groups!
Between-participant designs are for when you are testing two
completely different groups, like metallurgists and dolphins. The
independent-samples t-test allows you to see if a feature you measure is
different between these groups. The general principle is the same as for the
other t-tests: you first compute the difference in means between the groups,and you divide it by a measure of the variability. Just like before, this is a
bit like a signal-to-noise ratio, and you’re trying to determine if the
difference you found is within the realm of expectation or over.
As we are dealing with two samples, there are now two variances to
contend with: one for each group. If the samples are of equal size and
variance, pooling them together isn’t particularly troublesome. However,
problems arise when samples are of unequal size, and even more trouble
occurs if the variances are unequal. The reasons behind why these are issues
are a bit beyond the scope of this chapter, but if you’d like a flavour, just
look up the Welch-Satterthwaite equation.
Fortunately, SciPy’s stats module offers a clean and simple solution:
the ttest_ind function! This function has a keyword argument, equal_var,
that you can set to False. This applies the appropriate correction if your
samples are indeed of unequal variance. However, there is no harm in using
it on samples with equal variance: the correction tends towards the basic
independent-samples t-test if the sample sizes and variances are more
similar.
from scipy.stats import ttest_ind
# Define a feature that is different between
# metallurgists and dolphins.
# (Identifying this feature is left as an
# exercise to the reader.)
metal = [89, 137, 56, 104, 78, 29, 65, 67, 73, 84]
dolphin = [530, 642, 591, 593, 627, 595]
t, p = ttest_ind(metal, dolphin, equal_var=False)
print(t, p)
In sum, independent-samples t-tests are a bit more complicated that related￾samples t-tests, but with the ttest_ind set to equal_var=False, you should
mostly be safe.
9.3 Correlation
So far, we’ve talked about differences. But sometimes we’re interested in
whether things are similar. To this end, we can use correlation: the tendency
for different measurements to vary in similar ways. For example, things like
people’s salary, the number of minutes they listen to Taylor Swift per day,
and how often their spouse talks about mechanical keyboards all correlate
with life satisfaction [citation needed].Correlation is the bad boy of statistical tests, because everyone always
warns you about them. They’ll say “Correlation does not equal causation!
The number of Nicholas Cage films correlates with the number of
swimming pool drownings in the USA!” Speaking of that wonderful actor:
correlation is the Nick Cage of stats: Oscar- worthy when used
appropriately, but the results can be unintentionally funny when used
inappropriately.
9.3.1 Covariance
We previously looked at t-tests and noted that they quantified sample
differences with (kind of) signal-to-noise ratio. They did so by dividing
differences between means by a measure derived from sample variance(s).
Correlations are highly similar, but instead of differences, they quantify
association between two samples. The magnitude of this association is then
compared against, you guessed it, a measure derived from sample variance.
Associations between two variables can be quantified as their
covariance. Computing this comes down to looking at how far individuals
are from the group mean on both variables. For example, I might spend
more time reading about pigeon flight that the average person, and my
quality of life score might also be higher than the average. Some of my
colleagues, on the other hand, don’t care for pigeons for some reason (?!),
and I can only assume their quality of life is lower than the average. This is
covariance: when you score high on pigeon interest, you also score high on
quality of life; but when you score low on pigeon interest, you score low on
quality of life. Thus, if you were to multiply both distances from the group
mean, you would end up with a high value. The mean (across all people in
your sample) of all of these multiplied differences is the covariance.
Covariance works when two variables are high or low at the same time
within each participant: multiplying two positive values ends with a
positive value but so does multiplying two negative values! However, it
also works for when one variable is high but the other is low (and vice
versa) within each participant. In this case, the multiplication is of one
positive and one negative number, or one negative and one positive number;
and both end up as a negative value.
Covariance will be low if people are not consistent in their scores. Some
people will score higher than the mean on two variables, but others willscore higher than the mean on one and lower on the other, and yet others
will score lower on the first and higher on the second. If this is the case, the
result is a nice mixture of positive and negative values, which will average
out to around 0: no covariance!
9.3.2 Pearson's R Coefficient
You can think Pearson’s correlation coefficient R is computed as the ratio of
covariance and variance. It is computed by dividing the covariance between
two variables by the product of the standard deviations of those variables. R
varies from −1 for a completely negative correlation via 0 for no
correlation, to 1 for a completely positive correlation. Such a complete
correlation would mean that for every difference in one variable, the
difference in the other variable is the exact same. So if I score 1 standard
deviation above the mean for reading about pigeons, I would also be one
standard deviation above the mean on a quality-of-life questionnaire.
In Python, you can simply use SciPy’s stats module to compute R and an
associated p-value, by using the pearsonr function:
from scipy.stats import pearsonr
x = [1.4, -0.7, -0.9, 0.4, 0.3, \
⌴⌴⌴⌴-0.1, 1.0, -0.3, -0.2, 1.1]
y = [0.9, -0.6, -0.7, -0.3, 0.5, \
⌴⌴⌴⌴0.1, -0.2, -0.5, 0.3, 0.8]
r, p = pearsonr(x, y)
print(r, p)
The p-value for a correlation quantifies the probability of finding an R
value like the observed or more extreme, assuming that no correlation exists
between the two variables.
9.3.3 Spearman's ρ Coefficient
Pearson’s correlation coefficient R suffers from extreme values. When these
are present in either variable, this impacts the covariance computation, and
they can disproportionally pull on the R value. In these cases, you could opt
for using non-parametric tests of correlation. One such metric is Spearman’s
rank correlation coefficient ρ.The beauty of ρ is that it works exactly the same as R: it is the
standardised covariance, i.e. the covariance between two variables divided
by the product of their standard deviations. However, we employ a little
trick first to get rid of those pesky extreme values! Instead of using the
actual data, we use their rank-order instead. For the example above, the
rank orders would be like this:
x_rank = [10, 2, 1, 7, 6, 5, 8, 3, 4, 9]
y_rank = [10, 2, 1, 4, 8, 6, 5, 3, 7, 9]
We can now use them to compute the correlation:
r, p = pearsonr(x_rank, y_rank)
print(r, p)
An easier thing to do than rank-ordering the data first is by simply passing
the original data to the spearmanr function in SciPy’s stats module:
from scipy.stats import spearmanr
r, p = spearmanr(x, y)
print(r, p)
9.3.4 Side Note: Who Are These Tests Named After?
Like many statistical tests and concepts, the above tests are named after
people: Karl Pearson and Charles Spearman. They are statisticians who
were alive from around 1860 to 1940, and apparently the two hated each
other (academic gossip shall not be referenced). Perhaps more notable,
though, is how their efforts greatly helped the eugenics movement. Sadly,
many statisticians and psychologists around this time were active and
enthusiastic eugenicists, even though one could reasonably argue they could
have known better. Much is written on this topic, in much better and more
comprehensive prose than I will be able to produce. I simply wanted to
contextualise the names of these tests, as it felt wrong to hide this
information.
9.4 Linear Regression
Sometimes, we have more than one variable that we think is associated with
an outcome of our interest. For example, we might want to probe how theteaching evaluations of lecturers are related to them wearing a tweed jacket
and also their h-index. We could correlate both sets of values, but this only
gets at the individual pairwise relationships. Instead, it could be that people
with higher h-indices are more likely to wear tweed, which would make the
variables overlap in their relationship with teaching evaluations. Linear
regression allows us to test both variables at the same time, thereby
avoiding double counting any overlap.
Regression is often cloaked in the language of prediction. This is
because we explicitly use variables to predict an outcome. However, you
should really only consider this “prediction” from a practical mathematical
standpoint, and not from a more philosophical viewpoint of causation. If we
regress variables x1 and x2 on outcome y, it does not necessarily mean that
x1 and x2 caused y. In our example above, it could be that lecturers obtain
high teaching evaluations because students trust them more when they are
wearing tweed and because they have substantial experience with
publishing papers (which has also improved their h-index). However, it
could also be that lecturers are more likely to start wearing tweed if their
confidence in their academic ability is boosted by teaching evaluations and
their h-index. Linear regressions do not pick up on the direction of
causality, they just tell you about associations. You need to address
causality by cleverly designing your experiments and models, by using
manipulations, and by simply waiting for the passage of time. Perhaps,
taking all of these together, your theories can carefully converge on
causality.
With that disclaimer out of the way, let’s get our hands dirty. Our
example demanded two predictors, so let’s make up some data! First, we
have the wearing of tweed jackets. Let’s keep this simple and set it as a
binary variable: some people wear tweed jackets, and they will be assigned
a 1; whereas others do not, and they will be assigned a 0:
tweed = [0, 0, 1, 0, 1, 1, 1, 1, 0, 0]
Next, we have h-indices. These are almost completely meaningless values
that quantify how much an academic has published and how many times
each paper was cited. The higher the h-index, the more “impact” we think
someone has. (This metric is mostly meaningless, because it widely differs
between fields, can easily be gamed by pumping out many small papers that
cite each other, and for a whole host of other reasons.) Across all scientists,h-indices are skewed towards 0. (This is not unlike p-values for true effects,
so I guess we should start calling people with low h-indices “significant”!)
However, among the staff within a department, it is likely to be somewhat
closer to being normally distributed because all will have been in academia
for several years and thus be published and be cited reasonably often.
h_index = [14, 12, 29, 11, 2, 30, 33, 31, 10, 17]
(If you’re wondering about the 2 in there: that’s a recently graduated PhD
student who happens to have worked with the 33, copies everything about
them (including the tweed), and is so promising that the department simply
had to offer them a Tenure Track position after a completely fair hiring
procedure.)
The final ingredient to our regression is the outcome variable: teaching
evaluations. These are completed by a subset of students at the end of a
course module and are supposed to reflect teaching aptitude. (In practice,
they also reflect the module’s topic, random grievances, and a smorgasbord
of stereotypes.) In many places, these scores are between 1 and 5. Because
this resembles how many internet reviews work, let’s call these evaluation
scores “stars”.
evaluation = [2.44, 1.66, 4.40, 1.71, 1.00, \
⌴⌴⌴⌴4.67, 5.00, 4.98, 1.66, 2.62]
9.4.1 Univariable Linear Regression
First, let’s look at the relationship between each predictor and the outcome
separately. We can do so using SciPy’s stats module’s linregress
function:
from scipy.stats import linregress
result = linregress(tweed, evaluation)
print(result.rvalue, result.pvalue)
So far, we have just treated this as a simple correlation, looking at only the
R coefficient and the p-value. These suggest that there is a relationship
between wearing tweed and student evaluations, but the beauty of
regression is that it can more precisely quantify this. You can do so by
looking at the slope parameter, which tells you by how much the outcome
increases for every step in the predictor:print(result.slope)
This slope tells you that wearing tweed jackets increases your evaluation by
a whopping 2 stars! Let’s see if a similar thing is true for the h-index:
result = linregress(h_index, evaluation)
print(result.slope, result.rvalue, result.pvalue)
This result shows us that for every extra h-point, teaching evaluations
increased by about 0.14 points. The relationship is also very close, as R is
approaching 1! This would be a good time to stress that these values are
completely made up, and h-index does not actually correlate quite so
strongly with teaching performance (Figlio & Schapiro, 2017).
Another neat feature of doing linear regression is that we can easily plot
the outcomes:
from matplotlib import pyplot
# First, create a scatterplot of the data.
pyplot.plot(h_index, evaluation, "o", \
⌴⌴⌴⌴color="#FF69B4")
# Next, draw the fitted line.
x = numpy.linspace(0, 35, 10)
y = result.intercept + result.slope * x
pyplot.plot(x, y, "-", color="#FF69B4")
# Set axis labels
pyplot.xlabel("h-index", fontsize=16)
pyplot.ylabel("Teaching evaluation (stars)", \
⌴⌴⌴⌴fontsize=16)
9.4.2 Multivariable Linear Regression
The next step is to combine both predictors into a single model. To do so,
we will need to stick them into a single array. To do so, let’s use NumPy’s
ones function, which can create an array filled with the value 1. In this case,
we will give it the shape 10 × 3: one row for each observation (i.e. the
lecturers) and one column for each feature (i.e. the variables measured for
each lecturer).
X = numpy.ones((10,3))
Now let’s add the variables to the array:X[:,1] = tweed
X[:,2] = h_index
You’ll note that we left the first column, at index 0, untouched. It is to
remain as 1s, because that is what the model uses as an intercept. For the
linregress function, this intercept was included automatically, but in
multivariable regression, we actually have to do some work for our results!
Next, we need to run the regression. We’re going to do this using a
technique called ordinary least squares, which aims to automatically find
a solution that minimises the distance between the trend line and the data.
This distance is called the residuals, and the lower they are the better a fit
is. This is a complicated problem, because you need to find the best fitting
intercept and slope parameters, but you can’t try out all of the infinitely
many possibilities for what these parameters could be. Instead, most
minimisation techniques do a clever search around parameter space. In
these searches, they first randomly try a guess and then compute the
residuals. Then they move a little and compute the residuals again. If they
are lower, then we must be moving in the right direction! After a while,
every direction we move into will lead to higher residuals. This means
we’re in a local minimum. After trying a few different random starting
guesses and ending up in several local minima, we choose the lowest of the
minima and use the associated parameter values as our best fit.
Parameter space can be thought of as a landscape. The longitude and
latitude are determined by the intercept and the slope parameter, and the
elevation can be thought of as the residuals for each combination of
intercept and slope. The minimisation algorithm drops a sack of marbles out
over the landscape and chooses the (intercept, slope) coordinate of the
lowest landed marble.
Fortunately, you don’t have to implement the above search by yourself.
SciPy has a built-in function to do so! It’s part of the linalg module, called
lstsq, and can be used like this:
from scipy.linalg import lstsq
betas, ss_res, rank, s = lstsq(X, evaluation)
The least-squares algorithm produces quite a few outputs, but the most
important ones for now are the coefficients betas and the sum of squares of
the residuals ss_res. The betas here are the unstandardised coefficientsand are ordered in the same way as the columns in our predictor array X.
This means that beta0
(pronounce “beta naught”) is the intercept, beta1
the
coefficient associated with wearing tweed, and beta2
the coefficient
associated with the h-index.
These coefficients are “unstandardised” because we kept them in their
original spaces of h-index and “starts” for the evaluation scores. This is
useful if you need to know the practical effect, i.e. by how much does an
evaluation go up when wearing tweed. However, if you wanted to compare
the relative effects of tweed and h-index, these unstandardised coefficients
can’t just be compared. Instead, you would need to standardise all
(continuous) predictors and outcomes. Standardisation means that you
divide a set of scores by their standard deviation and then subtract their
mean, so that the resulting values have a mean of 0 and a standard deviation
of 1. When using these standardised values in the same regression, the betas
reflect standardised coefficients, and their magnitudes can be directly
compared to each other.
Note that standardisation should not happen the tweed variable, as this
one is binary: 0 for no tweed and 1 for tweed. Mathematically this is
convenient: a beta coefficient multiplied by 0 results in 0, but when
multiplied by 1, the result is the beta value itself. So they can be readily
interpreted as “wearing tweed is associated with a difference of beta in
teaching evaluations”.
Let’s see what the unstandardised coefficients are:
print("tweed: {}".format(betas[1]))
print("h-index: {}".format(betas[2]))
This shows us that wearing tweed jackets is associated with an
improvement in a lecturer’s evaluations by about 0.38 stars, and every step
in their h-index is associated with an improvement of 0.13 stars. Note that
these results are different from before: tweed previously was associated
with an improvement of 2 stars and h-index with an improvement of 0.14
stars. This is because the two variables share explained variance in the
outcome: part of the evaluation scores explained by wearing tweed were
also explained by h-index!
The other important value that was computed is the sum of squares of
the residuals. This is the total of all of the distances between the predicted
outcomes (this is what we previously visualised with the trend line) and thereal outcomes. These distances were squared to make sure they were all
positive (otherwise negative and positive values sum up to 0) and also to
make larger differences count more strongly than smaller differences. The
smaller the sum of squares of the residuals, the better the fit! However,
without any context, we don’t really know what a “small” value is for the
residuals…. How do we do that?
You might have already guessed it, but we need to compare the sum of
squares of the residuals to some measure of the variance of the outcome, to
once again compute some kind of a signal-to-noise ratio. In this case, we
can compute the total sum of squares of the outcome:
# Turn the outcome into a NumPy array,
# to make calculations easier.
evaluation = numpy.array(evaluation)
ss_tot = numpy.sum((evaluation \
⌴⌴⌴⌴- numpy.mean(evaluation))**2)
We can now compare the sum of squares of the residuals to the total sum of
squares. The result is the proportion of variance that is residual, i.e., that is
not explained by the regression model. To compute the variance that is
explained, we simply subtract the unexplained variance from 1:
r_sq = 1 - (ss_res / ss_tot)
print(r_sq)
The result here is the “coefficient of determination”, also called R
2
(pronounce “R square”), and quantifies the proportion of explained
variance. In our case, it’s almost all of it! (That’s because this is an example
with made-up data!) In realistic cases, it will be substantially lower, but that
should not deter you. Reality is complex, and biological systems
particularly so. Countless processes are active and interacting at any given
time, and linear associations between a handful of variables are not going to
explain more than a small proportion of the total variance in most
outcomes.
In sum, the R
2 will tell you how much of the variance is explained by
your model, and the betas will tell you the relationship between each
predictor and their outcome. These are the most important values to base
any conclusions on, as these tell you (1) how much of an outcome is
associated with your predictors and (2) the practical association between
each predictor and the outcome.At this point, you might wonder “How do I know if this is significant?”
If you’re asking out of a habitual need to slap one to three stars on values
before you feel good about a manuscript, then you might be asking the
wrong types of questions. However, it is most certainly not unreasonable to
want to know if an association is statistically significant before you start to
interpret it. You can derive an F-value and associated p-value from the
explained and unexplained variance, which will tell you if the whole model
is “significant”. You can also derive t-values and their associated p-values
from the betas and their standard errors. This requires some statistical
knowledge, but no further programming skills (you know all the required
ingredients at this point). However, you could also turn to specialised
packages like scikit-learn (focusses on prediction, less on statistics) and
statsmodels (will give you ALL the p-values). These are slightly beyond the
scope of this book, but they will build on the programming skills and
knowledge of the underlying fitting procedures that you have learned in this
chapter.GETTING HELP
DOI: 10.4324/9781003174332-13
After working your way through this book, you should be able to do quite a
bit of research with Python. However, there will inevitably be moments
where you get stuck on something. This is when you turn to the internet!
Stack Overflow
Stack Overflow is a programming forum. It is populated by an interesting
mix of complete idiots who will ask the stupidest questions, highly
qualified and experienced nerds who can fix any bug, and every kind of
programmer in between. If you have a question, chances are that you will
find someone else has already asked it and that another someone has
already provided an answer. You can find this wondrous website online on
stackoverflow.com.
Documentation Websites
Every Python package that was used in this book provides at least some
documentation on their website. You can find out more about PyGaze on
www.pygaze.org, more on PsychoPy can be found on www.psychopy.org,
and more on PyGame can be found on www.pygame.org. NumPy and
Matplotlib are both part of the SciPy project, and documentation can be
found through the project’s website: scipy.org.
PyGaze Forum
If you have a query that is specific to PyGaze, you can always turn to the
PyGaze forum. This is available via forum.cogsci.nl and is a platform where
psychologists can help each other. In addition, the package’s developers
regularly check it and provide help wherever they can.ACKNOWLEDGEMENTS
This book would have never been here, if it wasn’t for the support of
colleagues, friends, and family. (I won’t explicitly name everyone here, for
space reasons, but I’m grateful to all of you.) This is especially true for
Becca Hirst and Jon Peirce, who generously contributed the chapters on
coding experiments with PsychoPy. You’re great to work with, and I love
what you do with PsychoPy and with Open Science Tools!
My eternal gratitude goes out to Ignace Hooge, who introduced me to
programming (in Matlab), and to Sebastiaan Mathôt, whose code and help
allowed me to find my way in Python. Further thanks go out to all the
people at Utrecht University who had the courage to hire me, an over￾confident and under-skilled undergraduate, for their programming needs. A
special mention for Chris Paffen and Stefan van der Stigchel, who were the
first to employ me there.
As for actually writing the first edition of this book, I am indebted to
Masud Husain, my PhD supervisor. When he heard I was writing it, he
shook his head and reminded me that I should really start to focus on my
actual research projects. He was absolutely right, and any other supervisor
would have rightfully stopped me and/or given up hope that I would ever
finish my thesis. Thank you for understanding my perpetual need for
distraction. I also owe the late Glyn Humphreys, who allowed me to
organise a Python course for graduate students in his department, the
materials of which formed the basis for this book. I’m also grateful to the
participants of that course, for their enthusiasm, and for their suggestions
and corrections.
Huge thanks go to my former colleagues at the University of Oxford, my
lab mates in the groups of Masud Husain and the late Mark Stokes, and my
friends. You managed to cope with my continuous nagging and obsessing
over this book, and you provided me with the support I needed to pull
through. Bonus points for Laura Grima and Sean Fallon, who inquiredabout (or were involuntarily bothered with) my progress almost every day
in the final weeks before the deadline.
Writing the second edition was made substantially harder by the birth of
my sons, to the point that this book has been delayed so much that they are
now nearly old enough to help with the writing. I am grateful to my wife for
being an amazing co-parent and to nurseries and their wonderful staff for
allowing us to work (and sleep) during the day.
Of course, the fine people at Routledge deserve a mention here too.
Thank you to Michael Strang, Julie Toich, Elizabeth Rankin, and all the
copy editors who handled the first edition and to Lucy McClune, Akshita
Pattiyani, Adam Woods, and all the copy editors who handled the second
edition. Thanks so much for your support and for your continued patience!
(Especially Adam, thanks for your continued patience as I missed deadline
after deadline!) Finally, I would like to thank my parents. They somehow
successfully completed the process of producing and raising me, on a
shoestring budget, and while I attempted a teenage interpretation of
Reviewer Number 2. My belated apologies for being a little shit and also
thank you for persisting.REFERENCES
Dalmaijer, E. S., Mathôt, S., & Van der Stigchel, S. (2014). PyGaze:
An open-source, cross-platform toolbox for minimal-effort
programming of eyetracking experiments. Behavior Research
Methods, 46(4), 913–921. https://doi.org/10.3758/s13428-013-0422-2.
Damian, M. F. (2010). Does variability in human performance
outweigh imprecision in response devices such as computer
keyboards? Behavior Research Methods, 42(1), 205–211.
https://doi.org/10.3758/BRM.42.1.205.
Duryea, E. L., Hawkins, J. S., McIntire, D. D., Casey, B. M., &
Leveno, K. J. (2014). A revised birth weight reference for the United
States. Obstetrics & Gynecology, 124(1), 16.
https://doi.org/10.1097/AOG.0000000000000345.
Figlio, D. N., & Schapiro, M. (2017). Are great teachers poor
scholars? 2(6); Brookings Institution Evidence Speaks Reports, pp. 1–
7.
Fryar, C. D., Carroll, M. D., Gu, Q., Afful, J., & Ogden, C. L. (2021).
Anthropometric reference data for children and adults: United States,
2015–2018 (Vital and Health Statistics). National Centre for Health
Studies. https://www.cdc.gov/nchs/data/series/sr_03/sr03-046-508.pdf.
Harris, C. R., Millman, K. J., van der Walt, S. J., Gommers, R.,
Virtanen, P., Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N.
J., Kern, R., Picus, M., Hoyer, S., van Kerkwijk, M. H., Brett, M.,
Haldane, A., del Río, J. F., Wiebe, M., Peterson, P., … Oliphant, T. E.
(2020). Array programming with NumPy. Nature, 585(7825), 357–
362. https://doi.org/10.1038/s41586-020-2649-2.
Hunter, J. D. (2007). Matplotlib: A 2D graphics environment.
Computing in Science & Engineering, 9(3), 90–95.
https://doi.org/10.1109/MCSE.2007.55.Kerner, G. S., Fahrenkrog-Petersen, J.-U., Karges, C., Dehmel, J., &
Brendel, R. (1984, October 5). Irgendwie, irgendwo, irgenwann.
Columbia Broadcast System.
Mathôt, S., Dalmaijer, E. S., Grainger, J., & Van der Stigchel, S.
(2014). The pupillary light response reflects exogenous attention and
inhibition of return. Journal of Vision, 14(14), 7–7.
https://doi.org/10.1167/14.14.7
Oliphant, T. E. (2007). Python for scientific computing. Computing in
Science & Engineering, 9(3), 10–20.
https://doi.org/10.1109/MCSE.2007.58.
Peirce, J. W. (2007). PsychoPy—Psychophysics software in Python.
Journal of Neuroscience Methods, 162(1–2), 8–13.
https://doi.org/10.1016/j.jneumeth.2006.11.017.
Peirce, J. W. (2009). Generating stimuli for neuroscience using
PsychoPy. Frontiers in Neuroinformatics, 2.
https://doi.org/10.3389/neuro.11.010.2008.
Peirce, J. W., Hirst, R. J., & MacAskill, M. (2022). Building
experiments in psychopy (2nd ed.). SAGE Publishing.
Posner, M. I. (1980). Orienting of attention. Quarterly Journal of
Experimental Psychology, 32(1), 3–25.
https://doi.org/10.1080/00335558008248231.
Reep, C. (2021). Een studie naar de lengteontwikkeling van
Nederlanders. Centraal Bureau voor de statistiek.
https://www.cbs.nl/nl-nl/longread/statistische-trends/2021/een-studie￾naar-de-lengteontwikkeling-van-nederlanders.
Wallace, D. J., Greenberg, D. S., Sawinski, J., Rulla, S., Notaro, G., &
Kerr, J. N. D. (2013). Rats maintain an overhead binocular field at the
expense of constant fusion. Nature, 498(7452), 65–69.
https://doi.org/10.1038/nature12153.INDEX
Note: Italic page numbers refer to figures.
accuracy: peripheral 60–61
as variable in analysing behavioural data 110, 111, 114, 117–121,
132, 134
analysis: analysis.py 111, 114, 115, 118, 121, 125, 128, 131, 132, 135–
137, 153
of behavioural data see behavioural data analysis
repeated-measures analysis of variance (ANOVA) 128
of traces trace analysis
arange function 75, 77, 139
arguments 27–28
keyword 28, 107, 112, 147, 154, 156–158, 169
arrays 21–22
Booleans 114–116
NumPy 22–23, 32, 33, 45–46, 77, 112–114, 117, 122, 124, 128,
132, 134, 137, 154, 168, 176
attentional facilitation 80
averaging: data 115–117
traces 135–141, 139, 140 see also median reaction times
behavioural data analysis 110–129
analysis plan 110–111
averaging data 115–117
combining datasets 121–128, 127
extracting data 111–114
plotting data 118–121, 120
selecting data 114–115statistical testing 128–129
Bonferroni correction 138, 139
Boole, George 11
Booleans 11–13, 30, 66, 71, 92, 107, 118, 144, 158, 159
array 114–116
DUMMYMODE 144, 145
classes 24–25
colours 6, 7, 7, 18, 33, 44, 68, 70, 71, 119, 125, 126, 131, 133, 145,
150, 158
in PsychoPy 38–40
tone 106
command line 4
comments 40
compiled languages 36
constants 91–92
constants.py 102, 104, 105
eye-tracking experiment 144–146
gaze data extraction 152, 153
copy function 20
core.wait function 41, 42, 44, 55, 56, 62, 64, 67, 68, 83
correlation: covariance 170–171
Pearson’s correlation coefficient (R) 171
Spearman’s ρ coefficient 171–172
counterbalanced block designs 95–101
covariance 170–171
cue: duration 91
location 81, 110, 113
validity 81, 87, 110
cueing, Posner see Posner cueing
data analysis, behavioural see behavioural data analysis
decimal separator 90degree of freedom 166
dependencies 3
dialog box, presenting 92–93
dictionaries 23–24
keys 23
documentation websites 178
draw_fixation 146, 157–159
draw_image 148
draw_text 146, 150
DUMMYMODE 144–145, 152
editor 6–7, 7, 9, 36, 50, 76, 90, 102
behavioural data analysis 111–113, 117, 124
gaze data extraction 153, 155 see also Spyder
error bars 119, 125, 126
exceptions (errors) 113, 114, 163–165
exogenous cueing see Posner cueing
Experiment Handler 90–91
experiment.py 81, 101
eye-tracking experiment 146, 148
gaze data extraction 153
experiment scripting 80–101
constants 91–92
counterbalanced block designs 95–101
data, understanding 101
dialog box, presenting 92–93
Experiment Handler 90–91
keyboard accuracy, storing 93–94
randomized block designs 94–95
several trials 86–88
single trial 81–86
spreadsheet of trials, importing 89–90
TrialHandler 90explained variance 176
EyeLink 1000 tracker 130–132, 144, 149, 152, 153
eye tracking 142–162
analysing fixations 156–162, 157–162
class 147–148
constants.py 144–146
experiment 143–151
extracting gaze data 153–155
materials 143
processing gaze data 155–156
screens 146–147
single trial 148–150
whole experiment 151
feedback 66–68, 93, 94, 97–99, 101, 103
fixation analysis/visualisation, eye tracking 156–162, 156–162
fixation marks 145–147, 149, 152, 156
fixation screen 112, 146, 149
floats 8–10, 16, 17, 104, 113, 114
for loops 48–49, 51, 55, 56, 67, 72, 73, 86, 109
behavioural data analysis 113, 114, 116, 117, 119, 121, 123
and eye tracking 151, 155
and trace analysis 135–139
functions 25–31
and arguments 27–28
create your first function 29
create your second function 29–30
create your third function 30–31
and local and global variables 28–29
recipe example 26–27
string 14–15 see specific functions by name
gaze data: extracting 153–155processing 155–156
headers 89, 112, 163
heatmaps 158–159, 159, 161, 161, 162
if statements 27, 53, 66–67, 93, 108, 154
indentation 63–64
image drawing 148
IMGNAMES 145, 146, 148, 149, 151, 152, 155, 156, 158, 159
importing 20, 37, 39, 82, 104, 131, 145, 146, 153
spreadsheet of trials 89–90
indentation: and functions 27
and if statements 63–64
and loops 123, 151
independent-samples t-test 169–170
infinite loops 52, 53
inhibition of return 80, 81, 129
installation: Anaconda 3
dependencies 3
packages with pip 4–5
PsychoPy 4
versions 2–3
WinPython 4
instructions Screen 150
integers 8–9
interpreted languages 36
interpreter 5–8, 6, 11–14, 29, 30, 36, 74
behavioural data analysis 112, 115, 117, 124
and trace analysis 132–134
join method 148
joysticks 102–105
keyboard accuracy, storing 93–94keyboard input 61–66
in place of joystick 105–106
response times, “zero point” of 64–65
waiting for 62–63
while loops 51–53
without waiting, fetching 65–66
keys, dictionary 23
keyword arguments 28, 107, 112, 169
and eye tracking 147, 154, 156–158
len function 51, 66, 75, 113, 114, 116, 117, 132, 135, 137, 138–140,
155
letters 13–16
strings see strings
linear regression 172–177
multivariable 174–177
univariable 173–174
lists 17–20
expanding methods 19
nested 18, 19
removing values 19
reversing the order 18–19
local minimum 175
loops: and indentation 123, 151
infinite 52, 53
for see for loops
and sound 107–108
while 51–53
map function 105
Matplotlib 33–34, 75, 77, 111, 118, 119, 124, 131, 138, 153, 157, 174,
178
pyplot library 33, 34, 75, 77, 111, 118, 124, 125, 131, 132, 134,
138, 153, 157, 174mean function 125, 137
median reaction times 119, 121, 122, 124
methods (in classes) 25
mouse: current position, fetching 69–70
responses 69–72
scroll behaviour, checking 71–72
speed and accuracy 60–61
status of buttons, checking 70–71
using while loops with 72–73
multivariable linear regression 174–177
nested lists 18, 19
nesting 17, 18
noise: code listing 33, 45
sinusoid and 74–77
sound see sound
visual 32, 33, 45
numbers: floats 9–10
integers 8–9
random 32–33, 78, 116
to sound 77–79
NumPy 2, 5
arrays 22–23, 32, 33, 45–46, 77, 112–114, 117, 122, 124, 128,
132, 134, 137, 154, 168, 176
for behavioural data analysis 111–117, 122–128
rand function 33
range function 74–76
std function 137, 138
for trace analysis 131, 132, 134, 136–140
where function 134
object-oriented programming 25
one-sampled t-test 167–168ordinary least squares 175
parsing 112
patches 2
pause function 149
Pearson’s correlation coefficient (R) 171
peripherals 52–53 see also keyboard input
PIL Python Imaging Library (PIL)
Posner, M. I. 80
Posner cueing 80
processing responses 60–73
feedback see feedback
if statements see if statements
keyboard input see keyboard input
mouse mouse
peripheral accuracy 52–53
sound see sound
typed responses 67–69
properties (in classes) 25
proportion of correct responses 115, 122
PsychoPy 6, 22, 37, 144, 152
Coder View 36, 37
counterbalanced block designs 97
dialog box 92
DISPSIZE 102, 144, 152, 156–159
dynamic stimuli 57
feedback 97, 103
get_key method 106, 148, 150
images 44, 46
ImageStim 44–46
importing a spreadsheet of trials 89
installation 4joystick 103
keyboard input 61–63
mouse responses 69
presenting stimuli 82
scripting an experiment 82, 89, 92, 97
shapes 43
TextStim 41
units and colours in 3, 38–40
waitKeys 62–63
while loops 51, 52
pupillometry 142
eye tracking see eye tracking
pupil size 130
trace analysis trace analysis
p-value 166–167
PyGame 3, 74, 102, 178
eye tracking 144, 152
jouystick 102
mixer module 77–78
sinusoid and noise 76
PyGaze 35, 178
Analyser 130–131, 151, 153
DISPSIZE 143
eye tracking 143, 146, 147
forum 178
joystick 103–104
keyboard module 105
pyglet 3
pyplot library 33, 34, 75, 77, 111, 118, 124, 125, 131, 132, 134, 138,
153, 157, 174
Python: dependencies 3
editor see editorinstallation 2–5
interpreter see interpreter
popularity 1
processing responses see processing responses
scripts scripts
speed issues 2
and stimuli stimuli
variables see variables
versatility 1
versions 2–3
Python Imaging Library (PIL): blurring images using 46–47
rand function 33
randomisation 47, 80, 89, 90
random module 32, 47, 61
random numbers 32–33, 78, 116
range function 74–76
reaction times 64, 80, 81, 85, 110–113, 115, 116, 120, 120, 123, 125,
126, 128–130
median 119, 121, 122, 124
related samples t-test 168–169
repeated-measures analysis of variance (ANOVA) 128
residuals 175
SciPy 3, 175, 178
state module 111, 128, 131, 167–169, 171–173
screens: eye tracking 146–147
fixation 112, 146, 149
fixation marks 145–147, 149, 152, 156
image drawing 148
instructions 150
scripting an experiment 81, 82, 84, 97
scripts: comments 50–51creating 36
editor see editor
experiment see experiment.py
experiment scripting
SEM see standard error of the mean (SEM)
sets 16–24
arrays see arrays
dictionaries 23–24
lists see lists
tuples 20–21
sine waves 74–78, 107
SOA stimulus onset asynchrony (SOA)
sound 74
on button presses, playing 106–108
joystick 102–104
keyboard 105–106
loops and 107–108
noise noise
numbers to 77–79
sampling 75–76
Spearman’s ρ coefficient 171–172
speed issues 2
spreadsheet of trials, importing 89–90
Spyder 7, 7, 39, 112, 123, 155
Stack Overflow 178
standard error of the mean (SEM) 110, 111, 115, 117, 118, 125, 126,
128, 137, 139, 140, 164, 165, 167
standardisation 175–176
standardised coefficients 175
statistical testing 128–129, 163–177
error 163–165
linear regression see linear regressiont-tests t-tests
variance 163–165
std function 137, 138
stimuli, creating and presenting 35–59
comments 40, 58–59
dynamic stimuli 57–58
ElementArrayStim 54–55
indentation 49–51
for loops 48–49
presenting images 44–47
PsychoPy Coder View 36
random locations 47–48
scripts 36
text 40–43
throwing spaces 43–44
timing visual stimuli by frames 55–57
using loops to generate many stimuli 53–54
while loops 51–53
window 36–40
stimulus onset asynchrony (SOA): behavioural data analysis 114–120,
122, 124–126
scripting an experiment 80–81, 87–88, 89
statistical testing 128–129
strings 13–14
formatting 15–16
functions 14–15
terminals 5–6, 103
TextStim 41
throwing spaces 43–44
timeout 103–106, 146
timestamps 101, 104, 112
and eye tracking 154and trace analysis 132–134, 136
timing: visual stimuli by frames 55–57
trace analysis: averaging 135–141, 139, 141
eye-tracker data, reading 131–132
first trace, plotting 132–135, 133, 135
pupil size 130
PyGaze Analyser 130–131
TRACKERTYPE 144, 152
TrialHandler 90
try-except statements 113–114
ttest_rel function 111, 128, 129, 131, 138, 168
t-tests: correlation correlation
independent-samples 169–170
one-sampled 167–168
p-value 166–167
related samples 168–169
tuples 20–21
typed responses 67–69
univariable linear regression 173–174
unstandardised coefficients 175
Van Unnik building, Utrecht University 161, 161
variables 8–31
assigning 10–11
Booleans see Booleans
classes 24–25
functions 25–31
letters 13–16
lists 17–20
numbers numbers
sets see sets
strings see stringsvariance 163–165
vectors 77
Booleans see Booleans
visual noise 32, 33, 45
wave 76
where function 134
while loops 51–53
with mouse, using 72–73
win.flip() 42–43
WinPython 4
