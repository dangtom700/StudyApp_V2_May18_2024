Modern Discrete Probability
Providing a graduate-level introduction to discrete probability and its applications,
this book develops a toolkit of essential techniques for analyzing stochastic processes
on graphs, other random discrete structures, and algorithms.
The topics covered in this book include the first and second moment methods,
concentration inequalities, coupling and stochastic domination, martingales and po￾tential theory, spectral methods, and branching processes. Each chapter expands on a
fundamental technique, outlining common uses and showing them in action on sim￾ple examples and more substantial classical results. The focus is predominantly on
non-asymptotic methods and results.
All chapters provide a detailed background review section, plus exercises and
signposts to the wider literature. Readers are assumed to have undergraduate-level
linear algebra and basic real analysis, while prior exposure to graduate-level proba￾bility is recommended.
This much-needed broad overview of discrete probability could serve as a text￾book or as a reference for researchers in mathematics, statistics, data science, com￾puter science, and engineering.
S É B A S T I E N R O C H is Professor of Mathematics at the University of Wisconsin–
Madison. He has received an NSF CAREER award, an Alfred P. Sloan Fellowship,
and a Simons Fellowship in Mathematics, and is a Fellow of the Institute for Mathe￾matical Statistics.
Published online by Cambridge University PressC A M B R I D G E S E R I E S I N S TAT I S T I C A L A N D
P R O B A B I L I S T I C M AT H E M AT I C S
Editorial Board
Z. Ghahramani (Department of Engineering, University of Cambridge)
R. Gill (Mathematical Institute, Leiden University)
F. P. Kelly (Department of Pure Mathematics and Mathematical Statistics,
University of Cambridge)
B. D. Ripley (Department of Statistics, University of Oxford)
S. Ross (Department of Industrial and Systems Engineering,
University of Southern California)
M. Stein (Department of Statistics, Rutgers University & Department of Statistics,
University of Chicago)
This series of high-quality upper-division textbooks and expository monographs covers all aspects
of stochastic applicable mathematics. The topics range from pure and applied statistics to probabil￾ity theory, operations research, optimization, and mathematical programming. The books contain
clear presentations of new developments in the field and also of the state of the art in classical
methods. While emphasizing rigorous treatment of theoretical methods, the books also contain ap￾plications and discussions of new techniques made possible by advances in computational practice.
A complete list of books in the series can be found at www.cambridge.org/statistics.
Recent titles include the following:
34. Regression for Categorical Data, by Gerhard Tutz
35. Exercises in Probability (Second Edition), by Loïc Chaumont and Marc Yor
36. Statistical Principles for the Design of Experiments, by R. Mead, S. G. Gilmour and A. Mead
37. Quantum Stochastics, by Mou-Hsiung Chang
38. Nonparametric Estimation under Shape Constraints, by Piet Groeneboom and Geurt Jongbloed
39. Large Sample Covariance Matrices and High-Dimensional Data Analysis, by Jianfeng Yao,
Shurong Zheng and Zhidong Bai
40. Mathematical Foundations of Infinite-Dimensional Statistical Models, by Evarist Giné and
Richard Nickl
41. Confidence, Likelihood, Probability, by Tore Schweder and Nils Lid Hjort
42. Probability on Trees and Networks, by Russell Lyons and Yuval Peres
43. Random Graphs and Complex Networks (Volume 1), by Remco van der Hofstad
44. Fundamentals of Nonparametric Bayesian Inference, by Subhashis Ghosal and Aad van der Vaart
45. Long-Range Dependence and Self-Similarity, by Vladas Pipiras and Murad S. Taqqu
46. Predictive Statistics, by Bertrand S. Clarke and Jennifer L. Clarke
47. High-Dimensional Probability, by Roman Vershynin
48. High-Dimensional Statistics, by Martin J. Wainwright
49. Probability: Theory and Examples (Fifth Edition), by Rick Durrett
50. Model-based Clustering and Classification for Data Science, by Charles Bouveyron et al.
51. Spectral Analysis for Univariate Time Series, by Donald B. Percival and Andrew T. Walden
52. Statistical Hypothesis Testing in Context, by Michael P. Fay and Erica H. Brittain
53. The Fundamentals of Heavy Tails, by Jayakrishnan Nair, Adam Wierman and Bert Zwart
54. Random Graphs and Complex Networks (Volume 2), by Remco van der Hofstad
55. Modern Discrete Probability, by Sébastien Roch
56. Generalized Additive Models for Location, Scale and Shape, by Mikis D. Stasinopoulos et al.
Published online by Cambridge University PressModern Discrete Probability
An Essential Toolkit
Sébastien Roch
University of Wisconsin–Madison
Published online by Cambridge University PressShaftesbury Road, Cambridge CB2 8EA, United Kingdom
One Liberty Plaza, 20th Floor, New York, NY 10006, USA
477 Williamstown Road, Port Melbourne, VIC 3207, Australia
314–321, 3rd Floor, Plot 3, Splendor Forum, Jasola District Centre,
New Delhi – 110025, India
103 Penang Road, #05–06/07, Visioncrest Commercial, Singapore 238467
Cambridge University Press is part of Cambridge University Press & Assessment,
a department of the University of Cambridge.
We share the University’s mission to contribute to society through the pursuit of
education, learning and research at the highest international levels of excellence.
www.cambridge.org
Information on this title: www.cambridge.org/9781009305112
DOI: 10.1017/9781009305129
c Sébastien Roch 2024
This publication is in copyright. Subject to statutory exception and to the provisions
of relevant collective licensing agreements, no reproduction of any part may take
place without the written permission of Cambridge University Press & Assessment.
First published 2024
A catalogue record for this publication is available from the British Library
Library of Congress Cataloging-in-Publication Data
Names: Roch, Sébastien, author.
Title: Modern discrete probability : an essential toolkit / Sébastien
Roch, University of Wisconsin, Madison.
Description: Cambridge, United Kingdom ; New York, NY : Cambridge
University Press, 2024. | Series: Cambridge series in statistical and
probabilistic mathematics ; 55 | Includes bibliographical references and index.
Identifiers: LCCN 2023044218 | ISBN 9781009305112 (hardback) | ISBN
9781009305129 (ebook)
Subjects: LCSH: Stochastic processes. | Graph theory.
Classification: LCC QA274.2 .R63 2024 | DDC 519.2/3–dc23/eng/20231023
LC record available at https://lccn.loc.gov/2023044218
ISBN 978-1-009-30511-2 Hardback
Cambridge University Press & Assessment has no responsibility for the persistence
or accuracy of URLs for external or third-party internet websites referred to in this
publication and does not guarantee that any content on such websites is, or will remain,
accurate or appropriate.
Published online by Cambridge University PressTo Betsy
Published online by Cambridge University PressPublished online by Cambridge University PressContents
Preface xi
Notation xv
1 Introduction 1
1.1 Background 1
1.1.1 Review of Graph Theory 1
1.1.2 Review of Markov Chain Theory 7
1.2 Some Discrete Probability Models 14
Exercises 17
2 Moments and Tails 21
2.1 Background 21
2.1.1 Definitions 21
2.1.2 Basic Inequalities 22
2.2 First Moment Method 25
2.2.1 The Probabilistic Method 25
2.2.2 Boole’s Inequality 28
2.2.3 F Random Permutations: Longest Increasing Subsequence 30
2.2.4 F Percolation: Existence of a Non-trivial Threshold on Z
2 31
2.3 Second Moment Method 35
2.3.1 Paley–Zygmund Inequality 35
2.3.2 F Random Graphs: Subgraph Containment and Connectivity
in the Erdos–Rényi Model ˝ 37
2.3.3 F Percolation: Critical Value on Trees and Branching Number 43
2.4 Chernoff–Cramér Method 49
2.4.1 Tail Bounds Via the Moment-Generating Function 49
2.4.2 Sub-Gaussian and Sub-Exponential Random Variables 54
2.4.3 F Probabilistic Analysis of Algorithms: Knapsack Problem 61
2.4.4 Epsilon-Nets and Chaining 65
2.4.5 F Data Science: Johnson–Lindenstrauss Lemma and Appli￾cation to Compressed Sensing 72
2.4.6 F Data Science: Classification, Empirical Risk Minimization,
and VC Dimension 79
Exercises 90
vii
Published online by Cambridge University Pressviii Contents
3 Martingales and Potentials 95
3.1 Background 95
3.1.1 Stopping Times 95
3.1.2 F Markov Chains: Exponential Tail of Hitting Times and Some
Cover Time Bounds 101
3.1.3 Martingales 103
3.1.4 F Percolation: Critical Regime on Infinite d-regular Tree 113
3.2 Concentration for Martingales and Applications 114
3.2.1 Azuma–Hoeffding Inequality 114
3.2.2 Method of Bounded Differences 115
3.2.3 F Random Graphs: Exposure Martingale and Application to
the Chromatic Number in Erdos–Rényi Model ˝ 124
3.2.4 F Random Graphs: Degree Sequence of Preferential Attach￾ment Graphs 128
3.2.5 F Data Science: Stochastic Bandits and the Slicing Method 133
3.2.6 Coda: Talagrand’s Inequality 139
3.3 Potential Theory and Electrical Networks 141
3.3.1 Martingales, the Dirichlet Problem and Lyapounov Functions 142
3.3.2 Basic Electrical Network Theory 150
3.3.3 Bounding the Effective Resistance via Variational Principles 158
3.3.4 F Random Walks: Pólya’s Theorem, Two Ways 169
3.3.5 F Randomized Algorithms: Wilson’s Method for Generating
Uniform Spanning Trees 170
Exercises 176
4 Coupling 182
4.1 Background 182
4.1.1 Basic Definitions 182
4.1.2 F Random Walks: Harmonic Functions on Lattices and Infi￾nite d-regular Trees 184
4.1.3 Total Variation Distance and Coupling Inequality 186
4.1.4 F Random Graphs: Degree Sequence in Erdos–Rényi Model ˝ 192
4.2 Stochastic Domination 194
4.2.1 Definitions 195
4.2.2 Ising Model: Boundary Conditions 202
4.2.3 Correlation Inequalities: FKG and Holley’s Inequalities 205
4.2.4 F Random Graphs: Janson’s Inequality and Application to the
Clique Number in the Erdos–Rényi Model ˝ 210
4.2.5 F Percolation: RSW Theory and a Proof of Harris’ Theorem 213
4.3 Coupling of Markov Chains and Application to Mixing 219
4.3.1 Bounding the Mixing Time via Coupling 219
4.3.2 F Random Walks: Mixing on Cycles, Hypercubes, and Trees 222
4.3.3 Path Coupling 229
4.3.4 F Ising Model: Glauber Dynamics at High Temperature 231
4.4 Chen–Stein Method 234
Published online by Cambridge University PressContents ix
4.4.1 Main Bounds and Examples 235
4.4.2 Some Motivation and Proof 241
4.4.3 F Random Graphs: Clique Number at the Threshold in the
Erdos–Rényi Model ˝ 249
Exercises 250
5 Spectral Methods 256
5.1 Background 256
5.1.1 Eigenvalues and Their Variational Characterization 256
5.1.2 Elements of Spectral Graph Theory 261
5.1.3 Perturbation Results 268
5.1.4 F Data Science: Community Recovery 270
5.2 Spectral Techniques for Reversible Markov Chains 276
5.2.1 Spectral Gap 278
5.2.2 F Random Walks: A Spectral Look at Cycles and Hypercubes 282
5.2.3 F Markov Chains: Varopoulos–Carne and Diameter-Based
Bounds on the Mixing Time 287
5.2.4 F Randomized Algorithms: Markov Chain Monte Carlo and
a Quantitative Ergodic Theorem 292
5.2.5 Spectral Radius 296
5.3 Geometric Bounds 300
5.3.1 Cheeger’s Inequality 304
5.3.2 F Random Walks: Trees, Cycles, and Hypercubes Revisited 308
5.3.3 F Random Graphs: Existence of an Expander Family and
Application to Mixing 310
5.3.4 F Ising Model: Glauber Dynamics on Complete Graphs and
Expanders 315
5.3.5 Congestion Ratio 320
Exercises 323
6 Branching Processes 327
6.1 Background 327
6.1.1 Basic Definitions 327
6.1.2 Extinction 328
6.1.3 F Percolation: Galton–Watson Trees 332
6.1.4 Multitype Branching Processes 333
6.2 Random-Walk Representation 338
6.2.1 Exploration Process 338
6.2.2 Duality Principle 340
6.2.3 Hitting-Time Theorem 341
6.2.4 F Percolation: Critical Exponents on the Infinite b-ary Tree 345
6.3 Applications 348
6.3.1 F Probabilistic Analysis of Algorithms: Binary Search Tree 348
6.3.2 F Data Science: The Reconstruction Problem, the Kesten–
Stigum Bound and a Phase Transition in Phylogenetics 356
Published online by Cambridge University Pressx Contents
6.4 F Finale: The Phase Transition of the Erdos–Rényi Model ˝ 368
6.4.1 Statement and Proof Sketch 368
6.4.2 Bounding Cluster Size: Domination by Branching Processes 370
6.4.3 Concentration of Cluster Size: Second Moment Bounds 379
6.4.4 Critical Case via Martingales 384
6.4.5 F Encore: Random Walk on the Erdos–Rényi Graph ˝ 388
Exercises 391
Appendix A Useful Combinatorial Formulas 397
Appendix B Measure-Theoretic Foundations 398
B.1 Probability Spaces 398
B.2 Random Variables 400
B.3 Independence 403
B.4 Expectation 406
B.5 Fubini’s Theorem 411
B.6 Conditional Expectation 413
B.7 Filtered Spaces 418
Bibliography 419
Index 429
Published online by Cambridge University PressPreface
This book arose from a set of lecture notes prepared for a one-semester topics course I taught
at the University of Wisconsin–Madison in 2014, 2017, 2020, and 2023, which attracted a
wide spectrum of students in mathematics, computer sciences, engineering, and statistics.
What Is It About?
The purpose of the book is to provide a graduate-level introduction to discrete probabil￾ity. Topics covered are drawn primarily from stochastic processes on graphs: percolation,
random graphs, Markov random fields, random walks on graphs, and so on. No attempt is
made at covering these broad areas in depth. Rather, the emphasis is on illustrating important
techniques used to analyze such processes. Along the way, many standard results regarding
discrete probability models are worked out.
The “modern” in the title refers to the (nonexclusive) focus on non-asymptotic methods
and results, reflecting the impact of the theoretical computer science literature on the trajec￾tory of this field. In particular, several applications in randomized algorithms, probabilistic
analysis of algorithms, and theoretical machine learning are used throughout to motivate the
techniques described (although, again, these areas are not covered exhaustively).
Of course, the selection of topics is somewhat arbitrary and driven in part by personal
interests. But the choice was guided by a desire to introduce techniques that are widely used
across discrete probability and its applications. The material discussed here is developed in
much greater depth in the following (incomplete list of) excellent textbooks and expository
monographs, many of which influenced various sections of this book:
• Agarwal, Jiang, Kakade, Sun. Reinforcement Learning: Theory and Algorithms. [AJKS22]
• Aldous, Fill. Reversible Markov Chains and Random Walks on Graphs. [AF]
• Alon, Spencer. The Probabilistic Method. [AS11]
• B. Bollobás. Random graphs. [Bol01]
• Boucheron, Lugosi, Massart. Concentration Inequalities: A Nonasymptotic Theory of
Independence. [BLM13]
• Chung, Lu. Complex Graphs and Networks. [CL06]
• Durrett. Random Graph Dynamics. [Dur06]
• Frieze and Karonski. ´ Introduction to Random Graphs. [FK16]
• Grimmett. Percolation. [Gri10b]
• Janson, Luczak, Rucinski. Random Graphs. [JLR11]
• Lattimore, Szepesvári. Bandit Algorithms. [LS20]
xi
https://doi.org/10.1017/9781009305129.001 Published online by Cambridge University Pressxii Preface
• Levin, Peres, Wilmer. Markov Chains and Mixing Times. [LPW06]
• Lyons, Peres. Probability on Trees and Networks. [LP16]
• Mitzenmacher, Upfal. Probability and Computing: Randomized Algorithms and Proba￾bilistic Analysis. [MU05]
• Motwani, Raghavan. Randomized Algorithms. [MR95]
• Rassoul-Agha, Seppäläinen. A Course on Large Deviations with an Introduction to Gibbs
Measures. [RAS15]
• S. Shalev-Shwartz and S. Ben-David. Understanding Machine Learning: From Theory to
Algorithms. [SSBD14]
• van Handel. Probability in High Dimension. [vH16]
• van der Hofstad. Random Graphs and Complex Networks. Vol. 1. [vdH17]
• Vershynin. High-Dimensional Probability: An Introduction with Applications in Data
Science. [Ver18]
In fact, the book is meant as a first foray into the basic results and/or toolkits detailed in
these more specialized references. My hope is that, by the end, the reader will have picked
up sufficient fundamental background to learn advanced material on their own with some
ease. I should add that I used many additional helpful sources; they are acknowledged in
the “Bibliographic Remarks” at the end of each chapter. It is impossible to cover everything.
Some notable omissions include, for example, graph limits [Lov12], influence [KS05], and
group-theoretic methods [Dia88], among others. Much of the material covered here (and
more) can also be found in [HMRAR98], [Gri10a], and [Bre17] with a different emphasis
and scope.
Prerequisites
It is assumed throughout that the reader is fluent in undergraduate linear algebra, for exam￾ple, at the level of [Axl15], and basic real analysis, for example, at the level of [Mor05].
In addition, it is recommended that the reader has taken at least one semester of graduate
probability at the level of [Dur10]. I am also particularly fond of [Wil91], which heavily
influenced Appendix B, where measure-theoretic background is reviewed. Some familiarity
with countable Markov chain theory is necessary, as covered for instance in [Dur10, chap￾ter 6]. An advanced undergraduate or Master’s level treatment such as [Dur12], [Nor98],
[GS20], [Law06], or [Bre20] will suffice, however.
Organization of the Book
The book is organized around five major “tools.” The reader will have likely encountered
those tools in prior probability courses. The goal here is to develop them further, specifically
with their application to discrete random structures in mind, and to illustrate them in this
setting on a variety of major classical results and applications.
In the interest of keeping the book relatively self-contained and serving the widest spec￾trum of readers, each chapter begins with a “background” section that reviews the basic
https://doi.org/10.1017/9781009305129.001 Published online by Cambridge University PressPreface xiii
material on which the rest of the chapter builds. The remaining sections then proceed to ex￾pand on two or three important specializations of the tools. While the chapters are meant to
be somewhat modular, results from previous chapters do occasionally make an appearance.
The techniques are illustrated throughout with simple examples first, and then with more
substantial ones in separate sections marked with the symbol F. I have attempted to pro￾vide applications from many areas of discrete probability and theoretical computer science,
although some techniques are better suited for certain types of models or questions. The
examples and applications are important: many of the tools are quite straightforward (or
even elementary), and it is only when seen in action that their full power can be appreciated.
Moreover, the F sections serve as an excuse to introduce the reader to classical results and
important applications – beyond their reliance on specific tools.
Chapter 1 introduces some of the main probability on graph models we come back to
repeatedly throughout the book. It begins with a brief review of graph theory and Markov
chain theory.
Chapter 2 starts out with the probabilistic method, including the first moment principle
and second moment method, and then it moves on to concentration inequalities for sums of
independent random variables, mostly sub-Gaussian and sub-exponential variables. It also
discusses techniques to analyze the suprema of random processes.
Chapter 3 turns to martingales. The first main topic there is the Azuma–Hoeffding in￾equality and the method of bounded differences with applications to random graphs and
stochastic bandit problems. The second main topic is electrical network theory for random
walks on graphs.
Chapter 4 introduces coupling. It covers stochastic domination and correlation inequali￾ties as well as couplings of Markov chains with applications to mixing. It also discusses the
Chen–Stein method for Poisson approximation.
Chapter 5 is concerned with spectral methods. A major topic there is the use of the spectral
theorem and geometric bounds on the spectral gap to control the mixing time of a reversible
Markov chain. The chapter also introduces spectral methods for community recovery in
network analysis.
Chapter 6 ends the book with applications of branching processes. Among other applica￾tions, an introduction to the reconstruction problem on trees is provided. The final section
gives a detailed analysis of the phase transition of the Erdos–Rényi graph, where techniques ˝
from all chapters of the book are brought to bear.
Acknowledgments
The lecture notes on which this book is based were influenced by graduate courses of David
Aldous, Steve Evans, Elchanan Mossel, Yuval Peres, Alistair Sinclair, and Luca Trevisan at
UC Berkeley, where I learned much of this material. In particular, scribe notes for some of
these courses helped shape early iterations of this book.
I have also learned a lot over the years from my collaborators and mentors as well as
my former and current Ph.D. students and postdocs. I am particularly grateful to Elchanan
Mossel and Allan Sly for encouragements to finish this project and to the UW–Madison
students who have taken the various iterations of the course that inspired the book for their
invaluable feedback.
https://doi.org/10.1017/9781009305129.001 Published online by Cambridge University Pressxiv Preface
Warm thanks to everyone in the departments of mathematics at UCLA and UW–Madison
who have provided the stimulating environments that made this project possible. Beyond my
current departments, I am particularly indebted to my colleagues in the NSF-funded Institute
for Foundations of Data Science (IFDS) who have significantly expanded my knowledge of
applications of this material in machine learning and statistics.
This book would have not have been possible without the hard work and advice of var￾ious people at Cambridge University Press and Integra, including Diana Gillooly, Natalie
Tomlinson, Anna Scriven, Rebecca Grainger, Clare Dennison, Bhavani Vijayamani, and
Sajukrishnan Balakrishnan, as well as several anonymous reviewers.
Finally, I thank my parents, my wife, and my son for their love, patience, and support.
https://doi.org/10.1017/9781009305129.001 Published online by Cambridge University PressNotation
Throughout the book, we will use the following notation.
• The real numbers are denoted by R, the non-negative reals are denoted by R+, the integers
are denoted by Z, the non-negative integers are denoted by Z+, the natural numbers (i.e.,
positive integers) are denoted by N, and the rational numbers are denoted by Q. We will
also use the notation Z+ := {0, 1, . . . , +∞}.
• For two reals a, b ∈ R,
a ∧ b := min{a, b}, a ∨ b := max{a, b},
and
a
+ = 0 ∨ a, a
− = 0 ∨ (−a).
• For a real a, bac is the largest integer that is smaller than or equal to a and dae is the
smallest integer that is larger than or equal to a.
• For x ∈ R, the natural (i.e., base e) logarithm of x is denoted by log x. We also let NATURAL
exp(x) = e
x
. LOGARITHM
• For a positive integer n ∈ N, we let
[n] := {1, . . . , n}.
• The cardinality of a set A is denoted by |A|. The powerset of A is denoted by 2A
.
• For two sets A, B, their Cartesian product is denoted by A × B.
• We will use the following notation for standard vectors: 0 is the all-zero vector, 1 is the
all-one vector, and ei
is the standard basis vector with a 1 in coordinate i and 0 elsewhere.
In each case, the dimension is implicit, as well as whether it is a row or column vector.
• For a vector u = (u1, . . . , un) ∈ R
n
and real p > 0, its p-norm (or `
p
-norm) is p-NORM
kukp :=
 Xn
i=1
|ui
|
p
!1/p
.
When p = +∞, we have
kuk∞ := max
i
|ui
|.
We also use the notation kuk0 to denote the number of non-zero coordinates of u (although
it is not a norm; see Exercise 1.1). For two vectors u = (u1, . . . , un), v = (v1, . . . , vn) ∈ R
n
,
their inner product is INNER
PRODUCT
xv
Published online by Cambridge University Pressxvi Notation
hu, vi :=
Xn
i=1
uivi
.
The same notations apply to row vectors.
• For a matrix A, we denote the entries of A either by A(i, j) or by Ai,j (unless otherwise
specified). The ith row of A is denoted by A(i, ·) or Ai,·
. The jth column of A is denoted by
A(·, j) or A·,j
. The transpose of A is A
T
.
• For a vector z = (z1, . . . ,zd), we let diag(z) be the diagonal matrix with diagonal entries
z1, . . . ,zd.
BINOMIAL • The binomial coefficients are defined as
COEFFICIENTS 
n
k

=
n!
k!(n − k)!
,
where k, n ∈ N with k ≤ n and n! = 1 × 2 × · · · × n is the factorial of n. Some stand￾ard approximations for ￾
n
k

and n! are listed in Appendix A. See also Exercises 1.2, 1.3,
and 1.4.
• We use the abbreviation “a.s.” for “almost surely,” that is, with probability 1. We use
“w.p.” for “with probability.”
• Convergence in probability is denoted as →p. Convergence in distribution is denoted
as
d
→.
• For a random variable X and a probability distribution µ, we write X ∼ µ to indicate that
X has distribution µ. We write X
d= Y if the random variables X and Y have the same
distribution.
• For an event A, the random variable 1A is the indicator of A, that is, it is 1 if A occurs and
0 otherwise. We also use 1{A}.
TOTAL • For probability measures µ, ν on a countable set S, their total variation distance is
VARIATION
DISTANCE kµ − νkTV := sup
A⊆S
|µ(A) − ν(A)|.
• For non-negative functions f (n), g(n) of n ∈ Z+, we write f (n) = O(g(n)) if there exists
a positive constant C > 0 such that f (n) ≤ Cg(n) for all n large enough. Similarly,
f (n) = (g(n)) means that f (n) ≥ cg(n) for some constant c > 0 for all n large enough.
The notation f (n) = 2(g(n)) indicates that both f (n) = O(g(n)) and f (n) = (g(n))
hold. We also write f (n) = o(g(n)) or g(n) = ω(f (n)) or f (n)  g(n) or g(n)  f (n) if
f (n)/g(n) → 0 as n → +∞. If f (n)/g(n) → 1 we write f (n) ∼ g(n). The same notations
are used for functions of a real variable x as x → +∞.
Published online by Cambridge University Pres1
Introduction
In this chapter, we describe a few discrete probability models to which we will come back
repeatedly throughout the book. While there exists a vast array of well-studied random com￾binatorial structures (permutations, partitions, urn models, Boolean functions, polytopes,
etc.), our focus is primarily on a limited number of graph-based processes, namely, percola￾tion, random graphs, the Ising model, and random walks on networks. We will not attempt
to derive the theory of these models exhaustively here. Instead, we will employ them to il￾lustrate some essential techniques from discrete probability. Note that the toolkit developed
in this book is meant to apply to other probabilistic models of interest as well, and in fact
many more will be encountered along the way. After a brief review of graph basics and Mar￾kov chains theory in Section 1.1, we formally introduce our main models in Section 1.2. We
also formulate various questions about these models that will be answered (at least partially)
later on. We assume that the reader is familiar with the measure-theoretic foundations of
probability. A refresher of all required concepts and results is provided in Appendix B.
1.1 Background
We start with a brief review of graph terminology and standard countable-space Markov
chains results.
1.1.1 Review of Graph Theory
Basic definitions An undirected graph (or graph for short) is a pair G = (V, E), where V is GRAPH
the set of vertices (or nodes or sites) and
E ⊆ {{u, v}: u, v ∈ V}
is the set of edges (or bonds). See Figure 1.1 for an example. We occasionally write V(G)
and E(G) for the vertices and edges of the graph G. The set of vertices V is either finite or
countably infinite. Edges of the form {u} are called self-loops. In general, we do not allow E
to be a multiset unless otherwise stated. But, when E is a multiset, G is called a multigraph. MULTIGRAPH
A vertex v ∈ V is incident with an edge e ∈ E (or vice versa) if v ∈ e. The incident
vertices of an edge are called endvertices. Two vertices u, v ∈ V are adjacent (or neighbors),
denoted by u ∼ v, if {u, v} ∈ E. The set of adjacent vertices of v, denoted by N(v), is called
the neighborhood of v and its size, that is, δ(v) := |N(v)|, is the degree of v. A vertex v with
δ(v) = 0 is called isolated. A graph is called d-regular if all its degrees are d. A countable
graph is locally finite if all its vertices have a finite degree.
1
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University Press2 Introduction
Figure 1.1 Petersen graph.
Example 1.1.1 (Petersen graph). All vertices in the Petersen graph in Figure 1.1 have degree
3, that is, it is a 3-regular graph. In particular, it has no isolated vertex. J
A convenient (and mathematically useful) way to specify a graph is the following matrix
representation. Assume the graph G = (V, E) has n = |V| vertices. Assume that the ver￾ADJACENCY tices are numbered 1, . . . , n. The adjacency matrix A of G is the n × n symmetric matrix
MATRIX defined as
Axy =
(
1 if {x, y} ∈ E,
0 otherwise.
Example 1.1.2 (Triangle). The adjacency matrix of a triangle, that is, a 3-vertex graph with
all possible non-loop edges, is
A =


0 1 1
1 0 1
1 1 0

 .
J
There exist other matrix representations. Here is one. Let m = |E| and assume that the edges
INCIDENCE are labeled arbitrarily as e1, . . . , em. The incidence matrix of an undirected graph G = (V, E)
MATRIX is the n × m matrix B such that Bij = 1 if vertex i and edge ej are incident and 0 otherwise.
Subgraphs, paths, and cycles A subgraph of G = (V, E) is a graph G
0 = (V
0
, E
0
) with
V
0 ⊆ V and E
0 ⊆ E. Implied in this definition is the fact that the edges in E
0
are incident
only to V
0
. The subgraph G
0
is said to be induced if
E
0 = {{x, y}: x, y ∈ V
0
, {x, y} ∈ E},
that is, it contains exactly those edges of G that are between vertices in V
0
. In that case the
notation G
0
:= G[V
0
] is used. A subgraph is said to be spanning if V
0 = V. A subgraph
CLIQUE containing all possible non-loop edges between its vertices is called a clique (or complete
subgraph). A clique with k nodes is referred to as a k-clique.
Example 1.1.3 (Petersen graph (continued)). The Petersen graph contains no triangle, that
is, 3-clique, induced or not. J
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University Press1.1 Background 3
A walk in G is a sequence of (not necessarily distinct) vertices x0 ∼ x1 ∼ · · · ∼ xk
. Note
the requirement that consecutive vertices of a walk are adjacent. The number k ≥ 0 is the
length of the walk. If the endvertices x0, xk coincide, that is, x0 = xk
, we refer to the walk as
closed. If the vertices of a walk are all distinct, we call it a path (or self-avoiding walk). If the
vertices of a closed walk are all distinct except for the endvertices and its length is at least
3, we call it a cycle. A path or cycle can be seen as a (not necessarily induced) subgraph of
G. The length of the shortest path connecting two distinct vertices u, v is the graph distance GRAPH
between u and v, denoted by d DISTANCE G(u, v). It can be checked that the graph distance is a metric
(and that, in particular, it satisfies the triangle inequality; see Exercise 1.6). The minimum
length of a cycle in a graph is its girth.
We write u ↔ v if there is a path between u and v. It can be checked that the binary relation
↔ is an equivalence relation (i.e., it is reflexive, symmetric, and transitive; see Exercise 1.6).
Its equivalence classes are called connected components. A graph is connected if any two
vertices are linked by a path, that is, if u ↔ v for all u, v ∈ V. Or put differently, if there is
only one connected component.
Example 1.1.4 (Petersen graph (continued)). The Petersen graph is connected. J
Trees A forest is a graph with no cycle, or an acyclic graph. A tree is a connected forest. TREE
Vertices of degree 1 are called leaves. A spanning tree of G is a subgraph which is a tree and
is also spanning. A tree is said to be rooted if it has a single distinguished vertex called the
root.
Trees will play a key role and we collect several important facts about them (mostly
without proofs). The following characterizations of trees will be useful. The proof is left as
an exercise (see Exercise 1.8). We write G + e (respectively G − e) to indicate the graph G
with edge e added (respectively removed).
Theorem 1.1.5 (Trees: characterizations). The following are equivalent.
(i) The graph T is a tree.
(ii) For any two vertices in T, there is a unique path between them.
(iii) The graph T is connected, but T − e is not for any edge e in T.
(iv) The graph T is acyclic, but T + {x, y} is not for any pair of non-adjacent vertices x, y.
Here are two important implications.
Corollary 1.1.6 If G is connected, then it has at least one spanning tree.
Proof Indeed, from Theorem 1.1.5, a graph is a tree if and only if it is minimally connected,
in the sense that removing any of its edges disconnects it. So a spanning tree can be obtained
by removing edges of G that do not disconnect it until it is not possible anymore.
The following characterization is proved in Exercise 1.7.
Corollary 1.1.7 A connected graph with n vertices is a tree if and only if it has n − 1 edges.
And here is a related fact.
Corollary 1.1.8 Let G be a graph with n vertices. If an acyclic subgraph H has n vertices
and n − 1 edges, then it is a spanning tree of G.
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University Press4 Introduction
Proof If H is not connected, then it has at least two connected components. Each of them
is acyclic and therefore a tree. By applying Corollary 1.1.7 to the connected components and
summing up, we see that the total number of edges in H is ≤ n − 2, a contradiction. So H is
connected and therefore a spanning tree.
Finally, a classical formula:
Theorem 1.1.9 (Cayley’s formula). There are kk−2
CAYLEY’S trees on a set of k labeled vertices.
FORMULA
We give a proof of Cayley’s formula based on branching processes in Exercise 6.19.
Some standard graphs Here are a few more examples of finite graphs.
COMPLETE
GRAPH
• Complete graph Kn: This graph is made of n vertices with all possible non-loop edges.
• Cycle graph Cn (or n-cycle): The vertex set is {0, 1, . . . , n − 1} and two vertices i 6= j are
CYCLE GRAPH adjacent if and only if |i − j| = 1 or n − 1.
• Torus L
d
n
: The vertex set is {0, 1, . . . , n − 1}
d
TORUS and two vertices x 6= y are adjacent if and
only if there is a coordinate i such that |xi − yi
| = 1 or n − 1 and all other coordinates
j 6= i satisfy xj = yj
.
• Hypercube Z
n
2
(or n-dimensional hypercube): The vertex set is {0, 1}
n
HYPERCUBE and two vertices
x 6= y are adjacent if and only if kx − yk1 = 1.
• Rooted b-ary tree bT
`
b
: This graph is a tree with ` levels. The unique vertex on level 0 is
called the root. For j = 1, . . . , ` − 1, level j has b
j vertices, each of which has exactly one
neighbor on level j − 1 (its parent) and b neighbors on level j + 1 (its children). The b
`
vertices on level ` are leaves.
INFINITE Here are a few examples of infinite graphs, that is, a graph with a countably infinite number
GRAPH of vertices and edges.
• Infinite d-regular tree Td: This is an infinite tree where each vertex has exactly d neigh￾bors. The rooted version, that is, bT
`
b with ` = +∞ levels, is denoted by bTb.
• Lattice L
d
: The vertex set is Z
d
and two vertices x 6= y are adjacent if and only if
kx − yk1 = 1.
A bipartite graph G = (L ∪ R, E) is a graph whose vertex set is composed of the union
of two disjoint sets L, R and whose edge set E is a subset of {{`,r}: ` ∈ L, r ∈ R}. That is,
there is no edge between vertices in L, and likewise for R.
Example 1.1.10 (Some bipartite graphs). The cycle graph C2n is a bipartite graph. So is
the complete bipartite graph Kn,m with vertex set {`1, . . . , `n} ∪ {r1, . . . ,rm} and edge set
{{`i
,rj}: i ∈ [n], j ∈ [m]}. J
In a bipartite graph G = (L ∪ R, E), a perfect matching is a collection of edges M ⊆ E such
that each vertex is incident to exactly one edge in M.
AUTOMORPHISM An automorphism of a graph G = (V, E) is a bijection φ of V to itself that preserves the
edges, that is, such that {x, y} ∈ E if and only if {φ(x), φ( y)} ∈ E. A graph G = (V, E) is
vertex-transitive if for any u, v ∈ V there is an automorphism mapping u to v.
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University Press1.1 Background 5
Example 1.1.11 (Petersen graph (continued)). For any ` ∈ Z, a (2π`/5)-rotation of
the planar representation of the Petersen graph in Figure 1.1 corresponds to an
automorphism. J
Example 1.1.12 (Trees). The graph Td is vertex-transitive. The graph bT
`
b
on the other hand
has many automorphisms, but is not vertex-transitive. J
Flows Let G = (V, E) be a connected graph with two distinguished disjoint vertex sets, a
source-set (or source for short) A ⊆ V and a sink-set (or sink for short) Z. Let κ : E → R+
be a capacity function.
Definition 1.1.13 (Flow). A flow from source A to sink Z is a function f : V × V → R such FLOW
that:
F1 (Antisymmetry) f (x, y) = −f ( y, x), ∀x, y ∈ V.
F2 (Capacity constraint) | f (x, y)| ≤ κ(e), ∀e = {x, y} ∈ E, and f (x, y) = 0 otherwise.
F3 (Flow-conservation constraint)
X
y:y∼x
f (x, y) = 0, ∀x ∈ V \ (A ∪ Z).
For U, W ⊆ V, let f (U, W) :=
P
u∈U,w∈W
f (u,w). The strength of f is k f k := f (A, A
c
).
One useful consequence of antisymmetry is that, for any U ⊆ V, we have f (U, U) = 0
since each distinct pair x 6= y ∈ U appears exactly twice in the sum, once in each ordering.
Also if W1 and W2 are disjoint, then f (U, W1 ∪ W2) = f (U, W1) + f (U, W2). In particular,
combining both observations, f (U, W) = f (U, W \ U) = −f (W \ U, U).
For F ⊆ E, let κ(F) :=
P
e∈F
κ(e). We call F a cutset separating A and Z (or cutset for
short) if all paths connecting A and Z include an edge in F. For such an F, let AF be the set
of vertices not separated from A by F, that is, vertices from which there is a path to A not
crossing an edge in F. Clearly, A ⊆ AF but AF ∩ Z = ∅.
Lemma 1.1.14 (Max flow ≤ min cut). For any flow f and cutset F,
k f k = f (AF, A
c
F
) ≤
X
{x,y}∈F
| f (x, y)| ≤ κ(F). (1.1.1)
Proof Since F is a cutset, (AF \ A) ∩ (A ∪ Z) = ∅. So, by (F3),
f (A, A
c
) = f (A, A
c
) +
X
u∈AF \A
f (u, V)
= f (A, AF \ A) + f (A, A
c
F
)
+ f (AF \ A, AF) + f (AF \ A, A
c
F
)
= f (A, AF \ A) + f (A, A
c
F
)
+ f (AF \ A, A) + f (AF \ A, A
c
F
)
= f (AF, A
c
F
)
≤
X
{x,y}∈F
| f (x, y)|,
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University Press6 Introduction
where we used (F1) twice. The last line is justified by the fact that the edges between a vertex
in AF and a vertex in A
c
F
have to be in F by definition of AF. That proves the equality and the
first inequality in the claim. Condition (F2) implies the second inequality.
Remarkably, this bound is tight, in the following sense.
Theorem 1.1.15 (Max-flow min-cut theorem). Let G be a finite connected graph with source
A and sink Z, and let κ be a capacity function. Then the following holds
sup{k f k: flow f } = min{κ(F): cutset F}.
Proof Note that, by compactness, the supremum on the left-hand side is achieved. Let f be
an optimal flow. The idea of the proof is to construct a “matching” cutset.
An augmentable path is a path x0 ∼ · · · ∼ xk with x0 ∈ A, xi ∈/ A ∪ Z for all i 6= 0 or k,
and f (xi−1, xi) < κ({xi−1, xi}) for all i 6= 0. By default, each vertex in A is an augmentable
path. Moreover, by the optimality of f there cannot be an augmentable path with xk ∈ Z.
Indeed, otherwise, we could “push more flow through that path” and increase the strength of
f – a contradiction.
Let B ⊆ V be the set of all final vertices in some augmentable path and let F be the edge
set between B and B
c
:= V \ B. Note that, again by contradiction, all vertices in B can be
reached from A without crossing F and that f (x, y) = κ(e) for all e = {x, y} ∈ F with x ∈ B
and y ∈ B
c
. Furthermore, F is a cutset separating A from Z: trivially A ⊆ B; Z ⊆ B
c
as
argued above, and any path from A to Z must exit B and enter B
c
through an edge in F. Thus,
AF = B and we have equality in (1.1.1). That concludes the proof.
COLORING Colorings, independent sets, and matchings A coloring of a graph G = (V, E) is an
assignment of colors to each vertex in G. In a coloring, two vertices may share the same
color. A coloring is proper if for every edge e in G the endvertices of e have distinct colors.
The smallest number of colors in a proper coloring of a graph G is called the chromatic
number χ(G) of G.
INDEPENDENT An independent vertex set (or independent set for short) of G = (V, E) is a subset of
SET vertices W ⊆ V such that all pairs of vertices in W are non-adjacent. Likewise, two edges
MATCHING are independent if they are not incident to the same vertex. A matching is a set of pairwise
independent edges. A matching F is perfect if every vertex in G is incident to an edge of F.
Edge-weighted graphs We refer to an edge-weighted graph G = (V, E,w) as a network.
Here w: E → R+ is a function that assigns positive real weights to the edges. Definitions
can be generalized naturally. In particular, one defines the degree of a vertex i as
δ(i) =
X
j:e={i,j}∈E
we
.
The adjacency matrix A of G is the n × n symmetric matrix defined as
Aij =
(
we
if e = {i, j} ∈ E,
0 otherwise,
where we denote the vertices {1, . . . , n}.
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University Press1.1 Background 7
Directed graphs A directed graph (or digraph for short) is a pair G = (V, E) where V is a DIGRAPH
set of vertices (or nodes or sites) and E ⊆ V
2
is a set of directed edges (or arcs). A directed
edge from x to y is typically denoted by (x, y), or occasionally by hx, yi. A directed path is
a sequence of vertices x0, . . . , xk
, all distinct, with (xi−1, xi) ∈ E for all i = 1, . . . , k. We
write u → v if there is such a directed path with x0 = u and xk = v. We say that u, v ∈ V
communicate, denoted by u ↔ v, if u → v and v → u. In particular, we always have u ↔ u
for every state u. The binary relation ↔ relation is an equivalence relation (see Exercise 1.6).
The equivalence classes of ↔ are called the strongly connected components of G.
The following definition will prove useful.
Definition 1.1.16 (Oriented incidence matrix). Let G = (V, E) be an undirected graph.
Assume that the vertices of G = (V, E) are numbered 1, . . . , |V| and that the edges are
labeled arbitrarily as e1, . . . , e|E|
. An orientation of G is the choice of a direction Eei
for each
edge ei
, turning it into a digraph G. An E oriented incidence matrix of G is the incidence ORIENTED
INCIDENCE
MATRIX
matrix of an orientation, that is, the matrix B such that Bij = −1 if edge Eej
leaves vertex i,
Bij = 1 if edge Eej enters vertex i, and 0 otherwise.
1.1.2 Review of Markov Chain Theory
Informally, a Markov chain (or Markov process) is a time-indexed stochastic process sat- MARKOV
isfying the property: conditioned on the present, the future is independent of the past. We CHAIN
restrict ourselves to the discrete-time, time-homogeneous, countable-space case, where such
a process is characterized by its initial distribution and a transition matrix.
Construction of a Markov chain For our purposes, it will suffice to “define” a Markov
chain through a particular construction. Let V be a finite or countable space. Recall that a
stochastic matrix on V is a non-negative matrix P = (P(i, j))i, j∈V satisfying STOCHASTIC
X
MATRIX
j∈V
P(i, j) = 1, ∀i ∈ V.
We think of P(i, ·) as a probability distribution on V. In particular, for a set of states A ⊆ V,
we let
P(i, A) =
X
j∈A
P(i, j).
Let µ be a probability measure on V and let P be a stochastic matrix on V. One way to
construct a Markov chain (Xt)t≥0 on V with transition matrix P and initial distribution µ is
the following:
• Pick X0 ∼ µ and let (Y(i, n))i∈V,n≥1 be a mutually independent array of random variables
with Y(i, n) ∼ P(i, ·).
• Set inductively Xn := Y(Xn−1, n), n ≥ 1.
So in particular:
P[X0 = x0, . . . , Xt = xt] = µ(x0)P(x0, x1) · · · P(xt−1, xt).
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University Press8 Introduction
We use the notation Px
, Ex for the probability distribution and expectation under the chain
started at x. Similarly for Pµ, Eµ, where µ is a probability distribution.
Example 1.1.17 (Simple random walk on a graph). Let G = (V, E) be a finite or infinite,
SIMPLE locally finite graph. Simple random walk on G is the Markov chain on V, started at an
RANDOM
WALK
ON A GRAPH
arbitrary vertex, which at each time picks a uniformly chosen neighbor of the current state.
(Exercise 1.9 asks for the transition matrix.) J
Markov property Let (Xt)t≥0 be a Markov chain (or chain for short) with transition matrix
P and initial distribution µ. Define the filtration (Ft)t≥0 with Ft = σ(X0, . . . , Xt) (see Appen￾dix B). As mentioned above, the defining property of Markov chains, known as the Markov
property, is that given the present, the future is independent of the past. In its simplest form,
that can be interpreted as P[Xt+1 = y | Ft] = PXt
[Xt+1 = y] = P(Xt
, y). More generally:
Theorem 1.1.18 (Markov property). Let f : V MARKOV
∞ → R be bounded, measurable and let
PROPERTY F(x) := Ex[ f ((Xt)t≥0)], then
E[ f ((Xs+t)t≥0) | Fs] = F(Xs) a.s.
Remark 1.1.19 We will come back to the “strong” Markov property in Chapter 3.
We define P
t
(x, y) := Px[Xt = y]. An important consequence of the Markov property (The￾orem 1.1.18) is the following.
Theorem 1.1.20 (Chapman–Kolmogorov).
P
t
(x,z) =
X
y∈V
P
s
(x, y)P
t−s
( y,z), s ∈ {0, 1, . . . , t}.
Proof This follows from the Markov property. Indeed, note that Px[Xt = z| Fs] = F(Xs)
with F( y) := Py[Xt−s = z] and take Ex on each side.
Example 1.1.21 (Random walk on Z). Let (Xt) be simple random walk on Z interpreted as
a graph (i.e., L) where i ∼ j if |i−j| = 1.1 Then P(0, x) = 1/2 if |x| = 1. And P
2
(0, x) = 1/4
if |x| = 2 and P
2
(0, 0) = 1/2. J
If we write µs for the law of Xs as a row vector, then
µs = µ0P
s
,
where P
s
is the matrix product of P by itself s times. As is conventional in Markov chain
theory, we think of probability distributions over the state space as row vectors. We will
typically denote them by Greek letters (e.g., µ, π).
Stationarity The transition graph of a chain is the directed graph on V whose edges are
IRREDUCIBLE the transitions with strictly positive probability. A chain is irreducible if V is the unique
(strongly) connected component of its transition graph, that is, if all pairs of states have a
directed path between them in the transition graph.
1 On Z, simple random walk often refers to any nearest-neighbor random walk, whereas the example here is
called simple symmetric random walk. We will not adopt this terminology here.
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University Press1.1 Background 9
Example 1.1.22 (Simple random walk on a graph (continued)). Simple random walk on G
is irreducible if and only if G is connected. J
A stationary measure π is a measure on V such that
X
x∈V
π(x)P(x, y) = π( y), ∀y ∈ V,
or in matrix form π = πP. We say that π is a stationary distribution if in addition π is a STATIONARY
probability measure. DISTRIBUTION
Example 1.1.23 (Random walk on Z
d
). The all-one measure π ≡ 1 is stationary for simple
random walk on L
d
. J
Finite, irreducible chains always have a unique stationary distribution.
Theorem 1.1.24 (Existence and uniqueness: finite case). If P is irreducible and has a finite
state space, then:
(i) (Existence) it has a stationary distribution which, furthermore, is strictly positive;
(ii) (Uniqueness) the stationary distribution is unique.
This result follows from Perron–Frobenius theory (a version of which is stated as Theo￾rem 6.1.17). We give a self-contained proof.
Proof of Theorem 1.1.24 (i) We begin by proving existence. Denote by n the number of
states. Because P is stochastic, we have by definition that P1 = 1, where 1 is the all-one
vector. Put differently,
(P − I)1 = 0.
In particular, the columns of P − I are linearly dependent, that is, the rank of P − I is < n.
That, in turn, implies that the rows of P−I are linearly dependent since row rank and column
rank are equal. Hence, there exists a non-zero row vector z ∈ R
n
such that z(P − I) = 0, or
after rearranging,
zP = z. (1.1.2)
The rest of the proof is broken up into a series of lemmas. To take advantage of irre￾ducibility, we first construct a positive stochastic matrix with z as a left eigenvector with
eigenvalue 1. We then show that all entries of z have the same sign. Finally, we normalize z.
Lemma 1.1.25 (Existence: Step 1). There exists a non-negative integer h such that
R =
1
h + 1
[I + P + P
2 + · · · + P
h
]
is a stochastic matrix with strictly positive entries which satisfies
zR = z. (1.1.3)
Lemma 1.1.26 (Existence: Step 2). The entries of z are either all non-negative or all non￾positive.
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University Press10 Introduction
Lemma 1.1.27 (Existence: Step 3). Let
π =
z
z1
.
Then π is a strictly positive stationary distribution.
We denote the entries of R and P
s by Rx,y and P
s
x,y
, x, y = 1, . . . , n, respectively.
Proof of Lemma 1.1.25 By irreducibility (see Exercise 1.10), for any x, y ∈ [n] there is hxy
such that P
hxy
x,y > 0. Now define
h = max
x,y∈[n]
hxy.
The matrix P
s
, as a product of stochastic matrices, is a stochastic matrix for all s (see Exer￾cise 1.11). In particular, it has non-negative entries. Hence, for each x, y,
Rx,y =
1
h + 1
[Ix,y + Px,y + P
2
x,y + · · · + P
h
x,y
]
≥
1
h + 1
P
hx,y
x,y > 0.
Moreover, the matrix R, as a convex combination of stochastic matrices, is a stochastic ma￾trix (see Exercise 1.11).
Since zP = z, it follows by induction that zP
s = z for all s. Therefore,
zR =
1
h + 1
[zI + zP + zP
2 + · · · + zP
h
]
=
1
h + 1
[z + z + z + · · · + z]
= z.
That concludes the proof.
Proof of Lemma 1.1.26 We argue by contradiction. Suppose that two entries of z = (z1, . . . ,
zn) have different signs, say zi > 0, while zj < 0. By the previous lemma, Rx,y > 0 for all
x, y. Therefore,
|zy
| =





X
x
zxRx,y





=





X
x:zx≥0
zxRx,y +
X
x:zx<0
zxRx,y





.
The first term on the last line is strictly positive (since it is at least ziRi,y > 0), while the sec￾ond term is strictly negative (since it is at most zjRj,y < 0). Hence, because of cancellations
(see Exercise 1.13), the expression above is strictly smaller than the sum of the absolute
values, that is,
|zy
| <
X
x
|zx
|Rx,y
.
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University Press1.1 Background 11
Since R is stochastic by the previous lemma, we deduce after summing over y that
X
y
|zy
| <
X
y
X
x
|zx
|Rx,y =
X
x
|zx
|
X
y
Rx,y =
X
x
|zx
|,
a contradiction, thereby proving the claim.
Proof of Lemma 1.1.27 Now define π entrywise by
πx = P
zx
i
zi
=
|zx
|
P
i
|zi
|
≥ 0,
where the second equality comes from the previous lemma. We also used the fact that z 6= 0.
For all y, by definition of z,
X
x
πxPx,y =
X
x
P
zx
i
zi
Px,y =
1
P
i
zi
X
x
zxPx,y = P
zy
i
zi
= πy
.
The same holds with Px,y replaced by Rx,y from (1.1.3). Since Rx,y > 0 and z 6= 0, it follows
that πy > 0 for all y. That proves the claim.
That concludes the proof of the existence claim.
It remains to prove uniqueness. See Exercise 1.14 for an alternative proof based on the
maximum principle (to which we come back in Theorem 3.3.9 and Exercise 3.12).
Proof of Theorem 1.1.24 (ii) Suppose there are two distinct stationary distributions π1 and
π2 (which must be strictly positive). Since they are distinct, they are not a multiple of each
other and therefore are linearly independent. Apply the Gram–Schmidt procedure:
q1 =
π1
kπ1k2
and q2 =
π2 − hπ2, q1iq1
kπ2 − hπ2, q1iq1k2
.
Then
q1P =
π1
kπ1k2
P =
π1P
kπ1k2
=
π1
kπ1k2
= q1,
and all entries of q1 are strictly positive.
Similarly,
q2P =
π2 − hπ2, q1iq1
kπ2 − hπ2, q1iq1k2
P
=
π2P − hπ2, q1iq1P
kπ2 − hπ2, q1iq1k2
=
π2 − hπ2, q1iq1
kπ2 − hπ2, q1iq1k2
= q2.
Since z := q2 satisfies (1.1.2), by Lemmas 1.1.25–1.1.27 there is a multiple of q2, say
q
0
2 = αq2 with α 6= 0, such that q
0
2P = q
0
2
and all entries of q
0
2
are strictly positive. By the
Gram–Schmidt procedure,
hq1, q
0
2
i = hq1, αq2i = αhq1, q2i = 0.
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University Press12 Introduction
But this is a contradiction since both vectors are strictly positive. That concludes the proof
of the uniqueness claim.
REVERSIBLE Reversibility A transition matrix P is reversible with respect to (w.r.t.) a measure η if
η(x)P(x, y) = η( y)P( y, x)
for all x, y ∈ V. These equations are known as detailed balance. Here is the key observation:
by summing over y and using the fact that P is stochastic, such a measure is necessarily
stationary. (Exercise 1.12 explains the name.)
Example 1.1.28 (Random walk on Z
d
(continued)). The measure η ≡ 1 is reversible for
simple random walk on L
d
. J
Example 1.1.29 (Simple random walk on a graph (continued)). Let (Xt) be simple random
walk on a connected graph G = (V, E). Then (Xt) is reversible with respect to η(v) := δ(v),
where recall that δ(v) is the degree of v. Indeed, for all {u, v} ∈ E,
δ(u)P(u, v) = δ(u)
1
δ(u)
= 1 = δ(v)
1
δ(v)
= δ(v)P(v, u).
(See Exercise 1.9 for the transition matrix of simple random walk on a graph.) J
METROPOLIS Example 1.1.30 (Metropolis chain). The Metropolis algorithm modifies an irreducible,
ALGORITHM symmetric (i.e., whose transition matrix is a symmetric matrix) chain Q to produce a new
chain P with the same transition graph and a prescribed positive stationary distribution π.
The idea is simple. For each pair x 6= y, either we multiply Q(x, y) by π( y)/π(x) and leave
Q( y, x) intact or vice versa. Detailed balance immediately follows. To ensure that the new
transition matrix remains stochastic, for each pair we make the choice that lowers the transi￾tion probabilities; then we add the lost probability to the diagonal (i.e., to the probability of
staying put).
Formally, the definition of the new chain is
P(x, y) :=



Q(x, y)
h
π( y)
π(x)
∧ 1
i
if x 6= y,
1 −
P
z6=x Q(x,z)
h
π(z)
π(x)
∧ 1
i
otherwise.
Note that, by definition of P and the fact that Q is stochastic, we have P(x, y) ≤ Q(x, y) for
all x 6= y, so
X
y6=x
P(x, y) ≤ 1,
and hence P is well defined as a transition matrix. We claim further that P is reversible with
respect to π. Suppose x 6= y, and assume without loss of generality that π(x) ≥ π( y). Then,
by definition of P, we have
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University Press1.1 Background 13
π(x)P(x, y) = π(x)Q(x, y)
π( y)
π(x)
= Q(x, y)π( y)
= Q( y, x)π( y)
= P( y, x)π( y),
where we used the symmetry of Q. J
Convergence and mixing time A key property of Markov chains is that, under suitable as￾sumptions, they converge to a stationary regime. We need one more definition before stating
the theorem. A chain is said to be aperiodic if, for all x ∈ V, the greatest common divisor of APERIODIC
{t: P
t
(x, x) > 0} is 1.
Example 1.1.31 (Lazy random walk on a graph). The lazy simple random walk on G is the LAZY
Markov chain such that, at each time, it stays put with probability 1/2 or chooses a uniformly
random neighbor of the current state otherwise. Such a chain is aperiodic. J
Lemma 1.1.32 (Consequence of aperiodicity). If P is aperiodic, irreducible, and has a finite
state space, then there is a positive integer t0 such that for all t ≥ t0 the matrix Pt has strictly
positive entries.
We can now state the convergence theorem. For probability measures µ, ν on V, their total TOTAL
VARIATION
DISTANCE
variation distance is
kµ − νkTV := sup
A⊆V
|µ(A) − ν(A)|. (1.1.4)
Theorem 1.1.33 (Convergence theorem). Suppose P is irreducible, aperiodic, and has sta￾tionary distribution π. Then, for all x,
kP
t
(x, ·) − π(·)kTV → 0,
as t → +∞.
We give a proof in the finite case in Example 4.3.3. In particular, the convergence theorem
implies that for all x, y,
P
t
(x, y) → π( y).
Without aperiodicity, we have the weaker claim
1
t
Xt
s=1
P
s
(x, y) → π( y), (1.1.5)
as t → +∞.
We will be interested in quantifying the speed of convergence in Theorem 1.1.33. For this
purpose, we define
d(t) := sup
x∈V
kP
t
(x, ·) − π(·)kTV. (1.1.6)
Lemma 1.1.34 (Monotonicity of d(t)). The function d(t) is non-increasing in t.
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University Press14 Introduction
Proof Note that, by definition of P
t+1
,
d(t + 1) = sup
x∈V
sup
A⊆V
|P
t+1
(x, A) − π(A)|
= sup
x∈V
sup
A⊆V





X
z
P(x,z)(P
t
(z, A) − π(A))





≤ sup
x∈V
X
z
P(x,z) sup
A⊆V
|P
t
(z, A) − π(A)|
≤ sup
z∈V
sup
A⊆V
|P
t
(z, A) − π(A)|
= d(t),
where on the second and fourth line we used that P is a stochastic matrix.
The following concept will play a key role.
MIXING TIME Definition 1.1.35 (Mixing time). For a fixed ε > 0, the mixing time is defined as
tmix(ε) := inf{t ≥ 0: d(t) ≤ ε}.
1.2 Some Discrete Probability Models
With the necessary background covered, we are now in a position to define formally a few
important discrete probability models that will be ubiquitous in this book. These are all
graph-based processes. Many more interesting random discrete structures and other related
probabilistic models will be encountered throughout (and defined where needed).
Percolation Percolation processes are meant to model the movement of a fluid through
a porous medium. There are several types of percolation models. We focus here on bond
percolation. In words, edges of a graph are “open” at random, indicating that fluid is passing
through. We are interested in the “open clusters,” that is, the regions reached by the fluid.
BOND Definition 1.2.1 (Bond percolation). Let G = (V, E) be a finite or infinite graph. The bond
PERCOLATION percolation process on G with density p ∈ [0, 1], whose measure is denoted by Pp, is defined
as follows: each edge of G is independently set to open with probability p, otherwise it is set
to closed. Write x ⇔ y if x, y ∈ V are connected by a path all of whose edges are open. The
open cluster of x is
Cx
:= {y ∈ V : x ⇔ y}.
We will mostly consider bond percolation on the infinite graphs L
d or Td. The main question
we will ask is: For which values of p is there an infinite open cluster?
Random graphs Random graphs provide a natural framework to study complex networks.
Different behaviors are observed depending on the modeling choices made. Perhaps the
simplest and most studied is the Erdos–Rényi random graph model. We consider the version ˝
due to Gilbert. Here the edges are present independently with a fixed probability. Despite its
simplicity, this model exhibits a rich set of phenomena that make it a prime example for the
use of a variety of probabilistic techniques.
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University Press1.2 Some Discrete Probability Models 15
Definition 1.2.2 (Erdos–Rényi graph model). ˝ Let n ∈ N and p ∈ [0, 1]. Set V := [n]. Under
the Erdos–Rényi graph model on ˝ n vertices with density p, a random graph G = (V, E) is ERDOS˝ –RÉNYI
generated as follows: for each pair x 6= y in V, the edge {x, y} is in E with probability GRAPH MODEL
p independently of all other edges. We write G ∼ Gn,p and we denote the corresponding
measure by Pn,p.
Typical questions regarding the Erdos–Rényi graph model (and random graphs more gen- ˝
erally) include: How are degrees distributed? Is G connected? What is the (asymptotic)
probability of observing a particular subgraph, for example, a triangle? What is the typical
chromatic number?
As one alternative to the Erdos–Rényi model, we will also encounter preferential attach- ˝
ment graphs. These are meant to model the growth of a network where new edges are more
likely to be incident with vertices of high degree, a reasonable assumption in some ap￾plied settings. Such a process produces graphs with properties that differ from those of the
Erdos–Rényi model; in particular, they tend to have a “fatter” degree distribution tail. In ˝
the definition of preferential attachment graphs, we restrict ourselves to the tree case (see
Exercise 1.15).
Definition 1.2.3 (Preferential attachment graph). The preferential attachment graph process PREFERENTIAL
ATTACHMENT
GRAPHS
produces a sequence of graphs (Gt)t≥1 as follows: we start at time 1 with two vertices, de￾noted v0 and v1, connected by an edge. At time t, we add vertex vt with a single edge connect￾ing it to an old vertex, which is picked proportionally to its degree. We write (Gt)t≥1 ∼ PA1.
Markov random fields Another common class of graph-based processes involves the as￾signment of random “states” to the vertices of a fixed graph. The state distribution is typi￾cally specified through “interactions between neighboring vertices.” Such models are widely
studied in statistical physics and also have important applications in statistics. We focus on
models with a Markovian (i.e., conditional independence) structure that makes them particu￾larly amenable to rigorous analysis and computational methods. We start with Gibbs random
fields, a broad class of such models.
Definition 1.2.4 (Gibbs random field). Let S be a finite set and let G = (V, E) be a finite
graph. Denote by K the set of all cliques of G. A positive probability measure µ on X := S
V
is called a Gibbs random field if there exist clique potentials φK : S
K → R, K ∈ K, such GIBBS
RANDOM
FIELD
that
µ(x) =
1
Z
exp X
K∈K
φK(xK)
!
,
where xK is x restricted to the vertices of K and Z is a normalizing constant.
The following example introduces the primary Gibbs random field we will encounter.
Example 1.2.5 (Ising model). For β > 0, the (ferromagnetic) Ising model with inverse ISING MODEL
temperature β is the Gibbs random field with S := {−1, +1}, φ{i, j}(σ{i, j}) = βσiσj and
φK ≡ 0 if |K| 6= 2. The function H(σ) := −P
{i,j}∈E
σiσj
is known as the Hamiltonian.
The normalizing constant Z := Z(β) is called the partition function. The states (σi)i∈V are
referred to as spins. J
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University Press16 Introduction
Typical questions regarding Ising models include: How fast is correlation decaying down
the graph? How well can one guess the state at an unobserved vertex? We will also consider
certain Markov chains related to Ising models (see Definition 1.2.8).
Random walks on graphs and reversible Markov chains The last class of processes we
focus on are random walks on graphs and their generalizations. Recall the following defini￾tion.
SIMPLE Definition 1.2.6 (Simple random walk on a graph). Let G = (V, E) be a finite or countable,
RANDOM
WALK ON A
GRAPH
locally finite graph. Simple random walk on G is the Markov chain on V, started at an
arbitrary vertex, which at each time picks a uniformly chosen neighbor of the current state.
We generalize the definition by adding weights to the edges. In this context, we denote edge
weights by c(e) for “conductance” (see Section 3.3).
RANDOM Definition 1.2.7 (Random walk on a network). Let G = (V, E) be a finite or countably
WALK ON A
NETWORK
infinite graph. Let c: E → R+ be a positive edge weight function on G. Recall that we call
N = (G, c) a network. We assume that for all u ∈ V,
c(u) :=
X
e={u,v}∈E
c(e) < +∞.
Random walk on network N is the Markov chain on V, started at an arbitrary vertex, which
at each time picks a neighbor of the current state proportionally to the weight of the corre￾sponding edge. That is, the transition matrix is given by
P(u, v) =
(
c({u,v})
c(u)
if {u, v} ∈ E,
0 otherwise.
By definition of P, it is immediate that this Markov chain is reversible with respect to the
measure η(u) := c(u). In fact, conversely, any countable reversible Markov chain can be
seen as a random walk on a network by setting c(e) := π(x)P(x, y) = π( y)P( y, x) for all x, y
such that P(x, y) > 0.
Typical questions include: How long does it take to visit all vertices at least once or a
particular subset of vertices for the first time? How fast does the walk approach stationarity?
How often does the walk return to its starting point?
We will also encounter a particular class of Markov chains related to Ising models, the
Glauber dynamics.
GLAUBER Definition 1.2.8 (Glauber dynamics of the Ising model). Let µβ be the Ising model with
DYNAMICS inverse temperature β > 0 on a graph G = (V, E). The (single-site) Glauber dynamics is
the Markov chain on X := {−1, +1}
V
, which at each time
• selects a site i ∈ V uniformly at random, and
• updates the spin at i according to µβ conditioned on agreeing with the current state at all
sites in V\{i}.
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University PressExercises 17
Specifically, for γ ∈ {−1, +1}, i ∈ V, and σ ∈ X , let σ
i,γ be the configuration σ with
the spin at i being set to γ . Let n = |V| and Si(σ) :=
P
j∼i
σj
. The non-zero entries of the
transition matrix are
Qβ (σ, σ
i,γ
) :=
1
n
·
e
γβSi(σ)
e
−βSi(σ) + e
βSi(σ)
.
This chain is irreducible since we can flip each site one by one to go from any state to
any other state. It is straightforward to check that Qβ (σ, σ
i,γ
) is a stochastic matrix. The next
theorem shows that µβ is its stationary distribution.
Theorem 1.2.9 The Glauber dynamics is reversible with respect to µβ .
Proof For all σ ∈ X and i ∈ V, let
S6=i(σ) := H(σ
i,+
) + Si(σ) = H(σ
i,−
) − Si(σ).
We have
µβ (σ
i,−
) Qβ (σ
i,−
, σ
i,+
) =
e
−βS6=i(σ)
e
−βSi(σ)
Z(β)
·
e
βSi(σ)
n[e
−βSi(σ) + e
βSi(σ)
]
=
e
−βS6=i(σ)
nZ(β)[e
−βSi(σ) + e
βSi(σ)
]
=
e
−βS6=i(σ)
e
βSi(σ)
Z(β)
·
e
−βSi(σ)
n[e
−βSi(σ) + e
βSi(σ)
]
= µβ (σ
i,+
) Qβ (σ
i,+
, σ
i,−
).
That concludes the proof.
Exercises
Exercise 1.1 (0-norm). Show that kuk0 does not define a norm.
Exercise 1.2 (A factorial bound: one way). Let ` be a positive integer.
(i) Use the bound 1 + x ≤ e
x
to show that
k + 1
k
≤ e
1/k
and
k
k + 1
≤ e
1/(k+1)
for all positive integers k.
(ii) Use part (i) and the quantity
Y
`−1
k=1
(k + 1)k
k
k
to show that
`! ≥
`
`
e
`−1
.
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University Press18 Introduction
(iii) Use part (i) and the quantity
Y
`−1
k=1
k
k+1
(k + 1)k+1
to show that
`! ≤
`
`+1
e
`−1
.
Exercise 1.3 (A factorial bound: another way). Let ` be a positive integer. Show that
`
`
e
`−1
≤ `! ≤
`
`+1
e
`−1
by considering the logarithm of `!, interpreting the resulting quantity as a Riemann sum, and
bounding above and below by an integral.
Exercise 1.4 (A binomial bound). Show that for integers 0 < d ≤ n,
X
d
k=0

n
k

≤
en
d
d
.
(Hint: Multiply the left-hand side of the inequality by (d/n)
d ≤ (d/n)
k
and use the binomial
theorem.)
Exercise 1.5 (Powers of the adjacency matrix). Let A
n be the nth matrix power of the adja￾cency matrix A of a graph G = (V, E). Prove that the (i, j)th entry a
n
ij is the number of walks
of length exactly n between vertices i and j in G. (Hint: Use induction on n.)
Exercise 1.6 (Paths). Let u, v be vertices of a graph G = (V, E).
(i) Show that the graph distance dG(u, v) is a metric.
(ii) Show that the binary relation u ↔ v is an equivalence relation.
(iii) Prove (ii) in the directed case.
Exercise 1.7 (Trees: number of edges). Prove that a connected graph with n vertices is a
tree if and only if it has n−1 edges. (Hint: Proceed by induction. Then use Corollary 1.1.6.)
Exercise 1.8 (Trees: characterizations). Prove Theorem 1.1.5.
Exercise 1.9 (Simple random walk on a graph). Let (Xt)t≥0 be simple random walk on a
finite graph G = (V, E). Suppose the vertex set is V = [n]. Write down an expression for
the transition matrix of (Xt).
Exercise 1.10 (Communication lemma). Let (Xt) be a finite Markov chain. Show that if
x → y, then there is an integer r ≥ 1 such that
P[Xr = y | X0 = x] = (P
r
)x,y > 0.
Exercise 1.11 (Stochastic matrices from stochastic matrices). Let
P
(1)
, P
(2)
, . . . , P
(r) ∈ R
n×n
,
be stochastic matrices.
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University PressExercises 19
(i) Show that P
(1)P
(2) is a stochastic matrix. That is, a product of stochastic matrices is a
stochastic matrix.
(ii) Show that for any α1, . . . , αr ∈ [0, 1] with Pr
i=1 αi = 1,
Xr
i=1
αiP
(i)
is stochastic. That is, a convex combination of stochastic matrices is a stochastic ma￾trix.
Exercise 1.12 (Reversing time). Let (Xt) be a finite Markov chain with transition matrix P.
Assume P is reversible with respect to a probability distribution π. Assume that the initial
distribution is π. Show that for any sequence of states z0, . . . ,zs
, the reversed sequence has
the same probability, that is,
P[Xs = z0, . . . , X0 = zs] = P[Xs = zs
, . . . , X0 = z0].
Exercise 1.13 (A strict inequality). Let a, b ∈ R with a < 0 and b > 0. Show that
|a + b| < |a| + |b|.
(Hint: Consider the cases a + b ≥ 0 and a + b < 0 separately.)
Exercise 1.14 (Uniqueness: maximum principle). Let P = (Pi, j)
n
i, j=1 ∈ R
n be a transition
matrix.
(i) Let α1, . . . , αm > 0 such that Pm
i=1 αi = 1. Let x = (x1, . . . , xm) ∈ R
n
. Show that
Xm
i=1
αixi ≤ max
i
xi
,
and that equality holds if and only if x1 = x2 = · · · = xm.
(ii) Let 0 6= y ∈ R
n be a right eigenvector of P with eigenvalue 1, that is, Py = y. Assume
that y is not a constant vector, that is, there is i 6= j such that yi 6= yj
. Let k be such that
yk = maxi∈[n] yi
. Show that for any ` such that Pk,` > 0, we necessarily have y` = yk
.
(Hint: Use that yk =
Pn
i=1 Pk,iyi and apply (i).)
(iii) Assume that P is irreducible. Let 0 6= y ∈ R
n
again be a right eigenvector of P with
eigenvalue 1. Use (ii) to show that y is necessarily a constant vector.
(iv) Use (iii) to conclude that the dimension of the null space of P
T − I is exactly 1. (Hint:
Use the Rank–Nullity Theorem.)
Exercise 1.15 (Preferential attachment trees). Let (Gt)t≥1 ∼ PA1 as in Definition 1.2.3.
Show that Gt
is a tree with t + 1 vertices for all t ≥ 1.
Exercise 1.16 (Warm-up: a little calculus). Prove the following inequalities which we will
encounter throughout. (Hint: Basic calculus should do.)
(i) Show that 1 − x ≤ e
−x
for all x ∈ R.
(ii) Show that 1 − x ≥ e
−x−x
2
for x ∈ [0, 1/2].
(iii) Show that log(1 + x) ≤ x − x
2
/4 for x ∈ [0, 1].
(iv) Show that log x ≤ x − 1 for all x ∈ R+.
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University Press20 Introduction
(v) Show that cos x ≤ e
−x
2
/2
for x ∈ [0, π/2). (Hint: Consider the function h(x) =
log(e
x
2
/2
cos x) and recall that the derivative of tan x is 1 + tan2
x.)
Bibliographic Remarks
Section 1.1 For an introduction to graphs, see, for example, [Die10] or [Bol98]. Four dif￾ferent proofs of Cayley’s formula are detailed in the delightful [AZ18]. Markov chain theory
is covered in detail in [Dur10, chapter 6]. For a more gentle introduction, see, for exam￾ple, [Dur12, chapter 1], [Nor98, chapter 1], or [Res92, chapter 2].
Section 1.2 For book-length treatments of percolation theory, see [BR06a, Gri10b]. The
version of the Erdos–Rényi random graph model we consider here is due to Gilbert [ ˝ Gil59].
For much deeper accounts of the theory of random graphs and related processes, see, for
example, [Bol01, Dur06, JLR11, vdH17, FK16]. Two standard references on finite Markov
chains and mixing times are [AF, LPW06].
https://doi.org/10.1017/9781009305129.002 Published online by Cambridge University Press2
Moments and Tails
In this chapter, we look at the moments of a random variable. Specifically, we demonstrate
that moments capture useful information about the tail of a random variable while often be￾ing simpler to compute or at least bound. Several well-known inequalities quantify this intui￾tion. Although they are straightforward to derive, such inequalities are surprisingly powerful.
Through a range of applications, we illustrate the utility of controlling the tail of a random
variable, typically by allowing one to dismiss certain “bad events” as rare. We begin in
Section 2.1 by recalling the classical Markov and Chebyshev inequalities. Then we discuss
three of the most fundamental tools in discrete probability and probabilistic combinatorics.
In Sections 2.2 and 2.3, we derive the complementary first and second moment methods, and
give several standard applications, especially to threshold phenomena in random graphs and
percolation. In Section 2.4, we develop the Chernoff–Cramér method, which relies on the
moment-generating function and is the building block for a large class of tail bounds. Two
key applications in data science are briefly introduced: sparse recovery and empirical risk
minimization.
2.1 Background
We start with a few basic definitions and standard inequalities. See Appendix B for a re￾fresher on random variables and their expectation.
2.1.1 Definitions
Moments As a quick reminder, let X be a random variable with E|X|
k < +∞ for some
non-negative integer k. In that case we write X ∈ L
k
. Recall that the quantities E[X
k
] and
E[(X −E X)
k
], which are well defined when X ∈ L
k
, are called, respectively, the kth moment
and kth central moment of X. The first moment and the second central moment are known MOMENTS
as the mean and variance, the square root of which is the standard deviation. A random
variable is said to be centered if its mean is 0. Recall that for a non-negative random variable
X, the kth moment can be expressed as
E[X
k
] =
Z +∞
0
k xk−1P [X > x] dx. (2.1.1)
The moment-generating function (or exponential moment) of X is the function MOMENT￾GENERATING
MX (s) := E FUNCTION 
e
sX 
,
21
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press22 Moments and Tails
defined for all s ∈ R where it is finite, which includes at least s = 0. If MX (s) is defined on
(−s0,s0) for some s0 > 0, then X has finite moments of all orders, for any k ∈ Z,
d
k
ds
MX (s) = E

X
k
e
sX 
, (2.1.2)
and the following expansion holds
MX (s) =
X
k≥0
s
k
k!
E[X
k
], |s| < s0.
The moment-generating function plays nicely with sums of independent random variables.
Specifically, if X1 and X2 are independent random variables with MX1
and MX2 defined over
a joint interval (−s0,s0), then for s in that interval,
MX1+X2
(s) = E

e
s(X1+X2)

= E

e
sX1 e
sX2

= E

e
sX1

E

e
sX2

= MX1
(s)MX2
(s), (2.1.3)
where we used independence in the third equality.
One more piece of notation: if A is an event and X ∈ L
1
, then we use the shorthand
E[X; A] = E[X1A].
TAIL Tails We refer to a probability of the form P[X ≥ x] as an upper tail (or right tail) prob￾ability. Typically, x is (much) greater than the mean or median of X. Similarly, we refer to
P[X ≤ x] as a lower tail (or left tail) probability. Our general goal in this chapter is to bound
tail probabilities using moments and moment-generating functions.
Tail bounds arise naturally in many contexts, as events of interest can often be framed
in terms of a random variable being unusually large or small. Such probabilities are often
hard to compute directly however. As we will see in this chapter, moments offer an effective
means to control tail probabilities for two main reasons: (i) moments contain information
about the tails of a random variable, as (2.1.1) makes explicit for instance; and (ii) they are
typically easier to compute – or, at least, to approximate.
As we will see, tail bounds are also useful to study the maximum of a collection of random
variables.
2.1.2 Basic Inequalities
Markov’s inequality Our first bound on the tail of a random variable is Markov’s inequality.
In words, for a non-negative random variable, the heavier the tail, the larger the expectation.
This simple inequality is in fact a key ingredient in more sophisticated tail bounds, as we
will see.
MARKOV’S Theorem 2.1.1 (Markov’s inequality). Let X be a non-negative random variable. Then, for
INEQUALITY all b > 0,
P[X ≥ b] ≤
E X
b
. (2.1.4)
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.1 Background 23
Figure 2.1 Proof of Markov’s inequality: taking expectations of the two functions
depicted in the figure yields the inequality.
Proof
E X ≥ E[X; X ≥ b] ≥ E[b; X ≥ b] = b P[X ≥ b].
See Figure 2.1 for a proof by picture. Note that this inequality is non-trivial only when
b > E X.
Chebyshev’s inequality An application of Markov’s inequality (Theorem 2.1.1) to |X−E X|
2
gives a classical tail bound featuring the second moment of a random variable.
Theorem 2.1.2 (Chebyshev’s inequality). Let X be a random variable with E X
2 < +∞. CHEBYSHEV’S
Then, for all β > 0, INEQUALITY
P[|X − E X| > β] ≤
Var[X]
β
2
. (2.1.5)
Proof This follows immediately by applying (2.1.4) to |X − E X|
2 with b = β
2
.
Of course, this bound is non-trivial only when β is larger than the standard deviation. Re￾sults of this type that quantify the probability of deviating from the mean are referred to
as concentration inequalities. Chebyshev’s inequality is perhaps the simplest instance – we CONCENTRATION
will derive many more. To bound the variance, the following standard formula is sometimes INEQUALITIES
useful:
Var "Xn
i=1
Xi
#
=
Xn
i=1
Var[Xi] + 2
X
i<j
Cov[Xi
, Xj], (2.1.6)
where we recall that the covariance of Xi and Xj
is COVARIANCE
Cov[Xi
, Xj] := E[XiXj] − E[Xi] E[Xj].
When Xi and Xj are independent, then Cov[Xi
, Xj] = 0.
Example 2.1.3 Let X be a Gaussian random variable with mean µ and variance σ
2
, that is, GAUSSIAN
whose density is
fX (x) =
1
√
2πσ2
exp
−
(x − µ)
2
2σ
2

, x ∈ R.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press24 Moments and Tails
Figure 2.2 Comparison of the Markov and Chebyshev inequalities: the squared
deviation from the mean (solid) gives a better approximation of the indicator
function (dotted) close to the mean than the absolute deviation (dashed).
We write X ∼ N(µ, σ
2
). A direct computation shows that E|X−µ| = σ
q
2
π
. Hence Markov’s
inequality gives
P[|X − µ| ≥ b] ≤
E|X − µ|
b
=
r
2
π
·
σ
b
,
while Chebyshev’s inequality (Theorem 2.1.2) gives
P[|X − µ| ≥ b] ≤
σ
b
2
.
Hence, for b large enough, Chebyshev’s inequality produces a stronger bound. See Figure 2.2
for some insight. J
UNIFORM Example 2.1.4 (Coupon collector’s problem). Let (Xt)t∈N be i.i.d. uniform random variables
over [n], that is, that are equally likely to take any value in [n]. Let Tn,i be the first time that i
elements of [n] have been picked, that is,
Tn,i = inf{t ≥ 1: |{X1, . . . , Xt}| = i},
with Tn,0 := 0. We prove that the time it takes to pick all elements at least once – or “collect
COUPON each coupon” – has the following tail. For any ε > 0, we have as n → +∞:
COLLECTOR
Claim 2.1.5
P








Tn,n − n
Xn
j=1
j
−1






≥ ε n log n

 → 0.
To prove this claim we note that the time elapsed between Tn,i−1 and Tn,i
, which we denote by
τn,i
:= Tn,i − Tn,i−1, is geometric with success probability 1 −
i−1
n
. And all τn,is are independ￾GEOMETRIC ent. Recall that a geometric random variable Z with success probability p has probability
mass function P[Z = z] = (1 − p)
z−1p for z ∈ N and has mean 1/p and variance (1 − p)/p
2
.
So, the expectation and variance of Tn,n =
Pn
i=1
τn,i are
E[Tn,n] =
Xn
i=1

1 −
i − 1
n
−1
= n
Xn
j=1
j
−1 = 2(n log n) (2.1.7)
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.2 First Moment Method 25
and
Var[Tn,n] ≤
Xn
i=1

1 −
i − 1
n
−2
= n
2Xn
j=1
j
−2 ≤ n
2X
+∞
j=1
j
−2 = 2(n
2
). (2.1.8)
So by Chebyshev’s inequality
P








Tn,n − n
Xn
j=1
j
−1






≥ ε n log n

 ≤
Var[Tn,n]
(ε n log n)
2
≤
n
2 P+∞
j=1
j
−2
(ε n log n)
2
→ 0,
by (2.1.7) and (2.1.8). J
A classical implication of Chebyshev’s inequality is (a version of) the law of large num￾bers. Recall that a sequence of random variables (Xn)n≥1 converges in probability to a random
variable X, denoted by Xn →p X, if for all ε > 0,
lim
n→+∞
P[|Xn − X| ≥ ε] → 0.
Theorem 2.1.6 (L
2 weak law of large numbers). Let X1, X2, . . . be uncorrelated random vari- UNCORRELATED
ables, that is, E[XiXj] = E[Xi] E[Xj] for i 6= j, with E[Xi] = µ < +∞ and supi Var[Xi] <
+∞. Then
1
n
X
k≤n
Xk →p µ.
See Exercise 2.5 for a proof. When the Xk s are i.i.d. and integrable (but not necessarily
square integrable), convergence is almost sure. That result, the strong law of large numbers,
also follows from Chebyshev’s inequality (and other ideas), but we will not prove it here.
2.2 First Moment Method
In this section, we develop some techniques based on the first moment. Recall that the ex￾pectation of a random variable has an elementary, yet handy, property: linearity. That is, if
random variables X1, . . . , Xk defined on a joint probability space have finite first moments,
then
E[X1 + · · · + Xk ] = E[X1] + · · · + E[Xk ] (2.2.1)
without any further assumption. In particular, linearity holds whether or not the Xis are
independent.
2.2.1 The Probabilistic Method
A key technique of probabilistic combinatorics is the so-called probabilistic method. The
idea is that one can establish the existence of an object satisfying a certain property – with￾out having to construct one explicitly. Instead, one argues that a randomly chosen object
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press26 Moments and Tails
exhibits the given property with positive probability. The following “obvious” observation,
sometimes referred to as the first moment principle, plays a key role in this context.
FIRST Theorem 2.2.1 (First moment principle). Let X be a random variable with finite expecta￾MOMENT
PRINCIPLE
tion. Then, for any µ ∈ R,
E X ≤ µ =⇒ P[X ≤ µ] > 0.
Proof We argue by contradiction. Assume E X ≤ µ and P[X ≤ µ] = 0. We can write
{X ≤ µ} = T
n≥1
{X < µ + 1/n}. That implies by monotonicity (see Lemma B.2.6) that,
for any ε ∈ (0, 1), it holds that P[X < µ + 1/n] < ε for n large enough. Hence, because we
assume that P[X ≤ µ] = 0,
µ ≥ E X
= E[X; X < µ + 1/n] + E[X; X ≥ µ + 1/n]
≥ µP[X < µ + 1/n] + (µ + 1/n)(1 − P[X < µ + 1/n])
= µ + n
−1
(1 − P[X < µ + 1/n])
> µ + n
−1
(1 − ε)
> µ,
a contradiction.
The power of this principle is easier to appreciate through an example.
Example 2.2.2 (Balancing vectors). Let v1, . . . , vn be arbitrary unit vectors in R
n
. How
small can we make the 2-norm of the linear combination
x1v1 + · · · + xnvn
by appropriately choosing x1, . . . , xn ∈ {−1, +1}? We claim that it can be as small as √
n, for
any collection of vis. At first sight, this may appear to be a complicated geometry problem.
But the proof is trivial once one thinks of choosing the xis at random. Let X1, . . . , Xn be
independent random variables uniformly distributed in {−1, +1}. Then, since E[XiXj] =
E[Xi] E[Xj] = 0 for all i 6= j but E[X
2
i
] = 1 for all i,
EkX1v1 + · · · + Xnvnk
2
2 = E


X
i, j
XiXjhvi
, vji


=
X
i, j
E[XiXjhvi
, vji]
=
X
i, j
hvi
, vji E[XiXj]
=
X
i
kvik
2
2
= n,
where we used the linearity of expectation on the second line. Hence, random variable Z =
kX1v1 + · · · + Xnvnk
2 has expectation EZ = n and must take a value ≤ n with positive
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.2 First Moment Method 27
probability by the first moment principle (Theorem 2.2.1). In other words, there must be a
choice of Xis such that Z ≤ n. That proves the claim. J
Here is a slightly more subtle example of the probabilistic method, where one has to
modify the original random choice.
Example 2.2.3 (Independent sets). For d ∈ N, let G = (V, E) be a d-regular graph with n
vertices. Such a graph necessarily has m = nd/2 edges. Our goal is to derive a lower bound
on the size, α(G), of the largest independent set in G. Recall that an independent set is a
set of vertices in a graph, no two of which are adjacent. Again, at first sight, this may seem
like a rather complicated graph-theoretic problem. But an appropriate random choice gives
a non-trivial bound. Specifically:
Claim 2.2.4
α(G) ≥
n
2d
.
Proof The proof proceeds in two steps:
1. We first prove the existence of a subset S of vertices with relatively few edges.
2. We remove vertices from S to obtain an independent set.
Step 1. Let 0 < p < 1 to be chosen below. To form the set S, pick each vertex in V
independently with probability p. Letting X be the number of vertices in S, we have by the
linearity of expectation that
E X = E
"X
v∈V
1v∈S
#
= np,
where we used E[1v∈S] = p. Letting Y be the number of edges between vertices in S, we
have by the linearity of expectation
EY = E


X
{i, j}∈E
1i∈S1j∈S

 =
nd
2
p
2
,
where we also used that E[1i∈S1j∈S] = p
2 by independence. Hence, subtracting,
E[X − Y] = np −
nd
2
p
2
,
which, as a function of p, is maximized at p = 1/d, where it takes the value n/(2d). As a
result, by the first moment principle applied to X − Y, there must exist a set S of vertices in
G such that
|S| − |{{i, j} ∈ E: i, j ∈ S}| ≥
n
2d
. (2.2.2)
Step 2. For each edge e connecting two vertices in S, remove one of the endvertices of e.
By construction, the remaining set of vertices (i) forms an independent set, and (ii) has a size
larger than or equal to the left-hand side of (2.2.2). That inequality implies the claim.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press28 Moments and Tails
Note that a graph G made of n/(d + 1) cliques of size d + 1 (with no edge between the
cliques) has α(G) = n/(d + 1), showing that our bound is tight up to a constant. This is
known as a Turán graph. J
Remark 2.2.5 The previous result can be strengthened to
α(G) ≥
X
v∈V
1
δ(v) + 1
for a general graph G = (V, E), where δ(v) is the degree of v. This bound is achieved for
Turán graphs. See, for example, [AS11, The probabilistic lens: Turán’s theorem].
INDICATOR The previous example also illustrates the important indicator trick, that is, writing a ran￾TRICK dom variable as a sum of indicators, which is naturally used in combination with the linearity
of expectation.
2.2.2 Boole’s Inequality
One implication of the first moment principle (Theorem 2.2.1) is that if a non-negative,
integer-valued random variable X has expectation strictly smaller than 1, then its value is 0
with positive probability. The following application of Markov’s inequality (Theorem 2.1.1)
adds a quantitative twist: if that same X has a “small” expectation, then its value is 0 with
“large” probability.
Theorem 2.2.6 (First moment method). If X is a non-negative, integer-valued random var￾iable, then
P[X > 0] ≤ E X. (2.2.3)
Proof Take b = 1 in Markov’s inequality.
This simple fact is typically used in the following manner: one wants to show that a cer￾tain “bad event” does not occur with probability approaching 1; the random variable X then
counts the number of such “bad events.” In that case, X is a sum of indicators and Theo￾UNION rem 2.2.6 reduces simply to the standard union bound, also known as Boole’s inequality. We
BOUND record one useful version of this setting in the next corollary.
Corollary 2.2.7 Let Bn = An,1 ∪ · · · ∪ An,mn
, where An,1, . . . , An,mn
is a collection of events
for each n. Then, letting
µn :=
Xmn
i=1
P[An,i],
we have
P[Bn] ≤ µn.
In particular, if µn → 0 as n → +∞, then P[Bn] → 0.
Proof Take X := Xn =
Pmn
i=1
1An,i
in Theorem 2.2.6.
A useful generalization of the union bound is given in Exercise 2.2.
FIRST We will refer to applications of Theorem 2.2.6 as the first moment method. We give a few
MOMENT
METHOD
examples.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.2 First Moment Method 29
Example 2.2.8 (Random k-SAT threshold). For r ∈ R+, let 8n,r
: {0, 1}
n → {0, 1} be a
random k-CNF formula on n Boolean variables z1, . . . ,zn with drne clauses. That is, 8n,r
is
an AND of drne ORs, each obtained by picking independently k literals uniformly at random
(with replacement). Recall that a literal is a variable zi or its negation z¯i
. The formula 8n,r
is said to be satisfiable if there exists an assignment z = (z1, . . . ,zn) such that 8n,r(z) = 1.
Clearly, the higher the value of r, the less likely it is for 8n,r
to be satisfiable. In fact, it is
natural to conjecture that a sharp transition takes place, that is, that there exists an r
∗
k ∈ R+
(depending on k but not on n) such that
lim
n→∞
P[8n,r
is satisfiable] =
(
0 if r > r
∗
k
,
1 if r < r
∗
k
.
(2.2.4)
Studying such threshold phenomena is a major theme of modern discrete probability. Us- THRESHOLD
ing the first moment method (Theorem 2.2.6), we give an upper bound on the threshold. PHENOMENON
Formally:
Claim 2.2.9
r > 2
k
log 2 =⇒ lim sup
n→∞
P[8n,r
is satisfiable] = 0.
Proof How to start the proof should be obvious: let Xn be the number of satisfying assign￾ments of 8n,r
. Applying the first moment method, since
P[8n,r
is satisfiable] = P[Xn > 0],
it suffices to show that E Xn → 0. To compute E Xn, we use the indicator trick
Xn =
X
z∈{0,1}
n
1{z satisfies 8n,r}
.
There are 2n possible assignments. Each fixed assignment satisfies the random choice of
clauses 8n,r with probability (1 − 2
−k
)
drne
. Indeed, note that the rn clauses are picked inde￾pendently and each clause literal picked is satisfied with probability 1/2. Therefore, by the
assumption on r, for ε > 0 small enough and n large enough,
E Xn = 2
n
(1 − 2
−k
)
drne
≤ 2
n
(1 − 2
−k
)
(2k
log 2)(1+ε)n
≤ 2
n
e
−(log 2)(1+ε)n
= 2
−εn
→ 0,
where we used (1 − 1/`)
` ≤ e
−1
for all ` ∈ N (see Exercise 1.16). Theorem 2.2.6 implies
the claim.
Remark 2.2.10 Bounds in the other direction are also known. For instance, for k ≥ 3, it
has been shown that if r < 2
k
log 2 − k, then
lim inf
n→∞
P[8n,r
is satisfiable] = 1.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press30 Moments and Tails
See [ANP05]. For the k = 2 case, it is known that (2.2.4) in fact holds with r∗
2 = 1 [CR92].
A breakthrough of [DSS22] also establishes (2.2.4) for large k; the threshold r∗
k
is charac￾terized as the root of a certain equation coming from statistical physics. J
2.2.3 F Random Permutations: Longest Increasing Subsequence
In this section, we bound the expected length of a longest increasing subsequence in a
RANDOM random permutation. Let σn = (σn(1), . . . , σn(n)) be a uniformly random permutation of
PERMUTATION [n] := {1, . . . , n} (i.e., a bijection of [n] to itself chosen uniformly at random among all such
mappings) and let Ln be the length of a longest increasing subsequence of σn (i.e., a sequence
of indices i1 < · · · < ik such that σn(i1) < · · · < σn(ik )).
Claim 2.2.11
ELn = 2(
√
n).
Proof We first prove that
lim sup
n→∞
ELn √
n
≤ e, (2.2.5)
which implies half of the claim. Bounding the expectation of Ln is not straightforward as it
is the expectation of a maximum. A natural way to proceed is to find a value ` for which
P[Ln ≥ `] is “small.” More formally, we bound the expectation as
ELn ≤ ` P[Ln < `] + n P[Ln ≥ `] ≤ ` + n P[Ln ≥ `] (2.2.6)
for an ` chosen below. To bound the probability on the right-hand side, we appeal to the first
moment method (Theorem 2.2.6) by letting Xn be the number of increasing subsequences of
length `. We also use the indicator trick, that is, we think of Xn as a sum of indicators over
subsequences (not necessarily increasing) of length `.
There are ￾
n
`

such subsequences, each of which is increasing with probability 1/`!. Note
that these subsequences are not independent. Nevertheless, by the linearity of expectation
and the first moment method,
P[Ln ≥ `] = P[Xn > 0] ≤ E Xn =
1
`!

n
`

≤
n
`
(`!)
2
≤
n
`
e
2
[`/e]
2`
≤

e
√
n
`
2`
,
where we used a standard bound on factorials recalled in Appendix A. Note that, in order
for this bound to go to 0, we need ` > e
√
n. Then (2.2.5) follows by taking ` = (1 + δ)e
√
n
in (2.2.6), for an arbitrarily small δ > 0.
For the other half of the claim, we show that
ELn √
n
≥ 1.
This part does not rely on the first moment method (and may be skipped). We seek a lower
bound on the expected length of a longest increasing subsequence. The proof uses the fol￾lowing two ideas. First observe that there is a natural symmetry between the lengths of the
longest increasing and decreasing subsequences – they are identically distributed. Moreover,
if a permutation has a “short” longest increasing subsequence, then intuitively it must have
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Pres2.2 First Moment Method 31
a “long” decreasing subsequence, and vice versa. Combining these two observations gives a
lower bound on the expectation of Ln. Formally, let Dn be the length of a longest decreasing
subsequence. By symmetry and the arithmetic mean-geometric mean inequality, note that
ELn = E

Ln + Dn
2

≥ E
p
LnDn.
We show that LnDn ≥ n, which proves the claim. Let L
(k)
n
be the length of a longest increasing
subsequence ending at position k, and similarly for D
(k)
n
. It suffices to show that the pairs
(L
(k)
n
, D
(k)
n
), 1 ≤ k ≤ n, are distinct. Indeed, noting that L
(k)
n ≤ Ln and D
(k)
n ≤ Dn, the number
of pairs in [Ln] × [Dn] is at most LnDn, which must then be at least n.
Let 1 ≤ j < k ≤ n. If σn(k) > σn( j), then we see that L
(k)
n > L
( j)
n
by appending σn(k) to the
subsequence ending at position j achieving L
( j)
n
. If the opposite holds, then we have instead
D
(k)
n > D
( j)
n
. Either way, (L
( j)
n
, D
( j)
n
) and (L
(k)
n
, D
(k)
n
) must be distinct. This clever combinatorial
argument is known as the Erd ˝os–Szekeres Theorem. That concludes the proof of the second
claim.
Remark 2.2.12 It has been shown that in fact
ELn = 2
√
n + cn1/6 + o(n
1/6
),
as n → +∞, where c = −1.77 . . . [BDJ99].
2.2.4 F Percolation: Existence of a Non-Trivial Threshold on Z
2
In this section, we use the first moment method (Theorem 2.2.6) to prove the existence of
a non-trivial threshold in bond percolation on the two-dimensional lattice. We begin with
some background.
Threshold in bond percolation Consider bond percolation (Definition 1.2.1) on the two￾dimensional lattice L
2
(see Section 1.1.1) with density p. Let Pp denote the corresponding
measure. Recall that paths are “self-avoiding” by definition (see Section 1.1.1). We say that
a path is open if all edges in the induced subgraph are open. Writing x ⇔ y if x, y ∈ L
2
are OPEN PATH
connected by an open path; recall that the open cluster of x is
Cx
:= { y ∈ Z
2
: x ⇔ y}.
The percolation function is defined as PERCOLATION
FUNCTION
θ( p) := Pp[|C0| = +∞],
that is, θ( p) is the probability that the origin is connected by open paths to infinitely many
vertices. It is intuitively clear that the function θ( p) is non-decreasing. Indeed, consider
the following alternative representation of the percolation process: to each edge e, assign a
uniform [0, 1] random variable Ue and declare the edge open if Ue ≤ p. Using the same Ues
for densities p1 < p2, it follows immediately from the monotonicity of the construction that
θ( p1) ≤ θ( p2). (We will have much more to say about this type of “coupling” argument in
Chapter 4.) Moreover, note that θ(0) = 0 and θ(1) = 1. The critical value is defined as CRITICAL
VALUE
pc(L
2
) := sup{ p ≥ 0: θ( p) = 0},
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press32 Moments and Tails
the point at which the probability that the origin is contained in an infinite open cluster
becomes positive. Note that by a union bound over all vertices, when θ( p) = 0, we have that
Pp[∃x, |Cx
| = +∞] = 0. Conversely, because {∃x, |Cx
| = +∞} is a tail event (see Defini￾tion B.3.9) for any enumeration of the edges, by Kolmogorov’s 0-1 law (Theorem B.3.11) it
holds that Pp[∃x, |Cx
| = +∞] = 1 when θ( p) > 0.
Using the first moment method we show that the critical value is non-trivial, that is, it is
strictly between 0 and 1. This is a different example of a threshold phenomenon.
Claim 2.2.13
pc(L
2
) ∈ (0, 1).
Proof We first show that for any p < 1/3, θ( p) = 0. In order to apply the first moment
method, roughly speaking, we need to reduce the problem to counting the number of in￾stances of an appropriately chosen substructure. The key observation is the following:
An infinite C0 contains an open path starting at 0 of infinite length and, as a result, of all lengths.
Hence, we let Xn be the number of open paths of length n starting at 0. Then, by monotonicity,
Pp[|C0| = +∞] ≤ Pp[∩n{Xn > 0}] = lim
n
Pp[Xn > 0] ≤ lim sup
n
Ep[Xn], (2.2.7)
where the last inequality follows from Theorem 2.2.6. We bound the number of paths by
noting that they cannot backtrack. That gives four choices at the first step, and at most three
choices at each subsequent step. Hence, we get the following bound
Ep Xn ≤ 4(3n−1
)p
n
.
The right-hand side goes to 0 for all p < 1/3. When combined with (2.2.7), that proves half
of the claim:
pc(L
2
) > 0.
For the other direction, we show that θ( p) > 0 for p close enough to 1. This time, we
count “dual cycles.” This type of proof is known as a contour argument, or Peierls’ argument,
and is based on the following construction. Consider the dual lattice eL
2
DUAL LATTICE whose vertices are
Z
2 + (1/2, 1/2) and whose edges connect vertices u, v with ku − vk1 = 1. See Figure 2.3.
Figure 2.3 Primal (solid) and dual (dotted) lattices.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.2 First Moment Method 33
Note that each edge in the primal lattice L
2 has a unique corresponding edge in the dual
lattice which crosses it perpendicularly. We make the same assignment, open or closed, for
corresponding primal and dual edges. The following graph-theoretic lemma, whose proof is
sketched below, forms the basis of contour arguments. Recall that cycles are “self-avoiding”
by definition (see Section 1.1.1). We say that a cycle is closed if all edges in the induced
subgraph are closed, that is, are not open.
Lemma 2.2.14 (Contour lemma). If |C0| < +∞, then there is a closed cycle around the CONTOUR
origin in the dual lattice eL
2
. LEMMA
To prove that θ( p) > 0 for p close enough to 1, the idea is to apply the first moment method
to Zn equal to the number of closed dual cycles of length n surrounding the origin. We bound
from above the number of dual cycles of length n around the origin by the number of choices
for the starting edge across the upper y-axis and for each n−1 subsequent non-backtracking
choices. Namely,
P[|C0| < +∞] ≤ P[∃n ≥ 4, Zn > 0]
≤
X
n≥4
P[Zn > 0]
≤
X
n≥4
EZn
≤
X
n≥4
n
2
3
n−1
(1 − p)
n
=
3
3
(1 − p)
4
2
X
m≥1
(m + 3)(3(1 − p))m−1
=
3
3
(1 − p)
4
2

1
(1 − 3(1 − p))2
+ 3
1
1 − 3(1 − p)

when p > 2/3, where the first term in parentheses on the last line comes from differentiating
with respect to q the geometric series P
m≥0
q
m
and setting q := 1 − p. This expression can
be taken smaller than 1 if we let p approach 1. We have shown that θ( p) > 0 for p close
enough to 1, and that concludes the proof. (Exercise 2.3 sketches a proof that θ( p) > 0 for
all p > 2/3.)
It is straightforward to extend the claim to L
d
. (Exercise 2.4 asks for the details.)
Proof of the contour lemma We conclude this section by sketching the proof of the contour
lemma, which relies on topological arguments.
Proof of Lemma 2.2.14 Assume |C0| < +∞. Imagine identifying each vertex in L
2 with
a square of side 1 centered around it so that the sides line up with dual edges. Paint green
the squares of vertices in C0. Paint red the squares of vertices in C
c
0 which share a side with
a green square. Leave the other squares white. Let u0 be a highest vertex in C0 along the y￾axis and let v0 and v1 be the dual vertices corresponding to the upper left and right corners,
respectively, of the square of u0. Because u0 is highest, it must be that the square above it
is red. Walk along the dual edge {v0, v1}, separating the squares of u0 and u0 + (0, 1) from
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press34 Moments and Tails
v0 to v1. Notice that this edge satisfies what we call the red-green property: as you traverse
it from v0 to v1, a red square sits on your left and a green square is on your right. Proceed
further by iteratively walking along an incident dual edge with the following rule. Choose
an edge satisfying the red-green property, with the edges to your left, straight ahead, and
to your right in decreasing order of priority. Stop when a previously visited dual vertex is
reached. The claim is that this procedure constructs the desired cycle. Let v0, v1, v2, . . . be
the dual vertices visited. By construction {vi−1, vi} is a dual edge for all i.
• A dual cycle is produced. We first argue that this procedure cannot get stuck. Let {vi−1, vi}
be the edge just crossed and assume that it has the red-green property. If there is a green
square to the left ahead, then the edge to the left, which has highest priority, has the red￾green property. If the left square ahead is not green, but the right one is, then the left
square must in fact be red by construction (i.e., it cannot be white). In that case, the edge
straight ahead has the red-green property. Finally, if neither square ahead is green, then
the right square must in fact be red because the square behind to the right is green by
assumption. That implies that the edge to the right has the red-green property. Hence,
we have shown that the procedure does not get stuck. Moreover, because by assumption
the number of green squares is finite, this procedure must eventually terminate when a
previously visited dual vertex is reached, forming a cycle (of length at least 4).
• The origin lies within the cycle. The inside of a cycle in the plane is well defined by the
Jordan curve theorem. So the dual cycle produced above has its adjacent green squares
either on the inside (negative orientation) or on the outside (positive orientation). In the
former case the origin must lie inside the cycle as otherwise the vertices corresponding to
the green squares on the inside would not be in C0, as they could not be connected to the
origin with open paths.
So it remains to consider the latter case, where through a similar reasoning the origin
must lie outside the cycle. Let vj be the repeated dual vertex. Assume first that vj 6=
v0 and let vj−1 and vj+1 be the dual vertices preceding and following vj during the first
visit to vj
. Let vk be the dual vertex preceding vj on the second visit. After traversing the
edge from vj−1 to vj
, vk cannot be to the left or to the right because in those cases the
red-green properties of the two corresponding edges (i.e., {vj−1, vj} and {vk
, vj}) are not
compatible. So vk
is straight ahead and, by the priority rules, vj+1 must be to the left upon
entering vj
the first time. But in that case, for the origin to lie outside the cycle as we are
assuming and for the cycle to avoid the path v0, . . . , vj−1, we must traverse the cycle with a
negative orientation, that is, the green squares adjacent to the cycle must be on the inside,
a contradiction.
So, finally, assume v0 is the repeated vertex. If the cycle is traversed with a positive
orientation and the origin is on the outside, it must be that the cycle crosses the y-axis at
least once above u0 + (0, 1), again a contradiction.
Hence, we have shown that the origin is inside the cycle.
That concludes the proof.
Remark 2.2.15 It turns out that pc(L
2
) = 1/2. We will prove pc(L
2
) ≥ 1/2, known as
Harris’ Theorem, in Section 4.2.5. The other direction is due to Kesten [Kes80].
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.3 Second Moment Method 35
Figure 2.4 Second moment method: if the standard deviation σX of X is less than
its expectation µX , then the probability that X is 0 is bounded away from 1.
2.3 Second Moment Method
The first moment method (Theorem 2.2.6) gives an upper bound on the probability that a
non-negative, integer-valued random variable is positive – which is non-trivial provided its
expectation is small enough. In this section, we seek a lower bound on that probability. We
first note that a large expectation does not suffice in general. Say, Xn is n
2 with probability
1/n, and 0 otherwise. Then, E Xn = n → +∞, yet P[Xn > 0] → 0. That is, although the
expectation diverges, the probability that Xn is positive can be arbitrarily small.
So we turn to the second moment. Intuitively, the basis for the so-called second moment
method is that if the expectation of Xn is large and its variance is relatively small, then we
can bound the probability that Xn is close to 0. As we will see in applications, the first and
second moment methods often work hand in hand.
2.3.1 Paley–Zygmund Inequality
As an immediate corollary of Chebyshev’s inequality (Theorem 2.1.2), we get a first version
of the second moment method: if the standard deviation of X is less than its expectation,
then the probability that X is 0 is bounded away from 1 (see Figure 2.4). Formally, let X be
a non-negative random variable (not identically zero). Then
P[X > 0] ≥ 1 −
Var[X]
(E X)
2
. (2.3.1)
Indeed, by (2.1.5),
P[X = 0] ≤ P[|X − E X| ≥ E X] ≤
Var[X]
(E X)
2
.
The following tail bound, a simple application of Cauchy–Schwarz (Theorem B.4.8), leads
to an improved version of this inequality.
Theorem 2.3.1 (Paley–Zygmund inequality). Let X be a non-negative random variable. For PALEY–
ZYGMUND
INEQUALITY
all 0 < θ < 1,
P[X ≥ θ E X] ≥ (1 − θ)
2
(E X)
2
E[X2
]
. (2.3.2)
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press36 Moments and Tails
Proof We have
E X = E[X1{X<θE X}] + E[X1{X≥θE X}]
≤ θE X +
p
E[X2
]P[X ≥ θE X],
where we used Cauchy–Schwarz. Rearranging gives the result.
As an immediate application:
SECOND Theorem 2.3.2 (Second moment method). Let X be a non-negative random variable (not
MOMENT
METHOD
identically zero). Then
P[X > 0] ≥
(E X)
2
E[X2
]
. (2.3.3)
Proof Take θ ↓ 0 in (2.3.2).
Since
(E X)
2
E[X2
]
= 1 −
Var[X]
(E X)
2 + Var[X]
,
we see that (2.3.3) is stronger than (2.3.1).
We typically apply the second moment method to a sequence of random variables (Xn).
The previous theorem gives a uniform lower bound on the probability that {Xn > 0} when
E[X
2
n
] ≤ CE[Xn]
2
for some C > 0. Just like the first moment method, the second moment
method is often applied to a sum of indicators (but see Section 2.3.3 for a weighted case).
We record in the next corollary a convenient version of the method.
Corollary 2.3.3 Let Bn = An,1 ∪ · · · ∪ An,mn
, where An,1, . . . , An,mn
is a collection of events
for each n. Write i n
∼ j if i 6= j and An,i and An, j are not independent. Then, letting
µn :=
Xmn
i=1
P[An,i], γn :=
X
i
n
∼j
P[An,i ∩ An, j],
where the second sum is over ordered pairs, we have limn P[Bn] > 0 whenever µn → +∞
and γn ≤ Cµ
2
n
for some C > 0. If moreover γn = o(µ
2
n
), then limn P[Bn] = 1.
Proof We apply the second moment method to Xn :=
Pmn
i=1
1An,i
so that Bn = {Xn > 0}.
Note that
Var[Xn] =
X
i
Var[1An,i
] +
X
i6=j
Cov[1An,i
, 1An, j
],
where
Var[1An,i
] = E[(1An,i
)
2
] − (E[1An,i
])2 ≤ P[An,i],
and, if An,i and An, j are independent,
Cov[1An,i
, 1An, j
] = 0,
whereas, if i
n
∼ j,
Cov[1An,i
, 1An, j
] = E[1An,i1An, j
] − E[1An,i
]E[1An, j
] ≤ P[An,i ∩ An, j].
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.3 Second Moment Method 37
Hence,
Var[Xn]
(E Xn)
2
≤
µn + γn
µ2
n
=
1
µn
+
γn
µ2
n
.
Noting
(E Xn)
2
E[X2
n
]
=
(E Xn)
2
(E Xn)
2 + Var[Xn]
=
1
1 + Var[Xn]/(E Xn)
2
and applying Theorem 2.3.2 gives the result.
2.3.2 F Random Graphs: Subgraph Containment and Connectivity
in the Erd ˝os–Rényi Model
Threshold phenomena are also common in random graphs. We consider here the Erdos– ˝
Rényi random graph model (Definition 1.2.2). In this context, a threshold function for a THRESHOLD
graph property P is a function r(n) such that FUNCTION
lim
n
Pn,pn
[Gn has property P] =
(
0 if pn  r(n),
1 if pn  r(n),
where Gn ∼ Gn,pn
is a random graph with n vertices and density pn. In this section, we
illustrate this type of phenomenon on two properties: the containment of small subgraphs
and connectivity.
Subgraph containment
We first consider the clique number, then we turn to more general subgraphs.
Cliques Let ω(G) be the clique number of a graph G, that is, the size of its largest clique. CLIQUE
NUMBER
Claim 2.3.4 The property ω(Gn) ≥ 4 has threshold function n−2/3
.
Proof Let Xn be the number of 4-cliques in the random graph Gn ∼ Gn,pn
. Then, noting
that there are ￾
4
2

= 6 edges in a 4-clique,
En,pn
[Xn] =

n
4

p
6
n = 2(n
4
p
6
n
),
which goes to 0 when pn  n
−2/3
. Hence, the first moment method (Theorem 2.2.6) gives
one direction: Pn,pn
[ω(Gn) ≥ 4] → 0 in that case.
For the other direction, we apply the second moment method for sums of indicators, that
is, Corollary 2.3.3. We use the notation from that corollary. For an enumeration S1, . . . , Smn
of the 4-tuples of vertices in Gn, let An,1, . . . , An,mn be the events that the corresponding 4-
clique is present. By the calculation above we have µn = 2(n
4p
6
n
), which goes to +∞ when
pn  n
−2/3
. Also µ
2
n = 2(n
8p
12
n
), so it suffices to show that γn = o(n
8p
12
n
). Note that two
4-cliques with disjoint edge sets (but possibly sharing one vertex) are independent (i.e., their
presence or absence is independent). Suppose Si and Sj share three vertices. Then, i
n
∼ j and
Pn,pn
[An,i
| An, j] = p
3
n
,
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Pres38 Moments and Tails
as the event An, j
implies that all edges between three of the vertices in Si are already present,
and there are three edges between the remaining vertex and the rest of Si
. Similarly, if |Si ∩
Sj
| = 2, we have again i
n
∼ j and this time Pn,pn
[An,i
| An, j] = p
5
n
. Putting these together,
we get by the definition of the conditional probability (see Appendix B) and the fact that
Pn,pn
[An, j] = p
6
n
γn =
X
i
n
∼j
P[An,i ∩ An, j]
=
X
i
n
∼j
Pn,pn
[An, j] Pn,pn
[An,i
| An, j]
=
X
j
Pn,pn
[An, j]
X
i:i
n
∼j
Pn,pn
[An,i
| An, j]
=

n
4

p
6
n
4
3

(n − 4)p
3
n +

4
2
n − 4
2

p
5
n

= O(n
5
p
9
n
) + O(n
6
p
11
n
)
= O

n
8p
12
n
n
3p
3
n

+ O

n
8p
12
n
n
2pn

= o(n
8
p
12
n
)
= o(µ
2
n
),
where we used that pn  n
−2/3
(so that for example n
3p
3
n  1). Corollary 2.3.3 gives the
result: Pn,pn
[∪iAn,i] → 1 when pn  n
−2/3
.
Roughly speaking, the first and second moments suffice to pinpoint the threshold in this
case because the indicators in Xn are “mostly” pairwise independent and, as a result, the sum
is “concentrated around its mean.”
General subgraphs The methods of Claim 2.3.4 can be applied to more general subgraphs.
However, the situation is somewhat more complicated than it is for cliques. For a graph H0,
let vH0
and eH0
be the number of vertices and edges of H0, respectively. Let Xn be the number
of (not necessarily induced) copies of H0 in Gn ∼ Gn,pn
. By the first moment method,
P[Xn > 0] ≤ E[Xn] = 2(n
vH0 p
eH0
n ) → 0,
when pn  n
−vH0
/eH0 . The constant factor, which does not play a role in the asymptotics,
accounts in particular for the number of automorphisms of H0. Indeed, note that a fixed set
of vH0 vertices can contain several distinct copies of H0, depending on its structure.
From the proof of Claim 2.3.4, one might guess that the threshold function is n
−vH0
/eH0 .
That is not the case in general. To see what can go wrong, consider the graph H0 in Figure 2.5
whose edge density is eH0
vH0
=
6
5
. When pn  n
−5/6
EDGE DENSITY , the expected number of copies of H0 in
Gn tends to +∞. But observe that the subgraph H of H0 has the higher density 5/4 and,
hence, when n
−5/6  pn  n
−4/5
the expected number of copies of H tends to 0. By the
first moment method, the probability that a copy of H0 – and therefore H – is present in
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.3 Second Moment Method 39
Figure 2.5 Graph H0 and subgraph H.
that regime is asymptotically negligible despite its diverging expectation. This leads to the
following definition
rH0
:= max 
eH
vH
: subgraphs H ⊆ H0, eH > 0

.
Assume H0 has at least one edge.
Claim 2.3.5 “Having a copy of H0” has threshold n−1/rH0 .
Proof We proceed as in Claim 2.3.4. Let H
∗
0
be a subgraph of H0 achieving rH0
. When
pn  n
−1/rH0 , the probability that a copy of H
∗
0
is in Gn tends to 0 by the argument above.
Therefore, the same conclusion holds for H0 itself.
Assume pn  n
−1/rH0 . Let S1, . . . , Smn be an enumeration of the copies (as subgraphs) of
H0 in a complete graph on the vertices of Gn. Let An,i be the event that Si ⊆ Gn. Using again
the notation of Corollary 2.3.3,
µn = 2(n
vH0 p
eH0
n ) = (8H0
(n)),
where
8H0
(n) := min 
n
vH p
eH
n
: subgraphs H ⊆ H0, eH > 0
	
.
Note that 8H0
(n) → +∞ when pn  n
−1/rH0 by definition of rH0
. The events An,i and An, j
are independent if Si and Sj share no edge. Otherwise we write i
n
∼ j. Note that there are
2(n
vH n
2(vH0−vH )
) pairs Si
, Sj whose intersection is isomorphic to H. The probability that both
Si and Sj of such a pair are present in Gn is 2( p
eH
n
p
2(eH0−eH )
n ). Hence,
γn =
X
i
n
∼j
P[An,i ∩ An, j]
=
X
H⊆H0,eH>0
2

n
2vH0−vH p
2eH0−eH
n

≤
2(µ
2
n
)
2(8H0
(n))
= o(µ
2
n
),
where we used that 8H0
(n) → +∞. The result follows from Corollary 2.3.3.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press40 Moments and Tails
Going back to the example of Figure 2.5, the proof above confirms that when n
−5/6 
pn  n
−4/5
the second moment method fails for H0 since 8H0
(n) → 0. In that regime,
although there is in expectation a large number of copies of H0, those copies are highly
correlated as they are produced from a small (vanishing in expectation) number of copies
of H – producing a large variance that helps to explain the failure of the second moment
method.
Connectivity threshold
Next we use the second moment method to show that the threshold function for connectivity
in the Erdos–Rényi random graph model is ˝
log n
n
. In fact, we prove this result by deriving
the threshold function for the presence of isolated vertices. The connection between the
two is obvious in one direction. Isolated vertices imply a disconnected graph. What is less
obvious is that it also works the other way in the following sense: the two thresholds actually
coincide.
Isolated vertices We begin with isolated vertices.
Claim 2.3.6 “Not having an isolated vertex” has threshold function log n
n
.
Proof Let Xn be the number of isolated vertices in the random graph Gn ∼ Gn,pn
. Using
1 − x ≤ e
−x
for all x ∈ R (see Exercise 1.16),
En,pn
[Xn] = n(1 − pn)
n−1 ≤ e
log n−(n−1)pn → 0, (2.3.4)
when pn  log n
n
. So the first moment method gives one direction: Pn,pn
[Xn > 0] → 0.
For the other direction, we use the second moment method. Let An, j be the event that
vertex j is isolated. By the computation above, using 1 − x ≥ e
−x−x
2
for x ∈ [0, 1/2] (see
Exercise 1.16),
µn =
X
i
Pn,pn
[An,i] = n(1 − pn)
n−1 ≥ e
log n−npn−np2
n
, (2.3.5)
which goes to +∞ when pn  log n
n
. Note that An,i and An, j are not independent for all i 6= j
(because the absence of an edge between i and j is part of both events) and
Pn,pn
[An,i ∩ An, j] = (1 − pn)
2(n−2)+1
,
so that
γn =
X
i6=j
Pn,pn
[An,i ∩ An, j] = n(n − 1)(1 − pn)
2n−3
.
Because γn is not o(µ
2
n
), we cannot apply Corollary 2.3.3. Instead we use Theorem 2.3.2
directly. We have
En,pn
[X
2
n
]
En,pn
[Xn]
2
=
µn + γn
µ2
n
≤
n(1 − pn)
n−1 + n
2
(1 − pn)
2n−3
n
2
(1 − pn)
2n−2
≤
1
n(1 − pn)
n−1
+
1
1 − pn
, (2.3.6)
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.3 Second Moment Method 41
which is 1 + o(1) when pn  log n
n
by (2.3.5). The second moment method implies that
Pn,pn
[Xn > 0] → 1 in that case.
Connectivity We use Claim 2.3.6 to study the threshold for connectivity.
Claim 2.3.7 Connectivity has threshold function log n
n
.
Proof We start with the easy direction. If pn  log n
n
, Claim 2.3.6 implies that the graph
has at least one isolated vertex – and therefore is necessarily disconnected – with probability
going to 1 as n → +∞.
Assume now that pn  log n
n
. Let Dn be the event that Gn is disconnected. To bound
Pn,pn
[Dn], we let Yk be the number of subsets of k vertices that are disconnected from all
other vertices in the graph for k ∈ {1, . . . , n/2}. Then, by the first moment method,
Pn,pn
[Dn] ≤ Pn,pn
"Xn/2
k=1
Yk > 0
#
≤
Xn/2
k=1
En,pn
[Yk ].
The expectation of Yk
is straightforward to bound. Using k ≤ n/2 and ￾
n
k

≤ n
k
,
En,pn
[Yk ] =

n
k

(1 − pn)
k(n−k) ≤
￾
n(1 − pn)
n/2
k
.
The expression in parentheses is o(1) when pn  log n
n
by a calculation similar to (2.3.4).
Summing over k,
Pn,pn
[Dn] ≤
X
+∞
k=1
￾
n(1 − pn)
n/2
k
= O(n(1 − pn)
n/2
) = o(1),
where we used that the geometric series (started at k = 1) is dominated asymptotically by its
first term. So the probability of being disconnected goes to 0 when pn  log n
n
and we have
proved the claim.
A closer look We have shown that connectivity and the absence of isolated vertices have
the same threshold function. In fact, in a sense, isolated vertices are the “last obstacle” to
connectivity. A slight modification of the proof above leads to the following more precise
result. For k ∈ {1, . . . , n/2}, let Zk be the number of connected components of size k in Gn. In
particular, Z1 is the number of isolated vertices. We consider the “critical window” pn =
cn
n
,
where cn := log n + s for some fixed s ∈ R. We show that, in that regime, asymptotically
the graph is typically composed of a large connected component together with some isolated
vertices. Formally, we prove Claim 2.3.8, which says that with probability close to 1, either
the graph is connected or there are some isolated vertices together with a (necessarily unique)
connected component of size greater than n/2.
Claim 2.3.8
Pn,pn
[Z1 > 0] ≥
1
1 + e
s
+ o(1) and Pn,pn
"Xn/2
k=2
Zk > 0
#
= o(1).
The limit of Pn,pn
[Z1 > 0] can be computed explicitly using the method of moments. See
Exercise 2.19.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Pr42 Moments and Tails
Proof of Claim 2.3.8 We first consider isolated vertices. From (2.3.5), (2.3.6), and the sec￾ond moment method,
Pn,pn
[Z1 > 0] ≥

e
− log n+npn+np2
n +
1
1 − pn
−1
=
1
1 + e
s
+ o(1),
as n → +∞ by our choice of pn.
To bound the number of components of size k > 1, we note first that the random variable
Yk used in the previous claim (which imposes no condition on the edges between the vertices
in the subsets of size k) is too loose to provide a suitable bound. Instead, to bound the
probability that a subset of k vertices forms a connected component, we observe that a
connected component is characterized by two properties: it is disconnected from the rest of
the graph; and it contains a spanning tree. Formally, for k = 2, . . . , n/2, we let Z
0
k
be the
number of (not necessarily induced) maximal trees of size k or, put differently, the number
of spanning trees of connected components of size k. Then, by the first moment method, the
probability that a connected component of size > 1 is present in Gn is bounded by
Pn,pn
"Xn/2
k=2
Zk > 0
#
≤ Pn,pn
"Xn/2
k=2
Z
0
k > 0
#
≤
Xn/2
k=2
En,pn
[Z
0
k
]. (2.3.7)
To bound the expectation of Z
0
k
, we use Cayley’s formula, which states that there are k
k−2
trees on a set of k labeled vertices. Recall further that a tree on k vertices has k − 1 edges
(see Exercise 1.7). Hence,
En,pn
[Z
0
k
] =

n
k

k
k−2
| {z }
(a)
p
k−1
n
|{z}
(b)
(1 − pn)
k(n−k)
| {z }
(c)
,
where (a) is the number of trees of size k (as subgraphs) in a complete graph of size n,
(b) is the probability that such a tree is present in the graph, and (c) is the probability that
this tree is disconnected from every other vertex in the graph. Using that k! ≥ (k/e)
k
(see
Appendix A) and 1 − x ≤ e
−x
for all x ∈ R (see Exercise 1.16),
En,pn
[Z
0
k
] ≤
n
k
k!
k
k−2
p
k−1
n
(1 − pn)
k(n−k)
≤
n
k
e
k
k
k
k
k
npk
n
e
−pnk(n−k)
≤ n

ecne
−(1−
k
n )cn
k
= n

e(log n + s)e
−(1−
k
n )(log n+s)
k
.
For k ≤ n/2, the expression in parentheses is o(1). In fact, for 2 ≤ k ≤ n/2, En,pn
[Z
0
k
] = o(1).
Furthermore, summing over k > 2,
Xn/2
k=3
En,pn
[Z
0
k
] ≤
X
+∞
k=3
n

e(log n + s)e
−
1
2
(log n+s)
k
= O(n
−1/2
log3
n) = o(1).
Plugging this back into (2.3.7) gives the second claim in the statement.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.3 Second Moment Method 43
2.3.3 F Percolation: Critical Value on Trees and Branching Number
Consider bond percolation (see Definition 1.2.1) on the infinite d-regular tree Td. Root the
tree arbitrarily at a vertex 0 and let C0 be the open cluster of the root. In this section, we
illustrate the use of the first and second moment methods on the identification of the critical
value
pc(Td) = sup{ p ∈ [0, 1]: θ( p) = 0},
where recall that the percolation function is θ( p) = Pp[|C0| = +∞]. We then consider
general trees, introduce the branching number, and present a weighted version of the second
moment method.
Regular tree Our main result for Td is the following.
Claim 2.3.9
pc(Td) =
1
d − 1
.
Proof Let ∂n be the nth level of Td, that is, the set of vertices at graph distance n from 0.
Let Xn be the number of vertices in ∂n ∩ C0. In order for the open cluster of the root to be
infinite, there must be at least one vertex on the nth level connected to the root by an open
path. By the first moment method (Theorem 2.2.6),
θ( p) = Pp[|C0| = +∞] ≤ Pp[Xn > 0] ≤ EpXn = d(d − 1)n−1
p
n → 0, (2.3.8)
as n → +∞, for any p <
1
d−1
. Here we used that there is a unique path between 0 and any
vertex in the tree to deduce that Pp[x ∈ C0] = p
n
for x ∈ ∂n. Equation (2.3.8) implies half of
the claim: pc(Td) ≥
1
d−1
.
The second moment method gives a lower bound on Pp[Xn > 0]. To simplify the notation,
it is convenient to introduce the “branching ratio” b := d − 1. We say that x is a descendant
of z if the path between 0 and x goes through z. Each z 6= 0 has d − 1 descendant subtrees,
that is, subtrees of Td rooted at z made of all descendants of z. Let x ∧ y be the most recent
common ancestor of x and y, that is, the furthest vertex from 0 that lies on both the path from
0 to x and the path from 0 to y; see Figure 2.6. Letting
Figure 2.6 Most recent common ancestor of x and y.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press44 Moments and Tails
µn := Ep[Xn] = Ep
"X
x∈∂n
1{x∈C0}
#
= (b + 1)b
n−1
p
n
,
we have
Ep[X
2
n
] = Ep


 X
x∈∂n
1{x∈C0}
!2


=
X
x,y∈∂n
Pp[x, y ∈ C0]
=
X
x∈∂n
Pp[x ∈ C0] +
Xn−1
m=0
X
x,y∈∂n
1{x∧y∈∂m}p
m
p
2(n−m)
= µn + (b + 1)b
n−1Xn−1
m=0
(b − 1)b
(n−m)−1
p
2n−m
≤ µn + (b + 1)(b − 1)b
2n−2
p
2nX
+∞
m=0
(bp)
−m
= µn + µ
2
n
·
b − 1
b + 1
·
1
1 − (bp)
−1
,
where, on the fourth line, we used that all vertices on the nth level are equivalent and that,
for a fixed x, the set { y : x ∧ y ∈ ∂m} is composed of those vertices in ∂n that are descendants
of x ∧ y but not in the descendant subtree of x ∧ y containing x. When p >
1
d−1 =
1
b
, dividing
by (EpXn)
2 = µ
2
n → +∞, we get
Ep[X
2
n
]
(EpXn)
2
≤
1
µn
+
b − 1
b + 1
·
1
1 − (bp)
−1
(2.3.9)
≤ 1 +
b − 1
b + 1
·
1
1 − (bp)
−1
=: Cb,p.
By the second moment method (Theorem 2.3.2) and monotonicity,
θ( p) = Pp[|C0| = +∞] = Pp[∀n, Xn > 0] = lim
n
Pp[Xn > 0] ≥ C
−1
b,p > 0,
which concludes the proof. (Note that the version of the second moment method in (2.3.1)
does not work here. Subtract 1 in (2.3.9) and take p close to 1/b.)
The argument in the proof of Claim 2.3.9 relies crucially on the fact that, in a tree, any
two vertices are connected by a unique path. For instance, approximating Pp[x ∈ C0] is
much harder on a lattice. Note furthermore that, intuitively, the reason why the first moment
captures the critical threshold exactly in this case is that bond percolation on Td is a “branch￾ing process” (defined formally and studied at length in Chapter 6), where Xn represents the
“population size at generation n.” The qualitative behavior of a branching process is gov￾erned by its expectation: when the mean number of children bp exceeds 1, the process grows
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.3 Second Moment Method 45
exponentially on average and “explodes” with positive probability (see Theorem 6.1.6). We
will come back to this point of view in Section 6.2.4 where branching processes are used to
give a more refined analysis of bond percolation on Td.
General trees Let T be a locally finite tree (i.e., all its degrees are finite) with root 0. For
an edge e, let ve be the endvertex of e furthest from the root. We denote by |e| the graph
distance between 0 and ve
. Generalizing a previous definition from Section 1.1.1 to infinite,
locally finite graphs, a cutset separating 0 and +∞ is a finite set of edges 5 such that all
infinite paths (which, recall, are self-avoiding by definition) starting at 0 go through 5. (For
our purposes, it will suffice to assume that cutsets are finite by default.) For a cutset 5, we
let 5v := {ve
: e ∈ 5}. Repeating the argument in (2.3.8), for any cutset 5, by the first
moment method (i.e., union bound),
θ( p) = Pp[|C0| = +∞]
≤ Pp[C0 ∩ 5v 6= ∅]
≤
X
u∈5v
Pp[u ∈ C0]
=
X
e∈5
p
|e|
. (2.3.10)
This bound naturally leads to the next definition.
Definition 2.3.10 (Branching number). The branching number of T is given by BRANCHING
NUMBER
br(T ) = sup(
λ ≥ 1: inf
cutset 5
X
e∈5
λ
−|e| > 0
)
. (2.3.11)
Using the max-flow min-cut theorem (Theorem 1.1.15), the branching number can also be
characterized in terms of a “flow to +∞.” We will not do this here. (But see Theorem 3.3.30.)
Equation (2.3.10) implies that pc(T ) ≥
1
br(T )
. Remarkably, this bound is tight. The proof
is based on a “weighted” second moment method.
Claim 2.3.11 For any rooted, locally finite tree T ,
pc(T ) =
1
br(T )
.
Proof Suppose p <
1
br(T )
. Then, p
−1 > br(T ) and the sum in (2.3.10) can be made
arbitrarily small by definition of the branching number, that is, θ( p) = 0. Hence we have
shown that pc(T ) ≥
1
br(T )
.
To argue in the other direction, let p >
1
br(T )
, p
−1 < λ < br(T ), and ε > 0 such that
X
e∈5
λ
−|e| ≥ ε (2.3.12)
for all cutsets 5. The existence of such an ε is guaranteed by the definition of the branching
number. As in the proof of Claim 2.3.9, we use that θ( p) is the limit as n → +∞ of the
probability that C0 reaches the nth level (i.e., the vertices at graph distance n from the root 0,
which is necessarily a finite set in a locally finite tree). However, this time, we use a weighted
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press46 Moments and Tails
count on the nth level. Let Tn be the first n levels of T and, as before, let ∂n be the vertices
on the nth level. For a probability measure νn on ∂n, we define the weighted count
Xn =
X
z∈∂n
1{z∈C0}
νn(z)
Pp[z ∈ C0]
.
The purpose of the denominator is normalization, that is,
EpXn =
X
z∈∂n
νn(z) = 1.
Observe that, while νn(z) may be 0 for some zs (but not all), we still have that Xn > 0, ∀n
implies {|C0| = +∞}, which is what we need to apply the second moment method.
Because of (2.3.12), a natural choice of νn follows from the max-flow min-cut theorem
(Theorem 1.1.15) applied to Tn with source 0, sink ∂n, and capacity constraint |φ(x, y)| ≤
κ(e) := ε
−1λ
−|e|
for all edges e = {x, y}. Indeed, for all cutsets 5 in Tn separating 0 and
∂n, we have P
e∈5
κ(e) =
P
e∈5
ε
−1λ
−|e| ≥ 1 by (2.3.12). That then guarantees by Theo￾rem 1.1.15 the existence of a unit flow φ from 0 to ∂n satisfying the capacity constraints.
Define νn(z) to be the flow entering z ∈ ∂n under φ. In particular, because φ is a unit flow,
νn defines a probability measure. It remains to bound the second moment of Xn under this
choice. We have
EpX
2
n = Ep


 X
z∈∂n
1{z∈C0}
νn(z)
Pp[z ∈ C0]
!2


=
X
x,y∈∂n
νn(x)νn( y)
Pp[x, y ∈ C0]
Pp[x ∈ C0]Pp[ y ∈ C0]
=
Xn
m=0
X
x,y∈∂n
1{x∧y∈∂m}νn(x)νn( y)
p
mp
2(n−m)
p
2n
=
Xn
m=0
p
−mX
z∈∂m


X
x,y∈∂n
1{x∧y=z}νn(x)νn( y)

 .
In the expression in parentheses, for each x descendant of z, the sum over y is at most
νn(x)νn(z) by the definition of a flow; then the sum over those xs gives at most νn(z)
2
. So
EpX
2
n ≤
Xn
m=0
p
−mX
z∈∂m
νn(z)
2
≤
Xn
m=0
p
−mX
z∈∂m
(ε
−1
λ
−m
)νn(z)
≤ ε
−1X
+∞
m=0
( pλ)
−m
=
ε
−1
1 − ( pλ)
−1
=: Cε,λ,p < +∞,
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.3 Second Moment Method 47
where the second line follows from the capacity constraint, and we used pλ > 1 on the last
line. From the second moment method (recalling that EpXn = 1),
θ( p) = Pp[|C0| = +∞] ≥ Pp[∀n, Xn > 0] = lim
n
Pp[Xn > 0] ≥ C
−1
ε,λ,p > 0.
It follows that
θ( p) ≥ C
−1
ε,λ,p > 0,
and pc(T ) ≤
1
br(T )
. That concludes the proof.
Note that Claims 2.3.9 and 2.3.11 imply that br(Td) = d − 1. The next example is more
striking and insightful.
Example 2.3.12 (The 3–1 tree). The 3–1 tree Tc3−1 is an infinite rooted tree. We give a
planar description. The root ρ (level 0) is at the top. It has two children below it (level 1).
Then on level n, for n ≥ 1, the first 2n−1 vertices starting from the left have exactly 1 child
and the next 2n−1 vertices have exactly 3 children. In particular, level n has 2n vertices, which
we denote by un,1, . . . , un,2n . For vertex un, j we refer to j/2
n
as its relative position (on level RELATIVE
n). So vertices have 1 or 3 children according to whether their relative position is ≤ 1/2 POSITION
or > 1/2.
Because the level size is growing at rate 2, it is tempting to conjecture that the branching
number is 2 – but that turns out to be way off.
Claim 2.3.13 br(Tc3−1) = 1.
What makes this tree entirely different from the infinite 2-ary tree, despite having the same
level growth, is that each infinite path from the root in Tc3−1 eventually “stops branching,”
with the sole exception of the rightmost path which we refer to as the main path. Indeed, let MAIN PATH
0 = v0 ∼ v1 ∼ v2 ∼ · · · with v0 = ρ be an infinite path distinct from the main path. Let
xi be the relative position of vi
, i ≥ 1. Let vk be the first vertex of 0 not on the main path. It
lies on the kth level.
Lemma 2.3.14 Let v be a vertex that is not on the main path with relative position x and
assume that 0 ≤ x ≤ α < 1. Let w be a child of v and denote by y its relative position. Then,
y ≤
(
1
2
x if x ≤ 1/2,
x −
1
2
(1 − α) otherwise.
Proof Assume without loss of generality that v = un, j for some n and j < 2
n
. If j ≤ 2
n−1
,
then by construction v has exactly one child with relative position
y =
j
2
n+1
=
1
2
x.
That proves the first claim.
If j > 2
n−1
, then all vertices to the right of v have 3 children, all of whom are to the right
of the children of v. Hence, the children of v have relative position at most
y ≤
2
n+1 − 3(2n − j)
2
n+1
=
3j − 2
n
2
n+1
=
3
2
x −
1
2
.
Subtracting x and using x ≤ α gives the second claim.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press48 Moments and Tails
We now apply Lemma 2.3.14 to vk as defined above and its descendants on 0 with α =
1 − 1/2
k
. We get that the relative position decreases from vk by 1/2
k+1 on each level until it
falls below 1/2 at which point it gets cut in half at each level. Once this last regime is reached,
each vertex on 0 from then on has exactly one child – that is, there is no more branching.
We are now ready to prove the claim.
Proof of Claim 2.3.13 Take any λ > 1. From the definition of the branching number (Def￾inition 2.3.10), it suffices to find a sequence of cutsets (5n)n such that
X
e∈5n
λ
−|e| → 0,
as n → +∞. What does not work is to choose 5n := 3n to be the edges between level n−1
and level n, since we then have
X
e∈3n
λ
−|e| = 2
n
λ
−n
,
which diverges whenever λ < 2. Instead, we construct a new cutset 8n based on 3n as
follows. We divide up 3n into the disjoint union 3−
n ∪ 3+
n
, where 3−
n
are the edges whose
endvertex on level n has relative position ≤ 1/2 and 3+
n
are the rest of the edges. Start with
8n := ∅.
Step 1. For each edge e in 3−
n
, letting v be the endvertex of e on level n, add to 8n the edge
{v
0
, v
00} where v
0
and v
00 are the unique descendants of v on level mn − 1 and mn, respectively.
The value of mn ≥ n is chosen so that
2
n
λ
−mn ≤
1
2n
. (2.3.13)
Any infinite path from the root going through one of the edges in 3−
n
has to go through the
edge that replaced it in 8n since there is no branching below that point by Lemma 2.3.14.
Step 2. We also add to 8n the edge {w
0
,w
00} on the main path where w
0 = u`n−1,2`n−1 is on
level `n − 1 and w
00 = u`n,2`n is on level `n. We mean for the value of `n to be such that any
infinite path going through an edge in 3+
n
has to go through {w
0
,w
00} first. That is, we need
all vertices of level n with relative position > 1/2 to be a descendant of w
00. The number of
descendants of w
00 on level J > `n is 3J−`n until the last J such that it is ≤ 2
J−1
, which we
denote by J
∗
. A quick calculation gives
J
∗ =

`n log 3 − log 2
log 3 − log 2 
.
After level J
∗
, the leftmost descendant of w
00 has relative position ≤ 1/2 by Lemma 2.3.14.
Therefore, we need n > J
∗
. Taking
`n =

log 3/2
log 3
n

, (2.3.14)
will do for n large enough, say n ≥ n0.
Finishing up. By construction, 8n is a cutset for all n ≥ n0. Moreover,
X
e∈8n
λ
−|e| = 2
n−1
λ
−mn + λ
−`n <
1
n
for n large enough, where we used (2.3.13) and (2.3.14). Taking n → +∞ gives the
claim.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.4 Chernoff–Cramér Method 49
As a consequence of Claims 2.3.11 and 2.3.13, |Cρ| < +∞ almost surely for all p < 1
on Tc3−1. J
2.4 Chernoff–Cramér Method
Chebyshev’s inequality (Theorem 2.1.2) gives a bound on the concentration around its mean
of a square integrable random variable. It is, in general, best possible. Indeed, take X to
be µ + bσ or µ − bσ with probability (2b
2
)
−1
each, and µ otherwise. Then E X = µ,
VarX = σ
2
, and for β = bσ,
P[|X − E X| ≥ β] = P[|X − E X| = β] =
1
b
2
=
VarX
β
2
.
However, in many cases, much stronger bounds can be derived. For instance, if X ∼ N(0, 1),
by the following lemma
P[|X − E X| ≥ β] ∼
r
2
π
β
−1
exp(−β
2
/2) 
1
β
2
, (2.4.1)
as β → +∞. Indeed:
Lemma 2.4.1 For x > 0,
(x
−1 − x
−3
) e
−x
2
/2 ≤
Z +∞
x
e
−y
2
/2
dy ≤ x
−1
e
−x
2
/2
.
Proof By the change of variable y = x + z and using e
−z
2
/2 ≤ 1
Z +∞
x
e
−y
2
/2
dy ≤ e
−x
2
/2
Z +∞
0
e
−xzdz = e
−x
2
/2
x
−1
.
For the other direction, by differentiation,
Z +∞
x
(1 − 3y
−4
) e
−y
2
/2
dy = (x
−1 − x
−3
) e
−x
2
/2
.
In this section, we discuss the Chernoff–Cramér method, which produces exponential tail
bounds, provided the moment-generating function (see Section 2.1.1) is finite in a neighbor￾hood of 0.
2.4.1 Tail Bounds via the Moment-Generating Function
Under a finite variance, squaring within Markov’s inequality (Theorem 2.1.1) produces
Chebyshev’s inequality (Theorem 2.1.2). This “boosting” can be pushed further when stronger
integrability conditions hold.
Chernoff–Cramér We refer to (2.4.2) in the next lemma as the Chernoff–Cramér bound. CHERNOFF–
CRAMÉR
Lemma 2.4.2 BOUND (Chernoff–Cramér bound). Assume X is a random variable such that MX (s) <
+∞ for s ∈ (−s0,s0) for some s0 > 0. For any β > 0 and s > 0,
P[X ≥ β] ≤ exp [− {sβ − 9X (s)}] , (2.4.2)
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press50 Moments and Tails
where
9X (s) := log MX (s)
is the cumulant-generating function of X .
Proof Exponentiating within Markov’s inequality gives for s > 0,
P[X ≥ β] = P[e
sX ≥ e
sβ
] ≤
MX (s)
e
sβ
= exp [− {sβ − 9X (s)}] .
Returning to the Gaussian case, let X ∼ N(0, ν), where ν > 0 is the variance and note
that
MX (s) =
Z +∞
−∞
e
sx 1
√
2πν
e
−
x
2
2ν dx
=
Z +∞
−∞
e
s
2ν
2
1
√
2πν
e
−
(x−sν)
2
2ν dx
= exp
s
2
ν
2

.
By straightforward calculus, the optimal choice of s in (2.4.2) gives the exponent
sup
s>0
(sβ − s
2
ν/2) =
β
2
2ν
, (2.4.3)
achieved at sβ = β/ν. For β > 0, this leads to the bound
P[X ≥ β] ≤ exp
−
β
2
2ν

, (2.4.4)
which is much sharper than Chebyshev’s inequality for large β – compare to (2.4.1).
As another toy example, we consider simple random walk on Z.
Lemma 2.4.3 (Chernoff bound for simple random walk on Z). Let Z1, . . . , Zn be independ￾RADEMACHER ent Rademacher variables, that is, they are {−1, 1}-valued random variables with P[Zi =
VARIABLE 1] = P[Zi = −1] = 1/2. Let Sn =
P
i≤n
Zi
. Then, for any β > 0,
P[Sn ≥ β] ≤ e
−β
2
/2n
. (2.4.5)
Proof The moment-generating function of Z1 can be bounded as follows
MZ1
(s) =
e
s + e
−s
2
=
X
j≥0
s
2j
(2j)!
≤
X
j≥0
(s
2
/2)j
j!
= e
s
2
/2
. (2.4.6)
Taking s = β/n in the Chernoff–Cramér bound (2.4.2), we get
P[Sn ≥ β] ≤ exp ￾
−sβ + n9Z1
(s)

≤ exp ￾
−sβ + ns2
/2

= e
−β
2
/2n
,
which concludes the proof.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Pre2.4 Chernoff–Cramér Method 51
Observe the similarity between (2.4.5) and the Gaussian bound (2.4.4) if one takes ν to
be the variance of Sn, that is,
ν = Var[Sn] = nVar[Z1] = nE[Z
2
1
] = n,
where we used that Z1 is centered. The central limit theorem says that simple random walk is
well approximated by a Gaussian in the “bulk” of the distribution; the bound above extends
the approximation in the “large deviation” regime. The bounding technique used in the proof
of Lemma 2.4.3 will be substantially extended in Section 2.4.2.
Example 2.4.4 (Set balancing). Let v1, . . . , vm be arbitrary non-zero vectors in {0, 1}
n
. Think
of vi = (vi,1, . . . , vi,n) as representing a subset of [n] = {1, . . . , n}: vi, j = 1 indicates that
j is in subset i. Suppose we want to partition [n] into two groups such that the subsets
corresponding to the vis are as balanced as possible, that is, are as close as possible to
having the same number of elements from each group. More formally, we seek a vector
x = (x1, . . . , xn) ∈ {−1, +1}
n
such that B
∗ = maxi=1,...,m |x · vi
| is as small as possible.
A simple random choice does well: select each xi
independently, uniformly at random in
{−1, +1}. Fix ε > 0. We claim that
P
h
B
∗ ≥
p
2n(log m + log(2ε
−1
))i
≤ ε. (2.4.7)
Indeed, by (2.4.5) (considering only the non-zero entries of vi),
P
h
|x · vi
| ≥ p
2n(log m + log(2ε
−1
))i
≤ 2 exp
−
2n(log m + log(2ε
−1
))
2kvik1

≤
ε
m
,
where we used that kvik1 ≤ n. Taking a union bound over the m vectors gives the result.
In (2.4.7), the √
n term on the right-hand side of the inequality is to be expected since it
is the standard deviation of |x · vi
| in the worst case. The power of the exponential tail
bound (2.4.5) appears in the logarithmic terms, which would have been much larger if one
had used Chebyshev’s inequality instead. J
The Chernoff–Cramér bound is particularly useful for sums of independent random
variables as the moment-generating function then factorizes; see (2.1.3). Let
9
∗
X
(β) = sup
s∈R+
(sβ − 9X (s))
be the Fenchel–Legendre dual of the cumulant-generating function of X. FENCHEL–
LEGENDRE
Theorem 2.4.5 (Chernoff–Cramér method). Let Sn = DUAL P
i≤n Xi
, where the Xis are i.i.d. ran￾dom variables. Assume MX1
(s) < +∞ on s ∈ (−s0,s0) for some s0 > 0. For any β > 0,
P[Sn ≥ β] ≤ exp
−n9
∗
X1

β
n
. (2.4.8)
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press52 Moments and Tails
In particular, in the large deviations regime, that is, when β = bn for some b > 0, we
have
− lim sup
n
1
n
log P[Sn ≥ bn] ≥ 9
∗
X1
(b). (2.4.9)
Proof By independence, we get
9
∗
Sn
(β) = sup
s>0
(sβ − n9X1
(s)) = sup
s>0
n

s

β
n

− 9X1
(s)

= n9
∗
X1

β
n

,
and then we optimize over s in (2.4.2).
We use the Chernoff–Cramér method to derive a few standard bounds.
POISSON Poisson variables We start with the Poisson case. Let Z ∼ Poi(λ) be Poisson with mean λ,
where we recall that
P[Z = k] = e
−λ
λ
k
k!
, k ∈ Z+.
Letting X = Z − λ,
9X (s) = log X
`≥0
e
−λ
λ
`
`!
e
s(`−λ)
!
= log 
e
−(1+s)λX
`≥0
(e
sλ)
`
`!
!
= log ￾
e
−(1+s)λ
e
e
sλ

= λ(e
s − s − 1),
so that straightforward calculus gives for β > 0,
9
∗
X
(β) = sup
s>0
(sβ − λ(e
s − s − 1))
= λ
1 +
β
λ

log
1 +
β
λ

−
β
λ

=: λ h

β
λ

,
achieved at sβ = log ￾
1 +
β
λ

, where h is defined as the expression in square brackets in the
above display. Plugging 9∗
X
(β) into Theorem 2.4.5 leads for β > 0 to the bound
P[Z ≥ λ + β] ≤ exp
−λ h

β
λ
. (2.4.10)
A similar calculation for −(Z − λ) gives for β < 0,
P[Z ≤ λ + β] ≤ exp
−λ h

β
λ
. (2.4.11)
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Pre2.4 Chernoff–Cramér Method 53
If Sn is a sum of n i.i.d. Poi(λ) variables, then by (2.4.9) for a > λ,
− lim sup
n
1
n
log P[Sn ≥ an] ≥ λ h

a − λ
λ

= a log  a
λ

− a + λ
=: I
Poi
λ
(a), (2.4.12)
and similarly for a < λ,
− lim sup
n
1
n
log P[Sn ≤ an] ≥ I
Poi
λ
(a). (2.4.13)
In fact, these bounds follow immediately from (2.4.10) and (2.4.11) by noting that Sn ∼
Poi(nλ) (see, for example, Exercise 6.7).
Binomial variables and Chernoff bounds Let Z ∼ Bin(n, p) be a binomial random varia- BINOMIAL
ble with parameters n and p. Recall that Z is a sum of i.i.d. indicators Y1, . . . , Yn equal to 1
with probability p. The Yis are also known as Bernoulli random variables or Bernoulli trials, BERNOULLI
and their law is denoted by Ber( p). We also refer to p as the success probability. Letting
Xi = Yi − p and Sn = Z − np,
9X1
(s) = log ( pes + (1 − p)) − ps.
For b ∈ (0, 1 − p), letting a = b + p, direct calculation gives
9
∗
X1
(b) = sup
s>0
(sb − (log [pes + (1 − p)] − ps))
= (1 − a) log
1 − a
1 − p
+ a log
a
p
=: D(akp), (2.4.14)
achieved at sb = log (1−p)a
p(1−a)
. The function D(akp) in (2.4.14) is the so-called Kullback–Leibler KULLBACK–
LEIBLER
DIVERGENCE
divergence or relative entropy between two Bernoulli variables with parameters a and p,
respectively. By (2.4.8) for β > 0,
P[Z ≥ np + β] ≤ exp (−n D ( p + β/nkp)).
Applying the same argument to Z
0 = n − Z gives a bound in the other direction.
Remark 2.4.6 In the large deviations regime, it can be shown that the previous bound is
tight in the sense that
−
1
n
log P[Z ≥ np + bn] → D ( p + bkp) =: I
Bin
n,p
(b),
as n → +∞. The theory of large deviations provides general results of this type. See, for
example, [Dur10, section 2.6]. Upper bounds will be enough for our purposes.
The following related bounds, proved in Exercise 2.7, are often useful.
Theorem 2.4.7 (Chernoff bounds for Poisson trials). Let Y1, . . . , Yn be independent {0, 1}-
valued random variables with P[Yi = 1] = pi and µ =
P
i
pi
. These are called Poisson POISSON
trials. Let Z = TRIALS P
i
Yi
. Then:
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press54 Moments and Tails
(i) Above the mean
(a) For any δ > 0,
P[Z ≥ (1 + δ)µ] ≤

e
δ
(1 + δ)
(1+δ)
µ
.
(b) For any 0 < δ ≤ 1,
P[Z ≥ (1 + δ)µ] ≤ e
−µδ2
/3
.
(ii) Below the mean
(a) For any 0 < δ < 1,
P[Z ≤ (1 − δ)µ] ≤

e
−δ
(1 − δ)
(1−δ)
µ
.
(b) For any 0 < δ < 1,
P[Z ≤ (1 − δ)µ] ≤ e
−µδ2
/2
.
2.4.2 Sub-Gaussian and Sub-Exponential Random Variables
The bounds in Section 2.4.1 were obtained by computing the moment-generating function
explicitly (possibly with some approximations). This is not always possible. In this section,
we give some important examples of tail bounds derived from the Chernoff–Cramér method
for broad classes of random variables under natural conditions on their distributions.
Sub-Gaussian random variables
We begin with sub-Gaussian random variables which, as the name suggests, have a tail that
is bounded by that of a Gaussian.
General case Here is our key definition.
SUB- Definition 2.4.8 (Sub-Gaussian random variables). We say that a random variable X with
GAUSSIAN
VARIABLE
mean µ is sub-Gaussian with variance factor ν if
9X−µ(s) ≤
s
2
ν
2
∀s ∈ R (2.4.15)
for some ν > 0. We use the notation X ∈ sG(ν).
Note that the right-hand side in (2.4.15) is the cumulant-generating function of a N(0, ν).
By the Chernoff–Cramér method and (2.4.3) it follows immediately that
P [X − µ ≤ −β] ∨ P [X − µ ≥ β] ≤ exp
−
β
2
2ν

, (2.4.16)
where we used that X ∈ sG(ν) implies −X ∈ sG(ν). As a quick example, note that this is
the approach we took in Lemma 2.4.3, that is, we showed that a uniform random variable in
{−1, 1} (i.e., a Rademacher variable) is sub-Gaussian with variance factor 1.
When considering (weighted) sums of independent sub-Gaussian random variables, we
get the following.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.4 Chernoff–Cramér Method 55
Theorem 2.4.9 (General Hoeffding inequality). Suppose X1, . . . , Xn are independent ran￾dom variables where, for each i, Xi ∈ sG(νi) with 0 < νi < +∞. For w1, . . . ,wn ∈ R, let
Sn =
P
i≤n wiXi
. Then
Sn ∈ sG
 Xn
i=1
w
2
i
νi
!
.
In particular, for all β > 0,
P [Sn − ESn ≥ β] ≤ exp
−
β
2
2
Pn
i=1 w
2
i
νi

.
Proof Assume the Xis are centered. By independence and (2.1.3),
9Sn
(s) =
X
i≤n
9wiXi
(s) =
X
i≤n
9Xi
(swi) ≤
X
i≤n
(swi)
2
νi
2
=
s
2 P
i≤n w
2
i
νi
2
.
Bounded random variables For bounded random variables, the previous inequality reduces
to a standard bound.
Theorem 2.4.10 (Hoeffding’s inequality for bounded variables). Let X1, . . . , Xn be inde￾pendent random variables where, for each i, Xi
takes values in [ai
, bi] with −∞ < ai ≤ bi <
+∞. Let Sn =
P
i≤n Xi
. For all β > 0,
P[Sn − ESn ≥ β] ≤ exp 
−
2β
2
P
i≤n
(bi − ai)
2
!
.
By Theorem 2.4.9, it suffices to show that Xi − E Xi ∈ sG(νi) with νi =
1
4
(bi − ai)
2
. We first
give a quick proof of a weaker version that uses a trick called symmetrization. Suppose the SYMMETRIZA￾X TION is are centered and satisfy |Xi
| ≤ ci for some ci > 0. Let X
0
i
be an independent copy of Xi
and let Zi be an independent uniform random variable in {−1, 1}. For any s,
E

e
sXi

= E

e
sE[Xi−X
0
i
| Xi]

≤ E

E

e
s(Xi−X
0
i
)

 Xi

= E

e
s(Xi−X
0
i
)

,
where the first line comes from the taking out what is known lemma (Lemma B.6.16)
and the fact that X
0
i
is centered and independent of Xi
, the second line follows from the
conditional Jensen’s inequality (Lemma B.6.12), and the third line uses the tower prop￾erty (Lemma B.6.16). Observe that Xi − X
0
i
is symmetric, that is, identically distributed to
−(Xi − X
0
i
). Hence, using that Zi
is independent of both Xi and X
0
i
, we get
E

e
s(Xi−X
0
i
)

= E

E

e
s(Xi−X
0
i
)

 Zi

= E

E

e
sZi(Xi−X
0
i
)

 Zi

= E

e
sZi(Xi−X
0
i
)

= E

E

e
sZi(Xi−X
0
i
)

 Xi − X
0
i
.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press56 Moments and Tails
From (2.4.6) (together with Lemma B.6.15), the last line is
≤ E
h
e
(s(Xi−X
0
i
))2
/2
i
≤ e
−4c
2
i
s
2
/2
since |Xi
|, |X
0
i
| ≤ ci
. Putting everything together, we arrive at
E

e
sXi

≤ e
−4c
2
i
s
2
/2
.
That is, Xi
is sub-Gaussian with variance factor 4c
2
i
. By Theorem 2.4.9, Sn is sub-Gaussian
with variance factor P
i≤n
4c
2
i
and
P[Sn ≥ t] ≤ exp 
−
t
2
8
P
i≤n
c
2
i
!
.
Proof of Theorem 2.4.10 As pointed out above, it suffices to show that Xi − E Xi
is sub￾Gaussian with variance factor 1
4
(bi − ai)
2
. This is the content of Hoeffding’s lemma below
(which we will use again in Chapter 3). First an observation:
Lemma 2.4.11 (Variance of bounded random variables). For any random variable Z taking
values in [a, b] with −∞ < a ≤ b < +∞, we have
Var[Z] ≤
1
4
(b − a)
2
.
Proof Indeed,




Z −
a + b
2




≤
b − a
2
and
Var[Z] = Var 
Z −
a + b
2

≤ E
"
Z −
a + b
2
2
#
≤

b − a
2
2
.
HOEFFDING’S Lemma 2.4.12 (Hoeffding’s lemma). Let X be a random variable taking values in [a, b] for
LEMMA −∞ < a ≤ b < +∞. Then, X ∈ sG
￾
1
4
(b − a)
2

.
Proof Note first that X −E X ∈ [a−E X, b−E X] and 1
4
((b−E X)−(a−E X))2 =
1
4
(b−a)
2
.
So without loss of generality we assume that E X = 0. Because X is bounded, MX (s) is finite
for all s ∈ R. Hence, by (2.1.2),
9X (0) = log MX (0) = 0, 9
0
X
(0) =
M0
X
(0)
MX (0)
= E X = 0,
and by a Taylor expansion,
9X (s) = 9X (0) + s9
0
X
(0) +
s
2
2
9
00
X
(s
∗
) =
s
2
2
9
00
X
(s
∗
)
for some s
∗ ∈ [0,s]. Therefore, it suffices to show that for all s,
9
00
X
(s) ≤
1
4
(b − a)
2
. (2.4.17)
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Pres2.4 Chernoff–Cramér Method 57
Note that
9
00
X
(s) =
M00
X
(s)
MX (s)
−

M0
X
(s)
MX (s)
2
=
1
MX (s)
E

X
2
e
sX 
−

1
MX (s)
E

XesX 
2
= E

X
2
e
sX
MX (s)

−

E

X
e
sX
MX (s)
2
.
The trick to conclude is to notice that e
sx
MX (s)
defines a density on [a, b] with respect to the
law of X. The variance under this density – the last line above – is less than 1
4
(b − a)
2 by
Lemma 2.4.11. This establishes (2.4.17) and concludes the proof.
Remark 2.4.13 The change of measure above is known as tilting and is a standard trick in
large deviation theory. See, for example, [Dur10, section 2.6].
Since we have shown that Xi − E Xi
is sub-Gaussian with variance factor 1
4
(bi − ai)
2
,
Theorem 2.4.10 follows from Theorem 2.4.9.
Sub-exponential random variables
Unfortunately, not every random variable of interest is sub-Gaussian. A simple example is
the square of a Gaussian variable. Indeed, suppose X ∼ N(0, 1). Then W = X
2
is χ
2
-
distributed and its moment-generating function can be computed explicitly. Using the change
of variable u = x
√
1 − 2s, for s < 1/2,
MW (s) =
1
√
2π
Z +∞
−∞
e
sx2
e
−x
2
/2
dx
=
1
√
1 − 2s
×
1
√
2π
Z +∞
−∞
e
−u
2
/2
du
=
1
(1 − 2s)
1/2
. (2.4.18)
When s ≥ 1/2, however, we clearly have MW (s) = +∞. In particular, W cannot be sub￾Gaussian for any variance factor ν > 0. (Note that centering W produces an additional factor
of e
−s
in the moment-generating function which does not prevent it from diverging.) Further
confirming this observation, arguing as in (2.4.1), the upper tail of W decays as
P[W ≥ β] = P[X ≥
p
β]
∼
r
1
2π
[
p
β]
−1
exp(−[
p
β]
2
/2)
∼
s
1
2πβ
exp(−β/2),
as β → +∞. That is, it decays exponentially with β, but much slower than the Gaussian
tail.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press58 Moments and Tails
General case We now define a broad class of distributions which have such exponential tail
decay.
SUB- Definition 2.4.14 (Sub-exponential random variable). We say that a random variable X with
EXPONENTIAL
VARIABLE
mean µ is sub-exponential with parameters (ν, α) if
9X−µ(s) ≤
s
2
ν
2
∀|s| ≤
1
α
(2.4.19)
for some ν, α > 0. We write X ∈ sE(ν, α).
1
Observe that the key difference between (2.4.15) and (2.4.19) is the interval of s over which
it holds. As we will see, the parameter α dictates the exponential decay rate of the tail. The
specific form of the bound in (2.4.19) is natural once one notices that, as |s| → 0, a centered
random variable with variance ν should roughly satisfy
log E[e
sX ] ≈ log 
1 + sE[X] +
s
2
2
E[X
2
]

≈ log 
1 +
s
2
ν
2

≈
s
2
ν
2
.
Returning to the χ
2 distribution, note that from (2.4.18) we have for |s| ≤ 1/4:
9W−1(s) = −s −
1
2
log(1 − 2s)
= −s −
1
2
"
−
X
+∞
i=1
(2s)
i
i
#
=
s
2
2
"
4
X
+∞
i=2
(2s)
i−2
i
#
≤
s
2
2
"
2
X
+∞
i=2
|1/2|
i−2
#
≤
s
2
2
× 4.
Hence, W ∈ sE(4, 4).
Using the Chernoff–Cramér bound (Lemma 2.4.2), we obtain the following tail bound for
sub-exponential variables.
Theorem 2.4.15 (Sub-exponential tail bound). Suppose the random variable X with mean
µ is sub-exponential with parameters (ν, α). Then, for all β ∈ R+,
P[X − µ ≥ β] ≤
(
exp(−
β
2
2ν
) if 0 ≤ β ≤ ν/α,
exp(−
β
2α
) if β > ν/α.
(2.4.20)
In words, the tail decays exponentially fast at large deviations but behaves as in the sub￾Gaussian case for smaller deviations. We will see that this awkward double-tail allows to
extrapolate naturally between different regimes. First we prove the claim.
Proof of Theorem 2.4.15 We start by applying the Chernoff–Cramér bound. For any β > 0
and |s| ≤ 1/α,
P[X − µ ≥ β] ≤ exp (−sβ + 9X (s)) ≤ exp ￾
−sβ + s
2
ν/2

.
1 More commonly, “sub-exponential” refers to the case α =
√
ν.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Pres2.4 Chernoff–Cramér Method 59
At this point, the proof diverges from the sub-Gaussian case because the optimal choice of
s depends on β because of the additional constraint |s| ≤ 1/α. When s
∗ = β/ν satisfies
s
∗ ≤ 1/α, the quadratic function of s in the exponent is minimized at s
∗
, giving the bound
P[X ≥ β] ≤ exp
−
β
2
2ν

for 0 ≤ β ≤ ν/α.
On the other hand, when β > ν/α, the exponent is strictly decreasing over the interval
s ≤ 1/α. Hence, the optimal choice is s
∗ = 1/α, which produces the bound
P[X ≥ β] ≤ exp
−
β
α
+
ν
2α
2

< exp
−
β
α
+
β
2α

= exp
−
β
2α

,
where we used that ν < βα on the second line.
For (weighted) sums of independent sub-exponential random variables, we get the
following.
Theorem 2.4.16 (General Bernstein inequality). Suppose X1, . . . , Xn are independent ran￾dom variables where, for each i, Xi ∈ sE(νi
, αi) with 0 < νi
, αi < +∞. For w1, . . . ,wn ∈ R,
let Sn =
P
i≤n wiXi
. Then,
Sn ∈ sE
 Xn
i=1
w
2
i
νi
, max
i
|wi
|αi
!
.
In particular, for all β > 0,
P [Sn − ESn ≥ β] ≤



exp 
−
β
2
2
Pn
i=1 w
2
i
νi

if 0 ≤ β ≤
Pn
i=1 w
2
i
νi
maxi
|wi
|αi
,
exp 
−
β
2 maxi
|wi
|αi

if β >
Pn
i=1 w
2
i
νi
maxi
|wi
|αi
.
Proof Assume the Xis are centered. By independence and (2.1.3),
9Sn
(s) =
X
i≤n
9wiXi
(s) =
X
i≤n
9Xi
(swi) ≤
X
i≤n
(swi)
2
νi
2
=
s
2 P
i≤n w
2
i
νi
2
,
provided |swi
| ≤ 1/αi for all i, that is,
|s| ≤
1
maxi
|wi
|αi
.
Bounded random variables: revisited We apply the previous result to bounded random
variables.
Theorem 2.4.17 (Bernstein’s inequality for bounded variables). Let X1, . . . , Xn be inde￾pendent random variables, where, for each i, Xi has mean µi
, variance νi
, and satisfies
|Xi − µi
| ≤ c for some 0 < c < +∞. Let Sn =
P
i≤n Xi
. For all β > 0,
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press60 Moments and Tails
P [Sn − ESn ≥ β] ≤
(
exp 
−
β
2
4
Pn
i=1
νi

if 0 ≤ β ≤
Pn
i=1
νi
c
,
exp ￾
−
β
4c

if β >
Pn
i=1
νi
c
.
Proof We claim that Xi ∈ sE(2νi
, 2c). To establish the claim, we derive a bound on all
moments of Xi
. Note that for all integers k ≥ 2,
E|Xi − µi
|
k ≤ c
k−2E|Xi − µi
|
2 = c
k−2
νi
.
Hence, first applying the dominated convergence theorem (Proposition B.4.14) to establish
the limit, we have for |s| ≤ 1
2c
,
E[e
s(Xi−µi)
] =
X
+∞
k=0
s
k
k!
E[(Xi − µi)
k
]
≤ 1 + s E[(Xi − µi)] +
X
+∞
k=2
s
k
k!
c
k−2
νi
≤ 1 +
s
2
νi
2
+
s
2
νi
3!
X
+∞
k=3
(cs)
k−2
= 1 +
s
2
νi
2

1 +
1
3
cs
1 − cs
≤ 1 +
s
2
νi
2

1 +
1
3
1/2
1 − 1/2

≤ 1 +
s
2
2
2νi
≤ exp
s
2
2
2νi

.
Using the general Bernstein inequality (Theorem 2.4.16) gives the result.
It may seem counter-intuitive to derive a tail bound based on the sub-exponential prop￾erty of bounded random variables when we have already done so using their sub-Gaussian
behavior. After all, the latter is on the surface a strengthening of the former. However, note
that we have obtained a better bound in Theorem 2.4.17 than we did in Theorem 2.4.10 –
when β is not too large. That improvement stems from the use of the (actual) variance for
moderate deviations. This is easier to appreciate through an example.
Example 2.4.18 (Erdos–Rényi: maximum degree). Let ˝ Gn = (Vn, En) ∼ Gn,pn be a random
graph with n vertices and density pn under the Erdos–Rényi model (Definition ˝ 1.2.2). Recall
that two vertices u, v ∈ Vn are adjacent if {u, v} ∈ En and that the set of adjacent vertices
of v, denoted by N(v), is called the neighborhood of v. The degree of v is the size of its
neighborhood, that is, δ(v) = |N(v)|. Here we study the maximum degree of Gn,
Dn = max
v∈Vn
δ(v).
We focus on the regime npn = ω(log n). Note that for any vertex v ∈ Vn, its degree is Bin(n−
1, pn) by independence of the edges. In particular, its expected degree is (n − 1)pn. To prove
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Pres2.4 Chernoff–Cramér Method 61
a high-probability upper bound on the maximum Dn, we need to control the deviation of the
degree of each vertex from its expectation. Observe that the degrees are not independent.
Instead, we apply a union bound over all vertices, after using a tail bound.
Claim 2.4.19 For any ε > 0, as n → +∞,
P
h
|Dn − npn| ≥ 2
p
(1 + ε)npn log n
i
→ 0.
Proof For a fixed vertex v, think of δ(v) = Sn−1 ∼ Bin(n − 1, pn) as a sum of n − 1
independent
P
{0, 1}-valued random variables, one for each possible edge. That is, Sn−1 =
n−1
i=1 Xi
, where Xi
is a bounded random variable. The mean of Xi
is pn and its variance is
pn(1 − pn). So in Bernstein’s inequality (Theorem 2.4.17), we can take µi
:= pn, νi
:=
pn(1 − pn), and c := 1 for all i. We get
P [Sn−1 ≥ (n − 1)pn + β] ≤
(
exp 
−
β
2
4ν

if 0 ≤ β ≤ ν,
exp ￾
−
β
4

if β > ν,
where ν = (n − 1)pn(1 − pn) = ω(log n) by assumption. We choose β to be the smallest
value that will produce a tail probability less than n
−1−ε
for ε > 0, that is,
β =
p
4(n − 1)pn(1 − pn) ×
p
(1 + ε) log n = o(ν),
which falls in the lower regime of the tail bound. In particular, β = o(npn) (i.e., the deviation
is much smaller than the expectation). Finally, by a union bound over v ∈ Vn,
P
h
Dn ≥ (n − 1)pn +
p
4(1 + ε)pn(1 − pn)(n − 1) log n
i
≤ n ×
1
n
1+ε → 0.
The same holds in the other direction. That proves the claim.
Had we used Hoeffding’s inequality (Theorem 2.4.10) in the proof of Claim 2.4.19 we
would have had to take β =
√
(1 + ε)n log n. That would have produced a much weaker
bound when pn = o(1). Indeed, the advantage of Bernstein’s inequality is that it makes
explicit use of the variance, which when pn = o(1) is much smaller than the worst case for
bounded variables. J
2.4.3 F Probabilistic Analysis of Algorithms: Knapsack Problem
In a knapsack problem, we have n items. Item i has weight Wi and value Vi
. Given a weight
bound W, we want to pack as valuable a collection of items in the knapsack under the
constraint that the total weight is less than or equal to W. Formally, we seek a solution to
the optimization problem
Z
∗ = max



Xn
j=1
xjVj
: x1, . . . , xn ∈ [0, 1], Xn
j=1
xjWj ≤ W



. (2.4.21)
This is the fractional knapsack problem, where we allow a fraction of an item to be added to KNAPSACK
the knapsack. PROBLEM
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Pres62 Moments and Tails
Figure 2.7 Vizualization of the greedy algorithm.
It is used as a computationally tractable relaxation of the 0-1 knapsack problem, which
also includes the combinatorial constraint xj ∈ {0, 1}, ∀j. Indeed, it turns out that the
optimization problem (2.4.21) is solved exactly by a simple greedy solution (see Exercise 2.8
for a formal proof of correctness): let π be a permutation of {1, . . . , n} that puts the items in
decreasing order of value per unit weight
Vπ(1)
Wπ(1)
≥
Vπ(2)
Wπ(2)
≥ · · · ≥
Vπ(n)
Wπ(n)
;
add the items in that order until the first time the weight constraints is violated; include
whatever fraction of that last item that will fit. This greedy algorithm has a natural geometric
interpretation, depicted in Figure 2.7, that will be useful. We associate item j to a point
(Wj
, Vj) ∈ [0, 1]2
and keep only those items falling on or above a line with slope θ chosen to
satisfy the total weight constraint. Specifically, let
1θ =

j ∈ [n]: Vj > θWj
	
,
3θ =

j ∈ [n] : Vj = θWj
	
,
and
2
∗ = inf 
θ ≥ 0 : W1θ < W
	
,
where, for a subset of items J ⊂ [n], WJ =
P
j∈J Wj
.
We consider a stochastic version of the fractional knapsack problem where the weights
and values are i.i.d. random variables picked uniformly at random in [0, 1]. Characterizing
Z
∗
(e.g., its moments or distribution) is not straightforward. Here we show that Z
∗
is highly
concentrated around a natural quantity. Observe that, under our probabilistic model, almost
surely |3θ
| ∈ {0, 1} for any θ ≥ 0. Hence, there are two cases. Either 2∗ = 0, in which case
all items fit in the knapsack so that Z
∗ =
Pn
j=1 Wj
, or 2∗ > 0, in which case |32∗ | = 1 and
Z
∗ = V12∗ + (W − W12∗ )V32∗
. (2.4.22)
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.4 Chernoff–Cramér Method 63
One interesting regime is W = τn for some constant τ > 0. Clearly, τ > 1 is trivial. In
fact, because
E


Xn
j=1
Wj

 = n E[W1] =
1
2
n,
we assume that τ ≤ 1/2. To further simplify the calculations, we restrict ourselves to the
case τ ∈ (1/6, 1/2). (See Exercise 2.8 for the remaining case.) In this regime, we show that
Z
∗ grows linearly with n and give a bound on its deviation.
Although Z
∗
is technically a sum of random variables, the choice of 2∗
correlates them
and we cannot apply our concentration bounds directly. Instead, we show that 2∗
itself can
be controlled well. It is natural to conjecture that 2∗
is approximately equal to a solution θτ
of the expected constraint equation E[W1θτ
] = W, that is,
nw¯ θτ = nτ , (2.4.23)
where w¯ θ
is defined through
E[W1θ
] = E


X
j∈1θ
Wj


= E


Xn
j=1
1{Vj > θWj} Wj


= nE [1{V1 > θW1} W1]
=: nw¯ θ
.
Similarly, we define
v¯θ
:= E [1{V1 > θW1} V1] .
We see directly from the definitions that both w¯ θ and v¯θ are monotone as functions of θ.
Our main claim is the following.
Claim 2.4.20 There is a constant c > 0 such that for any δ > 0,
P
h
|Z
∗ − nv¯θτ
| ≥ p
cn log δ
−1
i
≤ δ
for all n large enough.
Proof Because all weights and values are in [0, 1], it follows from (2.4.22) that
V12∗ ≤ Z
∗ ≤ V12∗ + 1, (2.4.24)
and it will suffice to work with V12∗
. The idea of the proof is to show that 2∗
is close to θτ by
establishing that W1θ
is highly likely to be less than τn when θ > θτ
, while the opposite holds
when θ < θτ
. For this, we view W1θ
as a sum of independent bounded random variables and
use Hoeffding’s inequality (Theorem 2.4.10).
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press64 Moments and Tails
Controlling 2∗
. First, it will be useful to compute w¯ θ and θτ analytically. By definition,
w¯ θ = E [1{V1 > θW1} W1]
=
Z 1
0
Z 1
0
1{ y > θx}x dy dx
=
Z 1∧1/θ
0
(1 − θx)x dx
=
(
1
2 −
1
3
θ if θ ≤ 1,
1
6θ
2 otherwise.
(2.4.25)
Plugging back into (2.4.23), we get the unique solution
θτ
:= 3

1
2
− τ

∈ (0, 1)
for the range τ ∈ (1/6, 1/2).
Now observe that, for each fixed θ, the quantity
W1θ =
Xn
j=1
1{Vj > θWj} Wj
is a sum of independent random variables taking values in [0, 1]. Hence, for any β > 0,
Hoeffding’s inequality gives
P

W1θ − nw¯ θ ≥ β

≤ exp
−
2β
2
n

.
Using this inequality with θ = θτ −
C
√
n
(with n large enough that θ < 1) and β = 3C
√
n
gives
P

W1θτ − √C
n
− 3n

1
2
− θτ +
C
√
n

≥ 3C
√
n

≤ exp ￾
−2(3C)
2

,
where we used (2.4.25). After rearranging and using that 3n
￾
1
2 − θτ

= nτ by (2.4.23)
and (2.4.25), we get
P

2
∗ ≥ θτ −
C
√
n

= P

W1θτ − √C
n
≥ nτ

≤ exp ￾
−2(3C)
2

.
Applying the same argument to −W1θ with θ = θτ +
C
√
n
and combining with the previous
inequality gives
P

|2
∗ − θτ
| >
C
√
n

≤ 2 exp ￾
−2(3C)
2

. (2.4.26)
Controlling Z∗
. We conclude by applying Hoeffding’s inequality to V1θ
. Arguing as above
with the same θ’s and β, we obtain
P

V1θτ − √C
n
− nv¯θτ − √C
n
≥ 3C
√
n

≤ exp ￾
−2(3C)
2

(2.4.27)
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University 2.4 Chernoff–Cramér Method 65
and
P

V1θτ + √C
n
− nv¯θτ + √C
n
≤ −3C
√
n

≤ exp ￾
−2(3C)
2

. (2.4.28)
Again, it will be useful to compute v¯θ analytically. By definition,
v¯θ = E [1{V1 > θW1} V1]
=
Z 1
0
Z 1
0
1{ y > θx}y dx dy
=
Z 1∧θ
0
y
2
θ
dy +
Z 1
1∧θ
y dy
=
(
1
2 −
1
6
θ
2
if θ ≤ 1,
1
3θ
otherwise.
Assuming n is large enough that θτ + C/
√
n < 1 (recall that θτ < 1), we get
v¯θτ − ¯vθτ + √C
n
=
1
6

2
C
√
n
θτ +
C
2
n

≤
C
√
n
.
A quick check reveals that, similarly, v¯θτ − √C
n
− ¯vθτ ≤
C
√
n
. Plugging back into (2.4.27)
and (2.4.28) gives
P

V1θτ − √C
n
≥ nv¯θτ + 4C
√
n

≤ exp ￾
−2(3C)
2

(2.4.29)
and
P

V1θτ + √C
n
≤ nv¯θτ − 4C
√
n

≤ exp ￾
−2(3C)
2

. (2.4.30)
Observe that the following monotonicity property holds almost surely
θ0 ≤ θ1 ≤ θ2 =⇒ V1θ0
≥ V1θ1
≥ V1θ2
. (2.4.31)
Combining (2.4.24), (2.4.26), (2.4.29), (2.4.30), and (2.4.31), we obtain
P

Z
∗ − nv¯θτ

 > 5C
√
n

≤ 4 exp ￾
−2(3C)
2

for n large enough. Choosing C appropriately gives the claim.
A similar bound is proved for the 0-1 knapsack problem in Exercise 2.9.
2.4.4 Epsilon-Nets and Chaining
Suppose we are interested in bounding the expectation or tail of the supremum of a stochastic
process
sup
t∈T
Xt
,
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University P66 Moments and Tails
where T is an arbitrary index set and the Xts are real-valued random variables. To avoid
measurability issues, we assume throughout that T is countable.2 Note that t does not in
general need to be a “time” index.
So far we have developed tools that can handle cases where T is finite. When the supre￾mum is over an infinite index set, however, new ideas are required. One way to proceed is
to apply a tail inequality to a sufficiently dense finite subset of the index set and then extend
the resulting bound by a Lipschitz continuity argument. We present this type of approach in
this section, as well as a multi-scale version known as chaining.
First we summarize one important special case that will be useful below: T is finite and
Xt
is sub-Gaussian.
Theorem 2.4.21 (Maximal inequalities: sub-Gaussian case). Let {Xt}t∈T be a stochastic
process with finite index set T . Assume that there is ν > 0 such that, for all t, Xt ∈ sG(ν)
and E[Xt] = 0. Then,
E

sup
t∈T
Xt

≤
p
2ν log |T |,
and, for all β > 0,
P

sup
t∈T
Xt ≥
p
2ν log |T | + β

≤ exp
−
β
2
2ν

.
Proof For the expectation, we apply a variation on the Chernoff–Cramér method (Sec￾tion 2.4). Naively, we could bound the supremum supt∈T Xt by the sum P
t∈T |Xt
|, but that
would lead to a bound growing linearly with the cardinality |T |. Instead we first take an
exponential, which tends to amplify the largest term and produces a much stronger bound.
Specifically, by Jensen’s inequality (Theorem B.4.15), for any s > 0,
E

sup
t∈T
Xt

=
1
s
E

sup
t∈T
sXt

≤
1
s
log E

exp
sup
t∈T
sXt
 .
Since e
a∨b ≤ e
a + e
b by the non-negativity of the exponential, we can bound
E

sup
t∈T
Xt

≤
1
s
log "X
t∈T
E [exp (sXt)]
#
=
1
s
log "X
t∈T
MXi
(s)
#
≤
1
s
log h
|T | e
s
2ν
2
i
=
log |T |
s
+
sν
2
.
2 Technically, it suffices to assume that there is a countable T0 ⊆ T such that supt∈T Xt = supt∈T0
Xt almost
surely.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.4 Chernoff–Cramér Method 67
The optimal choice of s (i.e., leading to the least bound) is when the two terms in the sum
above are equal, that is, s =
p
2ν
−1
log |T |, which gives finally
E

sup
t∈T
Xt

≤
p
2ν log |T |,
as claimed.
For the tail inequality, we use a union bound and (2.4.16):
P

sup
t∈T
Xt ≥
p
2ν log |T | + β

≤
X
t∈T
P
h
Xt ≥
p
2ν log |T | + β
i
≤ |T | exp 
−
(
p
2ν log |T | + β)
2
2ν
!
≤ exp
−
β
2
2ν

,
as claimed, where we used that β > 0 on the last line.
Epsilon-nets and covering numbers
Moving on to infinite index sets, we first define the notion of an ε-net. This notion requires
that a pseudometric ρ (i.e., ρ : T × T → R+ is symmetric and satisfies the triangle ine￾quality) be defined over T .
Definition 2.4.22 (ε-net). Let T be a subset of a pseudometric space (M, ρ) and let ε > 0.
The collection of points N ⊆ M is called an ε-net of T if ε-NET
T ⊆
[
t∈N
Bρ(t, ε),
where Bρ(t, ε) = {s ∈ T : ρ(s, t) ≤ ε}, that is, each element of T is within distance ε of an
element in N. The smallest cardinality of an ε-net of T is called the covering number COVERING
NUMBER N (T , ρ, ε) = inf{|N|: N is an ε-net of T }.
A natural way to construct an ε-net is the following algorithm. Start with N = ∅ and succes￾sively add a point from T to N at distance at least ε from all other previous points until it is
not possible to do so anymore. Provided T is compact, this procedure will terminate after a
finite number of steps. This leads to the following dual perspective.
Definition 2.4.23 (ε-packing). Let T be a subset of a pseudometric space (M, ρ) and let
ε > 0. The collection of points N ⊆ T is called an ε-packing of T if
t ∈/ Bρ(t
0
, ε) ∀t 6= t
0 ∈ N,
that is, every pair of elements of N is at distance strictly greater than ε. The largest cardi￾nality of an ε-packing of T is called the packing number PACKING
NUMBER
P(T , ρ, ε) = sup{|N|: N is an ε-packing of T }.
Lemma 2.4.24 (Covering and packing numbers). For any T ⊆ M and all ε > 0,
N (T , ρ, ε) ≤ P(T , ρ, ε).
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press68 Moments and Tails
Proof Observe that a maximal ε-packing N is an ε-net. Indeed, by maximality, any element
of T \ N is at distance at most ε from an element of N.
Example 2.4.25 (Sphere in R
k
). We let B
k
(x, ε) be the ball of radius ε around x ∈ R
k with
the Euclidean metric. We let S := S
k−1 be the sphere of radius 1 centered around the origin
0, that is, the surface of B
k
(0, 1). Let 0 < ε < 1.
Claim 2.4.26
N (S, ρ, ε) ≤

3
ε
k
.
Proof Let N be any maximal ε-packing of S. We show that |N| ≤ (3/ε)
k
, which implies the
claim by Lemma 2.4.24. The balls of radius ε/2 around points in N, {B
k
(xi
, ε/2): xi ∈ N},
satisfy two properties:
1. They are pairwise disjoint: if z ∈ B
k
(xi
, ε/2) ∩ B
k
(xj
, ε/2), then kxi − xjk2 ≤ kxi − zk2 +
kxj − zk2 ≤ ε, a contradiction.
2. They are included in the ball of radius 3/2 around the origin: if z ∈ B
k
(xi
, ε/2), then
kzk2 ≤ kz − xik2 + kxik ≤ ε/2 + 1 ≤ 3/2.
The volume of a ball of radius ε/2 is π
k/2
(ε/2)k
0(k/2+1) and that of a ball of radius 3/2 is π
k/2
(3/2)k
0(k/2+1) .
Dividing one by the other proves the claim.
This bound will be useful later. J
The basic approach to use an ε-net for controlling the supremum of a stochastic process
LIPSCHITZ is the following. We say that a stochastic process {Xt}t∈T is Lipschitz for pseudometric ρ on
PROCESS T if there is a random variable 0 < K < +∞ such that
|Xt − Xs
| ≤ Kρ(s, t), ∀s, t ∈ T .
If in addition Xt
is sub-Gaussian for all t, then we can bound the expectation or tail proba￾bility of the supremum of {Xt}t∈T – if we can bound the expectation or tail probability of
the (random) Lipschitz constant K itself. To see this, let N be an ε-net of T and, for each
t ∈ T , let π(t) be the closest element of N to t. We will refer to π as the projection map of
N. We then have the inequality
sup
t∈T
Xt ≤ sup
t∈T
(Xt − Xπ(t)) + sup
t∈T
Xπ(t) ≤ Kε + sup
s∈N
Xs
, (2.4.32)
where we can use Theorem 2.4.21 to bound the last term. We give an example of this type
of argument next (although we do not apply the above bound directly). Another example
(where (2.4.32) is used this time) can be found in Section 2.4.5.
Example 2.4.27 (Spectral norm of a random matrix). For an m × n matrix A ∈ R
m×n
SPECTRAL , the
NORM spectral norm (or induced 2-norm, or 2-norm for short) is defined as
kAk2 := sup
x∈Rn\{0}
kAxk2
kxk2
= sup
x∈S
n−1
kAxk2 = sup
x∈S
n−1
y∈S
m−1
hAx, yi, (2.4.33)
where S
n−1
is the sphere of Euclidean radius 1 around the origin in R
n
. The rightmost ex￾pression, which is central to our developments, is justified in Exercise 5.4.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.4 Chernoff–Cramér Method 69
We will be interested in the case where A is a random matrix with independent entries.
One key observation is that the quantity hAx, yi can then be seen as a linear combination of
independent random variables
hAx, yi = X
i, j
xiyjAij.
Hence we will be able to apply our previous tail bounds. However, we also need to deal with
the supremum.
Theorem 2.4.28 (Upper tail of the spectral norm). Let A ∈ R
m×n be a random matrix whose
entries are centered, independent, and sub-Gaussian with variance factor ν. Then there
exists a constant 0 < C < +∞ such that, for all t > 0,
kAk2 ≤ C
√
ν(
√
m +
√
n + t),
with probability at least 1 − e
−t
2
.
Without the independence assumption, the norm can be much larger in general (see Exer￾cise 2.15).
Proof Fix ε = 1/4. By Claim 2.4.26, there is an ε-net N (respectively M) of S
n−1
(respec￾tively S
m−1
) with |N| ≤ 12n
(respectively |M| ≤ 12m
). We proceed in two steps:
1. We first apply the general Hoeffding inequality (Theorem 2.4.9) to control the deviations
of the supremum in (2.4.33) restricted to N and M.
2. We then extend the bound to the full supremum by Lipschitz continuity.
Formally, the result follows from the following two lemmas.
Lemma 2.4.29 (Spectral norm: ε-net). Let N and M be as above. For C large enough, for
all t > 0,
P

 max
x∈N
y∈M
hAx, yi ≥
1
2
C
√
ν(
√
m +
√
n + t)

 ≤ e
−t
2
.
Lemma 2.4.30 (Spectral norm: Lipschitz constant). For any ε-nets N and M of S
n−1 and
S
m−1
, respectively, the following inequalities hold:
sup
x∈N
y∈M
hAx, yi ≤ kAk2 ≤
1
1 − 2ε
sup
x∈N
y∈M
hAx, yi.
Proof of Lemma 2.4.29 Recall that
hAx, yi = X
i, j
xiyjAij
is a linear combination of independent random variables. By the general Hoeffding inequal￾ity, hAx, yi is sub-Gaussian with variance factor
X
i, j
(xiyj)
2
ν = kxk
2
2
kyk
2
2
ν = ν
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press70 Moments and Tails
for all x ∈ N and y ∈ M. In particular, for all β > 0,
P [hAx, yi ≥ β] ≤ exp
−
β
2
2ν

.
Hence, by a union bound over N and M,
P

 max
x∈N
y∈M
hAx, yi ≥
1
2
C
√
ν(
√
m +
√
n + t)


≤
X
x∈N
y∈M
P

hAx, yi ≥
1
2
C
√
ν(
√
m +
√
n + t)

≤ |N||M| exp 
−
1
2ν

1
2
C
√
ν(
√
m +
√
n + t)
2
!
≤ 12n+m
exp
−
C
2
8

m + n + t
2
	

≤ e
−t
2
for C
2
/8 = log 12 ≥ 1, where in the third inequality we ignored all cross-products since
they are non-negative.
Proof of Lemma 2.4.30 The first inequality is immediate by definition of the spectral norm.
For the second inequality, we will use the following observation:
hAx, yi − hAx0, y0i = hAx, y − y0i + hA(x − x0), y0i. (2.4.34)
Fix x ∈ S
n−1
and y ∈ S
m−1
such that hAx, yi = kAk2 (which exist by compactness), and let
x0 ∈ N and y0 ∈ M such that
kx − x0k2 ≤ ε and ky − y0k2 ≤ ε.
Then (2.4.34), Cauchy–Schwarz and the definition of the spectral norm imply
kAk2 − hAx0, y0i ≤ kAk2kxk2ky − y0k2 + kAk2kx − x0k2ky0k2 ≤ 2εkAk2.
Rearranging gives the claim.
Putting the two lemmas together concludes the proof of Theorem 2.4.28.
We will give an application of this bound in Section 5.1.4. J
Chaining method
We go back to the inequality
sup
t∈T
Xt ≤ sup
t∈T
(Xt − Xπ(t)) + sup
t∈T
Xπ(t)
. (2.4.35)
Previously we controlled the first term on the right-hand side with a random Lipschitz con￾stant and the second term with a maximal inequality for finite sets. Now we consider cases
where we may not have a good almost sure bound on the Lipschitz constant, but where
we can control increments uniformly in the following probabilistic sense. We say that a
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.4 Chernoff–Cramér Method 71
stochastic process {Xt}t∈T has sub-Gaussian increments on (T , ρ) if there exists a deter- SUB￾GAUSSIAN
INCREMENTS
ministic constant 0 < K < +∞ such that
Xt − Xs ∈ sG(K
2
ρ(s, t)
2
) ∀s, t ∈ T .
Even with this assumption, in (2.4.35) the first term on the right-hand side remains a supre￾mum over an infinite set. To control it, the chaining method repeats the argument above at CHAINING
progressively smaller scales, leading to the following inequality. The diameter of T , denoted METHOD
by diam(T ), is defined as
diam(T ) = sup{ρ(s, t): s, t, ∈ T }.
Theorem 2.4.31 (Discrete Dudley inequality). Let {Xt}t∈T be a zero-mean stochastic proc￾ess with sub-Gaussian increments on (T , ρ) and assume diam(T ) ≤ 1. Then
E

sup
t∈T
Xt

≤ C
X
+∞
k=0
2
−k
p
log N (T , ρ, 2−k
)
for some constant 0 ≤ C < +∞.
Proof Recall that we assume that T is countable. Let Tj ⊆ T , j ≥ 1, be a sequence of
finite sets such that Tj ↑ T . By monotone convergence (Proposition B.4.14),
E

sup
t∈T
Xt

= sup
j≥1
E
"
sup
t∈Tj
Xt
#
.
Moreover, N (Tj
, ρ, ε) ≤ N (T , ρ, ε) for any ε > 0 since Tj ⊆ T . Hence, it suffices to
handle the case |T | < +∞.
ε-nets at all scales. For each k ≥ 0, let Nk be an 2−k
-net of T with |Nk
| = N (T , ρ, 2−k
)
and projection map πk
. Because diam(T ) ≤ 1, N0 = {t0}, where t0 ∈ T can be taken
arbitrarily. Moreover, because T is finite, there is 1 ≤ κ < +∞ such that Nk = T for all
k ≥ κ. In particular, πκ (t) = t for all t ∈ T . By a telescoping argument,
Xt = Xt0 +
Xκ−1
k=0
￾
Xπk+1(t) − Xπk (t)

.
Taking a supremum and then an expectation gives
E

sup
t∈T
Xt

≤
Xκ−1
k=0
E

sup
t∈T
￾
Xπk+1(t) − Xπk (t)


, (2.4.36)
where we used E[Xt0
] = 0.
Sub-Gaussian bound. We use the maximal inequality (Theorem 2.4.21) to bound the expec￾tation in (2.4.36). For each k, the number of distinct elements in the supremum is at most

{(πk (t), πk+1(t)): t ∈ T }

 ≤ |Nk × Nk+1|
= |Nk
| × |Nk+1|
≤ (N (T , ρ, 2−k−1
))2
.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Pre72 Moments and Tails
For any t ∈ T , by the triangle inequality,
ρ(πk (t), πk+1(t)) ≤ ρ(πk (t), t) + ρ(t, πk+1(t)) ≤ 2
−k + 2
−k−1 ≤ 2
−k+1
,
so that
Xπk+1(t) − Xπk (t) ∈ sG(K
2
2
−2k+2
)
for some 0 < K < +∞ by the sub-Gaussian increments assumption. We can therefore
apply Theorem 2.4.21 to get
E

sup
t∈T
￾
Xπk+1(t) − Xπk (t)


≤
p
2K22
−2k+2
log(N (T , ρ, 2−k−1
)
2
)
≤ C2
−k−1
p
log N (T , ρ, 2−k−1
)
for some constant 0 ≤ C < +∞.
To finish the argument, we plug back into (2.4.36),
E

sup
t∈T
Xt

≤
Xκ−1
k=0
C2
−k−1
p
log N (T , ρ, 2−k−1
),
which implies the claim.
Using a similar argument, one can derive a tail inequality.
Theorem 2.4.32 (Chaining tail inequality). Let {Xt}t∈T be a zero-mean stochastic process
with sub-Gaussian increments on (T , ρ) and assume diam(T ) ≤ 1. Then, for all t0 ∈ T
and β > 0,
P
"
sup
t∈T
(Xt − Xt0
) ≥ C
X
+∞
k=0
2
−k
p
log N (T , ρ, 2−k
) + β
#
≤ C exp
−
β
2
C

for some constant 0 ≤ C < +∞.
We give an application of the discrete Dudley inequality in Section 2.4.6.
2.4.5 F Data Science: Johnson–Lindenstrauss Lemma and Application to
Compressed Sensing
In this section, we discuss an application of the Chernoff–Cramér method (Section 2.4.1) to
dimension reduction in data science. We use once again an ε-net argument (Section 2.4.4).
Johnson–Lindenstrauss lemma
The Johnson–Lindenstrauss lemma states roughly that, for any collection of points in a high￾dimensional Euclidean space, one can find an embedding of much lower dimension that
roughly preserves the metric relationships of the points, that is, their distances. Remarkably,
no structure is assumed on the original points and the result is independent of the input
dimension. The method of proof simply involves performing a random projection.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Pres2.4 Chernoff–Cramér Method 73
Lemma 2.4.33 (Johnson–Lindenstrauss lemma). For any set of points x
(1)
, . . . , x
(m)
in R
n
and θ ∈ (0, 1), there exists a mapping f : R
n → R
d with d = 2(θ
−2
log m) such that the
following hold: for all i, j,
(1 − θ)kx
(i) − x
( j)
k2 ≤ kf (x
(i)
) − f (x
( j)
)k2 ≤ (1 + θ)kx
(i) − x
( j)
k2. (2.4.37)
We use the probabilistic method: we derive a “distributional” version of the result that,
in turn, implies Lemma 2.4.33 by showing that a mapping with the desired properties exists
with positive probability. Before stating this claim formally, we define the explicit random
linear mapping we will employ. Let A be a d × n matrix whose entries are independent
N(0, 1). Note that, for any fixed z ∈ R
n
,
E kAzk
2
2 = E


X
d
i=1


Xn
j=1
Aijzj


2
 = d Var


Xn
j=1
A1jzj

 = dkzk
2
2
, (2.4.38)
where we used the independence of the Aijs (and, in particular, of the rows of A) and the fact
that
E


Xn
j=1
Aijzj

 = 0. (2.4.39)
Hence, the normalized mapping
L =
1
√
d
A
preserves the squared Euclidean norm “on average,” that is, E kLzk
2
2 = kzk
2
2
. We use the
Chernoff–Cramér method to prove a high-probability result.
Lemma 2.4.34 Fix δ, θ ∈ (0, 1). Then the random linear mapping L above with d =
2(θ
−2
log δ
−1
) is such that for any z ∈ R
n with kzk2 = 1,
P [|kLzk2 − 1| ≥ θ] ≤ δ. (2.4.40)
Before proving Lemma 2.4.34, we argue that it implies the Johnson–Lindenstrauss lemma
(Lemma 2.4.33). Simply take δ = 1/(2￾m
2

), apply the previous lemma to each normalized
pairwise difference z = (x
(i) − x
( j)
)/kx
(i) − x
( j)k2, and use a union bound over all ￾m
2

such
pairs. The probability that any of the inequalities (2.4.37) is not satisfied by the linear map￾ping f (z) = Lz is then at most 1/2. Hence, a mapping with the desired properties exists for
d = 2(θ
−2
log m).
Proof of Lemma 2.4.34 We prove one direction. Specifically, we establish
P [kL zk2 ≥ 1 + θ] ≤ exp
−
3
4
dθ
2

. (2.4.41)
Note that the right-hand side is ≤ δ for d = 2(θ
−2
log δ
−1
). An inequality in the other
direction can be proved similarly by working with −W below.
Recall that a sum of independent Gaussians is Gaussian (just compute the convolution
and complete the squares). So
(A z)k ∼ N(0, kzk
2
2
) = N(0, 1) ∀k,
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Pre74 Moments and Tails
where we argued as in (2.4.38) to compute the variance. Hence,
W = kAzk
2
2 =
X
d
k=1
(Az)
2
k
is a sum of squares of independent Gaussians, that is, χ
2
-distributed random variables.
By (2.4.18) and independence,
MW (s) =
1
(1 − 2s)
d/2
.
Applying the Chernoff–Cramér bound (2.4.2) with s =
1
2
(1 − d/β) gives
P[W ≥ β] ≤
MW (s)
e
sβ
=
1
e
sβ
(1 − 2s)
d/2
= e
(d−β)/2

β
d
d/2
.
Finally, take β = d(1 + θ)
2
. Rearranging we get
P[kLzk2 ≥ 1 + θ] = P[kAzk
2
2 ≥ d(1 + θ)
2
]
= P[W ≥ β]
≤ e
d[1−(1+θ)
2
]/2

(1 + θ)
2
d/2
= exp ￾
−d(θ + θ
2
/2 − log(1 + θ))
≤ exp
−
3
4
dθ
2

,
where we used log(1 + x) ≤ x − x
2
/4 on [0, 1] (see Exercise 1.16).
Remark 2.4.35 The Johnson–Lindenstrauss lemma is essentially optimal [Alo03, section
9]: any set of n points with all pairwise distances in [1 − θ, 1 + θ] requires at least (log n/
(θ
2
log θ
−1
)) dimensions. Note, however, that it relies crucially on the use of the Euclidean
norm [BC03].
To give some further geometric insights into the proof, we make a series of observations:
1. The d rows of 1
√
n
A are “on average” orthonormal. Indeed, note that for i 6= j,
E
"
1
n
Xn
k=1
AikAjk#
= E[Ai1] E[Aj1] = 0
by independence and
E
"
1
n
Xn
k=1
A
2
ik#
= E[A
2
i1
] = 1
since the Aik s have mean 0 and variance 1. When n is large, those two quantities are con￾centrated around their mean. Fix a unit vector z. Then 1
√
n
Az corresponds approximately to
an orthogonal projection of z onto a uniformly chosen random subspace of dimension d.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Pres2.4 Chernoff–Cramér Method 75
2. Now observe that projecting z on a uniform random subspace of dimension d can be done
in the following way: first apply a uniformly chosen random rotation to z; and then project
the resulting vector on the first d dimensions. In other words, 1
√
n
kAzk2 is approximately
distributed as the norm of the first d components of a uniform unit vector in R
n
. To
analyze this quantity, note that a vector in R
n whose components are independent N(0, 1),
when divided by its norm, produces a uniform vector in R
n
. When d is large, the norm of
the first d components of that vector is therefore a ratio whose numerator is concentrated
around √
d and whose denominator is concentrated around √
n (by calculations similar
to those in the first point).
3. Hence, kLzk2 =
pn
d ×
1
√
n
kAzk2 should be concentrated around 1.
The Johnson–Lindenstrauss lemma makes it possible to solve certain computational prob￾lems (e.g., finding the nearest point to a query) more efficiently by working in a smaller
dimension. We discuss a different type of application next.
Compressed sensing
In the compressed sensing problem, one seeks to recover a signal x ∈ R
n
from a small
number of linear measurements (Lx)i
, i = 1, . . . , d. In complete generality, one needs n such
measurements to recover any unknown x ∈ R
n
as the sensing matrix L must be invertible (or, SENSING
more precisely, injective). However, by imposing extra structure on the signal and choosing MATRIX
the sensing matrix appropriately, much better results can be obtained. Compressed sensing
relies on sparsity.
Definition 2.4.36 (Sparse vectors). We say that a vector z ∈ R
n
is k-sparse if it has at most K-SPARSE
k non-zero entries. We let S n VECTOR k
be the set of k-sparse vectors in R
n
. Note that S n
k
is a union
of ￾
n
k

linear subspaces, one for each support of the non-zero entries.
To solve the compressed sensing problem over k-sparse vectors, it suffices to find a sens￾ing matrix L satisfying that all subsets of 2k columns are linearly independent. Indeed, if
x, x
0 ∈ S n
k
, then x−x
0 has at most 2k non-zero entries. Hence, in order to have L(x−x
0
) = 0,
it must be that x − x
0 = 0 under the previous condition on L. That implies the required in￾jectivity. The implication goes in the other direction as well. Observe for instance that the
matrix used in the proof of the Johnson–Lindenstrauss lemma satisfies this property as long
as d ≥ 2k: because of the continuous density of its entries, the probability that 2k of its
columns are linearly dependent is 0 when d ≥ 2k. For practical applications, however, other
requirements must be met, in particular, computational efficiency. We describe such a com￾putationally efficient approach.
The following definition will play a key role. Roughly speaking, a restricted isometry
preserves enough of the metric structure of S n
k
to be invertible on its image.
Definition 2.4.37 (Restricted isometry property). A d × n linear mapping L satisfies the RESTRICTED
ISOMETRY
PROPERTY
(k, θ)-restricted isometry property (RIP) if for all z ∈ S n
k
,
(1 − θ)kzk2 ≤ kLzk2 ≤ (1 + θ)kzk2. (2.4.42)
We say that L is (k, θ)-RIP.
Given a (k, θ)-RIP matrix L, can we recover z ∈ S n
k
from Lz? And how small can d be? The
next two claims answer these questions.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Pres76 Moments and Tails
Figure 2.8 Because `
1 balls (square) have corners, minimizing the `
1 norm over a
linear subspace (line) tends to produce sparse solutions.
Lemma 2.4.38 (Sensing matrix). Let A be a d × n matrix whose entries are i.i.d. N(0, 1)
and let L =
1
√
d
A. There is a constant 0 < C < +∞ such that if d ≥ Ck log n, then L is
(10k, 1/3)-RIP with probability at least 1 − 1/n.
Lemma 2.4.39 (Sparse signal recovery). Let L be (10k, 1/3)-RIP. Then for any x ∈ S n
k
, the
unique solution to the following minimization problem
min
z∈Rn
kzk1 subject to Lz = Lx (2.4.43)
is z
∗ = x.
It may seem that a more natural alternative approach to (2.4.43) is to instead minimize
the number of non-zero entries in z, that is, kzk0. However, the advantage of the `
1 norm
is that the problem can then be formulated as a linear program, that is, the minimization
of a linear objective subject to linear inequalities (see Exercise 2.13). This permits much
faster computation of the solution using standard techniques – while still leading to a sparse
solution. See Figure 2.8 for some insights as to why `
1
indeed promotes sparsity.
Putting the two lemmas together shows we obtain the next claim:
Claim 2.4.40 Let L be as in Lemma 2.4.38 with d = 2(k log n). With probability 1 − o(1),
any x ∈ S n
k
can be recovered from the input Lx by solving (2.4.43).
Note that d can in general be much smaller than n and not far from the 2k bound we derived
above.
ε-net argument We start with the proof of Lemma 2.4.38. The claim does not follow im￾mediately from the (distributional) Johnson–Lindenstrauss lemma (i.e., Lemma 2.4.34). In￾deed, that lemma implies that a (normalized) matrix with i.i.d. standard Gaussian entries is
an approximate isometry on a finite set of points. Here we need a linear mapping that is an
approximate isometry for all vectors in S n
k
, an uncountable space.
For a subset of indices J ⊆ [n] and a vector y ∈ R
n
, we let yJ be the vector y restricted
to the entries in J, that is, the subvector (yj)j∈J
. Fix a subset of indices I ⊆ [n] of size 10k.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.4 Chernoff–Cramér Method 77
We need the RIP condition (Definition 2.4.37) to hold for all z ∈ R
n with non-zero entries
in I (and all such I). The way to achieve this is to use an ε-net argument, as described in
Section 2.4.4. Indeed, notice that, for z 6= 0, the function kLzk2/kzk2
1. does not depend on the norm of z, so that we can restrict ourselves to the compact set
∂BI
:= {z: z[n]\I = 0, kzk2 = 1}, and
2. is continuous on ∂BI
, so that it suffices to construct a fine enough covering of ∂BI by a
finite collection of balls (i.e., an ε-net) and apply Lemma 2.4.34 to the centers of those
balls.
Proof of Lemma 2.4.38 Let I ⊆ [n] be a subset of indices of size k
0
:= 10k. There are
￾
n
k
0

≤ n
k
0
= exp(k
0
log n) such subsets and we denote their collection by I(k
0
, n). We let NI
be an ε-net of ∂BI
. By Claim 2.4.26, we can choose one of size at most (3/ε)
k
0
. We take
ε =
1
C0
√
6n log n
for a constant C
0
that will be determined below. The reason for this choice will become clear
when we set C
0
. The union of all ε-nets has size

∪I∈I(k
0
,n)NI

 ≤ n
k
0

3
ε
k
0
≤ exp(C
00k
0
log n)
for some C
00 > 0. Our goal is to show that
sup
z∈∪I∈I(k
0
,n)∂BI
|kLzk2 − 1| ≤
1
3
. (2.4.44)
We seek to apply the inequality (2.4.32).
Applying Johnson–Lindenstrauss to the ε-nets: The first step is to control the supremum
in (2.4.44) – restricted to the ε-nets. Lemma 2.4.34 is exactly what we need for this. Take
θ = 1/6, δ = 1/(2n| ∪I NI
|), and
d = 2
￾
θ
−2
log(2n| ∪I NI
|)

= 2(k
0
log n),
as required by the lemma. Then, by a union bound over the NIs, with probability 1 − 1/(2n),
we have
sup
z∈∪INI
|kLzk2 − 1| ≤
1
6
. (2.4.45)
Lipschitz continuity: The next step is to establish Lipschitz continuity of |kLzk2 − 1|. For
vectors y,z ∈ R
n
, by repeated applications of the triangle inequality, we have
||kLzk2 − 1| − |kLyk2 − 1|| ≤ |kLzk2 − kLyk2| ≤ kL(z − y)k2.
To bound the rightmost expression, we let A∗ be the largest entry of A in absolute value and
note that
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Pre78 Moments and Tails
kL(z − y)k
2
2 =
X
d
i=1


Xn
j=1
Lij(zj − yj)


2
≤
X
d
i=1


Xn
j=1
L
2
ij




Xn
j=1
(zj − yj)
2


≤ dn
1
√
d
A∗
2
kz − yk
2
2
≤ nA2
∗
kz − yk
2
2
,
where we used Cauchy–Schwarz (Theorem B.4.8) on the second line. Taking the square root,
we see that the (random) Lipschitz constant of |kLzk2 − 1| (with respect to the Euclidean
metric) is at most K :=
√
nA∗.
Controlling the Lipschitz constant: So it remains to control A∗. For this we use the Chernoff–
Cramér bound for Gaussians (see (2.4.4)), which implies by a union bound over the entries
of A that
P[A∗ ≥ C
0
p
log n] ≤ P
h
∃i, j, |Aij| ≥ C
0
p
log n
i
≤ n
2
exp
−
(C
0√
log n)
2
2

≤
1
2n
for a C
0 > 0 large enough. Hence, with probability 1 − 1/(2n), we have A∗ < C
0√
log n and
Kε ≤
1
6
(2.4.46)
by the choice of ε made previously.
Putting everything together: We apply (2.4.32). Combining (2.4.45) and (2.4.46), with prob￾ability 1 − 1/n, the claim (2.4.44) holds. That concludes the proof.
`
1 minimization Finally we prove Lemma 2.4.39 (which can be skipped).
Proof of Lemma 2.4.39 Let z
∗ be a solution to (2.4.43) and note that such a solution exists
because z = x satisfies the constraint. Without loss of generality assume that only the first k
entries of x are non-zero, that is, x[n]\[k] = 0. Moreover, order the remaining entries of x so
that the residual r = z
∗ − x has its entries r[n]\[k]
in non-increasing order in absolute value.
Our goal is to show that krk2 = 0.
In order to leverage the RIP condition, we break up the vector r into 9k-long subvectors.
Let
I0 = [k], Ii = {(9(i − 1) + 1)k + 1, . . . , (9i + 1)k} ∀i ≥ 1,
and ¯Ii =
S
j>i
Ij
. We will also need I01 = I0 ∪ I1 and ¯I01 = ¯I1.
We first use the optimality of z
∗
. Note that x¯I0 = 0 implies that
kz
∗
k1 = kz
∗
I0
k1 + kz
∗
¯I0
k1 = kz
∗
I0
k1 + kr¯I0
k1
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.4 Chernoff–Cramér Method 79
and
kxk1 = kxI0
k1 ≤ kz
∗
I0
k1 + krI0
k1
by the triangle inequality. Since kz
∗k1 ≤ kxk1 by optimality (and the fact that x satisfies the
constraint), we then have
kr¯I0
k1 ≤ krI0
k1. (2.4.47)
On the other hand, the RIP condition gives a similar inequality in the other direction. In￾deed, notice that Lr = 0 by the constraint in (2.4.43) or, put differently, LrI01 = −P
i≥2
LrIi
.
Then, by the RIP condition and the triangle inequality, we have
2
3
krI01 k2 ≤ kLrI01 k2 ≤
X
i≥2
kLrIi
k2 ≤
4
3
X
i≥2
krIi
k2, (2.4.48)
where we used the fact that by construction rI01 is 10k-sparse and each rIi
is 9k-sparse.
We note that by the ordering of the entries of x,
krIi+1
k
2
2 ≤ 9k

krIi
k1
9k
2
=
krIi
k
2
1
9k
, (2.4.49)
where we bounded rIi+1
entrywise by the expression in parenthesis. Combining (2.4.47)
and (2.4.49), and using that krI0
k1 ≤
√
kkrI0
k2 by Cauchy–Schwarz, we have
X
i≥2
krIi
k2 ≤
X
j≥1
krIj
k1
√
9k
=
kr¯I0
k1
3
√
k
≤
krI0
k1
3
√
k
≤
krI0
k2
3
≤
krI01 k2
3
.
Plugging this back into (2.4.48) gives
krI01 k2 ≤ 2
X
i≥2
krIi
k2 ≤
2
3
krI01 k2,
which implies rI01 = 0. In particular, rI0 = 0 and, by (2.4.47), r¯I0 = 0 as well. We have
shown that r = 0. Or, in other words, z
∗ = x.
Remark 2.4.41 Lemma 2.4.39 can be extended to noisy measurements using a modifica￾tion of (2.4.43). This provides some robustness to noise which is important in applications.
See [CRT06b].
2.4.6 F Data Science: Classification, Empirical Risk Minimization,
and VC Dimension
In the binary classification problem, one is given samples Sn = {(Xi
,C(Xi))}
n
i=1 where Xi ∈ BINARY
R
d
is a feature vector and C(X CLASSIFICATION i) ∈ {0, 1} is a label. The feature vectors are assumed to be
independent samples from an unknown probability measure µ, and C: R
d → {0, 1} is a
measurable Boolean function. For instance, the feature vector might be an image (encoded
as a vector) and the label might indicate “cat” (label 0) or “dog” (label 1). Our goal is to
learn the function (or concept) C from the samples.
More precisely, we seek to construct a hypothesis h: R
d → {0, 1} that is a good approx- HYPOTHESIS
imation to C in the sense that it predicts the label well on a new sample (from the same
distribution). Formally, we want h to have small true risk (or generalization error): TRUE RISK
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press80 Moments and Tails
R(h) = P[h(X) 6= C(X)],
where X ∼ µ. Because we only have access to the distribution µ through the samples, it is
natural to estimate the true risk of the hypothesis h using the samples as
Rn(h) =
1
n
Xn
i=1
1{h(Xi) 6= C(Xi)},
EMPIRICAL which is called the empirical risk. Indeed, observe that ERn(h) = R(h) and, by the law of
RISK large numbers, Rn(h) → R(h) almost surely as n → +∞. Ignoring computational consider￾EMPIRICAL ations, one can then formally define an empirical risk minimizer
RISK
MINIMIZER h
∗ ∈ ERMH(Sn) = {h ∈ H: Rn(h) ≤ Rn(h
0
), ∀h
0 ∈ H},
where H, the hypothesis class, is a given collection of Boolean functions over R
d
HYPOTHESIS . We assume
CLASS further that h
∗
can be defined as a measurable function of the samples.
Overfitting Why restrict the hypothesis class? It turns out that minimizing the empirical
risk over all Boolean functions makes it impossible to achieve an arbitrarily small risk.
Intuitively considering too rich a class of functions, that is, functions that too intricately
follow the data, leads to overfitting: the learned hypothesis will fit the sampled data, but
LEARNER it may not generalize well to unseen examples. A learner A is a map from samples to
measurable Boolean functions over R
d
, that is, for any n and any Sn ∈ (R
d × {0, 1})
n
, the
learner outputs a function A( · , Sn): R
d → {0, 1}. The following theorem shows that any
learner has fundamental limitations if all concepts are possible.
Theorem 2.4.42 (No free lunch). For any learner A and any finite X ⊆ R
d of even size
|X | =: 2m > 4, there exist a concept C: X → {0, 1} and a distribution µ over X such that
P[R(A( · , Sm)) ≥ 1/8] ≥ 1/8, (2.4.50)
where Sm = {(Xi
,C(Xi))}
m
i=1 with independent Xi ∼ µ.
The gist of the proof is intuitive. In essence, if the target concept is arbitrary and we only get
to see half of the possible instances, then we have learned nothing about the other half and
cannot expect low generalization error.
Proof of Theorem 2.4.42 We let µ be uniform over X . To prove the existence of a concept
satisfying (2.4.50), we use the probabilistic method (Section 2.2.1) and pick C at random.
For each x ∈ X , we set C(x) := Yx
, where the Yxs are i.i.d. uniform in {0, 1}.
We first bound E[R(A( · , Sm))], where the expectation runs over both random labels
{Yx}x∈X and the samples Sm = {(Xi
,C(Xi))}
m
i=1
. For an additional independent sample X ∼ µ,
we will need the event that the learner, given samples Sm, makes an incorrect prediction
on X
B = {A(X, Sm)) 6= YX },
and the event that X is observed in the samples Sm
O = {X ∈ {X1, . . . , Xm}}.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.4 Chernoff–Cramér Method 81
By the tower property (Lemma B.6.16),
E[R(A( · , Sm))] = P[B]
= E[P[B | Sm]]
= E [P[B | O, Sm]P[O | Sm] + P[B | O
c
, Sm]P[O
c
| Sm]]
≥ E [P[B | O
c
, Sm]P[O
c
| Sm]]
≥
1
2
×
1
2
,
where we used that
• P[O
c
| Sm] ≥ 1/2 because |X | = 2m and µ is uniform, and
• P[B | O
c
, Sm] = 1/2 because for any x ∈ { / X1, . . . , Xm} the prediction A(x, Sm) ∈ {0, 1} is
independent of Yx and the latter is uniform.
Conditioning over the concept, we have proved that
E [E[R(A( · , Sm)) | {Yx}x∈X ]] ≥
1
4
.
Hence, by the first moment principle (Theorem 2.2.1),
P[E[R(A( · , Sm)) | {Yx}x∈X ] ≥ 1/4] > 0,
where the probability is taken over {Yx}x∈X . That is, there exists a choice { yx}x∈X ∈ {0, 1}
X
such that
E[R(A( · , Sm)) | {Yx = yx}x∈X ] ≥ 1/4. (2.4.51)
Finally, to prove (2.4.50), we use a variation on Markov’s inequality (Theorem 2.1.1)
for [0, 1]-valued random variables. If Z ∈ [0, 1] is a random variable with E[Z] = µ and
α ∈ [0, 1], then
E[Z] ≤ α × P[Z < α] + 1 × P[Z ≥ α] ≤ P[Z ≥ α] + α.
Taking α = µ/2 gives
P[Z ≥ µ/2] ≥ µ/2.
Going back to (2.4.51), we obtain
P

R(A( · , Sm)) ≥
1
8




{Yx = yx}x∈X

≥
1
8
,
establishing the claim.
The way out is to “limit the complexity” of the hypotheses. For instance, we could restrict
ourselves to half-spaces
HH =

h(x) = 1{x
T
u ≥ α}: u ∈ R
d
, α ∈ R
	
,
or axis-aligned boxes
HB = {h(x) = 1{xi ∈ [αi
, βi], ∀i}: − ∞ ≤ αi ≤ βi ≤ ∞, ∀i}.
In order for the empirical risk minimizer h
∗
to have a generalization error close to the best
achievable error, we need the empirical risk of the learned hypothesis Rn(h
∗
) to be close to
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press82 Moments and Tails
its expectation R(h
∗
), which is guaranteed by the law of large numbers for sufficiently large
n. But that is not enough, we also need that same property to hold for all hypotheses in
H simultaneously. Otherwise we could be fooled by a poorly performing hypothesis with
unusually good empirical risk on the samples. The hypothesis class is typically infinite and,
therefore, controlling empirical risk deviations from their expectations uniformly over H is
not straightforward.
Uniform deviations Our goal in this section is to show how to bound
E

sup
h∈H
{Rn(h) − R(h)}

= E
"
sup
h∈H
(
1
n
Xn
i=1
`(h, Xi) − E[`(h, X)])# (2.4.52)
in terms of a measure of complexity of the class H, where we defined the loss `(h, x) =
1{h(x) 6= C(x)} to simplify the notation. We assume that H is countable. (Observe for in￾stance that, for HH and HB, nothing is lost by assuming that the parameters defining the
hypotheses are rational-valued.)
Controlling deviations uniformly over H as in (2.4.52) allows one to provide guarantees
on the empirical risk minimizer. Indeed, for any h
0 ∈ H,
R(h
∗
) = Rn(h
∗
) + {R(h
∗
) − Rn(h
∗
)}
≤ Rn(h
∗
) + sup
h∈H
{R(h) − Rn(h)}
≤ Rn(h
0
) + sup
h∈H
{R(h) − Rn(h)}
= R(h
0
) +

Rn(h
0
) − R(h
0
)
	
+ sup
h∈H
{R(h) − Rn(h)}
≤ R(h
0
) + sup
h∈H
{Rn(h) − R(h)} + sup
h∈H
{R(h) − Rn(h)},
where, on the third line, we used the definition of the empirical risk minimizer. Taking an
infimum over h
0
, then an expectation over the samples, and rearranging gives
E[R(h
∗
)] − inf
h
0∈H
R(h
0
)
≤ E

sup
h∈H
{Rn(h) − R(h)}

+ E

sup
h∈H
{R(h) − Rn(h)}

. (2.4.53)
This inequality allows us to relate two quantities of interest: the expected true risk of the
empirical risk minimizer (i.e., E[R(h
∗
)]) and the best possible true risk (i.e., infh
0∈H R(h
0
)).
The first term on the right-hand side is (2.4.52) and the second one can be bounded in a
similar fashion as we argue below. Observe that the suprema are inside the expectations and
that the random variables Rn(h) − R(h) are highly correlated. Indeed, two similar hypotheses
will produce similar predictions. While the absence of independence in some sense makes
bounding this type expectation harder, the correlation is ultimately what allows us to tackle
infinite classes H.
To bound (2.4.52), we use the methods of Section 2.4.4. As a first step, we apply the
symmetrization trick, which we introduced in Section 2.4.2 to give a proof of Hoeffding’s
lemma (Lemma 2.4.12). Let (εi)
n
i=1
be i.i.d. uniform random variables in {−1, +1} (i.e.,
Rademacher variables) and let (X
0
i
)
n
i=1
be an independent copy of (Xi)
n
i=1
. Then,
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.4 Chernoff–Cramér Method 83
E

sup
h∈H
{Rn(h) − R(h)}

= E
"
sup
h∈H
(
1
n
Xn
i=1
`(h, Xi) − E[`(h, X)])#
= E
"
sup
h∈H
(
1
n
Xn
i=1
[`(h, Xi) − E[`(h, X
0
i
) | (Xj)
n
j=1
]])#
= E
"
sup
h∈H
E
"
1
n
Xn
i=1
[`(h, Xi) − `(h, X
0
i
)]





(Xj)
n
j=1
##
≤ E
"
sup
h∈H
(
1
n
Xn
i=1
[`(h, Xi) − `(h, X
0
i
)])# ,
where on the fourth line we used taking it out what is known (Lemma B.6.13) and on the
fifth line we used suph EYh ≤ E[suph Yh] and the tower property. Next we note that `(h, Xi)−
`(h, X
0
i
) is symmetric and independent of εi (which is also symmetric) to deduce that the last
line above is
= E
"
sup
h∈H
(
1
n
Xn
i=1
εi[`(h, Xi) − `(h, X
0
i
)])#
≤ E
"
sup
h∈H
1
n
Xn
i=1
εi`(h, Xi) + sup
h∈H
1
n
Xn
i=1
(−εi)`(h, X
0
i
)
#
= 2 E
"
sup
h∈H
1
n
Xn
i=1
εi`(h, Xi)
#
.
The exact same argument also applies to the second term on the right-hand side of (2.4.53),
so
E[R(h
∗
)] − inf
h
0∈H
R(h
0
) ≤ 4 E
"
sup
h∈H
1
n
Xn
i=1
εi`(h, Xi)
#
. (2.4.54)
Changing the normalization slightly, we define the process
Zn(h) =
1
√
n
Xn
i=1
εi`(h, Xi), h ∈ H. (2.4.55)
Our task reduces to upper bounding
E

sup
h∈H
Zn(h)

. (2.4.56)
Note that we will not compute the best possible true risk (which in general could be “bad,”
i.e., large) – only how close the empirical risk minimizer gets to it.
VC dimension We make two observations about Zn(h).
1. It is centered. Also, as a weighted sum of independent random variables in [−1, 1], it is
sub-Gaussian with variance factor 1 by the general Hoeffding inequality (Theorem 2.4.9)
and Hoeffding’s lemma (Lemma 2.4.12).
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press84 Moments and Tails
2. It depends only on the values of the hypothesis h at a finite number of points, X1, . . . , Xn.
Hence, while the supremum in (2.4.56) is over a potentially infinite class of functions H,
it is in effect a supremum over at most 2n
functions, that is, all the possible restrictions of
the hs to (Xi)
n
i=1
.
A naive application of the maximal inequality in Lemma 2.4.21, together with the two ob￾servations above, gives
E

sup
h∈H
Zn(h)

≤
p
2 log 2n =
p
2n log 2.
Unfortunately, plugging this back into (2.4.54) gives an upper bound, which fails to converge
to 0 as n → +∞.
To obtain a better bound, we show that in general the number of distinct restrictions of H
to n points can grow much slower than 2n
.
Definition 2.4.43 (Shattering). Let 3 = {`1, . . . , `n} ⊆ R
d be a finite set and let H be a
class of Boolean functions on R
d
. The restriction of H to 3 is
H3 = {(h(`1), . . . , h(`n)) : h ∈ H}.
We say that 3 is shattered by H if |H3| = 2
|3|
SHATTERING , that is, if all Boolean functions over 3 can
be obtained by restricting a function in H to the points in 3.
Definition 2.4.44 (VC dimension). Let H be a class of Boolean functions on R
d
VC . The VC
DIMENSION dimension of H, denoted vc(H), is the maximum cardinality of a set shattered by H.
We prove the following combinatorial lemma at the end of this section.
Lemma 2.4.45 (Sauer’s lemma). Let H be a class of Boolean functions on R
d
. For any finite
set 3 = {`1, . . . , `n} ⊆ R
d
,
|H3| ≤ 
en
vc(H)
vc(H)
.
That is, the number of distinct restrictions of H to any n points grows at most as ∝ n
vc(H)
.
Returning to E[suph∈H Zn(h)], we get the following inequality.
Lemma 2.4.46 There exists a constant 0 < C < +∞ such that, for any countable class of
measurable Boolean functions H over R
d
,
E

sup
h∈H
Zn(h)

≤ C
p
vc(H) log n. (2.4.57)
Proof Recall that Zn(h) ∈ sG(1). Since the supremum over H, when seen as restricted to
{X1, . . . , Xn}, is in fact a supremum over at most 
en
vc(H)
vc(H)
functions by Sauer’s lemma
(Lemma 2.4.45), we have by Lemma 2.4.21,
E

sup
h∈H
Zn(h)

≤
vuut2 log "
en
vc(H)
vc(H)
#
.
That proves the claim.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.4 Chernoff–Cramér Method 85
Returning to (2.4.54), the previous lemma finally implies
E[R(h
∗
)] − inf
h
0∈H
R(h
0
) ≤ 4C
r
vc(H) log n
n
.
For hypothesis classes with finite VC dimension, the bound goes to 0 as n → +∞.
We give some examples.
Example 2.4.47 (VC dimension of half-spaces). Consider the class of half-spaces.
Claim 2.4.48
vc(HH) = d + 1.
We only prove the case d = 1, where HH reduces to half-lines (−∞, γ ] or [γ , +∞). Clearly,
any set 3 = {`1, `2} ⊆ R with elements is shattered by HH. On the other hand, for any
3 = {`1, `2, `3} with `1 < `2 < `3, any half-line containing `1 and `3 necessarily includes
`2 as well. Hence, no set of size 3 is shattered by HH. J
Example 2.4.49 (VC dimension of boxes). Consider the class of axis-aligned boxes.
Claim 2.4.50
vc(HB) = 2d.
We only prove the case d = 2, where HB reduces to rectangles. The four-point set 3 =
{(−1, 0), (1, 0), (0, −1), (0, 1)} is shattered by HB. Indeed, the rectangle [−1, 1] × [−1, 1]
contains 3, with each side of the rectangle containing one of the points. Moving any side
inward by ε < 1 removes the corresponding point from the rectangle without affecting the
other ones. Hence, any subset of 3 can be obtained by this procedure.
On the other hand, let 3 = {`1, . . . , `5} ⊆ R
2 be any set of five distinct points. If the
points all lie on the same axis-aligned line, then an argument similar to the half-line case in
Claim 2.4.48 shows that 3 is not shattered. Otherwise consider the axis-aligned rectangle
with smallest area containing 3. For each side of the rectangle, choose one point of 3 that
lies on it. These necessarily exist (otherwise the rectangle could be made even smaller) and
denote them by xN for the highest, xE for the rightmost, xS for the lowest, and xW for the
leftmost. Note that they may not be distinct, but in any case at least one point in 3, say
`5 without loss of generality, is not in the list. Now observe that any axis-aligned rectangle
containing xN, xE, xS, xW must also contain `5 since its coordinates are sandwiched between
the bounds defined by those points. Hence, no set of size 5 is shattered. That proves the
claim. J
These two examples also provide insights into Sauer’s lemma. Consider the case of rect￾angles for instance. Over a collection of n sample points, a rectangle defines the same {0, 1}-
labeling as the minimal-area rectangle containing the same points. Because each side of a
minimal-area rectangle must touch at least one point in the sample, there are at most n
4
such
rectangles, and hence there are at most n
4  2
n
restrictions of HB to these sample points.
Application of chaining It turns out that the √
log n factor in (2.4.57) is not optimal. We
use chaining (Section 2.4.4) to improve the bound.
We claim that the process {Zn(h)}h∈H has sub-Gaussian increments under an appropriately
defined pseudometric. Indeed, conditioning on (Xi)
n
i=1
, by the general Hoeffding inequality
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press86 Moments and Tails
(Theorem 2.4.9) and Hoeffding’s lemma (Lemma 2.4.12), we have that the increment (as a
function of the εis which have variance factor 1)
Zn(g) − Zn(h) =
Xn
i=1
εi
`(g, Xi) − `(h, Xi)
√
n
is sub-Gaussian with variance factor
Xn
i=1

`(g, Xi) − `(h, Xi)
√
n
2
× 1 =
1
n
Xn
i=1
[`(g, Xi) − `(h, Xi)]2
.
Define the pseudometric
ρn(g, h) =
"
1
n
Xn
i=1
[`(g, Xi) − `(h, Xi)]2
#1/2
=
"
1
n
Xn
i=1
[g(Xi) − h(Xi)]2
#1/2
,
where we used that `(h, x) = 1{h(x) 6= C(x)} by definition. It satisfies the triangle inequality
since it can be expressed as a Euclidean norm. In fact, it will be useful to recast it in a more
general setting. For a probability measure η over R
d
, define
kg − hk
2
L
2
(η) =
Z
Rd
(f (x) − g(x))2
dη(x).
EMPIRICAL Let µn be the empirical measure
MEASURE
µn = µ(Xi)
n
i=1
:=
1
n
Xn
i=1
δXi
, (2.4.58)
where δx
is the probability measure that puts mass 1 on x. Then, we can rewrite
ρn(g, h) = kg − hkL
2
(µn)
.
Hence we have shown that, conditioned on the samples, the process {Zn(h)}h∈H has sub￾Gaussian increments with respect to k · kL
2
(µn)
. Note that the pseudometric here is random
as it depends on the samples. Though, by the law of large numbers, kg −hkL
2
(µn) approaches
its expectation, kg − hkL
2
(µ)
, as n → +∞.
Applying the discrete Dudley inequality (Theorem 2.4.31), we obtain the following bound.
Lemma 2.4.51 There exists a constant 0 < C < +∞ such that, for any countable class of
measurable Boolean functions H over R
d
,
E

sup
h∈H
Zn(h)

≤ C E
"X
+∞
k=0
2
−k
q
log N (H, k · kL
2
(µn)
, 2−k
)
#
,
where µn is the empirical measure over the samples (Xi)
n
i=1
.
Proof Because H comprises only Boolean functions, it follows that under the pseudo￾metric k · kL
2
(µn)
the diameter is bounded by 1. We apply the discrete Dudley inequality
conditioned on (Xi)
n
i=1
. Then we take an expectation over the samples.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press2.4 Chernoff–Cramér Method 87
Our use of the symmetrization trick is more intuitive than it may have appeared at first. The
central limit theorem indicates that the fluctuations of centered averages such as
(Rn(g) − R(g)) − (Rn(h) − R(h))
tend to cancel out and that, in the limit, the variance alone characterizes the overall behavior.
The εis in some sense explicitly capture the canceling part of this phenomenon, while ρn
captures the scale of the resulting global fluctuations in the increments.
Our final task is to bound the covering numbers N (H, k · kL
2
(µn)
, 2−k
).
Theorem 2.4.52 (Covering numbers via VC dimension). There exists a constant 0 < C <
+∞ such that, for any class of measurable Boolean functions H over R
d
, any probability
measure η over R
d
, and any ε ∈ (0, 1),
N (H, k · kL
2
(η)
, ε) ≤

2
ε
C vc(H)
.
Before proving Theorem 2.4.52, we derive its implications for uniform deviations. Compare
the following bound to Lemma 2.4.46.
Lemma 2.4.53 There exists a constant 0 < C < +∞ such that, for any countable class of
measurable Boolean functions H over R
d
,
E

sup
h∈H
Zn(h)

≤ C
p
vc(H).
Proof By Lemma 2.4.51,
E

sup
h∈H
Zn(h)

≤ C E
"X
+∞
k=0
2
−k
q
log N (H, k · kL
2
(µn)
, 2−k
)
#
≤ C E


X
+∞
k=0
2
−k
s
log
2
2
−k
C0 vc(H)


= C
p
vc(H) E
"X
+∞
k=0
2
−k
√
k + 1
p
C0
log 2#
≤ C
00p
vc(H)
for some 0 < C
00 < +∞.
It remains to prove Theorem 2.4.52.
Proof of Theorem 2.4.52 Let G = {g1, . . . , gN} ⊆ H be a maximal ε-packing of H with
N ≥ N (H, k · kL
2
(η)
, ε), which exists by Lemma 2.4.24. We use the probabilistic method
(Section 2.2) and Hoeffding’s inequality for bounded variables (Theorem 2.4.10) to show
that there exists a small number of points {x1, . . . , xm} such that G is still a good packing
when H is restricted to the xis. Then we use Sauer’s lemma (Lemma 2.4.45) to conclude.
1. Restriction. By construction, the collection G satisfies
kgi − gjkL
2
(η) > ε, ∀i 6= j.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press88 Moments and Tails
For an integer m that we will choose as small as possible below, let X = {X1, . . . , Xm}
be i.i.d. samples from η and let µX be the corresponding empirical measure (as defined
in (2.4.58)). Observe that, for any i 6= j,
E
h
kgi − gjk
2
L
2
(µX)
i
= E
"
1
m
Xm
k=1
[gi(Xk ) − gj(Xk )]2
#
= kgi − gjk
2
L
2
(η)
.
Moreover, [gi(Xk ) − gj(Xk )]2 ∈ [0, 1]. Hence, by Hoeffding’s inequality there exists a
constant 0 < C < +∞ and an m ≤ Cε
−4
logN such that
P

kgi − gjk
2
L
2
(η) − kgi − gjk
2
L
2
(µX) ≥
3ε
2
4

= P
"
mkgi − gjk
2
L
2
(η) −
Xm
k=1
[gi(Xk ) − gj(Xk )]2 ≥ m
3ε
2
4
#
≤ exp
−
2(m · 3ε
2
/4)2
m

= exp
−
9
8
mε
4

<
1
N2
.
This implies that, for this choice of m,
P
h
kgi − gjkL
2
(µX) >
ε
2
∀i 6= j
i
> 0,
where the probability is over the samples. Therefore, there must be a set X = {x1, . . . , xm} ⊆
R
d
such that
kgi − gjkL
2
(µX ) >
ε
2
∀i 6= j. (2.4.59)
2. VC bound. In particular, by (2.4.59), the functions in G restricted to X are distinct. By
Sauer’s lemma (Lemma 2.4.45),
N = |GX | ≤ |HX | ≤ 
em
vc(H)
vc(H)
≤

eCε
−4
logN
vc(H)
vc(H)
. (2.4.60)
Using that 1
2D
logN = logN
1/2D ≤ N
1/2D
, where D = vc(H), we get

eCε
−4
logN
vc(H)
vc(H)
≤
￾
C
0
ε
−4
vc(H)
N
1/2
, (2.4.61)
where C
0 = 2eC. Plugging (2.4.61) back into (2.4.60) and rearranging gives
N ≤
￾
C
0
ε
−4
2 vc(H)
.
That concludes the proof.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Pre2.4 Chernoff–Cramér Method 89
Proof of Sauer’s lemma Recall from Appendix A (see also Exercise 1.4) that for integers
0 < d ≤ n,
X
d
k=0

n
k

≤
en
d
d
. (2.4.62)
Sauer’s lemma (Lemma 2.4.45) follows from the following claim.
Lemma 2.4.54 (Pajor). Let H be a class of Boolean functions on R
d and let 3 = {`1, . . . , `n} PAJOR’S
⊆ R LEMMA d be any finite subset. Then
|H3| ≤ |{S ⊆ 3: S is shattered by H}| ,
where the right-hand side includes the empty set.
Going back to Sauer’s lemma, by Lemma 2.4.54 we have the upper bound
|H3| ≤ |{S ⊆ 3: S is shattered by H}| .
By definition of the VC-dimension (Definition 2.4.44), the subsets S ⊆ 3 that are shattered
by H have size at most vc(H). So the right-hand side is bounded above by the total number
of subsets of size at most d = vc(H) of a set of size n. By (2.4.62), this gives
|H3| ≤ 
en
vc(H)
vc(H)
,
which establishes Sauer’s lemma.
So it remains to prove Lemma 2.4.54.
Proof of Lemma 2.4.54 We prove the claim by induction on the size n of 3. The result is
trivial for n = 1. Assume the result is true for any H and any subset of size n − 1. To apply
induction, for ι = 0, 1 we let
Hι = {h ∈ H: h(`n) = ι},
and we set
3
0 = {`1, . . . , `n−1}.
It will be convenient to introduce the following notation:
S(3; H) = |{S ⊆ 3: S is shattered by H}| .
Because |H3| = |H0
30| + |H1
30| and the induction hypothesis implies S(30
; Hι
) ≥ |Hι
30| for
ι = 0, 1, it suffices to show that
S(3; H) ≥ S(3
0
; H0
) + S(3
0
; H1
). (2.4.63)
There are two types of sets that contribute to the right-hand side.
• One but not both. Let S ⊆ 30 be a set that contributes to one of S(30
; H0
) or S(30
; H1
)
but not both. Then, S is a subset of the larger set 3 and it is certainly shattered by the
larger collection H. Hence, it also contributes to the left-hand side of (2.4.63).
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press90 Moments and Tails
• Both. Let S ⊆ 30 be a set that contributes to both S(30
; H0
) and S(30
; H1
). Hence,
it contributes two to the right-hand side of (2.4.63). As in the previous point, it is also
included in S(3; H), but it only contributes one to the left-hand side of (2.4.63). It turns
out that there is another set that contributes one to the left-hand side but zero to the right￾hand side: the subset S ∪ {`n}. Indeed, by definition of Hι
, the subset S ∪ {`n} cannot be
shattered by it since all functions in it take the same value on `n. On the other hand, any
Boolean function h on S ∪ {`n} with h(`n) = ι is realized in Hι
since S itself is shattered
by Hι
.
That concludes the proof.
Exercises
Exercise 2.1 (Moments of non-negative random variables). Prove (B.5.1). (Hint: Use Fu￾bini’s Theorem to compute the integral.)
Exercise 2.2 (Bonferroni inequalities). Let A1, . . . , An be events and Bn := ∪iAi
. Define
S
(r)
:=
X
1≤i1<···<ir≤n
P[Ai1 ∩ · · · ∩ Air
]
and
Xn :=
Xn
i=1
1Ai
.
(i) Let x0 ≤ x1 ≤ · · · ≤ xs ≥ xs+1 ≥ · · · ≥ xm be a unimodal sequence of non-negative
reals such that Pm
j=0
(−1)j
xj = 0. Show that P`
j=0
(−1)j
xj
is ≥ 0 for even ` and ≤ 0
for odd `.
(ii) Show that, for all r,
X
1≤i1<···<ir≤n
1Ai1
1Ai2
· · · 1Air =

Xn
r

.
(iii) Use (i) and (ii) to show that when ` ∈ [n] is odd
P[Bn] ≤
X
`
r=1
(−1)r−1
S
(r)
and when ` ∈ [n] is even
P[Bn] ≥
X
`
r=1
(−1)r−1
S
(r)
.
These inequalities are called Bonferroni inequalities. The case ` = 1 is Boole’s
inequality.
Exercise 2.3 (Percolation on Z
2
: a better bound). Let E1 be the event that all edges are open
in [−N,N] × [−N,N] and E2 be the event that there is no closed self-avoiding dual cycle
surrounding [−N,N]
2
. By looking at E1 ∩ E2, show that θ( p) > 0 for p > 2/3.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University PressExercises 91
Exercise 2.4 (Percolation on Z
d
: existence of critical threshold). Consider bond percolation
on L
d
.
(i) Show that pc(L
d
) > 0. (Hint: Count self-avoiding paths.)
(ii) Show that pc(L
d
) < 1. (Hint: Use the result for L
2
.)
Exercise 2.5 (Sums of uncorrelated variables). Centered random variables X1, X2, . . . are
uncorrelated if
E[XrXs] = 0 ∀r 6= s.
(i) Assume further that Var[Xr] ≤ C < +∞ for all r. Show that
P
"
1
n
X
r≤n
Xr ≥ β
#
≤
C
2
β
2n
.
(ii) Use (i) to prove Theorem 2.1.6.
Exercise 2.6 (Pairwise independence: lack of concentration). Let U = (U1, . . . , U`) be
uniformly distributed over {0, 1}
`
. Let n = 2
` − 1. For all v ∈ {0, 1}
`\0, define
Xv = (U · v) mod 2.
(i) Show that the random variables Xv
, v ∈ {0, 1}
`\0, are uniformly distributed in {0, 1}
and pairwise independent.
(ii) Show that for any event A measurable with respect to σ(Xv
, v ∈ {0, 1}
`\0), P[A] is
either 0 or ≥ 1/(n + 1).
Exercise 2.5 shows that pairwise independence implies “polynomial concentration” of the
average of square-integrable Xvs. On the other hand, the current exercise suggests that in
general pairwise independence cannot imply “exponential concentration.”
Exercise 2.7 (Chernoff bound for Poisson trials). Using the Chernoff–Cramér method,
prove part (i) of Theorem 2.4.7. Show that part (ii) follows from part (i).
Exercise 2.8 (Stochastic knapsack: some details). Consider the stochastic fractional knap￾sack problem in Section 2.4.3.
(i) Prove that the greedy algorithm described there gives an optimal solution to prob￾lem (2.4.21).
(ii) Prove Claim 2.4.20 for τ ∈ (0, 1/6).
Exercise 2.9 (Stochastic knapsack: 0-1 version). Consider the stochastic fractional knap￾sack problem in Section 2.4.3.
(i) Adapt the greedy algorithm for the 0-1 knapsack problem and show that it is not
optimal in general. (Hint: Construct a counter-example with two items.)
(ii) Prove Claim 2.4.20 for the greedy solution of (i).
Exercise 2.10 (A proof of Pólya’s theorem). Let (St) be simple random walk on L
d
started
at the origin 0.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press92 Moments and Tails
(i) For d = 1, use Stirling’s formula (see Appendix A) to show that P[S2n = 0] =
2(n
−1/2
).
(ii) For j = 1, . . . , d, let N
( j)
t be the number of steps in the jth coordinate by time t.
Show that
P

N
( j)
n ∈

n
2d
,
3n
2d

, ∀j

≥ 1 − exp(−κdn)
for some constant κd > 0.
(iii) Use (i) and (ii) to show that, for any d ≥ 3, P[S2n = 0] = O(n
−d/2
).
Exercise 2.11 (Maximum degree). Let Gn = (Vn, En) ∼ Gn,pn be an Erdos–Rényi graph ˝
with n vertices and density pn. Suppose npn = C log n for some C > 0. Let Dn be the
maximum degree of Gn. Use Bernstein’s inequality to show that for any ε > 0,
P [Dn ≥ (n − 1)pn + max{C, 4(1 + ε)}log n] → 0,
as n → +∞.
Exercise 2.12 (RIP versus orthogonality). Show that a (k, 0)-RIP matrix with k ≥ 2 is
orthogonal, that is, its columns are orthonormal.
Exercise 2.13 (Compressed sensing: linear programming formulation). Formulate (2.4.43)
as a linear program, that is, the minimization of a linear objective subject to linear inequali￾ties.
Exercise 2.14 (Compressed sensing: almost sparse case). By adapting the proof of Lemma
2.4.39, show the following “almost sparse” version. Let L be (10k, 1/3)-RIP. Then, for
any x ∈ R
n
, the solution to (2.4.43) satisfies kz
∗ − xk2 = O(η(x)/
√
k), where η(x) :=
minx
0∈S n
k
kx − x
0k1.
Exercise 2.15 (Spectral norm without independence). Give an example of a random matrix
A ∈ R
n×n whose entries are bounded, but not independent, such that the spectral norm is
(n) with high probability.
Exercise 2.16 (Spectral norm: symmetric matrix). Let A ∈ R
n×n be a symmetric random
matrix. We assume that entries on and above the diagonal Ai, j
, i ≤ j, are centered, independ￾ent, and sub-Gaussian with variance factor ν. Each entry below the diagonal is equal to the
corresponding entry above it. Prove an analogue of Theorem 2.4.28 for A. (Hint: Mimic the
proof of Theorem 2.4.28.)
Exercise 2.17 (Chaining tail inequality). Prove Theorem 2.4.32.
Exercise 2.18 (Poisson convergence: method of moments). Let A1, . . . , An be events and
A := ∪iAi
. Define
S
(r)
:=
X
1≤i1<···<ir≤n
P[Ai1 ∩ · · · ∩ Air
]
and
Xn :=
Xn
i=1
Ai
.
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University PressBibliographic Remarks 93
Assume that there is µ > 0 such that, for all r,
S
(r) →
µ
r
r!
.
Use Exercise 2.2 and a Taylor expansion of e
−µ
to show that
P[Xn = 0] → e
−µ
.
In fact, Xn
d
→ Poi(µ) (no need to prove this). This is a special case of the method of moments.
Exercise 2.19 (Connectivity: critical window). Using Exercise 2.18 show that, when pn =
log n+s
n
, the probability that an Erdos–Rényi graph ˝ Gn ∼ Gn,pn
contains no isolated vertex
converges to e
−e
−s
.
Bibliographic Remarks
Section 2.1 For more on moment-generating functions, see [Bil12, section 21].
Section 2.2 The examples in Section 2.2.1 are taken from [AS11, sections 2.4, 3.2]. A
fascinating account of the longest increasing subsequence problem is given in [Rom15],
from which the material in Section 2.2.3 is taken. The contour lemma, Lemma 2.2.14, is
attributed to Whitney [Whi32] and is usually proved “by picture” [Gri10a, Figure 3.1]. A
formal proof of the lemma can be found in [Kes82, Appendix A]. For much more on perco￾lation, see [Gri10b]. A gentler introduction is provided in [Ste].
Section 2.3 The presentation in Section 2.3.2 follows [AS11, section 4.4] and [JLR11, sec￾tion 3.1]. The result for general subgraphs is due to Bollobás [Bol81]. A special case (in￾cluding cliques) was proved by Erdos and Rényi [ ˝ ER60]. For variants of the small subgraph
containment problem involving copies that are induced, disjoint, isolated, and so on, see,
for example, [JLR11, chapter 3]. For corresponding results for larger subgraphs, such as
cycles or matchings, see, for example, [Bol01]. The connectivity threshold in Section 2.3.2
is also due to the same authors [ER59]. The presentation here follows [vdH17, section 5.2].
For more on the method of moments, see, for example, [Dur10, section 3.3.5] or [JLR11,
section 6.1]. Claim 2.3.11 is due to R. Lyons [Lyo90].
Section 2.4 The use of the moment-generating function to derive tail bounds for sums of
independent random variables was pioneered by Cramér [Cra38], Bernstein [Ber46], and
Chernoff [Che52]. For much more on concentration inequalities, see, for example, [BLM13].
The basics of large deviation theory are covered in [Dur10, section 2.6]. See also [RAS15]
and [DZ10]. Section 2.4.2 is based partly on [Ver18] and [Lug, section 3.2]. Section 2.4.3
is based on [FR98, section 5.3]. Very insightful, and much deeper, treatment of the ma￾terial in Section 2.4.4 can be found in [Ver18, vH16]. The presentation in Section 2.4.5
is inspired by [Har, Lectures 6 and 8] and [Tao]. The Johnson–Lindenstrauss lemma was
first proved by Johnson and Lindenstrauss using non-probabilistic arguments [JL84]. The
idea of using random projections to simplify the proof was introduced by Frankl and Mae￾hara [FM88] and the proof presented here based on Gaussian projections is due to Indyk and
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press94 Moments and Tails
Motwani [IM98]. See [Ach03] for an overview of the various proofs known. For more on
the random projection method, see [Vem04]. For algorithmic applications of the Johnson–
Lindenstrauss lemma, see, for example, [Har, Lecture 7]. Compressed sensing emerged in
the works of Donoho [Don06] and Candès, Romberg, and Tao [CRT06a, CRT06b]. The re￾stricted isometry property was introduced by Candès and Tao [CT05]. Lemma 2.4.39 is due
to Candés, Romberg, and Tao [CRT06b]. The proof of Lemma 2.4.38 presented here is due
to Baraniuk et al. [BDDW08]. A survey of compressed sensing can be found in [CW08]. A
thorough mathematical introduction to compressed sensing can be found in [FR13]. The ma￾terial in Section 2.4.2 can be found in [BLM13, chapter 2]. Hoeffding’s lemma and inequality
are due to Hoeffding [Hoe63]. Section 2.4.6 borrows from [Ver18, vH16, SSBD14, Haz16].
The proof of Sauer’s lemma follows [Ver18, section 8.3.3]. For a proof of Claim 2.4.48 in
general dimension d, see, for example, [SSBD14, section 9.1.3].
https://doi.org/10.1017/9781009305129.003 Published online by Cambridge University Press3
Martingales and Potentials
In this chapter we turn to martingales, which play a central role in probability theory. We
illustrate their use in a number of applications to the analysis of discrete stochastic pro￾cesses. After some background on stopping times and a brief review of basic martingale
properties and results in Section 3.1, we develop two major directions. In Section 3.2, we
show how martingales can be used to derive a substantial generalization of our previous
concentration inequalities – from the sums of independent random variables we focused on
in Chapter 2 to nonlinear functions with Lipschitz properties. In particular, we give several
applications of the method of bounded differences to random graphs. We also discuss bandit
problems in machine learning. In the second thread in Section 3.3, we give an introduction to
potential theory and electrical network theory for Markov chains. This toolkit in particular
provides bounds on hitting times for random walks on networks, with important implications
in the study of recurrence among other applications. We also introduce Wilson’s remarkable
method for generating uniform spanning trees.
3.1 Background
We begin with a quick review of stopping times and martingales. Along the way, we prove a
few useful results. In particular, we derive some bounds on hitting times and cover times of
Markov chains.
Throughout, (, F, (Ft)t∈Z+
, P) is a filtered space. See Appendix B for a formal definition.
Recall that, intuitively, the σ-algebra Ft
in the filtration (Ft)t represents “the information
known at time t.” All time indices are discrete (in Z+ unless stated otherwise). We will also
use the notation Z+ := {0, 1, . . . , +∞} to allow time +∞.
3.1.1 Stopping Times
Definitions Roughly speaking, a stopping time is a random time whose value is determined
by a rule not depending on the future. Formally:
Definition 3.1.1 (Stopping time). A random variable τ :  → Z+ is called a stopping STOPPING
time if TIME
{τ ≤ t} ∈ Ft
, ∀t ∈ Z+,
or, equivalently,
{τ = t} ∈ Ft
, ∀t ∈ Z+.
To see this equivalence, note that {τ = t} = {τ ≤ t}\ {τ ≤ t−1}, and {τ ≤ t} = ∪i≤t{τ = i}.
95
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press96 Martingales and Potentials
Example 3.1.2 (Hitting time). Let (At)t∈Z+
, with values in (E, E), be adapted and B ∈ E.
Then,
τ = inf{t ≥ 0: At ∈ B}
HITTING TIME is a stopping time known as a hitting time. In contrast, the last visit to a set is typically not a
stopping time. J
Let τ be a stopping time. Denote by Fτ
the set of all events F such that, ∀t ∈ Z+, F ∩ {τ =
t} ∈ Ft
. Intuitively, the σ-algebra Fτ captures the information up to time τ . The following
lemmas help clarify the definition of Fτ
.
Lemma 3.1.3 Fτ = Fs
if τ := s, Fτ = F∞ = σ(∪tFt) if τ := +∞ and Fτ ⊆ F∞ for
any τ .
Proof In the first case, note that F∩ {τ = t} is empty if t 6= s and is F if t = s. So if F ∈ Fτ
then F = F ∩ {τ = s} ∈ Fs by definition of Fτ
, and if F ∈ Fs
then F = F ∩ {τ = t} ∈ Ft
for all t by definition of τ . So we have proved both inclusions. This works also for t = +∞.
For the third claim note that, for any F ∈ Fτ
,
F = ∪t∈Z+
F ∩ {τ = t} ∈ F∞,
again by definition of Fτ
.
Lemma 3.1.4 If (Xt) is adapted and τ is a stopping time then Xτ ∈ Fτ (where we assume
that X∞ ∈ F∞, for example, by setting X∞ := lim inf Xn).
Proof For B ∈ E,
{Xτ ∈ B} ∩ {τ = t} = {Xt ∈ B} ∩ {τ = t} ∈ Ft
by definition of τ . That shows Xτ
is measurable with respect to Fτ as claimed.
Lemma 3.1.5 If σ, τ are stopping times, then Fσ∧τ ⊆ Fτ
.
Proof Let F ∈ Fσ∧τ
. Note that
F ∩ {τ = t} = ∪s≤t[(F ∩ {σ ∧ τ = s}) ∩ {τ = t}] ∈ Ft
.
Indeed, the expression in parenthesis is in Fs ⊆ Ft by definition of Fσ∧τ and {τ = t} ∈
Ft
.
Let (Xt) be a Markov chain on a countable space V. The following two examples of stop￾ping times will play an important role.
FIRST RETURN Definition 3.1.6 (First visit and return). The first visit time and first return time to x ∈ V are
τx
:= inf{t ≥ 0: Xt = x} and τ
+
x
:= inf{t ≥ 1: Xt = x}.
Similarly, τB and τ
+
B are the first visit time and first return time to B ⊆ V.
COVER TIME Definition 3.1.7 (Cover time). Assume V is finite. The cover time of (Xt) is the first time that
all states have been visited, that is,
τcov := inf{t ≥ 0: {X0, . . . , Xt} = V}.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.1 Background 97
Strong Markov property Let (Xt) be a Markov chain with transition matrix P and initial
distribution µ. Let Ft = σ(X0, . . . , Xt). Recall that the Markov property (Theorem 1.1.18)
says that, given the present, the future is independent of the past. The Markov property
naturally extends to stopping times. Let τ be a stopping time with P[τ < +∞] > 0. In its
simplest form we have:
P[Xτ+1 = y | Fτ ] = PXτ
[Xτ+1 = y] = P(Xτ
, y).
In other words, the chain “starts afresh” at a stopping time with the state at that time as a
starting point. More generally:
Theorem 3.1.8 (Strong Markov property). Let ft
: V
∞ → R be a sequence of measurable
functions, uniformly bounded in t and let Ft(x) := Ex[ ft((Xs)s≥0)]. On {τ < +∞},
E[ fτ ((Xτ+t)t≥0) | Fτ ] = Fτ (Xτ ).
Throughout, when we say that two random variables Y, Z are equal on an event B, we mean
formally that Y1B = Z1B almost surely.
Proof of Theorem 3.1.8 We use that
E[ fτ ((Xτ+t)t≥0) | Fτ ]1τ<+∞ = E[ fτ ((Xτ+t)t≥0)1τ<+∞ | Fτ ].
Let A ∈ Fτ
. Summing over the possible values of τ , using the tower property (Lemma B.6.16)
and then the Markov property
E[ fτ ((Xτ+t)t≥0)1τ<+∞; A]
= E[ fτ ((Xτ+t)t≥0); A ∩ {τ < +∞}]
=
X
s≥0
E[ fs((Xs+t)t≥0); A ∩ {τ = s}]
=
X
s≥0
E[E[ fs((Xs+t)t≥0); A ∩ {τ = s} | Fs]]
=
X
s≥0
E[1A∩{τ=s}E[ fs((Xs+t)t≥0) | Fs]]
=
X
s≥0
E[1A∩{τ=s}Fs(Xs)]
=
X
s≥0
E[Fs(Xs); A ∩ {τ = s}]
= E[Fτ (Xτ ); A ∩ {τ < +∞}]
= E[Fτ (Xτ )1τ<+∞; A],
where, on the fifth line, we used that A∩{τ = s} ∈ Fs by definition of Fτ and taking out what
is known (Lemma B.6.13). The definition of the conditional expectation (Theorem B.6.1)
concludes the proof.
The following typical application of the strong Markov property (Theorem 3.1.8) is
useful.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press98 Martingales and Potentials
Theorem 3.1.9 (Reflection principle). Let X1, X2, . . . be i.i.d. with a distribution symmetric
about 0 and let St =
P
i≤t Xi
. Then, for b > 0,
P

sup
i≤t
Si ≥ b

≤ 2 P[St ≥ b].
Proof Let τ := inf{i ≤ t: Si ≥ b}. By the strong Markov property, on {τ < t}, St − Sτ
is
independent of Fτ and is symmetric about 0. In particular, it has probability at least 1/2 of
being greater or equal to 0 by the first moment principle (Theorem 2.2.1), an event which
implies that St
is greater than or equal to b. Hence,
P[St ≥ b] ≥ P[τ = t] +
1
2
P[τ < t] ≥
1
2
P[τ ≤ t].
(Exercise 3.1 asks for a more formal proof.)
In the case of simple random walk on Z, we get a stronger statement.
Theorem 3.1.10 (Reflection principle: simple random walk). Let (St) be simple random
walk on Z started at 0. Then, ∀a, b, t > 0,
P[St = b + a] = P

St = b − a, sup
i≤t
Si ≥ b

,
and
P

sup
i≤t
Si ≥ b

= P[St = b] + 2 P[St > b].
Proof Reflect the sub-path after the first visit to b across the line y = b. Summing over
a > 0 and rearranging gives the second claim.
We record another related result that will be useful later.
Theorem 3.1.11 (Ballot theorem). In an election with n voters, candidate A gets α votes
and candidate B gets β < α votes. The probability that A leads B throughout the counting
is α−β
n
.
kTH RETURN Recurrence Let (Xt) be a Markov chain on a countable state space V. The time of the kth
return to y is (letting τ
0
y
:= 0)
τ
k
y
:= inf{t > τ k−1
y
: Xt = y}.
In particular, τ
1
y = τ
+
y
. Define ρxy := Px[τ
+
y < +∞]. Then by the strong Markov property
(and induction)
Px[τ
k
y < +∞] = ρxyρ
k−1
yy . (3.1.1)
(Exercise 3.2 asks for a more formal proof.) Letting
Ny
:=
X
t>0
1{Xt=y} =
X
k≥1
1{τ
k
y <+∞}
be the number of visits to y after time 0, by linearity
Ex[Ny] =
ρxy
1 − ρyy
. (3.1.2)
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.1 Background 99
When ρyy < 1, we have Ey[Ny] < +∞ by (3.1.2), and in particular τ
k
y = +∞ for some k.
Or ρyy = 1 and, starting at x = y, we have τ
k
y < +∞ almost surely for all k by (3.1.1). That
leads us to the following dichotomy.
Definition 3.1.12 (Recurrence). A state x is recurrent if ρxx = 1. Otherwise it is transient. We RECURRENT
refer to the recurrence or transience of a state as its type. Let x be recurrent. If in addition
Ex[τ
+
x
] < +∞, we say that x is positive recurrent; otherwise we say that it is null recurrent.
A chain is recurrent (or transient, or positive recurrent, or null recurrent) if all its states are.
Recurrence is “contagious” in the following sense.
Lemma 3.1.13 If x is recurrent and ρxy > 0, then y is recurrent and ρyx = ρxy = 1.
A subset C ⊆ V is closed if x ∈ C and ρxy > 0 implies y ∈ C. A subset D ⊆ V is irreducible
if x, y ∈ D implies ρxy > 0. This definition is consistent with (and generalizes to sets) the
one we gave in Section 1.1.2. Recall that we have the following decomposition theorem.
Theorem 3.1.14 (Decomposition theorem). Let R := {x: ρxx = 1} be the recurrent states
of the chain. Then R can be written as a disjoint union ∪jRj
, where each Rj
is closed and
irreducible.
Example 3.1.15 (Simple random walk on Z). Consider simple random walk (St) on Z
started at 0. The chain is clearly irreducible so it suffices to check the type of state 0 by
Lemma 3.1.13. First note the periodicity of this chain. So we look at S2t
. Then by Stirling’s
formula (see Appendix A),
P[S2t = 0] =

2t
t

2
−2t ∼ 2
−2t
(2t)
2t
(t
t
)
2
√
2t
√
2πt
∼
1
√
πt
.
Thus,
E[N0] =
X
t>0
P[St = 0] = +∞,
and the chain is recurrent. J
Return times are closely related to stationary measures. We recall the following standard
results without proof. We gave an alternative proof of the existence of a unique stationary
distribution in the finite, irreducible case in Theorem 1.1.24.
Theorem 3.1.16 Let x be a recurrent state. Then the following defines a stationary measure:
µx( y) := Ex


X
0≤t<τ +
x
1{Xt=y}

 .
Theorem 3.1.17 If (Xt) is irreducible and recurrent, then the stationary measure is unique
up to a constant multiple.
Theorem 3.1.18 If there is a stationary distribution π, then all states y that have π( y) > 0
are recurrent.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press100 Martingales and Potentials
Theorem 3.1.19 If (Xt) is irreducible and has a stationary distribution π, then
π(x) =
1
Exτ
+
x
.
Theorem 3.1.20 If (Xt) is irreducible, then the following are equivalent.
(i) There is a stationary distribution.
(ii) All states are positive recurrent.
(iii) There is a positive recurrent state.
We have seen previously that, in the irreducible, positive recurrent, aperiodic case, there is
convergence to stationarity (see Theorem 1.1.33). In the transient and null recurrent cases,
there is no stationary distribution to converge to by Theorem 3.1.20. Instead, we have the
following.
Theorem 3.1.21 (Convergence of P
t
: transient and null recurrent cases). If P is an irreduc￾ible chain which is either transient or null recurrent, we have for all x, y that
lim
t
P
t
(x, y) = 0.
Proof We only prove the transient case. In that case, we showed in (3.1.2) that
X
t
P
t
(x, y) = Ex
"X
t
1{Xt=y}
#
= Ex[Ny] < +∞.
Hence, P
t
(x, y) → 0.
A useful identity A slight generalization of the “cycle trick” used in the proof of Theo￾rem 3.1.16 gives a useful identity.
GREEN Definition 3.1.22 (Green function). Let σ be a stopping time for a Markov chain (Xt). The
FUNCTION Green function of the chain stopped at σ is given by
Gσ (x, y) = Ex
" X
0≤t<σ
1{Xt=y}
#
, x, y ∈ V, (3.1.3)
that is, it is the expected number of visits to y before σ when started at x.
Lemma 3.1.23 (Occupation measure identity). Consider an irreducible, positive recurrent
Markov chain (Xt)t≥0 with transition matrix P and stationary distribution π. Let x be a state
and σ be a stopping time such that Ex[σ] < +∞ and Px[Xσ = x] = 1. For any y,
Gσ (x, y) = πy Ex[σ].
Proof By the uniqueness of the stationary measure up to constant multiple (Theorem
3.1.17), it suffices to show that Gσ (x, y) satisfies the system for a stationary measure as a
function of y
X
y
Gσ (x, y)P( y,z) = Gσ (x,z) ∀z, (3.1.4)
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.1 Background 101
and use the fact that
X
y
Gσ (x, y) =
X
y
Ex
" X
0≤t<σ
1{Xt=y}
#
= Ex[σ].
To check (3.1.4), because Xσ = X0 almost surely, observe that
Gσ (x,z) = Ex
" X
0≤t<σ
1Xt=z
#
= Ex
" X
0≤t<σ
1Xt+1=z
#
=
X
t≥0
Px[Xt+1 = z, σ > t].
Since {σ > t} ∈ Ft
, applying the Markov property we get
Gσ (x,z) =
X
t≥0
X
y
Px[Xt = y, Xt+1 = z, σ > t]
=
X
t≥0
X
y
Px[Xt+1 = z| Xt = y, σ > t] Px[Xt = y, σ > t]
=
X
t≥0
X
y
P( y,z) Px[Xt = y, σ > t]
=
X
y
Gσ (x, y)P( y,z),
which establishes (3.1.4) and proves the claim.
Here is a typical application of this lemma.
Corollary 3.1.24 In the setting of Lemma 3.1.23, for all x 6= y,
Px[τy < τ +
x
] =
1
πx(Ex[τy] + Ey[τx])
.
Proof Let σ be the time of the first visit to x after the first visit to y. Then, Ex[σ] =
Ex[τy] + Ey[τx] < +∞, where we used that the chain is irreducible and positive recurrent.
By the strong Markov property, the number of visits to x before the first visit to y is geometric
with success probability Px[τy < τ +
x
]. Moreover, the number of visits to x after the first visit
to y but before σ is 0 by definition. Hence, Gσ (x, y) is the mean of the geometric distribution,
namely, 1/Px[τy < τ +
x
]. Applying the occupation measure identity gives the result.
3.1.2 F Markov Chains: Exponential Tail of Hitting Times and Some Cover
Time Bounds
Tail of a hitting time On a finite state space, the tail of any hitting time converges to 0
exponentially fast.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press102 Martingales and Potentials
Lemma 3.1.25 Let (Xt) be a finite, irreducible Markov chain with state space V. For any
subset of states A ⊆ V and initial distribution µ:
(i) It holds that Eµ[τA] < +∞ (and, in particular, τA < +∞ a.s.).
(ii) Letting ¯tA := maxx Ex[τA], we have the tail bound
Pµ[τA > t] ≤ exp
−

t
de ¯tAe
.
Proof For any integer m, for some distribution θ over the state space V, by the strong
Markov property (Theorem 3.1.8),
Pµ[τA > ms| τA > (m − 1)s] = Pθ [τA > s] ≤ max
x
Px[τA > s] =: αs
.
Choose s large enough that, from any x, there is a path to A of length at most s of positive
probability. Such an s exists by irreducibility. In particular, αs < 1.
By induction, Pµ[τA > ms] ≤ α
m
s
, or put differently,
Pµ[τA > t] ≤ α
b
t
s
c
s . (3.1.5)
The result for the expectation follows from
Eµ[τA] =
X
t≥0
Pµ[τA > t] ≤
X
t
α
b
t
s
c
s < +∞
since αs < 1.
By Markov’s inequality (Theorem 2.1.1),
αs = max
x
Px[τA > s] ≤
¯tA
s
.
Plugging back into (3.1.5) gives Pµ[τA > t] ≤

¯tA
s
b
t
s
c
. By differentiating with respect to s,
it can be checked that a good choice for s is de ¯tAe. Simplifying gives the second claim.
Application to cover times We give an application of the previous bound to cover times.
Let (Xt) be a finite, irreducible Markov chain on V with n := |V| > 1. Recall that the cover
time is τcov := maxy τy
. We bound the mean cover time in terms of
¯thit := max
x6=y
Exτy
.
Claim 3.1.26
max
x
Ex[τcov] ≤ (3 + log n)de ¯thite.
Proof By a union bound over all states to be visited and Lemma 3.1.25,
max
x
Px[τcov > t] ≤ min 
1, n exp
−

t
de ¯thite
 .
Summing over t ∈ Z+ and appealing to the sum of a geometric series,
max
x
Ex[τcov] ≤ (log n + 1)de ¯thite +
1
1 − e
−1
de ¯thite,
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.1 Background 103
where the first term on the right-hand side comes from the fact that until t ≥ (log n+1)de ¯thite
the upper bound above is 1. The factor de ¯thite in the second term on the right-hand side
comes from the fact that we must break up the series into blocks of size de ¯thite. Simplifying
gives the claim.
A clever argument gives a better constant factor as well as a lower bound.
Theorem 3.1.27 (Matthews’ cover time bounds). Let
t
A
hit := min
x,y∈A, x6=y
Exτy
and hn :=
Pn
m=1
1
m
.
Then,
max
x
Ex[τcov] ≤ hn
¯thit (3.1.6)
and
min
x
Ex[τcov] ≥ max
A⊆V
h|A|−1 t
A
hit. (3.1.7)
Clearly, maxx6=y
t
{x,y}
hit is a lower bound on the worst expected cover time. Lower bound (3.1.7)
says that a tighter bound is obtained by finding a larger subset of states A that are “far away”
from each other.
We sketch the proof of the lower bound for A = V, which we assume is [n] without loss of
generality. The other cases are similar. Let (J1, . . . , Jn) be a uniform random ordering of V,
let Cm := maxi≤Jm
τi
, and let Lm be the last state visited among J1, . . . , Jm. Then, for m ≥ 2,
Ex[Cm − Cm−1 | J1, . . . , Jm,{Xt
, t ≤ Cm−1}] ≥ t
V
hit 1{Lm=Jm}
.
By symmetry, P[Lm = Jm] =
1
m
. To see this, first pick the set of vertices corresponding to
{J1, . . . , Jm}, wait for all of those vertices to be visited, then pick the ordering. Moreover,
observe that ExC1 ≥ (1 −
1
n
)tV
hit, where the factor of (1 −
1
n
) accounts for the probability that
J1 6= x. Taking expectations in the previous display and summing over m gives the result.
Exercise 3.3 asks for a proof that the bounds above cannot in general be improved up to
smaller order terms.
3.1.3 Martingales
Definition Martingales are an important class of stochastic processes that correspond in￾tuitively to the “probabilistic version of a monotone sequence.” They hide behind many
processes and have properties that make them powerful tools in the analysis of processes
where they have been identified. Formally:
Definition 3.1.28 (Martingale). An adapted process (Mt)t≥0 with E|Mt
| < +∞ for all t is a
martingale if MARTINGALE
E[Mt+1 | Ft] = Mt ∀t ≥ 0.
If equality is replaced with ≤ or ≥, we get a supermartingale or a submartingale, respec￾tively. We say that a martingale is bounded in L
p
if supt E[|Xt
|
p
] < +∞.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press104 Martingales and Potentials
Recall that adapted (Definition B.7.5) simply means that Mt ∈ Ft
, that is, roughly speaking
Mt
is “known at time t.” Note that for a martingale, by the tower property (Lemma B.6.16),
we have E[Mt
| Fs] = Ms for all t > s, and similarly (with inequalities) for supermartingales
and submartingales.
We start with a straightforward example.
Example 3.1.29 (Sums of i.i.d. random variables with mean 0). Let X0, X1, . . . be i.i.d. in￾tegrable, centered random variables, Ft = σ(X0, . . . , Xt), S0 = 0, and St =
P
1≤i≤t Xi
. Note
that E|St
| < ∞ by the triangle inequality. By taking out what is known and the role of
independence lemma (Lemma B.6.14), we obtain
E[St
| Ft−1] = E[St−1 + Xt
| Ft−1] = St−1 + E[Xt] = St−1,
which proves that (St) is a martingale. J
Martingales however are richer than random walks with centered steps. For instance, mix￾tures of such random walks are also martingales.
Example 3.1.30 (Mixtures of random walks). Consider again the setting of Example 3.1.29.
This time assume that X0 is uniformly distributed in {1, 2} and define
Rt = X0St
, t ≥ 0.
Then, because (St) is a martingale,
E[Rt
| Ft−1] = X0E[St
| Ft−1] = X0St−1 = Rt−1,
so (Rt) is also a martingale.
Further examples Martingales can also be a little more hidden. Here are two examples.
Example 3.1.31 (Variance of a sum of i.i.d. random variables). Consider again the setting
of Example 3.1.29 with σ
2
:= Var[X1] < ∞. Define
Mt = S
2
t − tσ
2
.
Note that by the triangle inequality and the fact that St has mean zero and is a sum of
independent random variables,
E|Mt
| ≤ X
1≤i≤t
Var[Xi] + tσ
2 ≤ 2tσ
2 < +∞.
Moreover, arguing similarly to the previous example, and using the fact that both Xt and St−1
are square integrable,
E[Mt
| Ft−1] = E[(Xt + St−1)
2 − tσ
2
| Ft−1]
= E[X
2
t + 2XtSt−1 + S
2
t−1 − tσ
2
| Ft−1]
= σ
2 + 0 + S
2
t−1 − tσ
2
= Mt−1,
which proves that (Mt) is a martingale. J
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.1 Background 105
Example 3.1.32 (Eigenvectors of a transition matrix). Let (Xt)t≥0 be a finite Markov chain
with state space E and transition matrix P, and let (Ft)t≥0 be the corresponding filtration.
Suppose f : E → R is such that
X
j
P(i, j)f ( j) = λf (i) ∀i ∈ S.
In other words, f is a (right) eigenvector of P with eigenvalue λ. Define
Mt = λ
−t
f (Xt).
Note that by the finiteness of the state space
E|Mt
| < +∞,
and that further by the Markov property
E[Mt
| Ft−1] = λ
−tE[ f (Xt) | Ft−1]
= λ
−tX
j
P(Xt−1, j)f ( j)
= λ
−t
· λf (Xt−1)
= Mt−1.
That is, (Mt) is a martingale. J
Or we can create martingales out of thin air. We give two important examples that will
appear later.
Example 3.1.33 (Doob martingale: accumulating data). Let X with E|X| < +∞. Define
Mt = E[X | Ft]. Note that E|Mt
| ≤ E|X| < +∞ by Jensen’s inequality, and
E[Mt
| Ft−1] = E[X | Ft−1] = Mt−1
by the tower property. This is known as a Doob martingale. Intuitively, this process tracks our DOOB
expectation of the unobserved X as “more information becomes available.” See the exposure MARTINGALE
martingales in Section 3.2.3 for a concrete illustration of this idea. J
Example 3.1.34 (Martingale transform). Let (Xt)t≥1 be an integrable, adapted process and
let (Ct)t≥1 be a bounded, predictable process. Recall that predictable (Definition B.7.6) means
Ct ∈ Ft−1 for all t, that is, roughly speaking Ct
is “known at time t − 1.” Define
Nt =
X
i≤t
(Xi − E[Xi
| Fi−1])Ci
.
Then,
E|Nt
| ≤ X
i≤t
2E|Xt
|K < +∞,
where |Ct
| < K for all t ≥ 1, and
E[Nt − Nt−1 | Ft−1] = E[(Xt − E[Xt
| Ft−1])Ct
| Ft−1]
= Ct(E[Xt
| Ft−1] − E[Xt
| Ft−1])
= 0,
by taking out what is known. So (Nt) is a martingale.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press106 Martingales and Potentials
When (Xt) is itself a martingale (in which case E[Xi
| Fi−1] = Xi−1 in the definition of Nt),
this is a sort of “stochastic (Stieltjes) integral.” When, instead, (Xt) is a supermartingale (re￾spectively submartingale) and (Ct) is non-negative and bounded, then the same computation
shows that
Nt =
X
i≤t
(Xi − Xi−1)Ci
defines a supermartingale (respectively submartingale). J
As implied by the next lemma, an immediate consequence of Jensen’s inequality (in its
conditional version of Lemma B.6.12), submartingales naturally arise as convex functions
of martingales.
Lemma 3.1.35 If (Mt)t≥0 is a martingale and φ is a convex function such that E|φ(Mt)| <
+∞ for all t, then (φ(Mt))t≥0 is a submartingale. Moreover, if (Mt)t≥0 is a submartingale
and φ is an increasing convex function with E|φ(Mt)| < +∞ for all t, then (φ(Mt))t≥0 is a
submartingale.
Martingales and stopping times A fundamental reason explaining the utility of martin￾gales in analyzing a variety of stochastic processes is that they play nicely with stopping
times, in particular, through what is known as the optional stopping theorem (in its various
forms). We will encounter many applications of this important result. First a definition:
Definition 3.1.36 Let (Mt) be an adapted process and σ be a stopping time. Then,
Mσ
t
(ω) := Mσ(ω)∧t(ω)
STOPPED is Mt stopped at σ.
PROCESS
Lemma 3.1.37 Let (Mt) be a supermartingale and σ be a stopping time. Then the stopped
process (Mσ
t
) is a supermartingale and in particular
E[Mt] ≤ E[Mσ∧t] ≤ E[M0].
The same result holds with equalities if (Mt) is a martingale, and with inequalities in the
opposite direction if (Mt) is a submartingale.
Proof Note that
Mσ
t − M0 =
X
i≤t
Ci(Xi − Xi−1),
with Ci = 1{i ≤ σ} ∈ Fi−1 (which is non-negative and bounded) and Xi = Mi for all i, and
use Example 3.1.34 to conclude that E[Mσ∧t] ≤ E[M0].
On the other hand,
Mt − Mσ
t =
X
i≤t
(1 − Ci)(Xi − Xi−1).
So the other inequality follows from the same argument.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.1 Background 107
Theorem 3.1.38 (Doob’s optional stopping theorem). Let (Mt) be a supermartingale and σ
be a stopping time. Then, Mσ is integrable and
E[Mσ ] ≤ E[M0]
if any of the following conditions hold:
(i) σ is bounded;
(ii) (Mt) is uniformly bounded and σ is almost surely finite;
(iii) E[σ] < +∞ and (Mt) has bounded increments (i.e., there is c > 0 such that |Mt −
Mt−1| ≤ c a.s. for all t);
(iv) (Mt) is non-negative and σ is almost surely finite.
The first three imply equality if (Mt) is a martingale.
Proof Case (iv) is Fatou’s lemma (Proposition B.4.14). We prove (iii). We leave the proof
of the other claims as an exercise (see Exercise 3.5).
From Lemma 3.1.37, we have
E[Mσ∧t − M0] ≤ 0. (3.1.8)
Furthermore, the assumption that E[σ] < +∞ implies that σ < +∞ almost surely. Hence,
we seek to take a limit as t → +∞ inside the expectation. To justify swapping limit and
expectation, note that by a telescoping sum
|Mσ∧t − M0| ≤





X
s≤σ∧t
(Ms − Ms−1)





≤
X
s≤σ
|Ms − Ms−1|
≤ cσ.
The claim now follows from dominated convergence (Proposition B.4.14). Equality holds if
(Mt) is a martingale.
Although the optional stopping theorem (Theorem 3.1.38) is useful, one often works di￾rectly with Lemma 3.1.37 and applies suitable limit theorems (see Proposition B.4.14). The
following martingale-based proof of Wald’s first identity provides an illustration.
Theorem 3.1.39 (Wald’s first identity). Let X1, X2, . . . ∈ L
1 be i.i.d. with E[X1] = µ and let
τ ∈ L
1 be a stopping time. Let St =
Pt
s=1 Xs
. Then,
E[Sτ ] = µE[τ ].
Proof We first prove the result for non-negative Xis. By Example 3.1.29, St − tµ is a mar￾tingale and Lemma 3.1.37 implies that E[Sτ∧t − µ(τ ∧ t)] = 0, or
E[Sτ∧t] = µE[τ ∧ t].
Note that, in the non-negative case, we have Sτ∧t ↑ Sτ and τ ∧ t ↑ τ . Thus, by monotone
convergence (Proposition B.4.14), the claim E[Sτ ] = µE[τ ] follows in that case.
Consider now the general case. Again, E[Sτ∧t] = µE[τ ∧t] and E[τ ∧t] ↑ E[τ ]. Applying
the previous argument to the sum of non-negative random variables Rt =
Pt
s=1
|Xs
| shows
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press108 Martingales and Potentials
that E[Rτ ] = E|X1| E[τ ] < +∞ by assumption. Since |Sτ∧t
| ≤ Rτ for all t by the triangle
inequality, dominated convergence (Proposition B.4.14) implies E[Sτ∧t] → E[Sτ ] and we
are done.
We also recall Wald’s second identity. The proof, which we omit, uses the martingale in
Example 3.1.31.
Theorem 3.1.40 (Wald’s second identity). Let X1, X2, . . . ∈ L
2 be i.i.d. with E[X1] = 0 and
Var[X1] = σ
2 and let τ ∈ L
1 be a stopping time. Then,
E[S
2
τ
] = σ
2E[τ ].
GAMBLER’S We illustrate Wald’s identities on the gambler’s ruin problem that is characteristic of ap￾RUIN plications of stopping times in Markov chains. We consider the “unbiased” and “biased”
cases separately.
Example 3.1.41 (Gambler’s ruin: unbiased case). Let (St) be simple random walk on Z
started at 0 and let τ = τa ∧ τb, where −∞ < a < 0 < b < +∞, where the first visit time
τx was defined formally in Definition 3.1.6.
Claim 3.1.42 We have:
(i) τ < +∞ almost surely;
(ii) P[τa < τb] =
b
b−a
;
(iii) E[τ ] = −ab;
(iv) τa < +∞ almost surely but E[τa] = +∞.
Proof We prove the claims in order.
(i) We argue that in fact E[τ ] < ∞. That follows immediately from the exponential tail
of hitting times in Lemma 3.1.25 for the chain (Sτ∧t) whose (effective) state space,
{a, a + 1, . . . , b}, is finite.
(ii) By Wald’s first identity (Theorem 3.1.39) and (i), we have E[Sτ ] = 0 or
a P[Sτ = a] + b P[Sτ = b] = 0,
that is, using P[Sτ = a] = 1 − P[Sτ = b] = P[τa < τb],
P[τa < τb] =
b
b − a
and P[τa < +∞] ≥ P[τa < τb] → 1,
where we took b → ∞ in the first expression to obtain the second one.
(iii) Because σ
2 = 1, Wald’s second identity (Theorem 3.1.40) says that E[S
2
τ
] = E[τ ].
Furthermore, we have by (ii),
E[S
2
τ
] =
b
b − a
a
2 +
−a
b − a
b
2 = −ab.
Thus, E[τ ] = −ab.
(iv) The first claim was proved in (ii). When b → +∞, τ = τa ∧ τb ↑ τa and monotone
convergence applied to (iii) gives that E[τa] = +∞.
That concludes the proof.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.1 Background 109
Note that (iv) shows that the L
1
condition on the stopping time in Wald’s second identity
(Theorem 3.1.40) is necessary. Indeed, we have shown a
2 = E[S
2
τa
] 6= σ
2E[τa] = +∞. J
Example 3.1.43 (Gambler’s ruin: biased case). The biased random walk on Z with parame￾ter 1/2 < p < 1 is the process (St) with S0 = 0 and St =
P
s≤t Xs
, where the Xss are i.i.d. in
{−1, +1} with P[X1 = 1] = p. Let again τ := τa ∧ τb, where a < 0 < b. Define q := 1 − p,
δ := p − q > 0, and φ(x) := (q/p)
x
.
Claim 3.1.44 We have:
(i) τ < +∞ almost surely;
(ii) P[τa < τb] =
φ(b)−φ(0)
φ(b)−φ(a)
;
(iii) E[τb] =
b
2p−1
;
(iv) τa = −∞ with positive probability.
Proof Let ψt(x) := x − δt. We use two martingales: (φ(St)) and (ψt(St)). Observe that
indeed both processes are clearly integrable and
E[φ(St) | Ft−1] = p(q/p)
St−1+1 + q(q/p)
St−1−1 = φ(St−1)
and
E[ψt(St) | Ft−1] = p[St−1 + 1 − δt] + q[St−1 − 1 − δt] = ψt−1(St−1).
(i) This claim follows by the same argument as in the unbiased case.
(ii) Note that (φ(St)) is a non-negative, bounded martingale since q < p by assumption. By
Lemma 3.1.37 and dominated convergence (Proposition B.4.14),
φ(0) = E[φ(Sτ )] = P[τa < τb] φ(a) + P[τa > τb] φ(b),
or, rearranging, P[τa < τb] =
φ(b)−φ(0)
φ(b)−φ(a)
. Taking b → +∞, by monotonicity
P[τa < +∞] =
1
φ(a)
< 1, (3.1.9)
so that τa = +∞ with positive probability. On the other hand, P[τb < τa] = 1−P[τa <
τb] =
φ(0)−φ(a)
φ(b)−φ(a)
, and taking a → −∞,
P[τb < +∞] = 1.
(iii) By Lemma 3.1.37 applied to (ψt(St)),
0 = E[Sτb∧t − δ(τb ∧ t)]. (3.1.10)
By monotone convergence (Proposition B.4.14), E[τb ∧ t] ↑ E[τb]. Furthermore, ob￾serve that − inft St ≥ 0 almost surely since S0 = 0. Moreover, for x ≥ 0, by (3.1.9),
P[− inf
t
St ≥ x] = P[τ−x < +∞] =

q
p
x
so that E[− inft St] =
P
x≥1 P[− inft St ≥ x] < +∞. Hence, in (3.1.10), we can use
dominated convergence (Proposition B.4.14) with
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press110 Martingales and Potentials
|Sτb∧t
| ≤ max{b, − inf
t
St},
and the fact that τb < +∞ almost surely from (ii) to deduce that E[τb] =
E[Sτb
]
p−q =
b
2p−1
.
(iv) That claim was proved in (ii).
That concludes the proof.
Note that, in (iii) above, in order to apply Wald’s first identity directly we would have had
to prove that τb ∈ L
1 first. J
We also obtain the following maximal version of Markov’s inequality (Theorem 2.1.1).
Theorem 3.1.45 (Doob’s submartingale inequality). Let (Mt) be a non-negative submartin￾gale. Then, for b > 0,
P

sup
0≤s≤t
Ms ≥ b

≤
E[Mt]
b
.
Observe that a naive application of Markov’s inequality implies only that
sup
0≤s≤t
P[Ms ≥ b] ≤
E[Mt]
b
,
where we used that E[Ms] ≤ E[Mt] for all 0 ≤ s ≤ t for a submartingale. Introducing an
appropriate stopping time immediately gives something stronger. (Exercise 3.6 asks for the
supermartingale version of this.)
Proof Let σ be the first time that Mt ≥ b. Then the event of interest can be characterized
as

sup
0≤s≤t
Ms ≥ b

= {Mσ∧t ≥ b}.
By Markov’s inequality,
P[Mσ∧t ≥ b] ≤
E[Mσ∧t]
b
.
Lemma 3.1.37 implies that E[Mσ∧t] ≤ E[Mt], which concludes the proof.
One consequence of the previous bound is a strengthening of Chebyshev’s inequality (The￾orem 2.1.2) for sums of independent random variables.
Corollary 3.1.46 (Kolmogorov’s maximal inequality). Let X1, X2, . . . be independent random
variables with E[Xi] = 0 and Var[Xi] < +∞. Define St =
P
i≤t Xi
. Then, for β > 0,
P

max
i≤t
|Si
| ≥ β

≤
Var[St]
β
2
.
Proof By Example 3.1.29, (St) is a martingale. By Lemma 3.1.35, (S
2
t
) is hence a (non￾negative) submartingale. The result follows from Doob’s submartingale inequality (Theo￾rem 3.1.45).
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.1 Background 111
Convergence Finally another fundamental result about martingales is the following con￾vergence theorem, which we state without proof. We give a quick application in Example
3.1.49.
Theorem 3.1.47 (Martingale convergence theorem). Let (Mt) be a supermartingale bounded
in L1
. Then, (Mt) converges almost surely to a finite limit M∞. Moreover, letting M∞ :=
lim supt Mt
, then M∞ ∈ F∞ and E|M∞| < +∞.
Corollary 3.1.48 (Convergence of non-negative supermartingales). If (Mt) is a non-negative
supermartingale, then Mt converges almost surely to a finite limit M∞ with E[M∞] ≤ E[M0].
Proof By the supermartingale property, (Mt) is bounded in L
1
since
E|Mt
| = E[Mt] ≤ E[M0], ∀t.
Then we use the martingale convergence theorem (Theorem 3.1.47) and Fatou’s lemma
(Proposition B.4.14).
Example 3.1.49 (Pólya’s urn). An urn contains one red ball and one green ball. At each
time, we pick one ball and put it back with an extra ball of the same color. This process is
known as Pólya’s urn. Let Rt (respectively Gt) be the number of red balls (respectively green PÓLYA’S URN
balls) after the tth draw. Let
Ft
:= σ(R0, G0, R1, G1, . . . , Rt
, Gt).
Define Mt
to be the fraction of green balls after the tth draw. Then,
E[Mt
| Ft−1] =
Rt−1
Gt−1 + Rt−1
Gt−1
Gt−1 + Rt−1 + 1
+
Gt−1
Gt−1 + Rt−1
Gt−1 + 1
Gt−1 + Rt−1 + 1
=
Gt−1
Gt−1 + Rt−1
= Mt−1.
Since Mt ≥ 0 and is a martingale, we have Mt → M∞ almost surely. In fact, Exercise 3.4
asks for a proof that
P[Gt = m + 1] =

t
m

m!(t − m)!
(t + 1)!
=
1
t + 1
.
So taking a limit as t → +∞,
P[Mt ≤ x] =
bx(t + 2) − 1c
t + 1
→ x.
That is, (Mt) converges in distribution to a uniform random variable on [0, 1]. J
Convergence of the expectation in general requires stronger conditions. A simple case is
boundedness in L
2
. Before stating the result, we derive a key property of martingales in L
2
which will be useful later.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press112 Martingales and Potentials
Lemma 3.1.50 (Orthogonality of increments). Let (Mt) be a martingale with Mt ∈ L
2
. Let
s ≤ t ≤ u ≤ v. Then,
hMt − Ms
, Mv − Mui = 0,
where hX, Yi = E[XY].
Proof Use Mu = E[Mv
| Fu] and Mt − Ms ∈ Fu, and apply the L
2
characterization of the
conditional expectation (Theorem B.6.2).
In other words, martingale increments over disjoint time intervals are uncorrelated (provided
the second moment exists). Note that this is weaker than the independence of increments of
random walks. (See Section 3.2.1 for more discussion on this.)
Theorem 3.1.51 (Convergence of martingales bounded in L
2
). Let (Mt) be a martingale
with Mt ∈ L
2
. Then, (Mt) is bounded in L2
if and only if
X
k≥1
E[(Mt − Mt−1)
2
] < +∞.
When this is the case, Mt converges almost surely and in L2
to a finite limit M∞, and further￾more
E[Mt] → E[M∞] < +∞
as t → +∞.
Proof Writing Mt as a telescoping sum of increments, the orthogonality of increments
(Lemma 3.1.50) implies
E[M2
t
] = E


 
M0 +
Xt
s=1
(Ms − Ms−1)
!2


= E[M2
0
] +
Xt
s=1
E[(Ms − Ms−1)
2
],
proving the first claim.
By the monotonicity of norms (Lemma B.4.16), (Mt) bounded in L
2
implies that (Mt) is
bounded in L
1
, which, in turn, implies that Mt converges almost surely to a finite limit M∞
with E|M∞| < +∞ by Theorem 3.1.47. Then, using Fatou’s lemma (Proposition B.4.14) in
E[(Mt+s − Mt)
2
] =
X
t+1≤i≤t+s
E[(Mi − Mi−1)
2
]
gives
E[(M∞ − Mt)
2
] ≤
X
t+1≤i
E[(Mi − Mi−1)
2
].
The right-hand side goes to 0 since the series is finite, which proves the second claim.
The last claim follows from Lemmas B.4.16 and B.4.17.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.1 Background 113
3.1.4 F Percolation: Critical Regime on Infinite d-Regular Tree
Consider bond percolation (see Definition 1.2.1) on the infinite d-regular tree Td rooted at a
vertex 0. In Section 2.3.3, we showed that
pc(Td) = sup{p ∈ [0, 1]: Pp[|C0| = +∞] = 0} =
1
d − 1
,
where recall that C0 is the open cluster of the root. Here we consider the critical case, that is,
we set density p =
1
d−1
. (The same results apply to the infinite b-ary tree bTb with d = b+1.)
Assume d ≥ 3 (since d = 2 is simply a path).
First:
Claim 3.1.52 |C0| < +∞ almost surely.
Let Xn := |∂n ∩ C0|, where ∂n are the nth level vertices. In Section 2.3.3, we proved the same
claim in the subcritical case using the first moment method. It does not work here because
EXn = d(d − 1)n−1
p
n =
d
d − 1
9 0.
Instead, we use a martingale argument which will be generalized when we discuss branching
processes in Section 6.1.
Proof of Claim 3.1.52 Let b := d − 1 be the branching ratio. Because the root has a dif￾ferent number of children, we consider the descendants of its children. Let Zn be the num￾ber of vertices in the open cluster of the first child of the root n levels below it and let
Fn = σ(Z0, . . . , Zn). Then, Z0 = 1 and
E[Zn | Fn−1] = bpZn−1 = Zn−1.
So (Zn) is a non-negative, integer-valued martingale and it converges almost surely to a finite
limit by Corollary 3.1.48. (In particular, E[Zn] = 1, which will be useful below.) But, clearly,
for any integer k > 0 and N ≥ 0,
P[Zn = k ∀n ≥ N] = 0,
so it must be that the limit is 0 almost surely. In other words, Zn is eventually 0 for all n large
enough. This is true for every child of the root. Hence, the open cluster of the root is finite
almost surely.
On the other hand:
Claim 3.1.53
E|C0| = +∞.
Proof Consider the descendant subtree, T1, of the first child of the root, which we denote
by 1. Let Ce1 be the open cluster of 1 in T1. As we showed in the previous claim, the ex￾pected number of vertices on any level of T1 is 1. So E|Ce1| = +∞ by summing over the
levels.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press114 Martingales and Potentials
3.2 Concentration for Martingales and Applications
The Chernoff–Cramér method extends naturally to martingales. This observation leads to
powerful new tail bounds that hold far beyond the case of sums of independent variables.
In particular, it will allow us to prove one version of the more general concentration phe￾nomenon, which can be stated informally as: a function f (X1, . . . , Xn) of many independent
random variables that is not too sensitive to any of its coordinates tends to be close to its
mean.
3.2.1 Azuma–Hoeffding Inequality
The main result of this section is the following generalization of Hoeffding’s inequality
(Theorem 2.4.10).
Theorem 3.2.1 (Maximal Azuma–Hoeffding inequality). Let (Zt)t∈Z+ be a martingale with
respect to the filtration (Ft)t∈Z+
. Assume that there are predictable processes (At) and (Bt)
(i.e., At
, Bt ∈ Ft−1) and constants 0 < ct < +∞ such that for all t ≥ 1, almost surely,
At ≤ Zt − Zt−1 ≤ Bt and Bt − At ≤ ct
.
Then, for all β > 0,
P

sup
0≤i≤t
(Zi − Z0) ≥ β

≤ exp 
−
2β
2
P
i≤t
c
2
i
!
.
Applying this inequality to (−Zt) gives a tail bound in the other direction.
Proof of Theorem 3.2.1 As in the Chernoff–Cramér method, we start by applying Markov’s
inequality (Theorem 2.1.1). Here we use the maximal version for submartingales, Doob’s
submartingale inequality (Theorem 3.1.45). First notice that e
sx is increasing and convex for
s > 0, so that by Lemma 3.1.35 the process (e
s(Zt−Z0)
)t
is a submartingale. Hence, for s > 0,
by Theorem 3.1.45
P

sup
0≤i≤t
(Zi − Z0) ≥ β

= P

sup
0≤i≤t
e
s(Zi−Z0) ≥ e
sβ

≤
E

e
s(Zt−Z0)

e
sβ
=
E
h
e
s
Pt
r=1
(Zr−Zr−1)
i
e
sβ
. (3.2.1)
Unlike the Chernoff–Cramér case, however, the terms in the exponent are not independ￾ent. Instead, to exploit the martingale property, we condition on the filtration. By taking out
what is known (Lemma B.6.13),
E
h
E
h
e
s
Pt
r=1
(Zr−Zr−1)


 Ft−1
ii = E
h
e
s
Pt−1
r=1
(Zr−Zr−1) E
h
e
s(Zt−Zt−1)


 Ft−1
ii .
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.2 Concentration for Martingales and Applications 115
The martingale property and the assumption in the statement imply that, conditioned on
Ft−1, the random variable Zt − Zt−1 is centered and lies in an interval of length ct
. Hence, by
Hoeffding’s lemma (Lemma 2.4.12), it holds almost surely that
E
h
e
s(Zt−Zt−1)


 Ft−1
i
≤ exp
s
2
c
2
t
/4
2

= exp
c
2
t
s
2
8

. (3.2.2)
Using the tower property (Lemma B.6.16) and arguing by induction, we obtain
E

e
s(Zt−Z0)

≤ exp 
s
2 P
r≤t
c
2
r
8
!
.
Put differently, we have proved that Zt − Z0 is sub-Gaussian with variance factor 1
4
P
r≤t
c
2
r
.
By (2.4.16) (or, equivalently, by choosing s = β/ 1
4
P
r≤t
c
2
r
in (3.2.1)), we get the result.
In Theorem 3.2.1, the martingale difference sequence (Xt), where Xt
:= Zt − Zt−1, is not MARTINGALE
only “pairwise uncorrelated” by Lemma 3.1.50, that is, DIFFERENCE
E[XsXr] = 0 ∀r 6= s,
but it is in fact “mutually uncorrelated,” that is,
E

Xj1
· · · Xjk

= 0 ∀ k ≥ 1, ∀ 1 ≤ j1 < · · · < jk
.
This stronger property helps explain why P
r≤t Xr
is highly concentrated. This point is the
subject of Exercise 3.7, which guides the reader through a slightly different proof of the
Azuma–Hoeffding inequality. Compare with Exercises 2.5 and 2.6.
3.2.2 Method of Bounded Differences
The power of the maximal Azuma–Hoeffding inequality (Theorem 3.2.1) is that it produces
tail inequalities for quantities other than sums of independent variables. The setting is the
following. Let X1, . . . , Xn be independent random variables where Xi
is Xi-valued for all i
and let X = (X1, . . . , Xn). Assume that f : X1 × · · · ×Xn → R is a measurable function. Our
goal is to characterize the concentration properties of f (X) around its expectation in terms
of its “discrete derivatives”:
Di
f (x) := sup
y∈Xi
f (x1, . . . , xi−1, y, xi+1, . . . , xn)
− inf
y
0∈Xi
f (x1, . . . , xi−1, y
0
, xi+1, . . . , xn),
where x = (x1, . . . , xn) ∈ X1 ×· · ·×Xn. We think of Di
f (x) as a measure of the “sensitivity”
of f to its ith coordinate.
High-level idea
We begin with two easier bounds that we will improve below. The trick to analyzing the
concentration of f (X) is to consider the Doob martingale (see Example 3.1.33)
Zi = E[ f (X) | Fi], (3.2.3)
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press116 Martingales and Potentials
where Fi = σ(X1, . . . , Xi), which is well defined provided E| f (X)| < +∞. Note that
Zn = E[ f (X) | Fn] = f (X)
and
Z0 = E[ f (X)],
so that we can write
f (X) − E[ f (X)] =
Xn
i=1
(Zi − Zi−1).
Intuitively, the martingale difference Zi − Zi−1 tracks the change in our expectation of f (X)
as Xi
is revealed.
In fact, a clever probabilistic argument relates martingale differences directly to discrete
derivatives. Let X
0 = (X
0
1
, . . . , X
0
n
) be an independent copy of X and let
X
(i) = (X1, . . . , Xi−1, X
0
i
, Xi+1, . . . , Xn).
Then,
Zi − Zi−1 = E[ f (X) | Fi] − E[ f (X) | Fi−1]
= E[ f (X) | Fi] − E[ f (X
(i)
) | Fi−1]
= E[ f (X) | Fi] − E[ f (X
(i)
) | Fi]
= E[ f (X) − f (X
(i)
) | Fi].
Note that we crucially used the independence of the Xk s in the second and third lines. But
then, by Jensen’s inequality (Lemma B.6.12),
|Zi − Zi−1| ≤ kDi
f k∞. (3.2.4)
By the orthogonality of increments of martingales in L
2
(Lemma 3.1.50), we immediately
obtain a bound on the variance of f
Var[ f (X)] = E[(Zn − Z0)
2
] =
Xn
i=1
E

(Zi − Zi−1)
2

≤
Xn
i=1
kDi
f k
2
∞. (3.2.5)
By the maximal Azuma–Hoeffding inequality and the fact that
Zi − Zi−1 ∈ [−kDi
f k∞, kDi
f k∞],
we also get a bound on the tail
P[ f (X) − E[ f (X)] ≥ β] ≤ exp 
−
β
2
2
P
i≤n
kDi
f k
2
∞
!
. (3.2.6)
A more careful analysis, which we detail below, leads to better bounds.
We emphasize that, although it may not be immediately obvious, independence plays a
crucial role in the bound (3.2.4), as the next example shows.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.2 Concentration for Martingales and Applications 117
Example 3.2.2 (A counterexample). Let f (x1, . . . , xn) = x1 + · · · + xn, where xi ∈ {−1, 1}
for all i. Then,
kD1 f k∞ = sup
x2,...,xn
[(1 + x2 + · · · + xn) − (−1 + x2 + · · · + xn)] = 2,
and similarly, kDi
f k∞ = 2 for i = 2, . . . , n. Let X1 be a uniform random variable on {−1, 1}.
First consider the case where we set X2, . . . , Xn all equal to X1. Then,
E[ f (X1, . . . , Xn)] = 0
and
E[ f (X1, . . . , Xn) | X1] = nX1,
so that
|E[ f (X1, . . . , Xn) | X1] − E[ f (X1, . . . , Xn)]| = n > 2.
In particular, the corresponding Doob martingale does not have increments bounded by
kDi
f k∞ = 2.
For a less extreme example that has support over all of {−1, 1}
n
, let
Ui =
(
1 w.p. 1 − ε,
−1 w.p. ε,
for some ε > 0 independently for all i = 1, . . . , n − 1. Let again X1 be a uniform random
variable on {−1, 1} and, for i = 2, . . . , n, define the random variable Xi = Ui−1Xi−1, that is,
Xi
is the same as Xi−1 with probability 1 − ε and otherwise is flipped. Then,
E[ f (X1, . . . , Xn)] = E [X1 + · · · + Xn]
= E

X1

1 +
Xn−1
i=1
Y
j≤i
Uj




= E[X1] E

1 +
Xn−1
i=1
Y
j≤i
Uj


= 0,
by the independence of X1 and the Uis. Similarly,
E[ f (X1, . . . , Xn) | X1] = X1 E

1 +
Xn−1
i=1
Y
j≤i
Uj

 = X1
 Xn−1
i=0
(1 − 2ε)
i
!
,
so that
|E[ f (X1, . . . , Xn) | X1] − E[ f (X1, . . . , Xn)]| = Xn−1
i=0
(1 − 2ε)
i
!
> 2,
for ε small enough and n ≥ 3. In particular, the corresponding Doob martingale does not
have increments bounded by kDi
f k∞ = 2. J
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press118 Martingales and Potentials
Variance bounds
We give improved bounds on the variance. Our first bound explicitly decomposes the vari￾ance of f (X) over the contributions of its individual entries.
Theorem 3.2.3 (Tensorization of the variance). Let X1, . . . , Xn be independent random vari￾ables where Xi
is Xi-valued for all i and let X = (X1, . . . , Xn). Assume that f : X1 × · · · ×
Xn → R is a measurable function with E[ f (X)
2
] < +∞. Define Fi = σ(X1, . . . , Xi),
Gi = σ(X1, . . . , Xi−1, Xi+1, . . . , Xn), and Zi = E[ f (X) | Fi]. Then, we have
Var[ f (X)] ≤
Xn
i=1
E [Var [f (X) | Gi]] .
(It may be helpful to recall the formula Var[Y] = E [Var [Y | H]] + Var [E [Y | H]].)
Proof of Theorem 3.2.3 The key lemma is the following.
Lemma 3.2.4
E [E [f (X) | Gi] | Fi] = E [f (X) | Fi−1]
Proof By the tower property (Lemma B.6.16),
E [f (X) | Fi−1] = E [E [f (X) | Gi] | Fi−1] .
Moreover, σ(Xi) is independent of σ(Gi
, Fi−1), so by the role of independence (Lemma
B.6.14), we have
E [E [f (X) | Gi] | Fi−1] = E [E [f (X) | Gi] | Fi−1, Xi] = E [E [f (X) | Gi] | Fi] .
Combining the last two displays gives the result.
Again, we take advantage of the orthogonality of increments to write
Var[ f (X)] =
Xn
i=1
E

(Zi − Zi−1)
2

.
By Lemma 3.2.4,
(Zi − Zi−1)
2 = (E [f (X) | Fi] − E [f (X) | Fi−1])
2
= (E [f (X) | Fi] − E [E [f (X) | Gi] | Fi])
2
= (E [f (X) − E [f (X) | Gi] | Fi])
2
≤ E

(f (X) − E [f (X) | Gi])
2

 Fi

,
where we used Jensen’s inequality on the last line. Taking expectations and using the tower
property,
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.2 Concentration for Martingales and Applications 119
Var[ f (X)] =
Xn
i=1
E

(Zi − Zi−1)
2

≤
Xn
i=1
E

E

(f (X) − E [f (X) | Gi])
2

 Fi

=
Xn
i=1
E

(f (X) − E [f (X) | Gi])
2

=
Xn
i=1
E

E

(f (X) − E [f (X) | Gi])
2

 Gi

=
Xn
i=1
E [Var [f (X) | Gi]] .
That concludes the proof.
We derive two useful consequences of the tensorization property of the variance. The first
one is the Efron–Stein inequality.
Theorem 3.2.5 (Efron–Stein inequality). Let X1, . . . , Xn be independent random variables
where Xi
is Xi-valued for all i and let X = (X1, . . . , Xn). Assume that f : X1 × · · · ×Xn → R
is a measurable function with E[ f (X)
2
] < +∞. Let X0 = (X
0
1
, . . . , X
0
n
) be an independent
copy of X and
X
(i) = (X1, . . . , Xi−1, X
0
i
, Xi+1, . . . , Xn).
Then,
Var[ f (X)] ≤
1
2
Xn
i=1
E[(f (X) − f (X
(i)
))2
].
Proof Observe that if Y
0
is an independent copy of Y ∈ L
2
, then Var[Y] =
1
2
E[(Y − Y
0
)
2
],
which can be seen by adding and subtracting the mean, expanding and using independence.
Hence,
Var [f (X) | Gi] =
1
2
E[(f (X) − f (X
(i)
))2
| Gi],
where we used the independence of the Xis and X
0
i
s. Plugging back into Theorem 3.2.3 gives
the claim.
Our second consequence of Theorem 3.2.3 is a Poincaré-type inequality which relates the
variance of a function to its expected “square gradient.” Compare to the much weaker (3.2.5),
which involves in each term a supremum rather than an expectation.
Theorem 3.2.6 (Bounded differences inequality). Let X1, . . . , Xn be independent random
variables where Xi
is Xi-valued for all i and let X = (X1, . . . , Xn). Assume that f : X1 ×· · ·×
Xn → R is a measurable function with E[ f (X)
2
] < +∞. Then,
Var[ f (X)] ≤
1
4
Xn
i=1
E[Di
f (X)
2
].
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press120 Martingales and Potentials
Proof By Lemma 2.4.11,
Var [f (X) | Gi] ≤
1
4
Di
f (X)
2
.
Plugging back into Theorem 3.2.3 gives the claim.
POINCARÉ Remark 3.2.7 For comparison, a version of the Poincaré inequality in one dimension as￾INEQUALITY serts the following: let f : [0, T] → R be continuously differentiable with f (0) = f (T) = 0,
R T
0
f (x)
2 + f
0
(x)
2dx < +∞ and R T
0
f (x)dx = 0, then
Z T
0
f (x)
2
dx ≤ C
Z T
0
f
0
(x)
2
dx, (3.2.7)
where the best possible C is T2
/4π
2
(see, for example, [SS03, chapter 3, Exercise 11]; this
case is also known as Wirtinger’s inequality). We give a quick proof for T = 1 with the
suboptimal C = 1. Note that f (x) =
R x
0
f
0
( y)dy, so by Cauchy–Schwarz (Theorem B.4.8),
f (x)
2 ≤ x
Z x
0
f
0
( y)
2
dy ≤
Z 1
0
f
0
( y)
2
dy.
The result follows by integration. Intuitively, for a function with mean 0 to have a large norm,
it must have a large absolute derivative somewhere.
Example 3.2.8 (Longest common subsequence). Let X1, . . . , X2n be independent uniform
random variables in {−1, +1}. Let Z be the length of the longest common subsequence in
(X1, . . . , Xn) and (Xn+1, . . . , X2n), that is,
Z = max 
k : ∃1 ≤ i1 < i2 < · · · < ik ≤ n
and n + 1 ≤ j1 < j2 < · · · < jk ≤ 2n
such that Xi1 = Xj1
, Xi2 = Xi2
, . . . , Xik = Xjk
	
.
Then, writing Z = f (X1, . . . , X2n), it follows that kDi
f k∞ ≤ 1. Indeed, fix x = (x1, . . . , x2n)
and let x
i,+ (respectively x
i,−) be x, where the ith component is replaced with +1 (re￾spectively −1). Assume without loss of generality that f (x
i,−) ≤ f (x
i,+). Then, | f (x
i,+) −
f (x
i,−)| ≤ 1 because removing the ith component (and its match) from a longest common
subsequence when xi = +1 (if present) decreases the length by 1. Since this is true for any
x, we have kDi
f k∞ ≤ 1. Finally, by the bounded differences inequality (Theorem 3.2.6),
Var[Z] ≤
1
4
X
2n
i=1
kDi
f k
2
∞ ≤
n
2
,
which is much better than the obvious Var[Z] ≤ E[Z
2
] ≤ n
2
. Note that we did not require
any information about the expectation of Z. J
McDiarmid’s inequality
The following powerful consequence of the Azuma–Hoeffding inequality is commonly re￾ferred to as the method of bounded differences. Compare to (3.2.6).
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.2 Concentration for Martingales and Applications 121
Theorem 3.2.9 (McDiarmid’s inequality). Let X1, . . . , Xn be independent random variables
where Xi
is Xi-valued for all i, and let X = (X1, . . . , Xn). Assume f : X1 × · · · × Xn → R is
a measurable function such that kDi
f k∞ < +∞ for all i. Then, for all β > 0,
P[ f (X) − Ef (X) ≥ β] ≤ exp 
−
2β
2
P
i≤n
kDi
f k
2
∞
!
.
Once again, applying the inequality to −f gives a tail bound in the other direction.
Proof of Theorem 3.2.9 As before, we let
Zi = E[ f (X) | Fi],
where Fi = σ(X1, . . . , Xi), and we let Gi = σ(X1, . . . , Xi−1, Xi+1, . . . , Xn). Then, it holds that
Ai ≤ Zi − Zi−1 ≤ Bi
, where
Bi = E
"
sup
y∈Xi
f (X1, . . . , Xi−1, y, Xi+1, . . . , Xn) − f (X)





Fi−1
#
and
Ai = E

inf
y∈Xi
f (X1, . . . , Xi−1, y, Xi+1, . . . , Xn) − f (X)




Fi−1

.
Indeed, since σ(Xi) is independent of Fi−1 and Gi
, by the role of independence (Lemma B.6.14),
Zi = E [f (X) | Fi]
≤ E
"
sup
y∈Xi
f (X1, . . . , Xi−1, y, Xi+1, . . . , Xn)





Fi
#
= E
"
sup
y∈Xi
f (X1, . . . , Xi−1, y, Xi+1, . . . , Xn)





Fi−1, Xi
#
= E
"
sup
y∈Xi
f (X1, . . . , Xi−1, y, Xi+1, . . . , Xn)





Fi−1
#
,
and similarly for the other direction. Moreover, by definition, Bi − Ai ≤ kDi
f k∞ := ci
. The
Azuma–Hoeffding inequality then gives the result.
Examples
The moral of McDiarmid’s inequality is that functions of independent variables that are
smooth, in the sense that they do not depend too much on any one of their variables, are
concentrated around their mean. Here are some straightforward applications.
Example 3.2.10 (Balls and bins: empty bins). Suppose we throw m balls into n bins inde￾pendently, uniformly at random. The number of empty bins, Zn,m, is centered at
EZn,m = n

1 −
1
n
m
.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press122 Martingales and Potentials
Writing Zn,m as the sum of indicators Pn
i=1
1Bi
, where Bi
is the event that bin i is empty, is a
natural first attempt at proving concentration around the mean. However, there is a problem –
the Bis are not independent. Indeed, because there is a fixed number of bins, the event Bi
intuitively makes the other such events less likely. Instead, let Xj be the index of the bin in
which ball j lands. The Xjs are independent by construction and, moreover, letting Zn,m =
f (X1, . . . , Xm) we have kDi
f k∞ ≤ 1. Indeed, moving a single ball changes the number of
empty bins by at most 1 (if at all). Hence, by the method of bounded differences,
P




Zn,m − n

1 −
1
n
m




≥ b
√
m

≤ 2e
−2b
2
. J
Example 3.2.11 (Pattern matching). Let X = (X1, X2, . . . , Xn) be i.i.d. random variables
taking values uniformly at random in a finite set S of size s = |S|. Let a = (a1, . . . , ak )
be a fixed string of elements of S. We are interested in the number of occurrences of a as
a (consecutive) substring in X, which we denote by Nn. Denote by Ei
the event that the
substring of X starting at i is a. Summing over the starting positions and using the linearity
of expectation, the mean of Nn is
ENn = E
"nX−k+1
i=1
1Ei
#
= (n − k + 1)
1
s
k
.
However, the 1Ei
s are not independent. So we cannot use a Chernoff bound for Poisson trials
(Theorem 2.4.7). Instead, we use the fact that Nn = f (X), where kDi
f k∞ ≤ k, as each Xi
appears in at most k substrings of length k. By the method of bounded differences, for all
b > 0,
P
"




Nn − (n − k + 1)
1
s
k





≥ bk√
n
#
≤ 2e
−2b
2
. J
The last two examples are perhaps not surprising in that they involve “sums of weakly inde￾pendent” indicator variables. One might reasonably expect a sub-Gaussian-type inequality
in that case. The next application is more striking and hints at connections to isoperimetric
considerations (which we will not explore here).
Example 3.2.12 (Concentration of measure on the hypercube). For A ⊆ {0, 1}
n
, a subset of
the hypercube, and r > 0, we let
Ar =

x ∈ {0, 1}
n
: inf
a∈A
kx − ak1 ≤ r

be the points at `
1 distance r from A. Fix ε ∈ (0, 1/2) and assume that |A| ≥ ε2
n
. Let λε
be such that e
−2λ
2
ε = ε. The following application of the method of bounded differences
indicates that much of the uniform measure on the high-dimensional hypercube lies in a
close neighborhood of any such set A. This is an example of the concentration of measure
phenomenon.
Claim 3.2.13
r > 2λε
√
n =⇒ |Ar
| ≥ (1 − ε)2n
.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.2 Concentration for Martingales and Applications 123
Proof Let X = (X1, . . . , Xn) be uniformly distributed in {0, 1}
n
. Note that the coordinates
are in fact independent. The function
f (x) = inf
a∈A
kx − ak1
has kDi
f k∞ ≤ 1. Indeed, changing one coordinate of x can increase the `
1 distance to the
closest point to x by at most 1; in the other direction, if a one-coordinate change were to
decrease f by more than 1, reversing it would produce an increase of that same amount – a
contradiction. Hence, McDiarmid’s inequality gives
P [Ef (X) − f (X) ≥ β] ≤ exp
−
2β
2
n

.
Choosing β = Ef (X) and noting that f (x) ≤ 0 if and only if x ∈ A gives
P[A] ≤ exp
−
2(Ef (X))2
n

,
or, rearranging and using our assumption on A,
Ef (X) ≤
s
1
2
n log
1
P[A]
≤
r
1
2
n log
1
ε
= λε
√
n.
By a second application of the method of bounded differences with β = λε
√
n,
P

f (X) ≥ 2λε
√
n

≤ P [ f (X) − Ef (X) ≥ b] ≤ exp
−
2β
2
n

= ε.
The result follows by observing that, with r > 2λε
√
n,
|Ar
|
2
n
≥ P

f (X) < 2λε
√
n

≥ 1 − ε.
Claim 3.2.13 is striking for two reasons: (1) the radius 2λε
√
n is much smaller than n, the
diameter of {0, 1}
n
; and (2) it applies to any A. The smallest r such that |Ar
| ≥ (1 − ε)2n
in
general depends on A. Here are two extremes.
For γ > 0, let
B(γ ) :=

x ∈ {0, 1}
n
: kxk1 ≤
n
2
− γ
r
n
4

.
Note that letting for Yn ∼ B(n,
1
2
),
1
2
n
|B(γ )| =
n
2 −γ
√n X 4
`=0

n
`

2
−n = P

Yn ≤
n
2
− γ
r
n
4

. (3.2.8)
By the Berry–Esséen theorem (e.g., [Dur10, Theorem 3.4.9]), there is a C > 0 such that,
after rearranging the final quantity in (3.2.8),




P

Yn − n/2
√
n/4
≤ −γ

− P[Z ≤ −γ ]




≤
C
√
n
,
where Z ∼ N(0, 1). Let ε < ε0 < 1/2 and let γε
0 be such that P[Z ≤ −γε
0] = ε
0
. Then,
setting A := B(γε
0), for n large enough, we have |A| ≥ ε2
n by (3.2.8). On the other hand,
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press124 Martingales and Potentials
setting r := γε
0
√
n/4, we have Ar ⊆ B(0), so that |Ar
| ≤ 1
2
2
n < (1 − ε)2n
. We have shown
that r = (
√
n) is in general required for Claim 3.2.13 to hold.
For an example at the other extreme, assume for simplicity that N := ε2
n
is an integer.
Let A ⊆ {0, 1}
n be constructed as follows: starting from the empty set, add points in {0, 1}
n
to A independently, uniformly at random until |A| = N. Set r := 2. Each point selected in A
has ￾
n
2

points within `
1 distance 2. By a union bound, the probability that Ar does not cover
all of {0, 1}
n
is at most
P[|{0, 1}
n
\Ar
| > 0] ≤
X
x∈{0,1}
n
P[x ∈/ Ar] ≤ 2
n
 
1 −
￾
n
2

2
n
!ε2
n
≤ 2
n
e
−ε(
n
2)
,
where, in the second inequality, we considered only the first N picks in the construction of
A (possibly with repeats), and in the third inequality we used 1 − z ≤ e
−z
for all z ∈ R (see
Exercise 1.16). In particular, as n → +∞,
P[|{0, 1}
n
\Ar
| > 0] < 1.
So for n large enough there is a set A such that Ar = {0, 1}
n
, where r = 2. J
Remark 3.2.14 In fact, it can be shown that sets of the form {x: kxk1 ≤ s} have the smallest
“expansion” among subsets of {0, 1}
n of the same size, a result known as Harper’s vertex
isoperimetric theorem. See, for example, [BLM13, Theorem 7.6 and Exercises 7.11–7.13].
3.2.3 F Random Graphs: Exposure Martingale and Application to the Chromatic
Number in Erd ˝os–Rényi Model
Exposure martingales In the context of the Erdos–Rényi graph model (Definition ˝ 1.2.2),
a common way to apply the Azuma–Hoeffding inequality (Theorem 3.2.1) is to introduce
an “exposure martingale.” Let G ∼ Gn,p and let F be any function on graphs such that
En,p|F(G)| < +∞ for all n, p. Choose an arbitrary ordering of the vertices and, for i =
1, . . . , n, denote by Hi
the subgraph of G induced by the first i vertices. Then, the filtration
Hi = σ(H1, . . . , Hi), i = 1, . . . , n, corresponds to exposing the vertices of G one at a time.
The Doob martingale
Zi = En,p[F(G) | Hi], i = 1, . . . , n,
VERTEX is known as a vertex exposure martingale. An alternative way to define the filtration is to
EXPOSURE
MARTINGALE
consider instead the random variables Xi = (1{{i, j}∈G}
: 1 ≤ j ≤ i) for i = 2, . . . , n. In other
words, Xi
is a vector whose entries indicate the status (present or absent) of all potential edges
incident to i and a vertex preceding it. Hence, Hi = σ(X2, . . . , Xi) for i = 1, . . . , n (and H1
is trivial as it corresponds to a graph with a single vertex and no edge). This representation
has an important property: the Xis are independent as they pertain to disjoint subsets of
edges. We are then in the setting of the method of bounded differences. Rewriting F(G) =
f (X1, . . . , Xn), the vertex exposure martingale coincides with the martingale (3.2.3) used in
that context.
As an example, consider the chromatic number χ(G), that is, the smallest number of col￾ors needed in a proper coloring of G. Define fχ (X1, . . . , Xn) := χ(G). We use the following
combinatorial observation to bound kDi
fχ k∞.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Pre3.2 Concentration for Martingales and Applications 125
Lemma 3.2.15 Altering the status (absent or present) of edges incident to a fixed vertex v
changes the chromatic number by at most 1.
Proof Altering the status of edges incident to v increases the chromatic number by at most
1, since in the worst case one can simply use an extra color for v. On the other hand, if
the chromatic number were to decrease by more than 1 after altering the status of edges
incident to v, reversing the change and using the previous observation would produce a
contradiction.
A fortiori, since Xi depends on a subset of the edges incident to node i, Lemma 3.2.15
implies that kDi
fχ k∞ ≤ 1. Hence, for all 0 < p < 1 and n, by an immediate application of
McDiarmid’s inequality (Theorem 3.2.9):
Claim 3.2.16
Pn,p
h
|χ(G) − En,p[χ(G)]| ≥ b
√
n − 1
i
≤ 2e
−2b
2
.
Edge exposure martingales can be defined in a similar manner: reveal the edges one at a EDGE
EXPOSURE
MARTINGALE
time in an arbitrary order. By Lemma 3.2.15, the corresponding function also satisfies the
same `
∞ bound. Observe however that, for the chromatic number, edge exposure results in
a much weaker bound as the 2(n
2
) random variables produce only a linear in n deviation
for the same tail probability. (The reader may want to ponder the apparent paradox: using
a larger number of independent variables seemingly leads to weaker concentration in this
case.)
Remark 3.2.17 Note that Claim 3.2.16 tells us nothing about the expectation of χ(G). It
turns out that, up to logarithmic factors, En,pn
[χ(G)] is of order npn when pn ∼ n
−α
for some
0 < α < 1. We will not prove this result here. See the “Bibliographic remarks” at the end of
this chapter for more on the chromatic number of Erd ˝os–Rényi graphs.
The chromatic number is concentrated on few values Much stronger concentration re￾sults can be obtained: when pn = n
−α with α > 1
2
, the chromatic number χ(G) is in fact
concentrated on two values! We give a partial result along those lines which illustrates a less
straightforward choice of martingale in the Azuma–Hoeffding inequality (Theorem 3.2.1).
Claim 3.2.18 Let pn = n
−α with α > 5
6
and let Gn ∼ Gn,pn
. Then, for any ε > 0 there is
ϕn := ϕn(α, ε) such that
Pn,pn
[ ϕn ≤ χ(Gn) ≤ ϕn + 3 ] ≥ 1 − ε
for all n large enough.
Proof We consider the following martingale. Let ϕn be the smallest integer such that
Pn,pn
[χ(Gn) ≤ ϕn] >
ε
3
. (3.2.9)
Let Fn(Gn) be the minimal size of a set of vertices, U, in Gn such that Gn\U is ϕn-colorable.
Let (Zi) be the vertex exposure martingale associated to the quantity Fn(Gn). The proof
proceeds in two steps: we show that (1) all but O(
√
n) vertices can be ϕn-colored and (2)
the remaining vertices can be colored using three additional colors. See Figure 3.1 for an
illustration of the proof strategy.
We claim that (Zi) has increments bounded by 1.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press126 Martingales and Potentials
Figure 3.1 All but O(
√
n) vertices are colored using ϕn colors. The remaining
vertices are colored using three additional colors.
Lemma 3.2.19 Changing the edges incident to a single vertex can change Fn by at most 1.
Proof Changing the edges incident to v can increase Fn by at most 1. Indeed, if Fn increases
after such a change, it must be that v ∈/ U since in the other case the edges incident to v
would not affect the colorability of Gn \U – present or not. So we can add v to U and restore
colorability. On the other hand, if Fn were to decrease by more than 1, reversing the change
and using the previous observation would give a contradiction.
Choose bε such that e
−b
2
ε
/2 =
ε
3
. Then, applying the Azuma–Hoeffding inequality to (−Zi),
Pn,pn
h
Fn(Gn) − En,pn
[Fn(Gn)] ≤ −bε
√
n − 1
i
≤
ε
3
,
which, since Pn,pn
[Fn(Gn) = 0] = Pn,pn
[χ(Gn) ≤ ϕn] >
ε
3
, implies that
En,pn
[Fn(Gn)] ≤ bε
√
n − 1.
Applying the Azuma–Hoeffding inequality to (Zi) gives
Pn,pn
h
Fn(Gn) ≥ 2bε
√
n − 1
i
≤ Pn,pn
h
Fn(Gn) − En,pn
[Fn(Gn)] ≥ bε
√
n − 1
i
≤
ε
3
. (3.2.10)
So with probability at least 1 −
ε
3
, we can color all vertices but 2bε
√
n − 1 using ϕn colors.
Let U be the remaining uncolored vertices.
We claim that, with high probability, we can color the vertices in U using at most three
extra colors.
Lemma 3.2.20 Fix c > 0, α > 5
6
, and ε > 0. Let Gn ∼ Gn,pn with pn = n
−α
. For all n large
enough,
Pn,pn

every subset of c√
n vertices of Gn can be 3-colored 
> 1 −
ε
3
. (3.2.11)
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.2 Concentration for Martingales and Applications 127
Proof We use the first moment method (Theorem 2.2.6). We refer to a subset of vertices
that is not 3-colorable but such that all of its subsets are as minimal, non-3-colorable. Let Yn
be the number of such subsets of size at most c
√
n in Gn.
Any minimal, non-3-colorable subset W must have degree at least 3. Indeed, suppose that
w ∈ W has degree less than 3. Then, W\{w} is 3-colorable by definition. But, since w has
fewer than three neighbors, it can also be properly colored without adding a new color – a
contradiction. In particular, the subgraph of Gn induced by W must have at least 3
2
|W| edges.
Hence, the probability that a subset of vertices of Gn of size ` is minimal, non-3-colorable
is at most
￾
`
2

3`
2

p
3`
2
n ,
by a union bound over all subsets of edges of size 3`
2
.
By the first moment method, by the binomial bounds ￾
n
`

≤
￾
en
`
`
(see Appendix A) and
￾
`
2

≤ `
2
/2, for some c
0 ∈ (0, +∞),
Pn,pn
[Yn > 0] ≤ En,pnYn
≤
c
√
Xn
`=4

n
`
￾
`
2

3`
2

p
3`
2
n
≤
c
√
Xn
`=4
en
`
`

e`
3
3`
2
n
−
3`α
2
≤
c
√
Xn
`=4
 
e
5
2 n
1−
3α
2 `
1
2
3
3
2
!`
≤
c
√
Xn
`=4

c
0
n
5
4 −
3α
2
`
≤ O

n
5
4 −
3α
2
4
→ 0,
as n → +∞, where we used that 5
4 −
3α
2 <
5
4 −
5
4 = 0 when α > 5
6
so that the geometric
series is dominated by its first term. Therefore, for n large enough, Pn,pn
[Yn > 0] ≤ ε/3,
concluding the proof.
By the choice of ϕn in (3.2.9),
Pn,pn
[χ(Gn) < ϕn] ≤
ε
3
.
By (3.2.10) and (3.2.11) with c = 2bε,
Pn,pn
[χ(Gn) > ϕn + 3] ≤
2ε
3
.
So, overall,
Pn,pn
[ϕn ≤ χ(Gn) ≤ ϕn + 3] ≥ 1 − ε.
That concludes the proof.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University 128 Martingales and Potentials
3.2.4 F Random Graphs: Degree Sequence of Preferential Attachment Graphs
Let (Gt)t≥1 ∼ PA1 be a preferential attachment graph (Definition 1.2.3). A key feature of
such graphs is a power-law degree sequence: the fraction of vertices with degree d behaves
like ∝ d
−α
for some α > 0, that is, it has a fat tail. Recall that we restrict ourselves to the tree
case. In contrast, we will show in Section 4.1.4 that a (sparse) Erdos–Rényi random graph ˝
has an asymptotically Poisson-distributed degree sequence, and therefore a much thinner
tail.
Power-law degree sequence Let Di(t) be the degree of the ith vertex in Gt
, denoted vi
, and
let
Nd(t) :=
Xt
i=0
1{Di(t)=d}
be the number of vertices of degree d in Gt
. By construction N0(t) = 0 for all t. Define the
sequence
fd :=
4
d(d + 1)(d + 2)
, d ≥ 1. (3.2.12)
Our main claim is:
Claim 3.2.21
1
t
Nd(t) →p fd ∀d ≥ 1.
Proof The claim is immediately implied by the following lemmas.
Lemma 3.2.22 (Convergence of the mean).
1
t
ENd(t) → fd ∀d ≥ 1.
Lemma 3.2.23 (Concentration around the mean). For any δ > 0,
P
"



1
t
Nd(t) −
1
t
ENd(t)




≥
r
2 log δ
−1
t
#
≤ 2δ ∀d ≥ 1, ∀t.
An alternative representation of the process We start with the proof of Lemma 3.2.23,
which is an application of the method of bounded differences.
Proof of Lemma 3.2.23 In our description of the preferential attachment process, the ran￾dom choices made at each time depend in a seemingly complicated way on previous choices.
In order to establish concentration of the process around its mean, we introduce a clever, al￾ternative construction which has the advantage that it involves independent choices.
We start with a single vertex v0. At time 1, we add a single vertex v1 and an edge e1
connecting v0 and v1. For bookkeeping, we orient edges away from the vertex of higher time
index (but we ignore the orientations in the output). For a directed edge (i, j), we refer to i
as its tail and j as its head. For all s ≥ 2, let Xs be an independent, uniformly chosen edge
extremity among the edges in Gs−1, that is, pick a uniform element in
Xs
:= {(1, tail), (1, head), . . . , (s − 1, tail), (s − 1, head)}.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.2 Concentration for Martingales and Applications 129
Figure 3.2 Graph obtained when x2 = (1, head), x3 = (2, tail), and x4 = (3, head).
To form Gs
, attach a new edge es
to the vertex of Gs−1 corresponding to Xs
. A vertex of
degree d
0
in Gs−1 is selected with probability d
0
2(s−1) , as it should. Note that Xs can be picked in
advance independently of the sequence (Gs
0)s
0<s
. For instance, if x2 = (1, head), x3 = (2, tail),
and x4 = (3, head), the graph obtained at time 4 is depicted in Figure 3.2.
We claim that Nd(t) =: h(X2, . . . , Xt) as a function of X2, . . . , Xt satisfies kDihk∞ ≤ 2.
Indeed, let (x2, . . . , xt) be a realization of (X2, . . . , Xt) and let y ∈ Xs with y 6= xs
. Replacing
xs = (i, end) with y = ( j, end0
), where i, j ∈ {1, . . . ,s−1} and end, end0 ∈ {tail, head} has the
effect of redirecting the head of edge es from the end of ei
to the end0
of ej
. This redirection
also brings along with it the heads of all other edges associated with the choice (s, head).
But, crucially, those changes only affect the degrees of the vertices (i, end) and ( j, end0
) in
the original graph. Hence, the number of vertices with degree d changes by at most 2, as
claimed. For instance, returning to the example of Figure 3.2. If we replace x3 = (2, tail)
with y = (1, tail), one obtains the graph in Figure 3.3. Note that only the degrees of vertices
v1 and v2 are affected by this change.
By McDiarmid’s inequality (Theorem 3.2.9), for all β > 0,
P[|Nd(t) − ENd(t)| ≥ β] ≤ 2 exp
−
2β
2
(2)2
(t − 1)
,
which, choosing β =
p
2t log δ
−1
, we can rewrite as
P
"



1
t
Nd(t) −
1
t
ENd(t)




≥
r
2 log δ
−1
t
#
≤ 2δ.
That concludes the proof of the lemma.
Dynamics of the mean Once again the method of bounded differences tells us nothing
about the mean, which must be analyzed by other means. The proof of Lemma 3.2.22 does
not rely on the Azuma–Hoeffding inequality but is given for completeness (and may be
skipped).
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press130 Martingales and Potentials
Figure 3.3 Substituting x3 = (2, tail) with y = (1, tail) in the example of Figure 3.2
has the effect of replacing the dashed edges with the dotted edges. Note that only
the degrees of vertices v1 and v2 are affected by this change.
Proof of Lemma 3.2.22 The idea of the proof is to derive a recursion for fd by considering
the evolution of ENd(t) and taking a limit as t → +∞. Let d ≥ 1. Observe that ENd(t) = 0
for t ≤ d − 1 since we need at least d edges to have a degree-d vertex. Moreover, by the
description of the preferential attachment process, the following recursion holds for t ≥
d − 1:
ENd(t + 1) − ENd(t) =
d − 1
2t
ENd−1(t)
| {z }
(a)
−
d
2t
ENd(t)
| {z }
(b)
+ 1{d=1}
| {z }
(c)
. (3.2.13)
Indeed, (a) Nd(t) increases by 1 if a vertex of degree d − 1 is picked, an event of probability
d−1
2t
Nd−1(t) because the sum of degrees at time t is twice the number of edges (i.e., t); (b)
Nd(t) decreases by 1 if a vertex of degree d is picked, an event of probability d
2t
Nd(t); and (c)
the last term comes from the fact that the new vertex always has degree 1. We rewrite (3.2.13)
as
ENd(t + 1) = ENd(t) +
d − 1
2t
ENd−1(t) −
d
2t
ENd(t) + 1{d=1}
=

1 −
d/2
t

ENd(t) +

d − 1
2

1
t
ENd−1(t)

+ 1{d=1}

=:

1 −
d/2
t

ENd(t) + gd(t), (3.2.14)
where gd(t) is defined as the expression in curly brackets on the second line. We will not
solve this recursion explicitly. Instead, we seek to analyze its asymptotics, specifically we
show that 1
t
ENd(t) → fd.
The key is to notice that the expression for ENd(t+1) depends on 1
t
ENd−1(t) – so we work
by induction on d. Because of the form of the recursion, the following technical lemma is
what we need to proceed.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.2 Concentration for Martingales and Applications 131
Lemma 3.2.24 Let f , g be non-negative functions of t ∈ N satisfying the following recursion
f (t + 1) =

1 −
α
t

f (t) + g(t) ∀t ≥ t0,
with g(t) → g ∈ [0, +∞) as t → +∞, and where α > 0, t0 ≥ 2α, f (t0) ≥ 0 are constants.
Then,
1
t
f (t) →
g
1 + α
,
as t → +∞.
The proof of this lemma is given after the proof of Claim 3.2.21. We first conclude the
proof of Lemma 3.2.22. First let d = 1. In that case, g1(t) = g1 := 1, α := 1/2, and t0 := 1.
By Lemma 3.2.24,
1
t
EN1(t) →
1
1 + 1/2
=
2
3
= f1.
Assuming by induction that 1
t
ENd−1(t) → fd−1 we get
gd(t) → gd :=
d − 1
2
fd−1,
as t → +∞. Using Lemma 3.2.24 with α := d/2 and t0 := d − 1, we obtain
1
t
ENd(t) →
1
1 + d/2

d − 1
2
fd−1

=
d − 1
d + 2
·
4
(d − 1)d(d + 1)
= fd.
That concludes the proof of Lemma 3.2.22.
To prove Claim 3.2.21, we combine Lemmas 3.2.22 and 3.2.23. Fix any d, δ, ε > 0.
Choose t
0
large enough that for all t ≥ t
0
,
max(



1
t
ENd(t) − fd




,
r
2 log δ
−1
t
)
≤ ε.
Then,
P




1
t
Nd(t) − fd




≥ 2ε

≤ 2δ
for all t ≥ t
0
. That proves convergence in probability.
Proof of the technical lemma It remains to prove Lemma 3.2.24.
Proof of Lemma 3.2.24 By induction on t, we have
f (t + 1) =

1 −
α
t

f (t) + g(t)
=

1 −
α
t

1 −
α
t − 1

f (t − 1) + g(t − 1)
+ g(t)
=

1 −
α
t

g(t − 1) + g(t) +

1 −
α
t

1 −
α
t − 1

f (t − 1)
= · · ·
=
Xt−t0
i=0
g(t − i)
Y
i−1
j=0

1 −
α
t − j

+ f (t0)
Yt−t0
j=0

1 −
α
t − j

,
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press132 Martingales and Potentials
or
f (t + 1) =
Xt
s=t0
g(s)
Yt
r=s+1

1 −
α
r

+ f (t0)
Yt
r=t0

1 −
α
r

, (3.2.15)
where empty products are equal to 1. To guess the limit note that, for large s, g(s) is roughly
constant and that the product in the first term behaves like
exp 
−
Xt
r=s+1
α
r
!
≈ exp (−α(log t − log s)) ≈
s
α
t
α
.
So approximating the sum by an integral we get that f (t + 1) ≈
gt
α+1
, which is indeed con￾sistent with the claim.
Formally, we use that there is a constant γ = 0.577 . . . such that (see, for example, [LL10,
Lemma 12.1.3])
Xm
`=1
1
`
= log m + γ + 2(m
−1
),
and that by a Taylor expansion, for |z| ≤ 1/2,
log (1 − z) = −z + 2(z
2
).
Fix η > 0 small and take t large enough that ηt > 2α and |g(s) − g| < η for all s ≥ ηt.
Then, for s + 1 ≥ t0,
Xt
r=s+1
log 
1 −
α
r

= − Xt
r=s+1
nα
r
+ 2(r
−2
)
o
= −α (log t − log s) + 2(s
−1
),
so, taking exponentials,
Yt
r=s+1

1 −
α
r

=
s
α
t
α
(1 + 2(s
−1
)).
Hence,
1
t
f (t0)
Yt
r=t0

1 −
α
r

=
t
α
0
t
α+1
(1 + 2(t
−1
0
)) → 0,
as t → +∞. Moreover,
1
t
Xt
s=ηt
g(s)
Yt
r=s+1

1 −
α
r

≤
1
t
Xt
s=ηt
(g + η)
s
α
t
α
(1 + 2(s
−1
))
≤ O(η) + (1 + 2(t
−1
))
g
t
α+1
Xt
s=ηt
s
α
≤ O(η) + (1 + 2(t
−1
))
g
t
α+1
(t + 1)α+1
α + 1
→ O(η) +
g
α + 1
,
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.2 Concentration for Martingales and Applications 133
where we bounded the sum on the second line by an integral. Similarly,
1
t
Xηt−1
s=t0
g(s)
Yt
r=s+1

1 −
α
r

≤
1
t
Xηt−1
s=t0
(g + η)
s
α
t
α
(1 + 2(s
−1
))
≤
ηt
t
(g + η)
(ηt)
α
t
α
(1 + 2(t
−1
0
))
→ O(η
α+1
).
Plugging these inequalities back into (3.2.15), we get
lim sup
t
1
t
f (t + 1) ≤
g
1 + α
+ O(η).
A similar inequality holds in the other direction. Letting η → 0 concludes the proof.
Remark 3.2.25 A more quantitative result (uniform in t and d) can be derived. See, for
example, [vdH17, sections 8.5, 8.6]. See the same reference for a generalization beyond
trees.
3.2.5 F Data Science: Stochastic Bandits and the Slicing Method
In this section, we consider an application of the maximal Azuma–Hoeffding inequality
(Theorem 3.2.1) to (multi-armed) bandit problems. These are meant as a simple model of
sequential decision-making with limited information where a fundamental issue is trading
off between exploitation of actions that have done well in the past and exploration of actions
that might perform better in the future. A typical application is online advertising, where
one must decide which advertisement to display to the next visitor to a website.
In the simplest version of the (two-arm) stochastic bandit problem, there are two unknown STOCHASTIC
reward distributions ν BANDIT 1, ν2 over [0, 1] with respective means µ1 6= µ2. At each time t =
1, . . . , n, we request an independent sample from νIt
, where we are free to choose It ∈ {1, 2}
based on past choices and observed rewards {(Is
, Zs)}s<t
. This will be referred to as pulling
arm It
. We then observe the reward Zt ∼ νIt
. Letting µ
∗
:= µ1 ∨ µ2, our goal is to minimize ARM
Rn = nµ
∗ − E
"Xn
t=1
µIt
#
, (3.2.16)
which is known as the pseudo-regret. That is, we seek to make choices (It)
n
t=1
that minimize PSEUDO￾the difference between the best achievable cumulative mean reward and the expected cumu- REGRET
lative mean reward from our decisions. Note that the expectation in (3.2.16) is taken over the
choices (It)
n
t=1
, which themselves depend on the random rewards (Zs)
n
t=1
. Because ν1 and ν2
are unknown, there is a fundamental friction between exploiting the arm that has done best
in the past and exploring further the other arm, which might perform better in the future.
One general approach that has proved effective in this type of problem is known as opti￾mism in the face of uncertainty. Roughly speaking, we construct a set of plausible environ￾ments (in our case, the means of the reward distributions) that are consistent with observed
data; then we make an optimal decision assuming that the true environment is the most fa￾vorable among them. A concrete implementation of this principle is the Upper Confidence
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press134 Martingales and Potentials
UCB Bound (UCB) algorithm, which we now describe. In other words, we use a concentration
inequality to build a confidence interval for each reward mean, and then we pick the arm
with highest upper bound.
UCB algorithm
To state the algorithm formally, we will need some notation. For i = 1, 2, let Ti(t) be the
number of times arm i is pulled up to time t
Ti(t) =
X
s≤t
1{Is = i},
and let Xi,s
, s = 1, . . . , n, be i.i.d. samples from νi
. Assume that the reward at time t is
Zt =
(
X1,T1(t−1)+1 if It = 1,
X2,T2(t−1)+1 otherwise.
In other words, Xi,s
is the sth observed reward from arm i. Let µˆi,s be the sample mean of the
observed rewards after pulling s times on arm i
µˆi,s =
1
s
X
r≤s
Xi,r
.
Since the Xi,ss are independent and [0, 1]-valued by assumption, by Hoeffding’s inequality
(Theorem 2.4.10), for any β > 0,
P[µˆi,s − µi ≥ β] ∨ P[µi − ˆµi,s ≥ β] ≤ exp ￾
−2sβ
2

.
The right-hand side can be made ≤ δ provided
β ≥
r
log δ
−1
2s
:= H(s, δ).
We are now ready to state the α-UCB algorithm, where α > 1 is the exploration parame￾ter. At each time t, we pick
It ∈ arg max
i=1,2

µˆi,Ti(t−1) + α H(Ti(t − 1), 1/t)
	
.
The argument above implies that the true mean µi has probability less than 1/t
α
2
of being
higher than µˆi,Ti(t−1) + αH(Ti(t − 1), 1/t). The algorithm makes an “optimistic” decision: it
chooses the higher of the two values.
The following theorem shows that UCB achieves a pseudo-regret of the order of O(log n).
Define 1i = µ
∗ − µi and 1∗ = 11 ∨ 12.
Theorem 3.2.26 (Pseudo-regret of UCB). In the two-arm stochastic bandit problem where
the rewards are in [0, 1] with distinct means, α-UCB with α > 1 achieves
Rn ≤
2α
2
1∗
log n + 1∗Cα,
for some constant Cα ∈ (0, +∞) depending only on α.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Pres3.2 Concentration for Martingales and Applications 135
This bound should not come entirely as a surprise. Indeed, a simple, alternative approach
to UCB is to (1) first pull each arm mn = o(n) times and then (2) use the arm with largest
estimated mean for the remainder. Assuming there is a known lower bound on 1∗, then
Hoeffding’s inequality (Theorem 2.4.10) guarantees that mn can be chosen of the order of
1
12
∗
log n to identify the largest mean with probability 1 − 1/n. Because the rewards are
bounded by 1, accounting for the contribution of the first phase and the probability of failure
in the second phase, one gets a pseudo-regret of the order of 1∗ 1
12
∗
log n +
1
n1∗n ≈
1
1∗
log n.
The UCB strategy, on the other hand, elegantly adapts to the gap 1∗ and the horizon n.
Analysis of the UCB algorithm
We break down the proof into a sequence of lemmas. We first rewrite the pseudo-regret as
Rn = nµ
∗ − E
"Xn
t=1
µIt
#
= E
"Xn
t=1
(µ
∗ − µIt
)
#
= E
"Xn
t=1
X
i=1,2
1{It = i}1i
#
=
X
i=1,2
1iE[Ti(n)]. (3.2.17)
Hence, the problem boils down to bounding E[Ti(n)], the expected number of times that arm
i is pulled. Note that Ti(n) is a complicated function of the observations. To analyze it, we
will use the following sufficient condition. Let i
∗ be the optimal arm, that is, the one that
achieves µ
∗
. Intuitively, if arm i 6= i
∗
is pulled, it is because either our upper estimate of
µi
∗ happens to be low or our lower estimate of µi happens to be high (i.e., our concentration
inequality failed); or there is too much uncertainty in our estimate of µi (i.e., we haven’t
pulled arm i enough).
Lemma 3.2.27 Under the α-UCB strategy, if arm i 6= i
∗
is pulled at time t, then at least one
of the following events hold:
Et,1 = { ˆµi
∗
,Ti
∗ (t−1) + α H(Ti
∗ (t − 1), 1/t) ≤ µ
∗
}, (3.2.18)
Et,2 = { ˆµi,Ti(t−1) − α H(Ti(t − 1), 1/t) > µi}, (3.2.19)
Et,3 =

α H(Ti(t − 1), 1/t) >
1i
2

. (3.2.20)
Proof We argue by contradiction. Assume all the conditions above are false. Then,
µˆi
∗
,Ti
∗ (t−1) + α H(Ti
∗ (t − 1), 1/t) > µ∗
= µi + 1i
≥ ˆµi,Ti(t−1) + α H(Ti(t − 1), 1/t).
That implies that arm i would not be chosen.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press136 Martingales and Potentials
We first deal with Et,3. Let
un =
2α
2
log n
12
∗
.
Using the condition in Lemma 3.2.27, we get the following bound on E[Ti(n)].
Lemma 3.2.28 Under the α-UCB strategy, for i 6= i
∗
,
E[Ti(n)] ≤ un +
Xn
t=1
P[Et,1] +
Xn
t=1
P[Et,2].
Proof For i 6= i
∗
, by definition of Ti(n),
E[Ti(n)] = E
"Xn
t=1
1{It=i}
#
≤ E
"Xn
t=1

1{It=i}∩Et,1 + 1{It=i}∩Et,2 + 1{It=i}∩Et,3 
#
,
where we used that by Lemma 3.2.27,
{It = i} ⊆ Et,1 ∪ Et,2 ∪ Et,3.
The condition in Et,3 can be written equivalently as
α
s
log t
2Ti(t − 1)
>
1i
2
⇐⇒ Ti(t − 1) <
2α
2
log t
12
i
.
In particular, for all t ≤ n, the event Et,3 implies that Ti(t − 1) < un. As a result, since
Ti(t) = Ti(t − 1) + 1 whenever It = i, the event {It = i} ∩ Et,3 can occur at most un times and
E[Ti(n)] ≤ un + E
"Xn
t=1

1{It=i}∩Et,1 + 1{It=i}∩Et,2 
#
≤ un +
Xn
t=1
P[Et,1] +
Xn
t=1
P[Et,2],
which proves the claim.
It remains to bound P[Et,1] and P[Et,2] from above. This is not entirely straightforward
because, while µˆi,Ti(t−1) involves a sum of independent random variables, the number of
terms Ti(t − 1) is itself a random variable. Moreover, Ti(t − 1) depends on the past rewards
Zs
, s ≤ t−1, in a complex way. So in order to apply a concentration inequality to µˆi,Ti(t−1), we
use a rather blunt approach: we bound the worst deviation over all possible (deterministic)
values in the support of Ti(t − 1). That is,
P[Et,2] = P[µˆi,Ti(t−1) − α H(Ti(t − 1), 1/t) > µi]
≤ P
" [
s≤t−1
{ ˆµi,s − α H(s, 1/t) > µi}
#
. (3.2.21)
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.2 Concentration for Martingales and Applications 137
We reformulate the previous bound as
P
" [
s≤t−1
{ ˆµi,s − α H(s, 1/t) > µi}
#
= P

sup
s≤t−1
￾
µˆi,s − µi − α H(s, 1/t)

> 0

= P
"
sup
s≤t−1
 
1
s
X
r≤s
Xi,r − µi − α
r
log t
2s
!
> 0
#
= P
"
sup
s≤t−1
1
√
s
 
1
√
s
X
r≤s
(Xi,r − µi) − α
r
log t
2
!
> 0
#
= P
"
sup
s≤t−1
Ps
r=1
(Xi,r − µi)
√
s
> αr
log t
2
#
. (3.2.22)
Observe that the numerator on the left-hand side of the inequality on the last line is a mar￾tingale (see Example 3.1.29) with increments in [−µi
, 1−µi]. But the denominator depends
on s.
We try two approaches:
• We could simply use √
s ≥ 1 on the denominator and apply the maximal Azuma–
Hoeffding inequality (Theorem 3.2.1) to get
Xn
t=1
P[Et,2] ≤
Xn
t=1
P
"
sup
s≤t−1
Xs
r=1
(Xi,r − µi) > αr
log t
2
#
≤
Xn
t=1
exp
−
2(α
√
(log t)/2)2
t − 1

≤
Xn
t=1
exp
−α
2
log t
t − 1

. (3.2.23)
That is of order 2(n) for any α.
• On the other hand, we could use a union bound over s and apply the maximal Azuma–
Hoeffding inequality to each term to get
Xn
t=1
P[Et,2] ≤
Xn
t=1
X
s≤t−1
P
"Xs
r=1
(Xi,r − µi) > αr
slog t
2
#
≤
Xn
t=1
X
s≤t−1
exp
−
2(α
√
(slog t)/2)2
s

=
Xn
t=1
(t − 1) exp ￾
−α
2
log t

≤
Xn
t=1
1
t
α
2−1
. (3.2.24)
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Pre138 Martingales and Potentials
The series converges for α > √
2. Therefore, in that case, this bound is 2(1), which is
much better than our previous attempt. For 1 < α ≤
√
2 however, we get a bound of order
2(n
α
2
), which is worse than before.
It turns out that doing something “in between” the two approaches above gives a bound
that significantly improves over both of them in the 1 < α ≤
√
2 regime. This is known as
the slicing (or peeling) method.
Slicing method
SLICING The slicing method is useful when bounding a weighted supremum. Its application is some￾METHOD what problem-specific so we will content ourselves with illustrating it in our case. Specifi￾cally, our goal is to control probabilities of the form
P

sup
s≤t−1
Ms
w(s)
≥ β

,
where Ms
:=
Ps
r=1
(Xi,r − µi), w(s) :=
√
s, and β := α
q
log t
2
. The idea is to divide up the
supremum into slices γ
k−1 ≤ s < γ k
, k ≥ 1, where the constant γ > 1 will be optimized
below. That is, fixing Kt = d log t
log γ
e (which roughly solves γ
Kt = t), by a union bound over
the slices
P

sup
1≤s<t
Ms
w(s)
≥ β

≤
X
Kt
k=1
P
"
sup
γ
k−1≤s<γ k
Ms
w(s)
≥ β
#
.
Because w(s) is increasing, on each slice separately we can bound
P
"
sup
γ
k−1≤s<γ k
Ms
w(s)
≥ β
#
≤ P
"
sup
γ
k−1≤s<γ k
Ms
w(γ
k−1
)
≥ β
#
= P
"
sup
γ
k−1≤s<γ k
Ms ≥ βw(γ
k−1
)
#
≤ P
"
sup
s≤γ
k
Ms ≥ βw(γ
k−1
)
#
.
Now we apply the maximal Azuma–Hoeffding inequality (Theorem 3.2.1) to obtain
P
"
sup
s≤γ
k
Ms ≥ βw(γ
k−1
)
#
≤ exp
−
2(βw(γ
k−1
))2
γ
k

≤ exp
−
2β
2
γ

= t
−α
2
/γ
,
where we used that Ms−Ms−1 = Xi,s−µi ∈ [−µi
, 1−µi], an interval of length 1. Combining
the last three displays we get
P

sup
1≤s<t
Ms
w(s)
≥ β

≤

log t
log γ

t
−α
2
/γ
. (3.2.25)
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.2 Concentration for Martingales and Applications 139
Now we see the trade-off: increasing γ makes the slices larger and hence the tail inequality
weaker, but it also makes the number of slices smaller, which helps with the union bound.
Combining (3.2.21), (3.2.22), and (3.2.25), we have proved:
Lemma 3.2.29 For any γ > 1, it holds that
Xn
t=1
P[Et,2] ≤
Xn
t=1

log t
log γ

t
−α
2
/γ
,
and similarly for P[Et,1].
For α > 1, we can choose γ > 1 such that α
2
/γ > 1. In that case, the series on the
right-hand side is summable. This improves over both (3.2.23) and (3.2.24).
We are ready to prove the main result.
Proof of Theorem 3.2.26 By (3.2.17) and Lemmas 3.2.27, 3.2.28, and 3.2.29, we have
Rn =
X
i=1,2
1iE[Ti(n)] ≤ 1∗
 
un + 2
Xn
t=1

log t
log γ

t
−α
2
/γ!
.
Recalling that α > 1, choose γ > 1 such that α
2
/γ > 1. In that case, as noted above, the
series on the right-hand side is summable and there is Cα ∈ (0, +∞) such that
Rn ≤ 1∗(un + Cα).
That proves the claim.
Remark 3.2.30 A slightly better – and provably optimal – multiplicative constant in the
pseudo-regret bound has been obtained by [GC11] using a variant of UCB called KL￾UCB. The matching lower bound is due to [LR85]. See also [BCB12, sections 2.3–2.4].
Further improvements can be obtained by using Bernstein’s rather than Hoeffding’s ine￾quality [AMS09].
3.2.6 Coda: Talagrand’s Inequality
We end this section with a celebrated concentration inequality that applies under weaker
conditions than McDiarmid’s inequality (Theorem 3.2.9) – but is not proved using the mar￾tingale method. It is known as Talagrand’s inequality.
Bounds on kDi
f k∞ are often expressed in terms of a Lipschitz condition under an ap￾propriate metric. Let 0 < ci < +∞, i = 1, . . . , n and c = (c1, . . . , cn). The c-weighted WEIGHTED
HAMMING
DISTANCE
Hamming distance is defined as
ρc(x, y) :=
Xn
i=1
ci1{xi6=yi}
for x = (x1, . . . , xn), y = (y1, . . . , yn) ∈ X1×· · ·×Xn. The proof of the following equivalence
is left as an exercise (see Exercise 3.8).
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press140 Martingales and Potentials
Lemma 3.2.31 (Lipschitz condition). A function f : X1 × · · · × Xn → R satisfies the Lips￾chitz condition
| f (x) − f (y)| ≤ ρc(x, y) ∀x, y ∈ X1 × · · · × Xn (3.2.26)
if and only if
kDi
f k∞ ≤ ci ∀i.
Consider the following relaxed version of (3.2.26):
f (x) − f (y) ≤
Xn
i=1
ci(x)1{xi6=yi} ∀x, y ∈ X1 × · · · × Xn, (3.2.27)
where now ci(x) is a finite, positive function over X1 × · · · × Xn. Notice the “one-sided”
nature of this condition, in the sense that ci depends on x but not on y. A typical example
where (3.2.27) is satisfied, but (3.2.26) is not, is given in Example 3.2.33.
We state Talagrand’s inequality without proof.
TALAGRAND’S Theorem 3.2.32 (Talagrand’s inequality). Let X1, . . . , Xn be independent random variables
INEQUALITY where Xi
is Xi-valued for all i, and let X = (X1, . . . , Xn). Assume f : X1 × · · · × Xn → R
is a measurable function such that (3.2.27) holds. Then f (X) is sub-Gaussian with variance
factor k
P
i≤n
c
2
i
k∞. In fact, for all β > 0 the following upper and lower tail bounds hold
P[ f (X) − Ef (X) ≥ β] ≤ exp 
−
β
2
2k
P
i≤n
c
2
i
k∞
!
and
P[ f (X) − Ef (X) ≤ −β] ≤ exp 
−
β
2
2 E
P
i≤n
ci(X)
2

!
.
Compared to McDiarmid’s inequality (Theorem 3.2.9), the upper tail in Theorem 3.2.32 has
the sum over the coordinates inside the supremum, potentially a major improvement; the
lower tail is even better, replacing the supremum with an expectation.
Example 3.2.33 (Spectral norm of a random matrix with bounded entries). Let A be an n×n
random matrix. We assume that the entries Ai,j
, i, j = 1, . . . , n are independent, centered ran￾dom variables in [−1, 1]. In Theorem 2.4.28, we proved an upper tail bound on the spectral
norm
kAk2 = sup
x∈Rn\{0}
kAxk2
kxk2
= sup
x∈S
n−1
y∈S
n−1
hAx, yi
of such a matrix (in the more general sub-Gaussian case) using an ε-net argument. Theo￾rem 2.4.28 also implies that EkAk2 = O(
√
n) by (B.5.1). (See Exercise 3.9 for a lower bound
on the expectation.)
Here we use Talagrand’s inequality (Theorem 3.2.32) directly to show concentration ar￾ound the mean. For this, we need to check (3.2.27) where we think of the spectral norm as a
function of n
2
independent random variables
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.3 Potential Theory and Electrical Networks 141
kAk2 = f ({Ai,j}i,j).
Let x
∗
(A) and y
∗
(A) be unit vectors in R
n
such that
kAk2 = hAx
∗
(A), y
∗
(A)i,
which exist by compactness.
Given two n × n matrices A,eA with entries in [−1, 1], we have
kAk2 − keAk2 = hAx
∗
(A), y
∗
(A)i − sup
x∈S
n−1
y∈S
n−1
heAx, yi
≤ hAx
∗
(A), y
∗
(A)i − heAx
∗
(A), y
∗
(A)i
= h(A − eA)x
∗
(A), y
∗
(A)i
≤
X
i,j
|Aij − eAij||x
∗
(A)i
||y
∗
(A)j
|
≤
X
i,j
1Aij6=eAij
cij(A),
where on the last line we set
cij(A) := 2|x
∗
(A)i
||y
∗
(A)j
|,
and used the fact that |Aij − eAij| ≤ 2. Note that
X
i,j
cij(A)
2 = 4
X
i
x
∗
(A)
2
i
X
j
y
∗
(A)
2
j = 4.
Hence, Talagrand’s inequality implies that kAk2 is sub-Gaussian with variance factor 4. J
3.3 Potential Theory and Electrical Networks
In this section, we develop a classical link between random walks and electrical networks.
The electrical interpretation is a useful physical analogy. The mathematical substance of the
connection starts with the following observation.
Let (Xt) be a Markov chain with transition matrix P on a finite or countable state space V.
Recall from Definition 3.1.6 that τB is the first visit time to B ⊆ V. For two disjoint subsets
A, Z of V, the probability of hitting A before Z
h(x) = Px[τA < τZ], (3.3.1)
seen as a function of the starting point x ∈ V, is harmonic (with respect to P) on W := HARMONIC
(A ∪ Z)
c
:= V \ (A ∪ Z) in the sense that FUNCTION
h(x) =
X
y
P(x, y)h( y) ∀x ∈ W. (3.3.2)
Indeed, note that h = 1 (respectively = 0) on A (respectively Z) and by the Markov property
(Theorem 1.1.18), after the first step of the chain, for x ∈ W,
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press142 Martingales and Potentials
Px[τA < τZ] =
X
y∈/A∪Z
P(x, y) Py[τA < τZ]
+
X
y∈A
P(x, y) · 1 +
X
y∈Z
P(x, y) · 0
=
X
y
P(x, y) Py[τA < τZ]. (3.3.3)
Quantities such as (3.3.1) arise naturally, for instance in the study of recurrence, and the
connection to potential theory, the study of harmonic functions, proves fruitful in that context
as we outline in this section. It turns out that harmonic functions and martingales are closely
related. In Section 3.3.1, we elaborate on that connection.
But first we rewrite (3.3.2) to reveal the electrical interpretation. For this we switch to
reversible chains. Recall that a reversible Markov chain is equivalent to a random walk on a
network N = (G, c), where the edges of G correspond to transitions of positive probability.
If the chain is reversible with respect to a stationary measure π, then the edge weights are
c(x, y) = π(x)P(x, y). In this notation (3.3.2) becomes
h(x) =
1
c(x)
X
y∼x
c(x, y)h( y) ∀x ∈ (A ∪ Z)
c
, (3.3.4)
where c(x) :=
P
y∼x
c(x, y) = π(x). In words, h(x) is the weighted average of its neighbor￾ing values. Now comes the electrical analogy: if one interprets c(x, y) as a conductance, a
function satisfying (3.3.4) is known as a voltage. The voltages at A and Z are 1 and 0, re￾spectively. We show in the next subsection by a martingale argument that, under appropriate
conditions, such a voltage exists and is unique. We develop the electrical analogy and many
of its applications in Section 3.3.2.
3.3.1 Martingales, the Dirichlet Problem and Lyapounov Functions
To see why martingales come in, let Ft = σ(X0, . . . , Xt) and let τ
∗
:= τWc . By a first-step
calculation again, (3.3.2) implies
h(Xt∧τ
∗ ) = E

h(X(t+1)∧τ
∗ ) | Ft

∀t ≥ 0, (3.3.5)
that is, (h(Xt∧τ
∗ ))t
is a martingale with respect to (Ft). Indeed, on {τ
∗ ≤ t},
E[h(X(t+1)∧τ
∗ ) | Ft] = h(Xτ
∗ ) = h(Xt∧τ
∗ ),
and on {τ
∗ > t},
E[h(X(t+1)∧τ
∗ ) | Ft] =
X
y
P(Xt
, y)h( y) = h(Xt) = h(Xt∧τ
∗ ).
Although the rest of Section 3.3 is concerned with reversible Markov chains, the cur￾rent subsection applies to the non-reversible case as well. We give an overview of potential
theory for general, countable-space, discrete-time Markov chains and its connections to mar￾tingales. As a major application, we introduce the concept of a Lyapounov function which is
useful in bounding certain hitting times.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.3 Potential Theory and Electrical Networks 143
Existence and uniqueness of a harmonic extension
We begin with a special case, which will be generalized in Theorem 3.3.9.
Theorem 3.3.1 (Harmonic extension: existence and uniqueness). Let P be an irreducible
transition matrix on a finite or countably infinite spate space V. Let W be a finite, proper
subset of V and let h: Wc → R be a bounded function on Wc
. Then there exists a unique
extension of h to W that is harmonic on W, that is, which satisfies (3.3.2). The solution is
given by
h(x) = Ex[h
￾
XτWc

].
Proof We first argue about uniqueness. Suppose h is defined over all of V and satis￾fies (3.3.2). Let τ
∗
:= τWc . Then the process (h (Xt∧τ
∗ ))t
is a martingale by (3.3.5). Because
W is finite and the chain is irreducible, we have τ
∗ < +∞ almost surely, as implied by
Lemma 3.1.25. Moreover, the process is bounded because h is bounded on Wc
and W is
finite. Hence, by Doob’s optional stopping theorem (Theorem 3.1.38 (ii)),
h(x) = Ex[h(Xτ
∗ )] ∀x ∈ W,
which implies that h is unique, since the right-hand side depends only on the chain and the
fixed values of h on Wc
.
For the existence, simply define h(x) := Ex[h (Xτ
∗ )]∀x ∈ W, and use a first-step argument
similarly to (3.3.3).
For some insights on what happens when the assumptions of Theorem 3.3.1 are not sat￾isfied, see Exercise 3.11. For an alternative (arguably more intuitive) proof of uniqueness
based on the maximum principle, see Exercise 3.12.
In the proof above it suffices to specify h on the outer boundary of W:
∂VW = {z ∈ V\W : ∃y ∈ W, P( y,z) > 0}.
Introduce the Laplacian associated to P: LAPLACIAN
1f (x) =
"X
y
P(x, y)f ( y)
#
− f (x)
=
X
y
P(x, y)[ f ( y) − f (x)]
= Ex[ f (X1) − f (X0)], (3.3.6)
provided the expectation exists. We have proved that, under the assumptions of Theorem 3.3.1,
there exists a unique solution to
(
1f (x) = 0 ∀x ∈ W,
f (x) = h(x) ∀x ∈ ∂VW,
(3.3.7)
and that solution is given by f (x) = Ex[h
￾
XτWc

] for x ∈ W ∪ ∂VW. The system (3.3.7), in
reference to its counterpart in the theory of partial differential equations, is referred to as a DIRICHLET
Dirichlet problem. PROBLEM
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Pre144 Martingales and Potentials
Example 3.3.2 (Simple random walk on Z
d
). The Laplacian above can be interpreted as a
discretized version of the standard Laplacian. For instance, for simple random walk on Z,
1f (x) =
"X
y
P(x, y)f ( y)
#
− f (x)
=
X
y
P(x, y)[ f ( y) − f (x)]
=
1
2
{[ f (x + 1) − f (x)] − [ f (x) − f (x − 1)]},
which is a discretized second derivative. More generally, for simple random walk on Z
d
, we
get
1f (x) =
"X
y
P(x, y)f ( y)
#
− f (x)
=
X
y
P(x, y)[ f ( y) − f (x)]
=
1
2d
X
d
i=1
{[ f (x + ei) − f (x)] − [ f (x) − f (x − ei)]},
where e1, . . . , ed is the standard basis in R
d
. J
Theorem 3.3.1 has many applications. One of its consequences is that harmonic functions
on a finite state space are constant.
Corollary 3.3.3 Let P be an irreducible transition matrix on a finite state space V. If h is
harmonic on all of V, then it is constant.
Proof Fix the value of h at an arbitrary vertex z and set W = V\{z}. Applying Theo￾rem 3.3.1, for all x ∈ W, h(x) = Ex[h
￾
XτWc

] = h(z).
As an example of application of this corollary, we prove the following surprising result:
in a finite, irreducible Markov chain, the expected time to hit a target chosen at random
according to the stationary distribution does not depend on the starting point.
Theorem 3.3.4 (Random target lemma). Let (Xt) be an irreducible Markov chain on a finite
state space V with transition matrix P and stationary distribution π. Then,
h(x) :=
X
y∈V
π( y) Ex[τy]
does not in fact depend on x.
Proof Because the chain is irreducible and has a finite state space, Ex[τy] < +∞ for all
x, y. By Corollary 3.3.3, it suffices to show that h(x) :=
P
y π( y) Ex[τy] is harmonic on all
of V. As before, it is natural to expand Ex[τy] according to the first step of the chain,
Ex[τy] = 1{x6=y}
 
1 +
X
z
P(x,z) Ez[τy]
!
.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Pres3.3 Potential Theory and Electrical Networks 145
Substituting into the definition of h(x) gives
h(x) = (1 − π(x)) +
X
z
X
y6=x
π( y)P(x,z) Ez[τy]
= (1 − π(x)) +
X
z
P(x,z)(h(z) − π(x) Ez[τx]).
Rearranging, we get
1h(x) =
"X
z
P(x,z)h(z)
#
− h(x)
= π(x)
 
1 +
X
z
P(x,z)Ez[τx]
!
− 1
= 0,
where we used 1/π(x) = Ex[τ
+
x
] = 1 +
P
z P(x,z) Ez[τx] by Theorem 3.1.19 and a first-step
argument (recall that the first return time τ
+
x was defined in Definition 3.1.6).
Potential theory for Markov chains
More generally, many quantities of interest can be expressed in the following form. Consider
again a subset W ⊂ V and the stopping time
τWc = inf{t ≥ 0: Xt ∈ Wc
}.
Let also h: Wc → R+ and k : W → R+. Define the quantity
u(x) := Ex
"
h(XτWc )1{τWc < +∞} + X
0≤t<τWc
k(Xt)
#
. (3.3.8)
The first term on the right-hand side is a final cost incurred when we exit W (and it depends
on where we do), while the second term is a unit time cost incurred along the sample path.
Note that, in fact, it suffices to define h on ∂VW, the outer boundary of W if we restrict our￾selves to x ∈ W. Observe also that the function u(x) may take the value +∞; the expectation
is well defined (in R+ ∪ {+∞}) by the non-negativity of the terms (see Appendix B).
Example 3.3.5 (Some special cases). Here are some important special cases:
• Revisiting (3.3.1), for two disjoint subsets A, Z of V, the probability
u(x) := Px[τA < τZ]
of hitting A before Z as a function of the starting point x ∈ V is obtained by taking
W := (A ∪ Z)
c
, h = 1 (respectively = 0) on A (respectively Z), and k = 0 on V. The
further special case Z = ∅ leads to the exit probability from A: EXIT
PROBABILITY
u(x) := Px[τA < +∞].
On the other hand, if A and Z form a disjoint partition of Wc
(or ∂VW will suffice if
x ∈ W), we get the exit law from W: EXIT LAW
u(x) := Px[XτWc ∈ A; τWc < +∞].
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press146 Martingales and Potentials
AVERAGE • The average occupation time of A ⊆ W before exiting W,
OCCUPATION
TIME
u(x) := Ex
" X
0≤t<τWc
1{Xt∈A}
#
,
is obtained by taking h = 0 on V, and k = 1 (respectively = 0) on A (respectively on A
c
).
Revisiting (3.1.3), the Green function of the chain stopped at τWc , that is,
u(x) := GτWc (x, y) = Ex
" X
0≤t<τWc
1{Xt=y}
#
,
MEAN EXIT is obtained by taking A = { y}. Another special case is A = W, where we get the mean
TIME exit time from A
u(x) := Ex [τAc ] . J
The function u in (3.3.8) turns out to satisfy a generalized version of (3.3.7). The proof is
FIRST-STEP usually called first-step analysis (of which we have already seen many instances).
ANALYSIS
Theorem 3.3.6 (First-step analysis). Let P be a transition matrix on a finite or countable
spate space V. Let W be a proper subset of V, and let h: Wc → R+ and k : W → R+ be
bounded functions. Then the function u ≥ 0, as defined in (3.3.8), satisfies the system of
equations
(
u(x) = k(x) +
P
y P(x, y)u( y) for x ∈ W,
u(x) = h(x) for x ∈ Wc
.
(3.3.9)
Proof For x ∈ Wc
, by definition u(x) = h(x) since τWc = 0. Fix x ∈ W. By taking out what
is known (Lemma B.6.13), the tower property (Lemma B.6.16) and the Markov property
(Theorem 1.1.18),
u(x) = k(x) + Ex
"
h(XτWc )1{τWc < +∞} + X
1≤t<τWc
k(Xt)
#
= k(x) + Ex
"
E
"
h(XτWc )1{τWc < +∞} + X
1≤t<τWc
k(Xt)





F1
##
= k(x) + Ex [u(X1)] ,
which gives the claim.
POISSON If u is finite, the system (3.3.9) can be rewritten as the Poisson equation (once again as an
EQUATION analogue of its counterpart in the theory of partial differential equations)
(
1u = −k on W,
u = h on Wc
.
(3.3.10)
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.3 Potential Theory and Electrical Networks 147
This is well defined for instance if W is a finite subset and P is irreducible. Indeed, as we
argued in the proof of Theorem 3.3.1, the stopping time τWc then has a finite expectation.
Because h is bounded, it follows that
u(x) := Ex
"
h(XτWc )1{τWc < +∞} + X
0≤t<τWc
k(Xt)
#
≤ sup
x∈Wc
h(x) + sup
x∈W
k(x) sup
x∈W
Ex [τWc ]
< +∞,
uniformly in x. Using (3.3.6) and rearranging (3.3.9) gives (3.3.10).
Remark 3.3.7 A more general form of the statement which can be used to study certain
moment-generating functions can be found, for example, in [Ebe, Theorem 1.3].
In a generalization of Theorem 3.3.1, our next theorem allows one to establish uniqueness
of the solution of the system (3.3.10) under some conditions (which we will not detail here,
but see Exercise 3.13). Perhaps even more useful, it also gives an effective approach to bound
the function u from above. This is based on the following supermartingale.
Lemma 3.3.8 (Locally superharmonic functions). Let P be a transition matrix on a finite
or countable spate space V. Let W be a proper subset of V, and let h: Wc → R+ and
k : W → R+ be bounded functions. Suppose the non-negative function ψ : V → R+ satisfies
1ψ ≤ −k on W.
Then the process
Nt
:= ψ(Xt∧τWc ) +
X
0≤s<t∧τWc
k(Xs)
is a non-negative supermartingale for any initial point x ∈ V.
Proof Observe that on {τWc ≤ t}, we have Nt+1 = Nt
; while on {τWc > t} we have Nt+1 −
Nt = ψ(Xt+1) − ψ(Xt) + k(Xt) by cancellations in the sum. So, since {τWc > t} ∈ Ft by
definition of a stopping time, it holds by taking out what is known that
E[Nt+1 − Nt
| Ft] = E[1{τWc > t}(ψ(Xt+1) − ψ(Xt) + k(Xt)) | Ft]
= 1{τWc > t}(E[ψ(Xt+1) − ψ(Xt) | Ft] + k(Xt))
= 1{τWc > t}(1ψ(Xt) + k(Xt))
≤ 1{τWc > t}(−k(Xt) + k(Xt))
= 0,
where we used that, by (3.3.6) and the Markov property,
E[ψ(Xt+1) − ψ(Xt) | Ft] = 1ψ(Xt), (3.3.11)
and that Xt ∈ W on {τWc > t}.
Theorem 3.3.9 (Poisson equation: bounding the solution). Let P be a transition matrix on
a finite or countable spate space V. Let W be a proper subset of V, and let h: Wc → R+
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press148 Martingales and Potentials
and k : W → R+ be bounded functions. Suppose the non-negative function ψ : V → R+
satisfies the system of inequalities
(
1ψ ≤ −k on W,
ψ ≥ h on Wc
.
(3.3.12)
Then,
ψ ≥ u, on V, (3.3.13)
where u is the function defined in (3.3.8).
Proof The system (3.3.13) holds on Wc by Theorem 3.3.6 and (3.3.12) since in that case
u(x) = h(x) ≤ ψ(x).
Fix x ∈ W. Consider the non-negative supermartingale (Nt) in Lemma 3.3.8. By the con￾vergence of non-negative supermartingales (Corollary 3.1.48), (Nt) converges almost surely
to a finite limit with expectation ≤ Ex[N0]. In particular, the limit NτWc is well defined, non￾negative, and finite, including on the event that {τWc = +∞}. As a result,
NτWc = ψ(XτWc )1{τWc < +∞} + X
0≤s<τWc
k(Xs)
≥ h(XτWc )1{τWc < +∞} + X
0≤s<τWc
k(Xs),
where we used (3.3.12).
Hence, by definition of u,
u(x) = Ex
"
h(XτWc )1{τWc < +∞} + X
0≤t<τWc
k(Xt)
#
≤ Ex

NτWc

≤ Ex[N0]
= ψ(x),
where, on the last line, we used that the initial state is x ∈ W. That proves the claim.
Lyapounov functions
Here is an important application, bounding from above the hitting time τA to a set A in
expectation.
Theorem 3.3.10 (Controlling hitting times via Lyapounov functions). Let P be a transition
matrix on a finite or countably infinite state space V. Let A be a proper subset of V. Suppose
the non-negative function ψ : V → R+ satisfies the system of inequalities
1ψ ≤ −1 on Ac
. (3.3.14)
Then,
Ex [τA] ≤ ψ(x)
for all x ∈ V.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.3 Potential Theory and Electrical Networks 149
Proof Indeed, by (3.3.14) and non-negativity (in particular on A), the function ψ satisfies
the assumptions of Theorem 3.3.9 with W = A
c
, h = 0 on A, and k = 1 on A
c
. Hence, by
definition of u and the claim in Theorem 3.3.9,
Ex [τA] = Ex
"
h(XτA
)1{τA < +∞} + X
0≤t<τA
k(Xt)
#
= u(x)
≤ ψ(x).
That establishes the claim.
Recalling (3.3.11), condition (3.3.14) is equivalent to the following conditional expected
decrease in ψ outside A:
E[ψ(Xt+1) − ψ(Xt) | Ft] ≤ −1 on {Xt ∈ A
c
}. (3.3.15)
A non-negative function satisfying an inequality of this type, also known as drift condition,
is often referred to as a Lyapounov function. Intuitively, it tends to decrease along the sample LYAPOUNOV
path outside of A. Because it is non-negative, it cannot decrease forever and therefore the FUNCTION
chain eventually enters A. We consider a simple example next.
Example 3.3.11 (A Markov chain on the non-negative integers). Let (Zt)t≥1 be i.i.d. inte￾grable random variables taking values in Z such that E[Z1] < 0. Let (Xt)t≥0 be the chain
defined by X0 = x for some x ∈ Z+ and
Xt+1 = (Xt + Zt+1)
+
,
where recall that z
+ = max{0,z}. In particular, Xt ∈ Z+ for all t. Let (Ft) be the correspond￾ing filtration. When Xt
is large, the “local drift” is close to E[Z1] < 0. By analogy to the
biased case of the gambler’s ruin (Example 3.1.43), we might expect that, from a large start￾ing point x, it will take time roughly x/|E[Z1]| in expectation to “return to a neighborhood
of 0.” We prove something along those lines here using a Lyapounov function.
Observe that, for any y ∈ Z+, we have on the event {Xt = y} by the Markov property:
Ex[Xt+1 − Xt
| Ft] = E[(y + Zt+1)
+ − y]
= E[−y1{Zt+1 ≤ −y} + Zt+11{Zt+1 > −y}]
≤ E[Zt+11{Zt+1 > −y}]
= E[Z11{Z1 > −y}]. (3.3.16)
For all y, the random variable |Z11{Z1 > −y}| is bounded by |Z1|, itself an integrable random
variable. Moreover, Z11{Z1 > −y} → Z1 as y → +∞ almost surely. Hence, the dominated
convergence theorem (Proposition B.4.14) implies that
lim
y→+∞
E[Z11{Z1 > −y}] = E[Z1] < 0.
So for any 0 < ε < −E[Z1], there is yε ∈ Z+ large enough that E[Z11{Z1 > −y}] < −ε for
all y > yε. Fix ε satisfying the previous constraint and define
A := {0, 1, . . . , yε}.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press150 Martingales and Potentials
We use Theorem 3.3.10 to bound τA in expectation. Define the Lyapounov function
ψ(x) =
x
ε
∀x ∈ Z+.
On the event {Xt = y}, we rewrite (3.3.16) as
E[ψ(Xt+1) − ψ(Xt) | Ft] ≤
E[Z11{Z1 > −y}]
ε
≤ −1
for y ∈ A
c
. This is the same as (3.3.15). Hence, we can apply Theorem 3.3.10 to get
Ex [τA] ≤ ψ(x) =
x
ε
for all x ≥ yε. J
A well-known, closely related result gives a criterion for positive recurrence. We state it
without proof.
Theorem 3.3.12 (Foster’s theorem). Let P be an irreducible transition matrix on a countable
state space V. Let A be a finite, proper subset of V. Suppose the non-negative function
ψ : V → R+ satisfies the system of inequalities
1ψ ≤ −1 on Ac
,
as well as the condition
X
y∈V
P(x, y)ψ( y) < +∞ ∀x ∈ A.
Then, P is positive recurrent.
3.3.2 Basic Electrical Network Theory
We now develop the basic theory of electrical networks for the analysis of random walks. All
results in this subsection (and the next one) concern reversible Markov chains, or random
walks on networks (see Definition 1.2.7). We begin with a few definitions. Throughout, we
will use the notation h|B for the function h restricted to the subset B. We also write h ≡ c if
h is identically equal to the constant c.
Definitions
Let N = (G, c) be a finite or countable network with G = (V, E). Throughout this section
we assume that N is connected and locally finite. In the context of electrical networks, edge
CONDUCTANCE weights are called conductances. The reciprocal of the conductances are called resistances
RESISTANCE and are denoted by r(e) := 1/c(e) for all e ∈ E. For an edge e = {x, y} we overload
c(x, y) := c(e) and r(x, y) := r(e). Both c and r are symmetric as functions of x, y. Recall that
the transition matrix of the random walk on N satisfies
P(x, y) =
c(x, y)
c(x)
,
where
c(x) =
X
z:z∼x
c(x,z).
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.3 Potential Theory and Electrical Networks 151
Let A, Z be disjoint, non-empty subsets of V such that W := (A ∪ Z)
c
is finite. For our
purposes it will suffice to take A to be a singleton, that is, A = {a} for some a. Then a is
called the source and Z is called the sink-set, or sink for short. As an immediate corollary SOURCE,
of Theorem 3.3.1, we obtain the existence and uniqueness of a voltage function, defined SINK
formally in the next corollary. It will be useful to consider voltages taking an arbitrary value
at a, but we always set the voltage on Z to 0.
Corollary 3.3.13 (Voltage) Fix v0 > 0. Let N = (G, c) be a finite or countable, connected
network with G = (V, E). Let A := {a}, Z be disjoint non-empty subsets of V such that
W = (A ∪ Z)
c
is non-empty and finite. Then there exists a unique voltage defined as follows: VOLTAGE
a function v on V such that v is harmonic on W, that is,
v(x) =
1
c(x)
X
y:y∼x
c(x, y)v( y) ∀x ∈ W, (3.3.17)
where
v(a) = v0 and v|Z ≡ 0. (3.3.18)
Moreover,
v(x)
v0
= Px[τa < τZ] (3.3.19)
for the corresponding random walk on N .
Proof Set h(x) = v(x) on A ∪ Z. Theorem 3.3.1 gives the result.
Note in the definition above that if v is a voltage with value v0 at a, then v˜(x) = v(x)/v0 is a
voltage with value 1 at a.
Let v be a voltage function on N with source a and sink Z. The Laplacian-based formula￾tion of harmonicity, (3.3.7), can be interpreted in terms of flows (see Definition 1.1.13). We
define the current function CURRENT
i(x, y) := c(x, y)[v(x) − v( y)], (3.3.20)
or, equivalently, v(x) − v( y) = r(x, y) i(x, y). The latter definition is usually referred to as
Ohm’s “law.” Notice that the current function is defined on ordered pairs of vertices and is OHM’S LAW
anti-symmetric, that is, i(x, y) = −i( y, x). In terms of the current function, the harmonicity
of v is then expressed as
X
y:y∼x
i(x, y) = 0 ∀x ∈ W, (3.3.21)
that is, i is a flow on W (without capacity constraints). This set of equations is known as
Kirchhoff’s node law. We also refer to these constraints as flow-conservation constraints. KIRCHHOFF’S
To be clear, the current function is not just any flow. It is a flow that can be written as a NODE LAW
potential difference according to Ohm’s law. Such a current also satisfies Kirchhoff’s cycle KIRCHHOFF’S
law: if x1 ∼ x2 ∼ · · · ∼ xk ∼ xk+1 = x1 is a cycle, then CYCLE LAW
X
k
j=1
i(xj
, xj+1)r(xj
, xj+1) = 0,
as can be seen by substituting Ohm’s law.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press152 Martingales and Potentials
STRENGTH The strength of the current is defined as
kik :=
X
y:y∼a
i(a, y).
Because a ∈/ W, it does not satisfy Kirchhoff ’s node law and the strength is not 0 in general.
The definition of i(x, y) ensures that the flow out of the source is non-negative as Py[τa <
τZ] ≤ 1 = Pa[τa < τZ] for all y ∼ a so that
i(a, y) = c(a, y)[v(a) − v( y)] = c(a, y)

v0Pa[τa < τZ] − v0Py[τa < τZ]

≥ 0.
Note that by multiplying the voltage by a constant we obtain a current which is similarly
scaled. Up to that scaling, the current function is unique from the uniqueness of the voltage.
UNIT We will often consider the unit current where we scale v and i so as to enforce that kik = 1.
CURRENT Summing up the previous paragraphs, to determine the voltage it suffices to find functions
v and i that simultaneously satisfy Ohm’s law and Kirchhoff ’s node law. Here is an example.
Example 3.3.14 (Network reduction: birth-death chain). Let N be the line on {0, 1, . . . , n}
with j ∼ k ⇐⇒ | j − k| = 1 and arbitrary (positive) conductances on the edges. Let
(Xt) be the corresponding walk. We use the principle above to compute Px[τ0 < τn] for
1 ≤ x ≤ n − 1. Consider the voltage function v when v(0) = 1 and v(n) = 0 with current i,
which exists and is unique by Corollary 3.3.13. The desired quantity is v(x).
Note that because i is a flow on N , the flow into every vertex equals the flow out of
that vertex, and we must have i( y, y + 1) = i(0, 1) = kik for all y. To compute v(x), we
note that it remains the same if we replace the path 0 ∼ 1 ∼ · · · ∼ x with a single edge
of resistance R0,x = r(0, 1) + · · · + r(x − 1, x). Indeed, leave the voltage unchanged on the
remaining nodes (to the right of x) and define the current on the new edge as kik. Kirchhoff ’s
node law is automatically satisfied by the argument above. To check Ohm’s law on the new
“super-edge,” note that on the original network N (with the original voltage function)
v(0) − v(x) = (v(0) − v(1)) + · · · + (v(x − 1) − v(x))
= r(x − 1, x)i(x − 1, x) + · · · + r(0, 1)i(0, 1)
= [r(0, 1) + · · · + r(x − 1, x)]kik
= R0,xkik.
Ohm’s law is also satisfied on every other edge (to the right of x) because nothing has
changed there. That proves the claim.
We do the same reduction on the other side of x by replacing x ∼ x + 1 ∼ · · · ∼ n with a
single edge of resistance Rx,n = r(x, x + 1) + · · · + r(n − 1, n). See Figure 3.4.
Because the voltage at x was not changed by this transformation, we can compute v(x) =
Px[τ0 < τn] directly on the reduced network, where it is now a straightforward computa￾tion. Indeed, starting at x, the reduced walk jumps to 0 with probability proportional to the
conductance on the new super-edge 0 ∼ x (or the reciprocal of the resistance), that is,
Px[τ0 < τn] =
R
−1
0,x
R
−1
0,x + R−1
x,n
=
Rx,n
Rx,n + R0,x
=
r(x, x + 1) + · · · + r(n − 1, n)
r(0, 1) + · · · + r(n − 1, n)
.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.3 Potential Theory and Electrical Networks 153
Figure 3.4 Reduced network.
Some special cases:
• Simple random walk. In the case of simple random walk, all resistances are equal and we
get
Px[τ0 < τn] =
n − x
n
.
• Gambler’s ruin. The gambler’s ruin example corresponds to taking c( j, j + 1) = (p/q)
j or
r( j, j + 1) = (q/p)
j
for some 0 < p < 1. In this case we obtain
Px[τ0 < τn] =
Pn−1
j=x
(q/p)
j
Pn−1
j=0
(q/p)
j
=
(q/p)
x
(1 − (q/p)
n−x
)
1 − (q/p)
n
=
(p/q)
n−x − 1
(p/q)
n − 1
,
when p 6= q (otherwise we get back the simple random walk case). J
The Example 3.3.14 illustrates the series law: resistances in series add up. There is a SERIES LAW,
PARALLEL
LAW
similar parallel law: conductances in parallel add up. To formalize these laws, one needs to
introduce multigraphs. This is straightforward, although to avoid complicating the notation
further we will not do this here. (But see Example 3.3.22 for a simple case.)
Another useful network reduction technique is illustrated in the next example.
Example 3.3.15 (Network reduction: binary tree). Let N be the rooted binary tree with n
levels bT
n
2
and equal conductances on all edges. Let 0 be the root. Pick an arbitrary leaf and
denote it by n. The remaining vertices on the path between 0 and n, which we refer to as the
main path, will be denoted by 1, . . . , n − 1 moving away from the root. We claim that, for all
0 < x < n, it holds that
Px[τ0 < τn] = (n − x)/n.
Indeed, let v be the voltage with values 1 and 0 at a = 0 and Z = {n}, respectively. Let i
be the corresponding current. Notice that, for each 0 ≤ y < n, the current – as a flow – has
“nowhere to go” on the subtree Ty hanging from y away from the main path. The leaves of
the subtree are dead ends. Hence the current must be 0 on Ty and by Ohm’s law the voltage
must be constant on it, that is, every vertex in Ty has voltage v( y).
Imagine collapsing all vertices in Ty
, including y, into a single vertex (and removing the
self-loops so created). Doing this for every vertex on the main path results in a new reduced
network which is formed of a single path as in Example 3.3.14. Note that the voltage and
the current can be taken to be the same as they were previously on the main path. Indeed,
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press154 Martingales and Potentials
with this choice, Ohm’s law is automatically satisfied. Moreover, because there is no current
on the hanging subtrees in the original network, Kirchhoff ’s node law is also satisfied on the
reduced network, as no current is “lost.”
Hence, the answer can be obtained from Example 3.3.14. That proves the claim. (You
should convince yourself that this result is obvious from a probabilistic point of view.) J
We gave a probabilistic interpretation of the voltage. What about the current? The follow￾ing result says that, roughly speaking, i(x, y) is the net traffic on the edge {x, y} from x to y.
We start with an important formula for the voltage at a. For the walk started at a, we use the
shorthand
P[a → Z] := Pa[τZ < τ +
a
]
ESCAPE for the escape probability. The next lemma can be interpreted as a sort of Ohm’s law between
PROBABILITY a and Z, where c(a) P[a → Z] is the “effective conductance.” (We will be more formal in
Definition 3.3.19.)
Lemma 3.3.16 (Effective Ohm’s Law). Let v be a voltage on N with source a and sink Z.
Let i be the associated current. Then,
v(a)
kik
=
1
c(a) P[a → Z]
. (3.3.22)
Proof Using the usual first-step analysis,
P[a → Z] =
X
x:x∼a
P(a, x)Px[τZ < τa]
=
X
x:x∼a
c(a, x)
c(a)

1 −
v(x)
v(a)

=
1
c(a)v(a)
X
x:x∼a
c(a, x)[v(a) − v(x)]
=
1
c(a)v(a)
X
x:x∼a
i(a, x),
where we used Corollary 3.3.13 on the second line and Ohm’s law on the last line. Rearrang￾ing gives the result.
Recall the Green function from (3.1.3).
Theorem 3.3.17 (Probabilistic interpretation of the current). For x ∼ y, let NZ
x→y
be the
number of transitions from x to y up to the time of the first visit to the sink Z for the random
walk on N started at a. Let v be the voltage corresponding to the unit current i. Then the
following formulas hold:
v(x) =
GτZ
(a, x)
c(x)
∀x (3.3.23)
and
i(x, y) = Ea[N
Z
x→y − N
Z
y→x
] ∀x ∼ y.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.3 Potential Theory and Electrical Networks 155
Proof We prove the formula for the voltage by showing that v(x) as defined in (3.3.23) is
harmonic on W = V\({a} ∪Z). Note first that, for all z ∈ Z, the expected number of visits to
z before reaching Z (i.e., GτZ
(a,z)) is 0. Or, put differently, 0 = v(z) =
GτZ
(a,z)
c(z)
. Moreover, to
compute GτZ
(a, a), note that the number of visits to a before the first visit to Z is geometric
with success probability P[a → Z] by the strong Markov property (Theorem 3.1.8) and
hence
GτZ
(a, a) =
1
P[a → Z]
,
and, by Lemma 3.3.16 and the fact that we are using the unit current, v(a) =
GτZ
(a,a)
c(a)
, as
required.
To establish the formula for x ∈ W, we compute the quantity
1
c(x)
X
y:y∼x
Ea[N
Z
y→x
]
in two ways. First, because each visit to x ∈ W must enter through one of x’s neighbors
(including itself in the presence of a self-loop), we get
1
c(x)
X
y:y∼x
Ea[N
Z
y→x
] =
GτZ
(a, x)
c(x)
. (3.3.24)
On the other hand, by the Markov property (Theorem 1.1.18):
Ea[N
Z
y→x
]
= Ea
" X
0≤t<τZ
1{Xt=y,Xt+1=x}
#
=
X
t≥0
Pa [Xt = y, Xt+1 = x, τZ > t]
=
X
t≥0
Pa[τZ > t]Pa[Xt = y | τZ > t]Pa[Xt+1 = x | Xt = y, τZ > t]
=
X
t≥0
Pa[τZ > t]Pa[Xt = y | τZ > t]P( y, x)
=
X
t≥0
Pa[Xt = y, τZ > t]P( y, x)
= P( y, x) Ea
" X
0≤t<τZ
1{Xt=y}
#
= P( y, x) GτZ
(a, y), (3.3.25)
so that, summing over y, we obtain this time
1
c(x)
X
y:y∼x
Ea[N
Z
y→x
] =
1
c(x)
X
y:y∼x
P( y, x) GτZ
(a, y)
=
X
y:y∼x
P(x, y)
GτZ
(a, y)
c( y)
, (3.3.26)
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press156 Martingales and Potentials
where we used that c(x, y) = c(x)P(x, y) = c( y)P( y, x) (see Definition 1.2.7). Equating (3.3.24)
and (3.3.26) shows that GτZ
(a,x)
c(x)
is harmonic on W and hence must be equal to the voltage
function by Corollary 3.3.13.
Finally, by (3.3.25),
Ea[N
Z
x→y − N
Z
y→x
] = P(x, y) GτZ
(a, x) − P( y, x) GτZ
(a, y)
= P(x, y)v(x)c(x) − P( y, x)v( y)c( y)
= c(x, y)[v(x) − v( y)]
= i(x, y).
That concludes the proof.
Example 3.3.18 (Network reduction: binary tree (continued)). Recall the setting of Exam￾ple 3.3.15. We argued that the current on side edges, that is, edges of subtrees hanging from
the main path, is 0. This is clear from the probabilistic interpretation of the current: in a walk
from a to z, any traversal of a side edge must be undone at a later time. J
The network reduction techniques illustrated above are useful. But the power of the elec￾trical network perspective is more apparent in what comes next: the definition of the effective
resistance and, especially, its variational characterization.
Effective resistance
Before proceeding further, let us recall our original motivation. Let N = (G, c) be a count￾able, locally finite, connected network and let (Xt) be the corresponding walk. Recall that a
vertex a in G is transient if Pa[τ
+
a < +∞] < 1.
EXHAUSTIVE To relate this to our setting, consider an exhaustive sequence of induced subgraphs Gn of
SEQUENCE G which for our purposes is defined as: G0 contains only a, Gn ⊆ Gn+1, G =
S
n Gn, and
every Gn is finite and connected. Such a sequence always exists by iteratively adding the
neighbors of the previous vertices and using that G is locally finite and connected. Let Zn be
the set of vertices of G not in Gn. Then, by Lemma 3.1.25, Pa[τZn ∧ τ
+
a = +∞] = 0 for all
n by our assumptions on (Gn). Hence, the remaining possibilities are
1 = Pa[∃n, τ
+
a < τZn
] + Pa[∀n, τZn < τ +
a
]
= Pa[τ
+
a < +∞] + lim
n
P[a → Zn].
Therefore, a is transient if and only if limn P[a → Zn] > 0. Note that the limit exists because
the sequence of events {τZn < τ +
a
} is decreasing by construction. By a sandwiching argument
the limit also does not depend on the exhaustive sequence. Hence, we define
P[a → ∞] := lim
n
P[a → Zn].
We use Lemma 3.3.16 to characterize this limit using electrical network concepts.
But, first, here comes the key definition. In Lemma 3.3.16, v(a) can be thought of as the
potential difference between the source and the sink, and kik can be thought of as the total
current flowing through the network from the source to the sink. Hence, viewing the network
as a single “super-edge,” (3.3.22) is the analogue of Ohm’s law if we interpret c(a) P[a → Z]
as an “effective conductance.”
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.3 Potential Theory and Electrical Networks 157
Definition 3.3.19 (Effective resistance and conductance). Let N = (G, c) be a finite or
countable, locally finite, connected network. Let A = {a} and Z be disjoint non-empty subsets
of the vertex set V such that W := V\(A ∪ Z) is finite. Let v be a voltage from source a to
sink Z and let i be the corresponding current. The effective resistance between a and Z is EFFECTIVE
defined as RESISTANCE
R(a ↔ Z) :=
1
c(a) P[a → Z]
=
v(a)
kik
,
where the rightmost equality holds by Lemma 3.3.16. The reciprocal is called the effective EFFECTIVE
conductance and denoted by C (a ↔ Z) := 1/R(a ↔ Z). CONDUCTANCE
Going back to recurrence, for an exhaustive sequence (Gn) with (Zn) as above, it is natural
to define
R(a ↔ ∞) := lim
n
R(a ↔ Zn),
where, once again, the limit does not depend on the choice of exhaustive sequence.
Theorem 3.3.20 (Recurrence and resistance). Let N = (G, c) be a countable, locally finite,
connected network. Vertex a (and hence all vertices) in N is transient if and only if R(a ↔
∞) < +∞.
Proof This follows immediately from the definition of the effective resistance. Recall that,
on a connected network, all states have the same type (recurrent or transient).
Note that the network reduction techniques we discussed previously leave both the volt￾age and the current strength unchanged on the reduced network. Hence, they also leave the
effective resistance unchanged.
Example 3.3.21 (Gambler’s ruin chain revisited). Extend the gambler’s ruin chain of Exam￾ple 3.3.14 to all of Z+. We determine when this chain is transient. Because it is irreducible,
all states have the same type and it suffices to look at 0. Consider the exhaustive sequence ob￾tained by letting Gn be the graph restricted to {0, 1, . . . , n−1} and letting Zn = {n, n+1 . . .}.
To compute the effective resistance R(0 ↔ Zn), we use the same reduction as in Exam￾ple 3.3.14. The “super-edge” between 0 and n has resistance
R(0 ↔ Zn) =
Xn−1
j=0
r( j, j + 1) =
Xn−1
j=0
(q/p)
j =
(q/p)
n − 1
(q/p) − 1
,
when p 6= q, and similarly it has resistance n in the p = q case. Hence, taking a limit as
n → +∞,
R(0 ↔ ∞) =
(
+∞, p ≤ 1/2,
p
2p−1
, p > 1/2.
So 0 is transient if and only if p > 1/2. J
Example 3.3.22 (Biased walk on the b-ary tree). Fix λ ∈ (0, +∞). Consider the rooted,
infinite b-ary tree with conductance λ
j on all edges between level j − 1 and j, for j ≥ 1.
We determine when this chain is transient. Because it is irreducible, all states have the same
type and it suffices to look at the root. Denote the root by 0. For an exhaustive sequence,
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press158 Martingales and Potentials
let Gn be the root together with the first n − 1 levels. Let Zn be as before. To compute
R(0 ↔ Zn): (i) glue together all vertices of Zn; (ii) glue together all vertices on the same
level of Gn; (iii) replace parallel edges with a single edge whose conductance is the sum of
the conductances; (iv) let the current on this edge be the sum of the currents; and (v) leave
the voltages unchanged. It can be checked that Ohm’s law and Kirchhoff ’s node law are still
satisfied, and that hence we have not changed the effective resistance. (This is an application
of the parallel law.)
The reduced network is now a line. Denote the new vertices 0, 1, . . . , n. The conductance
on the edge between j and j + 1 is b
j+1λ
j = b(bλ)
j
. So this is the chain from the previous
example with (p/q) = bλ where all conductances are scaled by a factor of b. Hence,
R(0 ↔ ∞) =
(
+∞, bλ ≤ 1,
1
b(1−(bλ)
−1
)
, bλ > 1.
So the root is transient if and only if bλ > 1.
A generalization is provided in Example 3.3.27. J
3.3.3 Bounding the Effective Resistance via Variational Principles
The examples we analyzed so far were atypical in that it was possible to reduce the network
down to a single edge using simple rules and read off the effective resistance. In general, we
need more robust techniques to bound the effective resistance. The following two variational
principles provide a powerful approach for this purpose. We derive them for finite networks,
but will later on apply them to exhaustive sequences.
Variational principles
Recall from Definition 1.1.13 that a flow θ from source a to sink Z on a countable, locally
finite, connected network N = (G, c) is a function on pairs of adjacent vertices such that θ is
anti-symmetric, that is, θ(x, y) = −θ( y, x) for all x ∼ y; and it satisfies the flow-conservation
constraint P
y:y∼x
θ(x, y) = 0 on all vertices x except those in {a} ∪ Z. The strength of the
flow is kθk = P
y:y∼a
θ(a, y). The current is a special flow – one that can be written as a
potential difference according to Ohm’s law. As we show next, it can also be characterized
ENERGY as a flow minimizing a certain energy. Specifically, the energy of a flow θ is defined as
E (θ) =
1
2
X
x,y
r(x, y)θ(x, y)
2
.
The proof of the variational principle we present here employs a neat trick, convex duality.
In particular, it reveals that the voltage and current are dual in the sense of convex analysis.
Theorem 3.3.23 (Thomson’s principle). Let N = (G, c) be a finite, connected network. The
effective resistance between source a and sink Z is characterized by
R(a ↔ Z) = inf 
E (θ): θ is a unit flow between a and Z	
. (3.3.27)
The unique minimizer is the unit current.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.3 Potential Theory and Electrical Networks 159
Proof It will be convenient to work in vector form. Let 1, . . . , n be the vertices of G and
order the edges arbitrarily as e1, . . . , em. Choose an arbitrary orientation of N , that is, replace
each edge ei = {x, y} with either Eei = (x, y) or ( y, x). Let
−→
G be the corresponding directed
graph. Think of the flow θ as a vector with one coordinate for each oriented edge. Then the
flow constraint can be written as a linear system Bθ = b. Here the matrix B has a column
for each directed edge and a row for each vertex except those in Z. The entries of B are
Bx,(x,y) = 1, By,(x,y) = −1, and 0 otherwise. We have already encountered this matrix: it is an
oriented incidence matrix of G (see Definition 1.1.16) restricted to the rows in V \ Z. The
vector b has 0s everywhere except for ba = 1. Let r be the vector of resistances and let R
be the diagonal matrix with diagonal r. In vector form, E (θ) = θ
TRθ and the optimization
problem (3.3.27) reads
E
∗ = inf{θ
TRθ : Bθ = b}.
We first characterize the optimal flow. We introduce the Lagrangian LAGRANGIAN
L (θ; h) := θ
TRθ − 2h
T
(Bθ − b),
where h has an entry for all vertices except those in Z. For all h,
E
∗ ≥ inf
θ
L (θ; h),
because those θs with Bθ = b make the second term vanish in L (θ; h). Since L (θ; h) is
strictly convex as a function of θ, the solution to its minimization is characterized by the
usual optimality conditions which in this case read 2Rθ − 2B
T h = 0, or
θ = R
−1B
T h. (3.3.28)
Substituting into the Lagrangian and simplifying, we have proved that
E (θ) ≥ E
∗ ≥ −h
TBR−1B
T h + 2h
T
b =: L ∗
(h) (3.3.29)
for all h and flow θ. This inequality is a statement of weak duality. To show that a flow θ is
optimal it suffices to find h such that E (θ) = L ∗
(h).
Let θ = i be the unit current in vector form, which satisfies Bθ = b by our choice of b
and Kirchhoff ’s node law (i.e., (3.3.21)). The suitable dual turns out to be the corresponding
voltage h = v in vector form restricted to V \ Z. To see this, observe that B
T h is the vector
of neighboring node differences
B
T h = (h(x) − h( y))
(x,y)∈
−→G
, (3.3.30)
where implicitly h|Z ≡ 0. Hence, the optimality condition (3.3.28) is nothing but Ohm’s law
(i.e., (3.3.20)) in vector form. Therefore, if i is the unit current and v is the associated voltage
in vector form, it holds that
L ∗
(v) = L (i; v) = E (i),
where the first equality follows from the fact that i minimizes L (i; v) by (3.3.28) and the
second equality follows from the fact that Bi = b. So we must have E (i) = E
∗ by weak
duality (i.e., (3.3.29)).
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press160 Martingales and Potentials
As for uniqueness, it can be checked that two minimizers θ, θ
0
satisfy
E
∗ =
E (θ) + E (θ
0
)
2
= E

θ + θ
0
2

+ E

θ − θ
0
2

by definition of the energy. The first term in the rightmost expression is greater than or equal
to E
∗
since the average of two unit flows is still a unit flow. The second term is non-negative
by definition. Hence, the latter must be zero and the only way for this to happen is if θ = θ
0
.
To conclude the proof, it remains to compute the optimal value. The matrix BR−1B
T
is
related to the Laplacian associated to random walk on N (see Section 3.3.1) up to a row
scaling. Multiplying by row x ∈ V \ Z involves taking a conductance-weighted average of
the neighboring values and subtracting the value at x, that is,
￾
BR−1B
T
v

x =
X
y:(x,y)∈
−→G
h
c(x, y)(v(x) − v( y))i
−
X
y:( y,x)∈
−→G
h
c( y, x)(v( y) − v(x))i
=
X
y:y∼x
h
c(x, y)(v(x) − v( y))i
,
where we used (3.3.30) and the facts that r(x, y)
−1 = c(x, y) and c(x, y) = c( y, x), and it is
assumed implicitly that v|Z ≡ 0. By Corollary 3.3.13, this is zero except for the row x = a,
where it is
X
y:y∼a
c(a, y)[v(a) − v( y)] =
X
y:y∼a
i(a, y) = 1,
where we used Ohm’s law and the fact that the current has unit strength. We have finally
E
∗ = L ∗
(v)
= −v
TBR−1B
T
v + 2v
T
b
= −v(a) + 2v(a)
= v(a)
= R(a ↔ Z),
by (3.3.16). That concludes the proof.
Observe that the convex combination α minimizing the sum of squares P
j α
2
j
is constant.
In a similar manner, Thomson’s principle (Theorem 3.3.23) stipulates roughly speaking that
the more the flow can be spread out over the network, the lower is the effective resistance
(penalizing flow on edges with higher resistance). Pólya’s theorem (Theorem 3.3.38) pro￾vides a vivid illustration. Here is a simple example suggesting that, in a sense, the current is
indeed a well-distributed flow.
Example 3.3.24 (Random walk on the complete graph). Let N be the complete graph on
{1, . . . , n} with unit resistances, and let a = 1 and Z = {n}. Assume n > 2. The effective
resistance is straightforward to compute in this case. Indeed, the escape probability (with a
slight abuse of notation) is
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Pres3.3 Potential Theory and Electrical Networks 161
P[1 → n] =
1
n − 1
+
1
2

1 −
1
n − 1

=
n
2(n − 1)
,
as we either jump to n immediately or jump to one of the remaining nodes, in which case we
reach n first with probability 1/2 by symmetry. Hence, since c(1) = n − 1, we get
R(1 ↔ n) =
2
n
from the definition of the effective resistance (Definition 3.3.19).
We now look for the optimal flow in Thomson’s principle. Pushing a flow of 1 through the
edge {1, n} gives an upper bound of 1, which is far from the optimal 2
n
. Spreading the flow a
bit more by pushing 1/2 through the edge {1, n} and 1/2 through the path 1 ∼ 2 ∼ n gives
the slightly better bound 3 · (1/2)2 = 3/4. Taking this further, pushing a flow of 1
n−1
through
{1, n} as well as through each two-edge path to n via the remaining neighbors of 1 gives the
yet improved bound

1
n − 1
2
+ 2(n − 2)
1
n − 1
2
=
2n − 3
(n − 1)2
=
2
n
·
2n
2 − 3n
2n
2 − 4n + 2
>
2
n
,
when n > 2. Because the direct path from 1 to n has a somewhat lower resistance, the
optimal flow is obtained by increasing the flow on that edge slightly. Namely, for a flow α
on {1, n} (and the rest divided up evenly among the two-edge paths), we get an energy of
α
2 + 2(n − 2)[ 1−α
n−2
]
2
, which is minimized at α =
2
n
, where it is indeed

2
n
2
+
2
n − 2

n − 2
n
2
=
2
n

2
n
+
n − 2
n

=
2
n
.
J
As we noted above, the matrix BR−1B
T
in the proof of Thomson’s principle is related to
the Laplacian. Because B
T h is the vector of neighboring node differences, we have
h
TBR−1B
T h =
1
2
X
x,y
c(x, y)[h( y) − h(x)]2
,
where we implicitly fix h|Z ≡ 0, which is called the Dirichlet energy. Thinking of B
T
as DIRICHLET
a “discrete gradient,” the Dirichlet energy can be interpreted as the weighted norm of the ENERGY
gradient of h. The following is a “dual” to Thomson’s principle. Exercise 3.15 asks for a
proof.
Theorem 3.3.25 (Dirichlet’s principle). Let N = (G, c) be a finite, connected network. The
effective conductance between source a and sink Z is characterized by
C (a ↔ Z) = inf(
1
2
X
x,y
c(x, y)[h( y) − h(x)]2
: h(a) = 1, h|Z ≡ 0}
)
.
The unique minimizer is the voltage v with v(a) = 1.
The following lower bound is a typical application of Thomson’s principle. See Pólya’s
theorem (Theorem 3.3.38) for an example of its use. Recall from Section 1.1.1 that, on a
finite graph, a cutset separating a from Z is a set of edges 5 such that any path between
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press162 Martingales and Potentials
a and Z must include at least one edge in 5. Similarly, as defined in Section 2.3.3, on a
countable, locally finite network, a cutset separating a from ∞ is a finite set of edges that
must be crossed by any infinite (self-avoiding) path from a.
Corollary 3.3.26 (Nash–Williams inequality) Let N be a finite, connected network and let
{5j}
n
j=1
be a collection of disjoint cutsets separating source a from sink Z. Then,
R(a ↔ Z) ≥
Xn
j=1


X
e∈5j
c(e)


−1
.
Similarly, if N is a countable, locally finite, connected network, then for any collection {5j}j
of finite, disjoint cutsets separating a from ∞,
R(a ↔ ∞) ≥
X
j


X
e∈5j
c(e)


−1
.
Proof Consider the case where N is finite first. We will need the following claim, which
follows immediately from Lemma 1.1.14: for any unit flow θ between a and Z and any cutset
5j separating a from Z, it holds that
X
e∈5j
|θ(e)| ≥ kθk = 1.
By Cauchy–Schwarz (Theorem B.4.8),
X
e∈5j
c(e)
X
e
0∈5j
r(e
0
)θ(e
0
)
2 ≥


X
e∈5j
p
c(e)r(e) |θ(e)|


2
=


X
e∈5j
|θ(e)|


2
≥ 1.
Rearranging, summing over j and using the disjointness of the cutsets,
E (θ) =
1
2
X
x,y
r(x, y)θ(x, y)
2 ≥
Xn
j=1
X
e
0∈5j
r(e
0
)θ(e
0
)
2 ≥
Xn
j=1


X
e∈5j
c(e)


−1
.
Thomson’s principle gives the result.
The infinite case follows from a similar argument using an exhaustive sequence.
The following example is an application of Nash–Williams (Corollary 3.3.26) and Thom￾son’s principle to recurrence.
Example 3.3.27 (Biased walk on general trees). Let T be a locally finite tree with root 0.
Consider again the biased walk from Example 3.3.22, that is, conductance is λ
j on all edges
between level j − 1 and j. Recall the branching number br(T ) from Definition 2.3.10.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.3 Potential Theory and Electrical Networks 163
Assume λ > br(T ). For any ε > 0, there is a cutset 5 such that P
e∈5
λ
−|e| ≤ ε. By
Nash–Williams,
R(0 ↔ ∞) ≥
 X
e∈5
c(e)
!−1
≥ ε
−1
.
Since ε is arbitrary, the walk is recurrent by Theorem 3.3.20.
Suppose instead that λ < br(T ) and let λ < λ∗ < br(T ). By the proof of Claim 2.3.11,
for all n ≥ 1, there exist ε > 0 and a unit flow φn from 0 to the n-level vertices ∂n with
capacity constraints |φn(x, y)| ≤ ε
−1λ
−|e|
∗
for all edges e = {x, y}, where |e| is the graph
distance from the root to the endvertex of e furthest from it. Then, letting Fm = {e: |e| = m},
the energy of the flow is
E (φn) =
1
2
X
x,y
r(x, y)φn(x, y)
2
≤
Xn
m=1
λ
m X
e={x,y}∈Fm
|φn(x, y)|ε
−1
λ
−|e|
∗
= ε
−1Xn
m=1

λ
λ∗
m X
e={x,y}∈Fm
|φn(x, y)|
≤ ε
−1X
+∞
m=1

λ
λ∗
m
< +∞,
where, on the fourth line, we used Lemma 1.1.14 together with the fact that φn is a unit
flow and Fm is a cutset separating 0 and ∂n. Thomson’s principle implies that R(0 ↔ ∂n) is
uniformly bounded in n. The walk is transient by Theorem 3.3.20. J
Another typical application of Thomson’s principle is the following monotonicity prop￾erty (which is not obvious from a probabilistic point of view).
Corollary 3.3.28 Adding an edge to a finite, connected network cannot increase the effective
resistance between a source a and a sink Z. In particular, if the added edge is not incident
to a, then P[a → Z] cannot decrease.
Proof The additional edge enlarges the space of possible flows, so by Thomson’s principle
it can only lower the resistance or leave it as is. The second statement follows from the
definition of the effective resistance.
More generally:
Corollary 3.3.29 (Rayleigh’s principle) Let N and N 0 be two networks on the same finite,
connected graph G such that, for each edge in G, the resistance in N 0
is greater than it is in
N . Then, for any source a and sink Z,
RN (a ↔ Z) ≤ RN0(a ↔ Z).
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press164 Martingales and Potentials
Proof Compare the energies of an arbitrary flow on N and N 0
, and apply Thomson’s
principle.
Note that this corollary implies the previous one by thinking of an absent edge as one with
infinite resistance.
Flows to infinity
Combining Theorem 3.3.20 and Thomson’s principle, we derive a flow-based criterion for
recurrence. To state the result, it is convenient to introduce the notion of a unit flow θ from
FLOW TO ∞ source a to ∞ on a countable, locally finite network: θ is anti-symmetric, it satisfies the
flow-conservation constraint on all vertices but a, and kθk :=
P
y∼a
θ(a, y) = 1. Note that
the energy E (θ) of such a flow is well defined in [0, +∞].
Theorem 3.3.30 (Recurrence and finite-energy flows). Let N = (G, c) be a countable,
locally finite, connected network. Vertex a (and hence all vertices) in N is transient if and
only if there is a unit flow from a to ∞ of finite energy.
Proof Suppose such a flow exists and has energy bounded by B < +∞. Let (Gn) be an
exhaustive sequence with associated sinks (Zn). A unit flow from a to ∞ on N yields, by
projection, a unit flow from a to Zn. This projected flow also has energy bounded by B.
Hence, Thomson’s principle implies R(a ↔ Zn) ≤ B for all n and transience follows from
Theorem 3.3.20.
Proving the other direction involves producing a flow to ∞. Suppose a is transient and
let (Gn) be an exhaustive sequence as above. Then, Theorem 3.3.20 implies that R(a ↔
Zn) ≤ R(a ↔ ∞) < B for some B < +∞ and Thomson’s principle guarantees in turn
the existence of a flow θn from a to Zn with energy bounded by B. In particular, there is a
unit current in, and associated voltage vn, of energy bounded by B. So it remains to use the
sequence of current flows (in) to construct a flow to ∞ on the infinite network. The technical
point is to show that the limit of (in) exists and is indeed a flow. For this, consider the random
walk on N started at a. Let Yn(x) be the number of visits to x before hitting Zn the first time.
By the monotone convergence theorem (Proposition B.4.14), EaYn(x) → EaY∞(x), where
Y∞(x) is the total number of visits to x. Moreover, EaY∞(x) < +∞ by transience and (3.1.2).
By (3.3.23), EaYn(x) = c(x)vn(x). So we can now define
v∞(x) := lim
n
vn(x) < +∞,
and then
i∞(x, y) := c(x, y)[v∞(x) − v∞( y)]
= lim
n
c(x, y)[vn(x) − vn( y)]
= lim
n
in(x, y)
by Ohm’s law (when n is large enough that both x and y are in Gn). Because in is a flow for
all n, by taking limits in the flow-conservation constraints we see that so is i∞. Note that by
construction of i`,
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.3 Potential Theory and Electrical Networks 165
1
2
X
x,y∈Gn
c(x, y)i∞(x, y)
2 = lim
`≥n
1
2
X
x,y∈Gn
c(x, y)i`(x, y)
2
≤ lim sup
`≥n
E (i`)
< B
uniformly in n. Because the left-hand side converges to the energy of i∞ as n → +∞, we
are done.
We give an application to Pólya’s theorem in Section 3.3.4.
Finally, we derive a useful general result illustrating the robustness reaped from Thom￾son’s principle. At a high level, a rough embedding from N to N 0
is a mapping of the edges
of N to paths of N 0 of comparable overall resistance that do not overlap much. The formal
definition follows. As we will see, the purpose of a rough embedding is to allow a flow on
N to be morphed into a flow on N 0 of comparable energy.
Definition 3.3.31 (Rough embedding). Let N = (G, c) and N 0 = (G
0
, c
0
) be networks with
resistances r and r0
, respectively. We say that a map φ from the vertices of G to the vertices
of G0
is a rough embedding if there are constants α, β < +∞ and a map 8 defined on the ROUGH
edges of G such that EMBEDDING
1 for every edge e = {x, y} in G, 8(e) is a non-empty path of edges of G0 between φ(x) and
φ( y) such that
X
e
0∈8(e)
r
0
(e
0
) ≤ α r(e);
2 for every edge e0
in G0
, there are no more than β edges in G whose image under 8 contains
e
0
.
The map φ need not in general be a bijection.
We say that two networks are roughly equivalent if there exist rough embeddings between ROUGHLY
them, one in each direction. EQUIVALENT
Example 3.3.32 (Independent-coordinate random walk). Let N = L
d with unit resistances
and let N 0 be the network corresponding to the independent-coordinate random walk
(Y
(1)
t
, . . . , Y
(d)
t
),
where each coordinate (Y
(i)
t
) is an independent simple random walk on Z started at 0. For
example, the neighborhood of the origin in N 0
is {(x1, . . . , xd): xi ∈ {−1, 1} ∀i}. Note that
N 0
contains only those points of Z
d with coordinates of identical parities.
Despite encoding quite different random walks, we claim that the networks N and N 0
are
roughly equivalent.
• N to N 0
: Consider the map φ, which associates to each x ∈ N a closest point in N 0
chosen in some arbitrary manner. For 8, associate to each edge e = {x, y} ∈ N a shortest
path in N 0 between φ(x) and φ( y), again chosen arbitrarily. If φ(x) = φ( y), choose an
arbitrary, non-empty, shortest cycle through φ(x).
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press166 Martingales and Potentials
• N 0
to N : Consider the map φ, which associates to each x ∈ N 0
the corresponding point
x in N . Construct 8 similarly to the previous case.
Exercise 3.19 asks for a rigorous proof of rough equivalence. See also Exercise 3.20 for an
important generalization of this example. J
Our main result about roughly equivalent networks is that they have the same type.
Theorem 3.3.33 (Recurrence and rough equivalence). Let N and N 0 be roughly equivalent,
locally finite, connected networks. Then N is transient if and only if N 0
is transient.
Proof Assume N is transient and let θ be a unit flow from some a to ∞ of finite energy.
The existence of this flow is guaranteed by Theorem 3.3.30. Let φ, 8 be a rough embedding
from N to N 0 with parameters α and β.
The basic idea of the proof is to map the flow θ onto N 0 using 8. Because flows are
directional, it will be convenient to think of edges as being directed. For e = {x, y} in
N , let −→
8(x, y) be the path 8(e) oriented from φ(x) to φ( y). So (x
0
, y
0
) ∈
−→
8(x, y) means
that {x
0
, y
0
} ∈ 8(e) and that x
0
is visited before y
0
in the path 8(e) from φ(x) to φ( y). (If
φ(x) = φ( y), choose an arbitrary orientation of the cycle 8(e) for −→
8(x, y) and the reversed
orientation for −→
8( y, x).) Then define, for x
0
, y
0 with {x
0
, y
0
} in N 0
,
θ
0
(x
0
, y
0
) :=
X
(x,y):(x
0
,y
0
)∈
−→8(x,y)
θ(x, y). (3.3.31)
See Figure 3.5.
We claim that θ
0
is a flow to ∞ of finite energy on N 0
. We first check that θ
0
is a flow.
1. (Anti-symmetry) By construction, θ
0
(y
0
, x
0
) = −θ
0
(x
0
, y
0
), that is, θ
0
is antisymmetric, be￾cause θ itself is anti-symmetric. We used the fact that −→
8( y, x) is −→
8(x, y) oriented in the
opposite direction.
2. (Flow conservation) Next we check the flow-conservation constraints. Fix z
0
in N 0
. By
Condition 2 in Definition 3.3.31, there are finitely many edges e in N such that 8(e)
visits z
0
. Let e = {x, y} be such an edge. There are two cases:
Figure 3.5 The flow on (x
0
, y
0
) is the sum of the flows on (x1, y1), (x2, y2), and
(x3, y3).
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.3 Potential Theory and Electrical Networks 167
• Assume first that φ(x), φ( y) 6= z
0
and let (u
0
,z
0
), (z
0
,w
0
) be the directed edges incident
with z
0 on
−→
8(x, y). Observe that, in the definition of θ
0
, ( y, x) contributes θ( y, x) =
−θ(x, y) to θ
0
(z
0
, u
0
) and (x, y) contributes θ(x, y) to θ
0
(z
0
,w
0
). So these contributions
cancel out in the flow-conservation constraint forz
0
, that is, in the sum P
v
0
:v
0∼z
0 θ
0
(z
0
, v
0
).
• If instead e = {x, y} is such that φ(x) = z
0
, let (z
0
,w
0
) be the first edge on the path
−→
8(x, y). Edge (x, y) contributes θ(x, y) to θ
0
(z
0
,w
0
). A similar statement applies to
φ( y) = z
0 by changing the role of x and y. This case also applies to φ(x) = φ( y) = z
0
.
From these two cases, summing over all paths visiting z
0 gives
X
v
0
:v
0∼z
0
θ
0
(z
0
, v
0
) =
X
z:φ(z)=z
0
 X
v:v∼z
θ(z, v)
!
.
Because θ is a flow, the sum in parentheses is 0 if z 6= a and 1 otherwise. So the right-hand
side is 0 unless a ∈ φ
−1
({z
0
}), in which case it is 1.
We have shown that θ
0
is a unit flow from φ(a) to ∞. It remains to bound the energy of
θ
0
. By (3.3.31), Cauchy–Schwarz, and Condition 2 in Definition 3.3.31,
θ
0
(x
0
, y
0
)
2 =


X
(x,y):(x
0
,y
0
)∈
−→8(x,y)
θ(x, y)


2
≤


X
(x,y):(x
0
,y
0
)∈
−→8(x,y)
1




X
(x,y):(x
0
,y
0
)∈
−→8(x,y)
θ(x, y)
2


≤ β
X
(x,y):(x
0
,y
0
)∈
−→8(x,y)
θ(x, y)
2
.
Summing over all pairs and using Condition 1 in Definition 3.3.31 gives
1
2
X
x
0
,y
0
r
0
(x
0
, y
0
)θ
0
(x
0
, y
0
)
2 ≤ β
1
2
X
x
0
,y
0
r
0
(x
0
, y
0
)
X
(x,y):(x
0
,y
0
)∈
−→8(x,y)
θ(x, y)
2
= β
1
2
X
x,y
θ(x, y)
2 X
(x
0
,y
0
)∈
−→8(x,y)
r
0
(x
0
, y
0
)
≤ αβ
1
2
X
x,y
r(x, y)θ(x, y)
2
,
which is finite by assumption. That concludes the proof.
As an application, we give a second proof of Pólya’s theorem in Section 3.3.4.
Other applications
So far we have emphasized applications to recurrence. Here we show that electrical net￾work theory can also be used to bound commute times. In Section 3.3.5, we give further
applications beyond random walks on graphs.
An application of Lemma 3.1.24 gives another probabilistic interpretation of the effective
resistance – and a useful formula.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press168 Martingales and Potentials
Theorem 3.3.34 (Commute time identity). Let N = (G, c) be a finite, connected network
COMMUTE with vertex set V. For x 6= y, let the commute time τx,y be the time of the first return to x after
TIME the first visit to y. Then,
Ex[τx,y] = Ex[τy] + Ey[τx] = cN R(x ↔ y),
where cN = 2
P
e={x,y}∈N c(e).
Proof This follows immediately from Lemma 3.1.24 and the definition of the effective
resistance (Definition 3.3.19). Specifically,
Ex[τy] + Ey[τx] =
1
πx Px[τy < τ +
x
]
=
1
(2P
e={x,y}∈N c(e))−1c(x) Px[τy < τ +
x
]
= cN R(x ↔ y).
Example 3.3.35 (Random walk on the torus). Consider random walk on the d-dimensional
torus L
d
n with unit resistances. We use the commute time identity to lower bound the mean
hitting time Ex[τy] for arbitrary vertices x 6= y at graph distance k on L
d
n
. To use the commute
time identity (Theorem 3.3.34), note that by symmetry Ex[τy] = Ey[τx] so that
Ex[τy] =
1
2
cN R(x ↔ y) = dnd R(x ↔ y), (3.3.32)
where we used that the number of vertices is n
d
and the graph is 2d-regular.
To simplify, assume n is odd and identify the vertices of L
d
n with the box
B := {−(n − 1)/2, . . . , (n − 1)/2}
d
in L
d
centered at x = 0. Let ∂B
∞
j = {z ∈ L
d
: kzk∞ = j} and let 5j be the set of edges
between ∂B
∞
j
and ∂B
∞
j+1
. Note that on B the `
1 norm of y is at most k (the graph distance
between x = 0 and y). Since the `
∞ norm is at least 1/d times the `
1 norm on L
d
, there exists
J = O(k) such that all 5js, j ≤ J, are cutsets separating x from y. By the Nash–Williams
inequality,
R(x ↔ y) ≥
X
0≤ j≤J
|5j
|
−1 =
X
0≤ j≤J

￾
j
−(d−1)
=
(
(log k), d = 2,
(1), d ≥ 3.
From (3.3.32), we get:
Claim 3.3.36
Ex[τy] =
(
(n
d
log k), d = 2,
(n
d
), d ≥ 3. J
Remark 3.3.37 The bounds in the previous example are tight up to constants. See [LPW06,
Proposition 10.13]. Note that the case d ≥ 3 does not in fact depend on the distance k.
See Exercise 3.22 for an application of the commute time identity to cover times.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Pres3.3 Potential Theory and Electrical Networks 169
3.3.4 F Random Walks: Pólya’s Theorem, Two Ways
The following is a classical result.
Theorem 3.3.38 (Pólya’s theorem). Random walk on L
d
is recurrent for d ≤ 2 and transient
for d ≥ 3.
We prove the theorem for d = 2, 3 using the tools developed in the previous subsection. The
other cases follow by Rayleigh’s principle (Corollary 3.3.29). There are elementary proofs
of this result. But we showed above that the electrical network approach has the advantage
of being robust to the details of the lattice. For a different argument, see Exercise 2.10.
The case d = 2 follows from the Nash–Williams inequality (Corollary 3.3.26) by letting
5j be the set of edges connecting vertices of `
∞ norm j and j + 1. Using the fact that all
conductances are 1, that |5j
| = O( j), and that P
j
j
−1 diverges, recurrence is established by
Theorem 3.3.20.
First proof
Now consider the case d = 3 and let a = 0 be the origin. We start with a proof based on
what is known as the random paths method.
We construct a finite-energy flow to ∞ using the method of random paths. Note that a METHOD OF
RANDOM
PATHS
simple way to produce a unit flow to ∞ is to push a flow of 1 through an infinite path (which,
recall, are self-avoiding by definition). Taking this a step further, let µ be a probability
measure on infinite paths and define the anti-symmetric function
θ(x, y) := E[1(x,y)∈0 − 1( y,x)∈0] = P[(x, y) ∈ 0] − P[( y, x) ∈ 0],
where 0 is a random path distributed according to µ, oriented away from 0. (We will give
an explicit construction below where the appropriate formal probability space will be clear.)
Observe that P
y∼x
[1(x,y)∈0 − 1( y,x)∈0] = 0 for any x 6= 0 because vertices visited by 0 are
entered and exited exactly once. That same sum is 1 at x = 0. Hence, θ is a unit flow to ∞.
For edge e = {x, y}, consider the following “edge marginal” of µ:
µ(e) := P[(x, y) ∈ 0 or ( y, x) ∈ 0] = P[(x, y) ∈ 0] + P[( y, x) ∈ 0] ≥ θ(x, y),
where we used that a path 0 cannot visit both (x, y) and ( y, x) by definition. Then we get the
following bound.
Claim 3.3.39 (Method of random paths).
E (θ) ≤
X
e
µ(e)
2
. (3.3.33)
For a measure µ concentrated on a single path, the sum in (3.3.33) is infinite. To obtain a
useful bound, what we need is a large collection of spread out paths. On the lattice L
3
, we
construct µ as follows. Let U be a uniformly random point on the unit sphere in R
3
and let
γ be the ray from 0 to ∞ going through U. Imagine centering a unit cube around each point
in Z
3 whose edges are aligned with the axes. Then, γ traverses an infinite number of such
cubes. Let 0 be the corresponding path in the lattice L
3
. To see that this procedure indeed
produces a path observe that γ , upon exiting a cube around a point z ∈ Z
3
, enters the cube of
a neighboring point z
0 ∈ Z
3
through a face corresponding to the edge between z and z
0 on the
lattice L
3
(unless it goes through a corner of the cube, but this has probability 0). To argue
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press170 Martingales and Potentials
that µ distributes its mass among sufficiently spread out paths, we bound the probability that
a vertex is visited by 0. Let z be an arbitrary vertex in Z
3
. Because the sphere of radius kzk2
around the origin in R
3 has area O(kzk
2
2
) and its intersection with the unit cube centered
around z has area O(1), it follows that
P[z ∈ 0] = O
￾
1/kzk
2
2

.
That immediately implies a similar bound on the probability that an edge is visited by 0.
Moreover:
Lemma 3.3.40 There are O(j
2
) edges with an endpoint at `
2 distance within [j, j + 1] from
the origin.
Proof Consider a ball of `
2
radius 1/2 centered around each vertex of `
2 norm within
[j, j + 1]. Those balls are non-intersecting and have total volume 2(Nj), where Nj
is the
number of such vertices. On the other hand, the volume of the shell of `
2
inner and outer
radii j − 1/2 and j + 3/2 centered around the origin (where all those balls lie) is
4
3
π( j + 3/2)3 −
4
3
π( j − 1/2)3 = O( j
2
).
Hence, Nj = O( j
2
). Finally, note that each vertex has six incident edges.
Plugging those bounds into (3.3.33), we get
E (θ) ≤
X
j
O( j
2
) ·

O(1/j
2
)
2
= O
P
j
j
−2

< +∞.
Transience follows from Theorem 3.3.30. (This argument clearly does not work on L where
there are only two rays. You should convince yourself that it does not work on L
2
either. But
see Exercise 3.17.)
Second proof
We briefly describe a second proof based on the independent-coordinate random walk. Con￾sider the networks N and N 0
in Example 3.3.32. Because they are roughly equivalent (Def￾inition 3.3.31), they have the same type by Theorem 3.3.33. Recall that because the number
of returns to 0 is geometric with success probability equal to the escape probability, random
walk on N 0
is transient if and only if the expected number of visits to 0 is finite (see (3.1.2)).
By independence of the coordinates, this expectation can be written as
X
t≥0

P
h
Y
(1)
2t = 0
id
=
X
t≥0
2t
t

2
−2t
d
=
X
t≥0
2(t
−d/2
),
where we used Stirling’s formula (see Appendix A). The rightmost sum is finite if and only
if d ≥ 3. That implies random walk on N 0
is transient under that condition. By rough
equivalence, the same is true of N .
3.3.5 F Randomized Algorithms: Wilson’s Method for Generating Uniform
Spanning Trees
In this section, we describe an application of electrical network theory to spanning trees.
With a slight abuse of notation, we use e ∈ G to indicate that e is an edge of G.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Pres3.3 Potential Theory and Electrical Networks 171
Uniform spanning trees Let G = (V, E) be a finite connected graph. Recall that a spanning
tree is a subtree of G containing all its vertices. Such a tree has |V| − 1 edges. A uniform UNIFORM
SPANNING
TREE
spanning tree is a spanning tree T chosen uniformly at random among all spanning trees
of G.
We make some simple observations first. Because G is connected, it has at least one
spanning tree by Corollary 1.1.6. Moreover, for any edge e ∈ G, there always exists at least
one spanning tree including it. To see this, let T
0 be any spanning tree of G, which exists by
the previous observation. If e ∈/ T
0
, then we obtain a new spanning tree by adding e to T
0
and
removing one edge 6= e in the cycle created. As a consequence, the probability of inclusion
P[e ∈ T] in a uniform spanning tree T cannot be 0. It is, however, possible for P[e ∈ T] to
equal to 1 if removing e disconnects the graph. Such an edge is called a bridge. BRIDGE
A fundamental property of uniform spanning trees is the following negative correlation
between edges.
Claim 3.3.41 For a uniform spanning tree T of a connected graph G,
P[e ∈ T | e
0 ∈ T] ≤ P[e ∈ T] ∀e 6= e
0 ∈ G.
This property is perhaps not surprising. For one, the number of edges in a spanning tree is
fixed, so the inclusion of e
0 makes it seemingly less likely for other edges to be present. Yet
proving Claim 3.3.41 is not trivial. The proof relies on the electrical network perspective.
The key is a remarkable formula for the inclusion of an edge in a uniform spanning tree.
Theorem 3.3.42 (Kirchhoff ’s resistance formula). Let G = (V, E) be a finite, connected
graph and let N be the network on G with unit resistances. If T is a uniform spanning tree
on G, then for all e = {x, y},
P[e ∈ T] = R(x ↔ y).
Before explaining how this formula arises, we show that it implies Claim 3.3.41.
Proof of Claim 3.3.41. Recall that P[e
0 ∈ T] 6= 0. By the law of total probability,
P[e ∈ T] = P[e ∈ T | e
0 ∈ T] P[e
0 ∈ T] + P[e ∈ T | e
0 ∈/ T] P[e
0 ∈/ T],
so, since P[e
0 ∈ T] + P[e
0 ∈/ T] = 1, we can instead prove
P[e ∈ T | e
0 ∈/ T] ≥ P[e ∈ T]. (3.3.34)
Picking a uniform spanning tree on N conditioned on {e
0 ∈/ T} is the same as picking a
uniform spanning tree on the modified network N 0
, where e
0
is removed. By Rayleigh’s
principle (in the form of Corollary 3.3.28),
RN0(x ↔ y) ≥ RN (x ↔ y),
and Kirchhoff ’s resistance formula (Theorem 3.3.42) gives (3.3.34).
Remark 3.3.43 More generally, thinking of a uniform spanning tree T as a random subset
of edges, the law of T has the property of negative associations, defined as follows. An event
A ⊆ 2
E
is said to be increasing if ω ∪ {e} ∈ A whenever ω ∈ A. The event A is said to
depend only on F ⊆ E if for all ω1, ω2 ∈ 2
E
that agree on F, either both are in A or neither
is. The law PT of T has negative associations in the sense that for any two increasing events
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press172 Martingales and Potentials
A and B that depend only on disjoint sets of edges, we have PT [A ∩ B] ≤ PT [A]PT [B].
See [LP16, Exercise 4.6].
Let e = {x, y}. To get some insight into Kirchhoff ’s resistance formula, we first note that,
if i is the unit current from x to y and v is the associated voltage, by definition of the effective
resistance
R(x ↔ y) =
v(x)
kik
= c(e)(v(x) − v( y)) = i(x, y), (3.3.35)
where we used Ohm’s law (i.e., (3.3.20)) as well as the fact that c(e) = 1, v( y) = 0, and
kik = 1. Note that kik and i(x, y) are not the same quantity: although kik = 1, i(x, y) is
only the current along the edge to y. Furthermore, by the probabilistic interpretation of the
current (Theorem 3.3.17), with Z = { y},
i(x, y) = Ex[N
Z
x→y − N
Z
y→x
] = Px

(x, y) is traversed before τy

. (3.3.36)
Indeed, started at x, N
Z
y→x = 0 and N
Z
x→y ∈ {0, 1}. Kirchhoff ’s resistance formula is then
established by relating the random walk on N to the probability that e is present in a uniform
spanning tree T. To do this we introduce a random-walk-based algorithm for generating
uniform spanning trees. This rather miraculous procedure, known as Wilson’s method, is of
independent interest. (For a classical connection between random walks and spanning trees,
see also Exercise 3.23.)
Wilson’s method It will be somewhat easier to work in a more general context. Let N =
(G, c) be a finite, connected network on G with arbitrary conductances and define the weight
of a spanning tree T on N as
W(T) =
Y
e∈T
c(e).
With a slight abuse, we continue to call a tree T picked at random among all spanning trees
of G with probability proportional to W(T) a “uniform” spanning tree on N .
LOOP To state Wilson’s method, we need the notion of loop erasure. Let P = x0 ∼ · · · ∼ xk
ERASURE be a walk in N . The loop erasure of P is obtained by removing cycles in the order they
appear. That is, let j
∗ be the smallest j such that xj = x` for some ` < j. Remove the subwalk
x`+1 ∼ · · · ∼ xj from P, and repeat. The result is self-avoiding, that is, a path, and is denoted
by LE(P).
Let v0 be an arbitrary vertex of G, which we refer to as the root, and let T0 be the subtree
made up of v0 alone. Starting with the root, order arbitrarily the vertices of G as v0, . . . , vn−1.
Wilson’s method constructs an increasing sequence of subtrees as follows. See Figure 3.6.
Let T := T0.
1. Let v be the vertex of G not in T with lowest index. Perform random walk on N started
at v until the first visit to a vertex of T. Let P be the resulting walk.
2. Add the loop erasure LE(P) to T.
3. Repeat until all vertices of G are in T.
Let T0, . . . , Tm be the sequence of subtrees produced by Wilson’s method.
Claim 3.3.44 Forgetting the root, Tm is a uniform spanning tree on N .
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.3 Potential Theory and Electrical Networks 173
Figure 3.6 An illustration of Wilson’s method. The dashed lines indicate erased
loops.
This claim is far from obvious. Before proving it, we finish the proof of Kirchhoff ’s re￾sistance formula.
Proof of Theorem 3.3.42 From (3.3.35) and (3.3.36), it suffices to prove that, for e = {x, y},
Px

(x, y) is traversed before τy

= P[e ∈ T],
where the probability on the left-hand side refers to random walk on N with unit resistances
started at x and the probability on the right-hand side refers to a uniform spanning tree T on
N . Generate T using Wilson’s method started at root v0 = y with the choice v1 = x. If the
walk from x to y during the first iteration of Wilson’s method includes (x, y), then the loop
erasure is simply x ∼ y and e is in T. On the other hand, if the walk from x to y does not
include (x, y), then e cannot be used at a later stage because it would create a cycle. That
immediately proves the theorem.
It remains to prove the claim.
Proof of Claim 3.3.44 The idea of the proof is to cast Wilson’s method in the more general
framework of cycle popping algorithms. We begin by explaining how such algorithms work.
Let P be the transition matrix corresponding to random walk on N = (G, c) with G =
(V, E) and root v0. To each vertex x 6= v0 in V, we assign an independent stack of “colored
directed edges”
S
x
0
:= (hx, Y
x
1
i1,hx, Y
x
2
i2, . . .),
where each Y
x
j
is chosen independently at random from the distribution P(x, · ). In particular,
all Y
x
j
s are neighbors of x in N . The index j in hx, Y
x
j
ij
is the color of the edge. It keeps track COLOR
of the position of the edge in the original stack. (Picture S
x
as a spring-loaded plate dispenser
located on vertex x.)
We consider a process which involves popping edges off the stacks. We use the notation
S
x
to denote the current stack at x. The initial assignment of the stack is S
x
:= S
x
0
as above.
Given the current stacks (S
x
)x
, we call visible graph the (colored) directed graph over V with VISIBLE
edges Top(S
x
) for all x 6= v GRAPH 0, where Top(S
x
) is the first edge in the current stack S
x
. The
latter are referred to as visible edges. We denote the current visible graph by
−→
G . VISIBLE EDGE
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press174 Martingales and Potentials
Note that
−→
G  has out-degree 1 for all x 6= v0 and the root has out-degree 0. In particular,
all undirected cycles in
−→
G  are in fact directed cycles, and we refer to them simply as
cycles. (Indeed, a set of edges forming an undirected cycle that is not directed must have a
vertex of out-degree 2.) Also recall the following characterization from Corollary 1.1.8: an
acyclic, undirected subgraph with |V| vertices and |V| − 1 edges is a spanning tree of G.
Hence, if there is no cycle in
−→
G , then it must be a spanning tree (as an undirected graph)
SPANNING AR- where, furthermore, all edges point toward the root. Such a tree is also known as a spanning
BORESCENCE arborescence. Once that happens, we are done.
As the name suggests, a cycle popping algorithm proceeds by popping cycles in
−→
G  off
the tops of the stacks until a spanning arborescence is produced. That is, at every iteration,
if
−→
G  contains at least one cycle, then a cycle
−→
C is picked according to some rule, the top
of each stack in
−→
C is popped, and a new visible graph
−→
G  is revealed. See Figure 3.7 for
an illustration.
With these definitions in place, the proof of the claim involves the following steps.
(i) Wilson’s method is a cycle popping algorithm. Recasting Wilson’s method, we
can think of the initial stacks (S
x
0
) as corresponding to picking – ahead of time –
all potential transitions in the random walks. With this representation, the algo￾rithm boils down to a recipe for choosing which cycle to pop next. Indeed, at each
iteration, we start from a vertex v not in the current tree T. A key observation: fol￾lowing the visible edges from v traces a path whose distribution is that of random
walk on N . Loop erasure then corresponds to popping cycles as they are closed.
We pop only those visible edges on the removed cycles, as they originate from
vertices that will be visited again by the algorithm and for which a new transition
will then be needed. Those visible edges in the resulting loop-erased path are not
popped – note that they are part of the final arborescence.
(ii) The popping order does not matter. We just argued that Wilson’s method is a cy￾cle popping algorithm. In fact, we claim that any cycle popping algorithm, that
is, no matter what popping choices are made along the way, produces the same
final arborescence. To make this precise, we identify the popped cycles uniquely.
COLORED This is where the colors come in. A colored cycle is a directed cycle over V
CYCLE made of colored edges from the stacks (not necessarily of the same color and not
necessarily in the current visible graph). We say that a colored cycle
−→
POPPABLE C is pop￾CYCLE pable for a visible graph
−→
G  if there exists a sequence of colored cycles
−→
C 1, . . . ,
−→
C r =
−→
C that can be popped in that order starting from
−→
G . Note that, by this
definition,
−→
C 1 is a cycle in
−→
G . Now we claim that if
−→
C
0
1 were popped first
instead of
−→
C 1, producing the new visible graph
−→
G
0

, then
−→
C would still be pop￾pable for
−→
G
0

. This claim implies that, in any cycle popping algorithm, either an
infinite number of cycles are popped or eventually all poppable cycles are popped
– independently of the order – producing the same outcome. (Note that, while the
same cycle may be popped more than once, the same colored cycle cannot.)
To prove the claim, note first that if
−→
C
0
1 =
−→
C or if
−→
C
0
1
does not share a vertex
with any of
−→
C 1, . . . ,
−→
C r
, there is nothing to prove. So let
−→
C j be the first cycle
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press3.3 Potential Theory and Electrical Networks 175
Figure 3.7 A realization of a cycle popping algorithm (from top to bottom). In all
three figures, the underlying graph is G while the arrows depict the visible edges.
in the sequence sharing a vertex with
−→
C
0
1
, say x. Let hx, yic and hx, y
0
ic
0 be the
colored edges emanating from x in
−→
C j and
−→
C
0
1
, respectively. By definition, x is
not on any of
−→
C 1, . . . ,
−→
C j−1 so the edge originating from x is not popped by
that sequence and we must have hx, yic = hx, y
0
ic
0 as colored edges. In particu￾lar, the vertex y is also a shared vertex of
−→
C j and
−→
C
0
1
, and the same argument
applies to it. Proceeding by induction leads to the conclusion that
−→
C
0
1 =
−→
C j as
colored cycles. But then
−→
C is clearly poppable for the visible graph resulting
from popping
−→
C
0
1 first, because it can be popped with the rearranged sequence
−→
C
0
1 =
−→
C j
,
−→
C 1, . . . ,
−→
C j−1,
−→
C j+1, . . . ,
−→
C r =
−→
C , where we used the fact that
−→
C
0
1
does not share a vertex with
−→
C 1, . . . ,
−→
C j−1.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press176 Martingales and Potentials
(iii) Termination occurs in finite time almost surely. We have shown so far that, in
any cycle popping algorithm, either an infinite number of cycles are popped or
eventually all poppable cycles are popped. But Wilson’s method – a cycle popping
algorithm as we have shown – stops after a finite amount of time with probability
1. Indeed, because the network is finite and connected, the random walk started at
each iteration hits the current T in finite time almost surely (by Lemma 3.1.25). To
sum up, all cycle popping algorithms terminate and produce the same spanning
arborescence. It remains to compute the distribution of the outcome.
(iv) The arborescence has the desired distribution. Let A be the spanning arbores￾cence produced by any cycle popping algorithm on the stacks (S
x
0
). To compute
the distribution of A, we first compute the distribution of a particular cycle pop￾ping realization leading to A. Because the popping order does not matter, by “re￾alization” we mean a collection C of colored cycles together with a final spanning
arborescence A. Notice that what lies in the stacks “under” A is not relevant to
the realization, that is, the same outcome is produced no matter what is under A.
So, from the distribution of the stacks, the probability of observing (C, A) is
simply the product of the transitions corresponding to the “popped edges” in C
and the “final edges” in A, that is,
Y
Ee∈C∪A
P(Ee) = 9(A)
Y
−→C ∈C
9
−→
C

,
where the function 9 returns the product of the transition probabilities of a set of
directed edges. Thanks to the product form on the right-hand side, summing over
all possible Cs gives that the probability of producing A is proportional to 9(A).
For this argument to work though, there are two small details to take care of.
First, note that we want the probability of the “uncolored” arborescence. But ob￾serve that, in fact, there is no need to keep track of the colors on the edges of A
because these are determined by C. Second, we need for the collection of possible
Cs not to vary with A. But it is clear that any arborescence could lie under any C.
To see that we are done, let T be the undirected spanning tree corresponding to the out￾come, A, of Wilson’s method. Then, because P(x, y) =
c(x,y)
c(x)
, we get
9(A) =
W(T)
Q
x6=v0
c(x)
,
where note that the denominator does not depend on T. So if we forget the orientation of A,
which is determined by the root (i.e., sum over all choices of root), we get a spanning tree
whose distribution is proportional to W(T), as required.
Exercises
Exercise 3.1 (Reflection). Give a rigorous proof of Theorem 3.1.9 through a formal appli￾cation of the strong Markov property (i.e., specify ft and Ft
in Theorem 3.1.8).
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University PressExercises 177
Exercise 3.2 (Time of kth return). Give a rigorous proof of (3.1.1) through a formal appli￾cation of the strong Markov property (i.e., specify ft and Ft
in Theorem 3.1.8).
Exercise 3.3 (Tightness of Matthews’ bounds). Show that the bounds (3.1.6) and (3.1.7)
are tight up to smaller order terms for the coupon collector problem (Example 2.1.4). (Hint:
State the problem in terms of the cover time of a random walk on the complete graph with
self-loops.)
Exercise 3.4 (Pólya’s urn: a suprisingly simple formula). Consider the setting of Exam￾ple 3.1.49. Prove that
P[Gt = m + 1] =

t
m

m!(t − m)!
(t + 1)!
.
(Hint: Consider the probability of one particular sequence of outcomes producing the desired
event.)
Exercise 3.5 (Optional stopping theorem). Give a rigorous proof of the remaining cases of
the optional stopping theorem (Theorem 3.1.38).
Exercise 3.6 (Supermartingale inequality). Let (Mt) be a non-negative, supermartingale.
Show that, for any b > 0,
P

sup
s≥0
Ms ≥ b

≤
E[M0]
b
.
(Hint: Mimic the proof of the submartingale case.)
Exercise 3.7 (Azuma–Hoeffding: a second proof). This exercise leads the reader through
an alternative proof of the Azuma–Hoeffding inequality.
(i) Show that for all x ∈ [−1, 1] and a > 0,
e
ax ≤ cosh a + x sinh a.
(ii) Use a Taylor expansion to show that for all x,
cosh x ≤ e
x
2
/2
.
(iii) Let X1, . . . , Xn be (not necessarily independent) random variables such that for all
i, |Xi
| ≤ ci for some constant ci < +∞ and
E

Xi1
· · · Xik

= 0 ∀ 1 ≤ k ≤ n, ∀ 1 ≤ i1 < · · · < ik ≤ n. (3.3.37)
Show, using (i) and (ii), that for all b > 0,
P
"Xn
i=1
Xi ≥ b
#
≤ exp
−
b
2
2
Pn
i=1
c
2
i

.
(iv) Prove that (iii) implies the Azuma–Hoeffding inequality as stated in Theorem 3.2.1.
(v) Show that the random variables in Exercise 2.6 do not satisfy (3.3.37) (without
using the claim in part (ii) of that exercise).
Exercise 3.8 (Lipschitz condition). Give a rigorous proof of Lemma 3.2.31.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press178 Martingales and Potentials
Exercise 3.9 (Lower bound on expected spectral norm). Let A be an n × n random matrix.
Assume that the entries Ai,j
, i, j = 1, . . . , n, are independent, centered random variables in
[−1, 1]. Suppose further that there is 0 < σ2 < +∞ such that Var[Aij] ≥ σ
2
for all i, j.
Show that there is 0 < c < +∞ such that
EkAk ≥ c
√
n
for n large enough. (Hint: Use the fact that kAk
2 ≥ kAe1k
2
together with Chebyshev’s ine￾quality.)
Exercise 3.10 (Kirchhoff ’s laws). Consider a finite, connected network with a source and a
sink. Show that an anti-symmetric function on the edges satisfying Kirchhoff ’s two laws is
a current function (i.e., it corresponds to a voltage function through Ohm’s law).
Exercise 3.11 (Dirichlet problem: non-uniqueness). Let (Xt) be the birth-and-death chain
on Z+ with P(x, x + 1) = p and P(x, x − 1) = 1 − p for all x ≥ 1, and P(0, 1) = 1, for some
0 < p < 1. Fix h(0) = 1.
(i) When p > 1/2, show that there is more than one bounded extension of h to Z+\{0}
that is harmonic on Z+\{0}. (Hint: Consider Px[τ0 = +∞].)
(ii) When p ≤ 1/2, show that there exists a unique bounded extension of h to Z+\{0}
that is harmonic on Z+\{0}.
Exercise 3.12 (Maximum principle). Let N = (G, c) be a finite or countable, connected
network with G = (V, E). Let W be a finite, connected, proper subset of V.
(i) Let h: V → R be a function on V. Prove the maximum principle: if h is harmonic
on W, that is, it satisfies
h(x) =
1
c(x)
X
y∼x
c(x, y)h( y) ∀x ∈ W,
and if h achieves its supremum on W, then h is constant on W ∪ ∂VW, where
∂VW = {z ∈ V \ W : ∃y ∈ W, y ∼ z}.
(ii) Let h: Wc → R be a bounded function on Wc
:= V \W. Let h1 and h2 be extensions
of h to W that are harmonic on W. Use part (i) to prove that h1 ≡ h2.
Exercise 3.13 (Poisson equation: uniqueness). Show that u is the unique solution of the
system in Theorem 3.3.6 under the conditions of Theorem 3.3.1. (Hint: Use Theorem 3.3.9
and mimic the proof of Theorem 3.3.1.)
Exercise 3.14 (Effective resistance: metric). Show that effective resistances between pairs
of vertices form a metric.
Exercise 3.15 (Dirichlet principle: proof). Prove Theorem 3.3.25.
Exercise 3.16 (Martingale problem). Let V be countable, let (Xt) be a stochastic process
adapted to (Ft) and taking values in V, and let P be a transition probability on V with
associated Laplacian operator 1. Show that the following are equivalent:
(i) The process (Xt) is a Markov chain with transition probability P.
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University PressExercises 179
(ii) For any bounded measurable function f : V → R, the process
M
f
t = f (Xt) −
Xt−1
s=0
1f (Xs)
is a martingale with respect to (Ft).
Exercise 3.17 (Random walk on L
2
: effective resistance). Consider random walk on L
2
,
which we showed is recurrent. Let (Gn) be the exhaustive sequence corresponding to vertices
at distance at most n from the origin and let Zn be the corresponding sink-set. Show that
R(0 ↔ Zn) = 2(log n). (Hint: Use the Nash–Williams inequality and the method of random
paths.)
Exercise 3.18 (Random walk on regular graphs: effective resistance). Let G be a d-regular
graph with n vertices and d > n/2. Let N be the network (G, c) with unit conductances. Let
a and z be arbitrary distinct vertices.
(i) Show that there are at least 2d − n vertices x 6= a,z such that a ∼ x ∼ z is a path.
(ii) Prove that
R(a ↔ z) ≤
2dn
2d − n
.
Exercise 3.19 (Independent-coordinate random walk). Give a rigorous proof that the two
networks in Example 3.3.32 are roughly equivalent.
Exercise 3.20 (Rough isometries). Graphs G = (V, E) and G
0 = (V
0
, E
0
) are roughly iso- ROUGH
metric (or quasi-isometric) if there is a map φ : V → V
0
and constants 0 < α, β < +∞ ISOMETRY
such that for all x, y ∈ V,
α
−1
d(x, y) − β ≤ d
0
(φ(x), φ( y)) ≤ αd(x, y) + β,
where d and d
0
are the graph distances on G and G
0
, respectively, and furthermore, all vertices
in G
0
are within distance β of the image of V. Let N = (G, c) and N 0 = (G
0
, c
0
) be countable,
connected networks with uniformly bounded conductances, resistances, and degrees. Prove
that if G and G
0
are roughly isometric, then N and N 0
are roughly equivalent. (Hint: Start
by proving that being roughly isometric is an equivalence relation.)
Exercise 3.21 (Random walk on the cycle: hitting time). Use the commute time identity
(Theorem 3.3.34) to compute Ex[τy] in Example 3.3.35 in the case d = 1. Give a second
proof using a direct martingale argument.
Exercise 3.22 (Random walk on the binary tree: cover time). As in Example 3.3.15, let N
be the rooted binary tree with n levels bT
n
2
and equal conductances on all edges.
(i) Show that the maximal hitting time Eaτb is achieved for a and b such that their
most recent common ancestor is the root 0. Furthermore, argue that in that case
Ea[τb] = Ea[τa,0], where recall that τa,0 is the commute time between a and 0.
(ii) Use the commute time identity (Theorem 3.3.34) and Matthews’ cover time bounds
(Theorem 3.1.27) to give an upper bound on the mean cover time of the order of
O(n
22
n
).
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press180 Martingales and Potentials
Exercise 3.23 (Markov chain tree theorem). Let P be the transition matrix of a finite, ir￾reducible Markov chain with stationary distribution π. Let G be the directed graph corre￾sponding to the positive transitions of P. For an arborescence A of G, define its weight as
9(A) =
Y
Ee∈A
P(Ee).
Consider the following process on spanning arborescences over G. Let ρ be the root of
the current spanning arborescence A. Pick an outgoing edge Ee = (ρ, x) of ρ according to
P(ρ, · ). Edge Ee is not in A by definition of an arborescence. Add Ee to A. This creates a
cycle. Remove the edge of this cycle originating from x, producing a new arborescence A0
with root x. Repeat the process.
(i) Show that this chain is irreducible.
(ii) Show that 9 is a stationary measure for this chain.
(iii) Prove the Markov chain tree theorem: the stationary distribution π of P is propor￾tional to
πx =
X
A : root(A)=x
9(A).
Bibliographic Remarks
Section 3.1 Picking up where Appendix B leaves off, Sections 3.1.1 and 3.1.3 largely fol￾low the textbooks [Wil91] and [Dur10], which contain excellent introductions to martin￾gales. The latter also covers Markov chains, and includes the proofs we skipped here. The￾orem 3.1.11 is proved in [Dur10, Theorem 4.3.2]. Many more results like Corollary 3.1.24
can be derived from the occupation measure identity; see, for example, [AF, chapter 2]. The
upper bound in Theorem 3.1.27 was first proved by Matthews [Mat88].
Section 3.2 The Azuma–Hoeffding inequality is due to Hoeffding [Hoe63] and Azuma
[Azu67]. The version of the inequality in Exercise 3.7 is from [Ste97]. The method of
bounded differences has its origins in the works of Yurinskii [Yur76], Maurey [Mau79], Mil￾man and Schechtman [MS86], Rhee and Talagrand [RT87], and Shamir and Spencer [SS87].
In its current form, it appears in [McD89]. Example 3.2.11 is taken from [MU05, section
12.5]. The presentation in Section 3.2.3 follows [AS11, section 7.3]. Claim 3.2.16 is due to
Shamir and Spencer [SS87]. The 2-point concentration result alluded to in Section 3.2.3 is
due to Alon and Krivelevich [AK97]. For the full story on the chromatic number of Erdos– ˝
Rényi graphs, see [JLR11, chapter 7]. Claim 3.2.21 is due to Bollobás, Riordan, Spencer,
and Tusnády [BRST01]. It confirmed simulations of Barabási and Albert [BA99]. The ex￾pectation was analyzed by Dorogovtsev, Mendes, and Samukhin [DMS00]. For much more
on preferential attachment models, see [Dur06], [CL06], or [vdH17]. Example 3.2.12 bor￾rows from [BLM13, section 7.1] and [Pet, section 6.3]. General references on the concen￾tration of measure phenomenon and concentration inequalities are [Led01] and [BLM13].
See [BCB12] or [LS20] for an introduction to bandit problems; or [AJKS22] for an in￾troduction to the sample complexity of the more general reinforcement learning problem.
The slicing argument in Section 3.2.5 is based on [Bub10]. A more general discussion of the
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University PressBibliographic Remarks 181
slicing method, whose best known application is the proof of the law of the iterated logarithm
(e.g., [Wil91, section 14.7]), can be found in [vH16]. Section 3.2.6 is based on [vH16, sec￾tion 4.3]. In particular, a proof of Talagrand’s inequality (Theorem 3.2.32) can be found
there. See also [AS11, chapter 7] or [BLM13, chapter 7].
Section 3.3 Section 3.3.1 is based partly on [Nor98, sections 4.1–2], [Ebe, sections 0.3,
1.1-2, 3.1-2], and [Bre17, sections 7.3, 17.1]. The material in Sections 3.3.2–3.3.5 borrows
from [LPW06, chapters 9, 10], [AF, chapters 2, 3], and, especially, [LP16, sections 2.1–2.6,
4.1–4.2, 5.5]. Foster’s theorem (Theorem 3.3.12) is from [Fos53]. The classical reference
on potential theory and its probabilistic counterpart is [Doo01]. For the discrete case and
the electrical network point of view, the book of Doyle and Snell is excellent [DS84]. In
particular, the series and parallel laws are defined and illustrated. See also [KSK76]. For
an introduction to convex optimization and duality, see, for example, [BV04]. The Nash–
Williams inequality is due to Nash–Williams [NW59]. The result in Example 3.3.27 is due to
R. Lyons [Lyo90]. Theorem 3.3.33 is due to Kanai [Kan86]. The commute time identity was
proved by Chandra, Raghavan, Ruzzo, Smolensky, and Tiwari [CRR+89]. An elementary
proof of Pólya’s theorem can be found in [Dur10, section 4.2]. The flow we used in the
proof of Pólya’s theorem is essentially due to T. Lyons [Lyo83]. Wilson’s method is due to
Wilson [Wil96]. A related method for generating uniform spanning trees was introduced
by Aldous [Ald90] and Broder [Bro89]. A connection between loop-erased random walks
and uniform spanning trees had previously been established by Pemantle [Pem91] using the
Aldous–Broder method. For more on negative correlation in uniform spanning trees, see, for
example, [LP16, section 4.2]. For a proof of the matrix tree theorem using Wilson’s method,
see [KRS]. For a discussion of the running time of Wilson’s method and other spanning tree
generation approaches, see [Wil96].
https://doi.org/10.1017/9781009305129.004 Published online by Cambridge University Press4
Coupling
In this chapter we move on to coupling, another probabilistic technique with a wide range
of applications (far beyond discrete stochastic processes). The idea behind the coupling
method is deceptively simple: to compare two probability measures µ and ν, it is some￾times useful to construct a joint probability space with marginals µ and ν. For instance, in
the classical application of coupling to the convergence of Markov chains (Theorem 1.1.33),
one simultaneously constructs two copies of a Markov chain – one of which is already at
stationarity – and shows that they can be made to coincide after a random amount of time,
called the coupling time. We begin in Section 4.1 by defining coupling formally and deriving
its connection to the total variation distance through the coupling inequality. We illustrate
the basic idea on a classical Poisson approximation result, which we apply to the degree
sequence of an Erdos–Rényi graph. In Section ˝ 4.2, we introduce the concept of stochastic
domination and some related correlation inequalities. We develop a key application in per￾colation theory. Coupling of Markov chains is the subject of Section 4.3, where it serves
as a powerful tool to derive mixing time bounds. Finally, we end in Section 4.4 with the
Chen–Stein method for Poisson approximations, a technique that applies in particular in
some natural settings with dependent variables.
4.1 Background
We begin with some background on coupling. After defining the concept formally and giving
a few simple examples, we derive the coupling inequality, which provides a fundamental
approach to bounding the distance between two distributions. As an application, we analyze
the degree distribution in the Erdos–Rényi graph model. Throughout this chapter, ( ˝ S, S) is a
measurable space. Also we will denote by µZ the law of random variable Z.
4.1.1 Basic Definitions
A formal definition of coupling follows. Recall (see Appendix B) that for measurable spaces
(S1, S1) (S2, S2), we can consider the product space (S1 × S2, S1 × S2) where
S1 × S2 := {(s1,s2): s1 ∈ S1,s2 ∈ S2}
is the Cartesian product of S1 and S2, and S1 × S2 is the smallest σ-algebra on S1 × S2
containing the rectangles A1 × A2 for all A1 ∈ S1 and A2 ∈ S2.
182
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.1 Background 183
Definition 4.1.1 (Coupling). Let µ and ν be probability measures on the same measura￾ble space (S, S). A coupling of µ and ν is a probability measure γ on the product space COUPLING
(S × S, S × S) such that the marginals of γ coincide with µ and ν, that is,
γ (A × S) = µ(A) and γ (S × A) = ν(A) ∀A ∈ S.
For two random variables X and Y taking values in (S, S), a coupling of X and Y is a joint
variable (X
0
, Y
0
) taking values in (S × S, S × S) whose law as a probability measure is
a coupling of the laws of X and Y. Note that, under this definition, X and Y need not be
defined on the same probability space (but X0 and Y0 do need to). We also say that (X
0
, Y
0
)
is a coupling of µ and ν if the law of (X
0
, Y
0
) is a coupling of µ and ν.
We give a few examples.
Example 4.1.2 (Coupling of Bernoulli variables). Let X and Y be Bernoulli random vari￾ables with parameters 0 ≤ q < r ≤ 1, respectively. That is, P[X = 1] = q and P[Y = 1] =
r. Here S = {0, 1} and S = 2
S
.
• (Independent coupling) One coupling of X and Y is (X
0
, Y
0
), where X
0
d= X and Y
0
d= Y
are independent of one another. Its law is

P[(X
0
, Y
0
) = (i, j)]
i, j∈{0,1}
=

(1 − q)(1 − r) (1 − q)r
q(1 − r) qr 
.
• (Monotone coupling) Another possibility is to pick U uniformly at random in [0, 1], and
set X
00 = 1{U≤q} and Y
00 = 1{U≤r}
. Then, (X
00
, Y
00) is a coupling of X and Y with law

P[(X
00
, Y
00) = (i, j)]
i, j∈{0,1}
=

1 − r r − q
0 q

.
J
Example 4.1.3 (Bond percolation: monotonicity). Let G = (V, E) be a countable graph.
Denote by Pp the law of bond percolation (Definition 1.2.1) on G with density p. Let x ∈ V
and assume 0 ≤ q < r ≤ 1. Using the monotone coupling in the previous example on each
edge independently produces a coupling of Pq and Pr
. More precisely:
• Let {Ue}e∈E be independent uniforms on [0, 1].
• For p ∈ [0, 1], let Wp be the set of edges e such that Ue ≤ p.
Thinking of Wp as specifying the open edges in the percolation process on G under Pp, we
see that (Wq, Wr) is a coupling of Pq and Pr with the property that P[Wq ⊆ Wr] = 1. Let C
(q)
x
and C
(r)
x
be the open clusters of x under Wq and Wr
, respectively. Because C
(q)
x ⊆ C
(r)
x
,
θ(q) := Pq[|Cx
| = +∞]
= P[|C
(q)
x
| = +∞]
≤ P[|C
(r)
x
| = +∞]
= Pr[|Cx
| = +∞]
= θ(r).
(We made this claim in Section 2.2.4.) J
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press184 Coupling
Example 4.1.4 (Biased random walk on Z). For p ∈ [0, 1], let (S
( p)
t
) be nearest-neighbor
random walk on Z started at 0 with probability p of jumping to the right and probability
1 − p of jumping to the left. (See the gambler’s ruin problem in Example 3.1.43.) Assume
0 ≤ q < r ≤ 1. Using again the monotone coupling of Bernoulli variables in Example 4.1.2
we produce a coupling of S
(q)
and S
(r)
.
• Let (X
00
i
, Y
00
i
)i be an infinite sequence of i.i.d. monotone Bernoulli couplings with parame￾ters q and r, respectively.
• Define (Z
(q)
i
, Z
(r)
i
) := (2X
00
i − 1, 2Y
00
i − 1). Note that P[2X
00
1 − 1 = 1] = P[X
00
1 = 1] = q
and P[2X
00
1 − 1 = −1] = P[X
00
1 = 0] = 1 − q, and similarly for Y
00
i
.
• Let Sˆ
(q)
t =
P
i≤t
Z
(q)
i
and Sˆ
(r)
t =
P
i≤t
Z
(r)
i
.
Then (Sˆ
(q)
t
, Sˆ
(r)
t
) is a coupling of (S
(q)
t
, S
(r)
t
) such that Sˆ
(q)
t ≤ Sˆ
(r)
t
for all t almost surely. In
particular, we deduce that for all y and all t,
P[S
(q)
t ≤ y] = P[Sˆ
(q)
t ≤ y] ≥ P[Sˆ
(r)
t ≤ y] = P[S
(r)
t ≤ y]. J
4.1.2 F Random Walks: Harmonic Functions on Lattices and Infinite d-Regular
Trees
Let (Xt) be a Markov chain on a finite or countably infinite state space V with transition
matrix P and let Px be the law of (Xt) started at x. We say that a function h: V → R is
bounded if supx∈V
|h(x)| < +∞. Recall from Section 3.3 that h is harmonic (with respect to
P) on V if
h(x) =
X
y∈V
P(x, y)h( y) ∀x ∈ V.
We first give a coupling-based criterion for bounded harmonic functions to be constant.
Recall that we treated the finite state-space case (where boundedness is automatic) in Corol￾lary 3.3.3.
Lemma 4.1.5 (Coupling and bounded harmonic functions). If, for all y,z ∈ V, there is a
coupling ((Yt)t
, (Zt)t) of Py and Pz such that
lim
t
P[Yt 6= Zt] = 0,
then all bounded harmonic functions on V are constant.
Proof Let h be bounded and harmonic on V with supx
|h(x)| = M < +∞. Let y,z be any
points in V. Then, arguing as in Section 3.3.1, (h(Yt)) and (h(Zt)) are martingales and, in
particular,
E[h(Yt)] = E[h(Y0)] = h( y) and E[h(Zt)] = E[h(Z0)] = h(z).
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.1 Background 185
So by Jensen’s inequality (Theorem B.4.15) and the boundedness assumption,
|h( y) − h(z)| = |E[h(Yt)] − E[h(Zt)]|
≤ E |h(Yt) − h(Zt)|
≤ 2M P[Yt 6= Zt]
→ 0.
So h( y) = h(z).
Harmonic functions on Z
d Consider random walk on L
d
for d ≥ 1. In that case, we show
that all bounded harmonic functions are constant.
Theorem 4.1.6 (Bounded harmonic functions on Z
d
). All bounded harmonic functions on
L
d are constant.
Proof From (3.3.2), h is harmonic with respect to random walk on L
d
if and only if it is
harmonic with respect to lazy random walk (Definition 1.1.31), that is, the walk that stays
put with probability 1/2 at every step. Let Py and Pz be the laws of lazy random walk on L
d
started at y and z, respectively. We construct a coupling ((Yt), (Zt)) = ((Y
(i)
t
)i∈[d]
, (Z
(i)
t
)i∈[d]) of
Py and Pz as follows: at time t, pick a coordinate I ∈ [d] uniformly at random, then
• if Y
(I)
t = Z
(I)
t
then do nothing with probability 1/2, otherwise pick W ∈ {−1, +1} uni￾formly at random, set Y
(I)
t+1 = Z
(I)
t+1
:= Z
(I)
t +W, and leave the other coordinates unchanged;
• if instead Y
(I)
t 6= Z
(I)
t
, pick W ∈ {−1, +1} uniformly at random, and with probability 1/2
set Y
(I)
t+1
:= Y
(I)
t + W and leave Zt and the other coordinates of Yt unchanged, or otherwise
set Z
(I)
t+1
:= Z
(I)
t + W and leave Yt and the other coordinates of Zt unchanged.
It is straightforward to check that ((Yt), (Zt)) is indeed a coupling of Py and Pz
. To apply the
previous lemma, it remains to bound P[Yt 6= Zt].
The key is to note that, for each coordinate i, the difference (Y
(i)
t − Z
(i)
t
) is itself a nearest￾neighbor random walk on Z started at y
(i) − z
(i) with holding probability (i.e., probability of
staying put) 1 −
1
d
– until it hits 0. Simple random walk on Z is irreducible and recurrent
(Theorem 3.3.38). The holding probability does not affect the type of the walk. So (Y
(i)
t −Z
(i)
t
)
hits 0 in finite time with probability 1. Hence, letting τ
(i) be the first time Y
(i)
t − Z
(i)
t = 0, we
have P[Y
(i)
t 6= Z
(i)
t
] ≤ P[τ
(i) > t] → P[τ
(i) = +∞] = 0.
By a union bound,
P[Yt 6= Zt] ≤
X
i∈[d]
P[Y
(i)
t 6= Z
(i)
t
] → 0,
as desired.
Exercise 4.1 asks for an example of a non-constant (necessarily unbounded) harmonic
function on Z
d
.
Harmonic functions on Td On trees, the situation is different. Let Td be the infinite d￾regular tree with root ρ. For x ∈ Td, we let Tx be the subtree, rooted at x, of descendants
of x.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press186 Coupling
Theorem 4.1.7 (Bounded harmonic functions on Td). For d ≥ 3, let (Xt) be simple random
walk on Td and let P be the corresponding transition matrix. Let a be a neighbor of the root
and consider the function
h(x) := Px[Xt ∈ Ta for all but finitely many t].
Then, h is a non-constant, bounded harmonic function on Td.
Proof The function h is bounded since it is defined as a probability, and by the usual first￾step analysis,
h(x) =
X
y:y∼x
1
d
Py[Xt ∈ Ta for all but finitely many t] =
X
y
P(x, y)h( y),
so h is harmonic on all of Td.
Let b 6= a be a neighbor of the root. The key of the proof is the following lemma.
Lemma 4.1.8
q := Pa[τρ = +∞] = Pb[τρ = +∞] > 0.
Proof The equality of the two probabilities follows by symmetry. To see that q > 0, let
(Zt) be simple random walk on Td started at a until the walk hits ρ and let Lt be the graph
distance between Zt and the root. Then (Lt) is a biased random walk on Z started at 1 jumping
to the right with probability 1−
1
d
and jumping to the left with probability 1
d
. The probability
that (Lt) hits 0 in finite time is < 1 because 1 −
1
d >
1
2 when d ≥ 3 by the gambler’s ruin
(Example 3.1.43).
Note that
h(ρ) ≤

1 −
1
d

(1 − q) < 1.
Indeed, if on the first step the random walk started at ρ moves away from a, an event of
probability 1 −
1
d
, then it must come back to ρ in finite time to reach Ta. Similarly, by the
strong Markov property (Theorem 3.1.8),
h(a) = q + (1 − q)h(ρ).
Since h(ρ) 6= 1 and q > 0, this shows that h(a) > h(ρ). So h is not constant.
4.1.3 Total Variation Distance and Coupling Inequality
In the examples of Section 4.1.1, we used coupling to prove monotonicity statements. Cou￾pling is also useful to bound the distance between probability measures. For this, we need
the coupling inequality.
Total variation distance Let µ and ν be probability measures on (S, S). Recall the defini￾tion of the total variation distance
kµ − νkTV := sup
A∈S
|µ(A) − ν(A)|.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.1 Background 187
As the next lemma shows in the countable case, the total variation distance can be thought
of as an `
1 distance on probability measures as vectors (up to a constant factor).
Lemma 4.1.9 (Alternative definition of total variation distance). If S is countable, then it
holds that
kµ − νkTV =
1
2
X
x∈S
|µ(x) − ν(x)|.
Proof Let E∗ := {x : µ(x) ≥ ν(x)}. Then, for any A ⊆ S, by definition of E∗,
µ(A) − ν(A) ≤ µ(A ∩ E∗) − ν(A ∩ E∗) ≤ µ(E∗) − ν(E∗).
Similarly, we have
ν(A) − µ(A) ≤ ν(E
c
∗
) − µ(E
c
∗
)
= (1 − ν(E∗)) − (1 − µ(E∗))
= µ(E∗) − ν(E∗).
The two bounds above are equal so |µ(A) − ν(A)| ≤ µ(E∗) − ν(E∗). Equality is achieved
when A = E∗. Also,
µ(E∗) − ν(E∗) =
1
2

µ(E∗) − ν(E∗) + ν(E
c
∗
) − µ(E
c
∗
)

=
1
2
X
x∈S
|µ(x) − ν(x)|.
That concludes the proof.
Like the `
1 distance, the total variation distance is a metric. In particular, it satisfies the
triangle inequality.
Lemma 4.1.10 (Total variation distance: triangle inequality). Let µ, ν, η be probability mea￾sures on (S, S). Then,
kµ − νkTV ≤ kµ − ηkTV + kη − νkTV.
Proof From the definition,
sup
A∈S
|µ(A) − ν(A)| ≤ sup
A∈S
{|µ(A) − η(A)| + |η(A) − ν(A)|}
≤ sup
A∈S
|µ(A) − η(A)| + sup
A∈S
|η(A) − ν(A)|.
Coupling inequality We come to an elementary, yet fundamental inequality.
Lemma 4.1.11 (Coupling inequality). Let µ and ν be probability measures on (S, S). For
any coupling (X, Y) of µ and ν,
kµ − νkTV ≤ P[X 6= Y].
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press188 Coupling
Proof For any A ∈ S,
µ(A) − ν(A) = P[X ∈ A] − P[Y ∈ A]
= P[X ∈ A, X = Y] + P[X ∈ A, X 6= Y]
− P[Y ∈ A, X = Y] − P[Y ∈ A, X 6= Y]
= P[X ∈ A, X 6= Y] − P[Y ∈ A, X 6= Y]
≤ P[X 6= Y],
and, similarly, ν(A) − µ(A) ≤ P[X 6= Y]. Hence,
|µ(A) − ν(A)| ≤ P[X 6= Y].
Taking a supremum over A gives the claim.
Here is a quick example.
Example 4.1.12 (A coupling of Poisson random variables). Let X ∼ Poi(λ) and Y ∼ Poi(ν)
with λ > ν. Recall that a sum of independent Poisson is Poisson (see Exercise 6.7). This fact
leads to a natural coupling: let Yˆ ∼ Poi(ν), Zˆ ∼ Poi(λ − ν) independently of Yˆ , and Xˆ =
Yˆ +Zˆ. Then, (Xˆ , Yˆ ) is a coupling of X and Y, and by the coupling inequality (Lemma 4.1.11),
kµX − µY kTV ≤ P[Xˆ 6= Yˆ ] = P[Zˆ > 0] = 1 − e
−(λ−ν) ≤ λ − ν,
where we used 1 − e
−x ≤ x for all x (see Exercise 1.16). J
Remarkably, the inequality in Lemma 4.1.11 is tight. For simplicity, we prove this in the
finite case only.
Lemma 4.1.13 (Maximal coupling). Assume S is finite and let S = 2
S
. Let µ and ν be
probability measures on (S, S). Then,
kµ − νkTV = inf{P[X 6= Y]: coupling (X, Y) of µ and ν}.
Proof We construct a coupling which achieves equality in the coupling inequality. Such a
coupling is called a maximal coupling.
MAXIMAL Let A = {x ∈ S : µ(x) > ν(x)}, B = {x ∈ S : µ(x) ≤ ν(x)}, and
COUPLING
p :=
X
x∈S
µ(x) ∧ ν(x), α :=
X
x∈A
[µ(x) − ν(x)], β :=
X
x∈B
[ν(x) − µ(x)].
Assume p > 0. First, two lemmas. See Figure 4.1 for a proof by picture.
Lemma 4.1.14
X
x∈S
µ(x) ∧ ν(x) = 1 − kµ − νkTV.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.1 Background 189
Figure 4.1 Proof by picture that: 1 − p = α = β = kµ − νkTV.
Proof We have
2kµ − νkTV =
X
x∈S
|µ(x) − ν(x)|
=
X
x∈A
[µ(x) − ν(x)] +
X
x∈B
[ν(x) − µ(x)]
=
X
x∈A
µ(x) +
X
x∈B
ν(x) −
X
x∈S
µ(x) ∧ ν(x)
= 2 −
X
x∈B
µ(x) −
X
x∈A
ν(x) −
X
x∈S
µ(x) ∧ ν(x)
= 2 − 2
X
x∈S
µ(x) ∧ ν(x),
where we used that both µ and ν sum to 1. Rearranging gives the claim.
Lemma 4.1.15
X
x∈A
[µ(x) − ν(x)] =
X
x∈B
[ν(x) − µ(x)] = kµ − νkTV = 1 − p.
Proof The first equality is immediate by the fact that µ and ν are probability measures.
The second equality follows from the first one together with the second line in the proof of
the previous lemma. The last equality is a restatement of the last lemma.
The maximal coupling is defined as follows:
• With probability p, pick X = Y from γmin, where
γmin(x) :=
1
p
µ(x) ∧ ν(x), x ∈ S.
• Otherwise, pick X from γA, where
γA(x) :=
µ(x) − ν(x)
1 − p
, x ∈ A,
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press190 Coupling
and, independently, pick Y from
γB(x) :=
ν(x) − µ(x)
1 − p
, x ∈ B.
Note that X 6= Y in that case because A and B are disjoint.
The marginal law of X is: for x ∈ A,
p γmin(x) + (1 − p) γA(x) = ν(x) + µ(x) − ν(x) = µ(x),
and for x ∈ B,
p γmin(x) + (1 − p) γA(x) = µ(x).
A similar calculation holds for Y. Finally, P[X 6= Y] = 1 − p = kµ − νkTV.
Remark 4.1.16 A proof of this result for general Polish spaces can be found in [dH, section
2.5].
We return to our coupling of Bernoulli variables.
Example 4.1.17 (Coupling of Bernoulli variables (continued)). Recall the setting of Exam￾ple 4.1.2. To construct the maximal coupling as in Lemma 4.1.13, we note that
A := {0}, B := {1},
p :=
X
x
µ(x) ∧ ν(x) = (1 − r) + q, 1 − p = α = β := r − q,
(γmin(x))x=0,1 =

1 − r
(1 − r) + q
,
q
(1 − r) + q

,
γA(0) := 1, γB(1) := 1.
The law of the maximal coupling (X
000
, Y
000) is given by

P[(X
000
, Y
000) = (i, j)]
i, j∈{0,1}
=

p γmin(0) (1 − p) γA(0)γB(1)
0 p γmin(1) 
=

1 − r r − q
0 q

.
Notice that it happens to coincide with the monotone coupling. J
Poisson approximation Here is a classical application of coupling: the approximation of
a sum of independent Bernoulli variables with a Poisson. It gives a quantitative bound in
total variation distance. Let X1, . . . , Xn be independent Bernoulli random variables with pa￾rameters p1, . . . , pn, respectively. We are interested in the case where the pis are “small.”
Let Sn :=
P
i≤n Xi
. We approximate Sn with a Poisson random variable Zn as follows: let
W1, . . . , Wn be independent Poisson random variables with means λ1, . . . , λn, respectively,
and define Zn :=
P
i≤n Wi
. We choose λi = − log(1 − pi) for reasons that will become clear
below. Note that Zn ∼ Poi(λ), where λ =
P
i≤n
λi
.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.1 Background 191
Theorem 4.1.18 (Poisson approximation).
kµSn − Poi(λ)kTV ≤
1
2
X
i≤n
λ
2
i
.
Proof We couple the pairs (Xi
, Wi) independently for i ≤ n. Let
W0
i ∼ Poi(λi) and X
0
i = W0
i ∧ 1.
Because of our choice λi = − log(1 − pi), which implies
1 − pi = P[Xi = 0] = P[Wi = 0] = e
−λi
,
(X
0
i
, W0
i
) is indeed a coupling of (Xi
, Wi). Let S
0
n
:=
P
i≤n X
0
i
and Z
0
n
:=
P
i≤n W0
i
. Then
(S
0
n
, Z
0
n
) is a coupling of (Sn, Zn). By the coupling inequality
kµSn − µZn
kTV ≤ P[S
0
n
6= Z
0
n
]
≤
X
i≤n
P[X
0
i
6= W0
i
]
=
X
i≤n
P[W0
i ≥ 2]
=
X
i≤n
X
j≥2
e
−λi
λ
j
i
j!
≤
X
i≤n
λ
2
i
2
X
`≥0
e
−λi
λ
`
i
`!
=
X
i≤n
λ
2
i
2
.
Mappings reduce total variation distance The following lemma will be useful.
Lemma 4.1.19 (Mappings). Let X and Y be random variables taking values in (S, S), let
h be a measurable map from (S, S) to (S
0
, S
0
), and let X0
:= h(X) and Y0
:= h(Y). The
following inequality holds
kµX0 − µY
0kTV ≤ kµX − µY kTV.
Proof From the definition of the total variation distance, we seek to bound
sup
A0∈S0

P[X
0 ∈ A
0
] − P[Y
0 ∈ A
0
]


= sup
A0∈S0

P[h(X) ∈ A
0
] − P[h(Y) ∈ A
0
]


= sup
A0∈S0

P[X ∈ h
−1
(A
0
)] − P[Y ∈ h
−1
(A
0
)]


.
Since h
−1
(A
0
) ∈ S by the measurability of h, this last expression is less than or equal to
sup
A∈S
|P[X ∈ A] − P[Y ∈ A]| ,
which proves the claim.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press192 Coupling
Coupling of Markov chains In the context of Markov chains, a natural way to couple is to
do so step by step. We will refer to such couplings as Markovian. An important special case
is a Markovian coupling of a chain with itself.
Definition 4.1.20 (Markovian coupling). Let P and Q be transition matrices on the same
state space V. A Markovian coupling of P and Q is a Markov chain (Xt MARKOVIAN , Yt)t on V × V with
COUPLING transition matrix R satisfying: for all x, y, x
0
, y
0 ∈ V,
X
z
0
R((x, y), (x
0
,z
0
)) = P(x, x
0
),
X
z
0
R((x, y), (z
0
, y
0
)) = Q(y, y
0
).
We will give many examples throughout this chapter. See also Example 4.2.14 for an exam￾ple of a coupling of Markov chains that is not Markovian.
4.1.4 F Random Graphs: Degree Sequence in Erd ˝os–Rényi Model
Let Gn ∼ Gn,pn be an Erdos–Rényi graph with ˝ pn :=
λ
n
and λ > 0 (see Definition 1.2.2). For
i ∈ [n], let Di(n) be the degree of vertex i and define
Nd(n) :=
Xn
i=1
1{Di(n)=d}
,
the number of vertices of degree d.
Theorem 4.1.21 (Erdos–Rényi graph: degree sequence). ˝
1
n
Nd(n) →p fd := e
−λ
λ
d
d!
∀d ≥ 0.
Proof We proceed in two steps:
1. We use the coupling inequality (Lemma 4.1.11) to show that the expectation of 1
n
Nd(n) is
close to fd; and
2. we appeal to Chebyshev’s inequality (Theorem 2.1.2) to show that 1
n
Nd(n) is close to its
expectation.
We justify each step as a lemma.
Lemma 4.1.22 (Convergence of the mean).
lim
n→+∞
1
n
En,pn
[Nd(n)] = fd ∀d ≥ 1.
Proof Note that the degrees Di(n), i ∈ [n], are identically distributed (but not independent)
so
1
n
En,pn
[Nd(n)] = Pn,pn
[D1(n) = d].
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.1 Background 193
Moreover, by definition, D1(n) ∼ Bin(n−1, pn). Let Sn ∼ Bin(n, pn) and Zn ∼ Poi(λ). Using
the Poisson approximation (Theorem 4.1.18) and a Taylor expansion,
kµSn − µZn
kTV ≤
1
2
X
i≤n
(− log(1 − pn))
2
=
1
2
X
i≤n

λ
n
+ O(n
−2
)
2
=
λ
2
2n
+ O(n
−2
).
We can further couple D1(n) and Sn as
 X
i≤n−1
Xi
,
X
i≤n
Xi
!
,
where the Xis are i.i.d. Ber(pn), that is, Bernoulli with parameter pn. By the coupling ine￾quality (Theorem 4.1.11),
kµD1(n) − µSn
kTV ≤ P
"X
i≤n−1
Xi 6= X
i≤n
Xi
#
= P[Xn = 1] = pn =
λ
n
.
By the triangle inequality for the total variation distance (Lemma 4.1.10) and the bounds
above,
1
2
X
d≥0
|Pn,pn
[D1(n) = d] − fd| = kµD1(n) − µZn
kTV
≤ kµD1(n) − µSn
kTV + kµSn − µZn
kTV
≤
λ + λ
2
/2
n
+ O(n
−2
).
Therefore, for all d,




1
n
En,pn
[Nd(n)] − fd




≤
2λ + λ
2
n
+ O(n
−2
) → 0,
as n → +∞.
Lemma 4.1.23 (Concentration around the mean).
Pn,pn




1
n
Nd(n) −
1
n
En,pn
[Nd(n)]




≥ ε

≤
2λ + 1
ε
2n
∀d ≥ 1, ∀n.
Proof By Chebyshev’s inequality, for all ε > 0,
Pn,pn




1
n
Nd(n) −
1
n
En,pn
[Nd(n)]




≥ ε

≤
Varn,pn
[
1
n
Nd(n)]
ε
2
. (4.1.1)
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press194 Coupling
To compute the variance, we note that
Varn,pn

1
n
Nd(n)

=
1
n
2



En,pn


 X
i≤n
1{Di(n)=d}
!2

 − (n Pn,pn
[D1(n) = d])2



=
1
n
2
n
n(n − 1)Pn,pn
[D1(n) = d, D2(n) = d]
+ n Pn,pn
[D1(n) = d] − n
2Pn,pn
[D1(n) = d]
2
o
≤
1
n
+
n
Pn,pn
[D1(n) = d, D2(n) = d] − Pn,pn
[D1(n) = d]
2
o
, (4.1.2)
where we used the crude bound Pn,pn
[D1(n) = d] ≤ 1. We bound the last line using a
neat coupling argument. Let Y1 and Y2 be independent Bin(n − 2, pn), and let X1 and X2
be independent Ber(pn). By separating the contribution of the edge between 1 and 2 from
those of edges to other vertices, we see that the joint degrees (D1(n), D2(n)) have the same
distribution as (X1 + Y1, X1 + Y2). So the term in curly bracket in (4.1.2) is equal to
P[(X1 + Y1, X1 + Y2) = (d, d)] − P[X1 + Y1 = d]
2
= P[(X1 + Y1, X1 + Y2) = (d, d)] − P[(X1 + Y1, X2 + Y2) = (d, d)]
≤ P[(X1 + Y1, X1 + Y2) = (d, d), (X1 + Y1, X2 + Y2) 6= (d, d)]
= P[(X1 + Y1, X1 + Y2) = (d, d), X2 + Y2 6= d]
= P[X1 = 0, Y1 = Y2 = d, X2 = 1]
+ P[X1 = 1, Y1 = Y2 = d − 1, X2 = 0]
≤ P[X2 = 1] + P[X1 = 1]
=
2λ
n
.
Plugging back into (4.1.2) we get Varn,pn

1
n
Nd(n)

≤
2λ+1
n
, and (4.1.1) gives the claim.
Combining the lemmas concludes the proof of Theorem 4.1.21.
4.2 Stochastic Domination
In comparing two probability measures, a natural relationship is that of “domination.” For
instance, let (Xi)
n
i=1
be independent Z+-valued random variables with
P[Xi ≥ 1] ≥ p,
and let S =
Pn
i=1 Xi be their sum. Now consider a separate random variable
S∗ ∼ Bin(n, p).
It is intuitively clear that one should be able to bound S from below by analyzing S∗ instead –
which may be considerably easier. Indeed, in some sense, S “dominates” S∗, that is, S should
have a tendency to be bigger than S∗. One expects more specifically that
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.2 Stochastic Domination 195
Figure 4.2 The law of X, represented here by its cumulative distribution function
FX in solid, stochastically dominates the law of Y, in dashed. The construction of a
monotone coupling, (Xˆ , Yˆ ) := (F
−1
X
(U), F
−1
Y
(U)), where U is uniform in [0, 1], is
also depicted.
P[S > x] ≥ P[S∗ > x].
Coupling provides a formal characterization of this notion, as we detail in this section.
In particular, we study an important special case known as positive associations. Here
a measure “dominates itself” in the following sense: conditioning on certain events makes
other events more likely. That concept is formalized in Section 4.2.3.
4.2.1 Definitions
We start with the simpler case of real random variables and then consider partially ordered
sets, a natural setting for this concept.
Ordering of real random variables Recall that, intuitively, stochastic domination cap￾tures the idea that one variable “tends to take larger values” than the other. For real random
variables, it is defined in terms of tail probabilities, or equivalently in terms of cumulative
distribution functions. See Figure 4.2 for an illustration.
Definition 4.2.1 (Stochastic domination). Let µ and ν be probability measures on R. The
measure µ is said to stochastically dominate ν, denoted by µ  ν, if for all x ∈ R, STOCHASTIC
DOMINATION
µ

(x, +∞)

≥ ν

(x, +∞)

.
A real random variable X stochastically dominates Y, denoted by X  Y, if the law of X
dominates the law of Y.
Example 4.2.2 (Bernoulli vs. Poisson). Let X ∼ Poi(λ) be Poisson with mean λ > 0 and
let Y be a Bernoulli trial with success probability p ∈ (0, 1). In order for X to stochastically
dominate Y, we need to have
P[X > `] ≥ P[Y > `] ∀` ≥ 0.
This is always true for ` ≥ 1 since P[X > `] > 0 but P[Y > `] = 0. So it remains to
consider the case ` = 0. We have
1 − e
−λ = P[X > 0] ≥ P[Y > 0] = p,
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press196 Coupling
if and only if
λ ≥ − log(1 − p).
J
Note that stochastic domination does not require X and Y to be defined on the same proba￾bility space. However, the connection to coupling arises from the following characterization.
Theorem 4.2.3 (Coupling and stochastic domination). The real random variable X stoch￾astically dominates Y if and only if there is a coupling (Xˆ , Yˆ ) of X and Y such that
P[Xˆ ≥ Yˆ ] = 1. (4.2.1)
We refer to (Xˆ , Yˆ MONOTONE ) as a monotone coupling of X and Y.
COUPLING
Proof Suppose there is such a coupling. Then, for all x ∈ R,
P[Y > x] = P[Yˆ > x] = P[Xˆ ≥ Yˆ > x] ≤ P[Xˆ > x] = P[X > x].
For the other direction, define the cumulative distribution functions FX (x) = P[X ≤ x]
and FY (x) = P[Y ≤ x]. Assume X  Y. The idea of the proof is to use the following
standard way of generating a real random variable (see Theorem B.2.7):
X
d= F
−1
X
(U), (4.2.2)
where U is a [0, 1]-valued uniform random variable and
F
−1
X
(u) := inf{x ∈ R: FX (x) ≥ u}
is a generalized inverse. It is natural to construct a coupling of X and Y by simply using
the same uniform random variable U in this representation, that is, we define Xˆ = F
−1
X
(U)
and Yˆ = F
−1
Y
(U). See Figure 4.2. By (4.2.2), this is a coupling of X and Y. It remains to
check (4.2.1). Because FX (x) ≤ FY (x) for all x by definition of stochastic domination, by the
definition of the generalized inverse,
P[Xˆ ≥ Yˆ ] = P[F
−1
X
(U) ≥ F
−1
Y
(U)] = 1,
as required.
Example 4.2.4 Returning to the example in the first paragraph of Section 4.2, let (Xi)
n
i=1
be independent Z+-valued random variables with P[Xi ≥ 1] ≥ p and consider their sum
S :=
Pn
i=1 Xi
. Furthermore, let S∗ ∼ Bin(n, p). Write S∗ as the sum Pn
i=1
Yi
, where (Yi) are
independent Bernoullli variables with P[Yi = 1] = p. To couple S and S∗, first set (Yˆ
i) :=
(Yi) and Sˆ
∗ :=
Pn
i=1
Yˆ
i
. Let Xˆ
i be 0 whenever Yˆ
i = 0. Otherwise (i.e., if Yˆ
i = 1), generate Xˆ
i
according to the distribution of Xi conditioned on {Xi ≥ 1}, independently of everything else.
By construction, Xˆ
i ≥ Yˆ
i almost surely for all i and as a result Pn
i=1 Xˆ
i =: Sˆ ≥ Sˆ
∗ almost
surely, or S  S∗ by Theorem 4.2.3. That implies for instance that P[S > x] ≥ P[S∗ > x]
as we claimed earlier. A slight modification of this argument gives the following useful fact
about binomials:
n ≥ m, q ≥ p =⇒ Bin(n, q)  Bin(m, p).
Exercise 4.2 asks for a formal proof. J
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.2 Stochastic Domination 197
Example 4.2.5 (Poisson distribution). Let X ∼ Poi(µ) and Y ∼ Poi(ν) with µ > ν. Recall
that a sum of independent Poisson is Poisson (see Exercise 6.7). This fact leads to a natural
coupling: let Yˆ ∼ Poi(ν), Zˆ ∼ Poi(µ − ν) independently of Y, and Xˆ = Yˆ + Zˆ. Then (Xˆ , Yˆ )
is a coupling and Xˆ ≥ Yˆ a.s. because Zˆ ≥ 0. Hence, X  Y. J
We record two useful consequences of Theorem 4.2.3.
Corollary 4.2.6 Let X and Y be real random variables with X  Y and let f : R → R be a
non-decreasing function. Then, f (X)  f (Y) and furthermore, provided E| f (X)|, E| f (Y)| <
+∞, we have that
E[ f (X)] ≥ E[ f (Y)].
Proof Let (Xˆ , Yˆ ) be the monotone coupling of X and Y whose existence is guaranteed by
Theorem 4.2.3. Then, f (Xˆ ) ≥ f (Yˆ ) almost surely so that, provided the expectations exist,
E[ f (X)] = E[ f (Xˆ )] ≥ E[ f (Yˆ )] = E[ f (Y)],
and furthermore ( f (Xˆ ), f (Yˆ )) is a monotone coupling of f (X) and f (Y). Hence, f (X) 
f (Y).
Corollary 4.2.7 Let X1, X2 be independent random variables. Let Y1, Y2 be independent
random variables such that Xi  Yi
, i = 1, 2. Then,
X1 + X2  Y1 + Y2.
Proof Let (Xˆ
1, Yˆ
1) and (Xˆ
2, Yˆ
2) be independent, monotone couplings of (X1, Y1) and (X2, Y2)
on the same probability space. Then,
X1 + X2
d= Xˆ
1 + Xˆ
2 ≥ Yˆ
1 + Yˆ
2
d= Y1 + Y2.
Example 4.2.8 (Binomial vs. Poisson). A sum of n independent Poisson variables with
mean λ is Poi(nλ). A sum of n independent Bernoulli trials with success probability p is
Bin(n, p). Using Example 4.2.2 and Corollary 4.2.7, we get
λ ≥ − log(1 − p) =⇒ Poi(nλ)  Bin(n, p). (4.2.3)
The following special case will be useful later. Let 0 < 3 < 1 and let m be a positive integer.
Then,
3
m − 1
≥
3
m − 3
=
m
m − 3
− 1 ≥ log
m
m − 3

= − log
1 −
3
m

,
where we used that log x ≤ x − 1 for all x ∈ R+ (see Exercise 1.16). So, setting λ :=
3
m−1
,
p :=
3
m
, and n := m − 1 in (4.2.3), we get
3 ∈ (0, 1) =⇒ Poi(3)  Bin
m − 1,
3
m

. (4.2.4)
J
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press198 Coupling
Ordering on partially ordered sets The definition of stochastic domination hinges on the
totally ordered nature of R. It also extends naturally to posets. Let (X , ≤) be a poset, that is, POSET
for all x, y,z ∈ X :
• (Reflexivity) x ≤ x;
• (Antisymmetry) if x ≤ y and y ≤ x, then x = y; and
• (Transitivity) if x ≤ y and y ≤ z, then x ≤ z.
For instance the set {0, 1}
F
is a poset when equipped with the relation x ≤ y if and only
if xi ≤ yi for all i ∈ F, where x = (xi)i∈F and y = (yi)i∈F. Equivalently, the subsets of F,
denoted by 2F
, form a poset with the inclusion relation.
A totally ordered set satisfies in addition that, for any x, y, we have either x ≤ y or y ≤ x.
That is not satisfied in the previous example.
INCREASING Let F be a σ-algebra over the poset X . An event A ∈ F is increasing if x ∈ A implies
that any y ≥ x is also in A. A function f : X → R is increasing if x ≤ y implies f (x) ≤ f ( y).
Some properties of increasing events are derived in Exercise 4.4.
Definition 4.2.9 (Stochastic domination for posets). Let (X , ≤) be a poset and let F be a
σ-algebra on X . Let µ and ν be probability measures on (X , F). The measure µ is said to
stochastically dominate ν, denoted by µ  ν, if for all increasing A ∈ F,
µ(A) ≥ ν(A).
An X -valued random variable X stochastically dominates Y, denoted by X  Y, if the law
of X dominates the law of Y.
As before, a monotone coupling (Xˆ , Yˆ ) of X and Y is one which satisfies Xˆ ≥ Yˆ almost
surely.
Example 4.2.10 (Monotonicity of the percolation function). We have already seen an exam￾ple of stochastic domination in Section 2.2.4. We revisit this example now to illustrate our
definitions. Consider bond percolation on the d-dimensional lattice L
d
(Definition 1.2.1).
Here the poset is the collection of all subsets of edges, specifying the open edges, with the
inclusion relation. Recall that the percolation function is given by
θ(p) := Pp[|C0| = +∞],
where C0 is the open cluster of the origin. We argued in Section 2.2.4 that θ(p) is non￾decreasing by considering the following alternative representation of the percolation process
under Pp: to each edge e, assign a uniform [0, 1]-valued random variable Ue and declare the
edge open if Ue ≤ p. Using the same Ues for two different values of p, say p1 < p2, gives a
monotone coupling of the processes for p1 and p2. It follows immediately that θ(p1) ≤ θ(p2),
where we used that the event {|C0| = +∞} is increasing. J
The existence of a monotone coupling is perhaps more surprising for posets. We prove
the result in the finite case only, which will be enough for our purposes.
Theorem 4.2.11 (Strassen’s theorem). Let X and Y be random variables taking values in a
finite poset (X , ≤) with the σ-algebra F = 2
X . Then, X  Y if and only if there exists a
monotone coupling (Xˆ , Yˆ ) of X and Y.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.2 Stochastic Domination 199
Proof Suppose there is such a coupling. Then for all increasing A,
P[Y ∈ A] = P[Yˆ ∈ A] = P[Xˆ ≥ Yˆ ∈ A] ≤ P[Xˆ ∈ A] = P[X ∈ A].
The proof in the other direction relies on the max-flow min-cut theorem (Theorem 1.1.15).
To see the connection with flows, let µX and µY be the laws of X and Y, respectively, and
denote by ν their joint distribution under the desired coupling. Noting that we want ν(x, y) >
0 only if x ≥ y, the marginal conditions on the coupling read
X
y≤x
ν(x, y) = µX (x) ∀x ∈ X (4.2.5)
and
X
x≥y
ν(x, y) = µY ( y), ∀y ∈ X . (4.2.6)
These equations can be interpreted as flow-conservation constraints. Consider the follow￾ing directed graph. There are two vertices, (w, 1) and (w, 2), for each element w in X with
edges connecting each (x, 1) to those (y, 2)s with x ≥ y. These edges have capacity +∞. In
addition, there is a source a and a sink z. The source has a directed edge of capacity µX (x)
to (x, 1) for each x ∈ X and, similarly, each (y, 2) has a directed edge of capacity µY ( y) to
the sink. The existence of a monotone coupling will follow once we show that there is a flow
of strength 1 between a and z. Indeed, in that case, all edges from the source and all edges
to the sink are at capacity. If we let ν(x, y) be the flow on edge h(x, 1), (y, 2)i, the systems
in (4.2.5) and (4.2.6) encode conservation of flow on the vertices (X × {1}) ∪ (X × {2}).
Hence, the flow between X × {1} and X × {2} yields the desired coupling. See Figure 4.3.
By the max-flow min-cut theorem (Theorem 1.1.15), it suffices to show that a minimum
cut has capacity 1. Such a cut is of course obtained by choosing all edges out of the source.
So it remains to show that no cut has capacity less than 1. This is where we use the fact that
µX (A) ≥ µY (A) for all increasing A. Because the edges between X × {1} and X × {2} have
infinite capacity, they cannot be used in a minimum cut. So we can restrict our attention to
those cuts containing edges from a to A∗× {1} and from Z∗× {2} to z for subsets A∗, Z∗ ⊆ X .
We must have
A∗ ⊇ {x ∈ X : ∃y ∈ Z
c
∗
, x ≥ y}
to block all paths of the form a ∼ (x, 1) ∼ (y, 2) ∼ z with x and y as in the previous display.
In fact, for a minimum cut, we further have
A∗ = {x ∈ X : ∃y ∈ Z
c
∗
, x ≥ y},
as adding an x not satisfying this property is redundant. In particular, A∗ is increasing: if
x1 ∈ A∗ and x2 ≥ x1, then ∃y ∈ Z
c
∗
such that x1 ≥ y and, since x2 ≥ x1 ≥ y, we also have
x2 ∈ A∗.
Observe further that, because y ≥ y, the set A∗ also includes Z
c
∗
. If it were the case that
A∗ 6= Z
c
∗
, then we could construct a cut with lower or equal capacity by fixing A∗ and setting
Z∗ := A
c
∗
: suppose A∗ ∩ Z∗ is non-empty; because A∗ is increasing, any y ∈ A∗ ∩ Z∗ is such
that paths of the form a ∼ (x, 1) ∼ (y, 2) ∼ z with x ≥ y are cut by x ∈ A∗; so we do not
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press200 Coupling
Figure 4.3 Construction of a monotone coupling through the max-flow
representation for independent Bernoulli pairs with parameters r (on the left) and
q < r (on the right). Edge labels indicate capacity. Edges without labels have
infinite capacity. The dotted edges depict a suboptimal cut. The dark vertices
correspond to the sets A∗ and Z∗ for this cut. The capacity of the cut is
r
2 + r(1 − r) + (1 − q)
2 + (1 − q)q = r + (1 − q) > r + (1 − r) = 1.
need those ys in Z∗. Hence, for a minimum cut, we can assume that in fact A∗ = Z
c
∗
. The
capacity of the cut is
µX (A∗) + µY (Z∗) = µX (A∗) + 1 − µY (A∗) = 1 + (µX (A∗) − µY (A∗)) ≥ 1,
where the term in parenthesis is non-negative by assumption and the fact that A∗ is increas￾ing. That concludes the proof.
Remark 4.2.12 Strassen’s theorem (Theorem 4.2.11) holds more generally on Polish spaces
with a closed partial order. See, for example, [Lin02, section IV.1.2] for the details.
The proof of Corollary 4.2.6 immediately extends to:
Corollary 4.2.13 Let X and Y be X -valued random variables with X  Y and let f : X →
R be an increasing function. Then, f (X)  f (Y) and furthermore, provided E| f (X)|, E| f (Y)| <
+∞, we have that
E[ f (X)] ≥ E[ f (Y)].
Ordering of Markov chains Stochastic domination also arises in the context of Markov
chains. We begin with an example. Recall the notion of a Markovian coupling from Defini￾tion 4.1.20. The following coupling of Markov chains is not Markovian.
Example 4.2.14 (Lazier chain). Consider a random walk (Xt) on the network N = ((V, E), c),
where V = {0, 1, . . . , n} and i ∼ j if and only if |i − j| ≤ 1 (including self-loops). Let N 0 =
((V, E), c
0
) be a modified version of N on the same graph where, for all i, c(i, i) ≤ c
0
(i, i).
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.2 Stochastic Domination 201
That is, if (X
0
t
) is random walk on N 0
, then (X
0
t
) is “lazier” than (Xt) in that it is more likely
to stay put. To simplify the calculations, assume c(i, i) = 0 for all i.
Assume that both (Xt) and (X
0
t
) start at i0 and define Ms
:= maxt≤s Xt and M0
s
:= maxt≤s X
0
t
.
Since (X
0
t
) “travels less” than (Xt), the following claim is intuitively obvious.
Claim 4.2.15
Ms  M0
s
.
We prove this by producing a monotone coupling. First set (Xˆ
t)t∈Z+
:= (Xt)t∈Z+
. We then
generate (Xˆ
0
t
)t∈Z+
as a “sticky” version of (Xˆ
t)t∈Z+
. That is, (Xˆ
0
t
) follows exactly the same
transitions as (Xˆ
t) (including the self-loops), but at each time it opts to stay where it currently
is, say state j, for an extra time step with probability
αj
:=
c
0
(j, j)
P
i:i∼j
c
0
(i, j)
,
which is in [0, 1] by assumption. Marginally, (Xˆ
0
t
) is a random walk on N 0
. Indeed, we have
by construction of the coupling that the probability of staying put when in state j is
αj =
c
0
(j, j)
P
i:i∼j
c
0
(i, j)
,
and, for k 6= j with k ∼ j, the probability of moving to state k when in state j is
(1 − αj)
c(j, k)
P
i:i∼j
c(i, j)
=
 
[
P
i:i∼j
c
0
(i, j)] − c
0
(j, j)
P
i:i∼j
c
0
(i, j)
!
c(j, k)
P
i:i∼j
c(i, j)
=
 P
i:i∼j
c(i, j)
P
i:i∼j
c
0
(i, j)
!
c
0
(j, k)
P
i:i∼j
c(i, j)
=
c
0
(j, k)
P
i:i∼j
c
0
(i, j)
,
where, on the second line, we used that c
0
(i, j) = c(i, j) for i 6= j and i ∼ j. This coupling
satisfies almost surely
Mbs
:= max
t≤s
Xˆ
t ≥ max
t≤s
Xˆ
0
t =: Mb0
s
because (Xˆ
0
t
)t≤s visits a subset of the states visited by (Xˆ
t)t≤s
. In other words, (Mbs
, Mb0
s
) is a
monotone coupling of (Ms
, M0
s
) and this proves the claim. J
As we indicated, the previous example involved an “asynchronous” coupling of the chains.
Often a simpler step-by-step approach – that is, through the construction of a Markovian
coupling – is possible. We specialize the notion of stochastic domination to that important
case.
Definition 4.2.16 (Stochastic domination of Markov chains). Let P and Q be transition
matrices on a finite or countably infinite poset (X , ≤). The transition matrix Q is said to
stochastically dominate the transition matrix P if
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press202 Coupling
x ≤ y =⇒ P(x, ·)  Q(y, ·). (4.2.7)
If the above condition is satisfied for P = Q, we say that P is stochastically monotone.
The analogue of Strassen’s theorem in this case is the following theorem, which we prove
in the finite case only again.
Theorem 4.2.17 Let (Xt)t∈Z+
and (Yt)t∈Z+
be Markov chains on a finite poset (X , ≤) with
transition matrices P and Q, respectively. Assume that Q stochastically dominates P. Then,
for all x0 ≤ y0 there is a coupling (Xˆ
t
, Yˆ
t) of (Xt) started at x0 and (Yt) started at y0 such that
almost surely
Xˆ
t ≤ Yˆ
t ∀t.
Furthermore, if the chains are irreducible and have stationary distributions π and µ,
respectively, then π  µ.
Observe that for a Markovian, monotone coupling to exist, it is not generally enough for the
weaker condition P(x, ·)  Q(x, ·) to hold for all x, as should be clear from the proof. See
also Exercise 4.3.
Proof of Theorem 4.2.17 Let
W := {(x, y) ∈ X × X : x ≤ y}.
For all (x, y) ∈ W, let R((x, y), ·) be the joint law of a monotone coupling of P(x, ·) and
Q(y, ·). Such a coupling exists by Strassen’s theorem and Condition (4.2.7). Let (Xˆ
t
, Yˆ
t) be a
Markov chain on W with transition matrix R started at (x0, y0). By construction, Xˆ
t ≤ Yˆ
t for
all t almost surely. That proves the first half of the theorem.
For the second half, let A be increasing on X . Note that the first half implies that for all
s ≥ 1,
P
s
(x0, A) = P[Xˆ
s ∈ A] ≤ P[Yˆ
s ∈ A] = Q
s
(y0, A),
because Xˆ
s ≤ Yˆ
s and A is increasing. Then, by a standard convergence result for irreducible
Markov chains (i.e., (1.1.5)),
π(A) = lim
t→+∞
1
t
X
s≤t
P
s
(x0, A) ≤ lim
t→+∞
1
t
X
s≤t
Q
s
(y0, A) = µ(A).
This proves the claim by definition of stochastic domination.
An example of application of this theorem is given in the next subsection.
4.2.2 Ising Model: Boundary Conditions
Consider the d-dimensional lattice L
d
. Let 3 be a finite subset of vertices in L
d
and define
X := {−1, +1}
3, which is a poset when equipped with the relation σ ≤ σ
0
if and only if
σi ≤ σ
0
i
for all i ∈ 3. Generalizing Example 1.2.5, for ξ ∈ {−1, +1}
L
d
, the (ferromagnetic)
BOUNDARY Ising model on 3 with boundary conditions ξ and inverse temperature β is the probability
CONDITIONS distribution over spin configurations σ ∈ X given by
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.2 Stochastic Domination 203
µ
ξ
β,3(σ) :=
1
Z3,ξ (β)
e
−βH3,ξ (σ)
,
where
H3,ξ (σ) := −X
i∼j
i,j∈3
σiσj −
X
i∼j
i∈3,j∈/3
σiξj
is the Hamiltonian and
Z3,ξ (β) :=
X
σ∈X
e
−βH3,ξ (σ)
is the partition function. For shorthand, we occasionally write + and − instead of +1 and
−1.
For the all-(+1) and all-(−1) boundary conditions we denote the measure above by
µ
+
β,3(σ) and µ
−
β,3(σ), respectively. In this section, we show that these two measures are
“extreme” in the following sense.
Claim 4.2.18 For all boundary conditions ξ ∈ {−1, +1}
L
d
,
µ
+
β,3  µ
ξ
β,3  µ
−
β,3
.
Intuitively, because the ferromagnetic Ising model favors spin agreement, the all-(+1) bound￾ary condition tends to produce more +1s, which in turn makes increasing events more likely.
And vice versa.
The idea of the proof is to use Theorem 4.2.17 with a suitable choice of Markov chain.
Stochastic domination In this context, vertices are often referred to as sites. Adapting
Definition 1.2.8, we consider the single-site Glauber dynamics, which is the Markov chain
on X which, at each time, selects a site i ∈ 3 uniformly at random and updates the spin σi
according to µ
ξ
β,3(σ) conditioned on agreeing with σ at all sites in 3\{i}. Specifically, for
γ ∈ {−1, +1}, i ∈ 3, and σ ∈ X , let σ
i,γ be the configuration σ with the state at i being set
to γ . Then, letting n = |3|, the transition matrix of the Glauber dynamics is
Q
ξ
β,3(σ, σ
i,γ
) :=
1
n
·
e
γβS
ξ
i
(σ)
e
−βS
ξ
i
(σ) + e
βS
ξ
i
(σ)
,
where
S
ξ
i
(σ) :=
X
j:j∼i
j∈3
σj +
X
j:j∼i
j∈/3
ξj
.
All other transitions have probability 0. It is straightforward to check that Q
ξ
β,3 is a stochastic
matrix.
This chain is clearly irreducible. It is also reversible with respect to µ
ξ
β,3. Indeed, for all
σ ∈ X and i ∈ 3, let
S
ξ
6=i
(σ) := H3,ξ (σ
i,+
) + S
ξ
i
(σ) = H3,ξ (σ
i,−
) − S
ξ
i
(σ).
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press204 Coupling
Arguing as in Theorem 1.2.9, we have
µ
ξ
β,3(σ
i,−
) Q
ξ
β,3(σ
i,−
, σ
i,+
) =
e
−βS
ξ
6=i
(σ)
e
−βS
ξ
i
(σ)
Z3,ξ (β)
·
e
βS
ξ
i
(σ)
n[e
−βS
ξ
i
(σ) + e
βS
ξ
i
(σ)
]
=
e
−βS
ξ
6=i
(σ)
nZ3,ξ (β)[e
−βS
ξ
i
(σ) + e
βS
ξ
i
(σ)
]
=
e
−βS
ξ
6=i
(σ)
e
βS
ξ
i
(σ)
Z3,ξ (β)
·
e
−βS
ξ
i
(σ)
n[e
−βS
ξ
i
(σ) + e
βS
ξ
i
(σ)
]
= µ
ξ
β,3(σ
i,+
) Q
ξ
β,3(σ
i,+
, σ
i,−
).
In particular, µ
ξ
β,3 is the stationary distribution of Q
ξ
β,3.
Claim 4.2.19
ξ
0 ≥ ξ =⇒ Q
ξ
0
β,3 stochastically dominates Qξ
β,3. (4.2.8)
Proof Because the Glauber dynamics updates a single site at a time, establishing stochastic
domination reduces to checking simple one-site inequalities.
Lemma 4.2.20 To establish (4.2.8), it suffices to show that for all i and all σ ≤ τ ,
Q
ξ
β,3(σ, σ
i,+
) ≤ Q
ξ
0
β,3(τ , τ
i,+
). (4.2.9)
Proof Assume (4.2.9) holds. Let A be increasing in X and let σ ≤ τ . Then, for the single￾site Glauber dynamics, we have
Q
ξ
β,3(σ, A) = Q
ξ
β,3(σ, A ∩ Bσ ), (4.2.10)
where
Bσ := {σ
i,γ
: i ∈ 3, γ ∈ {−1, +1}},
and similarly for τ , ξ
0
. Moreover, because A is increasing and τ ≥ σ,
σ
i,γ ∈ A =⇒ τ
i,γ ∈ A (4.2.11)
and
σ
i,− ∈ A =⇒ σ
i,+ ∈ A. (4.2.12)
Letting
I
±
σ,A
:= {i ∈ 3: σ
i,− ∈ A}, I
+
σ,A
:= {i ∈ 3: σ
i,+ ∈ A},
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.2 Stochastic Domination 205
and similarly for τ , we have by (4.2.9), (4.2.10), (4.2.11), and (4.2.12),
Q
ξ
β,3(σ, A) = Q
ξ
β,3(σ, A ∩ Bσ )
=
X
i∈I
+
σ,A
Q
ξ
β,3(σ, σ
i,+
) +
X
i∈I
±
σ,A
h
Q
ξ
β,3(σ, σ
i,−
) + Q
ξ
β,3(σ, σ
i,+
)
i
≤
X
i∈I
+
σ,A
Q
ξ
0
β,3(τ , τ
i,+
) +
X
i∈I
±
σ,A
1
n
≤
X
i∈I
+
τ ,A
Q
ξ
0
β,3(τ , τ
i,+
) +
X
i∈I
±
τ ,A
h
Q
ξ
0
β,3(τ , τ
i,−
) + Q
ξ
0
β,3(τ , τ
i,+
)
i
= Q
ξ
0
β,3(τ , A),
as claimed.
Returning to the proof of Claim 4.2.19, observe that
Q
ξ
β,3(σ, σ
i,+
) =
1
n
·
e
βS
ξ
i
(σ)
e
−βS
ξ
i
(σ) + e
βS
ξ
i
(σ)
=
1
n
·
1
e
−2βS
ξ
i
(σ) + 1
,
which is increasing in S
ξ
i
(σ). Now σ ≤ τ and ξ ≤ ξ
0
imply that S
ξ
i
(σ) ≤ S
ξ
0
i
(τ ). That proves
the claim by Lemma 4.2.20.
Finally:
Proof of Claim 4.2.18 Combining Theorem 4.2.17 and Claim 4.2.19 gives the result.
Remark 4.2.21 One can make sense of the limit of µ
+
β,3 and µ
−
β,3 when |3| → +∞, which
is known as an infinite-volume Gibbs measure. For more, see, for example, [RAS15, chapters
7–10].
Observe that we have not used any special property of the d-dimensional lattice. Indeed,
Claim 4.2.18 in fact holds for any countable, locally finite graph with positive coupling
constants. We give another proof in Example 4.2.33.
4.2.3 Correlation Inequalities: FKG and Holley’s Inequalities
A special case of stochastic domination is positive associations. In this section, we restrict
ourselves to posets of the form {0, 1}
F
for F finite. We begin with an example.
Example 4.2.22 (Erdos–Rényi graph: positive associations). Consider an Erd ˝ os–Rényi ˝
graph G ∼ Gn,p. Let E = {{x, y}: x, y ∈ [n], x 6= y}. Think of G as taking values in the
poset ({0, 1}
E
, ≤), where a 1 indicates that the corresponding edge is present. In fact, ob￾serve that the law of G, which we denote as usual by Pn,p, is a product measure on {0, 1}
E
.
The event A that G is connected is increasing because adding edges cannot disconnect an
already connected graph. So is the event B of having a chromatic number larger than 4.
Intuitively then, conditioning on A makes B more likely: the occurrence of A tends to be
accompanied with a larger number of edges which in turn makes B more probable.
This is an example of a more general phenomenon. That is, for any non-empty increasing
events A and B, we have:
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press206 Coupling
Claim 4.2.23
Pn,p[B | A] ≥ Pn,p[B]. (4.2.13)
Or, put differently, the conditional measure Pn,p[ · | A] stochastically dominates the uncondi￾tional measure Pn,p[ · ]. This is a special case of what is known as Harris’ inequality, proved
below. Note that (4.2.13) is equivalent to Pn,p[A ∩ B] ≥ Pn,p[A] Pn,p[B], that is, to the fact
that A and B are positively correlated. J
More generally:
Definition 4.2.24 (Positive associations). Let µ be a probability measure on {0, 1}
F where
POSITIVE F is finite. Then µ is said to have positive associations, or is positively associated, if for all
ASSOCIATIONS increasing functions f , g : {0, 1}
F → R,
µ(fg) ≥ µ(f )µ(g),
where
µ(h) :=
X
ω∈{0,1}
F
µ(ω)h(ω).
In particular, for any increasing events A and B it holds that
µ(A ∩ B) ≥ µ(A)µ(B),
POSITIVELY that is, A and B are positively correlated. Denoting by µ(A | B) the conditional probability
CORRELATED of A given B, this is equivalent to
µ(A | B) ≥ µ(A).
Remark 4.2.25 Note that positive associations is concerned only with increasing events.
See Remark 4.2.45.
Remark 4.2.26 A notion of negative associations, which is a somewhat more delicate con￾cept, was defined in Remark 3.3.43. See also [Pem00].
DECREASING Let µ be positively associated. Note that if A and B are decreasing, that is, their comple￾ments are increasing (see Exercise 4.4), then
µ(A ∩ B) = 1 − µ(A
c ∪ B
c
)
= 1 − µ(A
c
) − µ(B
c
) + µ(A
c ∩ B
c
)
≥ 1 − µ(A
c
) − µ(B
c
) + µ(A
c
)µ(B
c
)
= µ(A)µ(B),
or µ(A | B) ≥ µ(A). Similarly, if A is increasing and B is decreasing, we have µ(A ∩ B) ≤
µ(A)µ(B), or
µ(A | B) ≤ µ(A). (4.2.14)
Harris’ inequality states that product measures on {0, 1}
F have positive associations. We
prove a more general result known as the FKG inequality. For two configurations ω, ω
0
in
{0, 1}
F
, we let ω ∧ ω
0
and ω ∨ ω
0 be the coordinatewise minimum and maximum of ω and
ω
0
.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.2 Stochastic Domination 207
Definition 4.2.27 (FKG condition). Let X = {0, 1}
F
, where F is finite. A positive probability
measure µ on X satisfies the FKG condition if FKG
CONDITION
µ(ω ∨ ω
0
)µ(ω ∧ ω
0
) ≥ µ(ω)µ(ω
0
) ∀ω, ω
0 ∈ X . (4.2.15)
This property is also known as log-supermodularity. We call such a measure an FKG
measure.
Theorem 4.2.28 (FKG inequality). Let X = {0, 1}
F
, where F is finite. Suppose µ is a FKG
positive probability measure on X satisfying the FKG condition. Then µ has positive asso- INEQUALITY
ciations.
Remark 4.2.29 Strict positivity is not in fact needed [FKG71]. The FKG condition is equiv￾alent to a strong form of positive associations. See Exercise 4.8.
Note that product measures satisfy the FKG condition with equality. Indeed, if µ(ω) is of
the form Q
f ∈F µf (ωf ), then
µ(ω ∨ ω
0
)µ(ω ∧ ω
0
) =
Y
f
µf (ωf ∨ ω
0
f
) µf (ωf ∧ ω
0
f
)
=
Y
f :ωf =ω
0
f
µf (ωf )
2 Y
f :ωf 6=ω
0
f
µf (ωf )µf (ω
0
f
)
=
Y
f :ωf =ω
0
f
µf (ωf )µf (ω
0
f
)
Y
f :ωf 6=ω
0
f
µf (ωf )µf (ω
0
f
)
= µ(ω)µ(ω
0
).
So the FKG inequality (Theorem 4.2.28) applies, for instance, to bond percolation and the
Erdos–Rényi random graph model. The pointwise nature of the FKG condition also makes ˝
it relatively easy to check for measures which are defined explicitly up to a normalizing
constant, such as the Ising model.
Example 4.2.30 (Ising model with boundary conditions: checking FKG). Consider again
the setting of Section 4.2.2. We work on the space X := {−1, +1}
3 rather than {0, 1}
F
. Fix
a finite 3 ⊆ L
d
, ξ ∈ {−1, +1}
L
d
and β > 0.
Claim 4.2.31 The measure µ
ξ
β,3 satisfies the FKG condition and therefore has positive
associations.
Intuitively, taking the minimum (or maximum) of two spin configurations tends to increase
agreement and therefore leads to a higher likelihood. For σ, σ
0 ∈ X , let τ = σ ∨ σ
0
and
τ = σ ∧ σ
0
. By taking logarithms in the FKG condition and rearranging, we arrive at
H3,ξ (τ ) + H3,ξ (τ ) ≤ H3,ξ (σ) + H3,ξ (σ
0
), (4.2.16)
and we see that proving the claim boils down to checking an inequality for each term in the
Hamiltonian (which, confusingly, has a negative sign in it).
When i ∈ 3 and j ∈/ 3 such that i ∼ j, we have
τ iξj + τ i
ξj = (τ i + τ i
)ξj = (σi + σ
0
i
)ξj = σiξj + σ
0
i
ξj
. (4.2.17)
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press208 Coupling
For i, j ∈ 3 with i ∼ j, note first that the case σj = σ
0
j
reduces to the previous calculation
(with σj = σ
0
j
playing the role of ξj), so we assume σi 6= σ
0
i
and σj 6= σ
0
j
. Then,
τ iτ j + τ i
τ j = (+1)(+1) + (−1)(−1) = 2 ≥ σiσj + σ
0
i
σ
0
j
,
since 2 is the largest value the rightmost expression ever takes. We have established (4.2.16),
which implies the claim.
Again, we have not used any special property of the lattice and the same result holds for
countable, locally finite graphs with positive coupling constants. Note however that in the
anti-ferromagnetic case, that is, if we multiply the Hamiltonian by −1, the above argument
does not work. Indeed there is no reason to expect positive associations in that case. J
The FKG inequality in turn follows from a more general result known as Holley’s ine￾quality.
Theorem 4.2.32 (Holley’s inequality). Let X = {0, 1}
F
HOLLEY’S , where F is finite. Suppose µ1 and
INEQUALITY µ2 are positive probability measures on X satisfying
µ2(ω ∨ ω
0
)µ1(ω ∧ ω
0
) ≥ µ2(ω)µ1(ω
0
) ∀ω, ω
0 ∈ X . (4.2.18)
Then, µ1  µ2.
Before proving Holley’s inequality (Theorem 4.2.32), we check that it indeed implies the
FKG inequality. See Exercise 4.5 for an elementary proof in the independent case, that is, of
Harris’ inequality.
Proof of Theorem 4.2.28 Assume that µ satisfies the FKG condition and let f , g be in￾creasing functions. Because of our restriction to positive measures in Holley’s inequality, we
will work with positive functions. This is done without loss of generality. Indeed, letting 0
be the all-0 vector, note that f and g are increasing if and only if f
0
:= f − f (0) + 1 > 0 and
g
0
:= g − g(0) + 1 > 0 are increasing and that, moreover,
µ(f
0
g
0
) − µ(f
0
)µ(g
0
) = µ([ f
0 − µ(f
0
)][g
0 − µ(g
0
)])
= µ([ f − µ(f )][g − µ(g)])
= µ(fg) − µ(f )µ(g).
In Holley’s inequality, we let µ1 := µ and define the positive probability measure
µ2(ω) :=
g(ω)µ(ω)
µ(g)
.
We check that µ1 and µ2 satisfy the conditions of Theorem 4.2.32. Note that ω
0 ≤ ω ∨ ω
0
for any ω so that, because g is increasing, we have g(ω
0
) ≤ g(ω ∨ ω
0
). Hence, for any ω, ω
0
,
µ1(ω)µ2(ω
0
) = µ(ω)
g(ω
0
)µ(ω
0
)
µ(g)
= µ(ω)µ(ω
0
)
g(ω
0
)
µ(g)
≤ µ(ω ∧ ω
0
)µ(ω ∨ ω
0
)
g(ω ∨ ω
0
)
µ(g)
= µ1(ω ∧ ω
0
)µ2(ω ∨ ω
0
),
where on the third line we used the FKG condition satisfied by µ.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.2 Stochastic Domination 209
So Holley’s inequality implies that µ2  µ1. Hence, since f is increasing, by Corol￾lary 4.2.13,
µ(f ) = µ1(f ) ≤ µ2(f ) =
µ(fg)
µ(g)
,
and the theorem is proved.
Proof of Theorem 4.2.32 The idea of the proof is to use Theorem 4.2.17. This is similar
to what was done in Section 4.2.2. Again we use a single-site dynamic. For x ∈ X and
γ ∈ {0, 1}, we let x
i,γ be x with coordinate i set to γ . We write x ∼ y if kx − yk1 = 1. Let
n = |F|. We use a scheme analogous to the Metropolis algorithm (see Example 1.1.30). A
natural symmetric chain on X is to pick a coordinate uniformly at random, and flip its value.
We modify it to guarantee reversibility with respect to the desired stationary distributions,
namely, µ1 and µ2.
For α, β > 0 small enough, the following transition matrix over X is irreducible and
reversible with respect to its stationary distribution µ2: for all i ∈ F, y ∈ X ,
Q(y
i,0
, y
i,1) =
1
n
α {β},
Q(y
i,1
, y
i,0) =
1
n
α

β
µ2(y
i,0)
µ2(y
i,1)

,
Q(y, y) = 1 −
X
z:z∼y
Q(y,z).
Let P be similarly defined with respect to µ1 with the same values of α and β. For reasons
that will be clear below, the value of 0 < β < 1 is chosen small enough that the sum of
the two expressions in brackets above is smaller than 1 for all y, i in both P and Q. The
value of α > 0 is then chosen small enough that P( y, y), Q(y, y) ≥ 0 for all y. Reversibility
follows immediately from the first two equations. We call the first transition above an upward
transition and the second one a downward transition.
By Theorem 4.2.17, it remains to show that Q stochastically dominates P. That is, for any
x ≤ y, we want to show that P(x, ·)  Q(y, ·). We produce a monotone coupling (Xˆ , Yˆ ) of
these two distributions. Because x ≤ y, our goal is never to perform an upward transition in
x simultaneously with a downward transition in y. Observe that
µ1(x
i,0)
µ1(x
i,1)
≥
µ2(y
i,0)
µ2(y
i,1)
(4.2.19)
by taking ω = y
i,0 and ω
0 = x
i,1 in Condition (4.2.18).
The coupling works as follows. Fix x ≤ y. With probability 1 − α, set (Xˆ , Yˆ ) := (x, y).
Otherwise, pick a coordinate i ∈ F uniformly at random. There are several cases to consider
depending on the coordinates xi
, yi (with xi ≤ yi by assumption):
• (xi
, yi) = (0, 0): With probability β, perform an upward transition in both coordinates,
that is, set Xˆ := x
i,1 and Yˆ := y
i,1. With probability 1 − β, set (Xˆ , Yˆ ) := (x, y) instead.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press210 Coupling
• (xi
, yi) = (1, 1): With probability β
µ2(y
i,0)
µ2(y
i,1)
, perform a downward transition in both coordi￾nates, that is, set Xˆ := x
i,0 and Yˆ := y
i,0. With probability
β

µ1(x
i,0)
µ1(x
i,1)
−
µ2(y
i,0)
µ2(y
i,1)

,
perform a downward transition in x only, that is, set Xˆ := x
i,0 and Yˆ := y. With the
remaining probability, set (Xˆ , Yˆ ) := (x, y) instead. Note that (4.2.19) and our choice of β
guarantees that this step is well defined.
• (xi
, yi) = (0, 1): With probability β, perform an upward transition in x only, that is, set
Xˆ := x
i,1 and Yˆ := y. With probability β
µ2(y
i,0)
µ2(y
i,1)
, perform a downward transition in y only,
that is, set Xˆ := x and Yˆ := y
i,0. With the remaining probability, set (Xˆ , Yˆ ) := (x, y)
instead. Again our choice of β guarantees that this step is well defined.
A little accounting shows that this is indeed a coupling of P(x, ·) and Q(y, ·). By construction,
this coupling satisfies Xˆ ≤ Yˆ almost surely. An application of Theorem 4.2.17 concludes the
proof.
Example 4.2.33 (Ising model revisited). Holley’s inequality implies Claim 4.2.18. To see
this, just repeat the calculations of Example 4.2.30, where now (4.2.17) is replaced with an
inequality. See Exercise 4.6. J
4.2.4 F Random Graphs: Janson’s Inequality and Application to the Clique Number
in the Erd ˝os–Rényi Model
Let G = (V, E) ∼ Gn,p be an Erdos–Rényi graph. By Claim ˝ 2.3.5, the property of being
triangle-free has threshold n
−1
. That is, the probability that G contains a triangle goes to 0
or 1 as n → +∞ according to whether p  n
−1 or p  n
−1
, respectively. In this section,
we investigate what happens at the threshold, by which we mean that we take p = λ/n for
some λ > 0 not depending on n.
For any subset S of three distinct vertices of G, let BS be the event that S forms a triangle
in G. So
ε := Pn,p[BS] = p
3 → 0. (4.2.20)
Denoting the unordered triples of distinct vertices by ￾
V
3

, let Xn =
P
S∈(
V
3)
1BS be the number
of triangles in G. By the linearity of expectation, the mean number of triangles is
En,pXn =

n
3

p
3 =
n(n − 1)(n − 2)
6

λ
n
3
→
λ
3
6
,
as n → +∞. If the events {BS}S were mutually independent, Xn would be binomially distrib￾uted and the event that G is triangle-free would have probability
Y
S∈(
V
3)
Pn,p[B
c
S
] = (1 − p
3
)
(
n
3) → e
−λ
3
/6
. (4.2.21)
In fact, by the Poisson approximation to the binomial (e.g., Theorem 4.1.18), we would have
that the number of triangles converges weakly to Poi(λ
3
/6).
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Pres4.2 Stochastic Domination 211
In reality, of course, the events {BS} are not mutually independent. Observe however that,
for most pairs S, S
0
, the events BS and BS
0 are in fact pairwise independent. That is the case
whenever |S ∩ S
0
| ≤ 1, that is, whenever the edges connecting S are disjoint from those
connecting S
0
. Write S ∼ S
0
if S 6= S
0
are not independent, that is, if |S ∩ S
0
| = 2. The
expected number of unordered pairs S ∼ S
0 both forming a triangle is
1 :=
1
2
X
S,S
0∈(
V
3)
S∼S
0
Pn,p[BS ∩ BS
0] =
1
2

n
3
3
2

(n − 3)p
5 = 2(n
4
p
5
) → 0, (4.2.22)
where the ￾
n
3

comes from the number of ways of choosing S, the ￾
3
2

comes from the number
of ways of choosing the vertices in common between S and S
0
, and the n − 3 comes from
the number of ways of choosing the third vertex of S
0
. Given that the events {BS}S∈(
V
3)
are
“mostly” independent, it is natural to expect that Xn behaves asymptotically as it would in
the independent case. Indeed we prove:
Claim 4.2.34
Pn,p[Xn = 0] → e
−λ
3
/6
.
Remark 4.2.35 In fact, Xn
d
→ Poi(λ
3
/6). See Exercises 2.18 and 4.9.
The FKG inequality (Theorem 4.2.28) immediately gives one direction. Recall that Pn,p,
as a product measure over edge sets, satisfies the FKG condition and therefore has positive
associations by the FKG inequality. Moreover, the events B
c
S
are decreasing for all S. Hence,
applying positive associations inductively,
Pn,p
hT
S∈(
V
3)
B
c
S
i
≥
Y
S∈(
V
3)
Pn,p[B
c
S
] → e
−λ
3
/6
,
where the limit follows from (4.2.21). As it turns out, the FKG inequality also gives a bound
in the other direction. This is known as Janson’s inequality, which we state in a more general
context.
Janson’s inequality Let X := {0, 1}
F
, where F is finite. Let Bi
, i ∈ I, be a finite collection
of events of the form
Bi
:= {ω ∈ X : ω ≥ β
(i)
}
for some β
(i) ∈ X . Think of these as “bad events” corresponding to a certain subset of
coordinates being set to 1. By definition, the Bis are increasing. Assume P is a positive
product measure on X . Write i ∼ j if β
(i)
r = β
(j)
r = 1 for at least one r and note that Bi
is
independent of Bj
if i  j. Set
1 :=
X
{i,j}
i∼j
P[Bi ∩ Bj].
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Pre212 Coupling
Theorem 4.2.36 (Janson’s inequality). Let X := {0, 1}
F
, where F is finite and P be a
positive product measure on X . Let {Bi}i∈I and 1 be as above. Assume further that there
is ε > 0 such that P[Bi] ≤ ε for all i ∈ I. Then,
Y
i∈I
P[B
c
i
] ≤ P[∩i∈IB
c
i
] ≤ e
1
1−ε
Y
i∈I
P[B
c
i
].
Before proving the theorem, we show that it implies Claim 4.2.34. We have already shown
in (4.2.20) and (4.2.22) that ε → 0 and 1 → 0. Janson’s inequality (Theorem 4.2.36)
immediately implies the claim by (4.2.21).
Proof of Theorem 4.2.36 The lower bound is the FKG inequality.
In the other direction, assume without loss of generality that I = [m]. The first step is to
apply the chain rule to obtain
P[∩i∈IB
c
i
] =
Ym
i=1
P[B
c
i
| ∩j∈[i−1] B
c
j
].
The rest is clever manipulation. For i ∈ [m], let N(i) := {` ∈ [m]: ` ∼ i} and N<(i) :=
N(i) ∩ [i − 1]. Note that Bi
is independent of {B` : ` ∈ [i − 1]\N<(i)}. Hence,
P[Bi
| ∩j∈[i−1] B
c
j
] =
P

Bi ∩
￾
∩j∈[i−1]B
c
j

P[∩j∈[i−1]B
c
j
]
≥
P

Bi ∩
￾
∩j∈N<(i)B
c
j

∩
￾
∩j∈[i−1]\N<(i)B
c
j

P[∩j∈[i−1]\N<(i)B
c
j
]
= P

Bi ∩
￾
∩j∈N<(i)B
c
j
 
∩j∈[i−1]\N<(i)B
c
j

= P

Bi

∩j∈[i−1]\N<(i)B
c
j

×P

∩j∈N<(i)B
c
j

 Bi ∩
￾
∩j∈[i−1]\N<(i)B
c
j

= P [Bi] P

∩j∈N<(i)B
c
j

 Bi ∩
￾
∩j∈[i−1]\N<(i)B
c
j
,
where we used independence for the first term on the last line. By a union bound, the second
term on the last line is
P

∩j∈N<(i)B
c
j

 Bi ∩
￾
∩j∈[i−1]\N<(i)B
c
j

≥ 1 −
X
j∈N<(i)
P

Bj

 Bi ∩
￾
∩j∈[i−1]\N<(i)B
c
j

≥ 1 −
X
j∈N<(i)
P

Bj

 Bi

,
where the last line follows from the FKG inequality. This requires some explanations:
• On the event Bi
, all coordinates ` with β
(i)
` = 1 are fixed to 1, and the other ones are free.
So we can think of P[ · | Bi] as a positive product measure on {0, 1}
F
0
with F
0
:= {` ∈
[m]: β
(i)
` = 0}.
• The event Bj
is increasing, while the event ∩j∈[i−1]\N<(i)B
c
j
is decreasing as the intersection
of decreasing events (see Exercise 4.4).
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge Universi4.2 Stochastic Domination 213
• So we can apply the FKG inequality in the form (4.2.14) to P[ · | Bi].
Combining the last three displays and using 1 + x ≤ e
x
for all x (see Exercise 1.16), we
get
P[∩i∈IB
c
i
] ≤
Ym
i=1

P

B
c
i

+
X
j∈N<(i)
P

Bi ∩ Bj



≤
Ym
i=1
P

B
c
i


1 +
1
1 − ε
X
j∈N<(i)
P

Bi ∩ Bj



≤
Ym
i=1
P

B
c
i

exp


1
1 − ε
X
j∈N<(i)
P

Bi ∩ Bj


 ,
where we used the assumption P[Bi] ≤ ε on the second line. By the definition of 1, we are
done.
4.2.5 F Percolation: RSW Theory and a Proof of Harris’ Theorem
Consider bond percolation (Definition 1.2.1) on the two-dimensional lattice L
2
. Recall that
the percolation function is given by
θ(p) := Pp[|C0| = +∞],
where C0 is the open cluster of the origin. We know from Example 4.2.10 that θ(p) is non￾decreasing. Let
pc(L
2
) := sup{p ≥ 0: θ(p) = 0}
be the critical value. We proved in Section 2.2.4 that there is a non-trivial transition, that is,
pc(L
2
) ∈ (0, 1). See Exercise 2.3 for a proof that pc(L
2
) ∈ [1/3, 2/3].
Our goal in this section is to use the FKG inequality to improve this further to:
Theorem 4.2.37 (Harris’ theorem).
θ(1/2) = 0.
Or, put differently, pc(L
2
) ≥ 1/2.
Remark 4.2.38 This bound is tight, that is, in fact pc(L
2
) = 1/2. The other direction is
known as Kesten’s theorem. See, for example, [BR06a].
Here we present a proof of Harris’ theorem that uses an important tool in percolation
theory, the Russo–Seymour–Welsh (RSW) lemma, an application of the FKG inequality.
Harris’ theorem
To motivate the RSW lemma, we start with the proof of Harris’ theorem.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press214 Coupling
Figure 4.4 Top: the event Od(`). Bottom: the event O#
d
(`).
Proof of Theorem 4.2.37 Fix p = 1/2. We use the dual lattice eL
2
as we did in Section 2.2.4.
Consider the annulus
Ann(`) := [−3`, 3`]
2
\[−`, `]
2
.
The existence of a closed dual cycle inside Ann(`), an event we denote by Od(`), prevents the
possibility of an infinite open path from the origin in the primal lattice L
2
. See Figure 4.4.
That is,
P1/2[|C0| = +∞] ≤
Y
K
k=0
{1 − P1/2[Od(3k
)]} (4.2.23)
for all K, where we took powers of 3 to make the annuli disjoint and therefore independent.
To prove the theorem, it suffices to show that there is a constant c
∗ > 0 such that, for all `,
P1/2[Od(`)] ≥ c
∗
. Then the right-hand side of (4.2.23) tends to 0 as K → +∞.
To simplify further, thinking of Ann(`) as a union of four rectangles [−3`, −`)×[−3`, 3`],
[−3`, 3`] × (`, 3`], and so on, it suffices to consider the event O#
d
(`) that each one of these
rectangles contains a closed dual path connecting its two shorter sides. To be more precise,
for the first rectangle above for instance, the path connects [−3`+1/2, −`−1/2]×{3`−1/2}
to [−3` + 1/2, −` − 1/2] × {−3` + 1/2} and stays inside the rectangle. See Figure 4.4. By
symmetry the probability that such a path exists is the same for all four rectangles. Denote
that probability by ρ`. Moreover, the event that such a path exists is increasing so, although
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.2 Stochastic Domination 215
the four events are not independent, we can apply the FKG inequality (Theorem 4.2.28).
Hence, since O#
d
(`) ⊆ Od(`), we finally get the bound
P1/2[Od(`)] ≥ ρ
4
`
.
The RSW lemma and some symmetry arguments, both of which are detailed below, imply:
Claim 4.2.39 There is some c > 0 such that, for all `,
ρ` ≥ c.
That concludes the proof.
It remains to prove Claim 4.2.39. We first state the RSW lemma.
RSW theory
We have reduced the proof of Harris’ theorem to bounding the probability that certain closed
paths exist in the dual lattice. To be consistent with the standard RSW notation, we switch
to the primal lattice and consider open paths. We also let p take any value in (0, 1).
Let Rn,α(p) be the probability that the rectangle
B(αn, n) := [−n, (2α − 1)n] × [−n, n]
has an open path connecting its left and right sides with the path remaining inside the rec￾tangle. Such a path is called an (open) left-right crossing. The event that a left-right crossing
exists in a rectangle B is denoted by LR(B). We similarly define the event, TB(B), that a top￾bottom crossing exists in B. In essence, the RSW lemma says this: if there is a significant
probability that a left-right crossing exists in the square B(n, n), then there is a significant
probability that a left-right crossing exists in the rectangle B(3n, n). More precisely, here
is a version of the theorem that will be enough for our purposes. (See Exercise 4.10 for a
generalization.)
Lemma 4.2.40 (RSW lemma). For all n ≥ 2 (divisible by 4) and p ∈ (0, 1),
Rn,3(p) ≥
1
256
Rn,1(p)
11 Rn/2,1(p)
12. (4.2.24)
The right-hand side of (4.2.24) depends only on the probability of crossing a square from
left to right. By a duality argument, at p = 1/2, it turns out that this probability is at least 1/2
independently of n. Before presenting a proof of the RSW lemma, we detail this argument
and finish the proof of Harris’ theorem.
Proof of Claim 4.2.39 The point of (4.2.24) is that if Rn,1(1/2) is bounded away from 0
uniformly in n, then so is the left-hand side. By the argument in the proof of Harris’ theorem,
this then implies that a closed cycle exists in Ann(n) with a probability bounded away from
0 as well. Hence, to prove Claim 4.2.39 it suffices to give a lower bound on Rn,1(1/2). It is
crucial that this bound not depend on the “scale” n.
As it turns out, a simple duality-based symmetry argument does the trick. The following
fact about L
2
is a variant of the contour lemma (Lemma 2.2.14). Its proof is similar and
Exercise 4.11 asks for the details (the “if” direction being the non-trivial implication).
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press216 Coupling
Figure 4.5 Illustration of the implication
LR(B
0
1
) ∩ TB(B
0
1 ∩ B
0
2
) ∩ LR(B
0
2
) ⊆ LR(B(3n, n)).
Lemma 4.2.41 There is an open left-right crossing in the primal rectangle [0, n+1]×[0, n]
if and only if there is no closed top-bottom crossing in the dual rectangle [1/2, n + 1/2] ×
[−1/2, n + 1/2].
By symmetry, when p = 1/2, the two events in Lemma 4.2.41 have equal probability. So
they must have probability 1/2 because they form a partition of the space of outcomes. By
monotonicity, that implies Rn,1(1/2) ≥ 1/2 for all n. The RSW lemma then implies the
required bound.
The proof of the RSW lemma involves a clever choice of event that relates the existence
of crossings in squares and rectangles. (Combining crossings of squares into crossings of
rectangles is not as trivial as it might look. Try it before reading the proof.)
Proof of Lemma 4.2.40 There are several steps in the proof.
Step 1: It suffices to bound Rn,3/2(p) We first reduce the proof to finding a bound on
Rn,3/2(p). Let B
0
1
:= B(2n, n) and B
0
2
:= [n, 5n] × [−n, n]. Note that B
0
1 ∪ B
0
2 = B(3n, n)
and B
0
1 ∩ B
0
2 = [n, 3n] × [−n, n]. Then we have the implication
LR(B
0
1
) ∩ TB(B
0
1 ∩ B
0
2
) ∩ LR(B
0
2
) ⊆ LR(B(3n, n)).
See Figure 4.5. Each event on the left-hand side is increasing so the FKG inequality gives
Rn,3(p) ≥ Rn,2(p)
2Rn,1(p).
A similar argument over B(2n, n) gives
Rn,2(p) ≥ Rn,3/2(p)
2Rn,1(p).
Combining the two, we have proved:
Lemma 4.2.42 (Proof of RSW: step 1).
Rn,3(p) ≥ Rn,3/2(p)
4Rn,1(p)
3
. (4.2.25)
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.2 Stochastic Domination 217
Step 2: Bounding Rn,3/2(p) The heart of the proof is to bound Rn,3/2(p) using an event
involving crossings of squares. Let
B1 := B(n, n) = [−n, n] × [−n, n],
B2 := [0, 2n] × [−n, n],
B12 := B1 ∩ B2 = [0, n] × [−n, n],
S := [0, n] × [0, n].
Let 01 be the event that there are paths P1, P2, where P1 is a top-bottom crossing of S and P2
is an open path connecting the left side of B1 to P1 and stays inside B1. Similarly, let 0
0
2
be
the event that there are paths P
0
1
, P
0
2
, where P
0
1
is a top-bottom crossing of S and P
0
2
is an open
path connecting the right side of B2 to P
0
1
and stays inside B2. Then we have the implication
01 ∩ LR(S) ∩ 0
0
2 ⊆ LR(B(3n/2, n)).
See Figure 4.6. By symmetry Pp[01] = Pp[0
0
2
]. Moreover, the events on the left-hand side
are increasing so by the FKG inequality:
Lemma 4.2.43 (Proof of RSW: step 2).
Rn,3/2(p) ≥ Pp[01]
2Rn/2,1(p). (4.2.26)
Step 3: Bounding Pp[01] It remains to bound Pp[01]. That requires several additional defi￾nitions. Let P1 and P2 be top-bottom crossings of S. There is a natural partial order over such
crossings. The path P1 divides S into two subgraphs: [P1}, which includes the left side of S
(including edges on the left incident with P1 but not those edges on P1 itself) and {P1], which
includes the right side of S (and P1 itself). Then, we write P1  P2 if {P1] ⊆ {P2]. Assuming
TB(S) holds, one also gets the existence of a unique rightmost crossing. Roughly speaking, RIGHTMOST
take the union of all top-bottom crossings of S as sets of edges; then the “right boundary” CROSSING
of this set is a top-bottom crossing P
∗
S
such that P
∗
S  P for all top-bottom crossings P of
S. (We accept as a fact the existence of a unique rightmost crossing. See Exercise 4.11 for a
related construction.)
Let IS be the set of (not necessarily open) paths connecting the top and bottom of S and
stay inside S. For P ∈ IS, we let P
0 be the reflection of P in B12\S through the x-axis and
we let P
P0 be the union of P and P
0
. Define [ P
P0} to be the subgraph of B1 to the left of P
P0
(including edges on the left incident with P
P0 but not those edges on P
P0
itself). Let LR+
￾
[
P
P0}

be the event that there is a left-right crossing of [ P
P0} ending on P, that is, that there is an open
path connecting the left side of B1 and P that stays within [ P
P0}. See Figure 4.6. Note that the
existence of a left-right crossing of B1 implies the existence of an open path connecting the
left side of B1 to P
P0
. By symmetry we then get
Pp

LR+
￾
[
P
P0}
 ≥
1
2
Pp[LR(B1)] =
1
2
Rn,1(p). (4.2.27)
Now comes a subtle point. We turn to the rightmost crossing of S – for two reasons:
• First, by uniqueness of the rightmost crossing, {P
∗
S = P}P∈IS
forms a partition of TB(S).
Recall that we are looking to bound a probability from below, and therefore we have to be
careful not to “double count.”
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Pre218 Coupling
Figure 4.6 Top: illustration of the implication 01 ∩ LR(S) ∩ 0
0
2 ⊆ LR(B(3n/2, n)).
Bottom: the event LR+
￾
[
P
P0}

∩ {P = P
∗
S
}; the dashed path is the mirror image of
the rightmost top-bottom crossing in S; the shaded region on the right is the
complement in B1 of the set [ P
P0}. Note that, because in the bottom figure the
left-right path must stay within [ P
P0} by definition of P
∗
S
, the configuration shown in
the top figure where a left-right path (dotted) “travels behind” the top-bottom
crossing of S cannot occur.
• Second, the rightmost crossing has a Markov-like property. Observe that, for P ∈ IS, the
event {P
∗
S = P} depends only the bonds in {P]. In particular, it is independent of the bonds
in [
P
P0}, for example, of the event LR+
￾
[
P
P0}

. Hence,
Pp

LR+
￾
[
P
P0}

| P
∗
S = P

= Pp

LR+
￾
[
P
P0}
. (4.2.28)
Note that the event {P
∗
S = P} is not increasing, as adding more open bonds can shift the
rightmost crossing rightward. Therefore, we cannot use the FKG inequality here.
Combining (4.2.27) and (4.2.28), we get
Pp[01] ≥
X
P∈IS
Pp[P
∗
S = P] Pp

LR+
￾
[
P
P0}

| P
∗
S = P

≥
1
2
Rn,1(p)
X
P∈IS
Pp[P
∗
S = P]
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University 4.3 Coupling of Markov Chains and Application to Mixing 219
=
1
2
Rn,1(p) Pp[TB(S)]
=
1
2
Rn,1(p)Rn/2,1(p).
We have proved:
Lemma 4.2.44 (Proof of RSW: step 3).
Pp[01] ≥
1
2
Rn,1(p)Rn/2,1(p). (4.2.29)
Step 4: Putting everything together Combining (4.2.25), (4.2.26), and (4.2.29) gives
Rn,3(p) ≥ Rn,3/2(p)
4Rn,1(p)
3
≥ [Pp[01]
2Rn/2,1(p)]4Rn,1(p)
3
≥
"
1
2
Rn,1(p)Rn/2,1(p)
2
Rn/2,1(p)
#4
Rn,1(p)
3
.
Collecting the terms concludes the proof of the RSW lemma.
Remark 4.2.45 This argument is quite subtle. It is instructive to read the remark after
[Gri97, Theorem 9.3].
4.3 Coupling of Markov Chains and Application to Mixing
As we have seen, coupling is useful to bound total variation distance. In this section we apply
the technique to bound the mixing time of Markov chains.
4.3.1 Bounding the Mixing Time via Coupling
Let P be an irreducible, aperiodic Markov transition matrix on the finite state space V with
stationary distribution π. Recall from Definition 1.1.35 that, for a fixed 0 < ε < 1/2, the
mixing time of P is
tmix(ε) := min{t: d(t) ≤ ε},
where
d(t) := max
x∈V
kP
t
(x, ·) − πkTV.
It will be easier to work with
d¯(t) := max
x,y∈V
kP
t
(x, ·) − P
t
(y, ·)kTV.
The quantities d(t) and d¯(t) are related in the following way.
Lemma 4.3.1
d(t) ≤ d¯(t) ≤ 2d(t) ∀t.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press220 Coupling
Proof The second inequality follows from an application of the triangle inequality.
For the first inequality, note that by definition of the total variation distance and the sta￾tionarity of π,
kP
t
(x, ·) − πkTV = sup
A⊆V
|P
t
(x, A) − π(A)|
= sup
A⊆V






X
y∈V
π( y)[P
t
(x, A) − P
t
(y, A)]






≤ sup
A⊆V
X
y∈V
π( y)|P
t
(x, A) − P
t
(y, A)|
≤
X
y∈V
π( y)

sup
A⊆V
|P
t
(x, A) − P
t
(y, A)|

≤
X
y∈V
π( y)kP
t
(x, ·) − P
t
(y, ·)kTV
≤ max
x,y∈V
kP
t
(x, ·) − P
t
(y, ·)kTV.
Coalescence Recall that a Markovian coupling of P with itself is a Markov chain (Xt
, Yt)t
on V × V with transition matrix Q satisfying, for all x, y, x
0
, y
0 ∈ V, X
z
0
Q((x, y), (x
0
,z
0
)) = P(x, x
0
),
X
z
0
Q((x, y), (z
0
, y
0
)) = P( y, y
0
).
COALESCING We say that a Markovian coupling is coalescing if further, for all z ∈ V,
x
0
6= y
0 =⇒ Q((z,z), (x
0
, y
0
)) = 0.
Let (Xt
, Yt) be a coalescing Markovian coupling of P. By the coalescing condition, if
Xs = Ys
then Xt = Yt for all t ≥ s. That is, once (Xt) and (Yt) meet, they remain equal. Let
COALESCENCE τcoal be the coalescence time (also called coupling time), that is,
TIME
τcoal := inf{t ≥ 0: Xt = Yt}.
The key to the coupling approach to mixing times is the following immediate consequence
of the coupling inequality (Lemma 4.1.11). For any starting point (x, y),
kP
t
(x, ·) − P
t
(y, ·)kTV ≤ P(x,y)[Xt 6= Yt] = P(x,y)[τcoal > t]. (4.3.1)
Combining (4.3.1) and Lemma 4.3.1, we get the main tool of this section.
Theorem 4.3.2 (Bounding the mixing time: coupling method). Let (Xt
, Yt) be a coalescing
Markovian coupling of an irreducible transition matrix P on a finite state space V with
stationary distribution π. Then,
d(t) ≤ max
x,y∈V
P(x,y)[τcoal > t].
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.3 Coupling of Markov Chains and Application to Mixing 221
In particular,
tmix(ε) ≤ inf 
t ≥ 0: P(x,y)[τcoal > t] ≤ ε ∀x, y
	
.
We give a few simple examples in the next subsection. First, we discuss a classical result.
Example 4.3.3 (Doeblin’s condition). Let P be a transition matrix on a countable space V.
One form of Doeblin’s condition (also called a minorization condition) is: there is s ∈ Z+ DOEBLIN’S
and δ > 0 such that CONDITION
sup
z∈V
inf
w∈V
P
s
(w,z) > δ.
In words, there is a state z0 ∈ V such that, starting from any state w ∈ V, the probability of
reaching z0 in exactly s steps is at least δ (which does not depend on w). Assume such a z0
exists.
We construct a coalescing Markovian coupling (Xt
, Yt) of P. Assume first that s = 1 and
let
P˜(w,z) =
1
1 − δ
[P(w,z) − δ1{z = z0}] .
It can be checked that P˜ is a stochastic matrix on V provided z0 satisfies the condition above
(see Exercise 4.13). We use a technique known as splitting. While Xt 6= Yt
, at the next time SPLITTING
step: (i) with probability δ we set Xt+1 = Yt+1 = z0, (ii) otherwise we pick Xt+1 ∼ P˜(Xt
, · )
and Yt+1 ∼ P˜(Yt
, · ) independently. On the other hand, if Xt = Yt
, we maintain the equality
and pick the next state according to P. Put differently, the coupling Q is defined as: if x 6= y,
Q((x, y), (x
0
, y
0
)) = δ1{x
0 = y
0 = z0} + (1 − δ)P˜(x, x
0
)P˜(y, y
0
),
while if x = y,
Q((x, x), (x
0
, x
0
)) = P(x, x
0
).
Observe that, in case (i) above, coalescence occurs at time t + 1. In case (ii), coalescence
may or may not occur at time t + 1. In other words, while Xt 6= Yt
, coalescence occurs at
the next step with probability at least δ. So τcoal is stochastically dominated by a geometric
random variable with success probability δ, or
max
x,y∈V
P(x,y)[τcoal > t] ≤ (1 − δ)
t
.
By Theorem 4.3.2,
max
x∈V
kP
t
(x, ·) − πkTV ≤ (1 − δ)
t
.
Exponential decay of the worst-case total variation distance to the stationary distribution is
referred to as uniform geometric ergodicity. UNIFORM
GEOMETRIC
ERGODICITY
Suppose now that s > 1. We apply the argument above to the chain P
s
this time. We get
max
x,y∈V
P(x,y)[τcoal > ts] ≤ (1 − δ)
t
,
so that, after a change of variable,
max
x∈V
kP
t
(x, ·) − πkTV ≤ (1 − δ)
bt/sc
.
So, we have shown that uniform geometric ergodicity is implied by Doeblin’s condition.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press222 Coupling
We note however that the rate of decay derived from this technique can be very slow.
For instance, the condition always holds when P is finite, irreducible, and aperiodic (as
follows from Lemma 1.1.32), but a straight application of the technique may lead to a bound
depending badly on the size of the state space V (see Exercise 4.14). J
4.3.2 F Random Walks: Mixing on Cycles, Hypercubes, and Trees
In this section, we consider lazy simple random walk on various graphs. By this we mean
that the walk stays put with probability 1/2 and otherwise picks an adjacent vertex uniformly
at random. In each case, we construct a coupling to bound the mixing time. As a reference,
we compare our upper bounds to the diameter-based lower bound we will derive in Sec￾tion 5.2.3. Specifically, by Claim 5.2.25, for a finite, reversible Markov chain with stationary
distribution π and diameter 1 we have the lower bound
tmix(ε) = 

12
log(n ∨ π
−1
min)

,
where πmin is the smallest value taken by π.
Cycle
Let (Zt) be lazy simple random walk on the cycle of size n, Zn := {0, 1, . . . , n − 1}, where
i ∼ j if |j − i| = 1 (mod n). For any starting points x, y, we construct a Markovian coupling
(Xt
, Yt) of this chain. Set (X0, Y0) := (x, y). At each time, flip a fair coin. On heads, Yt
stays put and Xt moves one step, the direction of which is uniform at random. On tails,
proceed similarly with the roles of Xt and Yt reversed. Let Dt be the clockwise distance
between Xt and Yt
. Observe that, by construction, (Dt) is simple random walk on {0, . . . , n}
and τcoal = τ
D
{0,n}
, the first time (Dt) hits {0, n}.
We use Markov’s inequality (Theorem 2.1.1) to bound P(x,y)[τ
D
{0,n} > t]. Denote by
D0 = dx,y
the starting distance. By Wald’s second identity (Theorem 3.1.40),
E(x,y)

τ
D
{0,n}

= dx,y(n − dx,y).
Applying Theorem 4.3.2 and Markov’s inequality, we get
d(t) ≤ max
x,y∈V
P(x,y)[τcoal > t]
≤ max
x,y∈V
E(x,y)

τ
D
{0,n}

t
= max
x,y∈V
dx,y(n − dx,y)
t
≤
n
2
4t
,
or:
Claim 4.3.4
tmix(ε) ≤
n
2
4ε
.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.3 Coupling of Markov Chains and Application to Mixing 223
By the diameter-based lower bound on mixing in Section 5.2.3, this bound gives the cor￾rect order of magnitude in n up to logarithmic factors. Indeed, the diameter is 1 = n/2 and
πmin = 1/n so that Claim 5.2.25 gives
tmix(ε) ≥
n
2
64 log n
for n large enough. Exercise 4.15 sketches a tighter lower bound.
Hypercube
Let (Zt)t∈Z+ be lazy simple random walk on the n-dimensional hypercube Z
n
2
:= {0, 1}
n
,
where i ∼ j if ki−jk1 = 1. We denote the coordinates of Zt by (Z
(1)
t
, . . . , Z
(n)
t
). This is equiv￾alent to performing the Glauber dynamics chain on an empty graph (see Definition 1.2.8):
at each step, we first pick a coordinate uniformly at random, then refresh its value. Because
of the way the updating is done, the chain stays put with probability 1/2 at each time as
required.
Inspired by this observation, the coupling (Xt
, Yt) started at (x, y) is the following. At
each time t, pick a coordinate i uniformly at random in [n], pick a bit value b in {0, 1}
uniformly at random independent of the coordinate choice. Set both i coordinates to b, that
is, X
(i)
t = Y
(i)
t = b. By design we reach coalescence when all coordinates have been updated
at least once.
The following standard bound from the coupon collector’s problem (see Example 2.1.4)
is what is needed to conclude.
Lemma 4.3.5 Let τcoll be the time it takes to update each coordinate at least once. Then, for
any c > 0,
P [τcoll > dn log n + cne] ≤ e
−c
.
Proof Let Bi be the event that the ith coordinate has not been updated by time dn log n+cne.
Then, using that 1 − x ≤ e
−x
for all x (see Exercise 1.16),
P[τcoll > dn log n + cne] ≤
X
i
P[Bi]
=
X
i

1 −
1
n
dn log n+cne
≤ n exp
−
n log n + cn
n

= e
−c
.
Applying Theorem 4.3.2, we get
d(dn log n + cne) ≤ max
x,y∈V
P(x,y)[τcoal > dn log n + cne]
≤ P[τcoll > dn log n + cne]
≤ e
−c
.
Hence, for cε > 0 large enough:
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press224 Coupling
Claim 4.3.6
tmix(ε) ≤ dn log n + cεne.
Again we get a quick lower bound using the diameter-based result from Section 5.2.3.
Here 1 = n and πmin = 1/2
n
so that Claim 5.2.25 gives
tmix(ε) ≥
n
2
12 log n + (4 log 2)n
= (n)
for n large enough. So the upper bound we derived above is off at most by a logarithmic
factor in n. In fact:
Claim 4.3.7
tmix(ε) ≥
1
2
n log n − O(n).
Proof For simplicity, we assume that n is odd. Let Wt be the number of 1s, or Hamming
HAMMING weight, at time t. Let A be the event that the Hamming weight is ≤ n/2. To bound the mixing
WEIGHT time, we use the fact that for any z0,
d(t) ≥ kP
t
(z0, ·) − πkTV ≥ |P
t
(z0, A) − π(A)|. (4.3.2)
Under the stationary distribution, the Hamming weight is equal in distribution to a Bin(n,
1/2). In particular, the probability that a majority of coordinates are 0 is 1/2. That is,
π(A) = 1/2.
On the other hand, let (Zt) start at z0, the all-1 vector. Let Ut be the number of updated
coordinates up to time t in the Glauber dynamics representation of the chain discussed before
the statement of Lemma 4.3.5. By the definition of A,
|P
t
(z0, A) − π(A)| = |P[Wt ≤ n/2] − 1/2|. (4.3.3)
We use Chebyshev’s inequality (Theorem 2.1.2) to bound the probability on the right-hand
side. So we need to compute the expectation and variance of Wt
.
Observe that, conditioned on Ut
, the Hamming weight Wt
is equal in distribution to
Bin(Ut
, 1/2) + (n − Ut) as the updated coordinates are uniform and the other ones are 1.
Thus we have
E[Wt] = E[E[Wt
| Ut]]
= E

1
2
Ut + (n − Ut)

= E

n −
1
2
Ut

= n −
1
2
n

1 −

1 −
1
n
t
=
n
2

1 +

1 −
1
n
t
, (4.3.4)
where on the fourth line we used the fact that E[Ut] = n
h
1 −
￾
1 −
1
n
t
i
by summing over
the coordinates and using linearity of expectation.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Pres4.3 Coupling of Markov Chains and Application to Mixing 225
As to the variance, using again the observation above about the distribution of Wt
given Ut
,
Var[Wt] = E[Var[Wt
| Ut]] + Var[E[Wt
| Ut]]
=
1
4
E [Ut] +
1
4
Var[Ut]. (4.3.5)
It remains to compute Var[Ut]. Let I
(i)
t be 1 if coordinate i has not been updated up to time t
and 0 otherwise. Note that for i 6= j,
Cov[I
(i)
t
, I
(j)
t
] = E[I
(i)
t
I
(j)
t
] − E[I
(i)
t
]E[I
(j)
t
]
=

1 −
2
n
t
−

1 −
1
n
2t
=

1 −
2
n
t
−

1 −
2
n
+
1
n
2
t
≤ 0,
that is, I
(i)
t and I
(j)
t are negatively correlated, while
Var[I
(i)
t
] = E[(I
(i)
t
)
2
] − (E[I
(i)
t
])2 ≤ E[I
(i)
t
] =

1 −
1
n
t
.
Then, writing n − Ut as the sum of these indicators, we have
Var[Ut] = Var[n − Ut]
=
Xn
i=1
Var[I
(i)
t
] + 2
X
i<j
Cov[I
(i)
t
, I
(j)
t
]
≤ n

1 −
1
n
t
.
Plugging this back into (4.3.5), we get
Var[Wt] ≤
n
4

1 −

1 −
1
n
t
+
n
4

1 −
1
n
t
=
n
4
.
For tα =
1
2
n log n − n log α
2 with α > 0, by (4.3.4),
E[Wtα
] =
n
2
+ e
tα(−1/n+2(1/n
2
)) =
n
2
+
α
2
√
n + o(1),
where we used that by a Taylor expansion, for |z| ≤ 1/2, log (1 − z) = −z + 2(z
2
). Fix
0 < ε < 1/2. By Chebyshev’s inequality, for tα =
1
2
n log n − n log α
2
and n large enough,
P[Wtα ≤ n/2] ≤ P[|Wtα − E[Wtα
]| ≥ (α/2)√
n] ≤
n/4
(α/2)2n
≤
1
2
− ε
for α large enough. By (4.3.2) and (4.3.3), that implies d(tα) ≥ ε and we are done.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press226 Coupling
The previous proof relies on a “distinguishing statistic.” Recall from Lemma 4.1.19 that for
any random variables X, Y and mapping h it holds that
kµh(X) − µh( y)kTV ≤ kµX − µY kTV,
where µZ is the law of Z. The mapping used in the proof of the claim is the Hamming weight.
In essence, we gave a lower bound on the total variation distance between the laws of the
Hamming weight at stationarity and under P
t
(z0, · ). See Exercise 4.16 for a more general
treatment of the distinguishing statistic approach.
Remark 4.3.8 The upper bound in Claim 4.3.6 is indeed off by a factor of 2. See [LPW06,
Theorem 18.3] for an improved upper bound and a discussion of the so-called cutoff phe￾CUTOFF nomenon. The latter refers to the fact that for all 0 < ε < 1/2 it can be shown in this case
that
lim
n→+∞
t
(n)
mix(ε)
t
(n)
mix(1 − ε)
= 1,
where t
(n)
mix(ε) is the mixing time on the n-dimensional hypercube. In words, for large n, the
total variation distance drops from 1 to 0 in a short time window. See Exercise 5.10 for a
necessary condition for cutoff.
b-ary tree
Let (Zt)t∈Z+ be lazy simple random walk on the `-level rooted b-ary tree, bT
`
b
, with ` ≥ 2. The
root, 0, is on level 0 and the leaves, L, are on level `. All vertices have degree b + 1, except
for the root which has degree b and the leaves which have degree 1. By Example 1.1.29
(noting that laziness makes no difference), the stationary distribution is
π(x) :=
δ(x)
2(n − 1)
,
where n is the number of vertices and δ(x) is the degree of x. We used that a tree on n vertices
has n − 1 edges (Corollary 1.1.7). We construct a coupling (Xt
, Yt) of this chain started at
(x, y). Assume without loss of generality that x is no further from the root than y, which we
denote by x 4 y (which, here, does not mean that y is a descendant of x). The coupling has
two stages:
• In the first stage, at each time, flip a fair coin. On heads, Yt stays put and Xt moves one step
chosen uniformly at random among its neighbors. Similarly, on tails, reverse the roles of
Xt and Yt
. Do this until Xt and Yt are on the same level.
• In the second stage, that is, once the two chains are on the same level, at each time first
let Xt move as a lazy simple random walk on bT
`
b
. Then let Yt move in the same direction
as Xt
, that is, if Xt moves closer to the root, so does Yt
, and so on.
By construction, Xt 4 Yt for all t. The key observation is the following. Let τ
∗ be the first
time (Xt) visits the root after visiting the leaves. By time τ
∗
, the two chains have necessarily
met: because Xt 4 Yt
, when Xt reaches the leaves, so does Yt
; after that time, the coupling is
in the second stage so Xt and Yt remain on the same level; in particular, when Xt reaches the
root (after visiting the leaves), so does Yt
. Hence τcoal ≤ τ
∗
. Intuitively, the mixing time is
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.3 Coupling of Markov Chains and Application to Mixing 227
indeed dominated by the time it takes to reach the root from the worst starting point, a leaf.
See Figure 4.7 and the corresponding lower bound argument.
To estimate P(x,y)[τ
∗ > t], we use Markov’s inequality (Theorem 2.1.1), for which we need
a bound on E(x,y)[τ
∗
]. We note that E(x,y)[τ
∗
] is less than the mean time for the walk to go
from the root to the leaves and back. Let Lt be the level of Xt and let N be the corresponding
network (where the conductances are equal to the number of edges on each level of the tree).
In terms of Lt
, the quantity we seek to bound is the mean of τ0,`, the commute time of the
chain (Lt) between the states 0 and `. By the commute time identity (Theorem 3.3.34),
E[τ0,`] = cN R(0 ↔ `), (4.3.6)
where
cN = 2
X
e={x,y}∈N
c(e) = 4(n − 1),
where we simply counted the number of edges in bT
`
b
and the extra factor of 2 accounts
for self-loops. Using network reduction techniques, we computed the effective resistance
R(0 ↔ `) in Examples 3.3.21 and 3.3.22 – without self-loops. Of course, adding self￾loops does not affect the effective resistance as we can use the same voltage and current. So,
ignoring them, we get
R(0 ↔ `) =
X
`−1
j=0
r(j, j + 1) =
X
`−1
j=0
b
−(j+1) =
1
b
·
1 − b
−`
1 − b
−1
, (4.3.7)
which implies
1
b
≤ R(0 ↔ `) ≤
1
b − 1
≤ 1.
Finally, applying Theorem 4.3.2 and Markov’s inequality and using (4.3.6), we get
d(t) ≤ max
x,y∈V
P(x,y)[τ
∗ > t]
≤ max
x,y∈V
E(x,y)[τ
∗
]
t
≤
E[τ0,`]
t
≤
4n
t
,
or:
Claim 4.3.9
tmix(ε) ≤
4n
ε
.
This time the diameter-based bound is far off. We have 1 = 2` = 2(log n) and πmin =
1/2(n − 1) so that Claim 5.2.25 gives
tmix(ε) ≥
(2`)
2
12 log n + 4 log(2(n − 1))
= (log n)
for n large enough.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press228 Coupling
Figure 4.7 Setup for the lower bound on the mixing time on a b-ary tree. (Here
b = 2.)
Here is a better lower bound. We take b = 2 to simplify. Intuitively, the mixing time is sig￾nificantly greater than the squared diameter because the chain tends to be pushed away from
the root. Consider the time it takes to go from the leaves on one side of the root to the leaves
on the other, both of which have substantial weight under the stationary distribution. That
typically takes time exponential in the diameter – that is, linear in n. Indeed, one first has to
reach the root, which by the gambler’s ruin problem (Example 3.1.43), takes an exponential
in ` number of “excursions” (see Claim 3.1.44 (ii)).
Formally, let x0 be a leaf of bT
`
b
and let A be the set of vertices “on the other side of root
(inclusively),” that is, vertices whose graph distance from x0 is at least `. See Figure 4.7.
Then, π(A) ≥ 1/2 by symmetry. We use the fact that
kP
t
(x0, ·) − πkTV ≥ |P
t
(x0, A) − π(A)|
to bound the mixing time from below. We claim that, started at x0, the walk takes time linear
in n to reach A with non-trivial probability.
Consider again the level Lt of Xt
. Using definition of the effective resistance (Defini￾tion 3.3.19) as well as the expression for it in (4.3.7), we have
P`[τ0 < τ +
`
] =
1
c(`) R(0 ↔ `)
=
1
b
`
·
b − 1
1 − b
−`
=
b − 1
b
` − 1
= O

1
n

.
Hence, started from the leaves, the number of excursions back to the leaves needed to reach
the root for the first time is geometric with success probability O(n
−1
). Each such excursion
takes time at least 2 (which corresponds to going right back to the leaves after the first
step). So P
t
(x0, A) is bounded above by the probability that at least one such excursion was
successful among the first t/2 attempts. That is,
P
t
(x0, A) ≤ 1 −
￾
1 − O
￾
n
−1
t/2
<
1
2
− ε,
for all t ≤ αεn with αε > 0 small enough and
kP
αεn
(x0, ·) − πkTV ≥ |P
αεn
(x0, A) − π(A)| > ε.
We have proved that tmix(ε) ≥ αεn.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Pre4.3 Coupling of Markov Chains and Application to Mixing 229
4.3.3 Path Coupling
Path coupling is a method for constructing Markovian couplings from “simpler” couplings.
The building blocks are one-step couplings starting from pairs of initial states that are close
in some “dissimilarity graph.”
Let (Xt) be an irreducible Markov chain on a finite state space V with transition matrix P
and stationary distribution π. Assume that we have a dissimilarity graph H0 = (V0, E0) on DISSIMILARITY
GRAPH, PATH
METRIC
V0 := V with edge weights w0 : E0 → R+. This graph need not have the same edges as the
transition graph of (Xt). We extend w0 to the path metric
w0(x, y) := inf(Xm−1
i=0
w0(xi
, xi+1): x = x0, x1, . . . , xm = y is a path in H0
)
,
where the infimum is over all paths connecting x and y in H0. We call a path achieving the
infimum a minimum-weight path. It is straightforward to check that w0 satisfies the triangle
inequality. Let
10 := max
x,y
w0(x, y)
be the weighted diameter of H0.
Theorem 4.3.10 (Path coupling method). Assume that
w0(u, v) ≥ 1
for all {u, v} ∈ E0. Assume further that there exists κ ∈ (0, 1) such that:
• (Local couplings) For all x, y with {x, y} ∈ E0, there is a coupling (X
∗
, Y
∗
) of P(x, ·) and
P( y, ·) satisfying the contraction property
E[w0(X
∗
, Y
∗
)] ≤ κ w0(x, y). (4.3.8)
Then,
d(t) ≤ 10 κ
t
,
or
tmix(ε) ≤

log 10 + log ε
−1
log κ
−1

.
Proof The crux of the proof is to extend (4.3.8) to arbitrary pairs of vertices.
Claim 4.3.11 (Global coupling). For all x, y ∈ V there is a coupling (X
∗
, Y
∗
) of P(x, ·) and
P( y, ·) such that (4.3.8) holds.
Iterating the coupling in this last claim immediately implies the existence of a coalescing
Markovian coupling (Xt
, Yt) of P such that
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press230 Coupling
Figure 4.8 Coupling of P(x
0
, ·) and P( y
0
, ·) constructed from a sequence of local
couplings (Z
∗
0,0, Z
∗
0,1), . . . , (Z
∗
0,m−1
, Z
∗
0,m−1
).
E(x,y)[w0(Xt
, Yt)] = E(x,y) [E[w0(Xt
, Yt) | Xt−1, Yt−1]]
≤ E(x,y) [κ w0(Xt−1, Yt−1)]
≤ · · ·
≤ κ
t E(x,y)[w0(X0, Y0)]
= κ
t w0(x, y)
≤ κ
t 10.
By assumption, 1{x6=y} ≤ w0(x, y) so that by the coupling inequality and Lemma 4.3.1, we
have
d(t) ≤ d¯(t) ≤ max
x,y
P(x,y)[Xt 6= Yt] ≤ max
x,y
E(x,y)[w0(Xt
, Yt)] ≤ κ
t 10,
which implies the theorem.
Remark 4.3.12 In essence, w0 satisfies a form of Lyapounov condition (i.e., (3.3.15)) with
a “geometric drift.” See, for example, [MT09, chapter 15].
It remains to prove Claim 4.3.11.
Proof of Claim 4.3.11 Fix x
0
, y
0 ∈ V such that {x
0
, y
0
} is not an edge in the dissimilarity
graph H0. The idea is to combine the local couplings on a minimum-weight path between
x
0
and y
0
in H0. Let x
0 = x0 ∼ · · · ∼ xm = y
0 be such a path. For all i = 0, . . . , m − 1, let
(Z
∗
i,0, Z
∗
i,1) be a coupling of P(xi
, ·) and P(xi+1, ·) satisfying the contraction property (4.3.8).
Then we proceed as follows. Set Z
(0) := Z
∗
0,0 and Z
(1) := Z
∗
0,1. Then iteratively pick Z
(i+1)
according to the law P[Z
∗
i,1 ∈ · | Z
∗
i,0 = Z
(i)
]. By induction on i, (X
∗
, Y
∗
) := (Z
(0)
, Z
(m)
) is then
a coupling of P(x
0
, ·) and P( y
0
, ·). See Figure 4.8.
To be more formal, define the transition matrix
Ri(z
(i)
,z
(i+1)) := P[Z
∗
i,1 = z
(i+1) | Z
∗
i,0 = z
(i)
].
Observe that
X
z
(i+1)
Ri(z
(i)
,z
(i+1)) = 1 (4.3.9)
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.3 Coupling of Markov Chains and Application to Mixing 231
and
X
z
(i)
P(xi
,z
(i)
)Ri(z
(i)
,z
(i+1)) = P(xi+1,z
(i+1)), (4.3.10)
by construction of the coupling (Z
∗
i,0, Z
∗
i,1) and the definition of Ri
. The law of the full coupling
(Z
(0)
, . . . , Z
(m)
)
is
P[(Z
(0)
, . . . , Z
(m)
) = (z
(0)
, . . . ,z
(m)
)]
= P(x0,z
(0))R0(z
(0)
,z
(1)) · · · Rm−1(z
(m−1)
,z
(m)
).
Using (4.3.9) and (4.3.10) inductively gives, respectively,
P[X
∗ = z
(0)] = P[Z
(0) = z
(0)] = P(x0,z
(0))
and
P[Y
∗ = z
(m)
] = P[Z
(m) = z
(m)
] = P(xm,z
(m)
),
as required.
By the triangle inequality for w0, the coupling (X
∗
, Y
∗
) satisfies
E[w0(X
∗
, Y
∗
)] = E

w0(Z
(0)
, Z
(m)
)

≤
Xm−1
i=0
E

w0(Z
(i)
, Z
(i+1))

≤
Xm−1
i=0
κ w0(xi
, xi+1)
= κ w0(x
0
, y
0
),
where, on the third line, we used (4.3.8) for adjacent pairs and the last line follows from the
fact that we chose a minimum-weight path.
That concludes the proof of the theorem.
We illustrate the path coupling method in the next subsection. See Exercise 4.17 for an
optimal transport perspective on the path coupling method.
4.3.4 F Ising Model: Glauber Dynamics at High Temperature
Let G = (V, E) be a finite, connected graph with maximal degree δ¯. Define X := {−1, +1}
V
.
Recall from Example 1.2.5 that the (ferromagnetic) Ising model on V with inverse temper￾ature β is the probability distribution over spin configurations σ ∈ X given by
µβ (σ) :=
1
Z(β)
e
−βH(σ)
,
where
H(σ) := −X
i∼j
σiσj
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press232 Coupling
is the Hamiltonian and
Z(β) :=
X
σ∈X
e
−βH(σ)
is the partition function. In this context, recall that vertices are often referred to as sites.
The single-site Glauber dynamics (Definition 1.2.8) of the Ising model is the Markov chain
on X , which, at each time, selects a site i ∈ V uniformly at random and updates the spin
σi according to µβ (σ) conditioned on agreeing with σ at all sites in V\{i}. Specifically, for
γ ∈ {−1, +1}, i ∈ V, and σ ∈ X , let σ
i,γ be the configuration σ with the state at i being set
to γ . Then, letting n = |V|, the transition matrix of the Glauber dynamics is
Qβ (σ, σ
i,γ
) :=
1
n
·
e
γβSi(σ)
e
−βSi(σ) + e
βSi(σ)
=
1
n

1
2
+
1
2
tanh(γβSi(σ))
, (4.3.11)
where
Si(σ) :=
X
j∼i
σj
.
All other transitions have probability 0. Recall that this chain is irreducible and reversible
with respect to µβ . In particular, µβ is the stationary distribution of Qβ .
In this section, we give an upper bound on the mixing time, tmix(ε), of Qβ using path
FAST MIXING coupling. We say that the Glauber dynamics is fast mixing if tmix(ε) = O(n log n). We first
make a simple observation:
Claim 4.3.13 (Glauber dynamics: lower bound on mixing).
tmix(ε) = (n) ∀β > 0.
Proof Similarly to what we did in Section 4.3.2 in the context of random walk on the
hypercube (but for a lower bound this time), we use a coupon collecting argument (see
Example 2.1.4). Let σ¯ be the all-(−1) configuration and let A be the set of configurations
where at least half of the sites are +1. Then, by symmetry, µβ (A) = µβ (A
c
) = 1/2, where
we assumed for simplicity that n is odd. By definition of the total variation distance,
d(t) ≥ kQ
t
β
(σ¯ , ·) − µβ (·)kTV
≥ |Q
t
β
(σ¯ , A) − µβ (A)|
= |Q
t
β
(σ¯ , A) − 1/2|. (4.3.12)
So it remains to show that by time c n, for c > 0 small, the chain is unlikely to have reached
A. That happens if, say, fewer than a third of the sites have been updated. Using the notation
of Example 2.1.4, we are seeking a bound on Tn,n/3, that is, the time to collect n/3 coupons
out of n.
We can write this random variable as a sum of n/3 independent geometric variables
Tn,n/3 =
Pn/3
i=1
τn,i
, where E[τn,i] =
￾
1 −
i−1
n
−1
and Var[τn,i] ≤
￾
1 −
i−1
n
−2
. Hence, ap￾proximating the Riemann sums in the next two displays by integrals, we get
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Pre4.3 Coupling of Markov Chains and Application to Mixing 233
E[Tn,n/3] =
Xn/3
i=1

1 −
i − 1
n
−1
= n
Xn
j=2n/3+1
j
−1 = 2(n) (4.3.13)
and
Var[Tn,n/3] ≤
Xn/3
i=1

1 −
i − 1
n
−2
= n
2 Xn
j=2n/3+1
j
−2 = 2(n). (4.3.14)
So by Chebyshev’s inequality (Theorem 2.1.2),
P[|Tn,n/3 − E[Tn,n/3]| ≥ ε n] ≤
Var[Tn,n/3]
(ε n)
2
→ 0,
by (4.3.14). In view of (4.3.13), taking ε > 0 small enough and n large enough, we have
shown that for t ≤ cεn for some cε > 0,
Q
t
β
(σ¯ , A) ≤ 1/3,
which proves the claim by (4.3.12) and the definition of the mixing time (Definition 1.1.35).
Remark 4.3.14 In fact, Ding and Peres proved that tmix(ε) = (n log n) for any graph on
n vertices [DP11]. In Claim 4.3.7, we treated the special case of the empty graph, which is
equivalent to lazy random walk on the hypercube. See also Section 5.3.4 for a much stronger
lower bound at low temperature for certain graphs with good “expansion properties.”
In our main result of this section, we show that the Glauber dynamics of the Ising model
is fast mixing when the inverse temperature β is small enough as a function of the maximum
degree.
Claim 4.3.15 (Glauber dynamics: fast mixing at high temperature).
β < δ¯−1 =⇒ tmix(ε) = O(n log n).
Proof We use path coupling. Let H0 = (V0, E0), where V0 := X and {σ, ω} ∈ E0 if
1
2
kσ − ωk1 = 1 (i.e., they differ in exactly one coordinate) with unit weight on all edges. To
avoid confusion, we reserve the notation ∼ for adjacency in G.
Let {σ, ω} ∈ E0 differ at coordinate i. We construct a coupling (X
∗
, Y
∗
) of Qβ (σ, ·) and
Qβ (ω, ·). We first pick the same coordinate i∗ to update. If i∗ is such that all its neighbors
in G have the same state in σ and ω, that is, if σj = ωj for all j ∼ i∗, we update X
∗
from
σ according to the Glauber rule and set Y
∗
:= X
∗
. Note that this includes the case i∗ = i.
Otherwise, that is, if i∗ ∼ i, we proceed as follows. From the state σ, the probability of
updating site i∗ to state γ ∈ {−1, +1} is given by the expression in brackets in (4.3.11), and
similarly for ω. Unlike the previous case, we cannot guarantee that the update is identical
in both chains. In order to minimize the chance of increasing the distance between the two
chains, we use a monotone coupling, which recall from Example 4.1.17 is maximal in the
two-state case. Specifically, we pick a uniform random variable U in [−1, 1] and set
X
∗
i∗
:=
(
+1 if U ≤ tanh(βSi∗
(σ)),
−1 otherwise,
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press234 Coupling
and
Y
∗
i∗
:=
(
+1 if U ≤ tanh(βSi∗
(ω)),
−1 otherwise.
We set X
∗
j
:= σj and Y
∗
j
:= ωj for all j 6= i
∗
. The expected distance between X
∗
and Y
∗
is
then
E[w0(X
∗
, Y
∗
)]
= 1 −
1
n
|{z}
(a)
+
1
n
X
j:j∼i
1
2


tanh(βSj(σ)) − tanh(βSj(ω))


| {z }
(b)
, (4.3.15)
where (a) in Equation (4.3.14) corresponds to i∗ = i, in which case w0(X
∗
, Y
∗
) = 0; and (b)
in Equation (4.3.14) corresponds to i∗ ∼ i, in which case w0(X
∗
, Y
∗
) = 2 with probability
1
2
| tanh(βSi∗
(σ)) − tanh(βSi∗
(ω))|
by our coupling; and otherwise w0(X
∗
, Y
∗
) = w0(σ, ω) = 1. To bound (b) in Equation
(4.3.14), we note that for any j ∼ i,


tanh(βSj(σ)) − tanh(βSj(ω))

 = tanh(β(s + 2)) − tanh(βs), (4.3.16)
where
s := Sj(σ) ∧ Sj(ω).
The derivative of tanh is maximized at 0, where it is equal to 1. So the right-hand side
of (4.3.16) is ≤ β(s + 2) − βs = 2β. Plugging this back into (4.3.15) and using 1 − x ≤ e
−x
for all x (see Exercise 1.16), we get
E[w0(X
∗
, Y
∗
)] ≤ 1 −
1 − δβ¯
n
≤ exp
−
1 − δβ¯
n

= κ w0(σ, ω),
where
κ := exp
−
1 − δβ¯
n

< 1
by our assumption on β. The diameter of H0 is 10 = n. By Theorem 4.3.10,
tmix(ε) ≤

log 10 + log ε
−1
log κ
−1

=

n(log n + log ε
−1
)
1 − δβ¯

,
which implies the claim.
Remark 4.3.16 A slighlty more careful analysis shows that the condition δ¯ tanh(β) < 1 is
enough for the claim to hold. See [LPW06, Theorem 15.1].
4.4 Chen–Stein Method
The Chen–Stein method serves to establish Poisson approximation results with quantitative
bounds in certain settings with dependent variables that are common, for instance, in random
graphs and string statistics.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.4 Chen–Stein Method 235
Setting The basic setup is a sum of Bernoulli (i.e., {0, 1}-valued) random variables {Xi}
n
i=1
W =
Xn
i=1
Xi
, (4.4.1)
where the Xis are not assumed independent or identically distributed. Define
pi = P[Xi = 1] (4.4.2)
and
E[W] = λ :=
Xn
i=1
pi
. (4.4.3)
Letting µ denote the law of W and π be the Poisson distribution with mean λ, our goal is to
bound kµ − πkTV.
We first state the main bounds and give some examples of its use. We then motivate and
prove the result, and return to further applications. Throughout the next two subsections, we
use the notation in (4.4.1), (4.4.2), and (4.4.3).
4.4.1 Main Bounds and Examples
We begin with an elementary observation.
Theorem 4.4.1 (Stein equation for the Poisson distribution). Let λ > 0. A non-negative
integer-valued random variable Z is Poi(λ) if and only if for all g bounded,
E[λg(Z + 1) − Zg(Z)] = 0. (4.4.4)
The “only if” follows a direct calculation. The “if” follows from taking g(z) := 1{z=k} for all
k ≥ 1 and deriving a recursion. Exercise 4.18 asks for the details. One might expect that if
the left-hand side of (4.4.4) is “small for many gs,” then Z is approximately Poisson.
The following key result in some sense helps to formalize this intuition. We prove it by
constructing a Markov chain that “interpolates” between µ and π, where (4.4.4) will arise
naturally (see Section 4.4.2).
Theorem 4.4.2 (Chen–Stein method). Let W ∼ µ and π ∼ Poi(λ). Then there exists a
function h: {0, 1, . . . , n + 1} → R such that
kµ − πkTV = E [−λh(W + 1) + Wh(W)] . (4.4.5)
Moreover, h satisfies the following Lipschitz condition: for all y, y
0 ∈ {0, 1, . . . , n + 1},
|h( y
0
) − h( y)| ≤ (1 ∧ λ
−1
)| y
0 − y|. (4.4.6)
By bounding the right-hand side of (4.4.5) for any function satisfying (4.4.6), we get a Pois￾son approximation result for µ.
One way to do this is to construct a certain type of coupling. We begin with a definition,
which will be justified in Corollary 4.4.4. We write X ∼ Y|A to mean that X is distributed
as Y conditioned on the event A.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press236 Coupling
Definition 4.4.3 (Stein coupling). A Stein coupling is a pair (Ui STEIN , Vi), for each i = 1, . . . , n,
COUPLING such that
Ui ∼ W, Vi ∼ W − 1|Xi = 1.
Each pair (Ui
, Vi) is defined on a joint probability space, but different pairs do not need to.
How such a coupling is constructed will become clearer in the examples below.
Corollary 4.4.4 Let (Ui
, Vi), i = 1, . . . , n, be a Stein coupling. Then,
kµ − πkTV ≤ (1 ∧ λ
−1
)
Xn
i=1
pi E|Ui − Vi
|. (4.4.7)
Proof By (4.4.5), using the facts that λ =
Pn
i=1
pi and W =
Pn
i=1 Xi
, we get
kµ − πkTV
= E [−λh(W + 1) + Wh(W)]
= E
"
−
 Xn
i=1
pi
!
h(W + 1) +
 Xn
i=1
Xi
!
h(W)
#
=
Xn
i=1
(−piE [h(W + 1)] + E [Xih(W)])
=
Xn
i=1
(−piE [h(W + 1)] + E [h(W) | Xi = 1] P[Xi = 1])
=
Xn
i=1
pi (−E [h(W + 1)] + E [h(W) | Xi = 1]).
Let (Ui
, Vi), i = 1, . . . , n, be a Stein coupling (Definition 4.4.3). Then, we can rewrite this
last expression as
=
Xn
i=1
pi (−E [h(Ui + 1)] + E [h(Vi + 1)])
≤
Xn
i=1
piE [|h(Ui + 1) − h(Vi + 1)|] .
By (4.4.6), we finally get
kµ − πkTV ≤ (1 ∧ λ
−1
)
Xn
i=1
pi E|Ui − Vi
|,
which concludes the proof.
As a first example, we derive a Poisson approximation result in the independent case.
Compare to Theorem 4.1.18.
Example 4.4.5 (Independent Xis). Assume the Xis are independent. We prove the following:
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.4 Chen–Stein Method 237
Claim 4.4.6
kµ − πkTV ≤ (1 ∧ λ
−1
)
Xn
i=1
p
2
i
.
We use the following Stein coupling. For each i = 1, . . . , n, we let
Ui = W
and
Vi =
X
j:j6=i
Xj
.
By independence,
Vi = W − Xi ∼ W − 1|Xi = 1,
as desired. Plugging into (4.4.7), we obtain the bound
kµ − πkTV ≤ (1 ∧ λ
−1
)
Xn
i=1
pi E|Ui − Vi
|
≤ (1 ∧ λ
−1
)
Xn
i=1
pi E






W −
X
j6=i
Xj






≤ (1 ∧ λ
−1
)
Xn
i=1
pi E |Xi
|
≤ (1 ∧ λ
−1
)
Xn
i=1
p
2
i
.
J
Here is a less straightforward example.
Example 4.4.7 (Balls in boxes). Suppose we throw k balls uniformly at random in n boxes
independently. Let
Xi = 1{box i is empty},
and let W =
Pn
i=1 Xi be the number of empty boxes. Note that the Xis are not independent.
In particular, we cannot use Theorem 4.1.18. Note that
pi =

1 −
1
n
k
for all i and, hence,
λ = n

1 −
1
n
k
.
For each i = 1, . . . , n, we generate the coupling (Ui
, Vi) in the following way. We let
Ui = W. If box i is empty, then Vi = W − 1. Otherwise, we redistribute all balls in box i
among the remaining boxes and let Vi count the number of empty boxes 6= i. By construction,
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press238 Coupling
both conditions of the Stein coupling are satisfied. Moreover, we have almost surely Vi ≤ Ui
so that
Xn
i=1
piE|Ui − Vi
| = Xn
i=1
piE[Ui − Vi] = λ
2 −
Xn
i=1
piE[Vi].
By the fact that Vi ∼ Ui − 1|Xi = 1 and Bayes’ rule,
Xn
i=1
piE[Vi] =
Xn
i=1
P[Xi = 1]Xn
k=1
(k − 1)P[Vi = k − 1]
=
Xn
i=1
Xn
k=1
(k − 1)P[Ui = k | Xi = 1] P[Xi = 1]
=
Xn
i=1
Xn
k=1
(k − 1)P[Xi = 1 | Ui = k] P[Ui = k].
Now we use the fact that P[Xi = 1 | Ui = k] = E[Xi
| Ui = k] because Xi
is an indicator
variable. So the last line above is
=
Xn
i=1
Xn
k=1
(k − 1)E[Xi
| W = k] P[W = k]
=
Xn
k=1
(k − 1)E
"Xn
i=1
Xi





W = k
#
P[W = k]
=
Xn
k=1
(k − 1)k P[W = k]
= E[W2
] − E[W].
It remains to compute E[W2
]. We have by symmetry
E[W2
] = n E[X
2
1
] + n(n − 1)E[X1X2]
= λ + n(n − 1)
1 −
2
n
k
,
so by Corollary 4.4.4,
kµ − πkTV ≤ (1 ∧ λ
−1
)
(
n
2

1 −
1
n
2k
− n(n − 1)
1 −
2
n
k
)
.
When k = n log n + Cn for instance, it can be checked that kµ − πkTV = O(log n/n). J
This last example is generalized in Exercise 4.22.
In special settings, one can give useful general bounds by constructing an appropriate
Stein coupling. We give an important example next. Recall that [n] = {1, . . . , n}.
Theorem 4.4.8 (Chen–Stein method: dissociated case). Suppose that for each i there is a
neighborhood Ni ⊆ [n] \ {i} such that
Xi
is independent of {Xj
: j ∈/ Ni ∪ {i}}.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.4 Chen–Stein Method 239
Then,
kµ − πkTV ≤ (1 ∧ λ
−1
)
Xn
i=1



p
2
i +
X
j∈Ni
￾
pipj + E[XiXj]




.
Proof We use the following Stein coupling. Let
Ui = W.
Then generate
(Y
(i)
j
)j∈Ni ∼ (Xj)j∈Ni
|{Xk
: k ∈/ Ni ∪ {i}}, Xi = 1,
and set
Vi =
X
k∈/Ni∪{i}
Xk +
X
j∈Ni
Y
(i)
j
.
Because the law of {Xk
: k ∈/ Ni ∪ {i}} (and therefore of the first term in Vi) is independent
of the event {Xi = 1}, the above scheme satisfies the conditions of the Stein coupling.
Hence we can apply Corollary 4.4.4. The construction of (Ui
, Vi) guarantees that Ui − Vi
depends only on “i and its neighborhood.” Specifically, we get
kµ − πkTV ≤ (1 ∧ λ
−1
)
Xn
i=1
pi E|Ui − Vi
|
= (1 ∧ λ
−1
)
Xn
i=1
pi E






Xn
j=1
Xj −
X
k∈/Ni∪{i}
Xk −
X
j∈Ni
Y
(i)
j






= (1 ∧ λ
−1
)
Xn
i=1
pi E






Xi +
X
j∈Ni
(Xj − Y
(i)
j
)






≤ (1 ∧ λ
−1
)
Xn
i=1
pi

E|Xi
| +X
j∈Ni
(E|Xj
| + E| Y
(i)
j
|)

 ,
where we used the triangle inequality. Recalling that pi = P[Xi = 1] = E[Xi] = E|Xi
| and
the definition of Y
(i)
j
, the last expression above is
= (1 ∧ λ
−1
)
Xn
i=1
pi

pi +
X
j∈Ni
[pj + E[|Xj
||Xi = 1]


= (1 ∧ λ
−1
)
Xn
i=1



p
2
i +
X
j∈Ni
￾
pipj + piE[Xj
|Xi = 1]



= (1 ∧ λ
−1
)
Xn
i=1



p
2
i +
X
j∈Ni
￾
pipj + E[XiXj]




.
That concludes the proof.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Pr240 Coupling
Next we give an example of the previous theorem.
Example 4.4.9 (Longest head run). Let 0 < q < 1 and let Z1, Z2, . . . be i.i.d. Bernoulli ran￾dom variables with success probability q = P[Zi = 1]. We are interested in the distribution
of R, the length of the longest run of 1s starting in the first n tosses. For any positive integer
t, let X
(t)
1
:= Z1 · · · Zt and
X
(t)
i
:= (1 − Zi−1)Zi
· · · Zi+t−1, i ≥ 2.
The event {X
(t)
i = 1} indicates that a head run of length at least t starts at the ith toss. Now
define
W(t)
:=
Xn
i=1
X
(t)
i
.
The key observation is that
{R < t} = {W(t) = 0}. (4.4.8)
Notice that, for fixed t, the X
(t)
i
s are neither independent nor identically distributed. How￾ever, they exhibit a natural neighborhood structure as in Theorem 4.4.8. Indeed, let
N
(t)
i
:= {α ∈ [n]: |α − i| ≤ t} \ {i}.
Then, X
(t)
i
is independent of {X
(t)
j
: j ∈/ Ni ∪ {i}}. For example,
X
(t)
i = (1 − Zi−1)Zi
· · · Zi+t−1
and
X
(t)
i+t+1 = (1 − Zi+t)Zi+t+1 · · · Zi+2t
do not depend on any common Zj
, while X
(t)
i
and
X
(t)
i+t = (1 − Zi+t−1)Zi+t
· · · Zi+2t−1
both depend on Zi+t−1.
We compute the quantities needed to apply Theorem 4.4.8. We have
p
(t)
1
:= E[Z1 · · · Zt] =
Yt
j=1
E[Zj] = q
t
,
and, for i ≥ 2,
p
(t)
i
:= E[(1 − Zi−1)Zi
· · · Zi+t−1]
= E[1 − Zi−1]
i+
Yt−1
j=i
E[Zj]
= (1 − q)q
t
≤ q
t
.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.4 Chen–Stein Method 241
For i ≥ 1 and j ∈ N
(t)
i
, observe that a head run of length at least t cannot start simultaneously
at i and j. So E[X
(t)
i X
(t)
j
] = 0 in that case. We also have
λ
(t)
:= E[W(t)
] = q
t + (n − 1)(1 − q)q
t ∈ [n(1 − q)q
t
, nqt
]
and


N
(t)
i


 ≤ 2t.
We are ready to apply Theorem 4.4.8. We get
kµ − πkTV ≤ (1 ∧ (λ
(t)
)
−1
)
Xn
i=1



(p
(t)
i
)
2 +
X
j∈N
(t)
i

p
(t)
i p
(t)
j + E[X
(t)
i X
(t)
j
]




≤ (1 ∧ (n(1 − q)q
t
)
−1
)

nq2t + 2tnq2t

≤
1
(1 − q)n
(1 ∧ (nqt
)
−1
)[2t + 1](nqt
)
2
.
This bound is non-asymptotic – it holds for any q, n, t. One special regime of note is t =
log1/q n + C with large n. In that case, we have nqt → C
0
as n → +∞ for some 0 < C
0 <
+∞ and the total variation above is of the order of O(log n/n).
Going back to (4.4.8), we finally obtain when t = log1/q n + C that



P[R < t] − e
−λ
(t)


 = O

log n
n

,
where recall that R and λ
(t)
implicitly depend on n. J
4.4.2 Some Motivation and Proof
The idea behind the Chen–Stein method is to interpolate between µ and π in Theorem 4.4.2
by constructing a Markov chain with initial distribution µ and stationary distribution π.
Here we use a discrete-time, finite Markov chain.
Proof of Theorem 4.4.2 We seek a bound on
kµ − πkTV = sup
A⊆Z+
|µ(A) − π(A)|
= µ(A
∗
) − π(A
∗
)
=
X
z∈A∗
(µ(z) − π(z)), (4.4.9)
where A
∗ = {z ∈ Z+ : µ(z) > π(z)}, by Lemma 4.1.15. Since W ≤ n almost surely, µ(z) = 0
for all z > n, which implies that A
∗ ⊆ {0, 1, . . . , n}. In particular, it will suffice to bound
µ(z) − π(z) for 0 ≤ z ≤ n. We also assume λ < n (the case λ = n being uninteresting).
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press242 Coupling
Constructing the Markov chain It will be convenient to truncate π at n, that is, we define
π¯ (z) =



π(z), 0 ≤ z ≤ n,
1 − 5(n), z = n + 1,
0 otherwise,
where 5(z) =
P
w≤z π(w) is the cumulative distribution function of the Poisson distribution
with mean λ. We construct a Markov chain with stationary distribution π¯ . We will also need
the chain to be aperiodic and irreducible over {0, 1, . . . , n + 1}.
We choose the transition matrix (P(x, y))0≤x,y≤n+1 to be that of a birth–death chain revers￾ible with respect to π¯ , that is, we require P(x, y) = 0 unless |x − y| ≤ 1 and
P(x, x + 1)
P(x + 1, x)
=
π¯ (x + 1)
π¯ (x)
∀x ∈ [n]. (4.4.10)
For x < n,
π¯ (x + 1)
π¯ (x)
=
π(x + 1)
π(x)
=
e
−λλ
x+1
/(x + 1)!
e
−λλ
x/x!
=
λ
x + 1
.
In view of this, we want P(x, x+1) ∝ λ and P(x, x−1) ∝ x. We choose the proportionality
constant to ensure that all transition probabilities are in [0, 1]. Specifically, for x 6= y, the
non-zero transition probabilities take values
P(x, y) =



1
2n
λ if 0 ≤ x ≤ n, y = x + 1,
1
2n
x if 1 ≤ x ≤ n, y = x − 1,
1
2n
λ
π(n)
1−5(n)
if x = n + 1, y = n.
(4.4.11)
The probability of staying put is 1−
1
2n
λ if x = 0, 1−
1
2n
x−
1
2n
λ if 1 ≤ x ≤ n, and 1−
1
2n
λ
π(n)
1−5(n)
if x = n+1. Those are all strictly positive when λ < n. Hence, by construction P is aperiodic
and irreducible, and it satisfies the detailed balance conditions (4.4.10).
Recalling (3.3.6), the Laplacian is
1f (x) =
X
y
P(x, y)[ f ( y) − f (x)]
= P(x, x + 1)[ f (x + 1) − f (x)] − P(x, x − 1)[ f (x) − f (x − 1)]
= λg(x + 1) − xg(x)
for 0 ≤ x ≤ n, where we defined
g(x) :=
f (x) − f (x − 1)
2n
, x ∈ {1, . . . , n + 1} (4.4.12)
and g(0) is arbitrary. At x = n + 1,
1f (n + 1) = −λn
π(n)
1 − 5(n)
g(n + 1).
It is a standard fact (see Exercise 4.19) that the expectation of the Laplacian under the
stationary distribution is 0. Inverting the relationship (4.4.12), for any g : {0, . . . , n+1} → R,
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.4 Chen–Stein Method 243
there is a corresponding f (unique up to an additive constant). So we have shown that if
Z ∼ ¯π then
E

(λg(Z + 1) − Zg(Z))1{Z≤n} − λn
π(n)
1 − 5(n)
g(Z)1{Z=n+1}

= 0,
that is,
E

(λg(Z + 1) − Zg(Z))1{Z≤n}

= λnπ(n)g(n + 1).
Notice that, if g is extended to a bounded function on Z+, λ is fixed and Z ∼ Poi(λ), then
taking n → +∞ recovers Theorem 4.4.1 by dominated convergence (Proposition B.4.14).1
Markov chains calculations By the convergence theorem for Markov chains (Theorem
1.1.33),
P
t
(y,z) → ¯π(z)
for all 0 ≤ y ≤ n + 1 and 0 ≤ z ≤ n + 1 as t → +∞. Hence, letting δz(x) = 1{x=z}
, by
telescoping
δz( y) − ¯π(z) = lim
t→+∞
Ey[δz(X0) − δz(Xt)]
= lim
t→+∞
Xt−1
s=0
Ey[δz(Xs) − δz(Xs+1)], (4.4.13)
where the subscript of E indicates the initial state. We will later take expectations over µ to
interpolate between µ and π.
First, we use standard Markov chains facts to compute (4.4.13). Define for y ∈ {1, . . . ,
n + 1},
g
t
z
( y) :=
1
2n
Xt−1
s=0
(Ey[δz(Xs)] − Ey−1[δz(Xs)]) (4.4.14)
and g
t
z
(0) := 0. The function g
t
z
( y) is, up to a factor (whose purpose will be clearer below),
the difference between the expected number of visits to z up to time t − 1 when started at
y and y − 1, respectively. It depends on µ only through λ and n. By Chapman–Kolmogorov
(Theorem 1.1.20) applied to the first step of the chain,
Ey[δz(Xs+1)] = P( y, y + 1) Ey+1[δz(Xs)]
+ P( y, y) Ey[δz(Xs)] + P( y, y − 1) Ey−1[δz(Xs)].
Using that P( y, y + 1) + P( y, y) + P( y, y − 1) = 1 and rearranging we get for 0 ≤ y ≤ n and
0 ≤ z ≤ n + 1,
1 The above argument is more natural in the setting of continuous-time Markov chains, but we will not
introduce them here.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press244 Coupling
Xt−1
s=0
Ey[δz(Xs) − δz(Xs+1)]
=
Xt−1
s=0

− P( y, y + 1)(Ey+1[δz(Xs)] − Ey[δz(Xs)])
+ P( y, y − 1)(Ey[δz(Xs)] − Ey−1[δz(Xs)])
= −2nP( y, y + 1)g
t
z
( y + 1) + 2nP( y, y − 1)g
t
z
( y)
= −λg
t
z
( y + 1) + ygt
z
( y), (4.4.15)
where we used (4.4.11) on the last line.
We establish after the proof of the theorem that g
t
z
( y) has a well-defined limit. That fact
is not immediately obvious as the limit is the “difference of two infinities.” But a simple
coupling argument does the trick.
Lemma 4.4.10 Let gt
z
: {0, 1, . . . , n + 1} → R be defined in (4.4.14). Then there exists
a bounded function g∞
z
: {0, 1, . . . , n + 1} → R such that for all 0 ≤ z ≤ n + 1 and
0 ≤ y ≤ n + 1,
g
∞
z
( y) = lim
t→+∞
g
t
z
( y).
In fact, an explicit expression for g
∞
z
can be derived via the following recursion. That
expression will be helpful to establish the Lipschitz condition in Theorem 4.4.2.
Lemma 4.4.11 For all 0 ≤ y ≤ n and 0 ≤ z ≤ n + 1,
δz( y) − ¯π(z) = −λg
∞
z
( y + 1) + yg∞
z
( y).
Proof Combine (4.4.13), (4.4.15), and Lemma 4.4.10.
Lemma 4.4.11 leads to the following formula for g
∞
z
, which we establish after the proof of
the theorem.
Lemma 4.4.12 For 1 ≤ y ≤ n + 1 and 0 ≤ z ≤ n + 1,
g
∞
z
( y) =
( 5(y−1)
yπ( y)
π¯ (z) if z ≥ y,
−
1−5(y−1)
yπ( y)
π¯ (z) if z < y.
(4.4.16)
and g∞
z
(0) = 0.
Interpolating between µ and π For A ⊆ {0, 1, . . . , n}, define
g
∞
A
( y) :=
X
z∈A
g
∞
z
( y).
We obtain the following key bound.
Lemma 4.4.13 (Chen’s equation). Let W ∼ µ and π
d= Poi(λ). Then,
kµ − πkTV = E

−λg
∞
A∗ (W + 1) + Wg∞
A∗ (W)

, (4.4.17)
where A∗ = {z ∈ Z+ : µ(z) > π(z)}.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.4 Chen–Stein Method 245
Proof Fix z ∈ {0, 1, . . . , n}. Multiplying both sides in Lemma 4.4.11 by µ( y) and summing
over y in {0, 1, . . . , n} gives
µ(z) − π(z) = E

−λg
∞
z
(W + 1) + Wg∞
z
(W)

.
Now summing over z in A
∗ ⊆ {0, 1, . . . , n} and using (4.4.9) gives the claim.
Lemma 4.4.12 can be used to derive a Lipschitz constant for g
∞
A
. That lemma is also
established after the proof of the theorem.
Lemma 4.4.14 For A ⊆ {0, 1, . . . , n} and y, y
0 ∈ {0, 1, . . . , n + 1},
|g
∞
A
( y
0
) − g
∞
A
( y)| ≤ (1 ∧ λ
−1
)| y
0 − y|.
Lemmas 4.4.13 and 4.4.14 imply the theorem with h := g
∞
A∗ .
Proofs of technical lemmas It remains to prove Lemmas 4.4.10, 4.4.12, and 4.4.14.
Proof of Lemma 4.4.10 We use a coupling argument. Let (Ys
, Y˜
s)
+∞
s=0
be an independent
Markovian coupling of (Ys), the chain started at y−1, and (Y˜
s), the chain started at y. Let τ be
the first time s that Ys = Y˜
s
. Because Ys and Y˜
s are independent and P is a birth–death chain
with strictly positive nearest-neighbor and staying-put transition probabilities, the coupled
chain (Ys
, Y˜
s)
+∞
s=0
is aperiodic and irreducible over {0, 1, . . . , n + 1}
2
. By the exponential tail
of hitting times, Lemma 3.1.25, it holds that E[τ ] < +∞.
Modify the coupling (Ys
, Y˜
s) to enforce Y˜
s = Ys for all s ≥ τ (while not changing (Ys)),
that is, to make it coalescing. By the Strong Markov property (Theorem 3.1.8), the resulting
chain (Y
∗
s
, Y˜ ∗
s
) is also a Markovian coupling of the chain started at y − 1 and y, respectively.
Using this coupling, we rewrite
g
t
z
( y) =
1
2n
Xt−1
s=0
(Ey[δz(Xs)] − Ey−1[δz(Xs)])
=
1
2n
Xt−1
s=0
E[δz(Y˜
∗
s
) − δz(Y
∗
s
)]
=
1
2n
E
"Xt−1
s=0
(δz(Y˜
∗
s
) − δz(Y
∗
s
))#
.
The random variable inside the expectation is bounded in absolute value by





Xt−1
s=0
(δz(Y˜
∗
s
) − δz(Y
∗
s
))





≤ τ
uniformly in t. Indeed, after s = τ , the terms in the sum are 0, while before s = τ the terms
are bounded by 1 in absolute value. By the integrability of τ , the dominated convergence
theorem (Proposition B.4.14) allows to take the limit, leading to
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press246 Coupling
g
∞
z
( y) = lim
t→+∞
1
2n
E
"Xt−1
s=0
(δz(Y˜
∗
s
) − δz(Y
∗
s
))#
=
1
2n
E
"X
+∞
s=0
(δz(Y˜
∗
s
) − δz(Y
∗
s
))#
< +∞.
That concludes the proof.
Proof of Lemma 4.4.12 Our starting point is Lemma 4.4.11, from which we deduce the
recursive formula
g
∞
z
( y + 1) =
1
λ

yg∞
z
( y) + π(z) − δz( y)
	
(4.4.18)
for 0 ≤ y ≤ n and 0 ≤ z ≤ n.
We guess a general formula and then check it. By (4.4.18),
g
∞
z
(1) =
1
λ
{π(z) − δz(0)}, (4.4.19)
g
∞
z
(2) =
1
λ

g
∞
z
(1) + π(z) − δz(1)	
=
1
λ

1
λ
{π(z) − δz(0)} + π(z) − δz(1)
=
1
λ
2
{π(z) − δz(0)} +
1
λ
{π(z) − δz(1)},
g
∞
z
(3) =
1
λ

2g
∞
z
(2) + π(z) − δz(2)	
=
1
λ

2
1
λ
2
{π(z) − δz(0)} + 2
1
λ
{π(z) − δz(1)} + π(z) − δz(2)
=
2
λ
3
{π(z) − δz(0)} +
2
λ
2
{π(z) − δz(1)} +
1
λ
{π(z) − δz(2)},
and so forth. We posit the general formula
g
∞
z
( y) =
(y − 1)!
λ
y
X
y−1
k=0
λ
k
k!
{π(z) − δz(k)} (4.4.20)
for 1 ≤ y ≤ n + 1 and 0 ≤ z ≤ n.
The formula is straightforward to confirm by induction. Indeed, it holds for y = 1 as can
be seen in (4.4.19) (and recalling that 0! = 1 by convention) and, assuming it holds for y, we
have by (4.4.18),
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.4 Chen–Stein Method 247
g
∞
z
( y + 1) =
1
λ

yg∞
z
( y) + π(z) − δz( y)
	
=
1
λ
(
y
(y − 1)!
λ
y
X
y−1
k=0
λ
k
k!
{π(z) − δz(k)} + π(z) − δz( y)
)
=
y!
λ
y+1
X
y−1
k=0
λ
k
k!
{π(z) − δz(k)} +
1
λ
{π(z) − δz( y)}
=
y!
λ
y+1
X
y
k=0
λ
k
k!
{π(z) − δz(k)},
as desired.
We rewrite (4.4.20) according to whether the term δz( y) = 1{z = y} plays a role in the
equation. For z ≥ y > 0, the equation simplifies to
g
∞
z
( y) =
(y − 1)!
λ
y
X
y−1
k=0
λ
k
k!
π(z)
=
1
y
y!
e
−λλ
y
X
y−1
k=0
e
−λλ
k
k!
π(z)
=
5(y − 1)
yπ( y)
π(z).
For 0 ≤ z < y, we get instead
g
∞
z
( y) =
(y − 1)!
λ
y
( X
y−1
k=0
λ
k
k!
π(z)
!
−
λ
z
z!
)
=
1
y
y!
e
−λλ
y
( X
y−1
k=0
e
−λλ
k
k!
π(z)
!
− π(z)
)
=
5(y − 1) − 1
yπ( y)
π(z).
The cases z = n + 1 are analogous.
Proof of Lemma 4.4.14 It suffices to prove that, for A ⊆ {0, 1, . . . , n} and y ∈ {0, 1, . . . ,
n},
|g
∞
A
(y + 1) − g
∞
A
( y)| ≤ (1 ∧ λ
−1
), (4.4.21)
and then use the triangle inequality.
We start with the cases y ≥ 1. We use the expression derived in Lemma 4.4.12. For
1 ≤ y < z,
g
∞
z
( y + 1) − g
∞
z
( y) =
5( y)
(y + 1)π(y + 1)
π¯ (z) −
5(y − 1)
yπ( y)
π¯ (z)
= ¯π(z)
1
yπ( y)
n y
λ
5( y) − 5(y − 1)o
,
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press248 Coupling
where we used that π(y + 1)/π( y) = λ/(y + 1). We show that the expression in curly
brackets is non-negative. Indeed, taking out the term k
0 = 0 in the first sum below and
changing variables, we get
y
λ
X
y
k
0=0
e
−λλ
k
0
(k
0
)!
−
X
y−1
k=0
e
−λλ
k
k!
=
y
λ
e
−λ +
X
y−1
k=0
e
−λλ
(k+1)−1
(k + 1)!/y
−
X
y−1
k=0
e
−λλ
k
k!
≥
y
λ
e
−λ +
X
y−1
k=0
e
−λλ
k
k!
−
X
y−1
k=0
e
−λλ
k
k!
≥ 0.
So g
∞
z
( y+1)−g
∞
z
( y) ≥ 0 for 1 ≤ y < z. A similar calculation, which we omit, shows that the
same inequality holds for z < y ≤ n. The cases y = 0, which are analogous, are detailed below.
For notational convenience, it will be helpful to define g
∞
z
(n + 2) for all z. Then, for
y = n + 1 and z ≤ n, we get
g
∞
z
(n + 2) − g
∞
z
(n + 1) = 0 +
1 − 5(n)
(n + 1)π(n + 1)
π(z) ≥ 0.
Moreover, by telescoping,
0 = g
∞
z
(n + 2) − g
∞
z
(0) =
Xn+1
y=0
{g
∞
z
( y + 1) − g
∞
z
( y)}.
We have argued that all the terms in this last sum are non-negative – with the sole ex￾ception of the term y = z. Hence, for a fixed 0 ≤ z ≤ n, it must be that the maximum of
|g
∞
z
( y + 1) − g
∞
z
( y)| is achieved at z = y. The case z = n + 1 is analogous. By definition
of g
∞
z
, for 0 ≤ y ≤ n, the previous display holds with a sum over z rather y and it must be
that the maximum of |g
∞
A
( y + 1) − g
∞
A
( y)| over A ⊆ {0, 1, . . . , n} is achieved at A = {y}. It
remains to bound that last case.
We have, using π(y + 1)/π( y) = λ/(y + 1) again, that
|g
∞
y
( y + 1) − g
∞
y
( y)|
=



−
1 − 5( y)
(y + 1)π(y + 1)
π( y) −
5(y − 1)
yπ( y)
π( y)




=
1
λ
X
k≥y+1
e
−λ
λ
k
k!
+
1
y
X
y−1
k=0
e
−λ
λ
k
k!
=
e
−λ
λ



X
y
k
0=1
λ
k
0
(k
0
)!
k
0
y
+
X
k≥y+1
λ
k
k!



≤
e
−λ
λ
(X
k≥1
λ
k
k!
)
=
e
−λ
λ

e
λ − 1
	
=
1 − e
−λ
λ
.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press4.4 Chen–Stein Method 249
For λ ≥ 1, we have 1−e
−λ
λ ≤
1
λ = (1 ∧ λ
−1
), while for 0 < λ < 1 we have 1−e
−λ
λ ≤
λ
λ = 1 =
(1 ∧ λ
−1
) by Exercise 1.16. The case y = 0 is analogous, as detailed next.
It remains to consider the cases y = 0. Recall that g
∞
z
(0) = 0. By Lemma 4.4.12, for
z ≥ 1,
g
∞
z
(1) − g
∞
z
(0) = g
∞
z
(1)
=
5(0)
π(1)
π(z)
= e
−λ
e
−λλ
z
/z!
e
−λλ
=
1
λ
e
−λ
λ
z
z!
.
And
g
∞
0
(1) − g
∞
0
(0) = g
∞
0
(1) = −
1 − 5(0)
π(1)
π(0) = −
1 − e
−λ
λ
.
So we have established (4.4.21) and that concludes the proof.
4.4.3 F Random Graphs: Clique Number at the Threshold in the
Erd ˝os–Rényi Model
We revisit the subgraph containment problem of Section 2.3.2 (and Section 4.2.4). Let Gn ∼
Gn,pn
be an Erdos–Rényi graph with ˝ n vertices and density pn. Let ω(G) be the clique number
of a graph G, that is, the size of its largest clique. We showed previously that the property
ω(G) ≥ 4 has threshold function n
−2/3
. Here we consider what happens when
pn = Cn−2/3
for some constant C > 0. We use the Chen–Stein method in the form of Theorem 4.4.8.
For an enumeration S1, . . . , Sm of the 4-tuples of vertices in Gn, let A1, . . . , Am be the
events that the corresponding 4-cliques are present and define Zi = 1Ai
. Then, W =
Pm
i=1
Zi
is the number of 4-cliques in Gn. We argued previously (see Claim 2.3.4) that
qi
:= E[Zi] = p
6
n
and
λ := E[W] =

n
4

p
6
n
.
In our regime of interest, λ is of constant order.
Observe that the Zis are not independent because the 4-tuples may share potential edges.
However, they admit a neighborhood structure as in Theorem 4.4.8. Specifically, for i =
1, . . . , m, define
Ni = {j: Si and Sj share at least two vertices} \ {i}.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press250 Coupling
Then, the conditions of Theorem 4.4.8 are satisfied, that is, Xi
is independent of {Zj
: j ∈/
Ni ∪ {i}}. We argued previously (again see Claim 2.3.4) that
|Ni
| = 
4
3

(n − 4) +

4
2
n − 4
2

= 2(n
2
),
where the first term counts the number of Sjs sharing exactly three vertices with Si
, in which
case E[ZiZj] = p
9
n
, and the second term counts those sharing two, in which case E[ZiZj] =
p
11
n
.
We are ready to apply the bound in Theorem 4.4.8. Let π be the Poisson distribution with
mean λ. Using the formulas above, we get when pn = Cn−2/3
,
kµ − πkTV
≤ (1 ∧ λ
−1
)
Xn
i=1



q
2
i +
X
j∈Ni
￾
qiqj + E[ZiZj]




≤ (1 ∧ λ
−1
)

n
4

×

p
12
n +
4
3

(n − 4)(p
12
n + p
9
n
) +

4
2
n − 4
2

(p
12
n + p
11
n
)

= (1 ∧ λ
−1
) 2(n
4
p
12
n + n
5
p
9
n + n
6
p
11
n
)
= (1 ∧ λ
−1
) 2(n
4
n
−8 + n
5
n
−6 + n
6
n
−22/3
)
= (1 ∧ λ
−1
) 2(n
−1
),
which goes to 0 as n → +∞.
See Exercise 4.21 for an improved bound.
Exercises
Exercise 4.1 (Harmonic function on Z
d
: unbounded). Give an example of an unbounded
harmonic function on Z. Give one on Z
d
for general d. (Hint: What is the simplest function
after the constant one?)
Exercise 4.2 (Binomial vs. Binomial). Use coupling to show that
n ≥ m, q ≥ p =⇒ Bin(n, q)  Bin(m, p).
Exercise 4.3 (A chain that is not stochastically monotone). Consider random walk on a
network N = ((V, E), c), where V = {0, 1, . . . , n} and i ∼ j if and only if |i − j| = 1
(in particular, not including self-loops). Show that the transition matrix is, in general, not
stochastically monotone (see Definition 4.2.16).
Exercise 4.4 (Increasing events: properties). Let F be a σ-algebra over the poset X . Recall
that an event A ∈ F is increasing if x ∈ A implies that any y ≥ x is also in A and that a
function f : X → R is increasing if x ≤ y implies f (x) ≤ f ( y).
(i) Show that an event A ∈ F is increasing if and only if the indicator function 1A is
increasing.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University PresExercises 251
(ii) Let A, B ∈ F be increasing. Show that A ∩ B and A ∪ B are increasing.
(iii) An event A is decreasing if x ∈ A implies that any y ≤ x is also in A. Show that A
is decreasing if and only if A
c
is increasing.
(iv) Let A, B ∈ F be decreasing. Show that A ∩ B and A ∪ B are decreasing.
Exercise 4.5 (Harris’ inequality: alternative proof). We say that f : R
n → R is coordinate￾wise non-decreasing if it is non-decreasing in each variable while keeping the other variables
fixed.
(i) (Chebyshev’s association inequality) Let f : R → R and g : R → R be coordinate￾wise non-decreasing and let X be a real random variable. Show that
E[ f (X)g(X)] ≥ E[ f (X)]E[g(X)].
(Hint: Consider the quantity (f (X)−f (X
0
))(g(X)−g(X
0
)), where X
0
is an independent
copy of X.)
(ii) (Harris’ inequality) Let f : R
n → R and g : R
n → R be coordinatewise non￾decreasing and let X = (X1, . . . , Xn) be independent real random variables. Show
by induction on n that
E[ f (X)g(X)] ≥ E[ f (X)]E[g(X)].
Exercise 4.6 Provide the details for Example 4.2.33.
Exercise 4.7 (FKG: sufficient conditions). Let X := {0, 1}
F where F, is finite and let µ be
a positive probability measure on X . We use the notation introduced in the proof of Holley’s
inequality (Theorem 4.2.32).
(i) To check the FKG condition, show that it suffices to check that, for all x ≤ y ∈ X
and i ∈ F,
µ( y
i,1)
µ( y
i,0)
≥
µ(x
i,1)
µ(x
i,0)
.
(Hint: Write µ(ω ∨ ω
0
)/µ(ω) as a telescoping product.)
(ii) To check the FKG condition, show that it suffices to check (4.2.15) only for those
ω, ω
0 ∈ X such that kω − ω
0k1 = 2 and neither ω ≤ ω
0 nor ω
0 ≤ ω. (Hint: Use (i).)
Exercise 4.8 (FKG and strong positive associations). Let X := {0, 1}
F
, where F is finite
and let µ be a positive probability measure on X . For 3 ⊆ F and ξ ∈ X , let
X
ξ
3 := {ω3 × ξ3c : ω3 ∈ {0, 1}
3
},
where ω3 ×ξ3c agrees with ω on coordinates in 3 and with ξ on coordinates in F\3. Define
the measure µ
ξ
3 over {0, 1}
3 as
µ
ξ
3(ω3) :=
µ(ω3 × ξ3c )
µ(X
ξ
3)
.
That is, µ
ξ
3 is µ conditioned on agreeing with ξ on F\3. The measure µ is said to be
strongly positively associated if µ
ξ
3(ω3) is positively associated for all 3 and ξ . Prove that
the FKG condition is equivalent to strong positive associations. (Hint: Use Exercise 4.7 as
well as the FKG inequality.)
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press252 Coupling
Exercise 4.9 (Triangle-freeness: a second proof). Consider again the setting of Section 4.2.4.
(i) Let et be the minimum number of edges in a t-vertex union of k not mutually vertex￾disjoint triangles. Show that, for any k ≥ 2 and k ≤ t < 3k, it holds that et > t.
(ii) Use Exercise 2.18 to give a second proof of the fact that P[Xn = 0] → e
−λ
3
/6
.
Exercise 4.10 (RSW lemma: general α). Let Rn,α(p) be as defined in Section 4.2.5. Show
that for all n ≥ 2 (divisible by 4) and p ∈ (0, 1),
Rn,α(p) ≥

1
2
2α−2
Rn,1(p)
6α−7Rn/2,1(p)
6α−6
.
Exercise 4.11 (Primal and dual crossings). Modify the proof of Lemma 2.2.14 to prove
Lemma 4.2.41.
Exercise 4.12 (Square-root trick). Let µ be an FKG measure on {0, 1}
F
, where F is finite.
Let A1 and A2 be increasing events with µ(A1) = µ(A2). Show that
µ(A1) ≥ 1 −
p
1 − µ(A1 ∪ A2).
Exercise 4.13 (Splitting: details). Show that P˜, as defined in Example 4.3.3, is a transition
matrix on V provided z0 satisfies the condition there.
Exercise 4.14 (Doeblin’s condition in finite case). Let P be a transition matrix on a finite
state space.
(i) Show that Doeblin’s condition (see Example 4.3.3) holds when P is finite, irreduci￾ble, and aperiodic.
(ii) Show that Doeblin’s condition holds for lazy random walk on the hypercube with
s = n. Use it to derive a bound on the mixing time.
Exercise 4.15 (Mixing on cycles: lower bound). Let (Zt) be lazy, simple random walk on
the cycle of size n, Zn := {0, 1, . . . , n − 1}, where i ∼ j if |j − i| = 1 (mod n).
(i) Let A = {n/2, . . . , n − 1}. By coupling (Zt) with lazy, simple random walk on Z,
show that
P
αn
2
(n/4, A) <
1
2
− ε
for α ≤ αε for some αε > 0. (Hint: Use Kolmogorov’s maximal inequality (Corol￾lary 3.1.46).)
(ii) Deduce that
tmix(ε) ≥ αεn
2
.
Exercise 4.16 (Lower bound on mixing: distinguishing statistic). Let X and Y be random
variables on a finite state space S. Let h: S → R be a measurable real-valued map. Assume
that
E[h( Y)] − E[h(X)] ≥ rσ,
where r > 0 and σ
2
:= max{Var[h(X)], Var[h( Y)]}. Show that
kµX − µY kTV ≥ 1 −
8
r
2
.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University PressExercises 253
(Hint: Consider the interval on one side of the midpoint between E[h(X)] and
E[h( Y)].)
Exercise 4.17 (Path coupling and optimal transport). Let V be a finite state space and let P
be an irreducible transition matrix on V with stationary distribution π. Let w0 be a metric
on V. For probability measures µ, ν on V, let
W0(µ, ν) := inf{E[w0(X, Y)]: (X, Y) is a coupling of µ and ν}
be the so-called Wasserstein distance (or transportation metric) between µ and ν. WASSERSTEIN
DISTANCE
(i) Show that W0 is a metric. (Hint: See the proof of Claim 4.3.11.)
(ii) Assume that the conditions of Theorem 4.3.10 hold. Show that for any probability
measures µ, ν,
W0(µP, νP) ≤ κ W0(µ, ν).
(iii) Use (i) and (ii) to prove Theorem 4.3.10.
Exercise 4.18 (Stein equation for the Poisson distribution). Let λ > 0. Show that a non￾negative integer-valued random variable Z is Poi(λ) if and only if for all g bounded,
E[λg(Z + 1) − Zg(Z)] = 0.
Exercise 4.19 (Laplacian and stationarity). Let P be an irreducible transition matrix on a
finite or countably infinite spate space V. Recall the Laplacian operator is
1f (x) =
"X
y
P(x, y)f ( y)
#
− f (x)
provided the sum is finite. Show that a probability distribution µ over V is stationary for P
if and only if for all bounded measurable functions,
X
x∈V
µ(x)1f (x) = 0.
Exercise 4.20 (Chen–Stein method for positively related variables). Using the notation
in (4.4.1), (4.4.2), and (4.4.3), suppose that for each i we can construct a coupling {(X
(i)
j
: j =
1, . . . , n), (Y
(i)
j
: j 6= i)} with (X
(i)
j
)j ∼ (Xj)j such that
(Y
(i)
j
, j 6= i) ∼ (X
(i)
j
, j 6= i)|X
(i)
i = 1 and Y
(i)
j ≥ X
(i)
j
, ∀j 6= i.
Show that
kµ − πkTV ≤ (1 ∧ λ
−1
)
(
Var(W) − λ + 2
Xn
i=1
p
2
i
)
.
Exercise 4.21 (Chen–Stein and 4-cliques). Use Exercise 4.20 to give an improved asymp￾totic bound in the setting of Section 4.4.3.
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press254 Coupling
Exercise 4.22 (Chen–Stein for negatively related variables). Using the notation in (4.4.1),
(4.4.2), and (4.4.3), suppose that for each i we can construct a coupling {(X
(i)
j
: j = 1, . . . , n),
(Y
(i)
j
: j 6= i)} with (X
(i)
j
)j ∼ (Xj)j such that
(Y
(i)
j
, j 6= i) ∼ (X
(i)
j
, j 6= i)|X
(i)
i = 1 and Y
(i)
j ≤ X
(i)
j
, ∀j 6= i.
Show that
kµ − πkTV ≤ (1 ∧ λ
−1
){λ − Var(W)}.
Bibliographic Remarks
Section 4.1 The coupling method is generally attributed to Doeblin [Doe38]. The standard
reference on coupling is [Lin02]. See that reference for a history of coupling and a facsimile
of Doeblin’s paper. See also [dH]. Section 4.1.2 is based on [Per, section 6] and Section 4.1.4
is based on [vdH17, section 5.3].
Section 4.2 Strassen’s theorem is due to Strassen [Str65]. Harris’ inequality is due to Har￾ris [Har60]. The FKG inequality is due to Fortuin, Kasteleyn, and Ginibre [FKG71]. A
“four-function” version of Holley’s inequality, which also extends to distributive lattices,
was proved by Ahlswede and Daykin [AD78]. See, for example, [AS11, section 6.1]. An
exposition of submodularity and its connections to convexity can be found in [Lov83]. For
more on Markov random fields, see, for example, [RAS15]. Section 4.2.4 follows [AS11,
sections 8.1, 8.2, 10.1]. Janson’s inequality is due to Janson [Jan90]. Boppana and Spen￾cer [BS89] gave the proof presented here. For more on Janson’s inequality, see [JLR11, sec￾tion 2.2]. The presentation in Section 4.2.5 follows closely [BR06b, sections 3 and 4]. See
also [BR06a, chapter 3]. Broadbent and Hammersley [BH57, Ham57] initiated the study
of the critical value of percolation. Harris’ theorem proved by Harris [Har60] and Kesten’s
theorem was proved two decades later by Kesten [Kes80], confirming non-rigorous work of
Sykes and Essam [SE64]. The RSW lemma was obtained independently by Russo [Rus78]
and Seymour and Welsh [SW78]. The proof we gave here is due to Bollobás and Rior￾dan [BR06b]. Another short proof of a version of the RSW lemma for critical site percola￾tion on a triangular lattice was given by Smirnov; see, for example, [Ste]. The type of “scale
invariance” seen in the RSW lemma plays a key role in the contemporary theory of critical
two-dimensional percolation and of two-dimensional lattice models more generally. See, for
example, [Law05, Gri10a].
Section 4.3 The material in Section 4.3 borrows heavily from [LPW06, chapters 5, 14, 15]
and [AF, chapter 12]. Aldous [Ald83] was the first author to make explicit use of coupling to
bound total variation distance to stationarity of finite Markov chains. The link between cou￾plings of Markov chains and total variation distance was also used by Griffeath [Gri75]
and Pitman [Pit76]. Example 4.3.3 is based on [Str14] and [JH01]. For a more general
treatment, see [MT09, chapter 16]. The proof of Claim 4.3.7 is partly based on [LPW06,
Proposition 7.13]. See also [DGG+00] and [HS07] for alternative proofs. Path coupling is
due to Bubley and Dyer [BD97]. The optimal transport perspective on the path coupling
method in Exercise 4.17 is from [LPW06, chapter 14]. For more on optimal transport, see,
for example, [Vil09]. The main result in Section 4.3.4 is taken from [LPW06, Theorem 15.1].
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University PressBibliographic Remarks 255
For more background on the so-called critical slowdown of the Glauber dynamics of Ising
and Potts models on various graphs, see [CDL+12, LS12].
Section 4.4 The Chen–Stein method was introduced by Chen in [Che75] as an adaptation
of the Stein method [Ste72] to the Poisson distribution. The presentation in Section 4.4
is inspired heavily by [Dey] and [vH16]. Example 4.4.9 is taken from [AGG89]. Further
applications of the Chen–Stein and Stein methods to random graphs can be found in [JLR11,
chapter 6].
https://doi.org/10.1017/9781009305129.005 Published online by Cambridge University Press5
Spectral Methods
In this chapter, we develop spectral techniques. We highlight some applications to Markov
chain mixing and network analysis. The main tools are the spectral theorem and the varia￾tional characterization of eigenvalues, which we review in Section 5.1 together with some
related results. We also give a brief introduction to spectral graph theory and detail an ap￾plication to community recovery. In Section 5.2, we apply the spectral theorem to reversible
Markov chains. In particular, we define the spectral gap and establish its close relationship
to the mixing time. Roughly speaking, we show through an eigendecomposition of the tran￾sition matrix that the gap between the eigenvalue 1 (which is the largest in absolute value)
and the rest of the spectrum drives how fast P
t
converges to the stationary distribution. We
give several examples. We then show in Section 5.3 that the spectral gap can be bounded
using certain isoperimetric properties of the underlying network. We prove Cheeger’s in￾equality, which quantifies this relationship, and introduce expander graphs, an important
family of graphs with good “expansion.” Applications to mixing times are also discussed.
One specific technique is the “canonical paths method,” which bounds the spectral graph by
formalizing a notion of congestion in the network.
5.1 Background
We first review some important concepts from linear algebra. In particular, we recall the
spectral theorem as well as the variational characterization of eigenvalues. We also derive a
few perturbation results. We end this section with an application to community recovery in
network analysis.
5.1.1 Eigenvalues and Their Variational Characterization
SYMMETRIC When a d × d matrix A is symmetric, that is, aij = aji for all i, j, a remarkable result is
MATRIX that A is similar to a diagonal matrix by an orthogonal transformation. Put differently, there
exists an orthonormal basis of R
d made of eigenvectors of A. Recall that a matrix Q ∈ R
d×d
is orthogonal if QQT = Id×d and Q
T
ORTHOGONAL Q = Id×d, where Id×d is the d × d identity matrix. In
MATRIX words, its columns form an orthonormal basis of R
d
. For a vector z = (z1, . . . ,zd), we let
diag(z) = diag(z1, . . . ,zd) be the diagonal matrix with diagonal entries z1, . . . ,zd. Unless
specified otherwise, a vector is by default a “column vector” and its transpose is a “row
vector.”
256
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.1 Background 257
Theorem 5.1.1 (Spectral theorem). Let A ∈ R
d×d be a symmetric matrix, that is, AT = SPECTRAL
A. Then A has d orthonormal eigenvectors q THEOREM 1, . . . , qd with corresponding (not necessarily
distinct) real eigenvalues λ1 ≥ λ2 ≥ · · · ≥ λd. In matrix form, this is written as the matrix
factorization
A = Q3Q
T =
X
d
i=1
λiqiq
T
i
,
where Q has columns q1, . . . , qd and 3 = diag(λ1, . . . , λd). We refer to this factorization as
a spectral decomposition of A.
The proof uses a greedy sequence maximizing the quadratic form hv, Avi. To see why that
might come about, note that for a unit eigenvector v with eigenvalue λ we have hv, Avi =
hv, λvi = λ.
We will need the following formula. Consider the block matrices

y
z

and 
A B
C D
,
where y ∈ R
d1
, z ∈ R
d2
, A ∈ R
d1×d1
, B ∈ R
d1×d2
, C ∈ R
d2×d1
, and D ∈ R
d2×d2
. Then it
follows by direct calculation that

y
z
T 
A B
C D y
z

= y
TAy + y
TBz + z
TCy + z
TDz. (5.1.1)
We will also need the following linear algebra fact. Let v1, . . . , vj be orthonormal vectors
in R
d
, with j < d. Then they can be completed into an orthonormal basis v1, . . . , vd of R
d
.
Proof of Theorem 5.1.1 We proceed by induction.
A first eigenvector Let A1 = A. Maximizing over the objective function hv, A1vi, we let
v1 ∈ arg max{hv, A1vi: kvk2 = 1}
and
λ1 = max{hv, A1vi: kvk2 = 1}.
Complete v1 into an orthonormal basis of R
d
, v1, vˆ 2, . . . , vˆ d, and form the block matrix
Wˆ
1 :=
￾
v1 Vˆ
1

,
where the columns of Vˆ
1 are vˆ 2, . . . , vˆ d. Note that Wˆ
1 is orthogonal by construction.
Getting one step closer to diagonalization We show next that Wˆ
1 gets us one step closer
to a diagonal matrix by similarity transformation. Note first that
Wˆ
T
1 A1Wˆ
1 =

λ1 w
T
1
w1 A2

,
where w1 := Vˆ T
1 A1v1 and A2 := Vˆ T
1 A1Vˆ
1. The key claim is that w1 = 0. This follows from
an argument by contradiction.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Pres258 Spectral Methods
Suppose w1 6= 0 and consider the unit vector
z := Wˆ
1 ×
1
q
1 + δ
2kw1k
2
2

1
δw1

,
which achieves objective value
z
TA1z =
1
1 + δ
2kw1k
2
2

1
δw1
T 
λ1 w
T
1
w1 A2
  1
δw1

=
1
1 + δ
2kw1k
2
2
￾
λ1 + 2δkw1k
2
2 + δ
2w
T
1A2w1

,
where we used (5.1.1). By the Taylor expansion,
1
1 + 
2
= 1 − 
2 + O(
4
),
for δ small enough,
z
TA1z = (λ1 + 2δkw1k
2
2 + δ
2w
T
1A2w1)(1 − δ
2
kw1k
2
2 + O(δ
4
))
= λ1 + 2δkw1k
2
2 + O(δ
2
)
> λ1.
That gives the desired contradiction.
So, letting W1 := Wˆ
1, we get
WT
1 A1W1 =

λ1 0
0 A2

.
Finally, note that A2 = Vˆ T
1 A1Vˆ
1 is symmetric since
A
T
2 = (Vˆ
T
1 A1Vˆ
1)
T = Vˆ
T
1 A
T
1Vˆ
1 = Vˆ
T
1 A1Vˆ
1 = A2,
by the symmetry of A1 itself.
Next step of the induction Apply the same argument to the symmetric submatrix A2 ∈
R
(d−1)×(d−1), let Wˆ
2 ∈ R
(d−1)×(d−1) be the corresponding orthogonal matrix, and define λ2
and A3 through the equation
Wˆ
T
2 A2Wˆ
2 =

λ2 0
0 A3

.
Define the block matrix
W2 =

1 0
0 Wˆ
2

https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Pres5.1 Background 259
and observe that
WT
2 WT
1 A1W1W2 = WT
2

λ1 0
0 A2

W2
=

λ1 0
0 Wˆ T
2 A2Wˆ
2

=


λ1 0 0
0 λ2 0
0 0 A3

 .
Proceeding similarly by induction gives the claim, with the final Q being the product of
the Wis (which is orthogonal as the product of orthogonal matrices).
We derive an important variational characterization inspired by the proof of the spectral
theorem. We will need the following quantity.
Definition 5.1.2 (Rayleigh quotient). Let A ∈ R
d×d be a symmetric matrix. The Rayleigh
quotient is defined as RAYLEIGH
QUOTIENT
RA(u) =
hu, Aui
hu, ui
,
which is defined for any u 6= 0 in R
d
.
We let the span of a collection of vectors be defined as SPAN
span(u1, . . . , un) :=
(Xn
i=1
αiui
: α1, . . . , αn ∈ R
)
.
COURANT–
Theorem 5.1.3 FISCHER (Courant–Fischer theorem). Let A ∈ R
d×d be a symmetric matrix with spec￾tral decomposition A =
Pd
i=1
λiviv
T
i
, where λ1 ≥ · · · ≥ λd. For each k = 1, . . . , d, define
the subspace
Vk = span(v1, . . . , vk ) and Wd−k+1 = span(vk
, . . . , vd).
Then, for all k = 1, . . . , d,
λk = min
u∈Vk
RA(u) = max
u∈Wd−k+1
RA(u).
Furthermore, we have the following min-max formulas, which do not depend on the choice
of spectral decomposition, for all k = 1, . . . , d:
λk = max
dim(V)=k
min
u∈V
RA(u) = min
dim(W)=d−k+1
max
u∈W
RA(u).
Note that, in all these formulas, the vector u = vk
is optimal. To derive the “local” formula,
the first ones above, we expand a vector in Vk
into the basis v1, . . . , vk and use the fact that
RA(vi) = λi and that eigenvalues are in non-increasing order. The “global” formulas then
follow from a dimension argument.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press260 Spectral Methods
We will need the following dimension-based fact. Let U, V ⊆ R
d be linear subspaces
such that dim(U) + dim(V) > d, where dim(U) denotes the dimension of U. Then there
exists a non-zero vector in the intersection U ∩ V. That is,
dim(U) + dim(V) > d =⇒ (U ∩ V) \ {0} 6= ∅. (5.1.2)
Proof of Theorem 5.1.3 We first prove the local formulas, that is, the ones involving a
specific decomposition.
Local formulas Since v1, . . . , vk form an orthonormal basis of Vk
, any non-zero vector
u ∈ Vk can be written as u =
Pk
i=1
hu, viivi and it follows that
hu, ui = X
k
i=1
hu, vii
2
and
hu, Aui = *
u,
X
k
i=1
hu, viiλivi
+
=
X
k
i=1
λihu, vii
2
.
Thus,
RA(u) =
hu, Aui
hu, ui
=
Pk
i=1
λihu, vii
2
Pk
i=1
hu, vii
2
≥ λk
Pk
i=1
hu, vii
2
Pk
i=1
hu, vii
2
= λk
,
where we used λ1 ≥ · · · ≥ λk and the fact that hu, vii
2 ≥ 0. Moreover, RA(vk ) = λk
. So we
have established
λk = min
u∈Vk
RA(u).
The expression in terms of Wd−k+1 is proved similarly.
Global formulas Since Vk has dimension k, it follows from the local formula that
λk = min
u∈Vk
RA(u) ≤ max
dim(V)=k
min
u∈V
RA(u).
Let V be any subspace with dimension k. Because Wd−k+1 has dimension d −k +1, we have
that dim(V) + dim(Wd−k+1) > d and there must be non-zero vector u0 in the intersection
V ∩ Wd−k+1 by the dimension-based fact above. We then have by the other local formula
that
λk = max
u∈Wd−k+1
RA(u) ≥ RA(u0) ≥ min
u∈V
RA(u).
Since this inequality holds for any subspace of dimension k, we have
λk ≥ max
dim(V)=k
min
u∈V
RA(u).
Combining with the inequality in the other direction above gives the claim. The other global
formula is proved similarly.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.1 Background 261
5.1.2 Elements of Spectral Graph Theory
We apply the variational characterization of eigenvalues to matrices arising in graph theory.
In this section, graphs have no self-loop.
Unweighted graphs As we have previously seen, a convenient way of specifying a graph
is through a matrix representation. Assume the undirected graph G = (V, E) has n = |V|
vertices. Recall that the adjacency matrix A of G is the n × n symmetric matrix defined as
Axy =
(
1 if {x, y} ∈ E,
0 otherwise.
Another matrix of interest is the Laplacian matrix. It is related to the Laplace operator we
encountered previously. We will show in particular that it contains useful information about
the connectedness of the graph. Recall that, given a graph G = (V, E), the quantity δ(v)
denotes the degree of v ∈ V.
Definition 5.1.4 (Graph Laplacian). Let G = (V, E) be a graph with vertices V = {1, . . . , n}
and adjacency matrix A ∈ R
n×n
. Let D = diag(δ(1), . . . , δ(n)) be the degree matrix. The
graph Laplacian (or Laplacian matrix, or Laplacian for short) associated to G is defined as GRAPH
L = D − A. Its entries are LAPLACIAN
lij =



δ(i) if i = j,
−1 if {i, j} ∈ E,
0 otherwise.
Observe that the Laplacian L of a graph G is a symmetric matrix:
L
T = (D − A)
T = D
T − A
T = D − A,
where we used that both D and A are themselves symmetric. The associated quadratic form
is particularly simple and will play an important role.
Lemma 5.1.5 (Laplacian quadratic form). Let G = (V, E) be a graph with n = |V| vertices.
Its Laplacian L is a positive semi-definite matrix and furthermore we have the following
formula for the Laplacian quadratic form (or Dirichlet energy) LAPLACIAN
QUADRATIC
x FORM
T Lx =
X
e={i, j}∈E
(xi − xj)
2
for any x = (x1, . . . , xn) ∈ R
n
.
Proof of Lemma 5.1.5 Let B be an oriented incidence matrix of G (see Definition 1.1.16).
We claim that BBT = L. Indeed, for i 6= j, entry (i, j) of BBT
is a sum over all edges
containing i and j as endvertices, of which there is at most one. When e = {i, j} ∈ E, that
entry is −1, since one of i or j has a 1 in the column of B corresponding to e and the other
one has a −1. For i = j, letting bxy be entry (x, y) of B,
(BBT
)ii =
X
e={x,y}∈E:i∈e
b
2
xy = δ(i).
That shows that BBT = L entry-by-entry.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press262 Spectral Methods
For any x, we have (B
T x)k = xv − xu if the edge ek = {u, v} is oriented as (u, v) under B.
That implies
x
T Lx = x
TBBT
x = kB
T
xk
2
2 =
X
e={i, j}∈E
(xi − xj)
2
.
Since the latter quantity is always non-negative, it also implies that L is positive semi￾definite.
As a convention, we denote the eigenvalues of a Laplacian matrix L by
0 ≤ µ1 ≤ µ2 ≤ · · · ≤ µn,
LAPLACIAN and we will refer to them as Laplacian eigenvalues. Here is a simple observation. For any
EIGENVALUES G = (V, E), the constant unit vector
y1 =
1
√
n
(1, . . . , 1)
is an eigenvector of the Laplacian with eigenvalue 0. Indeed, let B be an oriented incidence
matrix of G and recall from the proof of Lemma 5.1.5 that L = BBT
. By construction,
B
T y1 = 0 since each column of B has exactly one 1 and one −1. So Ly1 = BBT y1 = 0
as claimed. In general, the constant vector may not be the only eigenvector with eigenvalue
one.
We are now ready to derive connectivity consequences. Recall that, for any graph G, the
Laplacian eigenvalue µ1 = 0.
Lemma 5.1.6 (Laplacian and connectivity). If G is connected, then the Laplacian eigen￾value µ2 > 0.
Proof Let G = (V, E) with n = |V| and let L =
Pn
i=1 µiyiy
T
i
be a spectral decomposition
of its Laplacian L with 0 = µ1 ≤ · · · ≤ µn. Suppose by way of contradiction that µ2 = 0.
Any eigenvector y = ( y1, . . . , yn) with 0 eigenvalue satisfies Ly = 0 by definition. By
Lemma 5.1.5 then,
0 = y
T Ly =
X
e={i, j}∈E
( yi − yj)
2
.
In order for this to hold, it must be that any two adjacent vertices i and j have yi = yj
. That
is, {i, j} ∈ E implies yi = yj
. Furthermore, because G is connected, between any two of its
vertices u and v (adjacent or not) there is a path u = w0 ∼ · · · ∼ wk = v along which the
yws must be the same. Thus, y is a constant vector.
But that is a contradiction since the eigenvectors y1, . . . , yn are in fact linearly independ￾ent, so that y1 and y2 cannot both be a constant vector.
The quantity µ2 is sometimes referred to as the algebraic connectivity of the graph. The
FIEDLER corresponding eigenvector, y2, is known as the Fiedler vector.
VECTOR We will be interested in more quantitative results of this type. Before proceeding, we start
with a simple observation. By our proof of Theorem 5.1.1, the largest eigenvalue µn of the
Laplacian L is the solution to the optimization problem
µn = max{hx, Lxi: kxk2 = 1}.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.1 Background 263
Such extremal characterization is useful in order to bound the eigenvalue µn, since any
choice of x with kxk2 = 1 gives a lower bound through the quantity hx, Lxi. We give a simple
consequence.
Lemma 5.1.7 (Laplacian and degree). Let G = (V, E) be a graph with maximum degree δ¯.
Let µn be the largest Laplacian eigenvalue. Then,
µn ≥ δ¯ + 1.
Proof Let u ∈ V be a vertex with degree δ¯. Let z be the vector with entries
zi =



δ¯ if i = u,
−1 if {i, u} ∈ E,
0 otherwise,
and let x be the unit vector z/kzk2. By definition of the degree of u, kzk
2
2 = δ¯2 + δ¯(−1)2 =
δ¯(δ¯ + 1).
Using the Lemma 5.1.5,
hz, Lzi = X
e={i, j}∈E
(zi − zj)
2
≥
X
i:{i,u}∈E
(zi − zu)
2
=
X
i:{i,u}∈E
(−1 − δ¯)
2
= δ¯(δ¯ + 1)2
,
where we restricted the sum to those edges incident with u and used the fact that all terms in
the sum are non-negative. Finally,
hx, Lxi = 
z
kzk2
, L
z
kzk2

=
1
kzk
2
2
hz, Lzi =
δ¯(δ¯ + 1)2
δ¯(δ¯ + 1)
= δ¯ + 1,
so that
µn = max{hx
0
, Lx
0
i : kx
0
k2 = 1} ≥ hx, Lxi = δ¯ + 1,
as claimed.
A special case of Courant–Fischer (Theorem 5.1.3) for the Laplacian matrix is the fol￾lowing.
Corollary 5.1.8 (Variational characterization of µ2) Let G = (V, E) be a graph with n = |V|
vertices. Assume the Laplacian L of G has spectral decomposition L =
Pn
i=1 µiyiy
T
i with
0 = µ1 ≤ µ2 ≤ · · · ≤ µn and y1 =
1
√
n
(1, . . . , 1). Then,
µ2 = min(P
{u,v}∈E
(xu − xv)
2
Pn
u=1
x
2
u
: x = (x1, . . . , xn) 6= 0,
Xn
u=1
xu = 0
)
.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press264 Spectral Methods
Proof By Theorem 5.1.3,
µ2 = min
x∈Wd−1
RL(x).
Since y1 is constant and Wd−1 is the subspace orthogonal to it, this is equivalent to restric￾tring the minimization to those non-zero xs such that
0 = hx, y1i =
1
√
n
Xm
u=1
xu.
Moreover, by Lemma 5.1.5,
hx, Lxi = X
{u,v}∈E
(xu − xv)
2
so the Rayleigh quotient is
RL(x) =
hx, Lxi
hx, xi
=
P
{u,v}∈E
(xu − xv)
2
Pn
u=1
x
2
u
.
That proves the claim.
One application of this extremal characterization is a graph drawing heuristic. Consider
the entries of the second Laplacian eigenvector y2 normalized to have unit norm. The entries
are centered around 0 by the condition Pn
u=1
xu = 0. Because it minimizes the quantity
P
{u,v}∈E
(xu − xv)
2
Pn
u=1
x
2
u
,
over all centered unit vectors, y2 tends to assign similar coordinates to adjacent vertices. A
similar reasoning applies to the third Laplacian eigenvector, which in addition is orthogonal
to the second one. See Figure 5.1 for an illustration.
Example 5.1.9 (Two-component graph). Let G = (V, E) be a graph with two connected
components ∅ 6= V1, V2 ⊆ V. By the properties of connected components, we have V1 ∩
V
P
2 = ∅ and V1 ∪ V2 = V. Assume the Laplacian L of G has spectral decomposition L =
n
i=1 µiyiy
T
i with 0 = µ1 ≤ µ2 ≤ · · · ≤ µn and y1 =
1
√
n
(1, . . . , 1). We claimed earlier that
for such a graph µ2 = 0. We prove this here using Corollary 5.1.8:
µ2 = min( X
{u,v}∈E
(xu − xv)
2
:
x = (x1, . . . , xn) ∈ R
n
,
Xn
u=1
xu = 0, Xn
u=1
x
2
u = 1
)
.
Based on this characterization, it suffices to find a vector x satisfying Pn
u=1
P
xu = 0 and
n
u=1
x
2
u = 1 such that P
{u,v}∈E
(xu − xv)
2 = 0. Indeed, since µ2 ≥ 0 and any such x gives an
upper bound on µ2, we then necessarily have that µ2 = 0.
For P
{u,v}∈E
(xu − xv)
2
to be 0, one might be tempted to take a constant vector x. But then
we could not satisfy Pn
u=1
xu = 0 and Pn
u=1
x
2
u = 1. Instead, we modify this guess slightly.
Because the graph has two connected components, there is no edge between V1 and V2.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.1 Background 265
Figure 5.1 Top: A 3-by-3 grid graph with vertices located at independent uniformly
random points in a square. Bottom: The same 3-by-3 grid graph with vertices
located at the coordinates corresponding to the second and third eigenvectors of the
Laplacian matrix. That is, vertex i is located at position ( y2,i
, y3,i).
Hence, we can assign a different value to each component and still get P
{u,v}∈E
(xu−xv)
2 = 0.
So we look for a vector x = (x1, . . . , xn) of the form
xu =
(
α if u ∈ V1,
β if u ∈ V2.
To satisfy the constraints on x, we require
Xn
u=1
xu =
X
u∈V1
α +
X
u∈V2
β = |V1|α + |V2|β = 0
and
Xn
u=1
x
2
u =
X
u∈V1
α
2 +
X
u∈V2
β
2 = |V1|α
2 + |V2|β
2 = 1.
Replacing the first equation in the second one, we get
|V1|

−|V2|β
|V1|
2
+ |V2|β
2 =
|V2|
2β
2
|V1|
+ |V2|β
2 = 1
or
β
2 =
|V1|
|V2|(|V2| + |V1|)
=
|V1|
n|V2|
.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press266 Spectral Methods
Take
β = −s
|V1|
n|V2|
, α =
−|V2|β
|V1|
=
s
|V2|
n|V1|
.
The vector x we constructed is in fact an eigenvector of L. Indeed, let B be an oriented
incidence matrix of G. Then, for ek = {u, v}, (B
T x)k
is either xu −xv or xv −xu. In both cases,
that is 0. So Lx = BBT x = 0, that is, x is an eigenvector of L with eigenvalue 0.
We have shown that µ2 = 0 when G has two connected components. A slight modification
of this argument shows that µ2 = 0 whenever G is not connected. J
Networks In the case of a network (i.e., edge-weighted graph) G = (V, E,w), the Laplacian
can be defined as follows. As usual, we assume that w: E → R+ is a function that assigns
positive real weights to the edges. We write we = wij for the weight of edge e = {i, j}. Recall
that the degree of a vertex i is
δ(i) =
X
j:{i, j}∈E
wij.
The adjacency matrix A of G is the n × n symmetric matrix defined as
Aij =
(
wij if {i, j} ∈ E,
0 otherwise.
Definition 5.1.10 (Network Laplacian). Let G = (V, E,w) be a network with n = |V|
vertices and adjacency matrix A. Let D = diag(δ(1), . . . , δ(n)) be the degree matrix. The
network Laplacian (or Laplacian matrix, or Laplacian for short) associated to G is defined
as L = D − A.
It can be shown (see Exercise 5.2) that the Laplacian quadratic form satisfies in the edge￾weighted case
hx, Lxi = X
{i, j}∈E
wij(xi − xj)
2
(5.1.3)
for x = (x1, . . . , xn) ∈ R
n
. (The keen observer will have noticed that we already en￾countered this quantity as the “Dirichlet energy” in Section 3.3.3; more on this in Sec￾tion 5.3.) As a positive semi-definite matrix (see again Exercise 5.2), the network Lapla￾cian has an orthonormal basis of eigenvectors with non-negative eigenvalues that satisfy the
variational characterization we derived above. In particular, if we denote the eigenvalues
0 = µ1 ≤ µ2 ≤ · · · ≤ µn, it follows from Courant–Fischer (Theorem 5.1.3) that
µ2 = min( X
{u,v}∈E
wuv(xu − xv)
2
:
x = (x1, . . . , xn)
T ∈ R
n
,
Xn
u=1
xu = 0,Xn
u=1
x
2
u = 1
)
.
Other variants of the Laplacian are useful. We introduce the normalized Laplacian next.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.1 Background 267
Definition 5.1.11 (Normalized Laplacian). The normalized Laplacian of G = (V, E,w) with NORMALIZED
adjacency matrix A and degree matrix D is defined as LAPLACIAN
L = I − D
−1/2AD−1/2
.
The entries of L are
Li, j =
(
1 if i = j,
−
wij √
δ(i)δ( j)
otherwise.
We also note the following relation to the (unnormalized) Laplacian:
L = D
−1/2LD−1/2
. (5.1.4)
We check that the normalized Laplacian is symmetric:
L
T = I
T − (D
−1/2AD−1/2
)
T
= I − (D
−1/2
)
TA
T
(D
−1/2
)
T
= I − D
−1/2AD−1/2
= L.
It is also positive semi-definite. Indeed,
x
TLx = x
TD
−1/2LD−1/2
x = (D
−1/2
x)
T L(D
−1/2
x) ≥ 0,
by the properties of the Laplacian. Hence, by the spectral theorem (Theorem 5.1.1), we can
write
L =
Xn
i=1
ηiziz
T
i
,
where the zis are orthonormal eigenvectors of L and the eigenvalues satisfy
0 ≤ η1 ≤ η2 ≤ · · · ≤ ηn.
One more observation: because the constant vector is an eigenvector of L with eigenvalue
0, we get from (5.1.4) that D
1/21 is an eigenvector of L with eigenvalue 0. So η1 = 0 and we
set
(z1)i =

D
1/21
kD1/21k2

i
=
s
δ(i)
P
i∈V
δ(i)
∀i ∈ [n],
which makes z1 into a unit norm vector. The relationship to the Laplacian implies (see
Exercise 5.3) that
x
TLx =
X
{i, j}∈E
wij 
xi
√
δ(i)
−
xj
√
δ( j)
2
for x = (x1, . . . , xn) ∈ R
n
. Through the change of variables,
yi =
xi
√
δ(i)
,
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press268 Spectral Methods
Courant–Fischer (Theorem 5.1.3) gives this time
η2 = min( X
{u,v}∈E
wuv( yu − yv)
2
:
y = ( y1, . . . , yn) ∈ R
n
,
Xn
u=1
δ(u)yu = 0, Xn
u=1
δ(u)y
2
u = 1
)
. (5.1.5)
5.1.3 Perturbation Results
We will need some perturbation results for eigenvalues and eigenvectors. Recall the follow￾ing definition. Define S
m−1 = {x ∈ R
m
: kxk2 = 1}. The spectral norm (or induced 2-norm
or 2-norm) of a matrix A ∈ R
n×m
is
kAk2 := max
06=x∈Rm
kAxk
kxk
= max
x∈S
m−1
kAxk.
The induced 2-norm of a matrix has many other useful properties.
Lemma 5.1.12 (Properties of the induced norm). Let A, B ∈ R
n×m and α ∈ R. The following
hold:
(i) kAxk2 ≤ kAk2kxk2 ∀0 6= x ∈ R
m
(ii) kAk2 ≥ 0
(iii) kAk2 = 0 if and only if A = 0
(iv) kαAk2 = |α|kAk2
(v) kA + Bk2 ≤ kAk2 + kBk2
(vi) kABk2 ≤ kAk2kBk2.
Proof These properties all follow from the definition of the induced norm and the corre￾sponding properties for the vector norm:
• Claims (i) and (ii) are immediate from the definition.
• For (ii) note that kAk2 = 0 implies kAxk2 = 0, ∀x ∈ S
m−1
, so that Ax = 0, ∀x ∈ S
m−1
. In
particular, Aij = e
T
i Aej = 0, ∀i, j.
• For (iv), (v), and (vi) observe that for all x ∈ S
m−1
,
kαAxk2 = |α|kAxk2,
k(A + B)xk2 = kAx + Bxk2 ≤ kAxk2 + kBxk2 ≤ kAk2 + kBk2,
k(AB)xk2 = kA(Bx)k2 ≤ kAk2kBxk2 ≤ kAk2kBk2.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.1 Background 269
Perturbations of eigenvalues For a symmetric matrix C ∈ R
d×d
, we let λj(C), j = 1, . . . , d,
be the eigenvalues of C in non-increasing order with corresponding orthonormal eigenvec￾tors vj(C), j = 1, . . . , d. As in the Courant–Fischer theorem (Theorem 5.1.3), define the
subspaces
Vk (C) = span(v1(C), . . . , vk (C))
and
Wd−k+1(C) = span(vk (C), . . . , vd(C)).
The following lemma is one version of what is known as Weyl’s inequality. WEYL’S
INEQUALITY
Lemma 5.1.13 (Weyl’s inequality). Let A ∈ R
d×d and B ∈ R
d×d be symmetric matrices.
Then, for all j = 1, . . . , d,
max
j∈[d]

λj(B) − λj(A)

 ≤ kB − Ak2.
Proof Let H = B − A. We prove only one upper bound. The other one follows from
interchanging the roles of A and B. Because
dim(Vj(B)) + dim(Wd−j+1(A)) = j + (d − j + 1) = d + 1 > d,
it follows from (5.1.2) that Vj(B) ∩ Wd−j+1(A) contains a non-zero vector. Let v be a unit
vector in that intersection.
By Theorem 5.1.3,
λj(B) ≤ hv, (A + H)vi = hv, Avi + hv, Hvi ≤ λj(A) + hv, Hvi.
Moreover, by Cauchy–Schwarz (Theorem B.4.8), since kvk2 = 1,
hv, Hvi ≤ kvk2kHvk2 ≤ kHk2,
which proves the claim after rearranging.
Perturbations of eigenvectors While Weyl’s inequality (Lemma 5.1.13) indicates that the
eigenvalues of A and B are close when kA−Bk2 is small, it says nothing about the eigenvec￾tors. The following theorem remediates that. It is traditionally stated in terms of the angle
between the eigenvectors (whereby the name). Here we give a version that is more suited to
the applications we will encounter. We do not optimize the constants. We use the same nota￾tion as in the previous paragraph. Recall Parseval’s identity: if u1, . . . , ud is an orthonormal
basis of R
d
, then kxk
2 =
Pd
i=1
hx, uii
2
.
Theorem 5.1.14 (Davis–Kahan sin θ theorem). Let A ∈ R
d×d and B ∈ R
d×d be symmetric
matrices. For an i ∈ {1, . . . , d}, assume that
δ := min
j6=i
|λi(A) − λj(A)| > 0.
Then
min
s∈{+1,−1}
kvi(A) − svi(B)k
2
2 ≤
8kA − Bk
2
2
δ
2
.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press270 Spectral Methods
Proof Expand vi(B) in the basis formed by the eigenvectors of A, that is,
vi(B) =
X
d
j=1
hvi(B), vj(A)i vj(A),
where we used the orthonormality of the vj(A)s. On the one hand,
k(A − λi(A)Id×d) vi(B)k
2
2
=






X
d
j=1
hvi(B), vj(A)i(A − λi(A)Id×d) vj(A)






2
2
=






X
d
j=1, j6=i
hvi(B), vj(A)i(λj(A) − λi(A)) vj(A)






2
2
=
X
d
j=1, j6=i
hvi(B), vj(A)i
2
(λj(A) − λi(A))2
≥ δ
2
(1 − hvi(B), vi(A)i
2
),
where, on the last two lines, we used the orthonormality of the vj(A)s and vj(B)s through
Parseval’s identity, as well as the definition of δ.
On the other hand, letting E = A − B, by the triangle inequality,
k(A − λi(A)I) vi(B)k2 = k(B + E − λi(A)I) vi(B)k2
≤ k(B − λi(A)I) vi(B)k2 + kE vi(B)k2
≤ |λi(B) − λi(A)|kvi(B)k2 + kEk2kvi(B)k2
= 2kEk2,
where we used Lemma 5.1.12 and Weyl’s inequality.
Combining the last two inequalities gives
(1 − hvi(B), vi(A)i
2
) ≤
4kEk
2
2
δ
2
.
The result follows by noting that since |hvi(B), vi(A)i| ≤ 1 by Cauchy–Schwarz (Theo￾rem B.4.8), we have
min
s∈{+1,−1}
kvi(A) − svi(B)k
2 = 2 − 2|hvi(B), vi(A)i|
≤ 2(1 − hvi(B), vi(A)i
2
)
≤
8kEk
2
2
δ
2
.
5.1.4 F Data Science: Community Recovery
A common task in network analysis is to recover hidden community structure. Informally, we
seek groups of vertices with more edges within the groups than to the rest of the graph. More
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.1 Background 271
rigorously, providing statistical guarantees on the output of a community recovery algorithm
requires some underlying random graph model. The standard model for this purpose is the
stochastic blockmodel, a generalization of the Erdos–Renyí graph model with a “planted ˝
partition.”
Stochastic blockmodel and recovery requirement We restrict ourselves to the simple case
of two strictly balanced communities. Consider a random graph on n (even) nodes where
there are two communities, labeled +1 and −1, consisting of n/2 nodes. Each vertex i ∈ V
is assigned a community label Xi ∈ {1, −1} as follows: a subset of n/2 vertices is chosen
uniformly at random among all such subsets to form community +1, and the rest of the
vertices form community −1. For two nodes i, j, the edge {i, j} is present with probability
p if they belong to the same community, and with probability q otherwise. All edges are
independent. The following 2 × 2 matrix describes the edge density within and across the
two communities:
W =
+1 −1
  +1 p q
−1 q p
.
We assume that p ≥ q, encoding the fact that vertices belonging to the same community are
more likely to share an edge. To summarize, we say that (X, G) ∼ SBMn,p,q if: STOCHASTIC
BOCKMODEL
1. (Communities) The assignment X = (X1, . . . , Xn) is uniformly random over
5n
2
:= {x ∈ {+1, −1}
n
: x
T
1 = 0},
where 1 = (1, . . . , 1) is the all-one vector.
2. (Graph) Conditioned on X, the graph G = ([n], E) has independent edges where {i, j} is
present with probability WXi
, Xj
for ∀i < j .
We denote the corresponding measure by Pn,p,q. We allow p and q to depend on n (although
we do not make that dependence explicit).
Roughly speaking, the community recovery problem is the following: given G, output X.
There are different notions of recovery.
Definition 5.1.15 (Agreement). The agreement between two community assignment vectors
x, y ∈ {+1, −1}
n
is the largest fraction of common assignments between x and ±y, that is,
α(x, y) = max
s∈{+1,−1}
1
n
Xn
i=1
1{xi = syi}.
The role of s in this formula is to account for the fact that the community names are not
meaningful.
Now consider the following recovery requirements. These are asymptotic notions, as n →
+∞.
Definition 5.1.16 (Recovery requirement). Let (X, G) ∼ SBMn,p,q. For any estimator Xˆ := RECOVERY
Xˆ (G) ∈ 5n
2
, we say that it achieves:
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press272 Spectral Methods
• exact recovery if Pn,p,q[α(X, Xˆ ) = 1] = 1 − o(1); or
• almost exact recovery if Pn,p,q[α(X, Xˆ ) = 1 − o(1)] = 1 − o(1).
Next we establish sufficient conditions for almost exact recovery. First we describe a natural
estimator Xˆ .
MAP estimator and spectral clustering A natural starting point is the maximum a pos￾teriori (MAP) estimator. Let (X) be the balanced partition of [n] corresponding to X and
ˆ (G) be the one corresponding to Xˆ (G). The probability of error, that is, the probability of
not recovering the true partition, is given by
P[(X) 6= ˆ (G)] =
X
g
P[ˆ (g) 6= (X) | G = g] P[G = g], (5.1.6)
where the sum is over all graphs on n vertices (i.e., all possible subsets of edges present) and
we dropped the subscript n, p, q to simplify the notation. The MAP estimator ˆ MAP(G) is
obtained by minimizing each term P[ˆ (g) 6= (X) | G = g] individually (note that P[G =
g] > 0 for all g by definition of the SBMn,p,q, a probability which does not depend on the
estimator). Equivalently, we choose for each g a partition γ that maximizes the posterior
probability
P[(X) = γ | G = g] =
P[G = g | (X) = γ ] P[(X) = γ ]
P[G = g]
= P[G = g | (X) = γ ] ·
1
|5n
2
| P[G = g]
, (5.1.7)
where we applied Bayes’ rule on the first line and the uniformity of the partition X on the
second line.
Based on (5.1.7), we seek a partition that maximizes P[G = g | (X) = γ ]. We compute
this last probability explicitly. For fixed g, let M := M(g) be the number of edges in g.
For any γ , denote by Min := Min(g, γ ) and Mout := Mout(g, γ ) the number of edges within
and across communities, respectively, and note that Min = M − Mout. By definition of the
SBMn,p,q model, the probability of a graph g given a partition γ is expressed simply as
P[G = g | (X) = γ ]
= q
Mout(1 − q)
(
n
2 )
2
−Moutp
Min (1 − p)

(
n
2)−(
n
2
)
2
	
−Min
= q
Mout(1 − q)
(
n
2 )
2
−Moutp
M−Mout(1 − p)

(
n
2)−(
n
2
)
2
	
−{M−Mout}
=

q
1 − q
·
1 − p
p
Mout 
(1 − q)
(
n
2 )
2
p
M (1 − p)

(
n
2)−(
n
2 )
2
	
−M

.
The expression in curly brackets does not depend on the partition γ . Moreover, since we
assume that p ≥ q, we have that h
q
1−q
·
1−p
p
i
≤ 1 (which can be checked directly by rear￾ranging and canceling). Therefore, to maximize P[G = g | (X) = γ ] over γ for a fixed g,
we need to choose a partition that results in the smallest possible value of Mout, the number
of edges across the two communities. This problem is well known in combinatorial optimi￾zation, where it is referred to as the minimum bisection problem. It is unfortunately NP-hard
MINIMUM
BISECTION
PROBLEM and we consider a relaxation that admits a polynomial-time algorithmic solution.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.1 Background 273
To see how this comes about, observe that the minimum bisection problem can be refor￾mulated as
max
x∈{+1,−1}
n
, x
T 1=0
x
TAx,
where A is the n×n adjacency matrix. Replacing the combinatorial constraint x ∈ {+1, −1}
n
by x ∈ R
n with kxk2 = n leads to the relaxation
max
z∈Rn
, z
T 1=0, kzk2=n
z
TAz
= max
06=z∈Rn
, z
T 1=0

n
z
kzk2
T
A

n
z
kzk2

= n
2 max
06=z∈Rn
, z
T 1=0
z
TAz
z
T z
,
where we changed the notation from x to z to emphasize that the solution no longer encodes
a partition. We recognize the Rayleigh quotient of A as the objective function in the final for￾mulation. At this point, it is tempting to use Courant–Fischer (Theorem 5.1.3) and conclude
that the maximum above is achieved at the second eigenvalue of A. Note, however, that the
vector 1 (appearing in the orthogonality constraint z
T 1 = 0) is not in general an eigenvector
of A (unless the graph happens to be regular). To leverage the variational characterization of
eigenvalues in a statistically justified way, we instead turn to the expected adjacency matrix
and then establish concentration.
Lemma 5.1.17 (Expected adjacency). Let (X, G) ∼ SBMn,p,q, let A be the adjacency matrix
of G, and let AX = En,p,q[A | X]. Then,
AX = n
p + q
2
u1u
T
1 + n
p − q
2
u2u
T
2 − p I,
where
u1 =
1
√
n
1, u2 =
1
√
n
X.
Proof For any distinct pair i, j, the term

n
p + q
2
u1u
T
1

i, j
= n
p + q
2

1
√
n
2
=
p + q
2
,
while the term

n
p − q
2
u2u
T
2

i, j
= n
p − q
2

1
√
n
2
XiXj =
p − q
2
XiXj
.
The product XiXj
is 1 when i and j belong to the same community and is −1 otherwise. In
the former case, summing the two terms indeed gives p, while in the latter case it gives q.
Finally, the term −pI accounts for the fact that A has zeros on the diagonal.
Now condition on X and observe that u1 and u2 in Lemma 5.1.17 are orthogonal by our
assumption that X corresponds to a balanced partition (i.e., with two communities of equal
size). Hence we deduce that an eigenvector decomposition of AX is formed of u1, u2, and any
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press274 Spectral Methods
orthonormal basis of the orthogonal complement of the span of u1 and u2, with respective
eigenvalues
n
p + q
2
− p, n
p − q
2
− p, −p.
So the second largest eigenvalue of AX is λ2(AX ) = n
p−q
2 − p (independently of X), and
Courant–Fischer implies
max
06=z∈Rn
,z
T 1=0
z
TAX z
z
T z
= λ2(AX ).
The corresponding eigenvector, up to scaling and sign, is precisely what we are trying to
recover, namely, the community assignment X.
SPECTRAL These observations motivate the following spectral clustering approach.
CLUSTERING
1. Input: graph G with adjacency matrix A.
2. Compute an eigenvector decomposition of A.
3. Let uˆ 2 be the eigenvector corresponding to the second largest eigenvalue.
4. Output: Xˆ (G) = sgn ￾
uˆ 2

.
Here we used the notation
(sgn(z))i =
(
+1 if zi ≥ 0,
−1 otherwise.
Because we used A rather than AX (which we do not know), it is not immediate that this
approach will work. Below, we use Davis–Kahan (Theorem 5.1.14) to show that, under some
conditions, the second eigenvector of A is concentrated around that of AX – and therefore
almost exact recovery holds.
Before getting to the analysis, we make a final algorithmic remark. The “clustering”
above, specifically taking the sign of the second eigenvector, works in this toy model but
is perhaps somewhat naive. More generally, in a spectral clustering method, one uses the top
eigenvectors (deciding how many is a bit of an art) of the adjacency matrix (or of another
matrix associated to the graph such as the Laplacian or normalized Laplacian) to obtain a
low-dimensional representation of the input. Then in a second step, one uses a clustering
algorithm, for example, k-means clustering, to extract communities in the low-dimensional
space.
Almost exact recovery We prove the following. We restrict ourselves to the case where p
and q are constants not depending on n.
Theorem 5.1.18 Let (X, G) ∼ SBMn,p,q and let A be the adjacency matrix of G. Let µ :=
min 
q,
p−q
2
	
> 0. Clustering according to the sign of the second eigenvector of A identifies
the two communities of G with probability at least 1 − e
−n
, except for C/µ2 misclassified
nodes for some constant C > 0.
There are two key ingredients to the proof: concentration of the adjacency matrix and per￾turbation arguments.
We start with the former.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Pres5.1 Background 275
Lemma 5.1.19 (Norm of the adjacency). Let (X, G) ∼ SBMn,p,q, let A be the adjacency
matrix of G and let AX = En,p,q[A | X]. There is a constant C0 > 0 such that, conditioned
on X ,
kA − AX k2 ≤ C
0√
n,
with probability at least 1 − e
−n
.
Proof Condition on X. We use Theorem 2.4.28 on the random matrix R := A − AX . The
entries of R are centered and independent (conditionally on X). Moreover, they are bounded.
Indeed, for i 6= j, Aij ∈ {0, 1} while (AX )ij ∈ {q, p}. So Rij ≤ [−p, 1 − q]. On the diagonal,
Rii = 0. Hence, by Hoeffding’s lemma (Lemma 2.4.12), the entries are sub-Gaussian with
variance factor
1
4
(1 − q − (−p))2 ≤ 1.
Taking t =
√
n in Theorem 2.4.28, there is a constant C > 0 such that with probability
1 − e
−n
,
kA − AX k2 ≤ C
√
1(√
n +
√
n +
√
n).
Adjusting the constant gives the claim.
We are ready to prove the theorem.
Proof of Theorem 5.1.18 Condition on X. To apply the Davis–Kahan theorem (Theorem
5.1.14), we need to bound the smallest gap δ between the second largest eigenvalue of AX
and its other eigenvalues. Recall that the eigenvalues are
n
p + q
2
− p, n
p − q
2
− p, −p,
so
δ = min 
n
p − q
2
, n q
= nµ > 0.
By Davis–Kahan and Lemma 5.1.19, with probability at least 1−e
−n
, there is θ ∈ {+1, −1}
such that
ku2 − θ uˆ 2k
2
2 ≤
8kA − AX k
2
2
δ
2
≤
8(C
0√
n)
2
(nµ)
2
=
C
nµ2
,
by adjusting the constant. Note that this bound holds for any X.
Rearranging and expanding the norm, we get
X
i


√
n (u2)i −
√
n θ (uˆ 2)i


2
≤
C
µ2
.
If the signs of (u2)i and θ (uˆ 2)i disagree, then the ith term in the sum above is ≥ 1. So there
can be at most C/µ2
such disagreements. That establishes the desired bound on the number
of misclassified nodes.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press276 Spectral Methods
Remark 5.1.20 It was shown in [YP14, MNS15a, AS15] that almost exact recovery in the
balanced two-community model SBMn,pn,qn with pn = an/n and qn = bn/n is achievable and
computationally efficiently so if and only if
(an − bn)
2
(an + bn)
= ω(1).
On the other hand, it was shown in [ABH16, MNS15a] that exact recovery in the SBMn,pn,qn
with pn = α log n/n and qn = β log n/n is achievable and computationally efficiently so if
√
α −
√
β > 2 and not achievable if √
α −
√
β < 2.
5.2 Spectral Techniques for Reversible Markov Chains
In this section, we apply the spectral theorem to reversible Markov chains. Throughout (Xt)
is a Markov chain on a state space V with transition matrix P reversible with respect to a
positive stationary measure π > 0. Recall that this means that π(x)P(x, y) = π( y)P( y, x)
for all x, y ∈ V. We also assume that P is irreducible.
A Hilbert space It will be convenient to introduce a Hilbert space of functions over V. Let
`
2
(V, π) be the space of functions f : V → R such that P
x∈V π(x)f (x)
2 < +∞. Equipped
with the following inner product, it forms a Hilbert space (i.e., a real inner product space that
is also a complete metric space (see Theorem B.4.10) with respect to the induced metric; we
will work mostly in finite dimension where it is merely a slight generalization of Euclidean
space). For f , g ∈ `
2
(V, π), define
hf , giπ :=
X
x∈V
π(x)f (x)g(x)
and
k f k
2
π
:= hf , f iπ .
The inner product is well defined since the series is summable by Hölder’s inequality (The￾orem B.4.8), which implies the Cauchy–Schwarz inequality
hf , giπ ≤ k f kπ kgkπ .
Minkowski’s inequality (Theorem B.4.9) implies the triangle inequality
k f + gkπ ≤ k f kπ + kgkπ .
The integral with respect to π (see Appendix B) reduces in this case to a sum
π( f ) :=
X
x∈V
π(x)f (x),
provided π(| f |) < +∞ or f ≥ 0. Here | f | is defined as | f |(x) := | f (x)| for all x ∈ V. We
also write πf = π( f ) to simplify the notation.
We recall some standard Hilbert space facts. The countable collection of functions {fi}
∞
i=1
in `
2
(V, π) is an orthonormal basis if: (i) hfi
, fjiπ = 0 if i 6= j and = 1 if i = j; and (ii) any
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.2 Spectral Techniques for Reversible Markov Chains 277
f ∈ `
2
(V, π) can be written as limn→+∞ Pn
i=1
hfi
, f iπ fi = f , where the limit is in the norm.
We then have Parseval’s identity: for any g ∈ `
2
(V, π), PARSEVAL’S
IDENTITY
kgk
2
π =
X∞
j=1
hg, fji
2
π
. (5.2.1)
Think of P as an operator on `
2
(V, π). That is, let Pf : V → R be defined as
(Pf )(x) :=
X
y∈V
P(x, y)f ( y),
for x ∈ V. For any f ∈ `
2
(V, π), Pf is well defined and further we have
kPf kπ ≤ k f kπ . (5.2.2)
Indeed by Cauchy–Schwarz, stochasticity, Fubini and stationarity,
kP| f |k2
π =
X
x
π(x)
"X
y
P(x, y)| f ( y)|
#2
≤
X
x
π(x)
"X
y
P(x, y)| f ( y)|
2X
z
P(x,z)
#
=
X
y
X
x
π(x)P(x, y)f ( y)
2
=
X
y
π( y)f ( y)
2
= k f k
2
π < +∞. (5.2.3)
This shows that Pf is well defined since π > 0 and hence the series in square brackets on
the first line is finite for all x. Applying the same argument to kPf k
2
π
gives the inequality
above.
Everything above holds whether or not P is reversible, so long as π is a stationary meas￾ure. Now we use reversibility. We claim that, when P reversible, then it is self-adjoint, that
is,
hf , Pgiπ = hPf , giπ ∀f , g ∈ `
2
(V, π). (5.2.4)
This follows immediately by reversibility
hf , Pgiπ =
X
x∈V
π(x)f (x)
X
y∈V
P(x, y)g( y)
=
X
x∈V
X
y∈V
π( y)P( y, x)f (x)g( y)
=
X
y∈V
π( y)g( y)
X
x∈V
P( y, x)f (x)
= hPf , giπ ,
where we argue as in (5.2.3) to justify using Fubini.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press278 Spectral Methods
Throughout this section, we denote by 0 and 1 the all-zero and all-one functions, respec￾tively.
5.2.1 Spectral Gap
In this subsection, we restrict ourselves to a finite state space V. Our goal is to bound the
mixing time of (Xt) in terms of the eigenvalues of the transition matrix P. We assume that π is
now the stationary distribution, that is, P
x∈V π(x) = 1 (which is unique by Theorem 1.1.24
and irreducibility). We also let n := |V| < +∞.
Spectral decomposition Self-adjointness generalizes the notion of a symmetric matrix,
with one consequence being that a version of the spectral theorem applies to P (at least in this
finite-dimensional case; see Section 5.2.5 for more discussion on this). For completeness, we
derive it from Theorem 5.1.1. It will be convenient to assume without loss of generality that
V = [n] and identify functions in `
2
(V, π) with vectors in R
n
.
Theorem 5.2.1 (Reversibility: spectral theorem). There is an orthonormal basis of `
2
(V, π)
formed of real eigenfunctions {fj}
n
j=1
of P with real eigenvalues {λj}
n
j=1
.
Proof Let Dπ be the diagonal matrix with π on the diagonal. By reversibility
M(x, y) := (D
1/2
π PD−1/2
π
)x,y
=
s
π(x)
π( y)
P(x, y)
=
s
π( y)
π(x)
P( y, x)
= (D
1/2
π PD−1/2
π
)y,x
= M( y, x).
So M = (M(x, y))x,y = D
1/2
π PD−1/2
π
is a symmetric matrix. By the spectral theorem (Theorem
5.1.1), it has real eigenvectors {φj}
n
j=1
forming an orthonormal basis of R
n with correspond￾ing real eigenvalues {λj}
n
j=1
. Define fj
:= D
−1/2
π φj
. Then,
Pfj = PD−1/2
π φj
= D
−1/2
π D
1/2
π PD−1/2
π φj
= D
−1/2
π Mφj
= λjD
−1/2
π φj
= λj
fj
and
hfi
, fjiπ = hD
−1/2
π φi
, D
−1/2
π φjiπ
=
X
x∈V
π(x)[π(x)
−1/2φi(x)][π(x)
−1/2φj(x)]
= hφi
, φji.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.2 Spectral Techniques for Reversible Markov Chains 279
Because {φj}
n
j=1
is an orthonormal basis of R
n
, we have that {fj}
n
j=1
is an orthonormal basis
of (R
n
,h·, ·iπ ).
We collect a few more facts about the eigenbasis. Recall that
k f k∞ = max
x∈V
| f (x)|.
Lemma 5.2.2 Any eigenvalue λ of P satisfies |λ| ≤ 1.
Proof It holds that
Pf = λf =⇒ |λ|k f k∞ = kPf k∞ = max
x





X
y
P(x, y)f ( y)





≤ k f k∞.
Rearranging gives the claim.
We order the eigenvalues 1 ≥ λ1 ≥ · · · ≥ λn ≥ −1. The second eigenvalue will play an
important role below.
Lemma 5.2.3 We have λ1 = 1 and λ2 < 1. Also we can take f1 = 1.
Proof Because P is stochastic, the all-one vector is a right eigenvector with eigenvalue 1.
Any eigenfunction with eigenvalue 1 is harmonic with respect to P on V (see (3.3.2)). By
Corollary 3.3.3, for a finite, irreducible chain the only harmonic functions are the constant
functions. So the eigenspace corresponding to 1 is one-dimensional. We must have λ2 < 1
by Lemma 5.2.2.
When the chain is aperiodic, it cannot have an eigenvalue −1. Exercise 5.9 asks for a proof.
Lemma 5.2.4 If P has an eigenvalue equal to −1, then P is not aperiodic.
Lemma 5.2.5 For all j 6= 1, πfj = 0.
Proof By orthonormality, hf1, fjiπ = 0. Now use the fact that f1 = 1.
Let δx( y) := 1{x=y}
.
Lemma 5.2.6 For all x, y,
Xn
j=1
fj(x)fj( y) = π(x)
−1
δx( y).
Proof Using the notation of Theorem 5.2.1, the matrix 8 whose columns are the φjs is
orthogonal so 88T = I. That is,
Xn
j=1
φj(x)φj( y) = δx( y),
or
Xn
j=1
p
π(x)π( y)fj(x)fj( y) = δx( y).
Rearranging gives the result.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press280 Spectral Methods
Using the eigendecomposition of P, we get the following expression for its tth power P
t
.
Theorem 5.2.7 (Spectral decomposition of P
t
). Let {fj}
n
j=1
be the eigenfunctions of a revers￾ible and irreducible transition matrix P with corresponding eigenvalues {λj}
n
j=1
, as defined
previously. Assume λ1 ≥ · · · ≥ λn. We have the decomposition
P
t
(x, y)
π( y)
= 1 +
Xn
j=2
fj(x)fj( y)λ
t
j
.
Proof Let F be the matrix whose columns are the eigenvectors {fj}
n
j=1
and let Dλ be the di￾agonal matrix with {λj}
n
j=1
on the diagonal. Using the notation in the proof of Theorem 5.2.1,
D
1/2
π P
tD
−1/2
π = Mt = (D
1/2
π F)D
t
λ
(D
1/2
π F)
T
,
which after rearranging becomes
P
tD
−1
π = FDt
λF
T
.
Expanding and using Lemma 5.2.3 gives the result.
Example 5.2.8 (Two-state chain). Let V := {0, 1} and
P :=

1 − α α
β 1 − β

for α, β ∈ (0, 1). Observe that P is reversible with respect to the stationary distribution
π :=

β
α + β
,
α
α + β

.
We know that f1 = 1 is an eigenfunction with eigenvalue 1. As can be checked by direct
computation, the other eigenfunction (in vector form) is
f2 :=
 r
α
β
, −
r
β
α
!
,
with eigenvalue λ2 := 1 − α − β. We normalized f2 so that k f2k
2
π = 1.
By Theorem 5.2.7, the spectral decomposition at time t is therefore
P
tD
−1
π =

1 1
1 1
+ (1 − α − β)
t
 α
β −1
−1
β
α

.
Or, rearranging,
P
t =
 β
α+β
α
α+β
β
α+β
α
α+β
!
+ (1 − α − β)
t
 
α
α+β −
α
α+β
−
β
α+β
β
α+β
!
.
Note for instance that the case α + β = 1 corresponds to a rank-one P, which immediately
converges to stationarity.
Assume β ≥ α. Then, by (1.1.6) and Lemma 4.1.9,
d(t) = max
x
1
2
X
y
|P
t
(x, y) − π( y)| =
β
α + β
|1 − α − β|
t
.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.2 Spectral Techniques for Reversible Markov Chains 281
As a result,
tmix(ε) =




log 
ε
α+β
β

log |1 − α − β|




=




log ε
−1 − log 
α+β
β

log |1 − α − β|
−1




.
J
Spectral gap and mixing Assume further that P is aperiodic. Recall that by the convergence
theorem (Theorem 1.1.33), for all x, y, P
t
(x, y) → π( y) as t → +∞, and that the mixing
time (Definition 1.1.35) is
tmix(ε) := min{t ≥ 0 : d(t) ≤ ε},
where d(t) := maxx∈V kP
t
(x, ·) − π(·)kTV. It will be convenient to work with a different
notion of distance.
Definition 5.2.9 (Separation distance). The separation distance is defined as SEPARATION
DISTANCE
sx(t) := max
y∈V

1 −
P
t
(x, y)
π( y)

,
and we let s(t) := maxx∈V sx(t).
Lemma 5.2.10 (Separation distance and total variation distance).
d(t) ≤ s(t).
Proof By Lemma 4.1.15,
kP
t
(x, ·) − π(·)kTV =
X
y:Pt
(x,y)<π( y)

π( y) − P
t
(x, y)

=
X
y:Pt
(x,y)<π( y)
π( y)

1 −
P
t
(x, y)
π( y)

≤ sx(t).
Since this holds for any x, the claim follows.
It follows that, from the spectral decomposition (Theorem 5.2.7), the speed of conver￾gence of P
t
(x, y) to π( y) is dominated by the largest eigenvalue of P not equal to 1.
Definition 5.2.11 (Spectral gap). The absolute spectral gap is γ∗ := 1 − λ∗ where λ∗ := ABSOLUTE
SPECTRAL
GAP
|λ2| ∨ |λn|. The spectral gap is γ := 1 − λ2.
By Lemmas 5.2.3 and 5.2.4, we have γ∗ > 0 when P is irreducible and aperiodic. Note
that the eigenvalues of the lazy version 1
2
P +
1
2
I of P are 
1
2
(λj + 1)	n
j=1
, which are all non￾negative. So, there, γ∗ = γ .
Definition 5.2.12 (Relaxation time). The relaxation time is defined as RELAXATION
TIME
trel := γ
−1
∗
.
Example 5.2.13 (Two-state chain (continued)). Returning to Example 5.2.8, there are two
cases:
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press282 Spectral Methods
• α + β ≤ 1: In that case the spectral gap is γ = γ∗ = α + β and the relaxation time is
trel = 1/(α + β).
• α + β > 1: In that case the spectral gap is γ = γ∗ = 2 − α − β and the relaxation time is
trel = 1/(2 − α − β). J
The following result clarifies the relationship between the mixing and relaxation times.
Let πmin = minx π(x).
Theorem 5.2.14 (Mixing time and relaxation time). Let P be reversible, irreducible, and
aperiodic with positive stationary distribution π. For all ε > 0,
(trel − 1) log
1
2ε

≤ tmix(ε) ≤ log
1
επmin
trel.
Proof We start with the upper bound. By Lemma 5.2.10, it suffices to find t such that
s(t) ≤ ε. By the spectral decomposition and Cauchy–Schwarz,




P
t
(x, y)
π( y)
− 1




≤ λ
t
∗
Xn
j=2
| fj(x)fj( y)| ≤ λ
t
∗
vuut
Xn
j=2
fj(x)
2Xn
j=2
fj( y)
2
.
By Lemma 5.2.6,
Pn
j=2
fj(x)
2 ≤ π(x)
−1
. Plugging this back above, we get




P
t
(x, y)
π( y)
− 1




≤ λ
t
∗
p
π(x)
−1π( y)
−1 ≤
λ
t
∗
πmin
=
(1 − γ∗)
t
πmin
≤
e
−γ∗t
πmin
, (5.2.5)
where we used that 1−z ≤ e
−z
for all z ∈ R (see Exercise 1.16). Observe that the right-hand
side is less than ε when t ≥ log 
1
επmin 
trel.
For the lower bound , let f∗ be an eigenfunction associated with an eigenvalue achieving
λ∗ := |λ2| ∨ |λn|. Let z be such that | f∗(z)| = k f∗k∞. By Lemma 5.2.5, πf∗ = 0. Hence,
λ
t
∗
| f∗(z)| = |P
t
f∗(z)|
=





X
y
[P
t
(z, y)f∗( y) − π( y)f∗( y)]





≤ k f∗k∞
X
y
|P
t
(z, y) − π( y)| ≤ k f∗k∞2d(t),
so d(t) ≥
1
2
λ
t
∗
. When t = tmix(ε), ε ≥
1
2
λ
tmix(ε)
∗ . Therefore,
tmix(ε)

1
λ∗
− 1

≥ tmix(ε) log
1
λ∗

≥ log
1
2ε

.
The result follows from 
1
λ∗
− 1
−1
=

1−λ∗
λ∗
−1
=

γ∗
1−γ∗
−1
= trel − 1.
5.2.2 F Random Walks: A Spectral Look at Cycles and Hypercubes
We illustrate the results in the previous subsection to random walk on cycles and hypercubes.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.2 Spectral Techniques for Reversible Markov Chains 283
Random walk on a cycle
Consider simple random walk on the n-cycle (see Example 1.1.17). That is, V := {0, 1, . . . ,
n − 1} and P(x, y) = 1/2 if and only if |x − y| = 1 mod n. We assume that n is odd
to avoid periodicity issues. Let π ≡ n
−1 be the stationary distribution (by symmetry and
|V| = n). We showed in Section 4.3.2 that (for the lazy version of the chain) the mixing time
is tmix(ε) = 2(n
2
).
Here we use spectral techniques. We first compute the eigendecomposition, which in this
case can be determined explicitly.
Lemma 5.2.15 (Cycle: eigenbasis). For j = 1, . . . , n − 1, the function
gj(x) :=
√
2 cos
2πjx
n

, x = 0, 1, . . . , n − 1,
is an eigenfunction of P with eigenvalue
µj
:= cos
2πj
n

,
and g0 = 1 is an eigenfunction with eigenvalue 1. Moreover, the gjs are orthonormal in
`
2
(V, π).
Proof We know from Lemma 5.2.3 that 1 is an eigenfunction with eigenvalue 1. Let j ∈
{1, . . . , n − 1}. Note that, for all x, switching momentarily to the complex representation
(where we use i for the imaginary unit),
X
y
P(x, y)gj( y) =
1
2
√
2 cos
2πj(x − 1)
n

+
√
2 cos
2πj(x + 1)
n

=
√
2
2
"
e
i
2πj(x−1)
n + e
−i
2πj(x−1)
n
2
+
e
i
2πj(x+1)
n + e
−i
2πj(x+1)
n
2
#
=
√
2
"
e
i
2πjx
n + e
−i
2πjx
n
2
# "e
i
2πj
n + e
−i
2πj
n
2
#
=
√
2 cos
2πjx
n
 cos
2πj
n

= cos
2πj
n

gj(x).
The orthonormality follows from standard trigonometric identities. We prove only that
they have unit norm. We use the Dirichtlet kernel (see Exercise 5.8)
1 + 2
Xn
k=1
cos kθ =
sin((n + 1/2)θ)
sin(θ/2)
for θ 6= 0, and the identity cos2
(θ) =
1
2
(1+cos(2θ)). For j = 0, gj = 1 and the norm squared
is P
x π(x) = 1. For j 6= 0, we have kgjk
2
π
is
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press284 Spectral Methods
X
x∈V
π(x)gj(x)
2 =
1
n
Xn−1
x=0
2 cos2

2πjx
n

=
1
n
Xn−1
x=0

1 + cos
4πjx
n

= 1 +
1
n
Xn
k=1
cos
k
4πj
n

= 1 +
1
2

sin((n + 1/2)(4πj/n))
sin((4πj/n)/2)
− 1

,
which is indeed 1.
From the eigenvalues, we derive the relaxation time (Definition 5.2.12) analytically.
Theorem 5.2.16 (Cycle: relaxation time). The relaxation time for lazy simple random walk
on the n-cycle is
trel =
1
1 − cos ￾
2π
n
 = 2(n
2
).
Proof By Lemma 5.2.15, the absolute spectral gap (Definition 5.2.11) is 1−cos ￾
2π
n

, using
that n is odd. By a Taylor expansion,
1 − cos
2π
n

=
4π
2
n
2
+ O(n
−4
).
Since πmin = 1/n, we get tmix(ε) = O(n
2
log n) and tmix(ε) = (n
2
) by Theorem 5.2.14.
It turns out our upper bound is off by a logarithmic factor. A sharper bound on the mixing
time can be obtained by working directly with the spectral decomposition. By Lemma 4.1.9
and Cauchy–Schwarz (Theorem B.4.8), for any x ∈ V,
4kP
t
(x, ·) − π(·)k
2
TV =
(X
y
π( y)




P
t
(x, y)
π( y)
− 1




)2
≤
X
y
π( y)

P
t
(x, y)
π( y)
− 1
2
=






Xn−1
j=1
µ
t
j
gj(x)gj






2
π
=
Xn−1
j=1
µ
2t
j
gj(x)
2
,
where we used the spectral decomposition of P
t
(Theorem 5.2.7) on the third line and Par￾seval’s identity (i.e., (5.2.1)) on the fourth line.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Pre5.2 Spectral Techniques for Reversible Markov Chains 285
Here comes the trick: the total variation distance does not depend on the starting point x
by symmetry. Multiplying by π(x) and summing over x – on the right-hand side only – gives
4kP
t
(x, ·) − π(·)k
2
TV ≤
X
x
π(x)
Xn−1
j=1
µ
2t
j
gj(x)
2
=
Xn−1
j=1
µ
2t
j
X
x
π(x)gj(x)
2
=
Xn−1
j=1
µ
2t
j
,
where we used that kgjk
2
π = 1.
We get
4d(t)
2 ≤
Xn−1
j=1
cos2t

2πj
n

= 2
(nX−1)/2
j=1
cos2t

2πj
n

.
For x ∈ [0, π/2), cos x ≤ e
−x
2
/2
(see Exercise 1.16). Then,
4d(t)
2 ≤ 2
(nX−1)/2
j=1
exp
−
4π
2
j
2
n
2
t

≤ 2 exp
−
4π
2
n
2
t
X∞
j=1
exp
−
4π
2
(j
2 − 1)
n
2
t

≤ 2 exp
−
4π
2
n
2
t
X∞
`=0
exp
−
4π
2
t
n
2
`

=
2 exp 
−
4π
2
n
2
t

1 − exp 
−
4π2
n
2
t
.
So tmix(ε) = O(n
2
).
Random walk on the hypercube
Consider simple random walk on the hypercube V := {−1, +1}
n
, where x ∼ y if they differ
at exactly one coordinate. We consider the lazy version to avoid issues of periodicity (see
Example 1.1.31). Let P be the transition matrix and let π ≡ 2
−n be the stationary distribution
(by symmetry and |V| = 2
n
). We showed in Section 4.3.2 that tmix(ε) = 2(n log n). Here we
use spectral techniques.
For J ⊆ [n], we let
χJ (x) =
Y
j∈J
xj
, x ∈ V.
These are called parity functions. We show that the parity functions form an eigenbasis of PARITY
the transition matrix. FUNCTION
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press286 Spectral Methods
Lemma 5.2.17 (Hypercube: eigenbasis). For all J ⊆ [n], the function χJ
is an eigenfunction
of P with eigenvalue
µJ
:=
n − |J|
n
.
Moreover, the χJ s are orthonormal in `
2
(V, π).
Proof For x ∈ V and i ∈ [n], let x
[i] be x where coordinate i is flipped. Note that, for all
J, x,
X
y
P(x, y)χJ ( y) =
1
2
χJ (x) +
1
2
Xn
i=1
1
n
χJ (x
[i]
)
=

1
2
+
1
2
n − |J|
n

χJ (x) −
1
2
|J|
n
χJ (x)
=
n − |J|
n
χJ (x).
For the orthonormality, note that
X
x∈V
π(x)χJ (x)
2 =
X
x∈V
1
2
n
Y
j∈J
x
2
j = 1.
For J 6= J
0 ⊆ [n],
X
x∈V
π(x)χJ (x)χJ
0(x)
=
X
x∈V
1
2
n
Y
j∈J∩J
0
x
2
j
Y
j∈J\J
0
xj
Y
j∈J
0\J
xj
=
2
|J∩J
0
|
2
n
Y
j∈J\J
0


X
xj∈{−1,+1}
xj


Y
j∈J
0\J


X
xj∈{−1,+1}
xj


= 0,
since at least one of J \ J
0 or J
0 \ J is non-empty.
From the eigenvalues, we obtain the relaxation time.
Theorem 5.2.18 (Hypercube: relaxation time). The relaxation time for lazy simple random
walk on the n-dimensional hypercube is
trel = n.
Proof From Lemma 5.2.17, the absolute spectral gap is
γ∗ = γ = 1 −
n − 1
n
=
1
n
.
Note that πmin = 1/2
n
. Hence, by Theorem 5.2.14, we have tmix(ε) = O(n
2
) and tmix(ε) =
(n). Those bounds, it turns out, are both off.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.2 Spectral Techniques for Reversible Markov Chains 287
As we did for the cycle, we obtain a sharper upper bound by working directly with the
spectral decomposition. By the same argument we used there,
4d(t)
2 ≤
X
J6=∅
µ
2t
J
.
Then,
4d(t)
2 ≤
X
J6=∅

n − |J|
n
2t
=
Xn
`=1

n
`
 1 −
`
n
2t
≤
Xn
`=1

n
`

exp
−
2t`
n

=

1 + exp
−
2t
n
n
− 1,
where we used that 1 − x ≤ e
−x
for all x (see Exercise 1.16). So, by definition, tmix(ε) ≤
1
2
n log n + O(n).
Remark 5.2.19 In fact, lazy simple random walk on the n-dimensional hypercube has a
“cutoff” at (1/2)n log n. Roughly speaking, within a time window of size O(n), the total
variation distance to the stationary distribution goes from near 1 to near 0. See, for exam￾ple, [LPW06, section 18.2.2].
5.2.3 F Markov Chains: Varopoulos–Carne and Diameter-Based Bounds on the
Mixing Time
If (St) is simple random walk on Z, then Lemma 2.4.3 guarantees that for any x, y ∈ Z,
P
t
(x, y) ≤ e
−|x−y|
2
/2t
, (5.2.6)
where P is the transition matrix of (St). Interestingly, a similar bound holds for any reversible
Markov chain, and Lemma 2.4.3 plays an unexpected role in its proof. An application to
mixing times is discussed in Claim 5.2.25.
Varopoulos–Carne bound
Our main bound is the following. Recall that a reversible Markov chain is equivalent to
a random walk on the network corresponding to its positive transition probabilities (see
Definition 1.2.7 and the discussion following it).
Theorem 5.2.20 (Varopoulos–Carne bound). Let P be the transition matrix of an irreducible
Markov chain (Xt) on the countable state space V. Assume further that P is reversible with
respect to the stationary measure π and that the corresponding network N is locally finite.
Then the following hold:
∀x, y ∈ V, ∀t ∈ N, P
t
(x, y) ≤ 2
s
π( y)
π(x)
e
−ρ(x,y)
2
/2t
,
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press288 Spectral Methods
where ρ(x, y) is the graph distance between x and y on N .
As a sanity check before proving the theorem, note that if the chain is aperiodic and π is the
stationary distribution, then by the convergence theorem (Theorem 1.1.33),
P
t
(x, y) → π( y) ≤ 2
s
π( y)
π(x)
as t → +∞,
since π(x), π( y) ≤ 1.
Proof of Theorem 5.2.20 The idea of the proof is to show that
P
t
(x, y) ≤ 2
s
π( y)
π(x)
P[St ≥ ρ(x, y)],
where again (St) is simple random walk on Z started at 0, and then use the Chernoff bound
(Lemma 2.4.3).
By the local finiteness assumption, only a finite number of states can be reached by time
t. Hence we can reduce the problem to a finite state space. More precisely, let V˜ = {z ∈
V : ρ(x,z) ≤ t} and for z,w ∈ V˜
P˜(z,w) =
(
P(z,w) if z 6= w,
P(z,z) + P(z, V \ V˜) otherwise.
By construction, P˜ is reversible with respect to π˜ = π/π(V˜) on V˜. Because within time t one
never reaches a state z where P(z, V \ V˜) > 0, by Chapman–Kolmogorov (Theorem 1.1.20)
and using the fact that π˜ ( y)/π˜ (x) = π( y)/π(x), it suffices to prove the result for P˜. Hence
we assume without loss of generality that V is finite with |V| = n.
To relate (Xt) to simple random walk on Z, we use a special representation of P
t based on
Chebyshev polynomials. For ξ = cos θ ∈ [−1, 1],
Tk (ξ ) = cos kθ
CHEBYSHEV is a Chebyshev polynomial of the first kind. Note that |Tk (ξ )| ≤ 1 on [−1, 1] by definition.
POLYNOMIALS The classical trigonometric identity (to see this, write it in complex form)
cos((k + 1)θ) + cos((k − 1)θ) = 2 cos θ cos(kθ)
implies the recursion
Tk+1(ξ ) + Tk−1(ξ ) = 2ξ Tk (ξ ),
which in turn implies that Tk
is indeed a polynomial. It has degree k from induction and the
fact that T0(ξ ) = 1 and T1(ξ ) = ξ . The connection to simple random walk on Z comes from
the following somewhat miraculous representation (which does not rely on reversibility). Let
Tk (P) denote the polynomial Tk evaluated at P as a matrix polynomial.
Lemma 5.2.21
P
t =
Xt
k=−t
P[St = k] T|k|(P).
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.2 Spectral Techniques for Reversible Markov Chains 289
Proof It suffices to prove
ξ
t =
Xt
k=−t
P[St = k] T|k|(ξ )
as an identity of polynomials. By the binomial theorem (Appendix A),
ξ
t =

e
iθ + e
−iθ
2
t
=
Xt
`=0
2
−t

t
`

(e
iθ
)
`
(e
−iθ
)
t−` =
Xt
k=−t
P[St = k]e
ikθ
,
where we used that the probability that
St = −t + 2` = (+1)` + (−1)(t − `)
is the event of making ` steps to the right and t − ` steps to the left. Now take real parts on
both sides and use that cos(kθ) = cos(−kθ) to get the claim. (Put differently, (cos θ)
t
is the
characteristic function E[e
iθSt
] of St
.)
We bound Tk (P)(x, y) as follows.
Lemma 5.2.22 It holds that
Tk (P)(x, y) = 0 ∀k < ρ(x, y)
and
Tk (P)(x, y) ≤
s
π( y)
π(x)
∀k ≥ ρ(x, y).
Proof Note that Tk (P)(x, y) = 0 when k < ρ(x, y) because Tk (P)(x, y) is a function of the
entries P
`
(x, y) for ` ≤ k, all of which are 0.
We work on `
2
(V, π). Let f1, . . . , fn be an eigendecomposition of P orthonormal with re￾spect to the inner product h·, ·iπ with eigenvalues λ1, . . . , λn ∈ [−1, 1]. Such a decomposition
exists by Theorem 5.2.1. Then, f1, . . . , fn is also an eigendecomposition of the polynomial
Tk (P) with eigenvalues
Tk (λ1), . . . , Tk (λn) ∈ [−1, 1],
by the definition of the Chebyshev polynomials. By decomposing any function f =
Pn
i=1 αi
fi
over this eigenbasis, it implies that
kTk (P)f k
2
π =





Xn
i=1
αiTk (λi)fi





2
π
=
Xn
i=1
α
2
i Tk (λi)
2
≤
Xn
i=1
α
2
i
= k f k
2
π
, (5.2.7)
where we used Parseval’s identity (5.2.1) twice and the fact that Tk (λi)
2 ∈ [0, 1].
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press290 Spectral Methods
Figure 5.2 The supports of P
b(1−1)/2c
(x0, · ) and P
b(1−1)/2c
( y0, · ) are contained in
A and A
c
, respectively.
Let δz denote the point mass at z. By Cauchy–Schwarz (Theorem B.4.8) and (5.2.7),
Tk (P)(x, y) =
hδx
, Tk (P)δyiπ
π(x)
≤
kδxkπ kδykπ
π(x)
=
√
π(x)
√
π( y)
π(x)
=
s
π( y)
π(x)
for any k (in particular for k ≥ ρ(x, y)) and we have proved the claim.
Combining the two lemmas gives the result.
Remark 5.2.23 The local finiteness assumption is made for simplicity only. The result holds
for any countable-space, reversible chain. See [LP16, section 13.2].
Lower bound on mixing Let (Xt) be an irreducible aperiodic (for now not necessarily re￾versible) Markov chain with finite state space V and stationary distribution π. Recall that,
for a fixed 0 < ε < 1/2, the mixing time is
tmix(ε) = min{t: d(t) ≤ ε},
where
d(t) = max
x∈V
kP
t
(x, · ) − πkTV.
It is intuitively clear that tmix(ε) is at least of the order of the “diameter” of the transition
graph of P. For x, y ∈ V, let ρ(x, y) be the graph distance between x and y on the undi￾rected version of the transition graph, that is, ignoring the orientation of the edges. With
this definition, a shortest directed path from x to y contains at least ρ(x, y) edges. Here we
DIAMETER define the diameter of the transition graph as 1 := maxx,y∈V ρ(x, y). Let x0, y0 be a pair of
vertices achieving the diameter. Then we claim that P
b(1−1)/2c
(x0, · ) and P
b(1−1)/2c
( y0, · ) are
supported on disjoint sets. To see this, let
A = {z ∈ V : ρ(x0,z) < ρ( y0,z)}
be the set of states closer to x0 than y0. See Figure 5.2. By the triangle inequality for ρ, any
z such that ρ(x0,z) ≤ b(1 − 1)/2c is in A, otherwise we would have ρ( y0,z) ≤ ρ(x0,z) ≤
b(1 −1)/2c and hence ρ(x0, y0) ≤ ρ(x0,z)+ρ( y0,z) ≤ 2b(1 −1)/2c < 1, a contradiction.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.2 Spectral Techniques for Reversible Markov Chains 291
Similarly, if ρ( y0,z) ≤ b(1 − 1)/2c, then z ∈ A
c
. By the triangle inequality for the total
variation distance,
d(b(1 − 1)/2c) ≥
1
2

P
b(1−1)/2c
(x0, · ) − P
b(1−1)/2c
( y0, · )


TV
≥
1
2

P
b(1−1)/2c
(x0, A) − P
b(1−1)/2c
( y0, A)
	
=
1
2
{1 − 0} =
1
2
, (5.2.8)
where we used (1.1.4) on the second line, so that:
Claim 5.2.24
tmix(ε) ≥
1
2
.
This bound is often far from the truth. Consider for instance simple random walk on a cycle
of size n. The diameter is 1 = n/2. But Lemma 2.4.3 suggests that it takes time of order
12
to even reach the antipode of the starting point, let alone achieve stationarity. More
generally, when P is reversible, the “diffusive behavior” captured by the Varopoulos–Carne
bound (Theorem 5.2.20) implies that the mixing time does indeed scale at least as the square
of the diameter.
Assume that P is reversible with respect to π and has diameter 1. Letting n = |V| and
πmin = minx∈V π(x), we then have the following.
Claim 5.2.25 The following lower bound holds
tmix(ε) ≥
12
12 log n + 4| log πmin|
provided n ≥
16
(1−2ε)
2
.
Proof The proof is based on the same argument we used to derive our first diameter-based
bound, except that the Varopoulos–Carne bound gives a better dependence on the diameter.
Namely, let x0, y0, and A be as above. By the Varopoulos–Carne bound,
P
t
(x0, A
c
) =
X
z∈Ac
P
t
(x0,z) ≤
X
z∈Ac
2
s
π(z)
π(x0)
e
−
ρ
2(x0
,z)
2t ≤ 2nπ
−1/2
min e
−
12
8t ,
where we used that |A
c
| ≤ n and ρ(x0,z) ≥
1
2
for z ∈ A
c
. For any
t <
12
12 log n + 4| log πmin|
, (5.2.9)
we get that
P
t
(x0, A
c
) ≤ 2nπ
−1/2
min exp
−
3 log n + | log πmin|
2

=
2
√
n
,
or P
t
(x0, A) ≥ 1 −
2
√
n
. Similarly, P
t
( y0, A) ≤
2
√
n
so that arguing as in (5.2.8)
d(t) ≥
1
2

1 −
2
√
n
−
2
√
n

=
1
2
−
2
√
n
≥ ε,
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press292 Spectral Methods
for t as in (5.2.9) and n as in the statement.
Remark 5.2.26 The dependence on 1 and πmin in Claim 5.2.25 cannot be improved. See
[LP16, section 13.3].
5.2.4 F Randomized Algorithms: Markov Chain Monte Carlo and a Quantitative
Ergodic Theorem
In Markov chain Monte Carlo methods, one generates samples from a probability distribu￾tion of interest π over some state space V in order to estimate some of its properties, for
example, its mean, by designing and then running a Markov chain with stationary distribu￾tion π. The Metropolis algorithm from Example 1.1.30 is a standard way of constructing
such a chain. These techniques play a central role in Bayesian statistics in particular where
π is the so-called posterior distribution given the data.
We restrict ourselves here to finite V and, without loss of generality, we assume that V =
[n]. Let P be an irreducible chain reversible with respect to a stationary distribution π =
(πx)x∈V . As previously, we work on `
2
(V, π). Let f : V → R be a function in `
2
(V, π).
Recall that
πf =
X
x∈V
πx
f (x).
Our goal is to estimate πf from the sample path of the Markov chain (Xt)t≥0 with transition
matrix P. Indeed, the ergodic theorem guarantees that
1
T
X
T
t=1
f (Xt) → πf
almost surely as T → +∞ for any starting point. We derive a simple, quantitative version
of this statement that provides insights into how long the chain needs to be run to get an
accurate estimate in terms of the spectral gap.
Theorem 5.2.27 (Ergodic theorem: reversible case). Let P = (Px,y)x,y∈V be an irreducible
aperiodic transition matrix over a finite state space V reversible with respect to the station￾ary distribution π = (πx)x∈V . Let f : V → R be a function in `
2
(V, π). Then for any initial
distribution µ = (µx)x∈V ,
1
T
X
T
t=1
f (Xt) → πf ,
in probability as T → +∞. Moreover, for any ε > 0,
P
"




1
T
X
T
t=1
f (Xt) − πf





≥ ε
#
≤
9π
−1
mink f k
2
∞γ
−1
∗
1
T
(ε − π
−1
mink f k∞γ
−1
∗
1
T
)
2
,
as T → +∞, where γ∗ > 0 is the absolute spectral gap of P.
Recall that, by Lemmas 5.2.3 and 5.2.4, we have γ∗ > 0 since P is irreducible and aperi￾odic. We will first need the following lemma.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.2 Spectral Techniques for Reversible Markov Chains 293
Lemma 5.2.28 (Convergence of the expectation). For any initial distribution µ = (µx)x∈V
and any t,
| E[ f (Xt)] − πf | ≤ (1 − γ∗)
tπ
−1
mink f k∞.
Proof We have
| E[ f (Xt)] − πf | =





X
x
X
y
µxP
t
x,y
f ( y) −
X
y
πy
f ( y)





.
Because P
x µx = 1, the right-hand side is
=





X
x
X
y
µxP
t
x,y
f ( y) −
X
x
X
y
µxπy
f ( y)





≤
X
x
µx
X
y

P
t
x,y − πy


| f ( y)|,
by the triangle inequality.
Now by (5.2.5) this is
≤
X
x
µx
X
y
(1 − γ∗)
t πy
πmin
| f ( y)|
= (1 − γ∗)
t
1
πmin
X
x
µx
X
y
πy
| f ( y)|
≤ (1 − γ∗)
tπ
−1
mink f k∞.
That proves the claim.
Proof of Theorem 5.2.27 We use Chebyshev’s inequality (Theorem 2.1.2), similarly to the
proof of the L
2 weak law of large numbers (Theorem 2.1.6). In particular, we note that the
Xts are not independent.
By Lemma 5.2.28, the expectation of the time average can be bounded as follows





E
"
1
T
X
T
t=1
f (Xt)
#
− πf





≤
1
T
X
T
t=1
|E[ f (Xt)] − πf |
≤
1
T
X
T
t=1
(1 − γ∗)
tπ
−1
mink f k∞
≤ π
−1
mink f k∞
1
T
X
+∞
t=0
(1 − γ∗)
t
= π
−1
mink f k∞γ
−1
∗
1
T
→ 0,
as T → +∞, since γ∗ > 0.
Next we bound the variance of the sum. We have
Var "
1
T
X
T
t=1
f (Xt)
#
=
1
T
2
X
T
t=1
Var[ f (Xt)] +
2
T
2
X
1≤s<t≤T
Cov[ f (Xs), f (Xt)].
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press294 Spectral Methods
We bound the variance and covariance terms separately.
To obtain convergence, a trivial bound on the variance suffices
0 ≤ Var[ f (Xt)] ≤ E[ f (Xt)
2
] ≤ k f k
2
∞.
Hence,
0 ≤
1
T
2
X
T
t=1
Var[ f (Xt)] ≤
Tk f k
2
∞
T
2
→ 0
as T → +∞.
Bounding the covariance requires a more delicate argument. Fix 1 ≤ s < t ≤ T. The trick
is to condition on Xs and use the Markov Property (Theorem 1.1.18). By definition of the co￾variance, the tower property (Lemma B.6.16) and taking out what is known (Lemma B.6.13),
Cov[ f (Xs), f (Xt)]
= E [( f (Xs) − E[ f (Xs)])( f (Xt) − E[ f (Xt)])]
=
X
x
E [( f (Xs) − E[ f (Xs)])( f (Xt) − E[ f (Xt)]) | Xs = x] P[Xs = x]
=
X
x
E [ f (Xt) − E[ f (Xt)] | Xs = x] ( f (x) − E[ f (Xs)]) P[Xs = x].
We now use the time homogeneity of the chain to note that
E [ f (Xt) − E[ f (Xt)] | Xs = x]
= E [ f (Xt) | Xs = x] − E[ f (Xt)]
= E [ f (Xt−s) | X0 = x] − E[ f (Xt)].
By Lemma 5.2.28,
|E [ f (Xt) − E[ f (Xt)] | Xs = x]|
= |E [ f (Xt−s) | X0 = x] − E[ f (Xt)]|
= |(E [ f (Xt−s) | X0 = x] − πf ) − (E[ f (Xt)] − πf )|
≤ |E [ f (Xt−s) | X0 = x] − πf | + |E[ f (Xt)] − πf |
≤ (1 − γ∗)
t−sπ
−1
mink f k∞ + (1 − γ∗)
tπ
−1
mink f k∞
≤ 2(1 − γ∗)
t−sπ
−1
mink f k∞,
which does not depend on x. Plugging back above,
|Cov[ f (Xs), f (Xt)]|
≤
X
x
|E [ f (Xt) − E[ f (Xt)] | Xs = x]| | f (x) − E[ f (Xs)]| P[Xs = x]
≤ 2(1 − γ∗)
t−sπ
−1
mink f k∞
X
x
| f (x) − E[ f (Xs)]| P[Xs = x]
≤ 2(1 − γ∗)
t−sπ
−1
mink f k∞
X
x
2k f k∞P[Xs = x]
≤ 4(1 − γ∗)
t−sπ
−1
mink f k
2
∞.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.2 Spectral Techniques for Reversible Markov Chains 295
Returning to the sum over the covariances, the previous bound gives





2
T
2
X
1≤s<t≤T
Cov[ f (Xs), f (Xt)]





≤
2
T
2
X
1≤s<t≤T
|Cov[ f (Xs), f (Xt)]|
≤
2
T
2
X
1≤s<t≤T
4(1 − γ?)
t−sπ
−1
mink f k
2
∞.
To evaluate the sum we make the change of variable h = t−s to get that the previous expres￾sion is
≤ 4π
−1
mink f k
2
∞
2
T
2
X
1≤s≤T
X
T−s
h=1
(1 − γ∗)
h
≤ 4π
−1
mink f k
2
∞
2
T
2
X
1≤s≤T
X
+∞
h=0
(1 − γ∗)
h
= 4π
−1
mink f k
2
∞
2
T
2
X
1≤s≤T
1
γ∗
= 8π
−1
mink f k
2
∞γ
−1
∗
1
T
→ 0
as T → +∞.
Combining the variance and covariance bounds, we have shown that
Var "
1
T
X
T
t=1
f (Xt)
#
≤ k f k
2
∞
1
T
+ 8π
−1
mink f k
2
∞γ
−1
∗
1
T
≤ 9π
−1
mink f k
2
∞γ
−1
∗
1
T
.
For any ε > 0,
P
"




1
T
X
T
t=1
f (Xt) − πf





≥ ε
#
= P
"




1
T
X
T
t=1
f (Xt) − E
"
1
T
X
T
t=1
f (Xt)
#
+
 
E
"
1
T
X
T
t=1
f (Xt)
#
− πf
!




≥ ε
#
≤ P
"




1
T
X
T
t=1
f (Xt) − E
"
1
T
X
T
t=1
f (Xt)
# 




+





E
"
1
T
X
T
t=1
f (Xt)
#
− πf





≥ ε
#
≤ P
"




1
T
X
T
t=1
f (Xt) − E
"
1
T
X
T
t=1
f (Xt)
# 




≥ ε − π
−1
mink f k∞γ
−1
∗
1
T
#
.
We can now apply Chebyshev’s inequality to get
P
"




1
T
X
T
t=1
f (Xt) − πf





≥ ε
#
≤
9π
−1
mink f k
2
∞γ
−1
∗
1
T
(ε − π
−1
mink f k∞γ
−1
∗
1
T
)
2
→ 0
as T → +∞.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press296 Spectral Methods
5.2.5 Spectral Radius
The results in this section have so far concerned finite state spaces. The countably infinite
case presents a number of complications. We start with a few observations:
• Suppose P is irreducible, aperiodic, and positive recurrent. Then we know from the con￾vergence theorem (Theorem 1.1.33) that if π is the stationary distribution, then for all
x,
kP
t
(x, ·) − π(·)kTV → 0
as t → +∞. The convergence rate depends on the starting point x. In the infinite state
space case, one typically needs to make that dependence explicit to get meaningful results.
In particular, the mixing time – as we have defined it – may not be a useful concept.
• In the transient and null recurrent cases, there is no stationary distribution to converge to
by Theorem 3.1.20. Instead, we have the following by Theorem 3.1.21: if P is an irreduc￾ible chain which is either transient or null recurrent, then we have that
lim
t
P
t
(x, y) = 0
for all x, y ∈ V.
• Conditions stronger than reversibility are needed for the spectral theorem – in a form
COMPACT similar to what we used – to apply. Specifically, one needs that P is a compact operator:
OPERATOR whenever (fn)n ∈ `
2
(V, π) is a bounded sequence, there exists a subsequence ( fnk
)k such
that (Pfnk
) converges in the norm. Unfortunately, that is often not the case, as the next
example illustrates, even in the reversible positive recurrent case.
Example 5.2.29 (A positive recurrent chain whose P is not compact). For p < 1/2, let (Xt)
be the birth-death chain with V := {0, 1, 2, . . .}, P(0, 0) := 1 − p, P(0, 1) = p, P(x, x + 1) :=
p and P(x, x − 1) := 1 − p for all x ≥ 1, and P(x, y) := 0 if |x − y| > 1. As can be
checked by direct computation, P is reversible with respect to the stationary distribution
π(x) = (1−γ )γ
x
for x ≥ 0, where γ :=
p
1−p
. For j ≥ 1, define gj(x) := π( j)
−1/21{x=j}
. Then,
kgjk
2
π = 1 for all j so {gj}j
is bounded in `
2
(V, π). On the other hand,
Pgj(x) = pπ( j)
−1/2
1{x=j−1} + (1 − p)π( j)
−1/2
1{x=j+1}
.
So
kPgjk
2
π = p
2π( j)
−1π(j − 1) + (1 − p)
2π( j)
−1π(j + 1)
= p
2
1 − p
p
+ (1 − p)
2
p
1 − p
= 2p(1 − p).
Hence, {Pgj}j
is also bounded. However, for j > `,
kPgj − Pg`k
2
π ≥ (1 − p)
2π( j)
−1π(j + 1) + p
2π(`)
−1π(` − 1)
= 2p(1 − p).
So {Pgj}j does not have a converging subsequence. J
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.2 Spectral Techniques for Reversible Markov Chains 297
We will not say much about the spectral theory of infinite networks. In this subsection, we
establish a relationship between the operator norm of P – which is related to its spectrum –
and the decay of P
t
(x, y).
Let `0(V) be the set of real-valued functions on V with finite support. It is dense in
`
2
(V, π). Indeed, let v1, v2, . . . be an enumeration of V and, for f ∈ `
2
(V, π), define f |n(vi) :=
f (vi)1i≤n to be f restricted to v1, . . . , vn. Then,
k f − f |nk
2
π =
X∞
i=n+1
π(vi)f (vi)
2 → 0 (5.2.10)
as n → ∞, since k f k
2
π =
P
x π(x)f (x)
2 < +∞. We will also need the following:
kPf − P( f |n)k
2
π = kP( f − f |n)k
2
π ≤ k f − f |nk
2
π → 0, (5.2.11)
where we used (5.2.2).
Definition 5.2.30 (Operator norm). The operator norm of P is OPERATOR
NORM
kPkπ = sup 
kPf kπ
k f kπ
: f ∈ `0(V), f 6= 0

.
By definition, for any f ∈ `0(V),
kPf kπ ≤ kPkπ k f kπ . (5.2.12)
The same can be seen to hold for any f ∈ `
2
(V, π) by considering the sequence ( f |n)n
and noting that k f |nkπ → k f kπ and kP( f |n)kπ → kPf kπ as n → ∞ by (5.2.10), (5.2.11),
and the triangle inequality. This latter observation explains why it suffices to restrict the
supremum to `0 in the definition of the norm.
Note that, by (5.2.2), kPkπ ≤ 1. Note further that if V is finite or, more generally, if π is
summable, then we have in fact kPkπ = 1 by taking f ≡ 1 above. When P is self-adjoint,
the norm kPkπ is also equal to what is known as the spectral radius, that is, the radius of SPECTRAL
RADIUS the smallest disk centered at 0 in the complex plane that contains the spectrum of P. We will
not need to define what that means formally here. (But Exercise 5.5 asks for a proof in the
setting of symmetric matrices.)
Our main result is the following.
Theorem 5.2.31 (Spectral radius). Let P be irreducible and reversible with respect to π > 0.
Then,
ρ(P) := lim sup
t
P
t
(x, y)
1/t = kPkπ .
In particular, the limit does not depend on x, y. Moreover, for all t,
P
t
(x, y) ≤
s
π( y)
π(x)
kPk
t
π
.
In the positive recurrent case ( for instance, if the chain is finite), we have P
t
(x, y) → π( y) >
0 and so ρ(P) = 1 = kPkπ . The theorem says that the equality between ρ(P) and kPkπ holds
in general for reversible chains.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press298 Spectral Methods
Proof of Theorem 5.2.31 To see that the limit does not depend on x, y, let u, v, x, y ∈ V and
k, m ≥ 0 such that P
m
(u, x) > 0 and P
k
( y, v) > 0. Then,
P
t+m+k
(u, v)
1/(t+m+k)
≥ (P
m
(u, x)P
t
(x, y)P
k
( y, v))1/(t+m+k)
≥ P
m
(u, x)
1/(t+m+k)P
t
(x, y)
1/tP
k
( y, v)
1/(t+m+k)
,
which shows that lim supt P
t
(u, v)
1/t ≥ lim supt P
t
(x, y)
1/t
for all u, v, x, y.
We first show that ρ(P) ≤ kPkπ . Observe that applying (5.2.4) and (5.2.12) repeatedly
gives that P
t
is self-adjoint and satisfies the inequality kP
tkπ ≤ kPk
t
π
. Because kδzk
2
π =
π(z) ≤ 1, by Cauchy–Schwarz,
π(x)P
t
(x, y) = hδx
, P
t
δyiπ ≤ kPk
t
π
kδxkπ kδykπ = kPk
t
π
p
π(x)π( y).
Hence, P
t
(x, y) ≤
q
π( y)
π(x)
kPk
t
π
and
ρ(P) = lim sup
t
P
t
(x, y)
1/t
≤ lim sup
t
 s
π( y)
π(x)
kPk
t
π
!1/t
= kPkπ .
To establish the inequality in the other direction, we make a series of observations. Fix a
non-zero f ∈ `0(V).
• By self-adjointness and Cauchy–Schwarz,
kP
t+1
f k
2
π = hP
t+1
f , P
t+1
f iπ = hP
t+2
f , P
t
f iπ ≤ kP
t+2
f kπ kP
t
f kπ ,
or
kP
t+1
f kπ
kPt
f kπ
≤
kP
t+2
f kπ
kPt+1
f kπ
.
So kP
t+1
f kπ
kPt
f kπ
is non-decreasing and therefore has a limit L ≤ +∞. Moreover, for t = 0, we
get
kPf kπ
k f kπ
≤ L, (5.2.13)
so it suffices to prove L ≤ ρ(P).
• Observe that

kP
t
f kπ
k f kπ
1/t
=

kPf kπ
k f kπ
× · · · ×
kP
t
f kπ
kPt−1
f kπ
1/t
→ L,
so in fact
L = lim
t
kP
t
f k
1/t
π
.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.2 Spectral Techniques for Reversible Markov Chains 299
• By self-adjointness again,
kP
t
f k
2
π = hf , P
2t
f iπ =
X
x
π(x)f (x)
X
y
f ( y)P
2t
(x, y).
By definition of ρ(P), for any ε > 0, there is a t large enough that
P
2t
(x, y) ≤ (ρ(P) + ε)
2t
,
for all x, y in the support of f . For such a t, plugging back into the previous display,
kP
t
f k
1/t
π ≤ (ρ(P) + ε)
 X
x
π(x)| f (x)|
X
y
| f ( y)|
!1/2t
.
The expression in parentheses on the right-hand side is finite because f has finite support.
Since ε is arbitrary, we get
L = lim
t
kP
t
f k
1/t
π ≤ ρ(P). (5.2.14)
So, combining (5.2.13) and (5.2.14), we have shown that kPkπ ≤ ρ(P) and that concludes
the proof.
Corollary 5.2.32 Let P be irreducible and reversible with respect to π. If kPkπ < 1, then
P is transient.
Proof By Theorem 5.2.31, P
t
(x, x) ≤ kPk
t
π
so
X
t
P
t
(x, x) ≤
X
t
kPk
t
π < +∞.
Let (Xt) be a chain with transition matrix P. Because
X
t
P
t
(x, x) = Ex
"X
t
1{Xt=x}
#
,
we have that P
t
1{Xt=x} < +∞, Px-a.s., and (Xt) is transient.
This is not an if and only if. Random walk on Z
3
is transient, yet P
2t
(0, 0) = 2(t
−3/2
) so there
kPkπ = ρ(P) = 1.
In the non-reversible case, our definition of kPkπ still makes sense with respect to any
stationary measure π (although P is not self-adjoint). But the equality in Theorem 5.2.31 no
longer holds in general.
Example 5.2.33 (Counter-example). Let (Xt) be asymmetric random walk on Z with prob￾ability p ∈ (1/2, 1) of going to the right. Then both π0(x) :=

p
1−p
x
and π1(x) := 1 define
stationary measures, but the transition matrix P is only reversible with respect to π0.
Under π1, we have kPkπ1 = 1. Indeed, let gn(x) := 1{|x|≤n} and note that
(Pgn)(x) = 1{|x|≤n−1} + p1{x = −n − 1 or −n} + (1 − p)1{x = n or n + 1}
,
so kgnk
2
π1 = 2n + 1 and kPgnk
2
π1 ≥ 2(n − 1) + 1. Hence,
lim sup
n
kPgnkπ1
kgnkπ1
≥ 1
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press300 Spectral Methods
and kPkπ1 ≥ 1. But we already showed that kPkπ1 ≤ 1 in (5.2.2), so the claim follows.
On the other hand, E0[Xt] = (2p − 1)t. So the martingale Zt
:= Xt − (2p − 1)t (see
Example 3.1.29), as a sum of t independent centered random variables in {−1−(2p−1), 1−
(2p−1)}, satisfies the assumptions of the Azuma–Hoeffding inequality (Theorem 3.2.1) with
increment bound ct
:= 2. So
P
t
(0, 0)1/t ≤ P0[Xt ≤ 0]1/t
= P0[Xt − (2p − 1)t ≤ −(2p − 1)t]
1/t
≤ e
−
2(2p−1)2t
2
2
2t
1
t
.
Therefore,
lim sup
t
P
t
(0, 0)1/t ≤ e
−(2p−1)2
/2 < 1.
J
5.3 Geometric Bounds
The goal of this section is to relate the spectral gap to certain geometric properties of the
underlying network, more specifically isoperimetric properties, that is, relationships between
ISOPERIMETRIC the “volume” of sets and their “circumference.” The classical isoperimetric inequality states
INEQUALITY that the area enclosed by any rectifiable simple closed curve in the plane is at most the length
of the curve squared divided by 4π. Moreover, equality is achieved if and only if the curve
is a circle.
Remark 5.3.1 Here is an easy proof in the smooth case. Suppose r(s) = (x(s), y(s)), s ∈
[0, 2π] is the parametrization of a positively oriented, smooth, simple closed curve in the
plane centered at the origin with arc-length 2π, where kr
0
(s)k2 = 1 for all s, R 2π
0
r(s) ds = 0
and x(0) = x(2π) = 0. By Green’s theorem, the area enclosed by the curve is
A =
Z 2π
0
x(s)y
0
(s) ds =
1
2
Z 2π
0
[x(s)
2 + y
0
(s)
2 − (x(s) − y
0
(s))2
] ds,
where we used that 2ab = a
2 + b
2 − (a − b)
2
. By the one-dimensional Poincaré inequality
(Remark 3.2.7),
A ≤
1
2
Z 2π
0
[x(s)
2 + y
0
(s)
2
] ds ≤
1
2
Z 2π
0
[x
0
(s)
2 + y
0
(s)
2
] ds = π,
which is indeed the area of a circle of circumference 2π.
Edge expansion We define our isoperimetric quantity of interest. Let (Xt) be a finite, irre￾ducible Markov chain on V reversible with respect to a stationary measure π > 0. (In this
section, we do not necessarily assume that π is a probability distribution.) Let P be its tran￾sition matrix. We think of (Xt) as a random walk on the network N = (G, c), where G is the
transition graph and c(x, y) := π(x)P(x, y) = π( y)P( y, x).
EDGE For a subset S ⊆ V, we let the edge boundary of S be
BOUNDARY
∂ES := {e = (x, y) ∈ E: x ∈ S, y ∈ S
c
}.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.3 Geometric Bounds 301
Figure 5.3 A bottleneck.
Let g : E → R+ be an edge weight function. For F ⊆ E, we define
| f |g :=
X
e∈F
g(e),
and similarly for a vertex function. Finally, for S ⊆ V, we let
8E(S; g, h) :=
|∂ES|g
|S|h
.
Roughly speaking, this is the ratio of the “size of the boundary” of a set to its “volume.”
Our main definition, the edge expansion constant, quantifies the worst such ratio. First,
one last piece of notation: for disjoint subsets S0, S1 ⊆ V, we let
c(S0, S1) :=
X
x0∈S0
X
x1∈S1
c(x0, x1).
Definition 5.3.2 (Edge expansion). For a subset of states S ⊆ V, the edge expansion con- EDGE
EXPANSION
CONSTANT
stant (or bottleneck ratio) of S is
8E(S; c, π) =
|∂ES|c
|S|π
=
c(S, S
c
)
π(S)
.
We refer to (S, S
c
) as a cut. The edge expansion constant (or bottleneck ratio or Cheeger
number or isoperimetric constant1
) of N is
8∗ := min 
8E(S; c, π): S ⊆ V, 0 < π(S) ≤
1
2

.
Intuitively, a small value of 8∗ suggests the existence of a “bottleneck” in N . Conversely, a
large value of 8∗ indicates that all sets “expand out.” See Figure 5.3. Note that the quantity
8E(S; c, π) has a natural probabilistic interpretation: pick a stationary state and make one
step according to the transition matrix; then, 8E(S; c, π) is the conditional probability that,
given that the first state is in S, the next one is in S
c
.
1
It is also called “conductance,” but that terminology clashes with our use of the term.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press302 Spectral Methods
Equivalently, the edge expansion constant can be expressed as
8∗ := min 
c(S, S
c
)
π(S) ∧ π(S
c
)
: S ⊆ V, 0 < π(S) < 1

.
Example 5.3.3 (Edge expansion: complete graph). Let G = Kn be the complete graph on
n vertices and assume c(x, y) = 1/n
2
for all x 6= y. For simplicity, take n even. Then for a
subset S of size |S| = k,
8E(S; c, π) =
|∂ES|c
|S|π
=
k(n − k)/n
2
k/n
=
n − k
n
.
Thus, the minimum is achieved for k = n/2 and
8∗ =
n − n/2
n
=
1
2
. J
Dirichlet form, Rayleigh quotient, and normalized Laplacian We relate the edge ex￾pansion constant of N to the spectral gap of P. Recall that we denote by λ1, . . . , λn the
eigenvalues of P in decreasing order. First, we adapt the variational characterization of The￾orem 5.1.3 to the network setting.
The Dirichlet form is defined over `
2 DIRICHLET (V, π) as the bilinear form
FORM
D( f , g) := hf , (I − P)giπ .
DIRICHLET The associated quadratic form, also known as Dirichlet energy, is D( f ) := D( f , f ). Note
ENERGY that, using stochasticity and reversibility,
hf , (I − P)f iπ = hf , f iπ − hf , Pf iπ
=
1
2
X
x,y
f (x)
2π(x)P(x, y)
+
1
2
X
x,y
f ( y)
2π( y)P( y, x) −
X
x,y
π(x)f (x)f ( y)P(x, y)
=
1
2
X
x,y
π(x)P(x, y)f (x)
2
+
1
2
X
x,y
π(x)P(x, y)f ( y)
2 −
X
x,y
π(x)P(x, y)f (x)f ( y)
=
1
2
X
x,y
c(x, y)[ f (x) − f ( y)]2
,
which is indeed consistent with the expression we encountered previously in Theorem 3.3.25.
The Rayleigh quotient for I − P over `
2
RAYLEIGH (V, π) is then
QUOTIENT
hf , (I − P)f iπ
hf , f iπ
=
1
2
P
x,y
c(x, y)[ f (x) − f ( y)]2
P
x π(x)f (x)
2
=
z
TLz
z
T z
,
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.3 Geometric Bounds 303
where L is the normalized Laplacian of the network N and we defined the vector z = (zx)x∈V
with zx
:=
√
π(x)f (x). Consequently, the Courant–Fischer theorem (Theorem 5.1.3) in the
form (5.1.5) gives the following. Here η2 = 1 − λ2 = γ is the spectral gap of P, which can
also be seen as the second smallest eigenvalue of I − P (which has the same eigenfunctions
as P itself). We have
γ = inf 
hf , (I − P)f iπ
hf , f iπ
: πf = 0, f 6= 0

.
The infimum is achieved by the eigenfunction f2 of P corresponding to its second largest
eigenvalue λ2. (Recall from Lemma 5.2.5 that πf2 = 0.)
We note further that if πf = 0, then
hf , f iπ = hf − πf , f − πf iπ = Varπ [ f ],
where the last expression denotes the variance under π. So the variational characterization
of γ implies that
Varπ [ f ] ≤ γ
−1D( f )
for all f such that πf = 0. In fact, it holds for any f by considering f − πf and noticing that
both sides are unaffected by subtracting a constant to f .
We have shown:
Theorem 5.3.4 (Poincaré inequality for N ). Let P be finite, irreducible, and reversible with
respect to π. Then,
Varπ [ f ] ≤ γ
−1D( f ) (5.3.1)
for all f ∈ `
2
(V π). Equality is achieved by the eigenfunction f2 of P corresponding to the
second largest eigenvalue λ2.
An inequality of the type
Varπ [ f ] ≤ CD( f ) ∀f (5.3.2)
is known as a Poincaré inequality, a simple version of which we encountered previously in POINCARÉ
Remark 3.2.7. To see the connection with that one-dimensional version, it will be conven- INEQUALITY
ient to work with directed edges. Let EE be an orientation of E, that is, for each e ∈ {x, y},
EE includes either (x, y) or ( y, x) with associated weight c(Ee) := c(e) > 0. For a function
f : V →R and an edge Ee = (x, y) ∈ EE, we define the “discrete gradient”
∇f (Ee) = f ( y) − f (x).
With this notation, we can rewrite the Dirichlet energy as
D( f ) =
1
2
X
x,y
c(x, y)[ f (x) − f ( y)]2 =
X
Ee
c(Ee)[∇f (Ee)]2
, (5.3.3)
hence (5.3.1) is a network analogue of (3.2.7).
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press304 Spectral Methods
5.3.1 Cheeger’s Inequality
The edge expansion constant and the spectral gap are related through the following isoperi￾CHEEGER’S metric inequalities. The lower bound is known as Cheeger’s inequality.
INEQUALITY
Theorem 5.3.5 Let P be a finite, irreducible, reversible Markov transition matrix and let
γ = 1 − λ2 be the spectral gap of P. Then,
82
∗
2
≤ γ ≤ 28∗.
In terms of the relaxation time trel = γ
−1
, these inequalities have an intuitive meaning:
the presence or absence of a bottleneck in the state space leads to slow or fast mixing,
respectively. We detail some applications to mixing times in the next subsections.
Before giving a proof of the theorem, we start with a trivial – yet insightful – example.
Example 5.3.6 (Two-state chain). Let V := {0, 1} and, for α, β ∈ (0, 1),
P :=

1 − α α
β 1 − β

,
which has stationary distribution
π :=

β
α + β
,
α
α + β

.
Recall from Example 5.2.8 that the second right eigenvector is
f2 :=
 r
α
β
, −
r
β
α
!
=
r
π1
π0
, −
r
π0
π1

,
with eigenvalue λ2 := 1 − α − β, so the spectral gap is α + β. Assume that β ≤ α. Then,
the bottleneck ratio is
8∗ =
c(0, 1)
π(0)
= P(0, 1) = α.
Then Theorem 5.3.5 reads
α
2
2
≤ α + β ≤ 2α,
which is indeed satisfied for all 0 < β ≤ α < 1. Note that the upper bound is tight when
α = β. J
Proof of Theorem 5.3.5 We start with the upper bound. In view of the Poincaré inequal￾ity for N (Theorem 5.3.4), to get an upper bound on the spectral gap, it suffices to plug
in a well-chosen function f in (5.3.1). Taking a hint from Example 5.3.6, for S ⊆ V with
π(S) ∈ (0, 1/2], we let
fS(x) :=



−
q
π(S
c
)
π(S)
x ∈ S,
q
π(S)
π(S
c
)
x ∈ S
c
.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.3 Geometric Bounds 305
Then,
X
x
π(x)fS(x) = π(S)
"
−
s
π(S
c
)
π(S)
#
+ π(S
c
)
"s
π(S)
π(S
c
)
#
= 0
and
X
x
π(x)fS(x)
2 = π(S)
"
−
s
π(S
c
)
π(S)
#2
+ π(S
c
)
"s
π(S)
π(S
c
)
#2
= 1.
So Varπ [ fS] = 1. Hence, from Theorem 5.3.4,
γ ≤
D( fS)
Varπ [ fS]
=
1
2
X
x,y
c(x, y)[ fS(x) − fS( y)]2
=
X
x∈S,y∈S
c
c(x, y)
"
−
s
π(S
c
)
π(S)
−
s
π(S)
π(S
c
)
#2
=
X
x∈S,y∈S
c
c(x, y)

−
π(S
c
) + π(S)
√
π(S)π(S
c
)
2
=
c(S, S
c
)
π(S)π(S
c
)
≤ 2
c(S, S
c
)
π(S)
,
as claimed.
The other direction is trickier. Because we seek an upper bound on the edge expansion
constant 8∗, our goal is to find a cut (S, S
c
) such that
c(S, S
c
)
π(S) ∧ π(S
c
)
≤
p
2γ . (5.3.4)
Because the eigenfunction f2 achieves γ in Theorem 5.3.4, it is natural to look to it for
“good cuts.” Thinking of f2 as a one-dimensional embedding of the network, it turns out to
be enough to consider only “sweep cuts” of the form S := {v : f2(v) ≤ θ} for a threshold θ.
How to pick the right threshold is less obvious.
Here we use a probabilistic argument, that is, we construct a random cut (Z, Z
c
). Observe
that it suffices that
E [c(Z, Z
c
)] ≤
p
2γE [π(Z) ∧ π(Z
c
)] , (5.3.5)
since then E
√
2γ π(Z) ∧ π(Z
c
) − c(Z, Z
c
)

≥ 0, which in turn implies that we have
P
√
2γ π(Z) ∧ π(Z
c
) − c(Z, Z
c
) ≥ 0

> 0 by the first moment principle (Theorem 2.2.1);
in other words, there exists a cut satisfying (5.3.4).
We now describe the random cut (Z, Z
c
):
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press306 Spectral Methods
1. (Cuts from f2) Let again f2 be an eigenfunction corresponding to the eigenvalue λ2 of P
with k f2k
2
π = 1. Order the vertices V := {v1, . . . , vn} in such a way that
f2(vi) ≤ f2(vi+1) ∀i = 1, . . . , n − 1.
As we described above, the function f2 naturally produces a series of cuts (Si
, S
c
i
), where
Si
:= {v1, . . . , vi}. By definition of the bottleneck ratio,
8∗ ≤
c(Si
, S
c
i
)
π(Si) ∧ π(S
c
i
)
. (5.3.6)
2. (Normalization) Let
m := min{i: π(Si) > 1/2},
and define the translated function
f := f2 − f2(vm).
We further set g := αf , where α > 0 is chosen so that
g(v1)
2 + g(vn)
2 = 1.
Note that, by construction, g(vm) = 0 and g(v1) ≤ · · · g(vm) = 0 ≤ g(vm+1) ≤ · · · ≤
g(vn). The function g is related to γ as follows:
Lemma 5.3.7
1
2
X
x,y
c(x, y)(g(x) − g( y))2 ≤ γ
X
x
π(x)g(x)
2
.
Proof By Theorem 5.3.4,
γ =
D( f2)
Varπ [ f2]
.
Because neither the numerator nor the denominator is affected by adding a constant, we
have also
γ =
D( f )
Varπ [ f ]
.
Furthermore, notice that a constant multiplying f cancels out in the ratio so
γ =
D(g)
Varπ [g]
.
Now use the fact that Varπ [g] ≤
P
x π(x)g(x)
2
.
1. (Random cut) Pick 2 in [g(v1), g(vn)] with density 2|θ|. Note that
Z g(vn)
g(v1)
2|θ| dθ = g(v1)
2 + g(vn)
2 = 1.
Finally, define
Z := {vi
: g(vi) < 2}.
The rest of the proof is calculations. We bound the expectations on both sides of (5.3.5).
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.3 Geometric Bounds 307
Lemma 5.3.8 The following hold:
(i)
E[π(Z) ∧ π(Z
c
)] =
X
x
π(x)g(x)
2
.
(ii)
E[c(Z, Z
c
)] ≤
 
1
2
X
x,y
c(x, y)(g(x) − g( y))2
!1/2 
2
X
x
π(x)g(x)
2
!1/2
.
Lemmas 5.3.7 and 5.3.8 immediately imply (5.3.5) and that concludes the proof of
Theorem 5.3.5. So it remains to prove this last lemma.
Proof of Lemma 5.3.8 We start with (i). By definition of g, 2 ≤ 0 implies that π(Z) ∧
π(Z
c
) = π(Z) and vice versa. Thus,
E[π(Z) ∧ π(Z
c
)] = E
"X
`<m
π(v`)1{v`∈Z}1{2≤0} +
X
`≥m
π(v`)1{v`∈Z
c
}1{2>0}
#
= E
"X
`<m
π(v`)1{g(v`)<2≤0} +
X
`≥m
π(v`)1{0<2≤g(v`)}
#
=
X
`<m
π(v`)P [g(v`) < 2 ≤ 0] +
X
`≥m
π(v`)P [0 < 2 ≤ g(v`)]
=
X
`<m
π(v`)g(v`)
2 +
X
`≥m
π(v`)g(v`)
2
=
X
x
π(x)g(x)
2
, (5.3.7)
where we integrated over the density of 2 to obtain the fourth line.
We move on to (ii). To compute E[c(Z, Z
c
)], we note that xk ∈ Z and x` ∈ Z
c
if and only
if g(vk ) < 2 ≤ g(v`). The probability of that event depends on the signs of g(vk ) and g(v`).
If g(vk )g(v`) ≥ 0,
P[g(vk ) < 2 ≤ g(v`)] = |g(vk )
2 − g(v`)
2
|
= |g(vk ) − g(v`)||g(vk ) + g(v`)|
= |g(vk ) − g(v`)|(|g(vk )| + |g(v`)|).
If g(vk )g(v`) < 0,
P[g(vk ) < 2 ≤ g(v`)] = g(vk )
2 + g(v`)
2
≤ g(vk )
2 + g(v`)
2 − 2g(vk )g(v`)
= (g(vk ) − g(v`))2
= |g(vk ) − g(v`)|(|g(vk )| + |g(v`)|).
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press308 Spectral Methods
We apply Cauchy–Schwarz to get
E[c(Z, Z
c
)] =
X
k<`
c(vk
, v`)P[g(vk ) < 2 ≤ g(v`)]
≤
X
k<`
c(vk
, v`)|g(vk ) − g(v`)|(|g(vk )| + |g(v`)|)
≤
 X
k<`
c(vk
, v`)(g(vk ) − g(v`))2
!1/2
×
 X
k<`
c(vk
, v`)(|g(vk )| + |g(v`)|)
2
!1/2
.
The expression in the first parentheses is equal to 1
2
P
x,y
c(x, y)(g(x) − g( y))2
. So it remain
to bound the expression in the second parentheses.
Note that
(|g(x)| + |g( y)|)
2 = 2g(x)
2 + 2g( y)
2 − (|g(x)| − |g( y)|)
2 ≤ 2g(x)
2 + 2g( y)
2
.
Therefore, since P
y
c(x, y) =
P
y
c( y, x) = π(x),
X
k<`
c(vk
, v`)(|g(vk )| + |g(v`)|)
2 ≤
1
2
X
x,y
c(x, y)(|g(x)| + |g( y)|)
2
≤
X
x
π(x)g(x)
2 +
X
y
π( y)g( y)
2
= 2
X
x
π(x)g(x)
2
.
That concludes the proof.
5.3.2 F Random Walks: Trees, Cycles, and Hypercubes Revisited
We use the techniques of the previous subsection to bound the mixing time of random walk
on some simple graphs. In particular, we revisit the examples of Section 4.3.2.
b-ary tree Let (Zt) be lazy simple random walk on the `-level rooted b-ary tree, bT
`
b
. The
root, 0, is on level 0 and the leaves, L, are on level `. All vertices have degree b + 1, except
for the root which has degree b and the leaves which have degree 1. Recall that the stationary
distribution is
π(x) :=
δ(x)
2(n − 1)
, (5.3.8)
where n is the number of vertices and δ(x) is the degree of x. We take b = 2 to simplify.
It is intuitively clear that each edge of this graph constitutes a bottleneck, with the root
being the most “balanced” one. Let x0 be a leaf of bT
`
b
and let A be the set of vertices “on
the other side of the root (inclusively),” that is, vertices whose graph distance from x0 is at
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.3 Geometric Bounds 309
least `. See Figure 4.7. Let S be the remaining vertices. Then, by symmetry, π(S) ≤ 1/2.
Note that there is a single edge connecting S and S
c = A, namely, the edge linking 0 and the
root of the subtree TS formed by the vertices in S. More precisely, let vS be the root of TS.
From (5.3.8), P(vS, 0) =
1
2
·
1
3 =
1
6
(where the 1/2 accounts for the laziness), π(vS) =
3
2n−2
,
and, by symmetry,
π(S) =
(2n − 2 − 2)/2
2n − 2
=
n − 2
2n − 2
,
where in the numerator we subtracted the degree of the root before dividing the sum of the
remaining degrees by 2. Hence,
8∗ ≤
1
6
￾
3
2n−2

n−2
2n−2
=
1
2(n − 2)
.
By Theorem 5.3.5,
γ ≤ 28∗ ≤
1
n − 2
and trel = γ
−1 ≥ n − 2.
Thus, by Theorem 5.2.14 and the fact that the chain is lazy
tmix(ε) ≥ (trel − 1) log
1
2ε

= (n).
We showed in Section 4.3.2, using other techniques, that tmix(ε) = 2(n).
Cycle Let (Zt) be lazy simple random walk on the cycle of size n, Zn := {0, 1, . . . , n − 1},
where i ∼ j if |j − i| = 1 (mod n). Assume n is even.
Consider a subset of vertices S. Note that by symmetry π(S) =
|S|
n
. Moreover, for all
i ∼ j, c(i, j) = π(i)P(i, j) =
1
n
·
1
2
·
1
2 =
1
4n
. Among all sets of size |S|, consecutive vertices
minimize the size of the boundary. So
8∗ ≤
2
1
4n
`
n
=
1
2`
for all ` ≤ n/2. This expression is minimized for ` = n/2 so
8∗ =
1
n
.
By Theorem 5.3.5,
1
2n
2
=
82
∗
2
≤ γ ≤ 28∗ =
2
n
and
n
2
≤ trel = γ
−1 ≤ 2n
2
.
Thus, by Theorem 5.2.14,
tmix(ε) ≥ (trel − 1) log
1
2ε

= (n)
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Pres310 Spectral Methods
and
tmix(ε) ≤ log
1
επmin
trel = O(n
2
log n).
We know from exact eigenvalue computations (see Section 5.2.2 where technically we con￾sidered the non-lazy chain; laziness only affects the relaxation time by a factor of 2) that in
fact γ =
2π
2
n
2 + O(n
−4
). We also showed in that section that tmix(ε) = O(n
2
). (Exercise 4.15
shows this is tight up to a constant factor.)
Hypercube Let (Zt) be lazy simple random walk on the n-dimensional hypercube Z
n
2
:=
{0, 1}
n
, where i ∼ j if ki − jk1 = 1.
To get a bound on the edge expansion constant, consider the set S = {x ∈ Z
n
2
: x1 = 0}.
By symmetry π(S) =
1
2
. For each i ∼ j, c(i, j) =
1
2
n
·
1
2
·
1
n =
1
n2
n+1
. Hence,
8∗ ≤
2
n−1 1
n2
n+1
1
2
=
1
2n
,
where in the numerator we used that |S| = 2
n−1
. By Theorem 5.3.5,
γ ≤ 28∗ ≤
1
n
.
Thus, by Theorem 5.2.14,
tmix(ε) ≥ (trel − 1) log
1
2ε

= (n).
We know from exact eigenvalue computations (Section 5.2.2) that in fact γ =
1
n
.
We also showed in Section 4.3.2 that tmix(ε) = 2(n log n).
5.3.3 F Random Graphs: Existence of an Expander Family and Application to
Mixing
In many applications, it is useful to construct “bottleneck-free” graphs. In particular, random
walks mix rapidly on such graphs. Formally:
Definition 5.3.9 (Expander family). Let {Gn}n be a collection of finite d-regular graphs with
limn |V(Gn)| = +∞, where V(Gn) is the vertex set of Gn. Let
8∗(Gn) := min 
|∂ES|
d|S|
: S ⊆ V(Gn), 0 < |S| ≤
|V(Gn)|
2

denote the edge expansion constant of Gn with unit conductances. Let α > 0. We say that
{Gn}n is a (d, α)-expander family if for all n,
8∗(Gn) ≥ α.
The key point of the definition is that the edge expansion constant of all graphs in an ex￾pander family is bounded away from 0 uniformly in n. Note that it is trivial to construct such
a family if we drop the bounded degree assumption: the edge expansion constant of the com￾plete graph Kn is 1/2 by Example 5.3.3. On the other hand, it is far from obvious that one
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.3 Geometric Bounds 311
Figure 5.4 A draw from Pinsker’s model.
can construct a family of sparse graphs (i.e., such that |E(Gn)| = O(|V(Gn)|)) with an edge
expansion constant uniformly bounded away from 0. It turns out that a simple probabilistic
construction does the trick.
We will need the following definition. For a subset S ⊆ V, we let the vertex boundary of VERTEX
S be BOUNDARY
∂VS := {y ∈ S
c
: ∃x ∈ S s.t. x ∼ y}.
Existence of expander graphs For simplicity, we allow multigraphs (i.e., E is a multiset;
or, put differently, there can be multiple edges between the same two vertices) and consider
the case d = 3. We construct a random bipartite multigraph Gn = (Ln, Rn, En) on 2n vertices
known as Pinsker’s model. Denote the vertices by Ln = {`1, . . . , `n} and Rn = {r1, . . . ,rn}.
Let σ
1
n
and σ
2
n
be independent uniform random permutations of [n]. The edge set of Gn is
given by
En := {(`i
,ri): i ∈ [n]} ∪

(`i
,rσ
1
n
(i)): i ∈ [n]
	
∪

(`i
,rσ
2
n
(i)): i ∈ [n]
	
.
In other words, Gn is a union of three independent uniform perfect matchings (and its vertices
are labeled so that one of the matchings is {(`i
,ri)}i). See Figure 5.4. Observe that, as a
multigraph, all vertices of Gn have degree 3. We show that there exists α > 0 such that,
for all n large enough, with positive (in fact, high) probability Gn has an edge expansion
constant bounded below by α. In particular, such a Gn exists for all n large enough and, thus,
there exists a (3, α)-expander family.
Claim 5.3.10 (Pinsker’s model: edge expansion constant). There exists α > 0 such that
lim
n
P[8∗(Gn) ≥ α] = 1.
Proof For convenience, assume n is even. We need to show that with probability going to
1, for any S with |S| ≤ |V(Gn)|/2 = n, we have |∂ES| ≥ αd|S| for some α > 0. We first
reduce the proof to a statement about sets of vertices lying on one side of Gn.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press312 Spectral Methods
Lemma 5.3.11 There is β > 0 such that
lim
n
P [|∂VK| ≥ (1 + β)|K|, ∀K ⊆ L, |K| ≤ n/2] = 1.
The same holds for R.
Before proving Lemma 5.3.11, we argue that it implies Claim 5.3.10. Note that the lemma
concerns the vertex boundary of K. To relate the latter to the edge boundary, let S with
|S| ≤ n, and let SL := S ∩ L and SR := S ∩ R. For any subset K ⊆ SL, the size of the edge
boundary of S can be bounded below as follows:
|∂ES| ≥ |∂VK| − |SR|, (5.3.9)
where we took into account that the vertices of ∂VK in SR do not contribute to the edge
boundary, but the others do as they are incident to at least one edge in ∂ES. It remains to find
a good K.
Assume without loss of generality that |SL| ≥ |SR| (in the other case, just interchange the
roles of L and R), and suppose that the event in the lemma holds. In particular, |SR| ≤ |S|/2.
We claim that there is a subset K of SL such that
|SR| ≤ |S|/2 ≤ |K| ≤ n/2. (5.3.10)
There are two cases:
• If |SL| < n/2, then take K = SL. It follows that |K| = |SL| ≥ |S|/2.
• If |SL| ≥ n/2, then let K be any subset of SL of size n/2. Since |S| ≤ n, it follows that
|K| = n/2 ≥ |S|/2.
Under the event in the lemma, |∂VK| ≥ (1 + β)|K|.
Going back to (5.3.9), using the lower bound on |∂VK| and (5.3.10), we get
|∂ES| ≥ (1 + β)|K| − |K| = β|K| ≥
β
2
|S| = α|S|,
where we set α = β/2. Since this holds for any set S with |S| ≤ n, we have proved
Claim 5.3.10.
It remains to prove the lemma.
Proof of Lemma 5.3.11 Let K ⊆ L with k := |K| ≤ n/2. Without loss of generality assume
K = {`1, . . . , `k }. Observe that, by construction, ∂VK ⊇ K
0
, where K
0 = {r1, . . . ,rk }. We
analyze the “bad event”
BK := {|∂VK| ≤ k + bβkc}
by considering all subsets of {rk+1, . . . ,rn} of size bβkc and bounding the probability that
all edges out of K fall into one of them and K0
. Note that there are ￾
n−k
bβkc

such subsets. See
Figure 5.5.
Since σ
1
n
and σ
2
n
are uniform and independent, they each match K to a uniformly chosen
subset of the same size in R and we have by a union bound
P[BK] ≤

n − k
bβkc
"￾
k+bβkc
k

￾
n
k

#2
≤

n
bβkc
￾
k+bβkc
bβkc
2
￾
n
k
2
,
where we used that ￾
n
s

=
￾
n
n−s

.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge Universit5.3 Geometric Bounds 313
Figure 5.5 Illustration of the main step in proof of the lemma.
Taking a union bound again, this time over Ks, we have
P[∃K ⊆ L, |K| ≤ n/2, |∂VK| ≤(1 + β)|K|]
≤
X
K⊆L, |K|≤n/2
P[BK]
≤
Xn/2
k=1

n
k
 n
bβkc
￾
k+bβkc
bβkc
2
￾
n
k
2
. (5.3.11)
We use the bound n
s
s
s ≤
￾
n
s

≤
e
sn
s
s
s ≤
e
tn
t
t
t for s ≤ t < n (Appendix A). To see the last inequality,
note that d
dt
log( e
tn
t
t
t ) = log( n
t
) > 0 for 0 < t < n. We obtain that the sum in the last display
is bounded as
Xn/2
k=1

n
k
 n
bβkc
￾
k+bβkc
bβkc
2
￾
n
k
2 =
Xn/2
k=1

n
bβkc
￾
k+bβkc
bβkc
2
￾
n
k

≤
Xn/2
k=1
e
βkn
βk
(βk)
βk

e
βk
(k+βk)
βk
(βk)
βk
2
n
k
k
k
≤
Xn/2
k=1

k
n
k(1−β) 
e
3
(1 + β)
2
β
3
βk
=
X∞
k=1
fn(k), (5.3.12)
where we defined
fn(k) := 1{k≤n/2}

k
n
k(1−β) 
e
3
(1 + β)
2
β
3
βk
.
Let also
g(k) :=
"
1
2
1−β 
e
3
(1 + β)
2
β
3
β
#k
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge Universit314 Spectral Methods
and notice that for β small enough
| fn(k)| ≤ g(k) ∀k
since k
n ≤
1
2
for k ≤
n
2
and
γβ :=

1
2
1−β 
e
3
(1 + β)
2
β
3
β
< 1,
using that β
β → 1 as β → 0. Moreover, for each k,
fn(k) → 0,
as n → +∞, and
X∞
k=1
g(k) ≤
1
1 − γβ
< +∞.
Hence, by the dominated convergence theorem (Theorem B.4.7), combining (5.3.11) and
(5.3.12), we get
P[∃K ⊆ L, |K| ≤ n/2, |∂VK| ≤ (1 + β)|K|] =
X∞
k=1
fn(k) → 0.
That concludes the proof.
That concludes the proof of Claim 5.3.10.
Claim 5.3.10 implies:
Theorem 5.3.12 (Existence of expander family). For α > 0 small enough, there exists a
(3, α)-expander (multigraph) family.
Proof By Claim 5.3.10, for all n large enough, there exists Gn with 8∗(Gn) ≥ α for some
fixed α > 0.
Fast mixing on expander graphs As we mentioned at the beginning of this subsection, an
important property of an expander graph is that random walk on such a graph mixes rapidly.
We make this precise.
Claim 5.3.13 (Mixing on expanders). Let {Gn} be a (d, α)-expander family. Then, tmix(ε) =
2(log |V(Gn)|), where the constant depends on ε and α.
Proof Because of the degree assumption, random walk on Gn is reversible with respect to
the uniform distribution (see Example 1.1.29). So, by Theorems 5.2.14 and 5.3.5, the mixing
time is upper bounded by
tmix(ε) ≤ log
1
επmin
trel ≤ log
|V(Gn)|
ε

2α
−2 = O(log |V(Gn)|).
By the diameter-based lower bound on the mixing time for reversible chains (Claim 5.2.25),
for n large enough,
tmix(ε) ≥
12
12 log |V(Gn)| + 4| log πmin|
,
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.3 Geometric Bounds 315
where 1 is the diameter of Gn. For a d-regular graph Gn, the diameter is at least log |V(Gn)|.
Indeed, by induction, the number of vertices within graph distance k of any vertex is at most
d
k
. For d
k
to be greater than |V(Gn)|, we need k ≥ logd
|V(Gn)|. Finally,
tmix(ε) ≥
(logd
|V(Gn)|)
2
16 log |V(Gn)|
= (log |V(Gn)|).
That concludes the proof.
5.3.4 F Ising Model: Glauber Dynamics on Complete Graphs and Expanders
Let G = (V, E) be a finite, connected graph with maximal degree δ¯. Define X := {−1, +1}
V
.
Recall from Example 1.2.5 that the (ferromagnetic) Ising model on V with inverse temper￾ature β is the probability distribution over spin configurations σ ∈ X given by
µβ (σ) :=
1
Z(β)
e
−βH(σ)
,
where
H(σ) := −X
i∼j
σiσj
is the Hamiltonian and
Z(β) :=
X
σ∈X
e
−βH(σ)
is the partition function. In this context, recall that vertices are often referred to as sites.
The single-site Glauber dynamics of the Ising model (Definition 1.2.8) is the Markov chain
on X which, at each time, selects a site i ∈ V uniformly at random and updates the spin
σi according to µβ (σ) conditioned on agreeing with σ at all sites in V\{i}. Specifically, for
γ ∈ {−1, +1}, i ∈ V, and σ ∈ X , let σ
i,γ be the configuration σ with the state at i being set
to γ . Then, letting n = |V|, the transition matrix of the Glauber dynamics is
Qβ (σ, σ
i,γ
) :=
1
n
·
e
γβSi(σ)
e
−βSi(σ) + e
βSi(σ)
=
1
n

1
2
+
1
2
tanh(γβSi(σ))
,
where
Si(σ) :=
X
j∼i
σj
.
All other transitions have probability 0. Recall that this chain is irreducible and reversi￾ble with respect to µβ . In particular, µβ is the stationary distribution of Qβ . We showed in
Claim 4.3.15 that the Glauber dynamics is fast mixing at high temperature. More precisely
we proved that tmix(ε) = O(n log n) when β < δ¯−1
. Here we prove a converse: at low tem￾perature, graphs with good enough expansion properties produce exponentially slow mixing
of the Glauber dynamics.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press316 Spectral Methods
Curie–Weiss model
Let G = Kn be the complete graph on n vertices. In this case, the Ising model is often referred
CURIE–WEISS to as the Curie–Weiss model. It is natural to scale β with n. We define α := β(n − 1). Since
MODEL δ¯ = n − 1, we have that when α < 1, β =
α
n−1 < δ¯−1
so tmix(ε) = O(n log n). In the other
direction, we prove:
Claim 5.3.14 (Curie–Weiss model: slow mixing at low temperature). For α > 1, tmix(ε) =
(exp(r(α)n)) for some function r(α) > 0 not depending on n.
Proof We first prove exponential mixing when α is large enough, an argument which will
be useful in the generalization to expander graphs in Claim 5.3.15.
The idea of the proof is to bound the edge expansion constant and use Theorem 5.3.5.
To simplify the proof, assume n is odd. We denote the edge expansion constant of the chain
by 8X
∗
to avoid confusion with that of the base graph G. Intuitively, because the spins tend
to align strongly at low temperature, it takes a considerable amount of time to travel from a
configuration with a majority of −1s to a configuration with a majority of +1s. Because the
model tends to prefer agreeing spins but does not favor any particular spin, a natural place
to look for a bottleneck is the set:
M :=
(
σ ∈ X :
X
i
σi < 0
)
,
where the quantity m(σ) :=
P
i
σi MAGNETI- is called the magnetization. Note that the magnetization is
ZATION positive if and only if a majority of spins are +1 and that it forms a Markov chain by itself.
So the boundary of the set M must be crossed to travel from configurations with mostly −1
spins to configurations with mostly −1 spins.
Observe further that µβ (M) = 1/2. The edge expansion constant is hence bounded by
8
X
∗ ≤
P
σ∈M,σ
0∈/M µβ (σ)Qβ (σ, σ
0
)
µβ (M)
= 2
X
σ∈M,σ
0∈/M
µβ (σ)Qβ (σ, σ
0
). (5.3.13)
Because the Glauber dynamics changes a single spin at a time, in order for σ ∈ M to be
adjacent to a configuration σ
0 ∈/ M, it must be that
σ ∈ M−1 := {σ ∈ X : m(σ) = −1},
and that σ
0 = σ
j,+ for some site j such that
j ∈ Jσ := {j ∈ V : σj = −1}.
Because the number of such sites is (n + 1)/2 on M−1, that is, |Jσ | = (n + 1)/2 for all
σ ∈ M−1, and the Glauber dynamics picks a site uniformly at random, it follows that for
σ ∈ M−1,
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.3 Geometric Bounds 317
X
σ∈M,σ
0∈/M
µβ (σ)Qβ (σ, σ
0
) =
X
σ∈M−1
µβ (σ)
X
j∈Jσ
Qβ (σ, σ
j,+
)
≤
X
σ∈M−1
µβ (σ)
(n + 1)/2
n
(5.3.14)
=
1
2

1 +
1
n

µβ (M−1). (5.3.15)
Thus, plugging this back in (5.3.13) gives
8
X
∗ ≤

1 +
1
n

µβ (M−1)
= (1 + o(1))
X
σ∈M−1
e
−βH(σ)
Z(β)
(5.3.16)
= (1 + o(1))
X
σ∈M−1
exp ￾
α
n−1
￾|Jσ |
2

+
￾
|J c
σ
|
2

− |Jσ ||J
c
σ
|

Z(β)
.
We bound the partition function Z(β) =
P
σ∈X
e
−βH(σ) with the term for the all-(−1) con￾figuration, leading to
8
X
∗ ≤ (1 + o(1))
X
σ∈M−1
exp ￾
α
n−1
￾|Jσ |
2

+
￾
|J c
σ
|
2

− |Jσ ||J
c
σ
|

exp ￾
α
n−1
￾|Jσ |
2

+
￾
|J c
σ
|
2

+ |Jσ ||J c
σ
|
 (5.3.17)
= (1 + o(1))
X
σ∈M−1
exp
−
2α
n − 1
|Jσ ||J
c
σ
|

= (1 + o(1))

n
(n + 1)/2

exp
−
2α
n − 1

n + 1
2
 n − 1
2

= (1 + o(1))
r
2
πn
2
n
(1 + o(1)) exp
−
α(n + 1)
2

≤ Cα
r
2
πn
exp 
−n
hα
2
− log 2i
for some constant Cα > 0 depending on α, where we used Stirling’s formula (see Appen￾dix A). Hence, by Theorems 5.2.14 and 5.3.5, for α > 2 log 2, there is r(α) > 0
tmix(ε) ≥ (trel − 1) log
1
2ε

≥ exp(r(α)n) log
1
2ε

.
That proves the weaker result.
We now show that α > 1 in fact suffices. For this, we need to improve our bound on the
partition function in (5.3.17). Writing
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge Univers318 Spectral Methods
Z(β) =
X
σ∈X
e
−βH(σ)
=
Xn
k=0

n
k

exp
α
n − 1
k
2

+

n − k
2

− k(n − k)

= 2
(nX−1)/2
k=0

n
k

exp
α
n − 1
k
2

+

n − k
2

− k(n − k)

=: 2
(nX−1)/2
k=0
Yα,k
,
we see that the partition function is a sum of O(n) exponentially large terms and is therefore
dominated by the term corresponding to the largest exponent. Using Stirling’s formula,
log
n
k

= (1 + o(1))nH(k/n),
where H( p) = −p log p − (1 − p) log(1 − p) is the entropy, and therefore
logYα,k = (1 + o(1))n

H(k/n) + α
(k/n)
2 + (1 − k/n)
2 − 2(k/n)(1 − k/n)
2

| {z }
Kα(k/n)
,
where, for p ∈ [0, 1], we let
Kα( p) := H( p) + α
(1 − 2p)
2
2
.
Note that the first term in Kα( p) is increasing on [0, 1/2], while the second term is decreasing
on [0, 1/2]. In a sense, we are looking at the trade-off between the contribution from the
entropy (i.e., how many ways are there to have k spins with value −1) and that from the
Hamiltonian (i.e., how much such a configuration is favored). We seek to maximize Kα( p)
to determine the leading term in the partition function.
By a straightforward computation,
K
0
α
( p) = log
1 − p
p

− 2α(1 − 2p)
and
K
00
α
( p) = −
1
p(1 − p)
+ 4α.
Observe first that when α < 1 (i.e., at high temperature), K0
α
(1/2) = 0 and K00
α
( p) < 0
for all p ∈ [0, 1] since p(1 − p) ≤ 1/4. Hence, in that case, Kα is maximized at p = 1/2.
In our case of interest, on the other hand, that is, when α > 1, K00
α
( p) > 0 in an interval
around 1/2 so there is p∗ < 1/2 with Kα( p∗) > Kα(1/2) = 1. So the distribution signifi￾cantly favors “unbalanced” configurations and crossing M−1 becomes a bottleneck for the
Glauber dynamics. Going back to (5.3.17) and bounding Z(β) ≥ 2Yα,bp∗nc
, we get
8
X
∗ = O (exp(−n[Kα( p∗) − Kα(1/2)])).
Applying Theorems 5.2.14 and 5.3.5 concludes the proof.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.3 Geometric Bounds 319
Expander graphs
In the proof of Claim 5.3.14, the bottleneck slowing down the chain arises as a result of
the fact that, when m(σ) = −1, there is a large number of edges in the base graph Kn
connecting Jσ and J
c
σ
. That produces a low probability for such configurations under the
ferromagnetic Ising model, where agreeing spins are favored. The same argument easily
extends to expander graphs. In words, we prove something that – at first – may seem a bit
counter-intuitive: good expansion properties in the base graph produces a bottleneck in the
Glauber dynamics at low temperature.
Claim 5.3.15 (Ising model on expander graphs: slow mixing of the Glauber dynamics). Let
{Gn}n be a (d, γ )-expander family. For large enough inverse temperature β > 0, the Glauber
dynamics of the Ising model on Gn satisfies tmix(ε) = (exp(r(β)|V(Gn)|)) for some function
r(β) > 0 not depending on n.
Proof Let µβ be the probability distribution over spin configurations under the Ising model
over Gn = (V, E) with inverse temperature β. Let Qβ be the transition matrix of the Glauber
dynamics. For not necessarily disjoint subsets of vertices W0, W1 ⊆ V in the base graph Gn,
let
E(W0, W1) := {{u, v}: u ∈ W0, v ∈ W1, {u, v} ∈ E}
be the set of edges with one endpoint in W0 and one endpoint in W1. Let N = |V(Gn)| and
assume it is odd for simplicity. We use the notation in the proof of Claim 5.3.14. Following
the argument in that proof, we observe that (5.3.15) and (5.3.16) still hold. Thus,
8
X
∗ ≤ (1 + o(1))
X
σ∈M−1
exp ￾
β

|E(Jσ ,Jσ )| + |E(J
c
σ
,J
c
σ
)| − |E(Jσ ,J
c
σ
)|

Z(β)
.
As we did in (5.3.17), we bound the partition function Z(β) =
P
σ∈X
e
−βH(σ) with the term
for the all-(−1) configuration, leading to
8
X
∗ ≤ (1 + o(1))
X
σ∈M−1
exp ￾
β

|E(Jσ ,Jσ )| + |E(J
c
σ
,J
c
σ
)| − |E(Jσ ,J
c
σ
)|

exp ￾
β

|E(Jσ ,Jσ )| + |E(J c
σ
,J c
σ
)| + |E(Jσ ,J c
σ
)|

= (1 + o(1))
X
σ∈M−1
exp ￾
−2β|E(Jσ ,J
c
σ
)|

= (1 + o(1))
X
σ∈M−1
exp ￾
−2β|∂EJ
c
σ
|

≤ (1 + o(1))

N
(N + 1)/2

exp ￾
−2βγ d|J
c
σ
|

= (1 + o(1))
r
2
πN
2
N
(1 + o(1)) exp (−βγ d(N − 1))
≤ Cβ,γ ,d
r
2
πN
exp (−N [βγ d − log 2]),
for some constant Cβ,γ ,d > 0. We used the definition of an expander family (Definition 5.3.9)
on the fourth line above. Taking β > 0 large enough gives the result.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University320 Spectral Methods
5.3.5 Congestion Ratio
Recall from (5.3.2) that an inequality of the type
Varπ [ f ] ≤ CD( f ) (5.3.18)
holding for all f is known as a Poincaré inequality. By Theorem 5.3.4, it implies the lower
bound γ ≥ C
−1 on the spectral gap γ = 1−λ2. In this section, we derive such an inequality
using a formal measure of “congestion” in the network.
Let N = (G, c) be a finite, connected network with G = (V, E). We assume that c(x, y) =
π(x)P(x, y) and therefore c(x) =
P
y∼x
c(x, y) = π(x), where π is the stationary distribution
of random walk on N . To state the bound, it will be convenient to work with directed edges
– this time in both directions. Let eE contain all edges from E with both orientations, that is,
for each e ∈ {x, y}, eE includes (x, y) and ( y, x) with associated weight c(x, y) = c( y, x) =
c(e) > 0. For a function f ∈ `
2
(V, π) and an edge Ee = (x, y) ∈ eE, we define as before
∇f (Ee) = f ( y) − f (x).
With this notation, we can rewrite the Dirichlet energy as
D( f ) =
1
2
X
x,y
c(x, y)[ f (x) − f ( y)]2 =
1
2
X
Ee∈eE
c(Ee)[∇f (Ee)]2
. (5.3.19)
For each pair of vertices x, y, let νx,y be a directed path between x and y in the digraph
eG = (V,eE), as a collection of directed edges. Let |νx,y
| be the number of edges in the path.
CONGESTION The congestion ratio associated with the paths ν = {νx,y}x,y∈V is
RATIO
Cν = max
Ee∈eE
1
c(Ee)
X
x,y:Ee∈νx,y
|νx,y
|π(x)π( y).
CANONICAL Note that Cν tends to be large when many selected paths, called canonical paths, go through
PATHS the same “congested” edge. To get a good bound in the theorem below, one must choose
canonical paths that are well “spread out.”
Theorem 5.3.16 (Canonical paths method). For any choice of paths ν as above, we have
the following bound on the spectral gap
γ ≥
1
Cν
.
Proof We establish a Poincaré inequality (5.3.18) with C := Cν . The proof strategy is to
start with the variance and manipulate it to bring out canonical paths.
For any f ∈ `
2
(V, π), it can be checked by expanding that
Varπ [ f ] =
1
2
X
x,y
π(x)π( y)( f (x) − f ( y))2
. (5.3.20)
To bring out terms similar to those in (5.3.19), we write f (x) − f ( y) as a telescoping sum
over the canonical path between x and y. That is, letting Ee1, . . . , Ee|νx,y| be the edges in νx,y
,
observe that
f ( y) − f (x) =
X
|νx,y|
i=1
∇f (Eei).
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press5.3 Geometric Bounds 321
By Cauchy–Schwarz (Theorem B.4.8),
( f ( y) − f (x))2 =


X
|νx,y|
i=1
∇f (Eei)


2
≤


X
|νx,y|
i=1
1
2




X
|νx,y|
i=1
∇f (Eei)
2


= |νx,y
|
X
Ee∈νx,y
∇f (Ee)
2
.
Combining the last display with (5.3.20) and rearranging, we arrive at
Varπ [ f ] ≤
1
2
X
x,y
π(x)π( y)|νx,y
|
X
Ee∈νx,y
∇f (Ee)
2
=
1
2
X
Ee∈eE
∇f (Ee)
2 X
x,y:Ee∈νx,y
|νx,y
|π(x)π( y)
=
1
2
X
Ee∈eE
c(Ee)∇f (Ee)
2


1
c(Ee)
X
x,y:Ee∈νx,y
|νx,y
|π(x)π( y)


≤ Cν D( f ).
That concludes the proof.
We give an example next.
Example 5.3.17 (Random walk inside a box). Consider random walk on the following d￾dimensional box with sides of length n:
V = [n]
d = {1, . . . , n}
d
,
E = {x, y ∈ [n]
d
: kx − yk1 = 1},
P(x, y) =
1
|{z: z ∼ x}|
∀x, y ∈ [n]
d
, x ∼ y,
π(x) =
|{z: z ∼ x}|
2|E|
,
and
c(e) =
1
2|E|
, ∀e ∈ E.
We define eE as before.
We use Theorem 5.3.16 to bound the spectral gap. For x = (x1, . . . , xd), y = ( y1, . . . , yd) ∈
[n]
d
, we construct νx,y by matching each coordinate in turn. That is, for two vertices w,
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press322 Spectral Methods
z ∈ [n]
d with a single distinct coordinate, let [w,z] be the directed path from w to z in
eG = (V,eE) corresponding to a straight line (or the empty path if w = z). Then,
νx,y =
[
d
i=1
[( y1, . . . , yi−1, xi
, xi+1, . . . , xd), ( y1, . . . , yi−1, yi
, xi+1, . . . , xd)] . (5.3.21)
It remains to bound
Cν = max
Ee∈eE
1
c(Ee)
X
x,y:Ee∈νx,y
|νx,y
|π(x)π( y)
from above.
Each term in the union defining νx,y contains at most n edges, and therefore
|νx,y
| ≤ dn, ∀x, y.
Not attempting to get the best constant factors, the edge weights (i.e., conductances) satisfy
c(Ee) =
1
2|E|
≥
1
2 · 2dnd
=
1
4dnd
for all Ee, since there are n
d vertices and each has at most 2d incident edges. Likewise, for
any x,
π(x) =
|{z: z ∼ x}|
2|E|
≤
2d
2 · (dnd
)/2
=
2
n
d
,
where we divided by two in the denominator to account for the double-counting of edges.
Hence we get
Cν ≤ max
Ee∈eE
1
1/(4dnd
)
X
x,y : Ee∈νx,y
(dn)(2/n
d
)(2/n
d
)
=
16d
2
n
d−1
max
Ee∈eE

{x, y : Ee ∈ νx,y}


.
To bound the cardinality of the set on the last line, we note that any edge Ee ∈ eE is of the
form
Ee = ((z1, . . . ,zi−1,zi
,zi+1, . . . ,zd), (z1, . . . ,zi−1,zi ± 1,zi+1, . . . ,zd)),
that is, the endvertices differ by exactly one unit along a single coordinate. By the construc￾tion of the path νx,y
in (5.3.21), if Ee ∈ νx,y
, then it must lie in the subpath
((z1, . . . ,zi−1,zi
,zi+1, . . . ,zd), (z1, . . . ,zi−1,zi ± 1,zi+1, . . . ,zd))
∈ [( y1, . . . , yi−1, xi
, xi+1, . . . , xd), ( y1, . . . , yi−1, yi
, xi+1, . . . , xd)] .
But that imposes constraints on x and y. Namely, we must have
y1 = z1, . . . , yi−1 = zi−1, xi+1 = zi+1, . . . , xd = zd.
The remaining components of x and y (of which there are i of the former and d − (i − 1) of
the latter) have at most n possible values (although not all of them are allowed), so that

{x, y : Ee ∈ νx,y}

 ≤ n
i
n
d−(i−1) = n
d+1
.
This upper bound is valid for any Ee.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University PressExercises 323
Putting everything together, we get the bound
Cν ≤
16d
2
n
d−1
n
d+1 = 16d
2
n
2
,
so that
γ ≥
1
16d
2n
2
.
Observe that this lower bound on the spectral gap depends only mildly (i.e., polynomially)
in the dimension. J
One advantage of the canonical paths method is that it is somewhat robust to modify￾ing the underlying network through comparison arguments. See Exercise 5.17 for a simple
illustration.
Exercises
Exercise 5.1 Let A be an n × n symmetric random matrix. We assume that the entries on
and above the diagonal, Ai, j
, i ≤ j, are independent and uniform in {+1, −1} (and each entry
below the diagonal is equal to the corresponding entry above). Use Talagrand’s inequality
(Theorem 3.2.32) to prove concentration of the largest eigenvalue of A around its mean
(which you do not need to compute).
Exercise 5.2 Let G = (V, E,w) be a network.
(i) Prove formula (5.1.3) for the Laplacian quadratic form. (Hint: For an orientation G
σ =
(V, E
σ
) of G (that is, give an arbitrary direction to each edge to turn it into a digraph),
consider the matrix B
σ ∈ R
n×m where the column corresponding to arc (i, j) has −
√wij
in row i and √wij in row j, and every other entry is 0.)
(ii) Show that the network Laplacian is positive semi-definite.
Exercise 5.3 Let G = (V, E,w) be a weighted graph with normalized Laplacian L. Show
that
x
TLx =
X
{i, j}∈E
wij 
xi
√
δ(i)
−
xj
√
δ( j)
2
for x = (x1, . . . , xn) ∈ R
n
.
Exercise 5.4 (2-norm). Prove that
sup
x∈S
n−1
kAxk2 = sup
x∈S
n−1
y∈S
m−1
hAx, yi.
(Hint: Use Cauchy–Schwarz (Theorem B.4.8) for one direction, and set y = Ax/kAxk2 for
the other one.)
Exercise 5.5 (Spectral radius of a symmetric matrix). Let A ∈ R
n×n be a symmetric matrix.
The set σ(A) of eigenvalues of A is called the spectrum of A and SPECTRUM
ρ(A) = max{|λ|: λ ∈ σ(A)}
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press324 Spectral Methods
SPECTRAL is its spectral radius. Prove that
RADIUS
ρ(A) = kAk2,
where we recall that
kAk2 = max
06=x∈Rm
kAxk
kxk
.
Exercise 5.6 (Community recovery in sparse networks). Assume without proof the follow￾ing theorem.
Theorem 5.3.18 (Remark 3.13 of [BH16]). Consider a symmetric matrix Z = [Zi, j] ∈ R
n×n
whose entries are independent and obey, EZi, j = 0 and Zi, j ≤ B ∀1 ≤ i, j ≤ n, EZ
2
i, j ≤ σ
2
,
then with high probability we have ||Z|| . σ
√
n + B
√
log n.
Let (X, G) ∼ SBMn,pn,qn
. Show that, under the conditions pn &
logn
n
and q
pn
n = o(pn − qn),
spectral clustering achieves almost exact recovery.
Exercise 5.7 (Parseval’s identity). Prove Parseval’s identity (i.e., (5.2.1)) in the finite-dimen￾sional case.
Exercise 5.8 (Dirichlet kernel). Prove that for θ 6= 0,
1 + 2
Xn
k=1
cos kθ =
sin((n + 1/2)θ)
sin(θ/2)
.
(Hint: Switch to the complex representation and use the formula for a geometric series.)
Exercise 5.9 (Eigenvalues and periodicity). Let P be a finite irreducible transition matrix
reversible with respect to π over V. Show that if P has a non-zero eigenfunction f with
eigenvalue −1, then P is not aperiodic. (Hint: Look at x achieving k f k∞.)
Exercise 5.10 (Mixing time: necessary condition for cutoff). Consider a sequence of Mar￾kov chains indexed by n = 1, 2, . . .. Assume that each chain has a finite state space and is
irreducible, aperiodic, and reversible. Let t(n)
mix(ε) and t(n)
rel be, respectively, the mixing time
and relaxation time of the nth chain. The sequence is said to have pre-cutoff if
sup
0<ε<1/2
lim sup
n→+∞
t
(n)
mix(ε)
t
(n)
mix(1 − ε)
< +∞.
Show that if for some ε > 0,
sup
n≥1
t
(n)
mix(ε)
t
(n)
rel
< +∞,
then there is no pre-cutoff. In particular, there is no cutoff, as defined in Remark 4.3.8.
Exercise 5.11 (Relaxation time and variance). Let P be a finite irreducible transition matrix
reversible with respect to π over V. Define
Varπ [g] =
X
x∈V
π(x)[g(x) − πg]
2
.
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University PressExercises 325
Let γ∗ be the absolute spectral gap of P. Show that
Varπ [P
t
f ] ≤ (1 − γ∗)
2tVarπ [ f ].
Exercise 5.12 (Lumping). Let (Xt) be a Markov chain on a finite state space V with transi￾tion P. Suppose there is an equivalence relation ∼ on V with equivalence classes V
]
, denot￾ing by [x] the equivalence class of x, such that [Xt] is a Markov chain with transition matrix
P
]
([x], [y]) = P(x, [y]).
(i) Let f : V → R be an eigenfunction of P with eigenvalue λ and assume that f is constant
on each equivalence class. Prove that f
]
([x]) := f (x) defines an eigenfunction of P
]
.
What is its eigenvalue?
(ii) Suppose g : V
] → R is eigenfunction of P
] with eigenvalue λ. Prove that g
[
: V → R
defined by g
[
(x) := g([x]) is eigenfunction of P. What is its eigenvalue?
Exercise 5.13 (Random walk on path with reflecting boundaries). Let n be an even positive
integer. Let (Xt) be simple random walk on the path {1, . . . , n} with reflecting boundaries,
that is, the transition matrix P is defined by P(x, x − 1) = P(x, x + 1) = 1/2 for x ∈ {2, . . . ,
n − 1}, and P(1, 2) = P(n, n − 1) = 1. Use Exercise 5.12 to compute the eigenfunctions of
P. (Hint: Use the results of Section 5.2.2.)
Exercise 5.14 (Product chain). For j = 1, . . . , d, let Pj be a transition matrix on the finite
state space Vj reversible with respect to the stationary distribution πj
. Let w = (wj)j∈[d]
be a probability distribution over [d]. Consider the following Markov chain (Xt) on V :=
V1 × · · · ×Vd: at each step, pick j according to w, then take one step along the jth coordinate
according to Pj
.
(i) Compute the transition matrix P and stationary distribution π of the chain (Xt). Show
that P is reversible with respect to π.
(ii) Construct an orthonormal basis of `
2
(V, π) made of eigenfunctions of P in terms of
eigenfunctions of the Pjs. What are the corresponding eigenvalues?
(iii) Compute the spectral gap γ of P in terms of the spectral gaps γj of the Pjs.
Exercise 5.15 (Hypercube revisited). Use Exercise 5.14 to recover Lemma 5.2.17.
Exercise 5.16 (Norm and Rayleigh quotient). Let P be irreducible and reversible with re￾spect to π > 0.
(i) Prove the polarization identity
hPf , giπ =
1
4
[hP( f + g), f + giπ − hP( f − g), f − giπ ] .
(ii) Show that
kPkπ = sup 
hf , Pf iπ
hf , f iπ
: f ∈ `0(V), f 6= 0

.
Exercise 5.17 (Random walk on a box with holes). Consider the random walk in Exam￾ple 5.3.17 with d = 2. Suppose we remove from the network an arbitrary collection of
horizontal edges at even heights. Use the canonical paths method to derive a lower bound on
the spectral gap of the form γ ≥ 1/(Cn2
). (Hint: Modify the argument in Example 5.3.17
and relate the congestion ratio before and after the removal.)
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press326 Spectral Methods
Bibliographic Remarks
Section 5.1 General references on the spectral theorem, the Courant–Fischer and pertur￾bation results include the classics [HJ13, Ste98]. Much more on spectral graph theory can
be gleaned from [Chu97, Nic18]. Section 5.1.4 is based largely on [Abb18], which gives a
broad survey of theoretical results for community recovery, and [Ver18, section 4.5] as well
as on scribe notes by Joowon Lee, Aidan Howells, Govind Gopakumar, and Shuyao Li for
“MATH 888: Topics in Mathematical Data Science” taught at the University of Wisconsin–
Madison in Fall 2021.
Section 5.2 For a great introduction to Hilbert space theory and its applications (including
to the Dirichlet problem), consult [SS05, chapters 4,5]. Section 5.2.1 borrows from [LP17,
chapter 12]. A representation-theoretic approach to computing eigenvalues and eigenfunc￾tions, greatly generalizing the calculations in 5.2.2, is presented in [Dia88]. The presentation
in Section 5.2.3 follows [KP, section 3] and [LP16, section 13.3]. The Varopoulos–Carne
bound is due to Carne [Car85] and Varopoulos [Var85]. For a probabilistic approach to
the Varopoulos–Carne bound, see Peyre’s proof [Pey08]. The application to mixing times is
from [LP16]. There are many textbooks dedicated to Markov chain Monte Carlo (MCMC)
and its uses in data analysis, for example, [RC04, GL06, GCS+14]. See also [Dia09]. A
good overview of the techniques developed in the statistics literature to bound the rate of
convergence of MCMC methods (a combination of coupling and Lyapounov arguments)
is [JH01]. A deeper treatment of these ideas is developed in [MT09]. A formal definition
of the spectral radius and its relationship to the operator norm can be found, for instance,
in [Rud73, Part III].
Section 5.3 This section follows partly the presentation in [LP16, section 6.4], [LPW06,
section 13.6], and [Spi12]. Various proofs of the isoperimetric inequality can be found
in [SS03, SS05]. Theorem 5.3.5 is due to [SJ89, LS88]. The approach to its proof used
here is due to Luca Trevisan. The original Cheeger inequality was proved, in the con￾text of manifolds, in [Che70]. For a fascinating introduction to expander graphs and their
applications, see [HLW06]. A detailed account of the Curie–Weiss model can be found
in [FV18]. Section 5.3.5 is based partly on [Ber14, sections 3 and 4]. The method of ca￾nonical paths, and some related comparison techniques, were developed in [JS89, DS91,
DSC93b, DSC93a]. For more advanced functional techniques for bounding the mixing time,
see, for example, [MT06].
https://doi.org/10.1017/9781009305129.006 Published online by Cambridge University Press6
Branching Processes
Branching processes, which are the focus of this chapter, arise naturally in the study of sto￾chastic processes on trees and locally tree-like graphs. Similarly to martingales, finding a
hidden (or not-so-hidden) branching process within a probabilistic model can lead to useful
bounds and insights into asymptotic behavior. After a review of the basic extinction theory of
branching processes in Section 6.1 and of a fruitful random-walk perspective in Section 6.2,
we give a couple of examples of applications in discrete probability in Section 6.3. In par￾ticular, we analyze the height of a binary search tree, a standard data structure in computer
science. We also give an introduction to phylogenetics, where a “multitype” variant of the
Galton–Watson branching process plays an important role; we use the techniques derived
in this chapter to establish a phase transition in the reconstruction of ancestral molecular
sequences. We end this chapter in Section 6.4 with a detailed look into the phase transition
of the Erd ˝os–Rényi graph model. The random-walk perspective mentioned above allows one
to analyze the “exploration” of a largest connected component, leading to information about
the “evolution” of its size as edge density increases. Tools from all chapters come to bear on
this final, marquee application.
6.1 Background
We begin with a review of the theory of Galton–Watson branching processes, a standard
stochastic model for population growth. In particular, we discuss extinction theory. We also
briefly introduce a multitype variant, where branching process and Markov chain aspects
interact to produce interesting new behavior.
6.1.1 Basic Definitions
Recall the definition of a Galton–Watson process.
Definition 6.1.1 A Galton–Watson branching process is a Markov chain of the following GALTON–
WATSON
PROCESS
form:
• Let Z0 := 1.
• Let X(i, t), i ≥ 1, t ≥ 1, be an array of i.i.d. Z+-valued random variables with finite mean
m = E[X(1, 1)] < +∞, and define inductively
Zt
:=
X
1≤i≤Zt−1
X(i, t).
327
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press328 Branching Processes
We denote by {pk }k≥0 the law of X(1, 1). We also let f (s) := E[s
X(1,1)] be the corresponding
probability generating function. To avoid trivialities we assume P[X(1, 1) = i] < 1 for all
i ≥ 0. We further assume that p0 > 0.
In words, Zt models the size of a population at time (or generation) t. The random vari￾able X(i, t) corresponds to the number of offspring of the ith individual (if there is one) in
generation t−1. Generation t is formed of all offspring of the individuals in generation t−1.
By tracking genealogical relationships, that is, who is whose child, we obtain a tree T
rooted at the single individual in generation 0 with a vertex for each individual in the progeny
GALTON– and an edge for each parent–child relationship. We refer to T as a Galton–Watson tree.
WATSON
TREE
A basic observation about Galton–Watson processes is that their growth (or decay) is
exponential in t.
Lemma 6.1.2 (Exponential growth I). Let
Wt
:= m
−tZt
. (6.1.1)
Then (Wt) is a non-negative martingale with respect to the filtration
Ft = σ(Z0, . . . , Zt).
In particular, E[Zt] = m
t
.
Proof We use Lemma B.6.17. Observe that on {Zt−1 = k},
E[Zt
| Ft−1] = E


X
1≤j≤k
X(j, t)





Ft−1

 = mk = mZt−1.
This is true for all k. Rearranging shows that (Wt) is a martingale. For the second claim, note
that E[Wt] = E[W0] = 1.
In fact, the martingale convergence theorem (Theorem 3.1.47) gives the following.
Lemma 6.1.3 (Exponential growth II). We have Wt → W∞ < +∞ almost surely for some
non-negative random variable W∞ ∈ σ(∪tFt) with E[W∞] ≤ 1.
Proof This follows immediately from the martingale convergence theorem for non-negative
martingales (Corollary 3.1.48).
6.1.2 Extinction
Observe that 0 is a fixed point of the process. The event
{Zt → 0} = {∃t: Zt = 0}
EXTINCTION is called extinction. Establishing when extinction occurs is a central question in branching
process theory. We let η be the probability of extinction. Recall that, to avoid trivialities, we
assume p0 > 0 and p1 < 1. Here is a first observation about extinction.
Lemma 6.1.4 Almost surely either Zt → 0 or Zt → +∞.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.1 Background 329
Proof The process (Zt) is integer-valued and 0 is the only fixed point of the process under
the assumption that p1 < 1. From any state k, the probability of never coming back to k > 0
is at least p
k
0 > 0, so every state k > 0 is transient. So the only possibilities left are Zt → 0
and Zt → +∞, and the claim follows.
In the critical case, that immediately implies almost sure extinction.
Theorem 6.1.5 (Extinction: critical case). Assume m = 1. Then Zt → 0 almost surely, that
is, η = 1.
Proof When m = 1, (Zt) itself is a martingale. Hence (Zt) must converge to 0 by Lemma
6.1.3.
We address the general case using probability generating functions. Let ft(s) = E[s
Zt
],
where by convention we set ft(0) := P[Zt = 0]. Note that, by monotonicity,
η = P[∃t ≥ 0: Zt = 0] = lim
t→+∞
P[Zt = 0] = lim
t→+∞
ft(0). (6.1.2)
Moreover, by the tower property (Lemma B.6.16) and the Markov property (Theorem 1.1.18),
ft has a natural recursive form
ft(s) = E[s
Zt
]
= E[E[s
Zt
| Ft−1]]
= E[ f (s)
Zt−1
]
= ft−1( f (s)) = · · · = f
(t)
(s), (6.1.3)
where f
(t)
is the tth iterate of f . The subcritical case below has an easier proof (see Exer￾cise 6.1).
Theorem 6.1.6 (Extinction: subcriticial and supercritical cases). The probability of extinc￾tion η is given by the smallest fixed point of f in [0, 1]. Moreover:
(i) (Subcritical regime) If m < 1, then η = 1.
(ii) (Supercritical regime) If m > 1, then η < 1.
Proof The case p0 + p1 = 1 is straightforward: the process dies almost surely after a
geometrically distributed time. So we assume p0 + p1 < 1 for the rest of the proof.
We first summarize without proof some properties of f which follow from standard power
series facts.
Lemma 6.1.7 On [0, 1], the function f satisfies:
(i) f (0) = p0, f (1) = 1;
(ii) f is infinitely differentiable on [0, 1);
(iii) f is strictly convex and increasing; and
(iv) lims↑1 f
0
(s) = m < +∞.
We first characterize the fixed points of f . See Figure 6.1 for an illustration.
Lemma 6.1.8 We have the following.
(i) If m > 1, then f has a unique fixed point η0 ∈ [0, 1).
(ii) If m < 1, then f (t) > t for t ∈ [0, 1). Let η0 := 1 in that case.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press330 Branching Processes
Figure 6.1 Fixed points of f in subcritical (a) and supercritical (b) cases.
Figure 6.2 Convergence of iterates to a fixed point.
Proof Assume m > 1. Since f
0
(1) = m > 1, there is δ > 0 such that f (1 − δ) < 1 − δ. On
the other hand, f (0) = p0 > 0 so by continuity of f there must be a fixed point in (0, 1 − δ).
Moreover, by strict convexity and the fact that f (1) = 1, if x ∈ (0, 1) is a fixed point, then
f (y) < y for y ∈ (x, 1), proving uniqueness.
The second part follows by strict convexity and monotonicity.
It remains to prove convergence of the iterates to the appropriate fixed point. See Fig￾ure 6.2 for an illustration.
Lemma 6.1.9 We have the following.
(i) If x ∈ [0, η0), then f (t)
(x) ↑ η0.
(ii) If x ∈ (η0, 1), then f (t)
(x) ↓ η0.
Proof We only prove (i). The argument for (ii) is similar. By monotonicity, for x ∈ [0, η0),
we have x < f (x) < f (η0) = η0. Iterating,
x < f
(1)(x) < · · · < f
(t)
(x) < f
(t)
(η0) = η0.
So f
(t)
(x) ↑ L ≤ η0 as t → ∞. By continuity of f , we can take the limit t → ∞ inside of f
on the right-hand side of the equality
f
(t)
(x) = f ( f
(t−1)(x))
to get L = f (L). So by definition of η0 we must have L = η0.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.1 Background 331
The result then follows from the above lemmas together with (6.1.2) and (6.1.3).
Example 6.1.10 (Poisson branching process). Consider the offspring distribution X(1, 1) ∼
Poi(λ) with mean λ > 0. We refer to this case as the Poisson branching process. Then,
f (s) = E[s
X(1,1)] =
X
i≥0
e
−λ
λ
i
i!
s
i = e
λ(s−1)
.
So the process goes extinct with probability 1 when λ ≤ 1. For λ > 1, the probability of
extinction η is the smallest solution in [0, 1] to the equation
e
−λ(1−x) = x.
The survival probability ζλ := 1 − η satisfies 1 − e
−λζλ = ζλ. J
We can use these extinction results to obtain more information on the limit in Lemma 6.1.3.
Recall the definition of (Wt) in (6.1.1). Of course, conditioned on extinction, W∞ = 0 almost
surely. On the other hand:
Lemma 6.1.11 (Exponential growth III). Conditioned on non-extinction, either W∞ = 0
almost surely or W∞ > 0 almost surely.
As a result, P[W∞ = 0] ∈ {η, 1}.
Proof of Lemma 6.1.11 A property of rooted trees is said to be inherited if all finite trees
satisfy the property and whenever a tree satisfies the property then so do all subtrees rooted at
the children of the root. The property {W∞ = 0}, as a property of the Galton–Watson tree T,
is inherited, seeing that Zt
is a sum over the children of the root of the number of descendants
at the corresponding generation t − 1. The result then follows from the following 0-1 law.
Lemma 6.1.12 (0-1 law for inherited properties). For a Galton–Watson tree T, an inherited
property A has, conditioned on non-extinction, probability 0 or 1.
Proof Let T
(1)
, . . . , T
(Z1) be the descendant subtrees of the children of the root. We use
the notation T ∈ A to mean that tree T satisfies A. By the tower property, the definition of
inherited, and conditional independence, we have
P[A] = E[P[T ∈ A | Z1]]
≤ E[P[T
(i) ∈ A, ∀i ≤ Z1 | Z1]]
= E[P[A]
Z1
]
= f (P[A]).
So P[A] ∈ [0, η] ∪ {1} by the proof of Lemma 6.1.8.
Moreover, since A holds for finite trees, we have P[A] ≥ η, where we recall that η is the
probability of extinction. Hence, in fact, P[A] ∈ {η, 1}. Conditioning on non-extinction gives
the claim.
That concludes the proof.
A further moment assumption provides a more detailed picture.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press332 Branching Processes
Lemma 6.1.13 (Exponential growth IV). Let (Zt) be a Galton–Watson branching process
with m = E[X(1, 1)] > 1 and σ
2 = Var[X(1, 1)] < +∞. Then, (Wt) converges in L2 and, in
particular, E[W∞] = 1. Furthermore, P[W∞ = 0] = η.
Proof We bound E[W2
t
] by computing it explicitly by induction. From the orthogonality of
increments (Lemma 3.1.50), it holds that
E[W2
t
] = E[W2
t−1
] + E[(Wt − Wt−1)
2
].
Since E[Wt
| Ft−1] = Wt−1 by the martingale property,
E[(Wt − Wt−1)
2
| Ft−1] = Var[Wt
| Ft−1]
= m
−2t Var[Zt
| Ft−1]
= m
−2t Var "X
Zt−1
i=1
X(i, t)





Ft−1
#
= m
−2tZt−1σ
2
.
Hence, taking expectations and using Lemma 6.1.2, we get
E[W2
t
] = E[W2
t−1
] + m
−t−1
σ
2
.
Since E[W2
0
] = 1, induction gives
E[W2
t
] = 1 + σ
2Xt+1
i=2
m
−i
,
which is uniformly bounded from above when m > 1.
By the convergence theorem for martingales bounded in L
2
(Theorem 3.1.51), (Wt) con￾verges almost surely and in L
2
to a finite limit W∞ and
1 = E[Wt] → E[W∞].
The last statement follows from Lemma 6.1.11.
Remark 6.1.14 A theorem of Kesten and Stigum gives a necessary and sufficient condition
for E[W∞] = 1 to hold [KS66b]. See, for example, [LP16, chapter 12].
6.1.3 F Percolation: Galton–Watson Trees
Let T be the Galton–Watson tree for an offspring distribution with mean m > 1. Now
perform bond percolation on T with density p (see Definition 1.2.1). Let C0 be the open
cluster of the root in T. Recall from Section 2.3.3 that the critical value is
pc(T) = sup{p ∈ [0, 1]: θ(p) = 0},
where the percolation function (conditioned on T) is θ(p) = Pp[|C0| = +∞ | T].
Theorem 6.1.15 (Bond percolation on Galton–Watson trees). Assume m > 1. Conditioned
on non-extinction of T,
pc(T) =
1
m
almost surely.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.1 Background 333
Proof We can think of C0 (or more precisely, its size on each level) as being itself generated
by a Galton–Watson branching process, where this time the offspring distribution is the law
of PX(1,1)
i=1
Ii
, where the Iis are i.i.d. Ber(p) and X(1, 1) is distributed according to the offspring
distribution of T. In other words, we are “thinning” T. By conditioning on X(1, 1) and then
using the tower property (Lemma B.6.16), the offspring mean under the process generating
C0 is mp.
If mp ≤ 1, then by the extinction theory (Theorems 6.1.5 and 6.1.6),
1 = Pp[|C0| < +∞] = E[Pp[|C0| < +∞ | T]],
and we must have Pp[|C0| < +∞ | T] = 1 almost surely. Taking p = 1/m, we get pc(T) ≥
1
m
almost surely. That holds, in particular, on the non-extinction of T, which happens with
positive probability.
For the other direction, fix p such that mp > 1. The property of trees{Pp[|C0| < +∞ | T] =
1} is inherited. So by Lemma 6.1.12, conditioned on non-extinction of T, it has probability
0 or 1. That probability is of course 1 on extinction. By Theorem 6.1.6,
1 > Pp[|C0| < +∞] = E[Pp[|C0| < +∞ | T]],
and, conditioned on non-extinction of T, we must have Pp[|C0| < +∞ | T] = 0 – i.e.,
pc(T) < p – almost surely. Repeating this argument for a sequence pn ↓ 1/m simultaneously
(i.e., on the same T) and using the monotonicity of Pp[|C0| < +∞ | T], we get that pc(T) ≤
1/m almost surely conditioned on non-extinction of T. That proves the claim.
6.1.4 Multitype Branching Processes
Multitype branching processes are a useful generalization of Galton–Watson processes (Def- MULTITYPE
BRANCHING
PROCESSES
inition 6.1.1). Their behavior combines aspects of branching processes (exponential growth,
extinction, etc.) and Markov chains (reducibility, mixing, etc.). We will not develop the full
theory here. In this section, we define this class of processes and hint (largely without proofs)
at their properties. In Section 6.3.2, we illustrate some of the more intricate interplay between
the driving phenomena involved in a special example of practical importance.
Definition In a multitype branching process, each individual has one of τ types, which we
will denote in this section by 1, . . . , τ for simplicity. Each type α ∈ [τ ] = {1, . . . , τ } has
its own offspring distribution {p
(α)
k
: k ∈ Z
τ
+
}, which specifies the distribution of the number
of offspring of each type it has. Just to emphasize, this is a collection of (typically distinct)
multivariate distributions.
For reasons that will become clear below, it will be convenient to work with row vectors.
For each α ∈ [τ ], let
X
(α)
(i, t) =

X
(α)
1
(i, t), . . . , X
(α)
τ
(i, t)

∀i, t ≥ 1
be an array of i.i.d. Z
τ
+
-valued random row vectors with distribution {p
(α)
k
}. Let
Z0 = k0 ∈ Z
τ
+
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press334 Branching Processes
be the initial population at time 0, again as a row vector. Recursively, the population
vector
Zt = (Zt,1, . . . , Zt,τ ) ∈ Z
τ
+
at time t ≥ 1 is set to
Zt
:=
Xτ
α=1
Z
Xt−1,α
i=1
X
(α)
(i, t). (6.1.4)
In other words, the ith individual of type α at generation t−1 produces X
(α)
β
(i, t) individuals
of type β at generation t (before itself dying). Let Ft = σ(Z0, . . . ,Zt) be the corresponding
filtration. We assume throughout that P[kX
(α)
(1, 1)k1 = 1] < 1 for at least one α (which
NON- is referred to as the non-singular case); otherwise the process reduces to a simple finite
SINGULAR
CASE
Markov chain.
Martingales As in the single-type case, the means of the offspring distributions play a
MEAN MATRIX key role in the theory. This time however they form a matrix, the so-called mean matrix
M = (mα,β ) with entries
mα,β = E
h
X
(α)
β
(1, 1)i
∀α, β ∈ [τ ].
That is, mα,β is the expected number of offspring of type β of an individual of type α. We
assume throughout that mα,β < +∞ for all α, β.
To see how M drives the growth of the process, we generalize the proof of Lemma 6.1.2.
By the recursive formula (6.1.4),
E [Zt
| Ft−1] = E
"Xτ
α=1
Z
Xt−1,α
i=1
X
(α)
(i, t)





Ft−1
#
=
Xτ
α=1
Z
Xt−1,α
i=1
E

X
(α)
(i, t)

 Ft−1

=
Xτ
α=1
Zt−1,α E

X
(α)
(1, 1)
= Zt−1M, (6.1.5)
where we recall that Zt−1 and Zt are row vectors. Inductively,
E [Zt
|Z0] = Z0Mt
. (6.1.6)
Moreover, any real right eigenvector u (as a column vector) of M with real eigenvalue λ 6= 0
gives rise to a martingale
Ut
:= λ
−tZtu, t ≥ 0, (6.1.7)
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.1 Background 335
since
E[Ut
| Ft−1] = E[λ
−tZtu | Ft−1]
= λ
−t E[Zt
| Ft−1] u
= λ
−tZt−1Mu
= λ
−tZt−1λu
= Ut−1.
Extinction The classical Perron–Frobenius Theorem characterizes the direction of largest
growth of the matrix M. We state a version of it without proof in the case where all entries
of M are strictly positive, which is referred to as the positive regular case. Note that, unlike POSITIVE
REGULAR
CASE
the case of simple finite Markov chains, the matrix M is not in general stochastic, as it also
reflects the “growth” of the population in addition to the “transitions” between types. We
encountered the following concept in Section 5.2.5 and Exercise 5.5.
Definition 6.1.16 The spectral radius ρ(A) of a matrix A is the maximum of the eigenvalues SPECTRAL
of A in absolute value. RADIUS
Theorem 6.1.17 (Perron–Frobenius theorem: positive regular case). Let M be a strictly
positive, square matrix. Then ρ := ρ(M) is an eigenvalue of M with algebraic and geometric
multiplicities 1. It is also the only eigenvalue with absolute value ρ. The corresponding
left and right eigenvectors, denoted by v (as a row vector) and w (as a column vector)
respectively, are positive vectors. They are referred to as left and right Perron vector. We PERRON
assume that they are normalized so that 1w = 1 and vw = 1. Here 1 is the all-one row VECTOR
vector.
Because w is positive, the martingale
Wt
:= ρ
−tZtw, t ≥ 0
is non-negative. Therefore, it converges almost surely to a random limit with a finite mean by
Corollary 3.1.48. When ρ < 1, an argument based on Markov’s inequality (Theorem 2.1.1)
implies that the process goes extinct almost surely. Formally, let q
(α) be the probability of
extinction when started with a single individual of type α, that is,
q
(α)
:= P[Zt = 0 for some t |Z0 = eα],
where eα ∈ Z
τ
+
is the standard basis row vector with a one in the αth coordinate, and let
q := (q
(1)
, . . . , q
(τ )
). Then,
ρ < 1 =⇒ q = 1. (6.1.8)
Exercise 6.1 asks for the proof. We state the following more general result without proof.
We use the notation of Theorem 6.1.17. We will also refer to the generating functions
f
(α)
(s) := E


Yτ
β=1
s
X
(α)
β
(1,1)
β

 , s ∈ [0, 1]τ
with f = ( f
(1)
, . . . , f
(τ )
).
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press336 Branching Processes
Theorem 6.1.18 (Extinction: multitype case). Let (Z)t be a positive regular, nonsingular
multitype branching process with a finite mean matrix M.
(i) If ρ ≤ 1, then q = 1.
(ii) If ρ > 1, then:
• It holds that q < 1.
• The unique solution to f(s) = s in [0, 1)τ
is q.
• Almost surely
lim
t→+∞
ρ
−tZt = vW∞,
where W∞ is a non-negative random variable.
• If in addition Var[X
(α)
β
(1, 1)] < +∞ for all α, β then
E[W∞ |Z0 = eα] = wα
and
q
(α) = P[W∞ = 0 |Z0 = eα]
for all α ∈ [τ ].
Remark 6.1.19 As in the single-type case, a theorem of Kesten and Stigum gives a necessary
and sufficient condition for the last claim of Theorem 6.1.18 (ii) to hold [KS66b].
Linear functionals Theorem 6.1.18 also characterizes the limit behavior of linear function￾als of the form Ztu for any vector that is not orthogonal to v. In contrast, interesting new
behavior arises when u is orthogonal to v. We will not derive the general theory here. We
only show through a second moment calculation that a phase transition takes place.
We restrict ourselves to the supercritical case ρ > 1 and to u = (u1, . . . , uτ ) being a real
right eigenvector of M with a real eigenvalue λ /∈ {0, ρ}. Let Ut be the corresponding martin￾gale from (6.1.7). The vector u is necessarily orthogonal to v. Indeed, vMu is equal to both
ρvu and λvu. Because ρ 6= λ by assumption, this is only possible if all three expressions are
0. That implies vu = 0 since we also have ρ 6= 0 by assumption.
To compute the second moment of Ut
, we mimic the computations in the proof of Lemma
6.1.13. We have
E[U
2
t
|Z0] = E[U
2
t−1
|Z0] + E[(Ut − Ut−1)
2
|Z0],
by the orthogonality of increments (Lemma 3.1.50). Since E[Ut
| Ft−1] = Ut−1, by the mar￾tingale property, we get
E[(Ut − Ut−1)
2
| Ft−1] = Var[Ut
| Ft−1]
= Var[λ
−tZtu | Ft−1]
= λ
−2t Var " Xτ
α=1
Z
Xt−1,α
i=1
X
(α)
(i, t)
!
u





Ft−1
#
= λ
−2tXτ
α=1
Zt−1,α Var
X
(α)
(1, 1) u

= λ
−2tZt−1S
(u)
,
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.1 Background 337
where S
(u) = (Var[X
(1)(1, 1) u], . . . , Var[X
(τ )
(1, 1) u]) as a column vector. In the last display,
we used (6.1.4) on the third line and the independence of the random vectors X
(α)
(i, t) on the
fourth line. Hence, taking expectations and using (6.1.6), we get
E[U
2
t
|Z0] = E[U
2
t−1
|Z0] + λ
−2tZ0Mt−1S
(u)
,
and finally,
E[U
2
t
|Z0] = (Z0u)
2 +
Xt
s=1
λ
−2sZ0Ms−1S
(u)
. (6.1.9)
The case S
(u) = 0 is trivial (see Exercise 6.4), so we exclude it from the following lemma.
Lemma 6.1.20 (Second moment of Ut). Assume S
(u) 6= 0 and Z0 6= 0. The sequence
E[U
2
t
|Z0], t = 0, 1, 2, . . ., is non-decreasing and satisfies
sup
t≥0
E[U
2
t
|Z0]
(
< +∞ if ρ < λ2
,
= +∞ otherwise.
Proof Because S
(u) 6= 0 and non-negative and the matrix M is strictly positive by assump￾tion, we have that
eS
(u)
:= MS
(u) > 0.
Since w is also strictly positive, there is 0 < C
− ≤ C
+ < +∞ such that
C
−w ≤ eS
(u) ≤ C
+w.
Moreover, since M is positive, each inequality is preserved when multiplying on both sides
by M, that is, for any s ≥ 1,
C
−
ρ
sw ≤ MseS
(u) ≤ C
+
ρ
sw. (6.1.10)
Now rewrite (6.1.9) as
E[U
2
t
|Z0] = (Z0u)
2 + λ
−2Z0S
(u) + λ
−4Xt
s=2
Z0(1/λ2
)
s−2Ms−2eS
(u)
.
There are two cases:
• When ρ < λ2
, using (6.1.10), the sum on the right-hand side can be bounded above by
C
+Z0w
Xt
s=2
 ρ
λ
2
s−2
≤ C
+Z0w
1
1 − (ρ/λ2
)
< +∞
uniformly in t.
• When ρ ≥ λ
2
, the same sum can be bounded from below by
C
−Z0w
Xt
s=2
 ρ
λ
2
s−2
→ +∞
as t → +∞. Indeed, Z0 6= 0 implies that the inner product Z0w is strictly positive.
That proves the claim.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press338 Branching Processes
In the case ρ < λ2
, the martingale (Ut) is bounded in L
2
and therefore converges al￾most surely to a limit U∞ with E[U∞ |Z0] = Z0u by Theorem 3.1.51. On the other hand,
when ρ ≥ λ
2
, it can be shown (we will not do this here) that Ztu/
√
Ztw satisfies a central
limit theorem with a limit independent of Z0. Implications of these claims are illustrated in
Section 6.3.2.
6.2 Random-Walk Representation
In this section, we develop a random-walk representation of the Galton–Watson process. We
give two applications: a characterization of the Galton–Watson process conditioned on ex￾tinction in terms of a dual branching process, and a formula for the size of the total progeny.
We illustrate both in Section 6.2.4, where we revisit percolation on the infinite b-ary tree.
6.2.1 Exploration Process
We introduce an exploration process where a random-walk perspective will naturally arise.
Exploration of a graph
Because this will be useful again later, we describe it first in the context of a locally finite
graph G = (V, E). The exploration process starts at an arbitrary vertex v ∈ V and has three
ACTIVE types of vertices:
EXPLORED
NEUTRAL • At
: active vertices,
• Et
: explored vertices,
• Nt
: neutral vertices.
At the beginning, we have A0 := {v}, E0 := ∅, and N0 contains all other vertices in G. At
time t, if At−1 = ∅ (i.e., there are no active vertices), we let (At
, Et
, Nt) := (At−1, Et−1, Nt−1).
Otherwise, we pick an element, at
, from At−1 (say in first-come, first-served basis to be ex￾plicit) and set:
• At
:= (At−1\{at}) ∪ {x ∈ Nt−1 : {x, at} ∈ E},
• Et
:= Et−1 ∪ {at},
• Nt
:= Nt−1\{x ∈ Nt−1 : {x, at} ∈ E}.
We imagine revealing the edges of G as they are encountered in the exploration process. In
words, starting with v, the connected component Cv of v is progressively grown by adding to
it at each time a vertex adjacent to one of the previously explored vertices and uncovering
its remaining neighbors in G. In this process, Et
is the set of previously explored vertices
and At – the frontier of the process – is the set of vertices that are known to belong to Cv but
whose full neighborhood is waiting to be uncovered. The rest of the vertices form the set Nt
.
See Figure 6.3.
Let At
:= |At
|, Et
:= |Et
|, and Nt
:= |Nt
|. Note that (Et) – not to be confused with the
edge set – is non-decreasing, while (Nt) is non-increasing. Let
τ0 := inf{t ≥ 0: At = 0}
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.2 Random-Walk Representation 339
Figure 6.3 Exploration process for Cv.
be the first time At
is 0 (which by convention is +∞ if there is no such t). The process is
fixed for all t > τ0. Notice that Et = t for all t ≤ τ0, as exactly one vertex is explored at each
time until the set of active vertices is empty. The size of the connected component of v can
be characterized as follows.
Lemma 6.2.1
τ0 = |Cv
|.
Proof Indeed, a single vertex of Cv
is explored at each time until all of Cv has been visited.
At that point, At
is empty.
Random-walk representation of a Galton–Watson tree
Let (Zi)i≥0 be a Galton–Watson branching process and let T be the corresponding Galton–
Watson tree. We run the exploration process above on T started at the root 0. We will refer
to the index i in Zi as a “generation,” and to the index t in the exploration process as “time” –
they are not the same. Let (At
, Et
, Nt) and At
:= |At
|, Et
:= |Et
|, and Nt
:= |Nt
| be as above.
Let (Ft) be the corresponding filtration. Because we explore the vertices on first-come, first￾served basis, we exhaust all vertices in generation i before considering vertices in generation
i + 1 (i.e., we perform breadth-first search).
The random-walk representation is the following. Observe that the process (At) admits a
simple recursive form. We start with A0 := 1. Then, conditioning on Ft−1:
• If At−1 = 0, the exploration process has finished its course and At = 0.
• Otherwise, (a) one active vertex becomes an explored vertex and (b) its offspring become
active vertices. That is,
At =



At−1 +
￾
−1
|{z}
(a)
+ Xt
|{z}
(b)

if t − 1 < τ0,
0 otherwise,
where Xt
is distributed according to the offspring distribution.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Pres340 Branching Processes
We let Yt
:= Xt − 1 and
St
:= 1 +
Xt
s=1
Ys
,
with S0 := 1. Then,
τ0 = inf{t ≥ 0: St = 0},
and
(At) = (St∧τ0
)
is a random walk started at 1 with i.i.d. increments (Yt) stopped when it hits 0 for the first
time.
We refer to
H = (X1, . . . , Xτ0
)
HISTORY as the history of the process (Zi). Observe that, under breadth-first search, the process (Zi)
can be reconstructed from H: Z0 = 1, Z1 = X1, Z2 = X2 + . . . + XZ1+1, and so forth.
(Exercise 6.5 asks for a general formula.) As a result, (Zi) can be recovered from (St) as
VALID well. We call (x1, . . . , xt) a valid history if
HISTORY
1 + (x1 − 1) + · · · + (xs − 1) > 0
for all s < t and
1 + (x1 − 1) + · · · + (xt − 1) = 0.
Note that a valid history may have probability 0 under the offspring distribution.
6.2.2 Duality Principle
The random-walk representation above is useful to prove the following duality principle.
Theorem 6.2.2 (Duality principle). Let (Zi) be a branching process with offspring distribu￾tion {pk }k≥0 and extinction probability η < 1. Let (Z
0
i
) be a branching process with offspring
distribution {p
0
k
}k≥0 where
p
0
k = η
k−1
pk
.
Then, (Zi) conditioned on extinction has the same distribution as (Z
0
i
), which is referred to
DUAL as the dual branching process.
BRANCHING
PROCESS Let f be the probability generating function of the offspring distribution of (Zi). Note that
X
k≥0
p
0
k =
X
k≥0
η
k−1
pk = η
−1
f (η) = 1,
because η is a fixed point of f by Theorem 6.1.6. So {p
0
k
}k≥0 is indeed a probability distribu￾tion. Note further that its expectation is
X
k≥0
kp0
k =
X
k≥0
kη
k−1
pk = f
0
(η) < 1,
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.2 Random-Walk Representation 341
since, by Lemma 6.1.7, f
0
is strictly increasing, f (η) = η < 1 and f (1) = 1 (which would
not be possible if f
0
(η) were greater or equal to 1; see Figure 6.1 for an illustration). So the
dual branching process is subcritical.
Proof of Theorem 6.2.2 We use the random-walk representation. Let H = (X1, . . . , Xτ0
)
and H
0 = (X
0
1
, . . . , X
0
τ
0
0
) be the histories of (Zi) and (Z
0
i
), respectively. In the case of extinction
of (Zi), the history H has finite length.
By definition of the conditional probability, for a valid history (x1, . . . , xt) with a finite t,
P[H = (x1, . . . , xt) | τ0 < +∞] =
P[H = (x1, . . . , xt)]
P[τ0 < +∞]
= η
−1 Yt
s=1
pxs
.
Because (x1 − 1) + · · · + (xt − 1) = −1,
η
−1 Yt
s=1
pxs = η
−1 Yt
s=1
η
1−xsp
0
xs =
Yt
s=1
p
0
xs = P[H
0 = (x1, . . . , xt)].
Since this is true for all valid histories and the processes can be recovered from their histo￾ries, we have proved the claim.
Example 6.2.3 (Poisson branching process). Let (Zi) be a Galton–Watson branching process
with offspring distribution Poi(λ) where λ > 1. Then, the dual probability distribution is
given by
p
0
k = η
k−1
pk = η
k−1
e
−λ
λ
k
k!
= η
−1
e
−λ
(λη)
k
k!
,
where recall from Example 6.1.10 that e
−λ(1−η) = η, so
p
0
k = e
λ(1−η)
e
−λ
(λη)
k
k!
= e
−λη (λη)
k
k!
.
That is, the dual branching process has offspring distribution Poi(λη). J
6.2.3 Hitting-Time Theorem
The random-walk representation also gives a formula for the distribution of the size of the
progeny.
Law of total progeny The key is the following claim.
Lemma 6.2.4 (Total progeny and random-walk representation). Let W be the total progeny
of the Galton–Watson branching process (Zi). Then,
W = τ0.
Proof Recall that
τ0 := inf{t ≥ 0 : At = 0}.
If the process does not go extinct, then τ0 = +∞ as there are always more vertices to
explore.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press342 Branching Processes
Suppose the process goes extinct and that W = n. Notice that Et = t for all t ≤ τ0, as
exactly one vertex is explored at each time until the set of active vertices is empty. Moreover,
for all t, (At
, Et
, Nt) forms a partition of [n], so
At + t + Nt = n ∀t ≤ τ0.
At t = τ0, At = Nt = 0 and we get
τ0 = n.
That proves the claim.
To compute the distribution of W = τ0, we use the following hitting-time theorem, which
is proved later in this subsection.
Theorem 6.2.5 (Hitting-time theorem). Let (Rt) be a random walk started at 0 with i.i.d. in￾crements (Ut) satisfying
P[Ut ≤ 1] = 1.
Fix a positive integer `. Let σ` be the first time t such that Rt = `. Then,
P[σ` = t] =
`
t
P[Rt = `].
Finally we get:
Theorem 6.2.6 (Law of total progeny). Let (Zt) be a Galton–Watson branching process with
total progeny W. In the random-walk representation of (Zt),
P[W = t] =
1
t
P[X1 + · · · + Xt = t − 1]
for all t ≥ 1.
Proof Recall that Yt
:= Xt − 1 ≥ −1 and
St = 1 +
Xt
s=1
Ys
,
with S0 = 1, and that
τ0 = inf{t ≥ 0: St = 0}
= inf{t ≥ 0: 1 + (X1 − 1) + · · · + (Xt − 1) = 0}
= inf{t ≥ 0: X1 + · · · + Xt = t − 1}.
Define Rt
:= 1 − St and Ut
:= −Yt for all t. Then R0 := 0,
{X1 + · · · + Xt = t − 1} = {Rt = 1},
and
τ0 = inf{t ≥ 0: Rt = 1}.
The process (Rt) satisfies the assumptions of the hitting-time theorem (Theorem 6.2.5) with
` = 1 and σ` = τ0 = W. Applying the theorem gives the claim.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.2 Random-Walk Representation 343
Example 6.2.7 (Poisson branching process (continued)). Let (Zi) be a Galton–Watson branch￾ing process with offspring distribution Poi(λ) where λ > 0. Let W be its total progeny. By
the hitting-time theorem, for t ≥ 1,
P[W = t] =
1
t
P[X1 + · · · + Xt = t − 1]
=
1
t
e
−λt
(λt)
t−1
(t − 1)!
= e
−λt
(λt)
t−1
t!
,
where we used that a sum of independent Poisson is Poisson. J
Spitzer’s combinatorial lemma Before proving the hitting-time theorem, we begin with
a combinatorial lemma of independent interest. Let u1, . . . , ut ∈ R and define r0 := 0 and
rj
:= u1 + · · · + uj for 1 ≤ j ≤ t. We say that j is a ladder index if rj > r0 ∨ · · · ∨ rj−1.
Consider the cyclic permutations of u = (u1, . . . , ut), that is, u
(0) = u, u
(1) = (u2, . . . , ut
, u1),
. . . , u
(t−1) = (ut
, u1, . . . , ut−1). Define the corresponding partial sums r
(β)
j
:= u
(β)
1 +· · ·+u
(β)
j
for j = 1, . . . , t and β = 0, . . . , t − 1.
Lemma 6.2.8 (Spitzer’s combinatorial lemma). Assume rt > 0. Let ` be the number of cyclic
permutations such that t is a ladder index. Then ` ≥ 1 and each such cyclic permutation has
exactly ` ladder indices.
Proof We will need the following observation:
(r
(β)
1
, . . . ,r
(β)
t
)
= (rβ+1 − rβ ,rβ+2 − rβ , . . . ,rt − rβ ,
[rt − rβ ] + r1, [rt − rβ ] + r2, . . . , [rt − rβ ] + rβ )
= (rβ+1 − rβ ,rβ+2 − rβ , . . . ,rt − rβ ,
rt − [rβ − r1],rt − [rβ − r2], . . . ,rt − [rβ − rβ−1],rt). (6.2.1)
We first show that ` ≥ 1, that is, there is at least one cyclic permutation where t is a ladder
index. Let β ≥ 1 be the smallest index achieving the maximum of r1, . . . ,rt
, that is,
rβ > r1 ∨ · · · ∨ rβ−1 and rβ ≥ rβ+1 ∨ · · · ∨ rt
.
Moreover, rt > 0 = r0 by assumption. Hence,
rβ+j − rβ ≤ 0 < rt ∀j = 1, . . . , t − β
and
rt − [rβ − rj] < rt ∀j = 1, . . . , β − 1.
From (6.2.1), in u
(β)
, t is a ladder index.
For the second claim, since ` ≥ 1, we can assume without loss of generality that u is such
that t is a ladder index. (Note that r
(β)
t = rt for all β.) We show that β is a ladder index in u if
and only if t is a ladder index in u
(β)
. That does indeed imply the claim as there are ` cyclic
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press344 Branching Processes
permutations where t is a ladder index by assumption. We use (6.2.1) again. Observe that β
is a ladder index in u if and only if
rβ > r0 ∨ · · · ∨ rβ−1,
which holds if and only if
rβ > r0 = 0 and rt − [rβ − rj] < rt ∀j = 1, . . . , β − 1. (6.2.2)
Moreover, because rt > rj for all j by the assumption that t is ladder index, the last display
holds if and only if
rβ+j − rβ < rt ∀j = 1, . . . , t − β (6.2.3)
and
rt − [rβ − rj] < rt
, ∀j = 1, . . . , β − 1, (6.2.4)
that is, if and only if t is a ladder index in u
(β) by (6.2.1). Indeed, the second condition
(i.e., (6.2.4)) is intact from (6.2.2), while the first one (i.e., (6.2.3)) can be rewritten as rβ >
−(rt−rβ+j), where the right-hand side is < 0 for j = 1, . . . , t−β−1 and = 0 for j = t−β.
Proof of hitting-time theorem We are now ready to prove the hitting-time theorem. We
only handle the case ` = 1 (which is the one we used for the law of the total progeny).
Exercise 6.6 asks for the full proof.
Proof of Theorem 6.2.5 Recall that Rt =
Pt
s=1 Us and σ1 = inf{j ≥ 0: Rj = 1}. By the
assumption that Us ≤ 1 almost surely for all s,
{σ1 = t} = {t is the first ladder index in R1, . . . , Rt}.
By symmetry, for all β = 0, . . . , t − 1,
P[t is the first ladder index in R1, . . . , Rt]
= P[t is the first ladder index in R
(β)
1
, . . . , R
(β)
t
].
Let Eβ be the event on the last line. Then,
P[σ1 = t] = E[1E0
] =
1
t
E


Xt−1
β=0
1Eβ

 .
By Spitzer’s combinatorial lemma (Lemma 6.2.8), there is at most one cyclic permutation
where t is the first ladder index. (There is at least one cyclic permutation where t is a ladder
index – but it may not be the first one, that is, there may be multiple ladder indices.) In
particular, Pt−1
β=0
1Eβ ∈ {0, 1}. So, by the previous display,
P[σ1 = t] =
1
t
P

∪
t−1
β=0Eβ

.
Finally, we claim that {Rt = 1} = ∪t−1
β=0Eβ . Indeed, because R0 = 0 and Us ≤ 1 for all
s, the partial sum at the jth ladder index must take value j. So the event ∪
t−1
β=0Eβ implies
{Rt = 1} since the last partial sum of all cyclic permutations is Rt
. Similarly, because there is
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.2 Random-Walk Representation 345
at least one cyclic permutation such that t is a ladder index, the event {Rt = 1} implies that
t is in fact the first ladder index in that cyclic permutation, and therefore it implies ∪
t
β=1Eβ .
Hence,
P[σ1 = t] =
1
t
P [Rt = 1] ,
which concludes the proof (for the case ` = 1).
6.2.4 F Percolation: Critical Exponents on the Infinite b-ary Tree
In this section, we use branching processes to study bond percolation (Definition 1.2.1) on
the infinite b-ary tree bTb and derive explicit expressions for quantities of interest. Close
to the critical value, we prove the existence of “critical exponents.” We illustrate the use of
both the duality principle (Theorem 6.2.2) and the hitting-time theorem (Theorem 6.2.6).
Critical value We denote the root by 0. Similarly to what we did in Section 6.1.3, we think
of the open cluster of the root, C0, as the progeny of a branching process as follows. Denote
by ∂n the nth level of bTb, that is, the vertices of bTb at graph distance n from the root. In the
branching process interpretation, we think of the immediate descendants in C0 of a vertex v
as the offspring of v. By construction, v has at most b children, independently of all other
vertices in the same generation. In this branching process, the offspring distribution {qk }
b
k=0
is binomial with parameters b and p; Zn := |C0 ∩ ∂n| represents the size of the progeny at
generation n; and W := |C0| is the total progeny of the process. In particular, |C0| < +∞
if and only if the process goes extinct. Because the mean number of offspring is bp, by
Theorem 6.1.6, this leads immediately to a second proof of (a rooted variant of) Claim
2.3.9:
Claim 6.2.9
pc
￾
bTb

=
1
b
.
Percolation function The generating function of the offspring distribution is φ(s) := ((1 −
p) + ps)
b
. So, by Theorems 6.1.5 and 6.1.6, the percolation function
θ(p) = Pp[|C0| = +∞]
is 0 on [0, 1/b], while on (1/b, 1] the quantity η(p) := 1 − θ(p) is the unique solution in
[0, 1) of the fixed point equation
s = ((1 − p) + ps)
b
. (6.2.5)
For b = 2, for instance, we can compute the fixed point explicitly by noting that
0 = ((1 − p) + ps)
2 − s
= p
2
s
2 + [2p(1 − p) − 1]s + (1 − p)
2
,
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Pres346 Branching Processes
whose solution for p ∈ (1/2, 1] is
s
∗ =
−[2p(1 − p) − 1] ±
p
[2p(1 − p) − 1]2 − 4p
2
(1 − p)
2
2p
2
=
−[2p(1 − p) − 1] ±
√
1 − 4p(1 − p)
2p
2
=
−[2p(1 − p) − 1] ± (2p − 1)
2p
2
=
2p
2 + [(1 − 2p) ± (2p − 1)]
2p
2
.
So, rejecting the fixed point 1,
θ(p) = 1 −
2p
2 + 2(1 − 2p)
2p
2
=
2p − 1
p
2
.
We have proved:
Claim 6.2.10 For b = 2,
θ(p) =
(
0, 0 ≤ p ≤
1
2
,
2(p−
1
2
)
p
2
,
1
2 < p ≤ 1.
Since η(p) = (1 − θ(p)), we have in that case
η(p) =
(
1, 0 ≤ p ≤
1
2
,
(1−p)
2
p
2
,
1
2 < p ≤ 1.
Conditioning on a finite cluster The expected size of the population at generation n is
(bp)
n by Lemma 6.1.2, so for p ∈ [0, 1
b
),
Ep|C0| = X
n≥0
(bp)
n =
1
1 − bp
. (6.2.6)
For p ∈ (
1
b
, 1), the total progeny is infinite with positive probability (and in particular the
expectation is infinite), but we can compute the expected cluster size on the event that
|C0| < +∞. For this purpose we use the duality principle.
Recall that qk =
￾
b
k

p
k
(1−p)
b−k
, k = 0, . . . , b, is the offspring distribution. For 0 ≤ k ≤ b,
we let the dual offspring distribution be
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Pres6.2 Random-Walk Representation 347
qˆ k
:= [η(p)]k−1
qk
= [η(p)]k−1

b
k

p
k
(1 − p)
b−k
=
[η(p)]k
((1 − p) + p η(p))b

b
k

p
k
(1 − p)
b−k
=

b
k
  p η(p)
(1 − p) + p η(p)
k 
1 − p
(1 − p) + p η(p)
b−k
=:

b
k

pˆ
k
￾
1 − ˆp
b−k
,
where we used (6.2.5) and implicitly defined the dual density
pˆ :=
p η(p)
(1 − p) + p η(p)
. (6.2.7)
In particular, { ˆqk } is a probability distribution as expected under Theorem 6.2.2 – it is in fact
binomial with parameters b and pˆ. Summarizing the implications of Theorem 6.2.2:
Claim 6.2.11 Conditioned on |C0| < +∞, (supercritical) percolation on bTb with density
p ∈ (
1
b
, 1) has the same distribution as (subcritical) percolation on bTb with density defined
by (6.2.7).
Hence, using (6.2.6) with both p and pˆ as well as the fact that Pp[|C0| < +∞] = η(p), we
have the following.
Claim 6.2.12
χ
f
(p) := Ep

|C0|1{|C0|<+∞}
=
(
1
1−bp , p ∈ [0, 1
b
),
η(p)
1−bpˆ
, p ∈ (
1
b
, 1).
For b = 2, η(p) = 1 − θ(p) =

1−p
p
2
so
pˆ =
p

1−p
p
2
(1 − p) + p

1−p
p
2 =
(1 − p)
2
p(1 − p) + (1 − p)
2
= 1 − p,
and
Claim 6.2.13 For b = 2,
χ
f
(p) =



1/2
1
2 −p
, p ∈ [0, 1
2
),
1
2

1−p
p
2
p−
1
2
, p ∈ (
1
2
, 1).
Distribution of the open cluster size In fact, the hitting-time theorem gives an explicit
formula for the distribution of |C0|. Namely, recall that |C0|
d= τ0, where
τ0 = inf{t ≥ 0: St = 0}
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Pres348 Branching Processes
for St =
P
`≤t X` − (t − 1), where S0 = 1 and the X`s are i.i.d. binomial with parameters b
and p. By Theorem 6.2.6,
P[τ0 = t] =
1
t
P[St = 0],
and we have
Pp[|C0| = `] =
1
`
P
"X
i≤`
X` = ` − 1
#
=
1
`

b`
` − 1

p
`−1
(1 − p)
b`−(`−1), (6.2.8)
where we used that a sum of independent binomials with the same p is itself binomial. In
particular, at criticality (where |C0| < +∞ almost surely; see Claim 3.1.52), using Stirling’s
formula (see Appendix A) it can be checked that
Ppc
[|C0| = `] ∼
1
`
1
√
2πpc(1 − pc)b`
=
1
p
2π(1 − pc)`
3
as ` → +∞.
Critical exponents Close to criticality, physicists predict that many quantities behave ac￾cording to power laws of the form |p − pc
|
β
, where the exponent is referred to as a critical
CRITICAL exponent. The critical exponents are believed to satisfy certain “universality” properties. But
EXPONENT even proving the existence of such exponents in general remains a major open problem. On
trees, though, we can simply read off the critical exponents from the above formulas. For
b = 2, Claims 6.2.10 and 6.2.13 imply for instance that as p → pc
,
θ(p) ∼ 8(p − pc)1{p>1/2}
and
χ
f
(p) ∼
1
2
|p − pc
|
−1
.
In fact, as can be seen from Claim 6.2.12, the critical exponent of χ
f
(p) does not depend on
b. The same holds for θ(p) (see Exercise 6.9). Using (6.2.8), the higher moments of |C0| can
also be studied around criticality (see Exercise 6.10).
6.3 Applications
We develop two applications of branching processes in discrete probability. First, we prove
a result about the height of a random binary search tree. Then we describe a phase transition
in an Ising model on a tree with applications to evolutionary biology. In the next section, we
also use branching processes to study the phase transition of an Erdos–Rényi random graph ˝
model.
6.3.1 F Probabilistic Analysis of Algorithms: Binary Search Tree
BINARY A binary search tree is a commonly used data structure in computer science. It consists of
SEARCH TREE a rooted binary tree Tn = (Vn, En). Each vertex has a “left” and “right” subtree (possibly
empty) and a “key” from an input sequence x1, . . . , xn ∈ R (which we assume are distinct)
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.3 Applications 349
that satisfies the BST property: the key at vertex v ∈ V is greater than all keys in the left
subtree below it and less than all keys in the right subtree below it. Such a data structure can
be used for a variety of algorithmic tasks, such as searching for keys or sorting them.
The tree is constructed recursively as follows. Assume that the keys x1, . . . , xi have already
been inserted and that the current tree Ti satisfies the BST property. To insert xi+1,
• start at the root;
• if the root’s key is strictly larger than xi+1, then move to its left descendant, otherwise
move to its right descendant;
• if such a descendant does not exist, then create it and assign it xi+1 as its key;
• otherwise repeat.
Inserting keys (and other operations such as deleting keys, which we do not describe) takes
time proportional to the height Hn of the tree Tn, that is, the length of the longest path from
the root to a leaf. While, in general, the height can be as large as n (if keys are inserted in
order for instance), the typical behavior can be much smaller.
Indeed, here we study the case of n keys X1, . . . , Xn i.i.d. from a continuous distribution on
R and establish a much better behavior for the random height. Let γ be the unique solution
greater than 1 of

1
e
 2e
γ
γ
= 1. (6.3.1)
See Exercise 6.14 for a proof that γ is well defined and that the left-hand side is strictly
decreasing at γ . We show:
Claim 6.3.1 Hn/ log n →p γ as n → ∞.
Alternative representation of the height
The main idea of the proof is to relate the height Hn of the tree Tn to a product of independent
uniform random variables. We make a series of observations about the structure of the tree.
First:
Observation 1 Keys affect the construction of the binary search tree only through their ordering. Let σ be
the corresponding (random) permutation, that is,
Xσ(1) < Xσ(2) < · · · < Xσ(n)
.
Let t[σ] be the binary search tree generated by the permutation σ.
Second, by symmetry:
Observation 2 The permutation σ is uniformly distributed.
Denote by Sv
the size of the subtree rooted at v (including v itself) in t[σ]. At the root ρ, we
have Sρ = n. What is the size of the subtree rooted at the left descendant ρ
0 of ρ? Eventually
all keys with a rank lower than σ
−1
(1), that is, those keys with indices in 
σ(i): i < σ −1
(1)	
,
find their way into the left subtree of the root. In other words,
Sρ
0 = σ
−1
(1) − 1.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press350 Branching Processes
Similarly, denoting by ρ
00 the right descendant of ρ, we see that
Sρ
00 = n − σ
−1
(1).
We refer to σ
−1
(1) as the rank of the root. By Observation 2:
Observation 3 The rank σ
−1
(1) of the root is uniformly distributed in [n]. Moreover, it is identically
distributed to bSρWρc + 1, where Wρ is uniform in [0, 1].
The second part of this last observation can be checked by direct computation. Rename
X
0
1
, . . . , X
0
Sρ
0
the keys in the subtree rooted at ρ
0
in the order that they are inserted and let σ
0
be the (random) permutation corresponding to their ordering, that is,
X
0
σ
0
(1) < X
0
σ
0
(2) < · · · < X
0
σ
0
(Sρ
0)
.
Define σ
00 similarly for ρ
00. Again by symmetry:
Observation 4 Conditioned on σ
−1
(1) (and therefore on Sρ
0 and Sρ
00), the permutations σ
0
and σ
00 are
independent and uniformly distributed.
Finally, recursively:
Observation 5 The binary search tree t[σ] is obtained by appending the left subtree t[σ
0
] and right subtree
t[σ
00] to the root ρ.
If Sρ
0 = 0, then t[σ
0
] = ∅ (and there is in fact no ρ
0
); while, if Sρ
0 = 1, the tree t[σ
0
] is com￾prised of the single vertex ρ
0
. Similarly for σ
00. Hence, this recursive process stops whenever
we reach a vertex v with Sv ∈ {0, 1}. But it will be convenient to extend it indefinitely to
produce an infinite binary tree T = bT2, where all additional vertices v are assigned Sv = 0.
The upshot of all these observations is that we obtain the following alternative character￾ization of the height Hn:
• assign an independent U[0, 1] (i.e., uniform in [0, 1]) random variable Wv
to each vertex
v in the infinite binary tree T ;
• at the root ρ, set
Sρ = n;
• then recursively from the root down, set
Sv
0 := bSvWvc and Sv
00 := bSv(1 − Wv)c, (6.3.2)
where v
0
and v
00 are the left and right descendants of v in T .
It can be checked that Sv
0 + Sv
00 = Sv − 1 almost surely, provided Sv ≥ 1 (see Exercise 6.15).
Moreover, notice that when Sv = 1, then Sv
0 = Sv
00 = 0 almost surely; while if Sv = 0, then
Sv
0 = Sv
00 = 0. Finally, the height Hn is the highest level containing a vertex with subtree size
at least 1, that is,
Hn = sup {h: ∃v ∈ Lh, Sv ≥ 1}, (6.3.3)
where Lh is the set of vertices of T at graph distance h from the root.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.3 Applications 351
Key technical bound
Because W ∼ U[0, 1] implies also that (1 − W) ∼ U[0, 1], we immediately get from (6.3.2)
that:
Lemma 6.3.2 (Distribution of subtree size). Let v be a vertex at topological distance ` from
the root of T . Let U1, . . . , U` be i.i.d. U[0, 1]. Then we have the equality in distribution
Sv
d= b· · · bbnU1cU2c · · · U`c.
From Lemma 6.3.2 and the characterization of the height in (6.3.3), we need to control
how fast products of independent uniforms decrease. But that is only half of the story: the
number of paths of length ` from the root grows exponentially with `. The following lemma,
which takes both effects into account, will play a key role in the analysis. It also explains the
definition of γ in (6.3.1). Note that we ignore – for the time being – the repeated rounding
in Lemma 6.3.2; it will turn out to have a minor effect.
Lemma 6.3.3 (Product of uniforms). Let U1, U2, . . . be i.i.d. U[0, 1]. Then
lim
`→+∞
2
` P

U1 · · · U` ≥ e
−`/c

=
(
+∞ if c < γ ,
0 if c > γ .
Proof Taking logarithms turns the product on the left-hand side into a sum of i.i.d. random
variables
2
` P

U1 · · · U` ≥ e
−`/c

= 2
` P
"X
`
i=1
(− log Ui) ≤ `/c
#
. (6.3.4)
Now it is elementary to bound the right-hand side.
Lemma 6.3.4 (A tail bound). Let U1, . . . , U` be i.i.d. U[0, 1]. Then, for any y > 0,
y
`
e
−y
`!
≤ P
"X
`
i=1
(− log Ui) ≤ y
#
≤
y
`
e
−y
`!
 
1
1 −
y
`+1
!
. (6.3.5)
Proof We prove a more general claim, specifically
P
"X
`
i=1
(− log Ui) ≤ y
#
= e
−y
(X
+∞
i=`
y
i
i!
)
,
from which (6.3.5) follows: the lower bound is obtained by keeping only the first term in the
sum; the upper bound is obtained by factoring out y
`
e
−y
/`! and relating the remaining sum
to a geometric series.
So it remains to prove the general claim. First note that − log U1 is exponentially distrib￾uted. Indeed, for any y ≥ 0,
P [− log U1 > y] = P

U1 < e
−y

= e
−y
.
So
P [− log U1 ≤ y] = 1 − e
−y = e
−y
(X
+∞
i=0
y
i
i!
− 1
)
= e
−y
(X
+∞
i=1
y
i
i!
)
,
as claimed in the base case ` = 1.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press352 Branching Processes
Proceeding by induction, suppose the claim holds up to ` − 1. Then,
P
"X
`
i=1
(− log Ui) > y
#
=
Z +∞
0
e
−z P
"X
`−1
i=1
(− log Ui) > y − z
#
dz
= e
−y +
Z y
0
e
−z P
"X
`−1
i=1
(− log Ui) > y − z
#
dz
= e
−y +
Z y
0
e
−z
e
−(y−z)
(X
`−2
i=0
(y − z)
i
i!
)
dz
= e
−y + e
−yX
`−2
i=0
y
i+1
i!(i + 1)
= e
−yX
`−1
j=0
y
j
j!
.
That proves the claim.
We return to the proof of Lemma 6.3.3. Plugging (6.3.5) into (6.3.4), we get
2
`
(`/c)
`
e
−(`/c)
`!
≤ 2
` P

U1 · · · U` ≥ e
−`/c

≤
2
`
(`/c)
`
e
−(`/c)
`!
 
1
1 −
(`/c)
`+1
!
. (6.3.6)
As ` → +∞,
1
1 −
(`/c)
`+1
→
1
1 −
1
c
, (6.3.7)
which is positive when c > 1. We will use the standard bound (see Exercise 1.3 for a proof)
`
`
e
`−1
≤ `! ≤
`
`+1
e
`−1
.
It implies immediately that
2
`
(`/c)
`
e
−(`/c)
e
`−1
`
`+1
≤
2
`
(`/c)
`
e
−(`/c)
`!
≤
2
`
(`/c)
`
e
−(`/c)
e
`−1
`
`
,
which after simplifying gives
(e`)
−1
1
e
 2e
c
c`/c
≤ 2
`
(`/c)
`
e
−(`/c)
`!
≤ e
−1
1
e
 2e
c
c`/c
. (6.3.8)
By (6.3.1) and the remark following it, the expression in square brackets is > 1 or < 1
depending on whether c < γ or c > γ . Combining (6.3.6), (6.3.7), and (6.3.8) and taking a
limit as ` → +∞ gives the claim.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.3 Applications 353
As an immediate consequence of Lemma 6.3.3, we bound the height from above. Fix any
ε > 0 and let h := (γ + ε) log n. We use a union bound as follows:
P [Hn ≥ h] = P
"[
v∈Lh
{Sv ≥ 1}
#
≤
X
v∈Lh
P [Sv ≥ 1] = 2
h P [Sv ≥ 1] (6.3.9)
for any v ∈ Lh, where the first equality follows from (6.3.3). Since
b· · · bbnU1cU2c · · · Uhc ≤ nU1U2 · · · Uh,
Lemmas 6.3.2 and 6.3.3 imply that
2
h P [Sv ≥ 1] ≤ 2
h P [nU1U2 · · · Uh ≥ 1]
= 2
h P

U1U2 · · · Uh ≥ e
−h/(γ +ε)

→ 0 (6.3.10)
as h → +∞. From (6.3.9) and (6.3.10), we obtain finally that for any ε > 0,
P [Hn/ log n ≥ γ + ε] → 0
as n → +∞, which establishes one direction of Claim 6.3.1.
Lower bounding the height: a branching process
Establishing the other direction is where branching processes enter the scene. We will need
some additional notation. Fix c < γ and let ` be a positive integer that will be set later on.
For any pair of vertex v,w ∈ T with w a descendant of v, let Q[v,w] be the set of vertices
on the path between v and w, including v but excluding w. Further, recalling (6.3.2), define
U[v,w] =
Y
z∈Q[u,v]
U
v,w
z
,
where U
v,w
z = Wz (respectively 1 − Wz) if the path from v to w takes the left (respectively
right) edge upon exiting z. Denote by L`[v] the set of descendant vertices of v in T at graph
distance ` from v and consider the random subset
L
∗
`
[v] =

w ∈ L`[v]: U[v,w] ≥ e
−`/c
	
.
Fix a vertex u ∈ T . We define the following Galton–Watson branching process.
• Initialize Z
u,`
0
:= 1 and u0,1 := u.
• For t ≥ 1, set
Z
u,`
t =
Z
u,` Xt−1
r=1

L
∗
`
[ut−1,r]


,
and let ut,1, . . . , ut,Z
u,`
t
be the vertices in ∪
Z
u,`
t−1
r=1L
∗
`
[ut−1,r] from left to right.
In other words, Z
u,`
1
counts the number of vertices ` levels below u whose subtree sizes
(ignoring rounding) have not decreased “too much” compared to that of u (in the sense of
Lemma 6.3.3). We let such vertices (if any) be u1,1, . . . , u1,Z
u,`
1
. Similarly, Z
u,`
2
counts the same
quantity over all vertices ` levels below the vertices u1,1, . . . , u1,Z
u,`
1
, and so forth.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press354 Branching Processes
Because the Wvs are i.i.d., this process is indeed a Galton–Watson branching process. The
expectation of the offspring distribution (which by symmetry does not depend on the choice
of u) is
m = E
h
Z
u,`
1
i
= 2
` P

U1 · · · U` ≥ e
−`/c

,
where we used the notation of Lemma 6.3.3. By that lemma, we can choose ` large enough
that m > 1. Fix such an ` for the rest of the proof. In that case, by Theorem 6.1.6, the process
survives with probability 1 − η for some 0 ≤ η < 1.
The relevance of this observation can be seen from taking u = ρ.
Claim 6.3.5 Let c0 < c. Conditioned on survival of (Z
ρ,`
t
), for n large enough Hn ≥ c
0
log n − θn`
almost surely for some θn ∈ [0, 1).
Proof To account for the rounding, we will need the inequality
b· · · bbnU1cU2c · · · Usc ≥ nU1U2 · · · Us − s, (6.3.11)
which holds for all n,s ≥ 1, as can be checked by induction. Write s = k` for some positive
integer k to be determined. Conditioned on survival of (Z
ρ,`
t
), the population at generation k
satisfies
Z
ρ,`
k ≥ 1,
which implies that, for some v
∗ ∈ Ls[ρ], it holds that
n U[ρ, v
∗
] ≥ n(e
−`/c
)
k
.
Now take s = c
0
log n − θn` with c
0 < c and θn ∈ [0, 1) such that s is a multiple of `. Then,
n(e
−`/c
)
k = n(e
−s/c
) = n(n
−c
0
/c
e
−θn`/c
) = n
1−c
0
/c
e
−θn`/c
≥ c
0
log n − θn` + 1 = s + 1 (6.3.12)
for all n large enough, where we used that 1 − c
0
/c > 0, θn ∈ [0, 1) and ` is fixed. So, using
the characterization of the height in (6.3.2) and (6.3.3) together with inequality (6.3.11), we
derive
Sv
∗ ≥ n U[ρ, v
∗
] − s ≥ n(e
−`/c
)
k − s ≥ 1. (6.3.13)
That is, Hn ≥ c
0
log n − θn`.
But this is not quite what we want: this last claim holds only conditioned on survival; or
put differently, it holds with probability 1 − η, a value which could be significantly smaller
than 1 in general. To handle this last issue, we consider a large number of independent copies
of the Galton–Watson process above in order to “boost” the probability that at least one of
them survives to a value arbitrarily close to 1.
Claim 6.3.6 For any δ > 0, there is a J so that Hn ≥ c
0
log n − θn` + J` with probability at
least 1 − δ for all n large enough.
Proof Let J` be a multiple of ` and let
u
∗
1
, . . . , u
∗
2
J`
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.3 Applications 355
be the vertices on level J` from left to right. Each process

Z
u
∗
i
,`
t

t≥0
, i = 1, . . . , 2J`
is an independent copy of (Z
ρ,`
t
)t≥0.
We define two “bad events”:
• (No survival) Let B1 be the event that all (Z
u
∗
i
,`
t
)s go extinct and choose J large enough
that this event has probability < δ/2, that is,
P[B1] = η
2
J`
< δ/2.
Under B
c
1
, at least one of the branching processes survives; let I be the lowest index among
them.
• (Fast decay at the top) To bound the height, we also need to control the effect of the
first J` levels on the subtree sizes. Let B2 be the event that at least one of the W-values
associated with the 2J` − 1 vertices ancestral to the u
∗
i
s is outside the interval (α, 1 − α).
Choose α small enough that this event has probability < δ/2, that is,
P[B2] ≤ (2α)(2J` − 1) < δ/2.
Under B
c
2
, we have almost surely the lower bound
U[ρ, u
∗
I
] ≥ α
J`
, (6.3.14)
since it in fact holds for all u
∗
i
s simultaneously.
We are now ready to conclude. Assume B
c
1
and B
c
2
hold. Taking
s = k` = c
0
log n − θn`
as before, we have Z
u
∗
I
,`
k ≥ 1 so there is v
∗ ∈ Ls[u
∗
I
] such that
n U[ρ, v
∗
] = n U[ρ, u
∗
I
] U[u
∗
I
, v
∗
] ≥ nα
J`
(e
−`/c
)
k
,
where we used (6.3.14). Observe that (6.3.12) remains valid (for potentially larger n) even
after multiplying all expressions on the left-hand side of the inequality by α
J`
. Arguing as
in (6.3.13), we get that Hn ≥ c
0
log n − θn` + J`. This event holds with probability at least
P[(B1 ∪ B2)
c
] = 1 − P[B1] − P[B2] ≥ 1 − δ.
We have proved the claim.
For any ε > 0, we can choose c
0 = γ − ε and c
0 < c < γ . Furthermore, δ can be made
arbitrarily small (provided n is large enough). Put differently, we have proved that for any
ε > 0,
P [Hn/ log n ≥ γ − ε] → 1
as n → +∞, which establishes the other direction of Claim 6.3.1.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press356 Branching Processes
6.3.2 F Data Science: The Reconstruction Problem, the Kesten–Stigum Bound and a
Phase Transition in Phylogenetics
In this section, we explore an application of multitype branching processes in statistical
phylogenetics, the reconstruction of evolutionary trees from molecular data. Informally, we
consider a ferromagnetic Ising model (Example 1.2.5) on an infinite binary tree and we ask:
When do the states at level h “remember” the state at the root? We establish the existence
of a phase transition. Before defining the problem formally and explaining its connection
to evolutionary biology, we describe an equivalent definition of the model. This alternative
“Markov chain on a tree” perspective will make it easier to derive recursions for quantities
of interest. Equivalence between the two models is proved in Exercise 6.16.
The reconstruction problem
Consider a rooted infinite binary tree T = bT2, where the root is denoted by 0. Fix a param￾MUTATION eter 0 < p < 1/2, which we will refer to as the mutation probability for reasons that will be
PROBABILITY explained below. We assign a state σv
in C = {+1, −1} to each vertex v as follows. At the
root 0, the state σ0 is picked uniformly at random in {+1, −1}. Moving away from the root,
the state σv at a vertex v, conditioned on the state at its immediate ancestor u, is equal to σu
with probability 1−p and to −σu with probability p. In the computational biology literature,
CFN MODEL this model is referred to as the Cavender–Farris–Neyman (CFN) model.
For h ≥ 0, let Lh be the set of vertices in T at graph distance h from the root. We denote
by σh = (σ`)`∈Lh
the vector of states at level h and we denote by µh the distribution of
RECONSTRUC- σh. The reconstruction problem consists in trying to “guess” the state at the root σ0 given
TION
PROBLEM
the states σh at level h. We first note that in general we cannot expect an arbitrarily good
estimator. Indeed, rewriting the Markov transition matrix along the edges (i.e., the matrix
encoding the probability of the state at a vertex given the state at its immediate ancestor) in
its random cluster form
P :=

1 − p p
p 1 − p

= (1 − 2p)

1 0
0 1
+ (2p)

1/2 1/2
1/2 1/2

, (6.3.15)
we see that the states σ1 at the first level are completely randomized (i.e., independent of
σ0) with probability (2p)
2 – in which case we cannot hope to reconstruct the root state better
than a coin flip. Intuitively, the reconstruction problem is solvable if we can find an estimator
of the root state which outperforms a random coin flip as h grows to +∞. Let µ
+
h
be the
distribution µh conditioned on the root state σ0 being +1, and similarly for µ
−
h
. Observe that
µh =
1
2
µ
+
h +
1
2
µ
−
h
. Recall also that
kµ
+
h − µ
−
h
kTV =
1
2
X
sh∈{+1,−1}
2
h
|µ
+
h
(sh) − µ
−
h
(sh)|.
RECONSTRUC- Definition 6.3.7 (Reconstruction solvability). We say that the reconstruction problem for
TION
SOLVABILITY
0 < p < 1/2 is solvable if
lim inf
h→+∞
kµ
+
h − µ
−
h
kTV > 0,
otherwise the problem is unsolvable.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.3 Applications 357
(Exercise 6.17 asks for a proof that kµ
+
h − µ
−
h
kTV is monotone in h and therefore has a
limit.)
To see the connection with the description above, consider an arbitrary root estimator
σˆ0(sh). Then the probability of a mistake is
P[σˆ0(σh) 6= σ0] =
1
2
X
sh∈{+1,−1}
2
h
µ
−
h
(sh)1{ ˆσ0(sh) = +1}
+
1
2
X
sh∈{+1,−1}
2
h
µ
+
h
(sh)1{ ˆσ0(sh) = −1}.
This expression is minimized by choosing for each sh separately
σˆ0(sh) =
(
+1 if µ
+
h
(sh) ≥ µ
−
h
(sh),
−1 otherwise.
Let µh(s0|sh) be the posterior probability of the root state, that is, the conditional probability
of the root state s0 given the states sh at level h. By Bayes’ rule,
µh(+1|sh) =
(1/2)µ
+
h
(sh)
µh(sh)
,
and similarly for µh(+1|sh). Hence, the choice above is equivalent to
σˆ0(sh) =
(
+1 if µh(+1|sh) ≥ µh(−|sh),
−1 otherwise,
which is known as the maximum a posteriori (MAP) estimator. (We encountered it in a MAP
different context in Section 5.1.4.) For short, we will denote it by σˆ ESTIMATOR MAP
0
.
Now note that
P[σˆ
MAP
0
(σh) = σ0] − P[σˆ
MAP
0
(σh) 6= σ0]
=
1
2
X
sh∈{+1,−1}
2
h
µ
+
h
(sh) [1{ ˆσ
MAP
0
(sh) = +1} − 1{ ˆσ
MAP
0
(sh) = −1}]
+
1
2
X
sh∈{+1,−1}
2
h
µ
−
h
(sh) [1{ ˆσ
MAP
0
(sh) = −1} − 1{ ˆσ
MAP
0
(sh) = +1}]
=
1
2
X
sh∈{+1,−1}
2
h
µ
+
h
(sh) σˆ
MAP
0
(sh)
−
1
2
X
sh∈{+1,−1}
2
h
µ
−
h
(sh) σˆ
MAP
0
(sh)
=
1
2
X
sh∈{+1,−1}
2
h
|µ
+
h
(sh) − µ
−
h
(sh)|
= kµ
+
h − µ
−
h
kTV,
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press358 Branching Processes
where the third equality comes from
|a − b| = (a − b)1{a ≥ b} + (b − a)1{a < b}.
Since P[σˆ0(σh) = σ0] + P[σˆ0(σh) 6= σ0] = 1, the display above can be rewritten as
P[σˆ
MAP
0
(σh) 6= σ0] =
1
2
−
1
2
kµ
+
h − µ
−
h
kTV.
Given that σˆ
MAP
0 was chosen to minimize the error probability, we also have that for any root
estimator σˆ0,
P[σˆ0(σh) 6= σ0] ≥
1
2
−
1
2
kµ
+
h − µ
−
h
kTV.
Since this last inequality also applies to the estimator − ˆσ0, we have also that
P[σˆ0(σh) 6= σ0] ≤
1
2
.
The next lemma summarizes the discussion above.
Lemma 6.3.8 (Probability of erroneous reconstruction). The probability of an erroneous
root reconstruction behaves as follows.
(i) If the reconstruction problem is solvable, then
lim
h→+∞
P[σˆ
MAP
0
(σh) 6= σ0] <
1
2
.
(ii) If the reconstruction problem is unsolvable, then for any root estimator σˆ0
lim
h→+∞
P[σˆ0(σh) 6= σ0] =
1
2
.
It turns out that the accuracy of the MAP estimator undergoes a phase transition at a
critical mutation probability p∗. Our main theorem is the following.
Theorem 6.3.9 (Solvability). Let θ∗ be the unique positive solution to
2θ
2
∗ = 1,
and set p∗ =
1−θ
∗
2
. Then the reconstruction problem is:
(i) solvable if 0 < p < p∗;
(ii) unsolvable if p∗ ≤ p < 1/2.
We will prove this theorem in the rest of the section.
But first, what does all of this have to do with evolutionary biology? Truncate T at level
h to obtain a finite tree Th with leaf set Lh. In phylogenetics, one uses such a tree to depict
evolutionary relationships between extant species that are represented by its leaves. Each
internal branching corresponds to a past speciation event. Extinctions have been pruned
from the tree. The genomes of ancestral species, starting from the most recent common
ancestor at the root, are posited to have evolved along the (deterministic) tree Th according
to a random process of single-site substitutions. To simplify, each position in the genome is
assumed to take one of two values, +1 or −1, and it evolves independently from all other
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.3 Applications 359
positions under a CFN model on Th. That is, on each edge of the tree a mutation occurs with
probability p, changing the state of the immediate descendant species at that position. This
is of course only a toy model, but it is not far from what evolutionary biologists actually use
in practice with great success. One practical problem of interest is to reconstruct the genome
of ancestors given access to contemporary genomes. This is, in a nutshell, the reconstruction
problem.
Kesten–Stigum bound
The condition in Theorem 6.3.9 is referred to as the Kesten–Stigum bound. We explain KESTEN–
STIGUM
BOUND
why next. We showed in Lemma 6.3.8 that the MAP estimator has an error probability
bounded away from 1/2 if and only if the reconstruction problem is solvable. Of course,
other estimators may also achieve that same desirable outcome. In fact, from the lemma,
to establish reconstruction solvability it suffices to exhibit one such “better-than-random”
estimator. So, rather than analyzing σˆ
MAP
0
, we look at a simpler estimator first and prove half
of Theorem 6.3.9. The other half will be proven below using different ideas.
The key is to notice that a multitype branching process (see Section 6.1.4) hides in the
background. For h ≥ 0, consider the random row vector Zh = (Zh,+, Zh,−) where the first
component records the number of +1 states (which we refer to as belonging to the + type)
in σh and, likewise, the second component counts the −1 states (referred to as of − type).
Then, (Zh)h≥0 is a two-type Galton–Watson process where each individual has exactly two
children. Their types depend on the type of the parent. A type + individual has the following
offspring distribution:
p
(+)
k =



(1 − p)
2
if k = (2, 0),
2p(1 − p) if k = (1, 1),
p
2
if k = (0, 2),
0 otherwise.
Similar expressions hold for p
(−)
k
. The mean matrix is given by
M =

2(1 − p)
2 + 2p(1 − p) 2p(1 − p) + 2p
2
2p(1 − p) + 2p
2 2(1 − p)
2 + 2p(1 − p)

= 2

(1 − p)(1 − p + p) p(1 − p + p)
p(1 − p + p) (1 − p)(1 − p + p)

= 2

1 − p p
p 1 − p

= 2P,
where (not coincidentally) we have already encountered the matrix P in (6.3.15). As a sym￾metric matrix, by the spectral theorem (Theorem 5.1.1), P has a real eigenvector
decomposition
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press360 Branching Processes
P =

1 − p p
p 1 − p

=

1/2 1/2
1/2 1/2

+ (1 − 2p)

1/2 −1/2
−1/2 1/2

= λ1x1x
T
1 + λ2x2x
T
2
,
where the eigenvalues and eigenvectors are
λ1 = 1, λ2 = 1 − 2p, x1 =

1/
√
2
1/
√
2

, x2 =

1/
√
2
−1/
√
2

.
The eigenvalues of M are twice those of P, while the eigenvectors are the same. In particular,
using the notation and convention of the Perron–Frobenius Theorem (Theorem 6.1.17), we
have
ρ = 2, w =

1/2
1/2

.
These should not come entirely as a surprise. In particular, recall from Theorem 6.1.18 that
ρ can be interpreted as an “overall rate of growth” of the population, which here is two since
each individual has exactly two children (ignoring the types).
Let u = (1, −1) be a column vector proportional to the second right eigenvector of M.
We know from Section 6.1.4 that
Uh = (2λ2)
−hZhu =
1
2
hθ
h
X
`∈Lh
σ`, h ≥ 0
is a martingale, where we used the notation
θ := λ2 = 1 − 2p.
Upon looking more closely, the quantity Uh has a natural interpretation: its sign is the ma￾MAJORITY jority estimator, that is, sgn(Uh) = +1 if a majority of individuals at level h are of type
ESTIMATOR + (breaking ties in favor of +), and is −1 otherwise. We indicated previously that we only
need to find one estimator with an error probability bounded away from 1/2 to establish
reconstruction solvability for a given value of p. The majority estimator
σˆ
Maj
0
:= sgn(Uh)
is an obvious one to try. What is less obvious is that it works – all the way to the threshold.
This essentially follows from the results of Section 6.1.4, as we detail next.
We begin with an informal discussion. When can σˆ
Maj
0
be expected to work? We will not
in fact bound the error probability of σˆ
Maj
0
, but instead analyze directly the properties of (Uh).
By our modeling assumptions, Z0 is either (1, 0) or (0, 1) with equal probability. Hence, by
the martingale property, we obtain that
E[Uh |Z0] = Z0u = σ0. (6.3.16)
In other words, Uh is “centered” around the root state. Intuitively, its second moment there￾fore captures how informative it is about σ0. Lemma 6.1.20 exhibits a phase transition for
E[U
2
h
|Z0]. The condition for that lemma to hold is
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.3 Applications 361
(Var[X
(+)
(1, 1) u], Var[X
(−)
(1, 1) u]) 6= 0,
where X
(+)
(1, 1) ∼ {p
(+)
k
} and X
(−)
(1, 1) ∼ {p
(−)
k
}. This is indeed satisfied. The lemma then
states that E[U
2
h
|Z0] is uniformly bounded if and only if ρ < (2λ2)
2
, or after rearranging,
2θ
2 > 1. (6.3.17)
Note that this is the condition in Theorem 6.3.9. It arises as a trade-off between the rate of
growth ρ = 2 and the second largest eigenvalue λ2 = θ of the Markov transition matrix P.
One way to make sense of it is to observe the following:
• On any infinite path out of the root, the process performs a finite Markov chain with
transition matrix P. We know from Theorem 5.2.14 (see in particular Example 5.2.8) that
the chain mixes – and therefore “forgets” its starting state σ0 – at a rate governed by the
spectral gap 1 − λ2.
• On the other hand, the tree itself is growing at rate ρ = 2, which produces an exponen￾tially large number of (overlapping) paths out of the root. That growth helps preserve the
information about σ0 down the tree through the duplication of the state (with mutation) at
each branching.
• The condition ρ < (2λ2)
2
says in essence that when mixing is slow enough – correspond￾ing to larger values of λ2 – compared to the growth, then the reconstruction problem is
solvable. Lemma 6.1.20 was first proved by Kesten and Stigum, and (6.3.17) is thereby
known as the Kesten–Stigum bound.
It remains to turn these observations into a formal proof.
Denote by E
+ the expectation conditioned on σ0 = +1, and similarly for E
−. The follow￾ing lemma is a consequence of (6.3.16). We give a quick alternative proof.
Lemma 6.3.10 (Unbiasedness of Uh). We have
E
+
[Uh] = +1, E
−
[Uh] = −1.
Proof By applying the Markov transition matrix P on the first level and using the symme￾tries of the model, for any ` ∈ Lh and `
0 ∈ Lh−1, we have
E
+
[σ`] = (1 − p)E
+
[σ`
0] + p E
−
[σ`
0]
= (1 − p)E
+
[σ`
0] + p E
+
[−σ`
0]
= (1 − 2p)E
+
[σ`
0]
= θ E
+
[σ`
0].
Iterating, we get E
+[σ`] = θ
h
. The claim follows by linearity of expectation.
Although we do not strictly need it, we also derive an explicit formula for the variance. The
proof is typical of how conditional independence properties of this kind of Markov model
on trees can be used to derive recursions for quantities of interest.
Lemma 6.3.11 (Variance of Uh). We have
Var[Uh] →
(
1/2
1−(2θ
2
)
−1
if 2θ
2 > 1,
+∞ otherwise.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press362 Branching Processes
Proof By the conditional variance formula
Var[Uh] = Var[E[Uh | σ0]] + E[Var[Uh | σ0]]
= Var[σ0] + E[Var[Uh | σ0]]
= 1 + Var+
[Uh], (6.3.18)
where the last line follows from symmetry, with Var+
indicating the conditional variance
given that the root state σ0 is +1. Write Uh = U˙
h+U¨
h as a sum over the left and right subtrees
below the root, respectively. Using the conditional independence of those two subtrees given
the root state, we get from (6.3.18) that
Var[Uh] = 1 + Var+
[Uh]
= 1 + Var+

U˙
h + U¨
h

= 1 + 2Var+

U˙
h

= 1 + 2

E
+

U˙
2
h

− E
+

U˙
h
2

. (6.3.19)
We now use the Markov transition matrix on the first level to derive a recursion in h. Let
σ˙0 be the state at the left child of the root. We use the fact that the random variables 2θU˙
h
conditioned on σ˙0 = +1 and Uh−1 conditioned on σ0 = +1 are identically distributed. Using
E
+[U˙
h] = 1/2 (by Lemma 6.3.10 and symmetry), we get from (6.3.19) that
Var[Uh] = 1 − 2E
+

U˙
h
2
+ 2 E
+

U˙
2
h

= 1 − 2(1/2)2 + 2

(1 − p)E
+

(2θ)
−2U
2
h−1

+ p E
−

(2θ)
−2U
2
h−1

= 1/2 + (2θ
2
)
−1E
+
[U
2
h−1
]
= 1/2 + (2θ
2
)
−1Var[Uh−1], (6.3.20)
where we used that
Var[Uh−1] = E[U
2
h−1
] = E
+
[U
2
h−1
] = E
−
[U
2
h−1
]
by symmetry and the fact that E[Uh−1] = 0. Solving the affine recursion (6.3.20) gives
Var[Uh] = (2θ
2
)
−h + (1/2)X
h−1
i=0
(2θ
2
)
−i
,
where we used that Var[U0] = Var[σ0] = 1. The result follows.
We can now prove the first part of Theorem 6.3.9.
Proof of Theorem 6.3.9 (i) Let µ¯ h be the distribution of Uh and define µ¯
+
h
and µ¯
−
h
similarly.
We give a bound on kµ
+
h −µ
−
h
kTV through a bound on k ¯µ
+
h
− ¯µ
−
h
kTV. Let s¯h be the Uh-value
associated to sh = (sh,`)`∈Lh ∈ {+1, −1}
2
h
, that is,
s¯h =
1
2
hθ
h
X
`∈Lh
sh,`.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.3 Applications 363
Then, by marginalizing and the triangle inequality,
X
z
| ¯µ
+
h
(z) − ¯µ
−
h
(z)| = X
z





X
sh:s¯h=z
(µ
+
h
(sh) − µ
−
h
(sh))





≤
X
z
X
sh:s¯h=z
|µ
+
h
(sh) − µ
−
h
(sh)|
=
X
sh∈{+1,−1}
2
h
|µ
+
h
(sh) − µ
−
h
(sh)|,
where the first sum is over the support of µ¯ h. So it suffices to bound from below the left-hand
side on the first line.
For that purpose, we apply Cauchy–Schwarz and use the variance bound in Lemma 6.3.11.
First note that 1
2
µ¯
+
h +
1
2
µ¯
−
h = ¯µh so that, by the triangle inequality,
| ¯µ
+
h
(z) − ¯µ
−
h
(z)|
2µ¯ h(z)
≤
µ¯
+
h
(z) + ¯µ
−
h
(z)
2µ¯ h(z)
= 1. (6.3.21)
Hence, we get
X
z
| ¯µ
+
h
(z) − ¯µ
−
h
(z)| = X
z
| ¯µ
+
h
(z) − ¯µ
−
h
(z)|
2µ¯ h(z)
2µ¯ h(z)
≥ 2
X
z

µ¯
+
h
(z) − ¯µ
−
h
(z)
2µ¯ h(z)
2
µ¯ h(z)
≥ 2
P
z
z

µ¯
+
h
(z)− ¯µ
−
h
(z)
2µ¯ h(z)

µ¯ h(z)
2
P
z
z
2µ¯ h(z)
≥
1
2
￾P
z
z
￾
µ¯
+
h
(z) − ¯µ
−
h
(z)
2
P
z
z
2µ¯ h(z)
=
1
2
(E
+[Uh] − E
−[Uh])2
Var[Uh]
≥ 4(1 − (2θ
2
)
−1
) > 0,
where we used (6.3.21) on the second line, Cauchy–Schwarz on the third line (after rear￾ranging), and Lemmas 6.3.10 and 6.3.11 on the last line.
Remark 6.3.12 The proof above and a correlation inequality of [EKPS00, Theorem 1.4]
give a lower bound on the probability of reconstruction of the majority estimator.
Impossibility of reconstruction
The previous result was based on showing that majority voting, that is, σˆ
Maj
0
, produces a
good root-state estimator – up to p = p∗. Here we establish that this result is best possible.
Majority is not in fact the best root-state estimator: in general, its error probability can be
higher than σˆ
MAP
0
as the latter also takes into account the configuration of the states at level
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Pre364 Branching Processes
h. However, perhaps surprisingly, it turns out that the critical threshold for σˆ
Maj
0
coincides
with that of σˆ
MAP
0
in the CFN model.
To prove the second part of Theorem 6.3.9 we analyze the MAP estimator. Recall that
µh(s0|sh) is the conditional probability of the root state s0 given the states sh at level h. It will
be more convenient to work with the following “root magnetization”:
Rh := µh(+1|σh) − µh(−1|σh),
which, as a function of σh, is a random variable. Note that E[Rh] = 0 by symmetry. By
Bayes’ rule and the fact that µh(+1|σh)+µh(−1|σh) = 1, we have the following alternative
formulas which will prove useful
Rh =
1
2µh(σh)
[µ
+
h
(σh) − µ
−
h
(σh)], (6.3.22)
Rh = 2µh(+1|σh) − 1 =
µ
+
h
(σh)
µh(σh)
− 1, (6.3.23)
Rh = 1 − 2µh(−1|σh) = 1 −
µ
−
h
(σh)
µh(σh)
. (6.3.24)
It turns out to be enough to prove an upper bound on the variance of Rh.
Lemma 6.3.13 (Second moment bound). It holds that
kµ
+
h − µ
−
h
kTV ≤
q
E[R
2
h
].
Proof By (6.3.22),
1
2
X
sh∈{+1,−1}
2
h
|µ
+
h
(sh) − µ
−
h
(sh)|
=
X
sh∈{+1,−1}
2
h
µh(sh) |µh(+1|sh) − µh(−1|sh)|
= E|Rh|
≤
q
E[R
2
h
],
where we used Cauchy–Schwarz on the last line.
Let z¯h = E[R
2
h
]. In view of Lemma 6.3.13, the proof of Theorem 6.3.9 (ii) will follow from
establishing the limit
lim
h→+∞
z¯h = 0.
We apply the same kind of recursive argument we used for the analysis of majority (see in
particular Lemma 6.3.11): we condition on the root to exploit conditional independence; we
use the Markov transition matrix on the top edges.
We first derive a recursion for Rh itself – as a random variable. We proceed in two steps:
• Step 1: We break up the first h levels of the tree into two identical (h − 1)-level trees with
an additional edge at their respective roots through conditional independence.
• Step 2: We account for that edge through the Markov transition matrix.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.3 Applications 365
We will need some notation. Let σ˙ h be the states at level h (from the root) below the left
child of the root and let µ˙ h be the distribution of σ˙ h. Define
Y˙
h = ˙µh(+1|σ˙ h) − ˙µh(−1|σ˙ h),
where µ˙ h(s0|s˙h) is the conditional probability that the root is s0 given that σ˙ h = s˙h. Similarly,
denote with a double dot the same quantities with respect to the subtree below the right child
of the root. Expressions similar to (6.3.22), (6.3.23), and (6.3.24) also hold.
Lemma 6.3.14 (Recursion: Step 1). It holds almost surely that
Rh =
Y˙
h + Y¨
h
1 + Y˙
hY¨
h
.
Proof Using µ
+
h
(sh) = ˙µ
+
h
(s˙h)µ¨
+
h
(s¨h) by conditional independence (where the superscript
indicates conditioning on the root), (6.3.22) applied to Rh, and (6.3.23) and (6.3.24) applied
to Y˙
h and Y¨
h, we get
Rh =
1
2
X
γ =+,−
γ
µ
γ
h
(σh)
µh(σh)
=
1
2
µ˙ h(σ˙ h)µ¨ h(σ¨ h)
µh(σh)
X
γ =+,−
γ
µ˙
γ
h
(σ˙ h)µ¨
γ
h
(σ¨ h)
µ˙ h(σ˙ h)µ¨ h(σ¨ h)
=
1
2
µ˙ h(σ˙ h)µ¨ h(σ¨ h)
µh(σh)
X
γ =+,−
γ
￾
1 + γ Y˙
h
 ￾1 + γ Y¨
h

=
µ˙ h(σ˙ h)µ¨ h(σ¨ h)
µh(σh)
(Y˙
h + Y¨
h).
The factor in front can be computed as follows:
µh(σh)
µ˙ h(σ˙ h)µ¨ h(σ¨ h)
=
X
γ =+,−
1
2
µ
γ
h
(σh)
µ˙ h(σ˙ h)µ¨ h(σ¨ h)
=
X
γ =+,−
1
2
µ˙
γ
h
(σ˙ h)µ¨
γ
h
(σ¨ h)
µ˙ h(σ˙ h)µ¨ h(σ¨ h)
=
1
2
X
γ =+,−
￾
1 + γ Y˙
h
 ￾1 + γ Y¨
h

= 1 + Y˙
hY¨
h.
That proves the claim.
For the second step of the recursion, we define
D˙
h = ˙νh(+1|σ˙ h) − ˙νh(−1|σ˙ h),
where ν˙h(s˙0|s˙h) is the conditional probability that the left child of the root is s˙0 given that
the states at level h (from the root) below the left child are σ˙ h = s˙h; and similarly for the
right child of the root. Again expressions similar to (6.3.22), (6.3.23), and (6.3.24) hold. The
following lemma is left as an exercise (see Exercise 6.18).
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University P366 Branching Processes
Lemma 6.3.15 (Recursion: Step 2). It holds almost surely that
Y˙
h = θD˙
h.
We are now ready to prove the second half of our main theorem.
Proof of Theorem 6.3.9 (ii) Putting Lemmas 6.3.14 and 6.3.15 together, we get
Rh =
θ(D˙
h + D¨
h)
1 + θ
2D˙
hD¨
h
. (6.3.25)
We now take expectations. Recall that we seek to compute the second moment of Rh. How￾ever, an important simplification arises from the following observation
E
+
[Rh] =
X
sh∈{+1,−1}
2
h
µ
+
h
(sh)Rh(sh)
=
X
sh∈{+1,−1}
2
h
µh(sh)
µ
+
h
(sh)
µh(sh)
Rh(sh)
=
X
sh∈{+1,−1}
2
h
µh(sh)(1 + Rh(sh))Rh(sh)
= E[(1 + Rh)Rh]
= E[R
2
h
],
where we used (6.3.23) on the third line and E[Rh] = 0 on the fifth line. So it suffices to
compute the conditional first moment.
Using the expansion
1
1 + r
= 1 − r +
r
2
1 + r
,
with r = θ
2D˙
hD¨
h, we have by (6.3.25) that
Rh = θ(D˙
h + D¨
h) − θ
3
(D˙
h + D¨
h)D˙
hD¨
h + θ
4D˙
2
hD¨
2
hRh
≤ θ(D˙
h + D¨
h) − θ
3
(D˙
h + D¨
h)D˙
hD¨
h + θ
4D˙
2
hD¨
2
h
, (6.3.26)
where we used |Rh| ≤ 1.
We will need the conditional first and second moments of D˙
h. For the first moment, note
that by symmetry (more precisely, by the fact that Rh−1 conditioned on σ0 = −1 is equal in
distribution to −Rh−1 conditioned on σ0 = +1),
E
+
[D˙
h] = (1 − p)E
+
[Rh−1] + p E
−
[Rh−1]
= (1 − p)E
+
[Rh−1] + p E
+
[−Rh−1]
= (1 − 2p)E
+
[Rh−1]
= θ E
+
[Rh−1].
Similarly, for the second moment, we have
E
+
[D˙
2
h
] = (1 − p)E
+
[R
2
h−1
] + p E
−
[R
2
h−1
]
= E[R
2
h−1
]
= E
+
[Rh−1],
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.3 Applications 367
where we used that E
+[R
2
h−1
] = E
−[R
2
h−1
] by symmetry so that E[R
2
h−1
] = (1/2)E
+[R
2
h−1
] +
(1/2)E
−[R
2
h−1
] = E
+[R
2
h−1
].
Taking expectations in (6.3.26), using conditional independence, and plugging in the for￾mulas for E
+[D˙
h] and E
+[D˙
2
h
] above, we obtain
z¯h = E
+
[Rh]
≤ θ(E
+
[D˙
h] + E
+
[D¨
h]) − θ
3
(E
+
[D˙
2
h
] E
+
[D¨
h] + E
+
[D¨
2
h
] E
+
[D˙
h])
+ θ
4E
+
[D˙
2
h
] E
+
[D¨
2
h
]
= 2θ
2E
+
[Rh−1] − 2θ
4E
+
[Rh−1]
2 + θ
4E
+
[Rh−1]
2
= 2θ
2
z¯h−1 − θ
4
z¯
2
h−1
. (6.3.27)
We analyze this recursion next. At h = 0, we have z¯0 = E
+[R0] = 1.
• When 2θ
2 < 1, the sequence z¯h decreases to 0 exponentially fast
z¯h ≤ (2θ
2
)
h
, h ≥ 0.
• When 2θ
2 = 1 on the other hand, convergence to 0 occurs at a slower rate. We show by
induction that
z¯h ≤
4
h
, h ≥ 0.
Note that z¯1 ≤ ¯z0−θ
4
z¯
2
0 = 3/4 ≤ 4 since θ
4 = 1/4, which proves the base case. Assuming
the bound holds for h − 1, we have from (6.3.27) that
z¯h ≤ ¯zh−1 −
1
4
z¯
2
h−1
≤
4
h − 1
−
4
(h − 1)2
= 4
h − 2
(h − 1)2
≤
4
h
,
where the last line follows from checking that h(h − 2) ≤ (h − 1)2
.
Since
lim
h→+∞
z¯h = 0,
the claim follows from Lemma 6.3.13.
Remark 6.3.16 While Theorem 6.3.9 part (i) can be generalized beyond the CFN model
(see, for example, [MP03]), part (ii) cannot. A striking construction of [Mos01] shows that,
under more general models, certain root-state estimators taking into account the configura￾tion of the states at level h can “beat” the Kesten–Stigum bound.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press368 Branching Processes
6.4 F Finale: The Phase Transition of the Erdos–Rényi Model ˝
A compelling way to view an Erdos–Rényi random graph – as its density varies – is the fol- ˝
lowing coupling or “evolution.” For each pair {i, j}, let U{i,j} be independent uniform random
variables in [0, 1] and set G(p) := ([n], E(p)), where {i, j} ∈ E(p) if and only if U{i,j} ≤ p.
Then, G(p) is distributed according to Gn,p. As p varies from 0 to 1, we start with an empty
graph and progressively add edges until the complete graph is obtained.
We showed in Section 2.3.2 that log n
n
is a threshold function for connectivity. Before con￾nectivity occurs in the evolution of the random graph, a quantity of interest is the size of
the largest connected component. As we show in the current section, this quantity itself un￾dergoes a remarkable phase transition: when p =
λ
n with λ < 1, the largest component has
size 2(log n); as λ crosses 1, many components quickly merge to form a so-called giant
component of size 2(n).
This celebrated result is often referred to as “the” phase transition of the Erdos–Rényi ˝
graph model. Although the proof is quite long, it is well worth studying in details. It employs
most tools we have seen up to this point: first and second moment methods, Chernoff–
Cramér bounds, martingale techniques, coupling and stochastic domination, and branching
processes. It is quintessential discrete probability.
6.4.1 Statement and Proof Sketch
Before stating the main theorems, we recall a basic result from Chapter 2.
• (Poisson tail) Let Sn be a sum of n i.i.d. Poi(λ) variables. Recall from (2.4.10) and (2.4.11)
that for a > λ,
−
1
n
log P[Sn ≥ an] ≥ a log  a
λ

− a + λ =: I
Poi
λ
(a), (6.4.1)
and similarly for a < λ,
−
1
n
log P[Sn ≤ an] ≥ I
Poi
λ
(a). (6.4.2)
To simplify the notation, we let
Iλ := I
Poi
λ
(1) = λ − 1 − log λ ≥ 0, (6.4.3)
where the inequality follows from the convexity of Iλ and the fact that it attains its mini￾mum at λ = 1 where it is 0.
We let p =
λ
n
and denote by Cmax a largest connected component. In the subcritical case, that
is, when λ < 1, we show that the largest connected component has logarithmic size in n.
Theorem 6.4.1 (Subcritical case: upper bound on the largest cluster). Let Gn ∼ Gn,pn
, where
pn =
λ
n
with λ ∈ (0, 1). For all κ > 0,
Pn,pn

|Cmax| ≥ (1 + κ)I
−1
λ
log n

= o(1),
where Iλ is defined in (6.4.3).
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.4 F Finale: The Phase Transition of the Erd ˝os–Rényi Model 369
Figure 6.4 Illustration of the phase transition.
We also give a matching logarithmic lower bound on the size of Cmax in Theorem 6.4.11.
In the supercritical case, that is, when λ > 1, we prove the existence of a unique connected
component of size linear in n, which is referred to as the giant component. GIANT
COMPONENT
Theorem 6.4.2 (Supercritical regime: giant component). Let Gn ∼ Gn,pn
, where pn =
λ
n
with λ > 1. For any γ ∈ (1/2, 1) and δ < 2γ − 1,
Pn,pn
[||Cmax| − ζλn| ≥ n
γ
] = O(n
−δ
),
where ζλ is the unique solution in (0, 1) to the fixed point equation
1 − e
−λζ = ζ .
In fact, with probability 1 − O(n
−δ
), there is a unique largest component and the second
largest connected component has size O(log n).
See Figure 6.4 for an illustration.
At a high level, the proof goes as follows:
• (Subcritical regime) In the subcritical case, we use an exploration process and a domina￾tion argument to approximate the size of the connected components with the progeny of a
branching process. The result then follows from the hitting-time theorem and the Poisson
tail.
• (Supercritical regime) In the supercritical case, a similar argument gives a bound on the
expected size of the giant component, which is related to the survival of the branching
process. Chebyshev’s inequality gives concentration. The hard part there is to bound the
variance.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press370 Branching Processes
6.4.2 Bounding Cluster Size: Domination by Branching Processes
For a vertex v ∈ [n], let Cv be the connected component containing v, which we also refer
to as the cluster of v. To analyze the size of Cv CLUSTER , we use the exploration process introduced in
Section 6.2.1 and show that it is dominated above and below by branching processes.
Exploration process
Recall that the exploration process started at v has three types of vertices: the active vertices
At
, the explored vertices Et
, and the neutral vertices Nt
. We start with A0 := {v}, E0 := ∅,
and N0 contains all other vertices in Gn. We imagine revealing the edges of Gn as they are
encountered in this process and we let (Ft) be the corresponding filtration. In words, starting
with v, the cluster of v is progressively grown by adding to it at each time a vertex adjacent
to one of the previously explored vertices and uncovering its remaining neighbors in Gn.
Let as before At
:= |At
|, Et
:= |Et
|, and Nt
:= |Nt
|, and
τ0 := inf{t ≥ 0: At = 0} = |Cv
|,
where the rightmost equality is from Lemma 6.2.1. Recall that (Et) is non-decreasing, while
(Nt) is non-increasing, and that the process is fixed for all t > τ0. Since Et = t for all t ≤ τ0
(as exactly one vertex is explored at each time until the set of active vertices is empty) and
(At
, Et
, Nt) forms a partition of [n] for all t, we have
At + t + Nt = n ∀t ≤ τ0. (6.4.4)
Hence, in tracking the size of the exploration process, we can work with At or Nt
. Moreover,
at t = τ0 we have
|Cv
| = τ0 = n − Nτ0
. (6.4.5)
Similarly to the case of a Galton–Watson tree, the processes (At) and (Nt) admit a simple
recursive form. Conditioning on Ft−1:
• (Active vertices) If At−1 = 0, the exploration process has finished its course and At = 0.
Otherwise, (a) one active vertex becomes explored and (b) its neutral neighbors become
active vertices. That is,
At = At−1 + 1{At−1>0}

−1
|{z}
(a)
+ Xt
|{z}
(b)

, (6.4.6)
where Xt
is binomial with parameters Nt−1 and pn. By (6.4.4), Nt−1 can be written in terms
of At−1 as Nt−1 = n − (t − 1) − At−1. For the coupling arguments below, it will be useful
to think of Xt as a sum of independent Bernoulli variables. That is, let (It,j
: t ≥ 1, j ≥ 1)
be an array of independent, identically distributed {0, 1}-variables with P[I1,1 = 1] = pn.
We write
Xt =
X
Nt−1
i=1
It,i
. (6.4.7)
• (Neutral vertices) Similarly, if At−1 > 0, that is, Nt−1 < n − (t − 1), Xt neutral vertices
become active. That is,
Nt = Nt−1 − 1{Nt−1<n−(t−1)} Xt
. (6.4.8)
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.4 F Finale: The Phase Transition of the Erd ˝os–Rényi Model 371
Poisson branching process approximation
With these observations, we now relate the size of the cluster of v to the total progeny of
a Poisson branching process with an appropriately chosen offspring mean. The intuition is
simple: when pn = λ/n, the number of neighbors of a vertex is well approximated by a
Poisson distribution; therefore, exploration of the cluster of v is similar to that of the cor￾responding branching process. We will see that this holds long enough to prove accurate
results about the subcritical regime (see Lemma 6.4.6). It will also be useful in the supercrit￾ical regime, but additional arguments will be required there (see Lemmas 6.4.8 and 6.4.7).
Lemma 6.4.3 (Cluster size: Poisson branching process approximation). Let Gn ∼ Gn,pn
,
where pn =
λ
n
with λ > 0 and let Cv be the connected component of v ∈ [n]. Let Wλ
be the total progeny of a branching process with offspring distribution Poi(λ). Then, for
1 ≤ kn = o(
√
n),
P[Wλ ≥ kn] − O

k
2
n
n

≤ Pn,pn
[|Cv
| ≥ kn] ≤ P[Wλ ≥ kn].
From Example 6.2.7, we have an explicit formula for the distribution of Wλ.
Before proving the lemma, recall the following simple domination results from Chapter 4:
• (Binomial domination) We have
n ≥ m =⇒ Bin(n, p)  Bin(m, p). (6.4.9)
The binomial distribution is also dominated by the Poisson distribution in the following
way:
λ ∈ (0, 1) =⇒ Poi(λ)  Bin
n − 1,
λ
n

. (6.4.10)
For the proofs, see Examples 4.2.4 and 4.2.8.
We use these domination results to relate the size of a connected component to the progeny
of a branching process.
Proof of Lemma 6.4.3 We start with the upper bound.
Upper bound: Because Nt−1 = n−(t−1)−At−1 ≤ n−1, conditioned on Ft−1, the following
stochastic domination relations hold
Bin
Nt−1,
λ
n

 Bin
n − 1,
λ
n

 Poi(λ),
by (6.4.9) and (6.4.10). Observe that the center and rightmost distributions do not depend on
Nt−1. Let (X

t
) be a sequence of independent Poi(λ).
Using the coupling in Example 4.2.8, we can couple the processes (It,j)j and (X

t
) in such
way that X

t ≥
Pn−1
j=1
It,j almost surely for all t. Then by induction on t,
At ≤ A

t
almost surely for all t, where we define (recalling (6.4.6))
A

t
:= A

t−1 + 1{A

t−1>0}

− 1 + X

t

, (6.4.11)
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press372 Branching Processes
with A

0
:= 1. In words, (A

t
) is the size of the active set of a Galton–Watson branching
process with offspring distribution Poi(λ), as defined in Section 6.2.1.
As a result, letting
Wλ = τ

0
:= inf{t ≥ 0: A

t = 0}
be the total progeny of this branching process, we immediately get
Pn,pn
[|Cv
| ≥ kn] = Pn,pn
[τ0 ≥ kn] ≤ P[τ

0 ≥ kn] = P[Wλ ≥ kn].
Lower bound: In the other direction, we proceed in two steps. We first show that, up to
a certain time, the process is bounded from below by a branching process with binomial
offspring distribution. In a second step, we show that this binomial branching process can
be approximated by a Poisson branching process.
1. (Domination from below) Let A
≺
t
be defined as (again recalling (6.4.6))
A
≺
t
:= A
≺
t−1 + 1{A
≺
t−1>0}

− 1 + X
≺
t

, (6.4.12)
with A
≺
0
:= 1, where
X
≺
t
:=
nX−kn
i=1
It,j
. (6.4.13)
Note that we use the same It,js as in the definition of Xt
, that is, we couple the two pro￾cesses. This time (A
≺
t
) is the size of the active set in the exploration process of a Galton–
Watson branching process with offspring distribution Bin(n − kn, pn). Let
τ
≺
0
:= inf{t ≥ 0: A
≺
t = 0}
be the total progeny of this branching process. We prove the following relationship be￾tween τ0 and τ
≺
0
.
Lemma 6.4.4 We have
P[τ
≺
0 ≥ kn] ≤ Pn,pn
[τ0 ≥ kn].
Proof We claim that At
is bounded from below by A
≺
t
up to the stopping time
σn−kn
:= inf{t ≥ 0: Nt ≤ n − kn},
which by convention is +∞ if the event is not reached (i.e., if the cluster is “small”; see
below). Indeed, N0 = n − 1 and for all t ≤ σn−kn
, Nt−1 > n − kn by definition. Hence, by
the coupling (6.4.7) and (6.4.13), Xt ≥ X
≺
t
for all t ≤ σn−kn
and as a result, by induction
on t,
At ≥ A
≺
t ∀t ≤ σn−kn
,
where we used the recursions (6.4.6) and (6.4.13).
Because the inequality between At and A
≺
t
holds only up to time σn−kn
, we cannot
compare directly τ0 and τ
≺
0
. However, we will use the following observation: the size of
the cluster of v is at least the total number of active and explored vertices at any time t.
In particular, when σn−kn < +∞,
τ0 = |Cv
| ≥ Aσn−kn + Eσn−kn = n − Nσn−kn ≥ kn.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.4 F Finale: The Phase Transition of the Erd ˝os–Rényi Model 373
On the other hand, when σn−kn = +∞, Nt > n − kn for all t – in particular for t = τ0
– and therefore |Cv
| = τ0 = n − Nτ0 < kn by (6.4.5). Moreover, in that case, because
At ≥ A
≺
t
for all t ≤ σn−kn = +∞, it holds in addition that τ
≺
0 ≤ τ0 < kn. To sum up, we
have proved the implications
τ
≺
0 ≥ kn =⇒ σn−kn < +∞ =⇒ τ0 ≥ kn.
In particular, we have proved the lemma.
2. (Poisson approximation) Our next step is approximate the tail of τ
≺
0
by that of τ

0
.
Lemma 6.4.5 We have
P[τ
≺
0 ≥ kn] = P[τ

0 ≥ kn] + O

k
2
n
n

.
Proof By Theorem 6.2.6,
P[τ
≺
0 = t] =
1
t
P
"Xt
i=1
X
≺
i = t − 1
#
, (6.4.14)
where the X
≺
i
s are independent Bin(n − kn, pn). Note further that, because the sum of
independent binomials with the same success probability is binomial,
Xt
i=1
X
≺
i ∼ Bin(t(n − kn), pn).
Recall on the other hand that (X

t
) is Poi(λ) and, because a sum of independent Poisson
is Poisson (see Exercise 6.7), we have
P[τ

0 = t] =
1
t
P
"Xt
i=1
X

i = t − 1
#
, (6.4.15)
where
Xt
i=1
X

i ∼ Poi(tλ).
We use the Poisson approximation result in Theorem 4.1.18 to compare the probabilities
on the right-hand sides of (6.4.14) and (6.4.15). In fact, because the Poisson approxima￾tion is in terms of the total variation distance – which bounds any event – one might be
tempted to apply it directly to the tails of τ
≺
0
and τ

0
by summing over t. However, note
that the factor of 1/t in (6.4.14) and (6.4.15) prevents us from doing so.
Instead, we argue for each t separately and use that





P
"Xt
i=1
X
≺
i = t − 1
#
− P
"Xt
i=1
X

i = t − 1
#




≤ kBin(t(n − kn), pn) − Poi(tλ)kTV ,
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press374 Branching Processes
by the observations in the previous paragraph. Theorem 4.1.18 tells us that
kBin(t(n − kn), pn) − Poi(t(n − kn)[− log(1 − pn)])kTV
≤
1
2
t(n − kn)[− log(1 − pn)]2
.
We must adjust the mean of the Poisson distribution. To do so, we argue as in Exam￾ple 4.1.12 to get
kPoi(t(n − kn)[− log(1 − pn)]) − Poi(tλ)kTV
≤ |tλ − t(n − kn)(− log(1 − pn))| .
Finally, recalling that pn = λ/n, combining the last three displays and using the triangle
inequality for the total variation distance,





P
"Xt
i=1
X
≺
i = t − 1
#
− P
"Xt
i=1
X

i = t − 1
#




≤
1
2
t(n − kn)[− log(1 − pn)]2 + |tλ − t(n − kn)(− log(1 − pn))|
≤
1
2
tn
λ
n
+ O

λ
2
n
2
2
+




tλ − t(n − kn)

λ
n
+ O

λ
2
n
2




= O

tkn
n

,
where we used that kn ≥ 1 and λ is fixed.
So, by (6.4.14) and (6.4.15), dividing by t and then summing over t < kn gives

P[τ
≺
0 < kn] − P[τ

0 < kn]

 = O

k
2
n
n

.
Rearranging proves the lemma.
Putting together Lemmas 6.4.4 and 6.4.5 gives
Pn,pn
[|Cv
| ≥ kn] = Pn,pn
[τ0 ≥ kn]
≥ P[τ

0 ≥ kn] − O

k
2
n
n

= P[Wλ ≥ kn] − O

k
2
n
n

,
as claimed.
Subcritical regime: largest cluster
We are now ready to analyze the subcritical regime, that is, the case λ < 1.
Lemma 6.4.6 (Subcritical regime: upper bound on cluster size). Let Gn ∼ Gn,pn where
pn =
λ
n
with λ ∈ (0, 1) and let Cv be the connected component of v ∈ [n]. For all κ > 0,
Pn,pn

|Cv
| ≥ (1 + κ)I
−1
λ
log n

= O(n
−(1+κ)
).
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.4 F Finale: The Phase Transition of the Erd ˝os–Rényi Model 375
Proof We use the Poisson branching process approximation (Lemma 6.4.3). To apply the
lemma we need to bound the tail of the progeny Wλ of a Poisson branching process. Using
the notation of Lemma 6.4.3, by Theorem 6.2.6,
P [Wλ ≥ kn] = P [Wλ = +∞] +
X
t≥kn
1
t
P
"Xt
i=1
X

i = t − 1
#
, (6.4.16)
where the X

i
s are i.i.d. Poi(λ). Both terms on the right-hand side depend on whether or not
the mean λ is smaller or larger than 1. When λ < 1, the Poisson branching process goes
extinct with probability 1 by the extinction theory (Theorem 6.1.6). Hence P[Wλ = +∞]
= 0.
As to the second term, the sum of the X

i
s is Poi(λt). Using the Poisson tail (6.4.1) for
λ < 1 and kn = ω(1),
X
t≥kn
1
t
P
"Xt
i=1
X

i = t − 1
#
≤
X
t≥kn
P
"Xt
i=1
X

i ≥ t − 1
#
≤
X
t≥kn
exp
−tIPoi
λ

t − 1
t

≤
X
t≥kn
exp ￾
−t(Iλ − O(t
−1
))
≤
X
t≥kn
C exp (−tIλ)
= O (exp (−Iλkn)) (6.4.17)
for some constant C > 0.
Let c = (1 + κ)I
−1
λ
for κ > 0. By Lemma 6.4.3,
Pn,pn
[|Cv
| ≥ c log n] ≤ P [Wλ ≥ c log n] .
By (6.4.16) and (6.4.17),
P [Wλ ≥ c log n] = O (exp (−Iλc log n)), (6.4.18)
which proves the claim.
As before, let Cmax be a largest connected component of Gn (choosing the component
containing the lowest label if there is more than one such component). A union bound and
the previous lemma immediately imply an upper bound on the size of Cmax in the subcritical
case.
Proof of Theorem 6.4.1 Let again c = (1 + κ)I
−1
λ
for κ > 0. By a union bound and sym￾metry,
Pn,pn
[|Cmax| ≥ c log n] = Pn,pn
[∃v, |Cv
| > c log n]
≤ n Pn,pn
[|C1| ≥ c log n] . (6.4.19)
By Lemma 6.4.6,
Pn,pn
[|Cmax| ≥ c log n] = O(n · n
−(1+κ)
) = O(n
−κ
) → 0
as n → +∞.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Pres376 Branching Processes
In fact we prove below that the largest component is indeed of size roughly I
−1
λ
log n. But
first we turn to the supercritical regime.
Supercritical regime: two phases
Applying the Poisson branching process approximation in the supercritical regime gives the
following.
Lemma 6.4.7 (Supercritical regime: extinction). Let Gn ∼ Gn,pn where pn =
λ
n
with λ > 1.
and let Cv be the connected component of v ∈ [n]. Let ζλ be the unique solution in (0, 1) to
the fixed point equation
1 − e
−λζ = ζ .
For any κ > 0,
Pn,pn

|Cv
| ≥ (1 + κ)I
−1
λ
log n

= ζλ + O

log2
n
n

.
Note the small but critical difference with Lemma 6.4.6: this time the branching process can
survive. This happens with probability ζλ by extinction theory (Theorem 6.1.6). In that case,
we will need further arguments to nail down the cluster size. Observe also that the result
holds for a fixed vertex v – and therefore does not yet tell us about the largest cluster. We
come back to the latter in the next subsection.
Proof of Lemma 6.4.7 We adapt the proof of Lemma 6.4.6, beginning with (6.4.16), which
recall states
P [Wλ ≥ kn] = P [Wλ = +∞] +
X
t≥kn
1
t
P
"Xt
i=1
X

i = t − 1
#
,
where the X

i
s are i.i.d. Poi(λ). When λ > 1, P[Wλ = +∞] = ζλ, where ζλ > 0 is the
survival probability of the branching process by Example 6.1.10. As to the second term,
using (6.4.2) for λ > 1,
X
t≥kn
1
t
P
"Xt
i=1
X

i = t − 1
#
≤
X
t≥kn
P
"Xt
i=1
X

i ≤ t
#
≤
X
t≥kn
exp (−tIλ)
≤ C exp (−Iλkn) (6.4.20)
for a constant C > 0.
Now let c = (1 + κ)I
−1
λ
for κ > 0. By Lemma 6.4.3,
Pn,pn
[|Cv
| ≥ c log n] = P [Wλ ≥ c log n] + O

log2
n
n

. (6.4.21)
By (6.4.16) and (6.4.20),
P [Wλ ≥ c log n] = ζλ + O (exp (−cIλ log n))
= ζλ + O(n
−(1+κ)
). (6.4.22)
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.4 F Finale: The Phase Transition of the Erd ˝os–Rényi Model 377
Combining (6.4.21) and (6.4.22), for any κ > 0,
Pn,pn
[|Cv
| ≥ c log n] = ζλ + O

log2
n
n

, (6.4.23)
as claimed.
Recall that the Poisson branching process approximation was based on the fact that the
degree of a vertex is well approximated by a Poisson distribution. When the exploration
process goes on for too long however (i.e., when kn is large), this approximation is not as
accurate because of a saturation effect: at each step of the exploration, we uncover edges
to the neutral vertices (which then become active); and, because an Erdos–Rényi graph has ˝
a finite pool of vertices from which to draw these edges, as the number of neutral vertices
decreases so does the expected number of uncovered edges. Instead, we use the following
lemma which explicitly accounts for the dwindling size of Nt
. Roughly speaking, we model
the set of neutral vertices as a process that discards a fraction pn of its current set at each
time step (i.e., those neutral vertices with an edge to the current explored vertex).
Lemma 6.4.8 Let Gn ∼ Gn,pn
, where pn =
λ
n
with λ > 0 and let Cv be the connected
component of v ∈ [n]. Let Yt ∼ Bin(n − 1, 1 − (1 − pn)
t
). Then, for any t,
Pn,pn
[|Cv
| = t] ≤ P[Yt = t − 1].
Proof We work with neutral vertices. By (6.4.4) and Lemma 6.2.1, for any t,
Pn,pn
[|Cv
| = t] = Pn,pn
[τ0 = t] ≤ Pn,pn
[Nt = n − t]. (6.4.24)
Recall that N0 = n − 1 and
Nt = Nt−1 − 1{Nt−1<n−(t−1)}
X
Nt−1
i=1
It,i
.
It is easier to consider the process without the indicator as it has a simple distribution. Define
N
0
0
:= n − 1 and
N
0
t
:= N
0
t−1 −
N
0 Xt−1
i=1
It,i
,
and observe that Nt ≥ N
0
t
for all t, as the two processes agree up to time τ0 at which point Nt
stays fixed. The interpretation of N
0
t
is straightforward: starting with n − 1 vertices, at each
time each remaining vertex is discarded with probability pn. Hence, the number of surviving
vertices at time t has distribution
N
0
t ∼ Bin(n − 1, (1 − pn)
t
),
by the independence of the steps. Arguing as in (6.4.24),
Pn,pn
[|Cv
| = t] ≤ Pn,pn
[N
0
t = n − t]
= Pn,pn
[(n − 1) − N
0
t = t − 1]
= P[Yt = t − 1],
which concludes the proof.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press378 Branching Processes
The previous lemma gives the following additional bound on the cluster size in the super￾critical regime. Together with Lemma 6.4.7 it shows that, when |Cv
| > c log n, the cluster
size is in fact linear in n with high probability. We will have more to say about the largest
cluster in the next subsection.
Lemma 6.4.9 (Supercritical regime: saturation). Let Gn ∼ Gn,pn
, where pn =
λ
n
with λ > 1
and let Cv be the connected component of v ∈ [n]. Let ζλ be the unique solution in (0, 1) to
the fixed point equation
1 − e
−λζ = ζ .
For any α < ζλ and any δ > 0, there exists κδ,α > 0 large enough so that
Pn,pn

(1 + κδ,α)I
−1
λ
log n ≤ |Cv
| ≤ αn

= O(n
−(1+δ)
). (6.4.25)
Proof By Lemma 6.4.8,
Pn,pn
[|Cv
| = t] ≤ P[Yt = t − 1] ≤ P[Yt ≤ t],
where Yt ∼ Bin(n − 1, 1 − (1 − pn)
t
). Roughly, the right-hand side is negligible until the
mean µt
:= (n − 1)(1 − (1 − λ/n)
t
) is of the order of t. Let ζλ be as above, and recall that it
is a solution to
1 − e
−λζ − ζ = 0.
Note in particular that when t = ζλn,
µt = (n − 1)(1 − (1 − λ/n)
ζλn
) ≈ n(1 − e
−λζλ
) = ζλn = t.
Let α < ζλ.
For any t ∈ [c log n, αn], by the Chernoff bound for Poisson trials (Theorem 2.4.7 (ii)(b)),
P[Yt ≤ t] ≤ exp 
−
µt
2

1 −
t
µt
2
!
. (6.4.26)
For t/n ≤ α < ζλ, using 1 − x ≤ e
−x
for x ∈ (0, 1) (see Exercise 1.16), there is γα > 1 such
that
µt ≥ (n − 1)(1 − e
−λ(t/n)
)
= t

n − 1
n

1 − e
−λ(t/n)
t/n
≥ t

n − 1
n

1 − e
−λα
α
≥ γαt,
for n large enough, where we used that 1 − e
−λx
is increasing in x on the third line and that
1 − e
−λx − x > 0 for 0 < x < ζλ on the fourth line (as can be checked by computing the first
and second derivatives). Plugging this back into (6.4.26), we get
P[Yt ≤ t] ≤ exp 
−t
(
γα
2

1 −
1
γα
2
)!.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.4 F Finale: The Phase Transition of the Erd ˝os–Rényi Model 379
Therefore,
Xαn
t=c log n
Pn,pn
[|Cv
| = t] ≤
Xαn
t=c log n
P[Yt ≤ t]
≤
X
+∞
t=c log n
exp 
−t
(
γα
2

1 −
1
γα
2
)!
= O
 
exp 
−c log n
(
γα
2

1 −
1
γα
2
)!!.
Taking κ > 0 large enough proves (6.4.25).
6.4.3 Concentration of Cluster Size: Second Moment Bounds
To characterize the size of the largest cluster in the supercritical case, we use Chebyshev’s
inequality. We also use a related second moment argument to give a lower bound on the
largest cluster in the subcritical regime.
Supercritical regime: giant component
Assume λ > 1. Our goal is to characterize the size of the largest component. We do this
by bounding what is not in it (i.e., intuitively those vertices whose exploration process goes
extinct). For δ > 0 and α < ζλ, let κδ,α be as defined in Lemma 6.4.9. Set
kn
:= (1 + κδ,α)I
−1
λ
log n and ¯kn := αn.
We call a vertex v such that |Cv
| ≤ kn
a small vertex. SMALL
Let VERTEX
Sk
:=
X
v∈[n]
1{|Cv|≤k}
.
It will also be useful to work with
Bk = n − Sk =
X
v∈[n]
1{|Cv|>k}
.
The quantity Skn
is the number of small vertices. By Lemma 6.4.7, its expectation is
En,pn
[Skn
] = n(1 − Pn,pn

|Cv
| > kn

) = (1 − ζλ)n + O
￾
log2
n

. (6.4.27)
Using Chebyshev’s inequality (Theorem 2.1.2), we prove that Skn
is concentrated.
Lemma 6.4.10 (Concentration of Skn
). For any γ ∈ (1/2, 1) and δ < 2γ − 1,
Pn,pn
[|Skn − (1 − ζλ)n| ≥ n
γ
] = O(n
−δ
).
Lemma 6.4.10, which is proved below, leads to our main result in the supercritical case: the GIANT
existence of the giant component, a unique cluster C COMPONENT max of size linear in n.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Pres380 Branching Processes
Proof of Theorem 6.4.2 Take α ∈ (ζλ/2, ζλ) and let kn
,
¯kn, and γ be as above. Let B1,n :=
{|Bkn − ζλn| ≥ n
γ
}. Because γ < 1, the event B
c
1,n
implies that
X
v∈[n]
1{|Cv|>kn
} = Bkn > ζλn − n
γ ≥ 1,
for n large enough. That is, there is at least one “large” cluster of size > kn
. In turn, that
implies
|Cmax| ≤ Bkn
,
since there are at most Bkn
vertices in that large cluster.
Let B2,n := {∃v, |Cv
| ∈ [kn
,
¯kn]}. If B
c
2,n
holds, in addition to B
c
1,n
, then
|Cmax| ≤ Bkn = B¯kn
,
since there is no cluster whose size falls in [kn
,
¯kn]. Moreover, there is equality across the
last display if there is a unique cluster of size greater than ¯kn.
This is indeed the case under B
c
1,n ∩B
c
2,n
: if there were two distinct clusters of size ¯kn, then
since 2α > ζλ we would have for n large enough
Bkn = B¯kn > 2¯kn = 2αn > ζλn + n
γ
,
a contradiction. Hence we have proved that under B
c
1,n ∩ B
c
2,n
,
|Cmax| = Bkn = B¯kn
.
Take δ < 2γ − 1. Applying Lemmas 6.4.9 and 6.4.10,
P[B1,n ∪ B2,n] ≤ O(n
−δ
) + n · O(n
−(1+δ)
) = O(n
−δ
),
which concludes the proof.
It remains to prove Lemma 6.4.10.
Proof of Lemma 6.4.10 As mentioned above, we use Chebyshev’s inequality. Hence our
main task is to bound the variance of Skn
.
Our starting point is the following expression for the second moment
En,pn
[S
2
k
] =
X
u,v∈[n]
Pn,pn
[|Cu| ≤ k, |Cv
| ≤ k]
=
X
u,v∈[n]

Pn,pn
[|Cu| ≤ k, |Cv
| ≤ k, u ↔ v]
+ Pn,pn
[|Cu| ≤ k, |Cv
| ≤ k, u = v]
	
, (6.4.28)
where u ↔ v indicates that u and v are in the same connected component.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.4 F Finale: The Phase Transition of the Erd ˝os–Rényi Model 381
To bound the first term in (6.4.28), we note that u ↔ v implies that Cu = Cv
. Hence,
X
u,v∈[n]
Pn,pn
[|Cu| ≤ k, |Cv
| ≤ k, u ↔ v] =
X
u,v∈[n]
Pn,pn
[|Cu| ≤ k, v ∈ Cu]
=
X
u,v∈[n]
En,pn
[1{|Cu|≤k}1{v∈Cu}]
=
X
u∈[n]
En,pn

1{|Cu|≤k}
X
v∈[n]
1{v∈Cu}


=
X
u∈[n]
En,pn
[|Cu|1{|Cu|≤k}]
= n En,pn
[|C1|1{|C1|≤k}]
≤ nk. (6.4.29)
To bound the second term in (6.4.28), we sum over the size of Cu and note that, conditioned
on {|Cu| = `, u = v}, the size of Cv has the same distribution as the unconditional size of C1
in a Gn−`,pn
random graph, that is,
Pn,pn
[|Cv
| ≤ k | |Cu| = `, u = v] = Pn−`,pn
[|C1| ≤ k].
Observe that the probability on the right-hand side is increasing in ` (as can be seen, for
example, by coupling; see below for a related argument). Hence,
X
u,v∈[n]
X
`≤k
Pn,pn
[|Cu| = `, |Cv
| ≤ k, u = v]
=
X
u,v∈[n]
X
`≤k
Pn,pn
[|Cu| = `, u = v] Pn,pn
[|Cv
| ≤ k | |Cu| = `, u = v]
=
X
u,v∈[n]
X
`≤k
Pn,pn
[|Cu| = `, u = v] Pn−`,pn
[|Cv
| ≤ k]
≤
X
u,v∈[n]
X
`≤k
Pn,pn
[|Cu| = `] Pn−k,pn
[|Cv
| ≤ k]
=
X
u,v∈[n]
Pn,pn
[|Cu| ≤ k] Pn−k,pn
[|Cv
| ≤ k].
To get a bound on the variance of Sk
, we need to relate this last expression to (En,pn
[Sk ])2
,
where we will use that
En,pn
[Sk ] = En,pn


X
v∈[n]
1{|Cv|≤k}

 =
X
v∈[n]
Pn,pn
[|Cv
| ≤ k]. (6.4.30)
We define
1k
:= Pn−k,pn
[|C1| ≤ k] − Pn,pn
[|C1| ≤ k].
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press382 Branching Processes
Then, plugging this back above, we get
X
u,v∈[n]
X
`≤k
Pn,pn
[|Cu| = `, |Cv
| ≤ k, u = v]
≤
X
u,v∈[n]
Pn,pn
[|Cu| ≤ k](Pn,pn
[|Cv
| ≤ k] + 1k )
≤ (En,pn
[Sk ])2 + n
2
|1k
|
by (6.4.30). It remains to bound 1k
.
We use a coupling argument. Let H ∼ Gn−k,pn
and construct H
0 ∼ Gn,pn
in the following
manner: let H
0
coincide with H on the first n−k vertices, and then pick the rest of the edges
independently. Then clearly 1k ≥ 0 since the cluster of 1 in H
0
includes the cluster of 1
in H. In fact, 1k
is the probability that under this coupling the cluster of 1 has at most k
vertices in H but not in H
0
. That implies in particular that at least one of the vertices in the
cluster of 1 in H is connected to a vertex in {n−k +1, . . . , n}. Hence, by a union bound over
those k
2 potential edges,
1k ≤ k
2
pn
and
X
u,v∈[n]
Pn,pn
[|Cu| ≤ k, |Cv
| ≤ k, u ↔ v] ≤ (En,pn
[Sk ])2 + λnk2
. (6.4.31)
Combining (6.4.29) and (6.4.31), we get
Var[Sk ] ≤ 2λnk2
.
The result follows from (6.4.27) and Chebyshev’s inequality
P[|Skn − (1 − ζλ)n| ≥ n
γ
]
≤ P[|Skn − En,pn
[Skn
]| ≥ n
γ − C log2
n]
≤
2λnk2
n
(n
γ − C log2
n)
2
≤
2λn(1 + κδ,α)
2
I
−2
λ
log2
n
C0n
2γ
≤ C
00n
−δ
for constants C,C
0
,C
00 > 0 and n large enough, where we used that 2γ > 1 and δ <
2γ − 1.
Subcritical regime: second moment argument
A second moment argument also gives a lower bound on the size of the largest component
in the subcritical case. We proved in Theorem 6.4.1 that, when λ < 1, the probability of
observing a connected component of size larger than I
−1
λ
log n is vanishingly small. In the
other direction, we get:
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.4 F Finale: The Phase Transition of the Erd ˝os–Rényi Model 383
Theorem 6.4.11 (Subcritical regime: lower bound on the largest cluster). Let Gn ∼ Gn,pn
,
where pn =
λ
n
with λ ∈ (0, 1). For all κ ∈ (0, 1),
Pn,pn

|Cmax| ≤ (1 − κ)I
−1
λ
log n

= o(1).
Proof Recall that
Bk =
X
v∈[n]
1{|Cv|>k}
.
It suffices to prove that with probability 1−o(1) we have Bk > 0 when k = (1−κ)I
−1
λ
log n.
To apply the second moment method (Theorem 2.3.2), we need an upper bound on the
second moment of Bk and a lower bound on its first moment. The following lemma is closely
related to Lemma 6.4.10. Exercise 6.12 asks for a proof.
Lemma 6.4.12 (Second moment of Xk ). Assume λ < 1. There is a constant C > 0 such
that
En,pn
[B
2
k
] ≤ (En,pn
[Bk ])2 + Cnke−kIλ ∀k ≥ 0.
Lemma 6.4.13 (First moment of Xk ). Let kn = (1 − κ)I
−1
λ
log n. Then, for any β ∈ (0, κ) we
have that
En,pn
[Bkn
] = (n
β
)
for n large enough.
Proof By Lemma 6.4.3,
En,pn
[Bkn
] = n Pn,pn
[|C1| > kn]
≥ n P[Wλ > kn] − O
￾
dkne
2

. (6.4.32)
Once again, we use the random-walk representation of the total progeny of a branching
process (Theorem 6.2.6). In contrast to the proof of Lemma 6.4.6, we need a lower bound
this time. For this purpose, we use the explicit expression for the law of the total progeny Wλ
from Example 6.2.7:
P[Wλ > kn] =
X
t>kn
1
t
e
−λt
(λt)
t−1
(t − 1)!
.
Using Stirling’s formula (see Appendix A) and (6.4.3), we note that
1
t
e
−λt
(λt)
t−1
(t − 1)!
= e
−λt
(λt)
t−1
t!
= e
−λt
(λt)
t
λt(t/e)
t
√
2πt(1 + o(1))
=
1 − o(1)
λ
√
2πt
3
exp (−tλ + t log λ + t)
=
1 − o(1)
λ
√
2πt
3
exp (−tIλ).
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Pres384 Branching Processes
Hence, for any ε > 0,
P[Wλ > kn] ≥ λ
−1X
t>kn
exp (−t(Iλ + ε))
=  (exp (−kn(Iλ + ε)))
for n large enough. For any β ∈ (0, κ), taking ε small enough we have
n P[Wλ > kn] =  (n exp (−kn(Iλ + ε)))
= 
￾
exp ￾
{1 − (1 − κ)I
−1
λ
(Iλ + ε)}log n

= (n
β
).
Plugging this back into (6.4.32) gives
En,pn
[Bkn
] = (n
β
),
which proves the claim.
We return to the proof of Theorem 6.4.11. Let again kn = (1 − κ)I
−1
λ
log n. By the second
moment method and Lemmas 6.4.12 and 6.4.13,
Pn,pn
[Bkn > 0] ≥
(EBkn
)
2
E[B
2
kn
]
≥

1 +
O(nkne
−knIλ
)
(n
2β
)
−1
=

1 +
O(nkne
(κ−1) log n
)
(n
2β
)
−1
=

1 +
O(knn
κ
)
(n
2β
)
−1
→ 1
for β close enough to κ. That proves the claim.
6.4.4 Critical Case via Martingales
It remains to consider the critical case, that is, when λ = 1. As it turns out, the model goes
through a “double jump”: as λ crosses 1, the largest cluster size goes from order log n to
order n
2/3
to order n. Here we use martingale methods to show the following.
Theorem 6.4.14 (Critical case: upper bound on the largest cluster). Let Gn ∼ Gn,pn
, where
pn =
1
n
. For all κ > 1,
Pn,pn

|Cmax| > κn
2/3

≤
C
κ
3/2
for some constant C > 0.
Remark 6.4.15 One can also derive a lower bound on the probability that |Cmax| > κn
2/3
for
some κ > 0 [ER60]. Exercise 6.20 provides a sketch based on counting tree components;
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Pre6.4 F Finale: The Phase Transition of the Erd ˝os–Rényi Model 385
the combinatorial approach has the advantage of giving insights into the structure of the
graph (see [Bol01] for more on this). See also [NP10] for a martingale proof of the lower
bound as well as a better upper bound.
The key technical bound is the following.
Lemma 6.4.16 Let Gn ∼ Gn,pn
, where pn =
1
n
and let Cv be the connected component of
v ∈ [n]. There are constants c, c
0 > 0 such that for all k ≥ c,
Pn,pn
[|Cv
| > k] ≤
c
0
√
k
.
Before we establish the lemma, we prove the theorem assuming it.
Proof of Theorem 6.4.14 Recall that
Bk =
X
v∈[n]
1{|Cv|>k}
.
Take
kn := κn
2/3
.
By Markov’s inequality (Theorem 2.1.1) and Lemma 6.4.16,
Pn,pn
[|Cmax| > kn] ≤ Pn,pn

Bkn > kn

≤
En,pn

Bkn

kn
=
n Pn,pn
[|Cv
| > kn]
kn
≤
nc0
k
3/2
n
≤
C
κ
3/2
for some constant C > 0.
It remains to prove the lemma.
Proof of Lemma 6.4.16 Once again, we use the exploration process defined in Section 6.4.2
started at v. Let (Ft) be the corresponding filtration and let At = |At
| be the size of the active
set.
Domination by a martingale Recalling (6.4.6), we define
Mt
:= Mt−1 +

−1 + eXt

, (6.4.33)
with M0 := 1 and (eXt) are i.i.d. Bin(n, 1/n). We couple (At) and (Mt) through (6.4.7) by
letting
eXt =
Xn
i=1
It,i
.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press386 Branching Processes
In particular, Mt ≥ At for all t.
Furthermore, we have
E[Mt
| Ft−1] = Mt−1 − 1 + n
1
n
= Mt−1.
So (Mt) is a martingale. We define the stopping time
τ˜0 := inf{t ≥ 0: Mt = 0}.
Recalling that
τ0 = inf{t ≥ 0: At = 0} = |Cv
|,
by Lemma 6.2.1, we have τ˜0 ≥ τ0 = |Cv
| almost surely. So
Pn,pn
[|Cv
| > k] ≤ P[τ˜0 > k].
The tail of τ˜0 To bound the tail of τ˜0, we introduce a modified stopping time. For h > 0, let
τ
0
h
:= inf{t ≥ 0: Mt = 0 or Mt ≥ h}.
We will use the inequality
P[τ˜0 > k] = P[Mt > 0, ∀t ≤ k] ≤ P[τ
0
h > k] + P[Mτ
0
h ≥ h],
and we will choose h below to minimize the rightmost expression (or, more specifically,
an upper bound on it). The rest of the analysis is similar to the gambler’s ruin problem in
Example 3.1.41, with some slight complications arising from the fact that the process is not
nearest-neighbor.
We note that by the exponential tail of hitting times on finite state spaces (Lemma 3.1.25),
the stopping time τ
0
h
is almost surely finite and, in fact, has a finite expectation. By two
applications of Markov’s inequality,
P[Mτ
0
h ≥ h] ≤
E[Mτ
0
h
]
h
and
P[τ
0
h > k] ≤
Eτ
0
h
k
.
So it remains to bound the expectations on the right-hand sides.
Bounding EMτ
0
h
and Eτ
0
h To compute EMτ
0
h
, we use the optional stopping theorem in the
uniformly bounded case (Theorem 3.1.38 (ii)) to the stopped process (Mt∧τ
0
h
) (which is also
a martingale by Lemma 3.1.37) to get that
E[Mτ
0
h
] = E[M0] = 1.
We conclude that
P[Mτ
0
h ≥ h] ≤
1
h
. (6.4.34)
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.4 F Finale: The Phase Transition of the Erd ˝os–Rényi Model 387
To compute Eτ
0
h
, we use a different martingale (adapted from Example 3.1.31), specifi￾cally
Lt
:= M2
t − σ
2
t,
where we let σ
2
:= n
1
n
￾
1 −
1
n

=
￾
1 −
1
n

, which is ≥
1
2 when n ≥ 2. To see that (Lt) is a
martingale, note that by taking out what is known (Lemma B.6.13) and using the fact that
(Mt) is itself a martingale
E[Lt
| Ft−1] = E[(Mt−1 + (Mt − Mt−1))2 − σ
2
t | Ft−1]
= E[M2
t−1 + 2Mt−1(Mt − Mt−1) + (Mt − Mt−1)
2 − σ
2
t | Ft−1]
= M2
t−1 + 2Mt−1 · 0 + σ
2 − σ
2
t
= Lt−1.
By Lemma 3.1.37, the stopped process (Lt∧τ
0
h
) is also a martingale; and it has bounded
increments since
|L(t+1)∧τ
0
h − Lt∧τ
0
h
| ≤ |M2
(t+1)∧τ
0
h
− M2
t∧τ
0
h
| + σ
2
≤


(−1 + eXt+1)
2 + 2h| − 1 + eXt+1|

 + σ
2
≤ n
2 + 2hn + 1.
We use the optional stopping theorem in the bounded increments case (Theorem 3.1.38 (iii))
on (Lt∧τ
0
h
) to get
E[M2
τ
0
h
− σ
2
τ
0
h
] = E[M2
τ
0
h
] − σ
2Eτ
0
h = 1.
After rearranging (6.4.35),
Eτ
0
h ≤
1
σ
2
E[M2
τ
0
h
] ≤ 2 E[M2
τ
0
h
], (6.4.35)
where we used the fact that σ
2 ≥ 1/2.
To bound E[M2
τ
0
h
], we need to control by how much the process “overshoots” h. A stochas￾tic domination argument gives the desired bound; Exercise 6.21 asks for a proof.
Lemma 6.4.17 (Overshoot bound). Let f be an increasing function and W ∼ Bin(n, 1/n).
Then,
E[ f (Mτ
0
h − h) | Mτ
0
h ≥ h] ≤ E[ f (W)].
The lemma implies that
E[M2
τ
0
h
| Mτ
0
h ≥ h] = E[(Mτ
0
h − h)
2 + 2(Mτ
0
h − h)h + h
2
| Mτ
0
h ≥ h]
≤ (σ
2 + 1) + 2h + h
2
≤ 4h
2
.
Plugging back into (6.4.35) gives
Eτ
0
h ≤ 2

1
h
E[M2
τ
0
h
| Mτ
0
h ≥ h]

≤ 8h,
where we used (6.4.34).
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Pre388 Branching Processes
Putting everything together Finally, take h :=
q
k
8
. Putting everything together,
Pn,pn
[|Cv
| > k] ≤ P[τ˜0 > k] ≤ P[τ
0
h > k] + P[Mτ
0
h ≥ h] ≤
8h
k
+
1
h
= 2
r
8
k
.
That concludes the proof.
6.4.5 F Encore: Random Walk on the Erd ˝os–Rényi Graph
So far in this section we have used techniques from all chapters of the book – with the
exception of Chapter 5. Not to be outdone, we discuss one last result that will make use of
spectral techniques. We venture a little further down the evolution of the Erdos–Rényi graph ˝
model to the connected regime. Specifically, recall from Section 2.3.2 that Gn = (Vn, En) ∼
Gn,pn
is connected with probability 1 − o(1) when npn = ω(log n).
We show in that regime that lazy simple random walk (Xt) on Gn “mixes fast.” Recall
from Example 1.1.29 that, when the graph is connected, the corresponding transition matrix
P is reversible with respect to the stationary distribution
π(v) :=
δ(v)
2|En|
,
where δ(v) is the degree of v. For a fixed ε > 0, the mixing time (see Definition 1.1.35) is
tmix(ε) = inf{t ≥ 0: d(t) ≤ ε},
where
d(t) = sup
x∈Vn
kP
t
(x, ·) − π(·)kTV.
By convention, we let tmix(ε) = +∞ if the graph is not connected. Our main result is the
following.
Theorem 6.4.18 (Mixing on a connected Erdos–Rényi graph). ˝ Let Gn ∼ Gn,pn with npn =
ω(log n). With probability 1 − o(1), the mixing time is O(log n).
Edge expansion We use Cheeger’s inequality (Theorem 5.3.5) which, recall, states that
γ ≥
82
∗
2
,
where γ is the spectral gap of P (see Definition 5.2.11) and
8∗ = min 
8E(S; c, π): S ⊆ V, 0 < π(S) ≤
1
2

is the edge expansion constant (see Definition 5.3.2) with
8E(S; c, π) =
c(S, S
c
)
π(S)
for a subset of vertices S ⊆ Vn. Here, for a pair of vertices x, y connected by an edge,
c(x, y) = π(x)P(x, y) =
δ(x)
2|En|
1
δ(x)
=
1
2|En|
.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press6.4 F Finale: The Phase Transition of the Erd ˝os–Rényi Model 389
Hence
c(S, S
c
) =
|E(S, S
c
)|
2|En|
,
where E(S, S
c
) is the set of edges between S and S
c
. Similarly,
π(S) =
P
x∈S
δ(x)
2|En|
.
The numerator is referred to as the volume of S and we use the notation vol(S) =
P
x∈S
δ(x).
So
c(S, S
c
)
π(S)
=
|E(S, S
c
)|
vol(S)
. (6.4.36)
Because the random walk is lazy, the spectral gap is equal to the absolute spectral gap
(see Definition 5.2.11), and as a consequence the relaxation time (see Definition 5.2.12) is
trel = γ
−1
.
Using Theorem 5.2.14, we get
tmix(ε) ≤ log
1
επmin
trel ≤ log
1
επmin
2
82
∗
, (6.4.37)
where
πmin = min
x
π(x) = min
x
δ(x)
2|En|
=
minx δ(x)
P
y
δ(y)
.
So our main task is to bound δ(x) and |E(S, S
c
)| with high probability. We do this next.
Bounding the degrees In fact, we have already done half the work. Indeed, in Exam￾ple 2.4.18 we studied the maximum degree of Gn
Dn = max
v∈Vn
δ(v)
in the regime npn = ω(log n). We showed that for any ζ > 0 as n → +∞,
P
h
|Dn − npn| ≤ 2
p
(1 + ζ )npn log n
i
→ 1.
The proof of that result actually shows something stronger: all degrees satisfy the inequality
simultaneously, that is,
P
h
∀v ∈ Vn, |δ(v) − npn| ≤ 2
p
(1 + ζ )npn log n
i
= 1 − o(1). (6.4.38)
We will use the fact that 2√
(1 + ζ )npn log n = o(npn) when npn = ω(log n). In essence, all
degrees are roughly npn. That implies the following claims.
Lemma 6.4.19 (Bounds on stationary distribution and volume). The following hold with
probability 1 − o(1).
(i) The smallest stationary probability satisfies
πmin ≥
1 − o(1)
n
.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press390 Branching Processes
(ii) For any set of vertices S ⊆ Vn with |S| > 2n/3, we have
π(S) >
1
2
.
(iii) For any set of vertices S ⊆ Vn with s := |S|,
vol(S) = snpn(1 + o(1)).
Proof We assume that the event in (6.4.38) holds.
For (i), that means
πmin ≥
npn − 2
√
(1 + ζ )npn log n
n(npn + 2
√
(1 + ζ )npn log n)
=
1
n
(1 − o(1)),
when npn = ω(log n).
For (ii), we get
π(S) =
P
x∈S
δ(x)
P
x∈Vn
δ(x)
≥
|S|(npn − 2
√
(1 + ζ )npn log n)
n(npn + 2
√
(1 + ζ )npn log n)
>
2
3
(1 − o(1)).
Finally, (iii) follows similarly.
Bounding the cut size An application of Bernstein’s inequality (Theorem 2.4.17) gives the
following bound.
Lemma 6.4.20 (Bound on the edge expansion). With probability 1 − o(1),
8∗ = (1).
Proof By the definition of 8∗ and Lemma 6.4.19 (ii), we can restrict ourselves to sets S of
size at most 2n/3. Let S be such a set with s = |S|. Then, |E(S, S
c
)| is Bin(s(n − s), pn). By
Bernstein’s inequality with c = 1 and νi = pn(1 − pn),
Pn,pn
[|E(S, S
c
)| ≤ s(n − s)pn − β] ≤ exp
−
β
2
4s(n − s)pn(1 − pn)

,
for β ≤ s(n − s)pn(1 − pn). We take β =
1
2
s(n − s)pn and get
Pn,pn

|E(S, S
c
)| ≤
1
2
s(n − s)pn

≤ exp
−
s(n − s)pn
16(1 − pn)

.
By a union bound over all sets of size s and using the fact that ￾
n
s

≤ (
ne
s
)
s
(see Appen￾dix A), there is a constant C > 0 such that
Pn,pn

∃S, |S| = s, |E(S, S
c
)| ≤
1
2
s(n − s)pn

≤

n
s

exp
−
s(n − s)pn
16(1 − pn)

≤ exp 
−s
npn
48
+ slog(ne/s)

≤ exp (−Csnpn),
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University PresExercises 391
for n large enough, where we also used that n − s ≥ n/3 and npn = ω(log n). Summing over
s gives, for a constant C
0 > 0,
Pn,pn

∃S, 1 ≤ |S| ≤ 2n/3, |E(S, S
c
)| ≤
1
2
|S|(n − |S|)pn

≤ C
0
exp (−Cnpn),
which goes to 0 as n → +∞.
Using (6.4.36) and Lemma 6.4.19 (iii), any set S such that |E(S, S
c
)| >
1
2
|S|(n − |S|)pn
has edge expansion
8E(S; c, π) ≥
1
2
|S|(n − |S|)pn
|S|npn(1 + o(1))
≥
1
6
(1 − o(1)).
That proves the claim.
Proof of the theorem Finally, we are ready to prove the main result.
Proof of Theorem 6.4.18 Plugging Lemma 6.4.19 (i) and Lemma 6.4.20 into (6.4.37) gives
tmix(ε) ≤ log
1
επmin
2
82
∗
≤ C
00 log(ε
−1
n(1 + o(1))) = O(log n)
for some constant C
00 > 0.
Remark 6.4.21 A mixing time of O(log n) in fact holds for lazy simple random walk on Gn,pn
when pn = λ log(n)/n with λ > 1 [CF07]. See also [Dur06, section 6.5]. Mixing time on the
giant component has also been studied. See, for example, [FR08, BKW14, DKLP11].
Exercises
Exercise 6.1 (Galton–Watson process: subcritical case). We use Markov’s inequality to an￾alyze the subcritical case.
(i) Let (Zt) be a Galton–Watson process with offspring distribution mean m < 1. Use
Markov’s inequality (Theorem 2.1.1) to prove that extinction occurs almost surely.
(ii) Prove the equivalent result in the multitype case, that is, prove (6.1.8).
Exercise 6.2 (Galton–Watson process: geometric offspring). Let (Zt) be a Galton–Watson
branching process with geometric offspring distribution (started at 0), that is, pk = p(1−p)
k
for all k ≥ 0, for some p ∈ (0, 1). Let q := 1 − p, let m be the mean of the offspring
distribution, and let Wt = m
−tZt
.
(i) Compute the probability generating function f of {pk }k≥0 and the extinction prob￾ability η := ηp as a function of p.
(ii) If G is a 2 × 2 matrix, define
G(s) :=
G11s + G12
G21s + G22
.
Show that G(H(s)) = (GH)(s).
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press392 Branching Processes
(iii) Assume m 6= 1. Use (ii) to derive
ft(s) =
pmt
(1 − s) + qs − p
qmt
(1 − s) + qs − p
.
Deduce that when m > 1,
E[exp(−λW∞)] = η + (1 − η)
(1 − η)
λ + (1 − η)
.
(iv) Assume m = 1. Show that
ft(s) =
t − (t − 1)s
t + 1 − ts
,
and deduce that
E[e
−λZt/t
| Zt > 0] →
1
1 + λ
.
Exercise 6.3 (Supercritical branching process: infinite line of descent). Let (Zt) be a super￾critical Galton–Watson branching process with offspring distribution {pk }k≥0. Let η be the
extinction probability and define ζ := 1 − η. Let Z
∞
t
be the number of individuals in the
tth generation with an infinite line of descent, that is, whose descendant subtree is infinite.
Denote by S the event of non-extinction of (Zt). Define p
∞
0
:= 0 and
p
∞
k
:= ζ
−1X
j≥k

j
k

η
j−k
ζ
k
pj
.
(i) Show that {p
∞
k
}k≥0 is a probability distribution and compute its expectation.
(ii) Show that for any k ≥ 0,
P[Z
∞
1 = k | S] = p
∞
k
.
(Hint: Condition on Z1.)
(iii) Show by induction on t that, conditioned on non-extinction, the process (Z
∞
t
)
has the same distribution as a Galton–Watson branching process with offspring
distribution {p
∞
k
}k≥0.
Exercise 6.4 (Multitype branching processes: a special case). Extend Lemma 6.1.20 to the
case S
(u) = 0. (Hint: Show that Ut = Z0u for all t almost surely.)
Exercise 6.5 (Galton–Watson: inverting history). Let
H = (X1, . . . , Xτ0
)
be the history (see Section 6.2) of the Galton–Watson process (Zi). Write Zi as a function of
H, for all i.
Exercise 6.6 (Spitzer’s lemma). Prove Theorem 6.2.5.
Exercise 6.7 (Sum of Poisson). Let Q1 and Q2 be independent Poisson random variables
with respective means λ1 and λ2. Show by direct computation of the convolution that the
sum Q1 + Q2 is Poisson with mean λ1 + λ2. (Hint: Recall that P[Q1 = k] = e
−λ1λ
k
1
/k! for
all k ∈ Z+.)
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University PressExercises 393
Exercise 6.8 (Percolation on bounded-degree graphs). Let G = (V, E) be a countable graph
such that all vertices have degree bounded by b+1 for b ≥ 2. Let 0 be a distinguished vertex
in G. For bond percolation on G, prove that
pc(G) ≥ pc(bTb),
by bounding the expected size of the cluster of 0. (Hint: Consider self-avoiding paths started
at 0.)
Exercise 6.9 (Percolation on bTb: critical exponent of θ(p)). Consider bond percolation on
the rooted infinite b-ary tree bTb with b > 2. For ε ∈ [0, 1 −
1
b
] and u ∈ [0, 1], define
h(ε, u) := u −
￾￾1 −
1
b − ε

(1 − u) +
1
b + ε
b
.
(i) Show that there is a constant C > 0 not depending on ε, u such that




h(ε, u) − bεu +
b − 1
2b
u
2




≤ C(u
3 ∨ εu
2
).
(ii) Use (i) to prove that
lim
p↓pc(bTb)
θ(p)
(p − pc(bTb))
=
2b
2
b − 1
.
Exercise 6.10 (Percolation on bT2: higher moments of |C0|). Consider bond percolation on
the rooted infinite binary tree bT2. For density p <
1
2
, let Zp be an integer-valued random
variable with distribution
Pp[Zp = `] =
` Pp[|C0| = `]
Ep|C0|
∀` ≥ 1.
(i) Using the explicit formula for Pp[|C0| = `] derived in Section 6.2.4, show that
for all 0 < a < b < +∞,
Pp
"
Zp
(1/4)( 1
2 − p)
−2
∈ [a, b]
#
→ C
Z b
a
x
−1/2
e
−x
dx,
as p ↑
1
2
, for some constant C > 0.
(ii) Show that for all k ≥ 2, there is Ck > 0 such that
lim
p↑pc(bT2)
Ep|C0|
k
(pc(bT2) − p)
−1−2(k−1)
= Ck
.
(iii) What happens when p ↓ pc(bT2)?
Exercise 6.11 (Branching process approximation: improved bound). Let pn =
λ
n with λ >
0. Let Wn,pn
, respectively Wλ, be the total progeny of a branching process with offspring
distribution Bin(n, pn), respectively Poi(λ).
(i) Show that
|P[Wn,pn ≥ k] − P[Wλ ≥ k]|
≤ max{P[Wn,pn ≥ k, Wλ < k], P[Wn,pn < k, Wλ ≥ k]}.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Pre394 Branching Processes
(ii) Couple the two processes step-by-step and use (i) to show that
|P[Wn,pn ≥ k] − P[Wλ ≥ k]| ≤
λ
2
n
X
k−1
i=1
P[Wλ ≥ i].
Exercise 6.12 (Subcritical Erdos–Rényi: second moment). Prove Lemma ˝ 6.4.12.
Exercise 6.13 (Random binary search tree: property (BST)). Show that the (BST) property
is preserved by the algorithm described at the beginning of Section 6.3.1.
Exercise 6.14 (Random binary search tree: limit). Consider equation (6.3.1).
(i) Show that there exists a unique solution greater than 1.
(ii) Prove that the expression on the left-hand side is strictly decreasing at that solution.
Exercise 6.15 (Random binary search tree: height is well defined). Let T be an infinite
binary tree. Assign an independent U[0, 1] random variable Zv
to each vertex v in T , set
Sρ = n and then recursively from the root down
Sv
0 := bSvZvc and Sv
00 := bSv(1 − Zv)c,
where v
0
and v
00 are the left and right descendants of v in T .
(i) Show that, for any v, it holds that Sv
0 + Sv
00 = Sv − 1 almost surely provided Sv ≥ 1.
(ii) Show that, for any v, there is almost surely a descendant w of v (not necessarily
immediate) such that Sw = 1.
(iii) Let
Hn = max {h: ∃v ∈ Vh, Sv = 1},
where Vh is the set of vertices of T at topological distance h from the root. Show
that Hn ≤ n.
Exercise 6.16 (Ising vs. CFN). Let Th be a rooted complete binary tree with h levels. Fix
0 < p < 1/2. Assign to each vertex v a state σv ∈ {+1, −1} at random according to the CFN
model described in Section 6.3.2. Show that this distribution is equivalent to a ferromagnetic
Ising model on Th and determine the inverse temperature β in terms of p. (Hint: Write the
distribution of the states under the CFN model as a product over the edges.)
Exercise 6.17 (Monotonicity of kµ
+
h − µ
−
h
kTV). Let µ
+
h
, µ
−
h
be as in Section 6.3.2. Show
that
kµ
+
h+1 − µ
−
h+1
kTV ≤ kµ
+
h − µ
−
h
kTV.
(Hint: Use the Markovian nature of the process.)
Exercise 6.18 (Unsolvability: recursion). Prove Lemma 6.3.15.
Exercise 6.19 (Cayley’s formula). Let (Zt) be a Poisson branching process with offspring
mean 1 started at Z0 = 1 and let T be the corresponding Galton–Watson tree. Let W be the
total of size of the progeny, that is, the number of vertices in T. Recall from Example 6.2.7
that
P[W = n] =
n
n−1
e
−n
n!
.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University PressExercises 395
(i) Given W = n, label the vertices of T uniformly at random with the integers 1, . . . , n.
Show that every rooted labeled tree on n vertices arises with probability e
−n
/n!.
(Hint: Label the vertices as you grow the tree and observe that a lot of terms cancel
out or simplify.)
(ii) Derive Cayley’s formula: the number of labeled trees on n vertices is n
n−2
.
Exercise 6.20 (Critical regime: tree components). Let Gn ∼ Gn,pn
, where pn =
1
n
.
(i) Let γn,k be the expected number of isolated tree components of size k in Gn.
Justify the formula
γn,k =

n
k

k
k−2

1
n
k−1 
1 −
1
n
k(n−k)+(
k
2)−(k−1)
.
(Hint: We did a related calculation in Section 2.3.2.)
(ii) Show that if k = ω(1) and k = o(n
3/4
), then
γn,k ∼ n
k
−5/2
√
2π
exp
−
k
3
6n
2

.
(iii) Conclude that for 0 < δ < 1 the expectation of U, the number of isolated tree
components of size in [(δn)
2/3
, n
2/3
] is (δ
−1
) as δ → 0.
(iv) For 1 ≤ k1 ≤ k2 ≤ n − k1, let σn,k1,k2 be the expected number of pairs of isolated
tree components where the first one has size k1 and the second one has size k2.
Justify the formula
σn,k1,k2 =

n
k1

k
k1−2
1

1
n
k1−1 
1 −
1
n
k1(n−k1)+(
k1
2 )−(k1−1)
×

n − k1
k2

k
k2−2
2

1
n
k2−1 
1 −
1
n
k2(n−(k1+k2))+(
k2
2 )−(k2−1)
,
and show that
σn,k1,k2 ≤ γn,k1γn,k2
.
(Hint: You may need to prove that, for 0 < a ≤ 1 ≤ b, it holds that 1 − ab ≤
(1 − a)
b
.)
(v) Prove that Var[U] = O(E[U]). (Hint: Use (2.1.6), (iv), and (ii).)
Exercise 6.21 (Critical regime: overshoot bound). The goal of this exercise is to prove
Lemma 6.4.17. We use the notation of Section 6.4.4.
(i) Let W, Z ∼ Bin(n, 1/n) and 0 ≤ r ≤ n. Show that W − r conditioned on W ≥ r
is stochastically dominated by Z. (Hint: Use the representation of W as a sum of
indicators. Thinking of the partial sums as a Markov chain, consider the first time
it reaches r.)
(ii) Show that Mτ
0
h − h conditioned on Mτ
0
h ≥ h is stochastically dominated by Z from
(i). (Hint: By the tower property, it suffices to show that
P[Mτ
0
h − h ≥ z| τ
0
h = `, M`−1 = h − r, M` ≥ h] ≤ P[Z ≥ z],
for the relevant `,r,z.)
(iii) Use (ii) to prove Lemma 6.4.17.
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University Press396 Branching Processes
Bibliographic Remarks
Section 6.1 See [Dur10, section 5.3.4] for a quick introduction to branching processes. A
more detailed overview relating to its use in discrete probability can be found in [vdH17,
chapter 3]. The classical reference on branching processes is [AN04]. The Kesten–Stigum
Theorem is due to Kesten and Stigum [KS66b]. Our proof of a weaker version with the
second moment condition follows [Dur10, Example 5.4.3]. Section 6.1.4 is based loosely
on [AN04, chapter V]. A proof of Theorem 6.1.18 can be found in [Har63]. A good refer￾ence for the Perron–Frobenius Theorem (Theorem 6.1.17 as well as more general versions)
is [HJ13, chapter 8]. The central limit theorem for ρ ≥ λ
2
referred to at the end of Sec￾tion 6.1.4 is due to Kesten and Stigum [KS66a, KS67]. The critical percolation threshold for
percolation on Galton–Watson trees is due to R. Lyons [Lyo90].
Section 6.2 The exploration process in Section 6.2.1 dates back to [ML86] and [Kar90].
The hitting-time theorem (Theorem 6.2.5) in the case ` = 1 was first proved in [Ott49]. For
alternative proofs, see, for example, [vdHK08] or [Wen75]. Spitzer’s combinatorial lemma
(Lemma 6.2.8) is from [Spi56]. See also [Fel71, section XII.6]. The presentation in Sec￾tion 6.2.4 follows [vdH10]. See also [Dur85].
Section 6.3 Section 6.3.1 follows [Dev98, section 2.1] from the excellent volume
[HMRAR98]. Section 6.3.2 is partly a simplified version of [BCMR06]. Further applications
in phylogenetics, specifically to the sample complexity of phylogeny inference algorithms,
can be found in, for example, [Mos04, Mos03, Roc10, DMR11, RS17]. The reconstruction
problem also has applications in community detection [MNS15b]. See [Abb18] for a survey.
Section 6.4 The phase transtion of the Erdos–Rényi graph model was first studied in [ ˝ ER60].
For much more, see, for example, [vdH17, chapter 4], [JLR11, chapter 5], and [Bol01, chap￾ter 6]. In particular, a central limit theorem for the giant component, proved by several
authors, including Martin–Löf [ML98], Pittel [Pit90], and Barraez, Boucheron, and de la
Vega [BBFdlV00], is established in [vdH17, section 4.5]. Section 6.4.4 is based on [NP10].
See also [Per09, sections 2 and 3]. Much more is known about the critical regime; see, for
example, [Ald97, Bol84, Lu90, LuPW94]. Section 6.4.5 is based partly on [Dur06, section
6.5]. For a lot more on random walk on random graphs (not just Erdos–Rényi), see [ ˝ Dur06,
chapter 6]. For more on the spectral properties of random graphs, see [CL06].
https://doi.org/10.1017/9781009305129.007 Published online by Cambridge University PressAppendix A
Useful Combinatorial Formulas
Recall the following facts about factorials and binomial coefficients:
n
n
e
n−1
≤ n! ≤
n
n+1
e
n−1
,
n
k
k
k
≤

n
k

≤
e
kn
k
k
k
,
(x + y)
n =
Xn
k=0

n
k

x
k
y
n−k
,
X
d
k=0

n
k

≤
en
d
d
,
n! ∼ √
2πn
n
e
n
,

2n
n

= (1 + o(1))
4
n
√
πn
,
and
log
n
k

= (1 + o(1))nH(k/n),
where H(p) := −p log p − (1 − p) log(1 − p). The third one is the binomial theorem. The
fifth one is Stirling’s formula.
397
https://doi.org/10.1017/9781009305129.008 Published online by Cambridge University PressAppendix B
Measure-Theoretic Foundations
This appendix contains relevant background on measure-theoretic probability. We follow
closely the highly recommended [Wil91]. Missing proofs (and a lot more details and exam￾ples) can be found there. Another excellent textbook on this topic is [Dur10].
B.1 Probability Spaces
Let S be a set. In general it turns out that we cannot assign a probability to every subset of S.
Here we discuss “well-behaved” collections of subsets. First an algebra on S is a collection
of subsets stable under finitely many set operations.
Definition B.1.1 (Algebra on S). A collection 60 of subsets of S is an algebra on S if the
following conditions hold:
(i) S ∈ 60;
(ii) F ∈ 60 implies Fc ∈ 60;
(iii) F, G ∈ 60 implies F ∪ G ∈ 60.
This, of course, implies that the empty set as well as all pairwise intersections are also in 60.
The collection 60 is an actual algebra (i.e., a vector space with a bilinear product) with the
symmetric difference as its “sum,” the intersection as its “product” and the underlying field
being the field with two elements.
Example B.1.2 On R, sets of the form
[
k
i=1
(ai
, bi],
where the union is disjoint with k < +∞ and −∞ ≤ ai ≤ bi ≤ +∞ form an algebra. J
Finite set operations are not enough for our purposes. For instance, we want to be able to
take limits. A σ-algebra is stable under countably many set operations.
Definition B.1.3 (σ-algebra on S). A collection 6 of subsets of S is a σ-algebra on S (or
σ-field on S) if
(i) S ∈ 6;
(ii) F ∈ 6 implies Fc ∈ 6;
(iii) Fn ∈ 6 ∀n implies ∪nFn ∈ 6.
398
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University PressB.1 Probability Spaces 399
Example B.1.4 2
S
is a trivial example. J
To give a non-trivial example, we need the following definition. We begin with a lemma.
Lemma B.1.5 (Intersection of σ-algebras). Let Fi
, i ∈ I, be σ-algebras on S, where I is
arbitrary. Then, ∩iFi
is a σ-algebra.
Proof We prove only one of the conditions. The other ones are similar. Suppose A ∈ Fi for
all i. Then, A
c
is in Fi for all i since each Fi
is itself a σ-algebra.
Definition B.1.6 (σ-algebra generated by C). Let C be a collection of subsets of S. Then
we let σ(C) be the smallest σ-algebra containing C, defined as the intersection of all such
σ-algebras (including in particular 2
S
).
Example B.1.7 The smallest σ-algebra containing all open sets in R, denoted B(R), is
called the Borel σ-algebra. This is a non-trivial σ-algebra in the sense that it can be proved
that there exist subsets of R that are not in B, but that any “reasonable” set is in B. In
particular, it contains the algebra in Example B.1.2. J
Example B.1.8 The σ-algebra generated by the algebra in Example B.1.2 is B(R). This
follows from the fact that all open sets of R can be written as a countable union of open
intervals. (Indeed, for x ∈ O an open set, let Ix be the largest open interval contained in O
and containing x. If Ix ∩ Iy 6= ∅, then Ix = Iy by maximality (i.e., take the union). Then,
O = ∪xIx and there are only countably many disjoint ones because each one contains a
rational.) J
We now define measures.
Definition B.1.9 (Additivity and σ-additivity). A non-negative set function on an algebra
60
µ0 : 60 → [0, +∞]
is additive if
(i) µ0(∅) = 0;
(ii) F, G ∈ 60 with F ∩ G = ∅ implies µ0(F ∪ G) = µ0(F) + µ0(G).
Moreover, µ0 is said to be σ-additive if condition (ii) is true for any countable collection
of disjoint sets whose union is in 60, that is, if Fn ∈ 60, n ≥ 0, all pairwise disjoint with
∪nFn ∈ 60, then µ0(∪nFn) =
P
n µ0(Fn).
Example B.1.10 For the algebra in the Example B.1.2, the set function
λ0
 [
k
i=1
(ai
, bi]
!
=
X
k
i=1
(bi − ai)
is additive. (In fact, it is also σ-additive. We will show this later.) J
Definition B.1.11 (Measure space). Let 6 be a σ-algebra on S. Then (S, 6) is a measurable
space. A σ-additive function µ on 6 is called a measure and (S, 6,µ) is called a measure
space.
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University Press400 Measure-Theoretic Foundations
PROBABILITY Definition B.1.12 (Probability space). If (, F, P) is a measure space with P() = 1, then
SPACE P is called a probability measure and (, F, P) is called a probability space (or probability
triple).
EVENTS The sets in F are referred to as events.
To define a measure on B(R) we need the following tools from abstract measure theory.
Theorem B.1.13 (Caratheodory’s extension theorem). Let 60 be an algebra on S and let
6 = σ(60). If µ0 is σ-additive on 60, then there exists a measure µ on 6 that agrees with
µ0 on 60.
If in addition µ0 is finite, the next lemma implies that the extension is unique.
Lemma B.1.14 (Uniqueness of extensions). Let I be a π-system on S, that is, a family of
subsets closed under finite intersections, and let 6 = σ(I). If µ1,µ2 are finite measures on
(S, 6) that agree on I, then they agree on 6.
Example B.1.15 The sets (−∞, x] for x ∈ R form a π-system generating B(R). That is,
B(R) is the smallest σ-algebra containing that π-system. J
Finally, we can define Lebesgue measure. We start with (0, 1] and extend to R in the
obvious way. We need the following lemma.
Lemma B.1.16 (σ-additivity of λ0). Let λ0 be the set function defined above, restricted to
(0, 1]. Then λ0 is σ-additive.
Definition B.1.17 (Lebesgue measure on unit interval). The unique extension of λ0 to (0, 1]
is denoted λ and is called Lebesgue measure.
B.2 Random Variables
Let (S, 6,µ) be a measure space and let B = B(R).
Definition B.2.1 (Measurable function). Suppose h: S → R and define
h
−1
(A) = {s ∈ S : h(s) ∈ A}.
The function h is 6-measurable if h−1
(B) ∈ 6 for all B ∈ B. We denote by m6 (resp.,
(m6)
+, b6) the 6-measurable functions (resp., that are non-negative, bounded).
In the probabilistic case:
RANDOM Definition B.2.2 A random variable is a measurable function on a probability space (, F, P).
VARIABLE
The behavior of a random variable is characterized by its distribution function.
Definition B.2.3 (Distribution function). Let X be a random variable on a probability space
(, F, P). The law of X is
LX = P ◦ X
−1
,
DISTRIBUTION which is a probability measure on (R,B). By Lemma B.1.14, LX is determined by the distri￾FUNCTION bution function (DF) of X :
FX (x) = P[X ≤ x], x ∈ R.
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University PressB.2 Random Variables 401
Example B.2.4 The distribution function of a constant random variable is a jump of size 1
at the value it takes almost surely. The distribution function of a random variable with law
equal to Lebesgue measure on (0, 1] is
FX (x) =



x, x ∈ (0, 1],
0, x ≤ 0,
1, x > 1.
We refer to such as random variable as a uniform random variable over (0, 1]. J
Distribution functions are characterized by a few simple properties.
Proposition B.2.5 Suppose F = FX is the distribution function of a random variable X on
(, F, P). Then the following hold:
(i) F is non-decreasing;
(ii) limx→+∞ F(x) = 1, limx→−∞ F(x) = 0;
(iii) F is right-continuous.
Proof The first property follows from the monotonicity of probability measure (which it￾self follows immediately from σ-additivity).
For the second property, note that the limit exists by the first property. The value of the
limit follows from the following important lemma.
Lemma B.2.6 (Monotone convergence properties of measures). Let (S, 6,µ) be a measure
space.
(i) If Fn ∈ 6, n ≥ 1, with Fn ↑ F, then µ(Fn) ↑ µ( F).
(ii) If Gn ∈ 6, n ≥ 1, with Gn ↓ G and µ(Gk ) < +∞ for some k, then µ(Gn) ↓ µ(G).
Proof Clearly, F = ∪nFn ∈ 6. For n ≥ 1, write Hn = Fn\Fn−1 (with F0 = ∅). Then by
disjointness,
µ(Fn) =
X
k≤n
µ(Hk ) ↑
X
k<+∞
µ(Hk ) = µ( F).
The second statement is similar.
Similarly, for the third property, by Lemma B.2.6 again,
P[X ≤ xn] ↓ P[X ≤ x]
if xn ↓ x.
It turns out that the properties above characterize distribution functions in the following
sense.
Theorem B.2.7 (Skorokhod representation). Let F satisfy the three properties above. Then
there is a random variable X on
(, F, P) = ((0, 1],B(0, 1], λ)
with distribution function F. The law of X is called the Lebesgue–Stieltjes measure
associated to F.
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University Press402 Measure-Theoretic Foundations
The result says that all real random variables can be generated from uniform random
variables over (0, 1].
Proof Assume first that F is continuous and strictly increasing. Define X(ω) = F
−1
(ω) for
all ω ∈ . Then, ∀x ∈ R,
P[X ≤ x] = P[{ω: F
−1
(ω) ≤ x}] = P[{ω: ω ≤ F(x)}] = F(x).
In general, let
X(ω) = inf{x : F(x) ≥ ω}.
It suffices to prove that
X(ω) ≤ x ⇐⇒ ω ≤ F(x).
The ⇐ direction is clear by definition of X. On the other hand, by the right-continuity of F,
we have that ω ≤ F(X(ω)). Therefore, by monotonicity of F,
X(ω) ≤ x ⇒ ω ≤ F(X(ω)) ≤ F(x).
That proves the claim.
Turning measurability on its head, we get the following important definition.
Definition B.2.8 Let (, F, P) be a probability space. Let Yγ , γ ∈ 0, be a collection of
maps from  to R. We let
σ(Yγ , γ ∈ 0)
be the smallest σ-algebra on which the Yγ s are measurable.
In a sense, the above σ-algebra corresponds to “the partial information available when the
Yγ s are observed.”
Example B.2.9 Suppose we flip two unbiased coins and let X be the number of heads
observed. Then, denoting heads by H and tails by T,
σ(X) = σ({{HH},{HT, TH},{TT}}),
which is coarser than the full σ-algebra 2. J
Note that h
−1 preserves all set operations. For example, h
−1
(A ∪ B) = h
−1
(A) ∪ h
−1
(B).
This gives the following important lemma.
Lemma B.2.10 (Sufficient condition for measurability). Suppose C ⊆ B with σ(C) = B.
Then, h−1
: C → 6 implies h ∈ m6. That is, it suffices to check measurability on a collection
generating B.
Proof Let E be the sets such that h
−1
(B) ∈ 6. By the observation before the statement, E
is a σ-algebra. But C ⊆ E, which implies σ(C) ⊆ E by minimality.
As a consequence we get the following properties of measurable functions.
Proposition B.2.11 (Properties of measurable functions). Let h, hn, n ≥ 1, be in m6 and
f ∈ mB.
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University PressB.3 Independence 403
(i) f ◦ h ∈ m6.
(ii) If S is a topological space and h is continuous, then h is B(S)-measurable, where B(S)
is generated by the open sets of S.
(iii) The function g : S → R is in m6 if for all c ∈ R,
{g ≤ c} ∈ 6.
(iv) ∀α ∈ R, h1 + h2, h1h2, αh ∈ m6.
(v) inf hn, sup hn, lim inf hn, lim sup hn are in m6.
(vi) The set
{s: lim hn(s) exists in R}
is measurable.
Proof We sketch the proof of a few of them.
(ii) This follows from Lemma B.2.10 by taking C as the open sets of R.
(iii) Similarly, take C to be the sets of the form (−∞, c].
(iv) This follows from (iii). For example note that, writing the left-hand side as h1 > c−h2,
{h1 + h2 > c} = ∪q∈Q[{h1 > q} ∩ {q > c − h2}],
which is a countable union of measurable sets by assumption.
(v) Note that
{sup hn ≤ c} = ∩n{hn ≤ c}.
furthermore, note that lim inf is the sup of an inf.
B.3 Independence
Let (, F, P) be a probability space.
Definition B.3.1 (Independence). Sub-σ-algebras G1, G2, . . . of F are independent if, for INDEPENDENCE
all Gi ∈ Gi
, i ≥ 1, and distinct i1, . . . , in, we have
P[Gi1 ∩ · · · ∩ Gin
] =
Yn
j=1
P[Gij
].
Specializing to events and random variables:
Definition B.3.2 (Independent random variables). Random variables X1, X2, . . . are inde￾pendent if the σ-algebras σ(X1), σ(X2), . . . are independent.
Definition B.3.3 (Independent events). Events E1, E2, . . . are independent if the σ-algebras
Ei = {∅, Ei
, E
c
i
, }, i ≥ 1,
are independent.
Recall the more familiar definitions.
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University Press404 Measure-Theoretic Foundations
Theorem B.3.4 (Independent random variables: familiar definition). Random variables X ,
Y are independent if and only if for all x, y ∈ R,
P[X ≤ x, Y ≤ y] = P[X ≤ x] P[Y ≤ y].
Theorem B.3.5 (Independent events: familiar definition). Events E1, E2 are independent if
and only if
P[E1 ∩ E2] = P[E1] P[E2].
The proofs of these characterizations follow immediately from the following lemma.
Lemma B.3.6 (Independence and π-systems). Suppose that G and H are sub-σ-algebras
and that I and J are π-systems such that
σ(I) = G, σ(J ) = H.
Then G and H are independent if and only if I and J are as well, that is,
P[I ∩ J] = P[I] P[J] ∀I ∈ I, J ∈ J .
Proof Suppose I and J are independent. For fixed I ∈ I, the measures P[I ∩ H] and
P[I] P[H] are equal for H ∈ J and have total mass P[I] < +∞. By the Uniqueness of
Extensions Lemma (Lemma B.1.14) the above measures agree on σ(J ) = H.
Repeat the argument. Fix H ∈ H. Then the measures P[G ∩ H] and P[G] P[H] agree on
I and have total mass P[H] < +∞. Therefore, they must agree on σ(I) = G.
We give a standard construction of an infinite sequence of independent random variables
with prescribed distributions.
Let (, F, P) = ((0, 1],B(0, 1], λ) and for ω ∈  consider the binary expansion
ω = 0.ω1ω2 . . .
(For dyadic rationals, use the all-1 ending and note that the dyadic rationals have measure 0
BERNOULLI by countability.) This construction produces a sequence of independent so-called Bernoulli
TRIALS trials. That is, under λ, each bit is Bernoulli(1/2) and any finite collection is independent.
To get two independent uniform random variables, consider the following construction:
U1 = 0.ω1ω3ω5 . . . ,
U2 = 0.ω2ω4ω6 . . .
Let A1 (resp. A2) be the π-system consisting of all finite intersections of events of the form
{ωi ∈ Hi} for odd i (resp. even i). By Lemma B.3.6, the σ-fields σ(A1) and σ(A2) are
independent.
More generally, let
V1 = 0.ω1ω3ω6 . . . ,
V2 = 0.ω2ω5ω9 . . . ,
V3 = 0.ω4ω8ω13 . . .
.
.
. =
.
.
.
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University PressB.3 Independence 405
that is, fill up the array diagonally. By the argument above, the Vis are independent and
Bernoulli(1/2).
Finally, let µn, n ≥ 1, be a sequence of probability measures with distribution functions
Fn, n ≥ 1. For each n, define
Xn(ω) = inf{x : Fn(x) ≥ Vn(ω)}.
By the (proof of the) Skorokhod Representation (Theorem B.2.7), Xn has distribution func￾tion Fn.
Definition B.3.7 (I.i.d. random variables). A sequence of independent random variables
(Xn) as above is independent and identically distributed (i.i.d.) if Fn = F for some n.
Alternatively, we have the following more general result.
Theorem B.3.8 (Kolmogorov’s extension theorem). Suppose we are given probability mea￾sures µn on (R
n
,B(R
n
)) that are consistent, that is,
µn+1((a1, b1] × · · · × (an, bn] × R) = µn((a1, b1] × · · · × (an, bn]).
Then there exists a unique probability measure P on (R
N
, RN
) with
P[ω: ωi ∈ (ai
, bi], 1 ≤ i ≤ n] = µn((a1, b1] × · · · × (an, bn]).
Here RN
is the product σ-algebra, that is, the σ-algebra generated by finite-dimensional
rectangles.
Next, we discuss a first non-trivial result about independent sequences.
Definition B.3.9 (Tail σ-algebra). Let X1, X2, . . . be random variables on a probability space
(, F, P). Define
T =
\
n≥1
Tn,
where
Tn = σ(Xn+1, Xn+2, . . .).
As an intersection of σ-algebras, T is a σ-algebra. It is called the tail σ-algebra of the
sequence (Xn).
Intuitively, an event is in the tail if changing a finite number of values does not affect its
occurence.
Example B.3.10 If Sn =
P
k≤n Xk
, then
{lim
n
Sn exists} ∈ T ,
{lim sup
n
n
−1
Sn > 0} ∈ T ,
but
{lim sup
n
Sn > 0} ∈/ T .
J
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University Press406 Measure-Theoretic Foundations
Theorem B.3.11 (Kolmogorov’s 0-1 law). Let (Xn) be a sequence of independent random
variables with tail σ-algebra T . Then T is P-trivial, that is, for all A ∈ T we have either
P[A] = 0 or 1.
Proof Let Xn = σ(X1, . . . , Xn). Note that Xn and Tn are independent. Moreover, since
T ⊆ Tn we have that Xn is independent of T . Now let
X∞ = σ(Xn, n ≥ 1).
Note that
K∞ =
[
n≥1
Xn
is a π-system generating X∞. Therefore, by Lemma B.3.6, X∞ is independent of T . But
T ⊆ X∞ and therefore T is independent of itself! Hence, if A ∈ T ,
P[A] = P[A ∩ A] = P[A]
2
,
which can occur only if P[A] ∈ {0, 1}.
B.4 Expectation
Let (S, 6,µ) be a measure space. We denote by 1A the indicator of a set A, that is,
1A(s) =
(
1 if s ∈ A,
0 o.w.
Definition B.4.1 (Simple functions). A simple function is a function of the form
f =
Xm
k=1
ak1Ak
,
where ak ∈ [0, +∞] and Ak ∈ 6 for all k. We denote the set of all such functions by SF+
.
We define the integral of f by
µ( f ) :=
Xm
k=1
akµ(Ak ) ≤ +∞.
We also write µf = µ( f ).
The following is left as a (somewhat tedious but) immediate exercise.
Proposition B.4.2 Let f , g ∈ SF+
.
(i) If µ(f 6= g) = 0, then µf = µg. (Hint: Rewrite f and g over the same disjoint sets.)
(ii) For all c ≥ 0, f + g, cf ∈ SF+
and
µ(f + g) = µf + µg, µ(cf ) = cµf .
(Hint: This one is obvious by definition.)
(iii) If f ≤ g, then µf ≤ µg. (Hint: Show that g − f ∈ SF+
and use linearity.)
The main definition and theorem of integration theory follows.
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University PressB.4 Expectation 407
Definition B.4.3 (Non-negative functions). Let f ∈ (m6)
+. Then the integral of f is defined
by
µ( f ) = sup{µ(h): h ∈ SF+
, h ≤ f }.
Again we also write µf = µ( f ).
Theorem B.4.4 (Monotone convergence theorem). If fn, f ∈ (m6)
+, n ≥ 1, with fn ↑ f ,
then
µfn ↑ µf .
Many theorems in integration follow from the monotone convergence theorem. In that
context, the following approximation is useful.
Definition B.4.5 (Staircase function). For f ∈ (m6)
+ and r ≥ 1, the rth staircase function
α
(r)
is
α
(r)
(x) =



0 if x = 0,
(i − 1)2−r
if (i − 1)2−r < x ≤ i2
−r ≤ r,
r if x > r.
We let f (r) = α
(r)
(f ). Note that f (r) ∈ SF+
and f (r) ↑ f as r → +∞.
Using the previous definition, we get for example the following properties.
Proposition B.4.6 Let f , g ∈ (m6)
+.
(i) If µ(f 6= g) = 0, then µ( f ) = µ(g).
(ii) For all c ≥ 0, f + g, cf ∈ (m6)
+ and
µ(f + g) = µf + µg, µ(cf ) = cµf .
(iii) If f ≤ g, then µf ≤ µg.
For a function f , let f
+ and f
− be the positive and negative parts of f , that is,
f
+
(s) = f (s) ∨ 0, f
−
(s) = (−f (s)) ∨ 0.
Note that | f | = f
+ + f
−. Finally, we define
µ( f ) := µ(f
+
) − µ(f
−
),
provided µ(f
+) + µ(f
−) < +∞, in which case we write f ∈ L
1
(S, 6,µ). Proposition B.4.6
can be generalized naturally to this definition. Moreover, we have the following.
Theorem B.4.7 (Dominated convergence theorem). If fn, f ∈ m6, n ≥ 1, with fn(s) → f (s)
for all s ∈ S, and there is a non-negative function g ∈ L
1
(S, 6,µ) such that | fn| ≤ g, then
µ(| fn − f |) → 0,
and in particular
µfn → µf
as n → ∞.
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University Press408 Measure-Theoretic Foundations
More generally, for 0 < p < +∞, the space L
p
(S, 6,µ) contains all functions f : S → R
such that k f kp < +∞, where
k f kp := µ(| f |
p
)
1/p
up to equality almost everywhere. We state the following results without proof.
Theorem B.4.8 (Hölder’s inequality). Let 1 < p, q < +∞ such that p−1 + q
−1 = 1. Then,
for any f ∈ L
p
(S, 6,µ) and g ∈ L
q
(S, 6,µ), it holds that fg ∈ L
1
(S, 6,µ) and further
k fgk1 ≤ k f kpkgkq.
CAUCHY– The case p = q = 2 is known as the Cauchy–Schwarz inequality (or Schwarz inequality).
SCHWARZ
INEQUALITY Theorem B.4.9 (Minkowski’s inequality). Let 1 < p < +∞. Then, for any f , g ∈ L
p
(S, 6,µ),
it holds that f + g ∈ L
p
(S, 6,µ) and furthermore,
k f + gkp ≤ k f kp + kgkp.
Theorem B.4.10 (L
p
completeness). Let 1 ≤ p < +∞. If (fn)n in Lp
(S, 6,µ) is Cauchy,
that is,
sup
n,m≥k
k fn − fmkp → 0,
as k → +∞, then there exists f ∈ L
p
(S, 6,µ) such that
k fn − f kp → 0
as n → +∞.
We can now define the expectation. Let (, F, P) be a probability space.
Definition B.4.11 (Expectation). If X ≥ 0 is a random variable then we define the expecta￾tion of X , denoted by E[X], as the integral of X over P. More generally, if
E|X| = E[X
+
] + E[X
−
] < +∞,
we let
E[X] = E[X
+
] − E[X
−
].
INTEGRABLE We denote the set of all such integrable random variables (up to equality almost surely) by
L
1
(, F, P).
The properties of the integral for non-negative functions (see Proposition B.4.6) extend to
the expectation.
Proposition B.4.12 Let X, X1, X2 be random variables in L1
(, F, P).
(LIN) If a1, a2 ∈ R, then E[a1X1 + a2X2] = a1E[X1] + a2E[X2].
(POS) If X ≥ 0, then E[X] ≥ 0.
One useful implication of (POS) is that |X| − X ≥ 0 so that E[X] ≤ E|X| and, by applying
the same argument to −X, we have further |E[X]| ≤ E|X|.
The monotone convergence theorem (Theorem B.4.4) implies the following results. We
first need a definition.
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University PressB.4 Expectation 409
Definition B.4.13 (Convergence almost sure). We say that Xn → X almost surely (a.s.) if
P[Xn → X] = 1.
Proposition B.4.14 Let X, Y, Xn, n ≥ 1, be random variables in L1
(, F, P).
(MON) If 0 ≤ Xn ↑ X , then E[Xn] ↑ E[X] ≤ +∞.
(FATOU) If Xn ≥ 0, then E[lim infn Xn] ≤ lim infn E[Xn].
(DOM) If |Xn| ≤ Y, n ≥ 1, with E[Y] < +∞ and Xn → X a.s., then
E|Xn − X| → 0,
and, hence,
E[Xn] → E[X].
(Indeed,
|E[Xn] − E[X]| = |E[Xn − X]|
= |E[(Xn − X)
+
] − E[(Xn − X)
−
]|
≤ E[(Xn − X)
+
] + E[(Xn − X)
−
]
= E|Xn − X|.)
(SCHEFFE) If Xn → X a.s. and E|Xn| → E|X|, then
E|Xn − X| → 0.
(BDD) If Xn → X a.s. and |Xn| ≤ K < +∞ for all n, then
E|Xn − X| → 0.
Proof We only prove (FATOU). To use (MON) we write the lim inf as an increasing limit.
Letting Zk = infn≥k Xn, we have
lim inf
n
Xn =↑ lim
k
Zk
,
so that by (MON)
E[lim inf
n
Xn] =↑ lim
k
E[Zk ].
For n ≥ k we have Xn ≥ Zk so that E[Xn] ≥ E[Zk ], hence
E[Zk ] ≤ inf
n≥k
E[Xn].
Finally, we get
E[lim inf
n
Xn] ≤↑ lim
k
inf
n≥k
E[Xn].
The following inequality is often useful. We give an example below.
Theorem B.4.15 (Jensen’s inequality). Let h: G → R be a convex function on an open JENSEN’S
interval G such that P[X ∈ G] = 1 and X, h(X) ∈ L INEQUALITY 1
(, F, P), then
E[h(X)] ≥ h(E[X]).
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University Press410 Measure-Theoretic Foundations
The L
p norm defined earlier applies to random variables as well. That is, for p ≥ 1, we let
kXkp = E[|X|
p
]
1/p
and denote by L
p
(, F, P) the collection of random variables X (up to
almost sure equality) such that kXkp < +∞. Jensen’s inequality (Theorem B.4.15) implies
the following relationship.
Lemma B.4.16 (Monotonicity of norms). For 1 ≤ p ≤ r < +∞, we have kXkp ≤ kXkr
.
Proof For n ≥ 0, let
Xn = (|X| ∧ n)
p
.
Take h(x) = x
r/p
, which is convex on (0, +∞). Then, by Jensen’s inequality,
(E[Xn])r/p ≤ E[(Xn)
r/p
] = E[(|X| ∧ n)
r
] ≤ E[|X|
r
].
Take n → ∞ and use (MON).
This latter inequality is useful among other things to argue about the convergence of expec￾tations. We say that Xn converges to X∞ in L
p
if kXn − X∞kp → 0. By the previous lemma,
convergence on L
r
implies convergence in L
p
for r ≥ p ≥ 1. Further we have:
Lemma B.4.17 (Convergence of expectations). Assume Xn, X∞ ∈ L
1
. Then,
kXn − X∞k1 → 0
implies
E[Xn] → E[X∞].
Proof Note that
|E[Xn] − E[X∞]| ≤ E|Xn − X∞| → 0.
So, a fortiori, convergence in L
p
implies convergence of expectations.
Square integrable random variables have a nice geometry by virtue of forming a Hilbert
space.
Definition B.4.18 (Square integrable variables). Recall that L2
(, F, P) denotes the set of
SQUARE all square integrable random variables (up to equality almost surely), that is, those X with
INTEGRABLE E[X
2
] < +∞. For X, Y ∈ L
2
(, F, P), define the inner product hX, Yi := E[XY]. Then the
L
2 norm is kXk2 =
√
hX, Xi.
Theorem B.4.19 (Cauchy–Schwarz inequality). If X, Y ∈ L
2
(, F, P), then XY ∈ L
1
(, F, P) and
E|XY| ≤ p
E[X2
]E[Y
2
],
or put differently,
|hX, Yi| ≤ kXk2kYk
2
2
.
Theorem B.4.20 (Parallelogram law). If X, Y ∈ L
2
PARALLELOG- (, F, P), then
RAM LAW
kX + Yk
2
2 + kX − Yk
2
2 = 2kXk
2
2 + 2kYk
2
2
.
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University PressB.5 Fubini’s Theorem 411
B.5 Fubini’s Theorem
We now define product measures and state (without proof) Fubini’s Theorem.
Definition B.5.1 (Product σ-algebra). Let (S1, 61) and (S2, 62) be measure spaces. Let S =
S1 × S2 be the Cartesian product of S1 and S2. For i = 1, 2, let πi
: S → Si be the projection
on the ith coordinate, that is,
πi(s1,s2) = si
.
The product σ-algebra 6 = 61 × 62 is defined as
6 = σ(π1, π2).
In other words, it is the smallest σ-algebra that makes coordinate maps measurable. It is
generated by sets of the form
π
−1
1
(B1) = B1 × S2, π
−1
2
(B2) = S1 × B2, B1 ∈ 61, B2 ∈ 62.
Theorem B.5.2 (Fubini’s Theorem). For F ∈ 6, let f = 1F and define FUBINI’S
THEOREM
µ( f ) :=
Z
S1
I
f
1
(s1)µ1(ds1) =
Z
S2
I
f
2
(s2)µ2(ds2),
where
I
f
1
(s1) :=
Z
S2
f (s1,s2)µ2(ds2) ∈ b61
and
I
f
2
(s2) :=
Z
S1
f (s1,s2)µ1(ds1) ∈ b62.
(The equality and inclusions above are part of the statement.) The set function µ is a measure
on (S, 6) called the product measure of µ1 and µ2 and we write µ = µ1 × µ2 and
(S, 6,µ) = (S1, 61,µ1) × (S2, 62,µ2).
Moreover, µ is the unique measure on (S, 6) for which
µ(A1 × A2) = µ(A1)µ(A2), Ai ∈ 6i
.
If f ∈ (m6)
+, then
µ( f ) =
Z
S1
I
f
1
(s1)µ1(ds1) =
Z
S2
I
f
2
(s2)µ2(ds2),
where If
1
, If
2
are defined as before (i.e., as the sup over bounded functions from below). The
same is valid if f ∈ m6 and µ(| f |) < +∞.
Some applications of Fubini’s Theorem (Theorem B.5.2) follow. We first recall the fol￾lowing useful formula.
Theorem B.5.3 (Change-of-variables formula). Let X be a random variable with law L. If
f : R → R is such that either f ≥ 0 or E| f (X)| < +∞, then
E[ f (X)] =
Z
R
f ( y)L(dy).
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University Press412 Measure-Theoretic Foundations
Proof We use the standard machinery.
1. For f = 1B with B ∈ B,
E[1B(X)] = L(B) =
Z
R
1B( y)L(dy).
2. If f =
Pm
k=1
ak1Ak
is a simple function, then by (LIN)
E[ f (X)] =
Xm
k=1
akE[1Ak
(X)] =
Xm
k=1
ak
Z
R
1Ak
( y)L(dy) =
Z
R
f ( y)L(dy).
3. Let f ≥ 0 and approximate f by a sequence {fn} of increasing simple functions. By
(MON),
E[ f (X)] = lim
n
E[ fn(X)] = lim
n
Z
R
fn( y)L(dy) =
Z
R
f ( y)L(dy).
4. Finally, assume that f is such that E| f (X)| < +∞. Then, by (LIN),
E[ f (X)] = E[ f
+
(X)] − E[ f
−
(X)]
=
Z
R
f
+
( y)L(dy) −
Z
R
f
−
( y)L(dy)
=
Z
R
f ( y)L(dy).
Theorem B.5.4 Let X and Y be independent random variables with respective laws µ and
ν. Let f and g be measurable functions such that either f , g ≥ 0 or E| f (X)|, E|g( y)| < +∞.
Then,
E[ f (X)g( y)] = E[ f (X)]E[g( y)].
Proof From the change-of-variables formula (Theorem B.5.3) and Fubini’s Theorem (The￾orem B.5.2), we get
E[ f (X)g( y)] =
Z
R2
f (x)g( y)(µ × ν)(dx × dy)
=
Z
R
Z
R
f (x)g( y)µ(dx)

ν(dy)
=
Z
R
(g( y)E[ f (X)]) ν(dy)
= E[ f (X)]E[g( y)].
Definition B.5.5 (Density). Let X be a random variable with law µ. We say that X has
density fX if for all B ∈ B(R),
µ(B) = P[X ∈ B] =
Z
B
fX (x)λ(dx).
Theorem B.5.6 (Convolution). Let X and Y be independent random variables with distri￾bution functions F and G, respectively. Then the distribution function, H, of X + Y is
H(z) =
Z
F(z − y)dG( y).
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University PressB.6 Conditional Expectation 413
This is called the convolution of F and G. Moreover, if X and Y have densities f and g,
respectively, then X + Y has density
h(z) =
Z
f (z − y)g( y)dy.
Proof From Fubini’s Theorem (Theorem B.5.3), denoting the laws of X and Y by µ and ν,
respectively,
P[X + Y ≤ z] =
Z Z 1{x+y≤z}µ(d x)ν(dy)
=
Z
F(z − y)ν(dy)
=
Z
F(z − y)dG( y)
=
Z Z z
−∞
f (x − y)dx

dG( y)
=
Z z
−∞ Z
f (x − y)dG( y)

dx
=
Z z
−∞ Z
f (x − y)g( y)dy

dx.
See Exercise 2.1 for a proof of the following standard formula.
Theorem B.5.7 (Moments of non-negative random variables). For any non-negative random
variable X and positive integer k,
E[X
k
] =
Z +∞
0
kxk−1P[X > x] dx. (B.5.1)
B.6 Conditional Expectation
Before defining the conditional expectation, we recall some elementary concepts. For two
events A, B, the conditional probability of A given B is defined as
P[A | B] =
P[A ∩ B]
P[B]
,
where we assume P[B] > 0.
Now let X and Z be random variables taking values x1, . . . , xm and z1, . . . ,zn, respectively.
The conditional expectation of X given Z = zj
is defined as
yj = E[X | Z = zj] =
X
i
xiP[X = xi
| Z = zj],
where we assume P[Z = zj] > 0 for all j. As motivation for the general definition, we make
the following observations.
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University Press414 Measure-Theoretic Foundations
• We can think of the conditional expectation as a random variable Y = E[X | Z] defined
as follows:
Y(ω) = yj on Gj = {ω: Z(ω) = zj}.
• Then Y is G-measurable where G = σ(Z).
• On sets in G, the expectation of Y agrees with the expectation of X. Indeed, note first that
E[Y; Gj] = yjP[Gj]
=
X
i
xiP[X = xi
| Z = zj]P[Z = zj]
=
X
i
xiP[X = xi
, Z = zj]
= E[X; Gj].
This is also true for all G ∈ G by summation.
We are ready to state the general definition of the conditional expectation. Its existence
and uniqueness follow from the next theorem.
Theorem B.6.1 (Conditional expectation). Let X ∈ L
1
(, F, P) and G ⊆ F a sub-σ-algebra.
Then:
(i) (Existence) There exists a random variable Y ∈ L
1
(, G, P) such that
E[Y; G] = E[X; G] ∀G ∈ G. (B.6.1)
CONDITIONAL Such a Y is called a version of the conditional expectation of X given G and is denoted
EXPECTATION by E[X | G].
(ii) (Uniqueness) It is unique in the sense that if Y and Y0 are two versions of the condi￾tional expectation, then Y = Y
0 almost surely.
When G = σ(Z), we sometimes use the notation E[X | Z] := E[X | G]. A similar convention
applies to collections of random variables, for example, E[X | Z1, Z2] := E[X | σ(Z1, Z2)],
and so on.
We first prove uniqueness. Existence is proved below after some more concepts are intro￾duced.
Proof of Theorem B.6.1 (ii) By way of contradiction, let Y, Y
0 be two versions of E[X | G]
such that without loss of generality P[Y > Y
0
] > 0. By monotonicity, there is n ≥ 1 with
G = {Y > Y
0 + n
−1
} ∈ G such that P[G] > 0. Then, by definition,
0 = E[Y − Y
0
; G] > n
−1P[G] > 0,
which gives a contradiction.
To prove existence, we use the L
2 method. In L
2
(, F, P), the conditional expectation
reduces to an orthogonal projection.
Theorem B.6.2 (Conditional expectation: L
2
case). Let X ∈ L
2
(, F, P) and G ⊆ F a
sub-σ-algebra. Then there exists an (almost surely) unique Y ∈ L
2
(, G, P) such that
kX − Yk2 = 1 := inf{kX − Wk2 : W ∈ L
2
(, G, P)},
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University PressB.6 Conditional Expectation 415
and, moreover, hZ, X − Yi = 0 ∀Z ∈ L
2
(, G, P). In particular, it satisfies (B.6.1). Such a Y
is called the orthogonal projection of X on L
2
(, G, P).
Proof Take (Yn) such that kX − Ynk2 → 1. We use the fact that L
2
(, G, P) is complete
(Theorem B.4.10) and first seek to prove that (Yn) is Cauchy. Using the parallelogram law
(Theorem B.4.20), note that
kX − Yrk
2
2 + kX − Ysk
2
2 = 2




X −
1
2
(Yr + Ys)




2
2
+ 2




1
2
(Yr − Ys)




2
2
.
The first term on the right-hand side is at least 212 by definition of 1, so taking limits
r,s → +∞ we have what we need, that is, that (Yn) is indeed Cauchy.
Let Y be the limit of (Yn) in L
2
(, G, P). Note that by the triangle inequality,
1 ≤ kX − Yk2 ≤ kX − Ynk2 + kYn − Yk2 → 1
as n → +∞. As a result, for any Z ∈ L
2
(, G, P) and t ∈ R,
kX − Y − tZk
2
2 ≥ 1
2 = kX − Yk
2
2
,
so that, expanding and rearranging, we have
−2thZ, X − Yi + t
2
kZk
2
2 ≥ 0,
which is only possible for every t ∈ R if the first term is 0.
Uniqueness follows from the parallelogram law and the definition of 1.
We return to the proof of existence of the conditional expectation. We use the standard
machinery.
Proof of Theorem B.6.1 (i) The previous theorem implies that conditional expectations ex￾ist for indicators and simple functions. Now take X ∈ L
1
(, F, P) and write X = X
+ − X
−,
so we can assume X is in fact non-negative without loss of generality. Using the staircase
function,
X
(r) =



0 if X = 0,
(i − 1)2−r
if (i − 1)2−r < X ≤ i2
−r ≤ r,
r if X > r,
we have 0 ≤ X
(r) ↑ X. Let Y
(r) = E[X
(r)
| G]. Using an argument similar to the proof of
uniqueness, it follows that U ≥ 0 implies E[U | G] ≥ 0 for a simple function U. Using
linearity (which is immediate from the definition), we then have Y
(r) ↑ Y := lim sup Y
(r)
,
which is measurable in G. By (MON),
E[Y; G] = E[X; G], ∀G ∈ G.
That concludes the proof.
Before deriving some properties, we give a few examples.
Example B.6.3 If X ∈ L
1
(, G, P), then E[X | G] = X almost surely trivially. J
Example B.6.4 If G = {∅, }, then E[X | G] = E[X]. J
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University Press416 Measure-Theoretic Foundations
Example B.6.5 Let A, B ∈ F with 0 < P[B] < 1. If G = {∅, B, B
c
, } and X = 1A, then
P[A | G] =
(
P[A∩B]
P[B]
on ω ∈ B,
P[A∩B
c
]
P[Bc
]
on ω ∈ B
c
. J
Intuition about the conditional expectation sometimes breaks down.
Example B.6.6 On (, F, P) = ((0, 1],B(0, 1], λ), let G be the σ-algebra of all counta￾ble and co-countable (i.e., whose complement in (0, 1] is countable) subsets of (0, 1]. Then
P[G] ∈ {0, 1} for all G ∈ G and
E[X; G] = E[E[X]; G] = E[X]P[G],
so that E[X | G] = E[X]. Yet, G contains all singletons and we seemingly have “full infor￾mation,” which would lead to the wrong guess E[X | G] = X. J
We show that the conditional expectation behaves similarly to the ordinary expectation.
In what follows, all X and Xis are in L
1
(, F, P) and G is a sub σ-algebra of F.
Lemma B.6.7 (cLIN). If a1, a2 ∈ R, then E[a1X1 + a2X2 | G] = a1E[X1 | G] + a2E[X2 | G]
a.s.
Proof Use the linearity of expectation and the fact that a linear combination of random
variables in G is also in G.
Lemma B.6.8 (cPOS). If X ≥ 0, then E[X | G] ≥ 0 a.s.
Proof Let Y = E[X | G] and assume for contradiction that P[Y < 0] > 0. There is n ≥ 1
such that P[Y < −n
−1
] > 0. But that implies, for G = {Y < −n
−1
},
E[X; G] = E[Y; G] < −n
−1P[G] < 0,
a contradiction.
Lemma B.6.9 (cMON). If 0 ≤ Xn ↑ X , then E[Xn | G] ↑ E[X | G] a.s.
Proof Let Yn = E[Xn | G]. By (cLIN) and (cPOS), 0 ≤ Yn ↑. Then letting Y = lim sup Yn,
by (MON),
E[X; G] = E[Y; G],
for all G ∈ G.
Lemma B.6.10 (cFATOU). If Xn ≥ 0, then E[lim inf Xn | G] ≤ lim infE[Xn | G] a.s.
Proof Note that, for n ≥ m,
Xn ≥ Zm := inf
k≥m
Xk ↑∈ G,
so that infn≥m E[Xn | G] ≥ E[Zm | G]. Applying (cMON),
E[lim Zm | G] = lim E[Zm | G] ≤ lim inf
n≥m
E[Xn | G].
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University PressB.6 Conditional Expectation 417
Lemma B.6.11 (cDOM). If Xn ≤ V ∈ L
1
(, F, P) and Xn → X a.s., then
E[Xn | G] → E[X | G] a.s.
Proof Applying (cFATOU) to Wn := 2V − |Xn − X| ≥ 0,
E[2V | G] = E[lim inf
n
Wn | G]
≤ lim inf
n
E[Wn | G]
= E[2V | G] − lim inf
n
E[|Xn − X| | G],
so we must have
lim inf
n
E[|Xn − X| | G] = 0.
Now use that |E[Xn − X | G]| ≤ E[|Xn − X| | G] (which follows from (cPOS)).
Lemma B.6.12 (cJENSEN). If f is convex and E[| f (X)|] < +∞, then
f (E[X | G]) ≤ E[ f (X) | G].
In addition, we highlight (without proof) the following important properties of the
conditional expectation.
Lemma B.6.13 (Taking out what is known). If X ∈ L
1
(, F, P) and Z ∈ mG is bounded
or if X is bounded and Z ∈ L
1
(, G, P), then E[ZX | G] = Z E[X | G]. This is also true if
X, Z ≥ 0, E[X] < +∞ and E[ZX] < +∞, or X ∈ L
2
(, F, P) and Z ∈ L
2
(, G, P).
Lemma B.6.14 (Role of independence). If X ∈ L
1
(, F, P) is independent of H then
E[X | H] = E[X]. In fact, if H is independent of σ(σ(X), G), then E[X | σ(G, H)] = E[X | G].
Lemma B.6.15 (Conditioning on an independent random variable). Suppose X, Y are inde￾pendent. Let φ be a function with E|φ(X, Y)| < +∞ and let g(x) = E(φ(x, Y)). Then,
E(φ(X, Y)|X) = g(X).
Lemma B.6.16 (Tower property). If H ⊆ G is a σ-algebra and X ∈ L
1
(, F, P), TOWER
PROPERTY
E[E[X | G] | H] = E[E[X | H] | G] = E[X | H].
That is, the “smallest σ-algebra wins.”
An important special case of the latter, also known as the law of total probability or the law
of total expectation, is E[E[X | G]] = E[X].
One last useful property:
Lemma B.6.17 Let (, F, P) be a probability space. If Y1 = Y2 a.s. on B ∈ F, then E[Y1 | F]
= E[Y2 | F] a.s. on B.
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University Press418 Measure-Theoretic Foundations
B.7 Filtered Spaces
Finally we define stochastic processes. Let E be a set and let E be a σ-algebra defined
over E.
PROCESS Definition B.7.1 A stochastic process (or process) is a collection {Xt}t∈T of (E, E)-valued
random variables on a probability space (, F, P), where T is an arbitrary index set.
Here is a typical example.
Example B.7.2 When T = Z+ (or T = N or T = Z) we have a discrete-time process, in
which case we often write the process as a sequence (Xt)t≥0. For instance:
• X0, X1, X2, . . . i.i.d. random variables;
• (St)t≥0, where St =
P
i≤t Xi with Xi as above.
We let
Ft = σ(X0, X1, . . . , Xt),
which can be thought of as “the information known up to time t.” For a fixed ω ∈ , (Xt(ω):
SAMPLE PATH t ∈ T ) is called a sample path. J
Definition B.7.3 A random walk on R
d
is a process of the form:
St = S0 +
Xt
i=1
Xi
, t ≥ 1,
where the Xis are i.i.d. in R
d
, independent of S0. The case Xi uniform in {−1, +1} is called
simple random walk on Z.
Filtered spaces provide a formal framework for time-indexed processes. We restrict our￾selves to discrete time. (We will not discuss continuous-time processes in this book.)
Definition B.7.4 A filtered space is a tuple (, F, (Ft)t∈Z+
, P) where:
• (, F, P) is a probability space;
• (Ft)t∈Z+
FILTRATION is a filtration, that is,
F0 ⊆ F1 ⊆ · · · ⊆ F∞ := σ(∪tFt) ⊆ F,
where each Fi
is a σ-algebra.
Definition B.7.5 Fix (, F, (Ft)t∈Z+
, P). A process (Wt)t≥0 is adapted if Wt ∈ Ft ADAPTED for all t.
Intuitively, in the previous definition, the value of Wt
is “known at time t.”
PREDICTABLE Definition B.7.6 A process (Ct)t≥1 is predictable if Ct ∈ Ft−1 for all t ≥ 1.
Example B.7.7 Continuing Example B.7.2. The collection (Ft)t≥0 forms a filtration. The
process (St)t≥0 is adapted. On the other hand, the process Ct = 1{St−1 ≤ k} is predictable. J
https://doi.org/10.1017/9781009305129.009 Published online by Cambridge University PressBibliography
[Abb18] E. Abbe. Community detection and stochastic block models. Found. Trends Commun. Inf.
Theory, 14(1–2):1–162, June 2018. Publisher: Now Publishers, Inc.
[ABH16] E. Abbe, A. S. Bandeira, and G. Hall. Exact recovery in the stochastic block model. IEEE
Transactions on Information Theory, 62(1):471–487, January 2016.
[Ach03] D. Achlioptas. Database-friendly random projections: Johnson–Lindenstrauss with binary
coins. J. Comput. Syst. Sci., 66(4):671–687, 2003.
[AD78] R. Ahlswede and D. E. Daykin. An inequality for the weights of two families of sets, their
unions and intersections. Z. Wahrsch. Verw. Gebiete, 43(3):183–185, 1978.
[AF] D. Aldous and J. A. Fill. Reversible Markov chains and random walks on graphs. www.stat
.berkeley.edu/∼aldous/RWG/book.html.
[AGG89] R. Arratia, L. Goldstein, and L. Gordon. Two moments suffice for Poisson approximations:
The Chen–Stein Method. Ann. Probab., 17(1):9–25, January 1989.
[AJKS22] A. Agarwal, N. Jiang, S. M. Kakade, and W. Sun. Reinforcement learning: Theory and algo￾rithms. https://rltheorybook.github.io/rltheorybook_AJKS.pdf, 2022.
[AK97] N. Alon and M. Krivelevich. The concentration of the chromatic number of random graphs.
Combinatorica, 17(3):303–313, 1997.
[Ald83] D. Aldous. Random walks on finite groups and rapidly mixing Markov chains. In Seminar on
Probability, XVII, volume 986 of Lecture Notes in Math., pages 243–297. Springer, Berlin,
1983.
[Ald90] D. J. Aldous. The random walk construction of uniform spanning trees and uniform labelled
trees. SIAM J. Discrete Math., 3(4):450–465, 1990.
[Ald97] D. Aldous. Brownian excursions, critical random graphs and the multiplicative coalescent.
Ann. Probab., 25(2):812–854, 1997.
[Alo03] N. Alon. Problems and results in extremal combinatorics. I. Discrete Math., 273(1–3):31–53,
2003.
[AMS09] J.-Y. Audibert, R. Munos, and C. Szepesvári. Exploration–exploitation tradeoff using vari￾ance estimates in multi-armed bandits. Theor. Comput. Sci., 410(19):1876–1902, 2009.
[AN04] K. B. Athreya and P. E. Ney. Branching Processes. Dover, Mineola, 2004. Reprint of the
1972 original [Springer, New York, MR0373040].
[ANP05] Dimitris Achlioptas, Assaf Naor, and Yuval Peres. Rigorous location of phase transitions in
hard optimization problems. Nature, 435:759–764, 2005.
[AS11] N. Alon and J. H. Spencer. The Probabilistic Method. Wiley Series in Discrete Mathematics
and Optimization. Wiley, Hoboken, NJ, 2011.
[AS15] E. Abbe and C. Sandon. Community detection in general stochastic block models: Funda￾mental limits and efficient algorithms for recovery. In Venkatesan Guruswami, ed., IEEE
56th Annual Symposium on Foundations of Computer Science, FOCS 2015, Berkeley, 17–20
October, 2015, pages 670–688. IEEE Computer Society, 2015.
[Axl15] S. Axler. Linear Algebra Done Right. Undergraduate Texts in Mathematics. Springer, Cham,
3rd ed., 2015.
[AZ18] M. Aigner and G. M. Ziegler. Proofs from The Book. Springer, Berlin, 6th ed., 2018.
419
https://doi.org/10.1017/9781009305129.010 Published online by Cambridge University Press420 Bibliography
[Azu67] K. Azuma. Weighted sums of certain dependent random variables. Tôhoku Math. J. (2),
19(2):357–367, 1967.
[BA99] A.-L. Barabási and R. Albert. Emergence of scaling in random networks. Science,
286(5439):509–512, 1999.
[BBFdlV00] D. Barraez, S. Boucheron, and W. Fernandez de la Vega. On the fluctuations of the giant
component. Combin. Probab. Comput., 9(4):287–304, 2000.
[BC03] B. Brinkman and M. Charikar. On the impossibility of dimension reduction in L1. In Pro￾ceedings of the 44th Annual IEEE Symposium on Foundations of Computer Science, IEEE
Computer Society, page 514, 2003.
[BCB12] S. Bubeck and N. Cesa-Bianchi. Regret Analysis of Stochastic and Nonstochastic Multi￾armed Bandit Problems. Now, 2012. Google-Books-ID: Rl2skwEACAAJ.
[BCMR06] C. Borgs, J. T. Chayes, E. Mossel, and S. Roch. The Kesten–Stigum reconstruction
bound is tight for roughly symmetric binary channels. In FOCS, pages 518–530, 2006.
doi:10.1109/FOCS.2006.76
[BD97] R. Bubley and M. E. Dyer. Path coupling: A technique for proving rapid mixing in Markov
chains. In 38th Annual Symposium on Foundations of Computer Science, FOCS ’97, Miami
Beach, Florida, October 19–22, 1997, pages 223–231. IEEE Computer Society, 1997. doi:
10.1109/SFCS.
[BDDW08] R. Baraniuk, M. Davenport, R. DeVore, and M. Wakin. A simple proof of the restricted
isometry property for random matrices. Constr. Approx., 28(3):253–263, 2008.
[BDJ99] J. Baik, P. Deift, and K. Johansson. On the distribution of the length of the longest increasing
subsequence of random permutations. J. Amer. Math. Soc., 12(4):1119–1178, 1999.
[Ber14] N. Berestycki. Lectures on mixing times: A crossroad between probability, analysis and
geometry. https://homepage.univie.ac.at/nathanael.berestycki/wp-content/uploads/2022/05/
mixing3.pdf, 2014.
[Ber46] S. N. Bernstein. Probability Theory (in Russian). M.-L. Gostechizdat, 1946.
[BH57] S. R. Broadbent and J. M. Hammersley. Percolation processes. I. Crystals and mazes. Proc.
Cambridge Philos. Soc., 53:629–641, 1957.
[BH16] A. S. Bandeira and R. Handel. Sharp nonasymptotic bounds on the norm of random matrices
with independent entries. Ann. Probab., 44(4):2479–2506, 2016.
[Bil12] P. Billingsley. Probability and Measure. Wiley Series in Probability and Statistics. Wiley,
Hoboken, NJ, 2012.
[BKW14] I. Benjamini, G. Kozma, and N. Wormald. The mixing time of the giant component of a
random graph. Random Structures Algorithms, 45(3):383–407, 2014.
[BLM13] S. Boucheron, G. Lugosi, and P. Massart. Concentration Inequalities: A Nonasymptotic The￾ory of Independence. Oxford University Press, Oxford, 2013.
[Bol81] B. Bollobás. Random graphs. In Combinatorics (Swansea, 1981), volume 52 of London
Math. Soc. Lecture Note Ser., pages 80–102. Cambridge University Press, Cambridge, 1981.
[Bol84] B. Bollobás. The evolution of random graphs. Trans. Amer. Math. Soc., 286(1):257–274,
1984.
[Bol98] B. Bollobás. Modern Graph Theory, volume 184 of Graduate Texts in Mathematics.
Springer-Verlag, New York, 1998.
[Bol01] B. Bollobás. Random Graphs, volume 73 of Cambridge Studies in Advanced Mathematics.
Cambridge University Press, Cambridge, 2nd ed., 2001.
[BR06a] B. Bollobás and O. Riordan. Percolation. Cambridge University Press, New York, 2006.
[BR06b] B. Bollobás and O. Riordan. A short proof of the Harris–Kesten theorem. Bull. London Math.
Soc., 38(3):470–484, 2006.
[Bre17] P. Bremaud. Discrete Probability Models and Methods, volume 78 of Probability Theory and
Stochastic Modelling. Springer, Cham, 2017. Probability on graphs and trees, Markov chains
and random fields, entropy and coding.
[Bre20] P. Bremaud. Markov Chains—Gibbs Fields, Monte Carlo Simulation and Queues, volume 31
of Texts in Applied Mathematics. Springer, Cham, 2020. 2nd ed.
https://doi.org/10.1017/9781009305129.010 Published online by Cambridge University PressBibliography 421
[Bro89] A. Z. Broder. Generating random spanning trees. In FOCS, pages 442–447. IEEE Computer
Society, 1989. doi: 10.1109/SFCS.1989.63516.
[BRST01] B. Bollobás, O. Riordan, J. Spencer, and G. Tusnády. The degree sequence of a scale-free
random graph process. Random Struct. Algorithms, 18(3):279–290, 2001.
[BS89] R. Boppona and J. Spencer. A useful elementary correlation inequality. J. Combin. Theory
Ser. A, 50(2):305–307, 1989.
[Bub10] S. Bubeck. Bandits Games and Clustering Foundations. Ph.D. thesis, Université des Sciences
et Technologie de Lille – Lille I, June 2010.
[BV04] S. P. Boyd and L. Vandenberghe. Convex Optimization. Berichte über verteilte messysteme.
Cambridge University Press, Cambridge, 2004.
[Car85] T. K. Carne. A transmutation formula for Markov chains. Bull. Sci. Math. (2), 109(4):399–
405, 1985.
[CDL+12] P. Cuff, J. Ding, O. Louidor et al. Glauber dynamics for the mean-field Potts model. J. Stat.
Phys., 149(3):432–477, 2012.
[CF07] C. Cooper and A. Frieze. The cover time of sparse random graphs. Random Struct. Algo￾rithms, 30(1–2):1–16, 2007.
[Che52] H. Chernoff. A measure of asymptotic efficiency for tests of a hypothesis based on the sum
of observations. Ann. Math. Statistics, 23:493–507, 1952.
[Che70] J. Cheeger. A lower bound for the smallest eigenvalue of the Laplacian. In Problems in Anal￾ysis (Sympos. in Honor of Salomon Bochner, Princeton Unviersity, Princeton, 1969), pages
195–199. Princeton University Press, Princeton, 1970.
[Che75] L. H. Y. Chen. Poisson approximation for dependent trials. Ann. Probab., 3(3):534–545,
1975.
[Chu97] F. R. K. Chung. Spectral Graph Theory, volume 92 of CBMS Regional Conference Series in
Mathematics. Published for the Conference Board of the Mathematical Sciences, Washing￾ton, DC; by the American Mathematical Society, Providence, 1997.
[CL06] F. Chung and L. Lu. Complex Graphs and Networks, volume 107 of CBMS Regional Con￾ference Series in Mathematics. Published for the Conference Board of the Mathematical
Sciences, Washington, DC; by the American Mathematical Society, Providence, 2006.
[CR92] V. Chvatal and B. Reed. Mick gets some (the odds are on his side) [satisfiability]. In Founda￾tions of Computer Science, 1992. Proceedings., 33rd Annual Symposium on, pages 620–627,
1992. doi: 10.1109/SFCS.1992.267789.
[Cra38] H. Cramér. Sur un nouveau théorème-limite de la théorie des probabilités. Actualités Scien￾tifiques et Industrielles, 736:5–23, 1938.
[CRR+89] A. K. Chandra, P. Raghavan, W. L. Ruzzo, R. Smolensky, and P. Tiwari. The electrical resist￾ance of a graph captures its commute and cover times (detailed abstract). In David S. John￾son, ed., STOC, pages 574–586. Association for Computing Machinery, New York, 1989.
[CRT06a] E. J. Candès, J. Romberg, and T. Tao. Robust uncertainty principles: Exact signal reconstruc￾tion from highly incomplete frequency information. IEEE Trans. Inform. Theory, 52(2):489–
509, 2006.
[CRT06b] E. J. Candès, J. K. Romberg, and T. Tao. Stable signal recovery from incomplete and inaccu￾rate measurements. Comm. Pure Appl. Math., 59(8):1207–1223, 2006.
[CT05] E. J. Candès and T. Tao. Decoding by linear programming. IEEE Trans. Inform. Theory,
51(12):4203–4215, 2005.
[CW08] E. J. Candès and M. B. Wakin. An introduction to compressive sampling. Signal Process.
Mag., IEEE, 25(2):21–30, 2008.
[Dev98] L. Devroye. Branching processes and their applications in the analysis of tree structures and
tree algorithms. In Michel Habib, C. McDiarmid, J. Ramirez–Alfonsin, and B. Reed, eds.,
Probabilistic Methods for Algorithmic Discrete Mathematics, volume 16 of Algorithms and
Combinatorics, pages 249–314. Springer Berlin Heidelberg, 1998.
[Dey] P. Dey. Lecture notes on “Stein–Chen method for Poisson approximation.” https://faculty
.math.illinois.edu/∼psdey/414CourseNotes.pdf.
https://doi.org/10.1017/9781009305129.010 Published online by Cambridge University Press422 Bibliography
[DGG+00] M. Dyer, L. A. Goldberg, C. Greenhill, M. Jerrum, and M. Mitzenmacher. An extension of
path coupling and its application to the Glauber dynamics for graph colourings (extended
abstract). In Proceedings of the Eleventh Annual ACM-SIAM Symposium on Discrete Algo￾rithms (San Francisco, 2000), pages 616–624. Association for Computing Machinery, New
York, 2000.
[dH] F. den Hollander. Probability theory: The coupling method, 2012. http://websites.math.leid
enuniv.nl/probability/lecturenotes/CouplingLectures.pdf.
[Dia88] P. Diaconis. Group Representations in Probability and Statistics, volume 11 of Institute of
Mathematical Statistics Lecture Notes—Monograph Series. Institute of Mathematical Sta￾tistics, Hayward, 1988.
[Dia09] P. Diaconis. The Markov chain Monte Carlo revolution. Bull. Amer. Math. Soc. (N.S.),
46(2):179–205, 2009.
[Die10] R. Diestel. Graph Theory, volume 173 of Graduate Texts in Mathematics. Springer, Heidel￾berg, 4th ed. 2010.
[DKLP11] J. Ding, J. H. Kim, E. Lubetzky, and Y. Peres. Anatomy of a young giant component in the
random graph. Random Struct. Algorithms, 39(2):139–178, 2011.
[DMR11] C. Daskalakis, E. Mossel, and S. Roch. Evolutionary trees and the Ising model on the Bethe
lattice: A proof of steel’s conjecture. Probab. Theory Related Fields, 149:149–189, 2011.
https://doi.org/10.1007/s00440-009-0246-2.
[DMS00] S. N. Dorogovtsev, J. F. F. Mendes, and A. N. Samukhin. Structure of growing networks with
preferential linking. Phys. Rev. Lett., 85:4633–4636, 2000.
[Doe38] W. Doeblin. Exposé de la théorie des chaînes simples constantes de markoff à un nombre fini
d’états. Rev. Math. Union Interbalkan, 2:77–105, 1938.
[Don06] D. L. Donoho. Compressed Sensing. IEEE Trans. Inform. Theory, 52(4):1289–1306, 2006.
[Doo01] J. L. Doob. Classical Potential Theory and Its Probabilistic Counterpart. Classics in Mathe￾matics. Springer, Berlin, 2001.
[DP11] J. Ding and Y. Peres. Mixing time for the Ising model: A uniform lower bound for all graphs.
Ann. Inst. Henri Poincaré Probab. Stat., 47(4):1020–1028, 2011.
[DS84] P. G. Doyle and J. L. Snell. Random Walks and Electric Networks. Carus Mathematical
Monographs. Mathematical Association of America, Washington, DC, 1984.
[DS91] P. Diaconis and D. Stroock. Geometric bounds for eigenvalues of Markov chains. Ann. Appl.
Probab., 1(1):36–61, 1991.
[DSC93a] P. Diaconis and L. Saloff-Coste. Comparison techniques for random walk on finite groups.
Ann. Probab., 21(4):2131–2156, 1993.
[DSC93b] P. Diaconis and L. Saloff-Coste. Comparison theorems for reversible Markov chains. Ann.
Appl. Probab., 3(3):696–730, 1993.
[DSS22] J. Ding, A. Sly, and N. Sun. Proof of the satisfiability conjecture for large k. Ann. of Math.
(2), 196(1):1–388, 2022.
[Dur85] R. Durrett. Some general results concerning the critical exponents of percolation processes.
Z. Wahrsch. Verw. Gebiete, 69(3):421–437, 1985.
[Dur06] R. Durrett. Random Graph Dynamics. Cambridge Series in Statistical and Probabilistic
Mathematics. Cambridge University Press, 2006.
[Dur10] R. Durrett. Probability: Theory and Examples. Cambridge Series in Statistical and Probabi￾listic Mathematics. Cambridge University Press, Cambridge, 2010.
[Dur12] R. Durrett. Essentials of Stochastic Processes. Springer Texts in Statistics. Springer, New
York, 2nd ed. 2012.
[DZ10] A. Dembo and O. Zeitouni. Large Deviations Techniques and Applications, volume 38 of
Stochastic Modelling and Applied Probability. Springer-Verlag, Berlin, 2010. Corrected re￾print of the 2nd ed. (1998).
[Ebe] A. Eberle. Markov Processes. 2021. https://uni-bonn.sciebo.de/s/kzTUFff5FrWGAay.
[EKPS00] W. S. Evans, C. Kenyon, Y. Peres, and L. J. Schulman. Broadcasting on trees and the Ising
model. Ann. Appl. Probab., 10(2):410–433, 2000.
[ER59] P. Erdos and A. Rényi. On random graphs. I. ˝ Publ. Math. Debrecen, 6:290–297, 1959.
https://doi.org/10.1017/9781009305129.010 Published online by Cambridge University PressBibliography 423
[ER60] P. Erdos and A. Rényi. On the evolution of random graphs. ˝ Magyar Tud. Akad. Mat. Kutató
Int. Közl., 5:17–61, 1960.
[Fel71] W. Feller. An introduction to Probability Theory and Its Applications. Vol. II. 2nd ed. John
Wiley, New York-London-Sydney, 1971.
[FK16] A. Frieze and M. Karonski. ´ Introduction to Random Graphs. Cambridge University Press,
Cambridge, 2016.
[FKG71] C. M. Fortuin, P. W. Kasteleyn, and J. Ginibre. Correlation inequalities on some partially
ordered sets. Comm. Math. Phys., 22:89–103, 1971.
[FM88] P. Frankl and H. Maehara. The Johnson–Lindenstrauss lemma and the sphericity of some
graphs. J. Combin. Theory Ser. B, 44(3):355–362, 1988.
[Fos53] F. G. Foster. On the stochastic matrices associated with certain queuing processes. Ann. Math.
Statistics, 24:355–360, 1953.
[FR98] A. M. Frieze and B. Reed. Probabilistic analysis of algorithms. In M. Habib, C. McDiarmid, J.
Ramirez–Alfonsin, and B. Reed, eds., Probabilistic Methods for Algorithmic Discrete Math￾ematics, volume 16 of Algorithms and Combinatorics, pages 36–92. Springer, Berlin, 1998.
[FR08] N. Fountoulakis and B. A. Reed. The evolution of the mixing rate of a simple random walk
on the giant component of a random graph. Random Struct. Algorithms, 33(1):68–86, 2008.
[FR13] S. Foucart and H. Rauhut. A Mathematical Introduction to Compressive Sensing. Applied
and Numerical Harmonic Analysis. Birkhäuser, Basel, 2013.
[FV18] S. Friedli and Y. Velenik. Statistical Mechanics of Lattice Systems. Cambridge University
Press, Cambridge, 2018. A Concrete Mathematical Introduction.
[GC11] A. Garivier and O. Cappé. The KL-UCB algorithm for bounded stochastic bandits and be￾yond. In Proceedings of the 24th Annual Conference on Learning Theory, pages 359–376.
JMLR Workshop and Conference Proceedings, December 2011. ISSN: 1938-7228.
[GCS+14] A. Gelman, J. B. Carlin, H. S. Stern et al. Bayesian Data Analysis. Texts in Statistical Science
Series. CRC Press, Boca Raton, 3rd ed., 2014.
[Gil59] E. N. Gilbert. Random graphs. Ann. Math. Statist., 30:1141–1144, 1959.
[GL06] D. Gamerman and H. F. Lopes. Markov Chain Monte Carlo. Texts in Statistical Science
Series. Chapman & Hall/CRC, Boca Raton, 3nd ed. 2006. Stochastic simulation for Bayesian
inference.
[Gri97] G. Grimmett. Percolation and disordered systems. In Lectures on Probability Theory and
Statistics (Saint–Flour, 1996), volume 1665 of Lecture Notes in Math., pages 153–300.
Springer, Berlin, 1997.
[Gri10a] G. Grimmett. Probability on Graphs, volume 1 of Institute of Mathematical Statistics Text￾books. Cambridge University Press, Cambridge, 2010.
[Gri10b] G. R. Grimmett. Percolation. Grundlehren der mathematischen Wissenschaften. Springer,
Berlin, 1999.
[Gri75] D. Griffeath. A maximal coupling for Markov chains. Z. Wahrscheinlichkeitstheorie und
Verw. Gebiete, 31:95–106, 1974/75.
[GS20] G. R. Grimmett and D. R. Stirzaker. Probability and Random Processes. Oxford University
Press, Oxford, 2020. 4th ed.
[Ham57] J. M. Hammersley. Percolation processes. II. The connective constant. Proc. Cambridge Phi￾los. Soc., 53:642–645, 1957.
[Har] N. Harvey. Lecture notes for CPSC 536N: Randomized Algorithms. www.cs.ubc.ca/∼
nickhar/W12/.
[Har60] T. E. Harris. A lower bound for the critical probability in a certain percolation process. Proc.
Cambridge Philos. Soc., 56:13–20, 1960.
[Har63] T. E. Harris. The Theory of Branching Processes. Die Grundlehren der mathematischen Wis￾senschaften, Band 119. Springer-Verlag, Berlin; Prentice Hall, Englewood Cliffs, 1963.
[Haz16] E. Hazan. Introduction to online convex optimization. Found. Trends Opt., 2(3–4):157–325,
2016.
[HJ13] R. A. Horn and C. R. Johnson. Matrix Analysis. Cambridge University Press, Cambridge,
2nd ed., 2013.
https://doi.org/10.1017/9781009305129.010 Published online by Cambridge University Press424 Bibliography
[HLW06] S. Hoory, Nathan Linial, and Avi Wigderson. Expander graphs and their applications. Bull.
Amer. Math. Soc. (N.S.), 43(4):439–561 (electronic), 2006.
[HMRAR98] M. Habib, C. McDiarmid, J. Ramirez-Alfonsin, and B. Reed, eds. Probabilistic Methods for
Algorithmic Discrete Mathematics, volume 16 of Algorithms and Combinatorics. Springer￾Verlag, Berlin, 1998.
[Hoe63] W. Hoeffding. Probability inequalities for sums of bounded random variables. J. Amer. Stat￾ist. Assoc., 58:13–30, 1963.
[HS07] T. P. Hayes and Alistair Sinclair. A general lower bound for mixing of single-site dynamics
on graphs. Ann. Appl. Probab., 17(3):931–952, 2007.
[IM98] P. Indyk and R. Motwani. Approximate nearest neighbors: Towards removing the curse of di￾mensionality. In Jeffrey Scott Vitter, ed., STOC, pages 604–613. Association for Computing
Machinery, New York 1998.
[Jan90] S. Janson. Poisson approximation for large deviations. Random Struct. Algorithms, 1(2):221–
229, 1990.
[JH01] G. L. Jones and J. P. Hobert. Honest exploration of intractable probability distributions via
Markov chain Monte Carlo. Statist. Sci., 16(4):312–334, 2001.
[JL84] W. B. Johnson and J. Lindenstrauss. Extensions of Lip–schitz mappings into a Hilbert space.
In Conference in Modern Analysis and Probability (New Haven, Conn., 1982), volume 26 of
Contemp. Math., pages 189–206. Amer. Math. Soc., Providence, 1984.
[JLR11] S. Janson, T. Luczak, and A. Rucinski. Random Graphs. Wiley Series in Discrete Mathemat￾ics and Optimization. Wiley, Hoboken, NJ, 2011.
[JS89] M. Jerrum and A. Sinclair. Approximating the permanent. SIAM J. Comput., 18(6):1149–
1178, 1989.
[Kan86] M. Kanai. Rough isometries and the parabolicity of Riemannian manifolds. J. Math. Soc.
Japan, 38(2):227–238, 1986.
[Kar90] R. M. Karp. The transitive closure of a random digraph. Random Struct. Algorithms, 1(1):73–
93, 1990.
[Kes80] H. Kesten. The critical probability of bond percolation on the square lattice equals 1
2
. Comm.
Math. Phys., 74(1):41–59, 1980.
[Kes82] H. Kesten. Percolation Theory for Mathematicians, volume 2 of Progress in Probability and
Statistics. Birkhäuser, Boston, 1982.
[KP] J. Komjáthy and Y. Peres. Lecture notes for Markov chains: Mixing times, hitting times,
and cover times, 2012. Saint-Petersburg Summer School. www.win.tue.nl/∼jkomjath/
SPBlecturenotes.pdf.
[KRS] M. J. Kozdron, L. M. Richards, and D. W. Stroock. Determinants, their applications to
Markov processes, and a random walk proof of Kirchhoff ’s matrix tree theorem, 2013.
http://arxiv.org/abs/1306.2059.
[KS66a] H. Kesten and B. P. Stigum. Additional limit theorems for indecomposable multidimensional
Galton–Watson processes. Ann. Math. Statist., 37:1463–1481, 1966.
[KS66b] H. Kesten and B. P. Stigum. A limit theorem for multi-dimensional Galton–Watson pro￾cesses. Ann. Math. Statist., 37:1211–1223, 1966.
[KS67] H. Kesten and B. P. Stigum. Limit theorems for decomposable multi-dimensional Galton–
Watson processes. J. Math. Anal. Appl., 17:309–338, 1967.
[KS05] G. Kalai and S. Safra. Threshold phenomena and influence: Perspectives from Mathe￾matics, Computer Science, and Economics. In Computational Complexity and Statistical
Physics. Oxford University Press, Oxford, December 2005. _eprint: https://academic.oup
.com/book/0/chapter/354512033/chapter-pdf/43716844/isbn-9780195177374-book-part-8
.pdf.
[KSK76] J. G. Kemeny, J. L. Snell, and A. W. Knapp. Denumerable Markov Chains. Springer-Verlag,
New York-Heidelberg-Berlin, 2nd ed., 1976. With a chapter on Markov random fields, by
David Griffeath, Graduate Texts in Mathematics, No. 40.
[Law05] G. F. Lawler. Conformally Invariant Processes in the Plane, volume 114 of Mathematical
Surveys and Monographs. American Mathematical Society, Providence, 2005.
https://doi.org/10.1017/9781009305129.010 Published online by Cambridge University PressBibliography 425
[Law06] G. F. Lawler. Introduction to Stochastic Processes. Chapman & Hall/CRC, Boca Raton, 2nd
ed. 2006.
[Led01] M. Ledoux. The Concentration of Measure Phenomenon. Mathematical Surveys and Mono￾graphs. American Mathematical Society, Providence, 2001.
[Lin02] T. Lindvall. Lectures on the Coupling Method. Dover, Mineola, 2002. Corrected reprint of
the 1992 original.
[LL10] G. F. Lawler and V. Limic. Random Walk: A Modern Introduction. Cambridge Studies in
Advanced Mathematics. Cambridge University Press, Cambridge, 2010.
[Lov83] L. Lovász. Submodular functions and convexity. In Mathematical Programming: The State
of the Art (Bonn, 1982), pages 235–257. Springer, Berlin, 1983.
[Lov12] L. Lovász. Large Networks and Graph Limits, volume 60 of American Mathematical Society
Colloquium Publications. American Mathematical Society, Providence, 2012.
[LP16] R. Lyons and Y. Peres. Probability on Trees and Networks, volume 42 of Cambridge Series
in Statistical and Probabilistic Mathematics. Cambridge University Press, New York, 2016.
[LP17] D. A. Levin and Y. Peres. Markov Chains and Mixing Times. American Mathematical Soci￾ety, Providence, 2017. 2nd ed., with Contributions by Elizabeth L. wilmer, with a chapter on
“Coupling from the past” by James G. Propp and David B. Wilson.
[LPW06] D. A. Levin, Y. Peres, and E. L. Wilmer. Markov Chains and Mixing Times. American Math￾ematical Society, Providence, 2006.
[LR85] T. L Lai and H. Robbins. Asymptotically efficient adaptive allocation rules. Adv. Appl. Math.,
6(1):4–22, 1985.
[LS88] G. F. Lawler and A. D. Sokal. Bounds on the L
2 Spectrum for Markov Chains and Markov
Processes: A Generalization of Cheeger’s Inequality. Trans. Amer. Math. Soc., 309(2):557–
580, 1988.
[LS12] E. Lubetzky and A. Sly. Critical Ising on the square lattice mixes in polynomial time. Comm.
Math. Phys., 313(3):815–836, 2012.
[LS20] T. Lattimore and C. Szepesvári. Bandit Algorithms. Cambridge University Press, Cambridge,
2020.
[Lu90] T. Łuczak. Component behavior near the critical point of the random graph process. Random
Struct. Algorithms, 1(3):287–310, 1990.
[Lug] G. Lugosi. Concentration-of-measure inequalities, 2004. www.econ.upf.edu/∼lugosi/anu
.pdf.
[LuPW94] T. Łuczak, B. Pittel, and J. C. Wierman. The structure of a random graph at the point of the
phase transition. Trans. Amer. Math. Soc., 341(2):721–748, 1994.
[Lyo83] T. Lyons. A simple criterion for transience of a reversible Markov chain. Ann. Probab.,
11(2):393–402, 1983.
[Lyo90] R. Lyons. Random walks and percolation on trees. Ann. Probab., 18(3):931–958, 1990.
[Mat88] P. Matthews. Covering problems for Markov chains. Ann. Probab., 16(3):1215–1228, 1988.
[Mau79] B. Maurey. Construction de suites symétriques. C. R. Acad. Sci. Paris Sér. A-B,
288(14):A679–A681, 1979.
[McD89] C. McDiarmid. On the method of bounded differences. In Surveys in Combinatorics, 1989
(Norwich, 1989), volume 141 of London Math. Soc. Lecture Note Ser., pages 148–188.
Cambridge University Press, Cambridge, 1989.
[ML86] A. Martin–Löf. Symmetric sampling procedures, general epidemic processes and their
threshold limit theorems. J. Appl. Probab., 23(2):265–282, 1986.
[ML98] A. Martin–Löf. The final size of a nearly critical epidemic, and the first passage time of a
Wiener process to a parabolic barrier. J. Appl. Probab., 35(3):671–682, 1998.
[MNS15a] E. Mossel, J. Neeman, and A. Sly. Consistency thresholds for the planted bisection model.
In Rocco A. Servedio and Ronitt Rubinfeld, eds., Proceedings of the Forty-Seventh Annual
ACM on Symposium on Theory of Computing, STOC 2015, Portland, June 14–17, 2015,
pages 69–75. Association for Computing Machinery, New York, 2015.
[MNS15b] E. Mossel, J. Neeman, and Allan Sly. Reconstruction and estimation in the planted partition
model. Probab. Theory Related Fields, 162(3-4):431–461, 2015.
https://doi.org/10.1017/9781009305129.010 Published online by Cambridge University Press426 Bibliography
[Mor05] F. Morgan. Real Analysis. American Mathematical Society, Providence, 2005.
[Mos01] E. Mossel. Reconstruction on trees: beating the second eigenvalue. Ann. Appl. Probab.,
11(1):285–300, 2001.
[Mos03] E. Mossel. On the impossibility of reconstructing ancestral data and phylogenies. J. Comput.
Biol., 10(5):669–678, 2003.
[Mos04] E. Mossel. Phase transitions in phylogeny. Trans. Amer. Math. Soc., 356(6):2379–2404, 2004.
[MP03] E. Mossel and Y. Peres. Information flow on trees. Ann. Appl. Probab., 13(3):817–844, 2003.
[MR95] R. Motwani and P. Raghavan. Randomized Algorithms. Cambridge University Press, Cam￾bridge, 1995.
[MS86] V. D. Milman and G. Schechtman. Asymptotic Theory of Finite-Dimensional Normed Spaces,
volume 1200 of Lecture Notes in Mathematics. Springer-Verlag, Berlin, 1986. With an ap￾pendix by M. Gromov.
[MT06] R. Montenegro and P. Tetali. Mathematical aspects of mixing times in Markov chains. Found.
Trends Theor. Comput. Sci., 1(3): 237–354, 2006.
[MT09] S. Meyn and R. L. Tweedie. Markov Chains and Stochastic Stability. Cambridge University
Press, Cambridge, 2nd ed., 2009. With a prologue by Peter W. Glynn.
[MU05] M. Mitzenmacher and E. Upfal. Probability and Computing: Randomized Algorithms and
Probabilistic Analysis. Cambridge University Press, New York, 2005.
[Nic18] B. Nica. A Brief Introduction to Spectral Graph Theory. EMS Textbooks in Mathematics.
European Mathematical Society (EMS), Zürich, 2018. https://doi.org/10.4171/188.
[Nor98] J. R. Norris. Markov Chains, volume 2 of Cambridge Series in Statistical and Probabilistic
Mathematics. Cambridge University Press, Cambridge, 1998. Reprint of 1997 original.
[NP10] A. Nachmias and Y. Peres. The critical random graph, with martingales. Israel J. Math.,
176:29–41, 2010.
[NW59] C. St. J. A. Nash-Williams. Random walk and electric currents in networks. Proc. Cambridge
Philos. Soc., 55:181–194, 1959.
[Ott49] R. Otter. The multiplicative process. Ann. Math. Statistics, 20:206–224, 1949.
[Pem91] R. Pemantle. Choosing a spanning tree for the integer lattice uniformly. Ann. Probab.,
19(4):1559–1574, 1991.
[Pem00] R. Pemantle. Towards a theory of negative dependence. J. Math. Phys., 41(3):1371–1390,
2000. Probabilistic techniques in equilibrium and nonequilibrium statistical physics.
[Per] Y. Peres. Course notes on Probability on trees and networks, 2004. http://stat-www.berkeley
.edu/∼peres/notes1.pdf.
[Per09] Y. Peres. The unreasonable effectiveness of martingales. In Proceedings of the Twentieth An￾nual ACM-SIAM Symposium on Discrete Algorithms, SODA ’09, pages 997–1000, Society
for Industrial and Applied Mathematics, Philadelphia, 2009.
[Pet] G. Pete. Probability and geometry on groups. Lecture notes for a graduate course. www.math
.bme.hu/∼gabor/PGG.html.
[Pey08] R. Peyre. A probabilistic approach to Carne’s bound. Potential Anal., 29(1):17–36, 2008.
[Pit76] J. W. Pitman. On coupling of Markov chains. Z. Wahrscheinlichkeitstheorie und Verw. Gebi￾ete, 35(4):315–322, 1976.
[Pit90] B. Pittel. On tree census and the giant component in sparse random graphs. Random Struct.
Algorithms, 1(3):311–342, 1990.
[RAS15] F. Rassoul-Agha and T. Seppäläinen. A course on Large Deviations with an Introduction to
Gibbs Measures, volume 162 of Graduate Studies in Mathematics. American Mathematical
Society, Providence, 2015.
[RC04] C. P. Robert and G. Casella. Monte Carlo Statistical Methods. Springer Texts in Statistics.
Springer-Verlag, New York, 2nd ed. 2004.
[Res92] S. Resnick. Adventures in Stochastic Processes. Birkhäuser Boston, Boston, 1992.
[Roc10] S. Roch. Toward extracting all phylogenetic information from matrices of evolutionary dis￾tances. Science, 327(5971):1376–1379, 2010.
[Rom15] D. Romik. The Surprising Mathematics of Longest Increasing Subsequences, volume 4 of
Institute of Mathematical Statistics Textbooks. Cambridge University Press, New York, 2015.
https://doi.org/10.1017/9781009305129.010 Published online by Cambridge University PressBibliography 427
[RS17] S. Roch and A. Sly. Phase transition in the sample complexity of likelihood-based phylogeny
inference. Probability Theory and Related Fields, 169(1):3–62, 2017.
[RT87] W. T. Rhee and M. Talagrand. Martingale inequalities and NP-complete problems. Math.
Oper. Res., 12(1):177–181, 1987.
[Rud73] W. Rudin. Functional Analysis. McGraw-Hill Series in Higher Mathematics. McGraw-Hill
Book, New York-Düsseldorf-Johannesburg, 1973.
[Rus78] L. Russo. A note on percolation. Z. Wahrscheinlichkeitstheorie und Verw. Gebiete, 43(1):39–
48, 1978.
[SE64] M. F. Sykes and J. W. Essam. Exact critical percolation probabilities for site and bond prob￾lems in two dimensions. J. Mathematical Phys., 5:1117–1127, 1964.
[SJ89] A. Sinclair and M. Jerrum. Approximate counting, uniform generation and rapidly mixing
Markov chains. Inform. and Comput., 82(1):93–133, 1989.
[Spi56] F. Spitzer. A combinatorial lemma and its application to probability theory. Trans. Amer.
Math. Soc., 82:323–339, 1956.
[Spi12] D. A. Spielman. Lecture notes on spectral graph theory. www.cs.yale.edu/homes/spielman/
561/2012/index.html, 2012.
[SS87] E. Shamir and J. Spencer. Sharp concentration of the chromatic number on random graphs
Gn,p. Combinatorica, 7(1):121–129, 1987.
[SS03] E. M. Stein and R. Shakarchi. Fourier Analysis, volume 1 of Princeton Lectures in Analysis.
Princeton University Press, Princeton, 2003.
[SS05] E. M. Stein and R. Shakarchi. Real Analysis, volume 3 of Princeton Lectures in Analysis.
Princeton University Press, Princeton, 2005.
[SSBD14] S. Shalev-Shwartz and S. Ben-David. Understanding Machine Learning: From Theory to
Algorithms. Cambridge University Press, Cambridge, 2014.
[Ste] J. E. Steif. A mini course on percolation theory, 2009. www.math.chalmers.se/∼steif/perc
.pdf.
[Ste72] C. Stein. A bound for the error in the normal approximation to the distribution of a sum of de￾pendent random variables. In Proceedings of the Sixth Berkeley Symposium on Mathematical
Statistics and Probability (University California, Berkeley, 1970/1971), Vol. II: Probability
theory, pages 583–602, University of California Press, Berkeley, 1972.
[Ste97] J. Michael Steele. Probability Theory and Combinatorial Optimization, volume 69 of
CBMS-NSF Regional Conference Series in Applied Mathematics. Society for Industrial and
Applied Mathematics (SIAM), Philadelphia, 1997.
[Ste98] G. W. Stewart. Matrix Algorithms. Vol. I. Society for Industrial and Applied Mathematics,
Philadelphia, 1998.
[Str65] V. Strassen. The existence of probability measures with given marginals. Ann. Math. Statist.,
36:423–439, 1965.
[Str14] Daniel W. Stroock. Doeblin’s Theory for Markov Chains. In An Introduction to Markov Pro￾cesses, pages 25–47. Springer Berlin Heidelberg, Berlin, Heidelberg, 2014.
[SW78] P. D. Seymour and D. J. A. Welsh. Percolation probabilities on the square lattice. Ann. Dis￾crete Math., 3:227–245, 1978. Advances in graph theory (Cambridge Combinatorial Conf.,
Trinity College, Cambridge, 1977).
[Tao] T. Tao. Open question: deterministic UUP matrices. https://terrytao.wordpress.com/2007/07/
02/open-question-deterministic-uup-matrices/.
[Var85] N. Th. Varopoulos. Long range estimates for Markov chains. Bull. Sci. Math. (2), 109(3):
225–252, 1985.
[vdH10] R. van der Hofstad. Percolation and random graphs. In New perspectives in Stochastic Ge￾ometry, pages 173–247. Oxford University Press, Oxford, 2010.
[vdH17] R. van der Hofstad. Random Graphs and Complex Networks. Vol. 1. Cambridge Series in
Statistical and Probabilistic Mathematics. Cambridge University Press, Cambridge, 2017.
[vdHK08] R. van der Hofstad and Michael Keane. An elementary proof of the hitting time theorem.
Amer. Math. Monthly, 115(8):753–756, 2008.
https://doi.org/10.1017/9781009305129.010 Published online by Cambridge University Press428 Bibliography
[Vem04] S. S. Vempala. The Random Projection Method. DIMACS Series in Discrete Mathematics
and Theoretical Computer Science, 65. American Mathematical Society, Providence, 2004.
With a foreword by Christos H. Papadimitriou.
[Ver18] R. Vershynin. High-Dimensional Probability: An Introduction with Applications in Data Sci￾ence. Cambridge University Press, 2018. Google-Books-ID: TahxDwAAQBAJ.
[vH16] R. van Handel. Probability in high dimension. www.princeton.edu/∼rvan/APC550.pdf,
2016.
[Vil09] Cédric Villani. Optimal Transport, volume 338 of Grundlehren der Mathematischen Wis￾senschaften [Fundamental Principles of Mathematical Sciences]. Springer-Verlag, Berlin,
2009.
[Wen75] J. G. Wendel. Left-continuous random walk and the Lagrange expansion. Amer. Math.
Monthly, 82:494–499, 1975.
[Whi32] H. Whitney. Non-separable and planar graphs. Trans. Amer. Math. Soc., 34(2):339–362,
1932.
[Wil91] D. Williams. Probability with Martingales. Cambridge Mathematical Textbooks. Cambridge
University Press, Cambridge, 1991.
[Wil96] D. B. Wilson. Generating random spanning trees more quickly than the cover time. In Gary L.
Miller, ed., STOC, pages 296–303. Association for Computing Machinery, New York, 1996.
[YP14] S.-Y. Yun and A. Proutière. Community detection via random and adaptive sampling. In
Maria-Florina Balcan, Vitaly Feldman, and Csaba Szepesvári, eds., Proceedings of The
27th Conference on Learning Theory, COLT 2014, Barcelona, Spain, June 13–15, 2014,
volume 35 of JMLR Workshop and Conference Proceedings, pages 138–175. JMLR.org,
PMLR, 2014.
[Yur76] V. V. Yurinski˘ı. Exponential inequalities for sums of random vectors. J. Multivariate Anal.,
6(4):473–499, 1976.
https://doi.org/10.1017/9781009305129.010 Published online by Cambridge University PressIndex
Azuma–Hoeffding inequality, see tail bounds
balancing vectors, 26
ballot theorem, 98
balls and bins, 121
bandits
definition, 133
optimism in the face of uncertainty, 133
upper confidence bound, 134
Bernstein’s inequality, see tail bounds
Berry–Esséen theorem, 123
binary classification
definitions, 79–80
empirical risk minimizer, 80
no free lunch, 80
binary search tree, 348
binomial coefficients
binomial theorem, 397
bounds, 18, 397
definition, xvi
bond percolation
definition, 14
FKG, 207
Bonferroni inequalities, 90
Boole’s inequality, see union bound
Boolean functions
random k-SAT problem, 29
bounded differences inequality, 119
branching number, 45
branching processes
binomial offspring, 345
duality principle, 340
exploration process, 339
extinction, 328, 329
Galton–Watson process, 327
Galton–Watson tree, 328, 332
geometric offspring, 391
history, 340, 392
infinite line of descent, 392
linear functionals, 336
multitype, see multitype branching processes
Poisson offspring, 331, 341, 343
positive regular case, 335
random-walk representation, 338, 339, 341
canonical paths, 320
Cauchy–Schwarz inequality, 408, 410
Cavender–Farris–Neyman (CFN) model, 356
Cayley’s formula, see trees
chaining method, 71
Chebyshev polynomials, 288
Chebyshev’s association inequality, 251
Chebyshev’s inequality, see tail bounds
Cheeger’s inequality, 304, 388
Chen–Stein method
dissociated case, 238, 249
main result, 235
negatively related variables, 254
positively related variables, 253
Stein coupling, 236, 239
Stein equation, 235
Chernoff–Cramér bound, see tail bounds
Chernoff–Cramér method, 51, 91, 114
community recovery, 271
compressed sensing, 75
concentration inequalities, see tail bounds, 93
concentration of measure, 122
conditional expectation
definition, 413–415
examples, 415–416
law of total probability, 417
properties, 416–417
tower property, 417
congestion ratio, 320
convergence in probability, 25
convex duality
Lagrangian, 159
weak duality, 159
coupling
coalescence time, 220
coalescing, 220
coupling inequality, 187, 192
definition, 183
Erdos–Rényi graph model, ˝ 368, 382
independent, 183
Markovian, 192, 220
maximal coupling, 188
monotone, 183, 196, 198, 201
path coupling, 229, 233
splitting, 221
429
https://doi.org/10.1017/9781009305129.011 Published online by Cambridge University Press430 Index
stochastic domination, 196
Strassen’s theorem, 198
coupon collector, 24, 223
Courant–Fischer theorem, 259, 263, 266, 268, 303
covariance, 23
covering number, 67, 87
cumulant-generating function, 50, 51
Curie–Weiss model, 316
cutset, 45
Davis–Kahan theorem, 269, 274
dependency graph, 36
dimension reduction, 72
Dirichlet
energy, 302, 320
form, 302
principle, 161, 178
problem, 143
drift condition, 149
Dudley’s inequality, 71, 86
ε-net, see epsilon-net
edge expansion constant, see networks
Efron–Stein inequality, 119
electrical networks
definitions, 150–152
Dirichlet energy, see Dirichlet
effective conductance, 157, 161
effective resistance, 157, 167, 178
flow, see flows
Kirchhoff ’s cycle law, 151
Kirchhoff ’s node law, 151
Kirchhoff ’s resistance formula, 171
Nash–Williams inequality, 162, 179
Ohm’s law, 151, 172
parallel law, 153
Rayleigh’s principle, 163, 171
series law, 153
Thomson’s principle, 158, 163
voltage, 151
empirical measure, 86, 88
epsilon-net, 67, 69, 76–78
Erdos–Rényi graph model ˝
chromatic number, 124
clique number, 249, 252
cluster, 370
connectivity, 41
definition, 15
degree sequence, 192
evolution, 368
exploration process, 370
FKG, 207
giant component, 369, 379
isolated vertices, 40
largest connected component, 368
maximum degree, 60
positive associations, 205
random walk, 388
subgraph containment, 210
threshold function, 37–42
Erdos–Rényi random graph model ˝
clique number, 37
exhaustive sequence, 179
expander graphs
(d, α)-expander family, 310
Pinsker’s model, 311
factorials
bounds, 17, 18, 397
definition, xvi
Stirling’s formula, 397
Fenchel–Legendre dual, 51
first moment method, 28–32, 36–38, 40–43, 45,
113, 127
first moment principle, 26, 28, 81
first-step analysis, 146
FKG
condition, 207, 251
inequality, 207, 251, 254
measure, 207, 252
flows
current, 151
definition, 5
energy, 158, 164, 166
flow-conservation constraints, 151, 164
max-flow min-cut theorem, 6, 199
strength, 152
to ∞, 164, 166
gambler’s ruin, 108–110, 153, 157
Gibbs random fields, 15
Glauber dynamics
definition, 16
fast mixing, 232, 315
graph Laplacian
connectivity, 262
definition, 261
degree, 263
eigenvalues, 262
Fiedler vector, 262
network, 266
normalized, 267
quadratic form, 261
graphs
3–1 tree, see trees
adjacency matrix, see matrices
b-ary tree bT
`
b
, 4, 226
bridge, 171
Cayley’s formula, see trees
chromatic number, 6, 124
clique, 2, 37
clique number, 37, 249
coloring, 6
complete graph Kn, 4
cutset, 45, 161
https://doi.org/10.1017/9781009305129.011 Published online by Cambridge University PressIndex 431
cycle Cn, 4, 222
definitions, 1–7
degree, 60
diameter, 290
directed, 6, 7
expander, see expander graphs
flow, see flows
graph distance, 3
hypercube Z
n
2
, 4, 223
incidence matrix, see matrices
independent set, 6, 27
infinite, 4
infinite binary tree, 356
Laplacian, see graph Laplacian
matching, 6
matrix representation, see matrices
multigraph, 1
n-clique, 302
network, see networks
oriented incidence matrix, see matrices
perfect matching, 6
spanning arborescence, 174
torus L
d
n
, 4
tree, see trees
Turán graphs, 28
Green function, see Markov chains
Hölder’s inequality, 408
Hamming distance, 139
harmonic functions, see Markov chains
Harper’s vertex isoperimetric theorem, 124
Harris’ inequality, 251, 254
Harris’ theorem, see percolation
hitting time, see stopping time
Hoeffding’s inequality, see tail bounds
Hoeffding’s lemma, see tail bounds, 115
Holley’s inequality, 208, 251, 254
increasing event, see posets
indicator trick, 28
inherited property, 331
Ising model
boundary conditions, 202
complete graph, 316
definition, 15
FKG, 207
Glauber dynamics, 223, 231, 315
magnetization, 316
random cluster, 356
trees, 356, 394
isoperimetric inequality, 300
Janson’s inequality, 212, 254
Jensen’s inequality, 409
Johnson–Lindenstrauss
distributional lemma, 73
lemma, 72–75
Kesten’s theorem, see percolation
knapsack problem, 61
Kolmogorov’s maximal inequality, 110, 252
Kullback–Leibler divergence, 53
Laplacian
graphs, see graph Laplacian
Markov chains, 143, 160, 253
networks, see graph Laplacian
large deviations, 53, 93
law of total probability, see conditional
expectation
laws of large numbers, 25
Lipschitz
condition, 139–141
process, 68
Lyapounov function, see Markov chains
Markov chain Monte Carlo, 292
Markov chain tree theorem, 180
Markov chains
average occupation time, 146
birth-death, 152, 178, 296
bottleneck ratio, see networks
Chapman–Kolmogorov, 8
commute time, 168
commute time identity, 168, 179, 227
construction, 7
cover time, 96
decomposition theorem, 99
definitions, 7–14
Doeblin’s condition, 221, 252
escape probability, 154, 160
examples, 7–13
exit law, 145
exit probability, 145
first return time, 96
first visit time, 96, 141
Green function, 100, 146, 154
harmonic functions, 141
hitting times, 245
irreducible set, 99
lower bound, 223
Lyapounov function, 149, 230
Markov property, 8
martingales, 105
Matthews’ cover time bounds, 103, 179
mean exit time, 146
Metropolis algorithm, 12
mixing time, see mixing times
positive recurrence, 99
potential theory, 145
recurrence, 156, 164–167
recurrent state, 99
relaxation time, 281
reversibility, 142, 287
splitting, see coupling
stationary measure, 99
https://doi.org/10.1017/9781009305129.011 Published online by Cambridge University Press432 Index
stochastic domination, 203, 209
stochastic monotonicity, 202
strong Markov property, 97
uniform geometric ergodicity, 221
Varopoulos–Carne bound, 287, 326
Markov’s inequality, see tail bounds, 49
martingales, 360
Azuma–Hoeffding inequality, see tail bounds
convergence theorem, 111, 328
definition, 103
Doob martingale, 105, 115, 124
Doob’s submartingale inequality, 110, 114
edge exposure martingale, 125
exposure martingale, 124
hitting time, 179
Markov chain, see Markov chains
martingale difference, 115
optional stopping theorem, 107
orthogonality of increments, 112, 116
stopped process, 106
submartingale, 103
supermartingale, 103
vertex exposure martingale, 124
matrices
2-norm, 68
adjacency, 2, 261
block, 257
diagonal, 256
graph Laplacian, see graph Laplacian
incidence, 2
oriented incidence, 7
orthogonal, 256
spectral norm, 68, 140, 268
spectral radius, 324, 335
spectrum, 323
stochastic matrix, 7
symmetric, 256
maximal Azuma–Hoeffding inequality, see tail
bounds
maximum principle, 11, 19, 143, 178
method of bounded differences, see tail bounds
method of moments, 93
method of random paths, 169, 179
Metropolis algorithm, see Markov chains
minimum bisection problem, 272
Minkowski’s inequality, 408
mixing times
b-ary tree, 226, 308
cutoff, 226, 287, 324
cycle, 252, 283, 309
definition, 14
diameter, 291
diameter bound, 291
distinguishing statistic, 226, 252
hypercube, 285, 310, 325
lower bound, 222, 224, 232, 252, 290, 291
random walk on cycle, 222
random walk on hypercube, 223
separation distance, 281
upper bound, 232
moment-generating functions
χ
2
, 57
definition, 21
Gaussian, 50
Poisson, 52
Rademacher, 50
moments, 21
exponential moment, see moment-generating
functions
multi-armed bandits, see bandits
multitype branching processes
definitions, 333–335
Kesten–Stigum bound, 359
mean matrix, 334
nonsingular case, 334
negative associations, 171
networks
cut, 301
definition, 6
edge boundary, 300
edge expansion, 301, 302
vertex boundary, 311
no free lunch, see binary classification
notation, xv–xvi
operator
compact, 296
norm, 297
spectral radius, 297
optimal transport, 253
optional stopping theorem, see martingales
Pólya’s theorem, see random walk
Pólya’s urn, 111
packing number, 67
Pajor’s lemma, 89
parity functions, 285
Parseval’s identity, 277
pattern matching, 122
peeling method, see slicing method
percolation
contour lemma, 33
critical exponents, 348
critical value, 31, 43, 213, 332, 345
dual lattice, 32, 214
Galton–Watson tree, 332
Harris’ theorem, 213, 254
Kesten’s theorem, 213, 254
on L
2
, 31, 213
on L
d
, 198
on a graph, 183
on infinite trees, 43, 113
percolation function, 31, 43, 198, 213, 345
RSW lemma, 213, 252, 254
https://doi.org/10.1017/9781009305129.011 Published online by Cambridge University PressIndex 433
permutations
Erdos–Szekeres Theorem, ˝ 31
longest increasing subsequence, 30
random, 30
Perron–Frobenius theory
Perron vector, 335
theorem, 9, 335, 360
Poincaré inequality, 119, 120, 303, 304, 320
Poisson approximation, 191, 210
Poisson equation, 146
Poisson trials, 53
posets
decreasing event, 206
definition, 198
increasing event, 198, 250
positive associations
definition, 206
strong, 251
positively correlated events, 206
probabilistic method, 25–28, 73, 80, 87
probability generating function, 329
probability spaces
definitions, 398–400
distribution function, 400
expectation, 406–410
filtered spaces, 95, 418
Fubini’s theorem, 411
independence, 403–406
process, 418
random variables, 400–403
pseudo-regret, 133
random graphs
Erdos–Rényi, ˝ see Erdos–Rényi graph model ˝
preferential attachment, 15, 128
stochastic blockmodel, 271
random projection, 72
random target lemma, 144
random variables
Bernoulli, 53, 183, 190, 195, 240
binomial, 53, 224, 250
χ
2
, 57, 74
Gaussian, 23, 54, 57, 73
geometric, 24, 221
Poisson, 52, 188, 190, 195, 197, 331, 392
Rademacher, 50, 54
uncorrelated, 25, 91, 112
uniform, 24
random walk
asymmetric random walk on Z, 299
b-ary tree, 226
biased random walk on Z, 109, 184
cycle, 222, 283
hypercube, 223, 285
lazy, 13, 185, 222
loop erasure, 172
on a graph, 8–12
on a network, 16
Pólya’s theorem, 169
reflection principle, 98
simple random walk on Z, 8, 99, 108, 144, 165,
287, 288, 418
simple random walk on Z
d
, 185
simple random walk on a graph, 16
tree, 186
Wald’s identities, 107–110
Rayleigh quotient, 259, 264, 302
reconstruction problem
definition, 356
MAP estimator, 357
solvability, 356
reflection principle, see random walk
relaxation times
cycle, 284
hypercube, 286
restricted isometry property, 75, 78–79
rough embedding, 165, 166
rough equivalence, 165, 179
rough isometry, 179
RSW lemma, see percolation
Sauer’s lemma, 84, 85, 87
second moment method, 35–37, 39, 40, 42, 44, 45,
47
set balancing, 51
shattering, 84
simple random walk on a graph, see random walk
slicing method, 138
span, 259
sparse signal recovery, 76
sparsity, 75
spectral clustering, 274
spectral gap, 281
spectral theorem, 256, 267
Spitzer’s combinatorial lemma, 343
Stirling’s formula, see factorials
stochastic bandits, see bandits
stochastic domination
binomial, 371
coupling, see coupling
Markov chains, 201
monotonicity, 250
posets, 198
real random variables, 195
stochastic processes
adapted, 418
definition, 418
filtration, 418
predictable, 418
sample path, 418
supremum, 65–72
stopping time
cover time, see Markov chains
definition, 95
first return time, see Markov chains
first visit time, see Markov chains
https://doi.org/10.1017/9781009305129.011 Published online by Cambridge University Press434 Index
hitting time, 96
strong Markov property, see Markov chains
Strassen’s theorem, 254
sub-exponential variable, see tail bounds
sub-Gaussian increments, 71
sub-Gaussian variable, see tail bounds, 115
submodularity, 254
symmetrization, 55, 82
tail bounds
Azuma–Hoeffding inequality, 114, 124, 125,
177, 300
Bernstein’s inequality, 61, 390
Bernstein’s inequality for bounded variables,
59
Chebyshev’s inequality, 23, 35, 192, 379
Chernoff bound, 53, 122, 288
Chernoff–Cramér bound, 49, 58, 66
definitions, 22
general Bernstein inequality, 59
general Hoeffding inequality, 55, 69
Hoeffding’s inequality, 63, 87
Hoeffding’s inequality for bounded variables, 55
Hoeffding’s lemma, 56
Markov’s inequality, 22, 28, 81, 110, 114
McDiarmid’s inequality, 121, 125, 129, 139, 140
method of bounded differences, 121, 122, 128
Paley–Zygmund inequality, 35
sub-exponential, 58
sub-Gaussian, 54, 66, 83
Talagrand’s inequality, 140
Talagrand’s inequality, see tail bounds
threshold phenomena, 29, 32, 37
tilting, 57
total variation distance, 13
tower property, see conditional expectation
trees
3–1 tree, 47
Cayley’s formula, 4, 20, 42, 394
characterization, 3–4
definition, 3
infinite, 43, 345
uniform spanning tree, 170–176
type, see recurrence
uniform spanning trees, see trees
union bound, 28, 90
Varopoulos–Carne bound, see Markov chains
VC dimension, 84, 87
Wald’s identities, see random walk
Wasserstein distance, 253
Weyl’s inequality, 269
https://doi.org/10.1017/9781009305129.011 Published online by Cambridge University Press
