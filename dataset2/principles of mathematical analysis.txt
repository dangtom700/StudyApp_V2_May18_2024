PRINICPLES OF
MATHEMATICAL
ANALYSISINTERNATIONAL SERIES IN PURE
AND APPLIED MATHEMATICS
William Ted Martin, E.H. Spainer, G. Springer and
P.J. Davis. Consulting Editors
AHLFORS: Complex Analysis
BUCK: Advanced Calculus
BUSACKER AND SAATY: Finite Graphs and Networks
CHENEY: Introduction to Approximation Theory
CHESTER: Techniques in Partial Differential Equations
CODDINGTON AND LEVINSON: Theory of Ordinary Differential Equations
CONTE AND DE BOOR: Elementary Numerical Analysis: An Algorithmic Approach
DENNEMEYER: Introduction to Partial Differential Equations and Boundary Value Problems
DETTMAN: Mathematical Methods in Physics and Engineering
GOLOMB AND SHANKS: Elements of Ordinary Differential Equations
GREENSPAN: Introduction to Partial Differential Equations
HAMMING: Numerical Methods for Scientists and Engineers
HILDEBRAND: Introduction to Numerical Analysis
HOUSEHOLDER: The Numerical Treatment of a Single Nonlinear Equation
KALMAN, FALB, AND ARBIB: Topics in Mathematical Systems Theory
LASS: Vector and Tensor Analysis
MCCARTY: Topology: An Introduction with Applications to Topological Groups
MONK: Introduction to Set Theory
MOORE: Elements of Linear Algebra and Matrix Theory
MOSTOW AND SAMPSON: Linear Algebra
MOURSUND AND DURIS: Elementary Theory and Application of Numerical Analysis
PEARL: Matrix Theory and Finite Mathematics
PIPES AND HARVILL: Applied Mathematics for Engineers and Physicists
RALSTON: A First Course in Numerical Analysis
RITGER AND ROSE: Differential Equations with Applications
RITT: Fourier Series
RUDIN: Principles of Mathematical Analysis
SHAPIRO: Introduction to Abstract Algebra
SIMMONS: Differential Equations with Applications and Historical Notes
SIMMONS: Introduction to Topology and Modern Analysis
SNEDDON: Elements of Partial Differential Equations
STRUBLE: Nonlinear Differential EquationsMcGraw-Hill, Inc.
New York St. Louis San Francisco Auckland Bogota´
Caracas Lisbon London Madrid Mexico City Milan
Montreal New Delhi San Juan Singapore
Sydney Tokyo Toronto
WALTER RUDIN
Professor of Mathematics
University of Wisconsin—Madison
Principles of
Mathematical
Analysis
THIRD EDITIONThis book was set in Euler.
The editors were A. Anthony Arthur and Shelly Levine Langman;
the production supervisor was Leroy A. Young.
R.R. Donnelley & Sons Company was printer and binder.
This book is printed on acid-free paper.
Library of Congress Cataloging in Publication Data
Rudin, Walter, date
Principles of mathematical analysis.
(International series in pure and applied mathematics)
Bibliography: p.
Includes index.
1. Mathematical Analysis. I. Title
QA300.R8 1976 515 75-17903
ISBN-13: 978-0-07-054235-8
ISBN-10: 0-07-054235-X
PRINCIPLES OF MATHEMATICAL ANALYSIS
Copyright © 1964, 1976 by McGraw-Hill, Inc. All rights reserved.
Copyright 1953 by McGraw-Hill, Inc. All rights reserved.
Printed in the United States of America. No part of this publication
may be reproduced, stored in a retrieval system, or transmitted, in any
form or by any means, electronic, mechanical, photocopying, recording, or
otherwise, without the prior written permission of the publisher.
42 43 44 45 DOC 1 5 4 3 2 1FOREWORD i
FOREWORD
Well, I have decided to completely retype Rudin’s Principles of Mathematical Anal￾ysis from scratch. There really are not many compelling reasons to do this—I de￾cided to begin the project just because I was tired of the fact that any time I wanted
to consult Rudin, I had to pull up a scanned copy of a book from the 1970s. Is this
a good reason? Probably not, as who will find value in this document? The main
group of people that need to consult Rudin are undergraduates in analysis courses
that use Rudin. But somebody has to do the work that nobody else will.
My original plan was to type 2 pages per day and be done in six months. How￾ever, to my surprise, five other people were willing to help me by typesetting some
of the chapters. This made the work go much faster than it otherwise would have,
and probably prevented me from only typing the first seven chapters before call￾ing it quits. Thank you. Of course, all of us will remain anonymous due to the fact
that this is a blatant violation of copyright law.
I have made modifications in several places, including global changes to Rudin’s
outdated (or simply bad) notation. These changes are:
• Rather than denoting the field of real numbers by R and the field of rational
numbers by Q, I have denoted them by R and Q, respectively. The same is
true for R
k.
• Rather than denoting the set of positive integers by J, I denote it by N.
• Rather than denoting sequences by {sk}, they are denoted by (sk) or (sk)∞
k=1
.
A real valued sequence is an element of the product RN, and so modern
notation has one write them as ordered tuples. The notation {sk} appears to
define the range of a sequence, not the sequence itself.
• Rather than denoting an ordered k-tuple by {i1, . . . ,ik} as Rudin does in The￾orem 10.14, I have used the notation (i1, . . . ,ik). That Rudin does not do this
is especially strange, given the fact that he does use this notation in Defini￾tion 9.33.
• Some sections, such as Definition 10.18, have been converted into a definition
environment, as that is what their essential purpose is. I have put the title of
the section as Rudin has written it in parenthesis. This shouldn’t cause any
major confusion, as the section number is unchanged (and uniquely identi￾fies each section of the book).
• Proofs are non-indented and written in proof environments; as a result, they
now end with a □ symbol.
• Rather than using the term “nonabsolutely” as Rudin does in Remark 3.46,
I have used the word “conditionally,” as it is much more standard. I have
inserted “[[nonabsolutely]]” after the first instance in which I do this.
• Rather than denoting a continuously differentiable function by C
′
, I have de￾noted it by C
1. Similarly, a function that is twice continuously differentiable
is denoted by C
2, etc.
• At my discretion, I have converted inline math fractions such as 1
2
,
x
|x|
to be
in the form 1/2, x/ |x|. Rudin uses both styles and is not consistent. I have
tried to be more consistent than he was.FOREWORD ii
• The remark above goes for summation symbols too. I have mostly followed
the notation Σan, but in some instances (when the series is sufficiently com￾plex), I have used P when Rudin uses Σ.
• Rather than referencing exercises as “Exercise 5, Chapter 3,” they are refer￾enced as “Exercise 3.5.” As a result, the exercises are numbered as C.E, where
C is the chapter and E is the exercise number as it appears in Rudin.
• Instead of writing Tn
1 Ej
, I have written it in full as Tn
j=1 Ej
.
• Some multi-line equations in Rudin are labeled via a single number that ap￾pears only on the first line, yet the number is supposed to label the entire
multi-line series of equations. I have fixed this.
• In the proof of Theorem 3.54, I have shrunk the text size of one of the equa￾tions in order to make it fit on the page. Rudin opts for an uglier solution of
adding an extra line that only contains − · · · − Qk2 < α2 at the very end.
• In Definition 5.1, Rudin says “If f
′
is defined at every point of a set E ⊂ [a, b],
f is said to be differentiable on E.” However, in Theorems (or proofs of) 5.9,
5.10 and 5.11, he says “f is differentiable in (a, b)” to mean f
′
is defined at
every point of (a, b) ⊂ [a, b]. In the Corollary to Theorem 5.12, he uses “on”
when f is defined on [a, b] and f
′
is differentiable at every point of [a, b]. In
Theorem 5.13, he again uses “in” for the situation where f is defined on [a, b]
and differentiable at every point of (a, b).
This situation continues on. It seems as if Rudin wants to say “differ￾entiable on E” for the situation where f is defined on E and differentiable
at every point of E. However, that is not how he defined it. As a result, I
have changed all instances of “differentiable in E” to “differentiable on E,”
to agree with his definition.
• Many typos have been fixed; however, I can’t help but feel it is likely that
even more have been introduced.
• Instead of placing a footnote to credit V.P. Havin for the proof of Theorem 5.19,
I have written Proof (V.P. Havin). I did this primarily because of whitespace
issues. Let it be noted here that he also translated the second edition of this
book into Russian.
Throughout the entire book, I have altered the way that Rudin uses commas
and creates paragraphs. Rudin is inconsistent with his comma usage and often
grammatically incorrect. He also seems to make new paragraphs whenever he
feels that he is saying something slightly different than the previous sentence—
there are many points throughout the book where he chains three one-sentence
paragraphs together, which I believe is simply bad style.
Page numbering is not identical: this document is slightly shorter than Rudin’s
book. All equation/exercise/theorem/corollary/definition/section/etc. number￾ing is consistent with Rudin’s original copy, however.
The page immediately before this foreword is copied exactly how it appears
in my “International Series in Pure and Applied Mathematics” copy, and so all
relevant data refers to that edition.
Should you wish, you could conceivably print this book out and bind it in some
way. The PDF has dimensions that are exactly the same as Rudin’s book (each pageFOREWORD iii
is 9in by 6in), and the font size is 9pt, as LATEXdefines it, if you’re curious.Contents
Foreword . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . i
Preface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . viii
1 The Real and Complex Number Systems 1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
Ordered Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
The Real Field . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
The Extended Real Number System . . . . . . . . . . . . . . . . . . . . . . 10
The Complex Field . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
Euclidean Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
Appendix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
2 Basic Topology 22
Finite, Countable, and Uncountable Sets . . . . . . . . . . . . . . . . . . . . 22
Metric Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
Compact Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
Perfect Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
Connected Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
3 Numerical Sequences and Series 43
Convergent Sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
Subsequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
Cauchy Sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
Upper and Lower Limits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
Some Special Sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
Series of Nonnegative terms . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
The Number e . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
The Root and Ratio Tests . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
Power Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
ivCONTENTS v
Summation by Parts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
Absolute Convergence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
Addition and Multiplication of Series . . . . . . . . . . . . . . . . . . . . . 66
Rearrangements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
4 Continuity 76
Limits of Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76
Continuous Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78
Continuity and Compactness . . . . . . . . . . . . . . . . . . . . . . . . . . 81
Continuity and Connectedness . . . . . . . . . . . . . . . . . . . . . . . . . 85
Discontinuities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86
Monotonic Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
Infinite Limits and Limits at Infinity . . . . . . . . . . . . . . . . . . . . . . 89
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
5 Differentiation 94
The Derivative of a Real Function . . . . . . . . . . . . . . . . . . . . . . . . 94
Mean Value Theorems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
The Continuity of Derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . 99
L’Hopital’s Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ˆ 99
Derivatives of Higher Order . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
Taylor’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
Differentiation of Vector-valued Functions . . . . . . . . . . . . . . . . . . . 102
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
6 The Riemann-Stieltjes Integral 110
Definition and Existence of the Integral . . . . . . . . . . . . . . . . . . . . 110
Properties of the Integral . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
Integration and Differentiation . . . . . . . . . . . . . . . . . . . . . . . . . 123
Rectifiable Curves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
7 Sequences and Series of Functions 132
Discussion of the Main Problem . . . . . . . . . . . . . . . . . . . . . . . . . 132
Uniform Convergence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
Uniform Convergence and Continuity . . . . . . . . . . . . . . . . . . . . . 137
Uniform Convergence and Integration . . . . . . . . . . . . . . . . . . . . . 140
Uniform Convergence and Differentiation . . . . . . . . . . . . . . . . . . . 141
Equicontinuous Families of Functions . . . . . . . . . . . . . . . . . . . . . 143
The Stone-Weierstrass Theorem . . . . . . . . . . . . . . . . . . . . . . . . . 147
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153CONTENTS vi
8 Some Special Functions 159
Power Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
The Exponential and Logarithmic Functions . . . . . . . . . . . . . . . . . . 165
The Trigonometric Functions . . . . . . . . . . . . . . . . . . . . . . . . . . 169
The Algebraic Completeness of the Complex Field . . . . . . . . . . . . . . 171
Fourier Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172
The Gamma Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183
9 Functions of Several Variables 190
Linear Transformations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
Differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197
The Contraction Principle . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
The Inverse Function Theorem . . . . . . . . . . . . . . . . . . . . . . . . . 207
The Implicit Function Theorem . . . . . . . . . . . . . . . . . . . . . . . . . 210
The Rank Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214
Determinants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218
Derivatives of Higher Order . . . . . . . . . . . . . . . . . . . . . . . . . . . 221
Differentiation of Integrals . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
10 Integration of Differential Forms 230
Integration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230
Primitive Mappings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233
Partitions of Unity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235
Change of Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 236
Differential Forms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238
Simplexes and Chains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251
Stokes’ Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 257
Closed Forms and Exact Forms . . . . . . . . . . . . . . . . . . . . . . . . . 260
Vector Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273
11 The Lebesgue Theory 282
Set Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282
Construction of the Lebesgue Measure . . . . . . . . . . . . . . . . . . . . . 284
Measure Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291
Measurable Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 292
Simple Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 294
Integration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 295
Comparison with the Riemann Integral . . . . . . . . . . . . . . . . . . . . 303
Integration of Complex Functions . . . . . . . . . . . . . . . . . . . . . . . . 306
Functions of Class L 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313CONTENTS vii
Bibliography 316CONTENTS viii
PREFACE
This book is intended to serve as a text for the course in analysis that is usually
taken by advanced undergraduates or by first-year students who study mathe￾matics.
The present edition covers essentially the same topics as the second one, with
some additions, a few minor omissions, and considerable rearrangement. I hope
that these changes will make the material more accessible and more attractive to
the students who take such a course.
Experience has convinced me that it is pedagogically unsound (though logi￾cally correct) to start off with the construction of the real numbers from the rational
ones. At the beginning, most students simply fail to appreciate the need for doing
this. Accordingly, the real number system is introduced as an ordered field with
the least-upper-bound property, and a few interesting applications of this property
are made. However, Dedekind’s construction is not omitted. It is now in an Ap￾pendix to Chapter 1, were it may be studied and enjoyed whenever the time seems
ripe.
The material on functions of several variables is almost completely rewritten,
with many details filled in, and with more examples and more motivation. The
proof of the inverse function theorem—the key item in Chapter 9—is simplified by
means of the fixed point theorem about contraction mappings. Differential forms
are discussed in much greater detail. Several applications of Stokes’ theorem are
included.
As regards other changes, the chapter on the Riemann-Stieltjes integral has
been trimmed a bit, a short do-it-yourself section on the gamma function has been
added to Chapter 8, and there is a large number of new exercises, most of them
with fairly detailed hints.
I have also included several references to articles appearing in the American
Mathematical Monthly and in Mathematics Magazine, in the hope that students will
develop the habit of looking into the journal literature. Most of these references
were kindly supplied by R. B. Burckel.
Over the years, many people students as well as teachers, have sent me correc￾tions, criticisms, and other comments concerning the previous edition of this book.
I have appreciated these, and I take this opportunity to express my sincere thanks
to all who have written me.
WALTER RUDINChapter 1
THE REAL AND COMPLEX NUMBER
SYSTEMS
INTRODUCTION
A satisfactory discussion of the main concepts of analysis (such as convergence,
continuity, differentiation, and integration) must be based on an accurately
defined number concept. We shall not, however, enter into any discussion of the
axioms that govern the arithmetic of the integers, but assume familiarity with the
rational numbers (i.e., the numbers of the form m/n where m and n are integers
and n ̸= 0 ).
The rational number system is inadequate for many purposes, both as a field
and as an ordered set. (These terms will be defined in Definitions 1.6 and 1.12.) For
instance, there is no rational p such that p
2 = 2. (We shall prove this presently.)
This leads to the introduction of so-called ”irrational numbers” which are often
written as infinite decimal expansions and are considered to be ”approximated”
by the corresponding finite decimals. Thus the sequence
1, 1.4, 1.41, 1.414, 1.4142, . . .
“tends to √
2.” But unless the irrational number √
2 has been clearly defined, the
question must arise: Just what is it that this sequence “tends to”?
This sort of question can be answered as soon as the so-called “real number
system” is constructed.
1.1 Example. We now show that the equation
(1.1) p
2 = 2
is not satisfied by any rational p. If there were such a p, we could write p = m/n
where m and n are integers that are not both even. Let us assume this is done.
1INTRODUCTION 2
Then (1.1) implies
(1.2) m2 = 2n2
,
This shows that m2 is even. Hence m is even (if m were odd, m2 would be odd),
and so m2 is divisible by 4. It follows that the right side of (1.2) is divisible by 4, so
that n
2 is even, which implies that n is even.
The assumption that (1.1) holds thus leads to the conclusion that both m and n
are even, contrary to our choice of m and n. Hence (1.1) is impossible for rational
p.
We now examine this situation a little more closely. Let A be the set of all
positive rationals p such that p
2 < 2 and let B consist of all positive rationals p
such that p
2 > 2. We shall show that A contains no largest number and B contains no
smallest.
More explicitly, for every p in A we can find a rational q in A such that p < q,
and for every p in B we can find a rational q in B such that q < p.
To do this, we associate with each rational p > 0 the number
(1.3) q = p −
p
2 − 2
p + 2
=
2p + 2
p + 2
.
Then
(1.4) q
2 − 2 =
2(p
2 − 2)
(p + 2)
2
.
If p is in A, then p
2 − 2 < 0, (1.3) shows that q > p and (1.4) shows that q
2 < 2.
Thus q is in A.
If p is in B, then p
2 − 2 > 0, (1.3) shows that 0 < q < p, and (1.4) shows that
q
2 > 2. Thus q is in B.
1.2 Remark. The purpose of the above discussion has been to show that the ra￾tional number system has certain gaps, in spite of the fact that between any two
rationals there is another: if r < s, then r < (r + s)/2 < s. The real number system
fills these gaps. This is the principal reason for the fundamental role for which it
plays in analysis.
In order to elucidate its structure, as well as that of the complex numbers, we
start with a brief discussion of the general concepts of ordered set and field.
Here is some of the standard set-theoretic terminology that will be used through￾out this book.
1.3 Definitions. If A is any set (whose elements may be numbers or any other
objects), we write x ∈ A to indicate that x is a member (or an element) of A. If x is
not a member of A, we write x ∈/ A.
The set which contains no element will be called the empty set. If a set has at
least one element, it is called nonempty.ORDERED SETS 3
If A and B are sets, and if every element of A is an element of B, we say that A
is a subset of B, and we write A ⊂ B, or B ⊃ A. If, in addition, there is an element
of B which is not in A, then A is said to be a proper subset of B. Note that A ⊂ A
for every set A.
If A ⊂ B and B ⊂ A, we write A = B. Otherwise, A ̸= B.
1.4 Definition. Throughout Chap. 1, the set of all rational numbers will be denoted
by Q.
ORDERED SETS
1.5 Definition. Let S be a set. An order on S is a relation, denoted by <, with the
following two properties
(i) If x ∈ S and y ∈ S, then one and only one of the statements
x < y, x = y, y < x
is true.
(ii) If x, y, z ∈ S, if x < y and y < z, then x < z.
The statement “x < y” may be read as “x is less than y ” or “x is smaller than y” or
“x precedes y”.
It is often convenient to write y > x in place of x < y.
The notation x ≤ y indicates that x < y or x = y, without specifying which of
these two is to hold. In other words, x ≤ y is the negation of x > y.
1.6 Definition. An ordered set is a set S in which an order is defined.
For example, Q is an ordered set if r < s is defined to mean that s − r is a
positive rational number.
1.7 Definition. Suppose S is an ordered set, and E ⊂ S. If there exists a β ∈ S such
that x ≤ β for every x ∈ E, we say that E is bounded above, and call β an upper bound
of E.
Lower bounds are defined the same way (with ≥ in place of ≤).
1.8 Definition. Suppose S is an ordered set, E ⊂ S, and E is bounded above. Sup￾pose there exists an α ∈ S with the following properties:
(i) α is an upper bound of E.
(ii) If γ < α then γ is not an upper bound of E.
Then α is called the least upper bound of E [that there is at most one such α is clear
from (ii)] or the supremum of E, and we write
α = sup E.ORDERED SETS 4
The greatest lower bound, or infimum, of a set E which is bounded below is defined
in the same manner: The statement
α = inf E
means that α is a lower bound of E and that no β with β > α is a lower bound
of E.
1.9 Examples.
(a) Consider the sets A and B of Example 1.1 as subsets of the ordered set Q.
The set A is bounded above. In fact, the upper bounds of A are exactly the
members of B. Since B contains no smallest member, A has no least upper
bound in Q.
Similarly, B is bounded below: the set of all lower bounds of B consists
of A and of all r ∈ Q with r ≤ 0. Since A has no largest member, B has no
greatest lower bound in Q.
(b) If α = sup E exists, then α may or may not be a member of E. For instance,
let E1 be the set of all r ∈ Q with r < 0. Let E2 be the set of all r ∈ Q with
r ≤ 0. Then
sup E1 = sup E2 = 0,
and 0 ∈/ E1, 0 ∈ E2.
(c) Let E consist of all numbers 1/n, where n = 1, 2, 3, . . . . Then sup E = 1,
which is in E, and inf E = 0, which is not in E.
1.10 Definition. An ordered set S is said to have the least-upper-bound property if
the following is true:
If E ⊂ S, E is not empty, and E is bounded above, then sup E exists in S.
Example 1.9(a) shows that Q does not have the least-upper-bound property.
We shall now show that there is a close relation between greatest lower bounds
and least upper bounds, and that every ordered set with the least-upper-bound
property also has the greatest-lower-bound property.
1.11 Theorem. Suppose S is an ordered set with the least-upper-bound property, B ⊂ S,
B is not empty, and B is bounded below. Let L be the set of all lower bounds of B. Then
α = sup L
exists in S and α = inf B.
In particular, inf B exists in S.
Proof. Since B is bounded below, L is not empty. Since L consists of exactly those
y ∈ S which satisfy the inequality y ≤ x for every x ∈ B, we see that every x ∈ B
is an upper bound of L. Thus L is bounded above. Our hypothesis about S implies
therefore that L has a supremum in S; call it α.FIELDS 5
If γ < α then (see Definition 1.8) γ is not an upper bound of L, hence γ ∈/ B. It
follows that α ≤ x for every x ∈ B. Thus α ∈ L.
If α < β then β ∈/ L, since α is an upper bound of L.
We have shown that α ∈ L but β ∈/ L if β > α. In other words, α is a lower
bound of B, but β is not if β > α. This means that α = inf B.
FIELDS
1.12 Definition. A field is a set F with two operations, called addition and
multiplication, which satisfy the following so-called ”field axioms” (A), (M),
and (D):
(A) Axioms for addition
(A1) x ∈ F and y ∈ F, then their sum x + y is in F.
(A2) Addition is commutative: x + y = y + x for all x, y ∈ F.
(A3) Addition is associative: (x + y) + z = x + (y + z) for all x, y, z ∈ F.
(A4) F contains an element 0 such that 0 + x = x for every x ∈ F.
(A5) To every x ∈ F corresponds an element −x ∈ F such that
x + (−x) = 0.
(M) Axioms for multiplication
(M1) If x ∈ F, then their product xy is in F.
(M2) Multiplication is commutative: xy = yx for all x, y ∈ F.
(M3) Multiplication is associative: (xy)z = x(yz) for all x, y, z ∈ F.
(M4) F contains an element 1 ̸= 0 such that 1x = x for every x ∈ F.
(M5) If x ∈ F and x ̸= 0 then there exists an element 1/x ∈ F such that
x · (1/x) = 1.
(D) The distributive law
x(y + z) = xy + xz
holds for all x, y, z ∈ F.
1.13 Remarks.
(a) One usually writes (in any field)
x − y,
x
y
, x + y + z, xyz, x
2
, x
3
, 2x, 3x, . . .
in place of
x + (−y), x ·

1
y

, (x + y) + z, (xy)z, xx, xxx, x + x, x + x + x, . . .FIELDS 6
(b) The field axioms clearly hold in Q, the set of all rational numbers, if addition
and multiplication have their customary meaning. Thus Q is a field.
(c) Although it is not our purpose to study fields (or any other algebraic struc￾tures) in detail, it is worthwhile to prove that some of the familiar properties
of Q are consequences of the field axioms; once we do this, we will not need
to do it again for the real numbers and for the complex numbers.
1.14 Proposition. The axioms for addition imply the following statements.
(a) If x + y = x + z then y = z.
(b) If x + y = x then y = 0.
(c) If x + y = 0 then y = −x.
(d) −(−x) = x.
Statement (a) is a cancellation law. Note that (b) asserts the uniqueness of the
element whose existence is assumed in (A4), and that (c) does the same for (A5).
Proof. If x + y = x + z, the axioms (A) give
y = 0 + y = (−x + x) + y = −x + (x + y)
= −x + (x + z) = (−x + x) + z = 0 + z = z.
This proves (a). Take z = 0 in (a) to obtain (b). Take z = −x in (a) to obtain (c).
Since −x + x = 0, (c) (with −x in place of x) gives (d).
1.15 Proposition. The axioms for multiplication imply the following statements
(a) If x ̸= 0 and xy = xz then y = z.
(b) If x ̸= 0 and xy = x then y = 1.
(c) If x ̸= 0 and xy = 1 then y = 1/x.
(d) If x ̸= 0 then 1/(1/x) = x.
The proof is so similar to that of Proposition 1.14 that we omit it.
1.16 Proposition. The field axioms imply the following statements, for any x, y, z ∈ F.
(a) 0x = 0.
(b) If x ̸= 0 and y ̸= 0 then xy ̸= 0.
(c) (−x)y = −(xy) = x(−y).
(d) (−x)(−y) = xy.
Proof. 0x + 0x = (0 + 0)x = 0x. Hence Proposition 1.14(b) implies that 0x = 0, and
(a) holds. Next, assume x ̸= 0, y ̸= 0, but xy = 0. Then (a) gives
1 =

1
y
  1
x

xy =

1
y
  1
x

0 = 0,
a contradiction. Thus (b) holds.FIELDS 7
The first equality in (c) comes from
(−x)y + xy = (−x + x)y = 0y = 0,
combined with Proposition 1.14(c); the other half of (c) is proved in the same way.
Finally,
(−x)(−y) = −[x(−y)] = −[−(xy)] = xy
by (c) and Proposition 1.14(d).
1.17 Definition. An ordered field is a field F which is also an ordered set, such that
(i) x + y < x + z if x, y, z ∈ F and y < z,
(ii) xy > 0 if x ∈ F, y ∈ F, x > 0, and y > 0.
If x > 0, we call x positive; if x < 0, x is negative.
For example, Q is an ordered field.
All the familiar rules for working with inequalities apply in every ordered field:
Multiplication by positive [negative] quantities preserves [reverses] inequalities,
no square is negative, etc. The following proposition lists some of these.
1.18 Proposition. The following statements are true in every ordered field.
(a) If x > 0 then −x < 0, and vice versa.
(b) If x > 0 and y < z then xy < xz.
(c) If x < 0 and y < z then xy > xz.
(d) If x ̸= 0 then x
2 > 0. In particular, 1 > 0.
(e) If 0 < x < y then 0 < 1/y < 1/x.
Proof.
(a) If x > 0 then 0 = −x + x > −x + 0, so that −x < 0. If x < 0 then 0 = −x + x <
−x + 0, so that −x > 0. This proves (a).
(b) Since z > y, we have z − y > y − y = 0, hence x(z − y) > 0, and therefore
xz = x(z − y) + xy > 0 + xy = xy.
(c) By (a), (b), and Proposition 1.16(c),
−[x(z − y)] = (−x)(z − y) > 0,
so that x(z − y) < 0, hence xz < xy.
(d) If x > 0, part (ii) of Definition 1.17 gives x
2 > 0. If x < 0, then −x > 0, hence
(−x)
2 > 0. But x
2 = (−x)
2 by Proposition 1.16(d). Since 1 = 1
2, 1 > 0.
(e) If y > 0 and v ≤ 0, then yv ≤ 0. But y · (1/y) = 1 > 0. Hence 1/y > 0.
Likewise, 1/x > 0. If we multiply both sides of the inequality x < y by the
positive quantity (1/x)(1/y), we obtain 1/y < 1/x.THE REAL FIELD 8
THE REAL FIELD
We now state the existence theorem which is the core of this chapter.
1.19 Theorem. There exists an ordered field R which has the least-upper-bound property.
Moreover, R contains Q as a subfield.
The second statement means that Q ⊂ R and that the operations of addition
and multiplication in R, when applied to members of Q, coincide with the usual
operations on rational numbers; also, the positive rational numbers are positive
elements of R. The members of R are called real numbers.
The proof of Theorem 1.19 is rather long and a bit tedious and is therefore
presented in an Appendix to Chap. 1. The proof actually constructs R from Q.
The next theorem could be extracted from this construction with very little ex￾tra effort. However, we prefer to derive it from Theorem 1.19 since this provided a
good illustration of what one can do with the least-upper-bound property.
1.20 Theorem.
(a) If x ∈ R, y ∈ R, and x > 0, then there is a positive integer n such that
nx > y.
(b) If x ∈ R, y ∈ R, and x < y, then there exists a p ∈ Q such that x < p < y.
Part (a) is usually referred to as the archimedean property of R. Part (b) may be
stated by saying that Q is dense in R: Between any two real numbers, there is a
rational one.
Proof.
(a) Let A be the set of all nx, where n runs through the positive integers. If (a)
were false, then y would be an upper bound of A. But then A has a least
upper bound in R. Put α = sup A. Since x > 0, α − x < α, and α − x is not
an upper bound of A. Hence α − x < mx for some positive integer m. But
then α < (m + 1)x ∈ A, which is impossible, since α is an upper bound of A.
(b) Since x < y, we have y − x > 0, and (a) furnishes a positive integer n such
that
n(y − x) > 1.
Apply (a) again, to obtain positive integers m1 and m2 such that m1 > nx,
m2 > −nx. Then
−m2 < nx < m1.
Hence there is an integer m (with −m2 ≤ m ≤ m1) such that
m − 1 ≤ nx < m.THE REAL FIELD 9
If we combine these inequalities, we obtain
nx < m ≤ 1 + nx < ny.
Since n > 0, it follows that
x <
m
n
< y.
This proves (b), with p = m/n.
We shall now prove the existence of nth roots of positive reals. This proof will
show how the difficulty pointed out in the Introduction (irrationality of √
2) can
be handled in R.
1.21 Theorem. For every real x > 0 and every integer n > 0, there is one and only one
positive real y such that y
n = x.
This number y is written n√
x or x
1/n.
Proof. That there is at most one such y is clear, since 0 < y1 < y2 implies y
n
1 < yn
2
.
Let E be the set consisting of all positive real numbers t such that t
n < x. If
t = x/(1 + x) then 0 ≤ t < 1. Hence t
n ≤ t < x. Thus t ∈ E, and E is not empty.
If t > 1 + x then t
n ≥ t > x so that t ∈/ E. Thus 1 + x is an upper bound of E.
Hence Theorem 1.19 implies the existence of
y = sup E.
To prove that y
n = x we will show that each of the inequalities y
n < x and y
n > x
leads to a contradiction.
The identity b
n − a
n = (b − a)(b
n−1 + b
n−2a + · · · + a
n−1) yields the in￾equality
b
n − a
n < (b − a)nbn−1
when 0 < a < b.
Assume y
n < x. Choose h so that 0 < h < 1 and
h < x − y
n
n(y + 1)n−1
.
Put a = y, b = y + h. Then
(y + h)
n − y
n < hn(y + h)
n−1 < hn(y + 1)
n−1 < x − y
n.
Thus (y + h)
n < x and y + h ∈ E. Since y + h > y, this contradicts the fact that y
is an upper bound of E.
Assume y
n > x. Put
k =
y
n − x
nyn−1
.THE EXTENDED REAL NUMBER SYSTEM 10
Then 0 < k < y. If t ≥ y − k, we conclude that
y
n − t
n ≤ y
n − (y − k)
n < knyn−1 = y
n − x.
Thus t
n > x and t ∈/ E. It follows that y − k is an upper bound of E. But y − k < y,
which contradicts the fact that y is the least upper bound of E.
Hence y
n = x, and the proof is complete.
Corollary. If a and b are positive real numbers and n is a positive integer, then
(ab)
1/n = a
1/nb
1/n.
Proof. Put α = a
1/n, β = b
1/n. Then
ab = α
nβ
n = (αβ)
n
since multiplication is commutative. [Axiom (M2) in Definition 1.12.] The unique￾ness assertion of Theorem 1.21 shows therefore that
(ab)
1/n = αβ = a
1/nb
1/n.
1.22 Decimals. We conclude this section by pointing out the relation between real
numbers and decimals.
Let x > 0 be real. Let n0 be the largest integer such that n0 ≤ x. (Note that
the existence of n0 depends on the archimedean property of R.) Having chosen
n0, n1, . . . , nk−1, let nk denote the largest integer such that
n0 +
n1
10 + · · · +
nk
10k
≤ x.
Let E be the set of these numbers
(1.5) n0 +
n1
10 + · · · +
nk
10k
(k = 0, 1, 2, . . .).
Then x = sup E. The decimal expansion of x is
(1.6) n0.n1n2n3 · · · .
Conversely, for any infinite decimal expansion (1.6) the set E of numbers (1.5) is
bounded above and (1.6) is the decimal expansion of sup E.
Since we shall never use decimals, we do not enter into a detailed discussion.
THE EXTENDED REAL NUMBER SYSTEM
1.23 Definition. The extended real number system consists of the real field R and
two symbols, +∞ and −∞. We preserve the original order in R and define
−∞ < x < +∞THE COMPLEX FIELD 11
for every x ∈ R.
It is then clear that +∞ is an upper bound of every subset of the extended real
number system, and that every nonempty subset has a least upper bound. If, for
example, E is a nonempty subset of real numbers which is not bounded above in
R, then sup E = +∞ in the extended real number system.
Exactly the same remarks apply to lower bounds.
The extended real number system does not form a field, but it is customary to
make the following conventions:
(a) If x is real then
x + ∞ = +∞, x − ∞ = −∞,
x
+∞
=
x
−∞
= 0.
(b) If x > 0 then x · (+∞) = +∞, x · (−∞) = −∞.
(c) If x < 0 then x · (+∞) = −∞, x · (−∞) = +∞.
When it is desired to make the distinction between real numbers on the one
hand and the symbols +∞ and −∞ on the other quite explicit, the former are
called finite.
THE COMPLEX FIELD
1.24 Definition. A complex number is an ordered pair (a, b) of real numbers. “Or￾dered” means that (a, b) and (b, a) are regarded as distinct if a ̸= b.
Let x = (a, b), y = (c, d) be two complex numbers. We write x = y if and only
if a = c and b = d. (Note that this definition is not entirely superfluous; think of
equality of rational numbers, represented as quotients of integers.) We define
x + y = (a + c, b + d)
xy = (ac − bd, ad + bc).
1.25 Theorem. These definitions of addition and multiplication turn the set of all complex
numbers into a field, which (0, 0) and (1, 0) in the role of 0 and 1.
Proof. We simply verify the field axioms, as listed in Definition 1.12. (Of course,
we use the field structure of R.) Let x = (a, b), y = (c, d), z = (e, f).
(A1) is clear.
(A2) x + y = (a + c, b + d) = (c + a, d + b) = y + x.
(A3) (x + y) + z = (a + c, b + d) + (e, f)
= (a + c + e, b + d + f)
= (a, b) + (c + e, d + f) = x + (y + z).
(A4) x + 0 = (a, b) + (0, 0) = (a, b) = x.
(A5) Put −x = (−a, −b). Then x + (−x) = (0, 0) = 0.THE COMPLEX FIELD 12
(M1) is clear.
(M2) xy = (ac − bd, ad + bc) = (ca − db, da + cb) = yx.
(M3) (xy)z = (ac − bd, ad + bc)(e, f)
= (ace − bde − adf − bcf, acf − bdf + ade + bce)
= (a, b)(ce − df, cf + de) = x(yz).
(M4) 1x = (1, 0)(a, b) = (a, b) = x.
(M5) If x ̸= 0 then (a, b) ̸= (0, 0), which means that at least one of the real numbers
a, b is different from 0. Hence a
2 + b
2 > 0, by Proposition 1.18(d), and we
can define
1
x
=

a
a2 + b2
,
−b
a2 + b2

.
Then
x ·
1
x
= (a, b)

a
a2 + b2
,
−b
a2 + b2

= (1, 0) = 1.
(D) x(y + z) = (a, b)(c + e, d + f)
= (ac + ae − bd − bf, ad + af + bc + be)
= (ac − bd, ad + bc) + (ae − bf, af + be)
= xy + xz.
1.26 Theorem. For any real numbers a and b we have
(a, 0) + (b, 0) = (a + b, 0), (a, 0)(b, 0) = (ab, 0).
The proof is trivial.
Theorem 1.26 shows that the complex numbers of the form (a, 0) have the same
arithmetic properties as the corresponding real numbers a. We can therefore iden￾tify (a, 0) with a. This identification gives us the real field as a subfield of the
complex field.
The reader may have noticed that we defined the complex numbers without
any reference to the mysterious square root of −1. We now show that the notation
(a, b) is equivalent to the more customary a + bi.
1.27 Definition. i = (0, 1).
1.28 Theorem. i
2 = −1.
Proof. i
2 = (0, 1)(0, 1) = (−1, 0) = −1.
1.29 Theorem. If a and b are real, then (a, b) = a + bi.
Proof.
a + bi = (a, 0) + (b, 0)(0, 1)
= (a, 0) + (0, b) = (a, b).THE COMPLEX FIELD 13
1.30 Definition. If a, b are real and z = a + bi, then the complex number z = a − bi
is called the conjugate of z. The numbers a and b are the real part and the imaginary
part of z, respectively.
We shall occasionally write
a = Re(z), b = Im(z).
1.31 Theorem. If z and w are complex, then
(a) z + w = z + w,
(b) zw = z · w,
(c) z + z = 2 Re(z), z − z = 2iIm(z),
(d) zz is real and positive (except when z = 0).
Proof. (a), (b), and (c) are quite trivial. To prove (d), write z = a + bi, and note that
zz = a
2 + b
2.
1.32 Definition. If z is a complex number, its absolute value |z| is the non-negative
square root of zz ; that is |z| = (zz)
1/2.
The existence (and uniqueness) of |z| follows from Theorem 1.21 and part (d)
of Theorem 1.31.
Note that when x is real, then x = x, hence |x| =
√
x
2. Thus |x| = x if x ≥ 0,
|x| = −x if x < 0.
1.33 Theorem. Let z and w be complex numbers. Then
(a) |z| > 0 unless z = 0, |0| = 0,
(b) |z| = |z|,
(c) |zw| = |z| |w|,
(d) |Re(z)| ≤ |z|,
(e) |z + w| ≤ |z| + |w|.
Proof. (a) and (b) are trivial. Put z = a + bi, w = c + di, with a, b, c, d real. Then
|zw|
2 = (ac − bd)
2 + (ad + bc)
2 = (a
2 + b
2
)(c
2 + d
2
) = |z|
2
|w|
2
or |zw|
2 = (|z| |w|)
2. Now (c) follows from the uniqueness assertion of Theo￾rem 1.21.
To prove (d), note that a
2 ≤ a
2 + b
2, hence
|a| =
√
a2 ≤
p
a2 + b2.EUCLIDEAN SPACES 14
To prove (e), note that zw is the conjugate of zw, so that zw + zw = 2Re(zw).
Hence
|z + w|
2 = (z + w)(z + w) = zz + zw + zw + ww
= |z|
2 + 2 Re(zw) + |w|
2
≤ |z|
2 + 2 |zw| + |w|
2
= |z|
2 + 2 |z| |w| + |w|
2 = (|z| + |w|)
2
.
Now (e) follows by taking square roots.
1.34 Notation. If x1, . . . , xn are complex numbers, we write
x1 + x2 + · · · + xn =
Xn
j=1
xj
.
We conclude this section with an important inequality, usually known as the
Schwarz inequality.
1.35 Theorem. If a1, . . . , an and b1, . . . , bn are complex numbers, then






Xn
j=1
ajbj






2
≤
Xn
j=1

aj


2Xn
j=1

bj


2
.
Proof. Put A = Σ|aj
|
2, B = Σ|bj
|
2, C = Σajbj
(in all sums in this proof, j runs over
the values 1, . . . , n). If B = 0, then b1 = · · · = bn = 0, and the conclusion is trivial.
Assume therefore that B > 0. By Theorem 1.31 we have
X
Baj − Cbj


2 =
X(Baj − Cbj
)(Baj − Cbj
)
= B
2X
aj


2 − BC
Xajbj − BCXajbj + |C|
2X
bj


2
= B
2A − B |C|
2
= B(AB − |C|
2
).
Since each term in the first sum is nonnegative, we see that
B(AB − |C|)
2 ≥ 0.
Since B > 0, it follows that AB − |C|
2 ≥ 0. This is the desired inequality.
EUCLIDEAN SPACES
1.36 Definitions. For each positive integer k, let Rk be the set of all ordered k￾tuples
x = (x1, x2, . . . , xk),EUCLIDEAN SPACES 15
where x1, . . . , xk are real numbers, called the coordinates of x. The elements of Rk
are called points, or vectors, especially when k > 1. We shall denote vectors by
boldfaced letters. If y = (y1, . . . , yk) and if α is a real number, put
x + y = (x1 + y1, . . . , xk + yk)
αx = (αx1, . . . , αxn)
so that x + y ∈ Rk and αx ∈ Rk. This defines addition of vectors, as well as
multiplication of a vector by a real number (a scalar). These two operations satisfy
the commutative, associative, and distributive laws (the proof is trivial, in view of
the analogous laws for the real numbers) and make Rk into a vector space over the
real field. The zero element of Rk (sometimes called the origin or the null vector) is
the point 0, all of whose coordinates are 0.
We also define the so-called ”inner product” (or scalar product) of x and y by
x · y =
X
k
i=1
xiyi
and the norm of x by
|x| = (x · x)
1/2 =
 X
k
i=1
x
2
i
!1/2
.
The structure now defined (the vector space Rk with the above inner product
and norm is called euclidean k-space.
1.37 Theorem. Suppose x, y, z ∈ Rk, and α is real. Then
(a) |x| ≥ 0;
(b) |x| = 0 if and only if x = 0;
(c) |αx| = |α| |x|;
(d) |x · y| ≤ |x| |y|;
(e) |x + y| ≤ |x| + |y|;
(f) |x − z| ≤ |x − y| + |y − z|.
Proof. (a), (b), and (c) are obvious, and (d) is an immediate consequence of the
Schwarz inequality. By (d) we have
|x + y|
2 = (x + y) · (x + y)
= x · x + 2x · y + y · y
≤ |x|
2 + 2 |x| |y| + |y|
2
= (|x| + |y|)
2
,
so that (e) is proved. Finally (f) follows from (e) if we replace x by x − y and y by
y − z.APPENDIX 16
1.38 Remarks. Theorem 1.37(a), (b), and (f) will allow us (see Chap. 2) to regard
Rk as a metric space.
R1 (the set of all real numbers) is usually called the line, or the real line. Like￾wise, R2 is called the plane, or the complex plane (compare Definitions 1.24 and
1.36). In these two cases, the norm is just the absolute value of the corresponding
real or complex number.
APPENDIX
Theorem 1.19 will be proved in this appendix by constructing R from Q. We shall
divide the construction into several steps.
Step 1 The members of R will be certain subsets of Q, called cuts. A cut is, by
definition, any set α ⊆ Q with the following three properties.
(I) α is not empty, and α ̸= Q.
(II) If p ∈ α, q ∈ Q, and q < p, then q ∈ α.
(III) If p ∈ α, then p < r for some r ∈ α.
The letters p, q, r, . . . will always denote rational numbers, and α, β, γ, . . . will
denote cuts.
Note that (III) simply says that α has no largest member; (II) implies two facts
which will be used freely:
If p ∈ α and q ∈/ α, then p < q.
If r ∈/ α and r < s, then s ∈/ α.
Step 2 Define “α < β” to mean: α is a proper subset of β.
Let us check that this meets the requirements of Definition 1.5.
If α < β and β < γ it is clear that α < γ. (A proper subset of a proper subset is
a proper subset.) It is also clear that at most one of the three relations
α < β, α = β, β < α
can hold for any pair α, β. To show that at least one holds, assume that the first
two fail. Then α is not a subset of β. Hence there is a p ∈ α with p ∈/ β. If q ∈ β,
it follows that q < p (since p ∈/ β), hence q ∈ α, by (II). Thus β ⊂ α. Since β ̸= α,
we conclude β < α.
Thus R is now an ordered set.
Step 3 The ordered set R has the least upper bound property.
To prove this, let A be a nonempty subset of R, and assume that β ∈ R is
an upper bound of A. Define γ to be the union of all α ∈ A. In other words,
p ∈ γ if and only if p ∈ α for some α ∈ A. We shall prove that γ ∈ R and that
γ = sup A.
Since A is not empty, there exists an α0 ∈ A. This α0 is not empty. Since
α0 ⊂ γ, γ is not empty. Next, γ ⊂ β (since α ⊂ β for every α ∈ A ), and therefore
γ ̸= Q. Thus γ satisfies property (I). To prove (II) and (III), pick p ∈ γ. Then p ∈ α1APPENDIX 17
for some α1 ∈ A. If q < p, then q ∈ α1, hence q ∈ γ; this proves (II). If r ∈ α1 is so
chosen that r > p, we see that r ∈ γ (since α1 ⊂ γ), and therefore γ satisfies (III).
Thus γ ∈ R.
It is clear that α ≤ γ for every α ∈ A.
Suppose δ < γ. Then there is an s ∈ γ such that s ∈/ δ. Since s ∈ γ, s ∈ α for
some α ∈ A. Hence δ < α and δ is not an upper bound of A.
This gives the desired result: γ = sup A.
Step 4 If α ∈ R and β ∈ R, we define α + β to be the set of all sums r + s, where
r ∈ α and s ∈ β.
We define 0
∗
to be the set of all negative rational numbers. It is clear that 0
∗
is a cut. We verify that the axioms for addition (see Definition 1.12) hold in R, with 0
∗
playing the role of 0.
(A1) We have to show that α + β is a cut. It is clear that α + β is a nonempty subset
of Q. Take r
′ ∈/ α, s
′ ∈/ β. Then r
′ + s
′ > r + s for all choices of r ∈ α, s ∈ β.
Thus r
′ + s
′ ∈/ α + β. It follows that α + β has property (I).
Pick p ∈ α + β. Then p = r + s, with r ∈ α, s ∈ β. If q < p, then q − s < r,
so q − s ∈ α, and q = (q − s) + s ∈ α + β. Thus (II) holds. Choose t ∈ α so
that t > r. Then p < t + s and t + s ∈ α + β. Thus (III) holds.
(A2) α + β is the set of all r + s, with r ∈ α, s ∈ β. By the same definition, β + α
is the set of all s + r. Since r + s = s + r for all r ∈ Q, s ∈ Q, we have
α + β = β + α.
(A3) As above, this follows from the associative law in Q.
(A4) If r ∈ α and s ∈ 0
∗
, then r + s < r, hence r + s ∈ α. Thus α + 0
∗ ⊂ α.
To obtain the opposite inclusion, pick p ∈ α, and pick r ∈ α, r > p. Then
p − r ∈ 0
∗
, and p = r + (p − r) ∈ α + 0
∗
. This α ⊂ α + 0
∗
. We conclude that
α + 0
∗ = α.
(A5) Fix α ∈ R. Let β be the set of all p with the following property:
There exists r > 0 such that −p − r ∈/ α
In other words, some rational number smaller than −p fails to be in α.
We show that β ∈ R and that α + β = 0
∗
.
If s ∈/ α and p = −s − 1, then −p − 1 ∈/ α, hence p ∈ β. So β is not empty.
If q ∈ α, then −q ∈/ β. So β ̸= Q. Hence β satisfies (I).
Pick p ∈ β and r > 0 so that −p − r ∈/ α. If q < p, then −q − r > −p − r,
hence −q − r ∈/ α. Thus q ∈ β and (II) holds. Put t = p + (r/2). Then t > p
and −t − (r/2) = −p − r ∈/ α, so that t ∈ β. Hence β satisfies (III).
We have proved that β ∈ R.
If r ∈ α and s ∈ β, then −s ∈/ α, hence r < −s, r + s < 0. Thus α + β ⊂ 0
∗
.
To prove the opposite inclusion, pick v ∈ 0
∗
, put w = −v/2. Then w > 0
and there is an integer n such that nw ∈ α but (n + 1)w ∈/ α. (Note that
this depends on the fact that Q has the archimedean property!) Put p =
−(n + 2)w. Then p ∈ β, since −p − w ∈/ α and
v = nw + p ∈ α + β.APPENDIX 18
Thus 0
∗ ⊂ α + β.
We conclude that α + β = 0
∗
. This β will of course be denoted by −α.
Step 5 Having proved that the addition defined in Step 4 satisfies axioms (A) of
Definition 1.12, it follows that Proposition 1.14 is valid in R, and we can prove one
of the requirements in Definition 1.17:
If α, β, γ ∈ R and β < γ, then α + β < α + γ.
Indeed, it is obvious from the definition of + in R that α + β ⊂ α + γ; if
we had α + β = α + γ, the cancellation law (Proposition 1.14) would imply
β = γ.
It also follows that α > 0∗
if and only if −α < 0∗
.
Step 6 Multiplication is a little more bothersome than addition in the present con￾text, since products of negative rationals are positive. For this reason we confine
ourselves first to R+ the set of all α ∈ R with α > 0∗
.
If α ∈ R+ and β ∈ R+, we define αβ to be the set of all p ≤ rs for some choice
of r ∈ α, s ∈ β, r > 0, s > 0.
We define 1
∗
to be the set of all q < 1.
Then the axioms (M) and (D) of Definition 1.12 hold, with R+ in place of F, and with
1
∗
in the role of 1.
The proofs are so similar to the ones given in detail in Step 4 that we omit
them.
Note, in particular, that the second requirement of Definition 1.17 holds: If
α > 0∗ and β > 0∗
, then αβ > 0∗
.
Step 7 We complete the definition of multiplication by setting α0∗ = 0
∗α = 0
∗
,
and by setting
αβ =



(−α)(−β) if α < 0∗
, β < 0∗
,
−[(−α)β] if α < 0∗
, β > 0∗
,
−[α(−β)] if α > 0∗
, β < 0∗
.
The products on the right were defined in Step 6.
Having proved (in Step 6) that the axioms (M) hold in R+, it is now perfectly
simple to prove them in R, by repeated application of the identity γ = −(−γ)
which is part of Proposition 1.14. (See Step 5.)
The proof of the distributive law
α(β + γ) = αβ + αγ
breaks into cases. For instance, suppose α > 0∗
, β < 0∗
, β + γ > 0∗
. Then γ =
(β + γ) + (−β), and (since we already know that the distributive law holds in R+)
αγ = α(β + γ) + α · (−β).APPENDIX 19
but α · (−β) = −(αβ). Thus
αβ + αγ = α(β + γ).
The other cases are handled in the same way.
We have now completed the proof that R is an ordered field with the least upper bound
property.
Step 8 We associate with each r ∈ Q the set r
∗ which consists of all p ∈ Q such
that p < r. It is clear that each r
∗
is a cut; that is, r
∗ ∈ R. These cuts satisfy the
following relations:
(a) r
∗ + s
∗ = (r + s)
∗
(b) r
∗
s
∗ = (rs)
∗
,
(c) r
∗ < s∗
if and only if r < s.
To prove (a), choose p ∈ r
∗ + s
∗
. Then p = u + v, where u < r, v < s. Hence
p < r + s, which says that p ∈ (r + s)
∗
.
Conversely, suppose p ∈ (r + s)
∗
. Then p < r + s. Choose t so that 2t =
r + s − p, put
r
′ = r − t, s
′ = s − t.
Then r
′ ∈ r
∗
, s
′ ∈ s
∗
, and p = r
′ + s
′
, so that p ∈ r
∗ + s
∗
. This proves (a). The
proof of (b) is similar.
If r < s then r ∈ s
∗
, but r ∈/ r
∗
; hence r
∗ < s∗
.
If r
∗ < s∗
, then there is a p ∈ s
∗
such that p ∈/ r
∗
. Hence r ≤ p < s, so that
r < s. This proves (c).
Step 9 We saw in Step 8 that the replacement of the rational numbers r by the
corresponding ”rational cuts” r
∗ ∈ R preserves sums, products, and order. This
fact may be expressed by saying that the ordered field Q is isomorphic to the ordered
field Q∗ whose elements are the rational cuts. Of course, r
∗
is by no means the
same as r, but the properties we are concerned with (arithmetic and order) are the
same in the two fields.
It is this identification of Q with Q∗ which allows us to regard Q as a subfield of R.
The second part of Theorem 1.19 is to be understood in terms of this identifica￾tion. Note that the same phenomenon occurs when the real numbers are regarded
as a subfield of the complex field, and it also occurs at a much more elementary
level, when the integers are identified with a certain subset of Q.
It is a fact, which we will not prove here, that any two ordered fields with the
least-upper-bound property are isomorphic. The first part of Theorem 1.19 therefore
characterizes the real field R completely.
The books by Landau [Lan51] and Thurston [Thu56] cited in the Bibliography
are entirely devoted to number systems. Chapter 1 of Knopp’s book [Kno28] con￾tains a more leisurely description of how R can be obtained from Q. Another
construction, in which each real number is defined to be an equivalence class ofEXERCISES 20
Cauchy sequences of rational numbers (see Chap. 3), is carried out in Sec. 5 of the
book by Hewitt and Stromberg [HS65].
The cuts in Q which we used here were invented by Dedekind. The construc￾tion of R from Q by means of Cauchy sequences is due to Cantor. Both Cantor and
Dedekind published their constructions in 1872.
EXERCISES
Unless the contrary is explicitly stated, all numbers that are mentioned in these exercises are
understood to be real.
1.1. If r is rational (r ̸= 0) and x is irrational, prove that r + x and rx are irrational.
1.2. Prove that there is no rational number whose square is 12.
1.3. Prove Proposition 1.15.
1.4. Let E be a nonempty subset of an ordered set; suppose α is a lower bound of E and β is
an upper bound of E. Prove that α ≤ β.
1.5. Let A be a nonempty set of real numbers which is bounded below. Let −A be the set of
all numbers −x, where x ∈ A. Prove that
inf A = − sup(−A).
1.6. Fix b > 1.
(a) If m, n, p, q are integers, n > 0, q > 0, and r = m/n = p/q, prove that
(b
m)
1/n = (b
p
)
1/q.
Hence it makes sense to define b
r = (bm)
1/n.
(b) Prove that b
r+s = b
rb
s
if r and s are rational.
(c) If x is real, define B(x) to be the set of all numbers b
t
, where t is rational and t ≤ x.
Prove that
b
r = sup B(r)
when r is rational. Hence it makes sense to define
b
x = sup B(x)
for every real x.
(d) Prove that b
x+y = b
xb
y for all real x and y.
1.7. Fix b > 1, y > 0, and prove that there is a unique real x such that b
x = y, by completing
the following outline. (This x is called the logarithm of y to the base b.)
(a) For any positive integer n, b
n − 1 ≥ n(b − 1).
(b) Hence b − 1 ≥ n(b
1/n − 1).
(c) If t > 1 and n > (b − 1)/(t − 1), then b
1/n < t.
(d) If w is such that bw < y, then bw+(1/n) < y for sufficiently large n; to see this, apply
part (c) with t = y · b
−w.
(e) If bw > y, then bw−(1/n) > y for sufficiently large n.
(f) Let A be the set of all w such that bw < y, and show that x = sup A satisfies b
x = y.EXERCISES 21
(g) Prove that this x is unique.
1.8. Prove that no order can be defined in the complex field that turns it into an ordered field.
Hint: −1 is a square.
1.9. Suppose z = a + bi, w + c + di. Define z < w if a < c, and also if a = c but b < d. Prove
that this turns the set of complex numbers into an ordered set. (This type of order relation
is called a dictionary order, or lexicographic order, for obvious reasons.) Does this ordered set
have the least-upper-bound property?
1.10. Suppose z = a + bi, w = u + iv, and
a =

|w| + u
2
1/2
, b =

|w| − u
2
1/2
.
Prove that z
2 = w if v ≥ 0 and that (z)
2 = w if v ≤ 0. Conclude that every complex number
(with one exception!) has two complex square roots.
1.11. If z is a complex number, prove that there exists an r ≥ 0 and a complex number w with
|w| = 1 such that z = rw. Are w and r always uniquely determined by z?
1.12. If z1, . . . , zn are complex, prove that
|z1 + z2 + · · · + zn | ≤ |z1 | + |z2 | + · · · + |zn | .
1.13. If x, y are complex, prove that
||x| − |y|| ≤ |x − y| .
1.14. If z is a complex number such that |z| = 1, that is, such that zz = 1, compute
|1 + z|
2 + |1 − z|
2
.
1.15. Under what conditions does equality hold in the Schwarz inequality?
1.16. Suppose k ≥ 3, x, y ∈ Rk, |x − y| = d > 0, and r > 0. Prove:
(a) If 2r > d, there are infinitely many z ∈ Rk such that
|z − x| = |z − y| = r.
(b) If 2r = d, there is exactly one such z.
(c) If 2r < d, there is no such z.
How must these statements be modified if k is 2 or 1?
1.17. Prove that
|x + y|
2 + |x − y|
2 = 2 |x|
2 + 2 |y|
2
if x ∈ Rk and y ∈ Rk. Interpret this geometrically, as a statement about parallelograms.
1.18. If k ≥ 2 and x ∈ Rk, prove that there exists y ∈ Rk such that y ̸= 0 but x · y = 0. Is this
also true if k = 1?
1.19. Suppose a ∈ Rk, b ∈ Rk. Find c ∈ Rk and r > 0 such that
|x − a| = 2 |x − b|
if and only if |x − c| = r.
(Solution: 3c = 4b − a, 3r = 2 |b − a|.)
1.20. With reference to the Appendix, suppose that property (III) were omitted from the def￾inition of a cut. Keep the same definitions of order and addition. Show that the resulting
ordered set has the least-upper-bound property, that addition satisfies axioms (A1) to (A4)
(with a slightly different zero-element!) but that (A5) fails.Chapter 2
BASIC TOPOLOGY
FINITE, COUNTABLE, AND UNCOUNTABLE SETS
We begin this section with a definition of the function concept.
2.1 Definition. Consider two sets A and B, whose elements may be any objects
whatsoever, and suppose that with each element x of A there is associated, in some
manner, an element of B, which we denote by f(x). Then f is said to be a function
from A to B (or a mapping of A into B). The set A is called the domain of f (we also
say f is defined on A) and the elements f(x) are called the values of f. The set of all
values of f is called the range of f.
2.2 Definition. Let A and B be two sets and let f be a mapping of A into B. If
E ⊂ A, f(E) is defined to be the set of all elements f(x), for x ∈ E. We call f(E) the
image of E under f. In this notation, f(A) is the range of f. It is clear that f(A) ⊂ B.
If f(A) = B, we say that f maps A onto B. (Note that, according to this usage, onto
is more specific than into).
If E ⊂ B, f
−1(E) denotes the set of all x ∈ A such that f(x) ∈ E. We call
f
−1(E) the inverse image of E under f. If y ∈ B, f
−1(y) is the set of all x ∈ A
such that f(x) = y. If, for each y ∈ B, f
−1(y) consists of at most one element of
A, then f is said to be a 1-1 (one-to-one) mapping of A into B. This may also be
expressed as follows: f is a 1-1 mapping of A into B provided that f(x1) ̸= f(x2)
whenever x1 ̸= x2, x1 ∈ A, x2 ∈ A.
(The notation x1 ̸= x2 means that x1 and x2 are distinct elements; otherwise
we write x1 = x2.)
2.3 Definition. If there exists a 1-1 mapping of A onto B, we say that A and B can
be put in 1-1 correspondence, or that A and B have the same cardinal number, or,
briefly, that A and B are equivalent, and we write A ∼ B. This relation clearly has
the following properties:
It is reflexive: A ∼ A.
22FINITE, COUNTABLE, AND UNCOUNTABLE SETS 23
It is symmetric: If A ∼ B, then B ∼ A.
It is transitive: If A ∼ B and B ∼ C, then A ∼ C.
Any relation with these three properties is called an equivalence relation.
2.4 Definition. For any positive integer n, let Nn be the set whose elements are
the integers 1, 2, . . . , n; let N be the set consisting of all positive integers. For any
set A, we say:
(a) A is finite if A ∼ Nn for some n (the empty set is also considered to be finite).
(b) A is infinite if A is not finite.
(c) A is countable if A ∼ N.
(d) A is uncountable if A is neither finite nor countable.
(e) A is at most countable if A is finite or countable.
Countable sets are sometimes called enumerable, or denumerable.
For two finite sets A and B, we evidently have A ∼ B if and only if A and
B contain the same number of elements. For infinite sets, however, the idea of
“having the same number of elements” becomes quite vague, whereas the notion
of 1-1 correspondence retains its clarity.
2.5 Example. Let Z be the set of all integers. Then Z is countable. For, consider
the following arrangement of the sets Z and N:
Z : 0, 1, −1, 2, −2, 3, −3, . . .
N : 1, 2, 3, 4, 5, 6, 7, . . .
We can, in this example, even give an explicit formula for a function f from N
to Z which sets up a 1-1 correspondence:
f(n) =



n
2
(n even),
−
n − 1
2
(n odd).
2.6 Remark. A finite set cannot be equivalent to one of its proper subsets. That
this is, however, possible for infinite sets, is shown by Example 2.5, in which N is
a proper subset of Z.
In fact, we could replace def:2.4(b) by the statement: A is infinite if A is equiv￾alent to one of its proper subsets.
2.7 Definition. By a sequence, we mean a function f defined on the set N of all
positive integers. If f(n) = xn, for n ∈ N, it is customary to denote the sequence
f by the symbol (xn)∞
n=1
, or more briefly by (xn), or sometimes by x1, x2, x3, . . . .
The values of f, that is, the elements xn, are called the terms of the sequence. If A
is a set and if xn ∈ A for all n ∈ N, then (xn) is said to be a sequence in A, or a
sequence of elements of A.FINITE, COUNTABLE, AND UNCOUNTABLE SETS 24
Note that the terms x1, x2, x3, . . . of a sequence need not be distinct.
Since every countable set is the range of a 1-1 function defined on N, we may
regard every countable set as the range of a sequence of distinct terms. Speaking
more loosely, we may say that the elements of any countable set can be “arranged
in a sequence.”
Sometimes it is convenient to replace N in this definition by the set of all non￾negative integers, i.e., to start with 0 rather than 1.
2.8 Theorem. Every infinite subset of a countable set A is countable.
Proof. Suppose E ⊂ A, and E is infinite. Arrange the elements x of A in a sequence
(xn) of distinct elements. Construct a sequence (nk) as follows:
Let n1 be the smallest positive integer such that xn1 ∈ E. Having chosen
n1, . . . , nk−1 (k = 2, 3, 4, . . .), let nk be the smallest integer greater than nk−1
such that xnk ∈ E.
Putting f(k) = xnk
(k = 1, 2, 3, . . .), we obtain a 1-1 correspondence between E
and N.
The theorem shows that, roughly speaking, countable sets represent the “small￾est” infinite: No uncountable set can be a subset of a countable set.
2.9 Definition. Let A and Ω be sets, and suppose that with each element α of A
there is associated a subset of Ω which we denote by Eα.
The set whose elements are the sets Eα will be denoted by {Eα}. Instead of
speaking of sets of sets, we shall sometimes speak of a collection of sets, or a family
of sets.
The union of the sets Eα is defined to be the set S such that x ∈ S if and only if
x ∈ Eα for at least one α ∈ A. We use the notation
(2.1) S =
[
α∈A
Eα.
If A consists of the integers 1, 2, . . . , n, one usually writes
(2.2) S =
[n
m=1
Em
or
(2.3) S = E1 ∪ E2 ∪ · · · ∪ En.
If A is the set of all positive integers, the usual notation is
(2.4) S =
[∞
m=1
Em.
The symbol ∞ in (2.4) merely indicates that the union of a countable collection
of sets is taken, and should not be confused with the symbols +∞, −∞, introducedFINITE, COUNTABLE, AND UNCOUNTABLE SETS 25
in Definition 1.23.
The intersection of the sets Eα is defined to be the set P such that x ∈ P if and
only if x ∈ Eα for every α ∈ A. We use the notation
(2.5) P =
\
α∈A
Eα,
or
(2.6) P =
\n
m=1
Em = E1 ∩ E2 ∩ · · · ∩ En,
or
(2.7) P =
\∞
m=1
Em,
as for unions. If A ∩ B is not empty, we say that A and B intersect; otherwise they
are disjoint.
2.10 Examples.
(a) Suppose E1 consists of 1, 2, 3 and E2 consists of 2, 3, 4. Then E1 ∪ E2 consists
of 1, 2, 3, 4, whereas E1 ∩ E2 consists of 2, 3.
(b) Let A be the set of real numbers x such that 0 < x ≤ 1. For every x ∈ A, let
Ex be the set of real numbers y such that 0 < y < x. Then
(i) Ex ⊂ Ez if and only if 0 < x ≤ z ≤ 1;
(ii) S
x∈A Ex = E1;
(iii) T
x∈A Ex is empty.
(i) and (ii) are clear. To prove (iii), we note that for every y > 0, y ∈/ Ex if x < y.
Hence y ∈/
T
x∈A Ex.
2.11 Remarks. Many properties of unions and intersections are quite similar to
those of sums and products; in fact, the words sum and product were sometimes
used in this connection, and the symbols Σ and Π were written in place of S
and
T
.
The commutative and associative laws are trivial:
A ∪ B = B ∪ A; A ∩ B = B ∩ A.(2.8)
(A ∪ B) ∪ C = A ∪ (B ∪ C); (A ∩ B) ∩ C = A ∩ (B ∩ C).(2.9)
Thus the omission of parenthesis in (2.3) and (2.6) is justified.
The distributive law also holds:
(2.10) A ∩ (B ∪ C) = (A ∩ B) ∪ (A ∩ C).FINITE, COUNTABLE, AND UNCOUNTABLE SETS 26
To prove this, let the left and right members of (2.10) be denoted by E and F, re￾spectively.
Suppose x ∈ E. Then x ∈ A and x ∈ B ∪ C, that is, x ∈ B or x ∈ C (possibly
both). Hence x ∈ A ∩ B or x ∈ A ∩ C, so that x ∈ F. Thus E ⊂ F.
Next, suppose x ∈ F. Then x ∈ A ∩ B or x ∈ A ∩ C. That is, x ∈ A, and
x ∈ B ∪ C. Hence x ∈ A ∩ (B ∪ C), so that F ⊂ E.
It follows that E = F.
We list a few more relations which are easily verified:
A ⊂ A ∪ B,(2.11)
A ∩ B ⊂ A.(2.12)
If ∅ denotes the empty set, then
(2.13) A ∪ ∅ = A, A ∩ ∅ = ∅.
If A ⊂ B, then
(2.14) A ∪ B = B, A ∩ B = A.
2.12 Theorem. Let {En}, n = 1, 2, 3, . . . , be a countable collection of countable sets, and
put
(2.15) S =
[∞
n=1
En.
Then S is countable.
Proof. Let every set En be arranged in a sequence (xnk), k = 1, 2, 3, . . . , and con￾sider the infinite array
(2.16)
x11 x12 x13 x14 · · ·
x21 x22 x23 x24 · · ·
x31 x32 x33 x34 · · ·
x41 x42 x43 x44 · · ·
· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·
in which the elements of En form the nth row. The array contains all elements of
S. As indicated by the arrows, these elements can be arranged in a sequence
(2.17) x11; x21, x12; x31, x22.x13; x41, x32, x23, x14; . . .
If any two of the sets En have elements in common, these will appear more than
once in (2.17). Hence there is a subset T of the set of all positive integers such that
S ∼ T, which shows that S is at most countable (Theorem 2.8). Since E1 ⊂ S, and
E1 is infinite, S is infinite, and thus countable.FINITE, COUNTABLE, AND UNCOUNTABLE SETS 27
Corollary. Suppose A is at most countable, and, for every α ∈ A, Bα is at most countable.
Put
T =
[
α∈A
Bα.
Then T is at most countable, for T is equivalent to a subset of (2.15).
2.13 Theorem. Let A be a countable set, and let Bn be the set of all n-tuples (a1, . . . , an),
where ak ∈ A (k = 1, . . . , n), and the elements a1, . . . , an need not be distinct. Then
Bn is countable.
Proof. That B1 is countable is evident, since B1 = A. Suppose Bn−1 is countable
(n = 2, 3, 4, . . .). The elements of Bn are of the form
(2.18) (b, a) (b ∈ Bn−1, a ∈ A).
For every fixed b, the set of pairs (b, a) is equivalent to A, and hence countable.
Thus Bn is the union of a countable set of countable sets. By Theorem 2.12, Bn is
countable.
The theorem follows by induction.
Corollary. The set of all rational numbers is countable.
Proof. We apply Theorem 2.13, with n = 2, noting that every rational r is of the
form b/a, where a and b are integers. The set of pairs (a, b), and therefore the set
of fractions b/a, is countable.
In fact, even the set of all algebraic numbers is countable (see Exercise 2.2). That
not all infinite sets are, however, countable, is shown by the next theorem.
2.14 Theorem. Let A be the set of all sequences whose elements are the digits 0 and 1.
This set A is uncountable.
The elements of A are sequences like 1, 0, 0, 1, 0, 1, 1, 1, . . . .
Proof. Let E be a countable subset of A, and let E consist of the sequences
s1, s2, s3, . . . . We construct a sequence s as follows. If the nth digit in sn is 1,
we let the nth digit of s be 0, and vice versa. Then the sequence s differs from
every member of E in at least one place; hence s ∈/ E. But clearly s ∈ A, so that E is
a proper subset of A.
We have shown that every countable subset of A is a proper subset of A. It
follows that A is uncountable (for otherwise A would be a proper subset of A,
which is absurd).
The idea of the above proof was first used by Cantor, and is called Cantor’s di￾agonal process; for, if the sequences s1, s2, s3, . . . are placed in an array like (2.16),
it is the elements on the diagonal which are involved in the construction of the new
sequence.METRIC SPACES 28
Readers who are familiar with the binary representation of the real numbers
(base 2 instead of 10) will notice that Theorem 2.14 implies that the set of all real
numbers is uncountable. We shall give a second proof of this fact in Theorem 2.43.
METRIC SPACES
2.15 Definition. A set X, whose elements we shall call points, is said to be a metric
space if with any two points p and q of X there is associated a real number d(p, q),
called the distance from p to q, such that
(a) d(p, q) > 0 if p ̸= q; d(p, p) = 0;
(b) d(p, q) = d(q, p);
(c) d(p, q) ≤ d(p, r) + d(r, q) for any r ∈ X.
Any function with these three properties is called a distance function, or a metric.
2.16 Examples. The most important examples of metric spaces, from our stand￾point, are the euclidean spaces Rk, especially R1 (the real line) and R2 (the com￾plex plane); the distance in Rk is defined by
(2.19) d(x, y) = |x − y| (x, y ∈ Rk
).
By Theorem 1.37, the conditions of Definition 2.15 are satisfied by (2.19).
It is important to observe that every subset Y of a metric space X is a metric
space in its own right, with the same distance function. For it is clear that if con￾ditions (a) to (c) of Definition 2.15 hold for p, q, r, ∈ X, they also hold if we restrict
p, q, r to lie in Y.
Thus, every subset of a euclidean space is a metric space. Other examples are
the spaces C (K) and L 2(µ), which are discussed in Chaps. 7 and 11, respectively.
2.17 Definition. By the segment (a, b) we mean the set of all real numbers x such
that a < x < b.
By the interval [a, b] we mean the set of all real numbers x such that a ≤ x ≤ b.
Occasionally we shall also encounter “half-open intervals” [a, b) and (a, b]; the
first consists of all x such that a ≤ x < b, the second of all x such that a < x ≤ b.
If ai < bi
for i = 1, . . . , k, the set of all points x = (x1, . . . , xk) in Rk whose
coordinates satisfy the inequalities ai ≤ xi ≤ bi
(1 ≤ i ≤ k) is called a k-cell. Thus
a 1-cell is an interval, a 2-cell is a rectangle, etc.
If x ∈ Rk and r > 0, the open (or closed) ball B with center at x and radius r is
defined to be the set of all y ∈ Rk such that |y − x| < r (or |y − x| ≤ r).
We call a set E ⊂ Rk convex if
λx + (1 − λ)y ∈ E
whenever x ∈ E, y ∈ E, and 0 < λ < 1.METRIC SPACES 29
For example, balls are convex. For if |y − x| < r, |z − x| < r, and 0 < λ < 1, we
have
|λy + (1 − λ)z − x| = |λ(y − x) + (1 − λ)(z − x)|
≤ λ |y − x| + (1 − λ)|z − x| < λr + (1 − λ)r
= r.
The same proof applies to closed balls. It is also easy to see that k-cells are convex.
2.18 Definition. Let X be a metric space. All points and sets mentioned below are
understood to be elements and subsets of X.
(a) A neighborhood of p is a set Nr(p) consisting of all q such that d(p, q) < r for
some r > 0. The number r is called the radius of Nr(p).
(b) A point p is a limit point of the set E if every neighborhood of p contains a
point q ̸= p such that q ∈ E.
(c) If p ∈ E and p is not a limit point of E, then p is called an isolated point of E.
(d) E is closed if every limit point of E is a point of E.
(e) A point p is an interior point of E if there is a neighborhood N of p such that
N ⊂ E.
(f) E is open if every point of E is an interior point of E.
(g) The complement of E (denoted by E
c
) is the set of all points p ∈ X such that
p ∈/ E.
(h) E is perfect if E is closed and if every point of E is a limit point of E.
(i) E is bounded if there is a real number M and a point q ∈ X such that d(p, q) <
M for all p ∈ E.
(j) E is dense in X if every point of X is a limit point of E, or a point of E (or both).
Let us note that in R1 neighborhoods are segments, whereas in R2 neighbor￾hoods are interiors of circles.
2.19 Theorem. Every neighborhood is an open set.
Proof. Consider a neighborhood E = Nr(p), and let q be any point of E. Then there
is a positive real number h such that
d(p, q) = r − h.
For all points s such that d(q, s) < h, we have then
d(p, s) ≤ d(p, q) + d(q, s) < r − h + h = r,
so that s ∈ E. Thus q is an interior point of E.
2.20 Theorem. If p is a limit point of a set E, then every neighborhood of p contains
infinitely many points of E.METRIC SPACES 30
Proof. Suppose there is a neighborhood N of p which contains only a finite number
of points of E. Let q1, . . . , qn be those points of N ∩ E which are distinct from p,
and put
r = min
1≤m≤n
d(p, qm).
[We use this notation to denote the smallest of the numbers d(p, q1), . . . , d(p, qn).]
The minimum of a finite set of positive numbers is clearly positive, so that r > 0.
The neighborhood Nr(p) contains no point q of E such that q ̸= p, so that p is
not a limit point of E. This contradiction establishes the theorem.
Corollary. A finite point set has no limit points.
2.21 Examples. Let us consider the following subset of R2:
(a) The set of all complex z such that |z| < 1.
(b) The set of all complex z such that |z| ≤ 1.
(c) A nonempty finite set.
(d) The set of all integers.
(e) The set consisting of the numbers 1/n (n = 1, 2, 3, . . .). Let us note that
this set E has a limit point (namely, z = 0) but that no point of E is a limit
point of E; we wish to stress the difference between having a limit point and
containing one.
(f) The set of all complex numbers (that is, R2).
(g) The segment (a, b).
Let us note that (d), (e), (g) can be regarded also as subsets of R1.
Some properties of these sets are tabulated below:
Closed Open Perfect Bounded
(a) No Yes No Yes
(b) Yes No Yes Yes
(c) Yes No No Yes
(d) Yes No No No
(e) No No No Yes
(f) Yes Yes Yes No
(g) No No Yes
In (g), we left the second entry blank. The reason is that the segment (a, b) is not
open if we regard it as a subset of R2, but it is an open subset of R1.
2.22 Theorem. Let {Eα} be a (finite or infinite) collection of sets Eα. Then
(2.20) 
[
α
Eα
!c
=
\
α
(E
c
α).METRIC SPACES 31
Proof. Let A and B be the left and right members of (2.20). If x ∈ A, then x ∈/
S
α Eα, hence x ∈/ Eα for any α, hence x ∈ E
c
α for every α, so that x ∈
T
E
c
α. Thus
A ⊂ B.
Conversely, if x ∈ B, then x ∈ E
c
α for every α, hence x ∈/ Eα for any α, hence
x ∈/
S
α Eα, so that x ∈ (
S
α Eα)
c
. Thus B ⊂ A.
It follows that A = B.
2.23 Theorem. A set E is open if and only if its complement is closed.
Proof. First, suppose E
c
is closed. Choose x ∈ E. Then x ∈/ E
c
, and x is not a limit
point of E
c
. Hence there exists a neighborhood N of x such that E
c ∩ N is empty,
that is, N ⊂ E. Thus x is an interior point of E, and E is open.
Next, suppose E is open. Let x be a limit point of E
c
. Then every neighborhood
of x contains a point of E
c
, so that x is not an interior point of E. Since E is open,
this means that x ∈ E
c
. It follows that E
c
is closed.
Corollary. A set F is closed if and only if its complement is open.
2.24 Theorem.
(a) For any collection {Gα} of open sets, S
α Gα is open.
(b) For any collection {Fα} of closed sets, T
α Fα is closed.
(c) For any finite collection G1, . . . , Gn of open sets, Tn
i=1 Gi
is open.
(d) For any finite collection F1, . . . , Fn of closed sets, Sn
i=1
Fi
is closed.
Proof. Put G =
S
α Gα. If x ∈ G then x ∈ Gα for some α. Since x is an interior
point of Gα, x is also an interior point of G, and G is open. This proves (a).
By Theorem 2.22,
(2.21) 
\
α
Fα
!c
=
[
α
(F
c
α),
and F
c
α is open, by Theorem 2.23. Hence (a) implies that (2.21) is open so that
T
α Fα is closed.
Next, put H =
Tn
i=1 Gi
. For any x ∈ H, there exist neighborhoods Ni of x, with
radii ri
, such that Ni ⊂ Gi
(i = 1, . . . , n). Put
r = min{r1, . . . , rn}
and let N be the neighborhood of x of radius r. Then N ⊂ Gi
for i = 1, . . . , n, so
that N ⊂ H, and H is open.
By taking complements, (d) follows from (c):
 
[n
i=1
Fi
!c
=
\n
i=1
(F
c
i
).METRIC SPACES 32
2.25 Example. In parts (c) and (d) of the preceding theorem, the finiteness of the
collections is essential. For let Gn be the segment (−1/n, 1/n) (n = 1, 2, 3, . . . ).
Then Gn is an open subset of R1. Put G =
T∞
n=1 Gn. Then G consists of a single
point (namely, x = 0) and is therefore not an open subset of R1.
Thus the intersection of an infinite collection of open sets need not be open.
Similarly, the union of an infinite collection of closed sets need not be closed.
2.26 Definition. If X is a metric space, if E ⊂ X, and if E
′ denotes the set of all limit
points of E in X, then the closure of E is the set E = E ∪ E
′
.
2.27 Theorem. If X is a metric space and E ⊂ X, then
(a) E is closed,
(b) E = E if and only if E is closed,
(c) E ⊂ F for every closed set F ⊂ X such that E ⊂ F.
By (a) and (c), E is the smallest closed subset of X that contains E.
Proof.
(a) If p ∈ X and p ∈/ E then P is neither a point of E nor a limit point of E. Hence
p has a neighborhood which does not intersect E. The complement of E is
therefore open. Hence E is closed.
(b) If E = E, (a) implies that E is closed. If E is closed, then E
′ ⊂ E [by Definitions
2.18(d) and 2.26], hence E = E.
(c) If F is closed and F ⊃ E, then F ⊃ F
′
, hence F ⊃ E
′
. Thus F ⊃ E.
2.28 Theorem. Let E be a nonempty set of real numbers which is bounded above. Let
y = sup E. Then y ∈ E. Hence y ∈ E if E is closed.
Compare this with the examples in Sec. 1.9.
Proof. If y ∈ E then y ∈ E. Assume y ∈/ E. For every h > 0 there exists then a point
x ∈ E such that y − h < x < y, for otherwise y − h would be an upper bound of E.
Thus y is a limit point of E. Hence y ∈ E.
2.29 Remark. Suppose E ⊂ Y ⊂ X, where X is a metric space. To say that E is
an open subset of X means that to each point p ∈ E there is associated a positive
number r such that the conditions d(p, q) < r, q ∈ X imply that q ∈ E. But we
have already observed (Example 2.16) that Y is also a metric space, so that our
definitions may equally well be made within Y. To be quite explicit, let us say that
E is open relative to Y if to each p ∈ E there is associated an r > 0 such that q ∈ E
whenever d(p, q) < r and q ∈ Y. Example 2.21(g) showed that a set may be open
relative to Y without being an open subset of X. However, there is a simple relation
between these concepts, which we now state.
2.30 Theorem. Suppose Y ⊂ X. A subset E of Y is open relative to Y if and only if
E = Y ∩ G for some open subset G of X.COMPACT SETS 33
Proof. Suppose E is open relative to Y. To each p ∈ E there is a positive number rp
such that the conditions d(p, q) < rp, q ∈ Y imply that q ∈ E. Let Vp be the set of
all q ∈ X such that d(p, q) < rp and define
G =
[
p∈E
Vp.
Then G is an open subset of X, by Theorems 2.19 and 2.24.
Since p ∈ Vp for all p ∈ E, it is clear that E ⊂ G ∩ Y.
By our choice of Vp, we have Vp ∩ Y ⊂ E for every p ∈ E, so that G ∩ Y ⊂ E.
Thus E = G ∩ Y, and one half of the theorem is proved.
Conversely, if G is open in X and E = G ∩ Y, every p ∈ E has a neighborhood
Vp ⊂ G. Then Vp ∩ Y ⊂ E, so that E is open relative to Y.
COMPACT SETS
2.31 Definition. By an open cover of a set E in a metric space X we mean a collection
{Gα} of open subset of X such that E ⊂
S
α Gα.
2.32 Definition. A subset K of a metric space X is said to be compact if every open
cover of K contains a finite subcover.
More explicitly, this requirement is that if {Gα} is an open cover of K, then there
are finitely many indices α1, . . . , αn such that
K ⊂ Gα1 ∪ · · · ∪ Gαn .
The notion of compactness is of great importance in analysis, especially in con￾nection with continuity (Chap. 4).
It is clear that every finite set is compact. The existence of a large class of infinite
compact sets in Rk will follow from Theorem 2.41.
We observed earlier (in Remark 2.29) that if E ⊂ Y ⊂ X, then E may be open
relative to Y without being open relative to X. The property of being open thus
depends on the space in which E is embedded. The same is true of the property of
being closed.
Compactness, however, behaves better, as we shall now see. To formulate the
next theorem, let us say, temporarily, that K is compact relative to X if the require￾ments of Definition 2.32 are met.
2.33 Theorem. Suppose K ⊂ Y ⊂ X. Then K is compact relative to X if and only if K is
compact relative to Y.
By virtue of this theorem we are able, in many situations, to regard compact
sets as metric spaces in their own right, without paying any attention to any em￾bedding space. In particular, although it makes little sense to talk of open spaces,
or of closed spaces (every metric space X is an open subset of itself, and is a closed
subset of itself), it does make sense to talk of compact metric spaces.COMPACT SETS 34
Proof. Suppose K is compact relative to X, and let {Vα} be a collection of sets, open
relative to Y, such that K ⊂
S
α Vα. By Theorem 2.30, there are sets Gα, open
relative to X, such that Vα = Y ∩ Gα, for all α; and since K is compact relative to X,
we have
(2.22) K ⊂ Gα1 ∪ · · · ∪ Gαn
for some choice of finitely many indices α1, . . . , αn. Since K ⊂ Y, (2.22) implies
(2.23) K ⊂ Vα1 ∪ · · · ∪ Vαn .
This proves that K is compact relative to Y.
Conversely, suppose K is compact relative to Y, let {Gα} be a collection of open
subset of X which covers K and put Vα = Y ∩ Gα. Then (2.23) will hold for some
choice of α1, . . . , αn; since Vα ⊂ Gα, (2.23) implies (2.22).
This completes the proof.
2.34 Theorem. Compact subsets of metric spaces are closed.
Proof. Let K be a compact subset of a metric space X. We shall prove that the
complement of K is an open subset of X.
Suppose p ∈ X, p ∈/ K. If q ∈ K, let Vq and Wq be neighborhoods of p and q,
respectively, of radius less than 1
2
d(p, q) [see Definition 2.18(a). Since K is compact,
there are finitely many points q1, . . . , qn in K such that
K ⊂ Wq1 ∪ · · · ∪ Wqn = W.
If V = Vq1 ∩ · · · ∩ Vqn , then V is a neighborhood of p which does not intersect W.
Hence V ∈ K
c
, so that p is an interior point of K
c
. The theorem follows.
2.35 Theorem. Closed subsets of compact sets are compact.
Proof. Suppose F ⊂ K ⊂ X, F is closed (relative to X), and K is compact. Let {Vα} be
an open cover of F. If F
c
is adjoined to {Vα}, we obtain an open cover Ω of K. Since
K is compact, there is a finite subcollection Φ of Ω which covers K, and hence F. If
F
c
is a member of Φ, we may remove it from Φ and still retain an open cover of F.
We have thus shown that a finite subcollection of {Vα} covers F.
Corollary. If F is closed and K is compact, then F ∩ K is compact.
Proof. Theorems 2.24(b) and 2.34 show that F ∩ K is closed; since F ∩ K ⊂ K, Theo￾rem 2.35 shows that F ∩ K is compact.
2.36 Theorem. If {Kα} is a collection of compact subsets of a metric space X such that the
intersection of every finite subcollection of {Kα} is nonempty, then T
Kα is nonempty.COMPACT SETS 35
Proof. Fix a member K1 of {Kα} and put Gα = K
c
α. Assume that no point of K1
belongs to every Kα. Then the sets Gα form an open cover of K1; since K1 is
compact, there are finitely many indices α1, . . . , αn such that K1 ⊂ Gα1 ∪ · · · ∪
Gαn . But this means that
K1 ∩ Kα1 ∩ · · · ∩ Kαn
is empty, in contradiction to our hypothesis.
Corollary. If {Kn} is a countable collection of nonempty compact sets such that Kn ⊃
Kn+1 (n = 1, 2, 3, . . . ), then T∞
n=1 Kn is not empty.
2.37 Theorem. If E is an infinite subset of a compact set K, then E has a limit point in K.
Proof. If no point of K were a limit point of E, then each q ∈ K would have a
neighborhood Vq which contains at most one point of E (namely, q, if q ∈ E). It
is clear that no finite subcollection of {Vq} can cover E; and the same is true of K,
since E ⊂ K. This contradicts the compactness of K.
2.38 Theorem. If {In} is a sequence of intervals in R1, such that In ⊃ In+1
(n = 1, 2, 3, . . . ), then T∞
n=1
In is not empty.
Proof. If In = [an, bn], let E be the set of all an. Then E is nonempty and bounded
above (by b1). Let x be the sup of E. If m and n are positive integers, then
an ≤ am+n ≤ bm+n ≤ bm,
so that x ≤ bm for each m. Since it is obvious that am ≤ x, we see that x ∈ Im for
m = 1, 2, 3, . . . .
2.39 Theorem. Let k be a positive integer. If {In} is a sequence of k-cells such that
In ⊃ In+1 (n = 1, 2, 3, . . . ), then T∞
n=1
In is not empty.
Proof. Let In consist of all points x = (x1, . . . , xk) such that
an,j ≤ xj ≤ bn,j
(1 ≤ j ≤ k; n = 1, 2, 3, . . . ),
and put In,j = [an,j
, bn,j
]. For each j, the collection {In,j
} satisfies the hypotheses
of Theorem 2.38. Hence there are real numbers x
∗
j
(1 ≤ j ≤ k) such that
an,j ≤ x
∗
j ≤ bn,j
(1 ≤ j ≤ k; n = 1, 2, 3, . . . ).
Setting x
∗ = (x
∗
1
, . . . , x
∗
k
), we see that x
∗ ∈ In for n = 1, 2, 3, . . . . The theorem
follows.
2.40 Theorem. Every k-cell is compact.COMPACT SETS 36
Proof. Let I be a k-cell, consisting of all points x = (x1, . . . , xk) such that
aj ≤ xj ≤ bj
(1 ≤ j ≤ k). Put
δ =
X
k
1
(bj − aj
)
2
1/2
.
Then |x − y| ≤ δ, if x ∈ I, y ∈ I.
Suppose, to get a contradiction, that there exists an open cover {Gα} of I which
contains no finite subcover of I. Put cj = (aj + bj
)/2. The intervals [aj
, cj
] and
[cj
, bj
] then determine 2
k k-cells Qi whose union is I. At least one of these sets
Qi
, call it I1, cannot be covered by any finite subcollection of {Gα} (otherwise I
could be so covered). We next subdivide I1 and continue the process. We obtain a
sequence (In) with the following properties:
(a) I ⊃ I1 ⊃ I2 ⊃ I3 ⊃ · · · ;
(b) In is not covered by any finite subcollection of {Gα};
(c) If x ∈ In and y ∈ In, then |x − y| ≤ 2
−nδ.
By (a) and Theorem 2.39, there is a point x
∗ which lies in every In. For some
α, x
∗ ∈ Gα. Since Gα is open, there exists r > 0 such that |y − x
∗
| < r implies that
y ∈ Gα. If n is so large that 2
−nδ < r (there is such an n, for otherwise 2
n ≤ δ/r
for all positive integers n, which is absurd since R is archimedean), then (c) implies
that In ⊂ Gα, which contradicts (b).
This completes the proof.
The equivalence of (a) and (b) in the next theorem is known as the Heine-Borel
theorem.
2.41 Theorem. If a set E in Rk has one of the following three properties, then it has the
other two:
(a) E is closed and bounded.
(b) E is compact.
(c) Every infinite subset of E has a limit point in E.
Proof. If (a) holds, then E ⊂ I for some k-cell I, and (b) follows from Theorems 2.40
and 2.35. Theorem 2.37 shows that (b) implies (c). It remains to be shown that (c)
implies (a).
If E is not bounded, then E contains points xn with
|xn | > n (n = 1, 2, 3, . . . ).
The set S consisting of these points xn is infinite and clearly has no limit point in
Rk, hence has none in E. Thus (c) implies that E is bounded.
If E is not closed, then there is a point x0 ∈ Rk which is a limit point of E but not
a point of E. For n = 1, 2, 3, . . . , there are points xn ∈ E such that |xn − x0| < 1/n.PERFECT SETS 37
Let S be the set of these points xn. Then S is infinite (otherwise |xn − x0| would
have a constant positive value, for infinitely many n), S has x0 as a limit point, and
S has no other limit point in Rk. For if y ̸= x0, then
|xn − y| ≥ |x0 − y| − |xn − x0|
≥ |x0 − y| −
1
n
≥
1
2
|x0 − y|
for all but finitely many n; this shows that y is not a limit point of S (Theorem 2.20).
Thus S has no limit point in E; hence E must be closed if (c) holds.
We should remark, at this point, that (b) and (c) are equivalent in any metric
space (Exercise 2.26), but that (a) does not, in general, imply (b) and (c). Examples
are furnished by Exercise 2.16 and by the space L 2, which is discussed in Chap. 11.
2.42 Theorem (Weierstrass). Every bounded infinite subset of Rk has a limit point in
Rk.
Proof. Being bounded, the set E in question is a subset of a k-cell I ⊂ Rk. By
Theorem 2.40, I is compact, and so E has a limit point in I, by Theorem 2.37.
PERFECT SETS
2.43 Theorem. Let P be a nonempty perfect set in Rk. Then P is uncountable.
Proof. Since P has limit points, P must be infinite. Suppose P is countable, and
denote the points of P by x1, x2, x3, . . . . We shall construct a countable collection
{Vn} of neighborhoods, as follows.
Let V1 be any neighborhood of x1. If V1 consists of all y ∈ Rk such that
|y − x1| < r, then closure V1 of V1 is the set of all y ∈ Rk such that |y − x1| ≤ r.
Suppose Vn has been constructed, so that Vn ∩ P is not empty. Since ev￾ery point of P is a limit point of P, there is a neighborhood Vn+1 such that
(i) Vn+1 ⊂ Vn, (ii) xn ∈/ Vn+1, (iii) Vn+1 ∩ P is not empty. By (iii), Vn+1 sat￾isfies our induction hypothesis, and the construction can proceed.
Put Kn = Vn ∩ P. Since Vn is closed and bounded, Vn is compact. Since xn ∈/
Kn+1, no point of P lies in T∞
n=1 Kn. Since Kn ⊂ P, this implies that T∞
n=1 Kn is
empty. But each Kn is nonempty, by (iii), and Kn ⊃ Kn+1, by (i); this contradicts
the Corollary to Theorem 2.36.
Corollary. Every interval [a, b] (a < b) is uncountable. In particular, the set of all real
numbers is uncountable.
2.44 The Cantor Set. The set which we are now going to construct shows that
there exist perfect sets in R1 which contain no segment.CONNECTED SETS 38
Let E0 be the interval [0, 1]. Remove the segment (1/3, 2/3), and let E1 be the
union of the intervals

0,
1
3

,

2
3
, 1

.
Remove the middle thirds of these intervals, and let E2 be the union of the intervals

0,
1
9

,

2
9
,
3
9

,

6
9
,
7
9

,

8
9
, 1

.
Continuing in this way, we obtain a sequence of compact sets En such that
(a) E1 ⊃ E2 ⊃ E3 ⊃ · · · ;
(b) En is the union of 2
n intervals, each of length 3
−n.
The set
P =
\∞
n=1
En
is called the Cantor set. P is clearly compact, and Theorem 2.36 shows that P is not
empty.
No segment of the form
(2.24) 
3k + 1
3m ,
3k + 2
3m

where k and m are positive integers, has a point in common with P. Since every
segment (α, β) contains a segment of the form (2.24), if
3
−m <
β − α
6
,
P contains no segment.
To show that P is perfect, it is enough to show that P contains no isolated point.
Let x ∈ P, and let S be any segment containing x. Let In be that interval of En
which contains x. Choose n large enough, so that In ⊂ S. Let xn be an endpoint
of In, such that xn ̸= x.
It follows from the construction of P that xn ∈ P. Hence x is a limit point of P,
and P is perfect.
One of the most interesting properties of the Cantor set is that it provides us
with an example of an uncountable set of measure zero (the concept of measure
will be discussed in Chap. 11).
CONNECTED SETS
2.45 Definition. Two subsets A ad B of a metric space X are said to be separated if
both A ∩ B and A ∩ B are empty, i.e., if no point of A lies in the closure of B and no
point of B lies in the closure of A.EXERCISES 39
A set E ⊂ X is said to be connected if E is not a union of two nonempty separated
sets.
2.46 Remark. Separated sets are of course disjoint, but disjoint sets need not be
separated. For example, the interval [0, 1] and the segment (1, 2) are not separated,
since 1 is a limit point of (1, 2). However, the segments (0, 1) and (1, 2) are sepa￾rated.
The connected subsets of the line have a particularly simple structure:
2.47 Theorem. A subset E of the real line R1 is connected if and only if it has the following
property: If x ∈ E, y ∈ E, and x < z < y, then z ∈ E.
Proof. If there exist x ∈ E, y ∈ E, and some z ∈ (x, y) such that z ∈/ E, then
E = Az ∪ Bz where
Az = E ∩ (−∞, z), Bz = E ∩ (z,∞).
Since x ∈ Az and y ∈ Bz, A and B are nonempty. Since Az ⊂ (−∞, z) and
Bz ⊂ (z,∞), they are separated. Hence E is not connected.
To prove the converse, suppose E is not connected. Then there are nonempty
separated sets A and B such that A ∪ B = E. Pick x ∈ A, y ∈ B, and assume
(without loss of generality) that x < y. Define
z = sup (A ∩ [x, y]).
By Theorem 2.28, z ∈ A; hence z ∈/ B. In particular, x ≤ z < y.
If z ∈/ A, it follows that x < z < y and z ∈/ E.
If z ∈ A, then z ∈/ B, hence there exists z1 such that z < z1 < y and z1 ∈/ B.
Then x < z1 < y and z1 ∈/ E.
EXERCISES
2.1. Prove that the empty set is a subset of every set.
2.2. A complex number z is said to be algebraic if there are integers a0, . . . , an, not all zero,
such that
a0z
n + a1z
n−1 + · · · + an−1z + an = 0.
Prove that the set of all algebraic numbers is countable. Hint: For every positive integer N
there are only finitely many equations with
n + |a0 | + |a1 | + · · · + |an | = N.
2.3. Prove that there exist real numbers which are not algebraic.
2.4. Is the set of all irrational real numbers countable?
2.5. Construct a bounded set of real numbers with exactly three limit points.
2.6. Let E
′ be the set of all limit points of a set E. Prove that E
′
is closed. Prove that E and E
have the same limit points. (Recall that E = E ∪ E
′
.) Do E and E
′ always have the same limit
points?EXERCISES 40
2.7. Let A1, A2, A3, . . . be subsets of a metric space.
(a) If Bn =
Sn
i=1 Ai, prove that Bn =
Sn
i=1 Ai for n = 1, 2, 3, . . . .
(b) If Bn =
S∞
i=1 Ai, prove that Bn ⊃
S∞
i=1 Ai.
Show, by an example, that this inclusion can be proper.
2.8. Is every point of every open set E ⊂ R2 a limit point of E? Answer the same question for
closed sets in R2
.
2.9. Let E
◦ denote the set of all interior points of a set E. [See Definition 2.18(e); E
◦
is called
the interior of E.]
(a) Prove that E
◦
is always open.
(b) Prove that E is open if and only if E
◦ = E.
(c) If G ⊂ E and G is open, prove that G ⊂ E
◦
.
(d) Prove that the complement of E
◦
is the closure of the complement of E.
(e) Do E and E always have the same interiors?
(f) Do E and E
◦ always have the same closures?
2.10. Let X be an infinite set. For p ∈ X and q ∈ X, define
d(p, q) = 
1 (if p ̸= q)
0 (if p = q).
Prove that this is a metric. Which subsets of the resulting metric space are open? Which are
closed? Which are compact?
2.11. For x ∈ R1 and y ∈ R1
, define
d1(x, y) = (x − y)
2
,
d2(x, y) = p
|x − y|,
d3(x, y) =

x
2 − y
2


,
d4(x, y) = |x − 2y| ,
d5(x, y) = |x − y|
1 + |x − y|
.
Determine, for each of these, whether it is a metric or not.
2.12. Let K ⊂ R1
consist of 0 and the numbers 1/n for n = 1, 2, 3, . . . . Prove that K is compact
directly from the definition (without using the Heine-Borel theorem).
2.13. Construct a compact set of real numbers whose limit points form a countable set.
2.14. Give an example of an open cover of the segment (0, 1) which has no finite subcover.
2.15. Show that Theorem 2.36 and its Corollary become false (in R1
, for example) if the word
“compact” is replaced by “closed” or by “bounded.”
2.16. Regard Q, the set of all rational numbers, as a metric space, with d(p, q) = |p − q|. Let
E be the set of all p ∈ Q such that 2 < p2 < 3. Show that E is closed and bounded in Q, but
that E is not compact. Is E open in Q?
2.17. Let E be the set of all x ∈ [0, 1] whose decimal expansion contains only the digits 4 and
7. Is E countable? Is E dense in [0, 1]? Is E compact? Is E perfect?
2.18. Is there a nonempty perfect set in R1 which contains no rational number?
2.19.
(a) If A and B are disjoint closed sets in some metric space X, prove that they are separated.
(b) Prove the same for disjoint open sets.EXERCISES 41
(c) Fix p ∈ X, δ > 0, define A to be the set of all q ∈ X for which d(p, q) < δ, define B
similarly, with > in place of <. Prove that A and B are separated.
(d) Prove that every connected metric space with at least two points is uncountable. Hint:
Use (c).
2.20. Are closures and interiors of connected sets always connected? (Look at subsets of R2
.)
2.21. Let A and B be separated subsets of some Rk, suppose a ∈ A, b ∈ B, and define
p(t) = (1 − t)a + tb
for t ∈ R1
. Put A0 = p
−1
(A), B0 = p
−1
(B). [Thus t ∈ A0 if and only if p(t) ∈ A.]
(a) Prove that A0 and B0 are separated subsets of R1
.
(b) Prove that there exists t0 ∈ (0, 1) such that p(t0) ∈/ A ∪ B.
(c) Prove that every convex subset of Rk is connected.
2.22. A metric space is called separable if it contains a countable dense subset. Show that Rk
is separable. Hint: Consider the set of points which have only rational coordinates.
2.23. A collection {Vα} of open subsets of X is said to be a base for X if the following is true:
For every x ∈ X and every open set G ⊂ X such that x ∈ G, we have x ∈ Vα ⊂ G for some α.
In other words, every open set in X is the union of a subcollection of {Vα}.
Prove that every separable metric space has a countable base. Hint: Take all neighbor￾hoods with rational radius and center in some countable dense subset of X.
2.24. Let X be a metric space in which every infinite subset has a limit point. Prove that X is
separable. Hint: Fix δ > 0, and pick x1 ∈ X. Having chosen x1, . . . , xj ∈ X, choose xj+1 ∈ X,
if possible, so that d(xi, xj+1) ≥ δ for i = 1, . . . , j. Show that this process must stop after a
finite number of steps, and that X can therefore be covered by finitely many neighborhoods
of radius δ. Take δ = 1/n (n = 1, 2, 3, . . . ), and consider the centers of the corresponding
neighborhoods.
2.25. Prove that every compact metric space K has a countable base, and that K is therefore
separable Hint: For every positive integer n, there are finitely many neighborhoods of radius
1/n whose union covers K.
2.26. Let X be a metric space in which every infinite subset has a limit point. Prove that X is
compact. Hint: By Exercises 2.23 and 2.24, X has a countable base. It follows that every open
cover of X has a countable subcover {Gn}, n = 1, 2, 3, . . . . If no finite subcollection of the {Gn}
covers X, then the complement Fn of G1 ∪ · · · ∪ Gn is nonempty for each n, but T∞
n=1
Fn
is empty. If E is a set which contains a point from each Fn, consider a limit point of E, and
obtain a contradiction.
2.27. Define a point p in a metric space X to be a condensation point of a set E ⊂ X if every
neighborhood of p contains uncountably many points of E.
Suppose E ⊂ Rk, E is uncountable, and let P be the set of all condensation points of E.
Prove that P is perfect and that at most countably many points of E are not in P. In other
words, show that P
c ∩ E is at most countable. Hint: Let {Vn} be a countable base of Rk, let W
be the union of those Vn for which E ∩ Vn is at most countable, and show that P = Wc
.
2.28. Prove that every closed set in a separable metric space is the union of a (possibly empty)
perfect set and a set which is at most countable. (Corollary: Every countable closed set in Rk
has isolated points.) Hint: Use Exercise 2.27.
2.29. Prove that every open set in R1
is the union of an at most countable collection of disjoint
segments. Hint: Use Exercise 2.22.EXERCISES 42
2.30. Imitate the proof of Theorem 2.43 to obtain the following result:
If Rk =
S∞
n=1
Fn, where each Fn is a closed subset of Rk, then at least one Fn has a
nonempty interior.
Equivalent statement: If Gn is a dense open subset of Rk for n = 1, 2, 3, . . . , then
T∞
n=1 Gn is not empty (in fact, it is dense in Rk).
(This is a special case of Baire’s theorem; see Exercise 3.22 for the general case.)Chapter 3
NUMERICAL SEQUENCES AND
SERIES
As the title indicates, this chapter will deal primarily with sequences and series
of complex numbers. The basic facts about convergence, however, are just as eas￾ily explained in a more general setting. The first three sections will therefore be
concerned with sequences in euclidean spaces, or even in metric spaces.
CONVERGENT SEQUENCES
3.1 Definition. A sequence (pn) in a metric space X is said to converge if there is
a point p ∈ X with the following property: For every ε > 0 there is an integer N
such that n ≥ N implies that d(pn, p) < ε. (Here d denotes the distance in X.)
In this case, we also say that (pn) converges to p, or that p is the limit of (pn)
[see Theorem 3.2(b), and we write pn → p, or
lim n→∞
pn = p.
If (pn) does not converge, it is said to diverge.
It might be well to point out that our definition of “convergent sequence” de￾pends not only on (pn) but also on X; for instance, the sequence (1/n) converges
in R1 (to 0), but fails to converge in the set of all positive real numbers [with
d(x, y) = |x − y|]. In cases of possible ambiguity, we can be more precise and
specify “convergent in X” rather that “convergent.”
We recall that the set of points pn (n = 1, 2, 3, . . . ) is the range of (pn). The
range of a sequence may be a finite set, or it may be infinite. The sequence (pn) is
said to be bounded if its range is bounded.
As examples, consider the following sequences of complex numbers (that is,
X = R2):
43CONVERGENT SEQUENCES 44
(a) If sn = 1/n, then limn→∞ sn = 0; the range is infinite, and the sequence is
bounded.
(b) If sn = n
2, the sequence sn is unbounded, is divergent, and has infinite
range.
(c) If sn = 1 + [(−1)
n/n], the sequence (sn) converges to 1, is bounded, and has
infinite range.
(d) If sn = i
n, the sequence (sn) is divergent, is bounded, and has finite range.
(e) If sn = 1 (n = 1, 2, 3, . . . ), then (sn) converges to 1, is bounded, and has finite
range.
We now summarize some important properties of convergent sequences in
metric spaces.
3.2 Theorem. Let (pn) be a sequence in a metric space X.
(a) (pn) converges to p ∈ X if and only if every neighborhood of p contains pn for all
but finitely many n.
(b) If p ∈ X, p
′ ∈ X, and if (pn) converges to p and to p
′
, then p
′ = p.
(c) If (pn) converges, then (pn) is bounded.
(d) If E ⊂ X and if p is a limit point of E, then there is a sequence (pn) in E such that
p = limn→∞ pn.
Proof.
(a) Suppose pn → p and let V be a neighborhood of p. For some ε > 0, the
conditions d(q, p) < ε, q ∈ X imply q ∈ V. Corresponding to this ε, there
exists N such that n ≥ N implies d(pn, p) < ε. Thus n ≥ N implies pn ∈ V.
Conversely, suppose every neighborhood of p contains all but finitely
many of the pn. Fix ε > 0 and let V be the set of all q ∈ X such that d(p, q) <
ε. By assumption, there exists N (corresponding to this V) such that pn ∈ V
if n ≥ N. Thus d(pn, p) < ε if n ≥ N; hence pn → p.
(b) Let ε > 0 be given. There exist integers N, N′
such that
n ≥ N implies d(pn, p) <
ε
2
,
n ≥ N′
implies d(pn, p
′
) <
ε
2
.
Hence if n ≥ max{N, N′
}, we have
d(p, p
′
) ≤ d(p, pn) + d(pn, p
′
) < ε.
Since ε was arbitrary, we conclude that d(p, p
′
) = 0.
(c) Suppose pn → p. Then there is an integer N such that n > N implies
d(pn, p) < 1. Put
r = max{1, d(p1, p), . . . , d(pN, p)}.
Then d(pn, p) ≤ r for n = 1, 2, 3, . . . .CONVERGENT SEQUENCES 45
(d) For each positive integer n, there is a point pn ∈ E such that d(pn, p) < 1/n.
Given ε > 0, choose N so that Nε > 1. If n > N, it follows that d(pn, p) < ε.
Hence pn → p.
This completes the proof.
For sequences in Rk we can study the relation between congruence, on the one
hand, and the algebraic operations on the other. We first consider sequences of
complex numbers.
3.3 Theorem. Suppose(sn), (tn) are complex sequences and limn→∞ sn = s, limn→∞ tn =
t. Then
(a) lim n→∞
(sn + tn) = s + t;
(b) lim n→∞
csn = cs, lim n→∞
(c + sn) = c + s for any number c;
(c) lim n→∞
sntn = st;
(d) lim n→∞
(1/s
n) = 1/s, provided sn ̸= 0 (n = 1, 2, 3, . . . ) and s ̸= 0.
Proof.
(a) Given ε > 0, there exist integers N1, N2 such that
n ≥ N1 implies |sn − s| <
ε
2
,
n ≥ N2 implies |tn − t| <
ε
2
.
If N = max{N1, N2}, then n ≥ N implies
|(sn + tn) − (s + t)| ≤ |sn − s| + |tn − t| < ε.
This proves (a). The proof of (b) is trivial.
(c) We use the identity
(3.1) sntn − st = (sn − s)(tn − t) + s(tn − t) + t(sn − s).
Given ε > 0, there are integers N1, N2 such that
n ≥ N1 implies |sn − s| <
√
ε,
n ≥ N2 implies |tn − t| <
√
ε.
If we take N = max{N1, N2}, n ≥ N implies
|(sn − s)(tn − t)| < ε,CONVERGENT SEQUENCES 46
so that
lim n→∞
(sn − s)(tn − t) = 0.
We now apply (a) and (b) to (3.1) and conclude that
lim n→∞
(sntn − st) = 0.
(d) Choosing m such that |sn − s| < |s| /2 if n ≥ m, we see that
|sn | >
1
2
|s| (n ≥ m).
Give ε > 0, there is an integer N > m such that n ≥ N implies
|sn − s| <
1
2
|s|
2
ε.
Hence, for n ≥ N,




1
sn
−
1
s



 =




sn − s
sns




<
2
|s|
2
|sn − s| < ε.
3.4 Theorem.
(a) Suppose xn ∈ Rk (n = 1, 2, 3, . . . ) and
xn = (α1,n, . . . , αk,n).
Then (xn) converges to x = (α1, . . . , αk) if and only if
(3.2) lim n→∞
αj,n = αj
(1 ≤ j ≤ k).
(b) Suppose (xn), (yn) are sequences in Rk, (βn) is a sequence of real numbers, and
xn → x, yn → y, βn → β. Then
lim n→∞
(xn + yn) = x + y, lim n→∞
xn · yn = x · y, lim n→∞
βnxn = βx.
Proof.
(a) If xn → x, the inequalities

αj,n − αj

 ≤ |xn − x| ,
which follow immediately from the definition of the norm in Rk, show that
(3.2) holds.
Conversely, if (3.2) holds, then to each ε > 0, there corresponds an integer
N such that n ≥ N implies

αj,n − αj

 <
ε√
k
(1 ≤ j ≤ k).SUBSEQUENCES 47
Hence n ≥ N implies
|xn − x| =



X
k
j=1

αj,n − αj


2



1/2
< ε,
so that xn → x. This proves (a).
Part (b) follows from (a) and Theorem 3.3.
SUBSEQUENCES
3.5 Definition. Given a sequence (pn), consider a sequence (nk) of positive inte￾gers such that n1 < n2 < n3 < · · · . Then the sequence (pni
) is called a subsequence
of (pn). If (pni
) converges, its limit is called it subsequential limit of (pn).
It is clear that (pn) converges to p if and only if every subsequence of (pn)
converges to p. We leave the details of the proof to the reader.
3.6 Theorem.
(a) If (pn) is a sequence in a compact metric space X, then some subsequence of (pn)
converges to a point of X.
(b) Every bounded sequence in Rk contains a convergent subsequence.
Proof.
(a) Let E be the range of (pn). If E is finite then there is a p ∈ E and a sequence
(ni
) with n1 < n2 < n3 < · · · such that
pn1 = pn2 = · · · = p.
The subsequence (pni
) so obtained converges evidently to p.
If E is infinite, Theorem 2.37 shows that E has a limit point p ∈ X. Choose
n1 so that d(p, pn1
) < 1. Having chosen n1, . . . , ni−1, we see from Theo￾rem 2.20 that there is an integer ni > ni−1 such that d(p, pni
) < 1/i. Then
(pni
) converges to p.
(b) This follows from (a) since Theorem 2.41 implies that every bounded subset
of Rk lies in a compact subset of Rk.
3.7 Theorem. The subsequential limits of a sequence (pn) in a metric space form a closed
subset of X.
Proof. Let E
∗ be the set of all subsequential limits of (pn) and let q be a limit point
of E
∗
. We have to show that q ∈ E
∗
.CAUCHY SEQUENCES 48
Choose n1 so that pn1
̸= q. (If no such n1 exists, then E
∗ has only one point,
and there is nothing to prove.) Put δ = d(q, pn1
). Suppose n1, . . . , ni−1 are cho￾sen. Since q is a limit point of E
∗
, there is an x ∈ E
∗ with d(x, q) < 2−iδ. Since
x ∈ E
∗
, there is an ni > ni−1 such that d(x, pni
) < 2−iδ. Thus
d(q, pni
) ≤ 2
1−i
δ
for i = 1, 2, 3, . . . . This says that (pni
) converges to q. Hence q ∈ E
∗
.
CAUCHY SEQUENCES
3.8 Definition. A sequence (pn) in a metric space X is said to be a Cauchy sequence
if for every ε > 0 there is an integer N such that d(pn, pm) < ε if n ≥ N and
m ≥ N.
In our discussion of Cauchy sequences, as well as other situations which will
arise later, the following geometric concept will be useful.
3.9 Definition. Let E be a nonempty subset of a metric space X and let S be the set
of all real numbers of the form d(p, q) with p ∈ E and q ∈ E. The sup of S is called
the diameter of E.
If (pn) is a sequence in X and if EN consists of the points pN, pN+1, pN+2, . . . ,
it is clear from the two preceding definitions that (pn) is a Cauchy sequence if and
only if
lim
N→∞
diam EN = 0.
3.10 Theorem.
(a) If E is the closure of a set E in a metric space X, then
diam E = diam E.
(b) If Kn is a sequence of compact sets in X such that Kn ⊃ Kn+1 (n = 1, 2, 3, . . . )
and if
lim n→∞
diam Kn = 0,
then T∞
n=1 Kn consists of exactly one point.
Proof.
(a) Since E ⊂ E, it is clear that
diam E ≤ diam E.CAUCHY SEQUENCES 49
Fix ε > 0, and choose p ∈ E, q ∈ E. By the definition of E, there are points
p
′
, q
′
in E such that d(p, p
′
) < ε, d(q, q
′
) < ε. Hence
d(p, q) ≤ d(p, p
′
) + d(p
′
, q
′
) + d(q
′
, q)
< 2ε + d(p
′
, q
′
) ≤ 2ε + diam E.
It follows that
diam E ≤ 2ε + diam E,
and since ε was arbitrary, (a) is proved.
(b) Put K =
T∞
n=1 Kn. By Theorem 2.36, K is not empty. If K contains more
than one point, then diam K > 0. But for each n, Kn ⊃ K so that diam Kn ≥
diam K. This contradicts the assumption that diam Kn → 0.
3.11 Theorem.
(a) In any metric space X, every convergent sequence is a Cauchy sequence.
(b) If X is a compact metric space and if (pn) is a Cauchy sequence in X, then (pn)
converges to some point of X.
(c) In Rk, every Cauchy sequence converges.
Note: The difference between the definition of convergence and the definition
of a Cauchy sequence is that the limit is explicitly involved in the former, but not
in the latter. Thus Theorem 3.11(b) may enable us to decide whether or not a given
sequence converges without knowledge of the limit to which it may converge.
The fact (contained in Theorem 3.11) that a sequence converges in Rk if and
only if it is a Cauchy sequence is usually called the Cauchy criterion for convergence.
Proof.
(a) If pn → p and if ε > 0, there is an integer N such that d(p, pn) < ε for all
n ≥ N. Hence
d(pn, pm) ≤ d(pn, p) + d(p, pm) < 2ε
as soon as n ≥ N and n ≥ N. Thus (pn) is a Cauchy sequence.
(b) Let (pn) be a Cauchy sequence in the compact space X. For N = 1, 2, 3, . . . ,
let EN be the set consisting of pN, pN+1, pN+2, . . . . Then
(3.3) lim
N→∞
diam EN = 0,
by Definition 3.9 and Theorem 3.10(a). Being a closed subset of a compact
space X, each EN is compact (Theorem 2.35). Also, EN ⊃ EN+1, so that
EN ⊃ EN+1.
Theorem 3.10(b) shows now that there is a unique p ∈ X which lies in
every EN.CAUCHY SEQUENCES 50
Let ε > 0 be given. By (3.3) there is an integer N0 such that diam EN < ε
if N ≥ N0. Since p ∈ EN, it follows that d(p, q) < ε for every q ∈ EN,
hence for every q ∈ EN. In other words, d(p, pn) < ε if n ≥ N0. This says
precisely that pn → p.
(c) Let (xn) be a Cauchy sequence in Rk. Define EN as in (b), with xi
in place
of pi
. For some N, diam EN < 1. The range of (xn) is the union of EN and
the finite set {x1, . . . , xN−1}. Hence (xn) is bounded. Since every bounded
subset of Rk has compact closure in Rk (Theorem 2.41), (c) follows from
(b).
3.12 Definition. A metric space in which every Cauchy sequence converges is said
to be complete
Thus Theorem 3.11 says that all compact metric spaces and all euclidean spaces are
complete. Theorem 3.11 implies also that every closed subset E of a complete metric
space X is complete. (Every Cauchy sequence in E is a Cauchy sequence in X, hence
it converges to some p ∈ X, and actually p ∈ E since E is closed.) An example
of a metric space which is not complete is the space of all rational numbers with
d(x, y) = |x − y|.
Theorem 3.2(c) and example (d) after Definition 3.1 show that convergent se￾quences are bounded, but that bounded sequences in Rk need not converge. How￾ever, there is one important case in which convergence is equivalent to bounded￾ness; this happens for monotonic sequences in R1.
3.13 Definition. A sequence (sn) of real numbers is said to be
(a) monotonically increasing if sn ≤ sn+1 (n = 1, 2, 3, . . . );
(b) monotonically decreasing if sn ≥ sn+1 (n = 1, 2, 3, . . . ).
The class of monotonic sequences consists of the increasing and decreasing se￾quences.
3.14 Theorem. Suppose (sn) is monotonic. Then (sn) converges if and only if it is
bounded.
Proof. Suppose sn ≤ sn+1 (the proof is analogous in the other case). Let E be the
range of (sn). If (sn) is bounded, let s be the upper bound of E. Then
sn ≤ s (n = 1, 2, 3, . . .).
For every ε > 0, there is an integer N such that
s − ε < sN ≤ s,
for otherwise s − ε would be an upper bound of E. Since (sn) increases n ≥ N
therefore implies
s − ε < sn ≤ s,UPPER AND LOWER LIMITS 51
which shows that (sn) converges (to s).
The converse follows from Theorem 3.2(c).
UPPER AND LOWER LIMITS
3.15 Definition. Let (sn) be a sequence of real numbers with the following prop￾erty: For every real M there is an integer N such that n ≥ N implies sn ≥ M. We
then write
sn → +∞.
Similarly, if for every real M there exists an integer N such that n ≥ N implies
sn ≤ M, we write
sn → −∞.
It should be noted that we now use the symbol → (introduced in Definition 3.1)
for certain types of divergent sequences, as well as for convergent sequences, but
that the definitions of convergence and of limit, given in Definition 3.1 are un￾changed.
3.16 Definition. Let (sn) be a sequence of real numbers. Let E be the set of num￾bers x (in the extended real number system) such that snk → x for some sub￾sequence (snk
). This set E contains all subsequential limits as defined in Defini￾tion 3.5, plus possibly the numbers +∞, −∞.
We now recall Definitions 1.8 and 1.23 and put
s
∗ = sup E,
s∗ = inf E.
The numbers s
∗
, s∗ are called the upper and lower limits of (sn); we use the notation
lim sup
n→∞
sn = s
∗
, lim inf
n→∞
sn = s∗.
3.17 Theorem. Let (sn) be a sequence of real numbers. Let E and s
∗ have the same
meaning as in Definition 3.16. Then s
∗ has the following two properties:
(a) s
∗ ∈ E.
(b) If x > s∗
, there is an integer N such that n ≥ N implies sn < x.
Moreover, s
∗
is the only number with the properties (a) and (b).
Of course, an analogous result is true for s∗.
Proof.
(a) If s
∗ = +∞, then E is not bounded above; hence (sn) is not bounded above,
and there is a subsequence (snk
) such that snk → +∞.SOME SPECIAL SEQUENCES 52
If s
∗
is real, then E is bounded above, and at least one subsequential limit
exists, so that (a) follows from Theorems 3.7 and 2.28.
If s
∗ = −∞, then E contains only one element, namely −∞, and there is
no subsequential limit. Hence, for any real M, sn > M for at most a finite
number of values of n, so that sn → −∞.
This establishes (a) in all cases.
(b) Suppose there is a number x > s∗
such that sn ≥ x for infinitely many values
of n. In that case, there is a number y ∈ E such that y ≥ x > s∗
, contradicting
the definition of s
∗
.
Thus s
∗
satisfies (a) and (b). To show the uniqueness, suppose there are two
numbers, p and q, which satisfy (a) and (b), and suppose p < q. Choose x such
that p < x < q. Since p satisfies (b), we have sn < x for n ≥ N. But then q cannot
satisfy (a).
3.18 Examples.
(a) Let (sn) be a sequence containing all rationals. Then every real number is a
subsequential limit, and
lim sup
n→∞
sn = +∞, lim inf
n→∞
sn = −∞.
(b) Let sn = (−1)
n/[1 + (1/n)]. Then
lim sup
n→∞
sn = 1, lim inf
n→∞
sn = −1.
(c) For a real-valued sequence (sn), limn→∞ sn = s if and only if
lim sup
n→∞
sn = lim inf
n→∞
sn = s.
We close this section with a theorem which is useful and whose proof is quite
trivial:
3.19 Theorem. If sn ≤ tn for n ≥ N, where N is fixed, then
lim inf
n→∞
sn ≤ lim inf
n→∞
tn,
lim sup
n→∞
sn ≤ lim sup
n→∞
tn.
SOME SPECIAL SEQUENCES
We shall now compute the limits of some sequences which occur frequently. The
proofs will all be based on the following remark: If 0 ≤ xn ≤ sn for n ≥ N, where
N is some fixed number, and if sn → 0, then xn → 0.SOME SPECIAL SEQUENCES 53
3.20 Theorem.
(a) If p > 0, then limn→∞ 1/n
p = 0.
(b) If p > 0, then limn→∞ n√
p = 1.
(c) limn→∞
n√
n = 1.
(d) If p > 0 and α is real, then limn→∞ n
α/(1 + p)
n = 0.
(e) If |x| < 1, then limn→∞ x
n = 0.
Proof.
(a) Take n > (1/ε)
1/p. (Note that the archimedean property of the real number
system is used here.)
(b) If p > 1, put xn = n√
p − 1. Then xn > 0 and, by the binomial theorem,
1 + nxn ≤ (1 + xn)
n = p,
so that
0 < xn ≤
p − 1
n
.
Hence xn → 0. If p = 1, (b) is trivial, and if 0 < p < 1, the result is obtained
by taking reciprocals.
(c) Put xn = n√
n − 1. Then xn ≥ 0 and, by the binomial theorem,
n = (1 + xn)
n ≥
n(n − 1)
2
x
2
n.
Hence
0 ≤ xn ≤
r
2
n − 1
(n ≥ 2).
(d) Let k be an integer such that k > α, k > 0. For n > 2k,
(1 + p)
n >

n
k

p
k =
n(n − 1)· · ·(n − k + 1)
k!
p
k >
n
kp
k
2
kk!
.
Hence
0 < n
α
(1 + p)n
<
2
kk!
pk
n
α−k
(n > 2k).
Since α − k < 0, n
α−k → 0, by (a).
(e) Take α = 0 in (d).SERIES 54
SERIES
In the remainder of this chapter, all sequences and series under consideration will
be complex-valued, unless the contrary is explicitly stated. Extensions of some
of the theorems which follow, to series with terms in Rk, are mentioned in Exer￾cise 3.15.
3.21 Definition. Given a sequence (an), we use the notation
X
q
n=p
an (p ≤ q)
to denote the sum ap + ap+1 + · · · + aq. With (an), we associate a sequence (sn),
where
sn =
Xn
k=1
ak.
For (sn) we also use the symbolic expression
a1 + a2 + a3 + · · ·
or, more concisely,
(3.4) X∞
n=1
an.
The symbol in (3.4) we call an infinite series or just a series. The numbers sn are
called the partial sums of the series. If (sn) converges to s, we say that the series
converges, and write
X∞
n=1
an = s.
The number s is called the sum of the series; but it should be clearly understood
that s is the limit of a sequence of sums, and is not obtained simply by addition.
If (sn) diverges, the series is said to diverge.
Sometimes, for convenience of notation, we shall consider series of the form
(3.5) X∞
n=0
an.
And frequently, when there is no possible ambiguity, or when the distinction is
immaterial, we shall simply write Σan in place of (3.4) or (3.5).
It is clear that every theorem about sequences can be stated in terms of series
(putting a1 = s1 and an = sn − sn−1 for n > 1), and vice versa. But it is never￾theless useful to consider both concepts.
The Cauchy criterion (Theorem 3.11) can be restated in the following form:SERIES 55
3.22 Theorem. Σan converges if and only if for every ε > 0 there is an integer N such
that
(3.6)





Xm
k=n
ak





≤ ε
if m ≥ n ≥ N.
In particular, by taking m = n, (3.6) becomes
|an | ≤ ε (n ≥ N).
In other words:
3.23 Theorem. If Σan converges, then limn→∞ an = 0.
The condition an → 0 is not, however, sufficient to ensure convergence of Σan.
For instance, the series
X∞
n=1
1
n
diverges; for the proof, we refer to Theorem 3.28.
Theorem 3.14, concerning monotonic sequences, also has an immediate coun￾terpart for series.
3.24 Theorem. A series of nonnegative1
terms converges if and only if its partial sums
form a bounded sequence.
We now turn to a convergence test of a different nature, the so-called “compar￾ison test.”
3.25 Theorem.
(a) If |an | ≤ cn for n ≥ N0, where N0 is some fixed integer, and if Σcn converges,
then Σan converges.
(b) If an ≥ dn ≥ 0 for n ≥ N0 and if Σdn diverges, then Σan diverges.
Note that (b) applies only to series of nonnegative terms an.
Proof. Given ε > 0, there exists N ≥ N0 such that m ≥ n ≥ N implies
Xm
k=n
ck ≤ ε
by the Cauchy criterion. Hence





Xm
k=n
ak





≤
Xm
k=n
|ak| ≤
Xm
k=n
ck ≤ ε,
1The expression “nonnegative” always refers to real numbers.SERIES OF NONNEGATIVE TERMS 56
and (a) follows.
Next, (b) follows from (a), for if Σan converges, so must Σdn [note that (b) also
follows from Theorem 3.24].
The comparison test is a very useful one; to use it efficiently, we have to be￾come familiar with a number of series of nonnegative terms whose convergence or
divergence is known.
SERIES OF NONNEGATIVE TERMS
The simplest of all is perhaps the geometric series.
3.26 Theorem. If 0 ≤ x < 1, then
X∞
n=0
x
n =
1
1 − x
.
If x ≥ 1, the series diverges.
Proof. If x ̸= 1,
sn =
Xn
k=0
x
k =
1 − x
n+1
1 − x
.
The result follows if we let n → ∞. For x = 1, we get
1 + 1 + 1 + · · · ,
which evidently diverges.
In many cases which occur in applications, the terms of the series decrease
monotonically. The following theorem of Cauchy is therefore of a particular inter￾est. The striking feature of the theorem is that a rather “thin” subsequence of (an)
determines the convergence or divergence of Σan.
3.27 Theorem. Suppose a1 ≥ a2 ≥ a3 ≥ · · · ≥ 0. Then the series P∞
n=1 an con￾verges if and only if the series
(3.7) X∞
k=0
2
ka2k = a1 + 2a2 + 4a4 + 8a8 + · · ·
converges.
Proof. By Theorem 3.24, it suffices to consider the boundedness of the partial sums.
Let
sn = a1 + a2 + · · · + an,
tk = a1 + 2a2 + · · · + 2
ka2k .SERIES OF NONNEGATIVE TERMS 57
For n < 2k,
sn ≤ a1 + (a2 + a3) + · · · + (a2k + · · · + a2k+1−1
)
≤ a1 + 2a2 + · · · + 2
ka2k
= tk,
so that
(3.8) sn ≤ tk.
On the other hand, if n > 2k,
sn ≥ a1 + a2 + (a3 + a4) + · · · + (a2k−1+1 + · · · + a2k )
≥
1
2
a1 + a2 + 2a4 + · · · + 2
k−1a2k
=
1
2
t
k
,
so that
(3.9) 2sn ≥ tk.
By (3.8) and (3.9), the sequences (sn) and (tn) are either both bounded or both
unbounded. This completes the proof.
3.28 Theorem. P 1
np converges if p > 1 and diverges if p ≤ 1.
Proof. If p ≤ 0, divergence follows from Theorem 3.23. If p > 0, Theorem 3.27 is
applicable, and we are led to the series
X∞
k=0
2
k
·
1
2
kp =
X∞
k=0
2
(1−p)k
.
Now, 2
1−p < 1 if and only if 1 − p < 0, and the result follows by comparison with
the geometric series (take x = 2
1−p in Theorem 3.26).
As a further application of Theorem 3.27, we prove:
3.29 Theorem. If p > 1,
(3.10) X∞
n=2
1
n(log n)
p
converges; if p ≤ 1, the series diverges.
Remark. “log n” denotes the logarithm of n to the base e (compare Exercise 1.7);
the number e will be defined in a moment (see Definition 3.30). We let the series
start with n = 2 since log 1 = 0.THE NUMBER e 58
Proof. The monotonicity of the logarithmic function (which will be discussed in
more detail in Chap. 8) implies that(log n)∞
n=1
increases. Hence (1/[n(log n)
p])∞
n=1
decreases, and we can apply Theorem 3.27 to (3.10); this leads us to the series
(3.11) X∞
k=1
2
k
·
1
2
k(log 2
k)
p
=
X∞
k=1
1
(k log 2)
p
=
1
(log 2)
p
X∞
k=1
1
k
p
,
and Theorem 3.29 follows from Theorem 3.28.
This procedure may evidently be continued. For instance,
(3.12) X∞
n=3
1
n log(n)log(log(n))
diverges, whereas
(3.13) X∞
n=3
1
n log(n)(log(log n))2
converges.
We may now observe that the terms of the series (3.12) differ very little from
those of (3.13). Still, one diverges, the other converges. If we continue the process
which led us from Theorem 3.28 to Theorem 3.29, and then to (3.12) and (3.13),
we get pairs of convergent and divergent series whose terms differ even less than
those of (3.12) and (3.13). One might thus be led to the conjecture that there is
a limiting situation of some sort, a “boundary” with all convergent series on one
side, all divergent series on the other side—at least as far as series with monotonic
coefficients are concerned. This notion of a “boundary” is of course quite vague.
The point we wish to make is this: No matter how we make this notion precise,
the conjecture is false. Exercises 3.11(b) and 3.12(b) may serve as illustrations.
We do not wish to go any deeper into this aspect of convergence theory, and
refer the reader to Knopp’s “Theory and Application of Infinite Series,” Chap. IX,
particularly Sec. 41 [Kno28].
THE NUMBER e
3.30 Definition. e =
P∞
n=0
1
n!
.
Here, n! = 1 · 2 · 3 · · · n if n ≥ 1, and 0! = 1. Since
sn = 1 + 1 +
1
1 · 2
+
1
1 · 2 · 3
+ · · · +
1
1 · 2 · · · n
< 1 + 1 +
1
2
+
1
2
2
+ · · · +
1
2n−1
< 3,THE NUMBER e 59
the series converges and the definition makes sense. In fact, the series converges
very rapidly and allows us to compute e with great accuracy.
It is of interest to note that e can also be defined by means of another limit
process; the proof provides a good illustration of operations with limits:
3.31 Theorem. limn→∞ 
1 +
1
n
n
= e.
Proof. Let
sn =
Xn
k=0
1
k!
, tn =

1 +
1
n
n
.
By the binomial theorem,
tn = 1 + 1 +
1
2!

1 −
1
n

+
1
3!

1 −
1
n
 1 −
2
n

+ · · ·
+
1
n!

1 −
1
n
 1 −
2
n

· · · 
1 −
n − 1
n

.
Hence tn ≤ sn, so that
(3.14) lim sup
n→∞
tn ≤ e,
by Theorem 3.19. Next, if n ≥ m,
tn ≥ 1 + 1 +
1
2!

1 −
1
n

+ · · · +
1
m!

1 −
1
n

· · · 
1 −
m − 1
n

.
Let n → ∞, keeping m fixed. We get
lim inf
n→∞
tn ≥ 1 + 1 +
1
2!
+ · · · +
1
m!
,
so that
sm ≤ lim inf
n→∞
tn.
Letting m → ∞, we finally get
(3.15) e ≤ lim inf
n→∞
tn.
The theorem follows from (3.14) and (3.15).
The rapidity with which the series P1/n! converges can be estimated as fol￾lows: If sn has the same meaning as above, we have
e − sn =
1
(n + 1)! +
1
(n + 2)! +
1
(n + 3)! + · · ·
<
1
(n + 1)! 
1 +
1
n + 1
+
1
(n + 1)
2
+ · · · 
=
1
n!nTHE ROOT AND RATIO TESTS 60
so that
(3.16) 0 < e − sn <
1
n!n
.
Thus s10, for instance, approximates e with an error less than 10−7. The inequality
(3.16) is of theoretical interest as well since it enables us to prove the irrationality
of e very easily.
3.32 Theorem. e is irrational.
Proof. Suppose e is rational. Then e = p/q, where p and q are positive integers.
By (3.16),
(3.17) 0 < q!(e − sq) <
1
q
.
By our assumption, q!e is an integer. Since
q!sq = q!

1 + 1 +
1
2!
+ · · · +
1
q!

is an integer, we see that q!(e − sq) is an integer.
Since q ≥ 1, (3.17) implies the existence of an integer between 0 and 1. We have
thus reached a contradiction.
Actually, e is not even an algebraic number. For a simple proof of this, see
page 25 of Niven’s book [Niv65], or page 176 of Herstein’s [Her64] cited in the
Bibliography.
THE ROOT AND RATIO TESTS
3.33 Theorem. Given Σan, put α = lim supn→∞
np
|an |.
(a) If α < 1, Σan converges;
(b) If α > 1, Σan diverges;
(c) If α = 1, the test gives no information.
Proof. If α < 1, we can choose β so that α < β < 1, and an integer N such that
np
|an | < β
for n ≥ N [by Theorem 3.17(b)]. That is, n ≥ N implies
|an | < βn.
Since 0 < β < 1, Σβn converges. Convergence of Σan follows now from the
comparison test.THE ROOT AND RATIO TESTS 61
If α > 1, then, again by Theorem 3.17, there is a sequence (nk) such that
nk
q
|ank
| → α.
Hence |an | > 1 for infinitely many values of n, so that the condition an → 0,
necessary for convergence of Σan, does not hold (Theorem 3.23).
To prove (c), we consider the series
X 1
n
,
X 1
n2
.
For each of these series, α = 1, but the first diverges and the second converges.
3.34 Theorem. The series Σan
(a) converges if lim supn→∞ |an+1/an | < 1,
(b) diverges if |an+1/an | ≥ 1 for all n ≥ n0, where n0 is some fixed integer.
Proof. If condition (a) holds, we can find β < 1, and an integer N such that




an+1
an




< β
for n ≥ N. In particular,
|aN+1| < β |aN| ,
|aN+2| < β |aN+1| < β2
|aN| ,
.
.
.

aN+p

 < βp |aN| .
That is,
|an | < |aN| β
−N · β
n
for n ≥ N, and (a) follows from the comparison test, since Σβn converges.
If |an+1| ≥ |an | for n ≥ n0, it is easily seen that the condition an → 0 does
not hold, and (b) follows.
Note: the knowledge that lim an+1/an = 1 implies nothing about the conver￾gence of Σan. The series P1/n and P1/n
2 demonstrate this.
3.35 Examples.
(a) Consider the series
1
2
+
1
3
+
1
2
2
+
1
3
2
+
1
2
3
+
1
3
3
+
1
2
4
+
1
3
4
+ · · · ,THE ROOT AND RATIO TESTS 62
for which
lim inf
n→∞
an+1
an
= lim n→∞ 
2
3
n
= 0,
lim inf
n→∞
n√
n = lim n→∞
2nr
1
3n
=
1
√
3
,
lim sup
n→∞
n√
an = lim n→∞
2nr
1
2n
=
1
√
2
,
lim sup
n→∞
an+1
an
= lim n→∞
1
2

3
2
n
= +∞.
The root test indicates convergence; the ratio test does not apply.
(b) The same is true for the series
1
2
+ 1 +
1
8
+
1
4
+
1
32 +
1
16 +
1
128 +
1
64 + · · · ,
where
lim inf
n→∞
an+1
an
=
1
8
,
lim sup
n→∞
an+1
an
= 2,
but
lim n→∞
n√
an =
1
2
.
3.36 Remarks. The ratio test is frequently easier to apply than the root test since
it is usually easier to compute ratios than nth roots. However, the root test has
wider scope. More precisely: Whenever the ratio test shows convergence, the root
test does too; whenever the root test is inconclusive, the ratio test is too. This is a
consequence of Theorem 3.37 and is illustrated by the above examples.
Neither of the two tests is subtle with regard to divergence. Both deduce diver￾gence from the fact that an does not tend to zero as n → ∞.
3.37 Theorem. For any sequence (cn) of positive numbers,
lim inf
n→∞
cn+1
cn
≤ lim inf
n→∞
n√
cn,
lim sup
n→∞
n√
cn ≤ lim sup
n→∞
cn+1
cn
.
Proof. We shall prove the second inequality; the proof of the first is quite similar.
Put
α = lim sup
n→∞
cn+1
cn
.POWER SERIES 63
If α = +∞, there is nothing to prove. If α is finite, choose β > α. There is an
integer N such that
cn+1
cn
≤ β
for n ≥ N. In particular, for any p > 0,
cN+k+1 ≤ βcN+k (k = 0, 1, . . . , p − 1).
Multiplying these inequalities, we obtain
cN+p ≤ β
pcN,
or
cn ≤ cNβ
−N · β
n (n ≥ N).
Hence
n√
cn ≤
n
q
cNβ−N · β,
so that
(3.18) lim sup
n→∞
n√
cn ≤ β,
by Theorem 3.20(b). Since (3.18) is true for every β > α, we have
lim sup
n→∞
n√
cn ≤ α.
POWER SERIES
3.38 Definition. Given a sequence (cn) of complex numbers, the series
(3.19) X∞
n=0
cnz
n
is called a power series. The numbers cn are called the coefficients of the series; z is a
complex number.
In general, the series will converge or diverge depending on the choice of z.
More specifically, with every power series there is associated a circle, the circle
of convergence, such that (3.19) converges if z is in the interior of the circle and
diverges if z is in the exterior of the circle (to cover all cases, we have to consider
the plane as the interior of a circle with infinite radius, and a point as a circle with
radius zero). The behavior on the circle of convergence is much more varied and
cannot be described so simply.SUMMATION BY PARTS 64
3.39 Theorem. Given the power series Σcnz
n, put
α = lim sup
n→∞
np
|cn |, R =
1
α
.
(If α = 0, R = +∞; if α = +∞, R = 0.) Then Σcnz
n converges if |z| < R and diverges
if |z| > R.
Proof. Put an = cnz
n and apply the root test:
lim sup
n→∞
np
|an | = |z| lim sup
n→∞
np
|cn | =
|z|
R
.
Note: R is called the radius of convergence of Σcnz
n.
3.40 Examples.
(a) The series Pn
nz
n has R = 0.
(b) The series Pz
n/n! has R = +∞. (In this case the ratio test is easier to apply
than the root test.)
(c) The series Pz
n has R = 1. If |z| = 1, the series diverges, since (z
n) does not
tend to 0 as n → ∞.
(d) The series Pz
n/n has R = 1. It diverges if z = 1. It converges for all other z
with |z| = 1. (The last assertion will be proved in Theorem 3.44.)
(e) The series Pz
n/n
2 has R = 1. It converges for all z with |z| = 1, by the
comparison test, since

z
n/n
2

 = 1/n
2.
SUMMATION BY PARTS
3.41 Theorem. Given two sequences (an) and (bn), put
An =
Xn
k=0
ak
if n ≥ 0; put A−1 = 0. Then, if 0 ≤ p ≤ q, we have
(3.20) X
q
n=p
anbn =
q
X−1
n=p
An(bn − bn+1) + Aqbq − Ap−1bp.
Proof.
X
q
n=p
anbn =
X
q
n=p
(An − An−1)bn =
X
q
n=p
Anbn −
q
X−1
n=p−1
Anbn+1,
and the last expression on the right is clearly equal to the right side of (3.20).SUMMATION BY PARTS 65
Formula (3.20), the so-called “partial summation formula,” is useful in the in￾vestigation of series of the form Σanbn, particularly when bn is monotonic. We
shall now give applications.
3.42 Theorem. Suppose
(a) the partial sums An of Σan form a bounded sequence;
(b) b0 ≥ b1 ≥ b2 ≥ · · · ;
(c) limn→∞ bn = 0.
Then Σanbn converges.
Proof. Choose M such that |An | ≤ M for all n. Given ε > 0, there is an integer N
such that bN ≤ ε/(2M). For N ≤ p ≤ q, we have





X
q
n=p
anbn





=






q
X−1
n=p
An(bn − bn+1) + Aqbq − Ap−1bp






≤ M






q
X−1
n=p
(bn − bn+1 + bq + bp)






= 2Mbp ≤ 2MbN ≤ ε.
Convergence now follows from the Cauchy criterion. We now that the first in￾equality in the above chain depends of course on the fact that bn − bn+1 ≥ 0.
3.43 Theorem. Suppose
(a) |c1| ≥ |c2| ≥ |c3| ≥ · · · ;
(b) c2m−1 ≥ 0, c2m ≤ 0 (m = 1, 2, 3, . . .);
(c) limn→∞ cn = 0.
Then Σcn converges.
Series for which (b) holds are called “alternating series”; the theorem was
known to Leibnitz.
Proof. Apply Theorem 3.42 with an = (−1)
n+1, bn = |cn |.
3.44 Theorem. Suppose the radius of convergence of Σcnz
n is 1, and suppose c0 ≥ c1 ≥
c2 ≥ · · · , limn→∞ cn = 0. Then Σcnz
n converges at every point on the circle |z| = 1,
except possibly at z = 1.
Proof. Put an = z
n, bn = cn. The hypotheses of Theorem 3.42 are then satisfied,
since
|An | =





Xn
n=0
zm





=




1 − z
n+1
1 − z




≤
2
|1 − z|
,
if |z| = 1 and z ̸= 1.ABSOLUTE CONVERGENCE 66
ABSOLUTE CONVERGENCE
The series Σan is said to converge absolutely if the series Σ |an | converges.
3.45 Theorem. If Σan converges absolutely, then Σan converges.
Proof. The assertion follows from the inequality





Xm
k=n
ak





≤
Xm
k=n
|ak| ,
plus the Cauchy criterion.
3.46 Remarks. For series of positive terms, absolute convergence is the same as
convergence.
If Σan converges, but Σ |an | diverges, we say that Σan converges conditionally
[[nonabsolutely]]. For instance, the series
X∞
n=1
(−1)
n
n
converges conditionally (Theorem 3.43).
The comparison test, as well as the root and ratio tests, is really a test for ab￾solute convergence and therefore cannot give any information about conditionally
convergent series. Summation by parts can sometimes be used to handle the lat￾ter. In particular, power series converge absolutely in the interior of the circle of
convergence.
We shall see that we may operate with absolutely convergent series very much
as with finite sums. We may multiply them term by term and we may change
the order in which the additions are carried out, without affecting the sum of the
series. But for conditionally convergent series, this is no longer true, and more care
has to be taken when dealing with them.
ADDITION AND MULTIPLICATION OF SERIES
3.47 Theorem. If Σan = A and Σbn = B, then Σ(an + bn) = A + B and
Σ(can) = cA for any fixed c.
Proof. Let
An =
Xn
k=0
ak, Bn =
Xn
k=0
bk.
Then
An + Bn =
Xn
k=0
(ak + bk).ADDITION AND MULTIPLICATION OF SERIES 67
Since limn→∞ An = A and limn→∞ Bn = B, we see that
lim n→∞
(An + Bn) = A + B.
The proof of the second assertion is even simpler.
Thus two convergent series may be added term by term, and the resulting se￾ries converges to the sum of the two series. The situation becomes more compli￾cated when we consider multiplication of two series. To begin with, we have to
define the product. This can be done in several ways; we shall consider the so￾called “Cauchy product.”
3.48 Definition. Given Σan and Σbn, we put
cn =
Xn
k=0
akbn−k (n = 0, 1, 2, . . .)
and call Σcn the product of the two given series.
This definition may be motivated as follows. If we take two power series
Σanz
n and Σbnz
n, multiply them term by term, and collect terms containing the
same power of z, we get
X∞
n=0
anz
n ·
X∞
n=0
bnz
n = (a0 + a1z + a2z
2 + · · ·)(b0 + b1z + b2z
2 + · · ·)
= a0b0 + (a0b1 + a1b0)z + (a0b2 + a1b1 + a2b0)z
2 + · · ·
= c0 + c1z + c2z
2 + · · · .
Setting z = 1, we arrive at the above definition.
3.49 Example. If
An =
Xn
k=0
ak, Bn =
Xn
k=0
bk,
Xn
k=0
ck,
and An → A, Bn → B, then it is not at all clear that (Cn) will converge to AB,
since we do not have Cn = AnBn. The dependence of (Cn) on (An) and (Bn) is
quite a complicated one (see the proof of Theorem 3.50). We shall now show that
the product of two convergent series may actually diverge.
The series
X∞
n=0
(−1)
n
√
n + 1
= 1 −
1
√
2
+
1
√
3
−
1
√
4
+ · · ·ADDITION AND MULTIPLICATION OF SERIES 68
converges (Theorem 3.43). We form the product of this series with itself and obtain
X∞
n=0
cn = 1 −

1
√
2
+
1
√
2

+

1
√
3
+
1
√
2
√
2
+
1
√
3

−

1
√
4
+
1
√
3
√
2
+
1
√
2
√
3
+
1
√
4

+ · · · ,
so that
cn = (−1)
n Xn
k=0
1
p
(n − k + 1)(k + 1)
.
Since
(n − k + 1)(k + 1) = n
2
+ 1
2
−
n
2
− k
2
≤
n
2
+ 1
2
.
we have
|cn | ≥
Xn
k=0
2
n + 2
=
2(n + 1)
n + 2
,
so that the condition cn → 0, which is necessary for the convergence of Σcn, is not
satisfied.
In view of the next theorem, due to Mertens, we note that we have here consid￾ered the product of two conditionally convergent series.
3.50 Theorem. Suppose
(a) P∞
n=0 an converges absolutely,
(b) P∞
n=0 an = A,
(c) P∞
n=0 bn = B,
(d) cn =
Pn
k=0 akbn−k (n = 0, 1, 2, . . .).
Then
X∞
n=0
cn = AB.
That is, the product of two convergent series converges, and to the right value, if at least
one of the two series converges absolutely.
Proof. Put
An =
Xn
k=0
ak, Bn =
Xn
k=0
bk, Cn =
Xn
k=0
ck, βn = Bn − B.REARRANGEMENTS 69
Then
Cn = a0b0 + (a0b1 + a1b0) + · · · + (a0bn + a1bn−1 + · · · + anb0)
= a0Bn + a1Bn−1 + · · · + anB0
= a0(B + βn) + a1(B + βn−1) + · · · + an(B + β0)
= AnB + a0βn + a1βn−1 + · · · + anβ0.
Put
γn = a0βn + a1βn−1 + · · · + anβ0.
We wish to show that Cn → AB. Since AnB → AB, it suffices to show that
(3.21) lim n→∞
γn = 0.
Put
α =
X∞
n=0
|an | .
[It is here that we use (a).] Let ε > 0 be given. By (c), βn → 0. Hence we can
choose N such that |βn | ≤ ε for n ≥ N, in which case
|γn | ≤ |β0an + · · · + βNan−N| + |βN+1an−N−1 + · · · + βna0|
≤ |β0an + · · · + βnan−N| + εα.
Keeping N fixed and letting n → ∞, we get
lim sup
n→∞
|γn | ≤ εα,
since ak → 0 as k → ∞. Since ε is arbitrary, (3.21) follows.
Another question which may be asked is whether the series Σcn, if convergent,
must have the sum AB. Abel showed that the answer is in the affirmative.
3.51 Theorem. If the series Σan, Σbn, Σcn converge to A, B, C, and cn = a0bn +
· · · + anb0, then C = AB.
Here no assumption is made concerning absolute convergence. We shall give a
simple proof (which depends on the continuity of power series) after Theorem 8.2.
REARRANGEMENTS
3.52 Definition. Let (kn), n = 1, 2, 3, . . . be a sequence in which every positive
integer appears once and only once (that is, (kn) is a 1-1 function from N onto N,
in the notation of Definition 2.2). Putting
a
′
n = akn
(n = 1, 2, 3, . . .),REARRANGEMENTS 70
we say that Σa′
n is a rearrangement of Σan.
If (sn), (s
′
n) are the sequences of the partial sums of Σan, Σa′
n, it is easily seen
that, in general, these two sequences consist of entirely different numbers. We
are thus lead to the problem of determining under what conditions all rearrange￾ments of a convergent series will converge and whether the sums are necessarily
the same.
3.53 Example. Consider the convergent series
(3.22) 1 −
1
2
+
1
3
−
1
4
+
1
5
−
1
6
+ · · ·
and one of its rearrangements
(3.23) 1 +
1
3
−
1
2
+
1
5
+
1
7
−
1
4
+
1
9
+
1
11 −
1
6
+ · · ·
in which two positive terms are always followed by one negative. If s is the sum
of (3.22), then
s < 1 −
1
2
+
1
3
=
5
6
.
Since
1
4k − 3
+
1
4k − 1
−
1
2k > 0
for k ≥ 1, we see that s
′
3 < s′
6 < s′
9 < · · · , where s
′
n is the nth partial sum of (3.23).
Hence
lim sup
n→∞
s
′
n > s′
3 =
5
6
,
so that (3.23) certainly does not converge to s [we leave it to the reader to verify
that (3.23) does, however, converge].
This example illustrates the following theorem, due to Riemann.
3.54 Theorem. Let Σan be a series of real numbers which converges, but not absolutely.
Suppose
−∞ ≤ α ≤ β ≤ ∞.
Then there exists a rearrangement Σa′
n with partial sums s
′
n such that
(3.24) lim inf
n→∞
s
′
n = α, lim sup
n→∞
s
′
n = β.
Proof. Let
pn =
|an | + an
2
, qn =
|an | − an
2
(n = 1, 2, 3, . . .).
Then pn − qn = an, pn + qn = |an |, pn ≥ 0, qn ≥ 0. The series Σpn, Σqn mustREARRANGEMENTS 71
both diverge, for if both were convergent, then
X(pn + qn) = X|an |
would converge, contrary to hypothesis. Since
X
N
n=1
an =
X
N
n=1
(pn − qn) = X
N
n=1
pn −
X
N
n=1
qn,
divergence of Σpn and convergence Σqn (or vice versa) implies divergence of Σan,
again contrary to hypothesis.
Now let P1, P2, P3, . . . denote the nonnegative terms of Σan, in the order in
which they occur, and let Q1, Q2, Q3, . . . be the absolute values of the negative
terms of Σan, also in their original order.
The series ΣPn, ΣQn differ from Σpn, Σqn only by zero terms, and are there￾fore divergent.
We shall construct sequences (mn), (kn) such that the series
(3.25)
P1 + · · · + Pm1 − Q1 − · · · − Qk1 + Pm1+1 + · · ·
+ Pm2 − Qk1+1 − · · · − Qk2 + · · · ,
which clearly is a rearrangement of Σan, satisfies (3.24).
Choose real-valued sequences (αn), (βn) such that αn → α, βn → β, αn <
βn, β1 > 0.
Let m1, k1 be the smallest positive integers such that
P1 + · · · + Pm1 > β1,
P1 + · · · + Pm1 − Q1 − · · · − Qk1 < α1;
let m2, k2 be the smallest positive integers such that
P1 + · · · + Pm1 − Q1 − · · · − Qk1 + Pm1+1 + · · · + Pm2 > β2,
P1 + · · · + Pm1 − Q1 − · · · − Qk1 + Pm1+1 + · · · + Pm2 − Qk1+1 − · · · − Qk2 < α2,
and continue in this way. This is possible since ΣPn and ΣQn diverge.
If xn, yn denote the partial sums of (3.25) whose last terms are Pmn − Qkn
,
then
|xn − βn | ≤ Pmn , |yn − αn | ≤ Qkn
.
Since Pn → 0 and Qn → 0 as n → ∞, we see that xn → β, yn → α.
Finally, it is clear that no number less than α or greater than β can be a subse￾quential limit of the partial sums (3.25).
3.55 Theorem. If Σan is a series of complex numbers which converges absolutely, then
every rearrangement of Σan converges, and they all converge to the same sum.EXERCISES 72
Proof. Let Σa′
n be a rearrangement, with partial sums s
′
n. Given ε > 0, there exists
an integer N such that m ≥ n ≥ N implies
(3.26) Xm
i=n
|ai
| ≤ ε.
Now choose p such that the integers 1, 2, . . . , N are all contained in the set
k1, k2, . . . , kp (we use the notation of Definition 3.52). Then if n > p, the num￾bers a1, . . . , aN will cancel in the difference sn − s
′
n, so that

sn − s
′
n

 ≤ ε, by
(3.26). Hence (s
′
n) converges to the same sum as (sn).
EXERCISES
3.1. Prove that convergence of (sn) implies convergence of (|sn |). Is the converse true?
3.2. Calculate limn→∞(
√
n2 + n − n).
3.3. If s1 =
√
2 and
sn+1 =
q
2 +
√
sn (n = 1, 2, 3, . . .),
prove that (sn) converges and that sn < 2 for n = 1, 2, 3, . . . .
3.4. Find the upper and lower limits of the sequence (sn) defined by
s1 = 0; s2m =
s2m−1
2
; s2m+1 =
1
2
+ s2m.
3.5. For any two real sequences (an), (bn), prove that
lim sup
n→∞
(an + bn) ≤ lim sup
n→∞
an + lim sup
n→∞
bn,
provided the sum on the right is not of the form ∞ − ∞.
3.6. Investigate the behavior (convergence or divergence) of Σan if
(a) an =
√
n + 1 −
√
n;
(b) an = (√
n + 1 −
√
n)/n;
(c) an = ( n√
n − 1)
n;
(d) an = 1/(1 + z
n), for complex values of z.
3.7. Prove that the convergence of Σan implies the convergence of
X∞
n=1
√
an
n
,
if an ≥ 0.
3.8. If Σan converges and if (bn) is monotonic and bounded, prove that Σanbn converges.
3.9. Find the radius of convergence of each of the following power series:
(a) Xn
3
z
n, (b) X 2
n
n!
z
n,
(c) X 2
n
n2
z
n, (d) X n
3
3n
z
n.EXERCISES 73
3.10. Suppose that the coefficients of the power series Σanz
n are integers, infinitely many of
which are distinct from zero. Prove that the radius of convergence is at most 1.
3.11. Suppose an > 0, sn = a1 + · · · + an, and Σan diverges.
(a) Prove that Pan/(1 + an) diverges.
(b) Prove that
aN+1
sN+1
+ · · · +
aN+k
sN+k
≥ 1 −
sN
sN+k
and deduce that Pan/sn diverges.
(c) Prove that
an
s
2
n
≤
1
sn−1
−
1
sn
and deduce that Pan/s
2
n converges.
(d) What can be said about
X an
1 + nan
and X an
1 + n2an
?
3.12. Suppose an > 0 and Σan converges. Put
rn =
X∞
m=n
am.
(a) Prove that
am
rm
+ · · · +
an
rn
> 1 −
rn
rm
if m < n, and deduce that Pan/rn diverges.
(b) Prove that
an √
rn
< 2(
√
rn −
√
rn+1)
and deduce that Pan/
√
rn converges.
3.13. Prove that the Cauchy product of two absolutely convergent series converges absolutely.
3.14. If (sn) is a complex sequence, define its arithmetic means σn by
σn =
s0 + s1 + · · · + sn
n + 1
(n = 0, 1, 2, . . .).
(a) If lim sn = s, prove that lim σn = s.
(b) Construct a sequence (sn) which does not converge, although lim σn = 0.
(c) Can it happen that sn > 0 for all n and that lim sup sn = ∞, although lim σn = 0?
(d) Put an = sn − sn−1 for n ≥ 1. Show that
sn − σn =
1
n + 1
Xn
k=1
kak.
Assume that lim(nan) = 0 and that (σn) converges. Prove that (sn) converges. [This
gives a converse of (a), but under the additional assumption that nan → 0.]
(e) Derive the last conclusion from a weaker hypothesis: Assume M < ∞, |nan | ≤ M for
all n, and lim σn = σ. Prove that lim sn = σ by completing the following outline:
If m < n, then
sn − σn =
m + 1
n − m
(σn − σm) + 1
n − m
Xn
i=m+1
(sn − si).EXERCISES 74
For these i,
|sn − si
| ≤
(n − i)M
i + 1
≤
(n − m − 1)M
m + 2
.
Fix ε > 0 and associate with each n the integer m that satisfies
m ≤
n − ε
1 + ε
< m + 1.
Then (m + 1)/(n − m) ≤ 1/ε and |sn − si
| < Mε. Hence
lim sup
n→∞
|sn − σ| ≤ Mε.
Since ε was arbitrary, lim sn = σ.
3.15. Definition 3.21 can be extended to the case in which the an lie in some fixed Rk. Abso￾lute convergence is defined as convergence of P|an |. Show that Theorems 3.22, 3.33, 3.25(a),
3.33, 3.34, 3.42, 3.45, 3.47, and 3.55 are true in this more general setting. (Only slight modifi￾cations are required in any of the proofs.)
3.16. Fix a positive number α. Choose x1 >
√
α, and define x2, x3, x4, . . . by the recursion
formula
xn+1 =
1
2

xn +
α
xn

.
(a) Prove that (xn) decreases monotonically and that lim xn =
√
α.
(b) Put εn = xn −
√
α and show that
εn+1 =
ε
2
n
2xn
<
ε
2
n
2
√
α
so that, setting β = 2
√
α,
εn+1 < β 
ε1
β
2n
(n = 1, 2, 3, . . .).
(c) This is a good algorithm for computing square roots, since the recursion formula is
simple and the convergence is extremely rapid. For example, if α = 3 and x1 = 2,
show that ε1/β < 1/10 and that therefore
ε5 < 4 · 10−16
, ε6 < 4 · 10−32
.
3.17. Fix α > 1. Take x1 >
√
α and define
xn+1 =
α + xn
1 + xn
= xn +
α − x
2
n
1 + xn
.
(a) Prove that x1 > x3 > x5 > · · · .
(b) Prove that x2 < x4 < x6 < · · · .
(c) Prove that lim xn =
√
α.
(d) Compare the rapidity of convergence of this process with the one described in Exer￾cise 3.16.
3.18. Replace the recursion formula of Exercise 3.16 by
xn+1 =
p − 1
p
xn +
α
p
x
−p+1
n ,
where p is a fixed positive integer, and describe the behavior of the resulting sequences (xn).EXERCISES 75
3.19. Associate to each sequence a = (αn) in which αn is 0 or 2, the real number
x(a) = X∞
n=1
αn
3n
.
Prove that the set of all x(a) is precisely the Cantor set described in Theorem 2.44
3.20. Suppose (pn) is a Cauchy sequence in a metric space X, and some subsequence (pni
)
converges to a point p ∈ X. Prove that the full sequence (pn) converges to p.
3.21. Prove the following analogue of Theorem 3.10(b): If (En) is a sequence of closed,
nonempty, and bounded sets in a complete metric space X, if En ⊃ En+1, and if
limn→∞
diam En = 0,
then T∞
n=1 En consists of exactly one point.
3.22. Suppose X is a nonempty complete metric space, and (Gn) is a sequence of dense open
subsets of X. Prove Baire’s theorem, namely, that T∞
n=1 Gn is not empty (In fact, it is dense
in X.) Hint: Find a shrinking sequence of neighborhoods En such that En ⊂ Gn, and apply
Exercise 3.21.
3.23. Suppose (pn) and (qn) are Cauchy sequences in a metric space X. Show that the se￾quence (d(pn, qn)) converges. Hint: For any m, n,
d(pn, qn) ≤ d(pn, pm) + d(pm, qm) + d(qm, qn);
it follows that
|d(pn, qn) − d(pm, qm)|
is small if m and n are large.
3.24. Let X be a metric space.
(a) Call two Cauchy sequences (pn), (qn) in X equivalent if
limn→∞
d(pn, qn) = 0.
Prove that this is an equivalence relation.
(b) Let X
∗ be the set of all equivalence classes so obtained. If P ∈ X
∗
, Q ∈ X
∗
, (pn) ∈ P,
(qn) ∈ Q, define
∆(P, Q) = limn→∞
d(pn, qn);
by Exercise 3.23, this limit exists. Show that the number ∆(P, Q) is unchanged if (pn)
and (qn) are replaced by equivalent subsequences, and hence that ∆ is a distance
function in X
∗
.
(c) Prove that the resulting metric space X
∗
is complete.
(d) For each p ∈ X, there is a Cauchy sequence all of whose terms are p; let Pp be the
element of X
∗ which contains this sequence. Prove that
∆(Pp, Pq) = d(p, q)
for all p, q ∈ X. In other words, the mapping φ defined by φ(p) = Pp is an isometry
(i.e., a distance-preserving mapping) of X into X
∗
.
(e) Prove that φ(X) is dense in X
∗ and that φ(X) = X
∗
if X is complete. By (d), we may
identify X and φ(X) and thus regard X as embedded in the complete metric space X
∗
.
We call X
∗
the completion of X.
3.25. Let X be the metric space whose points are the rational numbers, with the metric d(x, y) =
|x − y|. What is the completion of this space? (Compare Exercise 3.24).Chapter 4
CONTINUITY
The function concept and some of the related terminology were introduced in Def￾inition 2.1 and Definition 2.2. Although we shall (in later chapters) be mainly in￾terested in real and complex functions (i.e., in functions whose values are real or
complex numbers) we shall also discuss vector-valued functions (i.e., functions
with values in Rk) and functions with values in an arbitrary metric space. The
theorems we shall discuss in this general setting would not become any easier if
we restricted ourselves to real functions, for instance, and it actually simplifies
and clarifies the picture to discard unnecessary hypotheses and to state and prove
theorems in an appropriately general context.
The domains of definition of our functions will also be metric spaces, suitably
specialized in various instances.
LIMITS OF FUNCTIONS
4.1 Definition. Let X and Y be metric spaces; suppose E ⊂ X, f maps E into Y, and
p is a limit point of E. We write f(x) → q as x → p, or
(4.1) limx→p
f(x) = q
if there is a point q ∈ Y with the following property: For every ε > 0 there exists a
δ > 0 such that
(4.2) dY(f(x), q) < ε
for all points x ∈ E for which
(4.3) 0 < dX(x, p) < δ.
The symbols dX and dY refer to the distances in X and Y, respectively.
If X and/or Y are replaced by the real line, the complex plane, or by some
76LIMITS OF FUNCTIONS 77
euclidean space Rk, the distances dX, dY are of course replaced by absolute values,
or by norms of differences (see Example 2.16).
It should be noted that p ∈ X, but that p need not be a point of E in the above
definition. Moreover, even if p ∈ E, we may very well have f(p) ̸= limx→p f(x).
We can recast this definition in terms of limits of sequences:
4.2 Theorem. Let X, Y, E, f, and p be as in Definition 4.1. Then
(4.4) limx→p
f(x) = q
if and only if
(4.5) lim n→∞
f(pn) = q
for every sequence (pn) in E such that
(4.6) pn ̸= p, lim n→∞
pn = p.
Proof. Suppose (4.4) holds. Choose (pn) in E satisfying (4.6). Let ε > 0 be given.
Then there exists δ > 0 such that dY(f(x), q) < ε if x ∈ E and 0 < dX(x, p) < δ.
Also, there exists N such that n > N implies 0 < dX(pn, p) < δ. Thus, for n > N,
we have dY(f(pn), q) < ε, which shows that (4.5) holds.
Conversely, suppose (4.4) is false. Then there exists some ε > 0 such that for
every δ > 0 there exists a point x ∈ E (depending on δ), for which dY(f(x), q) ≥ ε
but 0 < dX(x, p) < δ. Taking δn = 1/n (n = 1, 2, 3, . . .), we thus find a sequence
in E satisfying (4.6) for which (4.5) is false.
Corollary. If f has a limit at p, this limit is unique.
This follows from Theorems 3.2(b) and 4.2
4.3 Definition. Suppose we have two complex functions, f and g, both defined
on E. By f + g we mean the function which assigns to each point x of E the num￾ber f(x) + g(x). Similarly we define the difference f − g, the product fg, and the
quotient f/g of two functions, with the understanding that the quotient is defined
only at those points x of E at which g(x) ̸= 0. If f assigns to each point x of E the
same number c, then f is said to be a constant function, or simply a constant, and
we write f = c. If f and g are real functions, and if f(x) ≥ g(x) for every x ∈ E, we
shall sometimes write f ≥ g for brevity.
Similarly, if f and g map E into Rk, we define f + g and f · g by
(f + g)(x) = f(x) + g(x), (f · g)(x) = f(x) · g(x);
and if λ is a real number, (λf)(x) = λf(x).CONTINUOUS FUNCTIONS 78
4.4 Theorem. Suppose E ⊂ X, a metric space, p is a limit point of E, f and g are complex
functions on E, and
limx→p
f(x) = A, limx→p
g(x) = B.
Then
(a) limx→p
(f + g)(x) = A + B;
(b) limx→p
(fg)(x) = AB;
(c) limx→p

f
g

(x) = A
B
, if B ̸= 0.
Proof. In view of Theorem 4.2, these assertions follow immediately from the anal￾ogous properties of sequences (Theorem 3.3).
Remark. If f and g map E into Rk, then (a) remains true, and (b) becomes
(b’) limx→p(f · g)(x) = A · B.
(Compare Theorem 3.4.)
CONTINUOUS FUNCTIONS
4.5 Definition. Suppose X and Y are metric spaces, E ⊂ X, p ∈ E, and f maps E
into Y. Then f is said to be continuous at p if for every ε > 0 there exists a δ > 0
such that
dY(f(x), f(p)) < ε
for all points x ∈ E for which dX(x, p) < δ.
If f is continuous at every point of E, then f is said to be continuous on E.
It should be noted that f has to be defined at the point p in order to be contin￾uous at p. (Compare this with the remark following Definition 4.1.)
If p is an isolated point of E, then our definition implies that every function
f which has E as its domain of definition is continuous at p. For, no matter
which ε > 0 we choose, we can pick δ > 0 so that the only point x ∈ E for which
dX(x, p) < δ is x = p; then
dY(f(x), f(p)) = 0 < ε.
4.6 Theorem. In the situation given in Definition 4.5, assume also that p is a limit point
of E. Then f is continuous at p if and only if limx→p f(x) = f(p).
Proof. This is clear if we compare Definitions 4.1 and 4.5.
We now turn to compositions of functions. A brief statement of the following
theorem is that a continuous function of a continuous function is continuous.CONTINUOUS FUNCTIONS 79
4.7 Theorem. Suppose X, Y, Z are metric spaces, E ⊂ X, f maps E into Y, g maps the
range of f, f(E), into Z, and h is the mapping of E into Z defined by
h(x) = g(f(x)) (x ∈ E).
If f is continuous at a point p ∈ E and if g is continuous at the point f(p), then h is
continuous at p.
This function h is called the composition or the composite of f and g. The notation
h = g ◦ f
is frequently used in this context.
Proof. Let ε > 0 be given. Since g is continuous at f(p), there exists η > 0 such that
dZ(g(y), g(f(p))) < ε if dY(y, f(p)) < η and y ∈ f(E).
Since f is continuous at p, there exists δ > 0 such that
dY(f(x), f(p)) < η if dX(x, p) < δ and x ∈ E.
It follows that
dZ(h(x), h(p)) = dZ(g(f(x)), g(f(p))) < ε
if dX(x, p) < δ and x ∈ E. Thus h is continuous at p.
4.8 Theorem. A mapping f of a metric space X into a metric space Y is continuous on X
if and only if f
−1(V) is open in X for every open set V in Y.
(Inverse images are defined in Definition 2.2.) This is a very useful characteri￾zation of continuity.
Proof. Suppose f is continuous on X and V is an open set in Y. We have to show
that every point of f
−1(V) is an interior point of f
−1(V). So, suppose p ∈ X and
f(p) ∈ V. Since V is open, there exists ε > 0 such that y ∈ V if dY(f(p), y) < ε;
and since f is continuous at p, there exists δ > 0 such that dY(f(x), f(p)) < ε if
dX(x, p) < δ. Thus x ∈ f
−1(V) as soon as dX(x, p) < δ.
Conversely, suppose f
−1(V) is open in X for every open set V in Y. Fix p ∈ X
and ε > 0, let V be the set of all y ∈ Y such that dY(y, f(p)) < ε. Then V is open;
hence f
−1(V) is open; hence there exists δ > 0 such that x ∈ f
−1(V) as soon as
dX(p, x) < δ. But if x ∈ f
−1(V), then f(x) ∈ V, so that dY(f(x), f(p)) < ε.
This completes the proof.
Corollary. A mapping f of a metric space X into a metric space Y is continuous if and
only if f
−1(C) is closed in X for every closed set C in Y.CONTINUOUS FUNCTIONS 80
This follows from the theorem, since a set is closed if and only if its complement
is open, and since f
−1(E
c
) = [f
−1(E)]c
for every E ⊂ Y.
We now turn to complex-valued and vector-valued functions, and to functions
defined on subsets of Rk.
4.9 Theorem. Let f and g be complex continuous functions on a metric space X. Then
f + g, fg, and f/g are continuous on X.
In the last case, we must of course assume that g(x) ̸= 0, for all x ∈ X.
Proof. At isolated points of X there is nothing to prove. At limit points, the state￾ment follows from Theorems 4.4 and 4.6.
4.10 Theorem.
(a) Let f1, . . . , fk be real functions on a metric space X, and let f be the mapping of X
into Rk defined by
(4.7) f(x) = (f1(x), . . . , fk(x)) (x ∈ X);
then f is continuous if and only if each of the functions f1, . . . , fk is continuous.
(b) If f and g are continuous mappings of X into Rk, then f + g and f· g are continuous
on X.
The functions f1, . . . , fk are called the components of f. Note that f + g is a map￾ping into Rk, whereas f · g is a real function on X.
Proof. Part (a) follows from the inequalities
|fj
(x) − fj
(y)| ≤ |f(x) − f(y)| =
X
k
i=1
|fj
(x) − fj
(y)|
2
1/2
,
for j = 1, . . . , k. Part (b) follows from (a) and Theorem 4.9
4.11 Examples. If x1, . . . , xk are the coordinates of the point x ∈ Rk, the functions
ϕi defined by
(4.8) ϕi
(x) = xi
(x ∈ Rk
)
are continuous on Rk, since the inequality
|ϕi
(x) − ϕi
(y)| ≤ |x − y|
shows that we may take δ = ε in Definition 4.5. The functions ϕi are sometimes
called the coordinate functions.
Repeated application of Theorem 4.9 then shows that every monomial
(4.9) x
n1
1
x
n2
2
· · · x
nk
kCONTINUITY AND COMPACTNESS 81
where n1, . . . , nk are nonnegative integers, is continuous on Rk. The same is true
of constant multiples of (4.9), since constants are evidently continuous. It follows
that every polynomial P, given by
(4.10) P(x) = Xcn1...nk
x
n1
1
· · · x
nk
k
(x ∈ Rk
),
is continuous on Rk. Here the coefficients cn1...nk
are complex numbers, n1, . . . , nk
are nonnegative integers, and the sum in (4.10) has finitely many terms.
Furthermore, every rational function in x1, . . . , xk, that is, every quotient of two
polynomials of the form (4.10), is continuous on Rk wherever the denominator is
different from zero.
From the triangle inequality one sees easily that
(4.11)


|x| − |y|

 ≤ |x − y| (x, y ∈ Rk
).
Hence the mapping x → |x| is a continuous real function on Rk.
If now f is a continuous mapping from a metric space X into Rk, and if ϕ
is defined on X by setting ϕ(p) = |f(p)|, it follows, by Theorem 4.7, that ϕ is a
continuous real function on X.
4.12 Remark. We defined the notion of continuity for functions defined on a subset
E of a metric space X. However, the complement of E in X plays no role whatever
in this definition (note that the situation was somewhat different for limits of func￾tions). Accordingly, we lose nothing of interest by discarding the complement of
the domain of f. This means that we may just as well talk only about continuous
mappings of one metric space into another, rather than of mappings of subsets.
This simplifies statements and proofs of some theorems. We have already made
use of this principle in Theorems 4.8 to 4.10, and will continue to do so in the fol￾lowing section on compactness.
CONTINUITY AND COMPACTNESS
4.13 Definition. A mapping f of a set E into Rk is said to be bounded if there is a
real number M such that |f(x)| ≤ M for all x ∈ E.
4.14 Theorem. Suppose f is a continuous mapping of a compact metric space X into a
metric space Y. Then f(X) is compact.
Proof. Let {Vα} be an open cover of f(X). Since f is continuous, Theorem 4.8 shows
that each of the sets f
−1(Vα) is open. Since X is compact, there are finitely many
indices, say α1, . . . , αn, such that
(4.12) X ⊂ f
−1
(Vα1
) ∪ · · · ∪ f
−1
(Vαn ).CONTINUITY AND COMPACTNESS 82
Since f(f
−1(E)) ⊂ E for every E ⊂ Y, (4.12) implies that
(4.13) f(X) ⊂ Vα1 ∪ · · · ∪ Vαn .
This completes the proof.
Note: We have used the relation f(f
−1(E)) ⊂ E, valid for E ⊂ Y. If E ⊂ X, then
f
−1(f(E)) ⊃ E; equality need not hold in either case.
We shall now deduce some consequences of Theorem 4.14.
4.15 Theorem. If f is a continuous mapping of a compact metric space X into Rk, then
f(X) is closed and bounded. Thus, f is bounded.
This follows from Theorem 2.41. The result is particularly important when f is
real:
4.16 Theorem. Suppose f is a continuous real function on a compact metric space X, and
(4.14) M = sup
p∈X
f(p), m = inf
p∈X
f(p).
Then there exist points p, q ∈ X such that f(p) = M and f(q) = m.
The notation in (4.14) means that M is the least upper bound of the set of all
numbers f(p), where p ranges over X, and that m is the greatest lower bound of
this set of numbers.
The conclusion may also be stated as follows: There exist points p and q in X such
that f(q) ≤ f(x) ≤ f(p) for all x ∈ X; that is, f attains its maximum (at p) and its
minimum (at q).
Proof. By Theorem 4.15, f(X) is a closed and bounded set of real numbers; hence
f(X) contains
M = sup f(X) and m = inf f(X),
by Theorem 2.28.
4.17 Theorem. Suppose f is a continuous 1-1 mapping of a compact metric space X onto
a metric space Y. Then the inverse mapping f
−1 defined on Y by
f
−1
(f(x)) = x (x ∈ X)
is a continuous mapping of Y onto X.
Proof. Applying Theorem 4.8 to f
−1 in place of f, we see that it suffices to prove
that f(V) is an open set in Y for every open set V in X. Fix such a set V.
The complement V
c of V is closed in X, hence compact (Theorem 2.35); hence
f(V
c
) is a compact subset of Y (Theorem 4.14) and so is closed in Y (Theorem 2.34).
Since f is one-to-one and onto, f(V) is the complement of f(V
c
). Hence f(V) is
open.CONTINUITY AND COMPACTNESS 83
4.18 Definition. Let f be a mapping of a metric space X into a metric space Y. We
say that f is uniformly continuous on X if for every ε > 0 there exists δ > 0 such that
(4.15) dY(f(p), f(q)) < ε
for all p and q in X for which dX(p, q) < δ.
Let us consider the differences between the concepts of continuity and of uni￾form continuity. First, uniform continuity is a property of a function on a set,
whereas continuity can be defined at a single point. To ask whether a given func￾tion is uniformly continuous at a certain point is meaningless. Second, if f is con￾tinuous on X, then it is possible to find, for each ε > 0 and for each point p of X, a
number δ > 0 having the property specified in Definition 4.5. This δ depends on ε
and on p. If f is, however, uniformly continuous on X, then it is possible, for each
ε > 0, to find one number δ > 0 which will do for all points p of X.
Evidently, every uniformly continuous function is continuous. That the two
concepts are equivalent on compact sets follows from the next theorem.
4.19 Theorem. Let f be a continuous mapping of a compact metric space X into a metric
space Y. Then f is uniformly continuous on X.
Proof. Let ε > 0 be given. Since f is continuous, we can associate to each point
p ∈ X a positive number ϕ(p) such that
(4.16) q ∈ X, dX(p, q) < ϕ(p) implies dY(f(p), f(q)) <
ε
2
.
Let J(p) be the set of all q ∈ X for which
(4.17) dX(p, q) <
1
2
ϕ(p).
Since p ∈ J(p), the collection of all sets J(p) is an open cover of X; since X is com￾pact, there is a finite set of points p1, . . . , pn in X, such that
(4.18) X ⊂ J(p1) ∪ · · · ∪ J(pn).
We put
(4.19) δ =
1
2
min{ϕ(p1), . . . , ϕ(pn)}.
Then δ > 0. (This is one point where the finiteness of the covering, inherent in
the definition of compactness, is essential. The minimum of a finite set of positive
numbers is positive, whereas the inf of an infinite set of positive numbers may very
well be 0.)
Now let q and p be points of X such that dX(p, q) < δ. By (4.18), there is anCONTINUITY AND COMPACTNESS 84
integer m, 1 ≤ m ≤ n, such that p ∈ J(pm); hence
(4.20) dX(p, pm) <
1
2
ϕ(pm),
and we also have
dX(q, pm) ≤ dX(p, q) + dX(p, pm) < δ +
1
2
ϕ(pm) ≤ ϕ(pm).
Finally, (4.16) shows that therefore
dY(f(p), f(q)) ≤ dY(f(p), f(pm)) + dY(f(q), f(pm)) < ε.
This completes the proof.
An alternative proof is sketched in Exercise 4.10.
We now proceed to show that compactness is essential in the hypotheses of
Theorems 4.14, 4.15, 4.16, and 4.19.
4.20 Theorem. Let E be a noncompact set in R1. Then
(a) there exists a continuous function on E which is not bounded;
(b) there exists a continuous and bounded function on E which has no maximum.
If, in addition, E is bounded, then
(c) there exists a continuous function on E which is not uniformly continuous.
Proof. Suppose first that E is bounded, so that there exists a limit point x0 of E
which is not a point of E. Consider
(4.21) f(x) = 1
x − x0
(x ∈ E).
This is continuous on E (Theorem 4.9), but evidently unbounded. To see that (4.21)
is not uniformly continuous, let ε > 0 and δ > 0 be arbitrary, and choose a point
x ∈ E such that |x − x0| < δ. Taking t close enough to x0, we can then make the
difference |f(t) − f(x)| greater than ε, although |t − x| < δ. Since this is true for
every δ > 0, f is not uniformly continuous on E.
The function g given by
(4.22) g(x) = 1
1 + (x − x0)
2
(x ∈ E)
is continuous on E and is bounded, since 0 < g(x) < 1. It is clear that
sup
x∈E
g(x) = 1,
whereas g(x) < 1 for all x ∈ E. Thus g has no maximum on E.CONTINUITY AND CONNECTEDNESS 85
Having proved the theorem for bounded sets E, let us now suppose that E is
unbounded. Then f(x) = x establishes (a), whereas
(4.23) h(x) = x
2
1 + x
2
(x ∈ E)
establishes (b), since
sup
x∈E
h(x) = 1
and h(x) < 1 for all x ∈ E.
Assertion (c) would be false if boundedness were omitted from the hypotheses.
For, let E be the set of all integers. Then every function defined on E is uniformly
continuous on E. To see this, we need merely take δ < 1 in Definition 4.18.
We conclude this section by showing that compactness is also essential in The￾orem 4.17.
4.21 Example. Let X be the half-open interval [0, 2π) on the real line, and let f be
the mapping of X onto the circle Y consisting of all points whose distance from the
origin is 1, given by
(4.24) f(t) = (cos t, sin t) (0 ≤ t < 2π).
The continuity of the trigonometric functions cosine and sine, as well as their pe￾riodicity properties, will be established in Chap. 8. These results show that f is a
continuous 1-1 mapping of X onto Y.
However, the inverse mapping (which exists, since f is one-to-one and onto)
fails to be continuous at the point (1, 0) = f(0). Of course, X is not compact in this
example. (It may be of interest to observe that f
−1 fails to be continuous in spite of
the fact that Y is compact!)
CONTINUITY AND CONNECTEDNESS
4.22 Theorem. If f is a continuous mapping of a metric space X into a metric space Y,
and if E is a connected subset of X, then f(E) is connected.
Proof. Assume, on the contrary, that f(E) = A ∪ B, where A and B are nonempty
separated subsets of Y. Put G = E ∩ f
−1(A), H = E ∩ f
−1(B).
Then E = G ∪ H, and neither G nor H is empty.
Since A ⊂ A (the closure of A), we have G ⊂ f
−1(A); the latter set is closed,
since f is continuous; hence G ⊂ f
−1(A). It follows that f(G) ⊂ A. Since f(H) = B
and A ∩ B is empty, we conclude that G ∩ H is empty.
The same argument shows that G ∩ H is empty. Thus G and H are separated.
This is impossible if E is connected.DISCONTINUITIES 86
4.23 Theorem. Let f be a continuous real function on the interval [a, b]. If f(a) < f(b)
and if c is a number such that f(a) < c < f(b), then there exists a point x ∈ (a, b) such
that f(x) = c
A similar result holds, of course, if f(a) > f(b). Roughly speaking, the theorem
says that a continuous real function assumes all intermediate values on an interval.
Proof. By Theorem 2.47, [a, b] is connected; hence Theorem 4.22 shows that f([a, b])
is a connected subset of R1, and the assertion follows if we appeal once more to
Theorem 2.47.
4.24 Remark. At first glance, it might seem that Theorem 4.23 has a converse.
That is, one might think that if for any two points x1 < x2 and for any number
c between f(x1) and f(x2) there is a point x in (x1, x2) such that f(x) = c, then f
must be continuous.
That this is not so may be concluded from Example 4.27(d).
DISCONTINUITIES
If x is a point in the domain of definition of the function f at which f is not con￾tinuous, we say that f is discontinuous at x, or that f has a discontinuity at x. If f is
defined on an interval or on a segment, it is customary to divide discontinuities
into two types. Before giving this classification, we have to define the right-hand
and the left-hand limits of f at x, which we denote by f(x+) and f(x−), respectively.
4.25 Definition. Let f be defined on (a, b). Consider any point x such that
a ≤ x < b. We write
f(x+) = q
if f(tn) → q as n → ∞, for all sequences (tn) in (x, b) such that tn → x. To obtain
the definition of f(x−), for a < x ≤ b, we restrict ourselves to sequences (tn) in
(a, x).
It is clear that for any point x of (a, b), limt→x f(t) exists if and only if
f(x+) = f(x−) = lim
t→x
f(t).
4.26 Definition. Let f be defined on (a, b). If f is discontinuous at a point x, and
if f(x+) and f(x−) exist, then f is said to have a discontinuity of the first kind, or
a simple discontinuity, at x. Otherwise the discontinuity is said to be of the second
kind.
There are two ways in which a function can have a simple discontinuity:
either f(x+) ̸= f(x−) [in which case the value f(x) is immaterial], or f(x+) =
f(x−) ̸= f(x).
4.27 Example.MONOTONIC FUNCTIONS 87
(a) Define
f(x) = 
1 (x rational),
0 (x irrational).
Then f has a discontinuity of the second kind at every point x since neither
f(x+) nor f(x−) exists.
(b) Define
f(x) = 
x (x rational),
0 (x irrational).
Then f is continuous at x = 0 and has a discontinuity of the second kind at
every other point.
(c) Define
f(x) =



x + 2 (−3 < x < −2),
−x − 2 (−2 ≤ x < 0),
x + 2 (0 ≤ x < 1).
Then f has a simple discontinuity at x = 0 and is continuous at every other
point of (−3, 1).
(d) Define
f(x) = 
sin 1
x
(x ̸= 0),
0 (x = 0).
Since neither f(0+) nor f(0−) exists, f has a discontinuity of the second kind
at x = 0. We have not yet shown that sin x is a continuous function. If we
assume this result for the moment, Theorem 4.7 implies that f is continuous
at every point x ̸= 0.
MONOTONIC FUNCTIONS
We shall now study those functions which never decrease (or never increase) on a
given segment.
4.28 Definition. Let f be real on (a, b). Then f is said to be monotonically increasing
on (a, b) if a < x < y < b implies f(x) ≤ f(y). If the last inequality is reversed, we
obtain the definition of a monotonically decreasing function. The class of monotonic
functions consists of both the increasing and the decreasing functions.
4.29 Theorem. Let f be monotonically increasing on (a, b). Then f(x+) and f(x−) exist
at every point of x of (a, b). More precisely,
(4.25) sup
a<t<x
f(t) = f(x−) ≤ f(x) ≤ f(x+) = inf
x<t<b
f(t).MONOTONIC FUNCTIONS 88
Furthermore, if a < x < y < b, then
(4.26) f(x+) ≤ f(y−).
Analogous results evidently hold for monotonically decreasing functions.
Proof. By hypothesis, the set of numbers f(t), where a < t < x, is bounded above
by the number f(x), and therefore has a least upper bound which we shall denote
by A. Evidently A ≤ f(x). We have to show that A = f(x−).
Let ε > 0 be given. It follows from the definition of A as a least upper bound
that there exists δ > 0 such that a < x − δ < x and
(4.27) A − ε < f(x − δ) ≤ A.
Since f is monotonic, we have
(4.28) f(x − δ) ≤ f(t) ≤ A (x − δ < t < x).
Combining (4.27) and (4.28), we see that
|f(t) − A| < ε (x − δ < t < x).
Hence f(x−) = A.
The second half of (4.25) is proved in precisely the same way.
Next, if a < x < y < b, we see from (4.25) that
(4.29) f(x+) = inf
x<t<b
f(t) = inf
x<t<y
f(t).
The last equality is obtained by applying (4.25) to (a, y) in place of (a, b). Similarly,
(4.30) f(y−) = sup
a<t<y
f(t) = sup
x<t<y
f(t).
Comparison of (4.29) and (4.30) gives (4.26).
Corollary. Monotonic functions have no discontinuities of the second kind.
This corollary implies that every monotonic function is discontinuous at a count￾able set of points at most. Instead of appealing to the general theorem whose proof
is sketched in Exercise 4.17, we give here a simple proof which is applicable to
monotonic functions.
4.30 Theorem. Let f be monotonic on (a, b). Then the set of points of (a, b) at which f is
discontinuous is at most countable.
Proof. Suppose, for the sake of definiteness, that f is increasing, and let E be the set
of points at which f is discontinuous.INFINITE LIMITS AND LIMITS AT INFINITY 89
With every point x of E we associate a rational number r(x) such that
f(x−) < r(x) < f(x+).
Since x1 < x2 implies f(x1+) ≤ f(x2−), we see that r(x1) ̸= r(x2) if x1 ̸= x2.
We have thus established a 1-1 correspondence between the set E and a subset
of the set of rational numbers. The latter, as we know, is countable.
4.31 Remark. It should be noted that the discontinuities of a monotonic function
need not be isolated. In fact, given any countable subset E of (a, b), which may
even be dense, we can construct a function f, monotonic on (a, b), discontinuous
at every point of E, and at no other point of (a, b).
To show this, let the points of E be arranged in a sequence (xn), n = 1, 2, 3, . . . .
Let (cn) be a sequence of positive numbers such that Pcn converges. Define
(4.31) f(x) = X
xn<x
cn (a < x < b).
The summation is to be understood as follows: Sum over those indices n for
which xn < x. If there are no points xn to the left of x, the sum is empty; following
the usual convention, we define it to be zero. Since (4.31) converges absolutely, the
order in which the terms are arranged is immaterial.
We leave the verification of the following properties f to the reader:
(a) f is monotonically increasing on (a, b);
(b) f is discontinuous at every point of E; in fact,
f(xn+) − f(xn−) = cn.
(c) f is continuous at every other point of (a, b).
Moreover, it is not hard to see that f(x−) = f(x) at all points of (a, b). If a function
satisfies this condition, we say that f is continuous from the left. If the summation in
(4.31) were taken over all indices n for which xn ≤ x, we would have f(x+) = f(x)
at every point of (a, b); that is, f would be continuous from the right.
Functions of this sort can also be defined by another method; for an example
we refer to Theorem 6.16.
INFINITE LIMITS AND LIMITS AT INFINITY
To enable us to operate in the extended real number system, we shall now enlarge
the scope of Definition 4.1 by reformulating it in terms of neighborhoods.
For any real number x, we have already defined a neighborhood of x to be any
segment (x − δ, x + δ).EXERCISES 90
4.32 Definition. For any real c, the set of real numbers x such that x > c is called a
neighborhood of +∞ and is written (c, +∞). Similarly, the set (−∞, c) is a neigh￾borhood of −∞.
4.33 Definition. Let f be a real function defined on E ⊂ R. We say that
f(t) → A as t → x,
where A and x are in the extended real number system, if for every neighborhood
U of A there is a neighborhood V of x such that V ∩ E is not empty, and such that
f(t) ∈ U for all t ∈ V ∩ E, t ̸= x.
A moment’s consideration will show that this coincides with Definition 4.1
when A and x are real.
The analogue of Theorem 4.4 is still true, and the proof offers nothing new. We
state it, for the sake of completeness.
4.34 Theorem. Let f and g be defined on E ⊂ R. Suppose
f(t) → A, g(t) → B as t → x.
Then
(a) f(t) → A′
implies A′ = A,
(b) (f + g)(t) → A + B,
(c) (fg)(t) → AB,
(d) (f/g)(t) → A/B,
provided the right members of (b), (c), and (d) are defined.
Note that ∞ − ∞, 0 · ∞, ∞/∞, and A/0 are not defined (see 1.23).
EXERCISES
4.1. Suppose f is a real function defined on R1 which satisfies
lim
h→0
[f(x + h) − f(x − h)] = 0
for every x ∈ R1
. Does this imply that f is continuous?
4.2. If f is a continuous mapping of a metric space X into a metric space Y, prove that
f(E) ⊂ f(E)
for every set E ⊂ X. (E denotes the closure of E.) Show, by an example, that f(E) can be a
proper subset of f(E).
4.3. Let f be a continuous real function on a metric space X. Let Z(f) (the zero set of f) be the
set of all p ∈ X at which f(p) = 0. Prove that Z(f) is closed.
4.4. Let f and g be continuous mappings of a metric space X into a metric space Y, and let E
be a dense subset of X. Prove that f(E) is dense in f(X). If g(p) = f(p) for all p ∈ E, prove thatEXERCISES 91
g(p) = f(p) for all p ∈ X (In other words, a continuous function is determined by its values
on a dense subset of its domain.)
4.5. If f is a real continuous function defined on a closed set E ⊂ R1
, prove that there exist
continuous real functions on R1
such that g(x) = f(x) for all x ∈ E. (Such functions g are
called continuous extensions of f from E to R1
.) Show that the result becomes false if the world
“closed” is omitted. Extend the result to vector-valued functions. Hint: Let the graph of g
be a straight line on each of the segments which constitute the complement of E (compare
Exercise 2.29). The result remains true if R1
is replaced by any metric space, but the proof is
not so simple.
4.6. If f is defined on E, the graph of f is the set of points (x, f(x)), for x ∈ E. In particular, if E
is a set of real numbers and f is real-valued, the graph of f is a subset of the plane.
Suppose E is compact and prove that f is continuous on E if and only if its graph is
compact.
4.7. If E ⊂ X and if f is a function defined on X, the restriction of f to E is the function g
whose domain of definition is E, such that g(p) = f(p) for p ∈ E. Define f and g on R2 by:
f(0, 0) = g(0, 0) = 0, f(x, y) = xy2/(x
2 + y
4
), g(x, y) = xy2/(x
2 + y
6
) if (x, y) ̸= (0, 0). Prove
that f is bounded on R2
, that g is unbounded in every neighborhood of (0, 0), and that f is
not continuous at (0, 0); nevertheless, the restrictions of both f and g to every straight line in
R2 are continuous!
4.8. Let f be a real uniformly continuous function on the bounded set E in R1
. Prove that f is
bounded on E. Show that the conclusion is false if the boundedness of E is omitted from the
hypothesis.
4.9. Show that the requirement in the definition of uniform continuity can be rephrased as fol￾lows, in terms of diameters of sets: To every ε > 0, there exists a δ > 0 such that diam f(E) < ε
for all E ⊂ X with diam E < δ.
4.10. Complete the details of the following alternative proof of Theorem 4.19: If f is not
uniformly continuous, then for some ε > 0 there are sequences (pn), (qn) in X such that
dX(pn, qn) → 0 but dY(f(pn), f(qn)) > ε. Use Theorem 2.37 to obtain a contradiction.
4.11. Suppose f is a uniformly continuous mapping of a metric space X into a metric space Y
and prove that (f(xn)) is a Cauchy sequence in Y for every Cauchy sequence (xn) in X. Use
this result to give an alternative proof of the theorem stated in Exercise 4.13.
4.12. A uniformly continuous function of a uniformly continuous function is uniformly con￾tinuous. State this more precisely and prove it.
4.13. Let E be a dense subset of a metric space X, and let f be a uniformly continuous real
function defined on E. Prove that f has a continuous extension from E to X (see Exercise 4.5
for terminology). (Uniqueness follows from Exercise 4.4.) Hint: For each p ∈ X and each
positive integer n, let Vn(p) be the set of all q ∈ E with d(p, q) < 1/n. Use Exercise 4.9 to
show that the intersection of the closures of the sets f(V1(p)), f(V2(p)), . . . consists of a single
point, say g(p), of R1
. Prove that the function g so defined on X is the desired extension of f.
Could the range space R1 be replaced by Rk? By any compact metric space? By any
complete metric space? By any metric space?
4.14. Let I = [0, 1] be the closed unit interval. Suppose f is a continuous mapping of I into I.
Prove that f(x) = x for at least one x ∈ I.
4.15. Call a mapping of X into Y open if f(V) is an open set in Y whenever V is an open set in
X. Prove that every continuous open mapping of R1
into R1
is monotonic.
4.16. Let [x] denote the largest integer contained in x, that is, [x] is the integer such that x − 1 <
[x] ≤ x, and let (x) = x − [x] denote the fractional part of x. What discontinuities do the
functions [x] and (x) have?EXERCISES 92
4.17. Let f be a real function defined on (a, b). Prove that the set of points at which f has a
simple discontinuity is at most countable. Hint: Let E be the set on which f(x−) < f(x+).
With each point x of E, associate a triple (p, q, r) of rational numbers such that
(a) f(x−) < p < f(x+),
(b) a < q < t < x implies f(t) < p,
(c) x < t < r < b implies f(t) > p.
The set of all such triples is countable. Show that each triple is associated with at most one
point of E. Deal similarly with the other possible types of simple discontinuities.
4.18. Every rational x can be written in the form x = m/n, where n > 0, and m and n are
integers without any common divisors. When x = 0, we take n = 1. Consider the function f
defined on R1 by
f(x) =



0 (x irrational),
1
n

x =
m
n

.
Prove that f is continuous at every irrational point, and that f has a simple discontinuity at
every rational point.
4.19. Suppose f is a real function with domain R1 which has the intermediate value property:
If f(a) < c < f(b), then f(x) = c for some x between a and b. Suppose also, for every rational
r, that the set of all x with f(x) = r is closed. Prove that f is continuous.
Hint: If xn → x0 but f(xn) > r > f(x0) for some r and all n, then f(tn) = r for some tn
between x0 and xn; thus tn → x0. Find a contradiction. (N.J. Fine, Ameri. Math. Monthly,
vol. 73, 1966, p.782 [GF66]).
4.20. If E is a nonempty subset of a metric space X, define the distance from x ∈ X to E by
ρE(x) = inf
z∈E
d(x, z).
(a) Prove that ρE(x) = 0 if and only if x ∈ E.
(b) Prove that ρE is a uniformly continuous function on X by showing that
|ρE(x) − ρE(y)| ≤ d(x, y)
for all x ∈ X, y ∈ X.
Hint: ρE(x) ≤ d(x, z) ≤ d(x, y) + d(y, z), so that
ρE(x) ≤ d(x, y) + ρE(y).
4.21. Suppose K and F are disjoint sets in a metric space X, K is compact, F is closed. Prove
that there exists δ > 0 such that d(p, q) > δ if p ∈ K, q ∈ F. Hint: pF is a continuous positive
function on K.
Show that the conclusion may fail for two disjoint closed sets if neither is compact.
4.22. Let A and B be disjoint nonempty closed sets in a metric space X, and define
f(p) = ρA(p)
ρA(p) + ρB(p)
(p ∈ X).
Show that f is a continuous function on X whose range lies in [0, 1], that f(p) = 0 precisely on
A and f(p) = 1 precisely on B. This establishes a converse of Exercise 4.3: Every closed set
A ⊂ X is Z(f) for some continuous real f on X. Setting
V = f
−1
([0, 1/2)), W = f
−1
((1/2, 1]),
show that V and W are open and disjoint, and that A ⊂ V, B ⊂ W. (Thus pairs of disjoint
closed sets in metric spaces can be covered by pairs of disjoint open sets. This property of
metric spaces is called normality.)EXERCISES 93
4.23. A real-valued function f defined in (a, b) is said to be convex if
f(λx + (1 − λ)y) ≤ λf(x) + (1 − λ)f(y)
whenever a < x < b, a < y < b, and 0 < λ < 1. Prove that every convex function is
continuous. Prove that every increasing convex function of a convex function is convex. (For
example, if f is convex, so is e
f
.)
If f is convex in (a, b) and if a < s < t < u < b, show that
f(t) − f(s)
t − s
≤
f(u) − f(s)
u − s
≤
f(u) − f(t)
u − t
.
4.24. Assume that f is a continuous real function defined in (a, b) such that
f

x + y
2

≤
f(x) + f(y)
2
for all x, y ∈ (a, b). Prove that f is convex.
4.25. If A ⊂ Rk and B ⊂ Rk, define A + B to be the set of all sums x + y with x ∈ A, y ∈ B.
(a) If K is compact and C is closed in Rk, prove that K + C is closed.
Hint: Take z ∈/ K + C, put F = z − C, the set of all z − y with y ∈ C. Then K and
F are disjoint. Choose δ as in Exercise 4.21. Show that the open ball with center z and
radius δ does not intersect K + C.
(b) Let α be an irrational real number. Let C1 be the set of all integers, let C2 be the set of
all nα with n ∈ C1. Show that C1 and C2 are closed subsets of R1 whose sum C1 + C2
is not closed, by showing that C1 + C2 is a countable dense subset of R1
.
4.26. Suppose X, Y, Z are metric spaces, and Y is compact. Let f map X into Y, let g be a
continuous one-to-one mapping of Y into Z, and put h(x) = g(f(x)) for x ∈ X. Prove that f
is uniformly continuous if h is uniformly continuous. Hint: g
−1 has compact domain g(Y),
and f(x) = g
−1
(h(x)).
Prove also that f is continuous if h is continuous. Show (by modifying Example 4.21,
or by finding a different example) that the compactness of Y cannot be omitted from the
hypotheses, even when X and Z are compact.Chapter 5
DIFFERENTIATION
In this chapter we shall (except in the final section) confine our attention to real
functions defined on intervals or segments. This is not just a matter of conve￾nience, since genuine differences appear when we pass from real functions to
vector-valued ones. Differentiation of functions defined on Rk will be discussed
in Chap. 9.
THE DERIVATIVE OF A REAL FUNCTION
5.1 Definition. Let f be defined (and real-valued) on [a, b]. For any x ∈ [a, b], form
the quotient
(5.1) ϕ(t) = f(t) − f(x)
t − x
(a < t < b, t ̸= x),
and define
(5.2) f
′
(x) = lim
t→x
ϕ(t),
provided this limit exists in accordance with Definition 4.1.
We thus associate with the function f a function f
′ whose domain is the set of
points x at which the limit (5.2) exists; f
′
is called the derivative of f.
If f
′
is defined at a point x, we say that f is differentiable at x. If f
′
is defined at
every point of a set E ⊂ [a, b], we say that f is differentiable on E.
It is possible to consider right-hand and left-hand limits in (5.2); this leads to
the definition of right-hand and left-hand derivatives. In particular, at the end￾points a and b, the derivative, if it exists, is a right-hand or left-hand derivative,
respectively. We shall not, however, discuss one-sided derivatives in any detail.
If f is defined on a segment (a, b) and if a < x < b, then f
′
(x) is defined by (5.1)
and (5.2), as above. But f
′
(a) and f
′
(b) are not defined in this case.
94THE DERIVATIVE OF A REAL FUNCTION 95
5.2 Theorem. Let f be defined on [a, b]. If f is differentiable at a point x ∈ [a, b], then f
is continuous at x.
Proof. As t → x, we have, by Theorem 4.4,
f(t) − f(x) = f(t) − f(x)
t − x
· (t − x) → f
′
(x) · 0 = 0.
The converse of this theorem is not true. It is easy to construct continuous
functions which fail to be differentiable at isolated points. In Chap. 7 we shall even
become acquainted with a function which is continuous on the whole line without
being differentiable at any point!
5.3 Theorem. Suppose f and g are defined on [a, b] and are differentiable at a point
x ∈ [a, b]. Then f + g, fg, and f/g are differentiable at x, and
(a) (f + g)
′
(x) = f
′
(x) + g
′
(x);
(b) (fg)
′
(x) = f
′
(x)g(x) + f(x)g
′
(x);
(c) 
f
g
′
(x) = g(x)f
′
(x) − g
′
(x)f(x)
g
2(x)
.
In (c), we assume of course that g(x) ̸= 0.
Proof. (a) is clear, by Theorem 4.4. Let h = fg. Then
h(t) − h(x) = f(t)[g(t) − g(x)] + g(x)[f(t) − f(x)].
If we divide this by t − x and note that f(t) → f(x) as t → x (Theorem 5.2), (b)
follows. Next, let h = f/g. Then
h(t) − h(x)
t − x
=
1
g(t)g(x)

g(x)
f(t) − f(x)
t − x
− f(x)
g(t) − g(x)
t − x

.
Letting t → x, and applying Theorems 4.4 and 5.2, we obtain (c).
5.4 Examples. The derivative of any constant is clearly zero. If f is defined by
f(x) = x, then f
′
(x) = 1. Repeated application of (b) and (c) then shows that x
n is
differentiable, and that its derivative is nxn−1 for any integer n (if n < 0, we have
to restrict ourselves to x ̸= 0). Thus every polynomial is differentiable and so is
every rational function, except at the points where the denominator is zero.
The following theorem is known as the “chain rule” for differentiation. It deals
with differentiation of composite functions and is probably the most important
theorem about derivatives. We shall meet more general versions of it in Chap. 9.
5.5 Theorem. Suppose f is continuous on [a, b], f
′
(x) exists at some point x ∈ [a, b], g
is defined on an interval I which contains the range of f, and g is differentiable at the point
f(x). If
h(t) = g(f(t)) (a ≤ t ≤ b),THE DERIVATIVE OF A REAL FUNCTION 96
then h is differentiable at x, and
(5.3) h
′
(x) = g
′
(f(x))f
′
(x).
Proof. Let y = f(x). By the definition of the derivative, we have
f(t) − f(x) = (t − x)[f
′
(x) + u(t)],(5.4)
g(s) − g(y) = (s − y)[g
′
(y) + v(s)],(5.5)
where t ∈ [a, b], s ∈ I, and u(t) → 0 as t → x, v(s) → 0 as s → y. Let s = f(t).
Using first (5.5) and then (5.4), we obtain
h(t) − h(x) = g(f(t)) − g(f(x))
= [f(t) − f(x)] · [g
′
(y) + v(s)]
= (t − x) · [f
′
(x) + u(t)] · [g
′
(y) + v(s)],
or, if t ̸= x,
(5.6) h(t) − h(x)
t − x
= [g
′
(y) + v(s)] · [f
′
(x) + u(t)].
Letting t → x, we see that s → y, by the continuity of f, so that the right side of
(5.6) tends to g
′
(y)f
′
(x), which gives (5.3).
5.6 Examples.
(a) Let f be defined by
(5.7) f(x) =



x sin 1
x
(x ̸= 0),
0 (x = 0).
Taking for granted that the derivative of sin x is cos x (we shall discuss the
trigonometric functions in Chap. 8), we can apply Theorems 5.3 and 5.5
whenever x ̸= 0, and obtain
(5.8) f
′
(x) = sin 1
x
−
1
x
cos
1
x
(x ̸= 0).
At x = 0, these theorems do not apply any longer, since 1/x is not defined
there, and we appeal directly to the definition: for t ̸= 0,
f(t) − f(0)
t − 0
= sin 1
t
.
As t → 0, this does not tend to any limit, so that f
′
(0) does not exist.MEAN VALUE THEOREMS 97
(b) Let f be defined by
(5.9) f(x) =



x
2 sin 1
x
(x ̸= 0),
0 (x = 0).
As above, we obtain
(5.10) f
′
(x) = 2x sin 1
x
− cos
1
x
(x ̸= 0).
At x = 0, we appeal to the definition, and obtain




f(t) − f(0)
t − 0



 =




t sin 1
t




≤ |t| (t ̸= 0);
letting t → 0, we see that
(5.11) f
′
(0) = 0.
Thus f is differentiable at all points x, but f
′
is not a continuous function,
since cos(1/x) in (5.10) does not tend to a limit as x → 0.
MEAN VALUE THEOREMS
5.7 Definition. Let f be a real function defined on a metric space X. We say that f
has a local maximum at a point p ∈ X if there exists δ > 0 such that f(q) ≤ f(p) for
all q ∈ X with d(p, q) < δ. Local minima are defined likewise.
Our next theorem is the basis of many applications of differentiation.
5.8 Theorem. Let f be defined on [a, b]; if f has a local maximum at a point
x ∈ (a, b) and if f
′
(x) exists, then f
′
(x) = 0.
The analogous statement for local minima is of course true.
Proof. Choose δ in accordance with Definition 5.7, so that
a < x − δ < x < x + δ < b.
If x − δ < t < x, then
f(t) − f(x)
t − x
≥ 0.
Letting t → x, we see that f
′
(x) ≥ 0.
If x < t < x + δ, then
f(t) − f(x)
t − x
≤ 0,
which shows that f
′
(x) ≤ 0. Hence f
′
(x) = 0.MEAN VALUE THEOREMS 98
5.9 Theorem. If f and g are continuous real functions on [a, b] which are differentiable
on (a, b), then there is a point x ∈ (a, b) at which
[f(b) − f(a)]g
′
(x) = [g(b) − g(a)]f
′
(x).
Note that differentiability is not required at the endpoints.
Proof. Put
h(t) = [f(b) − f(a)]g(t) − [g(b) − g(a)]f(t) (a ≤ t ≤ b).
Then h is continuous on [a, b], h is differentiable on (a, b), and
(5.12) h(a) = f(b)g(a) − f(a)g(b) = h(b).
To prove the theorem, we have to show that h
′
(x) = 0 for some x ∈ (a, b).
If h is a constant, this holds for every x ∈ (a, b). If h(t) > h(a) for some
t ∈ (a, b), let x be a point in [a, b] at which h attains its maximum (Theorem 4.16).
By (5.12), x ∈ (a, b), and Theorem 5.8 shows that h
′
(x) = 0. If h(t) < h(a) for some
t ∈ (a, b), the same argument applies if we choose for x a point on [a, b] where h
attains its minimum.
This theorem is often called a generalized mean value theorem; the following spe￾cial case is usually referred to as “the” mean value theorem:
5.10 Theorem. If f is a real continuous function on [a, b] which is differentiable on (a, b),
then there is a point x ∈ (a, b) at which
f(b) − f(a) = (b − a)f
′
(x).
Proof. Take g(x) = x in Theorem 5.9
5.11 Theorem. Suppose f is differentiable on (a, b).
(a) If f
′
(x) ≥ 0 for all x ∈ (a, b), then f is monotonically increasing.
(b) If f
′
(x) = 0 for all x ∈ (a, b), then f is constant.
(c) If f
′
(x) ≤ 0 for all x ∈ (a, b), then f is monotonically decreasing.
Proof. All conclusions can be read off from the equation
f(x2) − f(x1) = (x2 − x1)f
′
(x),
which is valid, for each pair of numbers x1, x2 in (a, b), for some x between x1 and
x2.THE CONTINUITY OF DERIVATIVES 99
THE CONTINUITY OF DERIVATIVES
We have already seen [Example 5.6(b)] that a function f may have a derivative f
′
which exists at every point but is discontinuous at some point. However, not every
function is a derivative. In particular, derivatives which exist at every point of an
interval have one important property in common with functions which are con￾tinuous on an interval: Intermediate values are assumed (compare Theorem 4.23).
The precise statement follows.
5.12 Theorem. Suppose f is a real differentiable function on [a, b] and suppose f
′
(a) <
λ < f′
(b). Then there is a point x ∈ (a, b) such that f
′
(x) = λ.
A similar result holds of course if f
′
(a) > f′
(b).
Proof. Put g(t) = f(t) − λt. Then g
′
(a) < 0 so that g(t1) < g(a) for some t1 ∈
(a, b) and g
′
(b) > 0, so that g(t2) < g(b) for some t2 ∈ (a, b). Hence g attains
its minimum on [a, b] (Theorem 4.16) at some point x such that a < x < b. By
Theorem 5.8, g
′
(x) = 0. Hence f
′
(x) = λ.
Corollary. If f is differentiable on [a, b], then f
′
cannot have any simple discontinuities
on [a, b].
But f
′ may very well have discontinuities of the second kind.
L’HOSPITAL’S RULE ˆ
The following theorem is frequently used in the evaluation of limits.
5.13 Theorem. Suppose f and g are real and differentiable on (a, b), and g
′
(x) ̸= 0 for
all x ∈ (a, b), where −∞ ≤ a < b ≤ +∞. Suppose
(5.13) f
′
(x)
g
′(x)
→ A as x → a.
If
(5.14) f(x) → 0 and g(x) → 0 as x → a,
or if
(5.15) g(x) → +∞ as x → a,
then
(5.16) f(x)
g(x)
→ A as x → a.DERIVATIVES OF HIGHER ORDER 100
The analogous statement is of course also true if x → b, or if g(x) → −∞
in (5.15). Let us note that we now use the limit concept in the extended sense of
Definition 4.33
Proof. We first consider the case in which −∞ ≤ A < +∞. Choose a real number
q such that A < q, and then choose r such that A < r < q. By (5.13) there is a point
c ∈ (a, b) such that a < x < c implies
(5.17) f
′
(x)
g
′(x)
< r.
If a < x < y < c, then Theorem 5.9 shows that there is a point t ∈ (x, y) such that
(5.18) f(x) − f(y)
g(x) − g(y)
=
f
′
(t)
g
′(t)
< r.
Suppose (5.14) holds. Letting x → a in (5.18), we see that
(5.19) f(y)
g(y)
≤ r < q (a < y < c).
Next, suppose (5.15) holds. Keeping y fixed in (5.18), we can choose a point c1 ∈
(a, y) such that g(x) > g(y) and g(x) > 0 if a < x < c1. Multiplying (5.18) by
[g(x) − g(y)]/g(x), we obtain
(5.20) f(x)
g(x)
< r − r
g(y)
g(x)
+
f(y)
g(x)
(a < x < c1).
If we let x → a in (5.20), (5.15) shows that there is a point c2 ∈ (a, c1) such that
(5.21) f(x)
g(x)
< q (a < x < c2).
Summing up, (5.19) and (5.21) show that for any q, subject only to the condition
A < q, there is a point c2 such that f(x)/g(x) < q if a < x < c2.
In the same manner, if −∞ < A ≤ +∞ and p is chosen so that p < A, we can
find a point c3 such that
(5.22) p <
f(x)
g(x)
(a < x < c3),
and (5.16) follows from these two statements.
DERIVATIVES OF HIGHER ORDER
5.14 Definition. If f has a derivative f
′ on an interval, and if f
′
is itself differen￾tiable, we denote the derivative of f
′ by f
′′ and call f
′′ the second derivative of f.TAYLOR’S THEOREM 101
Continuing in this manner, we obtain functions
f, f
′
, f
′′
, f
(3)
, . . . , f
(n)
,
each of which is the derivative of the preceding one. f
(n)
is called the nth deriva￾tive of f, or the derivative of order n, of f.
In order for f
(n)
(x) to exist at a point x, f
(n−1)
(t) must exist in a neighborhood
of x (or in a one-sided neighborhood, if x is an endpoint of the interval on which
f is defined), and f
(n−1) must be differentiable at x. Since f
(n−1) must exist in a
neighborhood of x, f
(n−2) must be differentiable in that neighborhood.
TAYLOR’S THEOREM
5.15 Theorem. Suppose f is a real function on [a, b], n is a positive integer, f
(n−1)
is
continuous on [a, b], f
(n)
(t) exists for every t ∈ (a, b). Let α, β be distinct points of
[a, b], and define
(5.23) P(t) =
nX−1
k=0
f
(k)
(α)
k!
(t − α)
k
.
Then there exists a point x between α and β such that
(5.24) f(β) = P(β) + f
(n)
(x)
n!
(β − α)
n.
For n = 1, this is just the mean value theorem. In general, the theorem shows
that f can be approximated by a polynomial of degree n − 1, and that (5.24) allows
us the estimate the error, if we know the bounds on

f
(n)
(x)


.
Proof. Let M be the number defined by
(5.25) f(β) = P(β) + M(β − α)
n
and put
(5.26) g(t) = f(t) − P(t) − M(t − α)
n (a ≤ t ≤ b).
We have to show that n!M = f
(n)
(x) for some x between α and β. By (5.23) and
(5.26),
(5.27) g
(n)
(t) = f
(n)
(t) − n!M (a < t < b).
Hence the proof will be complete if we can show that g
(n)
(x) = 0 for some x
between α and β.DIFFERENTIATION OF VECTOR-VALUED FUNCTIONS 102
Since P
(k)
(α) = f
(k)
(α) for k = 0, . . . , n − 1, we have
(5.28) g(α) = g
′
(α) = · · · = g
(n−1)
(α) = 0.
Our choice of M shows that g(β) = 0, so that g
′
(x1) = 0 for some x1 between
α and β, by the mean value theorem. Since g
′
(α) = 0, we conclude similarly that
g
′′(x2) = 0 for some x2 between α and x1. After n steps we arrive at the conclusion
that g
(n)
(xn) = 0 for some xn between α and xn−1, that is, between α and β.
DIFFERENTIATION OF VECTOR-VALUED FUNCTIONS
5.16 Remarks. Definition 5.1 applies without any change to complex functions f
defined on [a, b], and Theorems 5.2 and 5.3, as well as their proofs, remain valid.
If f1 and f2 are the real and imaginary parts of f, that is, if
f(t) = f1(t) + if2(t)
for a ≤ t ≤ b, where f1(t) and f2(t) are real, then we clearly have
(5.29) f
′
(x) = f
′
1
(x) + if′
2
(x);
also, f is differentiable at x if and only if both f1 and f2 are differentiable at x.
Passing to vector-valued functions in general, i.e., to functions f which map
[a, b] into some Rk, we may still apply Definition 5.1 to define f
′
(x). The term ϕ(t)
in (5.1) is now, for each t, a point in Rk, and the limit in (5.2) is taken with respect
to the norm of Rk. In other words, f
′
(x) is that point of Rk (if there is one) for
which
(5.30) lim
t→x




f(t) − f(x)
t − x
− f
′
(x)



 = 0,
and f
′
is again a function with values in Rk.
If f1, . . . , fk are the components of f, as defined in Theorem 4.10, then
(5.31) f
′ = (f
′
1
, . . . , f
′
k
),
and f is differentiable at a point x if and only if each of the functions f1, . . . , fk is
differentiable at x.
Theorem 5.2 is true in this context as well, and so is Theorem 5.3(a) and (b), if
fg is replaced by the inner product f · g (see Definition 4.3).
When we turn to the mean value theorem, however, and to one of its conse￾quences, namely L’Hospital’s rule, the situation changes. The next two examples ˆ
will show that each of these results fails to be true for complex-valued functions.
5.17 Example. Define, for real x,
(5.32) f(x) = e
ix = cos x + i sin x.DIFFERENTIATION OF VECTOR-VALUED FUNCTIONS 103
(The last expression may be taken as the definition of the complex exponential e
ix;
see Chap. 8 for a full discussion of these functions.) Then
(5.33) f(2π) − f(0) = 1 − 1 = 0,
but
(5.34) f
′
(x) = ieix
,
so that

f
′
(x)

 = 1 for all real x. Thus Theorem 5.10 fails to hold in this case.
5.18 Example. On the segment (0, 1), define f(x) = x and
(5.35) g(x) = x + x
2
e
i/x
2
.
Since

e
it 
 = 1 for all real t, we see that
(5.36) lim
x→0
f(x)
g(x)
= 1.
Next,
(5.37) g
′
(x) = 1 +

2x −
2i
x

e
i/x
2
(0 < x < 1),
so that
(5.38)

g
′
(x)

 ≥




2x −
2i
x



 − 1 ≥
2
x
− 1.
Hence
(5.39)




f
′
(x)
g
′(x)



 =
1
|g
′(x)|
≤
x
2 − x
and so
(5.40) lim
x→0
f
′
(x)
g
′(x)
= 0.
By (5.36) and (5.40), L’Hospital’s rule fails in this case. Note also that ˆ g
′
(x) ̸= 0 on
(0, 1), by (5.38).
However, there is a consequence of the mean value theorem which, for pur￾poses of applications, is almost as useful as Theorem 5.10, and which remains true
for vector valued functions: From Theorem 5.10 it follows that
(5.41) |f(b) − f(a)| ≤ (b − a) sup
a<x<b

f
′
(x)


.
5.19 Theorem. Suppose f is a continuous mapping of [a, b] into Rk and f is differentiableEXERCISES 104
on (a, b). Then there exists x ∈ (a, b) such that
|f(b) − f(a)| ≤ (b − a)

f
′
(x)


.
Proof (V.P. Havin). Put z = f(b) − f(a) and define
φ(t) = z · f(t) (a ≤ t ≤ b).
Then φ is a real-valued continuous function on [a, b] which is differentiable on
(a, b). The mean value theorem shows therefore that
φ(b) − φ(a) = (b − a)φ
′
(x) = (b − a)z · f
′
(x)
for some x ∈ (a, b). On the other hand,
φ(b) − φ(a) = z · f(b) − z · f(a) = z · z = |z|
2
.
The Schwarz inequality now gives
|z|
2 = (b − a)

z · f
′
(x)

 ≤ (b − a)|z|

f
′
(x)


Hence |z| ≤ (b − a)

f
′
(x)


, which is the desired conclusion.
EXERCISES
5.1. Let f be defined for all real x, and suppose that
|f(x) − f(y)| ≤ (x − y)
2
.
For all real x and y. Prove that x is constant.
5.2. Suppose f
′
(x) > 0 in (a, b). Prove that f is strictly increasing on (a, b), and let g be its
inverse function. Prove that g is differentiable and that
g
′
(f(x)) = 1
f
′(x)
(a < x < b).
5.3. Suppose g is a real function on R1 with bounded derivative (say |g
′
| ≤ M). Fix ε > 0 and
define f(x) = x + εg(x). Prove that f is one-to-one if ε is small enough (A set of admissible
values of ε can be determined which depends only on M.)
5.4. If
C0 +
C1
2
+ · · · +
Cn−1
n
+
Cn
n + 1
= 0,
where C0, . . . , Cn are real constants, prove that the equation
C0 + C1x + · · · + Cn−1x
n−1 + Cnx
n = 0
has at least one real root between 0 and 1.
5.5. Suppose f is defined and differentiable for every x > 0 and f
′
(x) → 0 as x → +∞. Put
g(x) = f(x + 1) − f(x). Prove that g(x) → 0 as x → +∞.EXERCISES 105
5.6. Suppose
(a) f is continuous for x ≥ 0,
(b) f
′
(x) exists for x > 0,
(c) f(0) = 0,
(d) f
′
is monotonically increasing.
Put
g(x) = f(x)
x
(x > 0)
and prove that g is monotonically increasing.
5.7. Suppose f
′
(x), g
′
(x) exist, g
′
(x) ̸= 0, and f(x) = g(x) = 0. Prove that
limt→x
f(t)
g(t)
=
f
′
(x)
g
′(x)
.
(This also holds for complex functions.)
5.8. Suppose f
′
is continuous on [a, b] and ε > 0. Prove that there exists δ > 0 such that




f(t) − f(x)
t − x
− f
′
(x)




< ε
whenever 0 < |t − x| < δ, a ≤ x ≤ b, a ≤ t ≤ b. (This could be expressed by saying that f is
uniformly differentiable on [a, b] if f
′
is continuous on [a, b].) Does this hold for vector-valued
functions too?
5.9. Let f be a continuous real function on R1
, of which it is known that f
′
(x) exists for all
x ̸= 0 and that f
′
(x) → 3 as x → 0. Does it follow that f
′
(0) exists?
5.10. Suppose f and g are complex differentiable functions on (0, 1), f(x) → 0, g(x) → 0,
f
′
(x) → A, g
′
(x) → B as x → 0, where A and B are complex numbers and B ̸= 0. Prove that
lim
x→0
f(x)
g(x)
=
A
B
.
Compare with Example 5.18. Hint:
f(x)
g(x)
=

f(x)
x
− A

·
x
g(x)
+ A ·
x
g(x)
.
Apply Theorem 5.13 to the real and imaginary parts of f(x)/x and g(x)/x.
5.11. Suppose f is defined in a neighborhood of x, and suppose f
′′(x) exists. Show that
lim
h→0
f(x + h) + f(x − h) − 2f(x)
h2
= f
′′(x).
Show by example that the limit may exist even if f
′′(x) does not. Hint: Use Theorem 5.13.
5.12. If f(x) = |x|
3
, compute f
′
(x), f
′′(x) for all real x, and show that f
(3)
(0) does not exist.
5.13. Suppose a and c are real numbers, c > 0, and f is defined on [−1, 1] by
f(x) = 
x
a sin(|x|
−c
) (if x ̸= 0),
0 (if x = 0).
Prove the following statements
(a) f is continuous if and only if a > 0.
(b) f
′
(0) exists if and only if a > 1.
(c) f
′
is bounded if and only if a ≥ 1 + c.
(d) f
′
is continuous if and only if a > 1 + c.EXERCISES 106
(e) f
′′(0) exists if and only if a > 2 + c.
(f) f
′′ is bounded if and only if a ≥ 2 + 2c.
(g) f
′′ is continuous if and only if a > 2 + 2c.
5.14. Let f be a differentiable real function defined on (a, b). Prove that f is convex if and
only if f
′
is monotonically increasing. Assume next that f
′′(x) exists for every x ∈ (a, b), and
prove that f is convex if and only if f
′′(x) ≥ 0 for all x ∈ (a, b).
5.15. Suppose a ∈ R1
, f is a twice-differentiable real function on (a,∞), and M0, M1, M2
are the least upper bounds of |f(x)|, |f
′
(x)|, |f
′′(x)|, respectively, on (a,∞). Prove that
M2
1 ≤ 4M0M2.
Hint: If h > 0, Taylor’s theorem shows that
f
′
(x) = 1
2h [f(x + 2h) − f(x)] − hf′′(ξ)
for some ξ ∈ (x, x + 2h). Hence

f
′
(x)

 ≤ hM2 +
M0
h
.
To show that M2
1 = 4M0M2 can actually happen, take a = −1, define
f(x) =



2x2 − 1 (−1 < x < 0),
x
2 − 1
x
2 + 1
(0 ≤ x < ∞),
and show that M0 = 1, M1 = 4, and M2 = 4.
Does M2
1 ≤ 4M0M2 hold for vector-valued functions too?
5.16. Suppose f is twice-differentiable on (0,∞), f
′′ is bounded on (0,∞), and f(x) → 0 as
x → ∞. Prove that f
′
(x) → 0 as x → ∞. Hint: Let a → ∞ in Exercise 5.15
5.17. Suppose f is a real, three times differentiable function on [−1, 1], such that
f(−1) = 0, f(0) = 0, f(1) = 1, f
′
(0) = 0.
Prove that f
(3)
(x) ≥ 3 for some x ∈ (−1, 1). Note that equality holds for (x
3 + x
2
)/2.
Hint: Use Theorem 5.15, with α = 0 and β = ±1, to show that there exist s ∈ (0, 1) and
t ∈ (−1, 0) such that
f
(3)
(s) + f
(3)
(t) = 6.
5.18. Suppose f is a real function on [a, b], n is a positive integer, and f
(n−1)
exists for every
t ∈ [a, b]. Let α, β, and P be as in Taylor’s theorem (Theorem 5.15). Define
Q(t) = f(t) − f(β)
t − β
for t ∈ [a, b], t ̸= β, differentiate
f(t) − f(β) = (t − β)Q(t)
n − 1 times at t = α, and derive the following version of Taylor’s theorem:
f(β) = P(β) + Q(n−1)
(α)
(n − 1)! (β − α)
n.EXERCISES 107
5.19. Suppose f is defined in (−1, 1) and f
′
(0) exists. Suppose −1 < αn < βn < 1, αn → 0,
and βn → 0 as n → ∞. Define the difference quotients
Dn =
f(βn) − f(αn)
βn − αn
.
Prove the following statements:
(a) If αn < 0 < βn, then lim Dn = f
′
(0).
(b) If 0 < αn < βn and (βn/(βn − αn))∞
n=1
is bounded, then lim Dn = f
′
(0).
(c) If f
′
is continuous in (−1, 1), then lim Dn = f
′
(0).
Give an example in which f is differentiable in (−1, 1) (but f
′
is not continuous at 0) and in
which αn, βn tend to 0 in such a way that lim Dn exists but is different from f
′
(0).
5.20. Formulate and prove an inequality which follows from Taylor’s theorem and which
remains valid for vector-valued functions.
5.21. Let E be a closed subset of R1
. We saw in Exercise 4.22 that there is a real continuous
function f on R1 whose zero set is E. Is it possible, for each closed set E, to find such an f
which is differentiable on R1
, or one which is n times differentiable, or even one which has
derivatives of all orders on R1
?
5.22. Suppose f is a real function on (−∞,∞). Call x a fixed point of f if f(x) = x.
(a) If f is differentiable and f
′
(t) ̸= 1 for every real t, prove that f has at most one fixed
point.
(b) Show that the function f defined by
f
′
(t) = t + (1 + e
t
)
−1
has no fixed point, although 0 < f′
(t) < 1 for all real t.
(c) However, if there is a constant A < 1 such that |f
′
(t)| ≤ A for all real t, prove that a
fixed point of f exists, and that x = lim xn, where x1 is an arbitrary real number and
xn+1 = f(xn)
for n = 1, 2, 3, . . . .
(d) Show that the process described in (c) can be visualized by the zig-zag path
(x1, x2) → (x2, x2) → (x2, x3) → (x3, x3) → (x3, x4) → · · · .
5.23. The function f defined by
f(x) = x
3 + 1
3
has three fixed points, say α, β, γ, where
−2 < α < −1, 0 < β < 1, 1 < γ < 2.
For arbitrarily chosen x1, define (xn) by setting xn+1 = f(xn).
(a) If x1 < α prove that xn → −∞ as n → ∞.
(b) If α < x1 < γ, prove that xn → β as n → ∞.
(c) If γ < x1, prove that xn → +∞ as n → ∞.
Thus β can be located by this method, but α and γ cannot.
5.24. The process described in part (c) of Exercise 5.22 can of course also be applied to func￾tions that map (0,∞) to (0,∞).
Fix some α > 1 and put
f(x) = 1
2

x +
α
x

, g(x) = α + x
1 + x
.EXERCISES 108
Both f and g have √
α as their only fixed point in (0,∞). Try to explain, on the basis of
properties of f and g, why the convergence in Exercise 3.16 is so much more rapid than it is
in Exercise 3.17. (Compare f
′ and g
′
, draw the zig-zags suggested in Exercise 5.22.) Do the
same when 0 < α < 1.
5.25. Suppose f is twice-differentiable on [a, b], f(a) < 0, f(b) > 0, f
′
(x) ≥ δ > 0, and
0 ≤ f
′′(x) ≤ M for all x ∈ [a, b]. Let ξ be the unique point in (a, b) at which f(ξ) = 0.
Complete the details of the following outline of Newton’s method for computing ξ.
(a) Choose x1 ∈ (ξ, b) and define (xn) by
xn+1 = xn −
f(xn)
f
′(xn)
.
Interpret this geometrically, in terms of a tangent to the graph of f.
(b) Prove that xn+1 < xn, and that
limn→∞
xn = ξ.
(c) Use Taylor’s theorem to show that
xn+1 − ξ =
f
′′(tn)
2f′(xn)
(xn − ξ)
2
for some tn ∈ (ξ, xn).
(d) If A = M/2δ, deduce that
0 ≤ xn+1 − ξ ≤
1
A
[A(x1 − ξ)]2n
.
Compare with Exercises 3.16 and 3.18.
(e) Show that Newton’s method amounts to finding a fixed point of the function g defined
by
g(x) = x −
f(x)
f
′(x)
.
How does g
′
(x) behave for x near ξ?
(f) Put f(x) = x
1/3 on (−∞,∞) and try Newton’s method. What happens?
5.26. Suppose f is differentiable on [a, b], f(a) = 0, and there is a real number A such that
|f
′
(x)| ≤ A |f(x)| on [a, b]. Prove that f(x) = 0 for all x ∈ [a, b]. Hint: Fix x0 ∈ [a, b], let
M0 = sup |f(x)| , M1 = sup

f
′
(x)


for a ≤ x ≤ x0. For any such x,
|f(x)| ≤ M1(x0 − a) ≤ A(x0 − a)M0.
Hence M0 = 0 if A(x0 − a) < 1. That is, f = 0 on [a, x0]. Proceed.
5.27. Let ϕ be a real function defined on a rectangle R in the plane given by a ≤ x ≤ b,
α ≤ y ≤ β. A solution of the initial-value problem
y
′ = ϕ(x, y), y(a) = c (α ≤ c ≤ β)
is, by definition, a differentiable function f on [a, b] such that f(a) = c, α ≤ f(x) ≤ β, and
f
′
(x) = ϕ(x, f(x)) (a ≤ x ≤ b).
Prove that such a problem has at most one solution if there is a constant A such that
|ϕ(x, y2) − ϕ(x, y1)| ≤ A |y2 − y1 |
whenever (x, y1) ∈ R and (x, y2) ∈ R.EXERCISES 109
Hint: Apply Exercise 5.26 to the difference of two solutions. Note that this uniqueness
theorem does not hold for the initial-value problem
y
′ = y
1/2
, y(0) = 0,
which has two solutions: f(x) = 0 and f(x) = x
2/4. Find all other solutions.
5.28. Formulate and prove an analogous uniqueness theorem for systems of differentiable
equations of the form
y
′
j = ϕj(x, y1, . . . , yk), yj(a) = cj (j = 1, . . . , k).
Note that this can be rewritten in the form
y
′ = ϕ(x, y), y(a) = c
where y = (y1, . . . , yk) ranges over a k-cell, ϕ is the mapping of a (k + 1)-cell into the eu￾clidean k-space whose components are the functions ϕ1, . . . , ϕk, and c is the vector(c1, . . . , ck).
Use Exercise 5.26, for vector-valued functions.
5.29. Specialize Exercise 5.28 by considering the system
y
′
j = yj+1 (j = 1, . . . , k − 1),
y
′
k = f(x) −Xk
j=1
gj(x)yj
,
where f, g1, . . . , gk are continuous real functions on [a, b], and derive a uniqueness theorem
for solutions of the equation
y
(k) + gk(x)y
(k−1) + · · · + g2(x)y
′ + g1(x)y = f(x),
subject to initial conditions
y(a) = c1, y
′
(a) = c2, . . . , y
(k−1)
(a) = ck.Chapter 6
THE RIEMANN-STIELTJES INTEGRAL
The present chapter is based on a definition of the Riemann integral which de￾pends very explicitly on the order structure of the real line. Accordingly, we begin
by discussing integration of real-valued functions on intervals. Extensions to com￾plex and vector-valued functions on intervals follow in later sections. Integration
over sets other than intervals is discussed in Chaps. 10 and 11.
DEFINITION AND EXISTENCE OF THE INTEGRAL
6.1 Definition. Let [a, b] be a given interval. By a partition P of [a, b], we mean a
finite set of points x0, x1, . . . , xn, where
a = x0 ≤ x1 ≤ · · · ≤ xn−1 ≤ xn = b.
We write
∆xi = xi − xi−1 (i = 1, . . . , n).
Now suppose f is a bounded real function defined on [a, b]. Corresponding to each
partition P of [a, b] we put
Mi = sup f(x) (xi−1 ≤ x ≤ xi
)
mi = inf f(x) (xi−1 ≤ x ≤ xi
)
U(P, f) = Xn
i=1
Mi ∆xi
,
L(P, f) = Xn
i=1
mi ∆xi
,
110DEFINITION AND EXISTENCE OF THE INTEGRAL 111
and finally
Z b
a
(6.1) f dx = inf U(P, f)
Z b
a
f dx = sup L(P, f).(6.2)
where the inf and sup are taken over all partitions P of [a, b]. The left members
of (6.1) and (6.2) are called the upper and lower Riemann integrals of f over [a, b],
respectively.
If the upper and lower integrals are equal, we say that f is Riemann integrable on
[a, b], we write f ∈ R (that is, R denotes the set of Riemann-integrable functions),
and we denote the common value of (6.1) and (6.2) by
(6.3) Z b
a
f dx,
or by
(6.4) Z b
a
f(x) dx.
This is the Riemann integral of f over [a, b].
Since f is bounded, there exist two numbers, m and M, such that
m ≤ f(x) ≤ M (a ≤ x ≤ b).
Hence, for every P,
m(b − a) ≤ L(P, f) ≤ U(P, f) ≤ M(b − a),
so that the numbers L(P, f) and U(P, f) form a bounded set. This shows that the up￾per and lower integrals are defined for every bounded function f. The question of their
equality, and hence the question of the integrability of f, is a more delicate one. In￾stead of investigating it separately for the Riemann integral, we shall immediately
consider a more general situation.
6.2 Definition. Let α be a monotonically increasing function on [a, b] (since α(a)
and α(b) are finite, it follows that α is bounded on [a, b]). Corresponding to each
partition P of [a, b], we write
∆αi = α(xi
) − α(xi−1).DEFINITION AND EXISTENCE OF THE INTEGRAL 112
It is clear that ∆αi ≥ 0. For any real function f which is bounded on [a, b] we put
U(P, f, α) = Xn
i=1
Mi∆ αi
,
L(P, f, α) = Xn
i=1
mi∆ αi
where Mi
, mi have the same meaning as in Definition 6.1, and we define
Z b
a
(6.5) f dα = inf U(P, f, α)
Z b
a
f dα = sup L(P, f, α),(6.6)
the inf and sup again being taken over all partitions.
If the left members of (6.5) and (6.6) are equal, we denote their common value
by
(6.7) Z b
a
f dα
or sometimes by
(6.8) Z b
a
f(x) dα(x).
This is the Riemann-Stieltjes integral (or simply the Stieltjes integral) of f with respect
to α, over [a, b]. If (6.7) exists, i.e., if (6.5) and (6.6) are equal, we say that f is
integrable with respect to α, in the Riemann sense, and write f ∈ R(α).
By taking α(x) = x, the Riemann integral is seen to be a special case of the
Riemann-Stieltjes integral. Let us mention explicitly, however, that in the general
case α need not even be continuous.
A few words should be said about the notation. We prefer (6.7) to (6.8), since
the letter x which appears in (6.8) adds nothing to the content of (6.7). It is imma￾terial which letter we use to represent the so-called “variable of integration.” For
instance, (6.8) is the same as
Z b
a
f(y) dα(y).
The integral depends on f, α, a, and b, but not on the variable of integration, which
may as well be omitted.
The role played by the variable of integration is quite analogous to that of theDEFINITION AND EXISTENCE OF THE INTEGRAL 113
index of summation: The two symbols
Xn
i=1
ci
,
Xn
k=1
ck
mean the same thing, since each means c1 + c2 + · · · + cn.
Of course, no harm is done by inserting the variable of integration, and in many
cases it is actually convenient to do so.
We shall now investigate the existence of the integral (6.7). Without saying so
every time, f will be assumed real and bounded, and α is monotonically increasing
on [a, b]; and, when there can be no misunderstanding, we shall write R
in place of
Rb
a
.
6.3 Definition. We say that the partition P
∗
is a refinement of P if P
∗ ⊃ P (that is, if
every point of P is a point of P
∗
). Given two partitions, P1 and P2, we say that P
∗
is their common refinement if P
∗ = P1 ∪ P2.
6.4 Theorem. If P
∗
is a refinement of P, then
(6.9) L(P, f, α) ≤ L(P
∗
, f, α)
and
(6.10) U(P
∗
, f, α) ≤ U(P, f, α).
Proof. To prove (6.9), suppose first that P
∗
contains just one point more than P. Let
this extra point be x
∗
, and suppose xi−1 < x∗ < xi
, where xi−1 and xi are two
consecutive points of P. Put
w1 = inf f(x) (xi−1 ≤ x ≤ x
∗
)
w2 = inf f(x) (x
∗ ≤ x ≤ xi
).
Clearly w1 ≥ mi and w2 ≥ mi
, where, as before,
mi = inf f(x) (xi−1 ≤ x ≤ xi
).
Hence
L(P
∗
, f, α) − L(P, f, α)
= w1[α(x
∗
) − α(xi−1)] + w2[α(xi
) − α(x
∗
)] − mi
[α(xi
) − α(xi−1)]
= (w1 − mi
)[α(x
∗
) − α(xi−1)] + (w2 − mi
)[α(xi
) − α(x
∗
)] ≥ 0.
If P
∗
contains k points more than P, we repeat this reasoning k times, and arrive at
(6.9). The proof of (6.10) is analogous.DEFINITION AND EXISTENCE OF THE INTEGRAL 114
6.5 Theorem. Rb
a
f dα ≤
Rb
a
f dα.
Proof. Let P
∗ be the common refinement of two partitions P1 and P2. By Theo￾rem 6.4,
L(P1, f, α) ≤ L(P
∗
, f, α) ≤ U(P
∗
, f, α) ≤ U(P2, f, α).
Hence
(6.11) L(P1, f, α) ≤ U(P2, f, α).
If P2 is fixed and the sup is taken over all P1, (6.11) gives
(6.12) Z
f dα ≤ U(P2, f, α).
The theorem follows by taking the inf over all P2 in (6.12).
6.6 Theorem. f ∈ R(α) on [a, b] if and only if for every ε > 0, there exists a partition P
such that
(6.13) U(P, f, α) − L(P, f, α) < ε.
Proof. For every P, we have
L(P, f, α) ≤
Z
f dα ≤
Z
f dα ≤ U(P, f, α).
Thus (6.13) implies
0 ≤
Z
f dα −
Z
f dα < ε.
Hence, if (6.13) can be satisfied for every ε > 0, we have
Z
f dα =
Z
f dα,
that is, f ∈ R(α).
Conversely, suppose f ∈ R(α), and let ε > 0 be given. Then there exist parti￾tions P1 and P2 such that
(6.14) U(P2, f, α) − Z
f dα <
ε
2
,
(6.15) Z
f dα − L(P1, f, α) <
ε
2
.
We choose P to be the common refinement of P1 and P2. Then Theorem 6.4, to-DEFINITION AND EXISTENCE OF THE INTEGRAL 115
gether with (6.14) and (6.15), shows that
U(P, f, α) ≤ U(P2, f, α) <
Z
f dα +
ε
2
< L(P1, f, α) + ε ≤ L(P, f, α) + ε,
so that (6.13) holds for this partition P.
Theorem 6.6 furnishes a convenient criterion for integrability. Before we apply
it, we state some closely related facts.
6.7 Theorem.
(a) If (6.13) holds for some P and some ε, then (6.13) holds (with the same ε) for every
refinement of P.
(b) If (6.13) holds for P = {x0, . . . , xn} and if si
, ti are arbitrary points in [xi−1, xi
],
then
Xn
i=1
|f(si
) − f(ti
)| ∆αi < ε.
(c) If f ∈ R(α) and the hypotheses of (b) hold, then





Xn
i=1
f(ti
)∆αi −
Z b
a
f dα





< ε.
Proof. Theorem 6.4 implies (a). Under the assumptions made in (b), both f(si
) and
f(ti
) lie in [mi
,Mi
] so that |f(si
) − f(ti
)| ≤ Mi − mi
. Thus
Xn
i=1
|f(si
) − f(ti
)| ∆αi ≤ U(P, f, α) − L(P, f, α),
which proves (b). The obvious inequalities
L(P, f, α) ≤
Xf(ti
)∆αi ≤ U(P, f, α)
and
L(P, f, α) ≤
Z
f dα ≤ U(P, f, α)
prove (c).
6.8 Theorem. If f is continuous on [a, b], then f ∈ R(α) on [a, b].
Proof. If f is continuous on [a, b] (Theorem 4.19), there exists a δ > 0 such that
(6.16) |f(x) − f(t)| < η
if x ∈ [a, b], t ∈ [a, b], and |x − t| < δ.DEFINITION AND EXISTENCE OF THE INTEGRAL 116
If P is any partition of [a, b] such that ∆xi < δ for all i, then (6.16) implies that
(6.17) Mi − mi ≤ η (i = 1, . . . , n)
and therefore
U(P, f, α) − L(P, f, α) = Xn
i=1
(Mi − mi
)∆αi
≤ η
Xn
i=1
∆αi = η[α(b) − α(a)] < ε.
By Theorem 6.6, f ∈ R(α).
6.9 Theorem. If f is monotonic on [a, b], and if α is continuous on [a, b], then f ∈ R(α).
(We still assume, of course, that α is monotonic.)
Proof. Let ε > 0 be given. For any positive integer n, choose a partition such that
∆αi =
α(b) − α(a)
n
(i = 1, . . . , n).
This is possible since α is continuous (Theorem 4.23).
We suppose that f is monotonically increasing (the proof is analogous in the
other case). Then
Mi = f(xi
), mi = f(xi−1) (i = 1, . . . , n),
so that
U(P, f, α) − L(P, f, α) = α(b) − α(a)
n
Xn
i=1
[f(xi
) − f(xi−1)]
=
α(b) − α(a)
n
· [f(b) − f(a)] < ε
if n is taken large enough. By Theorem 6.6, f ∈ R(α).
6.10 Theorem. Suppose f is bounded on [a, b], f has only finitely many points of discon￾tinuity on [a, b], and α is continuous at every point at which f is discontinuous. Then
f ∈ R(α).
Proof. Let ε > 0 be given. Put M = sup |f(x)|, let E be the set of points at which f
is discontinuous. Since E is finite and α is continuous at every point of E, we can
cover E by finitely many disjoint intervals [uj
, vj
] ⊂ [a, b] such that the sum of the
corresponding differences α(vj
) − α(uj
) is less than ε. Furthermore, we can place
these intervals in such a way that every point of E ∩ (a, b) lies in the interior of
some [uj
, vj
].DEFINITION AND EXISTENCE OF THE INTEGRAL 117
Remove the segments (uj
, vj
) from [a, b]. The remaining set K is compact.
Hence f is uniformly continuous on K, and there exists δ > 0 such that |f(s) − f(t)| <
ε if s ∈ K, t ∈ K, |s − t| < δ.
Now form a partition P = {x0, x1, . . . , xn} of [a, b] as follows: Each uj occurs in
P. Each vj occurs in P. No point of any segment (uj
, vj
) occurs in P. If xi−1 is not
one of the uj
, then ∆xi < δ.
Note that Mi − mi ≤ 2M for every i, and that Mi − mi ≤ ε unless xi−1 is one
of the uj
. Hence, as in the proof of Theorem 6.8,
U(P, f, α) − L(P, f, α) ≤ [α(b) − α(a)]ε + 2Mε.
Since ε is arbitrary, Theorem 6.6 shows that f ∈ R(α).
Note: If f and α have a common point of discontinuity, then f need not be in
R(α). Exercise 6.3 shows this.
6.11 Theorem. Suppose f ∈ R(α) on [a, b], m ≤ f ≤ M, ϕ is continuous on [m,M],
and h(x) = ϕ(f(x)) on [a, b]. Then h ∈ R(α) on [a, b].
Proof. Choose ε > 0. Since ϕ is uniformly continuous on [m,M], there exists δ > 0
such that δ < ε and |ϕ(s) − ϕ(t)| < ε if |s − t| ≤ δ and s, t ∈ [m,M].
Since f ∈ R(α), there is a partition P = {x0, x1, . . . , xn} of [a, b] such that
(6.18) U(P, f, α) − L(P, f, α) < δ2
Let Mi
, mi have the same meaning as in Definition 6.1, and let M∗
i
, m∗
i
be the
analogous numbers for h. Divide the numbers 1, . . . , n into two classes: i ∈ A if
Mi − mi < δ, i ∈ B if Mi − mi ≥ δ.
For i ∈ A, our choice of δ shows that M∗
i − m∗
i ≤ ε.
For i ∈ B, M∗
i − m∗
i ≤ 2K, where K = sup |ϕ(t)|, m ≤ t ≤ M. By (6.18), we
have
(6.19) δ
X
i∈B
∆αi ≤
X
i∈B
(Mi − mi
)∆αi < δ2
so that P
i∈B ∆αi < δ. It follows that
U(P, h, α) − L(P, h, α) = X
i∈A
(M∗
i − m∗
i
)∆αi +
X
i∈B
(M∗
i − m∗
i
)∆αi
≤ ε[α(b) − α(a)] + 2Kδ < ε[α(b) − α(a) + 2K].
Since ε was arbitrary, Theorem 6.6 implies that h ∈ R(α).
Remark: This theorem suggests the question: Just what functions are Riemann￾integrable? The answer is given by Theorem 11.33(b).PROPERTIES OF THE INTEGRAL 118
PROPERTIES OF THE INTEGRAL
6.12 Theorem.
(a) If f1 ∈ R(α) and f2 ∈ R(α) on [a, b], then
f1 + f2 ∈ R(α),
cf ∈ R(α) for every constant c, and
Z b
a
(f1 + f2) dα =
Z b
a
f1 dα +
Z b
a
f2 dα
Z b
a
cf dα = c
Z b
a
f dα.
(b) If f1(x) ≤ f2(x) on [a, b], then
Z b
a
f1 dα ≤
Z b
a
f2 dα.
(c) If f ∈ R(α) on [a, b] and if a < c < b, then f ∈ R(α) on [a, c] and on [c, b] and
Zc
a
f dα +
Z b
c
f dα =
Z b
a
f dα.
(d) If f ∈ R(α) on [a, b] and if |f(x)| ≤ M on [a, b], then





Z b
a
f dα





≤ M[α(b) − α(a)].
(e) If f ∈ R(α1) and f ∈ R(α2), then f ∈ R(α1 + α2) and
Z b
a
f d(α1 + α2) = Z b
a
f dα1 +
Z b
a
f dα2;
if f ∈ R(α) and c is a positive constant, then f ∈ R(cα) and
Z b
a
f d(cα) = c
Z b
a
f dα.
Proof. If f = f1 + f2 and P is any partition of [a, b], we have
(6.20)
L(P, f1, α) + L(P, f2, α) ≤ L(P, f, α)
≤ U(P, f, α) ≤ U(P, f1, α) + U(P, f2, α).
If f1 ∈ R(α) and f2 ∈ R(α), let ε > 0 be given. There are partitions Pj
(j = 1, 2)
such that
U(Pj
, fj
, α) − L(Pj
, fj
, α) < ε.PROPERTIES OF THE INTEGRAL 119
These inequalities persist if P1 and P2 are replaced by their common refinement P.
Then (6.20) implies
U(P, f, α) − L(P, f, α) < 2ε,
which proves that f ∈ R(α).
With this same P, we have
U(P, fj
, α) <
Z
fj dα + ε (j = 1, 2);
hence (6.20) implies
Z
f dα ≤ U(P, f, α) <
Z
f1 dα +
Z
f2 dα + 2ε.
Since ε was arbitrary, we conclude that
(6.21) Z
f dα ≤
Z
f1 dα +
Z
f2 dα.
If we replace f1 and f2 in (6.21) by −f1 and −f2, the inequality is reversed, and the
equality is proved.
The proof of the other assertions of Theorem 6.12 are so similar that we omit
the details. In part (c), the point is that (by passing to refinements) we may restrict
ourselves to partitions which contain the point c, in approximating R
f dα.
6.13 Theorem. If f ∈ R(α) and g ∈ R(α) on [a, b], then
(a) fg ∈ R(α);
(b) |f| ∈ R(α) and



Rb
a
f dα


 ≤
Rb
a
|f| dα.
Proof. If we take ϕ(t) = t
2, Theorem 6.11 shows that f
2 ∈ R(α) if f ∈ R(α). The
identity
4fg = (f + g)
2 − (f − g)
2
completes the proof of (a).
If we take ϕ(t) = |t|, Theorem 6.11 shows similarly that |f| ∈ R(α). Choose
c = ±1, so that
c
Z
f dα ≥ 0.
Then




Z
f dα



 = c
Z
f dα =
Z
cf dα ≤
Z
|f| dα,
since cf ≤ |f|.PROPERTIES OF THE INTEGRAL 120
6.14 Definition. The unit step function I is defined by
I(x) = 
0 (x ≤ 0),
1 (x > 0).
6.15 Theorem. If a < s < b, f is bounded on [a, b], f is continuous at s, and α(x) =
I(x − s), then
Z b
a
f dα = f(s).
Proof. Consider partitions P = {x0, x1, x2, x3}, where x0 = a, and x1 = s < x2 <
x3 = b. Then
U(P, f, α) = M2, L(P, f, α) = m2.
Since f is continuous at s, we see that M2 and m2 converge to f(s) as x2 → s.
6.16 Theorem. Suppose cn ≥ 0 for 1, 2, 3, . . . , Σcn converges, (sn) is a sequence of
distinct points in (a, b), and
(6.22) α(x) = X∞
n=1
cnI(x − sn).
Let f be continuous on [a, b]. Then
(6.23) Z b
a
f dα =
X∞
n=1
f(sn).
Proof. The comparison test shows that the series (6.22) converges for every x. Its
sum α(x) is evidently monotonic, and α(a) = 0, α(b) = Σcn. (This is the type of
function that occurred in Remark 4.31.)
Let ε > 0 be given, and choose N so that
X∞
n=N+1
cn < ε.
Put
α1(x) = X
N
n=1
cnI(x − sn), α2(x) = X∞
n=N+1
cnI(x − sn).
By Theorems 6.12 and 6.15,
(6.24) Z b
a
f dα1 =
X
N
i=1
cnf(sn).PROPERTIES OF THE INTEGRAL 121
Since α2(b) − α2(a) < ε,
(6.25)





Z b
a
f dα2





≤ Mε,
where M = sup |f(x)|. Since α = α1 + α2, it follows from (6.24) and (6.25) that
(6.26)





Z b
a
f dα −
X
N
i=1
cnf(sn)





≤ Mε.
If we let N → ∞, we obtain (6.23).
6.17 Theorem. Assume α increases monotonically and α
′ ∈ R on [a, b]. Let f be a
bounded real function on [a, b]. Then f ∈ R(α) if and only if fα′ ∈ R. In that case
(6.27) Z b
a
f dα =
Z b
a
f(x)α
′
(x) dx.
Proof. Let ε > 0 be given and apply Theorem 6.6 to α
′
: There is a partition P =
{x0, . . . , xn} of [a, b] such that
(6.28) U(P, α
′
) − L(P, α
′
) < ε.
The mean value theorem furnishes points ti ∈ [xi−1, xi
] such that
∆αi = α
′
(ti
)∆xi
for i = 1, . . . , n. If si ∈ [xi−1, xi
], then
(6.29) Xn
i=1

α
′
(si
) − α
′
(ti
)

 ∆xi < ε,
by (6.28) and Theorem 6.7(b). Put M = sup |f(x)|. Since
Xn
i=1
f(si
)∆αi =
Xn
i=1
f(si
)α
′
(ti
)∆xi
,
it follows from (6.29) that
(6.30)





Xn
i=1
f(si
)∆αi −
Xn
i=1
f(si
)α
′
(si
)∆xi





≤ Mε.
In particular,
Xn
i=1
f(si
)∆αi ≤ U(P, fα′
) + Mε,PROPERTIES OF THE INTEGRAL 122
for all choices of si ∈ [xi−1, xi
], so that
U(P, f, α) ≤ U(P, fα′
) + Mε.
The same argument leads from (6.30) to
U(P, fα′
) ≤ U(P, f, α) + Mε.
Thus
(6.31)

U(P, f, α) − U(P, fα′
)

 ≤ Mε.
Now note that (6.28) remains true if P is replaced by any refinement. Hence
(6.31) remains true. We conclude that





Z b
a
f dα −
Z b
a
f(x)α
′
(x) dx





≤ Mε.
But ε is arbitrary. Hence
(6.32) Z b
a
f dα =
Z b
a
f(x)α
′
(x) dx,
for any bounded f. The equality of the lower integrals follows from (6.30) in exactly
the same way. The theorem follows.
6.18 Remark. The two preceding theorems illustrate the generality and flexibility
which are inherent in the Stieltjes process of integration. If α is a pure step function
[this is the name often given to functions of the form (6.22)], the integral reduces to
a finite or infinite series. If α has an integrable derivative, the integral reduces to
an ordinary Riemann integral. This makes it possible in many cases to study series
and integrals simultaneously, rather than separately.
To illustrate this point, consider a physical example. The moment of inertia of
a straight wire of unit length, about an axis through an endpoint, at right angles to
the wire, is
(6.33) Z1
0
x
2 dm
where m(x) is the mass contained in the interval [0, x]. If the wire is regarded as
having continuous density ρ, that is, if m′
(x) = ρ(x), then (6.33) turns into
(6.34) Z1
0
x
2
ρ(x) dx.
On the other hand, if the wire is composed of masses mi concentrated at pointsINTEGRATION AND DIFFERENTIATION 123
xi
, (6.33) becomes
(6.35) X
i
x
2
i mi
.
Thus (6.33) contains (6.34) and (6.35) as special cases, but it contains much more;
for instance, the case in which m is continuous but not everywhere differentiable.
6.19 Theorem (Change of Variable). Suppose ϕ is a strictly increasing continuous
function that maps an interval [A, B] onto [a, b]. Suppose α is monotonically increasing
on [a, b] and f ∈ R(α) on [a, b]. Define β and g on [A, B] by
(6.36) β(y) = α(ϕ(y)), g(y) = f(ϕ(y)).
Then g ∈ R(β) and
(6.37) Z B
A
g dβ =
Z b
a
f dα.
Proof. To each partition P = {x0, . . . , xn} of [a, b] corresponds a partition Q =
{y0, . . . , yn} of [A, B], so that xi = ϕ(yi
). All partitions of [A, B] are obtained in
this way. Since the values taken by f on [xi−1, xi
] are exactly the same as those
taken by g on [yi−1, yi
], we see that
(6.38) U(Q, g, β) = U(P, f, α), L(Q, g, β) = L(P, f, α).
Since f ∈ R(α), P can be chosen so that both U(P, f, α) and L(P, f, α) are close to
R
f dα. Hence (6.38) combined with Theorem 6.6, shows that g ∈ R(β) and that
(6.37) holds. This completes the proof.
Let us note the following special case: Take α(x) = x. Then β = ϕ. Assume
ϕ′ ∈ R on [A, B]. If Theorem 6.17 is applied to the left side of (6.37), we obtain
(6.39) Z b
a
f(x) dx =
Z B
A
f(ϕ(y))ϕ
′
(y) dy.
INTEGRATION AND DIFFERENTIATION
We still confine ourselves to real functions in this section. We shall show that inte￾gration and differentiation are, in a certain sense, inverse operations.
6.20 Theorem. Let f ∈ R on [a, b]. For a ≤ x ≤ b, put
F(x) = Zx
a
f(t) dt.
Then F is continuous on [a, b]; furthermore, if f is continuous at a point x0 of [a, b], then
F is differentiable at x0, and
F
′
(x0) = f(x0).INTEGRATION AND DIFFERENTIATION 124
Proof. Since f ∈ R, f is bounded. Suppose |f(t)| ≤ M for a ≤ t ≤ b. If a ≤ x <
y ≤ b, then
|F(y) − F(x)| =




Z y
x
f(t) dt




≤ M(y − x),
by Theorem 6.12(c) and (d). Given ε > 0, we see that
|F(y) − F(x)| < ε,
provided that |y − x| < ε/M. This proves continuity (and, in fact, uniform conti￾nuity) of F.
Now suppose f is continuous at x0. Given ε > 0, choose δ > 0 such that
|f(t) − f(x0)| < ε
if |t − x0|, and a ≤ t ≤ b. Hence, if
x0 − δ < s ≤ x0 ≤ t < x0 + δ and a ≤ s < t ≤ b,
we have, by Theorem 6.12(d),




F(t) − F(s)
t − s
− f(x0)



 =




1
t − s
Z t
s
[f(u) − f(x0)] du




< ε.
It follows that F
′
(x0) = f(x0).
6.21 Theorem (The Fundamental Theorem of Calculus). If f ∈ R on [a, b] and if
there is a differentiable function F on [a, b] such that F
′ = f, then
Z b
a
f(x) dx = F(b) − F(a).
Proof. Let ε > 0 be given. Choose a partition P = {x0, . . . , xn} of [a, b] so that
U(P, f) − L(P, f) < ε. The mean value theorem furnishes points ti ∈ [xi−1, xi
] such
that
F(xi
) − F(xi−1) = f(ti
)∆xi
for i = 1, . . . , n. Thus
Xn
i=1
f(ti
)∆xi = F(b) − F(a).
It now follows from Theorem 6.7(c) that





F(b) − F(a) − Z b
a
f(x) dx





< ε.
Since this holds for every ε > 0, the proof is complete.INTEGRATION AND DIFFERENTIATION 125
6.22 Theorem (Integration by Parts). Suppose F and G are differentiable functions on
[a, b], F
′ = f ∈ R, and G′ = g ∈ R. Then
Z b
a
F(x)g(x) dx = F(b)G(b) − F(a)G(a) − Z b
a
f(x)G(x) dx.
Proof. Put H(x) = F(x)G(x) and apply Theorem 6.21 to H and its derivative. Note
that H′ ∈ R by Theorem 6.13.
6.23 Definition. Let f1, . . . , fk be real functions on [a, b], and let f = (f1, . . . , fk)
be the corresponding mapping of [a, b] into Rk. If α increases monotonically on
[a, b], to say that f ∈ R(α) means that fj ∈ R(α) for j = 1, . . . , k. If this is the case,
we define
Z b
a
f dα =
 Z b
a
f1 dα, . . . ,
Z b
a
fk dα
!
.
In other words, R
f dα is the point in Rk whose jth coordinate is R
fj dα.
It is clear that parts (a), (c), and (e) of Theorem 6.12 are valid for these vector￾valued integrals; we simply apply the earlier results to each coordinate. The same
is true of Theorems 6.17, 6.20, and 6.21. To illustrate, we state the analogue of
Theorem 6.21.
6.24 Theorem. If f and F map [a, b] into Rk, if f ∈ R on [a, b], and if F
′ = f, then
Z b
a
f(t) dt = F(b) − F(a).
The analogue of Theorem 6.13(b) offers some new features, however, at least in
its proof.
6.25 Theorem. If f maps [a, b] into Rk and if f ∈ R(α) for some monotonically increas￾ing function α on [a, b], then |f| ∈ R(α), and
(6.40)





Z b
a
f dα





≤
Z b
a
|f| dα.
Proof. If f1, . . . , fk are the components of f, then
(6.41) |f| = (f
2
1 + · · · + f
2
k
)
1/2
.
By Theorem 6.11, each of the functions f
2
i
belongs to R(α); hence so does their
sum. Since x
2 is a continuous function of x, Theorem 4.17 shows that the square￾root function is continuous on [0,M], for every real M. If we apply Theorem 6.11
once more, (6.41) shows that |f| ∈ R(α).
To prove (6.40), put y = (y1, . . . , yk), where yj =
R
fj dα. Then we have y =RECTIFIABLE CURVES 126
R
f dα, and
|y|
2 =
Xy
2
j =
Xyj
Z
fj dα =
Z Xyjfj

dα.
By the Schwarz inequality,
(6.42) Xyjfj
(t) ≤ |y| |f(t)| (a ≤ t ≤ b);
hence Theorem 6.12(b) implies
(6.43) |y|
2 ≤ |y|
Z
|f| dα.
If y = 0, (6.40) is trivial. If y ̸= 0, division of (6.43) by |y| gives (6.40).
RECTIFIABLE CURVES
We conclude this chapter with a topic of geometric interest which provides us an
application of some of the preceding theory. The case k = 2 (i.e., the case of plane
curves) is of considerable importance in the study of analytic functions of a com￾plex variable.
6.26 Definition. A continuous mapping γ of an interval [a, b] into Rk is called a
curve in Rk. To emphasize the parameter interval [a, b], we may also say that γ is
a curve on [a, b].
• If γ is one-to-one, γ is called an arc.
• If γ(a) = γ(b), γ is said to be a closed curve.
It should be noted that we define a curve to be a mapping, not a point set. Of course,
with each curve γ in Rk, there is an associated subset of Rk, namely the range of
γ, but different curves may have the same range.
We associate to each partition P = {x0, . . . , xn} of [a, b] and to each curve γ on
[a, b] the number
Λ(P, γ) = Xn
i=1
|γ(xi
) − γ(xi−1)| .
The ith term in this sum is the distance (in Rk) between the points γ(xi−1) and
γ(xi
). Hence Λ(P, γ) is the length of the polygonal path with vertices at γ(x0),
γ(x1), . . . , γ(xn), in this order. As our partition becomes finer and finer, this poly￾gon approaches the range of γ more and more closely. This makes it seem reason￾able to define the length of γ as
Λ(γ) = sup Λ(P, γ),
where the supremum is taken over all partitions of [a, b].
If Λ(γ) < ∞, we say that γ is rectifiable.RECTIFIABLE CURVES 127
In certain cases, Λ(γ) is given by a Riemann integral. We shall prove this for
continuously differentiable curves, i.e., for curves γ whose derivative γ
′
is continu￾ous.
6.27 Theorem. If γ
′
is continuous on [a, b], then γ is rectifiable, and
Λ(γ) = Z b
a

γ
′
(t)

 dt.
Proof. If a ≤ xi−1 < xi ≤ b, then
|γ(xi
) − γ(xi−1)| =




Zxi
xi−1
γ
′
(t) dt




≤
Zxi
xi−1

γ
′
(t)

 dt.
Hence
Λ(P, γ) ≤
Z b
a

γ
′
(t)

 dt
for every partition P of [a, b]. Consequently,
Λ(γ) ≤
Z b
a

γ
′
(t)

 dt.
To prove the opposite inequality, let ε > 0 be given. Since γ
′
is uniformly
continuous on [a, b], there exists δ > 0 such that

γ
′
(s) − γ
′
(t)

 < ε if |s − t| < δ.
Let P = {x0, . . . , xn} be a partition of [a, b], with ∆xi < δ for all i. If xi−1 ≤ t ≤ xi
,
it follows that

γ
′
(t)

 ≤

γ
′
(xi
)

 + ε.
Hence
Zxi
xi−1

γ
′
(t)

 dt ≤

γ
′
(xi
)

 ∆xi + ε∆xi
=




Zxi
xi−1
[γ
′
(t) + γ
′
(xi
) − γ
′
(t)] dt




+ ε∆xi
≤




Zxi
xi−1
γ
′
(t) dt




+




Zxi
xi−1
[γ
′
(xi
) − γ
′
(t)] dt




+ ε∆xi
≤ |γ(xi
) − γ(xi−1)| + 2ε∆xi
.
If we add these inequalities, we obtain
Z b
a

γ
′
(t)

 dt ≤ Λ(P, γ) + 2ε(b − a) ≤ Λ(y) + 2ε(b − a).EXERCISES 128
Since ε was arbitrary,
Z b
a

γ
′
(t)

 dt ≤ Λ(y).
This completes the proof.
EXERCISES
6.1. Suppose α increases on [a, b], a ≤ x0 ≤ b, α is continuous at x0, f(x0) = 1, and f(x) = 0
if x ̸= x0. Prove that f ∈ R(α) and that R
f dα = 0.
6.2. Suppose f ≥ 0, f is continuous on [a, b], and Rb
a
f(x) dx = 0. Prove that f(x) = 0 for all
x ∈ [a, b]. (Compare this with Exercise 6.1.)
6.3. Define three functions β1, β2, β3 as follows: βj(x) = 0 if x < 0, βj(x) = 1 if x > 0 for
j = 1, 2, 3; and β1(0) = 0, β2(0) = 1, β3(0) = 1/2. Let f be a bounded function on [−1, 1].
(a) Prove that f ∈ R(β1) if and only if f(0+) = f(0) and that then
Z
f dβ1 = f(0).
(b) State and prove a similar result for β2.
(c) Prove that f ∈ R(β3) if and only if f is continuous at 0.
(d) If f is continuous at 0 prove that
Z
f dβ1 =
Z
f dβ2 =
Z
f dβ3 = f(0).
6.4. If f(x) = 0 for all irrational x, f(x) = 1 for all rational x, prove that f ∈/ R on [a, b] for any
a < b.
6.5. Suppose f is a bounded real function on [a, b] and f
2 ∈ R on [a, b]. Does it follow that
f ∈ R? Does the answer chance if we assume that f
3 ∈ R?
6.6. Let P be the Cantor set constructed in Theorem 2.44. Let f be a bounded real function on
[0, 1] which is continuous at every point outside P. Prove that f ∈ R on [0, 1]. Hint: P can
be covered by finitely many segments whose total length can be made as small as desired.
Proceed as in Theorem 6.10.
6.7. Suppose f is a real function on (0, 1] and f ∈ R on [c, 1] for every c > 0. Define
Z 1
0
f(x) dx = lim
c→0
Z 1
c
f(x) dx
if this limit exists (and is finite).
(a) If f ∈ R on [0, 1], show that this definition of the integral agrees with the old one.
(b) Construct a function f such that the above limit exists, although it fails to exist with |f|
in place of f.
6.8. Suppose f ∈ R on [a, b] for every b > a where a is fixed. Define
Z∞
a
f(x) dx = lim
b→∞ Z b
a
f(x) dx
if this limit exists (and is finite). In that case, we say that the integral on the left converges. If
it also converges after f has been replaced by |f|, it is said to converge absolutely.EXERCISES 129
Assume that f(x) ≥ 0 and that f decreases monotonically on [1,∞). Prove that
Z∞
1
f(x) dx
converges if and only if
X∞
n=1
f(n)
converges. (This is the so-called “integral test” for convergence of series.)
6.9. Show that integration by parts can sometimes be applied to the “improper” integrals
defined in Exercises 6.7 and 6.8. (State the appropriate hypotheses, formulate a theorem, and
prove it.) For instance show that
Z∞
0
cos x
1 + x
dx =
Z∞
0
sin x
(1 + x)
2
dx.
Show that one of these integrals converges absolutely, but that the other does not.
6.10. Let p and q be positive real numbers such that
1
p
+
1
q
= 1.
Prove the following statements.
(a) If u ≥ 0 and v ≥ 0, then
uv ≤
u
p
p
+
v
q
q
.
Equality holds if and only if u
p = v
q.
(b) If f ∈ R(α), g ∈ R(α), f ≥ 0, g ≥ 0, and
Z b
a
f
p dα = 1 =
Z b
a
g
q dα,
then
Z b
a
fg dα ≤ 1.
(c) If f and g are complex functions in R(α), then




Z
fg dα




≤
Z b
a
|f|
p
dα
1/p Z b
a
|g|
q
dα
1/q
.
This is H¨older’s inequality. When p = q = 2, it is usually called the Schwarz inequality.
(Note that Theorem 1.35 is a very special case of this.)
(d) Show that Holder’s inequality is also true for the “improper” integrals described in ¨
Exercises 6.7 and 6.8.
6.11. Let α be a fixed increasing function on [a, b]. For u ∈ R(α), define
∥u∥2 =
Z b
a
|u|
2
1/2
.
Suppose f, g, h ∈ R(α), and prove the triangle inequality
∥f − h∥2 ≤ ∥f − g∥2 + ∥g − h∥2
as a consequence of the Schwarz inequality, as in the proof of Theorem 1.37.EXERCISES 130
6.12. With the notations of Exercise 6.11, suppose f ∈ R(α) and ε > 0. Prove that there exists
a continuous function g on [a, b] such that ∥f − g∥2 < ε.
Hint: Let P = {x0, . . . , xn} be a suitable partition on [a, b], define
g(t) = xi − t
∆xi
f(xi−1) + t − xi−1
∆xi
f(xi)
if xi−1 ≤ t ≤ xi.
6.13. Define
f(x) = Zx+1
x
sin(t
2
) dt.
(a) Prove that |f(x)| < 1/x if x > 0.
Hint: Put t
2 = u and integrate by parts, to show that f(x) is equal to
cos(x
2
)
2x −
cos[(x + 1)
2
]
2(x + 1)
−
Z (x+1)
2
x2
cos u
4u3/2
du.
Replace cos u by −1.
(b) Prove that
2xf(x) = cos(x
2
) − cos[(x + 1)
2
] + r(x)
where |r(x)| < c/x and c is a constant.
(c) Find the upper and lower limits of xf(x) as x → ∞.
(d) Does R∞
0
sin(t
2
) dt converge?
6.14. Deal similarly with
f(x) = Zx+1
x
sin(e
t
) dt.
Show that
e
x
|f(x)| < 2
and that
e
x
f(x) = cos(e
x
) − e
−1
cos(e
x+1
) + r(x),
where |r(x)| < Ce−x for some constant C.
6.15. Suppose f is a real, continuously differentiable function on [a, b], f(a) = f(b) = 0, and
Z b
a
f
2
(x) dx = 1.
Prove that
Z b
a
xf(x)f
′
(x) dx = −
1
2
and that
Z b
a
[f
′
(x)]2 dx ·
Z b
a
x
2
f
2
(x) dx >
1
4
.
6.16. For 1 < s < ∞, define
ζ(s) = X∞
n=1
1
ns
.
(This is Riemann’s zeta function, of great importance in the study of the distribution of prime
numbers.) Prove that
(a) ζ(s) = s
Z∞
1
[x]
x
s+1
dx,EXERCISES 131
(b) ζ(s) = s
s − 1
− s
Z∞
1
x − [x]
x
s+1
dx,
where [x] denotes the greatest integer ≤ x.
Prove that the integral in (b) converges for all s > 0.
Hint: To prove (a), compute the difference between the integral over [1, N] and the Nth
partial sum of the series that defines ζ(s).
6.17. Suppose α increases monotonically on [a, b], g is continuous, and g(x) = G′
(x) for
a ≤ x ≤ b. Prove that
Z b
a
α(x)g(x) dx = G(b)α(b) − G(a)α(a) − Z b
a
G dα.
Hint: Take g real, without loss of generality. Given P = {x0, x1, . . . , xn}, choose ti ∈
(xi−1, xi) so that g(ti)∆xi = G(xi) − G(xi−1). Show that
Xn
i=1
α(xi)g(ti) ∆xi = G(b)α(b) − G(a)α(a) −Xn
i=1
G(xi−1) ∆αi.
6.18. Let γ1, γ2, γ3 be curves in the complex plane defined on [0, 2π] by
γ1(t) = e
it
, γ2(t) = e
2it
, γ3(t) = e
2πit sin(1/t)
.
Show that these curves have the same range, that γ1 and γ2 are rectifiable, that the length of
γ1 is 2π, that the length of γ2 is 4π, and that γ3 is not rectifiable.
6.19. Let γ1 be a curve in Rk defined on [a, b]; let ϕ be a continuous 1-1 mapping of [c, d]
into [a, b] such that ϕ(c) = a; and define γ2(s) = γ1(ϕ(s)). Prove that γ2 is an arc, a closed
curve, or a rectifiable curve if and only if the same is true of γ1. Prove that γ2 and γ1 have
the same length.Chapter 7
SEQUENCES AND SERIES OF
FUNCTIONS
In the present chapter we confine our attention to complex-valued functions (in￾cluding the real-valued ones, of course), although many of the theorems and proofs
which follow extend without difficulty to vector-valued functions, and even to
mappings into general metric spaces. We choose to stay within this simple frame￾work in order to focus attention on the most important aspects of the problems
that arise when limit processes are interchanged.
DISCUSSION OF THE MAIN PROBLEM
7.1 Definition. Suppose (fn)∞
n=1
is a sequence of functions defined on a set E, and
suppose that the sequence of numbers (fn(x)) converges for every x ∈ E. We can
then define a function f by
(7.1) f(x) = lim n→∞
fn(x) (x ∈ E).
Under these circumstances we say that (fn) converges on E and that f is the
limit, or the limit function, of (fn). Sometimes we shall use a more descriptive
terminology and shall say that “(fn) converges to f pointwise on E” if (7.1) holds.
Similarly, if Σfn(x) converges for every x ∈ E, and if we define
(7.2) f(x) = X∞
n=1
fn(x) (x ∈ E),
the function f is called the sum of the series Σfn.
The main problem which arises is to determine whether important properties
of functions are preserved under the limit operations (7.1) and (7.2). For instance,
if the functions fn are continuous, or differentiable, or integrable, is the same true
132DISCUSSION OF THE MAIN PROBLEM 133
of the limit function? What are the relations between f
′
n and f
′
, say, or between the
integrals of fn and that of f?
To say that f is continuous at a limit point x means
lim
t→x
f(t) = f(x).
Hence, to ask whether the limit of a sequence of continuous functions is continuous
is the same as to ask whether
(7.3) lim
t→x
lim n→∞
fn(t) = lim n→∞
lim
t→x
fn(t),
i.e., whether the order in which limit processes are carried out is immaterial. On
the left side of (7.3), we first set n → ∞, then t → x; on the right side, t → x first,
then n → ∞.
We shall now show by means of several examples that limit processes cannot
in general be interchanged without affecting the result. Afterward, we shall prove
that under certain conditions the order in which limit operations are carried out is
immaterial.
Our first example, and the simplest one, concerns a “double sequence.”
7.2 Example. For m = 1, 2, 3, . . . , n = 1, 2, 3, . . . , let
sm,n =
m
m + n
.
Then, for every fixed n,
lim m→∞
sm,n = 1,
so that
(7.4) lim n→∞
lim m→∞
sm,n = 1.
On the other hand, for every fixed m,
lim n→∞
sm,n = 0,
so that
(7.5) lim m→∞
lim n→∞
sm,n = 0.
7.3 Example. Let
fn(x) = x
2
(1 + x
2)n
(x real; n = 0, 1, 2, . . .),DISCUSSION OF THE MAIN PROBLEM 134
and consider
(7.6) f(x) = X∞
n=0
fn(x) = X∞
n=0
x
2
(1 + x
2)n
.
Since fn(0) = 0, we have f(0) = 0. For x ̸= 0, the last series in (7.6) is a convergent
geometric series with sum 1 + x
2 (Theorem 3.26). Hence
(7.7) f(x) = 
0 (x = 0),
1 + x
2 (x ̸= 0),
so that a convergent series of continuous functions may have a discontinuous sum.
7.4 Example. For m = 1, 2, 3, . . . , put
fm(x) = lim n→∞
(cos m!πx)
2n.
When m!x is an integer, fm(x) = 1. For all other values of x, fm(x) = 0. Now let
f(x) = lim m→∞
fm(x).
For irrational x, fm(x) = 0 for every m; hence f(x) = 0. For rational x, say x = p/q,
where p and q are integers, we see that m!x is an integer if m ≥ q, so that f(x) = 1.
Hence
(7.8) lim m→∞
lim n→∞
(cos m!πx)
2n =

0 (x irrational),
1 (x rational).
We have thus obtained an everywhere discontinuous limit function, which is
not Riemann-integrable (Exercise 6.4).
7.5 Example. Let
(7.9) fn(x) = sin nx √
n
(x real, n = 1, 2, 3, . . .),
and
f(x) = lim n→∞
fn(x) = 0.
Then f
′
(x) = 0, and
f
′
n(x) = √
n cos nx,
so that (f
′
n) does not converge to f
′
. For instance,
f
′
n(0) = √
n → +∞
as n → ∞, whereas f
′
(0) = 0.UNIFORM CONVERGENCE 135
7.6 Example. Let
(7.10) fn(x) = n
2
x(1 − x
2
)
n (0 ≤ x ≤ 1, n = 1, 2, 3, . . .).
For 0 < x ≤ 1, we have
lim n→∞
fn(x) = 0,
by Theorem 3.20(d). Since fn(0) = 0, we see that
(7.11) lim n→∞
fn(x) = 0 (0 ≤ x ≤ 1).
A simple calculation show that
Z1
0
x(1 − x
2
)
n dx =
1
2n + 2
.
Thus, in spite of (7.11),
Z1
0
fn(x) dx =
n
2
2n + 2
→ +∞
as n → ∞.
If, in (7.10), we replace n
2 by n, (7.11) still holds, but we now have
lim n→∞ Z1
0
fn(x) dx = lim n→∞
n
2n + 2
=
1
2
,
whereas
Z1
0
h
lim n→∞
fn(x)
i
dx = 0.
Thus the limit of the integral need not be equal to the integral of the limit, even if
both are finite.
After these examples, which show what can go wrong if limit processes are
interchanged carelessly, we now define a new mode of convergence, stronger than
pointwise convergence as defined in Definition 7.1, which will enable us to arrive
at positive results.
UNIFORM CONVERGENCE
7.7 Definition. We say that a sequence of functions (fn), n = 1, 2, 3, . . . , converges
uniformly on E to a function f if for every ε > 0 there is an integer N such that
n ≥ N implies
(7.12) |fn(x) − f(x)| ≤ ε
for all x ∈ E.UNIFORM CONVERGENCE 136
It is clear that every uniformly convergent sequence is pointwise convergent.
Quite explicitly, the difference between the two concepts is this: If (fn) converges
pointwise on E, then there exists a function f such that, for every ε > 0, and for
every x ∈ E, there is an integer N, depending on ε and on x, such that (7.12) holds
if n ≥ N; if (fn) converges uniformly on E, it is possible, fr each ε > 0 to find one
integer N which will do for all x ∈ E.
We say that the series Σfn(x) converges uniformly on E if the sequence (sn) of
partial sums defined by
Xn
i=1
fi
(x) = sn(x)
converges uniformly on E.
The Cauchy criterion for uniform convergence is as follows.
7.8 Theorem. The sequence of functions (fn), defined on E, converges uniformly on E if
and only if for every ε > 0 there exists an integer N such that m ≥ N, n ≥ N, x ∈ E
implies
(7.13) |fn(x) − fm(x)| ≤ ε.
Proof. Suppose (fn) converges uniformly on E, and let f be the limit function. Then
there is an integer N such that n ≥ N, x ∈ E implies
|fn(x) − f(x)| ≤
ε
2
,
so that
|fn(x) − fm(x)| ≤ |fn(x) − f(x)| + |f(x) − fm(x)| ≤ ε
if n ≥ N, m ≥ N, x ∈ E.
Conversely, suppose the Cauchy condition holds. By Theorem 3.11, the se￾quence (fn(x)) converges, for every x, to a limit which we may call f(x). Thus
the sequence (fn) converges on E, to f. We have to prove that the convergence is
uniform.
Let ε > 0 be given, and choose N such that (7.13) holds. Fix n, and let m → ∞
in (7.13). Since fm(x) → f(x) as m → ∞, this gives
(7.14) |fn(x) − f(x)| ≤ ε
for every n ≥ N and every x ∈ E, which completes the proof.
The following criterion is sometimes useful.
7.9 Theorem. Suppose
lim n→∞
fn(x) = f(x) (x ∈ E).UNIFORM CONVERGENCE AND CONTINUITY 137
Put
Mn = sup
x∈E
|fn(x) − f(x)| .
Then fn → f uniformly on E if and only if Mn → 0 as n → ∞.
Since this is an immediate consequence of Definition 7.7, we omit the details of
the proof.
For series, there is a very convenient test for uniform convergence, due to
Weierstrass.
7.10 Theorem. Suppose (fn) is a sequence of functions defined on E, and suppose
|fn(x)| ≤ Mn (x ∈ E, n = 1, 2, 3, . . .).
Then Σfn converges uniformly on E if ΣMn converges.
Note that the converse is not asserted (and is, in fact, not true).
Proof. If ΣMn converges, then, for arbitrary ε > 0,





Xm
i=1
fi
(x)





≤
Xm
i=n
Mi ≤ ε (x ∈ E),
provided m and n are large enough. Uniform convergence now follows from The￾orem 7.8.
UNIFORM CONVERGENCE AND CONTINUITY
7.11 Theorem. Suppose fn → f uniformly on a set E in a metric space. Let x be a limit
point of E, and suppose that
(7.15) lim
t→x
fn(t) = An (n = 1, 2, 3, . . .).
Then (An) converges, and
(7.16) lim
t→x
f(t) = lim n→∞
An.
In other words, the conclusion is that
(7.17) lim
t→x
lim n→∞
fn(t) = lim n→∞
lim
t→x
fn(t).
Proof. Let ε > 0 be given. By the uniform convergence of (fn), there exists N such
that n ≥ N, m ≥ N, t ∈ E imply
(7.18) |fn(t) − fm(t)| ≤ ε.UNIFORM CONVERGENCE AND CONTINUITY 138
Letting t → x in (7.18), we obtain
|An − Am| ≤ ε
for n ≥ N, m ≥ N, so that (An) is a Cauchy sequence and therefore converges, say
to A.
Next,
(7.19) |f(t) − A| ≤ |f(t) − fn(t)| + |fn(t) − An | + |An − A| .
We first choose n such that
(7.20) |f(t) − fn(t)| ≤
ε
3
for all t ∈ E (this is possible by uniform convergence), and such that
(7.21) |An − A| ≤
ε
3
.
Then, for this n, we choose a neighborhood V of x such that
(7.22) |fn(t) − An | ≤
ε
3
if t ∈ V ∩ E, t ̸= x.
Substituting the inequalities (7.20) to (7.22) into (7.19), we see that
|f(t) − A| ≤ ε,
provided t ∈ V ∩ E, t ̸= x. This is equivalent to (7.16).
7.12 Theorem. If (fn) is a sequence of continuous functions on E, and if fn → f uni￾formly on E, then f is is continuous on E.
This very important result is an immediate corollary of Theorem 7.11.
The converse is not true; that is, a sequence of continuous functions may con￾verge to a continuous function, although the convergence is not uniform. Exam￾ple 7.6 is of this kind (to see this, apply Theorem 7.9). But there is a case in which
we can assert the converse.
7.13 Theorem. Suppose K is compact, and
(a) (fn) is a sequence of continuous functions on K,
(b) (fn) converges pointwise to a continuous function f on K,
(c) fn(x) ≥ fn+1(x) for all x ∈ K, n = 1, 2, 3, . . . .
Then fn → f uniformly on K.UNIFORM CONVERGENCE AND CONTINUITY 139
Proof. Put gn = fn −f. Then gn is continuous, gn → 0 pointwise, and gn ≥ gn+1.
We have to prove that gn → 0 uniformly on K.
Let ε > 0 be given. Let Kn be the set of all x ∈ K with gn(x) ≥ ε. Since gn
is continuous, Kn is closed (Theorem 4.8), hence compact (Theorem 2.35). Since
gn ≥ gn+1, we have Kn ⊃ Kn+1. Fix x ∈ K. Since gn(x) → 0, we see that x ̸∈ Kn
if n is sufficiently large. Thus x ̸∈ T
Kn. In other words, T
Kn is empty. Hence KN
is empty for some N (Theorem 2.36). It follows that 0 ≤ gn(x) < ε for all x ∈ K
and for all n ≥ N. This proves the theorem.
Let us note that compactness is really needed here. For instance if
fn(x) = 1
nx + 1
(0 < x < 1; n = 1, 2, 3, . . .)
then fn(x) → 0 monotonically in (0, 1), but the convergence is not uniform.
7.14 Definition. If X is a metric space C (X) will denote the set of all complex￾valued, continuous, bounded functions with domain X.
[Note that boundedness is redundant if X is compact (Theorem 4.15). Thus
C (X) consists of all complex continuous functions on X if X is compact.]
We associate with each f ∈ C (X) its supremum norm
∥f∥ = sup
x∈X
|f(x)| .
Since f is assumed to be bounded, ∥f∥ < ∞. It is obvious that ∥f∥ = 0 only if
f(x) = 0 for every x ∈ X, that is, only if f = 0. If h = f + g, then
|h(x)| ≤ |f(x)| + |g(x)| ≤ ∥f∥ + ∥g∥
for all x ∈ X; hence
∥f + g∥ ≤ ∥f∥ + ∥g∥ .
If we define the distance between f ∈ C (X) and g ∈ C (X) to be ∥f − g∥, it
follows that Axioms 2.15 for a metric are satisfied.
We have thus made C (X) into a metric space.
Theorem 7.9 can be rephrased as follows:
A sequence (fn) converges to f with respect to the metric of C (X) if
and only if fn → f uniformly on X.
Accordingly, closed subsets of C (X) are sometimes called uniformly closed, the
closure of a set A ⊂ C (X) is called its uniform closure, and so on.
7.15 Theorem. The above metric makes C (X) into a complete metric space.
Proof. Let (fn) be a Cauchy sequence C (X). This means that to each ε > 0 cor￾responds an N such that ∥fn − fm∥ < ε if n ≥ N and m ≥ N. It follows (byUNIFORM CONVERGENCE AND INTEGRATION 140
Theorem 7.8) that there is a function f with domain X to which (fn) converges uni￾formly. By Theorem 7.12, f is continuous. Moreover, f is bounded, since there is an
n such that |f(x) − fn(x)| < 1 for all x ∈ X, and fn is bounded.
Thus f ∈ C (X), and since fn → f uniformly on X, we have ∥f − fn∥ → 0 as
n → ∞.
UNIFORM CONVERGENCE AND INTEGRATION
7.16 Theorem. Let α be monotonically increasing on [a, b]. Suppose fn ∈ R(α) on
[a, b], for n = 1, 2, 3, . . . , and suppose fn → f uniformly on [a, b]. Then f ∈ R(α) on
[a, b], and
(7.23) Z b
a
f dα = lim n→∞ Z b
a
fn dα.
(The existence of the limit is part of the conclusion.)
Proof. It suffices to prove this for real fn. Put
(7.24) εn = sup |fn(x) − f(x)| ,
the supremum being taken over a ≤ x ≤ b. Then
fn − εn ≤ f ≤ fn + εn,
so that the upper and lower integrals of f (see Definition 6.2) satisfy
(7.25) Z b
a
(fn − εn)dα ≤
Z
f dα ≤
Z
f dα ≤
Z b
a
(fn + εn) dα.
Hence
0 ≤
Z
f dα −
Z
f dα ≤ 2εn[α(b) − α(a)].
Since εn → 0 as n → ∞ (Theorem 7.9), the upper and lower integrals of f are
equal.
Thus f ∈ R(α). Another application of (7.25) now yields
(7.26)





Z b
a
f dα −
Z b
a
fn dα





≤ εn[α(b) − α(a)].
Thus implies (7.23).
Corollary. If fn ∈ R(α) on [a, b] and if
f(x) = X∞
n=1
fn(x) (a ≤ x ≤ b),UNIFORM CONVERGENCE AND DIFFERENTIATION 141
the series converging uniformly on [a, b], then
Z b
a
f dα =
X∞
n=1
Z b
a
fn dα.
In other words the series may be integrated term by term.
UNIFORM CONVERGENCE AND DIFFERENTIATION
We have already seen, in Example 7.5, that uniform convergence of (fn) implies
nothing about the sequence (f
′
n). Thus stronger hypotheses are required for the
assertion that f
′
n → f
′
if fn → f.
7.17 Theorem. Suppose (fn) is a sequence of functions, differentiable on [a, b] and such
that (fn(x0)) converges for some point x0 on [a, b]. If (f
′
n) converges uniformly on [a, b],
then (fn) converges uniformly on [a, b], to a function f, and
(7.27) f
′
(x) = lim n→∞
f
′
n(x) (a ≤ x ≤ b).
Proof. Let ε > 0 be given. Choose N such that n ≥ N, m ≤ N, implies
(7.28) |fn(x0) − fm(x0)| <
ε
2
and
(7.29)

f
′
n(t) − f
′
m(t)

 <
ε
2(b − a)
(a ≤ t ≤ b).
If we apply the mean value theorem 5.19 to the function fn − fm, (7.29) shows
that
(7.30) |fn(x) − fm(x) − fn(t) + fm(t)| ≤
|x − t| ε
2(b − a)
≤
ε
2
for any x and t on [a, b], if n ≥ N, m ≥ N. The inequality
|fn(x) − fm(x)| ≤ |fn(x) − fm(x) − fn(x0) + fm(x0)| + |fn(x0) − fm(x0)|
implies, by (7.28) and (7.30), that
|fn(x) − fm(x)| < ε (a ≤ x ≤ b, n ≥ N, m ≥ N),
so that (fn) converges uniformly on [a, b]. Let
f(x) = lim n→∞
fn(x) (a ≤ x ≤ b).UNIFORM CONVERGENCE AND DIFFERENTIATION 142
Let us now fix a point x on [a, b] and define
(7.31) ϕn(t) = fn(t) − fn(x)
t − x
, ϕ(t) = f(t) − f(x)
t − x
for a ≤ t ≤ b, t ̸= x. Then
(7.32) lim
t→x
ϕn(t) = f
′
n(x) (n = 1, 2, 3, . . .).
The first inequality in (7.30) shows that
|ϕn(t) − ϕm(t)| ≤
ε
2(b − a)
(n ≥ N, m ≥ N),
so that (ϕn) converges uniformly, for t ̸= x. Since (fn) converges to f, we conclude
from (7.31) that
(7.33) lim n→∞
ϕn(t) = ϕ(t)
uniformly for a ≤ t ≤ b, t ̸= x.
If we now apply Theorem 7.11 to (ϕn), (7.32) and (7.33) show that
lim
t→x
ϕ(t) = lim n→∞
f
′
n(x);
and this is (7.27), by definition of ϕ(t).
Remark: If the continuity of the functions f
′
n is assumed in addition to the above
hypotheses, then a much shorter proof of (7.27) can be based on Theorem 7.16 and
the fundamental theorem of calculus.
7.18 Theorem. There exists a real continuous function on the real line which is nowhere
differentiable.
Proof. Define
(7.34) φ(x) = |x| (−1 ≤ x ≤ 1)
and extend the definition of φ(x) to all real x by requiring that
(7.35) φ(x + 2) = φ(x).
Then, for all s and t,
(7.36) |φ(s) − φ(t)| ≤ |s − t|.
In particular, φ is continuous on R1. Define
(7.37) f(x) = X∞
n=0

3
4
n
φ(4
nx).EQUICONTINUOUS FAMILIES OF FUNCTIONS 143
Since 0 ≤ φ ≤ 1, Theorem 7.10 shows that the series (7.37) converges uniformly
on R1. By Theorem 7.12, f is continuous on R1.
Now fix a real number x and a positive integer m. Put
(7.38) δm = ±
1
2
· 4
−m
where the sign is so chosen that no integer lies between 4mx and 4m(x + δm). This
can be done, since 4m |δm| = 1/2. Define
(7.39) γn =
φ(4
n(x + δm)) − φ(4
nx)
δm
.
When n > m, then 4
nδm is an even integer, so that γn = 0. When 0 ≤ n ≤ m,
(7.36) implies that |γn | ≤ 4
n.
Since |γm| = 4m, we conclude that




f(x + δm) − f(x)
δm



 =





Xm
n=0

3
4
n
γn





≥ 3m −
mX−1
n=0
3
n
=
1
2
(3m + 1).
As m → ∞, δm → 0. It follows that f is not differentiable at x.
EQUICONTINUOUS FAMILIES OF FUNCTIONS
In Theorem 3.6 we saw that every bounded sequence of complex numbers contains
a convergent subsequence, and the question arises whether something similar is
true for sequences of functions. To make the question more precise, we shall define
two kinds of boundedness.
7.19 Definition. Let (fn) be a sequence of functions defined on a set E.
We say that (fn) is pointwise bounded on E if the sequence (fn(x)) is bounded
for every x ∈ E, that is, if there exists a finite-valued function ϕ defined on E such
that
|fn(x)| < ϕ(x) (x ∈ E, n = 1, 2, 3, . . .).
We say that (fn) is uniformly bounded on E if there exists a number M such that
|fn(x)| < M (x ∈ E, n = 1, 2, 3, . . .).
Now if (fn) is pointwise bounded on E and E1 is a countable subset of E, it
is always possible to find a subsequence (fnk
) such that (fnk
(x)) converges forEQUICONTINUOUS FAMILIES OF FUNCTIONS 144
every x ∈ E1. This can be done by the diagonal process which is used in the proof
of Theorem 7.23.
However, even if (fn) is a uniformly bounded sequence of continuous func￾tions on a compact set E, there need not exist a subsequence which converges
pointwise on E. In the following example, this would be quite troublesome to
prove with the equipment which we have at hand so far, but the proof is simple if
we appeal to a theorem from Chap. 11.
7.20 Example. Let
fn(x) = sin nx (0 ≤ x ≤ 2π, n = 1, 2, 3, . . .).
Suppose there exists a sequence (nk) such that (sin nkx) converges, for every x ∈
[0, 2π]. In that case we must have
lim
k→∞
(sin nkx − sin nk+1x) = 0 (0 ≤ x ≤ 2π);
hence
(7.40) lim
k→∞
(sin nkx − sin nk+1x)
2 = 0 (0 ≤ x ≤ 2π).
By Lebesgue’s theorem concerning integration of boundedly convergent sequences
(Theorem 11.32), (7.40) implies
(7.41) lim
k→∞ Z2π
0
(sin nkx − sin nk+1x)
2 dx = 0.
But a simple calculation shows that
Z2π
0
(sin nkx − sin nk+1x)
2 dx = 2π,
which contradicts (7.41).
Another question is whether every convergent sequence contains a uniformly
convergent subsequence. Our next example will show that this need not be so,
even if the sequence is uniformly bounded on a compact set. (Example 7.6 shows
that a sequence of bounded functions may converge without being uniformly
bounded; but it is trivial to see that uniform convergence of a sequence of bounded
functions implies uniform boundedness.)
7.21 Example. Let
fn(x) = x
2
x
2 + (1 − nx)
2
(0 ≤ x ≤ 1, n = 1, 2, 3, . . .).EQUICONTINUOUS FAMILIES OF FUNCTIONS 145
Then |fn(x)| ≤ 1, so that (fn) is uniformly bounded on [0, 1]. Also
lim n→∞
fn(x) = 0 (0 ≤ x ≤ 1),
but
fn

1
n

= 1 (n = 1, 2, 3, . . .),
so that no subsequence can converge uniformly on [0, 1].
The concept which is needed in this connection is that of equicontinuity; it is
given in the following definition.
7.22 Definition. A family F of complex functions f defined on a set E in a metric
space X is said to be equicontinuous on E if for every ε > 0 there exists δ > 0 such
that
|f(x) − f(y)| < ε
whenever d(x, y) < δ, x ∈ E, y ∈ E, and f ∈ F. Here d denotes the metric of X.
It is clear that every member of an equicontinuous family is uniformly contin￾uous.
The sequence of Example 7.21 is not equicontinuous.
Theorems 7.24 and 7.25 will show that there is a very close relation between
equicontinuity, on the one hand, and uniform convergence of sequences of contin￾uous functions, on the other. But first we describe a selection process which has
nothing to do with continuity.
7.23 Theorem. If (fn) is a pointwise bounded sequence of complex functions on a count￾able set E, then (fn) has a subsequence (fnk
) such that (fnk
(x)) converges for every
x ∈ E.
Proof. Let (xi
),i = 1, 2, 3, . . . , be the points of E, arranged in a sequence. Since
(fn(x1)) is bounded, there exists a subsequence, which we shall denote by (f1,k),
such that (f1,k(x1)) converges as k → ∞.
Let us now consider sequences S1, S2, S3, . . . , which we represent by the array
S1 : f1,1 f1,2 f1,3 f1,4 . . .
S2 : f2,1 f2,2 f2,3 f2,4 . . .
S3 : f3,1 f3,2 f3,3 f3,4 . . .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
and which have the following properties:
(a) Sn is a subsequence of Sn−1, for n = 2, 3, 4, . . . .
(b) (fn,k(xn)) converges, as k → ∞ (the boundedness of (fn(xn)) makes it pos￾sible to choose Sn in this way);EQUICONTINUOUS FAMILIES OF FUNCTIONS 146
(c) The order in which the functions appear is the same in each sequence; i.e., if
one function precedes another in S1, they are in the same relation in every
Sn, until one or the other is deleted. Hence, when going from one row in the
above array to the next below, functions may move to the left but never to
the right.
We now go down the diagonal of the array; i.e., we consider the sequence
S : f1,1 f2,2 f3,3 f4,4 · · · .
By (c), the sequence S (except possible its first n − 1 terms) is a subsequence of Sn,
for n = 1, 2, 3, . . . . Hence (b) implies that (fn,n(xi
)) converges, as n → ∞, for
every xi ∈ E.
7.24 Theorem. If K is a compact metric space, if fn ∈ C (K) for n = 1, 2, 3, . . . , and if
(fn) converges uniformly on K, then (fn) is equicontinuous on K.
Proof. Let ε > 0 be given. Since (fn) converges uniformly, there is an integer N
such that
(7.42) ∥fn − fN∥ < ε (n > N).
(See Definition 7.14.) Since continuous functions are uniformly continuous on
compact sets, there is a δ > 0 such that
(7.43) |fi
(x) − fi
(y)| < ε
if 1 ≤ i ≤ N and d(x, y) < δ.
If n > N and d(x, y) < δ, it follows that
|fn(x) − fn(y)| ≤ |fn(x) − fN(x)| + |fN(x) − fN(y)| + |fN(y) − fn(y)| < 3ε.
In conjunction with (7.43), this proves the theorem.
7.25 Theorem. If K is compact, if fn ∈ C (K) for n = 1, 2, 3 . . . , and if (fn) is pointwise
bounded and equicontinuous on K, then
(a) (fn) is uniformly bounded on K,
(b) (fn) contains a uniformly convergent subsequence.
Proof.
(a) Let ε > 0 be given and choose δ > 0, in accordance with Definition 7.22, so
that
(7.44) |fn(x) − fn(y)| < ε
for all n, provided that d(x, y) < δ..THE STONE-WEIERSTRASS THEOREM 147
Since K is compact, there are finitely many points p1, . . . , pr in K such
that to every x ∈ K corresponds at least one pi with d(x, pi
) < δ. Since (fn)
is pointwise bounded, there exists Mi < ∞ such that |fn(pi
)| < Mi
for all n.
If M = max(M1, . . . ,Mr), then |fn(x)| < M + ε for every x ∈ K. This proves
(a).
(b) Let E be a countable dense subset of K. (For the existence of such a set E, see
Exercise 2.25.) Theorem 7.23 shows that (fn) has a subsequence (fni
) such
that (fni
(x)) converges for every x ∈ E.
Put fni = gi
, to simplify the notation. We shall prove that (gi
) converges
uniformly on K.
Let ε > 0, and pick δ > 0 as in the beginning of this proof. Let V(x, δ) be
the set of all y ∈ K with d(x, y) < δ. Since E is dense in K and K is compact,
there are finitely many points x1, . . . , xm in E such that
(7.45) K ⊂ V(x1, δ) ∪ · · · ∪ V(xm, δ).
Since (gi
(x)) converges for every x ∈ E, there is an integer N such that
(7.46)

gi
(xs) − gj
(xs)

 < ε
whenever i ≥ N, j ≥ N, 1 ≤ s ≤ m.
If x ∈ K, (7.45) shows that x ∈ V(xs, δ) for some s, so that
|gi
(x) − gi
(xs)| < ε
for every i. If i ≥ N and j ≥ N, it follows from (7.46) that

gi
(x) − gj
(x)

 ≤ |gi
(x) − gi
(xs)| +

gi
(xs) − gj
(xs)

 +

gj
(xs) − gj
(x)


< 3ε.
This completes the proof.
THE STONE-WEIERSTRASS THEOREM
7.26 Theorem. If f is a continuous complex function on [a, b], there exists a sequence of
polynomials Pn such that
lim n→∞
Pn(x) = f(x)
uniformly on [a, b]. If f is real, then Pn may be taken real.
This is the form in which the theorem was originally discovered by Weierstrass.
Proof. We may assume, without loss of generality, that [a, b] = [0, 1]. We may also
assume that f(0) = f(1) = 0. For if the theorem is proved for this case, consider
g(x) = f(x) − f(0) − x[f(1) − f(0)] (0 ≤ x ≤ 1).THE STONE-WEIERSTRASS THEOREM 148
Here g(0) = g(1) = 0, and if g can be obtained as the limit of a uniformly conver￾gent sequence of polynomials, it is clear that the same is true for f, since f − g is a
polynomial.
Furthermore, we define f(x) to be zero for x outside [0, 1]. Then f is uniformly
continuous on the whole line.
We put
(7.47) Qn(x) = cn(1 − x
2
)
n (n = 1, 2, 3, . . .),
where cn is chosen so that
(7.48) Z1
−1
Qn(x) dx = 1 (n = 1, 2, 3, . . .).
We need some information about the order of magnitude of cn. Since
Z1
−1
(1 − x
2
)
n dx = 2
Z1
0
(1 − x
2
)
n dx ≥ 2
Z1/
√
n
0
(1 − x
2
)
n dx
≥ 2
Z1/
√
n
0
(1 − nx2
) dx
=
4
3
√
n
>
1
√
n
,
it follows from (7.48) that
(7.49) cn <
√
n.
The inequality (1 − x
2)
n ≥ 1 − nx2 which we used above is easily shown to be
true by considering the function
(1 − x
2
)
n − 1 + nx2
which is zero at x = 0 an whose derivative is positive in (0, 1).
For any δ > 0, (7.49) implies
(7.50) Qn(x) ≤
√
n(1 − δ
2
)
n (δ ≤ |x| ≤ 1),
so that Qn → 0 uniformly in δ ≤ |x| ≤ 1.
Now set
(7.51) Pn(x) = Z1
−1
f(x + t)Qn(t) dt (0 ≤ x ≤ 1).THE STONE-WEIERSTRASS THEOREM 149
Our assumptions about f show, by a simple change of variable, that
Pn(x) = Z1−x
−x
f(x + t)Qn(t) dt =
Z1
0
f(t)Qn(t − x) dt,
and the last integral is clearly a polynomial in x. Thus (Pn) is a sequence of poly￾nomials, which are real if f is real.
Given ε > 0, we choose δ > 0 such that |y − x| < δ implies
|f(y) − f(x)| <
ε
2
.
Let M = sup |f(x)|. Using (7.48), (7.50), and the fact that Qn(x) ≥ 0, we see that
for 0 ≤ x ≤ 1,
|Pn(x) − f(x)| =





Z1
−1
[f(x + t) − f(x)]Qn(t) dt





≤
Z1
−1
|f(x + t) − f(x)| Qn(t) dt
≤ 2MZ −δ
−1
Qn(t) dt +
ε
2
Zδ
−δ
Qn(t) dt + 2MZ1
δ
Qn(t) dt
≤ 4M√
n(1 − δ
2
)
n +
ε
2
< ε
for all large enough n, which proves the theorem.
It is instructive to sketch the graphs of Qn for a few values of n; also, note that
we needed uniform continuity of f to deduce uniform convergence of (Pn).
In the proof of Theorem 7.32 we shall not need the full strength of Theorem 7.26,
but only the following special case, which we state as a corollary.
7.27 Corollary. For every interval [−a, a] there is a sequence of real polynomials Pn such
that Pn(0) = 0 and such that
lim n→∞
Pn(x) = |x|
uniformly on [−a, a].
Proof. By Theorem 7.26, there exists a sequence (P
∗
n) of real polynomials which
converges to |x| uniformly on [−a, a]. In particular, P
∗
n(0) → 0 as n → ∞. The
polynomials
Pn(x) = P
∗
n(x) − P
∗
n(0) (n = 1, 2, 3, . . .)
have desired properties.
We shall now isolate those properties of the polynomials which make the Weier￾strass theorem possible.THE STONE-WEIERSTRASS THEOREM 150
7.28 Definition. A family A of complex functions defined on a set E is said to be
an algebra if (i) f + g ∈ A , (ii) fg ∈ A , and (iii) cf ∈ A for all f ∈ A , g ∈ A and
all complex constants c, that is, if A is closed under addition, multiplication, and
scalar multiplication. We shall also have to consider algebras of real functions; in
this case, (iii) is of course only required to hold for all real c.
If A has the property that f ∈ A whenever fn ∈ A (n = 1, 2, 3, . . . ) and fn → f
uniformly on E, then A is said to be uniformly closed.
Let B be the set of all functions which are limits of uniformly convergent se￾quence of members of A . Then B is called the uniform closure of A . (See Defini￾tion 7.14.)
For example, the set of all polynomials is an algebra, and the Weierstrass the￾orem may be stated by saying that the set of continuous functions on [a, b] is the
uniform closure of the set of polynomials on [a, b].
7.29 Theorem. Let B be the uniform closure of an algebra A of bounded functions. Then
B is a uniformly closed algebra.
Proof. If f ∈ B and g ∈ B, there exist uniformly convergent sequences (fn),(gn)
such that fn → f, gn → g and fn ∈ A , gn ∈ A . Since we are dealing with
bounded functions, it is easy to show that
fn + gn → f + g, fngn → fg, cfn → cf,
where c is any constant, the convergence being uniform in each case. Hence
f + g ∈ B, fg ∈ B, and cf ∈ B, so that B is an algebra. By Theorem 2.27, B
is (uniformly) closed.
7.30 Definition. Let A be a family of functions on a set E. Then A is said to
separate points on E if to every pair of distinct points x1, x2 ∈ E there corresponds a
function f ∈ A such that f(x1) ̸= f(x2).
If to each x ∈ E there corresponds a function g ∈ A such that g(x) ̸= 0, we say
that A vanishes at no point of E.
The algebra of all polynomials in one variable clearly has these properties on
R1. An example of an algebra which does not separate points is the set of all even
polynomials, say on [−1, 1], since f(−x) = f(x) for every even function f.
The following theorem will illustrate these concepts further.
7.31 Theorem. Suppose A is an algebra of functions on a set E, A separates points on
E, and A vanishes at no point of E. Suppose x1, x2 are distinct points of E, and c1, c2 are
constants (real if A is a real algebra). Then A contains a function f such that
f(x1) = c1, f(x2) = c2.
Proof. The assumptions show that A contains functions g, h, and k such that
g(x1) ̸= g(x2), h(x1) ̸= 0, k(x2) ̸= 0.THE STONE-WEIERSTRASS THEOREM 151
Put
u = gk − g(x1)k, v = gh − g(x2)h.
Then u ∈ A , v ∈ A , u(x1) = v(x2) = 0, u(x2) ̸= 0, and v(x1) ̸= 0. Therefore
f =
c1v
v(x1)
+
c2u
u(x2)
has the desired properties.
We now have all the material needed for Stone’s generalization of the Weier￾strass theorem.
7.32 Theorem. Let A be an algebra of real continuous functions on a compact set K. If
A separates points on K and if A vanishes at no point of K, then the uniform closure B
of A consists of all real continuous functions on K.
We shall divide the proof into four steps.
STEP 1 If f ∈ B, then |f| ∈ B.
Proof. Let
(7.52) a = sup |f(x)| (x ∈ K)
and let ε > 0 be given. By Corollary 7.27 there exist real numbers c1, . . . , cn
such that
(7.53)





Xn
i=1
ciy
i − |y|





< ε (−a ≤ y ≤ a).
Since B is an algebra, the function
g =
Xn
i=1
cif
i
is a member of B. By (7.52) and (7.53), we have

g(x) − |f(x)|

 < ε (x ∈ K).
Since B is uniformly closed, this shows that |f| ∈ B.
STEP 2 If f ∈ B and g ∈ B, then max(f, g) ∈ B and min(f, g) ∈ B.
By max (f, g) we mean the function h defined by
h(x) = 
f(x) if f(x) ≥ g(x),
g(x) if f(x) < g(x),
and min(f, g) is defined likewise.THE STONE-WEIERSTRASS THEOREM 152
Proof. Step 2 follows from step 1 and identities
max(f, g) = f + g
2
+
|f − g|
2
,
min(f, g) = f + g
2
−
|f − g|
2
.
By iteration, the result can of course be extended to any finite set of func￾tions: If f1, . . . , fn ∈ B, then max(f1, . . . , fn) ∈ B and min(f1, . . . , fn) ∈ B.
STEP 3 Given a real function f, continuous on K, a point x ∈ K, and ε > 0, there exists a
function gx ∈ B such that gx(x) = f(x) and
(7.54) gx(t) > f(t) − ε (t ∈ K).
Proof. Since A ⊂ B and A satisfies the hypotheses of Theorem 7.31 so does
B. Hence, for every y ∈ K, we can find a function hy ∈ B such that
(7.55) hy(x) = f(x), hy(y) = f(y).
By the continuity of hy there exists an open set Jy, containing y, such that
(7.56) hy(t) > f(t) − ε (t ∈ Jy).
Since K is compact, there is a finite set of points y1, . . . , yn such that
(7.57) K ⊂ Jy1 ∪ · · · ∪ Jyn .
Put
gx = max(hy1
, . . . , hyn ).
By step 2, gx ∈ B, and the relations (7.55) to (7.57) show that gx has the other
required properties.
STEP 4 Given a real function f, continuous on K, and ε > 0, there exists a function h ∈ B
such that
(7.58) |h(x) − f(x)| < ε (x ∈ K).
Since B is uniformly closed, this statement is equivalent to the conclusion
of the theorem.
Proof. Let us consider the functions gx, for each x ∈ K constructed in step 3.
By the continuity of gx, there exist open sets Vx containing x, such that
(7.59) gx(t) < f(t) + ε (t ∈ Vx).
Since K is compact, there exists a finite set of points x1, . . . , xm such that
(7.60) K ⊂ Vx1 ∪ · · · ∪ Vxm.EXERCISES 153
Put
h = min(gx1
, . . . , gxm).
By step 2, h ∈ B, and (7.54) implies
(7.61) h(t) > f(t) − ε (t ∈ K),
whereas (7.59) and (7.60) imply
(7.62) h(t) < f(t) + ε (t ∈ K).
Finally, (7.58) follows from (7.61) and (7.62).
Theorem 7.32 does not hold for complex algebras. A counterexample is given in
Exercise 7.21. However, the conclusion of the theorem does hold, even for complex
algebras, if an extra condition is imposed on A , namely, that A be self-adjoint. This
means that for every f ∈ A its complex conjugate f also belong to A ; f is defined
by f(x) = f(x).
7.33 Theorem. Suppose A is a self-adjoint algebra of complex continuous functions on a
compact set K, A separates points on K, and A vanishes at no point of K. Then the uniform
closure B of A consists of all complex continuous functions on K. In other words, A is
dense C (K).
Proof. Let AR be the set of all real functions on K which belong to A .
If f ∈ A and f = u + iv with u, v real, then 2u = f + f and, since A is self￾adjoint, we see that u ∈ AR. If x1 ̸= x2, there exists f ∈ A such that f(x1) = 1,
f(x2) = 0; hence 0 = u(x2) ̸= u(x1) = 1, which shows that AR separates points on
K. If x ∈ K, then g(x) ̸= 0 for some g ∈ A , and there is a complex number such
that λg(x) > 0; if f = λg, f = u + iv, it follows that u(x) > 0; hence AR vanishes at
no point of K.
Thus AR satisfies the hypotheses of Theorem 7.32. It follows that every real
continuous function on K lies in the uniform closure of AR hence lies in B. If f is
a complex continuous function on K, f = u + iv, then u ∈ B, v ∈ B, hence f ∈ B.
This completes the proof.
EXERCISES
7.1. Prove that every uniformly convergent sequence of bounded functions is uniformly
bounded.
7.2. If (fn) and (gn) converge uniformly on a set E, prove that (fn + gn) converges uniformly
on E. If, in addition, (fn) and (gn) are sequences of bounded functions, prove that (fngn)
converges uniformly on E.
7.3. Construct sequences (fn),(gn) which converge uniformly on some set E, but such that
(fngn) does not converge uniformly on E (of course, (fngn) must converge on E).EXERCISES 154
7.4. Consider
f(x) = X∞
n=1
1
1 + n2x
.
For what values of x does the series converge absolutely? On what intervals does it converge
uniformly? On what intervals does it fail to converge uniformly? Is f continuous wherever
the series converges? Is f bounded?
7.5. Let
fn(x) =



0
￾
x < 1
n+1

,
sin2 π
x
￾
1
n+1 ≤ x ≤ 1
n

,
0
￾
1
n < x
.
Show that (fn) converges to a continuous function, but not uniformly. Use the series Σfn to
show that absolute convergence, even for all x, does not imply uniform convergence.
7.6. Prove that the series
X∞
n=1
(−1)
n x
2 + n
n2
converges uniformly in every bounded interval, but does not converge absolutely for any
value of x.
7.7. For n = 1, 2, 3, . . . , x real, put
fn(x) = x
1 + nx2
.
Show that (fn) converges uniformly to a function f, and that the equation
f
′
(x) = limn→∞
f
′
n(x)
is correct if x ̸= 0, but false if x = 0.
7.8. If
I(x) = 
0 (x ≤ 0),
1 (x > 0),
if (xn) is a sequence of distinct points of (a, b), and if Σ |cn | converges, prove that the series
f(x) = X∞
n=1
cnI(x − xn) (a ≤ x ≤ b)
converges uniformly, and that f is continuous for every x ̸= xn.
7.9. Let (fn) be a sequence of continuous functions which converges uniformly to a function
f on a set E. Prove that
limn→∞
fn(xn) = f(x)
for every sequence of points xn ∈ E such that xn → x, and x ∈ E. Is the converse of this
true?
7.10. Letting (x) denote the factorial part of the real number x (see Exercise 4.16 for the defi￾nition), consider the function
f(x) = X∞
n=1
(nx)
n2
(x real).
Find all discontinuities of f, and show that they form a countable dense set. Show that f is
nevertheless Riemann-integrable on every bounded interval.
7.11. Suppose (fn),(gn) are defined on E, EXERCISES 155
(a) Σfn has uniformly bounded partial sums;
(b) gn → 0 uniformly on E;
(c) g1(x) ≥ g2(x) ≥ g3(x) ≥ . . . for every x ∈ E.
Prove that Σfngn converges uniformly on E. Hint: Compare with Theorem 3.42.
7.12. Suppose g and fn (n = 1, 2, 3, . . . ) are defined on (0,∞), are Riemann-integrable on [t, T]
whenever 0 < t < T < ∞, |fn | ≤ g, fn → f uniformly on every compact subset of (0,∞),
and
Z∞
0
g(x) dx < ∞.
Prove that
limn→∞ Z∞
0
fn(x) dx =
Z∞
0
f(x) dx.
(See Exercises 6.7 and 6.8 for the relevant definitions.)
This is a rather weak form of Lebesgue’s dominated convergence theorem (Theorem 11.32).
Even in the context of the Riemann integral, uniform convergence can be replaced by point￾wise convergence if it is assumed that f ∈ R. (See the articles by F. Cunningham in Math.
Mag., vol. 40, 1967, pp. 179-186 [Cun67], and by H. Kestelman in Amer. Math. Monthly, vol.
77, 1970, pp. 182-187 [Kes70].)
7.13. Assume that (fn) is a sequence of monotonically increasing functions on R1 with 0 ≤
fn(x) ≤ 1 for all x and all n.
(a) Prove that there is a function f and a sequence (nk) such that
f(x) = lim
k→∞
fnk
(x)
for every x ∈ R1
. (The existence of such a pointwise convergent subsequence is usu￾ally called Helly’s selection theorem.)
(b) If, moreover, f is continuous, prove that fnk → f uniformly on compact sets.
Hint: (i) Some subsequence (fni
) converges at all rational points r, say, to f(r). (ii) Define
f(x), for any x ∈ R1
, to be sup f(r), the sup being taken over all r ≤ x. (iii) Show that
fni
(x) → f(x) at every x at which f is continuous. (This is where monotonicity is strongly
used.) (iv) A subsequence of (fni
) converges at every point of discontinuity of f since there
are at most countably many such points. This proves (a). To prove (b), modify your proof of
(iii) appropriately.
7.14. Let f be a continuous real function on R1 with the following properties: 0 ≤ f(t) ≤ 1,
f(t + 2) = f(t) for every t, and
f(t) = 
0 (0 ≤ t ≤ 1
3
)
1 (
2
3 ≤ t ≤ 1).
Put Φ(t) = (x(t), y(t)), where
x(t) = X∞
n=1
2
−nf(3
2n−1
t), y(t) = X∞
n=1
2
−nf(3
2nt).
Prove that Φ is continuous and that Φ maps I = [0, 1] onto the unit square I
2 ⊂ R2
. In fact,
show that Φ maps the Cantor set onto I
2
.
Hint: Each (x0, y0) ∈ I
2 has the form
x0 =
X∞
n=1
2
−na2n−1, y0 =
X∞
n=1
2
−na2nEXERCISES 156
where each ai is 0 or 1. If
t0 =
X∞
i=1
3
−i−1
(2ai)
show that f(3
kt0) = ak, and hence that x(t0) = x0, y(t0) = y0.
(This simple example of a so-called “space-filling curve” is due to I. J. Schoenberg, Bull.
A.M.S., vol. 44, 1938, pp. 519.)
7.15. Suppose f is a real continuous function on R1
, fn(t) = f(nt) for n = 1, 2, 3, . . . , and (fn)
is equicontinuous on [0, 1]. What conclusion can you draw about f?
7.16. Suppose (fn) is an equicontinuous sequence of functions on a compact set K, and (fn)
converges pointwise on K. Prove that (fn) converges uniformly on K.
7.17. Define the notions of uniform convergence and equicontinuity for mappings into any
metric space. Show that Theorems 7.9 and 7.12 are valid for mappings into any metric space,
that Theorems 7.8 and 7.11 are valid for mappings into any complete metric space, and that
Theorems 7.10, 7.16, 7.17, 7.24, and 7.25 hold for vector-valued functions, that is, for map￾pings into any Rk.
7.18. Let (fn) be a uniformly bounded sequence of functions which are Riemann-integrable
on [a, b], and put
Fn(x) = Zx
a
fn(t) dt (a ≤ x ≤ b).
Prove that there exists a subsequence (Fnk
) which converges uniformly on [a, b].
7.19. Let K be a compact metric space, let S be a subset of C (K). Prove that S is compact (with
respect to the metric defined in Definition 7.14) if and only if S is uniformly closed, pointwise
bounded, and equicontinuous. (If S is not equicontinuous, then S contains a sequence which
has no equicontinuous subsequence, hence has no subsequence that converges uniformly on
K.)
7.20. If f is continuous on [0, 1] and if
Z 1
0
f(x)x
n dx = 0 (n = 0, 1, 2, . . .),
prove that f(x) = 0 on [0, 1]. Hint: The integral of the product of f with any polynomial is
zero. Use the Weierstrass theorem to show that R1
0
f
2
(x) dx = 0.
7.21. Let K be the unit circle in the complex plane (i.e., the set of all z with |z| = 1), and let A
be the algebra of all functions of the form
f(e
iθ) = XN
n=0
cne
inθ (θ real).
Then A separates points on K and A vanishes at no point of K, but nevertheless there are
continuous functions on K which are not in the uniform closure of A .
Hint: For every f ∈ A
Z 2π
0
f(e
iθ)e
iθ dθ = 0,
and this is also true for every f in the closure of A .
7.22. Assume f ∈ R(α) on [a, b], and prove that there are polynomials Pn such that
limn→∞ Z b
a
|f − Pn |
2
dα = 0.
(Compare with Exercise 6.12.)EXERCISES 157
7.23. Put P0 = 0, and define, for n = 0, 1, 2, . . . ,
Pn+1(x) = Pn(x) + x
2 − P
2
n(x)
2
.
Prove that
limn→∞
Pn(x) = |x| ,
uniformly on [−1, 1].
(This makes it possible to prove the Stone-Weierstrass theorem without first proving The￾orem 7.26.)
Hint: Use the identity
|x| − Pn+1(x) = [|x| − Pn(x)] 
1 −
|x| + Pn(x)
2

to prove that 0 ≤ Pn(x) ≤ Pn+1(x) ≤ |x| if |x| ≤ 1, and that
|x| − Pn(x) ≤ |x|

1 −
|x|
2
n
<
2
n + 1
if |x| ≤ 1.
7.24. Let X be a metric space, with metric d. Fix a point a ∈ X. Assign to each p ∈ X the
function fp defined by
fp(x) = d(x, p) − d(x, a) (x ∈ X).
Prove that |fp(x)| ≤ d(a, p) for all x ∈ X, and that therefore fp ∈ C (X).
Prove that
∥fp − fq∥ = d(p, q)
for all p, q ∈ X.
If Φ(p) = fp it follows that Φ is an isometry (a distance-preserving mapping) of X onto
Φ(X) ⊂ C (X).
Let Y be the closure of Φ(X) in C (X). Show that Y is complete.
Conclusion: X is isometric to a dense subset of a complete metric space Y. (Exercise 3.24 contains
a different proof of this.)
7.25. Suppose ϕ is a continuous bounded real function in the strip defined by 0 ≤ x ≤ 1,
−∞ < y < ∞. Prove that the initial value problem
y
′ = ϕ(x, y), y(0) = c
has a solution. (Note that the hypotheses of this existence theorem are less stringent than
those of the corresponding uniqueness theorem; see Exercise 5.27.)
Hint: Fix n. For i = 0, . . . , n, put xi = i/n. Let fn be a continuous function on [0, 1] such
that fn(0) = c,
f
′
n(t) = ϕ(xi, fn(xi)) if xi < t < xi+1,
and put
∆n(t) = f
′
n(t) − ϕ(t, fn(t)),
except at the points xi, where ∆n(t) = 0. Then
fn(x) = c +
Zx
0
[ϕ(t, fn(t)) + ∆n(t)] dt.
Choose M < ∞ so that |ϕ| ≤ M. Verify the following assertions.
(a) |f
′
n | ≤ M, |∆n | ≤ 2M, ∆n ∈ R, and |fn | ≤ |c| + M = M1, say, on [0, 1], for all n.
(b) (fn) is equicontinuous on [0, 1], since |f
′
n | ≤ M.EXERCISES 158
(c) Some (fnk
) converges to some f, uniformly on [0, 1].
(d) Since ϕ is uniformly continuous on the rectangle 0 ≤ x ≤ 1, |y| ≤ M1,
ϕ(t, fnk
(t)) → ϕ(t, f(t))
uniformly on [0, 1].
(e) ∆n(t) → 0 uniformly on [0, 1], since
∆n(t) = ϕ(xi, fn(xi)) − ϕ(t, fn(t))
in (xi, xi+1).
(f) Hence
f(x) = c +
Zx
0
ϕ(t, f(t)) dt.
This f is a solution of the given problem.
7.26. Prove an analogous existence theorem for the initial-value problem
y
′ = Φ(x, y), y(0) = c,
where now c ∈ Rk, y ∈ Rk, and Φ is a continuous bounded mapping of the part of Rk+1
defined by 0 ≤ x ≤ 1, y ∈ Rk into Rk. (Compare Exercise 5.28.) Hint: Use the vector-valued
version of Theorem 7.25.Chapter 8
SOME SPECIAL FUNCTIONS
POWER SERIES
In this section we shall derive some properties of functions which are represented
by power series, i.e., functions of the form
(8.1) f(x) = X∞
n=0
cnx
n
or, more generally,
(8.2) f(x) = X∞
n=0
cn(x − a)
n.
These are called analytic functions.
We shall restrict ourselves to real values of x. Instead of circles of convergence
(see Theorem 3.39) we shall therefore encounter intervals of convergence.
If (8.1) converges for all x in (−R, R), for some R > 0 (R may be +∞), we say that
f is expanded in a power series about the point x = 0. Similarly, if (8.2) converges
for |x − a| < R, f is said to be expanded in a power series about the point x = a. As
a matter of convenience, we shall often take a = 0 without any loss of generality.
8.1 Theorem. Suppose the series
(8.3) X∞
n=0
cnx
n
converges for |x| < R, and define
(8.4) f(x) = X∞
n=0
cnx
n (|x| < R).
159POWER SERIES 160
Then (8.3) converges uniformly on [−R + ε, R − ε], no matter which ε > 0 is chosen.
The function f is continuous and differentiable in (−R, R), and
(8.5) f
′
(x) = X∞
n=1
ncnx
n−1
(|x| < R).
Proof. Let ε > 0 be given. For |x| ≤ R − ε, we have
|cnx
n | ≤ |cn(R − ε)
n | ;
and since
Xcn(R − ε)
n
converges absolutely (every power series converges absolutely in the interior of its
interval of convergence, by the root test), Theorem 7.10 shows the uniform conver￾gence of (8.3) on [−R + ε, R − ε].
Since n√
n → 1 as n → ∞, we have
lim sup
n→∞
np
n |cn | = lim sup
n→∞
np
|cn |,
so that the series (8.4) and (8.5) have the same interval of convergence.
Since (8.5) is a power series, it converges uniformly in [−R + ε, R − ε] for every
ε > 0, and we can apply Theorem 7.17 (for series instead of sequences). It follows
that (8.5) holds if |x| ≤ R − ε.
But, given any x such that |x| < R, we can find an ε > 0 such that |x| < R − ε.
This shows that (8.5) holds for |x| < R.
Continuity of f follows from the existence of f
′
(Theorem 5.2).
Corollary. Under the hypothesis of Theorem 8.1, f has derivatives of all orders in (−R, R),
which are given by
(8.6) f
(k)
(x) = X∞
n=k
n(n − 1)· · ·(n − k + 1)cnx
n−k
.
In particular,
(8.7) f
(k)
(0) = k!ck (k = 0, 1, 2, . . .).
(Here f
(0) means f, and f
(k)
is the kth derivative of f, for k = 1, 2, 3, . . . ).
Proof. Equation (8.6) follows if we apply Theorem 8.1 successively to f, f
′
, f
′′
, . . . .
Putting x = 0 in (8.6), we obtain (8.7).
Formula (8.7) is very interesting. It shows, on the one hand, that the coefficients
of the power series development of f are determined by the values of f and of its
derivatives at a single point. On the other hand, if the coefficients are given, thePOWER SERIES 161
values of the derivatives of f at the center of the interval of convergence can be
read off immediately from the power series.
Note, however, that although a function f may have derivatives of all orders,
the series Pcnx
n, where cn is computed by (8.7), need not converge to f(x) for
any x ̸= 0. In this case, f cannot be expanded in a power series about x = 0. For if
we had f(x) = Panx
n, we should have
n!an = f
(n)
(0);
hence an = cn. An example of this situation is given in Exercise 8.1.
If the series (8.3) converges at an endpoint, say at x = R, then f is continuous not
only in (−R, R), but also at x = R. This follows from Abel’s theorem (for simplicity
of notation, we take R = 1):
8.2 Theorem. Suppose Pcn converges. Put
f(x) = X∞
n=0
cnx
n (−1 < x < 1).
Then
(8.8) lim
x→1
f(x) = X∞
n=0
cn.
Proof. Let sn = c0 + · · · + cn, s−1 = 0. Then
X∞
n=0
cnx
n =
Xm
n=0
(sn − sn−1)x
n = (1 − x)
mX−1
n=0
snx
n + smxm.
For |x| < 1, we let m → ∞ and obtain
(8.9) f(x) = (1 − x)
X∞
n=0
snx
n.
Suppose s = limn→∞ sn. Let ε > 0 be given. Choose N so that n > N implies
|s − sn | <
ε
2
.
Then, since
(1 − x)
X∞
n=0
x
n = 1 (|x| < 1),
we obtain from (8.9)
|f(x) − s| =





(1 − x)
X∞
n=0
(sn − s)x
n





≤ (1 − x)
X
N
n=0
|sn − s| |x|
n +
ε
2
≤ εPOWER SERIES 162
if x > 1 − δ, for some suitably chosen δ > 0. This implies (8.8).
As an application, let us prove Theorem 3.51, which asserts: If Pan,
Pbn,
Pcn,
converge to A, B, C, and if cn = a0bn + . . . + anb0, then C = AB. We let
f(x) = X∞
n=0
anx
n, g(x) = X∞
n=0
bnx
n, h(x) = X∞
n=0
cnx
n,
for 0 ≤ x ≤ 1. For x < 1, these series converge absolutely and hence may be
multiplied according to Definition 3.48; when the multiplication is carried out, we
see that
(8.10) f(x) · g(x) = h(x) (0 ≤ x < 1).
By Theorem 8.2,
(8.11) f(x) → A, g(x) → B, h(x) → C
as x → 1. Equations (8.10) and (8.11) imply AB = C.
We now require a theorem concerning an inversion in the order of summation.
(See Exercises 8.2 and 8.3.)
8.3 Theorem. Given a double sequence ￾
aij
, i = 1, 2, 3 . . . , j = 1, 2, 3, . . . , suppose
that
(8.12) X∞
j=1

aij

 = bi
(i = 1, 2, 3, . . .)
and Pbi converges. Then
(8.13) X∞
i=1
X∞
j=1
aij =
X∞
j=1
X∞
i=1
aij.
Proof. We could establish (8.13) by a direct procedure similar to (although more
involved than) the one used in Theorem 3.55. However, the following method
seems more interesting.
Let E be a countable set, consisting of the points x0, x1, x2, . . . , and suppose
xn → x0 as n → ∞. Define
fi
(x0) = X∞
j=1
aij (i = 1, 2, 3, . . .),(8.14)
fi
(xn) = Xn
j=1
aij (i, n = 1, 2, 3, . . .),(8.15)
g(x) = X∞
i=1
fi
(x) (x ∈ E).(8.16POWER SERIES 163
Now, (8.14) and (8.15), together with (8.12), show that each fi
is continuous at
x0. Since |fi
(x)| ≤ bi
for x ∈ E, (8.16) converges uniformly, so that g is continuous
at x0 (Theorem 7.11). It follows that
X∞
i=1
X∞
j=1
aij =
X∞
i=1
fi
(x0) = g(x0) = lim n→∞
g(xn)
= lim n→∞
X∞
i=1
fi
(xn) = lim n→∞
X∞
i=1
Xn
j=1
aij
= lim n→∞
Xn
j=1
X∞
i=1
aij =
X∞
j=1
X∞
i=1
aij.
8.4 Theorem. Suppose
f(x) = X∞
n=0
cnx
n,
the series converging in |x| < R. If −R < a < R, then f can be expanded in a power series
about the point x = a which converges in |x − a| < R − |a| , and
(8.17) f(x) = X∞
n=0
f
(n)
(a)
n!
(x − a)
n (|x − a| < R − |a|).
This is an extension of Theorem 5.15 and is also known as Taylor’s theorem.
Proof. We have
f(x) = X∞
n=0
cn[(x − a) + a]
n
=
X∞
n=0
cn
Xn
m=0

n
m

a
n−m(x − a)m
=
X∞
m=0
" X∞
n=m

n
m

cna
n−m
#
(x − a)m.
This is the desired expansion about the point x = a. To prove its validity, we have
to justify the change which was made in the order of summation. Theorem 8.3
shows that this is permissible if
(8.18) X∞
n=0
Xn
m=0




cn

n
m

a
n−m(x − a)m



POWER SERIES 164
converges. But (8.18) is the same as
(8.19) X∞
n=0
|cn | · (|x − a| + |a|)
n,
and (8.19) converges if |x − a| + |a| < R
Finally, the form of the coefficients in (8.17) follows from (8.7).
It should be noted that (8.17) may actually converge in a larger interval than
the one given by |x − a| < R − |a|.
If two power series converge to the same function in (−R, R), (8.7) shows that
the two series must be identical, i.e., they must have the same coefficients. It is in￾teresting that the same conclusion can be deduced from much weaker hypotheses:
8.5 Theorem. Suppose the series Panx
n and Pbnx
n converge in the segment S =
(−R, R). Let E be the set of all x ∈ S at which
(8.20) X∞
n=0
anx
n =
X∞
n=0
bnx
n.
If E has a limit point in S, then an = bn for n = 0, 1, 2, . . . . Hence (8.20) holds for all
x ∈ S.
Proof. Put cn = an − bn and
(8.21) f(x) = X∞
n=0
cnx
n (x ∈ S).
Then f(x) = 0 on E.
Let A be the set of all limit points of E in S, and let B consist of all other points
of S. It is clear from the definition of “limit point” that B is open. Suppose we
can prove that A is open. Then A and B are disjoint open sets. Hence they are
separated (Definition 2.45). Since S = A ∪ B, and S is connected, one of A and B
must be empty. By hypothesis, A is not empty. Hence B is empty, and A = S.
Since f is continuous in S, A ⊂ E. Thus E = S, and (8.7) shows that cn = 0 for
n = 0, 1, 2, . . . , which is the desired conclusion.
Thus we have to prove that A is open. If x0 ∈ A, Theorem 8.4 shows that
(8.22) f(x) = X∞
n=0
dn(x − x0)
n (|x − x0| < R − |x0|).
We claim that dn = 0 for all n. Otherwise, let k be the smallest non-negative
integer such that dk ̸= 0. Then
(8.23) f(x) = (x − x0)
kg(x) (|x − x0| < R − |x0|),THE EXPONENTIAL AND LOGARITHMIC FUNCTIONS 165
where
(8.24) g(x) = X∞
m=0
dk+m(x − x0)m.
Since g is continuous at x0 and
g(x0) = dk ̸= 0,
there exists a δ > 0 such that g(x) ̸= 0 if |x − x0| < δ. It follows from (8.23) that
f(x) ̸= 0 if 0 < |x − x0| < δ. But this contradicts the fact that x0 is a limit point of E.
Thus dn = 0 for all n, so that f(x) = 0 for all x for which (8.22) holds, i.e., a
neighborhood of x0. This shows that A is open and completes the proof.
THE EXPONENTIAL AND LOGARITHMIC FUNCTIONS
We define
(8.25) E(z) = X∞
n=0
z
n
n!
.
The ratio test shows that this series converges for every complex z. Applying The￾orem 3.50 on multiplication of absolutely convergent series, we obtain
E(z)E(w) = X∞
n=0
z
n
n!
X∞
m=0
wm
m!
=
X∞
n=0
Xn
k=0
z
kwn−k
k!(n − k)!
=
X∞
n=0
1
n!
Xn
k=0

n
k

z
kw
n−k =
X∞
n=0
(z + w)
n
n!
,
which gives us the important addition formula
(8.26) E(z + w) = E(z)E(w) (z, w complex).
One consequence is that
(8.27) E(z)E(−z) = E(z − z) = E(0) = 1 (z complex).
This shows that E(z) ̸= 0 for all z. By (8.25), E(x) > 0 if x > 0; hence (8.27) shows
that E(x) > 0 for all real x. By (8.25), E(x) → +∞ as x → +∞; hence (8.27) shows
that E(x) → 0 as x → −∞ along the real axis. By (8.25), 0 < x < y implies that
E(x) < E(y); by (8.27), it follows that E(−y) < E(−x); hence E is strictly increasing
on the whole real axis.
The addition formula also shows that
(8.28) lim
h→0
E(z + h) − E(z)
h
= E(z) lim
h→0
E(h) − 1
h
= E(z);THE EXPONENTIAL AND LOGARITHMIC FUNCTIONS 166
the last equality follows directly from (8.25).
Iteration of (8.26) gives
(8.29) E(z1 + · · · + zn) = E(z1)· · · E(zn).
Let us take z1 = · · · = zn = 1. Since E(1) = e, where e is the number defined in
Definition 3.30, we obtain
(8.30) E(n) = e
n (n = 1, 2, 3, . . .).
If p = n/m, where n, m are positive integers, then
(8.31) [E(p)]m = E(mp) = E(n) = e
n,
so that
(8.32) E(p) = e
p (p > 0, p rational).
It follows from (8.27) that E(−p) = e
−p if p is positive and rational. Thus (8.32)
holds for all rational p.
In Exercise 1.6, we suggested the definition
(8.33) x
y = sup x
p,
where the sup is taken over all rational p such that p < y, for any real y, and x > 1.
If we thus define, for any real x,
(8.34) e
x = sup e
p (p < x, p rational),
the continuity and monotonicity properties of E, together with (8.32), show that
(8.35) E(x) = e
x
for all real x. Equation (8.35) explains why E is called the exponential function.
The notation exp(x) is often used in place of e
x, especially when x is a compli￾cated expression.
Actually one may very well use (8.35) instead of (8.34) as the definition of e
x;
(8.35) is a much more convenient starting point for the investigation of the prop￾erties of e
x. We shall see presently that (8.33) may also be replaced by a more
convenient definition [see (8.43)].
We now revert to the customary notation, e
x, in place of E(x), and summarize
what we have proved so far.
8.6 Theorem. Let e
x be defined on R1 by (8.35) and (8.25). Then
(a) e
x is continuous and differentiable for all x;
(b) (e
x)
′ = e
x;
(c) e
x is a strictly increasing function of x, and e
x > 0;THE EXPONENTIAL AND LOGARITHMIC FUNCTIONS 167
(d) e
x+y = e
xe
y
(e) e
x → +∞ as x → +∞, e
x → 0 as x → −∞;
(f) limx→+∞ x
ne
−x = 0 for every n.
Proof. We have already proved (a) to (e); (8.25) shows that
e
x >
x
n+1
(n + 1)!
for x > 0, so that
x
ne
−x <
(n + 1)!
x
,
and (f) follows. Part (f) shows that e
x tends to +∞ “faster” than any power of x as
x → +∞.
Since E is strictly increasing and differentiable on R1, it has an inverse function
L which is also strictly increasing and differentiable and whose domain is E(R1),
that is, the set of all positive numbers. L is defined by
(8.36) E(L(y)) = y (y > 0),
or, equivalently, by
(8.37) L(E(x)) = x (x real).
Differentiating (8.37), we get (compare Theorem 5.5)
L
′
(E(x)) · E(x) = 1.
Writing y = E(x), this gives us
(8.38) L
′
(y) = 1
y
(y > 0).
Taking x = 0 in (8.37), we see that L(1) = 0. Hence (8.38) implies
(8.39) L(y) = Z y
1
dx
x
.
Quite frequently, (8.39) is taken as the starting point of the theory of the logarithm
and the exponential function. Writing u = E(x), v = E(y), (8.26) gives
L(uv) = L(E(x) · E(y)) = L(E(x + y)) = x + y,
so that
(8.40) L(uv) = L(u) + L(v) (u > 0, v > 0).THE EXPONENTIAL AND LOGARITHMIC FUNCTIONS 168
This shows that L has the familiar property which makes logarithms useful tools
for computation. The customary notation L(x) is of course log x.
As to the behavior of log x as x → +∞ and as x → 0, Theorem 8.6(e) shows
that
log x → +∞ as x → +∞,
log x → −∞ as x → 0.
It is easily seen that
(8.41) x
n = E(nL(x))
if x > 0 and n is an integer. Similarly, if m is a positive integer, we have
(8.42) x
1/m = E

1
m
L(x)

,
since each term of (8.42), when raised to the mth power, yields the corresponding
term of (8.36). Combining (8.41) and (8.42), we obtain
(8.43) x
α = E(αL(x)) = e
α log x
for any rational α.
We now define x
α, for any real α and any x > 0, by (8.43). The continuity and
monotonicity of E and L show that this definition leads to the same result as the
previously suggested one. The facts stated in Exercise 1.6 are trivial consequences
of (8.43).
If we differentiate (8.43), we obtain, by Theorem 5.5,
(8.44) (x
α)
′ = E(αL(x)) ·
α
x
= αxα−1
.
Note that we have previously used (8.44) only for integral values of α, in which
case (8.44) follows easily from Theorem 5.3(b). To prove (8.44) directly from the
definition of the derivative, if x
α is defined by (8.33) and α is irrational, is quite
troublesome.
The well-known integration formula for x
α follows from (8.44) if α ̸= −1, and
from (8.38) if α = −1. We wish to demonstrate one property of log x, namely,
(8.45) lim x→+∞
x
−α log x = 0
for every α > 0. That is, log x → +∞ “slower” than any positive power of x as
x → +∞.THE TRIGONOMETRIC FUNCTIONS 169
For if 0 < ε < α, and x > 1, then
x
−α log x = x
−α
Zx
1
t
−1 dt < x−α
Zx
1
t
ε−1 dt
= x
−α ·
x
ε − 1
ε
<
x
ε−α
ε
,
and (8.45) follows. We could also have used Theorem 8.6(f) to derive (8.45).
THE TRIGONOMETRIC FUNCTIONS
Let us define
(8.46) C(x) = 1
2
[E(ix) + E(−ix)], S(x) = 1
2i[E(ix) − E(−ix)].
We shall show that C(x) and S(x) coincide with the functions cos x and sin x, whose
definition is usually based on geometric considerations. By (8.25), E(z) = E(z).
Hence (8.46) shows that C(x) and S(x) are real for real x. Also,
(8.47) E(ix) = C(x) + iS(x).
Thus C(x) and S(x) are the real and imaginary parts, respectively, of E(ix), if x is
real. By (8.27),
|E(ix)|
2 = E(ix)E(ix) = E(ix)E(−ix) = 1,
so that
(8.48) |E(ix) = 1| (x real).
From (8.46) we can read off that C(0) = 1, S(0) = 0, and (8.28) shows that
(8.49) C
′
(x) = −S(x), S
′
(x) = C(x).
We assert that there exist positive numbers x such that C(x) = 0. For suppose
this is not so. Since C(0) = 1, it then follows that C(x) > 0 for all x > 0, hence
S
′
(x) > 0, by (8.49), hence S is strictly increasing; and since S(0) = 0, we have
S(x) > 0 if x > 0. Hence if 0 < x < y, we have
(8.50) S(x)(y − x) <
Z y
x
S(t) dt = C(x) − C(y) ≤ 2.
The last inequality follows from (8.48) and (8.47). Since S(x) > 0, (8.50) cannot be
true for large y, and we have a contradiction.
Let x0 be the smallest positive number such that C(x0) = 0. This exists, since
the set of zeroes of a continuous function is closed, and C(0) ̸= 0. We define theTHE TRIGONOMETRIC FUNCTIONS 170
number π by
(8.51) π = 2x0.
Then C(π/2) = 0, and (8.48) shows that S(π/2) = ±1. Since C(x) > 0 in
(0, π/2), S is increasing in (0, π/2); hence S(π/2) = 1. Thus
E

πi
2

= i,
and the addition formula gives
(8.52) E(πi) = −1, E(2πi) = 1;
hence
(8.53) E(z + 2πi) = E(z) (z complex).
8.7 Theorem.
(a) The function E is periodic, with period 2πi.
(b) The functions C and S are periodic, with period 2π.
(c) If 0 < t < 2π, then E(it) ̸= 1.
(d) If z is a complex number with |z| = 1, there is a unique t in [0, 2π) such that
E(it) = z.
Proof. By (8.53), (a) holds; and (b) follows from (a) and (8.46).
Suppose 0 < t < π/2 and E(it) = x + iy, with x, y real. Our preceding work
shows that 0 < x < 1, 0 < y < 1. Note that
E(4it) = (x + iy)
4 = x
4 − 6x2y
2 + y
4 + 4ixy(x
2 − y
2
).
If E(4it) is real, it follows that x
2 − y
2 = 0; since x
2 + y
2 = 1, by (8.48), we have
x
2 = y
2 =
1
2
, hence E(4it) = −1. This proves (c).
If 0 ≤ t1 < t2 < 2π, then
E(it2)[E(it1)]−1 = E(it2 − it1) ̸= 1,
by (c). This establishes the uniqueness assertion in (d).
To prove the existence assertion in (d), fix z so that |z| = 1. Write z = x + iy,
with x and y real. Suppose first that x ≥ 0 and y ≥ 0. On [0, π/2], C decreases
from 1 to 0. Hence C(t) = x for some t ∈ [0, π/2]. Since C
2 + S
2 = 1 and S ≥ 0 on
[0, π/2], it follows that z = E(it).
If x < 0 and y ≥ 0, the preceding conditions are satisfied by −iz. Hence −iz =
E(it) for some t ∈ [0, π/2], and since i = E(πi/2), we obtain z = E(i(t + π/2)).THE ALGEBRAIC COMPLETENESS OF THE COMPLEX FIELD 171
Finally, if y < 0, the preceding two cases show that −z = E(it) for some t ∈ (0, π).
Hence z = −E(it) = E(i(t + π)).
This proves (d), and hence the theorem.
It follows from (d) and (8.48) that the curve γ defined by
(8.54) γ(t) = E(it) (0 ≤ t ≤ 2π)
is a simple closed curve whose range is the unit circle in the plane. Since γ
′
(t) =
iE(it), the length of γ is
Z2π
0

γ
′
(t)

 dt = 2π,
by Theorem 6.27. This is of course the expected result for the circumference of
a circle of radius 1. It shows that π, defined by (8.51), has the usual geometric
significance.
In the same way we see that the point γ(t) describes a circular arc of length t0
as t increases from 0 to t0. Consideration of the triangle whose vertices are
z1 = 0, z2 = γ(t0), z3 = C(t0)
shows that C(t) and S(t) are indeed identical with cos t and sin t, if the latter are
defined in the usual way as ratios of the sides of a right triangle.
It should be stressed that we derived the basic properties of the trigonometric
functions from (8.46) and (8.25), without any appeal to the geometric notion of
angle. There are other nongeometric approaches to these functions. The papers by
W. F. Eberlein (Amer. Math. Monthly, vol. 74, 1967, pp. 1223 –1225 [Ebe54]) and
by G. B. Robison (Math. Mag., vol. 41, 1968, pp. 66 –70 [Rob68]) deal with these
topics.
THE ALGEBRAIC COMPLETENESS OF THE COMPLEX FIELD
We are now in a position to give a simple proof of the fact that the complex field
is algebraically complete, that is to say, that every nonconstant polynomial with
complex coefficients has a complex root.
8.8 Theorem. Suppose a0, . . . , an are complex numbers, n ≥ 1, an ̸= 0,
P(z) = Xn
k=0
akz
k
.
Then P(z) = 0 for some complex number z.
Proof. Without loss of generality, assume an = 1. Put
(8.55) µ = inf |P(z)| (z complex)FOURIER SERIES 172
If |z| = R, then
(8.56) |P(z)| ≥ R
n[1 − |an−1| R
−1 − · · · − |a0| R
−n].
The right side of (8.56) tends to ∞ as R → ∞. Hence there exists R0 such that
|P(z)| > µ if |z| > R0. Since |P| is continuous on the closed disc with center at 0 and
radius R0, Theorem 4.16 shows that |P(z0)| = µ for some z0.
We claim that µ = 0.
If not, put Q(z) = P(z + z0)/P(z0). Then Q is a nonconstant polynomial,
Q(0) = 1, and |Q(z)| ≥ 1 for all z. There is a smallest integer k, 1 ≤ k ≤ n,
such that
(8.57) Q(z) = 1 + bkz
k + · · · + bnz
n, bk ̸= 0.
By Theorem 8.7(d) there is a real θ such that
(8.58) e
ikθbk = − |bk| .
If r > 0 and r
k |bk| < 1, (8.58) implies



1 + bkr
k
e
ikθ


 = 1 − r
k
|bk| ,
so that


Q(reiθ)


 ≤ 1 − r
k


|bk| − r |bk+1| − · · · − r
n−k
|bn |

.
For sufficiently small r, the expression in braces is positive; hence

Q(reiθ)

 < 1, a
contradiction.
Thus µ = 0, that is, P(z0) = 0.
Exercise 8.27 contains a more general result.
FOURIER SERIES
8.9 Definition. A trigonometric polynomial is a finite sum of the form
(8.59) f(x) = a0 +
X
N
n=1
(an cos nx + bn sin nx) (x real),
where a0, . . . , aN, b1, . . . , bN are complex numbers. On account of the identities
(8.46), (8.59) can also be written in the form
(8.60) f(x) = X
N
n=−N
cne
inx (x real),FOURIER SERIES 173
which is more convenient for most purposes. It is clear that every trigonometric
polynomial is periodic, with period 2π.
If n is a nonzero integer, e
inx is the derivative of e
inx/in, which also has
period 2π. Hence
(8.61) 1
2π Zπ
−π
e
inx dx =

1 (if n = 0)
0 (if n = ±1, ±2, . . .).
Let us multiply (8.60) by e
−imx, where m is an integer; if we integrate the
product, (8.61) shows that
(8.62) cm =
1
2π Zπ
−π
f(x)e
−imx dx
for |m| ≤ N. If |m| > N, the integral in (8.62) is 0.
The following observation can be read off from (8.60) and (8.62): The trigono￾metric polynomial f given by (8.60) is real if and only if c−n = cn for n = 0, . . . , N.
In agreement with (8.60), we define a trigonometric series to be a series of the
form
(8.63) X∞
n=−∞
cne
inx (x real);
the Nth partial sum of (8.63) is defined to be the right side of (8.60).
If f is an integrable function on [−π, π], the numbers cm defined by (8.62) for all
integers m are called the Fourier coefficients of f, and the series (8.63) formed with
these coefficients is called the Fourier series of f.
The natural question which now arises is whether the Fourier series of f con￾verges to f, or more generally, whether f is determined by its Fourier series. That
is to say, if we know the Fourier coefficients of a function, can we find the function,
and if so, how?
The study of such series, and, in particular, the problem of representing a given
function by a trigonometric series, originated in physical problems such as the the￾ory of oscillations and the theory of heat conduction (Fourier’s “Theorie analytique ´
de la chaleur” was published in 1822). The many difficult and delicate problems
which arouse during this study caused a thorough revision and reformulation of
the whole theory of functions of a real variable. Among many prominent names,
those of Riemann, Cantor, and Lebesgue are intimately connected with this field,
which nowadays, with all its generalizations and ramifications, may well be said
to occupy a central position in the whole of analysis.
We shall be content to derive some basic theorems which are easily accessible
by the methods developed in the preceding chapters. For more thorough investi￾gations, the Lebesgue integral is a natural and indispensable tool.
We shall first study more general systems of functions which share a propertyFOURIER SERIES 174
analogous to (8.61).
8.10 Definition. Let (ϕn) (n = 1, 2, 3, . . .) be a sequence of complex functions on
[a, b], such that
(8.64) Z b
a
ϕn(x)ϕm(x) dx = 0 (n ̸= m).
Then (ϕn) is said to be an orthogonal system of functions on [a, b]. If, in addition,
(8.65) Z b
a
|ϕn(x)|
2 dx = 1
for all n, (ϕn) is said to be orthonormal.
For example, the functions (2π)
−1/2e
inx form an orthonormal system on
[−π, π]. So do the real functions
1
√
2π
,
cos x √
π
,
sin x √
π
,
cos 2x
√
π
,
sin 2x
√
π
, . . . .
If (ϕn) is orthonormal on [a, b] and if
(8.66) cn =
Z b
a
f(t)ϕn(t) dt (n = 1, 2, 3, . . .),
we call cn the nth Fourier coefficient of f relative to (ϕn). We write
(8.67) f(x) ∼
X∞
n=1
cnϕn(x)
and call this series the Fourier series of f (relative to (ϕn)).
Note that the symbol ∼ used in (8.67) implies nothing about the convergence of
the series; it merely says that the coefficients are given by (8.66).
The following theorems show that the partial sums of the Fourier series of f
have a certain minimum property. We shall assume here and in the rest of this
chapter that f ∈ R, although this hypothesis can be weakened.
8.11 Theorem. Let (ϕn) be orthonormal on [a, b]. Let
(8.68) sn(x) = Xn
m=1
cmϕm(x)
be the nth partial sum of the Fourier series of f, and suppose
(8.69) tn(x) = Xn
m=1
γmϕm(x).FOURIER SERIES 175
Then
(8.70) Z b
a
|f − sn |
2 dx ≤
Z b
a
|f − tn |
2 dx,
and equality holds if and only if
(8.71) γm = cm (m = 1, . . . , n).
That is to say, among all functions tn, sn gives the best possible mean square approx￾imation to f.
Proof. Let R
denote the integral over [a, b], Σ the sum from 1 to n. Then
Z
ftn =
Z
f
Xγmϕm =
Xcmγm
by the definition of (cm),
Z
|tn |
2 =
Z
tntn =
Z Xγmϕm
Xγkϕk =
X|γm|
2
since (ϕm) is orthonormal, and so
Z
|f − tn |
2 =
Z
|f|
2 −
Z
ftn −
Z
ftn +
Z
|tn |
2
=
Z
|f|
2 −
Xcmγm −
Xcmγm +
Xγmγm
=
Z
|f|
2 −
X|cm|
2 +
X|γm − cm|
2
,
which is evidently minimized if and only if γm = cm.
Putting γm = cm in this calculation, we obtain
(8.72) Z b
a
|sn(x)|
2 dx =
Xn
m=1
|cm|
2 ≤
Z b
a
|f(x)|
2 dx,
since R
|f − tn |
2 ≥ 0.
8.12 Theorem. If (ϕn) is orthonormal on [a, b], and if
f(x) ∼
X∞
n=1
cnϕn(x),
then
(8.73) X∞
n=1
|cn |
2 ≤
Z b
a
|f(x)|
2 dx.FOURIER SERIES 176
In particular,
(8.74) lim n→∞
cn = 0.
Proof. Letting n → ∞ in (8.72), we obtain (8.73), the so-called “Bessel inequality.”
8.13 Trigonometric series. From now on we shall deal only with the trigonometric
system. We shall consider functions f that have period 2π and that are Riemann￾integrable on [−π, π] (and hence on every bounded interval). The Fourier series of
f is then the series (8.63) whose coefficients cn are given by the integrals (8.62), and
(8.75) sN(x) = sN(f; x) = X
N
n=−N
cne
inx
is the Nth partial sum of Fourier series of f. The inequality (8.72) now takes the
form
(8.76) 1
2π Zπ
−π
|sN(x)|
2 dx =
X
N
n=−N
|cn |
2 ≤
1
2π Zπ
−π
|f(x)|
2 dx.
In order to obtain an expression for sN that is more manageable than (8.75) we
introduce the Dirichlet kernel
(8.77) DN(x) = X
N
n=−N
e
inx =
sin(N +
1
2
)x
sin(x/2)
.
The first of these equalities is the definition of DN(x). The second follows if both
sides of the identity
(e
ix − 1)DN(x) = e
i(N+1)x − e
−iNx
are multiplied by e
−ix/2.
By (8.62) and (8.75), we have
sN(f; x) = X
N
n=−N
1
2π Zπ
−π
f(t)e
−int dt einx
=
1
2π Zπ
−π
f(t)
X
N
n=−N
e
in(x−t) dt,
so that
(8.78) sN(f; x) = 1
2π Zπ
−π
f(t)DN(x − t) dt =
1
2π Zπ
−π
f(x − t)DN(t) dt.FOURIER SERIES 177
The periodicity of all functions involved shows that it is immaterial over which
interval we integrate, as long as its length is 2π. This shows that the two integrals
in (8.78) are equal.
We shall prove just one theorem about the pointwise convergence of Fourier
series.
8.14 Theorem. If, for some x, there are constants δ > 0 and M < ∞ such that
(8.79) |f(x + t) − f(x)| ≤ M|t|
for all t ∈ (−δ, δ), then
(8.80) lim
N→∞
sN(f; x) = f(x).
Proof. Define
(8.81) g(t) = f(x − t) − f(x)
sin(t/2)
for 0 < |t| ≤ π, and put g(0) = 0. By the definition (8.77),
1
2π Zπ
−π
DN(x) dx = 1.
Hence (8.78) shows that
sN(f; x) − f(x) = 1
2π Zπ
−π
g(t) sin 
N +
1
2

t dt
=
1
2π Zπ
−π

g(t) cos
t
2

sin Nt dt +
1
2π Zπ
−π

g(t) sin t
2

cos Nt dt.
By (8.79) and (8.81), g(t) cos(t/2) and g(t) sin(t/2) are bounded. The last two
integrals thus tend to 0 as N → ∞, by (8.74). This proves (8.80).
Corollary. If f(x) = 0 for all x in some segment J, then lim sN(f; x) = 0 for every x ∈ J.
Here is another formulation of this corollary:
If f(t) = g(t) for all t in some neighborhood of x, then
sN(f; x) − sN(g; x) = sN(f − g; x) → 0 as N → ∞.
This is usually called the localization theorem. It shows that the behaviour of
the sequence (sN(f; x)), as far as convergence is concerned, depends only on the
values of f in some (arbitrarily small) neighborhood of x. Two Fourier series may
thus have the same behaviour in one interval, but may behave in entirely different
ways in some other interval. We have here a very striking contrast between Fourier
series and power series (Theorem 8.5).
We conclude with two other approximation theorems.FOURIER SERIES 178
8.15 Theorem. If f is continuous (with period 2π) and if ε > 0, then there is a trigono￾metric polynomial P such that
|P(x) − f(x)| < ε
for all real x.
Proof. If we identify x and x + 2π, we may regard the 2π-periodic functions on
R1 as functions on the unit circle T, by means of the mapping x → e
ix. The
trigonometric polynomials, i.e., the functions of the form (8.60), form a self-adjoint
algebra A , which seperates points on T, and which vanishes at no point of T. Since
T is compact, Theorem 7.33 tells us that A is dense in C (T). This is exactly what
the theorem asserts.
A more precise form of this theorem appears in Exercise 8.15.
8.16 Theorem (Parseval’s Theorem). Suppose f and g are Riemann-integrable
functions with period 2π, and
(8.82) f(x) ∼
X∞
n=−∞
cne
inx
, g(x) ∼
X∞
n=−∞
γne
inx
.
Then
lim
N→∞
1
2π Zπ
−π
|f(x) − sN(f; x)|
2 dx = 0,(8.83)
1
2π Zπ
−π
f(x)g(x) dx =
X∞
n=−∞
(8.84) cnγn
1
2π Zπ
−π
|f(x)|
2 dx =
X∞
n=−∞
|cn |
2
.(8.85)
Proof. Let us use the notation
(8.86) ∥h∥2 =

1
2π Zπ
−π
|h(x)|
2 dx
1/2
.
Let ε > 0 be given. Since f ∈ R and f(π) = f(−π), the construction described
in Exercise 6.12 yields a continuous 2π-periodic function h with
(8.87) ∥f − h∥2 < ε.
By Theorem 8.15, there is a trigonometric polynomial P such that |h(x) − P(x)| <
ε for all x. Hence ∥h − P∥2 < ε. If P has degree N0, Theorem 8.11 shows that
(8.88) ∥h − sN(h)∥2 ≤ ∥h − P∥2 < εTHE GAMMA FUNCTION 179
for all N ≥ N0. By (8.72), with h − f in place of f,
(8.89) ∥sN(h) − sN(f)∥2 = ∥sN(h − f)∥2 ≤ ∥h − f∥2 < ε.
Now the triangle inequality (Exercise 6.11), combined with (8.87), (8.88), and
(8.89), shows that
(8.90) ∥f − sN(f)∥2 < 3ε (N ≥ N0).
This proves (8.83). Next,
(8.91) 1
2π Zπ
−π
sN(f)g dx =
X
N
n=−N
cn
1
2π Zπ
−π
e
inxg(x) dx =
X
N
n=−N
cnγn,
and the Schwarz inequality shows that
(8.92)




Z
fg −
Z
sN(f)g




≤
Z
|f − sN(f)| |g| ≤
Z
|f − sN|
2
Z
|g|
2
1/2
,
which tends to 0, as N → ∞, by (8.83). Comparison of (8.91) and (8.92) gives (8.84).
Finally, (8.85) is the special case g = f of (8.84).
A more general version of Theorem 8.16 appears in Chap. 11.
THE GAMMA FUNCTION
This function is closely related to factorials and crops up in many unexpected
places in analysis. Its origin, history, and development are very well described
in an interesting article by P. J. Davis (Amer. Math. Monthly, vol. 66, 1959, pp.
849 –869 [Dav59]). Artin’s book [Art64] (cited in the Bibliography) is another good
elementary introduction.
Our presentation will be very condensed, with only a few comments after each
theorem. This section may thus be regarded as a large exercise, and as an oppor￾tunity to apply some of the material that has been presented so far.
8.17 Definition. For 0 < x < ∞,
(8.93) Γ (x) = Z∞
0
t
x−1
e
−t dt.
The integral converges for these x. (When x < 1, both 0 and ∞ have to be
looked at.)
8.18 Theorem.
(a) The functional equation
Γ (x + 1) = xΓ (x)THE GAMMA FUNCTION 180
holds if 0 < x < ∞.
(b) Γ (n + 1) = n! for n = 1, 2, 3, . . . .
(c) log Γ is convex on (0,∞).
Proof. An integration by parts proves (a). Since Γ (1) = 1, (a) implies (b), by induc￾tion. If 1 < p < ∞ and (1/p) + (1/q) = 1, apply Holder’s inequality (Exercise 6.10) ¨
to (8.93), and obtain
Γ

x
p
+
y
q

≤ Γ (x)
1/pΓ (y)
1/q.
This is equivalent to (c).
It is a rather surprising fact, discovered by Bohr and Mollerup, that these three
properties characterize Γ completely.
8.19 Theorem. If f is a positive function on (0,∞) such that
(a) f(x + 1) = xf(x),
(b) f(1) = 1,
(c) log f is convex,
then f(x) = Γ (x).
Proof. Since Γ satisfies (a), (b), and (c), it is enough to prove that f(x) is uniquely
determined by (a), (b), (c) for all x > 0. By (a), it is enough to do this for x ∈ (0, 1).
Put ϕ = log f. Then
(8.94) ϕ(x + 1) = ϕ(x) + log x (0 < x < ∞),
ϕ(1) = 0, and ϕ is convex. Suppose 0 < x < 1, and n is a positive integer. By
(8.94), ϕ(n + 1) = log(n!). Consider the difference quotients of ϕ on the intervals
[n, n + 1], [n + 1, n + 1 + x], [n + 1, n + 2]. Since ϕ is convex
log n ≤
ϕ(n + 1 + x) − ϕ(n + 1)
x
≤ log(n + 1).
Repeated application of (8.94) gives
ϕ(n + 1 + x) = ϕ(x) + log[x(x + 1)· · ·(x + n)].
Thus
0 ≤ ϕ(x) − log 
n!n
x
x(x + 1)· · ·(x + n)

≤ x log 
1 +
1
n

.
The last expression tends to 0 as n → ∞. Hence ϕ(x) is determined, and the proof
is complete.THE GAMMA FUNCTION 181
As a by-product we obtain the relation
(8.95) Γ (x) = lim n→∞
n!n
x
x(x + 1)· · ·(x + n)
at least when 0 < x < 1; from this one can deduce that (8.95) holds for all x > 0,
since Γ (x + 1) = xΓ (x).
8.20 Theorem. If x > 0 and y > 0, then
(8.96) Z1
0
t
x−1
(1 − t)
y−1 dt =
Γ (x)Γ (y)
Γ (x + y)
.
This integral is the so-called beta function B(x, y).
Proof. Note that B(1, y) = 1/y, that log B(x, y) is a convex function of x, for each
fixed y, by Holder’s inequality, as in Theorem 8.18, and that ¨
(8.97) B(x + 1, y) = x
x + y
B(x, y).
To prove (8.97), perform an integration by parts on
B(x + 1, y) = Z1
0

t
1 − t
x
(1 − t)
x+y−1 dt.
These three properties of B(x, y) show, for each y, that Theorem 8.19 applies to the
function f defined by
f(x) = Γ (x + y)
Γ (y)
B(x, y).
Hence f(x) = Γ (x).
8.21 Some consequences. The substitution t = sin2 θ turns (8.96) into
(8.98) 2
Zπ/2
0
(sin θ)
2x−1
(cos θ)
2y−1 dθ =
Γ (x)Γ (y)
Γ (x + y)
.
The special case x = y = 1/2 gives
(8.99) Γ

1
2

=
√
π.
The substitution t = s
2 turns (8.93) into
(8.100) Γ (x) = 2
Z∞
0
s
2x−1
e
−s
2
ds (0 < x < ∞).THE GAMMA FUNCTION 182
The special case x = 1/2 gives
(8.101) Z∞
−∞
e
−s
2
ds =
√
π.
By (8.99), the identity
(8.102) Γ (x) = 2
x−1
√
π
Γ
x
2

Γ

x + 1
2

follows directly from Theorem 8.19.
8.22 Stirling’s formula. This provides a simple approximate expression for Γ (x+1)
when x is large (hence for n! when n is large). The formula is
(8.103) limx→∞
Γ (x + 1)
(x/e)
x
√
2πx
= 1.
Here is a proof. Put t = x(1 + u) in (8.93). This gives
(8.104) Γ (x + 1) = x
x+1
e
−x
Z∞
−1

(1 + u)e
−u
x
du.
Determine h(u) so that h(0) = 1 and
(8.105) (1 + u)e
−u = exp 
−
u
2
2
h(u)

if −1 < u < ∞, u ̸= 0. Then
(8.106) h(u) = 2
u2
[u − log(1 + u)].
It follows that h is continuous, and that h(u) decreases monotonically from ∞ to 0
as u increases from −1 to ∞.
The substitution u = s
√
2/x turns (8.104) into
(8.107) Γ (x + 1) = x
x
e
−x
√
2x Z∞
−∞
ψx(s) ds
where
ψx(s) = 
exp 
−s
2h(s
√
2/x)

(−√
x/2 < s < ∞)
0 (s ≤ −
√
x/2).
Note the following facts about ψx(s):
(a) For every s, ψx(s) → e
−s
2
as x → ∞.
(b) The convergence in (a) is uniform on [−A, A], for every A < ∞.
(c) When s < 0, then 0 < ψx(s) < e−s
2
.
(d) When s > 0 and x > 1, then 0 < ψx(s) < ψ1(s).EXERCISES 183
(e) R∞
0 ψ1(s) ds < ∞.
The convergence theorem stated in Exercise 7.12 can therefore be applied to the
integral (8.107), and shows that this integral converges to √
π as x → ∞, by (8.101).
This proves (8.103).
A more detailed version of this proof may be found in R. C. Buck’s “Advanced
Calculus,” pp. 216–218 [Buc62a]. For two other, entirely different, proofs, see W.
Feller’s article in Amer. Math. Monthly, vol. 74, 1967, pp. 1223 –1225 [Fel67] (with
a correction in vol. 75, 1968, p. 518 [Fel68]) and pp. 20 –24 of Artin’s book [Art64].
Exercise 8.20 gives a simpler proof of a less precise result.
EXERCISES
8.1. Define
f(x) = 
e
−1/x
2
(x ̸= 0),
0 (x = 0).
Prove that f has derivatives of all orders at x = 0 and that f
(n)
(0) = 0 for n = 1, 2, 3, . . . .
8.2. Let aij be the number in the ith row and jth column of the array
−1 0 0 0 · · ·
1
2 −1 0 0 · · ·
1
4
1
2 −1 0 · · ·
1
8
1
4
1
2 −1 · · ·
· · · · · · · · · · · ·
.
.
.
so that
aij =



0 (i < j),
−1 (i = j),
2
j−i
(i > j).
Prove that
X
i
X
j
aij = −2
X
j
X
i
aij = 0.
8.3. Prove that
X
i
X
j
aij =
X
j
X
i
aij
if aij ≥ 0 for all i and j (the case +∞ = +∞ may occur).
8.4. Prove the following limit relations:
(a) lim
x→0
b
x − 1
x
= log b (b > 0).
(b) lim
x→0
log(1 + x)
x
= 1.
(c) lim
x→0
(1 + x)
1/x = e.
(d) limn→∞ 
1 +
x
n
n
= e
x
.EXERCISES 184
8.5. Find the following limits:
(a) lim
x→0
e − (1 + x)
1/x
x
.
(b) limn→∞
n
log n
h
n
1/n − 1
i
.
(c) lim
x→0
tan x − x
x(1 − cos x)
.
(d) lim
x→0
x − sin x
tan x − x
.
8.6. Suppose f(x)f(y) = f(x + y) for all real x and y.
(a) Assuming that f is differentiable and not zero, prove that
f(x) = e
cx
where c is a constant.
(b) Prove the same thing, assuming only that f is continuous.
8.7. If 0 < x < π
2
, prove that
2
π
<
sin x
x
< 1.
8.8. For n = 0, 1, 2, . . . and x real, prove that
|sin nx| ≤ n |sin x| .
Note that this inequality may be false for other values of n. For instance,




sin 1
2
π




>
1
2
|sin π| .
8.9.
(a) Put sN = 1 +
￾
1
2

+ · · · + (1/N). Prove that
lim
N→∞
(sN − log N)
exists. (The limit, often denoted by γ, is called Euler’s constant. Its numerical value is
0.5772 . . . . It is not known whether γ is rational or not.)
(b) Roughly how large must m be so that N = 10m satisfies sN > 100?
8.10. Prove that P1/p diverges; the sum extends over all primes.
(This shows that the primes form a fairly substantial subset of the positive integers.)
Hint: Given N, let p1, . . . , pk be those primes that divide at least one integer ≤ N. Then
XN
n=1
1
n
≤
Yk
j=1
 
1 +
1
pj
+
1
p
2
j
+ · · · !
=
Yk
j=1

1 −
1
pj
−1
≤ expXk
j=1
2
pj
EXERCISES 185
The last inequality holds because
(1 − x)
−1 ≤ e
2x
if 0 ≤ x ≤ 1
2
.
(There are many proofs of this result. See, for instance, the article by I. Niven in Amer.
Math. Monthly, vol. 78, 1971, pp. 272–273 [Niv71], and the one by R. Bellman in Amer. Math.
Monthly, vol. 50, 1943, pp. 318–319 [Bel43].)
8.11. Suppose f ∈ R on [0, A] for all A < ∞, and f(x) → 1 as x → +∞. Prove that
lim
t→0
t
Z∞
0
e
−txf(x) dx = 1 (t > 0).
8.12. Suppose 0 < δ < π, f(x) = 1 if |x| ≤ δ, f(x) = 0 if δ < |x| ≤ π, and f(x + 2π) = f(x) for
all x.
(a) Compute the Fourier coefficients of f.
(b) Conclude that
X∞
n=1
sin(nδ)
n
=
π − δ
2
(0 < δ < π).
(c) Deduce from Parseval’s theorem that
X∞
n=1
sin2
(nδ)
n2δ
=
π − δ
2
.
(d) Let δ → 0 and prove that
Z∞
0

sin x
x
2
dx =
π
2
.
(e) Put δ = π/2 in (c). What do you get?
8.13. Put f(x) = x if 0 ≤ x < 2π, and apply Parseval’s theorem to conclude that
X∞
n=1
1
n2
=
π
2
6
.
8.14. If f(x) = (π − |x|)
2 on [−π, π], prove that
f(x) = π
2
3
+
X∞
n=1
4
n2
cos nx
and deduce that
X∞
n=1
1
n2
=
π
2
6
,
X∞
n=1
1
n4
=
π
4
90 .
(A recent article by E. L. Stark contains many references to series of the form Pn
−s
,
where s is a positive integer. See Math. Mag., vol. 47, 1947, pp. 197 –202.)
8.15. With Dn as defined in (8.77), put
KN(x) = 1
N + 1
XN
n=0
Dn(x).
Prove that
KN(x) = 1
N + 1
·
1 − cos(N + 1)x
1 − cos xEXERCISES 186
and that
(a) KN ≥ 0,
(b) 1
2π Z π
−π
KN(x) dx = 1,
(c) KN(x) ≤
1
N + 1
·
2
1 − cos δ
if 0 < δ ≤ |x| ≤ π.
If sN = sN(f; x) is the Nth partial sum of the Fourier series of f, consider the arithmetic
means
σN =
s0 + s1 + · · · + sN
N + 1
.
Prove that
σN(f; x) = 1
2π Z π
−π
f(x − t)KN(t) dt,
and hence prove Fejer’s Theorem: ´
If f is continuous, with period 2π, then σN(f; x) → f(x) uniformly on [−π, π].
Hint: Use properties (a), (b), (c) to proceed as in Theorem 7.26.
8.16. Prove a pointwise version of Fejer’s Theorem: ´
If f ∈ R and f(x+), f(x−) exist for some x, then
lim
N→∞
σN(f; x) = 1
2
[f(x+) + f(x−)].
8.17. Assume f is bounded and monotonic on [π, π), with Fourier coefficients cn, as given by
(8.62).
(a) Use Exercise 6.17 to prove that (ncn) is a bounded sequence.
(b) Combine (a) with Exercise 8.16 and with Exercise 3.14(e) to conclude that
lim
N→∞
sN(f; x) = 1
2
[f(x+) + f(x−)]
for every x.
(c) Assume only that f ∈ R on [−π, π] and that f is monotonic in some segment (α, β) ⊂
[−π, π]. Prove that the conclusion of (b) holds for every x ∈ (α, β).
(This is an application of the localization theorem.)
8.18. Define
f(x) = x
3 − sin2
x tan x
g(x) = 2x2 − sin2
x − x tan x.
Find out, for each of these two functions, whether it is positive or negative for all x ∈ (0, π/2),
or whether it changes sign. Prove your answer.
8.19. Suppose f is a continuous function on R1
, f(x + 2π) = f(x), and α/π is irrational. Prove
that
lim
N→∞
1
N
XN
n=1
f(x + nα) = 1
2π Z π
−π
f(t) dt
for every x. Hint: Do it first for f(x) = e
ikx.
8.20. The following simple computation yields a good approximation to Stirling’s formula.
For m = 1, 2, 3, . . . , define
f(x) = (m + 1 − x)log m + (x − m)log(m + 1)EXERCISES 187
if m ≤ x ≤ m + 1, and define
g(x) = x
m
− 1 + log m
if m −
1
2 ≤ x < m +
1
2
. Draw the graphs of f and g. Note that f(x) ≤ log x ≤ g(x) if x ≥ 1
and that
Z n
1
f(x) dx = log(n!) − 1
2
log n > −
1
8
+
Z n
1
g(x) dx.
Integrate log x over [1, n]. Conclude that
7
8
< log(n!) − 
n +
1
2

log n + n < 1
for n = 2, 3, 4, . . . . (Note: log √
2π ∼ 0.918.) Thus
e
7/8 <
n!
(n/e)n
√
n
< e.
8.21. Let
Ln =
1
2π Z π
−π
|Dn(t)| dt (n = 1, 2, 3, . . .).
Prove that there exists a constant C > 0 such that
Ln > C log n (n = 1, 2, 3, . . .),
or, more precisely, that the sequence

Ln −
4
π2
log n

is bounded.
8.22. If α is real and −1 < x < 1, prove Newton’s binomial theorem
(1 + x)
α = 1 +
X∞
n=1
α(α − 1)· · ·(α − n + 1)
n!
x
n.
Hint: Denote the right side by f(x). Prove that the series converges. Prove that
(1 + x)f
′
(x) = αf(x)
and solve this differential equation.
Show also that
(1 − x)
−α =
X∞
n=0
Γ (n + α)
n!Γ (α)
x
n
if −1 < x < 1 and α > 0.
8.23. Let γ be a continuously differentiable closed curve in the complex plane, with parameter
interval [a, b], and assume that γ(t) ̸= 0 for every t ∈ [a, b]. Define the index of γ to be
Ind(γ) = 1
2πi Z b
a
γ
′
(t)
γ(t)
dt.
Prove that Ind(γ) is always an integer.
Hint: There exists ϕ on [a, b] with ϕ′ = γ
′/γ, ϕ(α) = 0. Hence γ exp(−ϕ) is constant.
Since γ(a) = γ(b) it follows that exp ϕ(b) = exp ϕ(a) = 1. Note that ϕ(b) = 2πi Ind(γ).
Compute Ind(γ) when γ(t) = e
int
, a = 0, b = 2π.
Explain why Ind(γ) is often called the winding number of γ around 0.EXERCISES 188
8.24. Let γ be as in Exercise 8.23, and assume in addition that the range of γ does not intersect
the negative real axis. Prove that Ind(γ) = 0. Hint: For 0 ≤ c < ∞, Ind(γ + c) is a continuous
integer-valued function of c. Also, Ind(γ + c) → 0 as c → ∞.
8.25. Suppose γ1 and γ2 are curves as in Exercise 8.23, and
|γ1(t) − γ2(t)| < |γ1(t)| (a ≤ t ≤ b).
Prove that Ind(γ1) = Ind(γ2).
Hint: Put γ = γ2/γ1. Then |1 − γ| < 1, hence Ind(γ) = 0, by Exercise 8.24. Also,
γ
′
γ
=
γ
′
2
γ2
−
γ
′
1
γ1
.
8.26. Let γ be a closed curve in the complex plane (not necessarily differentiable) with param￾eter interval [0, 2π], such that γ(t) ̸= 0 for every t ∈ [0, 2π].
Choose δ > 0 so that |γ(t)| > δ for all t ∈ [0, 2π]. If P1 and P2 are trigonometric poly￾nomials such that

Pj(t) − γ(t)

 < δ/4 for all t ∈ [0, 2π] (their existence is assured by Theo￾rem 8.15), prove that
Ind(P1) = Ind(P2)
by applying Exercise 8.25.
Define this common value to be Ind(γ).
Prove that the statements of Exercises 8.24 and 8.25 hold without any differentiability
assumption.
8.27. Let f be a continuous complex function defined in the complex plane. Suppose there is
a positive integer n and a complex number c ̸= 0 such that
lim
|z|→∞
z
−nf(z) = c.
Prove that f(z) = 0 for at least one complex number z.
Note that this is a generalization of Theorem 8.8.
Hint: Assume f(z) ̸= 0 for all z, define
γr(t) = f(reit)
for 0 ≤ r < ∞, 0 ≤ t ≤ 2π, and prove the following statements about the curves γr:
(a) Ind(γ0) = 0.
(b) Ind(γr) = n for all sufficiently large r.
(c) Ind(γr) is a continuous function of r on [0,∞).
[In (b) and (c), use the last part of Exercise 8.26.]
Show that (a), (b), and (c) are contradictory, since n > 0.
8.28. Let D be the closed unit disc in the complex plane. (Thus z ∈ D if and only if |z| ≤ 1.)
Let g be a continuous mapping of D into the unit circle T. (Thus, |g(z)| = 1 for every z ∈ D.)
Prove that g(z) = −z for at least one z ∈ T.
Hint: For 0 ≤ r ≤ 1, 0 ≤ t ≤ 2π, put
γr(t) = g(reit),
and put ψ(t) = e
−itγ1(t). If g(z) ̸= −z for every z ∈ T, then ψ(t) ̸= −1 for every t ∈ [0, 2π].
Hence Ind(ψ) = 0, by Exercises 8.24 and 8.26. It follows that Ind(γ1) = 1. But Ind(γ0) = 0.
Derive a contradiction, as in Exercise 8.27.
8.29. Prove that every continuous mapping f of D into D has a fixed point in D.
(This is the 2-dimensional case of Brouwer’s fixed-point theorem.)EXERCISES 189
Hint: Assume f(z) ̸= z for every z ∈ D. Associate to each z ∈ D the point g(z) ∈ T which
lies on the ray that starts at f(z) and passes through z. Then g maps D into T, g(z) = z if
z ∈ T, and g is continuous, because
g(z) = z − s(z)[f(z) − z],
where s(z) is the unique nonnegative root of a certain quadratic equation whose coefficients
are continuous functions of f and z. Apply Exercise 8.28.
8.30. Use Stirling’s formula to prove that
limx→∞
Γ (x + c)
x
cΓ (x)
= 1
for every real constant c.
8.31. In the proof of Theorem 7.26 it was shown that
Z 1
−1
(1 − x
2
)
n dx ≥
4
3
√
n
for n = 1, 2, 3, . . . . Use Theorem 8.20 and Exercise 8.30 to show the more precise result
limn→∞
√
n
Z 1
−1
(1 − x
2
)
n dx =
√
π.Chapter 9
FUNCTIONS OF SEVERAL
VARIABLES
LINEAR TRANSFORMATIONS
We begin this chapter with a discussion of sets of vectors in euclidean n-space Rn.
The algebraic facts presented here extend without change to finite-dimensional
vector spaces over any field of scalars. However, for our purposes it is quite suffi￾cient to stay within the familiar framework provided by the euclidean spaces.
9.1 Definition.
(a) A nonempty set X ⊂ Rn is a vector space if x + y ∈ X and cx ∈ X for all x ∈ X,
y ∈ X, and for all scalars c.
(b) If x1, . . . , xk ∈ Rn and c1, . . . , ck are scalars, the vector
c1x1 + · · · + ckxk
is called a linear combination of x1, . . . , xk. If S ⊂ Rn and if E is the set of all
linear combinations of elements of S, we say that S spans E or that E is the
span of S.
Observe that every span is a vector space.
(c) A set consisting of vectors x1, . . . , xk (we shall use the notation {x1, . . . , xk}
for such a set) is said to be independent if the relation c1x1 + · · · + ckxk = 0
implies that c1 = · · · = ck = 0. Otherwise {x1, . . . , xk} is said to be dependent.
Observe that no independent set contains the null vector.
(d) If a vector space X contains an independent set of r vectors but contains no
independent set of r + 1 vectors, we say that X has dimension r and write:
dim X = r.
The set consisting of 0 alone is a vector space; its dimension is 0.
190LINEAR TRANSFORMATIONS 191
(e) An independent subset of a vector space X which spans X is called a basis of
X.
Observe that if B = {x1, . . . , xn} is a basis of X, then every x ∈ X has
a unique representation of the form x = Σcjxj
. Such a representation ex￾ists since B spans X, and it is unique since B is independent. The numbers
c1, . . . , cr are called the coordinates of x with respect to the basis B.
The most familiar example of a basis is the set {e1, . . . , en}, where ej
is
the vector in Rn whose jth coordinate is 1 and whose other coordinates are
all 0. If x ∈ Rn, x = (x1, . . . , xn), then x = Σxjej
. We shall call
{e1, . . . , en}
the standard basis of Rn.
9.2 Theorem. Let r be a positive integer. If a vector space X is spanned by a set of r
vectors, then dim X ≤ r.
Proof. If this is false, there is a vector space X which contains an independent set
Q = {y1, . . . , yr+1} and which is spanned by a set S0 consisting of r vectors.
Suppose 0 ≤ i < r, and suppose a set Si has been constructed which spans X
and which consists of all yj with 1 ≤ j ≤ i plus a certain collection of r−i members
of S0, say x1, . . . , xr−i
. (In other words, Si
is obtained from S0 by replacing i of its
elements by members of Q, without altering the span.) Since Si spans X, yi+1 is
in the span of Si
; hence there are scalars a1, . . . , ai+1, b1, . . . , br−i with ai+1 = 1
such that
i
X
+1
j=1
ajyj +
Xr−i
k=1
bkxk = 0.
if all bk’s were 0, then independence of Q would force all aj
’s to be 0, a contradic￾tion. It follows that some xk ∈ Si
is a linear combination of the other members of
Ti = Si ∪ {yi+1}. Remove this xk from Ti and call the remaining set Si+1. Then
Si+1 spans the set set as Ti
, namely X, so that Si+1 has the properties postulated
for Si with i + 1 in place of i.
Starting with S0, we thus construct sets S1, . . . , Sr. The last of these consists of
y1, . . . , yr and our construction shows that it spans X. But Q is independent; hence
yr+1 is not in the span of Sr. This contradiction establishes the theorem.
Corollary. dim Rn = n.
Proof. Since {e1, . . . , en} spans Rn, the theorem shows that dim Rn ≤ n. Since
{e1, . . . , en} is independent, dim Rn ≥ n.
9.3 Theorem. Suppose X is a vector space and dim X = n.
(a) A set E of n vectors in X spans X if and only if E is independent.
(b) X has a basis, and every basis consists of n vectors.LINEAR TRANSFORMATIONS 192
(c) If 1 ≤ r ≤ n and {y1, . . . , yr} is an independent set in X, then X has a basis
containing {y1, . . . , yr}.
Proof. Suppose E = {x1, . . . , xn}. Since dim X = n, the set {x1, . . . , xn, y} is depen￾dent for every y ∈ X. If E is independent, it follows that y is in the span of E; hence
E spans X. Conversely, if E is independent, one of its members can be removed
without changing the span of E. Hence E cannot span X, by Theorem 9.2. This
proves (a).
Since dim X = n, X contains an independent set of n vectors, and (a) shows
that every such set is a basis of X; (b) now follows from Definition 9.1(d) and The￾orem 9.2.
To prove (c), let {x1, . . . , xn} be a basis of X. The set
S = {y1, . . . , yr, x1, . . . , xn}
spans X and is dependent since it contains more than n vectors. The argument
used in the proof of Theorem 9.2 shows that one of the xi
’s is a linear combination
of the other members of S. If we remove this xi
from S, the remaining set still spans
X. This process can be repeated r times and leads to a basis of X which contains
{y1, . . . , yr}, by (a).
9.4 Definitions. A mapping A of a vector space X into a vector space Y is said to
be a linear transformation if
A(x1 + x2) = Ax1 + Ax2, A(cx) = cAx
for all x, x1, x2 ∈ X and all scalars c. Note that one often writes Ax instead of A(x)
if A is linear.
Observe that A0 = 0 if A is linear. Observe also that a linear transformation A
of X into Y is completely determined by its action on any basis: If {x1, . . . , xn} is a
basis of X, then every x ∈ X has a unique representation of the form
x =
Xn
i=1
cixi
,
and the linearity of A allows us to compute Ax from the vectors Ax1, . . . , Axn and
the coordinates c1, . . . , cn by the formula
Ax =
Xn
i=1
ciAxi
.
Linear transformations of X into X are often called linear operators on X. If A is
a linear operator on X which (i) is one-to-one and (ii) maps X onto X, we say that
A is invertible. In this case we can define an operator A−1 on X by requiring thatLINEAR TRANSFORMATIONS 193
A−1(Ax) = x for all x ∈ X. It is trivial to verify that we then also have A(A−1x) = x
for all x ∈ X, and that A−1 is linear.
An important fact about linear operators on finite dimensional vector spaces is
that each of the above conditions (i) and (ii) implies the other:
9.5 Theorem. A linear operator A on a finite-dimensional vector space X is one-to-one if
and only if the range of A is all of X.
Proof. Let {x1, . . . , xn} be a basis of X. Then linearity of A shows that its range
R(A) is the span of the set Q = {Ax1, . . . , xn}. We therefore infer from Theorem
9.3(a) that R(A) = X if and only if Q is independent. We have to prove that this
happens if and only if A is one-to-one.
Suppose A is one-to-one and ΣciAxi = 0. Then A(Σcixi
) = 0, hence Σcixi = 0,
hence c1 = · · · = cn = 0 and we conclude that Q is independent.
Conversely, suppose Q is independent and A(Σcixi
) = 0. Then ΣciAxi = 0,
hence c1 = · · · = cn = 0 and we conclude: Ax = 0 if and only if x = 0. If now
Ax = Ay, then A(x − y) = Ax − Ay = 0, so that x − y = 0, and this says that A is
one-to-one.
9.6 Definitions.
(a) Let L(X, Y) be the set of all linear transformations of the vector space X into
the vector space Y. Instead of L(X, X), we shall simply write L(X). If A1, A2 ∈
L(X, Y) and if c1 and c2 are scalars, define c1A1 + c2A2 by
(c1A1 + c2A2)x = c1A1x + c2A2x (x ∈ X).
It is then clear that c1A1 + c2A2 ∈ L(X, Y).
(b) If X, Y, Z are vector spaces, and if A ∈ L(X, Y) and B ∈ L(Y, Z), we define
their product BA to be the composition of A and B:
(BA)x = B(Ax) (x ∈ X).
Then BA ∈ L(X, Z). Note that BA need not be the same as AB, even if X =
Y = Z.
(c) For A ∈ L(Rn, Rm), define the norm ∥A∥ of A to be the sup of all numbers
|Ax|, where x ranges over all vectors in Rn with |x| ≤ 1.
Observe that the inequality
|Ax| ≤ ∥A∥ |x|
holds for all x ∈ Rn. Also, if λ is such that |Ax| ≤ λ |x| for all x ∈ Rn, then
∥A∥ ≤ λ.LINEAR TRANSFORMATIONS 194
9.7 Theorem.
(a) If A ∈ L(Rn, Rm), then ∥A∥ < ∞ and A is a uniformly continuous mapping of
Rn into Rm.
(b) If A, B ∈ L(Rn, Rm) and c is a scalar, then
∥A + B∥ ≤ ∥A∥ + ∥B∥ , ∥cA∥ = |c| ∥A∥ .
With the distance between A and B defined as ∥A − B∥, L(Rn, Rm) is a metric
space.
(c) If A ∈ L(Rn, Rm) and B ∈ L(Rm, Rk), then
∥BA∥ ≤ ∥B∥ ∥A∥ .
Proof.
(a) Let {e1, . . . , en} be the standard basis in Rn and suppose x = Σciei and
|x| ≤ 1, so that |ci
| ≤ 1 for i = 1, . . . , n. Then
|Ax| =



XciAei


 ≤
X|ci
| |Aei
| ≤
X|Aei
|
so that
∥A∥ ≤
Xn
i=1
|Aei
| < ∞.
Since |Ax − Ay| ≤ ∥A∥ |x − y| if x, y ∈ Rn, we see that A is uniformly con￾tinuous.
(b) The inequality in (b) follows from
|(A + B)x| = |Ax + Bx| ≤ |Ax| + |Bx| ≤ (∥A∥ + ∥B∥)|x| .
The second part of (b) is proved in the same manner. If
A, B, C ∈ L(Rn, Rm),
we have the triangle inequality
∥A − C∥ = ∥(A − B) + (B − C)∥ ≤ ∥A − B∥ + ∥B − C∥ ,
and it is easily verified that ∥A − B∥ has the other properties of a metric (Def￾inition 2.15).
(c) Finally, (c) follows from
|(BA)x| = |B(Ax)| ≤ ∥B∥ |Ax| ≤ ∥B∥ ∥A∥ |x| .LINEAR TRANSFORMATIONS 195
Since we now have metrics in the spaces L(Rn, Rm), the concepts of open set,
continuity, etc., make sense for these spaces. Our next theorem utilizes these con￾cepts.
9.8 Theorem. Let Ω be the set of all invertible linear operators on Rn,
(a) If A ∈ Ω, B ∈ L(Rn), and
∥B − A∥

A
−1

 < 1,
then B ∈ Ω.
(b) Ω is an open subset of L(Rn) and the mapping A 7→ A−1 is continuous on Ω. (This
mapping is also obviously a 1-1 mapping of Ω onto Ω which is its own inverse.)
Proof.
(a) Put

A−1

 = 1/α, put ∥B − A∥ = β. Then β < α. For every x ∈ Rn,
α |x| = α

A
−1Ax

 ≤ α

A
−1

 |Ax|
= |Ax| ≤ |(A − B)x| + |Bx| ≤ β |x| + |Bx|
so that
(9.1) (α − β)|x| ≤ |Bx| (x ∈ Rn).
Since α − β > 0, (9.1) shows that Bx ̸= 0 if x ̸= 0. Hence B is 1-1. By
Theorem 9.5, B ∈ Ω. This holds for all B with ∥B − A∥ < α. Thus we have
(a) and the fact that Ω is open.
(b) Next, replace x by B
−1y in (9.1). The resulting inequality
(9.2) (α − β)

B
−1y

 ≤

BB−1y

 = |y| (y ∈ Rn)
shows that

B
−1

 ≤ (α − β)
−1. The identity
B
−1 − A
−1 = B
−1
(A − B)A
−1
,
combined with Theorem 9.7(c), implies therefore that

B
−1 − A
−1

 ≤

B
−1

 ∥A − B∥

A
−1

 ≤
β
α(α − β)
.
This establishes the continuity assertion made in (b), since β → 0 as
B → A.LINEAR TRANSFORMATIONS 196
9.9 Matrices. Suppose {x1, . . . , xn} and {y1, . . . , ym} are bases of vector spaces X
and Y, respectively. Then every A ∈ L(X, Y) determines a set of numbers aij such
that
(9.3) Axj =
Xm
i=1
aijyi
(1 ≤ j ≤ n).
It is convenient to visualize these numbers in a rectangular array of m rows and n
columns, called an m by n matrix:
[A] =






a11 a12 · · · a1n
a21 a22 · · · a2n
.
.
.
.
.
.
.
.
.
.
.
.
am1 am2 · · · amn






Observe that the coordinates aij of the vector Axj
(with respect to the basis {y1, . . . , ym})
appear in the jth column of [A]. The vectors Axj are therefore sometimes called the
column vectors of [A]. With this terminology, the range of A is spanned by the column
vectors [A].
If x = Σcjxj
, the linearity of A combined with (9.3) shows that
(9.4) Ax =
Xm
i=1

Xn
j=1
aijcj

 yi
.
Thus the coordinates of Ax are Σjaijcj
. Note that in (9.3) the summation ranges
over the first subscript of aij, but that we sum over the second subscript when
computing coordinates.
Suppose next that an m by n matrix is given, with real entries aij. If A is then
defined by (9.4), it is clear that A ∈ L(X, Y) and that [A] is the given matrix. Thus
there is a natural 1-1 correspondence between L(X, Y) and the set of all real m by
n matrices. We emphasize, though, that [A] depends not only on A but also on the
choice of bases in X and Y. The same A may give rise to many different matrices if
we change bases, and vice versa. We shall not pursue this observation any further,
since we shall usually work with fixed bases. (Some remarks on this may be found
in Remark 9.37.)
If Z is a third vector space with basis {z1, . . . , zp}, if A is given by (9.3), and if
Byi =
X
k
bkizk, (BA)xj =
X
k
ckjzk,
then A ∈ L(X, Y), B ∈ L(Y, Z), BA ∈ L(X, Z).DIFFERENTIATION 197
Since
B(Axj
) = B
 X
i
aijyi
!
=
X
i
aijByi
=
X
i
aijX
k
bkizk =
X
k
 X
i
bkiaij!
zk,
the independence of {z1, . . . , zp} implies that
(9.5) ckj =
X
i
bkiaij (1 ≤ k ≤ p, 1 ≤ j ≤ n).
This shows how to compute the p by n matrix [BA] from [B] and [A]. If we define
the product [B][A] to be [BA], then (9.5) describes the usual rule of matrix multipli￾cation.
Finally, suppose {x1, . . . , xn} and {y1, . . . , ym} are standard bases of Rn and
Rm and A is given by (9.4). The Schwarz inequality shows that
|Ax|
2 =
X
i

X
j
aijcj


2
≤
X
i

X
j
a
2
ij ·
X
j
c
2
j

 =
X
i,j
a
2
ij |x|
2
.
Thus
(9.6) ∥A∥ ≤



X
i,j
a
2
ij



1/2
.
If we apply (9.6) to B − A in place of A, where A, B ∈ L(Rn, Rm), we see that
if the matrix elements aij are continuous functions of a parameter, then the same
is true of A. More precisely:
If S is a metric space, if a11, . . . , amn are real continuous functions on S, and if, for
each p ∈ S, Ap is the linear transformation of Rn into Rm whose matrix has entries
aij(p), then the mapping p → Ap is a continuous mapping of S into L(Rn, Rm).
DIFFERENTIATION
9.10 Preliminaries. In order to arrive at a definition of the derivative of a function
whose domain is Rn (or an open subset of Rn), let us take another look at the
familiar case n = 1, and let us see how to interpret the derivative in that case in a
way which will naturally extend to n > 1.
If f is a real function with domain (a, b) ⊂ R1 and if x ∈ (a, b), then f
′
(x) isDIFFERENTIATION 198
usually defined to be the real number
(9.7) lim
h→0
f(x + h) − f(x)
h
,
provided, of course, that this limit exists. Thus
(9.8) f(x + h) − f(x) = f
′
(x)h + r(h)
where the “remainder” r(h) is small, in the sense that
(9.9) lim
h→0
r(h)
h
= 0.
Note that (9.8) expressed the difference f(x + h) − f(x) as the sum of a linear
function that takes h to f
′
(x)h, plus a small remainder. We can therefore regard the
derivative of f at x, not as a real number, but as the linear operator on R1 that takes
h to f
′
(x)h.
[Observe that every real number α gives rise to a linear operator R1; the opera￾tor in question is simply multiplication by α. Conversely, every linear function that
carries R1 to R1 is multiplication by some real number. It is this natural 1-1 corre￾spondence between R1 and L(R1) which motivates the preceding statements.]
Let us next consider a function f that maps (a, b) ⊂ R1 into Rm. In that case,
f
′
(x) was defined to be the vector y ∈ Rm (if there is one) for which
(9.10) lim
h→0

f(x + h) − f(x)
h
− y

= 0.
We can again rewrite this in the form
(9.11) f(x + h) − f(x) = hy + r(h),
where r(h)/h → 0 as h → 0. The main term on the right side of (9.11) is again a
linear function of h. Every y ∈ Rm induces a linear transformation of R1 into Rm,
by associating to each h ∈ R1 the vector hy ∈ Rm. This identification of Rm with
L(R1, Rm) allows us to regard f
′
(x) as a member of L(R1, Rm).
Thus, if f is a differentiable mapping of (a, b) ⊂ R1 into Rm, and if x ∈ (a, b),
then f
′
(x) is the linear transformation of R1 into Rm that satisfies
(9.12) lim
h→0
f(x + h) − f(x) − f
′
(x)h
h
= 0,
or, equivalently,
(9.13) lim
h→0

f(x + h) − f(x) − f
′
(x)h


|h|
= 0.
We are now ready for the case n > 1.DIFFERENTIATION 199
9.11 Definition. Suppose E is an open set in Rn, f maps E into Rm, and x ∈ E. If
there exists a linear transformation of A of Rn into Rm such that
(9.14) lim
h→0
|f(x + h) − f(x) − Ah|
|h|
= 0,
then we say that f is differentiable at x and we write
(9.15) f
′
(x) = A.
If f is differentiable at every x ∈ E, we say that f is differentiable in E.
It is of course understood in (9.14) that h ∈ Rn. If |h| is small enough, then
x + h ∈ E, since E is open. Thus f(x + h) is defined, f(x + h) ∈ Rm, and since
A ∈ L(Rn, Rm), Ah ∈ Rm. Thus
f(x + h) − f(x) − Ah ∈ Rm.
The norm in the numerator of (9.14) is that of Rm. In the denominator we have
the Rn-norm of h.
There is an obvious uniqueness problem that has to be settled before we go any
further.
9.12 Theorem. Suppose E and f are as in Definition 9.11, x ∈ E, and (9.14) holds with
A = A1 and with A = A2. Then A1 = A2.
Proof. If B = A1 − A2, the inequality
|Bh| ≤ |f(x + h) − f(x) − A1h| + |f(x + h) − f(x) − A2h|
shows that |Bh| / |h| → 0 as h → 0. For any fixed h ̸= 0, it follows that
(9.16) |B(th)|
|th|
→ 0 as t → 0.
The linearity of B shows that the left side of (9.16) is independent of t. Thus Bh = 0
for every h ∈ Rn. Hence B = 0.
9.13 Remarks.
(a) The relation (9.14) can be written in the form
(9.17) f(x + h) − f(x) = f
′
(x)h + r(h)
where the remainder r(h) satisfies
(9.18) lim
h→0
|r(h)|
|h|
= 0.DIFFERENTIATION 200
We may interpret (9.17), as in Theorem 9.10, by saying that for fixed x and
small h, the left side of (9.17) is approximately equal to f
′
(h), that is, to the
value of a linear transformation applied to h.
(b) Suppose f and E are as in Definition 9.11 and f is differentiable in E. For
every x ∈ E, f
′
(x) is then a function, namely, a linear transformation of Rn
into Rm. But f
′
is also a function: f
′ maps E into L(Rn, Rm).
(c) A glance at (9.17) shows that f is continuous at any point at which f is differ￾entiable.
(d) The derivative defined by (9.14) or (9.17) is often called the differential of f at
x, or the total derivative of f at x, to distinguish it from the partial derivatives
that will occur later.
9.14 Example. We have defined derivatives of functions carrying Rn to Rm to
be linear transformations of Rn into Rm. What is the derivative of such a linear
transformation? The answer is very simple: If A ∈ L(Rn, Rm) and if x ∈ Rn, then
(9.19) A
′
(x) = A.
Note that x appears on the left side of (9.19) but not on the right. Both sides of
(9.19) are members of L(Rn, Rm), whereas Ax ∈ Rm.
The proof of (9.19) is a triviality, since
(9.20) A(x + h) − Ax = Ah,
by the linearity of A. With f(x) = Ax, the numerator in (9.14) is thus 0 for every
h ∈ Rn. In (9.17), r(h) = 0.
We now extend the chain rule (Theorem 5.5) to the present situation.
9.15 Theorem. Suppose E is an open set in Rn, f maps E into Rm, f is differentiable at
x0 ∈ E, g maps an open set containing f(E) into Rk, and g is differentiable at f(x0). Then
the mapping F of E into Rk defined by
F(x) = g(f(x))
is differentiable at x0, and
(9.21) F
′
(x0) = g
′
(f(x0))f
′
(x0).
On the right side of (9.21), we have the product of two linear transformations,
as defined in Definition 9.6.
Proof. Put y0 = f(x0), A = f
′
(x0), B = g
′
(y0), and define
u(h) = f(x0 + h) − f(x0) − Ah,
v(k) = g(y0 + k) − g(y0) − Bk,DIFFERENTIATION 201
for all h ∈ Rn and k ∈ Rm for which f(x0 + h) and g(y0 + k) are defined. Then
(9.22) |u(h)| = ε(h)|h| , |v(k)| = η(k)|k| ,
where ε(h) → 0 as h → 0 and η(k) → 0 as k → 0.
Given h, put k = f(x0 + h) − f(x0). Then
(9.23) |k| = |Ah + u(h)| ≤ [∥A∥ + ε(h)] |h| ,
and
F(x0 + h) − F(x0) − BAh = g(y0 + k) − g(y0) − BAh
= B(k − Ah) + v(k)
= Bu(h) + v(k).
Hence (9.22) and (9.23) imply, for h ̸= 0, that
|F(x0 + h) − F(x0) − BAh|
|h|
≤ ∥B∥ ε(h) + [∥A∥ + ε(h)] η(k).
Let h → 0. Then ε(h) → 0. Also k → 0, by (9.23), so that η(k) → 0. It follows that
F
′
(x0) = BA, which is what (9.21) asserts.
9.16 Partial Derivatives. We again consider a function f that maps an open set
E ⊂ Rn into Rm. Let {e1, . . . , en} and {u1, . . . , um} be the standard bases of Rn
and Rm. The components of f are the real functions f1, . . . , fm defined by
(9.24) f(x) = Xm
i=1
fi
(x)ui
(x ∈ E),
or, equivalently, by fi
(x) = f(x) · ui
, 1 ≤ i ≤ m.
For x ∈ E, 1 ≤ i ≤ m, 1 ≤ j ≤ n, we define
(9.25) (Djfi
)(x) = lim
t→0
fi
(x + tej
) − fi
(x)
t
,
provided the limit exists. Writing fi
(x1, . . . , xn) in place of fi
(x), we see that Djfi
is the derivative of fi with respect to xj
, keeping the other variables fixed. The
notation
(9.26) ∂fi
∂xj
is therefore often used in place of Djfi
, and Djfi
is called a partial derivative.
In many cases where the existence of a derivative is sufficient when dealing
with functions of one variable, continuity or at least boundedness of the partial
derivatives is needed for functions of several variables. For example, the functionsDIFFERENTIATION 202
f and g described in Exercise 4.7 are not continuous, although their partial deriva￾tives exist at every point of R2. Even for continuous functions, the existence of all
partial derivatives does not imply differentiability in the sense of Definition 9.11;
see Exercises 9.6 and 9.14 and Theorem 9.21.
However, if f is known to be differentiable at a point x, then its partial deriva￾tives exist at x and they determine the linear transformation f
′
(x) completely:
9.17 Theorem. Suppose f maps an open set E ⊂ Rn into Rm, and f is differentiable at
a point x ∈ E. Then the partial derivatives (Djfi
)(x) exist and
(9.27) f
′
(x)ej =
Xm
i=1
(Djfi
)(x)ui
(1 ≤ j ≤ n).
Here, as in Theorem 9.16, {e1, . . . , en} and {u1, . . . , um} are the standard bases
of Rn and Rm.
Proof. Fix j. Since f is differentiable at x,
f(x + tej
) − f(x) = f
′
(x)(tej
) + r(tej
)
where

r(tej
)

 /t → 0 as t → 0. The linearity of f
′
(x) shows therefore that
(9.28) lim
t→0
f(x + tej
) − f(x)
t
= f
′
(x)ej
.
If we now represent f in terms of its components, as in (9.24), then (9.28) becomes
(9.29) lim
t→0
Xm
i=1
fi
(x + tej
) − fi
(x)
t
ui = f
′
(x)ej
.
It follows that each quotient in this sum has a limit as t → 0 (see Theorem 4.10), so
that each (Djfi
)(x) exists, and then (9.27) follows from (9.29).
Here are some consequences of Theorem 9.17:
Let [f
′
(x)] be the matrix that represents f
′
(x) with respect to our standard bases,
as in Theorem 9.9. Then f
′
(x)ej
is the jth column vector of [f
′
(x)] and (9.27) shows
therefore that the number (Djfi
)(x) occupies the spot in the ith row and the jth
column of [f
′
(x)]. Thus
[f
′
(x)] =




(D1f1)(x) · · · (Dnf1)(x)
.
.
.
.
.
.
.
.
.
(D1fm)(x) · · · (Dnfm)(x)




.DIFFERENTIATION 203
If h = Σhjej
is any vector in Rn, then (9.27) implies that
(9.30) f
′
(x)h =
Xm
i=1



Xn
j=1
(Djfi
)(x)hj



ui
.
9.18 Example. Let γ be a differentiable mapping of the segment (a, b) ⊂ R1 into
an open set E ⊂ Rn; in other words, γ is a differentiable curve in E. Let f be a real￾valued differentiable function with domain E. Thus f is a differentiable mapping
of E into R1. Define
(9.31) g(t) = f(γ(t)) (a < t < b).
The chain rule asserts then that
(9.32) g
′
(t) = f
′
(γ(t))γ
′
(t) (a < t < b).
Since γ
′
(t) ∈ L(R1, Rn) and f
′
(γ(t)) ∈ L(Rn, R1), (9.32) defines g
′
(t) as a lin￾ear operator on R1. This agrees with the fact that g maps (a, b) into R1. How￾ever, g
′
(t) can also be regarded as a real number. (This was discussed in Theo￾rem 9.10.) This number can be computed in terms of the partial derivatives of f
and the derivatives with the components of γ, as we shall now see.
With respect to the standard basis {e1, . . . , en} of Rn, [γ
′
(t)] is the n by 1 matrix
(a “column matrix”) which has γ
′
i
(t) in the ith row, where γ1, . . . , γn are the com￾ponents of γ. For every x ∈ E, [f
′
(x)] is the 1 by n matrix (a “row matrix”) which
has (Djf)(x) in the jth column. Hence [g
′
(t)] is the 1 by 1 matrix whose only entry
is the real number
(9.33) g
′
(t) = Xn
i=1
(Dif)(γ(t))γ
′
i
(t).
This is a frequently encountered special case of the chain rule. It can be rephrased
in the following manner.
Associate with each x ∈ E a vector, the so-called “gradient” of f at x, defined
by
(9.34) (∇f)(x) = Xn
i=1
(Dif)(x)ei
.
Since
(9.35) γ
′
(t) = Xn
i=1
γ
′
i
(t)ei
,DIFFERENTIATION 204
(9.33) can be written in the form
(9.36) g
′
(t) = (∇f)(γ(t)) · γ
′
(t),
the scalar product of the vectors (∇f)(γ(t)) and γ
′
(t).
Let us now fix an x ∈ E, let u ∈ Rn be a unit vector (that is, |u| = 1), and
specialize γ so that
(9.37) γ(t) = x + tu (−∞ < t < ∞).
Then γ
′
(t) = u for every t. Hence (9.36) shows that
(9.38) g
′
(0) = (∇f)(x) · u.
On the other hand, (9.37) shows that
g(t) − g(0) = f(x + tu) − f(x).
Hence (9.38) gives
(9.39) lim
t→0
f(x + tu) − f(x)
t
= (∇f)(x) · u.
The limit in (9.39) is usually called the directional derivative of f at x, in the direc￾tion of the unit vector u, and may be denoted by (Duf)(x). If f and x are fixed, but
u varies, then (9.39) shows that (Duf)(x) attains its maximum when u is a positive
scalar multiple of (∇f)(x). [The case (∇f)(x) = 0 should be excluded here.]
If u = Σuiei
, then (9.39) shows that (Duf)(x) can be expressed in terms of the
partial derivatives of f at x by the formula
(9.40) (Duf)(x) = Xn
i=1
(Dif)(x)ui
.
Some of these ideas will play a role in the following theorem.
9.19 Theorem. Suppose f maps a convex open set E ⊂ Rn into Rm, f is differentiable
in E, and there is a real number M such that

f
′
(x)

 ≤ M
for every x ∈ E. Then
|f(b) − f(a)| ≤ M(b − a)
for all a ∈ E, b ∈ E.
Proof. Fix a ∈ E, b ∈ E. Define
γ(t) = (1 − t)a + tbDIFFERENTIATION 205
for all t ∈ R1 such that γ(t) ∈ E. Since E is convex, γ(t) ∈ E if 0 ≤ t ≤ 1. Put
g(t) = f(γ(t)).
Then
g
′
(t) = f
′
(γ(t))γ
′
(t) = f
′
(γ(t))(b − a),
so that

g
′
(t)

 ≤

f
′
(γ(t))


|b − a| ≤ M|b − a|
for all t ∈ [0, 1]. By Theorem 5.19,
|g(1) − g(0)| ≤ M|b − a| .
But g(0) = f(a) and g(1) = f(b). This completes the proof.
Corollary. If, in addition, f
′
(x) = 0 for all x ∈ E, then f is constant.
Proof. To prove this, note that the hypothesis of the theorem now hold with M =
0.
9.20 Definition. A differentiable mapping f of an open set E ⊂ Rn into Rm is
said to be continuously differentiable if E if f
′
is a continuous mapping of E into
L(Rn, Rm).
More explicitly, it is required that to every x ∈ E and to every ε > 0 corresponds
a δ > 0 such that

f
′
(y) − f
′
(x)

 < ε
if y ∈ E and |x − y| < δ.
If this is so, we also say that f is a C
1 mapping, or that f ∈ C
1(E).
9.21 Theorem. Suppose f maps an open set E ⊂ Rn into Rm. Then f ∈ C
1(E) if and
only if the partial derivatives exist and are continuous for 1 ≤ i ≤ m, 1 ≤ j ≤ n.
Proof. Assume first that f ∈ C
1(E). By (9.27),
(Djfi
)(x) = (f
′
(x)ej
) · ui
for all i, j and for all x ∈ E. Hence
(Djfi
)(y) − (Djfi
)(x) = 
[f
′
(y) − f
′
(x)]ej
	
· ui
and since |ui
| = |ej
| = 1, it follows that

(Djfi
)(y) − (Djfi
)(x)

 ≤


[f
′
(y) − f
′
(x)]ej


≤

f
′
(y) − f
′
(x)

 .
Hence Djfi
is continuous.THE CONTRACTION PRINCIPLE 206
For the converse, it suffices to consider the case m = 1. (Why?) Fix x ∈ E and
ε > 0. Since E is open, there is an open ball S ⊂ E, with center at x and radius r,
and the continuity of the functions Djf shows that r can be chosen so that
(9.41)

(Djf)(y) − (Djf)(x)

 <
ε
n
(y ∈ S, 1 ≤ j ≤ n).
Suppose h = Σhjej
, |h| < r, put v0 = 0, and vk = h1e1 + · · · + hkek, for
1 ≤ k ≤ n. Then
(9.42) f(x + h) − f(x) = Xn
j=1
[f(x + vj
) − f(x + vj−1)].
Since |vk| < r for 1 ≤ k ≤ n and since S is convex, the segments with end points
x + vj−1 and x + vj
lie in S. Since vj = vj−1 + hjej
, the mean value theorem
(Theorem 5.10) shows that the jth summand in (9.42) is equal to
hj
(Djf)(x + vj−1 + θjhjej
)
for some θj ∈ (0, 1), and this differs from hj
(Djf)(x) by less than

hj

 ε/n, using
(9.41). By (9.42), it follows that






f(x + h) − f(x) −Xn
j=1
hj
(Djf)(x)






≤
1
n
Xn
j=1

hj

 ε ≤ |h| ε
for all h such that |h| < r.
This says that f is differentiable at x and that f
′
(x) is the linear function which
assigns the number Σhj
(Djf)(x) to the vector h = Σhjej
. The matrix [f
′
(x)] consists
of the row (D1f)(x), . . . ,(Dnf)(x); since D1f, . . . , Dnf are continuous functions on
E, the concluding remarks of Theorem 9.9 show that f ∈ C
1(E).
THE CONTRACTION PRINCIPLE
We now interrupt our discussion of differentiation to insert a fixed point theorem
that is valid in arbitrary complete metric spaces. It will be used in the proof of the
inverse function theorem.
9.22 Definition. Let X be a metric space with metric d. If φ maps X into X and if
there is a number c < 1 such that
(9.43) d(φ(x), φ(y)) ≤ cd(x, y)
for all x, y ∈ X, then φ is said to be a contraction of X into X.
9.23 Theorem. If X is a complete metric space and φ is a contraction of X into X, then
there exists one and only one x ∈ X such that φ(x) = x.THE INVERSE FUNCTION THEOREM 207
In other words, φ has a unique fixed point. The uniqueness is a triviality, for if
φ(x) = x and φ(y) = y, then (9.43) gives d(x, y) ≤ cd(x, y) which can only happen
when d(x, y) = 0.
The existence of a fixed point of φ is the essential part of the theorem. The proof
actually furnishes a constructive method for locating the fixed point.
Proof. Pick x0 ∈ X arbitrarily and define (xn) recursively, by setting
(9.44) xn+1 = φ(xn) (n = 0, 1, 2, . . .).
Choose c < 1 so that (9.43) holds. For n ≥ 1 we then have
d(xn+1, xn) = d(φ(xn), φ(xn−1)) ≤ cd(xn, xn−1).
Hence induction gives
(9.45) d(xn+1, dn) ≤ c
nd(x1, x0) (n = 0, 1, 2, . . .).
If n < m, it follows that
d(xn, xm) ≤
Xm
i=n+1
d(xi
, xi+1)
≤ (c
n + c
n+1 + · · · + cm−1
)d(x1, x0)
≤ [(1 − c)
−1d(x1, x0)]c
n.
Thus (xn) is a Cauchy sequence. Since X is complete, lim xn = x for some x ∈ X.
Since φ is a contraction, φ is continuous (in fact, uniformly continuous) on X.
Hence
φ(x) = lim n→∞
φ(xn) = lim n→∞
φ(xn+1) = x.
THE INVERSE FUNCTION THEOREM
The inverse function theorem states, roughly speaking, that a continuously dif￾ferentiable mapping f is invertible in a neighborhood of any point x at which the
linear transformation f
′
(x) is invertible:
9.24 Theorem. Suppose f is a C
1-mapping of an open set E ⊂ Rn into Rn, f
′
(a) is
invertible for some a ∈ E, and b = f(a). Then
(a) there exist open sets U and V in Rn such that a ∈ U, b ∈ V, f is one-to-one on U,
and f(U) = V;
(b) if g is the inverse of f [which exists, by (a)], defined in V by
g(f(x)) = x (x ∈ U),
then g ∈ C
1(V).THE INVERSE FUNCTION THEOREM 208
Writing the equation y = f(x) in component form, we arrive at the following
interpretation of the conclusion of the theorem: The system of n equations
yi = fi
(x1, . . . , xn) (1 ≤ i ≤ n)
can be solved for x1, . . . , xn in terms of y1, . . . , yn, if we restrict x and y to small
enough neighborhoods of a and b; the solutions are unique and continuously dif￾ferentiable.
Proof.
(a) Put f
′
(a) = A and choose λ so that
(9.46) 2λ

A
−1

 = 1.
Since f
′
is continuous at a, there is an open ball U ⊂ E with center a such that
(9.47)

f
′
(x) − A

 < λ (x ∈ U).
We associate to each y ∈ Rn a function φ, defined by
(9.48) φ(x) = x + A
−1
(y − f(x)) (x ∈ E).
Note that f(x) = y if and only if x is a fixed point of φ.
Since φ′
(x) = I − A−1f
′
(x) = A−1(A − f
′
(x)), (9.46) and (9.47) imply that
(9.49)

φ
′
(x)

 <
1
2
(x ∈ U).
Hence
(9.50) |φ(x1) − φ(x2)| ≤
1
2
|x1 − x2| (x1, x2 ∈ U),
by Theorem 9.19. It follows that φ has at most one fixed point in U, so that
f(x) = y for at most one x ∈ U.
Thus f is 1-1 in U.
Next, put V = f(U) and pick y0 ∈ V. Then y0 = f(x0) for some x0 ∈ U.
Let B be an open ball with center at x0 and radius r > 0, so small that its
closure B lies in U. We will show that y ∈ V whenever |y − y0| < λr. This
proves, of course, that V is open.
Fix y, |y − y0| < λr. With φ as in (9.48),
|φ(x0) − x0| =

A
−1
(y − y0)

 <

A
−1

λr =
r
2
.THE INVERSE FUNCTION THEOREM 209
If x ∈ B, it therefore follows from (9.50) that
|φ(x) − x0| ≤ |φ(x) − φ(x0)| + |φ(x0) − x0|
<
1
2
|x − x0| +
r
2
≤ r;
hence φ(x) ∈ B. Note that (9.50) holds if x1 ∈ B, x2 ∈ B.
Thus φ is a contraction of B into B. Being a closed subset of Rn, B is
complete. Theorem 9.23 implies therefore that φ has a fixed point x ∈ B.
For this x, f(x) = y. Thus y ∈ f(B) ⊂ f(U) = V. This proves part (a) of the
theorem.
(b) Pick y ∈ V, y + k ∈ V. Then there exist x ∈ U, x + h ∈ U, so that y = f(x),
y + k = f(x + h). With φ as in (9.48),
φ(x + h) − φ(x) = h + A
−1
[f(x) − f(x + h)] = h − A
−1k.
By (9.50),

h − A−1k

 ≤ |h| /2. Hence

A−1k

 ≥ |h| /2 and
(9.51) |h| ≤ 2

A
−1

 |k| = λ
−1
|k| .
By (9.46), (9.47), and Theorem 9.8, f
′
(x) has an inverse, say T. Since
g(y + k) − g(y) − Tk = h − Tk = −T[f(x + h) − f(x) − f
′
(x)h],
(9.51) implies
|g(y + k) − g(y) − Tk|
|k|
≤
∥T∥
λ
·

f(x + h) − f(x) − f
′
(x)h


|h|
.
As k → 0, (9.51) shows that h → 0. The right side of the last inequality
thus tends to 0. Hence the same is true of the left. We have thus proved that
g
′
(y) = T. But T was chosen to be the inverse of f
′
(x) = f
′
(g(y)). Thus
(9.52) g
′
(y) = 
f
′
(g(y))	−1
(y ∈ V).
Finally, note that g is a continuous mapping of V onto U (since g is differ￾entiable), that f
′
is a continuous mapping of U into the set Ω of all invertible
elements of L(Rn), and that inversion is a continuous mapping of Ω onto Ω,
by Theorem 9.8. If we combine these facts with (9.52), we see that g ∈ C
1(V).
This completes the proof.
Remark. The full force of the assumption that f ∈ C
1(E) was only used in the
last paragraph of the preceding proof. Everything else, down to (9.52), was derived
from the existence of f
′
(x) for x ∈ E, the invertibility of f
′
(a), and the continuity of
f
′ at just the point a. In this connection, we refer to the article by A. Nijenhuis in
Amer. Math. Monthly, vol. 81, 1974, pp. 969-980.THE IMPLICIT FUNCTION THEOREM 210
The following is an immediate consequence of part (a) of the inverse function
theorem.
9.25 Theorem. If f is a C
1-mapping of an open set E ⊂ Rn into Rn and if f
′
(x) is
invertible for every x ∈ E, then f(W) is an open subset of Rn for every open set W ⊂ E.
In other words, f is an open mapping of E into Rn.
The hypotheses made in this theorem ensure that each point x ∈ E has a neigh￾borhood in which f is 1-1. This may be expressed by saying that f is locally one-to￾one in E. But f need not be 1-1 in E under these circumstances. For an example, see
Exercise 9.17.
THE IMPLICIT FUNCTION THEOREM
If f is a continuously differentiable real function in the plane, then the equation
f(x, y) = 0 can be solved for y in terms of x in a neighborhood of any point (a, b)
at which f(a, b) = 0 and ∂f/∂y ̸= 0. Likewise, one can solve for x in terms of y
near (a, b) if ∂f/∂x ̸= 0 at (a, b). For a simple example which illustrates the need
for assuming ∂f/∂y ̸= 0, consider f(x, y) = x
2 + y
2 − 1.
The preceding very informal statement is the simplest case (the case m = n = 1
of Theorem 9.28) of the so-called “implicit function theorem.” Its proof makes
strong use of the fact that continuously differentiable transformations behave lo￾cally very much like their derivatives. Accordingly, we first prove Theorem 9.27,
the linear version of Theorem 9.28.
9.26 Notation. If x = (x1, . . . , xn) ∈ Rn and y = (y1, . . . , ym) ∈ Rm, let us write
(x, y) for the point (or vector)
(x1, . . . , xn, y1, . . . , ym) ∈ Rn+m.
In what follows, the first entry in (x, y) or in a similar symbol will always be a
vector in Rn, the second will be a vector in Rm.
Every A ∈ L(Rn+m, Rn) can be split into two linear transformations Ax and
Ay defined by
(9.53) Axh = A(h, 0), Ayk = A(0, k)
for any h ∈ Rn, k ∈ Rm. Then Ax ∈ L(Rn), Ay ∈ L(Rm, Rn), and
(9.54) A(h, k) = Axh + Ayk.
The linear version of the implicit function theorem is now almost obvious.THE IMPLICIT FUNCTION THEOREM 211
9.27 Theorem. If A ∈ L(Rn+m, Rn) and if Ax is invertible, then there corresponds to
every k ∈ Rm a unique h ∈ Rn such that A(h, k) = 0. This h can be computed from k
by the formula
(9.55) h = −(Ax)
−1Ayk.
Proof. By (9.54), A(h, k) = 0 if and only if
Axh + Ayk = 0,
which is the same as (9.55) when Ax is invertible.
The conclusion of Theorem 9.27 is, in other words, that the equation A(h, k) = 0
can be solved (uniquely) for h if k is given, and that the solution h is a linear func￾tion of k. Those who have some acquaintance with linear algebra will recognize
this as a very familiar statement about systems of linear equations.
9.28 Theorem. Let f be a C
1-mapping of an open set E ⊂ Rn+m into Rn such that
f(a, b) = 0 for some point (a, b) ∈ E.
Put A = f
′
(a, b) and assume that Ax is invertible. Then there exist open sets U ⊂
Rn+m and W ⊂ Rm, with (a, b) ∈ U and b ∈ W, having the following property:
To every y ∈ W corresponds a unique x such that
(9.56) (x, y) ∈ U and f(x, y) = 0.
If this x is defined to be g(y), then g is a C
1-mapping of W into Rn, g(b) = a,
(9.57) f(g(y), y) = 0 (y ∈ W),
and
(9.58) g
′
(b) = −(Ax)
−1Ay.
The function g is “implicitly” defined by (9.57). Hence the name of the theorem.
The equation f(x, y) = 0 can be written as a system of n equations in n + m
variables:
(9.59)



f1(x1, . . . , xn, y1, . . . , ym) = 0
.
.
.
.
.
.
fn(x1, . . . , xn, y1, . . . , ym) = 0.
The assumption that Ax is invertible means that the n by n matrix




D1f1 · · · Dnf1
.
.
.
.
.
.
.
.
.
D1fn · · · Dnfn



THE IMPLICIT FUNCTION THEOREM 212
evaluated at (a, b) defines an invertible linear operator in Rn; in other words, its
column vectors should be independent, or, equivalently, its determinant should be
nonzero. (See Theorem 9.36.) If, furthermore, (9.59) holds when x = a and y = b,
then the conclusion of the theorem is that (9.59) can be solved for x1, . . . , xn in
terms of y1, . . . , ym, for every y near b, and that these solutions are continuously
differentiable functions of y.
Proof. Define F by
(9.60) F(x, y) = (f(x, y), y) ((x, y) ∈ E).
Then F is a C
1-mapping of E into Rn+m. We claim that F
′
(a, b) is an invertible
element of L(Rn+m):
Since f(a, b) = 0, we have
f(a + h, b + k) = A(h, k) + r(h, k),
where r is the remainder that occurs in the definition of f
′
(a, b). Since
F(a + h, b + k) − F(a, b) = (f(a + h, b + k), k)
= (A(h, k), k) + (r(h, k), 0),
it follows that F
′
(a, b)is the linear operator on Rn+m that maps (h, k)to (A(h, k), k).
If this image vector is 0, then A(h, k) = 0 and k = 0, hence A(h, 0) = 0 and The￾orem 9.27 implies that h = 0. It follows that F
′
(a, b) is 1-1; hence it is invertible
(Theorem 9.5).
The inverse function theorem can therefore be applied to F. It shows that there
exist open sets U and V in Rn+m, with (a, b) ∈ U, (0, b) ∈ V, such that F is a 1-1
mapping of U onto V.
We let W be the set of all y ∈ Rm such that (0, y) ∈ V. Note that b ∈ W. It
is clear that W is open since V is open. If y ∈ W, then (0, y) = F(x, y) for some
(x, y) ∈ U. By (9.60), f(x, y) = 0 for this x.
Suppose, with the same y, that (x
′
, y) ∈ U and f(x
′
, y) = 0. Then
F(x
′
, y) = (f(x
′
, y), y) = (f(x, y), y) = F(x, y).
Since F is 1-1 in U, it follows that x
′ = x. This proves the first part of the theorem.
For the second part, define g(y) for y ∈ W, so that (g(y), y) ∈ U and (9.57)
holds. Then
(9.61) F(g(y), y) = (0, y) (y ∈ W).
If G is the mapping of V onto U that inverts F, then G ∈ C
1 by the inverse function
theorem and (9.61) gives
(9.62) (g(y), y) = G(0, y) (y ∈ W).THE IMPLICIT FUNCTION THEOREM 213
Since G ∈ C
1, (9.62) shows that g ∈ C
1.
Finally, to compute g
′
(b), put (g(y), y) = Φ(y). Then
(9.63) Φ′
(y)k = (g
′
(y)k, k) (y ∈ W, k ∈ Rm).
By (9.57), f(Φ(y)) = 0 in W. The chain rule shows therefore that
f
′
(Φ(y))Φ′
(y) = 0.
When y = b, then Φ(y) = (a, b) and f
′
(Φ(y)) = A. Thus
(9.64) AΦ′
(b) = 0.
It now follows from (9.64), (9.63), and (9.54) that
Axg
′
(b)k + Ayk = A(g
′
(b)k, k) = AΦ′
(b)k = 0
for every k ∈ Rm. Thus
(9.65) Axg
′
(b) + Ay = 0.
This is equivalent to (9.58) and completes the proof.
Note. In terms of the components of f and g, (9.65) becomes
Xn
j=1
(Djfi
)(a, b)(Dkgj
)(b) = −(Dn+kfi
)(a, b)
or Xn
j=1

∂fi
∂xj
  ∂gj
∂yk

= − 
∂fi
∂yk

where 1 ≤ i ≤ n, 1 ≤ k ≤ m.
For each k, this is a system of n linear equations in which the derivatives
∂gj/∂yk (1 ≤ j ≤ n) are the unknowns.
9.29 Example. Take n = 2, m = 3 and consider the mapping f = (f1, f2) of R5 into
R2 given by
f1(x1, x2, y1, y2, y3) = 2ex1 + x2y1 − 4y2 + 3
f2(x1, x2, y1, y2, y3) = x2 cos x1 − 6x1 + 2y1 − y3.
If a = (0, 1) and b = (3, 2, 7), then f(a, b) = 0.
With respect to the standard bases, the matrix of the transformation A = f
′
(a, b)
is
[A] = 
2 3 1 −4 0
−6 1 2 0 −1

.THE RANK THEOREM 214
Hence
[Ax] = 
2 3
−6 1
, [Ay] = 
1 −4 0
2 0 −1

.
We see that the column vectors of [Ax] are independent. Hence Ax is invertible and
the implicit function theorem asserts the existence of a C
1-mapping g, defined in
a neighborhood of (3, 2, 7), such that g(3, 2, 7) = (0, 1) and f(g(y), y) = 0.
We can use (9.58) to compute g
′
(3, 2, 7): Since
[(Ax)
−1
] = [Ax]
−1 =
1
20 
1 −3
6 2 
,
(9.58) gives
[g
′
(3, 2, 7)] = − 1
20 
1 −3
6 2  1 −4 0
2 0 −1

=
 1
4
1
5 −
3
20
−
1
2
6
5
1
10

.
In terms of the partial derivatives, the conclusion is that
D1g1 =
1
4
D2g1 =
1
5
D3g1 = −
3
20
D1g2 = −
1
2
D2g2 =
6
5
D3g2 =
1
10
at the point (3, 2, 7).
THE RANK THEOREM
Although this theorem is not as important as the inverse function theorem or the
implicit function theorem, we include it as another interesting illustration of the
general principle that the local behavior of a continuously differentiable mapping
F near a point x is similar to that of the linear transformation F
′
(x). Before stating
it, we need a few more facts about linear transformations.
9.30 Definitions. Suppose X and Y are vector spaces and A ∈ L(X, Y), as in Defi￾nition 9.6. The null space of A, N (A), is the set of all x ∈ X at which Ax = 0. It is
clear that N (A) is a vector space in X.
Likewise, the range of A, R(A), is a vector space in Y. The rank of A is defined
to be the dimension of R(A).
For example, the invertible elements of L(Rn) are precisely those whose rank
is n. This follows from Theorem 9.5. If A ∈ L(X, Y) and A has rank 0, then Ax = 0
for all x ∈ X, hence N (A) = X. In this connection, see Exercise 9.25.
9.31 Definition (Projections). Let X be a vector space. An operator P ∈ L(X) is said
to be a projection in X if P
2 = P.THE RANK THEOREM 215
More explicitly, the requirement is that P(Px) = Px for every x ∈ X. In other
words, P fixes every vector in its range R(P). Here are some elementary properties
of projections:
(a) If P is a projection in X, then every x ∈ X has a unique representation of the
form
x = x1 + x2
where x1 ∈ R(P), x2 ∈ N (P).
Proof. To obtain the representation, put x1 = Px, x2 = x − x1. Then Px2 =
Px − Px1 = Px − P
2x = 0. As regards the uniqueness, apply P to the equation
x = x1 + x2. Since x1 ∈ R(P), Px1 = x1; since Px2 = 0, it follows that
x1 = Px.
(b) If X is a finite-dimensional vector space and if X1 is a vector space in X, then
there is a projection P in X with R(P) = X1.
Proof. If X1 contains only 0, this is trivial: put Px = 0 for all x ∈ X.
Assume dim X1 = k > 0. By Theorem 9.3, X has then a basis {u1, . . . , un}
such that {u1, . . . , uk} is a basis if X1. Define
P(c1u1 + · · · + cnun) = c1u1 + · · · + ckuk
for arbitrary scalars c1, . . . , cn. Then Px = x for every x ∈ X1 and X1 = R(P).
Note that {uk+1, . . . , un} is a basis of N (P). Note also that there are in￾finitely many projections in X with range X1 if 0 < dim X1 < dim X.
9.32 Theorem. Suppose m, n, r are nonnegative integers, m ≥ r, n ≥ r, F is a C
1-
mapping of an open set E ⊂ Rn into Rm, and F
′
(x) has rank r for every x ∈ E.
Fix a ∈ E, put A = F
′
(a), let Y1 be the range of A, and let P be a projection in Rm
whose range is Y1. Let Y2 be the null space of P.
Then there are open sets U and V in Rn, with a ∈ U, U ⊂ E, and there is a 1-1
C
1-mapping H of V onto U (whose inverse is also of class C
1) such that
(9.66) F(H(x)) = Ax + φ(Ax) (x ∈ V)
where φ is a C
1-mapping of the open set A(V) ⊂ Y1 into Y2.
After the proof we shall give a more geometric description of the information
that (9.66) contains.
Proof. If r = 0, Theorem 9.19 shows that F(x) is constant in a neighborhood U of a
and (9.66) holds trivially with V = U, H(x) = x, φ(0) = F(a).
From now on we assume r > 0. Since dim Y1 = r, Y1 has a basis {y1, . . . , yr}.
Choose zi ∈ Rn so that Azi = yi
(1 ≤ i ≤ r), and define a linear mapping S of Y1
into Rn by setting
(9.67) S(c1y1 + · · · + cryr) = c1z1 + · · · + crzrTHE RANK THEOREM 216
for all scalars c1, . . . , cr. Then ASyi = Azi = yi
for 1 ≤ i ≤ r. Thus
(9.68) ASy = y (y ∈ Y1).
Define a mapping G into Rn by setting
(9.69) G(x) = x + SP[F(x) − Ax] (x ∈ E).
Since F
′
(a) = A, differentiation of (9.69) shows that G′
(a) = I, the identity operator
on Rn. By the inverse function theorem, there are open sets U and V in Rn, with
a ∈ U, such that G is a 1-1 mapping of U onto V whose inverse H is also of class
C
1. Moreover, by shrinking U and V, if necessary, we can arrange it so that V is
convex and H′
(x) is invertible for every x ∈ V.
Note that ASPA = A since PA = A and (9.68) holds. Therefore (9.69) gives
(9.70) AG(x) = PF(x) (x ∈ E).
In particular, (9.70) holds for x ∈ U. If we replace x by H(x), we obtain
(9.71) PF(H(x)) = Ax (x ∈ V).
Define
(9.72) ψ(x) = F(H(x)) − Ax (x ∈ V).
Since PA = A, (9.71) implies that Pψ(x) = 0 for all x ∈ V. This ψ is a C
1-mapping
of V into Y2. Since V is open it is clear that A(V) is an open subset of its range
R(A) = Y1.
To complete the proof, i.e., to go from (9.72) to (9.66), we have to show that
there is a C
1-mapping φ of A(V) into Y2 which satisfies
(9.73) φ(Ax) = ψ(x) (x ∈ V).
As a step toward (9.73), we will first prove that
(9.74) ψ(x1) = ψ(x2)
if x1 ∈ V, x2 ∈ V, Ax1 = Ax2.
Put Φ(x) = F(H(x)) for x ∈ V. Since H′
(x) has rank n for every x ∈ V and F
′
(x)
has rank r for every x ∈ U, it follows that
(9.75) rank Φ′
(x) = rank F
′
(H(x))H′
(x) = r (x ∈ V).
Fix x ∈ V. Let M be the range of Φ′
(x). Then M ⊂ Rm, dimM = r. By (9.71),
(9.76) PΦ′
(x) = A.
Thus P maps M onto R(A) = Y1. Since M and Y1 have the same dimension, itTHE RANK THEOREM 217
follows that P (restricted to M) is 1-1.
Suppose now that Ah = 0. Then PΦ′
(x)h = 0 by (9.76). But Φ′
(x)h ∈ M and P
is 1-1 on M. Hence Φ′
(x)h = 0. A look at (9.72) shows now that we have proved
the following:
If x ∈ V and Ah = 0, then ψ′
(x)h = 0.
We can now prove (9.74). Suppose x1 ∈ V, x2 ∈ V, Ax1 = Ax2. Put h = x2 − x1
and define
(9.77) g(t) = ψ(x1 + th) (0 ≤ t ≤ 1).
The convexity of V shows that x1 + th ∈ V for these t. Hence
(9.78) g
′
(t) = ψ
′
(x1 + th)h = 0 (0 ≤ t ≤ 1),
so that g(1) = g(0). But g(1) = ψ(x2) and g(0) = ψ(x1). This proves (9.74).
By (9.74), ψ(x) depends only on Ax for x ∈ V. Hence (9.73) defines φ unam￾biguously in A(V). It only remains to be proved that φ ∈ C
1.
Fix y0 ∈ A(V), fix x0 ∈ V so that Ax0 = y0. Since V is open, y0 was a neigh￾borhood W in Y1 such that the vector
(9.79) x = x0 + S(y − y0)
lies in V for all y ∈ W. By (9.68),
Ax = Ax0 + y − y0 = y.
Thus (9.73) and (9.79) give
(9.80) φ(y) = ψ(x0 − Sy0 + Sy) (y ∈ W).
This formula shows that φ ∈ C
1 in W, hence in A(V), since y0 was chosen arbi￾trarily in A(V). The proof is now complete.
Here is what the theorem tells us about the geometry of the mapping F. If
y ∈ F(U) then y = F(H(x)) for some x ∈ V and (9.66) shows that Py = Ax.
Therefore
(9.81) y = Py + φ(Py) (y ∈ F(U)).
This shows that y is determined by its projection Py and that P, restricted to F(U),
is a 1-1 mapping of F(U) onto A(V). Thus F(U) is an “r-dimensional surface” with
precisely one point “over” each point of A(V). We may also regard F(U) as the
graph of φ.
If Φ(x) = F(H(x)), as in the proof, then (9.66) shows that the level sets of Φ
(these are the sets in which Φ attains a given value) are precisely the level sets of ADETERMINANTS 218
in V. These are “flat” since they are intersections with V of translates of the vector
space N (A). Note that dim N (A) = n − r (Exercise 9.25).
The level sets of F in U are the images under H of the flat level sets of Φ in V.
They are thus “(n − r)-dimensional surfaces” in U.
DETERMINANTS
Determinants are numbers associated to square matrices, and hence to the oper￾ators represented by such matrices. They are 0 if and only if the corresponding
operator fails to be invertible. They can therefore be used to decide whether the
hypotheses of some of the preceding theorems are satisfied. They will play an even
more important role in Chap. 10.
9.33 Definition. If (j1, . . . , jn) is an ordered n-tuple of integers, define
(9.82) s(j1, . . . , jn) = Y
p<q
sgn(jq − jp),
where sgn x = 1 if x > 0, sgn x = −1 if x < 0, sgn x = 0 if x = 0. Then
s(j1, . . . , jn) = 1, −1, or 0, and it changes sign if any two of the j’s are interchanged.
Let [A] be the matrix of a linear operator A on Rn, relative to the standard basis
{e1, . . . , en}, with entries a(i, j) in the ith row and jth column. The determinant of
[A] is defined to be the number
(9.83) det[A] = Xs(j1, . . . , jn)a(1, j1)a(2, j2)· · · a(n, jn).
The sum in (9.83) extends over all ordered n-tuples of integers (j1, . . . , jn) with
1 ≤ jr ≤ n. The column vectors xj of [A] are
(9.84) xj =
Xn
i=1
a(i, j)ei
(1 ≤ j ≤ n).
It will be convenient to think of det[A] as a function of the column vectors [A]. If
we write
det(x1, . . . , xn) = det[A],
det is now a real function on the set of all ordered n-tuples of vectors in Rn.
9.34 Theorem.
(a) If I is the identity operator on Rn, then
det[I] = det(e1, . . . , en) = 1.
(b) det is a linear function of each of the column vectors xj
, if the others are held fixed.
(c) If [A]1 is obtained from [A] by interchanging two columns, then
det[A]1 = − det[A].DETERMINANTS 219
(d) If [A] has two equal columns, then det[A] = 0.
Proof. If A = I, then a(i,i) = 1 and a(i, j) = 0 for all i ̸= j. Hence
det[I] = s(1, 2, . . . , n) = 1,
which proves (a). By (9.82), s(j1, . . . , jn) = 0 if any two of the j’s are equal. Each of
the remaining n! products in (9.83) contains exactly one factor from each column.
This proves (b). Part (c) is an immediate consequence of the fact that s(j1, . . . , jn)
changes sign if any two of the jr’s are interchanged, and (d) is a corollary of (c).
9.35 Theorem. If [A] and [B] are n by n matrices, then
det([B][A]) = det[B] det[A].
Proof. If x1, . . . , xn are the columns of [A], define
(9.85) ∆B(x1, . . . , xn) = ∆B[A] = det([B][A]).
The columns of [B][A] are the vectors Bx1, . . . , Bxn. Thus
(9.86) ∆B(x1, . . . , xn) = det(Bx1, . . . , Bxn).
By (9.86) and Theorem 9.34, ∆B also has properties 9.34(b) to (d). By (b) and (9.84),
∆B[A] = ∆B
 X
i
a(i, 1)ei
, x2, . . . , xn
!
=
X
i
a(i, 1)∆B(ei
, x2, . . . , xn).
Repeating this process with x2, . . . , xn, we obtain
(9.87) ∆B[A] = Xa(i1, 1)a(i2, 2)· · · a(in, n)∆B(ei1
, . . . , ein
),
the sum being extended over all ordered n-tuples (i1, . . . ,in) with 1 ≤ ir ≤ n. By
(c) and (d),
(9.88) ∆B(ei1
, . . . , ein
) = t(i1, . . . ,in)∆B(e1, . . . , en),
where t = 1, 0, or −1, and since [B][I] = [B], (9.85) shows that
(9.89) ∆B(e1, . . . , en) = det[B].
Substituting (9.89) and (9.88) into (9.87), we obtain
det([B][A]) = 
Xa(i1, 1)· · · a(in, n)t(i1, . . . ,in)

det[B],
for all n by n matrices [A] and [B]. Taking B = I, we see that the above sum in
braces is det[A]. This proves the theorem.DETERMINANTS 220
9.36 Theorem. A linear operator A on Rn is invertible if and only if det[A] ̸= 0.
Proof. If A is invertible, Theorem 9.35 shows that
det[A] det[A
−1
] = det[AA−1
] = det[I] = 1,
so that det[A] ̸= 0.
If A is not invertible, the columns x1, . . . , xn of [A] are dependent (Theorem 9.5);
hence there is one, say xk, such that
(9.90) xk +
X
j̸=k
cjxj = 0
for certain scalars cj
. By Theorem 9.34(b) and (d), xk can be replaced by xk +
cjxj without altering the determinant, if j ̸= k. Repeating, we see that xk can be
replaced by the left side of (9.90), i.e., by 0, without altering the determinant. But a
matrix which has 0 for one column has determinant 0. Hence det[A] = 0.
9.37 Remark. Suppose {e1, . . . , en} and {u1, . . . , un} are bases in Rn. Every linear
operator A on Rn determines matrices [A] and [A]U, with entries aij and αij given
by
Aej =
X
i
aijei
, Auj
X
i
αijui
.
If uj = Bej = Σbijej
, then Auj
is equal to
X
k
αkjBek =
X
k
αkjX
i
bikei =
X
i
 X
k
bikαkj!
ei
,
and also to
ABej = A
X
k
bkjek =
X
i
 X
k
aikbkj!
ei
.
Thus Σbikαkj = Σaikbkj, or
(9.91) [B][A]U = [A][B].
Since B is invertible, det[B] ̸= 0. Hence (9.91), combined with Theorem 9.35, shows
that
(9.92) det[A]U = det[A].
The determinant of the matrix of a linear operator therefore does not depend
on the basis which is used to construct the matrix. It is thus meaningful to speak of
the determinant of a linear operator, without having any basis in mind.
9.38 Definition (Jacobians). If f maps an open set E ⊂ Rn into Rn and f is differ￾entiable at a point x ∈ E, the determinant of the linear operator f
′
(x) is called theDERIVATIVES OF HIGHER ORDER 221
Jacobian of f at x. In symbols,
(9.93) Jf
(x) = detf
′
(x).
We shall also use the notation
(9.94) ∂(y1, . . . , yn)
∂(x1, . . . , xn)
for Jf
(x) if (y1, . . . , yn) = f(x1, . . . , xn).
In terms of Jacobians, the crucial hypothesis in the inverse function theorem is
that Jf
(a) ̸= 0 (compare Theorem 9.36). If the implicit function theorem is stated in
terms of the functions (9.59), the assumption made there on A amounts to
∂(f1, . . . , fn)
∂(x1, . . . , xn)
̸= 0.
DERIVATIVES OF HIGHER ORDER
9.39 Definition. Suppose f is a real function defined in an open set E ⊂ Rn, with
partial derivatives D1f, . . . , Dnf. If the functions Djf are themselves differentiable,
then the second-order partial derivatives of f are defined by
Dijf = DiDjf (i, j = 1, . . . , n).
If all these functions Dijf are continuous in E, we say that f is of class C
2 in E,
or that f ∈ C
2(E). A mapping f of E into Rm is said to be of class C
2 if each
component of f is of class C
2.
It can happen that Dijf ̸= Djif at some point, although both derivatives exist
(see Exercise 9.27). However, we shall see below that Dijf = Djif whenever these
derivatives are continuous.
For simplicity (and without loss of generality), we state our next two theorems
for real functions of two variables. The first one is a mean value theorem.
9.40 Theorem. Suppose f is defined in an open set E ⊂ R2 and D1f and D21f exist at
every point of E. Suppose Q ⊂ E is a closed rectangle with sides parallel to the coordinate
axes, having (a, b) and (a + h, b + k) as opposite vertices (h ̸= 0, k ̸= 0). Put
∆(f, Q) = f(a + h, b + k) − f(a + h, b) − f(a, b + k) + f(a, b).
Then there is a point (x, y) in the interior of Q such that
(9.95) ∆(f, Q) = hk(D21f)(x, y).
Note that analogy between (9.95) and Theorem 5.10; the area of Q is hk.DIFFERENTIATION OF INTEGRALS 222
Proof. Put u(t) = f(t, b + k) − f(t, b). Two applications of Theorem 5.10 show that
there is an x between a and a + h, and that there is a y between b and b + k, such
that
∆(f, Q) = u(a + h) − u(a)
= hu′
(x)
= h[(D1f)(x, b + k) − (D1f)(x, b)]
= hk(D21f)(x, y).
9.41 Theorem. Suppose f is defined in an open set E ⊂ R2, suppose that D1f, D21f,
and D2f exist at every point of E, and D21f is continuous at some point (a, b) ∈ E. Then
D12f exists at (a, b) and
(9.96) (D12f)(a, b) = (D21f)(a, b).
Corollary. D21f = D12f if f ∈ C
2(E).
Proof. Put A = (D21f)(a, b). Choose ε > 0. If Q is a rectangle as in Theorem 9.40
and if h and k are sufficiently small, we have
|A − (D21f)(x, y)| < ε
for all (x, y) ∈ Q. Thus




∆(f, Q)
hk
− A




< ε,
by (9.95). Fix h and let k → 0. Since D2f exists in E, the last inequality implies that
(9.97)




(D2f)(a + h, b) − (D2f)(a, b)
h
− A




≤ ε.
Since ε was arbitrary, and since (9.97) holds for all sufficiently small h ̸= 0, it
follows that (D12f)(a, b) = A. This gives (9.96).
DIFFERENTIATION OF INTEGRALS
Suppose φ is a function of two variables which can be integrated with respect to
one and which can be differentiated with respect to the other. Under what condi￾tions will the result be the same if these two limit processes are carried out in the
opposite order? To state the question more precisely: Under what conditions on φ
can one prove that the equation
(9.98) d
dt
Z b
a
φ(x, t) dx =
Z b
a
∂ϕ
∂t (x, t) dx
is true? (A counter example is furnished by Exercise 9.28.)DIFFERENTIATION OF INTEGRALS 223
It will be convenient to use the notation
(9.99) φ
t
(x) = φ(x, t).
Thus φt
is, for each t, a function of one variable.
9.42 Theorem. Suppose
(a) φ(x, t) is defined for a ≤ x ≤ b, c ≤ t ≤ d;
(b) α is an increasing function on [a, b];
(c) φt ∈ R(α) for every t ∈ [c, d];
(d) c < s < d, and to every ε > 0 corresponds a δ > 0 such that
|(D2φ)(x, t) − (D2φ)(x, s)| < ε
for all x ∈ [a, b] and for all t ∈ (s − δ, s + δ).
Define
(9.100) f(t) = Z b
a
φ(x, t) dα(x) (c ≤ t ≤ d).
Then (D2φ)
s ∈ R(α), f
′
(s) exists, and
(9.101) f
′
(s) = Z b
a
(D2φ)(x, s) dα(x).
Note that (c) simply asserts the existence of the integrals (9.100) for all t ∈ [c, d].
Note also that (d) certainly holds whenever (D2φ) is continuous on the rectangle
on which φ is defined.
Proof. Consider the difference quotients
ψ(x, t) = φ(x, t) − φ(x, s)
t − s
for 0 < |t − s| < δ. By Theorem 5.10 there corresponds to each (x, t) a number u
between s and t such that
ψ(x, t) = (D2φ)(x, u).
Hence (d) implies that
(9.102) |ψ(x, t) − (D2φ)(x, s)| < ε (a ≤ x ≤ b, 0 < |t − s| < δ).
Note that
(9.103) f(t) − f(s)
t − s
=
Z b
a
ψ(x, t) dα(x).DIFFERENTIATION OF INTEGRALS 224
By (9.102), ψt → (D2φ)
s uniformly on [a, b] as t → s. Since each ψt ∈ R(α), the
desired conclusion follows from (9.103) and Theorem 7.16.
9.43 Example. One can of course prove analogues of Theorem 9.42 with (−∞,∞)
in place of [a, b]. Instead of doing this, let us simply look at an example. Define
(9.104) f(t) = Z∞
−∞
e
−x
2
cos(xt) dx
and
(9.105) g(t) = − Z∞
−∞
xe−x
2
sin(xt) dx,
for −∞ < t < ∞. Both integrals exist (they converge absolutely) since the absolute
values of the integrands are at most exp(−x
2) and |x| exp(−x
2), respectively.
Note that g is obtained from f by differentiating the integrand with respect to
t. We claim that f is differentiable and that
(9.106) f
′
(t) = g(t) (−∞ < t < ∞).
To prove this, let us first examine the difference quotients of the cosine: if β > 0,
then
(9.107) cos(α + β) − cos α
β
+ sin α =
1
β
Z α+β
α
(sin α − sin t) dt.
Since |sin α − sin t| ≤ |t − α|, the right side of (9.107) is at most β/2 in absolute
value; the case β < 0 is handled similarly. Thus
(9.108)




cos(α + β) − cos α
β
+ sin α




≤ |β|
for all β (if the left side is interpreted to be 0 when β = 0).
Now, fix t and h ̸= 0. Apply (9.108) with α = xt, β = xh; it follows from (9.104)
and (9.105) that




f(t + h) − f(t)
h
− g(t)




≤ |h|
Z∞
−∞
x
2
e
−x
2
dx.
When h → 0, we thus obtain (9.106).
Let us go a step further: An integration by parts, applied to (9.104), shows that
(9.109) f(t) = 2
Z∞
−∞
xe−x
2 sin(xt)
t
dx.
Thus tf(t) = −2g(t) and (9.106) implies now that f satisfies the differential equa-EXERCISES 225
tion
(9.110) 2f′
(t) + tf(t) = 0.
If we solve this differential equation and use the fact that f(0) = √
π (see Theo￾rem 8.21), we find that
(9.111) f(t) = √
π exp 
−
t
2
4

.
The integral in (9.104) is thus explicitly determined.
EXERCISES
9.1. If S is a nonempty subset of a vector space X, prove (as asserted in Definition 9.1) that the
span of S is a vector space.
9.2. Prove (as asserted in Definition 9.6) that BA is linear if A and B are linear transformations.
Prove also that A−1
is linear and invertible.
9.3. Assume A ∈ L(X, Y) and Ax = 0 only when x = 0. Prove that A is then 1-1.
9.4. Prove (as asserted in Definition 9.30) that null spaces and ranges of linear transformations
are vector spaces.
9.5. Prove that to every A ∈ L(Rn, R1
) corresponds a unique y ∈ Rn such that Ax = x · y.
Prove also that ∥A∥ = |y|. Hint: Under certain conditions, equality holds in the Schwarz
inequality.
9.6. If f(0, 0) = 0 and
f(x, y) = xy
x
2 + y2
if (x, y) ̸= (0, 0),
prove that (D1f)(x, y) and (D2f)(x, y) exist at every point of R2
, although f is not continuous
at (0, 0).
9.7. Suppose that f is a real-valued function defined in an open set E ⊂ Rn and that the
partial derivatives D1f, . . . , Dnf are bounded in E. Prove that f is continuous in E. Hint:
Proceed as in the proof of Theorem 9.21.
9.8. Suppose that f is a differentiable real function in an open set E ⊂ Rn into Rm and that f
has a local maximum at a point x ∈ E. Prove that f
′
(x) = 0.
9.9. If f is a differentiable mapping of a connected open set E ⊂ Rn, and if f
′
(x) = 0 for every
x ∈ E, prove that f is a constant in E.
9.10. If f is a real function defined in a convex open set E ⊂ Rn, such that (D1f)(x) = 0 for
every x ∈ E, prove that f(x) depends only on x2, . . . , xn.
Show that the convexity of E can be replaced by a weaker condition, but that some con￾dition is required. For example, if n = 2 and E is shaped like a horseshoe, the statement may
be false.
9.11. If f and g are differentiable real functions in Rn, prove that
∇(fg) = f∇g + g∇f
and that ∇(1/f) = −f
−2∇f whenever f ̸= 0.EXERCISES 226
9.12. Fix two real numbers a and b, 0 < a < b. Define a mapping f = (f1, f2, f3) of R2
into
R3 by
f1(s, t) = (b + a cos s) cos t
f2(s, t) = (b + a cos s) sin t
f3(s, t) = a sin s.
Describe the range K of f. (It is a certain compact subset of R3
.)
(a) Show that there are exactly 4 points p ∈ K such that
(∇f1)(f
−1
(p)) = 0.
Find these points.
(b) Determine the set of all q ∈ K such that
(∇f3)(f
−1
(q)) = 0.
(c) Show that one of the points p found in part (a) corresponds to a local maximum of f1,
one corresponds to a local minimum, and that the other two are neither (they are so￾called “saddle points”). Which of the points q found in part (b) correspond to maxima
or minima?
(d) Let λ be an irrational real number and define g(t) = f(t, λt). Prove that g is a 1-1
mapping of R1 onto a dense subset of K. Prove that

g
′
(t)


2 = a
2 + λ
2
(b + a cos t)
2
.
9.13. Suppose f is a differentiable mapping of R1
into R3
such that |f(t)| = 1 for every t.
Prove that f
′
(t) · f(t) = 0. Interpret this result geometrically.
9.14. Define f(0, 0) = 0 and
f(x, y) = x
3
x
2 + y2
if (x, y) ̸= (0, 0).
(a) Prove that D1f and D2f are bounded functions in R2
. (Hence f is continuous.)
(b) Let u be any unit vector in R2
. Show that the directional derivative (Duf)(0, 0) exists
and that its absolute value is at most 1.
(c) Let γ be a differentiable mapping of R1
into R2
(in other words, γ is a differentiable
curve in R2
) with γ(0) = (0, 0) and |γ
′
(0)| > 0. Put g(t) = f(γ(t)) and prove that g is
differentiable for every t ∈ R1
. If γ ∈ C
1
, prove that g ∈ C
1
.
(d) In spite of this, prove that f is not differentiable at (0, 0). Hint: Formula (9.40) fails.
9.15. Define f(0, 0) = 0 and put
f(x, y) = x
2 + y
2 − 2x2y −
4x6y
2
(x
4 + y2)
2
if (x, y) ̸= (0, 0).
(a) Prove, for all (x, y) ∈ R2
, that
4x4y
2 ≤ (x
4 + y
2
)
2
.
Conclude that f is continuous.
(b) For 0 ≤ θ ≤ 2π, −∞ < t < ∞, define
gθ(t) = f(t cos θ, t sin θ).EXERCISES 227
Show that gθ(0) = 0, g
′
θ
(0) = 0, g
′′
θ
(0) = 2. Each gθ therefore has a strict local
minimum at t = 0. In other words, the restriction of f to each line through (0, 0)
has a strict local minimum at (0, 0).
(c) Show that (0, 0) is nevertheless not a local minimum for f, since f(x, x
2
) = −x
4
.
9.16. Show that the continuity of f
′ at the point a is needed in the inverse function theorem,
even in the case n = 1: If
f(t) = t + 2t2
sin 
1
t

for t ̸= 0 and f(0) = 0, then f
′
(0) = 1, f
′
is bounded in (−1, 1), but f is not one-to-one in any
neighborhood of 0.
9.17. Let f = (f1, f2) be the mapping of R2
into R2 given by
f1(x, y) = e
x
cos y, f2(x, y) = e
x
sin y.
(a) What is the range of f?
(b) Show that the Jacobian of f is not zero at any point of R2
. Thus every point of R2 has
a neighborhood in which f is one-to-one. Nevertheless, f is not one-to-one on R2
.
(c) Put a = (0, π/3), b = f(a), and let g be the continuous inverse of f, defined in a
neighborhood of b, such that g(b) = a. Find an explicit formula for g, compute f
′
(a)
and g
′
(b), and verify the formula (9.52).
(d) What are the images under f of lines parallel to the coordinate axes?
9.18. Answer analogous questions for the mapping defined by
u = x
2 − y
2
, v = 2xy.
9.19. Show that the system of equations



3x + y − z + u
2 = 0
x − y + 2z + u = 0
2x + 2y − 3z + 2u = 0
can be solved for x, y, u in terms of z; for x, z, u in terms of y; for y, z, u in terms of x; but not
for x, y, z in terms of u.
9.20. Take n = m = 1 in the implicit function theorem, and interpret the theorem (as well as
its proof) graphically.
9.21. Define f in R2 by
f(x, y) = 2x3 − 3x2 + 2y3 + 3y2
.
(a) Find the four points in R2 at which the gradient of f is zero. Show that f has exactly
one local maximum and one local minimum in R2
.
(b) Let S be the set of all (x, y) ∈ R2 at which f(x, y) = 0. Find the points of S that have
no neighborhoods in which the equation f(x, y) = 0 can be solved for y in terms of x
(or for x in terms of y). Describe S as precisely as you can.
9.22. Give a similar discussion for
f(x, y) = 2x3 + 6xy2 − 3x2 + 3y2
.
9.23. Define f in R3 by
f(x, y1, y2) = x
2y1 + e
x + y2.
Show that f(0, 1, −1) = 0, (D1f)(0, 1, −1) ̸= 0, and that there exists therefore a differentiable
function g in some neighborhood of (1, −1) in R2
such that g(1, −1) = 0 and
f(g(y1, y2), y1, y2) = 0.EXERCISES 228
Find (D1g)(1, −1) and (D2g)(1, −1).
9.24. For (x, y) ̸= (0, 0), define f = (f1, f2) by
f1(x, y) = x
2 − y
2
x
2 + y2
, f2(x, y) = xy
x
2 + y2
.
Compute the rank of f
′
(x, y) and find the range of f.
9.25. Suppose A ∈ L(Rn, Rm); let r be the rank of A.
(a) Define S as in the proof of Theorem 9.32. Show that SA is a projection in Rn whose
null space is N (A) and whose range is R(S). Hint: By (9.68) SASA = SA.
(b) Use (a) to show that
dim N (A) + dim R(A) = n.
9.26. Show that the existence (and even the continuity) of D12f does not imply the existence
of D1f. For example, let f(x, y) = g(x), where g is nowhere differentiable.
9.27. Put f(0, 0) = 0 and
f(x, y) = xy(x
2 − y
2
)
x
2 + y2
if (x, y) ̸= (0, 0). Prove that
(a) f, D1f, D2f are continuous in R2
;
(b) D12f and D21f exist at every point of R2 and are continuous except at (0, 0);
(c) (D12f)(0, 0) = 1 and (D21f)(0, 0) = −1.
9.28. For t ≥ 0, put
φ(x, t) =



x (0 ≤ x ≤
√
t)
−x + 2
√
t (
√
t ≤ x ≤ 2
√
t)
0 (otherwise),
and put φ(x, t) = −φ(x, |t|) if t < 0.
Show that φ is continuous on R2 and
(D2φ)(x, 0) = 0
for all x. Define
f(t) = Z 1
−1
φ(x, t) dx.
Show that f(t) = t if |t| < 1/4. Hence
f
′
(0) ̸=
Z 1
−1
(D2φ)(x, 0) dx.
9.29. Let E be an open set in Rn. The classes C
1
(E) and C
2
(E) are defined in the text. By
induction, C
k(E) can be defined as follows, for all positive integers k: To say that f ∈ C
k(E)
means that the partial derivatives D1f, . . . , Dnf belong to C
k−1
(E).
Assume f ∈ C
k(E) and show (by repeated application of Theorem 9.41) that the kth
order derivative
Di1i2...ik
f = Di1Di2
· · · Dik
f
is unchanged if the subscripts i1, . . . ,ik are permuted.
For instance, if n ≥ 3, then
D1213f = D3112f
for every f ∈ C
4
.EXERCISES 229
9.30. Let f ∈ C m(E), where E is an open subset of Rn. Fix a ∈ E and suppose x ∈ Rn is so
close to 0 that the points
p(t) = a + tx
lie in E whenever 0 ≤ t ≤ 1. Define
h(t) = f(p(t))
for all t ∈ R1
for which p(t) ∈ E.
(a) For 1 ≤ k ≤ m, show (by repeated application of the chain rule) that
h
(k)
(t) = X(Di1...ik
f)(p(t))xi1
· · · xik
.
The sum extends over all ordered k-tuples (i1, . . . ,ik) in which each ij
is one of the
integers 1, . . . , n.
(b) By Taylor’s theorem (Theorem 5.15),
h(1) =
mX−1
k=0
h
(k)
(0)
k!
+
h
(m)
(t)
m!
for some t ∈ (0, 1). Use this to prove Taylor’s theorem in n variables by showing that
the formula
f(a + x) =
mX−1
k=0
1
k!
X(Di1...ik
f)(a)xi1
· · · xik + r(x)
represents f(a + x) as the sum of its so-called “Taylor polynomial of degree m − 1,”
plus a remainder that satisfies
lim
x→0
r(x)
|x|
m−1
= 0.
Each of the inner sums extends over all ordered k-tuples (i1, . . . ,ik), as in part (a);
as usual, the zero-order derivative of f is simply f, so that the constant term of the
Taylor polynomial of f at a is f(a).
(c) Exercise 9.29 shows that repetition occurs in the Taylor polynomial as written in part
(b). For instance, D113 occurs three times, as D113, D131, D311. The sum of the
corresponding three terms can be written in the form
3(D2
1D3f)(a)x
2
1
x3.
Prove (by calculating how often each derivative occurs) that the Taylor polynomial in
(b) can be written in the form
X (D
s1
1
· · · D
sn
n f)(a)
s1! · · · sn!
x
s1
1
· · · x
sn
n .
Here the summation extends over all ordered n-tuples (s1, . . . , sn) such that each si is
a nonnegative integer and s1 + · · · + sn ≤ m − 1.
9.31. Suppose f ∈ C
3
in some neighborhood of a point a ∈ R2
, the gradient of f is 0 at a but
not all second-order derivatives of f are 0 at a. Show how one can then determine from the
Taylor polynomial of f at a (of degree 2) whether f has a local maximum, or a local minimum,
or neither, at the point a. Extend this to Rn in place of R2
.Chapter 10
INTEGRATION OF DIFFERENTIAL
FORMS
Integration can be studied on many levels. In Chap. 6, the theory was developed
for reasonably well-behaved functions on subintervals of the real line. In Chap. 11
we shall encounter a very highly developed theory of integration that can be ap￾plied to much larger classes of functions, whose domains are more or less arbitrary
sets, not necessarily subsets of Rn. The present chapter is devoted to those aspects
of integration theory that are closely related to the geometry of euclidean spaces
such as the change of variables formula, line integrals, and the machinery of differ￾ential forms that is used in the statement and proof of the n-dimensional analogue
of the fundamental theorem of calculus, namely Stokes’ theorem.
INTEGRATION
10.1 Definition. Suppose I
k is a k-cell in Rk consisting of all
x = (x1, . . . , xk)
such that
(10.1) ai ≤ xi ≤ bi
(i = 1, . . . , k),
I
j
is the j-cell in Rj defined by the first j inequalities (10.1), and f is a real continu￾ous function on I
k.
Put f = fk and define fk−1 on I
k−1 by
fk−1(x1, . . . , xk−1) = Z bk
ak
fk(x1, . . . , xk−1, xk) dxk.
The uniform continuity of fk on I
k shows that fk−1 is continuous on I
k−1. Hence
230INTEGRATION 231
we can repeat this process and obtain functions fj
, continuous on I
j
, such that
fj−1 is the integral of fj with respect to xj over [aj
, bj
]. After k steps we arrive at a
number f0, which we call the integral of f over I
k; we write it in the form
(10.2) Z
Ik
f(x) dx or Z
Ik
f.
A priori, this definition of the integral depends on the order in which the k
integrations are carried out. However, this dependence is only apparent. To prove
this, let us introduce the temporary notation L(f) for the integral (10.2) and L
′
(f)
for the result obtained by carrying out the k integrations in some other order.
10.2 Theorem. For every f ∈ C (I
k), L(f) = L
′
(f).
Proof. If h(x) = h1(x1)· · · hk(xk), where hj ∈ C ([aj
, bj
]), then
L(h) = Y
k
i=1
Z bi
ai
hi
(xi
) dxi = L
′
(h).
If A is the set of all finite sums of such functions h, it follows that L(g) = L
′
(g) for
all g ∈ A . Also, A is an algebra of functions on I
k to which the Stone-Weierstrass
theorem applies.
Put V =
Qk
i=1
(bi − ai
). If f ∈ C (I
k) and ε > 0, there exists g ∈ A such that
∥f − g∥ < ε/V, where ∥f∥ is defined as max |f(x)| (x ∈ I
k). Then |L(f − g)| < ε,

L
′
(f − g)

 < ε, and since
L(f) − L
′
(f) = L(f − g) + L
′
(g − f),
we conclude that

L(f) − L
′
(f)

 < 2ε. In this connection, Exercise 10.2 is relevant.
10.3 Definition. The support of a (real or complex) function f on Rk is the closure
of the set of all points x ∈ Rk at which f(x) ̸= 0. If f is a continuous function with
compact support, let I
k be any k-cell which contains the support of f and define
(10.3) Z
Rk
f =
Z
Ik
f.
The integral so defined is evidently independent of the choice of I
k, provided only
that I
k contains the support of f.
It is now tempting to extend the definition of the integral over Rk to functions
which are limits (in some sense) of continuous functions with compact support.
We do not want to discuss the conditions under which this can be done; the proper
setting for this question is the Lebesgue integral. We shall merely describe one
very simple example which will be used in the proof of Stokes’ theorem.INTEGRATION 232
10.4 Example. Let Qk be the k-simplex which consists of all points x = (x1, . . . , xk)
in Rk for which x1 + · · · + xk ≤ 1 and xi ≥ 0 for i = 1, . . . , k. If k = 3, for
example, Qk is a tetrahedron with vertices at 0, e1, e2, e3. If f ∈ C (Qk), extend f
to a function on I
k by setting f(x) = 0 off Qk, and define
(10.4) Z
Qk
f =
Z
Ik
f.
Here I
k is the “unit cube” defined by
0 ≤ xi ≤ 1 (1 ≤ i ≤ k).
Since f may be discontinuous on I
k, the existence of the integral on the right of
(10.4) needs proof. We also wish to show that this integral is independent of the
order in which the k single integrations are carried out.
To do this, suppose 0 < δ < 1, put
(10.5) φ(t) =



1 (t ≤ 1 − δ)
1 − t
δ
(1 − δ < t ≤ 1)
0 (1 < t),
and define
(10.6) F(x) = φ(x1 + · · · + xk)f(x) (x ∈ I
k
).
Then F ∈ C (I
k).
Put y = (x1, . . . , xk−1), x = (y, xk). For each y ∈ I
k−1, the set of all xk such that
F(y, xk) ̸= f(y, xk) is either empty or is a segment whose length does not exceed δ.
Since 0 ≤ φ ≤ 1, it follows that
(10.7) |Fk−1(y) − fk−1(y)| ≤ δ ∥f∥ (y ∈ I
k−1
),
where ∥f∥ has the same meaning as in the proof of Theorem 10.2 and Fk−1, fk−1
are as in Definition 10.1.
As δ → 0, (10.7) exhibits fk−1 as a uniform limit of a sequence of continuous
functions. Thus fk−1 ∈ C (I
k−1) and the further integrations present no problem.
This proves the existence of the integral in (10.4). Moreover, (10.7) shows that
(10.8)




Z
Ik
F(x) dx −
Z
Ik
f(x) dx




≤ δ ∥f∥ .
Note that (10.8) is true regardless of the order in which the k single integrations are
carried out. Since F ∈ C (I
k),
R
F is unaffected by any change in this order. Hence
(10.8) shows that the same is true of R
f. This completes the proof.
Our next goal is the change of variables formula stated in Theorem 10.9. ToPRIMITIVE MAPPINGS 233
facilitate its proof, we first discuss so-called primitive mappings and partitions
of unity. Primitive mappings will enable us to get a clearer picture of the local
actions of a C
1-mapping with invertible derivative, and partitions of unity are a
very useful device that makes it possible to use local information in a global setting.
PRIMITIVE MAPPINGS
10.5 Definition. If G maps an open set E ⊂ Rn into Rn, and if there is an integer
m and a real function g with domain E such that
(10.9) G(x) = X
i̸=m
xiei + g(x)em (x ∈ E),
then we call G primitive.
A primitive mapping is thus one that changes at most one coordinate. Note
that (10.9) can also be written in the form
(10.10) G(x) = x + [g(x) − xm]em.
If g is differentiable at some point a ∈ E, so is G. The matrix [αij] of the operator
G′
(a) has
(10.11) (D1g)(a), . . . ,(Dmg)(a), . . . ,(Dng)(a)
as its mth row. For j ̸= m, we have αjj = 1 and αij = 0 if i ̸= j. The Jacobian of G
at a is thus given by
(10.12) JG(a) = det[G′
(a)] = (Dmg)(a),
and we see (by Theorem 9.36) that G′
(a) is invertible if and only if (Dmg)(a) ̸= 0.
10.6 Definition. A linear operator B on Rn that interchanges some pair of mem￾bers of the standard basis and leaves the others fixed is called a flip.
For example, the flip B on R4 that interchanges e2 and e4 has the form
(10.13) B(x1e1 + x2e2 + x3e3 + x4e4) = x1e1 + x2e4 + x3e3 + x4e2
or, equivalently,
(10.14) B(x1e1 + x2e2 + x3e3 + x4e4) = x1e1 + x4e2 + x3e3 + x2e4.
Hence B can also be thought of as interchanging two of the coordinates, rather than
two basis vectors.
In the proof that follows, we shall use the projections P0, . . . , Pn in Rn, defined
by P0x = 0 and
(10.15) Pmx = x1e1 + · · · + xmemPRIMITIVE MAPPINGS 234
for 1 ≤ m ≤ n. Thus Pm is the projection whose range and null space are spanned
by {e1, . . . , em} and {em+1, . . . , en}, respectively.
10.7 Theorem. Suppose F is a C
1-mapping of an open set E ⊂ Rn into Rn, 0 ∈ E,
F(0) = 0, and F
′
(0) is invertible. Then there is a neighborhood of 0 in Rn in which a
representation
(10.16) F(x) = B1 · · · Bn−1Gn ◦ · · · ◦ G1(x)
is valid.
In (10.16), each Gi
is a primitive C
1-mapping in some neighborhood of 0; Gi
(0) = 0,
G′
i
(0) is invertible, and each Bi
is either a flip or the identity operator.
Briefly, (10.16) represents F locally as a composition of primitive mappings and
flips.
Proof. Put F = F1. Assume 1 ≤ m ≤ n − 1, and make the following induction
hypothesis (which evidently holds for m = 1):
Vm is a neighborhood of 0, Fm ∈ C
1(Vm), Fm(0) = 0, F
′m(0) is invertible, and
(10.17) Pm−1Fm(x) = Pm−1x (x ∈ Vm).
By (10.17), we have
(10.18) Fm(x) = Pm−1x +
Xn
i=m
αi
(x)ei
,
where αm, . . . , αn are real C
1-functions in Vm. Hence
(10.19) F
′
m(0)em =
Xn
i=m
(Dmαi
)(0)ei
.
Since F
′
(0) is invertible, the left side of (10.19) is not 0, and therefore there is a k
such that m ≤ k ≤ n and (Dmαk)(0) ̸= 0.
Let Bm be the flip that interchanges this m and this k (if k = m, Bm is the
identity) and define
(10.20) Gm(x) = x + [αk(x) − xm]em (x ∈ Vm).
Then Gm ∈ C
1(Vm), Gm is primitive, and G′m(0)is invertible, since (Dmαk)(0) ̸=
0.
The inverse function theorem shows therefore that there is an open set Um with
0 ∈ Um ⊂ Vm such that Gm is a 1-1 mapping of Um onto a neighborhood Vm+1
of 0, in which G−1 m is continuously differentiable. Define Fm+1 by
(10.21) Fm+1(y) = BmFm ◦ G−1
m (y) (y ∈ Vm+1).PARTITIONS OF UNITY 235
Then Fm+1 ∈ C
1(Vm+1), Fm+1(0) = 0, and F
′
m+1
(0) is invertible (by the chain
rule). Also, for x ∈ Um,
(10.22)
PmFm+1(Gm(x)) = PmBmFm(x)
= Pm[Pm+1x + αk(x)em + · · · ]
= Pm−1x + αk(x)em
= PmGm(x)
so that
(10.23) PmFm+1(y) = Pmy (y ∈ Vm+1).
Our induction hypothesis holds therefore with m + 1 in place of m. [In (10.22), we
first used (10.21), then (10.18) and the definition of Bm, then the definition of Pm,
and finally (10.20).]
Since BmBm = I, (10.21), with y = Gm(x), is equivalent to
(10.24) Fm(x) = BmFm+1(Gm(x)) (x ∈ Um).
If we apply this with m = 1, . . . , n − 1, we successively obtain
F = F1 = B1F2 ◦ G1
= B1B2F3 ◦ G2 ◦ G1 = · · ·
= B1 · · · Bn−1Fn ◦ Gn−1 ◦ · · · ◦ G1
in some neighborhood of 0. By (10.17), Fn is primitive. This completes the proof.
PARTITIONS OF UNITY
10.8 Theorem. Suppose K is a compact subset of Rn and {Vα} is an open cover of K.
Then there exist functions ψ1, . . . , ψs ∈ C (Rn) such that
(a) 0 ≤ ψi ≤ 1 for 1 ≤ i ≤ s;
(b) each ψi has its support in some Vα, and
(c) ψ1(x) + · · · + ψs(x) = 1 for every x ∈ K.
Because of (c), {ψi
} is called a partition of unity, and (b) is sometimes expressed
by saying that {ψi
} is subordinate to the cover {Vα}.
Corollary. If f ∈ C (Rn) and the support of f lies in K, then
(10.25) f =
Xs
i=1
ψif.
Each ψif has its support in some Vα.CHANGE OF VARIABLES 236
The point of (10.25) is that it furnishes a representation of f as a sum of contin￾uous functions ψif with “small” supports.
Proof. Associate with each x ∈ K an index α(x) so that x ∈ Vα(x)
. Then there are
open balls B(x) and W(x), centered at x, with
(10.26) B(x) ⊂ W(x) ⊂ W(x) ⊂ Vα(x)
.
Since K is compact, there are points x1, . . . , xs in K such that
(10.27) K ⊂ B(x1) ∪ · · · ∪ B(xs).
By (10.26), there are functions φ1, . . . , φs ∈ C (Rn) such that φi
(x) = 1 on B(xi
),
φi
(x) = 0 outside W(xi
), and 0 ≤ φi
(x) ≤ 1 on Rn. Define ψ1 = φ1 and
(10.28) ψi+1 = (1 − φ1)· · ·(1 − φi
)φi+1
for i = 1, . . . , s − 1.
Properties (a) and (b) are clear. The relation
(10.29) ψ1 + · · · + ψi = 1 − (1 − φ1)· · ·(1 − φi
)
is trivial for i = 1. If (10.29) holds for some i < s, addition of (10.28) and (10.29)
yields (10.29) with i + 1 in place of i. It follows that
(10.30) Xs
i=1
ψi
(x) = 1 −
Ys
i=1
[1 − φi
(x)] (x ∈ Rn).
If x ∈ K, then x ∈ B(xi
) for some i, hence φi
(x) = 1, and the product in (10.30) is
0. This proves (c).
CHANGE OF VARIABLES
We can now describe the effect of a change of variables on a multiple integral.
For simplicity, we confine ourselves here to continuous functions with compact
support, although this is too restrictive for many applications. This is illustrated
by Exercises 10.9 to 10.13.
10.9 Theorem. Suppose T is a 1-1 C
1-mapping of an open set E ⊂ Rk into Rk such
that JT (x) ̸= 0 for all x ∈ E. If f is a continuous function on Rk whose support is compact
and lies in T(E), then
(10.31) Z
Rk
f(y) dy =
Z
Rk
f(T(x))|JT (x)| dx.CHANGE OF VARIABLES 237
We recall that JT is the Jacobian of T. The assumption JT (x) ̸= 0 implies, by the
inverse function theorem, that T
−1 is continuous on T(E), and this ensures that the
integrand on the right side of (10.31) has compact support in E (Theorem 4.14).
The appearance of the absolute value of JT (x) in (10.31) may call for a comment.
Take the case k = 1 and suppose that T is a 1-1 C
1-mapping of R1 onto R1. Then
JT (x) = T
′
(x); if T is increasing, we have
(10.32) Z
R1
f(y) dy =
Z
R1
f(T(x))T
′
(x) dx,
by Theorems 6.19 and 6.17, for all continuous f with compact support. But if T
decreases, then T
′
(x) < 0; if f is positive in the interior of its support, the left side
of (10.32) is positive and the right side is negative. A correct equation is obtained
if T
′
is replaced by

T
′


in (10.32).
The point is that the integrals we are now considering are integrals of functions
over subsets of Rk and we associate no direction or orientation with these subsets.
We shall adopt a different point of view when we come to integration of differential
forms over surfaces.
Proof. It follows from the remarks just made that (10.31) is true if T is a primitive
C
1-mapping (see Definition 10.5), and Theorem 10.2 shows that (10.31) is true if T
is a linear mapping which merely interchanges two coordinates.
If the theorem is true for transformations P, Q, and if S(x) = P(Q(x)), then
Z
f(z) dz =
Z
f(P(y))|JP(y)| dy
=
Z
f(P(Q(x)))|JP(Q(x))|

JQ(x)

 dx
=
Z
f(S(x))|JS(x)| dx,
since
JP(Q(x))JQ(x) = det P
′
(Q(x)) det Q′
(x)
= det[P
′
(Q(x))Q′
(x)] = det S
′
(x) = JS(x),
by the multiplication theorem for determinants and the chain rule. Thus the theo￾rem is also true for S.
Each point a ∈ E has a neighborhood U ⊂ E in which
(10.33) T(x) = T(a) + B1 · · · Bk−1Gk ◦ Gk−1 ◦ · · · ◦ G1(x − a),
where Gi and Bi are as in Theorem 10.7. Setting V = T(U), it follows that (10.31)
holds if the support of f lies in V. Thus:
Each point y ∈ T(E) lies in an open set Vy ⊂ T(E) such that (10.31) holds for all
continuous functions whose support lies in Vy.DIFFERENTIAL FORMS 238
Now let f be a continuous function with compact support K ⊂ T(E). Since {Vy}
covers K, the Corollary to Theorem 10.8 shows that f = Σψif, where each ψi
is
continuous and each ψi has its support in some Vy. Thus (10.31) holds for each
ψif, and hence also for their sum f.
DIFFERENTIAL FORMS
We shall now develop some of the machinery that is needed for the n-dimensional
version of the fundamental theorem of calculus which is usually called Stokes’ theo￾rem. The original form of Stokes’ theorem arose in applications of vector analysis to
electromagnetism and was stated in terms of the curl of a vector field. Green’s the￾orem and the divergence theorem are other special cases. These topics are briefly
discussed at the end of the chapter.
It is a curious feature of Stokes’ theorem that the only thing that is difficult
about it is the elaborate structure of the definitions that are needed for its state￾ment. These definitions concern differential forms, their derivatives, boundaries,
and orientation. Once these concepts are understood, the statement of the theorem
is very brief and succinct, and its proof presents little difficulty.
Up to now we have considered derivatives of functions of several variables
only for functions defined in open sets. This was done to avoid difficulties that can
occur at boundary points. It will now be convenient, however, to discuss differen￾tiable functions on compact sets. We therefore adopt the following convention:
To say that f is a C
1-mapping (or a C
2-mapping) of a compact set D ⊂ Rk into
Rn means that there is a C
1-mapping (or a C
2-mapping) g of an open set W ⊂ Rk
into Rn such that D ⊂ W and such that g(x) = f(x) for all x ∈ D.
10.10 Definition. Suppose E is an open set in Rn. A k-surface in E is a C
1-mapping
Φ from a compact set D ⊂ Rk into E. D is called the parameter domain of Φ. Points
of D will be denoted by u = (u1, . . . , uk).
We shall confine ourselves to the simple situation in which D is either a k-cell
or the k-simplex Qk described in Example 10.4. The reason for this is that we shall
have to integrate over D, and we have not yet discussed integration over more
complicated subsets of Rk. It will be seen that this restriction on D (which will be
made tacitly from now on) entails no significant loss of generality in the resulting
theory of differential forms.
We stress that k-surfaces in E are defined to be mappings into E, not subsets of E.
This agrees with our earlier definition of curves (Definition 6.26). In fact, 1-surfaces
are precisely the same as continuously differentiable curves.
10.11 Definition. Suppose E is an open set in Rn. A differentiable form of order k ≥ 1
in E (briefly, a k-form in E) is a function ω, symbolically represented by the sum
(10.34) ω =
Xai1,...,ik
(x) dxi1 ∧ · · · ∧ dxikDIFFERENTIAL FORMS 239
(the indices i1, . . . ,ik range independently from 1 to n), which assigns to each k￾surface Φ in E a number ω(Φ) = R
Φ ω, according to the rule
(10.35) Z
Φ
ω =
Z
D
Xai1,...,ik
(Φ(u))∂(xi1
, . . . , xik
)
∂(u1, . . . , uk)
du,
where D is the parameter domain of Φ.
The functions αi1,...,ik
are assumed to be real and continuous in E. If ϕ1, . . . , ϕn
are the components of Φ, the Jacobian in (10.35) is the one determined by the map￾ping
(u1, . . . , uk) 7→ (ϕi1
(u), . . . , ϕik
(u)).
Note that the right side of (10.35) is an integral over D, as defined in Definition 10.1
(or Example 10.4) and that (10.35) is the definition of the symbol R
Φ ω.
A k-form ω is said to be of class C
1 or C
2 if the functions ai1,...,ik
in (10.34)
are all of class C
1 or C
2. A 0-form in E is defined to be a continuous function in E.
10.12 Examples.
(a) Let γ be a 1-surface (a curve of class C
1) in R3, with parameter domain [0, 1].
Write (x, y, z) in place of (x1, x2, x3) and put
ω = x dy + y dx.
Then
Z
γ
ω =
Z1
0
[γ1(t)γ
′
2
(t) + γ2(t)γ
′
1
(t)] dt = γ1(1)γ2(1) − γ1(0)γ2(0).
Note that in this example R
γ ω depends only on the initial point γ(0) and on
the end point γ(1) of γ. In particular, R
γ ω = 0 for every closed curve γ. (As
we shall see later, this is true for every 1-form ω which is exact.) Integrals of
1-forms are often called line integrals.
(b) Fix a > 0, b > 0, and define
γ(t) = (a cos t, b sin t) (0 ≤ t ≤ 2π),
so that γ is a closed curve in R2. (Its range is an ellipse.) Then
Z
γ
x dy =
Z2π
0
ab cos2
t dt = πab,
whereas
Z
γ
y dx = − Z2π
0
ab sin2
t dt = −πab.
Note that R
γ
x dy is the area of the region bounded by γ. This is a special
case of Green’s theorem.DIFFERENTIAL FORMS 240
(c) Let D be the 3-cell defined by
0 ≤ r ≤ 1, 0 ≤ θ ≤ π, 0 ≤ φ ≤ 2π.
Define Φ(r, θ, ϕ) = (x, y, z), where
x = r sin θ cos φ,
y = r sin θ sin φ
z = r cos θ.
Then
JΦ(r, θ, φ) = ∂(x, y, z)
∂(r, θ, φ)
= r
2
sin θ.
Hence
(10.36) Z
Φ
dx ∧ dy ∧ dz =
Z
D
JΦ =
4π
3
.
Note that Φ maps D onto the closed unit ball of R3, that the mapping is 1-1
in the interior of D (but certain boundary points are identified by Φ), and
that the integral (10.36) is equal to the volume of Φ(D).
10.13 Elementary Properties. Let ω, ω1, ω2 be k-forms in E. We write ω1 = ω2
if and only if ω1(Φ) = ω2(Φ) for every k-surface Φ in E. In particular, ω = 0
means that ω(Φ) = 0 for every k-surface Φ in E. If c is a real number, then cω is
the k-form defined by
(10.37) Z
Φ
cω = c
Z
Φ
ω,
and ω = ω1 + ω2 means that
(10.38) Z
Φ
ω =
Z
Φ
ω1 +
Z
Φ
ω2
for every k-surface Φ in E. As a special case of (10.37), note that −ω is defined so
that
(10.39) Z
Φ
(−ω) = − Z
Φ
ω.
Consider a k-form
(10.40) ω = a(x) dxi1 ∧ · · · ∧ dxik
and let ω be the k-form obtained by interchanging some pair of subscripts in
(10.40). If (10.35) and (10.39) are combined with the fact that a determinant changesDIFFERENTIAL FORMS 241
sign if two of its rows are interchanged, we see that
(10.41) ω = −ω.
As a special case of this, note that the anticommutative relation
(10.42) dxi ∧ dxj = − dxj ∧ dxi
holds for all i and j. In particular,
(10.43) dxi ∧ dxi = 0 (i = 1, . . . , n).
More generally, let us return to (10.40) and assume that ir = is for some r ̸= s.
If these two subscripts are interchanged, then ω = ω, hence ω = 0 by (10.41). In
other words, if ω is given by (10.40), then ω = 0 unless the subscripts i1, . . . ,ik are all
distinct.
If ω is as in (10.34), the summands with repeated subscripts can therefore be
omitted without changing ω. It follows that 0 is the only k-form in any open subset
of Rn if k > n.
The anticommutativity expressed by (10.42) is the reason for the inordinate
amount of attention that has to be paid to minus signs when studying differential
forms.
10.14 Basic k-forms. If i1, . . . ,ik are integers such that 1 ≤ i1 < i2 < · · · < ik ≤ n
and if I is the ordered k-tuple (i1, . . . ,ik), then we call I an increasing k-index and
we use the brief notation
(10.44) dxI = dxi1 ∧ · · · ∧ dxik
.
These forms dxI are the so-called basic k-forms in Rn.
It is not hard to verify that there are precisely n!/k!(n − k)! basic k-forms in
Rn; we shall make no use of this, however.
Much more important is the fact that every k-form can be represented in terms
of basic k-forms. To see this, note that every k-tuple (j1, . . . , jk) of distinct integers
can be converted to an increasing k-index J by a finite number of interchanges of
pairs; each of these amounts to a multiplication by −1 as we saw in Sec. 10.13.
Hence
(10.45) dxj1 ∧ · · · ∧ dxjk = ε(j1, . . . , jk) dxJ
where ε(j1, . . . , jk) is 1 or −1 depending on the number of interchanges that are
needed. In fact, it is easy to see that
(10.46) ε(j1, . . . , jk) = s(j1, . . . , jk)
where s is as in Definition 9.33.DIFFERENTIAL FORMS 242
For example,
dx1 ∧ dx5 ∧ dx3 ∧ dx2 = − dx1 ∧ dx2 ∧ dx3 ∧ dx5
and
dx4 ∧ dx2 ∧ dx3 = dx2 ∧ dx3 ∧ dx4.
If every k-tuple in (10.34) is converted to an increasing k-index, then we obtain the
so-called standard presentation of ω:
(10.47) ω =
X
I
bI(x) dxI.
The summation in (10.47) ranges over all increasing indices I. [Of course, every
increasing k-index arises from many (from k!, to be precise) k-tuples. Each bI in
(10.47) may thus be a sum of several of the coefficients that occur in (10.34).]
For example
x1 dx2 ∧ dx1 − x2 dx3 ∧ dx2 + x3 dx2 ∧ dx3 + dx1 ∧ dx2
is a 2-form in R3 whose standard presentation is
(1 − x1) dx1 ∧ dx2 + (x2 + x3) dx2 ∧ dx3.
The following uniqueness theorem is one of the main reasons for the introduc￾tion of the standard presentation of a k-form.
10.15 Theorem. Suppose
(10.48) ω =
X
I
bI(x) dxI
is the standard presentation of a k-form ω in an open subset E ⊂ Rn. If ω = 0 in E, then
bI(x) = 0 for every increasing k-index I and for every x ∈ E.
Note that the analogous statement would be false for sums such as (10.34) since,
for example,
dx1 ∧ dx2 + dx2 ∧ dx1 = 0.
Proof. Assume, to reach a contradiction, that bJ(v) > 0 for some v ∈ E and for
some increasing k-index J = (j1, . . . , jk). Since bJ is continuous, there exists h > 0
such that bJ(x) > 0 for all x ∈ Rn whose coordinates satisfy |xi − vi
| ≤ h. Let D
be the k-cell in Rk such that u ∈ D if and only if |ur | ≤ h for r = 1, . . . , k. Define
(10.49) Φ(u) = v +
X
k
r=1
urejr
(u ∈ D).
Then Φ is a k-surface in E, with parameter domain D, and bJ(Φ(u)) > 0 for every
u ∈ D.DIFFERENTIAL FORMS 243
We claim that
(10.50) Z
Φ
ω =
Z
D
bJ(Φ(u)) du.
Since the right side of (10.50) is positive, it follows that ω(Φ) ̸= 0. Hence (10.50)
gives our contradiction.
To prove (10.50), apply (10.35) to the presentation (10.48). More specifically,
compute the Jacobians that occur in (10.35). By (10.49),
∂(xj1
, . . . , xjk
)
∂(u1, . . . , uk)
= 1.
For any other increasing k-index I ̸= J, the Jacobian is 0 since it is the determinant
of a matrix with at least one row of zeroes.
10.16 Products of Basic k-forms. Suppose
(10.51) I = (i1, . . . ,ip), J = (j1, . . . , jq)
where 1 ≤ i1 < · · · < ip ≤ n and 1 ≤ j1 < · · · < jq ≤ n. Then product of the
corresponding basic forms dxI and dxJ in Rn is a (p + q)-form in Rn, denoted by
the symbol dxI ∧ dxJ and defined by
(10.52) dxI ∧ dxJ = dxi1 ∧ · · · ∧ dxip ∧ dxj1 ∧ · · · ∧ dxjq
.
If I and J have an element in common, then the discussion in Sec. 10.13 shows
that dxI ∧ dxJ = 0. If I and J have no element in common, let us write [I, J] for the
increasing (p + q)-index which is obtained by arranging the members of I ∪ J in
increasing order. Then dx[I,J]
is a basic (p + q)-form. We claim that
(10.53) dxI ∧ dxJ = (−1)
α dx[I,J]
where α is the number of differences jt − is that are negative. (The number of
positive differences is thus pq − α.)
To prove (10.53), perform the following operations on the numbers
(10.54) i1, . . . ,ip, j1, . . . , jq.
Move ip to the right, step by step, until its right neighbor is larger than ip. The
number of steps is the number of subscripts t such that ip < jt. (Note that 0 steps
are distinct possibility.) Then do the same for ip−1, . . . ,i1. The total number of
steps taken is α. The final arrangement reached is [I, J]. Each step, when applied
to the right side of (10.52), multiplies dxI ∧ dxJ by −1. Hence (10.53) holds. Note
that the right side of (10.53) is the standard presentation of dxI ∧ dxJ.
Next, let K = (k1, . . . , kr) be an increasing r-index in {1, . . . , n}. We shall useDIFFERENTIAL FORMS 244
(10.53) to prove that
(10.55) (dxI ∧ dxJ) ∧ dxK = dxI ∧ (dxJ ∧ dxK).
If any of the two sets I, J,K have an element in common, then each side of
(10.55) is 0, hence they are equal. So, let us assume that I, J,K are pairwise disjoint.
Let [I, J,K] denote the increasing (p + q + r)-index obtained from their union. As￾sociate β with the ordered pair (J,K) and γ with the ordered pair (I,K) in the way
that α was associated with (I, J) in (10.53). The left side of (10.55) is then
(−1)
α dx[I,J] ∧ dxK = (−1)
α(−1)
β+γ dx[I,J,K]
by two applications of (10.53), and the right side of (10.55) is
(−1)
β dxI ∧ dx[J,K] = (−1)
β(−1)
α+γ dx[I,J,K]
.
Hence (10.55) is correct.
10.17 Multiplication. Suppose ω and λ are p- and q-forms, respectively, in some
open set E ⊂ Rn, with standard presentations
(10.56) ω =
X
I
bI(x) dxI, λ =
X
J
cj
(x) dxJ
where I and J range over all increasing p-indices and over all increasing q-indices
taken from the set {1, . . . , n}. Their product, denoted by the symbol ω ∧ λ, is de￾fined to be
(10.57) ω ∧ λ =
X
I,J
bI(x)cJ(x) dxI ∧ dxJ.
In this sum, I and J range independently over their possible values, and dxI ∧ dxJ
is as in Sec. 10.16. Thus ω ∧ λ is a (p + q)-form in E.
It is quite easy to see (we leave the details as an exercise) that the distributive
laws
(ω1 + ω2) + λ = (ω1 ∧ λ) + (ω2 ∧ λ)
and
ω ∧ (λ1 ∧ λ2) = (ω ∧ λ1) + (ω ∧ λ2)
hold, with respect to the addition defined in Sec. 10.13. If these distributive laws
are combined with (10.55), we obtain the associative law
(10.58) (ω ∧ λ) ∧ σ = ω ∧ (λ ∧ σ)
for arbitrary forms ω, λ, σ in E.
In this discussion it was tacitly assumed that p ≥ 1 and q ≥ 1. The product ofDIFFERENTIAL FORMS 245
a 0-form f with the p-form ω given by (10.56) is simply defined to be the p-form
fω = ωf =
X
I
f(x)bI(x) dxI.
It is customary to write fω, rather than f ∧ ω, when f is a 0-form.
We shall now define a differentiation operator d which associates a (k+1)-form
dω to each k-form ω of class C
1 in some open set E ⊂ Rn.
10.18 Definition (Differentiation). A 0-form of class C
1 in E is just a real function
f ∈ C
1(E) and we define
(10.59) df =
Xn
i=1
(Dif)(x) dxi
.
If ω = ΣbI(x) dxI is the standard presentation of a k-form ω and bI ∈ C
1(E) for
each increasing k-index I, then we define
(10.60) dω =
X
I
(dbI) ∧ dxI.
10.19 Example. Suppose E is open in Rn, f ∈ C
1(E), and γ is a continuously
differentiable curve in E with domain [0, 1]. By (10.59) and (10.35),
(10.61) Z
γ
df =
Z1
0
Xn
i=1
(Dif)(γ(t))γ
′
i
(t) dt.
By the chain rule, the last integrand is (f ◦ γ)
′
(t). Hence
(10.62) Z
γ
df = f(γ(1)) − f(γ(0)),
and we see that R
γ
df is the same for all γ with the same initial point and the same
end point, as in (a) of Example 10.12.
Comparison with Example 10.12(b) shows therefore that the 1-form x dy is not
the derivative of any 0-form f. This could also be deduced from part (b) of the
following theorem, since
d(x dy) = dx ∧ dy ̸= 0.
10.20 Theorem.
(a) If ω and λ are k- and m-forms, respectively, of class C
1 in E, then
(10.63) d(ω ∧ λ) = (dω) ∧ λ + (−1)
kω ∧ dλ.
(b) If ω is of class C
2 in E, then d
2ω = 0.DIFFERENTIAL FORMS 246
Here d2ω means, of course, d(dω).
Proof. Because of (10.57) and (10.60), (a) follows if (10.63) is proved for the special
case
(10.64) ω = f dxI, λ = g dxJ
where f, g ∈ C
1(E), dxI is a basic k-form, and dxJ is a basic m-form. [If k or m are
both 0, simply omit dxI or dxJ in (10.64); the proof that follows is unaffected by
this.] Then
ω ∧ λ = fg dxI ∧ dxJ.
Let us assume that I and J have no element in common. [In the other case, each of
the three terms in (10.63) is 0.] Then, using (10.53),
d(ω ∧ λ) = d(fg dxI ∧ dxJ) = (−1)
α d(fg dx[I,J]
).
By (10.59), d(fg) = f dg + g df. Hence (10.60) gives
d(ω ∧ λ) = (−1)
α(f dg + g df) ∧ dx[I,J]
= (g df + f dg) ∧ dxI ∧ dxJ.
Since dg is a 1-form and dxI is a k-form, we have
dg ∧ dxI = (−1)
k dxI ∧ dg,
by (10.42). Hence
d(ω ∧ λ) = (df ∧ dxI) ∧ (g dxJ) + (−1)
k
(f dxI) ∧ (dg ∧ dxJ)
= (dω) ∧ λ + (−1)
kω ∧ dλ,
which proves (a). Note that the associative law (10.58) was used freely.
Let us prove (b) first for a 0-form f ∈ C
2:
d
2
f = d

Xn
j=1
(Djf)(x) dxj


=
Xn
j=1
d(Djf) ∧ dxj
=
Xn
i,j=1
(Dijf)(x) dxi ∧ dxj
.
Since Dijf = Djif (Theorem 9.41) and dxi ∧ dxj = − dxj ∧ dxi
, we see that d2f =
0.
If ω = f dxI as in (10.64), then dω = (df) ∧ dxI. By (10.60), d(dxI) = 0. HenceDIFFERENTIAL FORMS 247
(10.63) shows that
d
2ω = (d
2
f) ∧ dxI = 0.
10.21 Change of Variables. Suppose E is an open set in Rn, T is a C
1-mapping of
E into an open set V ⊂ Rm, and ω is a k-form in V whose standard presentation is
(10.65) ω =
X
I
bI(y) dyI.
(We use y for points of V, x for points of E.)
Let t1, . . . , tm be the components of T: If
y = (y1, . . . , ym) = T(x)
then yi = ti
(x). As in (10.59),
(10.66) dti =
Xn
j=1
(Djti
)(x) dxj
(1 ≤ i ≤ m).
Thus each dti
is a 1-form in E.
The mapping T transforms ω into a k-form ωT in E, whose definition is
(10.67) ωT =
X
I
bI(T(x)) dti1 ∧ · · · ∧ dtik
.
In each summand of (10.67), I = (i1, . . . ,ik) is an increasing k-index.
Our next theorem shows that addition, multiplication, and differentiation of
forms are defined in such a way that they commute with changes of variables.
10.22 Theorem. With E and T as in Sec. 10.21, let ω and λ be k- and m-forms in V,
respectively. Then
(a) (ω + λ)T = ωT + λT if k = m;
(b) (ω ∧ λ)T = ωT ∧ λT ;
(c) d(ωT ) = (dω)T if ω is of class C
1 and T is of class C
2.
Proof. Part (a) follows immediately from the definitions. Part (b) is almost as obvi￾ous, once we realize that
(10.68) (dyi1 ∧ · · · ∧ dyir
)T = dti1 ∧ · · · ∧ dtir
regardless of whether (i1, . . . ,ir) is increasing or not; (10.68) holds because the
same number of minus signs are needed on each side of (10.68) to produce increas￾ing rearrangements.
We turn to the proof of (c). If f is a 0-form of class C
1 in V, then
fT (x) = f(T(x)), df =
X
i
(Dif)(y) dyi
.DIFFERENTIAL FORMS 248
By the chain rule, it follows that
(10.69)
d(fT ) = X
j
(DjfT )(x) dxj
=
X
j
X
i
(Dif)(T(x))(Djti
)(x) dxj
=
X
i
(Dif)(T(x)) dti
= (df)T .
If dyI = dyi1 ∧ · · · ∧ dyik
, then (dyI)T = dti1 ∧ · · · ∧ dtik
and Theorem 10.20
shows that
(10.70) d((dyI)T ) = 0.
(This is where the assumption T ∈ C
2 is used.)
Assume now that ω = f dyI. Then
ωT = fT (x)(dyI)T
and the preceding calculations lead to
d(ωT ) = d(fT ) ∧ (dyI)T = (df)T ∧ (dyI)T
= ((df) ∧ dyI)T = (dω)T .
The first equality holds by (10.63) and (10.70), the second by (10.69), the third by
part (b), and the last by the definition of dω. The general case of (c) follows from
the special case just proved, if we apply (a). This completes the proof.
Our next objective is Theorem 10.25. This will follow directly from two other
important transformation properties of differential forms, which we state first.
10.23 Theorem. Suppose T is a C
1-mapping of an open set E ⊂ Rn into an open set
V ⊂ Rm, S is a C
1-mapping of V into an open set W ⊂ Rp, and ω is a k-form in W, so
that ωS is a k-form in V and both (ωS)T and ωST are k-forms in E, where ST is defined
by (ST)(x) = S(T(x)). Then
(10.71) (ωS)T = ωST .
Proof. If ω and λ are forms in W, Theorem 10.22 shows that
((ω ∧ λ)S)T = (ωS ∧ λS)T = (ωS)T ∧ (λS)T
and
(ω ∧ λ)ST = ωST ∧ λST .
Thus if (10.71) holds for ω and for λ, it follows that (10.71) also holds for ω ∧DIFFERENTIAL FORMS 249
λ. Since every form can be built up from 0-forms and 1-forms by addition and
multiplication, and since (10.71) is trivial for 0-forms, it is enough to prove (10.71)
in the case ω = dzq, q = 1, . . . , p. (We denote the points of E, V, W by x, y, z,
respectively.)
Let t1, . . . , tm be the components of T, let s1, . . . , sp be the components of S,
and let r1, . . . , rp be the components of ST. If ω = dzq, then
ωS = dsq =
X
j
(Djsq)(y) dyj
,
so that the chain rule implies
(ωS)T =
X
j
(Djsq)(T(x)) dtj
=
X
j
(Djsq)(T(x))X
i
(Ditj
)(x) dxi
=
X
i
(Dirq)(x) dxi = drq = ωST .
10.24 Theorem. Suppose ω is a k-form in an open set E ⊂ Rn, Φ is a k-surface in E
with parameter domain D ⊂ Rk, and ∆ is the k-surface in Rk with parameter domain D
defined by ∆(u) = u (u ∈ D). Then
Z
Φ
ω =
Z
∆
ωΦ.
Proof. We need only consider the case
ω = a(x) dxi1 ∧ · · · ∧ dxik
.
If ϕ1, . . . , ϕn are the components of Φ, then
ωΦ = a(Φ(u)) dϕi1 ∧ · · · ∧ dϕik
.
The theorem will follow if we can show that
(10.72) dϕi1 ∧ · · · ∧ dϕik = J(u) du1 ∧ · · · ∧ duk,
where
J(u) = ∂(xi1
, . . . , xik
)
∂(u1, . . . , uk)
,DIFFERENTIAL FORMS 250
since (10.72) implies
Z
Φ
ω =
Z
D
a(Φ(u))J(u) du
=
Z
∆
a(Φ(u))J(u) du1 ∧ · · · ∧ duk =
Z
∆
ωΦ.
Let [A] be the k × k matrix with entries
α(p, q) = (Dqϕip
)(u) (p, q = 1, . . . , k).
Then
dϕip =
X
q
α(p, q) duq
so that
dϕi1 ∧ · · · ∧ dϕik =
Xα(1, q1)· · · α(k, qk) duq1 ∧ · · · ∧ duqk
.
In this last sum, q1, . . . , qk range independently over 1, . . . , k. The anticommuta￾tive relation (10.42) implies that
duq1 ∧ · · · ∧ duqk = s(q1, . . . , qk) du1 ∧ · · · ∧ duk,
where s is as in Definition 9.33; applying this definition, we see that
dϕi1 ∧ · · · ∧ dϕik = det[A] du1 ∧ · · · ∧ duk;
since J(u) = det[A], (10.72) is proved.
The final result of this section combines the two preceding theorems.
10.25 Theorem. Suppose T is a C
1-mapping of an open set E ⊂ Rn into an open set
V ⊂ Rm, Φ is a k-surface in E, and ω is a k-form in V. Then
Z
TΦ
ω =
Z
Φ
ωT .
Proof. Let D be the parameter domain of Φ (hence also of TΦ) and define ∆ as in
Theorem 10.24. Then
Z
TΦ
ω =
Z
∆
ωTΦ =
Z
∆
(ωT )Φ =
Z
Φ
ωT .
The first of these equalities is Theorem 10.24 applied to TΦ in place of Φ. The
second follows from Theorem 10.23. The third is Theorem 10.24 with ωT in place
of ω.SIMPLEXES AND CHAINS 251
SIMPLEXES AND CHAINS
10.26 Affine Simplexes. A mapping f that carries a vector space X into a vector
space Y is said to be affine if f − f(0) is linear. In other words, the requirement is
that
(10.73) f(x) = f(0) + Ax
for some A ∈ L(X, Y).
An affine mapping of Rk into Rn is thus determined if we know f(0) and f(ei
)
for 1 ≤ i ≤ k; as usual, {e1, . . . , ek} is the standard basis of Rk.
We define the standard simplex Qk to be the set of all u ∈ Rk of the form
(10.74) u =
X
k
i=1
αiei
such that αi ≥ 0 for i = 1, . . . , k and Σαi ≤ 1.
Assume now that p0, p1, . . . , pk are points of Rn. The oriented affine k-simplex
(10.75) σ = [p0, p1, . . . , pk]
is defined to be the k-surface in Rn with parameter domain Qk which is given by
the affine mapping
(10.76) σ(α1e1 + · · · + αkek) = p0 +
X
k
i=1
αi
(pi − p0).
Note that σ is characterized by
(10.77) σ(0) = p0, σ(ei
) = pi
(for 1 ≤ i ≤ k),
and that
(10.78) σ(u) = p0 + Au (u ∈ Qk
)
where A ∈ L(Rk, Rn) and Aei = pi − p0 for 1 ≤ i ≤ k.
We call σ oriented to emphasize that the ordering of the vertices p0, . . . , pk is
taken into account. If
(10.79) σ = [pi0
, pi1
, . . . , pik
]
where {i0,i1, . . . ,ik} is a permutation of the ordered set {0, 1, . . . , k}, we adopt the
notation.
(10.80) σ = s(i0,i1, . . . ,ik)σ,
where s is the function defined on Definition 9.33. Thus σ = ±σ, depending onSIMPLEXES AND CHAINS 252
whether s = 1 or s = −1. Strictly speaking, having adopted (10.75) and (10.76)
as the definition of σ, we should not write σ = σ unless i0 = 0, . . . ,ik = k, even
if s(i0, . . . ,ik) = 1; what we have here is an equivalence relation, not an equality.
However, for our purposes, the notation is justified by Theorem 10.27.
If σ = εσ (using the above convention) and if ε = 1, we say that σ and σ have
the same orientation; if ε = −1, σ and σ are said to have opposite orientations. Note
that we have not defined what we mean by the “orientation of a simplex.” What
we have defined is a relation between pairs of simplexes having the same set of
vertices, the relation being that of “having the same orientation.”
There is, however, one situation where the orientation of a simplex can be de￾fined in a natural way. This happens with n = k and when the vectors pi − p0
(1 ≤ i ≤ k) are independent. In that case, the linear transformation of A that ap￾pears in (10.78) is invertible, and its determinant (with is the same as the Jacobian
of σ) is not 0. Then σ is said to be positively (or negatively) oriented if det A is pos￾itive (or negative). In particular, the simplex [0, e1, . . . , ek] in Rk, given by the
identity mapping, has positive orientation.
So far we have assumed that k ≥ 1. An oriented 0-simplex is defined to be a
point with a sign attached. We write σ = +p0 or σ = −p0. If σ = εp0 (ε = ±1)
and if f is a 0-form (i.e., a real function), we defined
Z
σ
f = εf(p0).
10.27 Theorem. If σ is an oriented rectilinear k-simplex in an open set E ⊂ Rn and if
σ = εσ, then
(10.81) Z
σ
ω = ε
Z
σ
ω.
for every k-form ω in E.
Proof. For k = 0, (10.81) follows from the preceding definition. So we assume k ≥ 1
and assume that σ is given by (10.75).
Suppose 1 ≤ j ≤ k and suppose σ is obtained from σ by interchanging p0 and
pj
. Then ε = −1 and
σ(u) = pj + Bu (u ∈ Qk
),
where B is the linear mapping of Rk into Rn defined by Bej = p0 − pj
, Bei =
pi − pj
if i ̸= j. If we write Aei = xi
(1 ≤ i ≤ k), where A is given by (10.78), the
column vectors of B (that is, the vectors Bei
) are
x1 − xj
, . . . , xj−1 − xj
, −xj
, xj+1 − xj
, . . . , xk − xj
.
If we subtract the jth column from each of the others, none of the determinants in
(10.35) are affected, and we obtain columns x1, . . . , xj−1, −xj
, xj+1, . . . , xk. These
differ from those of A only in the sign of the jth column. Hence (10.81) holds forSIMPLEXES AND CHAINS 253
this case.
Suppose next that 0 < i < j ≤ k and that σ is obtained from σ by interchanging
pi and pj
. Then σ(u) = p0 + Cu, where C has the same columns as A, except that
the ith and jth columns have been interchanged. This again implies that (10.81)
holds, since ε = −1.
The general case follows, since every permutation of {0, 1, . . . , k} is a composi￾tion of the special cases we have just dealt with.
10.28 Affine Chains. An affine k-chain Γ in an open set E ⊂ Rn is a collection
of finitely many oriented affine k-simplexes σ1, . . . , σr in E. These need not be
distinct; a simplex may thus occur in Γ with a certain multiplicity.
If Γ is as above, and if ω is a k-form in E, we define
(10.82) Z
Γ
ω =
Xr
i=1
Z
σi
ω.
We may view a k-surface Φ in E as a function whose domain is the collection
of all k-forms in E and which assigns the number R
Φ ω to ω. Since real valued
functions can be added (as in Definition 4.3), this suggests the use of the notation
(10.83) Γ = σ1 + · · · + σr
or, more compactly,
(10.84) Γ =
Xr
i=1
σi
to state the fact that (10.82) holds for every k-form ω in E.
To avoid misunderstanding, we point out explicitly that the notations intro￾duced by (10.83) and (10.80) have to be handled with care. The point is that every
oriented affine k-simplex σ in Rn is a function in two ways, with different domains
and different ranges, and that therefore two entirely different operators of addition
are possible. Originally, σ was defined as an Rn-valued function with domain Qk;
accordingly, σ1 + σ2 could be interpreted to be the function σ that assigns the vec￾tor σ1(u) + σ2(u) to every u ∈ Qk; note that σ is then again an oriented affine
k-simplex in Rn! This is not what is meant by (10.83).
For example, if σ2 = −σ1 as in (10.80) (that is to say, if σ1 and σ2 have the same
set of vertices but are oppositely oriented) and if Γ = σ1 + σ2, then R
Γ ω = 0 for all
ω, and we may express this by writing Γ = 0 or σ1 + σ2 = 0. This does not mean
that σ1(u) + σ2(u) is the null vector in Rn.
10.29 Definition (Boundaries). For k ≥ 1, the boundary of the oriented affine k￾simplex
σ = [p0, p1, . . . , pk]SIMPLEXES AND CHAINS 254
is defined to be the affine (k − 1)-chain
(10.85) ∂σ =
X
k
j=0
(−1)
j
[p0, . . . , pj−1, pj+1, . . . , pk].
For example, if σ = [p0, p1, p2], then
∂σ = [p1, p2] − [p0, p2] + [p0, p1] = [p0, p1] + [p1, p2] + [p2, p0],
which coincides with the usual notion of the oriented boundary of a triangle.
For 1 ≤ j ≤ k, observe that the simplex σj = [p0, · · · , pj−1, pj+1, . . . , pk]
which occurs in (10.85) has Qk−1 as its parameter domain and that it is defined by
(10.86) σj
(u) = p0 + Bu (u ∈ Qk−1
),
where B is the linear mapping from Rk−1 to Rn determined by
Bei =

pi − p0 (if 1 ≤ i ≤ j − 1)
pi+1 − p0 (if j ≤ i ≤ k − 1)
The simplex
σ0 = [p1, p2, . . . , pk],
which also occurs in (10.85), is given by the mapping
σ0(u) = p1 + Bu,
where Bei = pi+1 − p1 for 1 ≤ i ≤ k − 1.
10.30 Differentiable Simplexes and Chains. Let T be a C
2-mapping of an open
set E ⊂ Rn into an open set V ⊂ Rm; T need not be one-to-one. If σ is an oriented
affine k-simplex in E, then the composite mapping Φ = T ◦ σ (which we shall
sometimes write in the simpler form Tσ) is a k-surface in V, with parameter domain
Qk. We call Φ an oriented k-simplex of class C
2.
A finite collection Ψ of oriented k-simplexes Φ1, . . . , Φr of class C
2 in V is
called a k-chain of class C
2 in V. If ω is a k-form in V, we define
(10.87) Z
Ψ
ω =
Xr
i=1
Z
Φi
ω
and use the corresponding notation Ψ = ΣΦi
.
If Γ = Σσi
is an affine chain and if Φi = T ◦ σi
, we also write Ψ = T ◦ Γ , or
(10.88) T
Xσi

=
XTσi
.
The boundary ∂Φ of the oriented k-simplex Φ = T ◦ σ is defined to be theSIMPLEXES AND CHAINS 255
(k − 1)-chain
(10.89) ∂Φ = T(∂σ).
In justification of (10.89), observe that if T is affine, then Φ = T ◦ σ is an oriented
affine k-simplex, in which case (10.89) is not a matter of definition, but is seen to
be a consequence of (10.85). Thus (10.89) generalizes this special case.
It is immediate that ∂Φ is of class C
2 if this is true of Φ.
Finally, we define the boundary ∂Ψ of the k-chain Ψ = ΣΦi
to be the (k − 1)-
chain
(10.90) ∂Ψ =
X∂Φi
.
10.31 Positively Oriented Boundaries. So far we have associated boundaries to
chains, not to subsets of Rn. This notion of boundary is exactly the one that is most
suitable for the statement and proof of Stokes’ theorem. However, in applications,
especially in R2 or R3, it is customary and convenient to talk about “oriented
boundaries” of certain sets as well. We shall now describe this briefly.
Let Qn be the standard simplex in Rn, let σ0 be the identity mapping with
domain Qn. As we saw in Theorem 10.26, σ0 may be regarded as a positively
oriented n-simplex in Rn. Its boundary ∂σ0 is an affine (n − 1)-chain. This chain
is called the positively oriented boundary of the set Qn.
For example, the positively oriented boundary of Q3 is
[e1, e2, e3] − [0, e2, e3] + [0, e1, e3] − [0, e1, e2].
Now let T be a 1-1 mapping of Qn into Rn, of class C
2, whose Jacobian is
positive (at least in the interior of Qn). Let E = T(Qn). By the inverse function
theorem, E is the closure of an open subset of Rn. We define the positively oriented
boundary of the set E to be the (n − 1)-chain
∂T = T(∂σ0),
and we maybe denote this (n − 1)-chain by ∂E.
An obvious question occurs here: if E = T1(Qn) = T2(Qn), and if both T1
and T2 have positive Jacobians, is it true that ∂T1 = ∂T2? That is to say, does the
equality
Z
∂T1
ω =
Z
∂T2
ω
hold for every (n − 1)-form ω? The answer is yes, but we shall omit the proof. (To
see an example, compare the end of this section with Exercise 10.17.)
One can go further. Let
Ω = E1 ∪ · · · ∪ Er,
where Ei = Ti
(Qn), each Ti has the properties that T had above, and the interiorsSIMPLEXES AND CHAINS 256
of the sets Ei are pairwise disjoint. Then the (n − 1)-chain
∂T1 + · · · + ∂Tr = ∂Ω
is called the positively oriented boundary of Ω.
For example, the unit square I
2 in R2 is the union of σ1(Q2) and σ2(Q2), where
σ1(u) = u, σ2(u) = e1 + e2 − u.
Both σ1 and σ2 have Jacobian 1 > 0. Since
σ1 = [0, e1, e2], σ2 = [e1 + e2, e2, e1],
we have
∂σ1 = [e1, e2] − [0, e2] + [0, e1],
∂σ2 = [e2, e1] − [e1 + e2, e1] + [e1 + e2, e2].
the sum of these two boundaries is
∂I2 = [0, e1] + [e1, e1 + e2] + [e1 + e2, e2] + [e2, 0],
the positively oriented boundary of I
2. Note that [e1, e2] canceled [e2, e1].
If Φ is a 2-surface in Rm with parameter domain I
2, then Φ (regarded as a
function on 2-forms) is the same as the 2-chain
Φ ◦ σ1 + Φ ◦ σ2.
Thus
∂Φ = ∂(Φ ◦ σ1) + ∂(Φ ◦ σ2)
= Φ(∂σ1) + Φ(∂σ2) = Φ(∂I2
).
In other words, if the parameter domain of Φ is the unit square I
2, we need not
refer back to the simplex Q2, but can obtain ∂Φ directly from ∂I2.
Other examples may be found in Exercises 10.17 to 10.19.
10.32 Example. For 0 ≤ u ≤ π, 0 ≤ v ≤ 2π, define
Σ(u, v) = (sin u cos v, sin u sin v, cos u).
Then Σ is a 2-surface in R3 whose parameter domain is a rectangle D ⊂ R2, and
whose range is the unit square in R3. Its boundary is
∂Σ = Σ(∂D) = γ1 + γ2 + γ3 + γ4STOKES’ THEOREM 257
where
γ1(u) = Σ(u, 0) = (sin u, 0, cos u),
γ2(v) = Σ(π, v) = (0, 0, −1),
γ3(u) = Σ(π − u, 2π) = (sin u, 0, − cos u),
γ4(v) = Σ(0, 2π − v) = (0, 0, 1)
with [0, π] and [0, 2π] as parameter intervals for u and v, respectively.
Since γ2 and γ4 are constant, their derivatives are 0, hence the integral of any
1-form over γ2 or γ4 is 0. [See Example 10.12(a).] Since γ3(u) = γ1(π − u), direct
application of (10.35) shows that
Z
γ3
ω = − Z
γ1
ω
for every 1-form ω. Thus R
∂Σ ω = 0 and we conclude that ∂Σ = 0.
(In geographic terminology, ∂Σ starts at the north pole N, runs to the south pole
S along a meridian, pauses at S, returns to N along the same meridian, and finally
pauses at N. The two passages along the meridian are in opposite directions. The
corresponding two line integrals therefore cancel each other. In Exercise 10.32 there
is also one curve which occurs twice in the boundary, but without cancellation.)
STOKES’ THEOREM
10.33 Theorem. If Ψ is a k-chain of class C
2 in an open set V ⊂ Rm and if ω is a
(k − 1)-form of class C
1 in V, then
(10.91) Z
Ψ
dω =
Z
∂Ψ
ω.
The case k = m = 1 is nothing but the fundamental theorem of calculus (with
an additional differentiability assumption). The case k = m = 2 is Green’s theo￾rem, and k = m = 3 gives the so-called “divergence theorem” of Gauss. The case
k = 2, m = 3 is the one originally discovered by Stokes. (Spivak’s book [Spi65]
describes some of the historical background.) These special cases will be discussed
further at the end of the present chapter.
Proof. It is enough to prove that
(10.92) Z
Φ
dω =
Z
∂Φ
ω
for every oriented k-simplex Φ of class C
2 in V. For if (10.92) is proved and if
Ψ = ΣΦi
, then (10.87) and (10.89) imply (10.91).STOKES’ THEOREM 258
Fix such a Φ and put
(10.93) σ = [0, e1, . . . , ek].
Thus σ is the oriented affine k-simplex with parameter domain Qk which is de￾fined by the identity mapping. Since Φ is also defined on Qk (see Sec. 10.30) and
Φ ∈ C
2, there is an open set E ⊂ Rk which contains Qk and there is a C
2-mapping
T of E into V such that Φ = T ◦ σ. By Theorems 10.25 and 10.22(c), the left side of
(10.92) is equal to
Z
Tσ
dω =
Z
σ
(dω)T =
Z
σ
d(ωT ).
Another application of Theorem 10.25 shows, by (10.89), that the right side of
(10.92) is
Z
∂(Tσ)
ω =
Z
T(∂σ)
ω =
Z
∂σ
ωT .
Since ωT is a (k − 1)-form in E, we see that in order to prove (10.92) we merely have to
show that
(10.94) Z
σ
dλ =
Z
∂σ
λ
for the special simplex (10.93) and for every (k − 1)-form λ of class C
1 in E.
If k = 1, the definition of an oriented 0-simplex shows that (10.94) merely as￾serts that
(10.95) Z1
0
f
′
(u) du = f(1) − f(0)
for every continuously differentiable function f on [0, 1], which is true by the fun￾damental theorem of calculus (Theorem 6.21).
From now on we assume that k > 1. Fix an integer r (1 ≤ r ≤ k) and choose
f ∈ C
1(E). It is then enough to prove (10.94) for the case
(10.96) λ = f(x) dx1 ∧ · · · ∧ dxr−1 ∧ dxr+1 ∧ · · · ∧ dxk
since every (k − 1)-form is a sum of these special ones, for r = 1, . . . , k.
By (10.85), the boundary of the simplex (10.93) is
∂σ = [e1, . . . , ek] +X
k
i=1
(−1)
i
τi
where
τi = [0, e1, . . . , ei−1, ei+1, . . . , ek]STOKES’ THEOREM 259
for i = 1, . . . , k. Put
τ0 = [er, e1, . . . , er−1, er+1, . . . ek].
Note that τ0 is obtained from [e1, . . . , ek] by r − 1 successive interchanges of er
and its left neighbors. Thus
(10.97) ∂σ = (−1)
r−1
τ0 +
X
k
i=1
(−1)
i
τi
.
Each τi has Qk−1 as its parameter domain.
If x = τ0(u) and u ∈ Qk−1, then
(10.98) xj =



uj
(1 ≤ j < r),
1 − (u1 + · · · + uk−1) (j = r),
uj−1 (r < j ≤ k).
If 1 ≤ i ≤ k, u ∈ Qk−1, and x = τi
(u), then
(10.99) xj =



uj
(1 ≤ j < i),
0 (j = i),
uj−1 (i < j ≤ k).
For 0 ≤ i ≤ k, let Ji be the Jacobian of the mapping
(10.100) (u1, . . . , uk−1) 7→ (x1, . . . , xr−1, xr+1, . . . , xk)
induced by τi
. When i = 0 and when i = r, (10.98) and (10.99) show that (10.100)
is the identity mapping. Thus J0 = 1, Jr = 1. For the other i, the fact that xi = 0 in
(10.99) shows that Ji has a row of zeroes, hence Ji = 0. Thus
(10.101) Z
τi
λ = 0 (i ̸= 0,i ̸= r),
by (10.35) and (10.96). Consequently, (10.97) gives
(10.102)
Z
∂σ
λ = (−1)
r−1
Z
τ0
λ + (−1)
r
Z
τr
λ
= (−1)
r−1
Z
Qk−1
[f(τ0(u)) − f(τr(u)) du.
On the other hand,
dλ = (Drf)(x) dxr ∧ dx1 ∧ · · · ∧ dxr−1 ∧ dxr+1 ∧ · · · ∧ dxk
= (−1)
r−1
(Drf)(x) dx1 ∧ · · · ∧ dxkCLOSED FORMS AND EXACT FORMS 260
so that
(10.103) Z
σ
dλ = (−1)
r−1
Z
Qk
(Drf)(x) dx.
To evaluate (10.103), first integrate with respect to xr over the interval
[0, 1 − (x1 + · · · + xr−1 + xr+1 + · · · + xk)],
put (x1, . . . , xr−1, xr+1, . . . , xk) = (u1, . . . , uk−1), and see with the aid of (10.98)
that the integral over Qk in (10.103) is equal to the integral over Qk−1 in (10.102).
Thus (10.94) holds, and the proof is complete.
CLOSED FORMS AND EXACT FORMS
10.34 Definition. Let ω be a k-form in an open set E ⊂ Rn. If there is a (k − 1)-
form λ in E such that ω = dλ, then ω is said to be exact in E. If ω is of class C
1 and
dω = 0, then ω is said to be closed.
Theorem 10.20(b) shows that every exact form of class C
1 is closed. In cer￾tain sets E, for example in convex ones, the converse is true; this is the content of
Theorem 10.39 (usually known as Poincar´e’s lemma) and Theorem 10.40. However,
Examples 10.36 and 10.37 will exhibit closed forms that are not exact.
10.35 Remarks.
(a) Whether a given k-form ω is or is not closed can be verified by simply dif￾ferentiating the coefficients in the standard presentation of ω. For example,
a 1-form
(10.104) ω =
Xn
i=1
fi
(x) dxi
,
with fi ∈ C
1(E) for some open set E ⊂ Rn, is closed if and only if the
equations
(10.105) (Djfi
)(x) = (Difj
)(x)
hold for all i, j in {1, . . . , n} and for all x ∈ E. Note that (10.105) is a “point￾wise” condition; it does not involve any global properties that depend on the
shape of E.
On the other hand, to show that ω is exact in E, one has to prove the
existence of a form λ, defined in E, such that dλ = ω. This amounts to
solving a system of partial differential equations, not just locally, but in all
of E. For example, to show that (10.104) is exact in a set E, one has to find a
function (or 0-form) g ∈ C
1(E) such that
(10.106) (Dig)(x) = fi
(x) (x ∈ E, 1 ≤ i ≤ n).CLOSED FORMS AND EXACT FORMS 261
Of course, (10.105) is a necessary condition for the solvability of (10.106).
(b) Let ω be an exact k-form in E. Then there is a (k − 1)-form λ in E with dλ = ω,
and Stokes’ theorem asserts that
(10.107) Z
Ψ
ω =
Z
Ψ
dλ =
Z
∂Ψ
λ
for every k-chain Ψ of class C
2 in E.
If Ψ1 and Ψ2 are such chains, and if they have the same boundaries, it
follows that
Z
Ψ1
ω =
Z
Ψ2
ω.
In particular, the integral of an exact k-form in E is 0 over every k-chain whose
boundary is 0. As an important special case of this, note that integrals of exact
1-forms in E are 0 over closed (differentiable) curves in E.
(c) Let ω be a closed k-form in E. Then dω = 0, and Stokes’ theorem asserts that
(10.108) Z
∂Ψ
ω =
Z
Ψ
dω = 0
for every (k + 1)-chain Ψ of class C
2 in E. In other words, integrals of closed
k-forms in E are 0 over k-chains that are boundaries of (k + 1)-chains in E.
(d) Let Ψ be a (k + 1)-chain in E and let λ be a (k − 1)-form in E, both of class C
2.
Since d2λ = 0, two applications of Stokes’ theorem show that
(10.109) Z
∂∂Ψ
λ =
Z
∂Ψ
dλ =
Z
Ψ
d
2
λ = 0.
We conclude that ∂
2Ψ = 0. In other words, the boundary of a boundary is 0. See
Exercise 10.16 for a more direct proof of this.
10.36 Example. Let E = R2 − {0}, the plane with the origin removed. The 1-form
(10.110) η =
x dy − y dx
x
2 + y2
is closed in R2 − {0}. This is easily verified by differentiation. Fix r > 0 and define
(10.111) γ(t) = (r cos t, r sin t) (0 ≤ t ≤ 2π).
Then γ is a curve (an “oriented 1-simplex”) in R2 − {0}. Since γ(0) = γ(2π), we
have
(10.112) ∂γ = 0.CLOSED FORMS AND EXACT FORMS 262
Direct computation shows that
(10.113) Z
γ
η = 2π ̸= 0.
The discussion in Remark 10.35(b) and (c) shows that we can draw two conclusions
from (10.113):
• First, η is not exact in R2 − {0}, for otherwise (10.112) would force the integral
(10.113) to be 0.
• Second, γ is not the boundary of any 2-chain R2 −{0} (of class C
2), for otherwise
the fact that η is closed would force the integral (10.113) to be 0.
10.37 Example. Let E = R3 − {0}, 3-space with the origin removed. Define
(10.114) ζ =
x dy ∧ dz + y dz ∧ dx + z dx ∧ dy
(x
2 + y2 + z
2)
3/2
,
where we have written (x, y, z) in place of (x1, x2, x3). Differentiation shows that
dζ = 0, so that ζ is a closed 2-form in R3 − {0}.
Let Σ be the 2-chain R3 − {0} that was constructed in Example 10.32; recall
that Σ is a parametrization of the unit sphere in R3. Using the rectangle D of
Example 10.32 as a parameter domain, it is easy to compute that
(10.115) Z
Σ
ζ =
Z
D
sin u du dv = 4π ̸= 0.
As in the preceding example, we can now conclude that ζ is not exact in R3 − {0}
(since ∂Σ = 0, as was shown in Example 10.32) and that the sphere Σ is not the
boundary of any 3-chain in R3 − {0} (of class C
2), although ∂Σ = 0.
The following result will be used in the proof of Theorem 10.39:
10.38 Theorem. Suppose E is a convex open set in Rn, f ∈ C
1(E), p is an integer,
1 ≤ p ≤ n, and
(10.116) (Djf)(x) = 0 (p < j ≤ n, x ∈ E).
Then there exists an F ∈ C
1(E) such that
(10.117) (DpF)(x) = f(x), (DjF)(x) = 0 (p < j ≤ n, x ∈ E).
Proof. Write x = (x
′
, xp, x
′′), where
x
′ = (x1, . . . , xp−1), x
′′ = (xp+1, . . . , xn).
(When p = 1, x
′
is absent; when p = n, x
′′ is absent.) Let V be the set of all
(x
′
, xp) ∈ Rp such that (x
′
, xp, x
′′) ∈ E for some x
′′. Being a projection of E, V is a
convex open set in Rp. Since E is convex and (10.116) holds, f(x) does not dependCLOSED FORMS AND EXACT FORMS 263
on x
′′. Hence there is a function φ, with domain V, such that
f(x) = φ(x
′
, xp)
for all x ∈ E.
If p = 1, V is a segment in R1 (possibly unbounded). Pick c ∈ V and define
F(x) = Zx1
c
φ(t) dt (x ∈ E).
If p > 1, let U be the set of all x
′ ∈ Rp−1 such that (x
′
, xp) ∈ V for some xp.
Then U is a convex open set in Rp−1 and there is a function α ∈ C
1(U) such that
(x
′
, α(x
′
)) ∈ V for every x
′ ∈ U; in other words, the graph of α lies in V (Exercise
10.29). Define
F(x) = Zxp
α(x
′)
φ(x
′
, t) dt (x ∈ E).
In either case, F satisfies (10.117).
10.39 Theorem. If E ⊂ Rn is convex and open, if k ≥ 1, if ω is a k-form of class C
1 in
E, and if ∂ω = 0, then there is a (k − 1)-form λ in E such that ω = dλ.
Briefly, closed forms are exact in convex sets.
Proof. For p = 1, . . . , n, let Yp denote the set of all k-forms ω of class C
1 in E whose
standard presentation
(10.118) ω =
X
I
fI(x) dxI
does not involve dxp+1, . . . , dxn. In other words, if I = (i1, . . . ,ik), then
{i1, . . . ,ik} ⊂ {1, . . . , p} if fI(x) ̸= 0 for some x ∈ E. We shall proceed by induc￾tion on p.
Assume first that ω ∈ Y1. Then ω = f(x) dx1. Since dω = 0, (Djf)(x) = 0 for
1 < j ≤ n, x ∈ E. By Theorem 10.38 there is an F ∈ C
1(E) such that D1F = f and
DjF = 0 for 1 < j ≤ n. Thus
dF = (D1F)(x) dx1 = f(x) dx1 = ω.
Now we take p > 1 and make the following induction hypothesis: Every closed
k-form that belongs to Yp−1 is exact in E.
Choose ω ∈ Yp so that dω = 0. By (10.118),
(10.119) X
I
Xn
j=1
(DjfI)(x) dxj ∧ dxI = dω = 0.
Consider a fixed j with p < j ≤ n. Each I that occurs in (10.118) lies in {1, . . . , p}. If
I1,I2 are two of these k-indices, and if I1 ̸= I2, then the (k + 1)-indices (I1, j),(I2, j)CLOSED FORMS AND EXACT FORMS 264
are distinct. Thus there is no cancellation, and we conclude that (10.119) that every
coefficient in (10.118) satisfies
(10.120) (DjfI)(x) = 0 (x ∈ E, p < j ≤ n).
We now gather those terms in (10.118) that contain dxp and rewrite ω in the
form
(10.121) ω = α +
X
I0
fI(x) dxI0 ∧ dxp,
where α ∈ Yp−1, each I0 is an increasing (k − 1)-index in {1, . . . , p − 1}, and I =
(I0, p). By (10.120), Theorem 10.38 furnishes functions FI ∈ C
1(E) such that
(10.122) DpFI = fI, DjFI = 0 (p < j ≤ n).
Put
(10.123) β =
X
I0
FI(x) dxI0
and define γ = ω − (−1)
k−1 dβ. Since β is a (k − 1)-form, it follows that
γ = ω −
X
I0
X
p
j=1
(DjFI)(x) dxI0 ∧ dxj
= α −
X
I0
p
X−1
j=1
(DjFI)(x) dxI0 ∧ dxj
,
which is clearly in Yp−1. Since dω = 0 and d2β = 0, we have dγ = 0. Our
induction hypothesis shows therefore that γ = dµ for some (k − 1)-form µ in E.
If λ = µ + (−1)
k−1β, we conclude that ω = dλ. By induction, this completes the
proof.
10.40 Theorem. Fix k, 1 ≤ k ≤ n. Let E ⊂ Rn be an open set in which every closed
k-form is exact. Let T be a 1-1 C
2-mapping of E onto an open set U ⊂ Rn whose inverse
S is also of class C
2. Then every closed k-form in U is exact in U.
Note that every convex open set E satisfies the present hypothesis by Theo￾rem 10.39. The relation between E and U may be expressed by saying that they are
C
2-equivalent.
Thus every closed form is exact in any set which is C
2 equivalent to a convex open set.
Proof. Let ω be a k-form in U with dω = 0. By Theorem 10.22(c), ωT is a k-form
in E for which d(ωT ) = 0. Hence ωT = dλ for some (k − 1)-form λ in E. ByVECTOR ANALYSIS 265
Theorem 10.23, and another application of Theorem 10.22(c),
ω = (ωT )S = (dλ)S = d(λS).
Since λS is a (k − 1)-form in U, ω is exact in U.
10.41 Remark. In applications, cells (see Definition 2.17) are often more convenient
parameter domains than simplexes. If our whole development had been based
on cells rather than simplexes, the computation that occurs in the proof of Stokes’
theorem would be even simpler. (It is done that way in Spivak’s book [Spi65].) The
reason for preferring simplexes is that the definition of the boundary of an oriented
simplex seems easier and more natural than is the case for a cell. (See Exercise
10.19.) Also, the partitioning of sets into simplexes (called “triangulation”) plays
an important role in topology and there are strong connections between certain
aspects of topology, on the one hand, and differential forms, on the other. These
are hinted at in Remark 10.35. The book by Singer and Thorpe [ST67] contains a
good introduction to this topic.
Since every cell can be triangulated, we may regard it as a chain. For dimension
2, this was done in Example 10.32; for dimension 3, see Exercise 10.18.
Poincare’s lemma (Theorem 10.39) can be proved in several ways. See, for ex- ´
ample, page 94 in Spivak’s book [Spi65], or page 280 in Fleming’s [Fle65]. Two
simple proofs for certain special cases are indicated in Exercise 10.24 and Exercise
10.27.
VECTOR ANALYSIS
We conclude this chapter with a few applications of the preceding material to the￾orems concerning vector analysis in R3. These are special cases of theorems about
differential forms, but are usually stated in different terminology. We are thus
faced with the job of translating from one language to another.
10.42 Vector Fields. Let F = F1e1 + F2e2 + F3e3 be a continuous mapping of an
open set E ⊂ R3 into R3. Since F associates a vector to each point of E, F is some￾times called a vector field, especially in physics. With every such F is associated a
1-form
(10.124) λF = F1 dx + F2 dy + F3 dz
and a 2-form
(10.125) ωF = F1 dy ∧ dz + F2 dz ∧ dx + F3 dx ∧ dy.
Here, and in the rest of this chapter, we use the customary notation (x, y, z) in place
of (x1, x2, x3).VECTOR ANALYSIS 266
It is clear, conversely, that every 1-form in E is λF for some vector field F in E,
and that every 2-form ω is ωF for some F. In R3, the study of 1-forms and 2-forms
is thus coextensive with the study of vector fields.
If u ∈ C
1(E) is a real function, then its gradient
∇u = (D1u)e1 + (D2u)e2 + (D3u)e3
is an example of a vector field in E.
Suppose now that F is a vector field in E, of class C
1. Its curl ∇ × F is the vector
field defined in E by
∇ × F = (D2F3 − D3F2)e1 + (D3F1 − D1F3)e2 + (D1F2 − D2F1)e3
and its divergence is the real function ∇ · F defined in E by
∇ · F = D1F1 + D2F2 + D3F3.
These quantities have various physical interpretations. We refer to the book by
O.D. Kellogg [Kel40] for more details.
Here are some relations between gradients, curls, and divergences.
10.43 Theorem. Suppose E is an open set in R3, u ∈ C
2(E), and G is a vector field in
E of class C
2.
(a) If F = ∇u, then ∇ × F = 0.
(b) If F = ∇ × G, then ∇ · F = 0.
Furthermore, if E is C
2-equivalent to a convex set, then (a) and (b) have converses, in
which we assume that F is a vector field in E of class C
1:
(a’) If ∇ × F = 0, then F = ∇u for some u ∈ C
2(E).
(b’) If ∇ · F = 0, then F = ∇ × G for some vector field G in E of class C ‘‘.
Proof. If we compare the definitions of ∇u, ∇ × F, and ∇ · F with the differen￾tial forms λF and ωF given by (10.124) and (10.125), we obtain the following four
statements:
F = ∇u if and only if λF = du.
∇ × F = 0 if and only if dλF = 0.
F = ∇ × G if and only if ωF = dλG.
∇ · F = 0 if and only if dωF = 0.
Now if F = ∇u, then λF = du, hence dλF = d
2u = 0 (Theorem 10.20), which
means that ∇ × F = 0. Thus (a) is proved. As regards (a’), the hypothesis amounts
to saying that dλF = 0 in E. By Theorem 10.40, λF = du for some 0-form u. Hence
F = ∇u.VECTOR ANALYSIS 267
The proofs of (b) and (b’) follow exactly the same pattern.
10.44 Volume Elements. The k-form
dx1 ∧ · · · ∧ dxk
is called the volume element in Rk. It is often denoted by dV (or by dVk if it seems
desirable to indicated the dimension explicitly), and the notation
(10.126) Z
Φ
f(x) dx1 ∧ · · · ∧ dxk =
Z
Φ
f dV
is used when Φ is a positively oriented k-surface in Rk and f is a continuous func￾tion on the range of Φ.
The reason for using this terminology is very simple: If D is a parameter do￾main in Rk and if Φ is a 1-1 C
1-mapping of D into Rk with positive Jacobian JΦ,
then the left side of (10.126) is
Z
D
f(Φ(u))JΦ(u) du =
Z
Φ(D)
f(x) dx,
by (10.35) and Theorem 10.9.
In particular, when f = 1, (10.126) defines the volume of Φ. We already saw a
special case of this in (10.36).
The usual notation for dV2 is dA.
10.45 Theorem (Green’s Theorem). Suppose E is an open set in R2, α ∈ C
1(E),
β ∈ C
1(E), and Ω is a closed subset of E with positively oriented boundary dΩ, as
described in Sec. 10.31. Then
(10.127) Z
dΩ
(α dx + β dy) = Z
Ω

∂β
∂x −
∂α
∂y 
dA.
Proof. Put λ = α dx + β dy. Then
dλ = (D2α) dy ∧ dx + (D1β) dx ∧ dy
= (D1β − D2α) dA,
and (10.127) is the same as
Z
∂Ω
λ =
Z
Ω
dλ,
which is true by Theorem 10.33.
With α(x, y) = −y and β(x, y) = x, (10.127) becomes
(10.128) 1
2
Z
∂Ω
(x dy − y dx) = A(Ω),VECTOR ANALYSIS 268
the area of Ω.
With α = 0, β = x, a similar formula is obtained. Example 10.12(b) contains a
special case of this.
10.46 Area Elements in R3. Let Φ be a 2-surface in R3 of class C
1 and with pa￾rameter domain D ⊂ R2. Associate with each point (u, v) ∈ D the vector
(10.129) N(u, v) = ∂(y, z)
∂(u, v)
e1 +
∂(z, x)
∂(u, v)
e2 +
∂(x, y)
∂(u, v)
e3.
The Jacobians in (10.129) correspond to the equation
(10.130) (x, y, z) = Φ(u, v).
If f is a continuous function on Φ(D), the area integral of f over Φ is defined to be
(10.131) Z
Φ
f dA =
Z
D
f(Φ(u, v))|N(u, v)| du dv.
In particular, when f = 1, we obtain the area of Φ, namely
(10.132) A(Φ) = Z
D
|N(u, v)| du dv.
The following discussion will show that (10.131) and its special case (10.132)
are reasonable definitions. It will also describe the geometric features of the vector
N.
Write Φ = φ1e1 + φ2e2 + φ3e3, fix a point p0 = (u0, v0) ∈ D, put N = N(p0),
put
(10.133) αi = (D1φi
)(p0), βi = (D2φi
)(p0) (i = 1, 2, 3),
and let T ∈ L(R2, R3) be the linear transformation given by
(10.134) T(u, v) = X
3
i=1
(αiu + βiv)ei
.
Note that T = Φ′
(p0), in accordance with Definition 9.11.
Let us now assume the rank of T is 2. (If it is 1 or 0, then N = 0, and the tangent
plane mentioned below degenerates to a line or to a point.) The range of the affine
mapping
(u, v) 7→ Φ(p0) + T(u, v)
is then a plane Π called the tangent plane to Φ at p0. [One would like to call Π
the tangent plane at Φ(p0), rather then at p0; if Φ is not one-to-one, this runs into
difficulties.]VECTOR ANALYSIS 269
If we use (10.133) in (10.129), we obtain
(10.135) N = (α2β3 − α3β2)e1 + (α3β1 − α1β3)e2 + (α1β2 − α2β1)e3,
and (10.134) shows that
(10.136) Te1 =
X
3
i=1
αiei
, Te2 =
X
3
i=1
βiei
.
A straightforward computation now leads to
(10.137) N · (Te1) = 0 = N · (Te2).
Hence N is perpendicular to Π. It is therefore called the normal to Φ at p0.
A second property of N, also verified by a direct computation based on (10.135)
and (10.136), is that the determinant of the linear transformation of R3 that takes
(e1, e2, e3) to (Te1, Te2, N) is |N|
2 > 0 (Exercise 10.30). The 3-simplex
(10.138) [0, Te1, Te2, N]
is thus positively oriented.
The third property of N that we shall use is a consequence of the first two: The
above-mentioned determinant, whose value is |N|
2
, is the volume of the paral￾lelepiped with edges [0, Te1], [0, Te2], [0, N]. By (10.137), [0, N] is perpendicular to
the other two edges. The area of the parallelogram with vertices
(10.139) 0, Te1, Te2, T(e1 + e2)
is therefore |N|.
This parallelogram is the image under T of the unit square in R2. If E is any
rectangle in R
2, it follows (by the linearity of T) that the area of the parallelogram
T(E) is
(10.140) A(T(E)) = |N| A(E) = Z
E
|N(u0, v0)| du dv
We conclude that (10.132) is correct when Φ is affine. To justify the definition
(10.132) in the general case, divide D into small rectangles, pick a point (u0, v0)
in each, and replace Φ in each rectangle by the corresponding tangent plane. The
sum of the areas of the resulting parallelograms, obtained via (10.140), is then an
approximation to A(Φ). Finally, one can justify (10.131) from (10.132) by approxi￾mating f by step functions.
10.47 Example. Let 0 < a < b be fixed. Let K be the 3-cell determined by
0 ≤ t ≤ a, 0 ≤ u ≤ 2π, 0 ≤ v ≤ 2π.VECTOR ANALYSIS 270
The equations
(10.141)
x = t cos u
y = (b + t sin u) cos v
z = (b + t sin u) sin v
describe a mapping Φ of R3 into R3 which is 1-1 in the interior of K, such that
Ψ(K) is a solid torus. Its Jacobian is
JΨ =
∂(x, y, z)
∂(t, u, v)
= t(b + t sin u)
which is positive on K, except on the face t = 0. If we integrate JΨ over K, we
obtain
vol(Ψ(K)) = 2π2a
2b
2
as the volume of our solid torus.
Now consider the 2-chain Φ = ∂Ψ. (See Exercise 10.19.) Ψ maps the faces
u = 0 and u = 2π of K onto the same cylindrical strip, but with the opposite
orientations. Ψ maps the faces v = 0 and v = 2π onto the same circular disc, but
with opposite orientations. Ψ maps the face t = 0 onto a circle, which contributes
0 to the 2-chain ∂Ψ. (The relevant Jacobians are 0.) Thus Φ is simply the 2-surface
obtained by setting t = a in (10.141), with parameter domain D the square defined
by 0 ≤ u ≤ 2π, 0 ≤ v ≤ 2π.
According to (10.129) and (10.141), the normal to Φ at (u, v) ∈ D is thus the
vector
N(u, v) = a(b + a sin u)n(u, v),
where
n(u, v) = (cos u)e1 + (sin u cos v)e2 + (sin u sin v)e3.
Since |n(u, v)| = 1, we have |N(u, v)| = a(b + a sin u), and if we integrate this over
D, (10.131) gives
A(Φ) = 4π2ab
as the surface area of our torus.
If we think of N = N(u, v) as a directed line segment pointing from Φ(u, v) to
Φ(u, v) + N(u, v), then N points outward, that is to say, away from Ψ(K). This is so
because JΨ > 0 when t = a.
For example, take u = v = π/2, t = a. This gives the largest value of z on Ψ(K),
and N = a(b + a)e3 points “upward” for this choice of (u, v).
10.48 Integrals of 1-forms in R3. Let γ be a C
1 curve in an open set E ⊂ R3 with
parameter interval [0, 1], let F be a vector field in E as in Sec. 10.42, and define λF
by (10.124). For any u ∈ [0, 1],
γ
′
(u) = γ
′
1
(u)e1 + γ
′
2
(u)e2 + γ
′
3
(u)e3VECTOR ANALYSIS 271
is called the tangent vector to γ at u. We define t = t(u) to be the unit vector in the
direction of γ
′
(u). Thus
γ
′
(u) =

γ
′
(u)


t(u).
[If γ
′
(u) = 0 for some u, put t(u) = e1; any other choice would do just as well.] By
(10.35),
(10.142)
Z
γ
λF =
X
3
i=1
Z1
0
Fi
(γ(u))γ
′
i
(u) du
=
Z1
0
F(γ(u)) · γ
′
(u) du
=
Z1
0
F(γ(u)) · t(u)

γ
′
(u)

 du
Theorem 6.27 makes it reasonable to call

γ
′
(u)


the element of arc length along γ. A
customary notation for it is ds, and (10.142) is rewritten in the form
(10.143) Z
γ
λF =
Z
γ
(F · t) ds.
Since t is a unit tangent vector to γ, F · t is called the tangential component of F along
γ.
The right side of (10.143) should be regarded as just an abbreviation for the last
integral in (10.142). The point is that F is defined on the range of γ, but t is defined
on [0, 1]; thus F · t has to be properly interpreted. Of course, when γ is one-to-one,
then t(u) can be replaced by t(γ(u)) and this difficulty disappears.
10.49 Integrals of 2-forms in R3. Let Φ be a 2-surface in an open set E ⊂ R3,
of class C
1, and with parameter domain D ⊂ R2. Let F be a vector field in E
and define ωF by (10.125). As in the preceding section, we shall obtain a different
representation of the integral of ωF over Φ. By (10.35) and (10.129),
Z
Φ
ωF =
Z
Φ
(F1 dy ∧ dz + F2 dz ∧ dx + F3 dx ∧ dy)
=
Z
D

(F1 ◦ Φ)
∂(y, z)
∂(u, v)
+ (F2 ◦ Φ)
∂(z, x)
∂(u, v)
+ (F3 ◦ Φ)
∂(x, y)
∂(u, v)

du dv
=
Z
D
F(Φ(u, v)) · N(u, v) du dv.
Now let n = n(u, v) be the unit vector in the direction of N(u, v). [If N(u, v) = 0 for
some (u, v) ∈ D, take n(u, v) = e1.] Then N = |N| n, and therefore the last integral
becomes
Z
D
F(Φ(u, v)) · n(u, v)|N(u, v)| du dv.VECTOR ANALYSIS 272
By (10.131), we can finally write this in the form
(10.144) Z
Φ
ωF =
Z
Φ
(F · n) dA.
With regard to the meaning of F · n, the remark made at the end of Sec. 10.48
applies here as well.
We can now state the original form of Stokes’ theorem.
10.50 Theorem (Stokes’ Formula). If F is a vector field of class C
1 in an open set
E ⊂ R3, and if Φ is a 2-surface of class C
2 in E, then
(10.145) Z
Φ
(∇ × F) · n dA =
Z
∂Φ
(F · t) ds.
Proof. Put H = ∇ × F. Then, as in the proof of Theorem 10.43, we have
(10.146) ωH = dλF.
Hence
Z
Φ
(∇ × F) · n dA =
Z
Φ
(H · n) dA =
Z
Φ
ωH
=
Z
Φ
dλF =
Z
∂Φ
λF =
Z
∂Φ
(F · t) ds.
Here we used the definition of H, then (10.144) with H in place of F, then
(10.146), then—the main step—Theorem 10.33, and finally (10.143), extended in
the obvious way from curves to 1-chains.
10.51 Theorem (The Divergence Theorem). If F is a vector field of class C
1 in an open
set E ⊂ R3, and if Ω is a closed subset of E with positively oriented boundary ∂Ω (as
described in Sec. 10.31 then
(10.147) Z
Ω
(∇ · F) dV =
Z
∂Ω
(F · n) dA.
Proof. By (10.125),
dωF = (∇ · F) dx ∧ dy ∧ dz = (∇ · F) dV.
Hence
Z
Ω
(∇ · F) dV =
Z
Ω
dωF =
Z
∂Ω
ωF =
Z
∂Ω
(F · n) dA,
by Theorem 10.33, applied to the 2-form ωF and (10.144).EXERCISES 273
EXERCISES
10.1. Let H be a compact convex set in Rk with nonempty interior. Let f ∈ C (H), put f(x) = 0
in the complement of H, and define R
H f as in Definition 10.3. Prove that R
H f is independent
of the order in which the k integrations are carried out.
Hint: Approximate f by functions that are continuous on Rk and whose supports are in
H, as was done in Example 10.4.
10.2. For i = 1, 2, 3, . . . , let φi ∈ C (R1
) have support in (2
−i
, 2
1−i
) and satisfy R
φi = 1. Put
f(x, y) = X∞
i=1
[φi(x) − φi+1(x)]φi(y).
Then f has compact support in R2
, f is continuous except at (0, 0), and
Z
dy
Z
f(x, y) dx = 0 but Z
dx
Z
f(x, y) dy = 1.
Observe that f is unbounded in every neighborhood of (0, 0).
10.3.
(a) If F is as in Theorem 10.7, put A = F
′
(0), F1(x) = A−1F(x). Then F
′
1
(0) = I. Show that
F1(x) = Gn ◦ Gn−1 ◦ · · · ◦ G1(x)
in some neighborhood of 0, for certain primitive mappings G1, . . . , Gn. This gives
another version of Theorem 10.7:
F(x) = F
′
(0)Gn ◦ Gn−1 ◦ · · · ◦ G1(x).
(b) Prove that the mapping (x, y) 7→ (y, x) of R2 onto R2
is not the composition of any
two primitive mappings, in any neighborhood of the origin. (This shows that the flips
Bi cannot be omitted from the statement of Theorem 10.7.)
10.4. For (x, y) ∈ R2
, define
F(x, y) = (e
x
cos y − 1, e
x
sin y).
Prove that F = G2 ◦ G1, where
G1(x, y) = (e
x
cos y − 1, y)
G2(u, v) = (u,(1 + u)tan v)
are primitive in some neighborhood of (0, 0).
Compute the Jacobians of G1, G2, F at (0, 0). Define
H2(x, y) = (xex
sin y),
and find
H1(u, v) = (h(u, v), v)
so that F = H1 ◦ H2 in some neighborhood of (0, 0).
10.5. Formulate and prove an analogue of Theorem 10.8, in which K is a compact subset of
an arbitrary metric space. (Replace the functions φi that occur in the proof of Theorem 10.8
by functions of the type constructed in Exercise 4.22.)
10.6. Strengthen the conclusion of Theorem 10.8 by showing that the functions ψi can be
made differentiable, and even infinitely differentiable. (Use Exercise 8.1 in the construction
of the auxiliary functions φi.)EXERCISES 274
10.7.
(a) Show that the simplex Qk is the smallest convex subset of Rk that contains 0, e1, . . . , ek.
(b) Show that affine mappings take convex sets to convex sets.
10.8. Let H be the parallelogram in R2 whose vertices are (1, 1), (3, 2), (4, 5), (2, 4). Find the
affine map T which sends (0, 0) to (1, 1), (1, 0) to (3, 2), (0, 1) to (2, 4). Show that JT = 5. Use
T to convert the integral
α =
Z
H
e
x−y dx dy
to an integral over I
2 and thus compute α.
10.9. Define (x, y) = T(r, θ) on the rectangle
0 ≤ r ≤ a, 0 ≤ θ ≤ 2π
by the equations
x = r cos θ, y = r sin θ.
Show that T maps this rectangle onto the closed disc D with center at (0, 0) and radius a, that
T is one-to-one in the interior of the rectangle, and that JT (r, θ) = r. If f ∈ C (D), prove the
formula for integration in polar coordinates:
Z
D
f(x, y) dx dy =
Z a
0
Z 2π
0
f(T(r, θ))r dr dθ.
Hint: Let D0 be the interior of D, minus the interval from (0, 0) to (0, a). As it stands,
Theorem 10.9 applies to continuous functions f whose support lies in D0. To remove this
restriction, proceed as in Example 10.4.
10.10. Let a → ∞ in Exercise 10.9 and prove that
Z
R2
f(x, y) dx dy =
Z∞
0
Z 2π
0
f(T(r, θ))r dr dθ
for continuous functions f that decrease sufficiently rapidly as |x| + |y| → ∞. (Find a more
precise formulation.) Apply this to
f(x, y) = exp(−x
2 − y
2
)
to derive formula (8.101).
10.11. Define (u, v) = T(s, t) on the strip
0 < s < ∞, 0 < t < 1
by setting u = s − st, v = st. Show that T is a 1-1 mapping of the strip onto the positive
quadrant Q in R2
. Show that JT (s, t) = s.
For x > 0, y > 0, integrate
u
x−1
e
−uv
y−1
e
−v
over Q, use Theorem 10.9 to convert the integral to one over the strip, and derive formula
(8.96) in this way.
(For this application, Theorem 10.9 has to be extended so as to cover certain improper
integrals. Provide this extension.)
10.12. Let I
k be the set of all u = (u1, . . . , uk) ∈ Rk with 0 ≤ ui ≤ 1 for all i; let Qk be the
set of all x = (x1, . . . , xk) ∈ Rk with xi ≥ 0, Σxi ≤ 1. (I
k is the unit cube; Qk is the standardEXERCISES 275
simplex in Rk.) Define x = T(u) by
x1 = u1
x2 = (1 − u1)u2
.
.
.
xk = (1 − u1)· · ·(1 − uk−1)uk.
Show that
Xk
i=1
xi = 1 −
Yk
i=1
(1 − ui).
Show that T maps I
k onto Qk, that T is 1-1 in the interior of I
k, and that its inverse S is
defined in the interior of Qk by u1 = x1 and
ui =
xi
1 − x1 − · · · − xi−1
for i = 2, . . . , k. Show that
JT (u) = (1 − u1)
k−1
(1 − u2)
k−2
· · ·(1 − uk−1),
and
JS(x) = [(1 − x1)(1 − x1 − x2)· · ·(1 − x1 − · · · − xk−1)]−1
.
10.13. Let r1, . . . , rk be nonnegative integers and prove that
Z
Qk
x
r1
1
· · · x
rk
k
dx =
r1! · · · rk!
(k + r1 + · · · + rk)!
Hint: Use Exercise 10.12, Theorems 10.9 and 8.20. Note that the special case r1 = · · · = rk = 0
shows that the volume of Qk is 1/k!.
10.14. Prove formula (10.46)
10.15. If ω and λ are k- and m-forms, respectively, prove that
ω ∧ λ = (−1)
kmλ ∧ ω.
10.16. If k ≥ 2 and σ = [p0, p1, . . . , pk] is an oriented affine k-simplex, prove that ∂
2σ = 0,
directly from the definition of the boundary operator ∂. Deduce from this that ∂
2Ψ = 0 for
every chain Ψ.
Hint: For orientation, do it first for k = 2, k = 3. In general, if i < j, let σij be the (k − 2)-
simplex obtained by deleting pi and pj
from σ. Show that each σij occurs twice in ∂
2σ with
opposite sign.
10.17. Put J
2 = τ1 + τ2, where
τ1 = [0, e1, e1 + e2], τ2 = −[0, e2, e2 + e1].
Explain why it is reasonable to call J
2
the positively oriented unit square in R2
. Show that
∂J2
is the sum of 4 oriented affine 1-simplexes. Find these. What is ∂(τ1 − τ2)?
10.18. Consider the oriented affine 3-simplex
σ1 = [0, e1, e1 + e2, e1 + e2 + e3]
in R3
. Show that σ1 (regarded as a linear transformation) has determinant 1. Thus σ1 is
positively oriented.EXERCISES 276
Let σ2, . . . , σ6 be five other oriented 3-simplexes, obtained as follows: There are five
permutations (i1,i2,i3) of (1, 2, 3), distinct from (1, 2, 3). Associate with each (i1,i2,i3) the
simplex
s(i1,i2,i3)[0, ei1
, ei1 + ei2
, ei1 + ei2 + ei3
]
where s is the sign that occurs in the definition of the determinant. (This is how τ2 was
obtained from τ1 in Exercise 10.17.) Show that σ2, . . . , σ6 are positively oriented.
Put J
3 = σ1 + · · · + σ6. Then J
3 may be called the positively oriented unit cube in R3
.
Show that ∂J3
is the sum of 12 oriented affine 2-simplexes. (These 12 triangles cover the
surface of the unit cube I
3
.)
Show that x = (x1, x2, x3) is in the range of σ1 if and only if 0 ≤ x3 ≤ x2 ≤ x1 ≤ 1. Show
that the ranges of σ1, . . . , σ6 have disjoint interiors and that their union covers I
3
. (Compare
with Exercise 10.13; note that 3! = 6.)
10.19. Let J
2 and J
3 be as in Exercise 10.17 and 10.18. Define
B01(u, v) = (0, u, v), B11(u, v) = (1, u, v),
B02(u, v) = (u, 0, v), B12(u, v) = (u, 1, v),
B03(u, v) = (u, v, 0), B13(u, v) = (u, v, 1).
These are affine, and map R2
into R3
.
Put βri = Bri(J
2
), for r = 0, 1, i = 1, 2, 3. Each βri is an affine-oriented 2-chain. (See Sec.
10.30.) Verify that
∂J3 =
X3
i=1
(−1)
i
(β0i − β1i),
in agreement with Exercise 10.18.
10.20. State conditions under which the formula
Z
Φ
f dω =
Z
∂Φ
fω −
Z
Φ
(df) ∧ ω
is valid, and show that it generalizes the formula for integration by parts.
Hint: d(fω) = (df) ∧ ω + f dω.
10.21. As in Example 10.36, consider the 1-form
η =
x dy − y dx
x
2 + y2
in R2 − {0}.
(a) Carry out the computation that leads to formula (10.113) and prove that dη = 0.
(b) Let γ(t) = (r cos t, r sin t), for some r > 0, and let Γ be a C
2
-curve in R2 − {0}, with
parameter interval [0, 2π], with Γ (0) = Γ (2π), such that the intervals [γ(t), Γ (t)] do not
contain 0 for any t ∈ [0, 2π]. Prove that
Z
Γ
η = 2π.
Hint: For 0 ≤ t ≤ 2π, 0 ≤ u ≤ 1, define
Φ(t, u) = (1 − u)Γ (t) + uγ(t).
Then Φ is a 2-surface in R2 − {0} whose parameter domain is the indicated rectangle.
Because of cancellations (as in Example 10.32),
∂Φ = Γ − γ.EXERCISES 277
Use Stokes’ theorem to deduce that
Z
Γ
η =
Z
γ
η
because dη = 0.
(c) Take Γ (t) = (a cos t, b sin t) where a > 0, b > 0 are fixed. Use part (b) to show that
Z 2π
0
ab
a2 cos2 t + b2 sin2
t
dt = 2π.
(d) Show that
η = d

arctan
y
x

in any convex open set in which x ̸= 0, and that
η = d

− arctan
x
y

in any convex open set in which y ̸= 0.
Explain why this justifies the notation η = dθ, in spite of the fact that η is not exact in
R2 − {0}.
(e) Show that (b) can be derived from (d).
(f) If Γ is any closed C
1
-curve in R2 − {0}, prove that
1
2π Z
Γ
η = Ind(Γ ).
(See Exercise 8.23 for the definition of the index of a curve.)
10.22. As in Example 10.37, define ζ in R3 − {0}
ζ =
x dy ∧ dz + y dz ∧ dx + z dx ∧ dy
r
3
where r = (x
2 + y
2 + z
2
)
1/2
, let D be the rectangle given by 0 ≤ u ≤ π, 0 ≤ v ≤ 2π, and let
Σ be the 2-surface in R3
, with parameter domain D, given by
x = sin u cos v, y = sin u sin v, z = cos u.
(a) Prove that dζ = 0 in R3 − {0}.
(b) Let S denote the restriction of Σ to a parameter domain E ⊂ D. Prove that
Z
S
ζ =
Z
E
sin u du dv = A(S),
where A denotes area, as in Theorem 10.43. Note that this contains (10.115) as a special
case.
(c) Suppose g, h1, h2, h3, are C
2
-functions on [0, 1], g > 0. Let (x, y, z) = Φ(s, t) define a
2-surface Φ, with parameter domain I
2
, by
x = g(t)h1(s), y = g(t)h2(s), z = g(t)h3(s).
Prove that
Z
Φ
ζ = 0,
directly from (10.35).
Note the shape of range Φ: For fixed s, Φ(s, t) runs over an interval on a line
through 0. The range of Φ thus lies in a “cone” with vertex at the origin.EXERCISES 278
(d) Let E be a closed rectangle in D with edges parallel to those of D. Suppose f ∈ C
2
(D),
f > 0. Let Ω be the 2-surface with a parameter domain E, defined by
Ω(u, v) = f(u, v)Σ(u, v).
Define S as in (b) and prove that
Z
Ω
ζ =
Z
S
ζ = A(S).
(Since S is the “radial projection” of Ω into the unit sphere, this result makes it reason￾able to call R
Ω ζ the “solid angle” subtended by the range of Ω at the origin.)
Hint: Consider the 3-surface Ψ given by
Ψ(t, u, v) = [1 − t + tf(u, v)]Σ(u, v),
where (u, v) ∈ E, 0 ≤ t ≤ 1. For fixed v, the mapping (t, u) → Ψ(t, u, v) is a 2-surface
Φ to which (c) can be applied to show that R
Φ ζ = 0. The same thing holds when u is
fixed. By (a) and Stokes’ theorem,
Z
∂Ψ
ζ =
Z
Ψ
dζ = 0.
(e) Put λ = −(z/r)η, where
η =
x dy − y dx
x
2 + y2
,
as in Exercise 10.21. Then λ is a 1-form in the open set V ⊂ R3
in which x
2 + y
2 > 0.
Show that ζ is exact in V by showing that
ζ = dλ.
(f) Derive (d) from (e), without using (c).
Hint: To begin with, assume 0 < u < π on E. By (e),
Z
Ω
ζ =
Z
∂Ω
λ and Z
S
ζ =
Z
∂S
λ.
Show that the two integrals of λ are equal, by using part (d) of Exercise 10.21, and by
noting that z/r is the same as Σ(u, v) as at Ω(u, v).
(g) Is ζ exact in the complement of every line through the origin?
10.23. Fix n. Define rk = (x
2
1 + · · · + x
2
k
)
1/2
for 1 ≤ k ≤ n, let Ek be the set of all x ∈ Rn at
which rk > 0 and let ωk be the (k − 1)-form defined in Ek by
ωk = (rk)
−kXk
i=1
(−1)
i−1
xi dx1 ∧ · · · ∧ dxi−1 ∧ dxi+1 ∧ · · · ∧ dxk.
Note that ω2 = η, ω3 = ζ, in the terminology of Exercise 10.21 and 10.22. Note also that
E1 ⊂ E2 ⊂ · · · ⊂ En = Rn − {0}.
(a) Prove that dωk = 0 in Ek.
(b) For k = 2, . . . , n, prove that ωk is exact in Ek−1 by showing that
ωk = d(fkωk−1) = (dfk) ∧ ωk−1,
where fk(x) = (−1)
kgk(xk/rk) and
gk(t) = Z t
−1
(1 − s
2
)
(k−3)/2 ds (−1 < t < 1).EXERCISES 279
Hint: fk satisfies the differential equations
x · (∇fk)(x) = 0
and
(Dkfk)(x) = (−1)
k(rk−1)
k−1
(rk)
k
.
(c) Is ωn exact in En?
(d) Note that (b) is a generalization of part (e) of Exercise 10.22. Try to extend some of the
other assertions of Exercise 10.21 and 10.22 to ωn, for arbitrary n.
10.24. Let ω = Σai(x) dxi be a 1-form of class C
2
in a convex open set E ⊂ Rn. Assume
dω = 0 and prove that ω is exact in E, by completing the following outline:
Fix p ∈ E. Define
f(x) = Z
[p,x]
ω (x ∈ E).
Apply Stokes’ theorem to affine-oriented 2-simplexes [p, x, y] in E. Deduce that
f(y) − f(x) = Xn
i=1
(yi − xi)
Z 1
0
ai((1 − t)x + ty) dt
for x ∈ E, y ∈ E. Hence (Dif)(x) = ai(x).
10.25. Assume that ω is a 1-form in an open set E ⊂ Rn such that
Z
γ
ω = 0
for every closed curve γ in E of class C
1
. Prove that ω is exact in E, by imitating part of the
argument sketched in Exercise 10.24.
10.26. Assume ω is a 1-form in R3 − {0} of class C
1
such that dω = 0. Prove that ω is exact
in R3 − {0}. Hint: Every closed continuously differentiable curve in R3 − {0} is the boundary
of the 2-surface in R3 − {0}. Apply Stokes’ theorem and Exercise 10.25.
10.27. Let E be an open ball 3-cell in R3 with edges parallel to the coordinate axes. Suppose
(a, b, c) ∈ E, fi ∈ C
1
(E) for i = 1, 2, 3,
ω = f1 dy ∧ dz + f2 dz ∧ dx + f3 dx ∧ dy,
and assume that dω = 0 in E. Define
λ = g1 dx + g2 dy
where
g1(x, y, z) = Z z
c
f2(x, y, s) ds −
Z y
b
f3(x, t, c) dt
g2(x, y, z) = − Z z
c
f1(x, y, s) ds,
for (x, y, z) ∈ E. Prove that dλ = ω in E.
Evaluate these integrals when ω = ζ and thus find the form λ that occurs in part (e) of
Exercise 10.22.EXERCISES 280
10.28. Fix b > a > 0, define
Φ(r, θ) = (r cos θ, r sin θ)
for a ≤ r ≤ b, 0 ≤ θ ≤ 2π. (The range of Φ is an annulus in R2
.) Put ω = x
3 dy, and
compute both
Z
Φ
dω and Z
∂Φ
ω
to verify that they are equal.
10.29. Prove the existence of a function α with the properties needed in the proof of Theo￾rem 10.38, and prove that the resulting function F is of class C
1
. (Both assertions become
trivial if E is an open cell or an open ball, since α can then be taken to be a constant. Refer to
Theorem 9.42.)
10.30. If N is the vector given by (10.135), prove that
det


α1 β1 α2β3 − α3β2
α2 β2 α3β1 − α1β3
α3 β3 α1β2 − α2β1

 = |N|
2
.
Also, verify Eq. (10.137).
10.31. Let E ⊂ R3 be open, suppose g ∈ C
2
(E), h ∈ C
2
(E), and consider the vector field
F = g∇h.
(a) Prove that
∇ · F = g∇2h + (∇g) · (∇h)
where ∇2h = ∇ · (∇h) = Σ∂2h/∂x2
i
is the so-called “Laplacian” of h.
(b) If Ω is a closed subset of E with positively oriented boundary ∂Ω (as in Theorem 10.51),
prove that
Z
Ω
[g∇2h + (∇g) · (∇h)] dV =
Z
∂Ω
g
∂h
∂n dA
where (as is customary) we have written ∂h/∂n in place of (∇h) · n. (Thus ∂h/∂n is
the directional derivative of h in the direction of the outward normal to ∂Ω, the so￾called normal derivative of h.) Interchange g and h and subtract the resulting formula
from the first one to obtain
Z
Ω
(g∇2h − h∇2g) dV =
Z
∂Ω 
g
∂h
∂n − h
∂g
∂n 
dA.
These two formulas are usually called Green’s identities.
(c) Assume that h is harmonic in E; this means that ∇2h = 0. Take g = 1 and conclude
that
Z
∂Ω
∂h
∂n dA = 0.
Take g = h and conclude that h = 0 in Ω if h = 0 on ∂Ω.
(d) Show that Green’s identities are also valid in R2
.
10.32. Fix δ, 0 < δ < 1. Let D be the set of all (θ, t) ∈ R2
such that 0 ≤ θ ≤ π, −δ ≤ t ≤ δ.
Let Φ be the 2-surface in R3
, with the parameter domain D, given by
x = (1 − t sin θ) cos 2θ
y = (1 − t sin θ) sin 2θ
z = t cos θ
where (x, y, z) = Φ(θ, t). Note that Φ(π, t) = Φ(0, −t), and that Φ is one-to-one on the rest of
D.EXERCISES 281
The range of M = Φ(D) of Φ is known as a M¨obius band. It is the simplest example of a
nonorientable surface.
Prove the various assertions made in the following description: Put p1 = (0, −δ), p2 =
(π, −δ), p3 = (π, δ), p4 = (0, δ), p5 = p1. Put γi = [pi, pi+1], i = 1, . . . , 4, and put Γi = Φ ◦ γi.
Then
∂Φ = Γ1 + Γ2 + Γ3 + Γ4.
Put a = (1, 0, −δ), b = (1, 0, δ). Then
Φ(p1) = Φ(p3) = a, Φ(p2) = Φ(p4) = b,
and ∂Φ can be described as follows.
• Γ1 spirals up from a to b; its projection into the (x, y)-plane has winding number +1
around the origin. (See Exercise 8.23.)
• Γ2 = [b, a].
• Γ3 spirals up from a to b; its projection into the (x, y) plane has winding number −1
around the origin.
• Γ4 = [b, a].
Thus ∂Φ = Γ1 + Γ3 + 2Γ2.
If we go from a to b along Γ1 and continue along the “edge” of M until we return to a,
the curve traced out is
Γ = Γ1 − Γ3,
which may also be represented on the parameter interval [0, 2π] by the equations
x = (1 + δ sin θ) cos 2θ
y = (1 + δ sin θ) sin 2θ
z = −δ cos θ.
It should be emphasized that Γ ̸= ∂Φ: Let η be the 1-form discussed in Exercises 10.21
and 10.22. Since dη = 0, Stokes’ theorem shows that
Z
∂Φ
η = 0.
But although Γ is the “geometric” boundary of M, we have
Z
Γ
η = 4π.
In order to avoid this possible source of confusion, Stokes’ formula (Theorem 10.50) is
frequently stated only for orientable surfaces Φ.Chapter 11
THE LEBESGUE THEORY
It is the purpose of this chapter to present the fundamental concepts of the Lebesgue
theory of measure and integration and to prove some of the crucial theorems in a
rather general setting, without obscuring the main lines of development by a mass
of comparatively trivial detail. Therefore proofs are only sketched in some cases,
and some of the easier propositions are stated without proof. However, the reader
who has become familiar with the techniques used in the preceding chapters will
certainly find no difficulty in supplying the missing steps.
The theory of the Lebesgue integral can be developed in several distinct ways.
Only one of these methods will be discussed here. For alternative procedures we
refer to the more specialized treatises on integration listed in the Bibliography.
SET FUNCTIONS
If A and B are any two sets, we write A − B for the set of all elements x such that
x ∈ A, x ∈/ B. The notation A − B does not imply that B ⊂ A. We denote the empty
set by ∅ and say that A and B are disjoint if A ∩ B = ∅.
11.1 Definition. A family R of sets is called a ring if A ∈ R and B ∈ R implies
(11.1) A ∪ B ∈ R, A − B ∈ R.
Since A ∩ B = A − (A − B), we also have A ∩ B ∈ R if R is a ring.
A ring is called a σ-ring if
(11.2) [∞
n=1
An ∈ R
282SET FUNCTIONS 283
whenever An ∈ R (n = 1, 2, 3, . . .). Since
\∞
n=1
An = A1 −
[∞
n=1
(A1 − An),
we also have
\∞
n=1
An ∈ R
if R is a σ-ring.
11.2 Definition. We say that ϕ is a set function defined on R if ϕ assigns to ev￾ery A ∈ R a number ϕ(A) of the extended real number system. ϕ is additive if
A ∩ B = ∅ implies
(11.3) ϕ(A ∪ B) = ϕ(A) + ϕ(B),
and ϕ is countably additive if Ai ∩ Aj = ∅ (i ̸= j) implies
(11.4) ϕ
 
[∞
n=1
An
!
=
X∞
n=1
ϕ(An).
We shall always assume that the range of ϕ does not contain both +∞ and −∞;
if it did, the right side of (11.3) could become meaningless. Also, we exclude set
functions whose only value is +∞ or −∞.
It is interesting to note that the left side of (11.4) is independent of the order
in which the An’s are arranged. Hence the rearrangement theorem shows that the
right side of (11.4) converges absolutely if it converges at all; if it does not converge,
the partial sums tend to +∞ or to −∞.
If ϕ is additive, the following properties are easily verified:
ϕ(∅) = ∅,(11.5)
(11.6) ϕ(A1 ∪ · · · ∪ An) = ϕ(A1) + · · · + ϕ(An)
if Ai ∩ Aj = ∅ whenever i ̸= j.
(11.7) ϕ(A1 ∪ A2) + ϕ(A1 ∩ A2) = ϕ(A1) + ϕ(A2).
If ϕ(A) ≥ 0 for all A and A1 ∪ A2, then
(11.8) ϕ(A1) ≤ ϕ(A2).
Because of (11.8), nonnegative additive set functions are often called mono￾tonic.
(11.9) ϕ(A − B) = ϕ(A) − ϕ(B)CONSTRUCTION OF THE LEBESGUE MEASURE 284
if B ⊂ A and |ϕ(B)| < +∞.
11.3 Theorem. Suppose ϕ is countably additive on a ring R. Suppose An ∈ R (n =
1, 2, 3, . . .), A1 ⊂ A2 ⊂ A3 ⊂ · · · , A ∈ R, and
A =
[∞
n=1
An.
Then, as n → ∞,
ϕ(An) → ϕ(A).
Proof. Put B1 = A1 and
Bn = An − An−1 (n = 2, 3, . . .).
Then Bi ∩ Bj = ∅ for i ̸= j, An = B1 ∪ · · · ∪ Bn, and A =
S
Bn. Hence
ϕ(An) = Xn
i=1
ϕ(Bi
)
and
ϕ(A) = X∞
i=1
ϕ(Bi
).
CONSTRUCTION OF THE LEBESGUE MEASURE
11.4 Definition. Let Rp denote p-dimensional euclidean space. By an interval in
Rp, we mean the set of points x = (x1, . . . , xp) such that
(11.10) ai ≤ xi ≤ bi
(i = 1, . . . , p),
or the set of points which is characterized by (11.10) with any or all of the ≤ signs
replaced by <. The possibility that ai = bi
for any value of i is not ruled out; in
particular, the empty set is included among intervals.
If A is the union of a finite number of intervals, A is said to be an elementary set.
If I is an interval, we define
m(I) = Y
p
i=1
(bi − ai
),
no matter whether equality is included or excluded in any of the inequalities (11.10).
If A = I1 ∪ · · · ∪ In, and if these intervals are pairwise disjoint, we set
(11.11) m(A) = m(I1) + · · · + m(In).
We let E denote the family of all elementary subsets of Rp.CONSTRUCTION OF THE LEBESGUE MEASURE 285
At this point, the following properties should be verified:
(11.12) E is a ring but not a σ-ring.
(11.13) If A ∈ E , then A is the union of a finite number of disjoint intervals.
(11.14) If A ∈ E , m(A) is well defined by (11.11); that is, if two different decompo￾sitions of A into disjoint intervals are used, each gives rise to the same value
of m(A).
(11.15) m is additive on E .
Note that if p = 1, 2, 3, then m is length, area, and volume, respectively.
11.5 Definition. A nonnegative additive set function ϕ defined on E is said to be
regular if the following is true: To every A ∈ E and to every ε > 0, there exists sets
F ∈ E , G ∈ E such that F is closed, G is open, F ⊂ A ⊂ G, and
(11.16) ϕ(G) − ε ≤ ϕ(A) ≤ ϕ(F) + ε.
11.6 Examples.
(a) The set function m is regular.
If A is an interval, it is trivial that the requirements of Definition 11.5 are
satisfied. The general case follows from (11.13).
(b) Take Rp = R1 and let α be a monotonically increasing function defined for
all real x. Put
µ([a, b)) = α(b−) − α(a−),
µ([a, b]) = α(b+) − α(a−),
µ((a, b]) = α(b+) − α(a+),
µ((a, b)) = α(b−) − α(a+).
Here [a, b) is the set a ≤ x < b, etc. Because of the possible discontinuities
of α, these cases have to be distinguished. If µ is defined for elementary sets
as in (11.11), µ is regular on E . The proof is just like that of (a).
Our next objective is to show that every regular set function on E can be ex￾tended to a countably additive set function on a σ-ring which contains E .
11.7 Definition. Let µ be additive, regular, nonnegative, and finite on E . Consider
countable coverings of any set E ⊂ Rp by open elementary sets An:
E ⊂
[∞
n=1
An.
Define
(11.17) µ
∗
(E) = inf X∞
n=1
µ(An),CONSTRUCTION OF THE LEBESGUE MEASURE 286
the inf being taken over all countable coverings of E by open elementary sets. µ
∗
(E)
is called the outer measure of E, corresponding to µ.
It is clear that µ
∗
(E) ≥ 0 for all E and that
(11.18) µ
∗
(E1) ≤ µ
∗
(E2)
if E1 ⊂ E2.
11.8 Theorem.
(a) For every A ∈ E , µ
∗
(A) = µ(A).
(b) If E ⊂
S∞
n=1 En, then
(11.19) µ
∗
(E) ≤
X∞
n=1
µ
∗
(En).
Note that (a) asserts that µ
∗
is an extension of µ from E to the family of all
subsets of Rp. The property (11.19) is called subadditivity.
Proof. Choose A ∈ E and ε > 0.
The regularity of µ shows that A is contained in an open elementary set G such
that µ(G) ≤ µ(A) + ε. Since µ
∗
(A) ≤ µ(G) and since ε was arbitrary, we have
(11.20) µ
∗
(A) ≤ µ(A).
The definition of µ
∗
shows that there is a countable collection of open elemen￾tary sets {An} whose union contains A, such that
X∞
n=1
µ(An) ≤ µ
∗
(A) + ε.
The regularity of µ shows that A contains a closed elementary set F such that
µ(F) ≥ µ(A) − ε; since F is compact, we have
F ⊂ A1 ∪ · · · ∪ AN
for some N. Hence
µ(A) ≤ µ(F) + ε ≤ µ(A1 ∪ · · · ∪ AN) + ε ≤
X
N
n=1
µ(An) + ε ≤ µ
∗
(A) + 2ε.
In conjunction with (11.20), this proves (a).
Next, suppose E =
S
En and assume that µ
∗
(En) < +∞ for all n. Given ε > 0,CONSTRUCTION OF THE LEBESGUE MEASURE 287
there are coverings {An,k}, k = 1, 2, 3, . . . , of En by open elementary sets such that
(11.21) X∞
k=1
µ(An,k) ≤ µ
∗
(En) + 2
−nε.
Then
µ
∗
(E) ≤
X∞
n=1
X∞
k=1
µ(An,k) ≤
X∞
n=1
µ
∗
(En) + ε,
and (11.19) follows. In the excluded case, i.e., if µ
∗
(En) = +∞ for some n, (11.19)
is of course trivial.
11.9 Definition. For any A ⊂ Rp, B ⊂ Rp, we define
S(A, B) = (A − B) ∪ (B − A),(11.22)
d(A, B) = µ
∗
(S(A, B)).(11.23)
We write An → A if
lim n→∞
d(A, An) = 0.
If there is a sequence (An) of elementary sets such that An → A, we say that
A is finitely µ-measurable and write A ∈ MF(µ). If A is the union of a countable
collection of finitely µ-measurable sets, we say that A is µ-measurable and write
A ∈ M(µ).
S(A, B) is the so-called “symmetric difference” of A and B. We shall see that
d(A, B) is essentially a distance function.
The following theorem will enable us to obtain the desired extension of µ.
11.10 Theorem. M(µ) is a σ-ring and µ
∗
is countably additive on M(µ).
Before we turn to the proof of this theorem, we develop some of the properties
of S(A, B) and d(A, B). We have
S(A, B) = S(B, A), S(A, A) = 0.(11.24)
S(A, B) ⊂ S(A, C) ∪ S(C, B).(11.25)
S(A1 ∪ A2, B1 ∪ B2)
S(A1 ∩ A2, B1 ∩ B2)
S(A1 − A2, B1 − B2)



⊂ S(A1, B1) ∪ S(A1, B2).(11.26)
(11.24) is clear and (11.25) follows from
(A − B) ⊂ (A − C) ∪ (C − B), (B − A) ⊂ (C − A) ∪ (B − C).
The first formula of (11.26) is obtained from
(A1 ∪ A2) − (B1 ∪ B2) ⊂ (A1 − B1) ∪ (A2 − B2).CONSTRUCTION OF THE LEBESGUE MEASURE 288
Next, writing E
c
for the complement of E, we have
S(A1 ∩ A2, B1 ∩ B2) = S(A
c
1 ∪ A
c
2
, B
c
1 ∪ B
c
2
)
⊂ S(A
c
1
, B
c
1
) ∪ S(A
c
2
, B
c
2
) = S(A1, B1) ∪ S(A2, B2);
the last formula of (11.26) is obtained if we note that
A1 − A2 = A1 ∩ A
c
2
.
by (11.23), (11.19), and (11.18), these properties of S(A, B) imply
d(A, B) = d(B, A), d(A, A) = 0,(11.27)
d(A, B) ≤ d(A, C) + d(C, B),(11.28)
d(A1 ∪ A2, B1 ∪ B2)
d(A1 ∩ A2, B1 ∩ B2)
d(A1 − A2, B1 − B2)



≤ d(A1, B1) + d(A2, B2).(11.29)
The relations (11.27) and (11.28) show that d(A, B) satisfies the requirements
of Definition 2.15, except that d(A, B) = 0 does not imply A = B. For instance, if
µ = m, A is countable, and B is empty, we have
d(A, B) = m∗
(A) = 0;
to see this, cover the nth point of A by an interval In such that
m(In) < 2−nε.
However, if we define two sets A and B to be equivalent, provided
d(A, B) = 0,
we divide the subsets of Rp into equivalence classes and d(A, B) makes the set
of these equivalence classes into a metric space. MF(µ) is then obtained as the
closure of E . This interpretation is not essential for the proof, but it explains the
underlying idea.
We need one more property of d(A, B), namely,
(11.30) |µ
∗
(A) − µ
∗
(B)| ≤ d(A, B),
if at least one of µ
∗
(A), µ
∗
(B) is finite. For suppose 0 ≤ µ
∗
(B) ≤ µ
∗
(A). Then
(11.28) showos that
d(A, ∅) ≤ d(A, B) + d(B, ∅),
that is,
µ
∗
(A) ≤ d(A, B) + µ
∗
(B).CONSTRUCTION OF THE LEBESGUE MEASURE 289
Since µ
∗
(B) is finite, it follows that
µ
∗
(A) − µ
∗
(B) ≤ d(A, B).
Proof of Theorem 11.10. Suppose A ∈ MF(µ), B ∈ MF(µ). Choose (An), (Bn) such
that An ∈ E , Bn ∈ E , An → A, Bn → B. Then (11.29) and (11.30) show that
An ∪ Bn → A ∪ B,(11.31)
An ∩ Bn → A ∩ B,(11.32)
An − Bn → A − B,(11.33)
µ
∗
(An) → µ
∗
(A),(11.34)
and µ
∗
(A) < +∞ since d(An, A) → 0. By (11.31) and (11.33), MF(µ) is a ring. By
(11.7),
µ(An) + µ(Bn) = µ(An ∪ Bn) + µ(An ∩ Bn).
Letting n → ∞, we obtain, by (11.34) and Theorem 11.8(a),
µ
∗
(A) + µ
∗
(B) = µ
∗
(A ∪ B) + µ
∗
(A ∩ B).
If A ∩ B = ∅, then µ
∗
(A ∩ B) = 0. It follows that µ
∗
is additive on MF(µ).
Now let A ∈ M(µ). Then A can be represented as the union of a countable
collection of disjoint sets of MF(µ). For if A =
S
A′
n, with A′
n ∈ MF(µ), write
A1 = A′
1
and
An = (A
′
1 ∪ · · · ∪ A
′
n) − (A
′
1 ∪ · · · ∪ A
′
n−1
) (n = 2, 3, 4, . . .).
Then
(11.35) A =
[∞
n=1
An
is the required representation. By (11.19),
(11.36) µ
∗
(A) ≤
X∞
n=1
µ
∗
(An).
On the other hand, A ⊃ A1 ∪ · · · ∪ An; by the additivity of µ
∗ on MF(µ), we
obtain
(11.37) µ
∗
(A) ≥ µ
∗
(A1 ∪ · · · ∪ An) = µ
∗
(A1) + · · · + µ
∗
(An).
Equations (11.36) and (11.37) imply
(11.38) µ
∗
(A) = X∞
n=1
µ
∗
(An).CONSTRUCTION OF THE LEBESGUE MEASURE 290
Suppose µ
∗
(A) is finite. Put Bn = A1 ∪ · · · ∪ An. Then (11.38) shows that
d(A, Bn) = µ
∗
 
[∞
i=n+1
Ai
!
=
X∞
i=n+1
µ
∗
(Ai
) → 0
as n → ∞. Hence Bn → A; since Bn ∈ MF(µ), it is easily seen that A ∈ MF(µ).
We have thus shown that A ∈ MF(µ) if A ∈ M(µ) and µ
∗
(A) < +∞.
It is now clear that µ
∗
is countably additive on M(µ). For if
A =
[∞
n=1
An,
where {An} is a countable collection of disjoint sets of M(µ), we have shown that
(11.38) holds if µ
∗
(An) < +∞ for every n, and in the other case (11.38) is trivial.
Finally, we have to show that M(µ) is a σ-ring. If An ∈ M(µ), n = 1, 2, 3, . . . , it
is clear that S
An ∈ M(µ) (Theorem 2.12). Suppose A ∈ M(µ), B ∈ M(µ), and
A =
[∞
n=1
An, B =
[∞
n=1
Bn,
where An, Bn ∈ MF(µ). Then the identity
An ∩ B =
[∞
i=1
(An ∩ Bi
)
shows that An ∩ B ∈ M(µ); since
µ
∗
(An ∩ B) ≤ µ
∗
(An) < ∞,
An ∩ B ∈ MF(µ). Hence An − B ∈ MF(µ), and A − B ∈ M(µ) since A − B =
S∞
n=1
(An − B).
We now replace µ
∗
(A) by µ(A) if A ∈ M(µ). Thus µ, originally only defined
on E , is extended to a countably additive set function on the σ-ring M(µ). This
extended set function is called a measure. The special case µ = m is called the
Lebesgue measure on Rp.
11.11 Remarks.
(a) If A is open, then A ∈ M(µ). For every open set in Rp is the union of a
countable collection of open intervals. To see this, it is sufficient to construct a
countable base whose members are open intervals. By taking complements,
it follows that every closed set is in M(µ).
(b) If A ∈ M(µ) and ε > 0, there exist sets F and G such that
F ⊂ A ⊂ G,MEASURE SPACES 291
F is closed, G is open, and
(11.39) µ(G − A) < ε, µ(A − F) < ε.
The first inequality holds since µ
∗ was defined by means of coverings by
open elementary sets. The second inequality then follows by taking comple￾ments.
(c) We say that E is a Borel set if E can be obtained by a countable number of op￾erations, starting from open sets, each operation consisting in taking unions,
intersections, or complements. The collection B of all Borel sets in Rp is a
σ-ring; in fact, it is the smallest sigma ring which contains all open sets. By
(a), E ∈ M(µ) if E ∈ B.
(d) If A ∈ M(µ), there exist Borel sets F and G such that F ⊂ A ⊂ G, and
(11.40) µ(G − A) = µ(A − F) = 0.
This follows from (b) if we take ε = 1/n and let n → ∞.
Since A = F ∪ (A − F) we see that every M(µ) is the union of a Borel set
and a set of measure zero.
The Borel sets are µ-measurable for every µ. But the sets of measure zero
[that is, the sets E for which µ
∗
(E) = 0] may be different for different µ’s.
(e) For every µ, the sets of measure zero form a σ-ring.
(f) In the case of the Lebesgue measure, every countable set has measure zero.
But there are uncountable sets of measure zero. The Cantor set may be taken
as an example: Using the notation of Theorem 2.44, it is easily seen that
m(En) = 
2
3
n
(n = 1, 2, 3, . . .);
since P =
T
En, P ⊂ En for every n so that m(P) = 0.
MEASURE SPACES
11.12 Definition. Suppose X is a set, not necessarily a subset of a euclidean space
or, indeed, of any metric space. X is said to be a measure space if there exists a σ-ring
M of subsets of X (which are called measurable sets) and a nonnegative countably
additive set function µ (which is called a measure), defined on M. If, in addition,
X ∈ M, then X is said to be a measurable space.
1
For instance, we can take X = Rp, M the collection of all Lebesgue-measurable
subsets of Rp, and µ the Lebesgue measure.
Or, let X be the set of all positive integers, M be the collection of all subsets of
X, and µ(E) the number of elements of E.
1The definition that Rudin gives here is very much at-odds with everybody else. Even he defines this
term differently later, in his Real and Complex Analysis text.MEASURABLE FUNCTIONS 292
Another example is provided by probability theory, where events may be con￾sidered as sets, and the probability of the occurrence of events is an additive (or
countably additive) set function.
In the following sections we shall always deal with measurable spaces. It
should be emphasized that the integration theory which we shall soon discuss
would not become simpler in any respect if we sacrificed the generality we have
now attained and restricted ourselves to Lebesgue measure, say, on an interval
of the real line. In fact, the essential features of the theory are brought out with
much greater clarity in the more general situation, where it is seen that everything
depends only on the countable additivity of µ on a σ-ring.
It will be convenient to introduce the notation
(11.41) {x | P}
for the set of all elements x which have the property P.
MEASURABLE FUNCTIONS
11.13 Definition. Let f be a function defined on the measurable space X with val￾ues in the extended real number system. The function f is said to be measurable if
the set
(11.42) {x | f(x) > a}
is measurable for every real a.
11.14 Example. If X = Rp and M = M(µ) as defined in Definition 11.9, then every
continuous f is measurable, since then (11.42) is an open set.
11.15 Theorem. Each of the following four conditions implies the other three:
(11.43) {x | f(x) > a} is measurable for every real a.
(11.44) {x | f(x) ≥ a} is measurable for every real a.
(11.45) {x | f(x) < a} is measurable for every real a.
(11.46) {x | f(x) ≤ a} is measurable for every real a.
Proof. The relations
{x | f(x) ≥ a} =
\∞
n=1

x



f(x) > a −
1
n

,
{x | f(x) < a} = X − {x | f(x) ≥ a},
{x | f(x) ≤ a} =
\∞
n=1

x



f(x) < a +
1
n

,
{x | f(x) > a} = X − {x | f(x) ≤ a}MEASURABLE FUNCTIONS 293
show successively that (11.43) implies (11.44), (11.44) implies (11.45), (11.45) im￾plies (11.46), and (11.46) implies (11.43).
Hence any of these conditions may be used instead of (11.42) to define measur￾ability.
11.16 Theorem. If f is measurable, then |f| is measurable.
Proof. {x | |f(x)| < a} = {x | f(x) < a} ∪ {x | f(x) > −a}.
11.17 Theorem. Let (fn) be a sequence of measurable functions. For x ∈ X, put
g(x) = sup fn(x) (n = 1, 2, 3, . . .),
h(x) = lim sup
n→∞
fn(x).
Then g and h are measurable. The same is of course true of the inf and lim inf.
Proof.
{x | g(x) > a} =
[∞
n=1
{x | fn(x) > a},
h(x) = inf gm(x),
where gm(x) = sup fn(x) (n ≥ m).
Corollary.
(a) If f and g are measurable, then max(f, g) and min(f, g) are measurable. If
(11.47) f
+ = max(f, 0), f
− = − min(f, 0),
it follows, in particular, that f
+ and f
− are measurable.
(b) The limit of a convergent sequence of measurable functions is measurable.
11.18 Theorem. Let f and g be measurable real-valued functions defined on X, let F be
real and continuous on R2, and put
h(x) = F(f(x), g(x)) (x ∈ X).
Then h is measurable. In particular, f + g and fg are measurable.
Proof. Let
Ga = {(u, v) | F(u, v) > a}.
Then Ga is an open subset of R2 and we can write
Ga =
[∞
n=1
In,SIMPLE FUNCTIONS 294
where (In) is a sequence of open intervals:
In = {(u, v) | an < u < bn, cn < v < dn}.
Since
{x | an < f(x) < bn} = {x | f(x) > an} ∩ {x | f(x) < bn}
is measurable, it follows that the set
{x | (f(x), g(x)) ∈ In} = {x | an < f(x) < bn} ∩ {x | cn < g(x) < dn}
is measurable. Hence the same is true of
{x | h(x) > a} = {x | (f(x), g(x)) ∈ Ga}
=
[∞
n=1
{x | (f(x), g(x)) ∈ In}.
Summing up, we may say that all ordinary operations of analysis, including
limit operations, when applied to measurable functions, lead to measurable func￾tions; in other words, all functions that are ordinarily met with are measurable.
That this is, however, only a rough statement is shown by the following ex￾ample (based on Lebesgue measure, on the real line): If h(x) = f(g(x)), where f
is measurable and g is continuous, then h is not necessarily measurable. (For the
details, we refer to McShane [McS44], page 241).
The reader may have noticed that measure has not been mentioned in our dis￾cussion of measurable functions. In fact, the class of measurable functions on X
depends only on the σ-ring M (using the notation of Definition 11.12). For in￾stance, we may speak of Borel-measurable functions on Rp, that is, of functions f for
which
{x | f(x) > a}
is always a Borel set, without reference to any particular measure.
SIMPLE FUNCTIONS
11.19 Definition. Let s be a real-valued function defined on X. If the range of s is
finite, we say that s is a simple function.
Let E ⊂ X, and put
(11.48) KE(x) = 
1 (x ∈ E),
0 (x ∈/ E).
KE is called the characteristic function of E.INTEGRATION 295
Suppose the range of s consists of the distinct numbers c1, . . . , cn. Let
Ei = {x | s(x) = ci
} (i = 1, . . . , n).
Then
(11.49) s =
Xn
i=1
ciKEi
,
that is, every simple function is a finite linear combination of characteristic func￾tions. It is clear that s is measurable if and only if the sets E1, . . . , En are measur￾able.
It is of interest that every function can be approximated by simple functions:
11.20 Theorem. Let f be a real function on X. There exists a sequence (sn) of simple
functions such that sn(x) → f(x) as n → ∞, for every x ∈ X. If f is measurable, (sn)
may be chosen to be a sequence of measurable functions. If f ≥ 0, (sn) may be chosen to
be a monotonically increasing sequence.
Proof. If f ≥ 0, define
En,i =

x



i − 1
2n ≤ f(x) <
i
2n

, Fn = {x | f(x) ≥ n}
for n = 1, 2, 3, . . . , i = 1, 2, . . . , n · 2
n. Put
(11.50) sn =
n·2
Xn
i=1
i − 1
2n
KEn,i + nKFn
.
In the general case, let f = f
+ − f
− and apply the preceding construction to f
+ and
f
−.
It may be noted that the sequence (sn) given by (11.50) converges uniformly to
f if f is bounded.
INTEGRATION
We shall define integration on a measurable space X, in which M is the σ-ring of
measurable sets, and µ is the measure. The reader who wishes to visualize a more
concrete situation may think of X as the real line, or an interval, and of µ as the
Lebesgue measure m.
11.21 Definition. Suppose
(11.51) s(x) = Xn
i=1
ciKEi
(x) (x ∈ X, ci > 0)INTEGRATION 296
is measurable, and suppose E ∈ M. We define
(11.52) IE(s) = Xn
i=1
ciµ(E ∩ Ei
).
If f is measurable and nonnegative, we define
(11.53) Z
E
f dµ = sup IE(s),
where the sup is taken over all measurable simple functions s such that 0 ≤ s ≤ f.
The left member of (11.53) is called the Lebesgue integral of f, with respect to the
measure µ, over the set E. It should be noted that the integral may have the value
+∞.
It is easily verified that
(11.54) Z
E
s dµ = IE(s)
for every nonnegative simple measurable function s.
11.22 Definition. Let f be measurable and consider the two integrals
(11.55) Z
E
f
+ dµ,
Z
E
f
− dµ,
where f
+ and f
− are defined as in (11.47). If at least one of the integrals (11.55) is
finite, we define
(11.56) Z
E
f dµ =
Z
E
f
+ dµ −
Z
E
f
− dµ.
If both integrals in (11.55) are finite, then (11.56) is finite, and we say that f is
integrable (or summable) on E in the Lebesgue sense, with respect to µ; we write
f ∈ L (µ) on E. If µ = m, the usual notation is f ∈ L on E.
This terminology may be a little confusing: If (11.56) is +∞ or −∞, then the
integral of f over E is defined, although f is not integrable in the above sense of the
word; f is integrable on E if and only if its integral over E is finite.
We shall mainly be interested in integrable functions, although in some cases it
is desirable to deal with the more general situation.
11.23 Remarks. The following properties are evident
(a) If f is measurable and bounded on E, and if µ(E) < +∞, then f ∈ L (µ) on E.
(b) If a ≤ f(x) ≤ b for x ∈ E, and µ(E) < +∞, then
aµ(E) ≤
Z
E
f dµ ≤ bµ(E).INTEGRATION 297
(c) If f and g ∈ L (µ) on E, and if f(x) ≤ g(x) for x ∈ E, then
Z
E
f dµ ≤
Z
E
g dµ.
(d) If f ∈ L (µ) on E, then cf ∈ L (µ) on E for every finite constant c, and
Z
E
cf dµ = c
Z
E
f dµ.
(e) If µ(E) = 0 and f is measurable, then
Z
E
f dµ = 0.
(f) If f ∈ L (µ) on E, A ∈ M, and A ⊂ E, then f ∈ L (µ) on A.
11.24 Theorem.
(a) Suppose f is measurable and nonnegative on X. For A ∈ M, define
(11.57) ϕ(A) = Z
A
f dµ.
Then ϕ is countably additive on M.
(b) The same conclusion holds if f ∈ L (µ) on X.
Proof. It is clear that (b) follows from (a) if we write f = f
+ − f
− and apply (a) to
f
+ and f
−.
To prove (a), we have to show that
(11.58) ϕ(A) = X∞
n=1
ϕ(An)
if An ∈ M (n = 1, 2, 3, . . .), Ai ∩ Aj = 0 for i ̸= j, and A =
S∞
n=1 An.
If f is a characteristic function, then the countable additivity of ϕ is precisely
the same as the countable additivity of µ, since
Z
A
KE dµ = µ(A ∩ E).
If f is simple, then f is of the form (11.51), and the conclusion again holds.
In the general case, we have, for every measurable simple function s such that
0 ≤ s ≤ f,
Z
A
s dµ =
X∞
n=1
Z
An
s dµ ≤
X∞
n=1
ϕ(An).INTEGRATION 298
Therefore, by (11.53),
(11.59) ϕ(A) ≤
X∞
n=1
ϕ(An).
Now if ϕ(An) = +∞ for some n, (11.58) is trivial, since ϕ(A) ≥ ϕ(An). Sup￾pose ϕ(An) < +∞ for every n.
Given ε > 0, we can choose a measurable function s such that 0 ≤ s ≤ f, and
such that
(11.60) Z
A1
s dµ ≥
Z
A1
f dµ − ε,
Z
A2
s dµ ≥
Z
A2
f dµ − ε.
Hence
ϕ(A1 ∪ A2) ≥
Z
A1∪A2
s dµ =
Z
A1
s dµ +
Z
A2
s dµ ≥ ϕ(A1) + ϕ(A2) − 2ε,
so that
ϕ(A1 ∪ A2) ≥ ϕ(A1) + ϕ(A2).
It follows that we have, for every n,
(11.61) ϕ(A1 ∪ · · · ∪ An) ≥ ϕ(A1) + · · · + ϕ(An).
Since A ⊃ A1 ∪ · · · ∪ An, (11.61) implies
(11.62) ϕ(A) ≥
X∞
n=1
ϕ(An),
and (11.58) follows from (11.59) and (11.62).
Corollary. If A ∈ M, B ∈ M, B ⊂ A, and µ(A − B) = 0, then
Z
A
f dµ =
Z
B
f dµ.
Since A = B ∪ (A − B), this follows from Remark 11.23(e).
11.25 Remarks. The preceding corollary shows that sets of measure zero are neg￾ligible in integration.
Let us write f ∼ g on E if the set
{x | f(x) ̸= g(x)} ∩ E
has measure zero. Then f ∼ f; f ∼ g implies g ∼ f; and f ∼ g, g ∼ h implies f ∼ h.
That is, the relation ∼ is an equivalence relation.INTEGRATION 299
If f ∼ g on E, we clearly have
Z
A
f dµ =
Z
A
g dµ,
provided the integrals exist, for every measurable subset A of E.
If a property P holds for every x ∈ E − A, and if µ(A) = 0, it is customary
to say that P holds for almost all x ∈ E, or that P holds almost everywhere on E.
(This concept of “almost everywhere” depends of course on the particular measure
under consideration. In the literature, unless something is said to the contrary, it
usually refers to the Lebesgue measure.)
If f ∈ L (µ) on E, it is clear that f(x) must be finite almost everywhere on
E. In most cases, we therefore do not lose any generality if we assume the given
functions to be finite-valued from the outset.
11.26 Theorem. If f ∈ L (µ) on E, then |f| ∈ L (µ) on E, and
(11.63)




Z
E
f dµ




≤
Z
E
|f| dµ.
Proof. Write E = A ∪ B, where f(x) ≥ 0 on A and f(x) < 0 on B. By Theorem 11.24,
Z
E
|f| dµ =
Z
A
|f| dµ +
Z
B
|f| dµ =
Z
A
f
+ dµ +
Z
B
f
− dµ < ∞,
so that |f| ∈ L (µ). Since f ≤ |f| and −f ≤ |f|, we see that
Z
E
f dµ ≤
Z
E
|f| dµ, −
Z
E
f dµ ≤
Z
E
|f| dµ,
and (11.63) follows.
Since the integrability of f implies that of |f|, the Lebesgue integral is often
called an absolutely convergent integral. It is of course possible to define nonabso￾lutely convergent integrals, and in the treatment of some problems it is essential to
do so. But these integrals lack some of the most useful properties of the Lebesgue
integral and play a somewhat less important role in analysis.
11.27 Theorem. Suppose f is measurable on E, |f| ≤ g, and g ∈ L (µ) on E. Then
f ∈ L (µ) on E.
Proof. We have f
+ ≤ g and f
− ≤ g.
11.28 Theorem (Lebesgue’s Monotone Convergence Theorem). Suppose E ∈ M.
Let (fn) be a sequence of measurable functions such that
(11.64) 0 ≤ f1(x) ≤ f2(x) ≤ · · · (x ∈ E).INTEGRATION 300
Let f be defined by
(11.65) fn(x) → f(x) (x ∈ E)
as n → ∞. Then
(11.66) Z
E
fn dµ −−−−→ n→∞ Z
E
f dµ.
Proof. By (11.64), it is clear that, as n → ∞,
(11.67) Z
E
fn dµ → α
for some α; since R
fn ≤
R
f, we have
(11.68) α ≤
Z
E
f dµ.
Choose c such that 0 < c < 1 and let s be a simple measurable function such
that 0 ≤ s ≤ f. Put
En = {x | fn(x) ≥ cs(x)} (n = 1, 2, 3, . . .).
By (11.64), E1 ⊂ E2 ⊂ E3 ⊂ · · · ; by (11.65)
(11.69) E =
[∞
n=1
En.
For every n,
(11.70) Z
E
fn dµ ≥
Z
En
fn dµ ≥ c
Z
En
s dµ.
We let n → ∞ in (11.70). Since the integral is a countably additive set function
(Theorem 11.24), (11.69) shows that we may apply Theorem 11.3 to the last integral
in (11.70) and we obtain
(11.71) α ≥ c
Z
E
s dµ.
Letting c → 1, we see that
α ≥
Z
E
s dµ,
and (11.53) implies
(11.72) α ≥
Z
E
f dµ.INTEGRATION 301
The theorem follows from (11.67), (11.68), and (11.72).
11.29 Theorem. Suppose f = f1 +f2, where fi ∈ L (µ) on E (i = 1, 2). Then f ∈ L (µ)
on E, and
(11.73) Z
E
f dµ =
Z
E
f1 dµ +
Z
E
f2 dµ.
Proof. First, suppose f1 ≥ 0, f2 ≥ 0. If f1 and f2 are simple, (11.73) follows trivially
from (11.52) and (11.54). Otherwise, choose monotonically increasing sequences
(s
′
n), (s
′′
n) of nonnegative measurable simple functions which converge to f1, f2.
Theorem 11.20 shows that this is possible. Put sn = s
′
n + s
′′
n. Then
Z
E
sn dµ =
Z
E
s
′
n dµ +
Z
E
s
′′
n dµ,
and (11.73) follows if we let n → ∞ and appeal to Theorem 11.28.
Next, suppose f1 ≥ 0, f2 ≤ 0. Put
A = {x | f(x) ≥ 0}, B = {x | f(x) < 0}.
Then f, f1, and −f2 are nonnegative on A. Hence
(11.74) Z
A
f1 dµ =
Z
A
f dµ +
Z
A
(−f2) dµ =
Z
A
f dµ −
Z
A
f2 dµ.
Similarly, −f, f1, and −f2 are nonnegative on B, so that
Z
B
(−f2) dµ =
Z
B
f1 dµ +
Z
B
(−f) dµ,
or
(11.75) Z
B
f1 dµ =
Z
B
f dµ −
Z
B
f2 dµ,
and (11.73) follows if we add (11.74) and (11.75).
In the general case, E can be decomposed into four sets Ei on each of which
f1(x) and f2(x) are of constant sign. These two cases we have proved so far imply
Z
Ei
f dµ =
Z
Ei
f1 dµ +
Z
Ei
f2 dµ (i = 1, 2, 3, 4),
and (11.73) follows by adding these four equations.
We are now in a position to reformulate Theorem 11.28 for series.INTEGRATION 302
11.30 Theorem. Suppose E ∈ M. If (fn) is a sequence of nonnegative measurable func￾tions and
(11.76) f(x) = X∞
n=1
fn(x) (x ∈ E),
then
Z
E
f dµ =
X∞
n=1
Z
E
fn dµ.
Proof. The partial sums of (11.76) form a monotonically increasing sequence.
11.31 Theorem (Fatou’s Theorem). Suppose E ∈ M. If (fn) is a sequence of nonnega￾tive measurable functions and
f(x) = lim inf
n→∞
fn(x) (x ∈ E),
then
(11.77) Z
E
f dµ ≤ lim inf
n→∞ Z
E
fn dµ.
Strict inequality may hold in (11.77). An example is given in Exercise 11.5.
Proof. For n = 1, 2, 3, . . . and x ∈ E, put
gn(x) = inf fi
(x) (i ≥ n).
Then gn is measurable on E, and
0 ≤ g1(x) ≤ g2(x) ≤ · · · ,(11.78)
gn(x) ≤ fn(x),(11.79)
gn(x) → f(x) (n → ∞).(11.80)
By (11.78), (11.80), and Theorem 11.28,
(11.81) Z
E
gn dµ →
Z
E
f dµ,
so that (11.77) follows from (11.79) and (11.81).
11.32 Theorem (Lebesgue’s Dominated Convergence Theorem). Suppose E ∈ M.
Let (fn) be a sequence of measurable functions such that
(11.82) fn(x) → f(x) (x ∈ E)
as n → ∞. If there exists a function g ∈ L (µ) on E such that
(11.83) |fn(x)| ≤ g(x) (n = 1, 2, 3, . . . , x ∈ E),COMPARISON WITH THE RIEMANN INTEGRAL 303
then
(11.84) lim n→∞ Z
E
fn dµ =
Z
E
f dµ.
Because of (11.83), (fn) is said to be dominated by g, and we talk about dom￾inated convergence. By Remark 11.25, the conclusion is the same if (11.82) holds
almost everywhere on E.
Proof. First, (11.83) and Theorem 11.27 imply that fn ∈ L (µ) and f ∈ L (µ) on E.
Since fn + g ≥ 0, Fatou’s theorem shows that
Z
E
(f + g) dµ ≤ lim inf
n→∞ Z
E
(fn + g) dµ,
or
(11.85) Z
E
f dµ ≤ lim inf
n→∞ Z
E
fn dµ.
Since g − fn ≥ 0, we see similarly that
Z
E
(g − f) dµ ≤ lim inf
n→∞ Z
E
(g − fn) dµ,
so that
−
Z
E
f dµ ≤ lim inf
n→∞ 
−
Z
E
fn dµ

,
which is the same as
(11.86) Z
E
f dµ ≥ lim sup
n→∞
Z
E
f dµ.
The existence of the limit in (11.84) and the equality asserted by (11.84) now
follow from (11.85) and (11.86).
Corollary. If µ(E) < +∞, (fn) is uniformly bounded on E, and fn(x) → f(x) on E,
then (11.84) holds.
COMPARISON WITH THE RIEMANN INTEGRAL
Our next theorem will show that every function which is Riemann-integrable on an
interval is also Lebesgue-integrable, and that the Riemann-integrable functions are
subject to rather stringent continuity conditions. Quite apart from the fact that the
Lebesgue theory therefore enables us to integrate a much larger class of functions,
its greatest advantage lies perhaps in the ease with which many limit operations
can be handled; from this point of view, Lebesgue’s convergence theorems may
well be regarded as the core of the Lebesgue theory.COMPARISON WITH THE RIEMANN INTEGRAL 304
One of the difficulties which is encountered in the Riemann theory is that lim￾its of Riemann-integrable functions (or even continuous functions) may fail to be
Riemann-integrable. This difficulty is now almost eliminated, since limits of mea￾surable functions are always measurable.
Let the measure space X be the interval [a, b] of the real line, with µ = m (the
Lebesgue measure), and M be the family of Lebesgue-measurable subsets of [a, b].
Instead of
Z
X
f dm,
it is customary to use the familiar notation
Z b
a
f dx
for the Lebesgue integral of f over [a, b]. To distinguish Riemann integrals from
Lebesgue integrals, we shall now denote the former by
R
Z b
a
f dx.
11.33 Theorem.
(a) If f ∈ R on [a, b], then f ∈ L on [a, b], and
(11.87) Z b
a
f dx = R
Z b
a
f dx.
(b) Suppose f is bounded on [a, b]. Then f ∈ R on [a, b] if and only if f is continuous
almost everywhere on [a, b].
Proof. Suppose f is bounded. By Definition 6.1 and Theorem 6.4, there is a se￾quence (Pk) of partitions of [a, b] such that Pk+1 is a refinement of Pk, the distance
between adjacent points of Pk is less than 1/k, and
(11.88) lim
k→∞
L(Pk, f) = R
Z
f dx, lim
k→∞
U(Pk, f) = R
Z
f dx.
(In this proof, all integrals are taken over [a, b].)
If Pk = {x0, x1, . . . , xn}, with x0 = a, xn = b, define
Uk(a) = Lk(a) = f(a);
put Uk(x) = Mi and Lk(x) = mi
for xi−1 < x ≤ xi
, 1 ≤ i ≤ n, using the notation
introduced in Definition 6.1. Then
(11.89) L(Pk, f) = Z
Lk dx, U(Pk, f) = Z
Uk dx,COMPARISON WITH THE RIEMANN INTEGRAL 305
and
(11.90) L1(x) ≤ L2(x) ≤ · · · ≤ f(x) ≤ · · · ≤ U2(x) ≤ U1(x)
for all x ∈ [a, b], since Pk+1 refines Pk. By (11.90), there exist
(11.91) L(x) = lim
k→∞
Lk(x), U(x) = lim
k→∞
Uk(x).
Observe that L and U are bounded measurable functions on [a, b], that
(11.92) L(x) ≤ f(x) ≤ U(x) (a ≤ x ≤ b),
and that
(11.93) Z
L dx = R
Z
f dx,
Z
U dx = R
Z
f dx,
by (11.88), (11.90), and the monotone convergence theorem.
So far, nothing has been assumed about f except that f is a bounded real func￾tion on [a, b].
To complete the proof, note that f ∈ R if and only if its upper and lower Rie￾mann integrals are equal, hence if and only if
(11.94) Z
L dx =
Z
U dx;
Since L ≤ U, (11.94) happens if and only if L(x) = U(x) for almost all x ∈ [a, b]
(Exercise 11.1). In that case, (11.92) implies that
(11.95) L(x) = f(x) = U(x)
almost everywhere on [a, b], so that f is measurable, and (11.87) follows from
(11.93) and (11.95).
Furthermore, if x belongs to no Pk, it is quite easy to see that U(x) = L(x) if and
only if f is continuous at x. Since the union of the sets Pk is countable, its measure
is 0, and we conclude that f is continuous almost everywhere on [a, b] if and only
if L(x) = U(x) almost everywhere, hence (as we saw above) if and only if f ∈ R.
This completes the proof.
The familiar connection between integration and differentiation is to a large
degree carried over into the Lebesgue theory. If f ∈ L on [a, b] and
(11.96) F(x) = Zx
a
f dt (a ≤ x ≤ b),
then F
′
(x) = f(x) almost everywhere on [a, b].
Conversely, if F is differentiable at every point of [a, b] (“almost everywhere” isINTEGRATION OF COMPLEX FUNCTIONS 306
not good enough here!) and if F
′ ∈ L on [a, b], then
F(x) − F(a) = Zx
a
F
′
(t) dt (a ≤ x ≤ b).
For the proofs of these two theorems, we refer the reader to any of the works
on integration cited in the Bibliography.
INTEGRATION OF COMPLEX FUNCTIONS
Suppose f is a complex-valued function defined on a measure space X, and f =
u + iv, where u and v are real. We say that f is measurable if and only if both u and
v are measurable.
It is easy to verify that sums and products of complex measurable functions are
again measurable. Since
|f| = (u
2 + v
2
)
1/2
,
Theorem 11.18 shows that |f| is measurable for every complex measurable f.
Suppose µ is a measure on X, E is a measurable subset of X, and f is a complex
function on X. We say that f ∈ L (µ) on E provided that f is measurable and
(11.97) Z
E
|f| dµ < +∞,
and we define
Z
E
f dµ =
Z
E
u dµ + i
Z
E
v dµ
if (11.97) holds. Since |u| ≤ |f|, |v| ≤ |f|, and |f| ≤ |u| + |v|, it is clear that (11.97)
holds if and only if u ∈ L (µ) and v ∈ L (µ) on E.
Theorems 11.23(a), (d), (e), (f), 11.24(b), 11.26, 11.27, 11.29, and 11.32 can now be
extended to Lebesgue integrals of complex functions. The proofs are quite straight￾forward. That of Theorem 11.26 is the only one that offers anything of interest:
If f ∈ L (µ) on E, there is a complex number c, |c| = 1, such that
c
Z
E
f dµ ≥ 0.
Put g = cf = u + iv, u and v real. Then




Z
E
f dµ



 = c
Z
E
f dµ =
Z
E
g dµ =
Z
E
u dµ ≤
Z
E
|f| dµ.
The third of the above equalities holds since the preceding ones show that R
g dµ
is real.FUNCTIONS OF CLASS L 2 307
FUNCTIONS OF CLASS L 2
As an application of the Lebesgue theory, we shall now extend the Parseval the￾orem (which we proved only for Riemann-integrable functions in Chap. 8) and
prove the Riesz-Fischer theorem for orthonormal sets of functions.
11.34 Definition. Let X be a measurable space. We say that a complex function
f ∈ L 2(µ) on X is measurable if
Z
X
|f|
2 dµ < +∞.
If µ is Lebesgue measure, we say f ∈ L 2. For f ∈ L 2(µ) (we shall omit the phrase
“on X” from now on) we define
∥f∥ =
Z
X
|f|
2 dµ
1/2
and call ∥f∥ the L 2(µ) norm of f.
11.35 Theorem. Suppose f ∈ L 2(µ) and g ∈ L 2(µ). Then fg ∈ L (µ) and
(11.98) Z
X
|fg| dµ ≤ ∥f∥ ∥g∥ .
This is the Schwarz inequality, which we have already encountered for series
and for Riemann integrals. It follows from the inequality
0 ≤
Z
X
(|f| + λ |g|)
2 dµ = ∥f∥
2 + 2λ Z
X
|fg| dµ + λ
2
∥g∥
2
,
which holds for every real λ.
11.36 Theorem. If f ∈ L 2(µ) and g ∈ L 2(µ), then f + g ∈ L 2(µ) and
∥f + g∥ ≤ ∥f∥ + ∥g∥ .
Proof. The Schwarz inequality shows that
∥f + g∥
2 =
Z
|f|
2 +
Z
fg +
Z
fg +
Z
|g|
2
≤ ∥f∥
2 + 2 ∥f∥ ∥g∥ + ∥g∥
2
= (∥f∥ + ∥g∥)
2
.
11.37 Remark. If we define the distance between two functions f and g in L 2(µ)
to be ∥f − g∥, we see that the conditions of Definition 2.15 are satisfied, except for
the fact that ∥f − g∥ = 0 does not imply that f(x) = g(x) for all x, but only for
almost all x. Thus, if we identify functions which differ only on a set of measure
zero, L 2(µ) is a metric space.FUNCTIONS OF CLASS L 2 308
We now consider L 2 on an interval of the real line, with respect to Lebesgue
measure.
11.38 Theorem. The continuous functions form a dense subset of L 2 on [a, b].
More explicitly, this means that for any f ∈ L 2 on [a, b], and any ε > 0, there
is a function g, continuous on [a, b], such that
∥f − g∥ =
Z b
a
|f − g|
2 dx
1/2
< ε.
Proof. We shall say that f is approximated in L 2 by a sequence (gn) if ∥f − gn∥ →
0 as n → ∞.
Let A be a closed subset of [a, b] and KA its characteristic function. Put
t(x) = inf |x − y| (y ∈ A)
and
gn(x) = 1
1 + nt(x)
(n = 1, 2, 3, . . .).
Then gn is continuous on [a, b], gn(x) = 1 on A, and gn(x) → 0 on B, where
B = [a, b] − A. Hence
∥gn − KA∥ =
Z
B
g
2
n dx
1/2
→ 0
by Theorem 11.32. Thus characteristic functions of closed sets can be approximated
in L 2 by continuous functions.
By (11.39), the same is true for the characteristic functions of any measurable
set, and hence also for simple measurable functions.
If f ≥ 0 and f ∈ L 2, let (sn) be a monotonically increasing sequence of simple
nonnegative measurable functions such that sn(x) → f(x). Since |f − sn |
2 ≤ f
2,
Theorem 11.32 shows that ∥f − sn∥ → 0. The general case follows.
11.39 Definition. We say that a sequence of complex functions (ϕn) is an orthonor￾mal set of functions on a measurable space X if
Z
X
ϕnϕm dµ =

0 (n ̸= m),
1 (n = m).
In particular, we must have ϕn ∈ L 2(µ). If f ∈ L 2(µ) and if
cn =
Z
X
fϕn dµ (n = 1, 2, 3, . . .),FUNCTIONS OF CLASS L 2 309
we write
f ∼
X∞
n=1
cnϕn,
as in Definition 8.10.
The definition of a trigonometric Fourier series is extended in the same way to
L 2 (or even to L ) on [−π, π]. Theorem 8.11 and Theorem 8.12 (the Bessel inequal￾ity) hold for any f ∈ L 2(µ). The proofs are the same, word for word.
We can now prove the Parseval theorem.
11.40 Theorem. Suppose
(11.99) f(x) ∼
X∞
n=−∞
cne
inx
,
where f ∈ L 2 on [−π, π]. Let sn be the nth partial sum of (11.99). Then
lim n→∞
∥f − sn∥ = 0,(11.100)
X∞
n=−∞
|cn |
2 =
1
2π Zπ
−π
|f|
2 dx.(11.101)
Proof. Let ε > 0 be given. By Theorem 11.38, there is a continuous function g such
that
∥f − g∥ <
ε
2
.
Moreover, it is easy to see that we can arrange it so that g(π) = g(−π). Then g
can be extended to a periodic continuous function. By Theorem 8.16, there is a
trigonometric polynomial T, of degree N, say, such that
∥g − T∥ <
ε
2
.
Hence, by Theorem 8.11 (extended to L 2), n ≥ N implies
∥sn − f∥ ≤ ∥T − f∥ < ε,
and (11.100) follows. Equation (11.101) is deduced from (11.100) as in the proof of
Theorem 8.16.
Corollary. If f ∈ L 2 on [−π, π], and if
Zπ
−π
f(x)e
−inx dx = 0 (n = 0, ±1, ±2, . . .),
then ∥f∥ = 0.
Thus if two functions in L 2 have the same Fourier series, they differ at most
on a set of measure zero.FUNCTIONS OF CLASS L 2 310
11.41 Definition. Let f and fn ∈ L 2(µ) (n = 1, 2, 3, . . .). We say that (fn) con￾verges to f in L 2(µ) if ∥fn − f∥ → 0. We say that (fn) is a Cauchy sequence in
L 2(µ) if for every ε > 0 there is an integer N such that n ≥ N, m ≥ N implies
∥fn − fm∥ ≤ ε.
11.42 Theorem. If (fn) is a Cauchy sequence in L 2(µ), then there exists a function
f ∈ L 2(µ) such that (fn) converges to f in L 2(µ).
This says, in other words, that L 2(µ) is a complete metric space.
Proof. Since (fn) is a Cauchy sequence, we can find a sequence (nk), k = 1, 2, 3, . . .
such that
∥fnk − fnk+1 ∥ <
1
2
k
(k = 1, 2, 3, . . .).
Choose a function g ∈ L 2(µ). By the Schwarz inequality,
Z
X

g(fnk − fnk+1
)

 dµ ≤
∥g∥
2
k
.
Hence
(11.102) X∞
k=1
Z
X

g(fnk − fnk+1
)

 dµ ≤ ∥g∥ .
By Theorem 11.30, we may interchange the summation and integration in (11.102).
It follows that
(11.103) |g(x)|
X∞
k=1

fnk
(x) − fnk+1
(x)

 < +∞
almost everywhere on X. Therefore
(11.104) X∞
k=1

fnk+1
(x) − fnk
(x)

 < +∞
almost everywhere on X. For if the series in (11.104) were divergent on a set E of
positive measure, we could take g(x) to be nonzero on a subset of E of positive
measure, thus obtaining a contradiction to (11.103).
Since the kth partial sum of the series
X∞
k=1
(fnk+1
(x) − fnk
(x)),
which converges almost everywhere on X, is
fnk+1
(x) − fn1
(x),FUNCTIONS OF CLASS L 2 311
we see that the equation
f(x) = lim
k→∞
fnk
(x)
defines f(x) for almost all x ∈ X, and it does not matter how we define f(x) at the
remaining points of X.
We shall now show that this function f has the desired properties. Let ε > 0 be
given and choose N as indicated in Definition 11.41. If nk > N, Fatou’s theorem
shows that
∥f − fnk ∥ < lim inf
i→∞
∥fni − fnk ∥ ≤ ε.
Thus f − fnk ∈ L 2(µ), and since f = (f − fnk
) + fnk
, we see that f ∈ L 2(µ). Also,
since ε is arbitrary,
lim
k→∞
∥f − fnk ∥ = 0.
Finally, the inequality
(11.105) ∥f − fn∥ ≤ ∥f − fnk ∥ + ∥fnk − fn∥
shows that (fn) converges to f in L 2(µ); for if we take n and nk large enough,
each of the two terms on the right of (11.105) can be made arbitrarily small.
11.43 The Riesz-Fischer Theorem. Let (ϕn) be orthonormal on X. Suppose Σ |cn |
2
converges, and put sn = c1ϕ1 + · · · + cnϕn. Then there exists a function
f ∈ L 2(µ) such that (sn) converges to f in L 2(µ), and
f ∼
X∞
n=1
cnϕn.
Proof. For n > m,
∥sn − sm∥
2 = |cm+1|
2 + · · · + |cn |
2
,
so that (sn) is a Cauchy sequence in L 2(µ). By Theorem 11.42, there is a function
f ∈ L 2(µ) such that
lim n→∞
∥f − sn∥ = 0.
Now, for n > k,
Z
X
fϕk dµ − ck =
Z
X
fϕk dµ −
Z
X
snϕk dµ,
so that




Z
X
fϕk dµ − ck




≤ ∥f − sn∥ · ∥ϕk∥ + ∥f − sn∥ .
Letting n → ∞, we see that
ck =
Z
X
fϕk dµ (k = 1, 2, 3, . . .),FUNCTIONS OF CLASS L 2 312
and the proof is complete.
11.44 Definition. An orthonormal set (ϕn) is said to be complete if, for f ∈ L 2(µ),
the equations
Z
X
fϕn dµ = 0 (n = 1, 2, 3, . . .)
imply that ∥f∥ = 0.
In the Corollary to Theorem 11.40 we deduced the completeness of the trigono￾metric system from the Parseval equation (11.101). Conversely, the Parseval equa￾tion holds for every complete orthonormal set:
11.45 Theorem. Let (ϕn) be a complete orthonormal set. If f ∈ L 2(µ) and if
(11.106) f ∼
X∞
n=1
cnϕn,
then
(11.107) Z
X
|f|
2 dµ =
X∞
n=1
|cn |
2
.
Proof. By the Bessel inequality, Σ |cn |
2
converges. Putting
sn = c1ϕ1 + · · · + cnϕn,
The Riesz-Fischer theorem shows that there is a function g ∈ L 2(µ) such that
(11.108) g ∼
X∞
n=1
cnϕn,
and such that ∥g − sn∥ → 0. Hence ∥sn∥ → ∥g∥. Since
∥sn∥
2 = |c1|
2 + · · · + |cn |
2
,
we have
(11.109) Z
X
|g|
2 dµ =
X∞
n=1
|cn |
2
.
Now (11.106), (11.108), and the completeness of (ϕn) show that ∥f − g∥ = 0, so
that (11.109) implies (11.107).
Combining Theorems 11.43 and 11.45, we arrive at the very interesting conclu￾sion that every complete orthonormal set induces a 1-1 correspondence between
the functions f ∈ L 2(µ) (identifying those which are equal almost everywhere)EXERCISES 313
on the one hand and the sequences (cn) for which Σ |cn |
2
converges, on the other.
The representation
f ∼
X∞
n=1
cnϕn,
together with the Parseval equation, shows that L 2(µ) may be regarded as an
infinite-dimensional euclidean space (the so-called “Hilbert space”), in which the
point f has coordinates cn and the functions ϕn are the coordinate vectors.
EXERCISES
11.1. If f ≥ 0 and R
E
f dµ = 0, prove that f(x) = 0 almost everywhere on E. Hint: Let En be
the subset of E on which f(x) > 1/n. Write A =
S
En. Then µ(A) = 0 if and only if µ(En) = 0
for every n.
11.2. If R
A f dµ = 0 for every measurable subset A of a measurable set E, then f(x) = 0 almost
everywhere on E.
11.3. If (fn) is a sequence of measurable functions, prove that the set of points x at which
(fn(x)) converges is measurable.
11.4. If f ∈ L (µ) on E and g is bounded and measurable on E, prove that fg ∈ L (µ) on E.
11.5. Put
g(x) = 
0 (0 ≤ x ≤ 1
2
),
1 (
1
2 ≤ x ≤ 1),
f2k(x) = g(x) (0 ≤ x ≤ 1),
f2k+1(x) = g(1 − x) (0 ≤ x ≤ 1).
Show that
lim inf
n→∞
fn(x) = 0 (0 ≤ x ≤ 1),
but
Z 1
0
fn(x) dx =
1
2
.
[Compare with (11.77).]
11.6. Let
fn(x) =  1
n
(|x| ≤ n),
0 (|x| > n).
Then fn(x) → 0 uniformly on R1
, but
Z∞
−∞
fn dx = 2 (n = 1, 2, 3, . . .).
(We write R∞
−∞ in place of R
R1 .) Thus uniform convergence does not imply dominated con￾vergence in the sense of Theorem 11.32. However, on sets of finite measure, uniformly con￾vergent sequences of bounded functions do satisfy Theorem 11.32.
11.7. Find a necessary and sufficient condition that f ∈ R(α) on [a, b]. Hint: Consider Exam￾ple 11.6(b) and Theorem 11.33.
11.8. If f ∈ R on [a, b] and if F(x) = Rx
a
f(t) dt, prove that F
′
(x) = f(x) almost everywhere on
[a, b].EXERCISES 314
11.9. Prove that the function F given by (11.96) is continuous on [a, b].
11.10. If µ(X) < +∞ and f ∈ L 2
(µ) on X, prove that f ∈ L (µ) on X. If
µ(X) = +∞,
this is false. For instance, if
f(x) = 1
1 + |x|
,
then f ∈ L 2 on R1
, but f ∈/ L on R1
.
11.11. If f, g ∈ L (µ) on X, define the distance between f and g by
Z
X
|f − g| dµ.
Prove that L (µ) is a complete metric space.
11.12. Suppose
(a) |f(x, y)| ≤ 1 if 0 ≤ x ≤ 1, 0 ≤ y ≤ 1,
(b) for fixed x, f(x, y) is a continuous function of y,
(c) for fixed y, f(x, y) is a continuous function of x.
Put
g(x) = Z 1
0
f(x, y) dy (0 ≤ x ≤ 1).
Is g continuous?
11.13. Consider the functions
fn(x) = sin nx (n = 1, 2, 3, . . . , −π ≤ x ≤ π)
as points of L 2
. Prove that the set of these points is closed and bounded, but not compact.
11.14. Prove that a complex function f is measurable if and only if f
−1
(V) is measurable for
every open set V in the plane.
11.15. Let R be the ring of all elementary subsets of (0, 1]. If 0 < a ≤ b ≤ 1, define
ϕ([a, b]) = ϕ([a, b)) = ϕ((a, b]) = ϕ((a, b)) = b − a,
but define
ϕ((0, b)) = ϕ((0, b]) = 1 + b
if 0 < b ≤ 1. Show that this gives an additive set function ϕ on R which is not regular and
cannot be extended to a countably additive set function on a σ-ring.
11.16. Suppose (nk) is an increasing sequence of positive integers and E is the set of all x ∈
(−π, π) at which (sin nkx)∞
k=1
converges. Prove that m(E) = 0. Hint: For every A ⊂ E,
Z
A
sin nkx dx → 0,
and
2
Z
A
(sin nkx)
2 dx =
Z
A
(1 − cos2 nkx) dx → m(A) as k → ∞.
11.17. Suppose E ⊂ (−π, π), m(E) > 0, δ > 0. Use the Bessel inequality to prove that there
are at most finitely many integers n such that sin nx ≥ δ for all x ∈ E.
11.18. Suppose f ∈ L 2
(µ), g ∈ L 2
(µ). Prove that




Z
fg dµ




2
=
Z
|f|
2
dµ
Z
|g|
2
dµEXERCISES 315
if and only if there is a constant c such that g(x) = cf(x) almost everywhere. (Compare
Theorem 11.35.)BIBLIOGRAPHY
Articles (Not Originally Listed Here)
[Bel43] Richard Bellman. “A Note on the Divergence of a Series”. In: The Ameri￾can Mathematical Monthly 50.5 (1943), pp. 318–319. ISSN: 00029890, 19300972.
URL: http://www.jstor.org/stable/2302832.
[Cun67] F. Cunningham. “Taking Limits under the Integral Sign”. In: Mathemat￾ics Magazine 40.4 (1967), pp. 179–186. ISSN: 0025570X, 19300980. URL:
http://www.jstor.org/stable/2688673.
[Dav59] Philip J. Davis. “Leonhard Euler’s Integral: A Historical Profile of the
Gamma Function: In Memoriam: Milton Abramowitz”. In: The Ameri￾can Mathematical Monthly 66.10 (1959), pp. 849–869. ISSN: 00029890, 19300972.
URL: http://www.jstor.org/stable/2309786.
[Ebe54] W.F. Eberlein. “The Elementary Transcendental Functions”. In: The Amer￾ican Mathematical Monthly 61.6 (1954), pp. 386–392. ISSN: 00029890, 19300972.
URL: http://www.jstor.org/stable/2307899.
[Fel67] William Feller. “A Direct Proof of Stirling’s Formula”. In: The Ameri￾can Mathematical Monthly 74.10 (1967), pp. 1223–1225. ISSN: 00029890,
19300972. URL: http://www.jstor.org/stable/2315671.
[Fel68] William Feller. “Correction to ”A Direct Proof of Stirling’s Formula””.
In: The American Mathematical Monthly 75.5 (1968), pp. 518–518. ISSN:
00029890, 19300972. URL: http://www.jstor.org/stable/2314719.
[GF66] A.M. Gleason and N.J. Fine. “E1792”. In: The American Mathematical
Monthly 73.7 (1966), pp. 782–782. ISSN: 00029890, 19300972. URL: http:
//www.jstor.org/stable/2314001.
[Kes70] H. Kestelman. “Riemann Integration of Limit Functions”. In: The Ameri￾can Mathematical Monthly 77.2 (1970), pp. 182–187. ISSN: 00029890, 19300972.
URL: http://www.jstor.org/stable/2317340.
[Niv71] Ivan Niven. “A Proof of the Divergence of σ 1/p”. In: The American
Mathematical Monthly 78.3 (1971), pp. 272–273. ISSN: 00029890, 19300972.
URL: http://www.jstor.org/stable/2317524.
316EXERCISES 317
[Rob68] Gerson B. Robison. “A New Approach to Circular Functions, II and
lim (sin x)/x”. In: Mathematics Magazine 41.2 (1968), pp. 66–70. DOI:
10.1080/0025570X.1968.11975839. eprint: https://doi.org/10.
1080/0025570X.1968.11975839. URL: https://doi.org/10.1080/
0025570X.1968.11975839.
[Sch38] I.J. Schoenberg. “On the Peano curve of Lebesgue”. In: Bulletin of the
American Mathematical Society 44.8 (1938), p. 519.
[Sta74] E.L. Stark. “The Series P∞
k=1
k
−s
, s = 2, 3, 4, . . . , Once More”. In: Math￾ematics Magazine 47.4 (1974), pp. 197–202. ISSN: 0025570X, 19300980.
URL: http://www.jstor.org/stable/2689209.
Books (Cited in the Original)
[Art64] E. Artin. The Gamma Function. New York: Holt, Rinehart and Winston,
Inc., 1964.
[Boa60] R.P. Boas. A Primer of Real Functions. Carus mathematical monographs
No. 13. New York: Mathematical Association of America, distributed
by Wiley & Sons, Inc., 1960. ISBN: 9780883850008.
[Buc62a] R.C. Buck. Advanced Calculus. 2nd ed. Studies in Mathematics. Engle￾wood Cliffs, N.J.: Prentice-Hall, 1962.
[Buc62b] R.C. Buck. Studies in Modern Analysis. Studies in Mathematics. Engle￾wood Cliffs, N.J.: Prentice-Hall, 1962.
[Bur51] J.C. Burkill. The Lesbesgue Integral. New York: Cambridge University
Press, 1951.
[Die60] J. Dieudonne.´ Foundations of Modern Analysis. New York: Academic Pres,
Inc., 1960.
[Fle65] W.H. Fleming. Functions of Several Variables. Reading, Mass.: Addison￾Wesley Publishing Company, Inc., 1965.
[Gra65] L.M. Graves. The Theory of Functions of Real Variables. 2nd ed. New York:
McGraw-Hill Book Company, 1965.
[Hal50] P.R. Halmos. Measure Theory. Princeton, N.J.: D. Van Nostrand Com￾pany, Inc., 1950.
[Hal58] P.R. Halmos. Finite-dimensional Vector Spaces. 2nd ed. Princeton, N.J.: D.
Van Nostrand Company, Inc., 1958.
[Har47] G.H. Hardy. Pure Mathematics. New York: Cambridge University Press,
1947.
[Her64] I.N. Herstein. Topics in Algebra. New York: Blaisdell Publishing Com￾pany, 1964.EXERCISES 318
[HR50] G.H. Hardy and W. Rogosinski. Fourier Series. 2nd ed. New York: Cam￾bridge University Press, 1950.
[HS65] E. Hewitt and K. Stromberg. Real and Abstract Analysis. New York: Springer
Publishing Co., Inc., 1965.
[Kel40] O.D. Kellogg. Foundations of Potential Theory. New York: Frederick Un￾gar Publishing Co., 1940.
[Kno28] K. Knopp. Theory and Application of Infinite Series. Glasgow: Blackie &
Son, Ltd., 1928.
[Lan51] E.G.H Landau. Foundations of Analysis. New York: Chelsea Publishing
Company, 1951.
[McS44] E.J. McShane. Integration. Princeton, N.J.: Princeton University Press,
1944.
[Niv65] I.M. Niven. Irrational Numbers. Carus mathematical monographs No.
11. New York: Mathematical Association of America, distributed by Wi￾ley & Sons, Inc., 1965.
[Roy63] H.L. Royden. Real Analysis. New York: The Macmillan Company, 1963.
[Rud74] W. Rudin. Real and Complex Analysis. 2nd ed. New York: McGraw-Hill
Book Company, 1974.
[Sim63] G.F. Simmons. Topology and Modern Analysis. New York: McGraw-Hill
Book Company, 1963.
[Smi71] K.T. Smith. Primer of Modern Analysis. Tarrytown-on-Hudson, N.Y.: Bog￾den and Quigley, 1971.
[Spi65] M. Spivak. Calculus on Manifolds. New York: W.A. Benjamin, Inc., 1965.
[ST67] I.M. Singer and J.A. Thorpe. Lecture Notes on Elementary Topology and
Geometry. Glenview, Ill.: Scott, Foresman and Company, 1967.
[Thu56] H.A. Thurston. The Number System. London-Glasgow: Blackie & Son,
Ltd., 1956.
