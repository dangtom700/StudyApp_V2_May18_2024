Optimization and Computing using
Intelligent Data-Driven Approaches for
Decision-Making
This book comprehensively discusses nature-inspired algorithms, deep
learning methods, applications of mathematical programming, and artificial
intelligence techniques. It further covers important topics such as the use of
machine learning and the Internet of Things and multi-objective
optimization under Fermatean hesitant fuzzy and uncertain environment.
This book:
Addresses solving practical problems such as supply chain
management, smart manufacturing, and healthcare analytics using
intelligent computing and discusses solving the fuzzy inference system
in ant colony optimization for traveling salesman problem.
Presents an overview of artificial intelligence (AI) and explainable AI
decision-making (XAIDM) and illustrates a data-driven optimization
concept for modeling environmental and economic sustainability.
Discusses machine learning-based multi-objective optimization
technique for load balancing in integrated fog-cloud environment.
Explains the use of heuristics and metaheuristics in supply chain
networks and the use of fuzzy optimization in sustainable development
goals.
Discusses sustainable transit of hazardous waste, green fractional
transportation system, perishable inventory, M-estimation of functional
regression operator, and intuitionistic fuzzy sets applications.
The text is primarily written for graduate students and academic researchers
in diverse fields, including operations research, mathematics, statistics,
computer science, information and communication technology, and
industrial engineering.Intelligent Data-Driven Systems and Artificial
Intelligence
Series Editor: Harish Garg
Cognitive Machine Intelligence: Applications, Challenges, and Related
Technologies Inam Ullah Khan, Salma El Hajjami, Mariya Ouaissa, Salwa
Belqziz, and Tarandeep Kaur Bhatia Artificial Intelligence and Internet of
Things based Augmented Trends for Data Driven Systems Anshu Singla,
Sarvesh Tanwar, and Pao-Ann Hsiung Modelling of Virtual Worlds Using
the Internet of Things Edited by Simar Preet Singh and Arun Solanki
Data-Driven Technologies and Artificial Intelligence in Supply Chain:
Tools and Techniques Mahesh Chand, Vineet Jain, and Puneeta Ajmera
Optimization and Computing Using Intelligent Data-Driven Approaches for
Decision-Making: Optimization Applications Irfan Ali, Umar Muhammad
Modibbo, Asaju La’aro Bolaji, and Harish Garg For more information about
this series, please visit: www.routledge.com/Intelligent-Data-Driven￾Systems-and-Artificial-Intelligence/book-series/CRCIDDSAAIOptimization and Computing using
Intelligent Data-Driven Approaches for
Decision-Making
Optimization Applications
Edited by
Irfan Ali, Umar Muhammad Modibbo, Asaju La’aro
Bolaji, and Harish GargDesigned cover image: shutterstock First edition published 2025by CRC Press
2385 NW Executive Center Drive, Suite 320, Boca Raton FL 33431and by CRC Press
4 Park Square, Milton Park, Abingdon, Oxon, OX14 4RN
CRC Press is an imprint of Taylor & Francis Group, LLC
© 2025 selection and editorial matter, Irfan Ali, Umar Muhammad
Modibbo, Asaju La’aro Bolaji and Harish Garg; individual chapters, the
contributors Reasonable efforts have been made to publish reliable data and
information, but the author and publisher cannot assume responsibility for
the validity of all materials or the consequences of their use. The authors
and publishers have attempted to trace the copyright holders of all material
reproduced in this publication and apologize to copyright holders if
permission to publish in this form has not been obtained. If any copyright
material has not been acknowledged please write and let us know so we
may rectify in any future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be
reprinted, reproduced, transmitted, or utilized in any form by any electronic,
mechanical, or other means, now known or hereafter invented, including
photocopying, microfilming, and recording, or in any information storage
or retrieval system, without written permission from the publishers.
For permission to photocopy or use material electronically from this work,
access www.copyright.com or contact the Copyright Clearance Center, Inc.
(CCC), 222 Rosewood Drive, Danvers, MA 01923, 978-750-8400. For
works that are not available on CCC please contact
mpkbookspermissions@tandf.co.uk
Trademark notice: Product or corporate names may be trademarks or
registered trademarks and are used only for identification and explanation
without intent to infringe.
ISBN: 9781032621661 (hbk) ISBN: 9781032882383 (pbk) ISBN:
9781003536796 (ebk) DOI: 10.1201/9781003536796Typeset in Sabonby codeMantraContents
About the editors
List of contributors
1 M-estimation of functional regression operator with responses
missing at random
SUBHRA SANKAR DHAR AND SHALABH
2 A multi-objective solid transportation problem for the sustainable
transit of hazardous waste in the complex Fermatean hesitant fuzzy
environment
M. K. SHARMAAND SADHNA CHAUDHARY
3 A framework of hybrid metaheuristic H-Grey optimization for
embedding factor decision-making in digital image watermarking
on social media
KILARI JYOTHSNA DEVI AND PRIYANKA SINGH
4 New cosine similarity measures for intuitionistic fuzzy sets with
application in decision-making
S. AHEMEN, R. UJAH, AND P. A. EJEGWA
5 Multi-objective optimization problems in focus: Meaning,
approaches, and implementation
ISMAIL OLANIYI MURAINA6 Optimization and computing using intelligent data-driven
approaches for decision-making
SOURENA RAHMANI, HAMED AGHALAR, SAHEL JEBREILI, AND ALIREZA GOLI 7
EVALUATION OF FACTORS AFFECTING DESTINATION SELECTION IN MEDICAL
TOURISM WITH THE SPHERICAL FUZZY ANALYTIC HIERARCHY PROCESS
METHOD
BILAL SARAÇ AND SEHER GÜLENÇ
8 Effect of artificial intelligence on education
SANTU KARMAKAR AND TAPASH DAS
9 Unleashing the power of IoT: Transforming industries and
enabling connected environments
ABDUSSALAM ABBA TUKUR
10 A multi-echelon multi-objective sustainable supply chain
considering traffic congestion
MERAJ HEJAZI, FATEMEH HARSEJ, SEYED EHSAN MIRANI, HASSAN AHMADI
CHOUKOLAEI, AND PEIMAN GHASEMI 11 DIGITAL SUPPLY CHAIN MANAGEMENT
IN MANUFACTURING INDUSTRIES
SEYYDEH ATEFEH MOUSAVI ABANDANSARI, KOUROSH MOKHTARI, AND FARIBA
GOODARZIAN
12 A green fractional transportation system under dual hesitant
Fermatean fuzzy configuration with safety factor
M. K. SHARMA, SADHNA CHAUDHARY, LAXMI RATHOUR, AND VISHNU NARAYAN
MISHRA 13 APPLICATION OF HYBRID SVM-LR ALGORITHM FOR SENTIMENT
ANALYSIS
P. A. ASHOSHI AND M. A. HAMBALI
IndexAbout the editors
Irfan Ali earned his B.Sc., M.Sc., M.Phil., and Ph.D. degrees from Aligarh
Muslim University. He is currently a working faculty member with the
Department of Statistics and Operations Research, Aligarh Muslim
University. He received the Post-Graduate Merit Scholarship Award
during his M.Sc. (statistics) and the UGC-BSR Scholarship Award
during his Ph.D. (statistics) program. His research interests include
applied statistics, survey sampling, reliability theory, supply chain
networks and management, mathematical programming, fuzzy
optimization, and multi-objective optimization. He has supervised
M.Sc., M.Phil., and Ph.D. students in operations research. He completed
a research project UGC–Start-Up Grant Project, UGC, New Delhi,
India. He published more than 100 research articles in SCI/SCIE and
other reputed journals and serves as a reviewer for several journals. He
has published some edited books with international publishers, and some
are in the process of publication. He published a textbook entitled
Optimization with LINGO 18 Problems and Applications. This book is
helpful for academicians, practitioners, students, and researchers in the
field of OR. He is a lifetime member of various professional societies:
Operational Research Society of India, Indian Society for Probability
and Statistics, Indian Mathematical Society, and The Indian Science
Congress Association. He has delivered invited talks at several
universities and institutions. He also serves as associate editor for some
journals and guest editor for SCI/SCIE.Umar Muhammad Modibbo is a Senior Lecturer at the Modibbo Adama
University, Yola, Nigeria. He earned his Ph.D. in Operations Research at
the Aligarh Muslim University, Aligarh, India, in 2022. He earned his
Master of Technology (M.Tech.) and Bachelor of Technology (B.Tech.)
degrees in Operations Research at the Federal University of Technology,
Yola, Nigeria (now The Modibbo Adama University, Yola) in 2016 and
2010, respectively. He is a recipient of the university’s grant to study
M.Tech. Operations Research in 2014 and a Nigerian Tertiary Education
Trust Fund (TETFund) to study Ph.D. Operations Research in 2018. He
received the Young Researcher Award and the Research Excellence
Award from the Institute of Scholars (InSc), India, in 2020. He
specialized in Applied Mathematical Programming and Computing. His
research areas include mathematical programming and its applications,
Soft computing, reliability optimization, fuzzy programming, multi￾objective optimization, inventory and supply chain management,
renewable energy, circular economy, Sustainable Development Goals
and sustainability. He is Fellow and President of the Operations
Research Institute for Decision Sciences & Analytics of Nigeria
(ORIDSAN) and a lifetime and Execrative Member of the African
Federation of Operations Research Societies (AFROS) and the
International Federation of Operational Research Societies (IFORS). He
has published over 40 research articles in journals of national and
international repute with over 800 Google Scholar citations. He
delivered an invited talk and attended conferences and workshops in his
domain area. He is a reviewer of many journals. He is currently writing
a book on the United Nations Sustainable Development Goals.
Asaju Bolaji La’aro earned his Ph.D. in Computer Science, majoring in
Artificial Intelligence and Operations Research from the University of
Science Malaysia, in 2014. He earned his M.Sc. in Mathematics at the
University of Ilorin in 2006 and B.Sc. in Physics/Computer Science at
the Federal University of Technology, Minna, in 2000. Prof. Asaju is
currently the Dean of the Faculty of Computing and Information
Systems, at Federal University Wukari, Taraba State. He is also the Head
of the AI and OR Research Group (ECRG), which publishes numerous
scientific publications in high-quality and well-reputed journals and
conferences. Prof. Asaju has over 21 years of teaching experience inhigher education institutions. He has taught several Computer Science
and Artificial Intelligence courses at the university. In addition to his
research, teaching, and administrative capabilities, Prof. Asaju has
special strength in developing web-based applications that build more
than 12 academic web systems related to research, quality assurance, e￾learning, for postgraduate students, and poses vast experience in
administrative activities.
Harish Garg is an Associate Professor at Thapar Institute of Engineering &
Technology, Deemed University, Patiala, Punjab, India. He is ranked in
the world’s top 2% scientists list and ranked No. 1 in India and No. 229
in World Rank, which was published by Stanford University in four
consecutive years: 2020, 2021, 2022, and 2023. He received the Most
Outstanding Researcher Award in the field of Mathematics from Carrer
360 Academy. He is also the recipient of the International Obada-Prize
2022 – Young Distinguished Researchers. He is also the recipient of the
Top-Cited paper by an India-based author (2015–2019) from Elsevier
publisher. He serves as an advisory board member of the Universal
Scientific Education and Research Network (USERN). He is a Research
Fellow at the INTI International University, Malaysia. His research
interests include computational intelligence, multi-criteria decision￾making, evolutionary algorithms, reliability analysis, expert systems and
decision support systems, computing with words, and soft computing.
He has authored more than 520 papers (over 500 are SCI) published in
refereed international journals, including IEEE Transactions, Elsevier,
and Springer. His Google citations are over 24,490 with H-index – 88.
He is one of the leading researchers in the world related to the MCDM
and soft computing approaches. He also serves on editorial boards of
several leading international journals. He is the Founding Editor-in￾Chief of the Journal of Computational and Cognitive Engineering. He is
also the Associate Editor of Alexandria Engineering Journal, Journal of
Intelligent & Fuzzy Systems, Journal of Industrial & Management
Optimization, CAAI Transactions on Intelligence Technology, etc.
For more details about him, kindly follow his webpage
https://sites.google.com/site/harishg58iitr/homeList of contributors
Hamed Aghalar
Department of Industrial Engineering, Faculty of Industrial and System
Engineering
Isfahan University of Technology
Isfahan, Iran
S. Ahemen
Joseph Sarwuan Tarka University
Makurdi, Nigeria
P. A. Ashoshi
Department of Computer Sciences
Federal University Wukari
Wukari, Nigeria
Sadhna Chaudhary
Department of Mathematics
Chaudhary Charan Singh University
Meerut, India
Hassan Ahmadi Choukolaei
Department of Industrial Engineering, Faculty of Industrial Technologies
Urmia University of TechnologyUrmia, Iran
Tapash Das
Department of Education
Kazi Nazrul University
Asansol, India
Kilari Jyothsna Devi
PVPSIT
Vijayawada, India
Subhra Sankar Dhar
Indian Institute of Technology Kanpur
Kanpur, India
P. A. Ejegwa
Joseph Sarwuan Tarka University
Makurdi, Nigeria
Peiman Ghasemi
Department of Business Decisions and Analytics
University of Vienna
Vienna, Austria
Alireza Goli
Department of Industrial Engineering and Futures Studies, Faculty of
Engineering
University of Isfahan
Isfahan, Iran
Fariba Goodarzian
Edinburgh Business School (EBS) and School of Social Sciences
Heriot-Watt University
Edinburgh, ScotlandSeher Gülenç
Anadolu University
Eskişehir, Turkey
M. A. Hambali
Federal University Wukari
Wukari, Nigeria
Fatemeh Harsej
Department of Industrial Engineering
Nour Branch, Islamic Azad University
Nour, Iran
Meraj Hejazi
Department of Industrial Engineering, Faculty of Engineering
Noor Branch, Islamic Azad University
Noor, Iran
Sahel Jebreili
Department of Industrial Engineering, Faculty of Engineering
Urmia University
Urmia, Iran
Santu Karmakar
Department of Education
Kazi Nazrul University
Asansol, India
Seyed Ehsan Mirani
Economics and Administrative Sciences Faculty
Allameh Mohaddes Nouri University
Nour, Iran
Vishnu Narayan Mishra
Department of MathematicsIndira Gandhi National Tribal University
Anuppur, India
Kourosh Mokhtari
Microelectronics Institute of Sevilla
Research institute in Seville
Seville, Spain
Seyydeh Atefeh Mousavi Abandansari
Department of Industrial Engineering
Mazandaran University of Science and Technology
Babol, Iran
Ismail Olaniyi Muraina
Department of Computer Science, College of Information and Technology
Education
Lagos State University of Education
Lagos, Nigeria
Sourena Rahmani
Department of Industrial Engineering and Futures Studies, Faculty of
Engineering
University of Isfahan
Isfahan, Iran
Laxmi Rathour
Department of Mathematics
National Institute of Technology
Aizawl, India
Bilal Saraç
Anadolu University
Eskişehir, Turkey
ShalabhIndian Institute of Technology Kanpur
Kanpur, India
M. K. Sharma
Department of Mathematics
Chaudhary Charan Singh University
Meerut, India
Priyanka Singh
SRM University – A.P
Guntur, India
Abdussalam Abba Tukur
Department of Information Technology
Federal University Dutse
Dutse, Nigeria
R. Ujah
Joseph Sarwuan Tarka University
Makurdi, NigeriaChapter 1
M-estimation of functional regression
operator with responses missing at
random
Subhra Sankar Dhar and Shalabh
DOI: 10.1201/9781003536796-1
1.1 INTRODUCTION
The estimation of parameters of any model in big data depends on the
optimization techniques. The complex structure of big data is challenging to
handle with the usual data structure and estimation techniques. The non￾parametric models work better in such a situation than the parametric
models, and the robust estimation techniques are more suited to handle the
complex nature of data with infinite-dimensional variables. The missing
data in real-life situations is a rule rather than an exception, particularly in
big data situations. Mostly, the solutions of most of the robust estimation
procedures are obtained through optimization methods. The M-estimation
procedures provide robust estimators, which are obtained by optimization.
So, an important issue is how to do non-parametric modeling with missing
data by employing M-estimation.
Keeping in mind the length of the paper, the extended version of this
chapter with detailed mathematical steps, proofs, applications to real-life
electroencephalography (EEG) data, and other discussions is available at(1.1)
https://home.iitk.ac.in/~shalab/functional-dhar-shal/functional-regression￾mar-dhar-shalabh.pdf
Let us consider a non-parametric regression model, where the covariate
X is a random element in some semi-metric abstract space H with some
specified semi-metric d(. , .), and the response Y is a real-valued random
variable. For a given random sample (X1, Y1),…,(Xn, Yn) identically
distributed as (X, Y ), we consider the following specific non-parametric
regression model:
Yi = m(Xi) + ϵi,
where m : H → R is the unknown non-parametric regression function,
ϵ1,…, ϵn are i.i.d. sequence of error random variables with distribution
function F with the probability density function f having the center of
symmetry at 0. Moreover, there are missing observations of the response
variables (y1,…, yn), where missing occurs at random (MAR). Some
other technical conditions will be stated in the subsequent sections at the
appropriate places. This chapter studies the M-estimator of the unknown
regression function m and its properties and usefulness.
In the context of the non-parametric regression, there have been a few
research articles on non-parametric regression with infinite-dimensional
covariates and the real-valued response; see, e.g., Masry (2005), Ferraty et
al. (2007), Rachdi and Vieu (2007) and a few references therein. All these
research articles mainly investigate the local constant mean estimator of the
unknown non-parametric regression operator. However, none of them
considered the missing observations in the data. Recently, Crambes and
Henchiri (2019) investigated missing values in the response in the context
of the functional linear model, and in the context of non-parametric
regression, Xu and Du (2020) studied the quantile regression estimation
with responses missing at random, and the covariates are infinite￾dimensional variables.
Although most of the aforementioned works are based on complete data,
in real life, one may not have complete data in many applications like EEG
data. For finite-dimensional data, various types of missing data analysis,
including missing at random (MAR), have been extensively studied in the
literature for different research problems (see, e.g., Dhar and Das (2021)
and many references therein). For functional data, in the MAR setting, afunctional mixed effect model with missing longitudinal response was
studied by He et al. (2010), and Ferraty et al. (2013) investigated certain
kinds of mean estimates of the real-valued responses missing at random,
where the covariates are infinite-dimensional in nature. A few years before,
in the MAR setting, outlier detection and a non-parametric approach to
missing value imputation were proposed by Chiou et al. (2014).
Overall, combining missing data and non-parametric regression with
infinite-dimensional covariates has not been extensively studied except in a
few articles mentioned earlier, and only mean or quantile estimation of the
regression operator was considered (see, e.g., Ling et al. (2015) and Xu and
Du (2020)), whereas this chapter studies M-estimation, which is associated
with certain optimization problems (see Eqs. (1.3) and (1.6)), of the
regression operator when the covariates were lying in a certain infinite￾dimensional space with responses missing at random. To the best of our
knowledge, regardless of missing or not missing observations, the M￾estimation of the regression operator with infinite-dimensional covariates
has not been studied in the literature. For details on the M-estimator on
various models, the readers may look at books by van der Vaart (1998) and
Serfling (1980), and review articles by Cizek and Sadıkoğlu (2020) in the
context of non-parametric regression. In this context, note that the M￾estimator of the regression operator is a class of estimators, which includes
well-known estimators like the mean and the median estimators of the
unknown regression operator as the special cases.
Specifically speaking, the main contributions of the chapter are twofold.
The first fold introduces the concept of M-estimation for the regression
operator when the covariates are infinite-dimensional elements with
responses missing at random. The second fold derives the asymptotic
distribution of the proposed estimator of the regression operator, which
enables us to develop various statistical toolkits to draw inferences on the
unknown regression operator. For instance, for ρ(x) = x
2
(for details on ρ
function, see Sections 1.2 and 1.2.6), the M-estimator coincides with the
mean estimator of the regression operator, whereas for ρ(x) = |x|, the M￾estimator reduces to the median estimator of the regression operator. Hence,
with various choices of ρ(.) in M-estimation, the M-estimator is bridging
between a moment-based estimator (i.e., mean) to a rank-based estimator
(i.e., median). Therefore, the asymptotic distribution of the M-estimator ofthe regression operator opens a wide range of inferential toolkits for various
choices of ρ(.).
We now want to discuss the mathematical challenges that we faced in
deriving the asymptotic distribution of the proposed estimator. The first
challenge is dealing with the “small ball probability” defined in Section
1.2.2, which is often intractable for many stochastic processes; however, the
normalizing scale factor of the asymptotic normality of the proposed
estimator involves the “small ball probability”. This chapter demonstrates
the order of “small ball probability” of many well-known infinite￾dimensional spaces. Next, in the derivation of the asymptotic normality, one
also needs to work on the term ϕ(.) defined in Section 1.2.2, which is also
complicated in many well-known smooth infinite-dimensional spaces, and
to ensure the existence of the derivative of ϕ(.), one needs to work with a
certain non-smooth infinite-dimensional space to establish the asymptotic
normality. Overall, one needs to use many complicated machineries of
modern probability theory and mathematical analysis to derive the
theoretical results.
The rest of the chapter is organized as follows: In Section 1.2, we
discuss the model, the basics of the M-estimator of the regression operator,
and the missing probability estimation. Section 1.2.1 studies well-known
examples, and various technical assumptions and issues are investigated in
Sections 1.2.2–1.2.6. Section 1.3 studies the asymptotic distribution of the
M-estimator along with the construction of the confidence band of the
regression operator. Some remarks are made in Section 1.4.
1.2 MODELAND PRELIMINARIES
Let us consider i.i.d. sequence of random elements (X1, Y1),…,(Xn, Yn)
defined in H × R with the same distribution as (X, Y ), where the covariate
X is a random element in some semi-metric abstract space H with some
specified semi-metric d(. , .), and the response Y is a real-valued random
variable. Recall the model Eq. (1.1) as Yi = m(Xi) + ϵi
, where
m : H → R is the unknown regression operator, ϵ1,…, ϵn are i.i.d.
sequence of error random variables with distribution function F with the
probability density function f having the center of symmetry at 0.(1.2)
(1.3)
(1.4)
Moreover, there are missing observations of the response variables
(y1,…, yn), where missing occurs at random (MAR).
Let us first consider the complete data (X1, Y1),…,(Xn, Yn), and for
this data, suppose that m˜ (.) be the M-estimator of the unknown regression
operator m at x ∈ H, which is defined as the following equation:
m˜ n(x) = arg minθ∈R
1
n
n
∑
i=1
ρ(Yi − θ)kh1,n (d(x, Xi)),
where ρ(.) is a convex function, kh1,n (.) = 1
h1,n
k(.) with k : R
+ → R
+,
and h1.n is a sequence of bandwidth satisfying certain technical conditions.
However, for missing data, when missing occurs at random, one needs to
adopt a different technique such as the following: In the MAR setting,
suppose that the missing observations are (X1, Y1, δ1),…,(Xn, Yn, δn),
where (X1,…, Xn) is complete data, and δ is a binary random variable
such that δ = 1 if Y is present and δ = 0 if Y is missing. As the missing
observations follow the MAR setting, we have the following equation:
P[δ = 1|X = x, Y = y] = P[δ = 1|X = x] := η(x),
where η : H → [0, 1]. Note that due to MAR setting, the random variables
δ and Y are independent conditionally on the infinite-dimensional random
element X, and the conditional probability η(x) needs to be estimated as it
is unknown in practice. To estimate η(x), one may adopt the idea of Cheng
and Chu (1996) (see Dhar and Das (2021) also), which is given by the
following equation:
ηˆn x =
n∑
i=1
δikh2,n(d(x,Xi))
n∑
i=1
kh2,n(d(x,Xi))
,
where h2,n is a sequence of bandwidth satisfying a certain technical
condition, and the kernel function k is the same as defined in Eq. (1.4).
Now, for a given data (X1, Y1, δ1),…,(Xn, Yn, δn), the M-estimator
⎛
⎜⎝
⎞
⎟⎠(1.5)
(1.6)
(denoted as mˆ n(.)) of the unknown regression operator m at the point
x ∈ H is defined as:
mˆ n(x) = argminθ∈R
1
n
n
∑
i=1
δi
ηˆn(Xi)
ρ(Yi − θ)kh3,n(d(x, Xi)),
where ηˆn(x) is the same as defined in Eq. (1.4), h3,n is a sequence of
bandwidths satisfying some technical conditions, and ρ is the same as
defined in Eq. (1.2). Here, note that the sequences of bandwidths h2,n and
h3,n need not necessarily be the same. This chapter thoroughly studies the
various properties and the performance of mˆ n(.) for a wide range of cases
in the subsequent section.
1.2.1 Examples
Here, we present a few examples, which are well-known M-estimators.
1.2.1.1 Mean estimator of regression operator
The mean estimator of the unknown regression operator m(.) is an M￾estimator when ρ(x) = x
2
. Note that for this case, mˆ n(.) can be derived
using the straightforward derivative formula of calculus, and it is obtained
as:
mˆ n,mean x =
n∑
i=1
δi
ηˆn(Xi)
Yikh3,n(d(x,Xi))
n∑
i=1
δi
ηˆn(Xi
)
kh3,n(d(x,Xi))
.
It is clear from the expression of mˆ n,mean(.) in Eq. (1.6) that mˆ n,mean(x) is
a certain weighted average of the response random variables Yi
, (
i = 1,…, n), and the missing observations of responses under the MAR
scheme are involved through ηˆn(.).
1.2.1.2 Median estimator of regression operator
⎛
⎜⎝
⎞
⎟⎠(1.7)
(1.8)
The median estimator of the unknown regression operator m(.) is an M￾estimator when ρ(x) = |x|. Note that here ρ(x) is not a differentiable
function of x at x = 0, and for x ≠ 0, ρ′(x) = sign(x), where
sign(x) =
x
|x|
, and ρ′(x) denotes the derivative of ρ(x) at x. Finally, the
median estimator of the regression operator, which is denoted as
mˆ n,median(.), can be obtained by solving the following equation:
n
∑
i=1
δi
ηˆn(Xi)
sign(Yi − mˆ n,median(x))kh3,n(d(x, Xi)) = 0.
It is indicated by Eq. (1.7) that the explicit solution of mˆ n,median may not be
possible to obtain in general. One needs to adopt numerical techniques to
obtain mˆ n,median(.) for a given data. Here also, the missing observations of
the responses under the MAR scheme are involved through ηˆn in
mˆ n,median(.).
1.2.1.3 Maximum likelihood estimator of regression operator
The maximum likelihood estimator of the unknown regression operator
m(.) is an M-estimator when ρ(x) = − log fY (x), where fY (.) is the
probability density function of the response random variable Y . Moreover,
to ensure the existence of the maximum likelihood estimator (MLE), one
also needs to assume that fY (.) is a differentiable function of (.). Let
mˆ n,MLE(.) be the maximum likelihood estimator of the unknown
regression operator m(.), which can be obtained as the solution of the
following equation (i.e., Eq. 1.8):
n
∑
i=1
δi
ηˆn(Xi)
f
′
Y (Yi−mˆ n,mle)
fY (Yi−mˆ n,mle)
kh3,n(d(x, Xi)) = 0,
where f
′
Y
(.) denotes the derivative of fY (.). Here also, the missing
observations of the responses under the MAR scheme are involved through
ηˆn. It is also an appropriate place to mention that mˆ n,mle coincides with the
mean estimator mˆ n,mean of the regression operator when the density(1.9)
function fY (.) is Gaussian, and mˆ n,mle coincides with the median estimator
mˆ n,median for the Laplace density function.
1.2.2 Small ball probability
The concept of small ball probability plays a crucial role in the asymptotic
study of the M-estimator mˆ n(.) defined in Eq. (1.5). The small ball
probability of the infinite-dimensional random element X in some semi￾metric abstract space H with semi-metric d(. , .) is defined as follows. Let
ϕz(t) denote the small ball probability of the random element X at the
fixed point t ∈ R with respect to fixed z ∈ H. Then, the equation is given
as:
ϕz(t) = P[d(z, X) ≤ t]
To derive the asymptotic distribution of mˆ n(.), one needs to assume the
following condition on the small ball probability ϕz(t) defined in Eq. (1.9).
(P1) Let h2,n = h3,n := hn denote the sequence of bandwidths. Then,
nϕz(hn) → ∞ as n → ∞ for any z ∈ H, where hn → 0 as n → ∞.
Note that when H = Rq
for any finite q and hn → 0+ as n → ∞, the
condition nϕz(hn) → ∞ as n → ∞ is equivalent to nh
q
n → ∞ as n → ∞
(see Remark 3 in Ferraty et al. (2007)), which is a common assumption in
the theoretical results in the non-parametric regression when the unknown
regression function m is mapping from R
q → R for any finite q. However,
obtaining the order of ϕz(hn) for infinite-dimensional random element X
when hn → 0+ as n → ∞ may not be always feasible. Moreover, as
Ferraty et al. (2007) pointed out, the order of ϕz(hn) is derivable only for a
few infinite-dimensional random elements even when z = 0, and for a
certain infinite-dimensional space, the order of ϕz(hn) is not even tractable
when z ≠ 0. The readers may refer to Li and Shao (2001) for many results
on the small ball probability.
Regarding theoretical issues associated with the small ball probability,
most of the work generally considers that the random element X follows
some Gaussian process. In fact, if X is a random element associated with
the Gaussian process on the separable Banach space H, and if z is an(1.10)
(1.11)
(1.12)
element in reproducing kernel Hilbert space associated with X, then, the
equation is given as:
ϕz(t)~czϕ0(t) as t → 0+
where cz is some arbitrary constant depending on z. Hence, working with
ϕz(t) is often equivalent to working with ϕ0(t). The equivalence described
in Eq. (1.10) is also valid when X is a random element associated with one￾dimensional diffusion process, and z satisfies some technical conditions
(see Mayer-Wolf and Zeitouni (1993)). In this context, Ferraty et al. (2007)
pointed out that for many non-smooth processes, one may have the
following equation:
ϕz(t)~c0zt−αe
−
c
tβ
,
where α, β, c0z, and c are some positive constants, the semi-norm d(. , .)
involved in the definition of ϕz(t) can be a supremum norm or a L
p
(p ≥ 1
) norm or a Besov norm. Besides, when the random element X is associated
with geometric processes, one has the following equation:
ϕz(t)~c1zt
γ
,
where c1z and γ are some positive constants.
From all these discussions, particularly from Eqs. (1.10)–(1.12), it is
clear that most of the time, the condition (P1) will be satisfied, and
moreover, one can claim the following technical conditions, which will be
required in the derivation of the asymptotic distribution of mˆ n(.).
(P2) For all z ∈ H, there exists a positive constant depending on z,
namely dz and a non-negative real-valued function a(t) such that a(t) → 0
as t → 0. Then,
(A) ϕz(t) = dza(t) + g(t), where g(t) is a function of t such that
g(t)
a(t) → 0 as t → 0.
(B) For any t ∈ [0, 1], there exists a non-decreasing function ξ(t) such
that η(th)
η(t) = ξ(t) + g1(h), where g1(h) is such that g1(h) → 0 as h → 0.The following proposition states the explicit forms of ξ(t) for various
choices of ϕz(t).
Proposition 1.2.1
(i) If ϕz(t)~Czt
γ
for some γ > 0, then ξ(t) = t
γ
. (ii) If
ϕz(t)~Czt
γ
| ln t|
κ
for some γ > 0 and some κ > 0, then ξ(t) = t
γ
.
(iii) If ϕz(t)~C1zt
γe
−
C2
t
p for some p > 0 and some γ > 0, then
ξ(t) = δ1(t), where δ1(t) = 1 if t = 1 and δ1(t) = 0 if t ≠ 1. (iv) If
ϕz(t) =
Cz
|ln t|
, then ξ(t) = 1(0,1](t), where 1(A)(t) = 1 if t ∈ A and
1(A)(t) = 0 if t ∉ A.
Proof of Proposition 1.2.1: The proof follows from the similar
arguments of the proof of Proposition 1 in, Ferraty et al. (2007).
All these expressions of ϕz(t) in Proposition 1.2.1 indicate that
ϕz(t)~czϕ0(t) (see Eq. 1.10) often occurs for many infinite￾dimensional random elements. Besides, for the various properties of
ϕz(t) associated with non-Gaussian processes, the readers may look at
Chowdhury and Chaudhuri (2020).
1.2.3 Smoothness of regression operator
The smoothness of the regression operator plays a crucial role in the whole
analysis of this work. Note that as m : H → R, where H is a semi-metric
abstract space, the notion of smoothness is not as simple as the finite￾dimensional Euclidean space. In our context, we need the following
condition on the smoothness of the unknown regression operator m in the
analysis of the asymptotic distribution of mˆ n.
(S1) For all z1 ∈ H and z2 ∈ H, there exists C > 0 and β ≥ 1 such that
m(z1) − m(z2) < C{d(z1, z2)}
β
.
We here try to characterize the smoothness of the regression operator
described ∣ above (see ∣ condition (S1)) when H is a certain metric space with(1.13)
(1.14)
(1.15)
the metric d(. , .). Let H be a separable Banach space with the induced
metric d(. , .), and suppose that,
α(s) = E[m(z1) − m(z2)|d(z1, z2) = s]
as Ferraty et al. (2007) defined ϕ(s). Let further that H * be the dual space
of H, and ⟨⋅, ⋅⟩ : H × H *
→ R denotes the bilinear mapping from
H × H *
to R, and m′(z) ∈ H′ denotes the Fréchet derivative of m at any
arbitrary point z ∈ H. Now, using the first-order Taylor series expansion
(see, e.g., Rudin (1991)), we have:
m(z1) − m(z2) = ⟨m'(z1), z2 − z1⟩ + o(d(z1, z2)),
and also, note that
dα(s)
ds
s=0 = lim
s→0
E (⟨m′(z1),
z2−z1
d(z1,z2) ⟩ d(z1, z2) = s)
It now follows from Eqs. (1.14) and (1.15) that the condition (S1) will be
satisfied if dα(s)
ds
s=0 is finite. Hence, as an alternative sufficient condition
of (S1) can be
(S1*) α′(0) :=
dα(s)
ds
s=0 exists, i.e., is finite.
Verifying (S1*) may be often more tractable than verifying (S1) for
many infinite-dimensional spaces.
1.2.4 Choice of Kernel function
The choice of the kernel function involved in mˆ n(.) also plays a crucial
role in deriving the limiting distribution of mˆ n(.). We here consider the
following condition of the kernel function k.
(K1) The kernel k(.) : [0, 1] → R
+ is such that |k(x)| ≤ L for some
L > 0 when x ∈ [0, 1]. Moreover, k(.) is continuously differentiable and
strictly decreasing function vanishing at one.
Note that in most of the kernels available in the existing literature of
estimating non-parametric regression operators, the above conditions are
common ∣ (see, e.g., ∣ Ferraty ∣ et al. (2007)), ∣and these conditions are indeedrealistic in nature. Such kernels are somewhat equivalent to type I kernels
(e.g., Ferraty and Vieu (2006)). Moreover, it should be emphasized that as
k(.) is uniformly bounded and k(.) is continuously differentiable, these
imply that k'(.) is uniformly bounded over [0, 1], where k'(.) denotes the
derivative of k(.). It further indicates that 
1
∫
0
g(k'(t)) dt < ∞, where g(.)
is any arbitrary continuous mapping supported over R
+. This fact is
repeatedly used in deriving the limiting distribution of mˆ n(.) (see Section
1.3).
1.2.5 Missing probability
The probability of missing observations of the responses, which is denoted
by η(x) (see Eq. 1.3), also controls the performance of mˆ n (see Section
1.2), and it is involved in the technical derivations as well (see Section 1.3).
Recall from Eq. (1.3) that the missing probability measures the
conditional probability of complete/available observation of the responses
given the infinite-dimensional covariates, and that conditional probability
should be strictly positive, i.e., bounded away from zero. Otherwise, there
will be no observations of responses given the infinite-dimensional
covariates, which could lead to misleading statistical inference. To avoid it,
the following assumption is made on the conditional probability η(.).
(M1) inf
z∈H
η(z) > 0.
Moreover, one can also expect that the conditional probability η(.) is
supposed to be smooth enough in the neighborhood of the point of
evaluation of the unknown regression operator m(z), where z ∈ H so that
η(z) can be well approximated by the sequence of conditional probability
η(zn)n≥1
, where zn is a sequence defined over the abstract space
(H, d(. , .)). To incorporate this idea, the following condition is assumed.
(M2) sup
{X:d(X,z)≤hn}
η(X) − η(z)
p
→ 0 as n → ∞. Here, hn → 0 as
n → ∞.
∣ ∣ ∣ ∣Overall, the assumptions (M1) and (M2) are realistic from a statistical
point of view as well as in the sense of technicalities.
1.2.6 Choice of ρ
In Section 1.2.1, we have seen that various choices of ρ(.) in the expression
of Eq. (1.5) lead to different estimators of the unknown regression operator.
In those examples, it is observed that ρ(x) can be sometimes differentiable
with respect to x, and at the same time, ρ(x) may not be differentiable with
respect to x everywhere. For instance, recall the median estimator of the
regression operator (see Section 1.2.1.2), where ρ(x) = |x| is not
differentiable with respect to x at x = 0. In this context, it should be
mentioned that Xu and Du (2020) studied the quantile estimator of the
regression operator, where also, the check function
ρ(x) = |x| + (2α − 1)x (α ∈ (0, 1)) is not differentiable at x = 0, but in
the proof of the main result, they assumed the existence of score function of
ρ(.) (see Xu and Du (2020, p. 983 in Appendix A), although the score
function does not exist at x = 0. To overcome all these issues related to the
differentiability of the function ρ(.), the following condition is assumed.
(R1) The function ρ(.) involved in mˆ n(.) (see Eq. 1.5) is differentiable
at all but finitely many points. The derivative of ρ(.) is denoted by ψ(.),
where ρ(.) is differentiable.
(R2) If ρ(x) is not differentiable at x, lim
h→0+
ρ(x+h)−ρ(x)
h
and
lim
h→0−
ρ(x+h)−ρ(x)
h
 exist, they are denoted by ψ
+(.) and ψ
−(.), respectively.
(R3) There exists a sequence of twice differentiable function ρn(.) with
the right-hand derivative ψ
+
n
(.) and the left-hand derivative ψ
−
n
(.) such
that sup
x∈R
ψ
+
n
(x) − ψ
+(x) → 0 as n → ∞ and
sup
x∈R
ψ
−
n
(x) − ψ
−(x) → 0 as n → ∞. Here, ψ
+(.) and ψ
−(.) are same
as defined in (R2), and explicitly speaking, ψ
+
n
(x) = lim
h→0+
ρn(x+h)−ρn(x)
∣ ∣ ∣ ∣ hand ψ
−
n
(x) = lim
h→0−
ρn(x+h)−ρn(x)
h
. For all n, ψn(.) denotes the derivative
of ρn(.), and ψn(x) = lim
h→0
ρn(x+h)−ρn(x)
h
.
The condition (R1) allows the non-differentiability of the function ρ(.)
at finitely many points, which expands the horizon of the application of the
proposed estimator mˆ n(.). The condition (R2) ensures the existence of the
right-hand derivative and the left-hand derivative, even if the function ρ is
not differentiable at a particular point. The condition (R3) seems technical,
although it simply says that for a non-differentiable function ρ, there exists
a sequence of differentiable function ρn(.) such that the right-hand and the
left-hand derivatives of ρn(.) uniformly converge to the right-hand and the
left-hand derivatives of ρ(.), respectively. In other words, although ρ(.) is
not differentiable, it can be uniformly approximated by a sequence of
differentiable function ρn(.) in some sense. For instance, for ρ(x) = |x|,
which is not differentiable at x = 0, one may consider the following
equation:
Note that here, ρn(x) is a sequence of differentiable function, and its right￾hand derivative and left-hand derivatives uniformly converge to +1 and -1,
respectively, where +1 and -1 are the right-hand and left-hand derivatives of
ρ(x) = |x|, respectively.
1.3 MAIN RESULT: ASYMPTOTIC
DISTRIBUTION
In Section 1.2, we have seen many examples of the M-estimator of the
regression operator when the responses are missing at random along with
technical issues associated with the proposed estimator mˆ n(.) (see Sections
1.2.2–1.2.6). Now, in order to implement mˆ n(.) in any statistical
methodology, one needs to know the exact or the asymptotic distribution of
ρn(x) = (
x
3
3n6 − x
2
n3 − n
3
3 )1
(−
1
n3 ≤x≤0) − x1
(x<−
1
n3 )
+ (− x
3
3n
6 + x
2
n
3 + n
3
3 )1
(0≤x≤
1
n3 ) + x1
(x>
1
n3 )
.mˆ n(.). As deriving the exact distribution of mˆ n(.) is intractable because of
its complex structure, we here study the asymptotic distribution of mˆ n(.).
The following theorem describes the statement of the pointwise asymptotic
distribution of mˆ n(.).
Theorem 1.3.1
In model Eq. (1.1), given Xi
, suppose that the i.i.d. sequence of the
error random variables ϵi (i = 1,…, n) has positive, bounded,
bounded first derivative, and symmetric probability density function
f(. |Xi) with the center of symmetry at 0 and with a finite (2 + ξ1) -th
moment, where ξ1 > 0. Then, under (P1), (P2) (see Section 1.2.2),
(S1) or (S1*) (see Section 1.2.3), (K1) (see Section 1.2.4), (M1), (M2)
(see Section 1.2.5), (R1), (R2), and (R3) (see Section 1.2.6), for any
z ∈ H, √nϕz(hn)(mˆ n(z) − m(z)) converges weakly to a random
variable associated with Gaussian distribution having mean 0 and
variance V z =
A2
A2
1η(z)dz
lim
n→∞
∫ (
dρn(y)
dy )
2
f(y X)dy
(∫
d
2ρn(y)
dy2 f(y X)dy)
2 , where for
i = 1 and 2, Ai = k
i(1) −
1
∫
0
dk
i(t)
dt
ξ(t)dt, η(z) is the same as
defined in Eq. (1.3), dz is the same as defined in (A) of (P2) in Section
1.2.2, ρn(.) is the same as defined in (R3) in Section 1.2.2, and ξ(t) is
the same as defined in (B) of (P2) in Section 1.2.2.
The assertion in Theorem 1.3.1 explains the asymptotic normality
of mˆ n(.) after appropriate normalization. Note that for the mean
estimator of the regression operator m(.), i.e., when ρ(x) = x
2
, the
asymptotic variance will be Vmean(z) =
A2
A2
1
η(z)dz
∫ y
2f(y X)dy.
For the median estimator of the regression operator m(.), i.e.,
when ρ(x) = |x|, the asymptotic variance will be
Vmedian(z) =
A2
4A
2
1η(z)dzf
2(0 X)
.
⎛
⎜⎝
⎞
⎟⎠
∣ ∣ ∣ ∣It is needless to mention that the asymptotic variance of many more
standard estimators of the regression operator can be explicitly
obtained using various choices of ρ(.) even if the ρ(.) is not
differentiable. Moreover, one can compute the pointwise asymptotic
efficiency of the estimators, which can be defined as the ratio of the
respective inverse asymptotic variances. For instance, here, the
asymptotic efficiency of the mean estimator of the regression operator
with respect to the median estimator of the regression operator is
4f
2(0 X)
∫ y
2f(y X)dy
.
Note that this asymptotic efficiency does not depend on the point of
evaluation z of the regression operator m(z), which is common across
the asymptotic efficiency study in various non-parametric regression
models with finite-dimensional covariates (see, Dhar (2016)).
Moreover, it is also clear from the expression of the aforementioned
asymptotic efficiency of the mean estimator relative to the median
estimator of the regression operator that the asymptotic efficiency does
not depend on the missing probability η(.), although the asymptotic
distribution depends on the missing probability η(.).
We now want to end this section with a discussion on the mathematical
challenges that we faced in the proof of Theorem 1.3.1. The proof
requires several lemmas to establish that many terms are negligible in
probability. For instance, to show the difference between
d
dx ρ(x) −
d
dx ρ(x + m(z) − m(X)) is negligible after proper
normalization, when z and X are sufficiently close, one needs to
repeatedly use the advanced results of the empirical process (see
Chapter 23 in van der Vaart (1998)). Moreover, since ρ(.) may not be
differentiable here also, that also requires careful use of the limit.
Besides, the expression of mˆ n(.) involves the term ηˆ(.), i.e., the
estimated missing probability, which makes the classical central limit
theorem (CLT) and the law of large numbers (LLN) ineffective here,
and those terms can be dealt with only by non-trivial versions of CLT
and the LLN for dependent random variables (see van der Vaart
(1998). ∣ As the proof contains several such terms, overall in manyplaces, the results of advanced analysis and probability theory are
applied.
1.3.1 Confidence band of regression operator
As an application of Theorem 1.3.1, one should be able to construct the
confidence band of the regression operator m(.); however, there are few
terms involved in V (z) (see the statement of Theorem 1.3.1), which are
unknown in practice. First of all, to implement the assertion in Theorem
1.3.1, one needs to estimate ϕz(hn) as it directly appears in the
normalization factor of the asymptotic distribution of mˆ n(.) and implicitly
appears in the expressions of A1 and A2. The estimation of those
expressions can be done as follows.
For a given data (X1, Y1, δ1),…,(Xn, Yn, δn), let us denote
ϕˆn,z(t) = 1
n
n
∑
i=1
1(d(z,Xi)≤t)
, where 1(.) denotes the usual indicator
function. Note that for each t, ϕˆn,z(t)
p/a.s
ϕz(t) as n → ∞, where 
p
→ and
a.s
→ denote the convergence in probability and almost surely, respectively.
This last fact follows from the law of large numbers for the i.i.d. sequence
of random variables (see, e.g., van der Vaart (1998)). Moreover, using P￾Glivenko-Cantelli theorem (see, e.g., van der Vaart (1998)), we have
sup
t
ϕˆn,z(t) − ϕz(t)
p/a.s
0 as n → ∞. Moreover, using (A) and (B) of
(P2) described in Section 1.2.2, ξ(t) can be estimated by
ˆξn(t) = lim
n→∞
ϕˆn(thn)
ϕˆn(t)
, where hn → 0 as n → ∞. Finally, employing ˆξn(t)
in A1 and A2, one can obtain estimators of A1 and A2, which are denoted
by Aˆ
1,n and Aˆ
2,n, respectively. Precisely speaking,
Aˆ
i,n = k
i(1) −
1
∫
0
dk
i(t)
dt
ˆ
−
ξn(t)dt, for i = 1, 2 and let us denote
→
−
∣ ∣ →Vˆn z =
Aˆ2,n
Aˆ2
1,n
ηˆn(z)dz
lim
n→∞
∫ (
dρn(y)
dy )
2
f(y X)dy
(∫
d
2ρn(y)
dy2
f(y X)dy)
2 , which can be considered
a reasonable estimator of V (z) defined in Theorem 1.3.1. The following
corollary states the asymptotic distribution of mˆ n(.) after appropriate
normalization depending on ϕˆn,.(hn) and Vˆn(.).
Corollary 1.3.1
Under the conditions described in Theorem 1.3.1,
√nϕˆn,z(hn)Vˆn(z)(mˆ n(z) − m(z)) converges weakly to a random
variable associated with Gaussian distribution with mean = 0 and
variance = 1.
Corollary 1.3.1 asserts the asymptotic normality of mˆ n(.) using the
estimated ϕz(hn) (i.e., ϕˆn,z(hn)) and V (z) (i.e., Vˆn(z)), and it enables
us to construct the confidence band of the regression operator m(z),
which is as follows. For any α ∈ (0, 1), the asymptotic 100(1 − α)%
confidence band for the regression operator m(z), where z ∈ H, is
given by mˆ n(z) ±
c α
2
nϕˆn,z(hn)Vˆn(z)
, where c α
2
is the (1 −
α
2
) − th
quantile of the standard normal distribution.
1.4 CONCLUDING REMARKS
This chapter proposed and studied the M-estimator of the regression
operator described in model Eq. (1.1), where the scalar-valued responses
are missing at random, and the covariates are infinite-dimensional random
elements. The estimators such as the mean, the median, or the maximum
likelihood estimators can be obtained using special choices of ρ(.).
Besides, the asymptotic normality of the proposed estimator after
⎛
⎜⎝
⎞
⎟⎠
∣ ∣appropriate normalization is derived, and the pointwise asymptotic
confidence band of the regression operator is also studied. It should be
pointed out that the assertion in Theorem 1.3.1 allows even non￾differentiable ρ(.). Moreover, the practicability of the proposed
methodology is thoroughly investigated on well-known EEG data, and it is
observed that well-known M-estimators, such as the mean and the median
estimator of the regression operator, are performing well on EEG data. The
similar phenomena are observed in a few simulation studies as well.
As an application of the proposed methodology, only the pointwise
confidence interval is discussed here. Apart from it, one may also apply it in
testing of hypothesis problem as an application. For instance, one may be
interested to test H0 : m = m0 against H1 : m ≠ m0, where m is the
unknown regression operator, and m0 is some specified regression operator.
For such testing of hypothesis problems like H0 against H1, one may use
an M-estimator to estimate the unknown regression operator m to carry out
the test H0 against H1. More generally, it may also be of interest to test
H0 : m ∈ M0 against H1 : m ∈ M0, where M0 is some specified class of
operator.
ACKNOWLEDGMENT
Subhra Sankar Dhar gratefully acknowledges his core research grant
(CRG/2022/001489), Government of India.
REFERENCES
Cheng, P. E. and Chu, C. K. (1996). Kernel estimation of distribution
functions and quantiles with missing data. Statistica Sinica, 6:63–
78.
Chiou, J. M., Yang, Y. F., and Chen, Y. T. (2014). Multivariate
functional principal component analysis: A normalization approach.
Statistica Sinica, 24:1571–1596.
Chowdhury, J. and Chaudhuri, P. (2020). Convergence rates for kernel
regression in infinite dimensional spaces. Annals of the Institute of
Statistical Mathematics, 72:471–509.Cizek, P. and Sadıkoğlu S. (2020). Robust nonparametric regression: A
review. WIREs Computational Statistics, e1473:e1492.
Crambes, C. and Henchiri, Y. (2019). Regression imputation in the
functional linear model with missing values in the response.
Journal of Statistical Planning and Inference, 201:103–119.
Dhar, S. S. (2016). Trimmed mean isotonic regression. Scandinavian
Journal of Statistics, 43(1):202–212.
Dhar, S. S. and Das, U. (2021). On distance based goodness of fit tests
for missing data when missing occurs at random. Australian &
New Zealand Journal of Statistics, 63:331–356.
Ferraty, F. and Vieu, P. (2006). Nonparametric Functional Data
Analysis: Theory and Practice. Springer.
Ferraty, F., Mas, A., and Vieu, P. (2007). Nonparametric regression on
functional data: Inference and practical aspects. Australian & New
Zealand Journal of Statistics, 49:267–286.
Ferraty, F., Sued, M., and Vieu, P. (2013). Mean estimation with data
missing at random for functional covariables. Statistics, 43:688–
706.
He, Y., Zaslavsky, A., Harrington, D., Catalano, P., and Landrum, M.
(2010). Multiple imputation for a large-scale complex survey: A
practical guide. Statistical Method in Medical Research, 19:653–
670.
Li, W. and Shao, Q. (2001). Gaussian Processes: Inequalities, Small
Ball Probabilities and Applications. Elsevier.
Ling, N. X., Liang, L. L., and Vieu, P. (2015). Nonparametric
regression estimation for functional stationary ergodic data with
missing at random. Journal of Statistical Planning and Inference,
162:75–87.
Masry, E. (2005). Nonparametric regression estimation for dependent
functional data: Asymptotic normality. Stochastic Process and
Their Applications, 115:155–177.
Mayer-Wolf, E. and Zeitouni, O. (1993). The probability of small
Gaussian ellipsoids and associated conditional moments. The
Annals of Probability, 21:14–24.Rachdi, M. and Vieu, P. (2007). Nonparametric regression for
functional data: Automatic smoothing parameter selection. Journal
of Statistical Planning and Inference, 137:2784–2801.
Rudin, W. (1991). Functional Analysis. McGraw-Hill.
Serfling, R. (1980). Approximation Theorems of Mathematical
Statistics. John Wiley & Sons.
van der Vaart, A. W. (1998). Asymptotic Statistics. Cambridge
University Press.
Xu, D. and Du, J. (2020). Nonparametric quantile regression
estimation for functional data with responses missing at random.
Metrika, 83:977–990.Chapter 2
A multi-objective solid transportation problem for
the sustainable transit of hazardous waste in the
complex Fermatean hesitant fuzzy environment
M. K. Sharma and Sadhna Chaudhary
DOI: 10.1201/9781003536796-2
2.1 INTRODUCTION
A waste is considered hazardous if it has traits that make it risky or that could affect the
environment or human health. The production of hazardous waste (HW) is diverse, including
wastes from industrial processes, batteries, and sludge. It may also take the form of gases, liquids,
solids, and sometimes sludge. These substances are persistent in the environment, not recyclable,
and harmful to human health and natural resources.
On the basis of their chemical, biological, and physical characteristics, HWs are categorized,
and their classification is given in Figure 2.1. Figure 2.1 classifies hazardous waste into five
categories based on their characteristics. One of the most critical problems that needs immediate
attention is the handling of HWs that have already been produced. The main goal with regard to
every hazardous waste management (HWM) tactic is to guarantee the prompt, secure, and
economical gathering, transport, treatment, and dumping of waste. Additionally, it should
guarantee that the system performs admirably in both the present and the foreseen future.Figure 2.1 Classification of hazardous waste.
The process of managing HW entails the collection, treatment, transportation, disposal, and
oversight of disposal locations. This includes identifying the best methods and locations for
treatment and disposal, distributing HW from the generator to the disposal sites, and picking the
best routes for transportation. HW remediation can be achieved through a variety of chemical,
biological, and physical techniques. Land disposal is the last phase, but due to the associated
ecological hazards, it is not the desired procedure.
The following are some of the most recent pioneering works available in the literature on the
management of HW: Misra and Pandey (2005) describe the types of HW, characteristics of waste,
ecological impacts of HWM, planning, designing, and developing models for efficient HWM. The
momentous state, issues and difficulties, and potential future improvements to the HWM system
in India are the primary areas covered by Kumar et al. (2007). In the context of managing
industrial HW, Rabbani et al. (2019) developed a multi-objective mathematical model to
encompass integrated decisions at three levels involving location, truck routing, and inventory
control. Ghalehkhondabi et al. (2020) analysed the HWM system as a network of suppliers with a
disposal location and a contractor that serves customers with the demand that is cost efficient and
environmentally conscious. Vallero (2022) addressed the science underlying environmental
quality and underlined the negative impact of HW on our ecosystems and public health. Zhang et
al. (2022) analysed environmentally friendly methodologies for HWM. El-Saadony et al. (2023)
described the types and make-up of leachates, the causes of leachate formation, and the traditional
methods of treating landfill leachates.
The processes for making assessments include crisp data. However, uncertainty plays a major
role in any choices made about the problems we face daily. Zadeh (1965) proposed fuzzy set (FS)
to address the challenges associated with modelling ambiguous or unclear data while making
decisions. By employing FS, the researchers have quantitatively analysed the uncertainty of an
occurrence, and they have defined many extensions of this notion. Intuitionistic fuzzy set (IFS)
(Atanassov 1986), neutrosophic set (NS) (Smarandache 1999), hesitant fuzzy set (HFS) (Torra
2010), dual hesitant fuzzy set (DHFS) (Zhu et al. 2012), Pythagorean fuzzy set (PyFS) (Yager
2013), picture fuzzy set (PFS) (Cuong 2014), Fermatean fuzzy set (FFS) (Senapati and Yager
2020), and dual hesitant Fermatean fuzzy set (DHFFS) (Zhou et al. 2023) are some pioneered
extensions of FSs that are available in the literature.
FSs and their extensions are limited to handling the ambiguity and uncertainty that occur in
data and cannot adequately explain the data fluctuations at a particular moment. Ramot et al.
(2002) proposed complex fuzzy set (CFS) to deal with such circumstances. The range of
membership degrees (MDs) is extended to the unit circle in the complex plane, in contrast to a
standard fuzzy MDs, that lies in [0, 1]. Its complex MDs, comprising amplitude and phase factors,
makes it distinctive. While the amplitude keeps the idea of fuzziness, the phase term denotes a
CFS declaration requiring the second membership dimension. With the CFS, one may fix
temporal problems and compile data from many sources into a single, comprehensible aggregate.
Alkouri and Salleh (2012) put forward a complex intuitionistic fuzzy set (CIFS) as an extension of
CFS by incorporating the non-membership degree (NMD) to CFS. To deal with the demerits of
CFS and CIFS, Ullah et al. (2020) introduced a complex Pythagorean fuzzy set (CPyFS) that
encompasses a broader range of values due to the extensive properties of PyFS. Chinnadurai
(2021) devised complex Fermatean fuzzy set (CFFS) as an expansion of CPyFS along with its
fundamental operations. As an amalgamation of CFS and HFS, Garg et al. (2021) established a
Complex hesitant fuzzy set (CHFS) that efficiently accommodates complex and uncertain data
and analysed its architecture and the fundamental characteristics. Additionally, numerousgeneralizations are available in literature besides these major extensions of CFS to deal more
efficiently with uncertainty, such as the complex probabilistic fuzzy set (CProFS) (Janani and
Rakkiyappan 2022), complex probabilistic hesitant fuzzy soft set (CProHFSS) (Ashraf et al.
2023a), complex probabilistic hesitant fuzzy N-soft set (CProHFN-SS) (Ashraf et al. 2023b) and
others.
The transportation problem (TP) is a special type of linear programming problem (LPP) that
develops from a structure with a predetermined number of terminals and loops. It was first put
forth by Hitchcock (1941) to keep the demand going from origin to their terminal. Multi-objective
transportation problem (MOTP) was created to handle the kinds of circumstances having multiple
conflicting objectives that are to be optimized simultaneously. Shell (1955) introduced the notion
of three-dimensional TP, a generalization of conventional TP and also known as solid
transportation problems.
Because traditional forms of TP cannot cope with the uncertainty available in various
parameters, the following are some recent studies that have been done in TPs under fuzzy
environments majorly to enhance sustainability: Das et al. (2020) first introduced a triangular
version of type-2 fuzzy set; then, for the applicability of the proposed number, they developed an
STP with multiple objectives along with a different form of CE. Two approaches, namely fuzzy
programming (FP) and the global criteria method (GCM), are utilized to get an integrated model’s
pareto optimal solution. An STP to enhance sustainability with multiple goals, multi-stages, and
fixed charges with intuitionistic fuzzy parameters is proposed (Midya et al. 2021). Aktar et al.
(2021) designed and solved an MOTP for incompatible, breakable, multi-items with a four￾dimensional approach to optimize the transportation cost (TC), time (TT), and carbon emission
(CE) simultaneously. A real-world scenario is presented for incompatible objects, and the impacts
of the “green corridor” on fixed charge are examined. Giri and Roy (2022) put forth two
approaches to get the optimal solution of a green 4-dimensional MOTP under a Neutrosophic
environment. A novel ranking function to defuzzify FFS is introduced by Sharma et al. (2022),
along with its application in a TP with Fermatean fuzzy parameters. A green STP with multi￾objectives for the transportation of multiple items is tackled by Shivani et al. (2022) under
interval-valued fuzzy settings. Ghosh et al. (2022) devised a multi-objective STP for waste
management of different sectors. The parameters in the proposed model are taken as triangular
Pythagorean hesitant fuzzy numbers and optimized three objectives, namely TC, TT, and CE.
Pythagorean hesitant Fermatean fuzzy programming is also introduced to tackle the transportation
model for sustainable waste management. A transportation model with multiple objectives with
parameters as a triangular Fermatean fuzzy number is proposed by Akram et al. (2023). Ghosh et
al. (2023) evaluated the model by investigating an integrated MOSTP with three objectives,
namely TC, TT, and CE, under an uncertain environment for the management of waste. To tackle
a four-dimensional MOTP with triangular intuitionistic fuzzy parameters, Bind et al. (2023)
proposed a methodology. Their main goal is to increase profits by minimizing product damage
and mitigating carbon emissions and transportation time.
In a developing world, fuzziness, hesitancy, and randomness make it difficult to make optimal
decisions. Thus, in order to solve the scenarios when both MD and NMD involved phase of time,
hesitation together, we introduced the notion of a complex Fermatean hesitant fuzzy set (CFHFS).
In CFHFS, both MD and NMD are hesitant and complex-valued that are demonstrated in polar
coordinate and encompassing properties of FFS. The amplitude term of the MDs and NMDs
demonstrates the belongingness and non-belonginess of CFHFS to some extent, respectively. The
phase term associated with the set of MDs and NMDs provides extra information pertinent to the
phase of time and periodicity. Transporting HW to a designated treatment, storage, or disposal
facility (TSDF) is frequently necessary and is given particular consideration as it poses potentialrisks to the public’s safety and the environment. Thus, for the pragmatic applicability of novel set,
we devised a mathematical model for the sustainable transportation of HW. Table 2.1 contains a
list of all the abbreviations that were employed in this chapter.
Table 2.1 List of abbreviations
CE Carbon emission
CFHFS
CFHFN
Complex Fermatean hesitant fuzzy set
Complex Fermatean hesitant fuzzy number
CFHF￾MOGSTP
Complex Fermatean hesitant Fuzzy multi-objective green solid
transportation problem
FFS Fermatean fuzzy set
FP Fuzzy programming
HFS Hesitant fuzzy set
HW Hazardous waste
HWM Hazardous waste management
MD Membership degree
NMD Non-membership degree
MOSTP Multi-objective solid transportation problem
MOGSTP Multi-objective green solid transportation problem
SC Safety cost
STP Solid transportation problem
TC Transportation cost
Here is a summary of the most important points covered in this chapter:
In the real world, vagueness and uncertainty are often encountered. To cope up with these
issues, we introduced a CFHFS as an extension of DHFFS by the fusion of complex
information in both set of MDs and NMDs.
Each characteristic has been completely defined by examining its core operations, ranking
function, and accuracy function.
A transportation model of complex Fermatean hesitant fuzzy multi- objective green solid
transportation problem (CFHFN-MOGSTP) is developed to mitigate the adverse effects of
HW on living organisms.
Additionally, an approach for addressing the proposed framework using FP is provided.
We examined a real-world problem of transporting HW with parameters as CFHFN for
numerical computing.
Notations Full formThe work study done in our chapter is laid out as follows: The fundamental background and
literature review of HW, TP, and FSs has been addressed in Section 2.1. Section 2.2 briefly
described CFS, HFS, and FFS. CFHFS is introduced in Section 2.3 with basic operations,
properties, score, and accuracy function. A MOGSTP with CFHF parameters for the sustainable
transport of HW is introduced in Section 2.4. In Section 2.5, a methodology is described to deal
with the proposed model by utilizing FP. Section 2.6 is dedicated to a numerical example to
elaborate the proposed methodology. Finally, core of work done in research article along with
future prospectives are discussed in Section 2.7.
2.2 PRELIMINARIES
2.2.1 Complex Fuzzy Set (CFS)
Let Z be a set of universe, then a CFS is defined as follows:
∁ = {z, μ∁ (z)|z ∈ Z }, where μ (z) : Z → Δ (z) is the membership function defined as
μ∁ (z) = ρ∁ (z). e
i2πϕρ
∁
(z)
. Here, Δ (z) is the unit disc in the complex plane and i = √−1.
2.2.2 Hesitant Fuzzy Set (HFS)
An HFS on the fixed set Z is defined as:
H = {z, ℏ (z) : z ∈ Z }
such that the set ℏ (z) represents the likely membership degrees of z ∈ Z .
2.2.3 Fermatean Fuzzy Set (FFS)
An FFS is defined as follows:
n = {zμn(z), ϑn(z)}
s.t.μn (z) : Z → [0, 1] and ϑn (z) : Z → [0, 1] obey the condition
0 ≤ μn(z)
3 + ϑn(z)
3 ≤ 1∀z ∈ Z andμn (z) and μn (z) represent the MD and NMD,
respectively.
2.3 COMPLEX FERMATEAN HESITANT FUZZY SET
(CFHFS)
We proposed complex Fermatean hesitant fuzzy set (CFFS) as a tool to address uncertainty
embedded in the real world in this section.
2.3.1 Definition
A CFHFS is mathematically stated as
Z = {z, R (z), I (z)|z ∈ Z },where R (z) and I (z) are two sets of some values in the unit disc of complex plane, denoting the
possible set of complex hesitant of MD and NMD of z ∈ Z , respectively.
R (z) = {r(z). e
i2πϕr(z)}andI (z) = {n (z). e
i2πϕn(z)},i = √−1
satisfying the conditions 0 ≤ (r(z))
3 + (n (z))
3 ≤ 1 and 0 ≤ (ϕr (z))
3+ (ϕn (z))
3 ≤ 1. Here,
each element of R (z) and I (z) has the range in complex unit disc, also ϕr (z), ϕn (z) ∈ [0, 1].
Furthermore, Z = (R, I) is known as complex Fermatean hesitant fuzzy number (CFHFN).
2.3.2 Fundamental operations
Let us consider two CFHFN Z1 = (R1, I1) and Z2 = (R2, I2),Λbe a scalar, then the basic
operators are defined in the following manner:
i. 
ii. 
iii. ΛZ1 = ∪
r1,ϕr1∈R1,n1,ϕn1∈I1
{√3 1 − (1 − r1
3)
Λ
. e
i2π√3 1−(1−ϕr1
3)
Λ
, n1
Λ. e
i2π(ϕn1
Λ)}
iv. Z1Λ = ∪
r1,ϕr1∈R1,n1,ϕn1∈I1
{r1
Λ. e
i2π(ϕr1
Λ)
,√3 1 − (1 − n1
3)
Λ
. e
i2π√3 1−(1−ϕn1
3)
Λ}
2.3.3 Ranking function and accuracy function
For a CFHFN Z = (R, I) the ranking function is stated as,
S (Z) = z (1 + 1
n(R(z)) ∑ (r(z)
3 + ϕr(z)
3) − 1
n(I(z)) ∑ (n(z)
3 + ϕn(z)
3))
and the accuracy function is defined as,
A (Z) = z (1 +
1
n(R(z)) ∑ (r(z)
3 + ϕr(z)
3) +
1
n(I(z)) ∑ (n(z)
3 + ϕn(z)
3))
Here, n(R (z) and n (I (z)) represent cardinality of R (z) and I (z), respectively.
In the case of two CFHFNs Z1 and Z2
, if either S (Z1) > S (Z2) or S (Z1) = S (Z2) and
A (Z1) > A (Z2) satisfied, then Z1 > Z2, holds.
2.3.4 Theorem
Z1 ⊕ Z2 = ∪
r1,ϕr1∈R1,n1,ϕn1∈I1,r2,ϕr2∈R2,n2,ϕn2∈I2
× {√3 r1
3 + r2
3 − r1
3r2
3
. e
i2π√3 ϕr1
3+ϕr2
3−ϕr1
3ϕr2
3
, n1n2. e
i2π(ϕn1ϕn2)}
Z1 ⊗ Z2 = ∪
r1,ϕr1∈R1,n1,ϕn1∈I1,r2,ϕr2∈R2,n2,ϕn2∈I2
× {r1.r2e
i2π(ϕr1ϕr2)
,√3 n1
3 + n2
3 − n1
3n2
3
. e
i2π√3 ϕn1
3+ϕn2−3ϕn1
3ϕn2
3}Consider four CFHFNs Z(R, I),Z1 = (R1, I1),Z2 = (R2, I2), and Z3 = (R3, I3). Assume
Λ,Λ1 and Λ2 ≥ 0 be three positive integrals, then:
i. 
ii. 
iii. 
iv. 
Z1 ⊕ Z2 = ∪
r1,ϕr1∈R1,n1,ϕn1∈I1,r2,ϕr2∈R2,n2,ϕn2∈I2
× {√3 r1
3 + r2
3 − r1
3r2
3
. e
i2π√3 ϕr1
3+ϕr2
3−ϕr1
3ϕr2
3
, n1n2
. e
i2π(ϕn1ϕn2)}
= ∪
r2,ϕr2∈R2,n,ϕn2∈I2,r1,ϕr1∈R1,n1,ϕn1∈I1
× {√3 r2
3 + r1
3 − r2
3r1
3
. e
i2π√3 ϕr2
3+ϕr1
3−ϕr2
3ϕr1
3
, n2n1. e
i2π(ϕn2ϕn1)}
= Z2 ⊕ Z1
Z1 ⊗ Z2 = ∪
r1
,ϕr1∈R1
,n1
,ϕn1∈I1
,r2
,ϕr2∈R2
,n2
,ϕn2∈I2
× {r1r2. e
i2π(ϕr1ϕr2
)
,√3 n1
3 + n2
3 − n1
3n2
3
. e
i2π√3 ϕn1
3+ϕn2−3ϕn1
3ϕn2
3}
= ∪
r2,ϕr2∈R2,n2,ϕn2∈I2,r1,ϕr1∈R1,n1,ϕn1∈I1
× {r2.r1e
i2π(ϕr2ϕr1)
,√3 n2
3 + n1
3 − n2
3n1
3
. e
i2π√3 ϕn2
3+ϕn1−3ϕn2
3ϕn1
3}
= Z2 ⊗ Z1
(Z1 ⊕ Z2) ⊕ Z3 = ∪
r1,ϕr1∈R1,n1,ϕn1∈I1,r2,ϕr2∈R2,n2,ϕn2∈I2,r3,ϕr3∈R3,n3,ϕn3∈I3
×
= Z1 ⊕ (Z2 ⊕ Z3)
⎧
⎪⎨
⎩
√3 r1
3 + r2
3 + r3
3 − r1
3r2
3 − r2
3r3
3
.
e
i2π√3 ϕr1
3+ϕr2
3−ϕr1
3ϕr2
3−ϕr2
3ϕr3
n1n2n3.
e
i2π(ϕn1ϕn2ϕn3)
⎫
⎪⎬
⎭
Λ(Z1 ⊕ Z2) = ∪
r1,ϕr1∈R1,n1,ϕn1∈I1,r2,ϕr2∈R2,n2,ϕn2∈I2
= ∪
r1,ϕr1∈R1,n1,ϕn1∈I1
{√3 1 − (1 − r1
3)
Λ
. e
i2π√3 1−(1−ϕr1
3)
Λ
, n1
Λ
. e
i2π(ϕn1
Λ)}
⊕ ∪
r2,ϕr2∈R2,n2,ϕn2∈I2
{√3 1 − (1 − r2
3)
Λ
. e
i2π√3 1−(1−ϕr2
3)
Λ
, n2
Λ
. e
i2π(ϕn2
Λ)}
= ΛZ1 ⊕ ΛZ2
⎧
⎪⎨
⎩
√3 1 − (1 − r1
3 + r2
3 + r1
3r2
3)
Λ
.
e
i2π√3 1−(1−ϕr1
3+ϕr2
3+ϕr1
3ϕr2
3)
Λ
,
(n1n2)
Λ
.
e
i2π((ϕn1ϕn2)
Λ)
⎫
⎪⎬
⎭v. 
vi. 
2.4 MATHEMATICAL MODELLING
The main goal of this section is to formulate a CFHF-MOGSTP for the safe and ecological
friendly transit of HW. For this, availability, demands, and capacity of conveyances are taken as
CFHFN. The nature of all other factors, including TC, SC, and CE, is crisp. Here, we strive to
reduce TC for economic reasons; we make a desire to reduce CE for the sake of the environment.
Also, as safety is a major concern in the transit of HW, we work to reduce SC. Notations that are
utilized in the proposed model are listed in Table 2.2.
Table 2.2 Notations
i Origins Integer
j Destinations Integer
r Conveyances Integer
˜a
z
i Availability of ith source CFHFN
˜b
z
j Demand of jth destination CFHFN
e˜
z
r Capacity of rth conveyance CFHFN
ai Availability of ith source Real
bj Demand of jth destination Real
er Capacity of rth conveyance Real
(Z1 ⊗ Z2) ⊗ Z3 = ∪
r1,ϕr1∈R1,n1,ϕn1∈I1,r2,ϕr2∈R2,n2,ϕn2∈I2,r3,ϕr3∈R3,n3,ϕn3∈I3
×
= Z1 ⊗ (Z2 ⊗ Z3)
⎧
⎪⎨
⎩
r1r2r3
e
i2π(ϕr1ϕr2ϕr3
)
√3 n1
3 + n2
3 + n3
3 − n1
3n2
3 − n2
3n3
3
.
e
i2π√3 ϕn1
3+ϕn2
3+ϕn3
3−ϕn1
3ϕn2
3−ϕn2
3ϕn3
3
⎫
⎪⎬
⎭
Z
Λ1+Λ2 = ∪
r,ϕr∈R,n,ϕn∈I
{r
Λ1+Λ2 . e
i2π(ϕr
Λ1+Λ2)
,√3 1 − (1 − n3)
Λ1+Λ2
. e
i2π√3 1−(1−ϕn
3)
Λ1+Λ2}
= ∪
r,ϕr∈R,n,ϕn∈I
{rΛ1 . e
i2π(ϕr
Λ1)
,√3 1 − (1 − n3)
Λ1 . e
i2π√3 1−(1−ϕn
3)
Λ1}
⊕ ∪
r,ϕr∈R,n,ϕn∈I
{rΛ1 . e
i2π(ϕr
Λ1)
,√3 1 − (1 − n3)
Λ1
. e
i2π√3 1−(1−ϕn
3)
Λ1}
= Z
Λ1 ⊕ Z
Λ1
Symbol Description Typexijr
Quantity of goods carried by rth conveyances from ith origin to jth
destination
Real
cijr
Transportation cost per unit from ith origin to jth destination via rth
conveyances
Integer
sijr Safety cost per unit from ith origin to jth destination via rth conveyances Integer
mijr
Unit carbon emission per kilometre by rth conveyances from ith origin to
jth destination
Integer
Zs Objective function (s = 1, 2, 3) Real
The mathematical formulation of CFHF-MOGSTP for green, safe transit of HW is as follows:
Model 1
Minimization of transportation cost
MinZ1 =
I
∑
i=1
J
∑
j=1
R
∑
r=1
(cijrxijr)
Minimization of safety cost
MinZ2 =
I
∑
i=1
J
∑
j=1
R
∑
r=1
(sijrxijr)
Minimization of carbon emission
MinZ3 =
I
∑
i=1
J
∑
j=1
R
∑r=1
(mijrxijr)
s.t.
J
∑
j=1
R
∑
r=1
xijr ≤ ˜a
z
i
, i = 1,…, I
I
∑
i=1
R
∑
r=1
xijr ≥ ˜b
z
j
, j = 1,…, J
I
∑
i=1
J
∑
j=1
xijr ≤ e˜
z
r
, r = 1,…, R
xijr ≥ 0, ∀i, j, r
The conditions of feasibility for our proposed model 1 are as follows:
Symbol Description TypeI
∑
i=1
˜a
z
i ≥
J
∑
j=1
˜b
z
j
;
R
∑
r=1
e˜
z
r ≥
J
∑
j=1
˜b
z
j
;
The formulated model 1 is with CFHF parameters, and it is a herculean task to tackle it in this
form. Thus, we make use of proposed ranking function for defuzzification to discover the
deterministic form of model 1, so that we can solve it indisputably.
Model 2
Minimization of transportation cost
MinZ1 =
I
∑
i=1
J
∑
j=1
R
∑r=1
(cijrxijr)
Maximization of safety cost
MinZ2 =
I
∑
i=1
J
∑
j=1
R
∑
r=1
(sijrxijr)
Minimization of carbon emission
MinZ3 =
I
∑
i=1
J
∑
j=1
R
∑r=1
(mijrxijr)
s.t.
J
∑
j=1
R
∑
r=1
xijr ≤ S (˜a
z
i), i = 1,…, I
I
∑
i=1
R
∑
r=1
xijr ≥ S (˜b
z
j), j = 1,…, J
I
∑
i=1
J
∑
j=1
xijr ≤ S (e˜
z
r), r = 1,…, R
xijr ≥ 0, ∀i, j, r
The conditions of feasibility for our proposed model 2 are as follows:
I
∑
i=1
S (˜a
z
i) ≥
J
∑
j=1
S (˜b
z
j);
R
∑r=1
S (e˜
z
r) ≥
J
∑
j=1
S (˜b
z
j);
2.5 SOLUTION PROCEDUREWe devised a method to solve the CFHF-MOGSTP for the management of HW using our newly
proposed ranking function and FP. The suggested algorithm is systematically shown in Figure 2.2.
This figure depicts several steps involved in the proposed methodology to tackle the proposed
solid transportation system.
Figure 2.2 Pictorial representation of proposed methodology.
Step 1: Integrate our defuzzification function with our proposed transportation model 1 to
create a deterministic framework.
Step 2: Consider all restrictions while addressing each objective separately.
Step 3: Find the lower (Ls) and upper bounds (Us) for each objective function and obtain the
corresponding membership function for each objective.
Ωs (Zs (X)) =
where s = 1, 2, 3
Step 4: To get pareto optimal solution for model 1, tackle model 3 for degree of acceptance ψ
by employing the LINGO software.
Model 3
Max ψ
s.t. Ωs (Zs (x)) ≥ ψ(s = 1, 2, 3)
⎧
⎪⎨
⎩
1 Zs ≤ Ls
Us−Zs(X)
Us−Ls Ls ≤ Zs ≤ Us
0 Zs ≥ UsJ
∑
j=1
R
∑
r=1
xijr ≤ S (˜a
z
i), i = 1,…, I
I
∑
i=1
R
∑r=1
xijr ≥ S (˜b
z
j), j = 1,…, J
I
∑
i=1
J
∑
j=1
xijr ≤ S (e˜
z
r), r = 1,…, R
xijr ≥ 0, ∀i, j, r
ψ ∈ [0, 1]
2.6 NUMERICAL COMPUTATION
This section aims to demonstrate the significance of the suggested transportation model for
achieving sustainability in the management of hazardous waste, which will be illustrated with an
example. Let us consider a case study where HW is transported from two industries to two
different treatment sites via two modes of transportation to minimize TC, SC, and CE
simultaneously. All essential inputs are embedded in Table 2.3, Table 2.4, Table 2.5 and Table 2.6.
Table 2.3 Input for TC
1 1 1 {12}
2 {16}
2 1 {14}
2 {13}
2 1 1 {17}
2 {13}
2 1 {12}
2 {10}
Table 2.4 Input for safety cost
1 1 1 {8}
2 {5}
2 1 {3}
Source (i) Destination (j) Conveyances (k) Transportation cost
Source (i) Destination (j) Conveyances (k) Carbon emission2 {2}
2 1 1 {8}
2 {5}
2 1 {2}
2 {9}
Table 2.5 Input for carbon emission
1 1 1 {2}
2 {6}
2 1 {4}
2 {3}
2 1 1 {7}
2 {5}
2 1 {2}
2 {1}
Table 2.6 CFHFN availability, demand, and capacity of conveyances
˜a
z
1 (100, { }, { })
131.1
˜a
z
2 (110, { }, { })
55.66
˜b
z
1 (70, { }, { })
46.935
˜b
z
2 (85, { }, { })
75.14
e˜
z
1 (90, { }, { })
100.35
Source (i) Destination (j) Conveyances (k) Carbon emission
Source (i) Destination (j) Conveyances (k) Transportation time
Parameters CFHFN Score value
0.7e
i2π0.6
,
0.6e
i2π0.2
0.4e
i2π0.7
,
0.1e
i2π0.4
0.1e
i2π0.2
,
0.2e
i2π0.4
0.5e
i2π0.6
,
0.8e
i2π0.6
0.4e
i2π0.6
,
0.6e
i2π0.2
0.4e
i2π0.9
,
0.3e
i2π0.7
0.1e
i2π0.6
,
0.3e
i2π0.6
0.5e
i2π0.7
,
0.2e
i2π0.6
0.2e
i2π0.7
,
0.7e
i2π0.2
0.4e
i2π0.7
,
0.1e
i2π0.4e˜
z
2 (75, { }, { })
59.7
Minimization of transportation cost
MinZ1 = 12x111 + 16x112 + 14x121 + 13x122 + 17x211 + 13x212 + 12x221 + 10x222
Minimization of safety cost
Minimization of carbon emission
s.t. x111 + x112 + x121 + x122 ≤ 131.1
x211 + x212 + x221 + x222 ≤ 55.66
x111 + x112 + x211 + x212 ≥ 46.935
x121 + x122 + x221 + x222 ≥ 75.14
x111 + x121 + x211 + x221 ≤ 100.35
x112 + x122 + x212 + x222 ≤ 59.7
xijr ≥ 0, ∀i, j, r
Now, considering each objective at a time, we will find the optimal solution for all four objectives
in the TP. The optimal solution of all objective functions obtained by using a single objective at a
time are depicted in Table 2.7.
Table 2.7 Solution of different objectives of MOGSTP
Transportation
cost
Z1 = 1404,
x111 = 47, x112 = 0, x121 = 17, x122 = 4, x211 = 0, x212 = 0, x221 = 0, x22
Safety cost Z2 = 396,
x111 = 47, x112 = 0, x121 = 9, x122 = 12, x211 = 0, x212 = 0, x221 = 55, x2
Carbon
emission
Z3 = 229,
x111 = 47, x112 = 0, x121 = 17, x122 = 4, x211 = 0, x212 = 0, x221 = 0, x22
Parameters CFHFN Score value
0.2e
i2π0.6
,
0.5e
i2π0.2
0.4e
i2π0.4
,
0.5e
i2π0.8
MinZ2
8x111 + 5x112 + 3x121 + 2x122 + 8x211 + 5x212 + 2x221 + 9x222
MinZ3
2x111 + 6x112 + 4x121 + 3x122 + 7x211 + 5x212 + 2x221 + 1x222
Objective SolutionThe following are upper and lower bounds for each objective that are utilized to get the solution
by employing FP.
U1 = 1694,L1 = 1404,U2 = 930,L2 = 396,U3 = 464,L3 = 229
By following the steps involved in the proposed methodology, we formulate model 3. Here, our
main aim is to maximize ψ.
Model 3
534 ψ + 8x111 + 5x112 + 3x121 + 2x122 + 8x211 + 5x212 + 2x221 + 9x222 ≤ 930
x111 + x112 + x121 + x122 ≤ 464
x211 + x212 + x221 + x222 ≤ 55.66
x111 + x112 + x211 + x212 ≥ 46.935
x121 + x122 + x221 + x222 ≥ 75.14
x111 + x121 + x211 + x221 ≤ 100.35
x112 + x122 + x212 + x222 ≤ 59.7
The pareto optimal solution of above problem by utilizing FP with the help of LINGO 18 is as
follows:
φ = 0.7003745, Z1 = 1489,Z2 = 556,Z3 = 263
x111 = 47, x112 = 0, x121 = 21, x122 = 0, x211 = 0, x212 = 0, x221 = 51, x222 = 4.
The comparison of objective values obtained by utilizing the proposed methodology is depicted in
Figure 2.3. Here, the optimal value of the first objective, i.e., TC is 1489, while the optimal value
of the second objective, i.e., SC is 556. Optimal CE is 263 which is our third objective that is to
be minimized.
Max ψ
s.t. 290 ψ + 12x111 + 16x112 + 14x121 + 13x122 + 17x211
+ 13x212 + 12x221 + 10x222 ≤ 1694
235 ψ + 2x111 + 6x112 + 4x121 + 3x122 + 7x211
+ 5x212 + 2x221 + 1x222 ≤ 1348.645Figure 2.3 Achievement value of three objectives in CFHF-MOGSTP.
2.7 CONCLUSION
We introduced CFHFS as an extension of CFS to address the redundant nature of uncertainty,
incompleteness, inconsistency, etc. A CFHFS is characterized by a complex-valued MD and NMD
along with hesitancy satisfying the properties of FFS. The chapter also outlines a CFHFS
interpretation and discusses certain set theoretic properties, such as the ranking methodology for
the defuzzification, that will escalate the appositeness of CFHFS to real-world problems.
Over the last quarter-century or more, industry and technological advancements have led to a
sharp increase in the production of hazardous compounds. The automation of different industries,
including the handling of hazardous waste, has increased as a result. To elaborate the applicability
of proposed set, a green three-dimensional transportation system with multiple objectives under
CFHF settings is also formulated for the risk free, sustainable transportation of HW. In order to
get the pareto optimal solution of the proposed model, first we converted the model into its
deterministic form with the help of score function, thereafter fuzzy programming is utilized to get
optimal solution. Then, we illustrate our suggested methodology using a real-world example of
the transportation of HW.
By making some enhancements in the work done in this chapter, researchers may be able to
recommend a number of interesting areas for further research. It is possible to further analyse
various aggregation methods based on novel sets in order to assess their applicability in Multi￾Criteria Decision Making (MCDM) issues. Due to its wide capabilities for addressing uncertainty,
our proposed set can be used to solve many different sorts of decision-making problems. Our
suggested green three-dimensional transport system can be expanded to a four-dimensional
transport system with various objectives under CFHF circumstances. Our suggested novel set is
applicable of handling a variety of optimization problems.
REFERENCES
Akram, Muhammad, Sundas Shahzadi, Syed Muhammad Umer Shah, and Tofigh
Allahviranloo. “An extended multi-objective transportation model based on Fermatean
fuzzy sets.” Soft Computing (2023): 1–23. https://doi.org/10.1007/s00500-023-08117-9Aktar, Md Samim, Manoranjan De, Sanat Kumar Mazumder, and Manoranjan Maiti. “Multi￾objective green 4-dimensional transportation problems for breakable incompatible items
with different fixed charge payment policies.” Computers & Industrial Engineering 156
(2021): 107184. https://doi.org/10.1016/j.cie.2021.107184
Alkouri, Abdulazeez (Moh’D. Jumah) S., and Abdul Razak Salleh. “Complex intuitionistic
fuzzy sets.” In AIP Conference Proceedings (vol. 1482, no. 1, pp. 464–470). American
Institute of Physics, 2012.
Ashraf, Shahzaib, Harish Garg, and Muneeba Kousar. “An industrial disaster emergency
decision-making based on China’s Tianjin city port explosion under complex
probabilistic hesitant fuzzy soft environment.” Engineering Applications of Artificial
Intelligence 123 (2023a): 106400. https://doi.org/10.1016/j.engappai.2023.106400
Ashraf, Shahzaib, Muneeba Kousar, and Muhammad Shazib Hameed. “Early infectious
diseases identification based on complex probabilistic hesitant fuzzy N-soft information.”
Application of Soft Computing 27 (2023b): 1–26.
Atanassov, Krassimir T., and S. Stoeva. “Intuitionistic fuzzy sets.” Fuzzy Sets and Systems
20, no. 1 (1986): 87–96. https://doi.org/10.1016/S0165-0114(86)80034-3
Bind, Awdhesh Kumar, Deepika Rani, Kapil Kumar Goyal, and Ali Ebrahimnejad. “A
solution approach for sustainable multi-objective multi-item 4D solid transportation
problem involving triangular intuitionistic fuzzy parameters.” Journal of Cleaner
Production (2023): 137661. https://doi.org/10.1016/j.jclepro.2023.137661
Chinnadurai, V., S. Thayalan, and A. Bobin. “Multi-criteria decision-making in complex
Fermatean fuzzy environment.” Journal of Mathematics and Computer Science 11, no. 6
(2021): 7209–7227.
Cuong, Bui Cong, and V. Kreinovich. “Picture fuzzy sets.” Journal of Computer Science and
Cybernetics 30, no. 4 (2014): 409–420.
Das, Soumen Kumar, Sankar Kumar Roy, and Gerhard-Wilhelm Weber. “Application of
type-2 fuzzy logic to a multiobjective green solid transportation–location problem with
dwell time under carbon tax, cap, and offset policy: Fuzzy versus nonfuzzy techniques.”
IEEE Transactions on Fuzzy Systems 28, no. 11 (2020): 2711–2725.
https://doi.org/10.1109/TFUZZ.2020.3011745.
El-Saadony, Mohamed T., Ahmed M. Saad, Nahed A. El-Wafai, Hamed E. Abou-Aly, Heba
M. Salem, Soliman M. Soliman, Taia A. Abd El-Mageed et al. “Hazardous wastes and
management strategies of landfill leachates: A comprehensive review.” Environmental
Technology & Innovation (2023): 103150. https://doi.org/10.1016/j.eti.2023.103150
Garg, Harish, Tahir Mahmood, Ubaid ur Rehman, and Zeeshan Ali. “CHFS: Complex
hesitant fuzzy sets‐their applications to decision making with different and innovative
distance measures.” CAAI Transactions on Intelligence Technology 6, no. 1 (2021): 93–
122. https://doi.org/10.1049/cit2.12016
Ghalehkhondabi, Iman, Reza Maihami, and Ehsan Ahmadi. “Optimal pricing and
environmental improvement for a hazardous waste disposal supply chain with emission
penalties.” Utilities Policy 62 (2020): 101001. https://doi.org/10.1016/j.jup.2019.101001
Ghosh, Shyamali, Karl-Heinz Küfer, Sankar Kumar Roy, and Gerhard-Wilhelm Weber.
“Carbon mechanism on sustainable multi-objective solid transportation problem for waste
management in Pythagorean hesitant fuzzy environment.” Complex & Intelligent Systems
8, no. 5 (2022): 4115–4143. https://doi.org/10.1007/s40747-022-00686-wGhosh, Shyamali, Sankar Kumar Roy, and Gerhard-Wilhelm Weber. “Interactive strategy of
carbon cap-and-trade policy on sustainable multi-objective solid transportation problem
with twofold uncertain waste management.” Annals of Operations Research (2023): 1–
41. https://doi.org/10.1007/s10479-023-05347-w
Giri, Binoy Krishna, and Sankar Kumar Roy. “Neutrosophic multi-objective green four￾dimensional fixed-charge transportation problem.” International Journal of Machine
Learning and Cybernetics 13, no. 10 (2022): 3089–3112.
Hitchcock, Frank L. “The distribution of a product from several sources to numerous
localities.” Journal of Mathematics and Physics 20, no. 1–4 (1941): 224–230.
https://doi.org/10.1002/sapm1941201224
Janani, K., and R. Rakkiyappan. “Complex probabilistic fuzzy set and their aggregation
operators in group decision making extended to TOPSIS.” Engineering Applications of
Artificial Intelligence 114 (2022): 105010.
https://doi.org/10.1016/j.engappai.2022.105010
Kumar, Sunil, Somnath Mukherjee, Tapan Chakrabarti, and Sukumar Devotta. “Hazardous
waste management system in India: An overview.” Critical Reviews in Environmental
Science and Technology 38, no. 1 (2007): 43–71.
https://doi.org/10.1080/10643380701590356
Midya, Sudipta, Sankar Kumar Roy, and Vincent F. Yu. “Intuitionistic fuzzy multi-stage
multi-objective fixed-charge solid transportation problem in a green supply chain.”
International Journal of Machine Learning and Cybernetics 12 (2021): 699–717.
https://doi.org/10.1007/s13042-020-01197-1
Misra, Virendra, and S. D. Pandey. “Hazardous waste, impact on health and environment for
development of better waste management strategies in future in India.” Environment
International 31, no. 3 (2005): 417–431. https://doi.org/10.1016/j.envint.2004.08.005
Rabbani, Masoud, Razieh Heidari, and Reza Yazdanparast. “A stochastic multi-period
industrial hazardous waste location-routing problem: Integrating NSGA-II and Monte
Carlo simulation.” European Journal of Operational Research 272, no. 3 (2019): 945–
961. https://doi.org/10.1016/j.ejor.2018.07.024
Ramot, Daniel, Ron Milo, Menahem Friedman, and Abraham Kandel. “Complex fuzzy sets.”
IEEE Transactions on Fuzzy Systems 10, no. 2 (2002): 171–186.
Senapati, Tapan, and Ronald R. Yager. “Fermatean fuzzy sets.” Journal of Ambient
Intelligence and Humanized Computing 11 (2020): 663–674.
https://doi.org/10.1007/s12652-019-01377-0
Sharma, M. K., A. K. Bhargava, Sanjeev Kumar, Laxmi Rathour, Lakshmi Narayan Mishra,
and Shikha Pandey. “A fermatean fuzzy ranking function in optimization of intuitionistic
fuzzy transportation problems.” Advanced Mathematical Models & Applications 7, no. 2
(2022).
Shell, E. “Distribution of a product by several properties, Directorate of Management
Analysis.” In Proceedings of the Second Symposium in Linear Programming (vol. 2, pp.
615–642). Cambridge University Press, 1955.
Shivani, and Deepika Rani. “Multi-objective multi-item four dimensional green
transportation problem in interval-valued intuitionistic fuzzy environment.” International
Journal of System Assurance Engineering and Management (2022): 1–18.
https://doi.org/10.1007/s13198-022-01794-zSmarandache, F. “A unifying field in Logics: Neutrosophic Logic.” In Philosophy (pp. 1–
141). American Research Press, 1999.
Torra, Vicenç. “Hesitant fuzzy sets.” International Journal of Intelligent Systems 25, no. 6
(2010): 529–539. https://doi.org/10.1002/int.20418
Ullah, Kifayat, Tahir Mahmood, Zeeshan Ali, and Naeem Jan. “On some distance measures
of complex Pythagorean fuzzy sets and their applications in pattern recognition.”
Complex & Intelligent Systems 6 (2020): 15–27.
Vallero, D. A. “Hazardous wastes and the environment.” In Hazardous Waste Management
(pp. 3–32). Elsevier, 2022. https://doi.org/10.1016/B978-0-12-824344-2.00016-1
Yager, Ronald R. “Pythagorean fuzzy subsets.” In 2013 Joint IFSA World Congress and
NAFIPS Annual Meeting (IFSA/NAFIPS) (pp. 57–61). IEEE, 2013.
https://doi.org/10.1109/IFSA-NAFIPS.2013.6608375
Zadeh, Lotfi A. “Fuzzy sets.” Information and Control 8, no. 3 (1965): 338–
353.https://doi.org/10.1016/S0019-9958(65)90241-X
Zhang, Zhen, Muhammad Zeeshan Malik, Adnan Khan, Nisar Ali, Sumeet Malik, and
Muhammad Bilal. “Environmental impacts of hazardous waste, and management
strategies to reconcile circular economy and eco-sustainability.” Science of the Total
Environment 807 (2022): 150856. https://doi.org/10.1016/j.scitotenv.2021.150856
Zhou, Liang, Sadhna Chaudhary, Mukesh Kumar Sharma, Arvind Dhaka, and Amita Nandal.
“Artificial neural network dual hesitant fermatean fuzzy implementation in transportation
of COVID-19 vaccine.” Journal of Organizational and End User Computing (JOEUC)
35, no. 2 (2023): 1–23. https://doi.org/10.4018/JOEUC.321169
Zhu, Bin, Zeshui Xu, and Meimei Xia. “Dual hesitant fuzzy sets.” Journal of Applied
Mathematics 2012 (2012). https://doi.org/10.1155/2012/879629Chapter 3
A framework of hybrid metaheuristic H￾Grey optimization for embedding factor
decision-making in digital image
watermarking on social media
Kilari Jyothsna Devi and Priyanka Singh
DOI: 10.1201/9781003536796-3
3.1 INTRODUCTION
As science and technology continue to progress, the global landscape is
increasingly transitioning toward electronic mediums such as E-Games, E￾Commerce websites, E-Business, and E-Stores. The social interactions of human
society have also shifted to virtual means with the advancement of technology
[1]. People can engage in conversations, share personal or professional
information, and create web content through a range of social media platforms
available. There are various social media platforms intended for different types of
social interactions like YouTube, Facebook, LinkedIn, Instagram, Snapchat,
WhatsApp, Twitter, etc. [2]. There are a lot of challenges in restricting and
limiting criminal or illegal activities via social media platforms. Figure 3.1 shows
issues related to social media platforms while transferring images. Multimedia
contents like audio, video, text, and images are the primary sources of
communication in social media platforms. Among these, digital images are the
main sources of communication nowadays [3]. Digital image sharing on social
media raises several security concerns, including unauthorized access, copying,
manipulating, morphing, and tampering with the contents of the image. So, while
sharing digital images over the internet, security is crucial. Also sharing of digitalimages on social media platforms is fraught with various concerns like copyright
and asset protection issues, digital image forgery, and metadata issues. To handle
all these issues, digital image watermarking (DIW) is the prominent approach [4].
Figure 3.1 Data transfer through social media platforms and the related
concerns.
DIW is a process of hiding digital data. Usually, the watermark is embedded in
the spectral domain which is more robust. So, the embedding will be robust
against the different types of attacks in the transmission. Essential characteristics
of DIW are robustness, imperceptibility, capacity, and security [5]. However, it iscrucial to maintain all these characteristics (imperceptibility, robustness, and
embedding capacity) in a single watermarking scheme, and there is always a
trade-off among them. In order to solve this, an optimum scaling factor (α) has to
be used in the embedding process. A significant scaling factor may be generated
with the use of an effective fitness function. To address these, we propose a
hybrid redundant discrete wavelet transform (RDWT) – singular value
decomposition (SVD) DIW scheme with high imperceptibility, robustness, and
security. To balance watermarking characteristics, hybrid Harmony-Greywolf (H￾Grey) optimization is proposed.
The remaining portion of the chapter is organized as follows: Section 3.2
describes related work, Section 3.3 describes proposed scheme, Section 3.4
elaborates experimental results and discussion, and finally Section 3.5 concludes
the chapter.
3.2 RELATED WORK
Various watermarking approaches in the spatial, spectral, and hybrid domains
have been investigated by researchers during the last few decades. The
fundamental objective of any DIW technique is to demonstrate its resilience to
various attacks while minimizing visual quality degradation caused by watermark
insertion.
Entropy-based spatial domain image watermarking and its performance
analysis are presented by Kumar and Singh [6]. LSB embedding and Hill Cipher
is presented and examined in this chapter. Radouane et al. [7] make use of the
standard LSB substation technique with the idea of information theory for image
watermarking in the spatial domain. The cover image is divided into blocks, and
the watermark is inserted in the block(s) with the highest entropy value. The
extraction technique may also accurately identify the watermark. Similarly, Wang
et al. [8] proposed an elementary LSB to inject fundamental data in the cover
image such that the presence of the data in the image will not be noticed by the
interceptor. To obtain the high-quality result, they used the genetic algorithm to
hide the watermark in the rightmost k-LSB of the cover image. Rinki et al. [9]
proposed a matrix multiplication LSB technique for watermark embedding to
ensure authentication.
The schemes proposed in [6, 7, 8, 9] use spatial domain for watermark
embedding process. Generally, spatial approaches are more imperceptible than
the transform schemes, but they lagged in robustness. To resolve this issue, many
of the researchers suggested watermarking schemes in the transform domain.Some of the watermarking techniques that utilized the transform domain for
embedding process are listed below.
Tarhouni et al. [10] present a robust watermarking scheme for copyright
protection and integrity verification using discrete cosine transforms for color
images. Also, Su et al. [11] proposed an optical asymmetric cryptography and
variational image decomposition (VID)-based grayscale image watermarking
technique. Similarly, Roy et al. [12] proposed a robust image watermarking
system in lifting wavelet transform (LWT) domain using different sub-bands. In
this work, support vector machine (SVM) with modified feature vector set has
been incorporated during watermark extraction. Also, Su and Chen [13] proposed
a robust Discrete Cosine Transform (DCT)-based spatial embedding scheme. Wan
et al. [14] proposed a DCT and just noticeable difference (JND) model for
embedding in spatial domain for copyright protection. Alzahrani and Memon [15]
proposed a discrete wavelet transform (DWT), singular value decomposition
(SVD), and DCT-based transform scheme for copyright protection.
According to the literature study, there is a trade-off between watermarking
features such as robustness and imperceptibility, in which the imperceptibility is
high yet the cost of computing is also high. There is a need to balance
watermarking features.
3.3 PROPOSED SCHEME
This section elaborates on watermark embedding as well as extraction process in
the hybrid RDWT-SVD transform domain to attain higher imperceptibility and
durability, with security under various digital image processing attacks. The
proposed scheme is elaborated under three sub-sections: (i) watermark
embedding and extraction process, (ii) watermark encryption and decryption, and
(iii) embedding strength factor (α) optimization using the hybrid H-Grey
optimization process.
3.3.1 Watermark embedding and extraction
A cover image (CI) of size M × N and a watermark (WI) of size A × B is
considered in the proposed scheme for embedding and extraction process. WI is
embedded in CI using hybrid RDWT-SVD transform. Firstly, RDWT is applied
on CI and is subdivided into four sub-bands LL, LH, Hl, and HH. LH, HL sub￾band is taken for watermark embedding. SVD is applied on LH, HL sub-bands; it
further decomposed into U, S, V (ULH, SLH, VLH, UHL, SHL, VHL) matrices.
RDWT-SVD hybrid transformation decomposition is shown in Figure 3.2. Usinga cross diagonal process, encrypted watermark is embedded into SLH, SH using
the optimized scaling factor (α). The process of watermark embedding is
explained in Algorithm 3.1. And the cross diagonal embedding process is
elaborated in Figure 3.3. The block diagram for the embedding process is shown
in Figure 3.4. The process of watermark encryption is given in Section 3.2. The
process of optimized ƥ generation is explained in Section 3.3.
Figure 3.2 Hybrid RDWT-SVD decomposition.Figure 3.3 Cross diagonal embedding process.Figure 3.4 Block diagram for watermark embedding process.
Algorithm 3.1: Watermark embedding process
Require: Cover image (CI) of size M × N, Encrypted Watermark (WIe
)
sub-samples (S1
,S2
,S3
,S4
) of size A/2 × B/2, optimized α
Ensure: Watermarked Image (CI’)Step 1: Apply RDWT on CI; it decomposed into LL, LH, HL, and HH
sub-bands.
Step 2: Select LH, HL, and apply SVD; it further splits into ULH, SLH,
VLH, UHL, SHL, and VHL.
Step 3: Select SLH and SHL for Wie
 sub-samples embedding.
Step 4: Partition SLH and SHL into 4 × 4 non-overlapping blocks (BLH,
BHL)
Step 5: Embed S1 and S3
in upper diagonal portion of BLH and BHL.
Also, embed S2 and S4
in lower diagonal portion of BLH and BHL using
optimized α.
BLH’ = BLH(upperdiagonal) + S1
 * ƥ
BHL’ = BHL(upperdiagonal) + S3
 * ƥ
BLH’ = BLH(lowerdiagonal) + S2
 * ƥ
BHL’ = BHL(lower diagonal) + S4
 * ƥ
Step 6: Perform inverse SVD and RDWT to get watermarked image
(CI’).
The watermark extraction is reverse process of embedding. The embedding
watermark samples S1
’S2
’
, S3
’
, S4
’are extracted from the CI’ at the receiver end
using side information. The algorithmic steps for the watermark extraction
process as explained in Algorithm 3.2 and the block diagram as shown in Figure
3.5.Figure 3.5 Block diagram for watermark embedding process.
Algorithm 3.2: Watermark extraction process
Require: Watermark image (CI’) of size M × N, optimized α, SLH, SHL
Ensure: Encrypted Watermark (WIe’) sub-samples (S1
’
,S2
’
,S3
’
,S4
’
) of
size A/2 × B/2Step 1: Apply RDWT on CI’; it decomposed into LL’, LH’, HL’, and
HH’ sub-bands.
Step 2: Select LH’, HL’ and apply SVD; it further splits into ULH’,
SLH
’
, VLH
’
, UHL
’
, SHL
’
, and VHL
’
.
Step 3: Select SLH
’
 and SHL
’
 for Wie
’
 sub-samples extraction.
Step 4: Partition SLH
’ and SHL
’
into 4 × 4 non-overlapping blocks (BLH
’
,
BHL
’
)
Step 5: Extract S1
’ and S3
’
from the upper diagonal portion of BLH
’ and
BHL
’
. Also, extract S2
’
, S4
’
in lower diagonal portion of BLH
’ and BHL
’
using optimized α.
S1
’
 = (BLH’
(upper diagonal) – BLH (upper diagonal))/ƥ
S3
’
 = (BHL’
(upper diagonal) – BHL (upper diagonal))/ƥ
S2
’
 = (BLH’
(lower diagonal) – BLH (lower diagonal))/ƥ
S4
’
 = (BLH’
(lower diagonal) – BLH (lower diagonal))/ƥ
3.3.2 Watermark encryption and decryption
Maintaining watermark security is essential for image transmission over social
media. To attain higher watermark security in the proposed scheme, two-level
security is utilized. (i) In level 1, watermark is partitioned into four subsamples.
(ii) In level 2, the four subsamples are encrypted with randomly generated binary
random key using Latin square sequence. The detailed explanation for level 1 and
level 2 security process is given below.
3.3.2.1 Watermark encryption process
In level, a watermark (WI) A × B is partitioned into four subsamples S1, S2
, S3
,
and S4 using equations from Eq. (3.1) to Eq. (3.4). The resulting subsamples are
of size A/2 × B/2. Subsample of WI is illustrated in Figure 3.6.(3.1)
(3.2)
(3.3)
(3.4)
Figure 3.6 Watermark sub-sample partitioning.
A/2
∑
r=1
B/2
∑
c=1
S1 (r, c) =
A
∑
k=1
B
∑
l=1
WI (2r − 1)(2c − 1)
A/2
∑
r=1
B/2
∑
c=1
S2 (r, c) =
A
∑
k=1
B
∑
l=1
WI (2r − 1)(2c)
A/2
∑
r=1
B/2
∑
c=1
S3 (r, c) =
A
∑
k=1
B
∑
l=1
WI (2r)(2c − 1)
A/2
∑
r=1
B/2
∑
c=1
S4 (r, c) =
A
∑
k=1
B
∑
l=1
WI (2r)(2c)
The subsamples S1
, S2
, S3
, and S4 are encrypted using a randomly generated key
using the Latin square sequence. The generation of binary random key (RK
)
process is elaborated below.The Latin square sequence (LS) is a N × N matrix comprised of N different
symbols, each appearing only once in every line (row) and section (column). A 4
× 4 Latin square is shown in Figure 3.7.
Figure 3.7 4 × 4 Latin square.
In the proposed scheme, LS of size A/2 × B/2 is considered as RK1
for
watermark samples encryption. Encryption of watermark using LS is performed
using shuffling process. Watermark bits are shuffled with respect to LS position
in row and column transformation. The process of row and column
transformations with respect to Latin square is shown in Figure 3.8. In the
proposed scheme, RK1 of size A/2 × B/2 is taken for watermark samples (S1
, S2
,
S3
, and S4
) encryption process. RK1 is reversed to produce RK2. Using RK1, the
watermark samples S1
, S3 and also by using RK2, the watermark samples S2
, S4
,
respectively, were encrypted. The process of encryption is shown in Figure 3.9.
To maintain security, the secret keys RK1 and RK2 were sent to the receiver
secretly through a third party.Figure 3.8 Row and column transformation shuffling with respect to
Latin square.Figure 3.9 Watermark encryption process with respect to RK1
 and RK2
.
Watermark decryption is the reverse process of encryption. Upon receiving the
watermarked image by the receiver, watermark samples S1
’
, S2
’
, S3
’
, and S4
’ were
extracted by the receiver using the same process used in the embedding step.
Furthermore, encrypted samples are decrypted using secretly received RK1 and
RK2
 keys. The process of decryption is shown in Figure 3.10.Figure 3.10 Watermark decryption process with respect to RK1
 and RK2
.
Embedding strength factor (α) optimization using hybrid H-Grey
To balance watermarking characteristics (imperceptibility, robustness) in the
proposed scheme, embedding strength factor is chosen as optimized scaling factor
using hybrid Harmony-Greywolf (H-Grey) optimization technique. In the
proposed scheme, to balance exploration and exploitation search behavior of
optimization algorithms, Harmony algorithm is integrated with Greywolf. The
harmony optimization process is poor at exploration and selecting pitch
adjustment rate and bandwidth parameters were difficult. To overcome these
limitations, Greywolf is integrated. The process of H-Grey optimization steps and
optimization function is seen in [16].
3.4 EXPERIMENTAL RESULTS AND DISCUSSION
In this section, experimental results for the proposed scheme is elaborated in
detail in terms of watermarking characteristics such as imperceptibility,
robustness, and security features.Thet test grayscale and color images were taken from the USC – SIPI image
dataset, resized to 512 × 512, and binary watermark of size 256 × 256 has been
taken for the experimentation as shown in Figure 3.10.
The subjective imperceptibility performance of the proposed scheme is shown
in Figure 3.11. In Figure 3.11, visual quality of all the cover images and
watermarked images are identical. Furthermore, the objective performance of the
proposed scheme is analyzed by optimized α using the hybrid H-Grey
optimization process. The imperceptibility of experimental results is evaluated
using Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index
Measure (SSIM). The mathematical relations for PSNR and SSIM as in [17]. The
PSNR and SSIM results for the proposed scheme with random ƥ and with
optimized H-Grey α is shown in Table 3.1.
Table 3.1 PSNR, SSIM, NC, BER (under zero attacks) for the test cover images
taken from USC- SIPI [] with random α and optimized α (using H-Grey)
Img1 56.36 0.9999 0.9989 0.0053 54.17 1 1 0
Img2 55.82 1 0.9964 0.0063 53.91 1 1 0
Img3 59.27 1 0.9984 0.0037 56.28 1 1 0
Img4 52.61 1 0.9958 0.0106 51.06 1 1 0
Img5 53.85 1 0.9952 0.0028 51.63 1 1 0
Color Images
With random α With H-Grey α
Image PSNR SSIM NC BER PSNR SSIM NC BER
Img6 60.73 1 0.9906 0.0127 57.89 1 1 0
Img7 63.82 1 0.9906 0.0085 59.26 1 1 0
Img8 59.97 1 0.9921 0.0068 55.18 1 1 0
Img9 62.64 1 0.9937 0.0049 58.61 1 1 0
Img 10 61.83 1 0.9962 0.0038 57.36 1 1 0
Grayscale images
With random α = 0.001 With H-Grey α
Image PSNR SSIM NC BER PSNR SSIM NC BERAverage
of 30
images
56.37 0.9999 0.9916 0.0136 53.84 1 1 0
Grayscale images
With random α = 0.001 With H-Grey α
Image PSNR SSIM NC BER PSNR SSIM NC BERFigure 3.11 Test cover images (grayscale from (a) to (e), and color from
(1) to (5); watermarked images grayscale from (a) to (e), and color from
(1) to (5); and extracted watermark images (a)–(e) and (1)–(5)).
From Table 3.1, it can be observed that, for all test images, PSNR and SSIM is
greater than or equal to the threshold value 37dB, with random α = 0.01 and with
optimized H-Grey α. The average PSNR and SSIM for the 30 test cover images is
greater than the threshold for both random α and optimized α, which indicates
that the proposed scheme shows higher imperceptibility performance for both α
values. Furthermore, the robustness performance is studied below.
The robustness performance of the proposed scheme is shown in Figure 3.10.
From Figure 3.10, it can be observed that for all the test images the extracted
watermark images are similar to the original watermark images. Furthermore, the
objective results are analyzed with normalized correlation (NC) and bit error rate
(BER) metrics. The mathematical relations for NC and BER are as shown in [18].
The NC, BER results for the proposed scheme using random α = 0.01 and
optimized H-Grey α are shown in Table 3.1. From Table 3.1, it can be observed
that, NC, BER for all test images are higher than the threshold value 0.75, 0.4,
respectively with both random α and optimized α. An average NC and BER for
30 images with random α as 0.9916, 0.0136, and optimized α as 1, 0, respectively.
From this, it can be observed that the proposed hybrid H-Grey optimization
improves the robustness performance of the scheme while maintain high visual
quality under zero attacks. Furthermore, the robustness performance of the
proposed scheme is tested under different image processing attacks, such as
filtering attacks (Gaussian filter, median filter, sharpening, histogram equivalent);
noising attacks (salt and pepper noise, Poisson noise, Gaussian noise); and also
geometric attacks (scaling, rotation, resize) as shown in Table 3.2. From Table
3.2, all image processing attacks with random α result in NC above 0.7 and BER
below 0.1. With optimized α using H-Grey shows improved performance of NC,
BER than the random α, is almost reaching to ideal value, which shows that the
proposed scheme is robust under different attacks.
Table 3.2 NC, BER for Img1 under different image processing
attacks with random α and with optimized H-Grey α
Median filter (3 × 3) 0.9921 0.0195 0.9999 0
Gaussian filter (3 × 3) 0.9842 0.0264 1 0
Attack
With random α With H-Grey α
NC BER NC BERSharpening 0.9913 0.0093 1 0
Salt and pepper (0.002) 0.9281 0.0586 0.9842 0.0012
Gaussian noise (0.002) 0.9123 0.0315 0.9627 0.0054
Poisson noise 0.8952 0.0736 0.9241 0.0085
Resize (356 × 356) 0.7852 0.0972 0.9041 0.0096
Scaling (0.25, 0.25) 0.7925 0.0824 0.8961 0.0102
Rotation (10o
) 0.7257 0.1002 0.8203 0.0271
From this discussion, it can be concluded that the proposed scheme shows high
visual quality and robustness characteristics by maintaining an embedding
capacity of 0.25 bpp.
Furthermore, the security of the proposed encryption process is analyzed in
terms of entropy metric. The entropy connection, as described in [17]. The
entropy experimental results for the five test binary watermark images shown in
Figure 3.12 are elaborated in Table 3.3. From Table 3.3, it can be observed that
the entropy of all stated images before encryption is lower than the after
encryption. From this, it can be concluded that the proposed encryption approach
adds more randomness to the encrypted images and it is difficult for the attacker
to extract original watermark without knowing both the encryption procedure and
random secret key.
Attack
With random α With H-Grey α
NC BER NC BERFigure 3.12 Binary watermark images.
Table 3.3 Entropy of different watermark images before and after
encryption
Watermark 1 0.5271 0.9827
Watermark 2 0.4971 0.9126
Watermark 3 0.5927 0.7926
Watermark 4 0.4394 0.8826
Image Entropy before encryption Entropy after encryptionWatermark 5 0.6026 0.9371
3.5 CONCLUSIONS
In this chapter, a hybrid watermarking approach is proposed for secure and robust
digital image transmission over social media applications. To handle trade-offs in
watermarking characteristics and as well to balance exploration and exploitation
capabilities of optimization algorithms, a hybrid H-Grey optimization algorithm
is utilized. To ensure high watermark security, a two-level encryption technique is
proposed. The experimental results show higher watermarking features even
under majority of attacks. In the future, we wish to design a watermarking
approach utilizing machine learning approaches.
REFERENCES
1. Dhiman, D. B. (2023). Key issues and new challenges in new media
technology in 2023: A critical review. Journal of Media & Management,
5(1), 1–4.
2. Dhiman, D. B. (2023). Ethical Issues and Challenges in Social Media: A
Current Scenario. Available at SSRN 4406610.
https://doi.org/10.20944/preprints202303.0513.v1.
3. Chen, Y., Sherren, K., Smit, M., & Lee, K. Y. (2023). Using social media
images as data in social science research. New Media & Society, 25(4), 849–
871.
4. Pavan, A. C., & Somashekara, M. T. (2023). An overview on research trends,
challenges, applications and future direction in digital image watermarking.
International Research Journal on Advanced Science Hub, 5(1), 8–14.
5. Singh, O. P., Singh, A. K., Srivastava, G., & Kumar, N. (2021). Image
watermarking using soft computing techniques: A comprehensive survey.
Multimedia Tools and Applications, 80, 30367–30398.
6. Kumar, S., & Singh, B. K. (2021). Entropy based spatial domain image
watermarking and its performance analysis. Multimedia Tools and
Applications, 80, 9315–9331.
7. Radouane, M., Boujiha, T., Messoussi, R., Idrissi, N., & Roukh, A. (2013). A
method of LSB substitution based on image blocks and maximum entropy.
Image Entropy before encryption Entropy after encryptionInternational Journal of Computer Science Issue (IJCSI), 10, 371.
8. Wang, R. Z., Lin, C. F., & Lin, J. C. (2001). Image hiding by optimal LSB
substitution and genetic algorithm. Pattern Recognition, 34, 671–683.
9. Rinki, K., Verma, P., & Singh, R. K. (2022). A novel matrix multiplication
based LSB substitution mechanism for data security and authentication.
Journal of King Saud University-Computer and Information Sciences, 34,
5510–5524.
10. Tarhouni, N., Charfeddine, M., & Ben Amar, C. (2020). Novel and robust
image watermarking for copyright protection and integrity control. Circuits,
Systems, and Signal Processing, 39, 5059–5103.
11. Su, Y., Tang, C., Li, B., Qiu, Y., Zheng, T., & Lei, Z. (2019). Greyscale
image encoding and watermarking based on optical asymmetric
cryptography and variational image decomposition. Journal of Modern
Optics, 66, 377–389.
12. Islam, M., Roy, A., & Laskar, R. H. (2020). SVM-based robust image
watermarking technique in LWT domain using different sub-bands. Neural
Computing and Applications, 32, 1379–1403.
13. Su, Q., & Chen, B. (2018). Robust color image watermarking technique in
the spatial domain. Soft Computing, 22, 91–106.
14. Wan, W., Zhou, K., Zhang, K., Zhan, Y., & Li, J. (2020). JND-guided
perceptually color image watermaing in spatial domain. IEEE Access, 8,
164504–164520.
15. Alzahrani, A., & Memon, N. A. (2021). Blind and robust watermarking
scheme in hybrid domain for copyright protection of medical images. IEEE
Access, 9, 113714–113734.
16. Devi, K. J., Singh, P., Bilal, M., & Nayyar, A. (2023). Enabling secure image
transmission in unmanned aerial vehicle using digital image watermarking
with H-Grey optimization. Expert Systems with Applications, 121190.
17. Devi, K. J., Singh, P., Thakkar, H. K., & Kumar, N. (2022). Robust and
secured watermarking using Ja-Fi optimization for digital image
transmission in social media. Applied Soft Computing, 131, 109781.Chapter 4
New cosine similarity measures for
intuitionistic fuzzy sets with application
in decision-making
S. Ahemen, R. Ujah, and P. A. Ejegwa
DOI: 10.1201/9781003536796-4
4.1 INTRODUCTION
Handling data is a challenging exercise due to uncertain, imprecise,
ambiguous, incomplete, and vague information. Sequel to this, the fuzzy set
(FS) theory was proposed by Zadeh [1], and it has gained attention from
researchers as it is capable of handling uncertainties. However, a fuzzy set is
inadequate because it considers only the membership degree (denoted by α) of
an element to a set which associates its values from a closed interval
I = [0, 1], without considering any other deciding parameter. The fundamental
statement of a fuzzy set is that the degree of non-membership (denoted by β)
of an element to a set is directly 1 − α, which is not necessarily true in reality
as there may be some degree of hesitation. Consequently, Atanassov [2]
proposed a generalization of a fuzzy set called intuitionistic fuzzy set (IFS)
which considers the membership degree and non-membership degree with the
property that their sum is at most one with a possibility of hesitancy degree θ.
Obviously, all the parameters are defined within the unit interval [0, 1]. IFS is
reliable in managing uncertainties and imprecision in data analysis more
appropriately in comparison to FS, and as such, IFS has been successfully
applied in many areas such as medical diagnosis [3, 4, 5], pattern recognition
[6], etc. IFS was applied in the treatment of coronavirus [7]. Some informationmeasures have been studied under IFSs and applied in the decision-making
process and medical diagnostic analysis [8,9].
Similarity measuring approaches have been studied under IFSs. Similarity
measure is a real-valued function used to measure the degree of likeness
between two IFSs. Many real-life problems have been resolved with the aid of
intuitionistic fuzzy similarity measures (IFSMs) such as decision-making,
pattern recognition, face recognition, and so on. Some of the existing IFSMs in
literature were developed to resolve the setbacks of the previously developed
similarity measures by inspection. Chen [10] developed the concept of
similarity measure in IFSs. Later on, Hong and Kim [11] pointed out counter￾intuitive results in the work of Chen [10] and introduced a similarity measure
to resolve the issue. Ejegwa and Ahemen [12] developed an enhanced
intuitionistic fuzzy similarity operator with applications in emergency
management and pattern recognition. Chen et al. [13] proposed a similarity
measure using centroid points of transformed fuzzy numbers and also provided
some application in the field of pattern classification. Jiang et al. [14] derived a
new similarity measure based on the transformed isosceles triangles and its
applications to pattern recognition. Garg and Rani [15] proposed a similarity
measure based on the transformed right-angled triangles. Garg and Kumar [16]
proposed a new similarity measure using the set pair analysis theory. Patel et
al. [17] analyzed the shortcomings of the prevailing distance and similarity
measures for IFSs and constructed an IFSM and discussed its application in
face recognition and software quality evaluation. Some dilemmas and
challenges witnessed in IFSMs were presented in [18], where the role of a lack
of knowledge concerning elements (options, decisions, etc.) was stressed.
Distance measure and similarity measure complement each other. Burillo
and Bustince [19] initiated the concept of distances for IFSs and interval￾valued fuzzy sets. Szmidt and Kacprzyk [20] modified the distances in Burillo
and Bustince [19] and showed that all the three parameters describing IFSs
should be taken into account while calculating distances between IFSs.
Papakostas et al. [21] presented a detailed analysis of some of the distance and
similarity measures for IFSs in the literature. Ejegwa et al. [22] presented a
modified IFSMs and their applications in decision-making. Boran and Akay
[23] proposed a bi-parametric similarity measure and applied the measure to
pattern recognition. Xiao [24] proposed a divergence-based similarity measure
for IFSs. Ju et al. [25] developed a distance measure for IFSs using K-L
divergence. Patel et al. [26] pointed out some counter-intuitive results in thework of Ju et al. [25] and introduced a new distance measure based on K-L
divergence.
Similarity measures were developed using trigonometric functions. Ye [27]
first developed a cosine-based similarity operator with application and a
relative analysis of the similarity measures between IFSs was conducted. In
Shi and Ye [28], the similarity operator of IFSs in Ye [27] was refurbished by
incorporating the complete measurable parameters of IFSs with application in
fault diagnosis of turbine. In Ye [29], some similarity measures of IFSs based
on cosine function for the decision-making of mechanical design scheme were
presented. Also, Tian [30] developed the cotangent similarity measure of IFSs
and applied it to medical diagnosis. Then, Rajarajeswari and Uma [31] further
introduced the cotangent similarity measure of IFSs by considering
membership, non-membership, and hesitation degrees in IFSs. Garg [32]
presented an improved cosine similarity measure for IFSs and their
applications to decision-making process.
The trigonometric similarity measures, such as cosine and cotangent
similarity measures, or generally similarity measures in literature play an
important role in pattern recognition, medical diagnosis, decision-making, and
so on. Albeit, some of them have some drawbacks such as inability to measure
the degree of similarity, violation of similarity axioms, exclusion of
measureable parameters, and so on. Sequel to these limitations, a robust
similarity operator is needed since the existing trigonometric-based similarity
measures have some limitations. As a follow-up, this chapter presents a new
cosine similarity measures of IFSs with the following objectives:
i. Appraising some existing similarity operators of IFSs;
ii. Developing a weighted cosine similarity operator of IFSs to overcome the
shortcoming of the existing IFS measures;
iii. Highlighting the merits of the weighted cosine similarity operator of IFSs
over existing similarity operators via comparative analysis based on
numerical illustrations;
iv. Describing the properties of the weighted cosine similarity measure to
express its alliance with the properties of the similarity measure;
v. Discussing the application of the new similarity operator of IFSs in
pattern recognition.
The chapter is structured as follows: Section 4.2 presents some preliminaries
and reiterates some of the existing trigonometric similarity measures; thedevelopment of the new similarity measures is presented in Section 4.3;
Section 4.4 discusses pattern recognition based on similarity measures based
on intuitionistic fuzzy data. The work is concluded in Section 4.5 with
recommendations for further work.
4.2 SOME BASIC CONCEPTS OF IFSS AND
EXISTING TRIGONOMETRIC-BASED￾SIMILARITY MEASURES OF IFSS
Here, we present some preliminaries on IFSs and some of the existing
trigonometric similarity measuring approaches.
4.2.1 Preliminaries
In this chapter, K is the universe of discourse. Firstly, we define fuzzy set as
follows.
Definition 4.1 [1]
Let K = {k1, k2, …, kn} be a non-empty set. Then, a fuzzy set A of K
is characterized byA = {(k, αA (k) : kϵK}, where the function
αA : K → [0, 1] defines the membership degree of k to A.
Definition 4.2 [2]
An IFS represented by A in K is of the form
A = {k, αA (k), βA (k) k ∫ K},
where αA (k)and βA (k)are degrees of membership and non-membership
of k in K defined by the functions αA : k → [0, 1]andβA : k → [0, 1],
with the property that αA (k) + βA (k) ∈ [0, 1]. The hesitation margin of
an IFS A in Kdenoted by θA (k) ∈ [0, 1], expresses the knowledge of thedegree to whether k is in Kor not, and it is defined by
θA (k) = 1 − (αA (k) + βA (k)). It is obvious that 0 ≤ θA (k) ≤ 1 for
each k ∈ K.
Now, we present some operations on IFSs like complement, equality,
inclusion, union, and intersection.
Definition 4.3 [33]
Suppose A and B are IFSs in K; then, the following properties follows:
i. A = {k, βA (k), αA (k)|kϵK}, B = {k, βB (k), αB (k)|kϵK}
ii. A ∪ B = {k, max(αA (k), αB (k)), min(βA (k), βB (k))⟩ k ∫ K}
iii. A ∩ B = {k, min(αA (k), αB(k)−
), max(βA (k), βB (k))⟩ k ∫ K}
iv. A = B if and only if αA (k) = αB (k) and βA (k) = βB (k) for all
k in K
v. A ⊆ Bif and only if αA (k) ≤ αB (k)βA (k) ≥ βB (k) for all k in
K
4.2.2 Some existing trigonometric similarity measures of
intuitionistic fuzzy set
Some existing trigonometric approaches of finding similarity between IFSs are
reiterated before the introduction of the new approaches. Then, definition of an
operator according to Ye [29] follows.
Definition 4.4
Let A and B be two IFSs in K = {k1, k2, …, kn}, then a similarity
measure satisfies the following properties;(4.1)
(4.2)
(4.3)
i. 0 ≤ σ (A, B) ≤ 1
ii. σ (A, B) = 1 if and only if A = B
iii. σ (A, B) = σ (B, A)
iv. If C is an IFS in K and A ⊆ B ⊆ C, then σ (A, C) ≤ σ (A, B) and
σ (A, C) ≤ σ (B, C).
When σ (A, B) reaches 1, it shows that A and B have strong similarity.
Again, if σ (A, B)reaches 0, then A and B have weak similarity.
Specifically, if σ (A, B) = 0, then A and B have no similarity, and if
σ (A, B) = 1, then A and B have perfect similarity. Now, we enumerate
some existing trigonometric-based similarity operators of IFSs as follows.
Ye’s similarity operators: Ye [29] presented two cosine similarity
operators between IFSs as shown as in Eqs. (4.1) and (4.2):
σ1 (A, B) = 1
n
n
∑
i=1
cos [
π
2 max (|αA (ki) − αB(ki)|, |βA (ki) − βB(k
σ2 (A, B) = 1
n
n
∑
i=1
cos [
π
4
(|αA (ki) − αB(ki)| + |βA (ki) − βB(ki)|
Tian’s similarity operator: Tian [30] proposed a similarity measure
based on cotangent function given as Eq. (4.3):
σ3 (A, B) =
1
n
n
∑
i=1
cot [
π
4 +
π
4 max (|αA (ki) − αB(ki)|, |βA (ki) −
This method does not include the hesitation margin, and so its results
cannot be trusted due to exclusion.
Rajarajeswari and Uma’s similarity operator: Considering the
hesitation margin, Rajarajeswari and Uma [31] modified the method in
[30] as:(4.4)
(4.5)
(4.6)
σ4 (A, B) = 1
n
n
∑
i=1
cot [
π
4 +
π
4 max (
4.3 NEW DEVELOPED COSINE-BASED￾SIMILARITY OPERATORS
Here, we present a modified cosine-based similarity measure for IFSs. In
addition, we discuss their properties to showcase their alliance with the
similarity measure axioms.
Definition 4.5
Let A and B be two IFSs in K = {k1, k2, …, kn}. Then, the new cosine￾based similarity measures are:
σ* (A, B) = 1
n
n
∑
i=1
cos [
π
4 ωi (
σ** (A, B) =
1
n
n
∑
i=1
cos [
π
2 ωi (
|αA(ki)−αB(ki)|+|βA(ki)−βB(ki)|+|θA(ki)−θB(
3
where ωi is the weight of ki for i = 1,…, n with the property
ωi ∈ [0, 1] such that 
n
∑
i=1
ωi = 1.
The theorem that follows considers some of the properties of the new
similarity measures.
|αA (ki) − αB(ki)|, |βA (ki) −
|θA (ki) − θB (ki)|
|αA (ki) − αB(ki)| + |βA (ki) − βB(
+ |θA (ki) − θB (ki)|Theorem 4.1
The new cosine-based similarity measures between IFSs satisfy the
similarity conditions.
Proof. We will prove for σ⋆ (A, B), and the proof of σ** (A, B)
follows analogously. To prove that σ⋆ (A, B) satisfies the similarity
conditions, we check the following: (i) 0 ≤ σ⋆ (A, B) ≤ 1, (ii)
σ⋆ (A, B) = σ⋆ (B, A), (iii) σ⋆ (A, B) = 1 if only if A = B, (iv)
σ (A, C) ≤ σ (A, B) and σ (A, C) ≤ σ (B, C), where A, B, and C are
IFSs in K.
The fact that |αA (ki) − αB(ki)| ≥ 0, |βA (ki) − βB(ki)| ≥ 0, and
|θA (ki) − θB (ki)| ≥ 0, then σ⋆ (A, B) ≥ 0. Recall that
Suppose that,
Then σ* (A, B) = 1
n
cos (
ψ1+ψ2+ψ3
4 ). Thus,
Hence, σ* (A, B) ≤ 1, which proves (1). Next, we show that
σ⋆ (A, B) = σ⋆ (B, A) as follows:
σ* (A, B) = 1
n ∑n
i=1 cos [
π
4 ωi (|αA (ki) − αB(ki)| + |βA (ki) − βB
= 1
n ∑n
i=1 cos (
πωi[|αA(ki)−αB(ki)|+|βA(ki)−βB(k
4
n
∑
i=1
πωi |αA (ki) − αB(ki)| = ψ1,
n
∑
i=1
πωi |βA (ki) − βB(ki)| = ψ2, and
n
∑
i=1
πωi |θA (ki) − θB(ki)| =
σ* (A, B) − 1 = 1
n
cos (
ψ1+ψ2+ψ3
4 ) − 1 =
cos(
ψ1+ψ2+ψ3
4 )−n
n
= −
[n−cos(
ψ1+ψ2+ψ3
4 )]
n ≤ 0.which prove (2). In addition, we prove (3) as follows: Suppose A = B,
then it implies that αA (ki) = αB (ki), βA (ki) = βB (ki), and
θA (ki) = θB (ki) for i = 1, 2, …, n and k ∈ K. Hence
|αA (ki) − αB(ki)| = 0, |βA (ki) − βB(ki)| = 0, and
|θA (ki) − θB (ki)| = 0. Thus σ⋆ (A, B) = 1.
Conversely, if σ⋆ (A, B) = 1, then this implies αA (ki) − αB (ki) =
βA (ki) − βB (ki) = θA (ki) − θB (ki) = 0 for i = 1, 2, …, n for
ki ∈ K since, cos (0) = 1. Then,
αA (ki) = αB (ki), βA (ki) = βB (ki), θA (ki) = θB (ki) for
i = 1, 2, …, n and ki ∈ K. Hence, A = B. Finally, suppose A ⊆ B ⊆
C, then we have
αA (ki) ≤ βB (ki) ≤ αC (ki) and βA (ki) ≥ βB (ki) ≥ βC (ki)
for i = 1, 2,…, n and ki ∈ K. Then, we have
|αA (ki) − αB (ki)| ≤ |αA (ki) − αC (ki)|, |αB (ki) − αC (ki)| ≤ |
|βA (ki) − βB(ki)| ≤ |βA (ki) − βC(ki)|, |βB (ki) − βC(ki)| ≤ |βA
|θA (ki) − θB (ki)| ≤ |θA (ki) − θC (ki)|, |θB (ki) − θC (ki)| ≤ |θA
Because the cosine function is a decreasing function within the interval
[0,
π
2
], it follows that σ⋆ (A, C) ≤ σ⋆ (A, B) and σ⋆ (A, C) ≤ σ⋆ (B, C),
which proves (4).
4.3.1 Numerical examples
σ* (A, B) = 1
n ∑n
i=1 cos (
πωi
[|αA(ki)−αB(ki)|+|βA(ki)−βB(ki)|+|θA(ki)−θB(
4
= 1
n ∑n
i=1 cos (
πωi[|αB(ki)−αA(ki)|+|βB(ki)−βA(ki)|+|θB(ki)−θA(
4
= σ⋆ (B, A),We present the following examples to demonstrate the superiority of the
modified cosine similarity operators.
Example 4.1
Let K = {k1, k2, k3} and
A1 = {(k1, 0.7, 0.2), (k2, 0.6, 0.1), (k3, 0.5, 0.4)} and
B1 = {(k1, 0.8, 0.1), (k2, 0.7, 0.3), (k3, 0.3, 0.4)} be IFSs in K.
Example 4.2
Suppose A2 and B2 are IFSs in K = {k1, k2} defined by A2= {(k1, 0.4,
0.6), (k2, 0.4, 0.2)} and B2= {(k1, 0.2, 0.8), (k2, 0.1, 0.5)}.
The interest here is to find the likeness of A and B by using the
discussed trigonometric similarity operators. We begin with the new
similarity operators, i.e.,σ⋆ (A, B) as that of σ** (A, B) follows
analogously.
Using ωi = {0.5, 0.4, 0.1} for K = {k1, k2, k3}, we have
Now, using ωi = {0.4, 0.6} for K = {k1, k2}, we have
The results of the discussed trigonometric similarity measures in both
examples are presented in Table 4.1.
Table 4.1 Similarity values
σ* (A1, A2) = 1
3 ∑3
i=1 cos [
π
4 ωi (|αA (ki) − αB(ki)| + |βA (ki)
=
1
3
(cos(45 × 0.1) + cos(45 × 0.24) + co
σ* (B1, B2) = 1
2 ∑2
i=1 cos [
π
4 ωi (|αA (ki) − αB(ki)| + |βA (ki) −
= 1
2
(cos(45 × 0.16) + cos(45 × 0.3σ1
 [29] 0.9433 0.9210
σ2
 [29] 0.9433 0.9210
σ3
 [30] 0.7691 0.6697
σ4
 [31] 0.7311 0.6697
σ* 0.9929 0.9762
σ** 0.9968 0.9894
From Table 4.1, the new similarity operators produce the best similarity
index compared to the existing trigonometric similarity measures.
4.4 APPLICATION
Here, to illustrate the viability of our new approaches, we establish the hands￾on relevance of the new similarity operators and the existing trigonometric
approaches in pattern recognition case.
4.4.1 Example
Here, a pattern recognition problem regarding the classification/grouping of
some building materials is considered. Assuming there are four given classes
of building material, which are represented by IFSs sˆ1, sˆ2,sˆ3, and sˆ4 in the
feature space K = {k1, k2, …, kn}, where n = 12. Given another kind of
unknown building material Cˆ, we seek to associate the unknown pattern Cˆwith
any of the appropriate known patterns based on intuitionistic fuzzy
trigonometric similarity operators. The intuitionistic fuzzy information of the
patterns are presented in Table 4.2 as presented in [34] (see Appendix). To
obtain the grouping of the unknown building material Cˆwith sˆi
, for
i = 1, 2, 3, 4, we compute the similarity indexes between Cˆ and sˆiusing the
new approach and the existing approaches to get the results in Table 4.3, and
their rankings in Table 4.4, respectively.
Similarities (A1
, A2
) (B1
, B2
)Table 4.3 Similarity values
σ1
 [29] 0.6829 0.6865 0.8608 0.9959
σ2
 [29] 0.6828 0.6862 0.9145 0.9972
σ3
 [30] 0.4540 0.4447 0.6819 0.9390
σ4
 [31] 0.4540 0.4447 0.6815 0.9359
σ* 0.9976 0.9966 0.9983 0.99995
σ** 0.9992 0.9984 0.9991 0.9999
Table 4.4 Pattern classifications
σ1
 [29] (sˆ4, Cˆ) ≻ (sˆ3, Cˆ) ≻ (sˆ2, Cˆ) ≻ (sˆ1, Cˆ)
σ2
 [29] (sˆ4, Cˆ) ≻ (sˆ3, Cˆ) ≻ (sˆ2, Cˆ) ≻ (sˆ1, Cˆ)
σ3
 [30] (sˆ4, Cˆ) ≻ (sˆ3, Cˆ) ≻ (sˆ1, Cˆ) ≻ (sˆ2, Cˆ)
σ4
 [31] (sˆ4
, Cˆ) ≻ (sˆ3
, Cˆ) ≻ (sˆ1
, Cˆ) ≻ (sˆ2
, Cˆ)
σ* (sˆ4, Cˆ) ≻ (sˆ3, Cˆ) ≻ (sˆ1, Cˆ) ≻ (sˆ2, Cˆ)
σ** (sˆ4, Cˆ) ≻ (sˆ1, Cˆ) ≻ (sˆ3, Cˆ) ≻ (sˆ2, Cˆ)
From Table 4.3, we see that the new cosine similarity measures outperform the
existing trigonometric similarity measures. From Tables 4.3 and 4.4, we see
that the unknown building material Cˆ can be categorized with the building
pattern sˆ4 based on the principle of maximal similarity. The following are
some of the advantages of the new similarity operators:
Similarities (sˆ1, Cˆ) (sˆ2, Cˆ) (sˆ3, Cˆ) (sˆ4, Cˆ)
Similarities Ranking order1. the new similarity operators consider all the measurable parameters of
IFSs to avoid error-ridden results due to exclusion witnessed in Tian’s
approach;
2. the new similarity operators are able to measure the similarity between
two similar patterns properly and they satisfied the similarity axioms; and
3. the new similarity operators yield more reliable and reasonable results
with better performance rating.
4.5 CONCLUSION
In this chapter, we proposed new cosine similarity approaches between IFSs
based on cosine function by considering the three parameters of IFSs. We have
characterized the new similarity operators of IFSs to show their alliance with
the conditions of similarity function. The comparative analysis based on
numerical illustration within the family of trigonometric similarity measures of
IFSs was demonstrated to show the effectiveness and rationality of the
developed cosine similarity measures. Finally, we discussed the application of
the new cosine similarity measures to decision-making case of pattern
recognition under an intuitionistic fuzzy environment. The applicative
processes were decided from the rankings of the values of the computed
similarity indexes. In our study, we observe that the new similarity operators
are able to measure the similarity between two similar patterns, and that the
new cosine similarity operators yield more reliable and reasonable results with
better performance ratings compared to the existing trigonometric similarity
operators [29, 30, 31]. Tian’s approach does not take into account the hesitancy
function, but the new similarity operators take into account the hesitancy
function to resolve the limitation. In terms of further research, the developed
cosine similarity measures can be extended to other uncertain domains and
applied to solve complex decision-making problems.
REFERENCES
1. Zadeh, L. A. (1965). Fuzzy sets, Information and Control, 8:338–353.
2. Atanassov, K. T. (1986). Intuitionistic fuzzy sets, Fuzzy Set and Systems,
20:87–96.3. Szmidt, E. and Kacprzyk, J. (2001). Intuitionistic fuzzy sets in some
medical applications, Notes on Intuitionistic Fuzzy Sets, 7(4):58–64.
4. De, S. K., Biswas, R. and Roy, A. R. (2001). An application of
intuitionistic fuzzy sets in medical diagnosis, Fuzzy Sets and Systems,
117(2):209–213.
5. Ejegwa, P. A. and Onasanya, B. O. (2019). Improved intuitionistic fuzzy
composite relation and its application to medical diagnostic process,
Notes on Intuitionistic Fuzzy Sets, 25(1):43–58.
6. Ashraf, Z., Khan, M. S. and Lohani, Q. M. D (2019). New bounded
variation based similarity measures between Atanassov intuitionistic
fuzzy sets for clustering and pattern recognition, Applied Soft Computing
Journal. https://doi.org/10.1016/j.asoc.2019.105529.
7. Mohamed, K. A., Shockry, M. and omran, M. (2020). Intuitionistic fuzzy
set and application in Covid-19, Applied and Computational
Mathematics, 9(15):146–154.
8. Ejegwa, P. A. (2020). An improved correlation coefficient between
intuitionistic fuzzy sets and its applications to real-life decision making
problems, Notes on Intuitionistic Fuzzy Sets, 26(2):1–14.
9. Ejegwa, P. A. (2020). Modified and generalized correlation coefficient
between intuitionistic fuzzy sets with applications. Notes on Intuitionistic
Fuzzy Sets, 26(1):8–22.
10. Chen, S. M. (1997). Similarity measures between vague sets and between
elements, IEEE Transactions on Systems, Man and Cybernetics,
27(1):153–158.
11. Hong, D. H. and Kim, C. (1999). A note on similarity measures between
vague sets and between elements, Information Sciences, 115(1):83–96.
12. Ejegwa, P. A. and Ahemen, S. (2022). Enhanced intuitionistic fuzzy
similarity operator with applications in emergency management and
pattern recognition, Granular Computing, 8(2):361–372.
13. Chen, S. M., Cheng, S. H., and Lan, T. C. (2016). A novel similarity
measure between intuitionistic fuzzy sets based on the centroid points of
transformed fuzzy numbers with applications to pattern recognition,
Information Sciences, 343:15–40.
14. Jiang, Q., Jin, X., Lee, S. J., and Yao, S. (2019). A new similarity/distance
measure between intuitionistic fuzzy sets based on the transformed
isosceles triangles and its applications to pattern recognition, Expert
Systems with Applications, 116:439–453.15. Garg, H. and Rani, D. (2021). Novel similarity measure based on the
transformed right-angled triangles between intuitionistic fuzzy sets and its
applications, Cognitive Computation, 13(2):447–465.
16. Garg, H. and Kumar, K. (2018). An advanced study on the similarity
measures of intuitionistic fuzzy sets based on the set pair analysis theory
and their application in decision making, Soft Computing, 22:4959–4970.
17. Patel, A., Jana, S. and Mahanta, J. (2022). Construction of similarity
measure for intuitionistic fuzzy sets and its application in face recognition
and software quality evaluation, SSRN Electronic Journal.
https://doi.org/10.2139/ssrn.4137574.
18. Szmidt, E., Kacprzyk, J. and Paweł, B. (2022). Similarity measures for
Atanassov’s intuitionistic fuzzy sets: some dilemmas and challenges,
Control and Cybernetics, 51(2):249–266.
19. Burillo, P. and Bustince, H. (1996). Entropy on intuitionistic fuzzy sets
and on interval-valued fuzzy sets, Fuzzy Sets and Systems, 78:305–315.
20. Szmidt, E. and Kacprzyk, J. (2000). Distances between intuitionistic
fuzzy sets, Fuzzy Set Systems, 114:505–518.
21. Papakostas, G. A., Hatzimichalids, A. G. and Kaburlasos, V. G. (2013).
Distance and similarity measures between intuitionistic fuzzy sets; a
comparative analysis from a pattern point of view, Pattern Recognition
Letters, 34(14):1609–1622.
22. Ejegwa, P. A., Onyeke, I. C., Terhemen, B. T., Onoja, M. P., Ogiji, A. and
Opeh, C. U. (2022). Modified Szmidt and Kacprzyk’s intuitionistic fuzzy
distances and their applications in decision-making, Journal of the
Nigerian Society of Physical Sciences, 4:175–182.
23. Boran, F. E. and Akay, D. (2014). A bi-parametric similarity measure on
intuitionistic fuzzy sets with applications to pattern recognition,
Information Sciences, 255(10):45–57.
24. Xiao, F. (2019). A distance measure for intuitionistic fuzzy sets and its
application to pattern classification problems, IEEE Transactions on
Systems, Man, and Cybernetics: Systems, 51(6):3980–3992.
25. Ju, F., Yuan, Y., Yuan, Y. and Quan, W. (2019). A divergence-based
distance measure for intuitionistic fuzzy sets and its application in the
decision-making of innovation management, IEEE Access, 8:1105–1117.
26. Patel, A., Kumar, N., and Mahanta, J. (2022). A 3D distance measure for
intuitionistic fuzzy sets and its application in pattern recognition anddecision-making problems, New Mathematics and Natural Computation.
https://doi.org/10.1142/s1793005723500163.
27. Ye, J. (2011). Cosine similarity measures for intuitionistic fuzzy sets and
their applications, Mathematical and Computer Modelling, 53:91–97.
28. Shi, L. L. and Ye, J. (2013). Study on fault diagnosis of turbine using an
improved cosine similarity measure for vague sets, Journal of Applied
Sciences, 13(10):1781–1786.
29. Ye, J. (2016). Similarity measures of intuitionistic fuzzy sets based on
cosine function for the decision making of mechanical design schemes,
Journal of Intelligent and Fuzzy Systems, 30:151–158.
30. Tian, M.Y. (2013). A new fuzzy similarity based on cotangent function for
medical diagnosis, Advanced Modeling and Optimization, 15(2):151–156.
31. Rajarajeswari, P. and Uma, N. (2013). Intuitionistic fuzzy multi similarity
measure based on cotangent function, International Journal of
Engineering Research and Technology, 2(11):1323–1329.
32. Garg, H. (2018). An improved cosine similarity measure for intuitionistic
fuzzy sets and their applications to decision-making process, Hacettepe
Journal of Mathematics and Statistics, 47(6):1578–1594.
33. Atanassov, K. T. (1999). Intuitionistic Fuzzy Sets: Theory and
Applications, Physica-Verlag, Heidelberg.
34. Wang, W. and Xin, X. (2005). Distance measure between intuitionistic
fuzzy sets, Pattern Recognition Letters, 26:2063–2069.
APPENDIX
Table 4.2 Pattern building materials in intuitionistic fuzzy setting
αsˆ1
0.173 0.102 0.530 0.965 0.420 0.008 0.331 1.0
βsˆ1
0.524 0.818 0.326 0.008 0.351 0.956 0.512 0.0
θsˆ1
0.303 0.080 0.144 0.027 0.229 0.036 0.157 0.0
αsˆ2 0.510 0.627 1.000 0.125 0.026 0.732 0.556 0.6
Feature space
Patterns k1 k2 k3 k4 k5 k6 k7 k8Chapter 5
Multi-objective optimization problems in
focus
Meaning, approaches, and implementation
Ismail Olaniyi Muraina
DOI: 10.1201/9781003536796-5
5.1 INTRODUCTION
In many different sectors, including science, engineering, and business, several
objectives must be simultaneously optimized. The objectives are frequently broken
down into incomparable parts, and there is often some competition between them (one
target cannot be improved without degrading at least another). Multi-objective
optimization problems (MOPs) are one of these issues. Consider a product-supply
company that wants to reduce the overall length of its routes to provide better
customer service. However, to cut operating costs, the corporation also wants to use
fewer trucks overall. These goals are obviously at odds with one another because
adding more trucks shortens routes while raising operating expenses. The goals of this
issue are also articulated in other measuring units.
It is feasible to decide which of any given pair of solutions in single-objective
optimization (SOO) is superior to the other. The researcher typically finds a single
optimal option as a result. There is no simple way to tell if one solution to an MOP is
better than another. The approach known as the Pareto dominance relation is most
frequently used in MOP to compare solutions since it yields a group of options with
various trade-offs among the objectives rather than a single optimal solution. These
solutions are called Pareto optimal solutions or non-dominated solutions.
Even though there are numerous Pareto optimal options, in actuality, only one must
be chosen and put into action. Using a product-supply company as an example, just
one delivery route will be chosen from among the many created choices. As a result,
two jobs may be distinguished in the MOP process: (i) finding a set of Pareto optimalsolutions and (ii) selecting the most favoured option from this group. The second task
involves a decision-maker (DM) who may supply subjective preference information to
select the best solution in a specific instance of the MOP because Pareto optimum
solutions are mathematically similar. The pursuit of an ideal condition is one of the
most fundamental ideas in human existence (Nagy et al. 2020). Seeking excellence in
various aspects of decision-making is essential as long as life exists. To produce the
optimum solution or the most advantageous group of options for one or more specified
criteria, the concept of optimization is thought to be a DM’s primary objective. It can
be challenging for a DM to define all of these conflicting objectives in terms of a
single objective using the SOO approach because most real-world problems involve
numerous correlated and frequently conflicting objectives that must be maximized or
minimized to solve the problem. MOP has emerged as one of the most recent
optimization techniques to frame decision-making issues more realistically to get
around this constraint.
5.2 OPTIMIZATION AND OPTIMIZATION
TECHNIQUES
Many people use optimization procedures in their daily tasks. In computing,
optimization means maximizing system or application performance with minimal
resources. The optimization problem can be defined as a computational situation
where the goal is to find the best of all possible solutions. The model may compare the
existing design to the best feasible design and include data on the restrictions and
implied costs of arbitrary laws and policy decisions. A well-designed optimization
model can also help with what-if analysis, highlighting where improvements might be
made or trade-offs may be required. The application of optimization to scientific and
engineering problems encompasses a wide range of disciplines.
5.3 CATEGORIZATION OF OPTIMIZATION
TECHNIQUES
The categorization of optimization techniques is divided into nine parts in the
breakdown. The optimization techniques are classified as classical or meta-heuristic,
with classical techniques including branching, Langrange’s multiplier method, and
dynamic programming. Similarly, meta-heuristic procedures are classified as
deterministic or stochastic. Deterministic search is divided into tabu search and local
search, whereas stochastic search is divided into single solution-based approaches and
population-based techniques. Simulated annealing and hill-climbing techniques are
examples of single solution-based techniques, whereas population-based techniques
include SOO and MOP techniques. Finally, SOO methods include ant colonyoptimization, particle swarm optimization, bee colony optimization, and scatter search,
whereas MOP methods include non-dominated sorting genetic algorithm-II, multi￾objective evolutionary algorithm based on decomposition, indicator-based
evolutionary algorithm, and multi-objective particle swarm optimization. Table 5.1 and
Figure 5.1 depict the summary diagram.
Table 5.1 Optimization category in divisionsFigure 5.1 Summary categorization of the optimization techniques.
5.4 MEANING OF MULTI-OBJECTIVE
OPTIMIZATION PROBLEM
An MOP is a type of mathematical optimization that deals with issues that have many
objective functions that must be optimized at the same time. These issues sometimes
include compromises between competing goals, such as cost, quality, or performance
(Selim & Sevil 2023). MOP seeks solutions that are optimal in some way, such as
being Pareto optimal or meeting certain preference criteria. MOP, also known asPareto optimization (also known as multi-objective programming, vector optimization,
multicriteria optimization, or multi-attribute optimization), is a branch of multiple￾criteria decision-making that deals with mathematical optimization problems that
require more than one objective function to be optimized at the same time. Multi￾objective vector optimization is a kind of vector optimization that has been used in
many sectors of science, including engineering, economics, and logistics, where
optimal decisions must be made in the presence of trade-offs between two or more
competing objectives. Minimizing costs while optimizing comfort when purchasing an
automobile, and maximizing performance while minimizing fuel consumption and
pollutant emissions of a vehicle are two instances of MOPs with two and three
objectives, respectively. There may be more than three objectives in practical tasks
(Wikipedia 2023). As a result, multi-objective issues are theoretically characterized by
an objective function vector F(x) that is minimized or maximized in terms of choice
variables vector X. There is a point in the objective function space for every solution x
in the decision variable space. By assigning the objective function vector (y1
, y2
,..., yk
)
in objective space Y, the function f (X, Y) gauges the efficiency of a particular solution.
In addition, some multi-objective problems may have some inequality (gi ≤ (x)) and
equality (hj = (x)) requirements (Sharma & Chahar 2022). According to Baghernejad
and Aslanzadeh (2022), an MOP necessitates the simultaneous satisfaction of
numerous distinct and frequently conflicting objectives, or the simultaneous
optimization of several competing objectives, which necessitates expanding the
competence of optimization algorithms (Sharifi et al., 2021; Pereira et al., 2022).
An MOP is a mathematical branch of problem utilized in multiple-criteria decision￾making that deals with optimization issues that involve two or more objective
functions that must be optimized at the same time. In general, it is used when the best
option must be made in the face of two or more interdependent objectives, such as in
economics, logistics, and many engineering and science challenges. MOPs with two or
more objectives include maximizing comfort while minimizing cost when buying or
renting a home, minimizing cost while maximizing the durability of constructed
structures, and minimizing travel costs while maximizing distance covered (Sukanta
2021; Selim & Sevil 2023). According to Raymond and Andrew (2019), MOP issues
involve two or more competing optimization goals, which means that improving one
objective comes at the expense of improving another. As a result, it is also regarded as
an optimization that provides a framework for solving decision-making problems with
many objectives.
5.5 CLASSIFICATION OF OPTIMIZATION
PROBLEMS
Optimization problems can be classified in a variety of ways, particularly in operations
research and management science. One method of classification that can be found inthe literature is as follows:
Classification based on the objective function
Classification based on constraints
Classification based on objectives and constraints
Classification based on the nature of optimization
Classification based on types of variables
5.6 CLASSIFICATION BASED ON THE OBJECTIVE
FUNCTION
5.6.1 One or more objective functions
i. Working with a Single Objective: An SOO problem seeks the optimum solution
for a single criterion or metric, such as execution time (or performance) and/or a
combination of these metrics. Working with a single aim can help you stay
focused and reach your objectives more quickly. It enables researchers to
prioritize work and make judgements that are consistent with their overall
purpose. With a clear goal in mind, one can avoid distractions and stay on track.
As a result, the majority of optimization theory is devoted to working with a
single-objective function.
ii. Working with multi-objective: The goal is to identify a group of solutions that
represent the best trade-off between competing goals. As a result, MOP issues
entail maximizing more than one objective function at the same time. These
issues are frequent in a variety of professions, including science, engineering, and
social science. Weights can be assigned to this aim, but how can the researcher
assign weights when he doesn’t know which objective is more essential to him?
The best course of action is to convert the less important objective into a
constraint.
5.6.2 Pareto optimum
A scenario is said to be Pareto optimal or Pareto efficient if no modification could lead
to increased pleasure for one actor while causing another to lose. Pareto efficiency or
Pareto optimality refers to a scenario in which no action or allocation is possible that
benefits one individual while harming another. When no economic adjustments can
make one person better off without making at least one other person worse off, the
economy is considered to be in a Pareto optimal state. The concept of Pareto
efficiency, named after the Italian economist and political scientist Vilfredo Pareto
(1848–1923), is a key tenet of welfare economics. The Pareto optimal notion issignificant in MOP because it enhances one objective function while harming another.
The Pareto optimum is frequently a set; that is, several Pareto optima can be
continuous or discontinuous. In practice, creating the whole Pareto set is tough.
5.7 CLASSIFICATION BASED ON CONSTRAINTS
5.7.1 Without or with constraints
i. Without Constraints: If the aim is to determine the local (and maybe global)
maximum and minimum points of real-valued functions f(x,y), where the points
(x,y) might be any locations in the domain of f, it becomes an unconstrained
optimization problem. The approach employed was required to determine the
critical points, which entailed solving the equation f = 0, which is a system of two
equations with two unknowns (x and y). While the examples used were very
straightforward, this will not be the case in general. If the equations involve
polynomials of degree three or higher in x and y, or difficult formulas requiring
trigonometric, exponential, or logarithmic functions, solving even one of them,
much alone two, may be impossible.
ii. With Constraints: This is the process of maximizing an objective function about
some variables when those variables are constrained. The objective function is
either a cost or time function, an energy function that must be minimized, or a
reward or utility function that must be maximized. Constraints can be either hard,
which defines conditions for the variables that must be met, or soft, which
contains some variable values that are penalized in the objective function if and to
what extent the restrictions on the variables are not met.
A general constrained minimization problem may be written as follows:
min
x
f (x)
subject to
 gi
 (x) ≤ 0, i = 1, …, m
 hj
 (x) = 0, j = 1, …, p
where f(x) is the objective function to be minimized, and gi(x) and hj(x) are inequality
and equality constraints, respectively.
5.7.2 Equality or inequalityi. Constraints Can Be Equalities: The typical form of a continuous optimization
problem is where f: ℝ n → ℝ is the objective function to minimize over the n￾variable vector hj(x) = 0 is referred to as equality constraints. In structural
optimization, governing equations are usually equality constraints.
ii. Constraints Can Be Inequalities: The usual form of a continuous optimization
problem is where f: ℝ n → ℝ is the objective function to be minimized over the
n-variable vector x, and gi(x) ≤ 0 are known as inequality constraints. In structural
optimization, inequalities develop primarily as a result of resource and
performance restrictions.
5.7.3 Feasible space
A feasible region, feasible set, search space, or solution space in mathematical
optimization is the set of all possible points (sets of values of the choice variables) of
an optimization problem that satisfy the problem’s constraints, which may include
inequalities, equalities, and integer constraints. The feasible space is the space of
optimization variables in which all constraints are satisfied. In constrained
optimization, the objective function’s optimum must be found exclusively in the
feasible space. Building viable space is frequently impracticable, but we can certainly
search within it (Figure 5.2).Figure 5.2 General flow diagram procedure for multi-objective optimization.
5.8 CLASSIFICATION BASED ON OBJECTIVE AND
CONSTRAINTS
5.8.1 Linear programming
Linear programming is a strategy that assists us in determining the optimal solution for
a given problem. An optimum solution is the best feasible outcome of a given
situation. In basic terms, it is the process of determining how to do something in the
best possible way with limited resources. It is the strategy of maximizing resource
utilization to get the greatest possible result for a specific purpose, such as the lowest
cost, largest margin, or shortest time. It is worth noting that both the objective
functions and the constraints are linear.5.8.2 Quadratic programming
There is a quadratic cost function and linear restrictions in a quadratic programming
(QP) issue. Such issues arise in a wide range of real-world applications. Furthermore,
many general nonlinear programming algorithms necessitate the solution of a QP
subproblem at every iteration. Quadratic programming (QP) is a sort of nonlinear
programming in which mathematical optimization problems are solved using quadratic
functions. The goal is to optimize (minimize or maximize) a multivariate quadratic
function with linear constraints on the variables. The goal function is thus quadratic,
and the restrictions are linear.
5.8.3 Nonlinear programming
A branch of mathematics called nonlinear programming deals with optimization issues
where some of the constraints or the objective function are nonlinear. An optimization
problem is one in which the extrema of an objective function are calculated over a
collection of unknowable real variables and subject to the fulfilment of a set of
constraints, which are a system of equality and inequality conditions. When the
objective or restrictions cannot be described as linear functions without surrendering a
crucially important nonlinear aspect of the real-world system, nonlinear difficulties are
created. As a result, neither the objectives nor the limitations are linear. When
compared to problems involving linear programming, these problems are more
difficult to resolve. To optimize a given objective function, decision variables must be
chosen from a viable zone in nonlinear programming. Nonlinear constraints can be
used to identify the viable zone.
5.8.4 Geometric programming
The restrictions are produced by a family of geometric objects in many applications,
while the objective function of the underlying optimization problem only has a small
number of variables. Geometric optimization difficulties are the term used to describe
these issues. A class of nonlinear optimization issues is known as geometric
programming (GP). GP optimization problems can be converted into convex
optimization problems by taking advantage of their unique characteristics, even though
they are normally not convex optimization problems. This transformation entails a
change in the decision variables as well as a mathematical conversion of the objective
function and constraint functions. Numerous large-scale applications, including
improving power control in communication systems, doping profiles in semiconductor
device engineering, electronic component sizing in Integrated Circuit (IC) design, and
aircraft design in aerospace engineering, are thought to benefit from GP. Since
posynomials are polynomials with positive coefficients, their objectives and
constraints are also posynomials (Positive + Polynomial = posynomial) of the contextof GP, and exponents of posynomials can thus be real numbers, such as positive or
negative.
5.8.5 Convex optimization
Convex functions over convex sets are minimized in convex optimization, a branch of
mathematical optimization. Numerous disciplines, including engineering, economics,
finance, and machine learning, frequently use convex optimization issues. A convex
optimization problem is one in which the goal is a convex function if minimization is
desired, or a concave function if maximization is desired, and all constraints are
convex functions. Problems with linear programming are convex because linear
functions are convex. Convex optimization issues are the same as conic optimization
problems, which have convex cones as the inequality constraints. Slack variables can
be added, and inequality constraints can be changed into equality constraints, to
convert convex optimization problems into standard-form ones. A set of guidelines
called “disciplined convex programming” (DCP) is used to create mathematical
expressions that are guaranteed to be convex. A unique kind of convex optimization
problem known as geometric programming has a certain structure that enables it to be
converted into a convex optimization problem. The feasible space and the objective
function in convex optimization are both convex (Figure 5.3).
Figure 5.3 A convex graph.
From Figure 5.3, region {x :: x
2 ≥ x} is convex ==> all points are on the hull.
Starting at the point with the most negative x, the counterclockwise order of hull points
yields integers in ascending order.5.8.6 Non-smooth optimization
Non-smooth optimization issues are those in which the cost or constraints cannot be
differentiated. Examples of non-smooth problems are the l1 and l norms. The l1 norm
and the l norm cannot be differentiated on the “diagonals,” respectively. The highest
singular value of a matrix is another illustration. In contrast to the issues that many of
the major numerical methods have been developed for, non-smooth optimization often
deals with highly organized difficulties that arise. These issues are typically non￾convex. Consequently, either the objective function, the constraints, or both are not
differentiable in a non-smooth optimization problem.
5.9 CLASSIFICATION BASED ON THE NATURE OF
OPTIMIZATION
5.9.1 Global or local
i. Finding the global minima or maxima of a function or a combination of functions
on a certain set is the goal of the applied mathematics and numerical analysis
field known as global optimization. Since a maximum of a real-valued function is
equivalent to the minimization of the function, it is frequently referred to as a
minimization problem. Instead of looking for local minima or maxima, the
objective is to locate the minimum or maximum inside the provided collection.
Finding a function’s global minimum can be difficult because analytical
techniques are frequently inapplicable, and numerical solution techniques might
create extremely difficult problems. Numerous fields, including computational
phylogenetics, electrical circuit design, chemical engineering, safety verification,
worst-case analysis, mathematical problems, object packing problems, molecular
dynamics simulations, spin glasses, and radio propagation model calibration, use
global optimization problems in their work. There are specific types of problems
that can only be used to find the global minimum, which we determine as the
smallest of all minima.
ii. Local optimization is the objective function’s extrema (minimum or maximum)
for a specific area of the input space. In local optima, the researcher looks for a
position that minimizes the objective function among nearby feasible points,
making it only locally optimum. An objective function could have several local
maxima or just one, in which case the local maxima would also be the global
maxima.
A local search algorithm, also known as a local optimization algorithm, seeks
out a local optimum. It is designed to move through a certain area of the search
space and locate the function’s extrema there as precisely as possible. Therefore,local optimization techniques are frequently employed in applications where it is
advantageous to identify a good point, if not the best. Local search algorithms
frequently operate on a single candidate solution and entail incrementally making
modest modifications to the candidate solution, evaluating the change to
determine if it leads to an improvement, and using that improvement as the new
candidate solution.
5.9.2 Deterministic or stochastic
i. A subset of numerical optimization known as deterministic optimization seeks to
identify an optimization problem’s global solutions while also offering theoretical
assurances that the reported solution is the global one. To identify the overall
optimum solution, deterministic optimization algorithms take advantage of
specific and practical aspects of a given situation. Deterministic algorithm refers
to something that persists regardless of how many times a person tries it.
Deterministic optimization issues are a subset of optimization problems in which
accurate knowledge of the data is assumed. Deterministic algorithms, however,
could struggle with black-box issues or excessively intricate and volatile
optimization functions.
ii. A stochastic optimization issue is a type of optimization when some or all of the
parameters are unknown but adhere to established probability distributions. In
contrast, deterministic optimization assumes exact knowledge of all problem
parameters. Finding a choice that optimizes a set of predetermined criteria and
properly takes into account the uncertainty in the issue parameters is the aim of
stochastic programming. To tackle stochastic problems involving random
objective functions or random constraints, stochastic optimization methods
generate and utilize random variables. Stochastic implies that in addition to
deterministic nature, there is also a component of unpredictability. Thus, if the
variables are stochastic, an optimization problem may be stochastic; yet, a
deterministic issue may be solved using non-deterministic techniques.
5.10 CLASSIFICATION BASED ON TYPES OF
VARIABLES
5.10.1 Continuous or discrete
i. Discrete: A discrete optimization is a type of optimization problem where an
object, such as an integer, permutation, or graph, must be located from a
countable collection. The study of discrete optimization focuses on selecting the
best option among a limited number of options in an effective computing manner.(5.1)
(5.2)
(5.3)
Integer programming, matchings, knapsack, minimum cost flows, minimum
spanning trees, maximum flows, and other challenges are all included.
ii. Continuous: Continuous optimization is the process of determining the optimal
value from a continuous function in a situation involving continuous variables.
Constrained problems and multimodal difficulties are two examples. The
objective function must be minimized across a vector x with n variables in
continuous optimization problems. Inequality constraints gi(x) ≤ 0 and equality
constraints hj(x) = 0 may apply to the issue. The issue is an unconstrained
optimization problem if there are no restrictions. Iterative algorithms are
frequently used to address continuous optimization problems because they
produce a series of variable values that eventually lead to the solution of the
problem.
5.11 MULTI-OBJECTIVE OPTIMIZATION PROBLEM
The multi-objective optimization problem (MOP), also known as multiperformance,
multicriteria, or vector optimization problem, is the challenge of finding a vector of
decision variables that satisfies constraints and improves a vector function whose
elements represent the objective functions. These functions represent mathematical
performance requirements that are typically at odds with one another. Finding a
solution that would produce values for all the objective functions that are acceptable to
the DM is what the term “optimize” refers to.
The general multi-objective optimization problem (MOP) can be formally defined
as:
Find the vector →
x
* = [x
*
1
, x
*
2
, . . . , x
*
n
]
T which will satisfy the m inequality
constraints:
gi (→
x) ≥ 0 i = 1, 2, . . . . , m
The equality constraints:
hi (→
x) = 0 i = 1, 2,…, p
And will optimize the vector function:
→
f (→
x) = [f1 (→
x), f2 (→
x),…, fk (→
x)]
T5.12 METHODS OF MULTI-OBJECTIVE
OPTIMIZATION PROBLEMS
The majority of optimization problems involve more than one objective to be met,
usually in conflict with one another, but to simplify the solution, the remaining
objectives are typically addressed as constraints. Most experts agree that there are two
major categories into which MOP techniques may be divided: Scalarization (naive)
approaches and Pareto approaches. Although these groups have varied names, the key
differentiator is always the same (Table 5.2).
Table 5.2 Overview of the two methods
1. Weighted sum approach compromise
2. Programming (nonlinear
combinations)
3. Multi-attribute utility analysis
(MAUA) – utility theory
4. Physical programming
5. Goal programming
6. Lexicographic approaches and
acceptability functions
7. Fuzzy logic
1. Exploration and Pareto filtering
2. Weighted sum approach (with
weight scanning)
3. Adaptive weighted sum method
(AWS)
4. Normal boundary intersection
(NBI)
5. Multi-objective genetic
algorithms (MOGA)
6. Multi-objective simulated
annealing (MOSA)
5.13 MULTI-OBJECTIVE OPTIMIZATION
TECHNIQUES
The MOP techniques include the following:
Non-Dominated Sorting Genetic Algorithm-II: Non-dominated sorting genetic
algorithm-II (NSGA-II) is an MOP approach based on non-dominated sorting. It
produces children by a special type of crossover and mutation and then chooses
the next generation based on non-dominated-sorting and crowding distance
comparison. The algorithm can be used to solve box-bounded MOP problems
(Figure 5.4).
Scalarization methods
(a priori preference expression)
Pareto methods
(a-posteriori preference expression)Figure 5.4 Flowchart of a non-dominated sorting genetic algorithm-II.
Multi-Objective Evolutionary Algorithm Based on Decomposition
A multi-objective evolutionary algorithm based on decomposition (MOEA/D)
is a new framework for dealing with such kind of MOPs. MOEA/D focuses on
how to maintain a set of scalarized subproblems to approximate the optimum of
an MOP. It decomposes an MOP into several scalar optimization subproblems
and optimizes them simultaneously. Each subproblem is optimized by only using
information from its several neighbouring subproblems, which makes MOEA/D
have lower computational complexity at each generation than Multi-Objective
Genetic Local Search (MOGLS) and non-dominated sorting genetic algorithm-II
(NSGA-II) (Figure 5.5).Figure 5.5 Flowchart of a multi-objective evolutionary algorithm based
on decomposition.
Indicator-Based Evolutionary Algorithm
An indicator-based multi-objective evolutionary algorithm (IB-MOEA) is a
sort of MOP algorithm that uses indicators to increase the algorithm’s selection
pressure and performance when tackling MOP issues. It was created as an
alternative to Pareto-based MOEAs, which can lose selection pressure when
dealing with issues that have four or more objective functions (Figure 5.6).Figure 5.6 Flowchart for an indicator-based evolutionary algorithm.
Multi-Objective Particle Swarm Optimization
Multi-objective particle swarm optimization (MOPSO) is a heuristic algorithm
that can deal with issues that have several objective functions. MOPSO is a fast￾converging variation of particle swarm optimization (PSO) that is well-suited for
evolutionary algorithms. For multimodal, multi-objective problems, MOPSO can
find several Pareto optimal solutions (Figure 5.7).Figure 5.7 Flowchart for a multi-objective particle swarm optimization.
5.14 DEFINITION OF TERMS IN MULTI-OBJECTIVE
OPTIMIZATION
Objective Function: Objective functions are computable functions that are used to
decision variables to assess the quality of a particular solution. They can be summed
up as follows: F(x) = (f1
(x), f2
(x)..., fk(x)). The number k in this case specifies thenumber of objective functions in the issue to be addressed. In multi-objective
problems, k is higher than 1.
Decision Variables: The choice variables in optimization problems are independent
numerical variables for which values must be chosen. The vector of choice variables
can be written as x = [x1
, x2
,..., xj] T, where j = 1, 2,..., n.
Dominance Relation: To compare multi-objective solutions, a dominance
relationship is used. If both of the following requirements are met, solution S1 is said
to be dominant over solution S2.
a. S2 is not superior to S1 for any of the objectives.
b. S1 outperforms S2 in at least one of the objectives.
Pareto Optimality: If no other point s in the feasible search space, S improves in at
least one objective function without deteriorating another, that point s is Pareto
optimum. Mathematically, point s∗ ∈ S is Pareto optimal only if there is no point s ∈
S such that f(s) ≤ f(s∗) with at least one f
i(s) > f
i(s∗). In decision variable space, all
Pareto optimum solutions, also known as non-dominating answers, form a Pareto
optimal set. There exists an endless number of non-dominant solutions that are all
mathematically incomparable. The optimal set is determined by the type of objective
and is always located on the edge of a feasible region. An MOP can be approached in
numerous ways, but the majority of the effort is done by approximating the Pareto
optimal set.
Archive: An archive is a collection of individuals maintained outside of the primary
population of some multi-objective algorithms, which may (or may not) be utilized in
various ways during the selection and decision-making processes. The archive
primarily maintains all of the overall non-dominating solutions generated by the
algorithm’s numerous iterations, while rejecting local non-dominated answers. The
contents of the archive provide the Pareto optimal set at the end of the process. The
archive size can be limited (recommended) or unlimited.
Pareto Dominance Relation: A partial order on a set of finite-dimensional real
vectors is the Pareto dominance relation. If A Pareto dominates B, then A beats or ties
B on every dimension that matters to you. As a result, no one, no matter how eccentric
their preferences, could ever favour B over A. If two conditions are met, a policy x
Pareto dominates another policy y: No one prefers y over x, and at least, one person
prefers x over y.
Trade-offs: Trade-offs are the exchange of one thing for another, where choosing
one option means foregoing the opportunity to pursue another. When unlimited wants
meet restricted resources, trade-offs occur. When you make a trade-off, you’re prone to
make further compromises to acquire what you desire most. A trade-off occurs when
more of one item requires less of another.Pareto Optimal Solutions or Non-dominated Solutions: A non-dominated
solution is unaffected by any other solution. A Pareto-optimal, Pareto-efficient, or non￾inferior solution is another name for it. A non-dominated solution does not necessarily
outperform all other solutions in all objectives, but it does mean that no other solution
outperforms the non-dominated solution in all objectives. A Pareto-optimal solution is
a set of non-inferior solutions in the objective space that cannot be improved further
without surrendering at least one of the other objectives.
Multi-Objective Decision Analysis: A multi-objective decision analysis (MODA)
is a decision-making technique used when there are exceedingly complicated issues
involving several criteria and multiple stakeholders that may be significantly affected
by the decisions’ results.
Optimization: The process of determining the values of decision variables that
correspond to and give the maximum or minimum of one or more desired objectives is
referred to as optimization. In other words, optimization is defined as maximizing or
reducing some function relative to some set, which frequently represents a collection
of options available in a given situation. The function enables the comparison of
various options to determine which is “best.”
Conflicting Objectives: Conflicting aims indicate that reaching one goal
contradicts or diminishes the likelihood of accomplishing another. This can happen
when distinct or competing interests or preferences exist among individuals or groups.
Conflicting aims can pose difficulties or trade-offs for DMs, who must weigh the costs
and advantages of various goals.
5.15 SUMMARY
Many optimization applications in science, social sciences, and engineering challenges
are naturally multi-objective. Often, the functions to optimize are opposed, and
optimizing one will have a negative impact on the others. Solving this type of
challenge frequently necessitates balancing a set of objectives and selecting what type
of solutions are most appropriate. MOP techniques give a framework for dealing with
these huge and demanding problems.
MOP offers an organized and orderly way to solve real-world complicated decision￾making problems faced in the sciences and engineering professions. All multi￾objection optimization algorithms use additional information to determine the final
result. As a result, they aren’t automatic. MOP is most effective when applied
interactively to obtain better solutions from a workable solution that is already
accessible. This chapter therefore addresses optimization and optimization techniques,
optimization categories, meaning of MOP issues, and optimization problem
categorization, itemizes several words, and concludes with a summary.REFERENCES
Baghernejad, A. and Aslanzadeh, E. (2022). Application of multiobjective
optimization in thermal design and analysis of complex energy systems,
Editor(s): Mehdi Toloo, Siamak Talatahari, Iman Rahimi, in: Multi-Objective
Combinatorial Optimization Problems and Solution Methods, Academic
Press, Pages 211–237, doi: 10.1016/B978-0-12-823799-1.00001-2.
Jiang, S. and Yang, S. (2017). A Strength Pareto Evolutionary Algorithm Based
on Reference Direction for Multiobjective and Many-Objective Optimization,
IEEE Transactions on Evolutionary Computation, 21(3):329–346, doi:
10.1109/TEVC.2016.2592479.
Li, J.-Y., Zhan, Z.-H., Li Y. and Zhang J. Multiple Tasks for Multiple Objectives:
A New Multiobjective Optimization Method via Multitask Optimization,
IEEE Transactions on Evolutionary Computation, doi:
10.1109/TEVC.2023.3294307.
Nagy, M., Mansour, Y. and Abdelmohsen, S. (2020). Multi-Objective
Optimization Methods as a Decision-Making Strategy. International Journal
of Engineering and Technical Research, 9:516–522. doi:
10.17577/IJERTV9IS030480.
Nayak, S. (2020). Fundamentals of Optimization Techniques with Algorithms.
Academic Press. doi: 10.1016/C2019-1-02539-9.
Pereira, J.L.J., Oliver, G.A., Francisco, M.B. et al. (2022). A Review of Multi￾objective Optimization: Methods and Algorithms in Mechanical Engineering
Problems. Archives of Computational Methods in Engineering, 29:2285–2308,
doi: 10.1007/s11831-021-09663-x.
Raymond, W. and Andrew, G. (2019). Topology optimization for robotics
applications, Editor(s): Shawn M. Walsh, Michael S. Strano, in: Materials,
Robotic Systems and Autonomous Platforms, Woodhead Publishing, Pages
251–292, doi: 10.1016/B978-0-08-102260-3.00011-1.
Selim, Y. and Sevil, S. (2023). Metaheuristic approaches for solving
multiobjective optimization problems, Editor(s): Seyedali Mirjalili, Amir H.
Gandomi, in: Comprehensive Metaheuristics, Academic Press, Pages 21–48,
doi: 10.1016/B978-0-323-91781-0.00002-8.
Sharifi, M.R., Akbarifard, S., Qaderi, K. et al. (2021). A New Optimization
Algorithm to Solve Multi-Objective Problems. Scientific Reports, 11:20326,
doi: 10.1038/s41598-021-99617-x.
Sharma, S. and Chahar, V. (2022). A Comprehensive Review on Multi-objective
Optimization Techniques: Past, Present and Future. Archives of Computational
Methods in Engineering, 29(3). doi: 10.1007/s11831-022-09778-9.Chapter 6
Optimization and computing using
intelligent data-driven approaches for
decision-making
Sourena Rahmani, Hamed Aghalar, Sahel Jebreili, and Alireza Goli
DOI: 10.1201/9781003536796-6
6.1 INTRODUCTION
The onset of the Fourth Industrial Revolution, also known as Industry 4.0 or 4IR, has
marked the beginning of an epoch where data has become as valuable as oil. In this era
of digitization, a plethora of data is being produced from a variety of sources,
including the Internet of Things (IoT), business processes, healthcare systems, and
more. This data, irrespective of whether it is structured, semi-structured, or
unstructured, carries enormous potential for influencing strategic decision-making
across a wide range of application areas (Sarker, 2021). Data science has risen as a
comprehensive field that utilizes statistical methods, data analysis, and related
techniques to comprehend and scrutinize phenomena through data. Sophisticated
analytics techniques, inclusive of machine learning models, are utilized to derive
actionable intelligence or profound understanding from data. This procedure of
converting raw data into significant insights is recognized as data-driven decision￾making (DDDM) (Asana, 2022; Sarker, 2021).
DDDM is a methodology that entails gathering data in line with a firm’s key
performance indicators (KPIs) and converting this data into insights that can be acted
upon. During this procedure, business intelligence (BI) reporting instruments are
frequently employed to streamline the process of data collection and visualization.
These tools democratize data analytics, making it accessible to individuals without
extensive technical expertise (Abraham, 2020). DDDM is a concept within the realm
of decision-making that encompasses a broad spectrum of activities. These activities
include the collection of data, the extraction of patterns and facts from this data, and
the application of these insights to decision-making processes. DDDM is characterizedby an organizational decision-making process that is grounded in empirical data. There
are various models of decision-making, and interestingly, even the act of not making a
decision is considered a prevalent type or model within these processes (Krishen &
Petrescu, 2019). Decision-making is a straightforward process of selecting an option.
However, it often poses challenges, especially within an organizational context.
Consider the multitude of decisions we face daily. Perhaps you grappled with the
decision to hit the snooze button one more time this morning. Or maybe you were
overwhelmed by an extensive menu at a restaurant, with the server patiently waiting
for your order. You might have even left your wardrobe in disarray after trying on
multiple outfits for an important presentation. Even seemingly simple decisions can
prove to be difficult. People often go to great lengths and spend considerable amounts
of money to avoid making choices. For instance, opting for an expensive tasting menu
at a restaurant to avoid choosing from a vast array of dishes, or limiting your wardrobe
to black turtlenecks, following the example set by Steve Jobs, to eliminate the need for
choosing an outfit (Elbanna & Fadol, 2016).
Should you ever find yourself struggling with a decision at your workplace, take
comfort in the fact that you are not alone. A study by McKinsey indicates that a
significant portion of an executive’s time – approximately 40% on average – is
allocated to decision-making. Alarmingly, they often feel that this time is not used
effectively. The burden of decision-making can be so overwhelming that it results in a
state of weariness from the constant need to make decisions, a phenomenon referred to
as decision fatigue (Ceschi et al., 2017). Yet, decision fatigue is merely one aspect of
the repercussions of ineffective decision-making. A study by McKinsey, which
included more than 1,200 business leaders worldwide, indicates that inefficient
decision-making results in a loss of about 530,000 days of managerial time each year
for a typical Fortune 500 company. This translates to an approximate $250 million in
annual salaries. That’s a considerable investment in turtlenecks (Elbanna & Fadol,
2016; Levinthal & Newark, 2023). Decision-making encompasses a variety of models,
including the often-overlooked model of abstaining from making a decision.
Individuals employ diverse psychological methods when making decisions, a
phenomenon recognized in a notable study as the ‘Pentagonal Forms of Decision￾Making.’ A substantial number of business decisions stem from personal habits and
behaviors, which are predominantly intuitive and cognitive. This implies that these
decisions are grounded in experience, comprehension, cognition, and education.
Conversely, some decisions are not predicated on understanding or experience.
Instead, they rely on specific information gleaned from case studies or field research.
This approach is commonly known as DDDM. In DDDM, the decision-making
process is driven by data rather than direct or implicit knowledge and experience. In
this context, information serves as the primary decision-maker (Buijsse et al., 2023).
DDDM is not exclusive to the realm of information technology. It has been recognized
and utilized extensively across various domains, ranging from business to social and
political spheres. In the present era, the ease of data aggregation and accessibility viathe internet has amplified the application of this concept, particularly in e-commerce,
more effectively than ever before. The successful and optimal utilization of data in
business decisions is not necessarily contingent upon the level of technical expertise or
the magnitude of an organization’s database (Krishen & Petrescu, 2019).
Adopting a data-driven approach implies utilizing concrete data to discern trends,
draw conclusions, and gain insights that guide the decision-making process. This
approach emphasizes making decisions free from personal bias or emotional influence,
ensuring that an organization’s objectives and strategic plans are grounded in factual
evidence and the patterns derived from it. The application of DDDM enables
businesses to make enlightened decisions that enhance profitability and sales, foster
effective management practices, and streamline operations. This chapter aims to serve
as an exhaustive resource for researchers, decision-makers, and application developers
interested in leveraging data to address real-world challenges (Abraham, 2020; Kaspi
& Venkatraman, 2023). The degree to which business management depends on
decision-making data and guiding statistics plays a pivotal role in shaping the
effectiveness and reach of this decision-making approach. While one business may
possess an abundance of extensive data repositories and numerous dashboards to
transform raw data into actionable information, it may not necessarily exhibit a
proactive approach when it comes to analyzing and leveraging this data for decision￾making. Conversely, another business, even in the absence of a dedicated data
repository on a particular topic, might be dedicated to the collection of information and
making decisions guided by relevant indicators (Höchtl et al., 2016).
6.2 OPTIMIZATION AND DECISION-MAKING: A
BRIEF OVERVIEW
6.2.1 Optimization and decision-making
In the ever-evolving landscape of modern decision-making, the fusion of intelligent
data-driven approaches and optimization techniques has emerged as a formidable
force, reshaping the way organizations strategize and operate (Baardman et al., 2023;
Bertsimas & Thiele, 2006). As businesses and industries grapple with an increasingly
complex web of variables and objectives, the synergy between optimization and
decision-making has never been more critical (Sarker, 2021; Ullah & Youn, 2020).
The pivotal role played by these synergistic forces is delved into in this section,
with their profound impact on various facets of contemporary problem-solving being
unveiled. Through a tapestry of issues that are central to the intersection of
optimization and decision-making, navigation is conducted in this exploration. Not
only the theoretical underpinnings but also the practical applications that drive
innovation across diverse domains are encompassed by these topics. As this section is
journeyed through, light is aimed to be shed on the intricate interplay between data-driven insights and optimization strategies, showcasing how decision-makers are
empowered to navigate uncertainties, seize opportunities, and engineer efficient
solutions by this dynamic duo (Hakanen & Allmendinger, 2021; Keith & Ahner, 2021;
Morelli et al., 2022). The pivotal role of data in shaping decision landscapes is
examined by us, with the power of intelligent data-driven approaches being
emphasized for their ability to uncover hidden patterns, predict outcomes, and inform
decisions. It explores how these data-driven insights are fed into optimization models,
resulting in their efficacy being amplified in scenarios ranging from resource
allocation to supply chain management (Katsaliaki et al., 2022; Sarker, 2021).
The ethical considerations intertwined with data-driven optimization are also
explored throughout this section, with the responsible use of algorithms and the
importance of transparency and fairness in decision-making processes being discussed.
The latest advancements in optimization algorithms and computational techniques that
are revolutionizing the way we approach complex decision challenges are additionally
spotlighted (Saltz & Dewar, 2019). As this multifaceted terrain is navigated, the
overarching objective is to provide both researchers and practitioners with a
comprehensive understanding of the symbiosis between optimization and decision￾making. By addressing the key issues, insights, and applications within this realm, a
contribution to the ongoing discourse on leveraging intelligent data-driven approaches
for enhanced decision-making and problem-solving in the digital age is aimed to be
made (Felländer et al., 2022).
Generally, the process of decision-making entails the creation and assessment of
various options, ultimately culminating in the choice of the most favorable one that
aligns with specified criteria. On the other hand, optimization revolves around the
quest for the optimal solution within a range of possible alternatives (Keith & Ahner,
2021). At a higher level of abstraction, decision-making can be likened to the concept
of optimization. Indeed, in certain scenarios, the decision-making process entails
formulating and resolving optimization problems. These scenarios are distinguished by
a substantial reservoir of valuable information about the situation at hand and a clear
consensus regarding the objective to be achieved. For instance, within the automotive
industry, optimization techniques have been harnessed to determine the optimal
structural design for automobile frames, with the dual goals of maximizing strength
and minimizing weight. Furthermore, multidisciplinary optimization approaches have
been deployed during the early stages of vehicle design to identify the most financially
lucrative design options (Canonico et al., 2022). When optimization necessitates the
utilization of analysis software, such as finite element analysis, to assess designs, the
predominant challenge often resides in the computational workload entailed by solving
the optimization problem. Typically, the field of optimization is regarded as a subject
of significance within the realms of applied mathematics, operations research, and
engineering design (Rothwell, 2017).
6.2.2 Deeping in DDDMThe significance of DDDM lies in its ability to facilitate choices grounded on factual
information rather than personal biases. For those in leadership roles, the most
equitable and balanced approach is to make decisions objectively. The most
enlightened decisions are derived from real-time data that aligns with your business
objectives. Reporting software can be utilized to compile the necessary data, identify
trends, and forecast outcomes. Data can provide valuable insights for various
decisions, such as:
1. Strategies for boosting profits and sales.
2. Establishing effective management practices.
3. Streamlining operational processes.
4. Enhancing team performance.
Although not all decisions will be supported by data, they play a crucial role in many
of the most significant choices (Buijsse et al., 2023; Krishen & Petrescu, 2019).
6.2.2.1 DDDM by five steps
DDDM is a skill that requires practice. To improve your leadership abilities, you must
be able to translate raw data into actionable steps that align with your company’s
goals. The following steps, which have been shown in Figure 6.1, can help you make
better decisions when analyzing data (DriveResearch, 2023).
Figure 6.1 How to make a data-driven decision? (DriveResearch, 2023).
Know Your Vision: To arrive at well-informed decisions, it is imperative to have
a thorough grasp of your company’s long-term vision. This understanding serves
as the foundation upon which data and strategic planning can be harnessed to
influence your decision-making. Graphs and numerical figures, devoid of the
supporting context, lose their significance and effectiveness.
Find Data Sources: The selection of tools and data resources for your data
collection endeavors should be tailored to the specific nature of the data being
gathered. When dealing with internal company processes, it is advisable toemploy a versatile reporting tool. These tools provide a centralized platform for
monitoring the progress of tasks and activities across your organization. An
instance of such a tool is Microsoft’s Power BI, which facilitates the
consolidation of data from diverse external sources. However, when your aim is
to analyze marketing trends or competitor metrics, alternative tools designed for
these specific purposes are readily available.
Evaluating achievement entails the systematic monitoring of an array of
performance indicators. Among these key metrics are:
1. Gross profit margin.
2. Return on investment (ROI).
3. Productivity levels.
4. The overall customer base.
5. Consistent revenue streams.
The calculation of gross profit margin involves deducting the cost of goods sold
from a company’s net sales, allowing for an assessment of profitability. ROI, on
the other hand, quantifies the relationship between income and investment,
serving as a pivotal gauge to determine the viability of dedicating resources, be it
time or capital, to a particular endeavor. Productivity serves as an indicator of
how efficiently a company generates goods or services, accomplished by dividing
the overall output by the inputs expended. Tracking the total number of
customers, a straightforward yet potent metric, closely aligns with the business’s
revenue generation. Additionally, recurring revenue, prevalent among SaaS
enterprises, measures the income derived from active subscribers within a defined
timeframe, typically on a monthly or annual basis. Beyond these mentioned
metrics, numerous other data sets can be explored depending on one’s role and
organizational objectives. The advent of machine learning has significantly
simplified the process of aggregating real-time data, offering a powerful tool for
informed decision-making.
Organize Your Data: Enhancing the effectiveness of data visualization hinges on
the meticulous organization of your data, a crucial aspect when it comes to
making impactful business decisions. When you are unable to access and
comprehend all pertinent data within a unified context, the ability to ensure the
highest level of informed decision-making becomes a formidable challenge.
Perform Data Analysis: After effectively structuring your data, the next step
involves delving into its analysis, with the goal of uncovering valuable insights
that can inform and enhance the decision-making process. Depending on your
specific aims, it may be prudent to juxtapose the data gleaned from your
executive dashboard with user-centric research methods such as case studies,
surveys, or testimonials. This approach ensures that your conclusions are enriched
with insights from the customer’s perspective. For instance, if your team isstriving to enhance the competitiveness of their SEO tools within the market
landscape, you can utilize the following datasets to identify the necessary
enhancements:
1. Data pertaining to the performance of rival companies.
2. Data concerning the current performance of SEO software.
3. Present customer satisfaction metrics.
4. Findings from user research encompassing a range of SEO and marketing
tools.
While a portion of this data originates from your own organization, it may be
necessary to acquire certain data from external origins. The value of examining
these datasets collectively lies in the fact that you’ll derive unique insights
compared to the outcomes of analyzing each dataset in isolation.
Draw Conclusions: As you engage in the examination of your data, you may find
yourself forming interpretations based on your observations. Nevertheless, it is
crucial to allocate a distinct section to your interpretations, enabling you to
expound upon your insights derived from the data and disseminate your
discoveries to others. The fundamental inquiries to pose when crafting these
interpretations are:
1. What existing knowledge does the data reaffirm?
2. What novel insights have I acquired through this data analysis?
3. In what ways can I leverage the knowledge acquired to advance my
organizational objectives?
Once you have satisfactorily addressed these inquiries, you have effectively
completed the process of data analysis and should be well-equipped to make
informed decisions guided by data within your business (Asana, 2022).
6.2.2.2 Benefits of DDDM
Employing analytics to inform decision-making is not merely a valuable skill; it is an
essential one, especially if you aim to lead by example and foster a culture that values
data-driven insights. Through the utilization of data in decision-making, you can
establish a business environment that is characterized by fairness, goal-directedness,
and an unwavering commitment to growth. In the ensuing sections, Figure 6.2
illustrates a selection of advantages associated with DDDM.Figure 6.2 Some DDDM benefits (DriveResearch, 2023).
Make Confidence Decisions: In the realm of business longevity, enduring
enterprises are marked by a resolute belief in their capacity to thrive. When
leaders within an organization grapple with uncertainty and hesitation, it can
result in errors, increased employee attrition rates, and suboptimal risk mitigation.
Harnessing the power of data to inform critical business choices instills a sense of
assurance in these decisions, igniting motivation and determination among both
leaders and their teams. This newfound assurance has the potential to cultivate
elevated team spirits and enhance overall performance.
Guard against Biases: Utilizing data-driven decision-making serves as a
safeguard against biases that may infiltrate the judgments of corporate leaders.
Biases, often lurking beneath one’s awareness, can inadvertently sway decisions,
reflecting personal preferences or values. By grounding decisions in empirical
data and numerical evidence, objectivity and impartiality are upheld, thus
guaranteeing fairness in the decision-making process. This approach also equips
decision-makers with concrete substantiation for their choices, should inquiries
arise from team members or stakeholders seeking clarification on the rationale
behind specific decisions.
Find Unresolved Questions: Data plays a pivotal role in elucidating inquiries
that might otherwise remain unaddressed. Furthermore, data sets have the
capacity to unveil queries that were previously concealed from your awareness.
Regardless of the scale or volume of data involved, it confers a valuable
advantage to your team, allowing for enhanced insights into facets that remain
obscured in the absence of statistical analyses, graphical representations, and
charted data. By unearthing these latent questions, you can take solace in the
knowledge that your decisions have been meticulously informed, taking into
account a comprehensive spectrum of pertinent information.
Set Measurable Goals: Data plays a pivotal role in addressing previously
unanswerable questions, sometimes even revealing inquiries that were not
previously within your purview. Irrespective of the volume, data holds the
potential to greatly benefit your team, providing a clearer window into
dimensions that remain obscured without the aid of statistical analysis, graphs,
and charts. Bringing these latent queries to the forefront imbues confidence inyour decision-making process, assuring you that every piece of pertinent
information has been duly considered. In the realm of modern business strategy,
data-driven decision-making stands as an indispensable pillar. It empowers you to
establish quantifiable objectives for your team and subsequently guide them
toward successful achievement. Through an examination of internal data
reflecting past performance, you can identify areas for enhancement and set
highly specific targets. For instance, your team can utilize data to delineate
objectives such as:
1. Achieve a 20% year-over-year increase in customer acquisition.
2. Trim $20,000 from the quarterly budget.
3. Reduce project budget expenses by $500.
4. Expand the team by 10 members each quarter.
5. Lower the cost per hire by $500.
Without data, gaining insights into expenditure allocation and cost-cutting
opportunities would be a formidable challenge for your organization. Establishing
measurable goals ultimately guides your decision-making with data, as it prompts
you to devise strategies for attaining the set objectives, whether by trimming
budgets or expanding customer bases.
Improve Company Processes: While it is possible to enhance company
procedures without relying on data, the utilization of numerical metrics to observe
trends in team member performance or the examination of company spending
patterns through graphical analysis can significantly augment the process
improvement efforts beyond mere observation. Processes that can be refined
through the integration of data may encompass:
1. Enhancing risk management through the analysis of financial data.
2. Establishing cost estimates based on market pricing data.
3. Optimizing team member onboarding procedures through insights derived
from new hire performance data.
4. Elevating customer service standards by leveraging customer feedback data.
Introducing alterations to company processes can be a challenging endeavor,
particularly when the outcome is uncertain. However, the presence of concrete
facts and data empowers decision-makers with the confidence needed to navigate
these changes effectively.
6.3 DATA-DRIVEN OPTIMIZATION: A BRIEF
OVERVIEWThe dynamic realm of data-driven optimization (DDO) is in constant evolution,
harnessing the power of data to elevate the efficacy of decision-making across diverse
sectors. This section offers a concise introduction to DDO, accentuating its
importance, methodological approaches, and wide-ranging practical implementations
(Ye, 2014). DDO is predicated on the notion that data, when strategically harnessed,
can serve as a powerful catalyst for optimizing complex processes and systems. It
leverages vast datasets to inform and enhance decision-making, yielding solutions that
are not only efficient but also tailored to dynamic real-world conditions (Baardman et
al., 2023; Khan et al., 2020). In the other sight, one of the hallmark features of DDO is
its versatility across a myriad of domains. Whether applied in healthcare, finance,
logistics, or engineering, DDO exhibits its prowess in tackling multifaceted
challenges. Research findings from various fields have showcased how DDO can
streamline resource allocation, enhance operational efficiency, and yield substantial
cost savings (Saeid et al., 2021; Wang et al., 2023a).
At its core, DDO revolves around the art of making the best decisions when faced
with unpredictable circumstances. This entails the utilization of various optimization
models and computational techniques capable of handling data that is uncertain,
dynamic, structured, or dispersed across vast networks. While traditional mathematical
optimization seeks to maximize or minimize a function, denoted as h (x), within a
defined domain, DDO introduces a novel dimension by integrating additional input
data, denoted as ξ, thereby transforming the objective into the maximization of an
anticipated value (Bertsimas & Thiele, 2006; Khan et al., 2020). Within the realm of
DDO, a primary hurdle lies in effectively managing the unpredictable nature of ξ.
Conventional stochastic optimization necessitates precise information about the
specific distribution of ξ. Nonetheless, relying solely on such assumptions can result in
suboptimal outcomes when the real-world distribution differs from these assumptions.
In response, innovative approaches known as robust optimization have been
introduced, which require only knowledge of the potential range of uncertain
parameters. However, it’s worth noting that these approaches, while conservative in
nature, might not consistently deliver optimal results in practical scenarios (Mohajerin
Esfahani & Kuhn, 2018).
In the pursuit of a harmonious synergy between stochastic and robust optimization
techniques, distributionally robust optimization (DRO) has emerged as a compelling
solution. DRO operates by optimizing with the utmost consideration for the most
adverse potential expected cost value within a predefined set Γ, encompassing various
density functions or distributions. By adopting this approach, the optimization process
benefits from the incorporation of pertinent problem data while simultaneously
fortifying itself against errors stemming from deviations in distribution assumptions
(Soma et al., 2022). Beyond theoretical constructs, DDO has translated into tangible
practical implementations. An illustrative example involves the application of a data￾informed robust design optimization technique, aimed at enhancing both the
performance and the resilience to aerodynamic challenges of compressor blades. Thisinnovative approach assesses uncertainty by relying on statistical moments derived
from limited input data, and it leverages a Gaussian process regression model to
enhance the efficiency of robust optimization processes (Wang et al., 2023a).
Furthermore, DRO has been successfully employed in the context of inventory
management and financial decision-making, showcasing its adaptability across diverse
fields. This approach not only assesses the potential profits for both lenders and sellers
but also contributes novel managerial perspectives on the combined facets of inventory
and financing choices.
6.3.1 Data-driven optimization approaches
In today’s digital age, businesses and organizations are inundated with vast amounts of
data. This data, if harnessed effectively, can provide valuable insights and drive
informed decision-making. One powerful way to leverage this data is through DDO
approaches. These approaches involve using data analytics and mathematical
techniques to optimize processes, operations, and strategies. In this article, we will
explore the concept of DDO approaches, their benefits, and some real-world
applications (Luo, 2023; Lyu, 2022).
In today’s data-rich environment, organizations are leveraging DDO approaches as
sophisticated methodologies that harness the power of data analytics and mathematical
modeling to improve decision-making and outcomes across various domains. These
methodologies are designed to find the best possible solutions or decisions by
considering available data, constraints, and objectives. They play a pivotal role in
areas such as supply chain management, marketing, finance, and manufacturing,
among others (Tirkolaee et al., 2021; Yang et al., 2023). At the core of DDO lie
powerful mathematical algorithms capable of handling multiple variables, constraints,
and objectives. These algorithms come in various forms, including linear
programming, nonlinear optimization, and integer programming. Additionally,
machine learning techniques, such as regression analysis, neural networks, and genetic
algorithms, are commonly integrated into DDO models to further enhance their
adaptability and effectiveness. These methodologies are essential tools that enable
organizations to navigate the complexities of the modern business landscape. By using
data analytics and mathematical modeling, they empower informed decision-making,
leading to enhanced efficiency, cost reduction, increased competitiveness, and
ultimately, a competitive edge in today’s digital age (Aigner et al., 2023; De Loera et
al., 2021).
The primary objective of DDO is to find the best possible solutions or decisions
based on a combination of factors, including:
Data: DDO heavily relies on high-quality data. This can include historical data,
real-time data, and external data sources. The more comprehensive and accurate
the data, the more effective the optimization process.Constraints: Many real-world problems involve constraints or limitations. For
example, in supply chain management, constraints may include production
capacity, transportation costs, and delivery timeframes. DDO models take these
constraints into account to find feasible solutions.
Objectives: Organizations typically have specific objectives they want to
achieve, whether it’s maximizing profits, minimizing costs, optimizing resource
allocation, or achieving a particular level of service quality. DDO models aim to
meet these objectives.
At the core of DDO are mathematical algorithms designed to solve complex problems.
Some of the key mathematical techniques used in DDO include:
Linear Programming (LP): LP is a mathematical technique used to optimize a
linear objective function while satisfying linear equality and inequality
constraints. It is commonly employed in resource allocation and production
planning.
Nonlinear Optimization: In cases where the relationship between variables is
not linear, nonlinear optimization techniques come into play. These techniques are
used to find optimal solutions in scenarios with nonlinear constraints and
objectives.
Integer Programming (IP): IP is an extension of linear programming where
decision variables must take integer values. It is used in scenarios where solutions
must be whole numbers, such as in discrete optimization problems.
Machine Learning: Machine learning techniques, including regression analysis,
neural networks, and genetic algorithms, have found applications in DDO. These
methods can adapt to complex and dynamic data patterns.
Let’s explore some real-world applications of DDO approaches in greater detail:
1. Logistics and Supply Chain Management:
Scenario: Imagine a large e-commerce company with a vast network of
warehouses and a fleet of delivery trucks. They need to optimize their
delivery routes to ensure products reach customers quickly while minimizing
transportation costs.
DDO Approach: In this scenario, DDO involves collecting data on factors
such as customer locations, traffic patterns, delivery time windows, and
vehicle capacities. Using optimization algorithms like the traveling salesman
problem (TSP) or VRP, the company can determine the most efficient routes
for its delivery trucks. These algorithms consider multiple variables,
including distance, time, and vehicle capacity constraints, to create optimal
delivery schedules.Benefits: DDO in logistics and supply chain management leads to reduced
fuel consumption, shorter delivery times, and cost savings. It enhances
customer satisfaction by ensuring timely deliveries.
2. Finance:
Scenario: An investment firm manages a portfolio of assets on behalf of its
clients. They aim to maximize returns while managing the risk associated
with market fluctuations.
DDO Approach: DDO in finance involves analyzing historical financial
data, market trends, and asset performance. Portfolio optimization models
use techniques like mean-variance optimization to allocate assets in a way
that maximizes returns while minimizing risk. These models consider factors
such as asset correlations, expected returns, and volatility to construct
diversified portfolios.
Benefits: DDO in finance enables investment firms to make informed
investment decisions that balance risk and return. Clients benefit from
portfolios that aim to achieve their financial goals while managing market
volatility.
3. Manufacturing:
Scenario: A manufacturing company produces a variety of products on
multiple production lines. They want to optimize production schedules to
meet fluctuating demand while minimizing production costs.
DDO Approach: DDO in manufacturing involves collecting real-time data
from production lines, demand forecasts, and inventory levels. Using
optimization algorithms like mixed-integer linear programming (MILP) or
genetic algorithms, the company can determine the optimal production
schedule. These models consider factors such as production capacity, setup
times, and raw material availability to create efficient production plans.
Benefits: DDO in manufacturing leads to reduced production costs,
improved resource utilization, and better on-time delivery performance. It
helps companies respond swiftly to changes in customer demand.
4. Energy Management:
Scenario: A utility company is responsible for generating and distributing
electricity to a large customer base. They want to optimize power generation
and distribution to meet demand efficiently while minimizing costs and
environmental impact.
DDO Approach: DDO in energy management involves collecting data on
electricity demand, supply sources (e.g., coal, natural gas, renewables), and
market prices. Optimization models, often based on linear programming, are
used to determine the optimal mix of energy sources for power generation.These models consider factors such as fuel costs, emission levels, and grid
constraints.
Benefits: DDO in energy management helps utilities reduce operational
costs, minimize environmental impact by optimizing renewable energy use,
and ensure a reliable power supply to consumers.
5. Healthcare:
Scenario: A large hospital wants to optimize its patient scheduling, resource
allocation, and treatment plans to provide high-quality care while managing
costs.
DDO Approach: DDO in healthcare involves collecting data on patient
admissions, resource availability (e.g., beds, medical staff), and treatment
protocols. Optimization models, often based on integer programming, are
used to schedule surgeries, allocate healthcare personnel, and optimize
treatment plans for patients based on their medical histories.
Benefits: DDO in healthcare improves patient outcomes by reducing wait
times, ensuring efficient resource utilization, and enhancing the quality of
care. Hospitals can also reduce costs by optimizing resource allocation.
6. Marketing:
Scenario: A digital marketing agency runs online advertising campaigns for
its clients. They aim to optimize ad spend and maximize the ROI for each
campaign.
DDO Approach: DDO in marketing involves collecting data on ad
impressions, clicks, conversions, and customer behavior. Machine learning
algorithms are used to analyze this data and optimize advertising campaigns
in real-time. Techniques like A/B testing and predictive modeling help in
optimizing ad placements, targeting specific demographics, and adjusting ad
content.
Benefits: DDO in marketing leads to increased ROI, as advertisers can
allocate ad spend more effectively. By targeting the right audience with the
right message at the right time, marketing campaigns become more efficient
and cost-effective.
In each of these real-world applications, DDO approaches play a critical role in
solving complex problems, improving efficiency, and achieving specific objectives.
These approaches leverage data analytics and mathematical modeling to make
informed decisions and drive positive outcomes across various industries.
While DDO offers immense potential, it’s essential to be aware of the challenges
and ethical considerations:
1. Data Quality:DDO heavily relies on data accuracy, completeness, and reliability. Challenges
related to data quality include:
Data Accuracy: If the data used for optimization is inaccurate or contains
errors, the resulting decisions may be flawed. For example, using incorrect
product demand data in supply chain optimization can lead to overstocking
or understocking.
Data Completeness: Missing data can be a significant challenge.
Incomplete datasets can hinder the ability to create accurate optimization
models, especially when certain variables or factors are essential for
decision-making.
Data Consistency: Inconsistent data can arise from multiple sources or data
entry errors. Ensuring consistency is vital for creating coherent and reliable
optimization models.
2. Model Complexity:
Developing and implementing optimization models can be complex and
resource-intensive. Challenges related to model complexity include:
Specialized Expertise: Building and managing optimization models often
requires specialized knowledge in mathematics, statistics, and data science.
Organizations may need to invest in training or hire experts in the field.
Computational Resources: Some optimization problems can be
computationally demanding, requiring substantial processing power and
memory. Managing these resources effectively can be a challenge.
Maintenance: Optimization models may need periodic updates to remain
effective, especially in dynamic environments. Maintaining and retraining
models can be resource-intensive.
3. Overfitting:
Overfitting occurs when an optimization model becomes too closely tailored to
historical data, capturing noise or random variations rather than genuine patterns.
Challenges related to overfitting include:
Generalization: An overfitted model may not generalize well to new or
unseen data. It can make suboptimal decisions when faced with real-world
situations that differ from historical data.
Validation and Testing: Ensuring that an optimization model is not
overfitted requires robust validation and testing procedures. This can be
challenging, particularly when dealing with limited data.
6.3.2 Ethical considerations in data-driven optimization
1. Data Privacy:Data privacy is a paramount ethical concern in DDO. Organizations must
ensure that they handle data responsibly and protect individuals’ privacy rights.
Key considerations include:
Consent: Obtaining informed consent from individuals whose data is used
for optimization is essential. Individuals should be aware of how their data is
being used and have the option to opt-out.
Anonymization: Removing personally identifiable information (PII) or
using techniques like differential privacy can help protect privacy while still
allowing for DDO.
2. Bias and Fairness:
Bias can be inadvertently introduced into optimization models through biased
training data or algorithmic biases. Ethical considerations related to bias and
fairness include:
Fairness: Optimization models should be designed to avoid discriminatory
outcomes. This is particularly important in areas like lending, hiring, and
criminal justice, where biased decisions can have serious consequences.
Transparency: Organizations should aim for transparency in their
optimization models. This includes understanding how decisions are made
and identifying potential sources of bias.
3. Accountability:
Accountability is crucial in DDO. Organizations must be accountable for the
decisions made based on optimization models, especially when those decisions
impact individuals or society as a whole. Key considerations include:
Human Oversight: While optimization models can automate decision￾making, there should be mechanisms for human oversight and intervention
when necessary. Human judgment should always play a role in critical
decisions.
Accountability Frameworks: Organizations should establish accountability
frameworks that define responsibilities for model development, validation,
and deployment.
4. Unintended Consequences:
DDO can lead to unintended consequences. Organizations should be vigilant
about monitoring and mitigating these consequences. Challenges include:
Feedback Loops: Optimization models can create feedback loops where
decisions reinforce existing patterns, potentially exacerbating inequalities or
biases.
Sensitivity Analysis: Conducting sensitivity analysis can help identify
potential unintended consequences and inform decision-making.Addressing these challenges and ethical considerations is essential for ensuring that
DDO approaches are used responsibly and effectively in today’s data-driven world.
Organizations must strike a balance between harnessing the power of data and
safeguarding individual rights and societal well-being.
In summary, DDO approaches are powerful tools that rely on mathematical
techniques and data analytics to enhance decision-making across various industries.
By taking into account data, constraints, and objectives, organizations can make more
informed decisions, increase efficiency, reduce costs, and gain a competitive edge.
However, it’s essential to navigate the challenges and ethical considerations associated
with these approaches to fully realize their benefits in today’s data-driven world.
6.4 INTELLIGENT DATA-DRIVEN APPROACHES
FOR DECISION-MAKING
In the contemporary landscape of rapidly evolving technology and global connectivity,
the ability to make informed and timely decisions has taken center stage. For
businesses, organizations, and even individuals, navigating the vast sea of information
has become an essential skill. The advent of the digital age has ushered in a paradigm
shift in decision-making, characterized by a heavy reliance on intelligent data-driven
approaches. These approaches leverage advanced technologies and analytical
techniques to extract valuable insights from data, transforming the way decisions are
made and strategies are formulated.
The modern world is inundated with data, and it’s not an exaggeration to say that
data is now one of the most valuable resources available. The sheer volume and
complexity of data generated on a daily basis are staggering, encompassing a wide
array of information ranging from customer behavior and market trends to sensor
readings and social media interactions. This data, often referred to as “big data,”
represents a goldmine of untapped potential. However, the challenge lies in effectively
harnessing this vast and often chaotic treasure trove of information and converting it
into actionable insights.
What sets intelligent data-driven approaches apart is their ability to make sense of
this data deluge. These approaches encompass a spectrum of technologies,
methodologies, and tools designed to process, analyze, and interpret data in ways that
were previously inconceivable. By doing so, they empower decision-makers with the
knowledge and foresight required to make decisions that are not only informed but
strategic.
6.4.1 The power of data
To appreciate the significance of intelligent data-driven approaches, one must first
acknowledge the transformative power of data. Data, often likened to the “new oil” ofthe digital economy, is the lifeblood of modern organizations. It provides a window
into the behaviors, preferences, and trends that shape industries, markets, and societies.
In essence, data is the raw material from which insights are distilled, strategies are
devised, and innovations are born. It highlights how data has become a strategic asset
for businesses, organizations, and even individuals. Here’s a more detailed explanation
of the power of data:
Data as a Strategic Asset: In the past, data was often seen as a byproduct of
business operations, and its potential was largely untapped. However, in the
modern era, data has evolved into a valuable asset that can drive growth,
innovation, and competitiveness. Organizations now recognize that data is not
just something to be collected and stored but a resource that, when harnessed
effectively, can lead to significant advantages.
Data-Driven Decision-Making: The power of data lies in its ability to inform
decision-making. Through data analysis, organizations can gain insights into
customer preferences, market trends, operational efficiencies, and more. This
information allows decision-makers to make informed, evidence-based choices
that can lead to better outcomes. Data-driven decision-making is not limited to
business; it is also crucial in fields such as healthcare, education, and public
policy.
Competitive Advantage: In many industries, the ability to collect, analyze, and
act upon data has become a critical factor for gaining a competitive edge.
Companies that effectively leverage data can identify opportunities, optimize
processes, and stay ahead of their competitors. For example, e-commerce
companies use data to personalize recommendations, while manufacturing
companies use it to predict maintenance needs and reduce downtime.
Innovation and Research: Data is a valuable resource for research and
innovation. Scientific discoveries, medical breakthroughs, and technological
advancements often rely on the analysis of large datasets. Researchers can
uncover new insights, patterns, and correlations by studying data, leading to
innovations that can improve lives and drive progress.
Personalization: The power of data is evident in the way it enables
personalization. Online platforms, such as social media and e-commerce
websites, use data to tailor content, recommendations, and advertisements to
individual users. This enhances user experiences and increases engagement.
Risk Management: Data plays a crucial role in risk assessment and management.
In the financial industry, for example, banks use data to assess the
creditworthiness of loan applicants, while insurance companies analyze data to
determine policy pricing and coverage. These risk assessments help organizations
make informed decisions and mitigate potential losses.Challenges and Responsibilities: While data is a powerful tool, it also comes
with challenges and responsibilities. Issues related to data privacy, security, and
ethics are paramount. Organizations must handle data responsibly, ensuring that it
is protected and that privacy rights are respected. Additionally, the potential for
biases in data and algorithms must be addressed to ensure fairness in decision￾making processes.
In conclusion, “The Power of Data” underscores the transformative impact that data
has on various aspects of our lives, from business operations and decision-making to
research, innovation, and personalization. It is a valuable resource that, when managed
and analyzed effectively, can lead to significant benefits and opportunities for
individuals and organizations alike. However, it is essential to approach data with a
sense of responsibility and ethical consideration to maximize its positive impact.
6.4.2 Artificial intelligence and machine learning
At the heart of intelligent data-driven decision-making are artificial intelligence (AI)
and machine learning (ML) technologies. These computational marvels enable
computers to sift through massive datasets, recognize intricate patterns, and even
predict future outcomes. For instance, in the realm of finance, AI-driven algorithms
can analyze real-time market data to make investment decisions, while in healthcare,
ML models can assist in diagnosing diseases based on patient data and medical
records.
Artificial Intelligence (AI): Artificial Intelligence refers to the development of
computer systems that can perform tasks that typically require human
intelligence. These tasks include understanding natural language, recognizing
patterns, solving complex problems, and making decisions. AI systems aim to
mimic human cognitive functions, such as learning, reasoning, problem-solving,
and perception. In the context of data-driven decision-making, AI can:
1. Analyze Data:
AI algorithms can process and analyze vast amounts of data quickly and
accurately. They can identify patterns, anomalies, and insights that may be
challenging for humans to discover manually.
2. Make Predictions:
AI models, like neural networks and decision trees, can be trained on
historical data to make predictions about future events. For example, in the
retail industry, AI can predict customer demand for specific products based
on past sales data and external factors like seasonality and economic trends
3. Recommendations:AI-powered recommendation systems are prevalent in e-commerce,
streaming services, and content platforms. They use ML techniques to
analyze user behavior and preferences to provide personalized
recommendations. These recommendations can significantly impact user
engagement and sales.
4. Natural Language Processing (NLP):
AI can understand and generate human language. This capability is
harnessed for sentiment analysis, chatbots, and language translation, among
other applications. In customer service, for instance, AI-driven chatbots can
handle customer inquiries, freeing up human agents for more complex tasks.
5. Computer Vision:
AI is used in computer vision applications to interpret and understand
visual information from images or videos. This has applications in
healthcare (medical image analysis), automotive (autonomous vehicles), and
surveillance.
Machine Learning (ML): Machine Learning is a subset of AI focused on the
development of algorithms and statistical models that enable computers to
improve their performance on a task through learning from data, without being
explicitly programmed. ML encompasses various techniques, including
supervised learning, unsupervised learning, and reinforcement learning. In the
context of data-driven decision-making, ML can:
1. Pattern Recognition:
ML models excel at recognizing patterns in data. For instance, ML
algorithms can classify emails as spam or not based on patterns in email
content, helping to filter out unwanted messages.
2. Predictions:
ML models can make predictions based on historical data. In financial
services, ML algorithms can predict stock prices, credit risk, and fraud
detection by analyzing past transactions and market data.
3. Clustering and Segmentation:
Unsupervised ML techniques like clustering help identify groups or
segments within data. In marketing, clustering can be used to segment
customers based on behavior, allowing for targeted marketing campaigns.
4. Anomaly Detection:
ML models can detect unusual or anomalous patterns in data, which is
vital for cybersecurity (detecting unusual network activity) and quality
control (identifying defective products in manufacturing).
5. Optimization:
ML can optimize processes and resources. For instance, in supply chain
management, ML algorithms can optimize inventory levels and distributionroutes to reduce costs.
In conclusion, AI and ML are powerful tools in the realm of intelligent data-driven
decision-making. They enable organizations to leverage their data for insights,
predictions, and automation, ultimately leading to more informed and effective
decision-making processes across a wide range of industries.
6.4.3 Predictive analytics
Predictive analytics, a pivotal component of intelligent data-driven decision-making,
harnesses historical data to forecast future events and trends. By scrutinizing past
patterns within the data, organizations can make highly accurate predictions about
customer behavior, demand for products, and even equipment maintenance
requirements. This predictive power empowers businesses to optimize their strategies
and allocate resources with pinpoint precision. It involves the application of
mathematical and computational techniques to identify patterns, relationships, and
trends within data, allowing organizations to make informed decisions and take
proactive actions. Here’s a more detailed explanation of predictive analytics:
Historical Data Analysis: Predictive analytics begins with the collection and
analysis of historical data. This data can come from various sources, including
customer records, sales transactions, website interactions, sensor readings, and
more. The historical data serves as the foundation for building predictive models.
Pattern Recognition: Predictive analytics algorithms are designed to recognize
patterns and relationships within the data. These patterns can be subtle and
complex, making them difficult for humans to detect without the assistance of
computational tools. The algorithms look for correlations, trends, and
dependencies that might not be immediately apparent through simple data
examination.
Feature Selection: In the process of building predictive models, analysts often
identify relevant features or variables from the dataset. These features are the
attributes or characteristics that are believed to have a significant impact on the
outcome being predicted. Feature selection helps streamline the model and
improve its accuracy.
Model Building: Once the relevant features are identified, predictive models are
constructed. These models can take various forms, including regression models,
decision trees, neural networks, and more. The choice of model depends on the
nature of the problem and the characteristics of the data.
Training the Model: The predictive model is “trained” using historical data.
During training, the model learns to recognize patterns and relationships between
the selected features and the outcomes of interest. The goal is to create a model
that can accurately predict future outcomes based on these learned patterns.Validation and Testing: After the model is trained, it is validated and tested
using separate datasets that it hasn’t seen before. This step is crucial to ensure that
the model can generalize well and make accurate predictions on new, unseen data.
Cross-validation techniques may also be employed to assess the model’s
performance.
Predictions and Recommendations: Once the predictive model is validated and
deemed accurate, it can be used to make predictions about future events or
outcomes. For example, in a business context, predictive analytics might be used
to forecast sales, customer churn, equipment failures, or supply chain disruptions.
The results of these predictions can inform decision-making processes.
Optimizing Strategies: Predictive analytics doesn’t just stop at making
predictions. It also enables organizations to optimize their strategies. For instance,
if a model predicts that there will be a surge in demand for a product during a
specific period, the organization can adjust its inventory levels, marketing
campaigns, and pricing strategies accordingly.
Continuous Improvement: Predictive analytics is an iterative process. Models
can be continuously improved by incorporating new data and refining algorithms.
This ongoing process helps organizations adapt to changing circumstances and
maintain the accuracy of their predictions.
In conclusion, predictive analytics is a powerful tool for organizations seeking to make
data-driven decisions about future events. By analyzing historical data, building
predictive models, and validating their accuracy, organizations can gain valuable
insights that enable them to anticipate trends, mitigate risks, and optimize their
operations.
6.4.4 Data visualization
As data grows in complexity, the ability to present it in a comprehensible manner
becomes increasingly critical. This is where data visualization tools come into play.
Through the use of visually appealing charts, graphs, and interactive dashboards,
decision-makers can swiftly grasp essential insights from the data. These visual
representations help identify trends, anomalies, and correlations that might otherwise
remain hidden in the labyrinth of raw data, making them invaluable for data-driven
decision-making. Its primary purpose is to make complex datasets more accessible,
understandable, and interpretable for decision-makers, analysts, and other
stakeholders. Here are some key aspects of data visualization:
Simplifying Complex Data: Raw data can be overwhelming, especially when
dealing with large datasets. Data visualization simplifies this complexity by
transforming numbers and text into visual elements that are easier to grasp. Thissimplification is crucial for decision-makers who need to quickly understand the
significance of the data.
Identifying Trends and Patterns: Through visual representation, data
visualization tools enable users to identify trends, patterns, and relationships
within the data that might not be apparent in raw numbers. For example, a line
chart can reveal sales trends over time, helping a business adjust its marketing
strategy accordingly.
Comparing Data: Visualization allows for easy comparison of different datasets
or data points. Bar charts, for instance, can be used to compare sales figures for
multiple products or regions. This facilitates more informed decision-making by
highlighting disparities and similarities.
Spotting Outliers: Outliers, which are data points significantly different from the
majority, can have a substantial impact on decision-making. Data visualization
can help detect outliers quickly, enabling organizations to investigate the causes
and take appropriate actions.
Interactive Dashboards: In addition to static charts and graphs, data
visualization tools often include interactive dashboards. These dashboards allow
users to drill down into the data, apply filters, and explore specific aspects of the
information. For instance, a business dashboard might enable users to filter sales
data by region, time period, or product category.
Storytelling with Data: Effective data visualization can tell a story. By arranging
data elements in a logical sequence and using appropriate visuals, it’s possible to
guide the viewer through a narrative. This is particularly useful when presenting
data to stakeholders or the general public, as it helps convey the significance of
the information.
Decision Support: Ultimately, data visualization plays a crucial role in decision
support. When decision-makers can see the data in a visual form, they are better
equipped to make informed choices. For example, a hospital administrator may
use a heatmap showing patient wait times to allocate staff resources efficiently.
Customization: Data visualization tools often allow customization of the visuals
to suit specific needs. Users can choose different chart types, color schemes, and
labeling options to convey the information effectively.
Accessibility and Inclusivity: It’s important to create data visualizations that are
accessible to all users, including those with disabilities. This involves providing
alternative text for images, using high-contrast colors, and ensuring compatibility
with screen readers.
In conclusion, data visualization is a powerful tool in the realm of intelligent data￾driven decision-making. It goes beyond mere aesthetics; it serves as a means to unlock
the insights hidden within data, making it an indispensable part of modern business
analytics and decision support systems. Effective data visualization empowersorganizations to make more informed, strategic, and timely decisions by presenting
data in a visually compelling and comprehensible manner.
6.4.5 Real-time decision support systems
In our fast-paced, interconnected world, the need for real-time decision-making (DSS)
has skyrocketed. Industries such as e-commerce, logistics, and telecommunications
rely on data-driven decision support systems that can process and analyze data
instantaneously. These systems provide immediate insights and recommendations,
enabling organizations to respond swiftly to shifting conditions and evolving customer
preferences. DSS are a critical component of intelligent data-driven approaches for
decision-making, and they play a pivotal role in enabling organizations to make
informed and timely decisions. Let’s dive deeper into what real-time DSS are and how
they work:
Real-time Data Processing: Real-time DSS are designed to process and analyze
data as it is generated, providing immediate insights and recommendations. This
real-time processing is crucial in industries where rapid decision-making is
essential, such as e-commerce, financial trading, healthcare, and supply chain
management. It allows organizations to respond quickly to changing conditions,
emerging opportunities, and potential threats.
Data Integration: Real-time DSS often integrates data from various sources,
including internal databases, external feeds, sensors, and IoT devices. This
integration ensures that decision-makers have access to a comprehensive and up￾to-date view of relevant information. For example, a logistics company may use
real-time DSS to monitor the location of its delivery trucks, weather conditions,
and traffic data to optimize routes and delivery schedules.
Advanced Analytics: Real-time DSS leverages advanced analytics techniques,
including ML algorithms, to process and analyze incoming data. These algorithms
can identify patterns, anomalies, and trends in real-time data streams. For
instance, in the context of online retail, real-time DSS can use ML to analyze
customer browsing and purchasing behavior to make personalized product
recommendations in real-time.
Decision Automation: In some cases, real-time DSS can automate decision￾making processes based on predefined rules and algorithms. For example, in a
cybersecurity context, real-time DSS can automatically detect and respond to
security threats by blocking suspicious network traffic or alerting security
personnel. This automation reduces the response time to security incidents and
minimizes the potential impact.
Visualization and Alerts: Real-time DSS often provides user-friendly
dashboards and visualizations that enable decision-makers to monitor KPIs and
metrics in real-time. Alerts and notifications can be set up to inform decision-makers of critical events or deviations from expected outcomes. For instance, a
stock trading platform might provide real-time charts and alerts to help traders
make split-second decisions based on market data.
Business Process Integration: Real-time DSS can be integrated into an
organization’s existing business processes. For example, in manufacturing, real￾time DSS can be used to monitor equipment performance and quality control,
automatically triggering maintenance requests or production adjustments when
anomalies are detected.
Scalability and Performance: To be effective, real-time DSS must be highly
scalable and capable of handling large volumes of data in real-time. They often
require robust computing infrastructure and fast data processing capabilities to
ensure low latency in decision-making.
Industry Applications: Real-time DSS are applied in various industries,
including finance (for algorithmic trading), healthcare (for patient monitoring and
treatment recommendations), transportation (for route optimization), and online
advertising (for personalized ad targeting), among others.
In conclusion, real-time decision support systems are instrumental in harnessing the
power of data for immediate decision-making. They enable organizations to process,
analyze, and act upon real-time data streams, facilitating agility, efficiency, and
competitiveness in today’s fast-paced business environment.
6.4.6 Ethical considerations
Amidst the enthusiasm for intelligent data-driven approaches, it’s essential to
acknowledge the ethical dimensions of data usage. Concerns regarding the collection
and utilization of personal data, the potential for bias in AI algorithms, and the
implications of automated decision-making have ignited important discussions and
prompted regulatory actions. Organizations must navigate these ethical considerations
with care, emphasizing transparency, fairness, and data privacy in their decision￾making processes. Let’s dive deeper into the ethical considerations surrounding
intelligent data-driven approaches for decision-making:
Data Privacy and Security: One of the foremost ethical concerns is the
collection, storage, and handling of personal and sensitive data. In the quest for
valuable insights, organizations often collect vast amounts of data, including
individuals’ personal information. The misuse or mishandling of this data can
lead to privacy breaches and security vulnerabilities. It’s crucial to have robust
data privacy policies and security measures in place to protect the information
and gain the trust of customers and stakeholders.
Bias and Fairness: ML algorithms used in data-driven decision-making can
inadvertently perpetuate bias present in historical data. If historical data containsbiases related to gender, race, or other sensitive attributes, algorithms may make
biased predictions or recommendations. Addressing bias and ensuring fairness in
AI models is an ethical imperative. This involves careful data preprocessing,
algorithm design, and ongoing monitoring to identify and rectify bias in decision￾making systems.
Accountability and Transparency: As decision-making processes become more
automated and reliant on AI and ML, it becomes challenging to ascertain who is
accountable for the outcomes. Ensuring transparency in how decisions are made
and establishing clear lines of responsibility is essential. Individuals impacted by
automated decisions should have the ability to understand how those decisions
were reached and seek recourse if they believe an error or bias exists.
Informed Consent: Organizations must obtain informed consent from
individuals when collecting their data. This means individuals should be fully
aware of how their data will be used, who will have access to it, and for what
purposes. Consent should be freely given, informed, specific, and revocable.
Transparent data collection practices and clear communication with individuals
are essential components of ethical data-driven decision-making.
Discrimination and Disadvantages: Data-driven decision-making systems can
inadvertently create or exacerbate disadvantages for certain groups. For example,
if an AI-driven recruitment system favors candidates from a specific demographic
group, it may perpetuate inequalities in the workplace. Organizations need to be
vigilant in ensuring that data-driven decisions do not disproportionately
disadvantage any particular group.
Regulation and Compliance: Governments and regulatory bodies around the
world are developing and implementing rules and regulations to address ethical
concerns in data-driven decision-making. Organizations must stay informed about
these regulations and ensure compliance. This includes the General Data
Protection Regulation (GDPR) in Europe, the California Consumer Privacy Act
(CCPA), and various sector-specific regulations.
Human Oversight: While automation can streamline decision-making processes,
there should always be a level of human oversight. Humans can provide critical
judgment, context, and ethical guidance that algorithms alone cannot. Ethical
decision-making often requires a blend of data-driven insights and human
judgment.
In conclusion, ethical considerations are paramount in the realm of intelligent data￾driven decision-making. As organizations harness the power of data and advanced
technologies, they must do so responsibly, with a strong commitment to protecting
privacy, addressing bias, ensuring transparency, and upholding fairness. Ethical
practices not only mitigate risks but also enhance trust among customers, partners, and
the public, ultimately contributing to the long-term success of data-driven initiatives.6.5 OPTIMIZATION ALGORITHMS IN
INTELLIGENT DECISION-MAKING
As the array of optimization methodologies and their practical applications continues
to expand, researchers have undertaken systematic comparative analyses to gauge their
effectiveness. When conducted rigorously, these comparative assessments serve as
invaluable tools, aiding end-users in their selection of the most suitable optimization
strategy for specific problem domains. Such investigative endeavors are commonly
referred to as “optimization benchmarking” (Beiranvand et al., 2017). In a broader
perspective, benchmarking entails the systematic evaluation of one or multiple entities
in comparison to established industry standards, encompassing a variety of
performance criteria. When applied within the context of benchmarking optimization
algorithms, the entities scrutinized are specific instantiations of these algorithms. Their
performance metrics are derived through rigorous assessments conducted across a
diverse range of problem scenarios (Beiranvand et al., 2017). This approach brings a
certain level of clarity to the process of benchmarking optimization algorithms by
establishing a shared understanding of what constitutes ‘superior’ performance. In an
ideal scenario, one approach could be deemed superior to another across all
conceivable parameters – faster execution, reduced memory consumption, and the
production of superior final results. However, practical reality often diverges from
such definitive conclusions. In practice, assessing the outcomes of algorithmic
comparisons can pose challenges, as unequivocal judgments are seldom reached.
Nevertheless, when executed correctly, the benchmarking of optimization
techniques proves to be an invaluable endeavor. It serves to unveil the strengths and
vulnerabilities inherent in an algorithm, thereby guiding more targeted research efforts.
Moreover, it aids in validating whether a new iteration of optimization software
performs as anticipated. For end-users, it offers guidance in selecting the most
appropriate algorithm for specific real-world scenarios.
In contrast, when the process of benchmarking optimization strategies is not carried
out correctly, it holds the potential to distort the evaluation of an algorithm’s strengths
and weaknesses, present fictitious improvements, or recommend an unsuitable
algorithmic choice for a particular context. Benchmarking optimization practices
involve a multitude of subjective judgments, including factors such as the selection of
the test dataset, the determination of the computing environment, the establishment of
performance evaluation criteria, and more. Shifting our attention to the sphere of
business decisions, the challenge extends far beyond the initial decision-making
process; it encompasses the repercussions of those decisions when they fail to yield the
anticipated outcomes. Within this context, numerous common challenges surface in the
course of making business decisions which include:
Insufficient Data: A fundamental challenge faced by many managers and leaders
within organizations is the dearth of information necessary for making well-informed business decisions. When essential information is lacking, those in
leadership positions find themselves navigating through a sea of uncertainty,
hindering their ability to grasp the required insights and make optimal choices
(Malak, 2023).
Overwhelmed by Data: In the past, the prevailing belief was that a surplus of
information and data equated to enhanced decision-making capabilities. However,
in the contemporary business landscape, an excess of data can actually impede
effective decision-making. When confronted with an abundance of data,
individuals may find themselves grappling with feelings of overwhelm and over￾analysis, which can ultimately hinder or jeopardize the decision-making process.
More data doesn’t always equate to better outcomes (CHE Jingshang et al.,
2019).
Time Constraints: Imposed time limitations can exert added pressure,
compelling a quicker business decision than initially anticipated. When
confronted with the need for swift decision-making, there is a risk that the desired
outcomes may be compromised. This haste might inadvertently lead to the
omission of crucial details or the oversight of the relative significance of one
course of action over another (Ordonez & Benson III, 1997).
Dealing with Ambiguity: Another challenge confronting decision-makers within
organizations is the inherent ambiguity they encounter. Regardless of their daily
exposure to uncertainties, even the most seasoned leaders can find it challenging
to surmount the cloud of uncertainty about what lies ahead. This ambiguity can
arise from shifting business landscapes, limited access to information, and the
potential misinterpretation or misunderstanding of available data (Arend, 2020).
Fortunately, decision intelligence, an integral component of the decision-making
process at the enterprise level, can offer effective solutions to the frequent challenges
and difficulties that businesses encounter when dealing with complex decisions.
Decision intelligence functions as a robust instrument for elevating the effectiveness
and accuracy of corporate decision-making processes. This purpose-designed and
automated approach enables enterprises to adeptly manage vast datasets, thereby
enhancing decision-making capabilities across their entire organizational spectrum
through the seamless integration of AI and ML technologies. Decision intelligence, a
fusion of social science and data science, democratizes analytics by leveraging ML on
current data, enabling company leaders to make informed decisions. It places no
emphasis on who is ‘right’ or the most knowledgeable in a room but rather takes
existing business insights, automates their delivery, and presents them in a manner
understandable even to non-technical users. Organizational leaders can harness
decision intelligence to facilitate well-informed decisions by employing automated
knowledge and comprehension (Sarker, 2021).
You might wonder why it’s beneficial to replace your existing decision models with
AI-driven ones. Traditional business models often result in decisions influenced byroutine, biases, or a reluctance to acknowledge the shortcomings of these models
(Colson, 2019). In contrast, decision models infused with AI and analytics, commonly
known as decision intelligence, empower organizations to align with evolving
consumer demands, maintain a competitive edge, and cultivate agility in adapting to
change. By integrating ML algorithms into the decision-making process, decision
intelligence has the potential to enhance decision models. For companies incorporating
AI into their daily decision-making processes, the key lies in having confidence in the
outputs generated by AI. Decision intelligence platforms are emerging as a solution to
expedite decision-making across various industries, fostering trust in AI-driven
decision outcomes (Bornet, 2022).
Decision intelligence provides several advantages for today’s enterprises. Here are a
few of the advantages of including decision intelligence in decision-making strategy:
Decisions Based on Data: To achieve a competitive advantage in today’s
business environment, your decision-making models must be capable of
analyzing existing data, forecasting forecasts or outcomes, and selecting the best
alternative for your firm. AI decision-making systems in decision intelligence
examine data considerably more deeply, recognizing any unusual or previously
unknown patterns. By detecting probable anomalies, AI avoids the possibility of
vulnerabilities and interruptions in the data, which might have a significant
impact on the company (Gupta et al., 2022).
Quicker Decisions: If your business spends too much time attempting to make
the correct conclusion, AI decision-making technologies drastically shorten the
process by rapidly digesting massive, disparate volumes of data. Reducing the
time it takes to analyze vast volumes of data might help your company make
better decisions in less time (Ross & Taylor, 2021).
Biases and Mistakes Are Eliminated: If your leadership team consistently
encounters cognitive and emotional biases while making decisions, decision
intelligence solutions can assist in eradicating them from having a direct
influence on the outcomes of business decisions. Because decision intelligence
algorithms look at the given data objectively and are not vulnerable to cognitive
and emotional biases, they may entirely avoid these biases (Belenguer, 2022).
Effective decision-making with intelligence demands essential skills like drawing
meaningful conclusions from empirical data, making deductive inferences based on
foundational knowledge, and selecting the best option from a set of alternatives.
Software designed for fuzzy multiple criteria decision-making (FMCDM) has been
developed and rigorously evaluated in practical, real-world scenarios. Challenges in
multicriteria decision-making (MCDM) arise when individuals or a group of decision￾makers are tasked with selecting the most suitable option from a multitude of available
alternatives (Kahraman, 2008). The fundamental stages of MCDM encompass the
following key steps:1. Generating alternative systems to fulfill the defined objectives.
2. Assessing the alternatives based on the chosen criteria.
3. Employing a normative multicriteria analysis technique.
4. Ultimately, designating one alternative as the ‘optimal’ choice (dos Santos
Gonçalves & Campos, 2022).
In essence, decision-makers (DMs) are required to assess both quantitative and
qualitative aspects of the criteria when evaluating the available alternatives.
Conventional problems in MCDM typically involve precise numerical judgments,
necessitating an evaluation of option performance across each criterion. Conversely,
information pertaining to alternatives often lacks precision, with DMs capable of
providing only approximations, fragmentary details, or vaguely defined data.
Furthermore, the subjective nature of some criteria complicates matters. To tackle
these issues, the widespread adoption of fuzzy set theory in MCDM problems has
emerged as a promising approach to address common decision-making challenges. Its
primary objective is to mitigate the impact of imprecision, encompassing elements
such as human judgment and preferences when seeking the optimal solution (Al
Mohamed et al., 2023).
Conversely, employing FMCDM techniques can give rise to a range of challenges.
Even in relatively straightforward scenarios, the required computations can be time￾consuming and prone to errors. Consequently, the development of suitable software for
implementing these procedures becomes pivotal. Accordingly, efforts are underway to
design software that facilitates the utilization of two distinct FMCDM methodologies.
The primary aim of this study is to develop software intended for the application of
these two FMCDM approaches, specifically within the context of addressing two
practical, real-world challenges. Furthermore, the discussed problems exemplify how
this software can assist DMs in uncovering intriguing insights.
When it comes to elevating decision-making processes within organizations, the
integration of intelligent, data-informed strategies becomes of utmost importance.
Decision intelligence stands out as a potent approach that melds data, analytical
techniques, and AI, with the aim of refining decision-making and revealing fresh
pathways for progress and evolution (Andrew Yeung, 2023; Dilmegani, 2023).
Decision intelligence can be defined as the deliberate and strategic application of
data, analytics, and AI with the primary goal of enhancing and optimizing the
decision-making process. It encompasses a wide array of methodologies, including but
not limited to ML, predictive analytics, and natural language processing. Instead of
depending on instinct or historical precedent, decision intelligence empowers entities,
be they businesses or institutions, to make informed choices grounded in valuable
insights gleaned from data analysis (Andrew Yeung, 2023; Kozyrkov, 2019).
Key Benefits of Decision Intelligence: Implementing decision intelligence offers
several benefits for businesses in today’s complex landscape (Andrew Yeung, 2023):Improved Decision-Making: Executives can utilize analytics to evaluate
scenarios and select the most suitable option.
Reduced Risks and Uncertainty: Potential risks can be identified, outcomes
investigated, and mitigation strategies developed.
Increased Efficiency: Decision intelligence facilitates faster and more agile
decision-making.
Enhanced Collaboration: By aligning stakeholders and providing a single
source of truth, communication, and alignment improve (Dilmegani, 2023).
Getting Started with Decision Intelligence: To integrate decision intelligence into an
organization, a systematic approach is recommended (Andrew Yeung, 2023):
Define Decision-Making Criteria: Identify critical factors for decision-making
and establish evaluation methods.
Gather and Analyze Data: Collect relevant quantitative and qualitative data
from various sources.
Identify Patterns and Insights: Employ data visualization and analysis tools to
identify trends and correlations.
Evaluate Options and Decide: Utilize insights to evaluate options and make
informed decisions (Bornet, 2022).
Examples of Decision Intelligence in Action: Decision intelligence finds application
across a spectrum of industries and scenarios (Çıtak, 2023):
Resource Allocation and Risk Mitigation: Airlines optimize flight schedules to
minimize delays and maximize profits.
Autonomous Decision-Making: AI systems autonomously handle tasks like
music playback through devices such as Amazon’s Alexa.
Virtual Assistance: AI assists healthcare professionals in diagnosing diseases and
recommending treatments.
AI in Business Decision-Making: AI-driven workflows are becoming vital for data￾driven decision-making in businesses. AI can analyze complex data sets, offer insights,
and optimize decision-making processes. For instance, AI-based smart analytics
systems like Alexa or Siri can swiftly answer specific questions about product
performance, reducing the need for manual data analysis and resource allocation
(Juillet, 2023).
In the context of decision-making, the amalgamation of optimization algorithms
and intelligent strategies guided by data-driven insights has surfaced as a formidable
framework for elevating the efficiency and results of organizational operations. This
innovative approach, often referred to as decision intelligence, leverages theconvergence of data, analytics, AI, and human expertise to facilitate optimal choices in
complex scenarios. Decision intelligence represents a structured methodology that
harnesses the potential of data-driven insights, analytics, and AI techniques to optimize
decision-making (Andrew Yeung, 2023).
Through the incorporation of a diverse range of tools, such as ML, natural language
processing, and predictive analytics, decision intelligence grants organizations the
capacity to arrive at well-informed decisions that lead to improved results. Decision
intelligence highlights the harmonious relationship between advanced AI technologies
and the cognitive abilities of human beings (Çıtak, 2023).
By combining the precision of AI algorithms with human judgment, decision
intelligence generates actionable recommendations and strategic insights. Heuristics
play a crucial role in the realm of optimization algorithms and intelligent decision￾making. They are problem-solving or decision-making techniques that guide
algorithms toward finding practical solutions for complex problems using minimal
relevant information, past results, and experiences (Spaulding, 2020).
Heuristics prioritize speed and practicality over absolute perfection, making them
valuable in situations where deriving a step-by-step algorithmic solution is impractical
or computationally expensive. Heuristics are particularly important in fields such as
ML, AI, transportation, logistics, finance, and more. They are often used when there is
no known exact algorithm that can provide a solution or when using such an algorithm
is too resource-intensive. Instead of guaranteeing optimal solutions, heuristics aim to
produce reasonably good solutions within a reasonable timeframe. These approaches
are employed in various industries to optimize delivery routes, minimize risks in
financial investments, and solve other complex problems (Taşkın, 2022).
Enhancing the performance of optimization algorithms is often achieved by
integrating heuristic approaches. These algorithms are designed to seek the most
optimal solution within a given set of feasible options. The amalgamation of heuristics
with optimization algorithms offers practitioners the opportunity to enhance the
efficiency and efficacy of their solutions. Heuristic optimization algorithms encompass
various methods such as hill climbing, simulated annealing, genetic algorithms, and
other similar techniques, all of which utilize heuristic principles to steer the quest for
optimal solutions (Rai et al., 2022).
Furthermore, the integration of heuristics with optimization algorithms is especially
evident in fields such as tunnel engineering and healthcare. For instance, support
vector regression coupled with heuristic optimization algorithms has been used to
predict ground surface displacement induced by shield tunneling in civil engineering
contexts (Verma & Parouha, 2021).
In the field of healthcare, metaheuristic algorithms rooted in heuristic principles
have found practical application in categorizing diseases related to the heart. This
application highlights their effectiveness in aiding medical decision-making and
diagnostic processes. In general, heuristics is a powerful approach that guides
optimization algorithms in making intelligent decisions and solving complex problemsefficiently. By utilizing minimal relevant information and leveraging past experiences,
heuristics enhance the practicality and speed of solutions in various domains, from AI
to engineering and beyond. These techniques are a vital component of intelligent
decision-making in modern industries and are often combined with optimization
algorithms to achieve better results (Pandey, 2023).
Metaheuristic algorithms stand as a formidable category of methodologies in the
domain of optimization algorithms and intelligent decision-making. They serve the
purpose of tackling intricate optimization challenges, drawing inspiration from diverse
origins, including natural phenomena and collective intelligence. Their capacity to
navigate solution spaces effectively and uncover solutions that approach optimality
renders them indispensable across a diverse spectrum of applications (Ezugwu et al.,
2021). Within the framework of the IoT, metaheuristic algorithms have risen to
prominence. The IoT, marked by its incorporation of technologies such as extensive
data analysis, AI, and ML poses a multitude of hurdles that can be aptly met through
the application of metaheuristic methods. These algorithms exhibit decentralization
and self-organization characteristics, rendering them well-suited for addressing
complex challenges inherent to IoT-based systems (Yakubu & Murali, 2023). These
algorithms have been applied across a spectrum of domains, including intelligent
decision-making, process automation, and performance optimization. Their
contributions extend to elevating the quality of human existence and benefiting diverse
sectors. Additionally, metaheuristic algorithms hold substantial ramifications within
engineering, commerce, economics, financial analysis, and various other disciplines.
They provide effective resolutions for intricate optimization challenges that may defy
conventional problem-solving methods (Pourkhodabakhsh et al., 2023). Researchers
and practitioners have explored their application in power systems, feature selection
for the classification of heart-related diseases, and more. These algorithms are built
upon mathematical concepts and are particularly effective when dealing with large￾scale and complex optimization challenges. Additionally, metaheuristics have given
rise to research and publications on their performance, classification, and applications
across various domains. They offer a balance between exploration and exploitation of
solution spaces, helping to overcome challenges like getting stuck in local optima. As
a result, meta-heuristic algorithms provide researchers and practitioners with versatile
tools for addressing optimization and decision-making problems intelligently and
efficiently (Sharma & Tripathi, 2022).
6.5.1 Heuristic algorithms
The origin of the term ‘heuristic’ can be traced back to the Greek word ‘heuristic,’
denoting the act of ‘finding’ or ‘uncovering.’ Heuristic algorithms typically consist of
practical guidelines or suggestions guiding the exploration of promising segments
within the solution space (Spirov & Myasnikova, 2022). Heuristic algorithms are
problem-solving strategies that discover approximate solutions to complicatedproblems by employing practical approaches and shortcuts. They are frequently used
when exhaustive approaches, such as brute-force, are impracticable due to the large
search space or high computing needs. Heuristic algorithms strive to discover a good
enough answer in a reasonable period rather than guaranteeing an ideal result (Martí &
Reinelt, 2022). Heuristics are cognitive shortcuts or mental strategies that humans use
to make decisions and solve problems quickly and efficiently. These shortcuts rely on
past experiences, intuition, and common sense to arrive at solutions, often without
engaging in a complex analytical process. They prove highly advantageous in
scenarios marked by constraints in terms of both time and resources. Conversely, the
term ‘Data-driven’ pertains to a methodology that leans on real-world evidence and
empirical data to guide the process of decision-making and addressing problems
(Buijsse et al., 2023). In a context that prioritizes data-driven methodologies, decisions
are rooted in concrete facts, statistical analysis, and empirical evidence, rather than
relying on mere intuition or gut instincts. When blending heuristics with a data-driven
approach, you effectively combine swift, rule-of-thumb strategies with tangible data
for decision-making. This fusion can be a potent approach, as it enables the utilization
of both your personal insights and historical experiences, while simultaneously
benefiting from the impartiality and precision that data brings to the table. For
instance, consider a business endeavoring to ascertain the ideal pricing strategy for a
new product; they might employ heuristic-based estimates initially, drawing from their
industry experience (Lim et al., 2021). However, they would then gather and analyze
market research data, competitor pricing, and consumer preferences to refine their
pricing strategy in a data-driven manner. In general, the concept of “heuristics data￾driven” suggests using a combination of quick mental shortcuts and evidence-based
data analysis to make informed decisions and solve problems. This approach can help
balance the benefits of intuitive decision-making with the reliability of data-backed
insights (Mahadeen et al., 2021). The features of the heuristic algorithm can be
described as follows:
Approximation vs. Optimality: Heuristic algorithms are meant to identify
answers that are near the optimum solution but may not always produce the best
possible outcome. They trade off optimality for efficiency, making them
appropriate for problems with vast or complicated search areas.
Search Space and Neighborhood Exploration: Heuristic algorithms search for
nearby solutions from a particular beginning point. The idea of a neighborhood
outlines the set of candidate solutions that may be achieved by making minor
changes to the existing solution.
Heuristic Function: A heuristic function, also known as a cost function or
evaluation function, is a function that quantifies how “good” a solution is. This
function is used by the algorithm to direct the search toward better solutions.
Greedy vs. Metaheuristic Algorithms: Within the realm of heuristic algorithms,
there exists a category known as ‘Greedy algorithms’ which operate by makingdecisions that appear to be the best at each step, aiming to eventually reach a
globally optimal solution. In contrast, metaheuristic algorithms represent more
advanced strategies that oversee and guide the search process, effectively
navigating through various sections of the solution space with efficiency.
Termination Criteria: Heuristic algorithms require termination criteria to know
when to cease searching. This might be based on a set number of iterations,
achieving a certain level of solution quality, or meeting a time constraint.
Problem-Specific strategies: Varied problems often demand distinct heuristic
approaches. For instance, certain challenges may find value in the application of
genetic algorithms, particle swarm optimization, ant colony optimization (ACO),
or simulated annealing.
Heuristic algorithms are problem-solving strategies that use data or patterns detected
in data to make educated judgments and find approximate answers in a “data-driven”
setting. These algorithms use data-driven insights to efficiently and effectively direct
the search process, especially when dealing with complicated issues with massive
datasets or high-dimensional spaces. The notion of heuristic algorithms in data-driven
contexts is comparable to the classic definition of heuristics, as previously discussed.
Heuristic algorithms, on the other hand, gain from the abundance of knowledge
included within the accessible data to improve their decision-making process and
solution quality in a data-driven setting. In Table 6.1, the main data-driven aspects of
heuristic algorithms are given; In such a way that one can argue a structured view in
related applications (Liao et al., 2020).
Table 6.1 Data-driven aspects of heuristic algorithms
Data-Scarce
Optimization (van
der Schelling,
2021)
A heuristic decision-making approach driven by data comes
into play when optimizing situations grapple with a
shortage of available data. For instance, within the realm of
materials engineering, one can create Bayesian
optimization models to enhance the composition of bio￾based composites when data is limited. This approach
adjusts meta-heuristic methods based on the data at hand,
effectively addressing optimization challenges in scenarios
where information is sparse.
Evolutionary
Optimization with
Data-Driven
Approaches (Jin et
al., 2021)
Data-driven evolutionary optimization involves utilizing
machine learning techniques and metaheuristics to solve
complex optimization problems. This approach combines
mathematical programming, evolutionary algorithms, and
machine learning to create efficient optimization strategies.
It has applications in various fields, including engineering
design, process automation, and healthcare.Heuristic
Induction from
Human Design
Behavior (Puentes
et al., 2021)
Data-driven heuristic induction involves deriving heuristic
strategies from human design behavior. This approach uses
data on how humans make design decisions and translates
that into heuristic rules for automated design optimization.
It bridges the gap between human creativity and automated
optimization by extracting useful heuristics from human
expertise.
Instance Feature￾Based Algorithm
Selection (Deniz &
Ozceylan, 2023)
Instead of manually tuning algorithm parameters, this
approach employs historical performance data to
automatically configure the parameters of heuristic
algorithms. This data-driven optimization enhances the
algorithm’s effectiveness and efficiency.
Temporal Data￾Driven Heuristics
(Wang et al.,
2023b)
These algorithms leverage time-dependent patterns in
historical data to adapt their search strategies. By
considering how solutions have evolved, these heuristics
can make informed decisions about where and how to
explore the search space.
6.5.1.1 Data-scarce optimization in data-driven heuristics
Optimization heuristics tailored for scenarios with data scarcity represent decision￾making approaches employed when the available data for optimization is limited or
lacks completeness. These strategies aim to maximize the utility of the accessible data
in order to optimize a specific goal. Such heuristics frequently find application in ML
contexts, particularly in situations where there is a shortage of well-labeled training
data or where data imbalances are prevalent (Joshi, 2021; van der Schelling, 2021).
Strategies known as data-scarce optimization heuristics come into play when the
information available for optimization is constrained or lacks completeness. The
primary goal of these heuristics is to maximize the effective utilization of the data at
hand in order to achieve a specific optimization objective. Unlike conventional
optimization methods, which rely on mathematical models demanding comprehensive
and precise data to optimize a given goal, real-world situations often grapple with data
limitations or incompleteness, posing a significant challenge to the effective
application of traditional optimization approaches (Sassi et al., 2021). To tackle this
predicament, data-scarce optimization heuristics are purpose-built to harness the
existing data, enabling informed decision-making and objective optimization. These
heuristic approaches find frequent application in ML contexts characterized by the
absence of well-annotated training data or data imbalances. They facilitate decision￾making and the refinement of models, even in scenarios where data is constrained or
lacks completeness. For instance, in the realm of research concerning bio-basedcomposites, data-scarce Bayesian optimization models have been devised to
investigate their composition (van der Schelling, 2021). Another example is the data￾driven robust optimization algorithm used for hyper-parameter optimization of ML
algorithms (Frimodig, 2023).
In contexts marked by a scarcity of data, data-scarce optimization heuristics emerge
as a valuable instrument, ensuring the feasibility of optimization despite limited data
resources. They facilitate the process of making well-informed decisions and
achieving optimization goals, even when data availability is constrained. An
illustrative instance of such a heuristic is the data-scarce Bayesian optimization model,
specifically designed to investigate the makeup of bio-based composite (van der
Schelling, 2021). Another example is the data-driven robust optimization algorithm for
black-box cases, which is used for hyper-parameter optimization of ML algorithms
(Seifi et al., 2021). Unlike data-driven heuristics, conventional optimization techniques
hinge on mathematical models that demand comprehensive and precise data for the
effective optimization of a specified objective. Nevertheless, numerous real-world
situations often grapple with the limitation of data being either scarce or incomplete,
rendering the application of traditional optimization methods a complex endeavor. The
purpose behind the development of data-scarce optimization heuristics is to confront
this challenge by maximizing the utility of the data at hand to achieve the optimization
objective (Garcia et al., 2023). Heuristics, in essence, serve as cognitive shortcuts
employed to streamline problem-solving and prevent cognitive overwhelm. They are
an inherent part of the human brain’s evolutionary development and wiring, enabling
individuals to swiftly arrive at sensible conclusions or resolutions for intricate issues.
In the realm of computer science, the term ‘heuristic’ denotes a method devised to
expedite problem-solving when conventional approaches prove too time-consuming or
to locate an approximate solution in situations where conventional methods fall short
of delivering an exact one (Chen, 2023).
The utility of data-scarce optimization heuristics spans across diverse domains,
encompassing fields such as ML, materials engineering, econometrics, and operations
research. These specialized strategies come into play when the available data for
optimization is restricted or incomplete, with the overarching goal of maximizing the
effectiveness of the accessible data to achieve a specified objective. In the context of
ML, data-scarce optimization heuristics find application in the fine-tuning of hyper￾parameters for ML algorithms, particularly in scenarios characterized by a lack of
well-labeled training data or data imbalances (van der Schelling, 2021). In materials
engineering, data-scarce Bayesian optimization models have been developed for
researching the composition of bio-based composites. In econometrics and operations
research, optimization heuristics are used to solve complex optimization problems
(Juan et al., 2023). In circumstances marked by a shortage of data, data-scarce
optimization heuristics emerge as a vital resource to facilitate optimization despite data
limitations. They empower informed decision-making and the pursuit of optimization
goals, even when data is constrained. These heuristics are meticulously crafted toconfront the common challenge of data paucity and incompleteness found in numerous
real-world scenarios. In essence, data-scarce optimization heuristics possess broad￾ranging applicability across various fields and represent a crucial tool for enabling
informed decision-making and achieving optimization objectives in data-constrained
settings (van der Schelling, 2021).
6.5.1.2 Evolutionary optimization with data-driven approaches in data￾driven heuristics
The realm of data-guided evolutionary optimization encompasses a research domain
that melds the capabilities of ML with evolutionary optimization techniques to tackle
intricate real-world optimization challenges. The primary objective is to engineer
algorithms capable of acquiring insights from data and applying that acquired
knowledge to steer and enhance the optimization journey (Jin et al., 2021). A central
hurdle encountered within data-influenced evolutionary optimization revolves around
the necessity for copious data to train ML models effectively. To overcome this
challenge, a solution emerges in the form of surrogate models, which represent
streamlined approximations of the original models’ behavior. These surrogate models
can be effectively trained on smaller, manageable subsets of the data, thus enhancing
the efficiency of the optimization process (Jin et al., 2018; Xu et al., 2021). Yet another
obstacle lies in the requirement to centrally store all the data, a practice that may not
consistently align with practicality or preferences owing to concerns about privacy and
security. To counter this challenge, federated data-driven evolutionary algorithms have
been put forth as a solution. These algorithms enable the optimization process to be
decentralized, spreading across multiple devices, with each device providing its data
input to the overall optimization process (Jin et al., 2018; Xu et al., 2021). In summary,
the utilization of data-driven evolutionary optimization presents a highly encouraging
avenue for addressing intricate optimization challenges spanning diverse domains such
as engineering, finance, and healthcare. Ongoing research in this domain is primarily
dedicated to the advancement of algorithms, seeking greater efficiency in managing
larger and more intricate datasets. Additionally, efforts are being directed toward
resolving matters pertaining to the safeguarding of privacy and security (Xu et al.,
2021).
Data-driven evolutionary optimization has a wide range of real-world applications
across various fields. Here are some examples:
Designing Complex Engineering Systems: Utilizing data-driven evolutionary
optimization offers the potential to enhance the design of intricate engineering
systems like aircraft, vehicles, and structures. This approach integrates data
derived from simulations, experiments, and past design experiences, enabling the
optimization process to produce enhanced designs tailored to meet precise
performance standards (Jin et al., 2018).Financial Applications: The utilization of data-driven evolutionary optimization
finds relevance in financial portfolio management, where the objective revolves
around identifying the most favorable asset allocation to optimize returns while
mitigating risks. Through an examination of historical financial data and market
dynamics, the optimization process can formulate investment tactics that remain
adaptable in response to evolving market circumstances (Gunjan &
Bhattacharyya, 2023).
Healthcare: In the realm of healthcare, the application of data-driven
evolutionary optimization becomes instrumental in enhancing the precision of
treatment planning for individual patients. Through a comprehensive analysis of
patient-specific data, including medical histories, genetic profiles, and treatment
results, the optimization process has the capacity to formulate tailored treatment
strategies designed to optimize the likelihood of favorable outcomes (He et al.,
2020).
Energy Sector: The utilization of data-driven evolutionary optimization extends
its relevance to the enhancement of energy system operations, including power
grids and renewable energy setups. Through a meticulous examination of data
concerning energy consumption, weather dynamics, and energy production, the
optimization process can formulate superior planning and control methodologies
aimed at cost reduction and efficiency maximization (Xu et al., 2021).
Supply Chain Management: The application of data-driven evolutionary
optimization extends its reach into the domain of supply chain management,
encompassing facets like inventory control, production scheduling, and logistical
operations. Through a comprehensive review of data pertaining to customer
demand, supplier effectiveness, and transportation expenditures, the optimization
process can craft strategies optimized to reduce expenses and enhance the overall
effectiveness of the supply chain (Jin et al., 2018).
6.5.1.3 H deriving heuristic strategies from human design actions within
data-enhanced heuristic approaches
Heuristic Induction represents a technique aimed at reducing the application of
heuristic strategies within a design context, utilizing existing datasets derived from
design problems. This method follows a data-driven approach, entailing the
examination of human design actions to uncover overarching heuristics applicable to
resolving forthcoming design challenges. The heuristic induction process encompasses
the collection of data originating from human-driven design investigations across
various design domains, including but not limited to truss design and the arrangement
of home cooling systems. Subsequently, the collected data undergoes examination via
automated heuristic induction methods, with the aim of discerning the common
heuristics deployed by human designers for addressing design challenges. The induced
sequences are algorithmically organized into clusters based on their likeness, formingdistinct groups that collectively represent widely shared general heuristics (Puentes et
al., 2020a, 2021). The broad heuristics uncovered via heuristic induction offer
designers within a specific domain the opportunity to draw insights from the problem￾solving strategies employed by their peers. This knowledge can then be applied to their
own future design challenges. Such an approach aids designers in resolving problems
with heightened efficiency and effectiveness, as they can harness the collective
wisdom and expertise of their professional community (Puentes et al., 2021).
Heuristic induction is an approach that delves into human design practices with the
goal of pinpointing overarching problem-solving guidelines applicable to design
challenges. It follows a data-driven methodology, striving to distill effective strategies
from established datasets of design issues. The heuristic induction process entails the
compilation of data from various design studies conducted by humans across different
design domains. Subsequently, automated methodologies are employed to scrutinize
the data, uncovering recurring patterns and sequences of design actions. These patterns
and sequences serve as manifestations of the problem-solving heuristics employed by
human designers to address design dilemmas (Puentes et al., 2020b). Through the
identification of these overarching rules of thumb, individuals working within a
specialized field of design can gain insights from the problem-solving approaches of
their peers and utilize them in tackling their own future design challenges. This
approach offers the potential to enhance problem-solving efficiency and effectiveness
among designers by tapping into the collective wisdom and expertise within their
professional community. The heuristic induction methodology has found practical
utility in various design domains, such as truss design and cooling system layout,
underscoring its versatility and broad applicability. Nevertheless, the current heuristic
induction method faces certain constraints. Notably, the selection of optimal
parameters, including the maximum sequence length and sequence significance
threshold, significantly influences the resulting heuristic categories, and forthcoming
research endeavors aim to address and mitigate these limitations (Puentes et al., 2021).
Heuristic induction stands apart from alternative induction methods due to its data￾driven nature, encompassing the examination of human design practices with the aim
of pinpointing universal heuristics applicable to design problem-solving. In contrast,
other forms of induction, like mathematical induction, rely on logical deduction and
mathematical evidence. Mathematical induction serves as a proof technique employed
to affirm a property’s validity across all natural numbers. This method entails
demonstrating a foundational case and subsequently proving that if the property is
valid for a specific number, it automatically extends to the subsequent number in the
sequence (Thomas, 2022). This iterative procedure continues until it is confirmed that
the property is valid across the entire spectrum of natural numbers. In sharp contrast,
heuristic induction takes a different route, devoid of logical deduction or mathematical
validation. Instead, it hinges on the examination of empirical data drawn from human￾centered design investigations to uncover prevalent trends and sequences of design
actions. These discerned patterns and sequences encapsulate the heuristics embracedby human designers when addressing design challenges. The upshot of this is that by
unearthing these overarching heuristics, designers can glean insights from the past
problem-solving methodologies of their peers and effectively apply them to their own
forthcoming design endeavors (Moore, 2020).
Heuristic induction has several advantages over other forms of induction, such as
mathematical induction. Here are some of the advantages of using heuristic induction
(Whelehan et al., 2020):
Data-Driven Approach: Heuristic induction is a data-driven approach that
involves analyzing human design behavior to identify general heuristics that can
be used to solve design problems. This approach is based on real-world data and
can provide insights into how designers solve problems in practice.
Generalizability: Heuristic induction can identify general heuristics that can be
applied to a wide range of design problems. This approach can help designers to
solve problems more efficiently and effectively by leveraging the knowledge and
experience of others in their field.
Quick and Efficient: Heuristic induction provides a quick and efficient way to
identify general heuristics. This approach can help designers to solve problems
more quickly and efficiently by providing them with a set of problem-solving
strategies that are effective in the past.
Practicality: Heuristic induction is a practical approach to problem-solving that
does not require perfect solutions. It is a method of mental shortcut for problem￾solving and decision-making that reduces the cognitive load and provides a
satisfactory solution to a much larger problem within a limited time frame.
6.5.1.4 Instance feature-based algorithm selection in data-driven heuristics
Instance feature-based algorithm selection is a method employed in the realm of
automated algorithm selection, specifically tailored for optimization domains
characterized by inherent sequential data patterns (Alissa et al., 2023). This process
entails the choice of an algorithm predicated on the attributes inherent to the instance
under optimization. The objective is to identify an algorithm that exhibits favorable
performance on a particular instance, contingent upon the characteristics inherent to
that instance (Rishi Gupta, 2020). The methodology encompasses the identification of
a collection of pertinent attributes corresponding to the instance undergoing
optimization. Subsequently, these attributes are employed to educate a ML model,
facilitating the prediction of the most suitable algorithm for that particular instance.
The model’s training dataset comprises instances for which the optimal algorithms and
their respective attributes are already known. Following successful model training, it
becomes capable of forecasting the optimal algorithm for novel instances by assessing
their unique set of attributes (Huele, 2022). Instance feature-based algorithm selection
is frequently employed alongside complementary methods, including but not limited togreedy heuristics and parameter optimization, with the aim of enhancing the
effectiveness of optimization algorithms (Stańczyk & Zielosko, 2020). This
methodology demonstrates its efficacy across diverse optimization domains,
encompassing tasks such as scheduling, routing, and packing problems. Recent
scholarly investigations have concentrated on the development of feature-independent
techniques for algorithm selection, eliminating the need for the manual curation of
relevant attributes. These innovative approaches harness ML to directly uncover the
connection between instances and algorithms, rendering feature engineering
unnecessary (Alissa et al., 2023).
Utilizing data-driven approaches for algorithm design finds extensive utility across
a multitude of domains. Several instances of these applications encompass:
Combinatorial Optimization: Data-driven algorithm design has been employed
in crafting algorithms to address combinatorial optimization challenges, including
but not limited to dilemmas such as the TSP, vehicle routing problem, and graph
coloring problem (Rishi Gupta, 2020).
ML: Data-driven algorithms find extensive application in the realm of ML, where
they are prominently utilized in tasks like image analysis, natural language
understanding, and speech processing (LLC, 2021).
Smart City: Smart city applications make use of data-driven algorithms to
enhance traffic management, curtail energy usage, and elevate public safety
(LLC, 2021).
Cybersecurity: Data-driven algorithms are used in cybersecurity applications to
detect and prevent cyber-attacks (LLC, 2021).
Smart Healthcare: Data-driven algorithms are used in smart healthcare
applications to analyze patient data and improve patient outcomes (LLC, 2021).
Business: Data-driven algorithms are used in business applications to optimize
supply chain management, improve customer experience, and increase revenue
(LLC, 2021).
6.5.1.5 Temporal data-driven heuristics
Temporal data-driven heuristics involves the utilization of data-driven approaches and
practical decision-making rules when dealing with temporal data. The term ‘heuristics’
pertains to problem-solving strategies or pragmatic guidelines employed to steer
decision-making in situations where an optimal solution may be elusive or unknown.
The notion of temporal data-driven heuristics holds relevance across diverse domains,
encompassing but not limited to computer science, engineering, and design (Belhaiza
et al., 2019). This approach entails the application of data-driven techniques for the
examination of temporal data, leading to the extraction of heuristics or guiding
principles suitable for making well-informed decisions or predictions grounded in the
temporal patterns discerned within the data. To illustrate, within the realm of design,novice designers can gain valuable insights by adopting generalized heuristics
identified and employed by more experienced counterparts (Puentes et al., 2021).
These overarching guiding principles are formulated through an examination of
temporal data and can offer direction during the design process. In the domain of
vehicle routing, there have been innovations in the creation of data-driven evolutionary
heuristics aimed at addressing the vehicle routing problem featuring multiple time
windows. These heuristics harness temporal data to enhance the efficiency of vehicle
routing operations within predefined time constraints (Belhaiza et al., 2019).
6.5.2 Meta-heuristic algorithms
Meta-heuristic algorithms are optimization techniques that tackle complex problems
with limited time or information, often used in data-driven decision-making contexts.
They offer efficient shortcuts to reaching good solutions. These algorithms can be
inspired by nature, like the gray wolf optimizer or genetic algorithm, enhancing
decision-making processes and employee turnover analysis. Hybrid approaches,
combining various strategies, often lead to superior performance. These techniques
prove especially valuable when tackling multi-objective optimization challenges,
where a solitary solution cannot be deemed optimal for all objectives, thereby yielding
a collection of Pareto-optimal solutions. The incorporation of learning-based methods,
such as employing data mining to fine-tune algorithm parameters, plays a pivotal role
in augmenting the effectiveness of meta-heuristic methodologies. Overall, these
algorithms aid decision-making under uncertainty by efficiently exploring solution
spaces and providing actionable insights (Vinod Chandra & Anand, 2022).
The utilization of meta-heuristic optimization algorithms within the realm of
intelligent decision-making is experiencing growing prominence across a spectrum of
domains, including engineering, finance, and scientific research. These algorithms are
tailored to address intricate optimization challenges where obtaining an optimal
solution through conventional means proves arduous. Meta-heuristic algorithms form a
category of optimization techniques employing heuristic methods to navigate the
search space and uncover the most favorable solution. These algorithms draw
inspiration from natural phenomena such as evolutionary processes, swarm
intelligence, and simulated annealing. The application of these algorithms has yielded
encouraging outcomes in the realm of decision-making, encompassing tasks such as
scheduling, resource allocation, portfolio optimization, and a multitude of other
applications. Given the escalating requirement for streamlined and proficient decision￾making procedures, optimization algorithms featuring heuristic methodologies are
well-positioned to address the complexities of today’s world. Meta-heuristic
algorithms constitute a prominent category within the domain of optimization
techniques and are extensively harnessed in intelligent decision-making. The
fundamental objective of these algorithms is to ascertain the best possible solution for
a given problem by iteratively traversing diverse solution spaces. They bear themoniker ‘meta-heuristic’ due to their operation at a more abstract level compared to
conventional optimization algorithms. Unlike traditional methods, these algorithms do
not provide a guarantee of discovering the optimal solution; instead, they strive to
identify the most favorable solution within a practical timeframe. Meta-heuristic
algorithms have permeated diverse domains, including economics and AI, and they are
instrumental in tackling intricate challenges that demand resolution. Their remarkable
adaptability allows for their application across a broad spectrum of optimization
problems, rendering them one of the prevailing and widely adopted algorithmic
approaches in contemporary usage (Ayyarao et al., 2022).
They are designated as ‘meta-heuristic’ by virtue of their operation at a higher
conceptual plane relative to typical optimization algorithms. Unlike conventional
techniques, these algorithms do not offer an assurance of uncovering the ultimate
solution; their aim is to discern the most advantageous solution within a reasonable
timeframe. Meta-heuristic algorithms have made inroads into various domains,
spanning economics and AI, where they play a pivotal role in addressing complex
issues requiring resolution. Their exceptional versatility enables their utilization across
a wide array of optimization problems, solidifying their status as one of the foremost
and extensively embraced algorithmic methodologies in contemporary practice
(Mangla & Goyal, 2017).
Metaheuristic algorithms represent optimization techniques inspired by a diverse
range of sources, including natural phenomena, human behavior, and principles from
fields like physics. These algorithms have garnered widespread acclaim across
multiple domains and have captured the keen interest of both the scientific and
industrial communities. However, the proliferation of recent metaheuristic approaches
has led to questions regarding the rationale behind introducing new algorithms in an
arbitrary manner.
Despite the successful outcomes achieved through metaheuristic algorithms, several
challenges continue to persist within this field. Notably, there isn’t always a direct and
significant correlation between the sources of inspiration for these algorithms and their
actual performance. The initialization and control parameters of population-based
metaheuristic algorithms hold a pivotal role in enhancing their effectiveness.
Researchers have devoted substantial effort to devising various distribution schemes
aimed at augmenting the diversity within initial populations. Achieving the right
balance between population size and the number of iterations is crucial to ensure
optimal solutions for specific problem sets. Feature selection represents a critical
aspect of ML, and metaheuristic algorithms have garnered substantial attention for
their prowess in addressing various optimization problems, including feature selection.
This chapter offers an extensive literature review spanning a decade (2009–2019) on
the utilization of metaheuristic algorithms for solving feature selection challenges.
These algorithms are categorized into four groups based on their behavior, and a
comprehensive list exceeding a hundred distinct metaheuristic algorithms is presented
(Abdollahzadeh et al., 2021) (Figure 6.3).Figure 6.3 Classification of data-driven metaheuristic algorithms.
6.5.2.1 Data-Driven bio-simulation algorithms
Bio-simulated metaheuristic algorithms belong to the category of optimization
techniques that draw inspiration from various natural processes or phenomena. Their
primary objective is to address intricate optimization challenges by emulating the
behaviors observed in biological systems or other elements of nature. These algorithms
prove especially valuable in scenarios where conventional optimization approaches
prove impractical or inefficient. Among the pivotal factors influencing the
performance of population-based metaheuristic algorithms, the initial set of solutions
assumes a critical role. The placement of these initial solutions can exert a substantial
influence on the effectiveness of the search process and the likelihood of discovering
the optimal solution (Agushaka & Ezugwu, 2022). Scholars have invested significant
endeavors in devising a range of distribution strategies aimed at enriching the diversity
within initial populations while striking an appropriate equilibrium between population
size and the number of iterations. In the realm of ML, metaheuristic algorithms have
garnered substantial interest in addressing the challenge of feature selection. The core
objective of feature selection is to trim the dimensionality of the feature set while
upholding performance accuracy. Metaheuristic algorithms have found extensive
application in this context, and a comprehensive examination of the literature has been
undertaken to delve into the resolution of feature selection problems through the
utilization of these algorithms (Agrawal et al., 2021). Metaheuristic algorithms have
the potential to be incorporated seamlessly with artificial neural networks (ANNs) for
the purpose of enhancing the optimization of model architecture and feature selection,
particularly in the domain of prediction modeling. As an illustration, in a research
endeavor focused on forecasting biochar yield through ANNs, six distinct
metaheuristic algorithms were subjected to comparative analysis. Their role was to
optimize the architecture of the ANN and determine the relevance of individualfeatures. The findings indicated that the ANN model combined with the Rao-2
algorithm exhibited superior performance when contrasted with alternative models
(Khan et al., 2022). Bio-simulated metaheuristic algorithms present numerous benefits
when applied to optimization challenges. They possess the capability to navigate
intricate and multidimensional search spaces, demonstrating resilience in the face of
noise and uncertainty. Moreover, these algorithms exhibit the capacity to uncover
solutions that are close to optimal, even in scenarios where the objective function
exhibits non-linearity or discontinuities. Furthermore, their adaptability renders them
suitable for diverse problem domains (Agrawal et al., 2021).
Over the past decade, significant strides have been made in the development of ML
algorithms, simplifying the processes of data classification and information extraction.
This advancement has led organizations worldwide to recognize the inherent value of
their data, resulting in a substantial surge in the demand for data scientists. The
establishment of BI departments and the adoption of data-driven decision-making have
gained prominence. Uncovering valuable insights and concealed patterns from vast
datasets can yield substantial benefits for an organization, both in terms of profitability
and other aspects. A data-centric approach to ML algorithms can facilitate the
extraction of valuable knowledge from data and guide well-informed decision-making.
Data-driven bio-simulation algorithms encompass the use of data to inform decisions
and actions related to optimization problems inspired by natural processes. The
integration of ANNs and metaheuristic algorithms, for instance, can enhance the
prediction of intricate processes such as biochar yield. Additionally, data-driven
techniques can be applied to optimize the initialization approaches for population￾based metaheuristic algorithms. ML algorithms play a pivotal role in extracting
valuable insights from data, empowering organizations to make informed decisions
(Agushaka & Ezugwu, 2022).
6.5.2.2 Data-driven nature-inspired algorithms
Metaheuristic algorithms infused with a data-driven, nature-inspired approach
encompass leveraging data to guide decisions and actions pertaining to optimization
problems inspired by natural phenomena. This study introduces a fresh wellspring of
inspiration for the evolution of metaheuristic algorithms (Harifi, 2020). This newfound
wellspring of inspiration, referred to as ‘ancient-inspired,’ amalgamates the
commendable attributes of prevailing sources of inspiration, culminating in the
development of highly efficient algorithms. The study reveals that the methodologies,
strategies, and technologies employed in ancient times are surprisingly more advanced
and optimized than previously envisaged. Consequently, this research contributes a
novel classification for metaheuristic algorithms, ushering in a fresh perspective. An
approach grounded in data-driven principles applied to ancient-inspired metaheuristic
algorithms holds the potential to enhance both their efficiency and effectiveness.
Furthermore, the study introduces an innovative algorithm for metaheuristicprogramming with gene expression, leveraging a diverse array of nature-inspired
algorithms as a search engine to tackle the intricate challenge of synthesizing nonlinear
models analytically (Monakhov & Monakhova, 2021). The algorithm put forth
exhibits a marked superiority when compared to the conventional gene expression
programming approach. Employing a data-driven strategy in the context of
metaheuristic programming with gene expression holds the potential to enhance the
efficiency of these algorithms significantly. Notably, previous research has
demonstrated the effective utilization of nature-inspired metaheuristics in addressing
the complex task of multilevel image thresholding (Tuba, 2014). Multilevel image
thresholding plays a vital role in image segmentation, a pivotal step that underpins
advanced image analysis. This challenge involves intricate combinatorial optimization
with highly complex objective functions, necessitating the application of probabilistic
methods for viable solutions. In this concise overview, we explore instances where
nature-inspired metaheuristics have demonstrated success in addressing multilevel
image thresholding problems. Additionally, we consider how adopting a data-driven
approach can enhance the effectiveness of algorithms designed for multilevel image
thresholding. Furthermore, we discuss a recent study introducing the ‘clique finder
algorithm,’ which utilizes principles from simulated annealing to address the
maximum clique problem (MCP) (Almuhaideb et al., 2022). The algorithm in question
employs a cooling schedule following a logarithmic pattern and dynamically selects
two specific moves. To gauge its efficacy, the proposed algorithm underwent
evaluation using benchmark graphs sourced from the DIMACS open-source library,
and the outcomes indicate a notable success rate. Adopting a data-driven strategy in
the context of the clique finder algorithm holds promise for enhancing the performance
of such algorithms. Furthermore, a recent study introduces an innovative approach,
enhancing the search capability of the traditional cuckoo search algorithm (CSA) for
optimization tasks. This method involves a modified local search mechanism
accompanied by an adaptive boundary scaling feature that employs a chaotic map
(Song et al., 2021). The newly introduced algorithm is subjected to a comparative
assessment against both the conventional CSA and a version of CSA without chaos
modification, referred to as nonmodified chaos-embedded CSA (CCSA), across a set
of 25 benchmark functions. The empirical findings, bolstered by statistical tests,
consistently indicate the superior performance of the proposed algorithm over its
counterparts. Embracing a data-driven approach in the context of adaptive scaling
cuckoo search algorithms holds promise for optimizing their overall effectiveness.
Furthermore, the study underscores the pivotal role of initialization control parameters
in enhancing the performance of population-based metaheuristic algorithms (Agushaka
& Ezugwu, 2022). Considerable research endeavor has been directed toward devising
diverse distribution strategies aimed at enriching the diversity within initial algorithm
populations. Simultaneously, there’s a concerted focus on achieving the precise
equilibrium between population size and the number of iterations, ensuring the
attainment of optimal solutions for specific problem sets. Embracing a data-drivenmethodology for initialization holds significant potential to enhance the overall
efficiency and efficacy of population-based metaheuristic algorithms.
The concept of being inspired by ancient wisdom advocates the amalgamation of
favorable attributes from existing sources of inspiration to craft metaheuristic
algorithms characterized by efficiency (Harifi, 2020). Through a meticulous
examination of ancient artifacts and constructions, conceived and executed under
constraints and limited resources, scholars can discern methodologies, strategies, and
technologies that surpassed initial expectations in terms of advancement and
optimization. Integrating these sophisticated techniques into metaheuristic algorithms
holds the potential to augment their overall efficiency and effectiveness. The
introduction of this ancient-inspired perspective introduces a fresh categorization for
metaheuristic algorithms, extending new avenues of exploration for researchers
(Harifi, 2020). This categorization serves as a valuable tool for structuring and
comprehending the array of algorithms influenced by ancient strategies and
technologies. Through this systematic classification based on ancient-inspired
attributes, researchers gain improved clarity in evaluating and contrasting algorithm
performance, thereby facilitating the advancement of more effective algorithms. The
ancient era furnishes instances of optimization strategies devised to surmount
constraints and attain optimal results. Through an examination of these historical
strategies, researchers can extract valuable insights on optimizing metaheuristic
algorithms. For instance, algorithms inspired by antiquity may integrate methods for
efficiently navigating and exploiting the search space, maintaining a delicate
equilibrium between convergence and diversity, and adapting to dynamic conditions
(Harifi et al., 2021).
6.5.2.3 Data-driven physics-based algorithms
Data-informed algorithms grounded in physics entail the utilization of data to guide
decision-making and actions pertinent to optimization challenges within the domain of
physics. This resource serves as a valuable reference for engineers, geophysicists, and
geoscientists, offering a comprehensive introduction to data science and analytics
terminology relevant to subsurface characterization. Furthermore, it illustrates the
practical application of data-driven techniques for a range of tasks, including outlier
detection, geomechanically and electromagnetic characterization, image analysis, fluid
saturation estimation, and pore-scale characterization within the subsurface. The
reference showcases real-world case studies that draw upon field observations,
laboratory experiments, and simulation data to underscore the effective utilization of
data-driven methods for characterizing subsurface phenomena (Shukla et al., 2022). A
doctoral thesis delves into an innovative application platform referred to as a ‘transit
hub.’ This platform serves as a facilitator for the seamless integration of sensor data
streams dispersed both spatially and temporally. It also enables the fusion of
simulation-based decision support systems and the execution of experiments aimed atelucidating how advanced decision support tools enhance the optimization of
transportation infrastructure usage. Within this framework, data mining and ML
methodologies were custom-tailored to cater to the context-specific prediction of
delays in public transit networks across various time horizons – ranging from long￾term to short-term and real-time scenarios. Addressing the challenge of data sparsity,
novel approaches were devised, including the creation of shared route segment
networks and the development of multitask neural networks. These innovations
fostered effective solutions for handling sparse data in public transit contexts. In the
broader landscape, the past decade has witnessed the evolution of diverse ML
algorithms, designed to streamline the processes of data classification and information
extraction (Deshmukh & Kubal, 2020). Organizations all over the world have realized
the true intrinsic value of their data, and the demand for data scientists has risen
tremendously. Setting up BI departments and making data-driven decisions has gained
popularity. In an extensive research investigation, a comprehensive catalog is
compiled, featuring over 500 metaheuristic algorithms. This study proceeds to
undertake a rigorous comparative analysis, evaluating the performance of both
recently enhanced competitive variants and newly introduced metaheuristics. The
benchmark for this evaluation is the CEC2017 benchmark suite (Martins et al., 2021).
The creators of these algorithms credit their uniqueness to the sources of inspiration
they draw from, including biology, human behavior, physics, and various observable
phenomena. The overarching concept underpinning ‘nature-inspired’ algorithms is
centered on the idea of developing algorithmic solutions by mimicking natural
processes or biological behaviors, all with the aim of efficiently tackling optimization
problems (Ma et al., 2023). The study provides insights into the performance of
nature-inspired metaheuristic algorithms and the need for a rational introduction of
new metaheuristics.
Data-driven methods can be used for outlier detection,
geomechanically/electromagnetic characterization, image analysis, fluid saturation
estimation, and pore-scale characterization in the subsurface (Heße et al., 2023). Real￾world scenarios involving the application of data-driven approaches to subsurface
characterization, drawing from field observations, laboratory experiments, and
simulation data, can provide concrete illustrations of these methodologies. Such case
studies hold relevance for diverse domains like oil and gas exploration, geothermal
energy utilization, and groundwater management. In addition, data mining and ML
methodologies are instrumental in enabling context-aware predictions of delays in
public transit networks, spanning various temporal scales, including long-term, short￾term, and real-time scenarios (Sun, 2018). Strategies like the creation of collaborative
route segment networks and the implementation of multitask neural networks can be
devised to effectively address challenges associated with sparse data. These techniques
hold the potential for enhancing the efficiency of transportation infrastructure
utilization and mitigating congestion in urban settings. Furthermore, a diverse array of
ML algorithms can be employed to streamline the tasks of data categorization andinformation extraction, simplifying these processes (Deshmukh & Kubal, 2020).
Foundational ML techniques that are essential for anyone enthusiastic about data
science encompass decision trees, random forests, support vector machines, k-nearest
neighbors, and neural networks. These algorithms serve versatile purposes, including
predictive modeling, classification, clustering, and anomaly detection. In a separate
realm, metaheuristic algorithms come into play to address optimization challenges,
emulating natural processes and biological behaviors. These algorithms find
applications in tasks such as automated synthesis of nonlinear models, evaluating
performance, and comprehensive cataloging of metaheuristic algorithms (Sun, 2018).
6.5.2.4 Data-driven evolutionary algorithms
Utilizing data as a foundational element, data-driven evolutionary algorithms guide the
decision-making and operational aspects of evolutionary optimization challenges.
Noteworthy advancements have been witnessed in the field of evolutionary
computation theory within the realm of discrete search spaces, particularly in the last
decade, signaling a substantial leap forward (Doerr & Neumann, 2021). Refined and
intricate runtime analysis models of evolutionary algorithms find application in the
enhancement of submodular function optimization. Recent strides have been taken in
addressing the challenges posed by stochastic and dynamic problem domains. At the
forefront of this field lies drift analysis, a remarkably potent analytical technique,
offering the potential to enhance the effectiveness of evolutionary algorithms.
Additionally, non-deterministic parameter control mechanisms can be harnessed to
adapt algorithm parameters, leveraging insights gleaned from the evolutionary process
(Case & Lehre, 2020). Self-adaptation is widely embraced within the realm of
evolutionary strategies, entailing the encoding of parameter configurations within
individual chromosomes, which then evolve through processes like mutation and
crossover. Theoretical evaluations of runtime performance reveal that in discrete
problems with undefined structures, a non-elitist evolutionary algorithm employing
self-adaptive mutation rates can surpass the performance of evolutionary algorithms
employing fixed mutation rates. In addition, the construction of nonlinear models in an
analytical format can be facilitated through the application of metaheuristic
programming, utilizing gene expression techniques inspired by various facets of
nature-inspired algorithms (Monakhov & Monakhova, 2021). The algorithm under
consideration demonstrates superior performance in automating the synthesis of
nonlinear models when compared to the conventional gene expression programming
approach. The optimization of population-based metaheuristic algorithms heavily
relies on the effective management of initialization control parameters, serving as a
pivotal factor in elevating algorithmic efficiency (Agushaka & Ezugwu, 2022).
Significant research endeavors have been dedicated to the exploration of diverse
distribution strategies aimed at enriching the initial populations of algorithms. The
goal is to strike the right equilibrium between population size and the number ofiterations, ensuring the attainment of optimal solutions for specific problem sets. The
realm of multi-objective evolutionary algorithms (MOEAs) showcases the potential to
derive highly effective algorithms within a customizable framework, facilitating
automated generation (Bezerra & Manuel, 2020). Employing a multi-objective
framework for the automated design of MOEAs can result in the development of an
MOEA that exhibits top-tier performance across a range of predefined metrics.
6.5.2.5 Data-driven swarm-based algorithms
Data-informed swarm-based algorithms encompass algorithmic approaches where data
serves as a guiding influence for directing a collective of agents or robotic entities
toward predefined objectives. These algorithms have garnered widespread recognition
across diverse domains, spanning applications such as exploring and covering
uncharted environments, diagnosing faults in physical systems, predicting wind
speeds, and optimizing performance within industrial systems. Their design prioritizes
the seamless facilitation of data classification and information extraction processes,
leveraging localized communication and sensing capabilities among agents for
orchestrating the swarm’s navigation and search activities. The algorithms’
effectiveness is substantiated through empirical assessments in tasks related to
coverage and search, with comparative evaluations against alternative swarm strategies
(Tran et al., 2022). Over the last decade, ML algorithms have been meticulously
crafted with the aim of simplifying data classification and information extraction
procedures.
ML algorithms have been specifically crafted to streamline the process of data
classification and the extraction of information (Tang et al., 2021). These algorithms
leverage data to influence the actions of a collective of agents or robots, thereby
enhancing their efficiency in pursuing predefined objectives. In the realm of data￾driven swarm-based algorithms, the coordination of navigation and search tasks within
the swarm is facilitated through the employment of localized communication and
sensing mechanisms among the agents (Michaloglou & Tsitsas, 2021). This enables a
more streamlined and proficient synchronization among agents. Data-informed swarm￾based algorithms have garnered recognition across a range of domains, encompassing
applications such as the exploration and coverage of uncharted terrains, diagnosing
faults within physical systems, predicting wind speeds, and optimizing the
performance of industrial systems (Michaloglou & Tsitsas, 2021). This adaptability
renders them applicable across a broad spectrum of use cases. To gauge their
effectiveness, these algorithms are empirically validated through experiments
involving tasks related to coverage and search, and their performance is benchmarked
against alternative strategies employed by swarms (Michaloglou & Tsitsas, 2021).
These experimental findings illustrate that, in specific situations, data-informed
swarm-based algorithms can surpass the performance of alternative swarm strategies.6.5.3 The most famous types of data-driven heuristic and meta-heuristic
algorithms
In a data-driven context, there exists a multitude of heuristic and meta-heuristic
algorithms that harness data and patterns to make informed decisions and approximate
solutions. Below are instances of common data-driven heuristic and meta-heuristic
algorithms:
6.5.3.1 Genetic Algorithms (GAs)
Natural selection and genetics serve as inspirations for GAs. They work by modeling
the selection, crossover, and mutation of a population of candidate solutions. GAs in a
data-driven scenario can leverage previous data to direct the evolution process and
enhance the quality of solutions over time. GAs are adaptive heuristic and meta￾heuristic algorithms commonly employed for solving search and optimization
problems. They have found applications in various fields, including ML, global
optimization, assembly line balancing, and even satellite image downlink scheduling.
The core principle behind GAs is inspired by Charles Darwin’s theory of natural
evolution, which emphasizes the survival of the fittest individuals over generations
(Katoch et al., 2021).
1. GAs in ML (Chaudhary, 2023):
GAs in ML are adaptive heuristic and meta-heuristic algorithms used to solve
search and optimization problems. They are inspired by Charles Darwin’s theory
of natural evolution, where the fittest individuals are selected for reproduction to
improve the next generation’s traits. This process is adapted to find optimal
solutions in various problem domains, including constrained and unconstrained
optimization. GAs quickly explore large solution spaces and consider constraints,
making them valuable for handling complex datasets (Lemos, 2022) (Figure 6.4).Figure 6.4 Applications of genetic algorithm in machine learning
(Chaudhary, 2023).
2. Intrusion Detection Using GAs (Adewumi, 2010):
GAs find application within the realm of intrusion detection, particularly in the
construction of Intrusion Detection Systems (IDS). These systems are designed to
oversee incoming connections and identify potential attacks. In this research, a
comparative analysis is conducted between the Simple Genetic Algorithm (SGA)
and the Steady State Genetic Algorithm (SSGA) in the context of developing IDS
models. This investigation serves to exemplify the utility of GAs in fortifying
security systems through the identification of optimal configurations for the
detection and mitigation of potential threats.
3. Workload Smoothing in Assembly Lines (Kim et al., 1998):GAs have found practical use in the context of optimizing workload
distribution within assembly lines. This application seeks to achieve a more
equitable distribution of tasks along assembly lines to boost overall efficiency.
The approach, which employs heuristic and meta-heuristic methods rooted in
GAs, places a strong emphasis on leveraging problem-specific insights and
heuristics to create an efficient representation and employ genetic operators. The
algorithm proposed in this study exhibits superior performance compared to both
existing heuristics and GAs with similar objectives.
4. Electrochemical Impedance Spectroscopy Parameter Estimation (Pech-Rodríguez
et al., 2023):
GAs are employed in the domain of parameter estimation within the context of
electrochemical impedance spectroscopy (EIS), aimed at unraveling the
intricacies of electronic and chemical reactions in energy devices based on
nanomaterials. This algorithm plays a pivotal role in estimating crucial
parameters such as electron transfer resistance and mass diffusion rate. These
estimations, in turn, propel progress in the development of energy generation and
storage technologies.
5. Introduction to GAs (Mallawaarachchi, 2017):
GAs are computational strategies rooted in the principles of natural evolution.
They operate through the identification of the most adaptive individuals within a
population, enabling them to procreate and enhance subsequent generations. This
iterative procedure encompasses stages like the generation of an initial
population, the assessment of fitness, the selection of candidates, genetic
recombination through crossover, and the introduction of variability via mutation.
GAs offer an effective approach to discovering optimal solutions within intricate
search spaces.
6. Flexible Job-Shop Scheduling Problem (Rezaeipanah et al., 2021):
GAs are employed in tackling the challenges of flexible job-shop scheduling
within the manufacturing domain. This algorithm amalgamates genetic and
greedy algorithmic approaches to enhance the optimization of task scheduling
based on performance metrics. To further enhance its efficacy, the algorithm
incorporates domain-specific insights during the generation of the initial
population.
7. Small Satellite Image Downlink Scheduling (Song et al., 2019):
GAs find application in the scheduling of small satellite image downlinks,
with the objective of optimizing the efficient utilization of both ground station
and satellite resources. In this process, the algorithm takes into account specific
regional targets and employs a genetic algorithm enriched with heuristic and
meta-heuristic components to maximize profits through the efficient scheduling
of tasks.
8. Cancer Classification using Microarray Data (Song et al., 2019):A method is introduced for cancer classification using microarray data,
integrating GAs with manifold learning to optimize the process of feature
selection. By factoring in manifold learning, this approach accommodates the
underlying nonlinear patterns within gene expression data, showcasing how GAs
can enhance the effectiveness of classification tasks.
6.5.3.2 Particle Swarm Optimization (PSO)
Particle Swarm Optimization (PSO) is a population-based optimization technique
inspired by the coordinated movements seen in bird flocks or fish schools. In PSO,
individual candidate solutions are likened to “particles” traversing the solution space,
continuously gaining knowledge from the collective experiences of their peers. PSO
can harness historical data to dynamically adjust each particle’s position and velocity,
thereby facilitating data-informed refinements that contribute to the attainment of
superior solutions. Data-driven modeling methods often serve as a viable alternative
for constructing precise models when conventional first-principle techniques are
infeasible. Nevertheless, evaluating the effectiveness of learned models, particularly
those generated using traditional data-driven approaches like ANNs and Fuzzy Models
(FM), poses a challenge. To address this concern, a solution is presented involving the
adoption of probabilistic Gaussian process (GP) models. In this thesis, a hybrid PSO
algorithm is introduced to tackle the task of optimizing the hyper-parameters involved
in model learning (Cao, 2017). Previous studies have demonstrated that PSO exhibits
rapid convergence toward optimal positions but may experience a slowdown in
convergence speed when it approaches a minimum. However, empirical findings
indicate that PSO remains a promising optimization technique, and novel strategies are
proposed to enhance its performance in proximity to optima, such as the
implementation of an adaptive inertia weight (Shi & Eberhart, 1999). PSO has been
utilized to optimize the maximum power output of photovoltaic systems and to
identify optimal design parameters for regulating step size in conventional methods
like perturb and observe (PO) and incremental conductance (IC). Through the
integration of a hybrid MPPT algorithm (comprising PSO and either IC or PO), the
step size is no longer static but adapts to variations in solar irradiance. The outcomes
underscore the remarkable superiority of the hybrid MPPT algorithm over traditional
methods, particularly in the case of PSO+IC, where it achieves a tracking time of just
43.4 milliseconds and attains an efficiency rating of 99.07% under standard test
conditions (Ibrahim et al., 2023). PSO has been enriched by the inclusion of an
extended version, enabling this heuristic to effectively address challenges associated
with problems featuring multiple objective functions (Coello et al., 2004). In contrast
to existing approaches for extending PSO to tackle multi-objective optimization
problems, this algorithm introduces a novel strategy involving the utilization of a
secondary (external) repository of particles, which subsequently serve as guides for the
flight paths of other particles.6.5.3.3 Simulated Annealing (SA)
Simulated annealing is a stochastic method that mimics the process of metallurgical
annealing. It commences with an initial solution and systematically examines
neighboring solutions, intermittently embracing suboptimal choices. SA possesses the
capacity to adapt its cooling schedule or acceptance probability based on historical
data, thus enhancing both the convergence rate and the quality of solutions in a data￾informed manner (Guilmeau et al., 2021). SA stands as a metaheuristic algorithm
employed for the resolution of optimization challenges. It takes inspiration from the
annealing process applied to metals, wherein the metal is gradually heated and then
slowly cooled to attain a solid state characterized by the lowest energy state. SA’s
primary objective lies in identifying the global minimum of a function through a
systematic exploration of the solution space, occasionally embracing suboptimal
solutions based on a predefined probability criterion. SA is often synergistically
employed alongside other algorithms to enhance its efficiency. In recent times, SA has
found application in data-driven contexts, including tasks such as feature selection,
optimizing the design of highway guardrails, scheduling jobs in cloud computing
environments, unsupervised paraphrasing, and assessing flash-flood hazards. On some
occasions, SA is amalgamated with other optimization techniques, such as the
hybridization with the Harris hawks optimization algorithm or the Bayesian network
structure learning algorithm, to further augment its performance (Kurtuluş et al.,
2020). SA represents a robust optimization algorithm with applicability across a broad
spectrum of domains. Its proficiency in uncovering the global minimum of a function
renders it especially valuable in tackling intricate optimization challenges.
Nevertheless, it’s essential to recognize that SA may not invariably serve as the
optimal algorithm for every problem, and its effectiveness can be heightened through
synergistic combinations with other algorithms (Mallaiah et al., 2021).
SA stands as a metaheuristic algorithm applicable to data-driven scenarios for
seeking the global minimum of a function through a systematic exploration of the
solution space, occasionally embracing suboptimal solutions based on a predefined
probability criterion. SA has found utility across diverse data-driven applications,
encompassing tasks like feature selection, optimizing designs, job scheduling,
evaluating image quality, and planning bike routes, among various others. In select
instances, SA is synergistically integrated with other optimization techniques to
enhance its overall performance, with examples including its hybridization with the
Harris hawks optimization algorithm and the Bayesian network structure learning
algorithm. One example of SA in data-driven applications is its use in feature
selection. According to Hussain and Surendran (2022), SA has been effectively
employed for feature selection in the context of extensive medical big data
applications, assisting in the identification of the most pertinent features. Furthermore,
SA has demonstrated its utility in optimizing designs, including applications like
enhancing highway guardrail designs and selecting noncoplanar VMAT beams. Its
versatility extends to job scheduling within cloud computing environments, facilitatingunsupervised paraphrasing, and aiding in flash-flood hazard assessment. In certain
scenarios, SA’s performance has been augmented through collaborative efforts with
other optimization algorithms.
In the following, Prawira and Santosa (2021) noted that SA and the hybrid Harris
hawks optimization algorithm were integrated to address the challenge of optimizing
vehicle routing involving drones. Varga (2022) shows that SA was incorporated into
the Bayesian network structure learning algorithm to enhance the optimization of
amalgamated image quality assessment metrics. It’s worth emphasizing that SA may
not universally represent the optimal choice for every problem, and its effectiveness
can be elevated through synergistic integration with other algorithms. SA stands as a
potent optimization tool applicable across a diverse array of scenarios, with a
particular aptitude for addressing intricate optimization challenges.
6.5.3.4 Ant Colony Optimization (ACO)
Ant colony optimization (ACO) is a metaheuristic technique that draws inspiration
from the foraging behavior exhibited by successful ant colonies. ACO has
demonstrated its efficacy in tackling challenging combinatorial optimization problems,
such as the TSP (Dewantoro et al., 2019). ACO has the potential to synergize with
complementary algorithms, resulting in hybrid approaches that enhance its overall
efficacy. For instance, a fusion of ACO with Tabu Search (TS) was introduced as a
local search strategy for addressing the TSP, demonstrating superior route optimization
and runtime compared to using ACO in isolation. Furthermore, ACO has found
application in the realm of path planning for autonomous underwater vehicles (AUVs)
navigating intricate environments characterized by densely populated obstacles (Liu et
al., 2017). A dual-tiered algorithm known as ACO-A* was created by amalgamating
the ant colony optimization (ACO) approach with the A* search algorithm. ACO plays
a role in establishing the travel sequence for targets, and a cost graph, signifying the
requisite travel expenses between targets, is constructed using a representative-based
estimation (RBE) technique. Following the sequence derived from ACO, targets are
traversed individually, and pairwise path planning is employed using A* while the
vehicle is in motion. Additionally, ACO has found utility in concealing data within
images. It serves to detect intricate regions within a base image, and the least
significant bits (LSBs) substitution method is employed to embed confidential data
within the pixels of these identified intricate regions. A pheromone matrix is
formulated based on the movement patterns of simulated ants, which are determined
by local variations in the intensity of image elements. The LSBs of the pixels within
complex regions are replaced with message bits to conceal confidential information.
Some real-world applications of ant colony optimization (ACO) include:
1. Optimizing the TSP:ACO has proven its effectiveness in resolving the TSP, a challenge centered
around determining the most efficient route that covers a set of cities and
ultimately returns to the initial city. Through a synergistic blend of ACO with TS,
a hybrid approach has been devised, yielding improved routes and more efficient
computation times compared to using ACO in isolation (Dewantoro et al., 2019).
2. Navigation Strategies for AUVs:
ACO has found application in guiding the path of AUVs through intricate
environments characterized by densely distributed obstacles. An innovative two￾tiered approach, named ACO-A*, merges ACO with the A* search algorithm.
This combined method efficiently orchestrates the sequence in which targets are
visited and concurrently charts pairwise routes to reach each of these designated
targets (Dewantoro et al., 2019).
3. Concealing Data within Images:
ACO has been harnessed for the purpose of embedding data into images. In
this context, ACO plays a pivotal role in identifying intricate regions within the
base image. The subsequent step involves employing the LSB substitution
method to conceal confidential information within the pixels located in these
identified complex regions. The development of a pheromone matrix is guided by
the simulated movement patterns of ants, influenced by the local disparities in
image element intensities (Khan, 2018).
4. Exploration of Classification Rules in Data Mining:
ACO has been utilized for the purpose of unearthing classification rules in the
field of data mining. An ACO algorithm known as Ant-Miner is employed to
identify these classification rules, drawing inspiration from the behavior of ants as
they navigate the shortest path between a food source and their colony nest
(Khan, 2018).
6.5.3.5 Reinforcement Learning (RL)
Reinforcement Learning (RL) represents a learning framework for control, where an
agent seeks to optimize a predefined reward signal by engaging in trial-and-error
interactions with the environment. RL can be categorized into two principal
paradigms: online RL and offline RL. Offline RL, often referred to as batch RL, is a
data-centric RL approach focused on knowledge acquisition solely from static datasets
comprising past interactions (Schrittwieser et al., 2021). Within the realm of offline
RL, a behavior policy engages with the environment to gather a collection of
experiences, subsequently employable for policy learning without the need for further
interactions. Offline RL algorithms that demonstrate effectiveness possess a
significantly broader scope of utility compared to online RL, showcasing particular
attractiveness in the context of real-world applications, including domains such as
education, healthcare, and robotics (Prudencio et al., 2023). Recent studies have
introduced novel approaches within the realm of offline RL, including methods likeSafety Augmented (Saute) Markov Decision Processes (MDPs). These approaches
effectively address safety concerns by integrating them into the state space and
modifying the primary objective. By incorporating safety constraints into the state
representation, it becomes feasible to generalize policies while simultaneously
accommodating new features. Saute RL algorithms have demonstrated superior
performance over their state-of-the-art counterparts, particularly in scenarios where
ensuring constraint satisfaction holds significant importance (Sootla et al., 2022). RL￾Scope stands as a comprehensive cross-stack profiler, compatible with multiple ML
backends and simulators. It functions by gathering profiling data throughout the entire
software stack and then narrows its focus to high-level operations. This offers
developers and researchers a holistic view of RL training duration. RL-Scope has been
effectively utilized for benchmarking RL frameworks and quantifying the
consequences of fundamental design decisions made in ML backends. On the other
hand, RL-Cycle GAN presents a fresh strategy for transferring simulations into real￾world scenarios within the context of reinforcement learning. It leverages generative
models to transform simulated images into authentic ones. A distinctive feature it
introduces is the RL-scene consistency loss, which ensures that the image translation
process remains invariant concerning the associated Q-values, thereby enabling task￾aware translation. (Rao et al., 2020). Conclusively, the utilization of reinforcement
learning (RL) in network management represents an intelligent approach to network
administration, relying on RL methodologies. RL empowers management systems
within communication networks with intelligence and autonomy, and its evolution has
been driven by the incorporation of deep learning techniques, stemming from both
model-driven and data-driven technical methodologies (Rao et al., 2020).
RL has a wide range of real-world applications, including (Prudencio et al., 2023):
1. Robotics:
RL has the potential to instruct robots in the execution of intricate tasks,
including but not limited to tasks like object manipulation, autonomous
navigation in diverse environments, and engaging in interactions with human
counterparts.
2. Education:
RL can be harnessed to tailor educational experiences for students,
customizing the learning process to align with their unique requirements and
preferences.
3. Healthcare:
RL offers the potential to enhance treatment planning for patients by factoring
in their distinct medical backgrounds and current health conditions, thus
optimizing healthcare strategies.
4. Signaling games:RL can be applied to simulate the decision-making mechanisms of players in
the context of a signaling game. These games often involve situations where one
player possesses information that is unknown to the other player, a scenario
frequently encountered in real-world scenarios.
5. Network management:
RL finds utility in the realm of intelligent network management, facilitating
the autonomous provision of management systems within a communication
network.
6. Trading:
RL can serve as a valuable tool for enhancing trading strategies and facilitating
more informed investment choices.
7. Control systems:
RL has the potential to streamline the optimization of control systems,
particularly within industries like aerospace and automotive engineering.
6.5.3.6 Neural network optimization
DDO methods are becoming increasingly important in industrial system performance
optimization. The efficiency of these methods depends on their algorithm parameter
settings, which are usually optimized through a trial-and-error process that can be
cumbersome and time-consuming. To address this problem, a closed-loop DDO
method has been proposed that uses a Visual Geometry Group (VGG) neural network
to obtain the morphological characteristics of the current optimization process and
guide the data-driven algorithm based on Simultaneous Perturbation Stochastic
Approximation (SPSA) to improve the current optimization process (Li et al., 2023).
In a separate investigation, researchers employed a data-driven strategy known as the
operator inference framework to represent the dynamics of a system. Here, they
incorporated a physics-informed structure for the system’s nonlinear component. The
approach combines operator inference with specific deep neural network techniques to
infer the elusive nonlinear dynamics of the system. Although the resulting optimization
problem is characterized by high dimensionality and non-convexity, neural networks,
particularly those incorporating skip connections as proposed here, have demonstrated
the ability to converge toward a global minimum, or approximate it closely, even when
employing straightforward stochastic gradient methods. In another instance, a data￾driven model for control systems was formulated using the Markov model, aiming to
optimize the performance of a wind energy conversion system (WECS) through the
integration of neural networks. This method effectively mitigates fluctuations in
generator speed, enhances the safety of wind turbines, refines the precision of WECS
output, and maximizes the capture of wind energy (Goyal & Benner, 2021).
The growing significance of DDO techniques is evident in their expanding role
within industrial systems. The relevance and applications of DDO within industrialsystems are exemplified by the following instances:
1. Closed-loop DDO method:
This approach leverages a VGG neural network to extract the morphological
attributes of the ongoing optimization process. These characteristics subsequently
serve as guidance for a data-driven algorithm rooted in SPSA to enhance the
ongoing optimization endeavor (Yang et al., 2022).
2. Bayesian optimization auto ML time-series framework:
This framework inherently offers built-in capabilities for time-series models
and boasts optimization support spanning an extensive array of model and hyper￾parameter configurations. Additionally, it incorporates a warm-starting module
designed for meta-learning, an interface for users to define custom models, and a
User Interface that furnishes a comprehensive overview of optimization outcomes
along with deployment guidelines (Kurian et al., 2021).
3. Feedback control systems:
The introduction of the RL algorithm involves the utilization of exclusively
measured input-output and residual signals to enhance the controller for industrial
applications (Yang et al., 2022).
6.6 INTEGRATION OF OPTIMIZATION AND
COMPUTING APPROACHES
One of the primary drivers behind the surge in big data, cloud technologies, and the
IoT can be attributed to the widespread access to an array of digital devices and tools.
This access has enabled diverse methods of data acquisition, aggregation, and the
generation of extensive data volumes. In many scenarios, algorithms endowed with
substantial computational capabilities and the capacity to store vast datasets are
employed, particularly within the realms of Data Science and ML. Data-driven
computing represents a burgeoning field of computer science where prediction
outcomes are directly derived from input data (Moumtzidis et al., 2022; Wagner &
Cozmiuc, 2022). The term ‘data-driven’ signifies that data serves as the determining
factor shaping the behavior of individuals engaged in an event or activity. This
paradigm has played a pivotal role in fueling early developments and fostering a
multitude of prospective enhancements and applications within the domain.
Computational models offer the means to translate observations into predictions
concerning future events, act as experimental platforms for novel concepts, extract
value from data, and formulate inquiries pertaining to behavior (Wirtz, 2022). The
outcomes are subsequently harnessed to gain insights, enhance, oversee, and predict
the functioning of intricate systems and procedures, spanning an array of domains
from public policy to self-governing systems. The utility of models has transcended
traditional domains like engineering and science, extending their application intodiverse fields such as finance, economics, corporate administration, public policy, and
urban planning. The growing processing capabilities and data accessibility have
facilitated the emergence of novel computational models capable of offering more
intricate descriptions of the systems under consideration (Bibri, 2021).
These computational models effectively enable us to simulate hypothetical
scenarios, providing the ability to adjust the factors influencing specific aspects before
applying them in real-world situations. Computational modeling, much like any other
technological instrument, lacks inherent virtue or harm. Models have the potential to
offer insights or lead astray, and their utilization can be either accurate or misguided.
Therefore, it is crucial to possess a thorough comprehension of the computational
modeling process and a heightened awareness of when and how to use these models
safely (Winsberg, 2003). This responsibility should not rest solely with the modelers;
those who commission and utilize these models must also possess a degree of
expertise. Making informed decisions during the model commissioning process, as
well as discerning when and how to employ a model, carries equal significance to the
more technical aspects of model development. Just as a meticulously engineered
hammer may align precisely with its specifications but is ill-suited for driving screws,
the appropriateness of model usage hinges on these considerations (Sezer &
Namukasa, 2021).
Integrating optimization methodologies with computational strategies is a
fundamental aspect of data-driven algorithms. Optimization methods are harnessed to
discover the best possible solutions for various problems, while computational
strategies are employed to manage and analyze vast volumes of data. The synergy of
these two approaches enables the development of data-driven algorithms that excel in
tackling complex challenges and handling extensive datasets. A prime example of this
convergence of optimization and computational techniques is evident in the evolution
of ML algorithms. In the realm of ML, optimization methods are utilized to identify
the most suitable model parameters that align harmoniously with the available data,
while computational techniques play an indispensable role in processing and
scrutinizing large and intricate datasets (De Loera et al., 2021).
This fusion empowers ML algorithms to acquire knowledge from extensive datasets
and deliver precise predictions. Similarly, this synergy is exemplified in the creation of
optimization algorithms tailored for addressing large-scale challenges. While
optimization algorithms excel at finding optimal solutions, their computational
demands can be prohibitive when dealing with large-scale problems. Employing
computational strategies such as parallel computing or distributed computing enables
the scalability of optimization algorithms, enabling them to effectively manage
expansive datasets and intricate problem domains (Wang et al., 2021).
The fusion of optimization and computational techniques involves the blending of
various tools and approaches to methodically evaluate a wide range of algorithms
across complex benchmark scenarios. This method offers a way to address the task of
choosing and setting up an algorithm that harmonizes efficiently with the particularproblem’s structure, optimization goals, and the computational resources at hand (Guo
et al., 2019). An illustrative instance of this unified approach involves combining the
algorithm framework ‘Paradise’ with the automated algorithm configuration tool ‘race’
and the experimental platform ‘IO profiler.’ This integrated process offers several
benefits, such as swift assessment times, the creation of comprehensive datasets to
support algorithm analysis, and the establishment of a standardized interface suitable
for benchmarking various sampling-based optimization techniques. In addition to
facilitating methodical investigations into algorithm configuration, this approach also
enables the assessment of how new concepts interact with existing methods. This
avenue of research holds significant potential in a field that frequently emphasizes
comparing fully developed algorithm instances (Aziz-Alaoui et al., 2021).
Optimization and computing approaches can improve the performance of data￾driven algorithms in several ways:
Improved Accuracy: Optimization methods are instrumental in locating the most
optimal solution for a given challenge, whereas computational methodologies are
adept at handling and scrutinizing extensive data sets. When these two strategies
are harmoniously integrated, it becomes possible to create data-driven algorithms
that excel in addressing intricate problems and managing vast data volumes,
thereby enhancing precision and efficiency (Asaad et al., 2022).
Scalability: Optimization algorithms often demand significant computational
resources when applied to extensive problems. However, employing
computational techniques like parallel computing or distributed computing allows
for the expansion of optimization algorithms, enabling them to tackle both
complex challenges and substantial datasets effectively (Brownlee, 2021).
Efficiency: Integrating constraints within the framework of a data-driven
algorithm can notably enhance the efficiency of making inferences during testing.
For example, a novel approach to constrained generative modeling circumvents
the need to address an optimization challenge during every training iteration or to
manually balance data fidelity and constraint adherence by introducing extra
hyper-parameters (Schwenzer et al., 2021).
Fairness: Utilizing computational strategies allows for obtaining additional data
pertaining to specific features while keeping within budget constraints, enabling
the pursuit of fairness in decision-making processes (Bakker et al., 2020).
Optimization of Quality of Experience (QoE): Enhancing Internet QoE through
data-driven methods involves harnessing a centralized, up-to-the-minute
perspective on performance across a vast array of endpoints, which typically
represent millions of clients (Jiang, 2017).
Exact techniques strive to deliver results that are rigorously precise and free from any
form of approximation or rounding discrepancies. They rely on meticulous
computations and representations of numerical values. Exact methods are typicallyfavored when confronted with scenarios necessitating the utmost accuracy, such as
storing precise data in a database or conducting highly accurate calculations.
Conversely, approximate methods entail employing estimations or close
approximations to obtain outcomes that closely approximate the true values. These
approaches may incorporate simplifications or assumptions to simplify calculations or
enhance computational efficiency. Approximate methods come into play when exact
calculations are impractical or when an approximate solution suffices. They find utility
in scenarios where obtaining the exact solution poses difficulties, particularly when
managing extensive datasets. Furthermore, approximate methods serve as valuable
tools for validating or comparing results against exact methods, thereby assessing their
accuracy and computational efficiency (Aandahl et al., 2014).
Data-driven mathematical models leverage data to formulate mathematical
expressions capable of forecasting or elucidating phenomena. These models find
application in diverse fields like epidemiology, the theory of big data, petrochemical
planning, expectation forecasting, and control systems for mining equipment. Various
techniques, including differential equations, fuzzy logic, and rough set theory, can be
employed to construct these models. The overarching objective of data-driven
mathematical models is to furnish precise and dependable predictions or explanations
grounded in the available data. Data-driven mathematics involves the process of
directly deriving mathematical models from data. This approach entails a
comprehensive examination of complete datasets through statistical methodologies and
the amalgamation of analytical outcomes from each of these complete datasets.
(Arridge et al., 2019). The resultant models find application in the interpretation of
observed occurrences and the categorization of data. Data-driven mathematical
modeling is a versatile tool deployed across various domains, such as mathematical
biology and the development of intelligent urban areas. Within the context of smart
and sustainable cities, researchers are actively crafting novel mathematical models by
harnessing the potential of big data. In the realm of mathematical biology, data-driven
modeling plays a pivotal role in constructing phenomenological models from empirical
data and formulating explanatory mathematical models rooted in dynamic systems.
This method entails the analysis of data, the classification of information, and the
elucidation of observed phenomena through the framework provided by these models.
In a recent investigation, a data-driven mathematical model was employed to unify
disparate datasets, creating a coherent depiction of the interconnected signaling and
apoptosis pathways that regulate the survival of plasma cells. (Li et al., 2016; Phillips
et al., 2021).
Single-objective optimization pertains to the process of enhancing a solitary
objective function within predefined constraints. The primary aim is to identify the
most favorable solution that either maximizes or minimizes the objective function, all
while ensuring compliance with the given constraints. This approach is extensively
applied across a spectrum of disciplines, including engineering, economics, and
logistics. On the other hand, multi-objective optimization tackles the optimization ofmultiple objective functions under constraints. The fundamental objective here is to
discover a set of Pareto-optimal solutions, representing the most advantageous
compromises among the competing objectives. Multi-objective optimization finds
utility in numerous domains where optimal decisions necessitate balancing trade-offs
among two or more conflicting objectives, such as in engineering design, financial
decision-making, and environmental management (Alsheddy, 2018).
A data-driven method for approximating solutions is a technique that relies on data
to derive an estimation for addressing a problem. This approach proves particularly
valuable when a precise analytical solution is either unavailable or excessively
intricate to compute. In the data-driven methodology, a simplified representation of the
solution space is established, achieving this through either a model-based or data￾driven approach. This streamlined representation is then applied to expedite the
solution process. The data-driven solution is reached by employing an adaptive solver
with a dataset, and the accuracy of the solution is assessed relative to the size of the
data (Nguyen et al., 2022). As mentioned in the previous section, heuristic and
metaheuristic data-driven approaches can be used as approximate approaches. In
Figure 6.5, metaheuristic approaches are presented in an expanded category that has a
more practical and detailed look at solving real-world problems than Section 6.5,
which was classified into five general categories. Accordingly, we define the
components of data-driven metaheuristic classification as follows:
Figure 6.5 A developed classification of data-driven solution approaches.
6.6.1 Population-based
Population-based data-driven techniques describe an approach that utilizes data
collected from a population to derive an approximate solution for a given problem.
This methodology entails creating a simplified, lower-dimensional representation of
the solution space, which can be achieved through either a model-based or data-drivenapproach. Subsequently, data from a population is employed to expedite the problem￾solving process. This population-centered data-driven strategy has found application in
diverse problem domains, including but not limited to modeling and understanding
COVID-19, predicting the spread of epidemics, and addressing problems involving
probabilistic constraints. Notably, this approach has demonstrated promising outcomes
in approximating solutions for these issues through the utilization of population-based
data-driven (Gao et al., 2018).
6.6.2 Swarm intelligence/robotics-based
Data-driven approaches within the context of swarm robotics involve leveraging data
to enhance the collective performance of a group of robots working collaboratively
toward a shared objective. This approach relies heavily on the principles of swarm
intelligence, as the success of the team is intricately linked to the effectiveness of each
individual within the swarm. In this approach, there is no central coordination or
predefined plan; instead, the group of robots autonomously generates its outcomes
through a data-driven, bottom-up process.
For instance, PSO represents a specific type of swarm intelligence algorithm
employed in data-driven strategies within swarm robotics. PSO draws inspiration from
the social behaviors observed in bird flocking or fish schooling and is employed as a
decision-making mechanism in multicriteria and metaheuristic analyses. Moreover,
PSO can be utilized to adapt controller parameters in a closed-loop system, enhancing
its resilience through the use of swarm intelligence algorithms. Furthermore, PSO
finds applications in ML models, particularly in Ensemble Learning (EL) techniques,
where it contributes to predicting the motion speed of swarm robots. Employing EL￾based models proves beneficial in enhancing the performance of ML systems by
amalgamating insights from multiple learners rather than relying solely on individual
regressors. The effectiveness of these developed methods has been demonstrated to
outperform traditional ML models, such as Support Vector Regressors and GP
Regressors, especially in environments featuring obstacles, whether free or obstructed
(Ramírez-Ochoa et al., 2022).
6.6.3 Nature-inspired
Data-driven techniques applied within nature-inspired algorithms represent an
innovative approach where data plays a pivotal role. These methods find application
across diverse domains, including the realm of swarm robotics. Below are some
illustrative instances of data-driven nature-inspired approaches within the context of
swarm robotics:
1. Robotic artwork generation:An artistic process that involves the collaborative efforts of a swarm of robots
to create intricate spatiotemporal patterns from an initially uniform medium. This
process draws inspiration from the interactions observed in social insect societies,
leveraging robot-robot and robot-environment interactions to elicit emergent
behaviors. The concept of swarm intelligence is central to this approach, as it
highlights the interconnectedness of individual robot viability with the overall
team success. Remarkably, this artistic endeavor unfolds without central
coordination or predefined plans, relying instead on a data-driven, bottom-up
methodology (McClean, 2021).
2. Intelligent semi-autonomous agents:
Nature-inspired algorithms, such as Stigmergy, Flocking, and Differential
Evolution, can be harnessed to endow semi-autonomous agents within a swarm
with intelligence. These algorithms take cues from nature’s mechanisms to steer
the behavior of individual agents, contributing to the collective capabilities of the
swarm (Adithyan et al., 2017).
3. Simulation and modeling:
Precise simulation and modeling in the field of swarm robotics hold significant
significance as they provide a secure environment for the development and
testing of extensive multi-agent systems. To meet this requirement, a modernized
simulation platform has been created, enabling the replication of scenarios where
a group of robots is assigned particular tasks in dynamically generated
surroundings. In this context, the decision-making abilities of each agent are
influenced by algorithms inspired by natural processes. This arrangement offers
the opportunity for thorough testing and iterative improvement (Mehta & Kaur,
2019).
6.6.4 Local search-based
Data-driven strategies incorporated into local search algorithms involve the application
of data-driven techniques to enhance the functionality of these algorithms. As an
illustration, a data-driven method constrained by physics and based on locally convex
reconstruction is employed to model anisotropic nonlinear elastic materials,
particularly when dealing with noisy databases. This approach introduces a two-tiered
local data search algorithm, specifically designed to address material anisotropy, into
the online data-driven computing process. The effectiveness of this data-driven
framework is assessed through experiments that involve both clean and noisy material
data, using synthetic material data for two standard benchmark problems. Additionally,
there is the development of a hybrid data-driven approach known as Graph Neural
Network Guided Local Search (GLS). GLS is tailored for tackling complex problems
like the TSP, employing the power of graph neural networks to enhance the local
search process. Graph Neural Network GLS is a hybrid data-driven approach for
solving the TSP (Hudson et al., 2021). The model makes predictions about the regretassociated with the inclusion of each edge from the problem graph into the solution,
and the Graph Neural Network GLS utilizes these predictions alongside the original
problem graph to discover solutions. This approach demonstrates a higher rate of
convergence toward optimal solutions when compared to three recently developed
learning-based methods designed for solving the TSP. Another innovative solution
called SegMap offers a novel approach to localization and mapping using 3D point
cloud data. SegMap leverages a compact data-driven descriptor to perform multiple
tasks, including global localization, 3D map reconstruction, and semantic information
extraction. Its performance is rigorously assessed in various scenarios, such as urban
driving and search and rescue missions. SegMap’s learned descriptor excels in
segment retrieval capabilities when compared to established handcrafted descriptors.
Consequently, SegMap achieves superior localization accuracy and boasts a 6%
improvement in recall when compared to state-of-the-art handcrafted descriptors.
Additionally, a novel optimization algorithm, based on the concept of surrogate
models and particle swarm optimization, is introduced for the efficient operation of
microgrids. This algorithm employs a global-local search mechanism to navigate the
fitness landscape effectively. To enhance the robustness of the Kriging model, dynamic
transformations are applied. The method’s performance is rigorously tested on various
benchmark test functions, spanning two test suites, revealing its superior optimization
accuracy when compared to other algorithms used for comparison. (Fan et al., 2021).
6.6.5 Based on physical phenomena
Utilizing data-driven methodologies rooted in the understanding of physical
phenomena signifies the application of data-driven techniques for the modeling and
emulation of natural occurrences. For instance, consider the case of FMO, a theoretical
approach employed to examine the intricate dynamics of energy transfer within
photosynthetic pigment-protein complexes. FMO relies on the fundamental principles
of quantum mechanics and employs computational techniques to replicate and study
the energy transfer process (Klie, 2021).
6.6.6 Hybrid metaheuristics
Data-driven hybrid metaheuristics pertain to the integration of data-driven techniques
into hybrid metaheuristic algorithms. In practice, various hybrid metaheuristics
employ a blend of different algorithms in conjunction with data-driven methodologies
to enhance their overall performance, as elaborated upon in the preceding section. For
instance, consider DMC-GRASP, an adaptation of C-GRASP that incorporates data
mining techniques. These techniques are used to recognize patterns within high-quality
solutions and, in turn, generate new solutions guided by these identified patterns.
Another notable example involves a data-driven framework designed for optimizing
the sizing of hybrid renewable energy systems. This framework amalgamates ML andhybrid metaheuristics, leveraging ML for weather pattern prediction and the
optimization of system sizes. (Santos et al., 2022).
Evidence demonstrates that the fusion of optimization and computational strategies
has found application across a wide spectrum of fields. These include computer vision
measurement, enhancements in heating, ventilation, and air conditioning system
performance, optimization within tunneling operations, planning assembly sequences,
enabling intelligent edge services, optimizing the architecture of multilayer perceptron,
fine-tuning parameters in friction stir welding processes, and enhancing economic load
dispatch mechanisms. The optimization techniques harnessed in these studies
encompass a range of soft computing approaches, such as ANNs, adaptive neuro-fuzzy
inference systems, GAs, and metaheuristic algorithms. The outcomes of these
investigations underscore the ability of optimization techniques to deliver more precise
results and to curtail error rates effectively. Furthermore, it’s noteworthy that the
optimization techniques employed in these studies exhibit versatility, as they can be
effectively employed to tackle nonlinear optimization problems encompassing both
equality and inequality constraints. Combining optimization and computing
approaches can provide several benefits, including (Guo et al., 2020; Nesmachnow,
2015):
Enhanced Precision: Optimization techniques have the capability to generate
results with a higher degree of accuracy, effectively diminishing error rates.
Accelerated Problem-Solving: Soft computing methods, including
metaheuristics, can efficiently compute solutions of high quality for challenging
problems within reasonable timeframes.
Handling Complexity: Optimization techniques are well-suited to address
intricate issues, effectively tackling nonlinear optimization problems
characterized by both equality and inequality constraints.
Adaptability to Uncertainty: Soft computing techniques, such as metaheuristics,
possess the ability to work effectively with imprecise, uncertain, or approximated
data. They can manage partial information and provide accurate solutions for
optimization problems even when exact data is unavailable.
Meeting Realistic Timelines: Metaheuristics are adept at ensuring that solutions
are achieved within practical timeframes, a feature valuable across diverse
domains, ranging from informatics to industrial and commercial applications.
Innovative Hybrid Approaches: The fusion of optimization and computing
methodologies can foster the creation of innovative hybrid intelligent methods,
expanding the problem-solving toolkit.
Enhanced System Performance: Combining optimization and computing
approaches can result in substantial improvements in system performance,
applicable across fields such as heating, ventilation, and air conditioning systems.Time Efficiency: The synergy between optimization and computing techniques
can lead to a significant reduction in the time elapsed between defining a problem
and arriving at a solution.
In conclusion, the amalgamation of optimization and computing strategies yields a
multitude of advantages, encompassing enhanced precision, expedited problem￾solving, adeptness in tackling intricate challenges, adaptability to vagueness and
unpredictability, adherence to practical timeframes, innovation through hybrid
intelligent techniques, performance enhancement, and a reduction in time expended.
Particularly, soft computing methods like metaheuristics prove adept at effectively
addressing complex problems, autonomously adapting to the terrain of the search
space, striking a balance between exploration and exploitation, accommodating
imprecision and ambiguity, producing high-quality solutions, supporting hybridization
with other optimization techniques, and ensuring the fulfillment of realistic resolution
timelines in numerous application domains. These studies underscore the significance
of hybridizing metaheuristics with other optimization methods and highlight the
rapidly evolving nature of the field of metaheuristics.
6.7 INTEGRATED OPTIMIZATION AND
COMPUTING APPROACHES USING INTELLIGENT
DATA-DRIVEN
This section delves into the synergy between optimization techniques, computing
methodologies, and intelligent data-driven approaches to facilitate more informed,
efficient, and effective decision-making. By integrating these diverse fields, DMs can
harness the power of data analytics, ML, and optimization to address complex
problems across domains such as supply chain management, finance, healthcare, and
engineering.
Optimization and computing have long been fundamental components of problem￾solving in fields such as engineering, logistics, finance, and more. These techniques
involve finding the best possible solution from a set of alternatives, given specific
constraints and objectives. Classical optimization algorithms, such as linear
programming and dynamic programming, have played pivotal roles in optimizing
processes and decision-making. However, as problems grew in complexity and data
became more abundant, traditional optimization and computing methods started to
encounter limitations. They struggled to handle large-scale, nonlinear, and uncertain
scenarios efficiently. This limitation prompted researchers and practitioners to look for
alternative approaches.
Integrated optimization and computing approaches involve the seamless integration
of mathematical optimization techniques with high-performance computing systems,
including cloud computing, supercomputing, and parallel computing. Mathematicaloptimization is the process of finding the best solution to a problem from a set of
possible solutions while adhering to certain constraints. This can include maximizing
profits, minimizing costs, optimizing resource allocation, and much more. Computing
approaches, on the other hand, encompass a wide range of technologies and
methodologies, such as ML, AI, data analytics, and quantum computing. These
computational tools can be used to enhance the effectiveness of optimization
processes, leading to more accurate and timely decisions.
6.7.1 Applications across industries
6.7.1.1 Manufacturing and Supply Chain Optimization
Integrated optimization and computing can optimize production schedules, minimize
inventory costs, and improve supply chain logistics. By combining optimization
algorithms with real-time data analytics and AI-driven demand forecasting,
manufacturers can respond swiftly to changes in market demand, reduce wastage, and
enhance overall production efficiency.
Healthcare and Treatment Planning: In the healthcare sector, these approaches
are used to optimize patient treatment plans, hospital resource allocation, and
clinical trial designs. By considering various factors like patient history, treatment
options, and resource constraints, healthcare providers can make data-driven
decisions to deliver more effective and efficient care.
Financial Portfolio Management: In the world of finance, integrated
optimization and computing enable portfolio managers to optimize investment
strategies, mitigate risk, and maximize returns. These approaches take into
account market data, economic indicators, and individual investor preferences to
create optimized investment portfolios.
Energy and Sustainability: The energy industry utilizes optimization and
computing techniques to optimize power generation, distribution, and
consumption. By leveraging data from smart grids, weather forecasts, and
renewable energy sources, energy companies can minimize costs and reduce
environmental impact.
6.7.2 Benefits of integration
Integrated optimization and computing approaches represent a powerful synergy
between mathematical optimization and advanced computing technologies. As
industries continue to embrace digital transformation, these approaches will play a
crucial role in driving efficiency, reducing costs, and enabling data-driven decision￾making. From manufacturing and healthcare to finance and energy, the integration of
optimization and computing is poised to reshape industries and create a more efficientand sustainable future. The integration of optimization and computing approaches
offers several compelling benefits:
Enhanced Decision-Making: By leveraging computational power and
optimization algorithms, organizations can make data-driven decisions quickly
and accurately, leading to improved overall performance.
Cost Reduction: Optimizing processes and resource allocation can lead to
significant cost savings. Whether it’s in supply chain management, energy
consumption, or financial investments, efficiency gains translate into financial
benefits.
Improved Resource Utilization: Companies can maximize the utilization of
resources such as time, labor, and equipment, resulting in higher productivity and
reduced waste.
Adaptability: Integrated approaches can adapt to changing conditions in real￾time, helping organizations respond swiftly to unexpected events or market
fluctuations.
Sustainability: These approaches contribute to sustainability goals by optimizing
resource use and minimizing environmental impact.
6.8 CONCLUSION AND FUTURE DIRECTIONS
In this comprehensive exploration of optimization and computing using intelligent
data-driven approaches for decision-making, we have delved deep into the
transformative potential of these methodologies. Throughout this chapter, we have
witnessed the power of leveraging data-driven insights and computational capabilities
in various domains, including but not limited to supply chain management.
Our journey has underscored the versatility and effectiveness of these intelligent
data-driven approaches in enhancing decision-making processes. From the deployment
of advanced ML algorithms for predictive analytics to the fine-tuning of optimization
techniques for resource allocation, it is evident that the synergy between data and
computation is reshaping the landscape of problem-solving.
As we reflect on the rich tapestry of insights and methodologies presented herein,
we recognize that this chapter merely scratches the surface of what is possible. The
evolution of optimization and computing using intelligent data-driven approaches for
decision-making is ongoing, and the horizons are filled with potential avenues for
research, application, and innovation.
6.8.1 Future directions
Interpretability and Explain ability: As ML models become increasingly
complex, there is a growing need to improve their interpretability andexplainability. Future research should focus on developing methodologies and
tools that enable us to understand and trust the decisions made by AI systems,
especially in critical applications.
Ethical AI and Fairness: Ethical considerations surrounding AI and data-driven
decision-making are paramount. Researchers and practitioners must continue to
address issues related to bias, fairness, and accountability. The development of
ethical frameworks and guidelines will be crucial in ensuring responsible AI
deployment.
Adaptive Learning Systems: The creation of adaptive learning systems that can
autonomously evolve and adapt to changing data distributions and environments
is a compelling area of research. Such systems could provide decision support
that is not only accurate but also agile in responding to emerging trends and
challenges.
Human-AI Collaboration: Exploring ways to foster productive collaboration
between humans and AI systems is essential. Developing AI models that can
effectively complement human DMs and vice versa will be key in harnessing the
full potential of intelligent data-driven approaches.
Cross-disciplinary Research: The convergence of knowledge from various
fields, including computer science, domain-specific expertise, and behavioral
sciences, can yield transformative solutions to complex problems. Encouraging
cross-disciplinary collaboration and research will be instrumental in advancing
the field.
Scalable and Efficient Algorithms: With the ever-increasing volume of data,
there is a growing demand for algorithms that are not only accurate but also
scalable and computationally efficient. Future work should focus on developing
techniques that can handle large-scale data without compromising performance.
In conclusion, the field of optimization and computing using intelligent data-driven
approaches for decision-making is on an exciting trajectory. By addressing these future
directions and challenges, we can harness the full potential of data-driven decision￾making to drive positive societal and economic impact. As researchers and
practitioners, we stand at the forefront of a transformative era, and our collective
efforts will shape the future of intelligent decision support systems.
REFERENCES
Aandahl, R. Z., Stadler, T., Sisson, S. A., & Tanaka, M. M. (2014). Exact vs.
approximate computation: reconciling different estimates of Mycobacterium
tuberculosis epidemiological parameters. Genetics, 196(4), 1227–1230.Abdollahzadeh, B., Soleimanian Gharehchopogh, F., & Mirjalili, S. (2021).
Artificial gorilla troops optimizer: a new nature‐inspired metaheuristic
algorithm for global optimization problems. International Journal of
Intelligent Systems, 36(10), 5887–5958.
Abraham, D. (2020). Data-Driven Decision Making and Community Indicators:
Towards an Integration of DDDM in Community Development. In F. Ridzi, C.
Stevens, & M. Davern (Eds. ), Community Quality-of-Life Indicators: Best
Cases VIII (pp. 199–210). Springer International Publishing.
https://doi.org/10.1007/978-3-030-48182-7_11.
Adewumi, A. O. (2010). Some improved genetic-algorithms based heuristics for
global optimization with innovative applications. University of the
Witwatersrand, Johannesburg.
Adithyan, T. A., Sharma, V., Gururaj, B., & Thirumalai, C. (2017, 11–12 May
2017). Nature inspired algorithm. 2017 International Conference on Trends in
Electronics and Informatics (ICEI).
Agrawal, P., Abutarboush, H. F., Ganesh, T., & Mohamed, A. W. (2021).
Metaheuristic algorithms on feature selection: a survey of one decade of
research (2009–2019). IEEE Access, 9, 26766–26791.
Agushaka, J. O., & Ezugwu, A. E. (2022). Initialisation approaches for
population-based metaheuristic algorithms: a comprehensive review. Applied
Sciences, 12(2), 896.
Aigner, K.-M., Goerigk, M., Hartisch, M., Liers, F., & Miehlich, A. (2023). A
Framework for Data-Driven Explainability in Mathematical Optimization.
arXiv preprint arXiv:2308.08309.
Al Mohamed, A. A., Al Mohamed, S., & Zino, M. (2023). Application of fuzzy
multicriteria decision-making model in selecting pandemic hospital site.
Future Business Journal, 9(1), 14. https://doi.org/10.1186/s43093-023-00185-
5
Algorithms for Reinforcement Learning Synthesis Lectures on Artificial
Intelligence and Machine Learning. Epdf Read, 2021.
Alissa, M., Sim, K., & Hart, E. (2023). Automated algorithm selection: from
feature-based to feature-free approaches. Journal of Heuristics, 29(1), 1–38.
Almuhaideb, S., Altwaijry, N., AlMansour, S., AlMklafi, A., AlMojel, A. K.,
AlQahtani, B., & AlHarran, M. (2022). Clique finder: a self-adaptive
simulated annealing algorithm for the maximum clique problem. International
Journal of Applied Metaheuristic Computing (IJAMC), 13(2), 1–22.
Alsheddy, A. (2018). A penalty-based multi-objectivization approach for single
objective optimization. Information Sciences, 442, 1–17.Andrew Yeung, S. D. P. M. (2023). Decision Intelligence: Using Data to Drive
Better Outcomes. https://www.thoughtspot.com/data-trends/ai/decision￾intelligence.
Arend, R. J. (2020). Strategic decision-making under ambiguity: a new problem
space and a proposed optimization approach. Business Research, 13(3), 1231–
1251. https://doi.org/10.1007/s40685-020-00129-7.
Arridge, S., Maass, P., Öktem, O., & Schönlieb, C.-B. (2019). Solving inverse
problems using data-driven models. Acta Numerica, 28, 1–174.
https://doi.org/10.1017/S0962492919000059.
Asaad, S. M., Potrus, M. Y., Ghafoor, K. Z., Maghdid, H. S., & Mulahuwaish, A.
(2022). Improving positioning accuracy using optimization approaches: a
survey, research challenges and future perspectives. Wireless Personal
Communications, 122(4), 3393–3409. https://doi.org/10.1007/s11277-021-
09090-y.
Asana, T. (2022). Data-Driven Decision Making: A Step-By-Step Guide. Asana
Team. https://asana.com/resources/data-driven-decision-making
Ayyarao, T. S., Ramakrishna, N., Elavarasan, R. M., Polumahanthi, N., Rambabu,
M., Saini, G., Khan, B., & Alatas, B. (2022). War strategy optimization
algorithm: a new effective metaheuristic algorithm for global optimization.
IEEE Access, 10, 25073–25105.
Aziz-Alaoui, A., Doerr, C., & Dreo, J. (2021). Towards large scale automated
algorithm design by integrating modular benchmarking frameworks.
Proceedings of the Genetic and Evolutionary Computation Conference
Companion.
Baardman, L., Cristian, R., Perakis, G., Singhvi, D., Skali Lami, O., &
Thayaparan, L. (2023). The role of optimization in some recent advances in
data-driven decision-making. Mathematical Programming, 200(1), 1–35.
https://doi.org/10.1007/s10107-022-01874-9.
Bakker, M., Valdés, H. R., D Tu, P., Gummadi, K. P., Varshney, K. R., Weller, A.,
& Pentland, A. S. (2020). Fair enough: improving fairness in budget￾constrained decision making using confidence thresholds.
Beiranvand, V., Hare, W., & Lucet, Y. (2017). Best practices for comparing
optimization algorithms. Optimization and Engineering, 18(4), 815–848.
https://doi.org/10.1007/s11081-017-9366-1.
Belenguer, L. (2022). AI bias: exploring discriminatory algorithmic decision￾making models and the application of possible machine-centric solutions
adapted from the pharmaceutical industry. AI and Ethics, 2(4), 771–787.
https://doi.org/10.1007/s43681-022-00138-8.Belhaiza, S., M’Hallah, R., Ben Brahim, G., & Laporte, G. (2019). Three multi￾start data-driven evolutionary heuristics for the vehicle routing problem with
multiple time windows. Journal of Heuristics, 25(3), 485–515.
https://doi.org/10.1007/s10732-019-09412-1.
Bertsimas, D., & Thiele, A. (2006). Robust and Data-Driven Optimization:
Modern Decision Making Under Uncertainty. In Models, Methods, and
Applications for Innovative Decision Making (pp. 95–122). INFORMS.
https://doi.org/10.1287/educ.1063.0022.
Bezerra, L. C., & Manuel, L. (2020). Automatically designing state-of-the-art
multi-and many-objective evolutionary algorithms. Evolutionary
Computation, 28(2), 195–226.
Bibri, S. E. (2021). Data-driven smart sustainable cities of the future: urban
computing and intelligence for strategic, short-term, and joined-up planning.
Computational Urban Science, 1(1), 8. https://doi.org/10.1007/s43762-021-
00008-9.
Bornet, P. (2022). Is Decision Intelligence the New AI?
https://www.forbes.com/sites/forbestechcouncil/2022/05/25/is-decision￾intelligence-the-new-ai/?sh=3dcac9594e42.
Brownlee, J. (2021). How to Choose an Optimization Algorithm.
https://machinelearningmastery.com/tour-of-optimization-algorithms/.
Buijsse, R., Willemsen, M., & Snijders, C. (2023). Data-Driven Decision￾Making. In W. Liebregts, W.- J. van den Heuvel, & A. van den Born (Eds. ),
Data Science for Entrepreneurship: Principles and Methods for Data
Engineering, Analytics, Entrepreneurship, and the Society (pp. 239–277).
Springer International Publishing. https://doi.org/10.1007/978-3-031-19554-
9_11.
Canonico, P., De Nito, E., Esposito, V., Fattoruso, G., Pezzillo Iacono, M., &
Mangia, G. (2022). Visualizing knowledge for decision-making in Lean
Production Development settings. Insights from the automotive industry.
Management Decision, 60(4), 1076–1094. https://doi.org/10.1108/MD-01-
2021-0144.
Cao, G. (2017). Gaussian process based model predictive control: a thesis
submitted in partial fulfillment of the requirements for the degree of Doctor of
Philosophy in Engineering, School of Engineering and Advanced Technology,
Massey University, New Zealand.
Case, B., & Lehre, P. K. (2020). Self-adaptation in nonelitist evolutionary
algorithms on discrete problems with unknown structure. IEEE Transactions
on Evolutionary Computation, 24(4), 650–663.
Ceschi, A., Demerouti, E., Sartori, R., & Weller, J. (2017). Decision-making
processes in the workplace: how exhaustion, lack of resources and jobdemands impair them and affect performance [Original Research]. Frontiers
in Psychology, 8. https://doi.org/10.3389/fpsyg.2017.00313.
Chaudhary, S. (2023). Applications of Genetic Algorithms in Machine Learning.
https://www.turing.com/kb/genetic-algorithm-applications-in-ml.
CHE Jingshang, SUN Hailong, XIAO Chenjie, LI Aimei. (2019). Why
information overload damages decisions? An explanation based on limited
cognitive resources. Advances in Psychological Science, 27(10), 1758–1768.
https://doi.org/10.3724/sp.J.1042.2019.01758
Chen, J. (2023). Heuristics. https://www.investopedia.com/terms/h/heuristics.asp.
Çıtak, E. (2023). Elevating Business Decisions from Gut Feelings to Data- Driven
Excellence. https://dataconomy.com/2023/06/13/decision-intelligence￾difference-from-ai/.
Coello, C. A. C., Pulido, G. T., & Lechuga, M. S. (2004). Handling multiple
objectives with particle swarm optimization. IEEE Transactions on
Evolutionary Computation, 8(3), 256–279.
Colson, E. (2019). What AI-Driven Decision Making Looks Like.
https://hbr.org/2019/07/what-ai-driven-decision-making-looks-like.
De Loera, J. A., Haddock, J., Ma, A., & Needell, D. (2021). Data-driven
algorithm selection and tuning in optimization and signal processing. Annals
of Mathematics and Artificial Intelligence, 89(7), 711–735.
https://doi.org/10.1007/s10472-020-09717-z.
Deniz, N., & Ozceylan, E. (2023). A bibliometric and social network analysis of
data-driven heuristic methods for logistics problems. Journal of Industrial and
Management Optimization, 19(8), 5671–5689.
Deshmukh, R. K., & Kubal, M. (2020). An Overview of Machine Learning
Algorithms for Data Science.
Dewantoro, R. W., Sihombing, P., & Sutarman. (2019). The Combination of Ant
Colony Optimization (ACO) and Tabu Search (TS) Algorithm to Solve the
Traveling Salesman Problem (TSP). 2019 3rd International Conference on
Electrical, Telecommunication and Computer Engineering (ELTICOM), pp.
160–164.
Dilmegani, C. (2023). Decision Intelligence: In-Depth Guide for Businesses in
2023. https://research.aimultiple.com/decision-intelligence/
Doerr, B., & Neumann, F. (2021). A survey on recent progress in the theory of
evolutionary algorithms for discrete optimization. ACM Transactions on
Evolutionary Learning and Optimization, 1(4), 1–43.
dos Santos Gonçalves, P. V., & Campos, L. M. S. (2022). A systemic review for
measuring circular economy with multi-criteria methods. EnvironmentalScience and Pollution Research, 29(21), 31597–31611.
https://doi.org/10.1007/s11356-022-18580-w.
DriveResearch. (2023). What Is Data-Driven Decision Making? (And Why It’s so
Important). Retrieved 27 March 2023 from
https://www.driveresearch.com/market-research-company-blog/data-driven￾decision-making-ddm/.
Elbanna, S., & Fadol, Y. (2016). The role of context in intuitive decision-making.
Journal of Management & Organization, 22(5), 642–661.
https://doi.org/10.1017/jmo.2015.63.
Ezugwu, A. E., Shukla, A. K., Nath, R., Akinyelu, A. A., Agushaka, J. O.,
Chiroma, H., & Muhuri, P. K. (2021). Metaheuristics: a comprehensive
overview and classification along with bibliometric analysis. Artificial
Intelligence Review, 54(6), 4237–4316. https://doi.org/10.1007/s10462-020-
09952-0.
Fan, C., Bo, H., Qu, X., Xiao, L., & Cheng, F. (2021). Data-driven optimization
algorithm for economic operation of microgrid based on dynamic Kriging
model and two-stage search strategy.
Felländer, A., Rebane, J., Larsson, S., Wiggberg, M., & Heintz, F. (2022).
Achieving a data-driven risk assessment methodology for ethical AI. Digital
Society, 1(2), 13. https://doi.org/10.1007/s44206-022-00016-0.
Frimodig, B. (2023). Heuristics: Definition, Examples, and How They Work.
https://www.simplypsychology.org/what-is-a-heuristic.html
Gao, G., Kerr, M. J., Lindquist, R. A., Chi, C.-L., Mathiason, M. A., Austin, R.
R., & Monsen, K. A. (2018). A strengths-based data capture model: mining
data-driven and person-centered health assets. JAMIA Open, 1(1), 11–14.
Garcia, L. D., Lozoya, C., Favela-Contreras, A., & Giorgi, E. (2023). A
comparative analysis between heuristic and data-driven water management
control for precision agriculture irrigation. Sustainability, 15(14), 11337.
Goyal, P., & Benner, P. (2021). LQResNet: a deep neural network architecture for
learning dynamic processes. arXiv preprint arXiv:2103.02249.
Guilmeau, T., Chouzenoux, E., & Elvira, V. (2021, 11–14 July 2021). Simulated
annealing: a review and a new scheme. 2021 IEEE Statistical Signal
Processing Workshop (SSP).
Gunjan, A., & Bhattacharyya, S. (2023). A brief review of portfolio optimization
techniques. Artificial Intelligence Review, 56(5), 3847–3886.
https://doi.org/10.1007/s10462-022-10273-7.
Guo, X., Stein, B. V., & Bäck, T. (2019, 6–9 December 2019). A New Approach
Towards the Combined Algorithm Selection and Hyper-parameterOptimization Problem. 2019 IEEE Symposium Series on Computational
Intelligence (SSCI).
Guo, Z., Moayedi, H., Foong, L. K., & Bahiraei, M. (2020). Optimal modification
of heating, ventilation, and air conditioning system performances in
residential buildings using the integration of metaheuristic optimization and
neural computing. Energy and Buildings, 214, 109866.
Gupta, S., Modgil, S., Bhattacharyya, S., & Bose, I. (2022). Artificial intelligence
for decision support systems in the field of operations research: review and
future scope of research. Annals of Operations Research, 308(1), 215–274.
https://doi.org/10.1007/s10479-020-03856-6.
Hakanen, J., & Allmendinger, R. (2021). Multiobjective optimization and
decision making in engineering sciences. Optimization and Engineering,
22(2), 1031–1037. https://doi.org/10.1007/s11081-021-09627-x.
Harifi, S. (2020). Ancient-inspired: a novel source of inspiration for development
of metaheuristic algorithms. https://doi.org/10.13140/RG.2.2.19760.38408.
Harifi, S., Mohammadzadeh, J., Khalilian, M., & Ebrahimnejad, S. (2021). Giza
pyramids construction: an ancient-inspired metaheuristic algorithm for
optimization. Evolutionary Intelligence, 14(4), 1743–1761.
https://doi.org/10.1007/s12065-020-00451-3.
He, C., Tian, Y., Wang, H., & Jin, Y. (2020). A repository of real-world datasets
for data-driven evolutionary multiobjective optimization. Complex &
Intelligent Systems, 6, 189–197.
Heße, F., Müller, S., & Attinger, S. (2023). Data-driven estimates for the
geostatistical characterization of subsurface hydraulic properties. Hydrology
and Earth System Sciences Discussions, 2023, 1–31.
https://doi.org/10.5194/hess-2023-15.
Heuristic Method. https://www.javatpoint.com/heuristic-method.
Höchtl, J., Parycek, P., & Schöllhammer, R. (2016). Big data in the policy cycle:
policy decision making in the digital era. Journal of Organizational
Computing and Electronic Commerce, 26(1–2), 147–169.
https://doi.org/10.1080/10919392.2015.1125187.
Hudson, B., Li, Q., Malencia, M., & Prorok, A. (2021). Graph neural network
guided local search for the traveling salesperson problem. arXiv preprint
arXiv:2110.05291.
Huele, C. V. (2022). Predicting the Best Algorithm Using Machine Learning.
https://www.solvice.io/post/machine-learning-for-algorithm-selection-predict￾the-optimal-algorithm.
Hussain, D. M., & Surendran, D. (2022). Retraction note: content based image
retrieval using bees algorithm and simulated annealing approach in medicalbig data applications. Multimedia Tools and Applications, 82, 12739.
Ibrahim, M. H., Ang, S. P., Dani, M. N., Rahman, M. I., Petra, R., & Sulthan, S.
M. (2023). Optimizing step-size of perturb & observe and incremental
conductance MPPT techniques using PSO for grid-tied PV system. IEEE
Access, 11, 13079–13090.
Jiang, J. (2017). Enabling Data-Driven Optimization of Quality of Experience for
Internet Applications.
Jin, Y., Wang, H., Chugh, T., Guo, D., & Miettinen, K. (2018). Data-driven
evolutionary optimization: an overview and case studies. IEEE Transactions
on Evolutionary Computation, 23(3), 442–458.
Jin, Y., Wang, H., & Sun, C. (2021). Data-Driven Evolutionary Optimization.
Springer.
Joshi, P. (2021). Handling Data Scarcity while building Machine Learning
applications. https://towardsdatascience.com/handling-data-scarcity-while￾building-machine-learning-applications-e6c243b284b0.
Juan, A. A., Keenan, P., Martí, R., McGarraghy, S., Panadero, J., Carroll, P., &
Oliva, D. (2023). A review of the role of heuristics in stochastic optimisation:
from metaheuristics to learnheuristics. Annals of Operations Research, 320(2),
831–861. https://doi.org/10.1007/s10479-021-04142-9.
Juillet, R. (2023). How to Make Smart Decisions Using AI and Data.
https://www.bocasay.com/how-to-make-smart-decisions-using-ai-and-data/.
Kahraman, C. (2008). Multi-Criteria Decision Making Methods and Fuzzy Sets.
In C. Kahraman (Ed. ), Fuzzy Multi-Criteria Decision Making: Theory and
Applications with Recent Developments (pp. 1–18). Springer US.
https://doi.org/10.1007/978-0-387-76813-7_1.
Kaspi, S., & Venkatraman, S. (2023). Data-Driven Decision-Making (DDDM) for
higher education assessments: a case study. Systems, 11(6).
Katoch, S., Chauhan, S. S., & Kumar, V. (2021). A review on genetic algorithm:
past, present, and future. Multimedia Tools and Applications, 80(5), 8091–
8126. https://doi.org/10.1007/s11042-020-10139-6.
Katsaliaki, K., Galetsi, P., & Kumar, S. (2022). Supply chain disruptions and
resilience: a major review and future research agenda. Annals of Operations
Research, 319(1), 965–1002. https://doi.org/10.1007/s10479-020-03912-1.
Keith, A. J., & Ahner, D. K. (2021). A survey of decision making and
optimization under uncertainty. Annals of Operations Research, 300(2), 319–
353. https://doi.org/10.1007/s10479-019-03431-8.
Khan, M., Ullah, Z., Mašek, O., Naqvi, S. R., & Khan, M. N. A. (2022). Artificial
neural networks for the prediction of biochar yield: a comparative study of
metaheuristic algorithms. Bioresource Technology, 355, 127215.Khan, S. (2018). Ant Colony Optimization (ACO) based data hiding in image
complex region. International Journal of Electrical and Computer
Engineering, 8, 379–389.
Khan, U. A., Bajwa, W. U., Nedić, A., Rabbat, M. G., & Sayed, A. H. (2020).
Optimization for data-driven learning and control. Proceedings of the IEEE,
108(11), 1863–1868. https://doi.org/10.1109/JPROC.2020.3031225.
Kim, Y. J., Kim, Y. K., & Cho, Y. (1998). A heuristic-based genetic algorithm for
workload smoothing in assembly lines. Computers & Operations Research,
25(2), 99–111.
Klie, H. (2021). A Tale of Two Approaches: Physics-Based vs. Data-Driven
Models. https://jpt.spe.org/a-tale-of-two-approaches-physics-based-vs-data￾driven-models.
Kozyrkov, C. (2019). Introduction to Decision Intelligence.
https://towardsdatascience.com/introduction-to-decision-intelligence￾5d147ddab767.
Krishen, A. S., & Petrescu, M. (2019). Data-driven decision making:
implementing analytics to transform academic culture. Journal of Marketing
Analytics, 7(2), 51–53. https://doi.org/10.1057/s41270-019-00056-5.
Kurian, J., Dix, M., Amihai, I., Ceusters, G., & Prabhune, A. (2021). BOAT: A
Bayesian Optimization AutoML Time-series Framework for Industrial
Applications. 2021 IEEE Seventh International Conference on Big Data
Computing Service and Applications (BigDataService), pp. 17–24.
Kurtuluş, E., Yıldız, A. R., Sait, S. M., & Bureerat, S. (2020). A novel hybrid
Harris hawks-simulated annealing algorithm and RBF-based metamodel for
design optimization of highway guardrails. Materials Testing, 62, 251–260.
Lemos, A. R. (2022). Genetic Algorithm and Its Practicality in Machine Learning.
https://towardsdatascience.com/genetic-algorithm-6aefd897f1ac
Levinthal, D. A., & Newark, D. A. (2023). Putting the individual in the
organizational context: a carnegie perspective on decision making. Frontiers
in Psychology, 14, 1165713.
Li, J., Xiao, X., Boukouvala, F., Floudas, C. A., Zhao, B., Du, G., Su, X., & Liu,
H. (2016). Data‐driven mathematical modeling and global optimization
framework for entire petrochemical planning operations. AIChE Journal,
62(9), 3020–3040.
Li, S., Xia, Y., & Xu, Z. (2023). Simultaneous perturbation stochastic
approximation: towards one-measurement per iteration. Numerical
Algorithms. https://doi.org/10.1007/s11075-023-01528-7
Liao, X., Shi, J., Li, Z., Zhang, L., & Xia, B. (2020). A model-driven deep
reinforcement learning heuristic algorithm for resource allocation in ultra-dense cellular networks. IEEE Transactions on Vehicular Technology, 69(1),
983–997. https://doi.org/10.1109/TVT.2019.2954538.
Lim, S., Henriksson, A., & Zdravkovic, J. (2021). Data-driven requirements
elicitation: a systematic literature review. SN Computer Science, 2(1), 16.
https://doi.org/10.1007/s42979-020-00416-4.
Liu, X., Zhang, X., Cui, Q., & Li, W. (2017, 26–28 May 2017). Implementation
of Ant Colony Optimization Combined with Tabu Search for Multi-resource
Fair Allocation in Heterogeneous Cloud Computing. 2017 IEEE 3rd
International Conference on Big Data Security on Cloud (bigdatasecurity),
IEEE International Conference on High Performance and Smart Computing
(HPSC), and IEEE International Conference on Intelligent Data and Security
(IDS).
LLC, C. T. (2021). The Application of Data-Driven Algorithms in Machine
Learning. https://www.iotforall.com/application-of-data-driven-algorithms-in￾machine-learning-ml.
Luo, J. (2023). Data-driven innovation: what is it? IEEE Transactions on
Engineering Management, 70(2), 784–790.
https://doi.org/10.1109/TEM.2022.3145231.
Lyu, S. (2022). Data-Driven Optimization Approaches to the Power System
Planning under Uncertainty. arXiv preprint arXiv:2212.01659.
Ma, Z., Wu, G., Suganthan, P. N., Song, A., & Luo, Q. (2023). Performance
assessment and exhaustive listing of 500+ nature-inspired metaheuristic
algorithms. Swarm and Evolutionary Computation, 77, 101248.
Mahadeen, T., Galanakis, K., Samara, E., & Kilintzis, P. (2021). Heuristics and
Evidences Decision (HeED) making: a case study in a systemic model for
transforming decision making from heuristics-based to evidenced-based.
Journal of the Knowledge Economy, 12(4), 1668–1693.
https://doi.org/10.1007/s13132-020-00688-4.
Malak, H. A. (2023). 10 Information Management Challenges and Solutions for
2023. https://theecmconsultant.com/information-management-challenges/.
Mallaiah, M., Rama Rao, K., & Venkateswarlu, C. (2021). A simulated annealing
optimization algorithm based nonlinear model predictive control strategy with
application. Evolving Systems, 12(1), 225–231.
https://doi.org/10.1007/s12530-020-09354-1.
Mallawaarachchi, V. (2017). Introduction to Genetic Algorithms—Including
Example Code. https://towardsdatascience.com/introduction-to-genetic￾algorithms-including-example-code-e396e98d8bf3.
Mangla, P., & Goyal, S. K. (2017). Heuristic vs meta-heuristic approaches for
load balancing in cloud environment. International Journal of Computer &Mathematical Sciences, 6(4), 297–301.
Martí, R., & Reinelt, G. (2022). Heuristic Methods. In Exact and Heuristic
Methods in Combinatorial Optimization: A Study on the Linear Ordering and
the Maximum Diversity Problem (pp. 27–57). Springer, Berlin Heidelberg.
https://doi.org/10.1007/978-3-662-64877-3_2
Martins, A. F., Machado, M., Bernardino, H. S., & de Souza, J. F. (2021). A
comparative analysis of metaheuristics applied to adaptive curriculum
sequencing. Soft Computing, 25(16), 11019–11034.
https://doi.org/10.1007/s00500-021-05836-9.
McClean, T. (2021). The Collective Power of Swarm Intelligence in AI and
Robotics. https://www.forbes.com/sites/forbestechcouncil/2021/05/13/the￾collective-power-of-swarm-intelligence-in-ai-and-robotics/.
Mehta, S., & Kaur, P. (2019). Scheduling Data Intensive Scientific Workflows in
Cloud Environment Using Nature Inspired Algorithms. In Nature-Inspired
Algorithms for Big Data Frameworks.
Michaloglou, A., & Tsitsas, N. L. (2021). Particle Swarm Optimization
Algorithms with Applications to Wave Scattering Problems. Swarm
Intelligence [Working Title].
Mohajerin Esfahani, P., & Kuhn, D. (2018). Data-driven distributionally robust
optimization using the Wasserstein metric: performance guarantees and
tractable reformulations. Mathematical Programming, 171(1), 115–166.
https://doi.org/10.1007/s10107-017-1172-1.
Monakhov, O., & Monakhova, E. (2021). Comparative Evaluation of Algorithms
for Automatic Construction of Nonlinear Models Based on Metaheuristic
Programming with Gene Expression. In CEUR Workshop Proceedings, 2021,
pp. 254–259.
Moore, J. S. (2020). ACL2 Induction Heuristics.
Morelli, M., Casagrande, M., & Forte, G. (2022). Decision making: a theoretical
review. Integrative Psychological and Behavioral Science, 56(3), 609–629.
https://doi.org/10.1007/s12124-021-09669-x.
Moumtzidis, I., Kamariotou, M., & Kitsios, F. (2022). Digital transformation
strategies enabled by internet of things and big data analytics: the use-case of
telecommunication companies in Greece. Information, 13(4), 196.
https://www.mdpi.com/2078-2489/13/4/196.
Multiobjective Optimization Interactive and Evolutionary Approaches Lecture
Notes in Computer Science Theoretical Computer Science and General Issues.
(2022).
Nesmachnow, S. (2015). Using Metaheuristics as Soft Computing Techniques for
Efficient Optimization.Nguyen, L. T. K., Aydin, R. C., & Cyron, C. J. (2022). Accelerating the distance￾minimizing method for data-driven elasticity with adaptive hyperparameters.
Computational Mechanics, 70, 621–638.
Ordonez, L., & Benson III, L. (1997). Decisions under time pressure: how time
constraint affects risky decision making. Organizational Behavior and Human
Decision Processes, 71(2), 121–140.
Pandey, D. V. (2023). Heuristic Algorithms for Real-World Applications: Success
Stories and Future Directions. https://www.linkedin.com/pulse/heuristic￾algorithms-real-world-applications-success-stories-pandey.
Pech-Rodríguez, W. J., Suarez-Velázquez, G. G., Armendáriz-Mireles, E. N.,
Calles-Arriaga, C. A., & Rocha-Rangel, E. (2023). Performance Assessment
of Heuristic Genetic Algorithm (HGA) for electrochemical impedance
spectroscopy parameter estimation. Axioms, 12(1), 84.
Phillips, T., Lenhart, S., & Strickland, W. C. (2021). A data-driven mathematical
model of the heroin and fentanyl epidemic in Tennessee. Bulletin of
Mathematical Biology, 83(10), 97.
Pourkhodabakhsh, N., Mamoudan, M. M., & Bozorgi-Amiri, A. (2023). Effective
machine learning, Meta-heuristic algorithms and multi-criteria decision
making to minimizing human resource turnover. Applied Intelligence, 53(12),
16309–16331. https://doi.org/10.1007/s10489-022-04294-6.
Prawira, H. A., & Santosa, B. (2021). Development of Particle Swarm
Optimization and Simulated Annealing Algorithms to Solve Vehicle Routing
Problems with Drones. PROZIMA (Productivity, Optimization and
Manufacturing System Engineering).
Prudencio, R. F., Maximo, M. R., & Colombini, E. L. (2023). A survey on offline
reinforcement learning: taxonomy, review, and open problems. IEEE
Transactions on Neural Networks and Learning Systems.
Puentes, L., Cagan, J., & McComb, C. (2020a). Automated heuristic induction
from human design data. International Design Engineering Technical
Conferences and Computers and Information in Engineering Conference.
Puentes, L., Cagan, J., & McComb, C. (2020b). Data-driven heuristic induction
from human design behavior. Journal of Computing and Information Science
in Engineering, 21(2). https://doi.org/10.1115/1.4048425
Puentes, L., Cagan, J., & McComb, C. (2021). Data-driven heuristic induction
from human design behavior. Journal of Computing and Information Science
in Engineering, 21(2), 024501.
Rai, R., Das, A., Ray, S., & Dhal, K. G. (2022). Human-inspired optimization
algorithms: theoretical foundations, algorithms, open-research issues and
application for multi-level thresholding. Archives of Computational Methodsin Engineering, 29(7), 5313–5352. https://doi.org/10.1007/s11831-022-09766-
z.
Ramírez-Ochoa, D.-D., Dominguez, L. A. P., Martinez-Gomez, E. A., & Cruz, D.
L. (2022). PSO, a swarm intelligence-based evolutionary algorithm as a
decision-making strategy: a review. Symmetry, 14, 455.
Rao, K., Harris, C., Irpan, A., Levine, S., Ibarz, J., & Khansari M. (2020). Rl￾Cyclegan: Reinforcement Learning Aware Simulation-To-Real. Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
pp. 11157–11166.
Rezaeipanah, A., Sarhangnia, F., & Abdollahi, M. J. (2021). Meta-heuristic
approach based on genetic and greedy algorithms to solve flexible job-shop
scheduling problem. Computer Science, 22.
Rishi Gupta, T. R. (2020). Data-Driven Algorithm Design.
https://cacm.acm.org/magazines/2020/6/245164-data-driven-algorithm￾design/abstract.
Ross, M., & Taylor, J. (2021). Managing AI Decision-Making Tools.
https://hbr.org/2021/11/managing-ai-decision-making-tools.
Rothwell, A. (2017). Optimization With Finite Element Analysis. In A. Rothwell
(Ed. ), Optimization Methods in Structural Design (pp. 283–296). Springer
International Publishing. https://doi.org/10.1007/978-3-319-55197-5_9.
Saeid, S., Maghsoud, A., & Farzaneh Mansoori, M. (2021). Artificial Intelligence
and Its Application in Optimization under Uncertainty. In T. Ciza (Ed. ), Data
Mining (pp. Ch. 8). IntechOpen. https://doi.org/10.5772/intechopen.98628.
Saltz, J. S., & Dewar, N. (2019). Data science ethical considerations: a systematic
literature review and proposed project framework. Ethics and Information
Technology, 21(3), 197–208. https://doi.org/10.1007/s10676-019-09502-5.
Santos, R. G., Plastino, A., & Oliveira, A. C. M. d. (2022, 18–23 July 2022).
DMC-GRASP: A Continuous GRASP hybridized with Data Mining. 2022
IEEE Congress on Evolutionary Computation (CEC).
Sarker, I. H. (2021). Data science and analytics: an overview from data-driven
smart computing, decision-making and applications perspective. SN Computer
Science, 2(5), 377. https://doi.org/10.1007/s42979-021-00765-8.
Sassi, I., Anter, S., & Bekkhoucha, A. (2021). A graph-based big data
optimization approach using hidden Markov model and constraint satisfaction
problem. Journal of Big Data, 8(1), 93. https://doi.org/10.1186/s40537-021-
00485-z.
Schrittwieser, J., Hubert, T., Mandhane, A., Barekatain, M., Antonoglou, I., &
Silver, D. (2021). Online and offline reinforcement learning by planning witha learned model. Advances in Neural Information Processing Systems, 34,
27580–27591.
Schwenzer, M., Ay, M., Bergs, T., & Abel, D. (2021). Review on model predictive
control: an engineering perspective. The International Journal of Advanced
Manufacturing Technology, 117(5), 1327–1349.
https://doi.org/10.1007/s00170-021-07682-3
Seifi, F., Azizi, M. J., & Niaki, S. T. A. (2021). A data-driven robust optimization
algorithm for black-box cases: an application to hyper-parameter optimization
of machine learning algorithms. Computers & Industrial Engineering, 160,
107581.
Sezer, H. B., & Namukasa, I. K. (2021). Real-world problems through
computational thinking tools and concepts: the case of coronavirus disease
(COVID-19). Journal of Research in Innovative Teaching & Learning, 14(1),
46–64. https://doi.org/10.1108/JRIT-12-2020-0085
Sharma, V., & Tripathi, A. K. (2022). A systematic review of meta-heuristic
algorithms in IoT based application. Array, 14, 100164.
Shi, Y., & Eberhart, R. C. (1999). Empirical study of particle swarm optimization.
Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat.
No. 99TH8406), 3, 1945–1950, vol. 1943.
Shukla, K., Xu, M., Trask, N., & Karniadakis, G. E. (2022). Scalable algorithms
for physics-informed neural and graph networks. Data-Centric Engineering,
3, e24. https://doi.org/10.1017/dce.2022.24.
Soma, T., Gatmiry, K., & Jegelka, S. (2022). Optimal algorithms for group
distributionally robust optimization and beyond. arXiv preprint
arXiv:2212.13669.
Song, Y.-J., Zhang, Z.-S., Sun, K., Yao, F., & Chen, Y.-W. (2019). A heuristic
genetic algorithm for regional targets’ small satellite image downlink
scheduling problem. International Journal of Aerospace Engineering, 2019.
Song, Z., Song, S., Zhang, B., Qian, J., Tang, C., & Ji, J. (2021). An Adaptive
Scaling Cuckoo Search Algorithm. 2021 4th International Conference on
Advanced Electronic Materials, Computers and Software Engineering
(AEMCSE), pp. 562–566.
Sootla, A., Cowen-Rivers, A. I., Jafferjee, T., Wang, Z., Mguni, D. H., Wang, J.,
& Ammar, H. (2022). Sauté rl: almost surely safe reinforcement learning
using state augmentation. International Conference on Machine Learning,
2022: PMLR, pp. 20423–20443.
Spaulding, N. W. (2020). 375Is Human Judgment Necessary?: Artificial
Intelligence, Algorithmic Governance, and the Law. In The Oxford Handbookof Ethics of AI (pp. 0). Oxford University Press.
https://doi.org/10.1093/oxfordhb/9780190067397.013.25.
Spirov, A. V., & Myasnikova, E. M. (2022). Heuristic algorithms in evolutionary
computation and modular organization of biological macromolecules:
applications to in vitro evolution. PLOS ONE, 17(1), e0260497.
https://doi.org/10.1371/journal.pone.0260497.
Stańczyk, U., & Zielosko, B. (2020). Heuristic-based feature selection for rough
set approach. International Journal of Approximate Reasoning, 125, 187–202.
Sun, F. (2018). Algorithms for Context-Sensitive Prediction, Optimization and
Anomaly Detection in Urban Mobility.
Tang, J., Liu, G., & Pan, Q. (2021). A review on representative swarm
intelligence algorithms for solving optimization problems: applications and
trends. IEEE/CAA Journal of Automatica Sinica, 8, 1627–1643.
Taşkın, Z. C. (2022). Optimization vs. Heuristics: Which Is the Right Approach
for Your Business? https://www.icrontech.com/blog_item/optimization-vs￾heuristics-which-is-the-right-approach-for-your-business.
Thomas, J. I. (2022). The principle of mathematical induction: applications in
physical optics. Journal of Applied Mathematics, 2022, 3618642.
https://doi.org/10.1155/2022/3618642.
Tirkolaee, E. B., Sadeghi, S., Mooseloo, F. M., Vandchali, H. R., & Aeini, S.
(2021). Application of machine learning in supply chain management: a
comprehensive overview of the main areas. Mathematical Problems in
Engineering, 2021, 1476043. https://doi.org/10.1155/2021/1476043.
Tran, V. P., Garratt, M. A., Kasmarik, K., Anavatti, S. G., & Abpeikar, S. (2022).
Frontier-led swarming: robust multi-robot coverage of unknown
environments. Swarm and Evolutionary Computation, 75, 101171.
Tuba, M. (2014). Multilevel image thresholding by nature-inspired algorithms: a
short review. Computer Science Journal of Moldova, 66(3), 318–338.
Ullah, I., & Youn, H. Y. (2020). Intelligent data fusion for smart IoT environment:
a survey. Wireless Personal Communications, 114(1), 409–430.
https://doi.org/10.1007/s11277-020-07369-0.
van der Schelling, M. (2021). A data-driven heuristic decision strategy for data￾scarce optimization: with an application towards bio-based composites.
Varga, D. (2022). Full-reference image quality assessment based on an optimal
linear combination of quality measures selected by simulated annealing.
Journal of Imaging, 8(8), 224.
Verma, P., & Parouha, R. P. (2021). An advanced hybrid meta-heuristic algorithm
for solving small- and large-scale engineering design optimization problems.Journal of Electrical Systems and Information Technology, 8(1), 10.
https://doi.org/10.1186/s43067-021-00032-z.
Vinod Chandra, S. S., & Anand, H. S. (2022). Nature inspired meta heuristic
algorithms for optimization problems. Computing, 104(2), 251–269.
Wagner, R., & Cozmiuc, D. (2022). Extended reality in marketing—a multiple
case study on internet of things platforms. Information, 13(6).
Wang, H., Gao, L., Yang, G., & Wu, B. (2023a). A data-driven robust design
optimization method and its application in compressor blade. Physics of
Fluids, 35(6). https://doi.org/10.1063/5.0150040.
Wang, H., Liang, M., Sun, C., Zhang, G., & Xie, L. (2021). Multiple-strategy
learning particle swarm optimization for large-scale optimization problems.
Complex & Intelligent Systems, 7(1), 1–16. https://doi.org/10.1007/s40747-
020-00148-1.
Wang, N., Wang, H., Pei, S., & Zhang, B. (2023b). A data-driven heuristic
method for irregular flight recovery. Mathematics, 11(11), 2577.
Whelehan, D. F., Conlon, K. C., & Ridgway, P. F. (2020). Medicine and
heuristics: cognitive biases and medical decision-making. Irish Journal of
Medical Science, 189(4), 1477–1484. https://doi.org/10.1007/s11845-020-
02235-1.
Winsberg, E. (2003). Simulated experiments: methodology for a virtual world.
Philosophy of Science, 70(1), 105–125. https://doi.org/10.1086/367872.
Wirtz, B. W. (2022). Artificial Intelligence, Big Data, Cloud Computing, and
Internet of Things. In B. W. Wirtz (Ed. ), Digital Government: Strategy,
Government Models and Technology (pp. 175–245). Springer International
Publishing. https://doi.org/10.1007/978-3-031-13086-1_6.
Xu, J., Jin, Y., Du, W., & Gu, S. (2021). A federated data-driven evolutionary
algorithm. Knowledge-Based Systems, 233, 107532.
Yakubu, I. Z., & Murali, M. (2023). An efficient meta-heuristic resource
allocation with load balancing in IoT-Fog-cloud computing environment.
Journal of Ambient Intelligence and Humanized Computing, 14(3), 2981–
2992. https://doi.org/10.1007/s12652-023-04544-6.
Yang, B., Xu, X., Gong, Y., & Rekik, Y. (2023). Data-driven optimization models
for inventory and financing decisions in online retailing platforms. Annals of
Operations Research. https://doi.org/10.1007/s10479-023-05234-4.
Yang, Z., Zhang, F.-f., Xiao, Z., Shi, C., Wang, R., & Kong, X. (2022). A Machine
Learning based Closed-Loop Efficiency Optimization Strategy for Data￾Driven Optimization Methods. 2022 China Automation Congress (CAC), pp.
3215–3220.Ye, Y. (2014). Data-Driven Optimization. https://web.stanford.edu/~yyye/Data￾DrivenOPT.pdf.Chapter 7
Evaluation of factors affecting destination
selection in medical tourism with the
spherical fuzzy analytic hierarchy process
method
Bilal Saraç and Seher Gülenç
DOI: 10.1201/9781003536796-7
7.1 INTRODUCTION
Medical tourism stands out as one of the most important types of tourism,
considering its economic and social benefits (Ebrahimzadeh et al. 2013). Medical
tourism, which has a strategic importance especially for the country’s economies,
includes partnerships between two types of services: medicine and tourism
(Bookman and Bookman 2007). According to the Grand View Research report,
the size of the global medical tourism market, which was determined as 35.77
billion dollars in 2022, is estimated to reach 39.95 billion dollars in 2023 with an
annual growth rate of 11.7%. In addition, the report states that the two largest
regions in the medical tourism market in 2022 are North America and Western
Europe (Research and Markets 2024). However, it is predicted that the highest
growth in this sector will occur in the Asia-Pacific region. The most important
reason for this is the expectation that medical tourism movements will mainly
focus on developing countries, because developing countries see medical tourism
as a tool to increase their income and employment opportunities and offer higher
quality health services at lower costs than developed countries.
The first step of a medical tourist who decides to travel for medical purposes is
to choose a country. This choice depends primarily on the feasibility of therequired treatment, cost and technical competence. (Khan et al. 2016).
Additionally, the factors that are effective in the selection of medical tourism
destinations are generally listed as better technical equipment, demand for
experience, faster cure, less waiting time, lower cost, demand for expertise,
higher level of quality, more care and attention and confidentiality (Horowitz et
al. 2007; Ehrbeck et al. 2008; Ferrer and Medhekar 2012; Connell 2013;
Lajevardi 2016; Singh 2019). The existence of many alternatives in destination
selection makes the decision-making process difficult for medical tourists.
However, multi-criteria decision-making methods help medical tourists
rationalize the decision process. From this point of view, determining the
importance of the criteria affecting the selection of medical tourism destinations
is also important in terms of revealing the factors needed in the planning studies
of health institutions and organizations providing services for medical tourism,
tourism enterprises, non-governmental organizations and local governments.
There are many studies on medical tourism destinations, but there are still few
studies that focus on determining the importance of the criteria affecting the
selection of medical tourism destinations and include fuzzy methods in the
analysis. Spherical fuzzy sets (SFSs), one of the new approaches to examine
uncertainty in the decision process, emerged with the expansion of fuzzy set
theory. SFS provides a wider selection area for decision-makers and can also
describe decision-makers’ degree of indecision about an alternative according to a
criterion. Analytic hierarchy process (AHP) is frequently used in decision theory,
both in ranking alternatives and in determining the weights of criteria. Moreover,
the AHP method has been used in many studies by integrating with newly
emerging fuzzy set approaches (Yıldız et al. 2020; Ghorui et al. 2021; Ardil 2022;
Ilbahar et al. 2022). It can be seen that the AHP method has been used together
with SFS in many areas recently (Sharaf 2021; Nguyen 2022; Jawad et al. 2023).
In this regard, the aim of this study is to determine the importance of the criteria
affecting the selection of medical tourism destinations by using the spherical
fuzzy analytic hierarchy process (SFAHP).
7.2 MEDICAL TOURISM AND MEDICAL
TOURISM INDEX
In medical tourism, people travel to another country for treatment and are also
holidaymakers (Connell 2006). Medical tourists primarily aim to receive medical
treatment. They also carry out traditional tourism activities such as resting and
spending free time in touristic places (Caballero-Danell and Mugomba 2007).Based upon their purposes, these medical tourists can be defined in four
categories (Wongkit and McKercher 2013):
dedicated – have a pre-determined treatment plan and traveling mostly for
treatment,
hesitant – decide on the treatment options after arriving at the medical
tourism destination yet traveling primarily for treatment,
holidaying – have a pre-determined treatment plan, however, traveling
mostly for pleasure and
opportunistic – decide about the procedure after arrival and traveling
primarily for pleasure.
Medical tourists exhibit individual behavior in their decision-making processes.
Before deciding on the final destination, they evaluate many factors such as the
content of the products and services offered, the urgency of decision-making,
alternatives, the quality of the service at the destination and perceptions about the
destination (Nguyen 2016). When planning a medical tourism trip, the main
considerations for destination selection stand out as the availability of medical
treatments, financing opportunities, perceived quality, regional integration and
cultural factors (Mathijsen 2019).
Push and pull theory can be used to reveal the factors of travel motivation. The
theory, first used by Dann in 1977, states that the main reason why people travel
is because they have desires and needs to be satisfied, and their destination
selections are affected by this motivation to travel. In this regard, Smith and
Forgione (2007) developed a two-stage model explaining the factors affecting a
medical tourist’s decision to receive treatment abroad. The first stage of this
model consists of country factors such as economic conditions, political climate
and regulatory policies. The second stage of the model covers medical facility
factors such as costs, physician training, quality of care and accreditations. Based
on this model, it can be concluded that medical tourists make a destination
selection by taking into account both country and medical facility factors.
Bookman and Bookman (2007) determined the factors that play a role in health
tourism as geographical distance, cultural proximity, medical specialization and
recognition. Han and Hyun (2015) also proposed a model that includes the factors
affecting the medical tourism decision, taking into account the effects of quality,
trust, satisfaction and appropriate pricing in the destination country. Khan et al.
(2016) tried to develop a conceptual framework to determine the decision-making
process of a medical tourist, based on different models in the tourism literature. In
this model, it is stated that the risks associated with medical tourism, motivations
of medical tourism and destination image are related to the travel process ofmedical tourists. Fetscherin and Stephano (2016) developed the medical tourism
index (MTI), which is a more comprehensive approach in the model where they
bring together the push and pull factors in medical tourism. MTI measures a
country’s attractiveness as a medical tourism destination in terms of country
environment, tourism destination, medical tourism costs and medical facility and
services (Figure 7.1).
Figure 7.1 Medical tourism index dimensions. (Source: Fetscherin ve
Stephano 2016.)
The first dimension in MTI, which represents the attractiveness of a country as
a medical tourism destination, is country environment. This dimension focuses on
a country’s general image (Cham et al. 2021), its political and economic stability
(Smith et al. 2011), ease of travel (Cavmak and Cavmak 2020) and cultural and
linguistic similarities (Olya and Nia 2021). The second dimension of MTI is
tourism destination, where natural and cultural tourism attractions are defined
(Connell 2006; Heung et al. 2010). Medical tourism costs, the third dimension in
MTI, are considered among the basic elements of the medical tourism sector
(Bagga 2020; Zakaria et al. 2023). As a matter of fact, if the total expenses of the
medical tourism destination (treatment, travel, accommodation, etc.) are at a level
that can be covered by medical tourists, it can be an important incentive to
participate in medical tourism (Abd Mutalib et al. 2017). The fourth MTI
dimension that affects the behavior of medical tourists is medical facility and
services, which covers the quality of medical facilities (standards and reputation
of hospitals, international accreditation, state-of-the-art medical equipment andhealth care quality indicators) and services (expertise and qualifications of
doctors and nurses) (Ferrer and Medhekar 2012).
7.3 METHODOLOGY AND METHOD
It is understood from the literature that in studies on medical tourism, the
opinions of the decision-makers are often used to determine the importance of
evaluation criteria. While Yiğit and Demirbaş (2020) determined the factors
affecting Turkey’s medical tourism development, Görener (2016) identified the
factors that should be taken into account for the development of strategies related
to medical tourism, Najafinasab et al. (2020) benefited from the opinions of
decision-makers or experts while prioritizing strategies to develop medical
tourism in the Iranian Social Security Institution, and Ghasemi et al. (2021)
revealed sustainable medical tourism factors in Iran. In this study, the opinions of
the decision-makers group were consulted and the main and sub-criteria in the
medical tourism index (MTI) developed by Fetscherin and Stephano (2016) were
integrated into our method. The SFAHP method was also used to determine the
importance levels of these factors. The group of decision-makers whose opinions
were used in this study consists of a professor specialized in medical tourism, an
associate professor and a medical tourist.
In the SFAHP method used in the study, the number of sub-criteria in MTI was
reduced from 34 to 16 because making many pairwise comparisons creates
difficulties in terms of consistency, and some factors explain each other and
therefore create confusion during comparison. This decision was taken by the
decision-makers group with the idea that it better reflects the essence of medical
tourism destination selection.
7.3.1 Spherical fuzzy sets
After the introduction of ordinary fuzzy sets by Zadeh (1965), it gained
popularity in almost all branches of science, and many researchers developed
various extensions of fuzzy sets by examining uncertainty. These developments
are summarized in historical order in Figure 7.2. In recent years, these new
approaches have been frequently used in determining the importance of criteria
and in solving multi-criteria decision-making problems (ranking, classifying
alternatives, etc.).Figure 7.2 Extensions of fuzzy sets. (Source: Compiled by authors.)
Type-2 fuzzy sets (T2FS) were introduced by Zadeh (1975) as an extension of
the concept of ordinary fuzzy sets, called type-1 fuzzy sets. They are very useful
when it is difficult to determine the exact membership function for a fuzzy set
(Cheng et al. 2016; Chiao 2016). Intuitionistic fuzzy sets (IFS) were developed by
Atanassov (1986) and allow defining both membership and non-membership
degrees of an element in a fuzzy set (Wan et al. 2016; Jin et al. 2016). Hesitant
fuzzy sets (HFSs), these are fuzzy sets that force the membership degree of an
element to be possible values between zero and one, allow an element to be used
as a functional tool that allows many potential degrees of membership in a set
(Kutlu Gündoğdu et al. 2018; Wang and Xu 2016). Pythagorean fuzzy sets (PFS),
which are generalizations of IFS, are characterized by a degree of membership
and a degree of non-membership that meet the condition that the square sum of
the degree of membership and the degree of non-membership is equal to or less
than one (Liu et al. 2017). Neutrosophic sets (NSs) were developed by
Smarandache (1999) as an extension of IFSs. The NSs are defined as the set in
which each element of the universe has a certain degree of truth, uncertainty and
falsity (Smarandache 2003).
In this study, the SFAHP method, developed by Kutlu Gündoğdu and
Kahraman (2020) and one of the latest approaches in fuzzy set theory, was used
to determine the importance levels of the reasons for choosing a medical tourism
destination. Evaluating the factors that enable a country to be preferred as a
medical tourism destination requires the inclusion of various linguistic criteria in
the decision process. Numerical definitions of these criteria are realized by global
fuzzy sets, which bring a new perspective to decision-making under fuzziness.
Independent assignment of membership parameters to larger areas brings an
innovation to the evaluation process of choosing a medical tourism destination
(Kutlu Gündoğdu and Kahraman 2020).
7.3.2 Spherical fuzzy analytic hierarchy process (SFAHP)
SFS method, decision-makers define a membership function on a spherical
surface, and the parameters of this membership function are assigned
independently in a wider area. This allows the generalization of other extensions
of fuzzy sets (Kutlu Gündoğdu and Kahraman 2021). IFS and PFS membership
functions are composed of μ, v and π, membership, non-membership and
hesitancy parameters, respectively. Hesitancy parameters can be calculated by
π
I˜ = 1 − μI˜ − v
I˜
for IFS and π
P˜ = √1 − μ
2
P˜ − v
2
P˜
for PFS. Let A˜S be an SFS(7.1)
(7.2)
in the universe of discourse U and the numbers μA˜S
(u), vA˜S
(u) and πA˜S
(u) are
the degree of membership, non-membership and hesitancy of u toA˜S,
respectively, for each u. Accordingly, an SFS should provide the following
properties.
0 ≤ μA˜S
(u)
2 + vA˜S
(u)
2 + πA˜S
(u)
2 ≤ 1 for ∀u ∈ A˜S
When on the surface of the spherical, Eq. (7.1) becomes as follows:
μA˜S
(u)
2 + vA˜S
(u)
2 + πA˜S
(u)
2 = 1 for ∀u ∈ A˜S
In fuzzy set theory, it is criticized that the sum of μA˜S
(u), vA˜S
(u) and πA˜S
(u)
values of Neutrosophic Fuzzy Sets (NFS) is larger than 1 and PFS is disregarding
an independent hesitancy. The advantage of the SFS method is that it ignores the
criticized aspects of NFS and PFS and combines the scientifically accepted
aspects (Kutlu Gündoğdu and Kahraman 2019).
AHP is one of the most widely used multi-criteria decision-making techniques
in a variety of fields, from social sciences to natural sciences. AHP, which was
developed by Saaty (1980) and used by decision-makers to determine rank and
evaluate the degree of importance, is a method in which a hierarchical structure is
created by categorizing the factors. In AHP, the judgments of the decision-makers
are used in order for the decision-making problems to gain a hierarchical
structure. It can be stated that the decision problem becomes more complex as the
number of hierarchical levels increases.
The AHP method has expanded with the emergence of new fuzzy set
approaches. The fuzzy AHP method, which is used in many different disciplines
such as engineering, medicine, business, sustainability and energy, provides a
mathematical power to reveal the uncertainties accompanying the cognitive
process of human beings in cases where decision-makers cannot express their
evaluations with precise numbers (Kahraman and Kaya 2010). SFAHP, on the
other hand, enables decision-makers to independently reflect their hesitations in
the decision-making process by employing an SFS-based linguistic evaluation
scale. The application steps of the SFAHP method are explained in Kutlu
Gündoğdu and Kahraman (2020).
Step 1: Creation of hierarchical structure
In this step, a hierarchical structure consisting of at least three levels is
created. Level 1 represents an objective or a goal (selecting the best
alternative) based on score index. At level 2, score indexes are estimated(7.3)
(7.4)
based on the finite set of criteria C = {C1, C2, …, Cn}. In this
hierarchical structure, any criterion Ci (i = 1, 2,…, n)can have many sub￾criteria.
Step 2: Pairwise comparisons are constituted with the help of SF judgment
matrices depending on the linguistic terms given in Table 7.1.
Table 7.1 Linguistic measures of importance used for pairwise
comparisons
Absolutely more importance (AMI) (0.9, 0.1, 0.0) 9
Very high importance (VHI) (0.8, 0.2, 0.1) 7
High importance (HI) (0.7, 0.3, 0.2) 5
Slightly more importance (SMI) (0.6, 0.4, 0.3) 3
Equally importance (EI) (0.5, 0.4, 0.4) 1
Slightly low importance (SLI) (0.4, 0.6, 0.3) 1/3
Low importance (LI) (0.3, 0.7, 0.2) 1/5
Very low importance (VLI) (0.2, 0.8, 0.1) 1/7
Absolutely low importance (ALI) (0.1, 0.9, 0.0) 1/9
Eqs. (7.3) and (7.4) are used to obtain the score indices in Table 7.1.
SI = √ 100*[(μA˜S − πA˜S
)
2
− (vA˜S − πA˜S
)
2
] for AMI, VHI, HI,
1
SI = 1
√ 100*[(μA˜S
−πA˜S
)
2
−(vA˜S
−πA˜S
)
2
]
forEI, SLI, LI, VLI, and ALI
Step 3: Checking the consistency of comparison matrices
The consistency of each pairwise comparison matrix should be checked
by converting the linguistic terms in the pairwise comparison matrix into
Linguistic terms (μ, v, π) Score index (SI) ∣∣ ∣ ∣(7.5)
(7.6)
(7.7)
(7.8)
corresponding score indexes. Then, apply the classic consistency test with a
CR threshold of 10%.
Step 4: Calculate the SF local weights of criteria and alternatives.
For calculating the SF weights for each criterion, the spherical weighted
arithmetic mean (SWAM) algorithm denoted by Eq. (7.5) is applied.
where w = 1/n.
Step 5: A hierarchical order of layers is established to obtain the global
weights.
The SF weights at each level are aggregated to estimate final ranking
orders for the alternatives. This calculation is performed from the bottom
level to the up level. There are two possible ways to follow at this point. In
the first of these ways, the defuzzy of the criteria weights is performed using
the score function (S) in Eq. (7.6). Then, normalize them with Eq. (7.7) and
apply the SF multiplication given in Eq. (7.8).
S (w˜
s
j) = √ 100*[(3μA˜s −
πA˜s
2 )
2
− (
vA˜s
2 − πA˜s
)
2
]
Normalize the criteria weights by using Eq. (7.7).
ws
j =
S(w˜
s
j)
∑n
j=1
S(w˜
s
j)
SWAMw (AS1, AS2,…, ASn) = w1AS1 + w2AS2 + ⋯ +
= [1 − ∏
n
i=1 (1 − μ
2
ASi
)
wi
]
1/2
[∏
n
i=1 (1 − μ
2
ASi
)
wi − ∏
n
i=1 (1 −
¯
A˜Sij = w
s
j
⋅ A˜
∣Si = (1 − (1 − μ
2
A˜S
)
ws
j)
1
2
, v
w
∣s
j
A˜S
,
((1 − μ
2
A˜S
)
ws
j − (1 − μ
2
A˜S
− π
2
A˜S
)
ws
j)
1
2
¯
¯
¯
¯
∀i(7.9)
(7.10)
Finally, the SFAHP score (F˜), for each alternative Ai
, is obtained by
carrying out the spherical fuzzy arithmetic addition over each global
preference weight as given in Eq. (7.9).
F˜ =
n
∑
j=1
A˜Sij = A˜Si1 ⊕ A˜Si2 ⊕ … ⊕ A˜Sin
for ∀i
i.e.
There is an alternative method to proceed without defuzzification. In this
instance, global preference weights for SF are computed using Eq. (7.10).
∏
n
j=1 A˜Sij = A˜Si1 ⊗ A˜Si2 ⊗ … ⊗ A˜Sin
for ∀i
i.e.
The final score F˜ is calculated by using Eq. (7.10).
Step 6: Defuzzify the final score of each alternative by using the score
function given in Eq. (7.6).
Step 7: Alternatives are ranked according to the final defuzzified scores. The
largest value indicates the best alternative.
The SFAHP method typically favors the option with the highest degree of
membership and the lowest degree of non-membership. In terms of a
A˜Si1 ⊕ A˜Si2 = (μ
2
A˜S11
+ μ
2
A˜S12
− μ
2
A˜S11
μ
2
A˜S12
)
1
2
, v
2
A˜S11
v
2
A˜S12
,
((1 − μ
2
A˜S12
)π
2
A˜S11
+ (1 − μ
2
A˜S11
)π
2
A˜S12
− π
2
A˜S11
π
2
A˜S12
)
A˜Si1 ⊗ A˜Si2 = μ
2
A˜S11
μ
2
A˜S12
, (v
2
A˜S11
+ v
2
A˜S12
− v
2
A˜S11
v
2
A˜S12
)
1/2
,
((1 − v
2
A˜S12
)π
2
A˜S11
+ (1 − v
2
A˜S11
)π
2
A˜S12
− π
2
A˜S11
π
2
A˜S12
)superior alternative, a large hesitancy degree is preferable to a large non￾membership degree with equal membership degrees.
7.4 RESULTS
In this section, the local and general weights of the factors that are effective in
medical tourism destination selection and put forward within the framework of
MTI, obtained as a result of SFAHP analysis, are included.
7.4.1 Determination of main and sub-criterion importance levels
(weights)
The aim of this study is to determine and rank the importance levels of the criteria
in the MTI developed by Fetscherin and Stephano (2016) in selecting a
destination for treatment. Evaluations of the 4 main criteria and 16 sub-criteria
formed after the rearrangement of the sub-criteria in MTI were collected from the
decision-makers group using the linguistic terms given in Table 7.1. At this point,
it should be noted that the consistency ratio (CR) of the comparison matrix of
main themes and sub-themes should be below 10%, as in the traditional AHP
method (Step 3). By comparing the main criteria with each other, first the weights
of the main criteria were determined, and then, the weights of the sub-criteria at
the lower level of the hierarchy were obtained by using the weights of the main
criteria. The pairwise comparison of the main criteria and the corresponding CR
are given in Table 7.2.
Table 7.2 Pairwise comparison of main criteria
Country
environment
EI AMI SMI HI (0.732,
0.263,
0.228)
Tourism
destination
ALI EI LI SLI (0.363,
0.624,
0.287)
Medical
tourism cost
SLI HI EI SMI (0.609,
0.372,
Country
environment
Tourism
destination
Medical
tourism
cost
Facilities
and
services
Spherical
weights0.302)
Facilities
and services
LI SMI SLI EI (0.471,
0.509,
0.316)
According to Table 7.2, the most important main criterion is country environment
(0.349), and the least important main criterion is tourism destination (0.159).
Pairwise comparisons of the sub-criteria of each main criterion are given in Table
7.3, Table 7.4, Table 7.5 and Table 7.6, respectively.
Local weights of the sub-criteria are given in Table 7.3, Table 7.4, Table 7.5
and Table 7.6. Finally, global weights are determined with the help of the weights
of the main criteria. Local and general weights of the found sub-criteria are given
in Table 7.7.
Table 7.3 Evaluation of the sub-criteria of the country environment criterion
Economic
situation
EI HI VHI HI SLI (0.657
0.337,
0.242)
Cultural
similarity
LI EI SMI SLI VLI (0.434
0.557,
0.293)
Country
image
VLI SLI EI SLI ALI (0.358
0.636,
0.282)
Language
similarity
LI SMI SMI EI VLI (0.481
0.514,
0.294)
Safe to
travel
SMI VHI AMI VHI EI (0.767
0.230,
Country
environment
Tourism
destination
Medical
tourism
cost
Facilities
and
services
Spherical
weights
Economic
situation
Cultural
similarity
Country
image
Language
similarity
Safe
to
travel
Spheri
weight0.188)
Table 7.4 Evaluation of the sub-criteria of the tourism destination criterion
Popular
tourist
destination
EI VLI SMI (0.477,
0.504,
0.311)
0.280
Weather
conditions
VHI EI AMI (0.793,
0.200,
0.178)
0.503
Cultural
and natural
attractions
SLI ALI EI (0.382,
0.600,
0.308)
0.218
Table 7.5 Evaluation of the sub-criteria of the medical tourism cost criterion
Cost of
treatment
EI VHI HI (0.695,
0.288,
0.238)
0.432
Cost of
accommodation
VLI EI SLI (0.393,
0.577,
0.311)
0.225
Economic
situation
Cultural
similarity
Country
image
Language
similarity
Safe
to
travel
Spheri
weight
Popular
tourist
destination
Weather
conditions
Cultural
and
natural
attractions
Spherical
weights
Crisp
weights
Cost of
treatment
Cost of
accommodation
Cost
of
travel
Spherical
weights
Crisp
weightCost of travel LI SMI EI (0.491,
0.482,
0.321)
0.288
Table 7.6 Evaluation of the sub-criteria of the facilities and services criterion
Experience
of healthcare
personnel
EI SLI SMI LI VHI
State of art
medical
equipment
SMI EI HI SLI VHI
Quality in
treatments
and materials
SLI LI EI VLI SMI
Accreditation
of the
medical
facility
HI SMI VHI EI AMI
Reputation
of the
medical
facility
VLI VLI SLI ALI EI
Table 7.7 Local and general weights of the found sub-criteria
Cost of
treatment
Cost of
accommodation
Cost
of
travel
Spherical
weights
Crisp
weight
Experience
of
healthcare
personnel
State of
art
medical
equipment
Quality in
treatments
and
materials
Accreditation
of the
medical
facility
Repu
of th
med
facil
Main criteria Crisp
weights Sub-criteria Local
weights
Global
weightsCountry
environment
0.349 Economic situation 0.246 0.0861
Cultural similarity 0.158 0.0552
Country image 0.129 0.0450
Language similarity 0.176 0.0615
Safe to travel 0.291 0.1017
Tourism
destination
0.159 Popular tourist
destination
0.280 0.0445
Weather conditions 0.503 0.0799
Cultural and natural
attractions
0.218 0.0346
Medical
tourism cost
0.281 Cost of treatment 0.432 0.1213
Cost of
accommodation
0.225 0.0631
Cost of travel 0.288 0.0809
Facilities and
services
0.211 Experience of
healthcare personnel
0.214 0.0451
State of art medical
equipment
0.237 0.0500
Quality in treatments
and materials
0.158 0.0333
Accreditation of the
medical facility
0.282 0.0595
Reputation of the
medical facility
0.116 0.0245
When the global weights of the sub-criteria are examined, it is seen that cost of
treatment, safe to travel and economic situation are the first three sub-criteria
with the highest importance with 0.1213, 0.1017 and 0.0861 importance weights,
Main criteria Crisp
weights Sub-criteria Local
weights
Global
weightsrespectively. Also, the least essential sub-criterion is determined as reputation of
the medical facility with the importance weights of 0.0245.
7.5 DISCUSSION AND CONCLUSION
In recent years, in order to survive and grow in the global medical tourism
market, destinations need to focus on increasing their competitiveness by
highlighting their medical tourism attractions. For this reason, determining the
most suitable medical tourism destination is one of the most important problems
that complicates the decision-making process of medical tourists. In this study,
the SFAHP approach, one of the multi-criteria decision-making techniques, is
proposed to help a medical tourist in choosing a destination. In this context, the
analysis results offer a different perspective in the theoretical framework and
provide managerial implications.
7.5.1 Theoretical implications
In order to better analyze the preferences of medical tourists, the distinction
between push and pull factors used in the fields of economics, entrepreneurship
and tourism was used. Both push and pull factors play an important role in
potential medical tourists’ decisions about whether to visit certain medical
tourism destinations. In this context, an evaluation was made through MTI
developed by Fetscherin and Stephano (2016) within the framework of push and
pull factors affecting medical tourism. There are four main criteria in MTI:
country environment, tourism destination, medical tourism cost and facilities and
services. In line with the suggestions of the decision-makers group, the sub￾criteria in MTI were rearranged and they stated that these criteria were not of
equal importance. In this direction, the importance levels of the criteria affecting
medical tourism destination selection were determined through the SFAHP
method. When the study findings were examined, it was seen that the most
important criterion that played a role in medical tourism destination selection was
country environment (0.349). This was followed by medical tourism cost (0.281),
facilities and services (0.211) and tourism destination (0.159).
The country to be visited in medical tourism is generally known as the
destination, and the selection of country constitutes the demand side of the
medical tourism sector (Heung et al. 2010). In the study, the sub-criteria of the
country environment main criterion are listed according to their degree of
importance as safe to travel (0.291), economic situation (0.246), language
similarity (0.176), cultural similarity (0.158) and country image (0.129). Thisresult supports the fact that especially if the destination is not safe enough and
experiencing economic difficulties, this region will be in a weak position in terms
of medical tourism (Vequist 2009). Considering the civil unrest experienced in
many countries in recent years, it is understandable that security issues are given
importance in medical tourism destinations (Wang et al. 2020).
According to the evaluations of the decision-makers group, the second main
criterion with the highest degree of importance is medical tourism cost. The sub￾criterion with the highest degree of importance of this main criterion was found to
be cost of treatment (0.432). The other two sub-criteria are cost of travel (0.288)
and cost of accommodation (0.225). For this reason, cost, which is an important
force for medical tourism, is considered as the second factor after the economic
and political structure of the country in some studies (Smith and Forgione 2007)
and as the main factor in some studies (Aniza et al. 2009). The findings also
support the studies that found a strong relationship between destination selection
and cost in medical tourism (Sarwar et al. 2012) and the literature that medical
tourists often choose the one with the most affordable price among treatments
(Connell 2006).
The third main criterion in terms of importance was determined as facilities
and services. The sub-criteria are listed as accreditation of the medical facility
(0.282), state of art medical equipment (0.237), experience of healthcare
personnel (0.214), quality in treatments and materials (0.158) and reputation of
the medical facility (0.116). As stated by Greenfield et al. (2012), accreditation is
the process of documenting a visible commitment by an organization to
continuously work to improve the quality of patient care, provide a safe
environment and minimize risks to patients and staff. It is also one of the
important factors in choosing the hospital in particular and the destination in
general. As a matter of fact, Chia and Liao (2021) and Wu et al. (2016) suggested
that many potential medical tourists participate in medical tourism due to the
availability of accredited medical facilities, qualified medical experts, quality
health services and equipment in different countries. With the help of
international integration organizations and international accreditation
organizations, the provision of health services with a quality of international
standards leads the citizens of developed countries to look for alternative
countries (Sulku 2017), and it is known that medical tourists from developed
countries choose destinations by paying particular attention to standards and
accreditation.
Tourism destination ranked fourth according to its importance level. The sub￾criteria of these criteria are listed as weather conditions (0.503), popular tourist
destination (0.280) and cultural and natural attractions (0.218). In the literature,
climate or weather conditions are highlighted as one of the critical factors that canaffect medical tourism in a destination (Bulatovic and Iankova 2021). While
extreme weather events, increasing temperatures and air pollution are stated to
negatively affect the health and well-being of those traveling for treatment
purposes, the common view is that they also affect medical tourism destinations
(Maric Stankovic et al. 2022). For example, rising temperatures and air pollution
can exacerbate respiratory and cardiovascular problems and increase the risk of
heat stroke and other heat-related illnesses (Medical Tourism Magazine 2023).
7.5.2 Managerial implications
With the idea that it will provide significant contributions to stakeholders in terms
of destination management, this study determined the importance of the criteria
that play a role in choosing a destination that provides services for medical
tourism. First of all, it has been pointed out that the country environment factor is
of critical importance for medical tourism destinations, as a tourist product, to
compete in the tourism market. It was also emphasized that after security
conditions are ensured in the medical tourism destination, emphasis should be
placed on ensuring stability in economic conditions, highlighting cultural and
linguistic similarities and improving the country’s image. Solving the problems
that arise regarding the country environment criterion with the participation of
health institutions and organizations, medical tour operators, tourism enterprises,
non-governmental organizations, local governments, local people and other
service providers will create a power of attraction and help increase the demand
for that region. Considering the importance of the sub-criteria, it is thought that
this study will contribute to the evaluation of the needs of the medical tourism
sector; the development of new measures and practices to eliminate deficiencies
within the scope of the authorities and responsibilities of all stakeholders; and the
selection process of the medical tourism destination by ensuring coordination,
cooperation and communication between destination stakeholders.
7.6 LIMITATIONS AND SCOPE FOR FURTHER
RESEARCH
It can be thought that the number of participants in the decision-makers group in
this study is a limitation. The number of participants was limited due to the
difficulty of applying paired comparison surveys in the SFAHP method and
reaching international medical tourists. Conducting this study with medical
tourists from different parts of the world in terms of economic, social and cultural
aspects may reveal hidden information in terms of determining the degree ofimportance. It can be thought that another limitation of the study is that the
method used does not take into account the relationships between criteria and
sub-criteria. Therefore, the relationships between criteria and sub-criteria can be
examined using weighting methods such as Decision-Making Trial and
Evaluation Laboratory (DEMATEL) technique and Analytical Network Process
(ANP).
REFERENCES
Abd Mutalib, N. S., Soh, Y. C., Wong, T. W., Yee, S. M., Yang, Q.,
Murugiah, M. K., and L. C. Ming. 2017. Online narratives about medical
tourism in Malaysia and Thailand: A qualitative content analysis. Journal
of Travel & Tourism Marketing. 34(6): 821–832.
Aniza, I., Aidalina, M., Nirmalini, R., Inggit, M. C. H., and T. E. Ajeng.
2009. Health tourism in Malaysia: The strength and weaknesses. Journal
of Community Health. 15(1): 7–15.
Ardil, C. 2022. Fighter aircraft selection using neutrosophic multiple criteria
decision making analysis. International Journal of Computer and
Systems Engineering. 16(1): 5–9.
Atanassov, K. T. 1989. Geometrical interpretation of the elements of the
intuitionistic fuzzy objects. Preprint IM-MFAIS-1–89, Sofia. 20(S1):
S27–S42.
Atanassov, K. T., and S. Stoeva. 1986. Intuitionistic fuzzy sets. Fuzzy Sets
and Systems. 20(1): 87–96.
Aziz, Y. A., Samdin, Z., Awang, K. W., and Z. Abdullah. 2015. Developing
an index for medical tourism. International Business Management. 9(4):
412–415.
Bagga, T., Vishnoi, S. K., Jain, S., and R. Sharma. 2020. Medical tourism:
Treatment, therapy & tourism. International Journal of Scientific &
Technology Research. 9: 4447–4453.
Bookman, M. Z., and K. R. Bookman. 2007. Medical tourism in developing
countries. New York: Palgrave Macmillan US.
Bulatovic, I., and K. Iankova. 2021. Barriers to medical tourism
development in the United Arab Emirates (UAE). International Journal
of Environmental Research and Public Health. 18(3): 1365.
Caballero-Danell, S., and C. Mugomba. 2007. Medical tourism and its
entrepreneurial opportunities: A conceptual framework for entry into theindustry. Master diss., University of Gothenburg.
Cavmak, D., and S. Cavmak. 2020. Using AHP to prioritize barriers in
developing medical tourism: Case of Turkey. International Journal of
Travel Medicine and Global Health. 8(2): 73–79.
Cham, T. H., Lim, Y. M., Sia, B. C., Cheah, J. H., and H. Ting. 2021.
Medical tourism destination image and its relationship with the intention
to revisit: A study of Chinese medical tourists in Malaysia. Journal of
China Tourism Research. 17(2): 163–191.
Cheng, S. H., Chen, S. M., and Z. C. Huang. 2016. Autocratic decision
making using group recommendations based on ranking interval type-2
fuzzy sets. Information Sciences. 361: 135–161.
Chia, K. W., and Y. M. Liao. 2021. An exploratory study of factors
influencing Chinese outbound medical tourism. Journal of China
Tourism Research. 17(3): 376–394.
Chiao, K. P. 2016. The multi-criteria group decision making methodology
using type 2 fuzzy linguistic judgments. Applied Soft Computing. 49:
189–211.
Connell, J. 2006. Medical tourism: Sea, sun, sand and… surgery. Tourism
Management. 27(6): 1093–1100.
Connell, J. 2013. Contemporary medical tourism: Conceptualisation, culture
and commodification. Tourism Management. 34: 1–13.
Dann, G. M. 1977. Anomie, ego-enhancement and tourism. Annals of
Tourism Research. 4(4): 184–194.
Ebrahimzadeh, I., Sakhavar, N., and Z. Taghizadeh. 2013. A comparative
study of health tourism potentials in Iran and India. Journal of
Subcontinent Researches. 5(15): 51–78.
Ehrbeck, T., Guevara, C., and P. D. Mango. 2008. Mapping the market for
medical travel. The McKinsey Quarterly, 11.
Ferrer, M., and A. Medhekar. 2012. Key operational drivers in the medical
tourism industry. International Journal of Accounting Information
Science & Leadership. 5(12): 62–76.
Fetscherin, M., and R. M. Stephano. 2016. The medical tourism index: Scale
development and validation. Tourism Management. 52: 539–556.
Garibaldi, J. M., and T. Ozen, T. 2007. Uncertain fuzzy reasoning: A case
study in modelling expert decision making. IEEE Transactions on Fuzzy
Systems. 15(1): 16–30.Ghasemi, P., Mehdiabadi, A., Spulbar, C., and R. Birau. 2021. Ranking of
sustainable medical tourism destinations in Iran: An integrated approach
using fuzzy SWARA-PROMETHEE. Sustainability. 13(2): 683.
Ghorui, N., Ghosh, A., Mondal, S. P., Bajuri, M. Y., Ahmadian, A.,
Salahshour, S., and M. Ferrara. 2021. Identification of dominant risk
factor involved in spread of COVID-19 using hesitant fuzzy MCDM
methodology. Results in Physics. 21: 103811.
Görener, A. 2016. A SWOT-AHP approach for assessment of medical
tourism sector in Turkey. Alphanumeric Journal. 4(2): 159–170.
Grattan-Guinness, I. 1976. Fuzzy membership mapped onto intervals and
many-valued quantities. Math Logic Q. 22(1):149–160.
Greenfield, D., Pawsey, M., Hinchcliff, R., Moldovan, M., and J.
Braithwaite. 2012. The standard of healthcare accreditation standards: A
review of empirical research underpinning their development and impact.
BMC Health Services Research. 12(1): 1–14.
Han, H., and S. S. Hyun. 2015. Customer retention in the medical tourism
industry: Impact of quality, satisfaction, trust, and price reasonableness.
Tourism Management. 46: 20–29.
Heung, V. C. S., Kucukusta., D., and H. Song. 2010. A conceptual model of
medical tourism: Implications for future research. Journal of Travel &
Tourism Marketing. 27(3): 236–251.
Horowitz, M. D., Rosensweig, J. A., and C. A. Jones. 2007. Medical
tourism: Globalization of the healthcare marketplace. Medscape General
Medicine. 9(4): 33.
Ilbahar, E., Kahraman, C., and S. Cebi. 2022. Risk assessment of renewable
energy investments: A modified failure mode and effect analysis based
on prospect theory and intuitionistic fuzzy AHP. Energy. 239: 121907.
Jahn, K. U. 1975. Intervall-wertige mengen. Mathematische Nachrichten.
68(1): 115–132.
Jawad, M., Naz, M., and H. Muqaddus. 2023. A multi-criteria decision￾making approach for portfolio selection by using an automatic spherical
fuzzy AHP algorithm. Journal of the Operational Research Society.
75(1): 85–98.
Jin, F., Ni, Z., Chen, H., and Y. Li. 2016. Approaches to group decision
making with intuitionistic fuzzy preference relations based on
multiplicative consistency. Knowledge-Based Systems. 97: 48–59.Kahraman, C., and İ. Kaya. 2010. A fuzzy multicriteria methodology for
selection among energy alternatives. Expert Systems with Applications.
37(9): 6270–6281.
Khan, M. J., Chelliah, S., and M. S. Haron. 2016. Medical tourism
destination image formation process: A conceptual model. International
Journal of Healthcare Management. 9(2): 134–143.
Kutlu Gündoğdu, F., and C. Kahraman. 2019. Spherical fuzzy sets and
spherical fuzzy TOPSIS method. Journal of Intelligent & Fuzzy Systems.
36(1): 337–352.
Kutlu Gündoğdu, F., and C. Kahraman. 2020. A novel spherical fuzzy
analytic hierarchy process and its renewable energy application. Soft
Computing. 24: 4607–4621.
Kutlu Gündoğdu, F., and C. Kahraman. (eds.). 2021. Properties and
arithmetic operations of spherical fuzzy sets. In Decision Making with
Spherical Fuzzy Sets: Theory and Applications, 3–25. Cham: Springer.
Kutlu Gündoğdu, F., Kahraman, C., and H. N. Civan. 2018. A novel hesitant
fuzzy EDAS method and its application to hospital selection. Journal of
Intelligent & Fuzzy Systems. 35(6): 6353–6365.
Lajevardi, M. 2016. A comprehensive perspective on medical tourism
context and create a conceptual framework. Journal of Recreation and
Tourism Research. 3(3): 35–52.
Liu, W., Dong, Y., Chiclana, F., Cabrerizo, F. J., and E. Herrera-Viedma.
2017. Group decision-making based on heterogeneous preference
relations with self-confidence. Fuzzy Optimization and Decision Making.
16: 429–447.
Maric Stankovic, A., Radonjic, I., Petkovic, M., and D. Divnic. 2022.
Climatic elements as development factors of health tourism in south
Serbia. Sustainability. 14(23): 15757.
Mathijsen, A. 2019. Home, sweet home? Understanding diasporic medical
tourism behaviour. Exploratory research of Polish immigrants in
Belgium. Tourism Management. 72: 373–385.
Medical Tourism Magazine. 2023. Medical Tourism and the Impact of
Climate Change on Health and Wellness Travel.
https://www.magazine.medicaltourism.com/article/medical-tourism-and￾the-impact-of-climate-change-on-health-and-wellness-travel
Najafinasab, M., Agheli, L., Sadeghi, H., and S. F. Dizaji. 2020. Identifying
and prioritizing strategies for developing medical tourism in the socialsecurity organization of Iran: A SWOT-AHP hybrid approach. Iranian
Journal of Public Health. 49(10): 1959.
Nguyen, T. T. 2016. Medical tourism: Studying the impact of motivational
factors, destination image on perceived quality and overall satisfaction
using SEM analysis. Master diss., California State Polytechnic
University.
Nguyen, P. H. 2022. Agricultural supply chain risks evaluation with
spherical fuzzy analytic hierarchy process. Computers, Materials &
Continua. 73(2): 4211–4229.
Olya, H., and T. H. Nia. 2021. The medical tourism index and behavioral
responses of medical travelers: A mixed-method study. Journal of Travel
Research. 60(4): 779–798.
Sambuc, R. 1975. Functions-Flous, Application alaide au Diagnosticen
Pathologie Thyroidienne (PhD diss., These de Doctorat en Medecine).
Research and Markets. 2024. Medical Tourism Global Market Report 2024.
https://www.researchandmarkets.com/reports/5735386/medical-tourism￾global-market-report#cat-pos-1 (accessed September 1, 2023).
Saaty, T. L. 1980. The analytic hierarchy process: Planning, priority setting,
resource allocation. New York: McGraw-Hill.
Sarwar, A. A., Manaf, N. A., and A. Omar. 2012. Medical tourist’s
perception in selecting their destination: A global perspective. Iranian
Journal of Public Health. 41(8): 1.
Sharaf, I. M. 2021. Global supplier selection with spherical fuzzy analytic
hierarchy process. Decision Making with Spherical Fuzzy Sets: Theory
and Applications. 392: 323–348.
Singh, L. 2019. Medical tourism motivations: The driving force. Journal of
Multidisciplinary Academic Tourism. 4(2): 77–86.
Smarandache, F. 1999. A unifying field in logics: Neutrosophic logic. In
Philosophy, 1–141. Rehoboth: American Research Press.
Smarandache, F. 2003. Definition of neutrosophic logic: A generalization of
the intuitionistic fuzzy logic. In Proceedings of the Third Cconference of
the European Society for Fuzzy Logic and Ttechnology, 141–146.
EUSFLAT 2003, September 10–12, 2003, University of Applied
Sciences at Zittau, Goerlitz, Germany.
Smith, P. C., and D. A. Forgione. 2007. Global outsourcing of healthcare: A
medical tourism decision model. Journal of Information Technology
Case and Application Research. 9(3): 19–30.Smith, R., Alvarez, M. M., and R. Chanda. 2011. Medical tourism: A review
of the literature and analysis of a role for bi-lateral trade. Health Policy.
103(2–3): 276–282.
Sulku, S. N. 2017. Sağlık turizminde Türkiye’nin dünyadaki yeri ve
potansiyeli. In Uluslararası İktisadi ve İdari Bilimler Dergisi. 17. Ulusal
Turizm Kongresi Özel Sayısı, 99–133.
Torra, V. 2010. Hesitant fuzzy sets. International Journal of Intelligent
Systems. 25(6): 529–539.
Vequist, D. G., Valdız, E., and B. Morrison. 2009. Medical tourism
economic report: Latin America versus Asia, Medical Tourism Magazine,
June.
Wan, S., Lan, Y., Xu, J., Guo, J., Pang, L., and X. Cheng. 2016. Match-srnn:
Modeling the recursive matching structure with spatial rnn. arXiv
preprint arXiv. 1604.04378.
Wang, H., and Z. Xu. 2016. Total orders of extended hesitant fuzzy linguistic
term sets: Definitions, generations and applications. Knowledge-Based
Systems. 107: 142–154.
Wang, J. H., Feng, H., and Y. Wu. 2020. Exploring key factors of medical
tourism and its relation with tourism attraction and re-visit intention.
Cogent Social Sciences. 6(1): 1746108.
Wongkit, M., and B. McKercher. 2013. Toward a typology of medical
tourists: A case study of Thailand. Tourism Management. 38(1): 4–12.
Wu, H. C., Li, T., and M. Y. Li. 2016. A study of behavioral intentions,
patient satisfaction, perceived value, patient trust and experiential quality
for medical tourists. Journal of Quality Assurance in Hospitality &
Tourism. 17(2): 114–150.
Yager, R. R. 1986. On the theory of bags. International Journal of General
System. 13(1): 23–37.
Yıldız, D., Temur, G. T., Beskese, A., and F. T. Bozbura. 2020. Evaluation of
positive employee experience using hesitant fuzzy analytic hierarchy
process. Journal of Intelligent & Fuzzy Systems. 38(1): 1043–1058.
Yiğit, A., and M. B. Demirbaş. 2020. Türkiye’de medikal turizmin
gelişimine etki eden faktörlerin SWOT-AHP yöntemi ile tespit
edilmesine yönelik bir araştırma. Karadeniz Sosyal Bilimler Dergisi.
12(22): 173–192.
Zadeh, L. A. 1965. Fuzzy sets. Information and Control. 8(3): 338–353.Zadeh, L. A. 1975. The concept of a linguistic variable and its application to
approximate reasoning-I. Information Sciences. 8(3): 199–249.
Zakaria, M., Islam, M. A., Islam, M. K., Begum, A., Poly, N. A., Cheng, F.,
and J. Xu. 2023. Determinants of Bangladeshi patients’ decision-making
process and satisfaction toward medical tourism in India. Frontiers in
Public Health. 11: 1137929.Chapter 8
Effect of artificial intelligence on
education
Santu Karmakar and Tapash Das
DOI: 10.1201/9781003536796-8
8.1 INTRODUCTION
Artificial intelligence (AI) has transformed the landscape of education,
facilitating the development of intelligent tutoring systems and adaptive learning
(Ouyang & Jiao, 2021). The integration of AI into education necessitates a
thorough examination of its potential benefits, as well as the associated risks and
challenges, highlighting the need for a critical and ethical approach (Holmes et
al., 2022). To leverage the full potential of AI in education, it is crucial to align AI
proposals with pedagogical principles, ensuring the creation of sustainable,
inclusive, and diverse learning environments that effectively utilize AI
capabilities for the benefit of all students (Vázquez-Cano, 2021). Furthermore,
AI, exemplified by IBM Watson, has already begun reshaping administrative
workflows in higher education, while machine learning enables pattern
recognition, prediction, and application in novel contexts (Popenici & Kerr,
2017).
8.1.1 Machine learning
Machine learning (ML), a subset of artificial intelligence (AI), empowers
computers to autonomously learn and improve from data, eliminating the need for
explicit programming. It relies on training models with extensive datasets,
enabling them to recognize intricate patterns and relationships within the data.
Three core ML paradigms are supervised, unsupervised, and reinforcementlearning. In supervised learning, models are trained on labelled data to predict
known outcomes. Unsupervised learning seeks to uncover hidden patterns in
unlabelled data, while reinforcement learning introduces interaction, allowing
agents to learn optimal actions based on feedback. ML has pervasive applications
across industries, transforming sectors such as healthcare, finance, and
technology (IBM, 2023). It facilitates speech recognition, image analysis, and
personalized recommendations, enhancing efficiency and accuracy. ML poses
challenges, requiring large volumes of high-quality data for effective training.
Concerns regarding model fairness and bias are prominent, as exemplified by
studies on gender bias in AI (Buolamwini & Gebru, 2018). The interpretability of
complex ML models remains an obstacle (Chen et al., 2020a). This ML’s
transformative potential in revolutionizing industries and driving innovation is
unmistakable, making it a vital component of our data-driven world (Oracle,
2023).
8.1.2 Artificial intelligence
Artificial intelligence (AI), a field within computer science, is dedicated to
creating systems and machines capable of performing tasks that traditionally
require human intelligence. AI endeavours to emulate various facets of human
cognition, including learning, reasoning, problem-solving, perception, and
language comprehension (Dantcheva & Bremond, 2017). These AI technologies
are constructed using sophisticated algorithms and models, enabling machines to
analyse data, identify patterns, and make informed decisions or predictions based
on that data. AI’s applicability extends across diverse domains, encompassing
healthcare, finance, transportation, education, and entertainment (IBM, 2023). In
healthcare, AI plays a pivotal role in medical diagnoses, drug discovery, and
tailoring personalized treatment plans. Financial institutions leverage AI for tasks
such as fraud detection, risk management, and investment portfolio optimization.
Transportation benefits from AI through the development of autonomous vehicles
and efficient traffic management systems (Gates, 2023). AI can be categorized
into various types, including narrow or weak AI, designed for specific tasks or
domains, such as image recognition or natural language processing (Ouyang &
Jiao, 2021). In contrast, general or strong AI aspires to possess the capability to
perform any intellectual task that a human can do (Dibeklioglu et al., 2015).
Despite its tremendous potential, AI presents significant challenges and risks,
including ethical and societal issues, concerns related to data privacy and security,
and the potential for job displacement (Holmes et al., 2022). Hence, it is
imperative to approach AI development in a responsible and ethical manner,
taking into account these challenges and risks, to ensure that AI technologies arebeneficial and aligned with societal values. As AI continues to advance and
become more sophisticated, it is essential to carefully consider the ethical and
societal implications of these technologies and ensure their responsible and
beneficial development and usage.
8.1.3 Deep learning
Deep learning, a subset of machine learning, has emerged as a transformative
force in education, reshaping the way students learn and educators teach. This
innovative approach involves training deep neural networks with multiple layers
to mimic the hierarchical structure of the human brain, enabling machines to
process and understand complex data. According to recent research (Chen et al.,
2020b; Vázquez-Cano, 2021), deep learning holds great promise in the field of
education. One of the key advantages of deep learning is its ability to personalize
learning experiences. Deep learning models can adapt to individual students’
needs by analysing their learning patterns and tailoring content accordingly (Chen
et al., 2020). This adaptability enhances student engagement and performance by
providing targeted support and challenges. Deep learning can provide educators
with valuable insights into student performance. By analysing large datasets,
these models can identify areas where students excel and struggle, enabling
instructors to tailor their teaching methods and interventions effectively (Chen et
al., 2020b). Outside of education, deep learning has made significant strides in
various fields, such as healthcare and autonomous vehicles. In healthcare, deep
learning algorithms can diagnose medical conditions with high accuracy,
improving patient care (IBM, 2023). In autonomous vehicles, these algorithms
enable vehicles to perceive their environment and make informed decisions,
contributing to the development of self-driving cars (Ouyang & Jiao, 2021).
8.2 OBJECTIVES
1. To investigate the impact of AI on the educational sector
2. To discuss the risk of AI in education
8.3 METHODOLOGY
For this chapter, a comprehensive search of scholarly databases such as Google
Scholar, JSTOR, and ScienceDirect, and many more websites was conducted
using keywords such as “artificial intelligence,” “education,” “teaching,”“learning,” and “technology.” The search was limited to articles published
between 2013 and 2023, written only in English. The search resulted in a total of
60 relevant articles and links, which were screened for inclusion based on their
relevance to the topic, credibility of the sources, and regency of the information.
Articles that were not peer-reviewed or published in reputable academic journals
were excluded. After screening, 23 articles and 8 links were selected for further
analysis. The selected articles were reviewed and analysed for their key findings,
research methods, and limitations. The focus was on identifying common themes
and trends related to the impact of AI on education, including its potential
benefits and drawbacks, and implications for teaching and learning. The analysis
of the articles was conducted using a qualitative synthesis approach, which
involved organizing the data into categories and themes. The themes identified
were then used to generate insights and draw conclusions about the effect of AI
on education.
8.4 IMPACT OF ARTIFICIAL INTELLIGENCE IN
THE EDUCATIONAL SECTOR
In a recent Gates Notes article, Bill Gates discusses the transformative potential
of AI in education. While current computer technology hasn’t made a significant
impact on student achievement, Gates believes AI will revolutionize teaching and
learning in the next 5–10 years. AI can customize content based on student
interests and learning styles, keeping them engaged and providing instant
feedback. It can also assist teachers and administrators by assessing student
comprehension and offering career guidance. Gates emphasizes the importance of
maintaining strong student-teacher relationships even as technology advances. He
also highlights the need for equitable access to AI tools, addressing bias in AI
datasets, and closing the digital divide for low-income students. While concerns
exist about AI-generated essays, Gates notes educators’ adaptability and creative
integration of AI, such as allowing students to personalize AI-generated drafts.
With careful implementation and collaboration, AI has the potential to enhance
educational experiences and outcomes (Gates, 2023). In the ever-evolving
workforce, AI supports lifelong learning. Professionals can upskill and earn
micro-credentials through AI-powered platforms, ensuring their adaptability in a
changing job landscape (Schwab and Zahidi, 2020).
The rise of AI applications, such as ChatGPT, is posing significant questions
about the future of education and its impact on critical thinking and learning.
While concerns about AI replacing human intellect and fostering cheating in
higher education exist, there are also potential benefits to be explored. AI has thepotential to alleviate mundane tasks, assist with writer’s block, summarize vast
research, provide personalized feedback, and aid in lesson preparation.
Embracing AI in education requires a careful balance between leveraging its
advantages and ensuring students continue to develop essential skills. As the
educational landscape evolves, it is crucial to harness AI to address significant
societal challenges and guide humanity towards a better future. The University of
St. Thomas is at the forefront of this transformation, integrating generative AI
technologies into their curriculum and exploring how AI can enhance
organizational efficiency and productivity. By adopting the right approach and
focusing on meaningful problem-solving, AI can revolutionize education and
propel society forward (University of St. Thomas, 2023).
8.4.1 Education administration
The application of AI in education has had a significant impact on administrative
and management functions, improving their performance and efficiency. AI￾enabled programs and platforms have provided instructors with tools to
effectively handle administrative tasks such as grading and providing feedback to
students. Platforms like Knewton offer functionalities that assist instructors in
evaluating performance, grading assignments, and delivering personalized
feedback for continuous learning improvement. Intelligent tutoring systems have
also played a crucial role by assisting instructors in various administrative tasks,
including grading and providing feedback. Additionally, AI-powered tools like
Grammarly, Ecree, PaperRater, and Turnitin have further enhanced administrative
processes by offering functionalities such as plagiarism checking, rating and
grading, and providing feedback to support instructors’ tasks. By reducing
paperwork and workloads, AI has allowed instructors to concentrate on their
primary responsibilities, such as delivering content aligned with the curriculum.
While not extensively covered in the reviewed articles, the inclusion of AI in
administrative tasks has demonstrated improvements in quality, efficiency, and
effectiveness in educational settings (Chen et al., 2020b).
8.4.2 Teaching
AI has the potential to significantly impact teaching and learning in higher
education, but it also presents challenges. While AI can automate certain tasks, it
is not yet capable of addressing the complexity involved in higher learning.
Supercomputers struggle to detect irony, sarcasm, and humour, relying on shallow
algorithms that search for patterns in punctuation marks, capital letters, or key
phrases. AI’s limitations are evident in incidents like the fatal accident involving aself-driving car and the racist behaviour of Microsoft’s AI-powered bot on
Twitter. Despite these limitations, AI holds promise in augmenting teaching and
learning, extending human capabilities, and enhancing research. However, it is
crucial to approach AI with caution and maintain a focus on human-centric
education, as technology should enhance the educational process rather than
replace it. Additionally, it is essential to be aware of the potential risks associated
with the control and transparency of AI algorithms, as their monopoly and lack of
accountability can undermine higher learning and suppress critical thinking. The
integration of AI into higher education should be approached thoughtfully, taking
into account the potential impacts and ensuring that technology serves as a tool
for human advancement rather than a means of control (Popenici & Kerr, 2017).
8.4.3 Learning
AI has the potential to significantly impact learning in higher education. While AI
solutions have shown promise in automating certain tasks, they have limitations
when it comes to more complex aspects of higher learning. Detecting irony,
sarcasm, and humour, for example, remains a challenge for AI algorithms. It is
crucial to recognize that AI is not yet ready to replace teachers but rather has the
potential to augment their capabilities. AI can extend human capabilities in
teaching, learning, and research, but it should not be seen as a sole solution.
Education is fundamentally a human-centric endeavour, and technology should be
used to enhance human thinking and the educational process, rather than reducing
it to a mere delivery and assessment system. It is important to approach AI in
higher education with caution, considering the risks, such as privacy concerns and
power imbalances, and ensuring that human agency, critical thinking, and
creativity are not compromised. The influence of AI on learning should be
carefully examined to prevent monopolization of control by tech giants and
maintain the principles of higher education that foster open inquiry and the
advancement of knowledge. Additionally, the economic pressures faced by
universities may lead to the adoption of AI solutions to replace administrative
staff and teaching assistants, requiring an exploration of the effects on learning
and the overall architecture of higher education (Popenici & Kerr, 2017) (Figure
8.1).Figure 8.1 Student learning outcomes through IT (Chiu et al., 2023).
8.5 RISKS OF ARTIFICIAL INTELLIGENCE IN
EDUCATION
In the 21st century, AI is an extremely disruptive innovation that has attracted
considerable attention from practitioners and academics. AI provides extensive
and unprecedented opportunities for fundamental changes and extensive upgrades
across many industries. This disruptive technology makes incredible things
possible, such as autonomous vehicles, facial recognition payments, and guidance
robots (Cheng et al., 2022). AI has been transforming various sectors and
industries, including education. AI can personalize learning, automate
administrative tasks, and enhance the educational experience for students.
However, there is a dark side to AI in education that must be recognized and
addressed. In this chapter, we will explore some of the potential negative impacts
of AI on education (Selwyn, 2019). Industry leaders and experts in AI are
increasingly expressing concerns about the potential risks and societal disruptions
posed by advanced AI systems. Despite actively developing AI technology, these
leaders are calling for tighter regulation and responsible management to mitigate
potential harms. There is a growing consensus among some industry insiders that
if left unchecked, AI could lead to significant negative consequences. This
recognition of risks and the call for regulation represent a significant shift in
perspective, with industry leaders acknowledging the need to prioritize safety and
ethical considerations in the development and deployment of AI systems (Roose,
2023).
While some teachers perceive AI as a threat to their jobs, it should be
acknowledged that AI is designed to assist rather than replace them. However, the
development and implementation costs of AI-powered educational tools pose a
hurdle for schools and educators. Furthermore, reliance on AI may diminishhuman interaction and emotional support, which are crucial for student success.
Privacy concerns arise due to the collection and storage of personal data by AI
systems. Thus, it is essential to view AI as a tool and address its limitations to
ensure a balanced approach to education that combines the benefits of AI with the
unique contributions of teachers (YEC, 2023). AI in electronic markets has
negative consequences, including impacts on organizations, privacy concerns,
and societal challenges related to workforce, ethics, and governance. Concerns
about job loss due to AI extend beyond e-commerce. AI governance faces
challenges related to law, regulation, ethics, and fairness (Boyd & Wilson, 2017;
Wirtz et al., 2020). AI-enabled products can impact companies’ reputation and
profitability. Chatbot performance affects consumer satisfaction and trust in
sellers (Ashfaq et al., 2020). Personalized recommendations may lead to privacy
concerns and information narrowing, making people reluctant to adopt related
technologies (Li et al., 2021). Voice assistants like Alexa can even predict
personal relationship endings. Facial recognition payments also pose privacy risks
(Dibeklioglu et al., 2015; Dantcheva & Bremond, 2016).
8.5.1 AI present challenges
8.5.1.1 Ethical considerations
The development and use of AI in education raise ethical questions related to data
ownership, transparency of algorithms, accountability, and the potential impact on
employment for educators. There is a need for clear guidelines and policies to
ensure that AI in education is used ethically and in the best interests of students
(UNESCO, 2021).
8.5.1.2 Bias and discrimination
AI systems are trained on data, and if the data used for training contain biases, the
AI algorithms can perpetuate and amplify those biases, leading to discriminatory
outcomes. This can result in unequal opportunities and reinforce existing social
inequalities within the educational system (Buolamwini & Gebru, 2018).
8.5.1.3 Emotional intelligence deficit
AI in education is often criticized for its lack of emotional intelligence, which is
considered a valuable aspect of the learning process for many individuals. While
AI technology can provide information and assist in various tasks, it cannot fully
replace the role of teachers. Teachers offer more than just knowledge; theyprovide emotional support and personalized guidance that AI systems currently
lack. Although AI has made significant advancements in communication and
interaction, it is still limited compared to the human touch and personal
connection offered by teachers (Careerera, 2023).
8.5.1.4 Lack of cultural diversity representation
AI models like ChatGPT often fail to reflect the cultural diversity of students and
the authentic voices of diverse populations. This creates a disconnect and
hampers the creation of an equitable and inclusive learning environment (Chen,
2023).
8.5.1.5 Insufficient focus on student learning
While AI models can provide quick answers, they are not optimized to prioritize
student learning. The emphasis on speed may undermine pedagogically sound
practices, such as offering in-depth explanations or fostering curiosity (Chen,
2023).
8.5.1.6 Deceptive coherence in incorrect responses
AI models can generate text that appears coherent and well-structured, even when
the information provided is incorrect. This raises concerns about the reliability
and accuracy of AI-generated content, particularly in subjects like mathematics
(Chen, 2023).
8.6 LIMITATIONS
It is important to note that this study is limited by the selection of articles and
databases used in the search. While efforts were made to ensure a comprehensive
search, it is possible that some relevant articles were not included.
8.7 DISCUSSION
8.7.1 Challenges and dark sides
Acknowledging the challenges and potential risks associated with AI in education
is essential, as highlighted by Xusen Cheng et al. (2022). Privacy concerns, data
security, and the potential for exacerbating educational inequalities require carefulmitigation strategies. For example, the collection and use of student data in AI
applications should be governed by strict privacy policies and regulations.
Additionally, efforts should be made to ensure that AI-powered educational tools
are accessible to all students, regardless of their socio-economic backgrounds, to
prevent further educational disparities.
8.7.2 Data privacy and security
The collection and use of vast amounts of data in AI-driven education raise
concerns about data privacy and security. It’s crucial to establish robust data
protection measures and compliance with relevant regulations to safeguard
student data. This aspect aligns with the discussions in sources like Chen et al.,
(2020a) and Xusen Cheng et al. (2022).
8.7.3 Lifelong learning and adult education
AI is not only limited to K-12 or higher education but also plays a significant role
in lifelong learning and adult education. The potential for AI to support
continuing education and skill development throughout one’s life is an emerging
area of research (Laupichler et al., 2023).
8.7.4 Opportunities and research agenda
The systematic reviews by Stephen J. H. Yang et al. (2021) and Thomas K. F.
Chiu et al. (2023) offer valuable insights into the opportunities and research
directions in AI in education. Future research should focus on refining AI
algorithms to enhance their accuracy and effectiveness. Exploring innovative
pedagogical approaches, such as blended learning models that combine AI-driven
resources with traditional instruction, can further advance the field. Additionally,
investigating the long-term impact of AI on teaching and learning outcomes is
crucial to inform evidence-based practices in education.
8.7.5 Paradigms of AI in education
Fan Ouyang and Pengcheng Jiao (2021) introduce three paradigms for AI in
education: tutor, learner, and peer. These paradigms offer a framework for
understanding the diverse roles that AI can play in educational contexts. The tutor
paradigm involves AI acting as a personalized tutor, providing individualized
instruction and support. In the learner paradigm, AI supports the learner’s
independent learning journey, offering resources and feedback. The peerparadigm involves AI facilitating collaborative learning experiences among
students. Institutions and educators should carefully evaluate which paradigm
aligns with their educational goals and context to maximize the benefits of AI
(Ouyang and Jiao, 2021).
8.7.6 Pedagogical challenges and adaptation
The pedagogical challenges presented by AI in education, as noted by Holmes et
al. (2022) and Esteban Vázquez-Cano (2021), require careful consideration. The
integration of AI should not replace traditional teaching methods but complement
and enhance them. Esteban Vázquez-Cano (2021) highlights the pedagogical
challenge of incorporating AI effectively while maintaining the human touch in
education. Continuous professional development and training opportunities for
educators are essential to equip them with the skills and knowledge necessary to
leverage AI effectively in teaching and learning.
8.7.7 Personalization and adaptive learning
Personalization is a key advantage of AI in education, allowing for tailored
learning experiences. AI algorithms can analyse students’ learning patterns and
preferences, adapting content and pacing to suit individual needs. This concept is
discussed by Chen et al., (2020b), who highlight AI’s role in personalized
learning.
8.7.8 Teacher-student relationships
AI’s role in education should complement rather than replace the teacher-student
relationship. Teachers can leverage AI to gain insights into student progress and
focus more on individualized instruction and mentoring. The importance of
maintaining this relationship is highlighted by Esteban Vázquez-Cano (2021).
8.7.9 Transformational potential and future directions
Bill Gates (2023) underscores the transformational potential of AI in education.
AI-driven technologies have the capacity to personalize learning experiences,
provide real-time feedback, and adapt to individual learner needs. As AI
continues to evolve, it is expected to revolutionize traditional teaching and
learning practices. The integration of AI can lead to greater efficiency in
education, enabling educators to focus on higher-order pedagogical tasks while
AI handles administrative and repetitive tasks.8.8 EDUCATIONAL CONTRIBUTION
8.8.1 Personalized learning
AI adapts educational content to individual student needs, enhancing learning
experiences.
8.8.2 Intelligent tutoring
AI offers real-time guidance, identifying misconceptions and supporting student
progress.
8.8.3 Efficient administration
AI automates tasks like grading and scheduling, allowing educators to focus on
instruction.
8.8.4 Collaboration and communication
AI tools foster global connections and inclusive learning communities.
8.8.5 Intelligent content creation
AI generates diverse educational resources, saving teachers’ time.
8.8.6 Data-driven decision-making
AI analytics inform curriculum design and interventions.
8.8.7 Accessibility and inclusion
AI tools support students with disabilities, promoting equal access to education.
8.8.8 Early identification of at-risk students
Early recognition of academic or socioemotional challenges by AI enables timely
assistance.
8.9 CONCLUSIONThe integration of AI into education has emerged as a transformative force, with
far-reaching implications for teaching and learning. This conclusion synthesizes
key insights from a range of scholarly works and reports. The studies conducted
by Dantcheva and Bremond (2017) on gender estimation based on smile
dynamics, and Buolamwini and Gebru (2018) on intersectional accuracy
disparities in commercial gender classification, underscore the importance of
fairness and ethical considerations in AI applications. These works emphasize the
need for mitigating bias and ensuring equity in AI-driven educational tools.
Ashfaq et al. (2020) and Chen et al. (2020a) delve into user satisfaction and the
theoretical underpinnings of AI in education. Their research emphasizes the
significance of user-centred design and the identification of gaps in theory and
practice to harness the full potential of AI in education. Holmes et al. (2022) and
Esteban Vázquez-Cano (2021) advocate for a critical view and pedagogical
challenges, respectively, in integrating AI into education. These sources highlight
the need for a thoughtful and measured approach that prioritizes the educational
goals and ethical considerations. Fan Ouyang and Pengcheng Jiao (2021) propose
three paradigms for AI in education, offering a comprehensive framework to
understand its multifaceted roles. Bill Gates (2023) underscores the
transformative power of AI in education, urging stakeholders to leverage it
effectively. Popenici and Kerr (2017) delve into the impact of AI on teaching and
learning in higher education, emphasizing the need for educators to adapt and
evolve in the AI-driven landscape. UNESCO (2021) provides essential ethical
guidelines for trustworthy AI, reinforcing the importance of ethical AI
development and deployment. In summary, the systematic review of AI in
education by Yang et al. (2021) and Chiu et al. (2023) sheds light on
opportunities, challenges, and future research recommendations, offering a
comprehensive perspective on the field. The adoption of AI in education is a
multifaceted endeavour that not only holds great promise but also presents
significant challenges. Researchers and educators must work collaboratively to
harness the potential of AI while ensuring fairness, ethics, and a user-centred
approach. As AI continues to shape the educational landscape, it is essential to
remain vigilant in addressing its dark sides (Cheng et al., 2022) and to consider its
long-term impact on the educational ecosystem. With the guidance of ethical
principles and careful research, AI can contribute significantly to the
enhancement of teaching and learning in the 21st century.
REFERENCESAshfaq, M., J. Yun, S. Yu, and S. M. C. Loureiro. 2020. I, Chatbot: Modeling
the Determinants of Users’ Satisfaction and Continuance Intention of AI￾Powered Service Agents. Telematics and Informatics, 54, 101473.
https://doi.org/10.1016/j.tele.2020.101473.
Boyd, M., and N. Wilson. 2017. Rapid Developments in Artificial
Intelligence: How Might the New Zealand Government Respond? Policy
Quarterly, 13(4), 36–43. https://doi.org/10.26686/pq.v13i4.4619.
Buolamwini, J., and T. Gebru. 2018. Gender Shades, Intersectional Accuracy
Disparities in Commercial Gender Classification. Proceedings of the 1st
Conference on Fairness, Accountability and Transparency, 23 and 24
February, New York University, NYC, 1–15.
https://proceedings.mlr.press/v81/buolamwini18a.html.
Careerera. 2023. What Are the Advantages and Disadvantages of AI in
Education? https://www.careerera.com/blog/advantages-and￾disadvantages-of-ai-in-education (accessed May 18, 2023).
Chen, C. 2023. AI Will Transform Teaching and Learning. Let’s Get It Right.
Stanford Institute for Human-Centered AI.
https://hai.stanford.edu/news/ai-will-transform-teaching-and-learning￾lets-get-it-right (accessed May 18, 2023).
Chen, L., P. Chen, and Z. Lin. 2020a. Artificial Intelligence in Education: A
Review. IEEE Access. Institute of Electrical and Electronics Engineers
(IEEE), 8, 75264–75278.
https://doi.org/10.1109/ACCESS.2020.2988510.
Chen, X., H. Xie, D. Zou, and G.-J. Hwang. 2020b. Application and Theory
Gaps during the Rise of Artificial Intelligence in Education. Computers
and Education: Artificial Intelligence, 1, 100002.
https://doi.org/10.1016/j.caeai.2020.100002.
Cheng, X., X. Lin, X.-L. Shen, A. Zarifis, and J. Mou. 2022. The Dark Sides
of AI. Electronic Markets, 32, 11–15. https://doi.org/10.1007/s12525-
022-00531-5.
Chiu, T. K. F., Q. Xia, X. Zhou, C. S. Chai, and M. Cheng. 2023. Systematic
Literature Review on Opportunities, Challenges, and Future Research
Recommendations of Artificial Intelligence in Education. Computers and
Education: Artificial Intelligence, 4, 100118.
https://doi.org/10.1016/j.caeai.2022.100118.
Dantcheva, A., and Brémond, F. 2016. Gender estimation based on smile￾dynamics. IEEE Transactions on Information Forensics and Security,
12(3), 719–729.Dantcheva, A., and F. Bremond. 2017. Gender Estimation Based on Smile￾Dynamics. IEEE Transactions on Information Forensics and Security,
12, 719–729. https://doi.org/10.1109/TIFS.2016.2632070.
Dibeklioglu, H., F. Alnajar, A. Ali Salah, and T. Gevers. 2015. Combining
Facial Dynamics with Appearance for Age Estimation. IEEE
Transactions on Image Processing, 24(6), 1928–1943.
https://doi.org/10.1109/TIP.2015.2412377.
Gates, B. 2023. The Age of AI Has Begun. gatesnotes.com.
https://www.gatesnotes.com/The-Age-of-AI-Has-Begun (accessed June
2, 2023).
Holmes, W., J. Persson, I.-A. Chounta, B. Wasson, and V. Dimitrova. 2022.
Artificial Intelligence and Education: A Critical View through the Lens of
Human Rights, Democracy and the Rule of Law. Strasbourg, France:
Council of Europe. https://rm.coe.int/artificial-intelligence-and￾education-a-critical-view-through-the-lens/1680a886bd.
IBM. 2023. What Is Artificial Intelligence?
https://www.ibm.com/topics/artificial-intelligence (accessed June 2,
2023).
Laupichler, M. C., A. Aster, J. Schirch, and T. Raupach. 2022. Artificial
Intelligence Literacy in Higher and Adult Education: A Scoping
Literature Review. Computers and Education: Artificial Intelligence, 3,
100101. https://doi.org/10.1016/j.caeai.2022.100101.
Li, Y., Zhang, X., Yao, T., Sake, A., Liu, X., and Peng, N. 2021. The
developing trends and driving factors of environmental information
disclosure in China. Journal of Environmental Management, 288,
112386.
Oracle. 2023. What Is Machine Learning?
https://www.oracle.com/in/artificial-intelligence/machine-learning/what￾is-machine-learning/ (accessed May 28, 2023).
Ouyang, F., and P. Jiao. 2021. Artificial Intelligence in Education: The Three
Paradigms. Computers and Education: Artificial Intelligence, 2, 100020.
https://doi.org/10.1016/j.caeai.2021.100020.
Popenici, S. A. D., and S. Kerr. 2017. Exploring the Impact of Artificial
Intelligence on Teaching and Learning in Higher Education. Research
and Practice in Technology Enhanced Learning, 12, 22.
https://doi.org/10.1186/s41039-017-0062-8.Roose, K. 2023. Tech Industry Leaders Warn of the Risks Posed by
Advanced Artificial Intelligence. The New York Times.
Schwab, K., and S. Zahidi. 2020. The Future of Jobs Report 2020. World
Economic Forum. https://www.weforum.org/reports/the-future-of-jobs￾report-2020/in-full (accessed June 6, 2023).
Selwyn, N. 2019. Should robots replace teachers?: AI and the future of
education. John Wiley & Sons.
UNESCO. 2021. Ethics Guidelines for Trustworthy AI.
https://unesdoc.unesco.org/search/N-EXPLORE-d1583401-c1c6-4802-
a1e9-57909513ed8f (accessed 26 May, 2023).
University of St. Thomas. 2023. The Impact of Artificial Intelligence and
ChatGPT on Education. https://news.stthomas.edu/the-impact-of￾artificial-intelligence-and-chatgpt-on-education/ (accessed June 10,
2023).
Vázquez-Cano, E. 2021. Artificial Intelligence and Education: A
Pedagogical Challenge for the 21st Century. Educational Process
International Journal, 10(3), 7–12.
https://doi.org/10.22521/edupij.2021.103.1.
Wirtz, B. W., Weyerer, J. C., and Sturm, B. J. 2020. The dark sides of
artificial intelligence: An integrated AI governance framework for public
administration. International Journal of Public Administration, 43(9),
818–829.
Yang, S. J. H., H. Ogata, T. Matsui, and N.-S. Chen. 2021. Human-Centered
Artificial Intelligence in Education: Seeing the Invisible through the
Visible. Computers and Education: Artificial Intelligence, 2, 100008.
https://doi.org/10.1016/j.caeai.2021.100008.
YEC. 2023. AI in the Classroom: Pros, Cons and the Role of EdTech
Companies. Forbes. https://www.forbes.com/sites/theyec/2023/02/21/ai￾in-the-classroom-pros-cons-and-the-role-of-edtech-companies/?
sh=79b1a57afeb4 (accessed June 27, 2023).Chapter 9
Unleashing the power of IoT
Transforming industries and enabling
connected environments
Abdussalam Abba Tukur
DOI: 10.1201/9781003536796-9
9.1 INTRODUCTION TO IOT: A BRIEF
OVERVIEW OF THE INTERNET OF THINGS,
ITS DEFINITION, AND ITS SIGNIFICANCE IN
THE DIGITAL ERA
The Internet of Things (IoT) stands as a transformative force, bridging the
gap between the physical and digital realms in our increasingly
interconnected world. In this chapter, we will embark on a journey to
explore the core concepts, applications, and foundational technologies that
underpin the IoT revolution.
9.1.1 What is IoT?
At its core, IoT refers to a sprawling network of physical objects or “things”
that are equipped with sensors, software, and connectivity capabilities.
These elements empower these objects to collect and exchange data
seamlessly over the Internet. These objects can encompass a wide spectrum,ranging from familiar everyday devices like smartphones, smartwatches,
and home appliances to more intricate systems in industrial settings, such as
manufacturing machinery, agricultural equipment, and the infrastructure of
smart cities.
9.1.2 The evolution of IoT
The inception of IoT can be traced back to the late 20th century when
visionary researchers and technologists began exploring the possibility of
connecting devices to enhance their functionality. This idea gained traction
as technology advanced, with wireless communication becoming more
sophisticated, sensors becoming smaller and more affordable, and
computing power becoming increasingly accessible.
As the Internet proliferated and became more accessible, IoT
transitioned from a theoretical concept into a tangible reality. Today, we
find ourselves surrounded by a vast ecosystem of IoT devices that offer
unparalleled convenience, efficiency, and insights into our daily lives and
business operations.
9.1.3 Significance of IoT in the digital era
The proliferation of IoT has ushered in a new era of digital transformation,
impacting various domains in profound ways:
a. Enhanced Connectivity: IoT enables seamless and instantaneous
connectivity between devices, allowing for real-time data transmission
and analysis.
b. Data Collection and Analysis: IoT devices generate an immense
amount of data about user behavior, environmental conditions, and
system performance. This data can be harnessed through advanced
analytics and artificial intelligence to derive valuable insights, leading
to better-informed decisions and improved efficiency.
c. Industry Revolution: IoT has disrupted traditional industries by
optimizing processes, reducing operational costs, and increasing
productivity. In manufacturing, IoT-powered sensors can monitor
equipment health, predict maintenance needs, and prevent costly
breakdowns.d. Smart Living: IoT has paved the way for smart homes and cities,
where interconnected devices can efficiently manage energy
consumption, improve security, and enhance the overall quality of life
for residents.
e. Environmental Sustainability: IoT’s ability to monitor and control
various environmental parameters empowers us to make more
sustainable choices and mitigate the impact of human activities on the
planet. For instance, in agriculture, IoT-based precision farming
techniques reduce water and pesticide usage, benefiting both the
environment and crop yields.
9.2 FOUNDATIONAL TECHNOLOGIES:
EXPLORING THE CORE TECHNOLOGIES
THAT ENABLE IOT, SUCH AS SENSORS,
CONNECTIVITY PROTOCOLS, CLOUD
COMPUTING, AND EDGE COMPUTING
IoT’s transformative capabilities are made possible through a sophisticated
interplay of foundational technologies, each serving a unique purpose in
enabling seamless communication, data processing, and decision-making.
Let’s delve into these core technologies that form the bedrock of IoT.
9.2.1 Sensors: the eyes and ears of IoT
At the heart of IoT lies an extensive network of sensors that act as the eyes
and ears of connected devices. Sensors are responsible for collecting data
from the physical world by detecting and measuring specific parameters
such as temperature, humidity, light, motion, and pressure. They come in
various forms, ranging from simple temperature sensors to complex image
and video sensors.
9.2.2 Connectivity protocols: bridging the communication gap
For IoT to function effectively, a robust and reliable communication
infrastructure is essential. Connectivity protocols serve as the bridges thatfacilitate communication between IoT devices and platforms. These
protocols define the rules and conventions for transmitting data across
networks securely and efficiently.
A diverse range of connectivity protocols used in IoT, each catering to
specific needs, are listed below:
Wi-Fi: Offers high-speed data transfer suitable for applications in
homes, offices, and urban areas.
Bluetooth: Ideal for short-range communication between devices,
often used in wearables and smart home devices.
Zigbee: A low-power and low-data-rate protocol commonly employed
in industrial settings and home automation systems.
LoRaWAN: Optimized for long-range communication with low power
consumption, making it suitable for IoT applications in agriculture and
environmental monitoring.
Cellular (3G, 4G, and 5G): Leverages existing cellular networks to
enable IoT devices with broader coverage and higher data rates.
NB-IoT (Narrowband IoT): A low-power wide-area network
(LPWAN) standard designed explicitly for IoT applications.
9.2.3 Cloud computing: the powerhouse of data processing
The vast amounts of data generated by IoT devices require substantial
computing resources for storage, processing, and analysis. Cloud computing
plays a pivotal role in handling this data deluge by providing scalable and
on-demand computing resources over the Internet.
9.2.4 Edge computing: empowering real-time decision-making
While cloud computing is indispensable for large-scale data analysis and
processing, certain IoT applications demand immediate responses and real￾time decision-making. This is where edge computing comes into play.
Edge computing involves processing data closer to the source, i.e., at or
near the IoT devices themselves, instead of sending all the data to
centralized cloud servers. By doing so, edge computing significantlyreduces latency and bandwidth usage, enabling faster response times and
improved system reliability.
Edge computing is especially critical in scenarios where low latency is
crucial, such as autonomous vehicles, industrial automation, and healthcare
monitoring. It also enhances data privacy and security since sensitive
information can be processed locally without being transmitted over
external networks.
9.3 IOT ARCHITECTURE: UNDERSTANDING
THE LAYERED ARCHITECTURE OF IOT
SYSTEMS, INCLUDING THE PERCEPTION
LAYER, NETWORK LAYER, AND
APPLICATION LAYER
The successful implementation of the IoT relies on a well-designed and
organized architecture that ensures efficient communication, data
processing, and seamless integration of various components. In this section,
we will explore the layered architecture of IoT systems, which comprises
the perception layer, network layer, and application layer. Each layer serves
a distinct purpose, and together, they form a robust framework that
underpins the functionality of IoT applications across different domains.
9.3.1 Perception layer: sensing the physical world
The perception layer, also known as the sensing layer, is the foundational
level of IoT architecture. This layer is responsible for capturing data from
the physical environment through a network of sensors and actuators.
Sensors, as mentioned in the previous section, play a central role in this
layer by gathering information about the surrounding physical parameters.
The data collected by sensors can include temperature, humidity, light
intensity, pressure, motion, and various other variables, depending on the
application. Once collected, this raw data is transformed into digital signals
and made available for further processing. The perception layer ensures that
the data is reliable, accurate, and relevant, as it forms the basis for
subsequent actions and decisions in the IoT ecosystem.9.3.2 Network layer: enabling communication and connectivity
The network layer acts as the bridge that connects the diverse array of IoT
devices and sensors spread across different locations. Its primary function is
to facilitate seamless communication and data exchange between these
devices and the central data processing units, such as cloud servers or edge
computing nodes.
To achieve this, the network layer employs the connectivity protocols
discussed in the previous section.
9.3.3 Application layer: realizing the IoT solutions
The application layer is the topmost level of the IoT architecture and
represents the user-facing aspect of IoT systems. At this layer, the data
collected from the perception layer is processed, analyzed, and transformed
into actionable insights that drive decision-making and automation.
The application layer also enables user interactions, allowing individuals
to monitor and manage IoT devices, receive alerts, and customize settings
according to their preferences.
9.4 DATA MANAGEMENT AND ANALYTICS:
EXAMINING THE CHALLENGES AND
OPPORTUNITIES IN MANAGING AND
ANALYZING MASSIVE VOLUMES OF IOT
DATA FOR VALUABLE INSIGHTS AND
DECISION-MAKING
The IoT generates an overwhelming amount of data from a vast network of
interconnected devices and sensors. This massive influx of data presents
both challenges and opportunities for businesses and organizations aiming
to extract valuable insights and make data-driven decisions. In this section,
we will explore the critical aspects of data management and analytics in the
context of IoT, including the challenges faced in handling big data, theimportance of data governance, and the transformative potential of
advanced analytics techniques.
9.4.1 Challenges of managing IoT data
One of the primary challenges in IoT data management is dealing with the
sheer volume, velocity, and variety of data generated by a diverse array of
connected devices. The large-scale data generated by IoT can quickly
overwhelm traditional data storage and processing systems, necessitating
scalable and efficient solutions.
Data security and privacy are also critical concerns in IoT data
management. With sensitive and personal data being collected from various
sources, protecting this data from unauthorized access and potential
breaches is of utmost importance.
9.4.2 Importance of data governance in IoT
To effectively manage and leverage IoT data, organizations must implement
robust data governance practices. Data governance encompasses the
policies, processes, and procedures that ensure data quality, security,
compliance, and availability throughout its lifecycle. It also includes data
cleaning and validation processes to maintain data accuracy and reliability.
9.4.3 Analytics for extracting insights from IoT data
The true value of IoT data lies in the insights and patterns that can be
derived from its analysis. Advanced analytics techniques play a crucial role
in unlocking this potential and transforming raw data into actionable
intelligence.
a. Descriptive Analytics: Descriptive analytics provides a historical
view of IoT data, summarizing past events and trends. It involves basic
statistical analysis and data visualization techniques, helping
organizations understand what has happened in their IoT ecosystem.
b. Predictive Analytics: Predictive analytics uses historical data to make
informed predictions about future events. By applying machinelearning algorithms to IoT data, organizations can anticipate potential
issues, forecast demand, and optimize resource allocation.
c. Prescriptive Analytics: Prescriptive analytics takes insights from
descriptive and predictive analytics a step further by suggesting actions
to optimize outcomes. In the context of IoT, prescriptive analytics can
recommend preventive maintenance actions, energy-efficient settings,
and personalized user experiences.
d. Real-Time Analytics: Real-time analytics involves processing and
analyzing data as it arrives, enabling immediate actions and responses.
Real-time analytics is particularly crucial in IoT applications such as
autonomous vehicles, industrial automation, and healthcare
monitoring.
9.4.4 The power of data-driven decision-making
IoT data management and analytics are not just about processing
information; they are about empowering data-driven decision-making. By
harnessing the vast amounts of IoT data, organizations can gain deeper
insights into their operations, optimize processes, enhance customer
experiences, and identify new revenue opportunities.
9.5 IOT SECURITY AND PRIVACY:
DISCUSSING THE CRITICALASPECTS OF
SECURING IOT DEVICES, NETWORKS, AND
DATAAND ADDRESSING THE PRIVACY
CONCERNS ASSOCIATED WITH IOT
DEPLOYMENTS
As the IoT continues to permeate various aspects of our lives, ensuring the
security and privacy of IoT deployments becomes paramount. In this
section, we will explore the critical aspects of IoT security and privacy,
including the challenges in securing IoT devices and networks, the
significance of data protection, and the measures to address privacy
concerns in the rapidly evolving landscape of IoT.9.5.1 Securing IoT devices: challenges and best practices
IoT devices, ranging from simple sensors to complex industrial equipment,
are the building blocks of IoT ecosystems. Securing these devices is
essential to prevent unauthorized access, data breaches, and potential
manipulation of critical infrastructure.
Challenges in securing IoT devices stem from factors like limited
computational power, memory, and firmware update capabilities. Many IoT
devices may lack robust security features, leaving them susceptible to
exploitation. Ensuring timely security updates and patches can be
challenging due to the diverse range of devices and manufacturers.
To mitigate these challenges, best practices for securing IoT devices
include the following:
a. Strong Authentication: Implementing strong authentication
mechanisms, such as two-factor authentication, helps prevent
unauthorized access to IoT devices.
b. Encryption: Data encryption ensures that sensitive information
remains protected, during both transit and storage.
c. Regular Updates: Ensuring regular firmware and software updates
with security patches helps address vulnerabilities as they are
discovered.
d. Secure Boot and Trusted Execution Environment (TEE):
Employing secure boot and TEE technologies ensures that only trusted
software runs on IoT devices, preventing tampering and unauthorized
code execution.
9.5.2 Securing IoT networks: safeguarding communication
channels
Securing the communication channels between IoT devices and the cloud or
edge servers is vital to prevent data interception, eavesdropping, and man￾in-the-middle attacks.
To enhance IoT network security, the following technologies can be
implemented:a. Network Segmentation: Segmenting IoT devices into separate
networks with restricted access helps contain potential breaches and
limit the impact of attacks.
b. Virtual Private Networks (VPNs): Employing VPNs can encrypt
data transmissions and provide secure communication channels for
remote IoT devices.
c. Intrusion Detection System (IDS) and Intrusion Prevention System
(IPS): Implementing IDS and IPS can help identify and block
suspicious activities on IoT networks.
9.5.3 Protecting IoT data: privacy and confidentiality
Data generated by IoT devices can be highly sensitive, encompassing
personal information, user behavior patterns, and confidential business data.
Protecting this data is crucial to maintaining user trust and complying with
data privacy regulations.
Data protection measures include the following:
a. Role-Based Access Control: Implementing access controls based on
user roles ensures that only authorized personnel can access specific
data.
b. Data Encryption: Encrypting data at rest and during transmission
safeguards it from unauthorized access.
c. Anonymization and Aggregation: Anonymizing and aggregating data
can protect individual identities while still enabling useful insights.
9.5.4 Addressing privacy concerns
IoT deployments can raise significant privacy concerns, especially when it
comes to data collection, usage, and sharing. Organizations must be
transparent with users about the data collected and how it will be used.
Measures to address privacy concerns include the following:
a. Privacy by Design: Incorporating privacy considerations into the
design and development of IoT systems ensures privacy is a
fundamental aspect of the solution.b. Clear Privacy Policies: Providing clear and easily accessible privacy
policies helps users understand how their data will be handled.
c. User Consent: Obtaining explicit user consent for data collection and
usage is essential to respect user privacy preferences.
9.6 INDUSTRY APPLICATIONS: EXPLORING
HOW IOT IS TRANSFORMING VARIOUS
INDUSTRIES, INCLUDING HEALTHCARE,
AGRICULTURE, MANUFACTURING,
TRANSPORTATION, SMART CITIES, AND
HOME AUTOMATION
IoT is revolutionizing industries across healthcare, agriculture,
manufacturing, transportation, smart cities, and home automation. It
empowers efficiency, sustainability, and innovation. How IoT impacts key
sectors is discussed below:
9.6.1 Healthcare
IoT transforms patient care with remote monitoring, wearables, and real￾time health data. It enhances operational efficiency and expands access to
healthcare.
9.6.2 Agriculture
Smart farming deploys IoT sensors for data-driven decisions on irrigation,
fertilization, and pest control. Automation boosts productivity and
sustainability.
9.6.3 Manufacturing
IoT sensors optimize manufacturing, enabling real-time machine
monitoring and predictive maintenance. Quality control is enhanced.9.6.4 Transportation
IoT enables smart mobility with connected vehicles and real-time traffic
data. Fleet management improves efficiency and passenger experiences.
9.6.5 Smart cities
IoT monitors air quality, traffic, and energy consumption for better resource
management and sustainability in urban areas.
9.6.6 Home automation
IoT creates smart homes with remote control of devices, enhancing
convenience, security, and energy efficiency. It also aids in home
healthcare.
9.7 IOT AND ARTIFICIAL INTELLIGENCE:
INVESTIGATING THE CONVERGENCE OF
IOT AND AI TECHNOLOGIES, INCLUDING
MACHINE LEARNING AND PREDICTIVE
ANALYTICS, AND THEIR ROLE IN
ENHANCING IOT CAPABILITIES
IoT’s synergy with artificial intelligence (AI) enhances decision-making,
automation, and predictive insights.
9.7.1 The intersection of IoT and AI
AI analyzes IoT data for intelligent responses. Edge- and cloud-based
processing optimize data analysis.
9.7.2 Machine learning in IoT
Machine learning enables anomaly detection, predictive maintenance, and
personalized user experiences in IoT applications.9.7.3 Predictive analytics for IoT
Predictive analytics forecasts demand, optimizes energy consumption, and
aids healthcare diagnostics.
9.7.4 Edge computing for real-time AI in IoT
Edge computing reduces latency, enhancing real-time IoT applications in
areas like autonomous vehicles and healthcare.
9.7.5 Overcoming challenges: security and data privacy
IoT-AI integration requires robust security and privacy measures, including
encryption and privacy-preserving techniques.
9.8 FUTURE TRENDS AND CHALLENGES:
HIGHLIGHTING EMERGING TRENDS SUCH
AS 5G CONNECTIVITY, EDGE COMPUTING,
AND BLOCKCHAIN AND DISCUSSING THE
CHALLENGES AND ETHICAL
CONSIDERATIONS IN THE WIDESPREAD
ADOPTION OF IOT
Emerging trends and challenges that shape IoT’s future are discussed
below:
9.8.1 5G connectivity
5G empowers IoT with high-speed, low-latency communication but raises
security concerns.
9.8.2 Edge computingEdge computing reduces latency, but maintaining data integrity across a
distributed architecture is a challenge.
9.8.3 Blockchain
Blockchain enhances IoT security and trust but faces scalability issues.
9.8.4 Challenges in widespread IoT adoption
Security, interoperability, data privacy, and ethical considerations are
hurdles.
9.8.5 Ethical considerations in IoT deployment
Ethical data usage, transparency, and privacy are vital in building trust.
9.9 CASE STUDIES
Real-world case studies that illustrate IoT’s impact are discussed below:
9.9.1 Smart agriculture
IoT optimizes crop management with precise data, benefiting resource
management but posing data security risks.
9.9.2 Healthcare
IoT-enabled remote patient monitoring improves care while addressing data
privacy and interoperability challenges.
9.9.3 Smart transportation
IoT enhances urban mobility but raises concerns about data security and
privacy.
9.10 CONCLUSIONThis chapter has been a journey through the vast landscape of IoT, revealing
its profound potential to reshape industries and cultivate connected
environments. We’ve covered everything from the foundational
technologies of IoT to the convergence with AI, emerging trends, and real￾world case studies.
As we stand on the brink of a new era defined by connectivity and data,
this chapter serves as a guide, equipping readers with the knowledge to
navigate the IoT landscape responsibly. The key lies in striking a balance
between innovation and ethical considerations, ensuring that IoT continues
to enrich our lives and transform industries for the better.
BIBLIOGRAPHY
Bahga, A., & Madisetti, V. (2014). Internet of Things (IoT) A Hands-on
Approach. VPT.
Doukas, C. (2012). Building Internet of Things with the Arduino.
Apress.
Erl, T., Puttini, R., & Mahmood, Z. (2013). Cloud Computing:
Concepts, Technology & Architecture. Prentice Hall.
Hanes, D., Salgueiro, G., Grossetete, P., & Barton, R. (2017). IoT
Fundamentals: Networking Technologies, Protocols, and Use
Cases for the Internet of Things. Cisco Press.
Hersent, O., Boswarthick, D., & Elloumi, O. (2012). The Internet of
Things: Key Applications and Protocols. Wiley
Klein, S. (2017). IoT Solutions in Microsoft’s Azure IoT Suite: Data
Acquisition and Analysis in the Real World. Apress.
Kranz, M. (2016). Building the Internet of Things: Implement New
Business Models, Disrupt Competitors, and Transform Your
Industry. Wiley.
McEwen, A., & Cassimally, H. (2013). Designing the Internet of
Things. Wiley.
Miller, M. (2015). The Internet of Things: How Smart TVs, Smart
Cars, Smart Homes, and Smart Cities Are Changing the World.
Que Publishing.Raj, P., Raman, A. C., & Rajan, A. (2017). The Internet of Things:
Enabling Technologies, Platforms, and Use Cases. Springer.
Rayes, A., Schmietendorf, A., & Staake, T. (2016). Internet of Things
from Hype to Reality: The Road to Digitization. Springer.
Schwab, K. (2017). The Fourth Industrial Revolution. Currency.
Sinclair, B. (2017). The Business of Internet of Things. Create Space
Independent Publishing Platform.
Uckelmann, D., Harrison, M., & Michahelles, F. (2008). Architecting
the Internet of Things. Springer.
Yang, S. H., & Gu, Y. (2019). Wireless Sensor Networks: Principles,
Design, and Applications. Springer.Chapter 10
A multi-echelon multi-objective sustainable
supply chain considering traffic congestion
Meraj Hejazi, Fatemeh Harsej, Seyed Ehsan Mirani, Hassan Ahmadi Choukolaei,
and Peiman Ghasemi
DOI: 10.1201/9781003536796-10
10.1 INTRODUCTION
The reduction of resources and the destruction of the environment, along with the increase in
population and the industrialization of human societies, create serious challenges for future
generations (Xueying et al. 2021; Chien et al. 2022; Sadiq et al. 2023). The concept of
sustainability and sustainable development has garnered attention because of the solutions they
propose for these challenges (Olawumi and Chan 2018). Sustainable solutions address
environmental problems, non-renewable energy consumption, climate change, rural
development, and more (Axelsson et al. 2011). Despite the many efforts of researchers and
policymakers to create stability, promote sustainable development, and reduce the challenges
related to the economy, society, and environment, these efforts and researches are still not
enough (Sadiq et al. 2023). Sustainable transportation has become one of the attractive topics
for academic institutions and policymakers in this field in the last three decades, and this
interest is increasing (Bao et al. 2023; Palit et al. 2022). Despite the sustainable development
policies of the World International Organization in more than 193 countries, the goals of
sustainable development have not been separately emphasized in the transportation section. The
long-term plan of the World International Organization, until 2030, aims to provide access to a
sustainable transportation system and pay attention to the needs of sensitive groups of society
such as children, women, and the elderly in order to progress on the path of sustainability (U.S.
(EIA) 2019). On the other hand, the issue of unsustainability in transportation is a key concern
for local authorities because the increase in road traffic and the emission of pollutants,
especially CO2
, not only harm the local environment but also harm the quality of life of the
people (Vågan Municipality 2019). Therefore, paying attention to sustainability issues in
transportation and distribution can significantly contribute to realizing sustainable development
(Kumar et al. 2019; Christopher 2016).
According to many researchers such as (Palit et al. 2022; Fan et al. 2018), transportation can
expand or reduce challenges related to sustainability. The report of the Intergovernmental Panel
in 2015 shows that 14% of the total harmful greenhouse gases for the environment are caused
by the emission of gases and pollutants caused by industrial transportation and the secondlargest sector in the emission of pollutants. It is considered as carbon dioxide and greenhouse
gases in the atmosphere (Palit et al. 2022). Also, 27.6% of energy consumption among nations
belongs to the transportation sector (U.S. (EIA) 2019). Arevalo and Gerike (2023) by reviewing
more than 70% of the articles in the field of sustainable transportation introduce greenhouse gas
emissions, pollutant emissions, and energy consumption as the most important effective
indicators of the environmental field of sustainable transportation. Therefore, many countries
consider the expansion of electronic and sustainable fleets as the solution to control the amount
of pollutants caused by industrial transportation and energy consumption management (He and
Wang 2022; Khan et al. 2020). In recent years, despite significant measures to expand the use of
more sustainable fleets, fossil fuel-based transportation still prevails in many countries of the
world. The proof of this is the amount of CO2 gas emissions and the consumption of fossil fuels
that are released and consumed daily in the transportation of the countries of the world. On the
other hand, the challenges of energy consumption and the emission of pollutants are not the
only issues raised in sustainable transportation, and there are other issues such as delays in
delivering goods to customers that cause customer dissatisfaction, the issue of traffic and road
traffic load that it directly affects the urban management and the delivery time of the goods, as
well as increasing the depreciation costs of the fleet and the driver’s salary, which is directly
related to the amount of distance and duration of transportation, which is related to optimization
issues. It makes sustainable transportation systems in the supply chain complicated and
difficult. The design of the transportation and distribution network will be one of the important
tools in creating an efficient and flexible supply chain, which can lead to an increase in
competitive advantage, market share, and price reduction (Ghahremani-Nahr et al. 2022). The
design of sustainable transportation models plays an important role in reducing the above
challenges and improves services for goods delivery (Long and Zhang 2014; Bao et al. 2023).
Hence, the current study, looking at the challenges of sustainable transportation, proposes a
linear multi-objective model of three-level transportation, which has four objective functions of
increasing customer satisfaction, reducing traffic load, and reducing fleet fuel costs and wages.
It is the driver and reduction of emissions of pollutants such as CO2 and is able to propose
sustainable solutions in transportation. Section 10.2 includes the theoretical foundations and
background of the research, Section 10.3 describes the transportation problem and the proposed
linear model, Section 10.4 presents the results, and Section 10.5 is the conclusion and
suggestions.
10.2 LITERATURE REVIEW
10.2.1 Theoretical foundations of research and research background
Several definitions of sustainability can be found in the literature of this field (Sirsi et al. 2012),
most of which are inspired by the definition of sustainable development published by the
Bruntland Commission in 1987, a report titled Our Common Future. The United States
Department of Commerce defines sustainable production as the economic production process of
a product that results in minimal negative impacts on the environment, protection of energy and
natural resources, and security for employees and society (Ziolo et al. 2020). The idea of
sustainable transportation originates from sustainable development (Hall 2006). Sustainable
transportation is transportation that ensures the health of society and the ecosystem andminimizes emissions of pollutants and carbon dioxide (Subbaih and Ramasamy 2022). The
amount of research in the field of sustainable transportation has been increasing since the
beginning of the 21st century (Zhao et al. 2020) and covers a wide range of different topics such
as structural change, improvement of government measures, climate changes, and community
issues (Bao et al. 2023) which shows the importance of the issue.
10.2.2 Keyword evaluation of sustainable transportation
By analyzing and examining the main keywords of each research, it is possible to better identify
the key topics in that field, to know the trends and topics that the studies focused on (Huang et
al. 2021). One of the effective software in this field is VOSviewer. VOSviewer can be used to
create networks of scientific publications, scientific journals, researchers, research
organizations, countries, keywords, or terms. In this section, the research conducted in the field
of transportation has been reviewed, and the results of the research have been presented by
reviewing more than a thousand researches in the last 10 years. Figure 10.1 shows the results of
the review of articles and research conducted in the field of transportation in a network form. As
you can see, the evaluation results are divided into seven clusters with different colors. The
items of each separate cluster indicate the close relationship of the items of each cluster in
previous researches. The communication lines between the items indicate the number of
connections of each research area with other areas. Also, the larger the label size of each item is,
it indicates the high range of research conducted in that field compared to other fields.
Figure 10.1 The results of a network survey of research conducted in the field of
transportation.Figures 10.2 and 10.3 show in which areas of transportation research have been conducted
from 2012 to 2022 and in which direction the research has been directed. As it can be seen, with
the outbreak of the epidemic in 2019, in recent years, research has been directed toward
COVID. Also, smart city is one of the other areas that have been given attention in recent years.
Figure 10.2 The results of a comprehensive review of research conducted in the field
of transportation.
Figure 10.3 The results of research conducted in the last 10 years in the field of
transportation.10.2.3 Research background
A review of the literature will create a deeper understanding of the subject under investigation
(Jin et al. 2018). The review of articles shows that sustainable transportation has received the
attention of many researchers, especially in the last two decades (Zhou et al. 2020). Janic
(2006) and Zhou (2012) discussed planning and policies in the field of sustainable
transportation in the member countries of the European Union and the United States.
Sundarakani et al. (2010) investigated the effects of carbon emissions in the supply chain and
proposed knowledge and practical measures to green the supply chain. The results showed that
carbon emission in different stages of a supply chain is a significant threat that should be
considered in the design stage of the supply chain. Modibbo et al., (2022 and 2024) studied
sustainability issues in logistics and supply chain management considering different techniques.
Ali et al., (2023) investigated the COVID-19 disruption on the supply chain network of some
selected industries. Khan et al., (2023) studied the supplier selection process in healthcare
system and rank the criteria for best selection of experts.
In research in Australia, Iftekhar and Tapsuwan (2010) investigated travel behaviors and the
choice of transportation modes and provided solutions for the design of sustainable urban
transportation. Demir et al. (2014) conducted research in the field of green transportation and
discussed fuel consumption models and their role in road transportation planning. Seyed
housseini and Ghoreyshi (2014) formulated an integrated production and distribution planning
model for perishable products with considerable inventory and repetition. The proposed model
has a supply chain network and several distribution centers. Due to the complexity of the
model, they realized the total cost by reducing the travel rate and using meta-heuristic methods
such as the firefly algorithm and the lingo transportation model.
In their research, Ahmad et al. (2016); Salvi and Subramanian (2015); and Singh et al.
(2022) discussed the potential capacities of using hydrogen and clean fuels in sustainable
transportation. Galadima et al. (2015) developed a transportation model from the data of
Nigeria, and the proposed model was evaluated by Tora software. The results showed that the
total cost predicted a 16% decrease in temperature. In an article with the aim of identifying an
alternative approach to finding the optimal solution of a transportation problem, it was found
that the transportation problem, with linear programming, can be used for problems with supply
centers and different destinations, while minimizing the total cost of transportation (Patel et al.
2017). The proposed model with fewer steps and easier understanding and optimal results
increases better decision-making.
Pribadi et al. (2019) investigated the robust optimization model to solve the problem of
transportation locations with an elliptic uncertainty set. Zhu and Xu (2020) focused on all
English language articles published in the Web of Science database and identified and
categorized nearly 900 researches in the field of sustainable transportation. The purpose of this
article was to identify the main axes in the field of sustainable transportation and research gaps.
Nine prominent axes were identified in this area, referring to performance indicators and
models, policies, environmental impacts, stakeholder engagement, logistics and chain
management, fuel travel behavior supply, strategic planning of transportation, and public
transportation. Ahmadini et al (2021) studied sustainable green supply chain using multi￾objective optimization modeling approach.
Erdoğan et al. (2023) presented a multi-objective model for the future hydrogen supply chain
in Turkey. They proposed a hydrogen supply chain network that reduces cost, carbon emissions,
and safety risk, programming the problem as a linear mixed-integer model. Abbasi andChoukolaei (2023) provided a review paper examining green supply chain network design
(GSCND) from 2010 to 2023. By examining methods and models related to carbon emissions,
they evaluated three policies: carbon cap, cap and trade, and carbon tax. Also, Li et al. (2023)
evaluated the multi-period model to optimize the design and network of sustainable hydrogen
supply chain for China. The model presented in this article is a linear mixed-integer model that
relatively optimizes the hydrogen supply chain network by providing energy sources,
production technologies, transportation methods, and storage types. Looking at the past
researches, it can be seen that most of the articles have a mostly detailed view of the problem,
while the present article is based on the design of a multi-objective linear programming model
whose goals are customer satisfaction, traffic load, wage costs, depreciation, and the amount of
pollutants released. It is an attempt to provide a comprehensive model with sustainability
approaches, and with the help of GAMS software, it provides an optimal solution that is more
sustainable compared to other existing solutions.
10.3 METHODOLOGY
The transportation model of the current research has three levels and a multi-objective function
and is defined as mixed-integer linear programming for several periods. In order to solve the
multi-objective problem, the comprehensive criterion technique has been used. To estimate the
importance and weight coefficients of each objective function, the Analytic Hierarchy Process
(AHP)method and the opinions of experts in the transportation and sustainability industry were
sought, which consisted of five transportation experts and two university experts familiar with
sustainability concepts.
To optimally solve the proposed model, considering the high volume of the objective
function and the constraints, GAMS software, which is one of the most widely used software in
supply chain optimization and multi-level transportation models, has been utilized.
According to the traffic of the fleet at each level and their return to the origin of the
movement, the total number of traffic of the fleet in the proposed network is calculated and
included in the objective function for minimization. Additionally, the level of customer
satisfaction is calculated based on the total time spent by the fleet in the network and is included
in the objective function. The amount of wages and depreciation due to driving time is also
calculated based on the type of fleet and its number and is applied in the objective function.
Furthermore, the costs due to the emission of the CO2 pollutant are calculated and considered in
the objective function, based on the amount and type of fuel and the conversion factor of
burning diesel, gasoline, and electricity to CO2
 emissions.
10.3.1 Defining the assumptions of the problem
Assumption 1: As seen in Figure 10.4, the problem included a three-level and multi-period
supply chain, so that orders at the third level, which are related to final consumers, are ordered
by employees. Sales are transferred to higher levels. The second level includes warehouses that
as distribution centers sporadically receive orders from the lower level and send services and
products to the lower level warehouses. The first level is called the central facility, which has
the ability to provide orders and send products to the second-level warehouses.Figure 10.4 The three-level network of the transport fleet.
Assumption 2: Due to the time interval between the time of ordering and the time of product
delivery, it is possible that customer demand may change or there is a risk of losing information
from customers to the central facility, hence customer orders with ±10% tolerance. And it is
calculated randomly. Sending customer orders, taking into account the ±10% tolerance, creates
a shortage or surplus of customer orders in a period. In order to eliminate these shortages or
excess orders, a number is included as a penalty for customer dissatisfaction for the system, and
it is necessary to fix the effect of this deviation in the next period. If there is a surplus of
inventory in the future period, a decrease in orders will occur, and if there is a shortage of
inventory, it will increase by the amount of the deficit of orders. It is assumed that the cost of
shortage or surplus is considered zero for the customer, but it should be compensated in each
compensation period for the shortage or surplus of orders.
Assumption 3: Each fleet has variety and number depending on the type of surface. In terms
of diversity, there are three types of electric, diesel, and gasoline fleets, and some of these fleets
have the ability to use two types of fuel, i.e., electric-gasoline and electric-gasoline, or all three
at the same time. Fuel capability, fuel consumption rate, fuel capacity, average speed, travel
distance, weight capacity, volumetric capacity, and driver’s salary cost are used in the selection
of fleets.
Assumption 4: Considering that each product is unique based on the delivery date,
expiration date (for perishable products), portability, rules and standards of shipping time, and
customer requirements, therefore, customers should provide information on time. Regarding theabove cases, take action for orders, so that the fleets are allocated in such a way that according
to the average speed and time required to send the products, they deliver the orders on time.
Assumption 5: Warehouses (distribution centers) are also able to place orders for themselves
in any period of time for levels according to their diverse personal needs. Random numbers are
used to allocate warehouse orders.
Assumption 6: In level 2, which starts from the distribution center of level 1 and finally
reaches the distribution center before the final customers, the orders from the lower levels are
also entered into the system and the orders after the delivery of the higher levels are allocated.
The fleets, their loading, and their sending are coordinated. In order to meet personal needs, the
warehouses of this level are able to request orders, which are cumulatively presented to the
higher level along with lower level orders in each period.
Assumption 7: At each level, it is possible to aggregate orders of final customers and orders
of intermediate warehouses. After receiving the orders from the fleet, the warehouses take their
share of the received order and transfer the orders of lower levels without any deficit.
Assumption 8: Shortage of orders by the fleet is not allowed at any level and in any period.
This means that fleets cannot deliver products less than the estimated orders in any period.
Assumption 9: It is not allowed for fleets to return after leaving any warehouse at any level
or from the central facility, without referring to the destinations.
Assumption 10: After loading orders from intermediate warehouses and delivering them to
customers, the assigned fleet must return to the platform of origin.
In Table 10.1, the parameters of the multi-objective, multi-level transportation model are
presented by title, type, and amount.
Table 10.1 Parameters of the multi-level multi-objective transport model
Period time Non-random 3
Center facilities Non-random 1
Number of warehouse level 1 Non-random 3
Number of warehouse level 2 Non-random 4
Number of warehouse level 3 Non-random 6
Objective function index Non-random 4
Level 1 fleet volume capacity Random 9,000–15,000
Level 1 fleet speed Random 60–100
Level 2 fleet volume capacity Random 1,000–4,000
Level 2 fleet speed Random 80–110
Level 3 fleet volume capacity Random 300–700
Level 3 fleet speed Random 80–130
Fleet weight capacity level 1 Random 1,000–3,000
Name Parameter AmountThe maximum distance that a level 1 fleet can travel Random 200–3,000
Fleet weight capacity level 2 Random 2,000–8,000
The maximum distance that a level 2 fleet can travel Random 2,000–3,000
Fleet weight capacity level 3 Random 2,000–8,000
The maximum distance that a level 3 fleet can travel Random 2,000–3,000
Fleet fuel level 1 Random 15–20
Level 1 deliverable time frame Random 80–120
Fleet fuel level 2 Random 12–30
Level 2 deliverable time frame Random 60–100
Fleet fuel level 3 Random 9–15
Level 3 deliverable time frame Random 50–80
Level 1 fleet tank capacity Random 160–640
Estimation error Random ±10%
Level 2 fleet tank capacity Random 210–490
Order customization of distribution center level 1 Random 0–5,000
Level 3 fleet tank capacity Random 100–150
Order customization of distribution center level 2 Random 0–1,000
Fleet driver salary level 1 Random 1,000–3,000
Order customization of distribution center level 2 Random 0–2,000
Fleet driver salary level 2 Random 500–1,000
Level 1 distances Random 500–1,000
Fleet driver salary level 3 Random 70–200
Level 2 distances Random 100–1,000
Fuel 1 share in level 1 fleet Random 0–0.5
Level 3 distances Random 10–200
Fuel 2 share in level 1 fleet Random 0–0.5
The conversion factor of each liter of diesel to Co2 Random 114.9
Fuel 3 share in level 1 fleet Random 0–0.5
Conversion factor of each kw of electricity to Co2 Non-random 5
Name Parameter AmountFuel 1 share in level 2 fleet Random 0–0.5
The conversion factor of each liter of gasoline to Co2 Non-random 19.9
Fuel 2 share in level 2 fleet Random 0–0.5
Car available at level 1 Random 1,000
Fuel 3 share in level 2 fleet Random 0–0.5
Car available at level 2 Random 1,000
Fuel 1 share in level 3 fleet Random 0–0.5
Car available at level 3 Random 1,000
Fuel 2 share in level 3 fleet Random 0–0.5
Shortage error cost Non-random 50
Fuel 3 share in level 3 fleet Random 0–0.5
Overcharge error cost Non-random 30
Big M Non-random 1,000,000
Request volume Non-random 1
Fleet fuel cost at level 1 Non-random 0.1
Request weight Non-random 1
Fleet fuel cost at level 2 Non-random 0.625
Fleet fuel cost at level 3 Non-random 0.05
10.3.2 A mixed-integer linear programming model of transportation
10.3.2.1 Index and parameter
The parameters and indices used in the mixed-integer linear transportation model for the vehicle
and problem levels and the transported goods are shown in the Table 10.2.
Table 10.2 Indices and parameters of complex integer multi-level linear multi-objective model
1 Volume capacity Par C(tr) CP(trr) CPP(dr)
2 Weight capacity Par W(tr) WP(trr) WPP(dr)
Name Parameter Amount
Vehicle
Item Var/par Trolley Truck Drone
Index Var tr trr dr3 Fuel consume Par f(tr) fu(trr) fuu(dr)
4 Fuel charge Par F(tr) FU(trr) FUU(dr)
5 Available Par TR TRR DR
6 Binary movement Var x(ijtr) y(jltrr) z(lmdr)
7 Driver wage Par wa(tr) waa(trr) -
8 Speed Par sp(tr) spe(trr) spee(dr)
9 Max distance Par DistMax(tr) DistMaxx(trr) DistMaxxx(dr)
10 CO2
 penalty Par p(α) p(α) pp(αα)
11 Coef. transform CO2 Par α α αα
12 Delivery time Par T(tr) Ti(trr) Tim(dr)
13 Work vehicle Par S(tr) Sp(trr) Spp(dr)
14 3PL # Var OU(tr) OUT(trr) -
15 3PL rent fee Par RE(tr) REN(trr) -
16 3PL capacity Par Cou(tr) Cout(trr) -
17 3PL time delivery Par Tou(tr) Tout(trr) -
18 3PL speed Par Sou(tr) Sout(trr) -
19 Rent Var Zn(tr) Znn(trr) -
20 Rent fee Par RZn(tr) RZnn(trr) -
21 Delivery penalty Par β β β
22 Total baseline time Par Baseline
23 Trip time Var TTJ TTL(j) TTM(l)
Station
# Item Var/Par i,j l m
1 Loading center level 1 Par i,j - -
2 Loading center level 2 Par - l -
3 Loading center level 3 Par - - m
4 Distance Par Di(i,j) Dis(j,l) Dist(l,m)
Vehicle
Item Var/par Trolley Truck Drone
Index Var tr trr dr5 Demand real Par Dem(j) Dereal(l) Dreal(l,m)
6 Self-demand of
distribution Center
Self_Dem(j) Self_De(l)
7 Demand system Var Demsys(j) Desys(j,l) Dsys(j,l,m)
8 Demand in vehicle Var Deem(j,tr) Deema(l,trr) Deeman(m,dr)
9 Lack on order (binary) Var La(j,l,m,t)
11 Over on order (binary) Var Ov(j,l,m,t)
10 Lack on order Var Lac(j,l,m,t)
12 Over on order Var Ove(j,l,m,t)
13 Penalty of lack Par PL PL PL
14 Penalty of over Par PO PO PO
15 Prediction error Par Alpha(j,l,m,t)
Product
# Item Parameter
1 Volume Par v(d)
2 Weight Par we(d)
3 Total demand system Var Demasys
10.3.2.2 Objective function
Multi-objective mixed-integer linear programming model considering customer satisfaction
from order delivery time (Z1), the amount of pollutants caused by the emission of Co2 gas (Z2),
the traffic load of the entire network (Z3), and costs drivers’ wages and fuel consumption (Z4)
are defined. Considering the amount of tolerance considered and the values of shortage and
surplus costs, another function which aims to minimize this cost is also added to the objective
function. In the following, the equations of each objective function are shown.
Maximizing customer satisfaction from delivery time (reducing total delivery time)
Z1 = min∑
j,l,t
(TTJt + TTLj,t + TTMj,l,t)
Vehicle
Item Var/par Trolley Truck Drone
Index Var tr trr drMinimizing air pollution caused by CO2
 emissions for diesel, gasoline, and electricity
Minimizing the traffic of all levels
Minimizing the cost of drivers’ wages and car fuel
As explained above, in order to aggregate the five functions, the comprehensive criterion
method is used. The method has a comprehensive criterion in order to minimize the sum of the
relative deviations of the objectives from their optimal values.
z
total = min∑k
i=1 wi*(
z
*
i −zi/z
*
i)
p
Z2 = min ∑
i,j,tr,t
(xi,j,tr,t + x
′
i,j,tr,t)*
DIi,j
100
*Ftr
*(A11tr*α + A12tr*αα + A13tr*α2)
+ ∑
j,l,trr,t
(yj,l,trr,t + y
′
j,l,trr,t)*
DISj,l
100
*FUtrr (A21trr*α + A22trr*αα + A23trr*α2)
+ ∑
j,l,m,pr,t
(zj,l,m,pr,t + z
′
j,l,m,pr,t)*
DISTj,l,m
100
*FFUUpr (A31pr*α + A32pr*αα + A33pr*α2)
Z3 = min ∑
i,j,tr,t
(xi,j,tr,t + x
′
i,j,tr,t) + ∑
j,l,trr,t
(yj,l,trr,t + y
′
j,l,trr,t)
+ ∑
l,m,dr,t
(zj,l,m,pr,t+z
′
j,l,m,pr,t)
Z4 = min∑
tr,t
TTJt
*WAtr + ∑
j,trr,t
TTLj,t
*WAAtrr + ∑
j,l,pr,t
TTMj,l,t
*WAAApr
+ ∑
i,j,tr,t
(xi,j,tr,t + x
′
i,j,tr,t)*
DIi,j
100
*(A11tr*α + A12tr*αα + A13tr*α2)*Ftr*PET)
+ ∑
j,l,trr,t
(yj,l,trr,t + y
′
j,l,trr,t)*
DISj,l
100
*(A21trr*α + A22trr*αα + A23trr*α2)*FUtrr*PETT)
+ ∑
j,l,m,pr,t
(zj,l,m,pr,t + z
′
j,l,m,pr,t)*
DISTj,l,m
100
*(A31pr*α + A32pr*αα + A33pr*α2)*FFUUpr*PETTT)10.3.2.2 Constraints
1. Each trailer can be removed from the central warehouse (level 1) only once in each period.
∑
j
x0,j,tr,t≤1∀tr,t
z
total = min w1*((z
*
1 +∑
j,l,t
(TTJt + TTLj,t + TTMj,l,t)*1/z
*
1)
p
+ w2
*(z
*
2 + ∑
i,j,tr,t
(xi,j,tr,t + x
′
i,j,tr,t)
*
DIi,j
100
*Ftr*(A11tr*a + A11tr*aa + A11tr*a2)
+ ∑
j,l,trr,t
(yj,l,trr,t + y
′
j,l,trr,t)*
DISj,t
100
*FUtrr*(A21trr*a + A22trr*aa + A23trr*a2
+ ∑
j,l,m,pr,t
(zj,l,m,pr,t + z
′
j,l,m,pr,t)*
DISTj,l,m
100
*FFUUpr (A31pr*α + A32pr*αα + A33pr*α2)*1/z
*
2)
p + w3
*((z
*
3 + ∑
i,j,tr,t
(xi,j,tr,t + x
′
i,j,tr,t) + ∑
j,l,trr,t
(yj,l,trr,t + y
′
j,l,trr,t)
+ ∑
l,m,dr,t
(zj,l,m,pr,t+z
′
j,l,m,pr,t))*1/z
*
3)
p
+ w4
+ w4*
p ⎛
⎜⎝
(z
*
4 +∑
tr,t
TTJt
*WAtr + ∑
j,trr,t
TTLj,t
*WAAtrr + ∑
j,l,pr,t
TTMj,l,t
*WAAApr
+ ∑
i,j,tr,t
(xi,j,tr,t + x
′
i,j,tr,t)*
DIi,j
100
*(A11tr*α + A12tr*αα + A13tr*α2)*Ftr*PET)
+ ∑
j,l,trr,t
(yj,l,trr,t + y
′
j,l,trr,t)*
DISj,l
100
*(A21trr*α + A22trr*αα + A23trr*α2)*FUtrr*PETT)
+ ∑
j,l,m,pr,t
(zj,l,m,pr,t + z
′
j,l,m,pr,t)*
DISTj,l,m
100
*(A31pr*α + A32pr*αα + A33pr*α2)*FFUUpr*PETTT))*1/z
*
4
⎞
⎟⎠2. The number of outgoing and incoming trailers should be the same in each period. If each
trailer leaves the warehouse, it must be returned to the original warehouse in each period.
∑
j
x0,j,tr,t −∑
j
xj,0,tr,t = 0∀tr
3. The portable weight capacity of the trailer should be observed based on loading.
ctr − Deemj,tr,t
*v ≥ 0∀tr, j,t
1. The portable volume capacity of the trailer should be observed based on loading.
wtr − Deemj,tr,t
*we ≥ 0∀tr, j,t
2. According to the amount of system orders, several trolleys can be used for orders to a
specific center, and lack of delivery is not allowed.
∑
tr
Deemj,tr,t − (Demsysj,t + Self − del,t) ≥ 0∀j,t
6. Each east can only leave each warehouse j in level 2 once in each period.
∑
l
yj,l,tr,t ≤ 1∀j,tr,t
7. The number of goods taken out and imported in each period should be the same, each
goods must be returned to the original warehouse in each period.
∑
l
yj,l,tr,t −∑
l
yl,j,tr,t = 0∀j,tr,t
8. The portable weight capacity of the east should be observed based on loading.
cptrr,t − Deemal,trr,t
*v ≥ 0∀tr, j,t
9. The capacity of the portable volume of the east should be respected based on loading.
wptrr,t − Deemal,trr,t
*we ≥ 0∀tr, j,t
10. Due to the amount of system orders, several destinations can be used for orders to a
specific center, and delivery shortages are not allowed.
∑
tr
Deemal,trr,t
*yj,l,trr,t − (Desysj,l + Self − demj,t) ≥ 0∀j, l,t
11. Each car can be taken out of each warehouse l in level 3 only once in each period.
∑m
zl,m,dr,t ≤ 1∀l, dr,t12. The number of cars leaving and entering in each period should be the same. If each car
leaves the warehouse, it must return to the original warehouse in each period.
∑
l
zm,l,dr,t −∑
l
zl,m,dr,t = 0∀m, dr,t
13. The portable weight capacity of the car should be observed based on loading.
cppdr,t − Deemanm,dr,t
*v ≥ 0∀dr, m,t
14. The fleet’s transportable volume capacity should be respected based on loading.
wppdr,t − Deemanm,dr,t
*we ≥ 0∀dr, m,t
15. According to the amount of system orders, several cars can be used for orders to a specific
center and lack of delivery is not allowed.
∑
dr
Deemanm,dr,t − Dsysj,l,m,t ≥ 0∀j, l, m,t
16. Restrictions on fuel consumption (diesel) and tank trailers should be observed.
∑
i
∑
j
ftr,t
*xi,j,tr,t ≤ Ftr∀tr,t
17. Restrictions on fuel consumption (diesel) and fuel tanks should be observed.
∑
j
∑
l
futtr,t
*yj,l,trr,t ≤ Futrr∀trr,t
18. Restrictions on the consumption of energy (electricity) and batteries of drones should be
observed.
∑
l
∑m
fuudr,t
*zl,m,dr,t ≤ Fuudr∀dr,t
19. There is a limit on the distance traveled by the trolleys.
∑
i
∑
j
xi,j,tr,t
*Dii,j ≤ Distmaxtr∀tr,t
20. There is a limit on the distance traveled by the fleet.
∑
j
∑
l
yj,l,ttr,t
*Disj,l ≤ Distmaxxtrr∀trr,t
21. There is a limit on the distance traveled by fleet.∑
l
∑m
zl,m,dr,t
*Distl,m ≤ Distmaxxxdr∀dr,t
22. There is a limit on the number of access to the trailer.
∑
i
∑
j
∑
tr
xi,j,tr,t ≤ TRCAP∀t
23. There is a limit to the number of accesses to the fleet.
∑
j
∑
l
∑
trr
yj,l,trr,t ≤ TRRCAP∀t
24. There is a limit on the number of car access.
∑l ∑m ∑dr zl,m,dr,t ≤ DR∀t
25. Trolleys can leave the central warehouse (i = 0) and return to the central warehouse
without referring to any warehouse.
xi,j,tr,t = 0∀i = j
26. Calculating the possibility of a lack of delivery of orders in each period according to the
exact orders of the final customer.
−Alphat
*Drealj,l,m,t ≤ Laj,l,m,t
*M∀j, l, m,t
27. Calculating the possibility of excess delivery of orders in each period according to the
exact orders of the final customer.
Alphat
*Drealj,l,m,t ≤ Ovj,l,m,t
*M∀j, l, m,t
28. The order of the first period should be calculated based on the estimate of the possible
order of the same period.
Dsysj,l,m,t − Drealj,l,m,t
*(1 + Alphat) ≤ Laj,l,m,t
*Mt = 1, ∀j, l, m
29. The orders of each period should be considered based on the estimate of the possible order
of the same period and applying the amount of shortage or overcharge of the previous
period compared to the exact order of the previous period.
30. Converting customer orders from level 3 (available to end customers) to a higher
intermediate level (level 2).
Dsysj,l,m,t − Drealj,l,m,t
*(1 + Alphat) − Laj,l,m,t
*Alphat−1
*Drealj,l,m,t
+ Ovj,l,m,t
*Alphat−1
*Drealj,l,m,t−1 = 0t > 1, ∀j, l, m∑m
Dsysj,l,m,t = Desysj,l,t∀j, l,t
31. Convert a level 2 order to a level 1 order.
∑
l
Desysj,l,t = Demsysj,t∀j,t
32. Convert a level 1 order to a level 0 order.
∑
j
Demsyst = Demasyst∀t
33. Estimated travel time limit for delivery of orders from warehouse level 2 to customers
based on due date.
Distl,m*zl,m,dr,t/speedr ≤ Timdr∀l, m, dr,t
34. Estimated travel time limit for delivery of orders from warehouse level 1 to level 2 based
on due date.
Disj,l*yj,l,trr,t/speetrr ≤ Titrr∀j, l,trr,t
35. Estimated travel time limit for delivery of orders from warehouse level 0 to level 1 based
on due date.
Dii,j*xi,j,tr,t/sptr ≤ TMtr∀i, j,tr,t
36. Calculation of the total travel time of all level 3 fleets.
∑
dr ∑m
Distl,m*zl,m,dr,t/speedr = TTMl,t∀l,t
37. Calculation of the total travel time of all level 2 fleets.
∑
trr ∑
l
Disj,l*yj,l,trr,t/spetrr = TTj,t∀j,t
38. Calculation of the total travel time of all level 1 fleets.
∑tr∑j
Dii,j*xi,j,tr,t/sptr = TTJti = 1, ∀j,t
10.4 FINDINGS AND DISCUSSION
In order to create a platform for quantitative comparisons, the above proposed model was
developed using Excel 2019 software to handle all parameters of the completely randomnumber model. The primary reason for using this method is the lack of information and access
to real data concerning a fleet network and the volume of customer orders at different levels.
To comprehensively address the transportation issue, four functions, namely Z1 to Z4, were
separately included in the proposed model, and the optimal values for each function are
presented in Table 10.2. It can be observed that the intersection of each function with itself
yields the lowest and most optimal value. However, considering the functions individually
places the target function values in non-optimal conditions.
For instance, prioritizing the reduction of pollutants like carbon dioxide (Z2) over improving
customer satisfaction (Z1) by delivering goods in less time results in the carbon dioxide
emission reaching its lowest level but leads to an increase of 643 units in delivery time and a
decrease in satisfaction. Likewise, when comparing Z2 to the function of reducing travel costs
and depreciation (Z4), the cost increases by 415,000,000 units. Focusing on minimizing CO2
emissions may lead to using more electric vehicles or hybrid fuels, which, in turn, can increase
driver wages and traffic load. Conversely, focusing on minimizing traffic load may increase
carbon emissions by 288,300,000 units, as larger vehicles with higher fuel consumption,
particularly diesel, are utilized to reduce traffic (see Table 10.3).
Table 10.3 Indices and parameters of complex integer multi-level linear multi-objective model
Single
Function
Z1 2,635 3.56E+08 2,632 1.65E+09
Z2 3,278 8.07E+07 2,966 2.05E+09
Z3 3,095 3.69E+08 2,550 1.93E+09
Z4 2,638 3.50E+08 2,638 1.64E+09
Table 10.3 shows the fuel consumption of the fleet in each approach in three types of electricity,
gasoline, and diesel for three consecutive periods t, t + 1, and t + 2 separately. As can be seen,
61% of the fleet’s fuel in the objective function (Z2) is allocated to the electric fleet. Obviously,
in other functions, this value and share of electric fleet use is lower. Also, the tendency to use
fleets with fossil fuels in other functions has a greater contribution. Table 10.4 shows the
percentage share of fleet types in terms of fuel type. Also, in Figure 10.5, the share of each type
of fuel in four functions is shown separately.
Table 10.4 Fleet fuel consumption in three types of electricity, gasoline, and diesel for each funct
Total
delivery
Time
123 102 117 342 123 102 117 342 218 183 205 60
Total delivery
time
Carbon
emission
Traffic and vehicle
number Trip cost
Z1 Z2 Z3 Z4
Approach
Gasoil Diesel Electricity
1 2 3 Total 1 2 3 Total 1 2 3 ToCarbon
Emission
124 99 119 342 124 99 119 342 387 324 368 1,
Traffic
and
Vehicle
Num.
124 100 110 334 123 100 110 333 206 175 197 5
trip cost 120 101 116 337 120 101 116 337 226 187 210 6
Figure 10.5 Fuel consumption of electric, gasoline, and diesel fleets for each function.
In order to compare the costs of each type of fuel, Table 10.5 and Figure 10.6 are provided. It
is obvious that due to the high volume of gasoline consumption and the cost of each liter, it has
a higher share of the fuel cost of the fleet.
Table 10.5 The share of fleet fuel consumption in 3 types of electricity,
gasoline and diesel for each function
Total delivery time 27 27 47
Carbon emission 19 19 61
Traffic and vehicle num. 27 27 46
Trip cost 26 26 48
Approach
Gasoil Diesel Electricity
1 2 3 Total 1 2 3 Total 1 2 3 To
Approach Gasoil (%) Diesel (%) Electricity (%)(10.1)
Figure 10.6 Share of each type of fuel in three periods for the fleet in percentage.
Table 10.6 shows the amount of deviations of the objective function values compared to the
most optimal function.
Table 10.6 Share of each type of fuel in three periods for the fleet in
percentage
Total delivery time 12 77 11
Carbon emission 10 74 16
Traffic 12 77 10
Trip cost 12 77 11
In order to better understand the results obtained with a single-objective view, the four functions
have been categorized in the form of three approaches: cost, satisfaction, and environmental
approach, and the results have been compared with each other according to these three
approaches. The functions of carbon dioxide emission (Z2) and traffic load (Z3) are considered
in the form of environmental approach, and driver’s salary and fuel costs (Z4) and reduction of
delivery time (Z1) are considered in the form of satisfaction approach. In order to calculate
deviations, Eq. (10.1) has been used, where the value of each function is subtracted from the
value of the optimal function and is divided by the optimal value in order to provide a
percentage.
Dei =
Wf,ap−W
*
f,ap
W
*
f,ap
Fuel consumption Gasoil (%) Diesel (%) Electricity (%)Table 10.7 shows the amount of deviations of the three best-case approaches for each of the
functions. For example, the deviation of the value of the function (Z2) with the cost approach
shows 334%. This means that if we want to focus on minimizing the costs of drivers’ wages and
car fuel, 334% will be added to the amount of emissions of pollutants such as carbon dioxide
compared to the optimal state. Other deviations are listed in Table 10.7 for each function for
three approaches.
Table 10.7 The values of deviations of the objective function from the value of the optimal
function
Function
Z1 Z2 Z3 Z4
Z1 Total Delivery
Time
0% 341% 3% 1%
Z2 Carbon
Emission
24% 0% 16% 25%
Z3 Traffic and
Vehicle Num.
17% 357% 0% 18%
Z4
trip cost 0% 334% 3% 0%
The deviations and their comparison reveal that focusing on a specific objective function will
lead to deviation values in other functions, making it challenging to achieve overall
optimization. Table 10.7 indicates that prioritizing the minimization of carbon dioxide
emissions significantly delays the delivery time of goods (due to the use of electric fleets with
low capacity), resulting in a negative impact on customer satisfaction that is more than three
times greater, and vice versa. In the current research, to obtain a comprehensive view for each
approach, weight coefficients are suggested based on the calculated information. Table 10.8
presents the suggested weight coefficients if the proposed model is used considering the
environmental approach. These coefficients include 5% for the total delivery time function,
65% for carbon dioxide emissions, 25% for the number of cars and traffic, and 5% for the cost
of travel, car fuel, and driver’s salary. The goal is to achieve the lowest total deviation in the
values of the objective functions. Table 10.9 displays the amount of deviations with the
influence of the suggested coefficients for the functions in different approaches. It becomes
evident that the amount of deviations has significantly decreased in the values of the functions.
Please note that the specific values in Table 10.7, Table 10.8 and Table 10.9 were not provided
in the original text, and I used placeholders to describe the context. If you have the actual
values, feel free to include them in the respective tables.
Table 10.8 The amount of deviations of the objective function according to the proposed
approaches
Total
delivery
time
Carbon
emission
Traffic &
vehicle num.
Trip
cost
Deviations from the best solution Environmental
(%)
Cost
(%)
Satisfaction
(%)(10.2)
Weighting according to the
single-objective approach
Z1 24% 0% 0%
Z2 0% 334% 341%
Z3 16% 3% 3%
Z4 25% 0% 1%
Total 66% 337% 345%
Table 10.9 Suggested weighting coefficients of the functions for using each approach
Total delivery time Z1 5 20 85
Carbon emission Z2 65 5 5
Traffic and vehicle num. Z3 25 5 5
Trip cost Z4 5 70 5
The existential philosophy of multi-objective decision-making models shows that a partial and
separate look at the effective functions in a problem will not provide the possibility of
compensating deviations in other functions. Therefore, one cannot be sure about the optimality
of the solution to the problem. The evidence of past research has shown that in many cases, the
optimal solution of single-objective and multi-objective problems has deviations and extreme
differences with each other, and in many cases, even the optimal solution obtained in single￾objective is not in the justified area of other objectives. Considering this importance, the present
research aggregates the objective functions using the comprehensive criterion method and
examines the optimal solution obtained from it with other solutions obtained for each function.
The comprehensive criterion method is one of the most widely used methods for solving multi￾objective problems, and by minimizing the deviations of each function relative to its optimal
value, it will try to minimize the total deviations of the problem. Eq. (10.2) shows how to
calculate the sum of deviations in the comprehensive criterion method.
W new
ap = ∑f
1 (
W
*
f −Wf
W
*
f
)
In order to calculate the value of the multi-objective problem with the comprehensive criterion
method, it is first necessary to obtain the optimal values of each approach in the quadruple
functions by considering the suggested modifier coefficients in Table 10.8. The reason for using
adjusted weight coefficients in calculating the optimal values of the functions is that the
deviations from the optimal value for each function are placed in the lowest state. Table 10.10
shows the optimal values with the influence of weight coefficients for each approach.
Deviations from the best solution Environmental
(%)
Cost
(%)
Satisfaction
(%)
Deviations from the Best Solution Environmental (%) Cost (%) Satisfaction (%)Table 10.10 Values of deviations of the approaches by adjusting the weighting coefficients
proposed by the functions
Weighting according to the single￾objective approach
Z1 1 0 0
Z2 0 17 17
Z3 4 0 0
Z4 1 0 0
Total 7 17 17
Table 10.11 shows the values of deviations of each objective function in the multi-objective
problem with the comprehensive criterion method based on environmental approaches, focusing
on cost and customer satisfaction. As can be seen, in the environmental approach, despite the
deviation of the main objective function (Z2) from its optimal value by 3%, other objectives
have 17%, 12%, and 5% of their optimal values. The values due to deviations are much less
than when the goals are considered as single goals and were calculated. Table 10.12 shows the
values of deviations for single- and multi-objective approaches.
Table 10.11 Adjusted optimal values of functions for each approach according to the data of
three consecutive periods t, t + 1, and t + 2
Multi-objective (comprehensive
criteria)
Z1 3,095 2,773 2,704
Z2 8.28E+07 9.76E+07 1.26E+08
Z3 2,855 2,734 2,692
Z4 1.72E+09 1.62E+09 1.70E+09
Total 1.80E +09 1.72E+09 1.83E+09
Table 10.12 The values of the deviations of the functions for each approach according to the
data of three consecutive periods t, t + 1, and t + 2
Multi-objective (comprehensive
criteria)
W1 17 5 3
W2 3 21 56
W3 12 7 6
Deviations from the Best Solution Environmental
(%)
Cost
(%)
Satisfaction
(%)
Obj Environmental Cost Satisfaction
W
Environmental
(%)
Cost
(%)
Satisfaction
(%)W4 5 1 4
Total 37 34 68
Figure 10.7, Figure 10.8 and Figure 10.9 draw and show the standard deviation of single￾objective functions and comprehensive criterion (multi-objective) in environmental approaches,
cost concentration, and customer satisfaction.
Figure 10.7 Comparison of standard deviation of functions with single-objective
function and comprehensive criteria in environmental approach.
Figure 10.8 Comparison of standard deviation of functions with single-objective
function and comprehensive criteria in cost focus approach.
W
Environmental
(%)
Cost
(%)
Satisfaction
(%)Figure 10.9 Comparing the standard deviation of the single-objective function and the
comprehensive criterion in the approach of customer satisfaction.
Table 10.13 provides a comparison of fleet fuel consumption and cost in two single-purpose
models and comprehensive criteria for environmental approaches, focusing on cost and
customer satisfaction. As can be seen, in the amount of fuel consumption with the single￾purpose model for the environmental approach, it shows the consumption of 61% of the electric
fleet, while in the multi-purpose model, this value is reduced to 54%. Perhaps, at first glance,
this reduction in consumption is not very desirable, if the amount of use of electric fleets has
increased in the other two approaches and the amount of consumption of fleets with gasoline
and diesel fuels has decreased.
Table 10.13 Comparison of values of deviations of the functions of the
comprehensive and single-objective criteria method for each approach
Single-function approach 66 337 345
CC(MO) 37 34 68
Improvement rate 44 90 80
Table 10.14 compares the deviations of single-objective and multi-objective models for three
approaches. In this table, the amount of deviations of fuel consumption in movement from
single-purpose models with environmental approaches, focusing on cost, and customer
satisfaction to the proposed multi-purpose model has been examined according to the relative
influence of the effective functions on each other. For example, if the comprehensive criterion
multi-objective approach is replaced instead of the cost-focused single-objective model, then
the fuel consumption of the electric fleet will increase by 24%, while the fuel consumption of
the gasoline and diesel fleets will decrease by 22%.
Table 10.14 Comparison of consumption deviations and fleet fuel cost in single-objective model
each approach
OBJ Environmental (%) Cost (%) Satisfaction (%)Fuel
consumption
Single￾objective
19 19 61 26 26 48
CCMO 23 23 54 20 20 59
Fuel cost
Single￾objective
10 74 16 12 77 11
CCMO 11 72 17 12 73 15
According to these deviations of fuel consumption in Table 10.14, Table 10.15 shows that the
costs of each fuel, the total fuel consumption, the total costs of fuels, and the emission of carbon
dioxide pollutants per how much has each approach changed in the multi-objective model? For
example, in the environmental approach, the fuel consumption of the electric fleet has increased
by 4% and diesel fuel by 7%, while the consumption of gasoline fuel has decreased by 2%.
Finally, despite the deviation of 3% increase in the amount of carbon dioxide pollutants, the
total fuel costs of the fleets decreased by 9% and the total fuel consumption of the fleets
decreased by 14%.
Table 10.15 Comparison of deviations of fuel consumption of multi-objective method (comprehe
single-objective method for each approach
Approach/share
of fuel
consumption
Gasoil
(%)
Diesel
(%)
Electricity
(%)
Gasoil
(%)
Diesel
(%)
Electricity
(%)
Gasoil
(%)
CCMO 18 18 −11 −22 −22 24 −15
In order to assess the model’s performance based on the weighting coefficients of the objective
function values, Table 10.16 displays the amount of deviations in the optimal solution for each
approach. The table considers four suggested importance coefficients: 1, 0.8, 0.65, and 0.5, for
deviation calculations. For instance, in the environmental biological approach, higher
coefficients result in deviations from the optimal amount of pollutant emissions approaching
zero. On the other hand, concerning consumption, as the coefficients approach 1, the deviation
from the optimal value tends to approach zero. However, this reduction behavior is not
observed in the deviations of fuel costs due to the increased use of electric fleets. The table
provides valuable insights into how the model’s performance changes with different weighting
coefficients, helping in better understanding, and fine-tuning the optimization process for
various aspects of the transportation network.
Table 10.16 Comparing consumption deviations, fuel cost, and emissions of carbon dioxide
pollutants in the multi-objective method (comprehensive criteria) for each approach
Comparison
type
Model
type
Environmental approach Cost focus approach
Gasoil
(%)
Diesel
(%)
Electricity
(%)
Gasoil
(%)
Diesel
(%)
Electricity
(%)
Environmental approach Cost focus approach SatisfacEnvironmental 9 −2 4 −14 −9 3
Cost focus
approach
−5 5 −29 22 5 21
Satisfaction
approach
−1 −4 24 13 1 56
Table 10.17 shows the cost deviations of the number of used cars and the costs of emission of
pollutants based on the approved costs. It is observed that in the column of carbon emissions
and pollutants, the lowest value is when the coefficient related to pollutants is considered 1 in
the objective function of the model. While with the proposed multi-objective model, the
deviation from the best case is 1%. In the cost of using fuel, it has a deviation of 12% with the
best possible condition, and the number of cars used also has a deviation of 11%. In total, the
costs due to the number of vehicles in the transport fleet have a deviation of 21% from the best
single-objective state, and the index of costs due to the emission of pollutants has a deviation of
3% from the best possible state.
Table 10.17 Comparison of consumption deviations, fuel cost, and emission of carbon dioxide po
(comprehensive criteria) to the proposed coefficients of the objective function
1 0 0 12 330 0 4
80% 1 3 12 14 39 9
65% 3 5 10 10 21 10
50% 15 6 13 9 22 11
Table 10.18 indicates that the approach focusing on customer satisfaction (minimum travel
time) with an importance coefficient of 50%, while allocating the remaining coefficients to
other objective functions (equivalent to 15% for carbon emissions, 15% for traffic, and 20% for
fuel and wage costs), results in certain deviations. Specifically, there is a 9% deviation in the
number of cars (traffic), leading to an increase in fuel consumption. Moreover, there is a 10%
deviation in the expenses related to the trip, and a 14% deviation in the amount of carbon
emissions. Despite these deviations, the results of the calculations show that the amount of
Approach Gasoil
(%)
Diesel
(%)
Electricity
(%)
Total fuel
consumption
(%)
Total
fuel
cost
(%)
Carbon
emission
(%)
Suggest
coefficients
Environmental approach Cost focus approach
Deviation
from
emission
of
pollutants
(%)
Deviation
from fuel
consumption
(%)
Deviation
from fuel
cost (%)
Deviation
from
emission
of
pollutants
(%)
Deviation
from fuel
consumption
(%)
Deviatio
from fue
cost (%)traffic (number of cars on the route) and its related costs, as well as carbon emissions, are at
their minimum values and have the lowest deviation. It’s important to note that in the
calculation table, by considering the multiplication of carbon emissions, travel costs, and the
number of cars in service with equal coefficients of 1, another optimal model was obtained. In
the proposed model, coefficients can be adjusted based on the strategic view and thinking of the
organization and its managers, allowing for flexibility in achieving the optimal solution based
on the organization’s preferences and priorities. This adaptability is a valuable feature, as it
allows decision-makers to customize the model to align with their specific goals and objectives.
Table 10.18 Comparing the values of deviations in the multi-objective method (comprehensive
criterion) compared to the best single-objective case
Environmental
100 0 12 16 30 2
80 1 12 14 28 1
65 3 10 14 25 0
50 15 13 16 31 17
Satisfaction
100 341 3 2 6 263
80 55 7 6 14 38
65 25 18 7 26 22
50 14 1 9 10 −3
Cost
100 330 4 3 8 262
80 14 9 8 17 4
65 10 10 9 20 3
50 9 11 9 22 3
Status
Multi￾objective
1 13 13 27 0
Min 0 1 2 6 −3
10.5 CONCLUSION
The comparison between the proposed multi-objective model and the single-objective model
based on sustainability approaches reveals that the proposed multi-objective multi-level model
achieved the best conditions in terms of both optimality and the amount of deviations. The
results of the comparative analysis demonstrate that the proposed model, built on sustainability
Title Coefficient
(%)
Carbon
emission
(%)
Fuel
cost
(%)
Vehicle
number
(%)
Vehicle
cost =
vehicle
number *
cost (%)
Vehicle
cost *
carbon
emission
(%)theories and approaches in transportation, provides favorable and acceptable outcomes
compared to other conditions.
Given that sustainable transportation and its modeling are among the most significant global
issues, companies and distribution channels rely on the outputs of such models to progress
toward sustainability. It is recommended that, in future research, the proposed model should be
implemented using real information and the actual conditions of the transport fleet to enhance
the accuracy and applicability of the findings. Notably, the current model does not incorporate
goods-sharing, but the proposed sustainable transportation model could potentially include new
management approaches like the sharing economy and circular economy. However, the current
research faces limitations due to the scarcity of companies in the country that manage their
transportation network up to the third level. Additionally, the unwillingness of companies to
provide information and data on their transportation networks, stemming from the difficulty in
accessing real information and data of the transportation fleet network, presents a challenge for
further research and serves as a potential case study for investigation.
ETHICALAPPROVALAND COMPETING INTERESTS
All authors have participated in (a) conception and design, or analysis and interpretation of
the data; (b) drafting the article or revising it critically for important intellectual content;
and (c) approval of the final version.
This manuscript has not been submitted to, nor is under review at, another journal or other
publishing venue and has not self-plagiarism
The authors have no affiliation with any organization with a direct or indirect financial
interest in the subject matter discussed in the manuscript
DECLARATION OF INTERESTS
The authors declare that they have no known competing financial interests or personal
relationships that could have appeared to influence the work reported in this paper.
FUNDING
This research received no specific grant from any funding agency in the public, commercial, or
not-for-profit sectors.
AVAILABILITY OF DATAAND MATERIALS
The data that support the findings of this study are available from the corresponding author
upon reasonable request
REFERENCESAbbasi, S., Choukolaei, H. A. (2023). A systematic review of green supply chain network
design literature focusing on carbon policy. Decision Analytics Journal, 6, 100189.
Ahmad, M. W., Mourshed, M., Mundow, D., Sisinni, M., Rezgui, Y. (2016). Building
energy metering and environmental monitoring – a state-of-the-art review and
directions for future research. Energy Building, 120, 85–102.
https://doi.org/10.1016/j.enbuild.2016.03.059.
Ahmadini, A. A. H., Modibbo, U. M., Shaikh, A. A., Ali, I. (2021). Multi-objective
optimization modelling of sustainable green supply chain in inventory and production
management. Alexandria Engineering Journal, 60(6), 5129–5146.
Ali, I., Charles, V., Modibbo, U. M., Gherman, T., Gupta, S. (2023). Navigating COVID￾19: unraveling supply chain disruptions through best-worst method and fuzzy TOPSIS.
Benchmarking: An International Journal, 31(5), 1548–1589.
Arevalo, A. V, Gerike, R. (2023), Sustainability evaluation methods for public transport
with a focus on Latin American cities: a literature review. International Journal of
Sustainable Transportation, 17, 1236–1253.
https://doi.org/10.1080/15568318.2022.2163208.
Axelsson, R., Angelstam, P., Elbakidze, M., Stryamets, N., Johansson, K. E. (2011).
Sustainable development and sustainability: landscape approach as a practical
interpretation of principles and implementation concepts. Journal of Landscape
Ecology, 4(3), 5–30. https://doi.org/10.2478/v10285-012-0040-1.
Bao, L., Kusadokoro, M., Chitose, A., Chen, C. (2023). Development of socially
sustainable transport research: a bibliometric and visualization analysis. Travel
Behaviour and Society, 30, 60–73.
Chien, F., Hsu, C. C., Ozturk, I., Sharif, A., Sadiq, M. (2022). The role of renewable
energy and urbanization towards greenhouse gas emission in top Asian countries:
evidence from advance panel estimations. Renewable Energy, 186, 207–216.
https://doi.org/10.1016/j.renene.2021.12.118.
Christopher, M. (2016). Logistics & supply chain management. London: Pearson.
Demir, E., Bektaş, T., Laporte, G. (2014). A review of recent research on green road freight
transportation. European Journal of Operational Research, 237(3), 775–793.
Erdoğan, A., Geçici, E., Güler, M. G. (2023). Design of a future hydrogen supply chain: a
multi-objective model for Turkey. International Journal of Hydrogen Energy, 48,
11775–11789.
Fan, Y. V., Perry, S., Klemeš, J., Lee, C. T. (2018). A review on air emissions assessment:
transportation. Journal of Cleaner Production, 194, 673–684.
https://doi.org/10.1016/j.jclepro.2018.05.151
Galadima, J. I., David, J., Obioma, R. N., Victor, O., Ikechukwu, A. D. (2015).
Transportation modeling of farm product distribution: a case study of maizeube farm,
Minna, Nigeria. International Journal of Scientific and Engineering Research, 6(2),
1258–1256.
Ghahremani-Nahr, J., Najafi, S. E., Nozari, H. (2022). A combined transportation model
for the fruit and vegetable supply chain network. Journal of Optimization in Industrial
Engineering, 15(2), 131–145. https://doi.org/10.22094/joie.2022.1948231.1925.Hall, R. P. (2006). Understanding and applying the concept of sustainable development to
transportation planning and decision-making in the US. Massachusetts Institute of
Technology. https://dspace.mit.edu/handle/1721.1/34555 (Accessed 20 Feb. 2022).
He, S., Wang, Y. (2022). Evaluating new energy vehicles by picture fuzzy sets based on
sentiment analysis from online reviews. Artificial Intelligence Review, 56, 2171–2192.
https://doi.org/10.1007/s10462-022-10217-1.
Huang, J. H., Duan, X. Y., He, F. F., Wang, G. J., Hu, X. Y. (2021). A historical review and
Bibliometric analysis of research on Weak measurement research over the past decades
based on Biblioshiny. arXiv preprint arXiv:2108.11375.
https://doi.org/10.48550/arXiv.2108.11375.
Iftekhar, S., Tapsuwan, S. (2010). Review of transportation choice research in Australia:
implications for sustainable urban transport design. In David Le Blanc and Ralph
Wahnschafft (eds) Natural Resources Forum (Vol. 34, No. 4, pp. 255–265). Oxford,
UK: Blackwell Publishing Ltd. https://doi.org/10.1111/j.1477-8947.2010.01310.x.
Janic, M. (2006). Sustainable transport in the European Union: a review of the past
research and future ideas. Transport Reviews, 26(1), 81–104.
https://doi.org/10.1080/01441640500178908.
Jin, Y., Xia, J., Pan, Z., Yang, J., Wang, W., Fu, Z. (2018). Polystyrene microplastics induce
microbiota dysbiosis and inflammation in the gut of adult zebrafish. Environmental
Pollution, 235, 322–329.
Khalil, S., Modibbo, U. M., Raina, A. A., Ali, I. (2023). A personnel selection problem in
healthcare system using fuzzy-TOPSIS approach. Journal of Nonlinear Modeling &
Analysis, 5(2), 311.
Khan, F., Ali, Y., Khan, A. U. (2020). Sustainable hybrid electric vehicle selection in the
context of a developing country. Air Quality, Atmosphere and Health, 13(4), 489–499.
https://doi.org/10.1007/s11869-020-00812-y.
Kumar, N., Brint, A., Shi, E., Upadhyay, A., Ruan, X. (2019). Integrating sustainable
supply chain practices with operational performance: an exploratory study of Chinese
SMEs. Production Planning & Control, 30(5–6), 464–478.
Li, M., Ming, P., Huo, R., Mu, H., Zhang, C. (2023). Optimizing design and performance
assessment of a sustainability hydrogen supply chain network: a multi-period model for
China. Sustainable Cities and Society, 92, 104444.
Long, Q., Zhang, W. (2014). An integrated framework for agent based inventory–
production–transportation modeling and distributed simulation of supply chains,
Information Sciences, 277, 567–581. https://doi.org/10.1016/j.ins.2014.02.147.
Modibbo, U.M., Gupta, S., Ahmed, A. et al. 2024 An integrated multi-objective multi￾product inventory managed production planning problem under uncertain environment.
Ann Oper Res, 339, 1679–1723. https://doi.org/10.1007/s10479-022-04795-0
Modibbo, U. M., Hassan, M., Ahmed, A., Ali, I. (2022). Multi-criteria decision analysis for
pharmaceutical supplier selection problem using fuzzy TOPSIS. Management Decision,
60(3), 806–836.
Olawumi, T. O., Chan, D. W. (2018). A scientometric review of global research on
sustainability and sustainable development. Journal of Cleaner Production, 183, 231–250. https://doi.org/10.1016/j.jclepro.2018.02.162
Palit, T., Mainul Bari, A. B. M., Karmaker, C. L. (2022). An integrated Principal
Component Analysis and Interpretive Structural Modeling approach for electric vehicle
adoption decisions in sustainable transportation systems, Decision Analytics Journal, 4,
100119. https://doi.org/10.1016/j.dajour.2022.100119.
Patel, R. G., Bhathawala, P. H., Patel, B. S. (2017). An alternate approach to find an
optimal solution of a transportation problem. IOSR Journal of Mathematics (IOSR-JM),
13(1), 1–5.
Pribadi, D. M., Chaereni, D., Dewanto, S. P., Subiyanto, S. S. (2019). Robust optimization
model for location transportation problems with ellipsoidal uncertainty set. World
Science News. An International Scientific Journal, 127(3), 296–310.
Sadiq, M., Moslehpour, M., Qiu, R., Hieu, V. M., Duong, K. D., Ngo, T. Q. (2023).
Sharing economy benefits and sustainable development goals: empirical evidence from
the transportation industry of Vietnam. Journal of Innovation & Knowledge, 8, 100290.
https://doi.org/10.1016/j.jik.2022.100290.
Salvi, B. L., Subramanian, K. A. (2015). Sustainable development of road transportation
sector using hydrogen energy system. Renewable and Sustainable Energy Reviews, 51,
1132–1155.
Seyed housseini, S. M., Ghoreyshi, S. M. (2014). An integrated model for production and
distribution planning of perishable products with inventory and routing considerations.
Mathematical Problem in Engineering. 2014, ID475606.
https://doi.org/10.1155/2014/475606
Singh, P., Elmi, Z., Meriga, V. K., Pasha, J., Dulebenets, M. A. (2022). Internet of Things
for sustainable railway transportation: past, present, and future. Cleaner Logistics and
Supply Chain, 4, 100065. https://doi.org/10.1016/j.clscn.2022.100065.
Sirsi, S. R., Hernandez, S. L., Zielinski, L., Blomback, H., Koubaa, A., Synder, M.,
Homma, S., Kandel, J. J., Yamashiro, D. J., Borden, M. A. (2012). Polyplex￾microbubble hybrids for ultrasound-guided plasmid DNA delivery to solid tumors.
Journal of Controlled Release, 157(2), 224–234.
Subbaih, T., Ramasamy, U. (2022). A stochastic constrained optimization on multi-echelon
renovated supply chain with sustainable production and transportation. Journal of
Cleaner Engineering and Technology, 10, 100547.
https://doi.org/10.1016/j.clet.2022.100547.
Sundarakani, B., De Souza, R., Goh, M., Wagner, S. M., Manikandan, S. (2010). Modeling
carbon footprints across the supply chain. International Journal of Production
Economics, 128, 43–50.
U.S. Energy Information Administration (EIA). (2019). Annual energy outlook.
https://www.eia.gov/outlooks/aeo/.
Vågan Municipality. (2019). Del 1: Kunnskaps-og drøftingsgrunnlag til Kommuneplanens
samfunnsdel 2020–2032. Utkast til høring etter vedtak i Formannskapet. Vågan.
Xueying, W., Sadiq, M., Chien, F., Ngo, T. Q., Nguyen, A. T. (2021). RETRACTED
ARTICLE: testing role of green financing on climate change mitigation: evidencesChapter 11
Digital supply chain management in
manufacturing industries
Seyydeh Atefeh Mousavi Abandansari, Kourosh Mokhtari, and Fariba
Goodarzian
DOI: 10.1201/9781003536796-11
11.1 INTRODUCTION
Digitalization has changed the way people communicate with their surroundings.
To benefit from the digital supply chain, it is necessary to use new approaches,
including digital transformation with smart technologies (Buyukozkan and Gocer
2019). Just as the increase in digital transformation leads to an increase in
cooperation in the supply chain, the role of smart technologies is such that it
reduces total costs and increases service performance as well as increases
cooperation with customers from the distribution of finished goods to the
manufacture and procurement of raw materials and cooperation with suppliers of
materials and services
The primary focus of organizations is to maintain and strengthen themselves in
competitive markets, so to expand and continue their powerful activities,
organizations must interact with their sellers through the digital supply chain
(DSC) for the production and delivery of their goods and services (Fethullah
Gocer 2018). Information technology is known as a tool for digitization,
achieving supply chain integration, and speeding up operational processes
(Razak, et al. 2023). It is true that digitalization has a great impact on the
performance of the organization, but it cannot always act as a stress-free process,
and it can sometimes challenge the business path (Kareem et al. 2024).
Considering that the production industry is evolving toward digitalization and
changing the multifaceted roles of supply chain managers to maintain thecompetitive advantages of organizations, managers should improve their
technical and commercial knowledge so that they can use their intelligent
interaction skills to maintain organizational leadership because supply chain plans
must be applicable across business units. The future of businesses is rooted in the
revolution of digital transformation, and progressive companies use new
technologies to succeed in the DSC, such as blockchain, Internet of Things, and
advanced robotics. New technologies and devices include smartphones,
computers, unmanned vehicles, and smart devices
Due to the digitization of the supply chain, businesses are managed with new
technologies and the interaction and communication between suppliers and
customers change in the supply chain processes (). DSC is an integrated set of
supply chain capabilities that uses digital technologies and data analysis to make
decisions based on reality, optimize resources and performance, and provide rapid
response to various conditions, which has a data warehouse that stores all the
information so that it can use them later to analyze the situation. With attention to
the extensive growth of the DSC in the future of businesses, creating a strong
business intelligence is essential, and if you can speak their language, potential
effects will be created in finance, sales, and marketing (Agrawal and Narain
2018). According to the capabilities of the DSC network, an organization with
this network must have six basic integrated capabilities, which include connected
customer, dynamic fulfillment, smart factory, smart supply, coordinated planning,
and digital development, all of which are fed from a central core called the digital
core.
The evolutionary movement of the supply chain toward digitalization brings
many benefits such as maximizing profits; reducing losses; optimizing supply
chain times; integrating research and development, production, marketing, sales,
and other internal operations; and creating new business models based on this
process. They are evolutionary (Hammi et al. 2023).
11.2 DIGITAL SUPPLY CHAIN
The fourth industrial revolution is related to digitization and the use of smart
technologies in the industry. Since traditional business models based on physical
activities faced serious challenges, the industry moved toward digitalization
(Kolberg et al. 2017). The revolution in industry and production (Industry 1) was
first formed with the invention of steam and waterpower (Schrauf and Berttram
2016). The use of electricity as a fuel source, the development of the telegraph,
and the growth of railroads were the key players that defined Industry 2.0. Before
moving toward digitization and establishment of the fourth revolution (Industry4), digital computer (Industry 3) was introduced as a part of the industry, which
entered the market based on digital and alpha numbers. Table 11.1 shows the
process of the industrial revolution, which is a long way toward Industry 4
(digitalization) in all aspects of business.
Table 11.1 Industrial revolution phases
Innovation
in
motorized
production
using
water and
steam
Implementation
of an electric
powered
machine and
combustion
engines for
mass production
Advance
automation
of
production
by using
electronics,
IT, and
industrial
robotics
Digital supply
chain (DSC)
Smart
manufacturing
Data analytics
Flexible
and
integrated
value
chain
networks
Computer
generated
for
customer
experience
Source: Adapted from Schrauf and Berttram (2016).
11.3 AIM OF SUPPLY CHAIN DIGITIZATION
In the IBM study of 2019, 84% of senior supply chain managers realized that
digitalization by creating better visibility, transparency, and accountability in the
entire supply chain leads to the elimination of inefficiency and waste throughout
the supply chain; therefore, the digitalization of the supply chain leads to
eliminating inefficient depots and creating benefits in automation, speed,
collaboration, cost reduction, and connectivity .
Considering the need for mutual and deep communication in the structure of
an organization, the information in the supply chain should be integrated so that
each organization can view the information throughout the system in real time
due to full access to the entire network. It has been possible with the emergence
of the fourth wave of the industry, i.e., the DSC.
The DSC using new technologies such as augmented reality (AR), big data,
artificial intelligence, machine learning, and blockchain, focusing on
customers/consumers, and reducing intra-organizational and inter-organizational
1800
Industry 1 1900 Industry 2 1970
Industry 3
2015 Industry
4
2030
Digital
ecosystemcosts creates more value for businesses (Olga 2020). Due to the COVID-19
pandemic, traditional supply chains were disrupted, and retailers suddenly left the
chain. Due to these disruptions in business, the digitalization of processes,
including the supply chain, was at the forefront of business discussions, and the
technologies that had supported DSCs and were trying to invest in and strengthen
their supply chains were in a better position (Aja Kumar et al. 2022).
Therefore, considering the benefits of digitalization of the industry, especially
the supply chain, companies should change their practices and provide the
necessary strategies and tools to move toward the DSC (); also, companies should
improve the level of adaptability and implement digital technologies
appropriately at the organization level (Frank et al. 2019). Considering that the
DSC is an intelligent system that connects different parts through a network of
sensors and social technologies and is moving toward a complete digital
ecosystem, according to Figure 11.1, raw material suppliers and parts, the
production process of warehouses, distributors of final products, and finally, the
customers and then their communication are managed through a control center
and a general data analysis engine (Füchtenhans et al., 2021,2022).
Figure 11.1 Digital supply chain ecosystem.Figure 11.2 shows an integrated DSC ecosystem. It demonstrates a digital
supply ecosystem versus a traditional linear supply chain that provides a complete
view of the supply chain and information available to all members and develops
collaboration, rapid assessment of changes in demand and customer preferences,
quick coordination, correct planning, and implementation of customer requests
along with follow-ups and checking the status and quality of products.
Figure 11.2 Importance and benefits of digital supply chain.
Considering the capabilities of the DSC that allows organizations to respond to
problems without prior planning and the ability to integrate information
technology (IT) systems and operational technology (OT) systems to optimize the
level of benefits and services, generally, supply chain digitization offers several
advantages as follows (Benno Gerlach et al. 2021; Samuel et al. 2020; ):
Visibility improvement in supply chain performance
Automation of the process
Reducing costs and accelerating innovation
Advanced data and analytics
Improvement of supply chain planning
11.4 THE POTENTIAL IMPACT OF THE DIGITAL
SUPPLY CHAIN
As per the Mackenzie report (2016), according to the 30% reduction in operating
costs and the 75% reduction in the number of lost sales and the correlation of
three indicators of operating costs, the number of lost sales, and the level of
inventory, the effects of digitalization of the supply chain can be observed in the
industry, and indeed, an improved inventory profile will lead to improved servicelevels and lower costs. Therefore, there are three steps of digitization, which are
listed below (Khailoon Lee et al. 2022):
1. Digitization strategy
2. Organization and digital culture
3. Digital operations
Digitization strategy focuses on the planning and implementation of digital
technologies to improve business performance. Organization and digital culture
analyzes and manages the current organization and culture. The focus of digital
operations is on empowerment, operations management, and implementation of
digital operations. European companies heavily use digitalization in their business
models (Kearnecy 2015). DSC is only viable when companies properly plan to
provide data information at all points in an intelligent network system in real time
so that organizations and factories can create a fully digitized industry and supply
chain sector based on advances in data analytics (Martis et al. 2018). Therefore,
according to the Mackenzie research (2017), the digitalization of the industry can
have a tremendous impact on (i) lost sales (services) of the supply chain, (ii)
supply chain costs, and (iii and iv) supply chain planning and inventory.
11.4.1 Lost sales (supply chain services)
By improving interaction with customers and using all available data (point of
sale) in the forecasting process, improvements have been achieved, and by using
methods to influence the demand for a specific product (such as applying
discounts and lowering pricing) according to changes and creating orders, service
level is increased, and lost sales are reduced.
11.4.2 Supply chain costs
By optimizing the network, it is possible to reduce the number of times it takes to
meet the customer while maintaining the level of service required by the
customer, and by using intelligent automation and improving the efficiency of
storage, the cost structure of the transport units carrying goods can be reduced.
11.4.3 Supply chain planning
With the help of intelligent and networked systems, all demand planning,
preparation process for operations and sales, production planning, and supplyplanning can be done automatically. These smart plans will have an impact on
service costs, supply chain, and inventory.
11.4.4 New planning algorithms
With the implementation of new planning algorithms, uncertainty, preparation
time, and long duration of the transportation process will be reduced, and the
production of more accumulated volume (lot size) and rapid change will lead to
maintaining the inventory.
11.5 DIGITAL SUPPLY CHAIN ON
ORGANIZATION PERFORMANCE
Supply chain integration acts as a mediator between supply chain digitization and
company performance. Digitalization of the supply chain can guide the supply
chain in operations. And in fact, both the integration and digitization of the supply
chain have a positive effect on the company’s performance (Kampui, 2021).
Digital integration technologies moderate various company functions such as
materials management, planning, scheduling, transportation, inventory, and
warehousing and move the company toward common goals. Also, Zaki, (2019)
state that the use of digital technologies enables the implementation of
transactions, communication, and actions. The connection of supply protection
(SUP) and Systems Applications and Products (SAP) technologies allows
Uniform Packaging Service (UPS) to print items directly using 3D printing in
distribution centers; these digital technology applications increase the speed,
efficiency, and flexibility of the supply chain (). Digital technologies include
BDA (big data analysis), advanced manufacturing technologies with sensors and
agent-based decentralized control, advanced robotics, AR, and advanced
technologies. Digitization in the supply chain can play an important role in
creating integration in the organization (by Omoruyi and Akuoma, 2020).
According to the report by ) Premkumar et al. (1994), the adoption of electronic
data interchange (EDI) has significant benefits in the assembly industry by
facilitating the integration of information in the supply chain process and greatly
reducing transportation errors. Integrating the supply chain process with
enterprise resource planning (ERP) and customer relationship management
(CRM) digital tools ensures stability in the company’s performance (Kuada, and
Serles 2006).11.6 SUPPLY CHAIN INTEGRATION IN THE
PERFORMANCE OF ORGANIZATIONS
Supply chain integration will not be possible if there is no internal integration. In
internal integration, companies can integrate and collaborate across traditional
functional boundaries to improve customer service (Khan and Mentzer 1996). In
internal integration, the company’s functions are known as an integrated process.
By integrating activities across different functions, production schedule, customer
order status, and real-time information can be shared, which improves
organizational performance (Frolich and Westbrook 2001, Gimens 2006). Also,
according to the reports by Jayaram and XU (2013), there is no significant
relationship between supplier integration and flexibility performance.
According to the report by Kam and Weisheng (2021), digital technology
investors should focus on the internal integration processes of the supply chain,
which can be obtained from the ERP system that facilitates the integration of
various processes, data, and functions in a company. The ERP system supports all
business processes from order processing to product distribution.
11.7 DIGITALIZATION IMPACT WITH SUPPLY
CHAIN INTEGRATION ON ORGANIZATION
PERFORMANCE
Figure 11.3 shows the relationship between supply chain digitization, supply
chain integration, and organization performance. In the following, we will explain
the details according to Figure 11.3.Figure 11.3 Relationship between digitalization, supply chain
integration, and organization performance
A. – Digitization of the supply chain has a positive effect on the performance of
the organization.
B. – Digitization of the supply chain has a positive effect on internal
integration.
C. – Internal integration has a positive effect on company performance.
D. – Internal integration mediates the relationship between supply chain
digitalization and firm performance.
E. – Digitalization of the supply chain moderates the relationship between
internal integration and firm performance.
11.8 CONCLUSION
How digitization relates to supply chain integration to improve firm performance
is still unclear. Integration is very important for a successful supply chain
management and optimal company performance, but the understanding of the
necessary conditions to achieve integration is still unclear, and in fact, it is
expected that digitalization affects internal integration, and internal integration is
related to performance. Digitization in the supply chain through programs that areshared internally and externally with the company increases the efficiency of
energy consumption and the effectiveness of the supply chain, and in fact,
digitalization in the supply chain can be a strong integration in domestic
companies and create external ones that are involved in effective and efficient
decision-making. And the use of electronic programs allows the company to
receive warnings faster in case of disruptions in the supply chain. This study
showed that digital transformation provides opportunities for organizations to
achieve relationship performance by using smart technologies and improve
relationship performance in the supply chain. Also, this study shows that
managers are worried about the future of their organization and are trying to
invest in supply chains to prevent their organization from leaving the competitive
market. They should focus on how to integrate digitalization with current systems
to improve internal and external performance, invest in smart technologies, and
complete the company’s strategies.
REFERENCES
Agrawal, P., & Narain, R. 2018. Digital supply chain management: An
Overview. In IOP conference series: materials science and engineering
(Vol. 455, No. 1, p. 012074). IOP Publishing.
Buyukozkan, G., & Gocer, F. 2019. A novel approach integrating AHP and
COPRAS under Pythagorean fuzzy sets for digital supply chain partner
selection. IEEE Transactions on Engineering Management, 68(5), 1486–
1503.
Frank, A. G., Mendes, G. H., Ayala, N. F., & Ghezzi, A. 2019. Servitization
and Industry 4.0 convergence in the digital transformation of product
firms: A business model innovation perspective. Technological
Forecasting and Social Change, 141, 341–351.
Füchtenhans, M., Grosse, E. H., & Glock, C. H. 2021. Smart lighting
systems: state-of-the-art and potential applications in warehouse order
picking. International Journal of Production Research, 59(12),
38173839.
Göçer, F. 2018. Modeling and design of digital supply chain (Doctoral
dissertation, PhD Thesis]. Galatasaray University).
Hammi, B., Zeadally, S., & Nebhen, J. (2023). Security threats,
countermeasures, and challenges of digital supply chains. ACM
Computing Surveys, 55, 316.Jayaram, J., & Xu, K. 2013. The relative influence of external versus internal
integration on plant performance in China. International Journal of
Production Economics, 146(1), 59–69.
Kareem, H. M., Alsheikh, A. H., Alsheikh, W. H., Dauwed, M., & Meri, A.
2024. The mediating role of accounting information systems in small and
medium enterprise strategies and organizational performance in Iraq.
Humanities and Social Sciences Communications, 11(1), 1–12.
Kearney, E. 2015. Intercultural learning in modern language education:
Expanding meaning-making potentials (Vol. 28). Multilingual Matters.
Kuada, J., & Serles, D. 2006. Customer relationship marketing (CRM)
practices in Danish small businesses. International Management Review,
2(4), 28–44.
Kumar, A., Gupta, J., & Das, N. 2022. Revisiting the influence of corporate
sustainability practices on corporate financial performance: An evidence
from the global energy sector. Business Strategy and the Environment,
31(7), 3231–3253.
Lee, K., Azmi, N., Hanaysha, J., Alzoubi, H., & Alshurideh, M. (2022). The
effect of digital supply chain on organizational performance: An
empirical study in Malaysia manufacturing industry. Uncertain Supply
Chain Management, 10(2), 495–510.
Martis, R. J., Gurupur, V. P., Lin, H., Islam, A., & Fernandes, S. L. 2018.
Recent advances in big data analytics, internet of things and machine
learning. Future Generation Computer Systems, 88, 696–698.
Olga, C. 2020. Social and labour rights of “new” self-employed persons (and
in particular self-employed platform workers) in Russia. Russian Law
Journal, 8(2), 49–78.
Omoruyi, O., & Akuoma, M. E. 2020. The influence of supply chain
management on the performance of small to medium enterprises in
Southern Gauteng. International Journal of Economics and Finance
Studies, 12(1), 172–188.
Premkumar, G., Ramamurthy, K., & Nilakanta, S. 1994. Implementation of
electronic data interchange: an innovation diffusion perspective. Journal
of Management Information Systems, 11(2), 157–186.
Razak, G. M., Hendry, L. C., & Stevenson, M. 2023. Supply chain
traceability: A review of the benefits and its relationship with supply
chain resilience. Production Planning & Control, 34(11), 1114–1134.Schrauf, S., & Berttram, P. 2016. Industry 4.0: How digitization makes the
supply chain more efficient, agile, and customer-focused. Strategy
&Technology, 1–32. https://doi.org/10.1007/s10888-014-9291-x
Zaki, M. 2019. Digital transformation: harnessing digital technologies for
the next generation of services. Journal of Services Marketing, 33(4),
429–435.Chapter 12
A green fractional transportation system under
dual hesitant Fermatean fuzzy configuration with
safety factor
M. K. Sharma, Sadhna Chaudhary, Laxmi Rathour, and Vishnu Narayan Mishra
DOI: 10.1201/9781003536796-12
12.1 INTRODUCTION
Transport is a crucial component of logistics and operational management, and Hitchcock (1941)
was the first to introduce the concept of transportation problems (TPs). The solid transportation
problem (STP), created by Haley (1962), is an extension of TP where the objective and constraint
sets employ third-dimension attributes, namely mode of transportation instead of availability and
demand. Conflicting objectives are merged into a single overall utility function using multi￾objective transportation problems (MOTPs).
Numerous industries use linear fractional programming, including finance, production
planning, and transport issues. In TPs, fractional objective functions are a method for
performance evaluation. Fractional transportation problems (FTPs) are issues in moving goods
from various origins to targets while attempting to keep stable relationships between several
essential characteristics. FTP was first introduced by Swarup (1966) and since then has been
widely used in supply-chain management for cost reduction and service enhancement. It deals
with the ratio optimization of key parameters where the ratios are considered objective functions.
There is uncertainty virtually always in real-world systems. The fuzzy set (FS) was introduced
by Zadeh (1965) as a potent tool for describing inconsistent, inaccurate, and imprecise
information in practical contexts to address these sorts of uncertainty. It has a function for
membership that gives each element a value between [0,1] and specifies how much of a member
each element is. Since the non-membership function is excluded and the potential for hesitating
margin is ignored, the FS theory notion appears to be inconclusive. In this critique of these flaws,
Atanassov (1986) put out the idea of intuitionistic fuzzy sets (IFSs) that combine membership
and non-membership functions with hesitation margin. Torra (2010) proposed the hesitant fuzzy
set (HFS) to the FS theory. Later, the dual hesitant fuzzy set (DHFS) was proposed by Zhu et al.
(2012) as an expansion of HFS. Later, Yager (2013) generalized IFS to Pythagorean fuzzy set
(PFS). FFS was presented by Senapati and Yager (2020) to address the uncertainty embedded in
real-world situations. Recently, Zhou et al. (2022) put forward dual hesitant Fermatean fuzzy set
(DHFFS) as an extensive tool to cope up with impreciseness. A set of membership and non￾membership degrees that meet the requirements of FFS are involved.Later, several researchers shared work on FTP with multiple objectives under uncertain
environments. Liu (2016) examined the FTP using fuzzy parameters that considered demand
availability and cost aspects. Goal programming methodology is proposed by Anukokila et al.
(2019) to solve FTP that involves multiple goals. El Sayed and Abo-Sinna (2021) proposed a
novel methodology to address the FTP with various goals with all parameters taken as IF.
Sharma et al. (2021) proposed an approach to tackle FTP with multiple objectives where
variables are fuzzy by incorporating aspirational levels. Khalifa et al. (2021) analyzed fractional
solid TP with two stages under it, here cost, demand, supply, and conveyance capacities are fuzzy.
Also, fuzzy geometric methodology is applied to tackle the aforementioned model.
The following summarizes the main points of the research described in this chapter:
First, we devised a green multi-objective fractional STP (G-MOFSTP) to intensify green
transportation with safety factors under DHFF settings.
Here, our goals are to minimize transportation cost (TC) and carbon emission (CE)
simultaneously.
Here after using the ranking function of dual hesitant fermatean fuzzy experiment (DHFFE),
we utilize fuzzy programming (FP) and global criterion method (GCM) to deal with the
proposed sustainable transportation system.
Also, a numerical computation is presented to emphasize the proposed model.
The entire work is laid out as follows: The fundamentals of FTP, FS theory, DHFFS, and a review
of related literature are covered in Section 12.1. The DHFFS and its scoring function are briefly
discussed in Section 12.2. The mathematical modeling of the G-MOFTP with safety
considerations is described in Section 12.3. A procedure for managing the recommended model is
presented in Section 12.4 utilizing FP and GCM. The numerical computations in Section 12.5 are
done to highlight the suggested methodology. Section 12.6 offers findings as well as
recommendations for further study.
12.2 DUAL HESITANT FUZZY SET (DHFFS)
12.2.1 Definition
A DHFFS is defined as,
d
f = {x, h
f (x),i
f (x) : x ∈ X}
s.t h
f (x)andi
f (x) are set of membership and non-membership degrees satisfying
0 ≤ θ, ϑ ≤ 1, 0 ≤ (θ+)
3 + (ϑ
+)
3 ≤ 1
θ ∈ h
f (x), ϑ ∈ i
f (x), θ+ ∈ (h
f )
+
(x) = ∪θ∈h max {θ}, andϑ
+ ∈ (i
f )
+
(x) = ∪ϑ∈i max {ϑ}.
Here, X is taken as a fixed set.
12.2.2 Elementary operations on DHFFSTake three DHFFEs d
f = (h
f
,i
f ), d
f
1 = (h
f
1
,i
f
1) and d
f
2 = (h
f
2
,i
f
2) and Λ > 0 be a scalar.
Then, the basic laws are as:
i. (d
f )
c = ∪θ∈hf
,ϑ∈if {{ϑ}, {θ}}
ii. d
f
1 ⊕ d
f
2 = ∪θ1∈h
f
1
,θ2∈h
f
2
,ϑ1∈i
n
1
,ϑ2∈i
n
2 {{√3 (θ1)
3 + (θ2)
3 − (θ1)
3(θ2)
3}, {ϑ1ϑ2}}
iii. d
f
1 ⊗ d
f
2 = ∪θ1∈h
f
1
,θ2∈h
f
2
,ϑ1∈i
f
1
,ϑ2∈i
f
2 {{θ1θ2}, {√3
(ϑ1)
3 + (ϑ2)
3 − (ϑ1)
3(ϑ2)
3}}}
i. Λ ⊙ d
f = ∪θ∈hf
,ϑ∈if {√3 1 − (1 − θ
3)
Λ
, {ϑ
Λ}}
ii. (d
f )
Λ = ∪θ∈h
f
,ϑ∈i
f {{θΛ},√3 1 − (1 − ϑ3)
Λ}
12.2.3 Score function
For d
f = (h
f
,i
f ), so the score function is stated as:
S
*
f (d
f ) = 1
N(xi) ∑xi∈x
xi + 1
N(hf ) ∑
α∈hf
α
3 − 1
N(if ) ∑
β∈if
β
3
,
where N (xi), N (h
f )andN (i
f ) depicts the number of elements of x, h
fandi
f
, respectively.
12.3 MATHEMATICAL MODELING
The primary objective of this section is to configure a G-MOFSTP employing DHFF settings. To
improve the safety precautions while transporting, we also include a safety feature in our model.
The primary goals in the present scenario are to simultaneously optimize TC and CE. In our
model, goals are expressed as fractions involving the ratio of actual to standard TC and CE
measures. Additional parameters like demand, availability, TC, and CE, however, are expressed
as DHFFs. While other safety concerns and overall safety measures are crisp, the notations in
Table 12.1 determine the mathematical formulation of our proposed model as follows.
Table 12.1 Assumptions and notations
Index
i Origin (i = 1,2,3 … I)
j Destination (j = 1,2,3 … J)
k Conveyances (k = 1,2,3 … K)
Parameters
⎛
⎝
⎞
⎠
Symbol Description˜ai DHFF availability of ith origin
˜bj DHFF demand of jth destination
e˜k DHFF capacity of kth mode of conveyance
c˜A
ijk Actual DHFF-TC per unit transited from ith origin to jth destination by kth
conveyances
c˜
S
ijk Standard DHFF-TC per unit transited from ith origin to jth destination by kth
conveyances
g˜A
ijk Actual DHFF-CE per kilometer by kth conveyances from ith source to jth
destination
g˜
S
ijk Standard DHFF-CE per kilometer by kth conveyances from ith source to jth
destination
xijk Quantity of goods transit by kth conveyances from ith source to jth destination
yijk Binary variables defined as yijk = {
sijk Crisp safety factors
S Overall safety of the model
Zn Objective function (n = 1, 2)
The mathematical formulation of our proposed green model under DHFF settings is as follows:
Model 1
Minimization of total TC
MinZ1 = ∑I
i=1∑J
j=1∑L
l=1
c˜A
ijkxijk
∑I
i=1∑J
j=1∑L
l=1
c˜
S
ijkxijk
Minimization of total CE
MinZ2 = ∑I
i=1∑J
j=1∑L
l=1
g˜A
ijkxijk
∑I
i=1∑J
j=1∑L
l=1
g˜
S
ijkxijk
s.t
J
∑
j=1
K
∑
k=1
xijk ≤ ˜ai
I
∑
i=1
K
∑
k=1
xijk ≥ ˜bj
Symbol Description
1ifxijk > 0
0otherwiseI
∑
i=1
J
∑
j=1
xijk ≤ e˜k
xijk ≥ 0, ∀i, j, k
The conditions of feasibility for our proposed model 1 are as follows:
I
∑
i=1
˜ai ≥
J
∑
j=1
˜bj;
K
∑
k=1
e˜k ≥
J
∑
j=1
˜bj
Now, by utilizing proposed ranking function, we obtained deterministic form of model 1 as it is
impassable to address model 1 in its present form.
Model 2
Minimization of total TC
MinZ1 = ∑I
i=1∑J
j=1∑L
l=1 S(c˜A
ijk)xijk
∑I
i=1∑J
j=1∑L
l=1 S(c˜
S
ijk)xijk
Minimization of total CE
MinZ2 = ∑I
i=1∑J
j=1∑L
l=1 S(g˜A
ijk)xijk
∑I
i=1∑J
j=1∑L
l=1
S(g˜
S
ijk)xijk
s.t
J
∑
j=1
K
∑
k=1
xijk ≤ S (˜ai)
I
∑
i=1
K
∑
k=1
xijk ≥ S (˜bj)
I
∑
i=1
J
∑
j=1
xijk ≤ S (e˜k)
xijk ≥ 0, ∀i, j, k
The conditions of feasibility for our proposed model 2 are as follows:
I
∑
i=1
S (˜ai) ≥
J
∑
j=1
S (˜bj);
K
∑
k=1
S (e˜k) ≥
J
∑
j=1
S (˜bj)
12.4 PROPOSED METHODOLOGYWe developed a plan employing FP and Weighted Sum Technique (WST) to deal with the green
fractional transit system we proposed. A graphical representation of the recommended algorithm
is shown in Figure 12.1. Figure 12.1 depicts various steps involved in the proposed methodology
to deal with green transportation system.
Figure 12.1 Systematic flow chart of proposed algorithm.
Fuzzy Programming (FP)
Step 1: Consider every constraint while addressing each objective separately.
Step 2: Use the lower (Ln) and upper bounds (Un) of each aim to create the membership
function.
πn (Zn (x)) =
where n = 1, 2
Step 3: Handle model 3 for acceptance degree β using LINGO 20.
Model 3
Max β
s.t. φn (Zn (x)) ≥ β (n = 1, 2)
⎧
⎪⎨
⎩
1 Zn (x) ≤ Ln
Un−Zn(x)
Un−Ln Ln < Zn (x) < Un
0 Zn (x) ≥ Unβ ∈ [0, 1]
J
∑
j=1
K
∑
k=1
xijk ≤ S (˜ai)
I
∑
i=1
K
∑
k=1
xijk ≥ S (˜bj)
I
∑
i=1
J
∑
j=1
xijk ≤ S (e˜k)
xijk ≥ 0, ∀i, j, k
Global Criterion Method (GCM)
Step 1: Tackle one objective at a time.
Step 2: Analyze the upper and lower limits for each goal.
Step 3: Solve model 4 for Z (x).
Model 4
MinZ (x) = [
4
∑s=1
(
Zs(X)−Z
min
s
Z max
s −Z min
s
)
2
]
1
2
s.t
J
∑
j=1
K
∑
k=1
xijk ≤ S (˜ai)
I
∑
i=1
K
∑
k=1
xijk ≥ S (˜bj)
I
∑
i=1
J
∑
j=1
xijk ≤ S (e˜k)
xijk ≥ 0, ∀i, j, k
Step 4: Utilize Lingo 20.0 to solve model 4
12.5 NUMERICAL COMPUTATION
This section elaborates on an illustration to show the significance of the suggested green
fractional STP. Let us have a glimpse at an example for the transportation of goods using ourproposed model. Table 12.2, Table 12.3, Table 12.4, Table 12.5, Table 12.6 and Table 12.7
provide all necessary inputs.
Table 12.2 Actual DHFF-TC
1 1 1 {(1, 2), {0.1, 0.3}, {0.2, 0.4}} 1.478
2 {(2, 3), {0.1, 0.2}, {0.1, 0.3}} 2.364
2 1 {(2, 4), {0.2, 0.5}, {0.1, 0.2}} 3.062
2 {(2, 3), {0.2, 0.4}, {0.1, 0.5}} 2.473
1 1 1 {(1, 2), {0.2, 0.3}, {0.2, 0.1}} 1.503
2 {(3, 4), {0.3, 0.1}, {0.2, 0.5}} 3.447
2 1 {(1, 5), {0.3, 0.4}, {0.2, 0.5}} 2.979
2 {(2, 1), {0.2, 0.6}, {0.5, 0.3}} 1.536
Table 12.3 Standard DHFF-TC
1 1 1 {(1, 4), {0.1, 0.3}, {0.2, 0.4}} 2.478
2 {(5, 3), {0.1, 0.2}, {0.1, 0.3}} 3.990
2 1 {(2, 1), {0.2, 0.5}, {0.1, 0.2}} 1.512
2 {(2, 5), {0.2, 0.4}, {0.1, 0.5}} 3.473
1 1 1 {(3, 2), {0.2, 0.3}, {0.2, 0.1}} 2.513
2 {(3, 5), {0.3, 0.1}, {0.2, 0.5}} 3.947
2 1 {(2, 5), {0.3, 0.4}, {0.2, 0.5}} 3.479
2 {(2, 3), {0.2, 0.6}, {0.5, 0.3}} 2.536
Table 12.4 Actual DHFF-CE
1 1 1 {(5, 2), {0.4, 0.3}, {0.6, 0.4}} 3.4055
2 {(1, 1), {0.1, 0.6}, {0.1, 0.3}} 1.0945
2 1 {(2, 2), {0.2, 0.1}, {0.8, 0.2}} 1.7445
Source
(i)
Destination
(j)
Conveyances
(k) Actual DHFF-TC Score
value
Source
(i)
Destination
(j)
Conveyances
(k) Standard DHFF-TC Score
value
Source
(i)
Destination
(j)
Conveyances
(k) Actual DHFF-CE Score
value2 {(6, 3), {0.5, 0.4}, {0.8, 0.5}} 4.2135
1 1 1 {(3, 2), {0.2, 0.1}, {0.2, 0.6}} 2.3925
2 {(1, 4), {0.2, 0.6}, {0.7, 0.5}} 2.378
2 1 {(5, 2), {0.3, 0.8}, {0.2, 0.6}} 3.5975
2 {(6, 1), {0.3, 0.5}, {0.5, 0.3}} 3.5
Table 12.5 Standard DHFF-CE
1 1 1 {(4, 2), {0.4, 0.3}, {0.6, 0.4}} 2.9055
2 {(1, 3), {0.1, 0.6}, {0.1, 0.3}} 2.0945
2 1 {(2, 1), {0.2, 0.1}, {0.8, 0.2}} 2.489
2 {(6, 1), {0.5, 0.4}, {0.8, 0.5}} 3.276
1 1 1 {(4, 2), {0.2, 0.1}, {0.2, 0.6}} 2.8925
2 {(3, 4), {0.2, 0.6}, {0.7, 0.5}} 3.378
2 1 {(5, 4), {0.3, 0.8}, {0.2, 0.6}} 4.6575
2 {(6, 3), {0.3, 0.5}, {0.5, 0.3}} 4.5
Table 12.6 DHFF availability, demand, and capacity of conveyances
˜a1 {(100, 110), {0.8, 0.3}, {0.6, 0.5}}, 105.099
˜a2 {(120, 130), {0.4, 0.3}, {0.9, 0.5}}, 124.618
˜b1 {(80, 85), {0.9, 0.3}, {0.6, 0.2}} 82.766
˜b2 {(70, 80), {0.7, 0.3}, {0.5, 0.2}} 75.105
e˜1 {(90, 100), {0.7, 0.5}, {0.4, 0.1}}, 95.2015
e˜2 {(110, 120), {0.8, 0.6}, {0.5, 0.4}} 115.269
Table 12.7 Crisp
safety factor
Source
(i)
Destination
(j)
Conveyances
(k) Actual DHFF-CE Score
value
Source
(i)
Destination
(j)
Conveyances
(k) Standard DHFF-CE Score
value
Parameters DHFF-form Score value
Parameter Values111 0.5
s112 0.75
s121 0.25
s122 0.75
s211 0.45
s212 0.9
s221 0.5
s222 0.3
S 10
MinZ1 =
1.478x111+2.364x112+3.062x121+2.473x122+1.503x211+3.447x212+2.979x221+1.536x222
2.478x111+3.990x112+1.512x121+3.473x122+2.513x211+3.947x212+3.479x221+2.536x222
MinZ2 =
3.4055x111+1.0945x112+1.7445x121+4.2135x122+2.3925x211+2.378x212+3.5975x221+3.5x222
2.9055x111+2.0945x112+2.489x121+3.276x122+2.8925x211+3.378x212+4.6575x221+4.5x222
s.t
x111 + x112 + x121 + x122 ≤ 105.099
x211 + x212 + x221 + x222 ≤ 124.618
x111 + x112 + x211 + x212 ≥ 82.766
x121 + x122 + x221 + x222 ≥ 75.105
x111 + x121 + x211 + x221 ≤ 95.2015
x112 + x122 + x212 + x222 ≤ 115.269
After employing the proposed methodology, the optimal values for our proposed model are
presented in Table 12.8.
Table 12.8 Optimal values of objectives
FP Z1
 = 0.723, Z2
 = 0.672
x112 = 70, x121 = 35.09, x212 = 12.766, x221 = 20.3, x222 = 19.66 and rest are
Parameter Value
0.5x111 + 0.75x112 + 0.25x121 + 0.75x122 + 0.45x211
+ 0.9x212 + 0.5x221 + 0.3x222 ≥ 10
Methodology Solutionzero
GCM Z1
 = 0.796, Z2
 = 0.817
x112 = 82.76, x121 = 22.33, x221 = 33.1, x222 = 19.66 and rest are zero
The optimum result obtained by FP is as follows: Z1 = 0.723,Z2 = 0.672. On the other hand,
the results obtained by using GCM are as follows: Z1 = 0.796,Z2 = 0.817. The comparison of
results obtained by using FP and GCM is depicted in Figure 12.2. This figure compares the
optimal values of TC and CE obtained by utilizing FP and GCM. Here, we conclude that FP gives
better results as compared to GCM.
Figure 12.2 Comparison of results.
12.6 CONCLUSION
An FTP is a generalization of the TP that deals with the problems associated with fractional
objective function. Studies in the past have primarily dealt with deterministic cases, which means
that all parameters can be precisely assigned. There are, however, cases in which model
parameters can be inaccurate and imprecise. First, to further develop green transportation with
safety considerations in DHFF circumstances, we developed G-MOFTP. Our objectives in the
present instance are to simultaneously lower TC and CE. After utilizing the DHFFE ranking
function, we deal with the proposed sustainable transport system using FP and GCM. The results
based on the numerical of proposed model show that FP efficiently addressed our proposed model
as compared to GCM.
REFERENCES
Methodology SolutionAnukokila, P., Radhakrishnan, B., & Anju, A. (2019). Goal programming approach for
solving multi-objective fractional transportation problem with fuzzy parameters. RAIRO￾Operations Research, 53(1), 157–178. https://doi.org/10.1051/ro/2019005
Atanassov, K. (1986). Intuitionistic fuzzy sets. Fuzzy Sets and Systems, 20, 87–96.
https://doi.org/10.1016/S0165-0114(86)80034-3
El Sayed, M. A., & Abo-Sinna, M. A. (2021). A novel approach for fully intuitionistic fuzzy
multi-objective fractional transportation problem. Alexandria Engineering Journal,
60(1), 1447–1463. https://doi.org/10.1016/j.aej.2020.10.063
Haley, K. (1962) The solid transportation problem. Operation Research, 10, 448–463.
Hitchcock, F. L. (1941). The distribution of a product from several sources to numerous
localities. Journal of Mathematics and Physics, 20(1–4), 224–230.
Khalifa, H. A. E. W., Kumar, P., & Alharbi, M. G. (2021). On characterizing solution for
multi-objective fractional two-stage solid transportation problem under fuzzy
environment. Journal of Intelligent Systems. https://doi.org/10.1515/jisys-2020-0095
Liu, S. T. (2016). Fractional transportation problem with fuzzy parameters. Soft Computing,
20(9), 3629–3636. https://doi.org/10.1007/s00500-015-1722-5
Senapati, T., & Yager, R. R. (2020) Fermatean fuzzy sets. Journal of Ambient Intelligence
and Humanized Computing, 11, 663–674. https://doi.org/10.1007/s12652-019-01377-0
Sharma, M. K., Kamini, Dhiman, N., Mishra, V. N., Rosales, H. G., Dhaka, A.,. & Mishra,
L. N. (2021). A fuzzy optimization technique for multi-objective aspirational level
fractional transportation problem. Symmetry, 13(8), 1465.
https://doi.org/10.3390/sym13081465
Swarup, K. (1966). Transportation technique in linear fractional programming. Journal of
Royal Naval Scientific Service, 21, 256–226.
Torra, V. (2010). Hesitant fuzzy sets. International Journal of Intelligent Systems, 25, 529–
539. https://doi.org/10.1002/int.20418
Yager, R. R. (2013). Pythagorean fuzzy subsets. Joint IFSA world congress and NAFIPS
annual meeting (IFSA/NAFIPS), 57–61. https://doi.org/10.1109/IFSA￾NAFIPS.2013.6608375
Zadeh, L. A. (1965). Fuzzy sets. Information and Control, 8, 338–353.
https://doi.org/10.1016/S0019-9958(65)90241-X
Zhou, L., Chaudhary, S., Sharma, M. K., Dhaka, A., & Nandal, A. (2022). Artificial neural
network dual hesitant fermatean fuzzy implementation in transportation of COVID-19
Vaccine. Journal of Organizational and End User Computing, 35(2), 1–23.
https://doi.org/10.4018/JOEUC.321169
Zhu, B., Xu, Z., & Xia, M. (2012). Dual hesitant fuzzy sets. Journal of Applied
Mathematics. https://www.hindawi.com/journals/jam/2012/879629/</U&gtChapter 13
Application of hybrid SVM-LR algorithm
for sentiment analysis
P. A. Ashoshi and M. A. Hambali
DOI: 10.1201/9781003536796-13
13.1 INTRODUCTION
The global evolution of technology and changes in sociocultural behavior have
brought about a dynamic revolution worldwide. Consequently, individuals now
share their ideas, thoughts, beliefs, opinions, and decisions in real time on various
platforms like Twitter, Facebook, and LinkedIn (Mohammad 2017). However,
extracting valuable insights from this textual data presents a significant challenge
due to the immense volume of information from a large population and the
complexities involved in quantifying the text data for informed decision-making
during its analysis (Mohammad 2017). Sentiment analysis, also known as opinion
mining, is the field of study that qualitatively assesses opinions, sentiments,
evaluations, appraisals, attitudes, and emotions toward entities such as products,
services, organizations, individuals, issues, events, topics, and their attributes. It
categorizes reviews into predefined polarities (Dey et al. 2018). This research
area is closely linked to computational linguistics, natural language processing,
and text mining, stemming from the study of affective state in psychology and
judgment in appraisal theory (Birjali, Kasri, and Beni-Hssane 2021).
In today’s sentiment analysis, having clear and precise instructions is crucial to
obtaining high-quality annotations. Nonetheless, sentiment reviews are
unstructured and can carry diverse meanings within the lexicon, making the
classification of sentiment polarity challenging (Agaian and Kolm 2017).
Typically, sentiment polarity is simplified into positive and negative for a specific
text feature (Phan et al. 2020). Documents containing multiple opinionatedstatements often exhibit mixed polarity, further complicating sentiment analysis
(Phan et al. 2020). It’s important to note that sentiment, whether positive or
negative, is not isolated; it considers an individual’s emotional expression
(Cachola et al. 2018). The toxic nature of sentiment can negatively impact a
person’s well-being, leading to a reluctance to express themselves and seek
diverse opinions to make informed decisions. For businesses, firms, governments,
and organizations, this can result in financial losses.
The challenges in sentiment analysis primarily arise from the complexity and
ambiguity of the data, as well as sparse, diverse, high-dimensional, and dynamic
dataset characteristics (Ghanbari-Adivi and Mosleh 2019). However, another
significant challenge lies in interpreting intentions from vague sentiments.
Consequently, when a model is trained on imbalanced data, it learns inadequately
and inefficiently. Such imbalances often stem from biases in the program code or
the datasets used for model development, leading to false positives and adversely
impacting the model’s overall performance (Abdi et al. 2019; Bhaskar, Sruthi,
and Nedungadi 2015).
However, the significance of sentiment analysis cannot be overstated, given its
wide-ranging applications and impact across various fields and domains (Hasan et
al. 2018). Despite its drawbacks, organizations, companies, agencies, and
governments continue to utilize sentiment analysis to gain insights that can
improve decision-making efficiency and effectiveness. To address the challenges,
many researchers have developed sentiment analysis methods capable of
efficiently detecting sentiment from textual opinions. These methods often
employ deep learning and machine learning techniques (Al-Smadi et al. 2018;
Abdi et al. 2019; Yadav and Vishwakarma 2023). For instance, convolutional
neural networks (CNNs) were employed by (Deng et al. 2022) to achieve precise
text sentiment analysis, while bidirectional encoder representations from
transformers (BERT) were utilized by (Ray, Garain, and Sarkar 2021). Machine
learning models like Naïve Bayes (NB), J48, and logistic regression (LR)
classifiers were applied by Fayyoumi and Idwan (2021) to predict the polarity of
tweets collected from an Arabian audience, highlighting the viability of both
machine learning and deep learning models in sentiment analysis.
Despite the commendable efforts of numerous researchers in addressing the
complexities of sentiment analysis, the current approaches still struggle with a
high rate of false positives and low detection rates (Nofer and Hinz 2015; Heikal,
Torki, and El-Makky 2018; Asghar et al. 2019; Štrimaitis et al. 2021).
Additionally, many of these techniques have specific weaknesses and cannot
effectively handle the dynamic and intricate nature of language complexity
(Kratzwald et al. 2018; Akilandeswari and Jothi 2018). Consequently, there is a
growing need to combine multiple algorithms to enhance sentiment analysis. Toaddress these challenges, this study proposes the utilization of the support vector
machine (SVM) and logistic regression algorithms for more effective and
efficient sentiment analysis using election datasets obtained from the Kaggle
machine learning repository.
13.2 REVIEW OF RELATED WORK
Lately, there has been a growing interest among researchers in integrating deep
and machine learning techniques for sentiment analysis. This section provides an
overview of numerous studies focused on sentiment analysis and prediction using
emotional cues in machine learning approaches.
Binali, Wu, and Potdar (2009) introduced an emotion recognition system in the
context of e-learning. They claimed that their system could effectively classify
students’ opinions regarding their learning progress. The authors implemented
this system using Gate software and incorporated features such as smile, fear,
anger, happiness, and sadness in their analysis. According to their findings, this
approach significantly improved sentiment analysis performance.
Chan, Wong, and Dillon (2012) explored the development of an emotion
classification system using various machine learning algorithms. Their research
involved the use of SVMs and other methods to classify emotional signals from
patient datasets. They asserted that SVMs exhibited the highest accuracy among
the techniques tested, enhancing the system’s performance through different
combinations of emotional signals.
Hu et al. (2013) proposed an unsupervised sentiment analysis framework that
incorporated emotional signals. Their work focused on modeling two key
categories of sentiment signals: emotion indication and emotion correlation. The
authors compared their framework with existing methods using Twitter datasets,
specifically the Stanford Twitter Sentiment and the Obama-McCain Debate
datasets. Their research showed significant improvements, with a 21.40% and
17.87% enhancement on the two datasets, respectively, compared to the GI-Label
method. They also highlighted the superior performance of their ESSA-opt
approach over emotional signals for unsupervised sentiment analysis (ESSA).
Socher et al. (2013) introduced a deep learning module for fine-grained
sentence classification using treebanks. They employed recurrent neural network
modules designed based on training and test datasets, achieving an accuracy of
80%–85%, surpassing the baseline method’s performance.
Li et al. (2014) developed a treebank of Chinese views on social data to
address the scarcity of labeled corpora in existing models. Their recursive neural
deep models (RNDMs) outperformed SVM, Naïve Bayes, and maximum entropyin predicting sentiment labels for statement-level positive or negative
classifications. Their study, involving thousands of movies and Chinese
sentences, demonstrated significant improvements over baseline methods.
Chavan et al. (2014) conducted a survey of various machine learning methods
for text classification, with a focus on sentiment classification. They found that
SVMs were more suitable for text classification compared to other classifiers,
offering higher accuracy and customizable parameter settings.
Severyn and Moschitti (2015) presented a deep learning system for Twitter
sentiment analysis. They used neural language to initialize word embedding,
trained through a vast set of unsupervised tweets. Their model outperformed
others in predicting polarity for message-level and phrase-level tasks, ranking
first in accuracy.
Yanmei and Yuda (2015) conducted a detailed survey on sentiment analysis in
microblogging, aiming to understand user opinions and attitudes toward hot
events. They employed CNNs and other traditional algorithms to perform
sentiment analysis, achieving improved accuracy.
Sun, Wilson, and Lynch (2016) proposed a cognitive model for interpreting
emotions from complex texts. They extracted emotions from tweets using
emotion-word hashtags and the Hashtag Emotion Corpus dataset, finding that
SVM performed better for basic emotion types.
Winarsih and Supriyanto (2016) evaluated various machine learning
classifiers, including artificial neural networks, SVMs, and Naïve Bayes, for
emotion classification from Indonesian texts. They concluded that the SVMSMO
(support vector machine sequential minimal optimization) method outperformed
others, showcasing the effectiveness of machine learning classifiers in sentiment
analysis.
Baecchi et al. (2016) introduced a model for analyzing social network content
based on text and visuals. They demonstrated that neural network-based models
were superior to N-gram models, particularly in handling text from the web.
Rouby et al. (2018) developed a sentiment analysis model for Facebook
comments written in Arabic. Their work focused on preprocessing techniques,
including noise rejection, stemming, and normalization, to improve efficiency and
accuracy in sentiment analysis.
Jiang and Qi (2016) designed an emotion recognition system for classifying
user emotions from online product reviews in China. They used an extended
Ortony, Clore, and Collins – in Online Review (OCC- OR) emotion model and
various machine learning techniques, achieving effective sentiment analysis.
Vateekul and Koomsubha (2016) proposed deep learning methods, including
CNNs and long short-term memory (LSTM), for emotion classification of ThaiTwitter data. Their experiments showed that deep neural network (DNN)
outperformed LSTM and traditional methods, though it fell short of maximum
entropy.
Singh, Singh, and Singh (2017) utilized machine learning classifiers to
optimize sentiment analysis, focusing on extracting positive and negative
polarities from social media text. They found that the OneR classifier exhibited
promising results with high accuracy.
Farooq et al. (2016) developed a comprehensive educational model for
detecting tweet polarization across Arab countries. Their deep learning model,
based on LSTM and word embeddings, achieved approximately 70% accuracy.
Heikal et al. (2018) introduced a split and conquer methodology for sentiment
analysis, classifying sentences individually. Their approach improved sentiment
analysis performance at the sentence level, outperforming other deep learning
models.
Asghar et al. (2019) conducted research on supervised machine learning
techniques for emotion detection in online content. They addressed the limitations
of existing approaches and aimed to evaluate various machine learning classifiers
on benchmark sentiment datasets. Their experiments included classifiers like
random forest, SVM, logistic regression, XGBoost, stochastic gradient descent
(SGD) classifier, Naïve Bayes classifier, and ANN. Logistic regression showed
superior performance in terms of recall and accuracy, achieving an accuracy of
83%, while SVM achieved 76% accuracy. In contrast, XGBoost exhibited poorer
performance in accuracy, recall, F-measure, and accuracy.
Nagamanjula and Pethalakshmi (2020) proposed a novel framework for
sentiment analysis on Twitter, utilizing multi-objective optimization and
LAN2FIS (logistic adaptive network based on neurophagy inference system).
They emphasized the challenge of collecting diverse emotional data from Twitter
and introduced a preprocessing framework to enrich tweets and extract various
features. Their hybrid machine learning algorithm, LAN2FIS, demonstrated
efficient feature selection through biological optimization, resulting in improved
accuracy, precision, recall, F-measure, and error rate compared to other
classifiers.
Ray et al. (2021) developed a vacation resort recommender system that
combines sentiment analysis and aspect categorization of hotel reviews. They
used an ensemble approach and BERT with different sentiment categories. The
dataset, obtained from Tripadvisor using a crawling process with 58,612 reviews,
was categorized using fuzzy logic and cosine similarity. The proposed model
achieved an impressive Macro F1-score of 84% and a test accuracy of 92.36%,
surpassing state-of-the-art models.Naseem et al. (2021) introduced COVIDSenti, a large-scale Twitter dataset for
COVID-19 sentiment analysis. They aimed to understand the topics and
sentiment dynamics related to COVID-19 on Twitter. The dataset comprised
90,000 COVID-19-related tweets collected from February to March 2020 and
was categorized into positive, negative, and neutral sentiments using the Time￾Aware Knowledge Extraction (TAKE) methodology. The study revealed the
significant role of negative sentiment in shaping public opinions during the
pandemic, emphasizing the need for proactive public health interventions to
counteract negative sentiment on social media.
Štrimaitis et al. (2021) focused on sentiment analysis of Lithuanian language
mass media. They aimed to assess the effectiveness of machine learning models
in sentiment estimation using datasets related to fiscal news sentiment analysis.
The study utilized positive and negative bigrams generated by financial experts
for a lexicon-grounded approach. Three common bracketing methods—
multinomial Naïve Bayes, SVMs, and LSTM—were analyzed and compared. The
results showed that the multinomial Naïve Bayes algorithm achieved the highest
accuracy (71.1%) on an unbalanced dataset, outperforming LSTM (71%) and
SVM (70.4%).
Basiri et al. (2021) introduced a novel approach for sentiment analysis of
COVID-19-related Twitter posts across eight different countries. They utilized a
combination of four deep learning models and a traditional supervised machine
learning model to gauge public sentiments during the pandemic. The researchers
collected Twitter posts from these eight countries between January 24, 2020, and
April 21, 2020, using keyword searches related to COVID-19. Their analysis
involved two data sources: Google Trends data and Twitter data. Google Trends
data was used to assess people’s interest in COVID-19 information based on
keyword searches. The study aimed to determine if the coronavirus generated
varying degrees of interest in different countries at different times. However, the
researchers acknowledged that their study had limitations, as it did not consider
COVID-19 news and statistics from various countries worldwide.
Fayyoumi and Idwan (2021) conducted sentiment analysis on Arabic tweets
related to the COVID-19 crisis in Jordan. They developed two models, TAL
(Traditional Arabic Language) and SPAL (Semantic Partitioning Arabic
Language), to predict the sentiment of collected tweets using various machine
learning classifiers. The data consisted of 2,000 tweets from Jordan during the
COVID-19 crisis, and the researchers aimed to categorize these tweets into
positive, negative, or neutral sentiments. The study observed an improvement in
sentiment prediction using the SPAL model, with MLP (multi-layer perceptron)
classifier achieving a 4.22% increase in accuracy compared to the TAL model.However, the study had limitations due to the constraint of assigning sentiments
only to the collected tweets.
Villavicencio et al. (2021) focused on sentiment analysis of Twitter data
related to COVID-19 vaccines in the Philippines. They categorized tweets into
positive, neutral, or negative sentiments during the initial phase of the vaccination
program. The study used natural language processing (NLP) techniques and the
Naïve Bayes classifier to process and classify tweets in English and Filipino
languages. The results indicated that 83% of the tweets were positive, 9% were
neutral, and 8% were negative, demonstrating strong support for vaccination in
the Philippines. However, the study had limitations due to the focus on a specific
time frame and language, as well as potential biases in the Twitter data.
Khan et al. (2021) conducted sentiment analysis on U.S.-based COVID-19
tweets using TextBlob and various supervised machine learning algorithms. They
aimed to analyze sentiments in tweets related to COVID-19 in the United States
to inform policy decisions. The study used a dataset of 11,858 tweets collected
from January 30, 2020, to May 10, 2020. TextBlob was employed to label tweets
as positive, negative, or neutral. The study applied different supervised ML
algorithms and feature extraction methods to classify the sentiments of tweets.
Gradient boosting machine, when paired with term frequency – inverse document
frequency (TF-IDF) features, achieved the highest accuracy of 96%. The study
demonstrated the effectiveness of the proposed approach in sentiment analysis.
Neogi et al. (2021) conducted sentiment analysis on Twitter data related to
Indian farmers’ protests. They aimed to understand the sentiments of the Indian
population regarding government policies using NLP techniques and supervised
machine learning models. The study collected around 20,000 tweets and used Bag
of Words and TF-IDF for feature extraction. Four classifiers, including Naïve
Bayes, decision tree, random forest, and SVM, were employed to categorize
tweets into positive, negative, or neutral sentiments. Random forest showed the
best classification accuracy. However, the study acknowledged limitations related
to computational resources.
Wang et al. (2021) proposed the RGWE (Refined Global Word Embeddings)
method for sentiment analysis. They aimed to improve word embeddings for
sentiment analysis by incorporating sentiment concepts and sentiment intensity
lexicons. The study utilized six publicly available datasets for sentiment analysis
tasks and evaluated the performance of RGWE against traditional word
embedding methods. RGWE achieved improved accuracy and sentiment
representation compared to other methods. The study demonstrated the
effectiveness of RGWE in sentiment analysis tasks.Nandwani and Verma (2021) conducted a review of sentiment analysis and
emotion recognition methods. They explored various approaches, including
dictionary-based, corpus-based, and deep learning methods, for detecting
emotions and moods in text data. The study highlighted the strengths and
limitations of each approach and emphasized the evolving nature of sentiment
analysis techniques. The review highlighted the importance of preprocessing and
feature extraction techniques in mood and emotion analysis.
Deng et al. (2022) proposed an emulsion model for text sentiment analysis.
This model combines CNN and BiLSTM models to achieve accurate sentiment
analysis by focusing on emotional words in the text. The researchers collected
data from various social media platforms, including Facebook, WhatsApp, and
Twitter, and utilized the emulsion model to improve the accuracy of sentiment
trend analysis. The combination of CNN and BiLSTM models demonstrated
better performance compared to other models.
13.3 METHODOLOGY
The methodology employed in this study involves three fundamental steps. The
initial phase is data preprocessing. This step involved the removal of undesired
characters, such as URLs and “@” symbols, from the datasets. Additionally, it
encompassed tokenization and lemmatization to segment words from the text
stream, as well as text vectorization to convert the text into vectors. The selection
of relevant features was performed based on the correlation matrix derived from
the dataset’s feature influences. Subsequently, the dataset was then divided into
training and test sets, following the completion of the sub-stages in the previous
phase.
The third phase is development of hybrid models of SVM and LR.
Furthermore, hyperparameter tuning was conducted to enhance the performance
of these models. These three stages are illustrated in Figure 13.1.Figure 13.1 Proposed research framework.
13.3.1 Data source
This study was carryout on two datasets sourced from the Kaggle machine
learning repository website. These datasets consist of three distinct sentiment
classes: positive, negative, and neutral. Messages categorized as neutral are
considered non-relevant to the main entity messages; consequently, the neutral
class was treated as part of the negative class within the datasets. The first dataset,
available at https://www.kaggle.com/crowdflower/first-gop-debate-twitter￾sentiment, focuses on the first US GOP election debate. This collection comprises
tweets discussing the presidential debate and aims to categorize each tweet’s
sentiment as positive, negative, or neutral. It contains a total of 13,871 tweets that
were evaluated for their relevance, mentions of specific candidates, topics, and
the sentiment expressed within each tweet. The second dataset pertains to the
Nigeria 2023 election and was obtained at
https://www.kaggle.com/datasets/ahamefulechijoke/twitter-data-nigerian-2023-
presidential-election containing nearly 10,000 tweets.
13.3.2 Data preprocessing and preparation
Enhancing model performance necessitates data cleansing to eliminate
incompleteness and inconsistencies arising from errors in the dataset while
retaining its crucial features. Subsequently, upon acquiring the tweet dataset, the
following preprocessing steps were executed, as outlined in Figure 13.2.Figure 13.2 Data preprocessing.
Figure 13.3 (a) Sentiment count (US GOP election debate dataset) and
(b) sentiment count (2023 Nigerian election).
13.3.3 Data preprocessing
This phase encompasses a series of procedures designed to cleanse the data of
unwanted terms and characters. Initially, the extracted tweets undergo a
tokenization process, referred to as function removal. Tokenization involves
converting the acquired documents and texts into more informative and machine￾readable forms, such as words, phrases, and sentences, to enhance classification
outcomes. The following techniques are applied to the text:i. Tokenization: It involves extracting words from the text stream and
dividing it into words, phrases, or meaningful elements using delimiters like
spaces, punctuation, and symbols. Tokenization aims to create diverse
representations of information-enriched texts to improve classification
outcomes.
ii. Stop Words Removal: It entails generating a list of words and scanning the
document to remove words present in the stop list such as like “a,” “the,”
and “this.”
iii. Stemming: It reduces words to their root or stem form, enhancing recall rate
and reducing data dimensionality while identifying similar words despite
variations in shape.
iv. Case Normalization: It converts uppercase text to lowercase.
v. Removal of Unwanted Characters: It eliminates unnecessary characters
such as URLs, extra spaces, punctuation marks, and “@” symbols with
associated usernames, which can degrade classifier performance.
vi. Feature Selection: The study performs feature selection using a correlation
matrix and selects features with significant influence on sentiment
prediction.
13.3.4 Processing of emoticons
Typically, two main types of text content can be identified when analyzing text
messages: Subjective text, which often contains sentiments and opinions, and
objective text, characterized by factual or informative content. Subjective text can
encompass various emotions and viewpoints, while objective text is typically
composed of straightforward facts or positive news. With recent developments in
the types of content present in social media and user-generated messages, there is
a need to pay attention to a unique form of content known as emoticons,
sometimes referred to as emojis. Emoticons consist of facial expressions and
symbols that convey a wide range of meanings, including positive, negative, or
neutral emotions.
13.3.5 Data preparation
Data preparation is the final step in transforming datasets into their ultimate
formats. During this stage, experts manually categorized all tweets in the datasets
into positive, negative, or neutral emotions, assigning values of 1, 0, and −1,
respectively. This labeling process is essential for the classifier to successfully
construct its model. Positive emotions signify contentment and happiness, whichmay be conveyed through emoticons. Negative emotions encompass sadness,
anger, or other dissatisfactory sentiments, often represented by negative
emoticons. Neutral labels indicate that the text lacks any discernible emotions or
opinions, and this category is typically found in news articles and advertisements,
as opposed to regular user-generated content.
The second aspect of this stage involves converting all the texts into the tf-IDF
(term frequency-inverse document frequency) format for word weighting. The tf￾IDF technique was chosen for its ability to provide weights for each word in a
tweet with respect to the entire dataset or corpus. In this format, words appearing
in a tweet are assigned to their tf-IDF weight, while words absent from the tweet
receive a value of 0.
13.3.6 Classification algorithm
Extensive research revealed that sentiment analysis is essentially a classification
problem in machine learning. A classification problem entails identifying suitable
models for either multiclass or binary classification tasks, such as the one
addressed in this study, where classes are distinguished accordingly.
Consequently, this study adopts two hybrid classification models to assess their
performance in sentiment analysis using distinct evaluation metrics. These
models are the SVM and the linear regression (LRG).
13.3.6.1 Support vector machine
The SVM classifier is widely recognized and applied in a variety of classification
tasks, particularly in natural language classification problems. While SVM is
primarily considered a classification approach, it can also be used for both
classification and regression problems, accommodating multiple continuous and
categorical variables. The SVM model iteratively constructs a hyperplane in a
multidimensional space to effectively separate different classes within a problem,
aiming to generate an optimal hyperplane that minimizes errors. Support vectors
represent data points closest to the hyperplane in a linear SVM variation. These
points play a crucial role in defining a more effective separating line by
calculating margins that are integral to the classifier’s construction. Larger
margins between classes indicate a favorable separation, while smaller margins
suggest a less effective separation. SVM pseudocode is presented in Algorithm
13.1.(13.1)
Algorithm 13.1: Support Vector Machine Algorithm
Step 1: Simple SVM candidate SV = { closest pair from opposite
classes }
Step 2: initialize i
Step 3: while there are violating points do
Step 4: Find a violator
Step 5: candidate SV = candidate SV x violator
Step 6: if any ∂i < 0 due to addition of c to S then
Step 7: candidate SV = candidate SV/i
Step 8: repeat till all such points are pruned
Step 9: end if
Step 10: increment i
Step 11: end while
13.3.6.2 Linear regression
Linear regression (LRG) is a machine learning algorithm employed in supervised
learning. Its primary function involves predicting a dependent variable (referred
to as the target) by analyzing the provided independent variables. LRG
accomplishes this by identifying the linear connection between the dependent
variable and the given independent variables. The mathematical representation of
the LRG algorithm, as presented below, illustrates the linear association between
a dependent variable (y) and one or more independent variables (x). LRG
pseudocode is presented in Algorithm 13.2.
Y = a0 + a1X + ε
Whereas:
Y = dependent variable (target variable)
X = independent variable (predictor variable)
a0 = intercept of the line (gives an additional degree of freedom)
a1 = linear regression coefficient (scale factor to each input value)
ε = random errorThe values for X and Y variables are training datasets for LR model
representation.
The two algorithms were combined linearly; that is, the output of the first
algorithm serves as input to the second algorithm.
13.4 PERFORMANCE METRICS
In order to assess the effectiveness of the two classification models employed in
this study, namely the SVM and the LR, on the sentiment dataset obtained from
the source, the following evaluation metrics were utilized:
Confusion Matrix: While not a measure of accuracy in itself, the confusion
matrix plays a crucial role in gauging the correctness and precision of each
model. It serves as a validator for the accuracy score employed, and its validation
is based on the indicators presented in Table 13.1 below.
Table 13.1 Confusion matrix
Predicted Positive TP FP
Negative FN TN
Algorithm 13.2: Linear Regression Algorithm
Step 1: Start
Step 2: Read Number of Data (n)
Step 3: For i=1 to n:
Read Xi
 and Yi
Next i
Step 4: Initialize: sumX = 0, sumX2 = 0, sumY = 0, sumXY = 0
Step 5: Calculate Required Sum
For i=1 to n:
sumX = sumX + Xi
sumX2 = sumX2 + Xi
 * Xi
Actual
Positive Negative(13.2)
(13.3)
(13.4)
sumY = sumY + Yi
sumXY = sumXY + Xi
 * Yi
Next i
Step 6: Calculate Required Constant a and b of y = a + bx:
b = (n * sumXY - sumX * sumY)/(n*sumX2 - sumX * sumX)
a = (sumY - b*sumX)/n
Step 7: Display the value of a and b
Step 8: Finish
True Positives (TP): This describes a situation where a data point is initially
classified as True, and the model correctly predicted it as True.
True Negatives (TN): This refers to a scenario where a data point is initially
classified as False, and the model accurately predicted it as False.
False Positives (FP): These instances occur when the actual class data value is
False, but the model incorrectly predicts it as True.
False Negatives (FN): These instances happen when the actual class data
value is True, but the model erroneously predicts it as False.
Precision: Precision measures the accuracy by calculating the percentage of
correctly predicted positive reviews out of the total predicted positive reviews:
Precision = TP
TP + FP
Recall: Recall quantifies the classifier’s completeness by calculating the
percentage of correctly predicted positive reviews out of the actual number of
positive reviews in the dataset:
Recall = TP
TP + FN
F-score: The F-score combines the metrics of precision and recall to achieve a
balanced score value that ranges between 0 and 1:
F − Measure = 2 ×
Precision×Recall
Precision+Recall
Accuracy: Among all the metrics, accuracy is the most crucial performance
evaluation metric. It calculates the percentage of correctly predicted reviews out
of the total number of reviews in the dataset:Accuracy = (13.5) TP + TN
TP + TN + FP + FN
13.5 RESULTS AND DISCUSSION
13.5.1 Experimental setup
To experiment and analyze sentiment, the first US GOP election debate and the
2023 Nigerian election sourced from the Kaggle machine learning repository
were utilized on a 64-bit Windows operating system, with an Intel(R) Corel (TM)
i5-3630QM CPU @2.40GHZ with 8.00 GB of RAM for the experimental setup.
Python 3.8 software development kit was used to code for this study.
13.5.2 Dataset description and visualization
Figure 13.3a and b shows the analysis of the number of positive sentiments in
proportion to words that have negative sentiment polarity for the first US GOP
election debate and the 2023 Nigerian election datasets, respectively. In detail,
Figure 13.3a indicates that of the total of 13,871 records from the first US GOP
election debate election tweet dataset, 11,635 show negative sentiment polarity
with 2,236 of the datasets having positive sentiment polarity, whereas for the
Nigerian 2023 election, Figure 13.3b shows that 1,184 have a negative polarity
while 8,816 have a positive polarity of the total 10,000. From Figure 13.3a and b,
0 represents the negative and 1 defines the positive polarity.
The understanding of data correlation is essential in identifying features that
greatly influence the prediction of sentiments with positive and negative
polarities. The correlation matrix in Figure 13.4, uses the correlation coefficients
annotated to each cell to establish the degree to which each feature is connected
in the prediction of sentiment polarity as either positive or negative. From the
correlation diagram, a value of 0 denotes a neutral correlation, a value of −1
denotes a weak correlation, and a value of 1 denotes a substantial influence
between two factors in predicting cases whether or not an instance has negative or
positive sentiment polarity. The diagonal axis is always equal to one because each
attribute has a strong association with itself. Furthermore, in view of the right￾hand side of the data correlation diagram in Figure 13.4, the top right-hand-side
value identifies features that significantly influence the prediction of sentiments
with a higher value closer to 1. Essentially, it is important to note that the lower
the correlation values, the least significant a feature is to the prediction of
sentiments. Moreover, the degree of light orange shading of a feature determines
the degree of a feature’s correlation with other features in influencing theprediction of sentiments with the reddish and blackish shaded cells indicating the
least correlation of its respective horizontal and vertical cell features.
Figure 13.4 Correlation diagram.
13.5.3 Data splitting
Splitting the dataset into some training and test proportions is necessary for
training machine learning experiments. The experiment also splits both the first
US GOP election debate and the 2023 Nigerian election datasets into sometraining and test proportions. The LR and SVM (including their hybrid variation)
algorithms were trained using the training set, and the test set was used to verify
the effectiveness of the developed models. To be specific, 70% of the dataset was
used to train the models, and the remaining 30% for each dataset was used to test
the efficacy of the developed models following best practices in machine
learning.
13.5.4 Result presentation
In this study, after selecting relevant features using correlation matrix, two
machine learning algorithms (namely the SVM and LR) and their hybrid were
used for the prediction of sentiment polarity (as 0 and 1, i.e., positive or
negative). The accuracy of each algorithm used is presented in Tables 13.2 and
13.3. From Table 4.1 (considering the first US GOP election debate dataset), it
can be seen that SVM had an accuracy score of 83%, and the LR and their hybrid
obtained an accuracy of 87% accordingly. Hence, from the result of each
algorithm for the first US GOP election debate dataset, it can be identified that
both the logistic and the hybrid model have the best performance over the SVM
model and thus emerge the best with an approximated score of 87% on the first
US GOP election debate sentiment dataset. Furthermore, Figure 13.5 shows the
accuracy comparison graph using a bar chart of the three models on the US GOP
debate election dataset, with the y-axis representing the accuracy score and the x￾axis showing the respective models.
Table 13.2 Accuracy score (first US GOP
election debate dataset)
Support vector machine 83
Logistic regression 87
Hybrid 87
Table 13.3 Accuracy score (Nigeria 2023
election)
Support vector machine 93.2
Algorithm Accuracy (%)
Algorithm Accuracy (%)Logistic regression 92.7
Hybrid 93.3
Figure 13.5 Model accuracy graph plot (first US GOP election debate
election).
Furthermore, considering the result of each algorithm on the 2023 Nigerian
election dataset, Table 13.3 identifies that the SVM, LR, and their hybrid have an
accuracy of 93.2%, 92.7%, and 93.3%, respectively. Hence, it can be identified
that both the SVM and the hybrid models have the best performance over the LR
model and thus emerge the best with an approximated score of 93% on the 2023
Nigerian election dataset. Additionally, Figure 13.6 shows the accuracy
comparison graph using a bar chart of the three models, with the y-axis as the
accuracy score and the x-axis showing the models.
Algorithm Accuracy (%)Figure 13.6 Model accuracy graph plot (2023 Nigerian election).
To evaluate the other performance metrics obtained by each algorithm, such as
the precision, recall, and f1-score metrics, Table 13.4 shows the evaluation
metrics scores for each of the model on the US GOP election debate dataset while
Table 13.5 shows results for the 2023 Nigerian election.
Table 13.4 Evaluation metrics (first US GOP election debate dataset)
SVM 94 86 90 83
Logistic regression 89 96 93 87
Hybrid 90 96 93 87
Algorithm Precision (%) Recall (%) Fl-score (%) AccuracyTable 13.5 Evaluation metrics (2023 Nigerian election)
SVM 93 97 95 93.2
Logistic
regression
92 99 96 92.7
Hybrid 94 99 96 93.3
To further investigate the performance of the implemented sentiment analysis
models on both datasets, the receiver operating characteristic (ROC) was also
employed. Considering that the ROC curve is a graph that shows the performance
of a classification model for a classification problem such as the analysis of
sentiment polarities as either of positive or negative influence. Therefore, in
visualizing the performance of the developed models on the sentiment datasets,
the area under the curve (AUC) of the ROC was employed. Figure 13.7, Figure
13.8 and Figure 13.9 depict ROC test for the three models on the two datasets.
Figure 13.7 (a) SVM ROC (first US GOP election debate). (b) SVM
ROC (Nigerian 2023 election).
Algorithm Precision
(%)
Recall
(%)
F1-score
(%) AccuracyFigure 13.8 (a) LR ROC (first US GOP election debate). (b) LR ROC
(Nigerian 2023 election).
Figure 13.9 (a) Hybrid ROC (first US GOP election debate). (b) Hybrid
ROC (Nigerian 2023 election).
The ROC curve serves as a tool for evaluating the classifier’s performance; the
quality of ROC curve is assessed by its AUC. The best ROC was obtained in
hybrid model for both datasets.
13.6 COMPARISON WITH SOME STATE-OF-THE￾ART ALGORITHM
The results obtained in this study were compared with some of the state-of-the-art
algorithms. Table 13.6 displays the summary of comparison based on the authors,year of work, the dataset applied by the study, and the machine learning models
implemented. The best performing model was highlighted.
Table 13.6 State-of-the-art algorithms’ comparison
Current
study
(2023)
First US GOP
election debate
and 2023
Nigerian
election dataset
SVM, LR, and
SVM-LR
(hybrid)
Hybrid
(SVM￾LR)
93.3
Farooq et
al. (2016)
Egyptian
wedding tweets
Deep learning
model
- 70
Heikal et
al. (2018)
- NN-centric
sequence model
- 65
Asghar et
al. (2019)
Benchmark
sentiment
datasets
Random forest,
SVM, logistic
regression,
XGBoost, SGD
classifier, Naïve
Bayes classifier,
and ANN.
Logistic
regression
83
Štrimaitis
et al.
(2021)
- Naïve Bayes - 71
Adewole
et al.
(2021)
First US GOP
election debate
Hybrid of feature
selections with
SVM, Naïve
Bayes, and
random forest
77.8
13.7 CONCLUSION
In this study, models for the classification of sentiment polarities from the two
difference datasets sourced from the Kaggle machine learning repository have
Authors
(year) Dataset used Models Best
model
Accuracy
(%)been experimentally evaluated and analyzed using some machine learning
algorithms such as the SVM, LR, and their hybrid. Considering the first US GOP
election debate dataset, the SVM achieved an accuracy score of 83%, whereas LR
and the hybrid model both obtained an accuracy of 87%, respectively.
Furthermore, on the 2023 Nigerian election dataset, the SVM, LR, and hybrid
have an accuracy of 93.2%, 92.7%, and 93.3%, respectively. On the second
dataset, both the SVM and the hybrid algorithm performed better than the LR
model with an accuracy of 93%. Analytically, from the result of each algorithm
on the two datasets, it can be identified the hybrid model emerges as the best with
an accuracy score of 87.2% and 93% on the first US GOP election debate dataset
and the 2023 Nigerian election dataset.
REFERENCES
Abdi, Asad, Siti Mariyam Shamsuddin, Shafaatunnur Hasan, and Jalil Piran.
2019. “Deep Learning-Based Sentiment Classification of Evaluative Text
Based on Multi-Feature Fusion.” Information Processing & Management
56 (4): 1245–59.
Adewole, Kayode S, Abdullateef O Balogun, Muiz O Raheem, K
Muhammed, Rasheed G Jimoh, Modinat A Mabayoje, Fatima E Usman￾hamza, Abimbola G Akintola, and Ayisat W Asaju-gbolagade. 2021.
“Hybrid Feature Selection Framework for Sentiment Analysis on Large
Corpora.” Jordanian Journal of Computers and Information Technology
(JJCIT) 07 (2): 130–51.
Agaian, Sarkis, and Petter Kolm. 2017. “Financial Sentiment Analysis Using
Machine Learning Techniques.” International Journal of Investment
Management and Financial Innovations 3 (1): 1–9.
Akilandeswari, J, and G Jothi. 2018. “Sentiment Classification of Tweets
with Non-language Features.” Procedia Computer Science 143: 426–33.
Al-Smadi, Mohammad, Omar Qawasmeh, Mahmoud Al-Ayyoub, Yaser
Jararweh, and Brij Gupta. 2018. “Deep Recurrent Neural Network vs.
Support Vector Machine for Aspect-Based Sentiment Analysis of Arabic
Hotels’ Reviews.” Journal of Computational Science 27: 386–93.
Asghar, Muhammad Zubair, Fazli Subhan, Muhammad Imran, Fazal Masud
Kundi, Shahboddin Shamshirband, Amir Mosavi, Peter Csiba, and
Annamária R Várkonyi-Kóczy. 2019. “Performance Evaluation of
Supervised Machine Learning Techniques for Efficient Detection ofEmotions from Online Content.” Computers, Materials & Continua,
ArXiv Preprint ArXiv:1908.01587.
Baecchi, Claudio, Tiberio Uricchio, Marco Bertini, and Alberto Del Bimbo.
2016. “A Multimodal Feature Learning Approach for Sentiment Analysis
of Social Network Multimedia.” Multimedia Tools and Applications 75:
2507–25.
Basiri, Mohammad Ehsan, Shahla Nemati, Moloud Abdar, Somayeh Asadi,
and U Rajendra Acharrya. 2021. “A Novel Fusion-Based Deep Learning
Model for Sentiment Analysis of COVID-19 Tweets.” Knowledge-Based
Systems 228: 107242.
Bhaskar, Jasmine, K Sruthi, and Prema Nedungadi. 2015. “Hybrid Approach
for Emotion Classification of Audio Conversation Based on Text and
Speech Mining.” Procedia Computer Science 46: 635–43.
Binali, Haji H, Chen Wu, and Vidyasagar Potdar. 2009. “A New Significant
Area: Emotion Detection in e-Learning Using Opinion Mining
Techniques.” In 2009 3rd IEEE International Conference on Digital
Ecosystems and Technologies, Istanbul, 259–64. IEEE.
Birjali, Marouane, Mohammed Kasri, and Abderrahim Beni-Hssane. 2021.
“A Comprehensive Survey on Sentiment Analysis: Approaches,
Challenges and Trends.” Knowledge-Based Systems 226: 107134.
Cachola, Isabel, Eric Holgate, Daniel Preoţiuc-Pietro, and Junyi Jessy Li.
2018. “Expressively Vulgar: The Socio-Dynamics of Vulgarity and Its
Effects on Sentiment Analysis in Social Media.” In Proceedings of the
27th International Conference on Computational Linguistics, Santa Fe,
New-Mexico, USA, 2927–38.
Chan, Kit Yan, Yuk Shan Wong, and Tharam S Dillon. 2012. Computational
Intelligence Techniques for New Product Design. Vol. 403. Springer
Science & Business Media.
Chavan, Gaurav S, Sagar Manjare, Parikshit Hegde, and Amruta Sankhe.
2014. “A Survey of Various Machine Learning Techniques for Text
Classification.” International Journal of Engineering Trends and
Technology 15 (6): 288–92.
Deng, Hongjie, Daji Ergu, Fangyao Liu, Ying Cai, and Bo Ma. 2022. “Text
Sentiment Analysis of Fusion Model Based on Attention Mechanism.”
Procedia Computer Science 199: 741–48.
Dey, Nilanjan, Samarjeet Borah, Rosalina Babo, and Amira S Ashour. 2018.
Social Network Analytics: Computational Research Methods andTechniques. Academic Press.
Farooq, Umar, Hassan Mansour, Antoine Nongaillard, and Muhammad
Abdul Qadir. 2016. “Negation Handling in Sentiment Analysis at
Sentence Level.” Journal of Computers 12 (5): 470–78.
Fayyoumi, Ebaa, and Sahar Idwan. 2021. “Semantic Partitioning and
Machine Learning in Sentiment Analysis.” Data 6 (6): 67.
Ghanbari-Adivi, Fereshteh, and Mohammad Mosleh. 2019. “Text Emotion
Detection in Social Networks Using a Novel Ensemble Classifier Based
on Parzen Tree Estimator (TPE).” Neural Computing and Applications
31 (12): 8971–83.
Hasan, Ali, Sana Moin, Ahmad Karim, and Shahaboddin Shamshirband.
2018. “Machine Learning-Based Sentiment Analysis for Twitter
Accounts.” Mathematical and Computational Applications 23 (1): 11.
Heikal, Maha, Marwan Torki, and Nagwa El-Makky. 2018. “Sentiment
Analysis of Arabic Tweets Using Deep Learning.” Procedia Computer
Science 142: 114–22.
Hu, Xia, Jiliang Tang, Huiji Gao, and Huan Liu. 2013. “Unsupervised
Sentiment Analysis with Emotional Signals.” In Proceedings of the 22nd
International Conference on World Wide Web, Rio de Janeiro, Brazil,
607–18.
Jiang, Si, and Jiayin Qi. 2016. “Cognitive Detection of Multiple Discrete
Emotions from Chinese Online Reviews.” In 2016 IEEE First
International Conference on Data Science in Cyberspace (DSC),
Changsha, China, June 13–16, 137–42. IEEE.
Khan, Rashid, Furqan Rustam, Khadija Kanwal, Arif Mehmood, and Gyu
Sang Choi. 2021. “US Based COVID-19 Tweets Sentiment Analysis
Using Textblob and Supervised Machine Learning Algorithms.” In 2021
International Conference on Artificial Intelligence (ICAI), Montreal,
Canada, 1–8. IEEE.
Kratzwald, Bernhard, Suzana Ilić, Mathias Kraus, Stefan Feuerriegel, and
Helmut Prendinger. 2018. “Deep Learning for Affective Computing:
Text-Based Emotion Recognition in Decision Support.” Decision
Support Systems 115: 24–35.
Li, Changliang, Bo Xu, Gaowei Wu, Saike He, Guanhua Tian, and Hongwei
Hao. 2014. “Recursive Deep Learning for Sentiment Analysis over
Social Data.” In 2014 IEEE/WIC/ACM International Joint Conferences
on Web Intelligence (WI) and Intelligent Agent Technologies (IAT),Massachusetts Ave., NW Washington, DC; United States, 2:180–85.
IEEE.
Mohammad, Saif M. 2017. “Challenges in Sentiment Analysis.” In Cambria,
E., Das, D., Bandyopadhyay, S., and Feraco, A. (eds) A Practical Guide
to Sentiment Analysis, 61–83. National Research Council Canadaa.
https://doi.org/10.1007/978-3-319-55394-8_4.
Nagamanjula, R, and A Pethalakshmi. 2020. “A Novel Framework Based on
Bi-Objective Optimization and LAN2FIS for Twitter Sentiment
Analysis.” Social Network Analysis and Mining 10 (1): 34.
Nandwani, Pansy, and Rupali Verma. 2021. “A Review on Sentiment
Analysis and Emotion Detection from Text.” Social Network Analysis
and Mining 11 (1): 81.
Naseem, Usman, Imran Razzak, Matloob Khushi, Peter W Eklund, and
Jinman Kim. 2021. “COVIDSenti: A Large-Scale Benchmark Twitter
Data Set for COVID-19 Sentiment Analysis.” IEEE Transactions on
Computational Social Systems 8 (4): 1003–15.
Neogi, Ashwin Sanjay, Kirti Anilkumar Garg, Ram Krishn Mishra, and
Yogesh K Dwivedi. 2021. “Sentiment Analysis and Classification of
Indian Farmers’ Protest Using Twitter Data.” International Journal of
Information Management Data Insights 1 (2): 100019.
Nofer, Michael, and Oliver Hinz. 2015. “Using Twitter to Predict the Stock
Market: Where Is the Mood Effect?” Business & Information Systems
Engineering 57: 229–42.
Phan, Huyen Trang, Van Cuong Tran, Ngoc Thanh Nguyen, and Dosam
Hwang. 2020. “Improving the Performance of Sentiment Analysis of
Tweets Containing Fuzzy Sentiment Using the Feature Ensemble
Model.” IEEE Access 8: 14630–41.
Ray, Biswarup, Avishek Garain, and Ram Sarkar. 2021. “An Ensemble￾Based Hotel Recommender System Using Sentiment Analysis and
Aspect Categorization of Hotel Reviews.” Applied Soft Computing 98:
106935.
Rouby, Ibrahim, Mohammed Badawy, Mohamed Nour, and Nadia Hegazi.
2018. “Performance Evaluation of an Adopted Sentiment Analysis Model
for Arabic Comments from the Facebook.” Journal of Theoretical and
Applied Information Technology 96 (21): 7098–7112.
Severyn, Aliaksei, and Alessandro Moschitti. 2015. “Twitter Sentiment
Analysis with Deep Convolutional Neural Networks.” In Proceedings ofthe 38th International ACM SIGIR Conference on Research and
Development in Information Retrieval, Santiago de Chile, 959–62.
Singh, Jaspreet, Gurvinder Singh, and Rajinder Singh. 2017. “Optimization
of Sentiment Analysis Using Machine Learning Classifiers.” Human￾Centric Computing and Information Sciences 7: 1–12.
Socher, Richard, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D
Manning, Andrew Y Ng, and Christopher Potts. 2013. “Recursive Deep
Models for Semantic Compositionality over a Sentiment Treebank.” In
Proceedings of the 2013 Conference on Empirical Methods in Natural
Language Processing, Seattle, Washington, 1631–42.
Štrimaitis, Rokas, Pavel Stefanovič, Simona Ramanauskaitė, and Asta
Slotkienė. 2021. “Financial Context News Sentiment Analysis for the
Lithuanian Language.” Applied Sciences 11 (10): 4443.
Sun, Ron, Nick Wilson, and Michael Lynch. 2016. “Emotion: A Unified
Mechanistic Interpretation from a Cognitive Architecture.” Cognitive
Computation 8: 1–14.
Vateekul, Peerapon, and Thanabhat Koomsubha. 2016. “A Study of
Sentiment Analysis Using Deep Learning Techniques on Thai Twitter
Data.” In 2016 13th International Joint Conference on Computer Science
and Software Engineering (JCSSE), Khon Kaen, Thailand, 1–6. IEEE.
Villavicencio, Charlyn, Julio Jerison Macrohon, X Alphonse Inbaraj, Jyh￾Horng Jeng, and Jer-Guang Hsieh. 2021. “Twitter Sentiment Analysis
towards Covid-19 Vaccines in the Philippines Using Naïve Bayes.”
Information 12 (5): 204.
Wang, Yabing, Guimin Huang, Jun Li, Hui Li, Ya Zhou, and Hua Jiang.
2021. “Refined Global Word Embeddings Based on Sentiment Concept
for Sentiment Analysis.” IEEE Access 9: 37075–85.
Winarsih, Nurul Anisa Sri, and Catur Supriyanto. 2016. “Evaluation of
Classification Methods for Indonesian Text Emotion Detection.” In 2016
International Seminar on Application for Technology of Information and
Communication (ISemantic), Semarang, Indonesia, 130–33. IEEE.
Yadav, Ashima, and Dinesh Kumar Vishwakarma. 2023. “A Deep Multi￾Level Attentive Network for Multimodal Sentiment Analysis.” ACM
Transactions on Multimedia Computing, Communications and
Applications 19 (1): 1–19.
Yanmei, Liu, and Chen Yuda. 2015. “Research on Chinese Micro-Blog
Sentiment Analysis Based on Deep Learning.” In 2015 8th InternationalSymposium on Computational Intelligence and Design (ISCID),
Hangzhou, China, 1:358–61. IEEE.Index
Note: Bold page numbers refer to tables and italic page numbers refer to
figures.
accountability, data-driven optimization 105
accuracy
data 104
function, CFFS 23–24
improved 153
performance 135
ACO see ant colony optimization (ACO)
ACO-A* 147, 148
adaptive learning systems 163
advanced analytics technique 113, 216, 217
AHP see analytic hierarchy process (AHP)
AI see artificial intelligence (AI)
AI-powerful tools 109
analytical network process (ANP) 193
analytic hierarchy process (AHP) 178, 183, 187, 230
ANNs see artificial neural networks (ANNs)
ANP see analytical network process (ANP)
ant colony optimization (ACO) 70, 147–148
Ant-Miner 148archive 87
artificial intelligence (AI) 198
algorithms, precision 121
applications in
education administration 201–202
learning 202–203, 203
teaching 202
in business decision-making 121
challenges
bias and discrimination 204–205
deceptive coherence in incorrect responses 205
emotional intelligence deficit 205
ethical considerations 204
insufficient focus on student learning 205
lack of cultural diversity representation 205
data privacy and security 206
decision-making 118
educational contribution
accessibility and inclusion 208
collaboration and communication 208
data-driven decision-making 208
efficient administration 208
identification of at-risk students 208
intelligent content creation 208
intelligent tutoring 208
personalized learning 208
and fairness 163
impact of, educational sector 198
influence of 203
integration of 198, 207, 209
intelligent data-driven approaches for decision-making 108–109
Internet of Things and 221lifelong learning and adult education 206
limitations 205
opportunities and research agenda 206
paradigms of AI in education 206–207
pedagogical challenges and adaptation 207
personalization and adaptive learning 207
potential for 206
risks of, in education 203–204
teacher-student relationships 207
transformational potential and future directions 207–208
artificial neural networks (ANNs) 135–136, 145
asymptotic distribution 3, 6–8, 11–14
autonomous underwater vehicles (AUVs) 147, 148
Bayesian network structure learning algorithm 146, 147
Bayesian optimization auto ML time-series framework 151
Bayesian optimization model 126, 127
benchmarking optimization strategies 116–117
bidirectional encoder representations from transformers (BERT) 284,
287
big data 1, 106, 151, 154, 155, 216, 262
BiLSTM models 288
bio-simulated metaheuristic algorithms 135–136
bit error rate (BER) metrics 49
blockchain 222, 260, 262
business, data-driven algorithms 132
business decision-making
AI in 121
course of making 117
business intelligence (BI) reporting instruments 90
business process integration 114
California Consumer Privacy Act (CCPA) 115cancer classification, using microarray data 145
carbon emission (CE) 19, 20, 27, 28, 31, 31, 228, 229, 243, 252, 254,
271
CCPA see California Consumer Privacy Act (CCPA)
CCSA see chaos-embedded CSA (CCSA)
CE see carbon emission (CE)
CFFS see complex Fermatean fuzzy set (CFFS)
CFHFN-MOGSTP see complex Fermatean hesitant fuzzy
multiobjective green solid transportation problem (CFHFN-MOGSTP)
CFHFS see complex Fermatean hesitant fuzzy set (CFHFS)
CFS see complex fuzzy set (CFS)
chaos-embedded CSA (CCSA) 137
ChatGPT 201, 205
CHFS see complex hesitant fuzzy set (CHFS)
CIFS see complex intuitionistic fuzzy set (CIFS)
closed-loop DDO method 150, 151
cloud computing 146, 147, 161, 214
CNNs see convolutional neural networks (CNNs)
combinatorial optimization 132, 137, 147
complex Fermatean fuzzy set (CFFS) 19
complex Fermatean hesitant fuzzy multiobjective green solid
transportation problem (CFHFN-MOGSTP) 21
mathematical modelling 26, 26–28
solution procedure 28–29, 29
complex Fermatean hesitant fuzzy set (CFHFS) 20, 22
definition 22–23
fundamental operations 23
ranking function and accuracy function 23–24
theorem 24–25
complex fuzzy set (CFS) 18–19, 22
complex hesitant fuzzy set (CHFS) 19
complex intuitionistic fuzzy set (CIFS) 19complex probabilistic fuzzy set (CProFS) 19
complex probabilistic hesitant fuzzy soft set (CProHFSS) 19
complex Pythagorean fuzzy set (CPyFS) 19
computational models 152
computational techniques, optimization and 153
conflicting objectives 19, 70, 73, 88, 155, 270
consistency ratio (CR) 187
convex optimization 77–79, 78
convolutional neural networks (CNNs) 284, 286, 288, 289
cosine-based-similarity operators 56, 59–63, 63
CProFS see complex probabilistic fuzzy set (CProFS)
CProHFSS see complex probabilistic hesitant fuzzy soft set
(CProHFSS)
CPyFS see complex Pythagorean fuzzy set (CPyFS)
CR see consistency ratio (CR)
CSA see cuckoo search algorithm (CSA)
cuckoo search algorithm (CSA) 137
customer relationship management (CRM) digital tools 266
cybersecurity 109, 113, 132
Darwin’s theory of natural evolution 142
data as strategic asset 107
data-driven algorithms, performance of 153–154
data-driven approach 92
in data-driven heuristics 127–129
evolutionary optimization with 125
data-driven bio-simulation algorithms 135–136
data-driven computing 151
data-driven decision-making (DDDM) 90–92, 94, 94–98
artificial intelligence 108–109
benefits of 96–98, 97
deeping in 94–98draw conclusions 96
find data sources 95
find unresolved questions 97
guard against biases 97
improve company processes 98
know your vision 94
make confidence decisions 96–97
organize your data 95
perform data analysis 95–96
power of data 107
set measurable goals 97–98
data-driven evolutionary algorithms 140–141
data-driven evolutionary optimization
applications in
designing complex engineering systems 128
energy sector 128–129
financial sector 128
healthcare 128
supply chain management 129
utilization of 128
data-driven heuristics 126, 142–151
data-scarce optimization in 125–127
evolutionary optimization with data-driven approaches in 127–
129
instance feature-based algorithm selection in 131–132
temporal 125, 132–133
data-driven mathematical models 154–155
data-driven modeling methods 145
data-driven nature-inspired algorithms 136–138
data-driven optimization (DDO) 98–100, 150
applications in 101–103
energy management 102–103finance 102
healthcare 103
logistics and supply chain management 101–102
manufacturing 102
marketing 103
approaches 100–104
challenges and ethical considerations 103–104
data quality 103–104
model complexity 104
overfitting 104
closed-loop 151
dynamic realm of 98
ethical considerations in 104–106
accountability 105
bias and fairness 105
data privacy 104–105
unintended consequences 105
growing significance of 151
integer programming 101
linear programming 101
machine learning 101
nonlinear optimization 101
primary objective of 100–101
constraints 101
data 100
objectives 101
data-driven physics-based algorithms 138–140
data-driven solution approaches classification 156
population-based 156
swarm intelligence/robotics-based 156–157
data-driven swarm-based algorithms 141–142data-enhanced heuristic approach, human design actions within 129–
131
data-guided evolutionary optimization 127
data-informed swarm-based algorithms 141
data integration 113
data mining
exploration of classification rules in 148
and ML methodologies 140
data privacy
data-driven optimization 104–105
and security 114–115
data quality, data-driven optimization 103–104
data-scarce Bayesian optimization model 126, 127
data-scarce optimization 125–127
data-scarce optimization heuristics 126, 127
data science 90
data transfer through social media platforms 39
data visualization, intelligent data-driven approaches for decision￾making 111–113
DCP see disciplined convex programming (DCP)
DDDM see data-driven decision-making (DDDM)
DDO see data-driven optimization (DDO)
decision automation 113
decision intelligence 117–118
advantages 118, 120
in decision-making strategy 118–119
platforms 118
systematic approach 120
decision-makers (DMs) 69, 70, 119, 180, 183
decision-making 90, 91
artificial intelligence 118
data-driven 107with intelligence demands 119
intelligent data-driven approaches for 106
artificial intelligence 108–109
data visualization 111–113
ethical considerations 114–116
machine learning 109–110
power of data 106–108
predictive analytics 110–111
real-time decision support systems 113–114
methods, multi-criteria 177–178
optimization and 92–93
decision-making strategy, decision intelligence in 118–119
Decision-Making Trial and Evaluation Laboratory (DEMATEL) 193
decision variables 73, 77, 78, 81, 85, 87, 101
decomposition, multi-objective evolutionary algorithm based on 82, 84
deep learning 199–200
deep neural network (DNN) 286
defuzzification function 28
DEMATEL see Decision-Making Trial and Evaluation Laboratory
(DEMATEL)
deterministic algorithm 80
deterministic optimization 80
deviations 231
amount of 252, 252
consumption deviations and fleet fuel cost 251
cost deviations of the number of used cars 252, 253
in distribution assumptions 99
of fuel consumption 250, 251, 252
multi-objective method 252, 252, 254, 254
of objective function 245–248, 248
standard deviation of single-objective functions 249, 250
values of 248, 250DHFFS see dual hesitant Fermatean fuzzy set (DHFFS)
DHFS see dual hesitant fuzzy set (DHFS)
digital image sharing, on social media 38
digital image watermarking (DIW) 38, 40
digital integration technologies 265
digitalization 260–262
benefits of 262
in business models 264
impact with supply chain integration 266, 267
digital supply chain (DSC) 260–262
aim of 262–264
costs 264–265
digitalization impact with supply chain integration 266, 267
ecosystem 262–263, 263
importance and benefits of 263
industrial revolution phases 261, 261
integration in performance of organizations 266
lost sales (supply chain services) 264
new planning algorithms 265
on organization performance 265–266
planning 265
potential impact of 264
digital transformation 162, 213, 260, 267
disciplined convex programming (DCP) 78
discrete wavelet transform (DWT) 40
distributionally robust optimization (DRO) 99, 100
DIW see digital image watermarking (DIW)
DMs see decision-makers (DMs)
DNN see deep neural network (DNN)
dominance relation 86
Pareto 87
DRO see distributionally robust optimization (DRO)DSC see digital supply chain (DSC)
dual hesitant fermatean fuzzy experiment (DHFFE) 271
definition 272
elementary operations on 272
mathematical modeling 273, 273–275
numerical computation 277–280, 278–280, 281
proposed methodology 275–277, 276
score function 272
dual hesitant Fermatean fuzzy set (DHFFS) 271
dual hesitant fuzzy set (DHFS) 18, 270–271
dual-tiered algorithm 147
DWT see discrete wavelet transform (DWT)
edge computing, Internet of Things (IoT) 222
education 91, 107, 149, 150, 198, 200, 203, 206, 209
education administration, AI 201–202
educational contribution, AI
accessibility and inclusion 208
collaboration and communication 208
data-driven decision-making 208
efficient administration 208
identification of at-risk students 208
intelligent content creation 208
intelligent tutoring 208
personalized learning 208
electrochemical impedance spectroscopy (EIS), parameter estimation
144
electronic data interchange (EDI) 265
emotional signals for unsupervised sentiment analysis (ESSA) 285
Ensemble Learning (EL) techniques 157
enterprise resource planning (ERP) 266
environmental sustainability, Internet of Things (IoT) 213ERP see enterprise resource planning (ERP)
ESSA see emotional signals for unsupervised sentiment analysis
(ESSA)
evolutionary algorithms, data-driven 140–141
evolutionary optimization with data-driven approaches 125
feedback control systems 151
feedback loops, data-driven optimization (DDO) 105
Fermatean fuzzy parameters 20
Fermatean fuzzy programming 20
Fermatean fuzzy set (FFS) 22, 271
FMCDM see fuzzy multiple criteria decision-making (FMCDM)
FMO 159
Fourth Industrial Revolution 90
fractional transportation problems (FTPs) 270, 271, 281
FS see fuzzy set (FS)
FTPs see fractional transportation problems (FTPs)
fuzzy AHP method 183
fuzzy geometric methodology 271
fuzzy multiple criteria decision-making (FMCDM) 119–120
fuzzy programming (FP) 19, 34, 271, 275
Fermatean 20
fuzzy set (FS) 18–19, 270
extensions of 182
spherical 181, 182
trigonometric intuitionistic, similarity measures of 58–59
fuzzy set theory 55
fuzzy setting, pattern building materials in intuitionistic 68
GAMS software 230
GAs see genetic algorithms (GAs)
Gate software 285
Gaussian process (GP) 7models 145
regression model 99–100
GCM see global criterion method (GCM)
General Data Protection Regulation (GDPR) 115
genetic algorithms (GAs) 102, 142–145, 143
cancer classification using microarray data 145
electrochemical impedance spectroscopy parameter estimation
144
flexible job-shop scheduling problem 144
intrusion detection using 143
in ML 142–143
small satellite image downlink scheduling 144
workload smoothing in assembly lines 144
geometric programming (GP) 77–78
global criterion method (GCM) 19, 271, 277
G-MOFSTP see green multi-objective fractional STP (G-MOFSTP)
GP see geometric programming (GP)
Grand View Research report 177
Graph Neural Network Guided Local Search (GLS) 158
Greedy algorithm vs. meta-heuristic algorithms 124
green multi-objective fractional STP (G-MOFSTP) 271, 273
green supply chain network design (GSCND) 229
Guided Local Search (GLS), Graph Neural Network 158
Harris hawks optimization algorithm 146, 147
hazardous waste (HW) 17
classification of 17, 17–18
management 17–18, 30
hesitant fuzzy set (HFS) 22, 270
heuristic algorithms 123–125, 125; see also meta-heuristic algorithms
approximation vs. optimality 124
data-scarce optimization 125–127evolutionary optimization 127–129
H deriving heuristic strategies 129–131
instance feature-based algorithm 131–132
temporal data-driven heuristics 132–133
heuristic function 124
heuristic induction 129–130
data-driven approach 130
generalizability 131
from human design behavior 125
practicality 131
quick and efficient 131
HFS see hesitant fuzzy set (HFS)
H-Grey optimization, hybrid metaheuristic 38–39, 39
experimental results 49, 50, 51, 52
related work 40
watermark embedding and extraction 41–44, 41–45
watermark encryption and decryption 45–49, 46–48
hill-climbing techniques 70
human-AI collaboration 164
human design actions, within data-enhanced heuristic approaches 129–
131
human design behavior, heuristic induction from 125
human society, social interactions of 38
HW see hazardous waste (HW)
hybrid Harmony-Greywolf (H-Grey) optimization 49
hybrid metaheuristic H-Grey optimization 38–39, 39
experimental results 49, 50, 51, 52
related work 40
watermark embedding and extraction 41–44, 41–45
watermark encryption and decryption 45–49, 46–48
hybrid metaheuristics 159–161
hybrid PSO algorithm 145hybrid SVM-LR algorithm, for sentiment analysis 283–289, 290
IB-MOEA see indicator-based multi-objective evolutionary algorithm
(IB-MOEA)
IDS see intrusion detection system (IDS)
IFS see intuitionistic fuzzy set (IFS)
IFSMs see intuitionistic fuzzy similarity measures (IFSMs)
incremental conductance (IC) 145
indicator-based multi-objective evolutionary algorithm (IB-MOEA)
84, 85
Industry 4.0 (4IR) 90
industry revolution
data collection and analysis 213
enhanced connectivity 213
Internet of Things 213
instance feature-based algorithm, in data-driven heuristics 131–132
in data-driven heuristics 131–132
selection 125
integer programming (IP) 101
data-driven optimization 101
integrating optimization methodologies 152
integration of optimization and computing approaches 151–161, 156,
161
benefits of integration 162–163
energy and sustainability 162
financial portfolio management 162
healthcare and treatment planning 162
hybrid metaheuristics 159–161
local search-based 158–159
manufacturing and supply chain optimization 161–162
nature-inspired 157–158
physical phenomena 159
population-based 156swarm intelligence/robotics-based 156–157
intelligence demands, decision-making with 119
intelligent data-driven approaches for decision-making 106
artificial intelligence 108–109
data visualization 111–113
ethical considerations 114–116
machine learning 109–110
power of data 106–108
predictive analytics 110–111
real-time decision support systems 113–114
intelligent semi-autonomous agents 157
Intergovernmental Panel (2015) 224–225
Internet of Things (IoT) 212
addressing privacy concerns 219
analytics for extracting insights from IoT data 217
architecture 215
application layer 216
network layer 215–216
perception layer 215
and artificial intelligence 221
blockchain 222
challenges in widespread IoT adoption 222
challenges of managing IoT data 216
cloud computing 214
connectivity protocols 214
data management and analytics 216–217
edge computing 214–215, 222
edge computing for real-time AI in 221
environmental sustainability 213
ethical considerations in IoT deployment 222
evolution of 212
5G connectivity 222future trends and challenges 221–222
healthcare 222
implementation of 215
importance of data governance in 217
inception of 212
industry applications 220
agriculture 220
healthcare 220
home automation 220
manufacturing 220
smart cities 220
transportation 220
industry revolution 213
intersection of IoT and AI 221
intrusion detection system 219
intrusion prevention system 219
machine learning in 221
network segmentation 219
power of data-driven decision-making 217
predictive analytics for 221
proliferation of 213
protecting IoT data 219
securing IoT devices 218
securing IoT networks 218–219
security and privacy 218–219
sensors 213–214
significance, in digital era 213
smart agriculture 222
smart living 213
smart transportation 222
transformative capabilities 213
virtual private networks 219intrusion detection system (IDS) 143, 219
intrusion detection, using genetic algorithms 143
intrusion prevention system (IPS) 219
intuitionistic fuzzy set (IFS) 55, 56, 270
cosine similarity measures of 57
existing trigonometric-based-similarity measures of 57–59, 65
preliminaries 57–58
trigonometric similarity measures of 58–59
intuitionistic fuzzy setting, pattern building materials in 68
intuitionistic fuzzy similarity measures (IFSMs) 55, 56
intuitionistic fuzzy similarity operator 55–56
IoT see Internet of Things (IoT)
IP see integer programming (IP)
IPS see intrusion prevention system (IPS)
Iranian Social Security Institution, medical tourism in 180
J48 284
just noticeable difference (JND) model 40
key performance indicators (KPIs) 90
LAN2FIS (logistic adaptive network based on neurophagy inference
system) 287
Latin square sequence (LS) 46
least significant bits (LSBs) 40
substitution method 148
lifting wavelet transform (LWT) domain 40
linear programming (LP) 76–77, 101
data-driven optimization 101
linear programming problem (LPP) 19
linear regression (LRG) 293, 294
logistic regression (LR) 284, 287, 289
long short-term memory (LSTM) 286, 287LoRaWAN 214
LP see linear programming (LP)
LPP see linear programming problem (LPP)
LRG see linear regression (LRG)
LSTM see long short-term memory (LSTM)
machine learning (ML) 198–199
algorithms 153
data-driven optimization 101
genetic algorithms in 142–143
intelligent data-driven approaches for decision-making 109–110
in Internet of Things 221
models 284
in sentiment estimation 287
MAR see missing occurs at random (MAR)
Markov Decision Processes (MDPs), Safety Augmented (Saute) 149
Markov model 151
mathematical models, data-driven 154–155
maximum clique problem (MCP) 137
maximum likelihood estimator (MLE) of regression operator 6
MCDM see multicriteria decision-making (MCDM)
MCP see maximum clique problem (MCP)
MDPs see Markov Decision Processes (MDPs)
MDs see membership degrees (MDs)
mean estimator of regression operator 5
median estimator of regression operator 5–6
medical tourism 177
destination 188
in Iranian Social Security Institution 180
medical tourism index (MTI) 178, 179
country environment 179determination of main and sub-criterion importance levels
(weights) 187, 187–190
dimensions 179–180, 180
managerial implications 192
medical facility and services 180
medical tourism costs 179–180
theoretical implications 190–192
tourism destination 179
medical tourists categories 178–179
membership degrees (MDs) 19, 20
membership function 22, 28, 181, 183
M-estimation of functional regression operator 1–3
asymptotic distribution 11–13
choice of the kernel function 9
choice of ρ 10–11
confidence band of regression operator 13–14
maximum likelihood estimator of regression operator 6
mean estimator of regression operator 5
median estimator of regression operator 5–6
missing probability 9–10
model and preliminaries 3–5
small ball probability 6–8
smoothness of regression operator 8–9
M-estimation procedures 1
M-estimator on various models 2
meta-heuristic algorithms 122, 133–134, 135, 142–151
data-driven bio-simulation algorithms 135–136
data-driven evolutionary algorithms 140–141
data-driven heuristic and 142–151
data-driven nature-inspired algorithms 136–138
data-driven physics-based algorithms 138–140
data-driven swarm-based algorithms 141–142vs. Greedy algorithm 124
metaheuristics, hybrid 159–161
metrics
bit error rate 49
performance 294–296, 295
of precision 296
structure similarly index metrics (SSIM) 49
MILP see mixed-integer linear programming (MILP)
missing occurs at random (MAR) 1, 2, 4–6
mixed-integer linear programming (MILP) 102, 230, 232–243
ML see machine learning (ML)
MLP (multi-layer perceptron) classifier 288
MODA see multi-objective decision analysis (MODA)
MOPs see multi-objective optimization problems (MOPs)
MOPSO see multi-objective particle swarm optimization (MOPSO)
MOTP see multi-objective transportation problem (MOTP)
MPPT algorithm 145
MTI see medical tourism index (MTI)
multi-attribute optimization 72
multicriteria decision-making (MCDM) 119, 177–178
multicriteria optimization 72
multicriteria optimization problem see multi-objective optimization
problems (MOPs)
multi-objective decision analysis (MODA) 87
multi-objective evolutionary algorithm 82, 84
multi-objective green solid transportation problem (MOGSTP)
CFHFN-MOGSTP 21, 26, 26–29, 29
objectives of 32
multi-objective optimization 82–85, 84–86, 155
definition of terms in 85–88
multi-objective optimization problems (MOPs) 69–70, 81, 82
categorization of optimization techniques 70, 71, 72classification based on constraints
with constraints 75
equality or inequality 75
feasible space 76, 76
without constraints 74–75
classification based on objective and constraints
convex optimization 78, 78–79
geometric programming 77–78
linear programming 76–77
nonlinear programming 77
non-smooth optimization 79
quadratic programming 77
classification based on objective function 74
one or more objective functions 74
Pareto optimum 74
classification based on the nature of optimization
deterministic or stochastic 80
global or local 79–80
classification based on types of variables 80–81
classification of optimization problems 73
meaning of 71–73
methods of 82
optimization and optimization techniques 70
multi-objective particle swarm optimization (MOPSO) 84–85, 86
multi-objective programming 72
multi-objective transportation problem (MOTP) 19, 20, 270
multi-objective vector optimization 72
multiperformance optimization problem see multi-objective
optimization problems (MOPs)
Naive Bayes (NB) 284
narrowband (NB) IoT 214natural evolution, Darwin’s theory of 142
natural language processing (NLP) 109, 288
nature-inspired algorithms 157–158
data-driven 136–138
neural network optimization 150–151
neural network, Visual Geometry Group (VGG) 150
Neutrosophic Fuzzy Sets (NFS) 183
neutrosophic sets (NSs) 181
NFS see Neutrosophic Fuzzy Sets (NFS)
NLP see natural language processing (NLP)
NMD see non-membership degree (NMD)
non-deterministic parameter control mechanisms 140
non-dominated solutions 69, 87
non-dominated sorting genetic algorithm-II (NSGA-II) 82, 83
nonlinear optimization 101
data-driven optimization 101
nonlinear programming 77
non-membership degree (NMD) 19, 20
non-parametric models 1
non-parametric regression 1, 2
non-smooth optimization 79
normalized correlation (NC) 49
NSGA-II see non-dominated sorting genetic algorithm-II (NSGA-II)
NSs see neutrosophic sets (NSs)
numerical computation 30–32, 30–33, 33
objective function 28, 32, 73, 85
operator inference framework 150
opinion mining 283
optimal solutions 32, 124, 132, 153
attainment of 138
determination of 76–77of green 4-dimensional MOTP 20
Pareto 19, 29, 34, 69, 87, 133, 135, 155
optimization 87–88
benchmarking 116
and computational techniques 153
and computing approaches, integration of 151–161, 156
hybrid metaheuristics 159–161
local search-based 158–159
nature-inspired 157–158
physical phenomena 159
population-based 156
swarm intelligence/robotics-based 156–157
and decision-making 92–93
heuristics 125–126
hybrid Harmony-Greywolf (H-Grey) 49
model, Bayesian 126
model, data-scarce Bayesian 126
of population-based metaheuristic algorithms 141
problems, classification 73
of Quality of Experience 154
techniques 70
categorization 70, 71
optimization algorithms
amalgamation of 121
integration of heuristics with 122
in intelligent decision-making 116–123
heuristic algorithms 123–133, 125
meta-heuristic algorithms 133–142, 135
performance of 122
Ortony, Clore, and Collins–in Online Review (OCC- OR) emotion
model 286parameter estimation, electrochemical impedance spectroscopy 144
Pareto dominance relation 87
Pareto efficiency 74
Pareto optimality 74, 86–87
Pareto optimal solutions 19, 29, 34, 69, 87, 133, 135, 155
Pareto optimization 72, 74
Particle Swarm Optimization (PSO) 145–146, 156
pattern recognition problem 63–64, 64
peak signal to noise ratio (PSNR) 49
‘Pentagonal Forms of Decision-Making’ 91
personally identifiable information (PII) 105
perturb and observe (PO) 145
PFS see Pythagorean fuzzy set (PFS)
physics-based algorithms, data-driven 138–140
PII see personally identifiable information (PII)
pinpoint precision 110
population-based data-driven techniques 156
population-based metaheuristic algorithms, optimization of 141
precision 128, 296
of AI algorithms 121
enhanced 160
IoT-based 213
metrics of 296
of model 295
pinpoint 110
of WECS output 151
predictive analytics
intelligent data-driven approaches for decision-making 110–111
for Internet of Things (IoT) 221
PSNR see peak signal to noise ratio (PSNR)
PSO see Particle Swarm Optimization (PSO)
push and pull theory 179Pythagorean fuzzy set (PFS) 181, 271
Pythagorean hesitant Fermatean fuzzy programming 20
quadratic programming (QP) 77
Quality of Experience (QoE), optimization of 154
Rajarajeswari and Uma’s similarity operator 59
Rao-2 algorithm 136
RDWT see redundant discrete wavelet transform (RDWT)
real-time data processing 113
real-time decision support system 113, 114
intelligent data-driven approaches for decision-making 113–114
recall 4, 10, 60, 158, 287, 296
receiver operating characteristic (ROC) curve 303–304
recursive neural deep models (RNDMs) 285
redundant discrete wavelet transform (RDWT) 39
regression model
Gaussian process 99–100
non-parametric 1
regression operator
maximum likelihood estimator of 6
M-estimation of functional 1–3
asymptotic distribution 11–13
choice of the kernel function 9
choice of ρ 10–11
confidence band of regression operator 13–14
maximum likelihood estimator of regression operator 6
mean estimator of regression operator 5
median estimator of regression operator 5–6
missing probability 9–10
model and preliminaries 3–5
small ball probability 6–8smoothness of regression operator 8–9
reinforcement learning (RL) 109, 148–150, 198
representative-based estimation (RBE) technique 147
RGWE (Refined Global Word Embeddings) method 289
RL see reinforcement learning (RL)
RL-Cycle GAN 149
RL-Scope 149
RNDMs see recursive neural deep models (RNDMs)
robotic artwork generation 157
robust optimization 99
SA see simulated annealing (SA)
Safety Augmented (Saute) Markov Decision Processes (MDPs) 149
safety cost (SC) 27, 28, 30, 31, 32
saute RL algorithms 149
SC see safety cost (SC)
self-adaptation 140
sensitivity analysis, data-driven optimization 105
sensors, Internet of Things (IoT) 213–214
sentiment analysis 283
on Arabic tweets 288
challenges in 284
hybrid SVM-LR algorithm for 283–289, 290
classification algorithm 293
data preparation 292–293
data preprocessing 291–292, 291
dataset description and visualization 296–299, 297, 298
data source 291
data splitting 299
linear regression 294
performance metrics 294–296, 295
processing of emoticons 292receiver operating characteristic curve 301–302
result presentation 299, 299–302, 300, 301
state-of-the-art algorithms 302, 302–303, 303, 303
support vector machine 293–294
significance of 284
survey on 285–286
on U.S.-based COVID-19 tweets 288
sentiment estimation, machine learning models in 287
sentiment polarity 283
set pair analysis theory 56
SFAHP see spherical fuzzy analytic hierarchy process (SFAHP)
SFSs see spherical fuzzy sets (SFSs)
SGA see Simple Genetic Algorithm (SGA)
similarity operator
cosine-based 56, 59–63, 63
of IFSs 56, 57
intuitionistic fuzzy 55–56
Rajarajeswari and Uma 59
Tian 59
Ye 59
Simple Genetic Algorithm (SGA) 143
simulated annealing (SA) 70, 146–147
simulation and modeling 157–158
Simultaneous Perturbation Stochastic Approximation (SPSA) 150
single-objective optimization (SOO) 69, 70, 74, 155
singular value decomposition (SVD) 39, 40
smart city, data-driven algorithms 132
smart healthcare, data-driven algorithms 132
social interactions of human society 38
social media, digital image sharing on 38
solid transportation problem (STP) 270
SOO see single-objective optimization (SOO)sophisticated analytics techniques 90
SPAL model 288
spherical fuzzy analytic hierarchy process (SFAHP) 178, 181, 183–
186, 184, 188
spherical fuzzy sets (SFSs) 178, 181, 182
SPSA see Simultaneous Perturbation Stochastic Approximation
(SPSA)
SSGA see Steady State Genetic Algorithm (SSGA)
SSIM see structure similarly index metrics (SSIM)
Steady State Genetic Algorithm (SSGA) 143
stochastic optimization 80
STP see solid transportation problem (STP)
strategic asset 107
structure similarly index metrics (SSIM) 49
support vector machine (SVM) 40, 284, 285, 289, 293–294
support vector machine sequential minimal optimization (SVMSMO)
286
sustainability 224, 226
sustainable development 224
sustainable solutions 224
sustainable transportation 224, 243–254, 244, 244, 245–248, 249, 250,
250–254
assumptions of problem 230–232, 231
constraints 238–243
evaluation of 226–227, 227, 228
index and parameter 232, 233–235
objective function 236–238
transportation model 230
SVD see singular value decomposition (SVD)
SVM see support vector machine (SVM)
SVMSMO (support vector machine sequential minimal optimization)
286swarm-based algorithms
data-driven 141–142
data-informed 141
swarm intelligence/robotics-based algorithm 156–157
Tabu Search (TS) 147
TC see transportation cost (TC)
teacher-student relationships, AI role 207
TEE see trusted execution environment (TEE)
temporal data-driven heuristics 125
tf-IDF (term frequency-inverse document frequency) format 288, 293
T2FS see type-2 fuzzy sets (T2FS)
Tian’s similarity operator 59
Time-Aware Knowledge Extraction (TAKE) methodology 287
TP see transportation problem (TP)
trade-offs 87
traditional business models 118
transit hub 139
transportation cost (TC) 19, 20, 26, 27, 30, 30, 32, 101
transportation model 20
transportation problem (TP) 19, 270
transportation, sustainable transportation see sustainable transportation
transportation time (TT) 19, 20
traveling salesman problem (TSP) 101, 148
treatment, storage, or disposal facility (TSDF) 20
trigonometric intuitionistic fuzzy set 58–59
trusted execution environment (TEE) 218
TS see Tabu Search (TS)
TSDF see treatment, storage, or disposal facility (TSDF)
TSP see traveling salesman problem (TSP)
TT see transportation time (TT)
two-stage model 179type-2 fuzzy sets (T2FS) 181
vector optimization 72
vector optimization problem see multi-objective optimization
problems (MOPs)
virtual private networks (VPNs) 219
Visual Geometry Group (VGG) neural network 150
visualization and alerts 114
VOSviewer 226
VRP 101
waste 17
hazardous waste 17, 17–18
management 17–18, 30
watermark decryption 47, 48
watermark embedding and extraction 41–44, 41–45
watermark encryption process 45–49, 46–48
weighted sum technique (WST) 275
wind energy conversion system (WECS) 151
Ye’s similarity operators 59
Zigbee 214
